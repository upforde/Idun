{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import os\n",
    "from sdv.tabular import CTGAN\n",
    "from utils.utils import *\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0. Prelude.</h3>\n",
    "This pipeline takes care of the CTGAN generation and sampling. <br>\n",
    "First we decide on either generation just one type or both. <br>\n",
    "Thereafter we ensure distances between the generated matches attributes. <br>\n",
    "Lastly we save the data corresponding the wished format. i.e. either a dataframe or as a text. <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r'C:\\Users\\aleks\\Desktop\\Master Thesis\\Idun\\CTGAN\\testing_param\\textual_time\\cpu'\n",
    "model_A_name = \"textual_m_1000_3000.pkl\"\n",
    "model_A_sample_size = 1000\n",
    "\n",
    "# Determine if we are generating both types of data.\n",
    "# NOTE: If we are, model_A should always be \"matched\" !!!\n",
    "generate_both = False\n",
    "if generate_both:\n",
    "    model_B_name = \"Placeholder2.pkl\"\n",
    "    model_B_sample_size = 1000\n",
    "else:\n",
    "    # Determine what type of singular data we are generating\n",
    "    generate_matches = True\n",
    "\n",
    "# If the syntethic dataset should be saved as a dataframe or text \n",
    "ditto_format = False \n",
    "\n",
    "# The directory for where the dataset will be saved, and its name. \n",
    "datasets_dir = r'C:\\Users\\aleks\\Desktop\\Master Thesis\\Py_Magellan\\DataSets\\temp'\n",
    "name_of_sample_set = \"generated_set\"\n",
    "\n",
    "# Takes care of file format...\n",
    "if ditto_format:\n",
    "    name_of_sample_set = name_of_sample_set + \".txt\"\n",
    "else:\n",
    "    name_of_sample_set = name_of_sample_set + \".csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Load models.</h3>\n",
    "First, load the CTGAN model(s) from our model path. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_path = model_dir + os.sep + model_A_name\n",
    "\n",
    "if generate_both:\n",
    "    model_B_path = model_dir + os.sep + model_B_name\n",
    "    model_B = CTGAN.load(model_B_path)\n",
    "\n",
    "    model_A = CTGAN.load(model_A_path)\n",
    "else:\n",
    "    model_A = CTGAN.load(model_A_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Generate Matches and/or Non-Matches.</h3>\n",
    "After loading our model(s), we generate the synthethic sample data. <br>\n",
    "Then, we ensure that the generated matches follows some coherency between the attributes <br>\n",
    "between l_table and r_table. We use Levhenstein distance to ensure similarities between the attributes. <br>\n",
    "Lastly, we concat the tables together if we are generating both types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_both:\n",
    "    model_A_data = model_A.sample(model_A_sample_size)\n",
    "    model_B_data = model_B.sample(model_B_sample_size)\n",
    "\n",
    "    model_A_data = ensure_data(model_A_data, True)\n",
    "    model_B_data = ensure_data(model_B_data, False)\n",
    "    data = model_A_data.append(model_B_data, ignore_index=True)\n",
    "else:\n",
    "    model_A_data = model_A.sample(100000)\n",
    "    if generate_matches:\n",
    "        data = ensure_data(model_A_data, True, 0.6)\n",
    "    else:\n",
    "        data = ensure_data(model_A_data, False)\n",
    "\n",
    "# temp_path = r'C:\\Users\\aleks\\Desktop\\Master Thesis\\Idun\\CTGAN\\testing_param\\textual_time\\cpu\\train.txt'\n",
    "\n",
    "# with open(temp_path, 'r', encoding='utf-8') as file:\n",
    "#         data_origin = file.read()\n",
    "\n",
    "# table_A, table_B, truth_table = ditto_reformater(data_origin)\n",
    "\n",
    "# table_A = table_A.add_prefix(\"ltable_\")\n",
    "# table_B = table_B.add_prefix(\"rtable_\")\n",
    "# table = pd.concat([table_A, table_B, truth_table], axis=1)\n",
    "\n",
    "# table = table[table['Truth'] > 0]\n",
    "# orig_columns = table.columns.to_list()\n",
    "\n",
    "# display(HTML(table.drop_duplicates().to_html()))\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "# data = data[orig_columns]\n",
    "display(HTML(data.to_html()))\n",
    "len(data.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Lastly, we ensure that the data format is satisfied.</h3>\n",
    "If we are generating data to be tested for \"Magellan\", we can conclude and <br>\n",
    "save the dataframe to a .csv file. <br> <br>\n",
    "If the data is to be fed to \"DITTO\", we need to reformat the dataframe to <br>\n",
    "a text-based format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ditto_format:\n",
    "    ditto_data = magellan_reformater(data)\n",
    "\n",
    "    data_save_path = datasets_dir + os.sep + name_of_sample_set\n",
    "\n",
    "    with open(data_save_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(ditto_data)\n",
    "else:\n",
    "    data.to_csv(datasets_dir + os.sep + name_of_sample_set)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2058fc30687b0128d95a989c948081aa14c6a2edcd16aff3f04d2286aad1f775"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
