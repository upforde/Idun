cuda
Device: cuda
step: 0, loss: 0.7818814516067505
step: 10, loss: 0.5372042059898376
step: 20, loss: 0.5091540813446045
step: 30, loss: 0.5406774878501892
step: 40, loss: 0.4521246552467346
step: 50, loss: 0.15927383303642273
step: 60, loss: 0.7575279474258423
step: 70, loss: 0.1343287229537964
step: 80, loss: 0.15644720196723938
step: 90, loss: 0.21917392313480377
step: 100, loss: 0.17116397619247437
step: 110, loss: 0.16744820773601532
step: 120, loss: 0.18316513299942017
step: 130, loss: 0.4021960496902466
step: 140, loss: 0.11896669119596481
step: 150, loss: 0.24727904796600342
step: 160, loss: 0.32971811294555664
step: 170, loss: 0.11096492409706116
step: 180, loss: 0.1427774876356125
step: 190, loss: 0.05794680863618851
step: 200, loss: 0.16946087777614594
step: 210, loss: 0.1767338514328003
step: 220, loss: 0.1522926539182663
step: 230, loss: 0.21978990733623505
step: 240, loss: 0.03214266896247864
step: 250, loss: 0.24506090581417084
step: 260, loss: 0.20767022669315338
step: 270, loss: 0.12203028798103333
step: 280, loss: 0.055601317435503006
step: 290, loss: 0.1354178786277771
step: 300, loss: 0.22413162887096405
step: 310, loss: 0.145566925406456
step: 320, loss: 0.2587844431400299
step: 330, loss: 0.11681661754846573
step: 340, loss: 0.1671711802482605
step: 350, loss: 0.239879310131073
step: 360, loss: 0.15578505396842957
step: 370, loss: 0.16625165939331055
step: 380, loss: 0.06593778729438782
step: 390, loss: 0.08714871853590012
step: 400, loss: 0.19600379467010498
step: 410, loss: 0.18416456878185272
step: 420, loss: 0.10519964247941971
step: 430, loss: 0.14868339896202087
step: 440, loss: 0.07963932305574417
step: 450, loss: 0.10660625994205475
step: 460, loss: 0.25205865502357483
epoch 1: dev_f1=0.9742441209406495, f1=0.9773755656108598, best_f1=0.9773755656108598
step: 0, loss: 0.09760560840368271
step: 10, loss: 0.12719306349754333
step: 20, loss: 0.1321854442358017
step: 30, loss: 0.08127661794424057
step: 40, loss: 0.08523350954055786
step: 50, loss: 0.02362036518752575
step: 60, loss: 0.0998569056391716
step: 70, loss: 0.08528181910514832
step: 80, loss: 0.17873840034008026
step: 90, loss: 0.10093678534030914
step: 100, loss: 0.15739397704601288
step: 110, loss: 0.18627017736434937
step: 120, loss: 0.022830070927739143
step: 130, loss: 0.07400942593812943
step: 140, loss: 0.08837307244539261
step: 150, loss: 0.0340094156563282
step: 160, loss: 0.05040460079908371
step: 170, loss: 0.005960347130894661
step: 180, loss: 0.3028672933578491
step: 190, loss: 0.05478028953075409
step: 200, loss: 0.17779238522052765
step: 210, loss: 0.10874007642269135
step: 220, loss: 0.1635570526123047
step: 230, loss: 0.16323457658290863
step: 240, loss: 0.04356754571199417
step: 250, loss: 0.091481052339077
step: 260, loss: 0.2678813338279724
step: 270, loss: 0.1055719256401062
step: 280, loss: 0.035798508673906326
step: 290, loss: 0.03809270262718201
step: 300, loss: 0.08729170262813568
step: 310, loss: 0.1834716498851776
step: 320, loss: 0.06205131113529205
step: 330, loss: 0.13632334768772125
step: 340, loss: 0.14332614839076996
step: 350, loss: 0.14965564012527466
step: 360, loss: 0.08310213685035706
step: 370, loss: 0.13125623762607574
step: 380, loss: 0.1923859417438507
step: 390, loss: 0.0463167279958725
step: 400, loss: 0.07061164826154709
step: 410, loss: 0.11425691097974777
step: 420, loss: 0.01855160854756832
step: 430, loss: 0.08256682008504868
step: 440, loss: 0.09798850864171982
step: 450, loss: 0.15063036978244781
step: 460, loss: 0.16565337777137756
epoch 2: dev_f1=0.9865470852017937, f1=0.9730941704035874, best_f1=0.9730941704035874
step: 0, loss: 0.07425413280725479
step: 10, loss: 0.011378221213817596
step: 20, loss: 0.08202560245990753
step: 30, loss: 0.1530056893825531
step: 40, loss: 0.11170374602079391
step: 50, loss: 0.0665016695857048
step: 60, loss: 0.0447782538831234
step: 70, loss: 0.1474636048078537
step: 80, loss: 0.1309899538755417
step: 90, loss: 0.10501454770565033
step: 100, loss: 0.08844199031591415
step: 110, loss: 0.1326306313276291
step: 120, loss: 0.07657364010810852
step: 130, loss: 0.05545083060860634
step: 140, loss: 0.06110898777842522
step: 150, loss: 0.08428721874952316
step: 160, loss: 0.02764822542667389
step: 170, loss: 0.08249875158071518
step: 180, loss: 0.08923805505037308
step: 190, loss: 0.056531861424446106
step: 200, loss: 0.0718110203742981
step: 210, loss: 0.023950528353452682
step: 220, loss: 0.09484139084815979
step: 230, loss: 0.02819109335541725
step: 240, loss: 0.12194118648767471
step: 250, loss: 0.06692204624414444
step: 260, loss: 0.09199527651071548
step: 270, loss: 0.06906503438949585
step: 280, loss: 0.11885847896337509
step: 290, loss: 0.07857150584459305
step: 300, loss: 0.06701698899269104
step: 310, loss: 0.15288633108139038
step: 320, loss: 0.015111143700778484
step: 330, loss: 0.15078918635845184
step: 340, loss: 0.08439433574676514
step: 350, loss: 0.23526616394519806
step: 360, loss: 0.049352627247571945
step: 370, loss: 0.022831179201602936
step: 380, loss: 0.01842249371111393
step: 390, loss: 0.10298576951026917
step: 400, loss: 0.02897401712834835
step: 410, loss: 0.06074695289134979
step: 420, loss: 0.0005149334901943803
step: 430, loss: 0.14940635859966278
step: 440, loss: 0.07851152867078781
step: 450, loss: 0.021304981783032417
step: 460, loss: 0.015509570948779583
epoch 3: dev_f1=0.9876265466816648, f1=0.9784824462061155, best_f1=0.9784824462061155
step: 0, loss: 0.13621851801872253
step: 10, loss: 0.11328379064798355
step: 20, loss: 0.07863761484622955
step: 30, loss: 0.14398884773254395
step: 40, loss: 0.0008243737975135446
step: 50, loss: 0.10907606780529022
step: 60, loss: 0.04777169227600098
step: 70, loss: 0.03839497268199921
step: 80, loss: 0.032173190265893936
step: 90, loss: 0.17038677632808685
step: 100, loss: 0.052822697907686234
step: 110, loss: 0.08418180048465729
step: 120, loss: 0.1498338133096695
step: 130, loss: 0.14878198504447937
step: 140, loss: 0.08424364030361176
step: 150, loss: 0.11118454486131668
step: 160, loss: 0.0060912310145795345
step: 170, loss: 0.21656441688537598
step: 180, loss: 0.08787497133016586
step: 190, loss: 0.09139364957809448
step: 200, loss: 0.02803053706884384
step: 210, loss: 0.044663287699222565
step: 220, loss: 0.012599954381585121
step: 230, loss: 0.1389560103416443
step: 240, loss: 0.026131991297006607
step: 250, loss: 0.010694886557757854
step: 260, loss: 0.03513680398464203
step: 270, loss: 0.043325867503881454
step: 280, loss: 0.15450002253055573
step: 290, loss: 0.010039363987743855
step: 300, loss: 0.08424345403909683
step: 310, loss: 0.09021220356225967
step: 320, loss: 0.048518337309360504
step: 330, loss: 0.029788406565785408
step: 340, loss: 0.21005234122276306
step: 350, loss: 0.01654980145394802
step: 360, loss: 0.045125432312488556
step: 370, loss: 0.055052876472473145
step: 380, loss: 0.010632222518324852
step: 390, loss: 0.006771069020032883
step: 400, loss: 0.014927358366549015
step: 410, loss: 0.18213632702827454
step: 420, loss: 0.01031437423080206
step: 430, loss: 0.053125154227018356
step: 440, loss: 0.07134187966585159
step: 450, loss: 0.06671818345785141
step: 460, loss: 0.09346242994070053
epoch 4: dev_f1=0.9898762654668166, f1=0.9798206278026906, best_f1=0.9798206278026906
step: 0, loss: 0.11802183091640472
step: 10, loss: 0.08792202174663544
step: 20, loss: 0.027123307809233665
step: 30, loss: 0.09431619197130203
step: 40, loss: 0.1570017784833908
step: 50, loss: 0.007263283245265484
step: 60, loss: 0.042370084673166275
step: 70, loss: 0.05593089014291763
step: 80, loss: 0.00987863726913929
step: 90, loss: 0.08221188187599182
step: 100, loss: 0.13842400908470154
step: 110, loss: 0.019865315407514572
step: 120, loss: 0.10456302762031555
step: 130, loss: 0.06999334692955017
step: 140, loss: 0.12428642809391022
step: 150, loss: 8.07750184321776e-05
step: 160, loss: 0.08146799355745316
step: 170, loss: 0.1305921971797943
step: 180, loss: 0.01397774089127779
step: 190, loss: 0.014954309910535812
step: 200, loss: 0.01029707957059145
step: 210, loss: 0.033733006566762924
step: 220, loss: 0.011112351901829243
step: 230, loss: 0.03934643045067787
step: 240, loss: 0.03678913414478302
step: 250, loss: 0.09079290181398392
step: 260, loss: 0.08921590447425842
step: 270, loss: 0.037017371505498886
step: 280, loss: 0.041417643427848816
step: 290, loss: 0.14966264367103577
step: 300, loss: 0.03685859590768814
step: 310, loss: 0.052597712725400925
step: 320, loss: 0.1352948248386383
step: 330, loss: 0.10187622904777527
step: 340, loss: 0.00910396222025156
step: 350, loss: 0.10983314365148544
step: 360, loss: 0.09281612932682037
step: 370, loss: 0.05846331641077995
step: 380, loss: 0.08393758535385132
step: 390, loss: 0.031639520078897476
step: 400, loss: 0.016271037980914116
step: 410, loss: 0.020681124180555344
step: 420, loss: 0.08457045257091522
step: 430, loss: 0.08212321996688843
step: 440, loss: 0.025435376912355423
step: 450, loss: 0.13909316062927246
step: 460, loss: 0.0024371205363422632
epoch 5: dev_f1=0.9808773903262092, f1=0.9753363228699552, best_f1=0.9798206278026906
step: 0, loss: 0.13517478108406067
step: 10, loss: 0.1458377093076706
step: 20, loss: 0.05712142959237099
step: 30, loss: 0.013524779118597507
step: 40, loss: 0.017537539824843407
step: 50, loss: 0.2652568817138672
step: 60, loss: 0.0702950730919838
step: 70, loss: 0.009939901530742645
step: 80, loss: 0.06188949570059776
step: 90, loss: 0.10242283344268799
step: 100, loss: 0.00702841067686677
step: 110, loss: 0.010327213443815708
step: 120, loss: 0.07091421633958817
step: 130, loss: 0.036215584725141525
step: 140, loss: 0.06665940582752228
step: 150, loss: 0.019174115732312202
step: 160, loss: 0.03907008469104767
step: 170, loss: 0.023429198190569878
step: 180, loss: 0.04489799588918686
step: 190, loss: 0.09211257100105286
step: 200, loss: 0.10607819259166718
step: 210, loss: 0.08694557845592499
step: 220, loss: 0.07580596208572388
step: 230, loss: 0.10070647299289703
step: 240, loss: 0.10860597342252731
step: 250, loss: 0.062310829758644104
step: 260, loss: 0.009475024417042732
step: 270, loss: 0.0010396064026281238
step: 280, loss: 0.12813061475753784
step: 290, loss: 0.03032972849905491
step: 300, loss: 0.024626174941658974
step: 310, loss: 0.03196098282933235
step: 320, loss: 0.13639698922634125
step: 330, loss: 0.13064683973789215
step: 340, loss: 0.10888129472732544
step: 350, loss: 0.07374320924282074
step: 360, loss: 0.00732270535081625
step: 370, loss: 0.012048684060573578
step: 380, loss: 0.00606057932600379
step: 390, loss: 0.1071195900440216
step: 400, loss: 0.10732028633356094
step: 410, loss: 0.00021663561346940696
step: 420, loss: 0.04550446569919586
step: 430, loss: 0.11684533953666687
step: 440, loss: 0.058130595833063126
step: 450, loss: 0.04523769021034241
step: 460, loss: 0.10511750727891922
epoch 6: dev_f1=0.9910112359550561, f1=0.978675645342312, best_f1=0.978675645342312
step: 0, loss: 0.038266465067863464
step: 10, loss: 0.06604713201522827
step: 20, loss: 0.05236579477787018
step: 30, loss: 0.04039814695715904
step: 40, loss: 0.04072830453515053
step: 50, loss: 0.1541605144739151
step: 60, loss: 0.022458186373114586
step: 70, loss: 0.006537502631545067
step: 80, loss: 0.024771321564912796
step: 90, loss: 0.04925701022148132
step: 100, loss: 0.017235146835446358
step: 110, loss: 0.113029845058918
step: 120, loss: 0.0651431530714035
step: 130, loss: 0.15781690180301666
step: 140, loss: 0.03605864569544792
step: 150, loss: 0.02489404007792473
step: 160, loss: 0.06797077506780624
step: 170, loss: 0.048833008855581284
step: 180, loss: 0.13481512665748596
step: 190, loss: 0.06393998116254807
step: 200, loss: 0.15588951110839844
step: 210, loss: 0.24406369030475616
step: 220, loss: 0.05209215730428696
step: 230, loss: 0.009434797801077366
step: 240, loss: 0.0067716618068516254
step: 250, loss: 0.10966445505619049
step: 260, loss: 0.10496844351291656
step: 270, loss: 0.03321147337555885
step: 280, loss: 0.047221336513757706
step: 290, loss: 0.127009779214859
step: 300, loss: 0.006154924165457487
step: 310, loss: 0.006001742091029882
step: 320, loss: 0.04630499333143234
step: 330, loss: 0.022354602813720703
step: 340, loss: 0.09272163361310959
step: 350, loss: 0.05418666452169418
step: 360, loss: 0.1120937317609787
step: 370, loss: 0.09315859526395798
step: 380, loss: 0.025976186618208885
step: 390, loss: 0.13308146595954895
step: 400, loss: 0.010129342786967754
step: 410, loss: 0.056942276656627655
step: 420, loss: 0.07726521790027618
step: 430, loss: 0.11667375266551971
step: 440, loss: 0.012993727810680866
step: 450, loss: 0.0720910131931305
step: 460, loss: 0.0194559209048748
epoch 7: dev_f1=0.9921436588103255, f1=0.9832026875699889, best_f1=0.9832026875699889
step: 0, loss: 0.08427388966083527
step: 10, loss: 0.0713392049074173
step: 20, loss: 5.0963561079697683e-05
step: 30, loss: 0.3149926960468292
step: 40, loss: 0.03626511991024017
step: 50, loss: 0.02787133865058422
step: 60, loss: 0.024428801611065865
step: 70, loss: 0.036318644881248474
step: 80, loss: 0.08193794637918472
step: 90, loss: 0.031145673245191574
step: 100, loss: 0.024397574365139008
step: 110, loss: 0.07920056581497192
step: 120, loss: 0.04192802309989929
step: 130, loss: 0.11177221685647964
step: 140, loss: 0.009286796674132347
step: 150, loss: 0.16916416585445404
step: 160, loss: 0.09333381801843643
step: 170, loss: 0.04798687621951103
step: 180, loss: 0.033924419432878494
step: 190, loss: 0.061766549944877625
step: 200, loss: 0.01239790953695774
step: 210, loss: 0.0663282722234726
step: 220, loss: 0.018393196165561676
step: 230, loss: 0.009456801228225231
step: 240, loss: 0.046453122049570084
step: 250, loss: 0.0032655643299221992
step: 260, loss: 0.046069782227277756
step: 270, loss: 0.05648628994822502
step: 280, loss: 0.10694266110658646
step: 290, loss: 0.0672530010342598
step: 300, loss: 0.039464376866817474
step: 310, loss: 0.08736250549554825
step: 320, loss: 0.04418538883328438
step: 330, loss: 0.07505441457033157
step: 340, loss: 0.10993331670761108
step: 350, loss: 0.05040665343403816
step: 360, loss: 0.024025477468967438
step: 370, loss: 0.062019653618335724
step: 380, loss: 0.01938081532716751
step: 390, loss: 0.0020947048906236887
step: 400, loss: 0.15220534801483154
step: 410, loss: 0.06382495164871216
step: 420, loss: 0.04217468574643135
step: 430, loss: 0.07863249629735947
step: 440, loss: 0.016085313633084297
step: 450, loss: 0.08332285284996033
step: 460, loss: 0.1223132461309433
epoch 8: dev_f1=0.990990990990991, f1=0.9764837625979844, best_f1=0.9832026875699889
step: 0, loss: 0.006868353579193354
step: 10, loss: 0.041157253086566925
step: 20, loss: 0.02993537299335003
step: 30, loss: 0.0190604105591774
step: 40, loss: 0.042130403220653534
step: 50, loss: 0.011175861582159996
step: 60, loss: 0.009351421147584915
step: 70, loss: 0.012850604020059109
step: 80, loss: 0.04181182384490967
step: 90, loss: 0.11586389690637589
step: 100, loss: 0.11287321895360947
step: 110, loss: 0.06970711052417755
step: 120, loss: 0.05778151750564575
step: 130, loss: 0.06188022717833519
step: 140, loss: 0.049446962773799896
step: 150, loss: 0.007639992982149124
step: 160, loss: 0.08195111155509949
step: 170, loss: 0.025301188230514526
step: 180, loss: 0.07537069171667099
step: 190, loss: 0.06247257441282272
step: 200, loss: 0.05235062167048454
step: 210, loss: 0.020605972036719322
step: 220, loss: 0.022501487284898758
step: 230, loss: 0.1075507253408432
step: 240, loss: 0.06082470342516899
step: 250, loss: 0.05314240977168083
step: 260, loss: 0.04328471049666405
step: 270, loss: 0.04064887389540672
step: 280, loss: 0.058722544461488724
step: 290, loss: 0.020532015711069107
step: 300, loss: 0.05453208461403847
step: 310, loss: 0.18788982927799225
step: 320, loss: 0.07299311459064484
step: 330, loss: 0.006702384911477566
step: 340, loss: 0.21834318339824677
step: 350, loss: 0.06411569565534592
step: 360, loss: 0.04309755563735962
step: 370, loss: 0.06189557909965515
step: 380, loss: 0.06271187961101532
step: 390, loss: 0.017301976680755615
step: 400, loss: 0.04797700047492981
step: 410, loss: 0.0595228411257267
step: 420, loss: 0.15106800198554993
step: 430, loss: 0.11673813313245773
step: 440, loss: 0.03326096758246422
step: 450, loss: 0.03261242061853409
step: 460, loss: 0.053151167929172516
epoch 9: dev_f1=0.9898534385569334, f1=0.978675645342312, best_f1=0.9832026875699889
step: 0, loss: 0.09714086353778839
step: 10, loss: 0.02424057200551033
step: 20, loss: 0.04428810626268387
step: 30, loss: 0.02861166000366211
step: 40, loss: 0.07585792243480682
step: 50, loss: 0.03830797225236893
step: 60, loss: 0.09065127372741699
step: 70, loss: 0.013126146979629993
step: 80, loss: 0.10300509631633759
step: 90, loss: 0.04107733070850372
step: 100, loss: 0.011449412442743778
step: 110, loss: 0.07866610586643219
step: 120, loss: 0.05453226715326309
step: 130, loss: 0.029016146436333656
step: 140, loss: 0.03496529534459114
step: 150, loss: 0.003525943960994482
step: 160, loss: 0.03682404011487961
step: 170, loss: 0.09728527069091797
step: 180, loss: 0.06312653422355652
step: 190, loss: 0.05508141219615936
step: 200, loss: 0.04529066011309624
step: 210, loss: 0.03664935752749443
step: 220, loss: 0.005300790071487427
step: 230, loss: 0.06238454580307007
step: 240, loss: 0.06621001660823822
step: 250, loss: 0.1666281521320343
step: 260, loss: 0.1347438246011734
step: 270, loss: 0.043198589235544205
step: 280, loss: 0.02340090088546276
step: 290, loss: 0.010908753611147404
step: 300, loss: 0.04673464968800545
step: 310, loss: 0.016482358798384666
step: 320, loss: 0.0010810502571985126
step: 330, loss: 0.06115224212408066
step: 340, loss: 0.033116456121206284
step: 350, loss: 0.066764235496521
step: 360, loss: 0.08160095661878586
step: 370, loss: 0.08422814309597015
step: 380, loss: 0.10636568814516068
step: 390, loss: 0.11209424585103989
step: 400, loss: 0.03908148035407066
step: 410, loss: 0.0764627680182457
step: 420, loss: 0.11915409564971924
step: 430, loss: 0.08345681428909302
step: 440, loss: 0.038844283670186996
step: 450, loss: 0.11236846446990967
step: 460, loss: 0.06588758528232574
epoch 10: dev_f1=0.9898989898989898, f1=0.9821428571428571, best_f1=0.9832026875699889
step: 0, loss: 0.06371856480836868
step: 10, loss: 0.059991054236888885
step: 20, loss: 0.056017231196165085
step: 30, loss: 0.1360066682100296
step: 40, loss: 0.029923876747488976
step: 50, loss: 0.20820021629333496
step: 60, loss: 0.013904605992138386
step: 70, loss: 0.10100341588258743
step: 80, loss: 0.0162876695394516
step: 90, loss: 0.01136395987123251
step: 100, loss: 0.014581057243049145
step: 110, loss: 0.04438475891947746
step: 120, loss: 0.02006884478032589
step: 130, loss: 0.021273579448461533
step: 140, loss: 0.08477131277322769
step: 150, loss: 0.08586621284484863
step: 160, loss: 0.079673171043396
step: 170, loss: 0.03364530950784683
step: 180, loss: 0.012964259833097458
step: 190, loss: 0.0375736728310585
step: 200, loss: 0.06490445882081985
step: 210, loss: 0.06425005197525024
step: 220, loss: 0.002891198731958866
step: 230, loss: 0.05121375992894173
step: 240, loss: 0.09198091924190521
step: 250, loss: 6.332631892291829e-05
step: 260, loss: 6.744370330125093e-05
step: 270, loss: 0.03619766980409622
step: 280, loss: 7.218478276627138e-05
step: 290, loss: 0.016809945926070213
step: 300, loss: 0.03309078514575958
step: 310, loss: 0.05824563279747963
step: 320, loss: 0.02462156116962433
step: 330, loss: 0.02480553276836872
step: 340, loss: 0.03566896170377731
step: 350, loss: 0.07677298784255981
step: 360, loss: 0.01969469152390957
step: 370, loss: 0.14494037628173828
step: 380, loss: 0.08407052606344223
step: 390, loss: 0.1416013538837433
step: 400, loss: 0.03190835192799568
step: 410, loss: 0.05510777607560158
step: 420, loss: 0.044673942029476166
step: 430, loss: 5.043793498771265e-05
step: 440, loss: 0.0820533037185669
step: 450, loss: 0.06120515987277031
step: 460, loss: 0.012328115291893482
epoch 11: dev_f1=0.9910112359550561, f1=0.977728285077951, best_f1=0.9832026875699889
step: 0, loss: 0.00803385954350233
step: 10, loss: 0.21483615040779114
step: 20, loss: 0.05270928889513016
step: 30, loss: 0.012281308881938457
step: 40, loss: 0.12271596491336823
step: 50, loss: 0.036105941981077194
step: 60, loss: 0.045988842844963074
step: 70, loss: 0.09349554032087326
step: 80, loss: 0.08539067208766937
step: 90, loss: 0.027170568704605103
step: 100, loss: 0.022443898022174835
step: 110, loss: 0.012952500954270363
step: 120, loss: 0.02896733023226261
step: 130, loss: 0.14481055736541748
step: 140, loss: 0.09257832914590836
step: 150, loss: 0.07725600898265839
step: 160, loss: 0.07723970711231232
step: 170, loss: 0.034765928983688354
step: 180, loss: 8.21978464955464e-05
step: 190, loss: 0.04536714032292366
step: 200, loss: 0.0980258509516716
step: 210, loss: 0.013945109210908413
step: 220, loss: 0.042407795786857605
step: 230, loss: 0.013030702248215675
step: 240, loss: 0.005471149459481239
step: 250, loss: 0.06498271226882935
step: 260, loss: 0.0061796060763299465
step: 270, loss: 0.015101918950676918
step: 280, loss: 0.0014285476645454764
step: 290, loss: 0.06999221444129944
step: 300, loss: 0.0811527669429779
step: 310, loss: 0.04940000921487808
step: 320, loss: 0.045943427830934525
step: 330, loss: 0.08689050376415253
step: 340, loss: 0.07698094844818115
step: 350, loss: 0.017416298389434814
step: 360, loss: 0.1002165749669075
step: 370, loss: 0.036654844880104065
step: 380, loss: 0.021074429154396057
step: 390, loss: 0.05260590836405754
step: 400, loss: 0.04975874722003937
step: 410, loss: 0.07497835904359818
step: 420, loss: 0.02941814251244068
step: 430, loss: 0.03982391580939293
step: 440, loss: 0.10451579093933105
step: 450, loss: 0.1047661155462265
step: 460, loss: 0.013064034283161163
epoch 12: dev_f1=0.9898305084745763, f1=0.9852774631936579, best_f1=0.9832026875699889
step: 0, loss: 4.793706102645956e-05
step: 10, loss: 0.05092800781130791
step: 20, loss: 0.018329482525587082
step: 30, loss: 0.06256772577762604
step: 40, loss: 0.034946683794260025
step: 50, loss: 0.015257246792316437
step: 60, loss: 0.014363463968038559
step: 70, loss: 0.008730689063668251
step: 80, loss: 0.008991151116788387
step: 90, loss: 0.00012909426004625857
step: 100, loss: 0.01830776035785675
step: 110, loss: 0.00546452309936285
step: 120, loss: 0.0007407073280774057
step: 130, loss: 0.036149103194475174
step: 140, loss: 0.022830992937088013
step: 150, loss: 0.0003218409838154912
step: 160, loss: 0.12416546791791916
step: 170, loss: 0.05161578953266144
step: 180, loss: 0.038375046104192734
step: 190, loss: 0.07288643717765808
step: 200, loss: 0.00036341443774290383
step: 210, loss: 0.043396033346652985
step: 220, loss: 0.09381724894046783
step: 230, loss: 0.04195790737867355
step: 240, loss: 0.1259719729423523
step: 250, loss: 0.022491345182061195
step: 260, loss: 0.07652507722377777
step: 270, loss: 0.0314457081258297
step: 280, loss: 0.0005536070675589144
step: 290, loss: 0.12072736769914627
step: 300, loss: 0.058258701115846634
step: 310, loss: 0.09447064250707626
step: 320, loss: 0.11144065111875534
step: 330, loss: 0.03154108673334122
step: 340, loss: 0.06194431707262993
step: 350, loss: 0.018381305038928986
step: 360, loss: 0.00041164204594679177
step: 370, loss: 0.006422957871109247
step: 380, loss: 0.040208641439676285
step: 390, loss: 0.06694342941045761
step: 400, loss: 0.08638734370470047
step: 410, loss: 0.04059839993715286
step: 420, loss: 0.09220033884048462
step: 430, loss: 0.017457326874136925
step: 440, loss: 0.07770195603370667
step: 450, loss: 0.0012304005213081837
step: 460, loss: 0.140509232878685
epoch 13: dev_f1=0.9921259842519685, f1=0.9809203142536477, best_f1=0.9832026875699889
step: 0, loss: 0.04380055516958237
step: 10, loss: 0.024846192449331284
step: 20, loss: 0.00171589944511652
step: 30, loss: 0.024469848722219467
step: 40, loss: 0.1496969759464264
step: 50, loss: 0.02692710980772972
step: 60, loss: 0.037335582077503204
step: 70, loss: 0.024457121267914772
step: 80, loss: 0.0013784215552732348
step: 90, loss: 2.965983367175795e-05
step: 100, loss: 0.05925730615854263
step: 110, loss: 0.07007110863924026
step: 120, loss: 0.023261450231075287
step: 130, loss: 0.03893294185400009
step: 140, loss: 0.021203739568591118
step: 150, loss: 0.1115969866514206
step: 160, loss: 0.0244198739528656
step: 170, loss: 0.05921155586838722
step: 180, loss: 0.03837494179606438
step: 190, loss: 0.054654307663440704
step: 200, loss: 0.016390984877943993
step: 210, loss: 0.07414471358060837
step: 220, loss: 0.02925884537398815
step: 230, loss: 0.10847365111112595
step: 240, loss: 0.05598435550928116
step: 250, loss: 0.020885741338133812
step: 260, loss: 3.814720912487246e-05
step: 270, loss: 0.05295578017830849
step: 280, loss: 0.06382455676794052
step: 290, loss: 0.005741508211940527
step: 300, loss: 0.007657332345843315
step: 310, loss: 0.03051060438156128
step: 320, loss: 3.479219230939634e-05
step: 330, loss: 0.009515415877103806
step: 340, loss: 0.04165951535105705
step: 350, loss: 0.027339044958353043
step: 360, loss: 0.0005360611248761415
step: 370, loss: 0.023557931184768677
step: 380, loss: 0.1095818281173706
step: 390, loss: 0.05292646214365959
step: 400, loss: 1.9248300304752775e-05
step: 410, loss: 0.07280884683132172
step: 420, loss: 0.056128960102796555
step: 430, loss: 0.05227595567703247
step: 440, loss: 0.0005969988997094333
step: 450, loss: 0.003308754414319992
step: 460, loss: 0.06065663695335388
epoch 14: dev_f1=0.9898762654668166, f1=0.9841628959276018, best_f1=0.9832026875699889
step: 0, loss: 0.05393192917108536
step: 10, loss: 0.07333051413297653
step: 20, loss: 0.00018125535279978067
step: 30, loss: 0.00026355707086622715
step: 40, loss: 0.03743794932961464
step: 50, loss: 0.04792441427707672
step: 60, loss: 0.017282918095588684
step: 70, loss: 0.031172268092632294
step: 80, loss: 5.5673037422820926e-05
step: 90, loss: 0.00063754414441064
step: 100, loss: 0.0021060567814856768
step: 110, loss: 0.05624616891145706
step: 120, loss: 0.13333715498447418
step: 130, loss: 0.08925240486860275
step: 140, loss: 0.10169963538646698
step: 150, loss: 0.0006208129925653338
step: 160, loss: 0.03184353932738304
step: 170, loss: 0.06981851160526276
step: 180, loss: 0.005230369046330452
step: 190, loss: 0.013059007935225964
step: 200, loss: 0.04854823276400566
step: 210, loss: 0.02013988234102726
step: 220, loss: 0.09767080843448639
step: 230, loss: 0.036740370094776154
step: 240, loss: 0.054686322808265686
step: 250, loss: 0.019723959267139435
step: 260, loss: 0.02334754541516304
step: 270, loss: 0.01638791896402836
step: 280, loss: 2.5994526367867365e-05
step: 290, loss: 0.030985016375780106
step: 300, loss: 0.05132142826914787
step: 310, loss: 0.07370910793542862
step: 320, loss: 0.02266468107700348
step: 330, loss: 0.015351193025708199
step: 340, loss: 0.029654817655682564
step: 350, loss: 0.00032646494219079614
step: 360, loss: 0.046554479748010635
step: 370, loss: 0.00022915472800377756
step: 380, loss: 0.03470515087246895
step: 390, loss: 0.09408016502857208
step: 400, loss: 0.0721791684627533
step: 410, loss: 0.05990268290042877
step: 420, loss: 6.132158159743994e-05
step: 430, loss: 0.09437822550535202
step: 440, loss: 0.008748169057071209
step: 450, loss: 9.14933334570378e-05
step: 460, loss: 0.020061761140823364
epoch 15: dev_f1=0.9910112359550561, f1=0.9810055865921787, best_f1=0.9832026875699889
step: 0, loss: 0.0002706066588871181
step: 10, loss: 0.06007010117173195
step: 20, loss: 0.016195710748434067
step: 30, loss: 0.0028978665359318256
step: 40, loss: 0.04758358374238014
step: 50, loss: 0.028012298047542572
step: 60, loss: 0.004849908873438835
step: 70, loss: 0.038089875131845474
step: 80, loss: 0.04700591787695885
step: 90, loss: 0.01596907712519169
step: 100, loss: 0.000128005602164194
step: 110, loss: 0.03549429029226303
step: 120, loss: 0.07857462018728256
step: 130, loss: 0.0608200877904892
step: 140, loss: 0.041579682379961014
step: 150, loss: 0.0074386997148394585
step: 160, loss: 0.05115194618701935
step: 170, loss: 0.03369361534714699
step: 180, loss: 0.0280601903796196
step: 190, loss: 0.00767081743106246
step: 200, loss: 0.03460944443941116
step: 210, loss: 0.036440614610910416
step: 220, loss: 0.0012352243065834045
step: 230, loss: 0.02163153514266014
step: 240, loss: 0.11030253022909164
step: 250, loss: 0.04388552904129028
step: 260, loss: 0.11117644608020782
step: 270, loss: 0.021953832358121872
step: 280, loss: 0.06049633398652077
step: 290, loss: 0.04992906376719475
step: 300, loss: 0.04390745609998703
step: 310, loss: 0.0216673593968153
step: 320, loss: 0.041991718113422394
step: 330, loss: 0.024790536612272263
step: 340, loss: 0.1049487516283989
step: 350, loss: 0.0367458201944828
step: 360, loss: 0.011831948533654213
step: 370, loss: 0.06117158383131027
step: 380, loss: 0.0287928469479084
step: 390, loss: 0.0023456949274986982
step: 400, loss: 0.02026340179145336
step: 410, loss: 0.07714720815420151
step: 420, loss: 0.01703404262661934
step: 430, loss: 0.04320846125483513
step: 440, loss: 0.020568618550896645
step: 450, loss: 0.08000174164772034
step: 460, loss: 0.09289795160293579
epoch 16: dev_f1=0.9921259842519685, f1=0.9809203142536477, best_f1=0.9832026875699889
step: 0, loss: 0.02536308765411377
step: 10, loss: 0.018142566084861755
step: 20, loss: 0.06901475787162781
step: 30, loss: 0.05868212506175041
step: 40, loss: 0.01457995269447565
step: 50, loss: 0.00026750421966426075
step: 60, loss: 0.036251284182071686
step: 70, loss: 5.390932346927002e-05
step: 80, loss: 0.06102012097835541
step: 90, loss: 0.024764014407992363
step: 100, loss: 0.05422009527683258
step: 110, loss: 0.057325080037117004
step: 120, loss: 0.04993680492043495
step: 130, loss: 0.044235143810510635
step: 140, loss: 0.06481034308671951
step: 150, loss: 0.054436542093753815
step: 160, loss: 0.000542392663192004
step: 170, loss: 0.01759190484881401
step: 180, loss: 0.059862758964300156
step: 190, loss: 0.054751425981521606
step: 200, loss: 0.021575383841991425
step: 210, loss: 0.022750379517674446
step: 220, loss: 0.05006210505962372
step: 230, loss: 0.046834271401166916
step: 240, loss: 0.042900729924440384
step: 250, loss: 0.017815416678786278
step: 260, loss: 0.02200401946902275
step: 270, loss: 0.028661444783210754
step: 280, loss: 0.02064625732600689
step: 290, loss: 0.027618104591965675
step: 300, loss: 0.07717439532279968
step: 310, loss: 0.0288391150534153
step: 320, loss: 0.029245520010590553
step: 330, loss: 0.005516319070011377
step: 340, loss: 0.02555224299430847
step: 350, loss: 0.13791178166866302
step: 360, loss: 0.009498278610408306
step: 370, loss: 0.0444592647254467
step: 380, loss: 0.03321106731891632
step: 390, loss: 0.0023772595450282097
step: 400, loss: 0.029409941285848618
step: 410, loss: 0.04078786075115204
step: 420, loss: 0.04689646512269974
step: 430, loss: 0.04623100906610489
step: 440, loss: 0.00030974732362665236
step: 450, loss: 0.0406402088701725
step: 460, loss: 0.00256943516433239
epoch 17: dev_f1=0.9910112359550561, f1=0.9799107142857142, best_f1=0.9832026875699889
step: 0, loss: 0.05693412199616432
step: 10, loss: 0.00011793633893830702
step: 20, loss: 0.0036284762900322676
step: 30, loss: 1.731125666992739e-05
step: 40, loss: 0.02589694783091545
step: 50, loss: 0.04259014129638672
step: 60, loss: 0.06959563493728638
step: 70, loss: 0.027197064831852913
step: 80, loss: 4.183835335425101e-05
step: 90, loss: 0.03189513087272644
step: 100, loss: 0.04978366568684578
step: 110, loss: 0.013039982877671719
step: 120, loss: 0.03471904620528221
step: 130, loss: 0.07939552515745163
step: 140, loss: 0.019836142659187317
step: 150, loss: 0.031833257526159286
step: 160, loss: 0.03494337573647499
step: 170, loss: 0.022505884990096092
step: 180, loss: 0.020756220445036888
step: 190, loss: 0.02525581605732441
step: 200, loss: 0.002266847062855959
step: 210, loss: 0.09050322324037552
step: 220, loss: 0.04228103160858154
step: 230, loss: 0.06819427758455276
step: 240, loss: 8.858114597387612e-05
step: 250, loss: 0.05104183405637741
step: 260, loss: 0.022076502442359924
step: 270, loss: 0.11185971647500992
step: 280, loss: 0.03675113245844841
step: 290, loss: 0.02259000390768051
step: 300, loss: 2.2068099497118965e-05
step: 310, loss: 0.13046079874038696
step: 320, loss: 2.008640512940474e-05
step: 330, loss: 0.028483755886554718
step: 340, loss: 0.006569205783307552
step: 350, loss: 1.6819503798615187e-05
step: 360, loss: 0.023206382989883423
step: 370, loss: 2.4935838155215606e-05
step: 380, loss: 0.027454962953925133
step: 390, loss: 0.07754921168088913
step: 400, loss: 0.0011222942266613245
step: 410, loss: 6.440641300287098e-05
step: 420, loss: 0.030336935073137283
step: 430, loss: 3.001738696184475e-05
step: 440, loss: 0.025707146152853966
step: 450, loss: 2.0730800315504894e-05
step: 460, loss: 0.04264593869447708
epoch 18: dev_f1=0.9921259842519685, f1=0.9798206278026906, best_f1=0.9832026875699889
step: 0, loss: 0.029207807034254074
step: 10, loss: 0.07158507406711578
step: 20, loss: 0.02213250659406185
step: 30, loss: 0.0671229138970375
step: 40, loss: 0.02342081256210804
step: 50, loss: 0.022285031154751778
step: 60, loss: 0.055403243750333786
step: 70, loss: 3.5115419450448826e-05
step: 80, loss: 0.05944828316569328
step: 90, loss: 0.02435581013560295
step: 100, loss: 0.04256827384233475
step: 110, loss: 0.04244619607925415
step: 120, loss: 2.105478779412806e-05
step: 130, loss: 0.12069685757160187
step: 140, loss: 0.038921061903238297
step: 150, loss: 0.02265086956322193
step: 160, loss: 0.06061111018061638
step: 170, loss: 0.02311016246676445
step: 180, loss: 0.01636500284075737
step: 190, loss: 0.019905932247638702
step: 200, loss: 0.023732565343379974
step: 210, loss: 0.11103764921426773
step: 220, loss: 0.019527308642864227
step: 230, loss: 0.026475293561816216
step: 240, loss: 0.05644984915852547
step: 250, loss: 0.0036610120441764593
step: 260, loss: 0.005755148828029633
step: 270, loss: 1.571685788803734e-05
step: 280, loss: 0.026347188279032707
step: 290, loss: 0.000396249582991004
step: 300, loss: 0.03793388977646828
step: 310, loss: 0.0399848148226738
step: 320, loss: 4.185362558928318e-05
step: 330, loss: 0.0426863469183445
step: 340, loss: 0.024052457883954048
step: 350, loss: 0.01862780936062336
step: 360, loss: 2.4865352315828204e-05
step: 370, loss: 2.2712600184604526e-05
step: 380, loss: 0.028371745720505714
step: 390, loss: 0.0004244521842338145
step: 400, loss: 0.023018179461359978
step: 410, loss: 0.02638045884668827
step: 420, loss: 0.0337105467915535
step: 430, loss: 0.03665689751505852
step: 440, loss: 0.02748819626867771
step: 450, loss: 0.02757614105939865
step: 460, loss: 8.522668213117868e-05
epoch 19: dev_f1=0.9921259842519685, f1=0.9820627802690582, best_f1=0.9832026875699889
step: 0, loss: 0.05176766216754913
step: 10, loss: 0.0012109134113416076
step: 20, loss: 0.019256465137004852
step: 30, loss: 0.06627960503101349
step: 40, loss: 0.044821906834840775
step: 50, loss: 0.04104147106409073
step: 60, loss: 0.043812014162540436
step: 70, loss: 0.0013134325854480267
step: 80, loss: 0.06318449229001999
step: 90, loss: 0.016945617273449898
step: 100, loss: 0.04129769280552864
step: 110, loss: 0.03148646280169487
step: 120, loss: 0.019191065803170204
step: 130, loss: 0.013876345008611679
step: 140, loss: 0.04017959535121918
step: 150, loss: 2.499204856576398e-05
step: 160, loss: 0.047467220574617386
step: 170, loss: 2.912704076152295e-05
step: 180, loss: 0.019373243674635887
step: 190, loss: 0.019104978069663048
step: 200, loss: 0.01908228173851967
step: 210, loss: 0.039198100566864014
step: 220, loss: 1.9531353245838545e-05
step: 230, loss: 0.01871320605278015
step: 240, loss: 0.07217008620500565
step: 250, loss: 0.08280977606773376
step: 260, loss: 0.05390733852982521
step: 270, loss: 0.08480284363031387
step: 280, loss: 0.00016045293887145817
step: 290, loss: 0.058132804930210114
step: 300, loss: 0.00044482992962002754
step: 310, loss: 0.04645588994026184
step: 320, loss: 0.00021282202214933932
step: 330, loss: 6.294974446063861e-05
step: 340, loss: 0.06767141819000244
step: 350, loss: 0.07770128548145294
step: 360, loss: 0.018065694719552994
step: 370, loss: 0.027125626802444458
step: 380, loss: 0.011295070871710777
step: 390, loss: 0.03063899278640747
step: 400, loss: 4.358014484751038e-05
step: 410, loss: 0.07743663340806961
step: 420, loss: 0.06157296895980835
step: 430, loss: 0.022847546264529228
step: 440, loss: 0.03363566845655441
step: 450, loss: 0.04538623243570328
step: 460, loss: 0.07021202892065048
epoch 20: dev_f1=0.9910112359550561, f1=0.9820627802690582, best_f1=0.9832026875699889
