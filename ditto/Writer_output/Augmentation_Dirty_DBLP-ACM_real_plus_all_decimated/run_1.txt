cuda
Device: cuda
step: 0, loss: 0.914291501045227
step: 10, loss: 0.4379124641418457
step: 20, loss: 0.4646547734737396
step: 30, loss: 0.590994119644165
step: 40, loss: 0.2609405517578125
step: 50, loss: 0.12261836230754852
step: 60, loss: 0.04598153010010719
step: 70, loss: 0.24291756749153137
step: 80, loss: 0.22874325513839722
step: 90, loss: 0.34861961007118225
step: 100, loss: 0.1489664614200592
step: 110, loss: 0.1266910880804062
step: 120, loss: 0.18568038940429688
step: 130, loss: 0.10036034137010574
step: 140, loss: 0.23311395943164825
step: 150, loss: 0.06813804060220718
step: 160, loss: 0.12570826709270477
step: 170, loss: 0.1955052614212036
step: 180, loss: 0.105877585709095
step: 190, loss: 0.15022070705890656
step: 200, loss: 0.0966937467455864
step: 210, loss: 0.10814566910266876
step: 220, loss: 0.09250157326459885
step: 230, loss: 0.06248624622821808
step: 240, loss: 0.06269563734531403
step: 250, loss: 0.06313803046941757
step: 260, loss: 0.08609380573034286
step: 270, loss: 0.08620458841323853
step: 280, loss: 0.09370998293161392
step: 290, loss: 0.17122994363307953
step: 300, loss: 0.16839422285556793
step: 310, loss: 0.13735799491405487
step: 320, loss: 0.21970395743846893
step: 330, loss: 0.25403231382369995
step: 340, loss: 0.05762642249464989
step: 350, loss: 0.07548494637012482
step: 360, loss: 0.10441479086875916
step: 370, loss: 0.13005051016807556
step: 380, loss: 0.08732734620571136
step: 390, loss: 0.044626809656620026
step: 400, loss: 0.3183876574039459
step: 410, loss: 0.16757677495479584
step: 420, loss: 0.12626782059669495
step: 430, loss: 0.09539435803890228
step: 440, loss: 0.1309167444705963
step: 450, loss: 0.1346615105867386
step: 460, loss: 0.20224495232105255
epoch 1: dev_f1=0.9876543209876544, f1=0.9762174405436014, best_f1=0.9762174405436014
step: 0, loss: 0.10946540534496307
step: 10, loss: 0.09035903215408325
step: 20, loss: 0.07945454865694046
step: 30, loss: 0.20471733808517456
step: 40, loss: 0.12592069804668427
step: 50, loss: 0.03782452270388603
step: 60, loss: 0.2052004337310791
step: 70, loss: 0.08297659456729889
step: 80, loss: 0.0373828299343586
step: 90, loss: 0.0760389044880867
step: 100, loss: 0.06133086606860161
step: 110, loss: 0.05180957913398743
step: 120, loss: 0.1105666309595108
step: 130, loss: 0.024422774091362953
step: 140, loss: 0.058452628552913666
step: 150, loss: 0.11524636298418045
step: 160, loss: 0.1679099053144455
step: 170, loss: 0.059888262301683426
step: 180, loss: 0.08643025159835815
step: 190, loss: 0.08165353536605835
step: 200, loss: 0.018499815836548805
step: 210, loss: 0.20996789634227753
step: 220, loss: 0.018396494910120964
step: 230, loss: 0.021883659064769745
step: 240, loss: 0.10706020891666412
step: 250, loss: 0.148060604929924
step: 260, loss: 0.05945882201194763
step: 270, loss: 0.07715251296758652
step: 280, loss: 0.13261590898036957
step: 290, loss: 0.09292617440223694
step: 300, loss: 0.10960947722196579
step: 310, loss: 0.0002117685362463817
step: 320, loss: 0.01772843301296234
step: 330, loss: 0.0879751592874527
step: 340, loss: 0.14740021526813507
step: 350, loss: 0.09913643449544907
step: 360, loss: 0.08083485066890717
step: 370, loss: 0.20996595919132233
step: 380, loss: 0.0670444518327713
step: 390, loss: 0.05584143102169037
step: 400, loss: 0.23253433406352997
step: 410, loss: 0.1067173108458519
step: 420, loss: 0.09177933633327484
step: 430, loss: 0.0837261825799942
step: 440, loss: 0.04680049419403076
step: 450, loss: 0.05334581062197685
step: 460, loss: 0.060646168887615204
epoch 2: dev_f1=0.9865168539325843, f1=0.9717514124293786, best_f1=0.9762174405436014
step: 0, loss: 0.11983493715524673
step: 10, loss: 0.05002952367067337
step: 20, loss: 0.06501594930887222
step: 30, loss: 0.0979766920208931
step: 40, loss: 0.13544949889183044
step: 50, loss: 0.06567739695310593
step: 60, loss: 0.08244244754314423
step: 70, loss: 0.029279310256242752
step: 80, loss: 0.06547623127698898
step: 90, loss: 0.16917593777179718
step: 100, loss: 0.1392916589975357
step: 110, loss: 0.06868292391300201
step: 120, loss: 0.03347494453191757
step: 130, loss: 0.12015074491500854
step: 140, loss: 0.1573740839958191
step: 150, loss: 0.03255171701312065
step: 160, loss: 0.08954145014286041
step: 170, loss: 0.04473504051566124
step: 180, loss: 0.11561914533376694
step: 190, loss: 0.05460447072982788
step: 200, loss: 0.08397146314382553
step: 210, loss: 0.0192031878978014
step: 220, loss: 0.11047900468111038
step: 230, loss: 0.11153977364301682
step: 240, loss: 0.2144995629787445
step: 250, loss: 0.02989995665848255
step: 260, loss: 0.04963136091828346
step: 270, loss: 0.07033753395080566
step: 280, loss: 0.011717958375811577
step: 290, loss: 0.11797618865966797
step: 300, loss: 0.12614397704601288
step: 310, loss: 0.030611133202910423
step: 320, loss: 0.05219848453998566
step: 330, loss: 0.0007383069023489952
step: 340, loss: 0.12918269634246826
step: 350, loss: 0.10524882376194
step: 360, loss: 0.0708649754524231
step: 370, loss: 0.05604725703597069
step: 380, loss: 0.036526430398225784
step: 390, loss: 0.05788590759038925
step: 400, loss: 0.022446975111961365
step: 410, loss: 0.029870744794607162
step: 420, loss: 0.03647661209106445
step: 430, loss: 0.10526397079229355
step: 440, loss: 0.037586286664009094
step: 450, loss: 0.08551902323961258
step: 460, loss: 0.04843923822045326
epoch 3: dev_f1=0.9898762654668166, f1=0.983050847457627, best_f1=0.983050847457627
step: 0, loss: 0.12119601666927338
step: 10, loss: 0.034813292324543
step: 20, loss: 0.017285829409956932
step: 30, loss: 0.011052161455154419
step: 40, loss: 0.11231137812137604
step: 50, loss: 0.029062433168292046
step: 60, loss: 0.15874381363391876
step: 70, loss: 0.04609217122197151
step: 80, loss: 0.09670861065387726
step: 90, loss: 0.02916528843343258
step: 100, loss: 0.06544256955385208
step: 110, loss: 0.11252035200595856
step: 120, loss: 0.0874020978808403
step: 130, loss: 0.0011841693194583058
step: 140, loss: 0.12272706627845764
step: 150, loss: 0.04693102464079857
step: 160, loss: 0.047156039625406265
step: 170, loss: 0.016738343983888626
step: 180, loss: 0.025733496993780136
step: 190, loss: 0.05291113257408142
step: 200, loss: 0.1320064663887024
step: 210, loss: 0.07687044143676758
step: 220, loss: 0.0077495030127465725
step: 230, loss: 0.02785544842481613
step: 240, loss: 0.017788972705602646
step: 250, loss: 0.008422059006989002
step: 260, loss: 0.04088694602251053
step: 270, loss: 0.13448278605937958
step: 280, loss: 0.022006653249263763
step: 290, loss: 0.08092983067035675
step: 300, loss: 0.0721297338604927
step: 310, loss: 0.109385184943676
step: 320, loss: 0.018059778958559036
step: 330, loss: 0.05818061903119087
step: 340, loss: 0.0352567583322525
step: 350, loss: 0.04920215904712677
step: 360, loss: 0.06311921775341034
step: 370, loss: 0.10644650459289551
step: 380, loss: 0.08819683641195297
step: 390, loss: 0.01915811188519001
step: 400, loss: 0.03675299137830734
step: 410, loss: 0.054351408034563065
step: 420, loss: 0.11335645616054535
step: 430, loss: 0.011113900691270828
step: 440, loss: 0.03263777121901512
step: 450, loss: 0.04898552596569061
step: 460, loss: 0.07604563981294632
epoch 4: dev_f1=0.992108229988726, f1=0.9775280898876404, best_f1=0.9775280898876404
step: 0, loss: 0.03184105455875397
step: 10, loss: 0.058721620589494705
step: 20, loss: 0.1118248999118805
step: 30, loss: 0.06095772981643677
step: 40, loss: 0.04883226007223129
step: 50, loss: 0.0400833785533905
step: 60, loss: 0.035573866218328476
step: 70, loss: 0.08302882313728333
step: 80, loss: 0.029797552153468132
step: 90, loss: 0.05358400568366051
step: 100, loss: 0.08859138190746307
step: 110, loss: 0.07214028388261795
step: 120, loss: 0.057383839040994644
step: 130, loss: 0.026405123993754387
step: 140, loss: 0.06010401248931885
step: 150, loss: 0.11573291569948196
step: 160, loss: 0.16269633173942566
step: 170, loss: 0.00907148513942957
step: 180, loss: 0.040613435208797455
step: 190, loss: 0.053291186690330505
step: 200, loss: 0.043873533606529236
step: 210, loss: 0.08135350048542023
step: 220, loss: 0.0671357586979866
step: 230, loss: 0.03972598537802696
step: 240, loss: 0.05693407356739044
step: 250, loss: 0.0005060421535745263
step: 260, loss: 0.00803446676582098
step: 270, loss: 0.17467059195041656
step: 280, loss: 0.021298477426171303
step: 290, loss: 0.19651249051094055
step: 300, loss: 0.019336186349391937
step: 310, loss: 0.010977813974022865
step: 320, loss: 0.09065864235162735
step: 330, loss: 0.1659936010837555
step: 340, loss: 0.08842045068740845
step: 350, loss: 0.01574035733938217
step: 360, loss: 0.07055399566888809
step: 370, loss: 0.03676658123731613
step: 380, loss: 0.05300687998533249
step: 390, loss: 0.06375769525766373
step: 400, loss: 0.09767230600118637
step: 410, loss: 0.10266336053609848
step: 420, loss: 0.03564243018627167
step: 430, loss: 0.09251883625984192
step: 440, loss: 0.025458695366978645
step: 450, loss: 0.05500478297472
step: 460, loss: 0.022636933252215385
epoch 5: dev_f1=0.9865168539325843, f1=0.9785794813979707, best_f1=0.9775280898876404
step: 0, loss: 0.0623604841530323
step: 10, loss: 0.008704896084964275
step: 20, loss: 0.049851931631565094
step: 30, loss: 0.057092323899269104
step: 40, loss: 0.07760824263095856
step: 50, loss: 0.07073605805635452
step: 60, loss: 0.1520288735628128
step: 70, loss: 0.06205873191356659
step: 80, loss: 0.0671595111489296
step: 90, loss: 0.11089330911636353
step: 100, loss: 0.056938525289297104
step: 110, loss: 0.1449669450521469
step: 120, loss: 0.11507177352905273
step: 130, loss: 0.036136046051979065
step: 140, loss: 0.04264836758375168
step: 150, loss: 0.10880117118358612
step: 160, loss: 0.24016915261745453
step: 170, loss: 0.16522563993930817
step: 180, loss: 0.07002672553062439
step: 190, loss: 0.19163979589939117
step: 200, loss: 0.09337174147367477
step: 210, loss: 0.00838569737970829
step: 220, loss: 0.07446654886007309
step: 230, loss: 0.0812942236661911
step: 240, loss: 0.19008679687976837
step: 250, loss: 0.029732147231698036
step: 260, loss: 0.0799729973077774
step: 270, loss: 0.10966388136148453
step: 280, loss: 0.07436083257198334
step: 290, loss: 0.02450680546462536
step: 300, loss: 0.053912531584501266
step: 310, loss: 0.04976365715265274
step: 320, loss: 0.043644580990076065
step: 330, loss: 0.025205565616488457
step: 340, loss: 0.0805600956082344
step: 350, loss: 0.060440436005592346
step: 360, loss: 0.05979436635971069
step: 370, loss: 0.009162012487649918
step: 380, loss: 0.057970739901065826
step: 390, loss: 0.08318828791379929
step: 400, loss: 0.0020861716475337744
step: 410, loss: 0.052845265716314316
step: 420, loss: 0.030353715643286705
step: 430, loss: 0.08258271217346191
step: 440, loss: 0.029678810387849808
step: 450, loss: 0.04419301822781563
step: 460, loss: 0.026745609939098358
epoch 6: dev_f1=0.9876265466816648, f1=0.9841628959276018, best_f1=0.9775280898876404
step: 0, loss: 0.011520168744027615
step: 10, loss: 0.07632974535226822
step: 20, loss: 0.1045224741101265
step: 30, loss: 0.022033950313925743
step: 40, loss: 0.010201839730143547
step: 50, loss: 0.016604065895080566
step: 60, loss: 0.031199289485812187
step: 70, loss: 0.07344136387109756
step: 80, loss: 0.10104292631149292
step: 90, loss: 0.009348766878247261
step: 100, loss: 0.043997183442115784
step: 110, loss: 0.0807182788848877
step: 120, loss: 0.09630855172872543
step: 130, loss: 0.14669090509414673
step: 140, loss: 0.16347147524356842
step: 150, loss: 0.11332865059375763
step: 160, loss: 0.06176602840423584
step: 170, loss: 0.024954257532954216
step: 180, loss: 0.02517559751868248
step: 190, loss: 0.18567734956741333
step: 200, loss: 0.07324035465717316
step: 210, loss: 0.040189169347286224
step: 220, loss: 0.07403293251991272
step: 230, loss: 0.08979308605194092
step: 240, loss: 0.026884758844971657
step: 250, loss: 0.07423396408557892
step: 260, loss: 0.07516086101531982
step: 270, loss: 0.18554434180259705
step: 280, loss: 0.059726782143116
step: 290, loss: 0.05078157037496567
step: 300, loss: 0.16168095171451569
step: 310, loss: 0.04496920108795166
step: 320, loss: 2.7466006940812804e-05
step: 330, loss: 0.03638788312673569
step: 340, loss: 0.07564203441143036
step: 350, loss: 0.08333075046539307
step: 360, loss: 0.0698009580373764
step: 370, loss: 0.12363353371620178
step: 380, loss: 0.12068114429712296
step: 390, loss: 0.030339457094669342
step: 400, loss: 0.00836842879652977
step: 410, loss: 0.06016305461525917
step: 420, loss: 0.05886007845401764
step: 430, loss: 0.08147722482681274
step: 440, loss: 0.11916274577379227
step: 450, loss: 0.09713263809680939
step: 460, loss: 0.05243600904941559
epoch 7: dev_f1=0.9910313901345291, f1=0.9788182831661093, best_f1=0.9775280898876404
step: 0, loss: 0.07082273066043854
step: 10, loss: 0.11053958535194397
step: 20, loss: 0.08572936058044434
step: 30, loss: 0.12380895763635635
step: 40, loss: 0.06533514708280563
step: 50, loss: 0.0051771183498203754
step: 60, loss: 0.03635980188846588
step: 70, loss: 0.1255413442850113
step: 80, loss: 0.012283812277019024
step: 90, loss: 0.12367915362119675
step: 100, loss: 0.15535855293273926
step: 110, loss: 0.10449182242155075
step: 120, loss: 0.023302685469388962
step: 130, loss: 0.05082269757986069
step: 140, loss: 0.050569791346788406
step: 150, loss: 0.024520989507436752
step: 160, loss: 0.03266787528991699
step: 170, loss: 0.05048872530460358
step: 180, loss: 0.019461890682578087
step: 190, loss: 0.004028702154755592
step: 200, loss: 0.045188058167696
step: 210, loss: 0.0666026845574379
step: 220, loss: 0.02359587885439396
step: 230, loss: 0.0396377332508564
step: 240, loss: 0.06261193752288818
step: 250, loss: 0.10704909265041351
step: 260, loss: 0.08650942146778107
step: 270, loss: 0.009188131429255009
step: 280, loss: 0.011147738434374332
step: 290, loss: 0.09364373236894608
step: 300, loss: 0.10389553010463715
step: 310, loss: 0.04087996855378151
step: 320, loss: 0.10156780481338501
step: 330, loss: 0.04614289104938507
step: 340, loss: 0.05732398480176926
step: 350, loss: 0.09263439476490021
step: 360, loss: 0.07151090353727341
step: 370, loss: 0.025384195148944855
step: 380, loss: 0.02679445408284664
step: 390, loss: 0.06633122265338898
step: 400, loss: 0.06556005775928497
step: 410, loss: 0.0036408526357263327
step: 420, loss: 0.05876415595412254
step: 430, loss: 0.22616761922836304
step: 440, loss: 0.057372331619262695
step: 450, loss: 0.033322516828775406
step: 460, loss: 0.05128184333443642
epoch 8: dev_f1=0.9876543209876544, f1=0.9754464285714286, best_f1=0.9775280898876404
step: 0, loss: 0.0592646449804306
step: 10, loss: 0.015531027689576149
step: 20, loss: 0.025540774688124657
step: 30, loss: 0.0830005332827568
step: 40, loss: 0.019280733540654182
step: 50, loss: 0.008934871293604374
step: 60, loss: 0.059998370707035065
step: 70, loss: 0.06081853061914444
step: 80, loss: 0.011902891099452972
step: 90, loss: 0.1191960945725441
step: 100, loss: 0.046432167291641235
step: 110, loss: 0.04002641886472702
step: 120, loss: 0.0951756164431572
step: 130, loss: 0.16682069003582
step: 140, loss: 0.10081660002470016
step: 150, loss: 0.11232656240463257
step: 160, loss: 0.029421664774417877
step: 170, loss: 0.05578967183828354
step: 180, loss: 0.06883523613214493
step: 190, loss: 0.07518552243709564
step: 200, loss: 0.1592734009027481
step: 210, loss: 0.012413850985467434
step: 220, loss: 0.04901677370071411
step: 230, loss: 0.021072836592793465
step: 240, loss: 0.06403239071369171
step: 250, loss: 0.08325306326150894
step: 260, loss: 0.03166757524013519
step: 270, loss: 0.0508439727127552
step: 280, loss: 0.012510250322520733
step: 290, loss: 0.026349196210503578
step: 300, loss: 0.006122414022684097
step: 310, loss: 0.036823876202106476
step: 320, loss: 0.03605397045612335
step: 330, loss: 0.07111427187919617
step: 340, loss: 0.051459841430187225
step: 350, loss: 0.10369075834751129
step: 360, loss: 0.03923521935939789
step: 370, loss: 0.14467506110668182
step: 380, loss: 0.06681927293539047
step: 390, loss: 0.06506170332431793
step: 400, loss: 0.009948796592652798
step: 410, loss: 0.1399577111005783
step: 420, loss: 0.0937616229057312
step: 430, loss: 0.09136900305747986
step: 440, loss: 0.11391986161470413
step: 450, loss: 0.07813671976327896
step: 460, loss: 0.08536848425865173
epoch 9: dev_f1=0.9887133182844244, f1=0.9785794813979707, best_f1=0.9775280898876404
step: 0, loss: 0.015249231830239296
step: 10, loss: 0.028426526114344597
step: 20, loss: 0.033353932201862335
step: 30, loss: 0.05882249400019646
step: 40, loss: 0.06518955528736115
step: 50, loss: 0.0001023183431243524
step: 60, loss: 0.06445629149675369
step: 70, loss: 0.03804335370659828
step: 80, loss: 0.00844433531165123
step: 90, loss: 0.1496123969554901
step: 100, loss: 0.06555365771055222
step: 110, loss: 0.0211428701877594
step: 120, loss: 0.0058083198964595795
step: 130, loss: 0.0035257390700280666
step: 140, loss: 0.02052156999707222
step: 150, loss: 0.11167110502719879
step: 160, loss: 0.02574852667748928
step: 170, loss: 0.08183412998914719
step: 180, loss: 0.05667402595281601
step: 190, loss: 0.028539229184389114
step: 200, loss: 0.0574396513402462
step: 210, loss: 0.03455609083175659
step: 220, loss: 0.12072274088859558
step: 230, loss: 0.030216170474886894
step: 240, loss: 0.03812015429139137
step: 250, loss: 0.09186633676290512
step: 260, loss: 0.0971800908446312
step: 270, loss: 0.00484560988843441
step: 280, loss: 0.10452638566493988
step: 290, loss: 0.018849017098546028
step: 300, loss: 0.0019481780473142862
step: 310, loss: 0.06394828855991364
step: 320, loss: 0.04108287766575813
step: 330, loss: 0.03754522651433945
step: 340, loss: 0.06000176817178726
step: 350, loss: 0.012632809579372406
step: 360, loss: 0.03207606077194214
step: 370, loss: 0.04951799288392067
step: 380, loss: 0.016390495002269745
step: 390, loss: 0.023001903668045998
step: 400, loss: 0.10566560924053192
step: 410, loss: 0.0723009780049324
step: 420, loss: 0.03621571138501167
step: 430, loss: 0.017388466745615005
step: 440, loss: 0.028369218111038208
step: 450, loss: 0.0010588127188384533
step: 460, loss: 0.07481536269187927
epoch 10: dev_f1=0.9842696629213483, f1=0.9762174405436014, best_f1=0.9775280898876404
step: 0, loss: 0.03712334856390953
step: 10, loss: 0.20615048706531525
step: 20, loss: 0.031283020973205566
step: 30, loss: 0.06459132581949234
step: 40, loss: 0.04330947995185852
step: 50, loss: 0.02806096524000168
step: 60, loss: 0.09032043814659119
step: 70, loss: 0.04746298864483833
step: 80, loss: 0.01898851990699768
step: 90, loss: 0.031299274414777756
step: 100, loss: 0.009751870296895504
step: 110, loss: 0.04750290885567665
step: 120, loss: 0.045490313321352005
step: 130, loss: 0.05323651432991028
step: 140, loss: 0.06055537611246109
step: 150, loss: 0.014284895732998848
step: 160, loss: 0.0001506438566138968
step: 170, loss: 0.027278218418359756
step: 180, loss: 0.041409291326999664
step: 190, loss: 0.04510525241494179
step: 200, loss: 0.08515452593564987
step: 210, loss: 0.06562834978103638
step: 220, loss: 0.08667541295289993
step: 230, loss: 0.1444532573223114
step: 240, loss: 0.06646717339754105
step: 250, loss: 0.03083609789609909
step: 260, loss: 0.2120390683412552
step: 270, loss: 0.029849153012037277
step: 280, loss: 0.09564462304115295
step: 290, loss: 0.06625886261463165
step: 300, loss: 0.09266453981399536
step: 310, loss: 0.013810623437166214
step: 320, loss: 0.05200948193669319
step: 330, loss: 0.03786647319793701
step: 340, loss: 0.002794967032968998
step: 350, loss: 0.02916790544986725
step: 360, loss: 0.040822044014930725
step: 370, loss: 0.022510424256324768
step: 380, loss: 0.05302420258522034
step: 390, loss: 0.03001248836517334
step: 400, loss: 0.12060481309890747
step: 410, loss: 0.01300051435828209
step: 420, loss: 0.06702286750078201
step: 430, loss: 0.07616809010505676
step: 440, loss: 0.0494624562561512
step: 450, loss: 0.025821495801210403
step: 460, loss: 0.05984717980027199
epoch 11: dev_f1=0.9898989898989898, f1=0.9776785714285714, best_f1=0.9775280898876404
step: 0, loss: 0.04865337908267975
step: 10, loss: 0.00021427436149679124
step: 20, loss: 0.024819180369377136
step: 30, loss: 0.057812489569187164
step: 40, loss: 0.06775902211666107
step: 50, loss: 0.08071379363536835
step: 60, loss: 0.13294462859630585
step: 70, loss: 0.0594651997089386
step: 80, loss: 0.03493176028132439
step: 90, loss: 0.03937724232673645
step: 100, loss: 0.016780570149421692
step: 110, loss: 0.003771191230043769
step: 120, loss: 0.02814675308763981
step: 130, loss: 0.014534778892993927
step: 140, loss: 0.0019130496075376868
step: 150, loss: 0.06143569201231003
step: 160, loss: 0.04956648498773575
step: 170, loss: 0.12898139655590057
step: 180, loss: 0.0327385812997818
step: 190, loss: 0.031205350533127785
step: 200, loss: 0.027899455279111862
step: 210, loss: 0.061814628541469574
step: 220, loss: 0.0020196381956338882
step: 230, loss: 0.09680251777172089
step: 240, loss: 0.004021685104817152
step: 250, loss: 0.05000235512852669
step: 260, loss: 0.0911896750330925
step: 270, loss: 0.04300140216946602
step: 280, loss: 0.024871347472071648
step: 290, loss: 0.12281670421361923
step: 300, loss: 0.07977762818336487
step: 310, loss: 0.060919687151908875
step: 320, loss: 0.00011943135177716613
step: 330, loss: 0.07114645093679428
step: 340, loss: 0.08732137084007263
step: 350, loss: 0.0302500631660223
step: 360, loss: 0.020270969718694687
step: 370, loss: 0.09688737243413925
step: 380, loss: 0.03492803871631622
step: 390, loss: 0.10535356402397156
step: 400, loss: 0.006567026022821665
step: 410, loss: 0.013974211178719997
step: 420, loss: 0.04603605717420578
step: 430, loss: 0.038593512028455734
step: 440, loss: 0.15509553253650665
step: 450, loss: 0.10251403599977493
step: 460, loss: 0.10833463072776794
epoch 12: dev_f1=0.9887387387387387, f1=0.9831271091113611, best_f1=0.9775280898876404
step: 0, loss: 0.05900673195719719
step: 10, loss: 0.05312503129243851
step: 20, loss: 0.05885133147239685
step: 30, loss: 0.018489401787519455
step: 40, loss: 0.047909341752529144
step: 50, loss: 0.05072132125496864
step: 60, loss: 0.0008931036572903395
step: 70, loss: 0.2245618999004364
step: 80, loss: 0.05207769572734833
step: 90, loss: 0.017390387132763863
step: 100, loss: 0.07832832634449005
step: 110, loss: 0.04314205422997475
step: 120, loss: 0.04799719154834747
step: 130, loss: 0.029684416949748993
step: 140, loss: 0.09432417154312134
step: 150, loss: 0.048508696258068085
step: 160, loss: 0.019504103809595108
step: 170, loss: 0.005959297996014357
step: 180, loss: 0.002451020060107112
step: 190, loss: 0.033812105655670166
step: 200, loss: 0.023775048553943634
step: 210, loss: 0.053134504705667496
step: 220, loss: 0.027125906199216843
step: 230, loss: 0.07902310788631439
step: 240, loss: 0.06276315450668335
step: 250, loss: 0.024100294336676598
step: 260, loss: 0.037500280886888504
step: 270, loss: 0.026359766721725464
step: 280, loss: 0.023916594684123993
step: 290, loss: 0.04229111224412918
step: 300, loss: 0.006674688309431076
step: 310, loss: 0.0038517063949257135
step: 320, loss: 0.14321792125701904
step: 330, loss: 0.009730968624353409
step: 340, loss: 0.06975574791431427
step: 350, loss: 0.09010113775730133
step: 360, loss: 0.08427084237337112
step: 370, loss: 0.026209723204374313
step: 380, loss: 0.03430807963013649
step: 390, loss: 0.04915402829647064
step: 400, loss: 0.04489237815141678
step: 410, loss: 0.01809747889637947
step: 420, loss: 0.03256950527429581
step: 430, loss: 0.042983073741197586
step: 440, loss: 0.046725235879421234
step: 450, loss: 0.02513582445681095
step: 460, loss: 0.0020035041961818933
epoch 13: dev_f1=0.9887892376681614, f1=0.9765363128491621, best_f1=0.9775280898876404
step: 0, loss: 0.08061163872480392
step: 10, loss: 0.041779775172472
step: 20, loss: 0.04203120246529579
step: 30, loss: 0.016596024855971336
step: 40, loss: 0.029862122610211372
step: 50, loss: 0.10497301816940308
step: 60, loss: 0.04010554030537605
step: 70, loss: 0.02328771911561489
step: 80, loss: 0.061475832015275955
step: 90, loss: 0.04737534373998642
step: 100, loss: 0.0001523457613075152
step: 110, loss: 0.0778542160987854
step: 120, loss: 0.020788496360182762
step: 130, loss: 0.03110709972679615
step: 140, loss: 0.04903983697295189
step: 150, loss: 0.04173266887664795
step: 160, loss: 0.016999833285808563
step: 170, loss: 0.0227546077221632
step: 180, loss: 0.025477761402726173
step: 190, loss: 0.0008348375558853149
step: 200, loss: 0.002260198350995779
step: 210, loss: 0.02660832181572914
step: 220, loss: 0.04445861279964447
step: 230, loss: 5.759231498814188e-05
step: 240, loss: 0.022688722237944603
step: 250, loss: 0.03712565079331398
step: 260, loss: 0.03794027119874954
step: 270, loss: 0.025759540498256683
step: 280, loss: 0.06904185563325882
step: 290, loss: 0.044914666563272476
step: 300, loss: 0.07309768348932266
step: 310, loss: 0.050854623317718506
step: 320, loss: 0.07251697778701782
step: 330, loss: 0.0229816734790802
step: 340, loss: 0.02395927533507347
step: 350, loss: 0.08042973279953003
step: 360, loss: 0.048237115144729614
step: 370, loss: 0.052620917558670044
step: 380, loss: 0.02787874825298786
step: 390, loss: 0.02802375704050064
step: 400, loss: 0.019062303006649017
step: 410, loss: 0.07397476583719254
step: 420, loss: 0.02786930650472641
step: 430, loss: 0.025113478302955627
step: 440, loss: 0.00012613070430234075
step: 450, loss: 0.08985905349254608
step: 460, loss: 0.03827600181102753
epoch 14: dev_f1=0.9898534385569334, f1=0.9742441209406495, best_f1=0.9775280898876404
step: 0, loss: 0.08405425399541855
step: 10, loss: 0.03375006839632988
step: 20, loss: 0.00017174758249893785
step: 30, loss: 0.001060573267750442
step: 40, loss: 0.07239661365747452
step: 50, loss: 0.007679921109229326
step: 60, loss: 0.0031291027553379536
step: 70, loss: 0.04331512749195099
step: 80, loss: 0.018685489892959595
step: 90, loss: 0.023005938157439232
step: 100, loss: 0.007715368177741766
step: 110, loss: 0.023746686056256294
step: 120, loss: 0.08216217905282974
step: 130, loss: 0.02241867035627365
step: 140, loss: 0.018514122813940048
step: 150, loss: 0.09942161291837692
step: 160, loss: 0.021188179031014442
step: 170, loss: 0.0018150854157283902
step: 180, loss: 0.08935026824474335
step: 190, loss: 0.028772078454494476
step: 200, loss: 0.10579295456409454
step: 210, loss: 0.05912270396947861
step: 220, loss: 0.027104942128062248
step: 230, loss: 0.12468552589416504
step: 240, loss: 0.11289601027965546
step: 250, loss: 0.07804471999406815
step: 260, loss: 0.049690909683704376
step: 270, loss: 0.06163060665130615
step: 280, loss: 0.0007442345377057791
step: 290, loss: 0.00012566029909066856
step: 300, loss: 0.015106079168617725
step: 310, loss: 0.00871270801872015
step: 320, loss: 0.0011815241305157542
step: 330, loss: 0.07852376252412796
step: 340, loss: 0.021643389016389847
step: 350, loss: 0.08738099783658981
step: 360, loss: 0.00021532065875362605
step: 370, loss: 0.0186687670648098
step: 380, loss: 0.04116057604551315
step: 390, loss: 0.007649831473827362
step: 400, loss: 0.027114998549222946
step: 410, loss: 0.12271256744861603
step: 420, loss: 0.03010355681180954
step: 430, loss: 0.020840749144554138
step: 440, loss: 0.06485185027122498
step: 450, loss: 0.09961549192667007
step: 460, loss: 0.02771252766251564
epoch 15: dev_f1=0.990990990990991, f1=0.9764837625979844, best_f1=0.9775280898876404
step: 0, loss: 0.04389313608407974
step: 10, loss: 0.00012393300130497664
step: 20, loss: 0.06119247153401375
step: 30, loss: 0.05559349060058594
step: 40, loss: 0.06670034676790237
step: 50, loss: 0.060534633696079254
step: 60, loss: 0.04221460595726967
step: 70, loss: 0.02485641837120056
step: 80, loss: 0.0007557226927019656
step: 90, loss: 0.019694333896040916
step: 100, loss: 0.08616653084754944
step: 110, loss: 0.025255165994167328
step: 120, loss: 0.00031277965172193944
step: 130, loss: 0.04028468579053879
step: 140, loss: 0.04354312643408775
step: 150, loss: 0.12652668356895447
step: 160, loss: 0.01123087015002966
step: 170, loss: 0.049392249435186386
step: 180, loss: 0.04142037779092789
step: 190, loss: 0.022909820079803467
step: 200, loss: 0.0001667057367740199
step: 210, loss: 0.023793809115886688
step: 220, loss: 0.05736026540398598
step: 230, loss: 0.04843861237168312
step: 240, loss: 0.023371651768684387
step: 250, loss: 0.040187858045101166
step: 260, loss: 0.05737052485346794
step: 270, loss: 0.00097941723652184
step: 280, loss: 0.020523564890027046
step: 290, loss: 0.008363049477338791
step: 300, loss: 0.00010152703180210665
step: 310, loss: 0.1129152774810791
step: 320, loss: 0.032364971935749054
step: 330, loss: 0.09614226967096329
step: 340, loss: 0.03821716085076332
step: 350, loss: 0.0949225127696991
step: 360, loss: 0.004576547536998987
step: 370, loss: 0.01737416721880436
step: 380, loss: 0.06289342045783997
step: 390, loss: 0.019845278933644295
step: 400, loss: 0.08816026151180267
step: 410, loss: 0.04224037379026413
step: 420, loss: 0.040272634476423264
step: 430, loss: 0.015898432582616806
step: 440, loss: 0.022790513932704926
step: 450, loss: 0.00010855232540052384
step: 460, loss: 0.03481051325798035
epoch 16: dev_f1=0.990990990990991, f1=0.9787709497206705, best_f1=0.9775280898876404
step: 0, loss: 0.04714064300060272
step: 10, loss: 0.10974235832691193
step: 20, loss: 0.04498293623328209
step: 30, loss: 0.04864170402288437
step: 40, loss: 0.03755401074886322
step: 50, loss: 0.004486988298594952
step: 60, loss: 0.023149892687797546
step: 70, loss: 0.04737517610192299
step: 80, loss: 0.08234245330095291
step: 90, loss: 0.025298964232206345
step: 100, loss: 0.022555893287062645
step: 110, loss: 9.380395931657404e-05
step: 120, loss: 0.04303891211748123
step: 130, loss: 0.022791769355535507
step: 140, loss: 0.07358535379171371
step: 150, loss: 0.058015089482069016
step: 160, loss: 0.036377422511577606
step: 170, loss: 0.03478909656405449
step: 180, loss: 0.06534872949123383
step: 190, loss: 0.023754941299557686
step: 200, loss: 0.047845058143138885
step: 210, loss: 0.02185223624110222
step: 220, loss: 8.839914517011493e-05
step: 230, loss: 0.051873452961444855
step: 240, loss: 0.0032749667298048735
step: 250, loss: 0.05478627607226372
step: 260, loss: 0.00012255665205884725
step: 270, loss: 0.02070019207894802
step: 280, loss: 0.03383543714880943
step: 290, loss: 0.02709297463297844
step: 300, loss: 0.025735443457961082
step: 310, loss: 0.0005015760543756187
step: 320, loss: 0.00022424518829211593
step: 330, loss: 0.0018148105591535568
step: 340, loss: 0.024439560249447823
step: 350, loss: 0.023812351748347282
step: 360, loss: 0.041444528847932816
step: 370, loss: 0.06955189257860184
step: 380, loss: 0.04171810299158096
step: 390, loss: 0.023743318393826485
step: 400, loss: 0.00016946707910392433
step: 410, loss: 0.04082481935620308
step: 420, loss: 0.0012176453601568937
step: 430, loss: 0.04484568536281586
step: 440, loss: 0.03938430920243263
step: 450, loss: 0.0001869353436632082
step: 460, loss: 0.01469802763313055
epoch 17: dev_f1=0.992108229988726, f1=0.978675645342312, best_f1=0.9775280898876404
step: 0, loss: 8.682246698299423e-05
step: 10, loss: 0.040588025003671646
step: 20, loss: 0.02337733283638954
step: 30, loss: 0.02549992874264717
step: 40, loss: 0.053963545709848404
step: 50, loss: 0.06952773034572601
step: 60, loss: 0.00016726850299164653
step: 70, loss: 0.045287247747182846
step: 80, loss: 0.0942142903804779
step: 90, loss: 0.04011577367782593
step: 100, loss: 0.0002591875090729445
step: 110, loss: 0.02535797469317913
step: 120, loss: 0.01330490130931139
step: 130, loss: 0.04610860347747803
step: 140, loss: 3.240450314478949e-05
step: 150, loss: 0.18969760835170746
step: 160, loss: 9.731594036566094e-05
step: 170, loss: 0.04266722872853279
step: 180, loss: 0.07809796929359436
step: 190, loss: 0.05811860039830208
step: 200, loss: 0.04962069168686867
step: 210, loss: 0.06758996099233627
step: 220, loss: 0.02851743996143341
step: 230, loss: 0.022209985181689262
step: 240, loss: 0.044808343052864075
step: 250, loss: 0.04130898043513298
step: 260, loss: 0.02226320281624794
step: 270, loss: 0.012367988005280495
step: 280, loss: 0.03317141905426979
step: 290, loss: 0.023442324250936508
step: 300, loss: 0.035740721970796585
step: 310, loss: 0.0003697287174873054
step: 320, loss: 0.06280053406953812
step: 330, loss: 0.02375064790248871
step: 340, loss: 0.022329043596982956
step: 350, loss: 0.04022512957453728
step: 360, loss: 0.08818129450082779
step: 370, loss: 0.0002708009269554168
step: 380, loss: 0.06606938689947128
step: 390, loss: 4.7014640585985035e-05
step: 400, loss: 0.043326642364263535
step: 410, loss: 0.0003614871820900589
step: 420, loss: 0.00032844734960235655
step: 430, loss: 0.028028268367052078
step: 440, loss: 0.0006980615435168147
step: 450, loss: 0.04884781315922737
step: 460, loss: 0.04266026243567467
epoch 18: dev_f1=0.990990990990991, f1=0.9787234042553192, best_f1=0.9775280898876404
step: 0, loss: 0.0880710557103157
step: 10, loss: 0.00023892609169706702
step: 20, loss: 1.5299250662792474e-05
step: 30, loss: 0.022932838648557663
step: 40, loss: 0.048138704150915146
step: 50, loss: 0.06359522044658661
step: 60, loss: 0.029367046430706978
step: 70, loss: 0.023638548329472542
step: 80, loss: 0.02197957970201969
step: 90, loss: 7.338271825574338e-05
step: 100, loss: 0.0608307309448719
step: 110, loss: 0.02168755605816841
step: 120, loss: 0.00013906871026847512
step: 130, loss: 0.11746498942375183
step: 140, loss: 0.029090480878949165
step: 150, loss: 0.0004885096568614244
step: 160, loss: 0.050548143684864044
step: 170, loss: 0.059487827122211456
step: 180, loss: 0.09097297489643097
step: 190, loss: 0.00035932729952037334
step: 200, loss: 0.042821019887924194
step: 210, loss: 0.026539713144302368
step: 220, loss: 0.02877555787563324
step: 230, loss: 0.018566502258181572
step: 240, loss: 0.06214629113674164
step: 250, loss: 0.06672180444002151
step: 260, loss: 0.04282760992646217
step: 270, loss: 5.715410952689126e-05
step: 280, loss: 0.030922770500183105
step: 290, loss: 0.01974141038954258
step: 300, loss: 0.09362867474555969
step: 310, loss: 8.647796494187787e-05
step: 320, loss: 0.018238358199596405
step: 330, loss: 0.03660732880234718
step: 340, loss: 0.09124813973903656
step: 350, loss: 0.0549110509455204
step: 360, loss: 0.05249178409576416
step: 370, loss: 0.06073971092700958
step: 380, loss: 0.01919911615550518
step: 390, loss: 0.06018038094043732
step: 400, loss: 0.022897042334079742
step: 410, loss: 0.014180604368448257
step: 420, loss: 0.0011127537582069635
step: 430, loss: 0.003688252065330744
step: 440, loss: 0.0543472021818161
step: 450, loss: 0.022542184218764305
step: 460, loss: 0.02457197569310665
epoch 19: dev_f1=0.990990990990991, f1=0.9776286353467561, best_f1=0.9775280898876404
step: 0, loss: 0.030290568247437477
step: 10, loss: 0.0014864318072795868
step: 20, loss: 0.06336933374404907
step: 30, loss: 0.048116665333509445
step: 40, loss: 0.0485011488199234
step: 50, loss: 0.04461571201682091
step: 60, loss: 0.02129906602203846
step: 70, loss: 0.027397336438298225
step: 80, loss: 0.023182161152362823
step: 90, loss: 0.0014965515583753586
step: 100, loss: 0.026718666777014732
step: 110, loss: 0.0033589093945920467
step: 120, loss: 0.027619270607829094
step: 130, loss: 7.627041486557573e-05
step: 140, loss: 0.02250867709517479
step: 150, loss: 0.03144453838467598
step: 160, loss: 0.06594379246234894
step: 170, loss: 0.07308530062437057
step: 180, loss: 0.08606807887554169
step: 190, loss: 0.048035718500614166
step: 200, loss: 0.023190956562757492
step: 210, loss: 0.02101009711623192
step: 220, loss: 0.03939139097929001
step: 230, loss: 0.0486137755215168
step: 240, loss: 0.04570567235350609
step: 250, loss: 0.018389014527201653
step: 260, loss: 4.570143573801033e-05
step: 270, loss: 0.02201288752257824
step: 280, loss: 0.025896882638335228
step: 290, loss: 0.04262130334973335
step: 300, loss: 0.026738205924630165
step: 310, loss: 0.009187868796288967
step: 320, loss: 0.03444518521428108
step: 330, loss: 0.03866495192050934
step: 340, loss: 0.0734606385231018
step: 350, loss: 0.020780855789780617
step: 360, loss: 3.813521107076667e-05
step: 370, loss: 0.03476709872484207
step: 380, loss: 0.038969025015830994
step: 390, loss: 0.024039264768362045
step: 400, loss: 0.042052946984767914
step: 410, loss: 0.027802975848317146
step: 420, loss: 0.01795079931616783
step: 430, loss: 0.007567755412310362
step: 440, loss: 0.0003798404068220407
step: 450, loss: 0.047959767282009125
step: 460, loss: 8.541368879377842e-05
epoch 20: dev_f1=0.990990990990991, f1=0.9776286353467561, best_f1=0.9775280898876404
