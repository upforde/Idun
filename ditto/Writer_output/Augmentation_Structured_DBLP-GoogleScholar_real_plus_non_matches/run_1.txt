cuda
Device: cuda
step: 0, loss: 0.6988038420677185
step: 10, loss: 0.4536789655685425
step: 20, loss: 0.2246687412261963
step: 30, loss: 0.3159498870372772
step: 40, loss: 0.3133912682533264
step: 50, loss: 0.14664295315742493
step: 60, loss: 0.20373210310935974
step: 70, loss: 0.13488063216209412
step: 80, loss: 0.29948940873146057
step: 90, loss: 0.1928882747888565
step: 100, loss: 0.17927125096321106
step: 110, loss: 0.15793731808662415
step: 120, loss: 0.2231915146112442
step: 130, loss: 0.15141379833221436
step: 140, loss: 0.26428866386413574
step: 150, loss: 0.12653493881225586
step: 160, loss: 0.10833481699228287
step: 170, loss: 0.06633104383945465
step: 180, loss: 0.062097884714603424
step: 190, loss: 0.2556889057159424
step: 200, loss: 0.06804631650447845
step: 210, loss: 0.13694103062152863
step: 220, loss: 0.07720509171485901
step: 230, loss: 0.1002604067325592
step: 240, loss: 0.18115083873271942
step: 250, loss: 0.16882996261119843
step: 260, loss: 0.10354616492986679
step: 270, loss: 0.10631152987480164
step: 280, loss: 0.08745318651199341
step: 290, loss: 0.06266389042139053
step: 300, loss: 0.13885052502155304
step: 310, loss: 0.22103475034236908
step: 320, loss: 0.07544920593500137
step: 330, loss: 0.09423863887786865
step: 340, loss: 0.21929004788398743
step: 350, loss: 0.29256394505500793
step: 360, loss: 0.12557372450828552
step: 370, loss: 0.09332385659217834
step: 380, loss: 0.06740095466375351
step: 390, loss: 0.05328908935189247
step: 400, loss: 0.15625333786010742
step: 410, loss: 0.24646413326263428
step: 420, loss: 0.359188973903656
step: 430, loss: 0.1667575240135193
step: 440, loss: 0.14455263316631317
step: 450, loss: 0.12321589142084122
step: 460, loss: 0.03049946017563343
step: 470, loss: 0.017022090032696724
step: 480, loss: 0.13871216773986816
step: 490, loss: 0.08430401980876923
step: 500, loss: 0.09326495975255966
step: 510, loss: 0.1438741534948349
step: 520, loss: 0.21338902413845062
step: 530, loss: 0.06631726026535034
step: 540, loss: 0.1272280216217041
step: 550, loss: 0.13747352361679077
step: 560, loss: 0.09636250883340836
step: 570, loss: 0.07731401920318604
step: 580, loss: 0.13822366297245026
step: 590, loss: 0.07587885856628418
step: 600, loss: 0.045306675136089325
step: 610, loss: 0.1551019847393036
step: 620, loss: 0.10405685007572174
step: 630, loss: 0.18251089751720428
step: 640, loss: 0.16770003736019135
step: 650, loss: 0.17498260736465454
step: 660, loss: 0.1493932604789734
step: 670, loss: 0.05832555145025253
step: 680, loss: 0.1223306655883789
step: 690, loss: 0.07758556306362152
step: 700, loss: 0.10558021068572998
step: 710, loss: 0.1588992178440094
step: 720, loss: 0.11793018132448196
step: 730, loss: 0.2105666697025299
step: 740, loss: 0.03267170861363411
step: 750, loss: 0.11199503391981125
step: 760, loss: 0.05118093639612198
step: 770, loss: 0.14019109308719635
step: 780, loss: 0.08572294563055038
step: 790, loss: 0.10870124399662018
step: 800, loss: 0.1330360323190689
step: 810, loss: 0.1839677095413208
step: 820, loss: 0.14218807220458984
step: 830, loss: 0.028049003332853317
step: 840, loss: 0.21535620093345642
step: 850, loss: 0.06788439303636551
step: 860, loss: 0.033216554671525955
step: 870, loss: 0.038022566586732864
step: 880, loss: 0.24752530455589294
step: 890, loss: 0.10528291761875153
step: 900, loss: 0.1933458298444748
step: 910, loss: 0.09650446474552155
step: 920, loss: 0.18872107565402985
step: 930, loss: 0.16170692443847656
step: 940, loss: 0.05772658437490463
step: 950, loss: 0.10957248508930206
step: 960, loss: 0.02423647791147232
step: 970, loss: 0.0581403523683548
epoch 1: dev_f1=0.9271461716937355, f1=0.9293302540415704, best_f1=0.9293302540415704
step: 0, loss: 0.06571908295154572
step: 10, loss: 0.205985888838768
step: 20, loss: 0.06628511101007462
step: 30, loss: 0.0713815987110138
step: 40, loss: 0.09777387976646423
step: 50, loss: 0.06110798567533493
step: 60, loss: 0.0313463993370533
step: 70, loss: 0.14256790280342102
step: 80, loss: 0.22524450719356537
step: 90, loss: 0.17713110148906708
step: 100, loss: 0.11691403388977051
step: 110, loss: 0.044975440949201584
step: 120, loss: 0.155562162399292
step: 130, loss: 0.0776297003030777
step: 140, loss: 0.2209947258234024
step: 150, loss: 0.06859325617551804
step: 160, loss: 0.15530340373516083
step: 170, loss: 0.0921553298830986
step: 180, loss: 0.03356485441327095
step: 190, loss: 0.013364162296056747
step: 200, loss: 0.20871028304100037
step: 210, loss: 0.16331864893436432
step: 220, loss: 0.19451960921287537
step: 230, loss: 0.08487605303525925
step: 240, loss: 0.11587122827768326
step: 250, loss: 0.0474148690700531
step: 260, loss: 0.030491771176457405
step: 270, loss: 0.055019740015268326
step: 280, loss: 0.04258788749575615
step: 290, loss: 0.16919450461864471
step: 300, loss: 0.041932612657547
step: 310, loss: 0.09682851284742355
step: 320, loss: 0.13267435133457184
step: 330, loss: 0.4379279613494873
step: 340, loss: 0.15639567375183105
step: 350, loss: 0.12786546349525452
step: 360, loss: 0.05176922306418419
step: 370, loss: 0.06284059584140778
step: 380, loss: 0.24924039840698242
step: 390, loss: 0.05041039362549782
step: 400, loss: 0.06300505995750427
step: 410, loss: 0.12810130417346954
step: 420, loss: 0.02952605113387108
step: 430, loss: 0.02261156029999256
step: 440, loss: 0.10505744069814682
step: 450, loss: 0.09535838663578033
step: 460, loss: 0.21932435035705566
step: 470, loss: 0.09943287819623947
step: 480, loss: 0.12738458812236786
step: 490, loss: 0.2005656212568283
step: 500, loss: 0.08382244408130646
step: 510, loss: 0.08273408561944962
step: 520, loss: 0.05498894304037094
step: 530, loss: 0.06072258949279785
step: 540, loss: 0.17197436094284058
step: 550, loss: 0.13506977260112762
step: 560, loss: 0.03333018347620964
step: 570, loss: 0.026518499478697777
step: 580, loss: 0.4015304446220398
step: 590, loss: 0.09517935663461685
step: 600, loss: 0.13985957205295563
step: 610, loss: 0.05886068940162659
step: 620, loss: 0.09230754524469376
step: 630, loss: 0.11339274793863297
step: 640, loss: 0.21318760514259338
step: 650, loss: 0.07467107474803925
step: 660, loss: 0.06977493315935135
step: 670, loss: 0.1438385397195816
step: 680, loss: 0.0484921969473362
step: 690, loss: 0.06985097378492355
step: 700, loss: 0.20984601974487305
step: 710, loss: 0.11060664057731628
step: 720, loss: 0.23758770525455475
step: 730, loss: 0.24556684494018555
step: 740, loss: 0.07588975876569748
step: 750, loss: 0.04327745363116264
step: 760, loss: 0.06672990322113037
step: 770, loss: 0.05877864360809326
step: 780, loss: 0.013016513548791409
step: 790, loss: 0.126015767455101
step: 800, loss: 0.03918313607573509
step: 810, loss: 0.058604177087545395
step: 820, loss: 0.018594397231936455
step: 830, loss: 0.11022234708070755
step: 840, loss: 0.20852991938591003
step: 850, loss: 0.024885274469852448
step: 860, loss: 0.04377325624227524
step: 870, loss: 0.020354410633444786
step: 880, loss: 0.08653604984283447
step: 890, loss: 0.10882548987865448
step: 900, loss: 0.11660630255937576
step: 910, loss: 0.042692869901657104
step: 920, loss: 0.030063092708587646
step: 930, loss: 0.02892070822417736
step: 940, loss: 0.04095923900604248
step: 950, loss: 0.05401008203625679
step: 960, loss: 0.11666382104158401
step: 970, loss: 0.24987538158893585
epoch 2: dev_f1=0.9293218720152817, f1=0.9246901811248809, best_f1=0.9246901811248809
step: 0, loss: 0.17096655070781708
step: 10, loss: 0.08997771888971329
step: 20, loss: 0.1324125975370407
step: 30, loss: 0.06057601422071457
step: 40, loss: 0.04733993485569954
step: 50, loss: 0.04855866730213165
step: 60, loss: 0.07204195857048035
step: 70, loss: 0.09141483157873154
step: 80, loss: 0.03769785165786743
step: 90, loss: 0.017212795093655586
step: 100, loss: 0.16225554049015045
step: 110, loss: 0.0664571225643158
step: 120, loss: 0.09455525130033493
step: 130, loss: 0.06684611737728119
step: 140, loss: 0.032644495368003845
step: 150, loss: 0.15887980163097382
step: 160, loss: 0.04232996329665184
step: 170, loss: 0.050932545214891434
step: 180, loss: 0.07055249065160751
step: 190, loss: 0.030410341918468475
step: 200, loss: 0.048395778983831406
step: 210, loss: 0.05908600986003876
step: 220, loss: 0.0443546287715435
step: 230, loss: 0.08617715537548065
step: 240, loss: 0.05744815990328789
step: 250, loss: 0.17916274070739746
step: 260, loss: 0.07461636513471603
step: 270, loss: 0.02502479963004589
step: 280, loss: 0.15518084168434143
step: 290, loss: 0.07459373027086258
step: 300, loss: 0.12837423384189606
step: 310, loss: 0.1100161224603653
step: 320, loss: 0.09837895631790161
step: 330, loss: 0.05767056345939636
step: 340, loss: 0.029412105679512024
step: 350, loss: 0.057312097400426865
step: 360, loss: 0.16247400641441345
step: 370, loss: 0.12019762396812439
step: 380, loss: 0.07519970834255219
step: 390, loss: 0.16062039136886597
step: 400, loss: 0.08502187579870224
step: 410, loss: 0.13563404977321625
step: 420, loss: 0.023647254332900047
step: 430, loss: 0.038497816771268845
step: 440, loss: 0.07989447563886642
step: 450, loss: 0.007196977734565735
step: 460, loss: 0.14509063959121704
step: 470, loss: 0.0590796135365963
step: 480, loss: 0.09082180261611938
step: 490, loss: 0.09796805679798126
step: 500, loss: 0.086329884827137
step: 510, loss: 0.06242859363555908
step: 520, loss: 0.16955897212028503
step: 530, loss: 0.026186786592006683
step: 540, loss: 0.06645337492227554
step: 550, loss: 0.07853706926107407
step: 560, loss: 0.12889757752418518
step: 570, loss: 0.024106187745928764
step: 580, loss: 0.03846009448170662
step: 590, loss: 0.14983178675174713
step: 600, loss: 0.0913996621966362
step: 610, loss: 0.1442868411540985
step: 620, loss: 0.10592769086360931
step: 630, loss: 0.03858622908592224
step: 640, loss: 0.11109484732151031
step: 650, loss: 0.13586032390594482
step: 660, loss: 0.06035573035478592
step: 670, loss: 0.11650547385215759
step: 680, loss: 0.03542044386267662
step: 690, loss: 0.03084138222038746
step: 700, loss: 0.03638094663619995
step: 710, loss: 0.056309327483177185
step: 720, loss: 0.10744547843933105
step: 730, loss: 0.06650661677122116
step: 740, loss: 0.07157360762357712
step: 750, loss: 0.07989959418773651
step: 760, loss: 0.1128213033080101
step: 770, loss: 0.011447062715888023
step: 780, loss: 0.07481524348258972
step: 790, loss: 0.21330298483371735
step: 800, loss: 0.09484078735113144
step: 810, loss: 0.045660194009542465
step: 820, loss: 0.05476026237010956
step: 830, loss: 0.05285011604428291
step: 840, loss: 0.055206749588251114
step: 850, loss: 0.05717085674405098
step: 860, loss: 0.06675522774457932
step: 870, loss: 0.10323812812566757
step: 880, loss: 0.0342094749212265
step: 890, loss: 0.04736790806055069
step: 900, loss: 0.027152474969625473
step: 910, loss: 0.08290907740592957
step: 920, loss: 0.20153459906578064
step: 930, loss: 0.08084206283092499
step: 940, loss: 0.05750564485788345
step: 950, loss: 0.1331031173467636
step: 960, loss: 0.2623918056488037
step: 970, loss: 0.0543554425239563
epoch 3: dev_f1=0.9372114496768237, f1=0.9381918819188192, best_f1=0.9381918819188192
step: 0, loss: 0.08663774281740189
step: 10, loss: 0.06251221895217896
step: 20, loss: 0.11035160720348358
step: 30, loss: 0.06923476606607437
step: 40, loss: 0.1097492203116417
step: 50, loss: 0.034101810306310654
step: 60, loss: 0.05339301377534866
step: 70, loss: 0.017801256850361824
step: 80, loss: 0.01886514574289322
step: 90, loss: 0.05384242534637451
step: 100, loss: 0.0759371742606163
step: 110, loss: 0.06852670013904572
step: 120, loss: 0.11885528266429901
step: 130, loss: 4.33648528996855e-05
step: 140, loss: 0.07202724367380142
step: 150, loss: 0.06699776649475098
step: 160, loss: 0.06627418100833893
step: 170, loss: 0.06284214556217194
step: 180, loss: 0.024367818608880043
step: 190, loss: 0.02229437604546547
step: 200, loss: 0.021719537675380707
step: 210, loss: 0.03420247510075569
step: 220, loss: 0.02967929281294346
step: 230, loss: 0.017993908375501633
step: 240, loss: 0.035984162241220474
step: 250, loss: 0.1273118108510971
step: 260, loss: 0.08945193886756897
step: 270, loss: 0.10898522287607193
step: 280, loss: 0.07521489262580872
step: 290, loss: 0.02701057493686676
step: 300, loss: 0.028705283999443054
step: 310, loss: 0.15433891117572784
step: 320, loss: 0.05723799765110016
step: 330, loss: 0.08894246816635132
step: 340, loss: 0.10489651560783386
step: 350, loss: 0.06322791427373886
step: 360, loss: 0.022918518632650375
step: 370, loss: 0.06340741366147995
step: 380, loss: 0.05632701888680458
step: 390, loss: 0.015020203776657581
step: 400, loss: 0.05316448211669922
step: 410, loss: 0.27740973234176636
step: 420, loss: 0.10178471356630325
step: 430, loss: 0.07338661700487137
step: 440, loss: 0.07178492099046707
step: 450, loss: 0.05790369585156441
step: 460, loss: 0.09042561054229736
step: 470, loss: 0.021930072456598282
step: 480, loss: 0.044436629861593246
step: 490, loss: 0.10094812512397766
step: 500, loss: 0.058833301067352295
step: 510, loss: 0.1061655580997467
step: 520, loss: 0.022035934031009674
step: 530, loss: 0.04111470282077789
step: 540, loss: 0.23716215789318085
step: 550, loss: 0.044344641268253326
step: 560, loss: 0.1040506362915039
step: 570, loss: 0.014603735879063606
step: 580, loss: 0.06464862078428268
step: 590, loss: 0.02309967391192913
step: 600, loss: 0.02112906239926815
step: 610, loss: 0.09616712480783463
step: 620, loss: 0.04497041553258896
step: 630, loss: 0.1367981731891632
step: 640, loss: 0.0751112848520279
step: 650, loss: 0.02156764641404152
step: 660, loss: 0.020166875794529915
step: 670, loss: 0.18885090947151184
step: 680, loss: 0.02908046916127205
step: 690, loss: 0.06542281806468964
step: 700, loss: 0.06965898722410202
step: 710, loss: 0.07860766351222992
step: 720, loss: 0.01746806502342224
step: 730, loss: 0.07365909218788147
step: 740, loss: 0.12095676362514496
step: 750, loss: 0.051197588443756104
step: 760, loss: 0.09363517165184021
step: 770, loss: 0.07351396232843399
step: 780, loss: 0.22547276318073273
step: 790, loss: 0.06587089598178864
step: 800, loss: 0.08578653633594513
step: 810, loss: 0.21425005793571472
step: 820, loss: 0.05069814622402191
step: 830, loss: 0.022127790376544
step: 840, loss: 0.13808569312095642
step: 850, loss: 0.050467804074287415
step: 860, loss: 0.10263951867818832
step: 870, loss: 0.04193458333611488
step: 880, loss: 0.0800260454416275
step: 890, loss: 0.08458593487739563
step: 900, loss: 0.028362106531858444
step: 910, loss: 0.04642592370510101
step: 920, loss: 0.04978519678115845
step: 930, loss: 0.048733294010162354
step: 940, loss: 0.034087978303432465
step: 950, loss: 0.1285639852285385
step: 960, loss: 0.09179942309856415
step: 970, loss: 0.10634341090917587
epoch 4: dev_f1=0.9348127600554785, f1=0.9333333333333333, best_f1=0.9381918819188192
step: 0, loss: 0.00821531843394041
step: 10, loss: 0.08295326679944992
step: 20, loss: 0.11109858751296997
step: 30, loss: 0.043876465409994125
step: 40, loss: 0.032188910990953445
step: 50, loss: 0.09256372600793839
step: 60, loss: 0.08433229476213455
step: 70, loss: 0.056417495012283325
step: 80, loss: 0.039079442620277405
step: 90, loss: 0.02680109068751335
step: 100, loss: 0.07636202126741409
step: 110, loss: 0.008412797935307026
step: 120, loss: 0.0745943933725357
step: 130, loss: 0.02642347291111946
step: 140, loss: 0.05111195519566536
step: 150, loss: 0.11180216819047928
step: 160, loss: 0.06699512898921967
step: 170, loss: 0.05813455954194069
step: 180, loss: 0.039184510707855225
step: 190, loss: 0.10374679416418076
step: 200, loss: 0.0070887780748307705
step: 210, loss: 0.012687725946307182
step: 220, loss: 0.1315506398677826
step: 230, loss: 0.10172826051712036
step: 240, loss: 0.020213015377521515
step: 250, loss: 0.03012550249695778
step: 260, loss: 0.022608792409300804
step: 270, loss: 0.15718808770179749
step: 280, loss: 0.025313079357147217
step: 290, loss: 0.02452300488948822
step: 300, loss: 0.06780494004487991
step: 310, loss: 0.0921868085861206
step: 320, loss: 0.13848114013671875
step: 330, loss: 0.1256682425737381
step: 340, loss: 0.019764535129070282
step: 350, loss: 0.099474236369133
step: 360, loss: 0.04392362758517265
step: 370, loss: 0.059906668961048126
step: 380, loss: 0.10044442862272263
step: 390, loss: 0.07534046471118927
step: 400, loss: 0.016376424580812454
step: 410, loss: 0.02169693075120449
step: 420, loss: 0.0020126181188970804
step: 430, loss: 0.2360815554857254
step: 440, loss: 0.04155513271689415
step: 450, loss: 0.020178072154521942
step: 460, loss: 0.119414784014225
step: 470, loss: 0.0985276848077774
step: 480, loss: 0.0528128556907177
step: 490, loss: 0.1338133066892624
step: 500, loss: 0.15991228818893433
step: 510, loss: 0.09038026630878448
step: 520, loss: 0.096521757543087
step: 530, loss: 0.07166349142789841
step: 540, loss: 0.09297601878643036
step: 550, loss: 0.12127633392810822
step: 560, loss: 0.03500915318727493
step: 570, loss: 0.013807869516313076
step: 580, loss: 0.09100402146577835
step: 590, loss: 0.2001386135816574
step: 600, loss: 0.0870191901922226
step: 610, loss: 0.16506659984588623
step: 620, loss: 0.07145920395851135
step: 630, loss: 0.10805879533290863
step: 640, loss: 0.017759138718247414
step: 650, loss: 0.06004096940159798
step: 660, loss: 0.029225654900074005
step: 670, loss: 0.12823040783405304
step: 680, loss: 0.13603532314300537
step: 690, loss: 0.07369963824748993
step: 700, loss: 0.019951753318309784
step: 710, loss: 0.03539619967341423
step: 720, loss: 0.036590080708265305
step: 730, loss: 0.005394983571022749
step: 740, loss: 0.029084336012601852
step: 750, loss: 0.2177061289548874
step: 760, loss: 0.13010728359222412
step: 770, loss: 0.11305248737335205
step: 780, loss: 0.030657777562737465
step: 790, loss: 0.019881166517734528
step: 800, loss: 0.09630408883094788
step: 810, loss: 0.054256465286016464
step: 820, loss: 0.12308135628700256
step: 830, loss: 0.011209934018552303
step: 840, loss: 0.04010069742798805
step: 850, loss: 0.05808393284678459
step: 860, loss: 0.14480099081993103
step: 870, loss: 0.04307365417480469
step: 880, loss: 0.23231066763401031
step: 890, loss: 0.08439196646213531
step: 900, loss: 0.062125492841005325
step: 910, loss: 0.0006088507943786681
step: 920, loss: 0.020483754575252533
step: 930, loss: 0.06934014707803726
step: 940, loss: 0.023305993527173996
step: 950, loss: 0.03759383782744408
step: 960, loss: 0.017235631123185158
step: 970, loss: 0.1018780767917633
epoch 5: dev_f1=0.9367552703941339, f1=0.9334557136301056, best_f1=0.9381918819188192
step: 0, loss: 0.08593598753213882
step: 10, loss: 0.07997675985097885
step: 20, loss: 0.010260016657412052
step: 30, loss: 0.056732725352048874
step: 40, loss: 0.014344795607030392
step: 50, loss: 0.05555388703942299
step: 60, loss: 0.12001531571149826
step: 70, loss: 0.04159875586628914
step: 80, loss: 0.13351179659366608
step: 90, loss: 0.06327507644891739
step: 100, loss: 0.27537623047828674
step: 110, loss: 0.004817407578229904
step: 120, loss: 0.06351029127836227
step: 130, loss: 0.039004676043987274
step: 140, loss: 0.1220368966460228
step: 150, loss: 0.06406733393669128
step: 160, loss: 0.2672935724258423
step: 170, loss: 0.04837571084499359
step: 180, loss: 0.0796588584780693
step: 190, loss: 0.13468065857887268
step: 200, loss: 0.03206643834710121
step: 210, loss: 0.04208506643772125
step: 220, loss: 0.10064464807510376
step: 230, loss: 0.06860704720020294
step: 240, loss: 0.05899466946721077
step: 250, loss: 0.12251745909452438
step: 260, loss: 0.11238843202590942
step: 270, loss: 0.03945619985461235
step: 280, loss: 0.05626320466399193
step: 290, loss: 0.01805986650288105
step: 300, loss: 0.059294719249010086
step: 310, loss: 0.09293047338724136
step: 320, loss: 0.04297669231891632
step: 330, loss: 0.023926962167024612
step: 340, loss: 0.05453452095389366
step: 350, loss: 0.031199032440781593
step: 360, loss: 0.01224546693265438
step: 370, loss: 0.247327983379364
step: 380, loss: 0.08163444697856903
step: 390, loss: 0.04526273533701897
step: 400, loss: 0.2594466209411621
step: 410, loss: 0.15685860812664032
step: 420, loss: 0.05897144600749016
step: 430, loss: 0.09978887438774109
step: 440, loss: 0.05437010899186134
step: 450, loss: 0.10375247895717621
step: 460, loss: 0.0389082133769989
step: 470, loss: 0.03863270580768585
step: 480, loss: 0.014418977312743664
step: 490, loss: 0.06100335344672203
step: 500, loss: 0.12440928816795349
step: 510, loss: 0.028365815058350563
step: 520, loss: 0.1304224282503128
step: 530, loss: 0.020372742787003517
step: 540, loss: 0.0674571841955185
step: 550, loss: 0.1278870850801468
step: 560, loss: 0.052971865981817245
step: 570, loss: 0.10272638499736786
step: 580, loss: 0.08495435863733292
step: 590, loss: 0.09248562157154083
step: 600, loss: 0.012722646817564964
step: 610, loss: 0.08632196485996246
step: 620, loss: 0.1381290704011917
step: 630, loss: 0.11987391114234924
step: 640, loss: 0.06314586102962494
step: 650, loss: 0.006564256269484758
step: 660, loss: 0.06439712643623352
step: 670, loss: 0.2106419801712036
step: 680, loss: 0.07774405181407928
step: 690, loss: 0.07654733210802078
step: 700, loss: 0.0541643463075161
step: 710, loss: 0.025896921753883362
step: 720, loss: 0.01485662255436182
step: 730, loss: 0.08001537621021271
step: 740, loss: 0.06792090833187103
step: 750, loss: 0.13355103135108948
step: 760, loss: 0.015088404528796673
step: 770, loss: 0.20690272748470306
step: 780, loss: 0.0921926274895668
step: 790, loss: 0.11335430294275284
step: 800, loss: 0.014555074274539948
step: 810, loss: 0.18155698478221893
step: 820, loss: 0.06917943805456161
step: 830, loss: 0.0683295801281929
step: 840, loss: 0.012872793711721897
step: 850, loss: 0.008582878857851028
step: 860, loss: 0.01846981793642044
step: 870, loss: 0.12342911958694458
step: 880, loss: 0.035867586731910706
step: 890, loss: 0.16272401809692383
step: 900, loss: 0.0781443640589714
step: 910, loss: 0.034634314477443695
step: 920, loss: 0.08273176103830338
step: 930, loss: 0.07528544217348099
step: 940, loss: 0.04366785287857056
step: 950, loss: 0.04646770656108856
step: 960, loss: 0.030135503038764
step: 970, loss: 0.07398707419633865
epoch 6: dev_f1=0.9302325581395349, f1=0.9262295081967213, best_f1=0.9381918819188192
step: 0, loss: 0.0674867108464241
step: 10, loss: 0.06827384233474731
step: 20, loss: 0.0748925507068634
step: 30, loss: 0.0378284752368927
step: 40, loss: 0.027313562110066414
step: 50, loss: 0.010386066511273384
step: 60, loss: 0.043820276856422424
step: 70, loss: 0.02528560161590576
step: 80, loss: 0.011252055875957012
step: 90, loss: 0.1001143530011177
step: 100, loss: 0.06062508001923561
step: 110, loss: 0.01109854131937027
step: 120, loss: 0.05169898644089699
step: 130, loss: 0.08823959529399872
step: 140, loss: 0.027899742126464844
step: 150, loss: 0.11539295315742493
step: 160, loss: 0.0699799656867981
step: 170, loss: 0.1484384685754776
step: 180, loss: 0.023507319390773773
step: 190, loss: 0.11268932372331619
step: 200, loss: 0.06298932433128357
step: 210, loss: 0.04761321097612381
step: 220, loss: 0.06006366014480591
step: 230, loss: 0.09762510657310486
step: 240, loss: 0.059026267379522324
step: 250, loss: 0.036643173545598984
step: 260, loss: 0.014744536019861698
step: 270, loss: 0.09111471474170685
step: 280, loss: 0.018209703266620636
step: 290, loss: 0.02563260868191719
step: 300, loss: 0.014415462501347065
step: 310, loss: 0.009613599628210068
step: 320, loss: 0.022913813591003418
step: 330, loss: 0.17612549662590027
step: 340, loss: 0.1250000298023224
step: 350, loss: 0.006128975190222263
step: 360, loss: 0.024674400687217712
step: 370, loss: 0.1287112981081009
step: 380, loss: 0.10703017562627792
step: 390, loss: 0.07379654794931412
step: 400, loss: 0.0799986869096756
step: 410, loss: 0.04009938985109329
step: 420, loss: 0.05388393998146057
step: 430, loss: 0.13077126443386078
step: 440, loss: 0.05909174308180809
step: 450, loss: 0.07198318839073181
step: 460, loss: 0.026991229504346848
step: 470, loss: 0.012625928968191147
step: 480, loss: 0.004782038740813732
step: 490, loss: 0.02579883486032486
step: 500, loss: 0.06700099259614944
step: 510, loss: 0.02392462082207203
step: 520, loss: 0.08235228806734085
step: 530, loss: 0.08315493166446686
step: 540, loss: 0.07574455440044403
step: 550, loss: 0.10274384915828705
step: 560, loss: 0.06279008090496063
step: 570, loss: 0.020628221333026886
step: 580, loss: 0.15856501460075378
step: 590, loss: 0.13385915756225586
step: 600, loss: 0.13800224661827087
step: 610, loss: 0.07792337983846664
step: 620, loss: 0.0577407032251358
step: 630, loss: 0.053292740136384964
step: 640, loss: 0.08781372010707855
step: 650, loss: 0.09720920771360397
step: 660, loss: 0.044297631829977036
step: 670, loss: 0.02053792215883732
step: 680, loss: 0.2125481516122818
step: 690, loss: 0.04314770922064781
step: 700, loss: 0.054971545934677124
step: 710, loss: 0.01955866627395153
step: 720, loss: 0.11168097704648972
step: 730, loss: 0.055308304727077484
step: 740, loss: 0.12241595983505249
step: 750, loss: 0.013676781207323074
step: 760, loss: 0.01681753247976303
step: 770, loss: 0.038015216588974
step: 780, loss: 0.050074558705091476
step: 790, loss: 0.1335916817188263
step: 800, loss: 0.07429340481758118
step: 810, loss: 0.026893869042396545
step: 820, loss: 0.14488831162452698
step: 830, loss: 0.03574540466070175
step: 840, loss: 0.018949298188090324
step: 850, loss: 6.336055230349302e-05
step: 860, loss: 0.21084167063236237
step: 870, loss: 0.13631507754325867
step: 880, loss: 0.19429242610931396
step: 890, loss: 0.0881526991724968
step: 900, loss: 0.05619461089372635
step: 910, loss: 0.16906800866127014
step: 920, loss: 0.31412363052368164
step: 930, loss: 0.025025486946105957
step: 940, loss: 0.05581721290946007
step: 950, loss: 0.06288403272628784
step: 960, loss: 0.12863396108150482
step: 970, loss: 0.037536632269620895
epoch 7: dev_f1=0.9305816135084428, f1=0.9345182413470534, best_f1=0.9381918819188192
step: 0, loss: 0.03667420521378517
step: 10, loss: 0.015547027811408043
step: 20, loss: 0.08033744990825653
step: 30, loss: 0.06973816454410553
step: 40, loss: 0.04357174411416054
step: 50, loss: 0.046535324305295944
step: 60, loss: 0.014921034686267376
step: 70, loss: 0.005334849469363689
step: 80, loss: 0.09214772284030914
step: 90, loss: 0.14134693145751953
step: 100, loss: 0.06849496066570282
step: 110, loss: 0.11440988630056381
step: 120, loss: 0.021957237273454666
step: 130, loss: 0.08129919320344925
step: 140, loss: 0.02166691981256008
step: 150, loss: 0.057189568877220154
step: 160, loss: 0.0624619796872139
step: 170, loss: 0.07442630082368851
step: 180, loss: 0.019025972113013268
step: 190, loss: 0.09199207276105881
step: 200, loss: 0.022476857528090477
step: 210, loss: 0.028819531202316284
step: 220, loss: 0.08488599210977554
step: 230, loss: 0.03957897052168846
step: 240, loss: 0.004356401972472668
step: 250, loss: 0.018236182630062103
step: 260, loss: 0.025954876095056534
step: 270, loss: 0.05388801917433739
step: 280, loss: 2.691062582016457e-05
step: 290, loss: 0.023869575932621956
step: 300, loss: 0.1090020164847374
step: 310, loss: 0.05372538045048714
step: 320, loss: 0.010799386538565159
step: 330, loss: 0.002943409141153097
step: 340, loss: 0.11071214079856873
step: 350, loss: 0.002132242312654853
step: 360, loss: 0.07020122557878494
step: 370, loss: 0.17565768957138062
step: 380, loss: 0.09469282627105713
step: 390, loss: 0.025774603709578514
step: 400, loss: 0.08121791481971741
step: 410, loss: 0.029655585065484047
step: 420, loss: 2.6601530407788232e-05
step: 430, loss: 0.03639139235019684
step: 440, loss: 0.25074678659439087
step: 450, loss: 0.01970316283404827
step: 460, loss: 0.05873200297355652
step: 470, loss: 0.01607315056025982
step: 480, loss: 0.04166505113244057
step: 490, loss: 0.05876311659812927
step: 500, loss: 0.11686913669109344
step: 510, loss: 0.08216133713722229
step: 520, loss: 0.18761858344078064
step: 530, loss: 0.012511387467384338
step: 540, loss: 0.0718943327665329
step: 550, loss: 0.07667125016450882
step: 560, loss: 0.0819578766822815
step: 570, loss: 0.07036386430263519
step: 580, loss: 0.06557635962963104
step: 590, loss: 0.02470523491501808
step: 600, loss: 0.05053078383207321
step: 610, loss: 0.012400851584970951
step: 620, loss: 0.06570864468812943
step: 630, loss: 0.1192253977060318
step: 640, loss: 0.12373829632997513
step: 650, loss: 0.19248606264591217
step: 660, loss: 0.045351542532444
step: 670, loss: 0.13930565118789673
step: 680, loss: 0.1461772918701172
step: 690, loss: 0.05965878441929817
step: 700, loss: 0.023390332236886024
step: 710, loss: 0.3010459840297699
step: 720, loss: 0.05296611040830612
step: 730, loss: 0.018373295664787292
step: 740, loss: 0.03860141336917877
step: 750, loss: 0.0232798233628273
step: 760, loss: 0.017417799681425095
step: 770, loss: 0.059960298240184784
step: 780, loss: 0.06058695912361145
step: 790, loss: 0.129115492105484
step: 800, loss: 0.08615166693925858
step: 810, loss: 0.01209784671664238
step: 820, loss: 0.15671773254871368
step: 830, loss: 0.05525137111544609
step: 840, loss: 0.09031039476394653
step: 850, loss: 0.10612896829843521
step: 860, loss: 0.14248687028884888
step: 870, loss: 0.07441232353448868
step: 880, loss: 0.0005088807665742934
step: 890, loss: 0.00942128337919712
step: 900, loss: 0.09200736880302429
step: 910, loss: 0.0295318141579628
step: 920, loss: 0.07758737355470657
step: 930, loss: 0.024701854214072227
step: 940, loss: 0.0953633114695549
step: 950, loss: 0.01794406585395336
step: 960, loss: 0.1445644199848175
step: 970, loss: 0.013066893443465233
epoch 8: dev_f1=0.934844192634561, f1=0.9304964539007093, best_f1=0.9381918819188192
step: 0, loss: 0.04439428448677063
step: 10, loss: 0.03883449360728264
step: 20, loss: 0.04201798886060715
step: 30, loss: 0.06254108995199203
step: 40, loss: 0.017481781542301178
step: 50, loss: 0.039073396474123
step: 60, loss: 0.00981338694691658
step: 70, loss: 0.08708275854587555
step: 80, loss: 0.03131859749555588
step: 90, loss: 0.02768237143754959
step: 100, loss: 0.011420372873544693
step: 110, loss: 0.11090623587369919
step: 120, loss: 0.03515302389860153
step: 130, loss: 0.04377565160393715
step: 140, loss: 0.07733796536922455
step: 150, loss: 0.01955808885395527
step: 160, loss: 0.06712322682142258
step: 170, loss: 0.13415728509426117
step: 180, loss: 0.09463728964328766
step: 190, loss: 0.06564972549676895
step: 200, loss: 0.11068013310432434
step: 210, loss: 0.016848912462592125
step: 220, loss: 0.016937782987952232
step: 230, loss: 0.06661807745695114
step: 240, loss: 0.052422355860471725
step: 250, loss: 0.03962863236665726
step: 260, loss: 0.015649674460291862
step: 270, loss: 0.011295785196125507
step: 280, loss: 0.11441901326179504
step: 290, loss: 0.07587610185146332
step: 300, loss: 0.053374551236629486
step: 310, loss: 0.0052999830804765224
step: 320, loss: 0.015275700017809868
step: 330, loss: 0.00827401876449585
step: 340, loss: 0.025769641622900963
step: 350, loss: 0.034205362200737
step: 360, loss: 0.06972191482782364
step: 370, loss: 0.02736487239599228
step: 380, loss: 0.1983068436384201
step: 390, loss: 0.21709105372428894
step: 400, loss: 0.04879729077219963
step: 410, loss: 0.010767430067062378
step: 420, loss: 0.09113644808530807
step: 430, loss: 0.053599078208208084
step: 440, loss: 0.09397845715284348
step: 450, loss: 0.011801481246948242
step: 460, loss: 0.008992204442620277
step: 470, loss: 0.02810143306851387
step: 480, loss: 0.033525630831718445
step: 490, loss: 0.0755573958158493
step: 500, loss: 0.08134231716394424
step: 510, loss: 0.01675836369395256
step: 520, loss: 0.10219624638557434
step: 530, loss: 0.10722307860851288
step: 540, loss: 0.004153199028223753
step: 550, loss: 0.033021677285432816
step: 560, loss: 0.157579705119133
step: 570, loss: 0.07941801100969315
step: 580, loss: 0.09366187453269958
step: 590, loss: 0.03415495529770851
step: 600, loss: 0.006401895545423031
step: 610, loss: 2.2269503460847773e-05
step: 620, loss: 0.27099284529685974
step: 630, loss: 0.007413401268422604
step: 640, loss: 0.19676752388477325
step: 650, loss: 0.044391363859176636
step: 660, loss: 0.11784609407186508
step: 670, loss: 0.07223404198884964
step: 680, loss: 0.05981175974011421
step: 690, loss: 0.05937686935067177
step: 700, loss: 0.07211404293775558
step: 710, loss: 0.06399794667959213
step: 720, loss: 0.06525872647762299
step: 730, loss: 0.04656499624252319
step: 740, loss: 0.08218182623386383
step: 750, loss: 0.007174929138273001
step: 760, loss: 0.12098728120326996
step: 770, loss: 0.10607276856899261
step: 780, loss: 0.05662362650036812
step: 790, loss: 0.1072831079363823
step: 800, loss: 0.04740642383694649
step: 810, loss: 0.09000926464796066
step: 820, loss: 0.11884894222021103
step: 830, loss: 0.09358198940753937
step: 840, loss: 0.09948856383562088
step: 850, loss: 0.05616643652319908
step: 860, loss: 0.11812224984169006
step: 870, loss: 0.2541445195674896
step: 880, loss: 0.09677860140800476
step: 890, loss: 0.1480579972267151
step: 900, loss: 0.012914186343550682
step: 910, loss: 0.28907662630081177
step: 920, loss: 0.0160305667668581
step: 930, loss: 0.03855859115719795
step: 940, loss: 0.05622777342796326
step: 950, loss: 0.015428129583597183
step: 960, loss: 0.04749805107712746
step: 970, loss: 0.15132227540016174
epoch 9: dev_f1=0.9347724073205067, f1=0.9334582942830365, best_f1=0.9381918819188192
step: 0, loss: 0.08739233016967773
step: 10, loss: 0.09692592173814774
step: 20, loss: 0.012461472302675247
step: 30, loss: 0.04408348724246025
step: 40, loss: 0.034796491265296936
step: 50, loss: 0.031445518136024475
step: 60, loss: 0.007581300567835569
step: 70, loss: 0.08328229933977127
step: 80, loss: 0.006554717663675547
step: 90, loss: 0.06712708622217178
step: 100, loss: 0.00880659744143486
step: 110, loss: 0.007802195381373167
step: 120, loss: 0.0746150016784668
step: 130, loss: 0.0018013715744018555
step: 140, loss: 0.1269427239894867
step: 150, loss: 0.0181320458650589
step: 160, loss: 0.05488467216491699
step: 170, loss: 0.05727100744843483
step: 180, loss: 0.016098901629447937
step: 190, loss: 0.01821199618279934
step: 200, loss: 0.13510800898075104
step: 210, loss: 0.08696912229061127
step: 220, loss: 0.006264539435505867
step: 230, loss: 0.15199697017669678
step: 240, loss: 0.10584921389818192
step: 250, loss: 0.09398163110017776
step: 260, loss: 0.07710205018520355
step: 270, loss: 0.019506895914673805
step: 280, loss: 0.05258685350418091
step: 290, loss: 0.12018384784460068
step: 300, loss: 0.006448608357459307
step: 310, loss: 0.021528808400034904
step: 320, loss: 0.02483994886279106
step: 330, loss: 0.06894447654485703
step: 340, loss: 0.10355158150196075
step: 350, loss: 0.056842394173145294
step: 360, loss: 0.004907185677438974
step: 370, loss: 0.2152881771326065
step: 380, loss: 0.05973042920231819
step: 390, loss: 0.06465747952461243
step: 400, loss: 0.010935842990875244
step: 410, loss: 0.08148130029439926
step: 420, loss: 0.0907098799943924
step: 430, loss: 0.016870321705937386
step: 440, loss: 0.06815280765295029
step: 450, loss: 0.07351566106081009
step: 460, loss: 0.00916470866650343
step: 470, loss: 0.03737950697541237
step: 480, loss: 0.010678255930542946
step: 490, loss: 0.07355223596096039
step: 500, loss: 0.010554410517215729
step: 510, loss: 0.09391893446445465
step: 520, loss: 0.07917731255292892
step: 530, loss: 0.04521044343709946
step: 540, loss: 0.14508086442947388
step: 550, loss: 0.025583453476428986
step: 560, loss: 0.10529083758592606
step: 570, loss: 0.04494866356253624
step: 580, loss: 0.05795246735215187
step: 590, loss: 0.1101222038269043
step: 600, loss: 0.021558359265327454
step: 610, loss: 0.10945935547351837
step: 620, loss: 0.2006554752588272
step: 630, loss: 0.04784039407968521
step: 640, loss: 0.33483490347862244
step: 650, loss: 0.08628084510564804
step: 660, loss: 0.08643822371959686
step: 670, loss: 0.04661831259727478
step: 680, loss: 0.004617375321686268
step: 690, loss: 0.018386466428637505
step: 700, loss: 0.006921613588929176
step: 710, loss: 0.03063954785466194
step: 720, loss: 0.13058321177959442
step: 730, loss: 0.032582201063632965
step: 740, loss: 0.07672420889139175
step: 750, loss: 0.014523250050842762
step: 760, loss: 0.0653003379702568
step: 770, loss: 0.0963880866765976
step: 780, loss: 0.02126968838274479
step: 790, loss: 0.06647251546382904
step: 800, loss: 0.029482830315828323
step: 810, loss: 0.07885505259037018
step: 820, loss: 0.07528356462717056
step: 830, loss: 0.008280244655907154
step: 840, loss: 0.017308369278907776
step: 850, loss: 0.17522823810577393
step: 860, loss: 0.012119435705244541
step: 870, loss: 0.08178804814815521
step: 880, loss: 0.06393223255872726
step: 890, loss: 0.006682615261524916
step: 900, loss: 0.020934179425239563
step: 910, loss: 0.010926042683422565
step: 920, loss: 0.02418418414890766
step: 930, loss: 5.224574124440551e-05
step: 940, loss: 0.08254344761371613
step: 950, loss: 0.122576043009758
step: 960, loss: 0.06462674587965012
step: 970, loss: 0.01094796136021614
epoch 10: dev_f1=0.9315196998123827, f1=0.9290382819794585, best_f1=0.9381918819188192
step: 0, loss: 0.09693680703639984
step: 10, loss: 0.07556421309709549
step: 20, loss: 0.06788497418165207
step: 30, loss: 0.032183192670345306
step: 40, loss: 0.016749517992138863
step: 50, loss: 0.09686677902936935
step: 60, loss: 0.07374449819326401
step: 70, loss: 0.07617098093032837
step: 80, loss: 0.03882719203829765
step: 90, loss: 0.007949820719659328
step: 100, loss: 0.05664553493261337
step: 110, loss: 0.015080399811267853
step: 120, loss: 0.12755221128463745
step: 130, loss: 0.09339120239019394
step: 140, loss: 0.023040467873215675
step: 150, loss: 0.018445279449224472
step: 160, loss: 0.09655502438545227
step: 170, loss: 0.028242075815796852
step: 180, loss: 0.009261378087103367
step: 190, loss: 0.005403566639870405
step: 200, loss: 0.09621205925941467
step: 210, loss: 0.002749362727627158
step: 220, loss: 0.08092964440584183
step: 230, loss: 0.03456763178110123
step: 240, loss: 0.025093914940953255
step: 250, loss: 0.11163058876991272
step: 260, loss: 0.028741635382175446
step: 270, loss: 0.11966834962368011
step: 280, loss: 0.019761184230446815
step: 290, loss: 0.02265992760658264
step: 300, loss: 0.017792081460356712
step: 310, loss: 0.1738964319229126
step: 320, loss: 0.12394455820322037
step: 330, loss: 0.04575532302260399
step: 340, loss: 0.043844033032655716
step: 350, loss: 0.10929734259843826
step: 360, loss: 0.04604716598987579
step: 370, loss: 0.09663725644350052
step: 380, loss: 0.028547119349241257
step: 390, loss: 0.0673266127705574
step: 400, loss: 0.028481774032115936
step: 410, loss: 0.009771721437573433
step: 420, loss: 0.024520494043827057
step: 430, loss: 0.060256801545619965
step: 440, loss: 0.004864843096584082
step: 450, loss: 0.0013580195372924209
step: 460, loss: 0.03083663247525692
step: 470, loss: 0.02447226271033287
step: 480, loss: 0.14735564589500427
step: 490, loss: 0.09281506389379501
step: 500, loss: 0.010192417539656162
step: 510, loss: 0.01815423183143139
step: 520, loss: 0.07372231036424637
step: 530, loss: 0.0020639728754758835
step: 540, loss: 0.0055410368368029594
step: 550, loss: 0.12163220345973969
step: 560, loss: 0.043717678636312485
step: 570, loss: 0.05011788010597229
step: 580, loss: 0.07253454625606537
step: 590, loss: 0.008748006075620651
step: 600, loss: 0.10040895640850067
step: 610, loss: 0.009295632131397724
step: 620, loss: 0.03133278340101242
step: 630, loss: 0.05311834439635277
step: 640, loss: 0.0526282899081707
step: 650, loss: 0.03200015425682068
step: 660, loss: 0.0018981657922267914
step: 670, loss: 0.1933702826499939
step: 680, loss: 0.06532587856054306
step: 690, loss: 0.04275066405534744
step: 700, loss: 0.10405340790748596
step: 710, loss: 0.0060826074331998825
step: 720, loss: 0.008942781016230583
step: 730, loss: 0.05126676708459854
step: 740, loss: 0.04293595999479294
step: 750, loss: 0.050592292100191116
step: 760, loss: 0.07250745594501495
step: 770, loss: 0.10614065825939178
step: 780, loss: 0.00354177737608552
step: 790, loss: 0.10058020055294037
step: 800, loss: 0.00842529907822609
step: 810, loss: 0.057679928839206696
step: 820, loss: 0.02387748844921589
step: 830, loss: 0.035795845091342926
step: 840, loss: 0.13945230841636658
step: 850, loss: 0.006108814384788275
step: 860, loss: 0.09571186453104019
step: 870, loss: 0.0998033657670021
step: 880, loss: 0.008855546824634075
step: 890, loss: 0.1720622479915619
step: 900, loss: 0.007699314504861832
step: 910, loss: 0.07214103639125824
step: 920, loss: 0.030508916825056076
step: 930, loss: 0.022101372480392456
step: 940, loss: 0.07052706182003021
step: 950, loss: 0.04039619490504265
step: 960, loss: 0.08804415166378021
step: 970, loss: 0.03746325895190239
epoch 11: dev_f1=0.9389454209065681, f1=0.9406307977736549, best_f1=0.9406307977736549
step: 0, loss: 0.1199154332280159
step: 10, loss: 0.12435631453990936
step: 20, loss: 0.02491684816777706
step: 30, loss: 0.037657126784324646
step: 40, loss: 0.004610938485711813
step: 50, loss: 0.0920211598277092
step: 60, loss: 0.13755477964878082
step: 70, loss: 0.059049103409051895
step: 80, loss: 0.03814283385872841
step: 90, loss: 0.09211823344230652
step: 100, loss: 0.017443064600229263
step: 110, loss: 0.014382584020495415
step: 120, loss: 0.03136254474520683
step: 130, loss: 2.5241872208425775e-05
step: 140, loss: 0.08196119964122772
step: 150, loss: 0.04752735793590546
step: 160, loss: 0.057058509439229965
step: 170, loss: 0.014757039956748486
step: 180, loss: 0.010409403592348099
step: 190, loss: 0.11143150925636292
step: 200, loss: 0.00339256739243865
step: 210, loss: 0.06695925444364548
step: 220, loss: 0.13221783936023712
step: 230, loss: 0.07243500649929047
step: 240, loss: 0.016832692548632622
step: 250, loss: 0.03861280903220177
step: 260, loss: 0.10054288059473038
step: 270, loss: 0.06739857792854309
step: 280, loss: 0.007203845307230949
step: 290, loss: 0.055023059248924255
step: 300, loss: 0.05107283964753151
step: 310, loss: 0.06481640785932541
step: 320, loss: 0.043047185987234116
step: 330, loss: 0.008207470178604126
step: 340, loss: 0.10925520211458206
step: 350, loss: 0.0501377135515213
step: 360, loss: 0.06444378197193146
step: 370, loss: 0.0401802696287632
step: 380, loss: 0.05616096034646034
step: 390, loss: 0.013843806460499763
step: 400, loss: 0.07659457623958588
step: 410, loss: 0.05098109319806099
step: 420, loss: 0.0539725124835968
step: 430, loss: 0.03206060081720352
step: 440, loss: 0.043803874403238297
step: 450, loss: 0.01368359848856926
step: 460, loss: 0.04085309058427811
step: 470, loss: 0.034719035029411316
step: 480, loss: 0.027490023523569107
step: 490, loss: 0.018922682851552963
step: 500, loss: 0.055127207189798355
step: 510, loss: 0.07169656455516815
step: 520, loss: 0.07632875442504883
step: 530, loss: 0.1253240406513214
step: 540, loss: 0.029637226834893227
step: 550, loss: 0.04677236080169678
step: 560, loss: 0.02585136704146862
step: 570, loss: 0.25140899419784546
step: 580, loss: 0.011186381801962852
step: 590, loss: 0.07281723618507385
step: 600, loss: 0.03285441920161247
step: 610, loss: 0.019487028941512108
step: 620, loss: 0.050645001232624054
step: 630, loss: 0.07480505108833313
step: 640, loss: 0.051707323640584946
step: 650, loss: 0.026561571285128593
step: 660, loss: 0.03194493055343628
step: 670, loss: 0.17136646807193756
step: 680, loss: 0.040073588490486145
step: 690, loss: 0.0013797833817079663
step: 700, loss: 0.19517721235752106
step: 710, loss: 0.04549003019928932
step: 720, loss: 0.08592380583286285
step: 730, loss: 0.08296288549900055
step: 740, loss: 0.01150742918252945
step: 750, loss: 0.09297265857458115
step: 760, loss: 0.10444703698158264
step: 770, loss: 0.02203643135726452
step: 780, loss: 0.020607762038707733
step: 790, loss: 0.021673424169421196
step: 800, loss: 0.022445926442742348
step: 810, loss: 0.059141334146261215
step: 820, loss: 0.09016919136047363
step: 830, loss: 0.1589716076850891
step: 840, loss: 0.04497954621911049
step: 850, loss: 0.06890606880187988
step: 860, loss: 0.06090664118528366
step: 870, loss: 0.025146596133708954
step: 880, loss: 0.1000765860080719
step: 890, loss: 0.015124132856726646
step: 900, loss: 0.047159597277641296
step: 910, loss: 0.13414990901947021
step: 920, loss: 0.005519135855138302
step: 930, loss: 0.01533950213342905
step: 940, loss: 0.002437870716676116
step: 950, loss: 0.06808492541313171
step: 960, loss: 0.08687890321016312
step: 970, loss: 0.03246358409523964
epoch 12: dev_f1=0.9344106463878328, f1=0.9221213569039657, best_f1=0.9406307977736549
step: 0, loss: 0.02908466011285782
step: 10, loss: 0.031890708953142166
step: 20, loss: 0.003550243563950062
step: 30, loss: 0.005627509206533432
step: 40, loss: 0.008354062214493752
step: 50, loss: 0.11744899302721024
step: 60, loss: 0.0004925067187286913
step: 70, loss: 0.0026467679999768734
step: 80, loss: 0.14303328096866608
step: 90, loss: 0.035142865031957626
step: 100, loss: 0.05332639440894127
step: 110, loss: 0.018709074705839157
step: 120, loss: 0.07602352648973465
step: 130, loss: 0.010352617129683495
step: 140, loss: 0.04305092617869377
step: 150, loss: 0.04814288392663002
step: 160, loss: 0.05334023758769035
step: 170, loss: 0.048334866762161255
step: 180, loss: 0.00592440739274025
step: 190, loss: 0.07892622798681259
step: 200, loss: 0.0846203938126564
step: 210, loss: 0.018391860648989677
step: 220, loss: 0.029760677367448807
step: 230, loss: 0.018425803631544113
step: 240, loss: 0.002669619396328926
step: 250, loss: 0.017507795244455338
step: 260, loss: 0.0831797644495964
step: 270, loss: 0.04813956096768379
step: 280, loss: 0.017360463738441467
step: 290, loss: 0.0732664093375206
step: 300, loss: 0.059831857681274414
step: 310, loss: 0.09491154551506042
step: 320, loss: 0.06920545548200607
step: 330, loss: 0.039601728320121765
step: 340, loss: 0.002350033260881901
step: 350, loss: 0.07502523809671402
step: 360, loss: 0.13031457364559174
step: 370, loss: 0.11535819619894028
step: 380, loss: 0.0003936956054531038
step: 390, loss: 0.012193197384476662
step: 400, loss: 0.019470427185297012
step: 410, loss: 0.024601517245173454
step: 420, loss: 0.04929358512163162
step: 430, loss: 0.019759492948651314
step: 440, loss: 0.0988726019859314
step: 450, loss: 0.06908615678548813
step: 460, loss: 0.014694162644445896
step: 470, loss: 0.009244863875210285
step: 480, loss: 0.012139318510890007
step: 490, loss: 0.022494569420814514
step: 500, loss: 0.07009104639291763
step: 510, loss: 0.043366070836782455
step: 520, loss: 0.12279972434043884
step: 530, loss: 0.04318683594465256
step: 540, loss: 0.05916687101125717
step: 550, loss: 0.0003320409741718322
step: 560, loss: 0.1484900861978531
step: 570, loss: 0.0012502814643085003
step: 580, loss: 0.16248120367527008
step: 590, loss: 0.042962148785591125
step: 600, loss: 0.005905510392040014
step: 610, loss: 0.069350466132164
step: 620, loss: 0.04944795370101929
step: 630, loss: 0.10492551326751709
step: 640, loss: 0.025413496419787407
step: 650, loss: 0.0033190888352692127
step: 660, loss: 0.020966406911611557
step: 670, loss: 0.02908877283334732
step: 680, loss: 0.10505010187625885
step: 690, loss: 0.0033667730167508125
step: 700, loss: 0.06708559393882751
step: 710, loss: 0.061989910900592804
step: 720, loss: 0.06402181833982468
step: 730, loss: 0.004749196581542492
step: 740, loss: 0.03602660074830055
step: 750, loss: 0.012671666219830513
step: 760, loss: 0.035243600606918335
step: 770, loss: 0.010881294496357441
step: 780, loss: 0.014579378068447113
step: 790, loss: 0.014666907489299774
step: 800, loss: 0.0013832290424034
step: 810, loss: 0.06078353524208069
step: 820, loss: 0.056494344025850296
step: 830, loss: 0.15090569853782654
step: 840, loss: 0.13102924823760986
step: 850, loss: 0.03313283994793892
step: 860, loss: 0.011570187285542488
step: 870, loss: 0.003958227578550577
step: 880, loss: 0.12977799773216248
step: 890, loss: 0.11251726001501083
step: 900, loss: 0.04754647612571716
step: 910, loss: 0.1190815344452858
step: 920, loss: 0.021922385320067406
step: 930, loss: 0.21020057797431946
step: 940, loss: 0.00018699129577726126
step: 950, loss: 0.0047105662524700165
step: 960, loss: 0.07280434668064117
step: 970, loss: 0.13591280579566956
epoch 13: dev_f1=0.9375293565054016, f1=0.9216981132075471, best_f1=0.9406307977736549
step: 0, loss: 0.02217220887541771
step: 10, loss: 0.00902328360825777
step: 20, loss: 0.00271712988615036
step: 30, loss: 0.09091052412986755
step: 40, loss: 0.037844907492399216
step: 50, loss: 0.06942576169967651
step: 60, loss: 0.05994591861963272
step: 70, loss: 0.012844284996390343
step: 80, loss: 0.01998610980808735
step: 90, loss: 0.06363590061664581
step: 100, loss: 0.2111167013645172
step: 110, loss: 0.001080223242752254
step: 120, loss: 0.029072239995002747
step: 130, loss: 0.0013142171083018184
step: 140, loss: 0.06606177985668182
step: 150, loss: 0.12162747979164124
step: 160, loss: 0.13569463789463043
step: 170, loss: 0.006179523188620806
step: 180, loss: 0.013050995767116547
step: 190, loss: 0.07130607962608337
step: 200, loss: 0.0010783113539218903
step: 210, loss: 0.031195489689707756
step: 220, loss: 0.03405168280005455
step: 230, loss: 0.004213728476315737
step: 240, loss: 0.05276321992278099
step: 250, loss: 0.06605078279972076
step: 260, loss: 0.048914872109889984
step: 270, loss: 0.0008406159467995167
step: 280, loss: 0.004061580169945955
step: 290, loss: 0.09557613730430603
step: 300, loss: 0.07637522369623184
step: 310, loss: 0.048731766641139984
step: 320, loss: 0.01923931948840618
step: 330, loss: 0.09516719728708267
step: 340, loss: 0.05761856213212013
step: 350, loss: 3.363308496773243e-05
step: 360, loss: 0.047638438642024994
step: 370, loss: 0.05694160982966423
step: 380, loss: 0.03243018686771393
step: 390, loss: 0.039617858827114105
step: 400, loss: 0.08352317661046982
step: 410, loss: 0.016257405281066895
step: 420, loss: 0.041903287172317505
step: 430, loss: 0.02406712993979454
step: 440, loss: 0.12989982962608337
step: 450, loss: 0.024367978796362877
step: 460, loss: 0.024983994662761688
step: 470, loss: 0.02021607756614685
step: 480, loss: 0.019950246438384056
step: 490, loss: 0.05078926682472229
step: 500, loss: 0.0026496360078454018
step: 510, loss: 0.0016724074957892299
step: 520, loss: 0.020967211574316025
step: 530, loss: 0.007658199407160282
step: 540, loss: 0.017222944647073746
step: 550, loss: 0.12502115964889526
step: 560, loss: 0.12793155014514923
step: 570, loss: 0.0855632796883583
step: 580, loss: 0.04964893311262131
step: 590, loss: 0.026794418692588806
step: 600, loss: 0.03081788495182991
step: 610, loss: 0.0032388779800385237
step: 620, loss: 0.10108062624931335
step: 630, loss: 0.09426217526197433
step: 640, loss: 0.023392729461193085
step: 650, loss: 0.0006430386565625668
step: 660, loss: 0.08554819226264954
step: 670, loss: 0.007141480688005686
step: 680, loss: 0.07309003919363022
step: 690, loss: 0.06120957434177399
step: 700, loss: 0.005229305475950241
step: 710, loss: 0.00914472434669733
step: 720, loss: 0.08259407430887222
step: 730, loss: 0.06435627490282059
step: 740, loss: 0.026715563610196114
step: 750, loss: 0.062344759702682495
step: 760, loss: 0.003826864529401064
step: 770, loss: 0.03408430144190788
step: 780, loss: 0.03314432501792908
step: 790, loss: 0.027094628661870956
step: 800, loss: 0.04615597799420357
step: 810, loss: 0.08612736314535141
step: 820, loss: 0.0028076807502657175
step: 830, loss: 0.028394648805260658
step: 840, loss: 0.019602764397859573
step: 850, loss: 0.005478236358612776
step: 860, loss: 0.001558528863824904
step: 870, loss: 0.0527723990380764
step: 880, loss: 0.0973055437207222
step: 890, loss: 0.18831278383731842
step: 900, loss: 0.11234953999519348
step: 910, loss: 0.004396525677293539
step: 920, loss: 0.020993851125240326
step: 930, loss: 0.005406227894127369
step: 940, loss: 0.03223194554448128
step: 950, loss: 0.07842396944761276
step: 960, loss: 0.005620976909995079
step: 970, loss: 0.0020393915474414825
epoch 14: dev_f1=0.9395348837209302, f1=0.9323378441437238, best_f1=0.9323378441437238
step: 0, loss: 0.17121893167495728
step: 10, loss: 0.04544862359762192
step: 20, loss: 0.06126956641674042
step: 30, loss: 0.029454538598656654
step: 40, loss: 0.05818969011306763
step: 50, loss: 0.04413529857993126
step: 60, loss: 0.022843943908810616
step: 70, loss: 0.07875552028417587
step: 80, loss: 0.061154115945100784
step: 90, loss: 0.013100438751280308
step: 100, loss: 0.05438775569200516
step: 110, loss: 0.006135658826678991
step: 120, loss: 0.02864375337958336
step: 130, loss: 0.04492102190852165
step: 140, loss: 0.005474922712892294
step: 150, loss: 0.030611224472522736
step: 160, loss: 0.03064284659922123
step: 170, loss: 0.018012644723057747
step: 180, loss: 0.023559795692563057
step: 190, loss: 0.051495566964149475
step: 200, loss: 0.012111982330679893
step: 210, loss: 0.00035825977101922035
step: 220, loss: 0.013371812179684639
step: 230, loss: 0.002774177584797144
step: 240, loss: 0.034096378833055496
step: 250, loss: 0.0533338226377964
step: 260, loss: 0.002217330504208803
step: 270, loss: 0.05142243951559067
step: 280, loss: 0.0292191281914711
step: 290, loss: 0.03924693167209625
step: 300, loss: 0.04574384540319443
step: 310, loss: 0.01937105320394039
step: 320, loss: 0.05157962441444397
step: 330, loss: 0.02074173465371132
step: 340, loss: 0.015623411163687706
step: 350, loss: 0.0001565413986099884
step: 360, loss: 0.0360577255487442
step: 370, loss: 0.1064651757478714
step: 380, loss: 0.009088624268770218
step: 390, loss: 0.03960944339632988
step: 400, loss: 0.03804951161146164
step: 410, loss: 0.03237227350473404
step: 420, loss: 9.297445649281144e-05
step: 430, loss: 0.03310181573033333
step: 440, loss: 0.021085163578391075
step: 450, loss: 0.11446409672498703
step: 460, loss: 0.01032280083745718
step: 470, loss: 0.008572936058044434
step: 480, loss: 0.04886655882000923
step: 490, loss: 0.06629323214292526
step: 500, loss: 0.04805610328912735
step: 510, loss: 0.10627327859401703
step: 520, loss: 0.003961311653256416
step: 530, loss: 0.037912432104349136
step: 540, loss: 0.052635375410318375
step: 550, loss: 0.040087975561618805
step: 560, loss: 0.040234796702861786
step: 570, loss: 0.005202830769121647
step: 580, loss: 0.00044389069080352783
step: 590, loss: 0.10823540389537811
step: 600, loss: 0.03433989733457565
step: 610, loss: 0.05236783251166344
step: 620, loss: 0.060362059623003006
step: 630, loss: 0.012184097431600094
step: 640, loss: 0.07159747928380966
step: 650, loss: 0.02790505811572075
step: 660, loss: 0.13726644217967987
step: 670, loss: 0.012826170772314072
step: 680, loss: 0.12220162898302078
step: 690, loss: 0.002651256276294589
step: 700, loss: 0.028300028294324875
step: 710, loss: 0.0021355259232223034
step: 720, loss: 0.029987795278429985
step: 730, loss: 0.01093656849116087
step: 740, loss: 0.03329533711075783
step: 750, loss: 0.011704870499670506
step: 760, loss: 0.07902058959007263
step: 770, loss: 0.02342402935028076
step: 780, loss: 0.002739916555583477
step: 790, loss: 0.09165766090154648
step: 800, loss: 0.005304356105625629
step: 810, loss: 0.01844487152993679
step: 820, loss: 0.09090393781661987
step: 830, loss: 0.05060400813817978
step: 840, loss: 0.009454529732465744
step: 850, loss: 0.012153352610766888
step: 860, loss: 0.021236758679151535
step: 870, loss: 0.03199733421206474
step: 880, loss: 0.0007252817740663886
step: 890, loss: 0.010982729494571686
step: 900, loss: 0.047419533133506775
step: 910, loss: 0.0025823544710874557
step: 920, loss: 0.041422050446271896
step: 930, loss: 0.022788964211940765
step: 940, loss: 0.0673731341958046
step: 950, loss: 0.0813169926404953
step: 960, loss: 0.04194043576717377
step: 970, loss: 0.08867616951465607
epoch 15: dev_f1=0.9308755760368663, f1=0.9213069489185457, best_f1=0.9323378441437238
step: 0, loss: 0.047670260071754456
step: 10, loss: 0.0009359550895169377
step: 20, loss: 0.07260248810052872
step: 30, loss: 0.06089240312576294
step: 40, loss: 0.10239171236753464
step: 50, loss: 0.11303135752677917
step: 60, loss: 0.03326328843832016
step: 70, loss: 0.017930520698428154
step: 80, loss: 0.05729798227548599
step: 90, loss: 0.004292558878660202
step: 100, loss: 0.002011249540373683
step: 110, loss: 0.04045287147164345
step: 120, loss: 0.02831687033176422
step: 130, loss: 0.0018342504044994712
step: 140, loss: 0.028682565316557884
step: 150, loss: 0.09535360336303711
step: 160, loss: 0.0029194289818406105
step: 170, loss: 0.040210261940956116
step: 180, loss: 0.10969507694244385
step: 190, loss: 0.015771837905049324
step: 200, loss: 0.011397752910852432
step: 210, loss: 0.009125113487243652
step: 220, loss: 0.0008091359632089734
step: 230, loss: 0.00024629398831166327
step: 240, loss: 0.12193316966295242
step: 250, loss: 0.0017562961438670754
step: 260, loss: 0.02276322804391384
step: 270, loss: 0.00419839471578598
step: 280, loss: 3.688557626446709e-05
step: 290, loss: 0.0004671288770623505
step: 300, loss: 0.10490500926971436
step: 310, loss: 0.1149536594748497
step: 320, loss: 0.006182281766086817
step: 330, loss: 0.05595708638429642
step: 340, loss: 0.07545500248670578
step: 350, loss: 0.11620476841926575
step: 360, loss: 0.02955799177289009
step: 370, loss: 0.04552450776100159
step: 380, loss: 0.008286876603960991
step: 390, loss: 0.00038313568802550435
step: 400, loss: 0.055449966341257095
step: 410, loss: 0.0323936864733696
step: 420, loss: 0.05248848348855972
step: 430, loss: 0.0369110181927681
step: 440, loss: 0.06387404352426529
step: 450, loss: 0.0004381505714263767
step: 460, loss: 0.06502262502908707
step: 470, loss: 0.003277683397755027
step: 480, loss: 0.020044824108481407
step: 490, loss: 0.17212779819965363
step: 500, loss: 0.013395514339208603
step: 510, loss: 0.031193789094686508
step: 520, loss: 0.022023897618055344
step: 530, loss: 0.03831196948885918
step: 540, loss: 0.029540415853261948
step: 550, loss: 0.0799916461110115
step: 560, loss: 0.09889692068099976
step: 570, loss: 0.06804942339658737
step: 580, loss: 0.08153822273015976
step: 590, loss: 0.07726918160915375
step: 600, loss: 0.05263182520866394
step: 610, loss: 0.22761563956737518
step: 620, loss: 0.00012190259440103546
step: 630, loss: 0.028125084936618805
step: 640, loss: 0.04493928700685501
step: 650, loss: 0.049617279320955276
step: 660, loss: 0.07774153351783752
step: 670, loss: 0.046263571828603745
step: 680, loss: 0.030407605692744255
step: 690, loss: 0.04559160768985748
step: 700, loss: 0.014698333106935024
step: 710, loss: 0.01096281222999096
step: 720, loss: 0.029356563463807106
step: 730, loss: 0.0035242459271103144
step: 740, loss: 0.0363602414727211
step: 750, loss: 0.03199319541454315
step: 760, loss: 0.03147101402282715
step: 770, loss: 0.026502203196287155
step: 780, loss: 0.10744737833738327
step: 790, loss: 0.10043291747570038
step: 800, loss: 0.03911222517490387
step: 810, loss: 0.06754487007856369
step: 820, loss: 4.2016989027615637e-05
step: 830, loss: 0.027062460780143738
step: 840, loss: 0.028071025386452675
step: 850, loss: 0.056728657335042953
step: 860, loss: 0.05638933181762695
step: 870, loss: 0.00010251584171783179
step: 880, loss: 0.057553526014089584
step: 890, loss: 0.008099548518657684
step: 900, loss: 0.041049543768167496
step: 910, loss: 0.02647264301776886
step: 920, loss: 0.08914314210414886
step: 930, loss: 0.048071082681417465
step: 940, loss: 0.057957831770181656
step: 950, loss: 0.0033011557534337044
step: 960, loss: 0.029496440663933754
step: 970, loss: 0.06967388838529587
epoch 16: dev_f1=0.935771214252227, f1=0.9300797747536368, best_f1=0.9323378441437238
step: 0, loss: 0.053232695907354355
step: 10, loss: 0.01943904720246792
step: 20, loss: 0.032978713512420654
step: 30, loss: 0.0002961830759886652
step: 40, loss: 0.01900102011859417
step: 50, loss: 0.03703804314136505
step: 60, loss: 0.06293133646249771
step: 70, loss: 0.16948223114013672
step: 80, loss: 0.038786400109529495
step: 90, loss: 0.0681791827082634
step: 100, loss: 0.0064320191740989685
step: 110, loss: 0.0005676496657542884
step: 120, loss: 0.00045105625758878887
step: 130, loss: 0.00014186868793331087
step: 140, loss: 0.0016152303433045745
step: 150, loss: 0.01936626248061657
step: 160, loss: 0.03934262692928314
step: 170, loss: 0.0021967333741486073
step: 180, loss: 0.05377836152911186
step: 190, loss: 0.00029319696477614343
step: 200, loss: 0.06409752368927002
step: 210, loss: 0.021688617765903473
step: 220, loss: 0.05869075655937195
step: 230, loss: 0.019483067095279694
step: 240, loss: 0.029919223859906197
step: 250, loss: 0.0665934756398201
step: 260, loss: 0.002072365256026387
step: 270, loss: 0.028271399438381195
step: 280, loss: 0.023573359474539757
step: 290, loss: 0.04296734556555748
step: 300, loss: 0.0215716902166605
step: 310, loss: 0.06795230507850647
step: 320, loss: 0.028417587280273438
step: 330, loss: 0.027743149548768997
step: 340, loss: 0.03374111279845238
step: 350, loss: 0.00045180911547504365
step: 360, loss: 0.02484561875462532
step: 370, loss: 0.04494016245007515
step: 380, loss: 0.0028831837698817253
step: 390, loss: 0.0010901442728936672
step: 400, loss: 0.02004080079495907
step: 410, loss: 0.025161074474453926
step: 420, loss: 0.00021837823442183435
step: 430, loss: 0.028154028579592705
step: 440, loss: 0.010481937788426876
step: 450, loss: 0.00031749275512993336
step: 460, loss: 0.04938066005706787
step: 470, loss: 0.03576164320111275
step: 480, loss: 0.039324499666690826
step: 490, loss: 0.07236919552087784
step: 500, loss: 0.0599551722407341
step: 510, loss: 0.021959446370601654
step: 520, loss: 0.07192612439393997
step: 530, loss: 0.0003200483915861696
step: 540, loss: 0.009267582558095455
step: 550, loss: 0.056690480560064316
step: 560, loss: 0.016909241676330566
step: 570, loss: 0.016976002603769302
step: 580, loss: 0.03025197423994541
step: 590, loss: 0.07212800532579422
step: 600, loss: 0.08868997544050217
step: 610, loss: 0.048696327954530716
step: 620, loss: 0.009330380707979202
step: 630, loss: 0.09025871008634567
step: 640, loss: 0.026812376454472542
step: 650, loss: 0.03409016504883766
step: 660, loss: 0.0361151248216629
step: 670, loss: 0.00029914587503299117
step: 680, loss: 0.03801988437771797
step: 690, loss: 0.1995253562927246
step: 700, loss: 1.0359976840845775e-05
step: 710, loss: 0.0019108951091766357
step: 720, loss: 0.020092248916625977
step: 730, loss: 0.035815685987472534
step: 740, loss: 0.0005720623885281384
step: 750, loss: 0.03874815255403519
step: 760, loss: 0.07245655357837677
step: 770, loss: 0.017926502972841263
step: 780, loss: 9.714492625789717e-05
step: 790, loss: 0.0001194229771499522
step: 800, loss: 0.048029981553554535
step: 810, loss: 0.01675104908645153
step: 820, loss: 0.07798760384321213
step: 830, loss: 0.03667129948735237
step: 840, loss: 0.022875767201185226
step: 850, loss: 0.035221025347709656
step: 860, loss: 0.0601581409573555
step: 870, loss: 0.03079107217490673
step: 880, loss: 0.009631821885704994
step: 890, loss: 0.05124859884381294
step: 900, loss: 0.02761409804224968
step: 910, loss: 0.029614068567752838
step: 920, loss: 0.0871027261018753
step: 930, loss: 0.04199354350566864
step: 940, loss: 0.04592613875865936
step: 950, loss: 0.1082226112484932
step: 960, loss: 0.06545546650886536
step: 970, loss: 0.00023649336071684957
epoch 17: dev_f1=0.9364269141531322, f1=0.9262865090403337, best_f1=0.9323378441437238
step: 0, loss: 0.07752076536417007
step: 10, loss: 0.015436369925737381
step: 20, loss: 0.05100305378437042
step: 30, loss: 0.033365990966558456
step: 40, loss: 0.02782234363257885
step: 50, loss: 0.043655604124069214
step: 60, loss: 0.02233966439962387
step: 70, loss: 0.00012179363693576306
step: 80, loss: 0.029511544853448868
step: 90, loss: 0.03577994927763939
step: 100, loss: 0.05733072757720947
step: 110, loss: 0.023571142926812172
step: 120, loss: 0.011073851957917213
step: 130, loss: 0.021430496126413345
step: 140, loss: 1.5586141671519727e-05
step: 150, loss: 0.04331837221980095
step: 160, loss: 0.023519689217209816
step: 170, loss: 0.02280449867248535
step: 180, loss: 0.03306664153933525
step: 190, loss: 0.01651761680841446
step: 200, loss: 0.07612693309783936
step: 210, loss: 0.04747069627046585
step: 220, loss: 0.05329564958810806
step: 230, loss: 0.06512875854969025
step: 240, loss: 0.0314369723200798
step: 250, loss: 5.27565207448788e-05
step: 260, loss: 0.026864323765039444
step: 270, loss: 0.03640437871217728
step: 280, loss: 0.020566320046782494
step: 290, loss: 0.10157784074544907
step: 300, loss: 0.02601577714085579
step: 310, loss: 0.011084229685366154
step: 320, loss: 0.024585338309407234
step: 330, loss: 0.04614397510886192
step: 340, loss: 0.04377220571041107
step: 350, loss: 0.039855048060417175
step: 360, loss: 0.000221277674427256
step: 370, loss: 2.484897049725987e-05
step: 380, loss: 0.04406508803367615
step: 390, loss: 0.0474773570895195
step: 400, loss: 0.021818989887833595
step: 410, loss: 0.00024914139066822827
step: 420, loss: 0.07726392149925232
step: 430, loss: 0.06434010714292526
step: 440, loss: 0.04006520286202431
step: 450, loss: 0.17474940419197083
step: 460, loss: 0.048545558005571365
step: 470, loss: 0.0001541117817396298
step: 480, loss: 0.0005661673494614661
step: 490, loss: 0.000997699680738151
step: 500, loss: 0.03827555105090141
step: 510, loss: 0.02407962456345558
step: 520, loss: 0.05013461410999298
step: 530, loss: 0.07947810739278793
step: 540, loss: 0.051660314202308655
step: 550, loss: 7.599854870932177e-05
step: 560, loss: 0.04360637813806534
step: 570, loss: 0.022257711738348007
step: 580, loss: 6.360079714795575e-05
step: 590, loss: 0.03946644067764282
step: 600, loss: 9.905494152917527e-06
step: 610, loss: 0.11823827773332596
step: 620, loss: 0.02902800962328911
step: 630, loss: 0.05487104132771492
step: 640, loss: 0.06211146339774132
step: 650, loss: 0.01897342875599861
step: 660, loss: 0.07066694647073746
step: 670, loss: 0.026290658861398697
step: 680, loss: 0.011245351284742355
step: 690, loss: 0.051400378346443176
step: 700, loss: 6.325887807179242e-05
step: 710, loss: 0.0008547024917788804
step: 720, loss: 0.05105782672762871
step: 730, loss: 0.0001473400043323636
step: 740, loss: 3.979319808422588e-05
step: 750, loss: 0.0007123348768800497
step: 760, loss: 0.020337339490652084
step: 770, loss: 0.021711943671107292
step: 780, loss: 0.021249229088425636
step: 790, loss: 0.03569503873586655
step: 800, loss: 0.008755053393542767
step: 810, loss: 0.0708930566906929
step: 820, loss: 0.061951279640197754
step: 830, loss: 0.004134008660912514
step: 840, loss: 0.001087593613192439
step: 850, loss: 0.01768748089671135
step: 860, loss: 0.046609994024038315
step: 870, loss: 0.026329921558499336
step: 880, loss: 0.014223598875105381
step: 890, loss: 0.0020155785605311394
step: 900, loss: 0.022553976625204086
step: 910, loss: 0.06879299879074097
step: 920, loss: 0.02785317786037922
step: 930, loss: 0.06597361713647842
step: 940, loss: 0.02230222336947918
step: 950, loss: 0.05030594393610954
step: 960, loss: 0.02720028907060623
step: 970, loss: 0.03523177653551102
epoch 18: dev_f1=0.9356779268857011, f1=0.9230055658627088, best_f1=0.9323378441437238
step: 0, loss: 0.04778503626585007
step: 10, loss: 0.053591370582580566
step: 20, loss: 0.0008451956673525274
step: 30, loss: 0.00023073166084941477
step: 40, loss: 0.01274208165705204
step: 50, loss: 0.07027819752693176
step: 60, loss: 0.026760263368487358
step: 70, loss: 0.03250476345419884
step: 80, loss: 0.02041585184633732
step: 90, loss: 0.018533896654844284
step: 100, loss: 8.773841545917094e-05
step: 110, loss: 0.030650610104203224
step: 120, loss: 0.023980656638741493
step: 130, loss: 8.521154813934118e-05
step: 140, loss: 0.03986268490552902
step: 150, loss: 0.03197597712278366
step: 160, loss: 0.016977693885564804
step: 170, loss: 9.80685799731873e-05
step: 180, loss: 0.03551715239882469
step: 190, loss: 0.006909148767590523
step: 200, loss: 5.507927562575787e-05
step: 210, loss: 0.08050667494535446
step: 220, loss: 0.022468682378530502
step: 230, loss: 1.783213701855857e-05
step: 240, loss: 0.046589575707912445
step: 250, loss: 0.035780150443315506
step: 260, loss: 0.028543364256620407
step: 270, loss: 0.01738124154508114
step: 280, loss: 0.041584085673093796
step: 290, loss: 0.0007434687577188015
step: 300, loss: 0.09288337826728821
step: 310, loss: 0.06864821165800095
step: 320, loss: 0.057806871831417084
step: 330, loss: 4.4772314140573144e-05
step: 340, loss: 0.0007429110119119287
step: 350, loss: 0.01789141073822975
step: 360, loss: 0.03893915191292763
step: 370, loss: 0.0021338060032576323
step: 380, loss: 0.0015548650408163667
step: 390, loss: 0.019388344138860703
step: 400, loss: 0.02485569752752781
step: 410, loss: 0.02696092799305916
step: 420, loss: 0.050433650612831116
step: 430, loss: 0.04885571822524071
step: 440, loss: 0.005714384838938713
step: 450, loss: 0.018505509942770004
step: 460, loss: 0.019139716401696205
step: 470, loss: 0.04516042396426201
step: 480, loss: 0.012197581119835377
step: 490, loss: 0.005159077234566212
step: 500, loss: 0.004497872665524483
step: 510, loss: 0.05749378353357315
step: 520, loss: 0.005071870982646942
step: 530, loss: 0.017799610272049904
step: 540, loss: 0.02942199632525444
step: 550, loss: 0.032877691090106964
step: 560, loss: 0.00010781540913740173
step: 570, loss: 1.4792884030612186e-05
step: 580, loss: 0.04680465906858444
step: 590, loss: 0.00013316154945641756
step: 600, loss: 0.07881812751293182
step: 610, loss: 0.028208011761307716
step: 620, loss: 4.1445055103395134e-05
step: 630, loss: 0.0626402348279953
step: 640, loss: 0.019434750080108643
step: 650, loss: 0.020794648677110672
step: 660, loss: 0.04095195606350899
step: 670, loss: 8.566233009332791e-05
step: 680, loss: 0.03495704010128975
step: 690, loss: 0.03696662560105324
step: 700, loss: 0.0057504852302372456
step: 710, loss: 0.02218262292444706
step: 720, loss: 5.501443229150027e-05
step: 730, loss: 0.040444448590278625
step: 740, loss: 0.00017550878692418337
step: 750, loss: 6.297770596574992e-05
step: 760, loss: 0.028192633762955666
step: 770, loss: 0.05318562313914299
step: 780, loss: 0.04357564076781273
step: 790, loss: 0.0001355899585178122
step: 800, loss: 0.04933774098753929
step: 810, loss: 0.0011644478654488921
step: 820, loss: 0.020429445430636406
step: 830, loss: 0.017551522701978683
step: 840, loss: 0.02311193384230137
step: 850, loss: 0.030294818803668022
step: 860, loss: 0.02461126819252968
step: 870, loss: 0.0570761077105999
step: 880, loss: 0.017747247591614723
step: 890, loss: 0.02729964628815651
step: 900, loss: 0.013011873699724674
step: 910, loss: 0.02528313547372818
step: 920, loss: 0.03614006191492081
step: 930, loss: 0.08596104383468628
step: 940, loss: 0.04594850912690163
step: 950, loss: 0.020416269078850746
step: 960, loss: 0.040794458240270615
step: 970, loss: 0.00021910019859205931
epoch 19: dev_f1=0.936269915651359, f1=0.923728813559322, best_f1=0.9323378441437238
step: 0, loss: 0.00047393463319167495
step: 10, loss: 0.0173412524163723
step: 20, loss: 0.00010582957474980503
step: 30, loss: 0.0003687033022288233
step: 40, loss: 0.026046311482787132
step: 50, loss: 0.04350714385509491
step: 60, loss: 0.08898352086544037
step: 70, loss: 0.04142456874251366
step: 80, loss: 5.110531492391601e-05
step: 90, loss: 0.00016133813187479973
step: 100, loss: 0.0008247201330959797
step: 110, loss: 1.4561770512955263e-05
step: 120, loss: 2.160472286050208e-05
step: 130, loss: 0.019627783447504044
step: 140, loss: 0.017015444114804268
step: 150, loss: 0.018870657309889793
step: 160, loss: 0.019674748182296753
step: 170, loss: 0.032885096967220306
step: 180, loss: 0.020418290048837662
step: 190, loss: 0.09813659638166428
step: 200, loss: 0.018472906202077866
step: 210, loss: 0.0010616544168442488
step: 220, loss: 0.04219674691557884
step: 230, loss: 0.12144772708415985
step: 240, loss: 0.0003411241341382265
step: 250, loss: 0.03405877575278282
step: 260, loss: 0.005086618009954691
step: 270, loss: 0.018540626391768456
step: 280, loss: 0.03596982732415199
step: 290, loss: 0.020833954215049744
step: 300, loss: 0.00682836351916194
step: 310, loss: 3.723962072399445e-05
step: 320, loss: 0.09432045370340347
step: 330, loss: 0.08201168477535248
step: 340, loss: 0.0210505910217762
step: 350, loss: 0.022938763722777367
step: 360, loss: 0.05787450075149536
step: 370, loss: 0.08173912763595581
step: 380, loss: 0.030331401154398918
step: 390, loss: 0.016147514805197716
step: 400, loss: 0.034351322799921036
step: 410, loss: 0.07623907178640366
step: 420, loss: 0.058664705604314804
step: 430, loss: 0.02264234609901905
step: 440, loss: 0.017622044309973717
step: 450, loss: 0.011579878628253937
step: 460, loss: 7.349113002419472e-05
step: 470, loss: 0.029614202678203583
step: 480, loss: 0.023780563846230507
step: 490, loss: 0.03949643298983574
step: 500, loss: 0.006958548445254564
step: 510, loss: 0.032569315284490585
step: 520, loss: 0.02756141498684883
step: 530, loss: 0.02316710352897644
step: 540, loss: 0.005328082479536533
step: 550, loss: 0.02956441231071949
step: 560, loss: 7.996488420758396e-05
step: 570, loss: 0.013047030195593834
step: 580, loss: 0.01960219070315361
step: 590, loss: 0.019306953996419907
step: 600, loss: 0.021536918357014656
step: 610, loss: 0.05412221699953079
step: 620, loss: 0.04307350516319275
step: 630, loss: 0.023215629160404205
step: 640, loss: 0.056670140475034714
step: 650, loss: 0.005703720264136791
step: 660, loss: 0.08641517907381058
step: 670, loss: 0.02220584638416767
step: 680, loss: 0.021319342777132988
step: 690, loss: 0.004792560823261738
step: 700, loss: 0.050850432366132736
step: 710, loss: 0.02353738434612751
step: 720, loss: 0.0001143719200626947
step: 730, loss: 0.02721688151359558
step: 740, loss: 0.08405792713165283
step: 750, loss: 0.06744436919689178
step: 760, loss: 0.0003657831985037774
step: 770, loss: 0.0001407832169206813
step: 780, loss: 0.034945711493492126
step: 790, loss: 0.04352466017007828
step: 800, loss: 8.657108264742419e-05
step: 810, loss: 0.12212461233139038
step: 820, loss: 0.07934223115444183
step: 830, loss: 0.02449478581547737
step: 840, loss: 0.010955044999718666
step: 850, loss: 0.0002984669990837574
step: 860, loss: 0.0389474555850029
step: 870, loss: 0.04961901530623436
step: 880, loss: 0.020572856068611145
step: 890, loss: 0.01879223622381687
step: 900, loss: 0.06053600832819939
step: 910, loss: 0.0021181656047701836
step: 920, loss: 0.022281751036643982
step: 930, loss: 0.01685079000890255
step: 940, loss: 0.00014470118912868202
step: 950, loss: 0.01870603859424591
step: 960, loss: 0.02651309221982956
step: 970, loss: 0.01696857437491417
epoch 20: dev_f1=0.9366494603472549, f1=0.924020764511562, best_f1=0.9323378441437238
