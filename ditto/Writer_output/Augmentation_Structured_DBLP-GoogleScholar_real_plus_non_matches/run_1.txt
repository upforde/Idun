cuda
Device: cuda
step: 0, loss: 0.9419975876808167
step: 10, loss: 0.28803467750549316
step: 20, loss: 0.5694833397865295
step: 30, loss: 0.37875425815582275
step: 40, loss: 0.3071836531162262
step: 50, loss: 0.3076215982437134
step: 60, loss: 0.20186299085617065
step: 70, loss: 0.16119666397571564
step: 80, loss: 0.28934985399246216
step: 90, loss: 0.20872728526592255
step: 100, loss: 0.2760513424873352
step: 110, loss: 0.27518728375434875
step: 120, loss: 0.25822994112968445
step: 130, loss: 0.10185004770755768
step: 140, loss: 0.05720387026667595
step: 150, loss: 0.057598985731601715
step: 160, loss: 0.38131582736968994
step: 170, loss: 0.09676571935415268
step: 180, loss: 0.20356756448745728
step: 190, loss: 0.12087742984294891
step: 200, loss: 0.15806743502616882
step: 210, loss: 0.08167154341936111
step: 220, loss: 0.13295868039131165
step: 230, loss: 0.12190158665180206
step: 240, loss: 0.07367035001516342
step: 250, loss: 0.07233632355928421
step: 260, loss: 0.13162560760974884
step: 270, loss: 0.16334649920463562
step: 280, loss: 0.29134702682495117
step: 290, loss: 0.07911475747823715
step: 300, loss: 0.1290305256843567
step: 310, loss: 0.07582691311836243
step: 320, loss: 0.12335991114377975
step: 330, loss: 0.1466124951839447
step: 340, loss: 0.1873244345188141
step: 350, loss: 0.1857331097126007
step: 360, loss: 0.2595731317996979
step: 370, loss: 0.05947485938668251
step: 380, loss: 0.22052378952503204
step: 390, loss: 0.09432815760374069
step: 400, loss: 0.0761018693447113
step: 410, loss: 0.11753527075052261
step: 420, loss: 0.07760527729988098
step: 430, loss: 0.05317153409123421
step: 440, loss: 0.1404183804988861
step: 450, loss: 0.07498904317617416
step: 460, loss: 0.0679965615272522
step: 470, loss: 0.05563626438379288
step: 480, loss: 0.18819236755371094
step: 490, loss: 0.12231777608394623
step: 500, loss: 0.06898712366819382
step: 510, loss: 0.1827852874994278
step: 520, loss: 0.20436790585517883
step: 530, loss: 0.16571372747421265
step: 540, loss: 0.08420950919389725
step: 550, loss: 0.1719619631767273
step: 560, loss: 0.05523215979337692
step: 570, loss: 0.11537696421146393
step: 580, loss: 0.1579849272966385
step: 590, loss: 0.12005207687616348
step: 600, loss: 0.12816794216632843
step: 610, loss: 0.2748972475528717
step: 620, loss: 0.08540105819702148
step: 630, loss: 0.1619630753993988
step: 640, loss: 0.1333806812763214
step: 650, loss: 0.10760309547185898
step: 660, loss: 0.08604249358177185
step: 670, loss: 0.179362490773201
step: 680, loss: 0.11775606870651245
step: 690, loss: 0.15750226378440857
step: 700, loss: 0.11347325146198273
step: 710, loss: 0.12724733352661133
step: 720, loss: 0.04470665380358696
step: 730, loss: 0.05752287060022354
step: 740, loss: 0.055318914353847504
step: 750, loss: 0.23258543014526367
step: 760, loss: 0.09257790446281433
step: 770, loss: 0.041970983147621155
step: 780, loss: 0.09990996867418289
step: 790, loss: 0.10817429423332214
step: 800, loss: 0.10490649193525314
step: 810, loss: 0.13007216155529022
step: 820, loss: 0.05957327410578728
step: 830, loss: 0.10437794029712677
step: 840, loss: 0.13390174508094788
step: 850, loss: 0.09920112788677216
step: 860, loss: 0.11651278287172318
step: 870, loss: 0.046701282262802124
step: 880, loss: 0.035156868398189545
step: 890, loss: 0.09202584624290466
step: 900, loss: 0.06341008841991425
step: 910, loss: 0.061711158603429794
step: 920, loss: 0.1906355768442154
step: 930, loss: 0.0878811776638031
step: 940, loss: 0.13932812213897705
step: 950, loss: 0.06299815326929092
step: 960, loss: 0.09899783879518509
step: 970, loss: 0.2007659673690796
epoch 1: dev_f1=0.9264909847434121, f1=0.9234296194406236, best_f1=0.9234296194406236
step: 0, loss: 0.035362232476472855
step: 10, loss: 0.11734214425086975
step: 20, loss: 0.013578011654317379
step: 30, loss: 0.09942373633384705
step: 40, loss: 0.046798426657915115
step: 50, loss: 0.12969566881656647
step: 60, loss: 0.03715398907661438
step: 70, loss: 0.03646529093384743
step: 80, loss: 0.0420367494225502
step: 90, loss: 0.13641369342803955
step: 100, loss: 0.14834804832935333
step: 110, loss: 0.11334477365016937
step: 120, loss: 0.09163364768028259
step: 130, loss: 0.23055563867092133
step: 140, loss: 0.12787817418575287
step: 150, loss: 0.031244700774550438
step: 160, loss: 0.07192734628915787
step: 170, loss: 0.16477543115615845
step: 180, loss: 0.08116330951452255
step: 190, loss: 0.18549670279026031
step: 200, loss: 0.0773930698633194
step: 210, loss: 0.15487462282180786
step: 220, loss: 0.09247366338968277
step: 230, loss: 0.043654028326272964
step: 240, loss: 0.07303997129201889
step: 250, loss: 0.047104623168706894
step: 260, loss: 0.08865813165903091
step: 270, loss: 0.018639864400029182
step: 280, loss: 0.14395050704479218
step: 290, loss: 0.14513641595840454
step: 300, loss: 0.09623623639345169
step: 310, loss: 0.057389479130506516
step: 320, loss: 0.07421822100877762
step: 330, loss: 0.0888705775141716
step: 340, loss: 0.08986619859933853
step: 350, loss: 0.046878162771463394
step: 360, loss: 0.07593626528978348
step: 370, loss: 0.18280640244483948
step: 380, loss: 0.0945224016904831
step: 390, loss: 0.07992283999919891
step: 400, loss: 0.06792356073856354
step: 410, loss: 0.07746671140193939
step: 420, loss: 0.03320783004164696
step: 430, loss: 0.10898078978061676
step: 440, loss: 0.09773236513137817
step: 450, loss: 0.14141610264778137
step: 460, loss: 0.06885138154029846
step: 470, loss: 0.2269594669342041
step: 480, loss: 0.03898172825574875
step: 490, loss: 0.02277008816599846
step: 500, loss: 0.06785441190004349
step: 510, loss: 0.008509565144777298
step: 520, loss: 0.05824921280145645
step: 530, loss: 0.22031019628047943
step: 540, loss: 0.09998665004968643
step: 550, loss: 0.11884915083646774
step: 560, loss: 0.09172860532999039
step: 570, loss: 0.09528001397848129
step: 580, loss: 0.06866420060396194
step: 590, loss: 0.010544203221797943
step: 600, loss: 0.11084511131048203
step: 610, loss: 0.06123855710029602
step: 620, loss: 0.1024765893816948
step: 630, loss: 0.17200469970703125
step: 640, loss: 0.0013181399554014206
step: 650, loss: 0.03488990664482117
step: 660, loss: 0.014203988015651703
step: 670, loss: 0.19834394752979279
step: 680, loss: 0.08358771353960037
step: 690, loss: 0.07171101123094559
step: 700, loss: 0.09027329832315445
step: 710, loss: 0.058522630482912064
step: 720, loss: 0.0348748080432415
step: 730, loss: 0.01718100532889366
step: 740, loss: 0.12234601378440857
step: 750, loss: 0.18247665464878082
step: 760, loss: 0.24058414995670319
step: 770, loss: 0.029789254069328308
step: 780, loss: 0.26433393359184265
step: 790, loss: 0.04470643401145935
step: 800, loss: 0.10858334600925446
step: 810, loss: 0.07190683484077454
step: 820, loss: 0.20722419023513794
step: 830, loss: 0.008341573178768158
step: 840, loss: 0.09805824607610703
step: 850, loss: 0.22609098255634308
step: 860, loss: 0.03319339454174042
step: 870, loss: 0.12101703882217407
step: 880, loss: 0.09361738711595535
step: 890, loss: 0.22163750231266022
step: 900, loss: 0.14115405082702637
step: 910, loss: 0.05715487152338028
step: 920, loss: 0.08976283669471741
step: 930, loss: 0.09209863841533661
step: 940, loss: 0.11861273646354675
step: 950, loss: 0.10862763971090317
step: 960, loss: 0.0847340077161789
step: 970, loss: 0.07954475283622742
epoch 2: dev_f1=0.9206349206349206, f1=0.9189678587596197, best_f1=0.9234296194406236
step: 0, loss: 0.0719691812992096
step: 10, loss: 0.21477454900741577
step: 20, loss: 0.2204311490058899
step: 30, loss: 0.07377329468727112
step: 40, loss: 0.015933150425553322
step: 50, loss: 0.21842126548290253
step: 60, loss: 0.11256686598062515
step: 70, loss: 0.09142199903726578
step: 80, loss: 0.10079589486122131
step: 90, loss: 0.09182360023260117
step: 100, loss: 0.17583909630775452
step: 110, loss: 0.00619893241673708
step: 120, loss: 0.056974004954099655
step: 130, loss: 0.06879997998476028
step: 140, loss: 0.03520965948700905
step: 150, loss: 0.03814462944865227
step: 160, loss: 0.03005036525428295
step: 170, loss: 0.03332772105932236
step: 180, loss: 0.0797441303730011
step: 190, loss: 0.04460334777832031
step: 200, loss: 0.09749334305524826
step: 210, loss: 0.18195992708206177
step: 220, loss: 0.018241826444864273
step: 230, loss: 0.03693205490708351
step: 240, loss: 0.038075197488069534
step: 250, loss: 0.12746916711330414
step: 260, loss: 0.051195528358221054
step: 270, loss: 0.14502441883087158
step: 280, loss: 0.10934071987867355
step: 290, loss: 0.06615784019231796
step: 300, loss: 0.01543620228767395
step: 310, loss: 0.26451772451400757
step: 320, loss: 0.00498218322172761
step: 330, loss: 0.03906961530447006
step: 340, loss: 0.033781636506319046
step: 350, loss: 0.059622328728437424
step: 360, loss: 0.06902267038822174
step: 370, loss: 0.11434521526098251
step: 380, loss: 0.2611551582813263
step: 390, loss: 0.03088950365781784
step: 400, loss: 0.03321748599410057
step: 410, loss: 0.1300238072872162
step: 420, loss: 0.13680224120616913
step: 430, loss: 0.0907554030418396
step: 440, loss: 0.20287251472473145
step: 450, loss: 0.056285370141267776
step: 460, loss: 0.14269448816776276
step: 470, loss: 0.12662029266357422
step: 480, loss: 0.05501319468021393
step: 490, loss: 0.1326518952846527
step: 500, loss: 0.05407340079545975
step: 510, loss: 0.12706373631954193
step: 520, loss: 0.12397914379835129
step: 530, loss: 0.03293980285525322
step: 540, loss: 0.01589757576584816
step: 550, loss: 0.11871009320020676
step: 560, loss: 0.10259425640106201
step: 570, loss: 0.054975029081106186
step: 580, loss: 0.048945195972919464
step: 590, loss: 0.15548191964626312
step: 600, loss: 0.05190281569957733
step: 610, loss: 0.10019940137863159
step: 620, loss: 0.021805763244628906
step: 630, loss: 0.05202241614460945
step: 640, loss: 0.0835825577378273
step: 650, loss: 0.09057436138391495
step: 660, loss: 0.03934088721871376
step: 670, loss: 0.02512470819056034
step: 680, loss: 0.08309539407491684
step: 690, loss: 0.022698916494846344
step: 700, loss: 0.01872050017118454
step: 710, loss: 0.04539484903216362
step: 720, loss: 0.02707419916987419
step: 730, loss: 0.04195450618863106
step: 740, loss: 0.09130948036909103
step: 750, loss: 0.07947573810815811
step: 760, loss: 0.07340385764837265
step: 770, loss: 0.09394259005784988
step: 780, loss: 0.16296827793121338
step: 790, loss: 0.0757327452301979
step: 800, loss: 0.00839478150010109
step: 810, loss: 0.2435532510280609
step: 820, loss: 0.09299279004335403
step: 830, loss: 0.07870137691497803
step: 840, loss: 0.1386842280626297
step: 850, loss: 0.05989537760615349
step: 860, loss: 0.07493915408849716
step: 870, loss: 0.12030492722988129
step: 880, loss: 0.09028530865907669
step: 890, loss: 0.01282451394945383
step: 900, loss: 0.016902469098567963
step: 910, loss: 0.10315446555614471
step: 920, loss: 0.017764464020729065
step: 930, loss: 0.06597401201725006
step: 940, loss: 0.049448560923337936
step: 950, loss: 0.1495855301618576
step: 960, loss: 0.21251891553401947
step: 970, loss: 0.02318805269896984
epoch 3: dev_f1=0.9352189781021898, f1=0.9366742596810934, best_f1=0.9366742596810934
step: 0, loss: 0.3044644892215729
step: 10, loss: 0.009845857508480549
step: 20, loss: 0.2226932942867279
step: 30, loss: 0.10497883707284927
step: 40, loss: 0.07896222919225693
step: 50, loss: 0.033184099942445755
step: 60, loss: 0.10535888373851776
step: 70, loss: 0.09173309057950974
step: 80, loss: 0.06599299609661102
step: 90, loss: 0.20073024928569794
step: 100, loss: 0.05969122424721718
step: 110, loss: 0.07575057446956635
step: 120, loss: 0.057685550302267075
step: 130, loss: 0.012600600719451904
step: 140, loss: 0.03407420590519905
step: 150, loss: 0.03850644826889038
step: 160, loss: 0.015411416068673134
step: 170, loss: 0.006539763882756233
step: 180, loss: 0.16529729962348938
step: 190, loss: 0.04763799533247948
step: 200, loss: 0.05906981602311134
step: 210, loss: 0.09527719765901566
step: 220, loss: 0.027840565890073776
step: 230, loss: 0.0861203670501709
step: 240, loss: 0.0869399905204773
step: 250, loss: 0.028811529278755188
step: 260, loss: 0.08426351100206375
step: 270, loss: 0.07534076273441315
step: 280, loss: 0.014362250454723835
step: 290, loss: 0.03908015787601471
step: 300, loss: 0.041516777127981186
step: 310, loss: 0.01636406034231186
step: 320, loss: 0.06771604716777802
step: 330, loss: 0.15960554778575897
step: 340, loss: 0.06163107603788376
step: 350, loss: 0.02754512056708336
step: 360, loss: 0.024809613823890686
step: 370, loss: 0.13623468577861786
step: 380, loss: 0.0679275169968605
step: 390, loss: 0.07073859125375748
step: 400, loss: 0.019188376143574715
step: 410, loss: 0.02202913910150528
step: 420, loss: 0.27706363797187805
step: 430, loss: 0.05204259231686592
step: 440, loss: 0.11444967985153198
step: 450, loss: 0.03629971295595169
step: 460, loss: 0.15385040640830994
step: 470, loss: 0.07859672605991364
step: 480, loss: 0.029821962118148804
step: 490, loss: 0.08706600219011307
step: 500, loss: 0.03994878754019737
step: 510, loss: 0.09808903932571411
step: 520, loss: 0.17824894189834595
step: 530, loss: 0.0502726212143898
step: 540, loss: 0.1541014164686203
step: 550, loss: 0.11468610912561417
step: 560, loss: 0.04625958949327469
step: 570, loss: 0.07096727937459946
step: 580, loss: 0.06076791509985924
step: 590, loss: 0.1141057163476944
step: 600, loss: 0.06390377879142761
step: 610, loss: 0.23779992759227753
step: 620, loss: 0.008182713761925697
step: 630, loss: 0.029637616127729416
step: 640, loss: 0.19262486696243286
step: 650, loss: 0.0677216500043869
step: 660, loss: 0.026623055338859558
step: 670, loss: 0.12310057878494263
step: 680, loss: 0.07779384404420853
step: 690, loss: 0.1728104203939438
step: 700, loss: 0.0753621906042099
step: 710, loss: 0.042872264981269836
step: 720, loss: 0.03243624418973923
step: 730, loss: 0.051612287759780884
step: 740, loss: 0.07680115103721619
step: 750, loss: 0.010190405882894993
step: 760, loss: 0.12878502905368805
step: 770, loss: 0.02277274616062641
step: 780, loss: 0.09980102628469467
step: 790, loss: 0.01874566078186035
step: 800, loss: 0.1012895405292511
step: 810, loss: 0.01697028987109661
step: 820, loss: 0.011536517180502415
step: 830, loss: 0.017840826883912086
step: 840, loss: 0.13987627625465393
step: 850, loss: 0.19579780101776123
step: 860, loss: 0.025840993970632553
step: 870, loss: 0.05791081488132477
step: 880, loss: 0.04702422395348549
step: 890, loss: 0.019310656934976578
step: 900, loss: 0.02490486577153206
step: 910, loss: 0.03381434828042984
step: 920, loss: 0.08398985862731934
step: 930, loss: 0.11374851316213608
step: 940, loss: 0.11401902139186859
step: 950, loss: 0.3970007300376892
step: 960, loss: 0.06461350619792938
step: 970, loss: 0.015575253404676914
epoch 4: dev_f1=0.9426573426573427, f1=0.9333954354913834, best_f1=0.9333954354913834
step: 0, loss: 0.13791050016880035
step: 10, loss: 0.007582411170005798
step: 20, loss: 0.06734901666641235
step: 30, loss: 0.01428960170596838
step: 40, loss: 0.06024249270558357
step: 50, loss: 0.014013377018272877
step: 60, loss: 0.09439091384410858
step: 70, loss: 0.16144539415836334
step: 80, loss: 0.14851044118404388
step: 90, loss: 0.1494646966457367
step: 100, loss: 0.01758185774087906
step: 110, loss: 0.06476456671953201
step: 120, loss: 0.1205868273973465
step: 130, loss: 0.04826028272509575
step: 140, loss: 0.03151370957493782
step: 150, loss: 0.015388088300824165
step: 160, loss: 0.12274523824453354
step: 170, loss: 0.09714972972869873
step: 180, loss: 0.012963809072971344
step: 190, loss: 0.06722308695316315
step: 200, loss: 0.01189439371228218
step: 210, loss: 0.02224102057516575
step: 220, loss: 0.0665953978896141
step: 230, loss: 0.021609216928482056
step: 240, loss: 0.12339852005243301
step: 250, loss: 0.0639539286494255
step: 260, loss: 0.08033888787031174
step: 270, loss: 0.042595025151968
step: 280, loss: 0.004941316321492195
step: 290, loss: 0.06690219044685364
step: 300, loss: 0.06575862318277359
step: 310, loss: 0.07937955856323242
step: 320, loss: 0.07622040063142776
step: 330, loss: 0.021051961928606033
step: 340, loss: 0.07427822053432465
step: 350, loss: 0.05090874433517456
step: 360, loss: 0.07934411615133286
step: 370, loss: 0.020595649257302284
step: 380, loss: 0.15133900940418243
step: 390, loss: 0.11462041735649109
step: 400, loss: 0.04888557270169258
step: 410, loss: 0.09032061696052551
step: 420, loss: 0.13546040654182434
step: 430, loss: 0.0631045550107956
step: 440, loss: 0.05421975255012512
step: 450, loss: 0.11490865051746368
step: 460, loss: 0.14664341509342194
step: 470, loss: 0.017920836806297302
step: 480, loss: 0.047408416867256165
step: 490, loss: 0.009989476762712002
step: 500, loss: 0.08976263552904129
step: 510, loss: 0.11471850425004959
step: 520, loss: 0.13072609901428223
step: 530, loss: 0.03403050824999809
step: 540, loss: 0.025744831189513206
step: 550, loss: 0.19428324699401855
step: 560, loss: 0.07672762870788574
step: 570, loss: 0.08801355212926865
step: 580, loss: 0.04429499804973602
step: 590, loss: 0.09318818897008896
step: 600, loss: 0.2096765637397766
step: 610, loss: 0.07862120121717453
step: 620, loss: 0.05612697824835777
step: 630, loss: 0.03353822976350784
step: 640, loss: 0.06481383740901947
step: 650, loss: 0.03514145314693451
step: 660, loss: 0.06734149158000946
step: 670, loss: 0.074941486120224
step: 680, loss: 0.050773367285728455
step: 690, loss: 0.0815216600894928
step: 700, loss: 0.05248438939452171
step: 710, loss: 0.021702880039811134
step: 720, loss: 0.030934549868106842
step: 730, loss: 0.06052035465836525
step: 740, loss: 0.06855162978172302
step: 750, loss: 0.10421136766672134
step: 760, loss: 0.03786351531744003
step: 770, loss: 0.02921627275645733
step: 780, loss: 0.011170065961778164
step: 790, loss: 0.06958043575286865
step: 800, loss: 0.023538175970315933
step: 810, loss: 0.054819028824567795
step: 820, loss: 0.06471385061740875
step: 830, loss: 0.021149558946490288
step: 840, loss: 0.025784440338611603
step: 850, loss: 0.009235365316271782
step: 860, loss: 0.05069415271282196
step: 870, loss: 0.007385628763586283
step: 880, loss: 0.10198485106229782
step: 890, loss: 0.008132148534059525
step: 900, loss: 0.07114377617835999
step: 910, loss: 0.014170227572321892
step: 920, loss: 0.11767531931400299
step: 930, loss: 0.04450998455286026
step: 940, loss: 0.028357727453112602
step: 950, loss: 0.05591076239943504
step: 960, loss: 0.08049008995294571
step: 970, loss: 0.12611570954322815
epoch 5: dev_f1=0.9428044280442804, f1=0.9420423183072677, best_f1=0.9420423183072677
step: 0, loss: 0.07822950184345245
step: 10, loss: 0.03770039975643158
step: 20, loss: 0.1024407297372818
step: 30, loss: 0.06246822327375412
step: 40, loss: 0.011566858738660812
step: 50, loss: 0.07608026266098022
step: 60, loss: 0.02997143380343914
step: 70, loss: 0.016788341104984283
step: 80, loss: 0.051719214767217636
step: 90, loss: 0.06810997426509857
step: 100, loss: 0.09129747748374939
step: 110, loss: 0.02581431344151497
step: 120, loss: 0.05630189925432205
step: 130, loss: 0.007205587346106768
step: 140, loss: 0.022246036678552628
step: 150, loss: 0.02343454211950302
step: 160, loss: 0.016410280019044876
step: 170, loss: 0.09604399651288986
step: 180, loss: 0.14934241771697998
step: 190, loss: 0.005893209017813206
step: 200, loss: 0.08581526577472687
step: 210, loss: 0.11684399098157883
step: 220, loss: 0.02977188304066658
step: 230, loss: 0.027041196823120117
step: 240, loss: 0.0588134303689003
step: 250, loss: 0.08050703257322311
step: 260, loss: 0.07757970690727234
step: 270, loss: 0.0766139030456543
step: 280, loss: 0.153294637799263
step: 290, loss: 0.1105908676981926
step: 300, loss: 0.0904952883720398
step: 310, loss: 0.06506023555994034
step: 320, loss: 0.11128637194633484
step: 330, loss: 0.051058102399110794
step: 340, loss: 0.10990742594003677
step: 350, loss: 0.04990852251648903
step: 360, loss: 0.2637341618537903
step: 370, loss: 0.06557808071374893
step: 380, loss: 0.022123368456959724
step: 390, loss: 0.1487102061510086
step: 400, loss: 0.02902461402118206
step: 410, loss: 0.011180028319358826
step: 420, loss: 0.05594388768076897
step: 430, loss: 0.09809211641550064
step: 440, loss: 0.009578442201018333
step: 450, loss: 0.09140580892562866
step: 460, loss: 0.17981554567813873
step: 470, loss: 0.0984196811914444
step: 480, loss: 0.06303247064352036
step: 490, loss: 0.06192093715071678
step: 500, loss: 0.014023764058947563
step: 510, loss: 0.19678011536598206
step: 520, loss: 0.07273709774017334
step: 530, loss: 0.006132341921329498
step: 540, loss: 0.06884417682886124
step: 550, loss: 0.058205585926771164
step: 560, loss: 0.07705561816692352
step: 570, loss: 0.1031658798456192
step: 580, loss: 0.0272807776927948
step: 590, loss: 0.07806133478879929
step: 600, loss: 0.05999092757701874
step: 610, loss: 0.07270123064517975
step: 620, loss: 0.08169738203287125
step: 630, loss: 0.0065789371728897095
step: 640, loss: 0.02172945626080036
step: 650, loss: 0.06648481637239456
step: 660, loss: 0.10474467277526855
step: 670, loss: 0.017005031928420067
step: 680, loss: 0.07030736654996872
step: 690, loss: 0.10987228900194168
step: 700, loss: 0.0002401027304586023
step: 710, loss: 0.09342648833990097
step: 720, loss: 0.02491343580186367
step: 730, loss: 0.009992367587983608
step: 740, loss: 0.12507836520671844
step: 750, loss: 0.08430761098861694
step: 760, loss: 0.09965939074754715
step: 770, loss: 0.01828123815357685
step: 780, loss: 0.019694974645972252
step: 790, loss: 0.00681705167517066
step: 800, loss: 0.1352424919605255
step: 810, loss: 0.05862188711762428
step: 820, loss: 0.029850417748093605
step: 830, loss: 0.04033027961850166
step: 840, loss: 0.043461281806230545
step: 850, loss: 0.03774954378604889
step: 860, loss: 0.13927391171455383
step: 870, loss: 0.07099678367376328
step: 880, loss: 0.03173774853348732
step: 890, loss: 0.07542935013771057
step: 900, loss: 0.19460175931453705
step: 910, loss: 0.023648297414183617
step: 920, loss: 0.049462396651506424
step: 930, loss: 0.04261871427297592
step: 940, loss: 0.07505947351455688
step: 950, loss: 0.08515926450490952
step: 960, loss: 0.012753965333104134
step: 970, loss: 0.07643286138772964
epoch 6: dev_f1=0.93202062822316, f1=0.9310344827586207, best_f1=0.9420423183072677
step: 0, loss: 0.07203178852796555
step: 10, loss: 0.054713357239961624
step: 20, loss: 0.03846083581447601
step: 30, loss: 0.035808149725198746
step: 40, loss: 0.06956788897514343
step: 50, loss: 0.034816302359104156
step: 60, loss: 0.024567922577261925
step: 70, loss: 0.00872656237334013
step: 80, loss: 0.021115919575095177
step: 90, loss: 0.04105678200721741
step: 100, loss: 0.018151618540287018
step: 110, loss: 0.08122935146093369
step: 120, loss: 0.21994096040725708
step: 130, loss: 0.06010312959551811
step: 140, loss: 0.026112664490938187
step: 150, loss: 0.0670475959777832
step: 160, loss: 0.052338551729917526
step: 170, loss: 0.09054962545633316
step: 180, loss: 0.13837546110153198
step: 190, loss: 0.08451160788536072
step: 200, loss: 0.016036957502365112
step: 210, loss: 0.04605105519294739
step: 220, loss: 0.05032479763031006
step: 230, loss: 0.022633714601397514
step: 240, loss: 0.06836367398500443
step: 250, loss: 0.02809213660657406
step: 260, loss: 0.01821892522275448
step: 270, loss: 0.08863107115030289
step: 280, loss: 0.013366300612688065
step: 290, loss: 0.014949481934309006
step: 300, loss: 0.009790914133191109
step: 310, loss: 0.20754694938659668
step: 320, loss: 0.08911459892988205
step: 330, loss: 0.10703130811452866
step: 340, loss: 0.017807818949222565
step: 350, loss: 0.10747560113668442
step: 360, loss: 0.08263744413852692
step: 370, loss: 0.09390977770090103
step: 380, loss: 0.017496081069111824
step: 390, loss: 0.039870865643024445
step: 400, loss: 0.060010697692632675
step: 410, loss: 0.07709646970033646
step: 420, loss: 0.057046886533498764
step: 430, loss: 0.004700730089098215
step: 440, loss: 0.01578357256948948
step: 450, loss: 0.15118029713630676
step: 460, loss: 0.02638729102909565
step: 470, loss: 0.0954107791185379
step: 480, loss: 0.11897507309913635
step: 490, loss: 0.08852390199899673
step: 500, loss: 0.04538540169596672
step: 510, loss: 0.01458646822720766
step: 520, loss: 0.08470766246318817
step: 530, loss: 0.02360471524298191
step: 540, loss: 0.02580009587109089
step: 550, loss: 0.016202889382839203
step: 560, loss: 0.12834760546684265
step: 570, loss: 0.11228980123996735
step: 580, loss: 0.06991313397884369
step: 590, loss: 0.0452021099627018
step: 600, loss: 0.0932483971118927
step: 610, loss: 0.019632672891020775
step: 620, loss: 0.056274402886629105
step: 630, loss: 0.09894289076328278
step: 640, loss: 0.16851647198200226
step: 650, loss: 0.0594249963760376
step: 660, loss: 0.05216536670923233
step: 670, loss: 0.022541899234056473
step: 680, loss: 0.007746357936412096
step: 690, loss: 0.14419269561767578
step: 700, loss: 0.06803451478481293
step: 710, loss: 0.10717228800058365
step: 720, loss: 0.1016741693019867
step: 730, loss: 0.09536643326282501
step: 740, loss: 0.008997428230941296
step: 750, loss: 0.02220246195793152
step: 760, loss: 0.023598643019795418
step: 770, loss: 0.022861022502183914
step: 780, loss: 0.02625199779868126
step: 790, loss: 0.1253996342420578
step: 800, loss: 0.011215804144740105
step: 810, loss: 0.15818201005458832
step: 820, loss: 0.12270991504192352
step: 830, loss: 0.0590030811727047
step: 840, loss: 0.14268235862255096
step: 850, loss: 0.14302678406238556
step: 860, loss: 0.06595823913812637
step: 870, loss: 0.04547017812728882
step: 880, loss: 0.05376992002129555
step: 890, loss: 0.017751723527908325
step: 900, loss: 0.010612442158162594
step: 910, loss: 0.06032028794288635
step: 920, loss: 0.05728234350681305
step: 930, loss: 0.03389277309179306
step: 940, loss: 0.054076701402664185
step: 950, loss: 0.10160113126039505
step: 960, loss: 0.051657989621162415
step: 970, loss: 0.08669586479663849
epoch 7: dev_f1=0.9413919413919414, f1=0.9357045143638849, best_f1=0.9420423183072677
step: 0, loss: 0.028057022020220757
step: 10, loss: 0.03532225638628006
step: 20, loss: 0.08933573961257935
step: 30, loss: 0.027639100328087807
step: 40, loss: 0.07349294424057007
step: 50, loss: 0.07265377044677734
step: 60, loss: 0.03162935748696327
step: 70, loss: 0.09888765960931778
step: 80, loss: 0.03646702319383621
step: 90, loss: 0.07635166496038437
step: 100, loss: 0.09981139749288559
step: 110, loss: 0.007721632719039917
step: 120, loss: 0.05140036344528198
step: 130, loss: 0.07383440434932709
step: 140, loss: 0.10192648321390152
step: 150, loss: 0.06627355515956879
step: 160, loss: 0.019302140921354294
step: 170, loss: 0.13934928178787231
step: 180, loss: 0.020956821739673615
step: 190, loss: 0.06550604104995728
step: 200, loss: 0.017173273488879204
step: 210, loss: 0.0322844572365284
step: 220, loss: 0.0821201279759407
step: 230, loss: 0.02554098144173622
step: 240, loss: 0.15228714048862457
step: 250, loss: 0.05486487224698067
step: 260, loss: 0.060114677995443344
step: 270, loss: 0.00559713551774621
step: 280, loss: 0.059045348316431046
step: 290, loss: 0.07010622322559357
step: 300, loss: 0.08005319535732269
step: 310, loss: 0.08975490182638168
step: 320, loss: 0.05765007808804512
step: 330, loss: 0.07011709362268448
step: 340, loss: 0.0212039053440094
step: 350, loss: 0.09967028349637985
step: 360, loss: 0.0818164050579071
step: 370, loss: 0.04312433302402496
step: 380, loss: 0.15270163118839264
step: 390, loss: 0.026590537279844284
step: 400, loss: 0.08257124572992325
step: 410, loss: 0.06347326934337616
step: 420, loss: 0.013181387446820736
step: 430, loss: 0.08763634413480759
step: 440, loss: 0.07059212774038315
step: 450, loss: 0.08852933347225189
step: 460, loss: 0.08180013298988342
step: 470, loss: 0.0558699406683445
step: 480, loss: 0.08710979670286179
step: 490, loss: 0.044067490845918655
step: 500, loss: 0.10585736483335495
step: 510, loss: 0.030164964497089386
step: 520, loss: 0.046827614307403564
step: 530, loss: 0.050911422818899155
step: 540, loss: 0.010021794587373734
step: 550, loss: 0.06613645702600479
step: 560, loss: 0.1544862687587738
step: 570, loss: 0.08116044849157333
step: 580, loss: 0.06465926766395569
step: 590, loss: 0.13733626902103424
step: 600, loss: 0.005541361402720213
step: 610, loss: 0.1319703906774521
step: 620, loss: 0.021093346178531647
step: 630, loss: 0.013304738327860832
step: 640, loss: 0.12364093214273453
step: 650, loss: 0.11477521806955338
step: 660, loss: 0.052933383733034134
step: 670, loss: 0.07397136837244034
step: 680, loss: 0.02302337810397148
step: 690, loss: 0.06319544464349747
step: 700, loss: 0.025713399052619934
step: 710, loss: 0.0413539856672287
step: 720, loss: 0.1346324235200882
step: 730, loss: 0.041454948484897614
step: 740, loss: 0.06546729803085327
step: 750, loss: 0.005754319950938225
step: 760, loss: 0.07283958047628403
step: 770, loss: 0.01497651543468237
step: 780, loss: 0.06228422746062279
step: 790, loss: 0.016871171072125435
step: 800, loss: 0.05160137265920639
step: 810, loss: 0.03539631515741348
step: 820, loss: 0.01663215085864067
step: 830, loss: 0.07595361769199371
step: 840, loss: 0.06863037496805191
step: 850, loss: 0.05349999666213989
step: 860, loss: 0.0781613141298294
step: 870, loss: 0.06478685140609741
step: 880, loss: 0.10391560941934586
step: 890, loss: 0.009920040145516396
step: 900, loss: 0.00032155620283447206
step: 910, loss: 0.009023159742355347
step: 920, loss: 0.022706961259245872
step: 930, loss: 0.19159381091594696
step: 940, loss: 0.014558471739292145
step: 950, loss: 0.05044130980968475
step: 960, loss: 0.0443003848195076
step: 970, loss: 0.09366168081760406
epoch 8: dev_f1=0.9387755102040817, f1=0.936111111111111, best_f1=0.9420423183072677
step: 0, loss: 0.03298009932041168
step: 10, loss: 0.08419402688741684
step: 20, loss: 0.07490197569131851
step: 30, loss: 0.03273574635386467
step: 40, loss: 0.07019690424203873
step: 50, loss: 0.09329531341791153
step: 60, loss: 0.1285688430070877
step: 70, loss: 0.029716575518250465
step: 80, loss: 0.02167842909693718
step: 90, loss: 0.0064448765479028225
step: 100, loss: 0.003510728944092989
step: 110, loss: 0.09271430969238281
step: 120, loss: 0.08576478809118271
step: 130, loss: 0.04160928353667259
step: 140, loss: 0.07526447623968124
step: 150, loss: 0.08585560321807861
step: 160, loss: 0.07838862389326096
step: 170, loss: 0.014638308435678482
step: 180, loss: 0.12446747720241547
step: 190, loss: 0.02252741903066635
step: 200, loss: 0.1425924152135849
step: 210, loss: 0.007820033468306065
step: 220, loss: 0.17230480909347534
step: 230, loss: 0.008921082131564617
step: 240, loss: 0.10675135254859924
step: 250, loss: 0.0918397456407547
step: 260, loss: 0.061589840799570084
step: 270, loss: 0.019914500415325165
step: 280, loss: 0.0490482859313488
step: 290, loss: 0.07259581238031387
step: 300, loss: 0.09273830056190491
step: 310, loss: 0.04534374549984932
step: 320, loss: 0.06348534673452377
step: 330, loss: 0.00807352364063263
step: 340, loss: 0.09666145592927933
step: 350, loss: 0.04903515800833702
step: 360, loss: 0.13081659376621246
step: 370, loss: 0.021634962409734726
step: 380, loss: 0.0911911204457283
step: 390, loss: 0.013096760027110577
step: 400, loss: 0.16102564334869385
step: 410, loss: 0.05021476373076439
step: 420, loss: 0.0658516064286232
step: 430, loss: 0.14690500497817993
step: 440, loss: 0.13055042922496796
step: 450, loss: 0.021744171157479286
step: 460, loss: 0.002032660413533449
step: 470, loss: 0.06786197423934937
step: 480, loss: 0.052430182695388794
step: 490, loss: 0.02097826451063156
step: 500, loss: 0.08773862570524216
step: 510, loss: 0.06903591752052307
step: 520, loss: 0.008108227513730526
step: 530, loss: 0.01564052887260914
step: 540, loss: 0.007891066372394562
step: 550, loss: 0.14787177741527557
step: 560, loss: 0.011473819613456726
step: 570, loss: 0.015411123633384705
step: 580, loss: 0.04043075442314148
step: 590, loss: 0.040289945900440216
step: 600, loss: 0.03330732136964798
step: 610, loss: 0.011004360392689705
step: 620, loss: 0.018892500549554825
step: 630, loss: 0.07381770759820938
step: 640, loss: 0.047887735068798065
step: 650, loss: 0.12983338534832
step: 660, loss: 0.08963144570589066
step: 670, loss: 0.31827881932258606
step: 680, loss: 0.07531224936246872
step: 690, loss: 0.017344387248158455
step: 700, loss: 0.12868088483810425
step: 710, loss: 0.02187156118452549
step: 720, loss: 0.02057386003434658
step: 730, loss: 0.008081448264420033
step: 740, loss: 0.07549760490655899
step: 750, loss: 0.04005306214094162
step: 760, loss: 0.07447583228349686
step: 770, loss: 0.11536508798599243
step: 780, loss: 0.04088917002081871
step: 790, loss: 0.012188087217509747
step: 800, loss: 0.021297752857208252
step: 810, loss: 0.0268862321972847
step: 820, loss: 0.021979812532663345
step: 830, loss: 0.05717084929347038
step: 840, loss: 0.0064954920671880245
step: 850, loss: 0.09248125553131104
step: 860, loss: 0.025020629167556763
step: 870, loss: 0.03126482665538788
step: 880, loss: 0.053002502769231796
step: 890, loss: 0.019314607605338097
step: 900, loss: 0.03997243195772171
step: 910, loss: 0.07302691787481308
step: 920, loss: 0.09005880355834961
step: 930, loss: 0.020341606810688972
step: 940, loss: 0.015610483475029469
step: 950, loss: 0.008158085867762566
step: 960, loss: 0.04527847841382027
step: 970, loss: 0.019049715250730515
epoch 9: dev_f1=0.9340710004610421, f1=0.9334557136301056, best_f1=0.9420423183072677
step: 0, loss: 0.13308580219745636
step: 10, loss: 0.0778513178229332
step: 20, loss: 0.10019391775131226
step: 30, loss: 0.023746969178318977
step: 40, loss: 0.043224137276411057
step: 50, loss: 0.09253903478384018
step: 60, loss: 0.15961062908172607
step: 70, loss: 0.011652500368654728
step: 80, loss: 0.045035529881715775
step: 90, loss: 0.01502852700650692
step: 100, loss: 0.08646531403064728
step: 110, loss: 0.033004485070705414
step: 120, loss: 0.03569311276078224
step: 130, loss: 0.0530768446624279
step: 140, loss: 0.022653646767139435
step: 150, loss: 0.01172693818807602
step: 160, loss: 0.012543506920337677
step: 170, loss: 0.058243270963430405
step: 180, loss: 0.1045796275138855
step: 190, loss: 0.030532583594322205
step: 200, loss: 0.08942582458257675
step: 210, loss: 0.0440107062458992
step: 220, loss: 0.06332386285066605
step: 230, loss: 0.11684831231832504
step: 240, loss: 0.09597301483154297
step: 250, loss: 0.07992915064096451
step: 260, loss: 0.28648507595062256
step: 270, loss: 0.04590464010834694
step: 280, loss: 0.13078346848487854
step: 290, loss: 0.018408479169011116
step: 300, loss: 0.06303166598081589
step: 310, loss: 0.1601686328649521
step: 320, loss: 0.007845116779208183
step: 330, loss: 0.07254070788621902
step: 340, loss: 0.00873640552163124
step: 350, loss: 0.049418993294239044
step: 360, loss: 0.0705254077911377
step: 370, loss: 0.007572226691991091
step: 380, loss: 0.07494665682315826
step: 390, loss: 0.01776697486639023
step: 400, loss: 0.028216149657964706
step: 410, loss: 0.07187796384096146
step: 420, loss: 0.06072522699832916
step: 430, loss: 0.007517880294471979
step: 440, loss: 0.041233453899621964
step: 450, loss: 0.01836331933736801
step: 460, loss: 0.008003843016922474
step: 470, loss: 0.004818950314074755
step: 480, loss: 0.01694547012448311
step: 490, loss: 0.08265400677919388
step: 500, loss: 0.026622772216796875
step: 510, loss: 0.003098955610767007
step: 520, loss: 0.021372182294726372
step: 530, loss: 0.12840449810028076
step: 540, loss: 0.10905484855175018
step: 550, loss: 0.0034339081030339003
step: 560, loss: 0.0733611062169075
step: 570, loss: 0.03267909586429596
step: 580, loss: 0.07784876227378845
step: 590, loss: 0.09093482792377472
step: 600, loss: 0.031471192836761475
step: 610, loss: 0.10485926270484924
step: 620, loss: 0.0519707091152668
step: 630, loss: 0.008723132312297821
step: 640, loss: 0.0044255428947508335
step: 650, loss: 0.007795908488333225
step: 660, loss: 0.10342320054769516
step: 670, loss: 0.12768559157848358
step: 680, loss: 0.029429543763399124
step: 690, loss: 0.09865555912256241
step: 700, loss: 0.00941863190382719
step: 710, loss: 0.07658674567937851
step: 720, loss: 0.020668331533670425
step: 730, loss: 0.02725476399064064
step: 740, loss: 0.015737712383270264
step: 750, loss: 0.07119408994913101
step: 760, loss: 0.08460094034671783
step: 770, loss: 0.08099900186061859
step: 780, loss: 0.06958133727312088
step: 790, loss: 0.031139163300395012
step: 800, loss: 0.031620971858501434
step: 810, loss: 0.000539903063327074
step: 820, loss: 0.08651907742023468
step: 830, loss: 0.016140921041369438
step: 840, loss: 0.017687764018774033
step: 850, loss: 0.05530613288283348
step: 860, loss: 0.17589184641838074
step: 870, loss: 0.016852980479598045
step: 880, loss: 0.03874378278851509
step: 890, loss: 0.16474871337413788
step: 900, loss: 0.017059678211808205
step: 910, loss: 0.08003097027540207
step: 920, loss: 0.08282699435949326
step: 930, loss: 0.10197506844997406
step: 940, loss: 0.06281071901321411
step: 950, loss: 0.1019444614648819
step: 960, loss: 0.03923241049051285
step: 970, loss: 0.08829516917467117
epoch 10: dev_f1=0.9298000929800094, f1=0.9296296296296297, best_f1=0.9420423183072677
step: 0, loss: 0.005532114766538143
step: 10, loss: 0.013280321843922138
step: 20, loss: 0.05570831894874573
step: 30, loss: 0.004120730794966221
step: 40, loss: 0.0005501084378920496
step: 50, loss: 0.002682290505617857
step: 60, loss: 0.054615672677755356
step: 70, loss: 0.05969295650720596
step: 80, loss: 0.17941828072071075
step: 90, loss: 0.051246512681245804
step: 100, loss: 0.10615397244691849
step: 110, loss: 0.1532292515039444
step: 120, loss: 0.06728470325469971
step: 130, loss: 0.029593966901302338
step: 140, loss: 0.02762855961918831
step: 150, loss: 0.01814448833465576
step: 160, loss: 0.07411488145589828
step: 170, loss: 0.04159645363688469
step: 180, loss: 0.10500030219554901
step: 190, loss: 0.14110252261161804
step: 200, loss: 0.031091969460248947
step: 210, loss: 0.018462859094142914
step: 220, loss: 0.09990184754133224
step: 230, loss: 0.016644954681396484
step: 240, loss: 0.031194433569908142
step: 250, loss: 0.012725957669317722
step: 260, loss: 0.0357789508998394
step: 270, loss: 0.09423238039016724
step: 280, loss: 0.03163023665547371
step: 290, loss: 0.0373532697558403
step: 300, loss: 0.061564285308122635
step: 310, loss: 0.017824765294790268
step: 320, loss: 0.17213064432144165
step: 330, loss: 0.04936430975794792
step: 340, loss: 0.052757151424884796
step: 350, loss: 0.052869778126478195
step: 360, loss: 0.12464212626218796
step: 370, loss: 0.22637365758419037
step: 380, loss: 0.04100751504302025
step: 390, loss: 0.015021818690001965
step: 400, loss: 0.26721468567848206
step: 410, loss: 0.010592343285679817
step: 420, loss: 0.005225555505603552
step: 430, loss: 0.05922319367527962
step: 440, loss: 0.04849008098244667
step: 450, loss: 0.054524146020412445
step: 460, loss: 0.003525699954479933
step: 470, loss: 0.015773147344589233
step: 480, loss: 0.021404672414064407
step: 490, loss: 0.048300620168447495
step: 500, loss: 0.014393780380487442
step: 510, loss: 0.1012246161699295
step: 520, loss: 0.024596234783530235
step: 530, loss: 0.01688527688384056
step: 540, loss: 0.07315131276845932
step: 550, loss: 0.009169457480311394
step: 560, loss: 0.09225022047758102
step: 570, loss: 0.10649044066667557
step: 580, loss: 0.05517382547259331
step: 590, loss: 0.05674139782786369
step: 600, loss: 0.022258741781115532
step: 610, loss: 0.11438874900341034
step: 620, loss: 0.040172576904296875
step: 630, loss: 0.008472678251564503
step: 640, loss: 0.06185765191912651
step: 650, loss: 0.0782831609249115
step: 660, loss: 0.03482065722346306
step: 670, loss: 0.012720217928290367
step: 680, loss: 0.05774417892098427
step: 690, loss: 0.10470204800367355
step: 700, loss: 0.011824339628219604
step: 710, loss: 0.010068992152810097
step: 720, loss: 0.013490156270563602
step: 730, loss: 0.037631358951330185
step: 740, loss: 0.021451707929372787
step: 750, loss: 0.13143889605998993
step: 760, loss: 0.04429143667221069
step: 770, loss: 0.009168367832899094
step: 780, loss: 0.1456034779548645
step: 790, loss: 0.08149655163288116
step: 800, loss: 0.03877067193388939
step: 810, loss: 0.01594528555870056
step: 820, loss: 0.011198125779628754
step: 830, loss: 0.007197413127869368
step: 840, loss: 0.015555515885353088
step: 850, loss: 0.03157207369804382
step: 860, loss: 0.041294775903224945
step: 870, loss: 0.10955584049224854
step: 880, loss: 0.10984112322330475
step: 890, loss: 0.14391133189201355
step: 900, loss: 0.08133276551961899
step: 910, loss: 0.0867646262049675
step: 920, loss: 0.06794793903827667
step: 930, loss: 0.01192819606512785
step: 940, loss: 0.05713426694273949
step: 950, loss: 0.012171948328614235
step: 960, loss: 0.05475010722875595
step: 970, loss: 0.1126951277256012
epoch 11: dev_f1=0.9358914365933552, f1=0.9390980939098094, best_f1=0.9420423183072677
step: 0, loss: 0.010734881274402142
step: 10, loss: 0.03576627001166344
step: 20, loss: 0.074751116335392
step: 30, loss: 0.02596868947148323
step: 40, loss: 0.014639837667346
step: 50, loss: 0.021097786724567413
step: 60, loss: 0.0234624445438385
step: 70, loss: 0.0471179336309433
step: 80, loss: 0.017399733886122704
step: 90, loss: 0.013114208355545998
step: 100, loss: 0.019397495314478874
step: 110, loss: 0.030413299798965454
step: 120, loss: 0.03459880128502846
step: 130, loss: 0.008698631078004837
step: 140, loss: 0.06083432585000992
step: 150, loss: 0.08741550892591476
step: 160, loss: 0.0197138674557209
step: 170, loss: 0.014563334174454212
step: 180, loss: 0.052972640842199326
step: 190, loss: 0.031261835247278214
step: 200, loss: 0.010047202929854393
step: 210, loss: 0.02213367260992527
step: 220, loss: 0.05368146300315857
step: 230, loss: 0.02073153853416443
step: 240, loss: 0.03201766684651375
step: 250, loss: 0.04180755838751793
step: 260, loss: 0.018456848338246346
step: 270, loss: 0.16000151634216309
step: 280, loss: 0.04937316104769707
step: 290, loss: 0.2790471017360687
step: 300, loss: 0.10999125987291336
step: 310, loss: 0.06530828773975372
step: 320, loss: 0.027132507413625717
step: 330, loss: 0.06372776627540588
step: 340, loss: 0.02947756089270115
step: 350, loss: 0.04025644809007645
step: 360, loss: 0.05322612449526787
step: 370, loss: 0.0253609512001276
step: 380, loss: 0.0058290972374379635
step: 390, loss: 0.004253981169313192
step: 400, loss: 0.04036955162882805
step: 410, loss: 0.12857438623905182
step: 420, loss: 0.02090451493859291
step: 430, loss: 0.03370103985071182
step: 440, loss: 0.04735284671187401
step: 450, loss: 0.12043557316064835
step: 460, loss: 0.011205697432160378
step: 470, loss: 0.01854693703353405
step: 480, loss: 0.08089236170053482
step: 490, loss: 0.01148374192416668
step: 500, loss: 0.062351346015930176
step: 510, loss: 0.07873763144016266
step: 520, loss: 0.022200562059879303
step: 530, loss: 0.03004610538482666
step: 540, loss: 0.04753198102116585
step: 550, loss: 0.010422216728329659
step: 560, loss: 0.0186602845788002
step: 570, loss: 0.0005923922290094197
step: 580, loss: 0.013110039755702019
step: 590, loss: 0.051631808280944824
step: 600, loss: 0.01400352455675602
step: 610, loss: 0.01202085055410862
step: 620, loss: 0.029289383441209793
step: 630, loss: 0.057397354394197464
step: 640, loss: 0.03336099907755852
step: 650, loss: 0.03987064212560654
step: 660, loss: 0.08691997081041336
step: 670, loss: 0.09945090115070343
step: 680, loss: 0.02891780063509941
step: 690, loss: 0.10121221095323563
step: 700, loss: 0.004224044736474752
step: 710, loss: 0.09761721640825272
step: 720, loss: 0.037153460085392
step: 730, loss: 0.03838733583688736
step: 740, loss: 0.01739548332989216
step: 750, loss: 0.03266819566488266
step: 760, loss: 0.04166556894779205
step: 770, loss: 0.1519741714000702
step: 780, loss: 0.06876679509878159
step: 790, loss: 0.027898311614990234
step: 800, loss: 0.0006800288683734834
step: 810, loss: 0.06274380534887314
step: 820, loss: 0.03037712536752224
step: 830, loss: 0.03549325838685036
step: 840, loss: 0.0805683359503746
step: 850, loss: 0.041923318058252335
step: 860, loss: 0.11801686137914658
step: 870, loss: 0.046922191977500916
step: 880, loss: 0.0866546779870987
step: 890, loss: 0.027547890320420265
step: 900, loss: 1.448007515136851e-05
step: 910, loss: 0.003931140527129173
step: 920, loss: 0.0830271989107132
step: 930, loss: 0.02067854069173336
step: 940, loss: 0.01389027014374733
step: 950, loss: 0.026111314073204994
step: 960, loss: 0.0809561237692833
step: 970, loss: 0.10782688111066818
epoch 12: dev_f1=0.9428172942817293, f1=0.939435968562182, best_f1=0.939435968562182
step: 0, loss: 0.010688738897442818
step: 10, loss: 0.06964278966188431
step: 20, loss: 0.04585793614387512
step: 30, loss: 0.0027236798778176308
step: 40, loss: 0.15444958209991455
step: 50, loss: 0.039159875363111496
step: 60, loss: 0.03937143459916115
step: 70, loss: 0.03548179194331169
step: 80, loss: 0.07387711107730865
step: 90, loss: 1.9933528164983727e-05
step: 100, loss: 0.021074390038847923
step: 110, loss: 0.041117191314697266
step: 120, loss: 0.03623504936695099
step: 130, loss: 0.016516493633389473
step: 140, loss: 0.031693827360868454
step: 150, loss: 0.11192911863327026
step: 160, loss: 0.08913350105285645
step: 170, loss: 0.03917184844613075
step: 180, loss: 0.0048203784972429276
step: 190, loss: 0.012587729841470718
step: 200, loss: 0.0034320286940783262
step: 210, loss: 0.15139971673488617
step: 220, loss: 0.01360643282532692
step: 230, loss: 0.012777375057339668
step: 240, loss: 0.017974913120269775
step: 250, loss: 0.00664315652102232
step: 260, loss: 0.006270779762417078
step: 270, loss: 0.059790175408124924
step: 280, loss: 0.0809902772307396
step: 290, loss: 0.0035437275655567646
step: 300, loss: 0.03282313793897629
step: 310, loss: 0.008282721973955631
step: 320, loss: 0.018365250900387764
step: 330, loss: 0.049231722950935364
step: 340, loss: 0.12160082906484604
step: 350, loss: 0.02449842169880867
step: 360, loss: 0.11814918369054794
step: 370, loss: 0.04612406715750694
step: 380, loss: 0.04833604022860527
step: 390, loss: 0.044162921607494354
step: 400, loss: 0.02008039318025112
step: 410, loss: 0.010858210735023022
step: 420, loss: 0.03182665631175041
step: 430, loss: 0.041063737124204636
step: 440, loss: 0.015040872618556023
step: 450, loss: 0.03312092646956444
step: 460, loss: 0.12635460495948792
step: 470, loss: 0.007751901168376207
step: 480, loss: 0.0332060381770134
step: 490, loss: 0.08334077149629593
step: 500, loss: 0.04821660742163658
step: 510, loss: 0.02056240476667881
step: 520, loss: 0.026223836466670036
step: 530, loss: 0.0028334632515907288
step: 540, loss: 0.0429859422147274
step: 550, loss: 0.043223004788160324
step: 560, loss: 0.006393943913280964
step: 570, loss: 0.13631464540958405
step: 580, loss: 0.07594724744558334
step: 590, loss: 9.13065014174208e-05
step: 600, loss: 0.09281652420759201
step: 610, loss: 0.0796857699751854
step: 620, loss: 0.08807678520679474
step: 630, loss: 0.12112566828727722
step: 640, loss: 0.009304793551564217
step: 650, loss: 0.07936396449804306
step: 660, loss: 0.03334645554423332
step: 670, loss: 0.04071879759430885
step: 680, loss: 0.01024290919303894
step: 690, loss: 0.09329014271497726
step: 700, loss: 0.04297592118382454
step: 710, loss: 0.01843022182583809
step: 720, loss: 0.016265379264950752
step: 730, loss: 0.044474806636571884
step: 740, loss: 6.097842560848221e-05
step: 750, loss: 0.04824278503656387
step: 760, loss: 0.06688801199197769
step: 770, loss: 0.01122402772307396
step: 780, loss: 0.00017311227566096932
step: 790, loss: 0.07761991024017334
step: 800, loss: 0.0651787668466568
step: 810, loss: 0.03103569522500038
step: 820, loss: 0.02358689345419407
step: 830, loss: 0.035012632608413696
step: 840, loss: 0.09903252124786377
step: 850, loss: 0.0524928905069828
step: 860, loss: 0.02404128573834896
step: 870, loss: 0.03903777524828911
step: 880, loss: 0.009937679395079613
step: 890, loss: 0.012025662697851658
step: 900, loss: 0.03777520731091499
step: 910, loss: 0.03428932651877403
step: 920, loss: 0.032301437109708786
step: 930, loss: 0.07146760821342468
step: 940, loss: 0.04060820862650871
step: 950, loss: 0.015427946113049984
step: 960, loss: 0.0037437856663018465
step: 970, loss: 0.05033198371529579
epoch 13: dev_f1=0.9365671641791044, f1=0.9301249421564091, best_f1=0.939435968562182
step: 0, loss: 0.06576332449913025
step: 10, loss: 0.05566467344760895
step: 20, loss: 0.07214111089706421
step: 30, loss: 0.06067820265889168
step: 40, loss: 0.101471908390522
step: 50, loss: 0.019124146550893784
step: 60, loss: 0.07078500837087631
step: 70, loss: 0.0003134148137178272
step: 80, loss: 0.051235493272542953
step: 90, loss: 0.02439987286925316
step: 100, loss: 0.013841291889548302
step: 110, loss: 0.08816321939229965
step: 120, loss: 0.026252929121255875
step: 130, loss: 0.09903259575366974
step: 140, loss: 0.039037324488162994
step: 150, loss: 0.03028251603245735
step: 160, loss: 0.008947823196649551
step: 170, loss: 0.026305105537176132
step: 180, loss: 0.09542764723300934
step: 190, loss: 0.09187760949134827
step: 200, loss: 0.10230275243520737
step: 210, loss: 0.09971535205841064
step: 220, loss: 0.057748954743146896
step: 230, loss: 0.04558359086513519
step: 240, loss: 0.008749308995902538
step: 250, loss: 0.07402803003787994
step: 260, loss: 0.06999943405389786
step: 270, loss: 0.031383149325847626
step: 280, loss: 0.03314730152487755
step: 290, loss: 0.01863802596926689
step: 300, loss: 0.0004129847511649132
step: 310, loss: 0.005872692912817001
step: 320, loss: 0.0141461081802845
step: 330, loss: 0.005232047755271196
step: 340, loss: 0.02426007017493248
step: 350, loss: 0.025006655603647232
step: 360, loss: 0.004559763241559267
step: 370, loss: 0.07394100725650787
step: 380, loss: 0.03367780148983002
step: 390, loss: 0.03590363264083862
step: 400, loss: 0.03249971941113472
step: 410, loss: 0.0489063635468483
step: 420, loss: 0.034856777638196945
step: 430, loss: 0.008199691772460938
step: 440, loss: 0.029927397146821022
step: 450, loss: 0.060559239238500595
step: 460, loss: 0.06396384537220001
step: 470, loss: 0.05451935902237892
step: 480, loss: 0.01705222949385643
step: 490, loss: 0.04552401602268219
step: 500, loss: 0.03721657395362854
step: 510, loss: 0.0057846549898386
step: 520, loss: 0.009336811490356922
step: 530, loss: 0.044876426458358765
step: 540, loss: 0.016613315790891647
step: 550, loss: 0.0029486450366675854
step: 560, loss: 0.08756665885448456
step: 570, loss: 0.044549405574798584
step: 580, loss: 0.062232933938503265
step: 590, loss: 0.01812194474041462
step: 600, loss: 0.016176261007785797
step: 610, loss: 0.00015493485261686146
step: 620, loss: 0.017364203929901123
step: 630, loss: 0.0063579208217561245
step: 640, loss: 0.05165882036089897
step: 650, loss: 0.0005824643303640187
step: 660, loss: 0.06060176342725754
step: 670, loss: 0.03426755219697952
step: 680, loss: 0.03784339129924774
step: 690, loss: 0.04840806871652603
step: 700, loss: 0.04829064756631851
step: 710, loss: 0.08424581587314606
step: 720, loss: 0.04246886819601059
step: 730, loss: 0.05030754581093788
step: 740, loss: 0.02412692829966545
step: 750, loss: 0.03603490814566612
step: 760, loss: 0.01869918406009674
step: 770, loss: 0.011234620586037636
step: 780, loss: 0.08311539888381958
step: 790, loss: 0.0017390428110957146
step: 800, loss: 0.0358455665409565
step: 810, loss: 0.02375020831823349
step: 820, loss: 9.857065379037522e-06
step: 830, loss: 0.06305065006017685
step: 840, loss: 0.048249974846839905
step: 850, loss: 0.14065730571746826
step: 860, loss: 0.05595139041543007
step: 870, loss: 0.05363123118877411
step: 880, loss: 0.02071334980428219
step: 890, loss: 0.03811619430780411
step: 900, loss: 0.0032478736247867346
step: 910, loss: 0.08592935651540756
step: 920, loss: 0.06739310175180435
step: 930, loss: 0.04226809740066528
step: 940, loss: 0.02412954345345497
step: 950, loss: 0.01577085070312023
step: 960, loss: 0.019332312047481537
step: 970, loss: 0.01678992435336113
epoch 14: dev_f1=0.9368863955119214, f1=0.9342592592592593, best_f1=0.939435968562182
step: 0, loss: 0.03860491141676903
step: 10, loss: 0.03268809989094734
step: 20, loss: 0.07323208451271057
step: 30, loss: 0.0018101574387401342
step: 40, loss: 0.040380217134952545
step: 50, loss: 0.056592341512441635
step: 60, loss: 0.021093379706144333
step: 70, loss: 0.02608974277973175
step: 80, loss: 0.0002229690144304186
step: 90, loss: 0.0005257040611468256
step: 100, loss: 0.009086200036108494
step: 110, loss: 0.05843415856361389
step: 120, loss: 0.030739398673176765
step: 130, loss: 0.007738661020994186
step: 140, loss: 0.08488735556602478
step: 150, loss: 0.026544004678726196
step: 160, loss: 0.06209642067551613
step: 170, loss: 0.0005934340879321098
step: 180, loss: 0.028436332941055298
step: 190, loss: 0.0853775292634964
step: 200, loss: 0.032418377697467804
step: 210, loss: 0.026199257001280785
step: 220, loss: 0.11661800742149353
step: 230, loss: 0.07820902019739151
step: 240, loss: 0.058434151113033295
step: 250, loss: 0.0011146200122311711
step: 260, loss: 8.051971963141114e-05
step: 270, loss: 0.0020125277806073427
step: 280, loss: 0.06969831138849258
step: 290, loss: 0.047752298414707184
step: 300, loss: 0.08001943677663803
step: 310, loss: 0.0036294881720095873
step: 320, loss: 0.03670618310570717
step: 330, loss: 0.03831429407000542
step: 340, loss: 0.006906701251864433
step: 350, loss: 0.1132575273513794
step: 360, loss: 0.02846708334982395
step: 370, loss: 0.074458546936512
step: 380, loss: 0.03874741494655609
step: 390, loss: 0.05165925249457359
step: 400, loss: 0.026369087398052216
step: 410, loss: 0.06567545980215073
step: 420, loss: 0.0014737764140591025
step: 430, loss: 0.04422528296709061
step: 440, loss: 0.05453610047698021
step: 450, loss: 0.023216620087623596
step: 460, loss: 0.016739290207624435
step: 470, loss: 5.262348349788226e-05
step: 480, loss: 0.01753886044025421
step: 490, loss: 0.008735396899282932
step: 500, loss: 0.0008808784768916667
step: 510, loss: 0.022895734757184982
step: 520, loss: 0.01901913806796074
step: 530, loss: 0.02829054929316044
step: 540, loss: 0.012187369167804718
step: 550, loss: 1.029292161547346e-05
step: 560, loss: 0.0261541698127985
step: 570, loss: 0.009792612865567207
step: 580, loss: 0.05570051819086075
step: 590, loss: 0.005936677101999521
step: 600, loss: 0.02609161101281643
step: 610, loss: 0.012685256078839302
step: 620, loss: 0.04216540604829788
step: 630, loss: 0.08833476155996323
step: 640, loss: 0.04411875829100609
step: 650, loss: 0.001988879172131419
step: 660, loss: 0.026100637391209602
step: 670, loss: 0.030859071761369705
step: 680, loss: 0.021003374829888344
step: 690, loss: 0.04900838062167168
step: 700, loss: 0.07183002680540085
step: 710, loss: 0.037443406879901886
step: 720, loss: 0.03688901290297508
step: 730, loss: 0.04928011819720268
step: 740, loss: 0.039274800568819046
step: 750, loss: 0.14257293939590454
step: 760, loss: 0.0023887723218649626
step: 770, loss: 0.007093582767993212
step: 780, loss: 0.002056992845609784
step: 790, loss: 0.038509517908096313
step: 800, loss: 0.10640015453100204
step: 810, loss: 0.027376577258110046
step: 820, loss: 0.08953216671943665
step: 830, loss: 0.07873107492923737
step: 840, loss: 0.1141907274723053
step: 850, loss: 0.055372703820466995
step: 860, loss: 9.335529284726363e-06
step: 870, loss: 0.03754129260778427
step: 880, loss: 0.02255907468497753
step: 890, loss: 0.12382947653532028
step: 900, loss: 0.04539823532104492
step: 910, loss: 0.07889987528324127
step: 920, loss: 0.0002259147586300969
step: 930, loss: 0.04321025684475899
step: 940, loss: 0.004860070999711752
step: 950, loss: 0.10257814824581146
step: 960, loss: 0.04010462015867233
step: 970, loss: 0.08589080721139908
epoch 15: dev_f1=0.935258500232883, f1=0.9288354898336414, best_f1=0.939435968562182
step: 0, loss: 0.03685807064175606
step: 10, loss: 0.05631810426712036
step: 20, loss: 0.06440089643001556
step: 30, loss: 0.01663348637521267
step: 40, loss: 0.02049444615840912
step: 50, loss: 0.0031864051707088947
step: 60, loss: 0.03181076794862747
step: 70, loss: 5.435977436718531e-05
step: 80, loss: 0.01903996616601944
step: 90, loss: 0.02287004142999649
step: 100, loss: 0.00033191029797308147
step: 110, loss: 0.0017218162538483739
step: 120, loss: 0.054518211632966995
step: 130, loss: 0.08294376730918884
step: 140, loss: 0.014842054806649685
step: 150, loss: 0.06675288081169128
step: 160, loss: 6.071344614611007e-05
step: 170, loss: 0.02428143098950386
step: 180, loss: 0.016297409310936928
step: 190, loss: 0.03222949802875519
step: 200, loss: 0.03734506294131279
step: 210, loss: 0.0011640720767900348
step: 220, loss: 0.04508599638938904
step: 230, loss: 0.04178905114531517
step: 240, loss: 0.02025989443063736
step: 250, loss: 0.009736794978380203
step: 260, loss: 0.03399809077382088
step: 270, loss: 0.10059522837400436
step: 280, loss: 0.00010674797522369772
step: 290, loss: 8.071231422945857e-05
step: 300, loss: 0.02443511039018631
step: 310, loss: 0.11086831241846085
step: 320, loss: 0.020276866853237152
step: 330, loss: 5.142674490343779e-05
step: 340, loss: 0.07483120262622833
step: 350, loss: 0.021606270223855972
step: 360, loss: 0.01802963577210903
step: 370, loss: 0.04108833894133568
step: 380, loss: 0.03852713853120804
step: 390, loss: 0.03937054052948952
step: 400, loss: 4.280867869965732e-05
step: 410, loss: 0.03807154297828674
step: 420, loss: 0.05225041136145592
step: 430, loss: 0.06475482136011124
step: 440, loss: 0.028762755915522575
step: 450, loss: 0.0002284871879965067
step: 460, loss: 0.11145317554473877
step: 470, loss: 0.054301708936691284
step: 480, loss: 0.09442365914583206
step: 490, loss: 0.0029029580764472485
step: 500, loss: 0.04745783284306526
step: 510, loss: 0.0276713315397501
step: 520, loss: 0.00014225346967577934
step: 530, loss: 0.016876231878995895
step: 540, loss: 0.06259985268115997
step: 550, loss: 0.06172226369380951
step: 560, loss: 0.00039372965693473816
step: 570, loss: 0.021284865215420723
step: 580, loss: 0.05745672434568405
step: 590, loss: 0.0003625302924774587
step: 600, loss: 0.0257815383374691
step: 610, loss: 0.019699057564139366
step: 620, loss: 0.0030552346725016832
step: 630, loss: 0.017647387459874153
step: 640, loss: 0.016009557992219925
step: 650, loss: 0.13040784001350403
step: 660, loss: 0.057396963238716125
step: 670, loss: 0.017489377409219742
step: 680, loss: 0.028507079929113388
step: 690, loss: 0.03183092549443245
step: 700, loss: 0.05825897678732872
step: 710, loss: 0.009906928986310959
step: 720, loss: 0.027965495362877846
step: 730, loss: 0.03144725039601326
step: 740, loss: 0.000999898067675531
step: 750, loss: 0.0014392315642908216
step: 760, loss: 0.05681908130645752
step: 770, loss: 0.002779353177174926
step: 780, loss: 0.0028755376115441322
step: 790, loss: 0.025393538177013397
step: 800, loss: 0.026440950110554695
step: 810, loss: 0.0566454716026783
step: 820, loss: 0.022519702091813087
step: 830, loss: 0.0914117693901062
step: 840, loss: 0.03835302218794823
step: 850, loss: 0.038092222064733505
step: 860, loss: 0.07895729690790176
step: 870, loss: 0.003985513933002949
step: 880, loss: 0.046106863766908646
step: 890, loss: 0.03455466777086258
step: 900, loss: 0.07513665407896042
step: 910, loss: 0.04684734344482422
step: 920, loss: 0.13860902190208435
step: 930, loss: 0.03014853037893772
step: 940, loss: 0.01948360539972782
step: 950, loss: 0.001303580473177135
step: 960, loss: 0.024948885664343834
step: 970, loss: 0.02976050041615963
epoch 16: dev_f1=0.9325789721829325, f1=0.9258741258741259, best_f1=0.939435968562182
step: 0, loss: 0.03374651446938515
step: 10, loss: 0.009013084694743156
step: 20, loss: 0.010332231409847736
step: 30, loss: 0.0002574071113485843
step: 40, loss: 0.013297416269779205
step: 50, loss: 0.005390793550759554
step: 60, loss: 0.0683753713965416
step: 70, loss: 0.0012373309582471848
step: 80, loss: 0.04880157485604286
step: 90, loss: 0.1257389932870865
step: 100, loss: 0.027620384469628334
step: 110, loss: 1.3142423995304853e-05
step: 120, loss: 0.016569245606660843
step: 130, loss: 0.051189813762903214
step: 140, loss: 0.0023148602340370417
step: 150, loss: 0.0405585952103138
step: 160, loss: 0.033623818308115005
step: 170, loss: 0.016398275271058083
step: 180, loss: 0.1167096495628357
step: 190, loss: 0.0002551321522332728
step: 200, loss: 0.10834395885467529
step: 210, loss: 0.10729728639125824
step: 220, loss: 0.04959353804588318
step: 230, loss: 0.0017484407871961594
step: 240, loss: 0.02731163799762726
step: 250, loss: 0.010864783078432083
step: 260, loss: 0.028374601155519485
step: 270, loss: 0.021245919167995453
step: 280, loss: 0.001464374247007072
step: 290, loss: 3.774675860768184e-05
step: 300, loss: 0.0013710606144741178
step: 310, loss: 0.02321537397801876
step: 320, loss: 0.03431154787540436
step: 330, loss: 5.1054550567641854e-05
step: 340, loss: 0.001903585041873157
step: 350, loss: 0.024733949452638626
step: 360, loss: 5.399746078182943e-05
step: 370, loss: 0.018930690363049507
step: 380, loss: 0.060646362602710724
step: 390, loss: 0.022364897653460503
step: 400, loss: 0.025519752874970436
step: 410, loss: 0.016956649720668793
step: 420, loss: 0.012770973145961761
step: 430, loss: 0.003927774727344513
step: 440, loss: 0.007132188882678747
step: 450, loss: 0.01230841875076294
step: 460, loss: 0.027658481150865555
step: 470, loss: 8.645791240269318e-05
step: 480, loss: 0.04752562567591667
step: 490, loss: 0.012570775113999844
step: 500, loss: 0.020996933802962303
step: 510, loss: 0.0006209358689375222
step: 520, loss: 9.791439515538514e-05
step: 530, loss: 0.04769497737288475
step: 540, loss: 0.02343093790113926
step: 550, loss: 0.01954128034412861
step: 560, loss: 0.00033964644535444677
step: 570, loss: 0.0018234775634482503
step: 580, loss: 0.004771596286445856
step: 590, loss: 0.0852794498205185
step: 600, loss: 0.03555683791637421
step: 610, loss: 0.00013197094085626304
step: 620, loss: 0.017080245539546013
step: 630, loss: 0.06511880457401276
step: 640, loss: 0.02327904850244522
step: 650, loss: 0.004004368092864752
step: 660, loss: 0.00016332679660990834
step: 670, loss: 0.03526876121759415
step: 680, loss: 0.00025228754384443164
step: 690, loss: 0.09110311418771744
step: 700, loss: 0.027554236352443695
step: 710, loss: 0.046870600432157516
step: 720, loss: 0.0433303527534008
step: 730, loss: 0.04576971381902695
step: 740, loss: 0.05994604155421257
step: 750, loss: 0.020025184378027916
step: 760, loss: 0.022961869835853577
step: 770, loss: 0.022172845900058746
step: 780, loss: 0.02149813063442707
step: 790, loss: 7.558708603028208e-05
step: 800, loss: 0.03078734315931797
step: 810, loss: 0.00011549015471246094
step: 820, loss: 0.0038814314175397158
step: 830, loss: 0.04540443792939186
step: 840, loss: 0.016903486102819443
step: 850, loss: 0.0005283627542667091
step: 860, loss: 0.0316496379673481
step: 870, loss: 0.045428331941366196
step: 880, loss: 0.001382011454552412
step: 890, loss: 0.030816208571195602
step: 900, loss: 5.725315349991433e-05
step: 910, loss: 0.04420161619782448
step: 920, loss: 0.13088497519493103
step: 930, loss: 0.022347576916217804
step: 940, loss: 0.005449923686683178
step: 950, loss: 0.02191673405468464
step: 960, loss: 0.026964319869875908
step: 970, loss: 0.055036671459674835
epoch 17: dev_f1=0.9317004239284032, f1=0.9282385834109972, best_f1=0.939435968562182
step: 0, loss: 9.213207522407174e-05
step: 10, loss: 0.0005329630803316832
step: 20, loss: 0.07758063822984695
step: 30, loss: 0.03658374771475792
step: 40, loss: 0.003383062547072768
step: 50, loss: 0.0698082372546196
step: 60, loss: 0.015072597190737724
step: 70, loss: 0.058293554931879044
step: 80, loss: 0.022951696068048477
step: 90, loss: 0.030437776818871498
step: 100, loss: 0.06275320798158646
step: 110, loss: 0.029403487220406532
step: 120, loss: 0.0013444566866382957
step: 130, loss: 0.023768220096826553
step: 140, loss: 0.038744330406188965
step: 150, loss: 0.026618648320436478
step: 160, loss: 0.0189508143812418
step: 170, loss: 0.021264050155878067
step: 180, loss: 0.029665615409612656
step: 190, loss: 0.009073270484805107
step: 200, loss: 0.0001911386934807524
step: 210, loss: 0.024664148688316345
step: 220, loss: 2.355115611862857e-05
step: 230, loss: 0.032338108867406845
step: 240, loss: 0.015632150694727898
step: 250, loss: 0.0005790091236121953
step: 260, loss: 0.0004545709816738963
step: 270, loss: 0.00012214451271574944
step: 280, loss: 5.326046084519476e-05
step: 290, loss: 0.00011141166760353372
step: 300, loss: 0.09135349839925766
step: 310, loss: 0.00023734293063171208
step: 320, loss: 0.06383661925792694
step: 330, loss: 0.04416237771511078
step: 340, loss: 0.00010869676771108061
step: 350, loss: 0.06466800719499588
step: 360, loss: 0.12394259124994278
step: 370, loss: 0.06067487969994545
step: 380, loss: 0.007948944345116615
step: 390, loss: 0.0010025860974565148
step: 400, loss: 0.0005523300496861339
step: 410, loss: 6.793761713197455e-05
step: 420, loss: 0.03349032998085022
step: 430, loss: 0.0019643944688141346
step: 440, loss: 0.05088980123400688
step: 450, loss: 0.12655125558376312
step: 460, loss: 0.04292061924934387
step: 470, loss: 0.05226314440369606
step: 480, loss: 0.02525998465716839
step: 490, loss: 0.060782644897699356
step: 500, loss: 0.05936901271343231
step: 510, loss: 0.020915821194648743
step: 520, loss: 0.0013930225977674127
step: 530, loss: 0.008645592257380486
step: 540, loss: 0.018528303131461143
step: 550, loss: 0.009772732853889465
step: 560, loss: 0.034965142607688904
step: 570, loss: 5.329444684321061e-05
step: 580, loss: 0.00033771645394153893
step: 590, loss: 0.05388094112277031
step: 600, loss: 0.07512164860963821
step: 610, loss: 0.06794993579387665
step: 620, loss: 0.022262897342443466
step: 630, loss: 0.07887750118970871
step: 640, loss: 0.10032451897859573
step: 650, loss: 0.032169923186302185
step: 660, loss: 0.01609809696674347
step: 670, loss: 0.0006615067250095308
step: 680, loss: 0.025613954290747643
step: 690, loss: 2.4597329684183933e-05
step: 700, loss: 0.028009578585624695
step: 710, loss: 0.03358907625079155
step: 720, loss: 0.02701559104025364
step: 730, loss: 0.0005316913011483848
step: 740, loss: 0.029134029522538185
step: 750, loss: 0.06313412636518478
step: 760, loss: 2.923598003690131e-05
step: 770, loss: 0.14951905608177185
step: 780, loss: 0.061200253665447235
step: 790, loss: 8.035418431973085e-06
step: 800, loss: 0.055780962109565735
step: 810, loss: 0.05969926714897156
step: 820, loss: 0.033324357122182846
step: 830, loss: 0.0011217989958822727
step: 840, loss: 0.03854459896683693
step: 850, loss: 8.0726695159683e-06
step: 860, loss: 2.2314728994388133e-05
step: 870, loss: 0.039516717195510864
step: 880, loss: 3.006247425219044e-05
step: 890, loss: 0.04628044739365578
step: 900, loss: 0.05347319319844246
step: 910, loss: 0.05423775315284729
step: 920, loss: 0.03910277038812637
step: 930, loss: 0.028176093474030495
step: 940, loss: 0.0003516118158586323
step: 950, loss: 0.05866360664367676
step: 960, loss: 1.4665713024442084e-05
step: 970, loss: 0.028352634981274605
epoch 18: dev_f1=0.9356505401596994, f1=0.9294062646096307, best_f1=0.939435968562182
step: 0, loss: 0.03126034513115883
step: 10, loss: 0.04621401056647301
step: 20, loss: 0.002133519621565938
step: 30, loss: 0.0033106766641139984
step: 40, loss: 0.03171412646770477
step: 50, loss: 0.00457659550011158
step: 60, loss: 5.467688606586307e-05
step: 70, loss: 0.00011511142656672746
step: 80, loss: 0.04204258322715759
step: 90, loss: 0.010680265724658966
step: 100, loss: 0.040146779268980026
step: 110, loss: 0.017443297430872917
step: 120, loss: 0.07632334530353546
step: 130, loss: 0.0002167868078686297
step: 140, loss: 0.03498243913054466
step: 150, loss: 0.06970714777708054
step: 160, loss: 0.04936002194881439
step: 170, loss: 0.05048516392707825
step: 180, loss: 0.033478155732154846
step: 190, loss: 0.0016623262781649828
step: 200, loss: 0.017557838931679726
step: 210, loss: 0.01607201248407364
step: 220, loss: 0.012736916542053223
step: 230, loss: 0.05406738445162773
step: 240, loss: 0.09832251816987991
step: 250, loss: 7.975814696692396e-06
step: 260, loss: 0.01504173781722784
step: 270, loss: 0.07383061945438385
step: 280, loss: 0.01094333827495575
step: 290, loss: 0.02553017996251583
step: 300, loss: 0.016991617158055305
step: 310, loss: 0.0001466315152356401
step: 320, loss: 0.00025207840371876955
step: 330, loss: 0.002402174985036254
step: 340, loss: 0.040599461644887924
step: 350, loss: 0.06778337061405182
step: 360, loss: 0.0019108997657895088
step: 370, loss: 0.10166767984628677
step: 380, loss: 0.02549407072365284
step: 390, loss: 0.05519314855337143
step: 400, loss: 0.01979438029229641
step: 410, loss: 0.02375282719731331
step: 420, loss: 0.00034140070783905685
step: 430, loss: 0.047556374222040176
step: 440, loss: 0.0297244880348444
step: 450, loss: 6.093427509767935e-05
step: 460, loss: 0.025785231962800026
step: 470, loss: 0.005392472259700298
step: 480, loss: 0.00019022513879463077
step: 490, loss: 0.06263581663370132
step: 500, loss: 8.63244422362186e-05
step: 510, loss: 0.017508933320641518
step: 520, loss: 0.03428144380450249
step: 530, loss: 0.042649105191230774
step: 540, loss: 0.028432033956050873
step: 550, loss: 0.02944827266037464
step: 560, loss: 0.04987023398280144
step: 570, loss: 0.01308654248714447
step: 580, loss: 0.020549310371279716
step: 590, loss: 0.019896436482667923
step: 600, loss: 0.04715467244386673
step: 610, loss: 0.005027353763580322
step: 620, loss: 0.00042739679338410497
step: 630, loss: 0.006310760043561459
step: 640, loss: 0.00033340355730615556
step: 650, loss: 0.046447496861219406
step: 660, loss: 0.036314934492111206
step: 670, loss: 0.020079825073480606
step: 680, loss: 0.005298006813973188
step: 690, loss: 2.2308573534246534e-05
step: 700, loss: 0.018891632556915283
step: 710, loss: 0.03950181603431702
step: 720, loss: 0.035980042070150375
step: 730, loss: 0.028420347720384598
step: 740, loss: 0.00033757585333660245
step: 750, loss: 0.043554384261369705
step: 760, loss: 0.01604684256017208
step: 770, loss: 0.0002967870677821338
step: 780, loss: 0.05340747907757759
step: 790, loss: 0.027272172272205353
step: 800, loss: 0.02385314181447029
step: 810, loss: 0.11736910045146942
step: 820, loss: 2.823024260578677e-05
step: 830, loss: 0.0546780526638031
step: 840, loss: 0.02519984543323517
step: 850, loss: 2.6025631086668e-05
step: 860, loss: 0.012431299313902855
step: 870, loss: 0.025855662301182747
step: 880, loss: 0.027790633961558342
step: 890, loss: 6.827039760537446e-05
step: 900, loss: 0.04446287080645561
step: 910, loss: 0.027093935757875443
step: 920, loss: 0.04505155235528946
step: 930, loss: 0.033046476542949677
step: 940, loss: 0.0009454829269088805
step: 950, loss: 0.01523398794233799
step: 960, loss: 0.02141464315354824
step: 970, loss: 0.027053793892264366
epoch 19: dev_f1=0.936470588235294, f1=0.9279700654817586, best_f1=0.939435968562182
step: 0, loss: 7.110415754141286e-05
step: 10, loss: 0.016002291813492775
step: 20, loss: 5.059436443843879e-05
step: 30, loss: 0.02377679944038391
step: 40, loss: 0.022897271439433098
step: 50, loss: 2.1987349100527354e-05
step: 60, loss: 0.04083779826760292
step: 70, loss: 0.06782672554254532
step: 80, loss: 0.03886368125677109
step: 90, loss: 7.814494892954826e-05
step: 100, loss: 7.670783088542521e-05
step: 110, loss: 0.029954086989164352
step: 120, loss: 0.012975543737411499
step: 130, loss: 0.02375577576458454
step: 140, loss: 0.04766971990466118
step: 150, loss: 0.01382831297814846
step: 160, loss: 0.00022083858493715525
step: 170, loss: 0.025205211713910103
step: 180, loss: 0.020078321918845177
step: 190, loss: 0.14301374554634094
step: 200, loss: 6.417009717551991e-05
step: 210, loss: 0.00018865859601646662
step: 220, loss: 0.029100142419338226
step: 230, loss: 0.031084194779396057
step: 240, loss: 0.02364535629749298
step: 250, loss: 0.01853710040450096
step: 260, loss: 2.463817327225115e-05
step: 270, loss: 0.02458321675658226
step: 280, loss: 0.04508388042449951
step: 290, loss: 7.135282794479281e-05
step: 300, loss: 0.05109822005033493
step: 310, loss: 6.439249409595504e-05
step: 320, loss: 0.0524907186627388
step: 330, loss: 0.036066360771656036
step: 340, loss: 0.0001235343370353803
step: 350, loss: 0.004433739464730024
step: 360, loss: 0.04386207088828087
step: 370, loss: 0.013044952414929867
step: 380, loss: 0.01978418603539467
step: 390, loss: 0.022260822355747223
step: 400, loss: 9.627215331420302e-05
step: 410, loss: 0.034016966819763184
step: 420, loss: 0.02065878175199032
step: 430, loss: 0.01714351214468479
step: 440, loss: 0.02932080812752247
step: 450, loss: 1.9976479961769655e-05
step: 460, loss: 0.001833630376495421
step: 470, loss: 0.021877313032746315
step: 480, loss: 0.0004775415582116693
step: 490, loss: 0.00011631802772171795
step: 500, loss: 0.05968635901808739
step: 510, loss: 0.021142352372407913
step: 520, loss: 0.037307750433683395
step: 530, loss: 7.154582999646664e-05
step: 540, loss: 7.655441550014075e-06
step: 550, loss: 0.03702044114470482
step: 560, loss: 0.03281787037849426
step: 570, loss: 0.028200889006257057
step: 580, loss: 0.0392867736518383
step: 590, loss: 0.0059867058880627155
step: 600, loss: 0.04416315257549286
step: 610, loss: 0.06628124415874481
step: 620, loss: 2.2114869352662936e-05
step: 630, loss: 0.03502136468887329
step: 640, loss: 0.000642474100459367
step: 650, loss: 0.027187075465917587
step: 660, loss: 0.02786659076809883
step: 670, loss: 0.04215927794575691
step: 680, loss: 0.02822539396584034
step: 690, loss: 0.06208876520395279
step: 700, loss: 0.00020662932365667075
step: 710, loss: 0.02873278595507145
step: 720, loss: 0.018944522365927696
step: 730, loss: 0.02392336167395115
step: 740, loss: 0.005683131515979767
step: 750, loss: 0.01843366026878357
step: 760, loss: 0.05024024844169617
step: 770, loss: 0.020577268674969673
step: 780, loss: 8.71902157086879e-05
step: 790, loss: 0.00015930697554722428
step: 800, loss: 0.017045559361577034
step: 810, loss: 0.04437941312789917
step: 820, loss: 0.053783565759658813
step: 830, loss: 0.03323071077466011
step: 840, loss: 0.0361601747572422
step: 850, loss: 0.06991606950759888
step: 860, loss: 1.5473904568352737e-05
step: 870, loss: 0.03151051700115204
step: 880, loss: 0.0004727669875137508
step: 890, loss: 0.03645234555006027
step: 900, loss: 0.019387930631637573
step: 910, loss: 0.006253174040466547
step: 920, loss: 0.06298914551734924
step: 930, loss: 0.0012805690057575703
step: 940, loss: 0.018398761749267578
step: 950, loss: 7.432138954754919e-05
step: 960, loss: 3.417364496272057e-05
step: 970, loss: 0.02178070694208145
epoch 20: dev_f1=0.9344030202925908, f1=0.9248014946286782, best_f1=0.939435968562182
