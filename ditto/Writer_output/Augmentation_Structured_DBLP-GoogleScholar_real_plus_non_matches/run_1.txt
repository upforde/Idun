cuda
Device: cuda
step: 0, loss: 0.7352796196937561
step: 10, loss: 0.2646401822566986
step: 20, loss: 0.3826114535331726
step: 30, loss: 0.1525193750858307
step: 40, loss: 0.2690606117248535
step: 50, loss: 0.2324388474225998
step: 60, loss: 0.22731707990169525
step: 70, loss: 0.2020532339811325
step: 80, loss: 0.10918206721544266
step: 90, loss: 0.1292915940284729
step: 100, loss: 0.20245561003684998
step: 110, loss: 0.26152145862579346
step: 120, loss: 0.1314459890127182
step: 130, loss: 0.09158758074045181
step: 140, loss: 0.045443687587976456
step: 150, loss: 0.05211508646607399
step: 160, loss: 0.09990289807319641
step: 170, loss: 0.08382320404052734
step: 180, loss: 0.14913809299468994
step: 190, loss: 0.05785658210515976
step: 200, loss: 0.06228816509246826
step: 210, loss: 0.10267679393291473
step: 220, loss: 0.0826982632279396
step: 230, loss: 0.22008231282234192
step: 240, loss: 0.3309307098388672
step: 250, loss: 0.02838200330734253
step: 260, loss: 0.23597347736358643
step: 270, loss: 0.08345717191696167
step: 280, loss: 0.1584663838148117
step: 290, loss: 0.10967429727315903
step: 300, loss: 0.153399258852005
step: 310, loss: 0.03124227188527584
step: 320, loss: 0.16490283608436584
step: 330, loss: 0.07689535617828369
step: 340, loss: 0.1183229386806488
step: 350, loss: 0.13866399228572845
step: 360, loss: 0.09729447215795517
step: 370, loss: 0.09321167320013046
step: 380, loss: 0.16824749112129211
step: 390, loss: 0.1207125335931778
step: 400, loss: 0.07374119758605957
step: 410, loss: 0.11111358553171158
step: 420, loss: 0.1363162100315094
step: 430, loss: 0.15671701729297638
step: 440, loss: 0.1688356101512909
step: 450, loss: 0.3202919065952301
step: 460, loss: 0.1362122744321823
step: 470, loss: 0.010658441111445427
step: 480, loss: 0.07724929600954056
step: 490, loss: 0.08243849873542786
step: 500, loss: 0.18832924962043762
step: 510, loss: 0.08654855191707611
step: 520, loss: 0.04711952060461044
step: 530, loss: 0.03627421334385872
step: 540, loss: 0.11311406642198563
step: 550, loss: 0.052937962114810944
step: 560, loss: 0.129774808883667
step: 570, loss: 0.06474775820970535
step: 580, loss: 0.2144508808851242
step: 590, loss: 0.12633733451366425
step: 600, loss: 0.07345696538686752
step: 610, loss: 0.04746043309569359
step: 620, loss: 0.11165332794189453
step: 630, loss: 0.06820525974035263
step: 640, loss: 0.14364047348499298
step: 650, loss: 0.10967548191547394
step: 660, loss: 0.14141641557216644
step: 670, loss: 0.08141134679317474
step: 680, loss: 0.1625903993844986
step: 690, loss: 0.049435749650001526
step: 700, loss: 0.09928028285503387
step: 710, loss: 0.16411055624485016
step: 720, loss: 0.3662116229534149
step: 730, loss: 0.05397867038846016
step: 740, loss: 0.17499080300331116
step: 750, loss: 0.13152697682380676
step: 760, loss: 0.0685926228761673
step: 770, loss: 0.07566272467374802
step: 780, loss: 0.2224293202161789
step: 790, loss: 0.03948686644434929
step: 800, loss: 0.12418778985738754
step: 810, loss: 0.15345793962478638
step: 820, loss: 0.13793683052062988
step: 830, loss: 0.10082684457302094
step: 840, loss: 0.050361331552267075
step: 850, loss: 0.2018084079027176
step: 860, loss: 0.06936104595661163
step: 870, loss: 0.11674362421035767
step: 880, loss: 0.09029846638441086
step: 890, loss: 0.21847818791866302
step: 900, loss: 0.04949517920613289
step: 910, loss: 0.07528875768184662
step: 920, loss: 0.24802695214748383
step: 930, loss: 0.06762270629405975
step: 940, loss: 0.07925432920455933
step: 950, loss: 0.05959967523813248
step: 960, loss: 0.08567790687084198
step: 970, loss: 0.02131960354745388
epoch 1: dev_f1=0.9284738041002277, f1=0.9222423146473779, best_f1=0.9222423146473779
step: 0, loss: 0.02949821949005127
step: 10, loss: 0.05631386488676071
step: 20, loss: 0.13369128108024597
step: 30, loss: 0.01072777807712555
step: 40, loss: 0.07127191126346588
step: 50, loss: 0.02219242788851261
step: 60, loss: 0.10182712227106094
step: 70, loss: 0.21288512647151947
step: 80, loss: 0.031040098518133163
step: 90, loss: 0.10605424642562866
step: 100, loss: 0.09869052469730377
step: 110, loss: 0.08886738121509552
step: 120, loss: 0.09557018429040909
step: 130, loss: 0.16937768459320068
step: 140, loss: 0.05816280469298363
step: 150, loss: 0.07774145156145096
step: 160, loss: 0.10203085839748383
step: 170, loss: 0.045220136642456055
step: 180, loss: 0.058025114238262177
step: 190, loss: 0.07553555816411972
step: 200, loss: 0.06452495604753494
step: 210, loss: 0.1253337413072586
step: 220, loss: 0.2008136510848999
step: 230, loss: 0.06607864797115326
step: 240, loss: 0.00792604498565197
step: 250, loss: 0.11566407978534698
step: 260, loss: 0.165948286652565
step: 270, loss: 0.09075786918401718
step: 280, loss: 0.148069828748703
step: 290, loss: 0.17458337545394897
step: 300, loss: 0.19417129456996918
step: 310, loss: 0.10581616312265396
step: 320, loss: 0.07001130282878876
step: 330, loss: 0.12838774919509888
step: 340, loss: 0.020248468965291977
step: 350, loss: 0.07177327573299408
step: 360, loss: 0.06414777040481567
step: 370, loss: 0.2109406441450119
step: 380, loss: 0.05039656162261963
step: 390, loss: 0.07424642145633698
step: 400, loss: 0.01963360607624054
step: 410, loss: 0.12358023971319199
step: 420, loss: 0.16911998391151428
step: 430, loss: 0.11040285974740982
step: 440, loss: 0.05780472606420517
step: 450, loss: 0.01949564553797245
step: 460, loss: 0.038478247821331024
step: 470, loss: 0.05336936563253403
step: 480, loss: 0.10432056337594986
step: 490, loss: 0.016357354819774628
step: 500, loss: 0.07774616777896881
step: 510, loss: 0.06299873441457748
step: 520, loss: 0.13656437397003174
step: 530, loss: 0.08969488739967346
step: 540, loss: 0.04177597537636757
step: 550, loss: 0.01517797913402319
step: 560, loss: 0.028857454657554626
step: 570, loss: 0.020939717069268227
step: 580, loss: 0.16974398493766785
step: 590, loss: 0.08257416635751724
step: 600, loss: 0.043946001678705215
step: 610, loss: 0.16701722145080566
step: 620, loss: 0.03634978085756302
step: 630, loss: 0.06746374815702438
step: 640, loss: 0.14484389126300812
step: 650, loss: 0.09376290440559387
step: 660, loss: 0.03892199695110321
step: 670, loss: 0.08095863461494446
step: 680, loss: 0.15675733983516693
step: 690, loss: 0.10056493431329727
step: 700, loss: 0.16229957342147827
step: 710, loss: 0.06873823702335358
step: 720, loss: 0.1130024641752243
step: 730, loss: 0.13840952515602112
step: 740, loss: 0.048830296844244
step: 750, loss: 0.049360137432813644
step: 760, loss: 0.06543262302875519
step: 770, loss: 0.10538153350353241
step: 780, loss: 0.2078375667333603
step: 790, loss: 0.06936825811862946
step: 800, loss: 0.17034687101840973
step: 810, loss: 0.04171595349907875
step: 820, loss: 0.0832040011882782
step: 830, loss: 0.11594356596469879
step: 840, loss: 0.03583760932087898
step: 850, loss: 0.07954361289739609
step: 860, loss: 0.10987445712089539
step: 870, loss: 0.07401963323354721
step: 880, loss: 0.1216731145977974
step: 890, loss: 0.18713796138763428
step: 900, loss: 0.07025294750928879
step: 910, loss: 0.08974376320838928
step: 920, loss: 0.14516369998455048
step: 930, loss: 0.10101190954446793
step: 940, loss: 0.08065369725227356
step: 950, loss: 0.14594382047653198
step: 960, loss: 0.030407961457967758
step: 970, loss: 0.2398286759853363
epoch 2: dev_f1=0.9276018099547513, f1=0.9239081494822152, best_f1=0.9222423146473779
step: 0, loss: 0.20859946310520172
step: 10, loss: 0.1453699767589569
step: 20, loss: 0.04457975551486015
step: 30, loss: 0.08400154113769531
step: 40, loss: 0.06229080259799957
step: 50, loss: 0.04696446284651756
step: 60, loss: 0.09950797259807587
step: 70, loss: 0.12596379220485687
step: 80, loss: 0.029486745595932007
step: 90, loss: 0.04418158531188965
step: 100, loss: 0.08220542222261429
step: 110, loss: 0.06886902451515198
step: 120, loss: 0.09902600944042206
step: 130, loss: 0.07014814764261246
step: 140, loss: 0.1033322662115097
step: 150, loss: 0.034239619970321655
step: 160, loss: 0.11742470413446426
step: 170, loss: 0.0706510990858078
step: 180, loss: 0.03940599039196968
step: 190, loss: 0.05855210870504379
step: 200, loss: 0.10578055679798126
step: 210, loss: 0.05404988303780556
step: 220, loss: 0.04765448719263077
step: 230, loss: 0.013367259874939919
step: 240, loss: 0.042458321899175644
step: 250, loss: 0.026438798755407333
step: 260, loss: 0.015823272988200188
step: 270, loss: 0.013892443850636482
step: 280, loss: 0.024574052542448044
step: 290, loss: 0.014145296066999435
step: 300, loss: 0.02551177702844143
step: 310, loss: 0.05201347917318344
step: 320, loss: 0.11528673768043518
step: 330, loss: 0.06345564126968384
step: 340, loss: 0.17474007606506348
step: 350, loss: 0.04158049821853638
step: 360, loss: 0.13510003685951233
step: 370, loss: 0.027831073850393295
step: 380, loss: 0.07997750490903854
step: 390, loss: 0.11045899242162704
step: 400, loss: 0.1394350528717041
step: 410, loss: 0.12609192728996277
step: 420, loss: 0.09831537306308746
step: 430, loss: 0.14239491522312164
step: 440, loss: 0.10802679508924484
step: 450, loss: 0.027404295280575752
step: 460, loss: 0.18120084702968597
step: 470, loss: 0.014654295518994331
step: 480, loss: 0.08487915992736816
step: 490, loss: 0.016400832682847977
step: 500, loss: 0.06362643092870712
step: 510, loss: 0.023808810859918594
step: 520, loss: 0.08735030144453049
step: 530, loss: 0.0810670480132103
step: 540, loss: 0.03861284255981445
step: 550, loss: 0.06440224498510361
step: 560, loss: 0.015577712096273899
step: 570, loss: 0.3355177342891693
step: 580, loss: 0.0490332655608654
step: 590, loss: 0.047350943088531494
step: 600, loss: 0.0678098276257515
step: 610, loss: 0.04857955873012543
step: 620, loss: 0.08026184141635895
step: 630, loss: 0.15044617652893066
step: 640, loss: 0.0438157357275486
step: 650, loss: 0.025032516568899155
step: 660, loss: 0.20995886623859406
step: 670, loss: 0.09818486124277115
step: 680, loss: 0.012135196477174759
step: 690, loss: 0.04847383499145508
step: 700, loss: 0.08787529915571213
step: 710, loss: 0.13556522130966187
step: 720, loss: 0.06388166546821594
step: 730, loss: 0.0974089577794075
step: 740, loss: 0.0568428635597229
step: 750, loss: 0.019964857026934624
step: 760, loss: 0.020794717594981194
step: 770, loss: 0.14849773049354553
step: 780, loss: 0.14821334183216095
step: 790, loss: 0.06600308418273926
step: 800, loss: 0.08453334867954254
step: 810, loss: 0.05310468003153801
step: 820, loss: 0.0937962457537651
step: 830, loss: 0.04084256291389465
step: 840, loss: 0.19538956880569458
step: 850, loss: 0.05207882821559906
step: 860, loss: 0.1265573650598526
step: 870, loss: 0.089656300842762
step: 880, loss: 0.13535070419311523
step: 890, loss: 0.03723359480500221
step: 900, loss: 0.043856024742126465
step: 910, loss: 0.06184143200516701
step: 920, loss: 0.2859158515930176
step: 930, loss: 0.04636518657207489
step: 940, loss: 0.018663307651877403
step: 950, loss: 0.011082721874117851
step: 960, loss: 0.0790511965751648
step: 970, loss: 0.053786106407642365
epoch 3: dev_f1=0.9337626494940202, f1=0.9306569343065694, best_f1=0.9306569343065694
step: 0, loss: 0.10140235722064972
step: 10, loss: 0.1026451587677002
step: 20, loss: 0.021546075120568275
step: 30, loss: 0.05818847939372063
step: 40, loss: 0.11536908149719238
step: 50, loss: 0.07945920526981354
step: 60, loss: 0.08930478245019913
step: 70, loss: 0.14138484001159668
step: 80, loss: 0.13184134662151337
step: 90, loss: 0.14324815571308136
step: 100, loss: 0.24341893196105957
step: 110, loss: 0.11548684537410736
step: 120, loss: 0.11114666610956192
step: 130, loss: 0.16193018853664398
step: 140, loss: 0.15778711438179016
step: 150, loss: 0.0882076621055603
step: 160, loss: 0.037963658571243286
step: 170, loss: 0.018563104793429375
step: 180, loss: 0.08748141676187515
step: 190, loss: 0.1174609363079071
step: 200, loss: 0.013957012444734573
step: 210, loss: 0.12885135412216187
step: 220, loss: 0.02246692404150963
step: 230, loss: 0.03003241866827011
step: 240, loss: 0.015803012996912003
step: 250, loss: 0.19018502533435822
step: 260, loss: 0.09959078580141068
step: 270, loss: 0.13811095058918
step: 280, loss: 0.020446499809622765
step: 290, loss: 0.1414940357208252
step: 300, loss: 0.007146329618990421
step: 310, loss: 0.05408962070941925
step: 320, loss: 0.09783120453357697
step: 330, loss: 0.05246506258845329
step: 340, loss: 0.03799176961183548
step: 350, loss: 0.035537902265787125
step: 360, loss: 0.13450832664966583
step: 370, loss: 0.044761527329683304
step: 380, loss: 0.07213886827230453
step: 390, loss: 0.07488646358251572
step: 400, loss: 0.024389788508415222
step: 410, loss: 0.08955308794975281
step: 420, loss: 0.07075722515583038
step: 430, loss: 0.08884815126657486
step: 440, loss: 0.05613986775279045
step: 450, loss: 0.020103147253394127
step: 460, loss: 0.02819759212434292
step: 470, loss: 0.010577298700809479
step: 480, loss: 0.11909815669059753
step: 490, loss: 0.06034933030605316
step: 500, loss: 0.01737656258046627
step: 510, loss: 0.04975306987762451
step: 520, loss: 0.11384667456150055
step: 530, loss: 0.00539172999560833
step: 540, loss: 0.019921189174056053
step: 550, loss: 0.08070366084575653
step: 560, loss: 0.0843072310090065
step: 570, loss: 0.06223081424832344
step: 580, loss: 0.03447272256016731
step: 590, loss: 0.1377522200345993
step: 600, loss: 0.29472413659095764
step: 610, loss: 0.11876445263624191
step: 620, loss: 0.1286596655845642
step: 630, loss: 0.0572100393474102
step: 640, loss: 0.09985910356044769
step: 650, loss: 0.06599949300289154
step: 660, loss: 0.05741572007536888
step: 670, loss: 0.10562179982662201
step: 680, loss: 0.04667931795120239
step: 690, loss: 0.08272374421358109
step: 700, loss: 0.024415701627731323
step: 710, loss: 0.07621592283248901
step: 720, loss: 0.0646628737449646
step: 730, loss: 0.024381671100854874
step: 740, loss: 0.1729426085948944
step: 750, loss: 0.12227582931518555
step: 760, loss: 0.04553017392754555
step: 770, loss: 0.04755742475390434
step: 780, loss: 0.0696033239364624
step: 790, loss: 0.010519307106733322
step: 800, loss: 0.055440932512283325
step: 810, loss: 0.08962357044219971
step: 820, loss: 0.036256205290555954
step: 830, loss: 0.06923703104257584
step: 840, loss: 0.0681961327791214
step: 850, loss: 0.017249174416065216
step: 860, loss: 0.06606758385896683
step: 870, loss: 0.03888790309429169
step: 880, loss: 0.05960260331630707
step: 890, loss: 0.033712588250637054
step: 900, loss: 0.16391271352767944
step: 910, loss: 0.12114979326725006
step: 920, loss: 0.1100868433713913
step: 930, loss: 0.11436972767114639
step: 940, loss: 0.04872315004467964
step: 950, loss: 0.03067593462765217
step: 960, loss: 0.0953143835067749
step: 970, loss: 0.08585571497678757
epoch 4: dev_f1=0.937095282146161, f1=0.934622467771639, best_f1=0.934622467771639
step: 0, loss: 0.05341752618551254
step: 10, loss: 0.11444740742444992
step: 20, loss: 0.10847283899784088
step: 30, loss: 0.05305332690477371
step: 40, loss: 0.139243021607399
step: 50, loss: 0.05176165699958801
step: 60, loss: 0.03204774484038353
step: 70, loss: 0.040812741965055466
step: 80, loss: 0.13496151566505432
step: 90, loss: 0.03507966548204422
step: 100, loss: 0.02667083591222763
step: 110, loss: 0.08246919512748718
step: 120, loss: 0.018019041046500206
step: 130, loss: 0.09252972155809402
step: 140, loss: 0.11143705993890762
step: 150, loss: 0.02723260596394539
step: 160, loss: 0.09367290884256363
step: 170, loss: 0.030292682349681854
step: 180, loss: 0.06536473333835602
step: 190, loss: 0.14075514674186707
step: 200, loss: 0.09915214776992798
step: 210, loss: 0.08133941888809204
step: 220, loss: 0.08360081166028976
step: 230, loss: 0.03654320910573006
step: 240, loss: 0.1141190379858017
step: 250, loss: 0.0064666722901165485
step: 260, loss: 0.031845610588788986
step: 270, loss: 0.02539229393005371
step: 280, loss: 0.09615162760019302
step: 290, loss: 0.05113924294710159
step: 300, loss: 0.17845121026039124
step: 310, loss: 0.022059373557567596
step: 320, loss: 0.08519984036684036
step: 330, loss: 0.040975552052259445
step: 340, loss: 0.05482585355639458
step: 350, loss: 0.1426900178194046
step: 360, loss: 0.0195568036288023
step: 370, loss: 0.11424797028303146
step: 380, loss: 0.025325624272227287
step: 390, loss: 0.009877567179501057
step: 400, loss: 0.07058250159025192
step: 410, loss: 0.019741550087928772
step: 420, loss: 0.09979242831468582
step: 430, loss: 0.21674008667469025
step: 440, loss: 0.06856633722782135
step: 450, loss: 0.11148388683795929
step: 460, loss: 0.09474455565214157
step: 470, loss: 0.01683238334953785
step: 480, loss: 0.07908063381910324
step: 490, loss: 0.11441566795110703
step: 500, loss: 0.006079445127397776
step: 510, loss: 0.024171682074666023
step: 520, loss: 0.12890230119228363
step: 530, loss: 0.03513190895318985
step: 540, loss: 0.22697137296199799
step: 550, loss: 0.04753817990422249
step: 560, loss: 0.045901644974946976
step: 570, loss: 0.0161591749638319
step: 580, loss: 0.1008436307311058
step: 590, loss: 0.12740477919578552
step: 600, loss: 0.12450316548347473
step: 610, loss: 0.04938705265522003
step: 620, loss: 0.027664633467793465
step: 630, loss: 0.09135913848876953
step: 640, loss: 0.12868623435497284
step: 650, loss: 0.05492548644542694
step: 660, loss: 0.12681439518928528
step: 670, loss: 0.04561041668057442
step: 680, loss: 0.0924336388707161
step: 690, loss: 0.004708053544163704
step: 700, loss: 0.0789996013045311
step: 710, loss: 0.04685591161251068
step: 720, loss: 0.05982517451047897
step: 730, loss: 0.13971446454524994
step: 740, loss: 0.07436615973711014
step: 750, loss: 0.07928967475891113
step: 760, loss: 0.08960194140672684
step: 770, loss: 0.17906609177589417
step: 780, loss: 0.07245081663131714
step: 790, loss: 0.02664792165160179
step: 800, loss: 0.1459599733352661
step: 810, loss: 0.0002207818761235103
step: 820, loss: 0.028923990204930305
step: 830, loss: 0.08094525337219238
step: 840, loss: 0.07465259730815887
step: 850, loss: 0.06861545145511627
step: 860, loss: 0.037738651037216187
step: 870, loss: 0.0577767938375473
step: 880, loss: 0.09705660492181778
step: 890, loss: 0.15045863389968872
step: 900, loss: 0.020759062841534615
step: 910, loss: 0.06762263923883438
step: 920, loss: 0.08084770292043686
step: 930, loss: 0.11566782742738724
step: 940, loss: 0.12556229531764984
step: 950, loss: 0.15908183157444
step: 960, loss: 0.014346896670758724
step: 970, loss: 0.0827910527586937
epoch 5: dev_f1=0.9289411764705882, f1=0.9174825174825175, best_f1=0.934622467771639
step: 0, loss: 0.06651123613119125
step: 10, loss: 0.007076223846524954
step: 20, loss: 0.18459828197956085
step: 30, loss: 0.026355654001235962
step: 40, loss: 0.07856480032205582
step: 50, loss: 0.10552767664194107
step: 60, loss: 0.14231395721435547
step: 70, loss: 0.019933413714170456
step: 80, loss: 0.0383780412375927
step: 90, loss: 0.029949385672807693
step: 100, loss: 0.03708835318684578
step: 110, loss: 0.029557842761278152
step: 120, loss: 0.03142460063099861
step: 130, loss: 0.10078386217355728
step: 140, loss: 0.0698552131652832
step: 150, loss: 0.11450319737195969
step: 160, loss: 0.1340140402317047
step: 170, loss: 0.0377676859498024
step: 180, loss: 0.06094500795006752
step: 190, loss: 0.009560124017298222
step: 200, loss: 0.09626933187246323
step: 210, loss: 0.0117478733882308
step: 220, loss: 0.012298258021473885
step: 230, loss: 0.13758395612239838
step: 240, loss: 0.0819648951292038
step: 250, loss: 0.05027446150779724
step: 260, loss: 0.04334799945354462
step: 270, loss: 0.03780781105160713
step: 280, loss: 0.13645720481872559
step: 290, loss: 0.012297755107283592
step: 300, loss: 0.03023088350892067
step: 310, loss: 0.07373002916574478
step: 320, loss: 0.047523945569992065
step: 330, loss: 0.06276623904705048
step: 340, loss: 0.1426682472229004
step: 350, loss: 0.03471825644373894
step: 360, loss: 0.06308936327695847
step: 370, loss: 0.17232155799865723
step: 380, loss: 0.08767207711935043
step: 390, loss: 0.059361062943935394
step: 400, loss: 0.010170361958444118
step: 410, loss: 0.060411594808101654
step: 420, loss: 0.05671095848083496
step: 430, loss: 0.12185420840978622
step: 440, loss: 0.09302675724029541
step: 450, loss: 0.04431356117129326
step: 460, loss: 0.04116268455982208
step: 470, loss: 0.03155805170536041
step: 480, loss: 0.05899936705827713
step: 490, loss: 0.07717814296483994
step: 500, loss: 0.02134120836853981
step: 510, loss: 0.06414908915758133
step: 520, loss: 0.17754432559013367
step: 530, loss: 0.05951659008860588
step: 540, loss: 0.03633296117186546
step: 550, loss: 0.049902673810720444
step: 560, loss: 0.05162914842367172
step: 570, loss: 0.15130455791950226
step: 580, loss: 0.10644631087779999
step: 590, loss: 0.04235294461250305
step: 600, loss: 0.047104235738515854
step: 610, loss: 0.05111033469438553
step: 620, loss: 0.09772378206253052
step: 630, loss: 0.048446036875247955
step: 640, loss: 0.1329420953989029
step: 650, loss: 0.0639832466840744
step: 660, loss: 0.07888087630271912
step: 670, loss: 0.12835527956485748
step: 680, loss: 0.18742012977600098
step: 690, loss: 0.06837520003318787
step: 700, loss: 0.0843624472618103
step: 710, loss: 0.10939159989356995
step: 720, loss: 0.035404037684202194
step: 730, loss: 0.18287336826324463
step: 740, loss: 0.108461894094944
step: 750, loss: 0.00988791324198246
step: 760, loss: 0.10296209901571274
step: 770, loss: 0.15286308526992798
step: 780, loss: 0.07487235218286514
step: 790, loss: 0.045621633529663086
step: 800, loss: 0.015937309712171555
step: 810, loss: 0.007133733481168747
step: 820, loss: 0.07162012159824371
step: 830, loss: 0.04030023515224457
step: 840, loss: 0.03211674839258194
step: 850, loss: 0.08021730184555054
step: 860, loss: 0.011079836636781693
step: 870, loss: 0.022809159010648727
step: 880, loss: 0.10210337489843369
step: 890, loss: 0.11215780675411224
step: 900, loss: 0.024225056171417236
step: 910, loss: 0.06102004274725914
step: 920, loss: 0.04161188378930092
step: 930, loss: 0.050419051200151443
step: 940, loss: 0.24658901989459991
step: 950, loss: 0.06822056323289871
step: 960, loss: 0.019388243556022644
step: 970, loss: 0.039957258850336075
epoch 6: dev_f1=0.9271461716937355, f1=0.9200743494423792, best_f1=0.934622467771639
step: 0, loss: 0.03854453191161156
step: 10, loss: 0.04876864328980446
step: 20, loss: 0.05846470594406128
step: 30, loss: 0.12788546085357666
step: 40, loss: 0.12321556359529495
step: 50, loss: 0.032405149191617966
step: 60, loss: 0.026685165241360664
step: 70, loss: 0.08086511492729187
step: 80, loss: 0.1518353521823883
step: 90, loss: 0.03629183769226074
step: 100, loss: 0.17384369671344757
step: 110, loss: 0.17608511447906494
step: 120, loss: 0.09486890584230423
step: 130, loss: 0.13338692486286163
step: 140, loss: 0.052580565214157104
step: 150, loss: 0.03784966841340065
step: 160, loss: 0.08337536454200745
step: 170, loss: 0.024432670325040817
step: 180, loss: 0.033400699496269226
step: 190, loss: 0.07419251650571823
step: 200, loss: 0.1128489300608635
step: 210, loss: 0.07466832548379898
step: 220, loss: 0.08076843619346619
step: 230, loss: 0.03515711426734924
step: 240, loss: 0.021531306207180023
step: 250, loss: 0.04322699457406998
step: 260, loss: 0.04407833516597748
step: 270, loss: 0.08925829827785492
step: 280, loss: 0.25329092144966125
step: 290, loss: 0.148445725440979
step: 300, loss: 0.04443812370300293
step: 310, loss: 0.07390628755092621
step: 320, loss: 0.018765754997730255
step: 330, loss: 0.012245948426425457
step: 340, loss: 0.041969895362854004
step: 350, loss: 0.03173574060201645
step: 360, loss: 0.1138746589422226
step: 370, loss: 0.2279418408870697
step: 380, loss: 0.033701784908771515
step: 390, loss: 0.062128908932209015
step: 400, loss: 0.1896449327468872
step: 410, loss: 0.0017728345701470971
step: 420, loss: 0.020469309762120247
step: 430, loss: 0.12266908586025238
step: 440, loss: 0.013439459726214409
step: 450, loss: 0.10956365615129471
step: 460, loss: 0.15456250309944153
step: 470, loss: 0.03764090687036514
step: 480, loss: 0.08810991048812866
step: 490, loss: 0.15353162586688995
step: 500, loss: 0.24552662670612335
step: 510, loss: 0.16107197105884552
step: 520, loss: 0.038009174168109894
step: 530, loss: 0.3651668429374695
step: 540, loss: 0.022621916607022285
step: 550, loss: 0.013743291608989239
step: 560, loss: 0.19455435872077942
step: 570, loss: 0.012775607407093048
step: 580, loss: 0.04688053950667381
step: 590, loss: 0.09301281720399857
step: 600, loss: 0.07126189023256302
step: 610, loss: 0.07894524186849594
step: 620, loss: 0.039931368082761765
step: 630, loss: 0.11092475056648254
step: 640, loss: 0.026228342205286026
step: 650, loss: 0.06017416715621948
step: 660, loss: 0.012981646694242954
step: 670, loss: 0.07129614800214767
step: 680, loss: 0.01279909722507
step: 690, loss: 0.055140171200037
step: 700, loss: 0.08404543995857239
step: 710, loss: 0.011769087053835392
step: 720, loss: 0.049135055392980576
step: 730, loss: 0.010929975658655167
step: 740, loss: 0.022233951836824417
step: 750, loss: 0.00365065922960639
step: 760, loss: 0.07522313296794891
step: 770, loss: 0.04394559562206268
step: 780, loss: 0.0939040258526802
step: 790, loss: 0.03610274940729141
step: 800, loss: 0.023674260824918747
step: 810, loss: 0.0705234557390213
step: 820, loss: 0.0891633853316307
step: 830, loss: 0.06819487363100052
step: 840, loss: 0.0241838488727808
step: 850, loss: 0.028745640069246292
step: 860, loss: 0.12093710154294968
step: 870, loss: 0.14149895310401917
step: 880, loss: 0.024728529155254364
step: 890, loss: 0.03471871837973595
step: 900, loss: 0.04041227698326111
step: 910, loss: 0.05514195188879967
step: 920, loss: 0.04699660837650299
step: 930, loss: 0.006126064341515303
step: 940, loss: 0.056284431368112564
step: 950, loss: 0.0863855853676796
step: 960, loss: 0.030425524339079857
step: 970, loss: 0.013117613270878792
epoch 7: dev_f1=0.9355432780847146, f1=0.9329073482428115, best_f1=0.934622467771639
step: 0, loss: 0.13361302018165588
step: 10, loss: 0.06224558874964714
step: 20, loss: 0.14560601115226746
step: 30, loss: 0.024867460131645203
step: 40, loss: 0.08246297389268875
step: 50, loss: 0.04413570836186409
step: 60, loss: 0.05291175842285156
step: 70, loss: 0.0075832754373550415
step: 80, loss: 0.03671291470527649
step: 90, loss: 0.06405129283666611
step: 100, loss: 0.08245828002691269
step: 110, loss: 0.034844305366277695
step: 120, loss: 0.08750654757022858
step: 130, loss: 0.002939479425549507
step: 140, loss: 0.0654749795794487
step: 150, loss: 0.05224579572677612
step: 160, loss: 0.0173896923661232
step: 170, loss: 0.14442791044712067
step: 180, loss: 0.04667668044567108
step: 190, loss: 0.04098288342356682
step: 200, loss: 0.03527076542377472
step: 210, loss: 0.11101190000772476
step: 220, loss: 0.03424236923456192
step: 230, loss: 0.04162028431892395
step: 240, loss: 0.08200860768556595
step: 250, loss: 0.010365363210439682
step: 260, loss: 0.016569364815950394
step: 270, loss: 0.032674625515937805
step: 280, loss: 0.07104479521512985
step: 290, loss: 0.011436069384217262
step: 300, loss: 0.02321440353989601
step: 310, loss: 0.017992878332734108
step: 320, loss: 0.14440283179283142
step: 330, loss: 0.093967504799366
step: 340, loss: 0.0032787853851914406
step: 350, loss: 0.02860439568758011
step: 360, loss: 0.014469223096966743
step: 370, loss: 0.05565403029322624
step: 380, loss: 0.01866617426276207
step: 390, loss: 0.06195404380559921
step: 400, loss: 0.08236417919397354
step: 410, loss: 0.0026078110095113516
step: 420, loss: 0.07826558500528336
step: 430, loss: 0.0067339101806283
step: 440, loss: 0.013759121298789978
step: 450, loss: 0.10837926715612411
step: 460, loss: 0.007762097753584385
step: 470, loss: 0.14414602518081665
step: 480, loss: 0.08263397216796875
step: 490, loss: 0.12869462370872498
step: 500, loss: 0.08915045112371445
step: 510, loss: 0.05495027080178261
step: 520, loss: 0.02112535759806633
step: 530, loss: 0.04672262817621231
step: 540, loss: 0.04173741117119789
step: 550, loss: 0.023227792233228683
step: 560, loss: 0.08586791902780533
step: 570, loss: 0.07948487251996994
step: 580, loss: 0.03930661454796791
step: 590, loss: 0.029614446684718132
step: 600, loss: 0.2665678560733795
step: 610, loss: 0.07041443884372711
step: 620, loss: 0.07945151627063751
step: 630, loss: 0.03260599076747894
step: 640, loss: 0.06800062209367752
step: 650, loss: 0.056443169713020325
step: 660, loss: 0.10907691717147827
step: 670, loss: 0.014892539009451866
step: 680, loss: 0.012327579781413078
step: 690, loss: 0.027294203639030457
step: 700, loss: 0.13214340806007385
step: 710, loss: 0.011282847262918949
step: 720, loss: 0.001925256452523172
step: 730, loss: 0.04061439633369446
step: 740, loss: 0.0021110493689775467
step: 750, loss: 0.04348302260041237
step: 760, loss: 0.23235683143138885
step: 770, loss: 0.027078496292233467
step: 780, loss: 0.1018710806965828
step: 790, loss: 0.029698969796299934
step: 800, loss: 0.046468667685985565
step: 810, loss: 0.04301918298006058
step: 820, loss: 0.11233808845281601
step: 830, loss: 0.029921026900410652
step: 840, loss: 0.09361498802900314
step: 850, loss: 0.3772357106208801
step: 860, loss: 0.015613501891493797
step: 870, loss: 0.07195866852998734
step: 880, loss: 0.05982744321227074
step: 890, loss: 0.07671266049146652
step: 900, loss: 0.011946998536586761
step: 910, loss: 0.050495412200689316
step: 920, loss: 0.01876540668308735
step: 930, loss: 0.09955380111932755
step: 940, loss: 0.08429645001888275
step: 950, loss: 0.0405399352312088
step: 960, loss: 0.00838488806039095
step: 970, loss: 0.12696440517902374
epoch 8: dev_f1=0.9401869158878504, f1=0.9306197964847363, best_f1=0.9306197964847363
step: 0, loss: 0.06390640884637833
step: 10, loss: 0.04524613171815872
step: 20, loss: 0.09865106642246246
step: 30, loss: 0.2271704077720642
step: 40, loss: 0.015247192233800888
step: 50, loss: 0.14368115365505219
step: 60, loss: 0.09027987718582153
step: 70, loss: 0.07110894471406937
step: 80, loss: 0.03205513209104538
step: 90, loss: 0.06544192880392075
step: 100, loss: 0.020280422642827034
step: 110, loss: 0.05648038163781166
step: 120, loss: 0.022686667740345
step: 130, loss: 0.03621005639433861
step: 140, loss: 0.02872513234615326
step: 150, loss: 0.13564424216747284
step: 160, loss: 0.0642840564250946
step: 170, loss: 0.007385215722024441
step: 180, loss: 0.05465810000896454
step: 190, loss: 0.10430248826742172
step: 200, loss: 0.04232504218816757
step: 210, loss: 0.020879901945590973
step: 220, loss: 0.028272390365600586
step: 230, loss: 0.003614831017330289
step: 240, loss: 0.022854819893836975
step: 250, loss: 0.00819488801062107
step: 260, loss: 0.10833312571048737
step: 270, loss: 0.07880684733390808
step: 280, loss: 0.019692039117217064
step: 290, loss: 0.0453324019908905
step: 300, loss: 0.015329595655202866
step: 310, loss: 0.055786870419979095
step: 320, loss: 0.02940692938864231
step: 330, loss: 0.0049995859153568745
step: 340, loss: 0.05305783823132515
step: 350, loss: 0.01752549037337303
step: 360, loss: 0.02854132279753685
step: 370, loss: 0.0787319764494896
step: 380, loss: 0.0199170783162117
step: 390, loss: 0.10084904730319977
step: 400, loss: 0.020973393693566322
step: 410, loss: 0.03810734674334526
step: 420, loss: 0.13223464787006378
step: 430, loss: 0.0214633010327816
step: 440, loss: 0.033206820487976074
step: 450, loss: 0.017311546951532364
step: 460, loss: 0.01168796420097351
step: 470, loss: 0.03734594210982323
step: 480, loss: 0.10325735807418823
step: 490, loss: 0.01367875374853611
step: 500, loss: 0.012715821154415607
step: 510, loss: 0.15806971490383148
step: 520, loss: 0.05450000613927841
step: 530, loss: 0.04589882865548134
step: 540, loss: 0.03498062491416931
step: 550, loss: 0.06349758803844452
step: 560, loss: 0.059602223336696625
step: 570, loss: 0.009608373045921326
step: 580, loss: 0.10922836512327194
step: 590, loss: 0.022131847217679024
step: 600, loss: 0.01999257318675518
step: 610, loss: 0.05549778416752815
step: 620, loss: 0.027465736493468285
step: 630, loss: 0.0012099395971745253
step: 640, loss: 0.061654359102249146
step: 650, loss: 0.11651064455509186
step: 660, loss: 0.025210252031683922
step: 670, loss: 0.08459946513175964
step: 680, loss: 0.29622286558151245
step: 690, loss: 0.08740512281656265
step: 700, loss: 0.01838522031903267
step: 710, loss: 0.057132549583911896
step: 720, loss: 0.08037067204713821
step: 730, loss: 0.08572476357221603
step: 740, loss: 0.002438404131680727
step: 750, loss: 0.08105648308992386
step: 760, loss: 0.10268816351890564
step: 770, loss: 0.07160179316997528
step: 780, loss: 0.00664108619093895
step: 790, loss: 0.0006296376814134419
step: 800, loss: 0.01341542974114418
step: 810, loss: 0.05876751244068146
step: 820, loss: 0.04893089085817337
step: 830, loss: 0.01848261058330536
step: 840, loss: 0.08029379695653915
step: 850, loss: 0.13889293372631073
step: 860, loss: 0.04296286031603813
step: 870, loss: 0.012741755694150925
step: 880, loss: 0.027044128626585007
step: 890, loss: 0.026361126452684402
step: 900, loss: 0.0182068832218647
step: 910, loss: 0.04947870224714279
step: 920, loss: 0.018496688455343246
step: 930, loss: 0.1480872482061386
step: 940, loss: 0.06367570906877518
step: 950, loss: 0.025765366852283478
step: 960, loss: 0.036721695214509964
step: 970, loss: 0.06050434336066246
epoch 9: dev_f1=0.9344413665743306, f1=0.9314442413162706, best_f1=0.9306197964847363
step: 0, loss: 0.10051347315311432
step: 10, loss: 0.0038003360386937857
step: 20, loss: 0.09545419365167618
step: 30, loss: 0.016346674412488937
step: 40, loss: 0.003855121787637472
step: 50, loss: 0.02821478061378002
step: 60, loss: 0.2157302349805832
step: 70, loss: 0.04908328130841255
step: 80, loss: 0.051465943455696106
step: 90, loss: 0.013641588389873505
step: 100, loss: 0.08067137002944946
step: 110, loss: 0.09534239768981934
step: 120, loss: 0.053237758576869965
step: 130, loss: 0.0018982075853273273
step: 140, loss: 0.10321006923913956
step: 150, loss: 0.010327866300940514
step: 160, loss: 0.06326557695865631
step: 170, loss: 0.03535771742463112
step: 180, loss: 0.009277342818677425
step: 190, loss: 0.06778775900602341
step: 200, loss: 0.07260985672473907
step: 210, loss: 0.025416938588023186
step: 220, loss: 0.001014800975099206
step: 230, loss: 0.00041937895002774894
step: 240, loss: 0.010552548803389072
step: 250, loss: 0.04444503411650658
step: 260, loss: 0.15350717306137085
step: 270, loss: 0.0546375997364521
step: 280, loss: 0.12518396973609924
step: 290, loss: 0.021842800080776215
step: 300, loss: 0.05920178443193436
step: 310, loss: 0.08937755227088928
step: 320, loss: 0.04967284947633743
step: 330, loss: 0.10162779688835144
step: 340, loss: 0.0741218775510788
step: 350, loss: 0.05506353825330734
step: 360, loss: 0.004231326747685671
step: 370, loss: 0.032057713717222214
step: 380, loss: 0.006914127618074417
step: 390, loss: 0.007811633870005608
step: 400, loss: 0.027953671291470528
step: 410, loss: 0.03179532289505005
step: 420, loss: 0.020741354674100876
step: 430, loss: 0.027572132647037506
step: 440, loss: 0.04633418098092079
step: 450, loss: 0.003811181290075183
step: 460, loss: 0.029357606545090675
step: 470, loss: 0.05531254783272743
step: 480, loss: 0.19875679910182953
step: 490, loss: 0.09615728259086609
step: 500, loss: 0.05642618611454964
step: 510, loss: 0.11789591610431671
step: 520, loss: 0.033594224601984024
step: 530, loss: 0.049897413700819016
step: 540, loss: 0.02051069214940071
step: 550, loss: 0.063026562333107
step: 560, loss: 0.029391609132289886
step: 570, loss: 0.07022681832313538
step: 580, loss: 0.061300985515117645
step: 590, loss: 0.0077493744902312756
step: 600, loss: 0.16188913583755493
step: 610, loss: 0.00979646760970354
step: 620, loss: 0.014056744985282421
step: 630, loss: 0.14084090292453766
step: 640, loss: 0.05358535796403885
step: 650, loss: 0.18911176919937134
step: 660, loss: 0.059662580490112305
step: 670, loss: 0.01615811139345169
step: 680, loss: 0.0001089062134269625
step: 690, loss: 0.011427769437432289
step: 700, loss: 0.011687282472848892
step: 710, loss: 0.030339768156409264
step: 720, loss: 0.03392781317234039
step: 730, loss: 0.020627696067094803
step: 740, loss: 0.03202192485332489
step: 750, loss: 0.030757961794734
step: 760, loss: 0.09433222562074661
step: 770, loss: 0.0428251288831234
step: 780, loss: 0.03142350912094116
step: 790, loss: 0.04839356988668442
step: 800, loss: 0.09670758247375488
step: 810, loss: 0.019064191728830338
step: 820, loss: 0.11547932773828506
step: 830, loss: 0.06162493675947189
step: 840, loss: 0.004538792185485363
step: 850, loss: 0.13761529326438904
step: 860, loss: 0.14389412105083466
step: 870, loss: 0.016713690012693405
step: 880, loss: 0.07340141385793686
step: 890, loss: 0.09904443472623825
step: 900, loss: 0.10635917633771896
step: 910, loss: 0.07992678135633469
step: 920, loss: 0.017744969576597214
step: 930, loss: 0.015877317637205124
step: 940, loss: 0.017687780782580376
step: 950, loss: 0.11241567134857178
step: 960, loss: 0.03278249502182007
step: 970, loss: 0.07361459732055664
epoch 10: dev_f1=0.927170868347339, f1=0.9239981575310916, best_f1=0.9306197964847363
step: 0, loss: 0.053795430809259415
step: 10, loss: 0.007312763016670942
step: 20, loss: 0.22079066932201385
step: 30, loss: 0.04062270745635033
step: 40, loss: 0.02800915576517582
step: 50, loss: 0.023202460259199142
step: 60, loss: 0.06937780976295471
step: 70, loss: 0.06601407378911972
step: 80, loss: 1.949049146787729e-05
step: 90, loss: 0.029650960117578506
step: 100, loss: 0.01445777714252472
step: 110, loss: 0.005570790730416775
step: 120, loss: 0.08261602371931076
step: 130, loss: 0.03910926356911659
step: 140, loss: 0.08750001341104507
step: 150, loss: 0.08753034472465515
step: 160, loss: 0.13069182634353638
step: 170, loss: 0.06387753784656525
step: 180, loss: 0.03806701675057411
step: 190, loss: 7.185230060713366e-05
step: 200, loss: 0.03771142289042473
step: 210, loss: 0.052493683993816376
step: 220, loss: 0.005859649274498224
step: 230, loss: 0.04281081631779671
step: 240, loss: 0.0033251445274800062
step: 250, loss: 0.07135184109210968
step: 260, loss: 0.00740528479218483
step: 270, loss: 0.018397720530629158
step: 280, loss: 0.11001849174499512
step: 290, loss: 0.00628167437389493
step: 300, loss: 0.052883975207805634
step: 310, loss: 0.057861048728227615
step: 320, loss: 0.013326534070074558
step: 330, loss: 0.018429169431328773
step: 340, loss: 0.05978383123874664
step: 350, loss: 0.03689424693584442
step: 360, loss: 0.06607787311077118
step: 370, loss: 0.0002449120511300862
step: 380, loss: 0.06543133407831192
step: 390, loss: 0.0010721279541030526
step: 400, loss: 0.009942649863660336
step: 410, loss: 0.01530543901026249
step: 420, loss: 0.014572890475392342
step: 430, loss: 0.033755652606487274
step: 440, loss: 0.02441795915365219
step: 450, loss: 0.027127722278237343
step: 460, loss: 0.00914202630519867
step: 470, loss: 0.10827117413282394
step: 480, loss: 0.04130825027823448
step: 490, loss: 0.0395832359790802
step: 500, loss: 0.12509563565254211
step: 510, loss: 0.028863847255706787
step: 520, loss: 0.0026209321804344654
step: 530, loss: 0.015743020921945572
step: 540, loss: 0.04949977248907089
step: 550, loss: 0.0762416273355484
step: 560, loss: 0.0013625782448798418
step: 570, loss: 0.003214276861399412
step: 580, loss: 0.0231639351695776
step: 590, loss: 0.055672965943813324
step: 600, loss: 0.03380748629570007
step: 610, loss: 0.0655628889799118
step: 620, loss: 0.050247158855199814
step: 630, loss: 0.059440236538648605
step: 640, loss: 0.0005345972022041678
step: 650, loss: 0.05998727306723595
step: 660, loss: 0.051362745463848114
step: 670, loss: 0.09091632068157196
step: 680, loss: 0.049762941896915436
step: 690, loss: 0.03161065652966499
step: 700, loss: 0.0323699414730072
step: 710, loss: 0.05849743261933327
step: 720, loss: 0.01541819702833891
step: 730, loss: 0.02508709952235222
step: 740, loss: 0.05869447439908981
step: 750, loss: 0.03497348725795746
step: 760, loss: 0.15364742279052734
step: 770, loss: 0.003226241562515497
step: 780, loss: 0.00013295671669766307
step: 790, loss: 0.050561580806970596
step: 800, loss: 0.018274493515491486
step: 810, loss: 0.04527188837528229
step: 820, loss: 0.017219772562384605
step: 830, loss: 0.03646085038781166
step: 840, loss: 0.013040518388152122
step: 850, loss: 0.008401124738156796
step: 860, loss: 0.004487521480768919
step: 870, loss: 0.022445643320679665
step: 880, loss: 0.11180351674556732
step: 890, loss: 0.10825473070144653
step: 900, loss: 0.047696467489004135
step: 910, loss: 0.06715703755617142
step: 920, loss: 0.0031765580642968416
step: 930, loss: 0.02876228280365467
step: 940, loss: 0.0026684547774493694
step: 950, loss: 0.06317362189292908
step: 960, loss: 0.007219197228550911
step: 970, loss: 0.06385520100593567
epoch 11: dev_f1=0.9349670122525918, f1=0.9306654257794322, best_f1=0.9306197964847363
step: 0, loss: 0.04922650754451752
step: 10, loss: 0.02793676219880581
step: 20, loss: 0.052021488547325134
step: 30, loss: 0.028756767511367798
step: 40, loss: 5.422017420642078e-05
step: 50, loss: 0.01777469553053379
step: 60, loss: 0.07026269286870956
step: 70, loss: 0.015037758275866508
step: 80, loss: 0.0613115057349205
step: 90, loss: 0.005833203438669443
step: 100, loss: 0.20175735652446747
step: 110, loss: 0.03414149954915047
step: 120, loss: 0.05627600476145744
step: 130, loss: 0.01948593556880951
step: 140, loss: 0.08184092491865158
step: 150, loss: 0.03179866075515747
step: 160, loss: 0.01625942811369896
step: 170, loss: 0.00765270134434104
step: 180, loss: 0.05266403779387474
step: 190, loss: 0.008634036406874657
step: 200, loss: 0.027769597247242928
step: 210, loss: 0.08939631283283234
step: 220, loss: 0.11781802773475647
step: 230, loss: 0.030353248119354248
step: 240, loss: 0.0500476211309433
step: 250, loss: 0.039914269000291824
step: 260, loss: 0.028448453173041344
step: 270, loss: 0.006802714895457029
step: 280, loss: 0.0068389419466257095
step: 290, loss: 0.008100517094135284
step: 300, loss: 0.003773232689127326
step: 310, loss: 0.0024244303349405527
step: 320, loss: 0.020467227324843407
step: 330, loss: 0.0008880756795406342
step: 340, loss: 0.029889464378356934
step: 350, loss: 0.004077009856700897
step: 360, loss: 0.021618159487843513
step: 370, loss: 0.0033852604683488607
step: 380, loss: 0.0527229905128479
step: 390, loss: 0.0003166181850247085
step: 400, loss: 0.0050401343032717705
step: 410, loss: 0.01064329408109188
step: 420, loss: 0.017303042113780975
step: 430, loss: 0.0024229520931839943
step: 440, loss: 0.11032996326684952
step: 450, loss: 0.020245123654603958
step: 460, loss: 0.020059339702129364
step: 470, loss: 0.03111674077808857
step: 480, loss: 0.039986126124858856
step: 490, loss: 0.02077309601008892
step: 500, loss: 0.011890427209436893
step: 510, loss: 0.017237670719623566
step: 520, loss: 0.03624927997589111
step: 530, loss: 0.21668164432048798
step: 540, loss: 0.0075576892122626305
step: 550, loss: 0.029392054304480553
step: 560, loss: 0.06591383367776871
step: 570, loss: 0.05255501717329025
step: 580, loss: 0.0670725554227829
step: 590, loss: 0.05027436837553978
step: 600, loss: 0.028413251042366028
step: 610, loss: 0.07417406886816025
step: 620, loss: 0.005475336220115423
step: 630, loss: 0.009453966282308102
step: 640, loss: 0.015282693319022655
step: 650, loss: 0.01749650575220585
step: 660, loss: 0.0466618649661541
step: 670, loss: 0.05942149460315704
step: 680, loss: 0.12317793071269989
step: 690, loss: 0.11058337241411209
step: 700, loss: 0.010521736927330494
step: 710, loss: 0.024527529254555702
step: 720, loss: 0.14980116486549377
step: 730, loss: 0.01611301302909851
step: 740, loss: 0.022087909281253815
step: 750, loss: 0.08894778788089752
step: 760, loss: 0.08525627106428146
step: 770, loss: 0.047677963972091675
step: 780, loss: 0.0014487099833786488
step: 790, loss: 0.013116264715790749
step: 800, loss: 0.04288957640528679
step: 810, loss: 0.015337169170379639
step: 820, loss: 0.05270220339298248
step: 830, loss: 0.008221259340643883
step: 840, loss: 0.013963664881885052
step: 850, loss: 0.04714406654238701
step: 860, loss: 0.05086258426308632
step: 870, loss: 0.0468660444021225
step: 880, loss: 0.03152715414762497
step: 890, loss: 0.15385420620441437
step: 900, loss: 0.023409143090248108
step: 910, loss: 0.058362603187561035
step: 920, loss: 0.035556890070438385
step: 930, loss: 0.09493019431829453
step: 940, loss: 0.09156215935945511
step: 950, loss: 0.09004741907119751
step: 960, loss: 0.006537475623190403
step: 970, loss: 0.0554497167468071
epoch 12: dev_f1=0.9310027598896043, f1=0.9275893675527039, best_f1=0.9306197964847363
step: 0, loss: 0.03251636028289795
step: 10, loss: 0.03364422172307968
step: 20, loss: 0.01951531507074833
step: 30, loss: 0.0587746687233448
step: 40, loss: 0.00746157206594944
step: 50, loss: 0.022045806050300598
step: 60, loss: 0.026580817997455597
step: 70, loss: 0.02989461086690426
step: 80, loss: 0.035211410373449326
step: 90, loss: 0.04368387535214424
step: 100, loss: 0.020351707935333252
step: 110, loss: 0.025910474359989166
step: 120, loss: 0.0014102734858170152
step: 130, loss: 0.05615951120853424
step: 140, loss: 0.027662277221679688
step: 150, loss: 0.001737085753120482
step: 160, loss: 0.00048465002328157425
step: 170, loss: 0.007596877869218588
step: 180, loss: 0.020148910582065582
step: 190, loss: 0.0011323349317535758
step: 200, loss: 0.025821181014180183
step: 210, loss: 0.0017199207795783877
step: 220, loss: 0.027439169585704803
step: 230, loss: 0.03047073632478714
step: 240, loss: 0.0768333449959755
step: 250, loss: 0.07453443855047226
step: 260, loss: 0.014148619025945663
step: 270, loss: 0.047150444239377975
step: 280, loss: 0.013775693252682686
step: 290, loss: 0.04743422940373421
step: 300, loss: 0.010950183495879173
step: 310, loss: 0.0199944656342268
step: 320, loss: 0.047109995037317276
step: 330, loss: 0.04033912345767021
step: 340, loss: 0.07677213847637177
step: 350, loss: 0.03125588595867157
step: 360, loss: 0.042695555835962296
step: 370, loss: 0.02298019453883171
step: 380, loss: 0.07040567696094513
step: 390, loss: 0.09046155214309692
step: 400, loss: 0.007594726514071226
step: 410, loss: 0.010294702835381031
step: 420, loss: 0.0687885507941246
step: 430, loss: 0.0002768095873761922
step: 440, loss: 0.022355955094099045
step: 450, loss: 0.02922777086496353
step: 460, loss: 0.046198297291994095
step: 470, loss: 0.04723874852061272
step: 480, loss: 0.0018029585480690002
step: 490, loss: 0.16839678585529327
step: 500, loss: 0.027347659692168236
step: 510, loss: 0.006096266210079193
step: 520, loss: 0.06623900681734085
step: 530, loss: 0.07825873047113419
step: 540, loss: 0.03027462400496006
step: 550, loss: 0.05017698183655739
step: 560, loss: 0.01712964102625847
step: 570, loss: 0.0006817456451244652
step: 580, loss: 0.0017663518665358424
step: 590, loss: 0.036488719284534454
step: 600, loss: 0.03681468591094017
step: 610, loss: 0.01542987022548914
step: 620, loss: 0.1021769642829895
step: 630, loss: 0.02013041265308857
step: 640, loss: 0.03785933554172516
step: 650, loss: 0.023502344265580177
step: 660, loss: 0.12804152071475983
step: 670, loss: 0.0748913437128067
step: 680, loss: 0.005695505067706108
step: 690, loss: 0.07388585805892944
step: 700, loss: 0.01921779289841652
step: 710, loss: 0.1467132568359375
step: 720, loss: 0.0496477372944355
step: 730, loss: 0.08846668154001236
step: 740, loss: 0.07362670451402664
step: 750, loss: 0.04276350513100624
step: 760, loss: 0.05127641558647156
step: 770, loss: 0.10725008696317673
step: 780, loss: 0.023974377661943436
step: 790, loss: 0.05123920366168022
step: 800, loss: 0.014337169006466866
step: 810, loss: 0.051222290843725204
step: 820, loss: 0.04766825959086418
step: 830, loss: 0.0947919636964798
step: 840, loss: 0.017168572172522545
step: 850, loss: 0.00719063077121973
step: 860, loss: 0.04558006674051285
step: 870, loss: 0.04303104430437088
step: 880, loss: 0.0664420798420906
step: 890, loss: 0.0004162385012023151
step: 900, loss: 0.05440878868103027
step: 910, loss: 0.022670667618513107
step: 920, loss: 0.035690318793058395
step: 930, loss: 0.03541772812604904
step: 940, loss: 0.02890634723007679
step: 950, loss: 0.061130695044994354
step: 960, loss: 0.08954731374979019
step: 970, loss: 0.13206414878368378
epoch 13: dev_f1=0.9286740067017711, f1=0.9241639189825719, best_f1=0.9306197964847363
step: 0, loss: 0.015949709340929985
step: 10, loss: 0.0310557521879673
step: 20, loss: 0.0030734383035451174
step: 30, loss: 0.06089339405298233
step: 40, loss: 0.03970116749405861
step: 50, loss: 0.08333572000265121
step: 60, loss: 0.02239089645445347
step: 70, loss: 0.030567681416869164
step: 80, loss: 0.052204474806785583
step: 90, loss: 0.05436081066727638
step: 100, loss: 0.0019528194097802043
step: 110, loss: 0.024064259603619576
step: 120, loss: 0.017109237611293793
step: 130, loss: 0.03639973700046539
step: 140, loss: 0.0006996560841798782
step: 150, loss: 0.027577659115195274
step: 160, loss: 0.00935320183634758
step: 170, loss: 0.029351959004998207
step: 180, loss: 0.0345398411154747
step: 190, loss: 0.0680236890912056
step: 200, loss: 0.01413594651967287
step: 210, loss: 0.04773576557636261
step: 220, loss: 0.011964797042310238
step: 230, loss: 0.016452817246317863
step: 240, loss: 9.271672752220184e-05
step: 250, loss: 0.05267108976840973
step: 260, loss: 0.0003777868114411831
step: 270, loss: 0.1017208993434906
step: 280, loss: 0.06490413099527359
step: 290, loss: 0.0694160908460617
step: 300, loss: 0.014852150343358517
step: 310, loss: 0.015896037220954895
step: 320, loss: 0.049499377608299255
step: 330, loss: 0.020178047940135002
step: 340, loss: 0.00017746291996445507
step: 350, loss: 0.04427406191825867
step: 360, loss: 0.043626561760902405
step: 370, loss: 0.11779983341693878
step: 380, loss: 0.03773394227027893
step: 390, loss: 0.1111936867237091
step: 400, loss: 0.09018649905920029
step: 410, loss: 0.0009206471149809659
step: 420, loss: 0.028911881148815155
step: 430, loss: 0.04697687178850174
step: 440, loss: 0.04025678336620331
step: 450, loss: 0.08382374048233032
step: 460, loss: 0.0045930854976177216
step: 470, loss: 7.767194801999722e-06
step: 480, loss: 0.03396428003907204
step: 490, loss: 0.008857308886945248
step: 500, loss: 0.004417194053530693
step: 510, loss: 0.0424797348678112
step: 520, loss: 0.00016560027142986655
step: 530, loss: 0.12205740809440613
step: 540, loss: 0.026751942932605743
step: 550, loss: 0.027277957648038864
step: 560, loss: 0.006278798449784517
step: 570, loss: 0.04940560832619667
step: 580, loss: 0.03354066237807274
step: 590, loss: 0.06585828959941864
step: 600, loss: 0.018263986334204674
step: 610, loss: 0.014189976267516613
step: 620, loss: 0.0026576202362775803
step: 630, loss: 0.0680919662117958
step: 640, loss: 0.034668732434511185
step: 650, loss: 0.06937873363494873
step: 660, loss: 0.033050548285245895
step: 670, loss: 0.02954975515604019
step: 680, loss: 0.05400178208947182
step: 690, loss: 0.008503928780555725
step: 700, loss: 0.011502510868012905
step: 710, loss: 0.021588820964097977
step: 720, loss: 0.12286362797021866
step: 730, loss: 0.052658628672361374
step: 740, loss: 0.010444730520248413
step: 750, loss: 0.07297761738300323
step: 760, loss: 0.12775281071662903
step: 770, loss: 0.018737465143203735
step: 780, loss: 0.05440989136695862
step: 790, loss: 0.07011561095714569
step: 800, loss: 0.0765177384018898
step: 810, loss: 0.0598328597843647
step: 820, loss: 0.0008412597235292196
step: 830, loss: 0.03710443526506424
step: 840, loss: 0.03312588110566139
step: 850, loss: 0.07067342847585678
step: 860, loss: 0.00023066408175509423
step: 870, loss: 0.024095118045806885
step: 880, loss: 0.01067627314478159
step: 890, loss: 0.09578751027584076
step: 900, loss: 0.022313470020890236
step: 910, loss: 0.00024945352924987674
step: 920, loss: 0.13877461850643158
step: 930, loss: 0.036716170608997345
step: 940, loss: 0.02037465199828148
step: 950, loss: 0.08098490536212921
step: 960, loss: 0.13011996448040009
step: 970, loss: 0.05187581852078438
epoch 14: dev_f1=0.9389846297158826, f1=0.9314942528735632, best_f1=0.9306197964847363
step: 0, loss: 0.05013208091259003
step: 10, loss: 0.03131822124123573
step: 20, loss: 0.023856237530708313
step: 30, loss: 0.0024322981480509043
step: 40, loss: 0.03743861988186836
step: 50, loss: 0.03413098305463791
step: 60, loss: 0.0018458268605172634
step: 70, loss: 0.049208614975214005
step: 80, loss: 0.030772751197218895
step: 90, loss: 0.03697926923632622
step: 100, loss: 0.013472733087837696
step: 110, loss: 0.018052447587251663
step: 120, loss: 0.06327007710933685
step: 130, loss: 0.014131051488220692
step: 140, loss: 0.013164185918867588
step: 150, loss: 0.0813811868429184
step: 160, loss: 0.002570229582488537
step: 170, loss: 0.01650947891175747
step: 180, loss: 0.000818232074379921
step: 190, loss: 0.05974526330828667
step: 200, loss: 0.0386795848608017
step: 210, loss: 0.04450308531522751
step: 220, loss: 0.04080444946885109
step: 230, loss: 0.05600694194436073
step: 240, loss: 0.06751693040132523
step: 250, loss: 0.05544861778616905
step: 260, loss: 0.03382669389247894
step: 270, loss: 0.0010159681551158428
step: 280, loss: 0.0639924556016922
step: 290, loss: 0.00042886348091997206
step: 300, loss: 0.01864705979824066
step: 310, loss: 0.062181517481803894
step: 320, loss: 0.01049361564218998
step: 330, loss: 0.04359637200832367
step: 340, loss: 0.01920480653643608
step: 350, loss: 0.03428851440548897
step: 360, loss: 0.024703126400709152
step: 370, loss: 0.03647439181804657
step: 380, loss: 0.03211367502808571
step: 390, loss: 0.00629678787663579
step: 400, loss: 0.04965091124176979
step: 410, loss: 0.021651573479175568
step: 420, loss: 0.07001202553510666
step: 430, loss: 0.01705976016819477
step: 440, loss: 0.028837265446782112
step: 450, loss: 0.02695279009640217
step: 460, loss: 0.0022208893205970526
step: 470, loss: 0.003477593418210745
step: 480, loss: 0.07070710510015488
step: 490, loss: 0.12291277199983597
step: 500, loss: 0.023597219958901405
step: 510, loss: 0.03152962028980255
step: 520, loss: 0.0009487458155490458
step: 530, loss: 0.09138941019773483
step: 540, loss: 0.014267569407820702
step: 550, loss: 0.0006971612456254661
step: 560, loss: 0.032487038522958755
step: 570, loss: 0.04898088797926903
step: 580, loss: 0.00048429652815684676
step: 590, loss: 0.03593721240758896
step: 600, loss: 0.0504935123026371
step: 610, loss: 0.0012233491288498044
step: 620, loss: 0.006317345891147852
step: 630, loss: 0.04487709328532219
step: 640, loss: 0.016252808272838593
step: 650, loss: 0.03444359824061394
step: 660, loss: 0.03214780613780022
step: 670, loss: 0.0032666996121406555
step: 680, loss: 0.000968964013736695
step: 690, loss: 0.023452777415513992
step: 700, loss: 0.0001619564718566835
step: 710, loss: 0.1860956996679306
step: 720, loss: 0.021056797355413437
step: 730, loss: 0.04233903810381889
step: 740, loss: 0.0762057974934578
step: 750, loss: 0.0742005705833435
step: 760, loss: 0.04013773426413536
step: 770, loss: 0.00017947610467672348
step: 780, loss: 0.061355337500572205
step: 790, loss: 0.021931687369942665
step: 800, loss: 0.00017222542373929173
step: 810, loss: 0.000191350351087749
step: 820, loss: 0.0016603607218712568
step: 830, loss: 0.0012099476298317313
step: 840, loss: 0.05775407329201698
step: 850, loss: 0.025692801922559738
step: 860, loss: 0.02217220328748226
step: 870, loss: 0.013130602426826954
step: 880, loss: 0.009254171513020992
step: 890, loss: 0.0001417419989593327
step: 900, loss: 0.05718165636062622
step: 910, loss: 0.000844234717078507
step: 920, loss: 0.06861238181591034
step: 930, loss: 0.06659143418073654
step: 940, loss: 6.850785212009214e-06
step: 950, loss: 0.02608240768313408
step: 960, loss: 0.007262705359607935
step: 970, loss: 0.020064864307641983
epoch 15: dev_f1=0.9393656716417911, f1=0.9311141932501156, best_f1=0.9306197964847363
step: 0, loss: 0.048485562205314636
step: 10, loss: 5.6871314882300794e-05
step: 20, loss: 0.08511985093355179
step: 30, loss: 0.007399728987365961
step: 40, loss: 0.018362630158662796
step: 50, loss: 0.02776203118264675
step: 60, loss: 0.0066819023340940475
step: 70, loss: 6.791174655518262e-06
step: 80, loss: 0.024945905432105064
step: 90, loss: 0.07656798511743546
step: 100, loss: 0.0022443586494773626
step: 110, loss: 0.046704236418008804
step: 120, loss: 0.025145655497908592
step: 130, loss: 0.001559792784973979
step: 140, loss: 0.009854214265942574
step: 150, loss: 0.04598810151219368
step: 160, loss: 0.0005512846983037889
step: 170, loss: 0.0007259549456648529
step: 180, loss: 0.0211128368973732
step: 190, loss: 0.00010774275870062411
step: 200, loss: 0.02007037028670311
step: 210, loss: 0.00016655254876241088
step: 220, loss: 0.03943878039717674
step: 230, loss: 0.04683510586619377
step: 240, loss: 0.02266250178217888
step: 250, loss: 0.00025885101058520377
step: 260, loss: 5.484532448463142e-05
step: 270, loss: 0.049804627895355225
step: 280, loss: 0.05299714580178261
step: 290, loss: 0.047386351972818375
step: 300, loss: 0.00027337585925124586
step: 310, loss: 2.28800781769678e-05
step: 320, loss: 0.00033910543425008655
step: 330, loss: 0.02338104508817196
step: 340, loss: 0.017902513965964317
step: 350, loss: 0.036046288907527924
step: 360, loss: 0.0018214546144008636
step: 370, loss: 0.057068731635808945
step: 380, loss: 0.013693886809051037
step: 390, loss: 0.010149084031581879
step: 400, loss: 0.023604894056916237
step: 410, loss: 0.04629261791706085
step: 420, loss: 0.05869559943675995
step: 430, loss: 7.524214743170887e-05
step: 440, loss: 3.205806569894776e-05
step: 450, loss: 0.0008188289357349277
step: 460, loss: 0.11150868982076645
step: 470, loss: 0.06056228652596474
step: 480, loss: 1.3436727385851555e-05
step: 490, loss: 9.76003721007146e-05
step: 500, loss: 0.02225964516401291
step: 510, loss: 0.02221047505736351
step: 520, loss: 0.011581775732338428
step: 530, loss: 0.0575275719165802
step: 540, loss: 0.02656378783285618
step: 550, loss: 0.06566211581230164
step: 560, loss: 0.005977294407784939
step: 570, loss: 0.018961122259497643
step: 580, loss: 0.058941811323165894
step: 590, loss: 0.06678234785795212
step: 600, loss: 0.021414054557681084
step: 610, loss: 0.0018853305373340845
step: 620, loss: 0.07330171763896942
step: 630, loss: 0.016847878694534302
step: 640, loss: 0.06960345804691315
step: 650, loss: 0.03743671998381615
step: 660, loss: 0.02134322188794613
step: 670, loss: 0.03603197634220123
step: 680, loss: 0.010672705247998238
step: 690, loss: 0.04273775592446327
step: 700, loss: 0.06113819777965546
step: 710, loss: 0.03908148407936096
step: 720, loss: 0.020526209846138954
step: 730, loss: 0.05027168244123459
step: 740, loss: 0.053322549909353256
step: 750, loss: 0.046558842062950134
step: 760, loss: 0.0020067787263542414
step: 770, loss: 0.024075431749224663
step: 780, loss: 0.013772099278867245
step: 790, loss: 0.0458800382912159
step: 800, loss: 0.00014846623525954783
step: 810, loss: 0.018767772242426872
step: 820, loss: 0.04250013083219528
step: 830, loss: 0.0007944576791487634
step: 840, loss: 0.06463287025690079
step: 850, loss: 0.03641769662499428
step: 860, loss: 0.02325357496738434
step: 870, loss: 0.008012914098799229
step: 880, loss: 0.0222515519708395
step: 890, loss: 0.02748771198093891
step: 900, loss: 0.00028710809419862926
step: 910, loss: 0.044624295085668564
step: 920, loss: 0.058136582374572754
step: 930, loss: 0.019980428740382195
step: 940, loss: 0.056351322680711746
step: 950, loss: 0.07956265658140182
step: 960, loss: 0.04233293607831001
step: 970, loss: 0.045964110642671585
epoch 16: dev_f1=0.9367205542725173, f1=0.9320565435476517, best_f1=0.9306197964847363
step: 0, loss: 0.12214937061071396
step: 10, loss: 0.030779574066400528
step: 20, loss: 0.0658179372549057
step: 30, loss: 0.019330238923430443
step: 40, loss: 0.03023447096347809
step: 50, loss: 3.6620378523366526e-05
step: 60, loss: 0.042436081916093826
step: 70, loss: 0.041848935186862946
step: 80, loss: 0.03848792612552643
step: 90, loss: 6.228594429558143e-05
step: 100, loss: 0.015462093986570835
step: 110, loss: 0.004897839389741421
step: 120, loss: 0.0005933605716563761
step: 130, loss: 0.025205394253134727
step: 140, loss: 0.00411548838019371
step: 150, loss: 0.09402316063642502
step: 160, loss: 0.03133353963494301
step: 170, loss: 0.01704488880932331
step: 180, loss: 3.126675437670201e-05
step: 190, loss: 0.004395964555442333
step: 200, loss: 0.04319686070084572
step: 210, loss: 0.07047785073518753
step: 220, loss: 0.035425178706645966
step: 230, loss: 0.058228712528944016
step: 240, loss: 0.037825893610715866
step: 250, loss: 0.03150784224271774
step: 260, loss: 0.014973465353250504
step: 270, loss: 0.037295516580343246
step: 280, loss: 0.0198441743850708
step: 290, loss: 0.1077718511223793
step: 300, loss: 0.020852915942668915
step: 310, loss: 2.4998324079206213e-05
step: 320, loss: 0.022622976452112198
step: 330, loss: 0.00039757473859936
step: 340, loss: 0.022481635212898254
step: 350, loss: 0.0042900824919342995
step: 360, loss: 0.021287690848112106
step: 370, loss: 0.08455262333154678
step: 380, loss: 0.008997857570648193
step: 390, loss: 0.025554679334163666
step: 400, loss: 0.04699048772454262
step: 410, loss: 0.046042416244745255
step: 420, loss: 0.0979810282588005
step: 430, loss: 0.03539567068219185
step: 440, loss: 0.05760985240340233
step: 450, loss: 6.027501058269991e-06
step: 460, loss: 0.00304554495960474
step: 470, loss: 0.041515134274959564
step: 480, loss: 0.06100146472454071
step: 490, loss: 0.08320700377225876
step: 500, loss: 0.0002666362561285496
step: 510, loss: 0.061147917062044144
step: 520, loss: 4.2550025682430714e-05
step: 530, loss: 0.009436037391424179
step: 540, loss: 0.03687743842601776
step: 550, loss: 0.02357339672744274
step: 560, loss: 6.13180691289017e-06
step: 570, loss: 0.03964187949895859
step: 580, loss: 0.020064156502485275
step: 590, loss: 0.034397635608911514
step: 600, loss: 0.06427289545536041
step: 610, loss: 9.274802869185805e-05
step: 620, loss: 0.05220923572778702
step: 630, loss: 0.04548518359661102
step: 640, loss: 0.04266016557812691
step: 650, loss: 0.09156426787376404
step: 660, loss: 7.801398169249296e-05
step: 670, loss: 0.017264630645513535
step: 680, loss: 0.004409363027662039
step: 690, loss: 0.07624395191669464
step: 700, loss: 0.02235453948378563
step: 710, loss: 0.08229582756757736
step: 720, loss: 0.0002797914785332978
step: 730, loss: 0.05943765491247177
step: 740, loss: 0.023005740717053413
step: 750, loss: 0.055085498839616776
step: 760, loss: 0.08873934298753738
step: 770, loss: 0.0697799026966095
step: 780, loss: 0.05731910467147827
step: 790, loss: 0.021774254739284515
step: 800, loss: 0.03953995555639267
step: 810, loss: 0.01968611776828766
step: 820, loss: 0.00045278758625499904
step: 830, loss: 0.03744607791304588
step: 840, loss: 0.00019329348288010806
step: 850, loss: 0.02139323018491268
step: 860, loss: 0.03143119439482689
step: 870, loss: 0.04368441179394722
step: 880, loss: 0.04201556742191315
step: 890, loss: 0.040047600865364075
step: 900, loss: 0.0017425855621695518
step: 910, loss: 0.01788114570081234
step: 920, loss: 0.04532667621970177
step: 930, loss: 9.692367893876508e-05
step: 940, loss: 0.0006417311378754675
step: 950, loss: 0.020367620512843132
step: 960, loss: 0.014304226264357567
step: 970, loss: 0.08383872359991074
epoch 17: dev_f1=0.9366494603472549, f1=0.9298653042266605, best_f1=0.9306197964847363
step: 0, loss: 0.04101178050041199
step: 10, loss: 0.029632018879055977
step: 20, loss: 0.0315118171274662
step: 30, loss: 0.060994092375040054
step: 40, loss: 0.05887988582253456
step: 50, loss: 0.0796426460146904
step: 60, loss: 0.02158673293888569
step: 70, loss: 0.019186971709132195
step: 80, loss: 0.017222952097654343
step: 90, loss: 0.000197040440980345
step: 100, loss: 4.7219775296980515e-05
step: 110, loss: 0.04500804841518402
step: 120, loss: 0.031313128769397736
step: 130, loss: 0.02897046133875847
step: 140, loss: 0.13783706724643707
step: 150, loss: 0.023384258151054382
step: 160, loss: 0.032630544155836105
step: 170, loss: 5.692178092431277e-05
step: 180, loss: 0.0007855373551137745
step: 190, loss: 0.04099300503730774
step: 200, loss: 6.504613702418283e-05
step: 210, loss: 0.10738125443458557
step: 220, loss: 0.023746635764837265
step: 230, loss: 0.07407617568969727
step: 240, loss: 0.02151862531900406
step: 250, loss: 0.01828254759311676
step: 260, loss: 0.0339740589261055
step: 270, loss: 0.008246326819062233
step: 280, loss: 0.009953481145203114
step: 290, loss: 0.040023114532232285
step: 300, loss: 0.05411779135465622
step: 310, loss: 0.04786021634936333
step: 320, loss: 0.033836282789707184
step: 330, loss: 0.11156056821346283
step: 340, loss: 0.001674144295975566
step: 350, loss: 0.019846627488732338
step: 360, loss: 0.005935917142778635
step: 370, loss: 0.037900350987911224
step: 380, loss: 3.6893638025503606e-05
step: 390, loss: 4.858308602706529e-05
step: 400, loss: 8.79597500897944e-05
step: 410, loss: 3.782297790166922e-05
step: 420, loss: 0.0349215492606163
step: 430, loss: 9.805994341149926e-05
step: 440, loss: 0.06097378209233284
step: 450, loss: 0.04642217978835106
step: 460, loss: 0.04782583564519882
step: 470, loss: 0.04728458821773529
step: 480, loss: 0.036572717130184174
step: 490, loss: 0.050912000238895416
step: 500, loss: 2.9789949621772394e-05
step: 510, loss: 0.00017978198593482375
step: 520, loss: 0.045769527554512024
step: 530, loss: 0.046730488538742065
step: 540, loss: 0.025679903104901314
step: 550, loss: 0.0001697029802016914
step: 560, loss: 0.04496638849377632
step: 570, loss: 0.02721981704235077
step: 580, loss: 0.028811011463403702
step: 590, loss: 9.315089118899778e-05
step: 600, loss: 0.015819428488612175
step: 610, loss: 0.0003697620122693479
step: 620, loss: 0.007369161117821932
step: 630, loss: 0.02584199048578739
step: 640, loss: 0.014272617176175117
step: 650, loss: 0.03109564445912838
step: 660, loss: 0.05797131732106209
step: 670, loss: 0.017352301627397537
step: 680, loss: 0.10307874530553818
step: 690, loss: 0.017878947779536247
step: 700, loss: 0.06633689254522324
step: 710, loss: 0.006000842899084091
step: 720, loss: 0.023271122947335243
step: 730, loss: 0.023168694227933884
step: 740, loss: 0.02474643662571907
step: 750, loss: 0.024841193109750748
step: 760, loss: 4.29618994530756e-05
step: 770, loss: 0.01825215294957161
step: 780, loss: 6.787453912693309e-06
step: 790, loss: 0.04186991974711418
step: 800, loss: 0.08589032292366028
step: 810, loss: 0.060622911900281906
step: 820, loss: 0.033060308545827866
step: 830, loss: 7.791636016918346e-05
step: 840, loss: 0.00038934702752158046
step: 850, loss: 0.0005079972324892879
step: 860, loss: 0.00011180926230736077
step: 870, loss: 0.01939617097377777
step: 880, loss: 0.025747468695044518
step: 890, loss: 0.031702592968940735
step: 900, loss: 0.0738098993897438
step: 910, loss: 0.025622010231018066
step: 920, loss: 0.02042437717318535
step: 930, loss: 0.02885669656097889
step: 940, loss: 0.02532266639173031
step: 950, loss: 0.022225774824619293
step: 960, loss: 0.037789735943078995
step: 970, loss: 1.5406712918775156e-05
epoch 18: dev_f1=0.9316360207449317, f1=0.9241507677989763, best_f1=0.9306197964847363
step: 0, loss: 0.02742130309343338
step: 10, loss: 0.011181130073964596
step: 20, loss: 0.048705652356147766
step: 30, loss: 0.0003986544907093048
step: 40, loss: 0.0009537276346236467
step: 50, loss: 0.0008414631593041122
step: 60, loss: 0.014467873610556126
step: 70, loss: 0.05564659461379051
step: 80, loss: 6.247290912142489e-06
step: 90, loss: 1.553685979160946e-05
step: 100, loss: 0.00022504695516545326
step: 110, loss: 0.028819432482123375
step: 120, loss: 0.029888387769460678
step: 130, loss: 0.041809067130088806
step: 140, loss: 0.01524313073605299
step: 150, loss: 4.736603659694083e-05
step: 160, loss: 0.028466297313570976
step: 170, loss: 0.022330140694975853
step: 180, loss: 0.01774715632200241
step: 190, loss: 0.06740757822990417
step: 200, loss: 0.05008488520979881
step: 210, loss: 0.07181434333324432
step: 220, loss: 0.027553346008062363
step: 230, loss: 3.865555481752381e-05
step: 240, loss: 0.039912059903144836
step: 250, loss: 0.029509399086236954
step: 260, loss: 0.003000326221808791
step: 270, loss: 0.10028902441263199
step: 280, loss: 0.013085704296827316
step: 290, loss: 0.04734618589282036
step: 300, loss: 0.04425148665904999
step: 310, loss: 0.0577392615377903
step: 320, loss: 0.021413588896393776
step: 330, loss: 0.0006378809921443462
step: 340, loss: 0.00010925704555120319
step: 350, loss: 0.03240670636296272
step: 360, loss: 0.07190480083227158
step: 370, loss: 0.05828520283102989
step: 380, loss: 0.017462169751524925
step: 390, loss: 0.038707222789525986
step: 400, loss: 0.00023913048789836466
step: 410, loss: 0.021844178438186646
step: 420, loss: 0.04665582627058029
step: 430, loss: 0.05268717557191849
step: 440, loss: 0.0001572752371430397
step: 450, loss: 0.2152118980884552
step: 460, loss: 0.0005257863667793572
step: 470, loss: 0.08621631562709808
step: 480, loss: 0.015815692022442818
step: 490, loss: 0.020293110981583595
step: 500, loss: 0.05098622292280197
step: 510, loss: 0.02694554254412651
step: 520, loss: 0.00225206115283072
step: 530, loss: 0.08813724666833878
step: 540, loss: 0.05731043964624405
step: 550, loss: 0.022961799055337906
step: 560, loss: 0.016008444130420685
step: 570, loss: 0.0198662206530571
step: 580, loss: 0.02646191418170929
step: 590, loss: 0.0349009744822979
step: 600, loss: 0.04737160727381706
step: 610, loss: 3.32270901708398e-05
step: 620, loss: 0.03243141248822212
step: 630, loss: 0.0873916819691658
step: 640, loss: 0.00017213920364156365
step: 650, loss: 0.02213888056576252
step: 660, loss: 0.00028985089738853276
step: 670, loss: 8.80868174135685e-05
step: 680, loss: 0.06363196671009064
step: 690, loss: 0.038743872195482254
step: 700, loss: 4.754388646688312e-05
step: 710, loss: 0.06457768380641937
step: 720, loss: 0.00014611700316891074
step: 730, loss: 0.046809010207653046
step: 740, loss: 8.950772462412715e-05
step: 750, loss: 0.06439686566591263
step: 760, loss: 0.01763097755610943
step: 770, loss: 0.02064790390431881
step: 780, loss: 0.042643800377845764
step: 790, loss: 0.0005798282218165696
step: 800, loss: 0.02374139428138733
step: 810, loss: 0.0001242511352756992
step: 820, loss: 0.01929774135351181
step: 830, loss: 0.02962634339928627
step: 840, loss: 0.017573539167642593
step: 850, loss: 5.494475772138685e-05
step: 860, loss: 5.949988553766161e-05
step: 870, loss: 0.0975257009267807
step: 880, loss: 0.022423386573791504
step: 890, loss: 0.05061720684170723
step: 900, loss: 0.040319256484508514
step: 910, loss: 0.08858561515808105
step: 920, loss: 0.046120911836624146
step: 930, loss: 0.04517679661512375
step: 940, loss: 0.0003174068406224251
step: 950, loss: 0.04196402058005333
step: 960, loss: 7.65730655984953e-05
step: 970, loss: 0.00034122640499845147
epoch 19: dev_f1=0.9379374708352777, f1=0.9276164130935916, best_f1=0.9306197964847363
step: 0, loss: 0.052708711475133896
step: 10, loss: 0.0001242801226908341
step: 20, loss: 0.03717869892716408
step: 30, loss: 0.10438276827335358
step: 40, loss: 5.038991366745904e-05
step: 50, loss: 0.07081101089715958
step: 60, loss: 0.034130267798900604
step: 70, loss: 0.025263968855142593
step: 80, loss: 0.023554278537631035
step: 90, loss: 0.05114152282476425
step: 100, loss: 0.061783455312252045
step: 110, loss: 7.41862750146538e-05
step: 120, loss: 0.02488327957689762
step: 130, loss: 0.019387267529964447
step: 140, loss: 0.09742797911167145
step: 150, loss: 0.05420192331075668
step: 160, loss: 0.029517654329538345
step: 170, loss: 0.01166194211691618
step: 180, loss: 0.05358251556754112
step: 190, loss: 8.190789230866358e-05
step: 200, loss: 0.0513189397752285
step: 210, loss: 7.13049594196491e-05
step: 220, loss: 0.000216703861951828
step: 230, loss: 0.02561008185148239
step: 240, loss: 0.029285944998264313
step: 250, loss: 0.02377888560295105
step: 260, loss: 0.03947257623076439
step: 270, loss: 0.028346765786409378
step: 280, loss: 0.00011087275197496638
step: 290, loss: 0.021510273218154907
step: 300, loss: 0.0003093003761023283
step: 310, loss: 0.021160362288355827
step: 320, loss: 0.00031477713491767645
step: 330, loss: 0.02621646225452423
step: 340, loss: 2.9218806957942434e-05
step: 350, loss: 0.0112833883613348
step: 360, loss: 0.03750854358077049
step: 370, loss: 0.02108719013631344
step: 380, loss: 0.020905043929815292
step: 390, loss: 0.00023992023488972336
step: 400, loss: 4.309487121645361e-05
step: 410, loss: 0.03156639263033867
step: 420, loss: 0.037621475756168365
step: 430, loss: 0.037282027304172516
step: 440, loss: 0.0001035182795021683
step: 450, loss: 0.037781134247779846
step: 460, loss: 0.09787198156118393
step: 470, loss: 0.04904019460082054
step: 480, loss: 0.046709492802619934
step: 490, loss: 0.04693898558616638
step: 500, loss: 0.00010290042700944468
step: 510, loss: 0.05099460110068321
step: 520, loss: 0.021551642566919327
step: 530, loss: 0.038981515914201736
step: 540, loss: 0.019331784918904305
step: 550, loss: 0.032537560909986496
step: 560, loss: 0.038017455488443375
step: 570, loss: 0.02645985409617424
step: 580, loss: 0.10549851506948471
step: 590, loss: 5.572018926613964e-05
step: 600, loss: 0.08009201288223267
step: 610, loss: 6.979822501307353e-05
step: 620, loss: 0.001543805468827486
step: 630, loss: 0.00043274223571643233
step: 640, loss: 0.00048019157839007676
step: 650, loss: 0.02453700825572014
step: 660, loss: 0.00016637283260934055
step: 670, loss: 0.040864910930395126
step: 680, loss: 0.045595306903123856
step: 690, loss: 0.039284300059080124
step: 700, loss: 0.03560559079051018
step: 710, loss: 0.024131856858730316
step: 720, loss: 0.02185891568660736
step: 730, loss: 0.021481122821569443
step: 740, loss: 0.040958013385534286
step: 750, loss: 0.04112185165286064
step: 760, loss: 0.052920665591955185
step: 770, loss: 0.015899911522865295
step: 780, loss: 0.02899029850959778
step: 790, loss: 0.01408817432820797
step: 800, loss: 0.0003658614296000451
step: 810, loss: 0.00010016760643338785
step: 820, loss: 0.08964897692203522
step: 830, loss: 0.03802205249667168
step: 840, loss: 0.022822344675660133
step: 850, loss: 0.023366866633296013
step: 860, loss: 0.01730337366461754
step: 870, loss: 0.00011612162052188069
step: 880, loss: 0.03666731342673302
step: 890, loss: 0.049496762454509735
step: 900, loss: 0.028804687783122063
step: 910, loss: 0.015830256044864655
step: 920, loss: 0.004762725438922644
step: 930, loss: 0.0007160594104789197
step: 940, loss: 0.015613578259944916
step: 950, loss: 0.03363937884569168
step: 960, loss: 0.03119831345975399
step: 970, loss: 3.19119862979278e-05
epoch 20: dev_f1=0.9382022471910113, f1=0.9282739472466451, best_f1=0.9306197964847363
