cuda
Device: cuda
step: 0, loss: 0.8326908349990845
step: 10, loss: 0.3133558928966522
step: 20, loss: 0.3072821795940399
step: 30, loss: 0.3682461977005005
step: 40, loss: 0.25521472096443176
step: 50, loss: 0.2529219388961792
step: 60, loss: 0.13656307756900787
step: 70, loss: 0.11550905555486679
step: 80, loss: 0.21284425258636475
step: 90, loss: 0.2285786122083664
step: 100, loss: 0.2220090627670288
step: 110, loss: 0.04835797846317291
step: 120, loss: 0.19333158433437347
step: 130, loss: 0.10209597647190094
step: 140, loss: 0.15478065609931946
step: 150, loss: 0.19182232022285461
step: 160, loss: 0.1301584392786026
step: 170, loss: 0.09294084459543228
step: 180, loss: 0.1350899338722229
step: 190, loss: 0.11205271631479263
step: 200, loss: 0.05472555011510849
step: 210, loss: 0.19907894730567932
step: 220, loss: 0.1350833624601364
step: 230, loss: 0.1232961043715477
step: 240, loss: 0.16074049472808838
step: 250, loss: 0.12815523147583008
step: 260, loss: 0.13876692950725555
step: 270, loss: 0.09880391508340836
step: 280, loss: 0.17453652620315552
step: 290, loss: 0.1427168846130371
step: 300, loss: 0.11640838533639908
step: 310, loss: 0.17669914662837982
step: 320, loss: 0.0645209327340126
step: 330, loss: 0.04354240000247955
step: 340, loss: 0.2047639787197113
step: 350, loss: 0.07279672473669052
step: 360, loss: 0.3495095670223236
step: 370, loss: 0.07012304663658142
step: 380, loss: 0.1701626032590866
step: 390, loss: 0.296857625246048
step: 400, loss: 0.23374736309051514
step: 410, loss: 0.12737730145454407
step: 420, loss: 0.09613686800003052
step: 430, loss: 0.06111787632107735
step: 440, loss: 0.07956315577030182
step: 450, loss: 0.09842271357774734
step: 460, loss: 0.15768848359584808
step: 470, loss: 0.06695766746997833
step: 480, loss: 0.022551389411091805
step: 490, loss: 0.12177274376153946
step: 500, loss: 0.10916174203157425
step: 510, loss: 0.0789552628993988
step: 520, loss: 0.06335282325744629
step: 530, loss: 0.0388614758849144
step: 540, loss: 0.09761800616979599
step: 550, loss: 0.06395690888166428
step: 560, loss: 0.020846610888838768
step: 570, loss: 0.01959562487900257
step: 580, loss: 0.1243109181523323
step: 590, loss: 0.10446196049451828
step: 600, loss: 0.10577413439750671
step: 610, loss: 0.21417520940303802
step: 620, loss: 0.05769946053624153
step: 630, loss: 0.14588145911693573
step: 640, loss: 0.08960319310426712
step: 650, loss: 0.16746361553668976
step: 660, loss: 0.06975284963846207
step: 670, loss: 0.03323251008987427
step: 680, loss: 0.10029133409261703
step: 690, loss: 0.01250174269080162
step: 700, loss: 0.028560487553477287
step: 710, loss: 0.2044041007757187
step: 720, loss: 0.05168655142188072
step: 730, loss: 0.12772199511528015
step: 740, loss: 0.10318486392498016
step: 750, loss: 0.10349638015031815
step: 760, loss: 0.019359270110726357
step: 770, loss: 0.06537416577339172
step: 780, loss: 0.20739449560642242
step: 790, loss: 0.05542236194014549
step: 800, loss: 0.1941831409931183
step: 810, loss: 0.08692415803670883
step: 820, loss: 0.09935178607702255
step: 830, loss: 0.12998484075069427
step: 840, loss: 0.041424158960580826
step: 850, loss: 0.0668555200099945
step: 860, loss: 0.060888879001140594
step: 870, loss: 0.12996838986873627
step: 880, loss: 0.03250802680850029
step: 890, loss: 0.014661294408142567
step: 900, loss: 0.1042688637971878
step: 910, loss: 0.06252479553222656
step: 920, loss: 0.07171730697154999
step: 930, loss: 0.050519876182079315
step: 940, loss: 0.1905694305896759
step: 950, loss: 0.10760307312011719
step: 960, loss: 0.1002863273024559
step: 970, loss: 0.09992094337940216
epoch 1: dev_f1=0.9256198347107438, f1=0.9307832422586522, best_f1=0.9307832422586522
step: 0, loss: 0.02813446708023548
step: 10, loss: 0.13873285055160522
step: 20, loss: 0.0568603090941906
step: 30, loss: 0.062008388340473175
step: 40, loss: 0.11638455092906952
step: 50, loss: 0.15617428719997406
step: 60, loss: 0.03631636127829552
step: 70, loss: 0.05941389873623848
step: 80, loss: 0.061400897800922394
step: 90, loss: 0.07589990645647049
step: 100, loss: 0.021394582465291023
step: 110, loss: 0.021357692778110504
step: 120, loss: 0.10630105435848236
step: 130, loss: 0.11827909201383591
step: 140, loss: 0.04696224257349968
step: 150, loss: 0.25147393345832825
step: 160, loss: 0.06175440922379494
step: 170, loss: 0.15288449823856354
step: 180, loss: 0.05960162356495857
step: 190, loss: 0.06430332362651825
step: 200, loss: 0.17170816659927368
step: 210, loss: 0.05313509330153465
step: 220, loss: 0.07772931456565857
step: 230, loss: 0.09349720180034637
step: 240, loss: 0.010782388038933277
step: 250, loss: 0.1365920901298523
step: 260, loss: 0.14043359458446503
step: 270, loss: 0.12369002401828766
step: 280, loss: 0.10704120248556137
step: 290, loss: 0.07214950025081635
step: 300, loss: 0.16733390092849731
step: 310, loss: 0.185028538107872
step: 320, loss: 0.041920535266399384
step: 330, loss: 0.0006255458574742079
step: 340, loss: 0.1757936328649521
step: 350, loss: 0.21929988265037537
step: 360, loss: 0.18251341581344604
step: 370, loss: 0.03296294063329697
step: 380, loss: 0.18873843550682068
step: 390, loss: 0.11630833894014359
step: 400, loss: 0.19015935063362122
step: 410, loss: 0.15626603364944458
step: 420, loss: 0.014347480610013008
step: 430, loss: 0.13560640811920166
step: 440, loss: 0.06848065555095673
step: 450, loss: 0.07534102350473404
step: 460, loss: 0.049025192856788635
step: 470, loss: 0.05168471112847328
step: 480, loss: 0.07781399041414261
step: 490, loss: 0.025309013202786446
step: 500, loss: 0.1292911022901535
step: 510, loss: 0.20739246904850006
step: 520, loss: 0.09076465666294098
step: 530, loss: 0.15695828199386597
step: 540, loss: 0.11207307130098343
step: 550, loss: 0.044302843511104584
step: 560, loss: 0.05627425014972687
step: 570, loss: 0.052212197333574295
step: 580, loss: 0.05109129846096039
step: 590, loss: 0.09623777866363525
step: 600, loss: 0.07963906973600388
step: 610, loss: 0.14683687686920166
step: 620, loss: 0.11861981451511383
step: 630, loss: 0.20706817507743835
step: 640, loss: 0.13827048242092133
step: 650, loss: 0.19555938243865967
step: 660, loss: 0.002364847343415022
step: 670, loss: 0.047492366284132004
step: 680, loss: 0.15498268604278564
step: 690, loss: 0.026724068447947502
step: 700, loss: 0.12776464223861694
step: 710, loss: 0.12489338964223862
step: 720, loss: 0.03489368408918381
step: 730, loss: 0.07048451900482178
step: 740, loss: 0.17942550778388977
step: 750, loss: 0.06627663224935532
step: 760, loss: 0.07422851771116257
step: 770, loss: 0.05259105563163757
step: 780, loss: 0.03299691900610924
step: 790, loss: 0.07029639184474945
step: 800, loss: 0.10121208429336548
step: 810, loss: 0.1520884931087494
step: 820, loss: 0.08873702585697174
step: 830, loss: 0.0018546695355325937
step: 840, loss: 0.06105976551771164
step: 850, loss: 0.03079572319984436
step: 860, loss: 0.0724698081612587
step: 870, loss: 0.12382837384939194
step: 880, loss: 0.16496898233890533
step: 890, loss: 0.14011897146701813
step: 900, loss: 0.10585525631904602
step: 910, loss: 0.08209316432476044
step: 920, loss: 0.11591153591871262
step: 930, loss: 0.08180911839008331
step: 940, loss: 0.10531128942966461
step: 950, loss: 0.05231025069952011
step: 960, loss: 0.15970104932785034
step: 970, loss: 0.06674841046333313
epoch 2: dev_f1=0.9393939393939394, f1=0.9371271225332722, best_f1=0.9371271225332722
step: 0, loss: 0.026806261390447617
step: 10, loss: 0.016554685309529305
step: 20, loss: 0.06540586054325104
step: 30, loss: 0.16947254538536072
step: 40, loss: 0.07756983488798141
step: 50, loss: 0.12126535922288895
step: 60, loss: 0.10527969896793365
step: 70, loss: 0.08355823159217834
step: 80, loss: 0.1170717254281044
step: 90, loss: 0.06436720490455627
step: 100, loss: 0.07856318354606628
step: 110, loss: 0.17457029223442078
step: 120, loss: 0.0473252534866333
step: 130, loss: 0.12102184444665909
step: 140, loss: 0.07056955993175507
step: 150, loss: 0.12159496545791626
step: 160, loss: 0.06734628230333328
step: 170, loss: 0.019827861338853836
step: 180, loss: 0.09985872358083725
step: 190, loss: 0.06145833432674408
step: 200, loss: 0.09867942333221436
step: 210, loss: 0.07548332214355469
step: 220, loss: 0.03770529851317406
step: 230, loss: 0.0181876327842474
step: 240, loss: 0.09805204719305038
step: 250, loss: 0.03438539803028107
step: 260, loss: 0.08440564572811127
step: 270, loss: 0.22416305541992188
step: 280, loss: 0.1467648148536682
step: 290, loss: 0.024206217378377914
step: 300, loss: 0.06336315721273422
step: 310, loss: 0.07280255854129791
step: 320, loss: 0.12788236141204834
step: 330, loss: 0.11330921202898026
step: 340, loss: 0.07643789052963257
step: 350, loss: 0.0362793505191803
step: 360, loss: 0.12774814665317535
step: 370, loss: 0.062421493232250214
step: 380, loss: 0.037444137036800385
step: 390, loss: 0.030176421627402306
step: 400, loss: 0.15448270738124847
step: 410, loss: 0.012168243527412415
step: 420, loss: 0.11205198615789413
step: 430, loss: 0.053444087505340576
step: 440, loss: 0.07292116433382034
step: 450, loss: 0.250324010848999
step: 460, loss: 0.052998580038547516
step: 470, loss: 0.07241763919591904
step: 480, loss: 0.026416152715682983
step: 490, loss: 0.012214777991175652
step: 500, loss: 0.13183936476707458
step: 510, loss: 0.03385324403643608
step: 520, loss: 0.0774650052189827
step: 530, loss: 0.077049121260643
step: 540, loss: 0.05254369229078293
step: 550, loss: 0.060197651386260986
step: 560, loss: 0.07431880384683609
step: 570, loss: 0.08226899057626724
step: 580, loss: 0.0626143142580986
step: 590, loss: 0.12631164491176605
step: 600, loss: 0.12600396573543549
step: 610, loss: 0.11200132966041565
step: 620, loss: 0.04093819484114647
step: 630, loss: 0.0659564733505249
step: 640, loss: 0.042036958038806915
step: 650, loss: 0.09806688129901886
step: 660, loss: 0.08317144215106964
step: 670, loss: 0.11758733540773392
step: 680, loss: 0.09180711209774017
step: 690, loss: 0.0768684446811676
step: 700, loss: 0.0890112817287445
step: 710, loss: 0.07761280983686447
step: 720, loss: 0.12327065318822861
step: 730, loss: 0.07856622338294983
step: 740, loss: 0.11004827171564102
step: 750, loss: 0.006660816725343466
step: 760, loss: 0.10718107968568802
step: 770, loss: 0.027433494105935097
step: 780, loss: 0.07461140304803848
step: 790, loss: 0.018932998180389404
step: 800, loss: 0.09490878880023956
step: 810, loss: 0.10670231282711029
step: 820, loss: 0.026500292122364044
step: 830, loss: 0.06526218354701996
step: 840, loss: 0.08006608486175537
step: 850, loss: 0.07970339059829712
step: 860, loss: 0.1591581404209137
step: 870, loss: 0.06101059541106224
step: 880, loss: 0.11643734574317932
step: 890, loss: 0.09491997957229614
step: 900, loss: 0.03861275315284729
step: 910, loss: 0.027112752199172974
step: 920, loss: 0.08602412790060043
step: 930, loss: 0.09664718061685562
step: 940, loss: 0.029219334945082664
step: 950, loss: 0.10396451503038406
step: 960, loss: 0.03486601263284683
step: 970, loss: 0.017223693430423737
epoch 3: dev_f1=0.9372693726937269, f1=0.9322892676186089, best_f1=0.9371271225332722
step: 0, loss: 0.010083282366394997
step: 10, loss: 0.11025119572877884
step: 20, loss: 0.07132704555988312
step: 30, loss: 0.047400541603565216
step: 40, loss: 0.06274845451116562
step: 50, loss: 0.11339154839515686
step: 60, loss: 0.1248466745018959
step: 70, loss: 0.022794300690293312
step: 80, loss: 0.07187565416097641
step: 90, loss: 0.006927465088665485
step: 100, loss: 0.06009814888238907
step: 110, loss: 0.06451962888240814
step: 120, loss: 0.02090158313512802
step: 130, loss: 0.036067117005586624
step: 140, loss: 0.12561655044555664
step: 150, loss: 0.21634890139102936
step: 160, loss: 0.052879367023706436
step: 170, loss: 0.13724535703659058
step: 180, loss: 0.00960421934723854
step: 190, loss: 0.025169597938656807
step: 200, loss: 0.10344593971967697
step: 210, loss: 0.05588453263044357
step: 220, loss: 0.18310143053531647
step: 230, loss: 0.08988307416439056
step: 240, loss: 0.10905854403972626
step: 250, loss: 0.12657412886619568
step: 260, loss: 0.09801188111305237
step: 270, loss: 0.08045076578855515
step: 280, loss: 0.07216712832450867
step: 290, loss: 0.08554596453905106
step: 300, loss: 0.0580524317920208
step: 310, loss: 0.10240890830755234
step: 320, loss: 0.021440895274281502
step: 330, loss: 0.011661767959594727
step: 340, loss: 0.067912258207798
step: 350, loss: 0.01948615349829197
step: 360, loss: 0.08085397630929947
step: 370, loss: 0.017249083146452904
step: 380, loss: 0.15849949419498444
step: 390, loss: 0.11849703639745712
step: 400, loss: 0.07880660146474838
step: 410, loss: 0.08659344911575317
step: 420, loss: 0.06445247679948807
step: 430, loss: 0.05850681662559509
step: 440, loss: 0.0880250632762909
step: 450, loss: 0.1740996241569519
step: 460, loss: 0.08078286796808243
step: 470, loss: 0.2566196322441101
step: 480, loss: 0.01880660280585289
step: 490, loss: 0.19847746193408966
step: 500, loss: 0.08690471947193146
step: 510, loss: 0.039345599710941315
step: 520, loss: 0.036721065640449524
step: 530, loss: 0.10062321275472641
step: 540, loss: 0.07843302190303802
step: 550, loss: 0.05383973941206932
step: 560, loss: 0.03861891105771065
step: 570, loss: 0.10759512335062027
step: 580, loss: 0.061821747571229935
step: 590, loss: 0.15821632742881775
step: 600, loss: 0.13614140450954437
step: 610, loss: 0.08274032175540924
step: 620, loss: 0.0813361331820488
step: 630, loss: 0.07248354703187943
step: 640, loss: 0.029132461175322533
step: 650, loss: 0.04870026931166649
step: 660, loss: 0.09756480157375336
step: 670, loss: 0.030043091624975204
step: 680, loss: 0.08687417209148407
step: 690, loss: 0.07619582861661911
step: 700, loss: 0.11886142939329147
step: 710, loss: 0.03856384754180908
step: 720, loss: 0.1626523733139038
step: 730, loss: 0.07793693989515305
step: 740, loss: 0.06778941303491592
step: 750, loss: 0.1477486789226532
step: 760, loss: 0.12798787653446198
step: 770, loss: 0.0252024345099926
step: 780, loss: 0.04473213478922844
step: 790, loss: 0.05374184250831604
step: 800, loss: 0.10137255489826202
step: 810, loss: 0.09444605559110641
step: 820, loss: 0.08771073073148727
step: 830, loss: 0.07629323750734329
step: 840, loss: 0.06697404384613037
step: 850, loss: 0.0668877512216568
step: 860, loss: 0.040247540920972824
step: 870, loss: 0.08886650204658508
step: 880, loss: 0.1311686635017395
step: 890, loss: 0.03398081660270691
step: 900, loss: 0.10434673726558685
step: 910, loss: 0.09634477645158768
step: 920, loss: 0.11847316473722458
step: 930, loss: 0.05898909643292427
step: 940, loss: 0.011251164600253105
step: 950, loss: 0.013014094904065132
step: 960, loss: 0.023015566170215607
step: 970, loss: 0.1604815125465393
epoch 4: dev_f1=0.937763219466542, f1=0.9329608938547487, best_f1=0.9371271225332722
step: 0, loss: 0.008741251192986965
step: 10, loss: 0.029559696093201637
step: 20, loss: 0.18603840470314026
step: 30, loss: 0.11156830191612244
step: 40, loss: 0.029725447297096252
step: 50, loss: 0.007034773007035255
step: 60, loss: 0.09449118375778198
step: 70, loss: 0.10563590377569199
step: 80, loss: 0.04357012361288071
step: 90, loss: 0.01635982282459736
step: 100, loss: 0.14726193249225616
step: 110, loss: 0.06560315191745758
step: 120, loss: 0.013531813398003578
step: 130, loss: 0.06727030128240585
step: 140, loss: 0.06406351178884506
step: 150, loss: 0.2318371683359146
step: 160, loss: 0.014925731346011162
step: 170, loss: 0.004987290129065514
step: 180, loss: 0.015346110798418522
step: 190, loss: 0.20255796611309052
step: 200, loss: 0.15474846959114075
step: 210, loss: 0.055480729788541794
step: 220, loss: 0.029782580211758614
step: 230, loss: 0.026183294132351875
step: 240, loss: 0.0340876504778862
step: 250, loss: 0.031072262674570084
step: 260, loss: 0.07868009060621262
step: 270, loss: 0.017596155405044556
step: 280, loss: 0.018328797072172165
step: 290, loss: 0.049157705157995224
step: 300, loss: 0.02269866317510605
step: 310, loss: 0.0326271615922451
step: 320, loss: 0.13885337114334106
step: 330, loss: 0.004870294593274593
step: 340, loss: 0.03674130514264107
step: 350, loss: 0.06022147089242935
step: 360, loss: 0.11018776148557663
step: 370, loss: 0.018094293773174286
step: 380, loss: 0.003144881222397089
step: 390, loss: 0.01716785319149494
step: 400, loss: 0.06954323500394821
step: 410, loss: 0.15603551268577576
step: 420, loss: 0.012300694361329079
step: 430, loss: 0.06974565237760544
step: 440, loss: 0.06350578367710114
step: 450, loss: 0.05069704353809357
step: 460, loss: 0.04195981100201607
step: 470, loss: 0.03274437040090561
step: 480, loss: 0.011714469641447067
step: 490, loss: 0.1217527985572815
step: 500, loss: 0.024388911202549934
step: 510, loss: 0.02871556580066681
step: 520, loss: 0.025483641773462296
step: 530, loss: 0.17619174718856812
step: 540, loss: 0.1300128698348999
step: 550, loss: 0.11565899103879929
step: 560, loss: 0.12242993712425232
step: 570, loss: 0.08518171310424805
step: 580, loss: 0.07976622134447098
step: 590, loss: 0.05005771666765213
step: 600, loss: 0.13096745312213898
step: 610, loss: 0.09302057325839996
step: 620, loss: 0.07126091420650482
step: 630, loss: 0.050810106098651886
step: 640, loss: 0.017112284898757935
step: 650, loss: 0.18593423068523407
step: 660, loss: 0.02494138665497303
step: 670, loss: 0.07866006344556808
step: 680, loss: 0.030613398179411888
step: 690, loss: 0.03314443677663803
step: 700, loss: 0.07927458733320236
step: 710, loss: 0.07483381778001785
step: 720, loss: 0.06264501065015793
step: 730, loss: 0.12997034192085266
step: 740, loss: 0.162522554397583
step: 750, loss: 0.08484728634357452
step: 760, loss: 0.08508211374282837
step: 770, loss: 0.07143751531839371
step: 780, loss: 0.071875661611557
step: 790, loss: 0.03040090762078762
step: 800, loss: 0.09705939888954163
step: 810, loss: 0.03551388531923294
step: 820, loss: 0.007311176974326372
step: 830, loss: 0.05670255795121193
step: 840, loss: 0.1497727483510971
step: 850, loss: 0.013796650804579258
step: 860, loss: 0.12061822414398193
step: 870, loss: 0.015071745030581951
step: 880, loss: 0.02091871201992035
step: 890, loss: 0.07454464584589005
step: 900, loss: 0.07618173956871033
step: 910, loss: 0.013681723736226559
step: 920, loss: 0.09091829508543015
step: 930, loss: 0.02675456553697586
step: 940, loss: 0.07191994041204453
step: 950, loss: 0.015008143149316311
step: 960, loss: 0.10935021936893463
step: 970, loss: 0.09467677772045135
epoch 5: dev_f1=0.9393090569561158, f1=0.9373549883990719, best_f1=0.9371271225332722
step: 0, loss: 0.01054023951292038
step: 10, loss: 0.055397745221853256
step: 20, loss: 0.07044309377670288
step: 30, loss: 0.01862807758152485
step: 40, loss: 0.02237534336745739
step: 50, loss: 0.11042365431785583
step: 60, loss: 0.03313480317592621
step: 70, loss: 0.007513416465371847
step: 80, loss: 0.06673818826675415
step: 90, loss: 0.017530353739857674
step: 100, loss: 0.0946914404630661
step: 110, loss: 0.029630422592163086
step: 120, loss: 0.0012274296022951603
step: 130, loss: 0.026710184291005135
step: 140, loss: 0.22770681977272034
step: 150, loss: 0.031719405204057693
step: 160, loss: 0.14250093698501587
step: 170, loss: 0.014377908781170845
step: 180, loss: 0.028647135943174362
step: 190, loss: 0.01338229887187481
step: 200, loss: 0.08144024759531021
step: 210, loss: 0.005140423774719238
step: 220, loss: 0.048117976635694504
step: 230, loss: 0.010456214658915997
step: 240, loss: 0.10368003696203232
step: 250, loss: 0.026970524340867996
step: 260, loss: 0.050629958510398865
step: 270, loss: 0.03029203787446022
step: 280, loss: 0.07254520058631897
step: 290, loss: 0.06544670462608337
step: 300, loss: 0.1355990618467331
step: 310, loss: 0.015397531911730766
step: 320, loss: 0.0770544558763504
step: 330, loss: 0.021630797535181046
step: 340, loss: 0.07129797339439392
step: 350, loss: 0.014280288480222225
step: 360, loss: 0.15483757853507996
step: 370, loss: 0.1188618615269661
step: 380, loss: 0.08320312201976776
step: 390, loss: 0.07559014111757278
step: 400, loss: 0.0068067219108343124
step: 410, loss: 0.013044753111898899
step: 420, loss: 0.09603142738342285
step: 430, loss: 0.029160309582948685
step: 440, loss: 0.09471961110830307
step: 450, loss: 0.0370161272585392
step: 460, loss: 0.07770541310310364
step: 470, loss: 0.026892993599176407
step: 480, loss: 0.012350616045296192
step: 490, loss: 0.055945977568626404
step: 500, loss: 0.081269271671772
step: 510, loss: 0.032340485602617264
step: 520, loss: 0.036993175745010376
step: 530, loss: 0.02012866735458374
step: 540, loss: 0.07776957005262375
step: 550, loss: 0.012227452360093594
step: 560, loss: 0.09745123237371445
step: 570, loss: 0.08385562896728516
step: 580, loss: 3.236473639844917e-05
step: 590, loss: 0.027507204562425613
step: 600, loss: 0.009079664945602417
step: 610, loss: 0.09756577759981155
step: 620, loss: 0.08529755473136902
step: 630, loss: 0.20290623605251312
step: 640, loss: 0.05736300349235535
step: 650, loss: 0.06017627939581871
step: 660, loss: 0.03784295544028282
step: 670, loss: 0.10479827970266342
step: 680, loss: 0.04996393993496895
step: 690, loss: 0.011287268251180649
step: 700, loss: 0.0151494350284338
step: 710, loss: 0.029573852196335793
step: 720, loss: 0.11299794912338257
step: 730, loss: 0.11123054474592209
step: 740, loss: 0.10411553829908371
step: 750, loss: 0.023377107456326485
step: 760, loss: 0.012190748006105423
step: 770, loss: 0.03398972377181053
step: 780, loss: 0.08888016641139984
step: 790, loss: 0.10355383157730103
step: 800, loss: 0.016679655760526657
step: 810, loss: 0.015023209154605865
step: 820, loss: 0.042541973292827606
step: 830, loss: 0.08188604563474655
step: 840, loss: 0.06124129146337509
step: 850, loss: 0.030997175723314285
step: 860, loss: 0.1062534898519516
step: 870, loss: 0.04056071117520332
step: 880, loss: 0.01850229874253273
step: 890, loss: 0.14872094988822937
step: 900, loss: 0.032072000205516815
step: 910, loss: 0.0210932195186615
step: 920, loss: 0.07454495131969452
step: 930, loss: 0.22563481330871582
step: 940, loss: 0.03505472093820572
step: 950, loss: 0.007740376517176628
step: 960, loss: 0.0808420404791832
step: 970, loss: 0.017143413424491882
epoch 6: dev_f1=0.9388915206063476, f1=0.9222699093943729, best_f1=0.9371271225332722
step: 0, loss: 0.0032983068376779556
step: 10, loss: 0.05224399268627167
step: 20, loss: 0.02009190060198307
step: 30, loss: 7.825979264453053e-05
step: 40, loss: 0.000408252322813496
step: 50, loss: 0.13834165036678314
step: 60, loss: 0.034609343856573105
step: 70, loss: 0.01524515450000763
step: 80, loss: 0.03816916048526764
step: 90, loss: 0.14239230751991272
step: 100, loss: 0.09167460352182388
step: 110, loss: 0.04312580078840256
step: 120, loss: 0.06330090761184692
step: 130, loss: 0.07287609577178955
step: 140, loss: 0.02328982762992382
step: 150, loss: 0.06483794003725052
step: 160, loss: 0.02123834192752838
step: 170, loss: 0.2097906768321991
step: 180, loss: 0.010998193174600601
step: 190, loss: 0.07459603995084763
step: 200, loss: 0.06374508887529373
step: 210, loss: 0.05353640019893646
step: 220, loss: 0.03442658856511116
step: 230, loss: 0.14157994091510773
step: 240, loss: 0.0851258933544159
step: 250, loss: 0.07906276732683182
step: 260, loss: 0.017746025696396828
step: 270, loss: 0.005290909670293331
step: 280, loss: 0.040143806487321854
step: 290, loss: 0.10325842350721359
step: 300, loss: 0.012214367277920246
step: 310, loss: 0.07934319227933884
step: 320, loss: 0.019508998841047287
step: 330, loss: 0.023278165608644485
step: 340, loss: 0.024932073429226875
step: 350, loss: 0.03249571472406387
step: 360, loss: 0.017195207998156548
step: 370, loss: 0.11590436846017838
step: 380, loss: 0.034499384462833405
step: 390, loss: 0.03290257602930069
step: 400, loss: 0.07168162614107132
step: 410, loss: 0.06629133969545364
step: 420, loss: 0.027144670486450195
step: 430, loss: 0.016549549996852875
step: 440, loss: 0.12360402941703796
step: 450, loss: 0.0670144259929657
step: 460, loss: 0.08508676290512085
step: 470, loss: 0.14095483720302582
step: 480, loss: 0.03090318664908409
step: 490, loss: 0.09389103204011917
step: 500, loss: 0.02820890210568905
step: 510, loss: 0.01574745774269104
step: 520, loss: 0.006733860820531845
step: 530, loss: 0.1168641448020935
step: 540, loss: 0.07062909752130508
step: 550, loss: 0.02961382456123829
step: 560, loss: 0.017594872042536736
step: 570, loss: 0.01621886156499386
step: 580, loss: 0.08530541509389877
step: 590, loss: 0.013870706781744957
step: 600, loss: 0.021143265068531036
step: 610, loss: 0.101927749812603
step: 620, loss: 0.06351582705974579
step: 630, loss: 0.09892944991588593
step: 640, loss: 0.06601530313491821
step: 650, loss: 0.12303201109170914
step: 660, loss: 0.09733984619379044
step: 670, loss: 0.033587176352739334
step: 680, loss: 0.12398868054151535
step: 690, loss: 0.026518719270825386
step: 700, loss: 0.05116935446858406
step: 710, loss: 0.10136672854423523
step: 720, loss: 0.028779860585927963
step: 730, loss: 0.048477355390787125
step: 740, loss: 0.057368598878383636
step: 750, loss: 0.08777818828821182
step: 760, loss: 0.0887162908911705
step: 770, loss: 0.04641789570450783
step: 780, loss: 0.09751694649457932
step: 790, loss: 0.01913881115615368
step: 800, loss: 0.0163376834243536
step: 810, loss: 0.018213067203760147
step: 820, loss: 0.11931964755058289
step: 830, loss: 0.16827644407749176
step: 840, loss: 0.05523141473531723
step: 850, loss: 0.1540626883506775
step: 860, loss: 0.028602078557014465
step: 870, loss: 0.08519253879785538
step: 880, loss: 0.06172650307416916
step: 890, loss: 0.10792594403028488
step: 900, loss: 0.00881296955049038
step: 910, loss: 0.03632728382945061
step: 920, loss: 0.18672937154769897
step: 930, loss: 0.0689232349395752
step: 940, loss: 0.006972499191761017
step: 950, loss: 0.04262422397732735
step: 960, loss: 0.06701411306858063
step: 970, loss: 0.07348767668008804
epoch 7: dev_f1=0.937763219466542, f1=0.9331476323119777, best_f1=0.9371271225332722
step: 0, loss: 0.053322724997997284
step: 10, loss: 0.12039179354906082
step: 20, loss: 0.08413440734148026
step: 30, loss: 0.05219831317663193
step: 40, loss: 0.09972728043794632
step: 50, loss: 0.12891241908073425
step: 60, loss: 0.025003407150506973
step: 70, loss: 0.07112598419189453
step: 80, loss: 0.03333578631281853
step: 90, loss: 0.09531781822443008
step: 100, loss: 0.014283867552876472
step: 110, loss: 0.11418866366147995
step: 120, loss: 0.15704093873500824
step: 130, loss: 0.0026085274294018745
step: 140, loss: 0.014968144707381725
step: 150, loss: 0.17943425476551056
step: 160, loss: 0.02805977687239647
step: 170, loss: 0.027701176702976227
step: 180, loss: 0.08183106780052185
step: 190, loss: 0.013882622122764587
step: 200, loss: 0.018883826211094856
step: 210, loss: 0.041194550693035126
step: 220, loss: 0.014587726444005966
step: 230, loss: 0.004822448827326298
step: 240, loss: 0.1409584879875183
step: 250, loss: 0.038270141929388046
step: 260, loss: 0.00818395335227251
step: 270, loss: 0.00027005403535440564
step: 280, loss: 0.004642216954380274
step: 290, loss: 0.03377380967140198
step: 300, loss: 0.06620483845472336
step: 310, loss: 0.10311651974916458
step: 320, loss: 0.0803663358092308
step: 330, loss: 0.009883936494588852
step: 340, loss: 0.10837819427251816
step: 350, loss: 0.003633971558883786
step: 360, loss: 0.043710943311452866
step: 370, loss: 0.005276298616081476
step: 380, loss: 0.033780526369810104
step: 390, loss: 0.05908329039812088
step: 400, loss: 0.06145903468132019
step: 410, loss: 0.04652244225144386
step: 420, loss: 0.018738947808742523
step: 430, loss: 0.03442807495594025
step: 440, loss: 0.09853571653366089
step: 450, loss: 0.016152044758200645
step: 460, loss: 0.032278817147016525
step: 470, loss: 0.020189661532640457
step: 480, loss: 0.03057049587368965
step: 490, loss: 0.034773532301187515
step: 500, loss: 0.023910824209451675
step: 510, loss: 0.07898271083831787
step: 520, loss: 0.01652091182768345
step: 530, loss: 0.06677929311990738
step: 540, loss: 0.008038051426410675
step: 550, loss: 0.017710311338305473
step: 560, loss: 0.028535878285765648
step: 570, loss: 0.08977731317281723
step: 580, loss: 0.02928992733359337
step: 590, loss: 0.04926687106490135
step: 600, loss: 0.021918758749961853
step: 610, loss: 0.08105571568012238
step: 620, loss: 0.05996416509151459
step: 630, loss: 0.03250157833099365
step: 640, loss: 0.06477806717157364
step: 650, loss: 0.10733145475387573
step: 660, loss: 0.08361341059207916
step: 670, loss: 0.00984498206526041
step: 680, loss: 0.028452491387724876
step: 690, loss: 0.013000457547605038
step: 700, loss: 0.0038444786332547665
step: 710, loss: 0.036858148872852325
step: 720, loss: 0.05976997688412666
step: 730, loss: 0.1088607907295227
step: 740, loss: 0.05962652340531349
step: 750, loss: 0.024212002754211426
step: 760, loss: 0.06196871027350426
step: 770, loss: 0.03336012363433838
step: 780, loss: 0.011239676736295223
step: 790, loss: 0.10923240333795547
step: 800, loss: 0.05469399318099022
step: 810, loss: 0.1629217267036438
step: 820, loss: 0.1540118157863617
step: 830, loss: 0.04777832701802254
step: 840, loss: 0.03467046469449997
step: 850, loss: 0.09433874487876892
step: 860, loss: 0.02687602862715721
step: 870, loss: 0.07486329227685928
step: 880, loss: 0.06517495959997177
step: 890, loss: 0.06822285801172256
step: 900, loss: 0.03458450734615326
step: 910, loss: 0.08580232411623001
step: 920, loss: 0.00678851967677474
step: 930, loss: 0.010477809235453606
step: 940, loss: 0.014042433351278305
step: 950, loss: 0.019730549305677414
step: 960, loss: 0.015410218387842178
step: 970, loss: 0.10017503052949905
epoch 8: dev_f1=0.9378995433789954, f1=0.9347329986307622, best_f1=0.9371271225332722
step: 0, loss: 0.03162276744842529
step: 10, loss: 0.10962438583374023
step: 20, loss: 0.04739304259419441
step: 30, loss: 0.0032785397488623857
step: 40, loss: 0.12384869158267975
step: 50, loss: 0.13040724396705627
step: 60, loss: 0.0106727983802557
step: 70, loss: 0.02243204414844513
step: 80, loss: 0.12095233798027039
step: 90, loss: 0.07760412991046906
step: 100, loss: 0.020497985184192657
step: 110, loss: 0.0784502774477005
step: 120, loss: 0.1006186380982399
step: 130, loss: 0.18516215682029724
step: 140, loss: 0.09593057632446289
step: 150, loss: 0.015468577854335308
step: 160, loss: 0.058117009699344635
step: 170, loss: 0.06502608209848404
step: 180, loss: 0.1293313354253769
step: 190, loss: 0.06254241615533829
step: 200, loss: 0.029448434710502625
step: 210, loss: 0.06845633685588837
step: 220, loss: 0.012450961396098137
step: 230, loss: 0.07316900044679642
step: 240, loss: 0.011150149628520012
step: 250, loss: 0.015040149912238121
step: 260, loss: 0.022529497742652893
step: 270, loss: 0.029793884605169296
step: 280, loss: 0.011954423040151596
step: 290, loss: 0.11753398180007935
step: 300, loss: 0.13266806304454803
step: 310, loss: 0.11208803951740265
step: 320, loss: 0.06915930658578873
step: 330, loss: 0.04071037471294403
step: 340, loss: 0.022253738716244698
step: 350, loss: 0.031377360224723816
step: 360, loss: 0.08283068984746933
step: 370, loss: 0.06578026711940765
step: 380, loss: 0.08572155237197876
step: 390, loss: 0.007374896202236414
step: 400, loss: 0.011663547717034817
step: 410, loss: 0.06381568312644958
step: 420, loss: 0.07081305980682373
step: 430, loss: 0.1126437559723854
step: 440, loss: 0.03975953906774521
step: 450, loss: 0.052932292222976685
step: 460, loss: 0.03101327270269394
step: 470, loss: 0.09224274009466171
step: 480, loss: 0.10185405611991882
step: 490, loss: 0.0362706184387207
step: 500, loss: 0.1390129029750824
step: 510, loss: 0.0432376004755497
step: 520, loss: 0.03318750485777855
step: 530, loss: 0.013061129488050938
step: 540, loss: 0.02468147873878479
step: 550, loss: 0.006245873402804136
step: 560, loss: 0.1899617612361908
step: 570, loss: 0.05631968751549721
step: 580, loss: 0.06959084421396255
step: 590, loss: 0.08478881418704987
step: 600, loss: 0.05253664031624794
step: 610, loss: 0.011354928836226463
step: 620, loss: 0.0867609977722168
step: 630, loss: 0.04995165392756462
step: 640, loss: 0.07834214717149734
step: 650, loss: 0.07652704417705536
step: 660, loss: 0.09073585271835327
step: 670, loss: 0.019998600706458092
step: 680, loss: 0.008754539303481579
step: 690, loss: 0.06303717941045761
step: 700, loss: 0.23298677802085876
step: 710, loss: 0.05649564042687416
step: 720, loss: 0.18507690727710724
step: 730, loss: 0.039145998656749725
step: 740, loss: 0.05671870335936546
step: 750, loss: 0.09815332293510437
step: 760, loss: 0.015860090032219887
step: 770, loss: 0.0808010995388031
step: 780, loss: 0.06714077293872833
step: 790, loss: 0.008775381371378899
step: 800, loss: 0.07278619706630707
step: 810, loss: 0.11279837787151337
step: 820, loss: 0.011322546750307083
step: 830, loss: 0.007970321923494339
step: 840, loss: 0.02331375516951084
step: 850, loss: 0.01658969186246395
step: 860, loss: 0.028607703745365143
step: 870, loss: 0.007732689380645752
step: 880, loss: 0.042399149388074875
step: 890, loss: 0.06567920744419098
step: 900, loss: 0.1087222620844841
step: 910, loss: 0.030769651755690575
step: 920, loss: 0.10924256592988968
step: 930, loss: 0.03135883808135986
step: 940, loss: 0.08242220431566238
step: 950, loss: 0.0005482534179463983
step: 960, loss: 0.06480993330478668
step: 970, loss: 0.14598849415779114
epoch 9: dev_f1=0.9355140186915888, f1=0.9308584686774942, best_f1=0.9371271225332722
step: 0, loss: 0.07409241795539856
step: 10, loss: 0.07586336135864258
step: 20, loss: 0.15225152671337128
step: 30, loss: 0.03489736467599869
step: 40, loss: 0.04929174482822418
step: 50, loss: 0.008274976164102554
step: 60, loss: 0.0008910091710276902
step: 70, loss: 0.12586066126823425
step: 80, loss: 0.043335869908332825
step: 90, loss: 0.10593181848526001
step: 100, loss: 0.011601900681853294
step: 110, loss: 0.015574461780488491
step: 120, loss: 0.013565841130912304
step: 130, loss: 0.0572255440056324
step: 140, loss: 0.0218181349337101
step: 150, loss: 0.002571918535977602
step: 160, loss: 0.005269632674753666
step: 170, loss: 0.0485435388982296
step: 180, loss: 0.003225684864446521
step: 190, loss: 0.0025968574918806553
step: 200, loss: 0.029091868549585342
step: 210, loss: 0.019445009529590607
step: 220, loss: 0.03233617916703224
step: 230, loss: 0.07577212154865265
step: 240, loss: 0.02400214597582817
step: 250, loss: 0.11030179262161255
step: 260, loss: 0.0005619829171337187
step: 270, loss: 0.001098374486900866
step: 280, loss: 0.09770818799734116
step: 290, loss: 0.0911530926823616
step: 300, loss: 0.014897245913743973
step: 310, loss: 0.08405951410531998
step: 320, loss: 0.09585931897163391
step: 330, loss: 0.052321579307317734
step: 340, loss: 0.05311527103185654
step: 350, loss: 0.031237531453371048
step: 360, loss: 0.00570394191890955
step: 370, loss: 0.019473133608698845
step: 380, loss: 0.013511191122233868
step: 390, loss: 0.07616059482097626
step: 400, loss: 0.03399249538779259
step: 410, loss: 0.01628950983285904
step: 420, loss: 0.03403836116194725
step: 430, loss: 0.01928308792412281
step: 440, loss: 0.032923389226198196
step: 450, loss: 0.011197399348020554
step: 460, loss: 0.05644736438989639
step: 470, loss: 0.07488521933555603
step: 480, loss: 0.007916470989584923
step: 490, loss: 0.02276020310819149
step: 500, loss: 0.02427598275244236
step: 510, loss: 0.16034045815467834
step: 520, loss: 0.055577632039785385
step: 530, loss: 0.056047871708869934
step: 540, loss: 0.021626316010951996
step: 550, loss: 0.06631199270486832
step: 560, loss: 0.046043090522289276
step: 570, loss: 0.033672627061605453
step: 580, loss: 0.016845300793647766
step: 590, loss: 0.004942308180034161
step: 600, loss: 0.05346807464957237
step: 610, loss: 0.10399305820465088
step: 620, loss: 0.046699680387973785
step: 630, loss: 0.03374810516834259
step: 640, loss: 0.05981937050819397
step: 650, loss: 0.04719623178243637
step: 660, loss: 0.07216998934745789
step: 670, loss: 0.051516734063625336
step: 680, loss: 0.04473264142870903
step: 690, loss: 0.10565394908189774
step: 700, loss: 0.008699165657162666
step: 710, loss: 0.012610074132680893
step: 720, loss: 0.08784555643796921
step: 730, loss: 0.0006186129758134484
step: 740, loss: 0.0050560180097818375
step: 750, loss: 0.02842453122138977
step: 760, loss: 0.010191305540502071
step: 770, loss: 0.11777031421661377
step: 780, loss: 0.014401303604245186
step: 790, loss: 0.0697798952460289
step: 800, loss: 0.10300209373235703
step: 810, loss: 0.045286308974027634
step: 820, loss: 0.05805445834994316
step: 830, loss: 0.04824605956673622
step: 840, loss: 0.06761009991168976
step: 850, loss: 0.015529454685747623
step: 860, loss: 0.06165578216314316
step: 870, loss: 0.01411813497543335
step: 880, loss: 0.0034958128817379475
step: 890, loss: 0.25823742151260376
step: 900, loss: 0.07948711514472961
step: 910, loss: 0.05709359422326088
step: 920, loss: 0.1262865513563156
step: 930, loss: 0.07746245712041855
step: 940, loss: 0.1451883465051651
step: 950, loss: 0.022694632411003113
step: 960, loss: 0.02627430111169815
step: 970, loss: 0.04534301906824112
epoch 10: dev_f1=0.9325894932589495, f1=0.9290023201856149, best_f1=0.9371271225332722
step: 0, loss: 0.06511690467596054
step: 10, loss: 0.012034451588988304
step: 20, loss: 0.04665708914399147
step: 30, loss: 0.0909016951918602
step: 40, loss: 0.04028034955263138
step: 50, loss: 0.03659510985016823
step: 60, loss: 0.007576523814350367
step: 70, loss: 0.10473250597715378
step: 80, loss: 0.07928243279457092
step: 90, loss: 0.13803160190582275
step: 100, loss: 0.16506819427013397
step: 110, loss: 0.002899904502555728
step: 120, loss: 0.007296404801309109
step: 130, loss: 0.08037953823804855
step: 140, loss: 0.03478667140007019
step: 150, loss: 0.015744220465421677
step: 160, loss: 6.138424214441329e-05
step: 170, loss: 0.05032968521118164
step: 180, loss: 0.015444103628396988
step: 190, loss: 0.017810579389333725
step: 200, loss: 0.027872717007994652
step: 210, loss: 0.0300159715116024
step: 220, loss: 0.0115903839468956
step: 230, loss: 0.06090420484542847
step: 240, loss: 0.04233482852578163
step: 250, loss: 0.04918571561574936
step: 260, loss: 0.06173792853951454
step: 270, loss: 0.03457341343164444
step: 280, loss: 0.038592640310525894
step: 290, loss: 0.016939353197813034
step: 300, loss: 0.03249569237232208
step: 310, loss: 0.030164744704961777
step: 320, loss: 0.0313728041946888
step: 330, loss: 0.000732916290871799
step: 340, loss: 0.028499159961938858
step: 350, loss: 0.04695095866918564
step: 360, loss: 0.02741452120244503
step: 370, loss: 0.029830843210220337
step: 380, loss: 0.03629704937338829
step: 390, loss: 0.033335935324430466
step: 400, loss: 0.05676368996500969
step: 410, loss: 0.0008632700191810727
step: 420, loss: 0.013438750989735126
step: 430, loss: 0.0556567907333374
step: 440, loss: 0.10493429750204086
step: 450, loss: 0.031746845692396164
step: 460, loss: 0.053975317627191544
step: 470, loss: 0.1319442242383957
step: 480, loss: 0.06989222764968872
step: 490, loss: 0.040711771696805954
step: 500, loss: 0.04674914851784706
step: 510, loss: 0.06718777865171432
step: 520, loss: 0.07127109915018082
step: 530, loss: 0.08237677812576294
step: 540, loss: 0.08483774960041046
step: 550, loss: 0.03869720920920372
step: 560, loss: 0.11690492182970047
step: 570, loss: 0.00508084474131465
step: 580, loss: 0.08317528665065765
step: 590, loss: 0.009408513084053993
step: 600, loss: 0.044619642198085785
step: 610, loss: 0.007144124712795019
step: 620, loss: 0.0648931935429573
step: 630, loss: 0.05471140146255493
step: 640, loss: 0.0444721020758152
step: 650, loss: 0.023777207359671593
step: 660, loss: 0.04306810349225998
step: 670, loss: 0.17966946959495544
step: 680, loss: 0.02938712388277054
step: 690, loss: 0.05640789866447449
step: 700, loss: 0.056197602301836014
step: 710, loss: 0.03951093554496765
step: 720, loss: 0.00011715367872966453
step: 730, loss: 0.02345201000571251
step: 740, loss: 0.041759032756090164
step: 750, loss: 0.02144206129014492
step: 760, loss: 0.053836699575185776
step: 770, loss: 0.08808531612157822
step: 780, loss: 0.0017769025871530175
step: 790, loss: 0.014209575951099396
step: 800, loss: 0.010790664702653885
step: 810, loss: 0.0578865185379982
step: 820, loss: 0.04693314805626869
step: 830, loss: 0.030245589092373848
step: 840, loss: 0.015799716114997864
step: 850, loss: 0.03732695430517197
step: 860, loss: 0.04489573463797569
step: 870, loss: 0.02328149601817131
step: 880, loss: 0.19719363749027252
step: 890, loss: 0.07584291696548462
step: 900, loss: 0.04970249906182289
step: 910, loss: 0.05687551945447922
step: 920, loss: 0.03525443375110626
step: 930, loss: 0.030315812677145004
step: 940, loss: 0.07915934920310974
step: 950, loss: 0.14711084961891174
step: 960, loss: 0.017262862995266914
step: 970, loss: 0.03599127009510994
epoch 11: dev_f1=0.9318497913769124, f1=0.9314179796107508, best_f1=0.9371271225332722
step: 0, loss: 0.0006713684415444732
step: 10, loss: 0.0007144507253542542
step: 20, loss: 0.0714438334107399
step: 30, loss: 0.14680086076259613
step: 40, loss: 0.0397036150097847
step: 50, loss: 0.02916795201599598
step: 60, loss: 0.003574064467102289
step: 70, loss: 0.02199186012148857
step: 80, loss: 0.03469986096024513
step: 90, loss: 0.05144917219877243
step: 100, loss: 0.0034667893778532743
step: 110, loss: 0.030785782262682915
step: 120, loss: 0.021967150270938873
step: 130, loss: 0.02721472829580307
step: 140, loss: 0.002822851063683629
step: 150, loss: 0.00045884662540629506
step: 160, loss: 0.12223878502845764
step: 170, loss: 0.005848298780620098
step: 180, loss: 0.005189191550016403
step: 190, loss: 0.006696897558867931
step: 200, loss: 0.000991361914202571
step: 210, loss: 0.07023956626653671
step: 220, loss: 0.017477132380008698
step: 230, loss: 0.08243727684020996
step: 240, loss: 0.05818609520792961
step: 250, loss: 0.0013115698238834739
step: 260, loss: 0.034705471247434616
step: 270, loss: 0.058377865701913834
step: 280, loss: 0.047787636518478394
step: 290, loss: 0.04449114575982094
step: 300, loss: 0.025564413517713547
step: 310, loss: 0.005972889252007008
step: 320, loss: 0.03404765948653221
step: 330, loss: 0.025788789615035057
step: 340, loss: 0.07232779264450073
step: 350, loss: 0.004095310810953379
step: 360, loss: 0.043887656182050705
step: 370, loss: 0.002176478272303939
step: 380, loss: 0.05706653743982315
step: 390, loss: 0.010377345606684685
step: 400, loss: 0.08889918774366379
step: 410, loss: 0.0009698459762148559
step: 420, loss: 0.028521334752440453
step: 430, loss: 0.05646967142820358
step: 440, loss: 0.1105526015162468
step: 450, loss: 0.04851071909070015
step: 460, loss: 0.03435947746038437
step: 470, loss: 0.13110162317752838
step: 480, loss: 0.03120323456823826
step: 490, loss: 0.03218880295753479
step: 500, loss: 0.21133968234062195
step: 510, loss: 0.025806032121181488
step: 520, loss: 0.008163750171661377
step: 530, loss: 0.03422984108328819
step: 540, loss: 0.057749006897211075
step: 550, loss: 0.0002813190803863108
step: 560, loss: 0.0011700713075697422
step: 570, loss: 0.04547349363565445
step: 580, loss: 0.0679871067404747
step: 590, loss: 0.007523305248469114
step: 600, loss: 0.06442185491323471
step: 610, loss: 0.011289505288004875
step: 620, loss: 0.03556789085268974
step: 630, loss: 0.07849235087633133
step: 640, loss: 0.07449772953987122
step: 650, loss: 0.06268656253814697
step: 660, loss: 0.02770937792956829
step: 670, loss: 0.03682504594326019
step: 680, loss: 0.054618339985609055
step: 690, loss: 0.04217119887471199
step: 700, loss: 0.1679590344429016
step: 710, loss: 0.006870210636407137
step: 720, loss: 0.016733892261981964
step: 730, loss: 0.06078687682747841
step: 740, loss: 0.015763862058520317
step: 750, loss: 0.015739887952804565
step: 760, loss: 0.003760496387258172
step: 770, loss: 0.0025614078622311354
step: 780, loss: 0.0054143015295267105
step: 790, loss: 0.02329198084771633
step: 800, loss: 0.036894164979457855
step: 810, loss: 0.0004494445165619254
step: 820, loss: 0.037646908313035965
step: 830, loss: 0.14976739883422852
step: 840, loss: 0.062043774873018265
step: 850, loss: 0.014158071018755436
step: 860, loss: 0.07401196658611298
step: 870, loss: 0.0033323937095701694
step: 880, loss: 0.0004683738516177982
step: 890, loss: 0.008066547103226185
step: 900, loss: 0.01411859504878521
step: 910, loss: 0.0398184172809124
step: 920, loss: 0.002545695286244154
step: 930, loss: 0.0782393366098404
step: 940, loss: 0.17866232991218567
step: 950, loss: 0.08115088194608688
step: 960, loss: 0.1436815708875656
step: 970, loss: 0.15458977222442627
epoch 12: dev_f1=0.931985294117647, f1=0.928735632183908, best_f1=0.9371271225332722
step: 0, loss: 0.01973014511168003
step: 10, loss: 0.06261296570301056
step: 20, loss: 0.07555186003446579
step: 30, loss: 0.10707565397024155
step: 40, loss: 0.037192296236753464
step: 50, loss: 0.02303692139685154
step: 60, loss: 0.0001470395363867283
step: 70, loss: 0.004054233431816101
step: 80, loss: 0.01699475198984146
step: 90, loss: 0.011682680808007717
step: 100, loss: 0.10770587623119354
step: 110, loss: 0.0060143680311739445
step: 120, loss: 0.013823707588016987
step: 130, loss: 0.03662431612610817
step: 140, loss: 0.05683237314224243
step: 150, loss: 0.06720345467329025
step: 160, loss: 0.024114549160003662
step: 170, loss: 0.021294990554451942
step: 180, loss: 0.06123484671115875
step: 190, loss: 0.012206913903355598
step: 200, loss: 0.04560796543955803
step: 210, loss: 0.05530048534274101
step: 220, loss: 0.037993475794792175
step: 230, loss: 0.09724565595388412
step: 240, loss: 0.03221237286925316
step: 250, loss: 0.00025255989748984575
step: 260, loss: 0.04131012782454491
step: 270, loss: 5.126887117512524e-05
step: 280, loss: 0.04535374790430069
step: 290, loss: 0.04712694510817528
step: 300, loss: 0.01954546570777893
step: 310, loss: 0.05541980639100075
step: 320, loss: 0.011915476992726326
step: 330, loss: 0.03317713364958763
step: 340, loss: 0.036587707698345184
step: 350, loss: 0.01702306605875492
step: 360, loss: 0.04666981101036072
step: 370, loss: 0.03443889692425728
step: 380, loss: 0.07188103348016739
step: 390, loss: 0.07293720543384552
step: 400, loss: 0.04278549551963806
step: 410, loss: 0.1541297882795334
step: 420, loss: 0.02477005496621132
step: 430, loss: 0.09959924221038818
step: 440, loss: 0.043896857649087906
step: 450, loss: 0.009018457494676113
step: 460, loss: 0.04311281070113182
step: 470, loss: 0.04715058580040932
step: 480, loss: 0.04646626114845276
step: 490, loss: 0.028135668486356735
step: 500, loss: 0.024431323632597923
step: 510, loss: 0.011828597635030746
step: 520, loss: 0.0011863635154441
step: 530, loss: 0.02563709206879139
step: 540, loss: 0.04369676485657692
step: 550, loss: 0.019114438444375992
step: 560, loss: 0.0011381569784134626
step: 570, loss: 0.04674651473760605
step: 580, loss: 0.022859811782836914
step: 590, loss: 2.3658585632801987e-05
step: 600, loss: 0.04388006776571274
step: 610, loss: 0.0016729721101000905
step: 620, loss: 0.001247469219379127
step: 630, loss: 0.054852962493896484
step: 640, loss: 0.017948433756828308
step: 650, loss: 0.06878335773944855
step: 660, loss: 0.04007357731461525
step: 670, loss: 0.0005556619144044816
step: 680, loss: 0.1853543519973755
step: 690, loss: 0.03933652862906456
step: 700, loss: 0.019700858741998672
step: 710, loss: 0.0031148698180913925
step: 720, loss: 0.03410083428025246
step: 730, loss: 0.004141546320170164
step: 740, loss: 0.03517095744609833
step: 750, loss: 0.03639376536011696
step: 760, loss: 0.0704994723200798
step: 770, loss: 0.018199462443590164
step: 780, loss: 0.1226685643196106
step: 790, loss: 0.07186117768287659
step: 800, loss: 0.027963869273662567
step: 810, loss: 0.05810265243053436
step: 820, loss: 0.053505584597587585
step: 830, loss: 0.0578070729970932
step: 840, loss: 0.02663392946124077
step: 850, loss: 0.09320414811372757
step: 860, loss: 0.028876740485429764
step: 870, loss: 0.037859879434108734
step: 880, loss: 0.1222277358174324
step: 890, loss: 0.08394092321395874
step: 900, loss: 0.004515399225056171
step: 910, loss: 0.07206013053655624
step: 920, loss: 0.058671314269304276
step: 930, loss: 0.017957039177417755
step: 940, loss: 0.0256202295422554
step: 950, loss: 0.0015265669208019972
step: 960, loss: 0.045292265713214874
step: 970, loss: 0.05273247882723808
epoch 13: dev_f1=0.9281352747768906, f1=0.9251059821008009, best_f1=0.9371271225332722
step: 0, loss: 0.0030834577046334743
step: 10, loss: 0.04393664002418518
step: 20, loss: 0.039837468415498734
step: 30, loss: 0.014706985093653202
step: 40, loss: 0.07851874083280563
step: 50, loss: 9.521663014311343e-05
step: 60, loss: 0.091345876455307
step: 70, loss: 0.014972185716032982
step: 80, loss: 0.053603529930114746
step: 90, loss: 0.00016763692838139832
step: 100, loss: 0.010845138691365719
step: 110, loss: 0.21063442528247833
step: 120, loss: 0.06985769420862198
step: 130, loss: 0.06815147399902344
step: 140, loss: 0.038634706288576126
step: 150, loss: 0.03454738110303879
step: 160, loss: 0.014439351856708527
step: 170, loss: 0.008139410056173801
step: 180, loss: 0.04324070364236832
step: 190, loss: 0.02191111631691456
step: 200, loss: 0.03457630053162575
step: 210, loss: 0.09474409371614456
step: 220, loss: 0.014816183596849442
step: 230, loss: 0.038613952696323395
step: 240, loss: 0.05676622316241264
step: 250, loss: 0.032120008021593094
step: 260, loss: 0.02140079252421856
step: 270, loss: 0.011262230575084686
step: 280, loss: 0.023477405309677124
step: 290, loss: 0.027399295940995216
step: 300, loss: 0.004427911248058081
step: 310, loss: 0.056750088930130005
step: 320, loss: 0.002205178840085864
step: 330, loss: 0.0027308983262628317
step: 340, loss: 0.049587201327085495
step: 350, loss: 0.018750037997961044
step: 360, loss: 0.08436115831136703
step: 370, loss: 0.11329623311758041
step: 380, loss: 0.032303713262081146
step: 390, loss: 0.060826316475868225
step: 400, loss: 0.02778935618698597
step: 410, loss: 0.02260698191821575
step: 420, loss: 0.16909416019916534
step: 430, loss: 0.0006036685081198812
step: 440, loss: 0.004545884672552347
step: 450, loss: 0.0436234325170517
step: 460, loss: 0.040020547807216644
step: 470, loss: 0.009111110121011734
step: 480, loss: 0.04788854345679283
step: 490, loss: 0.03549937903881073
step: 500, loss: 0.04206962510943413
step: 510, loss: 0.0004857105959672481
step: 520, loss: 0.10232170671224594
step: 530, loss: 0.025058919563889503
step: 540, loss: 0.012739412486553192
step: 550, loss: 0.00439664488658309
step: 560, loss: 0.02340579591691494
step: 570, loss: 0.0006793226348236203
step: 580, loss: 0.028595322743058205
step: 590, loss: 0.03907816857099533
step: 600, loss: 0.041434381157159805
step: 610, loss: 8.702022023499012e-05
step: 620, loss: 0.0010402689222246408
step: 630, loss: 0.0899854227900505
step: 640, loss: 6.706339627271518e-05
step: 650, loss: 0.02672824077308178
step: 660, loss: 0.062051113694906235
step: 670, loss: 0.015456343069672585
step: 680, loss: 0.000120252683700528
step: 690, loss: 0.017063869163393974
step: 700, loss: 0.09663181006908417
step: 710, loss: 0.030524350702762604
step: 720, loss: 0.06103324517607689
step: 730, loss: 0.07834970951080322
step: 740, loss: 0.0748567134141922
step: 750, loss: 0.03695902228355408
step: 760, loss: 0.023735586553812027
step: 770, loss: 0.009444234892725945
step: 780, loss: 0.02278774417936802
step: 790, loss: 0.05657824128866196
step: 800, loss: 0.03541417419910431
step: 810, loss: 0.025007816031575203
step: 820, loss: 0.029997432604432106
step: 830, loss: 0.08893261849880219
step: 840, loss: 0.04216979444026947
step: 850, loss: 0.042760297656059265
step: 860, loss: 0.013225778006017208
step: 870, loss: 0.040332574397325516
step: 880, loss: 0.09835360199213028
step: 890, loss: 0.025254640728235245
step: 900, loss: 0.05567847564816475
step: 910, loss: 0.008442439138889313
step: 920, loss: 0.0413108691573143
step: 930, loss: 0.036311130970716476
step: 940, loss: 0.022277476266026497
step: 950, loss: 0.017302177846431732
step: 960, loss: 0.030092034488916397
step: 970, loss: 0.031110648065805435
epoch 14: dev_f1=0.925925925925926, f1=0.9214417744916821, best_f1=0.9371271225332722
step: 0, loss: 1.578733827045653e-05
step: 10, loss: 0.004102782811969519
step: 20, loss: 0.0006068611983209848
step: 30, loss: 0.05699232220649719
step: 40, loss: 0.0012492082314565778
step: 50, loss: 0.10288646817207336
step: 60, loss: 0.0018021095311269164
step: 70, loss: 0.08484373986721039
step: 80, loss: 0.021492306143045425
step: 90, loss: 0.01515832170844078
step: 100, loss: 0.04598604142665863
step: 110, loss: 9.078313451027498e-05
step: 120, loss: 0.00891575776040554
step: 130, loss: 0.0385926328599453
step: 140, loss: 0.0021898963022977114
step: 150, loss: 0.02918105758726597
step: 160, loss: 0.04669690504670143
step: 170, loss: 0.00010782540630316362
step: 180, loss: 0.06049087271094322
step: 190, loss: 0.0001493551826570183
step: 200, loss: 0.05902870371937752
step: 210, loss: 0.04221004992723465
step: 220, loss: 0.07952360808849335
step: 230, loss: 0.00017215756815858185
step: 240, loss: 0.03186308965086937
step: 250, loss: 0.03947990760207176
step: 260, loss: 0.014103920198976994
step: 270, loss: 0.07392912358045578
step: 280, loss: 0.14675553143024445
step: 290, loss: 0.07785166800022125
step: 300, loss: 0.001406528172083199
step: 310, loss: 0.03062322922050953
step: 320, loss: 0.00012881073052994907
step: 330, loss: 0.022444622591137886
step: 340, loss: 0.05474185571074486
step: 350, loss: 0.04734448343515396
step: 360, loss: 0.021875817328691483
step: 370, loss: 0.03829373046755791
step: 380, loss: 0.06515438109636307
step: 390, loss: 0.05344334617257118
step: 400, loss: 0.033278707414865494
step: 410, loss: 0.05441991239786148
step: 420, loss: 0.08510858565568924
step: 430, loss: 0.032436009496450424
step: 440, loss: 0.01583055965602398
step: 450, loss: 0.05438060685992241
step: 460, loss: 0.04326559603214264
step: 470, loss: 0.008767395280301571
step: 480, loss: 0.030391311272978783
step: 490, loss: 0.014904782176017761
step: 500, loss: 0.0658607929944992
step: 510, loss: 0.027986856177449226
step: 520, loss: 0.0167301744222641
step: 530, loss: 0.11217939108610153
step: 540, loss: 8.916366641642526e-05
step: 550, loss: 0.0002337312325835228
step: 560, loss: 0.027134990319609642
step: 570, loss: 0.06208542734384537
step: 580, loss: 0.011597028002142906
step: 590, loss: 0.024369865655899048
step: 600, loss: 0.0013351564994081855
step: 610, loss: 0.0006206920370459557
step: 620, loss: 0.02397104725241661
step: 630, loss: 0.024448584765195847
step: 640, loss: 0.0360015332698822
step: 650, loss: 0.024463441222906113
step: 660, loss: 0.05933668091893196
step: 670, loss: 4.353352778707631e-05
step: 680, loss: 0.015001310035586357
step: 690, loss: 0.023814087733626366
step: 700, loss: 0.030151544138789177
step: 710, loss: 0.0057233101688325405
step: 720, loss: 0.05293191224336624
step: 730, loss: 2.9921680834377185e-05
step: 740, loss: 0.05278737470507622
step: 750, loss: 0.002285031834617257
step: 760, loss: 0.06616372615098953
step: 770, loss: 0.025568272918462753
step: 780, loss: 0.049986787140369415
step: 790, loss: 0.009948872961103916
step: 800, loss: 0.06411942094564438
step: 810, loss: 0.026333538815379143
step: 820, loss: 0.015727562829852104
step: 830, loss: 0.0004906030371785164
step: 840, loss: 0.07791510224342346
step: 850, loss: 0.05632010102272034
step: 860, loss: 0.047411832958459854
step: 870, loss: 0.07167693972587585
step: 880, loss: 0.013227819465100765
step: 890, loss: 0.022171005606651306
step: 900, loss: 0.05426806956529617
step: 910, loss: 0.01632322184741497
step: 920, loss: 0.015380693599581718
step: 930, loss: 0.05082683265209198
step: 940, loss: 0.00012651467113755643
step: 950, loss: 0.01724717766046524
step: 960, loss: 0.018168693408370018
step: 970, loss: 0.05820366367697716
epoch 15: dev_f1=0.9309701492537312, f1=0.9280373831775701, best_f1=0.9371271225332722
step: 0, loss: 0.03497306630015373
step: 10, loss: 0.07138067483901978
step: 20, loss: 9.461875742999837e-05
step: 30, loss: 0.02103419601917267
step: 40, loss: 0.02909582294523716
step: 50, loss: 0.00040382068254984915
step: 60, loss: 0.05341872572898865
step: 70, loss: 0.02285425364971161
step: 80, loss: 0.014211632311344147
step: 90, loss: 0.04090806096792221
step: 100, loss: 0.01950576715171337
step: 110, loss: 0.0807051733136177
step: 120, loss: 0.017253268510103226
step: 130, loss: 0.022460438311100006
step: 140, loss: 0.0003002274897880852
step: 150, loss: 0.014310061931610107
step: 160, loss: 0.009558533318340778
step: 170, loss: 0.024251233786344528
step: 180, loss: 0.01293730828911066
step: 190, loss: 0.006474208552390337
step: 200, loss: 0.027996158227324486
step: 210, loss: 0.001600573887117207
step: 220, loss: 0.06414027512073517
step: 230, loss: 0.12535759806632996
step: 240, loss: 5.36837505933363e-05
step: 250, loss: 0.021719694137573242
step: 260, loss: 0.07839369773864746
step: 270, loss: 0.043484918773174286
step: 280, loss: 0.03636282682418823
step: 290, loss: 0.04040287807583809
step: 300, loss: 0.04846954718232155
step: 310, loss: 0.041366029530763626
step: 320, loss: 0.09121458977460861
step: 330, loss: 0.046131350100040436
step: 340, loss: 0.023567598313093185
step: 350, loss: 3.1910312827676535e-05
step: 360, loss: 0.029105518013238907
step: 370, loss: 0.14298418164253235
step: 380, loss: 0.042557407170534134
step: 390, loss: 3.5955476050730795e-05
step: 400, loss: 0.020247723907232285
step: 410, loss: 0.03949875757098198
step: 420, loss: 0.021790090948343277
step: 430, loss: 0.046396706253290176
step: 440, loss: 5.9544378018472344e-05
step: 450, loss: 6.995321018621325e-05
step: 460, loss: 8.279549365397543e-05
step: 470, loss: 0.01807600073516369
step: 480, loss: 0.013279383070766926
step: 490, loss: 0.037978917360305786
step: 500, loss: 0.020148739218711853
step: 510, loss: 0.04353456199169159
step: 520, loss: 3.908193320967257e-05
step: 530, loss: 0.03223005309700966
step: 540, loss: 0.02349747158586979
step: 550, loss: 0.00850774347782135
step: 560, loss: 0.02053573727607727
step: 570, loss: 0.08781301975250244
step: 580, loss: 0.04542241245508194
step: 590, loss: 0.045050084590911865
step: 600, loss: 0.0003118482418358326
step: 610, loss: 0.017093533650040627
step: 620, loss: 0.0036754081957042217
step: 630, loss: 0.019430307671427727
step: 640, loss: 0.02873331308364868
step: 650, loss: 0.054389588534832
step: 660, loss: 0.03341812640428543
step: 670, loss: 0.02073649689555168
step: 680, loss: 0.00013675805530510843
step: 690, loss: 0.06236511841416359
step: 700, loss: 0.04150239750742912
step: 710, loss: 0.07293528318405151
step: 720, loss: 4.254246232449077e-05
step: 730, loss: 0.05319289490580559
step: 740, loss: 0.031026214361190796
step: 750, loss: 0.10338335484266281
step: 760, loss: 0.02687152661383152
step: 770, loss: 0.04025879502296448
step: 780, loss: 0.02331910841166973
step: 790, loss: 8.505218283971772e-05
step: 800, loss: 0.025106443092226982
step: 810, loss: 0.0394660048186779
step: 820, loss: 0.04552150145173073
step: 830, loss: 3.098117667832412e-05
step: 840, loss: 0.10825435072183609
step: 850, loss: 0.019364813342690468
step: 860, loss: 0.09905104339122772
step: 870, loss: 9.477083040110301e-06
step: 880, loss: 0.020992400124669075
step: 890, loss: 0.05994351953268051
step: 900, loss: 0.01742546632885933
step: 910, loss: 0.045835211873054504
step: 920, loss: 0.05088585242629051
step: 930, loss: 0.02035432681441307
step: 940, loss: 0.05870407447218895
step: 950, loss: 0.02518194541335106
step: 960, loss: 0.022187886759638786
step: 970, loss: 0.008611498400568962
epoch 16: dev_f1=0.935258500232883, f1=0.9280742459396751, best_f1=0.9371271225332722
step: 0, loss: 0.04150736704468727
step: 10, loss: 0.04295029118657112
step: 20, loss: 0.056163206696510315
step: 30, loss: 0.024471616372466087
step: 40, loss: 0.023894431069493294
step: 50, loss: 0.018072694540023804
step: 60, loss: 2.1206651581451297e-05
step: 70, loss: 0.010885786265134811
step: 80, loss: 0.02006387896835804
step: 90, loss: 0.00016397630679421127
step: 100, loss: 0.031897883862257004
step: 110, loss: 0.05600759759545326
step: 120, loss: 0.0641021877527237
step: 130, loss: 0.031018173322081566
step: 140, loss: 9.227759437635541e-05
step: 150, loss: 0.02749975398182869
step: 160, loss: 0.051833704113960266
step: 170, loss: 4.309203723096289e-05
step: 180, loss: 0.05470779538154602
step: 190, loss: 9.575067815603688e-05
step: 200, loss: 0.00048170704394578934
step: 210, loss: 0.04220325127243996
step: 220, loss: 0.027433032169938087
step: 230, loss: 0.04493312910199165
step: 240, loss: 8.168387284968048e-05
step: 250, loss: 0.016998086124658585
step: 260, loss: 0.052958786487579346
step: 270, loss: 0.0418316125869751
step: 280, loss: 0.034735001623630524
step: 290, loss: 0.00013597801444120705
step: 300, loss: 0.03806373104453087
step: 310, loss: 0.021941635757684708
step: 320, loss: 1.7529788237879984e-05
step: 330, loss: 3.651814768090844e-05
step: 340, loss: 0.0017522798152640462
step: 350, loss: 0.010618453845381737
step: 360, loss: 0.04472621530294418
step: 370, loss: 0.01372477039694786
step: 380, loss: 0.0185604989528656
step: 390, loss: 0.019870439544320107
step: 400, loss: 2.320648309250828e-05
step: 410, loss: 0.10061822086572647
step: 420, loss: 0.02569076418876648
step: 430, loss: 0.00506115285679698
step: 440, loss: 0.04001479595899582
step: 450, loss: 0.115104541182518
step: 460, loss: 0.09728690981864929
step: 470, loss: 0.05643963813781738
step: 480, loss: 0.08061231672763824
step: 490, loss: 0.042564090341329575
step: 500, loss: 0.06937985867261887
step: 510, loss: 0.019400516524910927
step: 520, loss: 0.039016950875520706
step: 530, loss: 0.0003405723546165973
step: 540, loss: 0.00012030493235215545
step: 550, loss: 0.00010097719496116042
step: 560, loss: 5.1668765081558377e-05
step: 570, loss: 0.021730918437242508
step: 580, loss: 0.06922989338636398
step: 590, loss: 1.56382484419737e-05
step: 600, loss: 0.020944839343428612
step: 610, loss: 0.10163485258817673
step: 620, loss: 0.020179525017738342
step: 630, loss: 5.16610307386145e-05
step: 640, loss: 0.02514851652085781
step: 650, loss: 0.0002660961472429335
step: 660, loss: 0.12610718607902527
step: 670, loss: 0.035552505403757095
step: 680, loss: 0.020167075097560883
step: 690, loss: 0.0634479895234108
step: 700, loss: 0.04191594570875168
step: 710, loss: 0.00030578719452023506
step: 720, loss: 0.07209350168704987
step: 730, loss: 0.02418234944343567
step: 740, loss: 0.02579650655388832
step: 750, loss: 0.02880421280860901
step: 760, loss: 0.05858910083770752
step: 770, loss: 0.00015399463882204145
step: 780, loss: 0.02942586876451969
step: 790, loss: 1.2118192898924462e-05
step: 800, loss: 0.020872343331575394
step: 810, loss: 0.03665531054139137
step: 820, loss: 0.022227954119443893
step: 830, loss: 0.01942606270313263
step: 840, loss: 0.10493718087673187
step: 850, loss: 0.003016963368281722
step: 860, loss: 0.05105452984571457
step: 870, loss: 0.06626587361097336
step: 880, loss: 4.665936285164207e-05
step: 890, loss: 0.0009480653679929674
step: 900, loss: 0.0003626733960118145
step: 910, loss: 0.004597481340169907
step: 920, loss: 0.04043591022491455
step: 930, loss: 0.03262560814619064
step: 940, loss: 0.04809402674436569
step: 950, loss: 0.05097103491425514
step: 960, loss: 0.03741896525025368
step: 970, loss: 0.07813796401023865
epoch 17: dev_f1=0.929472209248015, f1=0.9266012155212716, best_f1=0.9371271225332722
step: 0, loss: 0.06194595620036125
step: 10, loss: 0.00014945077418815345
step: 20, loss: 0.03788483887910843
step: 30, loss: 0.0570039376616478
step: 40, loss: 0.06982386112213135
step: 50, loss: 0.004957297351211309
step: 60, loss: 6.190384010551497e-05
step: 70, loss: 0.0327887237071991
step: 80, loss: 0.012884270399808884
step: 90, loss: 8.19280612631701e-05
step: 100, loss: 0.0008800642099231482
step: 110, loss: 4.5874694478698075e-05
step: 120, loss: 0.05738735944032669
step: 130, loss: 0.03628705069422722
step: 140, loss: 0.03739585354924202
step: 150, loss: 5.253713607089594e-05
step: 160, loss: 0.03132441267371178
step: 170, loss: 0.03393297642469406
step: 180, loss: 4.658882608055137e-05
step: 190, loss: 0.024979649111628532
step: 200, loss: 0.042094938457012177
step: 210, loss: 0.0003232927992939949
step: 220, loss: 0.022569922730326653
step: 230, loss: 9.354716166853905e-05
step: 240, loss: 0.056651342660188675
step: 250, loss: 0.05211431533098221
step: 260, loss: 0.03481225669384003
step: 270, loss: 0.02117522805929184
step: 280, loss: 0.06602449715137482
step: 290, loss: 0.06211134418845177
step: 300, loss: 0.07753175497055054
step: 310, loss: 0.021734118461608887
step: 320, loss: 0.021957432851195335
step: 330, loss: 0.007859602570533752
step: 340, loss: 0.020118355751037598
step: 350, loss: 0.0005928828613832593
step: 360, loss: 0.019092081114649773
step: 370, loss: 0.03221392631530762
step: 380, loss: 0.07913042604923248
step: 390, loss: 0.022919410839676857
step: 400, loss: 0.03810438513755798
step: 410, loss: 0.0466836541891098
step: 420, loss: 0.06789849698543549
step: 430, loss: 0.04209017753601074
step: 440, loss: 0.022649051621556282
step: 450, loss: 7.167433068389073e-06
step: 460, loss: 0.014360050670802593
step: 470, loss: 8.072662240010686e-06
step: 480, loss: 0.07284582406282425
step: 490, loss: 0.02318721078336239
step: 500, loss: 0.00024642181233502924
step: 510, loss: 0.020077679306268692
step: 520, loss: 0.04404909536242485
step: 530, loss: 0.011279710568487644
step: 540, loss: 0.060503117740154266
step: 550, loss: 0.021832425147294998
step: 560, loss: 0.0007764158071950078
step: 570, loss: 0.03545042499899864
step: 580, loss: 0.020256999880075455
step: 590, loss: 0.05500667169690132
step: 600, loss: 7.792667020112276e-05
step: 610, loss: 0.08611239492893219
step: 620, loss: 0.015770601108670235
step: 630, loss: 0.0004208307364024222
step: 640, loss: 0.05920758470892906
step: 650, loss: 0.0122616495937109
step: 660, loss: 0.07571930438280106
step: 670, loss: 0.02953622303903103
step: 680, loss: 0.0002470042963977903
step: 690, loss: 0.0037113206926733255
step: 700, loss: 0.03125977888703346
step: 710, loss: 0.0195982176810503
step: 720, loss: 0.021130278706550598
step: 730, loss: 0.08505765348672867
step: 740, loss: 0.04233797267079353
step: 750, loss: 0.019850682467222214
step: 760, loss: 0.042484745383262634
step: 770, loss: 0.027256589382886887
step: 780, loss: 0.03032728284597397
step: 790, loss: 0.023511065170168877
step: 800, loss: 0.05213624984025955
step: 810, loss: 0.05242430418729782
step: 820, loss: 0.022932739928364754
step: 830, loss: 0.040759239345788956
step: 840, loss: 0.00045680327457375824
step: 850, loss: 0.04841316491365433
step: 860, loss: 0.023692529648542404
step: 870, loss: 0.0031895851716399193
step: 880, loss: 0.002955528674647212
step: 890, loss: 0.02438833937048912
step: 900, loss: 0.03339194133877754
step: 910, loss: 0.06507401168346405
step: 920, loss: 0.028343716636300087
step: 930, loss: 0.07775038480758667
step: 940, loss: 0.08339126408100128
step: 950, loss: 0.024125833064317703
step: 960, loss: 0.050172265619039536
step: 970, loss: 6.42428349237889e-05
epoch 18: dev_f1=0.9328953542937587, f1=0.9271958666040395, best_f1=0.9371271225332722
step: 0, loss: 0.08060813695192337
step: 10, loss: 0.0348445363342762
step: 20, loss: 0.020347684621810913
step: 30, loss: 6.190940621308982e-05
step: 40, loss: 0.011406085453927517
step: 50, loss: 0.06019676476716995
step: 60, loss: 0.032114364206790924
step: 70, loss: 0.03239938244223595
step: 80, loss: 0.050523679703474045
step: 90, loss: 0.004160813521593809
step: 100, loss: 0.12516483664512634
step: 110, loss: 0.043709833174943924
step: 120, loss: 0.0500839501619339
step: 130, loss: 0.042464785277843475
step: 140, loss: 0.029532019048929214
step: 150, loss: 0.0807814672589302
step: 160, loss: 4.061082290718332e-05
step: 170, loss: 7.38530870876275e-05
step: 180, loss: 0.02095077559351921
step: 190, loss: 0.03558851778507233
step: 200, loss: 0.0006388480542227626
step: 210, loss: 8.02666982053779e-05
step: 220, loss: 0.00036718620685860515
step: 230, loss: 0.02068847045302391
step: 240, loss: 0.02093241736292839
step: 250, loss: 0.03841850161552429
step: 260, loss: 0.023771977052092552
step: 270, loss: 4.654389704228379e-05
step: 280, loss: 0.014878056943416595
step: 290, loss: 0.04849810153245926
step: 300, loss: 0.022551031783223152
step: 310, loss: 0.022020848467946053
step: 320, loss: 0.012661793269217014
step: 330, loss: 0.07372243702411652
step: 340, loss: 2.8714497602777556e-05
step: 350, loss: 0.0014400698710232973
step: 360, loss: 0.04845540225505829
step: 370, loss: 0.021549995988607407
step: 380, loss: 0.037682920694351196
step: 390, loss: 0.04703030362725258
step: 400, loss: 0.032306548207998276
step: 410, loss: 0.001832747831940651
step: 420, loss: 0.031946755945682526
step: 430, loss: 0.027013113722205162
step: 440, loss: 0.04149531573057175
step: 450, loss: 0.023245470598340034
step: 460, loss: 0.02863469161093235
step: 470, loss: 0.02888438105583191
step: 480, loss: 0.0241980142891407
step: 490, loss: 0.011668961495161057
step: 500, loss: 2.4530427253921516e-05
step: 510, loss: 0.017041826620697975
step: 520, loss: 0.05388447269797325
step: 530, loss: 0.08364320546388626
step: 540, loss: 3.542152626323514e-05
step: 550, loss: 0.024534819647669792
step: 560, loss: 0.03975837677717209
step: 570, loss: 0.07219632714986801
step: 580, loss: 0.0567978098988533
step: 590, loss: 0.01770561933517456
step: 600, loss: 0.05353322997689247
step: 610, loss: 0.0431823693215847
step: 620, loss: 0.038789235055446625
step: 630, loss: 6.479735020548105e-05
step: 640, loss: 1.7992066204897128e-05
step: 650, loss: 0.01932496204972267
step: 660, loss: 0.05550296604633331
step: 670, loss: 0.00027728406712412834
step: 680, loss: 2.22814705921337e-05
step: 690, loss: 0.054331224411726
step: 700, loss: 4.045194509672001e-05
step: 710, loss: 0.025161106139421463
step: 720, loss: 1.4989819646871183e-05
step: 730, loss: 0.020732656121253967
step: 740, loss: 0.04237094148993492
step: 750, loss: 0.02521185763180256
step: 760, loss: 2.304649751749821e-05
step: 770, loss: 0.03250342607498169
step: 780, loss: 0.024416586384177208
step: 790, loss: 4.722268568002619e-05
step: 800, loss: 2.5764398742467165e-05
step: 810, loss: 0.04197729006409645
step: 820, loss: 0.028532208874821663
step: 830, loss: 4.3848038330907e-05
step: 840, loss: 0.023622889071702957
step: 850, loss: 0.06956493854522705
step: 860, loss: 0.015847595408558846
step: 870, loss: 3.551911868271418e-05
step: 880, loss: 0.02691943757236004
step: 890, loss: 0.024362055584788322
step: 900, loss: 0.06596790254116058
step: 910, loss: 0.12529166042804718
step: 920, loss: 0.08475280553102493
step: 930, loss: 0.013625980354845524
step: 940, loss: 4.068969428772107e-05
step: 950, loss: 0.04069659858942032
step: 960, loss: 7.194188219727948e-05
step: 970, loss: 0.00011340207856846973
epoch 19: dev_f1=0.9308235294117647, f1=0.9284369114877589, best_f1=0.9371271225332722
step: 0, loss: 0.021807091310620308
step: 10, loss: 0.020160850137472153
step: 20, loss: 0.024583905935287476
step: 30, loss: 0.04994075000286102
step: 40, loss: 0.04090239852666855
step: 50, loss: 0.021566199138760567
step: 60, loss: 0.03868548572063446
step: 70, loss: 0.0220930278301239
step: 80, loss: 0.0030642191413789988
step: 90, loss: 0.023485813289880753
step: 100, loss: 0.0480925478041172
step: 110, loss: 0.07213985174894333
step: 120, loss: 3.725578426383436e-05
step: 130, loss: 0.009323676116764545
step: 140, loss: 5.859936209162697e-05
step: 150, loss: 0.014478426426649094
step: 160, loss: 0.02284199185669422
step: 170, loss: 0.03931029886007309
step: 180, loss: 0.045553483068943024
step: 190, loss: 0.12167804688215256
step: 200, loss: 0.02269325964152813
step: 210, loss: 0.033215802162885666
step: 220, loss: 0.021337788552045822
step: 230, loss: 0.049551017582416534
step: 240, loss: 0.037794869393110275
step: 250, loss: 0.036115895956754684
step: 260, loss: 0.023867707699537277
step: 270, loss: 9.433382365386933e-05
step: 280, loss: 0.0549103319644928
step: 290, loss: 0.0348542295396328
step: 300, loss: 0.0019176251953467727
step: 310, loss: 0.021088505163788795
step: 320, loss: 0.021022547036409378
step: 330, loss: 0.023762449622154236
step: 340, loss: 0.04197976365685463
step: 350, loss: 0.09856303781270981
step: 360, loss: 0.03002617321908474
step: 370, loss: 5.9238856920273975e-05
step: 380, loss: 0.037514183670282364
step: 390, loss: 4.6381388528971e-05
step: 400, loss: 0.02246682345867157
step: 410, loss: 4.4908621930517256e-05
step: 420, loss: 0.0015176547458395362
step: 430, loss: 0.02089644782245159
step: 440, loss: 0.04068075492978096
step: 450, loss: 3.358480171300471e-05
step: 460, loss: 0.000321548170177266
step: 470, loss: 0.09904591739177704
step: 480, loss: 0.034891605377197266
step: 490, loss: 0.07960408926010132
step: 500, loss: 0.04816151037812233
step: 510, loss: 0.015437216497957706
step: 520, loss: 0.0420021116733551
step: 530, loss: 0.039514731615781784
step: 540, loss: 0.04798788204789162
step: 550, loss: 0.06707318872213364
step: 560, loss: 0.07223030924797058
step: 570, loss: 0.03427748382091522
step: 580, loss: 0.04189493879675865
step: 590, loss: 0.04794231802225113
step: 600, loss: 0.04496140405535698
step: 610, loss: 2.1873065634281375e-05
step: 620, loss: 2.7711965230992064e-05
step: 630, loss: 0.04559239745140076
step: 640, loss: 0.00025390356313437223
step: 650, loss: 5.936506204307079e-05
step: 660, loss: 0.04089491069316864
step: 670, loss: 0.002418742747977376
step: 680, loss: 0.04410602152347565
step: 690, loss: 0.047935858368873596
step: 700, loss: 0.04070726037025452
step: 710, loss: 2.4611108528915793e-05
step: 720, loss: 6.469809159170836e-05
step: 730, loss: 0.015754586085677147
step: 740, loss: 0.09676501154899597
step: 750, loss: 0.022162562236189842
step: 760, loss: 2.2699328837916255e-05
step: 770, loss: 0.0007209054310806096
step: 780, loss: 0.02245308831334114
step: 790, loss: 0.0001590549072716385
step: 800, loss: 7.716290565440431e-05
step: 810, loss: 0.042084742337465286
step: 820, loss: 0.021463340148329735
step: 830, loss: 0.025101739913225174
step: 840, loss: 0.00018265601829625666
step: 850, loss: 0.016279101371765137
step: 860, loss: 0.08531853556632996
step: 870, loss: 0.028113072738051414
step: 880, loss: 8.982955478131771e-05
step: 890, loss: 7.299523713300005e-05
step: 900, loss: 3.8612764910794795e-05
step: 910, loss: 0.03795522823929787
step: 920, loss: 0.02340778335928917
step: 930, loss: 0.015263610519468784
step: 940, loss: 0.021766893565654755
step: 950, loss: 0.07928817719221115
step: 960, loss: 0.059279780834913254
step: 970, loss: 0.020064597949385643
epoch 20: dev_f1=0.9293401965372016, f1=0.9268978444236176, best_f1=0.9371271225332722
