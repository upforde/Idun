cuda
Device: cuda
step: 0, loss: 0.7832953929901123
step: 10, loss: 0.1655416637659073
step: 20, loss: 0.7163243293762207
step: 30, loss: 0.08420990407466888
step: 40, loss: 0.2987617254257202
step: 50, loss: 0.4504871964454651
step: 60, loss: 0.03995625674724579
step: 70, loss: 0.22080481052398682
step: 80, loss: 0.3651277720928192
step: 90, loss: 0.12026330828666687
step: 100, loss: 0.3574179708957672
step: 110, loss: 0.18277765810489655
step: 120, loss: 0.17358750104904175
step: 130, loss: 0.14350548386573792
step: 140, loss: 0.21923482418060303
step: 150, loss: 0.23744769394397736
step: 160, loss: 0.12650509178638458
step: 170, loss: 0.17001011967658997
step: 180, loss: 0.08797469735145569
step: 190, loss: 0.03446096554398537
step: 200, loss: 0.14007194340229034
step: 210, loss: 0.155076801776886
step: 220, loss: 0.07209909707307816
step: 230, loss: 0.1550222784280777
step: 240, loss: 0.17260752618312836
step: 250, loss: 0.16717372834682465
step: 260, loss: 0.15767411887645721
step: 270, loss: 0.20141153037548065
step: 280, loss: 0.20657019317150116
step: 290, loss: 0.23009181022644043
step: 300, loss: 0.16547061502933502
step: 310, loss: 0.1292511373758316
step: 320, loss: 0.13509108126163483
step: 330, loss: 0.4992949366569519
step: 340, loss: 0.05177371948957443
step: 350, loss: 0.05971638485789299
step: 360, loss: 0.01439675409346819
step: 370, loss: 0.16448210179805756
step: 380, loss: 0.1997281163930893
step: 390, loss: 0.08372253179550171
step: 400, loss: 0.09997297078371048
step: 410, loss: 0.11378645896911621
step: 420, loss: 0.076636902987957
step: 430, loss: 0.03315485268831253
step: 440, loss: 0.04993664473295212
step: 450, loss: 0.18234500288963318
step: 460, loss: 0.13297396898269653
step: 470, loss: 0.22625307738780975
step: 480, loss: 0.19824525713920593
step: 490, loss: 0.09516516327857971
step: 500, loss: 0.07841178774833679
step: 510, loss: 0.14667470753192902
step: 520, loss: 0.029724054038524628
step: 530, loss: 0.04690597951412201
step: 540, loss: 0.16013279557228088
step: 550, loss: 0.15743112564086914
step: 560, loss: 0.20965507626533508
step: 570, loss: 0.02860364131629467
step: 580, loss: 0.1124827042222023
step: 590, loss: 0.06155797466635704
step: 600, loss: 0.16137288510799408
step: 610, loss: 0.15817463397979736
step: 620, loss: 0.15815378725528717
step: 630, loss: 0.16941246390342712
step: 640, loss: 0.027364837005734444
step: 650, loss: 0.0363847054541111
step: 660, loss: 0.076118104159832
step: 670, loss: 0.156948983669281
step: 680, loss: 0.13158375024795532
step: 690, loss: 0.2609238028526306
step: 700, loss: 0.16649053990840912
step: 710, loss: 0.22124077379703522
step: 720, loss: 0.12158782035112381
step: 730, loss: 0.05880701541900635
step: 740, loss: 0.020870784297585487
step: 750, loss: 0.20639759302139282
step: 760, loss: 0.09381108731031418
step: 770, loss: 0.029651837423443794
step: 780, loss: 0.11444544792175293
step: 790, loss: 0.1739194691181183
step: 800, loss: 0.0960254892706871
step: 810, loss: 0.1460159868001938
step: 820, loss: 0.1063254326581955
step: 830, loss: 0.09403521567583084
step: 840, loss: 0.09391076862812042
step: 850, loss: 0.09295627474784851
step: 860, loss: 0.058267202228307724
step: 870, loss: 0.18952904641628265
step: 880, loss: 0.40438026189804077
step: 890, loss: 0.11238478124141693
step: 900, loss: 0.2014542818069458
step: 910, loss: 0.14833973348140717
step: 920, loss: 0.1599186360836029
step: 930, loss: 0.05001164972782135
step: 940, loss: 0.07910417765378952
step: 950, loss: 0.1209276020526886
step: 960, loss: 0.052148547023534775
step: 970, loss: 0.17342519760131836
epoch 1: dev_f1=0.9216840199185152, f1=0.9212880143112702, best_f1=0.9212880143112702
step: 0, loss: 0.08122628927230835
step: 10, loss: 0.07208673655986786
step: 20, loss: 0.13991783559322357
step: 30, loss: 0.10016234964132309
step: 40, loss: 0.10358689725399017
step: 50, loss: 0.07161252200603485
step: 60, loss: 0.08634980022907257
step: 70, loss: 0.11228948086500168
step: 80, loss: 0.08076784759759903
step: 90, loss: 0.1774921864271164
step: 100, loss: 0.22383789718151093
step: 110, loss: 0.02379930019378662
step: 120, loss: 0.06897582113742828
step: 130, loss: 0.01593606360256672
step: 140, loss: 0.022777549922466278
step: 150, loss: 0.02725406177341938
step: 160, loss: 0.14128628373146057
step: 170, loss: 0.09753169119358063
step: 180, loss: 0.16945673525333405
step: 190, loss: 0.1910862922668457
step: 200, loss: 0.054353732615709305
step: 210, loss: 0.07250957190990448
step: 220, loss: 0.1531844139099121
step: 230, loss: 0.1604134738445282
step: 240, loss: 0.11305546015501022
step: 250, loss: 0.047839727252721786
step: 260, loss: 0.03298477083444595
step: 270, loss: 0.12878167629241943
step: 280, loss: 0.1552179753780365
step: 290, loss: 0.197581484913826
step: 300, loss: 0.09122035652399063
step: 310, loss: 0.06388498097658157
step: 320, loss: 0.07001110911369324
step: 330, loss: 0.16672424972057343
step: 340, loss: 0.08213572949171066
step: 350, loss: 0.14326448738574982
step: 360, loss: 0.10357166081666946
step: 370, loss: 0.04560042917728424
step: 380, loss: 0.09631966799497604
step: 390, loss: 0.06648513674736023
step: 400, loss: 0.10696689784526825
step: 410, loss: 0.10943771153688431
step: 420, loss: 0.04783422872424126
step: 430, loss: 0.04548731818795204
step: 440, loss: 0.12698552012443542
step: 450, loss: 0.10956712067127228
step: 460, loss: 0.2319767028093338
step: 470, loss: 0.11489754915237427
step: 480, loss: 0.011359890922904015
step: 490, loss: 0.07154829055070877
step: 500, loss: 0.07416600733995438
step: 510, loss: 0.10125724226236343
step: 520, loss: 0.027929596602916718
step: 530, loss: 0.015472041442990303
step: 540, loss: 0.08210647851228714
step: 550, loss: 0.09296929091215134
step: 560, loss: 0.17036621272563934
step: 570, loss: 0.08481773734092712
step: 580, loss: 0.16269761323928833
step: 590, loss: 0.15639284253120422
step: 600, loss: 0.18011103570461273
step: 610, loss: 0.12820804119110107
step: 620, loss: 0.03030012920498848
step: 630, loss: 0.057061705738306046
step: 640, loss: 0.030039815232157707
step: 650, loss: 0.15643097460269928
step: 660, loss: 0.06222133710980415
step: 670, loss: 0.09327570348978043
step: 680, loss: 0.07939627766609192
step: 690, loss: 0.04021543636918068
step: 700, loss: 0.1203523650765419
step: 710, loss: 0.05890468880534172
step: 720, loss: 0.09878294914960861
step: 730, loss: 0.09608375281095505
step: 740, loss: 0.0705648809671402
step: 750, loss: 0.07985851168632507
step: 760, loss: 0.03904020041227341
step: 770, loss: 0.022130275145173073
step: 780, loss: 0.058691393584012985
step: 790, loss: 0.10647311061620712
step: 800, loss: 0.012116248719394207
step: 810, loss: 0.28171512484550476
step: 820, loss: 0.05405252426862717
step: 830, loss: 0.040705062448978424
step: 840, loss: 0.04992550238966942
step: 850, loss: 0.021808065474033356
step: 860, loss: 0.0663594901561737
step: 870, loss: 0.03425348922610283
step: 880, loss: 0.028785889968276024
step: 890, loss: 0.07273309677839279
step: 900, loss: 0.0730651244521141
step: 910, loss: 0.162391796708107
step: 920, loss: 0.09161287546157837
step: 930, loss: 0.22348812222480774
step: 940, loss: 0.07949049770832062
step: 950, loss: 0.05298079550266266
step: 960, loss: 0.04116746783256531
step: 970, loss: 0.128464937210083
epoch 2: dev_f1=0.9228650137741048, f1=0.925672594619243, best_f1=0.925672594619243
step: 0, loss: 0.07057875394821167
step: 10, loss: 0.13256345689296722
step: 20, loss: 0.04219168797135353
step: 30, loss: 0.13686832785606384
step: 40, loss: 0.09887063503265381
step: 50, loss: 0.014995253644883633
step: 60, loss: 0.06859280169010162
step: 70, loss: 0.03217078000307083
step: 80, loss: 0.05353939160704613
step: 90, loss: 0.1598525047302246
step: 100, loss: 0.024965060874819756
step: 110, loss: 0.02244166098535061
step: 120, loss: 0.18902355432510376
step: 130, loss: 0.11150567978620529
step: 140, loss: 0.05222256854176521
step: 150, loss: 0.02423490770161152
step: 160, loss: 0.044931139796972275
step: 170, loss: 0.07358179241418839
step: 180, loss: 0.014856583438813686
step: 190, loss: 0.08376427739858627
step: 200, loss: 0.1414063423871994
step: 210, loss: 0.02434956096112728
step: 220, loss: 0.141216441988945
step: 230, loss: 0.029138147830963135
step: 240, loss: 0.04466518014669418
step: 250, loss: 0.05471454933285713
step: 260, loss: 0.10743758827447891
step: 270, loss: 0.030855301767587662
step: 280, loss: 0.08336719125509262
step: 290, loss: 0.10003980249166489
step: 300, loss: 0.10780152678489685
step: 310, loss: 0.1379450112581253
step: 320, loss: 0.15376907587051392
step: 330, loss: 0.2051084041595459
step: 340, loss: 0.06591061502695084
step: 350, loss: 0.05630654841661453
step: 360, loss: 0.05226406455039978
step: 370, loss: 0.08071418106555939
step: 380, loss: 0.036356206983327866
step: 390, loss: 0.11515012383460999
step: 400, loss: 0.18498936295509338
step: 410, loss: 0.07182135432958603
step: 420, loss: 0.009274373762309551
step: 430, loss: 0.11368407309055328
step: 440, loss: 0.03378306329250336
step: 450, loss: 0.03022194281220436
step: 460, loss: 0.06729710847139359
step: 470, loss: 0.02699120342731476
step: 480, loss: 0.031844742596149445
step: 490, loss: 0.04563099145889282
step: 500, loss: 0.058560580015182495
step: 510, loss: 0.11669296771287918
step: 520, loss: 0.06846537441015244
step: 530, loss: 0.16020900011062622
step: 540, loss: 0.043496984988451004
step: 550, loss: 0.09761728346347809
step: 560, loss: 0.06718549132347107
step: 570, loss: 0.0802655965089798
step: 580, loss: 0.07209327816963196
step: 590, loss: 0.06579522043466568
step: 600, loss: 0.019041862338781357
step: 610, loss: 0.2227790206670761
step: 620, loss: 0.03120282292366028
step: 630, loss: 0.18268553912639618
step: 640, loss: 0.03120940551161766
step: 650, loss: 0.07327079027891159
step: 660, loss: 0.03318438678979874
step: 670, loss: 0.021340515464544296
step: 680, loss: 0.11881950497627258
step: 690, loss: 0.11546526104211807
step: 700, loss: 0.06191980093717575
step: 710, loss: 0.13697022199630737
step: 720, loss: 0.07201875746250153
step: 730, loss: 0.09808418154716492
step: 740, loss: 0.09350113570690155
step: 750, loss: 0.08894633501768112
step: 760, loss: 0.10007857531309128
step: 770, loss: 0.029125412926077843
step: 780, loss: 0.20738059282302856
step: 790, loss: 0.06654749810695648
step: 800, loss: 0.08680066466331482
step: 810, loss: 0.01159832626581192
step: 820, loss: 0.14242999255657196
step: 830, loss: 0.09394827485084534
step: 840, loss: 0.0862465500831604
step: 850, loss: 0.1318206787109375
step: 860, loss: 0.08239229023456573
step: 870, loss: 0.04235474392771721
step: 880, loss: 0.05754810944199562
step: 890, loss: 0.026397662237286568
step: 900, loss: 0.010056564584374428
step: 910, loss: 0.12197405844926834
step: 920, loss: 0.06721197068691254
step: 930, loss: 0.0820283591747284
step: 940, loss: 0.03856685012578964
step: 950, loss: 0.06910818815231323
step: 960, loss: 0.11275140196084976
step: 970, loss: 0.07446283102035522
epoch 3: dev_f1=0.9351981351981352, f1=0.9336448598130841, best_f1=0.9336448598130841
step: 0, loss: 0.09278504550457001
step: 10, loss: 0.10602214187383652
step: 20, loss: 0.05007832124829292
step: 30, loss: 0.15615102648735046
step: 40, loss: 0.036122437566518784
step: 50, loss: 0.013799266889691353
step: 60, loss: 0.021953994408249855
step: 70, loss: 0.06474588066339493
step: 80, loss: 0.16449719667434692
step: 90, loss: 0.05796651169657707
step: 100, loss: 0.043832775205373764
step: 110, loss: 0.06637680530548096
step: 120, loss: 0.01094669010490179
step: 130, loss: 0.20919518172740936
step: 140, loss: 0.14653848111629486
step: 150, loss: 0.07391788810491562
step: 160, loss: 0.040017854422330856
step: 170, loss: 0.059133756905794144
step: 180, loss: 0.037494998425245285
step: 190, loss: 0.03392694890499115
step: 200, loss: 0.03271712735295296
step: 210, loss: 0.07597166299819946
step: 220, loss: 0.00914067029953003
step: 230, loss: 0.02491915598511696
step: 240, loss: 0.026202619075775146
step: 250, loss: 0.018155090510845184
step: 260, loss: 0.06959003210067749
step: 270, loss: 0.02300729602575302
step: 280, loss: 0.12579397857189178
step: 290, loss: 0.04817510396242142
step: 300, loss: 0.06974644958972931
step: 310, loss: 0.02377508021891117
step: 320, loss: 0.21416765451431274
step: 330, loss: 0.11720119416713715
step: 340, loss: 0.11508076637983322
step: 350, loss: 0.10814093053340912
step: 360, loss: 0.11509255319833755
step: 370, loss: 0.13968825340270996
step: 380, loss: 0.04476878419518471
step: 390, loss: 0.00971378292888403
step: 400, loss: 0.03457769379019737
step: 410, loss: 0.055579204112291336
step: 420, loss: 0.06613273918628693
step: 430, loss: 0.025024421513080597
step: 440, loss: 0.13965678215026855
step: 450, loss: 0.0001885763049358502
step: 460, loss: 0.09028168022632599
step: 470, loss: 0.06317752599716187
step: 480, loss: 0.10635150223970413
step: 490, loss: 0.10892332345247269
step: 500, loss: 0.061120204627513885
step: 510, loss: 0.1405380368232727
step: 520, loss: 0.04585855081677437
step: 530, loss: 0.15162764489650726
step: 540, loss: 0.06374960392713547
step: 550, loss: 0.13924625515937805
step: 560, loss: 0.025589298456907272
step: 570, loss: 0.04137562960386276
step: 580, loss: 0.04195890203118324
step: 590, loss: 0.005720272660255432
step: 600, loss: 0.012705757282674313
step: 610, loss: 0.021427564322948456
step: 620, loss: 0.08983051031827927
step: 630, loss: 0.1366187036037445
step: 640, loss: 0.22784040868282318
step: 650, loss: 0.03216319903731346
step: 660, loss: 0.039194244891405106
step: 670, loss: 0.024829432368278503
step: 680, loss: 0.010742075741291046
step: 690, loss: 0.015410288237035275
step: 700, loss: 0.07488511502742767
step: 710, loss: 0.07520163804292679
step: 720, loss: 0.052173763513565063
step: 730, loss: 0.08147871494293213
step: 740, loss: 0.01800968497991562
step: 750, loss: 0.009069353342056274
step: 760, loss: 0.07903090864419937
step: 770, loss: 0.02060374803841114
step: 780, loss: 0.05349157750606537
step: 790, loss: 0.009553199633955956
step: 800, loss: 0.09675328433513641
step: 810, loss: 0.2800385355949402
step: 820, loss: 0.024720916524529457
step: 830, loss: 0.05936479941010475
step: 840, loss: 0.07341094315052032
step: 850, loss: 0.0546061247587204
step: 860, loss: 0.12766367197036743
step: 870, loss: 0.019892869517207146
step: 880, loss: 0.031812749803066254
step: 890, loss: 0.1423286646604538
step: 900, loss: 0.1947774440050125
step: 910, loss: 0.0280963946133852
step: 920, loss: 0.07272575795650482
step: 930, loss: 0.02550417184829712
step: 940, loss: 0.13056111335754395
step: 950, loss: 0.17694607377052307
step: 960, loss: 0.04136812314391136
step: 970, loss: 0.01346718892455101
epoch 4: dev_f1=0.9336426914153132, f1=0.927710843373494, best_f1=0.9336448598130841
step: 0, loss: 0.028345555067062378
step: 10, loss: 0.06831717491149902
step: 20, loss: 0.058585025370121
step: 30, loss: 0.06611209362745285
step: 40, loss: 0.04047417640686035
step: 50, loss: 0.027406806126236916
step: 60, loss: 0.03250148892402649
step: 70, loss: 0.02243969216942787
step: 80, loss: 0.06172029301524162
step: 90, loss: 0.060655076056718826
step: 100, loss: 0.00859853345900774
step: 110, loss: 0.03251369297504425
step: 120, loss: 0.0941193625330925
step: 130, loss: 0.14131662249565125
step: 140, loss: 0.17520450055599213
step: 150, loss: 0.04453231766819954
step: 160, loss: 0.037023983895778656
step: 170, loss: 0.15445785224437714
step: 180, loss: 0.0825173482298851
step: 190, loss: 0.05346749722957611
step: 200, loss: 0.02546226605772972
step: 210, loss: 0.010593890212476254
step: 220, loss: 0.1904871165752411
step: 230, loss: 0.02711598202586174
step: 240, loss: 0.040608931332826614
step: 250, loss: 0.05020802095532417
step: 260, loss: 0.07762913405895233
step: 270, loss: 0.008721799589693546
step: 280, loss: 0.12114125490188599
step: 290, loss: 0.014061281457543373
step: 300, loss: 0.025731464847922325
step: 310, loss: 0.11331209540367126
step: 320, loss: 0.10761560499668121
step: 330, loss: 0.12594380974769592
step: 340, loss: 0.10132183879613876
step: 350, loss: 0.026261422783136368
step: 360, loss: 0.10084989666938782
step: 370, loss: 0.006113849114626646
step: 380, loss: 0.06341775506734848
step: 390, loss: 0.055552467703819275
step: 400, loss: 0.09434428811073303
step: 410, loss: 0.09798458963632584
step: 420, loss: 0.15509149432182312
step: 430, loss: 0.04926597699522972
step: 440, loss: 0.10919765383005142
step: 450, loss: 0.06764430552721024
step: 460, loss: 0.009322665631771088
step: 470, loss: 0.1537381261587143
step: 480, loss: 0.01957046240568161
step: 490, loss: 0.03589637577533722
step: 500, loss: 0.07276450097560883
step: 510, loss: 0.11460348218679428
step: 520, loss: 0.09022616595029831
step: 530, loss: 0.06539317965507507
step: 540, loss: 0.08907968550920486
step: 550, loss: 0.04865168407559395
step: 560, loss: 0.015779126435518265
step: 570, loss: 0.012149316258728504
step: 580, loss: 0.08447150141000748
step: 590, loss: 0.0880601778626442
step: 600, loss: 0.0751098245382309
step: 610, loss: 0.030457310378551483
step: 620, loss: 0.05158301070332527
step: 630, loss: 0.08955612033605576
step: 640, loss: 0.020285218954086304
step: 650, loss: 5.9421650803415105e-05
step: 660, loss: 0.06473428010940552
step: 670, loss: 0.027944115921854973
step: 680, loss: 0.0844191312789917
step: 690, loss: 0.052815187722444534
step: 700, loss: 0.2637084722518921
step: 710, loss: 0.0210412684828043
step: 720, loss: 0.055595893412828445
step: 730, loss: 0.019926443696022034
step: 740, loss: 0.11921003460884094
step: 750, loss: 0.07827919721603394
step: 760, loss: 0.1226772591471672
step: 770, loss: 0.07824571430683136
step: 780, loss: 0.06960851699113846
step: 790, loss: 0.12599508464336395
step: 800, loss: 0.0637034922838211
step: 810, loss: 0.09985633194446564
step: 820, loss: 0.06341185420751572
step: 830, loss: 0.0967911034822464
step: 840, loss: 0.057486116886138916
step: 850, loss: 0.05565686523914337
step: 860, loss: 0.06234135851264
step: 870, loss: 0.1570446491241455
step: 880, loss: 0.052069928497076035
step: 890, loss: 0.049271099269390106
step: 900, loss: 0.08119505643844604
step: 910, loss: 0.04787912219762802
step: 920, loss: 0.13531064987182617
step: 930, loss: 0.016103507950901985
step: 940, loss: 0.008702169172465801
step: 950, loss: 0.06418231129646301
step: 960, loss: 0.07952409237623215
step: 970, loss: 0.025085316970944405
epoch 5: dev_f1=0.932963476652797, f1=0.929889298892989, best_f1=0.9336448598130841
step: 0, loss: 0.022163501009345055
step: 10, loss: 0.08966121822595596
step: 20, loss: 0.07249237596988678
step: 30, loss: 0.09472380578517914
step: 40, loss: 0.023074083030223846
step: 50, loss: 0.03982541337609291
step: 60, loss: 0.0208413228392601
step: 70, loss: 0.13429515063762665
step: 80, loss: 0.09094378352165222
step: 90, loss: 0.09891192615032196
step: 100, loss: 0.0879536122083664
step: 110, loss: 0.03411145880818367
step: 120, loss: 0.026949478313326836
step: 130, loss: 0.07593557983636856
step: 140, loss: 0.16428996622562408
step: 150, loss: 0.045867517590522766
step: 160, loss: 0.10145659744739532
step: 170, loss: 0.05505010858178139
step: 180, loss: 0.0523521862924099
step: 190, loss: 0.05287126824259758
step: 200, loss: 0.07524026930332184
step: 210, loss: 0.1540279984474182
step: 220, loss: 0.07364203780889511
step: 230, loss: 0.05959498509764671
step: 240, loss: 0.11238356679677963
step: 250, loss: 0.022924862802028656
step: 260, loss: 0.012227222323417664
step: 270, loss: 0.1135781928896904
step: 280, loss: 0.027015699073672295
step: 290, loss: 0.010381335392594337
step: 300, loss: 0.06387397646903992
step: 310, loss: 0.07724449783563614
step: 320, loss: 0.07663442194461823
step: 330, loss: 0.133268803358078
step: 340, loss: 0.031634047627449036
step: 350, loss: 0.12037865817546844
step: 360, loss: 0.013151779770851135
step: 370, loss: 0.038281816989183426
step: 380, loss: 0.23733927309513092
step: 390, loss: 0.03828519210219383
step: 400, loss: 0.039472755044698715
step: 410, loss: 0.009778237901628017
step: 420, loss: 0.08740130066871643
step: 430, loss: 0.022934280335903168
step: 440, loss: 0.01669900491833687
step: 450, loss: 0.03317619487643242
step: 460, loss: 0.21194684505462646
step: 470, loss: 0.05998507887125015
step: 480, loss: 0.030627219006419182
step: 490, loss: 0.15534378588199615
step: 500, loss: 0.07692538946866989
step: 510, loss: 0.06256169080734253
step: 520, loss: 0.10123814642429352
step: 530, loss: 0.07013824582099915
step: 540, loss: 0.024893589317798615
step: 550, loss: 0.028767049312591553
step: 560, loss: 0.006899331230670214
step: 570, loss: 0.00573346670717001
step: 580, loss: 0.053610362112522125
step: 590, loss: 0.22674737870693207
step: 600, loss: 0.17505672574043274
step: 610, loss: 0.021641332656145096
step: 620, loss: 0.04386606067419052
step: 630, loss: 0.12742383778095245
step: 640, loss: 0.08953860402107239
step: 650, loss: 0.03210019692778587
step: 660, loss: 0.048034220933914185
step: 670, loss: 0.12452095746994019
step: 680, loss: 0.07504194974899292
step: 690, loss: 0.25122326612472534
step: 700, loss: 0.04827873781323433
step: 710, loss: 0.006582758855074644
step: 720, loss: 0.019023895263671875
step: 730, loss: 0.04504752159118652
step: 740, loss: 0.01414281316101551
step: 750, loss: 0.23351575434207916
step: 760, loss: 0.06505881994962692
step: 770, loss: 0.20579077303409576
step: 780, loss: 0.06069786474108696
step: 790, loss: 0.13851317763328552
step: 800, loss: 0.01627694070339203
step: 810, loss: 0.023721780627965927
step: 820, loss: 0.006617735140025616
step: 830, loss: 0.021536335349082947
step: 840, loss: 0.021222909912467003
step: 850, loss: 0.05257365107536316
step: 860, loss: 0.06317608803510666
step: 870, loss: 0.01130740251392126
step: 880, loss: 0.012964369729161263
step: 890, loss: 0.12839417159557343
step: 900, loss: 0.12076660990715027
step: 910, loss: 0.1239236518740654
step: 920, loss: 0.13921312987804413
step: 930, loss: 0.016334952786564827
step: 940, loss: 0.07611069828271866
step: 950, loss: 0.023896023631095886
step: 960, loss: 0.07761681824922562
step: 970, loss: 0.02811603993177414
epoch 6: dev_f1=0.9319568277803848, f1=0.9312762973352035, best_f1=0.9336448598130841
step: 0, loss: 0.05518093705177307
step: 10, loss: 0.13076643645763397
step: 20, loss: 0.01980770193040371
step: 30, loss: 0.037333376705646515
step: 40, loss: 0.052008409053087234
step: 50, loss: 0.04443656653165817
step: 60, loss: 0.06809183210134506
step: 70, loss: 0.004628317430615425
step: 80, loss: 0.10057011991739273
step: 90, loss: 0.07847075909376144
step: 100, loss: 0.09041211754083633
step: 110, loss: 0.06775185465812683
step: 120, loss: 0.011645976454019547
step: 130, loss: 0.061400774866342545
step: 140, loss: 0.03204810619354248
step: 150, loss: 0.023006388917565346
step: 160, loss: 0.016055524349212646
step: 170, loss: 0.06291276961565018
step: 180, loss: 0.14344607293605804
step: 190, loss: 0.03262239694595337
step: 200, loss: 0.06892585009336472
step: 210, loss: 0.05540034547448158
step: 220, loss: 0.06464437395334244
step: 230, loss: 0.09858078509569168
step: 240, loss: 0.028652841225266457
step: 250, loss: 0.06814059615135193
step: 260, loss: 0.14042925834655762
step: 270, loss: 0.08540698885917664
step: 280, loss: 0.09981012344360352
step: 290, loss: 0.0846325010061264
step: 300, loss: 0.10426918417215347
step: 310, loss: 0.11398152261972427
step: 320, loss: 0.06783805787563324
step: 330, loss: 0.09282421320676804
step: 340, loss: 0.09921389073133469
step: 350, loss: 0.024942902848124504
step: 360, loss: 0.019889656454324722
step: 370, loss: 0.21205905079841614
step: 380, loss: 0.03257584944367409
step: 390, loss: 0.012645760551095009
step: 400, loss: 0.013132398948073387
step: 410, loss: 0.025244267657399178
step: 420, loss: 0.060455214232206345
step: 430, loss: 0.05940335988998413
step: 440, loss: 0.0708736851811409
step: 450, loss: 0.0104143675416708
step: 460, loss: 0.20480608940124512
step: 470, loss: 0.14753608405590057
step: 480, loss: 0.16443678736686707
step: 490, loss: 0.08499370515346527
step: 500, loss: 0.13019458949565887
step: 510, loss: 0.039727918803691864
step: 520, loss: 0.09550056606531143
step: 530, loss: 0.0056356522254645824
step: 540, loss: 0.162728950381279
step: 550, loss: 0.06837069243192673
step: 560, loss: 0.020386934280395508
step: 570, loss: 0.05006327107548714
step: 580, loss: 0.04242686554789543
step: 590, loss: 0.0977640450000763
step: 600, loss: 0.007897032424807549
step: 610, loss: 0.04409908503293991
step: 620, loss: 0.0700167641043663
step: 630, loss: 0.022811442613601685
step: 640, loss: 0.022006331011652946
step: 650, loss: 0.042347315698862076
step: 660, loss: 0.07531826198101044
step: 670, loss: 0.013307099230587482
step: 680, loss: 0.11439477652311325
step: 690, loss: 0.031318698078393936
step: 700, loss: 0.05803270265460014
step: 710, loss: 0.010458852164447308
step: 720, loss: 0.0031446614302694798
step: 730, loss: 0.06840157508850098
step: 740, loss: 0.036864474415779114
step: 750, loss: 0.06490945816040039
step: 760, loss: 0.07665399461984634
step: 770, loss: 0.08047091215848923
step: 780, loss: 0.009401509538292885
step: 790, loss: 0.036190323531627655
step: 800, loss: 0.07477512955665588
step: 810, loss: 0.027538498863577843
step: 820, loss: 0.010689301416277885
step: 830, loss: 0.1150449812412262
step: 840, loss: 0.0341314971446991
step: 850, loss: 0.04809114709496498
step: 860, loss: 0.11036422103643417
step: 870, loss: 0.16940659284591675
step: 880, loss: 0.042620304971933365
step: 890, loss: 0.1447247415781021
step: 900, loss: 0.10874507576227188
step: 910, loss: 0.07372331619262695
step: 920, loss: 0.058119699358940125
step: 930, loss: 0.051546260714530945
step: 940, loss: 0.04877296835184097
step: 950, loss: 0.09571576118469238
step: 960, loss: 0.004589999560266733
step: 970, loss: 0.03594888001680374
epoch 7: dev_f1=0.9355432780847146, f1=0.9322964318389753, best_f1=0.9322964318389753
step: 0, loss: 0.06368913501501083
step: 10, loss: 0.06088739261031151
step: 20, loss: 0.13860225677490234
step: 30, loss: 0.05784476175904274
step: 40, loss: 0.02332465723156929
step: 50, loss: 0.0254476610571146
step: 60, loss: 0.06987259536981583
step: 70, loss: 0.05378791317343712
step: 80, loss: 0.1969122588634491
step: 90, loss: 0.13346917927265167
step: 100, loss: 0.10156261920928955
step: 110, loss: 0.020665399730205536
step: 120, loss: 0.016102442517876625
step: 130, loss: 0.0032765979412943125
step: 140, loss: 0.011322134174406528
step: 150, loss: 0.15291215479373932
step: 160, loss: 0.07200971990823746
step: 170, loss: 0.06101508438587189
step: 180, loss: 0.03160809352993965
step: 190, loss: 0.15913553535938263
step: 200, loss: 0.028992878273129463
step: 210, loss: 0.10016046464443207
step: 220, loss: 0.06696794182062149
step: 230, loss: 0.11513549089431763
step: 240, loss: 0.012417350895702839
step: 250, loss: 0.01113145425915718
step: 260, loss: 0.029785869643092155
step: 270, loss: 0.14158067107200623
step: 280, loss: 0.12663717567920685
step: 290, loss: 0.015221397392451763
step: 300, loss: 0.0029425157699733973
step: 310, loss: 0.09042792022228241
step: 320, loss: 0.04928477481007576
step: 330, loss: 0.04464343190193176
step: 340, loss: 0.04616850987076759
step: 350, loss: 0.07576142251491547
step: 360, loss: 0.037989627569913864
step: 370, loss: 0.04660114645957947
step: 380, loss: 0.00641353614628315
step: 390, loss: 0.003066704608500004
step: 400, loss: 0.06638374924659729
step: 410, loss: 0.13273386657238007
step: 420, loss: 0.08353791385889053
step: 430, loss: 0.05618460103869438
step: 440, loss: 0.09542524814605713
step: 450, loss: 0.05116816237568855
step: 460, loss: 0.034838128834962845
step: 470, loss: 0.05247503146529198
step: 480, loss: 0.025619545951485634
step: 490, loss: 3.762519554584287e-05
step: 500, loss: 0.05795453488826752
step: 510, loss: 0.02084554359316826
step: 520, loss: 0.10619571805000305
step: 530, loss: 0.02154848538339138
step: 540, loss: 0.09836713969707489
step: 550, loss: 0.01326561439782381
step: 560, loss: 0.05395466461777687
step: 570, loss: 0.018923308700323105
step: 580, loss: 0.16742756962776184
step: 590, loss: 0.003865178907290101
step: 600, loss: 0.006313999183475971
step: 610, loss: 0.06853014975786209
step: 620, loss: 0.012801518663764
step: 630, loss: 0.1492597907781601
step: 640, loss: 0.07895763963460922
step: 650, loss: 0.12038686871528625
step: 660, loss: 0.019891060888767242
step: 670, loss: 0.046290021389722824
step: 680, loss: 0.05941833555698395
step: 690, loss: 0.038999512791633606
step: 700, loss: 0.15638300776481628
step: 710, loss: 0.09176475554704666
step: 720, loss: 0.05853894352912903
step: 730, loss: 0.01745360717177391
step: 740, loss: 0.006263078656047583
step: 750, loss: 0.02626884914934635
step: 760, loss: 0.08493644744157791
step: 770, loss: 0.1122388020157814
step: 780, loss: 0.08555079996585846
step: 790, loss: 0.047812141478061676
step: 800, loss: 0.0647575855255127
step: 810, loss: 0.11216989159584045
step: 820, loss: 0.02320929244160652
step: 830, loss: 0.06261257082223892
step: 840, loss: 0.12000032514333725
step: 850, loss: 0.016685592010617256
step: 860, loss: 0.04499233141541481
step: 870, loss: 0.09038633108139038
step: 880, loss: 0.053025566041469574
step: 890, loss: 0.008836851455271244
step: 900, loss: 0.05820034444332123
step: 910, loss: 0.04455958679318428
step: 920, loss: 0.021398203447461128
step: 930, loss: 0.11797632277011871
step: 940, loss: 0.08180791139602661
step: 950, loss: 0.046269502490758896
step: 960, loss: 0.00521570909768343
step: 970, loss: 0.009389255195856094
epoch 8: dev_f1=0.9296803652968036, f1=0.9307832422586522, best_f1=0.9322964318389753
step: 0, loss: 0.019313881173729897
step: 10, loss: 0.005197296384721994
step: 20, loss: 0.032540950924158096
step: 30, loss: 0.12175354361534119
step: 40, loss: 0.03172183036804199
step: 50, loss: 0.05739082396030426
step: 60, loss: 3.920158633263782e-05
step: 70, loss: 0.01625051721930504
step: 80, loss: 0.007835951633751392
step: 90, loss: 0.010640624910593033
step: 100, loss: 0.10125479847192764
step: 110, loss: 0.05614284798502922
step: 120, loss: 0.06020686775445938
step: 130, loss: 0.13832859694957733
step: 140, loss: 0.02102123387157917
step: 150, loss: 0.08757677674293518
step: 160, loss: 0.13434602320194244
step: 170, loss: 0.11017630249261856
step: 180, loss: 0.04130374640226364
step: 190, loss: 0.15941721200942993
step: 200, loss: 0.02260470949113369
step: 210, loss: 0.021410806104540825
step: 220, loss: 0.07724425941705704
step: 230, loss: 0.04177068918943405
step: 240, loss: 0.06669852137565613
step: 250, loss: 0.12017174810171127
step: 260, loss: 0.02414202317595482
step: 270, loss: 0.13659267127513885
step: 280, loss: 0.002452713903039694
step: 290, loss: 0.08586924523115158
step: 300, loss: 0.035993628203868866
step: 310, loss: 0.024431833997368813
step: 320, loss: 0.014528253115713596
step: 330, loss: 0.012976880185306072
step: 340, loss: 0.003959060646593571
step: 350, loss: 0.0018636572640389204
step: 360, loss: 0.0049893660470843315
step: 370, loss: 0.02268674597144127
step: 380, loss: 0.09388918429613113
step: 390, loss: 0.12100179493427277
step: 400, loss: 0.028096040710806847
step: 410, loss: 0.03205077722668648
step: 420, loss: 0.002576704602688551
step: 430, loss: 0.04015380144119263
step: 440, loss: 0.03791544586420059
step: 450, loss: 0.0709838792681694
step: 460, loss: 0.10132382810115814
step: 470, loss: 0.09452848881483078
step: 480, loss: 0.23234295845031738
step: 490, loss: 0.011152825318276882
step: 500, loss: 0.0639175996184349
step: 510, loss: 0.058290593326091766
step: 520, loss: 0.014012111350893974
step: 530, loss: 0.035983551293611526
step: 540, loss: 0.027007771655917168
step: 550, loss: 0.05578231066465378
step: 560, loss: 0.016859954223036766
step: 570, loss: 0.005880775395780802
step: 580, loss: 0.08320882171392441
step: 590, loss: 0.06230267509818077
step: 600, loss: 0.025385359302163124
step: 610, loss: 0.006814025342464447
step: 620, loss: 0.13427162170410156
step: 630, loss: 0.052761007100343704
step: 640, loss: 0.05897753685712814
step: 650, loss: 0.052965566515922546
step: 660, loss: 0.0485500693321228
step: 670, loss: 0.03424973413348198
step: 680, loss: 0.06372668594121933
step: 690, loss: 0.13594257831573486
step: 700, loss: 0.03897425904870033
step: 710, loss: 0.026534970849752426
step: 720, loss: 0.0028780153952538967
step: 730, loss: 0.024775968864560127
step: 740, loss: 0.00662542600184679
step: 750, loss: 0.018985092639923096
step: 760, loss: 0.02426062896847725
step: 770, loss: 0.11456757038831711
step: 780, loss: 0.1834442913532257
step: 790, loss: 0.057423029094934464
step: 800, loss: 0.06000339612364769
step: 810, loss: 0.0127185033634305
step: 820, loss: 0.0008005821728147566
step: 830, loss: 0.07716064155101776
step: 840, loss: 0.02846011333167553
step: 850, loss: 0.0060398937202990055
step: 860, loss: 0.04001476243138313
step: 870, loss: 0.14178168773651123
step: 880, loss: 0.036198366433382034
step: 890, loss: 0.04746933653950691
step: 900, loss: 0.05658682435750961
step: 910, loss: 0.005967374891042709
step: 920, loss: 0.095453180372715
step: 930, loss: 0.013018587604165077
step: 940, loss: 0.009382816031575203
step: 950, loss: 0.012651829048991203
step: 960, loss: 0.022305667400360107
step: 970, loss: 0.05867457762360573
epoch 9: dev_f1=0.9230068337129841, f1=0.9295774647887324, best_f1=0.9322964318389753
step: 0, loss: 0.09136508405208588
step: 10, loss: 0.04467519000172615
step: 20, loss: 0.04510873556137085
step: 30, loss: 0.007711260113865137
step: 40, loss: 0.03136782348155975
step: 50, loss: 0.021677592769265175
step: 60, loss: 0.0509955920279026
step: 70, loss: 0.08688738942146301
step: 80, loss: 0.026250969618558884
step: 90, loss: 0.03275793418288231
step: 100, loss: 0.038156699389219284
step: 110, loss: 0.01299495343118906
step: 120, loss: 0.010320965200662613
step: 130, loss: 0.08166816085577011
step: 140, loss: 0.00671404879540205
step: 150, loss: 0.01049973163753748
step: 160, loss: 0.012756742537021637
step: 170, loss: 0.022561565041542053
step: 180, loss: 0.008630428463220596
step: 190, loss: 0.07082592695951462
step: 200, loss: 0.21761669218540192
step: 210, loss: 0.07292316108942032
step: 220, loss: 0.03334613889455795
step: 230, loss: 0.07113795727491379
step: 240, loss: 0.11659999936819077
step: 250, loss: 0.08633768558502197
step: 260, loss: 0.07735810428857803
step: 270, loss: 0.007507974281907082
step: 280, loss: 0.012271339073777199
step: 290, loss: 0.08637380599975586
step: 300, loss: 0.051166169345378876
step: 310, loss: 0.06637376546859741
step: 320, loss: 0.14955738186836243
step: 330, loss: 0.04988366365432739
step: 340, loss: 0.03438856825232506
step: 350, loss: 0.020349904894828796
step: 360, loss: 0.015362909995019436
step: 370, loss: 0.03199358284473419
step: 380, loss: 0.024166060611605644
step: 390, loss: 0.04136482998728752
step: 400, loss: 0.015882695093750954
step: 410, loss: 0.03627098724246025
step: 420, loss: 0.06124601140618324
step: 430, loss: 0.06399151682853699
step: 440, loss: 0.006517546251416206
step: 450, loss: 0.10868500173091888
step: 460, loss: 0.05374933034181595
step: 470, loss: 0.05063626170158386
step: 480, loss: 0.12495724111795425
step: 490, loss: 0.07080940157175064
step: 500, loss: 0.10110301524400711
step: 510, loss: 0.004705433733761311
step: 520, loss: 0.014684567227959633
step: 530, loss: 0.047479208558797836
step: 540, loss: 0.024838954210281372
step: 550, loss: 0.07502415776252747
step: 560, loss: 0.1139736920595169
step: 570, loss: 0.025669049471616745
step: 580, loss: 0.031953781843185425
step: 590, loss: 0.005549816880375147
step: 600, loss: 0.011234237812459469
step: 610, loss: 0.011601012200117111
step: 620, loss: 0.049136508256196976
step: 630, loss: 0.07799820601940155
step: 640, loss: 0.001258342177607119
step: 650, loss: 0.09519768506288528
step: 660, loss: 0.039574190974235535
step: 670, loss: 0.057927727699279785
step: 680, loss: 0.029571078717708588
step: 690, loss: 0.0540841668844223
step: 700, loss: 0.026071084663271904
step: 710, loss: 0.0025397941935807467
step: 720, loss: 0.010093145072460175
step: 730, loss: 0.03512430563569069
step: 740, loss: 0.0829048678278923
step: 750, loss: 0.004627208691090345
step: 760, loss: 0.2621610164642334
step: 770, loss: 0.011253961361944675
step: 780, loss: 0.0520155243575573
step: 790, loss: 0.041868843138217926
step: 800, loss: 0.1350160390138626
step: 810, loss: 0.027701077982783318
step: 820, loss: 0.05376994237303734
step: 830, loss: 0.08602242171764374
step: 840, loss: 0.0023919169325381517
step: 850, loss: 0.02189769595861435
step: 860, loss: 0.10913480073213577
step: 870, loss: 0.08987689018249512
step: 880, loss: 0.06672694534063339
step: 890, loss: 0.021850351244211197
step: 900, loss: 0.004634682089090347
step: 910, loss: 0.0051507954485714436
step: 920, loss: 0.047282081097364426
step: 930, loss: 1.5668418200220913e-05
step: 940, loss: 0.01270639430731535
step: 950, loss: 0.039318621158599854
step: 960, loss: 0.016873415559530258
step: 970, loss: 0.00757559621706605
epoch 10: dev_f1=0.9304861426624261, f1=0.9209809264305178, best_f1=0.9322964318389753
step: 0, loss: 0.018730616196990013
step: 10, loss: 0.0011757559841498733
step: 20, loss: 0.07247281074523926
step: 30, loss: 0.004849961493164301
step: 40, loss: 0.002892287913709879
step: 50, loss: 0.12266897410154343
step: 60, loss: 0.04958002269268036
step: 70, loss: 0.05853688344359398
step: 80, loss: 0.12287525087594986
step: 90, loss: 0.008449211716651917
step: 100, loss: 0.003453952493146062
step: 110, loss: 0.020849697291851044
step: 120, loss: 0.1372900903224945
step: 130, loss: 0.008176431059837341
step: 140, loss: 0.05573658645153046
step: 150, loss: 0.027648042887449265
step: 160, loss: 0.10889605432748795
step: 170, loss: 0.04961014911532402
step: 180, loss: 0.002974141389131546
step: 190, loss: 0.030153684318065643
step: 200, loss: 0.0805160254240036
step: 210, loss: 0.03185219317674637
step: 220, loss: 0.008871922269463539
step: 230, loss: 0.053055211901664734
step: 240, loss: 0.03294847533106804
step: 250, loss: 0.06831572204828262
step: 260, loss: 0.013152307830750942
step: 270, loss: 0.051151540130376816
step: 280, loss: 0.03178572282195091
step: 290, loss: 0.09738116711378098
step: 300, loss: 0.01901116594672203
step: 310, loss: 0.06220674514770508
step: 320, loss: 0.010269921272993088
step: 330, loss: 0.03694147244095802
step: 340, loss: 0.008553492836654186
step: 350, loss: 0.026375306770205498
step: 360, loss: 0.06920581310987473
step: 370, loss: 0.17076656222343445
step: 380, loss: 0.011029810644686222
step: 390, loss: 0.02161402255296707
step: 400, loss: 0.0651695728302002
step: 410, loss: 0.03449219837784767
step: 420, loss: 0.09088936448097229
step: 430, loss: 0.0003764018474612385
step: 440, loss: 0.017299709841609
step: 450, loss: 0.000226064192247577
step: 460, loss: 0.0516853854060173
step: 470, loss: 0.005418508313596249
step: 480, loss: 0.03509565070271492
step: 490, loss: 0.14585018157958984
step: 500, loss: 0.036353666335344315
step: 510, loss: 0.01402234472334385
step: 520, loss: 0.03284965083003044
step: 530, loss: 0.06844888627529144
step: 540, loss: 0.040765780955553055
step: 550, loss: 0.05341147631406784
step: 560, loss: 0.06965692341327667
step: 570, loss: 0.08347271382808685
step: 580, loss: 0.0021089864894747734
step: 590, loss: 0.05291125550866127
step: 600, loss: 0.04441139101982117
step: 610, loss: 0.0006018651183694601
step: 620, loss: 0.06393982470035553
step: 630, loss: 0.04088450223207474
step: 640, loss: 0.09031791985034943
step: 650, loss: 0.0012983151245862246
step: 660, loss: 0.011059370823204517
step: 670, loss: 0.09864342212677002
step: 680, loss: 0.1837804913520813
step: 690, loss: 0.01693277806043625
step: 700, loss: 0.026503711938858032
step: 710, loss: 0.04263344779610634
step: 720, loss: 0.018346155062317848
step: 730, loss: 0.020521214231848717
step: 740, loss: 0.007919731549918652
step: 750, loss: 0.051713161170482635
step: 760, loss: 0.023942207917571068
step: 770, loss: 0.014773845672607422
step: 780, loss: 0.04997403919696808
step: 790, loss: 0.002596143167465925
step: 800, loss: 0.210585355758667
step: 810, loss: 0.04219961166381836
step: 820, loss: 0.002836310537531972
step: 830, loss: 0.1504281908273697
step: 840, loss: 0.1147288829088211
step: 850, loss: 0.06285413354635239
step: 860, loss: 0.06789801269769669
step: 870, loss: 0.0005770012503489852
step: 880, loss: 0.00798545777797699
step: 890, loss: 0.10298506170511246
step: 900, loss: 0.026385774835944176
step: 910, loss: 0.10225814580917358
step: 920, loss: 0.13707290589809418
step: 930, loss: 0.08925973623991013
step: 940, loss: 0.03959839046001434
step: 950, loss: 0.04077920690178871
step: 960, loss: 7.321061275433749e-05
step: 970, loss: 0.013589470647275448
epoch 11: dev_f1=0.9349930843706776, f1=0.9289617486338797, best_f1=0.9322964318389753
step: 0, loss: 0.07143408060073853
step: 10, loss: 0.04372711107134819
step: 20, loss: 0.026743635535240173
step: 30, loss: 0.04252997040748596
step: 40, loss: 0.058954596519470215
step: 50, loss: 0.024100765585899353
step: 60, loss: 0.02305304817855358
step: 70, loss: 0.10672278702259064
step: 80, loss: 0.02089470624923706
step: 90, loss: 0.029691362753510475
step: 100, loss: 0.041226018220186234
step: 110, loss: 0.02053573727607727
step: 120, loss: 1.6778478311607614e-05
step: 130, loss: 0.02465955913066864
step: 140, loss: 0.018556518480181694
step: 150, loss: 0.04757526144385338
step: 160, loss: 0.04880768805742264
step: 170, loss: 0.0002127577899955213
step: 180, loss: 0.09406502544879913
step: 190, loss: 0.033946599811315536
step: 200, loss: 0.2300306260585785
step: 210, loss: 0.055469151586294174
step: 220, loss: 2.0019420844619162e-05
step: 230, loss: 0.06299459934234619
step: 240, loss: 0.015782324597239494
step: 250, loss: 0.0020817008335143328
step: 260, loss: 0.03279861435294151
step: 270, loss: 0.02140836976468563
step: 280, loss: 0.02491343580186367
step: 290, loss: 0.03283720463514328
step: 300, loss: 0.03368167206645012
step: 310, loss: 0.07348396629095078
step: 320, loss: 0.07287828624248505
step: 330, loss: 0.029668932780623436
step: 340, loss: 0.02473166212439537
step: 350, loss: 0.040057942271232605
step: 360, loss: 0.07699576765298843
step: 370, loss: 0.09721849113702774
step: 380, loss: 0.00011784621165134013
step: 390, loss: 0.002201674971729517
step: 400, loss: 0.009811388328671455
step: 410, loss: 0.013455221429467201
step: 420, loss: 0.03954768925905228
step: 430, loss: 0.030005812644958496
step: 440, loss: 0.1150210052728653
step: 450, loss: 0.16930988430976868
step: 460, loss: 0.08744315803050995
step: 470, loss: 0.13454733788967133
step: 480, loss: 0.006662270985543728
step: 490, loss: 0.040375709533691406
step: 500, loss: 0.008163483813405037
step: 510, loss: 0.0007307364139705896
step: 520, loss: 0.017940418794751167
step: 530, loss: 0.0006030188524164259
step: 540, loss: 0.14846500754356384
step: 550, loss: 0.04137125983834267
step: 560, loss: 0.013029757887125015
step: 570, loss: 0.014707079157233238
step: 580, loss: 0.09414040297269821
step: 590, loss: 0.10143134742975235
step: 600, loss: 0.09344644099473953
step: 610, loss: 0.13915196061134338
step: 620, loss: 0.05172894150018692
step: 630, loss: 0.06835522502660751
step: 640, loss: 0.04118309170007706
step: 650, loss: 0.00019132222223561257
step: 660, loss: 0.19432908296585083
step: 670, loss: 0.028991296887397766
step: 680, loss: 0.0047869994305074215
step: 690, loss: 0.04108286276459694
step: 700, loss: 0.00013531994773074985
step: 710, loss: 0.0731709748506546
step: 720, loss: 0.052839405834674835
step: 730, loss: 0.007641781121492386
step: 740, loss: 0.06528955698013306
step: 750, loss: 0.007938956841826439
step: 760, loss: 0.01706349104642868
step: 770, loss: 0.025794226676225662
step: 780, loss: 0.04853111132979393
step: 790, loss: 0.020298559218645096
step: 800, loss: 0.025746818631887436
step: 810, loss: 0.005700932815670967
step: 820, loss: 0.16574329137802124
step: 830, loss: 0.00031545490492135286
step: 840, loss: 0.18316231667995453
step: 850, loss: 0.1367415487766266
step: 860, loss: 0.009359977208077908
step: 870, loss: 0.0913781151175499
step: 880, loss: 0.030905555933713913
step: 890, loss: 0.032321423292160034
step: 900, loss: 0.08216682821512222
step: 910, loss: 0.06253726780414581
step: 920, loss: 0.04110496863722801
step: 930, loss: 0.03523468226194382
step: 940, loss: 0.040200211107730865
step: 950, loss: 0.06477783620357513
step: 960, loss: 0.07090357691049576
step: 970, loss: 0.021025104448199272
epoch 12: dev_f1=0.9341262580054894, f1=0.9286039108685765, best_f1=0.9322964318389753
step: 0, loss: 0.026211924850940704
step: 10, loss: 0.0010587048018351197
step: 20, loss: 0.04984639957547188
step: 30, loss: 0.029312916100025177
step: 40, loss: 0.02075713686645031
step: 50, loss: 0.013835248537361622
step: 60, loss: 0.003312252229079604
step: 70, loss: 0.000261593668255955
step: 80, loss: 0.004052605014294386
step: 90, loss: 0.006842951290309429
step: 100, loss: 0.04299750551581383
step: 110, loss: 0.07432056218385696
step: 120, loss: 0.0728759914636612
step: 130, loss: 0.000663340266328305
step: 140, loss: 0.01565004512667656
step: 150, loss: 0.03368601202964783
step: 160, loss: 0.004341575317084789
step: 170, loss: 0.12694178521633148
step: 180, loss: 0.046774208545684814
step: 190, loss: 0.0009910097578540444
step: 200, loss: 0.037204861640930176
step: 210, loss: 0.05310652405023575
step: 220, loss: 0.024248087778687477
step: 230, loss: 0.03232895955443382
step: 240, loss: 0.0035115068312734365
step: 250, loss: 2.6835865355678834e-05
step: 260, loss: 0.013958546333014965
step: 270, loss: 0.03341419994831085
step: 280, loss: 0.01620602048933506
step: 290, loss: 0.016934234648942947
step: 300, loss: 0.027476534247398376
step: 310, loss: 0.0009245142573490739
step: 320, loss: 0.049427520483732224
step: 330, loss: 0.020882312208414078
step: 340, loss: 0.04259620979428291
step: 350, loss: 0.044625911861658096
step: 360, loss: 0.16835877299308777
step: 370, loss: 0.023592878133058548
step: 380, loss: 0.041056159883737564
step: 390, loss: 0.007911985740065575
step: 400, loss: 0.02741103246808052
step: 410, loss: 0.016267357394099236
step: 420, loss: 0.07226353883743286
step: 430, loss: 0.03412085771560669
step: 440, loss: 0.022792819887399673
step: 450, loss: 0.012943416833877563
step: 460, loss: 0.014194251969456673
step: 470, loss: 0.12687885761260986
step: 480, loss: 0.010242759250104427
step: 490, loss: 0.03772170469164848
step: 500, loss: 0.024259084835648537
step: 510, loss: 0.014390036463737488
step: 520, loss: 0.04290773719549179
step: 530, loss: 0.07931308448314667
step: 540, loss: 0.1455252766609192
step: 550, loss: 0.07715916633605957
step: 560, loss: 0.03596037998795509
step: 570, loss: 0.09732231497764587
step: 580, loss: 0.09588204324245453
step: 590, loss: 0.050419218838214874
step: 600, loss: 0.055297624319791794
step: 610, loss: 0.030724957585334778
step: 620, loss: 0.018669795244932175
step: 630, loss: 0.04235755652189255
step: 640, loss: 2.8033189664711244e-05
step: 650, loss: 0.03442234545946121
step: 660, loss: 0.06406725198030472
step: 670, loss: 0.03291203826665878
step: 680, loss: 0.00418030796572566
step: 690, loss: 0.03200389817357063
step: 700, loss: 0.04035237431526184
step: 710, loss: 0.06314218044281006
step: 720, loss: 0.1094922125339508
step: 730, loss: 0.05100241303443909
step: 740, loss: 0.06624502688646317
step: 750, loss: 1.1265202374488581e-05
step: 760, loss: 0.010249667800962925
step: 770, loss: 0.017538735643029213
step: 780, loss: 0.04512336477637291
step: 790, loss: 0.07314661890268326
step: 800, loss: 0.001415897044353187
step: 810, loss: 0.0029047722928225994
step: 820, loss: 0.03022504411637783
step: 830, loss: 0.05204518511891365
step: 840, loss: 0.09622060507535934
step: 850, loss: 0.01794016920030117
step: 860, loss: 0.00039737889892421663
step: 870, loss: 0.015606477856636047
step: 880, loss: 0.0002128309424733743
step: 890, loss: 0.02488560974597931
step: 900, loss: 0.0174209326505661
step: 910, loss: 0.0008430799935013056
step: 920, loss: 0.13361221551895142
step: 930, loss: 0.017546813935041428
step: 940, loss: 0.02294345758855343
step: 950, loss: 7.189696771092713e-05
step: 960, loss: 0.003943641670048237
step: 970, loss: 0.06836120784282684
epoch 13: dev_f1=0.9322268326417704, f1=0.9305301645338208, best_f1=0.9322964318389753
step: 0, loss: 0.04315846785902977
step: 10, loss: 0.08227042853832245
step: 20, loss: 0.00045294681331142783
step: 30, loss: 0.04142336547374725
step: 40, loss: 0.0150566715747118
step: 50, loss: 0.00078756915172562
step: 60, loss: 0.0687941238284111
step: 70, loss: 0.028303630650043488
step: 80, loss: 0.00026041993987746537
step: 90, loss: 0.019993336871266365
step: 100, loss: 0.0654228925704956
step: 110, loss: 0.10798226296901703
step: 120, loss: 0.03687736392021179
step: 130, loss: 0.0033526853658258915
step: 140, loss: 0.043443914502859116
step: 150, loss: 0.01459734607487917
step: 160, loss: 0.08585286140441895
step: 170, loss: 0.07829709351062775
step: 180, loss: 0.03530958294868469
step: 190, loss: 0.022053223103284836
step: 200, loss: 0.00783082377165556
step: 210, loss: 0.17701023817062378
step: 220, loss: 0.06298145651817322
step: 230, loss: 0.08185853809118271
step: 240, loss: 0.07850268483161926
step: 250, loss: 0.009031004272401333
step: 260, loss: 0.0019294825615361333
step: 270, loss: 0.02075798436999321
step: 280, loss: 0.09383833408355713
step: 290, loss: 0.0014065103605389595
step: 300, loss: 0.012974090874195099
step: 310, loss: 0.03714486584067345
step: 320, loss: 0.05166713893413544
step: 330, loss: 0.08631276339292526
step: 340, loss: 0.03968160226941109
step: 350, loss: 0.001397090032696724
step: 360, loss: 0.10270944237709045
step: 370, loss: 0.027881423011422157
step: 380, loss: 0.00025507312966510653
step: 390, loss: 0.06394080817699432
step: 400, loss: 0.014808369800448418
step: 410, loss: 0.0232071690261364
step: 420, loss: 0.0001616935624042526
step: 430, loss: 0.056210797280073166
step: 440, loss: 0.02987578883767128
step: 450, loss: 0.010311421938240528
step: 460, loss: 0.037034593522548676
step: 470, loss: 0.0334768146276474
step: 480, loss: 0.031882818788290024
step: 490, loss: 0.017377130687236786
step: 500, loss: 0.0029103001579642296
step: 510, loss: 0.030977679416537285
step: 520, loss: 0.016356566920876503
step: 530, loss: 0.024871356785297394
step: 540, loss: 0.00011216433631489053
step: 550, loss: 0.08823686093091965
step: 560, loss: 0.01729380339384079
step: 570, loss: 0.03247414156794548
step: 580, loss: 0.05064499005675316
step: 590, loss: 0.0019714427180588245
step: 600, loss: 0.0014427239075303078
step: 610, loss: 0.08508232235908508
step: 620, loss: 0.09957414865493774
step: 630, loss: 0.02709297277033329
step: 640, loss: 0.045625895261764526
step: 650, loss: 0.0028507388196885586
step: 660, loss: 0.17967738211154938
step: 670, loss: 0.06238165497779846
step: 680, loss: 0.027516581118106842
step: 690, loss: 0.019298309460282326
step: 700, loss: 0.09017106145620346
step: 710, loss: 0.016087858006358147
step: 720, loss: 0.05699395760893822
step: 730, loss: 0.02883574739098549
step: 740, loss: 0.05592095106840134
step: 750, loss: 0.05928235873579979
step: 760, loss: 0.07515248656272888
step: 770, loss: 0.0004605544963851571
step: 780, loss: 0.006356189027428627
step: 790, loss: 0.014158044941723347
step: 800, loss: 0.07654712349176407
step: 810, loss: 0.0030745710246264935
step: 820, loss: 0.06470075994729996
step: 830, loss: 0.046567752957344055
step: 840, loss: 0.05114614963531494
step: 850, loss: 0.0013872782001271844
step: 860, loss: 0.017305515706539154
step: 870, loss: 0.005224194377660751
step: 880, loss: 0.06122172996401787
step: 890, loss: 0.041656188666820526
step: 900, loss: 0.004217487294226885
step: 910, loss: 0.04854217916727066
step: 920, loss: 0.1448546051979065
step: 930, loss: 0.004213180858641863
step: 940, loss: 0.10895494371652603
step: 950, loss: 0.012572241015732288
step: 960, loss: 0.05910995975136757
step: 970, loss: 0.03343921899795532
epoch 14: dev_f1=0.9351981351981352, f1=0.9280074314909429, best_f1=0.9322964318389753
step: 0, loss: 0.04914645478129387
step: 10, loss: 0.10120303183794022
step: 20, loss: 0.06253262609243393
step: 30, loss: 0.027187617495656013
step: 40, loss: 0.12201967090368271
step: 50, loss: 0.053010981529951096
step: 60, loss: 0.01167252380400896
step: 70, loss: 0.016256865113973618
step: 80, loss: 0.02401721477508545
step: 90, loss: 0.0023938207887113094
step: 100, loss: 0.046583980321884155
step: 110, loss: 0.0007891577552072704
step: 120, loss: 0.005250988993793726
step: 130, loss: 0.011410118080675602
step: 140, loss: 0.016945166513323784
step: 150, loss: 0.003974254708737135
step: 160, loss: 0.015774091705679893
step: 170, loss: 0.003692016704007983
step: 180, loss: 0.042937397956848145
step: 190, loss: 0.02471991255879402
step: 200, loss: 0.0005836893687956035
step: 210, loss: 0.04105888679623604
step: 220, loss: 0.04328601434826851
step: 230, loss: 0.03533000871539116
step: 240, loss: 0.032993096858263016
step: 250, loss: 0.0779469832777977
step: 260, loss: 0.05778668075799942
step: 270, loss: 0.04160943254828453
step: 280, loss: 0.0002026929723797366
step: 290, loss: 0.04861174896359444
step: 300, loss: 0.05672468617558479
step: 310, loss: 0.030237745493650436
step: 320, loss: 0.00017932133050635457
step: 330, loss: 0.04803844541311264
step: 340, loss: 0.06664817780256271
step: 350, loss: 0.09417431801557541
step: 360, loss: 0.046274520456790924
step: 370, loss: 0.03552529960870743
step: 380, loss: 0.04262962192296982
step: 390, loss: 0.0511278435587883
step: 400, loss: 0.005205200519412756
step: 410, loss: 0.0013065801467746496
step: 420, loss: 0.04373478889465332
step: 430, loss: 0.025549037382006645
step: 440, loss: 0.01440121978521347
step: 450, loss: 4.055431054439396e-05
step: 460, loss: 0.03125416487455368
step: 470, loss: 5.301858618622646e-05
step: 480, loss: 0.06097034364938736
step: 490, loss: 0.024951323866844177
step: 500, loss: 0.012505323626101017
step: 510, loss: 0.055979471653699875
step: 520, loss: 0.06250712275505066
step: 530, loss: 0.015368890017271042
step: 540, loss: 0.040339477360248566
step: 550, loss: 0.01917838864028454
step: 560, loss: 0.016645070165395737
step: 570, loss: 0.10911151766777039
step: 580, loss: 0.04801928997039795
step: 590, loss: 0.040083833038806915
step: 600, loss: 0.11744304746389389
step: 610, loss: 0.016659827902913094
step: 620, loss: 0.01986212469637394
step: 630, loss: 0.02558077871799469
step: 640, loss: 0.061720915138721466
step: 650, loss: 0.02259162999689579
step: 660, loss: 0.03928660228848457
step: 670, loss: 0.0054838573560118675
step: 680, loss: 0.020130392163991928
step: 690, loss: 0.0034515676088631153
step: 700, loss: 0.06902677565813065
step: 710, loss: 0.032596271485090256
step: 720, loss: 0.06636006385087967
step: 730, loss: 0.010437079705297947
step: 740, loss: 0.0005814227042719722
step: 750, loss: 0.07816603779792786
step: 760, loss: 0.00011794224701588973
step: 770, loss: 0.09183342754840851
step: 780, loss: 0.047428470104932785
step: 790, loss: 0.04214297980070114
step: 800, loss: 0.03579573705792427
step: 810, loss: 0.0010870866244658828
step: 820, loss: 0.029332071542739868
step: 830, loss: 0.03046475350856781
step: 840, loss: 0.046089403331279755
step: 850, loss: 0.06540850549936295
step: 860, loss: 0.07741662114858627
step: 870, loss: 0.013223572634160519
step: 880, loss: 0.02856627106666565
step: 890, loss: 0.018071873113512993
step: 900, loss: 0.04463031142950058
step: 910, loss: 0.0271245539188385
step: 920, loss: 0.06631846725940704
step: 930, loss: 0.03160950541496277
step: 940, loss: 0.0030685074161738157
step: 950, loss: 0.010148562490940094
step: 960, loss: 0.012302570976316929
step: 970, loss: 0.0002411915920674801
epoch 15: dev_f1=0.9264844486333647, f1=0.9233627496516488, best_f1=0.9322964318389753
step: 0, loss: 0.044238220900297165
step: 10, loss: 0.00012977022561244667
step: 20, loss: 1.1969266779487953e-05
step: 30, loss: 0.046398188918828964
step: 40, loss: 0.001298192422837019
step: 50, loss: 0.022523533552885056
step: 60, loss: 0.00020062811381649226
step: 70, loss: 0.0006310886819846928
step: 80, loss: 0.04107678309082985
step: 90, loss: 0.04928913712501526
step: 100, loss: 0.026051906868815422
step: 110, loss: 0.069661945104599
step: 120, loss: 0.05654070898890495
step: 130, loss: 0.06611856818199158
step: 140, loss: 0.02756386622786522
step: 150, loss: 0.001885758712887764
step: 160, loss: 0.07545424997806549
step: 170, loss: 0.0389922596514225
step: 180, loss: 0.04020331799983978
step: 190, loss: 0.0566047839820385
step: 200, loss: 0.018440423533320427
step: 210, loss: 0.02928442880511284
step: 220, loss: 0.010712429881095886
step: 230, loss: 0.030011296272277832
step: 240, loss: 0.012723605148494244
step: 250, loss: 0.03366927057504654
step: 260, loss: 0.1284189373254776
step: 270, loss: 0.00030925104510970414
step: 280, loss: 0.05207788944244385
step: 290, loss: 0.0512080155313015
step: 300, loss: 0.04427604377269745
step: 310, loss: 0.0009985084179788828
step: 320, loss: 3.467727583483793e-05
step: 330, loss: 0.0019216506043449044
step: 340, loss: 0.019986582919955254
step: 350, loss: 0.001081643858924508
step: 360, loss: 0.14421792328357697
step: 370, loss: 0.021447595208883286
step: 380, loss: 0.05744164437055588
step: 390, loss: 0.00023364904336631298
step: 400, loss: 0.026912163943052292
step: 410, loss: 0.018392939120531082
step: 420, loss: 6.556071457453072e-05
step: 430, loss: 0.03953268378973007
step: 440, loss: 0.03484637290239334
step: 450, loss: 0.04177853837609291
step: 460, loss: 0.02654048427939415
step: 470, loss: 0.08401866257190704
step: 480, loss: 0.004010142292827368
step: 490, loss: 0.0029489791486412287
step: 500, loss: 0.025182444602251053
step: 510, loss: 0.04676714166998863
step: 520, loss: 0.018688440322875977
step: 530, loss: 0.025207165628671646
step: 540, loss: 0.014164677821099758
step: 550, loss: 0.007411534432321787
step: 560, loss: 0.07916552573442459
step: 570, loss: 0.07491207122802734
step: 580, loss: 0.0192631296813488
step: 590, loss: 0.025611206889152527
step: 600, loss: 0.0004846690280828625
step: 610, loss: 0.04415274038910866
step: 620, loss: 0.12508487701416016
step: 630, loss: 0.07922094315290451
step: 640, loss: 0.0005369266145862639
step: 650, loss: 0.04623596370220184
step: 660, loss: 0.042455144226551056
step: 670, loss: 0.0521012507379055
step: 680, loss: 9.026128827827051e-05
step: 690, loss: 0.022452522069215775
step: 700, loss: 0.11202064156532288
step: 710, loss: 0.01850581355392933
step: 720, loss: 0.0007464488735422492
step: 730, loss: 0.001492368639446795
step: 740, loss: 0.0018749606097117066
step: 750, loss: 0.08226338028907776
step: 760, loss: 0.03056998737156391
step: 770, loss: 0.04588211700320244
step: 780, loss: 0.04125101864337921
step: 790, loss: 0.0640108585357666
step: 800, loss: 0.03595760092139244
step: 810, loss: 0.09763967245817184
step: 820, loss: 0.003425720613449812
step: 830, loss: 0.050492558628320694
step: 840, loss: 0.037664324045181274
step: 850, loss: 0.04439997673034668
step: 860, loss: 0.007408962585031986
step: 870, loss: 0.017000867053866386
step: 880, loss: 0.04597438871860504
step: 890, loss: 0.01387797761708498
step: 900, loss: 1.4442650353885256e-05
step: 910, loss: 0.0422443151473999
step: 920, loss: 0.023790808394551277
step: 930, loss: 0.006322901230305433
step: 940, loss: 0.0015629412373527884
step: 950, loss: 0.05467057600617409
step: 960, loss: 0.022162768989801407
step: 970, loss: 0.03250201791524887
epoch 16: dev_f1=0.9333333333333333, f1=0.926984126984127, best_f1=0.9322964318389753
step: 0, loss: 0.02800743281841278
step: 10, loss: 0.0001388601231155917
step: 20, loss: 0.0009240256040357053
step: 30, loss: 0.02012331783771515
step: 40, loss: 0.056731969118118286
step: 50, loss: 0.11242035031318665
step: 60, loss: 0.06194962188601494
step: 70, loss: 0.0027331288438290358
step: 80, loss: 0.04519182816147804
step: 90, loss: 0.02278420887887478
step: 100, loss: 0.022603092715144157
step: 110, loss: 0.048644427210092545
step: 120, loss: 0.0396905280649662
step: 130, loss: 0.001016705995425582
step: 140, loss: 0.035159412771463394
step: 150, loss: 0.04144168645143509
step: 160, loss: 0.051657333970069885
step: 170, loss: 0.043970126658678055
step: 180, loss: 0.031743746250867844
step: 190, loss: 3.209012356819585e-05
step: 200, loss: 3.730131356860511e-05
step: 210, loss: 0.028564829379320145
step: 220, loss: 0.0010367203503847122
step: 230, loss: 0.0325719490647316
step: 240, loss: 0.08940745145082474
step: 250, loss: 8.789179992163554e-05
step: 260, loss: 0.046980828046798706
step: 270, loss: 0.021679462864995003
step: 280, loss: 0.00013577866775449365
step: 290, loss: 0.03948630020022392
step: 300, loss: 0.02329837717115879
step: 310, loss: 0.07500770688056946
step: 320, loss: 6.969567766645923e-05
step: 330, loss: 0.032544367015361786
step: 340, loss: 0.002027662703767419
step: 350, loss: 0.06230846419930458
step: 360, loss: 0.007913160137832165
step: 370, loss: 0.00015213216829579324
step: 380, loss: 0.024094779044389725
step: 390, loss: 0.013638599775731564
step: 400, loss: 0.14322073757648468
step: 410, loss: 0.08054020255804062
step: 420, loss: 0.04052386060357094
step: 430, loss: 0.007662630174309015
step: 440, loss: 0.014889287762343884
step: 450, loss: 0.027441194280982018
step: 460, loss: 0.03812262788414955
step: 470, loss: 0.0017791687278077006
step: 480, loss: 0.03342684730887413
step: 490, loss: 0.01860584318637848
step: 500, loss: 0.015640441328287125
step: 510, loss: 0.1124202311038971
step: 520, loss: 0.10762957483530045
step: 530, loss: 0.03766467794775963
step: 540, loss: 0.06436136364936829
step: 550, loss: 0.03571479022502899
step: 560, loss: 0.0652909204363823
step: 570, loss: 0.0018559816526249051
step: 580, loss: 0.036026012152433395
step: 590, loss: 0.00016181674436666071
step: 600, loss: 0.0400737039744854
step: 610, loss: 0.02207675389945507
step: 620, loss: 0.02326815575361252
step: 630, loss: 0.09019535034894943
step: 640, loss: 0.0019531615544110537
step: 650, loss: 0.0221660565584898
step: 660, loss: 0.01492256484925747
step: 670, loss: 0.01840542070567608
step: 680, loss: 0.021481018513441086
step: 690, loss: 0.021645018830895424
step: 700, loss: 0.02650335803627968
step: 710, loss: 0.0001797678996808827
step: 720, loss: 0.02617666684091091
step: 730, loss: 9.330009925179183e-05
step: 740, loss: 0.06066008657217026
step: 750, loss: 0.03482063487172127
step: 760, loss: 0.034169699996709824
step: 770, loss: 0.023350553587079048
step: 780, loss: 0.07304824888706207
step: 790, loss: 0.04549175500869751
step: 800, loss: 0.01015966385602951
step: 810, loss: 0.025347797200083733
step: 820, loss: 0.006959458813071251
step: 830, loss: 0.05237499251961708
step: 840, loss: 2.0554563889163546e-05
step: 850, loss: 0.043586548417806625
step: 860, loss: 0.01816101372241974
step: 870, loss: 0.08285345137119293
step: 880, loss: 0.05920146405696869
step: 890, loss: 0.03863314911723137
step: 900, loss: 0.00018992912373505533
step: 910, loss: 0.09165693074464798
step: 920, loss: 1.7627138731768355e-05
step: 930, loss: 0.019244886934757233
step: 940, loss: 0.017166657373309135
step: 950, loss: 0.048343341797590256
step: 960, loss: 0.027481775730848312
step: 970, loss: 0.1032165139913559
epoch 17: dev_f1=0.9313404950957496, f1=0.9235757295044, best_f1=0.9322964318389753
step: 0, loss: 0.04337477684020996
step: 10, loss: 0.02229267731308937
step: 20, loss: 0.02340490184724331
step: 30, loss: 0.040577612817287445
step: 40, loss: 0.0001843065838329494
step: 50, loss: 0.0311150960624218
step: 60, loss: 0.04066334664821625
step: 70, loss: 0.03977401927113533
step: 80, loss: 0.021587172523140907
step: 90, loss: 0.11740899085998535
step: 100, loss: 0.0005736526800319552
step: 110, loss: 0.0696697011590004
step: 120, loss: 4.706162144429982e-05
step: 130, loss: 0.025875482708215714
step: 140, loss: 0.025275716558098793
step: 150, loss: 0.03297433629631996
step: 160, loss: 0.00010749907232820988
step: 170, loss: 0.00015007166075520217
step: 180, loss: 0.009607692249119282
step: 190, loss: 0.03738044202327728
step: 200, loss: 9.784611029317603e-05
step: 210, loss: 0.025780031457543373
step: 220, loss: 0.029377451166510582
step: 230, loss: 0.015909891575574875
step: 240, loss: 6.231574661796913e-05
step: 250, loss: 0.024656355381011963
step: 260, loss: 0.011404610238969326
step: 270, loss: 0.03355717658996582
step: 280, loss: 0.028035199269652367
step: 290, loss: 0.00020514683274086565
step: 300, loss: 0.01976165547966957
step: 310, loss: 0.0003119109896942973
step: 320, loss: 0.030002208426594734
step: 330, loss: 0.03503367304801941
step: 340, loss: 0.0750807672739029
step: 350, loss: 0.010356652550399303
step: 360, loss: 0.00010569152073003352
step: 370, loss: 0.0001919880451168865
step: 380, loss: 0.0001571989560034126
step: 390, loss: 8.75564874149859e-05
step: 400, loss: 0.015757087618112564
step: 410, loss: 0.023705240339040756
step: 420, loss: 0.03389507904648781
step: 430, loss: 5.331218562787399e-05
step: 440, loss: 0.027990475296974182
step: 450, loss: 0.02091958001255989
step: 460, loss: 0.02834491617977619
step: 470, loss: 0.024175778031349182
step: 480, loss: 0.04964153841137886
step: 490, loss: 0.029310360550880432
step: 500, loss: 2.2375417756848037e-05
step: 510, loss: 0.07272212952375412
step: 520, loss: 0.047178640961647034
step: 530, loss: 0.018621105700731277
step: 540, loss: 0.056508131325244904
step: 550, loss: 0.00026457678177393973
step: 560, loss: 0.05350203439593315
step: 570, loss: 0.027244962751865387
step: 580, loss: 0.028249448165297508
step: 590, loss: 0.017039034515619278
step: 600, loss: 0.017375780269503593
step: 610, loss: 0.0028938804753124714
step: 620, loss: 0.000114596048661042
step: 630, loss: 0.07262681424617767
step: 640, loss: 0.057246752083301544
step: 650, loss: 0.10424524545669556
step: 660, loss: 0.015842653810977936
step: 670, loss: 0.030620090663433075
step: 680, loss: 0.034214992076158524
step: 690, loss: 0.013669328764081001
step: 700, loss: 0.00018213254224974662
step: 710, loss: 9.71794652286917e-05
step: 720, loss: 0.07947887480258942
step: 730, loss: 0.05276035517454147
step: 740, loss: 0.0577523373067379
step: 750, loss: 0.00029210723005235195
step: 760, loss: 0.018595173954963684
step: 770, loss: 0.09570405632257462
step: 780, loss: 0.014512560330331326
step: 790, loss: 0.022110752761363983
step: 800, loss: 0.050920259207487106
step: 810, loss: 0.06870070844888687
step: 820, loss: 0.013572477735579014
step: 830, loss: 0.06149202585220337
step: 840, loss: 0.001171919982880354
step: 850, loss: 0.00013227899034973234
step: 860, loss: 0.014062334783375263
step: 870, loss: 5.354981476557441e-05
step: 880, loss: 0.02903852052986622
step: 890, loss: 0.05509326606988907
step: 900, loss: 0.01949211210012436
step: 910, loss: 0.005378664005547762
step: 920, loss: 0.05310589075088501
step: 930, loss: 0.019825933501124382
step: 940, loss: 0.0020204251632094383
step: 950, loss: 0.0220933947712183
step: 960, loss: 0.04668427258729935
step: 970, loss: 0.059510644525289536
epoch 18: dev_f1=0.9280742459396751, f1=0.9226519337016574, best_f1=0.9322964318389753
step: 0, loss: 0.000955758208874613
step: 10, loss: 0.03382417932152748
step: 20, loss: 0.024355068802833557
step: 30, loss: 0.04113682731986046
step: 40, loss: 0.005579732824116945
step: 50, loss: 0.034044910222291946
step: 60, loss: 0.023865288123488426
step: 70, loss: 0.04146471247076988
step: 80, loss: 0.054885584861040115
step: 90, loss: 0.024321909993886948
step: 100, loss: 0.04453357309103012
step: 110, loss: 8.741292549530044e-05
step: 120, loss: 0.04638431593775749
step: 130, loss: 0.05013616010546684
step: 140, loss: 0.02178453654050827
step: 150, loss: 0.11207393556833267
step: 160, loss: 0.02036985196173191
step: 170, loss: 0.02247421257197857
step: 180, loss: 0.021244531497359276
step: 190, loss: 0.017902322113513947
step: 200, loss: 2.1924894099356607e-05
step: 210, loss: 0.021613413468003273
step: 220, loss: 0.06969090551137924
step: 230, loss: 0.048130303621292114
step: 240, loss: 0.048145975917577744
step: 250, loss: 0.06631360948085785
step: 260, loss: 0.009593276306986809
step: 270, loss: 0.06509728729724884
step: 280, loss: 0.02336958795785904
step: 290, loss: 0.020298609510064125
step: 300, loss: 0.00010598650987958536
step: 310, loss: 0.037718549370765686
step: 320, loss: 0.021016821265220642
step: 330, loss: 0.07846947014331818
step: 340, loss: 0.004866026807576418
step: 350, loss: 4.680515849031508e-05
step: 360, loss: 0.023580586537718773
step: 370, loss: 0.04664134606719017
step: 380, loss: 0.019001172855496407
step: 390, loss: 0.016964057460427284
step: 400, loss: 0.06207796186208725
step: 410, loss: 0.05835844576358795
step: 420, loss: 0.006419912911951542
step: 430, loss: 0.05146962031722069
step: 440, loss: 0.05964776501059532
step: 450, loss: 6.006359399179928e-05
step: 460, loss: 0.02449849806725979
step: 470, loss: 0.01678665354847908
step: 480, loss: 0.0626886636018753
step: 490, loss: 0.008372652344405651
step: 500, loss: 0.018810568377375603
step: 510, loss: 0.018237223848700523
step: 520, loss: 0.05275530740618706
step: 530, loss: 0.0006938318838365376
step: 540, loss: 0.00010443800420034677
step: 550, loss: 0.10238611698150635
step: 560, loss: 6.536123692058027e-05
step: 570, loss: 0.0018756429199129343
step: 580, loss: 0.05560029670596123
step: 590, loss: 0.02412300370633602
step: 600, loss: 0.04399575665593147
step: 610, loss: 0.018437126651406288
step: 620, loss: 0.05370504781603813
step: 630, loss: 0.05184477940201759
step: 640, loss: 0.018956724554300308
step: 650, loss: 0.00011295836884528399
step: 660, loss: 8.213619003072381e-05
step: 670, loss: 0.019634399563074112
step: 680, loss: 0.052452508360147476
step: 690, loss: 9.556644363328815e-05
step: 700, loss: 4.4451207941165194e-05
step: 710, loss: 0.027996482327580452
step: 720, loss: 0.014771669171750546
step: 730, loss: 0.020950177684426308
step: 740, loss: 0.1891663670539856
step: 750, loss: 0.03897054120898247
step: 760, loss: 0.0006727727013640106
step: 770, loss: 0.02160373143851757
step: 780, loss: 6.793776992708445e-05
step: 790, loss: 0.00010077278420794755
step: 800, loss: 0.020298438146710396
step: 810, loss: 0.0024646788369864225
step: 820, loss: 2.2416434148908593e-05
step: 830, loss: 0.014861103147268295
step: 840, loss: 0.04853805899620056
step: 850, loss: 0.04336550459265709
step: 860, loss: 0.0400664396584034
step: 870, loss: 0.0003841862780973315
step: 880, loss: 0.08439291268587112
step: 890, loss: 0.014990484341979027
step: 900, loss: 1.051268645824166e-05
step: 910, loss: 0.035418059676885605
step: 920, loss: 0.02571587637066841
step: 930, loss: 0.016294041648507118
step: 940, loss: 0.008443488739430904
step: 950, loss: 3.255704723414965e-05
step: 960, loss: 0.012083526700735092
step: 970, loss: 0.008089187555015087
epoch 19: dev_f1=0.9287054409005628, f1=0.9286713286713286, best_f1=0.9322964318389753
step: 0, loss: 0.10089381784200668
step: 10, loss: 0.005269995890557766
step: 20, loss: 6.434826354961842e-05
step: 30, loss: 0.02134113200008869
step: 40, loss: 0.05861593410372734
step: 50, loss: 5.328745464794338e-05
step: 60, loss: 0.0553298182785511
step: 70, loss: 9.656766633270308e-05
step: 80, loss: 0.058640170842409134
step: 90, loss: 0.0004673736111726612
step: 100, loss: 0.04862213134765625
step: 110, loss: 0.0013129606377333403
step: 120, loss: 0.014836958609521389
step: 130, loss: 0.00011870110756717622
step: 140, loss: 0.025630418211221695
step: 150, loss: 0.049137283116579056
step: 160, loss: 0.02842029184103012
step: 170, loss: 0.0004635159857571125
step: 180, loss: 0.026249468326568604
step: 190, loss: 0.014852475374937057
step: 200, loss: 0.02586846798658371
step: 210, loss: 9.727464203024283e-05
step: 220, loss: 0.03694027662277222
step: 230, loss: 0.036333587020635605
step: 240, loss: 0.09312119334936142
step: 250, loss: 0.04485814645886421
step: 260, loss: 0.013337449170649052
step: 270, loss: 0.02382112853229046
step: 280, loss: 0.06630222499370575
step: 290, loss: 0.03989135101437569
step: 300, loss: 0.04673907905817032
step: 310, loss: 0.0429682694375515
step: 320, loss: 0.0394609197974205
step: 330, loss: 0.04519561678171158
step: 340, loss: 2.539620254538022e-05
step: 350, loss: 0.008979760110378265
step: 360, loss: 0.07504191249608994
step: 370, loss: 3.155433660140261e-05
step: 380, loss: 0.043769385665655136
step: 390, loss: 8.551876817364246e-05
step: 400, loss: 0.037577226758003235
step: 410, loss: 3.451502198004164e-05
step: 420, loss: 0.04527279734611511
step: 430, loss: 4.482321674004197e-05
step: 440, loss: 0.04652426764369011
step: 450, loss: 0.02078600972890854
step: 460, loss: 0.002618079539388418
step: 470, loss: 0.024127915501594543
step: 480, loss: 0.0237627811729908
step: 490, loss: 0.007047867402434349
step: 500, loss: 0.018915031105279922
step: 510, loss: 0.025148862972855568
step: 520, loss: 0.023131372407078743
step: 530, loss: 0.05008295178413391
step: 540, loss: 0.057104483246803284
step: 550, loss: 0.06367000192403793
step: 560, loss: 0.028875738382339478
step: 570, loss: 0.03161585330963135
step: 580, loss: 3.546755397110246e-05
step: 590, loss: 0.0002850776363629848
step: 600, loss: 0.03756142035126686
step: 610, loss: 0.002801052061840892
step: 620, loss: 0.045687235891819
step: 630, loss: 0.05247269570827484
step: 640, loss: 6.343203131109476e-05
step: 650, loss: 0.022386211901903152
step: 660, loss: 0.02227051369845867
step: 670, loss: 0.01461026817560196
step: 680, loss: 0.03706521540880203
step: 690, loss: 0.0012370324693620205
step: 700, loss: 0.009887397289276123
step: 710, loss: 0.0014294144930317998
step: 720, loss: 6.615635356865823e-05
step: 730, loss: 0.02386854775249958
step: 740, loss: 0.041025012731552124
step: 750, loss: 0.021092457696795464
step: 760, loss: 0.024701260030269623
step: 770, loss: 0.006208559963852167
step: 780, loss: 0.05341048911213875
step: 790, loss: 0.03800050914287567
step: 800, loss: 0.07050473242998123
step: 810, loss: 3.371878119651228e-05
step: 820, loss: 0.06992851942777634
step: 830, loss: 0.03888198360800743
step: 840, loss: 0.06907786428928375
step: 850, loss: 0.017853301018476486
step: 860, loss: 0.025900501757860184
step: 870, loss: 0.037005502730607986
step: 880, loss: 0.00016332170343957841
step: 890, loss: 0.03438553586602211
step: 900, loss: 0.04076044633984566
step: 910, loss: 0.0244707390666008
step: 920, loss: 7.88872130215168e-05
step: 930, loss: 0.0677652508020401
step: 940, loss: 5.931459600105882e-05
step: 950, loss: 0.002377075143158436
step: 960, loss: 0.027892692014575005
step: 970, loss: 0.034456364810466766
epoch 20: dev_f1=0.9282027217268888, f1=0.927468413664015, best_f1=0.9322964318389753
