cuda
Device: cuda
step: 0, loss: 0.7263910174369812
step: 10, loss: 0.23255771398544312
step: 20, loss: 0.04454176872968674
step: 30, loss: 0.40877988934516907
step: 40, loss: 0.3048877418041229
step: 50, loss: 0.19242355227470398
step: 60, loss: 0.15406659245491028
step: 70, loss: 0.17108911275863647
step: 80, loss: 0.1745932251214981
step: 90, loss: 0.28500881791114807
step: 100, loss: 0.1529555469751358
step: 110, loss: 0.1645127683877945
step: 120, loss: 0.19191041588783264
step: 130, loss: 0.17014747858047485
step: 140, loss: 0.1964450478553772
step: 150, loss: 0.21047592163085938
step: 160, loss: 0.13128560781478882
step: 170, loss: 0.23613868653774261
step: 180, loss: 0.10457973182201385
step: 190, loss: 0.06771023571491241
step: 200, loss: 0.26071101427078247
step: 210, loss: 0.08357083052396774
step: 220, loss: 0.09033811837434769
step: 230, loss: 0.10986053943634033
step: 240, loss: 0.0903402715921402
step: 250, loss: 0.06253358721733093
step: 260, loss: 0.1279672086238861
step: 270, loss: 0.10552743822336197
step: 280, loss: 0.12014247477054596
step: 290, loss: 0.08448738604784012
step: 300, loss: 0.10011342912912369
step: 310, loss: 0.12430539727210999
step: 320, loss: 0.1404533088207245
step: 330, loss: 0.16583557426929474
step: 340, loss: 0.23157267272472382
step: 350, loss: 0.10751549154520035
step: 360, loss: 0.21935658156871796
step: 370, loss: 0.05981327220797539
step: 380, loss: 0.11763931810855865
step: 390, loss: 0.17915520071983337
step: 400, loss: 0.21071109175682068
step: 410, loss: 0.053696371614933014
step: 420, loss: 0.07663193345069885
step: 430, loss: 0.1870804876089096
step: 440, loss: 0.06481890380382538
step: 450, loss: 0.1385784149169922
step: 460, loss: 0.24822981655597687
step: 470, loss: 0.08764906972646713
step: 480, loss: 0.18077485263347626
step: 490, loss: 0.09680730104446411
step: 500, loss: 0.0713072419166565
step: 510, loss: 0.06582984328269958
step: 520, loss: 0.1618427187204361
step: 530, loss: 0.178212970495224
step: 540, loss: 0.08322566747665405
step: 550, loss: 0.24191324412822723
step: 560, loss: 0.17086568474769592
step: 570, loss: 0.11251305043697357
step: 580, loss: 0.07579211890697479
step: 590, loss: 0.108950175344944
step: 600, loss: 0.02621382661163807
step: 610, loss: 0.10730497539043427
step: 620, loss: 0.10225187987089157
step: 630, loss: 0.16121163964271545
step: 640, loss: 0.08986610174179077
step: 650, loss: 0.15406759083271027
step: 660, loss: 0.0807318314909935
step: 670, loss: 0.0656338632106781
step: 680, loss: 0.07197766751050949
step: 690, loss: 0.07179936021566391
step: 700, loss: 0.15883880853652954
step: 710, loss: 0.20340542495250702
step: 720, loss: 0.08067431300878525
step: 730, loss: 0.019935039803385735
step: 740, loss: 0.16416378319263458
step: 750, loss: 0.10621056705713272
step: 760, loss: 0.14087657630443573
step: 770, loss: 0.16514675319194794
step: 780, loss: 0.10934170335531235
step: 790, loss: 0.06942969560623169
step: 800, loss: 0.22839820384979248
step: 810, loss: 0.039965588599443436
step: 820, loss: 0.1462583690881729
step: 830, loss: 0.07635829597711563
step: 840, loss: 0.11839108914136887
step: 850, loss: 0.2420920580625534
step: 860, loss: 0.17070245742797852
step: 870, loss: 0.16719377040863037
step: 880, loss: 0.21471258997917175
step: 890, loss: 0.048276063054800034
step: 900, loss: 0.03297901526093483
step: 910, loss: 0.22867201268672943
step: 920, loss: 0.11348048597574234
step: 930, loss: 0.2333264797925949
step: 940, loss: 0.11042875796556473
step: 950, loss: 0.19306400418281555
step: 960, loss: 0.20804879069328308
step: 970, loss: 0.21723033487796783
epoch 1: dev_f1=0.9274809160305343, f1=0.9312470365101944, best_f1=0.9312470365101944
step: 0, loss: 0.09971793740987778
step: 10, loss: 0.0570533350110054
step: 20, loss: 0.12173885852098465
step: 30, loss: 0.1686088889837265
step: 40, loss: 0.028057202696800232
step: 50, loss: 0.1610938161611557
step: 60, loss: 0.22836551070213318
step: 70, loss: 0.06948903948068619
step: 80, loss: 0.0876288190484047
step: 90, loss: 0.10171832889318466
step: 100, loss: 0.06639030575752258
step: 110, loss: 0.1106000691652298
step: 120, loss: 0.028036002069711685
step: 130, loss: 0.26122748851776123
step: 140, loss: 0.06981458514928818
step: 150, loss: 0.11662086099386215
step: 160, loss: 0.024313556030392647
step: 170, loss: 0.06486821919679642
step: 180, loss: 0.06239410117268562
step: 190, loss: 0.05376388877630234
step: 200, loss: 0.06482137739658356
step: 210, loss: 0.004411568399518728
step: 220, loss: 0.08352409303188324
step: 230, loss: 0.2458331137895584
step: 240, loss: 0.08916384726762772
step: 250, loss: 0.11505255103111267
step: 260, loss: 0.06442853808403015
step: 270, loss: 0.1097182035446167
step: 280, loss: 0.17320048809051514
step: 290, loss: 0.11334506422281265
step: 300, loss: 0.009160589426755905
step: 310, loss: 0.28585630655288696
step: 320, loss: 0.19800853729248047
step: 330, loss: 0.08395413309335709
step: 340, loss: 0.053675904870033264
step: 350, loss: 0.061150651425123215
step: 360, loss: 0.02835262566804886
step: 370, loss: 0.07343734055757523
step: 380, loss: 0.0827435627579689
step: 390, loss: 0.01996620185673237
step: 400, loss: 0.07331737130880356
step: 410, loss: 0.08728138357400894
step: 420, loss: 0.05749950185418129
step: 430, loss: 0.08777367323637009
step: 440, loss: 0.23340028524398804
step: 450, loss: 0.07166577130556107
step: 460, loss: 0.1058303564786911
step: 470, loss: 0.06976021826267242
step: 480, loss: 0.06784326583147049
step: 490, loss: 0.07306874543428421
step: 500, loss: 0.06315501779317856
step: 510, loss: 0.06813094019889832
step: 520, loss: 0.2280498892068863
step: 530, loss: 0.08150497823953629
step: 540, loss: 0.18924950063228607
step: 550, loss: 0.14594832062721252
step: 560, loss: 0.038587238639593124
step: 570, loss: 0.08997602760791779
step: 580, loss: 0.11992011964321136
step: 590, loss: 0.011493781581521034
step: 600, loss: 0.19995132088661194
step: 610, loss: 0.08996254950761795
step: 620, loss: 0.20315997302532196
step: 630, loss: 0.06273109465837479
step: 640, loss: 0.11069540679454803
step: 650, loss: 0.02407781407237053
step: 660, loss: 0.017014630138874054
step: 670, loss: 0.029515964910387993
step: 680, loss: 0.16967914998531342
step: 690, loss: 0.16415658593177795
step: 700, loss: 0.13547228276729584
step: 710, loss: 0.07106170058250427
step: 720, loss: 0.16977207362651825
step: 730, loss: 0.11147845536470413
step: 740, loss: 0.09536315500736237
step: 750, loss: 0.035204336047172546
step: 760, loss: 0.08219235390424728
step: 770, loss: 0.05557480454444885
step: 780, loss: 0.018205273896455765
step: 790, loss: 0.16483747959136963
step: 800, loss: 0.1771661937236786
step: 810, loss: 0.08376612514257431
step: 820, loss: 0.06048194319009781
step: 830, loss: 0.09763502329587936
step: 840, loss: 0.20225000381469727
step: 850, loss: 0.18434664607048035
step: 860, loss: 0.13332553207874298
step: 870, loss: 0.047969330102205276
step: 880, loss: 0.05035826563835144
step: 890, loss: 0.04805576801300049
step: 900, loss: 0.11190451681613922
step: 910, loss: 0.21239706873893738
step: 920, loss: 0.07296910881996155
step: 930, loss: 0.08505134284496307
step: 940, loss: 0.1622297167778015
step: 950, loss: 0.0737387090921402
step: 960, loss: 0.09816237539052963
step: 970, loss: 0.033973708748817444
epoch 2: dev_f1=0.932904411764706, f1=0.9310661764705882, best_f1=0.9310661764705882
step: 0, loss: 0.038421157747507095
step: 10, loss: 0.044520918279886246
step: 20, loss: 0.08773145079612732
step: 30, loss: 0.020785165950655937
step: 40, loss: 0.07816395908594131
step: 50, loss: 0.014908735640347004
step: 60, loss: 0.057478513568639755
step: 70, loss: 0.09011771529912949
step: 80, loss: 0.11743662506341934
step: 90, loss: 0.008444647304713726
step: 100, loss: 0.07360514998435974
step: 110, loss: 0.04296867921948433
step: 120, loss: 0.16345016658306122
step: 130, loss: 0.027575049549341202
step: 140, loss: 0.022430138662457466
step: 150, loss: 0.28806716203689575
step: 160, loss: 0.06819919496774673
step: 170, loss: 0.11259958893060684
step: 180, loss: 0.08997169882059097
step: 190, loss: 0.03984026983380318
step: 200, loss: 0.18069273233413696
step: 210, loss: 0.0742727518081665
step: 220, loss: 0.08498366177082062
step: 230, loss: 0.043096061795949936
step: 240, loss: 0.0898137167096138
step: 250, loss: 0.07177194207906723
step: 260, loss: 0.06520413607358932
step: 270, loss: 0.07399413734674454
step: 280, loss: 0.09176819771528244
step: 290, loss: 0.07058237493038177
step: 300, loss: 0.08023906499147415
step: 310, loss: 0.058059193193912506
step: 320, loss: 0.1295471489429474
step: 330, loss: 0.09461955726146698
step: 340, loss: 0.05451825633645058
step: 350, loss: 0.15573281049728394
step: 360, loss: 0.2518078088760376
step: 370, loss: 0.10525358468294144
step: 380, loss: 0.027585173025727272
step: 390, loss: 0.11633803695440292
step: 400, loss: 0.032310087233781815
step: 410, loss: 0.06555615365505219
step: 420, loss: 0.03588298708200455
step: 430, loss: 0.13523058593273163
step: 440, loss: 0.2139769345521927
step: 450, loss: 0.1328388750553131
step: 460, loss: 0.02815239690244198
step: 470, loss: 0.03676567226648331
step: 480, loss: 0.08474753797054291
step: 490, loss: 0.07860491424798965
step: 500, loss: 0.057074256241321564
step: 510, loss: 0.06083538010716438
step: 520, loss: 0.1292342245578766
step: 530, loss: 0.17440682649612427
step: 540, loss: 0.11580794304609299
step: 550, loss: 0.02443823032081127
step: 560, loss: 0.14665621519088745
step: 570, loss: 0.11429040133953094
step: 580, loss: 0.07872197777032852
step: 590, loss: 0.12346909940242767
step: 600, loss: 0.09751704335212708
step: 610, loss: 0.04716188833117485
step: 620, loss: 0.07235979288816452
step: 630, loss: 0.1420421153306961
step: 640, loss: 0.027252066880464554
step: 650, loss: 0.016441307961940765
step: 660, loss: 0.16499681770801544
step: 670, loss: 0.02291582152247429
step: 680, loss: 0.1568799763917923
step: 690, loss: 0.05449162423610687
step: 700, loss: 7.24962810636498e-05
step: 710, loss: 0.05172959342598915
step: 720, loss: 0.03811650723218918
step: 730, loss: 0.07129815220832825
step: 740, loss: 0.06162413954734802
step: 750, loss: 0.016141895204782486
step: 760, loss: 0.10142253339290619
step: 770, loss: 0.08331621438264847
step: 780, loss: 0.03470215946435928
step: 790, loss: 0.10208990424871445
step: 800, loss: 0.07820168137550354
step: 810, loss: 0.02434316650032997
step: 820, loss: 0.19634807109832764
step: 830, loss: 0.06264293938875198
step: 840, loss: 0.13902480900287628
step: 850, loss: 0.08836182206869125
step: 860, loss: 0.133052259683609
step: 870, loss: 0.08877968788146973
step: 880, loss: 0.012310158461332321
step: 890, loss: 0.019093146547675133
step: 900, loss: 0.11885960400104523
step: 910, loss: 0.0884551852941513
step: 920, loss: 0.016592830419540405
step: 930, loss: 0.08402587473392487
step: 940, loss: 0.13113060593605042
step: 950, loss: 0.09237509220838547
step: 960, loss: 0.12385328114032745
step: 970, loss: 0.131888747215271
epoch 3: dev_f1=0.9409048938134812, f1=0.941447671738128, best_f1=0.941447671738128
step: 0, loss: 0.015699638053774834
step: 10, loss: 0.0881257951259613
step: 20, loss: 0.06954028457403183
step: 30, loss: 0.012140407226979733
step: 40, loss: 0.13612288236618042
step: 50, loss: 0.06771834939718246
step: 60, loss: 0.0761529952287674
step: 70, loss: 0.11943618208169937
step: 80, loss: 0.10518890619277954
step: 90, loss: 0.026016680523753166
step: 100, loss: 0.007770831696689129
step: 110, loss: 0.01588602550327778
step: 120, loss: 0.09183649718761444
step: 130, loss: 0.13593797385692596
step: 140, loss: 0.08978371322154999
step: 150, loss: 0.021203577518463135
step: 160, loss: 0.1482647806406021
step: 170, loss: 0.1130172461271286
step: 180, loss: 0.14597375690937042
step: 190, loss: 0.18181626498699188
step: 200, loss: 0.030044641345739365
step: 210, loss: 0.16019847989082336
step: 220, loss: 0.11918917298316956
step: 230, loss: 0.08891606330871582
step: 240, loss: 0.04459463804960251
step: 250, loss: 0.11325283348560333
step: 260, loss: 0.13352729380130768
step: 270, loss: 0.0533176064491272
step: 280, loss: 0.06414876133203506
step: 290, loss: 0.0565793514251709
step: 300, loss: 0.17104360461235046
step: 310, loss: 0.05523018538951874
step: 320, loss: 0.028985900804400444
step: 330, loss: 0.026197943836450577
step: 340, loss: 0.024169109761714935
step: 350, loss: 0.11363455653190613
step: 360, loss: 0.0640057846903801
step: 370, loss: 0.1125965267419815
step: 380, loss: 0.03520892187952995
step: 390, loss: 0.056218452751636505
step: 400, loss: 0.05025810748338699
step: 410, loss: 0.06763031333684921
step: 420, loss: 0.11548090726137161
step: 430, loss: 0.1709842085838318
step: 440, loss: 0.08696937561035156
step: 450, loss: 0.04273778945207596
step: 460, loss: 0.017195506021380424
step: 470, loss: 0.09273722022771835
step: 480, loss: 0.07204484194517136
step: 490, loss: 0.07599228620529175
step: 500, loss: 0.0960850641131401
step: 510, loss: 0.13473954796791077
step: 520, loss: 0.05215473100543022
step: 530, loss: 0.06771047413349152
step: 540, loss: 0.08348274230957031
step: 550, loss: 0.02379700541496277
step: 560, loss: 0.01389195304363966
step: 570, loss: 0.1560080647468567
step: 580, loss: 0.18470297753810883
step: 590, loss: 0.09278544783592224
step: 600, loss: 0.06450353562831879
step: 610, loss: 0.07021334767341614
step: 620, loss: 0.04972568154335022
step: 630, loss: 0.011492282152175903
step: 640, loss: 0.06152447313070297
step: 650, loss: 0.1380697339773178
step: 660, loss: 0.09572586417198181
step: 670, loss: 0.08228089660406113
step: 680, loss: 0.09430665522813797
step: 690, loss: 0.05868341401219368
step: 700, loss: 0.025241201743483543
step: 710, loss: 0.007538841105997562
step: 720, loss: 0.035540733486413956
step: 730, loss: 0.14092960953712463
step: 740, loss: 0.0652276948094368
step: 750, loss: 0.21237850189208984
step: 760, loss: 0.13956503570079803
step: 770, loss: 0.1874551773071289
step: 780, loss: 0.10508473217487335
step: 790, loss: 0.0446905791759491
step: 800, loss: 0.23808377981185913
step: 810, loss: 0.09794619679450989
step: 820, loss: 0.04631676897406578
step: 830, loss: 0.014208214357495308
step: 840, loss: 0.07017579674720764
step: 850, loss: 0.011218570172786713
step: 860, loss: 0.02965518645942211
step: 870, loss: 0.14572612941265106
step: 880, loss: 0.0543568953871727
step: 890, loss: 0.07305961102247238
step: 900, loss: 0.014254790730774403
step: 910, loss: 0.03643127158284187
step: 920, loss: 0.08283673226833344
step: 930, loss: 0.0531032457947731
step: 940, loss: 0.030459364876151085
step: 950, loss: 0.0730333998799324
step: 960, loss: 0.07628905773162842
step: 970, loss: 0.14501924812793732
epoch 4: dev_f1=0.9377555656519764, f1=0.9327272727272726, best_f1=0.941447671738128
step: 0, loss: 0.042150817811489105
step: 10, loss: 0.12183288484811783
step: 20, loss: 0.01597420871257782
step: 30, loss: 0.06989024579524994
step: 40, loss: 0.2484988421201706
step: 50, loss: 0.06656874716281891
step: 60, loss: 0.08228863030672073
step: 70, loss: 0.09512726217508316
step: 80, loss: 0.10954192280769348
step: 90, loss: 0.07037119567394257
step: 100, loss: 0.10081390291452408
step: 110, loss: 0.16340109705924988
step: 120, loss: 0.13545863330364227
step: 130, loss: 0.02516549453139305
step: 140, loss: 0.07867133617401123
step: 150, loss: 0.04827593266963959
step: 160, loss: 0.056226298213005066
step: 170, loss: 0.09778789430856705
step: 180, loss: 0.020327694714069366
step: 190, loss: 0.06636728346347809
step: 200, loss: 0.041738852858543396
step: 210, loss: 0.022333163768053055
step: 220, loss: 0.01686006225645542
step: 230, loss: 0.06385219097137451
step: 240, loss: 0.07521848380565643
step: 250, loss: 0.018842441961169243
step: 260, loss: 0.050690311938524246
step: 270, loss: 0.05699924752116203
step: 280, loss: 0.04549365118145943
step: 290, loss: 0.025827141478657722
step: 300, loss: 0.2595096528530121
step: 310, loss: 0.0486312173306942
step: 320, loss: 0.02028559148311615
step: 330, loss: 0.08040180802345276
step: 340, loss: 0.09803039580583572
step: 350, loss: 0.005920997820794582
step: 360, loss: 0.08429224789142609
step: 370, loss: 0.0121845044195652
step: 380, loss: 0.10370413213968277
step: 390, loss: 0.04824377968907356
step: 400, loss: 0.05142915993928909
step: 410, loss: 0.13096386194229126
step: 420, loss: 0.094171904027462
step: 430, loss: 0.01674589328467846
step: 440, loss: 0.0385851189494133
step: 450, loss: 0.01824312098324299
step: 460, loss: 0.003712165867909789
step: 470, loss: 0.11287142336368561
step: 480, loss: 0.08921591937541962
step: 490, loss: 0.11910425126552582
step: 500, loss: 0.058007705956697464
step: 510, loss: 0.023550475016236305
step: 520, loss: 0.06991513073444366
step: 530, loss: 0.060641124844551086
step: 540, loss: 0.08722881227731705
step: 550, loss: 0.08048302680253983
step: 560, loss: 0.1499686986207962
step: 570, loss: 0.07844889909029007
step: 580, loss: 0.0765768438577652
step: 590, loss: 0.21036849915981293
step: 600, loss: 0.04358725994825363
step: 610, loss: 0.08160413801670074
step: 620, loss: 0.06722832471132278
step: 630, loss: 0.13021232187747955
step: 640, loss: 0.011185136623680592
step: 650, loss: 0.034474484622478485
step: 660, loss: 0.07311029732227325
step: 670, loss: 0.15276643633842468
step: 680, loss: 0.2514176368713379
step: 690, loss: 0.03465186432003975
step: 700, loss: 0.015022695995867252
step: 710, loss: 0.1688963770866394
step: 720, loss: 0.10011767596006393
step: 730, loss: 0.09370897710323334
step: 740, loss: 0.0869777724146843
step: 750, loss: 0.05282304063439369
step: 760, loss: 0.059729427099227905
step: 770, loss: 0.08482983708381653
step: 780, loss: 0.07736466079950333
step: 790, loss: 0.03654005005955696
step: 800, loss: 0.04330114275217056
step: 810, loss: 0.030326349660754204
step: 820, loss: 0.11058875918388367
step: 830, loss: 0.20845966041088104
step: 840, loss: 0.14673767983913422
step: 850, loss: 0.03228972479701042
step: 860, loss: 0.01600390486419201
step: 870, loss: 0.06002715602517128
step: 880, loss: 0.06374485045671463
step: 890, loss: 0.0422787144780159
step: 900, loss: 0.1519746035337448
step: 910, loss: 0.044958360493183136
step: 920, loss: 0.06282704323530197
step: 930, loss: 0.08497005701065063
step: 940, loss: 0.2151537984609604
step: 950, loss: 0.03690611198544502
step: 960, loss: 0.0994853675365448
step: 970, loss: 0.029600754380226135
epoch 5: dev_f1=0.9331489165514063, f1=0.9361702127659576, best_f1=0.941447671738128
step: 0, loss: 0.02501794695854187
step: 10, loss: 0.047169044613838196
step: 20, loss: 0.06045772135257721
step: 30, loss: 0.01088915579020977
step: 40, loss: 0.018758047372102737
step: 50, loss: 0.07756392657756805
step: 60, loss: 0.005025852471590042
step: 70, loss: 0.07933039963245392
step: 80, loss: 0.09051813930273056
step: 90, loss: 0.0130709083750844
step: 100, loss: 0.045543793588876724
step: 110, loss: 0.25872910022735596
step: 120, loss: 0.08106362819671631
step: 130, loss: 0.031154632568359375
step: 140, loss: 0.23543843626976013
step: 150, loss: 0.14993253350257874
step: 160, loss: 0.1550087034702301
step: 170, loss: 0.00638820044696331
step: 180, loss: 0.049040794372558594
step: 190, loss: 0.12030548602342606
step: 200, loss: 0.11765038222074509
step: 210, loss: 0.004862326197326183
step: 220, loss: 0.08418989926576614
step: 230, loss: 0.07906057685613632
step: 240, loss: 0.01615048572421074
step: 250, loss: 0.0732569694519043
step: 260, loss: 0.15101569890975952
step: 270, loss: 0.011074691079556942
step: 280, loss: 0.026856791228055954
step: 290, loss: 0.022604526951909065
step: 300, loss: 0.09940862655639648
step: 310, loss: 0.10176442563533783
step: 320, loss: 0.14416611194610596
step: 330, loss: 0.03874005004763603
step: 340, loss: 0.011202802881598473
step: 350, loss: 0.017319150269031525
step: 360, loss: 0.1269938349723816
step: 370, loss: 0.07875073701143265
step: 380, loss: 0.12614893913269043
step: 390, loss: 0.017694752663373947
step: 400, loss: 0.013930830173194408
step: 410, loss: 0.07506124675273895
step: 420, loss: 0.026454228907823563
step: 430, loss: 0.0941728726029396
step: 440, loss: 0.08214934170246124
step: 450, loss: 0.05595533922314644
step: 460, loss: 0.0004715939285233617
step: 470, loss: 0.16574203968048096
step: 480, loss: 0.2808450162410736
step: 490, loss: 0.11631285399198532
step: 500, loss: 2.9323713533813134e-05
step: 510, loss: 0.051486335694789886
step: 520, loss: 0.05553159862756729
step: 530, loss: 0.1291550248861313
step: 540, loss: 0.0249974112957716
step: 550, loss: 0.035189323127269745
step: 560, loss: 0.023499738425016403
step: 570, loss: 0.017159197479486465
step: 580, loss: 0.015424082055687904
step: 590, loss: 0.012229644693434238
step: 600, loss: 0.10649965703487396
step: 610, loss: 0.008952577598392963
step: 620, loss: 0.03692682832479477
step: 630, loss: 0.09171465039253235
step: 640, loss: 0.08355719596147537
step: 650, loss: 0.08929355442523956
step: 660, loss: 0.08892801403999329
step: 670, loss: 0.13880866765975952
step: 680, loss: 0.04261016100645065
step: 690, loss: 0.12512056529521942
step: 700, loss: 0.09982166439294815
step: 710, loss: 0.024165311828255653
step: 720, loss: 0.12243656814098358
step: 730, loss: 0.07442662119865417
step: 740, loss: 0.015900680795311928
step: 750, loss: 0.052581992000341415
step: 760, loss: 0.03731366991996765
step: 770, loss: 0.1249970942735672
step: 780, loss: 0.018810506910085678
step: 790, loss: 0.062126245349645615
step: 800, loss: 0.08721645176410675
step: 810, loss: 0.08865072578191757
step: 820, loss: 0.0737999677658081
step: 830, loss: 0.2176099270582199
step: 840, loss: 0.04363477602601051
step: 850, loss: 0.0217055045068264
step: 860, loss: 0.01698864996433258
step: 870, loss: 0.05986938625574112
step: 880, loss: 0.07039876282215118
step: 890, loss: 0.0943162739276886
step: 900, loss: 0.07254910469055176
step: 910, loss: 0.13307639956474304
step: 920, loss: 0.06691863387823105
step: 930, loss: 0.07454067468643188
step: 940, loss: 0.07454249262809753
step: 950, loss: 0.018777301535010338
step: 960, loss: 0.15505625307559967
step: 970, loss: 0.039771925657987595
epoch 6: dev_f1=0.939282428702852, f1=0.9322892676186089, best_f1=0.941447671738128
step: 0, loss: 0.0439259298145771
step: 10, loss: 0.04786301404237747
step: 20, loss: 0.018026262521743774
step: 30, loss: 0.1268443763256073
step: 40, loss: 0.07447504997253418
step: 50, loss: 0.09628374874591827
step: 60, loss: 0.02252611517906189
step: 70, loss: 0.07521979510784149
step: 80, loss: 0.0510464645922184
step: 90, loss: 0.021640092134475708
step: 100, loss: 0.09369312971830368
step: 110, loss: 0.07154911011457443
step: 120, loss: 0.08582612872123718
step: 130, loss: 0.042142558842897415
step: 140, loss: 0.1402139514684677
step: 150, loss: 0.02133024111390114
step: 160, loss: 0.04351454973220825
step: 170, loss: 0.09353321045637131
step: 180, loss: 0.055577270686626434
step: 190, loss: 0.024656008929014206
step: 200, loss: 0.011508559808135033
step: 210, loss: 0.08300767838954926
step: 220, loss: 0.0764969140291214
step: 230, loss: 0.041802093386650085
step: 240, loss: 0.023572847247123718
step: 250, loss: 0.06718090176582336
step: 260, loss: 0.07548198103904724
step: 270, loss: 0.06592222303152084
step: 280, loss: 0.053458478301763535
step: 290, loss: 0.08436226844787598
step: 300, loss: 0.035595785826444626
step: 310, loss: 0.1346728354692459
step: 320, loss: 0.08232912421226501
step: 330, loss: 0.039623234421014786
step: 340, loss: 0.010409240610897541
step: 350, loss: 0.02509326860308647
step: 360, loss: 0.1073741763830185
step: 370, loss: 0.061776433140039444
step: 380, loss: 0.022115061059594154
step: 390, loss: 0.1878972053527832
step: 400, loss: 0.037786029279232025
step: 410, loss: 0.0817321389913559
step: 420, loss: 0.06947722285985947
step: 430, loss: 0.08799120783805847
step: 440, loss: 0.028231868520379066
step: 450, loss: 0.03581096604466438
step: 460, loss: 0.030088169500231743
step: 470, loss: 0.06898492574691772
step: 480, loss: 0.012872418388724327
step: 490, loss: 0.03807412460446358
step: 500, loss: 0.003411104902625084
step: 510, loss: 0.04676858335733414
step: 520, loss: 0.017734521999955177
step: 530, loss: 0.024132393300533295
step: 540, loss: 0.010422084480524063
step: 550, loss: 0.017628388479351997
step: 560, loss: 0.10073968768119812
step: 570, loss: 0.021747535094618797
step: 580, loss: 0.0615537166595459
step: 590, loss: 0.09006179124116898
step: 600, loss: 0.03277254104614258
step: 610, loss: 0.05304248631000519
step: 620, loss: 0.040621332824230194
step: 630, loss: 0.0315292663872242
step: 640, loss: 0.021633397787809372
step: 650, loss: 0.010339425876736641
step: 660, loss: 0.041965339332818985
step: 670, loss: 0.05582444369792938
step: 680, loss: 0.06307748705148697
step: 690, loss: 0.10742048174142838
step: 700, loss: 0.046082768589258194
step: 710, loss: 0.05241209641098976
step: 720, loss: 0.0647938996553421
step: 730, loss: 0.02289579063653946
step: 740, loss: 0.06009676307439804
step: 750, loss: 0.09997385740280151
step: 760, loss: 0.006923051550984383
step: 770, loss: 0.05128147080540657
step: 780, loss: 0.0733906626701355
step: 790, loss: 0.034317344427108765
step: 800, loss: 0.21012520790100098
step: 810, loss: 0.032355811446905136
step: 820, loss: 0.02576690912246704
step: 830, loss: 0.027676237747073174
step: 840, loss: 0.103326715528965
step: 850, loss: 0.04603888839483261
step: 860, loss: 0.24810059368610382
step: 870, loss: 0.0739808902144432
step: 880, loss: 0.10427226126194
step: 890, loss: 0.04425735026597977
step: 900, loss: 0.061507999897003174
step: 910, loss: 0.05341716483235359
step: 920, loss: 0.10241558402776718
step: 930, loss: 0.09799068421125412
step: 940, loss: 0.07625465840101242
step: 950, loss: 0.0984179899096489
step: 960, loss: 0.11068541556596756
step: 970, loss: 0.12850356101989746
epoch 7: dev_f1=0.9330188679245284, f1=0.9370300751879698, best_f1=0.941447671738128
step: 0, loss: 0.023554697632789612
step: 10, loss: 0.0023242300376296043
step: 20, loss: 0.008753197267651558
step: 30, loss: 0.005238926503807306
step: 40, loss: 0.030438963323831558
step: 50, loss: 0.002598321996629238
step: 60, loss: 0.1820901334285736
step: 70, loss: 0.0004888135590590537
step: 80, loss: 0.02732718735933304
step: 90, loss: 0.016078034415841103
step: 100, loss: 0.08084885776042938
step: 110, loss: 0.011541960760951042
step: 120, loss: 0.015283079817891121
step: 130, loss: 0.030460018664598465
step: 140, loss: 0.1571750044822693
step: 150, loss: 0.012815111316740513
step: 160, loss: 0.07875346392393112
step: 170, loss: 0.0706135556101799
step: 180, loss: 0.08847473561763763
step: 190, loss: 0.02962316945195198
step: 200, loss: 0.025924181565642357
step: 210, loss: 0.07720749825239182
step: 220, loss: 0.05149777606129646
step: 230, loss: 0.002396827796474099
step: 240, loss: 0.12067006528377533
step: 250, loss: 0.11682761460542679
step: 260, loss: 0.026177894324064255
step: 270, loss: 0.059021420776844025
step: 280, loss: 0.03708070516586304
step: 290, loss: 0.07703378051519394
step: 300, loss: 0.13408274948596954
step: 310, loss: 0.022880326956510544
step: 320, loss: 0.057603202760219574
step: 330, loss: 0.09006959944963455
step: 340, loss: 0.011564481072127819
step: 350, loss: 0.06202401965856552
step: 360, loss: 0.07378880679607391
step: 370, loss: 0.004594162106513977
step: 380, loss: 0.05095326527953148
step: 390, loss: 0.03173920884728432
step: 400, loss: 0.09433639794588089
step: 410, loss: 0.2280074805021286
step: 420, loss: 0.10336106270551682
step: 430, loss: 0.02850044146180153
step: 440, loss: 0.09645821154117584
step: 450, loss: 0.018430493772029877
step: 460, loss: 0.1210937574505806
step: 470, loss: 0.05044214800000191
step: 480, loss: 0.09595081955194473
step: 490, loss: 0.03769529610872269
step: 500, loss: 0.021656818687915802
step: 510, loss: 0.007887577638030052
step: 520, loss: 0.012541262432932854
step: 530, loss: 0.08418712019920349
step: 540, loss: 0.11407283693552017
step: 550, loss: 0.013798465952277184
step: 560, loss: 0.1946103870868683
step: 570, loss: 0.051811471581459045
step: 580, loss: 0.15796369314193726
step: 590, loss: 0.16409316658973694
step: 600, loss: 0.18217338621616364
step: 610, loss: 0.07412605732679367
step: 620, loss: 0.012747060507535934
step: 630, loss: 0.06018299236893654
step: 640, loss: 0.011225232854485512
step: 650, loss: 0.08996081352233887
step: 660, loss: 0.009497598744928837
step: 670, loss: 0.03408687561750412
step: 680, loss: 0.13209030032157898
step: 690, loss: 0.007391851395368576
step: 700, loss: 0.07379954308271408
step: 710, loss: 0.09734746813774109
step: 720, loss: 0.06032717972993851
step: 730, loss: 0.033079907298088074
step: 740, loss: 0.04261208698153496
step: 750, loss: 0.07579387724399567
step: 760, loss: 0.01545809768140316
step: 770, loss: 0.007865633815526962
step: 780, loss: 0.16169531643390656
step: 790, loss: 0.009230034425854683
step: 800, loss: 0.05345918610692024
step: 810, loss: 0.03974318876862526
step: 820, loss: 0.028614841401576996
step: 830, loss: 0.014333980157971382
step: 840, loss: 0.02370336279273033
step: 850, loss: 0.07153671979904175
step: 860, loss: 0.058070603758096695
step: 870, loss: 0.03277212381362915
step: 880, loss: 0.006255466490983963
step: 890, loss: 0.12320563942193985
step: 900, loss: 0.16625505685806274
step: 910, loss: 0.10525257140398026
step: 920, loss: 0.018046043813228607
step: 930, loss: 0.038802534341812134
step: 940, loss: 0.02234150655567646
step: 950, loss: 0.1689186543226242
step: 960, loss: 0.04256753996014595
step: 970, loss: 0.049034006893634796
epoch 8: dev_f1=0.931985294117647, f1=0.9343735658558971, best_f1=0.941447671738128
step: 0, loss: 0.06880345195531845
step: 10, loss: 0.03814666345715523
step: 20, loss: 0.004495631903409958
step: 30, loss: 0.126948744058609
step: 40, loss: 0.1440776288509369
step: 50, loss: 0.015770550817251205
step: 60, loss: 0.06345155835151672
step: 70, loss: 0.003982434514909983
step: 80, loss: 0.04311547055840492
step: 90, loss: 0.02064451575279236
step: 100, loss: 0.01160078402608633
step: 110, loss: 4.393942799651995e-05
step: 120, loss: 0.07065118849277496
step: 130, loss: 0.12493091076612473
step: 140, loss: 0.10746340453624725
step: 150, loss: 0.007762650027871132
step: 160, loss: 0.025482507422566414
step: 170, loss: 0.07786918431520462
step: 180, loss: 0.06625892221927643
step: 190, loss: 0.09155072271823883
step: 200, loss: 0.03898431360721588
step: 210, loss: 0.01840587705373764
step: 220, loss: 0.060614462941884995
step: 230, loss: 0.02483573742210865
step: 240, loss: 0.01567230001091957
step: 250, loss: 0.017685245722532272
step: 260, loss: 0.07668372243642807
step: 270, loss: 0.18349957466125488
step: 280, loss: 0.01418415829539299
step: 290, loss: 0.03347771242260933
step: 300, loss: 0.012336917221546173
step: 310, loss: 0.12074332684278488
step: 320, loss: 0.01643296144902706
step: 330, loss: 0.010164071805775166
step: 340, loss: 0.13050146400928497
step: 350, loss: 0.1791880577802658
step: 360, loss: 0.017798352986574173
step: 370, loss: 0.06521297246217728
step: 380, loss: 0.06994868069887161
step: 390, loss: 0.029656173661351204
step: 400, loss: 0.22542060911655426
step: 410, loss: 0.03923375532031059
step: 420, loss: 0.03782815486192703
step: 430, loss: 0.04049083963036537
step: 440, loss: 0.05777779221534729
step: 450, loss: 0.004844930022954941
step: 460, loss: 0.010613522492349148
step: 470, loss: 0.0485498383641243
step: 480, loss: 0.11840586364269257
step: 490, loss: 0.10266830027103424
step: 500, loss: 0.09056257456541061
step: 510, loss: 0.1756511628627777
step: 520, loss: 0.05555226653814316
step: 530, loss: 0.10039497911930084
step: 540, loss: 0.07972120493650436
step: 550, loss: 0.035200025886297226
step: 560, loss: 0.03157312050461769
step: 570, loss: 0.040789246559143066
step: 580, loss: 0.11315062642097473
step: 590, loss: 0.028508823364973068
step: 600, loss: 0.04967402666807175
step: 610, loss: 0.026987548917531967
step: 620, loss: 0.13294371962547302
step: 630, loss: 0.03148612007498741
step: 640, loss: 0.04937247559428215
step: 650, loss: 0.040737785398960114
step: 660, loss: 0.07822059094905853
step: 670, loss: 0.01512923277914524
step: 680, loss: 0.00961941760033369
step: 690, loss: 0.03267131373286247
step: 700, loss: 0.03688519075512886
step: 710, loss: 0.02023414522409439
step: 720, loss: 0.0005075909430161119
step: 730, loss: 0.024675127118825912
step: 740, loss: 0.024562980979681015
step: 750, loss: 0.016945257782936096
step: 760, loss: 0.08095203340053558
step: 770, loss: 0.029415059834718704
step: 780, loss: 0.008260302245616913
step: 790, loss: 0.03804316371679306
step: 800, loss: 0.0648348480463028
step: 810, loss: 0.12057296186685562
step: 820, loss: 0.0515911728143692
step: 830, loss: 0.0400891974568367
step: 840, loss: 0.09804341197013855
step: 850, loss: 0.058072034269571304
step: 860, loss: 0.09915894269943237
step: 870, loss: 0.03563259169459343
step: 880, loss: 0.16196653246879578
step: 890, loss: 0.04736197739839554
step: 900, loss: 0.02577328495681286
step: 910, loss: 0.07406265288591385
step: 920, loss: 0.006339040119200945
step: 930, loss: 0.024012692272663116
step: 940, loss: 0.10999900847673416
step: 950, loss: 0.05270707234740257
step: 960, loss: 0.10245611518621445
step: 970, loss: 0.04061475768685341
epoch 9: dev_f1=0.9348519362186788, f1=0.9310816978548607, best_f1=0.941447671738128
step: 0, loss: 0.11775948852300644
step: 10, loss: 0.059625040739774704
step: 20, loss: 0.023694243282079697
step: 30, loss: 0.025229522958397865
step: 40, loss: 0.016681719571352005
step: 50, loss: 0.014278310351073742
step: 60, loss: 0.008264085277915001
step: 70, loss: 0.05180658400058746
step: 80, loss: 0.012337150983512402
step: 90, loss: 0.019243312999606133
step: 100, loss: 0.005112816579639912
step: 110, loss: 0.06682590395212173
step: 120, loss: 0.03820442780852318
step: 130, loss: 0.021588392555713654
step: 140, loss: 0.005203215405344963
step: 150, loss: 0.11756286025047302
step: 160, loss: 0.0236787311732769
step: 170, loss: 0.05953840911388397
step: 180, loss: 0.007306553423404694
step: 190, loss: 0.08883335441350937
step: 200, loss: 0.009011920541524887
step: 210, loss: 0.013032974675297737
step: 220, loss: 0.0027867506723850965
step: 230, loss: 0.028357865288853645
step: 240, loss: 0.07282067835330963
step: 250, loss: 0.0762428566813469
step: 260, loss: 0.009153319522738457
step: 270, loss: 0.01328699104487896
step: 280, loss: 0.06843534857034683
step: 290, loss: 0.1637977957725525
step: 300, loss: 0.042339615523815155
step: 310, loss: 0.07527877390384674
step: 320, loss: 0.005232243798673153
step: 330, loss: 0.02772378921508789
step: 340, loss: 0.07540269196033478
step: 350, loss: 0.01599203236401081
step: 360, loss: 0.010550996288657188
step: 370, loss: 0.002400257159024477
step: 380, loss: 0.11802462488412857
step: 390, loss: 0.05337105318903923
step: 400, loss: 0.013145029544830322
step: 410, loss: 0.12533174455165863
step: 420, loss: 0.09552423655986786
step: 430, loss: 0.031482476741075516
step: 440, loss: 0.016156554222106934
step: 450, loss: 0.04769163578748703
step: 460, loss: 0.062214307487010956
step: 470, loss: 0.10506709665060043
step: 480, loss: 0.048336517065763474
step: 490, loss: 0.06034166365861893
step: 500, loss: 0.0166655033826828
step: 510, loss: 0.037101052701473236
step: 520, loss: 0.01619833894073963
step: 530, loss: 0.04190314561128616
step: 540, loss: 0.008905788883566856
step: 550, loss: 0.023001087829470634
step: 560, loss: 0.0955878272652626
step: 570, loss: 0.12608163058757782
step: 580, loss: 0.07435697317123413
step: 590, loss: 0.017393650487065315
step: 600, loss: 0.03204147517681122
step: 610, loss: 0.11470504850149155
step: 620, loss: 0.02606908604502678
step: 630, loss: 0.06920943409204483
step: 640, loss: 0.012862791307270527
step: 650, loss: 0.04053490608930588
step: 660, loss: 0.026804856956005096
step: 670, loss: 0.10192704200744629
step: 680, loss: 0.03133966028690338
step: 690, loss: 0.0912715345621109
step: 700, loss: 0.10997860878705978
step: 710, loss: 0.05551854893565178
step: 720, loss: 0.04598015919327736
step: 730, loss: 0.03721566125750542
step: 740, loss: 0.011830050498247147
step: 750, loss: 0.018694093450903893
step: 760, loss: 0.034167397767305374
step: 770, loss: 0.08272605389356613
step: 780, loss: 0.14466065168380737
step: 790, loss: 0.04839814454317093
step: 800, loss: 0.06652866303920746
step: 810, loss: 0.04332626238465309
step: 820, loss: 0.1427108347415924
step: 830, loss: 0.010789739899337292
step: 840, loss: 0.06888865679502487
step: 850, loss: 0.043774425983428955
step: 860, loss: 0.031158752739429474
step: 870, loss: 0.08820324391126633
step: 880, loss: 0.10198469460010529
step: 890, loss: 0.03088909015059471
step: 900, loss: 0.052432335913181305
step: 910, loss: 0.021074499934911728
step: 920, loss: 0.06303390115499496
step: 930, loss: 0.0648743137717247
step: 940, loss: 0.0697437971830368
step: 950, loss: 0.19479946792125702
step: 960, loss: 0.08241135627031326
step: 970, loss: 0.05027208477258682
epoch 10: dev_f1=0.9327188940092166, f1=0.9313815187557181, best_f1=0.941447671738128
step: 0, loss: 0.05923778936266899
step: 10, loss: 0.01837119273841381
step: 20, loss: 0.0012625032104551792
step: 30, loss: 0.0174407958984375
step: 40, loss: 0.03601101040840149
step: 50, loss: 0.004420706536620855
step: 60, loss: 0.10577244311571121
step: 70, loss: 0.01611153595149517
step: 80, loss: 0.06033695116639137
step: 90, loss: 0.08601516485214233
step: 100, loss: 0.07929946482181549
step: 110, loss: 0.0407295823097229
step: 120, loss: 0.06603559851646423
step: 130, loss: 0.04023848846554756
step: 140, loss: 0.012508983723819256
step: 150, loss: 0.01900814101099968
step: 160, loss: 0.026916466653347015
step: 170, loss: 0.013372061774134636
step: 180, loss: 0.11036430299282074
step: 190, loss: 0.026252374053001404
step: 200, loss: 0.002729289699345827
step: 210, loss: 0.026791319251060486
step: 220, loss: 0.11900591850280762
step: 230, loss: 0.0724973976612091
step: 240, loss: 0.012230207212269306
step: 250, loss: 0.01695554330945015
step: 260, loss: 0.04228653013706207
step: 270, loss: 0.015077494084835052
step: 280, loss: 0.06949800997972488
step: 290, loss: 0.006900548469275236
step: 300, loss: 0.03867378830909729
step: 310, loss: 0.02575560286641121
step: 320, loss: 0.017674695700407028
step: 330, loss: 0.01641962304711342
step: 340, loss: 0.017380669713020325
step: 350, loss: 0.021494964137673378
step: 360, loss: 1.8856970200431533e-05
step: 370, loss: 0.040018849074840546
step: 380, loss: 0.03475554287433624
step: 390, loss: 0.0806240439414978
step: 400, loss: 3.5566721635404974e-05
step: 410, loss: 0.03141926974058151
step: 420, loss: 0.03271446377038956
step: 430, loss: 0.035421524196863174
step: 440, loss: 0.10467009991407394
step: 450, loss: 0.04954567179083824
step: 460, loss: 6.369283801177517e-05
step: 470, loss: 0.09406904131174088
step: 480, loss: 0.03742264583706856
step: 490, loss: 0.057911962270736694
step: 500, loss: 0.06421976536512375
step: 510, loss: 0.024989649653434753
step: 520, loss: 0.1083231195807457
step: 530, loss: 0.047366913408041
step: 540, loss: 0.01603403501212597
step: 550, loss: 0.10270962119102478
step: 560, loss: 0.1111215129494667
step: 570, loss: 0.0715053528547287
step: 580, loss: 0.03706353157758713
step: 590, loss: 0.10059713572263718
step: 600, loss: 0.05023724213242531
step: 610, loss: 0.033628467470407486
step: 620, loss: 0.11825348436832428
step: 630, loss: 0.06938768178224564
step: 640, loss: 0.06998919695615768
step: 650, loss: 0.02772452123463154
step: 660, loss: 0.1343006193637848
step: 670, loss: 0.017545556649565697
step: 680, loss: 0.012992209754884243
step: 690, loss: 0.09106181561946869
step: 700, loss: 0.03988561034202576
step: 710, loss: 0.1901164948940277
step: 720, loss: 0.02185205928981304
step: 730, loss: 0.05123661458492279
step: 740, loss: 0.015263021923601627
step: 750, loss: 0.053721409291028976
step: 760, loss: 0.048348382115364075
step: 770, loss: 0.013101307675242424
step: 780, loss: 0.0024576541036367416
step: 790, loss: 0.06766455620527267
step: 800, loss: 0.018019402399659157
step: 810, loss: 0.012638687156140804
step: 820, loss: 0.020638633519411087
step: 830, loss: 0.012718618847429752
step: 840, loss: 0.03875318542122841
step: 850, loss: 0.009802189655601978
step: 860, loss: 0.05413154885172844
step: 870, loss: 0.0393461249768734
step: 880, loss: 0.07885313779115677
step: 890, loss: 0.014294708147644997
step: 900, loss: 0.042153649032115936
step: 910, loss: 0.016280755400657654
step: 920, loss: 0.013732291758060455
step: 930, loss: 0.09571371227502823
step: 940, loss: 0.00037780957063660026
step: 950, loss: 0.11207489669322968
step: 960, loss: 0.0594625398516655
step: 970, loss: 0.020195698365569115
epoch 11: dev_f1=0.9280074314909429, f1=0.9350529709811147, best_f1=0.941447671738128
step: 0, loss: 0.018644914031028748
step: 10, loss: 0.025008266791701317
step: 20, loss: 0.007127268705517054
step: 30, loss: 0.022652022540569305
step: 40, loss: 0.06895466148853302
step: 50, loss: 0.008061463013291359
step: 60, loss: 0.003437315346673131
step: 70, loss: 0.004377175122499466
step: 80, loss: 0.13284091651439667
step: 90, loss: 0.004861392080783844
step: 100, loss: 0.009739398024976254
step: 110, loss: 0.0826355442404747
step: 120, loss: 0.0015974496491253376
step: 130, loss: 0.0342378132045269
step: 140, loss: 0.007992452010512352
step: 150, loss: 0.009648329578340054
step: 160, loss: 0.00844242237508297
step: 170, loss: 0.05571161210536957
step: 180, loss: 0.01794334687292576
step: 190, loss: 0.06528161466121674
step: 200, loss: 0.1243201494216919
step: 210, loss: 0.010093417949974537
step: 220, loss: 0.041229814291000366
step: 230, loss: 0.04250248521566391
step: 240, loss: 0.0015266838017851114
step: 250, loss: 0.030131934210658073
step: 260, loss: 0.11624123901128769
step: 270, loss: 0.06427937746047974
step: 280, loss: 0.09677116572856903
step: 290, loss: 0.0419907420873642
step: 300, loss: 0.10802564769983292
step: 310, loss: 0.08970058709383011
step: 320, loss: 0.07446832954883575
step: 330, loss: 0.019774194806814194
step: 340, loss: 0.005851715337485075
step: 350, loss: 0.01760716736316681
step: 360, loss: 0.11569295078516006
step: 370, loss: 0.00891913939267397
step: 380, loss: 0.017956720665097237
step: 390, loss: 0.05385743826627731
step: 400, loss: 0.042507339268922806
step: 410, loss: 0.035956740379333496
step: 420, loss: 0.012778911739587784
step: 430, loss: 0.02694731391966343
step: 440, loss: 0.0017495108768343925
step: 450, loss: 0.03469150885939598
step: 460, loss: 0.011021428741514683
step: 470, loss: 0.04511915147304535
step: 480, loss: 0.03895523399114609
step: 490, loss: 0.07364249974489212
step: 500, loss: 0.034727901220321655
step: 510, loss: 0.055945612490177155
step: 520, loss: 0.019492430612444878
step: 530, loss: 0.049107640981674194
step: 540, loss: 0.0044987984001636505
step: 550, loss: 0.0017062323167920113
step: 560, loss: 0.03989608585834503
step: 570, loss: 0.06854013353586197
step: 580, loss: 0.013820791617035866
step: 590, loss: 0.004311801865696907
step: 600, loss: 0.029492678120732307
step: 610, loss: 0.024505089968442917
step: 620, loss: 0.031553737819194794
step: 630, loss: 0.0043127769604325294
step: 640, loss: 0.175938680768013
step: 650, loss: 0.15867067873477936
step: 660, loss: 0.020500415936112404
step: 670, loss: 0.02259628288447857
step: 680, loss: 0.029143383726477623
step: 690, loss: 0.010871262289583683
step: 700, loss: 0.003227332839742303
step: 710, loss: 0.049134958535432816
step: 720, loss: 0.024622967466711998
step: 730, loss: 2.5784893296076916e-05
step: 740, loss: 0.06904706358909607
step: 750, loss: 0.09685416519641876
step: 760, loss: 0.06592120230197906
step: 770, loss: 0.02885213866829872
step: 780, loss: 0.047154173254966736
step: 790, loss: 0.028032615780830383
step: 800, loss: 0.018599988892674446
step: 810, loss: 0.11011971533298492
step: 820, loss: 0.008189858868718147
step: 830, loss: 0.015128369443118572
step: 840, loss: 0.09337168186903
step: 850, loss: 0.0436890572309494
step: 860, loss: 0.0502956323325634
step: 870, loss: 0.009173034690320492
step: 880, loss: 0.04639747738838196
step: 890, loss: 0.09149457514286041
step: 900, loss: 0.09776945412158966
step: 910, loss: 0.09186141937971115
step: 920, loss: 0.015028197318315506
step: 930, loss: 0.03254631161689758
step: 940, loss: 0.07327939569950104
step: 950, loss: 0.0446232371032238
step: 960, loss: 0.004454992711544037
step: 970, loss: 0.004646294750273228
epoch 12: dev_f1=0.9332719742291763, f1=0.92925604746691, best_f1=0.941447671738128
step: 0, loss: 0.02461637370288372
step: 10, loss: 0.01652519963681698
step: 20, loss: 0.03344538435339928
step: 30, loss: 0.056587621569633484
step: 40, loss: 0.0023445244878530502
step: 50, loss: 0.01993487775325775
step: 60, loss: 0.0017102652927860618
step: 70, loss: 0.026410963386297226
step: 80, loss: 0.006192712113261223
step: 90, loss: 0.011170173063874245
step: 100, loss: 0.019143059849739075
step: 110, loss: 0.004105046857148409
step: 120, loss: 0.07142412662506104
step: 130, loss: 0.015394030138850212
step: 140, loss: 0.02099408581852913
step: 150, loss: 0.0008459147647954524
step: 160, loss: 0.001214417745359242
step: 170, loss: 0.0006306044524535537
step: 180, loss: 0.10983743518590927
step: 190, loss: 0.009992157109081745
step: 200, loss: 0.07294668257236481
step: 210, loss: 0.0013359959702938795
step: 220, loss: 0.09672985225915909
step: 230, loss: 0.0006249322323128581
step: 240, loss: 0.0010241726413369179
step: 250, loss: 0.048069361597299576
step: 260, loss: 0.01232488825917244
step: 270, loss: 0.0005392628372646868
step: 280, loss: 0.0222626980394125
step: 290, loss: 0.13703636825084686
step: 300, loss: 0.021188883110880852
step: 310, loss: 0.11636332422494888
step: 320, loss: 0.053275253623723984
step: 330, loss: 0.0476827546954155
step: 340, loss: 0.006581875495612621
step: 350, loss: 0.05525001510977745
step: 360, loss: 0.06386972963809967
step: 370, loss: 0.08065738528966904
step: 380, loss: 0.05645071715116501
step: 390, loss: 0.0029826476238667965
step: 400, loss: 0.03759269788861275
step: 410, loss: 0.007033711764961481
step: 420, loss: 0.00038408252294175327
step: 430, loss: 0.10778296738862991
step: 440, loss: 0.032170552760362625
step: 450, loss: 0.02895028330385685
step: 460, loss: 0.006935245357453823
step: 470, loss: 0.04655617102980614
step: 480, loss: 0.01809360645711422
step: 490, loss: 0.007020420860499144
step: 500, loss: 0.07199250161647797
step: 510, loss: 0.056198444217443466
step: 520, loss: 0.010081014595925808
step: 530, loss: 0.005475313402712345
step: 540, loss: 0.07591942697763443
step: 550, loss: 0.002568815601989627
step: 560, loss: 0.03694906830787659
step: 570, loss: 0.07703369110822678
step: 580, loss: 0.034556951373815536
step: 590, loss: 0.03646702319383621
step: 600, loss: 0.11502015590667725
step: 610, loss: 0.0036807239521294832
step: 620, loss: 0.09561290591955185
step: 630, loss: 0.022377310320734978
step: 640, loss: 0.00013600873353425413
step: 650, loss: 0.034462086856365204
step: 660, loss: 0.018671991303563118
step: 670, loss: 0.03430303931236267
step: 680, loss: 0.04681472107768059
step: 690, loss: 0.022357895970344543
step: 700, loss: 0.05796688422560692
step: 710, loss: 0.1397545337677002
step: 720, loss: 0.1505943089723587
step: 730, loss: 0.04841122776269913
step: 740, loss: 0.06411591917276382
step: 750, loss: 0.044389914721250534
step: 760, loss: 0.0539284311234951
step: 770, loss: 0.019922200590372086
step: 780, loss: 0.009303811006247997
step: 790, loss: 0.05863802134990692
step: 800, loss: 0.02212519571185112
step: 810, loss: 0.013758953660726547
step: 820, loss: 0.002962876809760928
step: 830, loss: 0.0651320144534111
step: 840, loss: 0.09560051560401917
step: 850, loss: 0.018950335681438446
step: 860, loss: 0.05065196380019188
step: 870, loss: 0.002932004164904356
step: 880, loss: 0.024136129766702652
step: 890, loss: 0.02779090218245983
step: 900, loss: 0.017822105437517166
step: 910, loss: 0.07650623470544815
step: 920, loss: 0.08841997385025024
step: 930, loss: 0.0029455339536070824
step: 940, loss: 0.020492393523454666
step: 950, loss: 0.024357104673981667
step: 960, loss: 0.03165610134601593
step: 970, loss: 0.033137913793325424
epoch 13: dev_f1=0.9314045730284647, f1=0.9271461716937355, best_f1=0.941447671738128
step: 0, loss: 0.022456428036093712
step: 10, loss: 0.005074519198387861
step: 20, loss: 0.0004018558538518846
step: 30, loss: 0.052708931267261505
step: 40, loss: 0.0009763954440131783
step: 50, loss: 0.14939256012439728
step: 60, loss: 0.03971976414322853
step: 70, loss: 0.10765108466148376
step: 80, loss: 0.04043570160865784
step: 90, loss: 0.0849875807762146
step: 100, loss: 0.04255613684654236
step: 110, loss: 0.0245241429656744
step: 120, loss: 0.020784270018339157
step: 130, loss: 0.08546274900436401
step: 140, loss: 0.050760261714458466
step: 150, loss: 0.044421061873435974
step: 160, loss: 0.02548353187739849
step: 170, loss: 0.01989217847585678
step: 180, loss: 0.014786278828978539
step: 190, loss: 0.014009413309395313
step: 200, loss: 0.017126990482211113
step: 210, loss: 0.05000241473317146
step: 220, loss: 0.0883273184299469
step: 230, loss: 0.002457104390487075
step: 240, loss: 0.07312099635601044
step: 250, loss: 0.11378446221351624
step: 260, loss: 0.08643936365842819
step: 270, loss: 0.05449520796537399
step: 280, loss: 0.07395251840353012
step: 290, loss: 0.03681106120347977
step: 300, loss: 0.028750184923410416
step: 310, loss: 0.11057785153388977
step: 320, loss: 0.03697595000267029
step: 330, loss: 0.11417610198259354
step: 340, loss: 0.00010424365609651431
step: 350, loss: 0.005282592494040728
step: 360, loss: 0.03974176198244095
step: 370, loss: 0.08006419241428375
step: 380, loss: 0.00643586553633213
step: 390, loss: 0.0846543237566948
step: 400, loss: 0.00010452300921315327
step: 410, loss: 0.0005983005394227803
step: 420, loss: 0.03255739063024521
step: 430, loss: 0.021363530308008194
step: 440, loss: 0.000627442670520395
step: 450, loss: 0.05484023690223694
step: 460, loss: 0.003983357455581427
step: 470, loss: 0.0646655485033989
step: 480, loss: 0.020487884059548378
step: 490, loss: 0.0036288853734731674
step: 500, loss: 0.014806077815592289
step: 510, loss: 0.02496029995381832
step: 520, loss: 0.05961010605096817
step: 530, loss: 0.009299208410084248
step: 540, loss: 0.07000186294317245
step: 550, loss: 0.003322544042021036
step: 560, loss: 0.14089332520961761
step: 570, loss: 0.001691398792900145
step: 580, loss: 0.0033126799389719963
step: 590, loss: 0.017016062512993813
step: 600, loss: 0.015513315796852112
step: 610, loss: 0.014540839940309525
step: 620, loss: 0.04596473649144173
step: 630, loss: 0.020434916019439697
step: 640, loss: 0.015116412192583084
step: 650, loss: 0.038415029644966125
step: 660, loss: 0.01653546653687954
step: 670, loss: 0.06506768614053726
step: 680, loss: 0.03762859106063843
step: 690, loss: 0.09671912342309952
step: 700, loss: 0.01863684505224228
step: 710, loss: 0.028979580849409103
step: 720, loss: 0.025307942181825638
step: 730, loss: 0.0009554718853905797
step: 740, loss: 0.06761765480041504
step: 750, loss: 0.03862481936812401
step: 760, loss: 0.1350107192993164
step: 770, loss: 0.09299888461828232
step: 780, loss: 0.03974181041121483
step: 790, loss: 0.01977304182946682
step: 800, loss: 0.0660419911146164
step: 810, loss: 0.0082356883212924
step: 820, loss: 0.012815129943192005
step: 830, loss: 0.016119372099637985
step: 840, loss: 0.001566382241435349
step: 850, loss: 0.0025753977242857218
step: 860, loss: 0.02871658094227314
step: 870, loss: 0.025253593921661377
step: 880, loss: 0.02943061850965023
step: 890, loss: 0.00010404617205495015
step: 900, loss: 0.024880068376660347
step: 910, loss: 0.016088683158159256
step: 920, loss: 0.05731898173689842
step: 930, loss: 0.030260350555181503
step: 940, loss: 0.019175289198756218
step: 950, loss: 0.047873999923467636
step: 960, loss: 0.038459960371255875
step: 970, loss: 0.0811820849776268
epoch 14: dev_f1=0.9345099860659545, f1=0.9307479224376731, best_f1=0.941447671738128
step: 0, loss: 0.0022742769215255976
step: 10, loss: 0.1086352989077568
step: 20, loss: 0.1386759728193283
step: 30, loss: 0.060156360268592834
step: 40, loss: 0.060192253440618515
step: 50, loss: 0.06152765825390816
step: 60, loss: 0.039800725877285004
step: 70, loss: 0.008976887911558151
step: 80, loss: 0.10043534636497498
step: 90, loss: 0.010540556162595749
step: 100, loss: 0.09872658550739288
step: 110, loss: 0.00018003657169174403
step: 120, loss: 6.472100358223543e-05
step: 130, loss: 0.0002548263582866639
step: 140, loss: 7.597742660436779e-05
step: 150, loss: 0.03001750074326992
step: 160, loss: 0.04373399168252945
step: 170, loss: 0.03646811097860336
step: 180, loss: 0.02153746224939823
step: 190, loss: 0.02227877825498581
step: 200, loss: 0.03249978646636009
step: 210, loss: 0.0012386069865897298
step: 220, loss: 0.012205349281430244
step: 230, loss: 0.01490852516144514
step: 240, loss: 0.14273139834403992
step: 250, loss: 0.0003271528403274715
step: 260, loss: 0.0005921294214203954
step: 270, loss: 0.0037301285192370415
step: 280, loss: 0.0014244311023503542
step: 290, loss: 0.06569328904151917
step: 300, loss: 0.037662308663129807
step: 310, loss: 0.026173897087574005
step: 320, loss: 0.05000939220190048
step: 330, loss: 0.073875293135643
step: 340, loss: 0.021945953369140625
step: 350, loss: 0.08838710933923721
step: 360, loss: 0.004970890935510397
step: 370, loss: 0.01098571252077818
step: 380, loss: 0.02889610081911087
step: 390, loss: 1.0531286534387618e-05
step: 400, loss: 0.0006521822651848197
step: 410, loss: 0.03439347445964813
step: 420, loss: 0.04235551133751869
step: 430, loss: 0.056252505630254745
step: 440, loss: 0.0003334403154440224
step: 450, loss: 0.03238128125667572
step: 460, loss: 0.025477930903434753
step: 470, loss: 0.012032004073262215
step: 480, loss: 0.0012680247891694307
step: 490, loss: 0.019212109968066216
step: 500, loss: 0.022979263216257095
step: 510, loss: 0.04215636104345322
step: 520, loss: 0.04224339872598648
step: 530, loss: 0.014214223250746727
step: 540, loss: 0.037246108055114746
step: 550, loss: 0.003018961986526847
step: 560, loss: 0.0019390450324863195
step: 570, loss: 0.030776096507906914
step: 580, loss: 0.0021683028899133205
step: 590, loss: 0.080379918217659
step: 600, loss: 0.03693293780088425
step: 610, loss: 0.00042417418444529176
step: 620, loss: 0.01838036999106407
step: 630, loss: 0.011452317237854004
step: 640, loss: 0.0011758276959881186
step: 650, loss: 0.05122200399637222
step: 660, loss: 0.032904237508773804
step: 670, loss: 0.04794896021485329
step: 680, loss: 0.05139145627617836
step: 690, loss: 0.04728975519537926
step: 700, loss: 0.08151865005493164
step: 710, loss: 0.06251266598701477
step: 720, loss: 0.009888610802590847
step: 730, loss: 0.02613411471247673
step: 740, loss: 0.08557009696960449
step: 750, loss: 0.013732307590544224
step: 760, loss: 0.0020742136985063553
step: 770, loss: 0.018333619460463524
step: 780, loss: 0.07846657931804657
step: 790, loss: 0.020333070307970047
step: 800, loss: 0.05344627425074577
step: 810, loss: 0.05717584490776062
step: 820, loss: 0.020037686452269554
step: 830, loss: 0.023029087111353874
step: 840, loss: 0.13851454854011536
step: 850, loss: 0.03396747261285782
step: 860, loss: 0.019332246854901314
step: 870, loss: 0.03958708420395851
step: 880, loss: 0.004131050314754248
step: 890, loss: 0.08131223917007446
step: 900, loss: 0.0015094352420419455
step: 910, loss: 0.07931403070688248
step: 920, loss: 0.023050876334309578
step: 930, loss: 0.0030369283631443977
step: 940, loss: 0.0035634851083159447
step: 950, loss: 0.019032282754778862
step: 960, loss: 0.020913666114211082
step: 970, loss: 0.038859885185956955
epoch 15: dev_f1=0.9298578199052132, f1=0.9259783121169259, best_f1=0.941447671738128
step: 0, loss: 0.05662811920046806
step: 10, loss: 0.08035578578710556
step: 20, loss: 0.07811043411493301
step: 30, loss: 0.003381699789315462
step: 40, loss: 0.03770478814840317
step: 50, loss: 0.026920758187770844
step: 60, loss: 0.023040052503347397
step: 70, loss: 0.029943276196718216
step: 80, loss: 0.0008483562851324677
step: 90, loss: 0.01684979349374771
step: 100, loss: 0.025055205449461937
step: 110, loss: 0.04205048456788063
step: 120, loss: 0.040521420538425446
step: 130, loss: 0.09353365749120712
step: 140, loss: 0.002028627321124077
step: 150, loss: 0.04072560369968414
step: 160, loss: 0.03898373618721962
step: 170, loss: 0.0014289323007687926
step: 180, loss: 0.0006629187264479697
step: 190, loss: 0.00020933391351718456
step: 200, loss: 0.018674220889806747
step: 210, loss: 0.050440993160009384
step: 220, loss: 0.0428597591817379
step: 230, loss: 0.0005042899865657091
step: 240, loss: 0.0002762651420198381
step: 250, loss: 0.004179768729954958
step: 260, loss: 0.05903707072138786
step: 270, loss: 0.051997110247612
step: 280, loss: 0.0188158992677927
step: 290, loss: 0.0008190501248463988
step: 300, loss: 0.02681301347911358
step: 310, loss: 0.0015213910955935717
step: 320, loss: 0.055337753146886826
step: 330, loss: 0.03161506727337837
step: 340, loss: 0.0349254347383976
step: 350, loss: 0.007160107139497995
step: 360, loss: 0.06409291177988052
step: 370, loss: 0.0001752558018779382
step: 380, loss: 0.0002666899235919118
step: 390, loss: 0.03569711372256279
step: 400, loss: 0.016761846840381622
step: 410, loss: 0.05568115413188934
step: 420, loss: 9.281908569391817e-05
step: 430, loss: 0.023498479276895523
step: 440, loss: 0.04440739005804062
step: 450, loss: 0.0314403660595417
step: 460, loss: 0.046382829546928406
step: 470, loss: 0.020762039348483086
step: 480, loss: 0.0016504310769960284
step: 490, loss: 0.000874015036970377
step: 500, loss: 0.09414763748645782
step: 510, loss: 3.542247577570379e-05
step: 520, loss: 0.09210094064474106
step: 530, loss: 0.030506720766425133
step: 540, loss: 0.04441080987453461
step: 550, loss: 0.06005822494626045
step: 560, loss: 0.06514234840869904
step: 570, loss: 0.018794875591993332
step: 580, loss: 0.009102636016905308
step: 590, loss: 0.038799136877059937
step: 600, loss: 0.04231119155883789
step: 610, loss: 0.013009046204388142
step: 620, loss: 0.006498124450445175
step: 630, loss: 0.059719331562519073
step: 640, loss: 0.007658917456865311
step: 650, loss: 0.03786531835794449
step: 660, loss: 0.06464631855487823
step: 670, loss: 6.612481956835836e-05
step: 680, loss: 0.05455808714032173
step: 690, loss: 0.07019740343093872
step: 700, loss: 0.06677655875682831
step: 710, loss: 0.021894322708249092
step: 720, loss: 0.02710603177547455
step: 730, loss: 0.02661266177892685
step: 740, loss: 0.02889809012413025
step: 750, loss: 0.04344614967703819
step: 760, loss: 0.00023689403315074742
step: 770, loss: 0.004222889430820942
step: 780, loss: 0.1339680552482605
step: 790, loss: 0.01571088656783104
step: 800, loss: 0.010531313717365265
step: 810, loss: 0.020751439034938812
step: 820, loss: 0.027715535834431648
step: 830, loss: 0.029631437733769417
step: 840, loss: 0.0021538815926760435
step: 850, loss: 0.04736991226673126
step: 860, loss: 2.7060697902925313e-05
step: 870, loss: 0.03138013184070587
step: 880, loss: 7.923384691821411e-05
step: 890, loss: 0.003885946935042739
step: 900, loss: 0.08007392287254333
step: 910, loss: 0.0001863261713879183
step: 920, loss: 0.02537851221859455
step: 930, loss: 0.1162947341799736
step: 940, loss: 0.042976949363946915
step: 950, loss: 0.005777466576546431
step: 960, loss: 0.07085053622722626
step: 970, loss: 0.08103317767381668
epoch 16: dev_f1=0.9327146171693736, f1=0.9303184125519152, best_f1=0.941447671738128
step: 0, loss: 0.03292860463261604
step: 10, loss: 0.0002060097031062469
step: 20, loss: 0.008375442586839199
step: 30, loss: 0.04501817747950554
step: 40, loss: 0.0010792551329359412
step: 50, loss: 0.026155920699238777
step: 60, loss: 0.0014552880311384797
step: 70, loss: 0.04792115092277527
step: 80, loss: 0.004124063067138195
step: 90, loss: 0.02006717585027218
step: 100, loss: 0.021816976368427277
step: 110, loss: 0.08415406197309494
step: 120, loss: 0.019550971686840057
step: 130, loss: 0.007226162124425173
step: 140, loss: 0.0006134987925179303
step: 150, loss: 0.02586970664560795
step: 160, loss: 0.00010837573063327
step: 170, loss: 0.01046091690659523
step: 180, loss: 0.01512989867478609
step: 190, loss: 0.0011755417799577117
step: 200, loss: 0.04988492652773857
step: 210, loss: 0.004365701228380203
step: 220, loss: 0.055524829775094986
step: 230, loss: 0.011299573816359043
step: 240, loss: 0.06770357489585876
step: 250, loss: 0.05050608515739441
step: 260, loss: 0.02933773584663868
step: 270, loss: 0.0017565257148817182
step: 280, loss: 0.10354633629322052
step: 290, loss: 0.022757112979888916
step: 300, loss: 0.02793160267174244
step: 310, loss: 0.026314731687307358
step: 320, loss: 0.042333561927080154
step: 330, loss: 0.01869042217731476
step: 340, loss: 0.03046000748872757
step: 350, loss: 0.01305162999778986
step: 360, loss: 0.021570280194282532
step: 370, loss: 0.005751879420131445
step: 380, loss: 0.05214676260948181
step: 390, loss: 0.035292986780405045
step: 400, loss: 0.02500820904970169
step: 410, loss: 0.026911823078989983
step: 420, loss: 0.020628800615668297
step: 430, loss: 0.0005768913542851806
step: 440, loss: 0.012124093249440193
step: 450, loss: 0.00026575278025120497
step: 460, loss: 0.00023324975336436182
step: 470, loss: 0.0308129470795393
step: 480, loss: 0.04816416651010513
step: 490, loss: 0.017344212159514427
step: 500, loss: 0.10607073456048965
step: 510, loss: 0.00013981288066133857
step: 520, loss: 0.03045620210468769
step: 530, loss: 0.05951673537492752
step: 540, loss: 0.05653553083539009
step: 550, loss: 8.926693408284336e-05
step: 560, loss: 0.06177406758069992
step: 570, loss: 0.001469506649300456
step: 580, loss: 0.020125417038798332
step: 590, loss: 0.003721190383657813
step: 600, loss: 0.07184542715549469
step: 610, loss: 0.016154220327734947
step: 620, loss: 0.0018624529475346208
step: 630, loss: 0.00040482328040525317
step: 640, loss: 0.06242433935403824
step: 650, loss: 0.03276178240776062
step: 660, loss: 0.21211422979831696
step: 670, loss: 0.040203798562288284
step: 680, loss: 0.040871310979127884
step: 690, loss: 0.01702328398823738
step: 700, loss: 0.036965981125831604
step: 710, loss: 0.09052775055170059
step: 720, loss: 0.073462575674057
step: 730, loss: 0.03433436155319214
step: 740, loss: 0.00610721530392766
step: 750, loss: 0.031085239723324776
step: 760, loss: 0.005112336948513985
step: 770, loss: 0.11182084679603577
step: 780, loss: 0.008903227746486664
step: 790, loss: 0.028128355741500854
step: 800, loss: 0.02674087882041931
step: 810, loss: 0.003053989028558135
step: 820, loss: 0.02252456545829773
step: 830, loss: 0.00022079472546465695
step: 840, loss: 0.0015061134472489357
step: 850, loss: 0.04423266276717186
step: 860, loss: 0.03914554789662361
step: 870, loss: 0.01680018939077854
step: 880, loss: 6.248310819501057e-05
step: 890, loss: 0.037693798542022705
step: 900, loss: 0.0017831249861046672
step: 910, loss: 0.002054344629868865
step: 920, loss: 0.021422002464532852
step: 930, loss: 0.030239902436733246
step: 940, loss: 0.03524085134267807
step: 950, loss: 0.019450897350907326
step: 960, loss: 0.011792609468102455
step: 970, loss: 0.07036545127630234
epoch 17: dev_f1=0.9298653042266605, f1=0.92619926199262, best_f1=0.941447671738128
step: 0, loss: 0.0005909219034947455
step: 10, loss: 0.0012037100968882442
step: 20, loss: 0.0270244013518095
step: 30, loss: 0.01926811784505844
step: 40, loss: 0.048057153820991516
step: 50, loss: 0.024208461865782738
step: 60, loss: 0.025150161236524582
step: 70, loss: 0.0003139225591439754
step: 80, loss: 0.03147391974925995
step: 90, loss: 0.11701484769582748
step: 100, loss: 0.0005879146046936512
step: 110, loss: 0.03478311002254486
step: 120, loss: 0.03603864461183548
step: 130, loss: 1.418149986420758e-05
step: 140, loss: 0.020186740905046463
step: 150, loss: 0.07996891438961029
step: 160, loss: 0.031484782695770264
step: 170, loss: 0.020412610843777657
step: 180, loss: 0.05302194878458977
step: 190, loss: 0.0006397109827958047
step: 200, loss: 8.032588084461167e-05
step: 210, loss: 0.027883056551218033
step: 220, loss: 0.0006956005236133933
step: 230, loss: 6.657029007328674e-05
step: 240, loss: 0.06178046762943268
step: 250, loss: 0.04407092183828354
step: 260, loss: 0.002889723051339388
step: 270, loss: 0.004934840369969606
step: 280, loss: 0.053629230707883835
step: 290, loss: 0.0294168870896101
step: 300, loss: 0.00048733007861301303
step: 310, loss: 0.0002766601392067969
step: 320, loss: 0.0009335100185126066
step: 330, loss: 0.03952891007065773
step: 340, loss: 0.04472579434514046
step: 350, loss: 8.886351133696735e-05
step: 360, loss: 0.20864877104759216
step: 370, loss: 0.02030341327190399
step: 380, loss: 0.0038821958005428314
step: 390, loss: 0.00038711028173565865
step: 400, loss: 0.020689263939857483
step: 410, loss: 0.0466589629650116
step: 420, loss: 0.022214483469724655
step: 430, loss: 0.03080061450600624
step: 440, loss: 0.014009973965585232
step: 450, loss: 0.045483484864234924
step: 460, loss: 0.03531354293227196
step: 470, loss: 0.06487896293401718
step: 480, loss: 0.00019428282394073904
step: 490, loss: 0.0509968176484108
step: 500, loss: 0.008012169040739536
step: 510, loss: 0.0006707749562337995
step: 520, loss: 0.0571594312787056
step: 530, loss: 0.0006013953243382275
step: 540, loss: 0.06361386179924011
step: 550, loss: 5.416387284640223e-05
step: 560, loss: 0.022423304617404938
step: 570, loss: 0.0414036363363266
step: 580, loss: 0.016397396102547646
step: 590, loss: 0.05131632089614868
step: 600, loss: 0.03719984367489815
step: 610, loss: 0.03195624053478241
step: 620, loss: 0.047349877655506134
step: 630, loss: 5.660685201291926e-05
step: 640, loss: 0.005388329736888409
step: 650, loss: 0.053064506500959396
step: 660, loss: 0.02563476376235485
step: 670, loss: 0.0006205880199559033
step: 680, loss: 0.018252456560730934
step: 690, loss: 0.0016519649652764201
step: 700, loss: 0.019863804802298546
step: 710, loss: 0.08699925243854523
step: 720, loss: 0.03894554078578949
step: 730, loss: 0.032609473913908005
step: 740, loss: 0.00035098771331831813
step: 750, loss: 0.03388895094394684
step: 760, loss: 0.060977205634117126
step: 770, loss: 0.0006793349166400731
step: 780, loss: 0.0001700747525319457
step: 790, loss: 0.017663657665252686
step: 800, loss: 0.029501447454094887
step: 810, loss: 0.00025576032930985093
step: 820, loss: 0.00022116285981610417
step: 830, loss: 0.029225440695881844
step: 840, loss: 0.017742838710546494
step: 850, loss: 0.033405911177396774
step: 860, loss: 0.06838250905275345
step: 870, loss: 0.038856327533721924
step: 880, loss: 0.040870070457458496
step: 890, loss: 0.04294469207525253
step: 900, loss: 0.03074037656188011
step: 910, loss: 0.03497724235057831
step: 920, loss: 0.00012932853132952005
step: 930, loss: 0.05640042573213577
step: 940, loss: 0.05681426078081131
step: 950, loss: 0.03092796355485916
step: 960, loss: 6.522855983348563e-05
step: 970, loss: 0.0005288660759106278
epoch 18: dev_f1=0.9303826648224988, f1=0.928212162780064, best_f1=0.941447671738128
step: 0, loss: 0.03212229907512665
step: 10, loss: 0.028210299089550972
step: 20, loss: 0.0005275059957057238
step: 30, loss: 0.001203310675919056
step: 40, loss: 0.029844461008906364
step: 50, loss: 0.02599521167576313
step: 60, loss: 0.057025257498025894
step: 70, loss: 0.03597637265920639
step: 80, loss: 0.05532262101769447
step: 90, loss: 0.00033346773125231266
step: 100, loss: 0.09336002171039581
step: 110, loss: 0.031095363199710846
step: 120, loss: 7.704666495556012e-05
step: 130, loss: 0.029594561085104942
step: 140, loss: 0.07683160901069641
step: 150, loss: 0.02999684028327465
step: 160, loss: 3.5911943996325135e-05
step: 170, loss: 0.03432977572083473
step: 180, loss: 0.00010371502139605582
step: 190, loss: 0.053251173347234726
step: 200, loss: 0.04846484586596489
step: 210, loss: 0.11775660514831543
step: 220, loss: 0.07428578287363052
step: 230, loss: 0.02069048024713993
step: 240, loss: 0.02303837612271309
step: 250, loss: 8.562745642848313e-05
step: 260, loss: 0.04845008999109268
step: 270, loss: 0.031591128557920456
step: 280, loss: 0.0001370366517221555
step: 290, loss: 0.023359350860118866
step: 300, loss: 0.08410666882991791
step: 310, loss: 0.04012090712785721
step: 320, loss: 0.01641734503209591
step: 330, loss: 0.00011277540761511773
step: 340, loss: 2.1015146558056585e-05
step: 350, loss: 0.052885059267282486
step: 360, loss: 0.07526465505361557
step: 370, loss: 0.0469602569937706
step: 380, loss: 0.04164854437112808
step: 390, loss: 0.022462844848632812
step: 400, loss: 0.08088435232639313
step: 410, loss: 0.00012991696712560952
step: 420, loss: 0.01998397521674633
step: 430, loss: 0.021345574408769608
step: 440, loss: 0.0006712202448397875
step: 450, loss: 0.007641833275556564
step: 460, loss: 7.729933713562787e-06
step: 470, loss: 0.026712803170084953
step: 480, loss: 0.010625029914081097
step: 490, loss: 0.06849943101406097
step: 500, loss: 0.051551226526498795
step: 510, loss: 0.026913732290267944
step: 520, loss: 0.023843178525567055
step: 530, loss: 0.0026628265623003244
step: 540, loss: 7.675746746826917e-05
step: 550, loss: 0.0001092957318178378
step: 560, loss: 0.023377161473035812
step: 570, loss: 0.026624256744980812
step: 580, loss: 0.08847679197788239
step: 590, loss: 0.0068608555011451244
step: 600, loss: 0.03337110951542854
step: 610, loss: 0.04260505363345146
step: 620, loss: 0.018232950940728188
step: 630, loss: 0.05372389033436775
step: 640, loss: 0.062425751239061356
step: 650, loss: 0.0014720539329573512
step: 660, loss: 4.888683542958461e-05
step: 670, loss: 0.020285947248339653
step: 680, loss: 0.025296738371253014
step: 690, loss: 0.02300686202943325
step: 700, loss: 0.05660685896873474
step: 710, loss: 0.06735070794820786
step: 720, loss: 0.027959298342466354
step: 730, loss: 0.018338656052947044
step: 740, loss: 0.014531978406012058
step: 750, loss: 0.014157772995531559
step: 760, loss: 0.00019753791275434196
step: 770, loss: 0.06944762915372849
step: 780, loss: 0.014400303363800049
step: 790, loss: 0.0792580395936966
step: 800, loss: 0.01148217637091875
step: 810, loss: 0.01447407715022564
step: 820, loss: 0.017794575542211533
step: 830, loss: 0.02354048378765583
step: 840, loss: 0.022800367325544357
step: 850, loss: 0.023603377863764763
step: 860, loss: 0.018489323556423187
step: 870, loss: 5.329952546162531e-05
step: 880, loss: 0.02435511164367199
step: 890, loss: 0.05026041716337204
step: 900, loss: 0.026304839178919792
step: 910, loss: 0.02351030521094799
step: 920, loss: 0.001157135353423655
step: 930, loss: 0.033253345638513565
step: 940, loss: 0.03610553592443466
step: 950, loss: 0.017840711399912834
step: 960, loss: 0.00014832409215159714
step: 970, loss: 0.07018294930458069
epoch 19: dev_f1=0.9309534992954438, f1=0.9242990654205607, best_f1=0.941447671738128
step: 0, loss: 0.013395392335951328
step: 10, loss: 0.039547838270664215
step: 20, loss: 0.022497234866023064
step: 30, loss: 0.1531638205051422
step: 40, loss: 0.014458032324910164
step: 50, loss: 9.62089907261543e-05
step: 60, loss: 4.4377629819791764e-05
step: 70, loss: 0.06768795102834702
step: 80, loss: 0.04056553170084953
step: 90, loss: 0.002243494614958763
step: 100, loss: 0.04522380977869034
step: 110, loss: 0.03926694020628929
step: 120, loss: 0.08725828677415848
step: 130, loss: 0.045613400638103485
step: 140, loss: 0.02523578517138958
step: 150, loss: 9.91411434370093e-05
step: 160, loss: 0.00014101190026849508
step: 170, loss: 0.00019436300499364734
step: 180, loss: 0.01621146686375141
step: 190, loss: 0.00015950984379742295
step: 200, loss: 0.02848210372030735
step: 210, loss: 0.05867670476436615
step: 220, loss: 0.06858666986227036
step: 230, loss: 0.05111038312315941
step: 240, loss: 0.004112815484404564
step: 250, loss: 0.022037846967577934
step: 260, loss: 6.069308437872678e-05
step: 270, loss: 9.238629718311131e-05
step: 280, loss: 0.01612979546189308
step: 290, loss: 0.023213323205709457
step: 300, loss: 0.023606987670063972
step: 310, loss: 3.459855361143127e-05
step: 320, loss: 0.03830600902438164
step: 330, loss: 0.037423618137836456
step: 340, loss: 0.004175183363258839
step: 350, loss: 0.053214043378829956
step: 360, loss: 0.06179298087954521
step: 370, loss: 0.07945549488067627
step: 380, loss: 0.01357308216392994
step: 390, loss: 0.040690720081329346
step: 400, loss: 0.03466915711760521
step: 410, loss: 0.06067844480276108
step: 420, loss: 0.04163379222154617
step: 430, loss: 0.07025052607059479
step: 440, loss: 0.052610740065574646
step: 450, loss: 0.040883131325244904
step: 460, loss: 0.015091017819941044
step: 470, loss: 0.055779874324798584
step: 480, loss: 0.019618723541498184
step: 490, loss: 0.04082838073372841
step: 500, loss: 0.028380801901221275
step: 510, loss: 0.008897063322365284
step: 520, loss: 0.07570689171552658
step: 530, loss: 3.048206963285338e-05
step: 540, loss: 0.013709909282624722
step: 550, loss: 8.227389480452985e-05
step: 560, loss: 0.00015587161760777235
step: 570, loss: 0.038600485771894455
step: 580, loss: 0.04127853363752365
step: 590, loss: 0.0005132544902153313
step: 600, loss: 0.03306545689702034
step: 610, loss: 0.05842064321041107
step: 620, loss: 0.047856420278549194
step: 630, loss: 0.04582595452666283
step: 640, loss: 2.555476203269791e-05
step: 650, loss: 0.05839001014828682
step: 660, loss: 0.00021166031365282834
step: 670, loss: 0.08337407559156418
step: 680, loss: 0.05704762786626816
step: 690, loss: 0.017474927008152008
step: 700, loss: 0.050234489142894745
step: 710, loss: 0.00012695345503743738
step: 720, loss: 4.9331196350976825e-05
step: 730, loss: 3.4895438147941604e-05
step: 740, loss: 0.11293354630470276
step: 750, loss: 0.018346793949604034
step: 760, loss: 0.0018577966839075089
step: 770, loss: 0.0003144551010336727
step: 780, loss: 0.015598861500620842
step: 790, loss: 0.09082624316215515
step: 800, loss: 0.019646186381578445
step: 810, loss: 0.00021991475659888238
step: 820, loss: 0.021355515345931053
step: 830, loss: 0.03897467255592346
step: 840, loss: 0.014243122190237045
step: 850, loss: 0.09088695049285889
step: 860, loss: 0.06502432376146317
step: 870, loss: 0.01993456669151783
step: 880, loss: 0.00010668143659131601
step: 890, loss: 0.01998008042573929
step: 900, loss: 3.794455551542342e-05
step: 910, loss: 0.011349127627909184
step: 920, loss: 0.0013474557781592011
step: 930, loss: 0.06677970290184021
step: 940, loss: 0.08265640586614609
step: 950, loss: 0.00011240428284509107
step: 960, loss: 0.04236164689064026
step: 970, loss: 0.0328902043402195
epoch 20: dev_f1=0.9301675977653632, f1=0.9303826648224988, best_f1=0.941447671738128
