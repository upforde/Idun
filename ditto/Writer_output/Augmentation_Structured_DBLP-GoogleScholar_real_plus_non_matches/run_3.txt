cuda
Device: cuda
step: 0, loss: 0.8027209043502808
step: 10, loss: 0.41365307569503784
step: 20, loss: 0.5803213715553284
step: 30, loss: 0.574497401714325
step: 40, loss: 0.32900044322013855
step: 50, loss: 0.3404126465320587
step: 60, loss: 0.23780834674835205
step: 70, loss: 0.25898781418800354
step: 80, loss: 0.09980710595846176
step: 90, loss: 0.3399524688720703
step: 100, loss: 0.2699007987976074
step: 110, loss: 0.10018426179885864
step: 120, loss: 0.14557138085365295
step: 130, loss: 0.0938825011253357
step: 140, loss: 0.16399893164634705
step: 150, loss: 0.20324644446372986
step: 160, loss: 0.11917602270841599
step: 170, loss: 0.15211181342601776
step: 180, loss: 0.08795809000730515
step: 190, loss: 0.08289358764886856
step: 200, loss: 0.08776365965604782
step: 210, loss: 0.08232981711626053
step: 220, loss: 0.12187834829092026
step: 230, loss: 0.06484730541706085
step: 240, loss: 0.21383367478847504
step: 250, loss: 0.3186626136302948
step: 260, loss: 0.18727460503578186
step: 270, loss: 0.3159029185771942
step: 280, loss: 0.13647527992725372
step: 290, loss: 0.14241454005241394
step: 300, loss: 0.18706652522087097
step: 310, loss: 0.1331714689731598
step: 320, loss: 0.24869506061077118
step: 330, loss: 0.13198719918727875
step: 340, loss: 0.1165439561009407
step: 350, loss: 0.18759842216968536
step: 360, loss: 0.1092851310968399
step: 370, loss: 0.15269224345684052
step: 380, loss: 0.052509743720293045
step: 390, loss: 0.04586304724216461
step: 400, loss: 0.10976070910692215
step: 410, loss: 0.11404076963663101
step: 420, loss: 0.018947381526231766
step: 430, loss: 0.07992963492870331
step: 440, loss: 0.1912456601858139
step: 450, loss: 0.13929146528244019
step: 460, loss: 0.18909266591072083
step: 470, loss: 0.11816393584012985
step: 480, loss: 0.08199327439069748
step: 490, loss: 0.0812147930264473
step: 500, loss: 0.08971954882144928
step: 510, loss: 0.027053382247686386
step: 520, loss: 0.11409076303243637
step: 530, loss: 0.05492249131202698
step: 540, loss: 0.20358359813690186
step: 550, loss: 0.052854571491479874
step: 560, loss: 0.15178944170475006
step: 570, loss: 0.10795388370752335
step: 580, loss: 0.1263960599899292
step: 590, loss: 0.10104119777679443
step: 600, loss: 0.08309709280729294
step: 610, loss: 0.17019161581993103
step: 620, loss: 0.06867806613445282
step: 630, loss: 0.03575634956359863
step: 640, loss: 0.1295597106218338
step: 650, loss: 0.0749342292547226
step: 660, loss: 0.058685172349214554
step: 670, loss: 0.20604321360588074
step: 680, loss: 0.22023043036460876
step: 690, loss: 0.028899675235152245
step: 700, loss: 0.29943281412124634
step: 710, loss: 0.17719100415706635
step: 720, loss: 0.09865899384021759
step: 730, loss: 0.05598323419690132
step: 740, loss: 0.08199205994606018
step: 750, loss: 0.10707193613052368
step: 760, loss: 0.17106176912784576
step: 770, loss: 0.09671256691217422
step: 780, loss: 0.15713536739349365
step: 790, loss: 0.07570376992225647
step: 800, loss: 0.06702280789613724
step: 810, loss: 0.07096774131059647
step: 820, loss: 0.13278724253177643
step: 830, loss: 0.19289982318878174
step: 840, loss: 0.08951492607593536
step: 850, loss: 0.08008041232824326
step: 860, loss: 0.13046634197235107
step: 870, loss: 0.11307340860366821
step: 880, loss: 0.06957294046878815
step: 890, loss: 0.06706108897924423
step: 900, loss: 0.14821653068065643
step: 910, loss: 0.07773306965827942
step: 920, loss: 0.1182355061173439
step: 930, loss: 0.08320362120866776
step: 940, loss: 0.13720159232616425
step: 950, loss: 0.03951198235154152
step: 960, loss: 0.20238439738750458
step: 970, loss: 0.10151065140962601
epoch 1: dev_f1=0.9192720485300979, f1=0.9232192414431082, best_f1=0.9232192414431082
step: 0, loss: 0.10105627030134201
step: 10, loss: 0.1680438071489334
step: 20, loss: 0.08607934415340424
step: 30, loss: 0.14606565237045288
step: 40, loss: 0.041361115872859955
step: 50, loss: 0.08475448191165924
step: 60, loss: 0.15150707960128784
step: 70, loss: 0.1633647382259369
step: 80, loss: 0.16569045186042786
step: 90, loss: 0.1870545744895935
step: 100, loss: 0.0940006822347641
step: 110, loss: 0.16800189018249512
step: 120, loss: 0.12188704311847687
step: 130, loss: 0.12893237173557281
step: 140, loss: 0.03388760983943939
step: 150, loss: 0.11906963586807251
step: 160, loss: 0.13121233880519867
step: 170, loss: 0.07585582137107849
step: 180, loss: 0.07846830040216446
step: 190, loss: 0.017131753265857697
step: 200, loss: 0.11276309937238693
step: 210, loss: 0.0662156343460083
step: 220, loss: 0.08668780326843262
step: 230, loss: 0.023376010358333588
step: 240, loss: 0.12704649567604065
step: 250, loss: 0.12813550233840942
step: 260, loss: 0.0947132408618927
step: 270, loss: 0.017104540020227432
step: 280, loss: 0.2645593285560608
step: 290, loss: 0.1403438299894333
step: 300, loss: 0.06489163637161255
step: 310, loss: 0.13104774057865143
step: 320, loss: 0.06440824270248413
step: 330, loss: 0.11885242164134979
step: 340, loss: 0.17464713752269745
step: 350, loss: 0.0345660075545311
step: 360, loss: 0.056881748139858246
step: 370, loss: 0.11812486499547958
step: 380, loss: 0.021883470937609673
step: 390, loss: 0.10693387687206268
step: 400, loss: 0.2314111590385437
step: 410, loss: 0.1504168063402176
step: 420, loss: 0.03448472172021866
step: 430, loss: 0.08321194350719452
step: 440, loss: 0.026268940418958664
step: 450, loss: 0.20991939306259155
step: 460, loss: 0.08681434392929077
step: 470, loss: 0.1112050861120224
step: 480, loss: 0.03891788423061371
step: 490, loss: 0.06730399280786514
step: 500, loss: 0.10864941030740738
step: 510, loss: 0.15066929161548615
step: 520, loss: 0.04886964336037636
step: 530, loss: 0.04320133849978447
step: 540, loss: 0.10047926008701324
step: 550, loss: 0.20285619795322418
step: 560, loss: 0.027135970070958138
step: 570, loss: 0.04554060846567154
step: 580, loss: 0.15205118060112
step: 590, loss: 0.11710276454687119
step: 600, loss: 0.14003966748714447
step: 610, loss: 0.10566291958093643
step: 620, loss: 0.028018847107887268
step: 630, loss: 0.05136634781956673
step: 640, loss: 0.14242389798164368
step: 650, loss: 0.005520346108824015
step: 660, loss: 0.1448829174041748
step: 670, loss: 0.12135468423366547
step: 680, loss: 0.10697321593761444
step: 690, loss: 0.07977534830570221
step: 700, loss: 0.09626958519220352
step: 710, loss: 0.03782753646373749
step: 720, loss: 0.1311616450548172
step: 730, loss: 0.18844644725322723
step: 740, loss: 0.08919952809810638
step: 750, loss: 0.23425684869289398
step: 760, loss: 0.2008187621831894
step: 770, loss: 0.06907389312982559
step: 780, loss: 0.06030825152993202
step: 790, loss: 0.03623625636100769
step: 800, loss: 0.10892529040575027
step: 810, loss: 0.1324557512998581
step: 820, loss: 0.017333660274744034
step: 830, loss: 0.125827819108963
step: 840, loss: 0.09571432322263718
step: 850, loss: 0.028786862269043922
step: 860, loss: 0.1100098192691803
step: 870, loss: 0.232449010014534
step: 880, loss: 0.13267835974693298
step: 890, loss: 0.07643190026283264
step: 900, loss: 0.25876930356025696
step: 910, loss: 0.030755380168557167
step: 920, loss: 0.0715799406170845
step: 930, loss: 0.022082041949033737
step: 940, loss: 0.07806865125894547
step: 950, loss: 0.15967221558094025
step: 960, loss: 0.13555407524108887
step: 970, loss: 0.090269535779953
epoch 2: dev_f1=0.9200367647058824, f1=0.9197278911564626, best_f1=0.9197278911564626
step: 0, loss: 0.05229639634490013
step: 10, loss: 0.009528503753244877
step: 20, loss: 0.05901559069752693
step: 30, loss: 0.03394169360399246
step: 40, loss: 0.0812598392367363
step: 50, loss: 0.041483279317617416
step: 60, loss: 0.1038302555680275
step: 70, loss: 0.030891740694642067
step: 80, loss: 0.035009730607271194
step: 90, loss: 0.007881838828325272
step: 100, loss: 0.06317570060491562
step: 110, loss: 0.06530722230672836
step: 120, loss: 0.0072278715670108795
step: 130, loss: 0.04328296706080437
step: 140, loss: 0.09711149334907532
step: 150, loss: 0.1075020283460617
step: 160, loss: 0.07650122046470642
step: 170, loss: 0.03440067917108536
step: 180, loss: 0.07364486157894135
step: 190, loss: 0.07567396759986877
step: 200, loss: 0.13015201687812805
step: 210, loss: 0.0806804671883583
step: 220, loss: 0.10668716579675674
step: 230, loss: 0.0307461004704237
step: 240, loss: 0.07906177639961243
step: 250, loss: 0.16121143102645874
step: 260, loss: 0.034018371254205704
step: 270, loss: 0.06748992949724197
step: 280, loss: 0.06513672322034836
step: 290, loss: 0.17750799655914307
step: 300, loss: 0.05215790495276451
step: 310, loss: 0.009399577975273132
step: 320, loss: 0.1135966032743454
step: 330, loss: 0.04443400725722313
step: 340, loss: 0.06706338375806808
step: 350, loss: 0.09561484307050705
step: 360, loss: 0.14747163653373718
step: 370, loss: 0.015594986267387867
step: 380, loss: 0.021843288093805313
step: 390, loss: 0.12695837020874023
step: 400, loss: 0.09798486530780792
step: 410, loss: 0.01953938789665699
step: 420, loss: 0.22715678811073303
step: 430, loss: 0.12544648349285126
step: 440, loss: 0.11300448328256607
step: 450, loss: 0.18033218383789062
step: 460, loss: 0.09124342352151871
step: 470, loss: 0.029663903638720512
step: 480, loss: 0.18832431733608246
step: 490, loss: 0.026987727731466293
step: 500, loss: 0.03702649846673012
step: 510, loss: 0.005540315993130207
step: 520, loss: 0.08844348788261414
step: 530, loss: 0.1203211098909378
step: 540, loss: 0.028290601447224617
step: 550, loss: 0.06503534317016602
step: 560, loss: 0.07670146226882935
step: 570, loss: 0.1297227293252945
step: 580, loss: 0.0601859875023365
step: 590, loss: 0.015926342457532883
step: 600, loss: 0.10989896953105927
step: 610, loss: 0.014828932471573353
step: 620, loss: 0.0678248181939125
step: 630, loss: 0.09633076190948486
step: 640, loss: 0.010318928398191929
step: 650, loss: 0.054588720202445984
step: 660, loss: 0.055382099002599716
step: 670, loss: 0.1031171903014183
step: 680, loss: 0.0271889790892601
step: 690, loss: 0.07948750257492065
step: 700, loss: 0.006386808585375547
step: 710, loss: 0.019005395472049713
step: 720, loss: 0.02913442812860012
step: 730, loss: 0.0330556221306324
step: 740, loss: 0.0653027817606926
step: 750, loss: 0.12197688221931458
step: 760, loss: 0.11965150386095047
step: 770, loss: 0.07475946843624115
step: 780, loss: 0.08111123740673065
step: 790, loss: 0.06428074091672897
step: 800, loss: 0.09468034654855728
step: 810, loss: 0.21090318262577057
step: 820, loss: 0.057950783520936966
step: 830, loss: 0.052750542759895325
step: 840, loss: 0.07192946970462799
step: 850, loss: 0.07561275362968445
step: 860, loss: 0.07549555599689484
step: 870, loss: 0.10330280661582947
step: 880, loss: 0.02006569504737854
step: 890, loss: 0.20750631392002106
step: 900, loss: 0.08840800076723099
step: 910, loss: 0.14647778868675232
step: 920, loss: 0.07679231464862823
step: 930, loss: 0.15496093034744263
step: 940, loss: 0.04571224004030228
step: 950, loss: 0.07511527836322784
step: 960, loss: 0.1182774156332016
step: 970, loss: 0.05549443140625954
epoch 3: dev_f1=0.9297347603536529, f1=0.9282739472466451, best_f1=0.9282739472466451
step: 0, loss: 0.03844662010669708
step: 10, loss: 0.151582270860672
step: 20, loss: 0.019486278295516968
step: 30, loss: 0.11344953626394272
step: 40, loss: 0.12898972630500793
step: 50, loss: 0.031104544177651405
step: 60, loss: 0.16597223281860352
step: 70, loss: 0.02656511217355728
step: 80, loss: 0.040165841579437256
step: 90, loss: 0.07400781661272049
step: 100, loss: 0.12622970342636108
step: 110, loss: 0.006524680182337761
step: 120, loss: 0.049329739063978195
step: 130, loss: 0.050961121916770935
step: 140, loss: 0.036986518651247025
step: 150, loss: 0.03209463879466057
step: 160, loss: 0.019061680883169174
step: 170, loss: 0.0822586789727211
step: 180, loss: 0.11397439241409302
step: 190, loss: 0.030161449685692787
step: 200, loss: 0.07969101518392563
step: 210, loss: 0.013667294755578041
step: 220, loss: 0.10860702395439148
step: 230, loss: 0.02046835422515869
step: 240, loss: 0.10258395224809647
step: 250, loss: 0.025256425142288208
step: 260, loss: 0.14019396901130676
step: 270, loss: 0.06999852508306503
step: 280, loss: 0.1312868446111679
step: 290, loss: 0.05544572323560715
step: 300, loss: 0.16985876858234406
step: 310, loss: 0.15568341314792633
step: 320, loss: 0.026622215285897255
step: 330, loss: 0.053614500910043716
step: 340, loss: 0.00597760546952486
step: 350, loss: 0.04748549684882164
step: 360, loss: 0.006840624380856752
step: 370, loss: 0.2557752728462219
step: 380, loss: 0.04304449260234833
step: 390, loss: 0.03392758220434189
step: 400, loss: 0.08431598544120789
step: 410, loss: 0.024274917319417
step: 420, loss: 0.07163513451814651
step: 430, loss: 0.04605400934815407
step: 440, loss: 0.025535225868225098
step: 450, loss: 0.04226328432559967
step: 460, loss: 0.15859107673168182
step: 470, loss: 0.027398133650422096
step: 480, loss: 0.014023590832948685
step: 490, loss: 0.22088125348091125
step: 500, loss: 0.21094992756843567
step: 510, loss: 0.052351586520671844
step: 520, loss: 0.05486270412802696
step: 530, loss: 0.23257872462272644
step: 540, loss: 0.0699041560292244
step: 550, loss: 0.015665462240576744
step: 560, loss: 0.14688640832901
step: 570, loss: 0.01874368265271187
step: 580, loss: 0.22668419778347015
step: 590, loss: 0.11473063379526138
step: 600, loss: 0.12950019538402557
step: 610, loss: 0.022337080910801888
step: 620, loss: 0.060967668890953064
step: 630, loss: 0.08912345767021179
step: 640, loss: 0.04772943630814552
step: 650, loss: 0.07256563752889633
step: 660, loss: 0.02500075101852417
step: 670, loss: 0.04191818833351135
step: 680, loss: 0.035635579377412796
step: 690, loss: 0.01473517157137394
step: 700, loss: 0.040641069412231445
step: 710, loss: 0.1377689242362976
step: 720, loss: 0.10386369377374649
step: 730, loss: 0.1535414606332779
step: 740, loss: 0.18045485019683838
step: 750, loss: 0.10396566987037659
step: 760, loss: 0.02704617939889431
step: 770, loss: 0.07314939051866531
step: 780, loss: 0.1014794260263443
step: 790, loss: 0.08050155639648438
step: 800, loss: 0.030590122565627098
step: 810, loss: 0.08779303729534149
step: 820, loss: 0.08635099977254868
step: 830, loss: 0.060376331210136414
step: 840, loss: 0.009833239018917084
step: 850, loss: 0.025472164154052734
step: 860, loss: 0.06406340003013611
step: 870, loss: 0.029264697805047035
step: 880, loss: 0.029588283970952034
step: 890, loss: 0.14761042594909668
step: 900, loss: 0.2725803852081299
step: 910, loss: 0.07842332869768143
step: 920, loss: 0.07508392632007599
step: 930, loss: 0.014908121898770332
step: 940, loss: 0.08862149715423584
step: 950, loss: 0.04455064982175827
step: 960, loss: 0.08245714753866196
step: 970, loss: 0.07604524493217468
epoch 4: dev_f1=0.9276285844333181, f1=0.9291553133514987, best_f1=0.9282739472466451
step: 0, loss: 0.1164175346493721
step: 10, loss: 0.008013647049665451
step: 20, loss: 0.10375504195690155
step: 30, loss: 0.11442036926746368
step: 40, loss: 0.02767004445195198
step: 50, loss: 0.007554864976555109
step: 60, loss: 0.030787471681833267
step: 70, loss: 0.03199723735451698
step: 80, loss: 0.010012594051659107
step: 90, loss: 0.04250232130289078
step: 100, loss: 0.010936981067061424
step: 110, loss: 0.09758628904819489
step: 120, loss: 0.13886681199073792
step: 130, loss: 0.12899188697338104
step: 140, loss: 0.05280422419309616
step: 150, loss: 0.03812113404273987
step: 160, loss: 0.00017846822447609156
step: 170, loss: 0.01222947146743536
step: 180, loss: 0.04327527806162834
step: 190, loss: 0.02599753625690937
step: 200, loss: 0.01988139934837818
step: 210, loss: 0.030583057552576065
step: 220, loss: 0.025100477039813995
step: 230, loss: 0.00017539525288157165
step: 240, loss: 0.08755973726511002
step: 250, loss: 0.10023976117372513
step: 260, loss: 0.02495766617357731
step: 270, loss: 0.0733124166727066
step: 280, loss: 0.16023197770118713
step: 290, loss: 0.02782679721713066
step: 300, loss: 0.030157823115587234
step: 310, loss: 0.09006543457508087
step: 320, loss: 0.06211484223604202
step: 330, loss: 0.009265877306461334
step: 340, loss: 0.08063576370477676
step: 350, loss: 0.016644150018692017
step: 360, loss: 0.027485759928822517
step: 370, loss: 0.024639980867505074
step: 380, loss: 0.18061697483062744
step: 390, loss: 0.01603277027606964
step: 400, loss: 0.08647140860557556
step: 410, loss: 0.07452956587076187
step: 420, loss: 0.19780415296554565
step: 430, loss: 0.048778947442770004
step: 440, loss: 0.06891831755638123
step: 450, loss: 0.17604990303516388
step: 460, loss: 0.11591716855764389
step: 470, loss: 0.1146821454167366
step: 480, loss: 0.021118640899658203
step: 490, loss: 0.0986839160323143
step: 500, loss: 0.07711523771286011
step: 510, loss: 0.06593972444534302
step: 520, loss: 0.04706154018640518
step: 530, loss: 0.024255825206637383
step: 540, loss: 0.028472181409597397
step: 550, loss: 0.015891779214143753
step: 560, loss: 0.06619028002023697
step: 570, loss: 0.019332846626639366
step: 580, loss: 0.041687995195388794
step: 590, loss: 0.05952609330415726
step: 600, loss: 0.14755991101264954
step: 610, loss: 0.06726197898387909
step: 620, loss: 0.05376433953642845
step: 630, loss: 0.1187247782945633
step: 640, loss: 0.06805930286645889
step: 650, loss: 0.024933427572250366
step: 660, loss: 0.07914359122514725
step: 670, loss: 0.07232483476400375
step: 680, loss: 0.1264423131942749
step: 690, loss: 0.13362768292427063
step: 700, loss: 0.05998314917087555
step: 710, loss: 0.030051231384277344
step: 720, loss: 0.0115101533010602
step: 730, loss: 0.1492771953344345
step: 740, loss: 0.034168541431427
step: 750, loss: 0.09721879661083221
step: 760, loss: 0.04020385071635246
step: 770, loss: 0.027969133108854294
step: 780, loss: 0.02540241926908493
step: 790, loss: 0.05524016171693802
step: 800, loss: 0.06997579336166382
step: 810, loss: 0.07325706630945206
step: 820, loss: 0.03684689477086067
step: 830, loss: 0.061917856335639954
step: 840, loss: 0.1558213233947754
step: 850, loss: 0.09837807714939117
step: 860, loss: 0.03844362497329712
step: 870, loss: 0.12636777758598328
step: 880, loss: 0.08627215772867203
step: 890, loss: 0.039269059896469116
step: 900, loss: 0.02621997334063053
step: 910, loss: 0.08791328221559525
step: 920, loss: 0.06611164659261703
step: 930, loss: 0.016473708674311638
step: 940, loss: 0.02864077128469944
step: 950, loss: 0.11387144029140472
step: 960, loss: 0.13843339681625366
step: 970, loss: 0.06860664486885071
epoch 5: dev_f1=0.9350529709811147, f1=0.9362880886426593, best_f1=0.9362880886426593
step: 0, loss: 0.07809817045927048
step: 10, loss: 0.15312518179416656
step: 20, loss: 0.005234545562416315
step: 30, loss: 0.023295028135180473
step: 40, loss: 0.1432383954524994
step: 50, loss: 0.004690253641456366
step: 60, loss: 0.04268360137939453
step: 70, loss: 0.09399103373289108
step: 80, loss: 0.024151979014277458
step: 90, loss: 0.01433916762471199
step: 100, loss: 0.06418812274932861
step: 110, loss: 0.2022380381822586
step: 120, loss: 0.09016945213079453
step: 130, loss: 0.019703304395079613
step: 140, loss: 0.027763692662119865
step: 150, loss: 0.27463218569755554
step: 160, loss: 0.025274770334362984
step: 170, loss: 0.06697183102369308
step: 180, loss: 0.027580631896853447
step: 190, loss: 0.022972222417593002
step: 200, loss: 0.1359322965145111
step: 210, loss: 0.0003600243362598121
step: 220, loss: 0.07210589200258255
step: 230, loss: 0.02518436685204506
step: 240, loss: 0.02061493694782257
step: 250, loss: 0.0350356288254261
step: 260, loss: 0.09934618324041367
step: 270, loss: 0.0944766253232956
step: 280, loss: 0.16745010018348694
step: 290, loss: 0.1467902511358261
step: 300, loss: 0.004061427898705006
step: 310, loss: 0.03713695704936981
step: 320, loss: 0.017543626949191093
step: 330, loss: 0.08413859456777573
step: 340, loss: 0.0845661461353302
step: 350, loss: 0.036147698760032654
step: 360, loss: 0.05819575488567352
step: 370, loss: 0.07068108022212982
step: 380, loss: 0.08031635731458664
step: 390, loss: 0.22828282415866852
step: 400, loss: 0.16317133605480194
step: 410, loss: 0.03407980129122734
step: 420, loss: 0.028382552787661552
step: 430, loss: 0.04804915934801102
step: 440, loss: 0.018014870584011078
step: 450, loss: 0.015498983673751354
step: 460, loss: 0.017554912716150284
step: 470, loss: 0.1313904970884323
step: 480, loss: 0.10092855244874954
step: 490, loss: 0.18670839071273804
step: 500, loss: 0.06237329542636871
step: 510, loss: 0.024420099332928658
step: 520, loss: 0.09695170819759369
step: 530, loss: 0.03866930305957794
step: 540, loss: 0.18476344645023346
step: 550, loss: 0.031815558671951294
step: 560, loss: 0.11016016453504562
step: 570, loss: 0.0674043595790863
step: 580, loss: 0.021166354417800903
step: 590, loss: 0.028446467593312263
step: 600, loss: 0.013718265108764172
step: 610, loss: 0.05553824454545975
step: 620, loss: 0.022827673703432083
step: 630, loss: 0.030693089589476585
step: 640, loss: 0.09195699542760849
step: 650, loss: 0.06101227179169655
step: 660, loss: 0.10269249975681305
step: 670, loss: 0.06878206878900528
step: 680, loss: 0.17820188403129578
step: 690, loss: 0.15991835296154022
step: 700, loss: 0.02818380296230316
step: 710, loss: 0.11493422836065292
step: 720, loss: 0.07255309820175171
step: 730, loss: 0.02268178015947342
step: 740, loss: 0.03109339065849781
step: 750, loss: 0.013777215965092182
step: 760, loss: 0.01912022940814495
step: 770, loss: 0.17463266849517822
step: 780, loss: 0.09715694934129715
step: 790, loss: 0.029651235789060593
step: 800, loss: 0.09134648740291595
step: 810, loss: 0.017904529348015785
step: 820, loss: 0.111757792532444
step: 830, loss: 0.06576493382453918
step: 840, loss: 0.07302521914243698
step: 850, loss: 0.0659961998462677
step: 860, loss: 0.14858876168727875
step: 870, loss: 0.006282176356762648
step: 880, loss: 0.027152009308338165
step: 890, loss: 0.0552588514983654
step: 900, loss: 0.01090775616466999
step: 910, loss: 0.02340884879231453
step: 920, loss: 0.010593883693218231
step: 930, loss: 0.03385445475578308
step: 940, loss: 0.06369935721158981
step: 950, loss: 0.15237751603126526
step: 960, loss: 0.054593805223703384
step: 970, loss: 0.07090085744857788
epoch 6: dev_f1=0.9339534883720929, f1=0.930276087973795, best_f1=0.9362880886426593
step: 0, loss: 0.016699040308594704
step: 10, loss: 0.005209631752222776
step: 20, loss: 3.6510085919871926e-05
step: 30, loss: 0.2086966633796692
step: 40, loss: 0.0742126852273941
step: 50, loss: 0.012188154272735119
step: 60, loss: 0.0590619295835495
step: 70, loss: 0.05261582136154175
step: 80, loss: 0.0876573696732521
step: 90, loss: 0.026969749480485916
step: 100, loss: 0.01845218613743782
step: 110, loss: 5.188670911593363e-05
step: 120, loss: 0.03545616194605827
step: 130, loss: 0.10389480739831924
step: 140, loss: 0.06235722824931145
step: 150, loss: 0.012443696148693562
step: 160, loss: 0.04551374539732933
step: 170, loss: 0.06482680886983871
step: 180, loss: 0.054841604083776474
step: 190, loss: 0.1263115406036377
step: 200, loss: 0.06966584920883179
step: 210, loss: 0.08087269961833954
step: 220, loss: 0.05282111093401909
step: 230, loss: 0.06894256174564362
step: 240, loss: 0.09913649410009384
step: 250, loss: 0.11618710309267044
step: 260, loss: 0.10390263795852661
step: 270, loss: 0.0762946605682373
step: 280, loss: 0.17783762514591217
step: 290, loss: 0.06581689417362213
step: 300, loss: 0.058601848781108856
step: 310, loss: 0.04030024632811546
step: 320, loss: 0.08955775201320648
step: 330, loss: 0.03181390464305878
step: 340, loss: 0.14075647294521332
step: 350, loss: 0.0335531085729599
step: 360, loss: 0.027111291885375977
step: 370, loss: 0.050368331372737885
step: 380, loss: 0.007733271922916174
step: 390, loss: 0.10534259676933289
step: 400, loss: 0.032402656972408295
step: 410, loss: 0.023400230333209038
step: 420, loss: 0.14214417338371277
step: 430, loss: 0.0024918310809880495
step: 440, loss: 0.09079144895076752
step: 450, loss: 0.06932994723320007
step: 460, loss: 0.08876712620258331
step: 470, loss: 0.07503905892372131
step: 480, loss: 0.13036970794200897
step: 490, loss: 0.013217265717685223
step: 500, loss: 0.07594767212867737
step: 510, loss: 0.04022753983736038
step: 520, loss: 0.10144098103046417
step: 530, loss: 0.11888168752193451
step: 540, loss: 0.0027855231892317533
step: 550, loss: 0.021133150905370712
step: 560, loss: 0.06344381719827652
step: 570, loss: 0.08905405551195145
step: 580, loss: 0.06977155059576035
step: 590, loss: 0.06356888264417648
step: 600, loss: 0.1008366048336029
step: 610, loss: 0.16563355922698975
step: 620, loss: 0.12828606367111206
step: 630, loss: 0.05800415202975273
step: 640, loss: 0.02383076585829258
step: 650, loss: 0.024102607741951942
step: 660, loss: 0.10598257184028625
step: 670, loss: 0.003976911306381226
step: 680, loss: 0.12453759461641312
step: 690, loss: 0.08626778423786163
step: 700, loss: 0.05574267730116844
step: 710, loss: 0.039884261786937714
step: 720, loss: 0.01911313086748123
step: 730, loss: 0.07575412094593048
step: 740, loss: 0.025229651480913162
step: 750, loss: 0.0224759578704834
step: 760, loss: 0.005605348385870457
step: 770, loss: 0.1750979721546173
step: 780, loss: 0.12303130328655243
step: 790, loss: 0.006897966377437115
step: 800, loss: 0.02098790556192398
step: 810, loss: 0.030923988670110703
step: 820, loss: 0.08983491361141205
step: 830, loss: 0.08701511472463608
step: 840, loss: 0.23087304830551147
step: 850, loss: 0.10807253420352936
step: 860, loss: 0.06066754832863808
step: 870, loss: 0.020892921835184097
step: 880, loss: 0.09964431077241898
step: 890, loss: 0.07796506583690643
step: 900, loss: 0.021574515849351883
step: 910, loss: 0.037639517337083817
step: 920, loss: 0.1123848706483841
step: 930, loss: 0.0047846343368291855
step: 940, loss: 0.04535188153386116
step: 950, loss: 0.03281841799616814
step: 960, loss: 0.04255075007677078
step: 970, loss: 0.027157703414559364
epoch 7: dev_f1=0.9243619489559165, f1=0.9321016166281756, best_f1=0.9362880886426593
step: 0, loss: 0.03317659720778465
step: 10, loss: 0.030121298506855965
step: 20, loss: 0.15277159214019775
step: 30, loss: 0.0834285318851471
step: 40, loss: 0.003937380388379097
step: 50, loss: 0.021113818511366844
step: 60, loss: 0.012693232856690884
step: 70, loss: 0.0837474912405014
step: 80, loss: 0.08417657017707825
step: 90, loss: 0.08559918403625488
step: 100, loss: 0.09224817156791687
step: 110, loss: 0.05628347769379616
step: 120, loss: 0.04069806635379791
step: 130, loss: 0.03509856015443802
step: 140, loss: 0.013797936961054802
step: 150, loss: 0.04571046680212021
step: 160, loss: 0.18822693824768066
step: 170, loss: 0.018567537888884544
step: 180, loss: 0.11732712388038635
step: 190, loss: 0.06913278251886368
step: 200, loss: 0.0014045051066204906
step: 210, loss: 0.11522988229990005
step: 220, loss: 0.03678423538804054
step: 230, loss: 0.0485062301158905
step: 240, loss: 0.014508506283164024
step: 250, loss: 0.0420614629983902
step: 260, loss: 0.059742022305727005
step: 270, loss: 0.00434515904635191
step: 280, loss: 0.01067618653178215
step: 290, loss: 0.10589469224214554
step: 300, loss: 0.029890352860093117
step: 310, loss: 0.0685758963227272
step: 320, loss: 0.05671902000904083
step: 330, loss: 0.01654825173318386
step: 340, loss: 0.03459913283586502
step: 350, loss: 0.09025364369153976
step: 360, loss: 0.029238443821668625
step: 370, loss: 0.10918021202087402
step: 380, loss: 0.020533328875899315
step: 390, loss: 0.0412813164293766
step: 400, loss: 0.01237923838198185
step: 410, loss: 0.06016108766198158
step: 420, loss: 0.007001420948654413
step: 430, loss: 0.09545577317476273
step: 440, loss: 0.004863496869802475
step: 450, loss: 0.13851697742938995
step: 460, loss: 0.011026280000805855
step: 470, loss: 0.007050323765724897
step: 480, loss: 0.05401764437556267
step: 490, loss: 0.046772487461566925
step: 500, loss: 0.004674280993640423
step: 510, loss: 0.04881177097558975
step: 520, loss: 0.07757247984409332
step: 530, loss: 0.01908571645617485
step: 540, loss: 0.05892817676067352
step: 550, loss: 0.06912948936223984
step: 560, loss: 0.08945781737565994
step: 570, loss: 0.023996401578187943
step: 580, loss: 0.09880935400724411
step: 590, loss: 0.0750245749950409
step: 600, loss: 0.005223625339567661
step: 610, loss: 0.10140537470579147
step: 620, loss: 0.018913142383098602
step: 630, loss: 0.04801921173930168
step: 640, loss: 0.07566558569669724
step: 650, loss: 0.04058270528912544
step: 660, loss: 0.02239329181611538
step: 670, loss: 0.01779862493276596
step: 680, loss: 0.02257964015007019
step: 690, loss: 0.009419594891369343
step: 700, loss: 0.17794492840766907
step: 710, loss: 0.08991135656833649
step: 720, loss: 0.03989393636584282
step: 730, loss: 0.07701202481985092
step: 740, loss: 0.03383447229862213
step: 750, loss: 0.021259121596813202
step: 760, loss: 0.08139335364103317
step: 770, loss: 0.019303953275084496
step: 780, loss: 0.13813109695911407
step: 790, loss: 0.075393907725811
step: 800, loss: 0.016548117622733116
step: 810, loss: 0.02757706679403782
step: 820, loss: 0.022515784949064255
step: 830, loss: 0.030401602387428284
step: 840, loss: 0.12282250821590424
step: 850, loss: 0.08239961415529251
step: 860, loss: 0.027049658820033073
step: 870, loss: 0.08258266001939774
step: 880, loss: 0.020370488986372948
step: 890, loss: 0.06272020190954208
step: 900, loss: 0.018956994637846947
step: 910, loss: 0.10309267789125443
step: 920, loss: 0.01365138404071331
step: 930, loss: 0.014475749805569649
step: 940, loss: 0.03757806494832039
step: 950, loss: 0.0492265559732914
step: 960, loss: 0.14227722585201263
step: 970, loss: 0.08432310819625854
epoch 8: dev_f1=0.9337626494940202, f1=0.9359560841720037, best_f1=0.9362880886426593
step: 0, loss: 0.07233171164989471
step: 10, loss: 0.009985013864934444
step: 20, loss: 0.0291947852820158
step: 30, loss: 0.11597689986228943
step: 40, loss: 0.009411649778485298
step: 50, loss: 0.020073819905519485
step: 60, loss: 0.10940173268318176
step: 70, loss: 0.05110449343919754
step: 80, loss: 0.07674077153205872
step: 90, loss: 0.003137320512905717
step: 100, loss: 0.0404372364282608
step: 110, loss: 0.026189545169472694
step: 120, loss: 0.0341997891664505
step: 130, loss: 0.01823456585407257
step: 140, loss: 0.00948761124163866
step: 150, loss: 0.07047831267118454
step: 160, loss: 0.04869269207119942
step: 170, loss: 0.02209298498928547
step: 180, loss: 0.0044397288002073765
step: 190, loss: 0.016838831827044487
step: 200, loss: 0.02245025709271431
step: 210, loss: 0.05148104578256607
step: 220, loss: 0.1963474452495575
step: 230, loss: 0.0888083428144455
step: 240, loss: 0.033129721879959106
step: 250, loss: 0.09053809195756912
step: 260, loss: 0.0550711415708065
step: 270, loss: 0.015142199583351612
step: 280, loss: 0.00507239019498229
step: 290, loss: 0.11126785725355148
step: 300, loss: 0.02060495875775814
step: 310, loss: 0.07975518703460693
step: 320, loss: 0.07441135495901108
step: 330, loss: 0.022448280826210976
step: 340, loss: 0.04419267177581787
step: 350, loss: 0.01865941286087036
step: 360, loss: 0.08031529188156128
step: 370, loss: 0.09640492498874664
step: 380, loss: 0.10665498673915863
step: 390, loss: 0.06910617649555206
step: 400, loss: 0.005187740549445152
step: 410, loss: 0.2268424928188324
step: 420, loss: 0.048581670969724655
step: 430, loss: 0.023721609264612198
step: 440, loss: 0.010228117927908897
step: 450, loss: 0.027106843888759613
step: 460, loss: 0.17055588960647583
step: 470, loss: 0.013414761051535606
step: 480, loss: 0.07560276985168457
step: 490, loss: 0.150738924741745
step: 500, loss: 0.03557278960943222
step: 510, loss: 0.03519323095679283
step: 520, loss: 0.0793493464589119
step: 530, loss: 0.0713202953338623
step: 540, loss: 0.05444659665226936
step: 550, loss: 0.13973721861839294
step: 560, loss: 0.011379826813936234
step: 570, loss: 0.011376660317182541
step: 580, loss: 0.0019853312987834215
step: 590, loss: 0.0025415532290935516
step: 600, loss: 0.09220778197050095
step: 610, loss: 0.12017355114221573
step: 620, loss: 0.022221751511096954
step: 630, loss: 0.050781119614839554
step: 640, loss: 0.015857860445976257
step: 650, loss: 0.04524651914834976
step: 660, loss: 0.05643904581665993
step: 670, loss: 0.03954223543405533
step: 680, loss: 0.05996745452284813
step: 690, loss: 0.11243356019258499
step: 700, loss: 0.07142291218042374
step: 710, loss: 0.10052696615457535
step: 720, loss: 0.11239568889141083
step: 730, loss: 0.028782930225133896
step: 740, loss: 0.05319757014513016
step: 750, loss: 0.010049964301288128
step: 760, loss: 0.0434022881090641
step: 770, loss: 0.028711071237921715
step: 780, loss: 0.0665358155965805
step: 790, loss: 0.16277384757995605
step: 800, loss: 0.09091890603303909
step: 810, loss: 0.0817134752869606
step: 820, loss: 0.014199254103004932
step: 830, loss: 0.19374997913837433
step: 840, loss: 0.16226479411125183
step: 850, loss: 0.026905858889222145
step: 860, loss: 0.07378267496824265
step: 870, loss: 0.14742939174175262
step: 880, loss: 0.11175598204135895
step: 890, loss: 0.12085677683353424
step: 900, loss: 0.06716695427894592
step: 910, loss: 0.05521456152200699
step: 920, loss: 0.06522276252508163
step: 930, loss: 0.17344991862773895
step: 940, loss: 0.013246802613139153
step: 950, loss: 0.036662645637989044
step: 960, loss: 0.10571315139532089
step: 970, loss: 0.018072739243507385
epoch 9: dev_f1=0.9244935543278084, f1=0.9253321117727897, best_f1=0.9362880886426593
step: 0, loss: 0.021545834839344025
step: 10, loss: 0.06681946665048599
step: 20, loss: 0.03032732754945755
step: 30, loss: 0.040015190839767456
step: 40, loss: 0.040238525718450546
step: 50, loss: 0.010454937815666199
step: 60, loss: 0.010939410887658596
step: 70, loss: 0.009210854768753052
step: 80, loss: 0.008527923375368118
step: 90, loss: 0.062117401510477066
step: 100, loss: 0.08272404968738556
step: 110, loss: 0.03651820123195648
step: 120, loss: 0.07763084024190903
step: 130, loss: 0.021616855636239052
step: 140, loss: 0.08160293102264404
step: 150, loss: 0.05413519963622093
step: 160, loss: 0.06203417479991913
step: 170, loss: 0.21734604239463806
step: 180, loss: 0.05706040561199188
step: 190, loss: 0.03331415727734566
step: 200, loss: 0.09893739968538284
step: 210, loss: 0.018049130216240883
step: 220, loss: 2.347579356865026e-05
step: 230, loss: 0.06412650644779205
step: 240, loss: 0.015245018526911736
step: 250, loss: 0.07469108700752258
step: 260, loss: 0.08160415291786194
step: 270, loss: 0.07813115417957306
step: 280, loss: 0.03750605136156082
step: 290, loss: 0.011768931522965431
step: 300, loss: 0.149038165807724
step: 310, loss: 0.08040038496255875
step: 320, loss: 0.060363415628671646
step: 330, loss: 0.035725872963666916
step: 340, loss: 0.008039665408432484
step: 350, loss: 0.08681362867355347
step: 360, loss: 0.10816627740859985
step: 370, loss: 0.009510637260973454
step: 380, loss: 0.1908576935529709
step: 390, loss: 0.016711488366127014
step: 400, loss: 0.04698825255036354
step: 410, loss: 0.06604795157909393
step: 420, loss: 0.11927034705877304
step: 430, loss: 0.024603646248579025
step: 440, loss: 0.11572085320949554
step: 450, loss: 0.02569492720067501
step: 460, loss: 0.034384291619062424
step: 470, loss: 0.005124283954501152
step: 480, loss: 0.08164442330598831
step: 490, loss: 0.09491792321205139
step: 500, loss: 0.09424807876348495
step: 510, loss: 0.08633167296648026
step: 520, loss: 0.12857189774513245
step: 530, loss: 0.051343679428100586
step: 540, loss: 0.0716899186372757
step: 550, loss: 0.03887004405260086
step: 560, loss: 0.1390761435031891
step: 570, loss: 0.06074950098991394
step: 580, loss: 0.15706853568553925
step: 590, loss: 0.01847686804831028
step: 600, loss: 0.06390326470136642
step: 610, loss: 0.06097341328859329
step: 620, loss: 0.12539921700954437
step: 630, loss: 0.05276377871632576
step: 640, loss: 0.021251127123832703
step: 650, loss: 0.023010503500699997
step: 660, loss: 0.00010064976959256455
step: 670, loss: 0.00936007872223854
step: 680, loss: 0.08738287538290024
step: 690, loss: 0.07967984676361084
step: 700, loss: 0.08150013536214828
step: 710, loss: 0.06900525838136673
step: 720, loss: 0.21276327967643738
step: 730, loss: 0.042997539043426514
step: 740, loss: 0.04860299453139305
step: 750, loss: 0.05716243013739586
step: 760, loss: 0.08076681941747665
step: 770, loss: 0.0063186767511069775
step: 780, loss: 0.13378643989562988
step: 790, loss: 0.023812677711248398
step: 800, loss: 0.0734957680106163
step: 810, loss: 0.005833521485328674
step: 820, loss: 0.09586907178163528
step: 830, loss: 0.02707745134830475
step: 840, loss: 0.004675577394664288
step: 850, loss: 0.03451312705874443
step: 860, loss: 0.010477302595973015
step: 870, loss: 0.018566381186246872
step: 880, loss: 0.006825019605457783
step: 890, loss: 0.07453558593988419
step: 900, loss: 0.025422409176826477
step: 910, loss: 0.0021235262975096703
step: 920, loss: 0.06645304709672928
step: 930, loss: 0.067033551633358
step: 940, loss: 0.07452838122844696
step: 950, loss: 0.0940462127327919
step: 960, loss: 0.061763107776641846
step: 970, loss: 0.12389867007732391
epoch 10: dev_f1=0.9335205992509362, f1=0.9339578454332552, best_f1=0.9362880886426593
step: 0, loss: 0.026018958538770676
step: 10, loss: 0.027031317353248596
step: 20, loss: 0.08011584728956223
step: 30, loss: 0.021354619413614273
step: 40, loss: 0.09083087742328644
step: 50, loss: 0.0728568434715271
step: 60, loss: 0.007611523382365704
step: 70, loss: 0.04017464444041252
step: 80, loss: 0.02928030677139759
step: 90, loss: 0.00022635847562924027
step: 100, loss: 0.06310345977544785
step: 110, loss: 0.007128579542040825
step: 120, loss: 0.09225966036319733
step: 130, loss: 0.020956628024578094
step: 140, loss: 0.01601037010550499
step: 150, loss: 0.02057584747672081
step: 160, loss: 0.09179677814245224
step: 170, loss: 0.13432565331459045
step: 180, loss: 0.03646188601851463
step: 190, loss: 0.0790976732969284
step: 200, loss: 0.04251304268836975
step: 210, loss: 0.13664288818836212
step: 220, loss: 0.018840841948986053
step: 230, loss: 0.03869635611772537
step: 240, loss: 0.007727418560534716
step: 250, loss: 0.0323231965303421
step: 260, loss: 0.09406265616416931
step: 270, loss: 0.0061205411329865456
step: 280, loss: 0.05155552923679352
step: 290, loss: 0.025284793227910995
step: 300, loss: 0.05203215777873993
step: 310, loss: 0.028034286573529243
step: 320, loss: 0.013960009440779686
step: 330, loss: 0.030167728662490845
step: 340, loss: 0.03220921754837036
step: 350, loss: 0.013098884373903275
step: 360, loss: 0.014263373799622059
step: 370, loss: 0.00786567758768797
step: 380, loss: 0.06810815632343292
step: 390, loss: 0.014981694519519806
step: 400, loss: 0.053036514669656754
step: 410, loss: 0.12982288002967834
step: 420, loss: 0.008404582738876343
step: 430, loss: 0.005183892790228128
step: 440, loss: 0.07949494570493698
step: 450, loss: 0.03760725259780884
step: 460, loss: 0.02712518721818924
step: 470, loss: 0.038574639707803726
step: 480, loss: 0.05573107302188873
step: 490, loss: 0.044708725064992905
step: 500, loss: 0.013226671144366264
step: 510, loss: 0.08878792822360992
step: 520, loss: 0.03735946863889694
step: 530, loss: 0.00329022528603673
step: 540, loss: 0.12810231745243073
step: 550, loss: 0.043944649398326874
step: 560, loss: 0.02674069255590439
step: 570, loss: 0.06912188231945038
step: 580, loss: 0.05226575583219528
step: 590, loss: 0.005636389367282391
step: 600, loss: 0.04171996936202049
step: 610, loss: 0.23018667101860046
step: 620, loss: 0.0547974668443203
step: 630, loss: 0.08097214251756668
step: 640, loss: 0.14983080327510834
step: 650, loss: 0.003957912791520357
step: 660, loss: 0.058196015655994415
step: 670, loss: 0.06286826729774475
step: 680, loss: 0.03917054459452629
step: 690, loss: 0.1052890196442604
step: 700, loss: 0.02472350001335144
step: 710, loss: 0.06239613890647888
step: 720, loss: 0.004735502880066633
step: 730, loss: 0.01362909097224474
step: 740, loss: 0.01592428982257843
step: 750, loss: 0.025086967274546623
step: 760, loss: 0.1153215616941452
step: 770, loss: 0.04078434780240059
step: 780, loss: 0.009131025522947311
step: 790, loss: 0.054615214467048645
step: 800, loss: 0.0342583954334259
step: 810, loss: 0.04441847652196884
step: 820, loss: 0.015000193379819393
step: 830, loss: 0.10345005244016647
step: 840, loss: 0.005822259932756424
step: 850, loss: 0.1252416968345642
step: 860, loss: 0.016044843941926956
step: 870, loss: 0.00502934493124485
step: 880, loss: 0.17302706837654114
step: 890, loss: 0.07303879410028458
step: 900, loss: 0.06200016289949417
step: 910, loss: 0.06512143462896347
step: 920, loss: 0.08297858387231827
step: 930, loss: 0.1807161569595337
step: 940, loss: 0.07623229920864105
step: 950, loss: 0.084741972386837
step: 960, loss: 0.14912422001361847
step: 970, loss: 0.030717583373188972
epoch 11: dev_f1=0.9332723948811701, f1=0.9338201734367868, best_f1=0.9362880886426593
step: 0, loss: 0.02294941432774067
step: 10, loss: 0.058104924857616425
step: 20, loss: 0.03086097538471222
step: 30, loss: 0.0013080262579023838
step: 40, loss: 0.01680627092719078
step: 50, loss: 0.061389848589897156
step: 60, loss: 0.07011190056800842
step: 70, loss: 0.10422004014253616
step: 80, loss: 0.0201598908752203
step: 90, loss: 0.007197358645498753
step: 100, loss: 0.035356659442186356
step: 110, loss: 0.06722822040319443
step: 120, loss: 0.11031056195497513
step: 130, loss: 0.014147770591080189
step: 140, loss: 0.0018003196455538273
step: 150, loss: 0.0052164699882268906
step: 160, loss: 0.026875510811805725
step: 170, loss: 0.005874557886272669
step: 180, loss: 0.025756793096661568
step: 190, loss: 0.058683253824710846
step: 200, loss: 0.0028797974810004234
step: 210, loss: 0.0233167577534914
step: 220, loss: 0.0021732207387685776
step: 230, loss: 0.004890644457191229
step: 240, loss: 0.0008507256861776114
step: 250, loss: 0.020077664405107498
step: 260, loss: 0.040024805814027786
step: 270, loss: 0.019707156345248222
step: 280, loss: 0.046228837221860886
step: 290, loss: 0.06263373047113419
step: 300, loss: 0.0028367743361741304
step: 310, loss: 0.012866218574345112
step: 320, loss: 0.013956407085061073
step: 330, loss: 0.003947305027395487
step: 340, loss: 0.14048834145069122
step: 350, loss: 0.040776919573545456
step: 360, loss: 0.02038194239139557
step: 370, loss: 0.14642584323883057
step: 380, loss: 0.10267768055200577
step: 390, loss: 0.05436132103204727
step: 400, loss: 0.015695855021476746
step: 410, loss: 0.19543753564357758
step: 420, loss: 0.004008639138191938
step: 430, loss: 0.032590072602033615
step: 440, loss: 0.13001635670661926
step: 450, loss: 0.05215689539909363
step: 460, loss: 0.09020324796438217
step: 470, loss: 0.15133191645145416
step: 480, loss: 0.03485369682312012
step: 490, loss: 0.0036348686553537846
step: 500, loss: 0.006659985985606909
step: 510, loss: 0.032377537339925766
step: 520, loss: 0.045512620359659195
step: 530, loss: 0.0001622282579774037
step: 540, loss: 0.02921532467007637
step: 550, loss: 0.07286425679922104
step: 560, loss: 0.04933156818151474
step: 570, loss: 0.008584417402744293
step: 580, loss: 0.00027398348902352154
step: 590, loss: 0.1031150370836258
step: 600, loss: 0.11569704860448837
step: 610, loss: 0.005703621543943882
step: 620, loss: 0.1657652109861374
step: 630, loss: 0.023003198206424713
step: 640, loss: 0.07224602997303009
step: 650, loss: 0.07484360784292221
step: 660, loss: 0.19504377245903015
step: 670, loss: 0.010931265540421009
step: 680, loss: 0.21936804056167603
step: 690, loss: 0.052388858050107956
step: 700, loss: 0.018449241295456886
step: 710, loss: 0.022449776530265808
step: 720, loss: 0.10754586011171341
step: 730, loss: 0.16354277729988098
step: 740, loss: 0.07438361644744873
step: 750, loss: 0.038837216794490814
step: 760, loss: 0.050447531044483185
step: 770, loss: 0.019638890400528908
step: 780, loss: 0.062411077320575714
step: 790, loss: 0.015547862276434898
step: 800, loss: 0.0008659459999762475
step: 810, loss: 0.10982514172792435
step: 820, loss: 0.0033251065760850906
step: 830, loss: 0.025023983791470528
step: 840, loss: 0.04409907013177872
step: 850, loss: 0.014834667555987835
step: 860, loss: 0.030947832390666008
step: 870, loss: 0.08761397749185562
step: 880, loss: 0.05199534818530083
step: 890, loss: 0.13028690218925476
step: 900, loss: 0.007585732266306877
step: 910, loss: 0.006642544642090797
step: 920, loss: 0.0022976843174546957
step: 930, loss: 0.05035266652703285
step: 940, loss: 0.14843623340129852
step: 950, loss: 0.03745241463184357
step: 960, loss: 0.054939642548561096
step: 970, loss: 0.09197957813739777
epoch 12: dev_f1=0.9330254041570438, f1=0.9349930843706776, best_f1=0.9362880886426593
step: 0, loss: 0.020044609904289246
step: 10, loss: 0.01907602697610855
step: 20, loss: 0.004746094811707735
step: 30, loss: 0.009256378747522831
step: 40, loss: 0.009320758283138275
step: 50, loss: 0.020368076860904694
step: 60, loss: 0.05233043432235718
step: 70, loss: 0.0192215945571661
step: 80, loss: 0.005962682887911797
step: 90, loss: 0.09371375292539597
step: 100, loss: 0.0030980997253209352
step: 110, loss: 0.012834256514906883
step: 120, loss: 0.0005111753707751632
step: 130, loss: 0.02705032005906105
step: 140, loss: 0.062170784920454025
step: 150, loss: 0.026563448831439018
step: 160, loss: 0.07133755087852478
step: 170, loss: 0.04722839966416359
step: 180, loss: 0.025837887078523636
step: 190, loss: 2.2671005353913642e-05
step: 200, loss: 0.014677315950393677
step: 210, loss: 0.02324637398123741
step: 220, loss: 0.08402671664953232
step: 230, loss: 0.03923608735203743
step: 240, loss: 0.09128674119710922
step: 250, loss: 0.001537122530862689
step: 260, loss: 0.08064191788434982
step: 270, loss: 0.0044410317204892635
step: 280, loss: 0.05852265655994415
step: 290, loss: 0.026773590594530106
step: 300, loss: 0.042481742799282074
step: 310, loss: 0.005817846395075321
step: 320, loss: 0.039045292884111404
step: 330, loss: 0.0011640721932053566
step: 340, loss: 0.011024910025298595
step: 350, loss: 0.08424414694309235
step: 360, loss: 0.05785347521305084
step: 370, loss: 0.00011343826918164268
step: 380, loss: 0.0010536378249526024
step: 390, loss: 0.03033977933228016
step: 400, loss: 0.05190977081656456
step: 410, loss: 0.0014076844090595841
step: 420, loss: 0.05624770000576973
step: 430, loss: 0.05297187715768814
step: 440, loss: 0.036092475056648254
step: 450, loss: 0.02089705690741539
step: 460, loss: 0.011442501097917557
step: 470, loss: 0.09491901844739914
step: 480, loss: 0.005497257225215435
step: 490, loss: 0.00810862984508276
step: 500, loss: 0.09386246651411057
step: 510, loss: 0.04134093225002289
step: 520, loss: 0.10638363659381866
step: 530, loss: 0.0029791868291795254
step: 540, loss: 0.001045526354573667
step: 550, loss: 0.06810467690229416
step: 560, loss: 0.035451117902994156
step: 570, loss: 0.11849065870046616
step: 580, loss: 0.13147574663162231
step: 590, loss: 0.000316148332785815
step: 600, loss: 0.05453917756676674
step: 610, loss: 0.0008378223283216357
step: 620, loss: 0.07342217862606049
step: 630, loss: 0.07721241563558578
step: 640, loss: 0.009821955114603043
step: 650, loss: 0.029605379328131676
step: 660, loss: 0.027807187288999557
step: 670, loss: 0.07288850098848343
step: 680, loss: 0.0030076184775680304
step: 690, loss: 0.050244610756635666
step: 700, loss: 0.018584545701742172
step: 710, loss: 0.12808899581432343
step: 720, loss: 0.005365727469325066
step: 730, loss: 0.02668759413063526
step: 740, loss: 0.0034496551379561424
step: 750, loss: 0.19388121366500854
step: 760, loss: 0.0005168638308532536
step: 770, loss: 0.09774629771709442
step: 780, loss: 0.05166444554924965
step: 790, loss: 0.009770060889422894
step: 800, loss: 0.010608583688735962
step: 810, loss: 0.022572871297597885
step: 820, loss: 0.028170209378004074
step: 830, loss: 0.021105831488966942
step: 840, loss: 0.0035078921355307102
step: 850, loss: 0.022649448364973068
step: 860, loss: 0.004790579900145531
step: 870, loss: 0.04542789235711098
step: 880, loss: 0.030176373198628426
step: 890, loss: 0.08566462993621826
step: 900, loss: 0.030723385512828827
step: 910, loss: 0.03267946466803551
step: 920, loss: 0.01674731634557247
step: 930, loss: 0.005722118075937033
step: 940, loss: 0.06769260764122009
step: 950, loss: 0.06421931833028793
step: 960, loss: 0.03208988904953003
step: 970, loss: 0.07274328172206879
epoch 13: dev_f1=0.9298000929800094, f1=0.9323447636700649, best_f1=0.9362880886426593
step: 0, loss: 0.04455240070819855
step: 10, loss: 0.0016699788393452764
step: 20, loss: 0.0009902319870889187
step: 30, loss: 0.045658133924007416
step: 40, loss: 0.28810983896255493
step: 50, loss: 0.053776226937770844
step: 60, loss: 0.048245932906866074
step: 70, loss: 0.06905312836170197
step: 80, loss: 0.033314451575279236
step: 90, loss: 0.0015314092161133885
step: 100, loss: 0.0074545289389789104
step: 110, loss: 0.07592702656984329
step: 120, loss: 0.01044886652380228
step: 130, loss: 0.05125811696052551
step: 140, loss: 0.012364080175757408
step: 150, loss: 0.06348172575235367
step: 160, loss: 0.22622522711753845
step: 170, loss: 0.045125678181648254
step: 180, loss: 0.05660395324230194
step: 190, loss: 0.02896362543106079
step: 200, loss: 0.07092047482728958
step: 210, loss: 0.04286147654056549
step: 220, loss: 0.05340440571308136
step: 230, loss: 0.00042206718353554606
step: 240, loss: 0.023443780839443207
step: 250, loss: 0.0011598952114582062
step: 260, loss: 0.009955963119864464
step: 270, loss: 0.02825072780251503
step: 280, loss: 0.02339314855635166
step: 290, loss: 0.0017816780600696802
step: 300, loss: 0.0005506836459971964
step: 310, loss: 0.040145620703697205
step: 320, loss: 0.034744035452604294
step: 330, loss: 0.027369823306798935
step: 340, loss: 0.0008666248759254813
step: 350, loss: 0.018632449209690094
step: 360, loss: 0.031474024057388306
step: 370, loss: 0.08278939127922058
step: 380, loss: 0.08454202860593796
step: 390, loss: 0.057430148124694824
step: 400, loss: 0.01580633409321308
step: 410, loss: 0.01950821466743946
step: 420, loss: 0.01999075524508953
step: 430, loss: 0.08547879755496979
step: 440, loss: 0.0013309473870322108
step: 450, loss: 0.05874445661902428
step: 460, loss: 0.13706810772418976
step: 470, loss: 0.03347455710172653
step: 480, loss: 0.06589213013648987
step: 490, loss: 0.006691415794193745
step: 500, loss: 0.009373239241540432
step: 510, loss: 0.04599309340119362
step: 520, loss: 0.002145039848983288
step: 530, loss: 0.02599751017987728
step: 540, loss: 0.0417386032640934
step: 550, loss: 0.012058637104928493
step: 560, loss: 0.13606955111026764
step: 570, loss: 0.036376968026161194
step: 580, loss: 0.03188815712928772
step: 590, loss: 0.019715605303645134
step: 600, loss: 0.004903905093669891
step: 610, loss: 0.020551525056362152
step: 620, loss: 0.014576164074242115
step: 630, loss: 0.05145282298326492
step: 640, loss: 0.037107180804014206
step: 650, loss: 0.030834604054689407
step: 660, loss: 0.0917077288031578
step: 670, loss: 0.010349219664931297
step: 680, loss: 0.03160544112324715
step: 690, loss: 0.03067852556705475
step: 700, loss: 0.09017964452505112
step: 710, loss: 0.012408461421728134
step: 720, loss: 0.01578681729733944
step: 730, loss: 0.0187077634036541
step: 740, loss: 0.00024517072597518563
step: 750, loss: 0.04448531195521355
step: 760, loss: 0.027164625003933907
step: 770, loss: 0.007127465680241585
step: 780, loss: 0.025529062375426292
step: 790, loss: 0.03755663335323334
step: 800, loss: 0.01989423669874668
step: 810, loss: 0.12087495625019073
step: 820, loss: 0.06526880711317062
step: 830, loss: 0.01330677792429924
step: 840, loss: 0.014790814369916916
step: 850, loss: 0.05832814797759056
step: 860, loss: 0.15248572826385498
step: 870, loss: 0.05764709413051605
step: 880, loss: 0.05619966238737106
step: 890, loss: 0.05759419500827789
step: 900, loss: 0.06748289614915848
step: 910, loss: 0.002601275220513344
step: 920, loss: 0.03480231761932373
step: 930, loss: 0.03535674139857292
step: 940, loss: 0.0013675320660695434
step: 950, loss: 0.033723827451467514
step: 960, loss: 0.022395603358745575
step: 970, loss: 0.05463019013404846
epoch 14: dev_f1=0.9298162976919454, f1=0.933083762283575, best_f1=0.9362880886426593
step: 0, loss: 0.06109107658267021
step: 10, loss: 0.06277354061603546
step: 20, loss: 0.03211723268032074
step: 30, loss: 0.17718751728534698
step: 40, loss: 0.0011190572986379266
step: 50, loss: 0.06548413634300232
step: 60, loss: 0.027519118040800095
step: 70, loss: 0.0029341995250433683
step: 80, loss: 0.0015128154773265123
step: 90, loss: 0.09429039806127548
step: 100, loss: 0.0239217821508646
step: 110, loss: 0.044068384915590286
step: 120, loss: 0.14215262234210968
step: 130, loss: 0.044719595462083817
step: 140, loss: 0.052565742284059525
step: 150, loss: 0.051862750202417374
step: 160, loss: 0.07083509862422943
step: 170, loss: 0.020793704316020012
step: 180, loss: 0.06645721197128296
step: 190, loss: 0.07675911486148834
step: 200, loss: 0.058324623852968216
step: 210, loss: 0.04174074903130531
step: 220, loss: 0.00016204078565351665
step: 230, loss: 0.09643218666315079
step: 240, loss: 0.0008067046292126179
step: 250, loss: 0.005661605857312679
step: 260, loss: 0.0065344772301614285
step: 270, loss: 0.09814362972974777
step: 280, loss: 0.0016922160284593701
step: 290, loss: 0.02587244287133217
step: 300, loss: 0.024286488071084023
step: 310, loss: 0.05246477574110031
step: 320, loss: 0.025024909526109695
step: 330, loss: 0.011913836002349854
step: 340, loss: 0.10254549980163574
step: 350, loss: 0.10110681504011154
step: 360, loss: 0.004508110228925943
step: 370, loss: 0.00024278031196445227
step: 380, loss: 0.03181985765695572
step: 390, loss: 0.0004636191588360816
step: 400, loss: 0.01550829317420721
step: 410, loss: 0.025013599544763565
step: 420, loss: 0.06303223967552185
step: 430, loss: 0.0046229674480855465
step: 440, loss: 0.07102853059768677
step: 450, loss: 0.08857353031635284
step: 460, loss: 0.029695870354771614
step: 470, loss: 0.008754893206059933
step: 480, loss: 0.06653609871864319
step: 490, loss: 0.059486329555511475
step: 500, loss: 0.02827441692352295
step: 510, loss: 0.03390468657016754
step: 520, loss: 0.01394152082502842
step: 530, loss: 0.021832358092069626
step: 540, loss: 0.05783543735742569
step: 550, loss: 0.017012251541018486
step: 560, loss: 0.026168646290898323
step: 570, loss: 0.09440966695547104
step: 580, loss: 0.12086373567581177
step: 590, loss: 0.025332044810056686
step: 600, loss: 0.07567285001277924
step: 610, loss: 0.02063184604048729
step: 620, loss: 0.04422781243920326
step: 630, loss: 0.07294589281082153
step: 640, loss: 0.03745071962475777
step: 650, loss: 0.07187243551015854
step: 660, loss: 0.05437305197119713
step: 670, loss: 0.06675019860267639
step: 680, loss: 0.03924393281340599
step: 690, loss: 0.0772840827703476
step: 700, loss: 0.01644635945558548
step: 710, loss: 0.03577094525098801
step: 720, loss: 0.027734952047467232
step: 730, loss: 0.062152717262506485
step: 740, loss: 0.019490590319037437
step: 750, loss: 0.040613144636154175
step: 760, loss: 0.021203981712460518
step: 770, loss: 0.08204946666955948
step: 780, loss: 0.0758470892906189
step: 790, loss: 0.11001449823379517
step: 800, loss: 0.06604752689599991
step: 810, loss: 0.038796961307525635
step: 820, loss: 0.02551358751952648
step: 830, loss: 1.3596948519989382e-05
step: 840, loss: 0.001546467305161059
step: 850, loss: 0.039185669273138046
step: 860, loss: 0.03909634053707123
step: 870, loss: 0.0006892498349770904
step: 880, loss: 0.023996101692318916
step: 890, loss: 0.030585231259465218
step: 900, loss: 0.019898688420653343
step: 910, loss: 0.14998558163642883
step: 920, loss: 0.09500093013048172
step: 930, loss: 0.005179199390113354
step: 940, loss: 0.11729511618614197
step: 950, loss: 0.034873299300670624
step: 960, loss: 9.931597742252052e-05
step: 970, loss: 0.08935537934303284
epoch 15: dev_f1=0.9315323707498836, f1=0.9337042188224385, best_f1=0.9362880886426593
step: 0, loss: 0.0005747727118432522
step: 10, loss: 0.03745468705892563
step: 20, loss: 0.0358676016330719
step: 30, loss: 0.030867356806993484
step: 40, loss: 0.003026661230251193
step: 50, loss: 0.01529562659561634
step: 60, loss: 0.02192295715212822
step: 70, loss: 0.08795036375522614
step: 80, loss: 0.03127821907401085
step: 90, loss: 0.04742511734366417
step: 100, loss: 0.06437596678733826
step: 110, loss: 0.002670599613338709
step: 120, loss: 0.0005537354736588895
step: 130, loss: 0.015748558565974236
step: 140, loss: 0.009801402688026428
step: 150, loss: 0.02393278479576111
step: 160, loss: 0.04681285470724106
step: 170, loss: 0.0017125318991020322
step: 180, loss: 0.08380816131830215
step: 190, loss: 0.06546325236558914
step: 200, loss: 0.014717797748744488
step: 210, loss: 0.0007799609447829425
step: 220, loss: 0.02246827632188797
step: 230, loss: 0.0165720134973526
step: 240, loss: 0.07433019578456879
step: 250, loss: 0.006607587914913893
step: 260, loss: 0.013313434086740017
step: 270, loss: 0.014435946010053158
step: 280, loss: 0.002291820477694273
step: 290, loss: 0.0008992311195470393
step: 300, loss: 5.5071868700906634e-05
step: 310, loss: 0.008251761086285114
step: 320, loss: 0.04001379385590553
step: 330, loss: 0.023024413734674454
step: 340, loss: 0.03357483074069023
step: 350, loss: 5.495426376000978e-05
step: 360, loss: 0.07671207189559937
step: 370, loss: 0.041488830000162125
step: 380, loss: 0.08189678937196732
step: 390, loss: 0.021353116258978844
step: 400, loss: 0.004213312175124884
step: 410, loss: 0.07489074766635895
step: 420, loss: 0.030272478237748146
step: 430, loss: 0.045162882655858994
step: 440, loss: 0.009377268142998219
step: 450, loss: 0.06119881942868233
step: 460, loss: 0.03941745311021805
step: 470, loss: 0.01941167190670967
step: 480, loss: 0.02303183078765869
step: 490, loss: 0.05681472271680832
step: 500, loss: 0.13663725554943085
step: 510, loss: 0.0235665924847126
step: 520, loss: 0.0002507594763301313
step: 530, loss: 0.0130450539290905
step: 540, loss: 0.10763577371835709
step: 550, loss: 0.004274010192602873
step: 560, loss: 0.02134132944047451
step: 570, loss: 0.037784405052661896
step: 580, loss: 0.03708546236157417
step: 590, loss: 0.04512244090437889
step: 600, loss: 0.08701203763484955
step: 610, loss: 0.03503300994634628
step: 620, loss: 0.0628836378455162
step: 630, loss: 0.02948022447526455
step: 640, loss: 0.054568372666835785
step: 650, loss: 0.04764354228973389
step: 660, loss: 0.08415962755680084
step: 670, loss: 0.07585117220878601
step: 680, loss: 0.06709454953670502
step: 690, loss: 0.002903394168242812
step: 700, loss: 0.09854093194007874
step: 710, loss: 0.027454566210508347
step: 720, loss: 0.07138485461473465
step: 730, loss: 0.002930173184722662
step: 740, loss: 0.03708195686340332
step: 750, loss: 0.040542516857385635
step: 760, loss: 0.05969206988811493
step: 770, loss: 0.019374337047338486
step: 780, loss: 0.031368058174848557
step: 790, loss: 0.15276768803596497
step: 800, loss: 0.03548753261566162
step: 810, loss: 0.03111504390835762
step: 820, loss: 0.03673524037003517
step: 830, loss: 0.028461063280701637
step: 840, loss: 0.06825118511915207
step: 850, loss: 0.00022442889166995883
step: 860, loss: 0.001638223184272647
step: 870, loss: 0.057815004140138626
step: 880, loss: 0.050384748727083206
step: 890, loss: 0.015338938683271408
step: 900, loss: 0.031656548380851746
step: 910, loss: 0.02144002355635166
step: 920, loss: 0.00015264553076121956
step: 930, loss: 0.05055614188313484
step: 940, loss: 0.04558991640806198
step: 950, loss: 0.02984652854502201
step: 960, loss: 0.0010899084154516459
step: 970, loss: 0.005514238961040974
epoch 16: dev_f1=0.9309865678554886, f1=0.933456561922366, best_f1=0.9362880886426593
step: 0, loss: 0.0010495665483176708
step: 10, loss: 0.03191138431429863
step: 20, loss: 0.05679803341627121
step: 30, loss: 0.04877256602048874
step: 40, loss: 0.054553139954805374
step: 50, loss: 0.04029564931988716
step: 60, loss: 0.06955961883068085
step: 70, loss: 0.01969010941684246
step: 80, loss: 0.01226199883967638
step: 90, loss: 0.028297150507569313
step: 100, loss: 0.0001181794868898578
step: 110, loss: 0.01826331578195095
step: 120, loss: 0.007364340126514435
step: 130, loss: 0.0032069210428744555
step: 140, loss: 0.039518263190984726
step: 150, loss: 0.0978352278470993
step: 160, loss: 0.08855707198381424
step: 170, loss: 0.043526630848646164
step: 180, loss: 7.209129398688674e-05
step: 190, loss: 0.018847571685910225
step: 200, loss: 0.01724664866924286
step: 210, loss: 0.09609518945217133
step: 220, loss: 0.00020591032807715237
step: 230, loss: 0.018648916855454445
step: 240, loss: 0.02325628697872162
step: 250, loss: 0.028997622430324554
step: 260, loss: 0.04820098727941513
step: 270, loss: 0.019115956500172615
step: 280, loss: 0.09186763316392899
step: 290, loss: 0.05035035312175751
step: 300, loss: 0.008132279850542545
step: 310, loss: 0.004751008935272694
step: 320, loss: 0.024788208305835724
step: 330, loss: 0.09624190628528595
step: 340, loss: 0.010793489404022694
step: 350, loss: 0.06342481076717377
step: 360, loss: 0.037036165595054626
step: 370, loss: 0.07060185074806213
step: 380, loss: 0.021611161530017853
step: 390, loss: 0.039079297333955765
step: 400, loss: 0.02002553641796112
step: 410, loss: 0.003909281920641661
step: 420, loss: 0.021667808294296265
step: 430, loss: 0.025827322155237198
step: 440, loss: 0.03416416421532631
step: 450, loss: 0.0003705191775225103
step: 460, loss: 0.0008546812459826469
step: 470, loss: 0.0002198422880610451
step: 480, loss: 0.02833978272974491
step: 490, loss: 0.06619291752576828
step: 500, loss: 0.0003792199131567031
step: 510, loss: 0.00025482007185928524
step: 520, loss: 0.016505710780620575
step: 530, loss: 0.03824426978826523
step: 540, loss: 0.0042146677151322365
step: 550, loss: 0.022331904619932175
step: 560, loss: 0.01965274102985859
step: 570, loss: 0.10598786175251007
step: 580, loss: 0.024472670629620552
step: 590, loss: 1.0251907042402308e-05
step: 600, loss: 0.0024812771007418633
step: 610, loss: 0.0724780485033989
step: 620, loss: 0.00010994119656970724
step: 630, loss: 0.04653265327215195
step: 640, loss: 0.10436010360717773
step: 650, loss: 0.0005813370808027685
step: 660, loss: 0.0013515042373910546
step: 670, loss: 0.037544410675764084
step: 680, loss: 0.07042154669761658
step: 690, loss: 8.04594237706624e-05
step: 700, loss: 0.012943408451974392
step: 710, loss: 0.021596094593405724
step: 720, loss: 0.05169712007045746
step: 730, loss: 0.010516745038330555
step: 740, loss: 0.03071133978664875
step: 750, loss: 0.0010866617085412145
step: 760, loss: 0.03985811024904251
step: 770, loss: 0.008111239410936832
step: 780, loss: 0.029963023960590363
step: 790, loss: 0.10858308523893356
step: 800, loss: 0.052426133304834366
step: 810, loss: 0.08602418005466461
step: 820, loss: 0.05338185280561447
step: 830, loss: 0.004978492856025696
step: 840, loss: 0.025304660201072693
step: 850, loss: 0.03532099723815918
step: 860, loss: 0.11897407472133636
step: 870, loss: 0.022689392790198326
step: 880, loss: 0.045935891568660736
step: 890, loss: 0.0212332122027874
step: 900, loss: 0.18798454105854034
step: 910, loss: 8.231489482568577e-05
step: 920, loss: 0.07138204574584961
step: 930, loss: 0.000787927012424916
step: 940, loss: 0.002095166128128767
step: 950, loss: 0.018753599375486374
step: 960, loss: 0.0005550466012209654
step: 970, loss: 0.07773993164300919
epoch 17: dev_f1=0.9328984156570364, f1=0.9309865678554886, best_f1=0.9362880886426593
step: 0, loss: 0.02597169019281864
step: 10, loss: 0.00012561683251988143
step: 20, loss: 0.0012102905893698335
step: 30, loss: 0.05823659151792526
step: 40, loss: 9.140794281847775e-05
step: 50, loss: 3.145175287500024e-05
step: 60, loss: 0.0019170643063262105
step: 70, loss: 0.05114442855119705
step: 80, loss: 0.03649274259805679
step: 90, loss: 0.02552267163991928
step: 100, loss: 0.019447162747383118
step: 110, loss: 8.172290836228058e-05
step: 120, loss: 1.678469925536774e-05
step: 130, loss: 0.044140491634607315
step: 140, loss: 0.07431121915578842
step: 150, loss: 0.05138518288731575
step: 160, loss: 0.0040625035762786865
step: 170, loss: 0.030679825693368912
step: 180, loss: 0.04161422327160835
step: 190, loss: 0.023433560505509377
step: 200, loss: 0.03432551398873329
step: 210, loss: 0.007955181412398815
step: 220, loss: 0.050877489149570465
step: 230, loss: 0.0002581920998636633
step: 240, loss: 0.01809895783662796
step: 250, loss: 0.014358836226165295
step: 260, loss: 0.04780179262161255
step: 270, loss: 0.02090359665453434
step: 280, loss: 0.04707576707005501
step: 290, loss: 0.02473810873925686
step: 300, loss: 4.672572686104104e-05
step: 310, loss: 0.00023650287766940892
step: 320, loss: 0.06614499539136887
step: 330, loss: 0.00020768535614479333
step: 340, loss: 0.05185576155781746
step: 350, loss: 0.02208520844578743
step: 360, loss: 0.0446632094681263
step: 370, loss: 0.05737430974841118
step: 380, loss: 0.0439399816095829
step: 390, loss: 0.06790412217378616
step: 400, loss: 0.023431850597262383
step: 410, loss: 0.00010583245602902025
step: 420, loss: 0.032781071960926056
step: 430, loss: 0.027780422940850258
step: 440, loss: 0.023173145949840546
step: 450, loss: 0.08877523988485336
step: 460, loss: 0.019502902403473854
step: 470, loss: 0.002550743520259857
step: 480, loss: 0.025776732712984085
step: 490, loss: 0.04041740298271179
step: 500, loss: 0.0451180562376976
step: 510, loss: 0.0002477433590684086
step: 520, loss: 0.028633443638682365
step: 530, loss: 0.0339081697165966
step: 540, loss: 2.3076634533936158e-05
step: 550, loss: 0.0007775298436172307
step: 560, loss: 0.003662433475255966
step: 570, loss: 0.10279852151870728
step: 580, loss: 0.00043061748147010803
step: 590, loss: 0.1081899031996727
step: 600, loss: 0.00032888242276385427
step: 610, loss: 0.007282217964529991
step: 620, loss: 0.02596239000558853
step: 630, loss: 0.021396690979599953
step: 640, loss: 0.0002934487711172551
step: 650, loss: 0.05776027962565422
step: 660, loss: 4.863877984462306e-05
step: 670, loss: 0.0004329460207372904
step: 680, loss: 0.015956604853272438
step: 690, loss: 0.09487872570753098
step: 700, loss: 0.06039998680353165
step: 710, loss: 0.020143039524555206
step: 720, loss: 0.019264573231339455
step: 730, loss: 0.020898297429084778
step: 740, loss: 0.03288523107767105
step: 750, loss: 0.007501192390918732
step: 760, loss: 0.029893698170781136
step: 770, loss: 0.038424935191869736
step: 780, loss: 0.030885251238942146
step: 790, loss: 0.04666122794151306
step: 800, loss: 0.06590017676353455
step: 810, loss: 0.036111969500780106
step: 820, loss: 0.02716539241373539
step: 830, loss: 0.04753558710217476
step: 840, loss: 0.0005249882815405726
step: 850, loss: 0.07278937846422195
step: 860, loss: 0.015714386478066444
step: 870, loss: 0.02563338540494442
step: 880, loss: 0.0001074589163181372
step: 890, loss: 0.022063031792640686
step: 900, loss: 0.07975725084543228
step: 910, loss: 0.021934520453214645
step: 920, loss: 0.01942184567451477
step: 930, loss: 0.000734577770344913
step: 940, loss: 0.06291155517101288
step: 950, loss: 0.003339948831126094
step: 960, loss: 0.13607068359851837
step: 970, loss: 0.0366818867623806
epoch 18: dev_f1=0.9309701492537312, f1=0.9326521133302369, best_f1=0.9362880886426593
step: 0, loss: 0.036938924342393875
step: 10, loss: 0.022329505532979965
step: 20, loss: 0.014686843380331993
step: 30, loss: 0.04822412505745888
step: 40, loss: 0.02802659571170807
step: 50, loss: 0.028729993849992752
step: 60, loss: 0.04894282668828964
step: 70, loss: 0.0414765365421772
step: 80, loss: 0.08806698769330978
step: 90, loss: 0.0007090924773365259
step: 100, loss: 0.027944641187787056
step: 110, loss: 0.026937929913401604
step: 120, loss: 9.00572631508112e-05
step: 130, loss: 1.9536739273462445e-05
step: 140, loss: 0.0003714500926434994
step: 150, loss: 0.038250286132097244
step: 160, loss: 0.020849205553531647
step: 170, loss: 0.07217054069042206
step: 180, loss: 0.03415551409125328
step: 190, loss: 0.03179560974240303
step: 200, loss: 0.01880873367190361
step: 210, loss: 0.06668522208929062
step: 220, loss: 0.00018511789676267654
step: 230, loss: 0.04297034069895744
step: 240, loss: 0.02124621346592903
step: 250, loss: 0.057463422417640686
step: 260, loss: 0.029752599075436592
step: 270, loss: 0.03147095814347267
step: 280, loss: 0.0026604854501783848
step: 290, loss: 0.023602697998285294
step: 300, loss: 0.05210413038730621
step: 310, loss: 0.00010757763084257022
step: 320, loss: 0.02516908012330532
step: 330, loss: 0.018206648528575897
step: 340, loss: 0.04857240989804268
step: 350, loss: 0.021434186026453972
step: 360, loss: 0.02916903980076313
step: 370, loss: 0.027282917872071266
step: 380, loss: 0.00011962001008214429
step: 390, loss: 0.025171222165226936
step: 400, loss: 0.01569982059299946
step: 410, loss: 0.04094676300883293
step: 420, loss: 0.029594827443361282
step: 430, loss: 0.014233177527785301
step: 440, loss: 2.478552414686419e-05
step: 450, loss: 0.02259906195104122
step: 460, loss: 0.027533775195479393
step: 470, loss: 0.042187124490737915
step: 480, loss: 0.019509207457304
step: 490, loss: 0.020104916766285896
step: 500, loss: 0.021284140646457672
step: 510, loss: 0.07254645228385925
step: 520, loss: 0.08745361119508743
step: 530, loss: 0.026179959997534752
step: 540, loss: 0.01845032535493374
step: 550, loss: 0.0006915919948369265
step: 560, loss: 0.024369288235902786
step: 570, loss: 0.004278886131942272
step: 580, loss: 0.000393842114135623
step: 590, loss: 0.03845646604895592
step: 600, loss: 0.0001026228055707179
step: 610, loss: 0.023543737828731537
step: 620, loss: 1.0777059287647717e-05
step: 630, loss: 0.025082582607865334
step: 640, loss: 0.02554924041032791
step: 650, loss: 0.00048446047003380954
step: 660, loss: 9.805910667637363e-05
step: 670, loss: 0.025757988914847374
step: 680, loss: 0.01794159971177578
step: 690, loss: 0.00038803587085567415
step: 700, loss: 7.81098788138479e-05
step: 710, loss: 0.0002233510313089937
step: 720, loss: 3.4071894333465025e-05
step: 730, loss: 0.024270854890346527
step: 740, loss: 0.03804852440953255
step: 750, loss: 0.04572435840964317
step: 760, loss: 8.217952199629508e-06
step: 770, loss: 0.0009180431952700019
step: 780, loss: 0.05778738483786583
step: 790, loss: 0.01776241324841976
step: 800, loss: 0.005772449541836977
step: 810, loss: 0.00029227303457446396
step: 820, loss: 5.117710315971635e-05
step: 830, loss: 0.03471163287758827
step: 840, loss: 0.052691467106342316
step: 850, loss: 0.00019313330994918942
step: 860, loss: 0.036995477974414825
step: 870, loss: 0.05644729360938072
step: 880, loss: 3.900190131389536e-05
step: 890, loss: 0.048982925713062286
step: 900, loss: 0.032588161528110504
step: 910, loss: 0.00016661152767483145
step: 920, loss: 7.997544889803976e-05
step: 930, loss: 0.015106123872101307
step: 940, loss: 0.005126710049808025
step: 950, loss: 0.01645079255104065
step: 960, loss: 0.03160111606121063
step: 970, loss: 0.047850362956523895
epoch 19: dev_f1=0.9320843091334895, f1=0.9351981351981352, best_f1=0.9362880886426593
step: 0, loss: 0.03549496456980705
step: 10, loss: 0.017810191959142685
step: 20, loss: 0.018349280580878258
step: 30, loss: 0.00011872559844050556
step: 40, loss: 0.04394805431365967
step: 50, loss: 0.0225226953625679
step: 60, loss: 0.03928272798657417
step: 70, loss: 5.996245818096213e-05
step: 80, loss: 0.02154042199254036
step: 90, loss: 0.018430806696414948
step: 100, loss: 4.0328450268134475e-05
step: 110, loss: 0.01839180290699005
step: 120, loss: 0.043657656759023666
step: 130, loss: 0.03983250632882118
step: 140, loss: 0.03416534885764122
step: 150, loss: 0.012508113868534565
step: 160, loss: 0.028664052486419678
step: 170, loss: 2.6472709578229114e-05
step: 180, loss: 0.00012188742402940989
step: 190, loss: 0.06321045011281967
step: 200, loss: 1.644225267227739e-05
step: 210, loss: 0.04196831211447716
step: 220, loss: 0.002437017858028412
step: 230, loss: 0.021843528375029564
step: 240, loss: 0.02324783429503441
step: 250, loss: 0.025654684752225876
step: 260, loss: 0.04978565871715546
step: 270, loss: 0.022253526374697685
step: 280, loss: 0.06758574396371841
step: 290, loss: 0.00015785299183335155
step: 300, loss: 0.04561784863471985
step: 310, loss: 0.04397566244006157
step: 320, loss: 0.04145452380180359
step: 330, loss: 0.0012790439650416374
step: 340, loss: 0.000655116920825094
step: 350, loss: 0.04878190532326698
step: 360, loss: 0.06070978567004204
step: 370, loss: 0.061894264072179794
step: 380, loss: 0.020605040714144707
step: 390, loss: 0.07582434266805649
step: 400, loss: 0.02759166620671749
step: 410, loss: 1.5041737242427189e-05
step: 420, loss: 1.9198689187760465e-05
step: 430, loss: 0.05155443400144577
step: 440, loss: 0.04694829136133194
step: 450, loss: 0.0005778537015430629
step: 460, loss: 0.014424452558159828
step: 470, loss: 7.725067553110421e-05
step: 480, loss: 8.060828986344859e-05
step: 490, loss: 0.05523147061467171
step: 500, loss: 7.429078686982393e-05
step: 510, loss: 2.7678912374540232e-05
step: 520, loss: 0.029327841475605965
step: 530, loss: 0.0004287187766749412
step: 540, loss: 0.029017025604844093
step: 550, loss: 0.034363552927970886
step: 560, loss: 0.04848216846585274
step: 570, loss: 0.015170919708907604
step: 580, loss: 0.001329065184108913
step: 590, loss: 0.024223513901233673
step: 600, loss: 0.023271044716238976
step: 610, loss: 0.008124072104692459
step: 620, loss: 0.02320990338921547
step: 630, loss: 0.004902703687548637
step: 640, loss: 0.021213319152593613
step: 650, loss: 0.0022593201138079166
step: 660, loss: 0.020187271758913994
step: 670, loss: 0.02228393405675888
step: 680, loss: 0.04191441833972931
step: 690, loss: 0.03267373889684677
step: 700, loss: 0.015163588337600231
step: 710, loss: 0.019350090995430946
step: 720, loss: 0.05794909596443176
step: 730, loss: 0.01353493146598339
step: 740, loss: 0.00023964884167071432
step: 750, loss: 5.424237315310165e-05
step: 760, loss: 0.019992001354694366
step: 770, loss: 0.06286494433879852
step: 780, loss: 0.017195597290992737
step: 790, loss: 4.693491428042762e-05
step: 800, loss: 0.04565030336380005
step: 810, loss: 3.4921969927381724e-05
step: 820, loss: 0.021790221333503723
step: 830, loss: 0.05245998874306679
step: 840, loss: 0.02177342027425766
step: 850, loss: 0.11012786626815796
step: 860, loss: 0.01930571161210537
step: 870, loss: 0.04189462587237358
step: 880, loss: 0.021598903462290764
step: 890, loss: 0.05244261771440506
step: 900, loss: 0.04002872854471207
step: 910, loss: 0.041416849941015244
step: 920, loss: 0.06590494513511658
step: 930, loss: 0.00021334257326088846
step: 940, loss: 0.018598055467009544
step: 950, loss: 0.025131531059741974
step: 960, loss: 0.02052067220211029
step: 970, loss: 0.0018701601075008512
epoch 20: dev_f1=0.931892907468295, f1=0.9349555451567618, best_f1=0.9362880886426593
