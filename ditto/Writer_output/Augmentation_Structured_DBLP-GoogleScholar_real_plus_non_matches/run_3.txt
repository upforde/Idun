cuda
Device: cuda
step: 0, loss: 0.7010822296142578
step: 10, loss: 0.4300020933151245
step: 20, loss: 0.33469098806381226
step: 30, loss: 0.38752281665802
step: 40, loss: 0.35395547747612
step: 50, loss: 0.39772242307662964
step: 60, loss: 0.11533224582672119
step: 70, loss: 0.07436849921941757
step: 80, loss: 0.22993583977222443
step: 90, loss: 0.21804095804691315
step: 100, loss: 0.1466933637857437
step: 110, loss: 0.24120166897773743
step: 120, loss: 0.05874451622366905
step: 130, loss: 0.16525954008102417
step: 140, loss: 0.08781908452510834
step: 150, loss: 0.2162320464849472
step: 160, loss: 0.15273255109786987
step: 170, loss: 0.17086254060268402
step: 180, loss: 0.08675281703472137
step: 190, loss: 0.0761764869093895
step: 200, loss: 0.09200897067785263
step: 210, loss: 0.07635170221328735
step: 220, loss: 0.05601945146918297
step: 230, loss: 0.19062456488609314
step: 240, loss: 0.2196662575006485
step: 250, loss: 0.20677246153354645
step: 260, loss: 0.031387366354465485
step: 270, loss: 0.04314495250582695
step: 280, loss: 0.08985382318496704
step: 290, loss: 0.11499633640050888
step: 300, loss: 0.15023428201675415
step: 310, loss: 0.10697565972805023
step: 320, loss: 0.0642869770526886
step: 330, loss: 0.17551560699939728
step: 340, loss: 0.09408795088529587
step: 350, loss: 0.1693466156721115
step: 360, loss: 0.2231811285018921
step: 370, loss: 0.03898470848798752
step: 380, loss: 0.05470723286271095
step: 390, loss: 0.07427272200584412
step: 400, loss: 0.13537748157978058
step: 410, loss: 0.1674230992794037
step: 420, loss: 0.06995964050292969
step: 430, loss: 0.12696732580661774
step: 440, loss: 0.1028822809457779
step: 450, loss: 0.12927085161209106
step: 460, loss: 0.08569645136594772
step: 470, loss: 0.08384138345718384
step: 480, loss: 0.15601663291454315
step: 490, loss: 0.23643985390663147
step: 500, loss: 0.11602365970611572
step: 510, loss: 0.09677356481552124
step: 520, loss: 0.20009805262088776
step: 530, loss: 0.04479721933603287
step: 540, loss: 0.06897736340761185
step: 550, loss: 0.06747045367956161
step: 560, loss: 0.07637550681829453
step: 570, loss: 0.09943348914384842
step: 580, loss: 0.11065168678760529
step: 590, loss: 0.11377757787704468
step: 600, loss: 0.05310872942209244
step: 610, loss: 0.04547034204006195
step: 620, loss: 0.43207353353500366
step: 630, loss: 0.06662746518850327
step: 640, loss: 0.14961041510105133
step: 650, loss: 0.06124576926231384
step: 660, loss: 0.11979993432760239
step: 670, loss: 0.0639684870839119
step: 680, loss: 0.18449397385120392
step: 690, loss: 0.154033362865448
step: 700, loss: 0.0850517749786377
step: 710, loss: 0.059811484068632126
step: 720, loss: 0.12771612405776978
step: 730, loss: 0.06376507133245468
step: 740, loss: 0.16138990223407745
step: 750, loss: 0.021610068157315254
step: 760, loss: 0.23806388676166534
step: 770, loss: 0.07918427884578705
step: 780, loss: 0.07750434428453445
step: 790, loss: 0.07547135651111603
step: 800, loss: 0.036943573504686356
step: 810, loss: 0.06422386318445206
step: 820, loss: 0.2225695103406906
step: 830, loss: 0.08639299124479294
step: 840, loss: 0.14354479312896729
step: 850, loss: 0.07831588387489319
step: 860, loss: 0.12391902506351471
step: 870, loss: 0.07321144640445709
step: 880, loss: 0.09373710304498672
step: 890, loss: 0.06933647394180298
step: 900, loss: 0.10283924639225006
step: 910, loss: 0.12824663519859314
step: 920, loss: 0.10651955008506775
step: 930, loss: 0.07614492624998093
step: 940, loss: 0.12286426872015
step: 950, loss: 0.10774007439613342
step: 960, loss: 0.12313616275787354
step: 970, loss: 0.234381765127182
epoch 1: dev_f1=0.9387199273717658, f1=0.9401631912964642, best_f1=0.9401631912964642
step: 0, loss: 0.15956230461597443
step: 10, loss: 0.10144715011119843
step: 20, loss: 0.06397384405136108
step: 30, loss: 0.037272464483976364
step: 40, loss: 0.03437462076544762
step: 50, loss: 0.044020313769578934
step: 60, loss: 0.11252421140670776
step: 70, loss: 0.13596701622009277
step: 80, loss: 0.19378606975078583
step: 90, loss: 0.10648570209741592
step: 100, loss: 0.08004139363765717
step: 110, loss: 0.0388675257563591
step: 120, loss: 0.14169085025787354
step: 130, loss: 0.04033593833446503
step: 140, loss: 0.1094045415520668
step: 150, loss: 0.04953945428133011
step: 160, loss: 0.08176484704017639
step: 170, loss: 0.0545564740896225
step: 180, loss: 0.07611273229122162
step: 190, loss: 0.13574157655239105
step: 200, loss: 0.09414417296648026
step: 210, loss: 0.013950108550488949
step: 220, loss: 0.08242939412593842
step: 230, loss: 0.008335433900356293
step: 240, loss: 0.10782448947429657
step: 250, loss: 0.050440993160009384
step: 260, loss: 0.12962523102760315
step: 270, loss: 0.051917269825935364
step: 280, loss: 0.038884203881025314
step: 290, loss: 0.0929793268442154
step: 300, loss: 0.08222940564155579
step: 310, loss: 0.03947605937719345
step: 320, loss: 0.3690204918384552
step: 330, loss: 0.1567985713481903
step: 340, loss: 0.42403605580329895
step: 350, loss: 0.12993299961090088
step: 360, loss: 0.11161644756793976
step: 370, loss: 0.0935099795460701
step: 380, loss: 0.05512756481766701
step: 390, loss: 0.06443244963884354
step: 400, loss: 0.16084882616996765
step: 410, loss: 0.10672825574874878
step: 420, loss: 0.025638621300458908
step: 430, loss: 0.0878807008266449
step: 440, loss: 0.10404184460639954
step: 450, loss: 0.16578014194965363
step: 460, loss: 0.10654877871274948
step: 470, loss: 0.1728045493364334
step: 480, loss: 0.11730773746967316
step: 490, loss: 0.06449275463819504
step: 500, loss: 0.10074075311422348
step: 510, loss: 0.035457104444503784
step: 520, loss: 0.2856532335281372
step: 530, loss: 0.02903437241911888
step: 540, loss: 0.18620601296424866
step: 550, loss: 0.1951356828212738
step: 560, loss: 0.12016019970178604
step: 570, loss: 0.08546450734138489
step: 580, loss: 0.07505141198635101
step: 590, loss: 0.12044458836317062
step: 600, loss: 0.21030697226524353
step: 610, loss: 0.05563148856163025
step: 620, loss: 0.10017351806163788
step: 630, loss: 0.09913195669651031
step: 640, loss: 0.14665727317333221
step: 650, loss: 0.09679651260375977
step: 660, loss: 0.17711970210075378
step: 670, loss: 0.08649246394634247
step: 680, loss: 0.249853253364563
step: 690, loss: 0.07717522978782654
step: 700, loss: 0.12869025766849518
step: 710, loss: 0.030939361080527306
step: 720, loss: 0.07195950299501419
step: 730, loss: 0.1367916464805603
step: 740, loss: 0.05359802767634392
step: 750, loss: 0.05341173708438873
step: 760, loss: 0.04080468788743019
step: 770, loss: 0.10546364635229111
step: 780, loss: 0.0655030682682991
step: 790, loss: 0.022052280604839325
step: 800, loss: 0.17832712829113007
step: 810, loss: 0.1329721063375473
step: 820, loss: 0.0953143909573555
step: 830, loss: 0.055213890969753265
step: 840, loss: 0.12854672968387604
step: 850, loss: 0.057036057114601135
step: 860, loss: 0.05031372606754303
step: 870, loss: 0.08674021065235138
step: 880, loss: 0.0573745034635067
step: 890, loss: 0.07816026359796524
step: 900, loss: 0.027299780398607254
step: 910, loss: 0.0024204589426517487
step: 920, loss: 0.12376982718706131
step: 930, loss: 0.08430980145931244
step: 940, loss: 0.0859474167227745
step: 950, loss: 0.03246210142970085
step: 960, loss: 0.11852879822254181
step: 970, loss: 0.143202543258667
epoch 2: dev_f1=0.9278538812785389, f1=0.9248291571753987, best_f1=0.9401631912964642
step: 0, loss: 0.09918899834156036
step: 10, loss: 0.08320152014493942
step: 20, loss: 0.047030817717313766
step: 30, loss: 0.029774874448776245
step: 40, loss: 0.03914840146899223
step: 50, loss: 0.0262160561978817
step: 60, loss: 0.011266106739640236
step: 70, loss: 0.1340983361005783
step: 80, loss: 0.06033478304743767
step: 90, loss: 0.0903274193406105
step: 100, loss: 0.050026893615722656
step: 110, loss: 0.046580057591199875
step: 120, loss: 0.05694000795483589
step: 130, loss: 0.02906063199043274
step: 140, loss: 0.12042857706546783
step: 150, loss: 0.09297814965248108
step: 160, loss: 0.010372981429100037
step: 170, loss: 0.1523687094449997
step: 180, loss: 0.09887136518955231
step: 190, loss: 0.028320273384451866
step: 200, loss: 0.07372841984033585
step: 210, loss: 0.18303386867046356
step: 220, loss: 0.12296025454998016
step: 230, loss: 0.09339386224746704
step: 240, loss: 0.06905173510313034
step: 250, loss: 0.25198429822921753
step: 260, loss: 0.1106862872838974
step: 270, loss: 0.042241405695676804
step: 280, loss: 0.10622989386320114
step: 290, loss: 0.03608192503452301
step: 300, loss: 0.020698944106698036
step: 310, loss: 0.118798166513443
step: 320, loss: 0.0901443213224411
step: 330, loss: 0.08901521563529968
step: 340, loss: 0.07709351181983948
step: 350, loss: 0.08304548263549805
step: 360, loss: 0.055850010365247726
step: 370, loss: 0.09049146622419357
step: 380, loss: 0.026106126606464386
step: 390, loss: 0.18602053821086884
step: 400, loss: 0.03586061671376228
step: 410, loss: 0.03554338589310646
step: 420, loss: 0.013003147207200527
step: 430, loss: 0.15463316440582275
step: 440, loss: 0.08071967959403992
step: 450, loss: 0.08599542826414108
step: 460, loss: 0.07106058299541473
step: 470, loss: 0.10603386163711548
step: 480, loss: 0.08362997323274612
step: 490, loss: 0.1393006294965744
step: 500, loss: 0.03040371835231781
step: 510, loss: 0.054815761744976044
step: 520, loss: 0.01708913780748844
step: 530, loss: 0.08026370406150818
step: 540, loss: 0.3679049015045166
step: 550, loss: 0.10012131184339523
step: 560, loss: 0.05149093270301819
step: 570, loss: 0.04397813230752945
step: 580, loss: 0.017690453678369522
step: 590, loss: 0.011302147060632706
step: 600, loss: 0.49696487188339233
step: 610, loss: 0.09733212739229202
step: 620, loss: 0.07318586111068726
step: 630, loss: 0.08612854033708572
step: 640, loss: 0.09048515558242798
step: 650, loss: 0.056869156658649445
step: 660, loss: 0.12388170510530472
step: 670, loss: 0.08495413511991501
step: 680, loss: 0.05707903578877449
step: 690, loss: 0.07946315407752991
step: 700, loss: 0.07970951497554779
step: 710, loss: 0.09271987527608871
step: 720, loss: 0.008416365832090378
step: 730, loss: 0.11040094494819641
step: 740, loss: 0.23063553869724274
step: 750, loss: 0.11560498178005219
step: 760, loss: 0.09036076813936234
step: 770, loss: 0.07069418579339981
step: 780, loss: 0.09399110823869705
step: 790, loss: 0.06944998353719711
step: 800, loss: 0.08495781570672989
step: 810, loss: 0.10473302751779556
step: 820, loss: 0.031696852296590805
step: 830, loss: 0.06209896504878998
step: 840, loss: 0.098231740295887
step: 850, loss: 0.017223885282874107
step: 860, loss: 0.062222834676504135
step: 870, loss: 0.02338102087378502
step: 880, loss: 0.10323572903871536
step: 890, loss: 0.028573058545589447
step: 900, loss: 0.15708313882350922
step: 910, loss: 0.04718734696507454
step: 920, loss: 0.05705227702856064
step: 930, loss: 0.014230521395802498
step: 940, loss: 0.18827657401561737
step: 950, loss: 0.16199566423892975
step: 960, loss: 0.09718236327171326
step: 970, loss: 0.07813769578933716
epoch 3: dev_f1=0.9311778290993071, f1=0.9284403669724771, best_f1=0.9401631912964642
step: 0, loss: 0.02654215507209301
step: 10, loss: 0.11769090592861176
step: 20, loss: 0.02274930477142334
step: 30, loss: 0.05170182138681412
step: 40, loss: 0.05569397285580635
step: 50, loss: 0.01586381159722805
step: 60, loss: 0.03137969970703125
step: 70, loss: 0.051497265696525574
step: 80, loss: 0.13933338224887848
step: 90, loss: 0.1167551651597023
step: 100, loss: 0.01701241545379162
step: 110, loss: 0.01328855101019144
step: 120, loss: 0.10783389955759048
step: 130, loss: 0.07290790230035782
step: 140, loss: 0.17984221875667572
step: 150, loss: 0.05589112639427185
step: 160, loss: 0.11427479237318039
step: 170, loss: 0.09247483313083649
step: 180, loss: 0.010944581590592861
step: 190, loss: 0.07634129375219345
step: 200, loss: 0.31829240918159485
step: 210, loss: 0.08425605297088623
step: 220, loss: 0.0013619385426864028
step: 230, loss: 0.12063097953796387
step: 240, loss: 0.11789754033088684
step: 250, loss: 0.07416332513093948
step: 260, loss: 0.06286861002445221
step: 270, loss: 0.035672981292009354
step: 280, loss: 0.09365745633840561
step: 290, loss: 0.06874679028987885
step: 300, loss: 0.06986644119024277
step: 310, loss: 0.10990014672279358
step: 320, loss: 0.01473311148583889
step: 330, loss: 0.005186510272324085
step: 340, loss: 0.13809381425380707
step: 350, loss: 0.14408446848392487
step: 360, loss: 0.10280115902423859
step: 370, loss: 0.03317486494779587
step: 380, loss: 0.04657551273703575
step: 390, loss: 0.05518759787082672
step: 400, loss: 0.03897969797253609
step: 410, loss: 0.029040228575468063
step: 420, loss: 0.056193191558122635
step: 430, loss: 0.23168930411338806
step: 440, loss: 0.18653427064418793
step: 450, loss: 0.09978730976581573
step: 460, loss: 0.13391883671283722
step: 470, loss: 0.12163949012756348
step: 480, loss: 0.21579867601394653
step: 490, loss: 0.07837724685668945
step: 500, loss: 0.03220108523964882
step: 510, loss: 0.01799602061510086
step: 520, loss: 0.0911455750465393
step: 530, loss: 0.0736309364438057
step: 540, loss: 0.1008896753191948
step: 550, loss: 0.0899253860116005
step: 560, loss: 0.10126389563083649
step: 570, loss: 0.01107970904558897
step: 580, loss: 0.12105751782655716
step: 590, loss: 0.0336509570479393
step: 600, loss: 0.1599668264389038
step: 610, loss: 0.06795164197683334
step: 620, loss: 0.02747304178774357
step: 630, loss: 0.025260310620069504
step: 640, loss: 0.003960707224905491
step: 650, loss: 0.014329043217003345
step: 660, loss: 0.024267137050628662
step: 670, loss: 0.030990153551101685
step: 680, loss: 0.1350879967212677
step: 690, loss: 0.10390661656856537
step: 700, loss: 0.029999250546097755
step: 710, loss: 0.0312681645154953
step: 720, loss: 0.028151459991931915
step: 730, loss: 0.10574740916490555
step: 740, loss: 0.024599356576800346
step: 750, loss: 0.1626383513212204
step: 760, loss: 0.01076448243111372
step: 770, loss: 0.15808026492595673
step: 780, loss: 0.02471872605383396
step: 790, loss: 0.07362623512744904
step: 800, loss: 0.010043943300843239
step: 810, loss: 0.007169818971306086
step: 820, loss: 0.1429007649421692
step: 830, loss: 0.19823531806468964
step: 840, loss: 0.10138178616762161
step: 850, loss: 0.050951037555933
step: 860, loss: 0.16749757528305054
step: 870, loss: 0.02350062131881714
step: 880, loss: 0.056807465851306915
step: 890, loss: 0.10100417584180832
step: 900, loss: 0.03853125497698784
step: 910, loss: 0.07942193746566772
step: 920, loss: 0.12999363243579865
step: 930, loss: 0.09883259981870651
step: 940, loss: 0.1245502233505249
step: 950, loss: 0.05844554305076599
step: 960, loss: 0.017235085368156433
step: 970, loss: 0.07726934552192688
epoch 4: dev_f1=0.9372114496768237, f1=0.9330254041570438, best_f1=0.9401631912964642
step: 0, loss: 0.10591799765825272
step: 10, loss: 0.09041915088891983
step: 20, loss: 0.09666646271944046
step: 30, loss: 0.08067405968904495
step: 40, loss: 0.045304082334041595
step: 50, loss: 0.022494370117783546
step: 60, loss: 0.2274196445941925
step: 70, loss: 0.13703249394893646
step: 80, loss: 0.1406925618648529
step: 90, loss: 0.22524893283843994
step: 100, loss: 0.12242598831653595
step: 110, loss: 0.05331914871931076
step: 120, loss: 0.06934922188520432
step: 130, loss: 0.009806860238313675
step: 140, loss: 0.08573723584413528
step: 150, loss: 0.011942536570131779
step: 160, loss: 0.1478990614414215
step: 170, loss: 0.07351571321487427
step: 180, loss: 0.283797949552536
step: 190, loss: 0.040608666837215424
step: 200, loss: 0.10921664535999298
step: 210, loss: 0.06831443309783936
step: 220, loss: 0.05965835973620415
step: 230, loss: 0.14810259640216827
step: 240, loss: 0.12045641243457794
step: 250, loss: 0.06416890770196915
step: 260, loss: 0.02537700906395912
step: 270, loss: 0.06997954845428467
step: 280, loss: 0.21984729170799255
step: 290, loss: 0.07002891600131989
step: 300, loss: 0.07043610513210297
step: 310, loss: 0.1268792748451233
step: 320, loss: 0.020819606259465218
step: 330, loss: 0.05628250911831856
step: 340, loss: 0.09111439436674118
step: 350, loss: 0.13263124227523804
step: 360, loss: 0.04086189717054367
step: 370, loss: 0.04334934055805206
step: 380, loss: 0.016156446188688278
step: 390, loss: 0.2023417353630066
step: 400, loss: 0.04258124902844429
step: 410, loss: 0.014205357991158962
step: 420, loss: 0.1765163540840149
step: 430, loss: 0.11459982395172119
step: 440, loss: 0.02170342206954956
step: 450, loss: 0.009167873300611973
step: 460, loss: 0.1823006123304367
step: 470, loss: 0.08468738198280334
step: 480, loss: 0.01637517474591732
step: 490, loss: 0.104498490691185
step: 500, loss: 0.08757293969392776
step: 510, loss: 0.05102125182747841
step: 520, loss: 0.04316463693976402
step: 530, loss: 0.0406470000743866
step: 540, loss: 0.1979343146085739
step: 550, loss: 0.10977158695459366
step: 560, loss: 0.11148369312286377
step: 570, loss: 0.10811515152454376
step: 580, loss: 0.0876462459564209
step: 590, loss: 0.05258342623710632
step: 600, loss: 0.07514024525880814
step: 610, loss: 0.025662126019597054
step: 620, loss: 0.020405156537890434
step: 630, loss: 0.03166661411523819
step: 640, loss: 0.14604692161083221
step: 650, loss: 0.011588647961616516
step: 660, loss: 0.0112295001745224
step: 670, loss: 0.07787369191646576
step: 680, loss: 0.12850360572338104
step: 690, loss: 0.062097471207380295
step: 700, loss: 0.09775647521018982
step: 710, loss: 0.08688922971487045
step: 720, loss: 0.1411425918340683
step: 730, loss: 0.04858333617448807
step: 740, loss: 0.07210114598274231
step: 750, loss: 0.06068943068385124
step: 760, loss: 0.159129798412323
step: 770, loss: 0.11479836702346802
step: 780, loss: 0.017140386626124382
step: 790, loss: 0.03205807879567146
step: 800, loss: 0.12484489381313324
step: 810, loss: 0.08443871140480042
step: 820, loss: 0.06275255233049393
step: 830, loss: 0.07061081379652023
step: 840, loss: 0.02266344614326954
step: 850, loss: 0.015110448002815247
step: 860, loss: 0.016902685165405273
step: 870, loss: 0.13123080134391785
step: 880, loss: 0.09562913328409195
step: 890, loss: 0.06226762756705284
step: 900, loss: 0.12472626566886902
step: 910, loss: 0.04287920519709587
step: 920, loss: 0.02401004359126091
step: 930, loss: 0.04143839702010155
step: 940, loss: 0.12556755542755127
step: 950, loss: 0.05320849269628525
step: 960, loss: 0.024884354323148727
step: 970, loss: 0.09216396510601044
epoch 5: dev_f1=0.922863741339492, f1=0.9249999999999999, best_f1=0.9401631912964642
step: 0, loss: 0.10986881703138351
step: 10, loss: 0.022553374990820885
step: 20, loss: 0.01694982871413231
step: 30, loss: 0.06756123900413513
step: 40, loss: 0.1266467124223709
step: 50, loss: 0.015505075454711914
step: 60, loss: 0.015389950945973396
step: 70, loss: 0.18424755334854126
step: 80, loss: 0.03361652418971062
step: 90, loss: 0.03084484674036503
step: 100, loss: 0.014509616419672966
step: 110, loss: 0.10224597901105881
step: 120, loss: 0.023569615557789803
step: 130, loss: 0.11936242133378983
step: 140, loss: 0.06351543962955475
step: 150, loss: 0.20634570717811584
step: 160, loss: 0.046973325312137604
step: 170, loss: 0.09869440644979477
step: 180, loss: 0.15243801474571228
step: 190, loss: 0.06856332719326019
step: 200, loss: 0.014502443373203278
step: 210, loss: 0.03694827854633331
step: 220, loss: 0.09440487623214722
step: 230, loss: 0.06656578183174133
step: 240, loss: 0.05826544016599655
step: 250, loss: 0.09632304310798645
step: 260, loss: 0.014377571642398834
step: 270, loss: 0.04089123010635376
step: 280, loss: 0.14697495102882385
step: 290, loss: 0.058589380234479904
step: 300, loss: 0.06111052632331848
step: 310, loss: 0.06948087364435196
step: 320, loss: 0.042765334248542786
step: 330, loss: 0.04080694913864136
step: 340, loss: 0.16339457035064697
step: 350, loss: 0.09300681948661804
step: 360, loss: 0.032100096344947815
step: 370, loss: 0.029866646975278854
step: 380, loss: 0.02469264529645443
step: 390, loss: 0.10529728978872299
step: 400, loss: 0.059091534465551376
step: 410, loss: 0.04356975480914116
step: 420, loss: 0.20073288679122925
step: 430, loss: 0.05702313780784607
step: 440, loss: 0.11792338639497757
step: 450, loss: 0.03823114186525345
step: 460, loss: 0.0747513622045517
step: 470, loss: 0.08836939185857773
step: 480, loss: 0.019314218312501907
step: 490, loss: 0.0815318152308464
step: 500, loss: 0.06421366333961487
step: 510, loss: 0.36720359325408936
step: 520, loss: 0.15022093057632446
step: 530, loss: 0.03102879412472248
step: 540, loss: 0.04759847745299339
step: 550, loss: 0.047241516411304474
step: 560, loss: 0.06795493513345718
step: 570, loss: 0.12218542397022247
step: 580, loss: 0.09737594425678253
step: 590, loss: 0.02202076092362404
step: 600, loss: 0.0780826285481453
step: 610, loss: 0.08178255707025528
step: 620, loss: 0.16267414391040802
step: 630, loss: 0.04068656265735626
step: 640, loss: 0.05262947455048561
step: 650, loss: 0.00720820389688015
step: 660, loss: 0.02337305061519146
step: 670, loss: 0.01736869476735592
step: 680, loss: 0.08708790689706802
step: 690, loss: 0.04443680867552757
step: 700, loss: 0.11005109548568726
step: 710, loss: 0.07913802564144135
step: 720, loss: 0.016272513195872307
step: 730, loss: 0.07839774340391159
step: 740, loss: 0.006762751378118992
step: 750, loss: 0.1312403827905655
step: 760, loss: 0.047471754252910614
step: 770, loss: 0.029163355007767677
step: 780, loss: 0.02165842615067959
step: 790, loss: 0.1182360127568245
step: 800, loss: 0.06150702014565468
step: 810, loss: 0.0317375510931015
step: 820, loss: 0.057246092706918716
step: 830, loss: 0.026367928832769394
step: 840, loss: 0.02565789595246315
step: 850, loss: 0.06150096282362938
step: 860, loss: 0.17266742885112762
step: 870, loss: 0.04986371099948883
step: 880, loss: 0.15511557459831238
step: 890, loss: 0.08401000499725342
step: 900, loss: 0.06240434944629669
step: 910, loss: 0.0742160826921463
step: 920, loss: 0.05796355381608009
step: 930, loss: 0.08596392720937729
step: 940, loss: 0.17752321064472198
step: 950, loss: 0.023273317143321037
step: 960, loss: 0.08944673836231232
step: 970, loss: 0.03236346319317818
epoch 6: dev_f1=0.933826931975937, f1=0.9372384937238494, best_f1=0.9401631912964642
step: 0, loss: 0.015252338722348213
step: 10, loss: 0.021287333220243454
step: 20, loss: 0.04943506419658661
step: 30, loss: 0.0038173352368175983
step: 40, loss: 0.010461662895977497
step: 50, loss: 0.024935252964496613
step: 60, loss: 0.03236732631921768
step: 70, loss: 0.010133356787264347
step: 80, loss: 0.05198075994849205
step: 90, loss: 0.014827070757746696
step: 100, loss: 0.08145716786384583
step: 110, loss: 0.07975780963897705
step: 120, loss: 0.019549045711755753
step: 130, loss: 0.030143728479743004
step: 140, loss: 0.11920291930437088
step: 150, loss: 0.04332137480378151
step: 160, loss: 0.06846628338098526
step: 170, loss: 0.0814894437789917
step: 180, loss: 0.0208513792604208
step: 190, loss: 0.07063763588666916
step: 200, loss: 0.13168269395828247
step: 210, loss: 0.008842875249683857
step: 220, loss: 0.07018471509218216
step: 230, loss: 0.04831569641828537
step: 240, loss: 0.04729008674621582
step: 250, loss: 0.05994703248143196
step: 260, loss: 0.02383800595998764
step: 270, loss: 0.048834532499313354
step: 280, loss: 0.030154723674058914
step: 290, loss: 0.07091791927814484
step: 300, loss: 0.15476137399673462
step: 310, loss: 0.008304673247039318
step: 320, loss: 0.047554973512887955
step: 330, loss: 0.060854751616716385
step: 340, loss: 0.04152451083064079
step: 350, loss: 0.03468630090355873
step: 360, loss: 0.08803215622901917
step: 370, loss: 0.16620180010795593
step: 380, loss: 0.02363724634051323
step: 390, loss: 0.12536726891994476
step: 400, loss: 0.08187977224588394
step: 410, loss: 0.08267202973365784
step: 420, loss: 0.11471295356750488
step: 430, loss: 0.06619542092084885
step: 440, loss: 0.015016659162938595
step: 450, loss: 0.011788103729486465
step: 460, loss: 0.004484782461076975
step: 470, loss: 0.138779416680336
step: 480, loss: 0.022908855229616165
step: 490, loss: 0.0524543821811676
step: 500, loss: 0.019948985427618027
step: 510, loss: 0.07174332439899445
step: 520, loss: 0.0677867904305458
step: 530, loss: 0.204010009765625
step: 540, loss: 0.032836489379405975
step: 550, loss: 0.0321633517742157
step: 560, loss: 0.012606825679540634
step: 570, loss: 0.1324981153011322
step: 580, loss: 0.0345437154173851
step: 590, loss: 0.020020650699734688
step: 600, loss: 0.08003641664981842
step: 610, loss: 0.023472120985388756
step: 620, loss: 0.0881517305970192
step: 630, loss: 0.015564887784421444
step: 640, loss: 0.23199310898780823
step: 650, loss: 0.021986091509461403
step: 660, loss: 0.03152521699666977
step: 670, loss: 0.0689115896821022
step: 680, loss: 0.09465903788805008
step: 690, loss: 0.029071547091007233
step: 700, loss: 0.022618331015110016
step: 710, loss: 0.0677550733089447
step: 720, loss: 0.07602911442518234
step: 730, loss: 0.055434152483940125
step: 740, loss: 0.013765114359557629
step: 750, loss: 0.09683096408843994
step: 760, loss: 0.03360583633184433
step: 770, loss: 0.011763760820031166
step: 780, loss: 0.08000535517930984
step: 790, loss: 0.08398330956697464
step: 800, loss: 0.043913714587688446
step: 810, loss: 0.1793334037065506
step: 820, loss: 0.027580706402659416
step: 830, loss: 0.08488530665636063
step: 840, loss: 0.03756663203239441
step: 850, loss: 0.06370825320482254
step: 860, loss: 0.07718532532453537
step: 870, loss: 0.19670289754867554
step: 880, loss: 0.05051610618829727
step: 890, loss: 0.018204674124717712
step: 900, loss: 0.02352188155055046
step: 910, loss: 0.09006617218255997
step: 920, loss: 0.1296577900648117
step: 930, loss: 0.09466423839330673
step: 940, loss: 0.05394163355231285
step: 950, loss: 0.07397270947694778
step: 960, loss: 0.18485885858535767
step: 970, loss: 0.06789053231477737
epoch 7: dev_f1=0.9340054995417048, f1=0.9310027598896043, best_f1=0.9401631912964642
step: 0, loss: 0.1094641387462616
step: 10, loss: 0.1385742872953415
step: 20, loss: 0.0725465640425682
step: 30, loss: 0.0029028092976659536
step: 40, loss: 0.03938513994216919
step: 50, loss: 0.03959269821643829
step: 60, loss: 0.06929261237382889
step: 70, loss: 0.07867537438869476
step: 80, loss: 0.01849946938455105
step: 90, loss: 0.057317279279232025
step: 100, loss: 0.01864594779908657
step: 110, loss: 0.019734065979719162
step: 120, loss: 0.07334446161985397
step: 130, loss: 0.12526445090770721
step: 140, loss: 0.10394654422998428
step: 150, loss: 0.03844066709280014
step: 160, loss: 0.02142646349966526
step: 170, loss: 0.160121351480484
step: 180, loss: 0.05847682058811188
step: 190, loss: 0.011181415058672428
step: 200, loss: 0.012650829739868641
step: 210, loss: 0.084721140563488
step: 220, loss: 0.022517893463373184
step: 230, loss: 0.14706625044345856
step: 240, loss: 0.05636592209339142
step: 250, loss: 0.011072907596826553
step: 260, loss: 0.1436174362897873
step: 270, loss: 0.06649269908666611
step: 280, loss: 0.038225699216127396
step: 290, loss: 0.08476684987545013
step: 300, loss: 0.028966408222913742
step: 310, loss: 0.006509267725050449
step: 320, loss: 0.018053457140922546
step: 330, loss: 0.051707033067941666
step: 340, loss: 0.1406255066394806
step: 350, loss: 0.13939876854419708
step: 360, loss: 0.03994249179959297
step: 370, loss: 0.056868698447942734
step: 380, loss: 0.032650042325258255
step: 390, loss: 0.06800296157598495
step: 400, loss: 0.15136981010437012
step: 410, loss: 0.036437202244997025
step: 420, loss: 0.009528158232569695
step: 430, loss: 0.10022740811109543
step: 440, loss: 0.0578494593501091
step: 450, loss: 0.06868082284927368
step: 460, loss: 0.27094367146492004
step: 470, loss: 0.05149078369140625
step: 480, loss: 0.08405082672834396
step: 490, loss: 0.08772658556699753
step: 500, loss: 0.011025197803974152
step: 510, loss: 0.010507292114198208
step: 520, loss: 0.09761346131563187
step: 530, loss: 0.09830127656459808
step: 540, loss: 0.13120341300964355
step: 550, loss: 0.003269611392170191
step: 560, loss: 0.0052755470387637615
step: 570, loss: 0.029083067551255226
step: 580, loss: 0.058779530227184296
step: 590, loss: 0.032737649977207184
step: 600, loss: 0.08116400241851807
step: 610, loss: 0.032696813344955444
step: 620, loss: 0.011449369601905346
step: 630, loss: 0.016727466136217117
step: 640, loss: 0.08209998905658722
step: 650, loss: 0.06069859117269516
step: 660, loss: 0.05138978362083435
step: 670, loss: 0.08433395624160767
step: 680, loss: 0.03774401545524597
step: 690, loss: 0.10009198635816574
step: 700, loss: 0.053972452878952026
step: 710, loss: 0.0774460881948471
step: 720, loss: 0.07206703722476959
step: 730, loss: 0.07465440034866333
step: 740, loss: 0.1304645836353302
step: 750, loss: 0.011661208234727383
step: 760, loss: 0.008305678144097328
step: 770, loss: 0.013125723227858543
step: 780, loss: 0.10308999568223953
step: 790, loss: 0.009705283679068089
step: 800, loss: 0.18100892007350922
step: 810, loss: 0.12876065075397491
step: 820, loss: 0.028156530112028122
step: 830, loss: 0.08212403953075409
step: 840, loss: 0.05667426809668541
step: 850, loss: 0.06859302520751953
step: 860, loss: 0.014649259857833385
step: 870, loss: 0.02543986402451992
step: 880, loss: 0.08784861862659454
step: 890, loss: 0.08340732753276825
step: 900, loss: 0.042162179946899414
step: 910, loss: 0.02781163528561592
step: 920, loss: 0.10270656645298004
step: 930, loss: 0.1062529981136322
step: 940, loss: 0.04816646873950958
step: 950, loss: 0.0090212756767869
step: 960, loss: 0.08026483654975891
step: 970, loss: 0.1371408998966217
epoch 8: dev_f1=0.9349555451567618, f1=0.9396914446002805, best_f1=0.9401631912964642
step: 0, loss: 0.019462263211607933
step: 10, loss: 0.009919298812747002
step: 20, loss: 0.023876620456576347
step: 30, loss: 0.011426671408116817
step: 40, loss: 0.19415968656539917
step: 50, loss: 0.07591625303030014
step: 60, loss: 0.07700826227664948
step: 70, loss: 0.06004451587796211
step: 80, loss: 0.028255779296159744
step: 90, loss: 0.010279118083417416
step: 100, loss: 0.013013932853937149
step: 110, loss: 0.05716807767748833
step: 120, loss: 0.04261225461959839
step: 130, loss: 6.582452624570578e-05
step: 140, loss: 0.06363844871520996
step: 150, loss: 0.01784580945968628
step: 160, loss: 0.04663057625293732
step: 170, loss: 0.07814270257949829
step: 180, loss: 0.02780960127711296
step: 190, loss: 0.052632030099630356
step: 200, loss: 0.12874716520309448
step: 210, loss: 0.08300577849149704
step: 220, loss: 0.29939836263656616
step: 230, loss: 0.05110061541199684
step: 240, loss: 0.08302325755357742
step: 250, loss: 0.04108986631035805
step: 260, loss: 0.0019817808642983437
step: 270, loss: 0.042719174176454544
step: 280, loss: 0.14494416117668152
step: 290, loss: 0.008481127209961414
step: 300, loss: 0.15803825855255127
step: 310, loss: 0.011472047306597233
step: 320, loss: 0.005651144310832024
step: 330, loss: 0.06741132587194443
step: 340, loss: 0.11506807804107666
step: 350, loss: 0.033529095351696014
step: 360, loss: 0.014492891728878021
step: 370, loss: 0.03253895044326782
step: 380, loss: 0.017551615834236145
step: 390, loss: 0.10066552460193634
step: 400, loss: 0.019768429920077324
step: 410, loss: 0.009517813101410866
step: 420, loss: 0.03244919702410698
step: 430, loss: 0.007112666964530945
step: 440, loss: 0.12725569307804108
step: 450, loss: 0.09072156995534897
step: 460, loss: 0.057042475789785385
step: 470, loss: 0.040008094161748886
step: 480, loss: 0.02847619168460369
step: 490, loss: 0.03998015820980072
step: 500, loss: 0.07888368517160416
step: 510, loss: 0.14114969968795776
step: 520, loss: 0.02299950271844864
step: 530, loss: 0.11886826157569885
step: 540, loss: 0.040496814996004105
step: 550, loss: 0.09821099787950516
step: 560, loss: 0.003596995258703828
step: 570, loss: 0.04955581575632095
step: 580, loss: 0.01438995636999607
step: 590, loss: 0.16268455982208252
step: 600, loss: 0.040598608553409576
step: 610, loss: 0.14397448301315308
step: 620, loss: 0.049545567482709885
step: 630, loss: 8.145502215484157e-05
step: 640, loss: 0.03373020514845848
step: 650, loss: 0.014448079280555248
step: 660, loss: 0.08734063804149628
step: 670, loss: 0.009494442492723465
step: 680, loss: 0.07896596938371658
step: 690, loss: 0.02957446686923504
step: 700, loss: 0.04837723821401596
step: 710, loss: 0.040772486478090286
step: 720, loss: 0.13304530084133148
step: 730, loss: 0.12885919213294983
step: 740, loss: 0.08355334401130676
step: 750, loss: 0.08889783918857574
step: 760, loss: 0.04650961607694626
step: 770, loss: 0.034253135323524475
step: 780, loss: 0.017535675317049026
step: 790, loss: 0.012383961118757725
step: 800, loss: 0.00881953164935112
step: 810, loss: 0.07707386463880539
step: 820, loss: 0.08922640979290009
step: 830, loss: 0.00949285738170147
step: 840, loss: 0.05993391573429108
step: 850, loss: 0.0120499636977911
step: 860, loss: 0.1055002212524414
step: 870, loss: 0.09300220757722855
step: 880, loss: 0.014018178917467594
step: 890, loss: 0.020838920027017593
step: 900, loss: 0.016074135899543762
step: 910, loss: 0.18944360315799713
step: 920, loss: 0.09467185288667679
step: 930, loss: 0.06020267307758331
step: 940, loss: 0.07834446430206299
step: 950, loss: 0.09126388281583786
step: 960, loss: 0.012744836509227753
step: 970, loss: 0.03044847957789898
epoch 9: dev_f1=0.9310661764705882, f1=0.9315693430656934, best_f1=0.9401631912964642
step: 0, loss: 0.06865061074495316
step: 10, loss: 0.06039047986268997
step: 20, loss: 0.07278431206941605
step: 30, loss: 0.022496048361063004
step: 40, loss: 0.13017065823078156
step: 50, loss: 0.0067195226438343525
step: 60, loss: 0.07240049540996552
step: 70, loss: 0.02301703579723835
step: 80, loss: 0.05962260439991951
step: 90, loss: 0.00830111000686884
step: 100, loss: 0.013183314353227615
step: 110, loss: 0.06655706465244293
step: 120, loss: 0.005100809969007969
step: 130, loss: 0.03421474248170853
step: 140, loss: 0.03541658818721771
step: 150, loss: 0.028849052265286446
step: 160, loss: 0.052057672291994095
step: 170, loss: 0.09156735241413116
step: 180, loss: 0.0054326895624399185
step: 190, loss: 0.008162970654666424
step: 200, loss: 0.1505252718925476
step: 210, loss: 0.04892391711473465
step: 220, loss: 0.1142096221446991
step: 230, loss: 0.05047985166311264
step: 240, loss: 0.06222059950232506
step: 250, loss: 0.07614217698574066
step: 260, loss: 0.07182136923074722
step: 270, loss: 0.07579878717660904
step: 280, loss: 0.06166359409689903
step: 290, loss: 0.15578503906726837
step: 300, loss: 0.026763085275888443
step: 310, loss: 0.14223286509513855
step: 320, loss: 0.008872504346072674
step: 330, loss: 0.051420439034700394
step: 340, loss: 0.05819423124194145
step: 350, loss: 0.0954628512263298
step: 360, loss: 0.014350643381476402
step: 370, loss: 0.010068112052977085
step: 380, loss: 0.026665665209293365
step: 390, loss: 0.06960731744766235
step: 400, loss: 0.05955664440989494
step: 410, loss: 0.014286218211054802
step: 420, loss: 0.028004106134176254
step: 430, loss: 0.018856776878237724
step: 440, loss: 0.011896993964910507
step: 450, loss: 0.06777006387710571
step: 460, loss: 0.020548978820443153
step: 470, loss: 0.023334180936217308
step: 480, loss: 0.0036077063996344805
step: 490, loss: 0.020867541432380676
step: 500, loss: 0.013069084845483303
step: 510, loss: 0.06375367939472198
step: 520, loss: 0.11031999439001083
step: 530, loss: 0.046060480177402496
step: 540, loss: 0.00652284687384963
step: 550, loss: 0.0152587890625
step: 560, loss: 0.028195902705192566
step: 570, loss: 0.029169520363211632
step: 580, loss: 0.04946047440171242
step: 590, loss: 0.04945937171578407
step: 600, loss: 0.008230479434132576
step: 610, loss: 0.009080620482563972
step: 620, loss: 0.05308675765991211
step: 630, loss: 0.024055806919932365
step: 640, loss: 0.0009644711390137672
step: 650, loss: 0.07225608080625534
step: 660, loss: 0.0066096363589167595
step: 670, loss: 0.04439018294215202
step: 680, loss: 0.09742920100688934
step: 690, loss: 0.051441047340631485
step: 700, loss: 0.019921930506825447
step: 710, loss: 0.016495294868946075
step: 720, loss: 0.04144342988729477
step: 730, loss: 0.026849431917071342
step: 740, loss: 0.14866316318511963
step: 750, loss: 0.04376187175512314
step: 760, loss: 0.05724103003740311
step: 770, loss: 0.04786314815282822
step: 780, loss: 0.004260274115949869
step: 790, loss: 0.11316407471895218
step: 800, loss: 0.02795713022351265
step: 810, loss: 0.06334950029850006
step: 820, loss: 0.052881982177495956
step: 830, loss: 0.06629112362861633
step: 840, loss: 0.05332604795694351
step: 850, loss: 0.047414589673280716
step: 860, loss: 0.09360047429800034
step: 870, loss: 0.02164553664624691
step: 880, loss: 0.07593228667974472
step: 890, loss: 0.0719170868396759
step: 900, loss: 0.14050252735614777
step: 910, loss: 0.1275661438703537
step: 920, loss: 0.04405215010046959
step: 930, loss: 0.10115575045347214
step: 940, loss: 0.08381183445453644
step: 950, loss: 0.07183133810758591
step: 960, loss: 0.0649111270904541
step: 970, loss: 0.0014094267971813679
epoch 10: dev_f1=0.9318497913769124, f1=0.9247808029533918, best_f1=0.9401631912964642
step: 0, loss: 0.10203535109758377
step: 10, loss: 0.16782528162002563
step: 20, loss: 0.02945040538907051
step: 30, loss: 0.002291060984134674
step: 40, loss: 0.012447218410670757
step: 50, loss: 0.048773571848869324
step: 60, loss: 0.02161947265267372
step: 70, loss: 0.01098223589360714
step: 80, loss: 0.07107013463973999
step: 90, loss: 0.10129629820585251
step: 100, loss: 0.09850070625543594
step: 110, loss: 0.057189177721738815
step: 120, loss: 0.0820150077342987
step: 130, loss: 0.024815402925014496
step: 140, loss: 0.09525638073682785
step: 150, loss: 0.1000855416059494
step: 160, loss: 0.022347435355186462
step: 170, loss: 0.09185326844453812
step: 180, loss: 0.11198550462722778
step: 190, loss: 0.001625126926228404
step: 200, loss: 0.008869149722158909
step: 210, loss: 0.10538776218891144
step: 220, loss: 0.018879415467381477
step: 230, loss: 0.12246854603290558
step: 240, loss: 0.06483636796474457
step: 250, loss: 0.044808853417634964
step: 260, loss: 0.00037626063567586243
step: 270, loss: 0.03639650717377663
step: 280, loss: 0.05146380886435509
step: 290, loss: 0.015647368505597115
step: 300, loss: 0.004085374530404806
step: 310, loss: 0.052950795739889145
step: 320, loss: 0.013051253743469715
step: 330, loss: 0.07636868208646774
step: 340, loss: 0.037688083946704865
step: 350, loss: 0.005141015164554119
step: 360, loss: 0.08318625390529633
step: 370, loss: 0.02834613248705864
step: 380, loss: 0.017254548147320747
step: 390, loss: 0.056096676737070084
step: 400, loss: 0.07436888664960861
step: 410, loss: 0.04187672212719917
step: 420, loss: 0.01387616153806448
step: 430, loss: 0.0069113438948988914
step: 440, loss: 0.05365382134914398
step: 450, loss: 0.14677467942237854
step: 460, loss: 0.04924088716506958
step: 470, loss: 0.027956118807196617
step: 480, loss: 0.002598909894004464
step: 490, loss: 0.019264444708824158
step: 500, loss: 0.18117928504943848
step: 510, loss: 0.03664598986506462
step: 520, loss: 0.050998006016016006
step: 530, loss: 0.0546526163816452
step: 540, loss: 0.14535564184188843
step: 550, loss: 0.011809039860963821
step: 560, loss: 0.052683062851428986
step: 570, loss: 0.15676039457321167
step: 580, loss: 0.09277781844139099
step: 590, loss: 0.003402562579140067
step: 600, loss: 0.12471523880958557
step: 610, loss: 0.01376563310623169
step: 620, loss: 0.07033348828554153
step: 630, loss: 0.06899168342351913
step: 640, loss: 0.009186655282974243
step: 650, loss: 0.06530428677797318
step: 660, loss: 0.024667825549840927
step: 670, loss: 0.028016678988933563
step: 680, loss: 0.012625571340322495
step: 690, loss: 0.08291181921958923
step: 700, loss: 0.022183312103152275
step: 710, loss: 0.015316181816160679
step: 720, loss: 0.0879783183336258
step: 730, loss: 0.07722248136997223
step: 740, loss: 0.015270336531102657
step: 750, loss: 0.06687186658382416
step: 760, loss: 0.06517193466424942
step: 770, loss: 0.0393156036734581
step: 780, loss: 0.0020006373524665833
step: 790, loss: 0.04451369866728783
step: 800, loss: 0.06797367334365845
step: 810, loss: 0.05925242602825165
step: 820, loss: 0.1226893812417984
step: 830, loss: 0.00653921440243721
step: 840, loss: 0.008925624191761017
step: 850, loss: 0.10679584741592407
step: 860, loss: 0.09869718551635742
step: 870, loss: 0.056775838136672974
step: 880, loss: 0.029902059584856033
step: 890, loss: 0.0530514270067215
step: 900, loss: 0.03150148689746857
step: 910, loss: 0.04213927686214447
step: 920, loss: 0.0548960380256176
step: 930, loss: 0.04770546406507492
step: 940, loss: 0.0039423503912985325
step: 950, loss: 0.012676673009991646
step: 960, loss: 0.07014473527669907
step: 970, loss: 0.12912093102931976
epoch 11: dev_f1=0.9327731092436975, f1=0.9285051067780873, best_f1=0.9401631912964642
step: 0, loss: 0.050110653042793274
step: 10, loss: 0.1559249311685562
step: 20, loss: 0.10660645365715027
step: 30, loss: 0.010752737522125244
step: 40, loss: 0.01431642472743988
step: 50, loss: 0.079164057970047
step: 60, loss: 0.0029635634273290634
step: 70, loss: 0.008025206625461578
step: 80, loss: 0.04094354808330536
step: 90, loss: 0.03860891982913017
step: 100, loss: 0.04804664105176926
step: 110, loss: 0.00693487236276269
step: 120, loss: 0.004502248018980026
step: 130, loss: 0.03371620923280716
step: 140, loss: 0.016860151663422585
step: 150, loss: 0.016356363892555237
step: 160, loss: 0.034558627754449844
step: 170, loss: 0.0023319877218455076
step: 180, loss: 0.04315689206123352
step: 190, loss: 0.07481854408979416
step: 200, loss: 0.028119556605815887
step: 210, loss: 0.011524200439453125
step: 220, loss: 0.04554324224591255
step: 230, loss: 0.00696074403822422
step: 240, loss: 0.0063073597848415375
step: 250, loss: 0.03923103213310242
step: 260, loss: 0.0017912737093865871
step: 270, loss: 0.016345204785466194
step: 280, loss: 0.07449935376644135
step: 290, loss: 0.013587424531579018
step: 300, loss: 0.1159992441534996
step: 310, loss: 0.006661619991064072
step: 320, loss: 0.07177863270044327
step: 330, loss: 0.023941706866025925
step: 340, loss: 0.0016132951714098454
step: 350, loss: 0.025281038135290146
step: 360, loss: 0.06573671847581863
step: 370, loss: 0.01742432452738285
step: 380, loss: 0.06431359052658081
step: 390, loss: 0.02645050175487995
step: 400, loss: 0.0384865365922451
step: 410, loss: 0.026163587346673012
step: 420, loss: 0.011244675144553185
step: 430, loss: 0.10781214386224747
step: 440, loss: 0.1007966548204422
step: 450, loss: 0.042148489505052567
step: 460, loss: 0.023734048008918762
step: 470, loss: 0.08558367192745209
step: 480, loss: 0.032560743391513824
step: 490, loss: 0.23339998722076416
step: 500, loss: 0.02188776060938835
step: 510, loss: 0.04680598899722099
step: 520, loss: 0.025507401674985886
step: 530, loss: 0.07225103676319122
step: 540, loss: 0.03847340866923332
step: 550, loss: 0.0581965334713459
step: 560, loss: 0.040482450276613235
step: 570, loss: 0.04821231961250305
step: 580, loss: 0.005942914634943008
step: 590, loss: 0.008652818389236927
step: 600, loss: 0.05569916591048241
step: 610, loss: 0.04272250086069107
step: 620, loss: 0.008533623069524765
step: 630, loss: 0.014026306569576263
step: 640, loss: 0.015051497146487236
step: 650, loss: 0.03171281889081001
step: 660, loss: 0.028043972328305244
step: 670, loss: 0.07453257590532303
step: 680, loss: 0.03339660167694092
step: 690, loss: 0.08153099566698074
step: 700, loss: 0.008543380536139011
step: 710, loss: 0.000798237684648484
step: 720, loss: 0.029163111001253128
step: 730, loss: 0.02040887251496315
step: 740, loss: 0.047436654567718506
step: 750, loss: 0.10213412344455719
step: 760, loss: 0.0009767896262928843
step: 770, loss: 0.023045668378472328
step: 780, loss: 0.05349572002887726
step: 790, loss: 0.01343489345163107
step: 800, loss: 0.041913170367479324
step: 810, loss: 0.08967000991106033
step: 820, loss: 0.06063573807477951
step: 830, loss: 0.053296178579330444
step: 840, loss: 0.027878154069185257
step: 850, loss: 0.006396006792783737
step: 860, loss: 0.018802747130393982
step: 870, loss: 0.08686234056949615
step: 880, loss: 0.04208717867732048
step: 890, loss: 0.0527186319231987
step: 900, loss: 0.020022422075271606
step: 910, loss: 0.052022580057382584
step: 920, loss: 0.04896632581949234
step: 930, loss: 0.014410292729735374
step: 940, loss: 0.09290220588445663
step: 950, loss: 0.1674714982509613
step: 960, loss: 0.017345672473311424
step: 970, loss: 0.16604630649089813
epoch 12: dev_f1=0.9357541899441341, f1=0.931975937066173, best_f1=0.9401631912964642
step: 0, loss: 0.0131301274523139
step: 10, loss: 0.0036282744258642197
step: 20, loss: 0.06407950073480606
step: 30, loss: 0.001713485224172473
step: 40, loss: 0.03884384408593178
step: 50, loss: 0.0384657047688961
step: 60, loss: 0.0012420940911397338
step: 70, loss: 0.03561156243085861
step: 80, loss: 0.01661626435816288
step: 90, loss: 0.027684230357408524
step: 100, loss: 0.029681285843253136
step: 110, loss: 0.030921876430511475
step: 120, loss: 0.06778999418020248
step: 130, loss: 0.01093401201069355
step: 140, loss: 0.017525576055049896
step: 150, loss: 0.033299315720796585
step: 160, loss: 0.005977040156722069
step: 170, loss: 0.011789171025156975
step: 180, loss: 0.1325739175081253
step: 190, loss: 0.02748650684952736
step: 200, loss: 0.019885336980223656
step: 210, loss: 0.03223134204745293
step: 220, loss: 0.04433680698275566
step: 230, loss: 0.02516952157020569
step: 240, loss: 0.03117433935403824
step: 250, loss: 0.0006575841107405722
step: 260, loss: 0.08579433709383011
step: 270, loss: 0.09596586972475052
step: 280, loss: 0.007355681620538235
step: 290, loss: 0.0585651695728302
step: 300, loss: 0.024134313687682152
step: 310, loss: 0.04799414053559303
step: 320, loss: 0.0021127075888216496
step: 330, loss: 0.04102817550301552
step: 340, loss: 0.0010382655309513211
step: 350, loss: 0.02635917440056801
step: 360, loss: 0.06907837837934494
step: 370, loss: 0.1817629635334015
step: 380, loss: 0.13338835537433624
step: 390, loss: 0.03313427418470383
step: 400, loss: 0.09169727563858032
step: 410, loss: 0.023808885365724564
step: 420, loss: 0.05934794992208481
step: 430, loss: 0.0294941496104002
step: 440, loss: 0.0635216161608696
step: 450, loss: 0.1333719789981842
step: 460, loss: 0.039123691618442535
step: 470, loss: 0.12156537920236588
step: 480, loss: 0.0030736057087779045
step: 490, loss: 0.14786148071289062
step: 500, loss: 0.049343232065439224
step: 510, loss: 0.1391015201807022
step: 520, loss: 0.029312171041965485
step: 530, loss: 0.007908964529633522
step: 540, loss: 0.03123428113758564
step: 550, loss: 0.003729193238541484
step: 560, loss: 0.10860846191644669
step: 570, loss: 0.09701934456825256
step: 580, loss: 0.04638483375310898
step: 590, loss: 0.025996675714850426
step: 600, loss: 0.09099732339382172
step: 610, loss: 0.049694351851940155
step: 620, loss: 0.035916518419981
step: 630, loss: 0.032561250030994415
step: 640, loss: 0.027820678427815437
step: 650, loss: 0.025015877559781075
step: 660, loss: 0.09645254909992218
step: 670, loss: 0.08140034973621368
step: 680, loss: 0.027903806418180466
step: 690, loss: 0.05109237879514694
step: 700, loss: 0.048048436641693115
step: 710, loss: 0.05364932119846344
step: 720, loss: 0.03975963220000267
step: 730, loss: 0.08963075280189514
step: 740, loss: 0.08307866752147675
step: 750, loss: 0.019319729879498482
step: 760, loss: 0.05732518434524536
step: 770, loss: 0.060156211256980896
step: 780, loss: 0.013976826332509518
step: 790, loss: 0.003018115647137165
step: 800, loss: 0.04113359376788139
step: 810, loss: 0.07914024591445923
step: 820, loss: 0.046403612941503525
step: 830, loss: 0.019213702529668808
step: 840, loss: 0.053942710161209106
step: 850, loss: 0.009948504157364368
step: 860, loss: 0.07802998274564743
step: 870, loss: 0.02893855981528759
step: 880, loss: 0.1495790183544159
step: 890, loss: 0.027635231614112854
step: 900, loss: 0.00203882297500968
step: 910, loss: 0.0001304811448790133
step: 920, loss: 0.030284037813544273
step: 930, loss: 0.029065527021884918
step: 940, loss: 0.04890630394220352
step: 950, loss: 0.03539247065782547
step: 960, loss: 0.04540703073143959
step: 970, loss: 0.0005928024183958769
epoch 13: dev_f1=0.9341317365269461, f1=0.9308924485125859, best_f1=0.9401631912964642
step: 0, loss: 0.005784305743873119
step: 10, loss: 0.015481899492442608
step: 20, loss: 0.06602610647678375
step: 30, loss: 0.026840558275580406
step: 40, loss: 0.000856425438541919
step: 50, loss: 0.00196458981372416
step: 60, loss: 0.016464263200759888
step: 70, loss: 0.00803580041974783
step: 80, loss: 0.023334752768278122
step: 90, loss: 0.011108667589724064
step: 100, loss: 0.02697736769914627
step: 110, loss: 0.02514750510454178
step: 120, loss: 0.0810108631849289
step: 130, loss: 0.012618421576917171
step: 140, loss: 0.027887942269444466
step: 150, loss: 0.010753455571830273
step: 160, loss: 0.019171463325619698
step: 170, loss: 0.005482344422489405
step: 180, loss: 0.07007607072591782
step: 190, loss: 0.11381303519010544
step: 200, loss: 0.06266245245933533
step: 210, loss: 0.05599493160843849
step: 220, loss: 0.00688012782484293
step: 230, loss: 0.23612266778945923
step: 240, loss: 0.08046489208936691
step: 250, loss: 0.0186623502522707
step: 260, loss: 0.0052643646486103535
step: 270, loss: 0.00616312213242054
step: 280, loss: 0.06096209958195686
step: 290, loss: 0.017294734716415405
step: 300, loss: 0.03637734428048134
step: 310, loss: 0.007486213464289904
step: 320, loss: 0.004603129345923662
step: 330, loss: 9.618219337426126e-05
step: 340, loss: 0.05966867133975029
step: 350, loss: 0.024048149585723877
step: 360, loss: 0.01543766912072897
step: 370, loss: 0.0029193158261477947
step: 380, loss: 0.03361371159553528
step: 390, loss: 0.02825390174984932
step: 400, loss: 0.034537240862846375
step: 410, loss: 0.01659214124083519
step: 420, loss: 0.03718211501836777
step: 430, loss: 0.08446161448955536
step: 440, loss: 0.11928797513246536
step: 450, loss: 0.008160771802067757
step: 460, loss: 0.06242362782359123
step: 470, loss: 0.0018207387765869498
step: 480, loss: 0.020299173891544342
step: 490, loss: 0.0019444245845079422
step: 500, loss: 0.032108016312122345
step: 510, loss: 0.021796517074108124
step: 520, loss: 0.010228486731648445
step: 530, loss: 0.03150595352053642
step: 540, loss: 0.08523794263601303
step: 550, loss: 0.026377059519290924
step: 560, loss: 0.007694566622376442
step: 570, loss: 1.3403434422798455e-05
step: 580, loss: 8.941348642110825e-05
step: 590, loss: 0.044074442237615585
step: 600, loss: 0.033298224210739136
step: 610, loss: 0.0023229222279042006
step: 620, loss: 0.026451803743839264
step: 630, loss: 0.07733973115682602
step: 640, loss: 0.0004252082435414195
step: 650, loss: 0.04527716338634491
step: 660, loss: 0.01569945178925991
step: 670, loss: 0.013974255882203579
step: 680, loss: 0.05524550750851631
step: 690, loss: 2.7950152798439376e-05
step: 700, loss: 0.04199182242155075
step: 710, loss: 0.07257278263568878
step: 720, loss: 0.007366049103438854
step: 730, loss: 0.043107375502586365
step: 740, loss: 0.01332595944404602
step: 750, loss: 0.004062894266098738
step: 760, loss: 0.03108854405581951
step: 770, loss: 0.020956330001354218
step: 780, loss: 0.06008225306868553
step: 790, loss: 0.10743708163499832
step: 800, loss: 0.021619312465190887
step: 810, loss: 0.07134745270013809
step: 820, loss: 0.036822136491537094
step: 830, loss: 0.01869496889412403
step: 840, loss: 0.09114113450050354
step: 850, loss: 0.051339153200387955
step: 860, loss: 0.05168929696083069
step: 870, loss: 6.7940003646072e-05
step: 880, loss: 0.04529082030057907
step: 890, loss: 0.08768164366483688
step: 900, loss: 0.002696709707379341
step: 910, loss: 0.02862759679555893
step: 920, loss: 0.03695623204112053
step: 930, loss: 0.04531465470790863
step: 940, loss: 0.00018894911045208573
step: 950, loss: 0.0058776866644620895
step: 960, loss: 5.957697067060508e-05
step: 970, loss: 0.01682206243276596
epoch 14: dev_f1=0.9335205992509362, f1=0.9269427640763147, best_f1=0.9401631912964642
step: 0, loss: 0.0004085585824213922
step: 10, loss: 0.03944230452179909
step: 20, loss: 0.01116266194730997
step: 30, loss: 0.018507586792111397
step: 40, loss: 2.8173497412353754e-05
step: 50, loss: 5.3452826250577345e-05
step: 60, loss: 0.016879776492714882
step: 70, loss: 0.0227854885160923
step: 80, loss: 0.022105639800429344
step: 90, loss: 0.024142291396856308
step: 100, loss: 0.07275226712226868
step: 110, loss: 0.008551565930247307
step: 120, loss: 0.09311579167842865
step: 130, loss: 0.012540388852357864
step: 140, loss: 0.012078594416379929
step: 150, loss: 0.05849101021885872
step: 160, loss: 0.07935845851898193
step: 170, loss: 0.03412454202771187
step: 180, loss: 0.01803247258067131
step: 190, loss: 0.019688783213496208
step: 200, loss: 0.0196317657828331
step: 210, loss: 0.052170757204294205
step: 220, loss: 0.05711309239268303
step: 230, loss: 0.020877305418252945
step: 240, loss: 0.055888496339321136
step: 250, loss: 0.07432825118303299
step: 260, loss: 0.03746979683637619
step: 270, loss: 0.08040139824151993
step: 280, loss: 0.04156104102730751
step: 290, loss: 0.002397126518189907
step: 300, loss: 0.028850652277469635
step: 310, loss: 0.04226692020893097
step: 320, loss: 0.009935399517416954
step: 330, loss: 0.037977736443281174
step: 340, loss: 0.024513063952326775
step: 350, loss: 0.028450854122638702
step: 360, loss: 0.02183874137699604
step: 370, loss: 0.04961695522069931
step: 380, loss: 0.0067798118107020855
step: 390, loss: 0.022580673918128014
step: 400, loss: 0.09884455800056458
step: 410, loss: 0.019373847171664238
step: 420, loss: 0.022947994992136955
step: 430, loss: 0.03718564286828041
step: 440, loss: 0.0027537632267922163
step: 450, loss: 0.04753890261054039
step: 460, loss: 0.037523992359638214
step: 470, loss: 0.024303914979100227
step: 480, loss: 0.01981750689446926
step: 490, loss: 0.060689251869916916
step: 500, loss: 0.0272926464676857
step: 510, loss: 0.014437167905271053
step: 520, loss: 0.001109238713979721
step: 530, loss: 0.014624361880123615
step: 540, loss: 0.1245950385928154
step: 550, loss: 0.0011911522597074509
step: 560, loss: 0.178678497672081
step: 570, loss: 0.015872467309236526
step: 580, loss: 0.00020727913943119347
step: 590, loss: 0.029593750834465027
step: 600, loss: 0.04809105396270752
step: 610, loss: 0.07707870006561279
step: 620, loss: 0.046429574489593506
step: 630, loss: 0.029998110607266426
step: 640, loss: 0.026945769786834717
step: 650, loss: 0.03615184873342514
step: 660, loss: 0.029313677921891212
step: 670, loss: 0.0008769023697823286
step: 680, loss: 0.046261873096227646
step: 690, loss: 0.08927718549966812
step: 700, loss: 0.020741701126098633
step: 710, loss: 0.052193570882081985
step: 720, loss: 0.10542163997888565
step: 730, loss: 0.1178441196680069
step: 740, loss: 0.04539377987384796
step: 750, loss: 0.005553067196160555
step: 760, loss: 0.058757148683071136
step: 770, loss: 0.03825896605849266
step: 780, loss: 0.04282677173614502
step: 790, loss: 0.048421308398246765
step: 800, loss: 0.01229139044880867
step: 810, loss: 0.04580938443541527
step: 820, loss: 0.0008355443715117872
step: 830, loss: 0.05156697332859039
step: 840, loss: 0.029965290799736977
step: 850, loss: 0.09248482435941696
step: 860, loss: 0.0005247066728770733
step: 870, loss: 0.0017003673128783703
step: 880, loss: 0.06560038030147552
step: 890, loss: 0.03860912099480629
step: 900, loss: 0.012577389366924763
step: 910, loss: 0.028220096603035927
step: 920, loss: 0.04939418286085129
step: 930, loss: 0.06422368437051773
step: 940, loss: 0.03882041200995445
step: 950, loss: 0.048933520913124084
step: 960, loss: 0.028709542006254196
step: 970, loss: 0.06151062995195389
epoch 15: dev_f1=0.9317757009345794, f1=0.9260808926080892, best_f1=0.9401631912964642
step: 0, loss: 0.05242156237363815
step: 10, loss: 0.026431165635585785
step: 20, loss: 0.07269048690795898
step: 30, loss: 0.034772682934999466
step: 40, loss: 0.059200920164585114
step: 50, loss: 0.0686323270201683
step: 60, loss: 0.12436582148075104
step: 70, loss: 7.550785085186362e-05
step: 80, loss: 0.01726362854242325
step: 90, loss: 0.08954856544733047
step: 100, loss: 0.035094402730464935
step: 110, loss: 0.0003002751327585429
step: 120, loss: 0.04496372491121292
step: 130, loss: 0.008991148322820663
step: 140, loss: 0.018359528854489326
step: 150, loss: 0.051947157829999924
step: 160, loss: 1.3444348951452412e-05
step: 170, loss: 0.13619829714298248
step: 180, loss: 0.03127751499414444
step: 190, loss: 0.01841752603650093
step: 200, loss: 0.04650478437542915
step: 210, loss: 0.029650937765836716
step: 220, loss: 0.0461307093501091
step: 230, loss: 0.038058508187532425
step: 240, loss: 0.02586248517036438
step: 250, loss: 0.012762099504470825
step: 260, loss: 8.325293310917914e-05
step: 270, loss: 0.03360431268811226
step: 280, loss: 9.908656647894531e-05
step: 290, loss: 0.02615339495241642
step: 300, loss: 0.0026136692613363266
step: 310, loss: 0.003766485024243593
step: 320, loss: 0.0001603049604455009
step: 330, loss: 0.00032809237018227577
step: 340, loss: 0.06668521463871002
step: 350, loss: 0.04055900126695633
step: 360, loss: 0.0009156421874649823
step: 370, loss: 0.05236544460058212
step: 380, loss: 0.00031901037436909974
step: 390, loss: 0.07293175905942917
step: 400, loss: 0.0763983428478241
step: 410, loss: 0.030779344961047173
step: 420, loss: 0.03885520249605179
step: 430, loss: 0.0015523385955020785
step: 440, loss: 0.13347943127155304
step: 450, loss: 0.023930154740810394
step: 460, loss: 0.04618820548057556
step: 470, loss: 0.0073942462913692
step: 480, loss: 0.012635210528969765
step: 490, loss: 0.016702141612768173
step: 500, loss: 0.06810922920703888
step: 510, loss: 0.015667034313082695
step: 520, loss: 0.03038761578500271
step: 530, loss: 0.09626038372516632
step: 540, loss: 0.007655989844352007
step: 550, loss: 0.04630197584629059
step: 560, loss: 0.018736328929662704
step: 570, loss: 0.02559969574213028
step: 580, loss: 0.05300779640674591
step: 590, loss: 0.0003775769146159291
step: 600, loss: 0.005060288123786449
step: 610, loss: 0.005718437489122152
step: 620, loss: 0.07840251177549362
step: 630, loss: 0.041891131550073624
step: 640, loss: 4.344920671428554e-05
step: 650, loss: 0.00012548381346277893
step: 660, loss: 0.07198481261730194
step: 670, loss: 0.03839632868766785
step: 680, loss: 0.052864618599414825
step: 690, loss: 0.000253234407864511
step: 700, loss: 0.014034926891326904
step: 710, loss: 0.022643402218818665
step: 720, loss: 0.14700362086296082
step: 730, loss: 0.004002488683909178
step: 740, loss: 0.00015575106954202056
step: 750, loss: 0.03137766197323799
step: 760, loss: 0.026227662339806557
step: 770, loss: 0.0856417566537857
step: 780, loss: 0.02814541384577751
step: 790, loss: 0.008591284975409508
step: 800, loss: 0.020378023386001587
step: 810, loss: 0.018589120358228683
step: 820, loss: 0.0867810845375061
step: 830, loss: 0.0015281358500942588
step: 840, loss: 0.00011547360918484628
step: 850, loss: 0.026189081370830536
step: 860, loss: 0.024156775325536728
step: 870, loss: 0.023319728672504425
step: 880, loss: 0.08024627715349197
step: 890, loss: 0.042575154453516006
step: 900, loss: 0.08773384243249893
step: 910, loss: 0.01746481843292713
step: 920, loss: 0.023023976013064384
step: 930, loss: 0.036179956048727036
step: 940, loss: 0.02217257395386696
step: 950, loss: 0.04476860538125038
step: 960, loss: 0.0063961525447666645
step: 970, loss: 0.06390749663114548
epoch 16: dev_f1=0.9317757009345794, f1=0.9258049463369109, best_f1=0.9401631912964642
step: 0, loss: 0.04550546407699585
step: 10, loss: 0.017694838345050812
step: 20, loss: 0.08415375649929047
step: 30, loss: 0.030858388170599937
step: 40, loss: 1.9496577806421556e-05
step: 50, loss: 0.029025249183177948
step: 60, loss: 0.07322417944669724
step: 70, loss: 0.022944267839193344
step: 80, loss: 0.023824747651815414
step: 90, loss: 0.009329099208116531
step: 100, loss: 0.040711838752031326
step: 110, loss: 0.02114691026508808
step: 120, loss: 0.009128676727414131
step: 130, loss: 0.022120527923107147
step: 140, loss: 0.03096030466258526
step: 150, loss: 0.04126059263944626
step: 160, loss: 0.0362556055188179
step: 170, loss: 0.0001454606099287048
step: 180, loss: 0.05117226019501686
step: 190, loss: 0.019856885075569153
step: 200, loss: 0.00216937274672091
step: 210, loss: 0.07275468111038208
step: 220, loss: 5.0759637815644965e-05
step: 230, loss: 0.024400921538472176
step: 240, loss: 0.00013241867418400943
step: 250, loss: 0.03552417457103729
step: 260, loss: 0.02065972425043583
step: 270, loss: 0.023620467633008957
step: 280, loss: 0.019690386950969696
step: 290, loss: 0.03797609359025955
step: 300, loss: 0.036564894020557404
step: 310, loss: 0.028839493170380592
step: 320, loss: 0.004868467338383198
step: 330, loss: 0.02458198182284832
step: 340, loss: 0.09031645953655243
step: 350, loss: 0.06573096662759781
step: 360, loss: 0.0008837257046252489
step: 370, loss: 7.607998850289732e-05
step: 380, loss: 0.0003008572675753385
step: 390, loss: 0.00013224694703239948
step: 400, loss: 6.116054282756522e-05
step: 410, loss: 0.010362530127167702
step: 420, loss: 0.017797674983739853
step: 430, loss: 0.024174969643354416
step: 440, loss: 0.07349487394094467
step: 450, loss: 0.08120787888765335
step: 460, loss: 0.053983546793460846
step: 470, loss: 0.027690228074789047
step: 480, loss: 0.07425963133573532
step: 490, loss: 0.0004466028476599604
step: 500, loss: 0.0015876898542046547
step: 510, loss: 0.004956206772476435
step: 520, loss: 0.03149327635765076
step: 530, loss: 0.020426781848073006
step: 540, loss: 0.01771329902112484
step: 550, loss: 0.08467408269643784
step: 560, loss: 0.039313461631536484
step: 570, loss: 0.00010740709694800898
step: 580, loss: 0.022436296567320824
step: 590, loss: 0.018703468143939972
step: 600, loss: 0.014081395231187344
step: 610, loss: 0.04310772567987442
step: 620, loss: 0.06653224676847458
step: 630, loss: 0.0448789969086647
step: 640, loss: 0.04535788297653198
step: 650, loss: 0.10959407687187195
step: 660, loss: 0.05351861193776131
step: 670, loss: 0.013270351104438305
step: 680, loss: 0.01973390206694603
step: 690, loss: 0.02201218530535698
step: 700, loss: 0.039581552147865295
step: 710, loss: 1.2449498171918094e-05
step: 720, loss: 0.05712812393903732
step: 730, loss: 0.0822925791144371
step: 740, loss: 0.06479053944349289
step: 750, loss: 0.05876070261001587
step: 760, loss: 0.012796753086149693
step: 770, loss: 0.047430410981178284
step: 780, loss: 0.03971431776881218
step: 790, loss: 0.014887009747326374
step: 800, loss: 0.08353874832391739
step: 810, loss: 0.0001220781123265624
step: 820, loss: 4.257042019162327e-05
step: 830, loss: 0.014990165829658508
step: 840, loss: 0.02275797165930271
step: 850, loss: 0.016798503696918488
step: 860, loss: 0.018652794882655144
step: 870, loss: 0.0002147608029190451
step: 880, loss: 0.05172840133309364
step: 890, loss: 0.0016706001479178667
step: 900, loss: 0.020386837422847748
step: 910, loss: 0.05119097977876663
step: 920, loss: 0.021963339298963547
step: 930, loss: 0.02186424843966961
step: 940, loss: 0.04656679183244705
step: 950, loss: 0.06578671187162399
step: 960, loss: 0.005840394180268049
step: 970, loss: 0.0004313074459787458
epoch 17: dev_f1=0.9299482839680301, f1=0.9199063231850116, best_f1=0.9401631912964642
step: 0, loss: 0.0022980724461376667
step: 10, loss: 0.032618869096040726
step: 20, loss: 0.016015522181987762
step: 30, loss: 0.021197425201535225
step: 40, loss: 0.07101522386074066
step: 50, loss: 0.026072103530168533
step: 60, loss: 0.04810994490981102
step: 70, loss: 0.00027010554913431406
step: 80, loss: 0.030733125284314156
step: 90, loss: 0.0003022763121407479
step: 100, loss: 0.013521705754101276
step: 110, loss: 0.015757417306303978
step: 120, loss: 2.982224577863235e-05
step: 130, loss: 2.1113333787070587e-05
step: 140, loss: 0.029696453362703323
step: 150, loss: 0.00022781986626796424
step: 160, loss: 0.02508746273815632
step: 170, loss: 0.0716642513871193
step: 180, loss: 0.00011009728768840432
step: 190, loss: 0.02887016534805298
step: 200, loss: 0.06535758078098297
step: 210, loss: 0.026652514934539795
step: 220, loss: 0.01944589614868164
step: 230, loss: 0.026678912341594696
step: 240, loss: 0.0001034879096550867
step: 250, loss: 0.11163628101348877
step: 260, loss: 0.018776414915919304
step: 270, loss: 0.03493186831474304
step: 280, loss: 0.025811661034822464
step: 290, loss: 0.00014928134623914957
step: 300, loss: 0.014369886368513107
step: 310, loss: 0.01441930327564478
step: 320, loss: 0.05743229389190674
step: 330, loss: 0.017679860815405846
step: 340, loss: 0.03715355694293976
step: 350, loss: 0.017246220260858536
step: 360, loss: 0.058161936700344086
step: 370, loss: 0.0003511148097459227
step: 380, loss: 0.04615318030118942
step: 390, loss: 0.0004527433484327048
step: 400, loss: 0.06343799829483032
step: 410, loss: 0.0231005921959877
step: 420, loss: 1.864396472228691e-05
step: 430, loss: 6.11196956015192e-05
step: 440, loss: 0.0008207749342545867
step: 450, loss: 0.01372910849750042
step: 460, loss: 0.04845283180475235
step: 470, loss: 0.027566829696297646
step: 480, loss: 9.890381625154987e-05
step: 490, loss: 0.043031152337789536
step: 500, loss: 0.023756910115480423
step: 510, loss: 0.0006275190971791744
step: 520, loss: 0.0023759808391332626
step: 530, loss: 0.0008290643454529345
step: 540, loss: 0.07980576157569885
step: 550, loss: 0.015054515562951565
step: 560, loss: 2.9590719350380823e-05
step: 570, loss: 9.883079655992333e-06
step: 580, loss: 0.09200108796358109
step: 590, loss: 2.129230233549606e-05
step: 600, loss: 0.03994978591799736
step: 610, loss: 0.0065968395210802555
step: 620, loss: 0.019476572051644325
step: 630, loss: 0.020317433401942253
step: 640, loss: 0.013501720502972603
step: 650, loss: 0.009540109895169735
step: 660, loss: 0.08052055537700653
step: 670, loss: 3.945787830161862e-05
step: 680, loss: 0.03103315643966198
step: 690, loss: 0.018963653594255447
step: 700, loss: 0.025765137746930122
step: 710, loss: 0.02499905414879322
step: 720, loss: 0.0033533775713294744
step: 730, loss: 0.05960870906710625
step: 740, loss: 0.030096765607595444
step: 750, loss: 0.0001420059852534905
step: 760, loss: 0.10752034932374954
step: 770, loss: 0.016622403636574745
step: 780, loss: 0.029483724385499954
step: 790, loss: 0.0184747576713562
step: 800, loss: 0.039646852761507034
step: 810, loss: 0.06809257715940475
step: 820, loss: 0.01861841231584549
step: 830, loss: 0.04762190207839012
step: 840, loss: 0.06788082420825958
step: 850, loss: 8.975948730949312e-05
step: 860, loss: 0.02201414667069912
step: 870, loss: 0.06661967933177948
step: 880, loss: 0.06389559805393219
step: 890, loss: 0.021092964336276054
step: 900, loss: 0.049896787852048874
step: 910, loss: 0.02133590169250965
step: 920, loss: 0.028849946334958076
step: 930, loss: 8.73666867846623e-05
step: 940, loss: 0.062417298555374146
step: 950, loss: 0.1255153864622116
step: 960, loss: 0.04779507964849472
step: 970, loss: 0.1034276932477951
epoch 18: dev_f1=0.9295112781954888, f1=0.9231485794131347, best_f1=0.9401631912964642
step: 0, loss: 0.0003360400442034006
step: 10, loss: 0.09035667777061462
step: 20, loss: 0.0406191386282444
step: 30, loss: 0.043294332921504974
step: 40, loss: 0.04402836412191391
step: 50, loss: 0.06257081776857376
step: 60, loss: 0.05067111924290657
step: 70, loss: 5.8753095800057054e-05
step: 80, loss: 0.025537678971886635
step: 90, loss: 0.1045680046081543
step: 100, loss: 0.05639314651489258
step: 110, loss: 0.002925146371126175
step: 120, loss: 0.015899494290351868
step: 130, loss: 6.0254224081290886e-05
step: 140, loss: 0.04168182611465454
step: 150, loss: 0.02511543035507202
step: 160, loss: 3.133401332888752e-05
step: 170, loss: 0.035200003534555435
step: 180, loss: 0.019307879731059074
step: 190, loss: 0.05825549364089966
step: 200, loss: 0.05486970394849777
step: 210, loss: 0.04845985770225525
step: 220, loss: 0.07134803384542465
step: 230, loss: 3.567119347280823e-05
step: 240, loss: 0.018692681565880775
step: 250, loss: 5.0939954235218465e-05
step: 260, loss: 0.013912309892475605
step: 270, loss: 2.679058707144577e-05
step: 280, loss: 9.048265928868204e-05
step: 290, loss: 9.501653403276578e-05
step: 300, loss: 0.045971278101205826
step: 310, loss: 0.0366959422826767
step: 320, loss: 0.01929486356675625
step: 330, loss: 0.001041055773384869
step: 340, loss: 7.836727309040725e-05
step: 350, loss: 0.006528664380311966
step: 360, loss: 0.06281063705682755
step: 370, loss: 0.025646919384598732
step: 380, loss: 1.3447864148474764e-05
step: 390, loss: 0.12796223163604736
step: 400, loss: 0.017659861594438553
step: 410, loss: 0.010566244833171368
step: 420, loss: 0.09325747191905975
step: 430, loss: 0.05068815499544144
step: 440, loss: 0.01469437312334776
step: 450, loss: 7.089788414305076e-05
step: 460, loss: 0.07026200741529465
step: 470, loss: 0.00012452516239136457
step: 480, loss: 0.0007785562775097787
step: 490, loss: 0.03609514236450195
step: 500, loss: 0.0009636558243073523
step: 510, loss: 0.012991740368306637
step: 520, loss: 0.02346768230199814
step: 530, loss: 2.3228745703818277e-05
step: 540, loss: 0.014920101501047611
step: 550, loss: 0.0016713979421183467
step: 560, loss: 0.05098892003297806
step: 570, loss: 4.9264486733591184e-05
step: 580, loss: 0.01651156321167946
step: 590, loss: 0.0003416889230720699
step: 600, loss: 0.03671835735440254
step: 610, loss: 0.021330105140805244
step: 620, loss: 0.0511966198682785
step: 630, loss: 0.0060576628893613815
step: 640, loss: 0.03261633962392807
step: 650, loss: 0.07814041525125504
step: 660, loss: 0.02357729710638523
step: 670, loss: 0.1124647781252861
step: 680, loss: 0.026064222678542137
step: 690, loss: 0.05235275998711586
step: 700, loss: 0.05240194499492645
step: 710, loss: 0.04181879758834839
step: 720, loss: 0.026742126792669296
step: 730, loss: 0.046761173754930496
step: 740, loss: 7.901301614765543e-06
step: 750, loss: 0.04935155063867569
step: 760, loss: 0.020761806517839432
step: 770, loss: 7.83809955464676e-05
step: 780, loss: 0.05208795890212059
step: 790, loss: 0.03804060444235802
step: 800, loss: 0.0008853922481648624
step: 810, loss: 0.15996244549751282
step: 820, loss: 5.592607340076938e-05
step: 830, loss: 0.019556831568479538
step: 840, loss: 0.026620034128427505
step: 850, loss: 0.058392513543367386
step: 860, loss: 0.036276064813137054
step: 870, loss: 0.02499742992222309
step: 880, loss: 0.055499117821455
step: 890, loss: 0.025549160316586494
step: 900, loss: 0.028950145468115807
step: 910, loss: 0.04197751358151436
step: 920, loss: 0.016379384323954582
step: 930, loss: 0.043215587735176086
step: 940, loss: 0.03110674023628235
step: 950, loss: 0.07106533646583557
step: 960, loss: 0.028044288977980614
step: 970, loss: 0.02230185456573963
epoch 19: dev_f1=0.9301453352086263, f1=0.9237918215613383, best_f1=0.9401631912964642
step: 0, loss: 0.017288465052843094
step: 10, loss: 0.00040025587077252567
step: 20, loss: 0.02382664382457733
step: 30, loss: 0.05415952950716019
step: 40, loss: 0.021637337282299995
step: 50, loss: 0.0210650023072958
step: 60, loss: 0.00036375856143422425
step: 70, loss: 0.04281018301844597
step: 80, loss: 0.0012051338562741876
step: 90, loss: 0.021587766706943512
step: 100, loss: 0.025398187339305878
step: 110, loss: 6.583118374692276e-05
step: 120, loss: 0.059377968311309814
step: 130, loss: 0.00021491963707376271
step: 140, loss: 5.225324275670573e-05
step: 150, loss: 0.04038172587752342
step: 160, loss: 0.02323509007692337
step: 170, loss: 0.0175558440387249
step: 180, loss: 0.05576191842556
step: 190, loss: 0.025517335161566734
step: 200, loss: 0.044460270553827286
step: 210, loss: 0.000225365802180022
step: 220, loss: 0.034282442182302475
step: 230, loss: 0.04801130294799805
step: 240, loss: 0.038086678832769394
step: 250, loss: 0.019081715494394302
step: 260, loss: 2.0428520656423643e-05
step: 270, loss: 1.4777744581806473e-05
step: 280, loss: 0.017466280609369278
step: 290, loss: 0.09528617560863495
step: 300, loss: 0.00447845458984375
step: 310, loss: 0.001000983640551567
step: 320, loss: 0.021937379613518715
step: 330, loss: 0.011480906046926975
step: 340, loss: 0.012484918348491192
step: 350, loss: 7.49309328966774e-05
step: 360, loss: 0.02550318092107773
step: 370, loss: 0.001687019714154303
step: 380, loss: 0.01684918813407421
step: 390, loss: 0.023065045475959778
step: 400, loss: 0.033527035266160965
step: 410, loss: 0.050943002104759216
step: 420, loss: 0.04269405081868172
step: 430, loss: 0.060239844024181366
step: 440, loss: 3.6634788557421416e-05
step: 450, loss: 0.02129312977194786
step: 460, loss: 0.026233039796352386
step: 470, loss: 0.02131231501698494
step: 480, loss: 0.02179243415594101
step: 490, loss: 0.05212301388382912
step: 500, loss: 0.02339746616780758
step: 510, loss: 0.03756239637732506
step: 520, loss: 0.013734173960983753
step: 530, loss: 0.040866196155548096
step: 540, loss: 0.025370068848133087
step: 550, loss: 0.03517824038863182
step: 560, loss: 0.04869601130485535
step: 570, loss: 7.145358540583402e-05
step: 580, loss: 0.05865976959466934
step: 590, loss: 0.07226792722940445
step: 600, loss: 0.056055452674627304
step: 610, loss: 0.02036074921488762
step: 620, loss: 0.031203890219330788
step: 630, loss: 0.059996772557497025
step: 640, loss: 0.01933359168469906
step: 650, loss: 0.020213304087519646
step: 660, loss: 0.06482715904712677
step: 670, loss: 0.05032335966825485
step: 680, loss: 0.003333430038765073
step: 690, loss: 0.03453204780817032
step: 700, loss: 0.038910433650016785
step: 710, loss: 0.02956719510257244
step: 720, loss: 0.022811897099018097
step: 730, loss: 0.02436976507306099
step: 740, loss: 0.020693589001893997
step: 750, loss: 1.376070940750651e-05
step: 760, loss: 0.07457633316516876
step: 770, loss: 0.024227920919656754
step: 780, loss: 6.491450039902702e-05
step: 790, loss: 0.05335421487689018
step: 800, loss: 0.00011523857392603531
step: 810, loss: 0.020617084577679634
step: 820, loss: 0.02202937752008438
step: 830, loss: 0.04590672254562378
step: 840, loss: 0.016344131901860237
step: 850, loss: 0.00023354607401415706
step: 860, loss: 0.01994893327355385
step: 870, loss: 0.022413594648241997
step: 880, loss: 0.03321409597992897
step: 890, loss: 0.025332504883408546
step: 900, loss: 0.0455205999314785
step: 910, loss: 0.062452495098114014
step: 920, loss: 3.2942381949396804e-05
step: 930, loss: 0.03441961854696274
step: 940, loss: 0.046123530715703964
step: 950, loss: 0.026060590520501137
step: 960, loss: 0.046645715832710266
step: 970, loss: 1.558593248773832e-05
epoch 20: dev_f1=0.9298823529411765, f1=0.9237961664329126, best_f1=0.9401631912964642
