cuda
Device: cuda
step: 0, loss: 0.7033653855323792
step: 10, loss: 0.33778250217437744
step: 20, loss: 0.37153467535972595
step: 30, loss: 0.3969270884990692
step: 40, loss: 0.5032766461372375
step: 50, loss: 0.2688136398792267
step: 60, loss: 0.2741831839084625
step: 70, loss: 0.08610460162162781
step: 80, loss: 0.38350221514701843
step: 90, loss: 0.1349969506263733
step: 100, loss: 0.16809168457984924
step: 110, loss: 0.11580049991607666
step: 120, loss: 0.26666519045829773
step: 130, loss: 0.21577750146389008
step: 140, loss: 0.09948667138814926
step: 150, loss: 0.12257105857133865
step: 160, loss: 0.1769966185092926
step: 170, loss: 0.14520272612571716
step: 180, loss: 0.07337474822998047
step: 190, loss: 0.12346960604190826
step: 200, loss: 0.10813818871974945
step: 210, loss: 0.02677803672850132
step: 220, loss: 0.16168862581253052
step: 230, loss: 0.1492033451795578
step: 240, loss: 0.26643189787864685
step: 250, loss: 0.18430651724338531
step: 260, loss: 0.46492454409599304
step: 270, loss: 0.13724036514759064
step: 280, loss: 0.18792113661766052
step: 290, loss: 0.15996716916561127
step: 300, loss: 0.17269489169120789
step: 310, loss: 0.09650947898626328
step: 320, loss: 0.12905798852443695
step: 330, loss: 0.11844636499881744
step: 340, loss: 0.10562680661678314
step: 350, loss: 0.14028003811836243
step: 360, loss: 0.014415008015930653
step: 370, loss: 0.15442143380641937
step: 380, loss: 0.1987403780221939
step: 390, loss: 0.13323397934436798
step: 400, loss: 0.11258931457996368
step: 410, loss: 0.05702824890613556
step: 420, loss: 0.09175179898738861
step: 430, loss: 0.08295871317386627
step: 440, loss: 0.12453705072402954
step: 450, loss: 0.08208489418029785
step: 460, loss: 0.079372338950634
step: 470, loss: 0.07364404201507568
step: 480, loss: 0.29596495628356934
step: 490, loss: 0.1867632120847702
step: 500, loss: 0.12721554934978485
step: 510, loss: 0.1228623017668724
step: 520, loss: 0.10432770848274231
step: 530, loss: 0.02170131541788578
step: 540, loss: 0.2413002997636795
step: 550, loss: 0.24074256420135498
step: 560, loss: 0.03247610852122307
step: 570, loss: 0.015792042016983032
step: 580, loss: 0.12601283192634583
step: 590, loss: 0.2666822373867035
step: 600, loss: 0.18997523188591003
step: 610, loss: 0.08596232533454895
step: 620, loss: 0.10161922127008438
step: 630, loss: 0.20638252794742584
step: 640, loss: 0.20783287286758423
step: 650, loss: 0.038906536996364594
step: 660, loss: 0.09052053093910217
step: 670, loss: 0.09320506453514099
step: 680, loss: 0.17631849646568298
step: 690, loss: 0.06126857176423073
step: 700, loss: 0.290203720331192
step: 710, loss: 0.07838588207960129
step: 720, loss: 0.04966485872864723
step: 730, loss: 0.13759391009807587
step: 740, loss: 0.052414629608392715
step: 750, loss: 0.08219482004642487
step: 760, loss: 0.12224136292934418
step: 770, loss: 0.07075758278369904
step: 780, loss: 0.1541225165128708
step: 790, loss: 0.13056732714176178
step: 800, loss: 0.07285597920417786
step: 810, loss: 0.17244058847427368
step: 820, loss: 0.07668767869472504
step: 830, loss: 0.3192957937717438
step: 840, loss: 0.09494909644126892
step: 850, loss: 0.050874486565589905
step: 860, loss: 0.13661335408687592
step: 870, loss: 0.10321282595396042
step: 880, loss: 0.08948167413473129
step: 890, loss: 0.25251305103302
step: 900, loss: 0.14289021492004395
step: 910, loss: 0.08051078766584396
step: 920, loss: 0.09836383908987045
step: 930, loss: 0.2100415676832199
step: 940, loss: 0.20649027824401855
step: 950, loss: 0.02684585563838482
step: 960, loss: 0.08319634944200516
step: 970, loss: 0.01043287105858326
epoch 1: dev_f1=0.9340148698884759, f1=0.933456561922366, best_f1=0.933456561922366
step: 0, loss: 0.06523045152425766
step: 10, loss: 0.027120515704154968
step: 20, loss: 0.01607499271631241
step: 30, loss: 0.11056722700595856
step: 40, loss: 0.020955847576260567
step: 50, loss: 0.07498273253440857
step: 60, loss: 0.10753754526376724
step: 70, loss: 0.041152454912662506
step: 80, loss: 0.08999048173427582
step: 90, loss: 0.017009161412715912
step: 100, loss: 0.08776692301034927
step: 110, loss: 0.018841994926333427
step: 120, loss: 0.055138688534498215
step: 130, loss: 0.08084172010421753
step: 140, loss: 0.21718816459178925
step: 150, loss: 0.10930810868740082
step: 160, loss: 0.1074560284614563
step: 170, loss: 0.054547425359487534
step: 180, loss: 0.039237115532159805
step: 190, loss: 0.029317785054445267
step: 200, loss: 0.03482704982161522
step: 210, loss: 0.11906753480434418
step: 220, loss: 0.04014922305941582
step: 230, loss: 0.04405156895518303
step: 240, loss: 0.06760409474372864
step: 250, loss: 0.0594186894595623
step: 260, loss: 0.11830602586269379
step: 270, loss: 0.07726426422595978
step: 280, loss: 0.013503520749509335
step: 290, loss: 0.20493319630622864
step: 300, loss: 0.04274741932749748
step: 310, loss: 0.057027436792850494
step: 320, loss: 0.1734311431646347
step: 330, loss: 0.042711492627859116
step: 340, loss: 0.10158281028270721
step: 350, loss: 0.06867140531539917
step: 360, loss: 0.047432173043489456
step: 370, loss: 0.019159136340022087
step: 380, loss: 0.027682766318321228
step: 390, loss: 0.15920469164848328
step: 400, loss: 0.05085798352956772
step: 410, loss: 0.017130866646766663
step: 420, loss: 0.08271590620279312
step: 430, loss: 0.13966473937034607
step: 440, loss: 0.08227641135454178
step: 450, loss: 0.13045141100883484
step: 460, loss: 0.04287629574537277
step: 470, loss: 0.01795165240764618
step: 480, loss: 0.04511868953704834
step: 490, loss: 0.03279200568795204
step: 500, loss: 0.09613832831382751
step: 510, loss: 0.10042164474725723
step: 520, loss: 0.13706424832344055
step: 530, loss: 0.12197648733854294
step: 540, loss: 0.28251853585243225
step: 550, loss: 0.09699235111474991
step: 560, loss: 0.10336031019687653
step: 570, loss: 0.12606823444366455
step: 580, loss: 0.042737629264593124
step: 590, loss: 0.07872828096151352
step: 600, loss: 0.05932263657450676
step: 610, loss: 0.10601255297660828
step: 620, loss: 0.1602475345134735
step: 630, loss: 0.06163279339671135
step: 640, loss: 0.09999935328960419
step: 650, loss: 0.09760799258947372
step: 660, loss: 0.1479298621416092
step: 670, loss: 0.16813530027866364
step: 680, loss: 0.07808710634708405
step: 690, loss: 0.07370312511920929
step: 700, loss: 0.11744418740272522
step: 710, loss: 0.04991428554058075
step: 720, loss: 0.05112476274371147
step: 730, loss: 0.02583056315779686
step: 740, loss: 0.04176456481218338
step: 750, loss: 0.03995487093925476
step: 760, loss: 0.05697321146726608
step: 770, loss: 0.2449374794960022
step: 780, loss: 0.10611872375011444
step: 790, loss: 0.048598818480968475
step: 800, loss: 0.02738374099135399
step: 810, loss: 0.11141425371170044
step: 820, loss: 0.034750841557979584
step: 830, loss: 0.08259150385856628
step: 840, loss: 0.17065300047397614
step: 850, loss: 0.06847205013036728
step: 860, loss: 0.17383763194084167
step: 870, loss: 0.060165539383888245
step: 880, loss: 0.04600967466831207
step: 890, loss: 0.009041715413331985
step: 900, loss: 0.04631226137280464
step: 910, loss: 0.14510194957256317
step: 920, loss: 0.12518788874149323
step: 930, loss: 0.11645213514566422
step: 940, loss: 0.09556848555803299
step: 950, loss: 0.15056054294109344
step: 960, loss: 0.05872144550085068
step: 970, loss: 0.013825845904648304
epoch 2: dev_f1=0.9300140911225928, f1=0.9334582942830365, best_f1=0.933456561922366
step: 0, loss: 0.06590087711811066
step: 10, loss: 0.0911407545208931
step: 20, loss: 0.10851198434829712
step: 30, loss: 0.07207769900560379
step: 40, loss: 0.08763038367033005
step: 50, loss: 0.07755781710147858
step: 60, loss: 0.03786677494645119
step: 70, loss: 0.026749039068818092
step: 80, loss: 0.04562827944755554
step: 90, loss: 0.02457105740904808
step: 100, loss: 0.1105729267001152
step: 110, loss: 0.07858645170927048
step: 120, loss: 0.0752783939242363
step: 130, loss: 0.07673165947198868
step: 140, loss: 0.0950729101896286
step: 150, loss: 0.057749178260564804
step: 160, loss: 0.09646141529083252
step: 170, loss: 0.05681915953755379
step: 180, loss: 0.10864893347024918
step: 190, loss: 0.0998111367225647
step: 200, loss: 0.07672280073165894
step: 210, loss: 0.16238825023174286
step: 220, loss: 0.15603968501091003
step: 230, loss: 0.02890908345580101
step: 240, loss: 0.08844864368438721
step: 250, loss: 0.3019587993621826
step: 260, loss: 0.2656893730163574
step: 270, loss: 0.07000911980867386
step: 280, loss: 0.13445818424224854
step: 290, loss: 0.029058968648314476
step: 300, loss: 0.18240989744663239
step: 310, loss: 0.030916232615709305
step: 320, loss: 0.03405255079269409
step: 330, loss: 0.11190059781074524
step: 340, loss: 0.059569504112005234
step: 350, loss: 0.250027060508728
step: 360, loss: 0.05716187134385109
step: 370, loss: 0.08621111512184143
step: 380, loss: 0.13079652190208435
step: 390, loss: 0.08759038895368576
step: 400, loss: 0.09977690130472183
step: 410, loss: 0.030421709641814232
step: 420, loss: 0.08507005870342255
step: 430, loss: 0.17430828511714935
step: 440, loss: 0.0293273888528347
step: 450, loss: 0.10875514894723892
step: 460, loss: 0.023434534668922424
step: 470, loss: 0.07324197143316269
step: 480, loss: 0.06856915354728699
step: 490, loss: 0.05938216298818588
step: 500, loss: 0.09733863174915314
step: 510, loss: 0.08832796663045883
step: 520, loss: 0.13608522713184357
step: 530, loss: 0.0857093408703804
step: 540, loss: 0.14168000221252441
step: 550, loss: 0.018119340762495995
step: 560, loss: 0.1112239882349968
step: 570, loss: 0.023699648678302765
step: 580, loss: 0.07305769622325897
step: 590, loss: 0.024880263954401016
step: 600, loss: 0.026890883222222328
step: 610, loss: 0.01828206703066826
step: 620, loss: 0.15318086743354797
step: 630, loss: 0.0307466983795166
step: 640, loss: 0.19593507051467896
step: 650, loss: 0.024297622963786125
step: 660, loss: 0.12323685735464096
step: 670, loss: 0.07170447707176208
step: 680, loss: 0.06544221192598343
step: 690, loss: 0.05284368246793747
step: 700, loss: 0.05402792990207672
step: 710, loss: 0.1409534513950348
step: 720, loss: 0.07868015021085739
step: 730, loss: 0.028325265273451805
step: 740, loss: 0.04807775840163231
step: 750, loss: 0.2923937141895294
step: 760, loss: 0.052755773067474365
step: 770, loss: 0.07848239690065384
step: 780, loss: 0.03362252563238144
step: 790, loss: 0.07910164445638657
step: 800, loss: 0.1541450172662735
step: 810, loss: 0.030265169218182564
step: 820, loss: 0.0827597826719284
step: 830, loss: 0.07562065869569778
step: 840, loss: 0.06966958940029144
step: 850, loss: 0.07770012319087982
step: 860, loss: 0.043447345495224
step: 870, loss: 0.06271417438983917
step: 880, loss: 0.1225103810429573
step: 890, loss: 0.1579490751028061
step: 900, loss: 0.08047718554735184
step: 910, loss: 0.10425570607185364
step: 920, loss: 0.08857188373804092
step: 930, loss: 0.05070323869585991
step: 940, loss: 0.10158166289329529
step: 950, loss: 0.06572399288415909
step: 960, loss: 0.0819549635052681
step: 970, loss: 0.04584544152021408
epoch 3: dev_f1=0.9263947491795592, f1=0.9251637043966324, best_f1=0.933456561922366
step: 0, loss: 0.023664096370339394
step: 10, loss: 0.018009744584560394
step: 20, loss: 0.05084893852472305
step: 30, loss: 0.11668393015861511
step: 40, loss: 0.09768657386302948
step: 50, loss: 0.022616799920797348
step: 60, loss: 0.034658342599868774
step: 70, loss: 0.10277111828327179
step: 80, loss: 0.05361619591712952
step: 90, loss: 0.05605797842144966
step: 100, loss: 0.10256660729646683
step: 110, loss: 0.10342235863208771
step: 120, loss: 0.037241093814373016
step: 130, loss: 0.07030104100704193
step: 140, loss: 0.01866781897842884
step: 150, loss: 0.04122592881321907
step: 160, loss: 0.16874124109745026
step: 170, loss: 0.034420136362314224
step: 180, loss: 0.06404217332601547
step: 190, loss: 0.14582763612270355
step: 200, loss: 0.0627233237028122
step: 210, loss: 0.05999724939465523
step: 220, loss: 0.03473690524697304
step: 230, loss: 0.035123806446790695
step: 240, loss: 0.006807697471231222
step: 250, loss: 0.023016592487692833
step: 260, loss: 0.04087621718645096
step: 270, loss: 0.13409709930419922
step: 280, loss: 0.11631231755018234
step: 290, loss: 0.11839901655912399
step: 300, loss: 0.024954721331596375
step: 310, loss: 0.034285835921764374
step: 320, loss: 0.1875685602426529
step: 330, loss: 0.13154204189777374
step: 340, loss: 0.026066947728395462
step: 350, loss: 0.08188571035861969
step: 360, loss: 0.2063462883234024
step: 370, loss: 0.08015468716621399
step: 380, loss: 0.010342927649617195
step: 390, loss: 0.0460178405046463
step: 400, loss: 0.16113920509815216
step: 410, loss: 0.18686047196388245
step: 420, loss: 0.07608799636363983
step: 430, loss: 0.06389173120260239
step: 440, loss: 0.1097959354519844
step: 450, loss: 0.028444258496165276
step: 460, loss: 0.07186182588338852
step: 470, loss: 0.09053852409124374
step: 480, loss: 0.12354394793510437
step: 490, loss: 0.06071509048342705
step: 500, loss: 0.043502405285835266
step: 510, loss: 0.011120683513581753
step: 520, loss: 0.14532560110092163
step: 530, loss: 0.027012670412659645
step: 540, loss: 0.13340875506401062
step: 550, loss: 0.09559977054595947
step: 560, loss: 0.08404238522052765
step: 570, loss: 0.14240048825740814
step: 580, loss: 0.1250409036874771
step: 590, loss: 0.11191261559724808
step: 600, loss: 0.0933310016989708
step: 610, loss: 0.07359494268894196
step: 620, loss: 0.03310684114694595
step: 630, loss: 0.012433289550244808
step: 640, loss: 0.17345431447029114
step: 650, loss: 0.08174312859773636
step: 660, loss: 0.028452161699533463
step: 670, loss: 0.0923357903957367
step: 680, loss: 0.02176593616604805
step: 690, loss: 0.045549340546131134
step: 700, loss: 0.046743184328079224
step: 710, loss: 0.0448278933763504
step: 720, loss: 0.06303450465202332
step: 730, loss: 0.12193629145622253
step: 740, loss: 0.10119135677814484
step: 750, loss: 0.01760374754667282
step: 760, loss: 0.05494050309062004
step: 770, loss: 0.02819824405014515
step: 780, loss: 0.053489115089178085
step: 790, loss: 0.15703724324703217
step: 800, loss: 0.07643161714076996
step: 810, loss: 0.15100064873695374
step: 820, loss: 0.039029061794281006
step: 830, loss: 0.013807383365929127
step: 840, loss: 0.015826599672436714
step: 850, loss: 0.08849330246448517
step: 860, loss: 0.10405466705560684
step: 870, loss: 0.08599746972322464
step: 880, loss: 0.09554027765989304
step: 890, loss: 0.0626988634467125
step: 900, loss: 0.11291895806789398
step: 910, loss: 0.087946817278862
step: 920, loss: 0.012334435246884823
step: 930, loss: 0.049143433570861816
step: 940, loss: 0.0840686485171318
step: 950, loss: 0.06312883645296097
step: 960, loss: 0.053369972854852676
step: 970, loss: 0.060810528695583344
epoch 4: dev_f1=0.9332121762835075, f1=0.9287335451656831, best_f1=0.933456561922366
step: 0, loss: 0.12343020737171173
step: 10, loss: 0.10150854289531708
step: 20, loss: 0.05560532957315445
step: 30, loss: 0.0230582095682621
step: 40, loss: 0.01220901869237423
step: 50, loss: 0.14888300001621246
step: 60, loss: 0.08449278026819229
step: 70, loss: 0.013506179675459862
step: 80, loss: 0.012071933597326279
step: 90, loss: 0.016538383439183235
step: 100, loss: 0.1502072960138321
step: 110, loss: 0.007028621155768633
step: 120, loss: 0.12434384226799011
step: 130, loss: 0.008792622946202755
step: 140, loss: 0.06478214263916016
step: 150, loss: 0.04476800933480263
step: 160, loss: 0.047401927411556244
step: 170, loss: 0.026645362377166748
step: 180, loss: 0.005112788174301386
step: 190, loss: 0.04078413173556328
step: 200, loss: 0.018356842920184135
step: 210, loss: 0.19313427805900574
step: 220, loss: 0.03153432905673981
step: 230, loss: 0.02581074833869934
step: 240, loss: 0.023122921586036682
step: 250, loss: 0.029689645394682884
step: 260, loss: 0.06475915759801865
step: 270, loss: 0.10116013139486313
step: 280, loss: 0.04485142603516579
step: 290, loss: 0.09544811397790909
step: 300, loss: 0.0684533566236496
step: 310, loss: 0.04172687977552414
step: 320, loss: 0.02615787833929062
step: 330, loss: 0.03732646629214287
step: 340, loss: 0.12514227628707886
step: 350, loss: 0.09610023349523544
step: 360, loss: 0.07777360081672668
step: 370, loss: 0.03230796754360199
step: 380, loss: 0.1150437444448471
step: 390, loss: 0.08177197724580765
step: 400, loss: 0.09060514718294144
step: 410, loss: 0.10825567692518234
step: 420, loss: 0.06680292636156082
step: 430, loss: 0.21085122227668762
step: 440, loss: 0.07758275419473648
step: 450, loss: 0.12364606559276581
step: 460, loss: 0.0886479914188385
step: 470, loss: 0.09909240156412125
step: 480, loss: 0.10011937469244003
step: 490, loss: 0.08260507136583328
step: 500, loss: 0.0742550790309906
step: 510, loss: 0.06483957171440125
step: 520, loss: 0.08207223564386368
step: 530, loss: 0.13842298090457916
step: 540, loss: 0.11428617686033249
step: 550, loss: 0.17775002121925354
step: 560, loss: 0.042814627289772034
step: 570, loss: 0.07031965255737305
step: 580, loss: 0.011117862537503242
step: 590, loss: 0.12947985529899597
step: 600, loss: 0.09341993182897568
step: 610, loss: 0.08066686987876892
step: 620, loss: 0.07430059462785721
step: 630, loss: 0.157614067196846
step: 640, loss: 0.006583665497601032
step: 650, loss: 0.03308900073170662
step: 660, loss: 0.01944742724299431
step: 670, loss: 0.11998218297958374
step: 680, loss: 0.11944122612476349
step: 690, loss: 0.04230048507452011
step: 700, loss: 0.0880599245429039
step: 710, loss: 0.12661682069301605
step: 720, loss: 0.009319665841758251
step: 730, loss: 0.031334783881902695
step: 740, loss: 0.08038045465946198
step: 750, loss: 0.023539595305919647
step: 760, loss: 0.07889978587627411
step: 770, loss: 0.08059599995613098
step: 780, loss: 0.04165620356798172
step: 790, loss: 0.0686635673046112
step: 800, loss: 0.04764963313937187
step: 810, loss: 0.04165826737880707
step: 820, loss: 0.10019852221012115
step: 830, loss: 0.05111478641629219
step: 840, loss: 0.08770221471786499
step: 850, loss: 0.10363274067640305
step: 860, loss: 0.12055864930152893
step: 870, loss: 0.00864829495549202
step: 880, loss: 0.1038026213645935
step: 890, loss: 0.20056088268756866
step: 900, loss: 0.1294340193271637
step: 910, loss: 0.1233612522482872
step: 920, loss: 0.012411640025675297
step: 930, loss: 0.00045147002674639225
step: 940, loss: 0.044253867119550705
step: 950, loss: 0.14377330243587494
step: 960, loss: 0.0004962754319421947
step: 970, loss: 0.02642580308020115
epoch 5: dev_f1=0.9357884796978281, f1=0.9273323956868261, best_f1=0.9273323956868261
step: 0, loss: 0.1228790432214737
step: 10, loss: 0.11508175730705261
step: 20, loss: 0.10248193889856339
step: 30, loss: 0.021048564463853836
step: 40, loss: 0.006117265671491623
step: 50, loss: 0.05004202201962471
step: 60, loss: 0.022315019741654396
step: 70, loss: 0.15261179208755493
step: 80, loss: 0.09536528587341309
step: 90, loss: 0.25108957290649414
step: 100, loss: 0.019475458189845085
step: 110, loss: 0.020718006417155266
step: 120, loss: 0.1220359206199646
step: 130, loss: 0.025511959567666054
step: 140, loss: 0.03872336819767952
step: 150, loss: 0.04519752040505409
step: 160, loss: 0.005194955505430698
step: 170, loss: 0.08913619071245193
step: 180, loss: 0.03243467956781387
step: 190, loss: 0.007980947382748127
step: 200, loss: 0.12544579803943634
step: 210, loss: 0.07290975749492645
step: 220, loss: 0.12117073684930801
step: 230, loss: 0.04875033721327782
step: 240, loss: 0.007247642148286104
step: 250, loss: 0.07239169627428055
step: 260, loss: 0.02471279911696911
step: 270, loss: 0.0637567937374115
step: 280, loss: 0.0947587713599205
step: 290, loss: 0.08537228405475616
step: 300, loss: 0.06522844731807709
step: 310, loss: 0.012726636603474617
step: 320, loss: 0.011085414327681065
step: 330, loss: 0.014020157046616077
step: 340, loss: 0.05906857177615166
step: 350, loss: 0.0631641075015068
step: 360, loss: 0.0513494610786438
step: 370, loss: 0.06790824234485626
step: 380, loss: 0.15544788539409637
step: 390, loss: 0.13664710521697998
step: 400, loss: 0.019584516063332558
step: 410, loss: 0.04679889976978302
step: 420, loss: 0.06020660325884819
step: 430, loss: 0.04142682999372482
step: 440, loss: 0.05470263957977295
step: 450, loss: 0.185153990983963
step: 460, loss: 0.049445848912000656
step: 470, loss: 0.04871317744255066
step: 480, loss: 0.09817767143249512
step: 490, loss: 0.007289627566933632
step: 500, loss: 0.026128077879548073
step: 510, loss: 0.12909597158432007
step: 520, loss: 0.029083305969834328
step: 530, loss: 0.058165039867162704
step: 540, loss: 0.04199158027768135
step: 550, loss: 0.05277066305279732
step: 560, loss: 0.026747994124889374
step: 570, loss: 0.03749353811144829
step: 580, loss: 0.022737253457307816
step: 590, loss: 0.08234842121601105
step: 600, loss: 0.01642729341983795
step: 610, loss: 0.14815720915794373
step: 620, loss: 0.1239813044667244
step: 630, loss: 0.01930926740169525
step: 640, loss: 0.0693465992808342
step: 650, loss: 0.008314033038914204
step: 660, loss: 0.005554400850087404
step: 670, loss: 0.0795115977525711
step: 680, loss: 0.05884312093257904
step: 690, loss: 0.0903242751955986
step: 700, loss: 0.03076372668147087
step: 710, loss: 0.07206660509109497
step: 720, loss: 0.060490842908620834
step: 730, loss: 0.10666724294424057
step: 740, loss: 0.011675696820020676
step: 750, loss: 0.09640035778284073
step: 760, loss: 0.07503069192171097
step: 770, loss: 0.024705862626433372
step: 780, loss: 0.014505214057862759
step: 790, loss: 0.008750325068831444
step: 800, loss: 0.08415941148996353
step: 810, loss: 0.05939881503582001
step: 820, loss: 0.07889696210622787
step: 830, loss: 0.007267171982675791
step: 840, loss: 0.03828412666916847
step: 850, loss: 0.061902012676000595
step: 860, loss: 0.015117242932319641
step: 870, loss: 0.13900406658649445
step: 880, loss: 0.014551169238984585
step: 890, loss: 0.01543891429901123
step: 900, loss: 0.09837599843740463
step: 910, loss: 0.13980473577976227
step: 920, loss: 0.04035807400941849
step: 930, loss: 0.1398318111896515
step: 940, loss: 0.011119518429040909
step: 950, loss: 0.02776389941573143
step: 960, loss: 0.09336544573307037
step: 970, loss: 0.025915255770087242
epoch 6: dev_f1=0.9354545454545454, f1=0.9377817853922452, best_f1=0.9273323956868261
step: 0, loss: 0.08124003559350967
step: 10, loss: 0.10361715406179428
step: 20, loss: 0.020581524819135666
step: 30, loss: 0.009151605889201164
step: 40, loss: 0.043220046907663345
step: 50, loss: 0.08418694138526917
step: 60, loss: 0.08542028814554214
step: 70, loss: 0.02390056475996971
step: 80, loss: 0.0418899804353714
step: 90, loss: 0.07582785189151764
step: 100, loss: 0.0291365385055542
step: 110, loss: 0.008391935378313065
step: 120, loss: 0.01638091541826725
step: 130, loss: 0.00021456880494952202
step: 140, loss: 0.01592286489903927
step: 150, loss: 0.04925617575645447
step: 160, loss: 0.048190291970968246
step: 170, loss: 0.026276644319295883
step: 180, loss: 0.00010398506128694862
step: 190, loss: 0.07894384115934372
step: 200, loss: 0.054212477058172226
step: 210, loss: 0.04087468981742859
step: 220, loss: 0.1368626058101654
step: 230, loss: 0.0888284221291542
step: 240, loss: 0.04493371769785881
step: 250, loss: 0.1667984277009964
step: 260, loss: 0.061108410358428955
step: 270, loss: 0.02689392678439617
step: 280, loss: 0.01864662393927574
step: 290, loss: 0.0130557119846344
step: 300, loss: 0.03427104651927948
step: 310, loss: 0.13004177808761597
step: 320, loss: 0.021682055667042732
step: 330, loss: 0.08894394338130951
step: 340, loss: 0.1731691211462021
step: 350, loss: 0.02392609789967537
step: 360, loss: 0.01645698770880699
step: 370, loss: 0.1012464091181755
step: 380, loss: 0.06190982833504677
step: 390, loss: 0.05588426813483238
step: 400, loss: 0.2201625257730484
step: 410, loss: 0.03512541577219963
step: 420, loss: 0.0083246985450387
step: 430, loss: 0.0248173326253891
step: 440, loss: 0.11137840151786804
step: 450, loss: 0.09150997549295425
step: 460, loss: 0.05678779259324074
step: 470, loss: 0.04678313061594963
step: 480, loss: 0.1255350559949875
step: 490, loss: 0.19648084044456482
step: 500, loss: 0.12221948057413101
step: 510, loss: 0.08804994076490402
step: 520, loss: 0.007979710586369038
step: 530, loss: 0.04655066132545471
step: 540, loss: 0.06162836402654648
step: 550, loss: 0.018234487622976303
step: 560, loss: 0.00487832585349679
step: 570, loss: 0.07567231357097626
step: 580, loss: 0.0068090264685451984
step: 590, loss: 0.07057137787342072
step: 600, loss: 0.022062472999095917
step: 610, loss: 0.01086115837097168
step: 620, loss: 0.006201538722962141
step: 630, loss: 0.10670579969882965
step: 640, loss: 0.033116329461336136
step: 650, loss: 0.11298111826181412
step: 660, loss: 0.03258582949638367
step: 670, loss: 0.08508861064910889
step: 680, loss: 0.09724109619855881
step: 690, loss: 0.07670902460813522
step: 700, loss: 0.08440181612968445
step: 710, loss: 0.04255196452140808
step: 720, loss: 0.07372146844863892
step: 730, loss: 0.13122759759426117
step: 740, loss: 0.18725638091564178
step: 750, loss: 0.030046287924051285
step: 760, loss: 0.08515041321516037
step: 770, loss: 0.21141980588436127
step: 780, loss: 0.006587834097445011
step: 790, loss: 0.0765206441283226
step: 800, loss: 0.015700198709964752
step: 810, loss: 0.1987352818250656
step: 820, loss: 0.09514918923377991
step: 830, loss: 0.05719032138586044
step: 840, loss: 0.06815707683563232
step: 850, loss: 0.028479166328907013
step: 860, loss: 0.1322271227836609
step: 870, loss: 0.08239719271659851
step: 880, loss: 0.1056925430893898
step: 890, loss: 0.07906006276607513
step: 900, loss: 0.053398460149765015
step: 910, loss: 0.0455172061920166
step: 920, loss: 0.023457204923033714
step: 930, loss: 0.05719798803329468
step: 940, loss: 0.049296796321868896
step: 950, loss: 0.013625619001686573
step: 960, loss: 0.007635636255145073
step: 970, loss: 0.06596202403306961
epoch 7: dev_f1=0.9398040130657956, f1=0.9394785847299814, best_f1=0.9394785847299814
step: 0, loss: 0.10080517828464508
step: 10, loss: 0.019948046654462814
step: 20, loss: 0.020156769081950188
step: 30, loss: 0.04604625329375267
step: 40, loss: 0.12143583595752716
step: 50, loss: 0.0892036184668541
step: 60, loss: 0.014837373048067093
step: 70, loss: 0.02172686718404293
step: 80, loss: 0.05767270550131798
step: 90, loss: 0.08738269656896591
step: 100, loss: 0.0342908538877964
step: 110, loss: 0.012555941939353943
step: 120, loss: 0.033538203686475754
step: 130, loss: 0.08231145143508911
step: 140, loss: 0.09761998057365417
step: 150, loss: 0.08318748325109482
step: 160, loss: 0.042421385645866394
step: 170, loss: 0.07750234007835388
step: 180, loss: 0.031053675338625908
step: 190, loss: 0.07658389955759048
step: 200, loss: 0.07310158014297485
step: 210, loss: 0.04959568753838539
step: 220, loss: 0.06205897778272629
step: 230, loss: 0.07963024824857712
step: 240, loss: 0.13258109986782074
step: 250, loss: 0.030128952115774155
step: 260, loss: 0.004101740196347237
step: 270, loss: 0.1353446990251541
step: 280, loss: 0.15174005925655365
step: 290, loss: 0.03739935904741287
step: 300, loss: 0.010948829352855682
step: 310, loss: 0.006817325949668884
step: 320, loss: 0.07865773886442184
step: 330, loss: 0.06433615833520889
step: 340, loss: 0.04214121773838997
step: 350, loss: 0.015487918630242348
step: 360, loss: 0.020403770729899406
step: 370, loss: 0.02852853387594223
step: 380, loss: 0.00884892325848341
step: 390, loss: 0.023504316806793213
step: 400, loss: 0.024745814502239227
step: 410, loss: 0.027974175289273262
step: 420, loss: 0.12373518943786621
step: 430, loss: 0.11829622834920883
step: 440, loss: 0.01251164823770523
step: 450, loss: 0.163197860121727
step: 460, loss: 0.02342875301837921
step: 470, loss: 0.06902855634689331
step: 480, loss: 0.08681808412075043
step: 490, loss: 0.015840420499444008
step: 500, loss: 0.043046656996011734
step: 510, loss: 0.09471695870161057
step: 520, loss: 0.019655948504805565
step: 530, loss: 0.07005839794874191
step: 540, loss: 0.03492981567978859
step: 550, loss: 0.054988037794828415
step: 560, loss: 0.08219190686941147
step: 570, loss: 0.07714711129665375
step: 580, loss: 0.15107722580432892
step: 590, loss: 0.032996974885463715
step: 600, loss: 0.047038204967975616
step: 610, loss: 0.03252718970179558
step: 620, loss: 0.012685701251029968
step: 630, loss: 0.042403072118759155
step: 640, loss: 0.01640264131128788
step: 650, loss: 0.03706929832696915
step: 660, loss: 0.026907499879598618
step: 670, loss: 0.010944587178528309
step: 680, loss: 0.04300564154982567
step: 690, loss: 0.04469204321503639
step: 700, loss: 0.03587396442890167
step: 710, loss: 0.058538712561130524
step: 720, loss: 0.018027136102318764
step: 730, loss: 0.0727829560637474
step: 740, loss: 0.028568260371685028
step: 750, loss: 0.003197271144017577
step: 760, loss: 0.003115392290055752
step: 770, loss: 0.1746426671743393
step: 780, loss: 0.12138982117176056
step: 790, loss: 0.02273990586400032
step: 800, loss: 0.06432843208312988
step: 810, loss: 0.03143809735774994
step: 820, loss: 0.016513146460056305
step: 830, loss: 0.14721079170703888
step: 840, loss: 0.02603164315223694
step: 850, loss: 0.010976947844028473
step: 860, loss: 0.01909554935991764
step: 870, loss: 0.018446458503603935
step: 880, loss: 0.00471315486356616
step: 890, loss: 0.09970321506261826
step: 900, loss: 0.08985767513513565
step: 910, loss: 0.011705538257956505
step: 920, loss: 0.06307948380708694
step: 930, loss: 0.011495736427605152
step: 940, loss: 0.008367161266505718
step: 950, loss: 0.027707340195775032
step: 960, loss: 0.1085786297917366
step: 970, loss: 0.21342690289020538
epoch 8: dev_f1=0.9373571101966164, f1=0.9404216315307058, best_f1=0.9394785847299814
step: 0, loss: 0.03565863519906998
step: 10, loss: 0.015313640236854553
step: 20, loss: 0.057000529021024704
step: 30, loss: 0.01721441000699997
step: 40, loss: 0.014830759726464748
step: 50, loss: 0.018817588686943054
step: 60, loss: 0.007428308017551899
step: 70, loss: 0.11903760582208633
step: 80, loss: 0.06426087021827698
step: 90, loss: 0.06867114454507828
step: 100, loss: 0.07653472572565079
step: 110, loss: 0.013888793997466564
step: 120, loss: 0.018310517072677612
step: 130, loss: 0.017264118418097496
step: 140, loss: 0.12900730967521667
step: 150, loss: 0.03320153430104256
step: 160, loss: 0.021992681547999382
step: 170, loss: 0.11460717022418976
step: 180, loss: 0.08595430105924606
step: 190, loss: 0.016093963757157326
step: 200, loss: 0.10753034800291061
step: 210, loss: 0.09723042696714401
step: 220, loss: 0.026071744039654732
step: 230, loss: 0.0392245352268219
step: 240, loss: 0.003894468303769827
step: 250, loss: 0.002988405292853713
step: 260, loss: 0.0855151042342186
step: 270, loss: 0.1460496336221695
step: 280, loss: 0.025438597425818443
step: 290, loss: 0.007946961559355259
step: 300, loss: 0.07425343245267868
step: 310, loss: 0.18057025969028473
step: 320, loss: 0.06412523239850998
step: 330, loss: 0.014731701463460922
step: 340, loss: 0.0019191430183127522
step: 350, loss: 0.02209586091339588
step: 360, loss: 0.012914860621094704
step: 370, loss: 0.08389035612344742
step: 380, loss: 0.010496195405721664
step: 390, loss: 0.13903653621673584
step: 400, loss: 0.01319140288978815
step: 410, loss: 0.015540119260549545
step: 420, loss: 0.08148858696222305
step: 430, loss: 0.09270179271697998
step: 440, loss: 0.0806964561343193
step: 450, loss: 0.00750703364610672
step: 460, loss: 0.015977084636688232
step: 470, loss: 0.02982449345290661
step: 480, loss: 0.13157452642917633
step: 490, loss: 0.11464513838291168
step: 500, loss: 0.06898669898509979
step: 510, loss: 0.052337903529405594
step: 520, loss: 0.025583595037460327
step: 530, loss: 0.020408805459737778
step: 540, loss: 0.059040289372205734
step: 550, loss: 0.07130184024572372
step: 560, loss: 0.08819293975830078
step: 570, loss: 0.04417833685874939
step: 580, loss: 0.0826599970459938
step: 590, loss: 0.034791335463523865
step: 600, loss: 0.05667205899953842
step: 610, loss: 0.0430595837533474
step: 620, loss: 0.059783730655908585
step: 630, loss: 0.1326102912425995
step: 640, loss: 0.09773378819227219
step: 650, loss: 0.054012347012758255
step: 660, loss: 0.06661331653594971
step: 670, loss: 0.012348598800599575
step: 680, loss: 0.0874662846326828
step: 690, loss: 0.08374110609292984
step: 700, loss: 0.1374514102935791
step: 710, loss: 0.09003684669733047
step: 720, loss: 0.01957496628165245
step: 730, loss: 0.09445307403802872
step: 740, loss: 0.0875508189201355
step: 750, loss: 0.12398378551006317
step: 760, loss: 0.007222721353173256
step: 770, loss: 0.06683853268623352
step: 780, loss: 0.07250427454710007
step: 790, loss: 0.024594124406576157
step: 800, loss: 0.07641623914241791
step: 810, loss: 0.09453845024108887
step: 820, loss: 0.12291524559259415
step: 830, loss: 0.021059546619653702
step: 840, loss: 0.12938715517520905
step: 850, loss: 0.1526886373758316
step: 860, loss: 0.14631043374538422
step: 870, loss: 0.00789816863834858
step: 880, loss: 0.2726844847202301
step: 890, loss: 0.06106564775109291
step: 900, loss: 0.07884225994348526
step: 910, loss: 0.03133315220475197
step: 920, loss: 0.10107681900262833
step: 930, loss: 0.1262178122997284
step: 940, loss: 0.035692449659109116
step: 950, loss: 0.10968169569969177
step: 960, loss: 0.021446216851472855
step: 970, loss: 0.12811829149723053
epoch 9: dev_f1=0.9297094657919399, f1=0.9255813953488372, best_f1=0.9394785847299814
step: 0, loss: 0.06550263613462448
step: 10, loss: 0.06146061420440674
step: 20, loss: 0.041120462119579315
step: 30, loss: 0.07824353873729706
step: 40, loss: 0.04059438779950142
step: 50, loss: 0.07534034550189972
step: 60, loss: 0.01885085180401802
step: 70, loss: 0.05395727604627609
step: 80, loss: 0.004544785711914301
step: 90, loss: 0.12721340358257294
step: 100, loss: 0.0055433171801269054
step: 110, loss: 0.05483169108629227
step: 120, loss: 0.06676429510116577
step: 130, loss: 0.06192164868116379
step: 140, loss: 0.05104149505496025
step: 150, loss: 0.06255161017179489
step: 160, loss: 0.06670960783958435
step: 170, loss: 0.003614986315369606
step: 180, loss: 0.11497922241687775
step: 190, loss: 0.008155043236911297
step: 200, loss: 0.08033688366413116
step: 210, loss: 0.10560130327939987
step: 220, loss: 0.08810567855834961
step: 230, loss: 0.029645152390003204
step: 240, loss: 0.1192961186170578
step: 250, loss: 0.049959953874349594
step: 260, loss: 0.04875059425830841
step: 270, loss: 0.07534129917621613
step: 280, loss: 0.08359348028898239
step: 290, loss: 0.0258842334151268
step: 300, loss: 0.006927667651325464
step: 310, loss: 0.13072559237480164
step: 320, loss: 0.04914416745305061
step: 330, loss: 0.021025188267230988
step: 340, loss: 0.09673936665058136
step: 350, loss: 0.020940648391842842
step: 360, loss: 0.0172499381005764
step: 370, loss: 0.005825710017234087
step: 380, loss: 0.0738791674375534
step: 390, loss: 0.03811868652701378
step: 400, loss: 0.012927564792335033
step: 410, loss: 0.06882396340370178
step: 420, loss: 0.08592304587364197
step: 430, loss: 0.07161083817481995
step: 440, loss: 0.006336077116429806
step: 450, loss: 0.0051071918569505215
step: 460, loss: 0.058851420879364014
step: 470, loss: 0.022030044347047806
step: 480, loss: 0.0014025818090885878
step: 490, loss: 0.10395035892724991
step: 500, loss: 0.0010814424604177475
step: 510, loss: 0.11804725229740143
step: 520, loss: 0.04807962104678154
step: 530, loss: 0.014360379427671432
step: 540, loss: 0.12048943340778351
step: 550, loss: 0.14847427606582642
step: 560, loss: 0.03903681039810181
step: 570, loss: 0.12192481011152267
step: 580, loss: 0.00832897238433361
step: 590, loss: 0.11494866013526917
step: 600, loss: 0.03128762170672417
step: 610, loss: 0.004774984437972307
step: 620, loss: 0.0251864455640316
step: 630, loss: 0.11381223052740097
step: 640, loss: 0.06721707433462143
step: 650, loss: 0.012468556873500347
step: 660, loss: 0.005270122084766626
step: 670, loss: 0.13717308640480042
step: 680, loss: 0.06405626237392426
step: 690, loss: 0.12585744261741638
step: 700, loss: 0.01079347264021635
step: 710, loss: 0.02939043939113617
step: 720, loss: 0.022251106798648834
step: 730, loss: 0.0035621393471956253
step: 740, loss: 0.017877716571092606
step: 750, loss: 0.061961282044649124
step: 760, loss: 0.157330721616745
step: 770, loss: 0.03974531218409538
step: 780, loss: 0.07612159848213196
step: 790, loss: 0.01574377715587616
step: 800, loss: 0.11237571388483047
step: 810, loss: 0.019189896062016487
step: 820, loss: 0.10613793879747391
step: 830, loss: 0.015058718621730804
step: 840, loss: 0.1710926741361618
step: 850, loss: 0.08098259568214417
step: 860, loss: 0.07276329398155212
step: 870, loss: 0.02321089804172516
step: 880, loss: 0.02590964362025261
step: 890, loss: 0.022545818239450455
step: 900, loss: 0.0035776791628450155
step: 910, loss: 0.0698016956448555
step: 920, loss: 0.08182720839977264
step: 930, loss: 0.04585888609290123
step: 940, loss: 0.15082867443561554
step: 950, loss: 0.04292690381407738
step: 960, loss: 0.09291700273752213
step: 970, loss: 0.06661852449178696
epoch 10: dev_f1=0.9367088607594937, f1=0.9353233830845772, best_f1=0.9394785847299814
step: 0, loss: 0.05432679504156113
step: 10, loss: 0.021369311958551407
step: 20, loss: 0.014730534516274929
step: 30, loss: 0.029024135321378708
step: 40, loss: 0.049779731780290604
step: 50, loss: 0.04678153619170189
step: 60, loss: 0.0018552205292508006
step: 70, loss: 0.02949880249798298
step: 80, loss: 0.04899758845567703
step: 90, loss: 0.011565024964511395
step: 100, loss: 0.07862462103366852
step: 110, loss: 0.08944667130708694
step: 120, loss: 0.05342237651348114
step: 130, loss: 0.047243863344192505
step: 140, loss: 0.029717467725276947
step: 150, loss: 0.037235792726278305
step: 160, loss: 0.0033580202143639326
step: 170, loss: 0.020613905042409897
step: 180, loss: 0.01460983045399189
step: 190, loss: 0.03876215219497681
step: 200, loss: 0.014143211767077446
step: 210, loss: 0.08859609812498093
step: 220, loss: 0.0049472772516310215
step: 230, loss: 0.03325618430972099
step: 240, loss: 0.007397755514830351
step: 250, loss: 0.01786995865404606
step: 260, loss: 0.012602328322827816
step: 270, loss: 0.02020600438117981
step: 280, loss: 0.03903284668922424
step: 290, loss: 0.07070057094097137
step: 300, loss: 0.012249227613210678
step: 310, loss: 0.04854949936270714
step: 320, loss: 0.04840900003910065
step: 330, loss: 0.0189565010368824
step: 340, loss: 0.009418227709829807
step: 350, loss: 0.05887797102332115
step: 360, loss: 0.0757247731089592
step: 370, loss: 0.0532112643122673
step: 380, loss: 0.038911331444978714
step: 390, loss: 0.002512156032025814
step: 400, loss: 0.06484362483024597
step: 410, loss: 0.052332717925310135
step: 420, loss: 0.06793231517076492
step: 430, loss: 0.010255547240376472
step: 440, loss: 0.030252866446971893
step: 450, loss: 0.01566861756145954
step: 460, loss: 0.05122940614819527
step: 470, loss: 0.019136803224682808
step: 480, loss: 0.3114570677280426
step: 490, loss: 0.0432312972843647
step: 500, loss: 0.02988610416650772
step: 510, loss: 0.06364773958921432
step: 520, loss: 0.007082869298756123
step: 530, loss: 0.02580426260828972
step: 540, loss: 0.03198928013443947
step: 550, loss: 0.048139844089746475
step: 560, loss: 0.014944733120501041
step: 570, loss: 0.05747038125991821
step: 580, loss: 0.0832822322845459
step: 590, loss: 0.004723527003079653
step: 600, loss: 0.04037494957447052
step: 610, loss: 0.027628447860479355
step: 620, loss: 0.0925855040550232
step: 630, loss: 0.006675781682133675
step: 640, loss: 0.028068484738469124
step: 650, loss: 0.09950701147317886
step: 660, loss: 0.040225908160209656
step: 670, loss: 0.014331875368952751
step: 680, loss: 0.12430842220783234
step: 690, loss: 0.05086545646190643
step: 700, loss: 0.0028044141363352537
step: 710, loss: 0.08471139520406723
step: 720, loss: 0.05967042222619057
step: 730, loss: 0.042060211300849915
step: 740, loss: 0.014978435821831226
step: 750, loss: 0.08534814417362213
step: 760, loss: 0.06774437427520752
step: 770, loss: 0.0923462063074112
step: 780, loss: 0.01183047890663147
step: 790, loss: 0.0028214980848133564
step: 800, loss: 0.20148783922195435
step: 810, loss: 0.025650430470705032
step: 820, loss: 0.020874472334980965
step: 830, loss: 0.05887367203831673
step: 840, loss: 0.05994197353720665
step: 850, loss: 0.06259256601333618
step: 860, loss: 0.13702289760112762
step: 870, loss: 0.08467623591423035
step: 880, loss: 0.01610918715596199
step: 890, loss: 0.09910059720277786
step: 900, loss: 0.02291047014296055
step: 910, loss: 0.09099256247282028
step: 920, loss: 0.05022510886192322
step: 930, loss: 0.08789274096488953
step: 940, loss: 0.011063105426728725
step: 950, loss: 0.03371023014187813
step: 960, loss: 0.0329059474170208
step: 970, loss: 0.11675756424665451
epoch 11: dev_f1=0.9286740067017711, f1=0.922488038277512, best_f1=0.9394785847299814
step: 0, loss: 0.01870342716574669
step: 10, loss: 0.007339148316532373
step: 20, loss: 0.07046055048704147
step: 30, loss: 0.012921837158501148
step: 40, loss: 0.020014043897390366
step: 50, loss: 0.01467672549188137
step: 60, loss: 0.04545352980494499
step: 70, loss: 0.13999928534030914
step: 80, loss: 0.06341142952442169
step: 90, loss: 0.09252580255270004
step: 100, loss: 0.015241140499711037
step: 110, loss: 0.09045708924531937
step: 120, loss: 0.007397629786282778
step: 130, loss: 0.002189334249123931
step: 140, loss: 0.06886876374483109
step: 150, loss: 0.023789886385202408
step: 160, loss: 0.017167044803500175
step: 170, loss: 0.06532544642686844
step: 180, loss: 0.10149765014648438
step: 190, loss: 0.00170528469607234
step: 200, loss: 0.02974502183496952
step: 210, loss: 0.10028587281703949
step: 220, loss: 0.0343005433678627
step: 230, loss: 0.09136682748794556
step: 240, loss: 0.02898637019097805
step: 250, loss: 0.009987554512917995
step: 260, loss: 0.00048526746104471385
step: 270, loss: 0.07778359204530716
step: 280, loss: 0.0066991206258535385
step: 290, loss: 0.06932144612073898
step: 300, loss: 0.01791442185640335
step: 310, loss: 0.010402264073491096
step: 320, loss: 0.05007068067789078
step: 330, loss: 0.017760716378688812
step: 340, loss: 0.06379316747188568
step: 350, loss: 0.023252123966813087
step: 360, loss: 0.09478191286325455
step: 370, loss: 0.040286172181367874
step: 380, loss: 0.03764866665005684
step: 390, loss: 0.01435802411288023
step: 400, loss: 0.06351528316736221
step: 410, loss: 0.13684165477752686
step: 420, loss: 0.04557641223073006
step: 430, loss: 0.009903878904879093
step: 440, loss: 0.0074932267889380455
step: 450, loss: 0.007884127087891102
step: 460, loss: 0.004704218823462725
step: 470, loss: 0.006837133783847094
step: 480, loss: 0.0006405309541150928
step: 490, loss: 0.06340864300727844
step: 500, loss: 0.036801256239414215
step: 510, loss: 0.06407921016216278
step: 520, loss: 0.036935385316610336
step: 530, loss: 0.03380303457379341
step: 540, loss: 0.024184616282582283
step: 550, loss: 0.07692388445138931
step: 560, loss: 0.020473644137382507
step: 570, loss: 0.028001883998513222
step: 580, loss: 0.028814231976866722
step: 590, loss: 0.002895825309678912
step: 600, loss: 0.13203366100788116
step: 610, loss: 0.08092590421438217
step: 620, loss: 0.01371609978377819
step: 630, loss: 0.0497562475502491
step: 640, loss: 0.06468115746974945
step: 650, loss: 0.028894415125250816
step: 660, loss: 0.11738370358943939
step: 670, loss: 0.024003267288208008
step: 680, loss: 0.0058773295022547245
step: 690, loss: 0.03948063403367996
step: 700, loss: 0.0528176985681057
step: 710, loss: 0.0007730105426162481
step: 720, loss: 0.1450769603252411
step: 730, loss: 0.15037856996059418
step: 740, loss: 0.015417042188346386
step: 750, loss: 0.05890593305230141
step: 760, loss: 0.0005288198590278625
step: 770, loss: 0.009902307763695717
step: 780, loss: 0.01634897291660309
step: 790, loss: 0.0718880295753479
step: 800, loss: 0.011906873434782028
step: 810, loss: 0.04390520602464676
step: 820, loss: 0.2200375646352768
step: 830, loss: 0.09746567904949188
step: 840, loss: 0.013192703016102314
step: 850, loss: 0.029273971915245056
step: 860, loss: 0.005548272281885147
step: 870, loss: 0.08819900453090668
step: 880, loss: 0.0072680325247347355
step: 890, loss: 0.00425392109900713
step: 900, loss: 0.0055714878253638744
step: 910, loss: 0.03323718160390854
step: 920, loss: 5.6053100706776604e-05
step: 930, loss: 0.02588493563234806
step: 940, loss: 0.045965149998664856
step: 950, loss: 0.1679292619228363
step: 960, loss: 0.0017091340851038694
step: 970, loss: 0.05344400927424431
epoch 12: dev_f1=0.9330232558139535, f1=0.9396035039188566, best_f1=0.9394785847299814
step: 0, loss: 0.0335477739572525
step: 10, loss: 0.007535866927355528
step: 20, loss: 0.07942470908164978
step: 30, loss: 0.019186122342944145
step: 40, loss: 0.05968208611011505
step: 50, loss: 0.028105178847908974
step: 60, loss: 0.00015361931582447141
step: 70, loss: 0.09165740013122559
step: 80, loss: 0.024295901879668236
step: 90, loss: 0.00297170109115541
step: 100, loss: 0.023944232612848282
step: 110, loss: 0.0746554508805275
step: 120, loss: 0.03051966242492199
step: 130, loss: 0.08461914211511612
step: 140, loss: 0.0786844864487648
step: 150, loss: 0.06999320536851883
step: 160, loss: 0.005227958783507347
step: 170, loss: 0.049748703837394714
step: 180, loss: 0.007000118959695101
step: 190, loss: 0.07589973509311676
step: 200, loss: 0.004467569757252932
step: 210, loss: 0.028519924730062485
step: 220, loss: 0.009106123819947243
step: 230, loss: 1.3835619938618038e-05
step: 240, loss: 0.11230630427598953
step: 250, loss: 0.00010085708345286548
step: 260, loss: 0.07305161654949188
step: 270, loss: 0.032648175954818726
step: 280, loss: 0.033431392163038254
step: 290, loss: 0.007918236777186394
step: 300, loss: 0.03646311163902283
step: 310, loss: 0.15787887573242188
step: 320, loss: 0.0064367568120360374
step: 330, loss: 0.05511009320616722
step: 340, loss: 0.08316460251808167
step: 350, loss: 0.06627774983644485
step: 360, loss: 0.003378022462129593
step: 370, loss: 0.02760525792837143
step: 380, loss: 0.011012585833668709
step: 390, loss: 0.016240723431110382
step: 400, loss: 0.002801027614623308
step: 410, loss: 0.0756877139210701
step: 420, loss: 0.052730392664670944
step: 430, loss: 0.018325485289096832
step: 440, loss: 0.1556975245475769
step: 450, loss: 0.023287704214453697
step: 460, loss: 0.05238807573914528
step: 470, loss: 0.01130277756601572
step: 480, loss: 0.006927874870598316
step: 490, loss: 0.03598006069660187
step: 500, loss: 0.0326676107943058
step: 510, loss: 0.007900076918303967
step: 520, loss: 0.05281246453523636
step: 530, loss: 0.09156643599271774
step: 540, loss: 0.015378031879663467
step: 550, loss: 0.03687814995646477
step: 560, loss: 1.5038838682812639e-05
step: 570, loss: 0.053520649671554565
step: 580, loss: 0.09617388993501663
step: 590, loss: 0.11166831105947495
step: 600, loss: 0.09324833750724792
step: 610, loss: 0.05754636973142624
step: 620, loss: 0.0005871355533599854
step: 630, loss: 0.036168135702610016
step: 640, loss: 0.05418230593204498
step: 650, loss: 0.14060762524604797
step: 660, loss: 0.07126831263303757
step: 670, loss: 0.09110038727521896
step: 680, loss: 0.0139760822057724
step: 690, loss: 0.0004584744747262448
step: 700, loss: 0.04467460885643959
step: 710, loss: 0.030550764873623848
step: 720, loss: 0.030476504936814308
step: 730, loss: 0.09274560958147049
step: 740, loss: 0.0817277655005455
step: 750, loss: 0.06400170177221298
step: 760, loss: 0.022013699635863304
step: 770, loss: 0.22990889847278595
step: 780, loss: 0.03225426375865936
step: 790, loss: 0.027339741587638855
step: 800, loss: 0.020828139036893845
step: 810, loss: 0.021539928391575813
step: 820, loss: 0.03787604346871376
step: 830, loss: 0.01574392430484295
step: 840, loss: 0.04143265262246132
step: 850, loss: 0.01949257403612137
step: 860, loss: 0.0004888552357442677
step: 870, loss: 0.00012642506044358015
step: 880, loss: 0.03720832243561745
step: 890, loss: 0.03438137099146843
step: 900, loss: 0.024275504052639008
step: 910, loss: 0.10986820608377457
step: 920, loss: 0.0564870722591877
step: 930, loss: 0.06151297315955162
step: 940, loss: 0.020238781347870827
step: 950, loss: 0.028059834614396095
step: 960, loss: 0.00014018037472851574
step: 970, loss: 0.011458062566816807
epoch 13: dev_f1=0.9297752808988764, f1=0.9306654257794322, best_f1=0.9394785847299814
step: 0, loss: 0.04387316480278969
step: 10, loss: 0.01705600880086422
step: 20, loss: 0.041261784732341766
step: 30, loss: 0.010501323267817497
step: 40, loss: 0.003442588495090604
step: 50, loss: 0.04631025716662407
step: 60, loss: 0.015421679243445396
step: 70, loss: 0.006569378077983856
step: 80, loss: 0.015593333169817924
step: 90, loss: 0.0661926195025444
step: 100, loss: 0.029058322310447693
step: 110, loss: 0.06307709217071533
step: 120, loss: 0.0008748138789087534
step: 130, loss: 0.039469994604587555
step: 140, loss: 0.0008377822232432663
step: 150, loss: 0.060448769479990005
step: 160, loss: 0.06693930178880692
step: 170, loss: 0.008463854901492596
step: 180, loss: 0.09815970808267593
step: 190, loss: 0.05333995074033737
step: 200, loss: 0.01835457608103752
step: 210, loss: 0.05611370876431465
step: 220, loss: 0.05516858026385307
step: 230, loss: 0.07194994390010834
step: 240, loss: 0.009981917217373848
step: 250, loss: 0.07975125312805176
step: 260, loss: 0.07956822216510773
step: 270, loss: 0.04204721748828888
step: 280, loss: 0.0007246482418850064
step: 290, loss: 0.004475307650864124
step: 300, loss: 0.009752211160957813
step: 310, loss: 0.08918820321559906
step: 320, loss: 0.02008022740483284
step: 330, loss: 0.06019451841711998
step: 340, loss: 0.02212037704885006
step: 350, loss: 0.04129471629858017
step: 360, loss: 0.027742931619286537
step: 370, loss: 0.06381818652153015
step: 380, loss: 0.06601409614086151
step: 390, loss: 0.05080101266503334
step: 400, loss: 0.0005256024305708706
step: 410, loss: 1.918850466609001e-05
step: 420, loss: 0.03942893072962761
step: 430, loss: 0.04058700427412987
step: 440, loss: 0.02676316723227501
step: 450, loss: 0.0823630765080452
step: 460, loss: 0.05593528226017952
step: 470, loss: 0.07453754544258118
step: 480, loss: 0.014038577675819397
step: 490, loss: 0.049820493906736374
step: 500, loss: 0.030711263418197632
step: 510, loss: 9.731468162499368e-05
step: 520, loss: 0.10043329000473022
step: 530, loss: 0.041967108845710754
step: 540, loss: 0.018515238538384438
step: 550, loss: 0.03203441575169563
step: 560, loss: 0.0011814165627583861
step: 570, loss: 0.0004891065764240921
step: 580, loss: 0.00014502622070722282
step: 590, loss: 0.030133148655295372
step: 600, loss: 0.021755265071988106
step: 610, loss: 0.003337201662361622
step: 620, loss: 0.0002004420239245519
step: 630, loss: 0.021901387721300125
step: 640, loss: 0.034428492188453674
step: 650, loss: 0.0013176227221265435
step: 660, loss: 0.03402913734316826
step: 670, loss: 0.02668185718357563
step: 680, loss: 0.03569667413830757
step: 690, loss: 0.023578640073537827
step: 700, loss: 0.0035752668045461178
step: 710, loss: 0.09870043396949768
step: 720, loss: 0.10951554775238037
step: 730, loss: 0.04652605205774307
step: 740, loss: 0.057066988199949265
step: 750, loss: 0.023559782654047012
step: 760, loss: 0.022986693307757378
step: 770, loss: 0.01864210143685341
step: 780, loss: 0.07197139412164688
step: 790, loss: 0.030721968039870262
step: 800, loss: 0.02186446078121662
step: 810, loss: 0.002495412714779377
step: 820, loss: 0.023752886801958084
step: 830, loss: 0.050942014902830124
step: 840, loss: 0.07703337073326111
step: 850, loss: 0.12039589136838913
step: 860, loss: 0.00015133916167542338
step: 870, loss: 0.09083644300699234
step: 880, loss: 0.13619475066661835
step: 890, loss: 0.008686153218150139
step: 900, loss: 0.019807344302535057
step: 910, loss: 0.023087479174137115
step: 920, loss: 0.09236854314804077
step: 930, loss: 0.008828938007354736
step: 940, loss: 0.017081543803215027
step: 950, loss: 0.09772804379463196
step: 960, loss: 0.035362470895051956
step: 970, loss: 0.03487439453601837
epoch 14: dev_f1=0.9353647276084949, f1=0.93646408839779, best_f1=0.9394785847299814
step: 0, loss: 0.006449074950069189
step: 10, loss: 0.03194217383861542
step: 20, loss: 0.03317178040742874
step: 30, loss: 0.046732835471630096
step: 40, loss: 0.005351238884031773
step: 50, loss: 0.021320952102541924
step: 60, loss: 0.039036914706230164
step: 70, loss: 0.034838948398828506
step: 80, loss: 0.0018685043323785067
step: 90, loss: 0.055976979434490204
step: 100, loss: 3.92816546082031e-05
step: 110, loss: 0.0026080908719450235
step: 120, loss: 3.829346314887516e-05
step: 130, loss: 0.03465365245938301
step: 140, loss: 0.02608022652566433
step: 150, loss: 0.030289825052022934
step: 160, loss: 0.02360045164823532
step: 170, loss: 0.0011171107180416584
step: 180, loss: 0.0530925914645195
step: 190, loss: 0.0008542908472009003
step: 200, loss: 0.0003582911449484527
step: 210, loss: 0.07519112527370453
step: 220, loss: 0.02872692048549652
step: 230, loss: 0.04935266822576523
step: 240, loss: 0.05166878178715706
step: 250, loss: 0.002125544473528862
step: 260, loss: 0.025401711463928223
step: 270, loss: 0.032033443450927734
step: 280, loss: 0.06208331882953644
step: 290, loss: 0.00010258398833684623
step: 300, loss: 0.0020303837954998016
step: 310, loss: 0.0003636029432527721
step: 320, loss: 0.021612096577882767
step: 330, loss: 0.049343980848789215
step: 340, loss: 0.02884967066347599
step: 350, loss: 0.053462203592061996
step: 360, loss: 0.05222328007221222
step: 370, loss: 0.1195865124464035
step: 380, loss: 0.046965837478637695
step: 390, loss: 0.037985414266586304
step: 400, loss: 0.024981088936328888
step: 410, loss: 0.00011287956294836476
step: 420, loss: 0.0330800786614418
step: 430, loss: 0.08772368729114532
step: 440, loss: 0.01686001941561699
step: 450, loss: 0.00839915219694376
step: 460, loss: 0.025891486555337906
step: 470, loss: 0.09829536825418472
step: 480, loss: 0.014272245578467846
step: 490, loss: 0.008845320902764797
step: 500, loss: 0.06298190355300903
step: 510, loss: 0.032689183950424194
step: 520, loss: 0.021307973191142082
step: 530, loss: 0.07624442875385284
step: 540, loss: 0.06656759977340698
step: 550, loss: 0.05157960578799248
step: 560, loss: 0.0001630598708288744
step: 570, loss: 0.046630825847387314
step: 580, loss: 0.06509789079427719
step: 590, loss: 0.09560029208660126
step: 600, loss: 0.20018436014652252
step: 610, loss: 0.012618759647011757
step: 620, loss: 0.045830417424440384
step: 630, loss: 4.4052743760403246e-05
step: 640, loss: 0.03905253857374191
step: 650, loss: 0.009885227307677269
step: 660, loss: 0.06918414682149887
step: 670, loss: 0.023600930348038673
step: 680, loss: 0.045751821249723434
step: 690, loss: 0.008855678141117096
step: 700, loss: 0.09961684793233871
step: 710, loss: 0.019469818100333214
step: 720, loss: 0.09964119642972946
step: 730, loss: 0.010651867836713791
step: 740, loss: 0.013895880430936813
step: 750, loss: 0.059977930039167404
step: 760, loss: 0.013979688286781311
step: 770, loss: 0.06039733812212944
step: 780, loss: 0.09126187860965729
step: 790, loss: 0.07759422808885574
step: 800, loss: 0.025514965876936913
step: 810, loss: 0.04860717058181763
step: 820, loss: 0.029559511691331863
step: 830, loss: 0.007488994859158993
step: 840, loss: 0.04210300371050835
step: 850, loss: 0.031729016453027725
step: 860, loss: 0.02935081720352173
step: 870, loss: 0.0086117684841156
step: 880, loss: 0.004802066367119551
step: 890, loss: 3.415218088775873e-05
step: 900, loss: 0.031780142337083817
step: 910, loss: 0.02435561828315258
step: 920, loss: 0.006434604991227388
step: 930, loss: 0.036565400660037994
step: 940, loss: 0.02929406426846981
step: 950, loss: 0.12181387096643448
step: 960, loss: 0.06689740717411041
step: 970, loss: 0.0005230001988820732
epoch 15: dev_f1=0.931892907468295, f1=0.9328953542937587, best_f1=0.9394785847299814
step: 0, loss: 0.01726730726659298
step: 10, loss: 0.04502439126372337
step: 20, loss: 0.02484585903584957
step: 30, loss: 0.0004313513054512441
step: 40, loss: 0.014008420519530773
step: 50, loss: 0.07143518328666687
step: 60, loss: 0.012679878622293472
step: 70, loss: 0.061895087361335754
step: 80, loss: 0.022978292778134346
step: 90, loss: 0.015455481596291065
step: 100, loss: 0.0585365816950798
step: 110, loss: 0.019721701741218567
step: 120, loss: 0.06894544512033463
step: 130, loss: 0.0625990778207779
step: 140, loss: 0.02388588897883892
step: 150, loss: 0.1149650439620018
step: 160, loss: 0.019500097259879112
step: 170, loss: 0.03441046178340912
step: 180, loss: 0.000567182432860136
step: 190, loss: 0.04189720004796982
step: 200, loss: 0.0016568033024668694
step: 210, loss: 0.054491348564624786
step: 220, loss: 0.05014333128929138
step: 230, loss: 0.02368807978928089
step: 240, loss: 5.909694664296694e-05
step: 250, loss: 0.06671158969402313
step: 260, loss: 0.009763961657881737
step: 270, loss: 0.034232426434755325
step: 280, loss: 0.0016271340427920222
step: 290, loss: 0.015167837031185627
step: 300, loss: 0.0005497200763784349
step: 310, loss: 0.03717906400561333
step: 320, loss: 0.0026766143273562193
step: 330, loss: 0.011896190233528614
step: 340, loss: 0.026225542649626732
step: 350, loss: 0.00016796209092717618
step: 360, loss: 0.1297404170036316
step: 370, loss: 0.0019064408261328936
step: 380, loss: 0.0396600142121315
step: 390, loss: 0.06879904866218567
step: 400, loss: 0.038577474653720856
step: 410, loss: 0.007801508996635675
step: 420, loss: 0.05265204980969429
step: 430, loss: 0.05811816081404686
step: 440, loss: 0.023908954113721848
step: 450, loss: 0.022775989025831223
step: 460, loss: 0.02251807041466236
step: 470, loss: 0.007508999202400446
step: 480, loss: 0.0007450350094586611
step: 490, loss: 0.0014505133731290698
step: 500, loss: 0.021892407909035683
step: 510, loss: 0.12422259896993637
step: 520, loss: 0.01935199275612831
step: 530, loss: 0.04381819814443588
step: 540, loss: 0.08579961210489273
step: 550, loss: 0.0377994179725647
step: 560, loss: 0.016791630536317825
step: 570, loss: 0.00030646781669929624
step: 580, loss: 0.00023407506523653865
step: 590, loss: 0.022340508177876472
step: 600, loss: 0.04597941413521767
step: 610, loss: 0.05571351945400238
step: 620, loss: 0.04675844684243202
step: 630, loss: 0.0391499400138855
step: 640, loss: 0.03664889931678772
step: 650, loss: 0.01920494996011257
step: 660, loss: 0.017378617078065872
step: 670, loss: 0.0008509426843374968
step: 680, loss: 0.011171620339155197
step: 690, loss: 0.05049648880958557
step: 700, loss: 0.02088528499007225
step: 710, loss: 0.00010491181456018239
step: 720, loss: 0.014379785396158695
step: 730, loss: 0.08213480561971664
step: 740, loss: 0.02595251426100731
step: 750, loss: 0.007970547303557396
step: 760, loss: 0.00021128803200554103
step: 770, loss: 0.002481841016560793
step: 780, loss: 0.024373264983296394
step: 790, loss: 0.06803963333368301
step: 800, loss: 0.0010975729674100876
step: 810, loss: 0.05000108852982521
step: 820, loss: 0.05808626115322113
step: 830, loss: 0.015441462397575378
step: 840, loss: 0.04090188816189766
step: 850, loss: 1.1108745638921391e-05
step: 860, loss: 0.09632328897714615
step: 870, loss: 0.04433228075504303
step: 880, loss: 0.03615400567650795
step: 890, loss: 0.06611686944961548
step: 900, loss: 0.00024121486057993025
step: 910, loss: 0.026929352432489395
step: 920, loss: 0.003186820074915886
step: 930, loss: 0.027974404394626617
step: 940, loss: 0.0014819318894296885
step: 950, loss: 0.029631519690155983
step: 960, loss: 0.03678321838378906
step: 970, loss: 0.03445286676287651
epoch 16: dev_f1=0.9328984156570364, f1=0.9337656322371468, best_f1=0.9394785847299814
step: 0, loss: 0.02149626612663269
step: 10, loss: 0.030929606407880783
step: 20, loss: 0.045681294053792953
step: 30, loss: 0.09011442214250565
step: 40, loss: 0.0229022316634655
step: 50, loss: 0.03359160199761391
step: 60, loss: 0.0627114474773407
step: 70, loss: 0.0643911063671112
step: 80, loss: 0.04661495238542557
step: 90, loss: 0.02690913900732994
step: 100, loss: 0.0222718957811594
step: 110, loss: 0.036362890154123306
step: 120, loss: 0.031810883432626724
step: 130, loss: 0.03006749600172043
step: 140, loss: 0.05002656579017639
step: 150, loss: 0.02761642076075077
step: 160, loss: 9.103952470468357e-05
step: 170, loss: 0.008012634702026844
step: 180, loss: 0.07387875020503998
step: 190, loss: 0.031046761199831963
step: 200, loss: 0.022517818957567215
step: 210, loss: 0.04272611811757088
step: 220, loss: 0.000830798817332834
step: 230, loss: 0.044320669025182724
step: 240, loss: 4.894971425528638e-05
step: 250, loss: 0.04693625494837761
step: 260, loss: 0.07940474152565002
step: 270, loss: 0.006971639581024647
step: 280, loss: 0.018282197415828705
step: 290, loss: 0.012690525501966476
step: 300, loss: 0.005326797720044851
step: 310, loss: 0.0005574030219577253
step: 320, loss: 0.005732013378292322
step: 330, loss: 0.020503312349319458
step: 340, loss: 0.02372455969452858
step: 350, loss: 0.03138211369514465
step: 360, loss: 0.0004836382868234068
step: 370, loss: 0.038495272397994995
step: 380, loss: 0.046853598207235336
step: 390, loss: 6.05340683250688e-05
step: 400, loss: 0.06561382114887238
step: 410, loss: 0.02754891850054264
step: 420, loss: 0.027125021442770958
step: 430, loss: 0.03866245597600937
step: 440, loss: 0.03957713395357132
step: 450, loss: 0.026340825483202934
step: 460, loss: 0.020072972401976585
step: 470, loss: 0.0002872726181522012
step: 480, loss: 0.0855390727519989
step: 490, loss: 0.03540026769042015
step: 500, loss: 0.0599844865500927
step: 510, loss: 0.1510079801082611
step: 520, loss: 0.0554281622171402
step: 530, loss: 0.07689669728279114
step: 540, loss: 0.04362130165100098
step: 550, loss: 0.017276639118790627
step: 560, loss: 0.014621833339333534
step: 570, loss: 6.211177969817072e-05
step: 580, loss: 3.414683305891231e-05
step: 590, loss: 0.01553392969071865
step: 600, loss: 0.005810832139104605
step: 610, loss: 0.0006458613206632435
step: 620, loss: 0.042115677148103714
step: 630, loss: 0.03392690792679787
step: 640, loss: 0.018141021952033043
step: 650, loss: 0.04682454839348793
step: 660, loss: 0.00011792188161052763
step: 670, loss: 0.03859664127230644
step: 680, loss: 0.02622823789715767
step: 690, loss: 0.025211762636899948
step: 700, loss: 0.00023629989300388843
step: 710, loss: 0.029608380049467087
step: 720, loss: 0.022734256461262703
step: 730, loss: 0.02994535304605961
step: 740, loss: 0.045499008148908615
step: 750, loss: 0.039901379495859146
step: 760, loss: 0.09780971705913544
step: 770, loss: 0.014018953777849674
step: 780, loss: 0.06313003599643707
step: 790, loss: 0.01184091717004776
step: 800, loss: 0.03584851324558258
step: 810, loss: 0.09096499532461166
step: 820, loss: 0.03393568471074104
step: 830, loss: 0.00010937543265754357
step: 840, loss: 0.06982794404029846
step: 850, loss: 0.03564276546239853
step: 860, loss: 0.04221701622009277
step: 870, loss: 0.11916013807058334
step: 880, loss: 0.036623746156692505
step: 890, loss: 0.04598137363791466
step: 900, loss: 0.021162863820791245
step: 910, loss: 0.08893115073442459
step: 920, loss: 0.025328736752271652
step: 930, loss: 3.9797116187401116e-05
step: 940, loss: 0.010020722635090351
step: 950, loss: 0.0324995256960392
step: 960, loss: 0.001656159060075879
step: 970, loss: 0.0874321311712265
epoch 17: dev_f1=0.9265536723163843, f1=0.9262371615312792, best_f1=0.9394785847299814
step: 0, loss: 0.0493604950606823
step: 10, loss: 0.000587605289183557
step: 20, loss: 0.051603030413389206
step: 30, loss: 0.016592372208833694
step: 40, loss: 0.026938393712043762
step: 50, loss: 0.05674362555146217
step: 60, loss: 0.019468942657113075
step: 70, loss: 0.016754960641264915
step: 80, loss: 0.051722779870033264
step: 90, loss: 0.0030768830329179764
step: 100, loss: 0.0001061477669281885
step: 110, loss: 0.029477398842573166
step: 120, loss: 0.0002832417085301131
step: 130, loss: 4.133327092858963e-05
step: 140, loss: 0.08652397245168686
step: 150, loss: 0.022592362016439438
step: 160, loss: 0.01984504424035549
step: 170, loss: 0.0001434150617569685
step: 180, loss: 0.01400978583842516
step: 190, loss: 6.610871787415817e-05
step: 200, loss: 0.044094134122133255
step: 210, loss: 0.0002526014286559075
step: 220, loss: 0.06311090290546417
step: 230, loss: 0.021770145744085312
step: 240, loss: 0.04132571443915367
step: 250, loss: 0.07786227017641068
step: 260, loss: 0.03870484605431557
step: 270, loss: 0.01638456992805004
step: 280, loss: 0.03235927224159241
step: 290, loss: 0.043596189469099045
step: 300, loss: 0.0479283332824707
step: 310, loss: 0.023715272545814514
step: 320, loss: 0.06394045799970627
step: 330, loss: 2.469121136527974e-05
step: 340, loss: 0.07714063674211502
step: 350, loss: 0.021008091047406197
step: 360, loss: 0.014915918931365013
step: 370, loss: 0.01331300102174282
step: 380, loss: 0.10532138496637344
step: 390, loss: 0.09248435497283936
step: 400, loss: 0.0003110250399913639
step: 410, loss: 0.11187765747308731
step: 420, loss: 0.018501169979572296
step: 430, loss: 0.054033130407333374
step: 440, loss: 2.71320477622794e-05
step: 450, loss: 0.030322231352329254
step: 460, loss: 0.0011089766630902886
step: 470, loss: 0.00015874030941631645
step: 480, loss: 0.022389313206076622
step: 490, loss: 0.01931152492761612
step: 500, loss: 0.037290964275598526
step: 510, loss: 0.04995819926261902
step: 520, loss: 0.0401800274848938
step: 530, loss: 0.03160924091935158
step: 540, loss: 0.020790785551071167
step: 550, loss: 0.06725399941205978
step: 560, loss: 0.07267022877931595
step: 570, loss: 0.027658842504024506
step: 580, loss: 0.02666361816227436
step: 590, loss: 0.02383105456829071
step: 600, loss: 0.058064647018909454
step: 610, loss: 0.019743777811527252
step: 620, loss: 0.020214617252349854
step: 630, loss: 0.020371295511722565
step: 640, loss: 0.003087293589487672
step: 650, loss: 0.02139202505350113
step: 660, loss: 0.07356707751750946
step: 670, loss: 0.01259091030806303
step: 680, loss: 0.0286862775683403
step: 690, loss: 0.04622798040509224
step: 700, loss: 0.021053407341241837
step: 710, loss: 0.04988197609782219
step: 720, loss: 0.007125245872884989
step: 730, loss: 0.04886462166905403
step: 740, loss: 0.03326428681612015
step: 750, loss: 0.03211827576160431
step: 760, loss: 0.0463181771337986
step: 770, loss: 5.9687168686650693e-05
step: 780, loss: 0.023793287575244904
step: 790, loss: 0.05317823961377144
step: 800, loss: 0.025395197793841362
step: 810, loss: 0.07528920471668243
step: 820, loss: 0.07198160141706467
step: 830, loss: 0.009331968612968922
step: 840, loss: 0.024326574057340622
step: 850, loss: 0.031015479937195778
step: 860, loss: 0.0007885412196628749
step: 870, loss: 0.00032435095636174083
step: 880, loss: 0.07542470097541809
step: 890, loss: 0.036350782960653305
step: 900, loss: 0.00019405897182878107
step: 910, loss: 0.02110612764954567
step: 920, loss: 0.0005928974715061486
step: 930, loss: 0.10008654743432999
step: 940, loss: 0.024659914895892143
step: 950, loss: 0.03141403943300247
step: 960, loss: 0.01631820946931839
step: 970, loss: 0.03340966999530792
epoch 18: dev_f1=0.9312119794103885, f1=0.9324009324009325, best_f1=0.9394785847299814
step: 0, loss: 0.05136746168136597
step: 10, loss: 0.0527709424495697
step: 20, loss: 0.030428264290094376
step: 30, loss: 0.01537328865379095
step: 40, loss: 8.677957521285862e-05
step: 50, loss: 0.024355869740247726
step: 60, loss: 0.02187599241733551
step: 70, loss: 0.0001080555230146274
step: 80, loss: 0.04635006934404373
step: 90, loss: 0.012921284884214401
step: 100, loss: 0.0005494951037690043
step: 110, loss: 0.011184057220816612
step: 120, loss: 0.04554828628897667
step: 130, loss: 0.055651821196079254
step: 140, loss: 0.0768735259771347
step: 150, loss: 0.002980769844725728
step: 160, loss: 0.06352853775024414
step: 170, loss: 0.060102835297584534
step: 180, loss: 3.5908153222408146e-05
step: 190, loss: 0.07913801074028015
step: 200, loss: 0.0315108485519886
step: 210, loss: 0.02132290042936802
step: 220, loss: 0.00985105149447918
step: 230, loss: 0.022395534440875053
step: 240, loss: 0.039232440292835236
step: 250, loss: 0.018380368128418922
step: 260, loss: 0.015931257978081703
step: 270, loss: 0.051259689033031464
step: 280, loss: 3.546031075529754e-05
step: 290, loss: 0.0002267587697133422
step: 300, loss: 0.03753405064344406
step: 310, loss: 0.021013924852013588
step: 320, loss: 0.03760826215147972
step: 330, loss: 0.04713436961174011
step: 340, loss: 0.06956475228071213
step: 350, loss: 0.0039956760592758656
step: 360, loss: 0.08081438392400742
step: 370, loss: 5.892228364245966e-05
step: 380, loss: 0.024555014446377754
step: 390, loss: 0.0006484550540335476
step: 400, loss: 0.0018278170609846711
step: 410, loss: 0.012791415676474571
step: 420, loss: 0.022665515542030334
step: 430, loss: 0.00043931035907007754
step: 440, loss: 0.03274960815906525
step: 450, loss: 0.02651251293718815
step: 460, loss: 0.0677458867430687
step: 470, loss: 0.00018489715876057744
step: 480, loss: 0.04883291944861412
step: 490, loss: 0.02328445389866829
step: 500, loss: 7.1789683715906e-05
step: 510, loss: 0.007685573305934668
step: 520, loss: 0.08975521475076675
step: 530, loss: 0.07293353974819183
step: 540, loss: 0.04508906230330467
step: 550, loss: 0.06403298676013947
step: 560, loss: 0.09380876272916794
step: 570, loss: 0.05506006255745888
step: 580, loss: 0.02652181126177311
step: 590, loss: 9.548744856147096e-05
step: 600, loss: 0.1015540063381195
step: 610, loss: 0.00906986091285944
step: 620, loss: 0.05417865887284279
step: 630, loss: 0.00045206231880001724
step: 640, loss: 0.032951660454273224
step: 650, loss: 6.533979467349127e-05
step: 660, loss: 0.047642435878515244
step: 670, loss: 0.06713229417800903
step: 680, loss: 0.054318491369485855
step: 690, loss: 0.04612977057695389
step: 700, loss: 0.058911118656396866
step: 710, loss: 0.021518073976039886
step: 720, loss: 0.0008677582954987884
step: 730, loss: 0.00476949755102396
step: 740, loss: 0.05471668764948845
step: 750, loss: 0.051959190517663956
step: 760, loss: 0.04866587743163109
step: 770, loss: 0.0004285482573322952
step: 780, loss: 0.00436626560986042
step: 790, loss: 0.07762542366981506
step: 800, loss: 0.01806451566517353
step: 810, loss: 0.09414009004831314
step: 820, loss: 0.04853176325559616
step: 830, loss: 0.03428793326020241
step: 840, loss: 0.03096003085374832
step: 850, loss: 3.0209104806999676e-05
step: 860, loss: 0.04409018158912659
step: 870, loss: 0.0023560819681733847
step: 880, loss: 0.027479643002152443
step: 890, loss: 0.003273699199780822
step: 900, loss: 0.038077179342508316
step: 910, loss: 0.0789143443107605
step: 920, loss: 0.020566053688526154
step: 930, loss: 0.0233296025544405
step: 940, loss: 0.02514590322971344
step: 950, loss: 0.06703555583953857
step: 960, loss: 0.002027503214776516
step: 970, loss: 0.072059765458107
epoch 19: dev_f1=0.9318394024276377, f1=0.9324074074074072, best_f1=0.9394785847299814
step: 0, loss: 0.07600414007902145
step: 10, loss: 0.00010523285163799301
step: 20, loss: 0.08046954870223999
step: 30, loss: 0.04484248906373978
step: 40, loss: 0.03861507028341293
step: 50, loss: 0.00014811551955062896
step: 60, loss: 0.05496357008814812
step: 70, loss: 0.020972667261958122
step: 80, loss: 0.042793240398168564
step: 90, loss: 0.03243342414498329
step: 100, loss: 0.004389265086501837
step: 110, loss: 0.0016667302697896957
step: 120, loss: 5.702086855308153e-05
step: 130, loss: 8.36715626064688e-05
step: 140, loss: 0.0002331603755010292
step: 150, loss: 5.254208736005239e-05
step: 160, loss: 0.03385200351476669
step: 170, loss: 0.056997835636138916
step: 180, loss: 0.036697790026664734
step: 190, loss: 0.046710606664419174
step: 200, loss: 2.9415678000077605e-05
step: 210, loss: 0.0005428267177194357
step: 220, loss: 0.11520514637231827
step: 230, loss: 0.021467609331011772
step: 240, loss: 0.02378167398273945
step: 250, loss: 0.029078206047415733
step: 260, loss: 0.0778079479932785
step: 270, loss: 6.717432552250102e-05
step: 280, loss: 0.0305736493319273
step: 290, loss: 0.00016951982979662716
step: 300, loss: 0.02338029071688652
step: 310, loss: 6.650330760749057e-05
step: 320, loss: 2.507898534531705e-05
step: 330, loss: 0.03467608615756035
step: 340, loss: 0.02959449216723442
step: 350, loss: 0.026596536859869957
step: 360, loss: 0.0015102513134479523
step: 370, loss: 0.042543016374111176
step: 380, loss: 0.02127680368721485
step: 390, loss: 0.06385837495326996
step: 400, loss: 0.06449446082115173
step: 410, loss: 0.0030933143571019173
step: 420, loss: 5.9570607845671475e-05
step: 430, loss: 0.029227955266833305
step: 440, loss: 0.05064142122864723
step: 450, loss: 0.02524130418896675
step: 460, loss: 0.02560770884156227
step: 470, loss: 0.061458516865968704
step: 480, loss: 0.061341721564531326
step: 490, loss: 0.023913340643048286
step: 500, loss: 0.02215741202235222
step: 510, loss: 0.00010246176680084318
step: 520, loss: 7.048586121527478e-05
step: 530, loss: 0.0005911746993660927
step: 540, loss: 0.04516591504216194
step: 550, loss: 0.031247245147824287
step: 560, loss: 0.012837043032050133
step: 570, loss: 0.0317571647465229
step: 580, loss: 0.0591687336564064
step: 590, loss: 0.04911694675683975
step: 600, loss: 5.019117088522762e-05
step: 610, loss: 0.00010984489199472591
step: 620, loss: 0.025998802855610847
step: 630, loss: 0.023150606080889702
step: 640, loss: 0.027109419927001
step: 650, loss: 0.0002435019559925422
step: 660, loss: 0.020558247342705727
step: 670, loss: 0.018227797001600266
step: 680, loss: 0.0070267850533127785
step: 690, loss: 0.001941822236403823
step: 700, loss: 0.06479562819004059
step: 710, loss: 0.050875283777713776
step: 720, loss: 0.04919315502047539
step: 730, loss: 0.029719887301325798
step: 740, loss: 0.021006781607866287
step: 750, loss: 9.166048403130844e-05
step: 760, loss: 0.03442206606268883
step: 770, loss: 0.04237549006938934
step: 780, loss: 0.025595281273126602
step: 790, loss: 0.0006281731184571981
step: 800, loss: 0.0007438040338456631
step: 810, loss: 0.018227634951472282
step: 820, loss: 0.06862536817789078
step: 830, loss: 5.907472223043442e-05
step: 840, loss: 0.026642870157957077
step: 850, loss: 0.045600779354572296
step: 860, loss: 0.00018994389392901212
step: 870, loss: 0.04664163291454315
step: 880, loss: 1.7224740076926537e-05
step: 890, loss: 0.015289396047592163
step: 900, loss: 0.055723343044519424
step: 910, loss: 4.9543999921297655e-05
step: 920, loss: 0.0001433971046935767
step: 930, loss: 0.041141122579574585
step: 940, loss: 0.12952634692192078
step: 950, loss: 0.08742454648017883
step: 960, loss: 1.1518508472363465e-05
step: 970, loss: 0.01179567351937294
epoch 20: dev_f1=0.9305361305361305, f1=0.932963476652797, best_f1=0.9394785847299814
