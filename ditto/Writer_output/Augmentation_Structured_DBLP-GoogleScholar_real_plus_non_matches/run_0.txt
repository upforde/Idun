cuda
Device: cuda
step: 0, loss: 0.5910621285438538
step: 10, loss: 0.2440924346446991
step: 20, loss: 0.15355603396892548
step: 30, loss: 0.23552146553993225
step: 40, loss: 0.20095504820346832
step: 50, loss: 0.13772757351398468
step: 60, loss: 0.10599064081907272
step: 70, loss: 0.23186303675174713
step: 80, loss: 0.1824789047241211
step: 90, loss: 0.12067267298698425
step: 100, loss: 0.09328391402959824
step: 110, loss: 0.24281388521194458
step: 120, loss: 0.14965705573558807
step: 130, loss: 0.0855332762002945
step: 140, loss: 0.13125811517238617
step: 150, loss: 0.11493504047393799
step: 160, loss: 0.10038851946592331
step: 170, loss: 0.16408328711986542
step: 180, loss: 0.35441696643829346
step: 190, loss: 0.14822062849998474
step: 200, loss: 0.06315378099679947
step: 210, loss: 0.20124676823616028
step: 220, loss: 0.12353648245334625
step: 230, loss: 0.14413514733314514
step: 240, loss: 0.04479026794433594
step: 250, loss: 0.19606240093708038
step: 260, loss: 0.11184486746788025
step: 270, loss: 0.12475453317165375
step: 280, loss: 0.13716940581798553
step: 290, loss: 0.051381900906562805
step: 300, loss: 0.2011929154396057
step: 310, loss: 0.08731602877378464
step: 320, loss: 0.14027072489261627
step: 330, loss: 0.031809836626052856
step: 340, loss: 0.1076158881187439
step: 350, loss: 0.22796370089054108
step: 360, loss: 0.16143390536308289
step: 370, loss: 0.06438197195529938
step: 380, loss: 0.1376207023859024
step: 390, loss: 0.04552355408668518
step: 400, loss: 0.08808634430170059
step: 410, loss: 0.1507733166217804
step: 420, loss: 0.09237723797559738
step: 430, loss: 0.1378946155309677
step: 440, loss: 0.19103874266147614
step: 450, loss: 0.20010237395763397
step: 460, loss: 0.09172111749649048
step: 470, loss: 0.039132535457611084
step: 480, loss: 0.06604252755641937
step: 490, loss: 0.06924030184745789
step: 500, loss: 0.11591924726963043
step: 510, loss: 0.11238617449998856
step: 520, loss: 0.09536516666412354
step: 530, loss: 0.022247567772865295
step: 540, loss: 0.20287589728832245
step: 550, loss: 0.2940845489501953
step: 560, loss: 0.14975112676620483
step: 570, loss: 0.06266732513904572
step: 580, loss: 0.04367506504058838
step: 590, loss: 0.06479530781507492
step: 600, loss: 0.12075895816087723
step: 610, loss: 0.10065849125385284
step: 620, loss: 0.05857088044285774
step: 630, loss: 0.15294639766216278
step: 640, loss: 0.12439876049757004
step: 650, loss: 0.19961796700954437
step: 660, loss: 0.10931313037872314
step: 670, loss: 0.2105005383491516
step: 680, loss: 0.1231209933757782
step: 690, loss: 0.12551935017108917
step: 700, loss: 0.045026589184999466
step: 710, loss: 0.04908083751797676
step: 720, loss: 0.08705344051122665
step: 730, loss: 0.26676514744758606
step: 740, loss: 0.0818539708852768
step: 750, loss: 0.08276472985744476
step: 760, loss: 0.12070213258266449
step: 770, loss: 0.05132552981376648
step: 780, loss: 0.14904893934726715
step: 790, loss: 0.03758347034454346
step: 800, loss: 0.0646478608250618
step: 810, loss: 0.05206623673439026
step: 820, loss: 0.17090635001659393
step: 830, loss: 0.14671488106250763
step: 840, loss: 0.041018787771463394
step: 850, loss: 0.23463286459445953
step: 860, loss: 0.10133830457925797
step: 870, loss: 0.21190348267555237
step: 880, loss: 0.15040625631809235
step: 890, loss: 0.15552523732185364
step: 900, loss: 0.23593103885650635
step: 910, loss: 0.16270732879638672
step: 920, loss: 0.0828499123454094
step: 930, loss: 0.14588429033756256
step: 940, loss: 0.1652543693780899
step: 950, loss: 0.18424458801746368
step: 960, loss: 0.09077082574367523
step: 970, loss: 0.16622695326805115
epoch 1: dev_f1=0.9153488372093024, f1=0.9168207024029574, best_f1=0.9168207024029574
step: 0, loss: 0.024949343875050545
step: 10, loss: 0.08557044714689255
step: 20, loss: 0.15476436913013458
step: 30, loss: 0.024806760251522064
step: 40, loss: 0.07123026996850967
step: 50, loss: 0.11916304379701614
step: 60, loss: 0.17252543568611145
step: 70, loss: 0.4183640480041504
step: 80, loss: 0.045257311314344406
step: 90, loss: 0.1379953920841217
step: 100, loss: 0.06417198479175568
step: 110, loss: 0.10020899027585983
step: 120, loss: 0.10126002132892609
step: 130, loss: 0.11299854516983032
step: 140, loss: 0.10459570586681366
step: 150, loss: 0.03749736025929451
step: 160, loss: 0.0307480376213789
step: 170, loss: 0.08184128254652023
step: 180, loss: 0.13827389478683472
step: 190, loss: 0.10615571588277817
step: 200, loss: 0.034739162772893906
step: 210, loss: 0.10578394681215286
step: 220, loss: 0.09189199656248093
step: 230, loss: 0.039306629449129105
step: 240, loss: 0.02000969462096691
step: 250, loss: 0.08799117058515549
step: 260, loss: 0.06061786413192749
step: 270, loss: 0.05857783555984497
step: 280, loss: 0.15794526040554047
step: 290, loss: 0.14105138182640076
step: 300, loss: 0.05193409323692322
step: 310, loss: 0.13892371952533722
step: 320, loss: 0.13670380413532257
step: 330, loss: 0.14227554202079773
step: 340, loss: 0.08750849962234497
step: 350, loss: 0.06777383387088776
step: 360, loss: 0.0983116403222084
step: 370, loss: 0.10606284439563751
step: 380, loss: 0.2945055365562439
step: 390, loss: 0.037974752485752106
step: 400, loss: 0.15168018639087677
step: 410, loss: 0.1554974466562271
step: 420, loss: 0.1577456146478653
step: 430, loss: 0.054734934121370316
step: 440, loss: 0.11396123468875885
step: 450, loss: 0.019620142877101898
step: 460, loss: 0.052547283470630646
step: 470, loss: 0.07223241776227951
step: 480, loss: 0.029017889872193336
step: 490, loss: 0.1601887047290802
step: 500, loss: 0.28450748324394226
step: 510, loss: 0.06137549877166748
step: 520, loss: 0.12202677875757217
step: 530, loss: 0.12367052584886551
step: 540, loss: 0.06927052140235901
step: 550, loss: 0.13364917039871216
step: 560, loss: 0.053562093526124954
step: 570, loss: 0.050469741225242615
step: 580, loss: 0.15560109913349152
step: 590, loss: 0.09899626672267914
step: 600, loss: 0.12743833661079407
step: 610, loss: 0.09394736588001251
step: 620, loss: 0.09688345342874527
step: 630, loss: 0.13190282881259918
step: 640, loss: 0.08382942527532578
step: 650, loss: 0.04266519099473953
step: 660, loss: 0.1400335133075714
step: 670, loss: 0.04850851744413376
step: 680, loss: 0.10959064960479736
step: 690, loss: 0.03274060785770416
step: 700, loss: 0.07286251336336136
step: 710, loss: 0.017402231693267822
step: 720, loss: 0.06476129591464996
step: 730, loss: 0.14051564037799835
step: 740, loss: 0.08768370747566223
step: 750, loss: 0.037560295313596725
step: 760, loss: 0.04794355109333992
step: 770, loss: 0.1616857647895813
step: 780, loss: 0.028165781870484352
step: 790, loss: 0.07800483703613281
step: 800, loss: 0.14719663560390472
step: 810, loss: 0.07783399522304535
step: 820, loss: 0.06400256603956223
step: 830, loss: 0.08756715804338455
step: 840, loss: 0.033797454088926315
step: 850, loss: 0.022130565717816353
step: 860, loss: 0.07207094877958298
step: 870, loss: 0.048130348324775696
step: 880, loss: 0.1886480301618576
step: 890, loss: 0.11425696313381195
step: 900, loss: 0.18706576526165009
step: 910, loss: 0.1801844984292984
step: 920, loss: 0.07587140053510666
step: 930, loss: 0.15452447533607483
step: 940, loss: 0.13050763309001923
step: 950, loss: 0.17068418860435486
step: 960, loss: 0.1479726880788803
step: 970, loss: 0.21248774230480194
epoch 2: dev_f1=0.9321016166281756, f1=0.9325946445060019, best_f1=0.9325946445060019
step: 0, loss: 0.10289225727319717
step: 10, loss: 0.07791152596473694
step: 20, loss: 0.05322054401040077
step: 30, loss: 0.029381198808550835
step: 40, loss: 0.013511650264263153
step: 50, loss: 0.10136490315198898
step: 60, loss: 0.02565159648656845
step: 70, loss: 0.02933817356824875
step: 80, loss: 0.08173921704292297
step: 90, loss: 0.03507845848798752
step: 100, loss: 0.03637371212244034
step: 110, loss: 0.030886467546224594
step: 120, loss: 0.05803574621677399
step: 130, loss: 0.004254113882780075
step: 140, loss: 0.20800890028476715
step: 150, loss: 0.09087593108415604
step: 160, loss: 0.15043063461780548
step: 170, loss: 0.14035123586654663
step: 180, loss: 0.0653492882847786
step: 190, loss: 0.08270151168107986
step: 200, loss: 0.0747966542840004
step: 210, loss: 0.08478592336177826
step: 220, loss: 0.136307030916214
step: 230, loss: 0.07332261651754379
step: 240, loss: 0.010049674659967422
step: 250, loss: 0.1148950606584549
step: 260, loss: 0.1117883175611496
step: 270, loss: 0.0801268070936203
step: 280, loss: 0.04660871624946594
step: 290, loss: 0.013611364178359509
step: 300, loss: 0.21870321035385132
step: 310, loss: 0.07638590782880783
step: 320, loss: 0.043655477464199066
step: 330, loss: 0.06411963701248169
step: 340, loss: 0.06102793663740158
step: 350, loss: 0.11851165443658829
step: 360, loss: 0.15901769697666168
step: 370, loss: 0.06149109825491905
step: 380, loss: 0.008525099605321884
step: 390, loss: 0.10434572398662567
step: 400, loss: 0.12162452936172485
step: 410, loss: 0.07245846837759018
step: 420, loss: 0.032592374831438065
step: 430, loss: 0.08602270483970642
step: 440, loss: 0.04886263981461525
step: 450, loss: 0.03490297496318817
step: 460, loss: 0.08610231429338455
step: 470, loss: 0.14836110174655914
step: 480, loss: 0.06471390277147293
step: 490, loss: 0.03408681973814964
step: 500, loss: 0.08467535674571991
step: 510, loss: 0.040098756551742554
step: 520, loss: 0.057287827134132385
step: 530, loss: 0.054684773087501526
step: 540, loss: 0.0729878693819046
step: 550, loss: 0.05565326288342476
step: 560, loss: 0.050721682608127594
step: 570, loss: 0.12322446703910828
step: 580, loss: 0.11960434913635254
step: 590, loss: 0.06523073464632034
step: 600, loss: 0.11910970509052277
step: 610, loss: 0.12373112887144089
step: 620, loss: 0.021354278549551964
step: 630, loss: 0.08175133168697357
step: 640, loss: 0.08612343668937683
step: 650, loss: 0.16401298344135284
step: 660, loss: 0.08004233241081238
step: 670, loss: 0.20367568731307983
step: 680, loss: 0.03238333389163017
step: 690, loss: 0.07097507268190384
step: 700, loss: 0.11496704816818237
step: 710, loss: 0.07058098912239075
step: 720, loss: 0.018659943714737892
step: 730, loss: 0.015046622604131699
step: 740, loss: 0.1390801966190338
step: 750, loss: 0.12569205462932587
step: 760, loss: 0.08259391039609909
step: 770, loss: 0.07053948193788528
step: 780, loss: 0.0337824709713459
step: 790, loss: 0.05263596400618553
step: 800, loss: 0.09010064601898193
step: 810, loss: 0.04123295098543167
step: 820, loss: 0.04751243814826012
step: 830, loss: 0.1895112842321396
step: 840, loss: 0.08297055959701538
step: 850, loss: 0.13369497656822205
step: 860, loss: 0.1555825024843216
step: 870, loss: 0.011576160788536072
step: 880, loss: 0.06270608305931091
step: 890, loss: 0.050056520849466324
step: 900, loss: 0.11178356409072876
step: 910, loss: 0.07847799360752106
step: 920, loss: 0.02349114418029785
step: 930, loss: 0.1704641580581665
step: 940, loss: 0.13193446397781372
step: 950, loss: 0.009524567052721977
step: 960, loss: 0.04983235523104668
step: 970, loss: 0.10226226598024368
epoch 3: dev_f1=0.9304467987102718, f1=0.9310027598896043, best_f1=0.9325946445060019
step: 0, loss: 0.1091151013970375
step: 10, loss: 0.025551671162247658
step: 20, loss: 0.12166331708431244
step: 30, loss: 0.2014605551958084
step: 40, loss: 0.18639379739761353
step: 50, loss: 0.02859957329928875
step: 60, loss: 0.08374083787202835
step: 70, loss: 0.0055007413029670715
step: 80, loss: 0.06336895376443863
step: 90, loss: 0.019065802916884422
step: 100, loss: 0.0889926329255104
step: 110, loss: 0.0767536535859108
step: 120, loss: 0.030188027769327164
step: 130, loss: 0.06740635633468628
step: 140, loss: 0.26912328600883484
step: 150, loss: 0.05426168441772461
step: 160, loss: 0.0667046532034874
step: 170, loss: 0.088325634598732
step: 180, loss: 0.020997699350118637
step: 190, loss: 0.028874240815639496
step: 200, loss: 0.01535253319889307
step: 210, loss: 0.10366017371416092
step: 220, loss: 0.009841538965702057
step: 230, loss: 0.09349317848682404
step: 240, loss: 0.15418857336044312
step: 250, loss: 0.03497370705008507
step: 260, loss: 0.01775660365819931
step: 270, loss: 0.0386517159640789
step: 280, loss: 0.04886399582028389
step: 290, loss: 0.00022025384532753378
step: 300, loss: 0.010907155461609364
step: 310, loss: 0.06446526944637299
step: 320, loss: 0.025706343352794647
step: 330, loss: 0.08532719314098358
step: 340, loss: 0.06571829319000244
step: 350, loss: 0.10953386127948761
step: 360, loss: 0.09450483322143555
step: 370, loss: 0.038930103182792664
step: 380, loss: 0.062073104083538055
step: 390, loss: 0.08873698860406876
step: 400, loss: 0.014972818084061146
step: 410, loss: 0.07212243229150772
step: 420, loss: 0.0032809835392981768
step: 430, loss: 0.08929572254419327
step: 440, loss: 0.05103600025177002
step: 450, loss: 0.1614937037229538
step: 460, loss: 0.032031089067459106
step: 470, loss: 0.0975138321518898
step: 480, loss: 0.029810333624482155
step: 490, loss: 0.23047663271427155
step: 500, loss: 0.07027231156826019
step: 510, loss: 0.024390218779444695
step: 520, loss: 0.09025568515062332
step: 530, loss: 0.11885328590869904
step: 540, loss: 0.06487299501895905
step: 550, loss: 0.12145839631557465
step: 560, loss: 0.010518275201320648
step: 570, loss: 0.06136207655072212
step: 580, loss: 0.08265514671802521
step: 590, loss: 0.023057112470269203
step: 600, loss: 0.13368792831897736
step: 610, loss: 0.1283230483531952
step: 620, loss: 0.10526098310947418
step: 630, loss: 0.18430310487747192
step: 640, loss: 0.08225013315677643
step: 650, loss: 0.05433259159326553
step: 660, loss: 0.015609996393322945
step: 670, loss: 0.026508597657084465
step: 680, loss: 0.07463470101356506
step: 690, loss: 0.0694730281829834
step: 700, loss: 0.09322900325059891
step: 710, loss: 0.1007443219423294
step: 720, loss: 0.19565238058567047
step: 730, loss: 0.05093151703476906
step: 740, loss: 0.11750086396932602
step: 750, loss: 0.1549016535282135
step: 760, loss: 0.0001302910241065547
step: 770, loss: 0.0525481253862381
step: 780, loss: 0.02337915264070034
step: 790, loss: 0.020261993631720543
step: 800, loss: 0.09875524789094925
step: 810, loss: 0.3251696825027466
step: 820, loss: 0.09190438687801361
step: 830, loss: 0.0809527263045311
step: 840, loss: 0.08382786065340042
step: 850, loss: 0.045145176351070404
step: 860, loss: 0.1318921595811844
step: 870, loss: 0.1176963746547699
step: 880, loss: 0.08547165989875793
step: 890, loss: 0.029916906729340553
step: 900, loss: 0.09543348848819733
step: 910, loss: 0.03442945331335068
step: 920, loss: 0.030296018347144127
step: 930, loss: 0.033800605684518814
step: 940, loss: 0.05234770476818085
step: 950, loss: 0.044593293219804764
step: 960, loss: 0.12112288177013397
step: 970, loss: 0.08235301077365875
epoch 4: dev_f1=0.9323515876668201, f1=0.9348127600554785, best_f1=0.9348127600554785
step: 0, loss: 0.03212103247642517
step: 10, loss: 0.08048054575920105
step: 20, loss: 0.0283874049782753
step: 30, loss: 0.06638506799936295
step: 40, loss: 0.05667576566338539
step: 50, loss: 0.01899709179997444
step: 60, loss: 0.15343908965587616
step: 70, loss: 0.014378679916262627
step: 80, loss: 0.09713485836982727
step: 90, loss: 0.007445145398378372
step: 100, loss: 0.14135941863059998
step: 110, loss: 0.019820794463157654
step: 120, loss: 0.13515989482402802
step: 130, loss: 0.0051130494102835655
step: 140, loss: 0.04798267409205437
step: 150, loss: 0.07064436376094818
step: 160, loss: 0.08185870200395584
step: 170, loss: 0.09560028463602066
step: 180, loss: 0.10208870470523834
step: 190, loss: 0.1770942360162735
step: 200, loss: 0.07453072816133499
step: 210, loss: 0.11210652440786362
step: 220, loss: 0.004145290236920118
step: 230, loss: 0.038075342774391174
step: 240, loss: 0.01010906882584095
step: 250, loss: 0.05355921760201454
step: 260, loss: 0.0599626749753952
step: 270, loss: 0.12127237021923065
step: 280, loss: 0.055422428995370865
step: 290, loss: 0.04598002880811691
step: 300, loss: 0.07046888768672943
step: 310, loss: 0.017055431380867958
step: 320, loss: 0.1928415298461914
step: 330, loss: 0.03340453281998634
step: 340, loss: 0.11566762626171112
step: 350, loss: 0.057540543377399445
step: 360, loss: 0.1258644014596939
step: 370, loss: 0.0631117969751358
step: 380, loss: 0.060079675167798996
step: 390, loss: 0.07714806497097015
step: 400, loss: 0.14282594621181488
step: 410, loss: 0.024394309148192406
step: 420, loss: 0.02159017324447632
step: 430, loss: 0.018564410507678986
step: 440, loss: 0.12537312507629395
step: 450, loss: 0.1133638322353363
step: 460, loss: 0.02533305063843727
step: 470, loss: 0.030241264030337334
step: 480, loss: 0.04169319570064545
step: 490, loss: 0.04985448718070984
step: 500, loss: 0.05828539654612541
step: 510, loss: 0.20633970201015472
step: 520, loss: 0.06891721487045288
step: 530, loss: 0.021382825449109077
step: 540, loss: 0.19109110534191132
step: 550, loss: 0.06261372566223145
step: 560, loss: 0.017958946526050568
step: 570, loss: 0.015624258667230606
step: 580, loss: 0.06504826992750168
step: 590, loss: 0.059498488903045654
step: 600, loss: 0.021171702072024345
step: 610, loss: 0.2997939884662628
step: 620, loss: 0.11235608905553818
step: 630, loss: 0.03675924986600876
step: 640, loss: 0.017315836623311043
step: 650, loss: 0.1556786149740219
step: 660, loss: 0.016794471070170403
step: 670, loss: 0.01979506015777588
step: 680, loss: 0.0492660291492939
step: 690, loss: 0.016939669847488403
step: 700, loss: 0.027333613485097885
step: 710, loss: 0.08871867507696152
step: 720, loss: 0.03524870052933693
step: 730, loss: 0.09872700273990631
step: 740, loss: 0.04077748954296112
step: 750, loss: 0.3505631685256958
step: 760, loss: 0.018576860427856445
step: 770, loss: 0.08154860883951187
step: 780, loss: 0.010663836263120174
step: 790, loss: 0.08998607099056244
step: 800, loss: 0.055483628064394
step: 810, loss: 0.012829013168811798
step: 820, loss: 0.10527069121599197
step: 830, loss: 0.12601898610591888
step: 840, loss: 0.07893779128789902
step: 850, loss: 0.16982142627239227
step: 860, loss: 0.09144891798496246
step: 870, loss: 0.09599926322698593
step: 880, loss: 0.1071280986070633
step: 890, loss: 0.029664499685168266
step: 900, loss: 0.07612059265375137
step: 910, loss: 0.08779458701610565
step: 920, loss: 0.1037568598985672
step: 930, loss: 0.059606898576021194
step: 940, loss: 0.0001472696749260649
step: 950, loss: 0.018950914964079857
step: 960, loss: 0.02028789184987545
step: 970, loss: 0.13523295521736145
epoch 5: dev_f1=0.9404157043879908, f1=0.9317865429234339, best_f1=0.9317865429234339
step: 0, loss: 0.009578154422342777
step: 10, loss: 0.014190645888447762
step: 20, loss: 0.1084299087524414
step: 30, loss: 0.017575357109308243
step: 40, loss: 0.02933458983898163
step: 50, loss: 0.03667866811156273
step: 60, loss: 0.015145659446716309
step: 70, loss: 0.01007362175732851
step: 80, loss: 0.21148134768009186
step: 90, loss: 0.08298342674970627
step: 100, loss: 0.05602243170142174
step: 110, loss: 0.06782029569149017
step: 120, loss: 0.20254723727703094
step: 130, loss: 0.06546534597873688
step: 140, loss: 0.06179868429899216
step: 150, loss: 0.05186068266630173
step: 160, loss: 0.1797049194574356
step: 170, loss: 0.050099004060029984
step: 180, loss: 0.09578578174114227
step: 190, loss: 0.16350437700748444
step: 200, loss: 0.02798919752240181
step: 210, loss: 0.12870420515537262
step: 220, loss: 0.15151463449001312
step: 230, loss: 0.035873837769031525
step: 240, loss: 0.06760034710168839
step: 250, loss: 0.004325054585933685
step: 260, loss: 0.10293472558259964
step: 270, loss: 0.16135349869728088
step: 280, loss: 0.02980426326394081
step: 290, loss: 0.10655154287815094
step: 300, loss: 0.07380682975053787
step: 310, loss: 0.09843979775905609
step: 320, loss: 0.1490900218486786
step: 330, loss: 0.006906804628670216
step: 340, loss: 0.02092682011425495
step: 350, loss: 0.049492914229631424
step: 360, loss: 0.1384916752576828
step: 370, loss: 0.12083131074905396
step: 380, loss: 0.086704783141613
step: 390, loss: 0.14470045268535614
step: 400, loss: 0.0016574329929426312
step: 410, loss: 0.06415881961584091
step: 420, loss: 0.004357665777206421
step: 430, loss: 0.07134871929883957
step: 440, loss: 0.16281810402870178
step: 450, loss: 0.10547509044408798
step: 460, loss: 0.07939907908439636
step: 470, loss: 0.023968452587723732
step: 480, loss: 0.14324884116649628
step: 490, loss: 0.0669284239411354
step: 500, loss: 0.12154071778059006
step: 510, loss: 0.07292930781841278
step: 520, loss: 0.013902038335800171
step: 530, loss: 0.09373898804187775
step: 540, loss: 0.03334973007440567
step: 550, loss: 0.020205605775117874
step: 560, loss: 0.02407880127429962
step: 570, loss: 0.13208991289138794
step: 580, loss: 0.03200812637805939
step: 590, loss: 0.14024251699447632
step: 600, loss: 0.0412076935172081
step: 610, loss: 0.052046217024326324
step: 620, loss: 0.016932450234889984
step: 630, loss: 0.06607400625944138
step: 640, loss: 0.2003275603055954
step: 650, loss: 0.07798006385564804
step: 660, loss: 0.028375815600156784
step: 670, loss: 0.008622178807854652
step: 680, loss: 0.03406958654522896
step: 690, loss: 0.008461554534733295
step: 700, loss: 0.04764733463525772
step: 710, loss: 0.12605085968971252
step: 720, loss: 0.02587343007326126
step: 730, loss: 0.049396686255931854
step: 740, loss: 0.10859926044940948
step: 750, loss: 0.07635897397994995
step: 760, loss: 0.13843472301959991
step: 770, loss: 0.029378991574048996
step: 780, loss: 0.08468537777662277
step: 790, loss: 0.0989583283662796
step: 800, loss: 0.015328182838857174
step: 810, loss: 0.017597787082195282
step: 820, loss: 0.11543992906808853
step: 830, loss: 0.18209972977638245
step: 840, loss: 0.1537967026233673
step: 850, loss: 0.016515634953975677
step: 860, loss: 0.06391628086566925
step: 870, loss: 0.05479402095079422
step: 880, loss: 0.07172879576683044
step: 890, loss: 0.1384027600288391
step: 900, loss: 0.07918834686279297
step: 910, loss: 0.014195849187672138
step: 920, loss: 0.12080706655979156
step: 930, loss: 0.012166506610810757
step: 940, loss: 0.03589969128370285
step: 950, loss: 0.018518421798944473
step: 960, loss: 0.06696554273366928
step: 970, loss: 0.020513039082288742
epoch 6: dev_f1=0.9387379087977891, f1=0.9365225390984362, best_f1=0.9317865429234339
step: 0, loss: 0.12887535989284515
step: 10, loss: 0.075352743268013
step: 20, loss: 0.07070174813270569
step: 30, loss: 0.11184703558683395
step: 40, loss: 0.032296083867549896
step: 50, loss: 0.06340291351079941
step: 60, loss: 0.03489110991358757
step: 70, loss: 0.032310500741004944
step: 80, loss: 0.07760386168956757
step: 90, loss: 0.01125762052834034
step: 100, loss: 0.006912815850228071
step: 110, loss: 0.06800593435764313
step: 120, loss: 0.04830244928598404
step: 130, loss: 0.006338336504995823
step: 140, loss: 0.040126293897628784
step: 150, loss: 0.043245114386081696
step: 160, loss: 0.06531767547130585
step: 170, loss: 0.06989365816116333
step: 180, loss: 0.002583483699709177
step: 190, loss: 0.024561604484915733
step: 200, loss: 0.004277970176190138
step: 210, loss: 0.06763113290071487
step: 220, loss: 0.09105420857667923
step: 230, loss: 0.12428613007068634
step: 240, loss: 0.0241046492010355
step: 250, loss: 0.0809510126709938
step: 260, loss: 0.006967708468437195
step: 270, loss: 0.08716794848442078
step: 280, loss: 0.14111727476119995
step: 290, loss: 0.03397144377231598
step: 300, loss: 0.019346686080098152
step: 310, loss: 0.030216936022043228
step: 320, loss: 0.08582422882318497
step: 330, loss: 0.02420845627784729
step: 340, loss: 0.03732818365097046
step: 350, loss: 0.008418412879109383
step: 360, loss: 0.005325791891664267
step: 370, loss: 4.631890988093801e-05
step: 380, loss: 0.026030201464891434
step: 390, loss: 0.1815655380487442
step: 400, loss: 0.03425340726971626
step: 410, loss: 0.1265522837638855
step: 420, loss: 0.022071359679102898
step: 430, loss: 0.08262641727924347
step: 440, loss: 0.09318426251411438
step: 450, loss: 0.0193891953676939
step: 460, loss: 0.006931372918188572
step: 470, loss: 0.08845372498035431
step: 480, loss: 0.04592406749725342
step: 490, loss: 0.1073954850435257
step: 500, loss: 0.07818955928087234
step: 510, loss: 0.09598631411790848
step: 520, loss: 0.03825119137763977
step: 530, loss: 0.03866024315357208
step: 540, loss: 0.018627149984240532
step: 550, loss: 0.06982503086328506
step: 560, loss: 0.04381631687283516
step: 570, loss: 0.08216442167758942
step: 580, loss: 0.014986253343522549
step: 590, loss: 0.01964576356112957
step: 600, loss: 0.038051482290029526
step: 610, loss: 0.03171596676111221
step: 620, loss: 0.07124925404787064
step: 630, loss: 0.00013229623436927795
step: 640, loss: 0.08763203024864197
step: 650, loss: 0.10849331319332123
step: 660, loss: 0.0431644506752491
step: 670, loss: 0.07807814329862595
step: 680, loss: 0.19697587192058563
step: 690, loss: 0.13568828999996185
step: 700, loss: 0.017097745090723038
step: 710, loss: 0.012271461077034473
step: 720, loss: 0.08104167878627777
step: 730, loss: 0.08082327991724014
step: 740, loss: 0.009486766532063484
step: 750, loss: 0.05845993012189865
step: 760, loss: 0.026874734088778496
step: 770, loss: 0.011190641671419144
step: 780, loss: 0.01679803617298603
step: 790, loss: 0.065803661942482
step: 800, loss: 0.029751814901828766
step: 810, loss: 0.05355415120720863
step: 820, loss: 0.06624910235404968
step: 830, loss: 0.06890986859798431
step: 840, loss: 0.09581176936626434
step: 850, loss: 0.06148967146873474
step: 860, loss: 0.07885230332612991
step: 870, loss: 0.01680522784590721
step: 880, loss: 0.12162861227989197
step: 890, loss: 0.059583477675914764
step: 900, loss: 0.04933284595608711
step: 910, loss: 0.0264486875385046
step: 920, loss: 0.026113435626029968
step: 930, loss: 0.13992458581924438
step: 940, loss: 0.10449380427598953
step: 950, loss: 0.12444736063480377
step: 960, loss: 0.0918211117386818
step: 970, loss: 0.09852363914251328
epoch 7: dev_f1=0.9304666056724611, f1=0.9351005484460694, best_f1=0.9317865429234339
step: 0, loss: 0.07696763426065445
step: 10, loss: 0.00827505998313427
step: 20, loss: 0.05322280898690224
step: 30, loss: 0.04431119188666344
step: 40, loss: 0.04025803506374359
step: 50, loss: 0.037381190806627274
step: 60, loss: 0.009826019406318665
step: 70, loss: 0.04408546909689903
step: 80, loss: 0.08945649862289429
step: 90, loss: 0.057794488966464996
step: 100, loss: 0.011028415523469448
step: 110, loss: 0.012301952578127384
step: 120, loss: 0.022462129592895508
step: 130, loss: 0.013741948641836643
step: 140, loss: 0.013595125637948513
step: 150, loss: 0.029789278283715248
step: 160, loss: 0.00565523374825716
step: 170, loss: 0.10035452991724014
step: 180, loss: 0.02232249081134796
step: 190, loss: 0.006864572875201702
step: 200, loss: 0.004427071660757065
step: 210, loss: 0.006186051294207573
step: 220, loss: 0.041066814213991165
step: 230, loss: 0.02560599334537983
step: 240, loss: 0.15960659086704254
step: 250, loss: 0.04875865951180458
step: 260, loss: 0.06410232186317444
step: 270, loss: 0.007771824952214956
step: 280, loss: 0.05047157034277916
step: 290, loss: 0.11001942306756973
step: 300, loss: 0.10381355881690979
step: 310, loss: 0.06450205296278
step: 320, loss: 0.00513260904699564
step: 330, loss: 0.00697405356913805
step: 340, loss: 0.01580875739455223
step: 350, loss: 0.019155411049723625
step: 360, loss: 0.08680945634841919
step: 370, loss: 0.04975740239024162
step: 380, loss: 0.02671729400753975
step: 390, loss: 0.009005044586956501
step: 400, loss: 0.1830398142337799
step: 410, loss: 0.025370031595230103
step: 420, loss: 0.07049673795700073
step: 430, loss: 0.11243037134408951
step: 440, loss: 0.02681981399655342
step: 450, loss: 0.08188389241695404
step: 460, loss: 0.015627386048436165
step: 470, loss: 0.19788295030593872
step: 480, loss: 0.10603994131088257
step: 490, loss: 0.12431120127439499
step: 500, loss: 0.09613250941038132
step: 510, loss: 0.01584579423069954
step: 520, loss: 0.060389891266822815
step: 530, loss: 0.038159601390361786
step: 540, loss: 0.055983297526836395
step: 550, loss: 0.024779025465250015
step: 560, loss: 0.009250338189303875
step: 570, loss: 0.014458928257226944
step: 580, loss: 0.023137368261814117
step: 590, loss: 0.16689173877239227
step: 600, loss: 0.1151907667517662
step: 610, loss: 0.009122909978032112
step: 620, loss: 0.10341539233922958
step: 630, loss: 0.054440759122371674
step: 640, loss: 0.03899165242910385
step: 650, loss: 0.08362451195716858
step: 660, loss: 0.13611115515232086
step: 670, loss: 0.013242989778518677
step: 680, loss: 0.2139463573694229
step: 690, loss: 0.14601823687553406
step: 700, loss: 0.11218108981847763
step: 710, loss: 0.043181415647268295
step: 720, loss: 0.04623265564441681
step: 730, loss: 0.11758214235305786
step: 740, loss: 0.09644093364477158
step: 750, loss: 0.06282529979944229
step: 760, loss: 0.0581098347902298
step: 770, loss: 0.026215502992272377
step: 780, loss: 0.08269085735082626
step: 790, loss: 0.009820734150707722
step: 800, loss: 0.003634102176874876
step: 810, loss: 0.08032714575529099
step: 820, loss: 0.016113750636577606
step: 830, loss: 0.0211135596036911
step: 840, loss: 0.019797779619693756
step: 850, loss: 0.05915858969092369
step: 860, loss: 0.03208921477198601
step: 870, loss: 0.035399265587329865
step: 880, loss: 0.08448559045791626
step: 890, loss: 0.10873498767614365
step: 900, loss: 0.15006554126739502
step: 910, loss: 0.100397489964962
step: 920, loss: 0.024517659097909927
step: 930, loss: 0.15982332825660706
step: 940, loss: 0.05091303959488869
step: 950, loss: 0.17680807411670685
step: 960, loss: 0.04527183249592781
step: 970, loss: 0.00652420474216342
epoch 8: dev_f1=0.937442502299908, f1=0.9351127473538886, best_f1=0.9317865429234339
step: 0, loss: 0.041682541370391846
step: 10, loss: 0.06472084671258926
step: 20, loss: 0.11753054708242416
step: 30, loss: 0.013799235224723816
step: 40, loss: 0.058484502136707306
step: 50, loss: 0.07543507218360901
step: 60, loss: 0.04220821335911751
step: 70, loss: 0.019087690860033035
step: 80, loss: 0.09214810281991959
step: 90, loss: 0.04405214637517929
step: 100, loss: 0.02640221267938614
step: 110, loss: 0.043956708163022995
step: 120, loss: 0.06818890571594238
step: 130, loss: 0.02072739787399769
step: 140, loss: 0.15032079815864563
step: 150, loss: 0.026008883491158485
step: 160, loss: 0.015730883926153183
step: 170, loss: 0.010723989456892014
step: 180, loss: 0.006193603854626417
step: 190, loss: 0.0424652099609375
step: 200, loss: 0.06549122929573059
step: 210, loss: 0.012616152875125408
step: 220, loss: 0.007399054244160652
step: 230, loss: 0.13893555104732513
step: 240, loss: 0.04241175577044487
step: 250, loss: 0.008761909790337086
step: 260, loss: 0.007048174273222685
step: 270, loss: 0.11243334412574768
step: 280, loss: 0.037611622363328934
step: 290, loss: 0.12452415376901627
step: 300, loss: 0.10032103210687637
step: 310, loss: 0.0042439899407327175
step: 320, loss: 0.013656710274517536
step: 330, loss: 0.09176679700613022
step: 340, loss: 0.041760921478271484
step: 350, loss: 0.03937126323580742
step: 360, loss: 0.0026769209653139114
step: 370, loss: 0.04712408781051636
step: 380, loss: 0.028569834306836128
step: 390, loss: 0.017966222018003464
step: 400, loss: 0.009069014340639114
step: 410, loss: 0.0748400166630745
step: 420, loss: 0.017375338822603226
step: 430, loss: 0.03187816962599754
step: 440, loss: 0.05143756419420242
step: 450, loss: 0.15710128843784332
step: 460, loss: 0.018362833186984062
step: 470, loss: 0.05347341671586037
step: 480, loss: 0.0612921342253685
step: 490, loss: 0.06921537220478058
step: 500, loss: 0.03662674501538277
step: 510, loss: 0.0615408718585968
step: 520, loss: 0.11739106476306915
step: 530, loss: 0.028092755004763603
step: 540, loss: 0.18148592114448547
step: 550, loss: 0.06786369532346725
step: 560, loss: 0.024157943204045296
step: 570, loss: 0.018910696730017662
step: 580, loss: 0.09315283596515656
step: 590, loss: 0.03882293030619621
step: 600, loss: 0.015869418159127235
step: 610, loss: 0.10239305347204208
step: 620, loss: 0.031075725331902504
step: 630, loss: 0.022575650364160538
step: 640, loss: 0.008296675980091095
step: 650, loss: 0.02833322435617447
step: 660, loss: 0.07210156321525574
step: 670, loss: 0.02455904334783554
step: 680, loss: 0.08436647802591324
step: 690, loss: 0.00940994918346405
step: 700, loss: 0.08106717467308044
step: 710, loss: 0.0072382655926048756
step: 720, loss: 0.17181959748268127
step: 730, loss: 0.005093850195407867
step: 740, loss: 0.11511089652776718
step: 750, loss: 0.18192462623119354
step: 760, loss: 0.04961676895618439
step: 770, loss: 0.11058101058006287
step: 780, loss: 0.025054996833205223
step: 790, loss: 0.03580624237656593
step: 800, loss: 0.03906663507223129
step: 810, loss: 0.006340222433209419
step: 820, loss: 0.07829779386520386
step: 830, loss: 0.023374665528535843
step: 840, loss: 0.09353425353765488
step: 850, loss: 0.015002137050032616
step: 860, loss: 0.07666759192943573
step: 870, loss: 0.03774615004658699
step: 880, loss: 0.11241968721151352
step: 890, loss: 0.1053575649857521
step: 900, loss: 0.013040011748671532
step: 910, loss: 0.027857501059770584
step: 920, loss: 0.010301278904080391
step: 930, loss: 0.09150948375463486
step: 940, loss: 0.11739882826805115
step: 950, loss: 0.06978730857372284
step: 960, loss: 0.03475763276219368
step: 970, loss: 0.012826373800635338
epoch 9: dev_f1=0.9316596931659693, f1=0.9304467987102718, best_f1=0.9317865429234339
step: 0, loss: 0.021205760538578033
step: 10, loss: 0.004232815466821194
step: 20, loss: 0.025393513962626457
step: 30, loss: 0.05701667070388794
step: 40, loss: 0.009825420565903187
step: 50, loss: 0.11551306396722794
step: 60, loss: 0.08118316531181335
step: 70, loss: 0.00668418500572443
step: 80, loss: 0.021125297993421555
step: 90, loss: 0.01849694736301899
step: 100, loss: 0.043869730085134506
step: 110, loss: 0.08872036635875702
step: 120, loss: 0.1072629913687706
step: 130, loss: 0.03632809594273567
step: 140, loss: 0.02179662697017193
step: 150, loss: 0.07517039030790329
step: 160, loss: 0.013063563965260983
step: 170, loss: 4.266024916432798e-05
step: 180, loss: 0.042918842285871506
step: 190, loss: 0.0999135971069336
step: 200, loss: 0.01299256831407547
step: 210, loss: 0.06225332245230675
step: 220, loss: 0.009225699119269848
step: 230, loss: 0.011322193779051304
step: 240, loss: 0.015319121070206165
step: 250, loss: 0.24241627752780914
step: 260, loss: 0.006407637149095535
step: 270, loss: 8.22523797978647e-05
step: 280, loss: 0.09622432291507721
step: 290, loss: 0.015688784420490265
step: 300, loss: 0.01836714707314968
step: 310, loss: 0.04834483191370964
step: 320, loss: 0.01845797896385193
step: 330, loss: 0.01766512542963028
step: 340, loss: 0.005195687524974346
step: 350, loss: 0.006384586915373802
step: 360, loss: 0.020666221156716347
step: 370, loss: 0.12945611774921417
step: 380, loss: 0.17716462910175323
step: 390, loss: 0.14421571791172028
step: 400, loss: 0.02745472639799118
step: 410, loss: 0.08914832770824432
step: 420, loss: 0.01993267983198166
step: 430, loss: 0.125071182847023
step: 440, loss: 0.0023778360337018967
step: 450, loss: 0.10776935517787933
step: 460, loss: 0.09140831977128983
step: 470, loss: 0.036068376153707504
step: 480, loss: 0.022098606452345848
step: 490, loss: 0.028202489018440247
step: 500, loss: 0.015077061019837856
step: 510, loss: 0.002144072437658906
step: 520, loss: 0.007898427546024323
step: 530, loss: 0.004494322929531336
step: 540, loss: 0.06717390567064285
step: 550, loss: 0.15929777920246124
step: 560, loss: 0.03735625371336937
step: 570, loss: 0.02323976159095764
step: 580, loss: 0.041276197880506516
step: 590, loss: 0.05727456882596016
step: 600, loss: 0.11431355774402618
step: 610, loss: 0.062282219529151917
step: 620, loss: 0.032214775681495667
step: 630, loss: 0.12538884580135345
step: 640, loss: 0.07845814526081085
step: 650, loss: 0.06879521906375885
step: 660, loss: 0.057040028274059296
step: 670, loss: 0.10271337628364563
step: 680, loss: 0.10603203624486923
step: 690, loss: 0.12034975737333298
step: 700, loss: 0.02362632006406784
step: 710, loss: 0.021474190056324005
step: 720, loss: 0.0605078861117363
step: 730, loss: 0.023033231496810913
step: 740, loss: 0.08614533394575119
step: 750, loss: 0.11450466513633728
step: 760, loss: 0.02829667367041111
step: 770, loss: 0.010916158556938171
step: 780, loss: 0.0634726732969284
step: 790, loss: 0.07583416253328323
step: 800, loss: 0.04829321801662445
step: 810, loss: 0.12030303478240967
step: 820, loss: 0.013810552656650543
step: 830, loss: 0.07094497233629227
step: 840, loss: 0.10876943916082382
step: 850, loss: 0.13013695180416107
step: 860, loss: 0.1030430868268013
step: 870, loss: 3.356782690389082e-05
step: 880, loss: 0.05607955902814865
step: 890, loss: 0.11780433356761932
step: 900, loss: 0.02027245983481407
step: 910, loss: 0.10218920558691025
step: 920, loss: 0.024564143270254135
step: 930, loss: 0.03458457440137863
step: 940, loss: 0.03496796265244484
step: 950, loss: 0.06366068124771118
step: 960, loss: 0.02830197475850582
step: 970, loss: 0.13616684079170227
epoch 10: dev_f1=0.9347014925373135, f1=0.9349330872173512, best_f1=0.9317865429234339
step: 0, loss: 0.06881077587604523
step: 10, loss: 0.11444227397441864
step: 20, loss: 0.07281335443258286
step: 30, loss: 0.030061885714530945
step: 40, loss: 0.1248883381485939
step: 50, loss: 0.06782092899084091
step: 60, loss: 0.019812295213341713
step: 70, loss: 0.07959580421447754
step: 80, loss: 0.012983076274394989
step: 90, loss: 0.0005796523182652891
step: 100, loss: 0.06163007393479347
step: 110, loss: 0.019976919516921043
step: 120, loss: 0.0191761814057827
step: 130, loss: 0.027272023260593414
step: 140, loss: 0.08721570670604706
step: 150, loss: 0.18811027705669403
step: 160, loss: 0.026090174913406372
step: 170, loss: 0.03592042252421379
step: 180, loss: 0.021578580141067505
step: 190, loss: 0.09387736767530441
step: 200, loss: 0.002177021000534296
step: 210, loss: 0.008275299333035946
step: 220, loss: 0.04185669869184494
step: 230, loss: 0.030766749754548073
step: 240, loss: 0.0429789237678051
step: 250, loss: 0.060480765998363495
step: 260, loss: 0.09002614766359329
step: 270, loss: 0.06128682941198349
step: 280, loss: 0.0008397757774218917
step: 290, loss: 0.09351757913827896
step: 300, loss: 0.01684875786304474
step: 310, loss: 0.023854393512010574
step: 320, loss: 0.01597748138010502
step: 330, loss: 0.0008265039650723338
step: 340, loss: 0.2399190366268158
step: 350, loss: 0.09425670653581619
step: 360, loss: 0.05948580801486969
step: 370, loss: 0.02722443826496601
step: 380, loss: 0.059023167937994
step: 390, loss: 0.004439813084900379
step: 400, loss: 0.02154434472322464
step: 410, loss: 0.0099504254758358
step: 420, loss: 0.058408208191394806
step: 430, loss: 0.04260988533496857
step: 440, loss: 0.04111155867576599
step: 450, loss: 0.006679670885205269
step: 460, loss: 0.06353840976953506
step: 470, loss: 0.060937754809856415
step: 480, loss: 0.06124694272875786
step: 490, loss: 0.0143011175096035
step: 500, loss: 0.03067786432802677
step: 510, loss: 0.08396310359239578
step: 520, loss: 0.07387968897819519
step: 530, loss: 0.10379032790660858
step: 540, loss: 0.13183780014514923
step: 550, loss: 0.000947970082052052
step: 560, loss: 0.07577540725469589
step: 570, loss: 0.01189478300511837
step: 580, loss: 0.10276254266500473
step: 590, loss: 0.05397499352693558
step: 600, loss: 0.10844741016626358
step: 610, loss: 0.11395356059074402
step: 620, loss: 0.017746491357684135
step: 630, loss: 0.03103194385766983
step: 640, loss: 0.026911607012152672
step: 650, loss: 0.06331826001405716
step: 660, loss: 0.05005648359656334
step: 670, loss: 0.012923959642648697
step: 680, loss: 0.058556731790304184
step: 690, loss: 0.10181737691164017
step: 700, loss: 0.0007759467116557062
step: 710, loss: 0.014686317183077335
step: 720, loss: 0.07003607600927353
step: 730, loss: 0.002435358241200447
step: 740, loss: 0.008239179849624634
step: 750, loss: 0.015574546530842781
step: 760, loss: 0.005037122871726751
step: 770, loss: 0.07682791352272034
step: 780, loss: 0.054075296968221664
step: 790, loss: 0.01654738187789917
step: 800, loss: 0.026583382859826088
step: 810, loss: 0.05470357462763786
step: 820, loss: 0.06515959650278091
step: 830, loss: 0.010421969927847385
step: 840, loss: 0.07799427956342697
step: 850, loss: 0.003609525505453348
step: 860, loss: 0.03259693458676338
step: 870, loss: 0.13067319989204407
step: 880, loss: 0.03311631456017494
step: 890, loss: 0.04289819300174713
step: 900, loss: 0.07202010601758957
step: 910, loss: 0.0025614402256906033
step: 920, loss: 0.02159195765852928
step: 930, loss: 0.017791226506233215
step: 940, loss: 0.0020991992205381393
step: 950, loss: 0.04477400332689285
step: 960, loss: 0.05497683957219124
step: 970, loss: 0.04270921275019646
epoch 11: dev_f1=0.9383842994066636, f1=0.9286039108685765, best_f1=0.9317865429234339
step: 0, loss: 0.023607296869158745
step: 10, loss: 0.04632864147424698
step: 20, loss: 0.06916896253824234
step: 30, loss: 0.06538725644350052
step: 40, loss: 0.05764191970229149
step: 50, loss: 0.018236778676509857
step: 60, loss: 0.018049106001853943
step: 70, loss: 0.023057423532009125
step: 80, loss: 0.017367901280522346
step: 90, loss: 0.16940437257289886
step: 100, loss: 0.0065764873288571835
step: 110, loss: 0.016183454543352127
step: 120, loss: 0.050094734877347946
step: 130, loss: 0.1187283992767334
step: 140, loss: 0.0015344112180173397
step: 150, loss: 0.009541436098515987
step: 160, loss: 0.05370064452290535
step: 170, loss: 0.03602227196097374
step: 180, loss: 0.057870667427778244
step: 190, loss: 0.12442921102046967
step: 200, loss: 0.0614197663962841
step: 210, loss: 0.06987527012825012
step: 220, loss: 0.03587457165122032
step: 230, loss: 0.002982955425977707
step: 240, loss: 0.17042210698127747
step: 250, loss: 0.03494064882397652
step: 260, loss: 0.11277130246162415
step: 270, loss: 0.1375582069158554
step: 280, loss: 0.01606907695531845
step: 290, loss: 0.0025519344490021467
step: 300, loss: 0.014993805438280106
step: 310, loss: 0.054526437073946
step: 320, loss: 0.06518732756376266
step: 330, loss: 0.03904179483652115
step: 340, loss: 0.0024945077020674944
step: 350, loss: 0.02556614577770233
step: 360, loss: 0.06814607977867126
step: 370, loss: 0.025774989277124405
step: 380, loss: 0.06220676004886627
step: 390, loss: 0.0013621613616123796
step: 400, loss: 0.0547088161110878
step: 410, loss: 0.1452299803495407
step: 420, loss: 0.042491212487220764
step: 430, loss: 0.0351574644446373
step: 440, loss: 0.03455275669693947
step: 450, loss: 0.06880779564380646
step: 460, loss: 0.07107120007276535
step: 470, loss: 0.010326430201530457
step: 480, loss: 0.07748202234506607
step: 490, loss: 0.017137644812464714
step: 500, loss: 0.007428441662341356
step: 510, loss: 0.020921429619193077
step: 520, loss: 0.06437458842992783
step: 530, loss: 0.07121115177869797
step: 540, loss: 0.00021160274627618492
step: 550, loss: 0.0019038597820326686
step: 560, loss: 0.02435990422964096
step: 570, loss: 0.02008081041276455
step: 580, loss: 0.09023603051900864
step: 590, loss: 0.012342128902673721
step: 600, loss: 0.007887556217610836
step: 610, loss: 0.007734911050647497
step: 620, loss: 0.02799501083791256
step: 630, loss: 0.11589330434799194
step: 640, loss: 0.053462184965610504
step: 650, loss: 0.06304094940423965
step: 660, loss: 0.03566085547208786
step: 670, loss: 0.02890927530825138
step: 680, loss: 0.05382479727268219
step: 690, loss: 0.02446400374174118
step: 700, loss: 0.001143822679296136
step: 710, loss: 0.03800344467163086
step: 720, loss: 0.01722307875752449
step: 730, loss: 0.06652560085058212
step: 740, loss: 0.12405247986316681
step: 750, loss: 0.001254405127838254
step: 760, loss: 0.08857831358909607
step: 770, loss: 0.0002252158592455089
step: 780, loss: 0.005296181887388229
step: 790, loss: 0.022806614637374878
step: 800, loss: 0.022908920422196388
step: 810, loss: 0.02532235160470009
step: 820, loss: 0.05055985972285271
step: 830, loss: 0.010151220485568047
step: 840, loss: 0.001837846008129418
step: 850, loss: 0.02440517581999302
step: 860, loss: 0.02570985071361065
step: 870, loss: 0.003579189768061042
step: 880, loss: 0.1650899350643158
step: 890, loss: 0.046208567917346954
step: 900, loss: 0.012066279537975788
step: 910, loss: 0.03017568029463291
step: 920, loss: 0.03836645931005478
step: 930, loss: 0.07115866988897324
step: 940, loss: 0.06731215864419937
step: 950, loss: 0.11911899596452713
step: 960, loss: 0.018407631665468216
step: 970, loss: 0.041669175028800964
epoch 12: dev_f1=0.9359464627151052, f1=0.9294841457643163, best_f1=0.9317865429234339
step: 0, loss: 0.02889307215809822
step: 10, loss: 0.10531086474657059
step: 20, loss: 0.004203565418720245
step: 30, loss: 0.0234404094517231
step: 40, loss: 0.05102413892745972
step: 50, loss: 0.0320388525724411
step: 60, loss: 0.0073730177246034145
step: 70, loss: 0.03381037712097168
step: 80, loss: 0.02016248181462288
step: 90, loss: 0.006298018619418144
step: 100, loss: 0.05339599773287773
step: 110, loss: 0.00011627515777945518
step: 120, loss: 0.03433417156338692
step: 130, loss: 0.009555634111166
step: 140, loss: 0.1573060303926468
step: 150, loss: 0.053217813372612
step: 160, loss: 0.03607664257287979
step: 170, loss: 0.07165811210870743
step: 180, loss: 0.03554076701402664
step: 190, loss: 0.01732630282640457
step: 200, loss: 0.07197822630405426
step: 210, loss: 0.043453726917505264
step: 220, loss: 0.0239277221262455
step: 230, loss: 0.008780324831604958
step: 240, loss: 0.0002712711284402758
step: 250, loss: 0.0193721242249012
step: 260, loss: 0.03425446152687073
step: 270, loss: 0.05603783577680588
step: 280, loss: 0.047667648643255234
step: 290, loss: 0.03390157222747803
step: 300, loss: 0.047329243272542953
step: 310, loss: 0.01352888997644186
step: 320, loss: 0.00030038997647352517
step: 330, loss: 0.0575559139251709
step: 340, loss: 0.0728364959359169
step: 350, loss: 0.0028412574902176857
step: 360, loss: 0.02312489226460457
step: 370, loss: 0.02027226611971855
step: 380, loss: 0.0006203647935763001
step: 390, loss: 0.051199812442064285
step: 400, loss: 0.12596973776817322
step: 410, loss: 0.02211768366396427
step: 420, loss: 2.0570583728840575e-05
step: 430, loss: 0.02669907733798027
step: 440, loss: 0.0007664593867957592
step: 450, loss: 0.06003766506910324
step: 460, loss: 0.0014250584645196795
step: 470, loss: 0.004050450399518013
step: 480, loss: 0.0019537394400686026
step: 490, loss: 0.027322474867105484
step: 500, loss: 0.0034816169645637274
step: 510, loss: 0.060350123792886734
step: 520, loss: 0.04830872267484665
step: 530, loss: 0.005767687223851681
step: 540, loss: 0.060555193573236465
step: 550, loss: 0.08371017873287201
step: 560, loss: 0.04337109252810478
step: 570, loss: 0.018214015290141106
step: 580, loss: 0.07306704670190811
step: 590, loss: 0.021835286170244217
step: 600, loss: 0.0309007428586483
step: 610, loss: 0.05213070288300514
step: 620, loss: 0.02711402252316475
step: 630, loss: 0.12248959392309189
step: 640, loss: 0.0777394250035286
step: 650, loss: 0.060582228004932404
step: 660, loss: 0.05141742527484894
step: 670, loss: 0.06958486884832382
step: 680, loss: 0.02476097084581852
step: 690, loss: 0.011866554617881775
step: 700, loss: 0.0011219450971111655
step: 710, loss: 0.058891236782073975
step: 720, loss: 0.002447007689625025
step: 730, loss: 0.024643879383802414
step: 740, loss: 0.00033154000993818045
step: 750, loss: 0.052225321531295776
step: 760, loss: 0.057971708476543427
step: 770, loss: 0.08618825674057007
step: 780, loss: 0.07221738994121552
step: 790, loss: 0.0012575952569022775
step: 800, loss: 0.05401838943362236
step: 810, loss: 0.0066907345317304134
step: 820, loss: 3.3681601053103805e-05
step: 830, loss: 0.0790996104478836
step: 840, loss: 0.003773760050535202
step: 850, loss: 0.10740119218826294
step: 860, loss: 0.06079183518886566
step: 870, loss: 0.03824606537818909
step: 880, loss: 0.05088286101818085
step: 890, loss: 0.01077006384730339
step: 900, loss: 0.05023042485117912
step: 910, loss: 0.040813203901052475
step: 920, loss: 0.10142479836940765
step: 930, loss: 0.033173199743032455
step: 940, loss: 0.01887505128979683
step: 950, loss: 0.0018529922235757113
step: 960, loss: 0.1464088410139084
step: 970, loss: 0.07700978219509125
epoch 13: dev_f1=0.9420423183072677, f1=0.9338842975206612, best_f1=0.9338842975206612
step: 0, loss: 0.013814124278724194
step: 10, loss: 0.04135611280798912
step: 20, loss: 0.050227999687194824
step: 30, loss: 0.05912498012185097
step: 40, loss: 0.0003511846298351884
step: 50, loss: 0.043889909982681274
step: 60, loss: 0.00022671895567327738
step: 70, loss: 0.02117377705872059
step: 80, loss: 0.028241921216249466
step: 90, loss: 0.004784923046827316
step: 100, loss: 0.02012268826365471
step: 110, loss: 0.14807823300361633
step: 120, loss: 0.038566458970308304
step: 130, loss: 0.016343435272574425
step: 140, loss: 0.009991790167987347
step: 150, loss: 0.0016662129200994968
step: 160, loss: 0.037414245307445526
step: 170, loss: 0.02308635041117668
step: 180, loss: 0.0032880702055990696
step: 190, loss: 0.026158835738897324
step: 200, loss: 0.017597883939743042
step: 210, loss: 0.018588608130812645
step: 220, loss: 0.0976431593298912
step: 230, loss: 0.04236041009426117
step: 240, loss: 0.04835283011198044
step: 250, loss: 0.021831758320331573
step: 260, loss: 0.056865956634283066
step: 270, loss: 0.0009400098933838308
step: 280, loss: 0.06144259124994278
step: 290, loss: 0.05265050753951073
step: 300, loss: 0.0016919915797188878
step: 310, loss: 0.06722720712423325
step: 320, loss: 0.051209039986133575
step: 330, loss: 0.0008500452386215329
step: 340, loss: 0.015172872692346573
step: 350, loss: 0.0069341761991381645
step: 360, loss: 0.12897920608520508
step: 370, loss: 0.010609094984829426
step: 380, loss: 0.048667460680007935
step: 390, loss: 0.00039749027928337455
step: 400, loss: 0.058482471853494644
step: 410, loss: 0.03166617453098297
step: 420, loss: 0.09273826330900192
step: 430, loss: 0.02314644865691662
step: 440, loss: 0.00338648515753448
step: 450, loss: 0.0002486822195351124
step: 460, loss: 0.0041481065563857555
step: 470, loss: 0.06346134841442108
step: 480, loss: 0.0346766822040081
step: 490, loss: 0.03599857911467552
step: 500, loss: 0.04560687765479088
step: 510, loss: 0.026119813323020935
step: 520, loss: 0.0591893270611763
step: 530, loss: 0.0009623527876101434
step: 540, loss: 0.01294463500380516
step: 550, loss: 0.001093373284675181
step: 560, loss: 0.06299716234207153
step: 570, loss: 0.035397760570049286
step: 580, loss: 0.05083687603473663
step: 590, loss: 0.08025304228067398
step: 600, loss: 0.0012463119346648455
step: 610, loss: 0.020969204604625702
step: 620, loss: 0.028768645599484444
step: 630, loss: 0.028589218854904175
step: 640, loss: 0.04402739927172661
step: 650, loss: 0.021097611635923386
step: 660, loss: 0.18333430588245392
step: 670, loss: 0.022928135469555855
step: 680, loss: 0.03525415062904358
step: 690, loss: 0.002344726584851742
step: 700, loss: 0.024849005043506622
step: 710, loss: 0.02370915561914444
step: 720, loss: 0.11983143538236618
step: 730, loss: 0.07594210654497147
step: 740, loss: 0.03192226588726044
step: 750, loss: 0.0043429783545434475
step: 760, loss: 0.015770548954606056
step: 770, loss: 0.05128774419426918
step: 780, loss: 0.05066898092627525
step: 790, loss: 0.04112755134701729
step: 800, loss: 0.07757340371608734
step: 810, loss: 0.07417941093444824
step: 820, loss: 0.07179040461778641
step: 830, loss: 0.00908777117729187
step: 840, loss: 0.05752412602305412
step: 850, loss: 0.053784266114234924
step: 860, loss: 0.05637713894248009
step: 870, loss: 0.03515855595469475
step: 880, loss: 0.0635242611169815
step: 890, loss: 0.057883430272340775
step: 900, loss: 0.07976830750703812
step: 910, loss: 0.0288002360612154
step: 920, loss: 0.0618782564997673
step: 930, loss: 0.07041449099779129
step: 940, loss: 0.04598921537399292
step: 950, loss: 0.05973672866821289
step: 960, loss: 0.016035577282309532
step: 970, loss: 0.06026967614889145
epoch 14: dev_f1=0.934844192634561, f1=0.9325210871602625, best_f1=0.9338842975206612
step: 0, loss: 0.05254450440406799
step: 10, loss: 2.648561894602608e-05
step: 20, loss: 0.022743485867977142
step: 30, loss: 6.778159877285361e-05
step: 40, loss: 7.577348878839985e-05
step: 50, loss: 0.011930354870855808
step: 60, loss: 0.045849382877349854
step: 70, loss: 0.003014372196048498
step: 80, loss: 8.009685552679002e-05
step: 90, loss: 0.08419230580329895
step: 100, loss: 0.06225689873099327
step: 110, loss: 1.6420459360233508e-05
step: 120, loss: 0.03485291451215744
step: 130, loss: 0.02369098924100399
step: 140, loss: 0.026469992473721504
step: 150, loss: 0.038567621260881424
step: 160, loss: 0.11082533001899719
step: 170, loss: 0.019387757405638695
step: 180, loss: 0.018395747989416122
step: 190, loss: 0.004934794269502163
step: 200, loss: 0.04353666678071022
step: 210, loss: 0.03203696757555008
step: 220, loss: 0.048387303948402405
step: 230, loss: 0.00015542320034001023
step: 240, loss: 0.02080966718494892
step: 250, loss: 0.08567890524864197
step: 260, loss: 0.02744135819375515
step: 270, loss: 0.038495104759931564
step: 280, loss: 0.05531047657132149
step: 290, loss: 0.011773853562772274
step: 300, loss: 0.12959976494312286
step: 310, loss: 0.0657573714852333
step: 320, loss: 0.014619135297834873
step: 330, loss: 0.0004441076307557523
step: 340, loss: 0.05417517572641373
step: 350, loss: 0.007937598042190075
step: 360, loss: 0.030682945623993874
step: 370, loss: 0.031158752739429474
step: 380, loss: 0.000857161998283118
step: 390, loss: 0.016070399433374405
step: 400, loss: 0.05181248486042023
step: 410, loss: 0.024356961250305176
step: 420, loss: 1.4047895092517138e-05
step: 430, loss: 0.01630183309316635
step: 440, loss: 0.0005033143679611385
step: 450, loss: 0.000989882624708116
step: 460, loss: 0.032014720141887665
step: 470, loss: 0.11100983619689941
step: 480, loss: 0.048535510897636414
step: 490, loss: 0.06595724821090698
step: 500, loss: 0.04084765911102295
step: 510, loss: 0.014137868769466877
step: 520, loss: 0.024966806173324585
step: 530, loss: 0.0832306519150734
step: 540, loss: 0.008297279477119446
step: 550, loss: 0.07474987953901291
step: 560, loss: 0.002496191067621112
step: 570, loss: 0.020549887791275978
step: 580, loss: 0.000330735114403069
step: 590, loss: 0.033181991428136826
step: 600, loss: 0.05793645605444908
step: 610, loss: 0.011091772466897964
step: 620, loss: 0.051193900406360626
step: 630, loss: 0.029208892956376076
step: 640, loss: 0.058712735772132874
step: 650, loss: 0.00016678401152603328
step: 660, loss: 0.10145091265439987
step: 670, loss: 3.888289938913658e-05
step: 680, loss: 0.015410233289003372
step: 690, loss: 0.11352930217981339
step: 700, loss: 0.0016808464424684644
step: 710, loss: 0.026619097217917442
step: 720, loss: 0.0004725416365545243
step: 730, loss: 0.004068539012223482
step: 740, loss: 0.019481733441352844
step: 750, loss: 0.046710461378097534
step: 760, loss: 0.035795703530311584
step: 770, loss: 0.05868753418326378
step: 780, loss: 0.04465275630354881
step: 790, loss: 0.02849535271525383
step: 800, loss: 0.12819543480873108
step: 810, loss: 0.13495595753192902
step: 820, loss: 0.039511606097221375
step: 830, loss: 0.08436267077922821
step: 840, loss: 0.020591702312231064
step: 850, loss: 0.015339650213718414
step: 860, loss: 0.04622514918446541
step: 870, loss: 0.028120296075940132
step: 880, loss: 0.06469648331403732
step: 890, loss: 0.047752298414707184
step: 900, loss: 0.002923899330198765
step: 910, loss: 0.004075055476278067
step: 920, loss: 0.013924243859946728
step: 930, loss: 0.08196680247783661
step: 940, loss: 0.013715396635234356
step: 950, loss: 0.01643315702676773
step: 960, loss: 0.07780753821134567
step: 970, loss: 0.035941481590270996
epoch 15: dev_f1=0.9392111368909513, f1=0.933826931975937, best_f1=0.9338842975206612
step: 0, loss: 0.027185292914509773
step: 10, loss: 0.08705894649028778
step: 20, loss: 0.0003244773542974144
step: 30, loss: 0.10909240692853928
step: 40, loss: 0.09812761843204498
step: 50, loss: 0.021888963878154755
step: 60, loss: 0.048183947801589966
step: 70, loss: 0.03152413293719292
step: 80, loss: 0.06003957614302635
step: 90, loss: 0.0016069704433903098
step: 100, loss: 0.03894410282373428
step: 110, loss: 0.03911101818084717
step: 120, loss: 0.0018184477230533957
step: 130, loss: 0.009841102175414562
step: 140, loss: 0.03760454058647156
step: 150, loss: 0.1331350952386856
step: 160, loss: 0.018788978457450867
step: 170, loss: 0.043675608932971954
step: 180, loss: 0.03039265051484108
step: 190, loss: 0.019321033731102943
step: 200, loss: 0.005047978367656469
step: 210, loss: 0.03343940153717995
step: 220, loss: 0.025832805782556534
step: 230, loss: 0.034896109253168106
step: 240, loss: 0.01063152588903904
step: 250, loss: 0.027776341885328293
step: 260, loss: 0.061188384890556335
step: 270, loss: 0.06738921999931335
step: 280, loss: 0.041697319597005844
step: 290, loss: 0.0071771410293877125
step: 300, loss: 0.09791526198387146
step: 310, loss: 0.0360054150223732
step: 320, loss: 0.010870247147977352
step: 330, loss: 0.02309369668364525
step: 340, loss: 0.02238490805029869
step: 350, loss: 0.02120279334485531
step: 360, loss: 0.06901417672634125
step: 370, loss: 9.973088890546933e-05
step: 380, loss: 0.0015144605422392488
step: 390, loss: 0.05130772292613983
step: 400, loss: 0.01640544831752777
step: 410, loss: 0.0006786998710595071
step: 420, loss: 0.07804422825574875
step: 430, loss: 0.02766195684671402
step: 440, loss: 0.0171443372964859
step: 450, loss: 0.006018820218741894
step: 460, loss: 0.00013964252138976008
step: 470, loss: 2.1880179701838642e-05
step: 480, loss: 0.07531397044658661
step: 490, loss: 0.07599874585866928
step: 500, loss: 0.055035196244716644
step: 510, loss: 0.028387198224663734
step: 520, loss: 0.046135589480400085
step: 530, loss: 0.03415241092443466
step: 540, loss: 0.022265855222940445
step: 550, loss: 0.02612871676683426
step: 560, loss: 0.0038700660225003958
step: 570, loss: 0.004043870605528355
step: 580, loss: 0.05440429970622063
step: 590, loss: 0.0007781168096698821
step: 600, loss: 8.44665482873097e-05
step: 610, loss: 0.048864223062992096
step: 620, loss: 0.0726948231458664
step: 630, loss: 0.03625611215829849
step: 640, loss: 0.15055276453495026
step: 650, loss: 0.018144967034459114
step: 660, loss: 0.03595050424337387
step: 670, loss: 0.05471568554639816
step: 680, loss: 7.662627467652783e-05
step: 690, loss: 0.0005239959573373199
step: 700, loss: 0.009349275380373001
step: 710, loss: 0.0001406754890922457
step: 720, loss: 0.05678443983197212
step: 730, loss: 0.003208456328138709
step: 740, loss: 7.699726847931743e-05
step: 750, loss: 0.08018311858177185
step: 760, loss: 0.03539957106113434
step: 770, loss: 0.000289480434730649
step: 780, loss: 0.00585421035066247
step: 790, loss: 0.059238627552986145
step: 800, loss: 0.03299302980303764
step: 810, loss: 0.03564053773880005
step: 820, loss: 0.02072819508612156
step: 830, loss: 0.06794833391904831
step: 840, loss: 0.04398240149021149
step: 850, loss: 0.0017344080843031406
step: 860, loss: 0.022151494398713112
step: 870, loss: 0.0299531202763319
step: 880, loss: 0.027008917182683945
step: 890, loss: 0.03361399471759796
step: 900, loss: 0.013569392263889313
step: 910, loss: 0.02120113931596279
step: 920, loss: 0.024488389492034912
step: 930, loss: 0.03930751606822014
step: 940, loss: 0.01139851100742817
step: 950, loss: 0.019237948581576347
step: 960, loss: 0.055715303868055344
step: 970, loss: 0.021777590736746788
epoch 16: dev_f1=0.9394221808014911, f1=0.9345099860659545, best_f1=0.9338842975206612
step: 0, loss: 0.0020402816589921713
step: 10, loss: 0.00021331821335479617
step: 20, loss: 0.0162176676094532
step: 30, loss: 0.02572827972471714
step: 40, loss: 0.02485455758869648
step: 50, loss: 0.06472150981426239
step: 60, loss: 0.001302492804825306
step: 70, loss: 0.06460636854171753
step: 80, loss: 0.003894062712788582
step: 90, loss: 0.03783328831195831
step: 100, loss: 0.004209971521049738
step: 110, loss: 0.041027020663022995
step: 120, loss: 0.036237288266420364
step: 130, loss: 4.8154048272408545e-05
step: 140, loss: 0.03549414873123169
step: 150, loss: 0.003229716792702675
step: 160, loss: 5.002507896278985e-05
step: 170, loss: 0.14637747406959534
step: 180, loss: 0.007709984667599201
step: 190, loss: 0.03783785179257393
step: 200, loss: 0.0288789514452219
step: 210, loss: 0.032414935529232025
step: 220, loss: 0.02011256292462349
step: 230, loss: 0.0019707249011844397
step: 240, loss: 0.037149492651224136
step: 250, loss: 0.00015335412172134966
step: 260, loss: 0.10809428244829178
step: 270, loss: 0.0003581815690267831
step: 280, loss: 0.08017933368682861
step: 290, loss: 0.043427467346191406
step: 300, loss: 0.0008333610603585839
step: 310, loss: 0.00015964367776177824
step: 320, loss: 0.05441578850150108
step: 330, loss: 4.319284198572859e-05
step: 340, loss: 0.04089929908514023
step: 350, loss: 0.029536737129092216
step: 360, loss: 0.06396099925041199
step: 370, loss: 0.05404254421591759
step: 380, loss: 0.05444991588592529
step: 390, loss: 0.057421546429395676
step: 400, loss: 0.01868038810789585
step: 410, loss: 0.0006074586999602616
step: 420, loss: 0.009810452349483967
step: 430, loss: 0.04059983044862747
step: 440, loss: 0.013536696322262287
step: 450, loss: 0.028227873146533966
step: 460, loss: 0.030336519703269005
step: 470, loss: 0.000158251918037422
step: 480, loss: 0.0011976704699918628
step: 490, loss: 6.247810233617201e-05
step: 500, loss: 0.10249771177768707
step: 510, loss: 0.049685753881931305
step: 520, loss: 0.042238518595695496
step: 530, loss: 0.0561145544052124
step: 540, loss: 0.046269144862890244
step: 550, loss: 0.00028520298656076193
step: 560, loss: 0.048490628600120544
step: 570, loss: 4.512843588599935e-05
step: 580, loss: 0.04236350208520889
step: 590, loss: 0.041444193571805954
step: 600, loss: 0.04060860723257065
step: 610, loss: 0.02805325947701931
step: 620, loss: 0.016274485737085342
step: 630, loss: 0.00020197199773974717
step: 640, loss: 0.00014851537707727402
step: 650, loss: 0.022760674357414246
step: 660, loss: 0.003914454020559788
step: 670, loss: 0.037648674100637436
step: 680, loss: 0.03933120518922806
step: 690, loss: 8.930759940994903e-05
step: 700, loss: 0.08053173124790192
step: 710, loss: 6.609681440750137e-05
step: 720, loss: 0.04456371068954468
step: 730, loss: 0.03521096333861351
step: 740, loss: 0.002211543032899499
step: 750, loss: 0.04718954861164093
step: 760, loss: 0.018407035619020462
step: 770, loss: 0.03783575817942619
step: 780, loss: 0.10308321565389633
step: 790, loss: 0.03688443824648857
step: 800, loss: 0.09830456227064133
step: 810, loss: 0.05559077113866806
step: 820, loss: 0.0782119557261467
step: 830, loss: 0.005987919867038727
step: 840, loss: 0.04468495026230812
step: 850, loss: 0.0002447289298288524
step: 860, loss: 0.03140559047460556
step: 870, loss: 0.022598812356591225
step: 880, loss: 0.0002668883535079658
step: 890, loss: 0.03989036753773689
step: 900, loss: 0.018932528793811798
step: 910, loss: 0.026110241189599037
step: 920, loss: 0.016017599031329155
step: 930, loss: 0.05883345752954483
step: 940, loss: 0.025050422176718712
step: 950, loss: 0.00421556131914258
step: 960, loss: 0.07941997051239014
step: 970, loss: 0.09044212102890015
epoch 17: dev_f1=0.9392523364485983, f1=0.9334574220567706, best_f1=0.9338842975206612
step: 0, loss: 0.08225268125534058
step: 10, loss: 0.00023972158669494092
step: 20, loss: 0.06024936959147453
step: 30, loss: 0.03995756804943085
step: 40, loss: 0.04733610525727272
step: 50, loss: 0.03937873989343643
step: 60, loss: 0.021982237696647644
step: 70, loss: 0.005965566728264093
step: 80, loss: 0.0001452096621505916
step: 90, loss: 0.0230224821716547
step: 100, loss: 0.00019410907407291234
step: 110, loss: 0.039348166435956955
step: 120, loss: 0.07001935690641403
step: 130, loss: 0.0479428805410862
step: 140, loss: 0.02269262634217739
step: 150, loss: 0.042779453098773956
step: 160, loss: 0.0001109191362047568
step: 170, loss: 0.00045558338752016425
step: 180, loss: 0.0005547690088860691
step: 190, loss: 0.01997404918074608
step: 200, loss: 0.04962281882762909
step: 210, loss: 0.02081613428890705
step: 220, loss: 0.04241836816072464
step: 230, loss: 0.005090619903057814
step: 240, loss: 0.06497718393802643
step: 250, loss: 0.05188237875699997
step: 260, loss: 0.04439112916588783
step: 270, loss: 0.0357084795832634
step: 280, loss: 0.0658564418554306
step: 290, loss: 0.024580487981438637
step: 300, loss: 0.023636095225811005
step: 310, loss: 0.06947219371795654
step: 320, loss: 0.0002763262018561363
step: 330, loss: 0.01705593429505825
step: 340, loss: 0.00033945293398573995
step: 350, loss: 0.011224757879972458
step: 360, loss: 0.010373040102422237
step: 370, loss: 0.01990486867725849
step: 380, loss: 0.041399888694286346
step: 390, loss: 0.05234059691429138
step: 400, loss: 0.02131221815943718
step: 410, loss: 0.022187216207385063
step: 420, loss: 0.02359974943101406
step: 430, loss: 0.050729624927043915
step: 440, loss: 0.020840857177972794
step: 450, loss: 0.030153220519423485
step: 460, loss: 0.05765311419963837
step: 470, loss: 0.03931719437241554
step: 480, loss: 0.020729118958115578
step: 490, loss: 5.016900468035601e-05
step: 500, loss: 0.022968491539359093
step: 510, loss: 0.00023432893794961274
step: 520, loss: 0.04083448648452759
step: 530, loss: 0.12987948954105377
step: 540, loss: 0.0008166762418113649
step: 550, loss: 0.041308268904685974
step: 560, loss: 0.01665578968822956
step: 570, loss: 0.03041839599609375
step: 580, loss: 0.0971832349896431
step: 590, loss: 0.019205208867788315
step: 600, loss: 0.061946265399456024
step: 610, loss: 0.027602871879935265
step: 620, loss: 0.02398446947336197
step: 630, loss: 0.011083284392952919
step: 640, loss: 0.0279335156083107
step: 650, loss: 0.02735072560608387
step: 660, loss: 9.56313670030795e-05
step: 670, loss: 0.019064757972955704
step: 680, loss: 0.00014146060857456177
step: 690, loss: 0.0197552889585495
step: 700, loss: 0.07612457871437073
step: 710, loss: 0.0046217492781579494
step: 720, loss: 0.023410532623529434
step: 730, loss: 0.00012496089038904756
step: 740, loss: 0.03162159398198128
step: 750, loss: 0.048968710005283356
step: 760, loss: 0.023407988250255585
step: 770, loss: 0.0002497192472219467
step: 780, loss: 0.00020192777446936816
step: 790, loss: 0.03615623340010643
step: 800, loss: 0.016597285866737366
step: 810, loss: 0.0413052961230278
step: 820, loss: 8.586688636569306e-05
step: 830, loss: 0.016127541661262512
step: 840, loss: 0.039129748940467834
step: 850, loss: 0.03307515010237694
step: 860, loss: 0.04529840126633644
step: 870, loss: 0.04300960898399353
step: 880, loss: 0.002059277845546603
step: 890, loss: 0.04857143387198448
step: 900, loss: 0.027719836682081223
step: 910, loss: 0.021947430446743965
step: 920, loss: 0.0025628546718508005
step: 930, loss: 0.012515094131231308
step: 940, loss: 0.002553168684244156
step: 950, loss: 0.040117669850587845
step: 960, loss: 0.024603957310318947
step: 970, loss: 0.08023415505886078
epoch 18: dev_f1=0.940570893776322, f1=0.9341429238673518, best_f1=0.9338842975206612
step: 0, loss: 0.03680437058210373
step: 10, loss: 0.022512085735797882
step: 20, loss: 0.05291217193007469
step: 30, loss: 0.0016068071126937866
step: 40, loss: 0.042853958904743195
step: 50, loss: 0.02294558472931385
step: 60, loss: 0.0701860561966896
step: 70, loss: 0.02232666313648224
step: 80, loss: 0.07721283286809921
step: 90, loss: 0.0003734884085133672
step: 100, loss: 0.040413230657577515
step: 110, loss: 0.01635895110666752
step: 120, loss: 0.018151499330997467
step: 130, loss: 0.04295608401298523
step: 140, loss: 0.03165115788578987
step: 150, loss: 0.00010870941332541406
step: 160, loss: 0.07479425519704819
step: 170, loss: 0.018100900575518608
step: 180, loss: 0.040950577706098557
step: 190, loss: 0.00011173549137311056
step: 200, loss: 3.8176011003088206e-05
step: 210, loss: 0.022641535848379135
step: 220, loss: 0.021540140733122826
step: 230, loss: 0.024517538025975227
step: 240, loss: 0.023857682943344116
step: 250, loss: 0.06996623426675797
step: 260, loss: 0.02383102849125862
step: 270, loss: 0.00021796839428134263
step: 280, loss: 0.04094761610031128
step: 290, loss: 0.030444826930761337
step: 300, loss: 0.01865699142217636
step: 310, loss: 0.030543217435479164
step: 320, loss: 7.784240006003529e-05
step: 330, loss: 0.02198372408747673
step: 340, loss: 0.0052865371108055115
step: 350, loss: 0.019708091393113136
step: 360, loss: 0.023253999650478363
step: 370, loss: 0.0751967653632164
step: 380, loss: 0.019229112192988396
step: 390, loss: 0.0413854606449604
step: 400, loss: 0.02269815094769001
step: 410, loss: 0.022299224510788918
step: 420, loss: 5.501670966623351e-05
step: 430, loss: 2.960373240057379e-05
step: 440, loss: 0.0006190970307216048
step: 450, loss: 6.526285142172128e-05
step: 460, loss: 0.016955135390162468
step: 470, loss: 0.02580392360687256
step: 480, loss: 0.017726358026266098
step: 490, loss: 0.0206085704267025
step: 500, loss: 0.023659707978367805
step: 510, loss: 0.02334154024720192
step: 520, loss: 0.0017395383911207318
step: 530, loss: 0.0008481958648189902
step: 540, loss: 5.3938227210892364e-05
step: 550, loss: 0.037055112421512604
step: 560, loss: 4.8792269808473065e-05
step: 570, loss: 7.560221274616197e-05
step: 580, loss: 0.06451587378978729
step: 590, loss: 0.06047169119119644
step: 600, loss: 3.3342043025186285e-05
step: 610, loss: 5.701574991689995e-05
step: 620, loss: 0.041387323290109634
step: 630, loss: 4.349847949924879e-05
step: 640, loss: 0.014902263879776001
step: 650, loss: 0.00031305471202358603
step: 660, loss: 7.871221168898046e-05
step: 670, loss: 0.04749707505106926
step: 680, loss: 0.022303365170955658
step: 690, loss: 0.06155528873205185
step: 700, loss: 0.018806418403983116
step: 710, loss: 0.00018257448391523212
step: 720, loss: 6.211370782693848e-05
step: 730, loss: 0.0328722782433033
step: 740, loss: 0.02254626527428627
step: 750, loss: 0.024554749950766563
step: 760, loss: 0.00012935786799062043
step: 770, loss: 0.01902070827782154
step: 780, loss: 0.04690195620059967
step: 790, loss: 0.03097577951848507
step: 800, loss: 0.00010637138620950282
step: 810, loss: 0.019397318363189697
step: 820, loss: 0.0013532205484807491
step: 830, loss: 0.0603150874376297
step: 840, loss: 0.023153478279709816
step: 850, loss: 0.01686909608542919
step: 860, loss: 0.07210275530815125
step: 870, loss: 0.03856485337018967
step: 880, loss: 0.023320088163018227
step: 890, loss: 0.036880556493997574
step: 900, loss: 0.026459375396370888
step: 910, loss: 0.04140453040599823
step: 920, loss: 0.02696276269853115
step: 930, loss: 0.012722612358629704
step: 940, loss: 0.026470454409718513
step: 950, loss: 0.02219546213746071
step: 960, loss: 0.02379464916884899
step: 970, loss: 0.08333985507488251
epoch 19: dev_f1=0.9387947269303202, f1=0.933083762283575, best_f1=0.9338842975206612
step: 0, loss: 0.003910969011485577
step: 10, loss: 0.04142562299966812
step: 20, loss: 0.061062153428792953
step: 30, loss: 0.03706498071551323
step: 40, loss: 0.05172981321811676
step: 50, loss: 0.017983917146921158
step: 60, loss: 0.005061369389295578
step: 70, loss: 0.01714901812374592
step: 80, loss: 0.012455365620553493
step: 90, loss: 1.614881148270797e-05
step: 100, loss: 0.012554923072457314
step: 110, loss: 0.018687551841139793
step: 120, loss: 0.024913707748055458
step: 130, loss: 0.08687455952167511
step: 140, loss: 0.05139492452144623
step: 150, loss: 0.024458615109324455
step: 160, loss: 0.07784140110015869
step: 170, loss: 0.020644137635827065
step: 180, loss: 0.06407824158668518
step: 190, loss: 0.0003160507185384631
step: 200, loss: 0.02458552084863186
step: 210, loss: 2.1571264369413257e-05
step: 220, loss: 0.10582256317138672
step: 230, loss: 0.05293538048863411
step: 240, loss: 0.04568719118833542
step: 250, loss: 0.021988164633512497
step: 260, loss: 0.03347467631101608
step: 270, loss: 0.043262604624032974
step: 280, loss: 4.021311906399205e-05
step: 290, loss: 0.053602561354637146
step: 300, loss: 0.013766494579613209
step: 310, loss: 0.014839477837085724
step: 320, loss: 0.07833950966596603
step: 330, loss: 4.1756891732802615e-05
step: 340, loss: 0.04442434012889862
step: 350, loss: 0.0010700019774958491
step: 360, loss: 3.0059951313887723e-05
step: 370, loss: 9.153396968031302e-05
step: 380, loss: 0.006213658954948187
step: 390, loss: 0.03984281048178673
step: 400, loss: 0.02262282371520996
step: 410, loss: 0.018255410715937614
step: 420, loss: 0.07541884481906891
step: 430, loss: 0.04070580005645752
step: 440, loss: 0.06785562634468079
step: 450, loss: 0.05169786512851715
step: 460, loss: 0.05219118297100067
step: 470, loss: 0.08548267930746078
step: 480, loss: 0.07152856141328812
step: 490, loss: 0.019118156284093857
step: 500, loss: 0.023143528029322624
step: 510, loss: 3.827092587016523e-05
step: 520, loss: 0.05383293703198433
step: 530, loss: 0.030683334916830063
step: 540, loss: 0.021490667015314102
step: 550, loss: 0.03878314793109894
step: 560, loss: 5.937941386946477e-05
step: 570, loss: 0.02776206098496914
step: 580, loss: 0.021197980269789696
step: 590, loss: 0.06797979027032852
step: 600, loss: 0.0023371169809252024
step: 610, loss: 0.02246166206896305
step: 620, loss: 3.330687104607932e-05
step: 630, loss: 2.2300957425613888e-05
step: 640, loss: 0.057132378220558167
step: 650, loss: 0.023041365668177605
step: 660, loss: 0.03854656219482422
step: 670, loss: 0.00027502738521434367
step: 680, loss: 0.010810730047523975
step: 690, loss: 0.02101900987327099
step: 700, loss: 0.05458229035139084
step: 710, loss: 0.014450173825025558
step: 720, loss: 7.877546886447817e-05
step: 730, loss: 3.728610317921266e-05
step: 740, loss: 4.736933624371886e-05
step: 750, loss: 0.04160803183913231
step: 760, loss: 0.021266616880893707
step: 770, loss: 0.021628309041261673
step: 780, loss: 0.04495073854923248
step: 790, loss: 0.024350479245185852
step: 800, loss: 0.020450487732887268
step: 810, loss: 0.058174729347229004
step: 820, loss: 0.02115459367632866
step: 830, loss: 0.024223653599619865
step: 840, loss: 0.08210378885269165
step: 850, loss: 7.214895595097914e-05
step: 860, loss: 0.06457424908876419
step: 870, loss: 6.59921788610518e-05
step: 880, loss: 1.099325072573265e-05
step: 890, loss: 0.0005725300288759172
step: 900, loss: 0.06641550362110138
step: 910, loss: 9.805123409023508e-05
step: 920, loss: 0.02418130822479725
step: 930, loss: 0.10284435003995895
step: 940, loss: 0.014667355455458164
step: 950, loss: 7.987026765476912e-05
step: 960, loss: 0.017832376062870026
step: 970, loss: 0.023274201899766922
epoch 20: dev_f1=0.9380614657210402, f1=0.9308885754583921, best_f1=0.9338842975206612
