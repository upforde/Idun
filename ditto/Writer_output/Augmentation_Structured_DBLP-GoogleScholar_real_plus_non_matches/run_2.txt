cuda
Device: cuda
step: 0, loss: 0.5362910032272339
step: 10, loss: 0.11940975487232208
step: 20, loss: 0.5467779040336609
step: 30, loss: 0.2937471866607666
step: 40, loss: 0.3345729410648346
step: 50, loss: 0.15724590420722961
step: 60, loss: 0.25890856981277466
step: 70, loss: 0.3571780025959015
step: 80, loss: 0.1888301968574524
step: 90, loss: 0.11838869750499725
step: 100, loss: 0.1731884628534317
step: 110, loss: 0.3378745913505554
step: 120, loss: 0.17914114892482758
step: 130, loss: 0.13741381466388702
step: 140, loss: 0.061365120112895966
step: 150, loss: 0.16502662003040314
step: 160, loss: 0.20684897899627686
step: 170, loss: 0.07203061133623123
step: 180, loss: 0.12020894885063171
step: 190, loss: 0.11862439662218094
step: 200, loss: 0.12276779115200043
step: 210, loss: 0.14431115984916687
step: 220, loss: 0.07820673286914825
step: 230, loss: 0.14029909670352936
step: 240, loss: 0.14412370324134827
step: 250, loss: 0.36657649278640747
step: 260, loss: 0.06683491170406342
step: 270, loss: 0.16937552392482758
step: 280, loss: 0.15699411928653717
step: 290, loss: 0.12345487624406815
step: 300, loss: 0.10691040754318237
step: 310, loss: 0.14896713197231293
step: 320, loss: 0.05459029600024223
step: 330, loss: 0.09237753599882126
step: 340, loss: 0.14172528684139252
step: 350, loss: 0.0974496528506279
step: 360, loss: 0.14102183282375336
step: 370, loss: 0.11956577748060226
step: 380, loss: 0.1295342743396759
step: 390, loss: 0.15224570035934448
step: 400, loss: 0.11702078580856323
step: 410, loss: 0.12593333423137665
step: 420, loss: 0.036185309290885925
step: 430, loss: 0.05566585808992386
step: 440, loss: 0.1219717413187027
step: 450, loss: 0.183803528547287
step: 460, loss: 0.06137662008404732
step: 470, loss: 0.0953984335064888
step: 480, loss: 0.046119268983602524
step: 490, loss: 0.122010737657547
step: 500, loss: 0.2461521178483963
step: 510, loss: 0.18816311657428741
step: 520, loss: 0.21560785174369812
step: 530, loss: 0.22349099814891815
step: 540, loss: 0.0795871913433075
step: 550, loss: 0.08436039090156555
step: 560, loss: 0.08466809242963791
step: 570, loss: 0.050656139850616455
step: 580, loss: 0.08161063492298126
step: 590, loss: 0.07251957803964615
step: 600, loss: 0.15415406227111816
step: 610, loss: 0.1321655958890915
step: 620, loss: 0.011816712096333504
step: 630, loss: 0.2671836018562317
step: 640, loss: 0.08363652974367142
step: 650, loss: 0.13811849057674408
step: 660, loss: 0.2707071006298065
step: 670, loss: 0.1051519438624382
step: 680, loss: 0.175943061709404
step: 690, loss: 0.15497305989265442
step: 700, loss: 0.19967317581176758
step: 710, loss: 0.05477432906627655
step: 720, loss: 0.20632469654083252
step: 730, loss: 0.1547413319349289
step: 740, loss: 0.07261679321527481
step: 750, loss: 0.07161324471235275
step: 760, loss: 0.09295891225337982
step: 770, loss: 0.12658818066120148
step: 780, loss: 0.13879157602787018
step: 790, loss: 0.25767797231674194
step: 800, loss: 0.06852973997592926
step: 810, loss: 0.3169475495815277
step: 820, loss: 0.295534610748291
step: 830, loss: 0.15004079043865204
step: 840, loss: 0.058105431497097015
step: 850, loss: 0.06493991613388062
step: 860, loss: 0.1698109358549118
step: 870, loss: 0.09922409802675247
step: 880, loss: 0.08439041674137115
step: 890, loss: 0.03084777481853962
step: 900, loss: 0.154826819896698
step: 910, loss: 0.17404469847679138
step: 920, loss: 0.08828488737344742
step: 930, loss: 0.0777374804019928
step: 940, loss: 0.07915069162845612
step: 950, loss: 0.22889547049999237
step: 960, loss: 0.27348050475120544
step: 970, loss: 0.1590385138988495
epoch 1: dev_f1=0.922654462242563, f1=0.918525261720528, best_f1=0.918525261720528
step: 0, loss: 0.15808358788490295
step: 10, loss: 0.24208608269691467
step: 20, loss: 0.06181180849671364
step: 30, loss: 0.0640941932797432
step: 40, loss: 0.08443351089954376
step: 50, loss: 0.047922972589731216
step: 60, loss: 0.030508041381835938
step: 70, loss: 0.0865410789847374
step: 80, loss: 0.011319935321807861
step: 90, loss: 0.0870080217719078
step: 100, loss: 0.006308203097432852
step: 110, loss: 0.23143704235553741
step: 120, loss: 0.08440382033586502
step: 130, loss: 0.08962305635213852
step: 140, loss: 0.0754203349351883
step: 150, loss: 0.18355068564414978
step: 160, loss: 0.0813947394490242
step: 170, loss: 0.07405301183462143
step: 180, loss: 0.03045663982629776
step: 190, loss: 0.04295794665813446
step: 200, loss: 0.0653790831565857
step: 210, loss: 0.1568068563938141
step: 220, loss: 0.02938956394791603
step: 230, loss: 0.08723567426204681
step: 240, loss: 0.1757560521364212
step: 250, loss: 0.18212130665779114
step: 260, loss: 0.058493733406066895
step: 270, loss: 0.12403253465890884
step: 280, loss: 0.03404363989830017
step: 290, loss: 0.11781811714172363
step: 300, loss: 0.13101112842559814
step: 310, loss: 0.03247294947504997
step: 320, loss: 0.025592176243662834
step: 330, loss: 0.13849425315856934
step: 340, loss: 0.12531283497810364
step: 350, loss: 0.03094496764242649
step: 360, loss: 0.09045233577489853
step: 370, loss: 0.09411287307739258
step: 380, loss: 0.2704131305217743
step: 390, loss: 0.057913538068532944
step: 400, loss: 0.13479959964752197
step: 410, loss: 0.0913548618555069
step: 420, loss: 0.0848882868885994
step: 430, loss: 0.11635538190603256
step: 440, loss: 0.17019324004650116
step: 450, loss: 0.06821970641613007
step: 460, loss: 0.06114930659532547
step: 470, loss: 0.18376432359218597
step: 480, loss: 0.0567111000418663
step: 490, loss: 0.1424056887626648
step: 500, loss: 0.15992704033851624
step: 510, loss: 0.17995916306972504
step: 520, loss: 0.20005157589912415
step: 530, loss: 0.07160750776529312
step: 540, loss: 0.09330978244543076
step: 550, loss: 0.09293308109045029
step: 560, loss: 0.3415372967720032
step: 570, loss: 0.10485249012708664
step: 580, loss: 0.051264144480228424
step: 590, loss: 0.15932393074035645
step: 600, loss: 0.04878557100892067
step: 610, loss: 0.16035299003124237
step: 620, loss: 0.0905403271317482
step: 630, loss: 0.1118338331580162
step: 640, loss: 0.019277770072221756
step: 650, loss: 0.0584256574511528
step: 660, loss: 0.09372678399085999
step: 670, loss: 0.04510901868343353
step: 680, loss: 0.09822484105825424
step: 690, loss: 0.09589564055204391
step: 700, loss: 0.09742444008588791
step: 710, loss: 0.25070178508758545
step: 720, loss: 0.2890033721923828
step: 730, loss: 0.022184524685144424
step: 740, loss: 0.20869988203048706
step: 750, loss: 0.03908880427479744
step: 760, loss: 0.06682854145765305
step: 770, loss: 0.08274642378091812
step: 780, loss: 0.08003253489732742
step: 790, loss: 0.09342846274375916
step: 800, loss: 0.1663600355386734
step: 810, loss: 0.04946544021368027
step: 820, loss: 0.0562153086066246
step: 830, loss: 0.18577590584754944
step: 840, loss: 0.09207680076360703
step: 850, loss: 0.1474560797214508
step: 860, loss: 0.09063515812158585
step: 870, loss: 0.03900310397148132
step: 880, loss: 0.0352296382188797
step: 890, loss: 0.085973359644413
step: 900, loss: 0.08725845813751221
step: 910, loss: 0.02437879517674446
step: 920, loss: 0.018106726929545403
step: 930, loss: 0.14767427742481232
step: 940, loss: 0.02675381861627102
step: 950, loss: 0.06769338995218277
step: 960, loss: 0.04602418467402458
step: 970, loss: 0.05978687107563019
epoch 2: dev_f1=0.9233610341643583, f1=0.9233560090702948, best_f1=0.9233560090702948
step: 0, loss: 0.012955809012055397
step: 10, loss: 0.03643875941634178
step: 20, loss: 0.04622115567326546
step: 30, loss: 0.06851492077112198
step: 40, loss: 0.08029376715421677
step: 50, loss: 0.05242012441158295
step: 60, loss: 0.11178580671548843
step: 70, loss: 0.02178203873336315
step: 80, loss: 0.03376680985093117
step: 90, loss: 0.04984579235315323
step: 100, loss: 0.09332749247550964
step: 110, loss: 0.0845363512635231
step: 120, loss: 0.21965649724006653
step: 130, loss: 0.12369852513074875
step: 140, loss: 0.03577887639403343
step: 150, loss: 0.0435672327876091
step: 160, loss: 0.06648777425289154
step: 170, loss: 0.02738066017627716
step: 180, loss: 0.046599939465522766
step: 190, loss: 0.042820148169994354
step: 200, loss: 0.14451076090335846
step: 210, loss: 0.06447415798902512
step: 220, loss: 0.018889334052801132
step: 230, loss: 0.055661071091890335
step: 240, loss: 0.07000821828842163
step: 250, loss: 0.1290501356124878
step: 260, loss: 0.04697612300515175
step: 270, loss: 0.04432254284620285
step: 280, loss: 0.059947699308395386
step: 290, loss: 0.09722725301980972
step: 300, loss: 0.07975542545318604
step: 310, loss: 0.12198329716920853
step: 320, loss: 0.10607203841209412
step: 330, loss: 0.055233705788850784
step: 340, loss: 0.2285088300704956
step: 350, loss: 0.10517191886901855
step: 360, loss: 0.11101775616407394
step: 370, loss: 0.05259284749627113
step: 380, loss: 0.08976636826992035
step: 390, loss: 0.09329891949892044
step: 400, loss: 0.11288376897573471
step: 410, loss: 0.30965283513069153
step: 420, loss: 0.08157407492399216
step: 430, loss: 0.124252088367939
step: 440, loss: 0.05956316739320755
step: 450, loss: 0.1017906665802002
step: 460, loss: 0.02400863543152809
step: 470, loss: 0.03517067804932594
step: 480, loss: 0.14308686554431915
step: 490, loss: 0.07902158051729202
step: 500, loss: 0.09411101043224335
step: 510, loss: 0.02278723381459713
step: 520, loss: 0.07028406858444214
step: 530, loss: 0.20691761374473572
step: 540, loss: 0.012095751240849495
step: 550, loss: 0.05917596444487572
step: 560, loss: 0.11678178608417511
step: 570, loss: 0.12399617582559586
step: 580, loss: 0.0763045996427536
step: 590, loss: 0.14996831119060516
step: 600, loss: 0.07412143796682358
step: 610, loss: 0.09303204715251923
step: 620, loss: 0.05940571054816246
step: 630, loss: 0.027815107256174088
step: 640, loss: 0.03433020040392876
step: 650, loss: 0.09403853863477707
step: 660, loss: 0.08491498976945877
step: 670, loss: 0.14621587097644806
step: 680, loss: 0.07411428540945053
step: 690, loss: 0.09966778010129929
step: 700, loss: 0.05187823623418808
step: 710, loss: 0.06841426342725754
step: 720, loss: 0.14593833684921265
step: 730, loss: 0.04088509455323219
step: 740, loss: 0.05854768678545952
step: 750, loss: 0.1280732899904251
step: 760, loss: 0.10232806950807571
step: 770, loss: 0.1642935574054718
step: 780, loss: 0.008593827486038208
step: 790, loss: 0.18313835561275482
step: 800, loss: 0.07670339941978455
step: 810, loss: 0.28928351402282715
step: 820, loss: 0.07112302631139755
step: 830, loss: 0.10306791216135025
step: 840, loss: 0.09483422338962555
step: 850, loss: 0.10165707021951675
step: 860, loss: 0.026771562173962593
step: 870, loss: 0.046259306371212006
step: 880, loss: 0.07663426548242569
step: 890, loss: 0.14464685320854187
step: 900, loss: 0.04929861053824425
step: 910, loss: 0.03821340948343277
step: 920, loss: 0.1528782993555069
step: 930, loss: 0.0608990341424942
step: 940, loss: 0.06598929315805435
step: 950, loss: 0.1939198076725006
step: 960, loss: 0.1318451315164566
step: 970, loss: 0.09241171926259995
epoch 3: dev_f1=0.9341806627326373, f1=0.9267631103074142, best_f1=0.9267631103074142
step: 0, loss: 0.1255677193403244
step: 10, loss: 0.0458853654563427
step: 20, loss: 0.016718562692403793
step: 30, loss: 0.006791417486965656
step: 40, loss: 0.06467150151729584
step: 50, loss: 0.0841679498553276
step: 60, loss: 0.050001077353954315
step: 70, loss: 0.02537725493311882
step: 80, loss: 0.08165799081325531
step: 90, loss: 0.05235149711370468
step: 100, loss: 0.003699462627992034
step: 110, loss: 0.08330480754375458
step: 120, loss: 0.02004375122487545
step: 130, loss: 0.07005243748426437
step: 140, loss: 0.03679995238780975
step: 150, loss: 0.1565418690443039
step: 160, loss: 0.01828840561211109
step: 170, loss: 0.18871141970157623
step: 180, loss: 0.10880734771490097
step: 190, loss: 0.09078241884708405
step: 200, loss: 0.07040049135684967
step: 210, loss: 0.06589947640895844
step: 220, loss: 0.10334495455026627
step: 230, loss: 0.014887942932546139
step: 240, loss: 0.19293741881847382
step: 250, loss: 0.13976381719112396
step: 260, loss: 0.06136368587613106
step: 270, loss: 0.13997654616832733
step: 280, loss: 0.08958836644887924
step: 290, loss: 0.10133291780948639
step: 300, loss: 0.02784138172864914
step: 310, loss: 0.09509411454200745
step: 320, loss: 0.025103827938437462
step: 330, loss: 0.034203317016363144
step: 340, loss: 0.1137654036283493
step: 350, loss: 0.04050324112176895
step: 360, loss: 0.35440805554389954
step: 370, loss: 0.03024660237133503
step: 380, loss: 0.05911384895443916
step: 390, loss: 0.037855830043554306
step: 400, loss: 0.035372618585824966
step: 410, loss: 0.04765331372618675
step: 420, loss: 0.04803067445755005
step: 430, loss: 0.029506467282772064
step: 440, loss: 0.06787280738353729
step: 450, loss: 0.07276318967342377
step: 460, loss: 0.28301578760147095
step: 470, loss: 0.13034407794475555
step: 480, loss: 0.17065532505512238
step: 490, loss: 0.04244047403335571
step: 500, loss: 0.0999932736158371
step: 510, loss: 0.019410019740462303
step: 520, loss: 0.0085511589422822
step: 530, loss: 0.16368713974952698
step: 540, loss: 0.12435657531023026
step: 550, loss: 0.17766407132148743
step: 560, loss: 0.041253987699747086
step: 570, loss: 0.15809592604637146
step: 580, loss: 0.01720500737428665
step: 590, loss: 0.19806714355945587
step: 600, loss: 0.013930323533713818
step: 610, loss: 0.06269647926092148
step: 620, loss: 0.10470525920391083
step: 630, loss: 0.09943850338459015
step: 640, loss: 0.014543859288096428
step: 650, loss: 0.08366464078426361
step: 660, loss: 0.04215114191174507
step: 670, loss: 0.09776294231414795
step: 680, loss: 0.0598776713013649
step: 690, loss: 0.05783962830901146
step: 700, loss: 0.037385400384664536
step: 710, loss: 0.043108806014060974
step: 720, loss: 0.08981388062238693
step: 730, loss: 0.06849820166826248
step: 740, loss: 0.13036108016967773
step: 750, loss: 0.10915739834308624
step: 760, loss: 0.15477456152439117
step: 770, loss: 0.252537339925766
step: 780, loss: 0.11308395862579346
step: 790, loss: 0.0709063932299614
step: 800, loss: 0.11388136446475983
step: 810, loss: 0.06754026561975479
step: 820, loss: 0.08824983984231949
step: 830, loss: 0.10452381521463394
step: 840, loss: 0.07463414967060089
step: 850, loss: 0.08607307821512222
step: 860, loss: 0.13205033540725708
step: 870, loss: 0.011644613929092884
step: 880, loss: 0.10043343156576157
step: 890, loss: 0.16718806326389313
step: 900, loss: 0.08288559317588806
step: 910, loss: 0.08033707737922668
step: 920, loss: 0.07015729695558548
step: 930, loss: 0.03941371664404869
step: 940, loss: 0.15780937671661377
step: 950, loss: 0.021739238873124123
step: 960, loss: 0.01762332394719124
step: 970, loss: 0.07681406289339066
epoch 4: dev_f1=0.9340866290018832, f1=0.9392523364485983, best_f1=0.9267631103074142
step: 0, loss: 0.10440549999475479
step: 10, loss: 0.012134546414017677
step: 20, loss: 0.04538847506046295
step: 30, loss: 0.09382825344800949
step: 40, loss: 0.07422210276126862
step: 50, loss: 0.015747981145977974
step: 60, loss: 0.0839596837759018
step: 70, loss: 0.03558158501982689
step: 80, loss: 0.030036216601729393
step: 90, loss: 0.049592263996601105
step: 100, loss: 0.20890825986862183
step: 110, loss: 0.07244987040758133
step: 120, loss: 0.04103575646877289
step: 130, loss: 0.10377812385559082
step: 140, loss: 0.25710347294807434
step: 150, loss: 0.12619464099407196
step: 160, loss: 0.021577462553977966
step: 170, loss: 0.0777326375246048
step: 180, loss: 0.08201243728399277
step: 190, loss: 0.07255452126264572
step: 200, loss: 0.03825727105140686
step: 210, loss: 0.07511179894208908
step: 220, loss: 0.108770951628685
step: 230, loss: 0.021534334868192673
step: 240, loss: 0.1506311446428299
step: 250, loss: 0.29078149795532227
step: 260, loss: 0.12420956790447235
step: 270, loss: 0.024888359010219574
step: 280, loss: 0.07776787132024765
step: 290, loss: 0.03940673545002937
step: 300, loss: 0.11234208196401596
step: 310, loss: 0.1159290224313736
step: 320, loss: 0.03566921502351761
step: 330, loss: 0.11761081218719482
step: 340, loss: 0.009617267176508904
step: 350, loss: 0.006335864774882793
step: 360, loss: 0.06429290771484375
step: 370, loss: 0.24396070837974548
step: 380, loss: 0.05051875114440918
step: 390, loss: 0.012319033965468407
step: 400, loss: 0.06783811748027802
step: 410, loss: 0.037875697016716
step: 420, loss: 0.06579884886741638
step: 430, loss: 0.029821747913956642
step: 440, loss: 0.0984630286693573
step: 450, loss: 0.20994898676872253
step: 460, loss: 0.14564605057239532
step: 470, loss: 0.039615780115127563
step: 480, loss: 0.021650563925504684
step: 490, loss: 0.013532955199480057
step: 500, loss: 0.047481633722782135
step: 510, loss: 0.05200657248497009
step: 520, loss: 0.09397843480110168
step: 530, loss: 0.11640606820583344
step: 540, loss: 0.043668102473020554
step: 550, loss: 0.034399762749671936
step: 560, loss: 0.09187296032905579
step: 570, loss: 0.16379249095916748
step: 580, loss: 0.09447649866342545
step: 590, loss: 0.030005356296896935
step: 600, loss: 0.11475905030965805
step: 610, loss: 0.014197450131177902
step: 620, loss: 0.024357307702302933
step: 630, loss: 0.027255715802311897
step: 640, loss: 0.09420167654752731
step: 650, loss: 0.07396882772445679
step: 660, loss: 0.10375680774450302
step: 670, loss: 0.08267052471637726
step: 680, loss: 0.04796452820301056
step: 690, loss: 0.03365596383810043
step: 700, loss: 0.08332577347755432
step: 710, loss: 0.07876037061214447
step: 720, loss: 0.03217853605747223
step: 730, loss: 0.05655062943696976
step: 740, loss: 0.006758611183613539
step: 750, loss: 0.11437952518463135
step: 760, loss: 0.015382650308310986
step: 770, loss: 0.10485750436782837
step: 780, loss: 0.19491824507713318
step: 790, loss: 0.12166594713926315
step: 800, loss: 0.11574508249759674
step: 810, loss: 0.09602133929729462
step: 820, loss: 0.04144329950213432
step: 830, loss: 0.09957114607095718
step: 840, loss: 0.14577895402908325
step: 850, loss: 0.038271017372608185
step: 860, loss: 0.12457199394702911
step: 870, loss: 0.03530256077647209
step: 880, loss: 0.24317967891693115
step: 890, loss: 0.04661423712968826
step: 900, loss: 0.06097249686717987
step: 910, loss: 0.06665443629026413
step: 920, loss: 0.04729035124182701
step: 930, loss: 0.08584632724523544
step: 940, loss: 0.05542002618312836
step: 950, loss: 0.1415218859910965
step: 960, loss: 0.03848400339484215
step: 970, loss: 0.16568590700626373
epoch 5: dev_f1=0.9389067524115755, f1=0.9311445508435933, best_f1=0.9311445508435933
step: 0, loss: 0.12338361144065857
step: 10, loss: 0.026878708973526955
step: 20, loss: 0.02224867418408394
step: 30, loss: 0.1267482042312622
step: 40, loss: 0.035383399575948715
step: 50, loss: 0.020037518814206123
step: 60, loss: 0.07558070123195648
step: 70, loss: 0.17184492945671082
step: 80, loss: 0.049808185547590256
step: 90, loss: 0.07264658063650131
step: 100, loss: 0.07283955812454224
step: 110, loss: 0.07128795236349106
step: 120, loss: 0.025710226967930794
step: 130, loss: 0.022602301090955734
step: 140, loss: 0.03196258842945099
step: 150, loss: 0.04062637686729431
step: 160, loss: 0.03919309005141258
step: 170, loss: 0.10462617129087448
step: 180, loss: 0.07568340003490448
step: 190, loss: 0.02103412337601185
step: 200, loss: 0.10608701407909393
step: 210, loss: 0.06450916826725006
step: 220, loss: 0.06493531167507172
step: 230, loss: 0.0413837656378746
step: 240, loss: 0.0313679575920105
step: 250, loss: 0.005340736359357834
step: 260, loss: 0.06274346262216568
step: 270, loss: 0.012631762772798538
step: 280, loss: 0.06873545050621033
step: 290, loss: 0.11579249799251556
step: 300, loss: 0.1544753909111023
step: 310, loss: 0.1877143383026123
step: 320, loss: 0.06323246657848358
step: 330, loss: 0.058545004576444626
step: 340, loss: 0.150771826505661
step: 350, loss: 0.07045873999595642
step: 360, loss: 0.07439723610877991
step: 370, loss: 0.0729590505361557
step: 380, loss: 0.054681118577718735
step: 390, loss: 0.016365407034754753
step: 400, loss: 0.04413595795631409
step: 410, loss: 0.07251018285751343
step: 420, loss: 0.14962553977966309
step: 430, loss: 0.08255831152200699
step: 440, loss: 0.024311872199177742
step: 450, loss: 0.029203986749053
step: 460, loss: 0.07188814133405685
step: 470, loss: 0.1494465470314026
step: 480, loss: 0.10252372175455093
step: 490, loss: 0.0346665158867836
step: 500, loss: 0.02356487512588501
step: 510, loss: 0.03506789356470108
step: 520, loss: 0.030978819355368614
step: 530, loss: 0.02597780153155327
step: 540, loss: 0.005411501042544842
step: 550, loss: 0.08188892155885696
step: 560, loss: 0.01284462958574295
step: 570, loss: 0.11101371794939041
step: 580, loss: 0.11600510030984879
step: 590, loss: 0.080226831138134
step: 600, loss: 0.04441411793231964
step: 610, loss: 0.0786319151520729
step: 620, loss: 0.021397938951849937
step: 630, loss: 0.0778183862566948
step: 640, loss: 0.009991539642214775
step: 650, loss: 0.06319577991962433
step: 660, loss: 0.2849118709564209
step: 670, loss: 0.0056946794502437115
step: 680, loss: 0.018760796636343002
step: 690, loss: 0.10254575312137604
step: 700, loss: 0.0737098753452301
step: 710, loss: 0.1475299447774887
step: 720, loss: 0.017586857080459595
step: 730, loss: 0.06425920873880386
step: 740, loss: 0.08828020840883255
step: 750, loss: 0.08628509938716888
step: 760, loss: 0.0778266116976738
step: 770, loss: 0.0037709639873355627
step: 780, loss: 0.05702905356884003
step: 790, loss: 0.02727830782532692
step: 800, loss: 0.07656802237033844
step: 810, loss: 0.16096284985542297
step: 820, loss: 0.010030130855739117
step: 830, loss: 0.0822218731045723
step: 840, loss: 0.03424713760614395
step: 850, loss: 0.16239386796951294
step: 860, loss: 0.06927302479743958
step: 870, loss: 0.016230231150984764
step: 880, loss: 0.021885618567466736
step: 890, loss: 0.14357292652130127
step: 900, loss: 0.08845821768045425
step: 910, loss: 0.10577381402254105
step: 920, loss: 0.10268525779247284
step: 930, loss: 7.43499695090577e-05
step: 940, loss: 0.061500608921051025
step: 950, loss: 0.09726007282733917
step: 960, loss: 0.11358840018510818
step: 970, loss: 0.028378065675497055
epoch 6: dev_f1=0.9396591432519575, f1=0.9367319071461084, best_f1=0.9367319071461084
step: 0, loss: 0.04679032415151596
step: 10, loss: 0.02745063230395317
step: 20, loss: 0.07437118142843246
step: 30, loss: 0.009726122952997684
step: 40, loss: 0.10114917904138565
step: 50, loss: 0.013229086063802242
step: 60, loss: 0.06655740737915039
step: 70, loss: 0.013113055378198624
step: 80, loss: 0.018810514360666275
step: 90, loss: 0.02902049571275711
step: 100, loss: 0.06416590511798859
step: 110, loss: 0.0532417893409729
step: 120, loss: 0.32711464166641235
step: 130, loss: 0.05764921382069588
step: 140, loss: 0.031163815408945084
step: 150, loss: 0.07484384626150131
step: 160, loss: 0.09729210287332535
step: 170, loss: 0.11723638325929642
step: 180, loss: 0.010565301403403282
step: 190, loss: 0.005951211787760258
step: 200, loss: 0.014031054452061653
step: 210, loss: 0.03845834359526634
step: 220, loss: 0.03726692125201225
step: 230, loss: 0.025835443288087845
step: 240, loss: 0.025823501870036125
step: 250, loss: 0.11561638861894608
step: 260, loss: 0.08174926042556763
step: 270, loss: 0.08088434487581253
step: 280, loss: 0.06263875961303711
step: 290, loss: 0.01565302163362503
step: 300, loss: 0.0688675120472908
step: 310, loss: 0.03042660653591156
step: 320, loss: 0.010599210858345032
step: 330, loss: 0.0034066601656377316
step: 340, loss: 0.0366622619330883
step: 350, loss: 0.07393894344568253
step: 360, loss: 0.05254644900560379
step: 370, loss: 0.08627433329820633
step: 380, loss: 0.08665452152490616
step: 390, loss: 0.013782484456896782
step: 400, loss: 0.050685156136751175
step: 410, loss: 0.032851915806531906
step: 420, loss: 0.022591134533286095
step: 430, loss: 0.08279542624950409
step: 440, loss: 0.04103073477745056
step: 450, loss: 0.007757431361824274
step: 460, loss: 0.06578322499990463
step: 470, loss: 0.2320374697446823
step: 480, loss: 0.016892271116375923
step: 490, loss: 0.11503104865550995
step: 500, loss: 0.06542839109897614
step: 510, loss: 0.038576606661081314
step: 520, loss: 0.01680712215602398
step: 530, loss: 0.010039972141385078
step: 540, loss: 0.0667053759098053
step: 550, loss: 0.046135593205690384
step: 560, loss: 0.027946703135967255
step: 570, loss: 0.02247554436326027
step: 580, loss: 0.08144836872816086
step: 590, loss: 0.027622196823358536
step: 600, loss: 0.03931732103228569
step: 610, loss: 0.1228054016828537
step: 620, loss: 0.18650373816490173
step: 630, loss: 0.06708449125289917
step: 640, loss: 0.08588522672653198
step: 650, loss: 0.05363212525844574
step: 660, loss: 0.055711522698402405
step: 670, loss: 0.06096950173377991
step: 680, loss: 0.02994462661445141
step: 690, loss: 0.017400039359927177
step: 700, loss: 0.033003680408000946
step: 710, loss: 0.09107016772031784
step: 720, loss: 0.06471272557973862
step: 730, loss: 0.08517538756132126
step: 740, loss: 0.017141567543148994
step: 750, loss: 0.07388225197792053
step: 760, loss: 0.15472345054149628
step: 770, loss: 0.13525880873203278
step: 780, loss: 0.13771018385887146
step: 790, loss: 0.014231918379664421
step: 800, loss: 0.005764695815742016
step: 810, loss: 0.07590126991271973
step: 820, loss: 0.09456191956996918
step: 830, loss: 0.08037924021482468
step: 840, loss: 0.03344361111521721
step: 850, loss: 0.02489199861884117
step: 860, loss: 0.01699082739651203
step: 870, loss: 0.08644808083772659
step: 880, loss: 0.1256088763475418
step: 890, loss: 0.09865584224462509
step: 900, loss: 0.10515481233596802
step: 910, loss: 0.13521258533000946
step: 920, loss: 0.11315848678350449
step: 930, loss: 0.03463999554514885
step: 940, loss: 0.01744760014116764
step: 950, loss: 0.08888562023639679
step: 960, loss: 0.008404708467423916
step: 970, loss: 0.020133590325713158
epoch 7: dev_f1=0.9332105020727776, f1=0.9308462238398544, best_f1=0.9367319071461084
step: 0, loss: 0.07425131648778915
step: 10, loss: 0.04615074396133423
step: 20, loss: 0.024855898693203926
step: 30, loss: 0.2081359624862671
step: 40, loss: 0.051853738725185394
step: 50, loss: 0.008365163579583168
step: 60, loss: 0.10714465379714966
step: 70, loss: 0.0011968845501542091
step: 80, loss: 0.04268910363316536
step: 90, loss: 0.04404009133577347
step: 100, loss: 0.06223749369382858
step: 110, loss: 0.14913895726203918
step: 120, loss: 0.012002472765743732
step: 130, loss: 0.03866182640194893
step: 140, loss: 0.0234361682087183
step: 150, loss: 0.13380742073059082
step: 160, loss: 0.013584626838564873
step: 170, loss: 0.01570069044828415
step: 180, loss: 0.1651209145784378
step: 190, loss: 0.025517748668789864
step: 200, loss: 0.1723930686712265
step: 210, loss: 0.009276151657104492
step: 220, loss: 0.019940746948122978
step: 230, loss: 0.005709679331630468
step: 240, loss: 0.06442387402057648
step: 250, loss: 0.024038054049015045
step: 260, loss: 0.022495081648230553
step: 270, loss: 0.004358678590506315
step: 280, loss: 0.004682581871747971
step: 290, loss: 0.019614487886428833
step: 300, loss: 0.09551381319761276
step: 310, loss: 0.08335303515195847
step: 320, loss: 0.048218872398138046
step: 330, loss: 0.11632214486598969
step: 340, loss: 0.02288031205534935
step: 350, loss: 0.04252978041768074
step: 360, loss: 0.05430636927485466
step: 370, loss: 0.239932119846344
step: 380, loss: 0.08122971653938293
step: 390, loss: 0.06185803934931755
step: 400, loss: 0.07407477498054504
step: 410, loss: 0.07983296364545822
step: 420, loss: 0.02923309989273548
step: 430, loss: 0.1957438886165619
step: 440, loss: 0.0654015764594078
step: 450, loss: 0.024558989331126213
step: 460, loss: 0.009622088633477688
step: 470, loss: 0.04553597792983055
step: 480, loss: 0.01491000410169363
step: 490, loss: 0.009751014411449432
step: 500, loss: 0.09448465704917908
step: 510, loss: 0.054880231618881226
step: 520, loss: 0.04748621582984924
step: 530, loss: 0.06639465689659119
step: 540, loss: 0.14931213855743408
step: 550, loss: 0.016756435856223106
step: 560, loss: 0.011476024053990841
step: 570, loss: 0.03253328800201416
step: 580, loss: 0.06989007443189621
step: 590, loss: 0.01584671437740326
step: 600, loss: 0.06971147656440735
step: 610, loss: 0.038894835859537125
step: 620, loss: 0.15402384102344513
step: 630, loss: 0.03908907249569893
step: 640, loss: 0.013622980564832687
step: 650, loss: 0.08192940801382065
step: 660, loss: 0.06228002533316612
step: 670, loss: 0.046870194375514984
step: 680, loss: 0.07710080593824387
step: 690, loss: 0.014280297793447971
step: 700, loss: 0.10225150734186172
step: 710, loss: 0.026455648243427277
step: 720, loss: 0.10048733651638031
step: 730, loss: 0.04540364071726799
step: 740, loss: 0.06188797578215599
step: 750, loss: 0.02760111540555954
step: 760, loss: 0.0033972987439483404
step: 770, loss: 0.0800289735198021
step: 780, loss: 0.017350757494568825
step: 790, loss: 0.08218975365161896
step: 800, loss: 0.07997696101665497
step: 810, loss: 0.10784681141376495
step: 820, loss: 0.060717083513736725
step: 830, loss: 0.009581683203577995
step: 840, loss: 0.0697137713432312
step: 850, loss: 0.024725738912820816
step: 860, loss: 0.012347709387540817
step: 870, loss: 0.04723864048719406
step: 880, loss: 0.046886466443538666
step: 890, loss: 0.05476909503340721
step: 900, loss: 0.010410360991954803
step: 910, loss: 0.0318041555583477
step: 920, loss: 0.00822686031460762
step: 930, loss: 0.01975296624004841
step: 940, loss: 0.06589436531066895
step: 950, loss: 0.039928048849105835
step: 960, loss: 0.01800818182528019
step: 970, loss: 0.1414722502231598
epoch 8: dev_f1=0.9354838709677419, f1=0.935602575896964, best_f1=0.9367319071461084
step: 0, loss: 0.07548638433218002
step: 10, loss: 0.017392171546816826
step: 20, loss: 0.06014440953731537
step: 30, loss: 0.017855390906333923
step: 40, loss: 0.12931916117668152
step: 50, loss: 0.1225452646613121
step: 60, loss: 0.08507844805717468
step: 70, loss: 0.01946241594851017
step: 80, loss: 0.02673133835196495
step: 90, loss: 0.04728434607386589
step: 100, loss: 0.18217334151268005
step: 110, loss: 0.177168071269989
step: 120, loss: 0.02240758016705513
step: 130, loss: 0.0933404490351677
step: 140, loss: 0.04769984632730484
step: 150, loss: 0.08725469559431076
step: 160, loss: 0.0058930423110723495
step: 170, loss: 0.018755219876766205
step: 180, loss: 0.04059494286775589
step: 190, loss: 0.04714623838663101
step: 200, loss: 0.033673617988824844
step: 210, loss: 0.017683476209640503
step: 220, loss: 0.0705571174621582
step: 230, loss: 0.06301895529031754
step: 240, loss: 0.10117790848016739
step: 250, loss: 0.10663715749979019
step: 260, loss: 0.06308805197477341
step: 270, loss: 0.04145537689328194
step: 280, loss: 0.08028414845466614
step: 290, loss: 0.001446035341359675
step: 300, loss: 0.1282031238079071
step: 310, loss: 0.0681949257850647
step: 320, loss: 0.05813039839267731
step: 330, loss: 0.035549063235521317
step: 340, loss: 0.02732008323073387
step: 350, loss: 0.08358708024024963
step: 360, loss: 0.06843797862529755
step: 370, loss: 0.019710229709744453
step: 380, loss: 0.014432588592171669
step: 390, loss: 0.026761623099446297
step: 400, loss: 0.059801727533340454
step: 410, loss: 0.07373438775539398
step: 420, loss: 0.1237102746963501
step: 430, loss: 0.007564997766166925
step: 440, loss: 0.008266318589448929
step: 450, loss: 0.001978192711248994
step: 460, loss: 0.0044115036725997925
step: 470, loss: 0.043141212314367294
step: 480, loss: 0.12478496134281158
step: 490, loss: 0.13120801746845245
step: 500, loss: 0.10237056761980057
step: 510, loss: 0.04842901602387428
step: 520, loss: 0.11363499611616135
step: 530, loss: 0.07157132029533386
step: 540, loss: 0.04893357306718826
step: 550, loss: 0.025620941072702408
step: 560, loss: 0.05303545668721199
step: 570, loss: 0.041924428194761276
step: 580, loss: 0.007565270643681288
step: 590, loss: 0.09072979539632797
step: 600, loss: 0.07721704244613647
step: 610, loss: 0.01656918413937092
step: 620, loss: 0.027445456013083458
step: 630, loss: 0.040630191564559937
step: 640, loss: 0.07498510926961899
step: 650, loss: 0.014048159122467041
step: 660, loss: 0.013284638524055481
step: 670, loss: 0.0230337455868721
step: 680, loss: 0.29941418766975403
step: 690, loss: 0.037292513996362686
step: 700, loss: 0.1952037811279297
step: 710, loss: 0.18491849303245544
step: 720, loss: 0.04405742511153221
step: 730, loss: 0.10448950529098511
step: 740, loss: 0.051307640969753265
step: 750, loss: 0.1334867775440216
step: 760, loss: 0.07618378847837448
step: 770, loss: 0.06638004630804062
step: 780, loss: 0.008122717961668968
step: 790, loss: 0.09801793098449707
step: 800, loss: 0.0003843158483505249
step: 810, loss: 0.013637317344546318
step: 820, loss: 0.11808370053768158
step: 830, loss: 0.10828431695699692
step: 840, loss: 0.21255390346050262
step: 850, loss: 0.07956764101982117
step: 860, loss: 0.006627022288739681
step: 870, loss: 0.027595771476626396
step: 880, loss: 0.14347881078720093
step: 890, loss: 0.045060548931360245
step: 900, loss: 0.08067696541547775
step: 910, loss: 0.11076585203409195
step: 920, loss: 0.04095492511987686
step: 930, loss: 0.019159473478794098
step: 940, loss: 0.0024097454734146595
step: 950, loss: 0.07586756348609924
step: 960, loss: 0.02798863872885704
step: 970, loss: 0.018757717683911324
epoch 9: dev_f1=0.9353507565337, f1=0.9350885156604629, best_f1=0.9367319071461084
step: 0, loss: 0.21575519442558289
step: 10, loss: 0.06098851561546326
step: 20, loss: 0.07560684531927109
step: 30, loss: 0.013085179030895233
step: 40, loss: 0.08066216856241226
step: 50, loss: 0.07299604266881943
step: 60, loss: 0.009240640327334404
step: 70, loss: 0.05337969958782196
step: 80, loss: 0.018671786412596703
step: 90, loss: 0.020691171288490295
step: 100, loss: 0.003725382499396801
step: 110, loss: 0.06605219841003418
step: 120, loss: 0.017546338960528374
step: 130, loss: 0.1188458502292633
step: 140, loss: 0.13672195374965668
step: 150, loss: 0.13168643414974213
step: 160, loss: 0.0019324906170368195
step: 170, loss: 0.025056984275579453
step: 180, loss: 0.0025791667867451906
step: 190, loss: 0.029130464419722557
step: 200, loss: 0.03400857746601105
step: 210, loss: 0.006031956989318132
step: 220, loss: 0.0779028981924057
step: 230, loss: 0.01996852643787861
step: 240, loss: 0.08760253340005875
step: 250, loss: 0.010766478255391121
step: 260, loss: 0.03209967538714409
step: 270, loss: 0.14973744750022888
step: 280, loss: 0.016703704372048378
step: 290, loss: 0.07847601920366287
step: 300, loss: 0.01580709218978882
step: 310, loss: 0.07320062071084976
step: 320, loss: 0.08892932534217834
step: 330, loss: 0.0033667737152427435
step: 340, loss: 0.01520698145031929
step: 350, loss: 0.1558210551738739
step: 360, loss: 0.004239295143634081
step: 370, loss: 0.07410494238138199
step: 380, loss: 0.05054497718811035
step: 390, loss: 0.1637454777956009
step: 400, loss: 0.059164468199014664
step: 410, loss: 0.04958819970488548
step: 420, loss: 0.03711409494280815
step: 430, loss: 0.06644365936517715
step: 440, loss: 0.0945969894528389
step: 450, loss: 0.04356216639280319
step: 460, loss: 0.08713316917419434
step: 470, loss: 0.014230258762836456
step: 480, loss: 0.07077784091234207
step: 490, loss: 0.06571122258901596
step: 500, loss: 0.05652550980448723
step: 510, loss: 0.02314760722219944
step: 520, loss: 0.060145583003759384
step: 530, loss: 0.04077306389808655
step: 540, loss: 0.024486558511853218
step: 550, loss: 0.07218541949987411
step: 560, loss: 0.11964299529790878
step: 570, loss: 0.018168143928050995
step: 580, loss: 0.09035807102918625
step: 590, loss: 0.024374699220061302
step: 600, loss: 0.12889055907726288
step: 610, loss: 0.0075863623060286045
step: 620, loss: 0.04309883713722229
step: 630, loss: 7.317630661418661e-05
step: 640, loss: 0.0022546404507011175
step: 650, loss: 0.007823153398931026
step: 660, loss: 0.061161357909440994
step: 670, loss: 0.033261239528656006
step: 680, loss: 0.02479586750268936
step: 690, loss: 0.010997187346220016
step: 700, loss: 0.06382741779088974
step: 710, loss: 0.06675366312265396
step: 720, loss: 0.06815101206302643
step: 730, loss: 0.013423528522253036
step: 740, loss: 0.00025722055579535663
step: 750, loss: 0.020465418696403503
step: 760, loss: 0.06515305489301682
step: 770, loss: 0.040231745690107346
step: 780, loss: 0.21784789860248566
step: 790, loss: 0.11998903006315231
step: 800, loss: 0.11230120807886124
step: 810, loss: 0.0073372009210288525
step: 820, loss: 0.02157198078930378
step: 830, loss: 0.06222950294613838
step: 840, loss: 0.09947102516889572
step: 850, loss: 0.022716786712408066
step: 860, loss: 0.07412689179182053
step: 870, loss: 0.1223808005452156
step: 880, loss: 0.026445697993040085
step: 890, loss: 0.0714297816157341
step: 900, loss: 0.05189228430390358
step: 910, loss: 0.02014997787773609
step: 920, loss: 0.02615021914243698
step: 930, loss: 0.062103770673274994
step: 940, loss: 0.08303848654031754
step: 950, loss: 0.13390682637691498
step: 960, loss: 0.09523080289363861
step: 970, loss: 0.038464054465293884
epoch 10: dev_f1=0.9303391384051329, f1=0.9323583180987203, best_f1=0.9367319071461084
step: 0, loss: 0.03236616775393486
step: 10, loss: 0.07648305594921112
step: 20, loss: 0.073769211769104
step: 30, loss: 0.07481274753808975
step: 40, loss: 0.005163269117474556
step: 50, loss: 0.07200350612401962
step: 60, loss: 0.042660437524318695
step: 70, loss: 0.00476024579256773
step: 80, loss: 0.053299032151699066
step: 90, loss: 0.10126613080501556
step: 100, loss: 0.045030735433101654
step: 110, loss: 0.09007641673088074
step: 120, loss: 0.18751861155033112
step: 130, loss: 0.011953681707382202
step: 140, loss: 0.052612777799367905
step: 150, loss: 0.12509804964065552
step: 160, loss: 0.021558906883001328
step: 170, loss: 0.019587457180023193
step: 180, loss: 0.04855497553944588
step: 190, loss: 0.033132683485746384
step: 200, loss: 0.004793791100382805
step: 210, loss: 0.025255423039197922
step: 220, loss: 0.0018345621647313237
step: 230, loss: 0.0034567140974104404
step: 240, loss: 0.11399342864751816
step: 250, loss: 0.12854482233524323
step: 260, loss: 0.040229130536317825
step: 270, loss: 0.0037677043583244085
step: 280, loss: 0.023996062576770782
step: 290, loss: 0.035249583423137665
step: 300, loss: 0.005304600112140179
step: 310, loss: 0.015743238851428032
step: 320, loss: 0.039990413933992386
step: 330, loss: 0.021246688440442085
step: 340, loss: 0.05420219525694847
step: 350, loss: 0.0534115731716156
step: 360, loss: 0.06287772953510284
step: 370, loss: 0.025600360706448555
step: 380, loss: 0.11441300064325333
step: 390, loss: 0.012003458105027676
step: 400, loss: 0.013337544165551662
step: 410, loss: 0.031119348481297493
step: 420, loss: 0.0783480554819107
step: 430, loss: 0.14577914774417877
step: 440, loss: 0.14100344479084015
step: 450, loss: 0.030764717608690262
step: 460, loss: 0.08966788649559021
step: 470, loss: 0.022182587534189224
step: 480, loss: 0.0583154521882534
step: 490, loss: 0.06835980713367462
step: 500, loss: 0.09258601814508438
step: 510, loss: 0.033272791653871536
step: 520, loss: 0.08842042833566666
step: 530, loss: 0.0299203060567379
step: 540, loss: 0.18092863261699677
step: 550, loss: 0.07282651215791702
step: 560, loss: 0.039336103945970535
step: 570, loss: 0.03375682234764099
step: 580, loss: 0.005403872113674879
step: 590, loss: 0.1374501734972
step: 600, loss: 0.06907166540622711
step: 610, loss: 0.0007440839544869959
step: 620, loss: 0.013248025439679623
step: 630, loss: 0.10206376761198044
step: 640, loss: 0.035806044936180115
step: 650, loss: 0.12096607685089111
step: 660, loss: 0.12152538448572159
step: 670, loss: 0.0017809784039855003
step: 680, loss: 0.05206666886806488
step: 690, loss: 0.021662496030330658
step: 700, loss: 0.003557485295459628
step: 710, loss: 0.12542612850666046
step: 720, loss: 0.0711139366030693
step: 730, loss: 0.10989668220281601
step: 740, loss: 0.02551271952688694
step: 750, loss: 0.04096519947052002
step: 760, loss: 0.0592132993042469
step: 770, loss: 0.01824421063065529
step: 780, loss: 0.03987916558980942
step: 790, loss: 0.08019126951694489
step: 800, loss: 0.02875109389424324
step: 810, loss: 0.0784062072634697
step: 820, loss: 0.06200144439935684
step: 830, loss: 0.13367986679077148
step: 840, loss: 0.0663178488612175
step: 850, loss: 0.050573281943798065
step: 860, loss: 0.009356051683425903
step: 870, loss: 0.08561216294765472
step: 880, loss: 0.07525403052568436
step: 890, loss: 0.029128022491931915
step: 900, loss: 0.02117297239601612
step: 910, loss: 0.0019979074131697416
step: 920, loss: 0.006956008262932301
step: 930, loss: 0.13883686065673828
step: 940, loss: 0.042045511305332184
step: 950, loss: 0.06774326413869858
step: 960, loss: 0.0416557677090168
step: 970, loss: 0.021458815783262253
epoch 11: dev_f1=0.9368131868131868, f1=0.9329685362517101, best_f1=0.9367319071461084
step: 0, loss: 0.03156250715255737
step: 10, loss: 0.03491201996803284
step: 20, loss: 0.03693769872188568
step: 30, loss: 0.04873638600111008
step: 40, loss: 0.044080767780542374
step: 50, loss: 0.012931544333696365
step: 60, loss: 0.041774213314056396
step: 70, loss: 0.06448611617088318
step: 80, loss: 0.11256344616413116
step: 90, loss: 0.028555193915963173
step: 100, loss: 0.04508129879832268
step: 110, loss: 0.059937890619039536
step: 120, loss: 0.045113835483789444
step: 130, loss: 0.048687346279621124
step: 140, loss: 0.09388671815395355
step: 150, loss: 0.25247108936309814
step: 160, loss: 0.007668889593333006
step: 170, loss: 0.0035263560712337494
step: 180, loss: 0.0587410032749176
step: 190, loss: 0.03188129514455795
step: 200, loss: 0.08999952673912048
step: 210, loss: 0.0016164974076673388
step: 220, loss: 0.037182245403528214
step: 230, loss: 0.005335847847163677
step: 240, loss: 5.913926725042984e-05
step: 250, loss: 0.037602320313453674
step: 260, loss: 0.03198089450597763
step: 270, loss: 0.025349881500005722
step: 280, loss: 0.017568117007613182
step: 290, loss: 0.019356949254870415
step: 300, loss: 0.015922855585813522
step: 310, loss: 0.024472324177622795
step: 320, loss: 0.048281870782375336
step: 330, loss: 0.08480595052242279
step: 340, loss: 0.0008067995659075677
step: 350, loss: 0.004620556253939867
step: 360, loss: 0.05988567695021629
step: 370, loss: 0.09024392068386078
step: 380, loss: 0.028033964335918427
step: 390, loss: 0.006728524342179298
step: 400, loss: 0.004793765489012003
step: 410, loss: 0.0037133051082491875
step: 420, loss: 0.021852340549230576
step: 430, loss: 0.05016431584954262
step: 440, loss: 0.0440419465303421
step: 450, loss: 0.06548316776752472
step: 460, loss: 0.02828149124979973
step: 470, loss: 0.02548881247639656
step: 480, loss: 0.03398946672677994
step: 490, loss: 0.024188369512557983
step: 500, loss: 0.05851007625460625
step: 510, loss: 0.04942059889435768
step: 520, loss: 0.03944404795765877
step: 530, loss: 0.037549614906311035
step: 540, loss: 0.002826568903401494
step: 550, loss: 0.04212779551744461
step: 560, loss: 0.10828180611133575
step: 570, loss: 0.051219258457422256
step: 580, loss: 0.0022679083049297333
step: 590, loss: 0.020769217982888222
step: 600, loss: 0.07717138528823853
step: 610, loss: 0.014106204733252525
step: 620, loss: 0.057686515152454376
step: 630, loss: 0.08978747576475143
step: 640, loss: 0.03008364327251911
step: 650, loss: 0.027611957862973213
step: 660, loss: 0.1613413244485855
step: 670, loss: 0.024259865283966064
step: 680, loss: 0.08244872838258743
step: 690, loss: 0.07384401559829712
step: 700, loss: 0.027085240930318832
step: 710, loss: 0.05551622062921524
step: 720, loss: 0.0742429867386818
step: 730, loss: 0.059453170746564865
step: 740, loss: 0.006680803839117289
step: 750, loss: 0.006698795594274998
step: 760, loss: 0.1410532146692276
step: 770, loss: 0.04170520603656769
step: 780, loss: 0.04815642535686493
step: 790, loss: 0.019984770566225052
step: 800, loss: 0.01968999207019806
step: 810, loss: 0.0004787603684235364
step: 820, loss: 0.016553010791540146
step: 830, loss: 0.07801134884357452
step: 840, loss: 0.07254479825496674
step: 850, loss: 0.16282181441783905
step: 860, loss: 0.0077461134642362595
step: 870, loss: 0.07114721834659576
step: 880, loss: 0.12538327276706696
step: 890, loss: 0.12832486629486084
step: 900, loss: 0.011742695234715939
step: 910, loss: 0.116673044860363
step: 920, loss: 0.06855087727308273
step: 930, loss: 0.08663076162338257
step: 940, loss: 0.03979997709393501
step: 950, loss: 0.023065757006406784
step: 960, loss: 0.017446503043174744
step: 970, loss: 0.014959168620407581
epoch 12: dev_f1=0.9325210871602625, f1=0.9328984156570364, best_f1=0.9367319071461084
step: 0, loss: 0.007738994900137186
step: 10, loss: 0.025388382375240326
step: 20, loss: 0.05014950782060623
step: 30, loss: 0.00839376449584961
step: 40, loss: 0.010469833388924599
step: 50, loss: 0.047185175120830536
step: 60, loss: 0.0011070205364376307
step: 70, loss: 0.1737847924232483
step: 80, loss: 0.024362143129110336
step: 90, loss: 0.04788127914071083
step: 100, loss: 0.0634673535823822
step: 110, loss: 1.3321528967935592e-05
step: 120, loss: 0.005903924815356731
step: 130, loss: 0.018305214121937752
step: 140, loss: 0.005912237800657749
step: 150, loss: 0.03291104733943939
step: 160, loss: 0.0264650359749794
step: 170, loss: 0.02665369212627411
step: 180, loss: 0.007464529015123844
step: 190, loss: 0.030354157090187073
step: 200, loss: 0.0740450844168663
step: 210, loss: 0.013852113857865334
step: 220, loss: 0.07930254191160202
step: 230, loss: 0.08128909766674042
step: 240, loss: 0.01034771092236042
step: 250, loss: 0.03220122307538986
step: 260, loss: 0.025010699406266212
step: 270, loss: 0.056474387645721436
step: 280, loss: 0.041927095502614975
step: 290, loss: 0.0009213836747221649
step: 300, loss: 0.03902244567871094
step: 310, loss: 0.018497884273529053
step: 320, loss: 0.011339839547872543
step: 330, loss: 0.044217512011528015
step: 340, loss: 0.030811024829745293
step: 350, loss: 0.035524360835552216
step: 360, loss: 0.0157694723457098
step: 370, loss: 0.005567191634327173
step: 380, loss: 0.07214614003896713
step: 390, loss: 0.034731123596429825
step: 400, loss: 0.03268007934093475
step: 410, loss: 0.014500749297440052
step: 420, loss: 0.07292994111776352
step: 430, loss: 0.06103092432022095
step: 440, loss: 0.01610003039240837
step: 450, loss: 0.16654162108898163
step: 460, loss: 2.8717360692098737e-05
step: 470, loss: 0.023042554035782814
step: 480, loss: 0.03056742250919342
step: 490, loss: 0.02060827799141407
step: 500, loss: 0.013868196867406368
step: 510, loss: 0.02714235708117485
step: 520, loss: 0.038554348051548004
step: 530, loss: 0.025399262085556984
step: 540, loss: 0.1280243694782257
step: 550, loss: 0.022415556013584137
step: 560, loss: 0.04973316192626953
step: 570, loss: 0.08948320150375366
step: 580, loss: 0.005687408614903688
step: 590, loss: 0.039792124181985855
step: 600, loss: 0.031559210270643234
step: 610, loss: 0.08482299000024796
step: 620, loss: 0.0031673815101385117
step: 630, loss: 0.055591512471437454
step: 640, loss: 0.03843130171298981
step: 650, loss: 0.0008549331687390804
step: 660, loss: 0.0072935232892632484
step: 670, loss: 0.07380588352680206
step: 680, loss: 0.014266671612858772
step: 690, loss: 0.0031868680380284786
step: 700, loss: 0.005059397779405117
step: 710, loss: 0.04016744717955589
step: 720, loss: 0.04616313800215721
step: 730, loss: 0.06477072089910507
step: 740, loss: 0.054329708218574524
step: 750, loss: 0.040895670652389526
step: 760, loss: 0.0022555063478648663
step: 770, loss: 0.0037020461168140173
step: 780, loss: 0.0007686364115215838
step: 790, loss: 0.12939760088920593
step: 800, loss: 0.018471883609890938
step: 810, loss: 0.04287712648510933
step: 820, loss: 0.07269801199436188
step: 830, loss: 0.04750166833400726
step: 840, loss: 0.00821010023355484
step: 850, loss: 0.02771425060927868
step: 860, loss: 0.019285179674625397
step: 870, loss: 0.0385173037648201
step: 880, loss: 0.0692497119307518
step: 890, loss: 0.18637338280677795
step: 900, loss: 0.017509853467345238
step: 910, loss: 0.03132503852248192
step: 920, loss: 0.026901187375187874
step: 930, loss: 0.03574593737721443
step: 940, loss: 0.004985988140106201
step: 950, loss: 0.012437098659574986
step: 960, loss: 0.05061173811554909
step: 970, loss: 0.00014604524767491966
epoch 13: dev_f1=0.9337656322371468, f1=0.932904411764706, best_f1=0.9367319071461084
step: 0, loss: 0.18970370292663574
step: 10, loss: 0.061865486204624176
step: 20, loss: 0.05280521512031555
step: 30, loss: 0.027379900217056274
step: 40, loss: 0.08727755397558212
step: 50, loss: 0.003287916537374258
step: 60, loss: 5.08844168507494e-05
step: 70, loss: 0.030446097254753113
step: 80, loss: 0.06253215670585632
step: 90, loss: 0.08530719578266144
step: 100, loss: 0.00239774351939559
step: 110, loss: 0.05418841168284416
step: 120, loss: 0.08573868870735168
step: 130, loss: 0.04018889367580414
step: 140, loss: 0.057692866772413254
step: 150, loss: 6.908788782311603e-05
step: 160, loss: 1.0091754120367114e-05
step: 170, loss: 0.021866993978619576
step: 180, loss: 0.00017953773203771561
step: 190, loss: 0.014786546118557453
step: 200, loss: 0.0013775023398920894
step: 210, loss: 0.026928991079330444
step: 220, loss: 0.02993953227996826
step: 230, loss: 0.022988559678196907
step: 240, loss: 0.03823854774236679
step: 250, loss: 0.03451327607035637
step: 260, loss: 0.03930363804101944
step: 270, loss: 0.016826866194605827
step: 280, loss: 0.027653126046061516
step: 290, loss: 0.10198919475078583
step: 300, loss: 0.038298625499010086
step: 310, loss: 0.045719489455223083
step: 320, loss: 0.13271424174308777
step: 330, loss: 0.04367879778146744
step: 340, loss: 0.026602119207382202
step: 350, loss: 0.09823289513587952
step: 360, loss: 0.016827411949634552
step: 370, loss: 0.07875098288059235
step: 380, loss: 0.05048874393105507
step: 390, loss: 0.04972860962152481
step: 400, loss: 0.004453256260603666
step: 410, loss: 0.0525532029569149
step: 420, loss: 0.0795670598745346
step: 430, loss: 0.01915774680674076
step: 440, loss: 0.07193324714899063
step: 450, loss: 0.023342173546552658
step: 460, loss: 0.05735400691628456
step: 470, loss: 0.06759229302406311
step: 480, loss: 0.03834451735019684
step: 490, loss: 0.002876012586057186
step: 500, loss: 0.00123718346003443
step: 510, loss: 0.009729800745844841
step: 520, loss: 0.0002748900151345879
step: 530, loss: 0.03932061418890953
step: 540, loss: 0.017222775146365166
step: 550, loss: 0.02595967799425125
step: 560, loss: 0.021638816222548485
step: 570, loss: 0.01984921656548977
step: 580, loss: 0.07073398679494858
step: 590, loss: 0.02632695995271206
step: 600, loss: 0.043935954570770264
step: 610, loss: 0.0379357635974884
step: 620, loss: 0.01266747061163187
step: 630, loss: 0.04016302898526192
step: 640, loss: 0.0022156164050102234
step: 650, loss: 0.05327967181801796
step: 660, loss: 0.04626220464706421
step: 670, loss: 0.022930389270186424
step: 680, loss: 0.005721201654523611
step: 690, loss: 0.006964343134313822
step: 700, loss: 0.00011351212742738426
step: 710, loss: 0.0010204362915828824
step: 720, loss: 0.00017092961934395134
step: 730, loss: 0.004215188790112734
step: 740, loss: 0.022434940561652184
step: 750, loss: 0.015159429050981998
step: 760, loss: 0.013272684998810291
step: 770, loss: 0.034198760986328125
step: 780, loss: 0.04688632860779762
step: 790, loss: 0.05566725507378578
step: 800, loss: 0.15144850313663483
step: 810, loss: 0.10692921280860901
step: 820, loss: 0.0025540473870933056
step: 830, loss: 0.054418593645095825
step: 840, loss: 0.02221153862774372
step: 850, loss: 0.02435464970767498
step: 860, loss: 0.0001469037524657324
step: 870, loss: 0.034322626888751984
step: 880, loss: 0.0039703818038105965
step: 890, loss: 0.024838581681251526
step: 900, loss: 0.001231572823598981
step: 910, loss: 0.012421795167028904
step: 920, loss: 0.02439488098025322
step: 930, loss: 0.0004964086692780256
step: 940, loss: 0.0010034353472292423
step: 950, loss: 0.04746882990002632
step: 960, loss: 0.03324310854077339
step: 970, loss: 0.1146417185664177
epoch 14: dev_f1=0.9333950046253469, f1=0.9311294765840221, best_f1=0.9367319071461084
step: 0, loss: 0.07855834811925888
step: 10, loss: 0.00809201505035162
step: 20, loss: 0.0348842553794384
step: 30, loss: 0.026923535391688347
step: 40, loss: 0.022082999348640442
step: 50, loss: 0.02922368049621582
step: 60, loss: 0.05062592402100563
step: 70, loss: 0.061619918793439865
step: 80, loss: 0.017885249108076096
step: 90, loss: 0.07421797513961792
step: 100, loss: 0.00015724607510492206
step: 110, loss: 0.004434236790984869
step: 120, loss: 0.08593563735485077
step: 130, loss: 0.013012174516916275
step: 140, loss: 0.024945596233010292
step: 150, loss: 0.06343106180429459
step: 160, loss: 0.07042714953422546
step: 170, loss: 0.038953542709350586
step: 180, loss: 0.04196324944496155
step: 190, loss: 0.020064882934093475
step: 200, loss: 0.007558299694210291
step: 210, loss: 0.11902554333209991
step: 220, loss: 0.022953152656555176
step: 230, loss: 1.1332260328345e-05
step: 240, loss: 0.022637618705630302
step: 250, loss: 0.05238509550690651
step: 260, loss: 0.08232779800891876
step: 270, loss: 0.044413525611162186
step: 280, loss: 0.01729733869433403
step: 290, loss: 0.07242292165756226
step: 300, loss: 0.04530160874128342
step: 310, loss: 0.07044725865125656
step: 320, loss: 0.021078668534755707
step: 330, loss: 0.07281310856342316
step: 340, loss: 0.006035795900970697
step: 350, loss: 0.05636659264564514
step: 360, loss: 0.0006891243974678218
step: 370, loss: 0.023724185302853584
step: 380, loss: 0.06837885826826096
step: 390, loss: 0.013620289973914623
step: 400, loss: 0.03840923681855202
step: 410, loss: 0.014456738717854023
step: 420, loss: 0.09782519936561584
step: 430, loss: 3.6450033803703263e-05
step: 440, loss: 0.022635938599705696
step: 450, loss: 0.11924251168966293
step: 460, loss: 0.02686445228755474
step: 470, loss: 0.043099284172058105
step: 480, loss: 0.03219734504818916
step: 490, loss: 0.0846368670463562
step: 500, loss: 0.0017347055254504085
step: 510, loss: 0.020743535831570625
step: 520, loss: 0.001148007228039205
step: 530, loss: 0.046056073158979416
step: 540, loss: 0.03051134943962097
step: 550, loss: 0.017953572794795036
step: 560, loss: 0.04087715595960617
step: 570, loss: 0.048733942210674286
step: 580, loss: 0.07040800154209137
step: 590, loss: 0.06654193252325058
step: 600, loss: 0.026114048436284065
step: 610, loss: 0.019653214141726494
step: 620, loss: 0.04263795167207718
step: 630, loss: 0.021000878885388374
step: 640, loss: 0.004959713201969862
step: 650, loss: 0.0006400463171303272
step: 660, loss: 0.02366042323410511
step: 670, loss: 0.038432490080595016
step: 680, loss: 0.07018576562404633
step: 690, loss: 0.04738982021808624
step: 700, loss: 0.10980219393968582
step: 710, loss: 0.040209513157606125
step: 720, loss: 0.07987423241138458
step: 730, loss: 0.025025255978107452
step: 740, loss: 0.010994283482432365
step: 750, loss: 0.024679556488990784
step: 760, loss: 0.04451747238636017
step: 770, loss: 0.01662200316786766
step: 780, loss: 0.03949476778507233
step: 790, loss: 0.1418437361717224
step: 800, loss: 0.0030763752292841673
step: 810, loss: 0.004412226844578981
step: 820, loss: 0.004154223948717117
step: 830, loss: 0.016262320801615715
step: 840, loss: 0.06396647542715073
step: 850, loss: 0.029566215351223946
step: 860, loss: 0.21109463274478912
step: 870, loss: 0.031614210456609726
step: 880, loss: 0.0032281845342367887
step: 890, loss: 0.027825869619846344
step: 900, loss: 0.011933247558772564
step: 910, loss: 0.0004942824598401785
step: 920, loss: 0.03364318609237671
step: 930, loss: 0.09383340179920197
step: 940, loss: 0.06027506664395332
step: 950, loss: 0.142470121383667
step: 960, loss: 0.04133076220750809
step: 970, loss: 0.03804803639650345
epoch 15: dev_f1=0.9335167354424576, f1=0.9303595812471552, best_f1=0.9367319071461084
step: 0, loss: 0.028077611699700356
step: 10, loss: 0.011353131383657455
step: 20, loss: 0.022771047428250313
step: 30, loss: 0.06440363824367523
step: 40, loss: 0.04887944832444191
step: 50, loss: 0.020374229177832603
step: 60, loss: 0.009295023046433926
step: 70, loss: 0.0807093158364296
step: 80, loss: 0.001298328279517591
step: 90, loss: 0.08722162246704102
step: 100, loss: 1.9105567844235338e-05
step: 110, loss: 0.020218834280967712
step: 120, loss: 0.10864757746458054
step: 130, loss: 0.01982640102505684
step: 140, loss: 0.04874229058623314
step: 150, loss: 0.07697872817516327
step: 160, loss: 0.00010404098429717124
step: 170, loss: 0.038950446993112564
step: 180, loss: 0.06412097811698914
step: 190, loss: 0.003800520673394203
step: 200, loss: 0.021322891116142273
step: 210, loss: 0.002441088669002056
step: 220, loss: 0.06946888566017151
step: 230, loss: 0.04086979478597641
step: 240, loss: 0.032411329448223114
step: 250, loss: 0.028864216059446335
step: 260, loss: 0.0161205492913723
step: 270, loss: 0.00418813806027174
step: 280, loss: 0.06933806091547012
step: 290, loss: 0.025670690461993217
step: 300, loss: 0.041960060596466064
step: 310, loss: 0.03402801230549812
step: 320, loss: 0.039340998977422714
step: 330, loss: 0.005527704954147339
step: 340, loss: 0.055224671959877014
step: 350, loss: 0.03223514184355736
step: 360, loss: 0.04035034775733948
step: 370, loss: 0.031113876029849052
step: 380, loss: 0.03636925294995308
step: 390, loss: 0.005853599403053522
step: 400, loss: 0.027115562930703163
step: 410, loss: 0.023220732808113098
step: 420, loss: 0.012369327247142792
step: 430, loss: 0.010307680815458298
step: 440, loss: 0.023120258003473282
step: 450, loss: 0.018652938306331635
step: 460, loss: 0.004013848025351763
step: 470, loss: 0.017257094383239746
step: 480, loss: 0.006036497186869383
step: 490, loss: 0.00016790333029348403
step: 500, loss: 0.021659361198544502
step: 510, loss: 0.01223977841436863
step: 520, loss: 0.04914889484643936
step: 530, loss: 0.02091141603887081
step: 540, loss: 0.019236570224165916
step: 550, loss: 0.03567264601588249
step: 560, loss: 0.03006196767091751
step: 570, loss: 0.00034186613629572093
step: 580, loss: 0.0637105405330658
step: 590, loss: 0.0008584409952163696
step: 600, loss: 0.00604872964322567
step: 610, loss: 0.031232023611664772
step: 620, loss: 0.03142170235514641
step: 630, loss: 0.03841905668377876
step: 640, loss: 0.02604805864393711
step: 650, loss: 0.07978089898824692
step: 660, loss: 0.06190987303853035
step: 670, loss: 0.078858882188797
step: 680, loss: 0.018883083015680313
step: 690, loss: 0.007521209307014942
step: 700, loss: 0.0008646603091619909
step: 710, loss: 0.015824778005480766
step: 720, loss: 0.038445886224508286
step: 730, loss: 0.05453546345233917
step: 740, loss: 0.056545477360486984
step: 750, loss: 0.028253724798560143
step: 760, loss: 0.03857966512441635
step: 770, loss: 0.0008004947449080646
step: 780, loss: 0.020457671955227852
step: 790, loss: 0.012719761580228806
step: 800, loss: 0.01921386644244194
step: 810, loss: 0.05531845614314079
step: 820, loss: 1.8054864995065145e-05
step: 830, loss: 0.03646548464894295
step: 840, loss: 0.01851441152393818
step: 850, loss: 0.016288163140416145
step: 860, loss: 0.019883712753653526
step: 870, loss: 0.06484606862068176
step: 880, loss: 4.6411507355514914e-05
step: 890, loss: 0.07182244956493378
step: 900, loss: 0.0671042948961258
step: 910, loss: 0.044532835483551025
step: 920, loss: 0.026758095249533653
step: 930, loss: 0.0029556776862591505
step: 940, loss: 0.026434754952788353
step: 950, loss: 0.00010721559374360368
step: 960, loss: 0.025612547993659973
step: 970, loss: 0.07092436403036118
epoch 16: dev_f1=0.9311294765840221, f1=0.9297197978870005, best_f1=0.9367319071461084
step: 0, loss: 6.348524038912728e-05
step: 10, loss: 0.043931446969509125
step: 20, loss: 0.04027243331074715
step: 30, loss: 0.08284476399421692
step: 40, loss: 0.025871707126498222
step: 50, loss: 0.0381266325712204
step: 60, loss: 0.01826709695160389
step: 70, loss: 0.00010955808829749003
step: 80, loss: 0.0007940715877339244
step: 90, loss: 0.017379391938447952
step: 100, loss: 0.00010592821490718052
step: 110, loss: 0.020479513332247734
step: 120, loss: 0.028556622564792633
step: 130, loss: 0.04378454387187958
step: 140, loss: 0.020092401653528214
step: 150, loss: 0.039628926664590836
step: 160, loss: 1.4527904568240047e-05
step: 170, loss: 0.0040580411441624165
step: 180, loss: 0.04027491807937622
step: 190, loss: 0.04035203903913498
step: 200, loss: 0.027536172419786453
step: 210, loss: 0.0013330543879419565
step: 220, loss: 0.00016446517838630825
step: 230, loss: 0.06675754487514496
step: 240, loss: 0.047877807170152664
step: 250, loss: 0.02369464933872223
step: 260, loss: 0.1189909502863884
step: 270, loss: 0.02413085661828518
step: 280, loss: 0.020317934453487396
step: 290, loss: 9.531445539323613e-05
step: 300, loss: 0.002413758309558034
step: 310, loss: 0.0590035542845726
step: 320, loss: 0.04451236128807068
step: 330, loss: 0.06123564764857292
step: 340, loss: 0.04017329216003418
step: 350, loss: 0.00029672260279767215
step: 360, loss: 0.0699508860707283
step: 370, loss: 0.08894393593072891
step: 380, loss: 0.00029179707053117454
step: 390, loss: 0.06403816491365433
step: 400, loss: 0.0068047186359763145
step: 410, loss: 0.038233719766139984
step: 420, loss: 0.08537030220031738
step: 430, loss: 0.05307323485612869
step: 440, loss: 0.04434167221188545
step: 450, loss: 0.05493458732962608
step: 460, loss: 0.023025762289762497
step: 470, loss: 0.05408461019396782
step: 480, loss: 6.394679803634062e-05
step: 490, loss: 0.07771033048629761
step: 500, loss: 0.07133947312831879
step: 510, loss: 0.07733365148305893
step: 520, loss: 0.02497355453670025
step: 530, loss: 0.0677812322974205
step: 540, loss: 0.01688012294471264
step: 550, loss: 0.02606210485100746
step: 560, loss: 0.02599051222205162
step: 570, loss: 0.03034202568233013
step: 580, loss: 0.02266962267458439
step: 590, loss: 0.01020948775112629
step: 600, loss: 0.016085894778370857
step: 610, loss: 0.01995776779949665
step: 620, loss: 3.345524601172656e-05
step: 630, loss: 0.08177731186151505
step: 640, loss: 0.09202022105455399
step: 650, loss: 0.027203360572457314
step: 660, loss: 0.02432123012840748
step: 670, loss: 0.021582849323749542
step: 680, loss: 7.983115210663527e-05
step: 690, loss: 2.5050117983482778e-05
step: 700, loss: 0.04547087475657463
step: 710, loss: 0.021801399067044258
step: 720, loss: 0.020435255020856857
step: 730, loss: 0.02132522687315941
step: 740, loss: 0.027921874076128006
step: 750, loss: 0.021606091409921646
step: 760, loss: 0.001334529952146113
step: 770, loss: 0.0001907632249640301
step: 780, loss: 0.00020454442710615695
step: 790, loss: 0.03116370365023613
step: 800, loss: 0.06308063864707947
step: 810, loss: 2.6025911211036146e-05
step: 820, loss: 0.06011570990085602
step: 830, loss: 0.03927936777472496
step: 840, loss: 0.04722899571061134
step: 850, loss: 0.05518123134970665
step: 860, loss: 3.281514727859758e-05
step: 870, loss: 0.01809438318014145
step: 880, loss: 0.03412330150604248
step: 890, loss: 0.046965114772319794
step: 900, loss: 0.04715072363615036
step: 910, loss: 0.049531884491443634
step: 920, loss: 0.0692390576004982
step: 930, loss: 0.042470674961805344
step: 940, loss: 0.032380953431129456
step: 950, loss: 0.03130738437175751
step: 960, loss: 0.0013947597471997142
step: 970, loss: 0.04784480109810829
epoch 17: dev_f1=0.9330275229357798, f1=0.9340054995417048, best_f1=0.9367319071461084
step: 0, loss: 0.018409181386232376
step: 10, loss: 0.06315609067678452
step: 20, loss: 0.0658755749464035
step: 30, loss: 4.545810224954039e-05
step: 40, loss: 0.054992057383060455
step: 50, loss: 0.026978064328432083
step: 60, loss: 0.04389107599854469
step: 70, loss: 0.0037588386330753565
step: 80, loss: 0.02563190460205078
step: 90, loss: 0.002303337911143899
step: 100, loss: 0.06504486501216888
step: 110, loss: 0.035803116858005524
step: 120, loss: 0.023082485422492027
step: 130, loss: 1.7023712644004263e-05
step: 140, loss: 0.02644789032638073
step: 150, loss: 0.013218449428677559
step: 160, loss: 0.021236423403024673
step: 170, loss: 0.033380549401044846
step: 180, loss: 0.0433574914932251
step: 190, loss: 0.00512327253818512
step: 200, loss: 0.021512409672141075
step: 210, loss: 0.007254946511238813
step: 220, loss: 8.763811638345942e-05
step: 230, loss: 0.04760686308145523
step: 240, loss: 0.006646046880632639
step: 250, loss: 0.026241866871714592
step: 260, loss: 0.16968537867069244
step: 270, loss: 3.9826452848501503e-05
step: 280, loss: 0.06261390447616577
step: 290, loss: 0.015221293084323406
step: 300, loss: 0.089014433324337
step: 310, loss: 0.040777452290058136
step: 320, loss: 0.06280867010354996
step: 330, loss: 0.01941373385488987
step: 340, loss: 0.11219978332519531
step: 350, loss: 0.03092270903289318
step: 360, loss: 0.034464169293642044
step: 370, loss: 0.023628823459148407
step: 380, loss: 0.05384555831551552
step: 390, loss: 0.02062915824353695
step: 400, loss: 0.06831752508878708
step: 410, loss: 0.05283798277378082
step: 420, loss: 0.022778308019042015
step: 430, loss: 0.015044411644339561
step: 440, loss: 0.021379923447966576
step: 450, loss: 0.04330702871084213
step: 460, loss: 0.049751922488212585
step: 470, loss: 0.0735904723405838
step: 480, loss: 0.028926601633429527
step: 490, loss: 0.021848421543836594
step: 500, loss: 0.051426518708467484
step: 510, loss: 0.019558394327759743
step: 520, loss: 0.14018645882606506
step: 530, loss: 5.13536979269702e-05
step: 540, loss: 0.013204448856413364
step: 550, loss: 0.0032873901072889566
step: 560, loss: 0.037545345723629
step: 570, loss: 0.0689283087849617
step: 580, loss: 0.0591789074242115
step: 590, loss: 2.493099782441277e-05
step: 600, loss: 0.026645565405488014
step: 610, loss: 0.02940916270017624
step: 620, loss: 0.0926947072148323
step: 630, loss: 0.06971333175897598
step: 640, loss: 0.04086805507540703
step: 650, loss: 0.06398004293441772
step: 660, loss: 0.034673742949962616
step: 670, loss: 0.020110446959733963
step: 680, loss: 0.04704788699746132
step: 690, loss: 0.039211880415678024
step: 700, loss: 0.01948155276477337
step: 710, loss: 0.025256814435124397
step: 720, loss: 0.15749624371528625
step: 730, loss: 0.038380060344934464
step: 740, loss: 0.02197341062128544
step: 750, loss: 1.4781643585592974e-05
step: 760, loss: 0.013218680396676064
step: 770, loss: 0.030466657131910324
step: 780, loss: 0.020450910553336143
step: 790, loss: 0.022440694272518158
step: 800, loss: 0.016306206583976746
step: 810, loss: 0.023305945098400116
step: 820, loss: 0.02325262315571308
step: 830, loss: 0.020360101014375687
step: 840, loss: 0.0422137975692749
step: 850, loss: 0.02627089060842991
step: 860, loss: 0.021187953650951385
step: 870, loss: 8.930478361435235e-05
step: 880, loss: 0.07313811779022217
step: 890, loss: 0.06878098100423813
step: 900, loss: 0.017849572002887726
step: 910, loss: 0.019964171573519707
step: 920, loss: 0.027426138520240784
step: 930, loss: 0.00420523714274168
step: 940, loss: 0.05300860106945038
step: 950, loss: 0.05748807266354561
step: 960, loss: 0.042748309671878815
step: 970, loss: 0.03869151696562767
epoch 18: dev_f1=0.9355432780847146, f1=0.9336405529953917, best_f1=0.9367319071461084
step: 0, loss: 0.0010778941214084625
step: 10, loss: 0.01741231419146061
step: 20, loss: 0.043096207082271576
step: 30, loss: 0.008298640139400959
step: 40, loss: 4.444466685527004e-05
step: 50, loss: 0.03609542176127434
step: 60, loss: 0.0001328491634922102
step: 70, loss: 0.05028458684682846
step: 80, loss: 0.02266729064285755
step: 90, loss: 0.09713474661111832
step: 100, loss: 0.0012955780839547515
step: 110, loss: 0.02611825428903103
step: 120, loss: 0.022114712744951248
step: 130, loss: 0.02327539771795273
step: 140, loss: 0.07772701978683472
step: 150, loss: 0.050816260278224945
step: 160, loss: 0.00020818605844397098
step: 170, loss: 0.0429842546582222
step: 180, loss: 0.023137973621487617
step: 190, loss: 0.0057610501535236835
step: 200, loss: 0.021705521270632744
step: 210, loss: 0.028654038906097412
step: 220, loss: 0.048254743218421936
step: 230, loss: 2.572066296124831e-05
step: 240, loss: 9.488437353866175e-05
step: 250, loss: 0.021389419212937355
step: 260, loss: 6.069347000448033e-05
step: 270, loss: 0.044863663613796234
step: 280, loss: 0.04891924187541008
step: 290, loss: 1.6345744370482862e-05
step: 300, loss: 0.02040811814367771
step: 310, loss: 0.025594931095838547
step: 320, loss: 0.028841517865657806
step: 330, loss: 0.00025025036302395165
step: 340, loss: 0.05004381015896797
step: 350, loss: 0.046300895512104034
step: 360, loss: 0.02174823358654976
step: 370, loss: 5.5477987189078704e-05
step: 380, loss: 0.018854232504963875
step: 390, loss: 0.06346282362937927
step: 400, loss: 0.020959317684173584
step: 410, loss: 0.030421555042266846
step: 420, loss: 0.047921959310770035
step: 430, loss: 0.06138373166322708
step: 440, loss: 0.002609130460768938
step: 450, loss: 0.04699719697237015
step: 460, loss: 0.02413487806916237
step: 470, loss: 0.018223468214273453
step: 480, loss: 0.11527671664953232
step: 490, loss: 0.018867595121264458
step: 500, loss: 0.014621802605688572
step: 510, loss: 0.035746049135923386
step: 520, loss: 0.09205467253923416
step: 530, loss: 0.04629426449537277
step: 540, loss: 0.01773873344063759
step: 550, loss: 0.04725394770503044
step: 560, loss: 0.09340735524892807
step: 570, loss: 0.03710519149899483
step: 580, loss: 0.06287957727909088
step: 590, loss: 0.05618087574839592
step: 600, loss: 3.1354411476058885e-05
step: 610, loss: 2.2965046809986234e-05
step: 620, loss: 0.014290827326476574
step: 630, loss: 0.016215797513723373
step: 640, loss: 0.04222163185477257
step: 650, loss: 0.033489350229501724
step: 660, loss: 0.05975169315934181
step: 670, loss: 1.4099733562034089e-05
step: 680, loss: 0.015535114333033562
step: 690, loss: 0.044276993721723557
step: 700, loss: 0.03793353587388992
step: 710, loss: 0.01854303479194641
step: 720, loss: 0.017969323322176933
step: 730, loss: 0.05020538717508316
step: 740, loss: 0.015211929567158222
step: 750, loss: 3.638544512796216e-05
step: 760, loss: 0.01504465937614441
step: 770, loss: 0.024760672822594643
step: 780, loss: 0.002359776757657528
step: 790, loss: 0.010969521477818489
step: 800, loss: 0.00010521420335862786
step: 810, loss: 0.021783243864774704
step: 820, loss: 0.00010457662574481219
step: 830, loss: 0.04896121844649315
step: 840, loss: 0.022352563217282295
step: 850, loss: 0.07786211371421814
step: 860, loss: 0.04145502671599388
step: 870, loss: 0.00016259393305517733
step: 880, loss: 0.018776850774884224
step: 890, loss: 0.057525355368852615
step: 900, loss: 0.056688446551561356
step: 910, loss: 0.0018499414436519146
step: 920, loss: 0.0023294026032090187
step: 930, loss: 0.046245425939559937
step: 940, loss: 0.0009820465929806232
step: 950, loss: 0.06915283203125
step: 960, loss: 0.030929524451494217
step: 970, loss: 0.03767172247171402
epoch 19: dev_f1=0.9327731092436975, f1=0.9291044776119404, best_f1=0.9367319071461084
step: 0, loss: 0.015700813382864
step: 10, loss: 0.04185602813959122
step: 20, loss: 0.017392341047525406
step: 30, loss: 0.0018951629754155874
step: 40, loss: 0.09099636226892471
step: 50, loss: 0.041909512132406235
step: 60, loss: 2.202588802902028e-05
step: 70, loss: 2.0393175873323344e-05
step: 80, loss: 0.004669142421334982
step: 90, loss: 0.0213108379393816
step: 100, loss: 0.04404684528708458
step: 110, loss: 0.03832549229264259
step: 120, loss: 0.015997350215911865
step: 130, loss: 0.027994615957140923
step: 140, loss: 0.03910202905535698
step: 150, loss: 2.7978812795481645e-05
step: 160, loss: 0.00017867698625195771
step: 170, loss: 0.004564228933304548
step: 180, loss: 0.01933869533240795
step: 190, loss: 1.4282361007644795e-05
step: 200, loss: 0.01651502400636673
step: 210, loss: 0.023031288757920265
step: 220, loss: 0.015270973555743694
step: 230, loss: 0.06592926383018494
step: 240, loss: 0.015984877943992615
step: 250, loss: 3.507125802570954e-05
step: 260, loss: 0.0187078844755888
step: 270, loss: 2.390754161751829e-05
step: 280, loss: 0.04284291714429855
step: 290, loss: 0.04017546400427818
step: 300, loss: 0.027675163000822067
step: 310, loss: 0.049433160573244095
step: 320, loss: 0.01290988177061081
step: 330, loss: 0.09311725944280624
step: 340, loss: 0.031996991485357285
step: 350, loss: 0.02721703052520752
step: 360, loss: 0.018486468121409416
step: 370, loss: 0.0021749422885477543
step: 380, loss: 0.0213443823158741
step: 390, loss: 0.033166974782943726
step: 400, loss: 0.024210920557379723
step: 410, loss: 0.06197994202375412
step: 420, loss: 0.04679952934384346
step: 430, loss: 7.127370190573856e-05
step: 440, loss: 5.636864807456732e-05
step: 450, loss: 0.03679261356592178
step: 460, loss: 0.10405920445919037
step: 470, loss: 3.59319310518913e-05
step: 480, loss: 0.05299801751971245
step: 490, loss: 0.022843601182103157
step: 500, loss: 4.1497780330246314e-05
step: 510, loss: 1.7020147424773313e-05
step: 520, loss: 0.06326460093259811
step: 530, loss: 0.04445600137114525
step: 540, loss: 3.4530185075709596e-05
step: 550, loss: 0.00016442424384877086
step: 560, loss: 0.03011779859662056
step: 570, loss: 0.08420698344707489
step: 580, loss: 0.026142915710806847
step: 590, loss: 0.008928945288062096
step: 600, loss: 0.028147300705313683
step: 610, loss: 0.0020330571569502354
step: 620, loss: 0.00022038900351617485
step: 630, loss: 0.04614602029323578
step: 640, loss: 0.008108368143439293
step: 650, loss: 0.015979111194610596
step: 660, loss: 8.998218254419044e-05
step: 670, loss: 0.0216351468116045
step: 680, loss: 0.024623461067676544
step: 690, loss: 1.3637770280183759e-05
step: 700, loss: 0.03262260556221008
step: 710, loss: 0.0003732600307557732
step: 720, loss: 0.005049720406532288
step: 730, loss: 0.017581602558493614
step: 740, loss: 0.00024054375535342842
step: 750, loss: 0.038863472640514374
step: 760, loss: 4.46660524175968e-05
step: 770, loss: 0.0001229058689204976
step: 780, loss: 0.04807337373495102
step: 790, loss: 1.3823887456965167e-05
step: 800, loss: 0.05922254920005798
step: 810, loss: 1.9776793124037795e-05
step: 820, loss: 4.797580186277628e-05
step: 830, loss: 7.215190271381289e-05
step: 840, loss: 0.0228950846940279
step: 850, loss: 0.054402172565460205
step: 860, loss: 2.076392229355406e-05
step: 870, loss: 0.10452789813280106
step: 880, loss: 0.056205593049526215
step: 890, loss: 1.4792391084483825e-05
step: 900, loss: 0.030139893293380737
step: 910, loss: 0.04560475796461105
step: 920, loss: 3.946549622924067e-05
step: 930, loss: 2.095372292387765e-05
step: 940, loss: 0.039741240441799164
step: 950, loss: 0.062215033918619156
step: 960, loss: 0.06518100202083588
step: 970, loss: 0.044062066823244095
epoch 20: dev_f1=0.932274638019617, f1=0.9281716417910447, best_f1=0.9367319071461084
