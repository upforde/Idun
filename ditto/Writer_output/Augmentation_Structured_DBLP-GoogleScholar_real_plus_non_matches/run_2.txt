cuda
Device: cuda
step: 0, loss: 0.7653483152389526
step: 10, loss: 0.5040808320045471
step: 20, loss: 0.3686502277851105
step: 30, loss: 0.5431540012359619
step: 40, loss: 0.15731477737426758
step: 50, loss: 0.15318815410137177
step: 60, loss: 0.20226605236530304
step: 70, loss: 0.30204838514328003
step: 80, loss: 0.1306941956281662
step: 90, loss: 0.09186584502458572
step: 100, loss: 0.11145331710577011
step: 110, loss: 0.15166577696800232
step: 120, loss: 0.10484698414802551
step: 130, loss: 0.1317133605480194
step: 140, loss: 0.22077511250972748
step: 150, loss: 0.12455694377422333
step: 160, loss: 0.09911834448575974
step: 170, loss: 0.33756864070892334
step: 180, loss: 0.13299421966075897
step: 190, loss: 0.32375144958496094
step: 200, loss: 0.07635386288166046
step: 210, loss: 0.10243495553731918
step: 220, loss: 0.06350228190422058
step: 230, loss: 0.08672771602869034
step: 240, loss: 0.13267754018306732
step: 250, loss: 0.09429486095905304
step: 260, loss: 0.22780181467533112
step: 270, loss: 0.17275753617286682
step: 280, loss: 0.12138038128614426
step: 290, loss: 0.11099563539028168
step: 300, loss: 0.14716582000255585
step: 310, loss: 0.0775638148188591
step: 320, loss: 0.14845943450927734
step: 330, loss: 0.0660848319530487
step: 340, loss: 0.029794568195939064
step: 350, loss: 0.12259746342897415
step: 360, loss: 0.1164521798491478
step: 370, loss: 0.4896884858608246
step: 380, loss: 0.1598629206418991
step: 390, loss: 0.08962610363960266
step: 400, loss: 0.09299899637699127
step: 410, loss: 0.046726126223802567
step: 420, loss: 0.06736661493778229
step: 430, loss: 0.1331760287284851
step: 440, loss: 0.10801512002944946
step: 450, loss: 0.1466784030199051
step: 460, loss: 0.20465348660945892
step: 470, loss: 0.21533942222595215
step: 480, loss: 0.2774805724620819
step: 490, loss: 0.14108826220035553
step: 500, loss: 0.09051676094532013
step: 510, loss: 0.18961356580257416
step: 520, loss: 0.1504223793745041
step: 530, loss: 0.04647885635495186
step: 540, loss: 0.10020283609628677
step: 550, loss: 0.18393607437610626
step: 560, loss: 0.18360483646392822
step: 570, loss: 0.2017160803079605
step: 580, loss: 0.232881098985672
step: 590, loss: 0.07408031076192856
step: 600, loss: 0.14279621839523315
step: 610, loss: 0.08775267004966736
step: 620, loss: 0.12229278683662415
step: 630, loss: 0.07710916548967361
step: 640, loss: 0.051002368330955505
step: 650, loss: 0.13278570771217346
step: 660, loss: 0.13075408339500427
step: 670, loss: 0.2405841052532196
step: 680, loss: 0.09294156730175018
step: 690, loss: 0.1813914179801941
step: 700, loss: 0.20883595943450928
step: 710, loss: 0.040072157979011536
step: 720, loss: 0.031120477244257927
step: 730, loss: 0.13066479563713074
step: 740, loss: 0.12790443003177643
step: 750, loss: 0.02288256771862507
step: 760, loss: 0.07232662290334702
step: 770, loss: 0.12279776483774185
step: 780, loss: 0.09296426922082901
step: 790, loss: 0.10066980123519897
step: 800, loss: 0.03856080025434494
step: 810, loss: 0.1211114376783371
step: 820, loss: 0.06733115762472153
step: 830, loss: 0.2227899432182312
step: 840, loss: 0.0374605655670166
step: 850, loss: 0.11214979737997055
step: 860, loss: 0.015692152082920074
step: 870, loss: 0.18519805371761322
step: 880, loss: 0.025608468800783157
step: 890, loss: 0.06404104828834534
step: 900, loss: 0.04421708360314369
step: 910, loss: 0.1264539659023285
step: 920, loss: 0.18256886303424835
step: 930, loss: 0.0920819342136383
step: 940, loss: 0.05569302663207054
step: 950, loss: 0.05782528594136238
step: 960, loss: 0.05392805486917496
step: 970, loss: 0.14199239015579224
epoch 1: dev_f1=0.9189695550351288, f1=0.9202626641651033, best_f1=0.9202626641651033
step: 0, loss: 0.05433623120188713
step: 10, loss: 0.09380263835191727
step: 20, loss: 0.07675670087337494
step: 30, loss: 0.038392990827560425
step: 40, loss: 0.07799714803695679
step: 50, loss: 0.029834846034646034
step: 60, loss: 0.04034368693828583
step: 70, loss: 0.03787372633814812
step: 80, loss: 0.03688633069396019
step: 90, loss: 0.060416094958782196
step: 100, loss: 0.1951475590467453
step: 110, loss: 0.14898541569709778
step: 120, loss: 0.03746320679783821
step: 130, loss: 0.0933455377817154
step: 140, loss: 0.08400144428014755
step: 150, loss: 0.05188998207449913
step: 160, loss: 0.13392262160778046
step: 170, loss: 0.1611192673444748
step: 180, loss: 0.1254124492406845
step: 190, loss: 0.13356035947799683
step: 200, loss: 0.048754122108221054
step: 210, loss: 0.10689722001552582
step: 220, loss: 0.07470782101154327
step: 230, loss: 0.07419835776090622
step: 240, loss: 0.08489574491977692
step: 250, loss: 0.16167894005775452
step: 260, loss: 0.14859557151794434
step: 270, loss: 0.09668433666229248
step: 280, loss: 0.032048843801021576
step: 290, loss: 0.04905524104833603
step: 300, loss: 0.03450930118560791
step: 310, loss: 0.044448815286159515
step: 320, loss: 0.061854276806116104
step: 330, loss: 0.09146247804164886
step: 340, loss: 0.12028256803750992
step: 350, loss: 0.14617623388767242
step: 360, loss: 0.039567284286022186
step: 370, loss: 0.08134195953607559
step: 380, loss: 0.03460842743515968
step: 390, loss: 0.18702924251556396
step: 400, loss: 0.05052295699715614
step: 410, loss: 0.11933638155460358
step: 420, loss: 0.13774356245994568
step: 430, loss: 0.10144252330064774
step: 440, loss: 0.1610785573720932
step: 450, loss: 0.07193294912576675
step: 460, loss: 0.1169128492474556
step: 470, loss: 0.28011563420295715
step: 480, loss: 0.0679079070687294
step: 490, loss: 0.05032557249069214
step: 500, loss: 0.10222754627466202
step: 510, loss: 0.06557651609182358
step: 520, loss: 0.10252132266759872
step: 530, loss: 0.07744388282299042
step: 540, loss: 0.22944486141204834
step: 550, loss: 0.07538905739784241
step: 560, loss: 0.06910058856010437
step: 570, loss: 0.17070181667804718
step: 580, loss: 0.1102285236120224
step: 590, loss: 0.051652226597070694
step: 600, loss: 0.09999918192625046
step: 610, loss: 0.11910255998373032
step: 620, loss: 0.03742149472236633
step: 630, loss: 0.10995843261480331
step: 640, loss: 0.10014854371547699
step: 650, loss: 0.2748486399650574
step: 660, loss: 0.10786658525466919
step: 670, loss: 0.0775151178240776
step: 680, loss: 0.006467448081821203
step: 690, loss: 0.03524889424443245
step: 700, loss: 0.05409785732626915
step: 710, loss: 0.09356270730495453
step: 720, loss: 0.10941421240568161
step: 730, loss: 0.08801714330911636
step: 740, loss: 0.048140715807676315
step: 750, loss: 0.05163825675845146
step: 760, loss: 0.08122826367616653
step: 770, loss: 0.04538433253765106
step: 780, loss: 0.10069277882575989
step: 790, loss: 0.1305999755859375
step: 800, loss: 0.08394347131252289
step: 810, loss: 0.16298264265060425
step: 820, loss: 0.1673821657896042
step: 830, loss: 0.0313386432826519
step: 840, loss: 0.13421325385570526
step: 850, loss: 0.022344008088111877
step: 860, loss: 0.16545957326889038
step: 870, loss: 0.10670798271894455
step: 880, loss: 0.018686790019273758
step: 890, loss: 0.20196740329265594
step: 900, loss: 0.01950787380337715
step: 910, loss: 0.13482174277305603
step: 920, loss: 0.03313881531357765
step: 930, loss: 0.10469075292348862
step: 940, loss: 0.05816973000764847
step: 950, loss: 0.10786885768175125
step: 960, loss: 0.03957503288984299
step: 970, loss: 0.06170055270195007
epoch 2: dev_f1=0.9267831837505905, f1=0.9314553990610329, best_f1=0.9314553990610329
step: 0, loss: 0.10277676582336426
step: 10, loss: 0.02329850010573864
step: 20, loss: 0.10192825645208359
step: 30, loss: 0.07476101815700531
step: 40, loss: 0.09670580178499222
step: 50, loss: 0.05841924250125885
step: 60, loss: 0.0907166600227356
step: 70, loss: 0.16688162088394165
step: 80, loss: 0.01688644289970398
step: 90, loss: 0.09748684614896774
step: 100, loss: 0.01070473250001669
step: 110, loss: 0.17780852317810059
step: 120, loss: 0.08901088684797287
step: 130, loss: 0.10022177547216415
step: 140, loss: 0.22396765649318695
step: 150, loss: 0.06306476891040802
step: 160, loss: 0.11467093974351883
step: 170, loss: 0.05065927654504776
step: 180, loss: 0.10268104821443558
step: 190, loss: 0.07926739007234573
step: 200, loss: 0.06650504469871521
step: 210, loss: 0.016859492287039757
step: 220, loss: 0.0379951186478138
step: 230, loss: 0.06572099030017853
step: 240, loss: 0.023465922102332115
step: 250, loss: 0.03289570286870003
step: 260, loss: 0.1034078299999237
step: 270, loss: 0.21421822905540466
step: 280, loss: 0.09674211591482162
step: 290, loss: 0.08892469853162766
step: 300, loss: 0.1652471274137497
step: 310, loss: 0.041315484791994095
step: 320, loss: 0.0331587940454483
step: 330, loss: 0.19516323506832123
step: 340, loss: 0.04693470895290375
step: 350, loss: 0.05072518810629845
step: 360, loss: 0.14085450768470764
step: 370, loss: 0.12222260981798172
step: 380, loss: 0.2136022001504898
step: 390, loss: 0.0542629100382328
step: 400, loss: 0.17900292575359344
step: 410, loss: 0.04898085072636604
step: 420, loss: 0.15452487766742706
step: 430, loss: 0.15153588354587555
step: 440, loss: 0.10920591652393341
step: 450, loss: 0.18903154134750366
step: 460, loss: 0.06438267230987549
step: 470, loss: 0.08086974918842316
step: 480, loss: 0.050302065908908844
step: 490, loss: 0.03719768300652504
step: 500, loss: 0.03632371872663498
step: 510, loss: 0.06595408916473389
step: 520, loss: 0.10432368516921997
step: 530, loss: 0.07540646940469742
step: 540, loss: 0.11822784692049026
step: 550, loss: 0.1618800163269043
step: 560, loss: 0.17367200553417206
step: 570, loss: 0.09821034222841263
step: 580, loss: 0.08912011981010437
step: 590, loss: 0.04209371656179428
step: 600, loss: 0.07548288255929947
step: 610, loss: 0.08069781959056854
step: 620, loss: 0.2139206975698471
step: 630, loss: 0.06928517669439316
step: 640, loss: 0.03826192393898964
step: 650, loss: 0.14517246186733246
step: 660, loss: 0.12280600517988205
step: 670, loss: 0.20101532340049744
step: 680, loss: 0.08099865913391113
step: 690, loss: 0.07752451300621033
step: 700, loss: 0.06065177172422409
step: 710, loss: 0.0373181477189064
step: 720, loss: 0.022644735872745514
step: 730, loss: 0.08284953981637955
step: 740, loss: 0.03779112547636032
step: 750, loss: 0.0948263630270958
step: 760, loss: 0.11916697025299072
step: 770, loss: 0.08084169030189514
step: 780, loss: 0.023287208750844002
step: 790, loss: 0.2514372766017914
step: 800, loss: 0.05406556278467178
step: 810, loss: 0.17702212929725647
step: 820, loss: 0.11994218826293945
step: 830, loss: 0.043071117252111435
step: 840, loss: 0.09148640185594559
step: 850, loss: 0.01681150682270527
step: 860, loss: 0.08387615531682968
step: 870, loss: 0.08582491427659988
step: 880, loss: 0.02738247811794281
step: 890, loss: 0.10997551679611206
step: 900, loss: 0.2794824242591858
step: 910, loss: 0.02060607261955738
step: 920, loss: 0.1770108938217163
step: 930, loss: 0.19801221787929535
step: 940, loss: 0.09121619164943695
step: 950, loss: 0.08970009535551071
step: 960, loss: 0.08280953019857407
step: 970, loss: 0.020258689299225807
epoch 3: dev_f1=0.923581809657759, f1=0.9271028037383178, best_f1=0.9314553990610329
step: 0, loss: 0.14876239001750946
step: 10, loss: 0.17736615240573883
step: 20, loss: 0.12635400891304016
step: 30, loss: 0.03837136551737785
step: 40, loss: 0.014208128675818443
step: 50, loss: 0.08665163069963455
step: 60, loss: 0.011534313671290874
step: 70, loss: 0.08291523158550262
step: 80, loss: 0.09486494958400726
step: 90, loss: 0.06868701428174973
step: 100, loss: 0.14431744813919067
step: 110, loss: 0.1808483600616455
step: 120, loss: 0.2158830314874649
step: 130, loss: 0.03706402704119682
step: 140, loss: 0.2094631940126419
step: 150, loss: 0.08207529038190842
step: 160, loss: 0.027742646634578705
step: 170, loss: 0.1282438486814499
step: 180, loss: 0.09553426504135132
step: 190, loss: 0.08750061690807343
step: 200, loss: 0.05308050662279129
step: 210, loss: 0.038286011666059494
step: 220, loss: 0.044440656900405884
step: 230, loss: 0.04228784888982773
step: 240, loss: 0.07611659914255142
step: 250, loss: 0.021435491740703583
step: 260, loss: 0.0780661404132843
step: 270, loss: 0.011024071834981441
step: 280, loss: 0.18259036540985107
step: 290, loss: 0.1486683189868927
step: 300, loss: 0.011346128769218922
step: 310, loss: 0.12785980105400085
step: 320, loss: 0.07481160759925842
step: 330, loss: 0.11613361537456512
step: 340, loss: 0.14052535593509674
step: 350, loss: 0.14086578786373138
step: 360, loss: 0.08206119388341904
step: 370, loss: 0.11757044494152069
step: 380, loss: 0.042663898319005966
step: 390, loss: 0.03388721123337746
step: 400, loss: 0.06384256482124329
step: 410, loss: 0.017124401405453682
step: 420, loss: 0.032688360661268234
step: 430, loss: 0.15526603162288666
step: 440, loss: 0.22481469810009003
step: 450, loss: 0.02670382149517536
step: 460, loss: 0.017079919576644897
step: 470, loss: 0.055344630032777786
step: 480, loss: 0.12489651888608932
step: 490, loss: 0.09212599694728851
step: 500, loss: 0.15166375041007996
step: 510, loss: 0.11496187746524811
step: 520, loss: 0.08891613781452179
step: 530, loss: 0.04611092433333397
step: 540, loss: 0.02304251864552498
step: 550, loss: 0.021680349484086037
step: 560, loss: 0.17064332962036133
step: 570, loss: 0.06289731711149216
step: 580, loss: 0.0921076238155365
step: 590, loss: 0.023178739473223686
step: 600, loss: 0.1388045698404312
step: 610, loss: 0.1580655425786972
step: 620, loss: 0.0722958892583847
step: 630, loss: 0.0618622787296772
step: 640, loss: 0.11439398676156998
step: 650, loss: 0.11676109582185745
step: 660, loss: 0.01210363581776619
step: 670, loss: 0.1688850373029709
step: 680, loss: 0.07250840216875076
step: 690, loss: 0.09286870807409286
step: 700, loss: 0.06097904220223427
step: 710, loss: 0.03140268102288246
step: 720, loss: 0.14755848050117493
step: 730, loss: 0.08915788680315018
step: 740, loss: 0.04997203126549721
step: 750, loss: 0.014017339795827866
step: 760, loss: 0.08946125209331512
step: 770, loss: 0.06047141179442406
step: 780, loss: 0.16363748908042908
step: 790, loss: 0.10511579364538193
step: 800, loss: 0.18572492897510529
step: 810, loss: 0.13050474226474762
step: 820, loss: 0.031121615320444107
step: 830, loss: 0.03315003216266632
step: 840, loss: 0.17542177438735962
step: 850, loss: 0.0700545385479927
step: 860, loss: 0.16489501297473907
step: 870, loss: 0.07655990123748779
step: 880, loss: 0.05429418757557869
step: 890, loss: 0.08356498181819916
step: 900, loss: 0.2033235728740692
step: 910, loss: 0.07245667278766632
step: 920, loss: 0.0385700985789299
step: 930, loss: 0.03822408616542816
step: 940, loss: 0.10869170725345612
step: 950, loss: 0.09297996759414673
step: 960, loss: 0.02315940521657467
step: 970, loss: 0.09519533067941666
epoch 4: dev_f1=0.9255514705882354, f1=0.928505957836847, best_f1=0.9314553990610329
step: 0, loss: 0.08092577010393143
step: 10, loss: 0.1379963457584381
step: 20, loss: 0.08314426243305206
step: 30, loss: 0.013423062860965729
step: 40, loss: 0.05252433195710182
step: 50, loss: 0.017571434378623962
step: 60, loss: 0.03825705870985985
step: 70, loss: 0.03806189447641373
step: 80, loss: 0.15904316306114197
step: 90, loss: 0.075562983751297
step: 100, loss: 0.014200981706380844
step: 110, loss: 0.13435521721839905
step: 120, loss: 0.07475697994232178
step: 130, loss: 0.03068271465599537
step: 140, loss: 0.11799807101488113
step: 150, loss: 0.056877195835113525
step: 160, loss: 0.05532296746969223
step: 170, loss: 0.04528990387916565
step: 180, loss: 0.04193144664168358
step: 190, loss: 0.022242804989218712
step: 200, loss: 0.06758671998977661
step: 210, loss: 0.04858867824077606
step: 220, loss: 0.0498567558825016
step: 230, loss: 0.02075061947107315
step: 240, loss: 0.021524012088775635
step: 250, loss: 0.16140589118003845
step: 260, loss: 0.10267537087202072
step: 270, loss: 0.07534575462341309
step: 280, loss: 0.0732736885547638
step: 290, loss: 0.0988604724407196
step: 300, loss: 0.14198344945907593
step: 310, loss: 0.1817994862794876
step: 320, loss: 0.22994494438171387
step: 330, loss: 0.12849067151546478
step: 340, loss: 0.029347898438572884
step: 350, loss: 0.0861559510231018
step: 360, loss: 0.08483314514160156
step: 370, loss: 0.09026184678077698
step: 380, loss: 0.038257092237472534
step: 390, loss: 0.004270739387720823
step: 400, loss: 0.11052880436182022
step: 410, loss: 0.2089834213256836
step: 420, loss: 0.011398096568882465
step: 430, loss: 0.1532662957906723
step: 440, loss: 0.009954898618161678
step: 450, loss: 0.13892212510108948
step: 460, loss: 0.017959704622626305
step: 470, loss: 0.11268976330757141
step: 480, loss: 0.08546055853366852
step: 490, loss: 0.03061668574810028
step: 500, loss: 0.10515905171632767
step: 510, loss: 0.20144282281398773
step: 520, loss: 0.09424836933612823
step: 530, loss: 0.08531513065099716
step: 540, loss: 0.019174886867403984
step: 550, loss: 0.014419939368963242
step: 560, loss: 0.054990004748106
step: 570, loss: 0.0692354291677475
step: 580, loss: 0.07998348027467728
step: 590, loss: 0.05948401242494583
step: 600, loss: 0.08182679116725922
step: 610, loss: 0.10149097442626953
step: 620, loss: 0.00649487366899848
step: 630, loss: 0.07110816240310669
step: 640, loss: 0.03548978641629219
step: 650, loss: 0.07927509397268295
step: 660, loss: 0.05534619092941284
step: 670, loss: 0.07046446949243546
step: 680, loss: 0.00908515602350235
step: 690, loss: 0.01824360527098179
step: 700, loss: 0.06989530473947525
step: 710, loss: 0.17428049445152283
step: 720, loss: 0.05494830012321472
step: 730, loss: 0.06716922670602798
step: 740, loss: 0.017121996730566025
step: 750, loss: 0.12768210470676422
step: 760, loss: 0.0050582922995090485
step: 770, loss: 0.11211805045604706
step: 780, loss: 0.01313838828355074
step: 790, loss: 0.04838692024350166
step: 800, loss: 0.05101003870368004
step: 810, loss: 0.07397624850273132
step: 820, loss: 0.15682452917099
step: 830, loss: 0.09078200161457062
step: 840, loss: 0.03252030536532402
step: 850, loss: 0.005695635452866554
step: 860, loss: 0.08931948989629745
step: 870, loss: 0.012878947891294956
step: 880, loss: 0.051273688673973083
step: 890, loss: 0.07473265379667282
step: 900, loss: 0.2114982008934021
step: 910, loss: 0.0640522763133049
step: 920, loss: 0.09648020565509796
step: 930, loss: 0.12679721415042877
step: 940, loss: 0.138529434800148
step: 950, loss: 0.01105007529258728
step: 960, loss: 0.0001670825877226889
step: 970, loss: 0.10913313180208206
epoch 5: dev_f1=0.9345351043643263, f1=0.9304511278195489, best_f1=0.9304511278195489
step: 0, loss: 0.05589601397514343
step: 10, loss: 0.04232281073927879
step: 20, loss: 0.11723235249519348
step: 30, loss: 0.1531556248664856
step: 40, loss: 0.006826081313192844
step: 50, loss: 0.08404302597045898
step: 60, loss: 0.11180949956178665
step: 70, loss: 0.03206673264503479
step: 80, loss: 0.027092698961496353
step: 90, loss: 0.1562032699584961
step: 100, loss: 0.010096457786858082
step: 110, loss: 0.08771327137947083
step: 120, loss: 0.10566052794456482
step: 130, loss: 0.11334539949893951
step: 140, loss: 0.024540185928344727
step: 150, loss: 0.16242830455303192
step: 160, loss: 0.12402384728193283
step: 170, loss: 0.03265955671668053
step: 180, loss: 0.015741145238280296
step: 190, loss: 0.026576245203614235
step: 200, loss: 0.0661483108997345
step: 210, loss: 0.021132856607437134
step: 220, loss: 0.0746898204088211
step: 230, loss: 0.0428079292178154
step: 240, loss: 0.04063103348016739
step: 250, loss: 0.1006968766450882
step: 260, loss: 0.007218712475150824
step: 270, loss: 0.05751682072877884
step: 280, loss: 0.10536915808916092
step: 290, loss: 0.01759561337530613
step: 300, loss: 0.13513968884944916
step: 310, loss: 0.20651638507843018
step: 320, loss: 0.009411602281033993
step: 330, loss: 0.2673850357532501
step: 340, loss: 0.03836048021912575
step: 350, loss: 0.04584720730781555
step: 360, loss: 0.10127487033605576
step: 370, loss: 0.16183649003505707
step: 380, loss: 0.03170054405927658
step: 390, loss: 0.025188829749822617
step: 400, loss: 0.047480009496212006
step: 410, loss: 0.08285295218229294
step: 420, loss: 0.022094568237662315
step: 430, loss: 0.009563643485307693
step: 440, loss: 0.043304193764925
step: 450, loss: 0.017732374370098114
step: 460, loss: 0.035433318465948105
step: 470, loss: 0.05693163722753525
step: 480, loss: 0.08266336470842361
step: 490, loss: 0.12629763782024384
step: 500, loss: 0.02966930903494358
step: 510, loss: 0.14082342386245728
step: 520, loss: 0.028684910386800766
step: 530, loss: 0.031224729493260384
step: 540, loss: 0.03560451790690422
step: 550, loss: 0.042138054966926575
step: 560, loss: 0.08159667998552322
step: 570, loss: 0.012606999836862087
step: 580, loss: 0.036467842757701874
step: 590, loss: 0.0744936540722847
step: 600, loss: 0.04793453589081764
step: 610, loss: 0.1936919242143631
step: 620, loss: 0.05963308736681938
step: 630, loss: 0.03119063377380371
step: 640, loss: 0.02394370175898075
step: 650, loss: 0.053434692323207855
step: 660, loss: 0.16644874215126038
step: 670, loss: 0.07561689615249634
step: 680, loss: 0.042973361909389496
step: 690, loss: 0.06466381996870041
step: 700, loss: 0.08492355048656464
step: 710, loss: 0.029829159379005432
step: 720, loss: 0.07181491702795029
step: 730, loss: 0.015275480225682259
step: 740, loss: 0.07736078649759293
step: 750, loss: 0.03565387800335884
step: 760, loss: 0.171228289604187
step: 770, loss: 0.0397462323307991
step: 780, loss: 0.07927124947309494
step: 790, loss: 0.01485336385667324
step: 800, loss: 0.09414691478013992
step: 810, loss: 0.11106656491756439
step: 820, loss: 0.0758647620677948
step: 830, loss: 0.10723838955163956
step: 840, loss: 0.07287038117647171
step: 850, loss: 0.05714470520615578
step: 860, loss: 0.08775698393583298
step: 870, loss: 0.030804723501205444
step: 880, loss: 0.1018817126750946
step: 890, loss: 0.06512758880853653
step: 900, loss: 0.13851898908615112
step: 910, loss: 0.11637131869792938
step: 920, loss: 0.06952494382858276
step: 930, loss: 0.10147290676832199
step: 940, loss: 0.022585343569517136
step: 950, loss: 0.09259829670190811
step: 960, loss: 0.015371330082416534
step: 970, loss: 0.01978856325149536
epoch 6: dev_f1=0.9263157894736843, f1=0.9215328467153284, best_f1=0.9304511278195489
step: 0, loss: 0.03635489568114281
step: 10, loss: 0.028393371030688286
step: 20, loss: 0.10195546597242355
step: 30, loss: 0.04007906839251518
step: 40, loss: 0.11270613968372345
step: 50, loss: 0.04503346607089043
step: 60, loss: 0.06133125722408295
step: 70, loss: 0.013418559916317463
step: 80, loss: 0.07718148827552795
step: 90, loss: 0.07902251183986664
step: 100, loss: 0.035161834210157394
step: 110, loss: 0.13410137593746185
step: 120, loss: 0.08598130941390991
step: 130, loss: 0.006859871558845043
step: 140, loss: 0.041337285190820694
step: 150, loss: 0.005851743742823601
step: 160, loss: 0.03801420331001282
step: 170, loss: 0.05657808110117912
step: 180, loss: 0.005985252093523741
step: 190, loss: 0.09272859990596771
step: 200, loss: 0.03174811974167824
step: 210, loss: 0.04954635724425316
step: 220, loss: 0.12616580724716187
step: 230, loss: 0.09175973385572433
step: 240, loss: 0.05528915673494339
step: 250, loss: 0.007004133425652981
step: 260, loss: 0.04211469739675522
step: 270, loss: 0.05408176779747009
step: 280, loss: 0.08172538876533508
step: 290, loss: 0.02392011508345604
step: 300, loss: 0.08461466431617737
step: 310, loss: 0.1429971307516098
step: 320, loss: 0.09337908774614334
step: 330, loss: 0.0059804110787808895
step: 340, loss: 0.14260858297348022
step: 350, loss: 0.09884727001190186
step: 360, loss: 0.055048178881406784
step: 370, loss: 0.05940431356430054
step: 380, loss: 0.11619178205728531
step: 390, loss: 0.0053402129560709
step: 400, loss: 0.11720983684062958
step: 410, loss: 0.08116608113050461
step: 420, loss: 0.09148147702217102
step: 430, loss: 0.07260402292013168
step: 440, loss: 0.19490905106067657
step: 450, loss: 0.20625752210617065
step: 460, loss: 0.0758984237909317
step: 470, loss: 0.06889773160219193
step: 480, loss: 0.042397692799568176
step: 490, loss: 0.013924743980169296
step: 500, loss: 0.11165683716535568
step: 510, loss: 0.04428776726126671
step: 520, loss: 0.05871833860874176
step: 530, loss: 0.33775195479393005
step: 540, loss: 0.09299834817647934
step: 550, loss: 0.047470346093177795
step: 560, loss: 0.029740892350673676
step: 570, loss: 0.05799129232764244
step: 580, loss: 0.13561663031578064
step: 590, loss: 0.09411142021417618
step: 600, loss: 0.021596720442175865
step: 610, loss: 0.12086083739995956
step: 620, loss: 0.03816228732466698
step: 630, loss: 0.01810646615922451
step: 640, loss: 0.15328574180603027
step: 650, loss: 0.02620067074894905
step: 660, loss: 0.13650935888290405
step: 670, loss: 0.06474938988685608
step: 680, loss: 0.005939313676208258
step: 690, loss: 0.006386591587215662
step: 700, loss: 0.06200457736849785
step: 710, loss: 0.03509700670838356
step: 720, loss: 0.0044618998654186726
step: 730, loss: 0.08729932457208633
step: 740, loss: 0.03417511284351349
step: 750, loss: 0.029453348368406296
step: 760, loss: 0.026333721354603767
step: 770, loss: 0.06804034113883972
step: 780, loss: 0.076227106153965
step: 790, loss: 0.04172462597489357
step: 800, loss: 0.029776887968182564
step: 810, loss: 0.014575057663023472
step: 820, loss: 0.0596596784889698
step: 830, loss: 0.1077122688293457
step: 840, loss: 0.0039294203743338585
step: 850, loss: 0.014036880806088448
step: 860, loss: 0.1015828475356102
step: 870, loss: 0.1416672170162201
step: 880, loss: 0.030497360974550247
step: 890, loss: 0.029631346464157104
step: 900, loss: 0.05014536529779434
step: 910, loss: 0.11670788377523422
step: 920, loss: 0.10394822061061859
step: 930, loss: 0.016207894310355186
step: 940, loss: 0.0969434306025505
step: 950, loss: 0.06399580091238022
step: 960, loss: 0.06813987344503403
step: 970, loss: 0.11277323216199875
epoch 7: dev_f1=0.9321723189734189, f1=0.9289967934035731, best_f1=0.9304511278195489
step: 0, loss: 0.01173620205372572
step: 10, loss: 0.048901837319135666
step: 20, loss: 0.13833922147750854
step: 30, loss: 0.016455847769975662
step: 40, loss: 0.1300589144229889
step: 50, loss: 0.07117685675621033
step: 60, loss: 0.005285505671054125
step: 70, loss: 0.08684499561786652
step: 80, loss: 0.0962742269039154
step: 90, loss: 0.08294284343719482
step: 100, loss: 0.04124247282743454
step: 110, loss: 0.00037462517502717674
step: 120, loss: 0.01524029765278101
step: 130, loss: 0.09319473803043365
step: 140, loss: 0.042595166712999344
step: 150, loss: 0.0169544517993927
step: 160, loss: 0.058052822947502136
step: 170, loss: 0.016594847664237022
step: 180, loss: 0.02611622028052807
step: 190, loss: 0.029011636972427368
step: 200, loss: 0.004764909856021404
step: 210, loss: 0.006204273551702499
step: 220, loss: 0.03352679684758186
step: 230, loss: 0.042680710554122925
step: 240, loss: 0.013591348193585873
step: 250, loss: 0.09447678923606873
step: 260, loss: 0.035376112908124924
step: 270, loss: 0.08252623677253723
step: 280, loss: 0.04977981373667717
step: 290, loss: 0.011204911395907402
step: 300, loss: 0.014058365486562252
step: 310, loss: 0.004465864039957523
step: 320, loss: 0.09304327517747879
step: 330, loss: 0.044744040817022324
step: 340, loss: 0.0994553193449974
step: 350, loss: 0.003966489806771278
step: 360, loss: 0.0100583890452981
step: 370, loss: 0.04132619872689247
step: 380, loss: 0.05737670511007309
step: 390, loss: 0.025836395099759102
step: 400, loss: 0.09120171517133713
step: 410, loss: 0.13958244025707245
step: 420, loss: 0.047310132533311844
step: 430, loss: 0.07359079271554947
step: 440, loss: 0.05894673988223076
step: 450, loss: 0.0567975677549839
step: 460, loss: 0.07812465727329254
step: 470, loss: 0.07612088322639465
step: 480, loss: 0.032851628959178925
step: 490, loss: 0.06432313472032547
step: 500, loss: 0.006235181353986263
step: 510, loss: 0.017538398504257202
step: 520, loss: 0.0749746561050415
step: 530, loss: 0.09079782664775848
step: 540, loss: 0.1350187361240387
step: 550, loss: 0.040591321885585785
step: 560, loss: 0.038656964898109436
step: 570, loss: 0.07973718643188477
step: 580, loss: 0.01665051095187664
step: 590, loss: 0.027178054675459862
step: 600, loss: 0.12664403021335602
step: 610, loss: 0.08206082135438919
step: 620, loss: 0.10370496660470963
step: 630, loss: 0.16799119114875793
step: 640, loss: 0.04840225726366043
step: 650, loss: 0.03727944195270538
step: 660, loss: 0.005882187280803919
step: 670, loss: 0.020078470930457115
step: 680, loss: 0.0453820526599884
step: 690, loss: 0.016717415302991867
step: 700, loss: 0.18609869480133057
step: 710, loss: 0.011345929466187954
step: 720, loss: 0.016199354082345963
step: 730, loss: 0.13598158955574036
step: 740, loss: 0.06958862394094467
step: 750, loss: 0.07802706211805344
step: 760, loss: 0.06069241836667061
step: 770, loss: 0.12102831155061722
step: 780, loss: 0.06461913883686066
step: 790, loss: 0.05688326060771942
step: 800, loss: 0.09251171350479126
step: 810, loss: 0.09822454303503036
step: 820, loss: 0.020621737465262413
step: 830, loss: 0.15084265172481537
step: 840, loss: 0.0791073888540268
step: 850, loss: 0.07969262450933456
step: 860, loss: 0.11358007043600082
step: 870, loss: 0.0487392321228981
step: 880, loss: 0.029371732845902443
step: 890, loss: 0.051544710993766785
step: 900, loss: 0.13213452696800232
step: 910, loss: 0.06765685230493546
step: 920, loss: 0.07448528707027435
step: 930, loss: 0.16261179745197296
step: 940, loss: 0.09708256274461746
step: 950, loss: 0.03216877952218056
step: 960, loss: 0.008547229692339897
step: 970, loss: 0.07034358382225037
epoch 8: dev_f1=0.9287335451656831, f1=0.924187725631769, best_f1=0.9304511278195489
step: 0, loss: 0.02779950574040413
step: 10, loss: 0.03350546583533287
step: 20, loss: 0.026952633634209633
step: 30, loss: 0.02580227144062519
step: 40, loss: 0.01317697111517191
step: 50, loss: 0.016669293865561485
step: 60, loss: 0.10325632989406586
step: 70, loss: 0.02587156556546688
step: 80, loss: 0.07479135692119598
step: 90, loss: 0.01731218583881855
step: 100, loss: 0.094091035425663
step: 110, loss: 0.0007566531421616673
step: 120, loss: 0.006904949899762869
step: 130, loss: 0.03871713951230049
step: 140, loss: 0.03489936888217926
step: 150, loss: 0.050646957010030746
step: 160, loss: 0.023982539772987366
step: 170, loss: 0.016141073778271675
step: 180, loss: 0.01107720285654068
step: 190, loss: 0.1620965152978897
step: 200, loss: 0.00910084880888462
step: 210, loss: 0.07460378855466843
step: 220, loss: 0.07478004693984985
step: 230, loss: 0.09787178039550781
step: 240, loss: 0.004967778921127319
step: 250, loss: 0.050847701728343964
step: 260, loss: 0.011160017922520638
step: 270, loss: 0.004762741737067699
step: 280, loss: 0.07952336966991425
step: 290, loss: 0.06981279700994492
step: 300, loss: 0.025711145251989365
step: 310, loss: 0.010794474743306637
step: 320, loss: 0.024061456322669983
step: 330, loss: 0.09220244735479355
step: 340, loss: 0.06300346553325653
step: 350, loss: 0.15278592705726624
step: 360, loss: 0.09536220878362656
step: 370, loss: 0.0047216895036399364
step: 380, loss: 0.050765834748744965
step: 390, loss: 0.08689337968826294
step: 400, loss: 0.025621755048632622
step: 410, loss: 0.00020089876488782465
step: 420, loss: 0.09150448441505432
step: 430, loss: 0.11382552981376648
step: 440, loss: 0.022551413625478745
step: 450, loss: 0.07831401377916336
step: 460, loss: 0.06894011795520782
step: 470, loss: 0.08480369299650192
step: 480, loss: 0.06820861250162125
step: 490, loss: 0.024682939052581787
step: 500, loss: 0.14429539442062378
step: 510, loss: 0.01574103720486164
step: 520, loss: 0.06624536961317062
step: 530, loss: 0.05797739699482918
step: 540, loss: 0.039240408688783646
step: 550, loss: 0.018462881445884705
step: 560, loss: 0.04438294470310211
step: 570, loss: 0.07302624732255936
step: 580, loss: 0.07061455398797989
step: 590, loss: 0.16935956478118896
step: 600, loss: 0.11916287988424301
step: 610, loss: 0.024456260725855827
step: 620, loss: 0.023575596511363983
step: 630, loss: 0.08028747141361237
step: 640, loss: 0.05755377560853958
step: 650, loss: 0.13677212595939636
step: 660, loss: 0.06896787136793137
step: 670, loss: 0.04050058871507645
step: 680, loss: 0.08172601461410522
step: 690, loss: 0.053957048803567886
step: 700, loss: 0.08599060028791428
step: 710, loss: 0.06496461480855942
step: 720, loss: 0.027648691087961197
step: 730, loss: 0.06702853739261627
step: 740, loss: 0.026726452633738518
step: 750, loss: 0.030951473861932755
step: 760, loss: 0.048549529165029526
step: 770, loss: 0.045952796936035156
step: 780, loss: 0.06280466914176941
step: 790, loss: 0.07111618667840958
step: 800, loss: 0.019271131604909897
step: 810, loss: 0.017179517075419426
step: 820, loss: 0.034646015614271164
step: 830, loss: 0.08542647957801819
step: 840, loss: 0.031365152448415756
step: 850, loss: 0.04804065823554993
step: 860, loss: 0.06579333543777466
step: 870, loss: 0.02556552365422249
step: 880, loss: 0.017369594424962997
step: 890, loss: 0.0010423995554447174
step: 900, loss: 0.05108910799026489
step: 910, loss: 0.06278945505619049
step: 920, loss: 0.03271261975169182
step: 930, loss: 0.13781334459781647
step: 940, loss: 0.08637020736932755
step: 950, loss: 0.05759313702583313
step: 960, loss: 0.011862986721098423
step: 970, loss: 0.05584288015961647
epoch 9: dev_f1=0.939186099679927, f1=0.9289617486338797, best_f1=0.9289617486338797
step: 0, loss: 0.028294509276747704
step: 10, loss: 0.03607012331485748
step: 20, loss: 0.1310119479894638
step: 30, loss: 0.03857167810201645
step: 40, loss: 0.028921635821461678
step: 50, loss: 0.035006288439035416
step: 60, loss: 0.05776243656873703
step: 70, loss: 0.07543119788169861
step: 80, loss: 0.006815985310822725
step: 90, loss: 0.005762248300015926
step: 100, loss: 0.02128576673567295
step: 110, loss: 0.004296399187296629
step: 120, loss: 0.18077385425567627
step: 130, loss: 0.03579872101545334
step: 140, loss: 0.10502030700445175
step: 150, loss: 0.03477836400270462
step: 160, loss: 0.0587710402905941
step: 170, loss: 0.0435606874525547
step: 180, loss: 0.007987975142896175
step: 190, loss: 0.09867732971906662
step: 200, loss: 0.15351749956607819
step: 210, loss: 0.015897156670689583
step: 220, loss: 0.001869413536041975
step: 230, loss: 0.0946703553199768
step: 240, loss: 0.017242303118109703
step: 250, loss: 0.02649761736392975
step: 260, loss: 0.10511807352304459
step: 270, loss: 0.0050000823102891445
step: 280, loss: 0.000557843130081892
step: 290, loss: 0.2559821307659149
step: 300, loss: 0.18530632555484772
step: 310, loss: 0.09974334388971329
step: 320, loss: 0.07152977585792542
step: 330, loss: 0.06022944301366806
step: 340, loss: 0.03610935062170029
step: 350, loss: 0.0526626780629158
step: 360, loss: 0.01340626273304224
step: 370, loss: 0.028693512082099915
step: 380, loss: 0.09964060038328171
step: 390, loss: 0.06057598069310188
step: 400, loss: 0.15376845002174377
step: 410, loss: 0.08667190372943878
step: 420, loss: 0.02617063745856285
step: 430, loss: 0.009214399382472038
step: 440, loss: 0.07115865498781204
step: 450, loss: 0.049510013312101364
step: 460, loss: 0.02319680154323578
step: 470, loss: 0.05289025977253914
step: 480, loss: 0.0907590314745903
step: 490, loss: 0.09948151558637619
step: 500, loss: 0.02183789387345314
step: 510, loss: 0.06898807734251022
step: 520, loss: 0.029418155550956726
step: 530, loss: 0.14236977696418762
step: 540, loss: 0.040346063673496246
step: 550, loss: 0.030837945640087128
step: 560, loss: 0.007008770480751991
step: 570, loss: 0.07607701420783997
step: 580, loss: 0.02016003057360649
step: 590, loss: 0.01807567849755287
step: 600, loss: 0.06900540739297867
step: 610, loss: 0.10700330138206482
step: 620, loss: 0.05405708774924278
step: 630, loss: 0.010734636336565018
step: 640, loss: 0.04917623847723007
step: 650, loss: 0.024047911167144775
step: 660, loss: 0.03840530291199684
step: 670, loss: 0.02898404560983181
step: 680, loss: 0.02071664109826088
step: 690, loss: 0.01879217103123665
step: 700, loss: 0.10445889085531235
step: 710, loss: 0.08176158368587494
step: 720, loss: 0.01334169041365385
step: 730, loss: 0.05071825161576271
step: 740, loss: 0.04713813215494156
step: 750, loss: 0.052643269300460815
step: 760, loss: 0.09359294176101685
step: 770, loss: 0.09107774496078491
step: 780, loss: 0.0016617377987131476
step: 790, loss: 0.03147320821881294
step: 800, loss: 0.009366512298583984
step: 810, loss: 0.07511638104915619
step: 820, loss: 0.07581263780593872
step: 830, loss: 0.002422640100121498
step: 840, loss: 0.017708446830511093
step: 850, loss: 0.02570037543773651
step: 860, loss: 0.042263370007276535
step: 870, loss: 0.22285810112953186
step: 880, loss: 0.042918022722005844
step: 890, loss: 0.08327026665210724
step: 900, loss: 0.01685265451669693
step: 910, loss: 0.041015204042196274
step: 920, loss: 0.02346944995224476
step: 930, loss: 0.08084460347890854
step: 940, loss: 0.05977930128574371
step: 950, loss: 0.12338226288557053
step: 960, loss: 0.08477699011564255
step: 970, loss: 0.24801486730575562
epoch 10: dev_f1=0.9383842994066636, f1=0.9282470481380563, best_f1=0.9289617486338797
step: 0, loss: 0.00021901160653214902
step: 10, loss: 0.05735291913151741
step: 20, loss: 0.035471800714731216
step: 30, loss: 0.012781423516571522
step: 40, loss: 0.006944798864424229
step: 50, loss: 0.04327307641506195
step: 60, loss: 0.10570977628231049
step: 70, loss: 0.011582438834011555
step: 80, loss: 0.0014051501639187336
step: 90, loss: 0.03706131502985954
step: 100, loss: 0.06945758312940598
step: 110, loss: 0.07511969655752182
step: 120, loss: 0.06720583140850067
step: 130, loss: 0.26413023471832275
step: 140, loss: 0.013947950676083565
step: 150, loss: 0.08523377031087875
step: 160, loss: 0.010978437960147858
step: 170, loss: 0.07351526618003845
step: 180, loss: 0.05732256919145584
step: 190, loss: 0.007265785709023476
step: 200, loss: 0.02146800421178341
step: 210, loss: 0.03508774936199188
step: 220, loss: 0.08427926152944565
step: 230, loss: 0.06731870770454407
step: 240, loss: 0.002633832162246108
step: 250, loss: 0.09627804905176163
step: 260, loss: 0.05456536263227463
step: 270, loss: 0.014100974425673485
step: 280, loss: 0.0023062461987137794
step: 290, loss: 0.08712457120418549
step: 300, loss: 0.035773396492004395
step: 310, loss: 0.05623246729373932
step: 320, loss: 0.02561573125422001
step: 330, loss: 0.0013385274214670062
step: 340, loss: 0.04283718764781952
step: 350, loss: 0.11941176652908325
step: 360, loss: 0.08134062588214874
step: 370, loss: 0.05895300209522247
step: 380, loss: 0.06242968514561653
step: 390, loss: 0.010305361822247505
step: 400, loss: 0.15989506244659424
step: 410, loss: 0.05802574381232262
step: 420, loss: 0.020259929820895195
step: 430, loss: 0.13794635236263275
step: 440, loss: 0.11505996435880661
step: 450, loss: 0.0629875436425209
step: 460, loss: 0.10183433443307877
step: 470, loss: 0.004149510990828276
step: 480, loss: 0.030813205987215042
step: 490, loss: 0.00909140333533287
step: 500, loss: 0.0436023510992527
step: 510, loss: 0.04093408212065697
step: 520, loss: 0.024345818907022476
step: 530, loss: 0.0038635069504380226
step: 540, loss: 0.10440926998853683
step: 550, loss: 0.0014657764695584774
step: 560, loss: 0.08050794154405594
step: 570, loss: 0.0230509415268898
step: 580, loss: 0.0493164099752903
step: 590, loss: 0.023600954562425613
step: 600, loss: 0.035005614161491394
step: 610, loss: 0.017088280990719795
step: 620, loss: 0.08395086228847504
step: 630, loss: 0.03814273327589035
step: 640, loss: 0.03373827412724495
step: 650, loss: 0.02000608667731285
step: 660, loss: 0.12466849386692047
step: 670, loss: 0.21314767003059387
step: 680, loss: 0.03169581666588783
step: 690, loss: 0.0725630447268486
step: 700, loss: 0.004236503504216671
step: 710, loss: 0.03320649266242981
step: 720, loss: 0.002804929856210947
step: 730, loss: 0.049408212304115295
step: 740, loss: 0.04659486934542656
step: 750, loss: 0.12490958720445633
step: 760, loss: 0.017084715887904167
step: 770, loss: 0.02067660540342331
step: 780, loss: 0.023462729528546333
step: 790, loss: 0.06433875858783722
step: 800, loss: 0.10320165008306503
step: 810, loss: 0.003089665435254574
step: 820, loss: 0.10130594670772552
step: 830, loss: 0.10732771456241608
step: 840, loss: 0.03356969729065895
step: 850, loss: 0.022865386679768562
step: 860, loss: 0.05277060344815254
step: 870, loss: 0.015958337113261223
step: 880, loss: 0.11036812514066696
step: 890, loss: 0.031176667660474777
step: 900, loss: 0.013659187592566013
step: 910, loss: 0.04521871730685234
step: 920, loss: 0.07919764518737793
step: 930, loss: 0.06746037304401398
step: 940, loss: 0.06361310184001923
step: 950, loss: 0.004780294839292765
step: 960, loss: 0.07894504070281982
step: 970, loss: 0.0872153490781784
epoch 11: dev_f1=0.9338919925512105, f1=0.9262180974477957, best_f1=0.9289617486338797
step: 0, loss: 0.10107162594795227
step: 10, loss: 0.013061003759503365
step: 20, loss: 0.028186528012156487
step: 30, loss: 0.014149576425552368
step: 40, loss: 4.6830369683448225e-05
step: 50, loss: 0.005004336591809988
step: 60, loss: 0.030982311815023422
step: 70, loss: 0.007141066715121269
step: 80, loss: 0.06665109097957611
step: 90, loss: 0.068146251142025
step: 100, loss: 0.10879785567522049
step: 110, loss: 9.07664216356352e-05
step: 120, loss: 0.04140341654419899
step: 130, loss: 0.09719688445329666
step: 140, loss: 0.007183196023106575
step: 150, loss: 0.07033554464578629
step: 160, loss: 0.0585201196372509
step: 170, loss: 0.18151035904884338
step: 180, loss: 0.006449869833886623
step: 190, loss: 0.009697476401925087
step: 200, loss: 0.09279868006706238
step: 210, loss: 0.009918509982526302
step: 220, loss: 0.027242472395300865
step: 230, loss: 0.08817890286445618
step: 240, loss: 0.05456393212080002
step: 250, loss: 0.02147161215543747
step: 260, loss: 0.16123998165130615
step: 270, loss: 0.2123022973537445
step: 280, loss: 0.004071370232850313
step: 290, loss: 0.06329474598169327
step: 300, loss: 0.09810339659452438
step: 310, loss: 0.0059370361268520355
step: 320, loss: 0.010284301824867725
step: 330, loss: 0.07531068474054337
step: 340, loss: 0.018211137503385544
step: 350, loss: 0.06281649321317673
step: 360, loss: 0.0930667519569397
step: 370, loss: 0.002764791250228882
step: 380, loss: 0.010870017111301422
step: 390, loss: 0.002796055283397436
step: 400, loss: 0.00038048505666665733
step: 410, loss: 0.025812197476625443
step: 420, loss: 0.019343718886375427
step: 430, loss: 0.044515836983919144
step: 440, loss: 0.005225268192589283
step: 450, loss: 0.14455676078796387
step: 460, loss: 0.02866007201373577
step: 470, loss: 0.0485648587346077
step: 480, loss: 0.0040088011883199215
step: 490, loss: 0.11497486382722855
step: 500, loss: 0.08760040253400803
step: 510, loss: 0.015657838433980942
step: 520, loss: 0.04011613875627518
step: 530, loss: 0.026950262486934662
step: 540, loss: 0.04233754426240921
step: 550, loss: 0.0015032687224447727
step: 560, loss: 0.1123678907752037
step: 570, loss: 0.0029351075645536184
step: 580, loss: 0.052457258105278015
step: 590, loss: 0.04435863718390465
step: 600, loss: 0.012571239843964577
step: 610, loss: 0.008933876641094685
step: 620, loss: 0.10601760447025299
step: 630, loss: 0.023250017315149307
step: 640, loss: 0.059229202568531036
step: 650, loss: 0.00022558262571692467
step: 660, loss: 0.08391056209802628
step: 670, loss: 0.03818124905228615
step: 680, loss: 0.034634023904800415
step: 690, loss: 0.030055683106184006
step: 700, loss: 0.048542965203523636
step: 710, loss: 0.0014401444932445884
step: 720, loss: 0.018967170268297195
step: 730, loss: 0.08602083474397659
step: 740, loss: 0.007152324542403221
step: 750, loss: 0.010108229704201221
step: 760, loss: 0.00010673897486412898
step: 770, loss: 0.016717320308089256
step: 780, loss: 0.12144067883491516
step: 790, loss: 0.11626062542200089
step: 800, loss: 0.016201848164200783
step: 810, loss: 0.015804579481482506
step: 820, loss: 0.020509425550699234
step: 830, loss: 0.051474250853061676
step: 840, loss: 0.026960249990224838
step: 850, loss: 0.09033673256635666
step: 860, loss: 0.08034105598926544
step: 870, loss: 0.0315210297703743
step: 880, loss: 0.06503661721944809
step: 890, loss: 0.047138139605522156
step: 900, loss: 0.03311401605606079
step: 910, loss: 0.08335529267787933
step: 920, loss: 0.06734785437583923
step: 930, loss: 0.06381005793809891
step: 940, loss: 0.02065427228808403
step: 950, loss: 0.011662721633911133
step: 960, loss: 0.00039365870179608464
step: 970, loss: 0.00029908205033279955
epoch 12: dev_f1=0.9327808471454879, f1=0.9274965800273598, best_f1=0.9289617486338797
step: 0, loss: 0.00029820622876286507
step: 10, loss: 0.08899393677711487
step: 20, loss: 0.05152956396341324
step: 30, loss: 0.05320265516638756
step: 40, loss: 0.05449187383055687
step: 50, loss: 0.0844312533736229
step: 60, loss: 0.0010403502965345979
step: 70, loss: 0.010086082853376865
step: 80, loss: 0.01701912097632885
step: 90, loss: 0.043810274451971054
step: 100, loss: 0.03733038902282715
step: 110, loss: 0.04565255716443062
step: 120, loss: 0.0671110451221466
step: 130, loss: 0.10640721768140793
step: 140, loss: 0.12420988082885742
step: 150, loss: 0.03731834143400192
step: 160, loss: 0.034446991980075836
step: 170, loss: 0.028233371675014496
step: 180, loss: 0.038268547505140305
step: 190, loss: 0.11572199314832687
step: 200, loss: 0.00742975203320384
step: 210, loss: 0.0359434112906456
step: 220, loss: 0.06633619219064713
step: 230, loss: 0.040570419281721115
step: 240, loss: 0.031793415546417236
step: 250, loss: 0.06618931889533997
step: 260, loss: 0.156673863530159
step: 270, loss: 0.030217474326491356
step: 280, loss: 0.009164990857243538
step: 290, loss: 0.005755745805799961
step: 300, loss: 0.043741025030612946
step: 310, loss: 0.043244387954473495
step: 320, loss: 0.0372612290084362
step: 330, loss: 0.07082214206457138
step: 340, loss: 0.0025294418446719646
step: 350, loss: 0.06376276165246964
step: 360, loss: 0.0060343570075929165
step: 370, loss: 0.004498536232858896
step: 380, loss: 0.001376597909256816
step: 390, loss: 0.20519840717315674
step: 400, loss: 0.08593133091926575
step: 410, loss: 0.04762961342930794
step: 420, loss: 0.02809470146894455
step: 430, loss: 0.12863600254058838
step: 440, loss: 0.07910539209842682
step: 450, loss: 0.0604705736041069
step: 460, loss: 0.0437634214758873
step: 470, loss: 0.04337456449866295
step: 480, loss: 0.07214809209108353
step: 490, loss: 0.028966514393687248
step: 500, loss: 9.864864841802046e-05
step: 510, loss: 0.11633528769016266
step: 520, loss: 0.024041904136538506
step: 530, loss: 0.03399056941270828
step: 540, loss: 0.08805093169212341
step: 550, loss: 0.01738986000418663
step: 560, loss: 0.005559590645134449
step: 570, loss: 0.04291854798793793
step: 580, loss: 0.03730173408985138
step: 590, loss: 0.00274398154579103
step: 600, loss: 0.06970953196287155
step: 610, loss: 0.03881983458995819
step: 620, loss: 0.032027993351221085
step: 630, loss: 0.05656392499804497
step: 640, loss: 0.0918717011809349
step: 650, loss: 0.06919893622398376
step: 660, loss: 0.07528194040060043
step: 670, loss: 0.012660548090934753
step: 680, loss: 0.029559100046753883
step: 690, loss: 0.07899803668260574
step: 700, loss: 0.03300279378890991
step: 710, loss: 0.07153686881065369
step: 720, loss: 0.02193942666053772
step: 730, loss: 0.04204302281141281
step: 740, loss: 0.040483903139829636
step: 750, loss: 0.07186983525753021
step: 760, loss: 0.03788738697767258
step: 770, loss: 0.02828032337129116
step: 780, loss: 0.10947596281766891
step: 790, loss: 0.05380933731794357
step: 800, loss: 0.04997528716921806
step: 810, loss: 0.09127721935510635
step: 820, loss: 0.06596999615430832
step: 830, loss: 0.017989007756114006
step: 840, loss: 0.16697272658348083
step: 850, loss: 0.0031690457835793495
step: 860, loss: 0.002880127402022481
step: 870, loss: 0.05505985766649246
step: 880, loss: 0.027888158336281776
step: 890, loss: 0.09979908913373947
step: 900, loss: 3.612343789427541e-05
step: 910, loss: 0.18721579015254974
step: 920, loss: 0.0459025576710701
step: 930, loss: 0.09872247278690338
step: 940, loss: 0.007286203093826771
step: 950, loss: 0.006061993073672056
step: 960, loss: 0.07698042690753937
step: 970, loss: 0.02865786664187908
epoch 13: dev_f1=0.9330254041570438, f1=0.9211009174311927, best_f1=0.9289617486338797
step: 0, loss: 0.020805783569812775
step: 10, loss: 0.11875675618648529
step: 20, loss: 0.0227288119494915
step: 30, loss: 0.03897048160433769
step: 40, loss: 0.04651667922735214
step: 50, loss: 0.06336688250303268
step: 60, loss: 0.026838375255465508
step: 70, loss: 0.09806443750858307
step: 80, loss: 0.004834570921957493
step: 90, loss: 0.01583521068096161
step: 100, loss: 0.05269940569996834
step: 110, loss: 0.00048703537322580814
step: 120, loss: 0.03207048773765564
step: 130, loss: 0.029380768537521362
step: 140, loss: 0.009441046044230461
step: 150, loss: 0.04492323100566864
step: 160, loss: 0.030706234276294708
step: 170, loss: 0.0020839779172092676
step: 180, loss: 0.07038057595491409
step: 190, loss: 0.0038492565508931875
step: 200, loss: 0.02683684229850769
step: 210, loss: 0.06295236945152283
step: 220, loss: 0.014088723808526993
step: 230, loss: 0.01869868114590645
step: 240, loss: 0.03190984949469566
step: 250, loss: 0.01967305690050125
step: 260, loss: 0.006804295349866152
step: 270, loss: 0.013850492425262928
step: 280, loss: 0.08269653469324112
step: 290, loss: 0.002577154664322734
step: 300, loss: 0.04976440221071243
step: 310, loss: 0.006774899549782276
step: 320, loss: 0.017735783010721207
step: 330, loss: 0.02628900855779648
step: 340, loss: 0.030929289758205414
step: 350, loss: 0.019462736323475838
step: 360, loss: 8.92350944923237e-05
step: 370, loss: 0.0004371980903670192
step: 380, loss: 0.021860014647245407
step: 390, loss: 0.00034934189170598984
step: 400, loss: 0.006580564193427563
step: 410, loss: 0.09543126821517944
step: 420, loss: 0.03018432855606079
step: 430, loss: 0.0014150186907500029
step: 440, loss: 0.0799877941608429
step: 450, loss: 0.05983724072575569
step: 460, loss: 0.005921715870499611
step: 470, loss: 0.1270698606967926
step: 480, loss: 0.05513050779700279
step: 490, loss: 0.014312468469142914
step: 500, loss: 0.07480894029140472
step: 510, loss: 0.014255923219025135
step: 520, loss: 0.014662859961390495
step: 530, loss: 0.04399685189127922
step: 540, loss: 0.060442883521318436
step: 550, loss: 0.06347963213920593
step: 560, loss: 0.09859742969274521
step: 570, loss: 0.022923462092876434
step: 580, loss: 0.029697369784116745
step: 590, loss: 0.030069079250097275
step: 600, loss: 0.07684825360774994
step: 610, loss: 0.12383255362510681
step: 620, loss: 0.035330880433321
step: 630, loss: 0.016488349065184593
step: 640, loss: 0.06530068814754486
step: 650, loss: 0.10190455615520477
step: 660, loss: 0.017606573179364204
step: 670, loss: 0.11856447160243988
step: 680, loss: 0.03536936268210411
step: 690, loss: 0.0718030333518982
step: 700, loss: 0.04285581037402153
step: 710, loss: 0.000136518880026415
step: 720, loss: 0.021701328456401825
step: 730, loss: 0.039264168590307236
step: 740, loss: 0.022707657888531685
step: 750, loss: 0.08689124882221222
step: 760, loss: 0.07642409205436707
step: 770, loss: 0.04407276213169098
step: 780, loss: 0.04266741871833801
step: 790, loss: 0.018384065479040146
step: 800, loss: 0.03380569443106651
step: 810, loss: 0.06847552955150604
step: 820, loss: 0.00020184522145427763
step: 830, loss: 0.04897443577647209
step: 840, loss: 0.0019347862107679248
step: 850, loss: 0.04164566472172737
step: 860, loss: 0.04990728572010994
step: 870, loss: 0.018724339082837105
step: 880, loss: 0.016251608729362488
step: 890, loss: 0.017070380970835686
step: 900, loss: 0.022051481530070305
step: 910, loss: 0.03631128743290901
step: 920, loss: 0.12118807435035706
step: 930, loss: 0.062493160367012024
step: 940, loss: 0.02419842779636383
step: 950, loss: 0.04603924602270126
step: 960, loss: 0.057739775627851486
step: 970, loss: 0.06191360577940941
epoch 14: dev_f1=0.9338881183541378, f1=0.9213069489185457, best_f1=0.9289617486338797
step: 0, loss: 0.022683890536427498
step: 10, loss: 0.016363974660634995
step: 20, loss: 0.01230564620345831
step: 30, loss: 0.06410149484872818
step: 40, loss: 0.040547702461481094
step: 50, loss: 0.03505532443523407
step: 60, loss: 0.023002654314041138
step: 70, loss: 0.023972896859049797
step: 80, loss: 0.0959424376487732
step: 90, loss: 0.018771547824144363
step: 100, loss: 0.007218868006020784
step: 110, loss: 0.020970279350876808
step: 120, loss: 0.014669250696897507
step: 130, loss: 0.024776224046945572
step: 140, loss: 0.00017033354379236698
step: 150, loss: 0.07409851253032684
step: 160, loss: 0.006830834783613682
step: 170, loss: 0.016690999269485474
step: 180, loss: 0.020902639254927635
step: 190, loss: 0.056710802018642426
step: 200, loss: 0.014467383734881878
step: 210, loss: 0.006291618570685387
step: 220, loss: 0.04598398134112358
step: 230, loss: 0.01060771755874157
step: 240, loss: 0.07932273298501968
step: 250, loss: 0.10319621115922928
step: 260, loss: 0.0546678751707077
step: 270, loss: 0.008042830973863602
step: 280, loss: 0.10765727609395981
step: 290, loss: 0.02757982537150383
step: 300, loss: 0.00011102453572675586
step: 310, loss: 0.23785848915576935
step: 320, loss: 0.06437839567661285
step: 330, loss: 0.014622416347265244
step: 340, loss: 0.019275378435850143
step: 350, loss: 0.058916911482810974
step: 360, loss: 0.00012556907313410193
step: 370, loss: 0.010145168751478195
step: 380, loss: 0.04793500527739525
step: 390, loss: 0.07811594754457474
step: 400, loss: 0.014936894178390503
step: 410, loss: 0.013918823562562466
step: 420, loss: 0.04565252363681793
step: 430, loss: 0.03231238201260567
step: 440, loss: 0.004153047222644091
step: 450, loss: 0.009019657969474792
step: 460, loss: 0.020824486389756203
step: 470, loss: 0.008228093385696411
step: 480, loss: 0.10300331562757492
step: 490, loss: 0.04665044695138931
step: 500, loss: 0.03671158850193024
step: 510, loss: 0.00879752915352583
step: 520, loss: 0.013692579232156277
step: 530, loss: 0.08119373023509979
step: 540, loss: 0.00021450428175739944
step: 550, loss: 0.06362747400999069
step: 560, loss: 0.09113626182079315
step: 570, loss: 0.005391482263803482
step: 580, loss: 3.370393460500054e-05
step: 590, loss: 0.05026419088244438
step: 600, loss: 0.018362486734986305
step: 610, loss: 0.014892338775098324
step: 620, loss: 0.037021588534116745
step: 630, loss: 0.0713343545794487
step: 640, loss: 0.03378279507160187
step: 650, loss: 0.003419009502977133
step: 660, loss: 0.0032803546637296677
step: 670, loss: 0.07739291340112686
step: 680, loss: 0.032208558171987534
step: 690, loss: 0.0010975042823702097
step: 700, loss: 0.0004007442912552506
step: 710, loss: 0.006815353408455849
step: 720, loss: 0.003476695856079459
step: 730, loss: 0.16894985735416412
step: 740, loss: 0.017402958124876022
step: 750, loss: 0.010743052698671818
step: 760, loss: 0.00031055737053975463
step: 770, loss: 0.029176931828260422
step: 780, loss: 8.37438437883975e-06
step: 790, loss: 0.03407233580946922
step: 800, loss: 0.015435991808772087
step: 810, loss: 0.0791974887251854
step: 820, loss: 0.015184363350272179
step: 830, loss: 0.0006721887039020658
step: 840, loss: 0.10521508008241653
step: 850, loss: 0.03989303484559059
step: 860, loss: 0.027833623811602592
step: 870, loss: 0.1271940916776657
step: 880, loss: 0.03622804954648018
step: 890, loss: 0.026806816458702087
step: 900, loss: 0.0357084795832634
step: 910, loss: 0.05651798099279404
step: 920, loss: 0.025099370628595352
step: 930, loss: 0.07269652187824249
step: 940, loss: 2.5163044483633712e-05
step: 950, loss: 0.016639070585370064
step: 960, loss: 0.05775713175535202
step: 970, loss: 4.6399283746723086e-05
epoch 15: dev_f1=0.9322892676186089, f1=0.9223034734917733, best_f1=0.9289617486338797
step: 0, loss: 0.04624311625957489
step: 10, loss: 0.0008007122669368982
step: 20, loss: 0.04578106850385666
step: 30, loss: 0.002624196233227849
step: 40, loss: 0.06477200239896774
step: 50, loss: 0.04354039207100868
step: 60, loss: 0.042006149888038635
step: 70, loss: 0.00022730996715836227
step: 80, loss: 0.03295573964715004
step: 90, loss: 0.028028812259435654
step: 100, loss: 0.07958942651748657
step: 110, loss: 0.001916359644383192
step: 120, loss: 0.05451418086886406
step: 130, loss: 0.000693917041644454
step: 140, loss: 0.03766210377216339
step: 150, loss: 0.06017300486564636
step: 160, loss: 0.01122176181524992
step: 170, loss: 0.03407680615782738
step: 180, loss: 5.9292684454703704e-05
step: 190, loss: 0.01620704121887684
step: 200, loss: 0.09122826904058456
step: 210, loss: 0.004283084999769926
step: 220, loss: 0.08501460403203964
step: 230, loss: 0.04917694255709648
step: 240, loss: 0.010823625139892101
step: 250, loss: 0.02179238572716713
step: 260, loss: 0.030012549832463264
step: 270, loss: 0.03885353356599808
step: 280, loss: 0.047798141837120056
step: 290, loss: 0.10702867805957794
step: 300, loss: 0.00249953824095428
step: 310, loss: 0.0018937826389446855
step: 320, loss: 0.011880343779921532
step: 330, loss: 0.04377392679452896
step: 340, loss: 0.09329891949892044
step: 350, loss: 0.17024202644824982
step: 360, loss: 0.007601265795528889
step: 370, loss: 0.0012472310336306691
step: 380, loss: 0.026535289362072945
step: 390, loss: 0.04746410623192787
step: 400, loss: 0.01267042476683855
step: 410, loss: 0.02356036938726902
step: 420, loss: 0.01790761575102806
step: 430, loss: 0.024301860481500626
step: 440, loss: 0.0027914890088140965
step: 450, loss: 0.024110548198223114
step: 460, loss: 0.07981595396995544
step: 470, loss: 0.00010950370779028162
step: 480, loss: 3.1108909752219915e-05
step: 490, loss: 0.0846414864063263
step: 500, loss: 0.05015237629413605
step: 510, loss: 0.032362811267375946
step: 520, loss: 0.021042168140411377
step: 530, loss: 0.023294098675251007
step: 540, loss: 0.07533468306064606
step: 550, loss: 0.01075875572860241
step: 560, loss: 0.03575357422232628
step: 570, loss: 0.05537932366132736
step: 580, loss: 0.04707738012075424
step: 590, loss: 2.6615045499056578e-05
step: 600, loss: 0.04517262801527977
step: 610, loss: 0.05161226540803909
step: 620, loss: 0.05521209165453911
step: 630, loss: 0.0385432206094265
step: 640, loss: 0.09021241962909698
step: 650, loss: 0.0004328992508817464
step: 660, loss: 0.093503437936306
step: 670, loss: 0.014182182028889656
step: 680, loss: 0.06490878760814667
step: 690, loss: 0.001052512088790536
step: 700, loss: 0.018681900575757027
step: 710, loss: 0.028470110148191452
step: 720, loss: 0.00014824488607700914
step: 730, loss: 0.03372219577431679
step: 740, loss: 0.06694555282592773
step: 750, loss: 0.03630036860704422
step: 760, loss: 0.05260131135582924
step: 770, loss: 0.03658329322934151
step: 780, loss: 0.009354720823466778
step: 790, loss: 0.008880377747118473
step: 800, loss: 0.001766734174452722
step: 810, loss: 0.046014830470085144
step: 820, loss: 0.001433927332982421
step: 830, loss: 0.03049340844154358
step: 840, loss: 0.041912246495485306
step: 850, loss: 0.00016833998961374164
step: 860, loss: 0.01930498704314232
step: 870, loss: 0.01774037629365921
step: 880, loss: 0.05778993293642998
step: 890, loss: 0.061065398156642914
step: 900, loss: 0.00031956651946529746
step: 910, loss: 0.00012071082892362028
step: 920, loss: 0.010817966423928738
step: 930, loss: 0.041414257138967514
step: 940, loss: 0.042615119367837906
step: 950, loss: 0.0027608443051576614
step: 960, loss: 0.04970785975456238
step: 970, loss: 0.021995460614562035
epoch 16: dev_f1=0.9341806627326373, f1=0.9201623815967523, best_f1=0.9289617486338797
step: 0, loss: 0.07104606926441193
step: 10, loss: 0.025323214009404182
step: 20, loss: 0.0020311663392931223
step: 30, loss: 0.06663361191749573
step: 40, loss: 0.047135066241025925
step: 50, loss: 0.0006780250696465373
step: 60, loss: 7.113867468433455e-05
step: 70, loss: 0.05242210999131203
step: 80, loss: 0.02566608227789402
step: 90, loss: 0.001212598872371018
step: 100, loss: 0.025273866951465607
step: 110, loss: 0.01822183094918728
step: 120, loss: 0.009346909821033478
step: 130, loss: 0.02606685273349285
step: 140, loss: 0.04149002954363823
step: 150, loss: 0.050597913563251495
step: 160, loss: 0.06297139078378677
step: 170, loss: 0.0526554137468338
step: 180, loss: 0.017270684242248535
step: 190, loss: 0.02818671241402626
step: 200, loss: 0.030739717185497284
step: 210, loss: 0.011214516125619411
step: 220, loss: 0.018000097945332527
step: 230, loss: 0.00018560854368843138
step: 240, loss: 0.019672583788633347
step: 250, loss: 0.026995321735739708
step: 260, loss: 0.02764192596077919
step: 270, loss: 0.009879238903522491
step: 280, loss: 0.021816564723849297
step: 290, loss: 0.12112152576446533
step: 300, loss: 0.0048709409311413765
step: 310, loss: 0.05903616547584534
step: 320, loss: 0.021292034536600113
step: 330, loss: 0.0013621466932818294
step: 340, loss: 0.029511641710996628
step: 350, loss: 0.07531837373971939
step: 360, loss: 0.02715197764337063
step: 370, loss: 0.06159859895706177
step: 380, loss: 8.898580563254654e-05
step: 390, loss: 0.06610288470983505
step: 400, loss: 0.03739750012755394
step: 410, loss: 0.02134004235267639
step: 420, loss: 0.0568266399204731
step: 430, loss: 0.031742244958877563
step: 440, loss: 0.00027861815760843456
step: 450, loss: 0.09719430655241013
step: 460, loss: 0.04367498308420181
step: 470, loss: 0.022175336256623268
step: 480, loss: 0.0006219233036972582
step: 490, loss: 0.022176964208483696
step: 500, loss: 0.0736832320690155
step: 510, loss: 2.3330952899414115e-05
step: 520, loss: 0.00010298455890733749
step: 530, loss: 0.021303344517946243
step: 540, loss: 0.011357538402080536
step: 550, loss: 0.03184356167912483
step: 560, loss: 0.044505976140499115
step: 570, loss: 0.013286611996591091
step: 580, loss: 0.02709675207734108
step: 590, loss: 0.0949024111032486
step: 600, loss: 0.06418046355247498
step: 610, loss: 0.04118892550468445
step: 620, loss: 0.06532487273216248
step: 630, loss: 0.0001222952123498544
step: 640, loss: 0.0004173058259766549
step: 650, loss: 0.028909776359796524
step: 660, loss: 0.016507217660546303
step: 670, loss: 0.001507278997451067
step: 680, loss: 0.011224781163036823
step: 690, loss: 0.017659440636634827
step: 700, loss: 0.054310329258441925
step: 710, loss: 0.03765476495027542
step: 720, loss: 0.018199676647782326
step: 730, loss: 5.989265628159046e-05
step: 740, loss: 0.0025362055748701096
step: 750, loss: 0.0001650587801123038
step: 760, loss: 0.05267644673585892
step: 770, loss: 0.002986121689900756
step: 780, loss: 0.04924449697136879
step: 790, loss: 0.11690545827150345
step: 800, loss: 0.009992326609790325
step: 810, loss: 0.0040777698159217834
step: 820, loss: 0.03159753233194351
step: 830, loss: 0.04100427404046059
step: 840, loss: 0.05506618693470955
step: 850, loss: 2.6089443053933792e-05
step: 860, loss: 0.027101755142211914
step: 870, loss: 0.00010290928912581876
step: 880, loss: 0.06944999098777771
step: 890, loss: 0.0001045812969096005
step: 900, loss: 0.04802175611257553
step: 910, loss: 0.039470963180065155
step: 920, loss: 0.05039972439408302
step: 930, loss: 0.0009194836602546275
step: 940, loss: 0.07371395826339722
step: 950, loss: 0.08783765882253647
step: 960, loss: 0.007078181020915508
step: 970, loss: 0.021187137812376022
epoch 17: dev_f1=0.9341317365269461, f1=0.9220246238030095, best_f1=0.9289617486338797
step: 0, loss: 0.028784245252609253
step: 10, loss: 0.005135145969688892
step: 20, loss: 0.05917108431458473
step: 30, loss: 0.027667023241519928
step: 40, loss: 0.026636000722646713
step: 50, loss: 3.3883457945194095e-05
step: 60, loss: 0.021262340247631073
step: 70, loss: 2.9756221920251846e-05
step: 80, loss: 0.04318060353398323
step: 90, loss: 0.01822720468044281
step: 100, loss: 0.04173702746629715
step: 110, loss: 0.020271116867661476
step: 120, loss: 4.396747317514382e-05
step: 130, loss: 0.0004654577060136944
step: 140, loss: 0.14172881841659546
step: 150, loss: 0.025096731260418892
step: 160, loss: 0.021696334704756737
step: 170, loss: 0.04331162944436073
step: 180, loss: 0.08973614871501923
step: 190, loss: 0.05356323719024658
step: 200, loss: 8.987287583295256e-05
step: 210, loss: 0.00015407784667331725
step: 220, loss: 0.016112608835101128
step: 230, loss: 0.07579471915960312
step: 240, loss: 6.514301639981568e-05
step: 250, loss: 0.02260882779955864
step: 260, loss: 0.10479338467121124
step: 270, loss: 0.03994647040963173
step: 280, loss: 0.04475178197026253
step: 290, loss: 0.05540907010436058
step: 300, loss: 0.09849347174167633
step: 310, loss: 0.010732952505350113
step: 320, loss: 0.0943388119339943
step: 330, loss: 0.026652060449123383
step: 340, loss: 0.059409864246845245
step: 350, loss: 0.07498778402805328
step: 360, loss: 0.0575365386903286
step: 370, loss: 0.01787404902279377
step: 380, loss: 2.5427003492950462e-05
step: 390, loss: 0.00028497050516307354
step: 400, loss: 0.09089820832014084
step: 410, loss: 0.06792040914297104
step: 420, loss: 0.0007301628938876092
step: 430, loss: 0.026210280135273933
step: 440, loss: 0.034768953919410706
step: 450, loss: 0.025010276585817337
step: 460, loss: 0.0397074893116951
step: 470, loss: 7.604795973747969e-05
step: 480, loss: 0.05737666040658951
step: 490, loss: 0.042740363627672195
step: 500, loss: 0.002914294134825468
step: 510, loss: 6.785213918192312e-05
step: 520, loss: 0.02835281938314438
step: 530, loss: 0.06331993639469147
step: 540, loss: 0.040510281920433044
step: 550, loss: 4.2714080336736515e-05
step: 560, loss: 0.011275609955191612
step: 570, loss: 0.07436846196651459
step: 580, loss: 0.04952908307313919
step: 590, loss: 0.013993481174111366
step: 600, loss: 0.024768806993961334
step: 610, loss: 0.05669812485575676
step: 620, loss: 0.04051406309008598
step: 630, loss: 0.034793365746736526
step: 640, loss: 0.02530480921268463
step: 650, loss: 0.021403735503554344
step: 660, loss: 0.02154530957341194
step: 670, loss: 2.523178955016192e-05
step: 680, loss: 0.06380314379930496
step: 690, loss: 0.00468612601980567
step: 700, loss: 0.019486108794808388
step: 710, loss: 0.03299422189593315
step: 720, loss: 5.1514805818442255e-05
step: 730, loss: 0.029994245618581772
step: 740, loss: 0.05979553610086441
step: 750, loss: 0.03245225548744202
step: 760, loss: 0.009152986109256744
step: 770, loss: 0.043279558420181274
step: 780, loss: 0.09028422087430954
step: 790, loss: 0.00016993556346278638
step: 800, loss: 7.002862548688427e-05
step: 810, loss: 0.0005470489268191159
step: 820, loss: 0.05004916340112686
step: 830, loss: 0.10209641605615616
step: 840, loss: 3.9445825677830726e-05
step: 850, loss: 0.024045662954449654
step: 860, loss: 0.0057378485798835754
step: 870, loss: 0.0317118838429451
step: 880, loss: 0.02239014208316803
step: 890, loss: 0.036683231592178345
step: 900, loss: 0.06369409710168839
step: 910, loss: 0.008309854194521904
step: 920, loss: 0.08171705156564713
step: 930, loss: 0.018892688676714897
step: 940, loss: 0.027060972526669502
step: 950, loss: 0.05789486691355705
step: 960, loss: 0.07631947100162506
step: 970, loss: 0.0006144509534351528
epoch 18: dev_f1=0.933454876937101, f1=0.9186991869918699, best_f1=0.9289617486338797
step: 0, loss: 5.148214040673338e-05
step: 10, loss: 0.023569054901599884
step: 20, loss: 0.018397126346826553
step: 30, loss: 0.05404776707291603
step: 40, loss: 0.03229111060500145
step: 50, loss: 0.035991549491882324
step: 60, loss: 0.02727781981229782
step: 70, loss: 0.022362766787409782
step: 80, loss: 0.019447969272732735
step: 90, loss: 0.002904221648350358
step: 100, loss: 0.06641516089439392
step: 110, loss: 0.01741311140358448
step: 120, loss: 0.07291534543037415
step: 130, loss: 0.05559791997075081
step: 140, loss: 0.05140099301934242
step: 150, loss: 0.10982714593410492
step: 160, loss: 0.06661908328533173
step: 170, loss: 0.039645276963710785
step: 180, loss: 0.018937725573778152
step: 190, loss: 0.019665993750095367
step: 200, loss: 0.00027524938923306763
step: 210, loss: 0.11022879183292389
step: 220, loss: 0.03218197450041771
step: 230, loss: 0.03403457626700401
step: 240, loss: 0.05226470157504082
step: 250, loss: 0.00824170745909214
step: 260, loss: 0.05482574179768562
step: 270, loss: 0.014064226299524307
step: 280, loss: 0.017532313242554665
step: 290, loss: 0.030329139903187752
step: 300, loss: 0.0020247148349881172
step: 310, loss: 0.0010781557066366076
step: 320, loss: 0.02345256693661213
step: 330, loss: 0.04285089299082756
step: 340, loss: 0.09258759766817093
step: 350, loss: 7.16694921720773e-05
step: 360, loss: 0.0016458575846627355
step: 370, loss: 0.017161305993795395
step: 380, loss: 0.03777371346950531
step: 390, loss: 0.000334281096002087
step: 400, loss: 0.0590970553457737
step: 410, loss: 0.006858792155981064
step: 420, loss: 0.023243609815835953
step: 430, loss: 0.04290802776813507
step: 440, loss: 0.01560113113373518
step: 450, loss: 0.10689160227775574
step: 460, loss: 0.021404236555099487
step: 470, loss: 0.005748556926846504
step: 480, loss: 0.021128369495272636
step: 490, loss: 0.027869755402207375
step: 500, loss: 0.06872840225696564
step: 510, loss: 0.03602101281285286
step: 520, loss: 0.09649210423231125
step: 530, loss: 0.0585310123860836
step: 540, loss: 0.02573172003030777
step: 550, loss: 0.01771807111799717
step: 560, loss: 0.025147084146738052
step: 570, loss: 0.0565122589468956
step: 580, loss: 0.06212793290615082
step: 590, loss: 0.01942615769803524
step: 600, loss: 9.253472853743006e-06
step: 610, loss: 0.05131640285253525
step: 620, loss: 4.6966055379016325e-05
step: 630, loss: 0.06782267987728119
step: 640, loss: 0.02637440897524357
step: 650, loss: 0.019020017236471176
step: 660, loss: 0.0022775924298912287
step: 670, loss: 0.03408697620034218
step: 680, loss: 0.039915695786476135
step: 690, loss: 0.0444168895483017
step: 700, loss: 0.027988271787762642
step: 710, loss: 0.06063602492213249
step: 720, loss: 0.03297904506325722
step: 730, loss: 0.01542480755597353
step: 740, loss: 0.02014286071062088
step: 750, loss: 0.0008403074461966753
step: 760, loss: 0.020761627703905106
step: 770, loss: 0.04439592361450195
step: 780, loss: 0.020661385729908943
step: 790, loss: 0.023434823378920555
step: 800, loss: 0.01797671429812908
step: 810, loss: 0.02282986231148243
step: 820, loss: 0.02042672596871853
step: 830, loss: 0.07576330006122589
step: 840, loss: 0.02231363020837307
step: 850, loss: 0.00047852651914581656
step: 860, loss: 0.00010784171900013462
step: 870, loss: 0.027258843183517456
step: 880, loss: 0.027756139636039734
step: 890, loss: 0.016189351677894592
step: 900, loss: 0.013944456353783607
step: 910, loss: 0.02793407253921032
step: 920, loss: 0.04233238101005554
step: 930, loss: 0.02071702852845192
step: 940, loss: 0.00011961157724726945
step: 950, loss: 0.09586930274963379
step: 960, loss: 0.020997166633605957
step: 970, loss: 0.07549217343330383
epoch 19: dev_f1=0.9300827966881325, f1=0.9219534459151072, best_f1=0.9289617486338797
step: 0, loss: 0.011944249272346497
step: 10, loss: 0.05742480605840683
step: 20, loss: 8.082633576123044e-05
step: 30, loss: 0.008445833809673786
step: 40, loss: 0.020291762426495552
step: 50, loss: 0.025313176214694977
step: 60, loss: 0.06082793325185776
step: 70, loss: 0.0054346551187336445
step: 80, loss: 0.07959317415952682
step: 90, loss: 0.02557220309972763
step: 100, loss: 7.555988122476265e-05
step: 110, loss: 0.038095276802778244
step: 120, loss: 0.02075081877410412
step: 130, loss: 0.00028408606885932386
step: 140, loss: 0.031066033989191055
step: 150, loss: 0.0572458915412426
step: 160, loss: 4.833778803003952e-05
step: 170, loss: 9.160307854472194e-06
step: 180, loss: 0.03978860378265381
step: 190, loss: 0.0003558093449100852
step: 200, loss: 0.04499222710728645
step: 210, loss: 0.0795232504606247
step: 220, loss: 0.04848822206258774
step: 230, loss: 0.027047714218497276
step: 240, loss: 0.054193463176488876
step: 250, loss: 0.029324766248464584
step: 260, loss: 0.0013995025074109435
step: 270, loss: 0.07028676569461823
step: 280, loss: 0.025008952245116234
step: 290, loss: 0.10145941376686096
step: 300, loss: 0.011814700439572334
step: 310, loss: 0.00017919030506163836
step: 320, loss: 0.059357233345508575
step: 330, loss: 0.0003103974158875644
step: 340, loss: 0.040343474596738815
step: 350, loss: 7.062121585477144e-05
step: 360, loss: 0.029643168672919273
step: 370, loss: 0.010423407889902592
step: 380, loss: 0.022852743044495583
step: 390, loss: 0.00011085494770668447
step: 400, loss: 7.7544515079353e-05
step: 410, loss: 4.79001973872073e-05
step: 420, loss: 0.018195053562521935
step: 430, loss: 0.02144862897694111
step: 440, loss: 0.022062048316001892
step: 450, loss: 0.0695996806025505
step: 460, loss: 0.0025583680253475904
step: 470, loss: 0.05390322580933571
step: 480, loss: 0.0010834801942110062
step: 490, loss: 0.0077317217364907265
step: 500, loss: 0.021123863756656647
step: 510, loss: 0.044529326260089874
step: 520, loss: 4.9758717068471014e-05
step: 530, loss: 0.04071186110377312
step: 540, loss: 0.003260968253016472
step: 550, loss: 0.021112827584147453
step: 560, loss: 0.0063766250386834145
step: 570, loss: 0.008372502401471138
step: 580, loss: 0.0524531826376915
step: 590, loss: 0.01700560934841633
step: 600, loss: 5.308315667207353e-05
step: 610, loss: 0.02529437653720379
step: 620, loss: 0.04548807442188263
step: 630, loss: 0.02347700111567974
step: 640, loss: 0.015820039436221123
step: 650, loss: 0.01031474769115448
step: 660, loss: 0.08493306487798691
step: 670, loss: 0.018572287634015083
step: 680, loss: 0.00013344829494599253
step: 690, loss: 0.00029557457310147583
step: 700, loss: 0.013047676533460617
step: 710, loss: 0.01685684360563755
step: 720, loss: 0.1215197965502739
step: 730, loss: 6.6218817664776e-05
step: 740, loss: 5.844960469403304e-06
step: 750, loss: 0.024794645607471466
step: 760, loss: 0.040740977972745895
step: 770, loss: 0.0470251590013504
step: 780, loss: 0.025551199913024902
step: 790, loss: 0.04541217163205147
step: 800, loss: 0.03316135331988335
step: 810, loss: 2.8187039788463153e-05
step: 820, loss: 0.05041545256972313
step: 830, loss: 0.017584046348929405
step: 840, loss: 0.0008281948394142091
step: 850, loss: 0.02505050040781498
step: 860, loss: 0.027447469532489777
step: 870, loss: 2.4056716938503087e-05
step: 880, loss: 6.190861313370988e-05
step: 890, loss: 0.04608842730522156
step: 900, loss: 0.08274639397859573
step: 910, loss: 0.06887093186378479
step: 920, loss: 0.03849282115697861
step: 930, loss: 2.0031917301821522e-05
step: 940, loss: 0.011811766773462296
step: 950, loss: 0.08005113154649734
step: 960, loss: 0.042188312858343124
step: 970, loss: 0.020901698619127274
epoch 20: dev_f1=0.9306839186691312, f1=0.922089825847846, best_f1=0.9289617486338797
