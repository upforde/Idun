cuda
Device: cuda
step: 0, loss: 0.5242795944213867
step: 10, loss: 0.3812751770019531
step: 20, loss: 0.22375239431858063
step: 30, loss: 0.12432365864515305
step: 40, loss: 0.30661502480506897
step: 50, loss: 0.15272200107574463
step: 60, loss: 0.09043551236391068
step: 70, loss: 0.15780207514762878
step: 80, loss: 0.1345062553882599
step: 90, loss: 0.35346436500549316
step: 100, loss: 0.16036401689052582
step: 110, loss: 0.1525336056947708
step: 120, loss: 0.10334514826536179
step: 130, loss: 0.25719642639160156
step: 140, loss: 0.18520183861255646
step: 150, loss: 0.14744408428668976
step: 160, loss: 0.06379306316375732
step: 170, loss: 0.13798664510250092
step: 180, loss: 0.20398060977458954
step: 190, loss: 0.1822424829006195
step: 200, loss: 0.28408321738243103
step: 210, loss: 0.19114331901073456
step: 220, loss: 0.11335116624832153
step: 230, loss: 0.052669595927000046
step: 240, loss: 0.16644920408725739
step: 250, loss: 0.07304736971855164
step: 260, loss: 0.15594208240509033
step: 270, loss: 0.33833229541778564
step: 280, loss: 0.10546630620956421
step: 290, loss: 0.13776728510856628
step: 300, loss: 0.17070114612579346
step: 310, loss: 0.022691674530506134
step: 320, loss: 0.16516001522541046
step: 330, loss: 0.10593727976083755
step: 340, loss: 0.18180783092975616
step: 350, loss: 0.17766797542572021
step: 360, loss: 0.0005385350668802857
step: 370, loss: 0.12145694345235825
step: 380, loss: 0.013860817067325115
step: 390, loss: 0.031859494745731354
step: 400, loss: 0.0953676849603653
step: 410, loss: 0.2016633003950119
step: 420, loss: 0.0365317203104496
step: 430, loss: 0.14074206352233887
step: 440, loss: 0.22742487490177155
step: 450, loss: 0.11657760292291641
step: 460, loss: 0.08499256521463394
step: 470, loss: 0.03750007227063179
step: 480, loss: 0.08168277144432068
step: 490, loss: 0.04445817321538925
step: 500, loss: 0.11593468487262726
step: 510, loss: 0.07398782670497894
step: 520, loss: 0.13854435086250305
step: 530, loss: 0.04689045622944832
step: 540, loss: 0.17740704119205475
step: 550, loss: 0.129272922873497
step: 560, loss: 0.23269149661064148
step: 570, loss: 0.15156172215938568
step: 580, loss: 0.0979013442993164
step: 590, loss: 0.0819869264960289
step: 600, loss: 0.03842387720942497
step: 610, loss: 0.17988939583301544
step: 620, loss: 0.07130888104438782
step: 630, loss: 0.18031394481658936
step: 640, loss: 0.07218114286661148
step: 650, loss: 0.23281444609165192
step: 660, loss: 0.21965153515338898
step: 670, loss: 0.13011381030082703
step: 680, loss: 0.09720274060964584
step: 690, loss: 0.01845608651638031
step: 700, loss: 0.06191488355398178
step: 710, loss: 0.11056020855903625
step: 720, loss: 0.08285931497812271
step: 730, loss: 0.01351358462125063
step: 740, loss: 0.04349542781710625
step: 750, loss: 0.05031551420688629
step: 760, loss: 0.169466033577919
step: 770, loss: 0.22561222314834595
step: 780, loss: 0.0346510112285614
step: 790, loss: 0.01342221163213253
step: 800, loss: 0.09877701848745346
step: 810, loss: 0.051726605743169785
step: 820, loss: 0.0428602360188961
step: 830, loss: 0.13007357716560364
step: 840, loss: 0.07209701091051102
step: 850, loss: 0.1492197960615158
step: 860, loss: 0.16550663113594055
step: 870, loss: 0.13461829721927643
step: 880, loss: 0.13887101411819458
step: 890, loss: 0.04671834036707878
step: 900, loss: 0.05941937863826752
step: 910, loss: 0.06127379089593887
step: 920, loss: 0.2162621170282364
step: 930, loss: 0.07189122587442398
step: 940, loss: 0.17654146254062653
step: 950, loss: 0.014591059647500515
step: 960, loss: 0.10937605798244476
step: 970, loss: 0.1266552060842514
epoch 1: dev_f1=0.9255571360834518, f1=0.9240150093808631, best_f1=0.9240150093808631
step: 0, loss: 0.08276113867759705
step: 10, loss: 0.045762740075588226
step: 20, loss: 0.042900342494249344
step: 30, loss: 0.13636896014213562
step: 40, loss: 0.09254403412342072
step: 50, loss: 0.14811870455741882
step: 60, loss: 0.07029459625482559
step: 70, loss: 0.058188263326883316
step: 80, loss: 0.07587576657533646
step: 90, loss: 0.046107303351163864
step: 100, loss: 0.13266462087631226
step: 110, loss: 0.09752453863620758
step: 120, loss: 0.10190946608781815
step: 130, loss: 0.08632950484752655
step: 140, loss: 0.1410212218761444
step: 150, loss: 0.06339548528194427
step: 160, loss: 0.12468608468770981
step: 170, loss: 0.08299706876277924
step: 180, loss: 0.05580829456448555
step: 190, loss: 0.04698662832379341
step: 200, loss: 0.10341006517410278
step: 210, loss: 0.01840313710272312
step: 220, loss: 0.0906752496957779
step: 230, loss: 0.11285141110420227
step: 240, loss: 0.0450957790017128
step: 250, loss: 0.0595942921936512
step: 260, loss: 0.2512120306491852
step: 270, loss: 0.08077005296945572
step: 280, loss: 0.09789462387561798
step: 290, loss: 0.12673375010490417
step: 300, loss: 0.17690227925777435
step: 310, loss: 0.06554253399372101
step: 320, loss: 0.027914458885788918
step: 330, loss: 0.012542422860860825
step: 340, loss: 0.18048737943172455
step: 350, loss: 0.07971828430891037
step: 360, loss: 0.15025658905506134
step: 370, loss: 0.14480359852313995
step: 380, loss: 0.20774279534816742
step: 390, loss: 0.09093748033046722
step: 400, loss: 0.04138599708676338
step: 410, loss: 0.14984139800071716
step: 420, loss: 0.0997811034321785
step: 430, loss: 0.08758435398340225
step: 440, loss: 0.07639618963003159
step: 450, loss: 0.2150716781616211
step: 460, loss: 0.026683511212468147
step: 470, loss: 0.16886930167675018
step: 480, loss: 0.061593517661094666
step: 490, loss: 0.11463763564825058
step: 500, loss: 0.0744151696562767
step: 510, loss: 0.1166667491197586
step: 520, loss: 0.1302131861448288
step: 530, loss: 0.201885387301445
step: 540, loss: 0.07542546093463898
step: 550, loss: 0.3345058858394623
step: 560, loss: 0.013101964257657528
step: 570, loss: 0.0422007218003273
step: 580, loss: 0.11263282597064972
step: 590, loss: 0.08387462049722672
step: 600, loss: 0.01873369887471199
step: 610, loss: 0.06055326759815216
step: 620, loss: 0.011313505470752716
step: 630, loss: 0.10492927581071854
step: 640, loss: 0.15936489403247833
step: 650, loss: 0.06975723057985306
step: 660, loss: 0.18041786551475525
step: 670, loss: 0.06910151988267899
step: 680, loss: 0.06425567716360092
step: 690, loss: 0.09105878323316574
step: 700, loss: 0.11365687847137451
step: 710, loss: 0.07157276570796967
step: 720, loss: 0.11866357922554016
step: 730, loss: 0.1305501013994217
step: 740, loss: 0.10966654866933823
step: 750, loss: 0.1698906123638153
step: 760, loss: 0.16586583852767944
step: 770, loss: 0.09047049283981323
step: 780, loss: 0.13283395767211914
step: 790, loss: 0.12920618057250977
step: 800, loss: 0.12082987278699875
step: 810, loss: 0.1343553066253662
step: 820, loss: 0.11520494520664215
step: 830, loss: 0.02299927920103073
step: 840, loss: 0.14788924157619476
step: 850, loss: 0.1502668708562851
step: 860, loss: 0.178480863571167
step: 870, loss: 0.18220902979373932
step: 880, loss: 0.09102189540863037
step: 890, loss: 0.09056618809700012
step: 900, loss: 0.057357482612133026
step: 910, loss: 0.22015248239040375
step: 920, loss: 0.06419657170772552
step: 930, loss: 0.06116155907511711
step: 940, loss: 0.10430257767438889
step: 950, loss: 0.042215634137392044
step: 960, loss: 0.09755432605743408
step: 970, loss: 0.07096005976200104
epoch 2: dev_f1=0.938134810710988, f1=0.9350411710887466, best_f1=0.9350411710887466
step: 0, loss: 0.004362991079688072
step: 10, loss: 0.014642499387264252
step: 20, loss: 0.1880694329738617
step: 30, loss: 0.28754761815071106
step: 40, loss: 0.05754457041621208
step: 50, loss: 0.05655432865023613
step: 60, loss: 0.018165776506066322
step: 70, loss: 0.09949001669883728
step: 80, loss: 0.13908283412456512
step: 90, loss: 0.02495691552758217
step: 100, loss: 0.047029078006744385
step: 110, loss: 0.016501285135746002
step: 120, loss: 0.15301376581192017
step: 130, loss: 0.006561249494552612
step: 140, loss: 0.09944623708724976
step: 150, loss: 0.038945745676755905
step: 160, loss: 0.06363348662853241
step: 170, loss: 0.07361509650945663
step: 180, loss: 0.17991600930690765
step: 190, loss: 0.0012834095396101475
step: 200, loss: 0.04693073406815529
step: 210, loss: 0.04700141027569771
step: 220, loss: 0.07133021205663681
step: 230, loss: 0.012678030878305435
step: 240, loss: 0.10580231994390488
step: 250, loss: 0.1701684296131134
step: 260, loss: 0.025693422183394432
step: 270, loss: 0.10055048763751984
step: 280, loss: 0.11391202360391617
step: 290, loss: 0.059655655175447464
step: 300, loss: 0.05593251436948776
step: 310, loss: 0.07574332505464554
step: 320, loss: 0.1277712881565094
step: 330, loss: 0.06870413571596146
step: 340, loss: 0.1377493441104889
step: 350, loss: 0.12110204249620438
step: 360, loss: 0.1197541356086731
step: 370, loss: 0.11813592910766602
step: 380, loss: 0.032191962003707886
step: 390, loss: 0.10666187107563019
step: 400, loss: 0.02501009590923786
step: 410, loss: 0.19711098074913025
step: 420, loss: 0.0358075276017189
step: 430, loss: 0.0363723486661911
step: 440, loss: 0.14623193442821503
step: 450, loss: 0.06143304705619812
step: 460, loss: 0.10256659239530563
step: 470, loss: 0.24218612909317017
step: 480, loss: 0.08256225287914276
step: 490, loss: 0.02414620667695999
step: 500, loss: 0.07549355179071426
step: 510, loss: 0.039110392332077026
step: 520, loss: 0.01560914609581232
step: 530, loss: 0.08348353952169418
step: 540, loss: 0.015702199190855026
step: 550, loss: 0.02883225306868553
step: 560, loss: 0.10772257298231125
step: 570, loss: 0.03394860774278641
step: 580, loss: 0.11629403382539749
step: 590, loss: 0.05358101800084114
step: 600, loss: 0.004452131688594818
step: 610, loss: 0.04815590754151344
step: 620, loss: 0.13373006880283356
step: 630, loss: 0.02294664829969406
step: 640, loss: 0.06220201030373573
step: 650, loss: 0.1326003521680832
step: 660, loss: 0.037206508219242096
step: 670, loss: 0.06451336294412613
step: 680, loss: 0.16077540814876556
step: 690, loss: 0.06101784482598305
step: 700, loss: 0.05218464136123657
step: 710, loss: 0.029248086735606194
step: 720, loss: 0.03899843618273735
step: 730, loss: 0.10359302163124084
step: 740, loss: 0.1742730438709259
step: 750, loss: 0.03258376568555832
step: 760, loss: 0.09985415637493134
step: 770, loss: 0.10934031009674072
step: 780, loss: 0.29081499576568604
step: 790, loss: 0.02129635214805603
step: 800, loss: 0.024768613278865814
step: 810, loss: 0.083232082426548
step: 820, loss: 0.03854545205831528
step: 830, loss: 0.07237169146537781
step: 840, loss: 0.02104904130101204
step: 850, loss: 0.035054389387369156
step: 860, loss: 0.04284179210662842
step: 870, loss: 0.038472652435302734
step: 880, loss: 0.03333142772316933
step: 890, loss: 0.02308996021747589
step: 900, loss: 0.018300071358680725
step: 910, loss: 0.008753801696002483
step: 920, loss: 0.04059106111526489
step: 930, loss: 0.02055724710226059
step: 940, loss: 0.06266296654939651
step: 950, loss: 0.07345419377088547
step: 960, loss: 0.02616964280605316
step: 970, loss: 0.17056216299533844
epoch 3: dev_f1=0.9334557136301056, f1=0.9299771167048057, best_f1=0.9350411710887466
step: 0, loss: 0.09740564972162247
step: 10, loss: 0.07194510847330093
step: 20, loss: 0.017562974244356155
step: 30, loss: 0.06829608231782913
step: 40, loss: 0.08630836755037308
step: 50, loss: 0.00994680542498827
step: 60, loss: 0.05315661057829857
step: 70, loss: 0.16744592785835266
step: 80, loss: 0.11585395038127899
step: 90, loss: 0.10512448847293854
step: 100, loss: 0.025471841916441917
step: 110, loss: 0.05579955875873566
step: 120, loss: 0.17728017270565033
step: 130, loss: 0.051055002957582474
step: 140, loss: 0.020042624324560165
step: 150, loss: 0.05365082249045372
step: 160, loss: 0.08426956832408905
step: 170, loss: 0.007948249578475952
step: 180, loss: 0.020092815160751343
step: 190, loss: 0.08593219518661499
step: 200, loss: 0.013235454447567463
step: 210, loss: 0.14879156649112701
step: 220, loss: 0.03183087334036827
step: 230, loss: 0.0980675145983696
step: 240, loss: 0.00858400296419859
step: 250, loss: 0.016388632357120514
step: 260, loss: 0.014619954861700535
step: 270, loss: 0.15719342231750488
step: 280, loss: 0.04360556602478027
step: 290, loss: 0.10166818648576736
step: 300, loss: 0.09913382679224014
step: 310, loss: 0.06337263435125351
step: 320, loss: 0.10541991889476776
step: 330, loss: 0.06431841105222702
step: 340, loss: 0.1089550033211708
step: 350, loss: 0.0148300901055336
step: 360, loss: 0.03322623670101166
step: 370, loss: 0.06133583188056946
step: 380, loss: 0.14112748205661774
step: 390, loss: 0.1373976171016693
step: 400, loss: 0.0522475428879261
step: 410, loss: 0.016867639496922493
step: 420, loss: 0.02163083106279373
step: 430, loss: 0.09970812499523163
step: 440, loss: 0.10478551685810089
step: 450, loss: 0.18059636652469635
step: 460, loss: 0.04802323877811432
step: 470, loss: 0.047967925667762756
step: 480, loss: 0.05321994423866272
step: 490, loss: 0.012102325446903706
step: 500, loss: 0.01184496097266674
step: 510, loss: 0.08632414042949677
step: 520, loss: 0.0996508076786995
step: 530, loss: 0.03632514551281929
step: 540, loss: 0.1055775061249733
step: 550, loss: 0.0077990153804421425
step: 560, loss: 0.11654156446456909
step: 570, loss: 0.10236575454473495
step: 580, loss: 0.030470386147499084
step: 590, loss: 0.031087100505828857
step: 600, loss: 0.009843911044299603
step: 610, loss: 0.047777362167835236
step: 620, loss: 0.08614742755889893
step: 630, loss: 0.05899195000529289
step: 640, loss: 0.03189023956656456
step: 650, loss: 0.0014006776036694646
step: 660, loss: 0.02504589408636093
step: 670, loss: 0.05734582245349884
step: 680, loss: 0.1238437071442604
step: 690, loss: 0.12113926559686661
step: 700, loss: 0.06273636966943741
step: 710, loss: 0.1831115186214447
step: 720, loss: 0.05617334321141243
step: 730, loss: 0.041049644351005554
step: 740, loss: 0.033578772097826004
step: 750, loss: 0.12600231170654297
step: 760, loss: 0.01172315888106823
step: 770, loss: 0.06604573130607605
step: 780, loss: 0.14108578860759735
step: 790, loss: 0.16669374704360962
step: 800, loss: 0.18553008139133453
step: 810, loss: 0.095291368663311
step: 820, loss: 0.13200633227825165
step: 830, loss: 0.029629869386553764
step: 840, loss: 0.12802916765213013
step: 850, loss: 0.02484905533492565
step: 860, loss: 0.21795514225959778
step: 870, loss: 0.012476826086640358
step: 880, loss: 0.061003148555755615
step: 890, loss: 0.12815767526626587
step: 900, loss: 0.10928263515233994
step: 910, loss: 0.06386814266443253
step: 920, loss: 0.18679079413414001
step: 930, loss: 0.07890009135007858
step: 940, loss: 0.02047596126794815
step: 950, loss: 0.1277005821466446
step: 960, loss: 0.0647951140999794
step: 970, loss: 0.11184432357549667
epoch 4: dev_f1=0.9363891487371375, f1=0.9288040949278734, best_f1=0.9350411710887466
step: 0, loss: 0.13864362239837646
step: 10, loss: 0.04404016584157944
step: 20, loss: 0.14620696008205414
step: 30, loss: 0.038209859281778336
step: 40, loss: 0.10008168965578079
step: 50, loss: 0.03886386752128601
step: 60, loss: 0.09691794961690903
step: 70, loss: 0.15493711829185486
step: 80, loss: 0.02919292449951172
step: 90, loss: 0.20826250314712524
step: 100, loss: 0.0545697957277298
step: 110, loss: 0.02528831735253334
step: 120, loss: 0.12526774406433105
step: 130, loss: 0.11876577138900757
step: 140, loss: 0.062059253454208374
step: 150, loss: 0.010586682707071304
step: 160, loss: 0.01886409893631935
step: 170, loss: 0.10875573754310608
step: 180, loss: 0.08995170146226883
step: 190, loss: 0.07475881278514862
step: 200, loss: 0.0708414763212204
step: 210, loss: 0.07735797762870789
step: 220, loss: 0.016730880364775658
step: 230, loss: 0.02725355140864849
step: 240, loss: 0.08324384689331055
step: 250, loss: 0.07151442766189575
step: 260, loss: 0.034615833312273026
step: 270, loss: 0.1061544194817543
step: 280, loss: 0.09919245541095734
step: 290, loss: 0.06545847654342651
step: 300, loss: 0.033071503043174744
step: 310, loss: 0.13760031759738922
step: 320, loss: 0.025798052549362183
step: 330, loss: 0.043559204787015915
step: 340, loss: 0.2069624811410904
step: 350, loss: 0.021857066079974174
step: 360, loss: 0.10631182044744492
step: 370, loss: 0.0697546899318695
step: 380, loss: 0.04775550588965416
step: 390, loss: 0.06485431641340256
step: 400, loss: 0.016400592401623726
step: 410, loss: 0.1099104955792427
step: 420, loss: 0.038498904556035995
step: 430, loss: 0.05646553263068199
step: 440, loss: 0.019611597061157227
step: 450, loss: 0.15557320415973663
step: 460, loss: 0.07681119441986084
step: 470, loss: 0.053146135061979294
step: 480, loss: 0.01984677091240883
step: 490, loss: 0.09045755863189697
step: 500, loss: 0.10181239992380142
step: 510, loss: 0.19558195769786835
step: 520, loss: 0.11775027215480804
step: 530, loss: 0.11807189136743546
step: 540, loss: 0.08369359374046326
step: 550, loss: 0.0866515040397644
step: 560, loss: 0.02600209228694439
step: 570, loss: 0.025117499753832817
step: 580, loss: 0.12958411872386932
step: 590, loss: 0.04508821293711662
step: 600, loss: 0.13108642399311066
step: 610, loss: 0.03001558966934681
step: 620, loss: 0.0960213765501976
step: 630, loss: 0.13233764469623566
step: 640, loss: 0.15821391344070435
step: 650, loss: 0.06423711031675339
step: 660, loss: 0.037938639521598816
step: 670, loss: 0.04000721126794815
step: 680, loss: 0.16729958355426788
step: 690, loss: 0.2446611523628235
step: 700, loss: 0.11573586612939835
step: 710, loss: 0.009227657690644264
step: 720, loss: 0.2815556228160858
step: 730, loss: 0.06844957917928696
step: 740, loss: 0.12866155803203583
step: 750, loss: 0.054369207471609116
step: 760, loss: 0.021961523219943047
step: 770, loss: 0.08259419351816177
step: 780, loss: 0.00663079135119915
step: 790, loss: 0.04302015155553818
step: 800, loss: 0.02101162262260914
step: 810, loss: 0.09749525040388107
step: 820, loss: 0.04698505625128746
step: 830, loss: 0.0260245893150568
step: 840, loss: 0.07605554163455963
step: 850, loss: 0.15583588182926178
step: 860, loss: 0.08778919279575348
step: 870, loss: 0.06276188790798187
step: 880, loss: 0.12057231366634369
step: 890, loss: 0.0068651591427624226
step: 900, loss: 0.12569975852966309
step: 910, loss: 0.2614789605140686
step: 920, loss: 0.08340810239315033
step: 930, loss: 0.08915182948112488
step: 940, loss: 0.01277755293995142
step: 950, loss: 0.06990128755569458
step: 960, loss: 0.0207659974694252
step: 970, loss: 0.02577807754278183
epoch 5: dev_f1=0.9384687646782527, f1=0.9249646059462011, best_f1=0.9249646059462011
step: 0, loss: 0.07620267570018768
step: 10, loss: 0.13299202919006348
step: 20, loss: 0.09186369180679321
step: 30, loss: 0.024786008521914482
step: 40, loss: 0.008862900547683239
step: 50, loss: 0.05822073295712471
step: 60, loss: 0.01794956624507904
step: 70, loss: 5.7812867453321815e-05
step: 80, loss: 0.015866342931985855
step: 90, loss: 0.11529143154621124
step: 100, loss: 0.07758007943630219
step: 110, loss: 0.08634582906961441
step: 120, loss: 0.11846961081027985
step: 130, loss: 0.029920382425189018
step: 140, loss: 0.18061810731887817
step: 150, loss: 0.033412668853998184
step: 160, loss: 0.07483284175395966
step: 170, loss: 0.04074842482805252
step: 180, loss: 0.07666656374931335
step: 190, loss: 0.04812617227435112
step: 200, loss: 0.04636629298329353
step: 210, loss: 0.05986209958791733
step: 220, loss: 0.045856818556785583
step: 230, loss: 0.05880443751811981
step: 240, loss: 0.011622382327914238
step: 250, loss: 0.08816342800855637
step: 260, loss: 0.027261637151241302
step: 270, loss: 0.10826782882213593
step: 280, loss: 0.11868563294410706
step: 290, loss: 0.08516882359981537
step: 300, loss: 0.012060202658176422
step: 310, loss: 0.09980345517396927
step: 320, loss: 0.02329571172595024
step: 330, loss: 0.10957977920770645
step: 340, loss: 0.12019369751214981
step: 350, loss: 0.08506684750318527
step: 360, loss: 0.018994931131601334
step: 370, loss: 0.0427841916680336
step: 380, loss: 0.08059843629598618
step: 390, loss: 0.015030317939817905
step: 400, loss: 0.04087238758802414
step: 410, loss: 0.06672965735197067
step: 420, loss: 0.20141291618347168
step: 430, loss: 0.06713514775037766
step: 440, loss: 0.02091635949909687
step: 450, loss: 0.022152867168188095
step: 460, loss: 0.03306696563959122
step: 470, loss: 0.10265163332223892
step: 480, loss: 0.027689184993505478
step: 490, loss: 0.014489948749542236
step: 500, loss: 0.032530829310417175
step: 510, loss: 0.07759556174278259
step: 520, loss: 0.08019962161779404
step: 530, loss: 0.029054032638669014
step: 540, loss: 0.23575866222381592
step: 550, loss: 0.014586876146495342
step: 560, loss: 0.1075013279914856
step: 570, loss: 0.1395019292831421
step: 580, loss: 0.11538299173116684
step: 590, loss: 0.010387498885393143
step: 600, loss: 0.1102091521024704
step: 610, loss: 0.0651894062757492
step: 620, loss: 0.04775794968008995
step: 630, loss: 0.019375143572688103
step: 640, loss: 0.03494418039917946
step: 650, loss: 0.06762008368968964
step: 660, loss: 0.03210486099123955
step: 670, loss: 0.02852509915828705
step: 680, loss: 0.041743893176317215
step: 690, loss: 0.09132193773984909
step: 700, loss: 0.07131914794445038
step: 710, loss: 0.03577282652258873
step: 720, loss: 0.05371347814798355
step: 730, loss: 0.04007468372583389
step: 740, loss: 0.10882266610860825
step: 750, loss: 0.2219407856464386
step: 760, loss: 0.10428490489721298
step: 770, loss: 0.18484696745872498
step: 780, loss: 0.0319414958357811
step: 790, loss: 0.04866388812661171
step: 800, loss: 0.09160665422677994
step: 810, loss: 0.11358705908060074
step: 820, loss: 0.04285518079996109
step: 830, loss: 0.023317251354455948
step: 840, loss: 0.14191268384456635
step: 850, loss: 0.006424814462661743
step: 860, loss: 0.011855537071824074
step: 870, loss: 0.010857422836124897
step: 880, loss: 0.14043308794498444
step: 890, loss: 0.11191900819540024
step: 900, loss: 0.08260412514209747
step: 910, loss: 0.08117146790027618
step: 920, loss: 0.05204765126109123
step: 930, loss: 0.09786814451217651
step: 940, loss: 0.021849559620022774
step: 950, loss: 0.15362006425857544
step: 960, loss: 0.1085384339094162
step: 970, loss: 0.060679517686367035
epoch 6: dev_f1=0.9345182413470534, f1=0.9296037296037295, best_f1=0.9249646059462011
step: 0, loss: 0.007743204012513161
step: 10, loss: 0.02684910036623478
step: 20, loss: 0.03537476435303688
step: 30, loss: 0.05827329680323601
step: 40, loss: 0.058864764869213104
step: 50, loss: 0.03567633405327797
step: 60, loss: 0.013471793383359909
step: 70, loss: 0.10689032077789307
step: 80, loss: 0.007065985817462206
step: 90, loss: 0.03758472204208374
step: 100, loss: 0.008217252790927887
step: 110, loss: 0.022398989647626877
step: 120, loss: 0.15603749454021454
step: 130, loss: 0.01715955138206482
step: 140, loss: 0.07051882147789001
step: 150, loss: 0.09386176615953445
step: 160, loss: 0.16247199475765228
step: 170, loss: 0.07729870826005936
step: 180, loss: 0.013150186277925968
step: 190, loss: 0.06456679850816727
step: 200, loss: 0.05181269720196724
step: 210, loss: 0.039595067501068115
step: 220, loss: 0.07197513431310654
step: 230, loss: 0.02801598608493805
step: 240, loss: 0.026464976370334625
step: 250, loss: 0.08651147037744522
step: 260, loss: 0.11417508125305176
step: 270, loss: 0.08137689530849457
step: 280, loss: 0.03317984938621521
step: 290, loss: 0.031000731512904167
step: 300, loss: 0.016050375998020172
step: 310, loss: 0.002381281927227974
step: 320, loss: 0.07498469948768616
step: 330, loss: 0.019412491470575333
step: 340, loss: 0.06821778416633606
step: 350, loss: 0.12272399663925171
step: 360, loss: 0.01122350338846445
step: 370, loss: 0.09337058663368225
step: 380, loss: 0.011783267371356487
step: 390, loss: 0.03278156742453575
step: 400, loss: 4.2487368773436174e-05
step: 410, loss: 0.07416363805532455
step: 420, loss: 0.0931469202041626
step: 430, loss: 0.02578873746097088
step: 440, loss: 0.021792329847812653
step: 450, loss: 0.08507576584815979
step: 460, loss: 0.07629291713237762
step: 470, loss: 0.029264602810144424
step: 480, loss: 0.07338512688875198
step: 490, loss: 0.20251333713531494
step: 500, loss: 0.21737338602542877
step: 510, loss: 0.022414932027459145
step: 520, loss: 0.10047047585248947
step: 530, loss: 0.0289516132324934
step: 540, loss: 0.058300912380218506
step: 550, loss: 0.04689405858516693
step: 560, loss: 0.056900084018707275
step: 570, loss: 0.03740275651216507
step: 580, loss: 0.06361755728721619
step: 590, loss: 0.008061978034675121
step: 600, loss: 0.05079090967774391
step: 610, loss: 0.18618395924568176
step: 620, loss: 0.04807720333337784
step: 630, loss: 0.02649201638996601
step: 640, loss: 0.084952712059021
step: 650, loss: 0.0777219831943512
step: 660, loss: 0.019977068528532982
step: 670, loss: 0.08122173696756363
step: 680, loss: 0.055594973266124725
step: 690, loss: 0.014257492497563362
step: 700, loss: 0.025036383420228958
step: 710, loss: 0.28195568919181824
step: 720, loss: 0.051354553550481796
step: 730, loss: 0.04245062917470932
step: 740, loss: 0.044456176459789276
step: 750, loss: 0.0038252677768468857
step: 760, loss: 0.19129708409309387
step: 770, loss: 0.12212318181991577
step: 780, loss: 0.01514491904526949
step: 790, loss: 0.0262301005423069
step: 800, loss: 0.11992350965738297
step: 810, loss: 0.15863771736621857
step: 820, loss: 0.15373583137989044
step: 830, loss: 0.2375679910182953
step: 840, loss: 0.06078575924038887
step: 850, loss: 0.023137856274843216
step: 860, loss: 0.03221282362937927
step: 870, loss: 0.08624416589736938
step: 880, loss: 0.02749931439757347
step: 890, loss: 0.01568489521741867
step: 900, loss: 0.013890976086258888
step: 910, loss: 0.07016913592815399
step: 920, loss: 0.11198139190673828
step: 930, loss: 0.10895248502492905
step: 940, loss: 0.09750716388225555
step: 950, loss: 0.022927934303879738
step: 960, loss: 0.1562090367078781
step: 970, loss: 0.019275492057204247
epoch 7: dev_f1=0.933774834437086, f1=0.9251893939393939, best_f1=0.9249646059462011
step: 0, loss: 0.04624825343489647
step: 10, loss: 0.0616435669362545
step: 20, loss: 0.04591602087020874
step: 30, loss: 0.03218986093997955
step: 40, loss: 0.010713424533605576
step: 50, loss: 0.11568984389305115
step: 60, loss: 0.07237591594457626
step: 70, loss: 0.10193102061748505
step: 80, loss: 0.0527215413749218
step: 90, loss: 0.05141794681549072
step: 100, loss: 0.04659237712621689
step: 110, loss: 0.06759048998355865
step: 120, loss: 0.052956901490688324
step: 130, loss: 0.14514930546283722
step: 140, loss: 0.037509407848119736
step: 150, loss: 0.0958244651556015
step: 160, loss: 0.046281639486551285
step: 170, loss: 0.06504973769187927
step: 180, loss: 0.050453703850507736
step: 190, loss: 0.005188011564314365
step: 200, loss: 0.16082477569580078
step: 210, loss: 0.0602434016764164
step: 220, loss: 0.1615360528230667
step: 230, loss: 0.06733638048171997
step: 240, loss: 0.06362481415271759
step: 250, loss: 0.027903448790311813
step: 260, loss: 0.004914076998829842
step: 270, loss: 0.172184020280838
step: 280, loss: 0.016393858939409256
step: 290, loss: 0.04213305935263634
step: 300, loss: 0.03284284472465515
step: 310, loss: 0.006610128562897444
step: 320, loss: 0.014466210268437862
step: 330, loss: 0.12098424881696701
step: 340, loss: 0.01895710453391075
step: 350, loss: 0.07046109437942505
step: 360, loss: 0.14289206266403198
step: 370, loss: 0.030039742588996887
step: 380, loss: 0.00011311440175632015
step: 390, loss: 0.06332210451364517
step: 400, loss: 0.049574583768844604
step: 410, loss: 0.09177576005458832
step: 420, loss: 0.03288522735238075
step: 430, loss: 0.028061041608452797
step: 440, loss: 0.04896451532840729
step: 450, loss: 0.02922539785504341
step: 460, loss: 0.08917839080095291
step: 470, loss: 0.11405958980321884
step: 480, loss: 0.16022445261478424
step: 490, loss: 0.05823707953095436
step: 500, loss: 0.03997291997075081
step: 510, loss: 0.07659994810819626
step: 520, loss: 0.02822403609752655
step: 530, loss: 0.09973003715276718
step: 540, loss: 0.05550358071923256
step: 550, loss: 0.02365082874894142
step: 560, loss: 0.041220299899578094
step: 570, loss: 0.00787607952952385
step: 580, loss: 0.054544445127248764
step: 590, loss: 0.003916477784514427
step: 600, loss: 0.0342768169939518
step: 610, loss: 0.004781555850058794
step: 620, loss: 0.11165343970060349
step: 630, loss: 0.025353409349918365
step: 640, loss: 0.13910086452960968
step: 650, loss: 0.04383402317762375
step: 660, loss: 0.04507029056549072
step: 670, loss: 0.02373351901769638
step: 680, loss: 0.0020122267305850983
step: 690, loss: 0.08970247954130173
step: 700, loss: 0.12468957901000977
step: 710, loss: 0.018786201253533363
step: 720, loss: 0.11690277606248856
step: 730, loss: 0.16611376404762268
step: 740, loss: 0.020183734595775604
step: 750, loss: 0.052434250712394714
step: 760, loss: 0.015107356011867523
step: 770, loss: 0.015561986714601517
step: 780, loss: 0.01550390012562275
step: 790, loss: 0.018502401188015938
step: 800, loss: 0.03196517378091812
step: 810, loss: 0.11511684209108353
step: 820, loss: 0.13943974673748016
step: 830, loss: 0.1354699730873108
step: 840, loss: 0.04681912809610367
step: 850, loss: 0.0632082149386406
step: 860, loss: 0.18796120584011078
step: 870, loss: 0.10946586728096008
step: 880, loss: 0.004518995527178049
step: 890, loss: 0.15702106058597565
step: 900, loss: 0.10983119904994965
step: 910, loss: 0.23381805419921875
step: 920, loss: 0.00972584169358015
step: 930, loss: 0.0035874159075319767
step: 940, loss: 0.03826574608683586
step: 950, loss: 0.06419161707162857
step: 960, loss: 0.02062162198126316
step: 970, loss: 0.035840071737766266
epoch 8: dev_f1=0.9407925407925408, f1=0.9376163873370577, best_f1=0.9376163873370577
step: 0, loss: 0.0024287295527756214
step: 10, loss: 0.05787406489253044
step: 20, loss: 0.07081104069948196
step: 30, loss: 0.04158077761530876
step: 40, loss: 0.01059019099920988
step: 50, loss: 0.13417252898216248
step: 60, loss: 0.01994173415005207
step: 70, loss: 0.04791063442826271
step: 80, loss: 0.03725307062268257
step: 90, loss: 0.07301799207925797
step: 100, loss: 0.08297263085842133
step: 110, loss: 0.02857564203441143
step: 120, loss: 0.08867426961660385
step: 130, loss: 0.025790708139538765
step: 140, loss: 0.005332297645509243
step: 150, loss: 0.029487911611795425
step: 160, loss: 0.027488965541124344
step: 170, loss: 0.01602615788578987
step: 180, loss: 0.011481083929538727
step: 190, loss: 0.04513697698712349
step: 200, loss: 0.006074775941669941
step: 210, loss: 0.010822607204318047
step: 220, loss: 0.13580185174942017
step: 230, loss: 0.07463260740041733
step: 240, loss: 0.012004689313471317
step: 250, loss: 0.036076512187719345
step: 260, loss: 0.0857761800289154
step: 270, loss: 0.07599422335624695
step: 280, loss: 0.030159195885062218
step: 290, loss: 0.08456502854824066
step: 300, loss: 0.10550802201032639
step: 310, loss: 0.07798536866903305
step: 320, loss: 0.09656496345996857
step: 330, loss: 0.07274089008569717
step: 340, loss: 0.05968094617128372
step: 350, loss: 0.1351415067911148
step: 360, loss: 0.005619245581328869
step: 370, loss: 0.029574763029813766
step: 380, loss: 0.04401421174407005
step: 390, loss: 0.037471819669008255
step: 400, loss: 0.031633611768484116
step: 410, loss: 0.06712884455919266
step: 420, loss: 0.17899000644683838
step: 430, loss: 0.004742320626974106
step: 440, loss: 0.01824597455561161
step: 450, loss: 0.11447963118553162
step: 460, loss: 0.052173685282468796
step: 470, loss: 0.05513365566730499
step: 480, loss: 0.04199919477105141
step: 490, loss: 0.005436933599412441
step: 500, loss: 0.07282993197441101
step: 510, loss: 0.030511926859617233
step: 520, loss: 0.165351003408432
step: 530, loss: 0.01544981636106968
step: 540, loss: 0.042000360786914825
step: 550, loss: 0.062232937663793564
step: 560, loss: 0.08857227861881256
step: 570, loss: 0.06193169951438904
step: 580, loss: 0.11887885630130768
step: 590, loss: 0.02262924425303936
step: 600, loss: 0.0106600821018219
step: 610, loss: 0.04899519681930542
step: 620, loss: 0.02451811544597149
step: 630, loss: 0.1160137802362442
step: 640, loss: 0.12086623162031174
step: 650, loss: 0.07981579005718231
step: 660, loss: 0.022346744313836098
step: 670, loss: 0.014687011018395424
step: 680, loss: 0.1069062277674675
step: 690, loss: 4.050868301419541e-05
step: 700, loss: 0.007827366702258587
step: 710, loss: 0.044568076729774475
step: 720, loss: 0.03591218218207359
step: 730, loss: 0.05447257682681084
step: 740, loss: 0.21735002100467682
step: 750, loss: 0.019721049815416336
step: 760, loss: 0.043992117047309875
step: 770, loss: 0.08050133287906647
step: 780, loss: 0.023865101858973503
step: 790, loss: 0.16073942184448242
step: 800, loss: 0.04862140864133835
step: 810, loss: 0.14747880399227142
step: 820, loss: 0.040918298065662384
step: 830, loss: 0.08225950598716736
step: 840, loss: 0.021280307322740555
step: 850, loss: 0.07298846542835236
step: 860, loss: 0.008947337046265602
step: 870, loss: 0.13705062866210938
step: 880, loss: 0.07363846898078918
step: 890, loss: 0.06127789616584778
step: 900, loss: 0.02921636588871479
step: 910, loss: 0.005638778209686279
step: 920, loss: 0.10939738154411316
step: 930, loss: 0.018076693639159203
step: 940, loss: 0.11082920432090759
step: 950, loss: 0.00047503490350209177
step: 960, loss: 0.10154705494642258
step: 970, loss: 0.03937768563628197
epoch 9: dev_f1=0.9442379182156133, f1=0.9304267161410019, best_f1=0.9304267161410019
step: 0, loss: 0.0519050732254982
step: 10, loss: 0.057973090559244156
step: 20, loss: 0.04811502620577812
step: 30, loss: 0.02002447098493576
step: 40, loss: 0.03626685217022896
step: 50, loss: 0.052055057138204575
step: 60, loss: 0.032037731260061264
step: 70, loss: 0.03652660548686981
step: 80, loss: 0.03892451152205467
step: 90, loss: 0.021113943308591843
step: 100, loss: 0.03572867810726166
step: 110, loss: 0.0032752137631177902
step: 120, loss: 0.06075369566679001
step: 130, loss: 0.05491117760539055
step: 140, loss: 0.0982789397239685
step: 150, loss: 0.02846839465200901
step: 160, loss: 0.09313634037971497
step: 170, loss: 0.028260838240385056
step: 180, loss: 0.016997601836919785
step: 190, loss: 0.004342156928032637
step: 200, loss: 0.09352503716945648
step: 210, loss: 0.027680201455950737
step: 220, loss: 0.022814761847257614
step: 230, loss: 0.03204014524817467
step: 240, loss: 0.03262718394398689
step: 250, loss: 0.014817263931035995
step: 260, loss: 0.08127076923847198
step: 270, loss: 0.04662337526679039
step: 280, loss: 0.09342774748802185
step: 290, loss: 0.08225273340940475
step: 300, loss: 0.0958702564239502
step: 310, loss: 0.060075219720602036
step: 320, loss: 0.007637512870132923
step: 330, loss: 0.08694952726364136
step: 340, loss: 0.059699587523937225
step: 350, loss: 0.03689398989081383
step: 360, loss: 0.07402351498603821
step: 370, loss: 0.018271729350090027
step: 380, loss: 0.04058113694190979
step: 390, loss: 0.08005879074335098
step: 400, loss: 0.05745210126042366
step: 410, loss: 0.015926498919725418
step: 420, loss: 0.025336436927318573
step: 430, loss: 0.0816529169678688
step: 440, loss: 0.08983472734689713
step: 450, loss: 0.09465859830379486
step: 460, loss: 0.0459112785756588
step: 470, loss: 0.02019537054002285
step: 480, loss: 0.08362457156181335
step: 490, loss: 0.018493976444005966
step: 500, loss: 0.10456529259681702
step: 510, loss: 0.03278219327330589
step: 520, loss: 0.011064660735428333
step: 530, loss: 0.03915608301758766
step: 540, loss: 0.04694053530693054
step: 550, loss: 0.09566948562860489
step: 560, loss: 0.12460289150476456
step: 570, loss: 0.057840753346681595
step: 580, loss: 0.005758537445217371
step: 590, loss: 0.023227659985423088
step: 600, loss: 0.04648395627737045
step: 610, loss: 0.038196269422769547
step: 620, loss: 0.007934077642858028
step: 630, loss: 0.13335436582565308
step: 640, loss: 0.02250772714614868
step: 650, loss: 0.08592241257429123
step: 660, loss: 0.018949981778860092
step: 670, loss: 0.008117128163576126
step: 680, loss: 0.07048017531633377
step: 690, loss: 0.009829538874328136
step: 700, loss: 0.02543414942920208
step: 710, loss: 0.10557524859905243
step: 720, loss: 0.04699805751442909
step: 730, loss: 0.06712784618139267
step: 740, loss: 0.01250274758785963
step: 750, loss: 0.0819791927933693
step: 760, loss: 0.027278896421194077
step: 770, loss: 0.040103401988744736
step: 780, loss: 0.02647504210472107
step: 790, loss: 0.061591096222400665
step: 800, loss: 0.0433153361082077
step: 810, loss: 0.003544269595295191
step: 820, loss: 0.12377963960170746
step: 830, loss: 0.027281930670142174
step: 840, loss: 0.09990238398313522
step: 850, loss: 0.12801221013069153
step: 860, loss: 0.051938045769929886
step: 870, loss: 0.030149230733513832
step: 880, loss: 0.06771434843540192
step: 890, loss: 0.06009784713387489
step: 900, loss: 0.03524944558739662
step: 910, loss: 0.03866174817085266
step: 920, loss: 0.013034740462899208
step: 930, loss: 0.005709825083613396
step: 940, loss: 0.051094915717840195
step: 950, loss: 0.08303100615739822
step: 960, loss: 0.011865882202982903
step: 970, loss: 0.007325202692300081
epoch 10: dev_f1=0.9393090569561158, f1=0.9340148698884759, best_f1=0.9304267161410019
step: 0, loss: 0.0048385318368673325
step: 10, loss: 0.019316652789711952
step: 20, loss: 0.040747661143541336
step: 30, loss: 0.1288364827632904
step: 40, loss: 0.02873014099895954
step: 50, loss: 0.04727570712566376
step: 60, loss: 0.035631462931632996
step: 70, loss: 0.05826658383011818
step: 80, loss: 0.026229828596115112
step: 90, loss: 0.04343348741531372
step: 100, loss: 0.0012155268341302872
step: 110, loss: 0.010640115477144718
step: 120, loss: 0.05903216078877449
step: 130, loss: 0.00849421601742506
step: 140, loss: 0.0024797457735985518
step: 150, loss: 0.04878953471779823
step: 160, loss: 0.0759330689907074
step: 170, loss: 0.01295545045286417
step: 180, loss: 0.013042701408267021
step: 190, loss: 0.025613432750105858
step: 200, loss: 0.003355080960318446
step: 210, loss: 0.018816044554114342
step: 220, loss: 0.023700661957263947
step: 230, loss: 0.0037768317852169275
step: 240, loss: 0.00279672141186893
step: 250, loss: 0.039891764521598816
step: 260, loss: 0.0024662758223712444
step: 270, loss: 0.029351135715842247
step: 280, loss: 0.010379188694059849
step: 290, loss: 0.03600498288869858
step: 300, loss: 0.0009340046090073884
step: 310, loss: 0.07375640422105789
step: 320, loss: 0.08992274850606918
step: 330, loss: 0.006129371002316475
step: 340, loss: 0.020489826798439026
step: 350, loss: 0.022387662902474403
step: 360, loss: 0.05187750607728958
step: 370, loss: 0.039213478565216064
step: 380, loss: 0.0043382542207837105
step: 390, loss: 0.01724950596690178
step: 400, loss: 0.004741027019917965
step: 410, loss: 0.10433873534202576
step: 420, loss: 0.07307834923267365
step: 430, loss: 0.040312759578228
step: 440, loss: 0.1664327085018158
step: 450, loss: 0.02062874846160412
step: 460, loss: 0.054917044937610626
step: 470, loss: 0.18489035964012146
step: 480, loss: 0.010978508740663528
step: 490, loss: 0.03145245835185051
step: 500, loss: 0.04212826117873192
step: 510, loss: 0.08820582181215286
step: 520, loss: 0.040177613496780396
step: 530, loss: 0.08261847496032715
step: 540, loss: 0.15049049258232117
step: 550, loss: 0.1268627792596817
step: 560, loss: 0.006299213040620089
step: 570, loss: 0.02353847399353981
step: 580, loss: 0.0017483029514551163
step: 590, loss: 0.04532960429787636
step: 600, loss: 0.001794658717699349
step: 610, loss: 0.022519772872328758
step: 620, loss: 0.03369521349668503
step: 630, loss: 0.06018867343664169
step: 640, loss: 0.0898212268948555
step: 650, loss: 0.024321021512150764
step: 660, loss: 0.06225608289241791
step: 670, loss: 0.011634495109319687
step: 680, loss: 0.06323421001434326
step: 690, loss: 0.0028917109593749046
step: 700, loss: 0.12147285789251328
step: 710, loss: 0.013806166127324104
step: 720, loss: 0.03576581925153732
step: 730, loss: 0.09744665771722794
step: 740, loss: 0.010814150795340538
step: 750, loss: 0.007284722290933132
step: 760, loss: 0.014119504019618034
step: 770, loss: 0.011493399739265442
step: 780, loss: 0.06892400979995728
step: 790, loss: 0.020238704979419708
step: 800, loss: 0.00921451486647129
step: 810, loss: 0.005072304978966713
step: 820, loss: 0.08876411616802216
step: 830, loss: 0.06855804473161697
step: 840, loss: 0.0795421451330185
step: 850, loss: 0.061659276485443115
step: 860, loss: 0.013112377375364304
step: 870, loss: 0.0007498471532016993
step: 880, loss: 0.13611607253551483
step: 890, loss: 0.021550238132476807
step: 900, loss: 0.028201624751091003
step: 910, loss: 0.05429812893271446
step: 920, loss: 0.04462572559714317
step: 930, loss: 0.05559071898460388
step: 940, loss: 0.10931823402643204
step: 950, loss: 0.037386078387498856
step: 960, loss: 0.0887271985411644
step: 970, loss: 0.09459008276462555
epoch 11: dev_f1=0.9330188679245284, f1=0.9232954545454546, best_f1=0.9304267161410019
step: 0, loss: 0.104776531457901
step: 10, loss: 0.006245918571949005
step: 20, loss: 0.01075900811702013
step: 30, loss: 0.027676183730363846
step: 40, loss: 0.022994404658675194
step: 50, loss: 0.04241502657532692
step: 60, loss: 0.04972332715988159
step: 70, loss: 0.015169003047049046
step: 80, loss: 0.05692463368177414
step: 90, loss: 0.015748994424939156
step: 100, loss: 0.01907479204237461
step: 110, loss: 0.0006879961583763361
step: 120, loss: 0.0014854787150397897
step: 130, loss: 0.022952020168304443
step: 140, loss: 0.09283263236284256
step: 150, loss: 0.11994440108537674
step: 160, loss: 0.03950940817594528
step: 170, loss: 0.04984600096940994
step: 180, loss: 0.05316977575421333
step: 190, loss: 0.020477289333939552
step: 200, loss: 0.024687519297003746
step: 210, loss: 0.03524889051914215
step: 220, loss: 0.01833336614072323
step: 230, loss: 0.02599705383181572
step: 240, loss: 0.0199130792170763
step: 250, loss: 0.05122288316488266
step: 260, loss: 0.04672888293862343
step: 270, loss: 0.04065762087702751
step: 280, loss: 0.04082239046692848
step: 290, loss: 0.013190008699893951
step: 300, loss: 0.09797503799200058
step: 310, loss: 0.09032970666885376
step: 320, loss: 0.038385238498449326
step: 330, loss: 0.04063340276479721
step: 340, loss: 0.023664651438593864
step: 350, loss: 0.027754466980695724
step: 360, loss: 0.01666470430791378
step: 370, loss: 0.07644432038068771
step: 380, loss: 0.002411388326436281
step: 390, loss: 0.13695991039276123
step: 400, loss: 0.08480435609817505
step: 410, loss: 0.0845978781580925
step: 420, loss: 0.005086892284452915
step: 430, loss: 0.0003041103482246399
step: 440, loss: 0.002366944681853056
step: 450, loss: 0.0009310286259278655
step: 460, loss: 0.1001560315489769
step: 470, loss: 0.020488016307353973
step: 480, loss: 0.005267145577818155
step: 490, loss: 0.0039048749022185802
step: 500, loss: 0.03812529146671295
step: 510, loss: 0.0038118199445307255
step: 520, loss: 0.06294896453619003
step: 530, loss: 0.05371999368071556
step: 540, loss: 0.08336218446493149
step: 550, loss: 0.09024176001548767
step: 560, loss: 0.04867912828922272
step: 570, loss: 0.19372999668121338
step: 580, loss: 0.0006228665006347001
step: 590, loss: 0.054201412945985794
step: 600, loss: 0.002501007402315736
step: 610, loss: 0.043230846524238586
step: 620, loss: 0.02363298460841179
step: 630, loss: 0.06384006142616272
step: 640, loss: 0.02669270895421505
step: 650, loss: 0.006535391788929701
step: 660, loss: 0.052042752504348755
step: 670, loss: 0.001614919281564653
step: 680, loss: 0.10367738455533981
step: 690, loss: 0.045897629112005234
step: 700, loss: 0.07895950227975845
step: 710, loss: 0.07300816476345062
step: 720, loss: 0.07475458830595016
step: 730, loss: 0.07030195742845535
step: 740, loss: 0.024712473154067993
step: 750, loss: 0.019640430808067322
step: 760, loss: 0.010460997931659222
step: 770, loss: 0.03838988021016121
step: 780, loss: 0.02998829074203968
step: 790, loss: 0.024050284177064896
step: 800, loss: 0.06522971391677856
step: 810, loss: 0.03524557128548622
step: 820, loss: 0.005372015759348869
step: 830, loss: 0.048822976648807526
step: 840, loss: 0.05620140954852104
step: 850, loss: 0.05506544187664986
step: 860, loss: 0.07256843894720078
step: 870, loss: 0.009445397183299065
step: 880, loss: 0.04474025219678879
step: 890, loss: 0.08175225555896759
step: 900, loss: 0.03914813697338104
step: 910, loss: 0.05129200965166092
step: 920, loss: 0.06077231839299202
step: 930, loss: 0.09514933824539185
step: 940, loss: 0.020339276641607285
step: 950, loss: 0.05854344740509987
step: 960, loss: 1.6614110791124403e-05
step: 970, loss: 0.05655297264456749
epoch 12: dev_f1=0.9366034243405831, f1=0.9340761374187557, best_f1=0.9304267161410019
step: 0, loss: 0.025232767686247826
step: 10, loss: 0.04578550532460213
step: 20, loss: 0.033129140734672546
step: 30, loss: 0.08485686779022217
step: 40, loss: 0.14172953367233276
step: 50, loss: 0.0006912817480042577
step: 60, loss: 0.0030672012362629175
step: 70, loss: 0.05849799886345863
step: 80, loss: 0.0022544730454683304
step: 90, loss: 0.07538390159606934
step: 100, loss: 0.09508614242076874
step: 110, loss: 0.02722330391407013
step: 120, loss: 0.04431871324777603
step: 130, loss: 0.049930885434150696
step: 140, loss: 0.06646621972322464
step: 150, loss: 0.04009755328297615
step: 160, loss: 0.18361704051494598
step: 170, loss: 0.0019550910219550133
step: 180, loss: 0.028957216069102287
step: 190, loss: 0.08110079914331436
step: 200, loss: 0.050454653799533844
step: 210, loss: 0.028496799990534782
step: 220, loss: 0.0328509658575058
step: 230, loss: 0.061928533017635345
step: 240, loss: 0.033682286739349365
step: 250, loss: 0.06813888251781464
step: 260, loss: 0.02264316752552986
step: 270, loss: 0.0791875347495079
step: 280, loss: 0.03177553787827492
step: 290, loss: 0.006292631383985281
step: 300, loss: 0.0006279161316342652
step: 310, loss: 0.0014702719636261463
step: 320, loss: 0.06949172168970108
step: 330, loss: 0.01699221320450306
step: 340, loss: 0.07938244193792343
step: 350, loss: 0.030983824282884598
step: 360, loss: 0.011428081430494785
step: 370, loss: 0.045916348695755005
step: 380, loss: 0.03716636449098587
step: 390, loss: 0.024907805025577545
step: 400, loss: 0.031608302146196365
step: 410, loss: 0.0034044114872813225
step: 420, loss: 0.11074332892894745
step: 430, loss: 0.04277576506137848
step: 440, loss: 0.02122216857969761
step: 450, loss: 0.008497286587953568
step: 460, loss: 0.0007160275708884001
step: 470, loss: 0.03708144649863243
step: 480, loss: 0.010796328075230122
step: 490, loss: 0.0163949616253376
step: 500, loss: 0.036591894924640656
step: 510, loss: 0.08590418100357056
step: 520, loss: 0.029045604169368744
step: 530, loss: 0.03585776686668396
step: 540, loss: 0.0010828202357515693
step: 550, loss: 0.0006147984531708062
step: 560, loss: 0.09608038514852524
step: 570, loss: 0.11465691775083542
step: 580, loss: 0.10729977488517761
step: 590, loss: 0.014980712905526161
step: 600, loss: 0.07535392791032791
step: 610, loss: 0.02347642369568348
step: 620, loss: 0.01809249259531498
step: 630, loss: 0.023251643404364586
step: 640, loss: 0.03182343766093254
step: 650, loss: 0.011282378807663918
step: 660, loss: 0.0995686799287796
step: 670, loss: 0.00012788442836608738
step: 680, loss: 0.02926485985517502
step: 690, loss: 0.039694443345069885
step: 700, loss: 0.022033721208572388
step: 710, loss: 0.07196004688739777
step: 720, loss: 0.015352758578956127
step: 730, loss: 0.0006264621624723077
step: 740, loss: 0.06812641769647598
step: 750, loss: 0.015623009763658047
step: 760, loss: 0.002900059102103114
step: 770, loss: 0.0359545536339283
step: 780, loss: 0.07099898904561996
step: 790, loss: 0.1072840541601181
step: 800, loss: 0.08947336673736572
step: 810, loss: 0.09572634845972061
step: 820, loss: 0.0005877716466784477
step: 830, loss: 0.10441721975803375
step: 840, loss: 0.08301489055156708
step: 850, loss: 0.09706129878759384
step: 860, loss: 0.0010755734983831644
step: 870, loss: 0.08120784163475037
step: 880, loss: 0.03522634878754616
step: 890, loss: 0.013392690569162369
step: 900, loss: 0.043537963181734085
step: 910, loss: 0.0019987388513982296
step: 920, loss: 0.004886611830443144
step: 930, loss: 0.012790704146027565
step: 940, loss: 0.04181374981999397
step: 950, loss: 0.030751517042517662
step: 960, loss: 0.056488581001758575
step: 970, loss: 0.050768621265888214
epoch 13: dev_f1=0.9310504396112911, f1=0.9315448658649398, best_f1=0.9304267161410019
step: 0, loss: 0.03801944479346275
step: 10, loss: 0.06276439875364304
step: 20, loss: 0.04857572540640831
step: 30, loss: 0.02181776612997055
step: 40, loss: 7.597196963615716e-05
step: 50, loss: 0.06165139377117157
step: 60, loss: 0.014155504293739796
step: 70, loss: 0.0001381407491862774
step: 80, loss: 0.08577145636081696
step: 90, loss: 0.029289042577147484
step: 100, loss: 0.05914276838302612
step: 110, loss: 0.06201137974858284
step: 120, loss: 0.00010421091428725049
step: 130, loss: 8.224764314945787e-05
step: 140, loss: 0.0566105917096138
step: 150, loss: 0.027545349672436714
step: 160, loss: 0.03853720426559448
step: 170, loss: 0.13741102814674377
step: 180, loss: 0.09112107753753662
step: 190, loss: 0.021615220233798027
step: 200, loss: 0.024014627560973167
step: 210, loss: 0.00012999839964322746
step: 220, loss: 0.02144765295088291
step: 230, loss: 0.07784673571586609
step: 240, loss: 0.044300518929958344
step: 250, loss: 0.03846941888332367
step: 260, loss: 0.050835251808166504
step: 270, loss: 0.05369944125413895
step: 280, loss: 0.032282084226608276
step: 290, loss: 0.04095503315329552
step: 300, loss: 0.00044443324441090226
step: 310, loss: 0.06868857145309448
step: 320, loss: 0.008806229569017887
step: 330, loss: 0.016001438722014427
step: 340, loss: 0.027174796909093857
step: 350, loss: 0.028415342792868614
step: 360, loss: 0.02924492582678795
step: 370, loss: 0.039904721081256866
step: 380, loss: 0.022116564214229584
step: 390, loss: 0.020719880238175392
step: 400, loss: 0.00020233183749951422
step: 410, loss: 0.02283267304301262
step: 420, loss: 0.0019628775771707296
step: 430, loss: 0.026457644999027252
step: 440, loss: 0.014855420216917992
step: 450, loss: 0.02591734379529953
step: 460, loss: 0.0449371263384819
step: 470, loss: 0.06316564232110977
step: 480, loss: 0.07547853887081146
step: 490, loss: 0.07236798107624054
step: 500, loss: 0.06791171431541443
step: 510, loss: 0.024330997839570045
step: 520, loss: 0.025994211435317993
step: 530, loss: 0.10162921249866486
step: 540, loss: 0.00022627455473411828
step: 550, loss: 0.0019192695617675781
step: 560, loss: 0.0012802522396668792
step: 570, loss: 0.09404537826776505
step: 580, loss: 0.0007334284018725157
step: 590, loss: 0.010970201343297958
step: 600, loss: 0.01154806837439537
step: 610, loss: 0.06993743032217026
step: 620, loss: 0.07190563529729843
step: 630, loss: 0.05417577922344208
step: 640, loss: 0.025859471410512924
step: 650, loss: 0.027620088309049606
step: 660, loss: 0.0025647873990237713
step: 670, loss: 0.00014717986050527543
step: 680, loss: 0.035697758197784424
step: 690, loss: 2.651754221005831e-05
step: 700, loss: 0.05883775278925896
step: 710, loss: 0.07501659542322159
step: 720, loss: 0.08394487202167511
step: 730, loss: 0.00501648336648941
step: 740, loss: 0.040184710174798965
step: 750, loss: 0.03039323166012764
step: 760, loss: 0.054220397025346756
step: 770, loss: 0.047139182686805725
step: 780, loss: 0.015396472066640854
step: 790, loss: 0.014339929446578026
step: 800, loss: 0.07719489187002182
step: 810, loss: 0.037319641560316086
step: 820, loss: 0.031285062432289124
step: 830, loss: 0.04993622004985809
step: 840, loss: 0.04270230978727341
step: 850, loss: 0.13841857016086578
step: 860, loss: 0.021824223920702934
step: 870, loss: 0.050110407173633575
step: 880, loss: 0.053939685225486755
step: 890, loss: 0.08586141467094421
step: 900, loss: 0.15637432038784027
step: 910, loss: 0.037067610770463943
step: 920, loss: 0.005057955160737038
step: 930, loss: 0.07099731266498566
step: 940, loss: 0.00968705303966999
step: 950, loss: 0.0501917265355587
step: 960, loss: 0.06293406337499619
step: 970, loss: 0.026725225150585175
epoch 14: dev_f1=0.9361900326036331, f1=0.9327731092436975, best_f1=0.9304267161410019
step: 0, loss: 0.045902375131845474
step: 10, loss: 0.02301907353103161
step: 20, loss: 0.06072455272078514
step: 30, loss: 0.007252563256770372
step: 40, loss: 0.015667548403143883
step: 50, loss: 0.038351502269506454
step: 60, loss: 0.020271433517336845
step: 70, loss: 0.025098038837313652
step: 80, loss: 3.807739994954318e-05
step: 90, loss: 0.03905913606286049
step: 100, loss: 0.06852493435144424
step: 110, loss: 0.0011543615255504847
step: 120, loss: 0.10627633333206177
step: 130, loss: 0.030491119250655174
step: 140, loss: 0.0676376149058342
step: 150, loss: 0.14651106297969818
step: 160, loss: 0.023842524737119675
step: 170, loss: 0.033885639160871506
step: 180, loss: 0.15406890213489532
step: 190, loss: 0.015722917392849922
step: 200, loss: 0.05170619860291481
step: 210, loss: 0.09792076796293259
step: 220, loss: 0.06015462800860405
step: 230, loss: 0.017361203208565712
step: 240, loss: 0.023952512070536613
step: 250, loss: 0.039617668837308884
step: 260, loss: 0.09790556877851486
step: 270, loss: 1.1067771993111819e-05
step: 280, loss: 0.005456726998090744
step: 290, loss: 0.09741348028182983
step: 300, loss: 0.01352129876613617
step: 310, loss: 0.0011475253850221634
step: 320, loss: 0.03396245837211609
step: 330, loss: 0.05464426428079605
step: 340, loss: 8.031325705815107e-05
step: 350, loss: 0.06557982414960861
step: 360, loss: 0.020191505551338196
step: 370, loss: 0.04148148000240326
step: 380, loss: 0.033106110990047455
step: 390, loss: 0.1209249272942543
step: 400, loss: 0.07240703701972961
step: 410, loss: 0.017737912014126778
step: 420, loss: 0.042767688632011414
step: 430, loss: 0.02197873964905739
step: 440, loss: 0.0003584866935852915
step: 450, loss: 0.0673532709479332
step: 460, loss: 0.0361093170940876
step: 470, loss: 0.0022729223128408194
step: 480, loss: 0.008709181100130081
step: 490, loss: 5.318734110915102e-05
step: 500, loss: 0.01286384928971529
step: 510, loss: 5.130268255015835e-05
step: 520, loss: 0.012718246318399906
step: 530, loss: 0.030703097581863403
step: 540, loss: 0.025612827390432358
step: 550, loss: 0.04817379266023636
step: 560, loss: 0.017512360587716103
step: 570, loss: 0.00038739797309972346
step: 580, loss: 0.06360126286745071
step: 590, loss: 0.02033502422273159
step: 600, loss: 0.03837638720870018
step: 610, loss: 0.019747992977499962
step: 620, loss: 0.01484966091811657
step: 630, loss: 0.0009239022620022297
step: 640, loss: 0.0014598218258470297
step: 650, loss: 0.06332509964704514
step: 660, loss: 0.030444826930761337
step: 670, loss: 0.07132793962955475
step: 680, loss: 4.0756884118309245e-05
step: 690, loss: 0.004083852283656597
step: 700, loss: 0.18432201445102692
step: 710, loss: 0.02758743427693844
step: 720, loss: 0.002910803072154522
step: 730, loss: 2.2193216864252463e-05
step: 740, loss: 0.03278917819261551
step: 750, loss: 0.00022234236530493945
step: 760, loss: 0.025920428335666656
step: 770, loss: 0.05443846434354782
step: 780, loss: 0.024239884689450264
step: 790, loss: 0.008090575225651264
step: 800, loss: 0.022444898262619972
step: 810, loss: 0.032603878527879715
step: 820, loss: 0.03525301814079285
step: 830, loss: 0.023157235234975815
step: 840, loss: 0.016608286648988724
step: 850, loss: 0.047410331666469574
step: 860, loss: 0.027022307738661766
step: 870, loss: 0.042547132819890976
step: 880, loss: 0.025967296212911606
step: 890, loss: 0.05248194560408592
step: 900, loss: 0.032247260212898254
step: 910, loss: 0.021399255841970444
step: 920, loss: 0.01606728509068489
step: 930, loss: 0.008825650438666344
step: 940, loss: 0.013135344721376896
step: 950, loss: 0.06560318171977997
step: 960, loss: 0.044431835412979126
step: 970, loss: 0.0018371297046542168
epoch 15: dev_f1=0.9368863955119214, f1=0.9341429238673518, best_f1=0.9304267161410019
step: 0, loss: 0.1382656991481781
step: 10, loss: 0.07426497340202332
step: 20, loss: 0.02154391258955002
step: 30, loss: 0.02345956303179264
step: 40, loss: 0.028183236718177795
step: 50, loss: 0.03427881374955177
step: 60, loss: 0.0986899584531784
step: 70, loss: 0.06373900175094604
step: 80, loss: 0.07431578636169434
step: 90, loss: 0.03876546025276184
step: 100, loss: 0.006636517122387886
step: 110, loss: 0.07234576344490051
step: 120, loss: 0.018955092877149582
step: 130, loss: 0.10500358790159225
step: 140, loss: 0.017906051129102707
step: 150, loss: 0.00022494471340905875
step: 160, loss: 0.020411144942045212
step: 170, loss: 0.014414520002901554
step: 180, loss: 0.05568021163344383
step: 190, loss: 0.03426652401685715
step: 200, loss: 0.0512394942343235
step: 210, loss: 1.0088028830068652e-05
step: 220, loss: 0.06592970341444016
step: 230, loss: 0.014278472401201725
step: 240, loss: 0.018412571400403976
step: 250, loss: 0.07328534871339798
step: 260, loss: 0.13464535772800446
step: 270, loss: 0.00014720490435138345
step: 280, loss: 0.045202888548374176
step: 290, loss: 0.051528606563806534
step: 300, loss: 0.021924255415797234
step: 310, loss: 2.332589792786166e-05
step: 320, loss: 0.02858787216246128
step: 330, loss: 0.0002591307566035539
step: 340, loss: 0.00013448372192215174
step: 350, loss: 0.028701240196824074
step: 360, loss: 0.014328870922327042
step: 370, loss: 0.06779174506664276
step: 380, loss: 0.09140937030315399
step: 390, loss: 0.027964729815721512
step: 400, loss: 0.06882800161838531
step: 410, loss: 0.12085193395614624
step: 420, loss: 0.02001582272350788
step: 430, loss: 9.614361624699086e-05
step: 440, loss: 0.044307999312877655
step: 450, loss: 0.038465894758701324
step: 460, loss: 0.028244435787200928
step: 470, loss: 0.0004790375824086368
step: 480, loss: 0.025580301880836487
step: 490, loss: 0.1131177470088005
step: 500, loss: 0.024011798202991486
step: 510, loss: 0.0184592567384243
step: 520, loss: 0.026002375409007072
step: 530, loss: 0.029717961326241493
step: 540, loss: 0.03062855266034603
step: 550, loss: 0.03161768987774849
step: 560, loss: 7.84986259532161e-05
step: 570, loss: 0.03887206315994263
step: 580, loss: 0.02473883517086506
step: 590, loss: 0.046393852680921555
step: 600, loss: 0.0006852713995613158
step: 610, loss: 0.00045637492439709604
step: 620, loss: 2.0933979612891562e-05
step: 630, loss: 0.04793031886219978
step: 640, loss: 0.058190230280160904
step: 650, loss: 0.03835302218794823
step: 660, loss: 2.5763967641978525e-05
step: 670, loss: 0.0005454694619402289
step: 680, loss: 0.0531766377389431
step: 690, loss: 7.181166438385844e-05
step: 700, loss: 0.006155971437692642
step: 710, loss: 0.018419750034809113
step: 720, loss: 0.026541784405708313
step: 730, loss: 0.02607550658285618
step: 740, loss: 0.1042654812335968
step: 750, loss: 0.07372217625379562
step: 760, loss: 0.055212125182151794
step: 770, loss: 0.059893760830163956
step: 780, loss: 0.07204420119524002
step: 790, loss: 0.02193727158010006
step: 800, loss: 0.049623433500528336
step: 810, loss: 0.024126114323735237
step: 820, loss: 0.12279759347438812
step: 830, loss: 0.032875075936317444
step: 840, loss: 0.025126248598098755
step: 850, loss: 0.004001724999397993
step: 860, loss: 0.04164731875061989
step: 870, loss: 0.039006561040878296
step: 880, loss: 0.008699781261384487
step: 890, loss: 0.026398736983537674
step: 900, loss: 0.06511490792036057
step: 910, loss: 0.0001667746837483719
step: 920, loss: 0.05947433412075043
step: 930, loss: 0.04434427246451378
step: 940, loss: 0.021420013159513474
step: 950, loss: 0.09817138314247131
step: 960, loss: 0.03901184722781181
step: 970, loss: 0.0025936360470950603
epoch 16: dev_f1=0.9360112097150864, f1=0.9323378441437238, best_f1=0.9304267161410019
step: 0, loss: 0.028153160586953163
step: 10, loss: 0.05241648107767105
step: 20, loss: 0.00030995026463642716
step: 30, loss: 0.022966621443629265
step: 40, loss: 0.03497885540127754
step: 50, loss: 0.008983885869383812
step: 60, loss: 0.04592253640294075
step: 70, loss: 0.06907276064157486
step: 80, loss: 0.0006419395795091987
step: 90, loss: 0.05993541330099106
step: 100, loss: 0.02043059468269348
step: 110, loss: 0.01699810102581978
step: 120, loss: 0.017552055418491364
step: 130, loss: 0.023085398599505424
step: 140, loss: 0.034501515328884125
step: 150, loss: 0.04241808503866196
step: 160, loss: 0.025805866345763206
step: 170, loss: 0.000278968655038625
step: 180, loss: 0.024087902158498764
step: 190, loss: 0.018739672377705574
step: 200, loss: 0.037033241242170334
step: 210, loss: 0.00516359182074666
step: 220, loss: 0.00017655492410995066
step: 230, loss: 0.01931382529437542
step: 240, loss: 0.05439439043402672
step: 250, loss: 0.01760822907090187
step: 260, loss: 0.00015784976130817086
step: 270, loss: 0.0002495975058991462
step: 280, loss: 0.05983414500951767
step: 290, loss: 0.023407405242323875
step: 300, loss: 0.0005144457099959254
step: 310, loss: 0.07989632338285446
step: 320, loss: 0.0017921157414093614
step: 330, loss: 0.01923985593020916
step: 340, loss: 0.003216275479644537
step: 350, loss: 0.03289639577269554
step: 360, loss: 0.05054595693945885
step: 370, loss: 0.16480976343154907
step: 380, loss: 0.06712932884693146
step: 390, loss: 0.024950284510850906
step: 400, loss: 0.0383402556180954
step: 410, loss: 0.07732179760932922
step: 420, loss: 0.05152583867311478
step: 430, loss: 0.04940945655107498
step: 440, loss: 0.029570113867521286
step: 450, loss: 0.023256223648786545
step: 460, loss: 0.037926338613033295
step: 470, loss: 0.014996174722909927
step: 480, loss: 0.041232362389564514
step: 490, loss: 0.04375310614705086
step: 500, loss: 0.0001462833461118862
step: 510, loss: 2.7065050744567998e-05
step: 520, loss: 0.026119932532310486
step: 530, loss: 0.00027600719477050006
step: 540, loss: 0.013662194833159447
step: 550, loss: 0.00012002923176623881
step: 560, loss: 0.04356873780488968
step: 570, loss: 0.0197337307035923
step: 580, loss: 0.0058319903910160065
step: 590, loss: 0.04057940095663071
step: 600, loss: 0.04280414432287216
step: 610, loss: 0.00035105206188745797
step: 620, loss: 0.03661157563328743
step: 630, loss: 0.004798825830221176
step: 640, loss: 0.0288078673183918
step: 650, loss: 0.022863192483782768
step: 660, loss: 2.3015283659333363e-05
step: 670, loss: 0.06279262900352478
step: 680, loss: 0.03347659856081009
step: 690, loss: 0.01647753268480301
step: 700, loss: 0.06751183420419693
step: 710, loss: 0.01944741979241371
step: 720, loss: 0.025831758975982666
step: 730, loss: 0.017591305077075958
step: 740, loss: 0.021233396604657173
step: 750, loss: 0.02854521945118904
step: 760, loss: 0.03337514027953148
step: 770, loss: 0.0018232272705063224
step: 780, loss: 0.018734160810709
step: 790, loss: 0.01896531507372856
step: 800, loss: 0.04486817866563797
step: 810, loss: 0.04663071781396866
step: 820, loss: 0.016462817788124084
step: 830, loss: 4.712363806902431e-05
step: 840, loss: 0.030787741765379906
step: 850, loss: 0.036454591900110245
step: 860, loss: 0.0018418304389342666
step: 870, loss: 0.008840165100991726
step: 880, loss: 0.019082214683294296
step: 890, loss: 0.0253487266600132
step: 900, loss: 0.08105485141277313
step: 910, loss: 0.09449585527181625
step: 920, loss: 0.04236361011862755
step: 930, loss: 0.0023733004927635193
step: 940, loss: 0.0015355405630543828
step: 950, loss: 0.09383295476436615
step: 960, loss: 0.0017717877635732293
step: 970, loss: 0.00032036338234320283
epoch 17: dev_f1=0.933768656716418, f1=0.9321478708469817, best_f1=0.9304267161410019
step: 0, loss: 0.023709287866950035
step: 10, loss: 0.04929380118846893
step: 20, loss: 0.0009660476353019476
step: 30, loss: 0.05537121742963791
step: 40, loss: 0.03614210709929466
step: 50, loss: 0.0006032781093381345
step: 60, loss: 0.1512826830148697
step: 70, loss: 0.0010626943549141288
step: 80, loss: 0.04661727324128151
step: 90, loss: 0.08501400053501129
step: 100, loss: 0.0507541224360466
step: 110, loss: 0.0034198423381894827
step: 120, loss: 0.04770750179886818
step: 130, loss: 0.020611699670553207
step: 140, loss: 0.02298000268638134
step: 150, loss: 0.022874755784869194
step: 160, loss: 0.024796798825263977
step: 170, loss: 0.0453774593770504
step: 180, loss: 0.02039513550698757
step: 190, loss: 0.053706325590610504
step: 200, loss: 0.0034637602511793375
step: 210, loss: 0.024064335972070694
step: 220, loss: 0.03826136514544487
step: 230, loss: 0.0003415195387788117
step: 240, loss: 0.06515795737504959
step: 250, loss: 0.042498115450143814
step: 260, loss: 0.03438436985015869
step: 270, loss: 0.026096543297171593
step: 280, loss: 2.1235151507426053e-05
step: 290, loss: 0.02511661686003208
step: 300, loss: 0.01734311319887638
step: 310, loss: 0.0571291521191597
step: 320, loss: 0.0213153176009655
step: 330, loss: 0.025973258540034294
step: 340, loss: 0.0009218782070092857
step: 350, loss: 0.023087089881300926
step: 360, loss: 0.07669279724359512
step: 370, loss: 0.05038220435380936
step: 380, loss: 0.025383807718753815
step: 390, loss: 0.015254194848239422
step: 400, loss: 0.07281844317913055
step: 410, loss: 0.024333467707037926
step: 420, loss: 0.07695580273866653
step: 430, loss: 2.377604141656775e-05
step: 440, loss: 0.01614091917872429
step: 450, loss: 0.04109383746981621
step: 460, loss: 0.06943704187870026
step: 470, loss: 0.00013943799422122538
step: 480, loss: 0.0458495132625103
step: 490, loss: 0.03993222117424011
step: 500, loss: 0.042721495032310486
step: 510, loss: 0.07403445988893509
step: 520, loss: 0.0555170401930809
step: 530, loss: 0.0006997003802098334
step: 540, loss: 0.020219119265675545
step: 550, loss: 0.021843593567609787
step: 560, loss: 0.06769097596406937
step: 570, loss: 0.023838257417082787
step: 580, loss: 0.08150902390480042
step: 590, loss: 0.06621428579092026
step: 600, loss: 7.476026803487912e-05
step: 610, loss: 0.04971056059002876
step: 620, loss: 0.00011120681301690638
step: 630, loss: 0.0008046714356169105
step: 640, loss: 0.02058258466422558
step: 650, loss: 0.0513821542263031
step: 660, loss: 0.028634164482355118
step: 670, loss: 0.0010094887111335993
step: 680, loss: 0.02384820580482483
step: 690, loss: 0.05335763841867447
step: 700, loss: 0.05800945311784744
step: 710, loss: 6.166492676129565e-05
step: 720, loss: 0.06650146842002869
step: 730, loss: 0.01757301576435566
step: 740, loss: 0.026997020468115807
step: 750, loss: 0.01781490631401539
step: 760, loss: 0.00402832729741931
step: 770, loss: 0.00025844413903541863
step: 780, loss: 0.024441692978143692
step: 790, loss: 0.059622716158628464
step: 800, loss: 0.05034438893198967
step: 810, loss: 0.005894889123737812
step: 820, loss: 0.00025904117501340806
step: 830, loss: 0.05372476577758789
step: 840, loss: 8.525498560629785e-05
step: 850, loss: 0.06957317143678665
step: 860, loss: 0.02772030048072338
step: 870, loss: 0.08513560891151428
step: 880, loss: 0.020138295367360115
step: 890, loss: 0.021582260727882385
step: 900, loss: 0.029674114659428596
step: 910, loss: 0.003327657701447606
step: 920, loss: 0.012375442311167717
step: 930, loss: 0.05326317250728607
step: 940, loss: 0.00011278966849204153
step: 950, loss: 0.050920166075229645
step: 960, loss: 0.0738171711564064
step: 970, loss: 0.060744162648916245
epoch 18: dev_f1=0.932387706855792, f1=0.9280303030303031, best_f1=0.9304267161410019
step: 0, loss: 0.04161737859249115
step: 10, loss: 0.07909274101257324
step: 20, loss: 0.020564734935760498
step: 30, loss: 0.025244710966944695
step: 40, loss: 0.028698429465293884
step: 50, loss: 9.741305984789506e-05
step: 60, loss: 0.017332153394818306
step: 70, loss: 9.490788215771317e-05
step: 80, loss: 5.8785291912499815e-05
step: 90, loss: 0.059327203780412674
step: 100, loss: 0.022126678377389908
step: 110, loss: 0.03047720529139042
step: 120, loss: 0.042505815625190735
step: 130, loss: 2.4568245862610638e-05
step: 140, loss: 5.34414139110595e-05
step: 150, loss: 6.739962555002421e-05
step: 160, loss: 7.207650924101472e-05
step: 170, loss: 0.025431297719478607
step: 180, loss: 0.04745565727353096
step: 190, loss: 0.07834699004888535
step: 200, loss: 0.025315657258033752
step: 210, loss: 0.08370847254991531
step: 220, loss: 0.03729850798845291
step: 230, loss: 0.0002487046003807336
step: 240, loss: 8.233198605012149e-05
step: 250, loss: 0.06609579920768738
step: 260, loss: 0.04167937859892845
step: 270, loss: 0.04466412216424942
step: 280, loss: 0.024284370243549347
step: 290, loss: 0.02562963031232357
step: 300, loss: 6.159658369142562e-05
step: 310, loss: 7.195782382041216e-05
step: 320, loss: 0.04091111570596695
step: 330, loss: 0.05102564021945
step: 340, loss: 0.018890395760536194
step: 350, loss: 0.024415573105216026
step: 360, loss: 0.00039309205021709204
step: 370, loss: 0.019438941031694412
step: 380, loss: 0.057466357946395874
step: 390, loss: 0.11508321762084961
step: 400, loss: 9.90760454442352e-05
step: 410, loss: 0.019560588523745537
step: 420, loss: 0.0338369682431221
step: 430, loss: 0.02475099265575409
step: 440, loss: 0.05020903795957565
step: 450, loss: 0.021833574399352074
step: 460, loss: 0.0011025384301319718
step: 470, loss: 6.137123273219913e-05
step: 480, loss: 0.0832475870847702
step: 490, loss: 0.021490728482604027
step: 500, loss: 0.02232656069099903
step: 510, loss: 8.482448720315006e-06
step: 520, loss: 0.00010643439600244164
step: 530, loss: 1.3783122085442301e-05
step: 540, loss: 0.0010014616418629885
step: 550, loss: 0.017697131261229515
step: 560, loss: 1.5157515917962883e-05
step: 570, loss: 6.54878094792366e-05
step: 580, loss: 0.023344025015830994
step: 590, loss: 0.04112161323428154
step: 600, loss: 0.04871298372745514
step: 610, loss: 0.06761600822210312
step: 620, loss: 0.013045079074800014
step: 630, loss: 0.02009602263569832
step: 640, loss: 0.1014605462551117
step: 650, loss: 0.025891724973917007
step: 660, loss: 0.02800726518034935
step: 670, loss: 0.06549390405416489
step: 680, loss: 0.06714138388633728
step: 690, loss: 8.099716797005385e-05
step: 700, loss: 0.028493797406554222
step: 710, loss: 0.0034320454578846693
step: 720, loss: 0.04593919217586517
step: 730, loss: 0.00016022463387344033
step: 740, loss: 0.0457095205783844
step: 750, loss: 0.00035280766314826906
step: 760, loss: 0.029050972312688828
step: 770, loss: 0.03814929723739624
step: 780, loss: 0.0011380601208657026
step: 790, loss: 0.0005131564103066921
step: 800, loss: 0.017656253650784492
step: 810, loss: 0.029755454510450363
step: 820, loss: 8.977899597084615e-06
step: 830, loss: 0.01941854879260063
step: 840, loss: 0.001856114948168397
step: 850, loss: 0.02139447256922722
step: 860, loss: 0.043665118515491486
step: 870, loss: 0.03626210242509842
step: 880, loss: 0.015972502529621124
step: 890, loss: 9.063335892278701e-05
step: 900, loss: 0.03954392671585083
step: 910, loss: 8.229129889514297e-06
step: 920, loss: 0.0018609274411574006
step: 930, loss: 0.04016312211751938
step: 940, loss: 0.020745154470205307
step: 950, loss: 0.07336723059415817
step: 960, loss: 0.05375463515520096
step: 970, loss: 0.045378293842077255
epoch 19: dev_f1=0.9338338808071328, f1=0.929683813119396, best_f1=0.9304267161410019
step: 0, loss: 0.00010662189743015915
step: 10, loss: 0.00012030446669086814
step: 20, loss: 0.0003865095495712012
step: 30, loss: 0.07774956524372101
step: 40, loss: 0.05496099591255188
step: 50, loss: 0.05920112133026123
step: 60, loss: 1.168596190836979e-05
step: 70, loss: 8.913845522329211e-05
step: 80, loss: 0.023320499807596207
step: 90, loss: 0.045205824077129364
step: 100, loss: 0.0004578017396852374
step: 110, loss: 0.0415470115840435
step: 120, loss: 0.045879997313022614
step: 130, loss: 0.026578132063150406
step: 140, loss: 0.03869495168328285
step: 150, loss: 0.10915621370077133
step: 160, loss: 0.0036777877248823643
step: 170, loss: 0.022336741909384727
step: 180, loss: 0.03878941014409065
step: 190, loss: 0.07312621921300888
step: 200, loss: 0.02311893180012703
step: 210, loss: 0.07398877292871475
step: 220, loss: 4.275177343515679e-05
step: 230, loss: 0.020587489008903503
step: 240, loss: 0.02394316904246807
step: 250, loss: 0.029190976172685623
step: 260, loss: 0.024993985891342163
step: 270, loss: 0.04556333273649216
step: 280, loss: 0.08263956755399704
step: 290, loss: 0.052074942737817764
step: 300, loss: 0.027983209118247032
step: 310, loss: 0.00011599325080169365
step: 320, loss: 0.03629762679338455
step: 330, loss: 0.02499805949628353
step: 340, loss: 5.494496872415766e-05
step: 350, loss: 0.05305720120668411
step: 360, loss: 0.011817002668976784
step: 370, loss: 0.07944507151842117
step: 380, loss: 0.1078040823340416
step: 390, loss: 0.01701788231730461
step: 400, loss: 0.00012063520989613608
step: 410, loss: 0.01871596649289131
step: 420, loss: 0.022060340270400047
step: 430, loss: 0.01832159422338009
step: 440, loss: 4.40618532593362e-05
step: 450, loss: 0.07810414582490921
step: 460, loss: 0.011575266718864441
step: 470, loss: 0.02649642713367939
step: 480, loss: 0.04846450686454773
step: 490, loss: 0.04603666812181473
step: 500, loss: 0.0011187567142769694
step: 510, loss: 0.021708281710743904
step: 520, loss: 0.018650170415639877
step: 530, loss: 0.030147507786750793
step: 540, loss: 0.05009356141090393
step: 550, loss: 0.03514862805604935
step: 560, loss: 0.022440951317548752
step: 570, loss: 0.06817947328090668
step: 580, loss: 0.0006028497591614723
step: 590, loss: 0.021937955170869827
step: 600, loss: 0.021658362820744514
step: 610, loss: 0.07723543047904968
step: 620, loss: 0.005648620892316103
step: 630, loss: 0.0251743383705616
step: 640, loss: 0.005318896379321814
step: 650, loss: 0.019854383543133736
step: 660, loss: 6.168489926494658e-05
step: 670, loss: 4.01480974687729e-05
step: 680, loss: 0.02241963893175125
step: 690, loss: 9.355477232020348e-05
step: 700, loss: 0.00014085954171605408
step: 710, loss: 0.00632538553327322
step: 720, loss: 0.075772725045681
step: 730, loss: 0.05236242711544037
step: 740, loss: 0.00013099989155307412
step: 750, loss: 0.019912095740437508
step: 760, loss: 4.7544785047648475e-05
step: 770, loss: 0.08693988621234894
step: 780, loss: 0.05376971885561943
step: 790, loss: 0.02148936502635479
step: 800, loss: 0.049184400588274
step: 810, loss: 0.05818326026201248
step: 820, loss: 0.01918475143611431
step: 830, loss: 0.04938117787241936
step: 840, loss: 0.060340091586112976
step: 850, loss: 8.093756332527846e-05
step: 860, loss: 0.02684214897453785
step: 870, loss: 0.06621749699115753
step: 880, loss: 0.07229653745889664
step: 890, loss: 0.0018775101052597165
step: 900, loss: 0.04009801149368286
step: 910, loss: 0.0012315221829339862
step: 920, loss: 1.7771808416000567e-05
step: 930, loss: 0.019734453409910202
step: 940, loss: 0.020574135705828667
step: 950, loss: 0.025393765419721603
step: 960, loss: 0.022017404437065125
step: 970, loss: 0.050413552671670914
epoch 20: dev_f1=0.9332079021636878, f1=0.9291784702549575, best_f1=0.9304267161410019
