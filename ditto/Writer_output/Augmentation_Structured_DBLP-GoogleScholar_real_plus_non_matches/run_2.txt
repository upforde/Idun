cuda
Device: cuda
step: 0, loss: 0.568714439868927
step: 10, loss: 0.24644102156162262
step: 20, loss: 0.3480868339538574
step: 30, loss: 0.17296350002288818
step: 40, loss: 0.16875258088111877
step: 50, loss: 0.14277689158916473
step: 60, loss: 0.15758778154850006
step: 70, loss: 0.07649900019168854
step: 80, loss: 0.2063532918691635
step: 90, loss: 0.11932265758514404
step: 100, loss: 0.11982966214418411
step: 110, loss: 0.13690422475337982
step: 120, loss: 0.2265014499425888
step: 130, loss: 0.14946937561035156
step: 140, loss: 0.17086443305015564
step: 150, loss: 0.230191171169281
step: 160, loss: 0.2195979207754135
step: 170, loss: 0.11490494012832642
step: 180, loss: 0.17834949493408203
step: 190, loss: 0.07830687612295151
step: 200, loss: 0.12403407692909241
step: 210, loss: 0.2251114547252655
step: 220, loss: 0.09775473922491074
step: 230, loss: 0.21824699640274048
step: 240, loss: 0.21755635738372803
step: 250, loss: 0.051665909588336945
step: 260, loss: 0.1370183676481247
step: 270, loss: 0.18097515404224396
step: 280, loss: 0.1772269457578659
step: 290, loss: 0.11459805071353912
step: 300, loss: 0.19507242739200592
step: 310, loss: 0.36504891514778137
step: 320, loss: 0.10332188010215759
step: 330, loss: 0.03842810168862343
step: 340, loss: 0.12283763289451599
step: 350, loss: 0.14759708940982819
step: 360, loss: 0.3016972541809082
step: 370, loss: 0.07392741739749908
step: 380, loss: 0.13291627168655396
step: 390, loss: 0.09112024307250977
step: 400, loss: 0.1647086888551712
step: 410, loss: 0.16968674957752228
step: 420, loss: 0.17084673047065735
step: 430, loss: 0.21670420467853546
step: 440, loss: 0.14053291082382202
step: 450, loss: 0.126681849360466
step: 460, loss: 0.15805885195732117
step: 470, loss: 0.11225048452615738
step: 480, loss: 0.07324005663394928
step: 490, loss: 0.3338548541069031
step: 500, loss: 0.1699983924627304
step: 510, loss: 0.21455484628677368
step: 520, loss: 0.14483503997325897
step: 530, loss: 0.07044296711683273
step: 540, loss: 0.11457879841327667
step: 550, loss: 0.11017364263534546
step: 560, loss: 0.07798995822668076
step: 570, loss: 0.13589131832122803
step: 580, loss: 0.16129669547080994
step: 590, loss: 0.2602281868457794
step: 600, loss: 0.06826699525117874
step: 610, loss: 0.09578478336334229
step: 620, loss: 0.1968696564435959
step: 630, loss: 0.11095328629016876
step: 640, loss: 0.2012602537870407
step: 650, loss: 0.09515377134084702
step: 660, loss: 0.09322026371955872
step: 670, loss: 0.21208864450454712
step: 680, loss: 0.24410271644592285
step: 690, loss: 0.06656923145055771
step: 700, loss: 0.021086324006319046
step: 710, loss: 0.21292363107204437
step: 720, loss: 0.11165700852870941
step: 730, loss: 0.12266293168067932
step: 740, loss: 0.0937567949295044
step: 750, loss: 0.39979782700538635
step: 760, loss: 0.244325190782547
step: 770, loss: 0.0595247708261013
step: 780, loss: 0.1284005492925644
step: 790, loss: 0.095158651471138
step: 800, loss: 0.06802840530872345
step: 810, loss: 0.21149961650371552
step: 820, loss: 0.06533500552177429
step: 830, loss: 0.06456681340932846
step: 840, loss: 0.08459295332431793
step: 850, loss: 0.12842537462711334
step: 860, loss: 0.05503122881054878
step: 870, loss: 0.07139366865158081
step: 880, loss: 0.01778842695057392
step: 890, loss: 0.02627347595989704
step: 900, loss: 0.05443552881479263
step: 910, loss: 0.15014714002609253
step: 920, loss: 0.08998087793588638
step: 930, loss: 0.13255970180034637
step: 940, loss: 0.057403940707445145
step: 950, loss: 0.0720113143324852
step: 960, loss: 0.1492060124874115
step: 970, loss: 0.01732536405324936
epoch 1: dev_f1=0.9254004576659038, f1=0.9228675136116152, best_f1=0.9228675136116152
step: 0, loss: 0.09173666685819626
step: 10, loss: 0.09735091030597687
step: 20, loss: 0.13545697927474976
step: 30, loss: 0.0731629878282547
step: 40, loss: 0.028375428169965744
step: 50, loss: 0.04120923951268196
step: 60, loss: 0.08608032763004303
step: 70, loss: 0.09453991055488586
step: 80, loss: 0.14946113526821136
step: 90, loss: 0.01937977410852909
step: 100, loss: 0.06036511808633804
step: 110, loss: 0.0828503966331482
step: 120, loss: 0.09776871651411057
step: 130, loss: 0.06270676106214523
step: 140, loss: 0.1000794991850853
step: 150, loss: 0.09059048444032669
step: 160, loss: 0.16526615619659424
step: 170, loss: 0.12696126103401184
step: 180, loss: 0.07738935947418213
step: 190, loss: 0.07568487524986267
step: 200, loss: 0.07868514955043793
step: 210, loss: 0.2268945425748825
step: 220, loss: 0.05424042418599129
step: 230, loss: 0.02227969840168953
step: 240, loss: 0.10272937268018723
step: 250, loss: 0.04703687131404877
step: 260, loss: 0.08865037560462952
step: 270, loss: 0.03697222098708153
step: 280, loss: 0.09947610646486282
step: 290, loss: 0.11149099469184875
step: 300, loss: 0.08916661143302917
step: 310, loss: 0.05925429239869118
step: 320, loss: 0.14865006506443024
step: 330, loss: 0.13768668472766876
step: 340, loss: 0.13299678266048431
step: 350, loss: 0.07413125783205032
step: 360, loss: 0.08588998019695282
step: 370, loss: 0.3298242688179016
step: 380, loss: 0.03684074804186821
step: 390, loss: 0.06861329078674316
step: 400, loss: 0.15604250133037567
step: 410, loss: 0.12691958248615265
step: 420, loss: 0.08577258139848709
step: 430, loss: 0.1632392555475235
step: 440, loss: 0.07286695390939713
step: 450, loss: 0.010649573057889938
step: 460, loss: 0.06410494446754456
step: 470, loss: 0.16032814979553223
step: 480, loss: 0.011345207691192627
step: 490, loss: 0.30969101190567017
step: 500, loss: 0.04382576793432236
step: 510, loss: 0.3150329887866974
step: 520, loss: 0.08090738207101822
step: 530, loss: 0.030489349737763405
step: 540, loss: 0.1384194791316986
step: 550, loss: 0.14876654744148254
step: 560, loss: 0.15460731089115143
step: 570, loss: 0.03956230729818344
step: 580, loss: 0.027959180995821953
step: 590, loss: 0.018165357410907745
step: 600, loss: 0.12019729614257812
step: 610, loss: 0.022505532950162888
step: 620, loss: 0.06768658757209778
step: 630, loss: 0.021806560456752777
step: 640, loss: 0.03549490496516228
step: 650, loss: 0.030331509187817574
step: 660, loss: 0.0019457105081528425
step: 670, loss: 0.13623815774917603
step: 680, loss: 0.08670628815889359
step: 690, loss: 0.08593510836362839
step: 700, loss: 0.09138795733451843
step: 710, loss: 0.12002646923065186
step: 720, loss: 0.03464149311184883
step: 730, loss: 0.17873577773571014
step: 740, loss: 0.12923452258110046
step: 750, loss: 0.12370087951421738
step: 760, loss: 0.035793185234069824
step: 770, loss: 0.023675179108977318
step: 780, loss: 0.18691255152225494
step: 790, loss: 0.025119291618466377
step: 800, loss: 0.026908114552497864
step: 810, loss: 0.027780991047620773
step: 820, loss: 0.06657518446445465
step: 830, loss: 0.21328242123126984
step: 840, loss: 0.023989787325263023
step: 850, loss: 0.11821328848600388
step: 860, loss: 0.10568177700042725
step: 870, loss: 0.032216258347034454
step: 880, loss: 0.1056041345000267
step: 890, loss: 0.02228635363280773
step: 900, loss: 0.08838395029306412
step: 910, loss: 0.08008415997028351
step: 920, loss: 0.020114967599511147
step: 930, loss: 0.12041059881448746
step: 940, loss: 0.18549928069114685
step: 950, loss: 0.13375291228294373
step: 960, loss: 0.08525170385837555
step: 970, loss: 0.10867669433355331
epoch 2: dev_f1=0.9275362318840579, f1=0.934299954689624, best_f1=0.934299954689624
step: 0, loss: 0.08442192524671555
step: 10, loss: 0.03126345947384834
step: 20, loss: 0.16268041729927063
step: 30, loss: 0.10000146925449371
step: 40, loss: 0.05884784460067749
step: 50, loss: 0.1265663504600525
step: 60, loss: 0.2586827874183655
step: 70, loss: 0.11225272715091705
step: 80, loss: 0.08189988881349564
step: 90, loss: 0.12547023594379425
step: 100, loss: 0.0946824699640274
step: 110, loss: 0.041344352066516876
step: 120, loss: 0.12706628441810608
step: 130, loss: 0.011897897347807884
step: 140, loss: 0.20902709662914276
step: 150, loss: 0.039967380464076996
step: 160, loss: 0.08225655555725098
step: 170, loss: 0.046720951795578
step: 180, loss: 0.053059909492731094
step: 190, loss: 0.12791666388511658
step: 200, loss: 0.10878752171993256
step: 210, loss: 0.09597452729940414
step: 220, loss: 0.10426044464111328
step: 230, loss: 0.24000057578086853
step: 240, loss: 0.1229948028922081
step: 250, loss: 0.2885499894618988
step: 260, loss: 0.13644179701805115
step: 270, loss: 0.01656245067715645
step: 280, loss: 0.08384860306978226
step: 290, loss: 0.05212043225765228
step: 300, loss: 0.048807304352521896
step: 310, loss: 0.08860243856906891
step: 320, loss: 0.0814763754606247
step: 330, loss: 0.05429806187748909
step: 340, loss: 0.109675332903862
step: 350, loss: 0.07663346081972122
step: 360, loss: 0.020525597035884857
step: 370, loss: 0.030011959373950958
step: 380, loss: 0.08432576805353165
step: 390, loss: 0.06938823312520981
step: 400, loss: 0.033426012843847275
step: 410, loss: 0.12030071765184402
step: 420, loss: 0.01819780468940735
step: 430, loss: 0.023604238405823708
step: 440, loss: 0.12029656767845154
step: 450, loss: 0.09486464411020279
step: 460, loss: 0.08239317685365677
step: 470, loss: 0.19100750982761383
step: 480, loss: 0.07101627439260483
step: 490, loss: 0.038234416395425797
step: 500, loss: 0.08179488033056259
step: 510, loss: 0.10705915093421936
step: 520, loss: 0.11720128357410431
step: 530, loss: 0.01673910580575466
step: 540, loss: 0.1231183111667633
step: 550, loss: 0.13930663466453552
step: 560, loss: 0.1132771447300911
step: 570, loss: 0.026135414838790894
step: 580, loss: 0.1283940225839615
step: 590, loss: 0.12002869695425034
step: 600, loss: 0.12296824902296066
step: 610, loss: 0.07136379927396774
step: 620, loss: 0.19616355001926422
step: 630, loss: 0.12773068249225616
step: 640, loss: 0.02254210039973259
step: 650, loss: 0.10986887663602829
step: 660, loss: 0.09638901054859161
step: 670, loss: 0.08322785794734955
step: 680, loss: 0.014349597506225109
step: 690, loss: 0.13747067749500275
step: 700, loss: 0.08314654231071472
step: 710, loss: 0.2385459989309311
step: 720, loss: 0.028140941634774208
step: 730, loss: 0.07408807426691055
step: 740, loss: 0.0815100148320198
step: 750, loss: 0.144412100315094
step: 760, loss: 0.02770913392305374
step: 770, loss: 0.0852762758731842
step: 780, loss: 0.04829634353518486
step: 790, loss: 0.20105259120464325
step: 800, loss: 0.11800061166286469
step: 810, loss: 0.048987213522195816
step: 820, loss: 0.1439439058303833
step: 830, loss: 0.06159114092588425
step: 840, loss: 0.04507526755332947
step: 850, loss: 0.11724242568016052
step: 860, loss: 0.07692959904670715
step: 870, loss: 0.19470547139644623
step: 880, loss: 0.04032406210899353
step: 890, loss: 0.04996158927679062
step: 900, loss: 0.2098483443260193
step: 910, loss: 0.1039368212223053
step: 920, loss: 0.09310512244701385
step: 930, loss: 0.13041570782661438
step: 940, loss: 0.11582116782665253
step: 950, loss: 0.1582878679037094
step: 960, loss: 0.08045323938131332
step: 970, loss: 0.00017091473273467273
epoch 3: dev_f1=0.9351598173515983, f1=0.9319323892188214, best_f1=0.9319323892188214
step: 0, loss: 0.08175801485776901
step: 10, loss: 0.02581603080034256
step: 20, loss: 0.18876777589321136
step: 30, loss: 0.017164267599582672
step: 40, loss: 0.06548888981342316
step: 50, loss: 0.11982332915067673
step: 60, loss: 0.031480807811021805
step: 70, loss: 0.10319183766841888
step: 80, loss: 0.011842692270874977
step: 90, loss: 0.053171709179878235
step: 100, loss: 0.00015476801490876824
step: 110, loss: 0.11000646650791168
step: 120, loss: 0.030493881553411484
step: 130, loss: 0.0074592516757547855
step: 140, loss: 0.07799626141786575
step: 150, loss: 0.08527237176895142
step: 160, loss: 0.05360668897628784
step: 170, loss: 0.0513274148106575
step: 180, loss: 0.1727580428123474
step: 190, loss: 0.08933622390031815
step: 200, loss: 0.1096949502825737
step: 210, loss: 0.10549561679363251
step: 220, loss: 0.12949027121067047
step: 230, loss: 0.08751428872346878
step: 240, loss: 0.06627662479877472
step: 250, loss: 0.11126638948917389
step: 260, loss: 0.057737838476896286
step: 270, loss: 0.18709006905555725
step: 280, loss: 0.07426991313695908
step: 290, loss: 0.009955229237675667
step: 300, loss: 0.17100289463996887
step: 310, loss: 0.18425287306308746
step: 320, loss: 0.05952947214245796
step: 330, loss: 0.07343162596225739
step: 340, loss: 0.031252942979335785
step: 350, loss: 0.11681291460990906
step: 360, loss: 0.09870351850986481
step: 370, loss: 0.07848557084798813
step: 380, loss: 0.03697225823998451
step: 390, loss: 0.2207043468952179
step: 400, loss: 0.10630127787590027
step: 410, loss: 0.11715841293334961
step: 420, loss: 0.05016694590449333
step: 430, loss: 0.12308603525161743
step: 440, loss: 0.03382725268602371
step: 450, loss: 0.00493969488888979
step: 460, loss: 0.021016616374254227
step: 470, loss: 0.03637981042265892
step: 480, loss: 0.05283237248659134
step: 490, loss: 0.029518740251660347
step: 500, loss: 0.030030101537704468
step: 510, loss: 0.0679527074098587
step: 520, loss: 0.04908926039934158
step: 530, loss: 0.02470037341117859
step: 540, loss: 0.03864772617816925
step: 550, loss: 0.008599426597356796
step: 560, loss: 0.09707927703857422
step: 570, loss: 0.07022285461425781
step: 580, loss: 0.06830117106437683
step: 590, loss: 0.1989593207836151
step: 600, loss: 0.08621919900178909
step: 610, loss: 0.052126385271549225
step: 620, loss: 0.06483215093612671
step: 630, loss: 0.10671240091323853
step: 640, loss: 0.07133933901786804
step: 650, loss: 0.09953241795301437
step: 660, loss: 0.17888149619102478
step: 670, loss: 0.1271675080060959
step: 680, loss: 0.03529181331396103
step: 690, loss: 0.06531532108783722
step: 700, loss: 0.14405862987041473
step: 710, loss: 0.09031940251588821
step: 720, loss: 0.15298862755298615
step: 730, loss: 0.030768470838665962
step: 740, loss: 0.08483487367630005
step: 750, loss: 0.009914916940033436
step: 760, loss: 0.020358366891741753
step: 770, loss: 0.19092939794063568
step: 780, loss: 0.058072321116924286
step: 790, loss: 0.07083295285701752
step: 800, loss: 0.08540452271699905
step: 810, loss: 0.0972459614276886
step: 820, loss: 0.02914351038634777
step: 830, loss: 0.020947298035025597
step: 840, loss: 0.0945742279291153
step: 850, loss: 0.09538707882165909
step: 860, loss: 0.12071887403726578
step: 870, loss: 0.11923033744096756
step: 880, loss: 0.1132827177643776
step: 890, loss: 0.13172899186611176
step: 900, loss: 0.052679676562547684
step: 910, loss: 0.18870338797569275
step: 920, loss: 0.18539391458034515
step: 930, loss: 0.04685945808887482
step: 940, loss: 0.07493674010038376
step: 950, loss: 0.05164443701505661
step: 960, loss: 0.07014869153499603
step: 970, loss: 0.13429062068462372
epoch 4: dev_f1=0.9346314325452018, f1=0.9386814200092208, best_f1=0.9319323892188214
step: 0, loss: 0.02124238759279251
step: 10, loss: 0.12072496861219406
step: 20, loss: 0.03468935564160347
step: 30, loss: 0.03368956595659256
step: 40, loss: 0.12242534011602402
step: 50, loss: 0.1795152872800827
step: 60, loss: 0.08033332228660583
step: 70, loss: 0.030223917216062546
step: 80, loss: 0.04494910687208176
step: 90, loss: 0.08877702802419662
step: 100, loss: 0.016809741035103798
step: 110, loss: 0.03339778631925583
step: 120, loss: 0.02979918010532856
step: 130, loss: 0.0991135761141777
step: 140, loss: 0.0800357386469841
step: 150, loss: 0.0759008601307869
step: 160, loss: 0.09272933751344681
step: 170, loss: 0.03134077787399292
step: 180, loss: 0.0681133046746254
step: 190, loss: 0.07369152456521988
step: 200, loss: 0.10823680460453033
step: 210, loss: 0.09463723003864288
step: 220, loss: 0.047596924006938934
step: 230, loss: 0.12260469794273376
step: 240, loss: 0.34061893820762634
step: 250, loss: 0.022767476737499237
step: 260, loss: 0.01953929290175438
step: 270, loss: 0.016979174688458443
step: 280, loss: 0.0357305184006691
step: 290, loss: 0.02985415793955326
step: 300, loss: 0.12726905941963196
step: 310, loss: 0.14437249302864075
step: 320, loss: 0.13374578952789307
step: 330, loss: 0.01194169744849205
step: 340, loss: 0.11378039419651031
step: 350, loss: 0.012829119339585304
step: 360, loss: 0.10584834218025208
step: 370, loss: 0.12882405519485474
step: 380, loss: 0.011203777976334095
step: 390, loss: 0.07496438920497894
step: 400, loss: 0.018802549690008163
step: 410, loss: 0.01573028601706028
step: 420, loss: 0.18868061900138855
step: 430, loss: 0.07741303741931915
step: 440, loss: 0.05159628018736839
step: 450, loss: 0.155028834939003
step: 460, loss: 0.11297768354415894
step: 470, loss: 0.05606440082192421
step: 480, loss: 0.09586453437805176
step: 490, loss: 0.05083990469574928
step: 500, loss: 0.040032144635915756
step: 510, loss: 0.059371646493673325
step: 520, loss: 0.005326017737388611
step: 530, loss: 0.10619989037513733
step: 540, loss: 0.25015321373939514
step: 550, loss: 0.2081366330385208
step: 560, loss: 0.036650680005550385
step: 570, loss: 0.04209110513329506
step: 580, loss: 0.12289532274007797
step: 590, loss: 0.06227179616689682
step: 600, loss: 0.013653622008860111
step: 610, loss: 0.19042536616325378
step: 620, loss: 0.08081304281949997
step: 630, loss: 0.031291261315345764
step: 640, loss: 0.019346829503774643
step: 650, loss: 0.190741166472435
step: 660, loss: 0.06431196630001068
step: 670, loss: 0.032034166157245636
step: 680, loss: 0.09780512750148773
step: 690, loss: 0.028300467878580093
step: 700, loss: 0.03591682389378548
step: 710, loss: 0.25582924485206604
step: 720, loss: 0.08889323472976685
step: 730, loss: 0.20582278072834015
step: 740, loss: 0.11774985492229462
step: 750, loss: 0.05683957785367966
step: 760, loss: 0.07101668417453766
step: 770, loss: 0.02272028662264347
step: 780, loss: 0.07360959053039551
step: 790, loss: 0.038339048624038696
step: 800, loss: 0.04325864464044571
step: 810, loss: 0.03284933790564537
step: 820, loss: 0.021887414157390594
step: 830, loss: 0.12918677926063538
step: 840, loss: 0.06230735033750534
step: 850, loss: 0.06632910668849945
step: 860, loss: 0.04430798068642616
step: 870, loss: 0.01659029722213745
step: 880, loss: 0.10598336160182953
step: 890, loss: 0.006482528056949377
step: 900, loss: 0.017891310155391693
step: 910, loss: 0.015052086673676968
step: 920, loss: 0.22276239097118378
step: 930, loss: 0.0423990897834301
step: 940, loss: 0.017078664153814316
step: 950, loss: 0.06692017614841461
step: 960, loss: 0.06640338897705078
step: 970, loss: 0.1846669316291809
epoch 5: dev_f1=0.9377049180327869, f1=0.9318394024276377, best_f1=0.9318394024276377
step: 0, loss: 0.037506479769945145
step: 10, loss: 0.047390181571245193
step: 20, loss: 0.07013637572526932
step: 30, loss: 0.025613058358430862
step: 40, loss: 0.08938494324684143
step: 50, loss: 0.10005559772253036
step: 60, loss: 0.056944310665130615
step: 70, loss: 0.07683487236499786
step: 80, loss: 0.015898730605840683
step: 90, loss: 0.062193483114242554
step: 100, loss: 0.08531780540943146
step: 110, loss: 0.05315229296684265
step: 120, loss: 0.019092192873358727
step: 130, loss: 0.027606358751654625
step: 140, loss: 0.034893523901700974
step: 150, loss: 0.024364084005355835
step: 160, loss: 0.03276342898607254
step: 170, loss: 0.020307326689362526
step: 180, loss: 0.07003080099821091
step: 190, loss: 0.010904661379754543
step: 200, loss: 0.004274316132068634
step: 210, loss: 0.055924419313669205
step: 220, loss: 0.04661623388528824
step: 230, loss: 0.02942432090640068
step: 240, loss: 0.02533712424337864
step: 250, loss: 0.007094927132129669
step: 260, loss: 0.02114908955991268
step: 270, loss: 0.12295340746641159
step: 280, loss: 0.028171787038445473
step: 290, loss: 0.054278045892715454
step: 300, loss: 0.06838875263929367
step: 310, loss: 0.09728195518255234
step: 320, loss: 0.09659738838672638
step: 330, loss: 0.030006838962435722
step: 340, loss: 0.18717914819717407
step: 350, loss: 0.05402154102921486
step: 360, loss: 0.06320536881685257
step: 370, loss: 0.12271516770124435
step: 380, loss: 0.2665811777114868
step: 390, loss: 0.01610495150089264
step: 400, loss: 0.1259889304637909
step: 410, loss: 0.12367412447929382
step: 420, loss: 0.07238290458917618
step: 430, loss: 0.024631084874272346
step: 440, loss: 0.11768144369125366
step: 450, loss: 0.15581375360488892
step: 460, loss: 0.0525282584130764
step: 470, loss: 0.013885719701647758
step: 480, loss: 0.039596349000930786
step: 490, loss: 0.036707714200019836
step: 500, loss: 0.03364644572138786
step: 510, loss: 0.11940133571624756
step: 520, loss: 0.005528999026864767
step: 530, loss: 0.042547620832920074
step: 540, loss: 0.020212963223457336
step: 550, loss: 0.1040492132306099
step: 560, loss: 0.06275178492069244
step: 570, loss: 0.11214946955442429
step: 580, loss: 0.0629330426454544
step: 590, loss: 0.05715849623084068
step: 600, loss: 0.1272454857826233
step: 610, loss: 0.058486394584178925
step: 620, loss: 0.1279163360595703
step: 630, loss: 0.05535752326250076
step: 640, loss: 0.029230035841464996
step: 650, loss: 0.1385723203420639
step: 660, loss: 0.06752154976129532
step: 670, loss: 0.19786329567432404
step: 680, loss: 0.015430926345288754
step: 690, loss: 0.008044688031077385
step: 700, loss: 0.10191867500543594
step: 710, loss: 0.11664468795061111
step: 720, loss: 0.08885108679533005
step: 730, loss: 0.12297424674034119
step: 740, loss: 0.05338914692401886
step: 750, loss: 0.0474298931658268
step: 760, loss: 0.10965774953365326
step: 770, loss: 0.042638443410396576
step: 780, loss: 0.01245859730988741
step: 790, loss: 0.11931484937667847
step: 800, loss: 0.059793125838041306
step: 810, loss: 0.031224790960550308
step: 820, loss: 0.05137668550014496
step: 830, loss: 0.10707534849643707
step: 840, loss: 0.038797128945589066
step: 850, loss: 0.07644525170326233
step: 860, loss: 0.06154906749725342
step: 870, loss: 0.02915768325328827
step: 880, loss: 0.07034526020288467
step: 890, loss: 0.07592263072729111
step: 900, loss: 0.057817116379737854
step: 910, loss: 0.10213897377252579
step: 920, loss: 0.07031285017728806
step: 930, loss: 0.0291416198015213
step: 940, loss: 0.1676795482635498
step: 950, loss: 0.06994181871414185
step: 960, loss: 0.13901270925998688
step: 970, loss: 0.05647428333759308
epoch 6: dev_f1=0.9347426470588236, f1=0.9327231121281464, best_f1=0.9318394024276377
step: 0, loss: 0.0002357921766815707
step: 10, loss: 0.03548971191048622
step: 20, loss: 0.08075504750013351
step: 30, loss: 0.009528450667858124
step: 40, loss: 0.024887816980481148
step: 50, loss: 0.05510978028178215
step: 60, loss: 0.11362233757972717
step: 70, loss: 0.22448307275772095
step: 80, loss: 0.04505021125078201
step: 90, loss: 0.03498018532991409
step: 100, loss: 0.10280723869800568
step: 110, loss: 0.06751648336648941
step: 120, loss: 0.06188300997018814
step: 130, loss: 0.021997112780809402
step: 140, loss: 0.012996360659599304
step: 150, loss: 0.010875681415200233
step: 160, loss: 0.08176379650831223
step: 170, loss: 0.12040071934461594
step: 180, loss: 0.15132559835910797
step: 190, loss: 0.0002624944900162518
step: 200, loss: 0.06673009693622589
step: 210, loss: 0.07953013479709625
step: 220, loss: 0.08389106392860413
step: 230, loss: 0.03168760612607002
step: 240, loss: 0.058626964688301086
step: 250, loss: 0.0196438767015934
step: 260, loss: 0.05552815645933151
step: 270, loss: 0.022387703880667686
step: 280, loss: 0.09561049938201904
step: 290, loss: 0.06948454678058624
step: 300, loss: 0.08201655745506287
step: 310, loss: 0.1055045798420906
step: 320, loss: 0.093289315700531
step: 330, loss: 0.028986996039748192
step: 340, loss: 0.03622833639383316
step: 350, loss: 0.05790267884731293
step: 360, loss: 0.028679706156253815
step: 370, loss: 0.08834118396043777
step: 380, loss: 0.13450588285923004
step: 390, loss: 0.014740271493792534
step: 400, loss: 0.007562148384749889
step: 410, loss: 0.0488111712038517
step: 420, loss: 0.098103366792202
step: 430, loss: 0.054419729858636856
step: 440, loss: 0.010195289738476276
step: 450, loss: 0.029126422479748726
step: 460, loss: 0.060458067804574966
step: 470, loss: 0.1426251381635666
step: 480, loss: 0.022517342120409012
step: 490, loss: 0.008360025472939014
step: 500, loss: 0.09607003629207611
step: 510, loss: 0.03133624047040939
step: 520, loss: 0.05173588544130325
step: 530, loss: 0.07384611666202545
step: 540, loss: 0.06490727514028549
step: 550, loss: 0.06361840665340424
step: 560, loss: 0.01648738794028759
step: 570, loss: 0.027054380625486374
step: 580, loss: 0.0993012860417366
step: 590, loss: 0.020764797925949097
step: 600, loss: 0.08052496612071991
step: 610, loss: 0.06584659963846207
step: 620, loss: 0.018605317920446396
step: 630, loss: 0.07624567300081253
step: 640, loss: 0.016054358333349228
step: 650, loss: 0.06647232174873352
step: 660, loss: 0.021822694689035416
step: 670, loss: 0.02772589772939682
step: 680, loss: 0.05783519521355629
step: 690, loss: 0.11851789057254791
step: 700, loss: 0.050708964467048645
step: 710, loss: 0.014555726200342178
step: 720, loss: 0.06939227133989334
step: 730, loss: 0.08276942372322083
step: 740, loss: 0.04981441795825958
step: 750, loss: 0.0069924406707286835
step: 760, loss: 0.07361995428800583
step: 770, loss: 0.009477835148572922
step: 780, loss: 0.08144106715917587
step: 790, loss: 0.06334634125232697
step: 800, loss: 0.03640759736299515
step: 810, loss: 0.08990569412708282
step: 820, loss: 0.02490353025496006
step: 830, loss: 0.04091333597898483
step: 840, loss: 0.010446881875395775
step: 850, loss: 0.08496414124965668
step: 860, loss: 0.017493439838290215
step: 870, loss: 0.028222009539604187
step: 880, loss: 0.029897911474108696
step: 890, loss: 0.05515114963054657
step: 900, loss: 0.16633957624435425
step: 910, loss: 0.13950160145759583
step: 920, loss: 0.043439291417598724
step: 930, loss: 0.02532285265624523
step: 940, loss: 0.052965905517339706
step: 950, loss: 0.1777820736169815
step: 960, loss: 0.02818971872329712
step: 970, loss: 0.06495396792888641
epoch 7: dev_f1=0.9309225776541493, f1=0.9403122130394856, best_f1=0.9318394024276377
step: 0, loss: 0.14191888272762299
step: 10, loss: 0.07978484779596329
step: 20, loss: 0.052918050438165665
step: 30, loss: 0.13771429657936096
step: 40, loss: 0.038448505103588104
step: 50, loss: 0.07412277907133102
step: 60, loss: 0.09624750912189484
step: 70, loss: 0.06095689535140991
step: 80, loss: 0.015463495627045631
step: 90, loss: 0.03691547363996506
step: 100, loss: 0.034680843353271484
step: 110, loss: 0.21957090497016907
step: 120, loss: 0.008717765100300312
step: 130, loss: 0.0843610018491745
step: 140, loss: 0.1415848582983017
step: 150, loss: 0.08895360678434372
step: 160, loss: 0.009807984344661236
step: 170, loss: 0.004318994469940662
step: 180, loss: 0.01745714619755745
step: 190, loss: 0.17032089829444885
step: 200, loss: 0.13105408847332
step: 210, loss: 0.033623069524765015
step: 220, loss: 0.03423602879047394
step: 230, loss: 0.033295318484306335
step: 240, loss: 0.12662911415100098
step: 250, loss: 0.057256247848272324
step: 260, loss: 0.03889128193259239
step: 270, loss: 0.07959922403097153
step: 280, loss: 0.007311900146305561
step: 290, loss: 0.025589700788259506
step: 300, loss: 0.026957806199789047
step: 310, loss: 0.054246753454208374
step: 320, loss: 0.1287839561700821
step: 330, loss: 0.04916596785187721
step: 340, loss: 0.03478984907269478
step: 350, loss: 0.041648585349321365
step: 360, loss: 0.10359835624694824
step: 370, loss: 0.016299070790410042
step: 380, loss: 0.16442179679870605
step: 390, loss: 0.09788887947797775
step: 400, loss: 0.06989329308271408
step: 410, loss: 0.13446468114852905
step: 420, loss: 0.09202960878610611
step: 430, loss: 0.022656472399830818
step: 440, loss: 0.049815159291028976
step: 450, loss: 0.07610195130109787
step: 460, loss: 0.14154264330863953
step: 470, loss: 0.07640334218740463
step: 480, loss: 0.13883209228515625
step: 490, loss: 0.11268206685781479
step: 500, loss: 0.09308954328298569
step: 510, loss: 0.03148481994867325
step: 520, loss: 0.04916760325431824
step: 530, loss: 0.07706663012504578
step: 540, loss: 0.023817766457796097
step: 550, loss: 0.04761922359466553
step: 560, loss: 0.08476070314645767
step: 570, loss: 0.02326035685837269
step: 580, loss: 0.05659552663564682
step: 590, loss: 0.010902038775384426
step: 600, loss: 0.07124676555395126
step: 610, loss: 0.0538891963660717
step: 620, loss: 0.06262598186731339
step: 630, loss: 0.18070058524608612
step: 640, loss: 0.09811118245124817
step: 650, loss: 0.05516631156206131
step: 660, loss: 0.11705467104911804
step: 670, loss: 0.08423042297363281
step: 680, loss: 0.06013272702693939
step: 690, loss: 0.1523561179637909
step: 700, loss: 0.1412011831998825
step: 710, loss: 0.13981877267360687
step: 720, loss: 0.04515395313501358
step: 730, loss: 0.05183904245495796
step: 740, loss: 0.051342468708753586
step: 750, loss: 0.023234745487570763
step: 760, loss: 0.17479589581489563
step: 770, loss: 0.02076435089111328
step: 780, loss: 0.021983012557029724
step: 790, loss: 0.05724666640162468
step: 800, loss: 0.007658820599317551
step: 810, loss: 0.036091625690460205
step: 820, loss: 0.01477907970547676
step: 830, loss: 0.052887823432683945
step: 840, loss: 0.07204567641019821
step: 850, loss: 0.06446055322885513
step: 860, loss: 0.006319864187389612
step: 870, loss: 0.026144538074731827
step: 880, loss: 0.07833335548639297
step: 890, loss: 0.19599813222885132
step: 900, loss: 0.03297952190041542
step: 910, loss: 3.2014449971029535e-05
step: 920, loss: 0.13262619078159332
step: 930, loss: 0.014804838225245476
step: 940, loss: 0.07534456253051758
step: 950, loss: 0.041803501546382904
step: 960, loss: 0.07181626558303833
step: 970, loss: 0.11137561500072479
epoch 8: dev_f1=0.9250234301780694, f1=0.9253592953175707, best_f1=0.9318394024276377
step: 0, loss: 0.09522608667612076
step: 10, loss: 0.02309480868279934
step: 20, loss: 0.1029452458024025
step: 30, loss: 0.0229607205837965
step: 40, loss: 0.03184157609939575
step: 50, loss: 0.11377134919166565
step: 60, loss: 0.024468671530485153
step: 70, loss: 0.01742403768002987
step: 80, loss: 0.07083404064178467
step: 90, loss: 0.12440969794988632
step: 100, loss: 0.2252226620912552
step: 110, loss: 0.031533416360616684
step: 120, loss: 0.02213870920240879
step: 130, loss: 0.028202135115861893
step: 140, loss: 0.06384564936161041
step: 150, loss: 0.05971766263246536
step: 160, loss: 0.03076021932065487
step: 170, loss: 0.020980317145586014
step: 180, loss: 0.015163172036409378
step: 190, loss: 0.009584873914718628
step: 200, loss: 0.023842087015509605
step: 210, loss: 0.021558964625000954
step: 220, loss: 0.15786460041999817
step: 230, loss: 0.0039158170111477375
step: 240, loss: 0.04251660406589508
step: 250, loss: 0.11340759694576263
step: 260, loss: 0.1520240157842636
step: 270, loss: 0.14003875851631165
step: 280, loss: 0.008780649863183498
step: 290, loss: 0.035586465150117874
step: 300, loss: 0.04095121845602989
step: 310, loss: 0.22075685858726501
step: 320, loss: 0.08496694266796112
step: 330, loss: 0.09155913442373276
step: 340, loss: 0.01948930136859417
step: 350, loss: 0.07283497601747513
step: 360, loss: 0.00705291610211134
step: 370, loss: 0.13871894776821136
step: 380, loss: 0.06389821320772171
step: 390, loss: 0.06278049200773239
step: 400, loss: 0.1108982041478157
step: 410, loss: 0.09505762904882431
step: 420, loss: 0.04193324223160744
step: 430, loss: 0.07439621537923813
step: 440, loss: 0.022682830691337585
step: 450, loss: 0.01573227532207966
step: 460, loss: 0.019824888557195663
step: 470, loss: 0.021235398948192596
step: 480, loss: 0.026473306119441986
step: 490, loss: 0.04365547373890877
step: 500, loss: 0.06864148378372192
step: 510, loss: 0.003861841280013323
step: 520, loss: 0.03488373011350632
step: 530, loss: 0.06986719369888306
step: 540, loss: 0.16455082595348358
step: 550, loss: 0.019487177953124046
step: 560, loss: 0.0458979457616806
step: 570, loss: 0.045967552810907364
step: 580, loss: 0.021942563354969025
step: 590, loss: 0.027806859463453293
step: 600, loss: 0.022076841443777084
step: 610, loss: 0.07655534893274307
step: 620, loss: 0.029658116400241852
step: 630, loss: 0.0566922165453434
step: 640, loss: 0.13471384346485138
step: 650, loss: 0.014437566511332989
step: 660, loss: 0.07310180366039276
step: 670, loss: 0.013338515534996986
step: 680, loss: 0.02347559481859207
step: 690, loss: 0.03981725499033928
step: 700, loss: 0.00867164321243763
step: 710, loss: 0.031056411564350128
step: 720, loss: 0.021497026085853577
step: 730, loss: 0.04561642184853554
step: 740, loss: 0.012763449922204018
step: 750, loss: 0.10408950597047806
step: 760, loss: 0.09355013072490692
step: 770, loss: 0.013146920129656792
step: 780, loss: 0.08464072644710541
step: 790, loss: 0.09707360714673996
step: 800, loss: 0.11928362399339676
step: 810, loss: 0.08799469470977783
step: 820, loss: 0.07129064202308655
step: 830, loss: 0.09222298115491867
step: 840, loss: 0.04144526645541191
step: 850, loss: 0.0424867644906044
step: 860, loss: 0.21206066012382507
step: 870, loss: 0.045681752264499664
step: 880, loss: 0.04711024835705757
step: 890, loss: 0.025744520127773285
step: 900, loss: 0.07404472678899765
step: 910, loss: 0.022815443575382233
step: 920, loss: 0.04311716556549072
step: 930, loss: 0.07185319811105728
step: 940, loss: 0.028287271037697792
step: 950, loss: 0.1777990609407425
step: 960, loss: 0.024542666971683502
step: 970, loss: 0.12099668383598328
epoch 9: dev_f1=0.9292833412434741, f1=0.9326424870466321, best_f1=0.9318394024276377
step: 0, loss: 0.07065178453922272
step: 10, loss: 0.05752737820148468
step: 20, loss: 0.005344067700207233
step: 30, loss: 0.05766959488391876
step: 40, loss: 0.15984463691711426
step: 50, loss: 0.28571003675460815
step: 60, loss: 0.04286313056945801
step: 70, loss: 0.04752414673566818
step: 80, loss: 0.09076034277677536
step: 90, loss: 0.06236610561609268
step: 100, loss: 0.07269405573606491
step: 110, loss: 0.06895160675048828
step: 120, loss: 0.04947971552610397
step: 130, loss: 0.09582740068435669
step: 140, loss: 0.02609816938638687
step: 150, loss: 0.17352761328220367
step: 160, loss: 0.05541800707578659
step: 170, loss: 0.04863579943776131
step: 180, loss: 0.1306304633617401
step: 190, loss: 0.03920843452215195
step: 200, loss: 0.1369287520647049
step: 210, loss: 0.1192050501704216
step: 220, loss: 0.06247640773653984
step: 230, loss: 0.07322550565004349
step: 240, loss: 0.08432339131832123
step: 250, loss: 0.05076681450009346
step: 260, loss: 0.016624797135591507
step: 270, loss: 0.11134866625070572
step: 280, loss: 0.10248015820980072
step: 290, loss: 0.06101900711655617
step: 300, loss: 0.14235743880271912
step: 310, loss: 0.022842753678560257
step: 320, loss: 0.09158607572317123
step: 330, loss: 0.03532268851995468
step: 340, loss: 0.08997263759374619
step: 350, loss: 0.13523925840854645
step: 360, loss: 0.028942199423909187
step: 370, loss: 0.04450706019997597
step: 380, loss: 0.04230966791510582
step: 390, loss: 0.007543295621871948
step: 400, loss: 0.011148476041853428
step: 410, loss: 0.00906378123909235
step: 420, loss: 0.12063651531934738
step: 430, loss: 0.09887204319238663
step: 440, loss: 0.07281166315078735
step: 450, loss: 0.010402323678135872
step: 460, loss: 0.06499295681715012
step: 470, loss: 0.06434755027294159
step: 480, loss: 0.04992493614554405
step: 490, loss: 0.07025681436061859
step: 500, loss: 0.0337340421974659
step: 510, loss: 0.00618772255256772
step: 520, loss: 0.030412722378969193
step: 530, loss: 0.02304980531334877
step: 540, loss: 0.009962734766304493
step: 550, loss: 0.07031350582838058
step: 560, loss: 0.01356604415923357
step: 570, loss: 0.020154748111963272
step: 580, loss: 0.01009298488497734
step: 590, loss: 0.10321740806102753
step: 600, loss: 0.09397001564502716
step: 610, loss: 0.06400413811206818
step: 620, loss: 0.07519824057817459
step: 630, loss: 0.013271325267851353
step: 640, loss: 0.003739121835678816
step: 650, loss: 0.00556242186576128
step: 660, loss: 0.023888427764177322
step: 670, loss: 0.052833836525678635
step: 680, loss: 0.07212738692760468
step: 690, loss: 0.03567791357636452
step: 700, loss: 0.012406397610902786
step: 710, loss: 0.0032651370856910944
step: 720, loss: 0.002824682043865323
step: 730, loss: 0.011944945901632309
step: 740, loss: 0.06129318103194237
step: 750, loss: 0.024551380425691605
step: 760, loss: 0.1676177829504013
step: 770, loss: 0.06811726838350296
step: 780, loss: 0.10129913687705994
step: 790, loss: 0.0626385509967804
step: 800, loss: 0.05258290097117424
step: 810, loss: 0.07617297768592834
step: 820, loss: 0.11164145171642303
step: 830, loss: 0.04289853572845459
step: 840, loss: 0.02902190200984478
step: 850, loss: 0.15548604726791382
step: 860, loss: 0.014477439224720001
step: 870, loss: 0.025494182482361794
step: 880, loss: 0.019517013803124428
step: 890, loss: 0.04373519495129585
step: 900, loss: 0.0753195732831955
step: 910, loss: 0.07625867426395416
step: 920, loss: 0.049104493111371994
step: 930, loss: 0.019040510058403015
step: 940, loss: 0.012800781987607479
step: 950, loss: 0.08850765228271484
step: 960, loss: 0.08455844223499298
step: 970, loss: 0.07175201922655106
epoch 10: dev_f1=0.9432558139534885, f1=0.938134810710988, best_f1=0.938134810710988
step: 0, loss: 0.14932987093925476
step: 10, loss: 0.06564339995384216
step: 20, loss: 0.052789002656936646
step: 30, loss: 0.17250686883926392
step: 40, loss: 0.03983588516712189
step: 50, loss: 0.0759393498301506
step: 60, loss: 0.07658643275499344
step: 70, loss: 0.0697418674826622
step: 80, loss: 0.03768884390592575
step: 90, loss: 0.010372838005423546
step: 100, loss: 0.0017388255801051855
step: 110, loss: 0.09009967744350433
step: 120, loss: 0.0891527384519577
step: 130, loss: 0.16569137573242188
step: 140, loss: 0.04158442094922066
step: 150, loss: 0.0032151408959180117
step: 160, loss: 0.1908995509147644
step: 170, loss: 0.00514574209228158
step: 180, loss: 0.012002958916127682
step: 190, loss: 0.01147269457578659
step: 200, loss: 0.0441930815577507
step: 210, loss: 0.05123383551836014
step: 220, loss: 0.10277394205331802
step: 230, loss: 0.06565877050161362
step: 240, loss: 0.1980047971010208
step: 250, loss: 0.006276818457990885
step: 260, loss: 0.004698914475739002
step: 270, loss: 0.061632465571165085
step: 280, loss: 0.010234147310256958
step: 290, loss: 0.1315004974603653
step: 300, loss: 0.15866386890411377
step: 310, loss: 0.033471234142780304
step: 320, loss: 0.018514113500714302
step: 330, loss: 0.00929983425885439
step: 340, loss: 0.004800205118954182
step: 350, loss: 0.14301776885986328
step: 360, loss: 0.007483656518161297
step: 370, loss: 0.06299594789743423
step: 380, loss: 0.0263817198574543
step: 390, loss: 0.025782279670238495
step: 400, loss: 0.0005519139813259244
step: 410, loss: 0.0017749445978552103
step: 420, loss: 0.06527786701917648
step: 430, loss: 0.04635827615857124
step: 440, loss: 0.07836875319480896
step: 450, loss: 0.0630171000957489
step: 460, loss: 0.0461474172770977
step: 470, loss: 0.02370193600654602
step: 480, loss: 0.152431920170784
step: 490, loss: 0.057841550558805466
step: 500, loss: 0.02950146608054638
step: 510, loss: 0.36310967803001404
step: 520, loss: 0.011460596695542336
step: 530, loss: 0.06427397578954697
step: 540, loss: 0.016037164255976677
step: 550, loss: 0.23892731964588165
step: 560, loss: 0.030230224132537842
step: 570, loss: 0.030352244153618813
step: 580, loss: 0.1355888992547989
step: 590, loss: 3.9461276173824444e-05
step: 600, loss: 0.11027814447879791
step: 610, loss: 0.03378294035792351
step: 620, loss: 0.002331376541405916
step: 630, loss: 0.05852584168314934
step: 640, loss: 0.012813962064683437
step: 650, loss: 0.03445771709084511
step: 660, loss: 0.13982641696929932
step: 670, loss: 0.00898229144513607
step: 680, loss: 0.05398281291127205
step: 690, loss: 0.020976409316062927
step: 700, loss: 0.044089481234550476
step: 710, loss: 0.012868897058069706
step: 720, loss: 0.016507884487509727
step: 730, loss: 0.02257564477622509
step: 740, loss: 4.697842086898163e-05
step: 750, loss: 0.13241182267665863
step: 760, loss: 0.04912910982966423
step: 770, loss: 0.03198980167508125
step: 780, loss: 0.011775885708630085
step: 790, loss: 0.0033249869011342525
step: 800, loss: 0.09600919485092163
step: 810, loss: 0.03463173285126686
step: 820, loss: 0.13094846904277802
step: 830, loss: 0.10749105364084244
step: 840, loss: 0.020552195608615875
step: 850, loss: 0.0034343607258051634
step: 860, loss: 0.08508886396884918
step: 870, loss: 0.06284689158201218
step: 880, loss: 0.08062567561864853
step: 890, loss: 0.09802445769309998
step: 900, loss: 0.10627610236406326
step: 910, loss: 0.011474061757326126
step: 920, loss: 0.11655344069004059
step: 930, loss: 0.09080225229263306
step: 940, loss: 0.007285636849701405
step: 950, loss: 0.08786960691213608
step: 960, loss: 0.06418941169977188
step: 970, loss: 0.017053648829460144
epoch 11: dev_f1=0.9343200740055504, f1=0.9317972350230416, best_f1=0.938134810710988
step: 0, loss: 0.016625674441456795
step: 10, loss: 0.03559793531894684
step: 20, loss: 0.11239712685346603
step: 30, loss: 0.013685770332813263
step: 40, loss: 0.04759451374411583
step: 50, loss: 0.013957668095827103
step: 60, loss: 0.016525380313396454
step: 70, loss: 0.04267143830657005
step: 80, loss: 0.09155486524105072
step: 90, loss: 0.009059610776603222
step: 100, loss: 0.1567908078432083
step: 110, loss: 0.10082264244556427
step: 120, loss: 0.020008910447359085
step: 130, loss: 0.05190572515130043
step: 140, loss: 0.01555850263684988
step: 150, loss: 0.014138429425656796
step: 160, loss: 0.055957067757844925
step: 170, loss: 0.003277722978964448
step: 180, loss: 0.007600936572998762
step: 190, loss: 0.0018381992122158408
step: 200, loss: 0.04249352589249611
step: 210, loss: 0.03142896667122841
step: 220, loss: 0.1169150173664093
step: 230, loss: 0.03554251044988632
step: 240, loss: 0.021823957562446594
step: 250, loss: 0.0021556555293500423
step: 260, loss: 0.008343325927853584
step: 270, loss: 0.052846137434244156
step: 280, loss: 0.10889726132154465
step: 290, loss: 0.0408138744533062
step: 300, loss: 0.031180089339613914
step: 310, loss: 0.14990398287773132
step: 320, loss: 0.08235378563404083
step: 330, loss: 0.04210866987705231
step: 340, loss: 0.028987031430006027
step: 350, loss: 0.130226731300354
step: 360, loss: 0.028218047693371773
step: 370, loss: 0.07229731231927872
step: 380, loss: 0.009250466711819172
step: 390, loss: 0.1139099970459938
step: 400, loss: 0.027310555800795555
step: 410, loss: 0.004111908376216888
step: 420, loss: 0.08421313762664795
step: 430, loss: 0.035801179707050323
step: 440, loss: 0.032817620784044266
step: 450, loss: 0.03373003378510475
step: 460, loss: 0.0024935407564044
step: 470, loss: 0.01678665168583393
step: 480, loss: 0.024829650297760963
step: 490, loss: 0.05097440257668495
step: 500, loss: 0.02127774991095066
step: 510, loss: 0.0605539008975029
step: 520, loss: 0.015305726788938046
step: 530, loss: 0.038805097341537476
step: 540, loss: 0.04928520694375038
step: 550, loss: 0.042507920414209366
step: 560, loss: 0.034104153513908386
step: 570, loss: 0.019676126539707184
step: 580, loss: 0.13650503754615784
step: 590, loss: 0.026849601417779922
step: 600, loss: 0.059009015560150146
step: 610, loss: 0.07048017531633377
step: 620, loss: 0.012866552919149399
step: 630, loss: 0.07400780916213989
step: 640, loss: 0.07249484211206436
step: 650, loss: 0.02007090300321579
step: 660, loss: 0.002509717596694827
step: 670, loss: 0.031460706144571304
step: 680, loss: 0.033096205443143845
step: 690, loss: 0.07665175199508667
step: 700, loss: 0.017655787989497185
step: 710, loss: 0.03436751663684845
step: 720, loss: 0.062097080051898956
step: 730, loss: 0.07681666314601898
step: 740, loss: 0.04060940816998482
step: 750, loss: 0.07327703386545181
step: 760, loss: 0.14353233575820923
step: 770, loss: 0.046984896063804626
step: 780, loss: 0.03695724159479141
step: 790, loss: 0.05905536562204361
step: 800, loss: 0.060765430331230164
step: 810, loss: 0.03432006388902664
step: 820, loss: 0.17643125355243683
step: 830, loss: 0.059730637818574905
step: 840, loss: 0.08373748511075974
step: 850, loss: 0.03206665441393852
step: 860, loss: 0.0277080275118351
step: 870, loss: 0.19652535021305084
step: 880, loss: 0.09527936577796936
step: 890, loss: 0.08653753250837326
step: 900, loss: 0.08234670758247375
step: 910, loss: 0.00711814733222127
step: 920, loss: 0.16867563128471375
step: 930, loss: 0.005278155207633972
step: 940, loss: 0.0548170767724514
step: 950, loss: 0.006511731538921595
step: 960, loss: 0.01269889622926712
step: 970, loss: 0.001356857013888657
epoch 12: dev_f1=0.9319470699432891, f1=0.9355742296918768, best_f1=0.938134810710988
step: 0, loss: 0.04646749421954155
step: 10, loss: 0.037748485803604126
step: 20, loss: 0.00209126528352499
step: 30, loss: 0.0712188184261322
step: 40, loss: 0.02530663087964058
step: 50, loss: 0.003206077730283141
step: 60, loss: 0.06621555984020233
step: 70, loss: 0.0013678992399945855
step: 80, loss: 0.033238522708415985
step: 90, loss: 0.017582986503839493
step: 100, loss: 0.015393058769404888
step: 110, loss: 0.0659070834517479
step: 120, loss: 0.07488871365785599
step: 130, loss: 0.03867950662970543
step: 140, loss: 0.08445826917886734
step: 150, loss: 0.11538276076316833
step: 160, loss: 0.08477906882762909
step: 170, loss: 0.028078775852918625
step: 180, loss: 0.09133447706699371
step: 190, loss: 0.021103903651237488
step: 200, loss: 0.09199359267950058
step: 210, loss: 0.07560255378484726
step: 220, loss: 0.012399968691170216
step: 230, loss: 0.01620195247232914
step: 240, loss: 0.09206151217222214
step: 250, loss: 0.013692731037735939
step: 260, loss: 0.103314109146595
step: 270, loss: 0.010310206562280655
step: 280, loss: 0.01981808803975582
step: 290, loss: 0.11053890734910965
step: 300, loss: 0.019664902240037918
step: 310, loss: 0.017197173088788986
step: 320, loss: 0.018690334632992744
step: 330, loss: 0.15390712022781372
step: 340, loss: 0.02288052625954151
step: 350, loss: 0.07288365066051483
step: 360, loss: 0.06959140300750732
step: 370, loss: 0.08253779262304306
step: 380, loss: 0.033602409064769745
step: 390, loss: 0.041231103241443634
step: 400, loss: 0.06889168173074722
step: 410, loss: 0.00570832472294569
step: 420, loss: 0.004928882699459791
step: 430, loss: 0.04257849231362343
step: 440, loss: 0.027711402624845505
step: 450, loss: 0.06061789393424988
step: 460, loss: 0.003818637691438198
step: 470, loss: 0.021340304985642433
step: 480, loss: 0.03514482080936432
step: 490, loss: 0.010468391701579094
step: 500, loss: 0.11195588856935501
step: 510, loss: 0.036327604204416275
step: 520, loss: 0.020014233887195587
step: 530, loss: 0.04169543832540512
step: 540, loss: 0.0219940897077322
step: 550, loss: 0.009662382304668427
step: 560, loss: 0.015251761302351952
step: 570, loss: 0.02609589323401451
step: 580, loss: 0.1392282247543335
step: 590, loss: 0.0073784105479717255
step: 600, loss: 0.04678931459784508
step: 610, loss: 0.06041855365037918
step: 620, loss: 0.06582276523113251
step: 630, loss: 0.04316287487745285
step: 640, loss: 0.016377514228224754
step: 650, loss: 0.09263288229703903
step: 660, loss: 0.10524744540452957
step: 670, loss: 0.006597177125513554
step: 680, loss: 0.07014120370149612
step: 690, loss: 0.10956867039203644
step: 700, loss: 0.07344510406255722
step: 710, loss: 0.011912956833839417
step: 720, loss: 0.018103424459695816
step: 730, loss: 0.05151425302028656
step: 740, loss: 0.08960306644439697
step: 750, loss: 0.029078371822834015
step: 760, loss: 0.017745358869433403
step: 770, loss: 0.05949142202734947
step: 780, loss: 0.052335020154714584
step: 790, loss: 0.0062755742110311985
step: 800, loss: 0.05555735528469086
step: 810, loss: 0.007070006802678108
step: 820, loss: 0.023600690066814423
step: 830, loss: 0.15799173712730408
step: 840, loss: 0.019115518778562546
step: 850, loss: 0.021386120468378067
step: 860, loss: 0.06518952548503876
step: 870, loss: 0.0686815083026886
step: 880, loss: 0.04373938962817192
step: 890, loss: 0.00018356660439167172
step: 900, loss: 0.02646084688603878
step: 910, loss: 0.030787277966737747
step: 920, loss: 0.02597188763320446
step: 930, loss: 0.048752039670944214
step: 940, loss: 0.05665120109915733
step: 950, loss: 0.018642116338014603
step: 960, loss: 0.003549566026777029
step: 970, loss: 0.0027215236332267523
epoch 13: dev_f1=0.9289411764705882, f1=0.930776426566885, best_f1=0.938134810710988
step: 0, loss: 0.013300305232405663
step: 10, loss: 0.05083095282316208
step: 20, loss: 0.07374385744333267
step: 30, loss: 0.03208320215344429
step: 40, loss: 0.08222059905529022
step: 50, loss: 0.08466020971536636
step: 60, loss: 0.0076704248785972595
step: 70, loss: 0.011728930287063122
step: 80, loss: 0.16573376953601837
step: 90, loss: 0.00862104445695877
step: 100, loss: 0.04099339246749878
step: 110, loss: 0.023668324574828148
step: 120, loss: 0.05904368683695793
step: 130, loss: 0.04429680109024048
step: 140, loss: 0.030511213466525078
step: 150, loss: 0.09985427558422089
step: 160, loss: 0.07026272267103195
step: 170, loss: 0.004253820516169071
step: 180, loss: 0.044817741960287094
step: 190, loss: 0.07032738626003265
step: 200, loss: 0.01979081891477108
step: 210, loss: 0.03329399600625038
step: 220, loss: 0.0007643483113497496
step: 230, loss: 0.0036969203501939774
step: 240, loss: 0.08051371574401855
step: 250, loss: 0.002506026765331626
step: 260, loss: 0.04688149318099022
step: 270, loss: 0.0031213678885251284
step: 280, loss: 0.00022310760687105358
step: 290, loss: 0.10313834249973297
step: 300, loss: 0.007992059923708439
step: 310, loss: 0.011443374678492546
step: 320, loss: 0.07286395877599716
step: 330, loss: 0.04496247321367264
step: 340, loss: 0.001640588161535561
step: 350, loss: 0.004405969753861427
step: 360, loss: 0.0029350845143198967
step: 370, loss: 0.07040879875421524
step: 380, loss: 0.1544199287891388
step: 390, loss: 0.04109073430299759
step: 400, loss: 0.0004653333453461528
step: 410, loss: 0.07875632494688034
step: 420, loss: 0.022917360067367554
step: 430, loss: 0.0006779654650017619
step: 440, loss: 0.1164325699210167
step: 450, loss: 0.02140495926141739
step: 460, loss: 0.03336722031235695
step: 470, loss: 0.00045847598812542856
step: 480, loss: 0.04660429432988167
step: 490, loss: 9.739337838254869e-05
step: 500, loss: 0.036219339817762375
step: 510, loss: 0.09439513832330704
step: 520, loss: 0.03603120893239975
step: 530, loss: 0.03741054609417915
step: 540, loss: 0.0009775686776265502
step: 550, loss: 0.07370792329311371
step: 560, loss: 0.051069024950265884
step: 570, loss: 0.024308757856488228
step: 580, loss: 0.004570744000375271
step: 590, loss: 0.20609210431575775
step: 600, loss: 0.039756618440151215
step: 610, loss: 0.05318344011902809
step: 620, loss: 0.022294215857982635
step: 630, loss: 0.042910296469926834
step: 640, loss: 0.008415281772613525
step: 650, loss: 0.040170103311538696
step: 660, loss: 0.04808195307850838
step: 670, loss: 0.06973448395729065
step: 680, loss: 0.03524908423423767
step: 690, loss: 0.04168112203478813
step: 700, loss: 0.09890127927064896
step: 710, loss: 0.028409697115421295
step: 720, loss: 0.0672641396522522
step: 730, loss: 0.11607480049133301
step: 740, loss: 0.033525869250297546
step: 750, loss: 0.02660186029970646
step: 760, loss: 0.014464296400547028
step: 770, loss: 0.0507221482694149
step: 780, loss: 0.0030211007688194513
step: 790, loss: 0.044602375477552414
step: 800, loss: 0.013049278408288956
step: 810, loss: 0.03842939808964729
step: 820, loss: 0.017077399417757988
step: 830, loss: 0.013438951224088669
step: 840, loss: 0.08695586770772934
step: 850, loss: 0.05186346918344498
step: 860, loss: 0.02572052739560604
step: 870, loss: 0.05620412528514862
step: 880, loss: 0.03365094214677811
step: 890, loss: 0.036735571920871735
step: 900, loss: 0.04131987690925598
step: 910, loss: 0.08316720277070999
step: 920, loss: 0.03527100384235382
step: 930, loss: 0.07681319862604141
step: 940, loss: 0.015280966646969318
step: 950, loss: 0.01216014102101326
step: 960, loss: 0.037773702293634415
step: 970, loss: 0.11962053179740906
epoch 14: dev_f1=0.935258500232883, f1=0.9367789570835257, best_f1=0.938134810710988
step: 0, loss: 0.06331312656402588
step: 10, loss: 0.027526769787073135
step: 20, loss: 0.06058156490325928
step: 30, loss: 0.08469191193580627
step: 40, loss: 0.11699244379997253
step: 50, loss: 0.04281361773610115
step: 60, loss: 0.016527904197573662
step: 70, loss: 0.01918056793510914
step: 80, loss: 0.02932623401284218
step: 90, loss: 0.012704825960099697
step: 100, loss: 0.02482517994940281
step: 110, loss: 0.015059016644954681
step: 120, loss: 0.04519147798418999
step: 130, loss: 0.011109762825071812
step: 140, loss: 0.012109441682696342
step: 150, loss: 0.003609503386542201
step: 160, loss: 0.02537182904779911
step: 170, loss: 0.00112531881313771
step: 180, loss: 0.17067013680934906
step: 190, loss: 0.038317639380693436
step: 200, loss: 0.005247083958238363
step: 210, loss: 0.056129198521375656
step: 220, loss: 0.03148525208234787
step: 230, loss: 0.014582129195332527
step: 240, loss: 0.001003387151286006
step: 250, loss: 0.03810294345021248
step: 260, loss: 0.04623153805732727
step: 270, loss: 0.18941110372543335
step: 280, loss: 0.06604575365781784
step: 290, loss: 0.03072228468954563
step: 300, loss: 0.06657159328460693
step: 310, loss: 0.06119028851389885
step: 320, loss: 0.031070271506905556
step: 330, loss: 0.053135454654693604
step: 340, loss: 0.07731705158948898
step: 350, loss: 0.02799246832728386
step: 360, loss: 0.0013790760422125459
step: 370, loss: 0.04964333772659302
step: 380, loss: 0.0003805643937084824
step: 390, loss: 0.02724950760602951
step: 400, loss: 0.004790112376213074
step: 410, loss: 0.03516734763979912
step: 420, loss: 0.12476339191198349
step: 430, loss: 0.012362846173346043
step: 440, loss: 0.021005380898714066
step: 450, loss: 0.007471099030226469
step: 460, loss: 0.0011955357622355223
step: 470, loss: 0.02281315065920353
step: 480, loss: 0.009744914248585701
step: 490, loss: 0.04057934880256653
step: 500, loss: 0.08680146932601929
step: 510, loss: 0.05371988192200661
step: 520, loss: 0.022759102284908295
step: 530, loss: 0.03431181609630585
step: 540, loss: 0.12585464119911194
step: 550, loss: 0.035443954169750214
step: 560, loss: 0.005991699639707804
step: 570, loss: 0.03618129715323448
step: 580, loss: 0.04686146229505539
step: 590, loss: 0.11734126508235931
step: 600, loss: 0.0003748884773813188
step: 610, loss: 0.009567205794155598
step: 620, loss: 0.002998901763930917
step: 630, loss: 0.03358149901032448
step: 640, loss: 0.026369640603661537
step: 650, loss: 0.016843296587467194
step: 660, loss: 0.05284330993890762
step: 670, loss: 0.012194273062050343
step: 680, loss: 0.02450660616159439
step: 690, loss: 0.0271059051156044
step: 700, loss: 0.1119651198387146
step: 710, loss: 0.06841734796762466
step: 720, loss: 0.0032025673426687717
step: 730, loss: 0.038504261523485184
step: 740, loss: 0.029711969196796417
step: 750, loss: 0.040063973516225815
step: 760, loss: 0.06732694804668427
step: 770, loss: 0.05161885917186737
step: 780, loss: 0.022268330678343773
step: 790, loss: 0.0004128252621740103
step: 800, loss: 0.026745107024908066
step: 810, loss: 0.005697774700820446
step: 820, loss: 0.07714688777923584
step: 830, loss: 0.06033730506896973
step: 840, loss: 0.02480669692158699
step: 850, loss: 0.03173843398690224
step: 860, loss: 0.1863793432712555
step: 870, loss: 0.02306271903216839
step: 880, loss: 0.007978629320859909
step: 890, loss: 0.06426491588354111
step: 900, loss: 0.03578046336770058
step: 910, loss: 0.005645593628287315
step: 920, loss: 0.04447418451309204
step: 930, loss: 0.005850652232766151
step: 940, loss: 0.05536365136504173
step: 950, loss: 0.06660986691713333
step: 960, loss: 0.11261681467294693
step: 970, loss: 0.05045032501220703
epoch 15: dev_f1=0.932093023255814, f1=0.9339491916859123, best_f1=0.938134810710988
step: 0, loss: 0.017553476616740227
step: 10, loss: 0.014886054210364819
step: 20, loss: 0.002724171383306384
step: 30, loss: 0.07184994965791702
step: 40, loss: 0.03712594509124756
step: 50, loss: 0.09093979001045227
step: 60, loss: 0.03562455624341965
step: 70, loss: 0.04932871460914612
step: 80, loss: 0.042489420622587204
step: 90, loss: 0.0484490767121315
step: 100, loss: 0.012927990406751633
step: 110, loss: 0.06918181478977203
step: 120, loss: 0.025530602782964706
step: 130, loss: 0.018453704193234444
step: 140, loss: 0.10903657227754593
step: 150, loss: 0.07738307863473892
step: 160, loss: 0.02172476425766945
step: 170, loss: 0.02371663600206375
step: 180, loss: 0.0007431278354488313
step: 190, loss: 0.042900897562503815
step: 200, loss: 0.01757827214896679
step: 210, loss: 0.024715621024370193
step: 220, loss: 0.039827313274145126
step: 230, loss: 0.00047090707812458277
step: 240, loss: 0.013001945801079273
step: 250, loss: 0.029032327234745026
step: 260, loss: 0.05510491132736206
step: 270, loss: 0.0019678825046867132
step: 280, loss: 0.028712211176753044
step: 290, loss: 0.014042495749890804
step: 300, loss: 0.0406796969473362
step: 310, loss: 0.08256404101848602
step: 320, loss: 0.0004545689735095948
step: 330, loss: 0.0038615649100393057
step: 340, loss: 0.11504233628511429
step: 350, loss: 0.02505568414926529
step: 360, loss: 0.07219363749027252
step: 370, loss: 0.07859893143177032
step: 380, loss: 0.03881143033504486
step: 390, loss: 0.02308388240635395
step: 400, loss: 0.029925521463155746
step: 410, loss: 0.031770166009664536
step: 420, loss: 0.015545520931482315
step: 430, loss: 0.05563027039170265
step: 440, loss: 0.020968664437532425
step: 450, loss: 0.0003842622973024845
step: 460, loss: 0.009182288311421871
step: 470, loss: 0.019355153664946556
step: 480, loss: 0.034454721957445145
step: 490, loss: 0.04664655774831772
step: 500, loss: 0.00021814399224240333
step: 510, loss: 0.03407006338238716
step: 520, loss: 0.03087328001856804
step: 530, loss: 0.04714982956647873
step: 540, loss: 0.05505911260843277
step: 550, loss: 1.0136443052033428e-05
step: 560, loss: 0.00035433360608294606
step: 570, loss: 0.0001509458670625463
step: 580, loss: 0.0488121472299099
step: 590, loss: 0.033437423408031464
step: 600, loss: 0.02404075115919113
step: 610, loss: 0.022884562611579895
step: 620, loss: 0.08470521867275238
step: 630, loss: 0.004313879646360874
step: 640, loss: 0.022272979840636253
step: 650, loss: 0.058028411120176315
step: 660, loss: 0.027777519077062607
step: 670, loss: 0.03724562004208565
step: 680, loss: 0.032644886523485184
step: 690, loss: 0.0754593089222908
step: 700, loss: 0.02882036566734314
step: 710, loss: 0.04892374947667122
step: 720, loss: 0.0002219898160547018
step: 730, loss: 0.037491779774427414
step: 740, loss: 0.1031990498304367
step: 750, loss: 0.00481116259470582
step: 760, loss: 0.017812589183449745
step: 770, loss: 0.11910755932331085
step: 780, loss: 0.03254738450050354
step: 790, loss: 0.02520633675158024
step: 800, loss: 0.04323255270719528
step: 810, loss: 0.00017360097263008356
step: 820, loss: 0.064826101064682
step: 830, loss: 0.008890234865248203
step: 840, loss: 0.0297437384724617
step: 850, loss: 0.04182424768805504
step: 860, loss: 0.022424964234232903
step: 870, loss: 0.020280268043279648
step: 880, loss: 0.05021529272198677
step: 890, loss: 0.04057978093624115
step: 900, loss: 0.016651775687932968
step: 910, loss: 0.05844917893409729
step: 920, loss: 0.0010299745481461287
step: 930, loss: 0.07150149345397949
step: 940, loss: 0.0195049736648798
step: 950, loss: 0.04453172907233238
step: 960, loss: 0.004392548929899931
step: 970, loss: 0.06687512248754501
epoch 16: dev_f1=0.9288354898336414, f1=0.9344413665743306, best_f1=0.938134810710988
step: 0, loss: 0.02312159165740013
step: 10, loss: 0.011699366383254528
step: 20, loss: 0.07138917595148087
step: 30, loss: 0.002045169472694397
step: 40, loss: 0.04214199632406235
step: 50, loss: 0.044804926961660385
step: 60, loss: 0.018430355936288834
step: 70, loss: 0.03604080528020859
step: 80, loss: 0.023247886449098587
step: 90, loss: 0.0704248920083046
step: 100, loss: 0.026097863912582397
step: 110, loss: 0.022896014153957367
step: 120, loss: 0.08610282838344574
step: 130, loss: 0.0409226156771183
step: 140, loss: 0.008183573372662067
step: 150, loss: 0.041651371866464615
step: 160, loss: 0.032532162964344025
step: 170, loss: 0.07781179994344711
step: 180, loss: 0.0397387258708477
step: 190, loss: 0.03333984687924385
step: 200, loss: 0.026966363191604614
step: 210, loss: 0.0028666285797953606
step: 220, loss: 0.005664943251758814
step: 230, loss: 0.009604183956980705
step: 240, loss: 0.036989402025938034
step: 250, loss: 0.018549691885709763
step: 260, loss: 0.018498120829463005
step: 270, loss: 9.93406938505359e-05
step: 280, loss: 0.018892353400588036
step: 290, loss: 0.021222583949565887
step: 300, loss: 0.0018054454121738672
step: 310, loss: 0.013706970028579235
step: 320, loss: 0.015729350969195366
step: 330, loss: 0.04660448059439659
step: 340, loss: 0.01756494864821434
step: 350, loss: 0.0013482242356985807
step: 360, loss: 0.007771756500005722
step: 370, loss: 0.021270178258419037
step: 380, loss: 0.02447725087404251
step: 390, loss: 2.1689394998247735e-05
step: 400, loss: 0.062338147312402725
step: 410, loss: 0.08303989470005035
step: 420, loss: 0.03950100019574165
step: 430, loss: 0.03748949244618416
step: 440, loss: 0.019170936197042465
step: 450, loss: 0.07417149096727371
step: 460, loss: 0.03633634001016617
step: 470, loss: 0.11674387007951736
step: 480, loss: 0.03645821660757065
step: 490, loss: 0.021484000608325005
step: 500, loss: 0.002167024416849017
step: 510, loss: 0.019327016547322273
step: 520, loss: 0.021540265530347824
step: 530, loss: 0.04058697447180748
step: 540, loss: 0.025393862277269363
step: 550, loss: 0.024614576250314713
step: 560, loss: 0.0314662903547287
step: 570, loss: 0.014487124048173428
step: 580, loss: 0.015053425915539265
step: 590, loss: 0.04833686724305153
step: 600, loss: 0.045081011950969696
step: 610, loss: 0.07066454738378525
step: 620, loss: 8.111901115626097e-05
step: 630, loss: 0.04566171392798424
step: 640, loss: 0.0004542032547760755
step: 650, loss: 0.032647665590047836
step: 660, loss: 0.05805591493844986
step: 670, loss: 0.00012977674487046897
step: 680, loss: 5.8735367929330096e-05
step: 690, loss: 0.04582614451646805
step: 700, loss: 0.0880003273487091
step: 710, loss: 0.04440541937947273
step: 720, loss: 0.03094612807035446
step: 730, loss: 0.04537235572934151
step: 740, loss: 0.014938444830477238
step: 750, loss: 0.11507460474967957
step: 760, loss: 0.011079750955104828
step: 770, loss: 0.019411316141486168
step: 780, loss: 0.0012511833338066936
step: 790, loss: 0.027461355552077293
step: 800, loss: 0.020110344514250755
step: 810, loss: 0.03143052011728287
step: 820, loss: 0.025761011987924576
step: 830, loss: 0.05751741677522659
step: 840, loss: 0.02085193619132042
step: 850, loss: 9.426529140910134e-05
step: 860, loss: 0.0828702300786972
step: 870, loss: 0.1395532637834549
step: 880, loss: 0.022615086287260056
step: 890, loss: 0.09760304540395737
step: 900, loss: 0.030337128788232803
step: 910, loss: 0.14884041249752045
step: 920, loss: 0.11145047098398209
step: 930, loss: 0.06935323774814606
step: 940, loss: 0.05617408826947212
step: 950, loss: 0.0007652402273379266
step: 960, loss: 5.834713010699488e-05
step: 970, loss: 0.036703966557979584
epoch 17: dev_f1=0.9334582942830365, f1=0.9306008383791335, best_f1=0.938134810710988
step: 0, loss: 0.03854987770318985
step: 10, loss: 0.000488719146233052
step: 20, loss: 0.053036052733659744
step: 30, loss: 0.0403340682387352
step: 40, loss: 0.1255141794681549
step: 50, loss: 0.11689160019159317
step: 60, loss: 0.002885476453229785
step: 70, loss: 0.024545567110180855
step: 80, loss: 0.05033471807837486
step: 90, loss: 0.011605671606957912
step: 100, loss: 0.018094617873430252
step: 110, loss: 0.0005470942123793066
step: 120, loss: 0.022539108991622925
step: 130, loss: 8.117849938571453e-05
step: 140, loss: 0.0004851844278164208
step: 150, loss: 0.07418850064277649
step: 160, loss: 0.020363181829452515
step: 170, loss: 0.05391605943441391
step: 180, loss: 0.0655498281121254
step: 190, loss: 0.10187400877475739
step: 200, loss: 0.054718222469091415
step: 210, loss: 0.0014378235209733248
step: 220, loss: 0.004246521275490522
step: 230, loss: 0.08016074448823929
step: 240, loss: 0.01818857342004776
step: 250, loss: 0.05112451687455177
step: 260, loss: 0.008850646205246449
step: 270, loss: 0.011138241738080978
step: 280, loss: 0.026698246598243713
step: 290, loss: 0.03711109608411789
step: 300, loss: 0.044199682772159576
step: 310, loss: 9.56268486334011e-05
step: 320, loss: 0.0163609329611063
step: 330, loss: 0.020327363163232803
step: 340, loss: 0.037529926747083664
step: 350, loss: 0.040689777582883835
step: 360, loss: 0.0393984280526638
step: 370, loss: 0.05293877050280571
step: 380, loss: 0.0002839016087818891
step: 390, loss: 0.025432437658309937
step: 400, loss: 0.00018767593428492546
step: 410, loss: 0.047974854707717896
step: 420, loss: 0.07317393273115158
step: 430, loss: 0.035322267562150955
step: 440, loss: 0.010507703758776188
step: 450, loss: 0.02661256119608879
step: 460, loss: 0.06728126853704453
step: 470, loss: 6.554899300681427e-05
step: 480, loss: 0.036692265421152115
step: 490, loss: 0.06283345073461533
step: 500, loss: 0.051639385521411896
step: 510, loss: 0.035152617841959
step: 520, loss: 0.002275200793519616
step: 530, loss: 0.03950880095362663
step: 540, loss: 0.03061312809586525
step: 550, loss: 0.11234681308269501
step: 560, loss: 0.02382601425051689
step: 570, loss: 0.035765018314123154
step: 580, loss: 5.3861294873058796e-05
step: 590, loss: 0.004375654272735119
step: 600, loss: 0.0034200563095510006
step: 610, loss: 0.000515551830176264
step: 620, loss: 0.015807222574949265
step: 630, loss: 0.022516079246997833
step: 640, loss: 0.0004209715116303414
step: 650, loss: 0.027255861088633537
step: 660, loss: 0.030771560966968536
step: 670, loss: 0.023228870704770088
step: 680, loss: 0.0020498810335993767
step: 690, loss: 0.027362389490008354
step: 700, loss: 0.03815869241952896
step: 710, loss: 0.08322031795978546
step: 720, loss: 0.00064710812876001
step: 730, loss: 0.02896939031779766
step: 740, loss: 0.02272368222475052
step: 750, loss: 0.0006862353184260428
step: 760, loss: 0.014832333661615849
step: 770, loss: 0.055888693779706955
step: 780, loss: 0.02967405691742897
step: 790, loss: 0.010558100417256355
step: 800, loss: 0.015133225359022617
step: 810, loss: 0.025300832465291023
step: 820, loss: 0.02686534821987152
step: 830, loss: 0.0235405582934618
step: 840, loss: 0.06404270976781845
step: 850, loss: 0.08840455859899521
step: 860, loss: 0.046579208225011826
step: 870, loss: 0.020624319091439247
step: 880, loss: 0.04233824089169502
step: 890, loss: 0.07123040407896042
step: 900, loss: 0.011198462918400764
step: 910, loss: 0.01934310421347618
step: 920, loss: 0.03300466388463974
step: 930, loss: 0.017617614939808846
step: 940, loss: 0.00012192937720101327
step: 950, loss: 0.05663102865219116
step: 960, loss: 0.014090162701904774
step: 970, loss: 0.04510686919093132
epoch 18: dev_f1=0.9342043863742416, f1=0.9304267161410019, best_f1=0.938134810710988
step: 0, loss: 6.161542114568874e-05
step: 10, loss: 0.03200417011976242
step: 20, loss: 0.06588535755872726
step: 30, loss: 0.040677789598703384
step: 40, loss: 0.03728213533759117
step: 50, loss: 0.04505043849349022
step: 60, loss: 0.025682585313916206
step: 70, loss: 0.02377508208155632
step: 80, loss: 0.04543658345937729
step: 90, loss: 0.06887643039226532
step: 100, loss: 0.0491173230111599
step: 110, loss: 0.00016969235730357468
step: 120, loss: 0.07630319893360138
step: 130, loss: 0.017837826162576675
step: 140, loss: 0.03902706876397133
step: 150, loss: 0.021175559610128403
step: 160, loss: 0.023677492514252663
step: 170, loss: 0.024592285975813866
step: 180, loss: 0.08619464933872223
step: 190, loss: 0.022795021533966064
step: 200, loss: 0.026957113295793533
step: 210, loss: 0.06445297598838806
step: 220, loss: 6.673752795904875e-05
step: 230, loss: 0.07462288439273834
step: 240, loss: 0.00027644750662148
step: 250, loss: 6.670231960015371e-05
step: 260, loss: 0.022997785359621048
step: 270, loss: 0.08142291009426117
step: 280, loss: 0.0005000742385163903
step: 290, loss: 6.58330536680296e-05
step: 300, loss: 0.022747410461306572
step: 310, loss: 0.003916440065950155
step: 320, loss: 0.09449451416730881
step: 330, loss: 0.0648682564496994
step: 340, loss: 8.609064389020205e-05
step: 350, loss: 0.07416559010744095
step: 360, loss: 8.350663119927049e-05
step: 370, loss: 0.02338988147675991
step: 380, loss: 0.04224052652716637
step: 390, loss: 0.0452958308160305
step: 400, loss: 0.047053270041942596
step: 410, loss: 0.03153785690665245
step: 420, loss: 0.023878466337919235
step: 430, loss: 0.00366716249845922
step: 440, loss: 0.014084519818425179
step: 450, loss: 0.026786314323544502
step: 460, loss: 0.03372484818100929
step: 470, loss: 0.06802618503570557
step: 480, loss: 0.026919210329651833
step: 490, loss: 0.014966482296586037
step: 500, loss: 0.03620224446058273
step: 510, loss: 0.00010175351781072095
step: 520, loss: 0.053675729781389236
step: 530, loss: 0.031995534896850586
step: 540, loss: 0.024977590888738632
step: 550, loss: 0.0037143935915082693
step: 560, loss: 0.035427164286375046
step: 570, loss: 0.02230881154537201
step: 580, loss: 0.036545343697071075
step: 590, loss: 0.022646106779575348
step: 600, loss: 0.00015502738824579865
step: 610, loss: 0.06685277074575424
step: 620, loss: 0.07886290550231934
step: 630, loss: 9.830745693761855e-05
step: 640, loss: 0.04687589779496193
step: 650, loss: 0.025618772953748703
step: 660, loss: 0.04370098188519478
step: 670, loss: 0.07183597981929779
step: 680, loss: 5.7434855989413336e-05
step: 690, loss: 0.0012299239169806242
step: 700, loss: 0.0012020582798868418
step: 710, loss: 0.1198810562491417
step: 720, loss: 0.020877936854958534
step: 730, loss: 0.04014052078127861
step: 740, loss: 0.04541613906621933
step: 750, loss: 0.0001529147120891139
step: 760, loss: 0.0421086922287941
step: 770, loss: 0.012955139391124249
step: 780, loss: 4.618717866833322e-05
step: 790, loss: 0.04357951134443283
step: 800, loss: 4.233975778333843e-05
step: 810, loss: 0.041740890592336655
step: 820, loss: 9.018658602144569e-05
step: 830, loss: 0.021189048886299133
step: 840, loss: 0.030537692829966545
step: 850, loss: 0.09731248021125793
step: 860, loss: 0.0051034498028457165
step: 870, loss: 0.0005730343400500715
step: 880, loss: 0.09438344091176987
step: 890, loss: 0.022540923207998276
step: 900, loss: 0.2071153223514557
step: 910, loss: 0.05851120874285698
step: 920, loss: 0.02161126211285591
step: 930, loss: 0.0013182464754208922
step: 940, loss: 0.021389905363321304
step: 950, loss: 0.01552726048976183
step: 960, loss: 0.07479899376630783
step: 970, loss: 0.013139092363417149
epoch 19: dev_f1=0.9334574220567706, f1=0.9311141932501156, best_f1=0.938134810710988
step: 0, loss: 0.01752592995762825
step: 10, loss: 0.028669225051999092
step: 20, loss: 0.013032524846494198
step: 30, loss: 0.0014944555005058646
step: 40, loss: 0.09221737086772919
step: 50, loss: 0.02558944746851921
step: 60, loss: 0.021698398515582085
step: 70, loss: 0.021512914448976517
step: 80, loss: 0.016043439507484436
step: 90, loss: 0.04236559942364693
step: 100, loss: 5.9394093113951385e-05
step: 110, loss: 0.016674542799592018
step: 120, loss: 0.020434513688087463
step: 130, loss: 0.08614195883274078
step: 140, loss: 0.037476781755685806
step: 150, loss: 0.025332530960440636
step: 160, loss: 0.00042436656076461077
step: 170, loss: 0.002260912209749222
step: 180, loss: 0.01946108415722847
step: 190, loss: 0.012894839979708195
step: 200, loss: 0.05678602308034897
step: 210, loss: 0.024466559290885925
step: 220, loss: 0.00042608054354786873
step: 230, loss: 0.0010613929480314255
step: 240, loss: 0.03296656534075737
step: 250, loss: 0.026377318426966667
step: 260, loss: 0.02718561328947544
step: 270, loss: 0.07856406271457672
step: 280, loss: 0.05420579016208649
step: 290, loss: 0.06283634155988693
step: 300, loss: 0.08195332437753677
step: 310, loss: 0.024077903479337692
step: 320, loss: 0.020197216421365738
step: 330, loss: 0.019566580653190613
step: 340, loss: 8.688402886036783e-05
step: 350, loss: 0.024676000699400902
step: 360, loss: 0.030968010425567627
step: 370, loss: 0.001127411494962871
step: 380, loss: 0.021072017028927803
step: 390, loss: 0.037560563534498215
step: 400, loss: 0.001474090968258679
step: 410, loss: 0.040632519870996475
step: 420, loss: 4.54386645287741e-05
step: 430, loss: 0.023047292605042458
step: 440, loss: 0.03826308250427246
step: 450, loss: 0.05691387876868248
step: 460, loss: 0.06023392453789711
step: 470, loss: 0.024031082168221474
step: 480, loss: 0.022756164893507957
step: 490, loss: 0.043342769145965576
step: 500, loss: 0.04952986538410187
step: 510, loss: 0.03203854709863663
step: 520, loss: 0.06020218878984451
step: 530, loss: 7.850280962884426e-05
step: 540, loss: 0.020681150257587433
step: 550, loss: 0.03019406646490097
step: 560, loss: 0.01705559343099594
step: 570, loss: 0.023262683302164078
step: 580, loss: 0.025530073791742325
step: 590, loss: 0.03149626404047012
step: 600, loss: 0.021160783246159554
step: 610, loss: 0.022339114919304848
step: 620, loss: 0.008920610882341862
step: 630, loss: 0.06513115018606186
step: 640, loss: 0.029284033924341202
step: 650, loss: 0.005238127429038286
step: 660, loss: 0.039788149297237396
step: 670, loss: 0.0005331042921170592
step: 680, loss: 0.024649476632475853
step: 690, loss: 0.11482164263725281
step: 700, loss: 0.0349276177585125
step: 710, loss: 0.00014943396672606468
step: 720, loss: 0.019607119262218475
step: 730, loss: 0.03839488700032234
step: 740, loss: 0.0013449451653286815
step: 750, loss: 0.06736317276954651
step: 760, loss: 0.08136668056249619
step: 770, loss: 0.020400535315275192
step: 780, loss: 0.09160127490758896
step: 790, loss: 0.009020416997373104
step: 800, loss: 0.0003180642961524427
step: 810, loss: 0.037948884069919586
step: 820, loss: 0.11602935194969177
step: 830, loss: 0.00021659588674083352
step: 840, loss: 0.01953563094139099
step: 850, loss: 0.01651112176477909
step: 860, loss: 0.022549578920006752
step: 870, loss: 8.626095950603485e-05
step: 880, loss: 0.042503371834754944
step: 890, loss: 0.040012065321207047
step: 900, loss: 0.021289171651005745
step: 910, loss: 0.01075697224587202
step: 920, loss: 0.07024998217821121
step: 930, loss: 0.04309064894914627
step: 940, loss: 0.00022303927107714117
step: 950, loss: 0.012663210742175579
step: 960, loss: 0.02292410284280777
step: 970, loss: 0.034673064947128296
epoch 20: dev_f1=0.9315838800374883, f1=0.9292364990689013, best_f1=0.938134810710988
