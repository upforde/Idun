cuda
Device: cuda
step: 0, loss: 0.8494225740432739
step: 10, loss: 0.12427812814712524
step: 20, loss: 0.5014808177947998
step: 30, loss: 0.8310536742210388
step: 40, loss: 0.2338232398033142
step: 50, loss: 0.1334104835987091
step: 60, loss: 0.2922624945640564
step: 70, loss: 0.4331822395324707
step: 80, loss: 0.45299458503723145
step: 90, loss: 0.21578311920166016
step: 100, loss: 0.1780015230178833
step: 110, loss: 0.24949263036251068
step: 120, loss: 0.26564541459083557
step: 130, loss: 0.20726323127746582
step: 140, loss: 0.16837440431118011
step: 150, loss: 0.09835827350616455
step: 160, loss: 0.0655733123421669
step: 170, loss: 0.07977818697690964
step: 180, loss: 0.12825804948806763
step: 190, loss: 0.2309429794549942
step: 200, loss: 0.062415990978479385
step: 210, loss: 0.13574527204036713
step: 220, loss: 0.1252758502960205
step: 230, loss: 0.2435930371284485
step: 240, loss: 0.21126118302345276
step: 250, loss: 0.09666254371404648
step: 260, loss: 0.08994381874799728
step: 270, loss: 0.09182308614253998
step: 280, loss: 0.13333134353160858
step: 290, loss: 0.11202451586723328
step: 300, loss: 0.16284672915935516
step: 310, loss: 0.1777823120355606
step: 320, loss: 0.050007086247205734
step: 330, loss: 0.09228271245956421
step: 340, loss: 0.09041640162467957
step: 350, loss: 0.08243110775947571
step: 360, loss: 0.2059939205646515
step: 370, loss: 0.32586732506752014
step: 380, loss: 0.12313041090965271
step: 390, loss: 0.17731629312038422
step: 400, loss: 0.11567613482475281
step: 410, loss: 0.0524548776447773
step: 420, loss: 0.10303761065006256
step: 430, loss: 0.11758014559745789
step: 440, loss: 0.0397740975022316
step: 450, loss: 0.100141741335392
step: 460, loss: 0.20842117071151733
step: 470, loss: 0.12841583788394928
step: 480, loss: 0.3005968928337097
step: 490, loss: 0.09491400420665741
step: 500, loss: 0.026998989284038544
step: 510, loss: 0.061544399708509445
step: 520, loss: 0.09737754613161087
step: 530, loss: 0.026105158030986786
step: 540, loss: 0.09293954074382782
step: 550, loss: 0.07163548469543457
step: 560, loss: 0.0949375256896019
step: 570, loss: 0.14542128145694733
step: 580, loss: 0.18473201990127563
step: 590, loss: 0.05539560690522194
step: 600, loss: 0.0071574184112250805
step: 610, loss: 0.01888909749686718
step: 620, loss: 0.085141122341156
step: 630, loss: 0.18912212550640106
step: 640, loss: 0.05782421678304672
step: 650, loss: 0.026094794273376465
step: 660, loss: 0.10204663127660751
step: 670, loss: 0.0835849866271019
step: 680, loss: 0.03778236731886864
step: 690, loss: 0.08491846919059753
step: 700, loss: 0.0885765329003334
step: 710, loss: 0.06671633571386337
step: 720, loss: 0.06822249293327332
step: 730, loss: 0.07817007601261139
step: 740, loss: 0.07622890174388885
step: 750, loss: 0.14369288086891174
step: 760, loss: 0.12104400992393494
step: 770, loss: 0.055733244866132736
step: 780, loss: 0.13315443694591522
step: 790, loss: 0.07420516014099121
step: 800, loss: 0.06988504528999329
step: 810, loss: 0.19788646697998047
step: 820, loss: 0.17301799356937408
step: 830, loss: 0.05230187252163887
step: 840, loss: 0.17285001277923584
step: 850, loss: 0.1583680957555771
step: 860, loss: 0.1556585729122162
step: 870, loss: 0.019733719527721405
step: 880, loss: 0.016533270478248596
step: 890, loss: 0.1327730268239975
step: 900, loss: 0.11992395669221878
step: 910, loss: 0.10268241167068481
step: 920, loss: 0.14726205170154572
step: 930, loss: 0.09840657562017441
step: 940, loss: 0.2441280037164688
step: 950, loss: 0.09622862935066223
step: 960, loss: 0.0881824716925621
step: 970, loss: 0.10826284438371658
epoch 1: dev_f1=0.9113345521023766, f1=0.9144409234947941, best_f1=0.9144409234947941
step: 0, loss: 0.07053236663341522
step: 10, loss: 0.16381771862506866
step: 20, loss: 0.10893619060516357
step: 30, loss: 0.07163337618112564
step: 40, loss: 0.09551463276147842
step: 50, loss: 0.24086889624595642
step: 60, loss: 0.12271922081708908
step: 70, loss: 0.14958256483078003
step: 80, loss: 0.18899549543857574
step: 90, loss: 0.11164897680282593
step: 100, loss: 0.05340348184108734
step: 110, loss: 0.06996061652898788
step: 120, loss: 0.019116289913654327
step: 130, loss: 0.19440890848636627
step: 140, loss: 0.15591317415237427
step: 150, loss: 0.10780925303697586
step: 160, loss: 0.09803345054388046
step: 170, loss: 0.05561099573969841
step: 180, loss: 0.011275991797447205
step: 190, loss: 0.07232625782489777
step: 200, loss: 0.021496573463082314
step: 210, loss: 0.18057584762573242
step: 220, loss: 0.1649484634399414
step: 230, loss: 0.055494535714387894
step: 240, loss: 0.2313627004623413
step: 250, loss: 0.08300475031137466
step: 260, loss: 0.057166118174791336
step: 270, loss: 0.18914039433002472
step: 280, loss: 0.11708812415599823
step: 290, loss: 0.0780763328075409
step: 300, loss: 0.19775155186653137
step: 310, loss: 0.1788405030965805
step: 320, loss: 0.13629911839962006
step: 330, loss: 0.047574132680892944
step: 340, loss: 0.17489446699619293
step: 350, loss: 0.07730814069509506
step: 360, loss: 0.13716399669647217
step: 370, loss: 0.019149910658597946
step: 380, loss: 0.07198968529701233
step: 390, loss: 0.03804965317249298
step: 400, loss: 0.04387111961841583
step: 410, loss: 0.1982332020998001
step: 420, loss: 0.13643930852413177
step: 430, loss: 0.1319965124130249
step: 440, loss: 0.08495435118675232
step: 450, loss: 0.05187467485666275
step: 460, loss: 0.16020801663398743
step: 470, loss: 0.14164529740810394
step: 480, loss: 0.13808086514472961
step: 490, loss: 0.07760648429393768
step: 500, loss: 0.14490485191345215
step: 510, loss: 0.07785414159297943
step: 520, loss: 0.07825013250112534
step: 530, loss: 0.2079092562198639
step: 540, loss: 0.027509424835443497
step: 550, loss: 0.14371900260448456
step: 560, loss: 0.11650174856185913
step: 570, loss: 0.07761956751346588
step: 580, loss: 0.09579967707395554
step: 590, loss: 0.10479727387428284
step: 600, loss: 0.09543594717979431
step: 610, loss: 0.09602990001440048
step: 620, loss: 0.19364187121391296
step: 630, loss: 0.049050189554691315
step: 640, loss: 0.10587828606367111
step: 650, loss: 0.1003485918045044
step: 660, loss: 0.07941335439682007
step: 670, loss: 0.10580991953611374
step: 680, loss: 0.15259793400764465
step: 690, loss: 0.08046995848417282
step: 700, loss: 0.04396903142333031
step: 710, loss: 0.13519461452960968
step: 720, loss: 0.15921612083911896
step: 730, loss: 0.1606817990541458
step: 740, loss: 0.07351406663656235
step: 750, loss: 0.05584295839071274
step: 760, loss: 0.12004169076681137
step: 770, loss: 0.09472674876451492
step: 780, loss: 0.08562226593494415
step: 790, loss: 0.04465434327721596
step: 800, loss: 0.23563677072525024
step: 810, loss: 0.08424092829227448
step: 820, loss: 0.12073471397161484
step: 830, loss: 0.028899921104311943
step: 840, loss: 0.05414817854762077
step: 850, loss: 0.08174068480730057
step: 860, loss: 0.14798030257225037
step: 870, loss: 0.036207765340805054
step: 880, loss: 0.11830703914165497
step: 890, loss: 0.08441789448261261
step: 900, loss: 0.18422535061836243
step: 910, loss: 0.1452600359916687
step: 920, loss: 0.036938317120075226
step: 930, loss: 0.13933391869068146
step: 940, loss: 0.18888968229293823
step: 950, loss: 0.10486079752445221
step: 960, loss: 0.1186896413564682
step: 970, loss: 0.053039394319057465
epoch 2: dev_f1=0.9341429238673518, f1=0.9318497913769124, best_f1=0.9318497913769124
step: 0, loss: 0.11963868141174316
step: 10, loss: 0.07097326964139938
step: 20, loss: 0.06908318400382996
step: 30, loss: 0.10625040531158447
step: 40, loss: 0.10403281450271606
step: 50, loss: 0.07450821995735168
step: 60, loss: 0.014282569289207458
step: 70, loss: 0.2387777715921402
step: 80, loss: 0.12424320727586746
step: 90, loss: 0.12272166460752487
step: 100, loss: 0.13211560249328613
step: 110, loss: 0.12683655321598053
step: 120, loss: 0.19488264620304108
step: 130, loss: 0.11369948089122772
step: 140, loss: 0.15125395357608795
step: 150, loss: 0.19192874431610107
step: 160, loss: 0.1029173880815506
step: 170, loss: 0.09318336844444275
step: 180, loss: 0.10906229168176651
step: 190, loss: 0.14982475340366364
step: 200, loss: 0.15464554727077484
step: 210, loss: 0.08106862753629684
step: 220, loss: 0.1599235087633133
step: 230, loss: 0.02981744147837162
step: 240, loss: 0.06314832717180252
step: 250, loss: 0.11659637838602066
step: 260, loss: 0.06050555035471916
step: 270, loss: 0.01041212398558855
step: 280, loss: 0.09984636306762695
step: 290, loss: 0.04161287844181061
step: 300, loss: 0.082720547914505
step: 310, loss: 0.09049012511968613
step: 320, loss: 0.16519245505332947
step: 330, loss: 0.039644014090299606
step: 340, loss: 0.02578553557395935
step: 350, loss: 0.07637600600719452
step: 360, loss: 0.07555253058671951
step: 370, loss: 0.09150682389736176
step: 380, loss: 0.21237175166606903
step: 390, loss: 0.036162253469228745
step: 400, loss: 0.14621037244796753
step: 410, loss: 0.0777999609708786
step: 420, loss: 0.07482176274061203
step: 430, loss: 0.14790816605091095
step: 440, loss: 0.0951729416847229
step: 450, loss: 0.09077520668506622
step: 460, loss: 0.07761764526367188
step: 470, loss: 0.05473918467760086
step: 480, loss: 0.01866469532251358
step: 490, loss: 0.07670512795448303
step: 500, loss: 0.09100636839866638
step: 510, loss: 0.14614877104759216
step: 520, loss: 0.044599857181310654
step: 530, loss: 0.1824713945388794
step: 540, loss: 0.12441530078649521
step: 550, loss: 0.08156019449234009
step: 560, loss: 0.12052050977945328
step: 570, loss: 0.0969233289361
step: 580, loss: 0.11248018592596054
step: 590, loss: 0.03977806866168976
step: 600, loss: 0.07045804709196091
step: 610, loss: 0.0470716655254364
step: 620, loss: 0.15721550583839417
step: 630, loss: 0.0750914216041565
step: 640, loss: 0.025349406525492668
step: 650, loss: 0.07965277880430222
step: 660, loss: 0.03576531633734703
step: 670, loss: 0.013945065438747406
step: 680, loss: 0.07799477875232697
step: 690, loss: 0.023295868188142776
step: 700, loss: 0.0806693434715271
step: 710, loss: 0.05347093194723129
step: 720, loss: 0.0015382415149360895
step: 730, loss: 0.07385092228651047
step: 740, loss: 0.12652327120304108
step: 750, loss: 0.1577501893043518
step: 760, loss: 0.09023122489452362
step: 770, loss: 0.06224571168422699
step: 780, loss: 0.06283366680145264
step: 790, loss: 0.17358627915382385
step: 800, loss: 0.09468073397874832
step: 810, loss: 0.2901308238506317
step: 820, loss: 0.0010805819183588028
step: 830, loss: 0.11005112528800964
step: 840, loss: 0.12369579821825027
step: 850, loss: 0.14278006553649902
step: 860, loss: 0.059728700667619705
step: 870, loss: 0.01180682796984911
step: 880, loss: 0.15551158785820007
step: 890, loss: 0.07053796947002411
step: 900, loss: 0.06941571086645126
step: 910, loss: 0.09118711948394775
step: 920, loss: 0.2358623743057251
step: 930, loss: 0.010748258791863918
step: 940, loss: 0.10161370784044266
step: 950, loss: 0.08792339265346527
step: 960, loss: 0.11659432202577591
step: 970, loss: 0.052145302295684814
epoch 3: dev_f1=0.9311294765840221, f1=0.9349112426035502, best_f1=0.9318497913769124
step: 0, loss: 0.11666422337293625
step: 10, loss: 0.1312718242406845
step: 20, loss: 0.02870032750070095
step: 30, loss: 0.1122228354215622
step: 40, loss: 0.05173087120056152
step: 50, loss: 0.16061976552009583
step: 60, loss: 0.0560566745698452
step: 70, loss: 0.07880596071481705
step: 80, loss: 0.024657338857650757
step: 90, loss: 0.022478893399238586
step: 100, loss: 0.004706755746155977
step: 110, loss: 0.0036248432006686926
step: 120, loss: 0.038780130445957184
step: 130, loss: 0.166697695851326
step: 140, loss: 0.0199679397046566
step: 150, loss: 0.09599116444587708
step: 160, loss: 0.1481207311153412
step: 170, loss: 0.14574573934078217
step: 180, loss: 0.0073151118122041225
step: 190, loss: 0.02321377396583557
step: 200, loss: 0.08239640295505524
step: 210, loss: 0.04607407748699188
step: 220, loss: 0.0982927456498146
step: 230, loss: 0.018567565828561783
step: 240, loss: 0.01666927896440029
step: 250, loss: 0.07466986030340195
step: 260, loss: 0.11173956096172333
step: 270, loss: 0.0068790363147854805
step: 280, loss: 0.023960329592227936
step: 290, loss: 0.12021231651306152
step: 300, loss: 0.15470317006111145
step: 310, loss: 0.08420224487781525
step: 320, loss: 0.13107158243656158
step: 330, loss: 0.040037404745817184
step: 340, loss: 0.0279449000954628
step: 350, loss: 0.1251482367515564
step: 360, loss: 0.14872708916664124
step: 370, loss: 0.1103961169719696
step: 380, loss: 0.12774911522865295
step: 390, loss: 0.11034978181123734
step: 400, loss: 0.07844231277704239
step: 410, loss: 0.02421538718044758
step: 420, loss: 0.13217300176620483
step: 430, loss: 0.038080472499132156
step: 440, loss: 0.07016249746084213
step: 450, loss: 0.019233210012316704
step: 460, loss: 0.0790737122297287
step: 470, loss: 0.10678786784410477
step: 480, loss: 0.1745244711637497
step: 490, loss: 0.13095220923423767
step: 500, loss: 0.08048859238624573
step: 510, loss: 0.05604182556271553
step: 520, loss: 0.11977560818195343
step: 530, loss: 0.10292206704616547
step: 540, loss: 0.011691037565469742
step: 550, loss: 0.08301893621683121
step: 560, loss: 0.04641358554363251
step: 570, loss: 0.1927260160446167
step: 580, loss: 0.11664412915706635
step: 590, loss: 0.09393028169870377
step: 600, loss: 0.13721232116222382
step: 610, loss: 0.13470841944217682
step: 620, loss: 0.06310787051916122
step: 630, loss: 0.10663718730211258
step: 640, loss: 0.13808000087738037
step: 650, loss: 0.09264618903398514
step: 660, loss: 0.11501429975032806
step: 670, loss: 0.14789342880249023
step: 680, loss: 0.07169290632009506
step: 690, loss: 0.011264346539974213
step: 700, loss: 0.19918319582939148
step: 710, loss: 0.04685714468359947
step: 720, loss: 0.04740229994058609
step: 730, loss: 0.02239685133099556
step: 740, loss: 0.043715737760066986
step: 750, loss: 0.13706620037555695
step: 760, loss: 0.013201066292822361
step: 770, loss: 0.030646076425909996
step: 780, loss: 0.11589809507131577
step: 790, loss: 0.12982258200645447
step: 800, loss: 0.07436732947826385
step: 810, loss: 0.29451072216033936
step: 820, loss: 0.15579725801944733
step: 830, loss: 0.09499482065439224
step: 840, loss: 0.050712667405605316
step: 850, loss: 0.014190800487995148
step: 860, loss: 0.045028477907180786
step: 870, loss: 0.10992302745580673
step: 880, loss: 0.158768430352211
step: 890, loss: 0.038112491369247437
step: 900, loss: 0.13481782376766205
step: 910, loss: 0.15500672161579132
step: 920, loss: 0.11410403996706009
step: 930, loss: 0.039060141891241074
step: 940, loss: 0.02143573760986328
step: 950, loss: 0.0836869478225708
step: 960, loss: 0.058808695524930954
step: 970, loss: 0.07263722270727158
epoch 4: dev_f1=0.9365079365079366, f1=0.9325894932589495, best_f1=0.9325894932589495
step: 0, loss: 0.08521392941474915
step: 10, loss: 0.05335744470357895
step: 20, loss: 0.14345939457416534
step: 30, loss: 0.01273409090936184
step: 40, loss: 0.061100561171770096
step: 50, loss: 0.032570257782936096
step: 60, loss: 0.06192132830619812
step: 70, loss: 0.06625024974346161
step: 80, loss: 0.2148856371641159
step: 90, loss: 0.07108328491449356
step: 100, loss: 0.012391611933708191
step: 110, loss: 0.02756686508655548
step: 120, loss: 0.07164446264505386
step: 130, loss: 0.11034172028303146
step: 140, loss: 0.005274408496916294
step: 150, loss: 0.02649066410958767
step: 160, loss: 0.04330690950155258
step: 170, loss: 0.03542736545205116
step: 180, loss: 0.13787084817886353
step: 190, loss: 0.08730882406234741
step: 200, loss: 0.020668335258960724
step: 210, loss: 0.02797616645693779
step: 220, loss: 0.1258721947669983
step: 230, loss: 0.16603709757328033
step: 240, loss: 0.038308851420879364
step: 250, loss: 0.03328259661793709
step: 260, loss: 0.033593133091926575
step: 270, loss: 0.30795079469680786
step: 280, loss: 0.12631557881832123
step: 290, loss: 0.09086740761995316
step: 300, loss: 0.08563103526830673
step: 310, loss: 0.08228929340839386
step: 320, loss: 0.12227045744657516
step: 330, loss: 0.10650906711816788
step: 340, loss: 0.04768083244562149
step: 350, loss: 0.029980313032865524
step: 360, loss: 0.10787911713123322
step: 370, loss: 0.07283078134059906
step: 380, loss: 0.09738007187843323
step: 390, loss: 0.10441549867391586
step: 400, loss: 0.0397300198674202
step: 410, loss: 0.16017630696296692
step: 420, loss: 0.05915326997637749
step: 430, loss: 3.699856824823655e-05
step: 440, loss: 0.12046807259321213
step: 450, loss: 0.09657637029886246
step: 460, loss: 0.06114461272954941
step: 470, loss: 0.03787308186292648
step: 480, loss: 0.0907280370593071
step: 490, loss: 0.12438085675239563
step: 500, loss: 0.04216175153851509
step: 510, loss: 0.06836707144975662
step: 520, loss: 0.009124305099248886
step: 530, loss: 0.01591647043824196
step: 540, loss: 0.08406075090169907
step: 550, loss: 0.125734344124794
step: 560, loss: 0.04151182621717453
step: 570, loss: 0.028798367828130722
step: 580, loss: 0.010166110470890999
step: 590, loss: 0.031265415251255035
step: 600, loss: 0.08832326531410217
step: 610, loss: 0.10579946637153625
step: 620, loss: 0.014354417100548744
step: 630, loss: 0.07128828763961792
step: 640, loss: 0.0591399110853672
step: 650, loss: 0.04018786549568176
step: 660, loss: 0.025737272575497627
step: 670, loss: 0.09211280196905136
step: 680, loss: 0.034423522651195526
step: 690, loss: 0.014647504314780235
step: 700, loss: 0.1004142314195633
step: 710, loss: 0.030675871297717094
step: 720, loss: 0.04492240399122238
step: 730, loss: 0.060191936790943146
step: 740, loss: 0.14621596038341522
step: 750, loss: 0.03983981907367706
step: 760, loss: 0.07952559739351273
step: 770, loss: 0.046686116605997086
step: 780, loss: 0.13438598811626434
step: 790, loss: 0.03377702832221985
step: 800, loss: 0.16839389503002167
step: 810, loss: 0.045038044452667236
step: 820, loss: 0.10460501164197922
step: 830, loss: 0.06398478895425797
step: 840, loss: 0.01746259070932865
step: 850, loss: 0.07026422768831253
step: 860, loss: 0.09740285575389862
step: 870, loss: 0.04721371829509735
step: 880, loss: 0.041725851595401764
step: 890, loss: 0.09059461951255798
step: 900, loss: 0.07035771012306213
step: 910, loss: 0.08323638141155243
step: 920, loss: 0.02017204277217388
step: 930, loss: 0.01507166214287281
step: 940, loss: 0.16307106614112854
step: 950, loss: 0.0949859768152237
step: 960, loss: 0.12376987934112549
step: 970, loss: 0.019323300570249557
epoch 5: dev_f1=0.9360146252285192, f1=0.9312072892938498, best_f1=0.9325894932589495
step: 0, loss: 0.07256850600242615
step: 10, loss: 0.08805010467767715
step: 20, loss: 0.1695578694343567
step: 30, loss: 0.0360151007771492
step: 40, loss: 0.07630178332328796
step: 50, loss: 0.054043639451265335
step: 60, loss: 0.05184135213494301
step: 70, loss: 0.08600451797246933
step: 80, loss: 0.2034606784582138
step: 90, loss: 0.10004733502864838
step: 100, loss: 0.01839710772037506
step: 110, loss: 0.03490898385643959
step: 120, loss: 0.0063660768792033195
step: 130, loss: 0.013013011775910854
step: 140, loss: 0.06858805567026138
step: 150, loss: 0.018518004566431046
step: 160, loss: 0.09947474300861359
step: 170, loss: 0.07974555343389511
step: 180, loss: 0.008208501152694225
step: 190, loss: 0.015907537192106247
step: 200, loss: 0.027501240372657776
step: 210, loss: 0.008175832219421864
step: 220, loss: 0.1189366951584816
step: 230, loss: 0.09798040241003036
step: 240, loss: 0.046708595007658005
step: 250, loss: 0.09152725338935852
step: 260, loss: 0.09774839133024216
step: 270, loss: 0.07176727056503296
step: 280, loss: 0.16667495667934418
step: 290, loss: 0.025691624730825424
step: 300, loss: 0.05941980704665184
step: 310, loss: 0.07280345261096954
step: 320, loss: 0.05633348971605301
step: 330, loss: 0.1951591670513153
step: 340, loss: 0.03200892359018326
step: 350, loss: 0.05457467958331108
step: 360, loss: 0.029362522065639496
step: 370, loss: 0.16610375046730042
step: 380, loss: 0.04277099296450615
step: 390, loss: 0.08407285064458847
step: 400, loss: 0.03303343802690506
step: 410, loss: 0.04494212940335274
step: 420, loss: 0.010584679432213306
step: 430, loss: 0.06944426149129868
step: 440, loss: 0.21416744589805603
step: 450, loss: 0.03534318134188652
step: 460, loss: 0.03240548446774483
step: 470, loss: 0.07404886186122894
step: 480, loss: 0.0794682502746582
step: 490, loss: 0.15349994599819183
step: 500, loss: 0.14571107923984528
step: 510, loss: 0.04347771406173706
step: 520, loss: 0.0953485444188118
step: 530, loss: 0.0470973365008831
step: 540, loss: 0.06538332998752594
step: 550, loss: 0.02675589546561241
step: 560, loss: 0.09241457283496857
step: 570, loss: 0.015518507920205593
step: 580, loss: 0.036586325615644455
step: 590, loss: 0.03263194113969803
step: 600, loss: 0.04695059731602669
step: 610, loss: 0.06294553726911545
step: 620, loss: 0.023922402411699295
step: 630, loss: 0.07828286290168762
step: 640, loss: 0.04729246720671654
step: 650, loss: 0.10103645920753479
step: 660, loss: 0.06852264702320099
step: 670, loss: 0.09070169180631638
step: 680, loss: 0.01586984097957611
step: 690, loss: 0.10306327044963837
step: 700, loss: 0.05342758446931839
step: 710, loss: 0.07426130026578903
step: 720, loss: 6.764200225006789e-05
step: 730, loss: 0.06268823146820068
step: 740, loss: 0.07229307293891907
step: 750, loss: 0.10282761603593826
step: 760, loss: 0.1093001514673233
step: 770, loss: 0.06966415792703629
step: 780, loss: 0.04171775281429291
step: 790, loss: 0.027994507923722267
step: 800, loss: 0.07825563102960587
step: 810, loss: 0.03946859389543533
step: 820, loss: 0.0684218555688858
step: 830, loss: 0.3054967522621155
step: 840, loss: 0.057295821607112885
step: 850, loss: 0.025289248675107956
step: 860, loss: 0.15490679442882538
step: 870, loss: 0.015315894037485123
step: 880, loss: 0.05843418464064598
step: 890, loss: 0.01136805023998022
step: 900, loss: 0.051905665546655655
step: 910, loss: 0.006836329586803913
step: 920, loss: 0.012852388434112072
step: 930, loss: 0.008605742827057838
step: 940, loss: 0.1071290373802185
step: 950, loss: 0.20959345996379852
step: 960, loss: 0.14609001576900482
step: 970, loss: 0.062430646270513535
epoch 6: dev_f1=0.9319323892188214, f1=0.9351005484460694, best_f1=0.9325894932589495
step: 0, loss: 0.023269211873412132
step: 10, loss: 0.038889624178409576
step: 20, loss: 0.07280831784009933
step: 30, loss: 0.11447848379611969
step: 40, loss: 0.08024978637695312
step: 50, loss: 0.009729641489684582
step: 60, loss: 0.017602646723389626
step: 70, loss: 0.056191809475421906
step: 80, loss: 0.007869143038988113
step: 90, loss: 0.07317773997783661
step: 100, loss: 0.07708446681499481
step: 110, loss: 0.04865041375160217
step: 120, loss: 0.05755050480365753
step: 130, loss: 0.03012561798095703
step: 140, loss: 0.021672189235687256
step: 150, loss: 0.06750262528657913
step: 160, loss: 0.1908257156610489
step: 170, loss: 0.03821087256073952
step: 180, loss: 0.01809025928378105
step: 190, loss: 0.07590176165103912
step: 200, loss: 0.06317537277936935
step: 210, loss: 0.10595681518316269
step: 220, loss: 0.1442326307296753
step: 230, loss: 0.048464905470609665
step: 240, loss: 0.008628994226455688
step: 250, loss: 0.08032280951738358
step: 260, loss: 0.10252383351325989
step: 270, loss: 0.05786408856511116
step: 280, loss: 0.1828332543373108
step: 290, loss: 0.08234760165214539
step: 300, loss: 0.04543198645114899
step: 310, loss: 0.19361892342567444
step: 320, loss: 0.03839433938264847
step: 330, loss: 0.00975040066987276
step: 340, loss: 0.07830015569925308
step: 350, loss: 0.17677193880081177
step: 360, loss: 0.02254825085401535
step: 370, loss: 0.1486188918352127
step: 380, loss: 0.039578188210725784
step: 390, loss: 0.07024263590574265
step: 400, loss: 0.09393962472677231
step: 410, loss: 0.010739302262663841
step: 420, loss: 0.10271840542554855
step: 430, loss: 0.11158677190542221
step: 440, loss: 0.009732664562761784
step: 450, loss: 0.012197304517030716
step: 460, loss: 0.08019595593214035
step: 470, loss: 0.07540631294250488
step: 480, loss: 0.09153002500534058
step: 490, loss: 0.11426277458667755
step: 500, loss: 0.014846839010715485
step: 510, loss: 0.09757192432880402
step: 520, loss: 0.1558142751455307
step: 530, loss: 0.02621668204665184
step: 540, loss: 0.2988315224647522
step: 550, loss: 0.02666371315717697
step: 560, loss: 0.1341455727815628
step: 570, loss: 0.21062509715557098
step: 580, loss: 0.07581829279661179
step: 590, loss: 0.09273813664913177
step: 600, loss: 0.00012554650311358273
step: 610, loss: 0.18094854056835175
step: 620, loss: 6.24587046331726e-05
step: 630, loss: 0.039714034646749496
step: 640, loss: 0.05989670753479004
step: 650, loss: 0.03422929719090462
step: 660, loss: 0.023645441979169846
step: 670, loss: 0.14784979820251465
step: 680, loss: 0.06193700432777405
step: 690, loss: 0.010785430669784546
step: 700, loss: 0.03636936843395233
step: 710, loss: 0.08541020005941391
step: 720, loss: 0.0008050480973906815
step: 730, loss: 0.04542449861764908
step: 740, loss: 0.010805638507008553
step: 750, loss: 0.06723048537969589
step: 760, loss: 0.05709208548069
step: 770, loss: 0.07532699406147003
step: 780, loss: 0.041573040187358856
step: 790, loss: 0.0852823480963707
step: 800, loss: 0.04902590438723564
step: 810, loss: 0.2298223078250885
step: 820, loss: 0.02907516248524189
step: 830, loss: 0.0716770812869072
step: 840, loss: 0.10132736712694168
step: 850, loss: 0.019094256684184074
step: 860, loss: 0.028469156473875046
step: 870, loss: 0.0985473021864891
step: 880, loss: 0.006772778462618589
step: 890, loss: 0.06810075789690018
step: 900, loss: 0.024818208068609238
step: 910, loss: 0.0746554285287857
step: 920, loss: 0.025400493294000626
step: 930, loss: 0.11630518734455109
step: 940, loss: 0.1933838129043579
step: 950, loss: 0.11395357549190521
step: 960, loss: 0.13387255370616913
step: 970, loss: 0.03705337271094322
epoch 7: dev_f1=0.9314697926059512, f1=0.9261083743842365, best_f1=0.9325894932589495
step: 0, loss: 0.07586032897233963
step: 10, loss: 0.11858674883842468
step: 20, loss: 0.027434365823864937
step: 30, loss: 0.12415643036365509
step: 40, loss: 0.17650239169597626
step: 50, loss: 0.07087388634681702
step: 60, loss: 0.04845805838704109
step: 70, loss: 0.01057023461908102
step: 80, loss: 0.1188146248459816
step: 90, loss: 0.013895583339035511
step: 100, loss: 0.020218465477228165
step: 110, loss: 0.004549885634332895
step: 120, loss: 0.025453729555010796
step: 130, loss: 0.030426837503910065
step: 140, loss: 0.05054061487317085
step: 150, loss: 0.006876234896481037
step: 160, loss: 0.09420214593410492
step: 170, loss: 0.08499717712402344
step: 180, loss: 0.21749362349510193
step: 190, loss: 0.07010278850793839
step: 200, loss: 0.020914461463689804
step: 210, loss: 0.08379638940095901
step: 220, loss: 0.03106105886399746
step: 230, loss: 0.005309229716658592
step: 240, loss: 0.06786162406206131
step: 250, loss: 0.029460102319717407
step: 260, loss: 0.042865823954343796
step: 270, loss: 6.379217666108161e-05
step: 280, loss: 0.027471503242850304
step: 290, loss: 0.09073102474212646
step: 300, loss: 0.023467278108000755
step: 310, loss: 0.021858729422092438
step: 320, loss: 0.008260047994554043
step: 330, loss: 0.008698660880327225
step: 340, loss: 0.13509459793567657
step: 350, loss: 0.1533689796924591
step: 360, loss: 0.09245676547288895
step: 370, loss: 0.32060545682907104
step: 380, loss: 0.09413576126098633
step: 390, loss: 0.06352443993091583
step: 400, loss: 0.13774830102920532
step: 410, loss: 0.07989638298749924
step: 420, loss: 0.06920686364173889
step: 430, loss: 0.01247404795140028
step: 440, loss: 0.062182605266571045
step: 450, loss: 0.019473768770694733
step: 460, loss: 0.017952030524611473
step: 470, loss: 0.0830531120300293
step: 480, loss: 0.02526358887553215
step: 490, loss: 0.028575371950864792
step: 500, loss: 0.2481658011674881
step: 510, loss: 0.06719839572906494
step: 520, loss: 0.03404438868165016
step: 530, loss: 0.1301785707473755
step: 540, loss: 0.01713826321065426
step: 550, loss: 0.04451311007142067
step: 560, loss: 0.16792601346969604
step: 570, loss: 0.024298282340168953
step: 580, loss: 0.012715328484773636
step: 590, loss: 0.018082305788993835
step: 600, loss: 0.1367221623659134
step: 610, loss: 0.03272639214992523
step: 620, loss: 0.05926039069890976
step: 630, loss: 0.10373716801404953
step: 640, loss: 0.07045702636241913
step: 650, loss: 0.09871875494718552
step: 660, loss: 0.19353866577148438
step: 670, loss: 0.0866023376584053
step: 680, loss: 0.03020963817834854
step: 690, loss: 0.03869519382715225
step: 700, loss: 0.08997595310211182
step: 710, loss: 0.09276769310235977
step: 720, loss: 0.016157180070877075
step: 730, loss: 0.12977080047130585
step: 740, loss: 0.04282933846116066
step: 750, loss: 0.006402154453098774
step: 760, loss: 0.026019137352705002
step: 770, loss: 0.05898863449692726
step: 780, loss: 0.0943683460354805
step: 790, loss: 0.004272643942385912
step: 800, loss: 0.0346728153526783
step: 810, loss: 0.07296504825353622
step: 820, loss: 0.08691375702619553
step: 830, loss: 0.09472337365150452
step: 840, loss: 0.009621106088161469
step: 850, loss: 0.06773221492767334
step: 860, loss: 0.09557988494634628
step: 870, loss: 0.07712869346141815
step: 880, loss: 0.011461920104920864
step: 890, loss: 0.008749011904001236
step: 900, loss: 0.1589755117893219
step: 910, loss: 0.017202477902173996
step: 920, loss: 0.06481074541807175
step: 930, loss: 0.02837347611784935
step: 940, loss: 0.009406914934515953
step: 950, loss: 0.07972332090139389
step: 960, loss: 0.07073599100112915
step: 970, loss: 0.1192774623632431
epoch 8: dev_f1=0.9285714285714286, f1=0.9258384506376948, best_f1=0.9325894932589495
step: 0, loss: 0.07575812190771103
step: 10, loss: 0.08528163284063339
step: 20, loss: 0.04206882417201996
step: 30, loss: 0.06965872645378113
step: 40, loss: 0.0972026139497757
step: 50, loss: 0.047156739979982376
step: 60, loss: 0.06915458291769028
step: 70, loss: 0.05705637112259865
step: 80, loss: 0.0007443620706908405
step: 90, loss: 0.06617092341184616
step: 100, loss: 0.026819629594683647
step: 110, loss: 0.12717711925506592
step: 120, loss: 0.01750797964632511
step: 130, loss: 0.05856974422931671
step: 140, loss: 0.008480578660964966
step: 150, loss: 0.13015088438987732
step: 160, loss: 0.011633606627583504
step: 170, loss: 0.11902428418397903
step: 180, loss: 0.07377491146326065
step: 190, loss: 0.00857176911085844
step: 200, loss: 0.005414414685219526
step: 210, loss: 0.10297943651676178
step: 220, loss: 0.12120866775512695
step: 230, loss: 0.10639497637748718
step: 240, loss: 0.006660814397037029
step: 250, loss: 0.034139856696128845
step: 260, loss: 0.09956561774015427
step: 270, loss: 0.04524100944399834
step: 280, loss: 0.12063270062208176
step: 290, loss: 0.055047087371349335
step: 300, loss: 0.09298615902662277
step: 310, loss: 0.04825405031442642
step: 320, loss: 0.0180780328810215
step: 330, loss: 0.053824592381715775
step: 340, loss: 0.045104119926691055
step: 350, loss: 0.009573846124112606
step: 360, loss: 0.08055981993675232
step: 370, loss: 0.05083353444933891
step: 380, loss: 0.04736874997615814
step: 390, loss: 0.08464304357767105
step: 400, loss: 0.14867138862609863
step: 410, loss: 0.022598324343562126
step: 420, loss: 0.07706528156995773
step: 430, loss: 0.022126369178295135
step: 440, loss: 0.006728691980242729
step: 450, loss: 0.08746086061000824
step: 460, loss: 0.21917618811130524
step: 470, loss: 0.027432052418589592
step: 480, loss: 0.20491714775562286
step: 490, loss: 0.02920558676123619
step: 500, loss: 0.05993308871984482
step: 510, loss: 0.008591854944825172
step: 520, loss: 0.04408220946788788
step: 530, loss: 0.09940202534198761
step: 540, loss: 0.18535147607326508
step: 550, loss: 0.14985226094722748
step: 560, loss: 0.15701065957546234
step: 570, loss: 0.017174823209643364
step: 580, loss: 0.02107972279191017
step: 590, loss: 0.09727416187524796
step: 600, loss: 0.06447462737560272
step: 610, loss: 0.0821351632475853
step: 620, loss: 0.03863822668790817
step: 630, loss: 0.018573764711618423
step: 640, loss: 0.022418305277824402
step: 650, loss: 0.006086535286158323
step: 660, loss: 0.004059334751218557
step: 670, loss: 0.019535139203071594
step: 680, loss: 0.035216622054576874
step: 690, loss: 0.04184581711888313
step: 700, loss: 0.27801212668418884
step: 710, loss: 0.15932868421077728
step: 720, loss: 0.015492230653762817
step: 730, loss: 0.07449524849653244
step: 740, loss: 0.08284300565719604
step: 750, loss: 0.08146917819976807
step: 760, loss: 0.07949794828891754
step: 770, loss: 0.08075620234012604
step: 780, loss: 0.1705094426870346
step: 790, loss: 0.06120919808745384
step: 800, loss: 0.07528478652238846
step: 810, loss: 0.0617934986948967
step: 820, loss: 0.014297235757112503
step: 830, loss: 0.06505803018808365
step: 840, loss: 0.04103973135352135
step: 850, loss: 0.001210907706990838
step: 860, loss: 0.009374480694532394
step: 870, loss: 0.013385972939431667
step: 880, loss: 0.027436625212430954
step: 890, loss: 0.007862825877964497
step: 900, loss: 0.03201144561171532
step: 910, loss: 0.13092368841171265
step: 920, loss: 0.12056092172861099
step: 930, loss: 0.00858308281749487
step: 940, loss: 0.0582965724170208
step: 950, loss: 0.05019000545144081
step: 960, loss: 0.05920916795730591
step: 970, loss: 0.14412474632263184
epoch 9: dev_f1=0.9343200740055504, f1=0.9324200913242009, best_f1=0.9325894932589495
step: 0, loss: 0.04380318522453308
step: 10, loss: 0.08091273158788681
step: 20, loss: 0.06811100989580154
step: 30, loss: 0.021290523931384087
step: 40, loss: 0.12452663481235504
step: 50, loss: 0.12514418363571167
step: 60, loss: 0.06329376995563507
step: 70, loss: 0.11710001528263092
step: 80, loss: 0.003239715937525034
step: 90, loss: 0.10807698220014572
step: 100, loss: 0.00820762850344181
step: 110, loss: 0.005209296941757202
step: 120, loss: 0.09554342925548553
step: 130, loss: 0.048702582716941833
step: 140, loss: 0.05583842843770981
step: 150, loss: 0.10028325021266937
step: 160, loss: 0.008821087889373302
step: 170, loss: 0.06896720826625824
step: 180, loss: 0.1958446353673935
step: 190, loss: 0.036769356578588486
step: 200, loss: 0.014556546695530415
step: 210, loss: 0.011278200894594193
step: 220, loss: 0.011051069013774395
step: 230, loss: 0.01756472699344158
step: 240, loss: 0.009989287704229355
step: 250, loss: 0.012607849203050137
step: 260, loss: 0.014940345659852028
step: 270, loss: 0.015070468187332153
step: 280, loss: 0.00030587695073336363
step: 290, loss: 0.20242886245250702
step: 300, loss: 0.01894504576921463
step: 310, loss: 0.12090252339839935
step: 320, loss: 0.017802434042096138
step: 330, loss: 0.10559090971946716
step: 340, loss: 0.03821320831775665
step: 350, loss: 0.2030116617679596
step: 360, loss: 0.0736759826540947
step: 370, loss: 0.08212889730930328
step: 380, loss: 0.023350873962044716
step: 390, loss: 0.16788874566555023
step: 400, loss: 0.11599497497081757
step: 410, loss: 0.019860684871673584
step: 420, loss: 0.017302395775914192
step: 430, loss: 0.016334937885403633
step: 440, loss: 0.06242180988192558
step: 450, loss: 0.06330569833517075
step: 460, loss: 0.026833008974790573
step: 470, loss: 0.00956122949719429
step: 480, loss: 0.03265974670648575
step: 490, loss: 0.06507015973329544
step: 500, loss: 0.025742098689079285
step: 510, loss: 0.09528308361768723
step: 520, loss: 0.08050446212291718
step: 530, loss: 0.05879039317369461
step: 540, loss: 0.0677279531955719
step: 550, loss: 0.06388170272111893
step: 560, loss: 0.033660151064395905
step: 570, loss: 0.09355037659406662
step: 580, loss: 0.011659911833703518
step: 590, loss: 0.060376230627298355
step: 600, loss: 0.06475993245840073
step: 610, loss: 0.00849220622330904
step: 620, loss: 0.01447038073092699
step: 630, loss: 0.028705434873700142
step: 640, loss: 0.007554416079074144
step: 650, loss: 0.06530344486236572
step: 660, loss: 0.005129422061145306
step: 670, loss: 0.1332809180021286
step: 680, loss: 0.07807213813066483
step: 690, loss: 0.009695122018456459
step: 700, loss: 0.15574249625205994
step: 710, loss: 0.029581744223833084
step: 720, loss: 0.0751415491104126
step: 730, loss: 0.04201050102710724
step: 740, loss: 0.01819049008190632
step: 750, loss: 0.0784778743982315
step: 760, loss: 0.08772389590740204
step: 770, loss: 0.04805317893624306
step: 780, loss: 0.007863040082156658
step: 790, loss: 0.07782553881406784
step: 800, loss: 0.07913346588611603
step: 810, loss: 0.1269124150276184
step: 820, loss: 0.04902205616235733
step: 830, loss: 0.07788731902837753
step: 840, loss: 0.028275884687900543
step: 850, loss: 0.007466363720595837
step: 860, loss: 0.08653659373521805
step: 870, loss: 0.00835081934928894
step: 880, loss: 0.011296464130282402
step: 890, loss: 0.012435346841812134
step: 900, loss: 0.06486943364143372
step: 910, loss: 0.07076413184404373
step: 920, loss: 0.03911857679486275
step: 930, loss: 0.08946362882852554
step: 940, loss: 0.013736849650740623
step: 950, loss: 0.106864333152771
step: 960, loss: 0.06481364369392395
step: 970, loss: 0.1212887316942215
epoch 10: dev_f1=0.9297597042513862, f1=0.9289667896678966, best_f1=0.9325894932589495
step: 0, loss: 0.013063143938779831
step: 10, loss: 0.12282465398311615
step: 20, loss: 0.023397449404001236
step: 30, loss: 0.049943748861551285
step: 40, loss: 0.013604084961116314
step: 50, loss: 0.014108013361692429
step: 60, loss: 0.09350752085447311
step: 70, loss: 0.011837831698358059
step: 80, loss: 0.054781924933195114
step: 90, loss: 0.09305047988891602
step: 100, loss: 0.039351481944322586
step: 110, loss: 0.10430056601762772
step: 120, loss: 0.01325138844549656
step: 130, loss: 0.01799982413649559
step: 140, loss: 0.047854065895080566
step: 150, loss: 0.020977936685085297
step: 160, loss: 0.03734983876347542
step: 170, loss: 0.05283501371741295
step: 180, loss: 0.014683078043162823
step: 190, loss: 0.004052123986184597
step: 200, loss: 0.147804394364357
step: 210, loss: 0.060757849365472794
step: 220, loss: 0.03831959515810013
step: 230, loss: 0.06667399406433105
step: 240, loss: 0.06795570999383926
step: 250, loss: 0.023171039298176765
step: 260, loss: 0.016809651628136635
step: 270, loss: 0.08299005031585693
step: 280, loss: 0.042602233588695526
step: 290, loss: 0.12666064500808716
step: 300, loss: 0.1525140106678009
step: 310, loss: 0.02879004366695881
step: 320, loss: 0.00556098623201251
step: 330, loss: 0.05006035789847374
step: 340, loss: 0.016567492857575417
step: 350, loss: 0.007967507466673851
step: 360, loss: 0.004712506663054228
step: 370, loss: 0.08475755155086517
step: 380, loss: 0.02803833968937397
step: 390, loss: 0.023307422176003456
step: 400, loss: 0.13808539509773254
step: 410, loss: 0.0339474119246006
step: 420, loss: 0.0754057765007019
step: 430, loss: 0.0005432372563518584
step: 440, loss: 0.009219360537827015
step: 450, loss: 0.08163204789161682
step: 460, loss: 0.06181134656071663
step: 470, loss: 0.04617457464337349
step: 480, loss: 0.06618031859397888
step: 490, loss: 0.009855911135673523
step: 500, loss: 0.13617098331451416
step: 510, loss: 0.039128366857767105
step: 520, loss: 0.10304585099220276
step: 530, loss: 0.029293280094861984
step: 540, loss: 0.056185513734817505
step: 550, loss: 0.018043674528598785
step: 560, loss: 0.02411765046417713
step: 570, loss: 0.3397202491760254
step: 580, loss: 0.02705971896648407
step: 590, loss: 0.06875916570425034
step: 600, loss: 0.0628739595413208
step: 610, loss: 0.07756180316209793
step: 620, loss: 0.03325805440545082
step: 630, loss: 0.005137781612575054
step: 640, loss: 0.05452889949083328
step: 650, loss: 0.047054629772901535
step: 660, loss: 0.2151482254266739
step: 670, loss: 0.1441454440355301
step: 680, loss: 2.0939552996424027e-05
step: 690, loss: 0.016454078257083893
step: 700, loss: 0.14396151900291443
step: 710, loss: 0.0020091126207262278
step: 720, loss: 0.018442122265696526
step: 730, loss: 0.013753560371696949
step: 740, loss: 0.07419852912425995
step: 750, loss: 0.0503508634865284
step: 760, loss: 0.055808719247579575
step: 770, loss: 0.026340313255786896
step: 780, loss: 0.014381756074726582
step: 790, loss: 0.02984555810689926
step: 800, loss: 0.06243089213967323
step: 810, loss: 0.03354838117957115
step: 820, loss: 0.0836656466126442
step: 830, loss: 0.13111552596092224
step: 840, loss: 0.0001983453257707879
step: 850, loss: 0.049368664622306824
step: 860, loss: 0.0015211827121675014
step: 870, loss: 0.0711255893111229
step: 880, loss: 0.055240463465452194
step: 890, loss: 0.01588285341858864
step: 900, loss: 0.050233665853738785
step: 910, loss: 0.005953521467745304
step: 920, loss: 0.029531486332416534
step: 930, loss: 0.12112215161323547
step: 940, loss: 0.09104983508586884
step: 950, loss: 0.033330924808979034
step: 960, loss: 0.03662872686982155
step: 970, loss: 0.03797701746225357
epoch 11: dev_f1=0.9348837209302325, f1=0.9311294765840221, best_f1=0.9325894932589495
step: 0, loss: 0.16598188877105713
step: 10, loss: 0.022020787000656128
step: 20, loss: 0.05219542607665062
step: 30, loss: 0.0906350240111351
step: 40, loss: 0.006168655585497618
step: 50, loss: 0.01523895375430584
step: 60, loss: 0.06359817087650299
step: 70, loss: 0.010020039044320583
step: 80, loss: 0.006008638069033623
step: 90, loss: 0.01557636447250843
step: 100, loss: 0.013604572974145412
step: 110, loss: 0.061886053532361984
step: 120, loss: 0.11676396429538727
step: 130, loss: 0.1583910882472992
step: 140, loss: 0.1543617993593216
step: 150, loss: 0.036151718348264694
step: 160, loss: 0.010447761975228786
step: 170, loss: 0.01662403903901577
step: 180, loss: 0.03665677458047867
step: 190, loss: 0.09415891766548157
step: 200, loss: 7.261368591571227e-05
step: 210, loss: 0.12464729696512222
step: 220, loss: 0.011388842016458511
step: 230, loss: 0.08576807379722595
step: 240, loss: 0.041154541075229645
step: 250, loss: 0.008475324138998985
step: 260, loss: 0.08602940291166306
step: 270, loss: 0.03259359672665596
step: 280, loss: 0.01254118513315916
step: 290, loss: 0.004826197866350412
step: 300, loss: 0.012470327317714691
step: 310, loss: 0.05072818696498871
step: 320, loss: 0.017072279006242752
step: 330, loss: 0.10134761035442352
step: 340, loss: 0.04666265845298767
step: 350, loss: 0.036557212471961975
step: 360, loss: 0.001986180664971471
step: 370, loss: 0.04619837552309036
step: 380, loss: 0.008393269963562489
step: 390, loss: 0.0004964685649611056
step: 400, loss: 0.12680445611476898
step: 410, loss: 0.07034376263618469
step: 420, loss: 0.008386712521314621
step: 430, loss: 0.007802712265402079
step: 440, loss: 0.07693508267402649
step: 450, loss: 0.009507506154477596
step: 460, loss: 0.10264504700899124
step: 470, loss: 0.0899328887462616
step: 480, loss: 0.004260100424289703
step: 490, loss: 0.05494198948144913
step: 500, loss: 0.012695342302322388
step: 510, loss: 0.03143461421132088
step: 520, loss: 0.047773778438568115
step: 530, loss: 0.01438187062740326
step: 540, loss: 0.06117229163646698
step: 550, loss: 0.044361621141433716
step: 560, loss: 0.011254869401454926
step: 570, loss: 0.01587042771279812
step: 580, loss: 0.06215894967317581
step: 590, loss: 0.2712227702140808
step: 600, loss: 0.02281600795686245
step: 610, loss: 3.046443816856481e-05
step: 620, loss: 0.021543128415942192
step: 630, loss: 0.02003394439816475
step: 640, loss: 0.05451222509145737
step: 650, loss: 0.01023503951728344
step: 660, loss: 0.06812865287065506
step: 670, loss: 0.006315640173852444
step: 680, loss: 0.031792011111974716
step: 690, loss: 0.021387673914432526
step: 700, loss: 0.05802120640873909
step: 710, loss: 0.004386264830827713
step: 720, loss: 0.024609366431832314
step: 730, loss: 0.09150296449661255
step: 740, loss: 0.005730304401367903
step: 750, loss: 0.008950403891503811
step: 760, loss: 0.15154138207435608
step: 770, loss: 0.05316564068198204
step: 780, loss: 0.0027175662107765675
step: 790, loss: 0.13589522242546082
step: 800, loss: 0.03668530657887459
step: 810, loss: 0.008599243126809597
step: 820, loss: 0.06682707369327545
step: 830, loss: 0.05537686124444008
step: 840, loss: 0.029144812375307083
step: 850, loss: 0.02784978412091732
step: 860, loss: 0.017278866842389107
step: 870, loss: 0.03851478546857834
step: 880, loss: 0.07284906506538391
step: 890, loss: 0.10130593180656433
step: 900, loss: 0.006742650177329779
step: 910, loss: 0.05412718653678894
step: 920, loss: 0.08351822942495346
step: 930, loss: 0.10172192007303238
step: 940, loss: 0.09414025396108627
step: 950, loss: 1.506847456766991e-05
step: 960, loss: 0.10094591230154037
step: 970, loss: 0.010193712078034878
epoch 12: dev_f1=0.9336426914153132, f1=0.9327188940092166, best_f1=0.9325894932589495
step: 0, loss: 0.019240044057369232
step: 10, loss: 0.06771280616521835
step: 20, loss: 0.05730569735169411
step: 30, loss: 0.013440310023725033
step: 40, loss: 0.055417437106370926
step: 50, loss: 0.15751732885837555
step: 60, loss: 0.12873037159442902
step: 70, loss: 0.025507580488920212
step: 80, loss: 0.003993404097855091
step: 90, loss: 0.04708411917090416
step: 100, loss: 0.09619376063346863
step: 110, loss: 0.061190783977508545
step: 120, loss: 0.00695079006254673
step: 130, loss: 0.015131703577935696
step: 140, loss: 0.09338817000389099
step: 150, loss: 0.01855451613664627
step: 160, loss: 0.07446403056383133
step: 170, loss: 0.16458112001419067
step: 180, loss: 0.07501691579818726
step: 190, loss: 0.03370516747236252
step: 200, loss: 0.02053692191839218
step: 210, loss: 0.01079675741493702
step: 220, loss: 0.08442768454551697
step: 230, loss: 0.07405823469161987
step: 240, loss: 0.08134573698043823
step: 250, loss: 0.006392301060259342
step: 260, loss: 0.05174654349684715
step: 270, loss: 0.02194414660334587
step: 280, loss: 0.07025336474180222
step: 290, loss: 0.005200785119086504
step: 300, loss: 0.0035273947287350893
step: 310, loss: 0.01582801342010498
step: 320, loss: 0.04110421612858772
step: 330, loss: 0.001672708778642118
step: 340, loss: 0.006876485422253609
step: 350, loss: 0.0647389143705368
step: 360, loss: 0.16799518465995789
step: 370, loss: 0.006651758216321468
step: 380, loss: 0.12528590857982635
step: 390, loss: 0.03099116124212742
step: 400, loss: 0.05597388744354248
step: 410, loss: 0.009384985081851482
step: 420, loss: 0.1418948918581009
step: 430, loss: 0.09901722520589828
step: 440, loss: 0.03295869380235672
step: 450, loss: 0.014460789039731026
step: 460, loss: 0.08843966573476791
step: 470, loss: 0.08071599155664444
step: 480, loss: 0.001584522775374353
step: 490, loss: 0.01530569326132536
step: 500, loss: 0.016768502071499825
step: 510, loss: 0.05785907804965973
step: 520, loss: 0.02218398079276085
step: 530, loss: 5.7291428674943745e-05
step: 540, loss: 0.03850163146853447
step: 550, loss: 0.1817387044429779
step: 560, loss: 0.07848526537418365
step: 570, loss: 0.09796019643545151
step: 580, loss: 0.0022113672457635403
step: 590, loss: 0.03346645087003708
step: 600, loss: 0.02577427588403225
step: 610, loss: 0.009768083691596985
step: 620, loss: 0.06932656466960907
step: 630, loss: 0.03761077672243118
step: 640, loss: 0.05593287944793701
step: 650, loss: 0.06794542074203491
step: 660, loss: 0.04691760987043381
step: 670, loss: 0.050177108496427536
step: 680, loss: 0.05809095874428749
step: 690, loss: 0.05795859545469284
step: 700, loss: 0.05562247708439827
step: 710, loss: 0.0007503380766138434
step: 720, loss: 0.08403973281383514
step: 730, loss: 0.1448194980621338
step: 740, loss: 0.0467185378074646
step: 750, loss: 0.06835313886404037
step: 760, loss: 0.056049082428216934
step: 770, loss: 0.04898715764284134
step: 780, loss: 0.02982371486723423
step: 790, loss: 0.06217969208955765
step: 800, loss: 0.009129405952990055
step: 810, loss: 0.07005572319030762
step: 820, loss: 0.11552424728870392
step: 830, loss: 0.047875016927719116
step: 840, loss: 0.0646461546421051
step: 850, loss: 0.011530976742506027
step: 860, loss: 0.012678710743784904
step: 870, loss: 0.020695218816399574
step: 880, loss: 0.0016412873519584537
step: 890, loss: 0.057081662118434906
step: 900, loss: 0.09665390104055405
step: 910, loss: 0.03307393938302994
step: 920, loss: 0.02554246596992016
step: 930, loss: 0.095931775867939
step: 940, loss: 0.2300483137369156
step: 950, loss: 0.0319533497095108
step: 960, loss: 0.09665058553218842
step: 970, loss: 0.018720291554927826
epoch 13: dev_f1=0.9307657038055936, f1=0.927007299270073, best_f1=0.9325894932589495
step: 0, loss: 0.023276541382074356
step: 10, loss: 0.021690603345632553
step: 20, loss: 0.03379400447010994
step: 30, loss: 0.028913678601384163
step: 40, loss: 0.019231317564845085
step: 50, loss: 0.012126479297876358
step: 60, loss: 0.024389250203967094
step: 70, loss: 0.00014710573304910213
step: 80, loss: 0.04258705675601959
step: 90, loss: 0.00421249121427536
step: 100, loss: 0.0809595137834549
step: 110, loss: 0.04314623028039932
step: 120, loss: 0.08022695779800415
step: 130, loss: 0.0371987447142601
step: 140, loss: 0.009749283082783222
step: 150, loss: 0.0018863928271457553
step: 160, loss: 0.051372017711400986
step: 170, loss: 0.01689765229821205
step: 180, loss: 0.050444141030311584
step: 190, loss: 0.03627051040530205
step: 200, loss: 0.08073928207159042
step: 210, loss: 0.11103761196136475
step: 220, loss: 0.03724981099367142
step: 230, loss: 0.029980452731251717
step: 240, loss: 0.0003608259139582515
step: 250, loss: 0.0963820293545723
step: 260, loss: 0.0466763898730278
step: 270, loss: 0.03958826884627342
step: 280, loss: 0.0790400505065918
step: 290, loss: 0.07007290422916412
step: 300, loss: 0.02540583536028862
step: 310, loss: 0.020967600867152214
step: 320, loss: 0.0007971799932420254
step: 330, loss: 0.0326114147901535
step: 340, loss: 0.0011529006296768785
step: 350, loss: 0.0001876731839729473
step: 360, loss: 0.047513045370578766
step: 370, loss: 0.02109629660844803
step: 380, loss: 0.0037152718286961317
step: 390, loss: 0.014781245961785316
step: 400, loss: 0.011630767025053501
step: 410, loss: 0.0008431078167632222
step: 420, loss: 0.026476629078388214
step: 430, loss: 0.007755528204143047
step: 440, loss: 0.02649507112801075
step: 450, loss: 0.03358214721083641
step: 460, loss: 0.14083287119865417
step: 470, loss: 0.02978585846722126
step: 480, loss: 0.01492901798337698
step: 490, loss: 0.03986429423093796
step: 500, loss: 0.11372452974319458
step: 510, loss: 0.05111064016819
step: 520, loss: 0.07735477387905121
step: 530, loss: 0.000244544557062909
step: 540, loss: 0.07637494802474976
step: 550, loss: 0.01312382984906435
step: 560, loss: 0.08363206684589386
step: 570, loss: 0.07459867745637894
step: 580, loss: 0.05929690599441528
step: 590, loss: 0.020578373223543167
step: 600, loss: 0.02163219451904297
step: 610, loss: 0.06233541667461395
step: 620, loss: 0.04757018759846687
step: 630, loss: 0.025594161823391914
step: 640, loss: 0.023122835904359818
step: 650, loss: 0.003019285388290882
step: 660, loss: 0.0009127767407335341
step: 670, loss: 0.012119678780436516
step: 680, loss: 0.004713015165179968
step: 690, loss: 0.005107314791530371
step: 700, loss: 0.0019934321753680706
step: 710, loss: 0.09469825029373169
step: 720, loss: 0.08430428057909012
step: 730, loss: 0.004939549136906862
step: 740, loss: 0.011824911460280418
step: 750, loss: 0.010373151861131191
step: 760, loss: 0.024733761325478554
step: 770, loss: 0.013165250420570374
step: 780, loss: 0.032427556812763214
step: 790, loss: 0.05912047252058983
step: 800, loss: 0.022724376991391182
step: 810, loss: 0.03043201006948948
step: 820, loss: 0.04262414574623108
step: 830, loss: 0.03351476043462753
step: 840, loss: 0.0005140856956131756
step: 850, loss: 0.00877782329916954
step: 860, loss: 0.06788644194602966
step: 870, loss: 0.07553672790527344
step: 880, loss: 0.034374915063381195
step: 890, loss: 0.09034979343414307
step: 900, loss: 0.0007369960658252239
step: 910, loss: 0.00335746631026268
step: 920, loss: 0.008236343041062355
step: 930, loss: 0.02605416625738144
step: 940, loss: 0.03375717252492905
step: 950, loss: 0.01928037405014038
step: 960, loss: 0.020913351327180862
step: 970, loss: 0.03936546668410301
epoch 14: dev_f1=0.9355870260392875, f1=0.9264972776769511, best_f1=0.9325894932589495
step: 0, loss: 0.0004319172876421362
step: 10, loss: 0.002493770094588399
step: 20, loss: 0.0626564547419548
step: 30, loss: 0.055796388536691666
step: 40, loss: 0.013134429231286049
step: 50, loss: 0.04159857705235481
step: 60, loss: 0.03497099131345749
step: 70, loss: 0.025074563920497894
step: 80, loss: 0.051493171602487564
step: 90, loss: 0.07697335630655289
step: 100, loss: 0.02409648522734642
step: 110, loss: 0.035010382533073425
step: 120, loss: 0.031033188104629517
step: 130, loss: 0.017074642702937126
step: 140, loss: 0.003921065013855696
step: 150, loss: 0.050503816455602646
step: 160, loss: 0.05944693833589554
step: 170, loss: 0.11307816952466965
step: 180, loss: 0.019028615206480026
step: 190, loss: 0.029353933408856392
step: 200, loss: 0.03428110107779503
step: 210, loss: 0.032339781522750854
step: 220, loss: 0.02124055102467537
step: 230, loss: 0.00010585501149762422
step: 240, loss: 0.05655025318264961
step: 250, loss: 0.0003656524932011962
step: 260, loss: 0.03601330891251564
step: 270, loss: 0.021307412534952164
step: 280, loss: 0.09462182223796844
step: 290, loss: 0.007017434574663639
step: 300, loss: 0.06798724085092545
step: 310, loss: 0.028455594554543495
step: 320, loss: 0.023968329653143883
step: 330, loss: 0.058455370366573334
step: 340, loss: 0.014457730576395988
step: 350, loss: 0.026099462062120438
step: 360, loss: 0.0025299901608377695
step: 370, loss: 0.0035384781658649445
step: 380, loss: 0.07736430317163467
step: 390, loss: 0.0765540823340416
step: 400, loss: 0.031898193061351776
step: 410, loss: 0.01894523575901985
step: 420, loss: 0.10740025341510773
step: 430, loss: 0.034646086394786835
step: 440, loss: 0.07889704406261444
step: 450, loss: 0.004708393476903439
step: 460, loss: 0.04416293278336525
step: 470, loss: 0.004736860282719135
step: 480, loss: 0.04611876234412193
step: 490, loss: 0.03150194510817528
step: 500, loss: 0.034644171595573425
step: 510, loss: 0.008811680600047112
step: 520, loss: 0.027593601495027542
step: 530, loss: 0.020112112164497375
step: 540, loss: 0.07656142860651016
step: 550, loss: 0.03341761603951454
step: 560, loss: 0.02112571895122528
step: 570, loss: 0.039385221898555756
step: 580, loss: 0.01654217205941677
step: 590, loss: 0.03502093255519867
step: 600, loss: 0.030895721167325974
step: 610, loss: 0.05688735842704773
step: 620, loss: 0.01653830148279667
step: 630, loss: 0.0896662101149559
step: 640, loss: 0.003683636896312237
step: 650, loss: 0.09534497559070587
step: 660, loss: 0.005696755833923817
step: 670, loss: 0.042307544499635696
step: 680, loss: 0.08110120892524719
step: 690, loss: 0.005460470914840698
step: 700, loss: 0.0012635115999728441
step: 710, loss: 9.339255484519526e-06
step: 720, loss: 0.0074358792044222355
step: 730, loss: 0.03959829360246658
step: 740, loss: 0.041019588708877563
step: 750, loss: 0.013561706058681011
step: 760, loss: 0.08887758105993271
step: 770, loss: 0.08358137309551239
step: 780, loss: 0.05060967430472374
step: 790, loss: 0.07218105345964432
step: 800, loss: 0.09894305467605591
step: 810, loss: 0.06627067178487778
step: 820, loss: 0.0040601869113743305
step: 830, loss: 0.045147910714149475
step: 840, loss: 0.07075567543506622
step: 850, loss: 0.02658606693148613
step: 860, loss: 0.01220949087291956
step: 870, loss: 0.07363200932741165
step: 880, loss: 0.033045846968889236
step: 890, loss: 0.02572762407362461
step: 900, loss: 0.021774981170892715
step: 910, loss: 0.10581951588392258
step: 920, loss: 0.010026531293988228
step: 930, loss: 0.09682334959506989
step: 940, loss: 0.10458754003047943
step: 950, loss: 0.000922027335036546
step: 960, loss: 0.02380262315273285
step: 970, loss: 0.058104462921619415
epoch 15: dev_f1=0.9284085727314182, f1=0.9184782608695652, best_f1=0.9325894932589495
step: 0, loss: 0.06582178175449371
step: 10, loss: 0.047880977392196655
step: 20, loss: 0.03404301777482033
step: 30, loss: 0.0802929624915123
step: 40, loss: 0.03678210824728012
step: 50, loss: 0.0008031213656067848
step: 60, loss: 8.950443589128554e-05
step: 70, loss: 0.0016931828577071428
step: 80, loss: 0.027741895988583565
step: 90, loss: 0.057740893214941025
step: 100, loss: 0.005121593363583088
step: 110, loss: 0.05561064928770065
step: 120, loss: 0.0012233797460794449
step: 130, loss: 0.05343004688620567
step: 140, loss: 0.018879693001508713
step: 150, loss: 0.06195478513836861
step: 160, loss: 0.02164522372186184
step: 170, loss: 0.012048994190990925
step: 180, loss: 0.011272047646343708
step: 190, loss: 0.0180241446942091
step: 200, loss: 0.0002589296200312674
step: 210, loss: 0.02655269205570221
step: 220, loss: 0.050599608570337296
step: 230, loss: 0.07076165825128555
step: 240, loss: 0.0016418665181845427
step: 250, loss: 0.15868708491325378
step: 260, loss: 0.013859464786946774
step: 270, loss: 0.05928849056363106
step: 280, loss: 0.0008411065209656954
step: 290, loss: 0.05591849610209465
step: 300, loss: 0.059490181505680084
step: 310, loss: 0.0333394855260849
step: 320, loss: 0.00023301066539715976
step: 330, loss: 0.023180998861789703
step: 340, loss: 0.04272180423140526
step: 350, loss: 0.0003827469190582633
step: 360, loss: 0.17907701432704926
step: 370, loss: 0.038045693188905716
step: 380, loss: 0.038147736340761185
step: 390, loss: 0.04559144750237465
step: 400, loss: 0.006880949717015028
step: 410, loss: 0.016487039625644684
step: 420, loss: 0.013525275513529778
step: 430, loss: 0.04656762257218361
step: 440, loss: 0.006709093227982521
step: 450, loss: 0.010846609249711037
step: 460, loss: 0.015530474483966827
step: 470, loss: 0.023115722462534904
step: 480, loss: 0.04353177174925804
step: 490, loss: 0.024791749194264412
step: 500, loss: 0.005359044764190912
step: 510, loss: 0.03886283189058304
step: 520, loss: 0.07114289700984955
step: 530, loss: 0.0002745635574683547
step: 540, loss: 0.06402362138032913
step: 550, loss: 0.0024196950253099203
step: 560, loss: 8.499316754750907e-05
step: 570, loss: 0.0011741159250959754
step: 580, loss: 1.3403438060777262e-05
step: 590, loss: 0.01050153560936451
step: 600, loss: 0.01923178695142269
step: 610, loss: 0.16324645280838013
step: 620, loss: 0.0018001483986154199
step: 630, loss: 0.029840733855962753
step: 640, loss: 0.1308491975069046
step: 650, loss: 0.031372491270303726
step: 660, loss: 0.10122177004814148
step: 670, loss: 0.05479133874177933
step: 680, loss: 0.03851490840315819
step: 690, loss: 0.025821924209594727
step: 700, loss: 0.05935937538743019
step: 710, loss: 0.01936948299407959
step: 720, loss: 0.018127935007214546
step: 730, loss: 0.04829510301351547
step: 740, loss: 0.0036354244221001863
step: 750, loss: 0.087171770632267
step: 760, loss: 0.024527495726943016
step: 770, loss: 0.00019366525521036237
step: 780, loss: 0.06300509721040726
step: 790, loss: 0.024620382115244865
step: 800, loss: 0.004118551500141621
step: 810, loss: 0.07299384474754333
step: 820, loss: 0.060377005487680435
step: 830, loss: 0.0622529499232769
step: 840, loss: 0.0005755695165134966
step: 850, loss: 0.0008958757389336824
step: 860, loss: 0.06087171658873558
step: 870, loss: 0.06262009590864182
step: 880, loss: 0.00043914112029597163
step: 890, loss: 0.10308040678501129
step: 900, loss: 0.014039394445717335
step: 910, loss: 0.05671286582946777
step: 920, loss: 0.01510616485029459
step: 930, loss: 0.020452888682484627
step: 940, loss: 0.005079859402030706
step: 950, loss: 0.024879731237888336
step: 960, loss: 0.018182914704084396
step: 970, loss: 4.981337406206876e-05
epoch 16: dev_f1=0.9290746829497416, f1=0.9245810055865922, best_f1=0.9325894932589495
step: 0, loss: 0.03476887568831444
step: 10, loss: 0.0550290122628212
step: 20, loss: 0.0006957646692171693
step: 30, loss: 0.020106971263885498
step: 40, loss: 0.0002745205711107701
step: 50, loss: 0.022566059604287148
step: 60, loss: 0.054794251918792725
step: 70, loss: 0.15978480875492096
step: 80, loss: 0.0002154878748115152
step: 90, loss: 0.005804302636533976
step: 100, loss: 0.024448230862617493
step: 110, loss: 0.016400840133428574
step: 120, loss: 0.001000732183456421
step: 130, loss: 0.036069292575120926
step: 140, loss: 0.01324770599603653
step: 150, loss: 0.0003752498887479305
step: 160, loss: 0.04202812537550926
step: 170, loss: 0.05816304311156273
step: 180, loss: 0.02440161630511284
step: 190, loss: 0.020409466698765755
step: 200, loss: 0.06639063358306885
step: 210, loss: 0.044009871780872345
step: 220, loss: 0.0574035719037056
step: 230, loss: 0.025881262496113777
step: 240, loss: 0.03277800977230072
step: 250, loss: 0.014905272051692009
step: 260, loss: 0.025913158431649208
step: 270, loss: 0.030678771436214447
step: 280, loss: 0.04167225956916809
step: 290, loss: 0.09489975869655609
step: 300, loss: 0.028050582855939865
step: 310, loss: 0.05248082056641579
step: 320, loss: 1.0479169759491924e-05
step: 330, loss: 0.055764105170965195
step: 340, loss: 0.0018747803987935185
step: 350, loss: 0.01962895691394806
step: 360, loss: 0.022097386419773102
step: 370, loss: 0.02325555309653282
step: 380, loss: 0.061122994869947433
step: 390, loss: 0.01154909934848547
step: 400, loss: 0.030985435470938683
step: 410, loss: 0.0012787431478500366
step: 420, loss: 0.0017958388198167086
step: 430, loss: 0.002641331171616912
step: 440, loss: 0.0002268323878524825
step: 450, loss: 0.00957416370511055
step: 460, loss: 0.0033541980665177107
step: 470, loss: 0.11870640516281128
step: 480, loss: 0.0002500179107300937
step: 490, loss: 0.04807964712381363
step: 500, loss: 0.001023554359562695
step: 510, loss: 0.03842480480670929
step: 520, loss: 0.053111426532268524
step: 530, loss: 0.025273259729146957
step: 540, loss: 0.0006117333541624248
step: 550, loss: 0.07038810104131699
step: 560, loss: 0.021658318117260933
step: 570, loss: 0.00037767007597722113
step: 580, loss: 0.026380382478237152
step: 590, loss: 0.06819947808980942
step: 600, loss: 3.188908158335835e-05
step: 610, loss: 0.05917934700846672
step: 620, loss: 0.03317483887076378
step: 630, loss: 0.051966339349746704
step: 640, loss: 0.0015260133659467101
step: 650, loss: 0.025370053946971893
step: 660, loss: 0.04549029469490051
step: 670, loss: 0.01889714039862156
step: 680, loss: 0.0414101742208004
step: 690, loss: 0.07793199270963669
step: 700, loss: 0.023799626156687737
step: 710, loss: 0.039821695536375046
step: 720, loss: 0.01924709789454937
step: 730, loss: 0.0023676096461713314
step: 740, loss: 0.0008983490988612175
step: 750, loss: 0.0005561577272601426
step: 760, loss: 0.04030011221766472
step: 770, loss: 0.10242515057325363
step: 780, loss: 0.023125287145376205
step: 790, loss: 0.02833273634314537
step: 800, loss: 0.01633540168404579
step: 810, loss: 0.026944555342197418
step: 820, loss: 0.03597104549407959
step: 830, loss: 0.023038703948259354
step: 840, loss: 0.007083950564265251
step: 850, loss: 0.052972663193941116
step: 860, loss: 0.019700486212968826
step: 870, loss: 0.0001056478577083908
step: 880, loss: 6.571717676706612e-05
step: 890, loss: 0.00020963334827683866
step: 900, loss: 0.00023391089052893221
step: 910, loss: 0.153322234749794
step: 920, loss: 0.04215899482369423
step: 930, loss: 0.07774925976991653
step: 940, loss: 0.018423035740852356
step: 950, loss: 0.030600763857364655
step: 960, loss: 0.01492045447230339
step: 970, loss: 0.026515722274780273
epoch 17: dev_f1=0.9318497913769124, f1=0.9250574712643677, best_f1=0.9325894932589495
step: 0, loss: 0.022506648674607277
step: 10, loss: 0.00017709714302327484
step: 20, loss: 0.05702619627118111
step: 30, loss: 1.449849150958471e-05
step: 40, loss: 0.022157883271574974
step: 50, loss: 0.031666290014982224
step: 60, loss: 0.010268932208418846
step: 70, loss: 0.01688644103705883
step: 80, loss: 0.02234007976949215
step: 90, loss: 0.0005940337432548404
step: 100, loss: 0.09813202172517776
step: 110, loss: 0.026961414143443108
step: 120, loss: 0.10027489811182022
step: 130, loss: 0.0005477642407640815
step: 140, loss: 0.058295633643865585
step: 150, loss: 0.06519044190645218
step: 160, loss: 4.043841909151524e-05
step: 170, loss: 0.0017468963051214814
step: 180, loss: 0.03271465376019478
step: 190, loss: 0.023762645199894905
step: 200, loss: 0.030253196135163307
step: 210, loss: 0.06540700793266296
step: 220, loss: 0.06593328714370728
step: 230, loss: 0.02426806464791298
step: 240, loss: 0.03264635056257248
step: 250, loss: 0.055456966161727905
step: 260, loss: 2.490127553755883e-05
step: 270, loss: 0.04711075872182846
step: 280, loss: 0.0021309403236955404
step: 290, loss: 0.03147515654563904
step: 300, loss: 0.027432756498456
step: 310, loss: 0.08203985542058945
step: 320, loss: 0.06813473999500275
step: 330, loss: 0.000220187779632397
step: 340, loss: 0.015058224089443684
step: 350, loss: 0.06095917895436287
step: 360, loss: 0.0188668891787529
step: 370, loss: 0.0011814869940280914
step: 380, loss: 0.016894062981009483
step: 390, loss: 0.08652516454458237
step: 400, loss: 0.05883938446640968
step: 410, loss: 0.017746811732649803
step: 420, loss: 0.028397219255566597
step: 430, loss: 0.06502103805541992
step: 440, loss: 0.016807150095701218
step: 450, loss: 2.663130908331368e-05
step: 460, loss: 0.04726202413439751
step: 470, loss: 0.0001298268762184307
step: 480, loss: 0.005048716440796852
step: 490, loss: 0.02585936337709427
step: 500, loss: 0.04673352837562561
step: 510, loss: 0.005823344923555851
step: 520, loss: 0.04542655497789383
step: 530, loss: 0.06564530730247498
step: 540, loss: 0.027591431513428688
step: 550, loss: 0.020270412787795067
step: 560, loss: 0.1216917634010315
step: 570, loss: 0.000524086004588753
step: 580, loss: 0.019749358296394348
step: 590, loss: 0.005187017377465963
step: 600, loss: 0.04694262892007828
step: 610, loss: 0.044568367302417755
step: 620, loss: 0.020190492272377014
step: 630, loss: 0.02332869917154312
step: 640, loss: 6.583170761587098e-05
step: 650, loss: 0.01828717067837715
step: 660, loss: 0.00015871794312261045
step: 670, loss: 0.014942700043320656
step: 680, loss: 0.024299954995512962
step: 690, loss: 0.046492479741573334
step: 700, loss: 0.033096250146627426
step: 710, loss: 0.00011078170064138249
step: 720, loss: 0.045128293335437775
step: 730, loss: 0.021930521354079247
step: 740, loss: 0.04988841339945793
step: 750, loss: 0.019391074776649475
step: 760, loss: 0.021338367834687233
step: 770, loss: 0.056039005517959595
step: 780, loss: 0.03365490213036537
step: 790, loss: 0.007071376778185368
step: 800, loss: 0.0010230696061626077
step: 810, loss: 0.027069075033068657
step: 820, loss: 0.00011969692423008382
step: 830, loss: 0.07435163855552673
step: 840, loss: 0.04479968920350075
step: 850, loss: 1.3839195162290707e-05
step: 860, loss: 0.18422213196754456
step: 870, loss: 0.014911984093487263
step: 880, loss: 0.07145316898822784
step: 890, loss: 0.08726488053798676
step: 900, loss: 0.025872133672237396
step: 910, loss: 0.043861061334609985
step: 920, loss: 0.13375289738178253
step: 930, loss: 0.03886905312538147
step: 940, loss: 0.008063373155891895
step: 950, loss: 0.03380405157804489
step: 960, loss: 0.02355230040848255
step: 970, loss: 0.09434717893600464
epoch 18: dev_f1=0.9325267566309912, f1=0.927643784786642, best_f1=0.9325894932589495
step: 0, loss: 0.016509754583239555
step: 10, loss: 0.052424538880586624
step: 20, loss: 0.04952719062566757
step: 30, loss: 0.054257698357105255
step: 40, loss: 0.049414634704589844
step: 50, loss: 0.06212577968835831
step: 60, loss: 6.98030780768022e-05
step: 70, loss: 0.025653526186943054
step: 80, loss: 0.039170943200588226
step: 90, loss: 0.027930129319429398
step: 100, loss: 0.07957723736763
step: 110, loss: 0.0007556870114058256
step: 120, loss: 0.017102627083659172
step: 130, loss: 0.025520646944642067
step: 140, loss: 0.030950356274843216
step: 150, loss: 0.029859647154808044
step: 160, loss: 0.040633462369441986
step: 170, loss: 0.05774533748626709
step: 180, loss: 0.03151218593120575
step: 190, loss: 0.06567970663309097
step: 200, loss: 0.0543309710919857
step: 210, loss: 0.03953723609447479
step: 220, loss: 0.02334555797278881
step: 230, loss: 0.07008708268404007
step: 240, loss: 0.03229892998933792
step: 250, loss: 0.05929293856024742
step: 260, loss: 0.025072339922189713
step: 270, loss: 0.002772226231172681
step: 280, loss: 0.10612708330154419
step: 290, loss: 0.00012245775724295527
step: 300, loss: 0.013506767340004444
step: 310, loss: 0.01869037188589573
step: 320, loss: 0.029947824776172638
step: 330, loss: 0.030080225318670273
step: 340, loss: 1.1179510693182237e-05
step: 350, loss: 0.01932024210691452
step: 360, loss: 0.02757980488240719
step: 370, loss: 0.11511903256177902
step: 380, loss: 0.036510296165943146
step: 390, loss: 0.03642817959189415
step: 400, loss: 0.06371354311704636
step: 410, loss: 0.011363771744072437
step: 420, loss: 0.0038099470548331738
step: 430, loss: 0.003220164682716131
step: 440, loss: 0.08301208913326263
step: 450, loss: 0.03160611540079117
step: 460, loss: 0.04708202928304672
step: 470, loss: 0.06301654130220413
step: 480, loss: 0.05228830873966217
step: 490, loss: 0.013521624729037285
step: 500, loss: 0.11208745837211609
step: 510, loss: 0.021785235032439232
step: 520, loss: 7.045410893624648e-05
step: 530, loss: 0.018220797181129456
step: 540, loss: 0.046922776848077774
step: 550, loss: 0.005361666437238455
step: 560, loss: 9.369161853101104e-05
step: 570, loss: 0.031480759382247925
step: 580, loss: 0.03444157913327217
step: 590, loss: 0.022108815610408783
step: 600, loss: 5.291192064760253e-05
step: 610, loss: 0.060194578021764755
step: 620, loss: 0.00035499644582159817
step: 630, loss: 0.04954248666763306
step: 640, loss: 0.009859524667263031
step: 650, loss: 0.0008185103069990873
step: 660, loss: 0.011986731551587582
step: 670, loss: 0.0010638702660799026
step: 680, loss: 0.01179273147135973
step: 690, loss: 0.0133667616173625
step: 700, loss: 0.03795870393514633
step: 710, loss: 0.01650845818221569
step: 720, loss: 0.2389627993106842
step: 730, loss: 9.134443098446354e-05
step: 740, loss: 9.049196523847058e-05
step: 750, loss: 9.138859604718164e-05
step: 760, loss: 0.07052908092737198
step: 770, loss: 0.017444778233766556
step: 780, loss: 0.0001814083370845765
step: 790, loss: 4.9958722229348496e-05
step: 800, loss: 0.026128221303224564
step: 810, loss: 0.00010275093518430367
step: 820, loss: 0.019665071740746498
step: 830, loss: 0.03821318596601486
step: 840, loss: 0.0009565879590809345
step: 850, loss: 0.04143483191728592
step: 860, loss: 0.04563590884208679
step: 870, loss: 0.06479218602180481
step: 880, loss: 0.022113176062703133
step: 890, loss: 0.016093220561742783
step: 900, loss: 0.017699087038636208
step: 910, loss: 0.024179581552743912
step: 920, loss: 0.018520958721637726
step: 930, loss: 0.04936126619577408
step: 940, loss: 2.3127757231122814e-05
step: 950, loss: 0.0001423411740688607
step: 960, loss: 0.00011968991020694375
step: 970, loss: 0.018343327566981316
epoch 19: dev_f1=0.930776426566885, f1=0.929368029739777, best_f1=0.9325894932589495
step: 0, loss: 0.00023441611847374588
step: 10, loss: 0.022526321932673454
step: 20, loss: 4.712432928499766e-05
step: 30, loss: 0.01572278141975403
step: 40, loss: 0.04444345459342003
step: 50, loss: 0.03349468111991882
step: 60, loss: 3.25886212522164e-05
step: 70, loss: 0.06249779090285301
step: 80, loss: 0.00011798495688708499
step: 90, loss: 0.06274399906396866
step: 100, loss: 0.023102065548300743
step: 110, loss: 9.689042053651065e-05
step: 120, loss: 0.006116715259850025
step: 130, loss: 0.005675718653947115
step: 140, loss: 0.04428720474243164
step: 150, loss: 0.0047665610909461975
step: 160, loss: 0.027390077710151672
step: 170, loss: 0.018721772357821465
step: 180, loss: 8.923076529754326e-05
step: 190, loss: 3.009746433235705e-05
step: 200, loss: 0.00015851674834266305
step: 210, loss: 0.025432219728827477
step: 220, loss: 0.011266128160059452
step: 230, loss: 0.04522846266627312
step: 240, loss: 0.01335214078426361
step: 250, loss: 0.07527299225330353
step: 260, loss: 5.846955900778994e-05
step: 270, loss: 0.06685512512922287
step: 280, loss: 0.0011359405471011996
step: 290, loss: 0.05547773838043213
step: 300, loss: 0.041143592447042465
step: 310, loss: 0.02162400633096695
step: 320, loss: 0.05084075778722763
step: 330, loss: 2.0439032596186735e-05
step: 340, loss: 0.04736757278442383
step: 350, loss: 7.581524550914764e-05
step: 360, loss: 0.025114092975854874
step: 370, loss: 0.04075926914811134
step: 380, loss: 0.02197822369635105
step: 390, loss: 0.00442839227616787
step: 400, loss: 0.0030080087017267942
step: 410, loss: 0.03517276048660278
step: 420, loss: 4.538476423476823e-05
step: 430, loss: 0.019539859145879745
step: 440, loss: 0.06062515825033188
step: 450, loss: 0.040991250425577164
step: 460, loss: 2.5685603759484366e-05
step: 470, loss: 0.01903994008898735
step: 480, loss: 0.014642313122749329
step: 490, loss: 0.008281790651381016
step: 500, loss: 0.0011780501808971167
step: 510, loss: 0.021406738087534904
step: 520, loss: 0.018499085679650307
step: 530, loss: 0.017727080732584
step: 540, loss: 0.029960941523313522
step: 550, loss: 0.04041706398129463
step: 560, loss: 0.002540959743782878
step: 570, loss: 0.014231713488698006
step: 580, loss: 0.07586351782083511
step: 590, loss: 0.0001961646048584953
step: 600, loss: 1.1846331290144008e-05
step: 610, loss: 0.023108048364520073
step: 620, loss: 0.016307123005390167
step: 630, loss: 0.00019881468324456364
step: 640, loss: 7.01530443620868e-05
step: 650, loss: 0.03069896250963211
step: 660, loss: 0.01686255820095539
step: 670, loss: 0.00012862235598731786
step: 680, loss: 0.022949984297156334
step: 690, loss: 0.056267838925123215
step: 700, loss: 9.280003723688424e-05
step: 710, loss: 9.81236280495068e-06
step: 720, loss: 0.0007659423863515258
step: 730, loss: 0.022295650094747543
step: 740, loss: 0.00012407498434185982
step: 750, loss: 0.015137999318540096
step: 760, loss: 0.012937244959175587
step: 770, loss: 0.01792876049876213
step: 780, loss: 1.2788786079909187e-05
step: 790, loss: 0.030378328636288643
step: 800, loss: 0.04175269976258278
step: 810, loss: 0.0015245259273797274
step: 820, loss: 0.00010080388165079057
step: 830, loss: 0.04716890677809715
step: 840, loss: 0.0574050098657608
step: 850, loss: 0.0547262579202652
step: 860, loss: 0.09544717520475388
step: 870, loss: 0.04964268207550049
step: 880, loss: 0.007092121988534927
step: 890, loss: 0.06015385687351227
step: 900, loss: 0.060995783656835556
step: 910, loss: 4.887465911451727e-05
step: 920, loss: 0.0004729141073767096
step: 930, loss: 0.04616633802652359
step: 940, loss: 0.02738499641418457
step: 950, loss: 0.00010329439101042226
step: 960, loss: 0.054321352392435074
step: 970, loss: 0.043098438531160355
epoch 20: dev_f1=0.9300797747536368, f1=0.9265325222274216, best_f1=0.9325894932589495
