cuda
Device: cuda
step: 0, loss: 0.6083375215530396
step: 10, loss: 0.45849117636680603
step: 20, loss: 0.4235076308250427
step: 30, loss: 0.5015700459480286
step: 40, loss: 0.18389564752578735
step: 50, loss: 0.12836407124996185
step: 60, loss: 0.2718566060066223
step: 70, loss: 0.21273982524871826
step: 80, loss: 0.21658357977867126
step: 90, loss: 0.13050022721290588
step: 100, loss: 0.2305842936038971
step: 110, loss: 0.14832338690757751
step: 120, loss: 0.10130086541175842
step: 130, loss: 0.23028463125228882
step: 140, loss: 0.07994057983160019
step: 150, loss: 0.16264647245407104
step: 160, loss: 0.10648003965616226
step: 170, loss: 0.10133670270442963
step: 180, loss: 0.05265277624130249
step: 190, loss: 0.19175004959106445
step: 200, loss: 0.05027255415916443
step: 210, loss: 0.22040419280529022
step: 220, loss: 0.2221556454896927
step: 230, loss: 0.11870290338993073
step: 240, loss: 0.0926646739244461
step: 250, loss: 0.06032879650592804
step: 260, loss: 0.13123883306980133
step: 270, loss: 0.09600585699081421
step: 280, loss: 0.06079159304499626
step: 290, loss: 0.15686284005641937
step: 300, loss: 0.04423645883798599
step: 310, loss: 0.025801941752433777
step: 320, loss: 0.0996459349989891
step: 330, loss: 0.06699188798666
step: 340, loss: 0.056305181235075
step: 350, loss: 0.1940024346113205
step: 360, loss: 0.13377130031585693
step: 370, loss: 0.2081710696220398
step: 380, loss: 0.1321699619293213
step: 390, loss: 0.14752216637134552
step: 400, loss: 0.14757129549980164
step: 410, loss: 0.1501052975654602
step: 420, loss: 0.3366791903972626
step: 430, loss: 0.1775333285331726
step: 440, loss: 0.06525964289903641
step: 450, loss: 0.167564257979393
step: 460, loss: 0.05270436406135559
step: 470, loss: 0.0517987497150898
step: 480, loss: 0.07384194433689117
step: 490, loss: 0.15406116843223572
step: 500, loss: 0.10190556943416595
step: 510, loss: 0.14321540296077728
step: 520, loss: 0.054597772657871246
step: 530, loss: 0.2610384225845337
step: 540, loss: 0.10627246648073196
step: 550, loss: 0.11320553719997406
step: 560, loss: 0.11605092883110046
step: 570, loss: 0.08306906372308731
step: 580, loss: 0.12408275902271271
step: 590, loss: 0.2718479335308075
step: 600, loss: 0.11837554723024368
step: 610, loss: 0.09436191618442535
step: 620, loss: 0.1579977124929428
step: 630, loss: 0.04611734673380852
step: 640, loss: 0.11781412363052368
step: 650, loss: 0.03866276144981384
step: 660, loss: 0.05973748490214348
step: 670, loss: 0.16860687732696533
step: 680, loss: 0.09171008318662643
step: 690, loss: 0.020208535715937614
step: 700, loss: 0.07239440083503723
step: 710, loss: 0.11004537343978882
step: 720, loss: 0.1399206668138504
step: 730, loss: 0.20121550559997559
step: 740, loss: 0.09560532867908478
step: 750, loss: 0.08128924667835236
step: 760, loss: 0.09122295677661896
step: 770, loss: 0.023310448974370956
step: 780, loss: 0.1294722557067871
step: 790, loss: 0.06727434694766998
step: 800, loss: 0.15796293318271637
step: 810, loss: 0.1857491433620453
step: 820, loss: 0.072716124355793
step: 830, loss: 0.1681673526763916
step: 840, loss: 0.08811139315366745
step: 850, loss: 0.2476789802312851
step: 860, loss: 0.09155572950839996
step: 870, loss: 0.0724257305264473
step: 880, loss: 0.147175133228302
step: 890, loss: 0.2609303295612335
step: 900, loss: 0.059429578483104706
step: 910, loss: 0.04206191748380661
step: 920, loss: 0.12572258710861206
step: 930, loss: 0.07686140388250351
step: 940, loss: 0.120753712952137
step: 950, loss: 0.1358155906200409
step: 960, loss: 0.09081989526748657
step: 970, loss: 0.015868375077843666
epoch 1: dev_f1=0.9182033096926715, f1=0.9165103189493434, best_f1=0.9165103189493434
step: 0, loss: 0.12509891390800476
step: 10, loss: 0.10378086566925049
step: 20, loss: 0.17542153596878052
step: 30, loss: 0.11418275535106659
step: 40, loss: 0.03882519528269768
step: 50, loss: 0.03772822394967079
step: 60, loss: 0.06945613026618958
step: 70, loss: 0.09710783511400223
step: 80, loss: 0.06000003591179848
step: 90, loss: 0.038706518709659576
step: 100, loss: 0.10182733088731766
step: 110, loss: 0.1688607633113861
step: 120, loss: 0.2572336792945862
step: 130, loss: 0.06279614567756653
step: 140, loss: 0.03811866044998169
step: 150, loss: 0.03194636479020119
step: 160, loss: 0.06017143651843071
step: 170, loss: 0.08100968599319458
step: 180, loss: 0.03685298562049866
step: 190, loss: 0.1499108225107193
step: 200, loss: 0.22984975576400757
step: 210, loss: 0.09257379174232483
step: 220, loss: 0.12877361476421356
step: 230, loss: 0.118468277156353
step: 240, loss: 0.12500081956386566
step: 250, loss: 0.1122097373008728
step: 260, loss: 0.15146099030971527
step: 270, loss: 0.06938840448856354
step: 280, loss: 0.01762201078236103
step: 290, loss: 0.031599484384059906
step: 300, loss: 0.09266813844442368
step: 310, loss: 0.0616617314517498
step: 320, loss: 0.06572958081960678
step: 330, loss: 0.046047382056713104
step: 340, loss: 0.09093303233385086
step: 350, loss: 0.09473960846662521
step: 360, loss: 0.0967465490102768
step: 370, loss: 0.1533912569284439
step: 380, loss: 0.16638416051864624
step: 390, loss: 0.1673719435930252
step: 400, loss: 0.0922699123620987
step: 410, loss: 0.05585256963968277
step: 420, loss: 0.010999924503266811
step: 430, loss: 0.08138451725244522
step: 440, loss: 0.05269553139805794
step: 450, loss: 0.07587820291519165
step: 460, loss: 0.12185510247945786
step: 470, loss: 0.05031687021255493
step: 480, loss: 0.09801685065031052
step: 490, loss: 0.14544181525707245
step: 500, loss: 0.07966815680265427
step: 510, loss: 0.031009159982204437
step: 520, loss: 0.03995876759290695
step: 530, loss: 0.0720164030790329
step: 540, loss: 0.006372829899191856
step: 550, loss: 0.1234293058514595
step: 560, loss: 0.208152174949646
step: 570, loss: 0.061949558556079865
step: 580, loss: 0.16625434160232544
step: 590, loss: 0.10649554431438446
step: 600, loss: 0.031259726732969284
step: 610, loss: 0.0731739029288292
step: 620, loss: 0.17036393284797668
step: 630, loss: 0.10997294634580612
step: 640, loss: 0.11407621949911118
step: 650, loss: 0.5661380290985107
step: 660, loss: 0.16648177802562714
step: 670, loss: 0.014286866411566734
step: 680, loss: 0.13924221694469452
step: 690, loss: 0.05975203961133957
step: 700, loss: 0.038384370505809784
step: 710, loss: 0.051399409770965576
step: 720, loss: 0.12564778327941895
step: 730, loss: 0.07956241816282272
step: 740, loss: 0.06010804697871208
step: 750, loss: 0.06217086687684059
step: 760, loss: 0.1035994365811348
step: 770, loss: 0.04354991763830185
step: 780, loss: 0.13513770699501038
step: 790, loss: 0.07599414885044098
step: 800, loss: 0.11083929985761642
step: 810, loss: 0.049670685082674026
step: 820, loss: 0.08363649249076843
step: 830, loss: 0.06833912432193756
step: 840, loss: 0.06756661832332611
step: 850, loss: 0.14063331484794617
step: 860, loss: 0.0435652956366539
step: 870, loss: 0.04465446621179581
step: 880, loss: 0.2692304253578186
step: 890, loss: 0.11342979967594147
step: 900, loss: 0.0904068574309349
step: 910, loss: 0.13164940476417542
step: 920, loss: 0.04925655201077461
step: 930, loss: 0.15852715075016022
step: 940, loss: 0.07035455852746964
step: 950, loss: 0.059308748692274094
step: 960, loss: 0.024885395541787148
step: 970, loss: 0.13240189850330353
epoch 2: dev_f1=0.9242560865644726, f1=0.9210053859964094, best_f1=0.9210053859964094
step: 0, loss: 0.12428488582372665
step: 10, loss: 0.06125854328274727
step: 20, loss: 0.08296553790569305
step: 30, loss: 0.07480523735284805
step: 40, loss: 0.016954945400357246
step: 50, loss: 0.023557648062705994
step: 60, loss: 0.0949491485953331
step: 70, loss: 0.20890215039253235
step: 80, loss: 0.01923586055636406
step: 90, loss: 0.15827475488185883
step: 100, loss: 0.17578580975532532
step: 110, loss: 0.06313788145780563
step: 120, loss: 0.13897234201431274
step: 130, loss: 0.01931198686361313
step: 140, loss: 0.12192489951848984
step: 150, loss: 0.11915566772222519
step: 160, loss: 0.018552690744400024
step: 170, loss: 0.10619998723268509
step: 180, loss: 0.08245908468961716
step: 190, loss: 0.24523210525512695
step: 200, loss: 0.16265907883644104
step: 210, loss: 0.07666327059268951
step: 220, loss: 0.13465532660484314
step: 230, loss: 0.10169807076454163
step: 240, loss: 0.0324115976691246
step: 250, loss: 0.12482393532991409
step: 260, loss: 0.023357052356004715
step: 270, loss: 0.050722040235996246
step: 280, loss: 0.028808386996388435
step: 290, loss: 0.04408833011984825
step: 300, loss: 0.1343512088060379
step: 310, loss: 0.008238691836595535
step: 320, loss: 0.009011907503008842
step: 330, loss: 0.13398265838623047
step: 340, loss: 0.08130667358636856
step: 350, loss: 0.0754401907324791
step: 360, loss: 0.10209383070468903
step: 370, loss: 0.1353732794523239
step: 380, loss: 0.1155363917350769
step: 390, loss: 0.030723242089152336
step: 400, loss: 0.03280229866504669
step: 410, loss: 0.04720134660601616
step: 420, loss: 0.15851636230945587
step: 430, loss: 0.02466532029211521
step: 440, loss: 0.11724832653999329
step: 450, loss: 0.024912064895033836
step: 460, loss: 0.0474366769194603
step: 470, loss: 0.11711803078651428
step: 480, loss: 0.07392647862434387
step: 490, loss: 0.05269331857562065
step: 500, loss: 0.039566997438669205
step: 510, loss: 0.12995490431785583
step: 520, loss: 0.015887785702943802
step: 530, loss: 0.014326836913824081
step: 540, loss: 0.06708827614784241
step: 550, loss: 0.10034739226102829
step: 560, loss: 0.019027775153517723
step: 570, loss: 0.05796978995203972
step: 580, loss: 0.021904554218053818
step: 590, loss: 0.1454717367887497
step: 600, loss: 0.05984062701463699
step: 610, loss: 0.0772087350487709
step: 620, loss: 0.015009039081633091
step: 630, loss: 0.04318112134933472
step: 640, loss: 0.08504801243543625
step: 650, loss: 0.09975138306617737
step: 660, loss: 0.09328243881464005
step: 670, loss: 0.07050152868032455
step: 680, loss: 0.08269813656806946
step: 690, loss: 0.05936127156019211
step: 700, loss: 0.06364770978689194
step: 710, loss: 0.06837356090545654
step: 720, loss: 0.11746791005134583
step: 730, loss: 0.01642625965178013
step: 740, loss: 0.00640497263520956
step: 750, loss: 0.201985701918602
step: 760, loss: 0.05210508778691292
step: 770, loss: 0.033953916281461716
step: 780, loss: 0.03403644636273384
step: 790, loss: 0.13960058987140656
step: 800, loss: 0.0897580236196518
step: 810, loss: 0.09633254259824753
step: 820, loss: 0.0531017892062664
step: 830, loss: 0.08910021930932999
step: 840, loss: 0.08408215641975403
step: 850, loss: 0.033657580614089966
step: 860, loss: 0.07446693629026413
step: 870, loss: 0.08185175806283951
step: 880, loss: 0.005292588844895363
step: 890, loss: 0.019669873639941216
step: 900, loss: 0.06109689548611641
step: 910, loss: 0.05837589129805565
step: 920, loss: 0.03614560514688492
step: 930, loss: 0.028092408552765846
step: 940, loss: 0.19605766236782074
step: 950, loss: 0.03180915489792824
step: 960, loss: 0.015017461031675339
step: 970, loss: 0.02074234001338482
epoch 3: dev_f1=0.9270588235294117, f1=0.9232209737827715, best_f1=0.9232209737827715
step: 0, loss: 0.023968778550624847
step: 10, loss: 0.06788639724254608
step: 20, loss: 0.09920322149991989
step: 30, loss: 0.17099440097808838
step: 40, loss: 0.09662100672721863
step: 50, loss: 0.08342651277780533
step: 60, loss: 0.029878215864300728
step: 70, loss: 0.03220744803547859
step: 80, loss: 0.08870726823806763
step: 90, loss: 0.12059293687343597
step: 100, loss: 0.016627268865704536
step: 110, loss: 0.021033918485045433
step: 120, loss: 0.06373020261526108
step: 130, loss: 0.2401445508003235
step: 140, loss: 0.026769012212753296
step: 150, loss: 0.06457489728927612
step: 160, loss: 0.06972692161798477
step: 170, loss: 0.07981893420219421
step: 180, loss: 0.15236583352088928
step: 190, loss: 0.035758085548877716
step: 200, loss: 0.09691034257411957
step: 210, loss: 0.01704438030719757
step: 220, loss: 0.10963516682386398
step: 230, loss: 0.09317108243703842
step: 240, loss: 0.07614459842443466
step: 250, loss: 0.15129849314689636
step: 260, loss: 0.0660957619547844
step: 270, loss: 0.090860515832901
step: 280, loss: 0.01336852740496397
step: 290, loss: 0.047851309180259705
step: 300, loss: 0.04122411459684372
step: 310, loss: 0.05378101021051407
step: 320, loss: 0.10612126439809799
step: 330, loss: 0.07212834060192108
step: 340, loss: 0.09458194673061371
step: 350, loss: 0.03781383857131004
step: 360, loss: 0.033637966960668564
step: 370, loss: 0.09484842419624329
step: 380, loss: 0.054646749049425125
step: 390, loss: 0.13100016117095947
step: 400, loss: 0.036739036440849304
step: 410, loss: 0.04134327173233032
step: 420, loss: 0.1424185186624527
step: 430, loss: 0.10706677287817001
step: 440, loss: 0.07744494825601578
step: 450, loss: 0.061818696558475494
step: 460, loss: 0.038675568997859955
step: 470, loss: 0.10390624403953552
step: 480, loss: 0.03815501928329468
step: 490, loss: 0.009586377069354057
step: 500, loss: 0.10859090089797974
step: 510, loss: 0.0376063771545887
step: 520, loss: 0.09450257569551468
step: 530, loss: 0.04237895831465721
step: 540, loss: 0.11813025921583176
step: 550, loss: 0.08917547762393951
step: 560, loss: 0.0998581200838089
step: 570, loss: 0.03359090909361839
step: 580, loss: 0.07193368673324585
step: 590, loss: 0.008612685836851597
step: 600, loss: 0.015550217591226101
step: 610, loss: 0.12817944586277008
step: 620, loss: 0.06390789896249771
step: 630, loss: 0.14060983061790466
step: 640, loss: 0.16898031532764435
step: 650, loss: 0.024050097912549973
step: 660, loss: 0.10855374485254288
step: 670, loss: 0.08734116703271866
step: 680, loss: 0.10279432684183121
step: 690, loss: 0.1427813321352005
step: 700, loss: 0.08121262490749359
step: 710, loss: 0.16460663080215454
step: 720, loss: 0.08627122640609741
step: 730, loss: 0.11014825850725174
step: 740, loss: 0.17775240540504456
step: 750, loss: 0.06040286272764206
step: 760, loss: 0.11094536632299423
step: 770, loss: 0.09523904323577881
step: 780, loss: 0.06444508582353592
step: 790, loss: 0.07688317447900772
step: 800, loss: 0.11378013342618942
step: 810, loss: 0.022483106702566147
step: 820, loss: 0.09753867238759995
step: 830, loss: 0.0891105905175209
step: 840, loss: 0.04152534902095795
step: 850, loss: 0.058424293994903564
step: 860, loss: 0.008518927730619907
step: 870, loss: 0.09050984680652618
step: 880, loss: 0.02442428097128868
step: 890, loss: 0.02883180044591427
step: 900, loss: 0.029505889862775803
step: 910, loss: 0.092703677713871
step: 920, loss: 0.08631667494773865
step: 930, loss: 0.08204803615808487
step: 940, loss: 0.41011378169059753
step: 950, loss: 0.1306297481060028
step: 960, loss: 0.048843663185834885
step: 970, loss: 0.06068074703216553
epoch 4: dev_f1=0.935933147632312, f1=0.9357374017568193, best_f1=0.9357374017568193
step: 0, loss: 0.053245801478624344
step: 10, loss: 0.0842638611793518
step: 20, loss: 0.0648300051689148
step: 30, loss: 0.014890405349433422
step: 40, loss: 0.008667577058076859
step: 50, loss: 0.06678316742181778
step: 60, loss: 0.01665305532515049
step: 70, loss: 0.05999453738331795
step: 80, loss: 0.12004612386226654
step: 90, loss: 0.023945489898324013
step: 100, loss: 0.030023477971553802
step: 110, loss: 0.032712727785110474
step: 120, loss: 0.06530686467885971
step: 130, loss: 0.032005976885557175
step: 140, loss: 0.06857915967702866
step: 150, loss: 0.09315983951091766
step: 160, loss: 0.04464361444115639
step: 170, loss: 0.06954259425401688
step: 180, loss: 0.17857947945594788
step: 190, loss: 0.0007110937149263918
step: 200, loss: 0.14318570494651794
step: 210, loss: 0.06307680159807205
step: 220, loss: 0.028324998915195465
step: 230, loss: 0.08288049697875977
step: 240, loss: 0.006141738500446081
step: 250, loss: 0.07018030434846878
step: 260, loss: 0.043212153017520905
step: 270, loss: 0.14349938929080963
step: 280, loss: 0.07768051326274872
step: 290, loss: 0.06927760690450668
step: 300, loss: 0.02109641768038273
step: 310, loss: 0.13881105184555054
step: 320, loss: 0.1730915755033493
step: 330, loss: 0.03728878125548363
step: 340, loss: 0.12956427037715912
step: 350, loss: 0.040858011692762375
step: 360, loss: 0.20003271102905273
step: 370, loss: 0.0691281259059906
step: 380, loss: 0.029820280149579048
step: 390, loss: 0.10689853131771088
step: 400, loss: 0.03652480989694595
step: 410, loss: 0.08017151057720184
step: 420, loss: 0.029306551441550255
step: 430, loss: 0.054167114198207855
step: 440, loss: 0.1432095766067505
step: 450, loss: 0.007845308631658554
step: 460, loss: 0.03166951239109039
step: 470, loss: 0.17053648829460144
step: 480, loss: 0.038533978164196014
step: 490, loss: 0.12604540586471558
step: 500, loss: 0.06356886774301529
step: 510, loss: 0.06661612540483475
step: 520, loss: 0.07109138369560242
step: 530, loss: 0.030084334313869476
step: 540, loss: 0.06423906981945038
step: 550, loss: 0.09964077174663544
step: 560, loss: 0.02197903022170067
step: 570, loss: 0.10211408138275146
step: 580, loss: 0.0956137627363205
step: 590, loss: 0.030076827853918076
step: 600, loss: 0.10296332836151123
step: 610, loss: 0.06913799792528152
step: 620, loss: 0.19171716272830963
step: 630, loss: 0.0690484568476677
step: 640, loss: 0.009984110482037067
step: 650, loss: 0.014193120412528515
step: 660, loss: 0.08507361263036728
step: 670, loss: 0.02378714643418789
step: 680, loss: 0.0226728655397892
step: 690, loss: 0.05597735941410065
step: 700, loss: 0.14453032612800598
step: 710, loss: 0.15250883996486664
step: 720, loss: 0.0823289081454277
step: 730, loss: 0.12560729682445526
step: 740, loss: 0.07613476365804672
step: 750, loss: 0.1499439924955368
step: 760, loss: 0.029496001079678535
step: 770, loss: 0.020352603867650032
step: 780, loss: 0.08715257793664932
step: 790, loss: 0.046327561140060425
step: 800, loss: 0.11274562031030655
step: 810, loss: 0.11463353037834167
step: 820, loss: 0.09817834943532944
step: 830, loss: 0.096284419298172
step: 840, loss: 0.05331270024180412
step: 850, loss: 0.22089876234531403
step: 860, loss: 0.022737232968211174
step: 870, loss: 0.006287937518209219
step: 880, loss: 0.02019990049302578
step: 890, loss: 0.16637654602527618
step: 900, loss: 0.11176583170890808
step: 910, loss: 0.07147908210754395
step: 920, loss: 0.0864168331027031
step: 930, loss: 0.047903042286634445
step: 940, loss: 0.02259785123169422
step: 950, loss: 0.12216601520776749
step: 960, loss: 0.055729884654283524
step: 970, loss: 0.06334824860095978
epoch 5: dev_f1=0.9245901639344263, f1=0.9195509822263798, best_f1=0.9357374017568193
step: 0, loss: 0.07075383514165878
step: 10, loss: 0.01109861209988594
step: 20, loss: 0.12782159447669983
step: 30, loss: 0.0190696120262146
step: 40, loss: 0.19255810976028442
step: 50, loss: 0.009957071393728256
step: 60, loss: 0.11844155192375183
step: 70, loss: 0.008293036371469498
step: 80, loss: 0.16485142707824707
step: 90, loss: 0.11675142496824265
step: 100, loss: 0.025383375585079193
step: 110, loss: 0.12715500593185425
step: 120, loss: 0.0857161208987236
step: 130, loss: 0.18618863821029663
step: 140, loss: 0.04914616048336029
step: 150, loss: 0.024849100038409233
step: 160, loss: 0.044921569526195526
step: 170, loss: 0.016333671286702156
step: 180, loss: 0.08480439335107803
step: 190, loss: 0.06930488348007202
step: 200, loss: 0.05799958109855652
step: 210, loss: 0.12022025138139725
step: 220, loss: 0.07060298323631287
step: 230, loss: 0.07277939468622208
step: 240, loss: 0.1159294918179512
step: 250, loss: 0.09445272386074066
step: 260, loss: 0.17916886508464813
step: 270, loss: 0.036918755620718
step: 280, loss: 0.0783078521490097
step: 290, loss: 0.022764794528484344
step: 300, loss: 0.018317701295018196
step: 310, loss: 0.1154940277338028
step: 320, loss: 0.044867999851703644
step: 330, loss: 0.07585445791482925
step: 340, loss: 0.015390882268548012
step: 350, loss: 0.025709275156259537
step: 360, loss: 0.028970932587981224
step: 370, loss: 0.012253360822796822
step: 380, loss: 0.14995154738426208
step: 390, loss: 0.1155741885304451
step: 400, loss: 0.06791558116674423
step: 410, loss: 0.01439867727458477
step: 420, loss: 0.09917602688074112
step: 430, loss: 0.059310201555490494
step: 440, loss: 0.08900319039821625
step: 450, loss: 0.009609407745301723
step: 460, loss: 0.032556306570768356
step: 470, loss: 0.20153409242630005
step: 480, loss: 0.034221015870571136
step: 490, loss: 0.1586921662092209
step: 500, loss: 0.06476208567619324
step: 510, loss: 0.06432188302278519
step: 520, loss: 0.07137148827314377
step: 530, loss: 0.11365653574466705
step: 540, loss: 0.030542274937033653
step: 550, loss: 0.004281836096197367
step: 560, loss: 0.09970803558826447
step: 570, loss: 0.13420526683330536
step: 580, loss: 0.012710342183709145
step: 590, loss: 0.1255810558795929
step: 600, loss: 0.01414544228464365
step: 610, loss: 0.009885110892355442
step: 620, loss: 0.09695126861333847
step: 630, loss: 0.013181919232010841
step: 640, loss: 0.12222489714622498
step: 650, loss: 0.12785100936889648
step: 660, loss: 0.06237370893359184
step: 670, loss: 0.05233290418982506
step: 680, loss: 0.07916457206010818
step: 690, loss: 0.010204597376286983
step: 700, loss: 0.08982513844966888
step: 710, loss: 0.019607296213507652
step: 720, loss: 0.12360871583223343
step: 730, loss: 0.007586709689348936
step: 740, loss: 0.046314239501953125
step: 750, loss: 0.12469559907913208
step: 760, loss: 0.1643049716949463
step: 770, loss: 0.06502953916788101
step: 780, loss: 0.018631909042596817
step: 790, loss: 0.021193597465753555
step: 800, loss: 0.08484751731157303
step: 810, loss: 0.1716495305299759
step: 820, loss: 0.10524620860815048
step: 830, loss: 0.09325934201478958
step: 840, loss: 0.016514699906110764
step: 850, loss: 0.01261017844080925
step: 860, loss: 0.04058048874139786
step: 870, loss: 0.07246293872594833
step: 880, loss: 0.15251919627189636
step: 890, loss: 0.023937903344631195
step: 900, loss: 0.013520165346562862
step: 910, loss: 0.03398475795984268
step: 920, loss: 0.09389058500528336
step: 930, loss: 0.010037828236818314
step: 940, loss: 0.09187307953834534
step: 950, loss: 0.09637029469013214
step: 960, loss: 0.04062342643737793
step: 970, loss: 0.025264492258429527
epoch 6: dev_f1=0.9353369763205829, f1=0.9255222524977295, best_f1=0.9357374017568193
step: 0, loss: 0.11696802824735641
step: 10, loss: 0.012265208177268505
step: 20, loss: 0.07230576127767563
step: 30, loss: 0.11959830671548843
step: 40, loss: 0.05730421096086502
step: 50, loss: 0.029613833874464035
step: 60, loss: 0.00014623854076489806
step: 70, loss: 0.06208192929625511
step: 80, loss: 0.08177097141742706
step: 90, loss: 0.08382801711559296
step: 100, loss: 0.07679089903831482
step: 110, loss: 0.017689518630504608
step: 120, loss: 0.17061170935630798
step: 130, loss: 0.04131792485713959
step: 140, loss: 0.07362300157546997
step: 150, loss: 0.03560562804341316
step: 160, loss: 0.008134354837238789
step: 170, loss: 0.17714685201644897
step: 180, loss: 0.027588428929448128
step: 190, loss: 0.007598130498081446
step: 200, loss: 0.01561621855944395
step: 210, loss: 0.015379214659333229
step: 220, loss: 0.07024554163217545
step: 230, loss: 0.09477115422487259
step: 240, loss: 0.033902909606695175
step: 250, loss: 0.0047183288261294365
step: 260, loss: 0.019473720341920853
step: 270, loss: 0.05321797356009483
step: 280, loss: 0.09685054421424866
step: 290, loss: 0.03761884570121765
step: 300, loss: 0.0036234520375728607
step: 310, loss: 0.10028563439846039
step: 320, loss: 0.07486012578010559
step: 330, loss: 0.01479196734726429
step: 340, loss: 0.06061546131968498
step: 350, loss: 0.1005992516875267
step: 360, loss: 0.017729464918375015
step: 370, loss: 0.045502036809921265
step: 380, loss: 0.14005838334560394
step: 390, loss: 0.08053649961948395
step: 400, loss: 0.08977261185646057
step: 410, loss: 0.02007395029067993
step: 420, loss: 0.016884014010429382
step: 430, loss: 0.054599784314632416
step: 440, loss: 0.14675502479076385
step: 450, loss: 0.037300389260053635
step: 460, loss: 0.0833534449338913
step: 470, loss: 0.0287731122225523
step: 480, loss: 0.017444714903831482
step: 490, loss: 0.11580225080251694
step: 500, loss: 0.05915876850485802
step: 510, loss: 0.04262777045369148
step: 520, loss: 0.011817710474133492
step: 530, loss: 0.0542641244828701
step: 540, loss: 0.06857423484325409
step: 550, loss: 0.03517066314816475
step: 560, loss: 0.046042948961257935
step: 570, loss: 0.0570731945335865
step: 580, loss: 0.007379926275461912
step: 590, loss: 0.2144106924533844
step: 600, loss: 0.006121543236076832
step: 610, loss: 0.0038498183712363243
step: 620, loss: 0.08297102898359299
step: 630, loss: 0.183462992310524
step: 640, loss: 0.03117695264518261
step: 650, loss: 0.019360478967428207
step: 660, loss: 0.0033212911803275347
step: 670, loss: 0.11037088185548782
step: 680, loss: 0.10968471318483353
step: 690, loss: 0.020680077373981476
step: 700, loss: 0.07224186509847641
step: 710, loss: 0.08166336268186569
step: 720, loss: 0.09031371027231216
step: 730, loss: 0.012808475643396378
step: 740, loss: 0.014801993034780025
step: 750, loss: 0.03826853260397911
step: 760, loss: 0.019000576809048653
step: 770, loss: 0.1153467446565628
step: 780, loss: 0.026373103260993958
step: 790, loss: 0.02316187508404255
step: 800, loss: 0.0349125899374485
step: 810, loss: 0.08401821553707123
step: 820, loss: 0.13258428871631622
step: 830, loss: 0.020237654447555542
step: 840, loss: 0.07045415788888931
step: 850, loss: 0.04100457578897476
step: 860, loss: 0.06047302484512329
step: 870, loss: 0.0717320516705513
step: 880, loss: 0.06712241470813751
step: 890, loss: 0.013211245648562908
step: 900, loss: 0.10193148255348206
step: 910, loss: 0.09890096634626389
step: 920, loss: 0.02503080852329731
step: 930, loss: 0.03268607705831528
step: 940, loss: 0.16307729482650757
step: 950, loss: 0.23605605959892273
step: 960, loss: 0.06094379350543022
step: 970, loss: 0.03836650773882866
epoch 7: dev_f1=0.9259770114942528, f1=0.9212962962962964, best_f1=0.9357374017568193
step: 0, loss: 0.05941712483763695
step: 10, loss: 0.02574344165623188
step: 20, loss: 0.028167197480797768
step: 30, loss: 0.02354639209806919
step: 40, loss: 0.14893005788326263
step: 50, loss: 0.021576471626758575
step: 60, loss: 0.06255730241537094
step: 70, loss: 0.008377132937312126
step: 80, loss: 0.10757146030664444
step: 90, loss: 0.03806481882929802
step: 100, loss: 0.056773968040943146
step: 110, loss: 0.061422474682331085
step: 120, loss: 0.03401925042271614
step: 130, loss: 0.0104238111525774
step: 140, loss: 0.12089914828538895
step: 150, loss: 0.009952953085303307
step: 160, loss: 0.07008404284715652
step: 170, loss: 0.008796248584985733
step: 180, loss: 0.03441673144698143
step: 190, loss: 0.034933608025312424
step: 200, loss: 0.05527954548597336
step: 210, loss: 0.04478089511394501
step: 220, loss: 0.05704857036471367
step: 230, loss: 0.10505659878253937
step: 240, loss: 0.021268893033266068
step: 250, loss: 0.012802863493561745
step: 260, loss: 0.043122127652168274
step: 270, loss: 0.007768489420413971
step: 280, loss: 0.07199738174676895
step: 290, loss: 0.12415727972984314
step: 300, loss: 0.13485437631607056
step: 310, loss: 0.1821116805076599
step: 320, loss: 0.02193109318614006
step: 330, loss: 0.0787145346403122
step: 340, loss: 0.06310085952281952
step: 350, loss: 0.10188388079404831
step: 360, loss: 0.06927211582660675
step: 370, loss: 0.07011966407299042
step: 380, loss: 0.030640829354524612
step: 390, loss: 0.016751348972320557
step: 400, loss: 0.016548611223697662
step: 410, loss: 0.006124110426753759
step: 420, loss: 5.428197619039565e-05
step: 430, loss: 0.1195468157529831
step: 440, loss: 0.1093037948012352
step: 450, loss: 0.12929442524909973
step: 460, loss: 0.14112305641174316
step: 470, loss: 0.16295796632766724
step: 480, loss: 0.09713774919509888
step: 490, loss: 0.0044437008909881115
step: 500, loss: 0.012458237819373608
step: 510, loss: 0.024233490228652954
step: 520, loss: 0.006575088482350111
step: 530, loss: 0.06178810074925423
step: 540, loss: 0.013579805381596088
step: 550, loss: 0.06960219144821167
step: 560, loss: 0.08849512785673141
step: 570, loss: 0.03223595395684242
step: 580, loss: 0.1028989851474762
step: 590, loss: 0.11777529865503311
step: 600, loss: 0.07204895466566086
step: 610, loss: 0.0542040690779686
step: 620, loss: 0.1263359934091568
step: 630, loss: 0.10098133981227875
step: 640, loss: 0.028091806918382645
step: 650, loss: 0.1438080072402954
step: 660, loss: 0.020830348134040833
step: 670, loss: 0.02653578110039234
step: 680, loss: 0.031341176480054855
step: 690, loss: 0.02775532752275467
step: 700, loss: 0.06633530557155609
step: 710, loss: 0.14319373667240143
step: 720, loss: 0.02300461009144783
step: 730, loss: 0.04400087147951126
step: 740, loss: 0.07047773152589798
step: 750, loss: 0.03835844621062279
step: 760, loss: 0.23147645592689514
step: 770, loss: 0.0707896277308464
step: 780, loss: 0.06949179619550705
step: 790, loss: 0.10580776631832123
step: 800, loss: 0.010745298117399216
step: 810, loss: 0.036658402532339096
step: 820, loss: 0.04913343861699104
step: 830, loss: 0.07187777012586594
step: 840, loss: 0.18239612877368927
step: 850, loss: 0.03373466804623604
step: 860, loss: 0.022006992250680923
step: 870, loss: 0.1620120406150818
step: 880, loss: 0.1764947772026062
step: 890, loss: 0.03304474800825119
step: 900, loss: 0.1820635199546814
step: 910, loss: 0.013279159553349018
step: 920, loss: 0.08503083139657974
step: 930, loss: 0.140969380736351
step: 940, loss: 0.06707864254713058
step: 950, loss: 0.017375610768795013
step: 960, loss: 0.04249093309044838
step: 970, loss: 0.009451091289520264
epoch 8: dev_f1=0.9363261566651397, f1=0.9308924485125859, best_f1=0.9308924485125859
step: 0, loss: 0.03482256829738617
step: 10, loss: 0.09453171491622925
step: 20, loss: 0.014345386996865273
step: 30, loss: 0.026750564575195312
step: 40, loss: 0.12700587511062622
step: 50, loss: 0.010648328810930252
step: 60, loss: 0.06128617003560066
step: 70, loss: 0.030779637396335602
step: 80, loss: 0.12542381882667542
step: 90, loss: 0.0004988944274373353
step: 100, loss: 0.07767302542924881
step: 110, loss: 0.009513000957667828
step: 120, loss: 0.06572318822145462
step: 130, loss: 0.023434313014149666
step: 140, loss: 0.07078912854194641
step: 150, loss: 0.0018593582790344954
step: 160, loss: 0.021188246086239815
step: 170, loss: 0.07205511629581451
step: 180, loss: 0.07035797834396362
step: 190, loss: 0.06444517523050308
step: 200, loss: 0.0717475414276123
step: 210, loss: 2.299564403074328e-05
step: 220, loss: 0.023433875292539597
step: 230, loss: 0.07938018441200256
step: 240, loss: 0.21690304577350616
step: 250, loss: 0.06007325276732445
step: 260, loss: 0.060372840613126755
step: 270, loss: 0.07676850259304047
step: 280, loss: 0.061025772243738174
step: 290, loss: 0.07695724815130234
step: 300, loss: 0.04230828583240509
step: 310, loss: 0.06169771030545235
step: 320, loss: 0.019625594839453697
step: 330, loss: 0.03470887616276741
step: 340, loss: 0.01801377721130848
step: 350, loss: 0.11682116985321045
step: 360, loss: 0.005402515642344952
step: 370, loss: 0.006954259239137173
step: 380, loss: 0.0377926379442215
step: 390, loss: 0.04911093786358833
step: 400, loss: 0.016766199842095375
step: 410, loss: 0.07120101898908615
step: 420, loss: 0.06664302945137024
step: 430, loss: 0.053634077310562134
step: 440, loss: 0.051694106310606
step: 450, loss: 0.023634113371372223
step: 460, loss: 0.010668016970157623
step: 470, loss: 0.1470586359500885
step: 480, loss: 0.22649286687374115
step: 490, loss: 0.06906598061323166
step: 500, loss: 0.1612599641084671
step: 510, loss: 0.05621883273124695
step: 520, loss: 0.039159584790468216
step: 530, loss: 0.06686548888683319
step: 540, loss: 0.06733545660972595
step: 550, loss: 0.04102964326739311
step: 560, loss: 0.002477816538885236
step: 570, loss: 0.10069102793931961
step: 580, loss: 0.19869902729988098
step: 590, loss: 0.09786950796842575
step: 600, loss: 0.11200928688049316
step: 610, loss: 0.013389579020440578
step: 620, loss: 0.07040994614362717
step: 630, loss: 0.17026105523109436
step: 640, loss: 0.08417823910713196
step: 650, loss: 0.08435959368944168
step: 660, loss: 0.057034555822610855
step: 670, loss: 0.027323786169290543
step: 680, loss: 0.03965163975954056
step: 690, loss: 0.12292380630970001
step: 700, loss: 0.053585443645715714
step: 710, loss: 0.02094573713839054
step: 720, loss: 0.09398628026247025
step: 730, loss: 0.07042811065912247
step: 740, loss: 0.014745214022696018
step: 750, loss: 0.004285488277673721
step: 760, loss: 0.058073051273822784
step: 770, loss: 0.010066068731248379
step: 780, loss: 0.06343511492013931
step: 790, loss: 0.03591344133019447
step: 800, loss: 0.15934951603412628
step: 810, loss: 0.12803581357002258
step: 820, loss: 0.031107045710086823
step: 830, loss: 0.006238756235688925
step: 840, loss: 0.11689808964729309
step: 850, loss: 0.1437664031982422
step: 860, loss: 0.08383236080408096
step: 870, loss: 0.10579035431146622
step: 880, loss: 0.08657971024513245
step: 890, loss: 0.09592593461275101
step: 900, loss: 0.05370279774069786
step: 910, loss: 0.07932637631893158
step: 920, loss: 0.08219233900308609
step: 930, loss: 0.07557133585214615
step: 940, loss: 0.08269386738538742
step: 950, loss: 0.02211875654757023
step: 960, loss: 0.05763588100671768
step: 970, loss: 0.007954676635563374
epoch 9: dev_f1=0.9383177570093458, f1=0.9343269678621332, best_f1=0.9343269678621332
step: 0, loss: 0.05858123302459717
step: 10, loss: 0.020512312650680542
step: 20, loss: 0.020994359627366066
step: 30, loss: 0.16801559925079346
step: 40, loss: 0.08039616793394089
step: 50, loss: 0.00794815644621849
step: 60, loss: 0.027178527787327766
step: 70, loss: 0.03590916469693184
step: 80, loss: 0.009137698449194431
step: 90, loss: 0.059164389967918396
step: 100, loss: 0.029202010482549667
step: 110, loss: 0.03519071638584137
step: 120, loss: 0.0024364686105400324
step: 130, loss: 0.06321132183074951
step: 140, loss: 0.003032092237845063
step: 150, loss: 0.014282841235399246
step: 160, loss: 0.021129639819264412
step: 170, loss: 0.1036471351981163
step: 180, loss: 0.1303657591342926
step: 190, loss: 0.09153436869382858
step: 200, loss: 0.11500271409749985
step: 210, loss: 0.087403304874897
step: 220, loss: 0.05880024656653404
step: 230, loss: 0.03183281421661377
step: 240, loss: 0.03260296955704689
step: 250, loss: 0.043442461639642715
step: 260, loss: 0.004856187850236893
step: 270, loss: 0.07119385898113251
step: 280, loss: 0.026825906708836555
step: 290, loss: 0.2741408944129944
step: 300, loss: 0.14525488018989563
step: 310, loss: 0.027515534311532974
step: 320, loss: 0.021365951746702194
step: 330, loss: 0.018272612243890762
step: 340, loss: 0.041899267584085464
step: 350, loss: 0.014082794077694416
step: 360, loss: 0.07065410912036896
step: 370, loss: 0.039010703563690186
step: 380, loss: 0.040134962648153305
step: 390, loss: 0.03479103371500969
step: 400, loss: 0.14477089047431946
step: 410, loss: 0.012952816672623158
step: 420, loss: 0.04975760355591774
step: 430, loss: 0.04889626055955887
step: 440, loss: 0.028194552287459373
step: 450, loss: 0.16940437257289886
step: 460, loss: 0.04971974715590477
step: 470, loss: 0.0009199242340400815
step: 480, loss: 0.015247725881636143
step: 490, loss: 0.05046572536230087
step: 500, loss: 0.011732921935617924
step: 510, loss: 0.000827742216642946
step: 520, loss: 0.07908625900745392
step: 530, loss: 0.006025537382811308
step: 540, loss: 0.017522547394037247
step: 550, loss: 0.006681173108518124
step: 560, loss: 0.18670746684074402
step: 570, loss: 0.05854112282395363
step: 580, loss: 0.0999605655670166
step: 590, loss: 0.06851421296596527
step: 600, loss: 0.08070071786642075
step: 610, loss: 0.04525567591190338
step: 620, loss: 0.07395192980766296
step: 630, loss: 0.08948533236980438
step: 640, loss: 0.06962674111127853
step: 650, loss: 0.06816684454679489
step: 660, loss: 0.004138519987463951
step: 670, loss: 0.04880379140377045
step: 680, loss: 0.057898811995983124
step: 690, loss: 0.10620538145303726
step: 700, loss: 0.04597988724708557
step: 710, loss: 0.11093750596046448
step: 720, loss: 0.01715160347521305
step: 730, loss: 0.028176743537187576
step: 740, loss: 0.13636183738708496
step: 750, loss: 0.003380351234227419
step: 760, loss: 0.14391835033893585
step: 770, loss: 0.045447058975696564
step: 780, loss: 0.018690846860408783
step: 790, loss: 0.03230529651045799
step: 800, loss: 0.05676017701625824
step: 810, loss: 0.020550783723592758
step: 820, loss: 0.05262290686368942
step: 830, loss: 0.07463424652814865
step: 840, loss: 0.04193194955587387
step: 850, loss: 0.02828028053045273
step: 860, loss: 0.008369903080165386
step: 870, loss: 0.005541510879993439
step: 880, loss: 0.13957533240318298
step: 890, loss: 0.11578652262687683
step: 900, loss: 0.10133294016122818
step: 910, loss: 0.012869885191321373
step: 920, loss: 0.007390134036540985
step: 930, loss: 0.10496819019317627
step: 940, loss: 0.012543930672109127
step: 950, loss: 0.0009742018301039934
step: 960, loss: 0.040765129029750824
step: 970, loss: 0.006609376985579729
epoch 10: dev_f1=0.9386248269497001, f1=0.9367205542725173, best_f1=0.9367205542725173
step: 0, loss: 0.007321328856050968
step: 10, loss: 0.06978846341371536
step: 20, loss: 0.057481393218040466
step: 30, loss: 0.09576601535081863
step: 40, loss: 0.007614834699779749
step: 50, loss: 0.001753760501742363
step: 60, loss: 0.004839680157601833
step: 70, loss: 0.030414476990699768
step: 80, loss: 0.014255108311772346
step: 90, loss: 0.019566280767321587
step: 100, loss: 0.037448421120643616
step: 110, loss: 0.007283930666744709
step: 120, loss: 0.0686069056391716
step: 130, loss: 0.016361484304070473
step: 140, loss: 0.007763462141156197
step: 150, loss: 0.006618807092308998
step: 160, loss: 0.16982872784137726
step: 170, loss: 0.012395095080137253
step: 180, loss: 0.036041006445884705
step: 190, loss: 0.1227419525384903
step: 200, loss: 0.022799355909228325
step: 210, loss: 0.002718566218391061
step: 220, loss: 0.09142403304576874
step: 230, loss: 0.00042458955431357026
step: 240, loss: 0.04529443010687828
step: 250, loss: 0.056901197880506516
step: 260, loss: 0.04599742963910103
step: 270, loss: 0.14112721383571625
step: 280, loss: 0.01418972946703434
step: 290, loss: 0.05576537176966667
step: 300, loss: 0.09287577867507935
step: 310, loss: 0.057449258863925934
step: 320, loss: 0.025083627551794052
step: 330, loss: 0.002474052831530571
step: 340, loss: 0.12185831367969513
step: 350, loss: 0.019981302320957184
step: 360, loss: 0.06776327639818192
step: 370, loss: 0.0952894538640976
step: 380, loss: 0.005195194855332375
step: 390, loss: 0.0451216846704483
step: 400, loss: 0.03170010820031166
step: 410, loss: 0.04095109552145004
step: 420, loss: 0.14682899415493011
step: 430, loss: 0.020570935681462288
step: 440, loss: 0.031062627211213112
step: 450, loss: 0.16810429096221924
step: 460, loss: 0.02211218699812889
step: 470, loss: 0.014622156508266926
step: 480, loss: 0.03179009258747101
step: 490, loss: 0.10634578764438629
step: 500, loss: 0.019320618361234665
step: 510, loss: 0.0039893826469779015
step: 520, loss: 0.13462361693382263
step: 530, loss: 0.15946775674819946
step: 540, loss: 0.04257960990071297
step: 550, loss: 0.08890590071678162
step: 560, loss: 0.014167300425469875
step: 570, loss: 0.01681305095553398
step: 580, loss: 0.09211131930351257
step: 590, loss: 0.04380594938993454
step: 600, loss: 0.02688235230743885
step: 610, loss: 0.014417480677366257
step: 620, loss: 0.29690220952033997
step: 630, loss: 0.10806577652692795
step: 640, loss: 0.0176895372569561
step: 650, loss: 0.2736690044403076
step: 660, loss: 0.01906239055097103
step: 670, loss: 0.16648074984550476
step: 680, loss: 0.07979457080364227
step: 690, loss: 0.019884107634425163
step: 700, loss: 0.02306339517235756
step: 710, loss: 0.01715729758143425
step: 720, loss: 0.012655804865062237
step: 730, loss: 0.001241675578057766
step: 740, loss: 0.006792072672396898
step: 750, loss: 0.004044623114168644
step: 760, loss: 0.025706570595502853
step: 770, loss: 0.0006212281878106296
step: 780, loss: 0.10530675947666168
step: 790, loss: 0.05786581337451935
step: 800, loss: 0.008202035911381245
step: 810, loss: 0.1035149097442627
step: 820, loss: 0.03973228856921196
step: 830, loss: 0.03363601118326187
step: 840, loss: 0.1857173591852188
step: 850, loss: 0.022503092885017395
step: 860, loss: 0.07752952724695206
step: 870, loss: 0.03854409605264664
step: 880, loss: 0.02180827222764492
step: 890, loss: 0.004808200057595968
step: 900, loss: 0.001727716764435172
step: 910, loss: 0.009377430193126202
step: 920, loss: 0.027910633012652397
step: 930, loss: 0.026949573308229446
step: 940, loss: 0.024309128522872925
step: 950, loss: 0.03940673545002937
step: 960, loss: 0.02740439772605896
step: 970, loss: 0.025837643072009087
epoch 11: dev_f1=0.9424326833797586, f1=0.9293023255813954, best_f1=0.9293023255813954
step: 0, loss: 0.029132889583706856
step: 10, loss: 0.011144923977553844
step: 20, loss: 0.07728099822998047
step: 30, loss: 0.0718524381518364
step: 40, loss: 0.09349379688501358
step: 50, loss: 0.023096542805433273
step: 60, loss: 0.04413340240716934
step: 70, loss: 0.004712321329861879
step: 80, loss: 0.0013495348393917084
step: 90, loss: 0.011325612664222717
step: 100, loss: 0.000374184746760875
step: 110, loss: 0.01396566815674305
step: 120, loss: 0.009425299242138863
step: 130, loss: 0.04906880483031273
step: 140, loss: 0.03118807077407837
step: 150, loss: 0.00034051990951411426
step: 160, loss: 0.12891627848148346
step: 170, loss: 1.5210173842206132e-05
step: 180, loss: 0.027937736362218857
step: 190, loss: 0.12811101973056793
step: 200, loss: 0.033173058182001114
step: 210, loss: 0.06698635965585709
step: 220, loss: 0.008758616633713245
step: 230, loss: 0.013706430792808533
step: 240, loss: 0.004597879014909267
step: 250, loss: 0.031808167695999146
step: 260, loss: 0.03143259882926941
step: 270, loss: 0.011341173201799393
step: 280, loss: 0.0076802377589046955
step: 290, loss: 0.0016667793970555067
step: 300, loss: 0.07235968858003616
step: 310, loss: 0.03457461670041084
step: 320, loss: 0.023036837577819824
step: 330, loss: 0.007797506172209978
step: 340, loss: 0.06862145662307739
step: 350, loss: 0.08875030279159546
step: 360, loss: 0.02947818487882614
step: 370, loss: 0.00012379609688650817
step: 380, loss: 0.03391016274690628
step: 390, loss: 0.04162779822945595
step: 400, loss: 1.2207688996568322e-05
step: 410, loss: 0.05209681764245033
step: 420, loss: 0.0872240737080574
step: 430, loss: 0.004494392313063145
step: 440, loss: 0.10866246372461319
step: 450, loss: 0.05414927378296852
step: 460, loss: 0.0008860129164531827
step: 470, loss: 0.08331957459449768
step: 480, loss: 1.460663497709902e-05
step: 490, loss: 0.025918874889612198
step: 500, loss: 0.1806844174861908
step: 510, loss: 0.005434961058199406
step: 520, loss: 0.005102368071675301
step: 530, loss: 0.014129453338682652
step: 540, loss: 0.0646076500415802
step: 550, loss: 0.014851344749331474
step: 560, loss: 0.013633913360536098
step: 570, loss: 0.010576575994491577
step: 580, loss: 0.05577785521745682
step: 590, loss: 0.0817795991897583
step: 600, loss: 0.05693116784095764
step: 610, loss: 0.035368312150239944
step: 620, loss: 0.10437488555908203
step: 630, loss: 0.14935417473316193
step: 640, loss: 0.13599702715873718
step: 650, loss: 0.03292699530720711
step: 660, loss: 0.054734136909246445
step: 670, loss: 0.05578829348087311
step: 680, loss: 0.017869723960757256
step: 690, loss: 0.022229386493563652
step: 700, loss: 0.01892165094614029
step: 710, loss: 0.04835719242691994
step: 720, loss: 0.09075172245502472
step: 730, loss: 0.12605063617229462
step: 740, loss: 0.07656288146972656
step: 750, loss: 0.05768711492419243
step: 760, loss: 0.05237899348139763
step: 770, loss: 0.03555553779006004
step: 780, loss: 0.002533102408051491
step: 790, loss: 0.10184472799301147
step: 800, loss: 0.11435940861701965
step: 810, loss: 0.03390803560614586
step: 820, loss: 0.06495475769042969
step: 830, loss: 0.046800125390291214
step: 840, loss: 0.07858016341924667
step: 850, loss: 0.08553911000490189
step: 860, loss: 0.00023284592316485941
step: 870, loss: 0.03550722077488899
step: 880, loss: 0.013439618982374668
step: 890, loss: 0.048440493643283844
step: 900, loss: 0.0029258313588798046
step: 910, loss: 0.0606643371284008
step: 920, loss: 0.10234180092811584
step: 930, loss: 0.04137318953871727
step: 940, loss: 0.09357340633869171
step: 950, loss: 0.04039677605032921
step: 960, loss: 0.17169472575187683
step: 970, loss: 0.0796280950307846
epoch 12: dev_f1=0.9364269141531322, f1=0.9285714285714285, best_f1=0.9293023255813954
step: 0, loss: 0.025374162942171097
step: 10, loss: 0.028482908383011818
step: 20, loss: 0.03190265968441963
step: 30, loss: 0.01633664220571518
step: 40, loss: 0.00471699982881546
step: 50, loss: 0.036733001470565796
step: 60, loss: 0.056751854717731476
step: 70, loss: 0.09155397117137909
step: 80, loss: 0.08049371838569641
step: 90, loss: 0.04244470223784447
step: 100, loss: 0.005294374190270901
step: 110, loss: 0.09893226623535156
step: 120, loss: 0.04925673082470894
step: 130, loss: 0.004475184716284275
step: 140, loss: 0.027588285505771637
step: 150, loss: 0.09434876590967178
step: 160, loss: 0.07714813947677612
step: 170, loss: 0.08539488911628723
step: 180, loss: 0.0018310063751414418
step: 190, loss: 0.009813588112592697
step: 200, loss: 2.9076769351377152e-05
step: 210, loss: 0.058359965682029724
step: 220, loss: 0.06357172131538391
step: 230, loss: 0.0020417331252247095
step: 240, loss: 0.017471112310886383
step: 250, loss: 0.09495750069618225
step: 260, loss: 0.007351728156208992
step: 270, loss: 0.010799637995660305
step: 280, loss: 0.051283545792102814
step: 290, loss: 0.014088373631238937
step: 300, loss: 0.18269720673561096
step: 310, loss: 1.4953105164750014e-05
step: 320, loss: 0.04868321493268013
step: 330, loss: 0.04555725306272507
step: 340, loss: 0.032928068190813065
step: 350, loss: 0.06690633296966553
step: 360, loss: 0.060182347893714905
step: 370, loss: 0.016485508531332016
step: 380, loss: 0.04075608775019646
step: 390, loss: 0.031194766983389854
step: 400, loss: 0.04781500995159149
step: 410, loss: 0.000398872303776443
step: 420, loss: 0.0022202366963028908
step: 430, loss: 0.009533754549920559
step: 440, loss: 0.10294099897146225
step: 450, loss: 0.03926416113972664
step: 460, loss: 0.025949012488126755
step: 470, loss: 0.04884061962366104
step: 480, loss: 0.03906626999378204
step: 490, loss: 0.10298613458871841
step: 500, loss: 0.07701922208070755
step: 510, loss: 0.021207869052886963
step: 520, loss: 0.087419293820858
step: 530, loss: 0.014824997633695602
step: 540, loss: 1.9277649698778987e-05
step: 550, loss: 0.09481380134820938
step: 560, loss: 0.00019371973758097738
step: 570, loss: 0.19034022092819214
step: 580, loss: 0.03221544250845909
step: 590, loss: 0.02493251860141754
step: 600, loss: 0.012635534629225731
step: 610, loss: 0.02041509747505188
step: 620, loss: 0.0319724977016449
step: 630, loss: 0.04101623594760895
step: 640, loss: 0.0008465474238619208
step: 650, loss: 0.10575320571660995
step: 660, loss: 0.05813511088490486
step: 670, loss: 0.006974551826715469
step: 680, loss: 0.066156767308712
step: 690, loss: 0.09216228872537613
step: 700, loss: 0.044978637248277664
step: 710, loss: 0.07105850428342819
step: 720, loss: 0.062100574374198914
step: 730, loss: 0.0437125526368618
step: 740, loss: 0.0001518546778243035
step: 750, loss: 0.056592587381601334
step: 760, loss: 0.0416940376162529
step: 770, loss: 0.020633086562156677
step: 780, loss: 0.018669284880161285
step: 790, loss: 0.03478575125336647
step: 800, loss: 0.0072175730019807816
step: 810, loss: 0.004447685554623604
step: 820, loss: 0.0974438264966011
step: 830, loss: 0.06146126240491867
step: 840, loss: 0.09739605337381363
step: 850, loss: 0.0016350626247003675
step: 860, loss: 0.001215954078361392
step: 870, loss: 0.04255043342709541
step: 880, loss: 0.1121385395526886
step: 890, loss: 0.03186042234301567
step: 900, loss: 0.0326627641916275
step: 910, loss: 0.07208468019962311
step: 920, loss: 0.10406529158353806
step: 930, loss: 0.017586475238204002
step: 940, loss: 0.008483529090881348
step: 950, loss: 0.22280007600784302
step: 960, loss: 0.04488128423690796
step: 970, loss: 0.03929069638252258
epoch 13: dev_f1=0.9358386801099908, f1=0.927816091954023, best_f1=0.9293023255813954
step: 0, loss: 0.09117147326469421
step: 10, loss: 0.035198092460632324
step: 20, loss: 0.02690390683710575
step: 30, loss: 0.029574789106845856
step: 40, loss: 0.09393858164548874
step: 50, loss: 0.0487261563539505
step: 60, loss: 0.05687832459807396
step: 70, loss: 0.08198868483304977
step: 80, loss: 0.18154321610927582
step: 90, loss: 0.04308415576815605
step: 100, loss: 0.020780233666300774
step: 110, loss: 0.05501725152134895
step: 120, loss: 0.09916327893733978
step: 130, loss: 0.023192312568426132
step: 140, loss: 0.011331459507346153
step: 150, loss: 0.036472681909799576
step: 160, loss: 0.0006556092412211001
step: 170, loss: 0.0705377385020256
step: 180, loss: 0.00010894036677200347
step: 190, loss: 0.024309279397130013
step: 200, loss: 3.297932926216163e-05
step: 210, loss: 0.04881393909454346
step: 220, loss: 0.02336590364575386
step: 230, loss: 0.022778859362006187
step: 240, loss: 0.04052334278821945
step: 250, loss: 0.12582086026668549
step: 260, loss: 0.03775840625166893
step: 270, loss: 0.009858142584562302
step: 280, loss: 0.04384670779109001
step: 290, loss: 0.01857849396765232
step: 300, loss: 0.03460255265235901
step: 310, loss: 0.0027054077945649624
step: 320, loss: 0.008440074510872364
step: 330, loss: 0.04030974581837654
step: 340, loss: 0.03008338063955307
step: 350, loss: 0.0037400841247290373
step: 360, loss: 0.010926119051873684
step: 370, loss: 0.00033132347743958235
step: 380, loss: 0.024138817563652992
step: 390, loss: 0.039596736431121826
step: 400, loss: 0.017751654610037804
step: 410, loss: 0.003037700429558754
step: 420, loss: 0.053640808910131454
step: 430, loss: 0.00201612152159214
step: 440, loss: 0.018037118017673492
step: 450, loss: 0.024029294028878212
step: 460, loss: 0.03322114422917366
step: 470, loss: 0.019649242982268333
step: 480, loss: 0.17323347926139832
step: 490, loss: 0.03583918511867523
step: 500, loss: 0.09120286256074905
step: 510, loss: 0.03211634233593941
step: 520, loss: 9.436105756321922e-06
step: 530, loss: 0.058420706540346146
step: 540, loss: 0.04254677891731262
step: 550, loss: 0.10366993397474289
step: 560, loss: 0.002250572433695197
step: 570, loss: 0.00020715799473691732
step: 580, loss: 0.1456938534975052
step: 590, loss: 0.0888482928276062
step: 600, loss: 0.07660908997058868
step: 610, loss: 0.03851461783051491
step: 620, loss: 0.02152489311993122
step: 630, loss: 0.0073539637960493565
step: 640, loss: 0.055310122668743134
step: 650, loss: 0.0041709402576088905
step: 660, loss: 0.22830821573734283
step: 670, loss: 0.03769858554005623
step: 680, loss: 0.04007437452673912
step: 690, loss: 0.007258037570863962
step: 700, loss: 0.04839568957686424
step: 710, loss: 0.00020370809943415225
step: 720, loss: 0.03054179809987545
step: 730, loss: 5.60085718461778e-05
step: 740, loss: 0.018751762807369232
step: 750, loss: 0.03586958348751068
step: 760, loss: 0.019349269568920135
step: 770, loss: 0.019769491627812386
step: 780, loss: 0.015003866516053677
step: 790, loss: 0.0009339887765236199
step: 800, loss: 0.0027102960739284754
step: 810, loss: 0.014668092131614685
step: 820, loss: 0.010205773636698723
step: 830, loss: 0.020563021302223206
step: 840, loss: 0.015719356015324593
step: 850, loss: 0.07994215935468674
step: 860, loss: 0.04019869491457939
step: 870, loss: 0.10921350121498108
step: 880, loss: 0.0370127409696579
step: 890, loss: 0.07782477140426636
step: 900, loss: 8.074133802438155e-05
step: 910, loss: 0.02029317431151867
step: 920, loss: 0.01627223566174507
step: 930, loss: 0.06479788571596146
step: 940, loss: 0.004918782971799374
step: 950, loss: 0.0019088219851255417
step: 960, loss: 0.0051297396421432495
step: 970, loss: 0.19259263575077057
epoch 14: dev_f1=0.9324074074074072, f1=0.9258572752548655, best_f1=0.9293023255813954
step: 0, loss: 0.0008747250540181994
step: 10, loss: 0.03317266330122948
step: 20, loss: 0.03987633064389229
step: 30, loss: 0.03017827682197094
step: 40, loss: 0.024632733315229416
step: 50, loss: 0.009557824581861496
step: 60, loss: 0.024951796978712082
step: 70, loss: 0.00048718173638917506
step: 80, loss: 0.06548929959535599
step: 90, loss: 0.009981938637793064
step: 100, loss: 0.07923974096775055
step: 110, loss: 0.05864065885543823
step: 120, loss: 0.05081149935722351
step: 130, loss: 0.023197634145617485
step: 140, loss: 0.00020755281730089337
step: 150, loss: 0.0017215900588780642
step: 160, loss: 0.07942785322666168
step: 170, loss: 0.02881866693496704
step: 180, loss: 0.05149766802787781
step: 190, loss: 0.0034990222193300724
step: 200, loss: 0.075081966817379
step: 210, loss: 0.021608510985970497
step: 220, loss: 0.000981554971076548
step: 230, loss: 0.08376314491033554
step: 240, loss: 0.026529455557465553
step: 250, loss: 0.06008248031139374
step: 260, loss: 0.011115922592580318
step: 270, loss: 0.0007280557183548808
step: 280, loss: 0.03309471160173416
step: 290, loss: 0.055029869079589844
step: 300, loss: 0.09397850930690765
step: 310, loss: 0.004934752359986305
step: 320, loss: 0.019484559074044228
step: 330, loss: 0.0293164923787117
step: 340, loss: 0.007318777963519096
step: 350, loss: 0.060506194829940796
step: 360, loss: 0.0905982032418251
step: 370, loss: 0.04622604697942734
step: 380, loss: 0.02306417003273964
step: 390, loss: 0.0427049919962883
step: 400, loss: 5.617006536340341e-05
step: 410, loss: 0.08792384713888168
step: 420, loss: 0.03272445499897003
step: 430, loss: 0.014983895234763622
step: 440, loss: 0.0014326932141557336
step: 450, loss: 0.012349625118076801
step: 460, loss: 0.000701821583788842
step: 470, loss: 0.0004960569785907865
step: 480, loss: 0.05325630307197571
step: 490, loss: 0.06482362002134323
step: 500, loss: 0.05751257762312889
step: 510, loss: 0.11294885724782944
step: 520, loss: 0.015064932405948639
step: 530, loss: 8.182566671166569e-05
step: 540, loss: 0.030191652476787567
step: 550, loss: 0.054931387305259705
step: 560, loss: 0.015540491789579391
step: 570, loss: 0.07187417149543762
step: 580, loss: 0.038775280117988586
step: 590, loss: 0.009366147220134735
step: 600, loss: 0.05490560084581375
step: 610, loss: 0.12165165692567825
step: 620, loss: 0.036180898547172546
step: 630, loss: 0.08254949003458023
step: 640, loss: 0.00023606416652910411
step: 650, loss: 0.05953711271286011
step: 660, loss: 0.020234646275639534
step: 670, loss: 0.06225228309631348
step: 680, loss: 1.2550346582429484e-05
step: 690, loss: 0.014436940662562847
step: 700, loss: 0.0459931343793869
step: 710, loss: 0.050767265260219574
step: 720, loss: 0.0036167739890515804
step: 730, loss: 0.01828465424478054
step: 740, loss: 0.07552044093608856
step: 750, loss: 0.04397336393594742
step: 760, loss: 0.05862308666110039
step: 770, loss: 3.0759219953324646e-05
step: 780, loss: 0.04175223037600517
step: 790, loss: 0.0005222592735663056
step: 800, loss: 0.027283448725938797
step: 810, loss: 0.025812417268753052
step: 820, loss: 0.0632382333278656
step: 830, loss: 2.6595607778290287e-05
step: 840, loss: 0.019136911258101463
step: 850, loss: 0.018463298678398132
step: 860, loss: 0.02643265761435032
step: 870, loss: 0.05391297861933708
step: 880, loss: 0.027225762605667114
step: 890, loss: 0.048404235392808914
step: 900, loss: 0.004589461255818605
step: 910, loss: 0.04122672230005264
step: 920, loss: 0.02370312623679638
step: 930, loss: 0.00016882760974112898
step: 940, loss: 0.019456055015325546
step: 950, loss: 0.04660843685269356
step: 960, loss: 0.018236322328448296
step: 970, loss: 0.06032905727624893
epoch 15: dev_f1=0.9313543599257884, f1=0.9235048678720444, best_f1=0.9293023255813954
step: 0, loss: 0.02348574623465538
step: 10, loss: 0.0418892428278923
step: 20, loss: 0.041771188378334045
step: 30, loss: 0.06455109268426895
step: 40, loss: 0.011635178700089455
step: 50, loss: 0.02216588519513607
step: 60, loss: 0.03372278809547424
step: 70, loss: 0.0005666663637384772
step: 80, loss: 0.03578810766339302
step: 90, loss: 0.00613672100007534
step: 100, loss: 0.02530803345143795
step: 110, loss: 0.07833784818649292
step: 120, loss: 0.04246986284852028
step: 130, loss: 0.002359726931899786
step: 140, loss: 0.07182182371616364
step: 150, loss: 0.10376174747943878
step: 160, loss: 0.025571702048182487
step: 170, loss: 0.04464171826839447
step: 180, loss: 0.021892312914133072
step: 190, loss: 0.1055913195014
step: 200, loss: 0.00697947945445776
step: 210, loss: 0.04460194706916809
step: 220, loss: 0.024081457406282425
step: 230, loss: 0.019339686259627342
step: 240, loss: 0.052744388580322266
step: 250, loss: 0.06870163977146149
step: 260, loss: 0.00041237397817894816
step: 270, loss: 4.476261528907344e-05
step: 280, loss: 2.8221063985256478e-05
step: 290, loss: 0.028943484649062157
step: 300, loss: 0.029212458059191704
step: 310, loss: 0.0003089380625169724
step: 320, loss: 0.05075276270508766
step: 330, loss: 0.02773093245923519
step: 340, loss: 0.04826296865940094
step: 350, loss: 0.057751089334487915
step: 360, loss: 0.05077249929308891
step: 370, loss: 0.1253930926322937
step: 380, loss: 0.011114425025880337
step: 390, loss: 0.00026173426886089146
step: 400, loss: 0.04283399134874344
step: 410, loss: 0.07698027789592743
step: 420, loss: 0.0006395284435711801
step: 430, loss: 0.03209759667515755
step: 440, loss: 6.234528700588271e-05
step: 450, loss: 0.026439037173986435
step: 460, loss: 0.047396279871463776
step: 470, loss: 7.72249677538639e-06
step: 480, loss: 0.025944920256733894
step: 490, loss: 0.017371201887726784
step: 500, loss: 0.000256844621617347
step: 510, loss: 0.03744640201330185
step: 520, loss: 0.02173564024269581
step: 530, loss: 0.10557258874177933
step: 540, loss: 0.020000558346509933
step: 550, loss: 0.041568007320165634
step: 560, loss: 0.06633367389440536
step: 570, loss: 0.00021195891895331442
step: 580, loss: 0.01700318604707718
step: 590, loss: 0.09632080048322678
step: 600, loss: 0.03821593150496483
step: 610, loss: 0.05970392003655434
step: 620, loss: 0.02593587338924408
step: 630, loss: 0.019743364304304123
step: 640, loss: 0.020369306206703186
step: 650, loss: 0.1293114423751831
step: 660, loss: 0.021371908485889435
step: 670, loss: 0.036901477724313736
step: 680, loss: 0.022096727043390274
step: 690, loss: 0.05563226342201233
step: 700, loss: 0.003800636623054743
step: 710, loss: 0.010843532159924507
step: 720, loss: 0.019174501299858093
step: 730, loss: 0.029759492725133896
step: 740, loss: 0.05875122919678688
step: 750, loss: 0.0228740144520998
step: 760, loss: 0.02867959812283516
step: 770, loss: 0.006992598529905081
step: 780, loss: 0.019285839051008224
step: 790, loss: 0.036868028342723846
step: 800, loss: 0.07547233253717422
step: 810, loss: 0.03479595109820366
step: 820, loss: 0.11679707467556
step: 830, loss: 0.022737130522727966
step: 840, loss: 0.05739627778530121
step: 850, loss: 0.04251642897725105
step: 860, loss: 0.0001893405569717288
step: 870, loss: 0.01598958857357502
step: 880, loss: 0.05818498879671097
step: 890, loss: 0.00041177807725034654
step: 900, loss: 9.01977764442563e-05
step: 910, loss: 0.034991152584552765
step: 920, loss: 0.06059243157505989
step: 930, loss: 0.02812788262963295
step: 940, loss: 0.0004173008492216468
step: 950, loss: 0.00564645417034626
step: 960, loss: 0.022329647094011307
step: 970, loss: 0.07309515029191971
epoch 16: dev_f1=0.935064935064935, f1=0.9280742459396751, best_f1=0.9293023255813954
step: 0, loss: 0.06671221554279327
step: 10, loss: 0.044330283999443054
step: 20, loss: 0.038167670369148254
step: 30, loss: 0.016936255618929863
step: 40, loss: 0.05959462746977806
step: 50, loss: 0.023470323532819748
step: 60, loss: 0.04593592882156372
step: 70, loss: 0.044818583875894547
step: 80, loss: 0.0015606534434482455
step: 90, loss: 2.232966471638065e-05
step: 100, loss: 0.0029404701199382544
step: 110, loss: 0.0008162984158843756
step: 120, loss: 0.019912635907530785
step: 130, loss: 0.0023073183838278055
step: 140, loss: 0.04009833559393883
step: 150, loss: 0.061731088906526566
step: 160, loss: 0.017869414761662483
step: 170, loss: 0.028482072055339813
step: 180, loss: 0.030472643673419952
step: 190, loss: 0.027617959305644035
step: 200, loss: 0.07231352478265762
step: 210, loss: 0.025143932551145554
step: 220, loss: 0.026441676542162895
step: 230, loss: 0.02458522655069828
step: 240, loss: 0.06428637355566025
step: 250, loss: 0.017746539786458015
step: 260, loss: 4.7586312575731426e-05
step: 270, loss: 0.036189448088407516
step: 280, loss: 0.0005540779675357044
step: 290, loss: 0.1040014997124672
step: 300, loss: 0.0001445070665795356
step: 310, loss: 0.07104155421257019
step: 320, loss: 0.029487745836377144
step: 330, loss: 0.0002157912531401962
step: 340, loss: 0.013172794133424759
step: 350, loss: 0.03501987084746361
step: 360, loss: 2.0211284208926372e-05
step: 370, loss: 0.02530684322118759
step: 380, loss: 0.020608050748705864
step: 390, loss: 0.00015424640150740743
step: 400, loss: 0.02190076746046543
step: 410, loss: 0.0001376962463837117
step: 420, loss: 0.07807828485965729
step: 430, loss: 0.03888300806283951
step: 440, loss: 0.04369289055466652
step: 450, loss: 0.01531768124550581
step: 460, loss: 0.03462899476289749
step: 470, loss: 0.09336274862289429
step: 480, loss: 0.01605949178338051
step: 490, loss: 0.026847122237086296
step: 500, loss: 0.004177819471806288
step: 510, loss: 0.0148864034563303
step: 520, loss: 0.00011205657210666686
step: 530, loss: 0.025588393211364746
step: 540, loss: 0.04117145389318466
step: 550, loss: 0.07731838524341583
step: 560, loss: 0.06368907541036606
step: 570, loss: 0.042806223034858704
step: 580, loss: 0.09235019981861115
step: 590, loss: 0.0451393723487854
step: 600, loss: 0.02880304679274559
step: 610, loss: 4.75447995995637e-05
step: 620, loss: 0.020590439438819885
step: 630, loss: 0.04369128867983818
step: 640, loss: 0.00010771665984066203
step: 650, loss: 0.03735926002264023
step: 660, loss: 0.012316718697547913
step: 670, loss: 0.0002048797468887642
step: 680, loss: 0.02113334648311138
step: 690, loss: 0.06497503817081451
step: 700, loss: 0.0006193967419676483
step: 710, loss: 0.03281465545296669
step: 720, loss: 7.815626304363832e-06
step: 730, loss: 0.02219892106950283
step: 740, loss: 0.0074250707402825356
step: 750, loss: 0.0203707218170166
step: 760, loss: 0.005719204433262348
step: 770, loss: 0.04740196093916893
step: 780, loss: 0.06299106031656265
step: 790, loss: 0.02875950187444687
step: 800, loss: 0.06282772868871689
step: 810, loss: 0.0005525105516426265
step: 820, loss: 0.0008541631978005171
step: 830, loss: 0.03283475711941719
step: 840, loss: 3.6598325095837936e-05
step: 850, loss: 0.026844574138522148
step: 860, loss: 0.0008958029793575406
step: 870, loss: 0.02503320388495922
step: 880, loss: 2.1279953216435388e-05
step: 890, loss: 0.01975986920297146
step: 900, loss: 0.019673356786370277
step: 910, loss: 0.05577133595943451
step: 920, loss: 0.019932324066758156
step: 930, loss: 0.0030074473470449448
step: 940, loss: 0.052450500428676605
step: 950, loss: 0.005845159292221069
step: 960, loss: 0.0007935998728498816
step: 970, loss: 0.025003567337989807
epoch 17: dev_f1=0.9343880874825501, f1=0.9279404927940492, best_f1=0.9293023255813954
step: 0, loss: 0.03462458774447441
step: 10, loss: 0.0012324225390329957
step: 20, loss: 0.09239109605550766
step: 30, loss: 0.02080228552222252
step: 40, loss: 0.03655527904629707
step: 50, loss: 0.02810383401811123
step: 60, loss: 0.03770817816257477
step: 70, loss: 4.0254122723126784e-05
step: 80, loss: 0.0015030644135549664
step: 90, loss: 0.06145111843943596
step: 100, loss: 0.051812995225191116
step: 110, loss: 0.015971221029758453
step: 120, loss: 0.023839078843593597
step: 130, loss: 0.0737173780798912
step: 140, loss: 0.0775332823395729
step: 150, loss: 0.024570157751441002
step: 160, loss: 0.0962592363357544
step: 170, loss: 0.037472471594810486
step: 180, loss: 0.021372219547629356
step: 190, loss: 0.03456214815378189
step: 200, loss: 0.017453022301197052
step: 210, loss: 0.0008664022316224873
step: 220, loss: 0.01923358626663685
step: 230, loss: 1.5436702597071417e-05
step: 240, loss: 0.00011759476910810918
step: 250, loss: 0.03239326551556587
step: 260, loss: 0.1284613460302353
step: 270, loss: 0.01985381357371807
step: 280, loss: 0.04121222347021103
step: 290, loss: 0.023633310571312904
step: 300, loss: 0.0033289387356489897
step: 310, loss: 0.00032152223866432905
step: 320, loss: 0.0009376993984915316
step: 330, loss: 0.0003024835023097694
step: 340, loss: 0.0601167194545269
step: 350, loss: 0.0401328019797802
step: 360, loss: 0.021073024719953537
step: 370, loss: 0.06519554555416107
step: 380, loss: 0.01591603271663189
step: 390, loss: 0.03072473593056202
step: 400, loss: 0.019802415743470192
step: 410, loss: 0.021198388189077377
step: 420, loss: 0.019208058714866638
step: 430, loss: 0.008736919611692429
step: 440, loss: 0.004695214331150055
step: 450, loss: 0.010346525348722935
step: 460, loss: 0.027191292494535446
step: 470, loss: 0.016663512215018272
step: 480, loss: 4.027130125905387e-05
step: 490, loss: 7.46917748983833e-06
step: 500, loss: 0.02101980708539486
step: 510, loss: 0.0006591801065951586
step: 520, loss: 0.04875291511416435
step: 530, loss: 0.0002671772090252489
step: 540, loss: 0.1266484558582306
step: 550, loss: 0.0002693179703783244
step: 560, loss: 0.029440511018037796
step: 570, loss: 7.81562539486913e-06
step: 580, loss: 0.04868750274181366
step: 590, loss: 0.10683054476976395
step: 600, loss: 0.0031501795165240765
step: 610, loss: 0.0005427622818388045
step: 620, loss: 0.0560770109295845
step: 630, loss: 0.04243829473853111
step: 640, loss: 0.00010544665565248579
step: 650, loss: 9.222470544045791e-05
step: 660, loss: 0.031235257163643837
step: 670, loss: 0.00022326456382870674
step: 680, loss: 0.06198452413082123
step: 690, loss: 0.020673520863056183
step: 700, loss: 0.015181627124547958
step: 710, loss: 0.018149014562368393
step: 720, loss: 0.015067042782902718
step: 730, loss: 0.015606390312314034
step: 740, loss: 0.00015937855641823262
step: 750, loss: 0.05845089256763458
step: 760, loss: 0.04731881245970726
step: 770, loss: 0.047869112342596054
step: 780, loss: 0.06505689769983292
step: 790, loss: 0.02747412957251072
step: 800, loss: 0.019521458074450493
step: 810, loss: 0.0014343899674713612
step: 820, loss: 0.02482769265770912
step: 830, loss: 0.046333204954862595
step: 840, loss: 0.01808551698923111
step: 850, loss: 0.046524494886398315
step: 860, loss: 0.0006240297807380557
step: 870, loss: 0.042800601571798325
step: 880, loss: 5.423175389296375e-05
step: 890, loss: 0.05775719881057739
step: 900, loss: 0.05459999293088913
step: 910, loss: 0.000792584614828229
step: 920, loss: 0.03740223869681358
step: 930, loss: 0.01880866475403309
step: 940, loss: 0.05093041807413101
step: 950, loss: 0.03131254389882088
step: 960, loss: 0.00013757029955741018
step: 970, loss: 0.02505469135940075
epoch 18: dev_f1=0.9330855018587362, f1=0.9290023201856149, best_f1=0.9293023255813954
step: 0, loss: 0.0008338268380612135
step: 10, loss: 0.0006314873462542892
step: 20, loss: 7.91713100625202e-05
step: 30, loss: 0.040056705474853516
step: 40, loss: 0.08531150966882706
step: 50, loss: 0.00019145429541822523
step: 60, loss: 9.641986252972856e-05
step: 70, loss: 0.022527068853378296
step: 80, loss: 0.0030390198808163404
step: 90, loss: 0.03483240306377411
step: 100, loss: 0.0001625102013349533
step: 110, loss: 3.6826226278208196e-05
step: 120, loss: 0.04639967903494835
step: 130, loss: 0.03850582242012024
step: 140, loss: 0.02598283626139164
step: 150, loss: 0.05439867824316025
step: 160, loss: 0.036588430404663086
step: 170, loss: 0.06545838713645935
step: 180, loss: 0.026425667107105255
step: 190, loss: 0.022914942353963852
step: 200, loss: 0.06555963307619095
step: 210, loss: 6.962541647226317e-06
step: 220, loss: 0.00014338821347337216
step: 230, loss: 0.051243528723716736
step: 240, loss: 0.023944607004523277
step: 250, loss: 0.03590364754199982
step: 260, loss: 0.05118225887417793
step: 270, loss: 0.006302989553660154
step: 280, loss: 0.00952448695898056
step: 290, loss: 0.017459921538829803
step: 300, loss: 0.023210525512695312
step: 310, loss: 0.02802460454404354
step: 320, loss: 0.03053380735218525
step: 330, loss: 0.02368161454796791
step: 340, loss: 0.05823325365781784
step: 350, loss: 0.023812081664800644
step: 360, loss: 0.0008107871981337667
step: 370, loss: 7.239761907840148e-05
step: 380, loss: 0.0021907563786953688
step: 390, loss: 0.05371915549039841
step: 400, loss: 4.61724994238466e-05
step: 410, loss: 3.721417306223884e-05
step: 420, loss: 0.01852215826511383
step: 430, loss: 7.28680970496498e-05
step: 440, loss: 0.030855074524879456
step: 450, loss: 0.028026485815644264
step: 460, loss: 0.039219532161951065
step: 470, loss: 0.13062070310115814
step: 480, loss: 0.016811447218060493
step: 490, loss: 0.05412278324365616
step: 500, loss: 0.0019006050424650311
step: 510, loss: 0.02219833992421627
step: 520, loss: 0.0006727571599185467
step: 530, loss: 0.023634711280465126
step: 540, loss: 0.032797250896692276
step: 550, loss: 0.02009354904294014
step: 560, loss: 0.055948127061128616
step: 570, loss: 0.005370193161070347
step: 580, loss: 0.04024951532483101
step: 590, loss: 0.394612193107605
step: 600, loss: 2.6406431061332114e-05
step: 610, loss: 0.04266331344842911
step: 620, loss: 0.00018564029596745968
step: 630, loss: 0.0010193438502028584
step: 640, loss: 0.00041708670323714614
step: 650, loss: 0.013454380445182323
step: 660, loss: 0.012688928283751011
step: 670, loss: 0.00030175631400197744
step: 680, loss: 0.0002650105452630669
step: 690, loss: 0.11422029137611389
step: 700, loss: 0.022133633494377136
step: 710, loss: 0.023873765021562576
step: 720, loss: 0.030351703986525536
step: 730, loss: 1.5816904124221765e-05
step: 740, loss: 2.8752108846674673e-05
step: 750, loss: 3.677007043734193e-05
step: 760, loss: 0.10583134740591049
step: 770, loss: 0.05318443849682808
step: 780, loss: 0.060554489493370056
step: 790, loss: 0.03671935945749283
step: 800, loss: 0.02616574615240097
step: 810, loss: 0.021260855719447136
step: 820, loss: 0.05501861497759819
step: 830, loss: 0.019435105845332146
step: 840, loss: 0.00012804096331819892
step: 850, loss: 0.021420814096927643
step: 860, loss: 0.03682585433125496
step: 870, loss: 0.03554726764559746
step: 880, loss: 0.00012481438170652837
step: 890, loss: 0.00011847272980958223
step: 900, loss: 0.0666552260518074
step: 910, loss: 0.005948647391051054
step: 920, loss: 0.01010909117758274
step: 930, loss: 2.47245352511527e-05
step: 940, loss: 0.05273100733757019
step: 950, loss: 0.0488528348505497
step: 960, loss: 0.07926265150308609
step: 970, loss: 0.029564619064331055
epoch 19: dev_f1=0.933826931975937, f1=0.9291338582677167, best_f1=0.9293023255813954
step: 0, loss: 0.0001771940296748653
step: 10, loss: 0.04856307432055473
step: 20, loss: 0.000138933421112597
step: 30, loss: 0.017994895577430725
step: 40, loss: 0.02481486275792122
step: 50, loss: 0.02456635981798172
step: 60, loss: 0.053438425064086914
step: 70, loss: 0.021354155614972115
step: 80, loss: 0.0625910758972168
step: 90, loss: 0.03839365765452385
step: 100, loss: 0.030466189607977867
step: 110, loss: 0.06201234459877014
step: 120, loss: 0.04736899957060814
step: 130, loss: 0.016968006268143654
step: 140, loss: 0.020307540893554688
step: 150, loss: 0.13622336089611053
step: 160, loss: 4.84199590573553e-05
step: 170, loss: 3.765799920074642e-05
step: 180, loss: 0.05024278163909912
step: 190, loss: 0.016774343326687813
step: 200, loss: 0.0031917099840939045
step: 210, loss: 0.02862994186580181
step: 220, loss: 0.01771269179880619
step: 230, loss: 0.0039003142155706882
step: 240, loss: 0.03672933205962181
step: 250, loss: 0.0008114049560390413
step: 260, loss: 0.03363652899861336
step: 270, loss: 0.09148180484771729
step: 280, loss: 0.02887110598385334
step: 290, loss: 0.053598638623952866
step: 300, loss: 7.674114021938294e-05
step: 310, loss: 0.053444162011146545
step: 320, loss: 0.08671578764915466
step: 330, loss: 0.08291619271039963
step: 340, loss: 0.005700444336980581
step: 350, loss: 0.02438499592244625
step: 360, loss: 0.10227885097265244
step: 370, loss: 0.025001348927617073
step: 380, loss: 0.018790721893310547
step: 390, loss: 0.02007155306637287
step: 400, loss: 0.019533712416887283
step: 410, loss: 0.013196168467402458
step: 420, loss: 5.0251470383955166e-05
step: 430, loss: 0.04668328911066055
step: 440, loss: 0.03358040377497673
step: 450, loss: 0.047234468162059784
step: 460, loss: 0.020262517035007477
step: 470, loss: 0.00012000784045085311
step: 480, loss: 0.00012168815010227263
step: 490, loss: 0.030181046575307846
step: 500, loss: 0.01969868317246437
step: 510, loss: 0.04280985891819
step: 520, loss: 0.02619209699332714
step: 530, loss: 0.0006623186636716127
step: 540, loss: 0.017110345885157585
step: 550, loss: 0.002361180493608117
step: 560, loss: 0.0001016117530525662
step: 570, loss: 0.02515372447669506
step: 580, loss: 0.045444101095199585
step: 590, loss: 0.018633149564266205
step: 600, loss: 0.056976478546857834
step: 610, loss: 0.0006895471015013754
step: 620, loss: 0.0002019595995079726
step: 630, loss: 0.02023882046341896
step: 640, loss: 0.017132483422756195
step: 650, loss: 0.06059538945555687
step: 660, loss: 0.0005911343614570796
step: 670, loss: 2.8871078029624186e-05
step: 680, loss: 5.648255319101736e-05
step: 690, loss: 0.02775723487138748
step: 700, loss: 7.165578426793218e-05
step: 710, loss: 0.03992484137415886
step: 720, loss: 0.02443305216729641
step: 730, loss: 0.07803652435541153
step: 740, loss: 0.06490150839090347
step: 750, loss: 0.041980329900979996
step: 760, loss: 0.0181466992944479
step: 770, loss: 0.07584137469530106
step: 780, loss: 0.06625527888536453
step: 790, loss: 0.048616938292980194
step: 800, loss: 0.03453032672405243
step: 810, loss: 0.04296623170375824
step: 820, loss: 0.02056192047894001
step: 830, loss: 0.04388004168868065
step: 840, loss: 0.023393947631120682
step: 850, loss: 8.438191434834152e-05
step: 860, loss: 0.017488185316324234
step: 870, loss: 0.06440293788909912
step: 880, loss: 0.027035284787416458
step: 890, loss: 0.022170770913362503
step: 900, loss: 0.0379381887614727
step: 910, loss: 0.029364613816142082
step: 920, loss: 0.08802493661642075
step: 930, loss: 0.0680159330368042
step: 940, loss: 0.01718602515757084
step: 950, loss: 0.08024051040410995
step: 960, loss: 0.00012141124170739204
step: 970, loss: 0.04082295671105385
epoch 20: dev_f1=0.9327731092436975, f1=0.9273066169617894, best_f1=0.9293023255813954
