cuda
Device: cuda
step: 0, loss: 0.6411030292510986
step: 10, loss: 0.24898719787597656
step: 20, loss: 0.07298846542835236
step: 30, loss: 0.04728235676884651
step: 40, loss: 0.07111474871635437
step: 50, loss: 0.14093582332134247
step: 60, loss: 0.13912995159626007
step: 70, loss: 0.23047387599945068
step: 80, loss: 0.5645508170127869
step: 90, loss: 0.3259122371673584
step: 100, loss: 0.3161613643169403
step: 110, loss: 0.23992228507995605
step: 120, loss: 0.13261188566684723
step: 130, loss: 0.24402600526809692
step: 140, loss: 0.21428674459457397
step: 150, loss: 0.13303326070308685
step: 160, loss: 0.22053039073944092
step: 170, loss: 0.3847270607948303
step: 180, loss: 0.12864519655704498
step: 190, loss: 0.032335493713617325
step: 200, loss: 0.22405536472797394
step: 210, loss: 0.06042825058102608
step: 220, loss: 0.07010511308908463
step: 230, loss: 0.020107749849557877
step: 240, loss: 0.14419175684452057
step: 250, loss: 0.03080499731004238
step: 260, loss: 0.040822695940732956
step: 270, loss: 0.18438123166561127
step: 280, loss: 0.20715470612049103
step: 290, loss: 0.3097914159297943
step: 300, loss: 0.12025385349988937
step: 310, loss: 0.31171223521232605
step: 320, loss: 0.2541370391845703
step: 330, loss: 0.12362262606620789
step: 340, loss: 0.02985338866710663
step: 350, loss: 0.32431402802467346
step: 360, loss: 0.3009951114654541
epoch 1: dev_f1=0.37889688249400477, f1=0.4097560975609756, best_f1=0.4097560975609756
step: 0, loss: 0.14589737355709076
step: 10, loss: 0.02316667139530182
step: 20, loss: 0.2563784122467041
step: 30, loss: 0.08882613480091095
step: 40, loss: 0.122215636074543
step: 50, loss: 0.04370393976569176
step: 60, loss: 0.24335327744483948
step: 70, loss: 0.2509276568889618
step: 80, loss: 0.060717903077602386
step: 90, loss: 0.05929672718048096
step: 100, loss: 0.11147814989089966
step: 110, loss: 0.060673005878925323
step: 120, loss: 0.09960675239562988
step: 130, loss: 0.10116100311279297
step: 140, loss: 0.13920679688453674
step: 150, loss: 0.13806188106536865
step: 160, loss: 0.16349653899669647
step: 170, loss: 0.013783884234726429
step: 180, loss: 0.15611159801483154
step: 190, loss: 0.6013813614845276
step: 200, loss: 0.09660141170024872
step: 210, loss: 0.06320147216320038
step: 220, loss: 0.14774593710899353
step: 230, loss: 0.09863807260990143
step: 240, loss: 0.11055935174226761
step: 250, loss: 0.1722632795572281
step: 260, loss: 0.07022792100906372
step: 270, loss: 0.08192472159862518
step: 280, loss: 0.18501010537147522
step: 290, loss: 0.1914013922214508
step: 300, loss: 0.1706935614347458
step: 310, loss: 0.20813460648059845
step: 320, loss: 0.052758824080228806
step: 330, loss: 0.09138279408216476
step: 340, loss: 0.15748196840286255
step: 350, loss: 0.11267286539077759
step: 360, loss: 0.09816619008779526
epoch 2: dev_f1=0.5450121654501218, f1=0.5402597402597402, best_f1=0.5402597402597402
step: 0, loss: 0.23060448467731476
step: 10, loss: 0.21589474380016327
step: 20, loss: 0.03833655267953873
step: 30, loss: 0.10845311731100082
step: 40, loss: 0.060492947697639465
step: 50, loss: 0.017974143847823143
step: 60, loss: 0.03825574368238449
step: 70, loss: 0.02513858489692211
step: 80, loss: 0.13949869573116302
step: 90, loss: 0.0028516598977148533
step: 100, loss: 0.13923482596874237
step: 110, loss: 0.2157200276851654
step: 120, loss: 0.07658643275499344
step: 130, loss: 0.035389844328165054
step: 140, loss: 0.17027287185192108
step: 150, loss: 0.021254589781165123
step: 160, loss: 0.13955272734165192
step: 170, loss: 0.06484060734510422
step: 180, loss: 0.03465169668197632
step: 190, loss: 0.06266915053129196
step: 200, loss: 0.06253877282142639
step: 210, loss: 0.0161956287920475
step: 220, loss: 0.05505283921957016
step: 230, loss: 0.011920398101210594
step: 240, loss: 0.011911919340491295
step: 250, loss: 0.19503352046012878
step: 260, loss: 0.0035853020381182432
step: 270, loss: 0.07319550961256027
step: 280, loss: 0.07501210272312164
step: 290, loss: 0.02230731211602688
step: 300, loss: 0.11196830123662949
step: 310, loss: 0.1366627812385559
step: 320, loss: 0.1067548543214798
step: 330, loss: 0.054786112159490585
step: 340, loss: 0.059412091970443726
step: 350, loss: 0.07570967823266983
step: 360, loss: 0.21295809745788574
epoch 3: dev_f1=0.6, f1=0.5459940652818991, best_f1=0.5459940652818991
step: 0, loss: 0.117676742374897
step: 10, loss: 0.03244025632739067
step: 20, loss: 0.006734181195497513
step: 30, loss: 0.12615053355693817
step: 40, loss: 0.05755713954567909
step: 50, loss: 0.16697199642658234
step: 60, loss: 0.0463140644133091
step: 70, loss: 0.2147621214389801
step: 80, loss: 0.06867048144340515
step: 90, loss: 0.18427960574626923
step: 100, loss: 0.03165992721915245
step: 110, loss: 0.06630463898181915
step: 120, loss: 0.03144129738211632
step: 130, loss: 0.021164489910006523
step: 140, loss: 0.052380453795194626
step: 150, loss: 0.17709210515022278
step: 160, loss: 0.030311619862914085
step: 170, loss: 0.07567039132118225
step: 180, loss: 0.08819079399108887
step: 190, loss: 0.01506739854812622
step: 200, loss: 0.0031265669967979193
step: 210, loss: 0.08080034703016281
step: 220, loss: 0.05308017134666443
step: 230, loss: 0.09069663286209106
step: 240, loss: 0.01636883243918419
step: 250, loss: 0.1354321837425232
step: 260, loss: 0.06451429426670074
step: 270, loss: 0.010438123717904091
step: 280, loss: 0.02735891193151474
step: 290, loss: 0.0033972389064729214
step: 300, loss: 0.023225460201501846
step: 310, loss: 0.09582027047872543
step: 320, loss: 0.14755655825138092
step: 330, loss: 0.00670642452314496
step: 340, loss: 0.059453334659338
step: 350, loss: 0.008579201065003872
step: 360, loss: 0.017006129026412964
epoch 4: dev_f1=0.6466165413533835, f1=0.631578947368421, best_f1=0.631578947368421
step: 0, loss: 0.04713562875986099
step: 10, loss: 0.006285272538661957
step: 20, loss: 0.03364355117082596
step: 30, loss: 0.004308133386075497
step: 40, loss: 0.0016529913991689682
step: 50, loss: 0.0028263265267014503
step: 60, loss: 0.0020196433179080486
step: 70, loss: 0.02355479635298252
step: 80, loss: 0.0875924602150917
step: 90, loss: 0.0012248678831383586
step: 100, loss: 0.010650957003235817
step: 110, loss: 0.2219018042087555
step: 120, loss: 0.0021708449348807335
step: 130, loss: 0.014268005266785622
step: 140, loss: 0.007706326432526112
step: 150, loss: 0.032999783754348755
step: 160, loss: 0.00326747540384531
step: 170, loss: 0.011320158839225769
step: 180, loss: 0.07370728254318237
step: 190, loss: 0.00586303137242794
step: 200, loss: 0.007799818646162748
step: 210, loss: 0.04200904071331024
step: 220, loss: 0.02305593714118004
step: 230, loss: 0.0005088442703709006
step: 240, loss: 0.0038624093867838383
step: 250, loss: 0.1387837827205658
step: 260, loss: 0.11296498030424118
step: 270, loss: 0.03317265585064888
step: 280, loss: 0.07890617102384567
step: 290, loss: 0.09637477993965149
step: 300, loss: 0.005378828849643469
step: 310, loss: 0.01457894779741764
step: 320, loss: 0.02654404006898403
step: 330, loss: 0.03382635489106178
step: 340, loss: 0.012132632546126842
step: 350, loss: 0.011175894178450108
step: 360, loss: 0.0029326663352549076
epoch 5: dev_f1=0.578125, f1=0.5779036827195467, best_f1=0.631578947368421
step: 0, loss: 0.07318737357854843
step: 10, loss: 0.02563643455505371
step: 20, loss: 0.002692017937079072
step: 30, loss: 0.0008481468539685011
step: 40, loss: 0.0007815700373612344
step: 50, loss: 0.07650240510702133
step: 60, loss: 0.08915798366069794
step: 70, loss: 0.03422868996858597
step: 80, loss: 0.0009383977157995105
step: 90, loss: 0.025411365553736687
step: 100, loss: 0.057962194085121155
step: 110, loss: 0.012305091135203838
step: 120, loss: 0.042360663414001465
step: 130, loss: 0.0031308152247220278
step: 140, loss: 0.007719933521002531
step: 150, loss: 0.01287001185119152
step: 160, loss: 0.007999665103852749
step: 170, loss: 0.004877329804003239
step: 180, loss: 0.030295034870505333
step: 190, loss: 0.001430132077075541
step: 200, loss: 0.02739519625902176
step: 210, loss: 0.0015199227491393685
step: 220, loss: 0.001470668357796967
step: 230, loss: 0.029589716345071793
step: 240, loss: 0.0038741857279092073
step: 250, loss: 0.0050906892865896225
step: 260, loss: 0.000315878598485142
step: 270, loss: 0.0013642755802720785
step: 280, loss: 0.005999507382512093
step: 290, loss: 0.000303220993373543
step: 300, loss: 0.08740309625864029
step: 310, loss: 0.028898240998387337
step: 320, loss: 0.14101260900497437
step: 330, loss: 0.00504342233762145
step: 340, loss: 0.04897856339812279
step: 350, loss: 0.1940363347530365
step: 360, loss: 0.0003883200988639146
epoch 6: dev_f1=0.6024691358024691, f1=0.598984771573604, best_f1=0.631578947368421
step: 0, loss: 0.017190808430314064
step: 10, loss: 0.046839140355587006
step: 20, loss: 0.000923211220651865
step: 30, loss: 0.0015832448843866587
step: 40, loss: 0.04460546374320984
step: 50, loss: 0.015773514285683632
step: 60, loss: 0.014378166757524014
step: 70, loss: 0.00747701246291399
step: 80, loss: 0.008903599344193935
step: 90, loss: 0.002148976316675544
step: 100, loss: 0.0871950015425682
step: 110, loss: 0.0014592469669878483
step: 120, loss: 0.0034482162445783615
step: 130, loss: 0.11384961754083633
step: 140, loss: 0.000741761876270175
step: 150, loss: 0.00012827273167204112
step: 160, loss: 0.00044625159353017807
step: 170, loss: 0.009043692611157894
step: 180, loss: 0.0011458375956863165
step: 190, loss: 0.005154594779014587
step: 200, loss: 0.004630707204341888
step: 210, loss: 0.0115638617426157
step: 220, loss: 0.0016316958935931325
step: 230, loss: 0.0009853900410234928
step: 240, loss: 0.0016055658925324678
step: 250, loss: 0.00025841034948825836
step: 260, loss: 0.0021127713844180107
step: 270, loss: 0.005880188662558794
step: 280, loss: 0.003908728715032339
step: 290, loss: 0.008092917501926422
step: 300, loss: 0.0005047650192864239
step: 310, loss: 0.006422925740480423
step: 320, loss: 0.0014851472806185484
step: 330, loss: 0.03785951808094978
step: 340, loss: 0.09452266991138458
step: 350, loss: 0.0008330696146003902
step: 360, loss: 0.014219950884580612
epoch 7: dev_f1=0.6395939086294417, f1=0.6304347826086957, best_f1=0.631578947368421
step: 0, loss: 0.02269919589161873
step: 10, loss: 0.03567444905638695
step: 20, loss: 0.0010629775933921337
step: 30, loss: 0.0048541901633143425
step: 40, loss: 0.0019801738671958447
step: 50, loss: 0.005846834741532803
step: 60, loss: 0.013655081391334534
step: 70, loss: 0.0152888847514987
step: 80, loss: 0.0011650017695501447
step: 90, loss: 0.0031505960505455732
step: 100, loss: 0.00013075731112621725
step: 110, loss: 0.0030294214375317097
step: 120, loss: 0.00798065960407257
step: 130, loss: 0.0004526172124315053
step: 140, loss: 0.006766081787645817
step: 150, loss: 0.03231925144791603
step: 160, loss: 0.0012281234376132488
step: 170, loss: 0.0016113754827529192
step: 180, loss: 0.0013768569333478808
step: 190, loss: 0.0003273128822911531
step: 200, loss: 0.00013242565910331905
step: 210, loss: 0.0005714378203265369
step: 220, loss: 0.000930022681131959
step: 230, loss: 0.00040495608118362725
step: 240, loss: 0.07896137982606888
step: 250, loss: 0.00447461660951376
step: 260, loss: 0.0009295651689171791
step: 270, loss: 0.0006801916169933975
step: 280, loss: 0.03694566711783409
step: 290, loss: 0.037575602531433105
step: 300, loss: 0.022864563390612602
step: 310, loss: 0.16364669799804688
step: 320, loss: 0.0029314053244888783
step: 330, loss: 0.017485572025179863
step: 340, loss: 0.0071766795590519905
step: 350, loss: 0.0003395700769033283
step: 360, loss: 0.021568935364484787
epoch 8: dev_f1=0.631868131868132, f1=0.6005830903790087, best_f1=0.631578947368421
step: 0, loss: 0.0003858740965370089
step: 10, loss: 0.03339836001396179
step: 20, loss: 0.03669621795415878
step: 30, loss: 0.0012649233685806394
step: 40, loss: 0.0005009938613511622
step: 50, loss: 0.007387317251414061
step: 60, loss: 0.033550698310136795
step: 70, loss: 0.0006525150965899229
step: 80, loss: 0.00029275380074977875
step: 90, loss: 0.0056149582378566265
step: 100, loss: 0.0337694026529789
step: 110, loss: 0.023152794688940048
step: 120, loss: 0.008164923638105392
step: 130, loss: 0.0002780472277663648
step: 140, loss: 0.002416500123217702
step: 150, loss: 0.005537014454603195
step: 160, loss: 0.06903546303510666
step: 170, loss: 6.106292858021334e-05
step: 180, loss: 0.01124739833176136
step: 190, loss: 0.014368413016200066
step: 200, loss: 0.0015543263871222734
step: 210, loss: 0.0013553597964346409
step: 220, loss: 0.004335716366767883
step: 230, loss: 0.0272859875112772
step: 240, loss: 0.00010605321585899219
step: 250, loss: 0.0015697000781074166
step: 260, loss: 0.010381937958300114
step: 270, loss: 0.09181228280067444
step: 280, loss: 0.013059983029961586
step: 290, loss: 0.002541173016652465
step: 300, loss: 0.036920081824064255
step: 310, loss: 0.000194346415810287
step: 320, loss: 0.0005574630340561271
step: 330, loss: 0.0005958867841400206
step: 340, loss: 0.009094951674342155
step: 350, loss: 4.7377627197420225e-05
step: 360, loss: 0.0002145297039533034
epoch 9: dev_f1=0.6273458445040214, f1=0.6193181818181819, best_f1=0.631578947368421
step: 0, loss: 0.029452359303832054
step: 10, loss: 0.0003114663704764098
step: 20, loss: 0.0011454860214143991
step: 30, loss: 0.00023415360192302614
step: 40, loss: 0.03557534143328667
step: 50, loss: 0.002540269633755088
step: 60, loss: 0.006491530686616898
step: 70, loss: 9.8817799880635e-05
step: 80, loss: 0.00031517332536168396
step: 90, loss: 0.0010379363084211946
step: 100, loss: 0.0006863850867375731
step: 110, loss: 0.0004492882580962032
step: 120, loss: 0.00028033717535436153
step: 130, loss: 0.0010557672940194607
step: 140, loss: 0.0003318354138173163
step: 150, loss: 0.0019577329512685537
step: 160, loss: 0.0004180109826847911
step: 170, loss: 0.00019745243480429053
step: 180, loss: 0.007200194522738457
step: 190, loss: 0.00040749445906840265
step: 200, loss: 7.568552246084437e-05
step: 210, loss: 0.00010177752847084776
step: 220, loss: 0.002210708800703287
step: 230, loss: 0.0009487852221354842
step: 240, loss: 0.0018729224102571607
step: 250, loss: 0.07337857782840729
step: 260, loss: 0.00017250285600312054
step: 270, loss: 0.04082642123103142
step: 280, loss: 0.0002101253776345402
step: 290, loss: 0.00020369040430523455
step: 300, loss: 0.0001305215118918568
step: 310, loss: 0.00024640533956699073
step: 320, loss: 0.0026498555671423674
step: 330, loss: 5.6785913329804316e-05
step: 340, loss: 0.00464908080175519
step: 350, loss: 0.0011874170741066337
step: 360, loss: 7.021410419838503e-05
epoch 10: dev_f1=0.6066838046272495, f1=0.6170212765957447, best_f1=0.631578947368421
step: 0, loss: 0.00012292125029489398
step: 10, loss: 8.644159242976457e-05
step: 20, loss: 0.0008433925686404109
step: 30, loss: 0.00036221189657226205
step: 40, loss: 0.0019212181214243174
step: 50, loss: 0.0019112701993435621
step: 60, loss: 0.024293681606650352
step: 70, loss: 0.011198661290109158
step: 80, loss: 0.06297598034143448
step: 90, loss: 0.0006003314629197121
step: 100, loss: 0.003058301517739892
step: 110, loss: 0.0003255854535382241
step: 120, loss: 0.00019545354007277638
step: 130, loss: 0.0009543317719362676
step: 140, loss: 0.0020432951860129833
step: 150, loss: 0.00012200539640616626
step: 160, loss: 0.0009308310691267252
step: 170, loss: 0.005999334156513214
step: 180, loss: 0.00516923563554883
step: 190, loss: 0.00010182867117691785
step: 200, loss: 0.000404645805247128
step: 210, loss: 0.0034170623403042555
step: 220, loss: 0.00202331505715847
step: 230, loss: 0.0019012480042874813
step: 240, loss: 0.00011852427269332111
step: 250, loss: 0.00024168755044229329
step: 260, loss: 0.00016522896476089954
step: 270, loss: 8.273317507700995e-05
step: 280, loss: 0.00010047024261439219
step: 290, loss: 0.0004010580596514046
step: 300, loss: 0.00011265640932833776
step: 310, loss: 0.1758028268814087
step: 320, loss: 0.00011657233699224889
step: 330, loss: 0.0001269605418201536
step: 340, loss: 0.011960072442889214
step: 350, loss: 0.00023653835523873568
step: 360, loss: 0.0007919362396933138
epoch 11: dev_f1=0.5897435897435896, f1=0.56, best_f1=0.631578947368421
step: 0, loss: 0.0003546995867509395
step: 10, loss: 0.0001842155324993655
step: 20, loss: 0.0004922212683595717
step: 30, loss: 0.003486892906948924
step: 40, loss: 0.0005094848456792533
step: 50, loss: 0.000689498265273869
step: 60, loss: 0.05692225694656372
step: 70, loss: 0.0014850933803245425
step: 80, loss: 0.0013605862623080611
step: 90, loss: 0.0007519200444221497
step: 100, loss: 0.0010576288914307952
step: 110, loss: 0.010237280279397964
step: 120, loss: 0.17207108438014984
step: 130, loss: 0.07112084329128265
step: 140, loss: 0.00014489136810880154
step: 150, loss: 0.06920240819454193
step: 160, loss: 0.06162916496396065
step: 170, loss: 0.0015009500784799457
step: 180, loss: 0.0009441003203392029
step: 190, loss: 0.0022421914618462324
step: 200, loss: 0.0018020265270024538
step: 210, loss: 0.003941915929317474
step: 220, loss: 0.0022723644506186247
step: 230, loss: 8.44076057546772e-05
step: 240, loss: 0.00014456479402724653
step: 250, loss: 0.00041170240729115903
step: 260, loss: 0.00013005964865442365
step: 270, loss: 0.0005513945943675935
step: 280, loss: 0.00662631168961525
step: 290, loss: 0.0011649635853245854
step: 300, loss: 0.0006787557504139841
step: 310, loss: 0.1659766584634781
step: 320, loss: 0.01841771975159645
step: 330, loss: 0.0009041139855980873
step: 340, loss: 0.0001870128617156297
step: 350, loss: 0.0007251733914017677
step: 360, loss: 0.0003960260364692658
epoch 12: dev_f1=0.6436170212765957, f1=0.6324786324786325, best_f1=0.631578947368421
step: 0, loss: 0.0007029083790257573
step: 10, loss: 0.00039867247687652707
step: 20, loss: 0.0004577891086228192
step: 30, loss: 0.0006807994213886559
step: 40, loss: 0.048085130751132965
step: 50, loss: 0.0017738492460921407
step: 60, loss: 0.0003547359083313495
step: 70, loss: 0.001390256336890161
step: 80, loss: 0.0010031888959929347
step: 90, loss: 0.0004164774436503649
step: 100, loss: 0.0018247950356453657
step: 110, loss: 0.0005925945588387549
step: 120, loss: 0.00012912116653751582
step: 130, loss: 0.00767162861302495
step: 140, loss: 0.007684379816055298
step: 150, loss: 4.701866055256687e-05
step: 160, loss: 0.00011938543320866302
step: 170, loss: 0.00014606225886382163
step: 180, loss: 0.0010602582478895783
step: 190, loss: 0.0004114687326364219
step: 200, loss: 0.0002886468719225377
step: 210, loss: 0.013559768907725811
step: 220, loss: 0.0063175843097269535
step: 230, loss: 0.00010816369467647746
step: 240, loss: 4.9632461013970897e-05
step: 250, loss: 0.03823814168572426
step: 260, loss: 0.0003770576440729201
step: 270, loss: 0.000318975216941908
step: 280, loss: 0.062041159719228745
step: 290, loss: 0.0019247253658249974
step: 300, loss: 0.0001299104478675872
step: 310, loss: 7.903258665464818e-05
step: 320, loss: 0.00034889779635705054
step: 330, loss: 0.00014653833932243288
step: 340, loss: 8.220168092520908e-05
step: 350, loss: 0.00041094113839790225
step: 360, loss: 0.00018011429347097874
epoch 13: dev_f1=0.6297229219143576, f1=0.6312997347480105, best_f1=0.631578947368421
step: 0, loss: 0.0002172136155422777
step: 10, loss: 0.0015291468007490039
step: 20, loss: 0.0021164754871279
step: 30, loss: 0.00018512937822379172
step: 40, loss: 0.00014521749108098447
step: 50, loss: 0.00012291436723899096
step: 60, loss: 0.0021949089132249355
step: 70, loss: 0.0037656251806765795
step: 80, loss: 0.00021202198695391417
step: 90, loss: 0.0001802410843083635
step: 100, loss: 0.0002914877259172499
step: 110, loss: 0.00044963322579860687
step: 120, loss: 0.0009516311110928655
step: 130, loss: 0.000635566480923444
step: 140, loss: 0.0002296314632985741
step: 150, loss: 0.0012014689855277538
step: 160, loss: 0.00027854484505951405
step: 170, loss: 0.001099645858630538
step: 180, loss: 0.033338434994220734
step: 190, loss: 7.33984779799357e-05
step: 200, loss: 0.0008726720116101205
step: 210, loss: 0.000421416771132499
step: 220, loss: 9.7465563158039e-05
step: 230, loss: 0.00013015809236094356
step: 240, loss: 0.00045925084850750864
step: 250, loss: 0.00015463116869796067
step: 260, loss: 0.00023543591669294983
step: 270, loss: 8.39847416500561e-05
step: 280, loss: 0.0001497614721301943
step: 290, loss: 8.559341949876398e-05
step: 300, loss: 8.753875590628013e-05
step: 310, loss: 6.570463301613927e-05
step: 320, loss: 0.0014967925380915403
step: 330, loss: 0.00020806450629606843
step: 340, loss: 0.00014889788872096688
step: 350, loss: 0.00032379015465267
step: 360, loss: 0.00020360272901598364
epoch 14: dev_f1=0.6459948320413437, f1=0.6376021798365122, best_f1=0.631578947368421
step: 0, loss: 4.3989111873088405e-05
step: 10, loss: 8.903755951905623e-05
step: 20, loss: 0.0003821526770479977
step: 30, loss: 3.918804941349663e-05
step: 40, loss: 0.1375422328710556
step: 50, loss: 4.8286958190146834e-05
step: 60, loss: 0.004821768030524254
step: 70, loss: 0.0013549202121794224
step: 80, loss: 0.0009540276369079947
step: 90, loss: 0.0002030043106060475
step: 100, loss: 0.011838757432997227
step: 110, loss: 0.00010078181367134675
step: 120, loss: 0.0022450247779488564
step: 130, loss: 2.482845047779847e-05
step: 140, loss: 0.000792757433373481
step: 150, loss: 0.0005561669822782278
step: 160, loss: 7.805349014233798e-05
step: 170, loss: 0.0002979130076710135
step: 180, loss: 0.0001128027361119166
step: 190, loss: 0.00018363275739829987
step: 200, loss: 0.0002543108130339533
step: 210, loss: 0.00013956366456113756
step: 220, loss: 0.0010063041700050235
step: 230, loss: 0.0001626511220820248
step: 240, loss: 9.060078446054831e-05
step: 250, loss: 8.976477693067864e-05
step: 260, loss: 5.879786112927832e-05
step: 270, loss: 0.0010861409828066826
step: 280, loss: 0.00024528431822545826
step: 290, loss: 4.212193380226381e-05
step: 300, loss: 6.731996109010652e-05
step: 310, loss: 0.00015525940398219973
step: 320, loss: 0.00011440103116910905
step: 330, loss: 0.0001569125452078879
step: 340, loss: 0.00014668900985270739
step: 350, loss: 6.895980914123356e-05
step: 360, loss: 9.089879313251004e-05
epoch 15: dev_f1=0.6473684210526316, f1=0.6440677966101694, best_f1=0.6440677966101694
step: 0, loss: 7.111940794857219e-05
step: 10, loss: 0.00017071363981813192
step: 20, loss: 0.026629656553268433
step: 30, loss: 4.399645695229992e-05
step: 40, loss: 3.950027530663647e-05
step: 50, loss: 0.0004524643300101161
step: 60, loss: 0.10241127759218216
step: 70, loss: 0.00032913009636104107
step: 80, loss: 2.968206536024809e-05
step: 90, loss: 0.0001447446848032996
step: 100, loss: 4.6931192628107965e-05
step: 110, loss: 7.469124102499336e-05
step: 120, loss: 0.00014635352999903262
step: 130, loss: 0.11484482884407043
step: 140, loss: 0.00023907162540126592
step: 150, loss: 0.00016266157035715878
step: 160, loss: 0.00012919794244226068
step: 170, loss: 0.1286579817533493
step: 180, loss: 0.000607015157584101
step: 190, loss: 0.00016528510604985058
step: 200, loss: 7.977657514857128e-05
step: 210, loss: 0.0008781764772720635
step: 220, loss: 7.41290787118487e-05
step: 230, loss: 0.00011149854253744707
step: 240, loss: 0.00020080071408301592
step: 250, loss: 7.974541222210974e-05
step: 260, loss: 7.515068136854097e-05
step: 270, loss: 0.00021110787929501384
step: 280, loss: 0.002523403614759445
step: 290, loss: 0.017661824822425842
step: 300, loss: 0.00010712346556829289
step: 310, loss: 0.00016087567200884223
step: 320, loss: 0.0005564402090385556
step: 330, loss: 0.0002773540618363768
step: 340, loss: 7.65951699577272e-05
step: 350, loss: 4.586127761285752e-05
step: 360, loss: 6.697541539324448e-05
epoch 16: dev_f1=0.6344086021505376, f1=0.6306818181818182, best_f1=0.6440677966101694
step: 0, loss: 7.755526894470677e-05
step: 10, loss: 0.0025491290725767612
step: 20, loss: 0.00017491308972239494
step: 30, loss: 0.00010082165681524202
step: 40, loss: 7.147468568291515e-05
step: 50, loss: 0.0003215456963516772
step: 60, loss: 7.827366789570078e-05
step: 70, loss: 0.00013412379485089332
step: 80, loss: 0.00011658822768367827
step: 90, loss: 0.00010365557682234794
step: 100, loss: 7.336080307140946e-05
step: 110, loss: 4.640465340344235e-05
step: 120, loss: 0.00034461208269931376
step: 130, loss: 4.62900243292097e-05
step: 140, loss: 0.0003858901036437601
step: 150, loss: 0.00018088612705469131
step: 160, loss: 0.0001074161336873658
step: 170, loss: 0.0001576642389409244
step: 180, loss: 0.00015240564243867993
step: 190, loss: 2.9663491659448482e-05
step: 200, loss: 5.5202363000717014e-05
step: 210, loss: 0.00758013129234314
step: 220, loss: 0.0006614303565584123
step: 230, loss: 0.00012582921772263944
step: 240, loss: 6.63450118736364e-05
step: 250, loss: 0.00022887035447638482
step: 260, loss: 5.264962601359002e-05
step: 270, loss: 0.0005058696260675788
step: 280, loss: 0.0002468053426127881
step: 290, loss: 0.00010091320291394368
step: 300, loss: 5.315873204381205e-05
step: 310, loss: 2.5461427867412567e-05
step: 320, loss: 5.1646788051584736e-05
step: 330, loss: 0.00043052053661085665
step: 340, loss: 0.00017428940918762237
step: 350, loss: 0.00013258948456496
step: 360, loss: 3.0273899028543383e-05
epoch 17: dev_f1=0.6430379746835443, f1=0.6580310880829016, best_f1=0.6440677966101694
step: 0, loss: 0.00010018340253736824
step: 10, loss: 4.3924901547143236e-05
step: 20, loss: 2.5674034986877814e-05
step: 30, loss: 6.841432332294062e-05
step: 40, loss: 0.00024336593924090266
step: 50, loss: 0.00012323468399699777
step: 60, loss: 3.093365376116708e-05
step: 70, loss: 9.00233571883291e-05
step: 80, loss: 0.0001596044166944921
step: 90, loss: 5.9690719353966415e-05
step: 100, loss: 7.437393651343882e-05
step: 110, loss: 4.674836600315757e-05
step: 120, loss: 2.7986619898001663e-05
step: 130, loss: 7.337419083341956e-05
step: 140, loss: 5.302548743202351e-05
step: 150, loss: 0.00069279910530895
step: 160, loss: 0.0033066561445593834
step: 170, loss: 6.261809903662652e-05
step: 180, loss: 0.0005771237192675471
step: 190, loss: 8.292308484669775e-05
step: 200, loss: 7.555943011539057e-05
step: 210, loss: 6.091120303608477e-05
step: 220, loss: 3.2937477953964844e-05
step: 230, loss: 6.34302559774369e-05
step: 240, loss: 0.00012430557399056852
step: 250, loss: 2.504786243662238e-05
step: 260, loss: 5.8519413869362324e-05
step: 270, loss: 0.00013876678713131696
step: 280, loss: 0.0001098646389436908
step: 290, loss: 0.00011818536586361006
step: 300, loss: 6.300614040810615e-05
step: 310, loss: 0.0006820024573244154
step: 320, loss: 0.00028361339354887605
step: 330, loss: 7.876372546888888e-05
step: 340, loss: 6.06121975579299e-05
step: 350, loss: 4.7206376621033996e-05
step: 360, loss: 0.0009810531046241522
epoch 18: dev_f1=0.6430517711171662, f1=0.6381766381766381, best_f1=0.6440677966101694
step: 0, loss: 0.00013106758706271648
step: 10, loss: 2.7375856006983668e-05
step: 20, loss: 5.766711547039449e-05
step: 30, loss: 2.9770995752187446e-05
step: 40, loss: 2.227289223810658e-05
step: 50, loss: 4.1868621337926015e-05
step: 60, loss: 1.571307257108856e-05
step: 70, loss: 0.0001130286036641337
step: 80, loss: 2.283124740642961e-05
step: 90, loss: 0.016505692154169083
step: 100, loss: 8.312895806739107e-05
step: 110, loss: 5.4267249652184546e-05
step: 120, loss: 0.00025126588298007846
step: 130, loss: 0.0006058735307306051
step: 140, loss: 3.9359725633403286e-05
step: 150, loss: 5.9360358136473224e-05
step: 160, loss: 4.350734889158048e-05
step: 170, loss: 0.0003845011524390429
step: 180, loss: 1.7814047168940306e-05
step: 190, loss: 2.964834129670635e-05
step: 200, loss: 3.3581014577066526e-05
step: 210, loss: 3.835561437881552e-05
step: 220, loss: 0.0001452514698030427
step: 230, loss: 5.427187352324836e-05
step: 240, loss: 0.000650121655780822
step: 250, loss: 0.0002589736832305789
step: 260, loss: 0.00010926136747002602
step: 270, loss: 0.0014625155599787831
step: 280, loss: 3.4404733014525846e-05
step: 290, loss: 3.935697895940393e-05
step: 300, loss: 2.979366763611324e-05
step: 310, loss: 0.003954190295189619
step: 320, loss: 0.0006147106178104877
step: 330, loss: 0.0010112666059285402
step: 340, loss: 3.961809125030413e-05
step: 350, loss: 2.5781400836422108e-05
step: 360, loss: 0.0008315396844409406
epoch 19: dev_f1=0.6520547945205479, f1=0.653295128939828, best_f1=0.653295128939828
step: 0, loss: 4.661281855078414e-05
step: 10, loss: 7.279379497049376e-05
step: 20, loss: 0.0001507634442532435
step: 30, loss: 6.075782948755659e-05
step: 40, loss: 0.00012765686551574618
step: 50, loss: 0.0001837832824094221
step: 60, loss: 2.679831231944263e-05
step: 70, loss: 2.8775917598977685e-05
step: 80, loss: 0.00032861792715266347
step: 90, loss: 0.0005529010086320341
step: 100, loss: 2.1363672203733586e-05
step: 110, loss: 4.6783246943959966e-05
step: 120, loss: 0.00011197776620974764
step: 130, loss: 0.0002462985285092145
step: 140, loss: 4.1159812099067494e-05
step: 150, loss: 6.171431596158072e-05
step: 160, loss: 4.722209996543825e-05
step: 170, loss: 0.0002701524645090103
step: 180, loss: 4.371593604446389e-05
step: 190, loss: 0.0007414256106130779
step: 200, loss: 0.000276724313152954
step: 210, loss: 3.917501089745201e-05
step: 220, loss: 6.32640949334018e-05
step: 230, loss: 0.00047907931730151176
step: 240, loss: 3.097344597335905e-05
step: 250, loss: 2.7841746486956254e-05
step: 260, loss: 8.708097448106855e-05
step: 270, loss: 7.160375389503315e-05
step: 280, loss: 0.002814322244375944
step: 290, loss: 3.964032293879427e-05
step: 300, loss: 5.063232310931198e-05
step: 310, loss: 3.266833664383739e-05
step: 320, loss: 6.234342436073348e-05
step: 330, loss: 3.459527579252608e-05
step: 340, loss: 0.0012214374728500843
step: 350, loss: 8.771463035373017e-05
step: 360, loss: 0.0002106086612911895
epoch 20: dev_f1=0.6521739130434783, f1=0.6478873239436621, best_f1=0.6478873239436621
