cuda
Device: cuda
step: 0, loss: 0.46343299746513367
step: 10, loss: 0.4287063479423523
step: 20, loss: 0.264333575963974
step: 30, loss: 0.2379288673400879
step: 40, loss: 0.2503213584423065
step: 50, loss: 0.21916572749614716
step: 60, loss: 0.14320681989192963
step: 70, loss: 0.17100198566913605
step: 80, loss: 0.05166809633374214
step: 90, loss: 0.1295093446969986
step: 100, loss: 0.13378889858722687
step: 110, loss: 0.3347909152507782
step: 120, loss: 0.19302457571029663
step: 130, loss: 0.12639908492565155
step: 140, loss: 0.2112470418214798
step: 150, loss: 0.2582397758960724
step: 160, loss: 0.3058020770549774
step: 170, loss: 0.23767176270484924
step: 180, loss: 0.11358357965946198
step: 190, loss: 0.2774292230606079
step: 200, loss: 0.16000239551067352
step: 210, loss: 0.14554451406002045
step: 220, loss: 0.037375591695308685
step: 230, loss: 0.22753341495990753
step: 240, loss: 0.10846881568431854
step: 250, loss: 0.17118464410305023
step: 260, loss: 0.03141302242875099
step: 270, loss: 0.13966816663742065
step: 280, loss: 0.12317285686731339
step: 290, loss: 0.21138563752174377
step: 300, loss: 0.13796472549438477
step: 310, loss: 0.16559800505638123
step: 320, loss: 0.20707733929157257
step: 330, loss: 0.04792669042944908
step: 340, loss: 0.016895964741706848
step: 350, loss: 0.1476738005876541
step: 360, loss: 0.1608099341392517
epoch 1: dev_f1=0.4680851063829788, f1=0.4827586206896552, best_f1=0.4827586206896552
step: 0, loss: 0.187387615442276
step: 10, loss: 0.3316287696361542
step: 20, loss: 0.10422956943511963
step: 30, loss: 0.24358001351356506
step: 40, loss: 0.1411808282136917
step: 50, loss: 0.17843692004680634
step: 60, loss: 0.08969992399215698
step: 70, loss: 0.06066596880555153
step: 80, loss: 0.15832176804542542
step: 90, loss: 0.05604444444179535
step: 100, loss: 0.12460809201002121
step: 110, loss: 0.11094072461128235
step: 120, loss: 0.09991372376680374
step: 130, loss: 0.18465960025787354
step: 140, loss: 0.12002283334732056
step: 150, loss: 0.10830555111169815
step: 160, loss: 0.33229032158851624
step: 170, loss: 0.08391610532999039
step: 180, loss: 0.13816416263580322
step: 190, loss: 0.061815045773983
step: 200, loss: 0.18328814208507538
step: 210, loss: 0.03417983278632164
step: 220, loss: 0.09559252113103867
step: 230, loss: 0.11164014041423798
step: 240, loss: 0.14640189707279205
step: 250, loss: 0.12393924593925476
step: 260, loss: 0.0979626402258873
step: 270, loss: 0.16934601962566376
step: 280, loss: 0.08022314310073853
step: 290, loss: 0.1818426251411438
step: 300, loss: 0.21445800364017487
step: 310, loss: 0.04494670778512955
step: 320, loss: 0.11467224359512329
step: 330, loss: 0.052975405007600784
step: 340, loss: 0.2083941251039505
step: 350, loss: 0.18153297901153564
step: 360, loss: 0.08591894805431366
epoch 2: dev_f1=0.5656108597285068, f1=0.5904761904761905, best_f1=0.5904761904761905
step: 0, loss: 0.20229724049568176
step: 10, loss: 0.01891738921403885
step: 20, loss: 0.048533208668231964
step: 30, loss: 0.07869268208742142
step: 40, loss: 0.12290172278881073
step: 50, loss: 0.09035446494817734
step: 60, loss: 0.05468689277768135
step: 70, loss: 0.06621991842985153
step: 80, loss: 0.07648073136806488
step: 90, loss: 0.11826270818710327
step: 100, loss: 0.03942898288369179
step: 110, loss: 0.07751013338565826
step: 120, loss: 0.16717445850372314
step: 130, loss: 0.09648114442825317
step: 140, loss: 0.07691006362438202
step: 150, loss: 0.06004216521978378
step: 160, loss: 0.1286529302597046
step: 170, loss: 0.13385970890522003
step: 180, loss: 0.02905072644352913
step: 190, loss: 0.11304235458374023
step: 200, loss: 0.007078590337187052
step: 210, loss: 0.10907673090696335
step: 220, loss: 0.02568812295794487
step: 230, loss: 0.04615449160337448
step: 240, loss: 0.22313246130943298
step: 250, loss: 0.01876905933022499
step: 260, loss: 0.15360280871391296
step: 270, loss: 0.06415338814258575
step: 280, loss: 0.05528753623366356
step: 290, loss: 0.08721024543046951
step: 300, loss: 0.09935593605041504
step: 310, loss: 0.09516215324401855
step: 320, loss: 0.10876845568418503
step: 330, loss: 0.13356506824493408
step: 340, loss: 0.05146639421582222
step: 350, loss: 0.014006078243255615
step: 360, loss: 0.05456078425049782
epoch 3: dev_f1=0.5791666666666667, f1=0.5743801652892563, best_f1=0.5743801652892563
step: 0, loss: 0.08087832480669022
step: 10, loss: 0.051871150732040405
step: 20, loss: 0.10832887142896652
step: 30, loss: 0.018506573513150215
step: 40, loss: 0.02587587758898735
step: 50, loss: 0.009110020473599434
step: 60, loss: 0.014374413527548313
step: 70, loss: 0.057962220162153244
step: 80, loss: 0.02096407301723957
step: 90, loss: 0.14335393905639648
step: 100, loss: 0.1502663642168045
step: 110, loss: 0.061387304216623306
step: 120, loss: 0.01800372265279293
step: 130, loss: 0.07603255659341812
step: 140, loss: 0.08476190268993378
step: 150, loss: 0.010561692528426647
step: 160, loss: 0.013760961592197418
step: 170, loss: 0.08465089648962021
step: 180, loss: 0.11606819182634354
step: 190, loss: 0.05182478949427605
step: 200, loss: 0.04502743110060692
step: 210, loss: 0.060843098908662796
step: 220, loss: 0.07761722803115845
step: 230, loss: 0.1505836546421051
step: 240, loss: 0.05391588807106018
step: 250, loss: 0.036222077906131744
step: 260, loss: 0.025433624163269997
step: 270, loss: 0.21837589144706726
step: 280, loss: 0.0388568751513958
step: 290, loss: 0.017539426684379578
step: 300, loss: 0.12278727442026138
step: 310, loss: 0.017878158017992973
step: 320, loss: 0.024638984352350235
step: 330, loss: 0.0023485487326979637
step: 340, loss: 0.005019709002226591
step: 350, loss: 0.16862383484840393
step: 360, loss: 0.02695237286388874
epoch 4: dev_f1=0.6411483253588516, f1=0.5994962216624684, best_f1=0.5994962216624684
step: 0, loss: 0.0731687843799591
step: 10, loss: 0.010065063834190369
step: 20, loss: 0.055807460099458694
step: 30, loss: 0.0819425880908966
step: 40, loss: 0.0006236070767045021
step: 50, loss: 0.02307956852018833
step: 60, loss: 0.05023350566625595
step: 70, loss: 0.043009184300899506
step: 80, loss: 0.08717422187328339
step: 90, loss: 0.06806066632270813
step: 100, loss: 0.017983760684728622
step: 110, loss: 0.031234299764037132
step: 120, loss: 0.005163137335330248
step: 130, loss: 0.0038050361908972263
step: 140, loss: 0.018749529495835304
step: 150, loss: 0.058229073882102966
step: 160, loss: 0.004140402656048536
step: 170, loss: 0.03979792818427086
step: 180, loss: 0.11292330175638199
step: 190, loss: 0.0014264429919421673
step: 200, loss: 0.10156907886266708
step: 210, loss: 0.1523580104112625
step: 220, loss: 0.008040458895266056
step: 230, loss: 0.012982315383851528
step: 240, loss: 0.2582318186759949
step: 250, loss: 0.008555658161640167
step: 260, loss: 0.1714996099472046
step: 270, loss: 0.019884411245584488
step: 280, loss: 0.0055265044793486595
step: 290, loss: 0.003389611141756177
step: 300, loss: 0.07220672070980072
step: 310, loss: 0.04082031548023224
step: 320, loss: 0.07912299782037735
step: 330, loss: 0.03058321587741375
step: 340, loss: 0.04187912121415138
step: 350, loss: 0.05417000874876976
step: 360, loss: 0.06645981967449188
epoch 5: dev_f1=0.6595174262734586, f1=0.6505376344086021, best_f1=0.6505376344086021
step: 0, loss: 0.03503827005624771
step: 10, loss: 0.016365718096494675
step: 20, loss: 0.008832035586237907
step: 30, loss: 0.0022481000050902367
step: 40, loss: 0.020501751452684402
step: 50, loss: 0.10721024125814438
step: 60, loss: 0.004567455966025591
step: 70, loss: 0.0009269090951420367
step: 80, loss: 0.0010122573003172874
step: 90, loss: 0.0004312350647523999
step: 100, loss: 0.03335057199001312
step: 110, loss: 0.007915493100881577
step: 120, loss: 0.011888494715094566
step: 130, loss: 0.00329494196921587
step: 140, loss: 0.0063665034249424934
step: 150, loss: 0.009389902465045452
step: 160, loss: 0.006063713226467371
step: 170, loss: 0.00336319487541914
step: 180, loss: 0.03452526032924652
step: 190, loss: 0.0026288777589797974
step: 200, loss: 0.04901328682899475
step: 210, loss: 0.009358033537864685
step: 220, loss: 0.04397827759385109
step: 230, loss: 0.2538864016532898
step: 240, loss: 0.005046952981501818
step: 250, loss: 0.04613986611366272
step: 260, loss: 0.012714482843875885
step: 270, loss: 0.007145924028009176
step: 280, loss: 0.012927285395562649
step: 290, loss: 0.008089330978691578
step: 300, loss: 0.004789664410054684
step: 310, loss: 0.0007043610094115138
step: 320, loss: 0.021056627854704857
step: 330, loss: 0.0036333634052425623
step: 340, loss: 0.009436369873583317
step: 350, loss: 0.01861099898815155
step: 360, loss: 0.08046018332242966
epoch 6: dev_f1=0.6218097447795824, f1=0.6095238095238096, best_f1=0.6505376344086021
step: 0, loss: 0.004765550140291452
step: 10, loss: 0.014956861734390259
step: 20, loss: 0.022787047550082207
step: 30, loss: 0.06930067390203476
step: 40, loss: 0.004243597388267517
step: 50, loss: 0.0009594386210665107
step: 60, loss: 0.0004587791336234659
step: 70, loss: 0.009029082022607327
step: 80, loss: 0.00038121489342302084
step: 90, loss: 0.016899559646844864
step: 100, loss: 0.029691578820347786
step: 110, loss: 0.0010965936817228794
step: 120, loss: 0.0015795707004144788
step: 130, loss: 0.07094541192054749
step: 140, loss: 0.02580328844487667
step: 150, loss: 0.008751523680984974
step: 160, loss: 0.02000240609049797
step: 170, loss: 0.02008574642241001
step: 180, loss: 0.026877325028181076
step: 190, loss: 0.0015857531689107418
step: 200, loss: 0.002324082888662815
step: 210, loss: 0.06881040334701538
step: 220, loss: 0.009783589281141758
step: 230, loss: 0.03821573778986931
step: 240, loss: 0.06878329813480377
step: 250, loss: 0.0037883161567151546
step: 260, loss: 0.019118772819638252
step: 270, loss: 0.001656610518693924
step: 280, loss: 0.00666978070512414
step: 290, loss: 0.0007864480139687657
step: 300, loss: 0.0021559118758887053
step: 310, loss: 0.0019746951293200254
step: 320, loss: 0.00044006409007124603
step: 330, loss: 0.017268197610974312
step: 340, loss: 0.01873115450143814
step: 350, loss: 0.023242373019456863
step: 360, loss: 0.0037952412385493517
epoch 7: dev_f1=0.6313364055299538, f1=0.6171171171171171, best_f1=0.6505376344086021
step: 0, loss: 0.0027310603763908148
step: 10, loss: 0.0037987835239619017
step: 20, loss: 0.0030519512947648764
step: 30, loss: 0.0984686091542244
step: 40, loss: 0.0016599821392446756
step: 50, loss: 0.006907556671649218
step: 60, loss: 0.0012664077803492546
step: 70, loss: 0.0018592083360999823
step: 80, loss: 0.0023155941162258387
step: 90, loss: 0.0022877678275108337
step: 100, loss: 0.04081282392144203
step: 110, loss: 0.002619248116388917
step: 120, loss: 0.01264883577823639
step: 130, loss: 0.011455615982413292
step: 140, loss: 0.0006715254276059568
step: 150, loss: 0.02917535975575447
step: 160, loss: 0.005662255920469761
step: 170, loss: 0.03822954371571541
step: 180, loss: 0.00335842277854681
step: 190, loss: 0.0018985813949257135
step: 200, loss: 0.01947060413658619
step: 210, loss: 0.003229644615203142
step: 220, loss: 0.007013009861111641
step: 230, loss: 0.04114338755607605
step: 240, loss: 0.0034022966865450144
step: 250, loss: 0.0003690279845613986
step: 260, loss: 0.006895869038999081
step: 270, loss: 0.0014491205802187324
step: 280, loss: 0.13644976913928986
step: 290, loss: 0.03648117557168007
step: 300, loss: 0.01175147108733654
step: 310, loss: 0.016703395172953606
step: 320, loss: 0.09285978227853775
step: 330, loss: 0.0337890088558197
step: 340, loss: 0.013601158745586872
step: 350, loss: 0.054405052214860916
step: 360, loss: 0.05277153104543686
epoch 8: dev_f1=0.5929648241206029, f1=0.5767195767195766, best_f1=0.6505376344086021
step: 0, loss: 0.010217981413006783
step: 10, loss: 0.000698423245921731
step: 20, loss: 0.042883601039648056
step: 30, loss: 0.00023886450799182057
step: 40, loss: 0.1725606918334961
step: 50, loss: 0.005512639880180359
step: 60, loss: 0.0007495272438973188
step: 70, loss: 0.0006696013151668012
step: 80, loss: 0.0042863693088293076
step: 90, loss: 0.00035963047412224114
step: 100, loss: 0.0006603932706639171
step: 110, loss: 0.0004839530447497964
step: 120, loss: 0.0022792075760662556
step: 130, loss: 0.0012198106851428747
step: 140, loss: 0.00048439798410981894
step: 150, loss: 0.0002010854659602046
step: 160, loss: 0.0012329327873885632
step: 170, loss: 0.0008630885276943445
step: 180, loss: 0.002215472050011158
step: 190, loss: 0.026541726663708687
step: 200, loss: 0.001102630514651537
step: 210, loss: 0.0003193063021171838
step: 220, loss: 0.15758080780506134
step: 230, loss: 0.01037946529686451
step: 240, loss: 0.003878142684698105
step: 250, loss: 0.002873841440305114
step: 260, loss: 0.0002630367234814912
step: 270, loss: 0.002399383345618844
step: 280, loss: 0.0050504026003181934
step: 290, loss: 0.016114836558699608
step: 300, loss: 0.005945474840700626
step: 310, loss: 0.00027870715712197125
step: 320, loss: 0.0005378675414249301
step: 330, loss: 0.008349478244781494
step: 340, loss: 0.00016060918278526515
step: 350, loss: 0.008280974812805653
step: 360, loss: 0.06485319137573242
epoch 9: dev_f1=0.6103542234332424, f1=0.6256983240223463, best_f1=0.6505376344086021
step: 0, loss: 0.003697614884003997
step: 10, loss: 0.0004414143040776253
step: 20, loss: 0.0005027293809689581
step: 30, loss: 0.0004777776193805039
step: 40, loss: 0.0023276787251234055
step: 50, loss: 0.0027738839853554964
step: 60, loss: 0.0005077782552689314
step: 70, loss: 0.02411942556500435
step: 80, loss: 0.0002893622440751642
step: 90, loss: 0.0014825838152319193
step: 100, loss: 0.0062587377615273
step: 110, loss: 0.002511965576559305
step: 120, loss: 0.00929251778870821
step: 130, loss: 0.00016585997946094722
step: 140, loss: 0.0034414215479046106
step: 150, loss: 0.0006647510454058647
step: 160, loss: 0.005927434656769037
step: 170, loss: 0.0003569586551748216
step: 180, loss: 0.00029643025482073426
step: 190, loss: 0.0008928519091568887
step: 200, loss: 0.008339705877006054
step: 210, loss: 0.0021280008368194103
step: 220, loss: 0.0006839626003056765
step: 230, loss: 0.009071019478142262
step: 240, loss: 0.0005486204754561186
step: 250, loss: 0.0002884425630327314
step: 260, loss: 0.00024738951469771564
step: 270, loss: 0.008118554018437862
step: 280, loss: 0.0007760485750623047
step: 290, loss: 0.00025613189791329205
step: 300, loss: 0.002176354406401515
step: 310, loss: 0.005655917339026928
step: 320, loss: 0.008153456263244152
step: 330, loss: 0.0017976578092202544
step: 340, loss: 0.03347594663500786
step: 350, loss: 0.00033885714947246015
step: 360, loss: 0.0030365404672920704
epoch 10: dev_f1=0.6265060240963856, f1=0.546031746031746, best_f1=0.6505376344086021
step: 0, loss: 0.08009462058544159
step: 10, loss: 0.00287628429941833
step: 20, loss: 0.0014079794054850936
step: 30, loss: 0.00412050262093544
step: 40, loss: 0.00017003985703922808
step: 50, loss: 0.003548098262399435
step: 60, loss: 0.002669182140380144
step: 70, loss: 0.10599303990602493
step: 80, loss: 0.038351722061634064
step: 90, loss: 0.0012556276051327586
step: 100, loss: 0.011175223626196384
step: 110, loss: 0.0014679053565487266
step: 120, loss: 0.0033111227676272392
step: 130, loss: 0.07704421877861023
step: 140, loss: 0.0008023307309485972
step: 150, loss: 0.0010882067726925015
step: 160, loss: 0.0005474525387398899
step: 170, loss: 0.0025579112116247416
step: 180, loss: 0.0006278880755417049
step: 190, loss: 0.0014058739179745317
step: 200, loss: 0.0011021837126463652
step: 210, loss: 0.0003549726970959455
step: 220, loss: 0.0007157425279729068
step: 230, loss: 0.0020058469381183386
step: 240, loss: 0.008752389810979366
step: 250, loss: 0.0010154194897040725
step: 260, loss: 0.0004530925361905247
step: 270, loss: 0.06420745700597763
step: 280, loss: 0.005104420706629753
step: 290, loss: 0.0019077229080721736
step: 300, loss: 0.0032506906427443027
step: 310, loss: 0.0005380866350606084
step: 320, loss: 0.030230846256017685
step: 330, loss: 0.0007140319212339818
step: 340, loss: 0.002802761271595955
step: 350, loss: 0.00396301643922925
step: 360, loss: 0.0005423772381618619
epoch 11: dev_f1=0.64, f1=0.6104218362282878, best_f1=0.6505376344086021
step: 0, loss: 0.0005574589595198631
step: 10, loss: 0.0007326193153858185
step: 20, loss: 0.0003432194935157895
step: 30, loss: 0.007055253256112337
step: 40, loss: 0.0031538326293230057
step: 50, loss: 0.0005561238504014909
step: 60, loss: 0.0022667874582111835
step: 70, loss: 0.0008629512740299106
step: 80, loss: 0.0019843089394271374
step: 90, loss: 0.035527899861335754
step: 100, loss: 0.00024246361863333732
step: 110, loss: 4.634369906852953e-05
step: 120, loss: 0.00024798011872917414
step: 130, loss: 0.0008740524062886834
step: 140, loss: 0.0011016384232789278
step: 150, loss: 0.00033998480648733675
step: 160, loss: 0.0005667445948347449
step: 170, loss: 0.00025517059839330614
step: 180, loss: 0.04365032911300659
step: 190, loss: 0.0347156748175621
step: 200, loss: 0.00022701031411997974
step: 210, loss: 0.0017463724361732602
step: 220, loss: 0.0008166952757164836
step: 230, loss: 0.00015896388504188508
step: 240, loss: 0.0011086839949712157
step: 250, loss: 0.00017452743486501276
step: 260, loss: 0.06046513468027115
step: 270, loss: 0.002278829226270318
step: 280, loss: 0.0036208333913236856
step: 290, loss: 0.010415684431791306
step: 300, loss: 0.00010305700561730191
step: 310, loss: 0.0032337598968297243
step: 320, loss: 0.05470765754580498
step: 330, loss: 0.00041056398185901344
step: 340, loss: 8.086775051197037e-05
step: 350, loss: 0.00015078348224051297
step: 360, loss: 0.0003378265246283263
epoch 12: dev_f1=0.6462395543175486, f1=0.5606936416184971, best_f1=0.6505376344086021
step: 0, loss: 7.354760600719601e-05
step: 10, loss: 0.0003143856883980334
step: 20, loss: 0.0006355639779940248
step: 30, loss: 0.006583972834050655
step: 40, loss: 0.0025085473898798227
step: 50, loss: 0.00016547992709092796
step: 60, loss: 0.0008189806248992682
step: 70, loss: 4.598386658472009e-05
step: 80, loss: 0.00013774468970950693
step: 90, loss: 0.0028209229931235313
step: 100, loss: 0.0032597570680081844
step: 110, loss: 0.00013195893552619964
step: 120, loss: 0.00021953758550807834
step: 130, loss: 0.00010908295371336862
step: 140, loss: 0.00020327622769400477
step: 150, loss: 6.394364027073607e-05
step: 160, loss: 0.00016430883260909468
step: 170, loss: 0.0007303529419004917
step: 180, loss: 4.9900281737791374e-05
step: 190, loss: 8.304489165311679e-05
step: 200, loss: 9.194246376864612e-05
step: 210, loss: 0.0015952980611473322
step: 220, loss: 0.0002782579103950411
step: 230, loss: 0.00010870492405956611
step: 240, loss: 0.00045773261808790267
step: 250, loss: 0.0006796485977247357
step: 260, loss: 0.0002919865073636174
step: 270, loss: 0.00023275135026779026
step: 280, loss: 0.0020666185300797224
step: 290, loss: 0.00018468998314347118
step: 300, loss: 0.0012984275817871094
step: 310, loss: 0.0004701307916548103
step: 320, loss: 0.0002670074172783643
step: 330, loss: 0.001076556509360671
step: 340, loss: 0.00034436641726642847
step: 350, loss: 0.00010844230564543977
step: 360, loss: 2.251149999210611e-05
epoch 13: dev_f1=0.6135693215339233, f1=0.5626911314984709, best_f1=0.6505376344086021
step: 0, loss: 0.00022375966364052147
step: 10, loss: 0.0001538741635158658
step: 20, loss: 0.0006736719515174627
step: 30, loss: 0.0002868270385079086
step: 40, loss: 5.662095281877555e-05
step: 50, loss: 0.00019304738088976592
step: 60, loss: 0.00016449019312858582
step: 70, loss: 0.00047402968630194664
step: 80, loss: 0.0004970448208041489
step: 90, loss: 0.00015018711565062404
step: 100, loss: 0.0006452957750298083
step: 110, loss: 0.00015929968503769487
step: 120, loss: 0.0022774210665374994
step: 130, loss: 0.00028608011780306697
step: 140, loss: 0.0008197351126000285
step: 150, loss: 0.0018880650168284774
step: 160, loss: 0.00018303071556147188
step: 170, loss: 0.0004283292219042778
step: 180, loss: 0.00029420928331092
step: 190, loss: 4.214849104755558e-05
step: 200, loss: 0.0001976386265596375
step: 210, loss: 9.284583939006552e-05
step: 220, loss: 5.2003721066284925e-05
step: 230, loss: 1.847720704972744e-05
step: 240, loss: 0.0002671089314389974
step: 250, loss: 0.13720965385437012
step: 260, loss: 0.002328168833628297
step: 270, loss: 7.140117668313906e-05
step: 280, loss: 9.608211985323578e-05
step: 290, loss: 8.638564759166911e-05
step: 300, loss: 0.0022021085023880005
step: 310, loss: 0.0026012822054326534
step: 320, loss: 0.0005921968258917332
step: 330, loss: 0.0009004191379062831
step: 340, loss: 7.496645412174985e-05
step: 350, loss: 0.17535583674907684
step: 360, loss: 9.542476618662477e-05
epoch 14: dev_f1=0.6219839142091154, f1=0.5958549222797928, best_f1=0.6505376344086021
step: 0, loss: 0.013519981876015663
step: 10, loss: 0.0005423414404504001
step: 20, loss: 0.00020300864707678556
step: 30, loss: 0.00017992175708059222
step: 40, loss: 0.0002174440014641732
step: 50, loss: 7.313413516385481e-05
step: 60, loss: 9.808015602175146e-05
step: 70, loss: 0.09641865640878677
step: 80, loss: 0.0010241558775305748
step: 90, loss: 0.002647297689691186
step: 100, loss: 0.000178911883267574
step: 110, loss: 0.0002972582879010588
step: 120, loss: 0.14037901163101196
step: 130, loss: 0.0035636830143630505
step: 140, loss: 0.00019026192603632808
step: 150, loss: 0.0010851045371964574
step: 160, loss: 0.00030051180510781705
step: 170, loss: 0.0003297837101854384
step: 180, loss: 0.0010508764535188675
step: 190, loss: 0.00036919419653713703
step: 200, loss: 7.719101995462552e-05
step: 210, loss: 0.005851603113114834
step: 220, loss: 0.00016002827032934874
step: 230, loss: 0.00011844991968246177
step: 240, loss: 0.0014479176606982946
step: 250, loss: 0.046368665993213654
step: 260, loss: 2.7797172151622362e-05
step: 270, loss: 0.00015734480984974653
step: 280, loss: 0.0005055249785073102
step: 290, loss: 0.0009056920534931123
step: 300, loss: 0.00023234215041156858
step: 310, loss: 0.02401837520301342
step: 320, loss: 0.0005834426847286522
step: 330, loss: 0.0002735337184276432
step: 340, loss: 0.00012324866838753223
step: 350, loss: 0.000923856976442039
step: 360, loss: 8.92667449079454e-05
epoch 15: dev_f1=0.6086956521739131, f1=0.6005221932114883, best_f1=0.6505376344086021
step: 0, loss: 0.0005262924823909998
step: 10, loss: 0.0004173825145699084
step: 20, loss: 0.0004149247251916677
step: 30, loss: 7.344157347688451e-05
step: 40, loss: 0.00038085022242739797
step: 50, loss: 0.00045439531095325947
step: 60, loss: 0.0008641842287033796
step: 70, loss: 0.00024195478181354702
step: 80, loss: 0.0005160978180356324
step: 90, loss: 4.9933165428228676e-05
step: 100, loss: 0.004205799661576748
step: 110, loss: 0.00010641278640832752
step: 120, loss: 8.748409163672477e-05
step: 130, loss: 4.8291858547599986e-05
step: 140, loss: 0.00013657819363288581
step: 150, loss: 0.00029068414005450904
step: 160, loss: 0.0006257581408135593
step: 170, loss: 0.0003400748537387699
step: 180, loss: 0.0002911428746301681
step: 190, loss: 0.03902048245072365
step: 200, loss: 0.0003251762827858329
step: 210, loss: 0.00023187240003608167
step: 220, loss: 5.595862239715643e-05
step: 230, loss: 0.008440935984253883
step: 240, loss: 0.029293419793248177
step: 250, loss: 0.012261088006198406
step: 260, loss: 0.0008629308431409299
step: 270, loss: 0.0015285597182810307
step: 280, loss: 0.0005187653005123138
step: 290, loss: 6.11743307672441e-05
step: 300, loss: 0.0004858395841438323
step: 310, loss: 0.00023682658502366394
step: 320, loss: 0.00020381085050757974
step: 330, loss: 5.222533945925534e-05
step: 340, loss: 0.0008779760100878775
step: 350, loss: 0.0015768302837386727
step: 360, loss: 0.0003656062763184309
epoch 16: dev_f1=0.6352941176470588, f1=0.6028985507246377, best_f1=0.6505376344086021
step: 0, loss: 0.0014376527396962047
step: 10, loss: 0.00038125229184515774
step: 20, loss: 0.0003732939367182553
step: 30, loss: 0.0013116723857820034
step: 40, loss: 0.00021768109581898898
step: 50, loss: 0.00017965855658985674
step: 60, loss: 0.00022684216673951596
step: 70, loss: 0.00020759445033036172
step: 80, loss: 0.00038949563167989254
step: 90, loss: 8.363580127479509e-05
step: 100, loss: 0.0002609306247904897
step: 110, loss: 8.902818080969155e-05
step: 120, loss: 7.093270687619224e-05
step: 130, loss: 6.027632480254397e-05
step: 140, loss: 9.107220103032887e-05
step: 150, loss: 0.00015914136020001024
step: 160, loss: 0.0001776406425051391
step: 170, loss: 6.448141357395798e-05
step: 180, loss: 0.0007266182219609618
step: 190, loss: 0.00021806787117384374
step: 200, loss: 0.0007011470152065158
step: 210, loss: 9.572674753144383e-05
step: 220, loss: 0.0008766105747781694
step: 230, loss: 0.0006913933320902288
step: 240, loss: 0.00017670606030151248
step: 250, loss: 0.0005057086236774921
step: 260, loss: 0.0003785603039432317
step: 270, loss: 0.0007470419513992965
step: 280, loss: 0.00011697843001456931
step: 290, loss: 0.00012353609781712294
step: 300, loss: 2.0130670236540027e-05
step: 310, loss: 0.00010416945588076487
step: 320, loss: 7.904842641437426e-05
step: 330, loss: 0.0003516856231726706
step: 340, loss: 0.007208253722637892
step: 350, loss: 6.699310324620456e-05
step: 360, loss: 0.0013680440606549382
epoch 17: dev_f1=0.6333333333333333, f1=0.6049046321525886, best_f1=0.6505376344086021
step: 0, loss: 0.00011939789692405611
step: 10, loss: 3.519380697980523e-05
step: 20, loss: 3.501926039461978e-05
step: 30, loss: 0.00011586918117245659
step: 40, loss: 0.000151450585690327
step: 50, loss: 3.345251388964243e-05
step: 60, loss: 0.01666118949651718
step: 70, loss: 0.00025769873172976077
step: 80, loss: 0.0001537771022412926
step: 90, loss: 0.00026082422118633986
step: 100, loss: 1.7691047105472535e-05
step: 110, loss: 0.00011161984730279073
step: 120, loss: 2.8244034183444455e-05
step: 130, loss: 0.002867107279598713
step: 140, loss: 0.00034139526542276144
step: 150, loss: 0.00012115525896660984
step: 160, loss: 0.0002947013999801129
step: 170, loss: 4.689559864345938e-05
step: 180, loss: 0.00018805472063831985
step: 190, loss: 0.018262261524796486
step: 200, loss: 2.9905178962508217e-05
step: 210, loss: 6.505595956696197e-05
step: 220, loss: 0.00011044925486203283
step: 230, loss: 0.00012772498303093016
step: 240, loss: 4.4733558752341196e-05
step: 250, loss: 5.367134144762531e-05
step: 260, loss: 6.13001175224781e-05
step: 270, loss: 1.8112010366166942e-05
step: 280, loss: 0.00013674507499672472
step: 290, loss: 0.0006920648738741875
step: 300, loss: 0.0006424191524274647
step: 310, loss: 0.00017565503367222846
step: 320, loss: 0.00010421526530990377
step: 330, loss: 0.03199050575494766
step: 340, loss: 0.00022075418382883072
step: 350, loss: 0.000336375116603449
step: 360, loss: 7.283889135578647e-05
epoch 18: dev_f1=0.5957446808510638, f1=0.5919003115264797, best_f1=0.6505376344086021
step: 0, loss: 0.011982732452452183
step: 10, loss: 4.2405896238051355e-05
step: 20, loss: 3.337769885547459e-05
step: 30, loss: 1.535914998385124e-05
step: 40, loss: 1.9900086044799536e-05
step: 50, loss: 1.4353404367284384e-05
step: 60, loss: 0.0005367840058170259
step: 70, loss: 2.143394340237137e-05
step: 80, loss: 5.4702213674318045e-05
step: 90, loss: 2.954703086288646e-05
step: 100, loss: 5.756147947977297e-05
step: 110, loss: 3.733882840606384e-05
step: 120, loss: 0.0005638525472022593
step: 130, loss: 2.7327414500177838e-05
step: 140, loss: 8.307438110932708e-05
step: 150, loss: 6.0099013353465125e-05
step: 160, loss: 5.427483483799733e-05
step: 170, loss: 3.403159644221887e-05
step: 180, loss: 3.0172985134413466e-05
step: 190, loss: 9.358559327665716e-05
step: 200, loss: 4.799802991328761e-05
step: 210, loss: 0.01947684958577156
step: 220, loss: 0.0017733662389218807
step: 230, loss: 2.938709076261148e-05
step: 240, loss: 0.00010362423199694604
step: 250, loss: 0.0005575614632107317
step: 260, loss: 0.00015990296378731728
step: 270, loss: 0.0001802570332074538
step: 280, loss: 7.526014087488875e-05
step: 290, loss: 6.232529995031655e-05
step: 300, loss: 7.149649900384247e-05
step: 310, loss: 0.0005202034953981638
step: 320, loss: 2.886762740672566e-05
step: 330, loss: 7.286979962373152e-05
step: 340, loss: 0.00016002095071598887
step: 350, loss: 0.0002798777131829411
step: 360, loss: 9.679006325313821e-05
epoch 19: dev_f1=0.6292134831460674, f1=0.6022099447513812, best_f1=0.6505376344086021
step: 0, loss: 2.0785721062566154e-05
step: 10, loss: 0.00010322096932213753
step: 20, loss: 8.963581058196723e-05
step: 30, loss: 0.0008836152846924961
step: 40, loss: 2.3460186639567837e-05
step: 50, loss: 7.528239075327292e-05
step: 60, loss: 0.001957520144060254
step: 70, loss: 0.0006936407298780978
step: 80, loss: 0.0008927081362344325
step: 90, loss: 3.011300759681035e-05
step: 100, loss: 2.2153421014081687e-05
step: 110, loss: 0.0001446827664040029
step: 120, loss: 0.005213667638599873
step: 130, loss: 8.651999814901501e-05
step: 140, loss: 0.00012998633610550314
step: 150, loss: 0.0002657201839610934
step: 160, loss: 0.0005292373825795949
step: 170, loss: 0.00011129771155538037
step: 180, loss: 4.198054375592619e-05
step: 190, loss: 0.00014162859588395804
step: 200, loss: 0.00013661909906659275
step: 210, loss: 0.0008577407570555806
step: 220, loss: 9.116710134549066e-05
step: 230, loss: 0.0002438179508317262
step: 240, loss: 6.108450179453939e-05
step: 250, loss: 0.000348120549460873
step: 260, loss: 0.00012771881301887333
step: 270, loss: 1.4759457371837925e-05
step: 280, loss: 0.0007156511419452727
step: 290, loss: 0.0003050053201150149
step: 300, loss: 3.993178688688204e-05
step: 310, loss: 3.915431079803966e-05
step: 320, loss: 2.81694683508249e-05
step: 330, loss: 0.06331225484609604
step: 340, loss: 5.361755029298365e-05
step: 350, loss: 5.9879119362449273e-05
step: 360, loss: 6.284135452006012e-05
epoch 20: dev_f1=0.6350974930362117, f1=0.5989010989010989, best_f1=0.6505376344086021
