cuda
Device: cuda
step: 0, loss: 0.6892151236534119
step: 10, loss: 0.26040515303611755
step: 20, loss: 0.22886773943901062
step: 30, loss: 0.14208954572677612
step: 40, loss: 0.3186567723751068
step: 50, loss: 0.24717120826244354
step: 60, loss: 0.3047238290309906
step: 70, loss: 0.02757394313812256
step: 80, loss: 0.16013821959495544
step: 90, loss: 0.25819605588912964
step: 100, loss: 0.14166082441806793
step: 110, loss: 0.03141907602548599
step: 120, loss: 0.05127808079123497
step: 130, loss: 0.23578399419784546
step: 140, loss: 0.34414446353912354
step: 150, loss: 0.1550353467464447
step: 160, loss: 0.03640729561448097
step: 170, loss: 0.04510536789894104
step: 180, loss: 0.31742843985557556
step: 190, loss: 0.45076072216033936
step: 200, loss: 0.30995190143585205
step: 210, loss: 0.13596752285957336
step: 220, loss: 0.1452215313911438
step: 230, loss: 0.22903205454349518
step: 240, loss: 0.1326420158147812
step: 250, loss: 0.03320344164967537
step: 260, loss: 0.2245604693889618
step: 270, loss: 0.05533900856971741
step: 280, loss: 0.39486056566238403
step: 290, loss: 0.1976621299982071
step: 300, loss: 0.3756868243217468
step: 310, loss: 0.06366593390703201
step: 320, loss: 0.21465900540351868
step: 330, loss: 0.2615795135498047
step: 340, loss: 0.22731073200702667
step: 350, loss: 0.07089361548423767
step: 360, loss: 0.20955030620098114
epoch 1: dev_f1=0.3220892274211099, f1=0.3326226012793177, best_f1=0.3326226012793177
step: 0, loss: 0.23337601125240326
step: 10, loss: 0.18190120160579681
step: 20, loss: 0.01667981781065464
step: 30, loss: 0.1260187327861786
step: 40, loss: 0.31765908002853394
step: 50, loss: 0.13914912939071655
step: 60, loss: 0.136913001537323
step: 70, loss: 0.1583687961101532
step: 80, loss: 0.042549554258584976
step: 90, loss: 0.12750999629497528
step: 100, loss: 0.4040212333202362
step: 110, loss: 0.1563979983329773
step: 120, loss: 0.2574346363544464
step: 130, loss: 0.10493478178977966
step: 140, loss: 0.15408571064472198
step: 150, loss: 0.18013936281204224
step: 160, loss: 0.3143461346626282
step: 170, loss: 0.22260341048240662
step: 180, loss: 0.37184083461761475
step: 190, loss: 0.05479191243648529
step: 200, loss: 0.16051669418811798
step: 210, loss: 0.09290128201246262
step: 220, loss: 0.24514462053775787
step: 230, loss: 0.04113065451383591
step: 240, loss: 0.04054107889533043
step: 250, loss: 0.18705438077449799
step: 260, loss: 0.028170129284262657
step: 270, loss: 0.1182740181684494
step: 280, loss: 0.05884088575839996
step: 290, loss: 0.05081061273813248
step: 300, loss: 0.16384755074977875
step: 310, loss: 0.20702412724494934
step: 320, loss: 0.41773808002471924
step: 330, loss: 0.23371459543704987
step: 340, loss: 0.1822909265756607
step: 350, loss: 0.10854038596153259
step: 360, loss: 0.1588231325149536
epoch 2: dev_f1=0.5659472422062349, f1=0.5639810426540284, best_f1=0.5639810426540284
step: 0, loss: 0.1648409068584442
step: 10, loss: 0.008157129399478436
step: 20, loss: 0.22474931180477142
step: 30, loss: 0.04188251495361328
step: 40, loss: 0.06808420270681381
step: 50, loss: 0.2482183873653412
step: 60, loss: 0.09910894185304642
step: 70, loss: 0.16206827759742737
step: 80, loss: 0.16249199211597443
step: 90, loss: 0.13331462442874908
step: 100, loss: 0.3556298017501831
step: 110, loss: 0.08410406857728958
step: 120, loss: 0.11680403351783752
step: 130, loss: 0.18028420209884644
step: 140, loss: 0.1116851270198822
step: 150, loss: 0.07136790454387665
step: 160, loss: 0.01411551795899868
step: 170, loss: 0.04288504645228386
step: 180, loss: 0.06592681258916855
step: 190, loss: 0.12638187408447266
step: 200, loss: 0.14009562134742737
step: 210, loss: 0.033307645469903946
step: 220, loss: 0.025903725996613503
step: 230, loss: 0.13396726548671722
step: 240, loss: 0.06091196462512016
step: 250, loss: 0.013516795821487904
step: 260, loss: 0.17424386739730835
step: 270, loss: 0.48059993982315063
step: 280, loss: 0.10464408248662949
step: 290, loss: 0.10525892674922943
step: 300, loss: 0.05342996492981911
step: 310, loss: 0.469489723443985
step: 320, loss: 0.08644808828830719
step: 330, loss: 0.18232306838035583
step: 340, loss: 0.2689911127090454
step: 350, loss: 0.12865892052650452
step: 360, loss: 0.016347583383321762
epoch 3: dev_f1=0.647814910025707, f1=0.6203473945409429, best_f1=0.6203473945409429
step: 0, loss: 0.048945073038339615
step: 10, loss: 0.16524538397789001
step: 20, loss: 0.008587853983044624
step: 30, loss: 0.10822045058012009
step: 40, loss: 0.17370904982089996
step: 50, loss: 0.035320669412612915
step: 60, loss: 0.13797271251678467
step: 70, loss: 0.027785582467913628
step: 80, loss: 0.06463094800710678
step: 90, loss: 0.01698356121778488
step: 100, loss: 0.07671665400266647
step: 110, loss: 0.02335832267999649
step: 120, loss: 0.020912056788802147
step: 130, loss: 0.10297520458698273
step: 140, loss: 0.16616681218147278
step: 150, loss: 0.07329212129116058
step: 160, loss: 0.20604528486728668
step: 170, loss: 0.12273024767637253
step: 180, loss: 0.019731977954506874
step: 190, loss: 0.16451071202754974
step: 200, loss: 0.06142675504088402
step: 210, loss: 0.02981911413371563
step: 220, loss: 0.024023594334721565
step: 230, loss: 0.1341777741909027
step: 240, loss: 0.009112623520195484
step: 250, loss: 0.0887368842959404
step: 260, loss: 0.23071153461933136
step: 270, loss: 0.038870420306921005
step: 280, loss: 0.027317730709910393
step: 290, loss: 0.09803689271211624
step: 300, loss: 0.0396154411137104
step: 310, loss: 0.0032377049792557955
step: 320, loss: 0.036989882588386536
step: 330, loss: 0.042433369904756546
step: 340, loss: 0.04056061431765556
step: 350, loss: 0.08909276127815247
step: 360, loss: 0.013256206177175045
epoch 4: dev_f1=0.6315789473684211, f1=0.6551724137931034, best_f1=0.6203473945409429
step: 0, loss: 0.02981553040444851
step: 10, loss: 0.01806538924574852
step: 20, loss: 0.38287511467933655
step: 30, loss: 0.016670433804392815
step: 40, loss: 0.09207313507795334
step: 50, loss: 0.016821319237351418
step: 60, loss: 0.23015601933002472
step: 70, loss: 0.03694536164402962
step: 80, loss: 0.13203227519989014
step: 90, loss: 0.00915299542248249
step: 100, loss: 0.0047110384330153465
step: 110, loss: 0.019805826246738434
step: 120, loss: 0.1190863847732544
step: 130, loss: 0.009345972910523415
step: 140, loss: 0.07493172585964203
step: 150, loss: 0.046953510493040085
step: 160, loss: 0.00364074413664639
step: 170, loss: 0.049089331179857254
step: 180, loss: 0.027535652741789818
step: 190, loss: 0.052470944821834564
step: 200, loss: 0.0009850047063082457
step: 210, loss: 0.10906753689050674
step: 220, loss: 0.18351376056671143
step: 230, loss: 0.012318901717662811
step: 240, loss: 0.0030044603627175093
step: 250, loss: 0.010692433454096317
step: 260, loss: 0.027760887518525124
step: 270, loss: 0.06091779097914696
step: 280, loss: 0.01673963852226734
step: 290, loss: 0.04228246584534645
step: 300, loss: 0.07028379291296005
step: 310, loss: 0.021350011229515076
step: 320, loss: 0.029439320787787437
step: 330, loss: 0.006740114651620388
step: 340, loss: 0.0264163538813591
step: 350, loss: 0.03326306492090225
step: 360, loss: 0.012163272127509117
epoch 5: dev_f1=0.631868131868132, f1=0.6612466124661247, best_f1=0.6203473945409429
step: 0, loss: 0.1166054829955101
step: 10, loss: 0.015357752330601215
step: 20, loss: 0.003790825605392456
step: 30, loss: 0.0012994528515264392
step: 40, loss: 0.003613272914662957
step: 50, loss: 0.00929843820631504
step: 60, loss: 0.007651156280189753
step: 70, loss: 0.16434220969676971
step: 80, loss: 0.05580570176243782
step: 90, loss: 0.009611275978386402
step: 100, loss: 0.11223068833351135
step: 110, loss: 0.0033462150022387505
step: 120, loss: 0.002964944113045931
step: 130, loss: 0.00526799401268363
step: 140, loss: 0.0015316077042371035
step: 150, loss: 0.13701951503753662
step: 160, loss: 0.028767665848135948
step: 170, loss: 0.04280216991901398
step: 180, loss: 0.11483770608901978
step: 190, loss: 0.006788991391658783
step: 200, loss: 0.08752336353063583
step: 210, loss: 0.05215153470635414
step: 220, loss: 0.044636134058237076
step: 230, loss: 0.04028855264186859
step: 240, loss: 0.16564983129501343
step: 250, loss: 0.014191669411957264
step: 260, loss: 0.027235256507992744
step: 270, loss: 0.011148461140692234
step: 280, loss: 0.08546044677495956
step: 290, loss: 0.07896511256694794
step: 300, loss: 0.02093154937028885
step: 310, loss: 0.06094807758927345
step: 320, loss: 0.03535452112555504
step: 330, loss: 0.0007714941166341305
step: 340, loss: 0.005365489516407251
step: 350, loss: 0.009710476733744144
step: 360, loss: 0.015414497815072536
epoch 6: dev_f1=0.6666666666666666, f1=0.6532663316582915, best_f1=0.6532663316582915
step: 0, loss: 0.052671730518341064
step: 10, loss: 0.020955746993422508
step: 20, loss: 0.0005676805740222335
step: 30, loss: 0.013723510317504406
step: 40, loss: 0.056730978190898895
step: 50, loss: 0.059582579880952835
step: 60, loss: 0.01361836027354002
step: 70, loss: 0.005206403322517872
step: 80, loss: 0.013279754668474197
step: 90, loss: 0.013991540297865868
step: 100, loss: 0.015320326201617718
step: 110, loss: 0.0029592495411634445
step: 120, loss: 0.0012383742723613977
step: 130, loss: 0.002156333066523075
step: 140, loss: 0.06274793297052383
step: 150, loss: 0.0005994655075483024
step: 160, loss: 0.059113696217536926
step: 170, loss: 0.11438976973295212
step: 180, loss: 0.04740530624985695
step: 190, loss: 0.0008065002621151507
step: 200, loss: 0.0027033817023038864
step: 210, loss: 0.002110461238771677
step: 220, loss: 0.008631832897663116
step: 230, loss: 0.003876024391502142
step: 240, loss: 0.0034337162505835295
step: 250, loss: 0.17310991883277893
step: 260, loss: 0.06281977891921997
step: 270, loss: 0.1663707047700882
step: 280, loss: 0.04080728068947792
step: 290, loss: 0.000532531354110688
step: 300, loss: 0.03762779384851456
step: 310, loss: 0.008806891739368439
step: 320, loss: 0.0007457445608451962
step: 330, loss: 0.18589147925376892
step: 340, loss: 0.005623943172395229
step: 350, loss: 0.003994557075202465
step: 360, loss: 0.0025333999656140804
epoch 7: dev_f1=0.6914153132250579, f1=0.6539379474940334, best_f1=0.6539379474940334
step: 0, loss: 0.01745305396616459
step: 10, loss: 0.008343980647623539
step: 20, loss: 0.007106953766196966
step: 30, loss: 0.0037400596775114536
step: 40, loss: 0.0006999487522989511
step: 50, loss: 0.0030754979234188795
step: 60, loss: 0.0070159947499632835
step: 70, loss: 0.00914681050926447
step: 80, loss: 0.0015970490640029311
step: 90, loss: 0.002494191750884056
step: 100, loss: 0.00037058425368741155
step: 110, loss: 0.0017979403492063284
step: 120, loss: 0.030027415603399277
step: 130, loss: 0.003975242841988802
step: 140, loss: 0.03178327530622482
step: 150, loss: 0.010701203718781471
step: 160, loss: 0.0004262263828422874
step: 170, loss: 0.0020376122556626797
step: 180, loss: 0.0100057702511549
step: 190, loss: 0.0012966044014319777
step: 200, loss: 0.04021986201405525
step: 210, loss: 0.0016261726850643754
step: 220, loss: 0.09004013985395432
step: 230, loss: 0.026301521807909012
step: 240, loss: 0.026086285710334778
step: 250, loss: 0.008889089338481426
step: 260, loss: 0.01814330741763115
step: 270, loss: 0.01338118501007557
step: 280, loss: 0.0013872046256437898
step: 290, loss: 0.00142950308509171
step: 300, loss: 0.051220644265413284
step: 310, loss: 0.18352985382080078
step: 320, loss: 0.0479174368083477
step: 330, loss: 0.03617723286151886
step: 340, loss: 0.03199312463402748
step: 350, loss: 0.002630312694236636
step: 360, loss: 0.003980766050517559
epoch 8: dev_f1=0.6422535211267607, f1=0.6050420168067228, best_f1=0.6539379474940334
step: 0, loss: 0.0013465776573866606
step: 10, loss: 0.0018759650411084294
step: 20, loss: 0.003452188102528453
step: 30, loss: 0.01486118882894516
step: 40, loss: 0.0008662909385748208
step: 50, loss: 0.021892011165618896
step: 60, loss: 0.031115859746932983
step: 70, loss: 0.013958743773400784
step: 80, loss: 0.009478294290602207
step: 90, loss: 0.016688555479049683
step: 100, loss: 0.007591685280203819
step: 110, loss: 0.0007966133416630328
step: 120, loss: 0.0811975747346878
step: 130, loss: 0.0011524871224537492
step: 140, loss: 0.0033865219447761774
step: 150, loss: 0.0038301676977425814
step: 160, loss: 0.00018420597189106047
step: 170, loss: 0.0051392014138400555
step: 180, loss: 0.0009137355373241007
step: 190, loss: 0.009428818710148335
step: 200, loss: 0.1110064685344696
step: 210, loss: 0.0013134687906131148
step: 220, loss: 0.007056189235299826
step: 230, loss: 0.00011333244037814438
step: 240, loss: 0.0044866325333714485
step: 250, loss: 0.07895798981189728
step: 260, loss: 0.0365188866853714
step: 270, loss: 0.00019216156215406954
step: 280, loss: 0.05404791235923767
step: 290, loss: 0.03188461437821388
step: 300, loss: 0.021876053884625435
step: 310, loss: 0.0001877867616713047
step: 320, loss: 0.04152965545654297
step: 330, loss: 0.01956585794687271
step: 340, loss: 0.00016287332982756197
step: 350, loss: 0.0005947417812421918
step: 360, loss: 0.0034900864120572805
epoch 9: dev_f1=0.656641604010025, f1=0.616867469879518, best_f1=0.6539379474940334
step: 0, loss: 0.0006537279696203768
step: 10, loss: 0.0008225628407672048
step: 20, loss: 0.000848775205668062
step: 30, loss: 0.0029865424148738384
step: 40, loss: 0.0012024487368762493
step: 50, loss: 0.022561214864253998
step: 60, loss: 0.013862330466508865
step: 70, loss: 0.0003086831420660019
step: 80, loss: 0.00011289583926554769
step: 90, loss: 0.025458896532654762
step: 100, loss: 0.01801975630223751
step: 110, loss: 0.00966416485607624
step: 120, loss: 0.0007536349585279822
step: 130, loss: 0.005781685002148151
step: 140, loss: 0.003624363336712122
step: 150, loss: 0.0005954353837296367
step: 160, loss: 0.00039231200935319066
step: 170, loss: 0.07098128646612167
step: 180, loss: 0.006434816401451826
step: 190, loss: 0.07855936139822006
step: 200, loss: 0.0019873278215527534
step: 210, loss: 0.007316662464290857
step: 220, loss: 0.005947391036897898
step: 230, loss: 0.006787416059523821
step: 240, loss: 0.0020529679022729397
step: 250, loss: 0.0009699370129965246
step: 260, loss: 0.0023472958710044622
step: 270, loss: 0.004553558770567179
step: 280, loss: 0.0004699536948464811
step: 290, loss: 0.0009975300636142492
step: 300, loss: 0.01016375981271267
step: 310, loss: 0.011433149687945843
step: 320, loss: 0.0022186078131198883
step: 330, loss: 0.0004712952650152147
step: 340, loss: 0.01633261889219284
step: 350, loss: 0.09746915847063065
step: 360, loss: 0.001268167863599956
epoch 10: dev_f1=0.6433915211970076, f1=0.6527415143603134, best_f1=0.6539379474940334
step: 0, loss: 0.0015548354713246226
step: 10, loss: 0.0009128465317189693
step: 20, loss: 0.0034485638607293367
step: 30, loss: 0.016744768247008324
step: 40, loss: 0.0014083207352086902
step: 50, loss: 0.0007748869247734547
step: 60, loss: 0.00010325259790988639
step: 70, loss: 0.0015623022336512804
step: 80, loss: 0.006761400029063225
step: 90, loss: 0.00025100784841924906
step: 100, loss: 0.0009381394484080374
step: 110, loss: 0.00016347454220522195
step: 120, loss: 0.00044203607831150293
step: 130, loss: 0.0005926194717176259
step: 140, loss: 0.2098410427570343
step: 150, loss: 0.0017203667666763067
step: 160, loss: 0.001355521846562624
step: 170, loss: 0.00039612356340512633
step: 180, loss: 0.0009290215675719082
step: 190, loss: 0.0002399663790129125
step: 200, loss: 0.0009676158661022782
step: 210, loss: 0.00032584223663434386
step: 220, loss: 0.0009266890701837838
step: 230, loss: 0.0002578368876129389
step: 240, loss: 0.001589653198607266
step: 250, loss: 0.013336285017430782
step: 260, loss: 0.0850922092795372
step: 270, loss: 0.0016270646592602134
step: 280, loss: 0.0012700685765594244
step: 290, loss: 0.029460690915584564
step: 300, loss: 0.002668622648343444
step: 310, loss: 0.009073886089026928
step: 320, loss: 0.004619665443897247
step: 330, loss: 0.007665205746889114
step: 340, loss: 0.0005238321027718484
step: 350, loss: 0.0010136469500139356
step: 360, loss: 0.015390941873192787
epoch 11: dev_f1=0.6648793565683646, f1=0.6576819407008087, best_f1=0.6539379474940334
step: 0, loss: 0.0035593174397945404
step: 10, loss: 0.009461970999836922
step: 20, loss: 0.0038562363479286432
step: 30, loss: 0.0009331098990514874
step: 40, loss: 0.0018235176103189588
step: 50, loss: 0.003452359000220895
step: 60, loss: 7.68892205087468e-05
step: 70, loss: 0.0006129923858679831
step: 80, loss: 0.0005115556996315718
step: 90, loss: 0.0005592392408289015
step: 100, loss: 0.0004670164780691266
step: 110, loss: 0.00011852112220367417
step: 120, loss: 5.310143387760036e-05
step: 130, loss: 0.0005706580122932792
step: 140, loss: 0.0001139970772783272
step: 150, loss: 0.00037303692079149187
step: 160, loss: 0.00019922017236240208
step: 170, loss: 0.003627108410000801
step: 180, loss: 0.0001433755096513778
step: 190, loss: 0.0005253910785540938
step: 200, loss: 0.028167707845568657
step: 210, loss: 0.0014131942298263311
step: 220, loss: 0.0008980922284536064
step: 230, loss: 0.00024480419233441353
step: 240, loss: 0.006176502909511328
step: 250, loss: 0.09294028580188751
step: 260, loss: 0.0007934658206067979
step: 270, loss: 0.0013477872125804424
step: 280, loss: 0.0005686339573003352
step: 290, loss: 0.0002747326507233083
step: 300, loss: 0.0009709402802400291
step: 310, loss: 0.0007921420619823039
step: 320, loss: 0.008481496013700962
step: 330, loss: 0.001042864634655416
step: 340, loss: 0.02376311831176281
step: 350, loss: 0.0008910853648558259
step: 360, loss: 0.0008700030157342553
epoch 12: dev_f1=0.6806282722513088, f1=0.6596858638743456, best_f1=0.6539379474940334
step: 0, loss: 0.0010750293731689453
step: 10, loss: 0.003205419983714819
step: 20, loss: 0.00232671108096838
step: 30, loss: 0.010518097318708897
step: 40, loss: 0.00021906646725255996
step: 50, loss: 0.000335370481479913
step: 60, loss: 0.00020687433425337076
step: 70, loss: 0.002861644374206662
step: 80, loss: 0.011554822325706482
step: 90, loss: 0.0013579748338088393
step: 100, loss: 6.0289039538474753e-05
step: 110, loss: 6.262047099880874e-05
step: 120, loss: 0.003061020513996482
step: 130, loss: 0.00010856662265723571
step: 140, loss: 0.0001114011465688236
step: 150, loss: 0.00021094294788781554
step: 160, loss: 0.0003885655605699867
step: 170, loss: 0.0015323961852118373
step: 180, loss: 0.025655120611190796
step: 190, loss: 8.071698539424688e-05
step: 200, loss: 5.876622162759304e-05
step: 210, loss: 0.049754779785871506
step: 220, loss: 0.0002805014664772898
step: 230, loss: 0.0036176699213683605
step: 240, loss: 0.006020242348313332
step: 250, loss: 0.0027220421470701694
step: 260, loss: 0.0017984488513320684
step: 270, loss: 0.0002566759940236807
step: 280, loss: 0.0024681598879396915
step: 290, loss: 0.0012524680932983756
step: 300, loss: 0.0006161870551295578
step: 310, loss: 0.0004810273239854723
step: 320, loss: 0.0006046661292202771
step: 330, loss: 0.0004168655432295054
step: 340, loss: 0.004057534504681826
step: 350, loss: 0.0008145096944645047
step: 360, loss: 0.0008009509183466434
epoch 13: dev_f1=0.6666666666666666, f1=0.6632124352331606, best_f1=0.6539379474940334
step: 0, loss: 0.00010281863069394603
step: 10, loss: 0.00011858212383231148
step: 20, loss: 0.00012119831808377057
step: 30, loss: 0.0006529961246997118
step: 40, loss: 0.0008023387636058033
step: 50, loss: 0.0013372033135965466
step: 60, loss: 0.0005067079910077155
step: 70, loss: 0.00011565228487597778
step: 80, loss: 0.001317113172262907
step: 90, loss: 0.002182665280997753
step: 100, loss: 0.012758300639688969
step: 110, loss: 0.00016523065278306603
step: 120, loss: 0.0002509334881324321
step: 130, loss: 0.00011088404426118359
step: 140, loss: 0.006859312765300274
step: 150, loss: 5.295813025441021e-05
step: 160, loss: 0.00010857482993742451
step: 170, loss: 0.0038810293190181255
step: 180, loss: 4.8255442379741e-05
step: 190, loss: 8.336173777934164e-05
step: 200, loss: 0.0006723154219798744
step: 210, loss: 0.00019155562040396035
step: 220, loss: 0.0005468837334774435
step: 230, loss: 0.002646309556439519
step: 240, loss: 2.7041236535296775e-05
step: 250, loss: 0.0003745732828974724
step: 260, loss: 0.00950529146939516
step: 270, loss: 0.00021111028036102653
step: 280, loss: 3.943029514630325e-05
step: 290, loss: 0.00030447199242189527
step: 300, loss: 0.0008639172883704305
step: 310, loss: 6.501711322925985e-05
step: 320, loss: 0.0035698029678314924
step: 330, loss: 0.00010726826440077275
step: 340, loss: 5.2112634875811636e-05
step: 350, loss: 0.0004037673934362829
step: 360, loss: 3.7459871236933395e-05
epoch 14: dev_f1=0.6473988439306357, f1=0.6220930232558138, best_f1=0.6539379474940334
step: 0, loss: 2.9536615329561755e-05
step: 10, loss: 0.0023052215110510588
step: 20, loss: 9.92929853964597e-05
step: 30, loss: 7.872097921790555e-05
step: 40, loss: 0.0005529816844500601
step: 50, loss: 0.00023334276920650154
step: 60, loss: 5.432597390608862e-05
step: 70, loss: 0.0004480856587179005
step: 80, loss: 0.00015456922119483352
step: 90, loss: 0.0002963892475236207
step: 100, loss: 0.0012693885946646333
step: 110, loss: 0.0003200173960067332
step: 120, loss: 1.9449516912573017e-05
step: 130, loss: 0.0004428679822012782
step: 140, loss: 2.388960638199933e-05
step: 150, loss: 7.048097177175805e-05
step: 160, loss: 0.00016243051504716277
step: 170, loss: 0.0012647582916542888
step: 180, loss: 8.552090730518103e-05
step: 190, loss: 0.00025435464340262115
step: 200, loss: 3.0207267627702095e-05
step: 210, loss: 0.0003318820090498775
step: 220, loss: 0.00021815569198224694
step: 230, loss: 0.00012772096670232713
step: 240, loss: 0.00705359922721982
step: 250, loss: 9.18204095796682e-05
step: 260, loss: 0.003362715942785144
step: 270, loss: 0.00016120368673000485
step: 280, loss: 0.0004675969830714166
step: 290, loss: 0.00019051854906138033
step: 300, loss: 2.4958793801488355e-05
step: 310, loss: 0.00039427686715498567
step: 320, loss: 6.642766675213352e-05
step: 330, loss: 0.007667882367968559
step: 340, loss: 0.00023964353022165596
step: 350, loss: 0.0006228763377293944
step: 360, loss: 1.7415532056475058e-05
epoch 15: dev_f1=0.6455331412103745, f1=0.6210826210826211, best_f1=0.6539379474940334
step: 0, loss: 8.215281559387222e-05
step: 10, loss: 0.001641842070966959
step: 20, loss: 0.0011981547577306628
step: 30, loss: 4.523356619756669e-05
step: 40, loss: 0.00025094562442973256
step: 50, loss: 9.028818021761253e-05
step: 60, loss: 8.270072430605069e-05
step: 70, loss: 2.7383041015127674e-05
step: 80, loss: 0.000297888444038108
step: 90, loss: 0.00014587625628337264
step: 100, loss: 0.00010810681851580739
step: 110, loss: 0.002689954824745655
step: 120, loss: 0.0004420026671141386
step: 130, loss: 0.00027008424513041973
step: 140, loss: 7.085842662490904e-05
step: 150, loss: 0.00014553793880622834
step: 160, loss: 3.898107024724595e-05
step: 170, loss: 9.104817581828684e-05
step: 180, loss: 3.413337253732607e-05
step: 190, loss: 0.00011393614113330841
step: 200, loss: 0.00022748777701053768
step: 210, loss: 9.762203990248963e-05
step: 220, loss: 0.00035129545722156763
step: 230, loss: 5.838812285219319e-05
step: 240, loss: 0.00024264927196782082
step: 250, loss: 3.635205212049186e-05
step: 260, loss: 0.001880089519545436
step: 270, loss: 5.508878530235961e-05
step: 280, loss: 0.00027136769494973123
step: 290, loss: 0.00015242220251820982
step: 300, loss: 0.000607712718192488
step: 310, loss: 0.00027480663266032934
step: 320, loss: 0.00015759494272060692
step: 330, loss: 0.00039822005783207715
step: 340, loss: 5.0212056521559134e-05
step: 350, loss: 1.968785909411963e-05
step: 360, loss: 2.1189040126046166e-05
epoch 16: dev_f1=0.60625, f1=0.5732484076433121, best_f1=0.6539379474940334
step: 0, loss: 0.151133194565773
step: 10, loss: 0.006655726116150618
step: 20, loss: 0.0015570729738101363
step: 30, loss: 0.00013503586524166167
step: 40, loss: 7.116379856597632e-05
step: 50, loss: 2.4891842258512042e-05
step: 60, loss: 3.194953023921698e-05
step: 70, loss: 0.0007078655180521309
step: 80, loss: 3.505304630380124e-05
step: 90, loss: 0.0002045949804596603
step: 100, loss: 0.000293809047434479
step: 110, loss: 0.000280271953670308
step: 120, loss: 0.002059575403109193
step: 130, loss: 0.0001338782749371603
step: 140, loss: 0.00038729238440282643
step: 150, loss: 0.00024403152929153293
step: 160, loss: 9.843402949627489e-05
step: 170, loss: 0.001567600411362946
step: 180, loss: 8.749147673370317e-05
step: 190, loss: 5.116395914228633e-05
step: 200, loss: 0.00036906637251377106
step: 210, loss: 0.00020802482322324067
step: 220, loss: 0.0446418896317482
step: 230, loss: 0.00030692413565702736
step: 240, loss: 9.45435167523101e-05
step: 250, loss: 0.00011657307186396793
step: 260, loss: 4.681790596805513e-05
step: 270, loss: 0.0033670144621282816
step: 280, loss: 6.982817285461351e-05
step: 290, loss: 0.0001513491151854396
step: 300, loss: 3.353268766659312e-05
step: 310, loss: 0.00012636066821869463
step: 320, loss: 5.778354170615785e-05
step: 330, loss: 6.686366396024823e-05
step: 340, loss: 0.0002394016773905605
step: 350, loss: 0.040501996874809265
step: 360, loss: 2.764406963251531e-05
epoch 17: dev_f1=0.6030769230769231, f1=0.5944272445820434, best_f1=0.6539379474940334
step: 0, loss: 0.0003161959757562727
step: 10, loss: 0.0003035434347111732
step: 20, loss: 5.280878031044267e-05
step: 30, loss: 0.00027838931418955326
step: 40, loss: 0.0003011609660461545
step: 50, loss: 0.00014389636635314673
step: 60, loss: 0.0005791031289845705
step: 70, loss: 8.000996604096144e-05
step: 80, loss: 0.00010903534712269902
step: 90, loss: 0.0002788002311717719
step: 100, loss: 0.00011134427040815353
step: 110, loss: 0.000503182178363204
step: 120, loss: 0.0028591055888682604
step: 130, loss: 0.006393881049007177
step: 140, loss: 7.889315747888759e-05
step: 150, loss: 3.779866892728023e-05
step: 160, loss: 0.00019253400387242436
step: 170, loss: 0.004127562511712313
step: 180, loss: 0.000262257584836334
step: 190, loss: 7.779316365486011e-05
step: 200, loss: 0.00012053994578309357
step: 210, loss: 0.00037557759787887335
step: 220, loss: 0.00019191611499991268
step: 230, loss: 0.0003690160810947418
step: 240, loss: 3.855230534099974e-05
step: 250, loss: 0.0004995521157979965
step: 260, loss: 0.00021958361321594566
step: 270, loss: 0.0004458276671357453
step: 280, loss: 0.00016473322466481477
step: 290, loss: 0.09018087387084961
step: 300, loss: 0.0012989226961508393
step: 310, loss: 0.019262956455349922
step: 320, loss: 0.0006627793191000819
step: 330, loss: 0.000758444657549262
step: 340, loss: 0.0005723360809497535
step: 350, loss: 0.013404441066086292
step: 360, loss: 4.810062819160521e-05
epoch 18: dev_f1=0.6361031518624642, f1=0.6327683615819208, best_f1=0.6539379474940334
step: 0, loss: 0.0003196638135705143
step: 10, loss: 2.6281462851329707e-05
step: 20, loss: 3.5459666833048686e-05
step: 30, loss: 0.0003590176929719746
step: 40, loss: 0.0004929006681777537
step: 50, loss: 0.012377042323350906
step: 60, loss: 6.258423672989011e-05
step: 70, loss: 3.4712502383627e-05
step: 80, loss: 0.00016070305719040334
step: 90, loss: 9.770011092768982e-05
step: 100, loss: 4.9701688112691045e-05
step: 110, loss: 8.884400449460372e-05
step: 120, loss: 0.00013119033246766776
step: 130, loss: 0.00012817814422305673
step: 140, loss: 0.0001899915951071307
step: 150, loss: 0.00020995251543354243
step: 160, loss: 0.0002933361101895571
step: 170, loss: 0.00020475966448429972
step: 180, loss: 0.0003583517682272941
step: 190, loss: 0.00018044108583126217
step: 200, loss: 7.030589767964557e-05
step: 210, loss: 6.016762927174568e-05
step: 220, loss: 0.0007981273229233921
step: 230, loss: 0.0002706098312046379
step: 240, loss: 0.01130567118525505
step: 250, loss: 0.00013644687714986503
step: 260, loss: 0.0001778676378307864
step: 270, loss: 2.7707907065632753e-05
step: 280, loss: 0.0006955070421099663
step: 290, loss: 0.0034470027312636375
step: 300, loss: 9.903591126203537e-05
step: 310, loss: 6.378428224707022e-05
step: 320, loss: 0.0007434370345436037
step: 330, loss: 8.862015238264576e-05
step: 340, loss: 0.00021767646830994636
step: 350, loss: 0.000269444368313998
step: 360, loss: 0.00016440387116745114
epoch 19: dev_f1=0.6611570247933883, f1=0.664864864864865, best_f1=0.6539379474940334
step: 0, loss: 0.00015264234389178455
step: 10, loss: 0.00010305795149179175
step: 20, loss: 0.0004119342484045774
step: 30, loss: 4.359645754448138e-05
step: 40, loss: 4.86777353216894e-05
step: 50, loss: 0.00031729371403343976
step: 60, loss: 0.00020537061209324747
step: 70, loss: 0.00037944226642139256
step: 80, loss: 8.449158485746011e-05
step: 90, loss: 0.00031523549114353955
step: 100, loss: 0.0002608217182569206
step: 110, loss: 6.658051279373467e-05
step: 120, loss: 7.280270074261352e-05
step: 130, loss: 5.793336822534911e-05
step: 140, loss: 0.00015002582222223282
step: 150, loss: 0.0018812910420820117
step: 160, loss: 5.718216561945155e-05
step: 170, loss: 3.301581818959676e-05
step: 180, loss: 5.009933011024259e-05
step: 190, loss: 7.637269300175831e-05
step: 200, loss: 9.060759475687519e-05
step: 210, loss: 3.6038672988070175e-05
step: 220, loss: 9.403072181157768e-05
step: 230, loss: 0.00020770425908267498
step: 240, loss: 0.0001143423723988235
step: 250, loss: 5.20326939295046e-05
step: 260, loss: 6.675405165879056e-05
step: 270, loss: 6.468252831837162e-05
step: 280, loss: 0.00031246186699718237
step: 290, loss: 5.8513207477517426e-05
step: 300, loss: 3.184603338013403e-05
step: 310, loss: 0.00011738479952327907
step: 320, loss: 0.06470677256584167
step: 330, loss: 0.0001263115555047989
step: 340, loss: 0.00016993381723295897
step: 350, loss: 0.0031496603041887283
step: 360, loss: 0.0005880400422029197
epoch 20: dev_f1=0.6355685131195336, f1=0.6303724928366763, best_f1=0.6539379474940334
cuda
Device: cuda
step: 0, loss: 0.6945666670799255
step: 10, loss: 0.2571091949939728
step: 20, loss: 0.22961357235908508
step: 30, loss: 0.13813580572605133
step: 40, loss: 0.31637734174728394
step: 50, loss: 0.2450169026851654
step: 60, loss: 0.3054179847240448
step: 70, loss: 0.026650190353393555
step: 80, loss: 0.1571306437253952
step: 90, loss: 0.25725317001342773
step: 100, loss: 0.1386450231075287
step: 110, loss: 0.03274993225932121
step: 120, loss: 0.059451181441545486
step: 130, loss: 0.25040000677108765
step: 140, loss: 0.32984787225723267
step: 150, loss: 0.14822962880134583
step: 160, loss: 0.034289855509996414
step: 170, loss: 0.05036667361855507
step: 180, loss: 0.3221755027770996
step: 190, loss: 0.4635099768638611
step: 200, loss: 0.3156982958316803
step: 210, loss: 0.13317131996154785
step: 220, loss: 0.14597371220588684
step: 230, loss: 0.22796045243740082
step: 240, loss: 0.13431261479854584
step: 250, loss: 0.03167039528489113
step: 260, loss: 0.21888428926467896
step: 270, loss: 0.06303583085536957
step: 280, loss: 0.37400785088539124
step: 290, loss: 0.2201969474554062
step: 300, loss: 0.3661157190799713
step: 310, loss: 0.05846016854047775
step: 320, loss: 0.22377915680408478
step: 330, loss: 0.26740893721580505
step: 340, loss: 0.22360602021217346
step: 350, loss: 0.05978890508413315
step: 360, loss: 0.20691438019275665
epoch 1: dev_f1=0.25379803395889183, f1=0.2653946227233305, best_f1=0.2653946227233305
step: 0, loss: 0.19555288553237915
step: 10, loss: 0.1811736822128296
step: 20, loss: 0.0655917078256607
step: 30, loss: 0.1399776190519333
step: 40, loss: 0.2909778654575348
step: 50, loss: 0.1156659796833992
step: 60, loss: 0.11437544226646423
step: 70, loss: 0.15671688318252563
step: 80, loss: 0.06238733232021332
step: 90, loss: 0.1364479511976242
step: 100, loss: 0.34234294295310974
step: 110, loss: 0.1498386412858963
step: 120, loss: 0.35490182042121887
step: 130, loss: 0.09315026551485062
step: 140, loss: 0.09762170910835266
step: 150, loss: 0.19507944583892822
step: 160, loss: 0.35713475942611694
step: 170, loss: 0.20832538604736328
step: 180, loss: 0.3035140633583069
step: 190, loss: 0.028942566365003586
step: 200, loss: 0.1633189469575882
step: 210, loss: 0.11875087767839432
step: 220, loss: 0.2112620323896408
step: 230, loss: 0.06279037147760391
step: 240, loss: 0.03761924430727959
step: 250, loss: 0.17618006467819214
step: 260, loss: 0.07787957042455673
step: 270, loss: 0.092322938144207
step: 280, loss: 0.10262427479028702
step: 290, loss: 0.045714981853961945
step: 300, loss: 0.17312659323215485
step: 310, loss: 0.19116683304309845
step: 320, loss: 0.4835500121116638
step: 330, loss: 0.22672897577285767
step: 340, loss: 0.30646073818206787
step: 350, loss: 0.15226028859615326
step: 360, loss: 0.18420156836509705
epoch 2: dev_f1=0.5070422535211268, f1=0.4470588235294118, best_f1=0.4470588235294118
step: 0, loss: 0.1816917061805725
step: 10, loss: 0.010062686167657375
step: 20, loss: 0.2040584683418274
step: 30, loss: 0.07381589710712433
step: 40, loss: 0.08720774203538895
step: 50, loss: 0.20205064117908478
step: 60, loss: 0.1472662389278412
step: 70, loss: 0.1900329887866974
step: 80, loss: 0.17623405158519745
step: 90, loss: 0.13165192306041718
step: 100, loss: 0.30503344535827637
step: 110, loss: 0.12239658832550049
step: 120, loss: 0.1647690385580063
step: 130, loss: 0.16896654665470123
step: 140, loss: 0.14428289234638214
step: 150, loss: 0.07049445807933807
step: 160, loss: 0.012416687794029713
step: 170, loss: 0.0561675950884819
step: 180, loss: 0.11015937477350235
step: 190, loss: 0.16795364022254944
step: 200, loss: 0.15591444075107574
step: 210, loss: 0.05350639298558235
step: 220, loss: 0.021761327981948853
step: 230, loss: 0.09914938360452652
step: 240, loss: 0.11812539398670197
step: 250, loss: 0.024886280298233032
step: 260, loss: 0.11788571625947952
step: 270, loss: 0.6325376629829407
step: 280, loss: 0.1543530970811844
step: 290, loss: 0.09356235712766647
step: 300, loss: 0.071497842669487
step: 310, loss: 0.4318217933177948
step: 320, loss: 0.11442022025585175
step: 330, loss: 0.19663256406784058
step: 340, loss: 0.29854723811149597
step: 350, loss: 0.2437044084072113
step: 360, loss: 0.016745902597904205
epoch 3: dev_f1=0.610576923076923, f1=0.5601851851851853, best_f1=0.5601851851851853
step: 0, loss: 0.06404481828212738
step: 10, loss: 0.1547982096672058
step: 20, loss: 0.012822641991078854
step: 30, loss: 0.11168235540390015
step: 40, loss: 0.19297291338443756
step: 50, loss: 0.053075600415468216
step: 60, loss: 0.09083343297243118
step: 70, loss: 0.025181936100125313
step: 80, loss: 0.1299624890089035
step: 90, loss: 0.06561225652694702
step: 100, loss: 0.04993615671992302
step: 110, loss: 0.01431218907237053
step: 120, loss: 0.08257144689559937
step: 130, loss: 0.10246860235929489
step: 140, loss: 0.22690249979496002
step: 150, loss: 0.17888271808624268
step: 160, loss: 0.18838343024253845
step: 170, loss: 0.14987285435199738
step: 180, loss: 0.1040492132306099
step: 190, loss: 0.1876089721918106
step: 200, loss: 0.028085555881261826
step: 210, loss: 0.04409518092870712
step: 220, loss: 0.07095848023891449
step: 230, loss: 0.14932654798030853
step: 240, loss: 0.013887201435863972
step: 250, loss: 0.10450921952724457
step: 260, loss: 0.22570979595184326
step: 270, loss: 0.05229003354907036
step: 280, loss: 0.033860210329294205
step: 290, loss: 0.0867069661617279
step: 300, loss: 0.1001528799533844
step: 310, loss: 0.013696574606001377
step: 320, loss: 0.06590809673070908
step: 330, loss: 0.051664967089891434
step: 340, loss: 0.014626294374465942
step: 350, loss: 0.13079415261745453
step: 360, loss: 0.024900902062654495
epoch 4: dev_f1=0.5402298850574713, f1=0.45562130177514787, best_f1=0.5601851851851853
step: 0, loss: 0.06966039538383484
step: 10, loss: 0.05209353566169739
step: 20, loss: 0.5023210048675537
step: 30, loss: 0.03366799280047417
step: 40, loss: 0.005594410467892885
step: 50, loss: 0.01831694506108761
step: 60, loss: 0.13781744241714478
step: 70, loss: 0.07636244595050812
step: 80, loss: 0.14863038063049316
step: 90, loss: 0.009108872152864933
step: 100, loss: 0.02592538669705391
step: 110, loss: 0.04915716499090195
step: 120, loss: 0.046664219349622726
step: 130, loss: 0.013965088874101639
step: 140, loss: 0.020947590470314026
step: 150, loss: 0.1938270479440689
step: 160, loss: 0.03390643373131752
step: 170, loss: 0.1405404955148697
step: 180, loss: 0.025342850014567375
step: 190, loss: 0.019368233159184456
step: 200, loss: 0.01469707302749157
step: 210, loss: 0.008867435157299042
step: 220, loss: 0.040736448019742966
step: 230, loss: 0.018713660538196564
step: 240, loss: 0.014865034259855747
step: 250, loss: 0.04666038602590561
step: 260, loss: 0.08651769906282425
step: 270, loss: 0.13730135560035706
step: 280, loss: 0.05196521058678627
step: 290, loss: 0.07397063821554184
step: 300, loss: 0.030438877642154694
step: 310, loss: 0.030542613938450813
step: 320, loss: 0.04608479142189026
step: 330, loss: 0.017880873754620552
step: 340, loss: 0.021513164043426514
step: 350, loss: 0.14835527539253235
step: 360, loss: 0.10972414910793304
epoch 5: dev_f1=0.6491646778042961, f1=0.6100917431192661, best_f1=0.6100917431192661
step: 0, loss: 0.21094483137130737
step: 10, loss: 0.03542117774486542
step: 20, loss: 0.026039116084575653
step: 30, loss: 0.010618684813380241
step: 40, loss: 0.031695425510406494
step: 50, loss: 0.0049583641812205315
step: 60, loss: 0.03427298739552498
step: 70, loss: 0.027836507186293602
step: 80, loss: 0.009869751520454884
step: 90, loss: 0.00621893722563982
step: 100, loss: 0.12692032754421234
step: 110, loss: 0.0061323088593780994
step: 120, loss: 0.030568305402994156
step: 130, loss: 0.012877599336206913
step: 140, loss: 0.01024005375802517
step: 150, loss: 0.23436814546585083
step: 160, loss: 0.00627110805362463
step: 170, loss: 0.15218840539455414
step: 180, loss: 0.009777304716408253
step: 190, loss: 0.014847265556454659
step: 200, loss: 0.18480052053928375
step: 210, loss: 0.016909826546907425
step: 220, loss: 0.0886097401380539
step: 230, loss: 0.14911893010139465
step: 240, loss: 0.1795530915260315
step: 250, loss: 0.0384569950401783
step: 260, loss: 0.015337950550019741
step: 270, loss: 0.007394290529191494
step: 280, loss: 0.044794559478759766
step: 290, loss: 0.10541484504938126
step: 300, loss: 0.12651102244853973
step: 310, loss: 0.07110170274972916
step: 320, loss: 0.0278801117092371
step: 330, loss: 0.0025627005379647017
step: 340, loss: 0.0027720320504158735
step: 350, loss: 0.05363534018397331
step: 360, loss: 0.016762739047408104
epoch 6: dev_f1=0.640625, f1=0.6084656084656085, best_f1=0.6100917431192661
step: 0, loss: 0.06188730150461197
step: 10, loss: 0.010587247088551521
step: 20, loss: 0.0015864770393818617
step: 30, loss: 0.07443489879369736
step: 40, loss: 0.09792391955852509
step: 50, loss: 0.014637826010584831
step: 60, loss: 0.007643046788871288
step: 70, loss: 0.18059790134429932
step: 80, loss: 0.1003001257777214
step: 90, loss: 0.012305560521781445
step: 100, loss: 0.07185647636651993
step: 110, loss: 0.009960325434803963
step: 120, loss: 0.027071235701441765
step: 130, loss: 0.0008917560917325318
step: 140, loss: 0.026677312329411507
step: 150, loss: 0.012196263298392296
step: 160, loss: 0.0308513343334198
step: 170, loss: 0.007987630553543568
step: 180, loss: 0.040298301726579666
step: 190, loss: 0.00030195442377589643
step: 200, loss: 0.004523475654423237
step: 210, loss: 0.013776103965938091
step: 220, loss: 0.11666255444288254
step: 230, loss: 0.04617585241794586
step: 240, loss: 0.21190524101257324
step: 250, loss: 0.007428931072354317
step: 260, loss: 0.0667494535446167
step: 270, loss: 0.1032654196023941
step: 280, loss: 0.059866294264793396
step: 290, loss: 0.039266638457775116
step: 300, loss: 0.09102407097816467
step: 310, loss: 0.022210408002138138
step: 320, loss: 0.010629945434629917
step: 330, loss: 0.03572310507297516
step: 340, loss: 0.013679401949048042
step: 350, loss: 0.018682770431041718
step: 360, loss: 0.02738548256456852
epoch 7: dev_f1=0.6201117318435755, f1=0.547008547008547, best_f1=0.6100917431192661
step: 0, loss: 0.006025900598615408
step: 10, loss: 0.015004688873887062
step: 20, loss: 0.005628248676657677
step: 30, loss: 0.018808050081133842
step: 40, loss: 0.00454323785379529
step: 50, loss: 0.0029155125375837088
step: 60, loss: 0.020682504400610924
step: 70, loss: 0.020604124292731285
step: 80, loss: 0.00039133676909841597
step: 90, loss: 0.009371993131935596
step: 100, loss: 0.00022155170154292136
step: 110, loss: 0.011603457853198051
step: 120, loss: 0.016577623784542084
step: 130, loss: 0.0011661896714940667
step: 140, loss: 0.016746649518609047
step: 150, loss: 0.0008440741803497076
step: 160, loss: 0.00020974839571863413
step: 170, loss: 0.003243174636736512
step: 180, loss: 0.006313024554401636
step: 190, loss: 0.0021982104517519474
step: 200, loss: 0.001134636695496738
step: 210, loss: 0.00600781012326479
step: 220, loss: 0.0625329464673996
step: 230, loss: 0.018565207719802856
step: 240, loss: 0.028996936976909637
step: 250, loss: 0.06810112297534943
step: 260, loss: 0.036009497940540314
step: 270, loss: 0.24797309935092926
step: 280, loss: 0.011144835501909256
step: 290, loss: 0.009233658201992512
step: 300, loss: 0.029417987912893295
step: 310, loss: 0.08313726633787155
step: 320, loss: 0.1707492172718048
step: 330, loss: 0.0059589119628071785
step: 340, loss: 0.0008226480567827821
step: 350, loss: 0.004384415224194527
step: 360, loss: 0.00989770982414484
epoch 8: dev_f1=0.6204986149584487, f1=0.5633802816901408, best_f1=0.6100917431192661
step: 0, loss: 0.010751542635262012
step: 10, loss: 0.01777621917426586
step: 20, loss: 0.006978638935834169
step: 30, loss: 0.04294776916503906
step: 40, loss: 0.003067913232371211
step: 50, loss: 0.03248528018593788
step: 60, loss: 0.015358354896306992
step: 70, loss: 0.0008132365765050054
step: 80, loss: 0.0005397931672632694
step: 90, loss: 0.023440271615982056
step: 100, loss: 0.02548193745315075
step: 110, loss: 0.03854069113731384
step: 120, loss: 0.07716140151023865
step: 130, loss: 0.004115738440304995
step: 140, loss: 0.002083026571199298
step: 150, loss: 0.01114826649427414
step: 160, loss: 0.0021546869538724422
step: 170, loss: 0.0024827206507325172
step: 180, loss: 0.038343850523233414
step: 190, loss: 0.031046411022543907
step: 200, loss: 0.08927957713603973
step: 210, loss: 0.0017849768046289682
step: 220, loss: 0.02085932530462742
step: 230, loss: 0.0003455583064351231
step: 240, loss: 0.038170937448740005
step: 250, loss: 0.10831228643655777
step: 260, loss: 0.01169090811163187
step: 270, loss: 0.0009086251957342029
step: 280, loss: 0.0020060662645846605
step: 290, loss: 0.00624705757945776
step: 300, loss: 0.01094317901879549
step: 310, loss: 0.00025376331177540123
step: 320, loss: 0.015728887170553207
step: 330, loss: 0.01962076872587204
step: 340, loss: 0.0016828975640237331
step: 350, loss: 0.023454753682017326
step: 360, loss: 0.04020017758011818
epoch 9: dev_f1=0.63, f1=0.5620253164556962, best_f1=0.6100917431192661
step: 0, loss: 0.006069588474929333
step: 10, loss: 0.0071242814883589745
step: 20, loss: 0.012258169241249561
step: 30, loss: 0.004616494290530682
step: 40, loss: 0.0016661735717207193
step: 50, loss: 0.002385310595855117
step: 60, loss: 0.04757453873753548
step: 70, loss: 0.0008267357479780912
step: 80, loss: 0.00016756662807893008
step: 90, loss: 0.013925560750067234
step: 100, loss: 0.003755762707442045
step: 110, loss: 0.0009826854802668095
step: 120, loss: 0.0004473538137972355
step: 130, loss: 0.0019683886785060167
step: 140, loss: 0.0022791954688727856
step: 150, loss: 0.0006180306663736701
step: 160, loss: 0.020631399005651474
step: 170, loss: 0.03585107997059822
step: 180, loss: 0.002891900483518839
step: 190, loss: 0.10862985998392105
step: 200, loss: 0.0018066705670207739
step: 210, loss: 0.0035778104793280363
step: 220, loss: 0.03096744976937771
step: 230, loss: 0.0010329937795177102
step: 240, loss: 0.009557015262544155
step: 250, loss: 0.004347990266978741
step: 260, loss: 0.0017945244908332825
step: 270, loss: 0.000367185624781996
step: 280, loss: 0.09622789174318314
step: 290, loss: 0.005246587097644806
step: 300, loss: 0.000196979075553827
step: 310, loss: 0.021523522213101387
step: 320, loss: 0.00019174153567291796
step: 330, loss: 0.0004514790780376643
step: 340, loss: 0.00038998553645797074
step: 350, loss: 0.026377253234386444
step: 360, loss: 0.004195707850158215
epoch 10: dev_f1=0.6259946949602122, f1=0.555858310626703, best_f1=0.6100917431192661
step: 0, loss: 0.0005284065846353769
step: 10, loss: 0.03218661993741989
step: 20, loss: 0.0021225232630968094
step: 30, loss: 0.0319831520318985
step: 40, loss: 0.015747973695397377
step: 50, loss: 8.066858572419733e-05
step: 60, loss: 0.0010516638867557049
step: 70, loss: 0.000592373195104301
step: 80, loss: 0.0525134913623333
step: 90, loss: 0.0006291092140600085
step: 100, loss: 0.00045267099631018937
step: 110, loss: 0.00024405083968304098
step: 120, loss: 0.007049905601888895
step: 130, loss: 0.0006011074292473495
step: 140, loss: 0.00802097748965025
step: 150, loss: 0.04978468269109726
step: 160, loss: 0.004759041126817465
step: 170, loss: 0.0036339384969323874
step: 180, loss: 0.002947726519778371
step: 190, loss: 0.0003472804091870785
step: 200, loss: 0.0009986000368371606
step: 210, loss: 0.0002980739518534392
step: 220, loss: 0.0011145091848447919
step: 230, loss: 0.0002892634365707636
step: 240, loss: 0.005889664404094219
step: 250, loss: 0.001092575490474701
step: 260, loss: 0.0016431394033133984
step: 270, loss: 0.00039605365600436926
step: 280, loss: 0.010193138383328915
step: 290, loss: 0.014182699844241142
step: 300, loss: 0.002612369367852807
step: 310, loss: 0.0073933787643909454
step: 320, loss: 0.000614201242569834
step: 330, loss: 0.0005754965823143721
step: 340, loss: 0.0001781683968147263
step: 350, loss: 0.0014263034099712968
step: 360, loss: 0.049195997416973114
epoch 11: dev_f1=0.6315789473684211, f1=0.5920000000000001, best_f1=0.6100917431192661
step: 0, loss: 0.01852543093264103
step: 10, loss: 0.02098259888589382
step: 20, loss: 0.0007134524639695883
step: 30, loss: 0.009082605130970478
step: 40, loss: 0.0006094069685786963
step: 50, loss: 0.0008025563438422978
step: 60, loss: 0.00015071564121171832
step: 70, loss: 0.0016118823550641537
step: 80, loss: 0.00017188701895065606
step: 90, loss: 0.035633619874715805
step: 100, loss: 0.0009904998587444425
step: 110, loss: 0.0005172112141735852
step: 120, loss: 4.905656533082947e-05
step: 130, loss: 0.0014549415791407228
step: 140, loss: 0.013990947045385838
step: 150, loss: 0.00023714435519650578
step: 160, loss: 0.0021324658300727606
step: 170, loss: 0.09396564215421677
step: 180, loss: 0.003304586512967944
step: 190, loss: 0.0014349048724398017
step: 200, loss: 0.1384403556585312
step: 210, loss: 0.001223968924023211
step: 220, loss: 0.01746974140405655
step: 230, loss: 0.0004328630166128278
step: 240, loss: 0.205398291349411
step: 250, loss: 0.01572028174996376
step: 260, loss: 0.0005167360650375485
step: 270, loss: 0.01806751824915409
step: 280, loss: 0.00022034837456885725
step: 290, loss: 0.0005796384066343307
step: 300, loss: 0.01139732263982296
step: 310, loss: 0.00037673578481189907
step: 320, loss: 0.006910502444952726
step: 330, loss: 0.0005289092077873647
step: 340, loss: 0.05883694812655449
step: 350, loss: 0.17986074090003967
step: 360, loss: 0.00015165150398388505
epoch 12: dev_f1=0.5945945945945946, f1=0.557471264367816, best_f1=0.6100917431192661
step: 0, loss: 0.012263745069503784
step: 10, loss: 0.0074937292374670506
step: 20, loss: 0.0017162840813398361
step: 30, loss: 0.020987961441278458
step: 40, loss: 0.0010553926695138216
step: 50, loss: 0.0005563094164244831
step: 60, loss: 0.00034822773886844516
step: 70, loss: 0.0006808370817452669
step: 80, loss: 0.007729468401521444
step: 90, loss: 0.0012443304294720292
step: 100, loss: 0.00020380037312861532
step: 110, loss: 0.01340149063616991
step: 120, loss: 0.012168856337666512
step: 130, loss: 0.03534548729658127
step: 140, loss: 0.000462309893919155
step: 150, loss: 0.00019570723816286772
step: 160, loss: 5.318308831192553e-05
step: 170, loss: 0.005926399491727352
step: 180, loss: 0.013171556405723095
step: 190, loss: 0.010721977800130844
step: 200, loss: 0.0018814352806657553
step: 210, loss: 0.11185271292924881
step: 220, loss: 0.000984619720838964
step: 230, loss: 0.07899646461009979
step: 240, loss: 0.0009153065038844943
step: 250, loss: 0.00018097918655257672
step: 260, loss: 0.0031103442888706923
step: 270, loss: 0.0026150618214160204
step: 280, loss: 0.004507238976657391
step: 290, loss: 0.0030335222836583853
step: 300, loss: 0.01636599935591221
step: 310, loss: 0.0003388847107999027
step: 320, loss: 0.004347694106400013
step: 330, loss: 0.00015366023581009358
step: 340, loss: 0.0036667666863650084
step: 350, loss: 7.956745685078204e-05
step: 360, loss: 0.00043545581866055727
epoch 13: dev_f1=0.6267806267806268, f1=0.5663716814159292, best_f1=0.6100917431192661
step: 0, loss: 5.794079334009439e-05
step: 10, loss: 0.0007261895225383341
step: 20, loss: 0.00016634158964734524
step: 30, loss: 0.0007799649611115456
step: 40, loss: 0.0001835823932196945
step: 50, loss: 0.0002903997665271163
step: 60, loss: 0.0003504300839267671
step: 70, loss: 0.0017309177201241255
step: 80, loss: 0.00018706609262153506
step: 90, loss: 0.0006793966167606413
step: 100, loss: 0.13437773287296295
step: 110, loss: 5.583391975960694e-05
step: 120, loss: 8.024910493986681e-05
step: 130, loss: 0.0004484174423851073
step: 140, loss: 0.021732147783041
step: 150, loss: 0.0001419960317434743
step: 160, loss: 0.0001824291975935921
step: 170, loss: 0.0005265191430225968
step: 180, loss: 0.0007924968376755714
step: 190, loss: 0.00037301212432794273
step: 200, loss: 0.00011478002124931663
step: 210, loss: 0.0008846240816637874
step: 220, loss: 0.0010424623033031821
step: 230, loss: 0.0008629481308162212
step: 240, loss: 4.25071339122951e-05
step: 250, loss: 0.021565355360507965
step: 260, loss: 0.00964544527232647
step: 270, loss: 0.002966978820040822
step: 280, loss: 7.415038999170065e-05
step: 290, loss: 0.001138573861680925
step: 300, loss: 0.006415922194719315
step: 310, loss: 0.00015201166388578713
step: 320, loss: 0.0002038879320025444
step: 330, loss: 7.30070605641231e-05
step: 340, loss: 9.452347876504064e-05
step: 350, loss: 9.427371696801856e-05
step: 360, loss: 7.497110345866531e-05
epoch 14: dev_f1=0.6318840579710145, f1=0.5432098765432098, best_f1=0.6100917431192661
step: 0, loss: 0.0027078911662101746
step: 10, loss: 0.0006202161894179881
step: 20, loss: 0.0004390040412545204
step: 30, loss: 0.0005754337180405855
step: 40, loss: 0.010116983205080032
step: 50, loss: 0.0009521348401904106
step: 60, loss: 7.882463978603482e-05
step: 70, loss: 0.002803041134029627
step: 80, loss: 0.0009405783494003117
step: 90, loss: 0.0007923893863335252
step: 100, loss: 0.0014694127021357417
step: 110, loss: 0.00047827421803958714
step: 120, loss: 5.5839194828877226e-05
step: 130, loss: 0.0006083437474444509
step: 140, loss: 3.9243892388185486e-05
step: 150, loss: 0.0006478073191829026
step: 160, loss: 0.004763382021337748
step: 170, loss: 0.0016578746726736426
step: 180, loss: 0.054179489612579346
step: 190, loss: 0.001294487970881164
step: 200, loss: 0.00020683760521933436
step: 210, loss: 0.02588748373091221
step: 220, loss: 0.0009707461576908827
step: 230, loss: 8.808595157461241e-05
step: 240, loss: 0.001024740980938077
step: 250, loss: 0.0003931501414626837
step: 260, loss: 0.002246115356683731
step: 270, loss: 5.186334965401329e-05
step: 280, loss: 0.0006159816985018551
step: 290, loss: 0.00021718649077229202
step: 300, loss: 0.0004240074194967747
step: 310, loss: 0.0008971267961896956
step: 320, loss: 0.0009877581615000963
step: 330, loss: 0.002567456802353263
step: 340, loss: 0.00043456919956952333
step: 350, loss: 0.0037768816109746695
step: 360, loss: 3.12247357214801e-05
epoch 15: dev_f1=0.629737609329446, f1=0.5545171339563864, best_f1=0.6100917431192661
step: 0, loss: 0.0001274452661164105
step: 10, loss: 0.0007092842133715749
step: 20, loss: 0.07991752028465271
step: 30, loss: 0.0002572946541476995
step: 40, loss: 0.0007214270299300551
step: 50, loss: 0.00023803023213986307
step: 60, loss: 0.00011957273090956733
step: 70, loss: 0.00036790542071685195
step: 80, loss: 0.00012152310227975249
step: 90, loss: 8.742596401134506e-05
step: 100, loss: 0.0002326952962903306
step: 110, loss: 0.0017897826619446278
step: 120, loss: 0.0015476207481697202
step: 130, loss: 0.0031315681990236044
step: 140, loss: 0.00036677561001852155
step: 150, loss: 0.0013127881102263927
step: 160, loss: 3.0315663025248796e-05
step: 170, loss: 0.0003863002930302173
step: 180, loss: 0.008914644829928875
step: 190, loss: 0.0003350485349074006
step: 200, loss: 0.00048325679381377995
step: 210, loss: 0.03413351997733116
step: 220, loss: 0.0015525398775935173
step: 230, loss: 0.0024065671022981405
step: 240, loss: 0.0005208776565268636
step: 250, loss: 0.0001304503093706444
step: 260, loss: 0.00108154967892915
step: 270, loss: 5.4909225582377985e-05
step: 280, loss: 0.00015793732018209994
step: 290, loss: 0.0002759362105280161
step: 300, loss: 0.004276723135262728
step: 310, loss: 0.0010172114707529545
step: 320, loss: 0.0010363567853346467
step: 330, loss: 0.0006491628591902554
step: 340, loss: 5.5675216572126374e-05
step: 350, loss: 4.526354678091593e-05
step: 360, loss: 4.4696735130855814e-05
epoch 16: dev_f1=0.6395939086294417, f1=0.5989010989010989, best_f1=0.6100917431192661
step: 0, loss: 0.018202172592282295
step: 10, loss: 0.00018494635878596455
step: 20, loss: 0.009582491591572762
step: 30, loss: 7.215124787762761e-05
step: 40, loss: 7.790602830937132e-05
step: 50, loss: 3.656583794509061e-05
step: 60, loss: 2.5063322027563117e-05
step: 70, loss: 0.0002614886616356671
step: 80, loss: 0.0015157379675656557
step: 90, loss: 8.84140536072664e-05
step: 100, loss: 0.003920846618711948
step: 110, loss: 8.487550803693011e-05
step: 120, loss: 0.00015165725199040025
step: 130, loss: 0.02156830206513405
step: 140, loss: 0.0007837419980205595
step: 150, loss: 0.00011356705363141373
step: 160, loss: 0.0028209800366312265
step: 170, loss: 0.00011900380195584148
step: 180, loss: 0.0001326529454672709
step: 190, loss: 4.1453284211456776e-05
step: 200, loss: 0.00023612436780240387
step: 210, loss: 0.19516779482364655
step: 220, loss: 3.5374319850234315e-05
step: 230, loss: 2.675086034287233e-05
step: 240, loss: 0.0014640976442024112
step: 250, loss: 0.014633976854383945
step: 260, loss: 0.00022118969354778528
step: 270, loss: 0.00027567913639359176
step: 280, loss: 6.292704347288236e-05
step: 290, loss: 0.0001233090879395604
step: 300, loss: 5.6148357543861493e-05
step: 310, loss: 0.00011879527301061898
step: 320, loss: 0.00010681221465347335
step: 330, loss: 0.00015181931667029858
step: 340, loss: 0.0016871499828994274
step: 350, loss: 0.0005138707929290831
step: 360, loss: 2.4206607122323476e-05
epoch 17: dev_f1=0.6385224274406333, f1=0.623229461756374, best_f1=0.6100917431192661
step: 0, loss: 0.00011214458208996803
step: 10, loss: 0.030476771295070648
step: 20, loss: 0.00011651460226858035
step: 30, loss: 0.0031060504261404276
step: 40, loss: 0.0001175790312117897
step: 50, loss: 0.0006414262461476028
step: 60, loss: 0.0003001723380293697
step: 70, loss: 0.00023003060778137296
step: 80, loss: 0.00012560516188386828
step: 90, loss: 8.145018364302814e-05
step: 100, loss: 0.0011904641287401319
step: 110, loss: 0.0010576940840110183
step: 120, loss: 0.0010286483447998762
step: 130, loss: 0.0003447927883826196
step: 140, loss: 0.0023960843682289124
step: 150, loss: 0.00021172297419980168
step: 160, loss: 2.684770879568532e-05
step: 170, loss: 0.00040617724880576134
step: 180, loss: 0.0004888560506515205
step: 190, loss: 2.4970237063826062e-05
step: 200, loss: 0.00017662536993157119
step: 210, loss: 0.00013745477190241218
step: 220, loss: 0.00022588235151488334
step: 230, loss: 7.543677202193066e-05
step: 240, loss: 0.0001590587926330045
step: 250, loss: 8.70812582434155e-05
step: 260, loss: 0.00012989183596801013
step: 270, loss: 0.0003931491810362786
step: 280, loss: 0.0015042265877127647
step: 290, loss: 0.0005398609209805727
step: 300, loss: 0.1165972352027893
step: 310, loss: 0.018910018727183342
step: 320, loss: 0.0003760220715776086
step: 330, loss: 0.0001626909215701744
step: 340, loss: 0.0009495279518887401
step: 350, loss: 0.013455497100949287
step: 360, loss: 0.000144877951242961
epoch 18: dev_f1=0.6388888888888888, f1=0.5964912280701754, best_f1=0.6100917431192661
step: 0, loss: 0.0001407219097018242
step: 10, loss: 2.3077827790984884e-05
step: 20, loss: 2.1256224499666132e-05
step: 30, loss: 0.00021365152497310191
step: 40, loss: 0.0010283731389790773
step: 50, loss: 0.000647617329377681
step: 60, loss: 4.2112733353860676e-05
step: 70, loss: 0.0006651610601693392
step: 80, loss: 0.003848669119179249
step: 90, loss: 4.437574534676969e-05
step: 100, loss: 4.755867485073395e-05
step: 110, loss: 3.103399649262428e-05
step: 120, loss: 0.0008985990425571799
step: 130, loss: 0.0003758707898668945
step: 140, loss: 0.0009587964741513133
step: 150, loss: 0.013389951549470425
step: 160, loss: 0.010744928382337093
step: 170, loss: 0.00448529003188014
step: 180, loss: 0.00011493780766613781
step: 190, loss: 2.2995864128461108e-05
step: 200, loss: 5.167803828953765e-05
step: 210, loss: 0.00022877649462316185
step: 220, loss: 0.0002162488381145522
step: 230, loss: 0.002337256446480751
step: 240, loss: 0.0016512403963133693
step: 250, loss: 0.00011080300464527681
step: 260, loss: 8.689714741194621e-05
step: 270, loss: 2.2928747057449073e-05
step: 280, loss: 0.0006190290441736579
step: 290, loss: 0.0003671667363960296
step: 300, loss: 0.002822569105774164
step: 310, loss: 9.665598918218166e-05
step: 320, loss: 0.00016516096366103739
step: 330, loss: 2.469433457008563e-05
step: 340, loss: 0.0027707600966095924
step: 350, loss: 0.0003549357352312654
step: 360, loss: 0.010543289594352245
epoch 19: dev_f1=0.622478386167147, f1=0.5705521472392638, best_f1=0.6100917431192661
step: 0, loss: 0.040820322930812836
step: 10, loss: 6.126000516815111e-05
step: 20, loss: 0.00018723492394201458
step: 30, loss: 6.217151531018317e-05
step: 40, loss: 9.537141886539757e-05
step: 50, loss: 4.741048178402707e-05
step: 60, loss: 0.0378381572663784
step: 70, loss: 9.547780064167455e-05
step: 80, loss: 0.0007776811835356057
step: 90, loss: 0.0020445154514163733
step: 100, loss: 0.0002472275518812239
step: 110, loss: 0.0011540009872987866
step: 120, loss: 0.00021911709336563945
step: 130, loss: 0.00011005337000824511
step: 140, loss: 5.4063264542492107e-05
step: 150, loss: 9.168532415060326e-05
step: 160, loss: 0.00019310535572003573
step: 170, loss: 2.8985643439227715e-05
step: 180, loss: 0.00018673852900974452
step: 190, loss: 0.0004963579121977091
step: 200, loss: 0.00047647531027905643
step: 210, loss: 2.4999921151902527e-05
step: 220, loss: 0.0003886624181177467
step: 230, loss: 9.526923531666398e-05
step: 240, loss: 0.0004075751348864287
step: 250, loss: 5.2989456889918074e-05
step: 260, loss: 0.0001609840983292088
step: 270, loss: 0.00013830284297000617
step: 280, loss: 0.0005532519426196814
step: 290, loss: 2.9968628950882703e-05
step: 300, loss: 7.100102811818942e-05
step: 310, loss: 0.0003131312842015177
step: 320, loss: 9.42035621847026e-05
step: 330, loss: 2.9312745027709752e-05
step: 340, loss: 8.272772538475692e-05
step: 350, loss: 0.0020508868619799614
step: 360, loss: 0.000965718412771821
epoch 20: dev_f1=0.6228571428571429, f1=0.5626911314984709, best_f1=0.6100917431192661
