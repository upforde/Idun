cuda
Device: cuda
step: 0, loss: 0.4545651376247406
step: 10, loss: 0.03089296445250511
step: 20, loss: 0.23616145551204681
step: 30, loss: 0.14111968874931335
step: 40, loss: 0.08356032520532608
step: 50, loss: 0.12796372175216675
step: 60, loss: 0.29036518931388855
step: 70, loss: 0.044319264590740204
step: 80, loss: 0.12515029311180115
step: 90, loss: 0.11948460340499878
step: 100, loss: 0.4116939306259155
step: 110, loss: 0.22316277027130127
step: 120, loss: 0.13258317112922668
step: 130, loss: 0.2168881595134735
step: 140, loss: 0.3482630252838135
step: 150, loss: 0.2759125828742981
step: 160, loss: 0.03786665201187134
step: 170, loss: 0.1950129270553589
step: 180, loss: 0.29327401518821716
step: 190, loss: 0.2431642860174179
step: 200, loss: 0.09031263738870621
step: 210, loss: 0.05111125856637955
step: 220, loss: 0.21389301121234894
step: 230, loss: 0.07354145497083664
step: 240, loss: 0.07865744829177856
step: 250, loss: 0.19538219273090363
step: 260, loss: 0.08727899938821793
step: 270, loss: 0.22571833431720734
step: 280, loss: 0.08286262303590775
step: 290, loss: 0.2171543389558792
step: 300, loss: 0.05652160942554474
step: 310, loss: 0.17815594375133514
step: 320, loss: 0.12734633684158325
step: 330, loss: 0.09971493482589722
step: 340, loss: 0.20619237422943115
step: 350, loss: 0.20484831929206848
step: 360, loss: 0.027335474267601967
epoch 1: dev_f1=0.4370179948586118, f1=0.4358974358974359, best_f1=0.4358974358974359
step: 0, loss: 0.12022578716278076
step: 10, loss: 0.12078822404146194
step: 20, loss: 0.029954683035612106
step: 30, loss: 0.18064214289188385
step: 40, loss: 0.2127804309129715
step: 50, loss: 0.17550089955329895
step: 60, loss: 0.06715572625398636
step: 70, loss: 0.12368451803922653
step: 80, loss: 0.13564346730709076
step: 90, loss: 0.004788131918758154
step: 100, loss: 0.1491159349679947
step: 110, loss: 0.045839399099349976
step: 120, loss: 0.09194336831569672
step: 130, loss: 0.06289438903331757
step: 140, loss: 0.4821043312549591
step: 150, loss: 0.08013410866260529
step: 160, loss: 0.15788313746452332
step: 170, loss: 0.040533099323511124
step: 180, loss: 0.23419898748397827
step: 190, loss: 0.04348741099238396
step: 200, loss: 0.15133331716060638
step: 210, loss: 0.23106397688388824
step: 220, loss: 0.24102109670639038
step: 230, loss: 0.06257425248622894
step: 240, loss: 0.16247007250785828
step: 250, loss: 0.13311228156089783
step: 260, loss: 0.15046469867229462
step: 270, loss: 0.24706292152404785
step: 280, loss: 0.06848461925983429
step: 290, loss: 0.09781702607870102
step: 300, loss: 0.06775885820388794
step: 310, loss: 0.24954935908317566
step: 320, loss: 0.2140149027109146
step: 330, loss: 0.056835003197193146
step: 340, loss: 0.006698982790112495
step: 350, loss: 0.08386379480361938
step: 360, loss: 0.016488317400217056
epoch 2: dev_f1=0.5794871794871795, f1=0.5633074935400517, best_f1=0.5633074935400517
step: 0, loss: 0.10787256807088852
step: 10, loss: 0.018623465672135353
step: 20, loss: 0.0430917926132679
step: 30, loss: 0.008100790902972221
step: 40, loss: 0.14331480860710144
step: 50, loss: 0.07664498686790466
step: 60, loss: 0.045221030712127686
step: 70, loss: 0.07876596599817276
step: 80, loss: 0.07343454658985138
step: 90, loss: 0.05933847278356552
step: 100, loss: 0.06314881145954132
step: 110, loss: 0.008279520086944103
step: 120, loss: 0.07026568800210953
step: 130, loss: 0.09821489453315735
step: 140, loss: 0.11283236742019653
step: 150, loss: 0.05253640189766884
step: 160, loss: 0.04661143943667412
step: 170, loss: 0.08648104220628738
step: 180, loss: 0.11242429912090302
step: 190, loss: 0.03083401918411255
step: 200, loss: 0.23952384293079376
step: 210, loss: 0.0969584658741951
step: 220, loss: 0.02014513500034809
step: 230, loss: 0.05927128717303276
step: 240, loss: 0.18671829998493195
step: 250, loss: 0.15413789451122284
step: 260, loss: 0.03597957640886307
step: 270, loss: 0.09420452266931534
step: 280, loss: 0.21262040734291077
step: 290, loss: 0.08283422887325287
step: 300, loss: 0.15302011370658875
step: 310, loss: 0.11119848489761353
step: 320, loss: 0.002822483889758587
step: 330, loss: 0.05796506255865097
step: 340, loss: 0.22604219615459442
step: 350, loss: 0.15298786759376526
step: 360, loss: 0.016594653949141502
epoch 3: dev_f1=0.6387434554973821, f1=0.5965909090909091, best_f1=0.5965909090909091
step: 0, loss: 0.04079020395874977
step: 10, loss: 0.11212414503097534
step: 20, loss: 0.013522063381969929
step: 30, loss: 0.01265837624669075
step: 40, loss: 0.018121814355254173
step: 50, loss: 0.061810486018657684
step: 60, loss: 0.029974134638905525
step: 70, loss: 0.0713486298918724
step: 80, loss: 0.22877565026283264
step: 90, loss: 0.06261207908391953
step: 100, loss: 0.007589820306748152
step: 110, loss: 0.01837337017059326
step: 120, loss: 0.10867266356945038
step: 130, loss: 0.06695569306612015
step: 140, loss: 0.04362069070339203
step: 150, loss: 0.27914172410964966
step: 160, loss: 0.1219809353351593
step: 170, loss: 0.05493057891726494
step: 180, loss: 0.040565572679042816
step: 190, loss: 0.008074234239757061
step: 200, loss: 0.0032101136166602373
step: 210, loss: 0.014732396230101585
step: 220, loss: 0.01351205725222826
step: 230, loss: 0.015664292499423027
step: 240, loss: 0.07800432294607162
step: 250, loss: 0.002337041776627302
step: 260, loss: 0.11035312712192535
step: 270, loss: 0.009105597622692585
step: 280, loss: 0.08212759345769882
step: 290, loss: 0.01875685714185238
step: 300, loss: 0.030613938346505165
step: 310, loss: 0.05001571774482727
step: 320, loss: 0.1965373456478119
step: 330, loss: 0.08333796262741089
step: 340, loss: 0.06623610854148865
step: 350, loss: 0.031769461929798126
step: 360, loss: 0.04647345468401909
epoch 4: dev_f1=0.6683168316831682, f1=0.6631578947368421, best_f1=0.6631578947368421
step: 0, loss: 0.10147210955619812
step: 10, loss: 0.13099204003810883
step: 20, loss: 0.03389574587345123
step: 30, loss: 0.012556999921798706
step: 40, loss: 0.029685528948903084
step: 50, loss: 0.014896951615810394
step: 60, loss: 0.22104664146900177
step: 70, loss: 0.0007234178483486176
step: 80, loss: 0.0015172060811892152
step: 90, loss: 0.007373301312327385
step: 100, loss: 0.0069341035559773445
step: 110, loss: 0.0019869315437972546
step: 120, loss: 0.0760406106710434
step: 130, loss: 0.00715348357334733
step: 140, loss: 0.01150835957378149
step: 150, loss: 0.0031767617911100388
step: 160, loss: 0.012263456359505653
step: 170, loss: 0.09930271655321121
step: 180, loss: 0.032295890152454376
step: 190, loss: 0.020984767004847527
step: 200, loss: 0.0641326978802681
step: 210, loss: 0.0028015212155878544
step: 220, loss: 0.04194066300988197
step: 230, loss: 0.005034733563661575
step: 240, loss: 0.0269746333360672
step: 250, loss: 0.023412011563777924
step: 260, loss: 0.09788349270820618
step: 270, loss: 0.01709219627082348
step: 280, loss: 0.005381427705287933
step: 290, loss: 0.3038633167743683
step: 300, loss: 0.08662233501672745
step: 310, loss: 0.01302635483443737
step: 320, loss: 0.04428330063819885
step: 330, loss: 0.01754927821457386
step: 340, loss: 0.0028705517761409283
step: 350, loss: 0.021572811529040337
step: 360, loss: 0.005757222883403301
epoch 5: dev_f1=0.6482412060301508, f1=0.6351706036745407, best_f1=0.6631578947368421
step: 0, loss: 0.10532207787036896
step: 10, loss: 0.024318937212228775
step: 20, loss: 0.032354116439819336
step: 30, loss: 0.007185295224189758
step: 40, loss: 0.006075010169297457
step: 50, loss: 0.007183278910815716
step: 60, loss: 0.0008105480228550732
step: 70, loss: 0.029193179681897163
step: 80, loss: 0.007889827713370323
step: 90, loss: 0.031001055613160133
step: 100, loss: 0.08355606347322464
step: 110, loss: 0.05375901609659195
step: 120, loss: 0.08465937525033951
step: 130, loss: 0.012089372612535954
step: 140, loss: 0.018299419432878494
step: 150, loss: 0.050120871514081955
step: 160, loss: 0.16261713206768036
step: 170, loss: 0.11358746141195297
step: 180, loss: 0.20867110788822174
step: 190, loss: 0.008578518405556679
step: 200, loss: 0.012235977686941624
step: 210, loss: 0.011457695625722408
step: 220, loss: 0.004622458014637232
step: 230, loss: 0.006170789711177349
step: 240, loss: 0.010127020068466663
step: 250, loss: 0.012442924082279205
step: 260, loss: 0.0328201986849308
step: 270, loss: 0.002621903084218502
step: 280, loss: 0.009728528559207916
step: 290, loss: 0.1577577441930771
step: 300, loss: 0.007990792393684387
step: 310, loss: 0.07069847732782364
step: 320, loss: 0.010394539684057236
step: 330, loss: 0.05868111178278923
step: 340, loss: 0.009136403910815716
step: 350, loss: 0.008830036036670208
step: 360, loss: 0.07098419964313507
epoch 6: dev_f1=0.6501377410468319, f1=0.6345609065155806, best_f1=0.6631578947368421
step: 0, loss: 0.03901568427681923
step: 10, loss: 0.0015693558380007744
step: 20, loss: 0.00024504188331775367
step: 30, loss: 0.0019346772460266948
step: 40, loss: 0.052170902490615845
step: 50, loss: 0.0026749938260763884
step: 60, loss: 0.007176926359534264
step: 70, loss: 0.0011407289421185851
step: 80, loss: 0.003167042974382639
step: 90, loss: 0.007459486369043589
step: 100, loss: 0.0035930254962295294
step: 110, loss: 0.0066959448158741
step: 120, loss: 0.012560026720166206
step: 130, loss: 0.007905091159045696
step: 140, loss: 0.011839902959764004
step: 150, loss: 0.0008929047617129982
step: 160, loss: 0.00086398288840428
step: 170, loss: 0.0008846673299558461
step: 180, loss: 0.0013108208077028394
step: 190, loss: 0.001803675084374845
step: 200, loss: 0.006174149923026562
step: 210, loss: 0.0008146872278302908
step: 220, loss: 0.005692970007658005
step: 230, loss: 0.0029895745683461428
step: 240, loss: 0.00047383675700984895
step: 250, loss: 0.0241635050624609
step: 260, loss: 0.0009519095765426755
step: 270, loss: 0.024427441880106926
step: 280, loss: 0.01826159842312336
step: 290, loss: 0.40693435072898865
step: 300, loss: 0.1462658941745758
step: 310, loss: 0.007186756003648043
step: 320, loss: 0.0021380216348916292
step: 330, loss: 0.026438916102051735
step: 340, loss: 0.000686841260176152
step: 350, loss: 0.00046562179340980947
step: 360, loss: 0.0044149053283035755
epoch 7: dev_f1=0.6524064171122995, f1=0.6576819407008087, best_f1=0.6631578947368421
step: 0, loss: 0.003713065292686224
step: 10, loss: 0.022994399070739746
step: 20, loss: 0.035675909370183945
step: 30, loss: 0.0014041143003851175
step: 40, loss: 0.00510849803686142
step: 50, loss: 0.0033847959712147713
step: 60, loss: 0.009112901985645294
step: 70, loss: 0.015392608009278774
step: 80, loss: 0.0009138791356235743
step: 90, loss: 0.000771279213950038
step: 100, loss: 0.0062441760674119
step: 110, loss: 0.0025414112024009228
step: 120, loss: 0.006898636929690838
step: 130, loss: 0.0034450392704457045
step: 140, loss: 0.00028545333771035075
step: 150, loss: 0.0005763762164860964
step: 160, loss: 0.0009753340273164213
step: 170, loss: 0.0008752718567848206
step: 180, loss: 0.011137031950056553
step: 190, loss: 0.0016793562099337578
step: 200, loss: 0.04244394972920418
step: 210, loss: 0.0016053080325946212
step: 220, loss: 0.0014107136521488428
step: 230, loss: 0.0009817449608817697
step: 240, loss: 0.006906247232109308
step: 250, loss: 0.0851588100194931
step: 260, loss: 0.08334359526634216
step: 270, loss: 0.001389924087561667
step: 280, loss: 0.0026841165963560343
step: 290, loss: 0.0012285956181585789
step: 300, loss: 0.0014899983070790768
step: 310, loss: 0.0015403609722852707
step: 320, loss: 0.00451623322442174
step: 330, loss: 0.0031958012841641903
step: 340, loss: 0.060917582362890244
step: 350, loss: 0.005534068215638399
step: 360, loss: 0.012307323515415192
epoch 8: dev_f1=0.6647058823529411, f1=0.6407185628742514, best_f1=0.6631578947368421
step: 0, loss: 0.0071662599220871925
step: 10, loss: 0.04363569989800453
step: 20, loss: 0.0006628473638556898
step: 30, loss: 0.0012019042624160647
step: 40, loss: 0.0005497541278600693
step: 50, loss: 0.0006321894470602274
step: 60, loss: 0.0012137879384681582
step: 70, loss: 0.0006906103226356208
step: 80, loss: 0.00036768734571523964
step: 90, loss: 0.00028678198577836156
step: 100, loss: 0.0008803096134215593
step: 110, loss: 0.0013114078901708126
step: 120, loss: 0.00030285216053016484
step: 130, loss: 0.0066399602219462395
step: 140, loss: 0.0005492571508511901
step: 150, loss: 0.0015840905252844095
step: 160, loss: 0.08843281120061874
step: 170, loss: 0.00029587093740701675
step: 180, loss: 0.000522003450896591
step: 190, loss: 0.011598790995776653
step: 200, loss: 0.0019171149469912052
step: 210, loss: 0.0015819491818547249
step: 220, loss: 9.94912043097429e-05
step: 230, loss: 0.012088591232895851
step: 240, loss: 0.0024402046110481024
step: 250, loss: 0.0033710403367877007
step: 260, loss: 0.0008848548750393093
step: 270, loss: 0.00018713661120273173
step: 280, loss: 0.0028312434442341328
step: 290, loss: 0.08787140250205994
step: 300, loss: 0.0002413273905403912
step: 310, loss: 0.0007072336156852543
step: 320, loss: 0.00013272585056256503
step: 330, loss: 0.027021003887057304
step: 340, loss: 0.0023838449269533157
step: 350, loss: 0.0007784072658978403
step: 360, loss: 0.0035577912349253893
epoch 9: dev_f1=0.6432748538011697, f1=0.6126126126126126, best_f1=0.6631578947368421
step: 0, loss: 0.015389207750558853
step: 10, loss: 0.0003888760111294687
step: 20, loss: 0.0005787888076156378
step: 30, loss: 0.002696939744055271
step: 40, loss: 0.0004222082789056003
step: 50, loss: 0.00027286758995614946
step: 60, loss: 0.006861033383756876
step: 70, loss: 0.0030153265688568354
step: 80, loss: 0.0006000732537358999
step: 90, loss: 0.0012905426556244493
step: 100, loss: 0.0028421978931874037
step: 110, loss: 0.0014917552471160889
step: 120, loss: 0.017795562744140625
step: 130, loss: 0.001309848390519619
step: 140, loss: 0.018384316936135292
step: 150, loss: 0.005139113403856754
step: 160, loss: 0.003486048663035035
step: 170, loss: 0.00040656313649378717
step: 180, loss: 0.007329265121370554
step: 190, loss: 0.013854051008820534
step: 200, loss: 0.0020130928605794907
step: 210, loss: 0.007693400140851736
step: 220, loss: 0.013718312606215477
step: 230, loss: 0.02332981489598751
step: 240, loss: 0.0015089391963556409
step: 250, loss: 0.09196782112121582
step: 260, loss: 0.001056765322573483
step: 270, loss: 0.001044616336002946
step: 280, loss: 0.000980081269517541
step: 290, loss: 0.0002653814444784075
step: 300, loss: 0.005376073531806469
step: 310, loss: 0.026865817606449127
step: 320, loss: 0.00017187258345074952
step: 330, loss: 0.0018924239557236433
step: 340, loss: 0.0002850578457582742
step: 350, loss: 0.0006092385738156736
step: 360, loss: 0.0014311089180409908
epoch 10: dev_f1=0.6544502617801047, f1=0.6501377410468319, best_f1=0.6631578947368421
step: 0, loss: 0.006726822350174189
step: 10, loss: 0.0010028393007814884
step: 20, loss: 0.00068966846447438
step: 30, loss: 0.0006033537210896611
step: 40, loss: 0.002059202641248703
step: 50, loss: 0.001197101199068129
step: 60, loss: 0.0018899631686508656
step: 70, loss: 0.0005249072564765811
step: 80, loss: 0.00037035802961327136
step: 90, loss: 0.0023765701334923506
step: 100, loss: 0.0004318385908845812
step: 110, loss: 0.004267665091902018
step: 120, loss: 0.0005993170198053122
step: 130, loss: 0.0007019690820015967
step: 140, loss: 0.00082426454173401
step: 150, loss: 0.003651460399851203
step: 160, loss: 0.0005528508336283267
step: 170, loss: 0.007287650369107723
step: 180, loss: 0.0011753311846405268
step: 190, loss: 0.0044921343214809895
step: 200, loss: 0.0015585892833769321
step: 210, loss: 7.041609205771238e-05
step: 220, loss: 0.0018961424939334393
step: 230, loss: 0.00017277960432693362
step: 240, loss: 0.0007030217093415558
step: 250, loss: 7.138490036595613e-05
step: 260, loss: 0.00010202723933616653
step: 270, loss: 0.00024185408256016672
step: 280, loss: 0.000859017251059413
step: 290, loss: 0.00010179592209169641
step: 300, loss: 0.0005040907417424023
step: 310, loss: 0.001279445830732584
step: 320, loss: 0.0617835707962513
step: 330, loss: 0.00023391415015794337
step: 340, loss: 0.015282955951988697
step: 350, loss: 5.234031050349586e-05
step: 360, loss: 0.0002447338483761996
epoch 11: dev_f1=0.6805970149253731, f1=0.6966966966966968, best_f1=0.6966966966966968
step: 0, loss: 0.00016053945000749081
step: 10, loss: 0.00033608890953473747
step: 20, loss: 0.06244897469878197
step: 30, loss: 7.013131835265085e-05
step: 40, loss: 0.0009249518043361604
step: 50, loss: 0.0006357039092108607
step: 60, loss: 0.0006205272511579096
step: 70, loss: 0.00043634985922835767
step: 80, loss: 0.0014420519582927227
step: 90, loss: 0.0008467465522699058
step: 100, loss: 0.0008122681174427271
step: 110, loss: 0.00025649077724665403
step: 120, loss: 0.002844817005097866
step: 130, loss: 0.00043544257641769946
step: 140, loss: 0.0006478768191300333
step: 150, loss: 0.0002540454443078488
step: 160, loss: 0.022833090275526047
step: 170, loss: 0.0003513568080961704
step: 180, loss: 0.009486104361712933
step: 190, loss: 0.0002944914158433676
step: 200, loss: 0.00016331093502230942
step: 210, loss: 0.0006272760219871998
step: 220, loss: 0.0007186568691395223
step: 230, loss: 0.0003256045747548342
step: 240, loss: 0.2800014615058899
step: 250, loss: 0.00022519318736158311
step: 260, loss: 0.00019859522581100464
step: 270, loss: 0.011458206921815872
step: 280, loss: 0.0016444283537566662
step: 290, loss: 0.000295833102427423
step: 300, loss: 0.0002592261880636215
step: 310, loss: 0.08112575858831406
step: 320, loss: 0.0047963643446564674
step: 330, loss: 0.0010929920244961977
step: 340, loss: 0.00034676180803216994
step: 350, loss: 0.0021662390790879726
step: 360, loss: 0.0003014992398675531
epoch 12: dev_f1=0.6483516483516483, f1=0.6444444444444445, best_f1=0.6966966966966968
step: 0, loss: 0.03618514910340309
step: 10, loss: 0.0017920860555022955
step: 20, loss: 0.001986987190321088
step: 30, loss: 0.0010642034467309713
step: 40, loss: 0.005929399747401476
step: 50, loss: 6.600881897611544e-05
step: 60, loss: 0.0005502200219780207
step: 70, loss: 5.858859731233679e-05
step: 80, loss: 0.0012868078192695975
step: 90, loss: 0.00021201244089752436
step: 100, loss: 0.00012320179666858166
step: 110, loss: 6.688655412290245e-05
step: 120, loss: 9.704571129987016e-05
step: 130, loss: 0.0014805480604991317
step: 140, loss: 0.00011139050911879167
step: 150, loss: 0.00013204169226810336
step: 160, loss: 0.0004825334472116083
step: 170, loss: 0.0004934818716719747
step: 180, loss: 0.0012592916609719396
step: 190, loss: 0.00392962247133255
step: 200, loss: 0.0025938304606825113
step: 210, loss: 0.15595965087413788
step: 220, loss: 0.002277550520375371
step: 230, loss: 0.0002528717159293592
step: 240, loss: 0.00043528550304472446
step: 250, loss: 0.0003250127483624965
step: 260, loss: 0.00020494297496043146
step: 270, loss: 0.00019947213877458125
step: 280, loss: 0.007067112252116203
step: 290, loss: 0.00017667064093984663
step: 300, loss: 0.002384962746873498
step: 310, loss: 0.00020064663840457797
step: 320, loss: 0.00015842836000956595
step: 330, loss: 0.019718598574399948
step: 340, loss: 0.0023302168119698763
step: 350, loss: 0.0008908284362405539
step: 360, loss: 0.00038068636786192656
epoch 13: dev_f1=0.6290322580645162, f1=0.6361031518624642, best_f1=0.6966966966966968
step: 0, loss: 0.0009445103351026773
step: 10, loss: 0.0012718515936285257
step: 20, loss: 0.00034519817563705146
step: 30, loss: 0.0008990370552055538
step: 40, loss: 0.003359309397637844
step: 50, loss: 0.0004147309809923172
step: 60, loss: 0.0002849486190825701
step: 70, loss: 9.819449041970074e-05
step: 80, loss: 0.0003225192485842854
step: 90, loss: 0.00023451235028915107
step: 100, loss: 0.00029895410989411175
step: 110, loss: 0.00022172648459672928
step: 120, loss: 7.899722550064325e-05
step: 130, loss: 0.0009339760290458798
step: 140, loss: 0.00026585833984427154
step: 150, loss: 4.9343041609972715e-05
step: 160, loss: 0.00025736723910085857
step: 170, loss: 0.019795900210738182
step: 180, loss: 0.0005552787333726883
step: 190, loss: 0.0010993218747898936
step: 200, loss: 0.10072261095046997
step: 210, loss: 0.04212254658341408
step: 220, loss: 0.00011238961451454088
step: 230, loss: 0.0007834769785404205
step: 240, loss: 0.0016115916660055518
step: 250, loss: 0.00012110714305890724
step: 260, loss: 7.774942059768364e-05
step: 270, loss: 0.004698639735579491
step: 280, loss: 0.00011828707647509873
step: 290, loss: 0.008704167790710926
step: 300, loss: 0.0009925973135977983
step: 310, loss: 7.275922689586878e-05
step: 320, loss: 4.931650619255379e-05
step: 330, loss: 0.005706590134650469
step: 340, loss: 0.20708857476711273
step: 350, loss: 0.026137247681617737
step: 360, loss: 0.0002756452013272792
epoch 14: dev_f1=0.663013698630137, f1=0.6628242074927955, best_f1=0.6966966966966968
step: 0, loss: 0.00018900887516792864
step: 10, loss: 0.00010159881639992818
step: 20, loss: 0.0001160278043244034
step: 30, loss: 0.00015045941108837724
step: 40, loss: 0.0007931035361252725
step: 50, loss: 0.0007728746859356761
step: 60, loss: 7.562401879113168e-05
step: 70, loss: 0.00015060475561767817
step: 80, loss: 9.201961802318692e-05
step: 90, loss: 0.0025814776308834553
step: 100, loss: 0.00020113287610001862
step: 110, loss: 0.0007256869575940073
step: 120, loss: 0.00040532436105422676
step: 130, loss: 0.00033085577888414264
step: 140, loss: 0.0011078566312789917
step: 150, loss: 0.00025747172185219824
step: 160, loss: 0.029667584225535393
step: 170, loss: 0.027484256774187088
step: 180, loss: 6.705584382871166e-05
step: 190, loss: 0.0007352310931310058
step: 200, loss: 0.0003729286545421928
step: 210, loss: 0.00019035192963201553
step: 220, loss: 0.0002723830402828753
step: 230, loss: 0.00217780121602118
step: 240, loss: 0.00022062291100155562
step: 250, loss: 0.00036692729918286204
step: 260, loss: 0.0012842454016208649
step: 270, loss: 0.00014096252562012523
step: 280, loss: 0.0003104790230281651
step: 290, loss: 0.000133657842525281
step: 300, loss: 0.0003315472276881337
step: 310, loss: 0.000327899178955704
step: 320, loss: 0.0024993938859552145
step: 330, loss: 0.001031006802804768
step: 340, loss: 0.00021005849703215063
step: 350, loss: 0.00031884488998912275
step: 360, loss: 0.0001596221118234098
epoch 15: dev_f1=0.661498708010336, f1=0.6984126984126985, best_f1=0.6966966966966968
step: 0, loss: 0.0012704477412626147
step: 10, loss: 0.0003444732865318656
step: 20, loss: 0.0009250086732208729
step: 30, loss: 0.00011867263674503192
step: 40, loss: 0.0003812346258200705
step: 50, loss: 0.00029878588975407183
step: 60, loss: 0.0012504595797508955
step: 70, loss: 0.0002916942466981709
step: 80, loss: 0.0003216563491150737
step: 90, loss: 0.0060993367806077
step: 100, loss: 0.00018068740610033274
step: 110, loss: 9.821618732530624e-05
step: 120, loss: 0.00026085751596838236
step: 130, loss: 0.000151706364704296
step: 140, loss: 0.00017454380576964468
step: 150, loss: 6.602457142435014e-05
step: 160, loss: 0.0006235199980437756
step: 170, loss: 0.00032530250609852374
step: 180, loss: 6.89140724716708e-05
step: 190, loss: 0.00012101393076591194
step: 200, loss: 0.0010665854206308722
step: 210, loss: 0.0004469803243409842
step: 220, loss: 4.931060175294988e-05
step: 230, loss: 0.00040149991400539875
step: 240, loss: 0.00016769836656749249
step: 250, loss: 0.0001159720923169516
step: 260, loss: 0.00031414447585120797
step: 270, loss: 8.523365249857306e-05
step: 280, loss: 4.133473339607008e-05
step: 290, loss: 0.0003977558808401227
step: 300, loss: 0.0003874415997415781
step: 310, loss: 0.00030390420579351485
step: 320, loss: 0.0003198643680661917
step: 330, loss: 5.470110409078188e-05
step: 340, loss: 0.0009642154909670353
step: 350, loss: 0.00027594229322858155
step: 360, loss: 2.8639267839025706e-05
epoch 16: dev_f1=0.6701298701298701, f1=0.6916890080428955, best_f1=0.6966966966966968
step: 0, loss: 0.00014258506416808814
step: 10, loss: 0.00010462576756253839
step: 20, loss: 0.0004565423005260527
step: 30, loss: 4.362476465757936e-05
step: 40, loss: 0.0001587733713677153
step: 50, loss: 0.0012358197709545493
step: 60, loss: 0.00011327883112244308
step: 70, loss: 0.00040363045991398394
step: 80, loss: 0.00011065102444263175
step: 90, loss: 0.00021836299856659025
step: 100, loss: 3.224515603506006e-05
step: 110, loss: 7.477283361367881e-05
step: 120, loss: 0.00015785652794875205
step: 130, loss: 0.0017437502974644303
step: 140, loss: 0.000965471554081887
step: 150, loss: 8.608480857219547e-05
step: 160, loss: 0.0006837759865447879
step: 170, loss: 0.0011677015572786331
step: 180, loss: 5.2764557040063664e-05
step: 190, loss: 3.579833355615847e-05
step: 200, loss: 6.660594954155385e-05
step: 210, loss: 0.000680388358887285
step: 220, loss: 0.00011666714999591932
step: 230, loss: 0.0001291606022277847
step: 240, loss: 0.0003317514783702791
step: 250, loss: 9.180757479043677e-05
step: 260, loss: 0.00022538450139109045
step: 270, loss: 9.779768879525363e-05
step: 280, loss: 0.0004018615873064846
step: 290, loss: 5.799627615488134e-05
step: 300, loss: 0.00035502470564097166
step: 310, loss: 0.0001472216099500656
step: 320, loss: 0.00015167228411883116
step: 330, loss: 2.5223296688636765e-05
step: 340, loss: 5.954728840151802e-05
step: 350, loss: 6.682160892523825e-05
step: 360, loss: 6.135118019301444e-05
epoch 17: dev_f1=0.6629834254143646, f1=0.6550724637681159, best_f1=0.6966966966966968
step: 0, loss: 3.564854705473408e-05
step: 10, loss: 0.00030078840791247785
step: 20, loss: 9.402132855029777e-05
step: 30, loss: 2.1885778551222757e-05
step: 40, loss: 0.002788884099572897
step: 50, loss: 0.00017295510042458773
step: 60, loss: 0.0002835174382198602
step: 70, loss: 3.366010787431151e-05
step: 80, loss: 0.00021575120626948774
step: 90, loss: 8.027313742786646e-05
step: 100, loss: 9.843621228355914e-05
step: 110, loss: 8.051905024331063e-05
step: 120, loss: 7.682789873797446e-05
step: 130, loss: 6.187423423398286e-05
step: 140, loss: 0.00013175883213989437
step: 150, loss: 8.926562441047281e-05
step: 160, loss: 4.9115278670797125e-05
step: 170, loss: 7.983431714819744e-05
step: 180, loss: 8.632474055048078e-05
step: 190, loss: 0.002543662441894412
step: 200, loss: 0.0001405494549544528
step: 210, loss: 0.0007154550985433161
step: 220, loss: 4.917668047710322e-05
step: 230, loss: 0.00028201198438182473
step: 240, loss: 0.0002201513125328347
step: 250, loss: 0.0001777045545168221
step: 260, loss: 0.000390636851079762
step: 270, loss: 9.87298262771219e-05
step: 280, loss: 0.00419970927760005
step: 290, loss: 4.839060056838207e-05
step: 300, loss: 0.00012434956443030387
step: 310, loss: 0.0002394417824689299
step: 320, loss: 0.00033674045698717237
step: 330, loss: 0.0007431819103658199
step: 340, loss: 0.0003108007076662034
step: 350, loss: 3.924198608729057e-05
step: 360, loss: 5.5992131819948554e-05
epoch 18: dev_f1=0.6702127659574468, f1=0.6868131868131868, best_f1=0.6966966966966968
step: 0, loss: 5.2181323553668335e-05
step: 10, loss: 0.00039047771133482456
step: 20, loss: 5.4011354222893715e-05
step: 30, loss: 0.00032221328001469374
step: 40, loss: 0.00021923081658314914
step: 50, loss: 4.355318014859222e-05
step: 60, loss: 7.859391917008907e-05
step: 70, loss: 3.6962301237508655e-05
step: 80, loss: 0.00013711396604776382
step: 90, loss: 8.817691559670493e-05
step: 100, loss: 5.901041367906146e-05
step: 110, loss: 0.00045726378448307514
step: 120, loss: 0.0023765910882502794
step: 130, loss: 0.00021248622215352952
step: 140, loss: 0.00044348134542815387
step: 150, loss: 0.00032333791023120284
step: 160, loss: 6.991027476033196e-05
step: 170, loss: 2.1959749574307352e-05
step: 180, loss: 0.00013192884216550738
step: 190, loss: 1.8428772818879224e-05
step: 200, loss: 0.00012610055273398757
step: 210, loss: 9.778488310985267e-05
step: 220, loss: 3.055988418054767e-05
step: 230, loss: 0.00041539056110195816
step: 240, loss: 4.4380180042935535e-05
step: 250, loss: 6.940516323084012e-05
step: 260, loss: 0.00253298063762486
step: 270, loss: 9.410765051143244e-05
step: 280, loss: 0.00010465997183928266
step: 290, loss: 0.00037422525929287076
step: 300, loss: 4.3578351323958486e-05
step: 310, loss: 0.0001982738176593557
step: 320, loss: 1.8402693967800587e-05
step: 330, loss: 9.520728781353682e-05
step: 340, loss: 6.39879799564369e-05
step: 350, loss: 3.982175621786155e-05
step: 360, loss: 4.0571951103629544e-05
epoch 19: dev_f1=0.6666666666666666, f1=0.6375000000000001, best_f1=0.6966966966966968
step: 0, loss: 3.043752076337114e-05
step: 10, loss: 2.373283132328652e-05
step: 20, loss: 2.8762000511051156e-05
step: 30, loss: 5.9677247918443754e-05
step: 40, loss: 7.242018182296306e-05
step: 50, loss: 3.642757292254828e-05
step: 60, loss: 2.2577994968742132e-05
step: 70, loss: 0.00019479064212646335
step: 80, loss: 5.213678741711192e-05
step: 90, loss: 0.00018227116379421204
step: 100, loss: 5.793368472950533e-05
step: 110, loss: 0.00023332698037847877
step: 120, loss: 2.788067467918154e-05
step: 130, loss: 0.00012086097558494657
step: 140, loss: 0.00013994178152643144
step: 150, loss: 0.0016897476743906736
step: 160, loss: 4.4650889321928844e-05
step: 170, loss: 2.884001878555864e-05
step: 180, loss: 5.042186239734292e-05
step: 190, loss: 0.0002677175507415086
step: 200, loss: 0.0001129802330979146
step: 210, loss: 0.0003490481758490205
step: 220, loss: 0.00010687488975236192
step: 230, loss: 1.5545472706435248e-05
step: 240, loss: 2.838157524820417e-05
step: 250, loss: 4.961734885000624e-05
step: 260, loss: 0.00011501365224830806
step: 270, loss: 0.00012359865650068969
step: 280, loss: 3.010225555044599e-05
step: 290, loss: 0.04888598620891571
step: 300, loss: 0.012896724045276642
step: 310, loss: 2.80691274383571e-05
step: 320, loss: 5.223787229624577e-05
step: 330, loss: 9.861010767053813e-05
step: 340, loss: 0.00014041144459042698
step: 350, loss: 5.283704012981616e-05
step: 360, loss: 0.00025014093262143433
epoch 20: dev_f1=0.6684931506849316, f1=0.6780626780626781, best_f1=0.6966966966966968
