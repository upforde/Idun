cuda
Device: cuda
step: 0, loss: 0.49156221747398376
step: 10, loss: 0.22954300045967102
step: 20, loss: 0.034829188138246536
step: 30, loss: 0.16838683187961578
step: 40, loss: 0.49058040976524353
step: 50, loss: 0.14607128500938416
step: 60, loss: 0.40559321641921997
step: 70, loss: 0.14353123307228088
step: 80, loss: 0.24281081557273865
step: 90, loss: 0.29487913846969604
step: 100, loss: 0.13214686512947083
step: 110, loss: 0.20209814608097076
step: 120, loss: 0.05123594403266907
step: 130, loss: 0.3390122652053833
step: 140, loss: 0.12916333973407745
step: 150, loss: 0.35570231080055237
step: 160, loss: 0.12640133500099182
step: 170, loss: 0.05368846654891968
step: 180, loss: 0.04446790739893913
step: 190, loss: 0.15889060497283936
step: 200, loss: 0.13400253653526306
step: 210, loss: 0.2513454556465149
step: 220, loss: 0.31532022356987
step: 230, loss: 0.2150195837020874
step: 240, loss: 0.3647288680076599
step: 250, loss: 0.21760347485542297
step: 260, loss: 0.10788965970277786
step: 270, loss: 0.15153665840625763
step: 280, loss: 0.10210121423006058
step: 290, loss: 0.16290602087974548
step: 300, loss: 0.1662176102399826
step: 310, loss: 0.19497698545455933
step: 320, loss: 0.2850481867790222
step: 330, loss: 0.2054518759250641
step: 340, loss: 0.2211713343858719
step: 350, loss: 0.10433806478977203
step: 360, loss: 0.09598933160305023
epoch 1: dev_f1=0.3827751196172248, f1=0.39, best_f1=0.39
step: 0, loss: 0.19675399363040924
step: 10, loss: 0.1623326987028122
step: 20, loss: 0.15077589452266693
step: 30, loss: 0.14083006978034973
step: 40, loss: 0.14030370116233826
step: 50, loss: 0.27448034286499023
step: 60, loss: 0.11691705137491226
step: 70, loss: 0.24038612842559814
step: 80, loss: 0.07032249122858047
step: 90, loss: 0.12647801637649536
step: 100, loss: 0.11574441939592361
step: 110, loss: 0.16172344982624054
step: 120, loss: 0.012781464494764805
step: 130, loss: 0.021421801298856735
step: 140, loss: 0.05536697804927826
step: 150, loss: 0.11634476482868195
step: 160, loss: 0.17134591937065125
step: 170, loss: 0.3760741651058197
step: 180, loss: 0.14227105677127838
step: 190, loss: 0.19898773729801178
step: 200, loss: 0.11532577872276306
step: 210, loss: 0.13473743200302124
step: 220, loss: 0.1724497675895691
step: 230, loss: 0.08696458488702774
step: 240, loss: 0.07393709570169449
step: 250, loss: 0.08631812036037445
step: 260, loss: 0.03128514438867569
step: 270, loss: 0.29365673661231995
step: 280, loss: 0.09498430788516998
step: 290, loss: 0.07629517465829849
step: 300, loss: 0.21154356002807617
step: 310, loss: 0.13199077546596527
step: 320, loss: 0.012535047717392445
step: 330, loss: 0.09743647277355194
step: 340, loss: 0.07824584096670151
step: 350, loss: 0.37402424216270447
step: 360, loss: 0.2630256116390228
epoch 2: dev_f1=0.6187050359712231, f1=0.5798525798525799, best_f1=0.5798525798525799
step: 0, loss: 0.24146106839179993
step: 10, loss: 0.0891033411026001
step: 20, loss: 0.01593695767223835
step: 30, loss: 0.012679093517363071
step: 40, loss: 0.19884070754051208
step: 50, loss: 0.11373850703239441
step: 60, loss: 0.012807117775082588
step: 70, loss: 0.33786430954933167
step: 80, loss: 0.053042881190776825
step: 90, loss: 0.1211242824792862
step: 100, loss: 0.03546970337629318
step: 110, loss: 0.11009485274553299
step: 120, loss: 0.05824108421802521
step: 130, loss: 0.06488091498613358
step: 140, loss: 0.03968208655714989
step: 150, loss: 0.15332528948783875
step: 160, loss: 0.0354328490793705
step: 170, loss: 0.060242604464292526
step: 180, loss: 0.055458102375268936
step: 190, loss: 0.034771498292684555
step: 200, loss: 0.14522689580917358
step: 210, loss: 0.015973351895809174
step: 220, loss: 0.06431812793016434
step: 230, loss: 0.25223514437675476
step: 240, loss: 0.18863047659397125
step: 250, loss: 0.05575171485543251
step: 260, loss: 0.13686725497245789
step: 270, loss: 0.04782504960894585
step: 280, loss: 0.012520951218903065
step: 290, loss: 0.031903013586997986
step: 300, loss: 0.044115033000707626
step: 310, loss: 0.062072791159152985
step: 320, loss: 0.007130507379770279
step: 330, loss: 0.07951012998819351
step: 340, loss: 0.3251557946205139
step: 350, loss: 0.18882183730602264
step: 360, loss: 0.019020019099116325
epoch 3: dev_f1=0.6274509803921569, f1=0.5958429561200924, best_f1=0.5958429561200924
step: 0, loss: 0.014050779864192009
step: 10, loss: 0.02822273224592209
step: 20, loss: 0.04710924252867699
step: 30, loss: 0.009602587670087814
step: 40, loss: 0.06395925581455231
step: 50, loss: 0.027416635304689407
step: 60, loss: 0.06247926130890846
step: 70, loss: 0.03869175538420677
step: 80, loss: 0.15384624898433685
step: 90, loss: 0.001373070408590138
step: 100, loss: 0.00814924668520689
step: 110, loss: 0.007324759382754564
step: 120, loss: 0.011282811872661114
step: 130, loss: 0.038850702345371246
step: 140, loss: 0.059319160878658295
step: 150, loss: 0.0935092344880104
step: 160, loss: 0.022402383387088776
step: 170, loss: 0.0968562513589859
step: 180, loss: 0.01580987684428692
step: 190, loss: 0.03854404389858246
step: 200, loss: 0.01654011569917202
step: 210, loss: 0.04352663457393646
step: 220, loss: 0.045914821326732635
step: 230, loss: 0.042465049773454666
step: 240, loss: 0.0016838822048157454
step: 250, loss: 0.24942749738693237
step: 260, loss: 0.013597507029771805
step: 270, loss: 0.1492891013622284
step: 280, loss: 0.00476448517292738
step: 290, loss: 0.08645737171173096
step: 300, loss: 0.07496845722198486
step: 310, loss: 0.03355487063527107
step: 320, loss: 0.05372441187500954
step: 330, loss: 0.02178722620010376
step: 340, loss: 0.01935288868844509
step: 350, loss: 0.0582156628370285
step: 360, loss: 0.03150118514895439
epoch 4: dev_f1=0.642156862745098, f1=0.6439024390243903, best_f1=0.6439024390243903
step: 0, loss: 0.039647459983825684
step: 10, loss: 0.004733052104711533
step: 20, loss: 0.06880205869674683
step: 30, loss: 0.08278162777423859
step: 40, loss: 0.01432444341480732
step: 50, loss: 0.0009629751439206302
step: 60, loss: 0.00502035953104496
step: 70, loss: 0.13315169513225555
step: 80, loss: 0.009546281769871712
step: 90, loss: 0.0020995570812374353
step: 100, loss: 0.004048570990562439
step: 110, loss: 0.003442807588726282
step: 120, loss: 0.00913867074996233
step: 130, loss: 0.22799667716026306
step: 140, loss: 0.04727516323328018
step: 150, loss: 0.009315875358879566
step: 160, loss: 0.08774936199188232
step: 170, loss: 0.014197787269949913
step: 180, loss: 0.0039041792042553425
step: 190, loss: 0.07066592574119568
step: 200, loss: 0.0030736238695681095
step: 210, loss: 0.040988653898239136
step: 220, loss: 0.06482478976249695
step: 230, loss: 0.015570404939353466
step: 240, loss: 0.0033889326732605696
step: 250, loss: 0.054994046688079834
step: 260, loss: 0.004243809264153242
step: 270, loss: 0.01120462641119957
step: 280, loss: 0.0732630118727684
step: 290, loss: 0.046101175248622894
step: 300, loss: 0.13218337297439575
step: 310, loss: 0.045949313789606094
step: 320, loss: 0.11976103484630585
step: 330, loss: 0.05267392471432686
step: 340, loss: 0.09801267832517624
step: 350, loss: 0.01038343831896782
step: 360, loss: 0.027409594506025314
epoch 5: dev_f1=0.694300518134715, f1=0.6666666666666666, best_f1=0.6666666666666666
step: 0, loss: 0.011957041919231415
step: 10, loss: 0.0006144500803202391
step: 20, loss: 0.003758216043934226
step: 30, loss: 0.005396384280174971
step: 40, loss: 0.004484635777771473
step: 50, loss: 0.0036366088315844536
step: 60, loss: 0.00497555872425437
step: 70, loss: 0.0024408234748989344
step: 80, loss: 0.04117535799741745
step: 90, loss: 0.057137150317430496
step: 100, loss: 0.002543626120314002
step: 110, loss: 0.004084203392267227
step: 120, loss: 0.007199431769549847
step: 130, loss: 0.00522591732442379
step: 140, loss: 0.0012192672584205866
step: 150, loss: 0.00019892795535270125
step: 160, loss: 0.0069231679663062096
step: 170, loss: 0.014374703168869019
step: 180, loss: 0.0016911658458411694
step: 190, loss: 0.01948005147278309
step: 200, loss: 0.00956299901008606
step: 210, loss: 0.11591695249080658
step: 220, loss: 0.018427874892950058
step: 230, loss: 0.019719237461686134
step: 240, loss: 0.002411582972854376
step: 250, loss: 0.0008790811407379806
step: 260, loss: 0.01029706746339798
step: 270, loss: 0.013102919794619083
step: 280, loss: 0.035043686628341675
step: 290, loss: 0.020970774814486504
step: 300, loss: 0.005517187528312206
step: 310, loss: 0.01644277013838291
step: 320, loss: 0.014545805752277374
step: 330, loss: 0.0009292501490563154
step: 340, loss: 0.013423805125057697
step: 350, loss: 0.0009595212759450078
step: 360, loss: 0.030508747324347496
epoch 6: dev_f1=0.6567164179104478, f1=0.6111111111111112, best_f1=0.6666666666666666
step: 0, loss: 0.050045497715473175
step: 10, loss: 0.0304807648062706
step: 20, loss: 0.008364072069525719
step: 30, loss: 0.029676834121346474
step: 40, loss: 0.004052323289215565
step: 50, loss: 0.0005249223322607577
step: 60, loss: 0.029669009149074554
step: 70, loss: 0.0045424532145261765
step: 80, loss: 0.009650561027228832
step: 90, loss: 0.0070207491517066956
step: 100, loss: 0.0006900203297846019
step: 110, loss: 0.0009904993930831552
step: 120, loss: 0.001292225206270814
step: 130, loss: 0.0029044703114777803
step: 140, loss: 0.0016508768312633038
step: 150, loss: 0.0013167912838980556
step: 160, loss: 0.0075952098704874516
step: 170, loss: 0.009401228278875351
step: 180, loss: 0.00974303763359785
step: 190, loss: 0.03806072100996971
step: 200, loss: 0.0021641962230205536
step: 210, loss: 0.0024432619102299213
step: 220, loss: 0.0023828495759516954
step: 230, loss: 0.0003400593705009669
step: 240, loss: 0.004040826577693224
step: 250, loss: 0.00989212654531002
step: 260, loss: 0.007573151960968971
step: 270, loss: 0.06582184135913849
step: 280, loss: 0.023675529286265373
step: 290, loss: 0.00909512396901846
step: 300, loss: 0.0006995927542448044
step: 310, loss: 0.00908430851995945
step: 320, loss: 0.013101484626531601
step: 330, loss: 0.017353631556034088
step: 340, loss: 0.026727790012955666
step: 350, loss: 0.002190394327044487
step: 360, loss: 0.0015704516554251313
epoch 7: dev_f1=0.6536312849162011, f1=0.64, best_f1=0.6666666666666666
step: 0, loss: 0.009496542625129223
step: 10, loss: 0.004410264547914267
step: 20, loss: 0.0007213688222691417
step: 30, loss: 0.00032810430275276303
step: 40, loss: 0.007991474121809006
step: 50, loss: 0.011986726894974709
step: 60, loss: 0.030013997107744217
step: 70, loss: 0.0004631884803529829
step: 80, loss: 0.0020752325654029846
step: 90, loss: 0.00013724675227422267
step: 100, loss: 0.05751638486981392
step: 110, loss: 0.0035715559497475624
step: 120, loss: 0.00784358847886324
step: 130, loss: 0.0013627742882817984
step: 140, loss: 0.011581663973629475
step: 150, loss: 0.02535860799252987
step: 160, loss: 0.00598546490073204
step: 170, loss: 0.0004909797571599483
step: 180, loss: 0.0005705201765522361
step: 190, loss: 0.001637856476008892
step: 200, loss: 0.028904976323246956
step: 210, loss: 0.00018340595124755055
step: 220, loss: 0.0008224728517234325
step: 230, loss: 0.0026672466192394495
step: 240, loss: 0.053286489099264145
step: 250, loss: 0.008984515443444252
step: 260, loss: 0.015453890897333622
step: 270, loss: 0.0037521340418606997
step: 280, loss: 0.14727742969989777
step: 290, loss: 0.04424966871738434
step: 300, loss: 0.0027231352869421244
step: 310, loss: 0.0010528559796512127
step: 320, loss: 0.0005082691204734147
step: 330, loss: 0.0007222843705676496
step: 340, loss: 0.0031012678518891335
step: 350, loss: 0.0016829251544550061
step: 360, loss: 0.07195591181516647
epoch 8: dev_f1=0.6700767263427111, f1=0.6458333333333333, best_f1=0.6666666666666666
step: 0, loss: 0.0075956182554364204
step: 10, loss: 0.0019108302658423781
step: 20, loss: 0.0007280599093064666
step: 30, loss: 0.0015037041157484055
step: 40, loss: 0.04072609543800354
step: 50, loss: 0.024184413254261017
step: 60, loss: 0.0003224507672712207
step: 70, loss: 0.0203437190502882
step: 80, loss: 0.013061054050922394
step: 90, loss: 0.012769819237291813
step: 100, loss: 0.000290828465949744
step: 110, loss: 0.00012286433775443584
step: 120, loss: 0.0011383108794689178
step: 130, loss: 0.000727746170014143
step: 140, loss: 0.11241407692432404
step: 150, loss: 0.0004440325719770044
step: 160, loss: 0.01374949049204588
step: 170, loss: 0.0019709235057234764
step: 180, loss: 0.007294453680515289
step: 190, loss: 0.01607978716492653
step: 200, loss: 0.0037452117539942265
step: 210, loss: 0.000305283727357164
step: 220, loss: 0.00013459660112857819
step: 230, loss: 0.0008440183009952307
step: 240, loss: 0.013738026842474937
step: 250, loss: 0.002756146714091301
step: 260, loss: 0.002759598195552826
step: 270, loss: 0.0012864056043326855
step: 280, loss: 0.0002522253489587456
step: 290, loss: 0.005727763287723064
step: 300, loss: 0.0010956113692373037
step: 310, loss: 0.031625453382730484
step: 320, loss: 0.007846206426620483
step: 330, loss: 0.0016403802437707782
step: 340, loss: 0.00258023664355278
step: 350, loss: 0.053224485367536545
step: 360, loss: 0.17313985526561737
epoch 9: dev_f1=0.6124661246612466, f1=0.6378378378378379, best_f1=0.6666666666666666
step: 0, loss: 0.00012943580804858357
step: 10, loss: 0.003161251312121749
step: 20, loss: 0.0002362595114391297
step: 30, loss: 0.07265843451023102
step: 40, loss: 0.00023589780903421342
step: 50, loss: 0.001184946857392788
step: 60, loss: 0.003433760954067111
step: 70, loss: 0.0001537963980808854
step: 80, loss: 0.00021956019918434322
step: 90, loss: 0.0013717464171350002
step: 100, loss: 0.0013571686577051878
step: 110, loss: 0.00015335956413764507
step: 120, loss: 0.0020755843725055456
step: 130, loss: 0.006435621529817581
step: 140, loss: 0.0002670748217497021
step: 150, loss: 0.000663873681332916
step: 160, loss: 0.00043261819519102573
step: 170, loss: 0.0003792940406128764
step: 180, loss: 0.0024554431438446045
step: 190, loss: 0.0014924167189747095
step: 200, loss: 0.00014056992949917912
step: 210, loss: 0.0001300842995988205
step: 220, loss: 0.02100139483809471
step: 230, loss: 0.002116092015057802
step: 240, loss: 0.08451461791992188
step: 250, loss: 0.00011955759691772982
step: 260, loss: 0.0006436451803892851
step: 270, loss: 0.00279245269484818
step: 280, loss: 0.000294141675112769
step: 290, loss: 0.00023419423087034374
step: 300, loss: 0.007881739176809788
step: 310, loss: 0.002534660743549466
step: 320, loss: 0.007004736922681332
step: 330, loss: 0.010660926811397076
step: 340, loss: 0.06097238510847092
step: 350, loss: 0.021900862455368042
step: 360, loss: 0.019578101113438606
epoch 10: dev_f1=0.6246973365617433, f1=0.6086956521739131, best_f1=0.6666666666666666
step: 0, loss: 0.023677196353673935
step: 10, loss: 0.011308063752949238
step: 20, loss: 0.007090466562658548
step: 30, loss: 0.0003345251316204667
step: 40, loss: 0.00024198100436478853
step: 50, loss: 0.0014174256939440966
step: 60, loss: 0.0011272917035967112
step: 70, loss: 0.0021956833079457283
step: 80, loss: 0.0018135145073756576
step: 90, loss: 0.020982740446925163
step: 100, loss: 0.01637362502515316
step: 110, loss: 0.00021184819343034178
step: 120, loss: 0.0006590250413864851
step: 130, loss: 0.005012868903577328
step: 140, loss: 0.004322827327996492
step: 150, loss: 0.0010389296803623438
step: 160, loss: 0.0019825175404548645
step: 170, loss: 0.004280375316739082
step: 180, loss: 6.878600834170356e-05
step: 190, loss: 0.0006115881842561066
step: 200, loss: 0.03795744851231575
step: 210, loss: 0.0017428762512281537
step: 220, loss: 0.03953266516327858
step: 230, loss: 0.0019801987800747156
step: 240, loss: 0.001379314810037613
step: 250, loss: 0.001916075125336647
step: 260, loss: 0.023502210155129433
step: 270, loss: 0.0013320508878678083
step: 280, loss: 0.0004601037653628737
step: 290, loss: 0.002108655171468854
step: 300, loss: 0.0010321756126359105
step: 310, loss: 0.0007115849293768406
step: 320, loss: 0.0017458850052207708
step: 330, loss: 0.002494956599548459
step: 340, loss: 0.0003504220803733915
step: 350, loss: 0.0014936545630916953
step: 360, loss: 0.0002077336102956906
epoch 11: dev_f1=0.6506666666666667, f1=0.6446280991735537, best_f1=0.6666666666666666
step: 0, loss: 0.004911684896796942
step: 10, loss: 0.005011281929910183
step: 20, loss: 0.00011220754822716117
step: 30, loss: 0.00044525685370899737
step: 40, loss: 0.0002596205740701407
step: 50, loss: 0.012001042254269123
step: 60, loss: 0.002259649336338043
step: 70, loss: 0.06447996199131012
step: 80, loss: 0.015692146494984627
step: 90, loss: 0.0006770783220417798
step: 100, loss: 0.0001923523668665439
step: 110, loss: 0.005934453569352627
step: 120, loss: 0.0016600977396592498
step: 130, loss: 0.0003151543205603957
step: 140, loss: 0.0027593974955379963
step: 150, loss: 0.04399959370493889
step: 160, loss: 0.0013509606942534447
step: 170, loss: 0.0003445538750384003
step: 180, loss: 0.06638623028993607
step: 190, loss: 0.0006622220389544964
step: 200, loss: 0.0005927434540353715
step: 210, loss: 8.166977931978181e-05
step: 220, loss: 0.0014016431523486972
step: 230, loss: 0.0003918982110917568
step: 240, loss: 0.004962329752743244
step: 250, loss: 0.000493678729981184
step: 260, loss: 0.03615960851311684
step: 270, loss: 0.004381953272968531
step: 280, loss: 7.086350524332374e-05
step: 290, loss: 0.03511343151330948
step: 300, loss: 0.005806135479360819
step: 310, loss: 0.0003179565246682614
step: 320, loss: 0.0011576995020732284
step: 330, loss: 0.03314058855175972
step: 340, loss: 0.0005057626985944808
step: 350, loss: 0.0003176851896569133
step: 360, loss: 0.0015036737313494086
epoch 12: dev_f1=0.6686046511627907, f1=0.6548672566371682, best_f1=0.6666666666666666
step: 0, loss: 0.0002505045849829912
step: 10, loss: 0.00024957029381766915
step: 20, loss: 0.009529519826173782
step: 30, loss: 0.001372812781482935
step: 40, loss: 0.00012115872232243419
step: 50, loss: 0.0003072072868235409
step: 60, loss: 0.0003864183381665498
step: 70, loss: 0.0038862964138388634
step: 80, loss: 0.10115698724985123
step: 90, loss: 0.004311766475439072
step: 100, loss: 0.00099184678401798
step: 110, loss: 9.405911259818822e-05
step: 120, loss: 0.00036019846447743475
step: 130, loss: 0.00037654387415386736
step: 140, loss: 0.0049521359615027905
step: 150, loss: 0.0009572069975547493
step: 160, loss: 0.0008810535655356944
step: 170, loss: 9.301443060394377e-05
step: 180, loss: 0.01470164954662323
step: 190, loss: 0.000575769750867039
step: 200, loss: 0.00041092693572863936
step: 210, loss: 0.0001492834708187729
step: 220, loss: 0.009280134923756123
step: 230, loss: 0.00014201914018485695
step: 240, loss: 7.531641313107684e-05
step: 250, loss: 0.000170567276654765
step: 260, loss: 0.0008777317125350237
step: 270, loss: 0.0052373651415109634
step: 280, loss: 0.0011338102631270885
step: 290, loss: 0.0005099238478578627
step: 300, loss: 0.00020133460930082947
step: 310, loss: 0.00018528543296270072
step: 320, loss: 9.712478640722111e-05
step: 330, loss: 0.0004202585550956428
step: 340, loss: 0.00024306291015818715
step: 350, loss: 0.003689379896968603
step: 360, loss: 0.00043435482075437903
epoch 13: dev_f1=0.6613756613756614, f1=0.6684350132625995, best_f1=0.6666666666666666
step: 0, loss: 0.00025404116604477167
step: 10, loss: 0.00013642580597661436
step: 20, loss: 9.138356108451262e-05
step: 30, loss: 0.0001581329997861758
step: 40, loss: 8.102456195047125e-05
step: 50, loss: 0.0030862295534461737
step: 60, loss: 0.0001310941152041778
step: 70, loss: 0.0003324311110191047
step: 80, loss: 6.538380694109946e-05
step: 90, loss: 0.00013762585876975209
step: 100, loss: 0.0008586741168983281
step: 110, loss: 0.005241759587079287
step: 120, loss: 0.022657914087176323
step: 130, loss: 9.525984205538407e-05
step: 140, loss: 0.00010823745833477005
step: 150, loss: 4.0591701690573245e-05
step: 160, loss: 0.0002088606561301276
step: 170, loss: 0.002826953772455454
step: 180, loss: 2.2202160835149698e-05
step: 190, loss: 8.405311382375658e-05
step: 200, loss: 7.837448356440291e-05
step: 210, loss: 0.00017812404257711023
step: 220, loss: 0.00013308021880220622
step: 230, loss: 2.7980126105831005e-05
step: 240, loss: 0.013324517756700516
step: 250, loss: 7.723608723608777e-05
step: 260, loss: 0.0006517723086290061
step: 270, loss: 0.0009709220612421632
step: 280, loss: 0.0014345586532726884
step: 290, loss: 0.10041772574186325
step: 300, loss: 0.000758288602810353
step: 310, loss: 0.0003085227217525244
step: 320, loss: 0.0019524674862623215
step: 330, loss: 0.01239828858524561
step: 340, loss: 0.0003330271865706891
step: 350, loss: 0.00010853959975065663
step: 360, loss: 0.00011457929213065654
epoch 14: dev_f1=0.6595174262734586, f1=0.6666666666666666, best_f1=0.6666666666666666
step: 0, loss: 0.0001325067860307172
step: 10, loss: 5.6004588259384036e-05
step: 20, loss: 0.00010274644591845572
step: 30, loss: 0.0022643236443400383
step: 40, loss: 6.158331234473735e-05
step: 50, loss: 0.00029809860279783607
step: 60, loss: 0.002906371606513858
step: 70, loss: 0.00017249470693059266
step: 80, loss: 0.0024143389891833067
step: 90, loss: 1.9423281628405675e-05
step: 100, loss: 0.0003729098243638873
step: 110, loss: 9.289848821936175e-05
step: 120, loss: 0.0021030891221016645
step: 130, loss: 0.0002887760638259351
step: 140, loss: 4.161694596405141e-05
step: 150, loss: 7.818942685844377e-05
step: 160, loss: 8.268681267509237e-05
step: 170, loss: 0.00012315150524955243
step: 180, loss: 0.0003155130834784359
step: 190, loss: 5.859291923115961e-05
step: 200, loss: 0.00017085019499063492
step: 210, loss: 4.3701289541786537e-05
step: 220, loss: 0.00022971309954300523
step: 230, loss: 0.00017298159946221858
step: 240, loss: 0.0003313669585622847
step: 250, loss: 4.8260135372402146e-05
step: 260, loss: 0.0005987816257402301
step: 270, loss: 0.00024166422372218221
step: 280, loss: 0.0005707306554540992
step: 290, loss: 0.00016047502867877483
step: 300, loss: 0.00015887891640886664
step: 310, loss: 0.0020439960062503815
step: 320, loss: 0.00010972917516482994
step: 330, loss: 0.0012767111184075475
step: 340, loss: 0.0003208182752132416
step: 350, loss: 0.0011812744196504354
step: 360, loss: 0.00016268299077637494
epoch 15: dev_f1=0.6453488372093024, f1=0.6572237960339944, best_f1=0.6666666666666666
step: 0, loss: 0.0028062101919203997
step: 10, loss: 4.858574175159447e-05
step: 20, loss: 0.00033757559140212834
step: 30, loss: 0.0003219663631170988
step: 40, loss: 8.1814439909067e-05
step: 50, loss: 0.0016855106223374605
step: 60, loss: 3.766830559470691e-05
step: 70, loss: 0.00018404333968646824
step: 80, loss: 0.00029271841049194336
step: 90, loss: 0.0001572405017213896
step: 100, loss: 0.0011805675458163023
step: 110, loss: 0.0001874071458587423
step: 120, loss: 0.00013653977657668293
step: 130, loss: 0.0007118598441593349
step: 140, loss: 0.00012970219540875405
step: 150, loss: 7.053380977595225e-05
step: 160, loss: 3.91558714909479e-05
step: 170, loss: 0.00037596310721710324
step: 180, loss: 3.79509583581239e-05
step: 190, loss: 0.006579949986189604
step: 200, loss: 0.0008953858050517738
step: 210, loss: 0.00011439548688940704
step: 220, loss: 0.0006158639444038272
step: 230, loss: 0.00011769052798626944
step: 240, loss: 4.139593875152059e-05
step: 250, loss: 0.00016197418153751642
step: 260, loss: 4.91779537696857e-05
step: 270, loss: 2.7811382096842863e-05
step: 280, loss: 0.00018818862736225128
step: 290, loss: 3.335851215524599e-05
step: 300, loss: 3.148476025671698e-05
step: 310, loss: 0.003810703055933118
step: 320, loss: 0.00016415944264736027
step: 330, loss: 0.0032157201785594225
step: 340, loss: 0.00048165745101869106
step: 350, loss: 0.0013278517872095108
step: 360, loss: 0.00011220021406188607
epoch 16: dev_f1=0.6793478260869564, f1=0.6595744680851063, best_f1=0.6666666666666666
step: 0, loss: 0.00019565765978768468
step: 10, loss: 0.00012481279554776847
step: 20, loss: 6.738439697073773e-05
step: 30, loss: 0.003956998232752085
step: 40, loss: 0.000549854536075145
step: 50, loss: 0.00013462925562635064
step: 60, loss: 3.420740904402919e-05
step: 70, loss: 0.0002038491511484608
step: 80, loss: 5.541125574382022e-05
step: 90, loss: 0.0021879086270928383
step: 100, loss: 1.8428725525154732e-05
step: 110, loss: 0.008049107156693935
step: 120, loss: 4.739284486277029e-05
step: 130, loss: 0.0004196202498860657
step: 140, loss: 0.00010149608715437353
step: 150, loss: 1.541498932056129e-05
step: 160, loss: 0.00030008816975168884
step: 170, loss: 0.0004708696505986154
step: 180, loss: 9.332448098575696e-05
step: 190, loss: 4.740032818517648e-05
step: 200, loss: 6.085609129513614e-05
step: 210, loss: 0.023675555363297462
step: 220, loss: 4.796620851266198e-05
step: 230, loss: 3.707911673700437e-05
step: 240, loss: 0.00018342830298934132
step: 250, loss: 0.020237650722265244
step: 260, loss: 9.032382513396442e-05
step: 270, loss: 6.644282984780148e-05
step: 280, loss: 3.5846824175678194e-05
step: 290, loss: 0.0001305239275097847
step: 300, loss: 0.00010827236110344529
step: 310, loss: 0.00011499127140268683
step: 320, loss: 0.0003566936356946826
step: 330, loss: 4.0023969631874934e-05
step: 340, loss: 0.003907112404704094
step: 350, loss: 0.0011330920970067382
step: 360, loss: 6.450182263506576e-05
epoch 17: dev_f1=0.6666666666666666, f1=0.6542553191489361, best_f1=0.6666666666666666
step: 0, loss: 0.00019102693477179855
step: 10, loss: 9.517483704257756e-05
step: 20, loss: 0.0001634174695936963
step: 30, loss: 8.063388668233529e-05
step: 40, loss: 5.098079418530688e-05
step: 50, loss: 4.035876190755516e-05
step: 60, loss: 1.916999462991953e-05
step: 70, loss: 4.927806367049925e-05
step: 80, loss: 8.939104009186849e-05
step: 90, loss: 0.0002150364889530465
step: 100, loss: 0.0002397098724031821
step: 110, loss: 8.190391963580623e-05
step: 120, loss: 8.536620589438826e-05
step: 130, loss: 7.1606962592341e-05
step: 140, loss: 0.00030079379212111235
step: 150, loss: 6.523679621750489e-05
step: 160, loss: 0.0009359783725813031
step: 170, loss: 0.0001708267955109477
step: 180, loss: 5.875556234968826e-05
step: 190, loss: 2.028380913543515e-05
step: 200, loss: 4.721347795566544e-05
step: 210, loss: 7.191381882876158e-05
step: 220, loss: 0.0022302574943751097
step: 230, loss: 0.0001718304120004177
step: 240, loss: 0.00022247589367907494
step: 250, loss: 9.801249689189717e-05
step: 260, loss: 0.000316396210109815
step: 270, loss: 0.0001065914475475438
step: 280, loss: 8.757242903811857e-05
step: 290, loss: 2.7900849090656266e-05
step: 300, loss: 1.6882817362784408e-05
step: 310, loss: 0.0050211697816848755
step: 320, loss: 6.304598355200142e-05
step: 330, loss: 0.00019042285566683859
step: 340, loss: 3.342553100083023e-05
step: 350, loss: 0.00010849734098883346
step: 360, loss: 2.3710448658675887e-05
epoch 18: dev_f1=0.6551724137931034, f1=0.668555240793201, best_f1=0.6666666666666666
step: 0, loss: 0.00031646419665776193
step: 10, loss: 5.664092896040529e-05
step: 20, loss: 9.69811444520019e-05
step: 30, loss: 0.00011113328946521506
step: 40, loss: 0.00026382668875157833
step: 50, loss: 4.0009144868236035e-05
step: 60, loss: 0.021569736301898956
step: 70, loss: 0.005774518940597773
step: 80, loss: 3.878240386256948e-05
step: 90, loss: 2.6068582883453928e-05
step: 100, loss: 4.835857907892205e-05
step: 110, loss: 0.0002724491059780121
step: 120, loss: 0.00012388723553158343
step: 130, loss: 3.436304905335419e-05
step: 140, loss: 0.00017553832731209695
step: 150, loss: 2.546130053815432e-05
step: 160, loss: 7.508967246394604e-05
step: 170, loss: 3.599125557229854e-05
step: 180, loss: 2.6295965653844178e-05
step: 190, loss: 6.078493970562704e-05
step: 200, loss: 0.0004730655928142369
step: 210, loss: 9.837410470936447e-05
step: 220, loss: 0.0013304308522492647
step: 230, loss: 0.034825026988983154
step: 240, loss: 0.00016619492089375854
step: 250, loss: 3.004954123753123e-05
step: 260, loss: 0.00024816746008582413
step: 270, loss: 4.063108281116001e-05
step: 280, loss: 9.580637561157346e-05
step: 290, loss: 0.0005962990690022707
step: 300, loss: 0.00010605496208881959
step: 310, loss: 0.00044081243686378
step: 320, loss: 0.0001307701168116182
step: 330, loss: 4.010407792520709e-05
step: 340, loss: 0.0001124459522543475
step: 350, loss: 3.5713099350687116e-05
step: 360, loss: 2.9972150514367968e-05
epoch 19: dev_f1=0.6631016042780749, f1=0.6541554959785524, best_f1=0.6666666666666666
step: 0, loss: 0.0001424817310180515
step: 10, loss: 0.0028285428415983915
step: 20, loss: 9.224753739545122e-05
step: 30, loss: 2.9637240004376508e-05
step: 40, loss: 3.8013458834029734e-05
step: 50, loss: 2.5736469979165122e-05
step: 60, loss: 0.0012514443369582295
step: 70, loss: 1.4129845112620387e-05
step: 80, loss: 1.7706030121189542e-05
step: 90, loss: 7.571759488200769e-05
step: 100, loss: 5.2288651204435155e-05
step: 110, loss: 2.036475962086115e-05
step: 120, loss: 3.639266287791543e-05
step: 130, loss: 4.580953100230545e-05
step: 140, loss: 4.719243952422403e-05
step: 150, loss: 0.005205940920859575
step: 160, loss: 0.0031208025757223368
step: 170, loss: 0.0002045960573013872
step: 180, loss: 7.07513972884044e-05
step: 190, loss: 0.00010079011553898454
step: 200, loss: 0.0001134889607783407
step: 210, loss: 0.0002908033784478903
step: 220, loss: 2.438127194182016e-05
step: 230, loss: 0.0019052565330639482
step: 240, loss: 8.915490616345778e-05
step: 250, loss: 4.170798638369888e-05
step: 260, loss: 4.789845843333751e-05
step: 270, loss: 0.00010110998118761927
step: 280, loss: 0.00019926507957279682
step: 290, loss: 8.188878564396873e-05
step: 300, loss: 8.275810978375375e-05
step: 310, loss: 4.088510468136519e-05
step: 320, loss: 0.0009772360790520906
step: 330, loss: 3.75134804926347e-05
step: 340, loss: 0.00020680326269939542
step: 350, loss: 0.00016833542031235993
step: 360, loss: 4.806726428796537e-05
epoch 20: dev_f1=0.6684491978609626, f1=0.6525198938992043, best_f1=0.6666666666666666
