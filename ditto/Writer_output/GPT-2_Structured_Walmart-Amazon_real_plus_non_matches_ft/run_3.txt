cuda
Device: cuda
step: 0, loss: 0.7495892643928528
step: 10, loss: 0.24596472084522247
step: 20, loss: 0.48856568336486816
step: 30, loss: 0.14389373362064362
step: 40, loss: 0.5098170042037964
step: 50, loss: 0.13910476863384247
step: 60, loss: 0.2406931072473526
step: 70, loss: 0.03729145973920822
step: 80, loss: 0.3036799430847168
step: 90, loss: 0.1433691531419754
step: 100, loss: 0.1572026163339615
step: 110, loss: 0.13847951591014862
step: 120, loss: 0.5098410844802856
step: 130, loss: 0.15305258333683014
step: 140, loss: 0.3279084265232086
step: 150, loss: 0.22506952285766602
step: 160, loss: 0.1455024778842926
step: 170, loss: 0.016890820115804672
step: 180, loss: 0.3047600984573364
step: 190, loss: 0.3860554099082947
step: 200, loss: 0.052989766001701355
step: 210, loss: 0.02885025553405285
step: 220, loss: 0.13114148378372192
step: 230, loss: 0.2114076167345047
step: 240, loss: 0.08927583694458008
step: 250, loss: 0.14419347047805786
step: 260, loss: 0.13954968750476837
step: 270, loss: 0.47038617730140686
step: 280, loss: 0.14125075936317444
step: 290, loss: 0.5089333653450012
step: 300, loss: 0.046761997044086456
step: 310, loss: 0.22359499335289001
step: 320, loss: 0.28036680817604065
step: 330, loss: 0.1366322934627533
step: 340, loss: 0.03911270946264267
step: 350, loss: 0.21406389772891998
step: 360, loss: 0.12915322184562683
epoch 1: dev_f1=0.21195973949082297, f1=0.21663674446439257, best_f1=0.21663674446439257
step: 0, loss: 0.14579211175441742
step: 10, loss: 0.12775404751300812
step: 20, loss: 0.12694130837917328
step: 30, loss: 0.1230291947722435
step: 40, loss: 0.20522445440292358
step: 50, loss: 0.35896942019462585
step: 60, loss: 0.21069900691509247
step: 70, loss: 0.12229624390602112
step: 80, loss: 0.20459668338298798
step: 90, loss: 0.3291490077972412
step: 100, loss: 0.14362719655036926
step: 110, loss: 0.28208592534065247
step: 120, loss: 0.3846171498298645
step: 130, loss: 0.27458471059799194
step: 140, loss: 0.12079574167728424
step: 150, loss: 0.11861000955104828
step: 160, loss: 0.17545998096466064
step: 170, loss: 0.11174694448709488
step: 180, loss: 0.18583649396896362
step: 190, loss: 0.04694361239671707
step: 200, loss: 0.021193232387304306
step: 210, loss: 0.11862960457801819
step: 220, loss: 0.2018267810344696
step: 230, loss: 0.21030385792255402
step: 240, loss: 0.39927181601524353
step: 250, loss: 0.1724354773759842
step: 260, loss: 0.41333526372909546
step: 270, loss: 0.13353867828845978
step: 280, loss: 0.12600155174732208
step: 290, loss: 0.13063229620456696
step: 300, loss: 0.11946927756071091
step: 310, loss: 0.09676078706979752
step: 320, loss: 0.05745306611061096
step: 330, loss: 0.33276715874671936
step: 340, loss: 0.15420827269554138
step: 350, loss: 0.08483178168535233
step: 360, loss: 0.3431888818740845
epoch 2: dev_f1=0.3855932203389831, f1=0.39999999999999997, best_f1=0.39999999999999997
step: 0, loss: 0.0557815246284008
step: 10, loss: 0.24075518548488617
step: 20, loss: 0.09109358489513397
step: 30, loss: 0.05376269668340683
step: 40, loss: 0.08913148194551468
step: 50, loss: 0.1353835165500641
step: 60, loss: 0.09525300562381744
step: 70, loss: 0.1898624151945114
step: 80, loss: 0.014169955626130104
step: 90, loss: 0.025179805234074593
step: 100, loss: 0.14394155144691467
step: 110, loss: 0.030064187943935394
step: 120, loss: 0.10451735556125641
step: 130, loss: 0.20123746991157532
step: 140, loss: 0.017611419782042503
step: 150, loss: 0.2686479687690735
step: 160, loss: 0.11349368840456009
step: 170, loss: 0.17297230660915375
step: 180, loss: 0.06692522019147873
step: 190, loss: 0.03971186280250549
step: 200, loss: 0.20293478667736053
step: 210, loss: 0.14292369782924652
step: 220, loss: 0.0521264411509037
step: 230, loss: 0.20345373451709747
step: 240, loss: 0.2627478837966919
step: 250, loss: 0.1493636667728424
step: 260, loss: 0.1747359037399292
step: 270, loss: 0.07650090754032135
step: 280, loss: 0.22834593057632446
step: 290, loss: 0.11113253980875015
step: 300, loss: 0.015518288128077984
step: 310, loss: 0.06202962249517441
step: 320, loss: 0.12092343717813492
step: 330, loss: 0.06526025384664536
step: 340, loss: 0.008435899391770363
step: 350, loss: 0.019294116646051407
step: 360, loss: 0.043808307498693466
epoch 3: dev_f1=0.46458923512747874, f1=0.3619047619047619, best_f1=0.3619047619047619
step: 0, loss: 0.018125906586647034
step: 10, loss: 0.18481573462486267
step: 20, loss: 0.030855756253004074
step: 30, loss: 0.06838931143283844
step: 40, loss: 0.22391670942306519
step: 50, loss: 0.07266402989625931
step: 60, loss: 0.07362152636051178
step: 70, loss: 0.06560895591974258
step: 80, loss: 0.09727801382541656
step: 90, loss: 0.12769344449043274
step: 100, loss: 0.05663603916764259
step: 110, loss: 0.0024563665501773357
step: 120, loss: 0.15003889799118042
step: 130, loss: 0.05925416573882103
step: 140, loss: 0.005004443693906069
step: 150, loss: 0.047855403274297714
step: 160, loss: 0.0787910595536232
step: 170, loss: 0.015384252183139324
step: 180, loss: 0.3444957137107849
step: 190, loss: 0.11918803304433823
step: 200, loss: 0.015990816056728363
step: 210, loss: 0.1518026739358902
step: 220, loss: 0.050462644547224045
step: 230, loss: 0.061937421560287476
step: 240, loss: 0.04489404335618019
step: 250, loss: 0.05624624714255333
step: 260, loss: 0.07966843992471695
step: 270, loss: 0.14874817430973053
step: 280, loss: 0.051803719252347946
step: 290, loss: 0.020965920761227608
step: 300, loss: 0.0626533031463623
step: 310, loss: 0.08566591143608093
step: 320, loss: 0.04516427218914032
step: 330, loss: 0.12725929915905
step: 340, loss: 0.44677579402923584
step: 350, loss: 0.07965030521154404
step: 360, loss: 0.22551989555358887
epoch 4: dev_f1=0.5811965811965812, f1=0.5428571428571428, best_f1=0.5428571428571428
step: 0, loss: 0.08972756564617157
step: 10, loss: 0.1329461932182312
step: 20, loss: 0.012090999633073807
step: 30, loss: 0.07812871783971786
step: 40, loss: 0.03002746030688286
step: 50, loss: 0.033041276037693024
step: 60, loss: 0.017258387058973312
step: 70, loss: 0.01701413281261921
step: 80, loss: 0.04470868036150932
step: 90, loss: 0.037874553352594376
step: 100, loss: 0.018775174394249916
step: 110, loss: 0.21361462771892548
step: 120, loss: 0.1045866534113884
step: 130, loss: 0.07231877744197845
step: 140, loss: 0.07134176045656204
step: 150, loss: 0.05646195635199547
step: 160, loss: 0.20387010276317596
step: 170, loss: 0.00983178149908781
step: 180, loss: 0.2860414385795593
step: 190, loss: 0.1617254912853241
step: 200, loss: 0.018239201977849007
step: 210, loss: 0.02395063452422619
step: 220, loss: 0.009401310235261917
step: 230, loss: 0.010174592025578022
step: 240, loss: 0.13080276548862457
step: 250, loss: 0.02930123172700405
step: 260, loss: 0.0059945909306406975
step: 270, loss: 0.037597741931676865
step: 280, loss: 0.1883806586265564
step: 290, loss: 0.09070347249507904
step: 300, loss: 0.014616038650274277
step: 310, loss: 0.009478750638663769
step: 320, loss: 0.052062906324863434
step: 330, loss: 0.2801674008369446
step: 340, loss: 0.026248160749673843
step: 350, loss: 0.06890895962715149
step: 360, loss: 0.012748034670948982
epoch 5: dev_f1=0.6162162162162161, f1=0.625668449197861, best_f1=0.625668449197861
step: 0, loss: 0.02033049426972866
step: 10, loss: 0.01645224168896675
step: 20, loss: 0.003252435941249132
step: 30, loss: 0.013241616077721119
step: 40, loss: 0.0038162865675985813
step: 50, loss: 0.06683158129453659
step: 60, loss: 0.008363064378499985
step: 70, loss: 0.02888183668255806
step: 80, loss: 0.05572466924786568
step: 90, loss: 0.027354180812835693
step: 100, loss: 0.003020830685272813
step: 110, loss: 0.017739849165081978
step: 120, loss: 0.014345966279506683
step: 130, loss: 0.004234782885760069
step: 140, loss: 0.003139508655294776
step: 150, loss: 0.03616749495267868
step: 160, loss: 0.019395293667912483
step: 170, loss: 0.10978852957487106
step: 180, loss: 0.026995636522769928
step: 190, loss: 0.054788414388895035
step: 200, loss: 0.0021034961100667715
step: 210, loss: 0.006677016615867615
step: 220, loss: 0.16819554567337036
step: 230, loss: 0.015618547797203064
step: 240, loss: 0.06486505270004272
step: 250, loss: 0.005315585061907768
step: 260, loss: 0.042522966861724854
step: 270, loss: 0.013387766666710377
step: 280, loss: 0.011865487322211266
step: 290, loss: 0.012614362873136997
step: 300, loss: 0.004146744962781668
step: 310, loss: 0.011695366352796555
step: 320, loss: 0.0660562664270401
step: 330, loss: 0.0275187399238348
step: 340, loss: 0.01569666713476181
step: 350, loss: 0.02176552638411522
step: 360, loss: 0.04075656086206436
epoch 6: dev_f1=0.6005089058524172, f1=0.568421052631579, best_f1=0.625668449197861
step: 0, loss: 0.07818073779344559
step: 10, loss: 0.01796591281890869
step: 20, loss: 0.08788248896598816
step: 30, loss: 0.0038164956495165825
step: 40, loss: 0.07405480742454529
step: 50, loss: 0.0004244465089868754
step: 60, loss: 0.0005407413118518889
step: 70, loss: 0.001372569240629673
step: 80, loss: 0.0036982973106205463
step: 90, loss: 0.008271929807960987
step: 100, loss: 0.04012652859091759
step: 110, loss: 0.005120361689478159
step: 120, loss: 0.04022177681326866
step: 130, loss: 0.005816704127937555
step: 140, loss: 0.0014930685283616185
step: 150, loss: 0.009410277009010315
step: 160, loss: 0.010132050141692162
step: 170, loss: 0.002054225653409958
step: 180, loss: 0.001218436867929995
step: 190, loss: 0.005487150512635708
step: 200, loss: 0.1296818107366562
step: 210, loss: 0.09473227709531784
step: 220, loss: 0.01090217288583517
step: 230, loss: 0.07379569113254547
step: 240, loss: 0.00411470141261816
step: 250, loss: 0.01750093512237072
step: 260, loss: 0.013946354389190674
step: 270, loss: 0.04032687097787857
step: 280, loss: 0.005783251021057367
step: 290, loss: 0.050092875957489014
step: 300, loss: 0.0027273516170680523
step: 310, loss: 0.0019549906719475985
step: 320, loss: 0.007344913203269243
step: 330, loss: 0.005861335434019566
step: 340, loss: 0.018767181783914566
step: 350, loss: 0.021191289648413658
step: 360, loss: 0.07877165824174881
epoch 7: dev_f1=0.6413043478260869, f1=0.6055555555555556, best_f1=0.6055555555555556
step: 0, loss: 0.008072997443377972
step: 10, loss: 0.0003858468262478709
step: 20, loss: 0.000346884538885206
step: 30, loss: 0.012852216139435768
step: 40, loss: 0.0005529184127226472
step: 50, loss: 0.0004159628297202289
step: 60, loss: 0.11079811304807663
step: 70, loss: 0.006673598196357489
step: 80, loss: 0.0023398015182465315
step: 90, loss: 0.0012227677507326007
step: 100, loss: 0.0763142928481102
step: 110, loss: 0.016622135415673256
step: 120, loss: 0.00424959696829319
step: 130, loss: 0.0028189406730234623
step: 140, loss: 0.0013866745866835117
step: 150, loss: 0.0467817448079586
step: 160, loss: 0.005148763302713633
step: 170, loss: 0.0037972191348671913
step: 180, loss: 0.213511124253273
step: 190, loss: 0.005931817460805178
step: 200, loss: 0.0006565043586306274
step: 210, loss: 0.016935361549258232
step: 220, loss: 0.010839014314115047
step: 230, loss: 0.0016865739598870277
step: 240, loss: 0.0003131184203084558
step: 250, loss: 0.0003628781414590776
step: 260, loss: 0.0007891408167779446
step: 270, loss: 0.0015797788510099053
step: 280, loss: 0.023389367386698723
step: 290, loss: 0.027619948610663414
step: 300, loss: 0.004011864773929119
step: 310, loss: 0.017244813963770866
step: 320, loss: 0.007756364997476339
step: 330, loss: 0.0022618735674768686
step: 340, loss: 0.09450097382068634
step: 350, loss: 0.003028147853910923
step: 360, loss: 0.012420643121004105
epoch 8: dev_f1=0.609375, f1=0.6005089058524172, best_f1=0.6055555555555556
step: 0, loss: 0.0671296939253807
step: 10, loss: 0.015316194854676723
step: 20, loss: 0.027162663638591766
step: 30, loss: 0.04696373641490936
step: 40, loss: 0.0069214641116559505
step: 50, loss: 0.0037967355456203222
step: 60, loss: 0.006980456877499819
step: 70, loss: 0.0012687387643381953
step: 80, loss: 0.052009716629981995
step: 90, loss: 0.0019588307477533817
step: 100, loss: 0.023171955719590187
step: 110, loss: 0.005339275114238262
step: 120, loss: 0.037370216101408005
step: 130, loss: 0.010846815072000027
step: 140, loss: 0.007967728190124035
step: 150, loss: 0.0027241543866693974
step: 160, loss: 0.0023738518357276917
step: 170, loss: 0.00033479160629212856
step: 180, loss: 0.0002928217872977257
step: 190, loss: 0.0014698316808789968
step: 200, loss: 0.0816975012421608
step: 210, loss: 0.002676344709470868
step: 220, loss: 0.00015256241022143513
step: 230, loss: 0.0026344959624111652
step: 240, loss: 0.003530673449859023
step: 250, loss: 0.002614394761621952
step: 260, loss: 0.007087447214871645
step: 270, loss: 0.02415633760392666
step: 280, loss: 0.011072281748056412
step: 290, loss: 0.05229664221405983
step: 300, loss: 0.0013041518395766616
step: 310, loss: 0.03707234561443329
step: 320, loss: 0.012750742956995964
step: 330, loss: 0.05130591616034508
step: 340, loss: 0.002397621050477028
step: 350, loss: 0.1767040342092514
step: 360, loss: 0.04667427018284798
epoch 9: dev_f1=0.6157894736842106, f1=0.6422976501305484, best_f1=0.6055555555555556
step: 0, loss: 0.0018423309084028006
step: 10, loss: 0.0012209867127239704
step: 20, loss: 0.0004181783879175782
step: 30, loss: 7.031829591142014e-05
step: 40, loss: 0.0007487109396606684
step: 50, loss: 0.02876850590109825
step: 60, loss: 0.00036942926817573607
step: 70, loss: 0.0009858388220891356
step: 80, loss: 0.00040460596210323274
step: 90, loss: 0.0028058879543095827
step: 100, loss: 0.0005509924376383424
step: 110, loss: 0.16413801908493042
step: 120, loss: 0.00550040090456605
step: 130, loss: 0.047625429928302765
step: 140, loss: 0.01959519274532795
step: 150, loss: 0.004793170839548111
step: 160, loss: 0.000665507570374757
step: 170, loss: 0.0018617878668010235
step: 180, loss: 0.0009760116809047759
step: 190, loss: 0.0005546227330341935
step: 200, loss: 0.009680710732936859
step: 210, loss: 0.08359846472740173
step: 220, loss: 0.09899718314409256
step: 230, loss: 0.0017837506020441651
step: 240, loss: 0.003429209813475609
step: 250, loss: 0.009781971573829651
step: 260, loss: 0.0007057766779325902
step: 270, loss: 0.0015906963963061571
step: 280, loss: 0.004629792179912329
step: 290, loss: 0.0009817470563575625
step: 300, loss: 0.0026877892669290304
step: 310, loss: 0.001853889087215066
step: 320, loss: 0.0036281596403568983
step: 330, loss: 0.0002092165086651221
step: 340, loss: 0.0012680783402174711
step: 350, loss: 0.04067555442452431
step: 360, loss: 0.005103031639009714
epoch 10: dev_f1=0.6226912928759895, f1=0.6145552560646901, best_f1=0.6055555555555556
step: 0, loss: 0.04739135503768921
step: 10, loss: 0.00025391855160705745
step: 20, loss: 0.0004510413855314255
step: 30, loss: 0.0002209560916526243
step: 40, loss: 0.003829389810562134
step: 50, loss: 0.02658444084227085
step: 60, loss: 0.0011135527165606618
step: 70, loss: 0.0027475745882838964
step: 80, loss: 0.07979688793420792
step: 90, loss: 0.021556923165917397
step: 100, loss: 0.0002947609464172274
step: 110, loss: 0.00033867775346152484
step: 120, loss: 0.0001242031139554456
step: 130, loss: 0.0001744000765029341
step: 140, loss: 0.0004485019890125841
step: 150, loss: 0.0010052021825686097
step: 160, loss: 0.0007147321593947709
step: 170, loss: 0.014057125896215439
step: 180, loss: 0.0006201028008945286
step: 190, loss: 0.0002741046482697129
step: 200, loss: 0.004616408608853817
step: 210, loss: 0.00027065593167208135
step: 220, loss: 0.011711398139595985
step: 230, loss: 0.02797834202647209
step: 240, loss: 0.0004692979855462909
step: 250, loss: 8.461096876999363e-05
step: 260, loss: 0.023244768381118774
step: 270, loss: 0.004032650031149387
step: 280, loss: 0.050302907824516296
step: 290, loss: 0.012392228469252586
step: 300, loss: 0.0016264597652480006
step: 310, loss: 0.0008472492336295545
step: 320, loss: 0.0012431064387783408
step: 330, loss: 0.0004033440782222897
step: 340, loss: 0.0004846062511205673
step: 350, loss: 0.032753512263298035
step: 360, loss: 0.010168178007006645
epoch 11: dev_f1=0.6264367816091954, f1=0.6355685131195336, best_f1=0.6055555555555556
step: 0, loss: 0.0009601326892152429
step: 10, loss: 0.08121581375598907
step: 20, loss: 0.0004609232419170439
step: 30, loss: 0.0017351519782096148
step: 40, loss: 0.00018673062731977552
step: 50, loss: 0.0009935321286320686
step: 60, loss: 0.1553339809179306
step: 70, loss: 0.00030334459734149277
step: 80, loss: 0.01096661388874054
step: 90, loss: 0.0038882577791810036
step: 100, loss: 0.00034751047496683896
step: 110, loss: 0.0038431596476584673
step: 120, loss: 0.015784544870257378
step: 130, loss: 0.004958398174494505
step: 140, loss: 0.00043960753828287125
step: 150, loss: 0.0009225759422406554
step: 160, loss: 0.000345437612850219
step: 170, loss: 0.0006091698305681348
step: 180, loss: 0.030002864077687263
step: 190, loss: 0.0015385361621156335
step: 200, loss: 0.0015417418908327818
step: 210, loss: 0.0009449423523619771
step: 220, loss: 0.015487751923501492
step: 230, loss: 0.007114302832633257
step: 240, loss: 0.01595425233244896
step: 250, loss: 0.0006813189247623086
step: 260, loss: 0.0013694349909201264
step: 270, loss: 0.001408625510521233
step: 280, loss: 0.000268073141342029
step: 290, loss: 0.0002772368607111275
step: 300, loss: 0.0016998074715957046
step: 310, loss: 0.0012210407294332981
step: 320, loss: 0.033442527055740356
step: 330, loss: 0.003981390502303839
step: 340, loss: 0.00013730772479902953
step: 350, loss: 0.001024773227982223
step: 360, loss: 0.0015491480007767677
epoch 12: dev_f1=0.6573033707865169, f1=0.629737609329446, best_f1=0.629737609329446
step: 0, loss: 0.0016434303252026439
step: 10, loss: 0.00019097354379482567
step: 20, loss: 0.0005030008614994586
step: 30, loss: 0.0003062797768507153
step: 40, loss: 0.0002686877269297838
step: 50, loss: 0.0298669021576643
step: 60, loss: 0.0002300091873621568
step: 70, loss: 0.0033883596770465374
step: 80, loss: 0.0008090928313322365
step: 90, loss: 0.0832207053899765
step: 100, loss: 0.0004998922231607139
step: 110, loss: 0.00030168337980285287
step: 120, loss: 0.005116393323987722
step: 130, loss: 0.0007015182636678219
step: 140, loss: 0.0002380799996899441
step: 150, loss: 7.78828325564973e-05
step: 160, loss: 0.10121519863605499
step: 170, loss: 0.00022638862719759345
step: 180, loss: 0.0009179997141472995
step: 190, loss: 0.00018396250379737467
step: 200, loss: 0.00020212342496961355
step: 210, loss: 0.05246428772807121
step: 220, loss: 0.004327206406742334
step: 230, loss: 0.0008973919320851564
step: 240, loss: 0.0004265907919034362
step: 250, loss: 0.002965429564937949
step: 260, loss: 0.0002145445760106668
step: 270, loss: 0.0014497803058475256
step: 280, loss: 0.0001511986629338935
step: 290, loss: 0.00011385361722204834
step: 300, loss: 0.000947268505115062
step: 310, loss: 9.391074854647741e-05
step: 320, loss: 3.313929482828826e-05
step: 330, loss: 7.392852421617135e-05
step: 340, loss: 0.02816680260002613
step: 350, loss: 0.0028552403673529625
step: 360, loss: 0.0004055508179590106
epoch 13: dev_f1=0.6428571428571429, f1=0.6005665722379604, best_f1=0.629737609329446
step: 0, loss: 0.0015250942669808865
step: 10, loss: 6.175036105560139e-05
step: 20, loss: 0.055534545332193375
step: 30, loss: 0.0029018905479460955
step: 40, loss: 0.001133485115133226
step: 50, loss: 0.00011509977048262954
step: 60, loss: 0.004906615242362022
step: 70, loss: 0.01718701235949993
step: 80, loss: 0.025439703837037086
step: 90, loss: 0.014292987994849682
step: 100, loss: 0.0003061816969420761
step: 110, loss: 0.012336106970906258
step: 120, loss: 0.0005976134561933577
step: 130, loss: 0.003461587242782116
step: 140, loss: 0.02831232361495495
step: 150, loss: 0.0003689150616992265
step: 160, loss: 8.220693416660652e-05
step: 170, loss: 0.0007182360859587789
step: 180, loss: 0.005612328182905912
step: 190, loss: 0.011190163902938366
step: 200, loss: 0.004648218397051096
step: 210, loss: 0.07055632770061493
step: 220, loss: 0.0006550579564645886
step: 230, loss: 0.0004993534530512989
step: 240, loss: 0.0006258439971134067
step: 250, loss: 0.0002017601509578526
step: 260, loss: 0.001051651663146913
step: 270, loss: 0.11156991869211197
step: 280, loss: 9.088192018680274e-05
step: 290, loss: 0.0001095425323001109
step: 300, loss: 0.003859835909679532
step: 310, loss: 0.00032632332295179367
step: 320, loss: 0.06656596809625626
step: 330, loss: 0.00019509068806655705
step: 340, loss: 0.000513831852003932
step: 350, loss: 0.0001426984672434628
step: 360, loss: 0.00019473877910058945
epoch 14: dev_f1=0.6158357771260997, f1=0.6190476190476191, best_f1=0.629737609329446
step: 0, loss: 0.0013183160917833447
step: 10, loss: 0.00042817782377824187
step: 20, loss: 0.00013748204219155014
step: 30, loss: 0.007603833917528391
step: 40, loss: 0.0029983017593622208
step: 50, loss: 0.0002379758661845699
step: 60, loss: 0.0041752769611775875
step: 70, loss: 0.0007768548675812781
step: 80, loss: 0.0004481624928303063
step: 90, loss: 0.0015606438973918557
step: 100, loss: 0.0006922937463968992
step: 110, loss: 0.002480614697560668
step: 120, loss: 0.0002108339685946703
step: 130, loss: 0.0007167349685914814
step: 140, loss: 5.3847510571358725e-05
step: 150, loss: 0.0005228003137744963
step: 160, loss: 7.460336928488687e-05
step: 170, loss: 0.0721355751156807
step: 180, loss: 0.0004315628029871732
step: 190, loss: 5.977049295324832e-05
step: 200, loss: 0.0013438889291137457
step: 210, loss: 4.711274596047588e-05
step: 220, loss: 4.9727696023182943e-05
step: 230, loss: 0.00046170130372047424
step: 240, loss: 0.00027455593226477504
step: 250, loss: 0.0024136302527040243
step: 260, loss: 0.002969813998788595
step: 270, loss: 0.027458498254418373
step: 280, loss: 0.0003223912208341062
step: 290, loss: 0.0001752753887558356
step: 300, loss: 0.002055382588878274
step: 310, loss: 0.0002190499217249453
step: 320, loss: 0.0006132908165454865
step: 330, loss: 7.805745553923771e-05
step: 340, loss: 0.0024880922865122557
step: 350, loss: 0.0002441711549181491
step: 360, loss: 0.00011146373435622081
epoch 15: dev_f1=0.6280991735537189, f1=0.6292134831460674, best_f1=0.629737609329446
step: 0, loss: 0.00047599623212590814
step: 10, loss: 0.0011051192414015532
step: 20, loss: 0.0003712259931489825
step: 30, loss: 3.5415072488831356e-05
step: 40, loss: 8.294907456729561e-05
step: 50, loss: 0.00015000604616943747
step: 60, loss: 0.0011192472884431481
step: 70, loss: 8.064968278631568e-05
step: 80, loss: 0.0007869994733482599
step: 90, loss: 0.00045500960550270975
step: 100, loss: 6.996850424911827e-05
step: 110, loss: 8.086518937489018e-05
step: 120, loss: 8.832550520310178e-05
step: 130, loss: 0.00421269191429019
step: 140, loss: 0.00023133677314035594
step: 150, loss: 0.00024801716790534556
step: 160, loss: 0.0010518573690205812
step: 170, loss: 0.0008085592999123037
step: 180, loss: 0.0001692891091806814
step: 190, loss: 0.00040809973143041134
step: 200, loss: 0.00010148405272047967
step: 210, loss: 7.314917456824332e-05
step: 220, loss: 0.0001069182762876153
step: 230, loss: 0.00014000118244439363
step: 240, loss: 4.467534745344892e-05
step: 250, loss: 0.01778659038245678
step: 260, loss: 0.00026181797147728503
step: 270, loss: 9.92236309684813e-05
step: 280, loss: 0.0006396531825885177
step: 290, loss: 0.0001636719680391252
step: 300, loss: 5.152292942511849e-05
step: 310, loss: 0.00012341348337940872
step: 320, loss: 0.0006327929440885782
step: 330, loss: 0.0004201540432404727
step: 340, loss: 0.00021106858912389725
step: 350, loss: 0.00027603868511505425
step: 360, loss: 0.00014038542576599866
epoch 16: dev_f1=0.6222222222222222, f1=0.6256983240223463, best_f1=0.629737609329446
step: 0, loss: 0.0011238979641348124
step: 10, loss: 5.4442065447801724e-05
step: 20, loss: 0.00020636421686504036
step: 30, loss: 0.0030760178342461586
step: 40, loss: 0.001269221887923777
step: 50, loss: 0.00037644151598215103
step: 60, loss: 0.0001461653591832146
step: 70, loss: 4.197187445242889e-05
step: 80, loss: 0.0001541581004858017
step: 90, loss: 0.00011712904961314052
step: 100, loss: 0.0004240016860421747
step: 110, loss: 7.424278010148555e-05
step: 120, loss: 8.607104973634705e-05
step: 130, loss: 0.016276657581329346
step: 140, loss: 3.6666526284534484e-05
step: 150, loss: 0.0015073487302288413
step: 160, loss: 0.00035991729237139225
step: 170, loss: 0.00017026218120008707
step: 180, loss: 0.0005654391134157777
step: 190, loss: 0.00014439647202380002
step: 200, loss: 8.090614574030042e-05
step: 210, loss: 7.648544851690531e-05
step: 220, loss: 0.0002557450789026916
step: 230, loss: 0.0006649048300459981
step: 240, loss: 5.6594701163703576e-05
step: 250, loss: 2.8233071134309284e-05
step: 260, loss: 0.00016296561807394028
step: 270, loss: 6.983258936088532e-05
step: 280, loss: 0.00010570911399554461
step: 290, loss: 3.529914829414338e-05
step: 300, loss: 4.223439464112744e-05
step: 310, loss: 3.1372012017527595e-05
step: 320, loss: 0.0006130649708211422
step: 330, loss: 0.00013069051783531904
step: 340, loss: 0.00015301666280720383
step: 350, loss: 0.0001401370100211352
step: 360, loss: 0.00015197001630440354
epoch 17: dev_f1=0.6153846153846154, f1=0.6099706744868035, best_f1=0.629737609329446
step: 0, loss: 0.027056226506829262
step: 10, loss: 5.718478132621385e-05
step: 20, loss: 0.00040562573121860623
step: 30, loss: 0.0051183877512812614
step: 40, loss: 0.00781810563057661
step: 50, loss: 2.3230202714330517e-05
step: 60, loss: 4.409394387039356e-05
step: 70, loss: 0.0003076577268075198
step: 80, loss: 5.42735360795632e-05
step: 90, loss: 7.484210800612345e-05
step: 100, loss: 4.5027794840279967e-05
step: 110, loss: 9.415194654138759e-05
step: 120, loss: 6.71276866341941e-05
step: 130, loss: 6.748401938239112e-05
step: 140, loss: 0.0010005272924900055
step: 150, loss: 4.9726142606232315e-05
step: 160, loss: 4.7484867536695674e-05
step: 170, loss: 5.5076485296012834e-05
step: 180, loss: 0.0001024180673994124
step: 190, loss: 0.014618461951613426
step: 200, loss: 4.464085941435769e-05
step: 210, loss: 0.002995679620653391
step: 220, loss: 0.03106684237718582
step: 230, loss: 0.00021952572569716722
step: 240, loss: 0.00550066027790308
step: 250, loss: 0.0001711026270641014
step: 260, loss: 0.0019807852804660797
step: 270, loss: 0.0004945905529893935
step: 280, loss: 0.0064632887952029705
step: 290, loss: 0.00027499347925186157
step: 300, loss: 0.00028193803154863417
step: 310, loss: 0.00015159108443185687
step: 320, loss: 0.0010910389246419072
step: 330, loss: 0.0007114890031516552
step: 340, loss: 0.00031301158014684916
step: 350, loss: 6.840057176304981e-05
step: 360, loss: 0.00011060429096687585
epoch 18: dev_f1=0.6091954022988505, f1=0.6331360946745561, best_f1=0.629737609329446
step: 0, loss: 7.64765209169127e-05
step: 10, loss: 0.0014931970508769155
step: 20, loss: 0.000632072682492435
step: 30, loss: 0.0005020619137212634
step: 40, loss: 0.00027194645372219384
step: 50, loss: 0.0002970034838654101
step: 60, loss: 0.00041603005956858397
step: 70, loss: 0.009693845175206661
step: 80, loss: 0.0008180050062946975
step: 90, loss: 0.0002540622663218528
step: 100, loss: 5.993090235278942e-05
step: 110, loss: 8.706533844815567e-05
step: 120, loss: 0.00022819692094344646
step: 130, loss: 3.224721149308607e-05
step: 140, loss: 9.515283454675227e-05
step: 150, loss: 0.00012073470861651003
step: 160, loss: 0.0001160412939498201
step: 170, loss: 5.111597420182079e-05
step: 180, loss: 0.00018347860896028578
step: 190, loss: 0.00018780826940201223
step: 200, loss: 7.466864917660132e-05
step: 210, loss: 3.234508403693326e-05
step: 220, loss: 0.0002691521658562124
step: 230, loss: 4.750731750391424e-05
step: 240, loss: 6.863657472422346e-05
step: 250, loss: 6.823264266131446e-05
step: 260, loss: 4.3794581870315596e-05
step: 270, loss: 0.0022523035295307636
step: 280, loss: 6.224567187018692e-05
step: 290, loss: 0.00021470163483172655
step: 300, loss: 0.00011053614434786141
step: 310, loss: 3.311955151730217e-05
step: 320, loss: 0.0020513557828962803
step: 330, loss: 0.00022098275076132268
step: 340, loss: 0.0013755328254774213
step: 350, loss: 2.2764490495319478e-05
step: 360, loss: 7.883746002335101e-05
epoch 19: dev_f1=0.6140845070422535, f1=0.6315789473684209, best_f1=0.629737609329446
step: 0, loss: 0.0003890572115778923
step: 10, loss: 0.00019936244643758982
step: 20, loss: 3.649852442322299e-05
step: 30, loss: 0.0003648508572950959
step: 40, loss: 0.0002797020715661347
step: 50, loss: 5.3705560276284814e-05
step: 60, loss: 0.0011599680874496698
step: 70, loss: 4.724551035906188e-05
step: 80, loss: 0.0012760459212586284
step: 90, loss: 0.00013378672883845866
step: 100, loss: 5.0953603931702673e-05
step: 110, loss: 0.002119815908372402
step: 120, loss: 8.803606760920957e-05
step: 130, loss: 6.664299871772528e-05
step: 140, loss: 6.886982009746134e-05
step: 150, loss: 0.00022115583124104887
step: 160, loss: 2.2634380002273247e-05
step: 170, loss: 4.342978718341328e-05
step: 180, loss: 0.0039264545775949955
step: 190, loss: 0.00011459340021247044
step: 200, loss: 3.7671299651265144e-05
step: 210, loss: 0.00020005552505608648
step: 220, loss: 0.00013002092600800097
step: 230, loss: 7.964591350173578e-05
step: 240, loss: 0.0001339236187050119
step: 250, loss: 8.37031111586839e-05
step: 260, loss: 0.0009809181792661548
step: 270, loss: 0.0011443860130384564
step: 280, loss: 0.0001946180418599397
step: 290, loss: 8.085727313300595e-05
step: 300, loss: 0.001870116451755166
step: 310, loss: 0.000570242409594357
step: 320, loss: 0.00026343384524807334
step: 330, loss: 0.0005339647177606821
step: 340, loss: 5.8538440498523414e-05
step: 350, loss: 0.00010177836520597339
step: 360, loss: 0.00017567914619576186
epoch 20: dev_f1=0.6197183098591549, f1=0.629737609329446, best_f1=0.629737609329446
cuda
Device: cuda
step: 0, loss: 0.7562845349311829
step: 10, loss: 0.24277646839618683
step: 20, loss: 0.4922378957271576
step: 30, loss: 0.1369466781616211
step: 40, loss: 0.5145725607872009
step: 50, loss: 0.1467655450105667
step: 60, loss: 0.23119793832302094
step: 70, loss: 0.037836138159036636
step: 80, loss: 0.31088584661483765
step: 90, loss: 0.1387152373790741
step: 100, loss: 0.1511026918888092
step: 110, loss: 0.1400212049484253
step: 120, loss: 0.5163098573684692
step: 130, loss: 0.16757437586784363
step: 140, loss: 0.322409987449646
step: 150, loss: 0.2287243753671646
step: 160, loss: 0.14296174049377441
step: 170, loss: 0.01576986350119114
step: 180, loss: 0.3113856315612793
step: 190, loss: 0.37673598527908325
step: 200, loss: 0.04613214731216431
step: 210, loss: 0.02675509639084339
step: 220, loss: 0.13250607252120972
step: 230, loss: 0.22030788660049438
step: 240, loss: 0.08106356114149094
step: 250, loss: 0.1369541883468628
step: 260, loss: 0.1518491506576538
step: 270, loss: 0.43746501207351685
step: 280, loss: 0.13296352326869965
step: 290, loss: 0.4970123767852783
step: 300, loss: 0.05670176446437836
step: 310, loss: 0.22387675940990448
step: 320, loss: 0.26505762338638306
step: 330, loss: 0.1416003406047821
step: 340, loss: 0.0396743007004261
step: 350, loss: 0.22918933629989624
step: 360, loss: 0.12872016429901123
epoch 1: dev_f1=0.22884224779959375, f1=0.2331288343558282, best_f1=0.2331288343558282
step: 0, loss: 0.14138033986091614
step: 10, loss: 0.12249095737934113
step: 20, loss: 0.12143673002719879
step: 30, loss: 0.12068769335746765
step: 40, loss: 0.17050474882125854
step: 50, loss: 0.3885094225406647
step: 60, loss: 0.21477597951889038
step: 70, loss: 0.13095968961715698
step: 80, loss: 0.19171294569969177
step: 90, loss: 0.3338284492492676
step: 100, loss: 0.11960376054048538
step: 110, loss: 0.17062361538410187
step: 120, loss: 0.27080318331718445
step: 130, loss: 0.20692062377929688
step: 140, loss: 0.10167950391769409
step: 150, loss: 0.1278325766324997
step: 160, loss: 0.16655495762825012
step: 170, loss: 0.09754980355501175
step: 180, loss: 0.13932295143604279
step: 190, loss: 0.0279393307864666
step: 200, loss: 0.01959381066262722
step: 210, loss: 0.09941036254167557
step: 220, loss: 0.22532476484775543
step: 230, loss: 0.1763981580734253
step: 240, loss: 0.2707781493663788
step: 250, loss: 0.132256418466568
step: 260, loss: 0.3392222225666046
step: 270, loss: 0.0855594053864479
step: 280, loss: 0.08116465061903
step: 290, loss: 0.07882212847471237
step: 300, loss: 0.1614697128534317
step: 310, loss: 0.10526110231876373
step: 320, loss: 0.06923604011535645
step: 330, loss: 0.3016522526741028
step: 340, loss: 0.11429975181818008
step: 350, loss: 0.05966919660568237
step: 360, loss: 0.2814944386482239
epoch 2: dev_f1=0.5378590078328982, f1=0.5091863517060368, best_f1=0.5091863517060368
step: 0, loss: 0.10563504695892334
step: 10, loss: 0.3204575777053833
step: 20, loss: 0.07582280784845352
step: 30, loss: 0.01484688650816679
step: 40, loss: 0.02300763688981533
step: 50, loss: 0.046865031123161316
step: 60, loss: 0.06973326206207275
step: 70, loss: 0.10422509908676147
step: 80, loss: 0.0078041632659733295
step: 90, loss: 0.040107887238264084
step: 100, loss: 0.08038773387670517
step: 110, loss: 0.04221738502383232
step: 120, loss: 0.08166785538196564
step: 130, loss: 0.1299358308315277
step: 140, loss: 0.010880328714847565
step: 150, loss: 0.20952945947647095
step: 160, loss: 0.06070372834801674
step: 170, loss: 0.1269620954990387
step: 180, loss: 0.06909410655498505
step: 190, loss: 0.09596472233533859
step: 200, loss: 0.15592533349990845
step: 210, loss: 0.17682066559791565
step: 220, loss: 0.06823715567588806
step: 230, loss: 0.2209354043006897
step: 240, loss: 0.15527330338954926
step: 250, loss: 0.15012963116168976
step: 260, loss: 0.10295561701059341
step: 270, loss: 0.03591836243867874
step: 280, loss: 0.150120809674263
step: 290, loss: 0.18952642381191254
step: 300, loss: 0.03186362236738205
step: 310, loss: 0.012487111613154411
step: 320, loss: 0.0907217413187027
step: 330, loss: 0.06019750237464905
step: 340, loss: 0.019731897860765457
step: 350, loss: 0.01395918894559145
step: 360, loss: 0.02797948755323887
epoch 3: dev_f1=0.5828092243186582, f1=0.5413870246085011, best_f1=0.5413870246085011
step: 0, loss: 0.046469055116176605
step: 10, loss: 0.13793149590492249
step: 20, loss: 0.016679201275110245
step: 30, loss: 0.07038209587335587
step: 40, loss: 0.13647760450839996
step: 50, loss: 0.04938789829611778
step: 60, loss: 0.06523148715496063
step: 70, loss: 0.011454090476036072
step: 80, loss: 0.08424118906259537
step: 90, loss: 0.03893277049064636
step: 100, loss: 0.05731600150465965
step: 110, loss: 0.007864268496632576
step: 120, loss: 0.04521918669342995
step: 130, loss: 0.08710075914859772
step: 140, loss: 0.0049268705770373344
step: 150, loss: 0.0072391452267766
step: 160, loss: 0.0408552810549736
step: 170, loss: 0.014419802464544773
step: 180, loss: 0.07988126575946808
step: 190, loss: 0.1666947603225708
step: 200, loss: 0.004247277043759823
step: 210, loss: 0.04325311630964279
step: 220, loss: 0.004830848891288042
step: 230, loss: 0.0259120911359787
step: 240, loss: 0.025682175531983376
step: 250, loss: 0.03326347470283508
step: 260, loss: 0.09390387684106827
step: 270, loss: 0.16715101897716522
step: 280, loss: 0.04700503498315811
step: 290, loss: 0.03434811532497406
step: 300, loss: 0.05140482261776924
step: 310, loss: 0.054475124925374985
step: 320, loss: 0.01753946952521801
step: 330, loss: 0.07653684914112091
step: 340, loss: 0.41994744539260864
step: 350, loss: 0.09370336681604385
step: 360, loss: 0.14275190234184265
epoch 4: dev_f1=0.6121372031662269, f1=0.6260387811634348, best_f1=0.6260387811634348
step: 0, loss: 0.047957293689250946
step: 10, loss: 0.09412901848554611
step: 20, loss: 0.003942939452826977
step: 30, loss: 0.03164687007665634
step: 40, loss: 0.12288270145654678
step: 50, loss: 0.1341632753610611
step: 60, loss: 0.06322535872459412
step: 70, loss: 0.03953715041279793
step: 80, loss: 0.03130708262324333
step: 90, loss: 0.056820426136255264
step: 100, loss: 0.00337370322085917
step: 110, loss: 0.11354571580886841
step: 120, loss: 0.05754999816417694
step: 130, loss: 0.01463255099952221
step: 140, loss: 0.013734320178627968
step: 150, loss: 0.025105426087975502
step: 160, loss: 0.20372624695301056
step: 170, loss: 0.06902087479829788
step: 180, loss: 0.21647539734840393
step: 190, loss: 0.007915236987173557
step: 200, loss: 0.07211882621049881
step: 210, loss: 0.00533199543133378
step: 220, loss: 0.005139303859323263
step: 230, loss: 0.10310140997171402
step: 240, loss: 0.005294612143188715
step: 250, loss: 0.012213976122438908
step: 260, loss: 0.007413900922983885
step: 270, loss: 0.05326603725552559
step: 280, loss: 0.0911145880818367
step: 290, loss: 0.02014746703207493
step: 300, loss: 0.03964716196060181
step: 310, loss: 0.047961749136447906
step: 320, loss: 0.06621618568897247
step: 330, loss: 0.10273177176713943
step: 340, loss: 0.005830150563269854
step: 350, loss: 0.032962579280138016
step: 360, loss: 0.007801814004778862
epoch 5: dev_f1=0.6486486486486486, f1=0.6576819407008087, best_f1=0.6576819407008087
step: 0, loss: 0.07948344200849533
step: 10, loss: 0.014889778569340706
step: 20, loss: 0.02814130112528801
step: 30, loss: 0.003323787823319435
step: 40, loss: 0.04807024821639061
step: 50, loss: 0.004209338687360287
step: 60, loss: 0.015365147963166237
step: 70, loss: 0.006959023419767618
step: 80, loss: 0.026070766150951385
step: 90, loss: 0.019902514293789864
step: 100, loss: 0.004170633386820555
step: 110, loss: 0.01052272878587246
step: 120, loss: 0.0022624677512794733
step: 130, loss: 0.0006830816273577511
step: 140, loss: 0.00257676700130105
step: 150, loss: 0.013800552114844322
step: 160, loss: 0.003224574727937579
step: 170, loss: 0.03343743830919266
step: 180, loss: 0.009136749431490898
step: 190, loss: 0.0020395792089402676
step: 200, loss: 0.0007271598442457616
step: 210, loss: 0.00915640126913786
step: 220, loss: 0.0036439900286495686
step: 230, loss: 0.011401037685573101
step: 240, loss: 0.0048543247394263744
step: 250, loss: 0.004858018364757299
step: 260, loss: 0.03074927255511284
step: 270, loss: 0.0022093658335506916
step: 280, loss: 0.003422395559027791
step: 290, loss: 0.00573008693754673
step: 300, loss: 0.0036084111779928207
step: 310, loss: 0.023517513647675514
step: 320, loss: 0.012219449505209923
step: 330, loss: 0.0026928926818072796
step: 340, loss: 0.004112309776246548
step: 350, loss: 0.014198925346136093
step: 360, loss: 0.007697518914937973
epoch 6: dev_f1=0.636604774535809, f1=0.6594005449591281, best_f1=0.6576819407008087
step: 0, loss: 0.0011641817400231957
step: 10, loss: 0.0017740257317200303
step: 20, loss: 0.007589689921587706
step: 30, loss: 0.001991988392546773
step: 40, loss: 0.0017703816993162036
step: 50, loss: 0.0023406362161040306
step: 60, loss: 0.0011809712741523981
step: 70, loss: 0.0006472631357610226
step: 80, loss: 0.0012511179083958268
step: 90, loss: 0.0006051243981346488
step: 100, loss: 0.006564547773450613
step: 110, loss: 0.0005046844016760588
step: 120, loss: 0.0036168384831398726
step: 130, loss: 0.0006261278176680207
step: 140, loss: 0.0014531236374750733
step: 150, loss: 0.0026661893352866173
step: 160, loss: 0.004407302476465702
step: 170, loss: 0.004165900405496359
step: 180, loss: 0.0004836159641854465
step: 190, loss: 0.009970485232770443
step: 200, loss: 0.0017908968729898334
step: 210, loss: 0.012912646867334843
step: 220, loss: 0.008080688305199146
step: 230, loss: 0.15137633681297302
step: 240, loss: 0.006772816646844149
step: 250, loss: 0.08015149086713791
step: 260, loss: 0.0015975050628185272
step: 270, loss: 0.0075896247290074825
step: 280, loss: 0.05005225911736488
step: 290, loss: 0.13432596623897552
step: 300, loss: 0.02018323726952076
step: 310, loss: 0.0060697514563798904
step: 320, loss: 0.024970360100269318
step: 330, loss: 0.023638954386115074
step: 340, loss: 0.022863008081912994
step: 350, loss: 0.002168801845982671
step: 360, loss: 0.012677120044827461
epoch 7: dev_f1=0.6086956521739131, f1=0.6538461538461539, best_f1=0.6576819407008087
step: 0, loss: 0.0027521117590367794
step: 10, loss: 0.0006700113299302757
step: 20, loss: 0.00237728632055223
step: 30, loss: 0.004135018214583397
step: 40, loss: 0.0024219078477472067
step: 50, loss: 0.00018290431762579829
step: 60, loss: 0.007740815635770559
step: 70, loss: 0.0030891525093466043
step: 80, loss: 0.0032899840734899044
step: 90, loss: 0.006253314670175314
step: 100, loss: 0.0013378291623666883
step: 110, loss: 0.05047806352376938
step: 120, loss: 0.02087477594614029
step: 130, loss: 0.002017475664615631
step: 140, loss: 0.004135987255722284
step: 150, loss: 0.0034133221488445997
step: 160, loss: 0.0015569854294881225
step: 170, loss: 0.009935825131833553
step: 180, loss: 0.1945454478263855
step: 190, loss: 0.02874845825135708
step: 200, loss: 0.02804405428469181
step: 210, loss: 0.0001886398094939068
step: 220, loss: 0.007283805403858423
step: 230, loss: 0.0019844037014991045
step: 240, loss: 0.03682400658726692
step: 250, loss: 0.001123917754739523
step: 260, loss: 0.003903558710590005
step: 270, loss: 0.009060615673661232
step: 280, loss: 0.013159590773284435
step: 290, loss: 0.027939550578594208
step: 300, loss: 0.002149441046640277
step: 310, loss: 0.006296588573604822
step: 320, loss: 0.006203691009432077
step: 330, loss: 0.01416676677763462
step: 340, loss: 0.004085439722985029
step: 350, loss: 0.0008833047468215227
step: 360, loss: 0.1258770376443863
epoch 8: dev_f1=0.6288951841359773, f1=0.6334310850439884, best_f1=0.6576819407008087
step: 0, loss: 0.11654013395309448
step: 10, loss: 0.018799858167767525
step: 20, loss: 0.004415983334183693
step: 30, loss: 0.03408169373869896
step: 40, loss: 0.0008253341075032949
step: 50, loss: 0.002421415178105235
step: 60, loss: 0.15007293224334717
step: 70, loss: 0.0027201815973967314
step: 80, loss: 0.004855428356677294
step: 90, loss: 0.002211536979302764
step: 100, loss: 0.0024741641245782375
step: 110, loss: 0.0003000580763909966
step: 120, loss: 0.00023575845989398658
step: 130, loss: 0.04128124937415123
step: 140, loss: 0.0013986804988235235
step: 150, loss: 0.001048658275976777
step: 160, loss: 0.0006776538793928921
step: 170, loss: 0.00030747009441256523
step: 180, loss: 0.00017890523304231465
step: 190, loss: 0.0009033059468492866
step: 200, loss: 0.014771559275686741
step: 210, loss: 0.0001691855868557468
step: 220, loss: 0.0003187531547155231
step: 230, loss: 0.002363127889111638
step: 240, loss: 0.012878981418907642
step: 250, loss: 0.000690448796376586
step: 260, loss: 0.0038521757815033197
step: 270, loss: 0.0020121547859162092
step: 280, loss: 0.0018592295236885548
step: 290, loss: 0.001270769163966179
step: 300, loss: 0.000550071825273335
step: 310, loss: 0.003614603541791439
step: 320, loss: 0.06238189712166786
step: 330, loss: 0.002761193783953786
step: 340, loss: 0.00024913373636081815
step: 350, loss: 0.010498862713575363
step: 360, loss: 0.00046151303104124963
epoch 9: dev_f1=0.649122807017544, f1=0.6646706586826346, best_f1=0.6646706586826346
step: 0, loss: 0.0018316881032660604
step: 10, loss: 0.0013172797625884414
step: 20, loss: 0.0014467244036495686
step: 30, loss: 0.0026111516635864973
step: 40, loss: 0.0003676492488011718
step: 50, loss: 0.00352528877556324
step: 60, loss: 0.0020357039757072926
step: 70, loss: 0.0004298716376069933
step: 80, loss: 0.0007035226444713771
step: 90, loss: 0.0022044184152036905
step: 100, loss: 0.00033658480970188975
step: 110, loss: 0.14817768335342407
step: 120, loss: 0.02150844968855381
step: 130, loss: 0.06627579778432846
step: 140, loss: 0.0004259377019479871
step: 150, loss: 0.0006079699960537255
step: 160, loss: 0.001169879804365337
step: 170, loss: 0.0002909392351284623
step: 180, loss: 0.00247089727781713
step: 190, loss: 0.0011098104296252131
step: 200, loss: 0.016101451590657234
step: 210, loss: 0.0016450349939987063
step: 220, loss: 0.009417484514415264
step: 230, loss: 0.0013406192883849144
step: 240, loss: 0.0005293029826134443
step: 250, loss: 0.007936663925647736
step: 260, loss: 0.15146170556545258
step: 270, loss: 0.0003271539171691984
step: 280, loss: 0.03556600213050842
step: 290, loss: 0.0004440045158844441
step: 300, loss: 0.07041262090206146
step: 310, loss: 0.00015309435548260808
step: 320, loss: 0.00010222205310128629
step: 330, loss: 0.0009445385076105595
step: 340, loss: 0.021519508212804794
step: 350, loss: 0.010400387458503246
step: 360, loss: 0.006606280338019133
epoch 10: dev_f1=0.6404494382022472, f1=0.6704545454545454, best_f1=0.6646706586826346
step: 0, loss: 0.011007256805896759
step: 10, loss: 0.001728785689920187
step: 20, loss: 0.0005642191972583532
step: 30, loss: 0.0003384138399269432
step: 40, loss: 0.017308121547102928
step: 50, loss: 0.00812157429754734
step: 60, loss: 0.00017413201567251235
step: 70, loss: 0.002292012330144644
step: 80, loss: 0.003661327064037323
step: 90, loss: 0.00402905372902751
step: 100, loss: 0.003900065552443266
step: 110, loss: 0.03696310892701149
step: 120, loss: 0.019685853272676468
step: 130, loss: 0.0010509175481274724
step: 140, loss: 0.0008089644252322614
step: 150, loss: 0.08641035854816437
step: 160, loss: 0.0014126906171441078
step: 170, loss: 0.0015388504834845662
step: 180, loss: 0.006420948076993227
step: 190, loss: 0.0021212201099842787
step: 200, loss: 0.00025705070584081113
step: 210, loss: 0.0006368387257680297
step: 220, loss: 0.003762975335121155
step: 230, loss: 0.0007707519107498229
step: 240, loss: 0.0003186307440046221
step: 250, loss: 0.0001991669851122424
step: 260, loss: 0.01575041189789772
step: 270, loss: 0.0005236708675511181
step: 280, loss: 0.02393851988017559
step: 290, loss: 0.0018306499114260077
step: 300, loss: 0.0006522446637973189
step: 310, loss: 0.0013066403334960341
step: 320, loss: 0.00014994364755693823
step: 330, loss: 0.0006599420448765159
step: 340, loss: 0.0017181122675538063
step: 350, loss: 0.003989867866039276
step: 360, loss: 0.002222927287220955
epoch 11: dev_f1=0.6352941176470588, f1=0.6626865671641792, best_f1=0.6646706586826346
step: 0, loss: 0.0027539911679923534
step: 10, loss: 0.005458571948111057
step: 20, loss: 7.81573835411109e-05
step: 30, loss: 0.005355720408260822
step: 40, loss: 0.00016342390154022723
step: 50, loss: 0.009388110600411892
step: 60, loss: 0.00020201498409733176
step: 70, loss: 0.0021986423525959253
step: 80, loss: 0.001535125426016748
step: 90, loss: 0.00040996598545461893
step: 100, loss: 0.0008981262217275798
step: 110, loss: 0.00035485182888805866
step: 120, loss: 0.00014321737398859113
step: 130, loss: 9.156541636912152e-05
step: 140, loss: 0.001166225178167224
step: 150, loss: 0.0006163379293866456
step: 160, loss: 8.902462286641821e-05
step: 170, loss: 7.683240983169526e-05
step: 180, loss: 0.0005641465540975332
step: 190, loss: 0.0038344115018844604
step: 200, loss: 0.0002651294635143131
step: 210, loss: 0.00028635759372264147
step: 220, loss: 0.00010179411037825048
step: 230, loss: 0.0010849172249436378
step: 240, loss: 0.00034672097535803914
step: 250, loss: 0.0001795388088794425
step: 260, loss: 0.0037561547942459583
step: 270, loss: 0.00021315446065273136
step: 280, loss: 0.00011076845112256706
step: 290, loss: 0.0001537571952212602
step: 300, loss: 0.0003612796135712415
step: 310, loss: 0.0002196907007601112
step: 320, loss: 0.00038422632496804
step: 330, loss: 0.00013054799637757242
step: 340, loss: 0.0002699830220080912
step: 350, loss: 0.0007628406165167689
step: 360, loss: 0.0004090034926775843
epoch 12: dev_f1=0.6702412868632708, f1=0.6462395543175486, best_f1=0.6462395543175486
step: 0, loss: 0.012620894238352776
step: 10, loss: 0.0007076627225615084
step: 20, loss: 0.0004985438426956534
step: 30, loss: 0.00018662087677512318
step: 40, loss: 0.000157271177158691
step: 50, loss: 0.0332704596221447
step: 60, loss: 0.014537458308041096
step: 70, loss: 0.0005432087928056717
step: 80, loss: 0.0006239130743779242
step: 90, loss: 0.0014536554226651788
step: 100, loss: 0.0012892050435766578
step: 110, loss: 0.000389192282455042
step: 120, loss: 0.00014456178178079426
step: 130, loss: 0.0002451998880133033
step: 140, loss: 0.00020488142035901546
step: 150, loss: 8.023047121241689e-05
step: 160, loss: 0.0016175475902855396
step: 170, loss: 0.009245744906365871
step: 180, loss: 0.0029269871301949024
step: 190, loss: 5.6789191148709506e-05
step: 200, loss: 0.00010914348240476102
step: 210, loss: 7.61643095756881e-05
step: 220, loss: 0.00042761577060446143
step: 230, loss: 0.0004334835393819958
step: 240, loss: 0.005607069935649633
step: 250, loss: 0.0003126086958218366
step: 260, loss: 3.124324211967178e-05
step: 270, loss: 0.03010610118508339
step: 280, loss: 0.00016561744268983603
step: 290, loss: 3.3727170375641435e-05
step: 300, loss: 0.0005733233410865068
step: 310, loss: 0.00015731000166852027
step: 320, loss: 4.815075226360932e-05
step: 330, loss: 4.546043055597693e-05
step: 340, loss: 0.027171963825821877
step: 350, loss: 0.003218183759599924
step: 360, loss: 0.003537909360602498
epoch 13: dev_f1=0.6384039900249376, f1=0.6489361702127661, best_f1=0.6462395543175486
step: 0, loss: 0.00030452036298811436
step: 10, loss: 7.19903182471171e-05
step: 20, loss: 0.00035613644286058843
step: 30, loss: 0.00017950306937564164
step: 40, loss: 0.00011570061178645119
step: 50, loss: 0.004268328659236431
step: 60, loss: 0.0003332057094667107
step: 70, loss: 0.0008112959330901504
step: 80, loss: 0.004504097159951925
step: 90, loss: 0.002869269112125039
step: 100, loss: 0.00047628412721678615
step: 110, loss: 0.0029856357723474503
step: 120, loss: 5.5106618674471974e-05
step: 130, loss: 0.001773271826095879
step: 140, loss: 0.00013595681230071932
step: 150, loss: 0.001364166964776814
step: 160, loss: 9.058529394678771e-05
step: 170, loss: 0.00042649905662983656
step: 180, loss: 0.0004728569183498621
step: 190, loss: 0.0010601191315799952
step: 200, loss: 0.00023316302394960076
step: 210, loss: 0.00013904391380492598
step: 220, loss: 0.010995684191584587
step: 230, loss: 4.529665966401808e-05
step: 240, loss: 0.0038731899112462997
step: 250, loss: 0.00018387706950306892
step: 260, loss: 0.0003932334075216204
step: 270, loss: 0.0009123076451942325
step: 280, loss: 0.00021744094556197524
step: 290, loss: 0.00012782536214217544
step: 300, loss: 0.00012595381122082472
step: 310, loss: 0.00011303641076665372
step: 320, loss: 0.00016061868518590927
step: 330, loss: 0.0005586434854194522
step: 340, loss: 0.0003232584858778864
step: 350, loss: 0.00026034770417027175
step: 360, loss: 8.928332681534812e-05
epoch 14: dev_f1=0.6233062330623306, f1=0.6534090909090908, best_f1=0.6462395543175486
step: 0, loss: 0.0004513505846261978
step: 10, loss: 6.0300732002360746e-05
step: 20, loss: 0.00030827271984890103
step: 30, loss: 0.0025745180901139975
step: 40, loss: 0.00011113029904663563
step: 50, loss: 0.0001229090994456783
step: 60, loss: 0.0008478353265672922
step: 70, loss: 0.00019214797066524625
step: 80, loss: 0.00013223677524365485
step: 90, loss: 0.0020154141820967197
step: 100, loss: 0.00011477406951598823
step: 110, loss: 0.00015854557568673044
step: 120, loss: 0.001269071944989264
step: 130, loss: 0.001608751597814262
step: 140, loss: 4.236137101543136e-05
step: 150, loss: 0.00035301802563481033
step: 160, loss: 0.0037136184982955456
step: 170, loss: 0.00030143122421577573
step: 180, loss: 0.0991157591342926
step: 190, loss: 0.00010906604438787326
step: 200, loss: 0.011781670153141022
step: 210, loss: 6.500535528175533e-05
step: 220, loss: 0.00021869321062695235
step: 230, loss: 0.0004914588644169271
step: 240, loss: 0.0003767389280255884
step: 250, loss: 0.00019531682482920587
step: 260, loss: 0.0003734245547093451
step: 270, loss: 9.547925583319739e-05
step: 280, loss: 0.0011609867215156555
step: 290, loss: 0.0002019382664002478
step: 300, loss: 0.0004834549908991903
step: 310, loss: 0.0036287030670791864
step: 320, loss: 0.00044018166954629123
step: 330, loss: 0.0002029128954745829
step: 340, loss: 0.03572738170623779
step: 350, loss: 0.0011079858522862196
step: 360, loss: 0.0005981228314340115
epoch 15: dev_f1=0.6239554317548747, f1=0.6318840579710145, best_f1=0.6462395543175486
step: 0, loss: 0.0005852014292031527
step: 10, loss: 0.0024532752577215433
step: 20, loss: 0.0012557711452245712
step: 30, loss: 0.00014481949619948864
step: 40, loss: 0.00020297376613598317
step: 50, loss: 0.000805123767349869
step: 60, loss: 0.00018793098570313305
step: 70, loss: 0.0008202172466553748
step: 80, loss: 0.00023079694074112922
step: 90, loss: 0.00019835756393149495
step: 100, loss: 0.00023364205844700336
step: 110, loss: 0.00011975957022514194
step: 120, loss: 0.00010671311611076817
step: 130, loss: 0.00020499153470154852
step: 140, loss: 0.0003760087420232594
step: 150, loss: 6.296628271229565e-05
step: 160, loss: 0.0002055469958577305
step: 170, loss: 0.00033641597838141024
step: 180, loss: 0.00016200571553781629
step: 190, loss: 0.0035239148419350386
step: 200, loss: 7.351098611252382e-05
step: 210, loss: 0.00021058438869658858
step: 220, loss: 0.03985320031642914
step: 230, loss: 0.00037651360617019236
step: 240, loss: 0.0003809388435911387
step: 250, loss: 0.0001445604721084237
step: 260, loss: 0.0008753213915042579
step: 270, loss: 4.845490548177622e-05
step: 280, loss: 0.00016545721155125648
step: 290, loss: 0.0002519705449230969
step: 300, loss: 0.00016761821461841464
step: 310, loss: 0.00016876104928087443
step: 320, loss: 0.00023704780323896557
step: 330, loss: 0.00020926253637298942
step: 340, loss: 0.00011773799633374438
step: 350, loss: 0.031054053455591202
step: 360, loss: 0.00029606788302771747
epoch 16: dev_f1=0.6478873239436621, f1=0.656891495601173, best_f1=0.6462395543175486
step: 0, loss: 0.0003163167857564986
step: 10, loss: 0.00033368816366419196
step: 20, loss: 0.00018393552454654127
step: 30, loss: 0.00010687534813769162
step: 40, loss: 6.178266630740836e-05
step: 50, loss: 0.00014641604502685368
step: 60, loss: 0.00034809429780580103
step: 70, loss: 8.956665988080204e-05
step: 80, loss: 4.662702122004703e-05
step: 90, loss: 0.0003397556720301509
step: 100, loss: 8.69735813466832e-05
step: 110, loss: 0.00017539944383315742
step: 120, loss: 0.0019020354375243187
step: 130, loss: 0.00041581285768188536
step: 140, loss: 3.997077146777883e-05
step: 150, loss: 0.001283501391299069
step: 160, loss: 0.0002775040629785508
step: 170, loss: 0.0004969813744537532
step: 180, loss: 0.0002750843996182084
step: 190, loss: 0.00011778316547861323
step: 200, loss: 7.403331983368844e-05
step: 210, loss: 0.00012139779573772103
step: 220, loss: 0.00010328447388019413
step: 230, loss: 9.30100868572481e-05
step: 240, loss: 9.69100947258994e-05
step: 250, loss: 0.000488276535179466
step: 260, loss: 0.0001862753852037713
step: 270, loss: 0.000255018996540457
step: 280, loss: 0.0005968952900730073
step: 290, loss: 3.980251494795084e-05
step: 300, loss: 4.885884845862165e-05
step: 310, loss: 5.5122218327596784e-05
step: 320, loss: 0.00015494966646656394
step: 330, loss: 0.00045282929204404354
step: 340, loss: 0.0004998997901566327
step: 350, loss: 0.00011017182259820402
step: 360, loss: 0.004841191228479147
epoch 17: dev_f1=0.6549707602339181, f1=0.6404833836858005, best_f1=0.6462395543175486
step: 0, loss: 0.0006641143700107932
step: 10, loss: 3.08889830193948e-05
step: 20, loss: 0.00027730275178328156
step: 30, loss: 8.37851912365295e-05
step: 40, loss: 4.032212382298894e-05
step: 50, loss: 2.6433948733028956e-05
step: 60, loss: 6.155125447548926e-05
step: 70, loss: 0.00034952128771692514
step: 80, loss: 0.00011626068589976057
step: 90, loss: 0.0002045496366918087
step: 100, loss: 6.748873420292512e-05
step: 110, loss: 7.022359204711393e-05
step: 120, loss: 4.9710095481714234e-05
step: 130, loss: 0.00014362622459884733
step: 140, loss: 0.000192635488929227
step: 150, loss: 0.0024711492005735636
step: 160, loss: 7.96715248725377e-05
step: 170, loss: 0.0002795319305732846
step: 180, loss: 9.251957817468792e-05
step: 190, loss: 0.0006285138661041856
step: 200, loss: 5.049476385465823e-05
step: 210, loss: 0.003759442362934351
step: 220, loss: 7.549504516646266e-05
step: 230, loss: 0.002455596812069416
step: 240, loss: 0.0001734045654302463
step: 250, loss: 7.682700379518792e-05
step: 260, loss: 0.0004028166295029223
step: 270, loss: 0.0001255498209502548
step: 280, loss: 0.001542725251056254
step: 290, loss: 0.00022958459157962352
step: 300, loss: 0.00022257459932006896
step: 310, loss: 7.202008418971673e-05
step: 320, loss: 4.9769034376367927e-05
step: 330, loss: 0.0016494917217642069
step: 340, loss: 0.00010845936049008742
step: 350, loss: 0.00013578256766777486
step: 360, loss: 0.00012121976033085957
epoch 18: dev_f1=0.6510263929618768, f1=0.6322188449848024, best_f1=0.6462395543175486
step: 0, loss: 0.0001861369819380343
step: 10, loss: 0.00015787982556503266
step: 20, loss: 9.55140931182541e-05
step: 30, loss: 6.075623969081789e-05
step: 40, loss: 0.00012278981739655137
step: 50, loss: 8.34288657642901e-05
step: 60, loss: 0.009466116316616535
step: 70, loss: 0.0021299864165484905
step: 80, loss: 0.00016517560288775712
step: 90, loss: 9.494422556599602e-05
step: 100, loss: 8.322267240146175e-05
step: 110, loss: 5.668521407642402e-05
step: 120, loss: 0.0017392978770658374
step: 130, loss: 3.511661270749755e-05
step: 140, loss: 0.0001042915100697428
step: 150, loss: 0.00010326264600735158
step: 160, loss: 0.00018109545635525137
step: 170, loss: 6.172464782139286e-05
step: 180, loss: 0.00010380568710388616
step: 190, loss: 0.00015513769176322967
step: 200, loss: 5.2765481086680666e-05
step: 210, loss: 3.423685484449379e-05
step: 220, loss: 0.00037432712269946933
step: 230, loss: 0.00022890038962941617
step: 240, loss: 0.00014135197852738202
step: 250, loss: 3.8040976505726576e-05
step: 260, loss: 4.1210510971723124e-05
step: 270, loss: 0.006922746542841196
step: 280, loss: 7.201405242085457e-05
step: 290, loss: 7.597218063892797e-05
step: 300, loss: 0.008880283683538437
step: 310, loss: 6.348080933094025e-05
step: 320, loss: 8.172808884410188e-05
step: 330, loss: 0.00017853705503512174
step: 340, loss: 7.235391240101308e-05
step: 350, loss: 5.768084156443365e-05
step: 360, loss: 0.0008434738265350461
epoch 19: dev_f1=0.6468842729970327, f1=0.6299694189602446, best_f1=0.6462395543175486
step: 0, loss: 0.00016878392489161342
step: 10, loss: 8.348123083123937e-05
step: 20, loss: 0.0003968125383835286
step: 30, loss: 0.015447159297764301
step: 40, loss: 8.644015179015696e-05
step: 50, loss: 0.0007090205908752978
step: 60, loss: 9.313081682194024e-05
step: 70, loss: 0.000714150897692889
step: 80, loss: 0.00011552107753232121
step: 90, loss: 0.00014360221393872052
step: 100, loss: 4.467034887056798e-05
step: 110, loss: 0.0006849950877949595
step: 120, loss: 0.00011060659016948193
step: 130, loss: 5.994716048007831e-05
step: 140, loss: 0.00016216179938055575
step: 150, loss: 0.00020966242300346494
step: 160, loss: 2.5517718313494697e-05
step: 170, loss: 0.00013536241021938622
step: 180, loss: 0.014446895569562912
step: 190, loss: 0.0004324397596064955
step: 200, loss: 4.0265018469654024e-05
step: 210, loss: 4.5141878217691556e-05
step: 220, loss: 7.68325335229747e-05
step: 230, loss: 7.746932533336803e-05
step: 240, loss: 0.00011294538126094267
step: 250, loss: 0.0005952505161985755
step: 260, loss: 0.0005280455807223916
step: 270, loss: 5.340459756553173e-05
step: 280, loss: 9.836626122705638e-05
step: 290, loss: 3.914313128916547e-05
step: 300, loss: 6.806053715990856e-05
step: 310, loss: 0.0009431631769984961
step: 320, loss: 0.00015913161041680723
step: 330, loss: 0.0001859065960161388
step: 340, loss: 0.00039218872552737594
step: 350, loss: 0.0003028256760444492
step: 360, loss: 9.289065928896889e-05
epoch 20: dev_f1=0.6418338108882521, f1=0.6242424242424243, best_f1=0.6462395543175486
