cuda
Device: cuda
step: 0, loss: 0.7794439792633057
step: 10, loss: 0.14475011825561523
step: 20, loss: 0.1438150256872177
step: 30, loss: 0.06067996099591255
step: 40, loss: 0.33188745379447937
step: 50, loss: 0.24617747962474823
step: 60, loss: 0.2414412796497345
step: 70, loss: 0.3357148766517639
step: 80, loss: 0.3906518220901489
step: 90, loss: 0.1418572962284088
step: 100, loss: 0.13705168664455414
step: 110, loss: 0.1360623836517334
step: 120, loss: 0.13614830374717712
step: 130, loss: 0.15087465941905975
step: 140, loss: 0.14429864287376404
step: 150, loss: 0.209497332572937
step: 160, loss: 0.06077935919165611
step: 170, loss: 0.132591113448143
step: 180, loss: 0.14139460027217865
step: 190, loss: 0.21494512259960175
step: 200, loss: 0.13180097937583923
step: 210, loss: 0.2171027660369873
step: 220, loss: 0.1465367078781128
step: 230, loss: 0.047312572598457336
step: 240, loss: 0.12530437111854553
step: 250, loss: 0.03246239572763443
step: 260, loss: 0.14813825488090515
step: 270, loss: 0.1247265636920929
step: 280, loss: 0.25235143303871155
step: 290, loss: 0.04382813721895218
step: 300, loss: 0.21673765778541565
step: 310, loss: 0.047592416405677795
step: 320, loss: 0.11098240315914154
step: 330, loss: 0.05366569012403488
step: 340, loss: 0.06215355917811394
step: 350, loss: 0.09864967316389084
step: 360, loss: 0.10184187442064285
epoch 1: dev_f1=0.3759398496240602, f1=0.35384615384615387, best_f1=0.35384615384615387
step: 0, loss: 0.3503401577472687
step: 10, loss: 0.12253548949956894
step: 20, loss: 0.1162227913737297
step: 30, loss: 0.13495329022407532
step: 40, loss: 0.02661445364356041
step: 50, loss: 0.03988860547542572
step: 60, loss: 0.20810917019844055
step: 70, loss: 0.05665190517902374
step: 80, loss: 0.14578433334827423
step: 90, loss: 0.07762876898050308
step: 100, loss: 0.053014807403087616
step: 110, loss: 0.17278070747852325
step: 120, loss: 0.1270950436592102
step: 130, loss: 0.14826376736164093
step: 140, loss: 0.13261374831199646
step: 150, loss: 0.23132389783859253
step: 160, loss: 0.2174621820449829
step: 170, loss: 0.12139397859573364
step: 180, loss: 0.5193543434143066
step: 190, loss: 0.14573216438293457
step: 200, loss: 0.05193160101771355
step: 210, loss: 0.058225467801094055
step: 220, loss: 0.06525258719921112
step: 230, loss: 0.10385164618492126
step: 240, loss: 0.16316433250904083
step: 250, loss: 0.043670084327459335
step: 260, loss: 0.17257629334926605
step: 270, loss: 0.07953210920095444
step: 280, loss: 0.3430880904197693
step: 290, loss: 0.19642850756645203
step: 300, loss: 0.07536082714796066
step: 310, loss: 0.4210965633392334
step: 320, loss: 0.1580311506986618
step: 330, loss: 0.17290502786636353
step: 340, loss: 0.09706466645002365
step: 350, loss: 0.0891294851899147
step: 360, loss: 0.04938512295484543
epoch 2: dev_f1=0.5219638242894057, f1=0.5824175824175823, best_f1=0.5824175824175823
step: 0, loss: 0.18679532408714294
step: 10, loss: 0.02376312017440796
step: 20, loss: 0.02944319136440754
step: 30, loss: 0.11101693660020828
step: 40, loss: 0.06493240594863892
step: 50, loss: 0.035645656287670135
step: 60, loss: 0.14918901026248932
step: 70, loss: 0.019185511395335197
step: 80, loss: 0.1519734263420105
step: 90, loss: 0.39678922295570374
step: 100, loss: 0.04321601241827011
step: 110, loss: 0.06018328666687012
step: 120, loss: 0.04392697289586067
step: 130, loss: 0.05347631871700287
step: 140, loss: 0.078513003885746
step: 150, loss: 0.1037750244140625
step: 160, loss: 0.03515884280204773
step: 170, loss: 0.09720415621995926
step: 180, loss: 0.16703911125659943
step: 190, loss: 0.11360980570316315
step: 200, loss: 0.08903771638870239
step: 210, loss: 0.06814615428447723
step: 220, loss: 0.16177378594875336
step: 230, loss: 0.08924272656440735
step: 240, loss: 0.14471088349819183
step: 250, loss: 0.01977608911693096
step: 260, loss: 0.19905701279640198
step: 270, loss: 0.15323102474212646
step: 280, loss: 0.022434500977396965
step: 290, loss: 0.06954649835824966
step: 300, loss: 0.07129272073507309
step: 310, loss: 0.02663281187415123
step: 320, loss: 0.04421781003475189
step: 330, loss: 0.11291801929473877
step: 340, loss: 0.0705290362238884
step: 350, loss: 0.2767177224159241
step: 360, loss: 0.16924023628234863
epoch 3: dev_f1=0.6140845070422535, f1=0.6413043478260869, best_f1=0.6413043478260869
step: 0, loss: 0.07023858278989792
step: 10, loss: 0.09461130946874619
step: 20, loss: 0.02552366629242897
step: 30, loss: 0.012429444119334221
step: 40, loss: 0.07714132964611053
step: 50, loss: 0.0025374700780957937
step: 60, loss: 0.016855234280228615
step: 70, loss: 0.037686917930841446
step: 80, loss: 0.06230960786342621
step: 90, loss: 0.0023069854360073805
step: 100, loss: 0.07314566522836685
step: 110, loss: 0.08526267111301422
step: 120, loss: 0.030649451538920403
step: 130, loss: 0.002149886917322874
step: 140, loss: 0.0006793924258090556
step: 150, loss: 0.06309837102890015
step: 160, loss: 0.030086025595664978
step: 170, loss: 0.020660296082496643
step: 180, loss: 0.1546708643436432
step: 190, loss: 0.028735777363181114
step: 200, loss: 0.053413275629282
step: 210, loss: 0.11495527625083923
step: 220, loss: 0.054022207856178284
step: 230, loss: 0.1596127450466156
step: 240, loss: 0.06057462468743324
step: 250, loss: 0.056887879967689514
step: 260, loss: 0.028238948434591293
step: 270, loss: 0.06852556765079498
step: 280, loss: 0.010735252872109413
step: 290, loss: 0.060401055961847305
step: 300, loss: 0.0073569160886108875
step: 310, loss: 0.002237060572952032
step: 320, loss: 0.03477286174893379
step: 330, loss: 0.00718611478805542
step: 340, loss: 0.04838643968105316
step: 350, loss: 0.032774847000837326
step: 360, loss: 0.021231811493635178
epoch 4: dev_f1=0.6308411214953271, f1=0.6495327102803737, best_f1=0.6495327102803737
step: 0, loss: 0.0053806183859705925
step: 10, loss: 0.017842931672930717
step: 20, loss: 0.00314964447170496
step: 30, loss: 0.2859250605106354
step: 40, loss: 0.0033309338614344597
step: 50, loss: 0.011970683000981808
step: 60, loss: 0.009474650956690311
step: 70, loss: 0.02883906476199627
step: 80, loss: 0.0016338566783815622
step: 90, loss: 0.06413346529006958
step: 100, loss: 0.002110784873366356
step: 110, loss: 0.032054416835308075
step: 120, loss: 0.014520340599119663
step: 130, loss: 0.06935366243124008
step: 140, loss: 0.01575770042836666
step: 150, loss: 0.006242704577744007
step: 160, loss: 0.00779672572389245
step: 170, loss: 0.004106903448700905
step: 180, loss: 0.01357102207839489
step: 190, loss: 0.023725543171167374
step: 200, loss: 0.0027047523763030767
step: 210, loss: 0.008042609319090843
step: 220, loss: 0.2178993821144104
step: 230, loss: 0.019946757704019547
step: 240, loss: 0.12676577270030975
step: 250, loss: 0.004265890922397375
step: 260, loss: 0.013917271047830582
step: 270, loss: 0.07366704940795898
step: 280, loss: 0.05556893348693848
step: 290, loss: 0.021582426503300667
step: 300, loss: 0.11373352259397507
step: 310, loss: 0.004044168163090944
step: 320, loss: 0.04169211909174919
step: 330, loss: 0.02483590692281723
step: 340, loss: 0.07651171833276749
step: 350, loss: 0.040810879319906235
step: 360, loss: 0.005319275427609682
epoch 5: dev_f1=0.6580310880829016, f1=0.6684073107049608, best_f1=0.6684073107049608
step: 0, loss: 0.042730867862701416
step: 10, loss: 0.0007580331293866038
step: 20, loss: 0.0050392854027450085
step: 30, loss: 0.020459404215216637
step: 40, loss: 0.029364507645368576
step: 50, loss: 0.15882232785224915
step: 60, loss: 0.12699346244335175
step: 70, loss: 0.003067910671234131
step: 80, loss: 0.12530599534511566
step: 90, loss: 0.002534727333113551
step: 100, loss: 0.01065486203879118
step: 110, loss: 0.03996077924966812
step: 120, loss: 0.20765803754329681
step: 130, loss: 0.006543442141264677
step: 140, loss: 0.0013129707658663392
step: 150, loss: 0.09604789316654205
step: 160, loss: 0.09265867620706558
step: 170, loss: 0.061537038534879684
step: 180, loss: 0.026841573417186737
step: 190, loss: 0.007434764411300421
step: 200, loss: 0.02406696230173111
step: 210, loss: 0.0355234369635582
step: 220, loss: 0.007322194520384073
step: 230, loss: 0.00047666262253187597
step: 240, loss: 0.006305309943854809
step: 250, loss: 0.06568033993244171
step: 260, loss: 0.14805889129638672
step: 270, loss: 0.03728238865733147
step: 280, loss: 0.01616448163986206
step: 290, loss: 0.023222224786877632
step: 300, loss: 0.006810117047280073
step: 310, loss: 0.013770629651844501
step: 320, loss: 0.15861733257770538
step: 330, loss: 0.00626142555847764
step: 340, loss: 0.01972140744328499
step: 350, loss: 0.02394634671509266
step: 360, loss: 0.0013196133077144623
epoch 6: dev_f1=0.6556603773584906, f1=0.6751269035532995, best_f1=0.6684073107049608
step: 0, loss: 0.004730995744466782
step: 10, loss: 0.001378626562654972
step: 20, loss: 0.01262654922902584
step: 30, loss: 0.0005011521861888468
step: 40, loss: 0.043861426413059235
step: 50, loss: 0.018734298646450043
step: 60, loss: 0.035223837941884995
step: 70, loss: 0.0029261207673698664
step: 80, loss: 0.08283745497465134
step: 90, loss: 0.0011047476436942816
step: 100, loss: 0.011469236575067043
step: 110, loss: 0.0003767425660043955
step: 120, loss: 0.08996477723121643
step: 130, loss: 0.012472016736865044
step: 140, loss: 0.0029073075857013464
step: 150, loss: 0.0013199432287365198
step: 160, loss: 0.012843257747590542
step: 170, loss: 0.0005022286204621196
step: 180, loss: 0.04968048259615898
step: 190, loss: 0.00773372408002615
step: 200, loss: 0.003338434034958482
step: 210, loss: 0.002215722808614373
step: 220, loss: 0.010587711818516254
step: 230, loss: 0.021285247057676315
step: 240, loss: 0.05835934728384018
step: 250, loss: 0.008889483287930489
step: 260, loss: 0.002211246406659484
step: 270, loss: 0.00224892096593976
step: 280, loss: 0.029005317017436028
step: 290, loss: 0.005284074693918228
step: 300, loss: 0.0025196385104209185
step: 310, loss: 0.005605257581919432
step: 320, loss: 0.023064281791448593
step: 330, loss: 0.0013743952149525285
step: 340, loss: 0.010640949942171574
step: 350, loss: 0.0007541187223978341
step: 360, loss: 0.005426614545285702
epoch 7: dev_f1=0.6376811594202899, f1=0.6412213740458015, best_f1=0.6684073107049608
step: 0, loss: 0.017339058220386505
step: 10, loss: 0.016922250390052795
step: 20, loss: 0.042506247758865356
step: 30, loss: 0.005452765617519617
step: 40, loss: 0.12686479091644287
step: 50, loss: 0.004418990574777126
step: 60, loss: 0.0010798422154039145
step: 70, loss: 0.022868258878588676
step: 80, loss: 0.017719849944114685
step: 90, loss: 0.00042615729034878314
step: 100, loss: 0.12709054350852966
step: 110, loss: 0.015304050408303738
step: 120, loss: 0.0036954169627279043
step: 130, loss: 0.004923637956380844
step: 140, loss: 0.015348968096077442
step: 150, loss: 0.06949135661125183
step: 160, loss: 0.0007073297747410834
step: 170, loss: 0.004401157610118389
step: 180, loss: 0.09017352759838104
step: 190, loss: 0.0012891774531453848
step: 200, loss: 0.0012700111838057637
step: 210, loss: 0.020621463656425476
step: 220, loss: 0.0009182829526253045
step: 230, loss: 0.000959133030846715
step: 240, loss: 0.003932660445570946
step: 250, loss: 0.09559877216815948
step: 260, loss: 0.025128699839115143
step: 270, loss: 0.0037762050051242113
step: 280, loss: 0.004382575862109661
step: 290, loss: 0.0014774735318496823
step: 300, loss: 0.0007970347651280463
step: 310, loss: 0.0024421699345111847
step: 320, loss: 0.002128815744072199
step: 330, loss: 0.009665701538324356
step: 340, loss: 0.023350423201918602
step: 350, loss: 0.0020486596040427685
step: 360, loss: 0.01436001155525446
epoch 8: dev_f1=0.6612466124661247, f1=0.6379310344827587, best_f1=0.6379310344827587
step: 0, loss: 0.002360914135351777
step: 10, loss: 0.010015026666224003
step: 20, loss: 0.01001995149999857
step: 30, loss: 0.0011405524564906955
step: 40, loss: 0.000513346865773201
step: 50, loss: 0.023728903383016586
step: 60, loss: 0.002321353182196617
step: 70, loss: 0.05200248584151268
step: 80, loss: 0.00026182059082202613
step: 90, loss: 0.00048805816913954914
step: 100, loss: 0.0005754617159254849
step: 110, loss: 0.0016169196460396051
step: 120, loss: 0.0032460340298712254
step: 130, loss: 0.0008945709560066462
step: 140, loss: 0.0003618190821725875
step: 150, loss: 0.001801697420887649
step: 160, loss: 0.0033068207558244467
step: 170, loss: 0.0008705417276360095
step: 180, loss: 0.028074057772755623
step: 190, loss: 0.001076720654964447
step: 200, loss: 0.001825065934099257
step: 210, loss: 0.002477203728631139
step: 220, loss: 0.006264437455683947
step: 230, loss: 0.0021024225279688835
step: 240, loss: 0.0002622604079078883
step: 250, loss: 0.008563309907913208
step: 260, loss: 0.0026246197521686554
step: 270, loss: 0.14479276537895203
step: 280, loss: 0.013059607706964016
step: 290, loss: 0.0007765176123939455
step: 300, loss: 0.03597480058670044
step: 310, loss: 0.00033510001958347857
step: 320, loss: 0.0027381419204175472
step: 330, loss: 0.0003701755777001381
step: 340, loss: 0.03069639392197132
step: 350, loss: 0.001012521213851869
step: 360, loss: 0.00038011674769222736
epoch 9: dev_f1=0.6264367816091954, f1=0.5934718100890207, best_f1=0.6379310344827587
step: 0, loss: 0.00313109764829278
step: 10, loss: 0.02532464824616909
step: 20, loss: 0.002017582766711712
step: 30, loss: 0.0009857196127995849
step: 40, loss: 0.0007799430750310421
step: 50, loss: 0.002829440403729677
step: 60, loss: 0.002108938293531537
step: 70, loss: 0.0010730926878750324
step: 80, loss: 0.0007224409491755068
step: 90, loss: 0.0022257273085415363
step: 100, loss: 0.009630721062421799
step: 110, loss: 0.00011795380851253867
step: 120, loss: 0.053690262138843536
step: 130, loss: 0.00025406756321899593
step: 140, loss: 0.0014506354928016663
step: 150, loss: 0.014828174374997616
step: 160, loss: 0.0001780036254785955
step: 170, loss: 0.008253613486886024
step: 180, loss: 0.00019825705385301262
step: 190, loss: 0.0006086159846745431
step: 200, loss: 0.0002897614613175392
step: 210, loss: 0.0006836733082309365
step: 220, loss: 0.00013187302101869136
step: 230, loss: 0.0002966858446598053
step: 240, loss: 0.06888169050216675
step: 250, loss: 0.0005245925858616829
step: 260, loss: 0.00513736205175519
step: 270, loss: 0.00030800775857642293
step: 280, loss: 0.010835076682269573
step: 290, loss: 0.016233572736382484
step: 300, loss: 0.00014291632396634668
step: 310, loss: 0.000263009947957471
step: 320, loss: 0.002152897184714675
step: 330, loss: 0.0006803962751291692
step: 340, loss: 0.0034075190778821707
step: 350, loss: 0.004409467801451683
step: 360, loss: 0.0006793185020796955
epoch 10: dev_f1=0.6526315789473683, f1=0.6540540540540541, best_f1=0.6379310344827587
step: 0, loss: 0.001352530438452959
step: 10, loss: 4.009760596090928e-05
step: 20, loss: 0.0002894147764891386
step: 30, loss: 0.0001984353584703058
step: 40, loss: 0.01380754541605711
step: 50, loss: 0.0004504446987994015
step: 60, loss: 0.0010593978222459555
step: 70, loss: 0.001773209311068058
step: 80, loss: 0.0020815145689994097
step: 90, loss: 0.0003809101472143084
step: 100, loss: 8.724538929527625e-05
step: 110, loss: 0.0003554457507561892
step: 120, loss: 0.03694705292582512
step: 130, loss: 0.00022500852355733514
step: 140, loss: 0.0005177511484362185
step: 150, loss: 0.0032465283293277025
step: 160, loss: 0.012087666429579258
step: 170, loss: 0.000302789150737226
step: 180, loss: 0.010697015561163425
step: 190, loss: 0.0003287539875600487
step: 200, loss: 0.00047121266834437847
step: 210, loss: 0.0003418132255319506
step: 220, loss: 0.0010044514201581478
step: 230, loss: 0.00028923829086124897
step: 240, loss: 0.0016330901999026537
step: 250, loss: 0.0009690764709375799
step: 260, loss: 0.002492504194378853
step: 270, loss: 0.00035369815304875374
step: 280, loss: 0.002224039053544402
step: 290, loss: 0.001534776296466589
step: 300, loss: 0.003540530102327466
step: 310, loss: 0.00016690669872332364
step: 320, loss: 0.00013441071496345103
step: 330, loss: 0.008356126956641674
step: 340, loss: 0.0009728965815156698
step: 350, loss: 0.0008107624598778784
step: 360, loss: 0.0002393471368122846
epoch 11: dev_f1=0.6802030456852791, f1=0.6951871657754011, best_f1=0.6951871657754011
step: 0, loss: 0.00030216382583603263
step: 10, loss: 0.0002177444112021476
step: 20, loss: 0.0010146264685317874
step: 30, loss: 0.00015953915135469288
step: 40, loss: 0.0009637430775910616
step: 50, loss: 0.0004925315733999014
step: 60, loss: 7.368515070993453e-05
step: 70, loss: 0.010754652321338654
step: 80, loss: 0.00016926565149333328
step: 90, loss: 0.0021989804226905107
step: 100, loss: 0.00012498126307036728
step: 110, loss: 0.0003843775193672627
step: 120, loss: 0.00013789992954116315
step: 130, loss: 0.0008998865960165858
step: 140, loss: 0.0010491152061149478
step: 150, loss: 0.0001399656612193212
step: 160, loss: 6.499588926089928e-05
step: 170, loss: 0.00010008298704633489
step: 180, loss: 0.0005200026207603514
step: 190, loss: 0.0008592891390435398
step: 200, loss: 0.0017502120463177562
step: 210, loss: 0.003173448843881488
step: 220, loss: 6.594548176508397e-05
step: 230, loss: 0.00038946326822042465
step: 240, loss: 0.00013736830442212522
step: 250, loss: 0.010029877535998821
step: 260, loss: 0.00039165312773548067
step: 270, loss: 0.012924772687256336
step: 280, loss: 0.003404307644814253
step: 290, loss: 0.00020789011614397168
step: 300, loss: 0.009105955250561237
step: 310, loss: 0.0004590415337588638
step: 320, loss: 0.04609835520386696
step: 330, loss: 0.0002609885123092681
step: 340, loss: 8.296684973174706e-05
step: 350, loss: 0.0005714528379030526
step: 360, loss: 0.0002567546034697443
epoch 12: dev_f1=0.6363636363636364, f1=0.6243093922651933, best_f1=0.6951871657754011
step: 0, loss: 0.00015615324082318693
step: 10, loss: 0.005635052919387817
step: 20, loss: 0.0010672886855900288
step: 30, loss: 0.000620081671513617
step: 40, loss: 0.0015107592334970832
step: 50, loss: 0.0007247010362334549
step: 60, loss: 0.0006609400734305382
step: 70, loss: 0.007701059337705374
step: 80, loss: 0.000170690385857597
step: 90, loss: 6.277357169892639e-05
step: 100, loss: 0.0009818697581067681
step: 110, loss: 0.0002829318691510707
step: 120, loss: 0.00029057738720439374
step: 130, loss: 0.000280392006970942
step: 140, loss: 0.00012617815809790045
step: 150, loss: 6.462022429332137e-05
step: 160, loss: 0.0005848205182701349
step: 170, loss: 0.0003058982256334275
step: 180, loss: 5.1178714784327894e-05
step: 190, loss: 6.96912975399755e-05
step: 200, loss: 0.0001012479915516451
step: 210, loss: 0.0003705072740558535
step: 220, loss: 3.5891767765861005e-05
step: 230, loss: 0.00026625581085681915
step: 240, loss: 0.00019505889213178307
step: 250, loss: 0.0001449532574042678
step: 260, loss: 0.007405200507491827
step: 270, loss: 0.007573776412755251
step: 280, loss: 0.0007996000931598246
step: 290, loss: 0.00011125535820610821
step: 300, loss: 0.0016479755286127329
step: 310, loss: 0.0032269335351884365
step: 320, loss: 0.0029632700607180595
step: 330, loss: 5.877537842025049e-05
step: 340, loss: 0.00011357462062733248
step: 350, loss: 0.0001365401258226484
step: 360, loss: 0.0002118513366440311
epoch 13: dev_f1=0.6306818181818182, f1=0.6434782608695652, best_f1=0.6951871657754011
step: 0, loss: 7.605050632264465e-05
step: 10, loss: 0.0033298167400062084
step: 20, loss: 0.003799106227234006
step: 30, loss: 0.0009697566856630147
step: 40, loss: 0.001064895186573267
step: 50, loss: 0.00011592432565521449
step: 60, loss: 0.01708725281059742
step: 70, loss: 0.0003226911649107933
step: 80, loss: 0.00023016173508949578
step: 90, loss: 0.0006672705058008432
step: 100, loss: 0.0546712651848793
step: 110, loss: 0.00014700222527608275
step: 120, loss: 0.0008234053384512663
step: 130, loss: 0.003096794942393899
step: 140, loss: 0.0003037560672964901
step: 150, loss: 0.00012377255188766867
step: 160, loss: 0.00021164113422855735
step: 170, loss: 0.00022562981757801026
step: 180, loss: 0.03876953199505806
step: 190, loss: 0.0022381094750016928
step: 200, loss: 0.0002251776895718649
step: 210, loss: 0.00012055855040671304
step: 220, loss: 0.0002588741190265864
step: 230, loss: 0.000268732343101874
step: 240, loss: 0.031863268464803696
step: 250, loss: 9.03093969100155e-05
step: 260, loss: 0.0005994369857944548
step: 270, loss: 7.182834815466776e-05
step: 280, loss: 0.00040556665044277906
step: 290, loss: 0.11839402467012405
step: 300, loss: 0.0001839292235672474
step: 310, loss: 0.0011879088124260306
step: 320, loss: 0.00024825651780702174
step: 330, loss: 0.00042923170258291066
step: 340, loss: 0.007743531838059425
step: 350, loss: 0.00489428173750639
step: 360, loss: 0.00030311194132082164
epoch 14: dev_f1=0.6444444444444445, f1=0.651558073654391, best_f1=0.6951871657754011
step: 0, loss: 6.393867079168558e-05
step: 10, loss: 0.0020016112830489874
step: 20, loss: 0.0006135402363725007
step: 30, loss: 7.67777455621399e-05
step: 40, loss: 0.00033718248596414924
step: 50, loss: 0.00015942065510898829
step: 60, loss: 0.0005582177545875311
step: 70, loss: 0.00018751462630461901
step: 80, loss: 0.0004219174152240157
step: 90, loss: 5.097017128719017e-05
step: 100, loss: 9.215237514581531e-05
step: 110, loss: 0.0004985257983207703
step: 120, loss: 0.00010639707033988088
step: 130, loss: 0.000844956433866173
step: 140, loss: 7.240860577439889e-05
step: 150, loss: 0.00814446434378624
step: 160, loss: 0.0026623448356986046
step: 170, loss: 0.03703323379158974
step: 180, loss: 5.934965520282276e-05
step: 190, loss: 5.299549957271665e-05
step: 200, loss: 0.00836490560323
step: 210, loss: 0.0002131952642230317
step: 220, loss: 0.000611859024502337
step: 230, loss: 0.10801727324724197
step: 240, loss: 0.001516627729870379
step: 250, loss: 0.00016125287220347673
step: 260, loss: 0.00011062687553931028
step: 270, loss: 0.02722090110182762
step: 280, loss: 0.00011334352166159078
step: 290, loss: 9.01971579878591e-05
step: 300, loss: 0.0005098584806546569
step: 310, loss: 0.0005636383430100977
step: 320, loss: 0.0007951998268254101
step: 330, loss: 0.0014563651056960225
step: 340, loss: 0.0004977552453055978
step: 350, loss: 0.00029799045296385884
step: 360, loss: 0.0004148652369622141
epoch 15: dev_f1=0.6556473829201102, f1=0.6553672316384181, best_f1=0.6951871657754011
step: 0, loss: 0.04496610909700394
step: 10, loss: 0.0021988502703607082
step: 20, loss: 0.00018216774333268404
step: 30, loss: 0.00011153100058436394
step: 40, loss: 0.0032488456927239895
step: 50, loss: 3.330307299620472e-05
step: 60, loss: 2.1818685127072968e-05
step: 70, loss: 3.161523272865452e-05
step: 80, loss: 0.0007430926198139787
step: 90, loss: 0.00042299969936721027
step: 100, loss: 0.0001086196061805822
step: 110, loss: 0.00013818417210131884
step: 120, loss: 0.00019728908955585212
step: 130, loss: 0.0004568468139041215
step: 140, loss: 0.00023508320737164468
step: 150, loss: 0.0009009863715618849
step: 160, loss: 5.2177372708683833e-05
step: 170, loss: 0.0021970588713884354
step: 180, loss: 0.0011901110410690308
step: 190, loss: 0.00020370067795738578
step: 200, loss: 0.0007398381712846458
step: 210, loss: 0.0004143792612012476
step: 220, loss: 0.0002983364975079894
step: 230, loss: 0.0012020387221127748
step: 240, loss: 7.899403863120824e-05
step: 250, loss: 0.001005992409773171
step: 260, loss: 0.0003958792076446116
step: 270, loss: 0.0004096171469427645
step: 280, loss: 6.036035847500898e-05
step: 290, loss: 0.008425071835517883
step: 300, loss: 0.0001440290652681142
step: 310, loss: 0.00010351053060730919
step: 320, loss: 0.00016208997112698853
step: 330, loss: 0.00018332665786147118
step: 340, loss: 0.0040861270390450954
step: 350, loss: 0.0008944539004005492
step: 360, loss: 4.753181565320119e-05
epoch 16: dev_f1=0.6554621848739497, f1=0.6416184971098267, best_f1=0.6951871657754011
step: 0, loss: 6.563131319126114e-05
step: 10, loss: 4.344724220572971e-05
step: 20, loss: 0.00018573718261905015
step: 30, loss: 5.881131437490694e-05
step: 40, loss: 0.00011707234807545319
step: 50, loss: 0.00019294244702905416
step: 60, loss: 2.3848935597925447e-05
step: 70, loss: 0.006478822324424982
step: 80, loss: 0.00022135913604870439
step: 90, loss: 5.072385465609841e-05
step: 100, loss: 0.00021602233755402267
step: 110, loss: 0.0003248474677093327
step: 120, loss: 8.544193406123668e-05
step: 130, loss: 8.79880171851255e-05
step: 140, loss: 9.725490235723555e-05
step: 150, loss: 0.0007581181707791984
step: 160, loss: 0.00010581782407825813
step: 170, loss: 4.341101521276869e-05
step: 180, loss: 0.00013571845192927867
step: 190, loss: 3.660318907350302e-05
step: 200, loss: 0.0007124858093447983
step: 210, loss: 7.19403542461805e-05
step: 220, loss: 7.225756417028606e-05
step: 230, loss: 0.00027858628891408443
step: 240, loss: 0.00022985403484199196
step: 250, loss: 0.000356946635292843
step: 260, loss: 7.61375340516679e-05
step: 270, loss: 0.0010605069110170007
step: 280, loss: 5.666788274538703e-05
step: 290, loss: 0.00011710071703419089
step: 300, loss: 0.00020309427054598927
step: 310, loss: 3.5471053706714883e-05
step: 320, loss: 0.00011049446766264737
step: 330, loss: 3.7720135878771544e-05
step: 340, loss: 0.0011275216238573194
step: 350, loss: 7.311908120755106e-05
step: 360, loss: 0.00011201784218428656
epoch 17: dev_f1=0.651685393258427, f1=0.633720930232558, best_f1=0.6951871657754011
step: 0, loss: 0.00023491415777243674
step: 10, loss: 0.0001708266354398802
step: 20, loss: 8.623130270279944e-05
step: 30, loss: 9.257067722501233e-05
step: 40, loss: 9.648197010392323e-05
step: 50, loss: 0.0006060980958864093
step: 60, loss: 0.00020242753089405596
step: 70, loss: 0.00015578400052618235
step: 80, loss: 3.671683953143656e-05
step: 90, loss: 0.00024526717606931925
step: 100, loss: 6.336699880193919e-05
step: 110, loss: 0.00015067083586473018
step: 120, loss: 0.0004371598770376295
step: 130, loss: 5.478907041833736e-05
step: 140, loss: 2.6344652724219486e-05
step: 150, loss: 4.051442738273181e-05
step: 160, loss: 6.38927158433944e-05
step: 170, loss: 4.256442480254918e-05
step: 180, loss: 8.69750147103332e-05
step: 190, loss: 3.749108873307705e-05
step: 200, loss: 6.821433635195717e-05
step: 210, loss: 3.7832338421139866e-05
step: 220, loss: 6.011263030814007e-05
step: 230, loss: 0.0003194486489519477
step: 240, loss: 4.155348869971931e-05
step: 250, loss: 8.187632192857563e-05
step: 260, loss: 0.00015350004832725972
step: 270, loss: 0.0037182653322815895
step: 280, loss: 0.0001040253191604279
step: 290, loss: 0.0003713597252499312
step: 300, loss: 0.0001298433489864692
step: 310, loss: 4.0879611333366483e-05
step: 320, loss: 6.498493894468993e-05
step: 330, loss: 3.903934339177795e-05
step: 340, loss: 0.00010890533303609118
step: 350, loss: 3.1518422474619e-05
step: 360, loss: 4.247217293595895e-05
epoch 18: dev_f1=0.6514285714285714, f1=0.6374269005847953, best_f1=0.6951871657754011
step: 0, loss: 0.00014133162039797753
step: 10, loss: 0.00042536610271781683
step: 20, loss: 0.004059826955199242
step: 30, loss: 0.0007848351378925145
step: 40, loss: 0.00019817343854811043
step: 50, loss: 0.00013569771545007825
step: 60, loss: 0.0007189978496171534
step: 70, loss: 0.0001515477488283068
step: 80, loss: 0.0004556718631647527
step: 90, loss: 0.00032444120733998716
step: 100, loss: 0.00012000266724498942
step: 110, loss: 0.00010246729652862996
step: 120, loss: 5.5429438361898065e-05
step: 130, loss: 7.16940630809404e-05
step: 140, loss: 0.0009141304763033986
step: 150, loss: 7.143312541302294e-05
step: 160, loss: 0.00011234912381041795
step: 170, loss: 0.00410082284361124
step: 180, loss: 8.003343100426719e-05
step: 190, loss: 0.0005017976509407163
step: 200, loss: 2.728700746956747e-05
step: 210, loss: 0.00011510164040373638
step: 220, loss: 0.00018815557996276766
step: 230, loss: 0.04426399618387222
step: 240, loss: 2.7845600925502367e-05
step: 250, loss: 0.00016976035840343684
step: 260, loss: 2.8784699679818004e-05
step: 270, loss: 0.0005804714164696634
step: 280, loss: 0.00010042145004263148
step: 290, loss: 0.00012529749074019492
step: 300, loss: 0.00010340468725189567
step: 310, loss: 3.0315561161842197e-05
step: 320, loss: 3.850269422400743e-05
step: 330, loss: 0.00013582294923253357
step: 340, loss: 8.221789903473109e-05
step: 350, loss: 0.002613609656691551
step: 360, loss: 6.442748417612165e-05
epoch 19: dev_f1=0.6440677966101694, f1=0.6436781609195402, best_f1=0.6951871657754011
step: 0, loss: 0.00031486249645240605
step: 10, loss: 4.2942996515193954e-05
step: 20, loss: 0.0026607976760715246
step: 30, loss: 0.002957042306661606
step: 40, loss: 0.00011571715731406584
step: 50, loss: 8.578288543503731e-05
step: 60, loss: 0.0015560517786070704
step: 70, loss: 0.005175785161554813
step: 80, loss: 0.00010604565613903105
step: 90, loss: 5.045592115493491e-05
step: 100, loss: 0.0002612037642393261
step: 110, loss: 6.918055441929027e-05
step: 120, loss: 6.46617409074679e-05
step: 130, loss: 0.00020591626525856555
step: 140, loss: 0.00010732606460805982
step: 150, loss: 0.00015019995043985546
step: 160, loss: 6.756235234206542e-05
step: 170, loss: 0.00018785284191835672
step: 180, loss: 2.31112317123916e-05
step: 190, loss: 0.00033800682285800576
step: 200, loss: 7.872718560975045e-05
step: 210, loss: 0.00014411738084163517
step: 220, loss: 0.0016675496008247137
step: 230, loss: 0.000376592215616256
step: 240, loss: 8.827994315652177e-05
step: 250, loss: 7.931976870168e-05
step: 260, loss: 4.8632919060764834e-05
step: 270, loss: 0.0004412646230775863
step: 280, loss: 8.918557432480156e-05
step: 290, loss: 5.1579365390352905e-05
step: 300, loss: 0.0001752008538460359
step: 310, loss: 7.805870700394735e-05
step: 320, loss: 5.669182792189531e-05
step: 330, loss: 3.954888597945683e-05
step: 340, loss: 0.00013731059152632952
step: 350, loss: 0.00015380913100671023
step: 360, loss: 0.00018362455011811107
epoch 20: dev_f1=0.6522911051212938, f1=0.6537396121883656, best_f1=0.6951871657754011
