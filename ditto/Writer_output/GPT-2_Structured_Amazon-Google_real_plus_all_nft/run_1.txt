cuda
Device: cuda
step: 0, loss: 0.6041237115859985
step: 10, loss: 0.37317830324172974
step: 20, loss: 0.1877833753824234
step: 30, loss: 0.2362510859966278
step: 40, loss: 0.4026777446269989
step: 50, loss: 0.11479321122169495
step: 60, loss: 0.4209842383861542
step: 70, loss: 0.19733020663261414
step: 80, loss: 0.1416347771883011
step: 90, loss: 0.3902026116847992
step: 100, loss: 0.1436702162027359
step: 110, loss: 0.19574694335460663
step: 120, loss: 0.3973737359046936
step: 130, loss: 0.23340018093585968
step: 140, loss: 0.17179355025291443
step: 150, loss: 0.3212132751941681
step: 160, loss: 0.2627526521682739
step: 170, loss: 0.3346281051635742
step: 180, loss: 0.2550849914550781
step: 190, loss: 0.44974392652511597
step: 200, loss: 0.3618851602077484
step: 210, loss: 0.2395419478416443
step: 220, loss: 0.36750707030296326
step: 230, loss: 0.17992934584617615
step: 240, loss: 0.2121482938528061
step: 250, loss: 0.16532407701015472
step: 260, loss: 0.29893815517425537
step: 270, loss: 0.2745321989059448
step: 280, loss: 0.2951628863811493
step: 290, loss: 0.2853112518787384
step: 300, loss: 0.12348764389753342
step: 310, loss: 0.23560871183872223
step: 320, loss: 0.14945854246616364
step: 330, loss: 0.2968845069408417
step: 340, loss: 0.29601287841796875
step: 350, loss: 0.11687520146369934
step: 360, loss: 0.12856550514698029
step: 370, loss: 0.10919894278049469
step: 380, loss: 0.3610895574092865
step: 390, loss: 0.17677423357963562
step: 400, loss: 0.1700107306241989
step: 410, loss: 0.2513583302497864
step: 420, loss: 0.2053205519914627
epoch 1: dev_f1=0.673773987206823, f1=0.6336206896551724, best_f1=0.6336206896551724
step: 0, loss: 0.15590360760688782
step: 10, loss: 0.16010436415672302
step: 20, loss: 0.06731334328651428
step: 30, loss: 0.20227129757404327
step: 40, loss: 0.07281215488910675
step: 50, loss: 0.07961767166852951
step: 60, loss: 0.35024601221084595
step: 70, loss: 0.06846530735492706
step: 80, loss: 0.17510539293289185
step: 90, loss: 0.2893766164779663
step: 100, loss: 0.20965680480003357
step: 110, loss: 0.2740822434425354
step: 120, loss: 0.07800761610269547
step: 130, loss: 0.15123169124126434
step: 140, loss: 0.2124543935060501
step: 150, loss: 0.13378457725048065
step: 160, loss: 0.11418871581554413
step: 170, loss: 0.15382227301597595
step: 180, loss: 0.2752574682235718
step: 190, loss: 0.21253572404384613
step: 200, loss: 0.15308819711208344
step: 210, loss: 0.2328728586435318
step: 220, loss: 0.05243557319045067
step: 230, loss: 0.08151774108409882
step: 240, loss: 0.1135152205824852
step: 250, loss: 0.15027204155921936
step: 260, loss: 0.1971953809261322
step: 270, loss: 0.1427188217639923
step: 280, loss: 0.15788574516773224
step: 290, loss: 0.09662193059921265
step: 300, loss: 0.021418550983071327
step: 310, loss: 0.14985595643520355
step: 320, loss: 0.1519007682800293
step: 330, loss: 0.07418019324541092
step: 340, loss: 0.1258697509765625
step: 350, loss: 0.1495809108018875
step: 360, loss: 0.019891908392310143
step: 370, loss: 0.320622056722641
step: 380, loss: 0.16206605732440948
step: 390, loss: 0.08345235884189606
step: 400, loss: 0.14651478826999664
step: 410, loss: 0.15672922134399414
step: 420, loss: 0.2796745002269745
epoch 2: dev_f1=0.736, f1=0.6492374727668846, best_f1=0.6492374727668846
step: 0, loss: 0.05632289499044418
step: 10, loss: 0.10506725311279297
step: 20, loss: 0.105002760887146
step: 30, loss: 0.07667236030101776
step: 40, loss: 0.03374653309583664
step: 50, loss: 0.031639423221349716
step: 60, loss: 0.19972430169582367
step: 70, loss: 0.1276053637266159
step: 80, loss: 0.16893693804740906
step: 90, loss: 0.0954948216676712
step: 100, loss: 0.2931908667087555
step: 110, loss: 0.04944215342402458
step: 120, loss: 0.0974736213684082
step: 130, loss: 0.024316612631082535
step: 140, loss: 0.09074711054563522
step: 150, loss: 0.10423538088798523
step: 160, loss: 0.2020857036113739
step: 170, loss: 0.07412935048341751
step: 180, loss: 0.14650718867778778
step: 190, loss: 0.06812302768230438
step: 200, loss: 0.057915620505809784
step: 210, loss: 0.05287691205739975
step: 220, loss: 0.06771156191825867
step: 230, loss: 0.12023165076971054
step: 240, loss: 0.14338257908821106
step: 250, loss: 0.18269877135753632
step: 260, loss: 0.05178731679916382
step: 270, loss: 0.04463451728224754
step: 280, loss: 0.1581137329339981
step: 290, loss: 0.20608796179294586
step: 300, loss: 0.1418868750333786
step: 310, loss: 0.050776634365320206
step: 320, loss: 0.10586114227771759
step: 330, loss: 0.08339016139507294
step: 340, loss: 0.04697767645120621
step: 350, loss: 0.11836883425712585
step: 360, loss: 0.0521564856171608
step: 370, loss: 0.0720679834485054
step: 380, loss: 0.21642740070819855
step: 390, loss: 0.05255179852247238
step: 400, loss: 0.11997027695178986
step: 410, loss: 0.10315386950969696
step: 420, loss: 0.25927144289016724
epoch 3: dev_f1=0.7394209354120267, f1=0.6255924170616114, best_f1=0.6255924170616114
step: 0, loss: 0.1429816633462906
step: 10, loss: 0.07343541085720062
step: 20, loss: 0.06538980454206467
step: 30, loss: 0.07068328559398651
step: 40, loss: 0.03209295868873596
step: 50, loss: 0.05549140274524689
step: 60, loss: 0.005589149426668882
step: 70, loss: 0.036146070808172226
step: 80, loss: 0.1266006976366043
step: 90, loss: 0.2035047560930252
step: 100, loss: 0.10868465155363083
step: 110, loss: 0.05840867757797241
step: 120, loss: 0.10189405083656311
step: 130, loss: 0.22834153473377228
step: 140, loss: 0.15369991958141327
step: 150, loss: 0.08113079518079758
step: 160, loss: 0.07448370009660721
step: 170, loss: 0.113780677318573
step: 180, loss: 0.24229466915130615
step: 190, loss: 0.05430290848016739
step: 200, loss: 0.014005785807967186
step: 210, loss: 0.04135655239224434
step: 220, loss: 0.1853111982345581
step: 230, loss: 0.04134427756071091
step: 240, loss: 0.2642993927001953
step: 250, loss: 0.046291548758745193
step: 260, loss: 0.31449607014656067
step: 270, loss: 0.1254701018333435
step: 280, loss: 0.03793637827038765
step: 290, loss: 0.12185140699148178
step: 300, loss: 0.008480784483253956
step: 310, loss: 0.028106942772865295
step: 320, loss: 0.12365110963582993
step: 330, loss: 0.10419423133134842
step: 340, loss: 0.05853360518813133
step: 350, loss: 0.11797777563333511
step: 360, loss: 0.08360461890697479
step: 370, loss: 0.261567085981369
step: 380, loss: 0.14307208359241486
step: 390, loss: 0.13045638799667358
step: 400, loss: 0.07926201075315475
step: 410, loss: 0.05754275247454643
step: 420, loss: 0.04281146451830864
epoch 4: dev_f1=0.7419354838709677, f1=0.6877637130801688, best_f1=0.6877637130801688
step: 0, loss: 0.037537120282649994
step: 10, loss: 0.1413971483707428
step: 20, loss: 0.013536222279071808
step: 30, loss: 0.009982788935303688
step: 40, loss: 0.01933998428285122
step: 50, loss: 0.00909284595400095
step: 60, loss: 0.03500084578990936
step: 70, loss: 0.062100645154714584
step: 80, loss: 0.02480805478990078
step: 90, loss: 0.0337977334856987
step: 100, loss: 0.06631678342819214
step: 110, loss: 0.11610428243875504
step: 120, loss: 0.14083321392536163
step: 130, loss: 0.0054156165570020676
step: 140, loss: 0.08408519625663757
step: 150, loss: 0.10911663621664047
step: 160, loss: 0.09950794279575348
step: 170, loss: 0.11751294136047363
step: 180, loss: 0.006848620716482401
step: 190, loss: 0.05121899023652077
step: 200, loss: 0.007016898598521948
step: 210, loss: 0.07356417924165726
step: 220, loss: 0.02306019701063633
step: 230, loss: 0.04616497457027435
step: 240, loss: 0.14414112269878387
step: 250, loss: 0.1922713816165924
step: 260, loss: 0.004875050392001867
step: 270, loss: 0.17085199058055878
step: 280, loss: 0.04148435220122337
step: 290, loss: 0.13042514026165009
step: 300, loss: 0.07042042911052704
step: 310, loss: 0.15868833661079407
step: 320, loss: 0.06963539123535156
step: 330, loss: 0.01089278794825077
step: 340, loss: 0.03290896117687225
step: 350, loss: 0.04767603054642677
step: 360, loss: 0.10557657480239868
step: 370, loss: 0.1276741325855255
step: 380, loss: 0.14215555787086487
step: 390, loss: 0.16673573851585388
step: 400, loss: 0.058972299098968506
step: 410, loss: 0.1010553166270256
step: 420, loss: 0.08494744449853897
epoch 5: dev_f1=0.7385892116182572, f1=0.6710816777041942, best_f1=0.6877637130801688
step: 0, loss: 0.08224033564329147
step: 10, loss: 0.12535245716571808
step: 20, loss: 0.05004669353365898
step: 30, loss: 0.07874061912298203
step: 40, loss: 0.08271613717079163
step: 50, loss: 0.07299374788999557
step: 60, loss: 0.07587799429893494
step: 70, loss: 0.0032816529273986816
step: 80, loss: 0.10210806876420975
step: 90, loss: 0.011579631827771664
step: 100, loss: 0.06850320100784302
step: 110, loss: 0.015434117056429386
step: 120, loss: 0.12474630773067474
step: 130, loss: 0.0053352066315710545
step: 140, loss: 0.07385111600160599
step: 150, loss: 0.006339057348668575
step: 160, loss: 0.014914379455149174
step: 170, loss: 0.0445149727165699
step: 180, loss: 0.05031472072005272
step: 190, loss: 0.08219499886035919
step: 200, loss: 0.0032515712082386017
step: 210, loss: 0.004265105817466974
step: 220, loss: 0.09258536994457245
step: 230, loss: 0.003247753018513322
step: 240, loss: 0.01347450353205204
step: 250, loss: 0.06281030178070068
step: 260, loss: 0.1215902715921402
step: 270, loss: 0.0671481043100357
step: 280, loss: 0.014484788291156292
step: 290, loss: 0.008426203392446041
step: 300, loss: 0.002135006943717599
step: 310, loss: 0.08173937350511551
step: 320, loss: 0.015465331263840199
step: 330, loss: 0.011154990643262863
step: 340, loss: 0.011235910467803478
step: 350, loss: 0.022182000800967216
step: 360, loss: 0.2987026870250702
step: 370, loss: 0.009116851724684238
step: 380, loss: 0.16137349605560303
step: 390, loss: 0.04390604421496391
step: 400, loss: 0.036079104989767075
step: 410, loss: 0.01601303182542324
step: 420, loss: 0.10360018163919449
epoch 6: dev_f1=0.7532467532467534, f1=0.6114942528735632, best_f1=0.6114942528735632
step: 0, loss: 0.010244172066450119
step: 10, loss: 0.01657300628721714
step: 20, loss: 0.01232218649238348
step: 30, loss: 0.0033140266314148903
step: 40, loss: 0.06207301840186119
step: 50, loss: 0.040335558354854584
step: 60, loss: 0.060871563851833344
step: 70, loss: 0.0601452961564064
step: 80, loss: 0.05521225184202194
step: 90, loss: 0.0108549939468503
step: 100, loss: 0.1314544528722763
step: 110, loss: 0.06587503105401993
step: 120, loss: 0.002604197710752487
step: 130, loss: 0.003994410391896963
step: 140, loss: 0.425780713558197
step: 150, loss: 0.003355091204866767
step: 160, loss: 0.004071114119142294
step: 170, loss: 0.004388805013149977
step: 180, loss: 0.01569223217666149
step: 190, loss: 0.07339783012866974
step: 200, loss: 0.15127798914909363
step: 210, loss: 0.12501288950443268
step: 220, loss: 0.028248906135559082
step: 230, loss: 0.013202505186200142
step: 240, loss: 0.10405293107032776
step: 250, loss: 0.021786117926239967
step: 260, loss: 0.012592359445989132
step: 270, loss: 0.07369348406791687
step: 280, loss: 0.006857903674244881
step: 290, loss: 0.0011986562749370933
step: 300, loss: 0.01612747460603714
step: 310, loss: 0.08233823627233505
step: 320, loss: 0.039560467004776
step: 330, loss: 0.1158912181854248
step: 340, loss: 0.019292471930384636
step: 350, loss: 0.009190373122692108
step: 360, loss: 0.004411206115037203
step: 370, loss: 0.002137242816388607
step: 380, loss: 0.061584267765283585
step: 390, loss: 0.042810697108507156
step: 400, loss: 0.01317087933421135
step: 410, loss: 0.051077574491500854
step: 420, loss: 0.020163606852293015
epoch 7: dev_f1=0.7364341085271319, f1=0.6813627254509018, best_f1=0.6114942528735632
step: 0, loss: 0.040073927491903305
step: 10, loss: 0.03414972126483917
step: 20, loss: 0.018828053027391434
step: 30, loss: 0.005181889981031418
step: 40, loss: 0.08642066270112991
step: 50, loss: 0.013421406038105488
step: 60, loss: 0.008017295971512794
step: 70, loss: 0.003283498575910926
step: 80, loss: 0.010540053248405457
step: 90, loss: 0.048507705330848694
step: 100, loss: 0.05791792646050453
step: 110, loss: 0.06955123692750931
step: 120, loss: 0.00574103556573391
step: 130, loss: 0.04773049056529999
step: 140, loss: 0.005297156050801277
step: 150, loss: 0.10928581655025482
step: 160, loss: 0.0029260183218866587
step: 170, loss: 0.0014604032039642334
step: 180, loss: 0.002886516274884343
step: 190, loss: 0.0017857415368780494
step: 200, loss: 0.013011643663048744
step: 210, loss: 0.01811925694346428
step: 220, loss: 0.0403527170419693
step: 230, loss: 0.12908042967319489
step: 240, loss: 0.01203499361872673
step: 250, loss: 0.08240360021591187
step: 260, loss: 0.004462750628590584
step: 270, loss: 0.15288126468658447
step: 280, loss: 0.004145290702581406
step: 290, loss: 0.02435794100165367
step: 300, loss: 0.124692402780056
step: 310, loss: 0.0343131385743618
step: 320, loss: 0.004298694897443056
step: 330, loss: 0.04791369289159775
step: 340, loss: 0.020805908367037773
step: 350, loss: 0.05484083294868469
step: 360, loss: 0.02559121698141098
step: 370, loss: 0.0039029023610055447
step: 380, loss: 0.002007473027333617
step: 390, loss: 0.07089976966381073
step: 400, loss: 0.09085428714752197
step: 410, loss: 0.06953294575214386
step: 420, loss: 0.06036610156297684
epoch 8: dev_f1=0.7459677419354839, f1=0.6594827586206896, best_f1=0.6114942528735632
step: 0, loss: 0.003743230365216732
step: 10, loss: 0.032136738300323486
step: 20, loss: 0.00688198022544384
step: 30, loss: 0.01746397092938423
step: 40, loss: 0.04613739624619484
step: 50, loss: 0.0028044346254318953
step: 60, loss: 0.006701883859932423
step: 70, loss: 0.039383355528116226
step: 80, loss: 0.004209817387163639
step: 90, loss: 0.02877652272582054
step: 100, loss: 0.10645616799592972
step: 110, loss: 0.0009458178537897766
step: 120, loss: 0.006204724777489901
step: 130, loss: 0.004328093957155943
step: 140, loss: 0.027845609933137894
step: 150, loss: 0.01323311310261488
step: 160, loss: 0.005852959584444761
step: 170, loss: 0.0023211680818349123
step: 180, loss: 0.012789673171937466
step: 190, loss: 0.09934049844741821
step: 200, loss: 0.02988673560321331
step: 210, loss: 0.2122213989496231
step: 220, loss: 0.016901150345802307
step: 230, loss: 0.008613456971943378
step: 240, loss: 0.0014801968354731798
step: 250, loss: 0.038383085280656815
step: 260, loss: 0.004227285273373127
step: 270, loss: 0.035261932760477066
step: 280, loss: 0.022440757602453232
step: 290, loss: 0.03749004378914833
step: 300, loss: 0.0007982113165780902
step: 310, loss: 0.003968642093241215
step: 320, loss: 0.008892439305782318
step: 330, loss: 0.007699363399296999
step: 340, loss: 0.009629195556044579
step: 350, loss: 0.011044745333492756
step: 360, loss: 0.02290423773229122
step: 370, loss: 0.041561421006917953
step: 380, loss: 0.003792949253693223
step: 390, loss: 0.004233960993587971
step: 400, loss: 0.013929869048297405
step: 410, loss: 0.005820778198540211
step: 420, loss: 0.0036894786171615124
epoch 9: dev_f1=0.7531914893617021, f1=0.6279069767441862, best_f1=0.6114942528735632
step: 0, loss: 0.01855677179992199
step: 10, loss: 0.0033254383597522974
step: 20, loss: 0.0028336644172668457
step: 30, loss: 0.000881948450114578
step: 40, loss: 0.0013120440999045968
step: 50, loss: 0.024446668103337288
step: 60, loss: 0.01945926621556282
step: 70, loss: 0.08866671472787857
step: 80, loss: 0.0072755953297019005
step: 90, loss: 0.11828600615262985
step: 100, loss: 0.0025885163340717554
step: 110, loss: 0.053977880626916885
step: 120, loss: 0.01252023410052061
step: 130, loss: 0.026408547535538673
step: 140, loss: 0.01427088025957346
step: 150, loss: 0.04893636330962181
step: 160, loss: 0.003469210583716631
step: 170, loss: 0.010659408755600452
step: 180, loss: 0.019746793434023857
step: 190, loss: 0.14930425584316254
step: 200, loss: 0.0044945948757231236
step: 210, loss: 0.0005344122764654458
step: 220, loss: 0.008052120916545391
step: 230, loss: 0.005309552885591984
step: 240, loss: 0.037135712802410126
step: 250, loss: 0.01401890255510807
step: 260, loss: 0.059895798563957214
step: 270, loss: 0.0012916459236294031
step: 280, loss: 0.011972395703196526
step: 290, loss: 0.057973623275756836
step: 300, loss: 0.004743857309222221
step: 310, loss: 0.010306507349014282
step: 320, loss: 0.015725674107670784
step: 330, loss: 0.010420666076242924
step: 340, loss: 0.05169659107923508
step: 350, loss: 0.0030340091325342655
step: 360, loss: 0.016950059682130814
step: 370, loss: 0.0022758590057492256
step: 380, loss: 0.009656226262450218
step: 390, loss: 0.03743407875299454
step: 400, loss: 0.15460491180419922
step: 410, loss: 0.027707956731319427
step: 420, loss: 0.003019942669197917
epoch 10: dev_f1=0.75, f1=0.6541666666666667, best_f1=0.6114942528735632
step: 0, loss: 0.039656173437833786
step: 10, loss: 0.0011768415570259094
step: 20, loss: 0.00479354290291667
step: 30, loss: 0.005968107376247644
step: 40, loss: 0.0030061095021665096
step: 50, loss: 0.00749148428440094
step: 60, loss: 0.004215093329548836
step: 70, loss: 0.0037223626859486103
step: 80, loss: 0.00016558892093598843
step: 90, loss: 0.004372619558125734
step: 100, loss: 0.06890290975570679
step: 110, loss: 0.011600757017731667
step: 120, loss: 0.05076800659298897
step: 130, loss: 0.00028590954025276005
step: 140, loss: 0.001380288042128086
step: 150, loss: 0.00031482792110182345
step: 160, loss: 0.000536138191819191
step: 170, loss: 0.18319246172904968
step: 180, loss: 0.00476562324911356
step: 190, loss: 0.033106375485658646
step: 200, loss: 0.001461414503864944
step: 210, loss: 0.002524023875594139
step: 220, loss: 0.01630988158285618
step: 230, loss: 0.07364178448915482
step: 240, loss: 0.007466303650289774
step: 250, loss: 0.0014657499268651009
step: 260, loss: 0.011504671536386013
step: 270, loss: 0.0017564675072208047
step: 280, loss: 0.0016791220987215638
step: 290, loss: 0.018462304025888443
step: 300, loss: 0.2899587154388428
step: 310, loss: 0.05661626160144806
step: 320, loss: 0.006481947377324104
step: 330, loss: 0.00204856158234179
step: 340, loss: 0.0013558128848671913
step: 350, loss: 0.015927817672491074
step: 360, loss: 0.002000009175390005
step: 370, loss: 0.02901257760822773
step: 380, loss: 0.021046794950962067
step: 390, loss: 0.005542542319744825
step: 400, loss: 0.0004825701762456447
step: 410, loss: 0.0038483645766973495
step: 420, loss: 0.0011835965560749173
epoch 11: dev_f1=0.7654320987654322, f1=0.645021645021645, best_f1=0.645021645021645
step: 0, loss: 0.0006718470249325037
step: 10, loss: 0.00044615325168706477
step: 20, loss: 0.008875772356987
step: 30, loss: 0.003277915297076106
step: 40, loss: 0.0026959050446748734
step: 50, loss: 0.02876615710556507
step: 60, loss: 0.020210806280374527
step: 70, loss: 0.0001578816445544362
step: 80, loss: 0.0019993905443698168
step: 90, loss: 0.0069795954041182995
step: 100, loss: 0.00041686627082526684
step: 110, loss: 9.334769856650382e-05
step: 120, loss: 0.01850755512714386
step: 130, loss: 0.010151195339858532
step: 140, loss: 0.03904585912823677
step: 150, loss: 0.04420913755893707
step: 160, loss: 0.020615218207240105
step: 170, loss: 0.0012837891699746251
step: 180, loss: 0.00643214350566268
step: 190, loss: 0.07877897471189499
step: 200, loss: 0.0003975033760070801
step: 210, loss: 0.005105543881654739
step: 220, loss: 0.005187135189771652
step: 230, loss: 0.00035282658063806593
step: 240, loss: 0.00013752213271800429
step: 250, loss: 0.04110689461231232
step: 260, loss: 0.00220848829485476
step: 270, loss: 0.0006883872556500137
step: 280, loss: 0.03762646019458771
step: 290, loss: 0.0010074919555336237
step: 300, loss: 0.01971321925520897
step: 310, loss: 0.07077816128730774
step: 320, loss: 0.04510039463639259
step: 330, loss: 0.0011505146976560354
step: 340, loss: 0.0026670664083212614
step: 350, loss: 0.018063396215438843
step: 360, loss: 0.0011566446628421545
step: 370, loss: 0.004702818114310503
step: 380, loss: 0.06250248849391937
step: 390, loss: 0.0006242102244868875
step: 400, loss: 0.004262958187609911
step: 410, loss: 0.02590039186179638
step: 420, loss: 0.04819144308567047
epoch 12: dev_f1=0.7529411764705882, f1=0.6435845213849287, best_f1=0.645021645021645
step: 0, loss: 0.003894714405760169
step: 10, loss: 0.0013097579358145595
step: 20, loss: 0.0003267945139668882
step: 30, loss: 0.015049050562083721
step: 40, loss: 0.020562293007969856
step: 50, loss: 0.0581304207444191
step: 60, loss: 0.0001813560666050762
step: 70, loss: 0.005018174182623625
step: 80, loss: 0.00013316015247255564
step: 90, loss: 0.0013096899492666125
step: 100, loss: 0.003919041249901056
step: 110, loss: 0.017921170219779015
step: 120, loss: 0.0003916790592484176
step: 130, loss: 0.00036897920654155314
step: 140, loss: 0.00013349828077480197
step: 150, loss: 0.005530230235308409
step: 160, loss: 0.016328001394867897
step: 170, loss: 0.00030878957477398217
step: 180, loss: 0.00036332960007712245
step: 190, loss: 0.0001031146093737334
step: 200, loss: 0.008079437538981438
step: 210, loss: 0.01844918355345726
step: 220, loss: 0.0002911559713538736
step: 230, loss: 0.0020910408347845078
step: 240, loss: 0.0003560774785000831
step: 250, loss: 0.007150590419769287
step: 260, loss: 0.000376007315935567
step: 270, loss: 0.00019883870845660567
step: 280, loss: 0.0057994294911623
step: 290, loss: 0.0003174038720317185
step: 300, loss: 0.16045059263706207
step: 310, loss: 0.018810315057635307
step: 320, loss: 0.0031373801175504923
step: 330, loss: 0.00014107507013250142
step: 340, loss: 0.00015911724767647684
step: 350, loss: 0.05930633470416069
step: 360, loss: 0.003899082075804472
step: 370, loss: 0.0012393674114719033
step: 380, loss: 0.0002773818268906325
step: 390, loss: 0.0002506626187823713
step: 400, loss: 0.02392667718231678
step: 410, loss: 0.0009988527745008469
step: 420, loss: 0.012746676802635193
epoch 13: dev_f1=0.7489361702127659, f1=0.6178489702517161, best_f1=0.645021645021645
step: 0, loss: 0.010719241574406624
step: 10, loss: 0.004569973796606064
step: 20, loss: 0.0036855931393802166
step: 30, loss: 0.00046896887943148613
step: 40, loss: 0.00026912306202575564
step: 50, loss: 0.00040059618186205626
step: 60, loss: 0.00023192520893644542
step: 70, loss: 0.00030224936199374497
step: 80, loss: 0.002658394630998373
step: 90, loss: 0.0035675852559506893
step: 100, loss: 6.47764973109588e-05
step: 110, loss: 0.00040379923302680254
step: 120, loss: 0.0017910628812387586
step: 130, loss: 0.0033157584257423878
step: 140, loss: 0.03046633116900921
step: 150, loss: 0.0027717920020222664
step: 160, loss: 0.11560455709695816
step: 170, loss: 0.002670126734301448
step: 180, loss: 0.004715233109891415
step: 190, loss: 0.01891150139272213
step: 200, loss: 0.02026345580816269
step: 210, loss: 0.03136349469423294
step: 220, loss: 8.24853268568404e-05
step: 230, loss: 7.193992496468127e-05
step: 240, loss: 9.723006223794073e-05
step: 250, loss: 0.028508776798844337
step: 260, loss: 0.043925199657678604
step: 270, loss: 0.00013952466542832553
step: 280, loss: 0.03555286303162575
step: 290, loss: 0.006298857741057873
step: 300, loss: 0.05704867094755173
step: 310, loss: 0.0034154560416936874
step: 320, loss: 0.0020082383416593075
step: 330, loss: 0.00010662719432730228
step: 340, loss: 0.0010080985957756639
step: 350, loss: 0.0001636917149880901
step: 360, loss: 0.015262735076248646
step: 370, loss: 0.02232547663152218
step: 380, loss: 0.0014314112486317754
step: 390, loss: 0.00019057848840020597
step: 400, loss: 0.04241819679737091
step: 410, loss: 0.0045715272426605225
step: 420, loss: 0.02674696408212185
epoch 14: dev_f1=0.7510204081632653, f1=0.6536796536796536, best_f1=0.645021645021645
step: 0, loss: 0.0008112597861327231
step: 10, loss: 0.01606994867324829
step: 20, loss: 0.0003444148460403085
step: 30, loss: 4.299865031498484e-05
step: 40, loss: 0.003598206676542759
step: 50, loss: 0.00015622582577634603
step: 60, loss: 0.0006188034312799573
step: 70, loss: 0.022669317200779915
step: 80, loss: 0.0009721146780066192
step: 90, loss: 6.735459464835003e-05
step: 100, loss: 0.0018017039401456714
step: 110, loss: 0.00042636756552383304
step: 120, loss: 0.00015196026652120054
step: 130, loss: 0.0007619650568813086
step: 140, loss: 0.010765030048787594
step: 150, loss: 0.000130405169329606
step: 160, loss: 0.0015332087641581893
step: 170, loss: 0.00012621426139958203
step: 180, loss: 0.003217169549316168
step: 190, loss: 0.0008208341314457357
step: 200, loss: 0.0005110582569614053
step: 210, loss: 9.764996502781287e-05
step: 220, loss: 5.625396443065256e-05
step: 230, loss: 0.00012393019278533757
step: 240, loss: 5.670671453117393e-05
step: 250, loss: 0.02860143408179283
step: 260, loss: 0.0012183727230876684
step: 270, loss: 0.0007338195573538542
step: 280, loss: 0.002007995964959264
step: 290, loss: 0.0005558326374739408
step: 300, loss: 0.0011888894950971007
step: 310, loss: 0.01723928563296795
step: 320, loss: 0.0007621768163517118
step: 330, loss: 0.0003026389458682388
step: 340, loss: 0.00011016234930139035
step: 350, loss: 0.0006071337265893817
step: 360, loss: 0.057895977050065994
step: 370, loss: 0.0010136592900380492
step: 380, loss: 0.00856897234916687
step: 390, loss: 0.00017539924010634422
step: 400, loss: 0.004673697054386139
step: 410, loss: 0.0015765909338369966
step: 420, loss: 0.0017166743054986
epoch 15: dev_f1=0.7541666666666668, f1=0.6488888888888888, best_f1=0.645021645021645
step: 0, loss: 0.002457371912896633
step: 10, loss: 0.0003552772104740143
step: 20, loss: 0.03442196547985077
step: 30, loss: 0.05084112659096718
step: 40, loss: 0.0032144314609467983
step: 50, loss: 0.004516080021858215
step: 60, loss: 6.344675057334825e-05
step: 70, loss: 0.0022170126903802156
step: 80, loss: 0.00021049805218353868
step: 90, loss: 0.006317728199064732
step: 100, loss: 0.00025018074666149914
step: 110, loss: 0.016981905326247215
step: 120, loss: 0.0001113432299462147
step: 130, loss: 0.003787954105064273
step: 140, loss: 0.16003061830997467
step: 150, loss: 0.00889555737376213
step: 160, loss: 0.07440680265426636
step: 170, loss: 8.882977272151038e-05
step: 180, loss: 6.415371899493039e-05
step: 190, loss: 3.275163908256218e-05
step: 200, loss: 0.0013970914296805859
step: 210, loss: 0.0007363955373875797
step: 220, loss: 0.003722545923665166
step: 230, loss: 0.0009144821669906378
step: 240, loss: 0.002866153372451663
step: 250, loss: 0.00013439168105833232
step: 260, loss: 0.005071327090263367
step: 270, loss: 0.00025284552248194814
step: 280, loss: 0.06488292664289474
step: 290, loss: 0.00011719267786247656
step: 300, loss: 0.00991468969732523
step: 310, loss: 0.0354100838303566
step: 320, loss: 0.0005951732746325433
step: 330, loss: 0.002396657830104232
step: 340, loss: 0.0006610266864299774
step: 350, loss: 0.00013681224663741887
step: 360, loss: 0.001187374466098845
step: 370, loss: 0.002357288496568799
step: 380, loss: 0.0016983718378469348
step: 390, loss: 0.025251636281609535
step: 400, loss: 0.0011784671805799007
step: 410, loss: 0.006572153884917498
step: 420, loss: 0.03378583490848541
epoch 16: dev_f1=0.754880694143167, f1=0.6190476190476191, best_f1=0.645021645021645
step: 0, loss: 7.20227908459492e-05
step: 10, loss: 0.00024756789207458496
step: 20, loss: 0.0005389208672568202
step: 30, loss: 0.00031375372782349586
step: 40, loss: 7.449123950209469e-05
step: 50, loss: 0.00025483014178462327
step: 60, loss: 0.06829734146595001
step: 70, loss: 4.865590017288923e-05
step: 80, loss: 0.000360640900908038
step: 90, loss: 0.014645951800048351
step: 100, loss: 8.594968676334247e-05
step: 110, loss: 0.028451019898056984
step: 120, loss: 0.000652183429338038
step: 130, loss: 0.00010516179463593289
step: 140, loss: 0.04644611477851868
step: 150, loss: 9.791312186280265e-05
step: 160, loss: 0.008440815843641758
step: 170, loss: 0.0004352533142082393
step: 180, loss: 0.00034314149525016546
step: 190, loss: 0.005407903343439102
step: 200, loss: 3.657262641354464e-05
step: 210, loss: 0.0001556419301778078
step: 220, loss: 0.005269475746899843
step: 230, loss: 0.017629118636250496
step: 240, loss: 0.000499140820465982
step: 250, loss: 3.3424967114115134e-05
step: 260, loss: 0.0010408670641481876
step: 270, loss: 0.004041225183755159
step: 280, loss: 7.660265691811219e-05
step: 290, loss: 0.0006057614227756858
step: 300, loss: 0.012323946692049503
step: 310, loss: 0.00012567697558552027
step: 320, loss: 0.0102172140032053
step: 330, loss: 0.0010280859423801303
step: 340, loss: 0.010235046967864037
step: 350, loss: 0.0022822050377726555
step: 360, loss: 0.00011773168807849288
step: 370, loss: 0.0003855427785310894
step: 380, loss: 0.01900847814977169
step: 390, loss: 7.857314631110057e-05
step: 400, loss: 5.294662696542218e-05
step: 410, loss: 4.2800529627129436e-05
step: 420, loss: 0.005343560129404068
epoch 17: dev_f1=0.7568710359408033, f1=0.6500000000000001, best_f1=0.645021645021645
step: 0, loss: 7.684653246542439e-05
step: 10, loss: 0.0007422131602652371
step: 20, loss: 0.00014640906010754406
step: 30, loss: 0.0011918017407879233
step: 40, loss: 4.8543315642746165e-05
step: 50, loss: 0.0006105393404141068
step: 60, loss: 7.569818990305066e-05
step: 70, loss: 3.7228779547149315e-05
step: 80, loss: 0.00047560263192281127
step: 90, loss: 0.00036917030229233205
step: 100, loss: 0.00033346592681482434
step: 110, loss: 9.29445814108476e-05
step: 120, loss: 0.0006689394358545542
step: 130, loss: 0.0005228138761594892
step: 140, loss: 0.00034628043067641556
step: 150, loss: 0.0008324114605784416
step: 160, loss: 6.571073026861995e-05
step: 170, loss: 0.0030571380630135536
step: 180, loss: 1.4960595763113815e-05
step: 190, loss: 0.00023695803247392178
step: 200, loss: 0.00043748985626734793
step: 210, loss: 9.214659803546965e-05
step: 220, loss: 2.0749452232848853e-05
step: 230, loss: 0.02955261990427971
step: 240, loss: 0.0023402043152600527
step: 250, loss: 0.005954449065029621
step: 260, loss: 0.00013884183135814965
step: 270, loss: 4.5234221033751965e-05
step: 280, loss: 0.007641729898750782
step: 290, loss: 0.0001342456234851852
step: 300, loss: 6.352135824272409e-05
step: 310, loss: 8.659323066240177e-05
step: 320, loss: 0.0020255076233297586
step: 330, loss: 0.0014654186088591814
step: 340, loss: 0.018075061962008476
step: 350, loss: 0.0001238795812241733
step: 360, loss: 4.81012393720448e-05
step: 370, loss: 0.0005131315556354821
step: 380, loss: 0.00011850296868942678
step: 390, loss: 7.631842163391411e-05
step: 400, loss: 9.585938096279278e-05
step: 410, loss: 0.025271283462643623
step: 420, loss: 0.00042719292105175555
epoch 18: dev_f1=0.759753593429158, f1=0.6506550218340611, best_f1=0.645021645021645
step: 0, loss: 6.361995474435389e-05
step: 10, loss: 0.00699317641556263
step: 20, loss: 0.023978279903531075
step: 30, loss: 0.0005513195064850152
step: 40, loss: 0.00017918649245984852
step: 50, loss: 0.0015804811846464872
step: 60, loss: 0.00010288917110301554
step: 70, loss: 0.014331711456179619
step: 80, loss: 0.03698958829045296
step: 90, loss: 4.3365787860238925e-05
step: 100, loss: 4.6343095164047554e-05
step: 110, loss: 0.0005820213700644672
step: 120, loss: 5.2982850320404395e-05
step: 130, loss: 0.0001025992605718784
step: 140, loss: 5.612596214632504e-05
step: 150, loss: 0.00038219738053157926
step: 160, loss: 0.00012279486691113561
step: 170, loss: 0.00010440808546263725
step: 180, loss: 0.0013414929853752255
step: 190, loss: 0.00046164169907569885
step: 200, loss: 0.00021603993081953377
step: 210, loss: 0.002006544265896082
step: 220, loss: 0.0007485183887183666
step: 230, loss: 8.422674727626145e-05
step: 240, loss: 2.3796075765858404e-05
step: 250, loss: 0.0049577271565794945
step: 260, loss: 0.00024891842622309923
step: 270, loss: 0.00474944245070219
step: 280, loss: 0.013568446971476078
step: 290, loss: 0.002336532808840275
step: 300, loss: 0.003107225289568305
step: 310, loss: 0.00029541781987063587
step: 320, loss: 9.552216215524822e-05
step: 330, loss: 0.00017650726658757776
step: 340, loss: 0.004269659519195557
step: 350, loss: 0.0027460046112537384
step: 360, loss: 0.0010252285283058882
step: 370, loss: 0.00018977666331920773
step: 380, loss: 0.0035685128532350063
step: 390, loss: 0.00011738095781765878
step: 400, loss: 0.0004191930638626218
step: 410, loss: 0.035932764410972595
step: 420, loss: 3.0002060157130472e-05
epoch 19: dev_f1=0.7577639751552795, f1=0.6428571428571428, best_f1=0.645021645021645
step: 0, loss: 4.293427991797216e-05
step: 10, loss: 7.459365588147193e-05
step: 20, loss: 0.008311278186738491
step: 30, loss: 0.0035336934961378574
step: 40, loss: 0.0011498520616441965
step: 50, loss: 6.672100425930694e-05
step: 60, loss: 0.0003795287339016795
step: 70, loss: 0.00013220944674685597
step: 80, loss: 0.0010277823312208056
step: 90, loss: 0.03914368152618408
step: 100, loss: 3.811249553109519e-05
step: 110, loss: 4.156706927460618e-05
step: 120, loss: 0.0006946462672203779
step: 130, loss: 0.00011487150186439976
step: 140, loss: 0.0004292263474781066
step: 150, loss: 0.0011782407527789474
step: 160, loss: 0.00018462301522959024
step: 170, loss: 7.648023165529594e-05
step: 180, loss: 9.621872595744208e-05
step: 190, loss: 0.0024745764676481485
step: 200, loss: 0.000221759793930687
step: 210, loss: 4.043061926495284e-05
step: 220, loss: 0.00031103554647415876
step: 230, loss: 0.004041894804686308
step: 240, loss: 0.0002227371442131698
step: 250, loss: 3.533980270731263e-05
step: 260, loss: 0.00025161143275909126
step: 270, loss: 0.0021170969121158123
step: 280, loss: 2.742841388680972e-05
step: 290, loss: 0.0005413545295596123
step: 300, loss: 8.936678932514042e-05
step: 310, loss: 0.0013330470537766814
step: 320, loss: 0.00015003538283053786
step: 330, loss: 0.00014035883941687644
step: 340, loss: 0.0003729102318175137
step: 350, loss: 0.013632298447191715
step: 360, loss: 0.009068498387932777
step: 370, loss: 0.0003301271062809974
step: 380, loss: 0.00010879785986617208
step: 390, loss: 0.0015960232121869922
step: 400, loss: 0.00628231605514884
step: 410, loss: 0.000621424987912178
step: 420, loss: 0.00010744089377112687
epoch 20: dev_f1=0.757201646090535, f1=0.6430155210643015, best_f1=0.645021645021645
