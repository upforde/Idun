cuda
Device: cuda
step: 0, loss: 0.9283640384674072
step: 10, loss: 0.19937928020954132
step: 20, loss: 0.45530328154563904
step: 30, loss: 0.3745489716529846
step: 40, loss: 0.2890925407409668
step: 50, loss: 0.1108819916844368
step: 60, loss: 0.29655152559280396
step: 70, loss: 0.5113720893859863
step: 80, loss: 0.16573642194271088
step: 90, loss: 0.28499075770378113
step: 100, loss: 0.3992297053337097
step: 110, loss: 0.24788177013397217
step: 120, loss: 0.19815033674240112
step: 130, loss: 0.13343173265457153
step: 140, loss: 0.0852416381239891
step: 150, loss: 0.4423280954360962
step: 160, loss: 0.0669729933142662
step: 170, loss: 0.14318834245204926
step: 180, loss: 0.306395560503006
step: 190, loss: 0.20711398124694824
step: 200, loss: 0.17883890867233276
step: 210, loss: 0.09089255332946777
step: 220, loss: 0.27939194440841675
step: 230, loss: 0.3416445851325989
step: 240, loss: 0.12175211310386658
step: 250, loss: 0.19024288654327393
step: 260, loss: 0.19177217781543732
step: 270, loss: 0.25625908374786377
step: 280, loss: 0.19545437395572662
step: 290, loss: 0.18483325839042664
step: 300, loss: 0.12350673973560333
step: 310, loss: 0.21256759762763977
step: 320, loss: 0.25513923168182373
step: 330, loss: 0.18183304369449615
step: 340, loss: 0.2505735754966736
step: 350, loss: 0.2443038821220398
step: 360, loss: 0.18135593831539154
step: 370, loss: 0.1332876831293106
step: 380, loss: 0.1666005551815033
step: 390, loss: 0.21875713765621185
step: 400, loss: 0.23763152956962585
step: 410, loss: 0.24971236288547516
step: 420, loss: 0.110446497797966
epoch 1: dev_f1=0.6947368421052633, f1=0.6347826086956522, best_f1=0.6347826086956522
step: 0, loss: 0.08219040930271149
step: 10, loss: 0.12069958448410034
step: 20, loss: 0.1579352468252182
step: 30, loss: 0.20938082039356232
step: 40, loss: 0.10386110842227936
step: 50, loss: 0.21787616610527039
step: 60, loss: 0.2608548104763031
step: 70, loss: 0.16243994235992432
step: 80, loss: 0.07019446045160294
step: 90, loss: 0.1124640554189682
step: 100, loss: 0.09475773572921753
step: 110, loss: 0.14781978726387024
step: 120, loss: 0.22060075402259827
step: 130, loss: 0.19316110014915466
step: 140, loss: 0.32241618633270264
step: 150, loss: 0.2432522177696228
step: 160, loss: 0.42464131116867065
step: 170, loss: 0.19614827632904053
step: 180, loss: 0.03503032773733139
step: 190, loss: 0.1519872099161148
step: 200, loss: 0.2997235655784607
step: 210, loss: 0.07390615344047546
step: 220, loss: 0.0876554623246193
step: 230, loss: 0.11506694555282593
step: 240, loss: 0.18817661702632904
step: 250, loss: 0.33183684945106506
step: 260, loss: 0.21085089445114136
step: 270, loss: 0.22712205350399017
step: 280, loss: 0.16885967552661896
step: 290, loss: 0.22430692613124847
step: 300, loss: 0.2008928656578064
step: 310, loss: 0.4235342741012573
step: 320, loss: 0.12088507413864136
step: 330, loss: 0.092504121363163
step: 340, loss: 0.14157748222351074
step: 350, loss: 0.11722862720489502
step: 360, loss: 0.13933289051055908
step: 370, loss: 0.20898164808750153
step: 380, loss: 0.10549785196781158
step: 390, loss: 0.24492259323596954
step: 400, loss: 0.24903610348701477
step: 410, loss: 0.18320374190807343
step: 420, loss: 0.1360529363155365
epoch 2: dev_f1=0.7312614259597806, f1=0.6758349705304519, best_f1=0.6758349705304519
step: 0, loss: 0.11645632982254028
step: 10, loss: 0.11194968968629837
step: 20, loss: 0.1762864887714386
step: 30, loss: 0.25965040922164917
step: 40, loss: 0.20733392238616943
step: 50, loss: 0.1357070803642273
step: 60, loss: 0.09846567362546921
step: 70, loss: 0.10325224697589874
step: 80, loss: 0.1133386418223381
step: 90, loss: 0.11775155365467072
step: 100, loss: 0.11184374243021011
step: 110, loss: 0.09767109155654907
step: 120, loss: 0.2670751214027405
step: 130, loss: 0.11172682046890259
step: 140, loss: 0.13785718381404877
step: 150, loss: 0.30897819995880127
step: 160, loss: 0.037106018513441086
step: 170, loss: 0.4402061402797699
step: 180, loss: 0.10176229476928711
step: 190, loss: 0.13094104826450348
step: 200, loss: 0.10472725331783295
step: 210, loss: 0.08186159282922745
step: 220, loss: 0.353782057762146
step: 230, loss: 0.12500809133052826
step: 240, loss: 0.0417499914765358
step: 250, loss: 0.20641353726387024
step: 260, loss: 0.3402148485183716
step: 270, loss: 0.17868633568286896
step: 280, loss: 0.05288798362016678
step: 290, loss: 0.3251124322414398
step: 300, loss: 0.19468188285827637
step: 310, loss: 0.19282644987106323
step: 320, loss: 0.5809706449508667
step: 330, loss: 0.1467183530330658
step: 340, loss: 0.19759953022003174
step: 350, loss: 0.3624211847782135
step: 360, loss: 0.1517152339220047
step: 370, loss: 0.21458926796913147
step: 380, loss: 0.2166968584060669
step: 390, loss: 0.28651162981987
step: 400, loss: 0.0799272432923317
step: 410, loss: 0.17240317165851593
step: 420, loss: 0.08791843801736832
epoch 3: dev_f1=0.7519083969465649, f1=0.7117296222664016, best_f1=0.7117296222664016
step: 0, loss: 0.020947951823472977
step: 10, loss: 0.1380195915699005
step: 20, loss: 0.015185189433395863
step: 30, loss: 0.11021093279123306
step: 40, loss: 0.0687870904803276
step: 50, loss: 0.07234398275613785
step: 60, loss: 0.15027199685573578
step: 70, loss: 0.08208099007606506
step: 80, loss: 0.11962549388408661
step: 90, loss: 0.18002931773662567
step: 100, loss: 0.016005748882889748
step: 110, loss: 0.10411500185728073
step: 120, loss: 0.08828356862068176
step: 130, loss: 0.08636406809091568
step: 140, loss: 0.16428466141223907
step: 150, loss: 0.028121817857027054
step: 160, loss: 0.08170895278453827
step: 170, loss: 0.1355152130126953
step: 180, loss: 0.163591206073761
step: 190, loss: 0.016921086236834526
step: 200, loss: 0.13546790182590485
step: 210, loss: 0.021164117380976677
step: 220, loss: 0.11358702182769775
step: 230, loss: 0.030020853504538536
step: 240, loss: 0.09678760170936584
step: 250, loss: 0.11394263058900833
step: 260, loss: 0.05342058092355728
step: 270, loss: 0.06787873059511185
step: 280, loss: 0.11142648011445999
step: 290, loss: 0.05617702752351761
step: 300, loss: 0.07839090377092361
step: 310, loss: 0.0543334074318409
step: 320, loss: 0.09768841415643692
step: 330, loss: 0.01603882759809494
step: 340, loss: 0.12939141690731049
step: 350, loss: 0.03675993159413338
step: 360, loss: 0.29899862408638
step: 370, loss: 0.07584439963102341
step: 380, loss: 0.14311537146568298
step: 390, loss: 0.39090225100517273
step: 400, loss: 0.11073455959558487
step: 410, loss: 0.04534636810421944
step: 420, loss: 0.09497345238924026
epoch 4: dev_f1=0.7623126338329764, f1=0.6697038724373576, best_f1=0.6697038724373576
step: 0, loss: 0.045220836997032166
step: 10, loss: 0.014881403185427189
step: 20, loss: 0.04180004447698593
step: 30, loss: 0.13305352628231049
step: 40, loss: 0.1381216049194336
step: 50, loss: 0.06918036192655563
step: 60, loss: 0.04822118580341339
step: 70, loss: 0.010375278070569038
step: 80, loss: 0.03861670568585396
step: 90, loss: 0.08147674053907394
step: 100, loss: 0.009993363171815872
step: 110, loss: 0.007977689616382122
step: 120, loss: 0.02129758894443512
step: 130, loss: 0.1414463222026825
step: 140, loss: 0.0460522398352623
step: 150, loss: 0.021234847605228424
step: 160, loss: 0.0660410225391388
step: 170, loss: 0.003830747911706567
step: 180, loss: 0.14300411939620972
step: 190, loss: 0.04497732222080231
step: 200, loss: 0.007967456243932247
step: 210, loss: 0.020409664139151573
step: 220, loss: 0.05816161260008812
step: 230, loss: 0.005041690077632666
step: 240, loss: 0.03487618640065193
step: 250, loss: 0.027567405253648758
step: 260, loss: 0.03282090649008751
step: 270, loss: 0.029898809269070625
step: 280, loss: 0.06590677797794342
step: 290, loss: 0.039927247911691666
step: 300, loss: 0.10396204888820648
step: 310, loss: 0.09000612050294876
step: 320, loss: 0.04567713290452957
step: 330, loss: 0.00617285817861557
step: 340, loss: 0.015932315960526466
step: 350, loss: 0.14148634672164917
step: 360, loss: 0.0005997336120344698
step: 370, loss: 0.08348742127418518
step: 380, loss: 0.008128824643790722
step: 390, loss: 0.10636631399393082
step: 400, loss: 0.03421600162982941
step: 410, loss: 0.2094862014055252
step: 420, loss: 0.1393834948539734
epoch 5: dev_f1=0.7288503253796095, f1=0.6213151927437643, best_f1=0.6697038724373576
step: 0, loss: 0.0033590495586395264
step: 10, loss: 0.04325834661722183
step: 20, loss: 0.13961240649223328
step: 30, loss: 0.06003565713763237
step: 40, loss: 0.017601503059267998
step: 50, loss: 0.023123381659388542
step: 60, loss: 0.02273637428879738
step: 70, loss: 0.06421691924333572
step: 80, loss: 0.09188492596149445
step: 90, loss: 0.0028874387498944998
step: 100, loss: 0.022673925384879112
step: 110, loss: 0.12388256937265396
step: 120, loss: 0.005014622118324041
step: 130, loss: 0.03723446652293205
step: 140, loss: 0.17351488769054413
step: 150, loss: 0.03742697834968567
step: 160, loss: 0.07826627790927887
step: 170, loss: 0.06166307255625725
step: 180, loss: 0.003659025765955448
step: 190, loss: 0.02735469862818718
step: 200, loss: 0.08484581857919693
step: 210, loss: 0.052320946007966995
step: 220, loss: 0.04664534330368042
step: 230, loss: 0.004923586267977953
step: 240, loss: 0.008907655254006386
step: 250, loss: 0.053239379078149796
step: 260, loss: 0.16923773288726807
step: 270, loss: 0.1295960247516632
step: 280, loss: 0.016958314925432205
step: 290, loss: 0.0933072417974472
step: 300, loss: 0.2288050353527069
step: 310, loss: 0.05688405781984329
step: 320, loss: 0.1052808165550232
step: 330, loss: 0.06703391671180725
step: 340, loss: 0.10640543699264526
step: 350, loss: 0.012457960285246372
step: 360, loss: 0.03226020932197571
step: 370, loss: 0.215479776263237
step: 380, loss: 0.009288303554058075
step: 390, loss: 0.04487872123718262
step: 400, loss: 0.04347120597958565
step: 410, loss: 0.028187520802021027
step: 420, loss: 0.05079597234725952
epoch 6: dev_f1=0.759753593429158, f1=0.6883116883116882, best_f1=0.6697038724373576
step: 0, loss: 0.035098765045404434
step: 10, loss: 0.010618048720061779
step: 20, loss: 0.06396239250898361
step: 30, loss: 0.09606576710939407
step: 40, loss: 0.007321503013372421
step: 50, loss: 0.023617872968316078
step: 60, loss: 0.0561581514775753
step: 70, loss: 0.011207991279661655
step: 80, loss: 0.02561354637145996
step: 90, loss: 0.025099309161305428
step: 100, loss: 0.00984480232000351
step: 110, loss: 0.05195414647459984
step: 120, loss: 0.026027873158454895
step: 130, loss: 0.0046452721580863
step: 140, loss: 0.0005910054314881563
step: 150, loss: 0.009033440612256527
step: 160, loss: 0.01581352762877941
step: 170, loss: 0.007708848919719458
step: 180, loss: 0.07513108104467392
step: 190, loss: 0.03270934522151947
step: 200, loss: 0.0468120239675045
step: 210, loss: 0.09115173667669296
step: 220, loss: 0.014151365496218204
step: 230, loss: 0.0026691192761063576
step: 240, loss: 0.0259552039206028
step: 250, loss: 0.00027821905678138137
step: 260, loss: 0.011437423527240753
step: 270, loss: 0.05855469033122063
step: 280, loss: 0.06862326711416245
step: 290, loss: 0.02047679014503956
step: 300, loss: 0.02082936279475689
step: 310, loss: 0.05486377328634262
step: 320, loss: 0.02509736455976963
step: 330, loss: 0.1397663950920105
step: 340, loss: 0.02737145684659481
step: 350, loss: 0.0223199762403965
step: 360, loss: 0.003448226023465395
step: 370, loss: 0.04658570885658264
step: 380, loss: 0.0109382513910532
step: 390, loss: 0.01337037980556488
step: 400, loss: 0.24706989526748657
step: 410, loss: 0.36516043543815613
step: 420, loss: 0.013965455815196037
epoch 7: dev_f1=0.7650485436893204, f1=0.6761710794297352, best_f1=0.6761710794297352
step: 0, loss: 0.1375916302204132
step: 10, loss: 0.03097892925143242
step: 20, loss: 0.022891517728567123
step: 30, loss: 0.004015084356069565
step: 40, loss: 0.010709437541663647
step: 50, loss: 0.12803591787815094
step: 60, loss: 0.016707850620150566
step: 70, loss: 0.017908534035086632
step: 80, loss: 0.024545816704630852
step: 90, loss: 0.03388119116425514
step: 100, loss: 0.031415700912475586
step: 110, loss: 0.03210658207535744
step: 120, loss: 0.11921687424182892
step: 130, loss: 0.027391701936721802
step: 140, loss: 0.07295359671115875
step: 150, loss: 0.02854793332517147
step: 160, loss: 0.0756877213716507
step: 170, loss: 0.013324790634214878
step: 180, loss: 0.17722345888614655
step: 190, loss: 0.04129781201481819
step: 200, loss: 0.03356482461094856
step: 210, loss: 0.016782132908701897
step: 220, loss: 0.05006568506360054
step: 230, loss: 0.018781082704663277
step: 240, loss: 0.09160377830266953
step: 250, loss: 0.0036795653868466616
step: 260, loss: 0.0023649686481803656
step: 270, loss: 0.02351052314043045
step: 280, loss: 0.005210831295698881
step: 290, loss: 0.03036155365407467
step: 300, loss: 0.025350257754325867
step: 310, loss: 0.023710157722234726
step: 320, loss: 0.004641235806047916
step: 330, loss: 0.003380435984581709
step: 340, loss: 0.09643162786960602
step: 350, loss: 0.0555562824010849
step: 360, loss: 0.025066722184419632
step: 370, loss: 0.16550281643867493
step: 380, loss: 0.04095257446169853
step: 390, loss: 0.09884167462587357
step: 400, loss: 0.03487293794751167
step: 410, loss: 0.005717712454497814
step: 420, loss: 0.0031327202450484037
epoch 8: dev_f1=0.782435129740519, f1=0.673728813559322, best_f1=0.673728813559322
step: 0, loss: 0.00826291274279356
step: 10, loss: 0.0025645096320658922
step: 20, loss: 0.002653995528817177
step: 30, loss: 0.028655141592025757
step: 40, loss: 0.00042138880235143006
step: 50, loss: 0.037543877959251404
step: 60, loss: 0.01990858092904091
step: 70, loss: 0.02243969403207302
step: 80, loss: 0.02200329676270485
step: 90, loss: 0.0010673383949324489
step: 100, loss: 0.0009744365233927965
step: 110, loss: 0.008419285528361797
step: 120, loss: 0.02580266445875168
step: 130, loss: 0.06806019693613052
step: 140, loss: 0.0027584312483668327
step: 150, loss: 0.010395338758826256
step: 160, loss: 0.0008946366142481565
step: 170, loss: 0.017084553837776184
step: 180, loss: 0.012267333455383778
step: 190, loss: 0.002089313929900527
step: 200, loss: 0.0003213496529497206
step: 210, loss: 0.053747497498989105
step: 220, loss: 0.01670270971953869
step: 230, loss: 0.037600327283144
step: 240, loss: 0.07491222023963928
step: 250, loss: 0.03608299791812897
step: 260, loss: 0.04650823771953583
step: 270, loss: 0.011736816726624966
step: 280, loss: 0.010090690106153488
step: 290, loss: 0.005228463560342789
step: 300, loss: 0.0015277414349839091
step: 310, loss: 0.018564239144325256
step: 320, loss: 0.00515151908621192
step: 330, loss: 0.003059447044506669
step: 340, loss: 0.039907097816467285
step: 350, loss: 0.02626531384885311
step: 360, loss: 0.0004437321040313691
step: 370, loss: 0.015234348364174366
step: 380, loss: 0.05748100206255913
step: 390, loss: 0.0036970991641283035
step: 400, loss: 0.0035515420604497194
step: 410, loss: 0.029245637357234955
step: 420, loss: 0.029914751648902893
epoch 9: dev_f1=0.7727272727272728, f1=0.6537634408602151, best_f1=0.673728813559322
step: 0, loss: 0.008907068520784378
step: 10, loss: 0.0009036250994540751
step: 20, loss: 0.021778766065835953
step: 30, loss: 0.0018497436540201306
step: 40, loss: 0.0035956690553575754
step: 50, loss: 0.005714445374906063
step: 60, loss: 0.058980681002140045
step: 70, loss: 0.01477896049618721
step: 80, loss: 0.0018989519448950887
step: 90, loss: 0.00018549614469520748
step: 100, loss: 0.004953504074364901
step: 110, loss: 0.005438397638499737
step: 120, loss: 0.002351682400330901
step: 130, loss: 0.006598590407520533
step: 140, loss: 0.0005748543189838529
step: 150, loss: 0.0012403380824252963
step: 160, loss: 0.07177459448575974
step: 170, loss: 0.00968455895781517
step: 180, loss: 0.0007972982130013406
step: 190, loss: 0.0581384003162384
step: 200, loss: 0.04612508788704872
step: 210, loss: 0.002885157009586692
step: 220, loss: 0.11175299435853958
step: 230, loss: 0.0001309975777985528
step: 240, loss: 0.007064953912049532
step: 250, loss: 0.06435831636190414
step: 260, loss: 0.022012200206518173
step: 270, loss: 0.022113941609859467
step: 280, loss: 0.014394823461771011
step: 290, loss: 0.008618757128715515
step: 300, loss: 0.0069847069680690765
step: 310, loss: 0.051382821053266525
step: 320, loss: 0.0010878404136747122
step: 330, loss: 0.001083227340131998
step: 340, loss: 0.00014520864351652563
step: 350, loss: 0.02900800295174122
step: 360, loss: 0.0025925845839083195
step: 370, loss: 0.0005642729229293764
step: 380, loss: 0.005088538397103548
step: 390, loss: 0.0004442459612619132
step: 400, loss: 0.022218838334083557
step: 410, loss: 0.03625869378447533
step: 420, loss: 0.002073834650218487
epoch 10: dev_f1=0.7655310621242485, f1=0.6918238993710691, best_f1=0.673728813559322
step: 0, loss: 0.00013457365275826305
step: 10, loss: 0.003511801129207015
step: 20, loss: 0.01024424284696579
step: 30, loss: 0.012078968808054924
step: 40, loss: 0.030371693894267082
step: 50, loss: 0.0002656797878444195
step: 60, loss: 0.005548510700464249
step: 70, loss: 0.06002645194530487
step: 80, loss: 0.007306982297450304
step: 90, loss: 0.0015482216840609908
step: 100, loss: 0.01270519569516182
step: 110, loss: 0.002245952608063817
step: 120, loss: 0.06383760273456573
step: 130, loss: 0.008849811740219593
step: 140, loss: 0.0005997016560286283
step: 150, loss: 0.01501399278640747
step: 160, loss: 0.00030426483135670424
step: 170, loss: 0.09136570990085602
step: 180, loss: 0.02182658016681671
step: 190, loss: 0.0002158396237064153
step: 200, loss: 0.0019431813852861524
step: 210, loss: 0.002800405491143465
step: 220, loss: 0.026746220886707306
step: 230, loss: 0.0008615801343694329
step: 240, loss: 0.005579239223152399
step: 250, loss: 0.005249973852187395
step: 260, loss: 0.033667050302028656
step: 270, loss: 0.00950904842466116
step: 280, loss: 0.00024163344642147422
step: 290, loss: 0.013880226761102676
step: 300, loss: 0.013682179152965546
step: 310, loss: 0.03780626505613327
step: 320, loss: 0.061215419322252274
step: 330, loss: 0.0009200216736644506
step: 340, loss: 0.049077246338129044
step: 350, loss: 0.06072215735912323
step: 360, loss: 0.0004933447926305234
step: 370, loss: 0.0016140349907800555
step: 380, loss: 0.01096289325505495
step: 390, loss: 0.007193738128989935
step: 400, loss: 0.0008784747333265841
step: 410, loss: 0.02437562867999077
step: 420, loss: 0.0008690495742484927
epoch 11: dev_f1=0.7617107942973524, f1=0.6722689075630253, best_f1=0.673728813559322
step: 0, loss: 0.000235694446018897
step: 10, loss: 0.0013444857904687524
step: 20, loss: 0.023824850097298622
step: 30, loss: 0.008724537678062916
step: 40, loss: 0.00013380324526224285
step: 50, loss: 0.0028802170418202877
step: 60, loss: 0.007597305811941624
step: 70, loss: 0.005119616631418467
step: 80, loss: 0.0016398414736613631
step: 90, loss: 0.033047620207071304
step: 100, loss: 0.002579350955784321
step: 110, loss: 0.0043565938249230385
step: 120, loss: 0.050302423536777496
step: 130, loss: 0.007691760081797838
step: 140, loss: 0.00011148562043672428
step: 150, loss: 0.004509041551500559
step: 160, loss: 0.0070792147889733315
step: 170, loss: 0.010163855738937855
step: 180, loss: 0.0007503759698010981
step: 190, loss: 0.013435718603432178
step: 200, loss: 0.00026841892395168543
step: 210, loss: 0.012388372793793678
step: 220, loss: 0.0016087568365037441
step: 230, loss: 0.0020074499770998955
step: 240, loss: 0.0056133451871573925
step: 250, loss: 0.0011418461799621582
step: 260, loss: 0.009332667104899883
step: 270, loss: 0.033797409385442734
step: 280, loss: 0.010071445256471634
step: 290, loss: 0.001602340955287218
step: 300, loss: 0.0035545802675187588
step: 310, loss: 0.0018916389672085643
step: 320, loss: 0.011657020077109337
step: 330, loss: 0.061319246888160706
step: 340, loss: 0.0022871133405715227
step: 350, loss: 0.00048078782856464386
step: 360, loss: 0.04828459396958351
step: 370, loss: 0.026333747431635857
step: 380, loss: 0.001443416578695178
step: 390, loss: 0.012466605752706528
step: 400, loss: 0.0004925644025206566
step: 410, loss: 0.008745727129280567
step: 420, loss: 0.00013623254199046642
epoch 12: dev_f1=0.7675906183368869, f1=0.6784922394678493, best_f1=0.673728813559322
step: 0, loss: 0.009987465105950832
step: 10, loss: 0.001012712367810309
step: 20, loss: 0.014618233777582645
step: 30, loss: 0.0012888198252767324
step: 40, loss: 0.04291770979762077
step: 50, loss: 0.009322029538452625
step: 60, loss: 0.001190823852084577
step: 70, loss: 0.0007494360907003284
step: 80, loss: 0.0006474812398664653
step: 90, loss: 0.00018647439719643444
step: 100, loss: 0.017600154504179955
step: 110, loss: 0.033026065677404404
step: 120, loss: 0.006103426218032837
step: 130, loss: 0.0002701207413338125
step: 140, loss: 0.0004119185032323003
step: 150, loss: 0.0018861319404095411
step: 160, loss: 0.0005925715668126941
step: 170, loss: 0.001919255475513637
step: 180, loss: 0.0017347331158816814
step: 190, loss: 0.0004411465779412538
step: 200, loss: 0.002976617543026805
step: 210, loss: 0.01600978896021843
step: 220, loss: 0.002100256970152259
step: 230, loss: 0.0030274083837866783
step: 240, loss: 0.013802073895931244
step: 250, loss: 0.0008162618614733219
step: 260, loss: 0.143529012799263
step: 270, loss: 0.010428069159388542
step: 280, loss: 0.011760901659727097
step: 290, loss: 0.00078303407644853
step: 300, loss: 0.0014065476134419441
step: 310, loss: 0.0007987804128788412
step: 320, loss: 0.0023104525171220303
step: 330, loss: 0.023059016093611717
step: 340, loss: 0.00016124032845254987
step: 350, loss: 0.0018650367856025696
step: 360, loss: 0.004068442620337009
step: 370, loss: 0.02302609197795391
step: 380, loss: 0.035226792097091675
step: 390, loss: 0.018267039209604263
step: 400, loss: 0.0002997311530634761
step: 410, loss: 4.841385816689581e-05
step: 420, loss: 0.00035251775989308953
epoch 13: dev_f1=0.7895791583166332, f1=0.6903765690376569, best_f1=0.6903765690376569
step: 0, loss: 0.005135700572282076
step: 10, loss: 0.004411881789565086
step: 20, loss: 0.019031289964914322
step: 30, loss: 0.0016041600611060858
step: 40, loss: 0.00012472507660277188
step: 50, loss: 0.01908954046666622
step: 60, loss: 0.0003445566399022937
step: 70, loss: 0.002408580854535103
step: 80, loss: 0.0011319720651954412
step: 90, loss: 0.1963062584400177
step: 100, loss: 0.002650435082614422
step: 110, loss: 0.005361403338611126
step: 120, loss: 0.0011355601018294692
step: 130, loss: 0.00011172841914230958
step: 140, loss: 0.0015181839698925614
step: 150, loss: 0.0028953186701983213
step: 160, loss: 0.00046400883002206683
step: 170, loss: 0.00012677507766056806
step: 180, loss: 0.033741582185029984
step: 190, loss: 0.0007433398859575391
step: 200, loss: 0.002886164700612426
step: 210, loss: 0.003396761603653431
step: 220, loss: 8.398128557018936e-05
step: 230, loss: 0.0274517759680748
step: 240, loss: 0.010959499515593052
step: 250, loss: 0.056506525725126266
step: 260, loss: 0.0001570453168824315
step: 270, loss: 0.009065110236406326
step: 280, loss: 0.002473550383001566
step: 290, loss: 0.05576329305768013
step: 300, loss: 0.00015976074791979045
step: 310, loss: 0.019957374781370163
step: 320, loss: 4.299927604733966e-05
step: 330, loss: 0.00014886129065416753
step: 340, loss: 0.011431526392698288
step: 350, loss: 0.00014136898971628398
step: 360, loss: 0.0011809461284428835
step: 370, loss: 0.0018900054274126887
step: 380, loss: 5.565971150645055e-05
step: 390, loss: 0.0011903251288458705
step: 400, loss: 8.934586367104203e-05
step: 410, loss: 0.0023907674476504326
step: 420, loss: 0.0004284747992642224
epoch 14: dev_f1=0.7662337662337663, f1=0.6788154897494305, best_f1=0.6903765690376569
step: 0, loss: 0.0016868829261511564
step: 10, loss: 0.0014734625583514571
step: 20, loss: 0.00012030063953716308
step: 30, loss: 0.0009146187803708017
step: 40, loss: 0.0024515618570148945
step: 50, loss: 0.0019089274574071169
step: 60, loss: 0.00015370073379017413
step: 70, loss: 0.0014567370526492596
step: 80, loss: 0.016678262501955032
step: 90, loss: 0.00017636803386267275
step: 100, loss: 6.223999662324786e-05
step: 110, loss: 0.00036374523187987506
step: 120, loss: 0.0770413875579834
step: 130, loss: 0.001917229383252561
step: 140, loss: 0.0003626015386544168
step: 150, loss: 0.01810876466333866
step: 160, loss: 5.8539641031529754e-05
step: 170, loss: 0.00010252355423290282
step: 180, loss: 0.006138812284916639
step: 190, loss: 0.07940657436847687
step: 200, loss: 0.0011278794845566154
step: 210, loss: 0.048262957483530045
step: 220, loss: 0.05943213403224945
step: 230, loss: 3.901002128259279e-05
step: 240, loss: 0.011416194960474968
step: 250, loss: 0.0030955530237406492
step: 260, loss: 0.00024351627507712692
step: 270, loss: 0.028645887970924377
step: 280, loss: 0.000596719968598336
step: 290, loss: 0.024082785472273827
step: 300, loss: 0.0005077249370515347
step: 310, loss: 0.00018257630290463567
step: 320, loss: 0.0016998139908537269
step: 330, loss: 0.006373348645865917
step: 340, loss: 0.021964222192764282
step: 350, loss: 0.0005928966565988958
step: 360, loss: 0.0001904818054754287
step: 370, loss: 0.10108712315559387
step: 380, loss: 0.002806709613651037
step: 390, loss: 0.017851000651717186
step: 400, loss: 0.005895718466490507
step: 410, loss: 0.0004456091264728457
step: 420, loss: 0.007664031349122524
epoch 15: dev_f1=0.7716535433070866, f1=0.6863157894736842, best_f1=0.6903765690376569
step: 0, loss: 0.017047598958015442
step: 10, loss: 0.0006785881123505533
step: 20, loss: 0.028092671185731888
step: 30, loss: 0.0011712400009855628
step: 40, loss: 5.7708217354957014e-05
step: 50, loss: 0.022808654233813286
step: 60, loss: 0.0005576554103754461
step: 70, loss: 0.014890307560563087
step: 80, loss: 0.0014278541784733534
step: 90, loss: 0.003916326444596052
step: 100, loss: 0.0001323363685514778
step: 110, loss: 0.0002544314775150269
step: 120, loss: 0.0018297333735972643
step: 130, loss: 7.438918692059815e-05
step: 140, loss: 0.0003435078833717853
step: 150, loss: 0.0002734878798946738
step: 160, loss: 6.27921981504187e-05
step: 170, loss: 0.0010147987632080913
step: 180, loss: 0.003656599437817931
step: 190, loss: 0.16378989815711975
step: 200, loss: 0.00047336608986370265
step: 210, loss: 0.0003692379395943135
step: 220, loss: 0.0004978023935109377
step: 230, loss: 0.003130019176751375
step: 240, loss: 0.03474147617816925
step: 250, loss: 0.00240763439796865
step: 260, loss: 0.000941923470236361
step: 270, loss: 0.03764714300632477
step: 280, loss: 0.0001146749418694526
step: 290, loss: 0.00013585580745711923
step: 300, loss: 0.00377963250502944
step: 310, loss: 0.0006632540025748312
step: 320, loss: 0.00023914662597235292
step: 330, loss: 0.08813667297363281
step: 340, loss: 0.22373206913471222
step: 350, loss: 0.019352594390511513
step: 360, loss: 0.06371685862541199
step: 370, loss: 0.008751222863793373
step: 380, loss: 0.00014165265019983053
step: 390, loss: 0.10238732397556305
step: 400, loss: 0.0186049472540617
step: 410, loss: 0.0007415410946123302
step: 420, loss: 0.001180557650513947
epoch 16: dev_f1=0.7554585152838428, f1=0.6697674418604652, best_f1=0.6903765690376569
step: 0, loss: 0.017008032649755478
step: 10, loss: 0.0004324979963712394
step: 20, loss: 0.00020237377611920238
step: 30, loss: 0.0002511543279979378
step: 40, loss: 0.0010664217406883836
step: 50, loss: 0.013933340087532997
step: 60, loss: 0.009924795478582382
step: 70, loss: 0.0001977421052288264
step: 80, loss: 0.0008862184477038682
step: 90, loss: 4.436605013324879e-05
step: 100, loss: 0.0013637011870741844
step: 110, loss: 0.02377602830529213
step: 120, loss: 0.0002696909650694579
step: 130, loss: 0.00022291092318482697
step: 140, loss: 0.00025887470110319555
step: 150, loss: 0.0003169716219417751
step: 160, loss: 0.015755491331219673
step: 170, loss: 0.01754002459347248
step: 180, loss: 0.0011702837655320764
step: 190, loss: 0.004211794584989548
step: 200, loss: 0.0036145588383078575
step: 210, loss: 0.033119261264801025
step: 220, loss: 0.00727413734421134
step: 230, loss: 0.0003797996323555708
step: 240, loss: 4.341674502938986e-05
step: 250, loss: 4.398503733682446e-05
step: 260, loss: 0.00010040926281362772
step: 270, loss: 0.00022749949130229652
step: 280, loss: 0.001169454539194703
step: 290, loss: 0.00013643043348565698
step: 300, loss: 8.087203605100513e-05
step: 310, loss: 0.001601922558620572
step: 320, loss: 0.0026362231001257896
step: 330, loss: 0.00024989410303533077
step: 340, loss: 0.00016722381405998021
step: 350, loss: 0.02190152369439602
step: 360, loss: 0.0002769323473330587
step: 370, loss: 0.001253079273737967
step: 380, loss: 0.0016976825427263975
step: 390, loss: 0.0010984678519889712
step: 400, loss: 0.0001461986976210028
step: 410, loss: 0.00019054787117056549
step: 420, loss: 0.015432214364409447
epoch 17: dev_f1=0.7660455486542443, f1=0.6695842450765865, best_f1=0.6903765690376569
step: 0, loss: 3.1921219488140196e-05
step: 10, loss: 0.00026735581923276186
step: 20, loss: 0.00022118895140010864
step: 30, loss: 5.629677252727561e-05
step: 40, loss: 0.008683905005455017
step: 50, loss: 0.0017676542047411203
step: 60, loss: 0.019401418045163155
step: 70, loss: 4.735259062726982e-05
step: 80, loss: 0.0003638525668065995
step: 90, loss: 0.00012715272896457464
step: 100, loss: 6.131800182629377e-05
step: 110, loss: 0.0009796556551009417
step: 120, loss: 0.0002721423516049981
step: 130, loss: 0.0010815334971994162
step: 140, loss: 0.09647228568792343
step: 150, loss: 3.64384068234358e-05
step: 160, loss: 0.00016197959484998137
step: 170, loss: 0.024118974804878235
step: 180, loss: 0.0006968032685108483
step: 190, loss: 0.0015223452355712652
step: 200, loss: 0.00024874001974239945
step: 210, loss: 0.0007508575799874961
step: 220, loss: 0.004853085149079561
step: 230, loss: 0.00025940395426005125
step: 240, loss: 6.25586326350458e-05
step: 250, loss: 0.0001770250964909792
step: 260, loss: 0.00042316995677538216
step: 270, loss: 0.0008072804776020348
step: 280, loss: 7.82825518399477e-05
step: 290, loss: 6.075625424273312e-05
step: 300, loss: 0.00020360980124678463
step: 310, loss: 4.3060266762040555e-05
step: 320, loss: 6.793598004151136e-05
step: 330, loss: 0.000715629430487752
step: 340, loss: 0.0014641229063272476
step: 350, loss: 0.0018983734771609306
step: 360, loss: 0.000130576197989285
step: 370, loss: 0.00030821681139059365
step: 380, loss: 0.00012560552568174899
step: 390, loss: 0.00018480831931810826
step: 400, loss: 0.0026042216923087835
step: 410, loss: 0.02598610147833824
step: 420, loss: 3.883804311044514e-05
epoch 18: dev_f1=0.772635814889336, f1=0.6822033898305084, best_f1=0.6903765690376569
step: 0, loss: 0.00010269526683259755
step: 10, loss: 0.00038453564047813416
step: 20, loss: 0.005480627063661814
step: 30, loss: 0.009526924230158329
step: 40, loss: 0.00013320475409273058
step: 50, loss: 0.012239000760018826
step: 60, loss: 0.016310961917042732
step: 70, loss: 8.812410669634119e-05
step: 80, loss: 5.1792841986753047e-05
step: 90, loss: 9.820343257160857e-05
step: 100, loss: 0.00043333336361683905
step: 110, loss: 0.0002689283574000001
step: 120, loss: 0.00035057379864156246
step: 130, loss: 0.00016814203991089016
step: 140, loss: 0.0003649195423349738
step: 150, loss: 0.009896338917315006
step: 160, loss: 8.203744073398411e-05
step: 170, loss: 0.0019463979406282306
step: 180, loss: 0.00017921763355843723
step: 190, loss: 0.0003749114111997187
step: 200, loss: 4.49631224910263e-05
step: 210, loss: 6.697525532217696e-05
step: 220, loss: 7.012147398199886e-05
step: 230, loss: 0.00014456828648690134
step: 240, loss: 0.00021882777218706906
step: 250, loss: 0.00029866970726288855
step: 260, loss: 3.931511309929192e-05
step: 270, loss: 0.00017886115529108793
step: 280, loss: 0.003156601684167981
step: 290, loss: 0.00023059526574797928
step: 300, loss: 0.017955800518393517
step: 310, loss: 0.015380979515612125
step: 320, loss: 0.0014292120467871428
step: 330, loss: 9.68989115790464e-05
step: 340, loss: 0.07217296212911606
step: 350, loss: 8.769665873842314e-05
step: 360, loss: 0.0004019848129246384
step: 370, loss: 0.00027144060004502535
step: 380, loss: 7.544018444605172e-05
step: 390, loss: 0.00014953875506762415
step: 400, loss: 0.0009387446334585547
step: 410, loss: 6.820177804911509e-05
step: 420, loss: 3.470699812169187e-05
epoch 19: dev_f1=0.7743271221532092, f1=0.685589519650655, best_f1=0.6903765690376569
step: 0, loss: 4.921346771880053e-05
step: 10, loss: 0.0018706697737798095
step: 20, loss: 0.0001309380604652688
step: 30, loss: 0.029913457110524178
step: 40, loss: 0.0008953424403443933
step: 50, loss: 0.0005485101137310266
step: 60, loss: 7.832206756575033e-05
step: 70, loss: 0.0016395441489294171
step: 80, loss: 4.3519936298253015e-05
step: 90, loss: 0.011749442666769028
step: 100, loss: 0.00032505259150639176
step: 110, loss: 0.0013234178768470883
step: 120, loss: 6.657675112364814e-05
step: 130, loss: 8.15201856312342e-05
step: 140, loss: 0.00030921268626116216
step: 150, loss: 4.551087840809487e-05
step: 160, loss: 0.016939885914325714
step: 170, loss: 0.00020712154218927026
step: 180, loss: 0.0003307368606328964
step: 190, loss: 5.70071060792543e-05
step: 200, loss: 8.862543472787365e-05
step: 210, loss: 0.0005511356284841895
step: 220, loss: 0.001865703845396638
step: 230, loss: 0.0012431751238182187
step: 240, loss: 0.00020106563169974834
step: 250, loss: 4.966259439243004e-05
step: 260, loss: 0.0004993327311240137
step: 270, loss: 6.659574864897877e-05
step: 280, loss: 7.911837019491941e-05
step: 290, loss: 5.7656703575048596e-05
step: 300, loss: 0.023793993517756462
step: 310, loss: 0.003878246294334531
step: 320, loss: 7.71934210206382e-05
step: 330, loss: 0.0001418837928213179
step: 340, loss: 5.067472375230864e-05
step: 350, loss: 6.350323383230716e-05
step: 360, loss: 5.973460793029517e-05
step: 370, loss: 0.00026904544210992754
step: 380, loss: 0.00029200883000157773
step: 390, loss: 0.024359727278351784
step: 400, loss: 9.426600445294753e-05
step: 410, loss: 0.0028369370847940445
step: 420, loss: 0.0013633174821734428
epoch 20: dev_f1=0.7732793522267206, f1=0.6794871794871795, best_f1=0.6903765690376569
