cuda
Device: cuda
step: 0, loss: 0.5339785218238831
step: 10, loss: 0.24232837557792664
step: 20, loss: 0.29121705889701843
step: 30, loss: 0.3039712607860565
step: 40, loss: 0.2683494985103607
step: 50, loss: 0.41009795665740967
step: 60, loss: 0.3336193263530731
step: 70, loss: 0.13599282503128052
step: 80, loss: 0.20120185613632202
step: 90, loss: 0.2036847323179245
step: 100, loss: 0.29717087745666504
step: 110, loss: 0.3048274517059326
step: 120, loss: 0.45805954933166504
step: 130, loss: 0.3712153136730194
step: 140, loss: 0.5036078691482544
step: 150, loss: 0.13630987703800201
step: 160, loss: 0.22961187362670898
step: 170, loss: 0.26838552951812744
step: 180, loss: 0.3825714588165283
step: 190, loss: 0.30882927775382996
step: 200, loss: 0.2665387988090515
step: 210, loss: 0.21567083895206451
step: 220, loss: 0.2892117202281952
step: 230, loss: 0.07226616889238358
step: 240, loss: 0.11291924864053726
step: 250, loss: 0.11467497795820236
step: 260, loss: 0.2656908929347992
step: 270, loss: 0.09852119535207748
step: 280, loss: 0.2030051350593567
step: 290, loss: 0.22227948904037476
step: 300, loss: 0.33260223269462585
step: 310, loss: 0.17205679416656494
step: 320, loss: 0.19861172139644623
step: 330, loss: 0.25371432304382324
step: 340, loss: 0.2785806357860565
step: 350, loss: 0.15297554433345795
step: 360, loss: 0.08023598790168762
step: 370, loss: 0.26467737555503845
step: 380, loss: 0.20185481011867523
step: 390, loss: 0.23099510371685028
step: 400, loss: 0.16091029345989227
step: 410, loss: 0.14807970821857452
step: 420, loss: 0.11456906795501709
epoch 1: dev_f1=0.6769230769230768, f1=0.6307692307692306, best_f1=0.6307692307692306
step: 0, loss: 0.3337102234363556
step: 10, loss: 0.34006357192993164
step: 20, loss: 0.172477126121521
step: 30, loss: 0.2446977198123932
step: 40, loss: 0.14914493262767792
step: 50, loss: 0.053274523466825485
step: 60, loss: 0.16460548341274261
step: 70, loss: 0.28878799080848694
step: 80, loss: 0.2694512903690338
step: 90, loss: 0.14086391031742096
step: 100, loss: 0.2993260622024536
step: 110, loss: 0.18018938601016998
step: 120, loss: 0.14250680804252625
step: 130, loss: 0.02516184188425541
step: 140, loss: 0.4330446720123291
step: 150, loss: 0.09954140335321426
step: 160, loss: 0.21528278291225433
step: 170, loss: 0.07325957715511322
step: 180, loss: 0.2594960033893585
step: 190, loss: 0.2021164745092392
step: 200, loss: 0.17434562742710114
step: 210, loss: 0.214040145277977
step: 220, loss: 0.1010575070977211
step: 230, loss: 0.15784087777137756
step: 240, loss: 0.16396969556808472
step: 250, loss: 0.11431720107793808
step: 260, loss: 0.11225821077823639
step: 270, loss: 0.03336597979068756
step: 280, loss: 0.20103631913661957
step: 290, loss: 0.19469670951366425
step: 300, loss: 0.12531401216983795
step: 310, loss: 0.069978266954422
step: 320, loss: 0.349960058927536
step: 330, loss: 0.03212197870016098
step: 340, loss: 0.11996573954820633
step: 350, loss: 0.12473892420530319
step: 360, loss: 0.2936423420906067
step: 370, loss: 0.36953625082969666
step: 380, loss: 0.16562515497207642
step: 390, loss: 0.39752206206321716
step: 400, loss: 0.17578548192977905
step: 410, loss: 0.17481660842895508
step: 420, loss: 0.35956892371177673
epoch 2: dev_f1=0.7204724409448819, f1=0.6474226804123712, best_f1=0.6474226804123712
step: 0, loss: 0.1433253139257431
step: 10, loss: 0.18532712757587433
step: 20, loss: 0.13070838153362274
step: 30, loss: 0.08204050362110138
step: 40, loss: 0.15987628698349
step: 50, loss: 0.06230682134628296
step: 60, loss: 0.05298492684960365
step: 70, loss: 0.204863503575325
step: 80, loss: 0.051125071942806244
step: 90, loss: 0.1539641171693802
step: 100, loss: 0.11608798801898956
step: 110, loss: 0.10565993189811707
step: 120, loss: 0.050508104264736176
step: 130, loss: 0.1514672189950943
step: 140, loss: 0.09978067874908447
step: 150, loss: 0.26354125142097473
step: 160, loss: 0.2877080738544464
step: 170, loss: 0.3659437894821167
step: 180, loss: 0.2686968743801117
step: 190, loss: 0.19897374510765076
step: 200, loss: 0.1385061889886856
step: 210, loss: 0.258265882730484
step: 220, loss: 0.18226462602615356
step: 230, loss: 0.03686356171965599
step: 240, loss: 0.09854741394519806
step: 250, loss: 0.0807420015335083
step: 260, loss: 0.07782045006752014
step: 270, loss: 0.24473033845424652
step: 280, loss: 0.32236745953559875
step: 290, loss: 0.04678715765476227
step: 300, loss: 0.09880174696445465
step: 310, loss: 0.3443445861339569
step: 320, loss: 0.04821804165840149
step: 330, loss: 0.11145330220460892
step: 340, loss: 0.30502134561538696
step: 350, loss: 0.02682332508265972
step: 360, loss: 0.13246412575244904
step: 370, loss: 0.17927050590515137
step: 380, loss: 0.07510498911142349
step: 390, loss: 0.06538145244121552
step: 400, loss: 0.11518603563308716
step: 410, loss: 0.10069577395915985
step: 420, loss: 0.06058458611369133
epoch 3: dev_f1=0.7362204724409449, f1=0.6265060240963856, best_f1=0.6265060240963856
step: 0, loss: 0.19611616432666779
step: 10, loss: 0.14041908085346222
step: 20, loss: 0.16664619743824005
step: 30, loss: 0.11188165098428726
step: 40, loss: 0.02905726619064808
step: 50, loss: 0.08178691565990448
step: 60, loss: 0.09158946573734283
step: 70, loss: 0.21441318094730377
step: 80, loss: 0.01679343543946743
step: 90, loss: 0.11199704557657242
step: 100, loss: 0.03263605758547783
step: 110, loss: 0.13442422449588776
step: 120, loss: 0.06730206310749054
step: 130, loss: 0.04815636947751045
step: 140, loss: 0.01947183720767498
step: 150, loss: 0.03201819583773613
step: 160, loss: 0.07090763002634048
step: 170, loss: 0.18362265825271606
step: 180, loss: 0.1807059347629547
step: 190, loss: 0.11610730737447739
step: 200, loss: 0.013021302409470081
step: 210, loss: 0.08432620763778687
step: 220, loss: 0.06220963969826698
step: 230, loss: 0.02716856263577938
step: 240, loss: 0.11181847751140594
step: 250, loss: 0.1406993716955185
step: 260, loss: 0.05627429485321045
step: 270, loss: 0.04948374256491661
step: 280, loss: 0.06791343539953232
step: 290, loss: 0.07254792749881744
step: 300, loss: 0.07689644396305084
step: 310, loss: 0.11634206026792526
step: 320, loss: 0.28605887293815613
step: 330, loss: 0.0360569953918457
step: 340, loss: 0.02505652792751789
step: 350, loss: 0.13112743198871613
step: 360, loss: 0.24150162935256958
step: 370, loss: 0.11536473035812378
step: 380, loss: 0.10932889580726624
step: 390, loss: 0.1389441192150116
step: 400, loss: 0.03195248171687126
step: 410, loss: 0.1744770109653473
step: 420, loss: 0.09980138391256332
epoch 4: dev_f1=0.7474747474747474, f1=0.6833333333333332, best_f1=0.6833333333333332
step: 0, loss: 0.016703343018889427
step: 10, loss: 0.2742963433265686
step: 20, loss: 0.10541631281375885
step: 30, loss: 0.015351238660514355
step: 40, loss: 0.025235140696167946
step: 50, loss: 0.05093659088015556
step: 60, loss: 0.011265221051871777
step: 70, loss: 0.06152070313692093
step: 80, loss: 0.07102750986814499
step: 90, loss: 0.0958012118935585
step: 100, loss: 0.05735631287097931
step: 110, loss: 0.15173476934432983
step: 120, loss: 0.052192363888025284
step: 130, loss: 0.1392802745103836
step: 140, loss: 0.07000330835580826
step: 150, loss: 0.008057829923927784
step: 160, loss: 0.10867678374052048
step: 170, loss: 0.03192979842424393
step: 180, loss: 0.04800371453166008
step: 190, loss: 0.051664505153894424
step: 200, loss: 0.02288750186562538
step: 210, loss: 0.054450321942567825
step: 220, loss: 0.04236414283514023
step: 230, loss: 0.09444767236709595
step: 240, loss: 0.10384167730808258
step: 250, loss: 0.15717151761054993
step: 260, loss: 0.09764304012060165
step: 270, loss: 0.02300267294049263
step: 280, loss: 0.030984262004494667
step: 290, loss: 0.19290046393871307
step: 300, loss: 0.1950976550579071
step: 310, loss: 0.12165248394012451
step: 320, loss: 0.01765706017613411
step: 330, loss: 0.027334587648510933
step: 340, loss: 0.010425078682601452
step: 350, loss: 0.09168759733438492
step: 360, loss: 0.026690367609262466
step: 370, loss: 0.0773468092083931
step: 380, loss: 0.10402865707874298
step: 390, loss: 0.19953873753547668
step: 400, loss: 0.023220552131533623
step: 410, loss: 0.10810606181621552
step: 420, loss: 0.06125013902783394
epoch 5: dev_f1=0.7551867219917012, f1=0.6865671641791045, best_f1=0.6865671641791045
step: 0, loss: 0.008382384665310383
step: 10, loss: 0.02702845074236393
step: 20, loss: 0.06360705196857452
step: 30, loss: 0.036944422870874405
step: 40, loss: 0.01676349714398384
step: 50, loss: 0.0026172641664743423
step: 60, loss: 0.03839435428380966
step: 70, loss: 0.01149055641144514
step: 80, loss: 0.04542435333132744
step: 90, loss: 0.08059517294168472
step: 100, loss: 0.05445920303463936
step: 110, loss: 0.020823506638407707
step: 120, loss: 0.010163278318941593
step: 130, loss: 0.014864914119243622
step: 140, loss: 0.005469425115734339
step: 150, loss: 0.024815477430820465
step: 160, loss: 0.01752251572906971
step: 170, loss: 0.2888600528240204
step: 180, loss: 0.029507696628570557
step: 190, loss: 0.07315737754106522
step: 200, loss: 0.012716369703412056
step: 210, loss: 0.08573267608880997
step: 220, loss: 0.05991438031196594
step: 230, loss: 0.21235087513923645
step: 240, loss: 0.01181946974247694
step: 250, loss: 0.15276753902435303
step: 260, loss: 0.03150371089577675
step: 270, loss: 0.07431706041097641
step: 280, loss: 0.012655518017709255
step: 290, loss: 0.0765693411231041
step: 300, loss: 0.025371117517352104
step: 310, loss: 0.042927179485559464
step: 320, loss: 0.008345109410583973
step: 330, loss: 0.05310502275824547
step: 340, loss: 0.18918476998806
step: 350, loss: 0.07965310662984848
step: 360, loss: 0.13868747651576996
step: 370, loss: 0.07542748004198074
step: 380, loss: 0.04698670655488968
step: 390, loss: 0.10124222934246063
step: 400, loss: 0.0013220086693763733
step: 410, loss: 0.030958933755755424
step: 420, loss: 0.07484882324934006
epoch 6: dev_f1=0.7563025210084033, f1=0.6475770925110133, best_f1=0.6475770925110133
step: 0, loss: 0.004515007603913546
step: 10, loss: 0.000811222882475704
step: 20, loss: 0.012548351660370827
step: 30, loss: 0.029600296169519424
step: 40, loss: 0.007964576594531536
step: 50, loss: 0.011815760284662247
step: 60, loss: 0.001700567896477878
step: 70, loss: 0.0829843059182167
step: 80, loss: 0.06731577962636948
step: 90, loss: 0.022379793226718903
step: 100, loss: 0.062196556478738785
step: 110, loss: 0.034993380308151245
step: 120, loss: 0.029385803267359734
step: 130, loss: 0.060350023210048676
step: 140, loss: 0.019549904391169548
step: 150, loss: 0.04371299594640732
step: 160, loss: 0.002969170454889536
step: 170, loss: 0.0937570184469223
step: 180, loss: 0.0846557468175888
step: 190, loss: 0.019882796332240105
step: 200, loss: 0.020936688408255577
step: 210, loss: 0.04513552412390709
step: 220, loss: 0.013691483996808529
step: 230, loss: 0.022476926445961
step: 240, loss: 0.007010271307080984
step: 250, loss: 0.1509890854358673
step: 260, loss: 0.021189352497458458
step: 270, loss: 0.05020216852426529
step: 280, loss: 0.007846563123166561
step: 290, loss: 0.0008668953087180853
step: 300, loss: 0.061656735837459564
step: 310, loss: 0.05845114588737488
step: 320, loss: 0.012006275355815887
step: 330, loss: 0.01606239192187786
step: 340, loss: 0.10827659070491791
step: 350, loss: 0.03080710954964161
step: 360, loss: 0.10256650298833847
step: 370, loss: 0.010877607390284538
step: 380, loss: 0.10109449923038483
step: 390, loss: 0.0026522197294980288
step: 400, loss: 0.08777125924825668
step: 410, loss: 0.0171612948179245
step: 420, loss: 0.0021486016921699047
epoch 7: dev_f1=0.7532467532467534, f1=0.6545454545454545, best_f1=0.6475770925110133
step: 0, loss: 0.028369029983878136
step: 10, loss: 0.004085507709532976
step: 20, loss: 0.011802571825683117
step: 30, loss: 0.0660426914691925
step: 40, loss: 0.011678658425807953
step: 50, loss: 0.023109806701540947
step: 60, loss: 0.002740486292168498
step: 70, loss: 0.030986474826931953
step: 80, loss: 0.009682005271315575
step: 90, loss: 0.022275462746620178
step: 100, loss: 0.09133340418338776
step: 110, loss: 0.04697399586439133
step: 120, loss: 0.0013392558321356773
step: 130, loss: 0.0019493126310408115
step: 140, loss: 0.0004174294590484351
step: 150, loss: 0.02559784986078739
step: 160, loss: 0.0011282478226348758
step: 170, loss: 0.0451933927834034
step: 180, loss: 0.00238654762506485
step: 190, loss: 0.0004385746724437922
step: 200, loss: 0.01775168813765049
step: 210, loss: 0.016235612332820892
step: 220, loss: 0.07172606885433197
step: 230, loss: 0.003970343619585037
step: 240, loss: 0.10943026095628738
step: 250, loss: 0.004928248934447765
step: 260, loss: 0.012494193390011787
step: 270, loss: 0.004375537857413292
step: 280, loss: 0.0026757528539747
step: 290, loss: 0.01997259631752968
step: 300, loss: 0.026059862226247787
step: 310, loss: 0.02256903424859047
step: 320, loss: 0.0009573411662131548
step: 330, loss: 0.03296366706490517
step: 340, loss: 0.013204230926930904
step: 350, loss: 0.0035010757856070995
step: 360, loss: 0.007488177623599768
step: 370, loss: 0.019654912874102592
step: 380, loss: 0.006369057111442089
step: 390, loss: 0.008051878772675991
step: 400, loss: 0.07997618615627289
step: 410, loss: 0.0025925221852958202
step: 420, loss: 0.0027354182675480843
epoch 8: dev_f1=0.7470355731225297, f1=0.6457023060796646, best_f1=0.6475770925110133
step: 0, loss: 0.033016789704561234
step: 10, loss: 0.014010293409228325
step: 20, loss: 0.023753158748149872
step: 30, loss: 0.023545920848846436
step: 40, loss: 0.008593159727752209
step: 50, loss: 0.058902811259031296
step: 60, loss: 0.001013297471217811
step: 70, loss: 0.08875613659620285
step: 80, loss: 0.0002041395055130124
step: 90, loss: 0.0075813522562384605
step: 100, loss: 0.0062299626879394054
step: 110, loss: 0.005346730817109346
step: 120, loss: 0.0378224216401577
step: 130, loss: 0.0580996610224247
step: 140, loss: 0.003228358691558242
step: 150, loss: 0.007316893432289362
step: 160, loss: 0.0010885754600167274
step: 170, loss: 0.00042154063703492284
step: 180, loss: 0.01953071728348732
step: 190, loss: 0.059426479041576385
step: 200, loss: 0.06242932006716728
step: 210, loss: 0.022443244233727455
step: 220, loss: 0.0006162606296129525
step: 230, loss: 0.006288948468863964
step: 240, loss: 0.03457000106573105
step: 250, loss: 0.0028053626883774996
step: 260, loss: 0.007453561294823885
step: 270, loss: 0.005873617250472307
step: 280, loss: 0.00028662345721386373
step: 290, loss: 0.0010176175273954868
step: 300, loss: 0.007502763532102108
step: 310, loss: 0.020203478634357452
step: 320, loss: 0.11296723037958145
step: 330, loss: 0.03890528529882431
step: 340, loss: 0.02246527373790741
step: 350, loss: 0.05691903084516525
step: 360, loss: 0.01711984910070896
step: 370, loss: 0.015080238692462444
step: 380, loss: 0.029303792864084244
step: 390, loss: 0.046518437564373016
step: 400, loss: 0.0035619051195681095
step: 410, loss: 0.005733024328947067
step: 420, loss: 0.03345021978020668
epoch 9: dev_f1=0.7159090909090908, f1=0.6551724137931033, best_f1=0.6475770925110133
step: 0, loss: 0.11487716436386108
step: 10, loss: 0.006553903222084045
step: 20, loss: 0.032493945211172104
step: 30, loss: 0.020736506208777428
step: 40, loss: 0.03225744143128395
step: 50, loss: 0.19388440251350403
step: 60, loss: 0.014840238727629185
step: 70, loss: 0.053580205887556076
step: 80, loss: 0.026503797620534897
step: 90, loss: 0.006392321083694696
step: 100, loss: 0.008272724226117134
step: 110, loss: 0.008004656992852688
step: 120, loss: 0.14058290421962738
step: 130, loss: 0.0008853691979311407
step: 140, loss: 0.017475947737693787
step: 150, loss: 0.017776167020201683
step: 160, loss: 0.031609077006578445
step: 170, loss: 0.0996142104268074
step: 180, loss: 0.015486212447285652
step: 190, loss: 0.020166920498013496
step: 200, loss: 0.011319566518068314
step: 210, loss: 0.005157992709428072
step: 220, loss: 0.009546573273837566
step: 230, loss: 0.023983987048268318
step: 240, loss: 0.021071381866931915
step: 250, loss: 0.026791339740157127
step: 260, loss: 0.027719290927052498
step: 270, loss: 0.05687808617949486
step: 280, loss: 0.09604863822460175
step: 290, loss: 0.030979963019490242
step: 300, loss: 0.030656354501843452
step: 310, loss: 0.007518616504967213
step: 320, loss: 0.011826787143945694
step: 330, loss: 0.05479965731501579
step: 340, loss: 0.0634070634841919
step: 350, loss: 0.00457394402474165
step: 360, loss: 0.012441818602383137
step: 370, loss: 0.00026144320145249367
step: 380, loss: 0.0035093785263597965
step: 390, loss: 0.01948043331503868
step: 400, loss: 0.007324249483644962
step: 410, loss: 0.10704022645950317
step: 420, loss: 0.005809939932078123
epoch 10: dev_f1=0.7558386411889596, f1=0.6591928251121076, best_f1=0.6475770925110133
step: 0, loss: 0.0003987392701674253
step: 10, loss: 0.005311025306582451
step: 20, loss: 0.020183060318231583
step: 30, loss: 0.041292496025562286
step: 40, loss: 0.0005375454784370959
step: 50, loss: 0.0034854330588132143
step: 60, loss: 0.0036975087132304907
step: 70, loss: 0.006487122271209955
step: 80, loss: 0.0183047316968441
step: 90, loss: 0.021149132400751114
step: 100, loss: 0.0036943177692592144
step: 110, loss: 0.011204364709556103
step: 120, loss: 0.000988753861747682
step: 130, loss: 0.051391903311014175
step: 140, loss: 0.011058993637561798
step: 150, loss: 0.014385518617928028
step: 160, loss: 0.05739728361368179
step: 170, loss: 0.0033180222380906343
step: 180, loss: 0.02797972597181797
step: 190, loss: 0.005376940127462149
step: 200, loss: 0.002046014182269573
step: 210, loss: 0.0010675645899027586
step: 220, loss: 0.007324109319597483
step: 230, loss: 0.00019575054466258734
step: 240, loss: 0.03920760378241539
step: 250, loss: 0.0050845080986619
step: 260, loss: 0.01742207258939743
step: 270, loss: 0.11210452765226364
step: 280, loss: 0.0026511133182793856
step: 290, loss: 0.0027377246879041195
step: 300, loss: 0.0004559931985568255
step: 310, loss: 0.027667293325066566
step: 320, loss: 0.0007436007144860923
step: 330, loss: 0.00010634824866428971
step: 340, loss: 0.0006461270386353135
step: 350, loss: 0.0382818840444088
step: 360, loss: 0.00012469095236156136
step: 370, loss: 0.001081885420717299
step: 380, loss: 0.008224540390074253
step: 390, loss: 0.004595862701535225
step: 400, loss: 0.0023096187505871058
step: 410, loss: 0.0008317727479152381
step: 420, loss: 0.05108124017715454
epoch 11: dev_f1=0.7449392712550607, f1=0.6608315098468271, best_f1=0.6475770925110133
step: 0, loss: 0.00031597763882018626
step: 10, loss: 0.019546905532479286
step: 20, loss: 0.0004313684185035527
step: 30, loss: 0.0004629037866834551
step: 40, loss: 0.03811967745423317
step: 50, loss: 0.01766270399093628
step: 60, loss: 0.046309586614370346
step: 70, loss: 0.005222987849265337
step: 80, loss: 0.00014985371672082692
step: 90, loss: 0.008719006553292274
step: 100, loss: 0.0026334398426115513
step: 110, loss: 0.027318861335515976
step: 120, loss: 0.0158295389264822
step: 130, loss: 0.0004884283407591283
step: 140, loss: 0.10782051086425781
step: 150, loss: 0.0003985844668932259
step: 160, loss: 0.011941426433622837
step: 170, loss: 0.014620577916502953
step: 180, loss: 0.00015182376955635846
step: 190, loss: 0.0006612765719182789
step: 200, loss: 0.005928767379373312
step: 210, loss: 0.0005763908266089857
step: 220, loss: 0.02053350955247879
step: 230, loss: 0.006485146004706621
step: 240, loss: 0.00019117529154755175
step: 250, loss: 0.0003313977213110775
step: 260, loss: 0.10393583029508591
step: 270, loss: 0.005112011451274157
step: 280, loss: 0.0007825454231351614
step: 290, loss: 0.01221194863319397
step: 300, loss: 0.07179112732410431
step: 310, loss: 0.00924462080001831
step: 320, loss: 0.005971185397356749
step: 330, loss: 0.00023597496328875422
step: 340, loss: 0.004403062164783478
step: 350, loss: 0.020739609375596046
step: 360, loss: 0.025979911908507347
step: 370, loss: 0.00020783809304703027
step: 380, loss: 0.07801295816898346
step: 390, loss: 0.0015486713964492083
step: 400, loss: 0.004834173247218132
step: 410, loss: 0.03174172341823578
step: 420, loss: 0.0030285895336419344
epoch 12: dev_f1=0.757085020242915, f1=0.6493506493506495, best_f1=0.6493506493506495
step: 0, loss: 0.032015904784202576
step: 10, loss: 0.0005885415012016892
step: 20, loss: 0.03530721366405487
step: 30, loss: 0.017997782677412033
step: 40, loss: 0.0010987627319991589
step: 50, loss: 0.024209104478359222
step: 60, loss: 0.018715139478445053
step: 70, loss: 0.008292178623378277
step: 80, loss: 0.000149756291648373
step: 90, loss: 0.000511669204570353
step: 100, loss: 0.0008702572667971253
step: 110, loss: 0.00014216604176908731
step: 120, loss: 7.466693932656199e-05
step: 130, loss: 0.0005069717299193144
step: 140, loss: 0.008580910973250866
step: 150, loss: 6.710031448164955e-05
step: 160, loss: 0.0010861955815926194
step: 170, loss: 0.03129114583134651
step: 180, loss: 0.00031511724228039384
step: 190, loss: 0.0004518736095633358
step: 200, loss: 0.0006486995262093842
step: 210, loss: 0.0023538703098893166
step: 220, loss: 0.005042846314609051
step: 230, loss: 0.06797440350055695
step: 240, loss: 0.0004637670936062932
step: 250, loss: 0.0014643234899267554
step: 260, loss: 0.008536639623343945
step: 270, loss: 0.0036247335374355316
step: 280, loss: 0.00970324594527483
step: 290, loss: 6.792804197175428e-05
step: 300, loss: 0.0030191964469850063
step: 310, loss: 0.007084670942276716
step: 320, loss: 0.00018796586664393544
step: 330, loss: 0.00016876166046131402
step: 340, loss: 0.00010072004806715995
step: 350, loss: 0.00021039004786871374
step: 360, loss: 0.0004028801340609789
step: 370, loss: 6.077003126847558e-05
step: 380, loss: 0.002377606462687254
step: 390, loss: 0.00739168468862772
step: 400, loss: 0.002250388730317354
step: 410, loss: 0.00026757654268294573
step: 420, loss: 0.0009055256959982216
epoch 13: dev_f1=0.7547169811320754, f1=0.6561797752808989, best_f1=0.6493506493506495
step: 0, loss: 0.0005098478868603706
step: 10, loss: 0.03207800164818764
step: 20, loss: 0.001846585888415575
step: 30, loss: 0.00887683592736721
step: 40, loss: 0.03481932356953621
step: 50, loss: 0.028962837532162666
step: 60, loss: 0.03956969082355499
step: 70, loss: 7.15442729415372e-05
step: 80, loss: 0.00020566534658428282
step: 90, loss: 0.003614241722971201
step: 100, loss: 0.00039446036680601537
step: 110, loss: 0.00018186375382356346
step: 120, loss: 0.00752357579767704
step: 130, loss: 0.0009980738395825028
step: 140, loss: 0.0009456299594603479
step: 150, loss: 4.5654709538212046e-05
step: 160, loss: 0.0005571416695602238
step: 170, loss: 0.010072475299239159
step: 180, loss: 0.03003411367535591
step: 190, loss: 4.417972741066478e-05
step: 200, loss: 0.01577056385576725
step: 210, loss: 0.03853851929306984
step: 220, loss: 0.004479710943996906
step: 230, loss: 0.03362507000565529
step: 240, loss: 6.915080302860588e-05
step: 250, loss: 0.011989420279860497
step: 260, loss: 0.017135806381702423
step: 270, loss: 0.013306967914104462
step: 280, loss: 0.018986843526363373
step: 290, loss: 0.07331785559654236
step: 300, loss: 0.0008853618055582047
step: 310, loss: 7.209310570033267e-05
step: 320, loss: 0.005342369433492422
step: 330, loss: 0.002890676259994507
step: 340, loss: 0.3037310838699341
step: 350, loss: 0.0005637333961203694
step: 360, loss: 0.12267918884754181
step: 370, loss: 0.0017773599829524755
step: 380, loss: 0.00043807420297525823
step: 390, loss: 0.00011989156337222084
step: 400, loss: 0.008525710552930832
step: 410, loss: 0.026589395478367805
step: 420, loss: 0.016704324632883072
epoch 14: dev_f1=0.7499999999999999, f1=0.6583333333333333, best_f1=0.6493506493506495
step: 0, loss: 0.06059635803103447
step: 10, loss: 0.010284900665283203
step: 20, loss: 0.04723294824361801
step: 30, loss: 0.00033053476363420486
step: 40, loss: 0.0009432733058929443
step: 50, loss: 8.421301754424348e-05
step: 60, loss: 0.0009476319537498057
step: 70, loss: 0.00030476029496639967
step: 80, loss: 0.0007097331108525395
step: 90, loss: 9.932821558322757e-05
step: 100, loss: 0.00016147323185577989
step: 110, loss: 0.017461923882365227
step: 120, loss: 0.0013874542200937867
step: 130, loss: 0.0016060118796303868
step: 140, loss: 0.010403187945485115
step: 150, loss: 0.007417893968522549
step: 160, loss: 0.00017474795458838344
step: 170, loss: 0.00012966137728653848
step: 180, loss: 5.9524387324927375e-05
step: 190, loss: 0.11238449066877365
step: 200, loss: 0.02761155180633068
step: 210, loss: 0.0011986404424533248
step: 220, loss: 0.0006039972649887204
step: 230, loss: 0.20310993492603302
step: 240, loss: 0.00022466806694865227
step: 250, loss: 0.002544925780966878
step: 260, loss: 6.920933810761198e-05
step: 270, loss: 0.032414816319942474
step: 280, loss: 0.004773886874318123
step: 290, loss: 0.01827039010822773
step: 300, loss: 0.0028429857920855284
step: 310, loss: 0.0002586775226518512
step: 320, loss: 8.118536788970232e-05
step: 330, loss: 0.022857243195176125
step: 340, loss: 0.00036050521885044873
step: 350, loss: 0.012703013606369495
step: 360, loss: 0.0009535368881188333
step: 370, loss: 0.03565465658903122
step: 380, loss: 0.00039681338239461184
step: 390, loss: 0.05391967296600342
step: 400, loss: 0.000652382499538362
step: 410, loss: 0.0003094815765507519
step: 420, loss: 0.050100866705179214
epoch 15: dev_f1=0.7531380753138075, f1=0.6487695749440716, best_f1=0.6493506493506495
step: 0, loss: 0.0001056501641869545
step: 10, loss: 0.00019702086865436286
step: 20, loss: 0.024415653198957443
step: 30, loss: 0.0024645051453262568
step: 40, loss: 9.219321509590372e-05
step: 50, loss: 0.0013607597211375833
step: 60, loss: 0.010972738265991211
step: 70, loss: 0.0014833470340818167
step: 80, loss: 0.0007794441771693528
step: 90, loss: 8.132792572723702e-05
step: 100, loss: 0.0005529080517590046
step: 110, loss: 9.247117122868076e-05
step: 120, loss: 0.0031022964976727962
step: 130, loss: 0.027962306514382362
step: 140, loss: 0.0013882319908589125
step: 150, loss: 0.00026905687991529703
step: 160, loss: 0.00011094014189438894
step: 170, loss: 0.00010811001993715763
step: 180, loss: 0.0001602215925231576
step: 190, loss: 0.000867463240865618
step: 200, loss: 0.0014428315917029977
step: 210, loss: 0.0009388340404257178
step: 220, loss: 0.0029513919726014137
step: 230, loss: 0.0001831124391173944
step: 240, loss: 0.013589327223598957
step: 250, loss: 0.001804187661036849
step: 260, loss: 0.004497325513511896
step: 270, loss: 0.0004139213706366718
step: 280, loss: 0.0006227307021617889
step: 290, loss: 3.946043943869881e-05
step: 300, loss: 0.001712287892587483
step: 310, loss: 0.0034258211962878704
step: 320, loss: 0.0006147162057459354
step: 330, loss: 0.00018740024825092405
step: 340, loss: 0.00011797792103607208
step: 350, loss: 0.000521957001183182
step: 360, loss: 0.0006071790703572333
step: 370, loss: 0.00013762213347945362
step: 380, loss: 0.03834981098771095
step: 390, loss: 0.00044314592378214
step: 400, loss: 0.00047600845573469996
step: 410, loss: 0.02228982374072075
step: 420, loss: 0.002466087229549885
epoch 16: dev_f1=0.7546391752577318, f1=0.6365591397849462, best_f1=0.6493506493506495
step: 0, loss: 0.0004078973433934152
step: 10, loss: 0.026353228837251663
step: 20, loss: 0.0006066995556466281
step: 30, loss: 0.012261411175131798
step: 40, loss: 0.0005368785350583494
step: 50, loss: 0.002051308751106262
step: 60, loss: 0.00820105616003275
step: 70, loss: 0.001687298296019435
step: 80, loss: 0.024043647572398186
step: 90, loss: 0.00038666994078084826
step: 100, loss: 0.0025267391465604305
step: 110, loss: 0.011069757863879204
step: 120, loss: 0.0004865805385634303
step: 130, loss: 0.001197383739054203
step: 140, loss: 0.00024181391927413642
step: 150, loss: 0.0002273580030305311
step: 160, loss: 0.0006218570051714778
step: 170, loss: 0.00010635576472850516
step: 180, loss: 0.00027494996902532876
step: 190, loss: 0.00010699706035666168
step: 200, loss: 0.00029134488431736827
step: 210, loss: 7.556845957878977e-05
step: 220, loss: 0.02973189391195774
step: 230, loss: 0.018702631816267967
step: 240, loss: 9.980611503124237e-05
step: 250, loss: 0.010607782751321793
step: 260, loss: 0.0003597821923904121
step: 270, loss: 0.0006021003937348723
step: 280, loss: 0.029144298285245895
step: 290, loss: 8.02529975771904e-05
step: 300, loss: 8.389639697270468e-05
step: 310, loss: 0.01423986442387104
step: 320, loss: 0.00040896623977459967
step: 330, loss: 0.000919318525120616
step: 340, loss: 0.0112718865275383
step: 350, loss: 0.009641844779253006
step: 360, loss: 0.0029564006254076958
step: 370, loss: 0.002486162818968296
step: 380, loss: 7.211398769868538e-05
step: 390, loss: 0.03250599652528763
step: 400, loss: 0.00024539686273783445
step: 410, loss: 5.583751044468954e-05
step: 420, loss: 0.001435503363609314
epoch 17: dev_f1=0.7467811158798283, f1=0.6405529953917051, best_f1=0.6493506493506495
step: 0, loss: 0.00020535865041892976
step: 10, loss: 0.0036856206133961678
step: 20, loss: 0.00019215623615309596
step: 30, loss: 0.00047030425048433244
step: 40, loss: 0.000232911785133183
step: 50, loss: 0.000529178767465055
step: 60, loss: 0.0001688582415226847
step: 70, loss: 0.03374168276786804
step: 80, loss: 0.00021607567032333463
step: 90, loss: 0.00022247486049309373
step: 100, loss: 0.0001165196081274189
step: 110, loss: 0.0005091875791549683
step: 120, loss: 0.008099332451820374
step: 130, loss: 0.00014073614147491753
step: 140, loss: 0.0003517429868225008
step: 150, loss: 0.022434484213590622
step: 160, loss: 0.0009056939743459225
step: 170, loss: 0.016525445505976677
step: 180, loss: 4.5721884816884995e-05
step: 190, loss: 0.004853217396885157
step: 200, loss: 0.0005928459577262402
step: 210, loss: 0.00017130214837379754
step: 220, loss: 4.682852159021422e-05
step: 230, loss: 0.0004255363019183278
step: 240, loss: 0.00018506358901504427
step: 250, loss: 0.0001430278061889112
step: 260, loss: 8.710566180525348e-05
step: 270, loss: 0.0001167530135717243
step: 280, loss: 0.0002902381820604205
step: 290, loss: 0.0003382665163371712
step: 300, loss: 6.0515740187838674e-05
step: 310, loss: 0.0003407495387364179
step: 320, loss: 5.9958725614706054e-05
step: 330, loss: 0.035664983093738556
step: 340, loss: 0.03523537144064903
step: 350, loss: 0.00021194916917011142
step: 360, loss: 0.007154748309403658
step: 370, loss: 0.0014479117235168815
step: 380, loss: 0.0005939406109973788
step: 390, loss: 0.0008252551779150963
step: 400, loss: 0.003274096641689539
step: 410, loss: 0.0004339256847742945
step: 420, loss: 0.011332043446600437
epoch 18: dev_f1=0.7390396659707724, f1=0.646288209606987, best_f1=0.6493506493506495
step: 0, loss: 0.0009961825562641025
step: 10, loss: 0.0008244968485087156
step: 20, loss: 5.6720818975009024e-05
step: 30, loss: 4.1662045987322927e-05
step: 40, loss: 4.28500134148635e-05
step: 50, loss: 6.96071729180403e-05
step: 60, loss: 0.00015093045658431947
step: 70, loss: 0.017563460394740105
step: 80, loss: 0.027925066649913788
step: 90, loss: 6.159137410577387e-05
step: 100, loss: 0.00020548413158394396
step: 110, loss: 6.463294994318858e-05
step: 120, loss: 0.0014233295805752277
step: 130, loss: 0.00011863012332469225
step: 140, loss: 0.00012441378203220665
step: 150, loss: 4.483547309064306e-05
step: 160, loss: 0.00020938248781021684
step: 170, loss: 6.927114009158686e-05
step: 180, loss: 0.0069808135740458965
step: 190, loss: 9.683638927526772e-05
step: 200, loss: 9.483321628067642e-05
step: 210, loss: 0.0034552982542663813
step: 220, loss: 0.040798988193273544
step: 230, loss: 0.0002727507962845266
step: 240, loss: 0.0065682134591042995
step: 250, loss: 0.0014394148020073771
step: 260, loss: 0.000752455263864249
step: 270, loss: 0.007898065261542797
step: 280, loss: 0.00031209527514874935
step: 290, loss: 0.000520930509082973
step: 300, loss: 0.03126262500882149
step: 310, loss: 0.0011987962061539292
step: 320, loss: 0.00013468056567944586
step: 330, loss: 0.014683504588901997
step: 340, loss: 0.0024352052714675665
step: 350, loss: 0.0006741273100487888
step: 360, loss: 0.0005297834286466241
step: 370, loss: 0.010844971984624863
step: 380, loss: 0.059060391038656235
step: 390, loss: 0.00017032198957167566
step: 400, loss: 5.9267538745189086e-05
step: 410, loss: 0.0001597011141711846
step: 420, loss: 0.017798833549022675
epoch 19: dev_f1=0.7397849462365591, f1=0.6344827586206897, best_f1=0.6493506493506495
step: 0, loss: 0.00021078737336210907
step: 10, loss: 5.7448480220045894e-05
step: 20, loss: 9.507449431112036e-05
step: 30, loss: 0.0007368416991084814
step: 40, loss: 5.4879368690308183e-05
step: 50, loss: 8.997264376375824e-05
step: 60, loss: 0.030406111851334572
step: 70, loss: 0.0009508576476946473
step: 80, loss: 8.118630648823455e-05
step: 90, loss: 0.019710857421159744
step: 100, loss: 8.490423351759091e-05
step: 110, loss: 0.003512422554194927
step: 120, loss: 6.173206929815933e-05
step: 130, loss: 5.796917685074732e-05
step: 140, loss: 8.068630995694548e-05
step: 150, loss: 0.0004447581013664603
step: 160, loss: 0.00016748983762227
step: 170, loss: 0.0005250460235401988
step: 180, loss: 0.0003388796467334032
step: 190, loss: 0.0019419704331085086
step: 200, loss: 0.0009655992616899312
step: 210, loss: 0.014545584097504616
step: 220, loss: 6.429600762203336e-05
step: 230, loss: 6.201639916980639e-05
step: 240, loss: 5.631945168715902e-05
step: 250, loss: 0.0012058622669428587
step: 260, loss: 8.03265065769665e-05
step: 270, loss: 0.00027283921372145414
step: 280, loss: 0.0007687326869927347
step: 290, loss: 9.77825911832042e-05
step: 300, loss: 7.069771527312696e-05
step: 310, loss: 7.495669706258923e-05
step: 320, loss: 0.0007872857386246324
step: 330, loss: 0.0009531418909318745
step: 340, loss: 0.0010158438235521317
step: 350, loss: 3.748259405256249e-05
step: 360, loss: 3.2137264497578144e-05
step: 370, loss: 0.0006843608571216464
step: 380, loss: 0.00011245807399973273
step: 390, loss: 0.0005021741962991655
step: 400, loss: 0.0005806390545330942
step: 410, loss: 9.755973587743938e-05
step: 420, loss: 8.306734525831416e-05
epoch 20: dev_f1=0.7379454926624738, f1=0.6426966292134831, best_f1=0.6493506493506495
