cuda
Device: cuda
step: 0, loss: 0.9426475763320923
step: 10, loss: 0.6313675045967102
step: 20, loss: 0.2800227105617523
step: 30, loss: 0.30280977487564087
step: 40, loss: 0.31094983220100403
step: 50, loss: 0.22154738008975983
step: 60, loss: 0.14776793122291565
step: 70, loss: 0.2381094992160797
step: 80, loss: 0.47757115960121155
step: 90, loss: 0.07170756161212921
step: 100, loss: 0.21557877957820892
step: 110, loss: 0.2043052464723587
step: 120, loss: 0.04835643991827965
step: 130, loss: 0.41364917159080505
step: 140, loss: 0.2185395061969757
step: 150, loss: 0.2143724113702774
step: 160, loss: 0.2064543217420578
step: 170, loss: 0.20138540863990784
step: 180, loss: 0.2635550796985626
step: 190, loss: 0.4210270047187805
step: 200, loss: 0.3597218692302704
step: 210, loss: 0.14912012219429016
step: 220, loss: 0.21460086107254028
step: 230, loss: 0.15062032639980316
step: 240, loss: 0.20600639283657074
step: 250, loss: 0.019865667447447777
step: 260, loss: 0.14183561503887177
step: 270, loss: 0.18471616506576538
step: 280, loss: 0.22411666810512543
step: 290, loss: 0.21485650539398193
step: 300, loss: 0.2105312943458557
step: 310, loss: 0.24039515852928162
step: 320, loss: 0.19761279225349426
step: 330, loss: 0.11854381114244461
step: 340, loss: 0.14486797153949738
step: 350, loss: 0.23179689049720764
step: 360, loss: 0.21863462030887604
step: 370, loss: 0.2034595012664795
step: 380, loss: 0.23807397484779358
epoch 1: dev_f1=0.6760563380281691, f1=0.6137339055793992, best_f1=0.6137339055793992
step: 0, loss: 0.17098689079284668
step: 10, loss: 0.04840495437383652
step: 20, loss: 0.22509586811065674
step: 30, loss: 0.08870995044708252
step: 40, loss: 0.05665646865963936
step: 50, loss: 0.2708060145378113
step: 60, loss: 0.034596238285303116
step: 70, loss: 0.08497237414121628
step: 80, loss: 0.1033177450299263
step: 90, loss: 0.19229541718959808
step: 100, loss: 0.13660794496536255
step: 110, loss: 0.10232411324977875
step: 120, loss: 0.13053640723228455
step: 130, loss: 0.09796766936779022
step: 140, loss: 0.24453043937683105
step: 150, loss: 0.2378818690776825
step: 160, loss: 0.05137723684310913
step: 170, loss: 0.2729710042476654
step: 180, loss: 0.25622057914733887
step: 190, loss: 0.0851602852344513
step: 200, loss: 0.1849069893360138
step: 210, loss: 0.2212246209383011
step: 220, loss: 0.2267523854970932
step: 230, loss: 0.09141439944505692
step: 240, loss: 0.11855002492666245
step: 250, loss: 0.09683230519294739
step: 260, loss: 0.09715770184993744
step: 270, loss: 0.029076408594846725
step: 280, loss: 0.1529286801815033
step: 290, loss: 0.06125004589557648
step: 300, loss: 0.11906806379556656
step: 310, loss: 0.11209478974342346
step: 320, loss: 0.062069203704595566
step: 330, loss: 0.0378735288977623
step: 340, loss: 0.06277984380722046
step: 350, loss: 0.12383483350276947
step: 360, loss: 0.15956005454063416
step: 370, loss: 0.10959190875291824
step: 380, loss: 0.022346895188093185
epoch 2: dev_f1=0.7114093959731543, f1=0.6914660831509848, best_f1=0.6914660831509848
step: 0, loss: 0.023708581924438477
step: 10, loss: 0.1917845755815506
step: 20, loss: 0.12561535835266113
step: 30, loss: 0.12157554179430008
step: 40, loss: 0.06531841307878494
step: 50, loss: 0.13125915825366974
step: 60, loss: 0.10351801663637161
step: 70, loss: 0.10577276349067688
step: 80, loss: 0.19021408259868622
step: 90, loss: 0.026270197704434395
step: 100, loss: 0.16586820781230927
step: 110, loss: 0.09503494948148727
step: 120, loss: 0.0674700140953064
step: 130, loss: 0.08089995384216309
step: 140, loss: 0.049541719257831573
step: 150, loss: 0.2151123434305191
step: 160, loss: 0.27937692403793335
step: 170, loss: 0.025115489959716797
step: 180, loss: 0.09807869046926498
step: 190, loss: 0.09157782793045044
step: 200, loss: 0.1297283172607422
step: 210, loss: 0.13759130239486694
step: 220, loss: 0.13453374803066254
step: 230, loss: 0.018368296325206757
step: 240, loss: 0.11989037692546844
step: 250, loss: 0.09038518369197845
step: 260, loss: 0.1805366724729538
step: 270, loss: 0.06220851093530655
step: 280, loss: 0.21098122000694275
step: 290, loss: 0.08945251256227493
step: 300, loss: 0.09105633199214935
step: 310, loss: 0.0392896831035614
step: 320, loss: 0.1950666457414627
step: 330, loss: 0.08282984793186188
step: 340, loss: 0.15686330199241638
step: 350, loss: 0.12270873039960861
step: 360, loss: 0.12121453136205673
step: 370, loss: 0.11363362520933151
step: 380, loss: 0.08039828389883041
epoch 3: dev_f1=0.7176781002638523, f1=0.6919191919191918, best_f1=0.6919191919191918
step: 0, loss: 0.014223016798496246
step: 10, loss: 0.1687137931585312
step: 20, loss: 0.12662853300571442
step: 30, loss: 0.11561994254589081
step: 40, loss: 0.14609917998313904
step: 50, loss: 0.13960888981819153
step: 60, loss: 0.09721925109624863
step: 70, loss: 0.12178273499011993
step: 80, loss: 0.46565648913383484
step: 90, loss: 0.11034410446882248
step: 100, loss: 0.07748604565858841
step: 110, loss: 0.12155117094516754
step: 120, loss: 0.022552723065018654
step: 130, loss: 0.1209215298295021
step: 140, loss: 0.14653204381465912
step: 150, loss: 0.08945262432098389
step: 160, loss: 0.05309414863586426
step: 170, loss: 0.1348179429769516
step: 180, loss: 0.15509715676307678
step: 190, loss: 0.18309657275676727
step: 200, loss: 0.011580653488636017
step: 210, loss: 0.014455859549343586
step: 220, loss: 0.08918962627649307
step: 230, loss: 0.12189280241727829
step: 240, loss: 0.06919283419847488
step: 250, loss: 0.09039701521396637
step: 260, loss: 0.1474038064479828
step: 270, loss: 0.020647546276450157
step: 280, loss: 0.13008251786231995
step: 290, loss: 0.05553583800792694
step: 300, loss: 0.11689508706331253
step: 310, loss: 0.02510344237089157
step: 320, loss: 0.06945016980171204
step: 330, loss: 0.18183259665966034
step: 340, loss: 0.1215570941567421
step: 350, loss: 0.08219163119792938
step: 360, loss: 0.09485930949449539
step: 370, loss: 0.06515038013458252
step: 380, loss: 0.1020013615489006
epoch 4: dev_f1=0.7238605898123326, f1=0.7382198952879582, best_f1=0.7382198952879582
step: 0, loss: 0.05424842610955238
step: 10, loss: 0.04124841094017029
step: 20, loss: 0.06615414470434189
step: 30, loss: 0.27295055985450745
step: 40, loss: 0.17519985139369965
step: 50, loss: 0.22126242518424988
step: 60, loss: 0.16661995649337769
step: 70, loss: 0.1693260669708252
step: 80, loss: 0.11825058609247208
step: 90, loss: 0.18500900268554688
step: 100, loss: 0.055434245616197586
step: 110, loss: 0.03781736642122269
step: 120, loss: 0.03272488713264465
step: 130, loss: 0.037321094423532486
step: 140, loss: 0.23910017311573029
step: 150, loss: 0.0800633579492569
step: 160, loss: 0.053755465894937515
step: 170, loss: 0.052896901965141296
step: 180, loss: 0.11079168319702148
step: 190, loss: 0.05718977749347687
step: 200, loss: 0.08947356790304184
step: 210, loss: 0.00818421971052885
step: 220, loss: 0.06924232840538025
step: 230, loss: 0.1222207173705101
step: 240, loss: 0.003442220389842987
step: 250, loss: 0.04580606520175934
step: 260, loss: 0.08981739729642868
step: 270, loss: 0.10910440236330032
step: 280, loss: 0.09046366065740585
step: 290, loss: 0.21228128671646118
step: 300, loss: 0.07826355844736099
step: 310, loss: 0.056756000965833664
step: 320, loss: 0.10492386668920517
step: 330, loss: 0.07798528671264648
step: 340, loss: 0.07531246542930603
step: 350, loss: 0.06606332212686539
step: 360, loss: 0.06495652347803116
step: 370, loss: 0.052708253264427185
step: 380, loss: 0.07635598629713058
epoch 5: dev_f1=0.7303921568627452, f1=0.7095238095238094, best_f1=0.7095238095238094
step: 0, loss: 0.05917127802968025
step: 10, loss: 0.014307902194559574
step: 20, loss: 0.00040585678652860224
step: 30, loss: 0.06057995557785034
step: 40, loss: 0.12260798364877701
step: 50, loss: 0.07134939730167389
step: 60, loss: 0.15260028839111328
step: 70, loss: 0.0769721120595932
step: 80, loss: 0.0924394279718399
step: 90, loss: 0.07499220967292786
step: 100, loss: 0.1667010486125946
step: 110, loss: 0.13964924216270447
step: 120, loss: 0.048951540142297745
step: 130, loss: 0.10919713973999023
step: 140, loss: 0.06449020653963089
step: 150, loss: 0.1314096450805664
step: 160, loss: 0.24039295315742493
step: 170, loss: 0.3156510591506958
step: 180, loss: 0.1972588300704956
step: 190, loss: 0.3513537049293518
step: 200, loss: 0.0600263811647892
step: 210, loss: 0.0719858929514885
step: 220, loss: 0.08126352727413177
step: 230, loss: 0.12036877870559692
step: 240, loss: 0.058840300887823105
step: 250, loss: 0.046910833567380905
step: 260, loss: 0.03247867152094841
step: 270, loss: 0.13382211327552795
step: 280, loss: 0.04294057935476303
step: 290, loss: 0.1956862360239029
step: 300, loss: 0.061811238527297974
step: 310, loss: 0.10608948022127151
step: 320, loss: 0.0516636036336422
step: 330, loss: 0.3141939043998718
step: 340, loss: 0.08124876022338867
step: 350, loss: 0.1217108815908432
step: 360, loss: 0.11471559852361679
step: 370, loss: 0.06298267096281052
step: 380, loss: 0.05691496655344963
epoch 6: dev_f1=0.7427184466019418, f1=0.6826923076923076, best_f1=0.6826923076923076
step: 0, loss: 0.023403141647577286
step: 10, loss: 0.10965549200773239
step: 20, loss: 0.04866386204957962
step: 30, loss: 0.04473858326673508
step: 40, loss: 0.10112425684928894
step: 50, loss: 0.056338462978601456
step: 60, loss: 0.1339866667985916
step: 70, loss: 0.03834143653512001
step: 80, loss: 0.09864628314971924
step: 90, loss: 0.05614462122321129
step: 100, loss: 0.026888560503721237
step: 110, loss: 0.09463447332382202
step: 120, loss: 0.012122636660933495
step: 130, loss: 0.12323665618896484
step: 140, loss: 0.034541524946689606
step: 150, loss: 0.0656212866306305
step: 160, loss: 0.049496956169605255
step: 170, loss: 0.05699105188250542
step: 180, loss: 0.05574915558099747
step: 190, loss: 0.05430072546005249
step: 200, loss: 0.08323809504508972
step: 210, loss: 0.02714974619448185
step: 220, loss: 0.03450438752770424
step: 230, loss: 0.06152670085430145
step: 240, loss: 0.0241911169141531
step: 250, loss: 0.06498627364635468
step: 260, loss: 0.09776782989501953
step: 270, loss: 0.16943226754665375
step: 280, loss: 0.08294349163770676
step: 290, loss: 0.14302663505077362
step: 300, loss: 0.13499832153320312
step: 310, loss: 0.13728483021259308
step: 320, loss: 0.06943634152412415
step: 330, loss: 0.023288531228899956
step: 340, loss: 0.1010877713561058
step: 350, loss: 0.0904390886425972
step: 360, loss: 0.04398331791162491
step: 370, loss: 0.04934828728437424
step: 380, loss: 0.14000532031059265
epoch 7: dev_f1=0.714975845410628, f1=0.7259615384615384, best_f1=0.6826923076923076
step: 0, loss: 0.10142640769481659
step: 10, loss: 0.0696772038936615
step: 20, loss: 0.02401808463037014
step: 30, loss: 0.05821720510721207
step: 40, loss: 0.11688880622386932
step: 50, loss: 0.06885165721178055
step: 60, loss: 0.06423276662826538
step: 70, loss: 0.056740306317806244
step: 80, loss: 0.0724845603108406
step: 90, loss: 0.028407715260982513
step: 100, loss: 0.05024935305118561
step: 110, loss: 0.0672282874584198
step: 120, loss: 0.06370560824871063
step: 130, loss: 0.023565689101815224
step: 140, loss: 0.0821181908249855
step: 150, loss: 0.02632574737071991
step: 160, loss: 0.02907884493470192
step: 170, loss: 0.04126361012458801
step: 180, loss: 0.08313394337892532
step: 190, loss: 0.053514301776885986
step: 200, loss: 0.026472656056284904
step: 210, loss: 0.08568917214870453
step: 220, loss: 0.05946024879813194
step: 230, loss: 0.030047865584492683
step: 240, loss: 0.10760485380887985
step: 250, loss: 0.20311985909938812
step: 260, loss: 0.08449667692184448
step: 270, loss: 0.023319976404309273
step: 280, loss: 0.05826790630817413
step: 290, loss: 0.12098439782857895
step: 300, loss: 0.08012225478887558
step: 310, loss: 0.07209125906229019
step: 320, loss: 0.05103171616792679
step: 330, loss: 0.06468356400728226
step: 340, loss: 0.11373384296894073
step: 350, loss: 0.07332408428192139
step: 360, loss: 0.12835593521595
step: 370, loss: 0.10730505734682083
step: 380, loss: 0.11445577442646027
epoch 8: dev_f1=0.7305699481865285, f1=0.6886075949367089, best_f1=0.6826923076923076
step: 0, loss: 0.06322909146547318
step: 10, loss: 0.024588368833065033
step: 20, loss: 0.08406203240156174
step: 30, loss: 0.10301519930362701
step: 40, loss: 0.022308645769953728
step: 50, loss: 0.010568201541900635
step: 60, loss: 0.16735436022281647
step: 70, loss: 0.028893696144223213
step: 80, loss: 0.15119968354701996
step: 90, loss: 0.04805876314640045
step: 100, loss: 0.08894787728786469
step: 110, loss: 0.05696086585521698
step: 120, loss: 0.03039383888244629
step: 130, loss: 0.10655948519706726
step: 140, loss: 0.07303833961486816
step: 150, loss: 0.06180525943636894
step: 160, loss: 0.030992472544312477
step: 170, loss: 0.043853167444467545
step: 180, loss: 0.0858701691031456
step: 190, loss: 0.1511470228433609
step: 200, loss: 0.09715873003005981
step: 210, loss: 0.0437927208840847
step: 220, loss: 0.052713774144649506
step: 230, loss: 0.1649908423423767
step: 240, loss: 0.12805941700935364
step: 250, loss: 0.0342462919652462
step: 260, loss: 0.07963493466377258
step: 270, loss: 0.042930491268634796
step: 280, loss: 0.06230251118540764
step: 290, loss: 0.05466459318995476
step: 300, loss: 0.07246220856904984
step: 310, loss: 0.0526299923658371
step: 320, loss: 0.08896913379430771
step: 330, loss: 0.10940080881118774
step: 340, loss: 0.02334488555788994
step: 350, loss: 0.08015131205320358
step: 360, loss: 0.04687610641121864
step: 370, loss: 0.025537261739373207
step: 380, loss: 0.0710037499666214
epoch 9: dev_f1=0.7435897435897435, f1=0.7263427109974423, best_f1=0.7263427109974423
step: 0, loss: 0.03119739703834057
step: 10, loss: 0.02086636982858181
step: 20, loss: 0.055885978043079376
step: 30, loss: 0.10137820988893509
step: 40, loss: 0.14229030907154083
step: 50, loss: 0.08321557939052582
step: 60, loss: 0.021723251789808273
step: 70, loss: 0.04498770460486412
step: 80, loss: 0.026278071105480194
step: 90, loss: 0.07330171018838882
step: 100, loss: 0.05383088067173958
step: 110, loss: 0.04948829486966133
step: 120, loss: 0.10160288214683533
step: 130, loss: 0.06868661195039749
step: 140, loss: 0.062458690255880356
step: 150, loss: 0.10680579394102097
step: 160, loss: 0.05779262259602547
step: 170, loss: 0.07330875098705292
step: 180, loss: 0.01994221843779087
step: 190, loss: 0.030346468091011047
step: 200, loss: 0.12673956155776978
step: 210, loss: 0.0795757845044136
step: 220, loss: 0.08820897340774536
step: 230, loss: 0.134430393576622
step: 240, loss: 0.02097746543586254
step: 250, loss: 0.04488329216837883
step: 260, loss: 0.002281311433762312
step: 270, loss: 0.04327980428934097
step: 280, loss: 0.04425254091620445
step: 290, loss: 0.02680159918963909
step: 300, loss: 0.014263514429330826
step: 310, loss: 0.013940677978098392
step: 320, loss: 0.04218702018260956
step: 330, loss: 0.029121864587068558
step: 340, loss: 0.11270252615213394
step: 350, loss: 0.025336364284157753
step: 360, loss: 0.09214308112859726
step: 370, loss: 0.02548960968852043
step: 380, loss: 0.05156981945037842
epoch 10: dev_f1=0.7430025445292621, f1=0.7052896725440806, best_f1=0.7263427109974423
step: 0, loss: 0.11587026715278625
step: 10, loss: 0.012964787892997265
step: 20, loss: 0.03576505556702614
step: 30, loss: 0.12491638213396072
step: 40, loss: 0.03132643923163414
step: 50, loss: 0.010900713503360748
step: 60, loss: 0.07619286328554153
step: 70, loss: 0.008246791549026966
step: 80, loss: 0.06351801753044128
step: 90, loss: 0.1505235880613327
step: 100, loss: 0.10652221739292145
step: 110, loss: 0.03197534382343292
step: 120, loss: 0.034402284771203995
step: 130, loss: 0.022164631634950638
step: 140, loss: 0.037207573652267456
step: 150, loss: 0.005997049622237682
step: 160, loss: 0.032968923449516296
step: 170, loss: 0.05416609346866608
step: 180, loss: 0.015126138925552368
step: 190, loss: 0.02393796108663082
step: 200, loss: 0.09487336874008179
step: 210, loss: 0.0293766800314188
step: 220, loss: 0.046472739428281784
step: 230, loss: 0.0712636187672615
step: 240, loss: 0.07062296569347382
step: 250, loss: 0.011233383789658546
step: 260, loss: 0.14135834574699402
step: 270, loss: 0.037606801837682724
step: 280, loss: 0.0469823032617569
step: 290, loss: 0.024435998871922493
step: 300, loss: 0.03275299444794655
step: 310, loss: 0.016869591549038887
step: 320, loss: 0.09108022600412369
step: 330, loss: 0.019285127520561218
step: 340, loss: 0.034629058092832565
step: 350, loss: 0.09400521963834763
step: 360, loss: 0.1940053105354309
step: 370, loss: 0.10564583539962769
step: 380, loss: 0.09363631159067154
epoch 11: dev_f1=0.7362924281984334, f1=0.7028423772609819, best_f1=0.7263427109974423
step: 0, loss: 0.0009364000870846212
step: 10, loss: 0.05143885686993599
step: 20, loss: 0.03012695722281933
step: 30, loss: 0.04052986204624176
step: 40, loss: 0.005214037373661995
step: 50, loss: 0.08581194281578064
step: 60, loss: 0.07638710737228394
step: 70, loss: 0.0928550586104393
step: 80, loss: 0.004167183302342892
step: 90, loss: 0.0381980799138546
step: 100, loss: 0.07294147461652756
step: 110, loss: 0.14701642096042633
step: 120, loss: 0.011494206264615059
step: 130, loss: 0.057799626141786575
step: 140, loss: 0.07504549622535706
step: 150, loss: 0.03123905323445797
step: 160, loss: 0.05361086130142212
step: 170, loss: 0.05297964811325073
step: 180, loss: 0.03833654895424843
step: 190, loss: 0.0008201039163395762
step: 200, loss: 0.04764597862958908
step: 210, loss: 0.02246067114174366
step: 220, loss: 0.062165454030036926
step: 230, loss: 0.06979940831661224
step: 240, loss: 0.025952907279133797
step: 250, loss: 0.05747034773230553
step: 260, loss: 0.07609321922063828
step: 270, loss: 0.04162738472223282
step: 280, loss: 0.06841294467449188
step: 290, loss: 0.01289433240890503
step: 300, loss: 0.023587282747030258
step: 310, loss: 0.016369717195630074
step: 320, loss: 0.005859801080077887
step: 330, loss: 0.16345162689685822
step: 340, loss: 0.05512943118810654
step: 350, loss: 0.16030587255954742
step: 360, loss: 0.041424259543418884
step: 370, loss: 0.23211637139320374
step: 380, loss: 0.09613031893968582
epoch 12: dev_f1=0.7155963302752294, f1=0.6819221967963386, best_f1=0.7263427109974423
step: 0, loss: 0.08460720628499985
step: 10, loss: 0.03236032649874687
step: 20, loss: 0.1256396323442459
step: 30, loss: 0.04905199259519577
step: 40, loss: 0.03349518030881882
step: 50, loss: 0.081514373421669
step: 60, loss: 0.013733921572566032
step: 70, loss: 0.03437509387731552
step: 80, loss: 0.013162781484425068
step: 90, loss: 0.03717875853180885
step: 100, loss: 0.011026659049093723
step: 110, loss: 0.04898199439048767
step: 120, loss: 0.0883278101682663
step: 130, loss: 0.051973167806863785
step: 140, loss: 0.004317995626479387
step: 150, loss: 0.07026120275259018
step: 160, loss: 0.016919316723942757
step: 170, loss: 0.04533351585268974
step: 180, loss: 0.0087280860170722
step: 190, loss: 0.05776180326938629
step: 200, loss: 0.17617571353912354
step: 210, loss: 0.06284697353839874
step: 220, loss: 0.042261820286512375
step: 230, loss: 0.028660250827670097
step: 240, loss: 0.06784118711948395
step: 250, loss: 0.0674629732966423
step: 260, loss: 0.02599371038377285
step: 270, loss: 0.05944687873125076
step: 280, loss: 0.009211614727973938
step: 290, loss: 0.05254137143492699
step: 300, loss: 0.021749459207057953
step: 310, loss: 0.1278175711631775
step: 320, loss: 0.03700941056013107
step: 330, loss: 0.006299297325313091
step: 340, loss: 0.11096976697444916
step: 350, loss: 0.08799020200967789
step: 360, loss: 0.07587799429893494
step: 370, loss: 0.04919666796922684
step: 380, loss: 0.007542189676314592
epoch 13: dev_f1=0.7196029776674937, f1=0.6945812807881775, best_f1=0.7263427109974423
step: 0, loss: 0.00013382172619458288
step: 10, loss: 0.01693314127624035
step: 20, loss: 0.07408849895000458
step: 30, loss: 0.008342089131474495
step: 40, loss: 0.06440111994743347
step: 50, loss: 0.018712107092142105
step: 60, loss: 0.03928953781723976
step: 70, loss: 0.029989371076226234
step: 80, loss: 0.01769769936800003
step: 90, loss: 0.002239100867882371
step: 100, loss: 5.676186628988944e-05
step: 110, loss: 0.0011668364750221372
step: 120, loss: 0.07825586199760437
step: 130, loss: 0.021155498921871185
step: 140, loss: 0.0522107370197773
step: 150, loss: 0.007831389084458351
step: 160, loss: 0.004184923600405455
step: 170, loss: 0.08850754052400589
step: 180, loss: 0.023427151143550873
step: 190, loss: 0.08465646952390671
step: 200, loss: 0.0009141327464021742
step: 210, loss: 0.021757500246167183
step: 220, loss: 0.011709950864315033
step: 230, loss: 0.01782570593059063
step: 240, loss: 0.07574766129255295
step: 250, loss: 0.04159633442759514
step: 260, loss: 0.04321867227554321
step: 270, loss: 0.011452915146946907
step: 280, loss: 0.07008416950702667
step: 290, loss: 0.014690840616822243
step: 300, loss: 0.11786387860774994
step: 310, loss: 0.015077437274158001
step: 320, loss: 0.05965740233659744
step: 330, loss: 0.16803817451000214
step: 340, loss: 0.08605851233005524
step: 350, loss: 0.028558900579810143
step: 360, loss: 0.015442761592566967
step: 370, loss: 0.02039887197315693
step: 380, loss: 0.021059446036815643
epoch 14: dev_f1=0.7350000000000001, f1=0.7002518891687657, best_f1=0.7263427109974423
step: 0, loss: 0.0623883455991745
step: 10, loss: 0.0027855217922478914
step: 20, loss: 0.0006746564758941531
step: 30, loss: 0.0054327016696333885
step: 40, loss: 0.03888404741883278
step: 50, loss: 0.02411806769669056
step: 60, loss: 0.071281298995018
step: 70, loss: 0.014954120852053165
step: 80, loss: 0.04445241764187813
step: 90, loss: 0.14153829216957092
step: 100, loss: 0.054704900830984116
step: 110, loss: 0.03651760146021843
step: 120, loss: 0.04512268304824829
step: 130, loss: 0.05090775340795517
step: 140, loss: 0.03185269236564636
step: 150, loss: 0.03852245584130287
step: 160, loss: 0.021508222445845604
step: 170, loss: 0.02074015513062477
step: 180, loss: 0.02189970575273037
step: 190, loss: 0.0893678218126297
step: 200, loss: 0.06491938978433609
step: 210, loss: 0.02555229142308235
step: 220, loss: 0.04398506507277489
step: 230, loss: 0.03566918894648552
step: 240, loss: 0.025539474561810493
step: 250, loss: 0.02441548742353916
step: 260, loss: 0.03281738609075546
step: 270, loss: 0.010638296604156494
step: 280, loss: 0.002760642906650901
step: 290, loss: 0.06583956629037857
step: 300, loss: 0.05658445507287979
step: 310, loss: 0.006760274060070515
step: 320, loss: 0.09031682461500168
step: 330, loss: 8.76736085047014e-05
step: 340, loss: 0.17177747189998627
step: 350, loss: 0.13770955801010132
step: 360, loss: 0.00996009074151516
step: 370, loss: 0.020909974351525307
step: 380, loss: 0.07133661210536957
epoch 15: dev_f1=0.7164179104477613, f1=0.6783919597989951, best_f1=0.7263427109974423
step: 0, loss: 0.02793092280626297
step: 10, loss: 0.020275268703699112
step: 20, loss: 0.019145384430885315
step: 30, loss: 0.00479746563360095
step: 40, loss: 0.04037989303469658
step: 50, loss: 0.07505161315202713
step: 60, loss: 0.007990704849362373
step: 70, loss: 0.06364855915307999
step: 80, loss: 0.056294433772563934
step: 90, loss: 0.008227278478443623
step: 100, loss: 0.00030216178856790066
step: 110, loss: 0.011294200085103512
step: 120, loss: 0.015262280590832233
step: 130, loss: 0.00016509958368260413
step: 140, loss: 0.022488970309495926
step: 150, loss: 0.013499945402145386
step: 160, loss: 0.00039660034235566854
step: 170, loss: 0.0200395155698061
step: 180, loss: 0.06700367480516434
step: 190, loss: 0.09424208104610443
step: 200, loss: 0.025210242718458176
step: 210, loss: 0.16289092600345612
step: 220, loss: 0.08056903630495071
step: 230, loss: 0.03839368000626564
step: 240, loss: 0.07506424933671951
step: 250, loss: 0.04592326655983925
step: 260, loss: 0.028208449482917786
step: 270, loss: 0.06114991381764412
step: 280, loss: 0.008006349205970764
step: 290, loss: 0.0020124600268900394
step: 300, loss: 0.009714463725686073
step: 310, loss: 0.05003279075026512
step: 320, loss: 0.00022115765023045242
step: 330, loss: 0.009053823538124561
step: 340, loss: 0.04068855568766594
step: 350, loss: 0.07036639004945755
step: 360, loss: 0.02346622198820114
step: 370, loss: 0.04558978229761124
step: 380, loss: 0.059806741774082184
epoch 16: dev_f1=0.717391304347826, f1=0.6721311475409837, best_f1=0.7263427109974423
step: 0, loss: 0.05131329596042633
step: 10, loss: 0.03798247501254082
step: 20, loss: 0.04676119238138199
step: 30, loss: 0.08476912975311279
step: 40, loss: 0.003962653689086437
step: 50, loss: 0.02932276949286461
step: 60, loss: 0.013025762513279915
step: 70, loss: 0.002604059176519513
step: 80, loss: 0.007919526658952236
step: 90, loss: 0.04810842126607895
step: 100, loss: 0.05023311451077461
step: 110, loss: 0.04625537246465683
step: 120, loss: 0.06941202282905579
step: 130, loss: 0.05625732243061066
step: 140, loss: 0.0005588444182649255
step: 150, loss: 0.07358626276254654
step: 160, loss: 0.015835661441087723
step: 170, loss: 0.019975556060671806
step: 180, loss: 0.04108787328004837
step: 190, loss: 0.011788244359195232
step: 200, loss: 0.015616366639733315
step: 210, loss: 0.008215902373194695
step: 220, loss: 0.02738882042467594
step: 230, loss: 0.0454290434718132
step: 240, loss: 0.04501720517873764
step: 250, loss: 0.10141658782958984
step: 260, loss: 0.004591287113726139
step: 270, loss: 0.0013318087439984083
step: 280, loss: 0.10399755090475082
step: 290, loss: 0.02475695312023163
step: 300, loss: 0.07366789877414703
step: 310, loss: 0.03824816271662712
step: 320, loss: 0.01816697232425213
step: 330, loss: 0.018479546532034874
step: 340, loss: 0.10941360145807266
step: 350, loss: 0.07298707216978073
step: 360, loss: 0.07624222338199615
step: 370, loss: 0.003111013676971197
step: 380, loss: 0.022881317883729935
epoch 17: dev_f1=0.7197802197802198, f1=0.6850828729281768, best_f1=0.7263427109974423
step: 0, loss: 3.73633811250329e-05
step: 10, loss: 0.02620207890868187
step: 20, loss: 1.6469350157422014e-05
step: 30, loss: 0.012781253084540367
step: 40, loss: 0.01299840584397316
step: 50, loss: 0.006363986991345882
step: 60, loss: 0.002679568249732256
step: 70, loss: 0.005662555806338787
step: 80, loss: 0.02601911872625351
step: 90, loss: 0.033085472881793976
step: 100, loss: 2.2116650143289007e-05
step: 110, loss: 0.015945743769407272
step: 120, loss: 0.03851402923464775
step: 130, loss: 0.02880190685391426
step: 140, loss: 0.012843727134168148
step: 150, loss: 0.031085463240742683
step: 160, loss: 0.022720079869031906
step: 170, loss: 0.07179398834705353
step: 180, loss: 0.04058068245649338
step: 190, loss: 0.030044512823224068
step: 200, loss: 0.009637652896344662
step: 210, loss: 0.013049738481640816
step: 220, loss: 0.017437787726521492
step: 230, loss: 0.0067628975957632065
step: 240, loss: 0.006854239851236343
step: 250, loss: 0.05745331943035126
step: 260, loss: 0.07530651241540909
step: 270, loss: 0.0006318567902781069
step: 280, loss: 0.008508394472301006
step: 290, loss: 0.1521739512681961
step: 300, loss: 0.04712922126054764
step: 310, loss: 0.03436118736863136
step: 320, loss: 0.01486632414162159
step: 330, loss: 0.010725807398557663
step: 340, loss: 0.01680346578359604
step: 350, loss: 0.036261964589357376
step: 360, loss: 0.018148168921470642
step: 370, loss: 0.044816579669713974
step: 380, loss: 0.010685006156563759
epoch 18: dev_f1=0.7146666666666668, f1=0.702127659574468, best_f1=0.7263427109974423
step: 0, loss: 0.0028868012595921755
step: 10, loss: 0.020863953977823257
step: 20, loss: 2.1241283320705406e-05
step: 30, loss: 0.06416766345500946
step: 40, loss: 0.03259573504328728
step: 50, loss: 0.00040998138138093054
step: 60, loss: 0.00858102086931467
step: 70, loss: 0.059475287795066833
step: 80, loss: 0.008616060949862003
step: 90, loss: 0.012495409697294235
step: 100, loss: 0.032091882079839706
step: 110, loss: 0.049257613718509674
step: 120, loss: 0.04377232491970062
step: 130, loss: 0.010178607888519764
step: 140, loss: 0.011102304793894291
step: 150, loss: 0.027774732559919357
step: 160, loss: 0.10125458985567093
step: 170, loss: 0.036912113428115845
step: 180, loss: 0.0015272421296685934
step: 190, loss: 0.08555252104997635
step: 200, loss: 0.041687045246362686
step: 210, loss: 0.05666734650731087
step: 220, loss: 0.0013855828437954187
step: 230, loss: 0.010882401838898659
step: 240, loss: 0.03362095728516579
step: 250, loss: 0.0007476211176253855
step: 260, loss: 0.05224079266190529
step: 270, loss: 0.002047308487817645
step: 280, loss: 4.990870365872979e-05
step: 290, loss: 0.05840517580509186
step: 300, loss: 0.009474569000303745
step: 310, loss: 0.07139047980308533
step: 320, loss: 0.017519567161798477
step: 330, loss: 0.013071100227534771
step: 340, loss: 0.11557172983884811
step: 350, loss: 0.012205502018332481
step: 360, loss: 4.129275475861505e-05
step: 370, loss: 0.014658013358712196
step: 380, loss: 0.057300928980112076
epoch 19: dev_f1=0.711484593837535, f1=0.6871508379888268, best_f1=0.7263427109974423
step: 0, loss: 0.023747500032186508
step: 10, loss: 0.023937661200761795
step: 20, loss: 2.0138624677201733e-05
step: 30, loss: 0.029065944254398346
step: 40, loss: 0.027444830164313316
step: 50, loss: 0.005026098806411028
step: 60, loss: 0.0679677277803421
step: 70, loss: 0.011643512174487114
step: 80, loss: 0.02041199803352356
step: 90, loss: 0.0081712631508708
step: 100, loss: 0.10546582192182541
step: 110, loss: 0.031107371672987938
step: 120, loss: 0.04286951571702957
step: 130, loss: 0.017317254096269608
step: 140, loss: 0.050365105271339417
step: 150, loss: 0.008436082862317562
step: 160, loss: 0.008464772254228592
step: 170, loss: 0.04357398673892021
step: 180, loss: 0.0046331449411809444
step: 190, loss: 0.0032676050905138254
step: 200, loss: 0.0016548560233786702
step: 210, loss: 0.04501930996775627
step: 220, loss: 0.05770626291632652
step: 230, loss: 0.0406741201877594
step: 240, loss: 0.013944301754236221
step: 250, loss: 0.028956549242138863
step: 260, loss: 0.030190765857696533
step: 270, loss: 0.007938473485410213
step: 280, loss: 0.04521922394633293
step: 290, loss: 0.03894495591521263
step: 300, loss: 0.052699703723192215
step: 310, loss: 0.004813492763787508
step: 320, loss: 0.12237436324357986
step: 330, loss: 0.03548456355929375
step: 340, loss: 3.43009814969264e-05
step: 350, loss: 0.008968556299805641
step: 360, loss: 0.04841286689043045
step: 370, loss: 0.04996239393949509
step: 380, loss: 0.016906054690480232
epoch 20: dev_f1=0.7103825136612021, f1=0.6904109589041095, best_f1=0.7263427109974423
