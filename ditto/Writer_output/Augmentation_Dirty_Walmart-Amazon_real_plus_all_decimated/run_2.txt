cuda
Device: cuda
step: 0, loss: 0.6339412331581116
step: 10, loss: 0.5314722061157227
step: 20, loss: 0.4484003484249115
step: 30, loss: 0.3180186152458191
step: 40, loss: 0.42383453249931335
step: 50, loss: 0.40292978286743164
step: 60, loss: 0.23974081873893738
step: 70, loss: 0.3195010721683502
step: 80, loss: 0.3039928078651428
step: 90, loss: 0.1517825424671173
step: 100, loss: 0.21251921355724335
step: 110, loss: 0.3308045566082001
step: 120, loss: 0.2787042558193207
step: 130, loss: 0.22125144302845
step: 140, loss: 0.19484789669513702
step: 150, loss: 0.057827178388834
step: 160, loss: 0.05679284408688545
step: 170, loss: 0.2703939974308014
step: 180, loss: 0.368243545293808
step: 190, loss: 0.05637887120246887
step: 200, loss: 0.09494663774967194
step: 210, loss: 0.18363989889621735
step: 220, loss: 0.20878076553344727
step: 230, loss: 0.12544798851013184
step: 240, loss: 0.15880733728408813
step: 250, loss: 0.06511181592941284
step: 260, loss: 0.19761164486408234
step: 270, loss: 0.10561932623386383
step: 280, loss: 0.05143078789114952
step: 290, loss: 0.035029273480176926
step: 300, loss: 0.17908672988414764
step: 310, loss: 0.22129017114639282
step: 320, loss: 0.21364480257034302
step: 330, loss: 0.10877539217472076
step: 340, loss: 0.043062567710876465
step: 350, loss: 0.05240211263298988
step: 360, loss: 0.03538494184613228
step: 370, loss: 0.19611768424510956
step: 380, loss: 0.20891395211219788
epoch 1: dev_f1=0.624, f1=0.6467391304347825, best_f1=0.6467391304347825
step: 0, loss: 0.1818743646144867
step: 10, loss: 0.14232145249843597
step: 20, loss: 0.16558127105236053
step: 30, loss: 0.07927386462688446
step: 40, loss: 0.30831006169319153
step: 50, loss: 0.07885388284921646
step: 60, loss: 0.11980986595153809
step: 70, loss: 0.121408611536026
step: 80, loss: 0.20882901549339294
step: 90, loss: 0.09594392031431198
step: 100, loss: 0.020128870382905006
step: 110, loss: 0.18064409494400024
step: 120, loss: 0.3363162875175476
step: 130, loss: 0.41302984952926636
step: 140, loss: 0.12054537236690521
step: 150, loss: 0.07230088114738464
step: 160, loss: 0.26581239700317383
step: 170, loss: 0.13893237709999084
step: 180, loss: 0.1997104287147522
step: 190, loss: 0.22808422148227692
step: 200, loss: 0.08442097902297974
step: 210, loss: 0.2738826870918274
step: 220, loss: 0.15237298607826233
step: 230, loss: 0.0857461541891098
step: 240, loss: 0.160016730427742
step: 250, loss: 0.019158311188220978
step: 260, loss: 0.13759398460388184
step: 270, loss: 0.0919719710946083
step: 280, loss: 0.1763460487127304
step: 290, loss: 0.12890104949474335
step: 300, loss: 0.025622501969337463
step: 310, loss: 0.06542933732271194
step: 320, loss: 0.2514429986476898
step: 330, loss: 0.0782676637172699
step: 340, loss: 0.0774129256606102
step: 350, loss: 0.09791194647550583
step: 360, loss: 0.06614945083856583
step: 370, loss: 0.15903781354427338
step: 380, loss: 0.10365644097328186
epoch 2: dev_f1=0.6540284360189573, f1=0.6713615023474179, best_f1=0.6713615023474179
step: 0, loss: 0.014268245548009872
step: 10, loss: 0.10547095537185669
step: 20, loss: 0.19514647126197815
step: 30, loss: 0.17178647220134735
step: 40, loss: 0.15650659799575806
step: 50, loss: 0.08688496798276901
step: 60, loss: 0.15771766006946564
step: 70, loss: 0.06672322750091553
step: 80, loss: 0.15449178218841553
step: 90, loss: 0.14852049946784973
step: 100, loss: 0.10394157469272614
step: 110, loss: 0.09356200695037842
step: 120, loss: 0.13526184856891632
step: 130, loss: 0.19405148923397064
step: 140, loss: 0.10993221402168274
step: 150, loss: 0.037134379148483276
step: 160, loss: 0.05443066731095314
step: 170, loss: 0.020884662866592407
step: 180, loss: 0.20756080746650696
step: 190, loss: 0.04655329883098602
step: 200, loss: 0.20599956810474396
step: 210, loss: 0.1643962264060974
step: 220, loss: 0.13772569596767426
step: 230, loss: 0.24050083756446838
step: 240, loss: 0.08458520472049713
step: 250, loss: 0.03283615782856941
step: 260, loss: 0.17374756932258606
step: 270, loss: 0.11542988568544388
step: 280, loss: 0.1271355152130127
step: 290, loss: 0.15564067661762238
step: 300, loss: 0.15103363990783691
step: 310, loss: 0.04343000799417496
step: 320, loss: 0.0506913885474205
step: 330, loss: 0.11181756108999252
step: 340, loss: 0.15622107684612274
step: 350, loss: 0.289046049118042
step: 360, loss: 0.12261825054883957
step: 370, loss: 0.08325809240341187
step: 380, loss: 0.10330003499984741
epoch 3: dev_f1=0.6793478260869564, f1=0.7024128686327078, best_f1=0.7024128686327078
step: 0, loss: 0.12513737380504608
step: 10, loss: 0.03269430994987488
step: 20, loss: 0.1589883416891098
step: 30, loss: 0.08314695954322815
step: 40, loss: 0.12404456734657288
step: 50, loss: 0.10824643075466156
step: 60, loss: 0.12370936572551727
step: 70, loss: 0.14227239787578583
step: 80, loss: 0.022992391139268875
step: 90, loss: 0.04232531785964966
step: 100, loss: 0.1754361391067505
step: 110, loss: 0.11649368703365326
step: 120, loss: 0.16331399977207184
step: 130, loss: 0.03613719716668129
step: 140, loss: 0.17603003978729248
step: 150, loss: 0.1064532995223999
step: 160, loss: 0.02063298411667347
step: 170, loss: 0.12561631202697754
step: 180, loss: 0.11257293075323105
step: 190, loss: 0.07055775821208954
step: 200, loss: 0.04978809878230095
step: 210, loss: 0.14649592339992523
step: 220, loss: 0.14236457645893097
step: 230, loss: 0.08536987006664276
step: 240, loss: 0.07635181397199631
step: 250, loss: 0.13639111816883087
step: 260, loss: 0.04337244853377342
step: 270, loss: 0.2014029175043106
step: 280, loss: 0.03619808703660965
step: 290, loss: 0.08258882164955139
step: 300, loss: 0.006862545385956764
step: 310, loss: 0.14595851302146912
step: 320, loss: 0.14058925211429596
step: 330, loss: 0.19846458733081818
step: 340, loss: 0.03991099074482918
step: 350, loss: 0.11502240598201752
step: 360, loss: 0.09255430847406387
step: 370, loss: 0.2310267686843872
step: 380, loss: 0.10555805265903473
epoch 4: dev_f1=0.7378640776699029, f1=0.7100000000000001, best_f1=0.7100000000000001
step: 0, loss: 0.09313131123781204
step: 10, loss: 0.14232833683490753
step: 20, loss: 0.0157040785998106
step: 30, loss: 0.09486235678195953
step: 40, loss: 0.19958864152431488
step: 50, loss: 0.10326573252677917
step: 60, loss: 0.06745665520429611
step: 70, loss: 0.2134755700826645
step: 80, loss: 0.09169850498437881
step: 90, loss: 0.1576928347349167
step: 100, loss: 0.11918054521083832
step: 110, loss: 0.07596322894096375
step: 120, loss: 0.09070386737585068
step: 130, loss: 0.05341075733304024
step: 140, loss: 0.04164860025048256
step: 150, loss: 0.1123083084821701
step: 160, loss: 0.0488031841814518
step: 170, loss: 0.0817011147737503
step: 180, loss: 0.16202674806118011
step: 190, loss: 0.07061699777841568
step: 200, loss: 0.18225455284118652
step: 210, loss: 0.14405745267868042
step: 220, loss: 0.12290503084659576
step: 230, loss: 0.07818610966205597
step: 240, loss: 0.1256355196237564
step: 250, loss: 0.1010090559720993
step: 260, loss: 0.01021008100360632
step: 270, loss: 0.13510464131832123
step: 280, loss: 0.053088415414094925
step: 290, loss: 0.13335008919239044
step: 300, loss: 0.038163505494594574
step: 310, loss: 0.06593319028615952
step: 320, loss: 0.06640766561031342
step: 330, loss: 0.044206101447343826
step: 340, loss: 0.20977678894996643
step: 350, loss: 0.07927536219358444
step: 360, loss: 0.07513889670372009
step: 370, loss: 0.042322658002376556
step: 380, loss: 0.02329038642346859
epoch 5: dev_f1=0.736, f1=0.7272727272727273, best_f1=0.7100000000000001
step: 0, loss: 0.01978680118918419
step: 10, loss: 0.06001906096935272
step: 20, loss: 0.06965582072734833
step: 30, loss: 0.008254941552877426
step: 40, loss: 0.07882439345121384
step: 50, loss: 0.01762041449546814
step: 60, loss: 0.12647512555122375
step: 70, loss: 0.07074065506458282
step: 80, loss: 0.18512536585330963
step: 90, loss: 0.1425325721502304
step: 100, loss: 0.03783873841166496
step: 110, loss: 0.2101641595363617
step: 120, loss: 0.2221272885799408
step: 130, loss: 0.06419540196657181
step: 140, loss: 0.029927058145403862
step: 150, loss: 0.16317202150821686
step: 160, loss: 0.16572782397270203
step: 170, loss: 0.1017787754535675
step: 180, loss: 0.17999036610126495
step: 190, loss: 0.07410364598035812
step: 200, loss: 0.06393755227327347
step: 210, loss: 0.08502142131328583
step: 220, loss: 0.11313972622156143
step: 230, loss: 0.16536904871463776
step: 240, loss: 0.1933494508266449
step: 250, loss: 0.005665251985192299
step: 260, loss: 0.12624476850032806
step: 270, loss: 0.03517811372876167
step: 280, loss: 0.09713968634605408
step: 290, loss: 0.04188602417707443
step: 300, loss: 0.051526300609111786
step: 310, loss: 0.0004805692005902529
step: 320, loss: 0.10356024652719498
step: 330, loss: 0.11224060505628586
step: 340, loss: 0.06357918679714203
step: 350, loss: 0.06026805564761162
step: 360, loss: 0.08390321582555771
step: 370, loss: 0.09569121897220612
step: 380, loss: 0.11202366650104523
epoch 6: dev_f1=0.741687979539642, f1=0.7012987012987013, best_f1=0.7012987012987013
step: 0, loss: 0.03197016939520836
step: 10, loss: 0.046142756938934326
step: 20, loss: 0.0462825745344162
step: 30, loss: 0.10802353918552399
step: 40, loss: 0.05066541209816933
step: 50, loss: 0.10580456256866455
step: 60, loss: 0.08648952841758728
step: 70, loss: 0.18900145590305328
step: 80, loss: 0.09491585940122604
step: 90, loss: 0.011615855619311333
step: 100, loss: 0.061874065548181534
step: 110, loss: 0.1244596466422081
step: 120, loss: 0.07784538716077805
step: 130, loss: 0.040443915873765945
step: 140, loss: 0.08331261575222015
step: 150, loss: 0.045250244438648224
step: 160, loss: 0.02885103039443493
step: 170, loss: 0.018855804577469826
step: 180, loss: 0.06039762496948242
step: 190, loss: 0.032700151205062866
step: 200, loss: 0.046295300126075745
step: 210, loss: 0.16599512100219727
step: 220, loss: 0.10557859390974045
step: 230, loss: 0.1699007898569107
step: 240, loss: 0.019083354622125626
step: 250, loss: 0.04465359449386597
step: 260, loss: 0.03408239781856537
step: 270, loss: 0.0853302925825119
step: 280, loss: 0.03388172388076782
step: 290, loss: 0.05968591570854187
step: 300, loss: 0.03548772260546684
step: 310, loss: 0.022140072658658028
step: 320, loss: 0.06930260360240936
step: 330, loss: 0.08180557936429977
step: 340, loss: 0.10572487115859985
step: 350, loss: 0.29218387603759766
step: 360, loss: 0.17782577872276306
step: 370, loss: 0.07197728753089905
step: 380, loss: 0.02930782176554203
epoch 7: dev_f1=0.7012345679012345, f1=0.6785714285714286, best_f1=0.7012987012987013
step: 0, loss: 0.17994064092636108
step: 10, loss: 0.1154395192861557
step: 20, loss: 0.08395935595035553
step: 30, loss: 0.059832893311977386
step: 40, loss: 0.09278623759746552
step: 50, loss: 0.03307923302054405
step: 60, loss: 0.04522811621427536
step: 70, loss: 0.06387151777744293
step: 80, loss: 0.12873297929763794
step: 90, loss: 0.019187232479453087
step: 100, loss: 0.11704647541046143
step: 110, loss: 0.11730147898197174
step: 120, loss: 0.05200028792023659
step: 130, loss: 0.017853908240795135
step: 140, loss: 0.07096312940120697
step: 150, loss: 0.1509646624326706
step: 160, loss: 0.09347015619277954
step: 170, loss: 0.055991966277360916
step: 180, loss: 0.03672492876648903
step: 190, loss: 0.04594109579920769
step: 200, loss: 0.0427955761551857
step: 210, loss: 0.06628336012363434
step: 220, loss: 0.1482732743024826
step: 230, loss: 0.08896451443433762
step: 240, loss: 0.026267215609550476
step: 250, loss: 0.0930861383676529
step: 260, loss: 0.08284088969230652
step: 270, loss: 0.0777258351445198
step: 280, loss: 0.04632352292537689
step: 290, loss: 0.07581236213445663
step: 300, loss: 0.039392922073602676
step: 310, loss: 0.023846998810768127
step: 320, loss: 0.03348257765173912
step: 330, loss: 0.053386252373456955
step: 340, loss: 0.04273677244782448
step: 350, loss: 0.19679319858551025
step: 360, loss: 0.025035584345459938
step: 370, loss: 0.1803092211484909
step: 380, loss: 0.06202443689107895
epoch 8: dev_f1=0.7064676616915423, f1=0.6947890818858561, best_f1=0.7012987012987013
step: 0, loss: 0.08470907807350159
step: 10, loss: 0.035839032381772995
step: 20, loss: 0.033532094210386276
step: 30, loss: 0.0905059278011322
step: 40, loss: 0.0964009016752243
step: 50, loss: 0.0448388010263443
step: 60, loss: 0.014813154004514217
step: 70, loss: 0.06366534531116486
step: 80, loss: 0.026576373726129532
step: 90, loss: 0.056811656802892685
step: 100, loss: 0.0004109363944735378
step: 110, loss: 0.056843146681785583
step: 120, loss: 0.07823697477579117
step: 130, loss: 0.0827956348657608
step: 140, loss: 0.04837632551789284
step: 150, loss: 0.036997318267822266
step: 160, loss: 0.002684318693354726
step: 170, loss: 0.12487969547510147
step: 180, loss: 0.19024372100830078
step: 190, loss: 0.003179659601300955
step: 200, loss: 0.06973328441381454
step: 210, loss: 0.046636324375867844
step: 220, loss: 0.18557053804397583
step: 230, loss: 0.06411667168140411
step: 240, loss: 0.0339210107922554
step: 250, loss: 0.02651895396411419
step: 260, loss: 0.07375489920377731
step: 270, loss: 0.0289209745824337
step: 280, loss: 0.09230265021324158
step: 290, loss: 0.051467929035425186
step: 300, loss: 0.1907619833946228
step: 310, loss: 0.09360891580581665
step: 320, loss: 0.027940919622778893
step: 330, loss: 0.10435676574707031
step: 340, loss: 0.1708439737558365
step: 350, loss: 0.05361935496330261
step: 360, loss: 0.0218227356672287
step: 370, loss: 0.05332238972187042
step: 380, loss: 0.012513160705566406
epoch 9: dev_f1=0.7309644670050761, f1=0.691292875989446, best_f1=0.7012987012987013
step: 0, loss: 0.12280344218015671
step: 10, loss: 0.0021656265016645193
step: 20, loss: 0.16007284820079803
step: 30, loss: 0.04435330629348755
step: 40, loss: 0.09022440761327744
step: 50, loss: 0.10127964615821838
step: 60, loss: 0.2383437603712082
step: 70, loss: 0.03673463687300682
step: 80, loss: 0.01844327710568905
step: 90, loss: 0.040013302117586136
step: 100, loss: 0.06127196550369263
step: 110, loss: 0.07251725345849991
step: 120, loss: 0.1442168653011322
step: 130, loss: 0.05548980459570885
step: 140, loss: 0.054121822118759155
step: 150, loss: 0.04395988583564758
step: 160, loss: 0.09319515526294708
step: 170, loss: 0.025141824036836624
step: 180, loss: 0.004782348871231079
step: 190, loss: 0.0012817016104236245
step: 200, loss: 0.04143737629055977
step: 210, loss: 0.036308079957962036
step: 220, loss: 0.08949081599712372
step: 230, loss: 0.12446921318769455
step: 240, loss: 0.023362763226032257
step: 250, loss: 0.12793835997581482
step: 260, loss: 0.03326326608657837
step: 270, loss: 0.19687999784946442
step: 280, loss: 0.07157348096370697
step: 290, loss: 0.05275111272931099
step: 300, loss: 0.12982907891273499
step: 310, loss: 0.05185142904520035
step: 320, loss: 0.13270245492458344
step: 330, loss: 0.08108072727918625
step: 340, loss: 0.007418552413582802
step: 350, loss: 0.08326505869626999
step: 360, loss: 0.05917275696992874
step: 370, loss: 0.036406271159648895
step: 380, loss: 0.0504380501806736
epoch 10: dev_f1=0.7178217821782177, f1=0.684863523573201, best_f1=0.7012987012987013
step: 0, loss: 0.010784431360661983
step: 10, loss: 0.012690993957221508
step: 20, loss: 0.012535546906292439
step: 30, loss: 0.047064732760190964
step: 40, loss: 0.08993703871965408
step: 50, loss: 0.055040325969457626
step: 60, loss: 0.029632046818733215
step: 70, loss: 0.10869225859642029
step: 80, loss: 0.013770228251814842
step: 90, loss: 0.030363714322447777
step: 100, loss: 0.05598092079162598
step: 110, loss: 0.029788825660943985
step: 120, loss: 0.06576959043741226
step: 130, loss: 0.01464440394192934
step: 140, loss: 0.08301068097352982
step: 150, loss: 0.09888767451047897
step: 160, loss: 0.014749887399375439
step: 170, loss: 0.07421989738941193
step: 180, loss: 0.03460962697863579
step: 190, loss: 0.05763385072350502
step: 200, loss: 0.021041879430413246
step: 210, loss: 0.03987124562263489
step: 220, loss: 0.027116017416119576
step: 230, loss: 0.14660198986530304
step: 240, loss: 0.08030857145786285
step: 250, loss: 0.06775208562612534
step: 260, loss: 0.11367957293987274
step: 270, loss: 0.0845952033996582
step: 280, loss: 0.10992512106895447
step: 290, loss: 0.08730463683605194
step: 300, loss: 0.02635648287832737
step: 310, loss: 0.09128667414188385
step: 320, loss: 0.06270499527454376
step: 330, loss: 0.10360027104616165
step: 340, loss: 0.0634181797504425
step: 350, loss: 0.06835738569498062
step: 360, loss: 0.07874906063079834
step: 370, loss: 0.06473678350448608
step: 380, loss: 0.08926308155059814
epoch 11: dev_f1=0.7347931873479319, f1=0.7222222222222223, best_f1=0.7012987012987013
step: 0, loss: 0.03800266236066818
step: 10, loss: 0.04489900544285774
step: 20, loss: 0.09116066247224808
step: 30, loss: 0.045488644391298294
step: 40, loss: 0.019298432394862175
step: 50, loss: 0.02646976336836815
step: 60, loss: 0.015157169662415981
step: 70, loss: 0.13500703871250153
step: 80, loss: 0.12229035794734955
step: 90, loss: 0.005265434272587299
step: 100, loss: 0.060135725885629654
step: 110, loss: 0.029384702444076538
step: 120, loss: 0.10146685689687729
step: 130, loss: 0.11731744557619095
step: 140, loss: 0.06334004551172256
step: 150, loss: 0.04514245688915253
step: 160, loss: 0.0004789238446392119
step: 170, loss: 0.06120343878865242
step: 180, loss: 0.09992077201604843
step: 190, loss: 0.06168103218078613
step: 200, loss: 0.0011615369003266096
step: 210, loss: 0.017115486785769463
step: 220, loss: 0.03657984361052513
step: 230, loss: 0.057442985475063324
step: 240, loss: 0.008768285624682903
step: 250, loss: 0.035858891904354095
step: 260, loss: 0.1635696291923523
step: 270, loss: 0.0011734581785276532
step: 280, loss: 0.039755262434482574
step: 290, loss: 0.08995415270328522
step: 300, loss: 0.05439450219273567
step: 310, loss: 0.05622783675789833
step: 320, loss: 0.03344835713505745
step: 330, loss: 0.07937781512737274
step: 340, loss: 0.054226960986852646
step: 350, loss: 0.15300877392292023
step: 360, loss: 0.07832490652799606
step: 370, loss: 0.060184597969055176
step: 380, loss: 0.1408746987581253
epoch 12: dev_f1=0.7277628032345013, f1=0.7065217391304348, best_f1=0.7012987012987013
step: 0, loss: 0.00018946400086861104
step: 10, loss: 0.0673629567027092
step: 20, loss: 0.03937217965722084
step: 30, loss: 0.01249428279697895
step: 40, loss: 0.04905552417039871
step: 50, loss: 0.009396830573678017
step: 60, loss: 0.01910487934947014
step: 70, loss: 0.0671280175447464
step: 80, loss: 0.053586237132549286
step: 90, loss: 0.024802662432193756
step: 100, loss: 0.030648520216345787
step: 110, loss: 0.07201720029115677
step: 120, loss: 0.014199277386069298
step: 130, loss: 0.0748995840549469
step: 140, loss: 0.07362987101078033
step: 150, loss: 0.03247653692960739
step: 160, loss: 0.005359499249607325
step: 170, loss: 0.023537511005997658
step: 180, loss: 0.04418516904115677
step: 190, loss: 0.023318946361541748
step: 200, loss: 0.08297786116600037
step: 210, loss: 0.08402986824512482
step: 220, loss: 0.1170182004570961
step: 230, loss: 0.06508956104516983
step: 240, loss: 0.0013226965675130486
step: 250, loss: 0.1019628494977951
step: 260, loss: 0.2669685482978821
step: 270, loss: 0.054378442466259
step: 280, loss: 0.08247186243534088
step: 290, loss: 0.012094552628695965
step: 300, loss: 0.05173715204000473
step: 310, loss: 0.05513134226202965
step: 320, loss: 0.1066252589225769
step: 330, loss: 0.056183915585279465
step: 340, loss: 0.026677589863538742
step: 350, loss: 0.02233717404305935
step: 360, loss: 0.038045115768909454
step: 370, loss: 0.012118394486606121
step: 380, loss: 0.015646956861019135
epoch 13: dev_f1=0.7174447174447175, f1=0.7044334975369458, best_f1=0.7012987012987013
step: 0, loss: 0.042250536382198334
step: 10, loss: 0.029708921909332275
step: 20, loss: 0.06025002524256706
step: 30, loss: 0.060847312211990356
step: 40, loss: 0.05652662739157677
step: 50, loss: 0.007137085311114788
step: 60, loss: 0.05607854574918747
step: 70, loss: 0.1282111406326294
step: 80, loss: 0.055597346276044846
step: 90, loss: 0.03503680229187012
step: 100, loss: 0.06762854754924774
step: 110, loss: 0.09258858859539032
step: 120, loss: 0.0007678713882341981
step: 130, loss: 0.04371625930070877
step: 140, loss: 0.024089278653264046
step: 150, loss: 0.011212789453566074
step: 160, loss: 0.042127687484025955
step: 170, loss: 0.05902664735913277
step: 180, loss: 0.07751297205686569
step: 190, loss: 0.03459743782877922
step: 200, loss: 0.05424480512738228
step: 210, loss: 0.012919159606099129
step: 220, loss: 0.08877061307430267
step: 230, loss: 0.08856083452701569
step: 240, loss: 0.02127680741250515
step: 250, loss: 0.008259236812591553
step: 260, loss: 0.0088221225887537
step: 270, loss: 0.043868858367204666
step: 280, loss: 0.02882622927427292
step: 290, loss: 0.01601669006049633
step: 300, loss: 0.011478916741907597
step: 310, loss: 0.11257028579711914
step: 320, loss: 0.03040388412773609
step: 330, loss: 0.044879041612148285
step: 340, loss: 0.002503341296687722
step: 350, loss: 0.005396360065788031
step: 360, loss: 0.021774446591734886
step: 370, loss: 0.04961990937590599
step: 380, loss: 0.00676247151568532
epoch 14: dev_f1=0.7308641975308642, f1=0.7079207920792079, best_f1=0.7012987012987013
step: 0, loss: 0.038812533020973206
step: 10, loss: 0.020709052681922913
step: 20, loss: 0.04421298950910568
step: 30, loss: 0.04580586776137352
step: 40, loss: 0.018594523891806602
step: 50, loss: 0.006572748068720102
step: 60, loss: 0.023946696892380714
step: 70, loss: 0.03765083849430084
step: 80, loss: 0.031330253928899765
step: 90, loss: 0.0649494156241417
step: 100, loss: 0.05758523568511009
step: 110, loss: 0.025501679629087448
step: 120, loss: 0.04878934845328331
step: 130, loss: 0.03226468339562416
step: 140, loss: 0.01662534289062023
step: 150, loss: 0.3095833361148834
step: 160, loss: 0.030017537996172905
step: 170, loss: 0.05958672612905502
step: 180, loss: 0.04277883097529411
step: 190, loss: 0.06383130699396133
step: 200, loss: 0.01740466244518757
step: 210, loss: 0.09658673405647278
step: 220, loss: 0.031328488141298294
step: 230, loss: 0.10258596390485764
step: 240, loss: 0.031967390328645706
step: 250, loss: 0.20570659637451172
step: 260, loss: 0.03838834911584854
step: 270, loss: 0.03626885637640953
step: 280, loss: 0.022444041445851326
step: 290, loss: 0.0012687970884144306
step: 300, loss: 0.043991852551698685
step: 310, loss: 0.06115332990884781
step: 320, loss: 0.05666879937052727
step: 330, loss: 0.0571526437997818
step: 340, loss: 0.040117476135492325
step: 350, loss: 0.14609003067016602
step: 360, loss: 0.06505872309207916
step: 370, loss: 0.08534561097621918
step: 380, loss: 0.05351858213543892
epoch 15: dev_f1=0.7281795511221945, f1=0.7082294264339153, best_f1=0.7012987012987013
step: 0, loss: 0.0034362757578492165
step: 10, loss: 0.020379330962896347
step: 20, loss: 0.07960467040538788
step: 30, loss: 0.0854649469256401
step: 40, loss: 0.015189925208687782
step: 50, loss: 0.009788240306079388
step: 60, loss: 0.024162128567695618
step: 70, loss: 0.065607950091362
step: 80, loss: 0.004697564989328384
step: 90, loss: 0.028552215546369553
step: 100, loss: 0.006707474123686552
step: 110, loss: 0.04952625557780266
step: 120, loss: 0.006114451680332422
step: 130, loss: 0.01093031745404005
step: 140, loss: 0.002611778909340501
step: 150, loss: 0.017508406192064285
step: 160, loss: 0.03363235294818878
step: 170, loss: 0.01115501020103693
step: 180, loss: 0.05356696993112564
step: 190, loss: 0.17692908644676208
step: 200, loss: 0.024661976844072342
step: 210, loss: 0.02348075993359089
step: 220, loss: 0.0027035789098590612
step: 230, loss: 0.0367003008723259
step: 240, loss: 0.04058867320418358
step: 250, loss: 0.0018812560010701418
step: 260, loss: 0.01793426275253296
step: 270, loss: 0.04393603280186653
step: 280, loss: 0.008974413387477398
step: 290, loss: 0.02671380154788494
step: 300, loss: 0.08550422638654709
step: 310, loss: 0.0013658006209880114
step: 320, loss: 0.037764787673950195
step: 330, loss: 0.12693339586257935
step: 340, loss: 0.01127496175467968
step: 350, loss: 0.0023489026352763176
step: 360, loss: 0.026801321655511856
step: 370, loss: 9.360253170598298e-05
step: 380, loss: 0.002338157733902335
epoch 16: dev_f1=0.7121951219512195, f1=0.693069306930693, best_f1=0.7012987012987013
step: 0, loss: 0.021167244762182236
step: 10, loss: 0.020173920318484306
step: 20, loss: 0.04635337367653847
step: 30, loss: 0.03918169438838959
step: 40, loss: 0.06452114880084991
step: 50, loss: 0.026293357834219933
step: 60, loss: 0.08862652629613876
step: 70, loss: 0.09261318296194077
step: 80, loss: 0.05155090615153313
step: 90, loss: 0.022430378943681717
step: 100, loss: 0.048225946724414825
step: 110, loss: 0.018455814570188522
step: 120, loss: 0.02364051714539528
step: 130, loss: 8.974499360192567e-05
step: 140, loss: 0.027265192940831184
step: 150, loss: 0.01817473955452442
step: 160, loss: 7.069828279782087e-05
step: 170, loss: 0.03164611756801605
step: 180, loss: 0.019500862807035446
step: 190, loss: 0.05447852239012718
step: 200, loss: 0.03675642982125282
step: 210, loss: 0.08107588440179825
step: 220, loss: 0.05235482007265091
step: 230, loss: 0.04719694331288338
step: 240, loss: 0.00010638563253451139
step: 250, loss: 0.029411545023322105
step: 260, loss: 0.040413230657577515
step: 270, loss: 0.04844578728079796
step: 280, loss: 0.08094242215156555
step: 290, loss: 0.002426228951662779
step: 300, loss: 0.02284092828631401
step: 310, loss: 0.06467069685459137
step: 320, loss: 0.0006302708061411977
step: 330, loss: 0.08958782255649567
step: 340, loss: 0.07425865530967712
step: 350, loss: 0.013691102154552937
step: 360, loss: 0.13978879153728485
step: 370, loss: 0.019387125968933105
step: 380, loss: 0.02847371995449066
epoch 17: dev_f1=0.7250000000000001, f1=0.6945812807881775, best_f1=0.7012987012987013
step: 0, loss: 0.0666687861084938
step: 10, loss: 0.0417625829577446
step: 20, loss: 0.06114530563354492
step: 30, loss: 0.017484234645962715
step: 40, loss: 0.07986599206924438
step: 50, loss: 0.03024814836680889
step: 60, loss: 0.026329929009079933
step: 70, loss: 0.06178359314799309
step: 80, loss: 0.01842615008354187
step: 90, loss: 0.020324932411313057
step: 100, loss: 0.005226321518421173
step: 110, loss: 0.04137549549341202
step: 120, loss: 0.0025994889438152313
step: 130, loss: 0.09637608379125595
step: 140, loss: 0.014403840526938438
step: 150, loss: 0.05551251769065857
step: 160, loss: 0.030836278572678566
step: 170, loss: 0.02464967966079712
step: 180, loss: 0.00706350477412343
step: 190, loss: 0.019457636401057243
step: 200, loss: 0.024752996861934662
step: 210, loss: 0.09112890064716339
step: 220, loss: 0.0018824608996510506
step: 230, loss: 0.21573160588741302
step: 240, loss: 0.0004124042752664536
step: 250, loss: 0.005432913079857826
step: 260, loss: 0.09378664940595627
step: 270, loss: 0.012659850530326366
step: 280, loss: 0.04190801829099655
step: 290, loss: 0.0014171053189784288
step: 300, loss: 0.055824119597673416
step: 310, loss: 0.007704040035605431
step: 320, loss: 0.019754625856876373
step: 330, loss: 0.08661326766014099
step: 340, loss: 0.019732140004634857
step: 350, loss: 0.0007727093761786819
step: 360, loss: 0.04622821509838104
step: 370, loss: 0.03426801785826683
step: 380, loss: 0.019557029008865356
epoch 18: dev_f1=0.7131367292225201, f1=0.6864864864864865, best_f1=0.7012987012987013
step: 0, loss: 0.06074700877070427
step: 10, loss: 0.03818604722619057
step: 20, loss: 0.03774263709783554
step: 30, loss: 0.03942503407597542
step: 40, loss: 0.057061318308115005
step: 50, loss: 0.0059618111699819565
step: 60, loss: 0.01615787111222744
step: 70, loss: 0.0008359572384506464
step: 80, loss: 0.06820964813232422
step: 90, loss: 0.08055080473423004
step: 100, loss: 0.024199549108743668
step: 110, loss: 0.08661250025033951
step: 120, loss: 0.025333117693662643
step: 130, loss: 0.11380641162395477
step: 140, loss: 0.011155246756970882
step: 150, loss: 0.01769191585481167
step: 160, loss: 0.021940065547823906
step: 170, loss: 0.009036100469529629
step: 180, loss: 2.0503541236394085e-05
step: 190, loss: 0.04857412353157997
step: 200, loss: 0.05697638541460037
step: 210, loss: 0.01293052826076746
step: 220, loss: 0.03826586902141571
step: 230, loss: 0.03279394283890724
step: 240, loss: 0.018701186403632164
step: 250, loss: 0.0670633390545845
step: 260, loss: 0.021501215174794197
step: 270, loss: 0.032589737325906754
step: 280, loss: 0.07271453738212585
step: 290, loss: 0.061997245997190475
step: 300, loss: 0.0467432476580143
step: 310, loss: 0.07588065415620804
step: 320, loss: 0.046639107167720795
step: 330, loss: 0.03774513676762581
step: 340, loss: 7.437256135744974e-05
step: 350, loss: 0.00024174840655177832
step: 360, loss: 0.04048359394073486
step: 370, loss: 0.06214294582605362
step: 380, loss: 0.008302359841763973
epoch 19: dev_f1=0.7071240105540898, f1=0.6774193548387096, best_f1=0.7012987012987013
step: 0, loss: 7.152953185141087e-05
step: 10, loss: 0.023490402847528458
step: 20, loss: 0.004448696970939636
step: 30, loss: 0.0007297482225112617
step: 40, loss: 1.95647771761287e-05
step: 50, loss: 0.039500195533037186
step: 60, loss: 0.017578015103936195
step: 70, loss: 0.017104389145970345
step: 80, loss: 0.06428572535514832
step: 90, loss: 0.0036689203698188066
step: 100, loss: 0.014983083121478558
step: 110, loss: 0.1281910091638565
step: 120, loss: 0.056094326078891754
step: 130, loss: 0.0139290951192379
step: 140, loss: 0.05769919604063034
step: 150, loss: 0.025334779173135757
step: 160, loss: 0.016515204682946205
step: 170, loss: 0.030285146087408066
step: 180, loss: 0.0013363079633563757
step: 190, loss: 0.13396374881267548
step: 200, loss: 0.00045846751891076565
step: 210, loss: 0.00015055129188112915
step: 220, loss: 0.08439534157514572
step: 230, loss: 0.05457201972603798
step: 240, loss: 0.02466827630996704
step: 250, loss: 0.056040871888399124
step: 260, loss: 0.023588761687278748
step: 270, loss: 0.016531482338905334
step: 280, loss: 1.8052480299957097e-05
step: 290, loss: 0.009170676581561565
step: 300, loss: 0.0012506337370723486
step: 310, loss: 0.022654294967651367
step: 320, loss: 0.06985392421483994
step: 330, loss: 0.022095533087849617
step: 340, loss: 0.11293698102235794
step: 350, loss: 0.15843534469604492
step: 360, loss: 0.027877086773514748
step: 370, loss: 0.00047132003237493336
step: 380, loss: 0.028586730360984802
epoch 20: dev_f1=0.7052631578947368, f1=0.6774193548387096, best_f1=0.7012987012987013
