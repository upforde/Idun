cuda
Device: cuda
step: 0, loss: 0.5711474418640137
step: 10, loss: 0.31788989901542664
step: 20, loss: 0.19163499772548676
step: 30, loss: 0.2509951591491699
step: 40, loss: 0.4741976857185364
step: 50, loss: 0.2616790533065796
step: 60, loss: 0.3251195251941681
step: 70, loss: 0.3825772702693939
step: 80, loss: 0.29820284247398376
step: 90, loss: 0.4027099907398224
step: 100, loss: 0.4623989462852478
step: 110, loss: 0.3031042218208313
step: 120, loss: 0.5177862048149109
step: 130, loss: 0.31155824661254883
step: 140, loss: 0.3315381407737732
step: 150, loss: 0.2913696765899658
step: 160, loss: 0.16861708462238312
step: 170, loss: 0.2727375328540802
step: 180, loss: 0.40565115213394165
step: 190, loss: 0.5490676164627075
step: 200, loss: 0.23517154157161713
step: 210, loss: 0.33725568652153015
step: 220, loss: 0.2551681101322174
step: 230, loss: 0.22735841572284698
step: 240, loss: 0.263173371553421
step: 250, loss: 0.17373794317245483
step: 260, loss: 0.06727897375822067
step: 270, loss: 0.17578256130218506
step: 280, loss: 0.24587838351726532
step: 290, loss: 0.08769094944000244
step: 300, loss: 0.14293718338012695
step: 310, loss: 0.23922432959079742
step: 320, loss: 0.164297416806221
step: 330, loss: 0.2020290493965149
step: 340, loss: 0.20269256830215454
step: 350, loss: 0.2765454053878784
epoch 1: dev_f1=0.6707070707070707, f1=0.6475095785440612, best_f1=0.6475095785440612
step: 0, loss: 0.17532671988010406
step: 10, loss: 0.1265104115009308
step: 20, loss: 0.256099134683609
step: 30, loss: 0.13680799305438995
step: 40, loss: 0.3146987557411194
step: 50, loss: 0.07423703372478485
step: 60, loss: 0.2647762894630432
step: 70, loss: 0.11564775556325912
step: 80, loss: 0.19610092043876648
step: 90, loss: 0.08077673614025116
step: 100, loss: 0.20637564361095428
step: 110, loss: 0.19453617930412292
step: 120, loss: 0.16396409273147583
step: 130, loss: 0.23983843624591827
step: 140, loss: 0.15714189410209656
step: 150, loss: 0.1173001304268837
step: 160, loss: 0.19472967088222504
step: 170, loss: 0.21678555011749268
step: 180, loss: 0.19692879915237427
step: 190, loss: 0.208521768450737
step: 200, loss: 0.18322990834712982
step: 210, loss: 0.07879528403282166
step: 220, loss: 0.15252190828323364
step: 230, loss: 0.1374012678861618
step: 240, loss: 0.11484705656766891
step: 250, loss: 0.14758415520191193
step: 260, loss: 0.05324160307645798
step: 270, loss: 0.14446087181568146
step: 280, loss: 0.4166855812072754
step: 290, loss: 0.1643926054239273
step: 300, loss: 0.12209145724773407
step: 310, loss: 0.1271841824054718
step: 320, loss: 0.23294612765312195
step: 330, loss: 0.10561415553092957
step: 340, loss: 0.05017968267202377
step: 350, loss: 0.21287046372890472
epoch 2: dev_f1=0.7499999999999999, f1=0.7608200455580866, best_f1=0.7608200455580866
step: 0, loss: 0.1929541826248169
step: 10, loss: 0.607367753982544
step: 20, loss: 0.10315550863742828
step: 30, loss: 0.3437715470790863
step: 40, loss: 0.09346792101860046
step: 50, loss: 0.0889967828989029
step: 60, loss: 0.012481504119932652
step: 70, loss: 0.08347555249929428
step: 80, loss: 0.16805008053779602
step: 90, loss: 0.1331794708967209
step: 100, loss: 0.17745375633239746
step: 110, loss: 0.10962891578674316
step: 120, loss: 0.1342964768409729
step: 130, loss: 0.17390650510787964
step: 140, loss: 0.08193370699882507
step: 150, loss: 0.10153058916330338
step: 160, loss: 0.15207727253437042
step: 170, loss: 0.0808071717619896
step: 180, loss: 0.1765381246805191
step: 190, loss: 0.0788889229297638
step: 200, loss: 0.08537717908620834
step: 210, loss: 0.07009710371494293
step: 220, loss: 0.07787565886974335
step: 230, loss: 0.14013732969760895
step: 240, loss: 0.16854873299598694
step: 250, loss: 0.16036750376224518
step: 260, loss: 0.08197320252656937
step: 270, loss: 0.10950782150030136
step: 280, loss: 0.162192240357399
step: 290, loss: 0.07267250120639801
step: 300, loss: 0.05747321620583534
step: 310, loss: 0.07958561182022095
step: 320, loss: 0.20460230112075806
step: 330, loss: 0.26169663667678833
step: 340, loss: 0.1368994563817978
step: 350, loss: 0.07555204629898071
epoch 3: dev_f1=0.7731481481481483, f1=0.8044444444444446, best_f1=0.8044444444444446
step: 0, loss: 0.08476223796606064
step: 10, loss: 0.13005822896957397
step: 20, loss: 0.09416229277849197
step: 30, loss: 0.06032000482082367
step: 40, loss: 0.12461266666650772
step: 50, loss: 0.15017366409301758
step: 60, loss: 0.02488880418241024
step: 70, loss: 0.0508931502699852
step: 80, loss: 0.08452553302049637
step: 90, loss: 0.14119866490364075
step: 100, loss: 0.17471908032894135
step: 110, loss: 0.12947137653827667
step: 120, loss: 0.17192618548870087
step: 130, loss: 0.0772491917014122
step: 140, loss: 0.10633909702301025
step: 150, loss: 0.10822141170501709
step: 160, loss: 0.1291157305240631
step: 170, loss: 0.07799024879932404
step: 180, loss: 0.10945531725883484
step: 190, loss: 0.29726284742355347
step: 200, loss: 0.12463561445474625
step: 210, loss: 0.05642811581492424
step: 220, loss: 0.11102811247110367
step: 230, loss: 0.0905398279428482
step: 240, loss: 0.051500577479600906
step: 250, loss: 0.087528295814991
step: 260, loss: 0.12032485753297806
step: 270, loss: 0.09704682230949402
step: 280, loss: 0.13100427389144897
step: 290, loss: 0.33837732672691345
step: 300, loss: 0.0977386087179184
step: 310, loss: 0.024987852200865746
step: 320, loss: 0.12813113629817963
step: 330, loss: 0.03821275755763054
step: 340, loss: 0.17270749807357788
step: 350, loss: 0.00568513385951519
epoch 4: dev_f1=0.7845804988662132, f1=0.8151447661469933, best_f1=0.8151447661469933
step: 0, loss: 0.15216051042079926
step: 10, loss: 0.255351185798645
step: 20, loss: 0.060136497020721436
step: 30, loss: 0.10446600615978241
step: 40, loss: 0.16181612014770508
step: 50, loss: 0.030548453330993652
step: 60, loss: 0.08797384053468704
step: 70, loss: 0.03071986511349678
step: 80, loss: 0.050399672240018845
step: 90, loss: 0.15019163489341736
step: 100, loss: 0.07004854083061218
step: 110, loss: 0.10685988515615463
step: 120, loss: 0.1640540063381195
step: 130, loss: 0.07610860466957092
step: 140, loss: 0.0839255154132843
step: 150, loss: 0.07924959808588028
step: 160, loss: 0.06320706009864807
step: 170, loss: 0.06859824061393738
step: 180, loss: 0.18141409754753113
step: 190, loss: 0.15009701251983643
step: 200, loss: 0.08035200089216232
step: 210, loss: 0.08990588784217834
step: 220, loss: 0.11044604331254959
step: 230, loss: 0.1078779399394989
step: 240, loss: 0.057995088398456573
step: 250, loss: 0.1340961903333664
step: 260, loss: 0.055532850325107574
step: 270, loss: 0.020612630993127823
step: 280, loss: 0.08656679093837738
step: 290, loss: 0.07931648194789886
step: 300, loss: 0.1248231902718544
step: 310, loss: 0.015398182906210423
step: 320, loss: 0.029309581965208054
step: 330, loss: 0.051959119737148285
step: 340, loss: 0.15103310346603394
step: 350, loss: 0.08130940794944763
epoch 5: dev_f1=0.8179669030732861, f1=0.7954022988505747, best_f1=0.7954022988505747
step: 0, loss: 0.07496777921915054
step: 10, loss: 0.0862748920917511
step: 20, loss: 0.1319420337677002
step: 30, loss: 0.1557476967573166
step: 40, loss: 0.20344278216362
step: 50, loss: 0.0954301580786705
step: 60, loss: 0.04227918013930321
step: 70, loss: 0.09030601382255554
step: 80, loss: 0.13810968399047852
step: 90, loss: 0.05849265679717064
step: 100, loss: 0.08971614390611649
step: 110, loss: 0.10559435188770294
step: 120, loss: 0.10665809363126755
step: 130, loss: 0.06610023975372314
step: 140, loss: 0.08397436887025833
step: 150, loss: 0.08489198982715607
step: 160, loss: 0.13190393149852753
step: 170, loss: 0.09069754183292389
step: 180, loss: 0.06653207540512085
step: 190, loss: 0.03905463591217995
step: 200, loss: 0.06987092643976212
step: 210, loss: 0.12708312273025513
step: 220, loss: 0.09694835543632507
step: 230, loss: 0.11102890968322754
step: 240, loss: 0.1243353933095932
step: 250, loss: 0.0293031744658947
step: 260, loss: 0.2567567527294159
step: 270, loss: 0.10261186212301254
step: 280, loss: 0.16824911534786224
step: 290, loss: 0.08523508161306381
step: 300, loss: 0.11492519080638885
step: 310, loss: 0.03645089268684387
step: 320, loss: 0.04320112615823746
step: 330, loss: 0.07646258175373077
step: 340, loss: 0.04985780641436577
step: 350, loss: 0.04890551418066025
epoch 6: dev_f1=0.8297362110311751, f1=0.8177570093457943, best_f1=0.8177570093457943
step: 0, loss: 0.05415608361363411
step: 10, loss: 0.037265632301568985
step: 20, loss: 0.19761602580547333
step: 30, loss: 0.10558810830116272
step: 40, loss: 0.1192718967795372
step: 50, loss: 0.009067555889487267
step: 60, loss: 0.18773987889289856
step: 70, loss: 0.09984349459409714
step: 80, loss: 0.09086348116397858
step: 90, loss: 0.09425985813140869
step: 100, loss: 0.03440976142883301
step: 110, loss: 0.026561615988612175
step: 120, loss: 0.02418508753180504
step: 130, loss: 0.13394294679164886
step: 140, loss: 0.05675003305077553
step: 150, loss: 0.08216496556997299
step: 160, loss: 0.10903751105070114
step: 170, loss: 0.08116462081670761
step: 180, loss: 0.0611080639064312
step: 190, loss: 0.02462896518409252
step: 200, loss: 0.07259077578783035
step: 210, loss: 0.14488089084625244
step: 220, loss: 0.09034475684165955
step: 230, loss: 0.06226023659110069
step: 240, loss: 0.1756201982498169
step: 250, loss: 0.19714520871639252
step: 260, loss: 0.10183559358119965
step: 270, loss: 0.05673510208725929
step: 280, loss: 0.1324291229248047
step: 290, loss: 0.10340746492147446
step: 300, loss: 0.08349384367465973
step: 310, loss: 0.09560847282409668
step: 320, loss: 0.08328887820243835
step: 330, loss: 0.2641279101371765
step: 340, loss: 0.09770098328590393
step: 350, loss: 0.19294312596321106
epoch 7: dev_f1=0.8116591928251121, f1=0.8043956043956044, best_f1=0.8177570093457943
step: 0, loss: 0.11596611142158508
step: 10, loss: 0.10495150834321976
step: 20, loss: 0.08883102983236313
step: 30, loss: 0.03571636602282524
step: 40, loss: 0.1095806136727333
step: 50, loss: 0.30889633297920227
step: 60, loss: 0.08961915969848633
step: 70, loss: 0.03566208854317665
step: 80, loss: 0.06797919422388077
step: 90, loss: 0.07884581387042999
step: 100, loss: 0.13376390933990479
step: 110, loss: 0.07412894070148468
step: 120, loss: 0.09271086752414703
step: 130, loss: 0.058649271726608276
step: 140, loss: 0.11578530818223953
step: 150, loss: 0.06696419417858124
step: 160, loss: 0.12188242375850677
step: 170, loss: 0.07723639160394669
step: 180, loss: 0.12378235906362534
step: 190, loss: 0.04122592508792877
step: 200, loss: 0.0665428414940834
step: 210, loss: 0.08342227339744568
step: 220, loss: 0.07241662591695786
step: 230, loss: 0.13995568454265594
step: 240, loss: 0.099482960999012
step: 250, loss: 0.10116419196128845
step: 260, loss: 0.02313312329351902
step: 270, loss: 0.0688500925898552
step: 280, loss: 0.11033240705728531
step: 290, loss: 0.14017103612422943
step: 300, loss: 0.16359281539916992
step: 310, loss: 0.10942622274160385
step: 320, loss: 0.0695115402340889
step: 330, loss: 0.06667115539312363
step: 340, loss: 0.0721835121512413
step: 350, loss: 0.096444271504879
epoch 8: dev_f1=0.8341013824884792, f1=0.8136363636363636, best_f1=0.8136363636363636
step: 0, loss: 0.07778917998075485
step: 10, loss: 0.07975717633962631
step: 20, loss: 0.15022212266921997
step: 30, loss: 0.10480725020170212
step: 40, loss: 0.177704319357872
step: 50, loss: 0.06281746923923492
step: 60, loss: 0.09689072519540787
step: 70, loss: 0.10649853199720383
step: 80, loss: 0.01599837653338909
step: 90, loss: 0.021563738584518433
step: 100, loss: 0.04972191900014877
step: 110, loss: 0.08125737309455872
step: 120, loss: 0.07347399741411209
step: 130, loss: 0.02149946615099907
step: 140, loss: 0.09779928624629974
step: 150, loss: 0.11279226839542389
step: 160, loss: 0.14566664397716522
step: 170, loss: 0.06894025951623917
step: 180, loss: 0.23307855427265167
step: 190, loss: 0.08690449595451355
step: 200, loss: 0.10293581336736679
step: 210, loss: 0.05124002695083618
step: 220, loss: 0.06574971228837967
step: 230, loss: 0.058610498905181885
step: 240, loss: 0.0627228394150734
step: 250, loss: 0.07886071503162384
step: 260, loss: 0.12807931005954742
step: 270, loss: 0.052878305315971375
step: 280, loss: 0.09056356549263
step: 290, loss: 0.07359836995601654
step: 300, loss: 0.048541128635406494
step: 310, loss: 0.12092536687850952
step: 320, loss: 0.1547907143831253
step: 330, loss: 0.06076803430914879
step: 340, loss: 0.11957848817110062
step: 350, loss: 0.0408133827149868
epoch 9: dev_f1=0.8207547169811321, f1=0.8310502283105023, best_f1=0.8136363636363636
step: 0, loss: 0.08362042158842087
step: 10, loss: 0.2692395746707916
step: 20, loss: 0.05542800948023796
step: 30, loss: 0.13547246158123016
step: 40, loss: 0.03630287945270538
step: 50, loss: 0.05319664254784584
step: 60, loss: 0.04023747518658638
step: 70, loss: 0.05829732492566109
step: 80, loss: 0.1100827157497406
step: 90, loss: 0.08410652726888657
step: 100, loss: 0.10264139622449875
step: 110, loss: 0.05308910831809044
step: 120, loss: 0.0545668788254261
step: 130, loss: 0.11236580461263657
step: 140, loss: 0.049121223390102386
step: 150, loss: 0.06187687814235687
step: 160, loss: 0.13518080115318298
step: 170, loss: 0.11591849476099014
step: 180, loss: 0.03998994082212448
step: 190, loss: 0.05663101375102997
step: 200, loss: 0.06965917348861694
step: 210, loss: 0.029416799545288086
step: 220, loss: 0.12403597682714462
step: 230, loss: 0.12745177745819092
step: 240, loss: 0.05206258222460747
step: 250, loss: 0.08778288215398788
step: 260, loss: 0.17283932864665985
step: 270, loss: 0.13200244307518005
step: 280, loss: 0.12918367981910706
step: 290, loss: 0.05055389553308487
step: 300, loss: 0.12327112257480621
step: 310, loss: 0.2725452780723572
step: 320, loss: 0.05811005085706711
step: 330, loss: 0.0569419227540493
step: 340, loss: 0.0589594729244709
step: 350, loss: 0.11977743357419968
epoch 10: dev_f1=0.8187919463087249, f1=0.8260869565217391, best_f1=0.8136363636363636
step: 0, loss: 0.08756221830844879
step: 10, loss: 0.05072123929858208
step: 20, loss: 0.07082267850637436
step: 30, loss: 0.07928800582885742
step: 40, loss: 0.18354596197605133
step: 50, loss: 0.02195943146944046
step: 60, loss: 0.055619530379772186
step: 70, loss: 0.0934533029794693
step: 80, loss: 0.09779371321201324
step: 90, loss: 0.13935859501361847
step: 100, loss: 0.08011473715305328
step: 110, loss: 0.11325135082006454
step: 120, loss: 0.11017901450395584
step: 130, loss: 0.05836392194032669
step: 140, loss: 0.09611667692661285
step: 150, loss: 0.06901762634515762
step: 160, loss: 0.08710535615682602
step: 170, loss: 0.09157752245664597
step: 180, loss: 0.03868715837597847
step: 190, loss: 0.06080709025263786
step: 200, loss: 0.05047187954187393
step: 210, loss: 0.03564486652612686
step: 220, loss: 0.16841956973075867
step: 230, loss: 0.07444807887077332
step: 240, loss: 0.08643656224012375
step: 250, loss: 0.07686252146959305
step: 260, loss: 0.11605693399906158
step: 270, loss: 0.033651214092969894
step: 280, loss: 0.08671024441719055
step: 290, loss: 0.08061759173870087
step: 300, loss: 0.06523532420396805
step: 310, loss: 0.06170320510864258
step: 320, loss: 0.12023825198411942
step: 330, loss: 0.08349330723285675
step: 340, loss: 0.12384814023971558
step: 350, loss: 0.022317873314023018
epoch 11: dev_f1=0.8310502283105023, f1=0.8400000000000001, best_f1=0.8136363636363636
step: 0, loss: 0.07556666433811188
step: 10, loss: 0.14723855257034302
step: 20, loss: 0.015530029311776161
step: 30, loss: 0.06593874096870422
step: 40, loss: 0.06590881198644638
step: 50, loss: 0.07985839247703552
step: 60, loss: 0.09281309694051743
step: 70, loss: 0.09321124106645584
step: 80, loss: 0.04641886427998543
step: 90, loss: 0.03053157404065132
step: 100, loss: 0.09139804542064667
step: 110, loss: 0.09804342687129974
step: 120, loss: 0.06529254466295242
step: 130, loss: 0.05443151295185089
step: 140, loss: 0.02104945480823517
step: 150, loss: 0.06326533108949661
step: 160, loss: 0.05216754600405693
step: 170, loss: 0.06064758077263832
step: 180, loss: 0.1092170849442482
step: 190, loss: 0.10988976061344147
step: 200, loss: 0.002881874330341816
step: 210, loss: 0.04995454102754593
step: 220, loss: 0.1001024916768074
step: 230, loss: 0.05407428368926048
step: 240, loss: 0.04945749044418335
step: 250, loss: 0.058155421167612076
step: 260, loss: 0.13186295330524445
step: 270, loss: 0.09269484877586365
step: 280, loss: 0.09020215272903442
step: 290, loss: 0.052281491458415985
step: 300, loss: 0.11604908108711243
step: 310, loss: 0.044535376131534576
step: 320, loss: 0.0451606921851635
step: 330, loss: 0.04615902900695801
step: 340, loss: 0.061575718224048615
step: 350, loss: 0.04427415505051613
epoch 12: dev_f1=0.803921568627451, f1=0.8403755868544601, best_f1=0.8136363636363636
step: 0, loss: 0.11842872202396393
step: 10, loss: 0.031411491334438324
step: 20, loss: 0.08228521794080734
step: 30, loss: 0.08059404790401459
step: 40, loss: 0.02204808034002781
step: 50, loss: 0.07939867675304413
step: 60, loss: 0.05461100488901138
step: 70, loss: 0.005883749574422836
step: 80, loss: 0.09078975021839142
step: 90, loss: 0.0835791528224945
step: 100, loss: 0.0686834305524826
step: 110, loss: 0.08132008463144302
step: 120, loss: 0.16183175146579742
step: 130, loss: 0.014526311308145523
step: 140, loss: 0.06997911632061005
step: 150, loss: 0.09100911021232605
step: 160, loss: 0.09037866443395615
step: 170, loss: 0.012075746431946754
step: 180, loss: 0.17002570629119873
step: 190, loss: 0.041351426392793655
step: 200, loss: 0.06922957301139832
step: 210, loss: 0.15060292184352875
step: 220, loss: 0.04671822488307953
step: 230, loss: 0.06636420637369156
step: 240, loss: 0.16665777564048767
step: 250, loss: 0.08854563534259796
step: 260, loss: 0.059251509606838226
step: 270, loss: 0.06592321395874023
step: 280, loss: 0.08257501572370529
step: 290, loss: 0.042467184364795685
step: 300, loss: 0.11584458500146866
step: 310, loss: 0.10967186838388443
step: 320, loss: 0.09747818112373352
step: 330, loss: 0.11284422129392624
step: 340, loss: 0.06558416783809662
step: 350, loss: 0.0761217549443245
epoch 13: dev_f1=0.7971014492753623, f1=0.8266033254156769, best_f1=0.8136363636363636
step: 0, loss: 0.13905572891235352
step: 10, loss: 0.1248432844877243
step: 20, loss: 0.063860684633255
step: 30, loss: 0.0566411055624485
step: 40, loss: 3.6253666621632874e-05
step: 50, loss: 0.0829947218298912
step: 60, loss: 0.0878794863820076
step: 70, loss: 0.06306266039609909
step: 80, loss: 0.026959173381328583
step: 90, loss: 0.0009758217493072152
step: 100, loss: 0.14797814190387726
step: 110, loss: 0.07592590153217316
step: 120, loss: 0.024335429072380066
step: 130, loss: 0.03406652808189392
step: 140, loss: 0.06455425918102264
step: 150, loss: 0.0612691268324852
step: 160, loss: 0.12595593929290771
step: 170, loss: 0.10067475587129593
step: 180, loss: 0.04126065596938133
step: 190, loss: 0.023291250690817833
step: 200, loss: 0.01856406219303608
step: 210, loss: 0.050321877002716064
step: 220, loss: 0.07407677173614502
step: 230, loss: 0.08144879341125488
step: 240, loss: 0.06534212082624435
step: 250, loss: 0.043961361050605774
step: 260, loss: 0.11508886516094208
step: 270, loss: 8.288126264233142e-05
step: 280, loss: 0.13821128010749817
step: 290, loss: 0.09099875390529633
step: 300, loss: 0.037835121154785156
step: 310, loss: 0.049294255673885345
step: 320, loss: 0.15732382237911224
step: 330, loss: 0.009062753058969975
step: 340, loss: 0.003364721080288291
step: 350, loss: 0.022656066343188286
epoch 14: dev_f1=0.8179669030732861, f1=0.8491879350348029, best_f1=0.8136363636363636
step: 0, loss: 0.01613864116370678
step: 10, loss: 0.03086094930768013
step: 20, loss: 0.03710739687085152
step: 30, loss: 0.008697657845914364
step: 40, loss: 0.10169617086648941
step: 50, loss: 0.0627235472202301
step: 60, loss: 0.07206864655017853
step: 70, loss: 0.06869500130414963
step: 80, loss: 0.10410908609628677
step: 90, loss: 0.03009532019495964
step: 100, loss: 0.05240693688392639
step: 110, loss: 0.028111858293414116
step: 120, loss: 0.049786973744630814
step: 130, loss: 0.05371901020407677
step: 140, loss: 0.060921356081962585
step: 150, loss: 0.06664489954710007
step: 160, loss: 0.06799013167619705
step: 170, loss: 0.04722091183066368
step: 180, loss: 0.03893837705254555
step: 190, loss: 0.09837117046117783
step: 200, loss: 0.06683448702096939
step: 210, loss: 9.753692575031891e-05
step: 220, loss: 0.03634943068027496
step: 230, loss: 0.077547088265419
step: 240, loss: 0.12274965643882751
step: 250, loss: 0.14044372737407684
step: 260, loss: 0.11361870914697647
step: 270, loss: 0.1056738793849945
step: 280, loss: 0.1322239637374878
step: 290, loss: 0.04144487902522087
step: 300, loss: 0.11106695234775543
step: 310, loss: 0.06399298459291458
step: 320, loss: 0.10877256840467453
step: 330, loss: 4.9195074097951874e-05
step: 340, loss: 0.041177812963724136
step: 350, loss: 0.051814109086990356
epoch 15: dev_f1=0.7960199004975125, f1=0.8117359413202935, best_f1=0.8136363636363636
step: 0, loss: 0.06597236543893814
step: 10, loss: 0.12045211344957352
step: 20, loss: 0.09408543258905411
step: 30, loss: 0.10756164789199829
step: 40, loss: 3.158130493829958e-05
step: 50, loss: 0.11746019124984741
step: 60, loss: 0.08520842343568802
step: 70, loss: 0.02182372286915779
step: 80, loss: 0.022049669176340103
step: 90, loss: 0.030658261850476265
step: 100, loss: 0.10984547436237335
step: 110, loss: 0.04008372500538826
step: 120, loss: 0.12196916341781616
step: 130, loss: 0.050714921206235886
step: 140, loss: 0.10816744714975357
step: 150, loss: 0.02576112002134323
step: 160, loss: 0.03632155805826187
step: 170, loss: 0.06900063157081604
step: 180, loss: 0.10145007818937302
step: 190, loss: 0.08617138862609863
step: 200, loss: 0.06643570959568024
step: 210, loss: 2.5253060812246986e-05
step: 220, loss: 0.0007483090739697218
step: 230, loss: 0.11015191674232483
step: 240, loss: 0.06364873796701431
step: 250, loss: 0.06589896231889725
step: 260, loss: 0.07597802579402924
step: 270, loss: 0.03554582968354225
step: 280, loss: 3.6657442251453176e-05
step: 290, loss: 0.0508517324924469
step: 300, loss: 0.11671348661184311
step: 310, loss: 0.022115807980298996
step: 320, loss: 0.07494449615478516
step: 330, loss: 0.07545720040798187
step: 340, loss: 0.10493673384189606
step: 350, loss: 0.07774978876113892
epoch 16: dev_f1=0.8124999999999999, f1=0.8325581395348837, best_f1=0.8136363636363636
step: 0, loss: 0.1289953738451004
step: 10, loss: 0.04356921836733818
step: 20, loss: 0.07252394407987595
step: 30, loss: 0.028834804892539978
step: 40, loss: 0.032503239810466766
step: 50, loss: 0.05390414595603943
step: 60, loss: 0.03489982709288597
step: 70, loss: 0.11510308086872101
step: 80, loss: 0.06365066021680832
step: 90, loss: 0.1445380449295044
step: 100, loss: 0.1433301866054535
step: 110, loss: 0.015880059450864792
step: 120, loss: 0.052618544548749924
step: 130, loss: 0.05046014115214348
step: 140, loss: 0.11791728436946869
step: 150, loss: 0.06765523552894592
step: 160, loss: 0.13316120207309723
step: 170, loss: 0.08113779872655869
step: 180, loss: 0.05639997497200966
step: 190, loss: 0.06014709174633026
step: 200, loss: 0.03421110659837723
step: 210, loss: 0.02547171339392662
step: 220, loss: 0.06602159142494202
step: 230, loss: 0.0760074034333229
step: 240, loss: 0.048698022961616516
step: 250, loss: 0.02224559523165226
step: 260, loss: 0.01721125841140747
step: 270, loss: 0.052818771451711655
step: 280, loss: 0.03062082827091217
step: 290, loss: 0.02732226438820362
step: 300, loss: 0.07424861192703247
step: 310, loss: 0.06603459268808365
step: 320, loss: 0.06490492820739746
step: 330, loss: 0.058930542320013046
step: 340, loss: 0.10680383443832397
step: 350, loss: 0.07095456123352051
epoch 17: dev_f1=0.8095238095238095, f1=0.834862385321101, best_f1=0.8136363636363636
step: 0, loss: 0.03524493798613548
step: 10, loss: 0.08086200803518295
step: 20, loss: 0.05671340227127075
step: 30, loss: 0.02303016372025013
step: 40, loss: 0.04570340737700462
step: 50, loss: 0.09057074040174484
step: 60, loss: 0.06825104355812073
step: 70, loss: 0.07162106782197952
step: 80, loss: 0.024398302659392357
step: 90, loss: 0.0726657509803772
step: 100, loss: 0.04264253005385399
step: 110, loss: 0.04776575416326523
step: 120, loss: 0.13518962264060974
step: 130, loss: 0.036490149796009064
step: 140, loss: 0.1288638859987259
step: 150, loss: 0.054508134722709656
step: 160, loss: 0.06925689429044724
step: 170, loss: 0.13979388773441315
step: 180, loss: 0.048820436000823975
step: 190, loss: 0.14567725360393524
step: 200, loss: 0.024290718138217926
step: 210, loss: 0.02985760010778904
step: 220, loss: 0.023045867681503296
step: 230, loss: 0.048903822898864746
step: 240, loss: 0.18691420555114746
step: 250, loss: 0.10782627761363983
step: 260, loss: 0.0837857648730278
step: 270, loss: 0.06582048535346985
step: 280, loss: 0.030956553295254707
step: 290, loss: 0.06685212254524231
step: 300, loss: 0.04012368991971016
step: 310, loss: 0.07337914407253265
step: 320, loss: 0.038693930953741074
step: 330, loss: 0.06915532797574997
step: 340, loss: 0.05924315005540848
step: 350, loss: 0.05066177248954773
epoch 18: dev_f1=0.815347721822542, f1=0.8387096774193549, best_f1=0.8136363636363636
step: 0, loss: 0.022233804687857628
step: 10, loss: 0.03176235780119896
step: 20, loss: 0.08112770318984985
step: 30, loss: 0.12162168323993683
step: 40, loss: 0.029420863837003708
step: 50, loss: 0.04522065073251724
step: 60, loss: 0.04596899077296257
step: 70, loss: 0.05979358032345772
step: 80, loss: 0.046594176441431046
step: 90, loss: 0.03221684321761131
step: 100, loss: 0.030343391001224518
step: 110, loss: 0.00017521811241749674
step: 120, loss: 0.07994720339775085
step: 130, loss: 0.06191759184002876
step: 140, loss: 0.11248846352100372
step: 150, loss: 0.09654875844717026
step: 160, loss: 0.0008231713436543941
step: 170, loss: 0.06510374695062637
step: 180, loss: 0.0218957606703043
step: 190, loss: 0.06501894444227219
step: 200, loss: 0.03230813890695572
step: 210, loss: 0.04549171403050423
step: 220, loss: 0.06689190864562988
step: 230, loss: 0.03233049064874649
step: 240, loss: 0.07466213405132294
step: 250, loss: 0.018662331625819206
step: 260, loss: 0.0533418208360672
step: 270, loss: 0.10348086059093475
step: 280, loss: 0.03479702025651932
step: 290, loss: 0.057127658277750015
step: 300, loss: 0.032830823212862015
step: 310, loss: 0.06924031674861908
step: 320, loss: 0.03173700347542763
step: 330, loss: 0.010257742367684841
step: 340, loss: 0.07930207997560501
step: 350, loss: 0.12076729536056519
epoch 19: dev_f1=0.8135593220338982, f1=0.8349056603773586, best_f1=0.8136363636363636
step: 0, loss: 0.0033542087767273188
step: 10, loss: 0.08625888079404831
step: 20, loss: 0.02549276500940323
step: 30, loss: 0.09979158639907837
step: 40, loss: 0.12957003712654114
step: 50, loss: 0.040317267179489136
step: 60, loss: 0.05183081328868866
step: 70, loss: 0.01698301173746586
step: 80, loss: 0.0289924293756485
step: 90, loss: 0.036402057856321335
step: 100, loss: 0.057027123868465424
step: 110, loss: 0.08682363480329514
step: 120, loss: 0.035013794898986816
step: 130, loss: 0.028039738535881042
step: 140, loss: 0.027977366000413895
step: 150, loss: 0.03242202475667
step: 160, loss: 0.01687363162636757
step: 170, loss: 0.1625036597251892
step: 180, loss: 0.06535543501377106
step: 190, loss: 0.04420827329158783
step: 200, loss: 0.022729672491550446
step: 210, loss: 0.0417972095310688
step: 220, loss: 0.036744944751262665
step: 230, loss: 0.035093337297439575
step: 240, loss: 0.10657571256160736
step: 250, loss: 0.09567397832870483
step: 260, loss: 0.09144514799118042
step: 270, loss: 0.030589327216148376
step: 280, loss: 0.03741509094834328
step: 290, loss: 0.0917876735329628
step: 300, loss: 0.07644353061914444
step: 310, loss: 0.08435594290494919
step: 320, loss: 0.07993026077747345
step: 330, loss: 0.06402860581874847
step: 340, loss: 0.02513197250664234
step: 350, loss: 0.11348220705986023
epoch 20: dev_f1=0.8068459657701711, f1=0.8238095238095239, best_f1=0.8136363636363636
