cuda
Device: cuda
step: 0, loss: 0.8202771544456482
step: 10, loss: 0.4354631006717682
step: 20, loss: 0.5565985441207886
step: 30, loss: 0.21790635585784912
step: 40, loss: 0.17731843888759613
step: 50, loss: 0.07054892182350159
step: 60, loss: 0.30588191747665405
step: 70, loss: 0.2472992241382599
step: 80, loss: 0.44598838686943054
step: 90, loss: 0.3693089485168457
step: 100, loss: 0.5489130616188049
step: 110, loss: 0.5905053615570068
step: 120, loss: 0.23252999782562256
step: 130, loss: 0.3930148780345917
step: 140, loss: 0.1667473316192627
step: 150, loss: 0.29692280292510986
step: 160, loss: 0.33769840002059937
step: 170, loss: 0.232571080327034
step: 180, loss: 0.3562702536582947
step: 190, loss: 0.315766304731369
step: 200, loss: 0.24547618627548218
step: 210, loss: 0.5670363306999207
step: 220, loss: 0.19977672398090363
step: 230, loss: 0.1877397894859314
step: 240, loss: 0.1187843456864357
step: 250, loss: 0.2296936810016632
step: 260, loss: 0.13341298699378967
step: 270, loss: 0.2291966676712036
step: 280, loss: 0.09146378934383392
step: 290, loss: 0.14926022291183472
step: 300, loss: 0.2628595530986786
step: 310, loss: 0.1712123602628708
step: 320, loss: 0.3220016658306122
step: 330, loss: 0.13329578936100006
step: 340, loss: 0.11507130414247513
step: 350, loss: 0.14947263896465302
epoch 1: dev_f1=0.7389558232931728, f1=0.7246963562753036, best_f1=0.7246963562753036
step: 0, loss: 0.10956044495105743
step: 10, loss: 0.096725694835186
step: 20, loss: 0.4234640300273895
step: 30, loss: 0.23525823652744293
step: 40, loss: 0.1341313123703003
step: 50, loss: 0.11654338240623474
step: 60, loss: 0.20275990664958954
step: 70, loss: 0.18672755360603333
step: 80, loss: 0.13695970177650452
step: 90, loss: 0.1312127709388733
step: 100, loss: 0.15500742197036743
step: 110, loss: 0.14020855724811554
step: 120, loss: 0.1406865268945694
step: 130, loss: 0.15510337054729462
step: 140, loss: 0.09731454402208328
step: 150, loss: 0.05388937518000603
step: 160, loss: 0.38949817419052124
step: 170, loss: 0.12093733251094818
step: 180, loss: 0.03335999697446823
step: 190, loss: 0.26466405391693115
step: 200, loss: 0.15843509137630463
step: 210, loss: 0.1662907600402832
step: 220, loss: 0.37994012236595154
step: 230, loss: 0.22248506546020508
step: 240, loss: 0.0860135406255722
step: 250, loss: 0.30728790163993835
step: 260, loss: 0.18384461104869843
step: 270, loss: 0.1700952649116516
step: 280, loss: 0.20466898381710052
step: 290, loss: 0.0855041965842247
step: 300, loss: 0.22215808928012848
step: 310, loss: 0.18593308329582214
step: 320, loss: 0.14881987869739532
step: 330, loss: 0.21044975519180298
step: 340, loss: 0.14453092217445374
step: 350, loss: 0.2615421414375305
epoch 2: dev_f1=0.7099391480730223, f1=0.7361963190184049, best_f1=0.7246963562753036
step: 0, loss: 0.11832219362258911
step: 10, loss: 0.16762398183345795
step: 20, loss: 0.18598225712776184
step: 30, loss: 0.09196093678474426
step: 40, loss: 0.13223965466022491
step: 50, loss: 0.19188712537288666
step: 60, loss: 0.07413143664598465
step: 70, loss: 0.20633697509765625
step: 80, loss: 0.10549518465995789
step: 90, loss: 0.06591668725013733
step: 100, loss: 0.10500317811965942
step: 110, loss: 0.19867533445358276
step: 120, loss: 0.11301063001155853
step: 130, loss: 0.13239875435829163
step: 140, loss: 0.0951826199889183
step: 150, loss: 0.18330469727516174
step: 160, loss: 0.11692053824663162
step: 170, loss: 0.019219432026147842
step: 180, loss: 0.03327963501214981
step: 190, loss: 0.11985962837934494
step: 200, loss: 0.15954211354255676
step: 210, loss: 0.09181702136993408
step: 220, loss: 0.13033342361450195
step: 230, loss: 0.15779122710227966
step: 240, loss: 0.13757939636707306
step: 250, loss: 0.1794154793024063
step: 260, loss: 0.26329201459884644
step: 270, loss: 0.15149781107902527
step: 280, loss: 0.08215656131505966
step: 290, loss: 0.09995180368423462
step: 300, loss: 0.16828805208206177
step: 310, loss: 0.11890683323144913
step: 320, loss: 0.08279232680797577
step: 330, loss: 0.19528619945049286
step: 340, loss: 0.221476748585701
step: 350, loss: 0.046526774764060974
epoch 3: dev_f1=0.7955555555555555, f1=0.801781737193764, best_f1=0.801781737193764
step: 0, loss: 0.08521518856287003
step: 10, loss: 0.06937982887029648
step: 20, loss: 0.08247160166501999
step: 30, loss: 0.11567553877830505
step: 40, loss: 0.07062721997499466
step: 50, loss: 0.034999243915081024
step: 60, loss: 0.08927340060472488
step: 70, loss: 0.21506784856319427
step: 80, loss: 0.09213510900735855
step: 90, loss: 0.08574152737855911
step: 100, loss: 0.11782778054475784
step: 110, loss: 0.11310067027807236
step: 120, loss: 0.18491937220096588
step: 130, loss: 0.1743284910917282
step: 140, loss: 0.1598254144191742
step: 150, loss: 0.12667812407016754
step: 160, loss: 0.057344935834407806
step: 170, loss: 0.12900392711162567
step: 180, loss: 0.12064682692289352
step: 190, loss: 0.1384856402873993
step: 200, loss: 0.0878688171505928
step: 210, loss: 0.1498989313840866
step: 220, loss: 0.19083760678768158
step: 230, loss: 0.1184997484087944
step: 240, loss: 0.19401952624320984
step: 250, loss: 0.16702160239219666
step: 260, loss: 0.04667402803897858
step: 270, loss: 0.13300788402557373
step: 280, loss: 0.19409242272377014
step: 290, loss: 0.16731669008731842
step: 300, loss: 0.19184225797653198
step: 310, loss: 0.14591456949710846
step: 320, loss: 0.2511196434497833
step: 330, loss: 0.20763367414474487
step: 340, loss: 0.17208023369312286
step: 350, loss: 0.13832451403141022
epoch 4: dev_f1=0.8190045248868778, f1=0.7911111111111112, best_f1=0.7911111111111112
step: 0, loss: 0.15088512003421783
step: 10, loss: 0.14171868562698364
step: 20, loss: 0.1181098148226738
step: 30, loss: 0.010117566213011742
step: 40, loss: 0.11803143471479416
step: 50, loss: 0.1506117582321167
step: 60, loss: 0.0667429268360138
step: 70, loss: 0.06106221675872803
step: 80, loss: 0.06246763840317726
step: 90, loss: 0.10102574527263641
step: 100, loss: 0.0631696879863739
step: 110, loss: 0.09950625151395798
step: 120, loss: 0.03747916221618652
step: 130, loss: 0.0821962058544159
step: 140, loss: 0.10859151184558868
step: 150, loss: 0.08518673479557037
step: 160, loss: 0.1251656413078308
step: 170, loss: 0.2961733937263489
step: 180, loss: 0.12952382862567902
step: 190, loss: 0.10066358745098114
step: 200, loss: 0.16080328822135925
step: 210, loss: 0.11885342001914978
step: 220, loss: 0.13093572854995728
step: 230, loss: 0.04019426554441452
step: 240, loss: 0.06366787850856781
step: 250, loss: 0.10539082437753677
step: 260, loss: 0.08339038491249084
step: 270, loss: 0.12869831919670105
step: 280, loss: 0.06198633089661598
step: 290, loss: 0.09886595606803894
step: 300, loss: 0.06030933931469917
step: 310, loss: 0.12227436155080795
step: 320, loss: 0.10943237692117691
step: 330, loss: 0.12207727134227753
step: 340, loss: 0.1531231850385666
step: 350, loss: 0.03320419788360596
epoch 5: dev_f1=0.7849223946784922, f1=0.7860262008733624, best_f1=0.7911111111111112
step: 0, loss: 0.100760817527771
step: 10, loss: 0.03822736442089081
step: 20, loss: 0.07329930365085602
step: 30, loss: 0.05671054869890213
step: 40, loss: 0.06827438622713089
step: 50, loss: 0.06222594156861305
step: 60, loss: 0.06976982206106186
step: 70, loss: 0.050637856125831604
step: 80, loss: 0.013047287240624428
step: 90, loss: 0.08495199680328369
step: 100, loss: 0.17950963973999023
step: 110, loss: 0.11225829273462296
step: 120, loss: 0.08427649736404419
step: 130, loss: 0.07055356353521347
step: 140, loss: 0.11180273443460464
step: 150, loss: 0.027900133281946182
step: 160, loss: 0.08776074647903442
step: 170, loss: 0.19693206250667572
step: 180, loss: 0.12738235294818878
step: 190, loss: 0.21965470910072327
step: 200, loss: 0.05022554472088814
step: 210, loss: 0.06831447780132294
step: 220, loss: 0.1069888100028038
step: 230, loss: 0.1261148452758789
step: 240, loss: 0.05938789248466492
step: 250, loss: 0.18848197162151337
step: 260, loss: 0.03445983678102493
step: 270, loss: 0.0835057720541954
step: 280, loss: 0.04185246676206589
step: 290, loss: 0.03457823768258095
step: 300, loss: 0.08426550030708313
step: 310, loss: 0.23964646458625793
step: 320, loss: 0.0766749233007431
step: 330, loss: 0.006678384263068438
step: 340, loss: 0.23722371459007263
step: 350, loss: 0.08235033601522446
epoch 6: dev_f1=0.8126410835214447, f1=0.7858719646799116, best_f1=0.7911111111111112
step: 0, loss: 0.07130930572748184
step: 10, loss: 0.021051980555057526
step: 20, loss: 0.04862707108259201
step: 30, loss: 0.0943187028169632
step: 40, loss: 0.14044848084449768
step: 50, loss: 0.10022534430027008
step: 60, loss: 0.08276151865720749
step: 70, loss: 0.03992162644863129
step: 80, loss: 0.058279745280742645
step: 90, loss: 0.10718503594398499
step: 100, loss: 0.1919364631175995
step: 110, loss: 0.015342503786087036
step: 120, loss: 0.08286020159721375
step: 130, loss: 0.18312793970108032
step: 140, loss: 0.12043817341327667
step: 150, loss: 0.12051638215780258
step: 160, loss: 0.06561273336410522
step: 170, loss: 0.018961956724524498
step: 180, loss: 0.04088782146573067
step: 190, loss: 0.0749637708067894
step: 200, loss: 0.0924704372882843
step: 210, loss: 0.017464654520154
step: 220, loss: 0.04880337417125702
step: 230, loss: 0.096001535654068
step: 240, loss: 0.10138101875782013
step: 250, loss: 0.06116931885480881
step: 260, loss: 0.2284851372241974
step: 270, loss: 0.09397447854280472
step: 280, loss: 0.07188234478235245
step: 290, loss: 0.09381561726331711
step: 300, loss: 0.08807302266359329
step: 310, loss: 0.12181035429239273
step: 320, loss: 0.13218675553798676
step: 330, loss: 0.0457586869597435
step: 340, loss: 0.02305593527853489
step: 350, loss: 0.07047458738088608
epoch 7: dev_f1=0.8232558139534882, f1=0.799097065462754, best_f1=0.799097065462754
step: 0, loss: 0.131001815199852
step: 10, loss: 0.05026821419596672
step: 20, loss: 0.02338842861354351
step: 30, loss: 0.16457003355026245
step: 40, loss: 0.07285419851541519
step: 50, loss: 0.02569521963596344
step: 60, loss: 0.03844573348760605
step: 70, loss: 0.013746406883001328
step: 80, loss: 0.08543535321950912
step: 90, loss: 0.043780677020549774
step: 100, loss: 0.13666367530822754
step: 110, loss: 0.10516597330570221
step: 120, loss: 0.04401904344558716
step: 130, loss: 0.09249907732009888
step: 140, loss: 0.13838684558868408
step: 150, loss: 0.07094727456569672
step: 160, loss: 0.10610727220773697
step: 170, loss: 0.09355895221233368
step: 180, loss: 0.12268424779176712
step: 190, loss: 0.10351620614528656
step: 200, loss: 0.046029530465602875
step: 210, loss: 0.07533836364746094
step: 220, loss: 0.05047989636659622
step: 230, loss: 0.09983523190021515
step: 240, loss: 0.09423939883708954
step: 250, loss: 0.10486605018377304
step: 260, loss: 0.07929078489542007
step: 270, loss: 0.08482314646244049
step: 280, loss: 0.1935271918773651
step: 290, loss: 0.07442979514598846
step: 300, loss: 0.1383352428674698
step: 310, loss: 0.1229177713394165
step: 320, loss: 0.07852240651845932
step: 330, loss: 0.04717292636632919
step: 340, loss: 0.07405893504619598
step: 350, loss: 0.1750102937221527
epoch 8: dev_f1=0.8210023866348449, f1=0.8137931034482758, best_f1=0.799097065462754
step: 0, loss: 0.1120358556509018
step: 10, loss: 0.07004140317440033
step: 20, loss: 0.059575002640485764
step: 30, loss: 0.1492241621017456
step: 40, loss: 0.09599792212247849
step: 50, loss: 0.024393653497099876
step: 60, loss: 0.030312595888972282
step: 70, loss: 0.0810508280992508
step: 80, loss: 0.07194338738918304
step: 90, loss: 0.1192009449005127
step: 100, loss: 0.05235804244875908
step: 110, loss: 0.1569960117340088
step: 120, loss: 0.06202790513634682
step: 130, loss: 0.07337727397680283
step: 140, loss: 0.07782651484012604
step: 150, loss: 0.18351705372333527
step: 160, loss: 0.0674474760890007
step: 170, loss: 0.08616305887699127
step: 180, loss: 0.07842268794775009
step: 190, loss: 0.17024394869804382
step: 200, loss: 0.06973094493150711
step: 210, loss: 0.1371113508939743
step: 220, loss: 0.09444122016429901
step: 230, loss: 0.08883508294820786
step: 240, loss: 0.12569764256477356
step: 250, loss: 0.12636679410934448
step: 260, loss: 0.12961934506893158
step: 270, loss: 0.04664383456110954
step: 280, loss: 0.041081950068473816
step: 290, loss: 0.0012575669679790735
step: 300, loss: 0.07692930102348328
step: 310, loss: 0.09837787598371506
step: 320, loss: 0.1070394366979599
step: 330, loss: 0.07630126923322678
step: 340, loss: 0.037229426205158234
step: 350, loss: 0.03286818042397499
epoch 9: dev_f1=0.8306264501160093, f1=0.801781737193764, best_f1=0.801781737193764
step: 0, loss: 0.159529447555542
step: 10, loss: 0.0384274497628212
step: 20, loss: 0.050446346402168274
step: 30, loss: 0.025154855102300644
step: 40, loss: 0.06226392090320587
step: 50, loss: 0.11664589494466782
step: 60, loss: 0.0667094960808754
step: 70, loss: 0.09395357221364975
step: 80, loss: 0.018281424418091774
step: 90, loss: 0.08168444037437439
step: 100, loss: 0.1291545331478119
step: 110, loss: 0.07219669222831726
step: 120, loss: 0.08695995062589645
step: 130, loss: 0.11591707915067673
step: 140, loss: 0.06919415295124054
step: 150, loss: 0.0595119446516037
step: 160, loss: 0.0415349006652832
step: 170, loss: 0.07574677467346191
step: 180, loss: 0.05438747629523277
step: 190, loss: 0.15212564170360565
step: 200, loss: 0.11674634367227554
step: 210, loss: 0.04188959300518036
step: 220, loss: 0.0015509374206885695
step: 230, loss: 0.060603559017181396
step: 240, loss: 0.08614172041416168
step: 250, loss: 0.03489324823021889
step: 260, loss: 0.08439432084560394
step: 270, loss: 0.07519365102052689
step: 280, loss: 0.13848087191581726
step: 290, loss: 0.05412217602133751
step: 300, loss: 0.023057833313941956
step: 310, loss: 0.057659778743982315
step: 320, loss: 0.029640482738614082
step: 330, loss: 0.06042345240712166
step: 340, loss: 0.09424162656068802
step: 350, loss: 0.0741056352853775
epoch 10: dev_f1=0.8188235294117647, f1=0.7925407925407925, best_f1=0.801781737193764
step: 0, loss: 0.11974874883890152
step: 10, loss: 0.09969955682754517
step: 20, loss: 0.09613620489835739
step: 30, loss: 0.050711724907159805
step: 40, loss: 0.1801728457212448
step: 50, loss: 0.060435518622398376
step: 60, loss: 0.09104542434215546
step: 70, loss: 0.047660768032073975
step: 80, loss: 0.13648556172847748
step: 90, loss: 0.07155045866966248
step: 100, loss: 0.034406911581754684
step: 110, loss: 0.051274511963129044
step: 120, loss: 0.04453511908650398
step: 130, loss: 0.058442335575819016
step: 140, loss: 0.17576630413532257
step: 150, loss: 0.02128356136381626
step: 160, loss: 0.0543784573674202
step: 170, loss: 0.05007904767990112
step: 180, loss: 0.07910487800836563
step: 190, loss: 0.07999727129936218
step: 200, loss: 0.08396168053150177
step: 210, loss: 0.0801466628909111
step: 220, loss: 0.1441674381494522
step: 230, loss: 0.09044784307479858
step: 240, loss: 0.07107977569103241
step: 250, loss: 0.10859183967113495
step: 260, loss: 0.06954196095466614
step: 270, loss: 0.058014705777168274
step: 280, loss: 0.07077846676111221
step: 290, loss: 0.03575385361909866
step: 300, loss: 0.1203434094786644
step: 310, loss: 0.06461755186319351
step: 320, loss: 0.04158670827746391
step: 330, loss: 0.08920913189649582
step: 340, loss: 0.04540250822901726
step: 350, loss: 0.0842987596988678
epoch 11: dev_f1=0.8266033254156769, f1=0.7706855791962176, best_f1=0.801781737193764
step: 0, loss: 0.06483424454927444
step: 10, loss: 0.0817657858133316
step: 20, loss: 0.08666327595710754
step: 30, loss: 0.07745106518268585
step: 40, loss: 0.036477118730545044
step: 50, loss: 0.03073342703282833
step: 60, loss: 0.02255343273282051
step: 70, loss: 0.03310661390423775
step: 80, loss: 0.015150219202041626
step: 90, loss: 0.03287019953131676
step: 100, loss: 0.024033229798078537
step: 110, loss: 0.09684111922979355
step: 120, loss: 0.011062766425311565
step: 130, loss: 0.13204288482666016
step: 140, loss: 0.0457286462187767
step: 150, loss: 0.12300866097211838
step: 160, loss: 0.05091280862689018
step: 170, loss: 0.06414047628641129
step: 180, loss: 0.0655461847782135
step: 190, loss: 0.017531700432300568
step: 200, loss: 0.06313693523406982
step: 210, loss: 0.06897024810314178
step: 220, loss: 0.05552508309483528
step: 230, loss: 0.10612200200557709
step: 240, loss: 8.941419218899682e-05
step: 250, loss: 0.12853282690048218
step: 260, loss: 0.17470386624336243
step: 270, loss: 0.14781790971755981
step: 280, loss: 0.04353610426187515
step: 290, loss: 0.04155662655830383
step: 300, loss: 0.1633554846048355
step: 310, loss: 0.11070255935192108
step: 320, loss: 0.04271550104022026
step: 330, loss: 0.07384069263935089
step: 340, loss: 0.021595094352960587
step: 350, loss: 0.09155254065990448
epoch 12: dev_f1=0.8341463414634146, f1=0.7836538461538461, best_f1=0.7836538461538461
step: 0, loss: 0.09565792232751846
step: 10, loss: 0.06829430162906647
step: 20, loss: 0.08984564244747162
step: 30, loss: 0.09853510558605194
step: 40, loss: 0.12908262014389038
step: 50, loss: 0.05633966624736786
step: 60, loss: 0.16888870298862457
step: 70, loss: 0.04828418791294098
step: 80, loss: 0.06409884989261627
step: 90, loss: 0.10563106089830399
step: 100, loss: 0.04445457085967064
step: 110, loss: 0.09111463278532028
step: 120, loss: 0.049581654369831085
step: 130, loss: 0.03914016857743263
step: 140, loss: 0.09683983027935028
step: 150, loss: 0.016176540404558182
step: 160, loss: 0.09385958313941956
step: 170, loss: 0.01932043395936489
step: 180, loss: 0.05549079179763794
step: 190, loss: 0.1412072479724884
step: 200, loss: 0.18880897760391235
step: 210, loss: 0.018836259841918945
step: 220, loss: 0.07047397643327713
step: 230, loss: 0.03645218908786774
step: 240, loss: 0.08132993429899216
step: 250, loss: 0.06759772449731827
step: 260, loss: 0.17880867421627045
step: 270, loss: 0.031123943626880646
step: 280, loss: 0.05358581244945526
step: 290, loss: 0.056869979947805405
step: 300, loss: 0.04809184372425079
step: 310, loss: 0.05460298806428909
step: 320, loss: 0.017072996124625206
step: 330, loss: 0.029236486181616783
step: 340, loss: 0.09272539615631104
step: 350, loss: 0.05834074690937996
epoch 13: dev_f1=0.8321513002364066, f1=0.7926267281105991, best_f1=0.7836538461538461
step: 0, loss: 0.022578788921236992
step: 10, loss: 0.0555545836687088
step: 20, loss: 0.0797509104013443
step: 30, loss: 0.07255338877439499
step: 40, loss: 0.06191473454236984
step: 50, loss: 0.024332471191883087
step: 60, loss: 0.019754482433199883
step: 70, loss: 0.018661530688405037
step: 80, loss: 0.11112619191408157
step: 90, loss: 0.02396084927022457
step: 100, loss: 0.02650303766131401
step: 110, loss: 0.10399707406759262
step: 120, loss: 0.029878895729780197
step: 130, loss: 0.10843904316425323
step: 140, loss: 0.11595386266708374
step: 150, loss: 0.014408462680876255
step: 160, loss: 0.180817112326622
step: 170, loss: 0.10468965023756027
step: 180, loss: 0.048776108771562576
step: 190, loss: 0.0850909948348999
step: 200, loss: 0.054596349596977234
step: 210, loss: 0.09229941666126251
step: 220, loss: 0.10497311502695084
step: 230, loss: 0.08053412288427353
step: 240, loss: 0.10814475268125534
step: 250, loss: 0.13641414046287537
step: 260, loss: 0.1113615334033966
step: 270, loss: 0.13095630705356598
step: 280, loss: 0.06517262011766434
step: 290, loss: 0.12288748472929001
step: 300, loss: 0.02855554223060608
step: 310, loss: 0.023268040269613266
step: 320, loss: 0.044739823788404465
step: 330, loss: 0.08210983127355576
step: 340, loss: 0.09218472242355347
step: 350, loss: 0.02910749427974224
epoch 14: dev_f1=0.8232445520581113, f1=0.7962085308056872, best_f1=0.7836538461538461
step: 0, loss: 0.051064882427453995
step: 10, loss: 0.08558805286884308
step: 20, loss: 0.04701700061559677
step: 30, loss: 0.13112381100654602
step: 40, loss: 0.08080966770648956
step: 50, loss: 0.004673334304243326
step: 60, loss: 0.04646347463130951
step: 70, loss: 0.07090486586093903
step: 80, loss: 0.02469969168305397
step: 90, loss: 0.08024973422288895
step: 100, loss: 0.06680850684642792
step: 110, loss: 0.02251787669956684
step: 120, loss: 0.019212869927287102
step: 130, loss: 0.06580042093992233
step: 140, loss: 0.04134698957204819
step: 150, loss: 0.04858628660440445
step: 160, loss: 0.18208879232406616
step: 170, loss: 0.1328672468662262
step: 180, loss: 0.002358309691771865
step: 190, loss: 0.0863780528306961
step: 200, loss: 0.04305274784564972
step: 210, loss: 0.04901661351323128
step: 220, loss: 0.0871439203619957
step: 230, loss: 0.07048043608665466
step: 240, loss: 0.10123498737812042
step: 250, loss: 3.313158595119603e-05
step: 260, loss: 0.04680316895246506
step: 270, loss: 0.01280465628951788
step: 280, loss: 0.0701477974653244
step: 290, loss: 0.11185196787118912
step: 300, loss: 0.010272447019815445
step: 310, loss: 0.03563789278268814
step: 320, loss: 0.06101065129041672
step: 330, loss: 0.06817138940095901
step: 340, loss: 0.020768944174051285
step: 350, loss: 0.07093833386898041
epoch 15: dev_f1=0.8286445012787724, f1=0.772378516624041, best_f1=0.7836538461538461
step: 0, loss: 0.13306587934494019
step: 10, loss: 0.08638934791088104
step: 20, loss: 0.021785620599985123
step: 30, loss: 0.05739733576774597
step: 40, loss: 3.665150507004e-05
step: 50, loss: 0.07140819728374481
step: 60, loss: 0.041644446551799774
step: 70, loss: 0.09054206311702728
step: 80, loss: 0.07251611351966858
step: 90, loss: 0.0827430784702301
step: 100, loss: 0.06460220366716385
step: 110, loss: 0.1082189679145813
step: 120, loss: 0.07269501686096191
step: 130, loss: 0.043113186955451965
step: 140, loss: 0.06151539087295532
step: 150, loss: 0.046321120113134384
step: 160, loss: 0.10291368514299393
step: 170, loss: 0.07390609383583069
step: 180, loss: 0.08505688607692719
step: 190, loss: 0.18256622552871704
step: 200, loss: 0.03266946226358414
step: 210, loss: 0.0981474444270134
step: 220, loss: 0.05096552520990372
step: 230, loss: 0.08166034519672394
step: 240, loss: 0.029725315049290657
step: 250, loss: 0.02816634811460972
step: 260, loss: 0.10726463049650192
step: 270, loss: 0.02478797547519207
step: 280, loss: 0.09015312045812607
step: 290, loss: 0.04781602323055267
step: 300, loss: 0.07248866558074951
step: 310, loss: 0.07570664584636688
step: 320, loss: 0.049531497061252594
step: 330, loss: 0.06932800263166428
step: 340, loss: 0.14948444068431854
step: 350, loss: 0.10778838396072388
epoch 16: dev_f1=0.8286445012787724, f1=0.7766497461928934, best_f1=0.7836538461538461
step: 0, loss: 0.05592884495854378
step: 10, loss: 0.03603016585111618
step: 20, loss: 0.08046543598175049
step: 30, loss: 0.009860692545771599
step: 40, loss: 3.097432272625156e-05
step: 50, loss: 0.029306186363101006
step: 60, loss: 0.05211596563458443
step: 70, loss: 0.057493552565574646
step: 80, loss: 0.06964754313230515
step: 90, loss: 0.05840442702174187
step: 100, loss: 0.0695742815732956
step: 110, loss: 0.10044001042842865
step: 120, loss: 0.04976915940642357
step: 130, loss: 0.01724780723452568
step: 140, loss: 0.002587229711934924
step: 150, loss: 0.04527467489242554
step: 160, loss: 0.123378224670887
step: 170, loss: 0.15990644693374634
step: 180, loss: 0.07353249192237854
step: 190, loss: 0.07689972966909409
step: 200, loss: 0.030707314610481262
step: 210, loss: 0.048109639436006546
step: 220, loss: 0.0401708222925663
step: 230, loss: 0.05245636776089668
step: 240, loss: 0.11195603758096695
step: 250, loss: 0.05101237818598747
step: 260, loss: 0.19888707995414734
step: 270, loss: 0.11430580914020538
step: 280, loss: 0.0744001492857933
step: 290, loss: 0.05189921706914902
step: 300, loss: 0.07515961676836014
step: 310, loss: 0.08466577529907227
step: 320, loss: 0.07096855342388153
step: 330, loss: 0.07613395154476166
step: 340, loss: 0.05486045777797699
step: 350, loss: 0.06716514378786087
epoch 17: dev_f1=0.8229665071770335, f1=0.7885985748218527, best_f1=0.7836538461538461
step: 0, loss: 0.09023437649011612
step: 10, loss: 0.026181038469076157
step: 20, loss: 0.09846027940511703
step: 30, loss: 0.07732048630714417
step: 40, loss: 0.060305405408144
step: 50, loss: 0.012632310390472412
step: 60, loss: 0.058420129120349884
step: 70, loss: 0.056522633880376816
step: 80, loss: 0.09759379923343658
step: 90, loss: 0.1055711954832077
step: 100, loss: 0.021763218566775322
step: 110, loss: 0.021393457427620888
step: 120, loss: 0.10528409481048584
step: 130, loss: 0.07663344591856003
step: 140, loss: 0.06253605335950851
step: 150, loss: 0.022159377112984657
step: 160, loss: 0.05724475905299187
step: 170, loss: 0.09092554450035095
step: 180, loss: 0.05972335860133171
step: 190, loss: 0.044922325760126114
step: 200, loss: 0.023000044748187065
step: 210, loss: 0.06569302827119827
step: 220, loss: 0.04234693944454193
step: 230, loss: 0.039193201810121536
step: 240, loss: 0.19257934391498566
step: 250, loss: 0.05919354036450386
step: 260, loss: 0.07211866229772568
step: 270, loss: 0.03916580229997635
step: 280, loss: 0.11479051411151886
step: 290, loss: 0.01973349042236805
step: 300, loss: 3.9139482396421954e-05
step: 310, loss: 0.03458879515528679
step: 320, loss: 0.09879662096500397
step: 330, loss: 0.01776326261460781
step: 340, loss: 0.00028342005680315197
step: 350, loss: 0.07286982983350754
epoch 18: dev_f1=0.8256410256410256, f1=0.7727272727272727, best_f1=0.7836538461538461
step: 0, loss: 0.09266740083694458
step: 10, loss: 0.02370356023311615
step: 20, loss: 0.04978007450699806
step: 30, loss: 0.050182126462459564
step: 40, loss: 0.05362110957503319
step: 50, loss: 0.05829838663339615
step: 60, loss: 0.06952172517776489
step: 70, loss: 0.044298410415649414
step: 80, loss: 0.060641832649707794
step: 90, loss: 0.15622933208942413
step: 100, loss: 0.0008160438155755401
step: 110, loss: 0.09916367381811142
step: 120, loss: 0.10570672154426575
step: 130, loss: 0.045651283115148544
step: 140, loss: 0.07333666831254959
step: 150, loss: 0.005075526423752308
step: 160, loss: 0.022452540695667267
step: 170, loss: 0.026299651712179184
step: 180, loss: 0.04530806466937065
step: 190, loss: 0.07078838348388672
step: 200, loss: 0.03238970786333084
step: 210, loss: 0.13366729021072388
step: 220, loss: 0.02082144469022751
step: 230, loss: 0.07481614500284195
step: 240, loss: 0.06246847286820412
step: 250, loss: 0.017252249643206596
step: 260, loss: 0.0964338406920433
step: 270, loss: 0.19748231768608093
step: 280, loss: 0.031104233115911484
step: 290, loss: 0.0338815301656723
step: 300, loss: 0.03873641416430473
step: 310, loss: 0.09275839477777481
step: 320, loss: 0.05043887346982956
step: 330, loss: 0.14611278474330902
step: 340, loss: 0.08570839464664459
step: 350, loss: 0.06816841661930084
epoch 19: dev_f1=0.8215158924205379, f1=0.7785888077858881, best_f1=0.7836538461538461
step: 0, loss: 0.046927329152822495
step: 10, loss: 0.05694719776511192
step: 20, loss: 0.06965494900941849
step: 30, loss: 0.02737274020910263
step: 40, loss: 0.16490620374679565
step: 50, loss: 0.035124070942401886
step: 60, loss: 0.04419448971748352
step: 70, loss: 0.03092299774289131
step: 80, loss: 0.0610412172973156
step: 90, loss: 0.17417092621326447
step: 100, loss: 0.1364479511976242
step: 110, loss: 0.025157896801829338
step: 120, loss: 0.0003763737913686782
step: 130, loss: 0.09793896228075027
step: 140, loss: 6.407905311789364e-05
step: 150, loss: 0.039470892399549484
step: 160, loss: 0.0909252017736435
step: 170, loss: 0.36920827627182007
step: 180, loss: 0.08743316680192947
step: 190, loss: 0.042506683617830276
step: 200, loss: 0.07703539729118347
step: 210, loss: 0.03488859161734581
step: 220, loss: 0.05922968313097954
step: 230, loss: 0.011814787052571774
step: 240, loss: 0.04675369709730148
step: 250, loss: 0.07948195189237595
step: 260, loss: 0.028746074065566063
step: 270, loss: 0.0759652629494667
step: 280, loss: 0.05953697860240936
step: 290, loss: 0.027565836906433105
step: 300, loss: 0.12399084120988846
step: 310, loss: 0.05954645574092865
step: 320, loss: 6.451540684793144e-05
step: 330, loss: 0.024104569107294083
step: 340, loss: 0.03142648935317993
step: 350, loss: 0.09924720227718353
epoch 20: dev_f1=0.8252427184466019, f1=0.7884615384615384, best_f1=0.7836538461538461
