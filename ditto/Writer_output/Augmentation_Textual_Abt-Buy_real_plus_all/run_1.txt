cuda
Device: cuda
step: 0, loss: 0.6818557977676392
step: 10, loss: 0.48031190037727356
step: 20, loss: 0.3082079291343689
step: 30, loss: 0.3645208775997162
step: 40, loss: 0.16023360192775726
step: 50, loss: 0.2504054605960846
step: 60, loss: 0.292525053024292
step: 70, loss: 0.24022625386714935
step: 80, loss: 0.4132811427116394
step: 90, loss: 0.24027669429779053
step: 100, loss: 0.21565677225589752
step: 110, loss: 0.3998028039932251
step: 120, loss: 0.4682939350605011
step: 130, loss: 0.25889623165130615
step: 140, loss: 0.21312324702739716
step: 150, loss: 0.3840058445930481
step: 160, loss: 0.15981906652450562
step: 170, loss: 0.34535905718803406
step: 180, loss: 0.254296213388443
step: 190, loss: 0.2385859340429306
step: 200, loss: 0.17436181008815765
step: 210, loss: 0.19104522466659546
step: 220, loss: 0.18594661355018616
step: 230, loss: 0.23421044647693634
step: 240, loss: 0.132911816239357
step: 250, loss: 0.23849287629127502
step: 260, loss: 0.21520355343818665
step: 270, loss: 0.19402842223644257
step: 280, loss: 0.18601229786872864
step: 290, loss: 0.18540935218334198
step: 300, loss: 0.03432564437389374
step: 310, loss: 0.12687654793262482
step: 320, loss: 0.13489946722984314
step: 330, loss: 0.14221298694610596
step: 340, loss: 0.20083726942539215
step: 350, loss: 0.08658670634031296
epoch 1: dev_f1=0.7175257731958763, f1=0.7042801556420233, best_f1=0.7042801556420233
step: 0, loss: 0.15595725178718567
step: 10, loss: 0.14071978628635406
step: 20, loss: 0.2464592158794403
step: 30, loss: 0.2577767074108124
step: 40, loss: 0.08882705867290497
step: 50, loss: 0.03730473294854164
step: 60, loss: 0.32651281356811523
step: 70, loss: 0.1196710616350174
step: 80, loss: 0.20228832960128784
step: 90, loss: 0.06869838386774063
step: 100, loss: 0.051627159118652344
step: 110, loss: 0.2684229910373688
step: 120, loss: 0.3166773319244385
step: 130, loss: 0.06849310547113419
step: 140, loss: 0.06470728665590286
step: 150, loss: 0.6160978674888611
step: 160, loss: 0.174574077129364
step: 170, loss: 0.16342823207378387
step: 180, loss: 0.11811265349388123
step: 190, loss: 0.1225702092051506
step: 200, loss: 0.2152150273323059
step: 210, loss: 0.14059293270111084
step: 220, loss: 0.25715741515159607
step: 230, loss: 0.2529067397117615
step: 240, loss: 0.14149412512779236
step: 250, loss: 0.09828393161296844
step: 260, loss: 0.19376954436302185
step: 270, loss: 0.18725557625293732
step: 280, loss: 0.0666554868221283
step: 290, loss: 0.08761708438396454
step: 300, loss: 0.09286889433860779
step: 310, loss: 0.18543066084384918
step: 320, loss: 0.10716324299573898
step: 330, loss: 0.12168293446302414
step: 340, loss: 0.14653810858726501
step: 350, loss: 0.07086536288261414
epoch 2: dev_f1=0.8037825059101655, f1=0.8101851851851851, best_f1=0.8101851851851851
step: 0, loss: 0.11019936949014664
step: 10, loss: 0.15494871139526367
step: 20, loss: 0.0981794074177742
step: 30, loss: 0.1065460741519928
step: 40, loss: 0.06464915722608566
step: 50, loss: 0.04082407429814339
step: 60, loss: 0.08691266924142838
step: 70, loss: 0.12246652692556381
step: 80, loss: 0.07613735646009445
step: 90, loss: 0.09557947516441345
step: 100, loss: 0.10976216197013855
step: 110, loss: 0.18079496920108795
step: 120, loss: 0.07199980318546295
step: 130, loss: 0.09089053422212601
step: 140, loss: 0.1360933929681778
step: 150, loss: 0.1444491147994995
step: 160, loss: 0.18031731247901917
step: 170, loss: 0.0752144381403923
step: 180, loss: 0.058640968054533005
step: 190, loss: 0.05013207718729973
step: 200, loss: 0.08797303587198257
step: 210, loss: 0.22738678753376007
step: 220, loss: 0.10782409459352493
step: 230, loss: 0.1260124295949936
step: 240, loss: 0.1362541764974594
step: 250, loss: 0.1931561380624771
step: 260, loss: 0.12934571504592896
step: 270, loss: 0.15201938152313232
step: 280, loss: 0.13875409960746765
step: 290, loss: 0.051856499165296555
step: 300, loss: 0.04994220659136772
step: 310, loss: 0.046222567558288574
step: 320, loss: 0.09135079383850098
step: 330, loss: 0.059659671038389206
step: 340, loss: 0.05213078856468201
step: 350, loss: 0.03360842913389206
epoch 3: dev_f1=0.8157894736842106, f1=0.7813163481953291, best_f1=0.7813163481953291
step: 0, loss: 0.27857649326324463
step: 10, loss: 0.07943379133939743
step: 20, loss: 0.06804303824901581
step: 30, loss: 0.1092529296875
step: 40, loss: 0.04705825075507164
step: 50, loss: 0.09094502776861191
step: 60, loss: 0.07993331551551819
step: 70, loss: 0.0907038152217865
step: 80, loss: 0.020307093858718872
step: 90, loss: 0.15361176431179047
step: 100, loss: 0.07335295528173447
step: 110, loss: 0.07415979355573654
step: 120, loss: 0.12815788388252258
step: 130, loss: 0.11323896050453186
step: 140, loss: 0.09269499778747559
step: 150, loss: 0.10272158682346344
step: 160, loss: 0.08383281528949738
step: 170, loss: 0.13260120153427124
step: 180, loss: 0.02024916745722294
step: 190, loss: 0.15444861352443695
step: 200, loss: 0.0661531388759613
step: 210, loss: 0.09588723629713058
step: 220, loss: 0.10673787444829941
step: 230, loss: 0.12072712928056717
step: 240, loss: 0.14244654774665833
step: 250, loss: 0.11877845972776413
step: 260, loss: 0.05836765840649605
step: 270, loss: 0.26035767793655396
step: 280, loss: 0.07140954583883286
step: 290, loss: 0.07715357840061188
step: 300, loss: 0.034143317490816116
step: 310, loss: 0.05704430490732193
step: 320, loss: 0.10806751251220703
step: 330, loss: 0.09793887287378311
step: 340, loss: 0.08619222044944763
step: 350, loss: 0.16613195836544037
epoch 4: dev_f1=0.8042553191489361, f1=0.8085106382978723, best_f1=0.7813163481953291
step: 0, loss: 0.14499831199645996
step: 10, loss: 0.10342328250408173
step: 20, loss: 0.08784892410039902
step: 30, loss: 0.13860702514648438
step: 40, loss: 0.09753195196390152
step: 50, loss: 0.1577768623828888
step: 60, loss: 0.08317852765321732
step: 70, loss: 0.06611865013837814
step: 80, loss: 0.25066056847572327
step: 90, loss: 0.12491723895072937
step: 100, loss: 0.08214540034532547
step: 110, loss: 0.0967845618724823
step: 120, loss: 0.09270134568214417
step: 130, loss: 0.12099707871675491
step: 140, loss: 0.09237341582775116
step: 150, loss: 0.14464171230793
step: 160, loss: 0.06701468676328659
step: 170, loss: 0.031876955181360245
step: 180, loss: 0.059460919350385666
step: 190, loss: 0.12483493983745575
step: 200, loss: 0.02155442349612713
step: 210, loss: 0.16371837258338928
step: 220, loss: 0.07868702709674835
step: 230, loss: 0.0029294805135577917
step: 240, loss: 0.0378977470099926
step: 250, loss: 0.04910105839371681
step: 260, loss: 0.04534886032342911
step: 270, loss: 0.09772222489118576
step: 280, loss: 0.027582591399550438
step: 290, loss: 0.05810884013772011
step: 300, loss: 0.0950506329536438
step: 310, loss: 0.09596774727106094
step: 320, loss: 0.17143896222114563
step: 330, loss: 0.12704075872898102
step: 340, loss: 0.19293071329593658
step: 350, loss: 0.13542301952838898
epoch 5: dev_f1=0.8090909090909091, f1=0.8080357142857143, best_f1=0.7813163481953291
step: 0, loss: 0.04532298818230629
step: 10, loss: 0.04501209780573845
step: 20, loss: 0.07377402484416962
step: 30, loss: 0.03323441371321678
step: 40, loss: 0.07225968688726425
step: 50, loss: 0.11976684629917145
step: 60, loss: 0.06695790588855743
step: 70, loss: 0.04670584201812744
step: 80, loss: 0.08128931373357773
step: 90, loss: 0.1527862697839737
step: 100, loss: 0.05405730754137039
step: 110, loss: 0.062230899930000305
step: 120, loss: 0.05442223697900772
step: 130, loss: 0.03994850069284439
step: 140, loss: 0.1425653100013733
step: 150, loss: 0.0823628231883049
step: 160, loss: 0.10451813042163849
step: 170, loss: 0.06219203770160675
step: 180, loss: 0.17116685211658478
step: 190, loss: 0.07212316244840622
step: 200, loss: 0.056936800479888916
step: 210, loss: 0.07145072519779205
step: 220, loss: 0.07321001589298248
step: 230, loss: 0.1183289885520935
step: 240, loss: 0.168212890625
step: 250, loss: 0.07302436232566833
step: 260, loss: 0.04524242877960205
step: 270, loss: 0.04624422267079353
step: 280, loss: 0.01655915379524231
step: 290, loss: 0.10476844012737274
step: 300, loss: 0.11457367241382599
step: 310, loss: 0.10226292163133621
step: 320, loss: 0.11909107863903046
step: 330, loss: 0.07253256440162659
step: 340, loss: 0.04382892698049545
step: 350, loss: 0.1997593343257904
epoch 6: dev_f1=0.8264840182648402, f1=0.8181818181818181, best_f1=0.8181818181818181
step: 0, loss: 0.039754439145326614
step: 10, loss: 0.006900840904563665
step: 20, loss: 0.08642122149467468
step: 30, loss: 0.09969469904899597
step: 40, loss: 0.08491898328065872
step: 50, loss: 0.08247201889753342
step: 60, loss: 0.047904375940561295
step: 70, loss: 0.09634069353342056
step: 80, loss: 0.07324741780757904
step: 90, loss: 0.031026778742671013
step: 100, loss: 0.054906897246837616
step: 110, loss: 0.09374331682920456
step: 120, loss: 0.04594035446643829
step: 130, loss: 0.04489448666572571
step: 140, loss: 0.08517207205295563
step: 150, loss: 0.13171415030956268
step: 160, loss: 0.08786161988973618
step: 170, loss: 0.03827524557709694
step: 180, loss: 0.03503696620464325
step: 190, loss: 0.05634365975856781
step: 200, loss: 0.01749950274825096
step: 210, loss: 0.007787025533616543
step: 220, loss: 0.07008755207061768
step: 230, loss: 0.07884509116411209
step: 240, loss: 0.12323427200317383
step: 250, loss: 0.07641500979661942
step: 260, loss: 0.023199189454317093
step: 270, loss: 0.054058145731687546
step: 280, loss: 0.056947436183691025
step: 290, loss: 0.13560734689235687
step: 300, loss: 0.17244550585746765
step: 310, loss: 0.04168516397476196
step: 320, loss: 0.09038543701171875
step: 330, loss: 0.047670841217041016
step: 340, loss: 0.09023755043745041
step: 350, loss: 0.05019043758511543
epoch 7: dev_f1=0.818627450980392, f1=0.7901234567901234, best_f1=0.8181818181818181
step: 0, loss: 0.0627853125333786
step: 10, loss: 0.03096354939043522
step: 20, loss: 0.07300244271755219
step: 30, loss: 0.06727445125579834
step: 40, loss: 0.053031522780656815
step: 50, loss: 0.09345590323209763
step: 60, loss: 0.04212014377117157
step: 70, loss: 0.2018832117319107
step: 80, loss: 0.18852168321609497
step: 90, loss: 0.06641039997339249
step: 100, loss: 0.025757666677236557
step: 110, loss: 0.06647728383541107
step: 120, loss: 0.0844397023320198
step: 130, loss: 0.10266179591417313
step: 140, loss: 0.10714835673570633
step: 150, loss: 0.07214771956205368
step: 160, loss: 0.056123051792383194
step: 170, loss: 0.08051728457212448
step: 180, loss: 0.08665983378887177
step: 190, loss: 0.041687726974487305
step: 200, loss: 0.0720125138759613
step: 210, loss: 0.06749674677848816
step: 220, loss: 0.2242477834224701
step: 230, loss: 0.10102374106645584
step: 240, loss: 0.06505358964204788
step: 250, loss: 0.05178048089146614
step: 260, loss: 0.10174045711755753
step: 270, loss: 0.08753307163715363
step: 280, loss: 0.07567889988422394
step: 290, loss: 0.07199352234601974
step: 300, loss: 0.06983619928359985
step: 310, loss: 0.03519932180643082
step: 320, loss: 0.12969383597373962
step: 330, loss: 0.041684504598379135
step: 340, loss: 0.15765514969825745
step: 350, loss: 0.17343170940876007
epoch 8: dev_f1=0.8130841121495326, f1=0.8156682027649769, best_f1=0.8181818181818181
step: 0, loss: 0.1772381067276001
step: 10, loss: 0.1695414036512375
step: 20, loss: 0.12469518184661865
step: 30, loss: 0.10107700526714325
step: 40, loss: 0.09281481057405472
step: 50, loss: 0.08863481134176254
step: 60, loss: 0.008042708970606327
step: 70, loss: 0.04398217424750328
step: 80, loss: 0.040954478085041046
step: 90, loss: 0.023412048816680908
step: 100, loss: 0.10194439440965652
step: 110, loss: 0.06602010130882263
step: 120, loss: 0.09638776630163193
step: 130, loss: 0.05028117820620537
step: 140, loss: 0.141436368227005
step: 150, loss: 0.012424623593688011
step: 160, loss: 0.145283043384552
step: 170, loss: 0.1252271831035614
step: 180, loss: 0.10672939568758011
step: 190, loss: 0.021894408389925957
step: 200, loss: 0.04055844247341156
step: 210, loss: 0.09419900178909302
step: 220, loss: 0.0688047707080841
step: 230, loss: 0.09310347586870193
step: 240, loss: 0.05690426006913185
step: 250, loss: 0.06889385730028152
step: 260, loss: 0.024146532639861107
step: 270, loss: 0.034963373094797134
step: 280, loss: 0.06795958429574966
step: 290, loss: 0.1040458157658577
step: 300, loss: 0.1049002930521965
step: 310, loss: 0.06020340695977211
step: 320, loss: 0.05795925483107567
step: 330, loss: 0.037037838250398636
step: 340, loss: 0.06016191095113754
step: 350, loss: 0.04347377270460129
epoch 9: dev_f1=0.8275862068965516, f1=0.7849223946784922, best_f1=0.7849223946784922
step: 0, loss: 0.10436351597309113
step: 10, loss: 0.07447365671396255
step: 20, loss: 0.13219456374645233
step: 30, loss: 0.09155251085758209
step: 40, loss: 0.1468382328748703
step: 50, loss: 0.07409916073083878
step: 60, loss: 0.1193816289305687
step: 70, loss: 0.041900862008333206
step: 80, loss: 0.11223295331001282
step: 90, loss: 0.05534461885690689
step: 100, loss: 0.06414168328046799
step: 110, loss: 0.0010833641281351447
step: 120, loss: 0.05095918849110603
step: 130, loss: 0.05090535804629326
step: 140, loss: 0.06192135065793991
step: 150, loss: 0.03887627273797989
step: 160, loss: 0.19131454825401306
step: 170, loss: 0.09209684282541275
step: 180, loss: 0.03393806144595146
step: 190, loss: 0.07441636919975281
step: 200, loss: 0.1548820286989212
step: 210, loss: 0.006818200461566448
step: 220, loss: 0.05100512132048607
step: 230, loss: 0.04175388813018799
step: 240, loss: 0.062173739075660706
step: 250, loss: 0.1483038067817688
step: 260, loss: 0.09973056614398956
step: 270, loss: 0.07767122983932495
step: 280, loss: 0.07272761315107346
step: 290, loss: 0.04030747711658478
step: 300, loss: 0.1605859100818634
step: 310, loss: 0.05135423690080643
step: 320, loss: 0.10760088264942169
step: 330, loss: 0.08092804998159409
step: 340, loss: 0.1691705882549286
step: 350, loss: 0.14569281041622162
epoch 10: dev_f1=0.832535885167464, f1=0.8163265306122449, best_f1=0.8163265306122449
step: 0, loss: 0.09700159728527069
step: 10, loss: 0.051680631935596466
step: 20, loss: 0.05898098647594452
step: 30, loss: 0.060933489352464676
step: 40, loss: 0.07331321388483047
step: 50, loss: 0.01497146487236023
step: 60, loss: 0.1345265656709671
step: 70, loss: 0.03244583681225777
step: 80, loss: 0.09557133913040161
step: 90, loss: 0.023789672181010246
step: 100, loss: 0.046356819570064545
step: 110, loss: 0.06929683685302734
step: 120, loss: 0.06302162259817123
step: 130, loss: 0.03903041407465935
step: 140, loss: 0.10665556788444519
step: 150, loss: 0.04075073450803757
step: 160, loss: 0.052881039679050446
step: 170, loss: 0.11530265212059021
step: 180, loss: 0.0768597349524498
step: 190, loss: 0.08033160120248795
step: 200, loss: 0.13026991486549377
step: 210, loss: 0.08597869426012039
step: 220, loss: 0.11736928671598434
step: 230, loss: 0.027261175215244293
step: 240, loss: 0.05271031707525253
step: 250, loss: 0.0984734371304512
step: 260, loss: 0.08197394758462906
step: 270, loss: 0.163605734705925
step: 280, loss: 0.08895216137170792
step: 290, loss: 0.014953728765249252
step: 300, loss: 0.07070319354534149
step: 310, loss: 0.07754331082105637
step: 320, loss: 0.2529943883419037
step: 330, loss: 0.0440448597073555
step: 340, loss: 0.06345658004283905
step: 350, loss: 0.06794177740812302
epoch 11: dev_f1=0.8472906403940887, f1=0.8337349397590362, best_f1=0.8337349397590362
step: 0, loss: 0.11860001087188721
step: 10, loss: 0.08133404701948166
step: 20, loss: 0.058290883898735046
step: 30, loss: 0.10162568092346191
step: 40, loss: 0.027409585192799568
step: 50, loss: 0.05543769523501396
step: 60, loss: 0.03551901876926422
step: 70, loss: 0.040522828698158264
step: 80, loss: 0.0247394610196352
step: 90, loss: 0.03816197067499161
step: 100, loss: 0.09151822328567505
step: 110, loss: 0.03734574839472771
step: 120, loss: 0.051905307918787
step: 130, loss: 0.07559821009635925
step: 140, loss: 0.045342765748500824
step: 150, loss: 0.06025777757167816
step: 160, loss: 0.00012340764806140214
step: 170, loss: 0.039583969861269
step: 180, loss: 0.07301431149244308
step: 190, loss: 0.12889964878559113
step: 200, loss: 0.018703356385231018
step: 210, loss: 0.0792185515165329
step: 220, loss: 0.1704552173614502
step: 230, loss: 0.08546022325754166
step: 240, loss: 0.052068039774894714
step: 250, loss: 0.18080075085163116
step: 260, loss: 0.08550817519426346
step: 270, loss: 0.06330762803554535
step: 280, loss: 0.09362832456827164
step: 290, loss: 0.10605257004499435
step: 300, loss: 0.08541122078895569
step: 310, loss: 0.10127533972263336
step: 320, loss: 0.06973140686750412
step: 330, loss: 0.05638360232114792
step: 340, loss: 0.20079167187213898
step: 350, loss: 0.15938903391361237
epoch 12: dev_f1=0.8425925925925926, f1=0.8074245939675173, best_f1=0.8337349397590362
step: 0, loss: 0.0651913434267044
step: 10, loss: 0.06352969259023666
step: 20, loss: 0.060451969504356384
step: 30, loss: 0.16401904821395874
step: 40, loss: 0.1435188204050064
step: 50, loss: 0.10845820605754852
step: 60, loss: 0.0795295313000679
step: 70, loss: 0.07081110030412674
step: 80, loss: 0.05056573823094368
step: 90, loss: 0.018130512908101082
step: 100, loss: 0.0858834758400917
step: 110, loss: 0.10017406940460205
step: 120, loss: 0.13334912061691284
step: 130, loss: 0.009240387007594109
step: 140, loss: 0.06469330191612244
step: 150, loss: 0.028915205970406532
step: 160, loss: 0.07729337364435196
step: 170, loss: 0.004913080483675003
step: 180, loss: 0.0670417845249176
step: 190, loss: 0.02653367444872856
step: 200, loss: 0.06676557660102844
step: 210, loss: 0.039963386952877045
step: 220, loss: 0.06623739004135132
step: 230, loss: 0.034234240651130676
step: 240, loss: 0.03433501720428467
step: 250, loss: 0.026292944326996803
step: 260, loss: 0.08347995579242706
step: 270, loss: 0.09374880790710449
step: 280, loss: 0.1124781146645546
step: 290, loss: 0.051078423857688904
step: 300, loss: 0.07332168519496918
step: 310, loss: 0.09533312916755676
step: 320, loss: 0.14320489764213562
step: 330, loss: 0.1092858761548996
step: 340, loss: 0.08556430041790009
step: 350, loss: 0.08096735179424286
epoch 13: dev_f1=0.8300970873786409, f1=0.8144578313253013, best_f1=0.8337349397590362
step: 0, loss: 0.11537204682826996
step: 10, loss: 0.0641460195183754
step: 20, loss: 0.0701821967959404
step: 30, loss: 0.047073110938072205
step: 40, loss: 0.054432082921266556
step: 50, loss: 0.08159893751144409
step: 60, loss: 0.10693932324647903
step: 70, loss: 0.01920248009264469
step: 80, loss: 0.08635452389717102
step: 90, loss: 0.06517981737852097
step: 100, loss: 0.033059507608413696
step: 110, loss: 0.030067535117268562
step: 120, loss: 0.028201431035995483
step: 130, loss: 0.015644332394003868
step: 140, loss: 0.1180955097079277
step: 150, loss: 0.15495923161506653
step: 160, loss: 0.1099591925740242
step: 170, loss: 0.12531036138534546
step: 180, loss: 0.12394178658723831
step: 190, loss: 0.06034707650542259
step: 200, loss: 0.04795267805457115
step: 210, loss: 0.01719774305820465
step: 220, loss: 0.10445272922515869
step: 230, loss: 0.03444661200046539
step: 240, loss: 0.030176714062690735
step: 250, loss: 0.06533578783273697
step: 260, loss: 0.14821669459342957
step: 270, loss: 0.3398861587047577
step: 280, loss: 0.05998454988002777
step: 290, loss: 0.09280138462781906
step: 300, loss: 0.03439787030220032
step: 310, loss: 0.032019443809986115
step: 320, loss: 0.071851447224617
step: 330, loss: 0.10149640589952469
step: 340, loss: 0.05284559726715088
step: 350, loss: 0.07105214893817902
epoch 14: dev_f1=0.837962962962963, f1=0.7954545454545455, best_f1=0.8337349397590362
step: 0, loss: 0.11169895529747009
step: 10, loss: 0.1509685069322586
step: 20, loss: 0.06540803611278534
step: 30, loss: 0.07690488547086716
step: 40, loss: 0.06558116525411606
step: 50, loss: 0.06664196401834488
step: 60, loss: 0.03271494433283806
step: 70, loss: 0.10029873996973038
step: 80, loss: 0.05780898779630661
step: 90, loss: 0.12468130886554718
step: 100, loss: 0.07241601496934891
step: 110, loss: 0.021103816106915474
step: 120, loss: 0.09990343451499939
step: 130, loss: 0.0956617146730423
step: 140, loss: 0.04410950839519501
step: 150, loss: 0.056802619248628616
step: 160, loss: 0.19087687134742737
step: 170, loss: 0.03943253308534622
step: 180, loss: 0.054645977914333344
step: 190, loss: 0.050130926072597504
step: 200, loss: 0.13018962740898132
step: 210, loss: 0.04554685205221176
step: 220, loss: 0.06318745762109756
step: 230, loss: 0.03951931744813919
step: 240, loss: 0.0738021582365036
step: 250, loss: 0.07696282118558884
step: 260, loss: 0.040771063417196274
step: 270, loss: 0.08652736246585846
step: 280, loss: 0.029401108622550964
step: 290, loss: 0.055359847843647
step: 300, loss: 0.04517316073179245
step: 310, loss: 0.05519282817840576
step: 320, loss: 0.018317092210054398
step: 330, loss: 0.07874970138072968
step: 340, loss: 0.054469820111989975
step: 350, loss: 0.0008528101025149226
epoch 15: dev_f1=0.8481927710843373, f1=0.8, best_f1=0.8
step: 0, loss: 0.07588434219360352
step: 10, loss: 0.038261156529188156
step: 20, loss: 0.1053832396864891
step: 30, loss: 0.0805499255657196
step: 40, loss: 0.030272040516138077
step: 50, loss: 0.010104880668222904
step: 60, loss: 0.10090344399213791
step: 70, loss: 0.06696891039609909
step: 80, loss: 0.025833263993263245
step: 90, loss: 0.05709132179617882
step: 100, loss: 0.04488073289394379
step: 110, loss: 0.11949615925550461
step: 120, loss: 0.0504877008497715
step: 130, loss: 0.05676739290356636
step: 140, loss: 0.07558217644691467
step: 150, loss: 0.040571290999650955
step: 160, loss: 0.09184353053569794
step: 170, loss: 0.09332217276096344
step: 180, loss: 0.02987663447856903
step: 190, loss: 0.09057047218084335
step: 200, loss: 0.015193190425634384
step: 210, loss: 0.09543034434318542
step: 220, loss: 0.10368682444095612
step: 230, loss: 0.034501366317272186
step: 240, loss: 0.04385684058070183
step: 250, loss: 0.0076875993981957436
step: 260, loss: 0.01804390735924244
step: 270, loss: 0.0984748899936676
step: 280, loss: 0.10241733491420746
step: 290, loss: 0.06594694405794144
step: 300, loss: 0.08152839541435242
step: 310, loss: 0.0006982081104069948
step: 320, loss: 0.06795773655176163
step: 330, loss: 0.03440362587571144
step: 340, loss: 0.09275273978710175
step: 350, loss: 0.05024844408035278
epoch 16: dev_f1=0.8226600985221675, f1=0.7971360381861575, best_f1=0.8
step: 0, loss: 0.06789492070674896
step: 10, loss: 0.10441930592060089
step: 20, loss: 0.052468106150627136
step: 30, loss: 0.04162207990884781
step: 40, loss: 0.0946868434548378
step: 50, loss: 0.021783752366900444
step: 60, loss: 0.0873279944062233
step: 70, loss: 0.11031016707420349
step: 80, loss: 0.1138509064912796
step: 90, loss: 0.021107394248247147
step: 100, loss: 0.06581468880176544
step: 110, loss: 0.0024785802233964205
step: 120, loss: 0.11436720937490463
step: 130, loss: 0.017063388600945473
step: 140, loss: 0.15437327325344086
step: 150, loss: 0.09497320652008057
step: 160, loss: 0.044336315244436264
step: 170, loss: 0.045649051666259766
step: 180, loss: 0.075064517557621
step: 190, loss: 0.13053718209266663
step: 200, loss: 0.05438130348920822
step: 210, loss: 0.1052277460694313
step: 220, loss: 0.05827988684177399
step: 230, loss: 0.0076126717031002045
step: 240, loss: 0.00015207298565655947
step: 250, loss: 0.11977417767047882
step: 260, loss: 0.053470298647880554
step: 270, loss: 0.06615851819515228
step: 280, loss: 0.01699695736169815
step: 290, loss: 0.07933953404426575
step: 300, loss: 0.12610864639282227
step: 310, loss: 0.10932941734790802
step: 320, loss: 0.07612131536006927
step: 330, loss: 0.0340527705848217
step: 340, loss: 0.04052664339542389
step: 350, loss: 0.013830728828907013
epoch 17: dev_f1=0.8238213399503721, f1=0.8058252427184465, best_f1=0.8
step: 0, loss: 0.043171998113393784
step: 10, loss: 0.11800266802310944
step: 20, loss: 0.04968209192156792
step: 30, loss: 0.07147122174501419
step: 40, loss: 0.041058678179979324
step: 50, loss: 0.049772974103689194
step: 60, loss: 0.0009191019926220179
step: 70, loss: 0.16735945641994476
step: 80, loss: 0.04482194036245346
step: 90, loss: 0.01300511509180069
step: 100, loss: 0.033079516142606735
step: 110, loss: 0.08009575307369232
step: 120, loss: 0.08387741446495056
step: 130, loss: 0.036961629986763
step: 140, loss: 0.049729377031326294
step: 150, loss: 0.06292171031236649
step: 160, loss: 0.10501330345869064
step: 170, loss: 0.08935130387544632
step: 180, loss: 0.020731186494231224
step: 190, loss: 0.050266847014427185
step: 200, loss: 0.024183768779039383
step: 210, loss: 0.041112061589956284
step: 220, loss: 0.05166154354810715
step: 230, loss: 0.11619042605161667
step: 240, loss: 0.05964311957359314
step: 250, loss: 0.0751863569021225
step: 260, loss: 0.04215387627482414
step: 270, loss: 0.06655310839414597
step: 280, loss: 0.0876053124666214
step: 290, loss: 0.08340409398078918
step: 300, loss: 3.7940681067993864e-05
step: 310, loss: 0.06428474187850952
step: 320, loss: 0.06447241455316544
step: 330, loss: 0.03414304181933403
step: 340, loss: 0.010372881777584553
step: 350, loss: 0.12070004642009735
epoch 18: dev_f1=0.8238213399503721, f1=0.8058252427184465, best_f1=0.8
step: 0, loss: 0.030512647703289986
step: 10, loss: 0.041696902364492416
step: 20, loss: 0.008199501782655716
step: 30, loss: 0.036598969250917435
step: 40, loss: 0.028113318607211113
step: 50, loss: 0.05066964030265808
step: 60, loss: 0.1241089478135109
step: 70, loss: 0.07768967002630234
step: 80, loss: 0.061317119747400284
step: 90, loss: 0.07715452462434769
step: 100, loss: 0.06561213731765747
step: 110, loss: 0.033092744648456573
step: 120, loss: 0.03705449402332306
step: 130, loss: 0.04612050950527191
step: 140, loss: 0.07924776524305344
step: 150, loss: 0.03695463761687279
step: 160, loss: 0.0959775447845459
step: 170, loss: 0.0630209818482399
step: 180, loss: 0.07177162915468216
step: 190, loss: 0.05518447980284691
step: 200, loss: 0.02221824787557125
step: 210, loss: 0.12519758939743042
step: 220, loss: 0.09297119081020355
step: 230, loss: 0.1369776725769043
step: 240, loss: 0.025617852807044983
step: 250, loss: 0.08914931863546371
step: 260, loss: 0.059320516884326935
step: 270, loss: 0.06818394362926483
step: 280, loss: 0.13220708072185516
step: 290, loss: 0.032640308141708374
step: 300, loss: 0.10597176849842072
step: 310, loss: 0.023646606132388115
step: 320, loss: 0.0893205925822258
step: 330, loss: 0.06411414593458176
step: 340, loss: 0.06440137326717377
step: 350, loss: 0.06194198131561279
epoch 19: dev_f1=0.8148148148148149, f1=0.802919708029197, best_f1=0.8
step: 0, loss: 0.022364541888237
step: 10, loss: 0.17035047709941864
step: 20, loss: 0.12269050627946854
step: 30, loss: 7.204708526842296e-05
step: 40, loss: 0.11115334182977676
step: 50, loss: 0.02188468538224697
step: 60, loss: 0.03569963574409485
step: 70, loss: 0.09364023059606552
step: 80, loss: 0.000319808314088732
step: 90, loss: 0.02102532796561718
step: 100, loss: 0.05502816662192345
step: 110, loss: 0.02371855080127716
step: 120, loss: 0.08124756813049316
step: 130, loss: 0.08147241920232773
step: 140, loss: 0.10450389236211777
step: 150, loss: 0.052675701677799225
step: 160, loss: 0.005102253053337336
step: 170, loss: 0.04815707728266716
step: 180, loss: 0.05038056522607803
step: 190, loss: 0.10133904218673706
step: 200, loss: 0.05117161571979523
step: 210, loss: 4.0797036490403116e-05
step: 220, loss: 0.10310988873243332
step: 230, loss: 0.05380979925394058
step: 240, loss: 0.092359259724617
step: 250, loss: 0.06880611926317215
step: 260, loss: 0.05717777833342552
step: 270, loss: 0.041805557906627655
step: 280, loss: 0.0008639467414468527
step: 290, loss: 0.15551035106182098
step: 300, loss: 0.0075597260147333145
step: 310, loss: 0.0318484865128994
step: 320, loss: 0.08603629469871521
step: 330, loss: 0.07977135479450226
step: 340, loss: 0.00015880247519817203
step: 350, loss: 0.06233759596943855
epoch 20: dev_f1=0.8049999999999999, f1=0.8048780487804877, best_f1=0.8
