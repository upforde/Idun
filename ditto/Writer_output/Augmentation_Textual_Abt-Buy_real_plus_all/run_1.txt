cuda
Device: cuda
step: 0, loss: 0.8544366359710693
step: 10, loss: 0.4440643787384033
step: 20, loss: 0.3055925965309143
step: 30, loss: 0.44106337428092957
step: 40, loss: 0.15405310690402985
step: 50, loss: 0.4362480342388153
step: 60, loss: 0.5486533045768738
step: 70, loss: 0.33287563920021057
step: 80, loss: 0.0676029622554779
step: 90, loss: 0.3740241527557373
step: 100, loss: 0.4385054409503937
step: 110, loss: 0.1870999038219452
step: 120, loss: 0.5690376162528992
step: 130, loss: 0.26675137877464294
step: 140, loss: 0.29144421219825745
step: 150, loss: 0.25703778862953186
step: 160, loss: 0.2499091625213623
step: 170, loss: 0.3282979428768158
step: 180, loss: 0.1587945818901062
step: 190, loss: 0.2753722667694092
step: 200, loss: 0.35799315571784973
step: 210, loss: 0.30941417813301086
step: 220, loss: 0.2649083733558655
step: 230, loss: 0.2952486276626587
step: 240, loss: 0.17019428312778473
step: 250, loss: 0.29904744029045105
step: 260, loss: 0.28998279571533203
step: 270, loss: 0.185129776597023
step: 280, loss: 0.19626064598560333
step: 290, loss: 0.12560220062732697
step: 300, loss: 0.2888127267360687
step: 310, loss: 0.14995358884334564
step: 320, loss: 0.24032005667686462
step: 330, loss: 0.15322203934192657
step: 340, loss: 0.20590661466121674
step: 350, loss: 0.1098996251821518
epoch 1: dev_f1=0.7441860465116279, f1=0.7477876106194691, best_f1=0.7477876106194691
step: 0, loss: 0.40674325823783875
step: 10, loss: 0.11043106764554977
step: 20, loss: 0.12732085585594177
step: 30, loss: 0.1808003932237625
step: 40, loss: 0.12380179017782211
step: 50, loss: 0.1761355698108673
step: 60, loss: 0.2065737247467041
step: 70, loss: 0.19923743605613708
step: 80, loss: 0.15414966642856598
step: 90, loss: 0.30336248874664307
step: 100, loss: 0.17335349321365356
step: 110, loss: 0.15597215294837952
step: 120, loss: 0.1408788561820984
step: 130, loss: 0.10246922075748444
step: 140, loss: 0.2355148047208786
step: 150, loss: 0.18090413510799408
step: 160, loss: 0.06525417417287827
step: 170, loss: 0.22297969460487366
step: 180, loss: 0.1369701623916626
step: 190, loss: 0.14027249813079834
step: 200, loss: 0.08511921018362045
step: 210, loss: 0.16705958545207977
step: 220, loss: 0.11373022943735123
step: 230, loss: 0.12763115763664246
step: 240, loss: 0.0980888083577156
step: 250, loss: 0.36662164330482483
step: 260, loss: 0.16196879744529724
step: 270, loss: 0.10923156142234802
step: 280, loss: 0.12206082046031952
step: 290, loss: 0.05789458751678467
step: 300, loss: 0.2477758228778839
step: 310, loss: 0.12231561541557312
step: 320, loss: 0.12845464050769806
step: 330, loss: 0.11089377850294113
step: 340, loss: 0.09626021236181259
step: 350, loss: 0.09242680668830872
epoch 2: dev_f1=0.7835990888382688, f1=0.8061674008810573, best_f1=0.8061674008810573
step: 0, loss: 0.07283862680196762
step: 10, loss: 0.2307450771331787
step: 20, loss: 0.13042151927947998
step: 30, loss: 0.2455504685640335
step: 40, loss: 0.0958457812666893
step: 50, loss: 0.15693707764148712
step: 60, loss: 0.10430728644132614
step: 70, loss: 0.13330373167991638
step: 80, loss: 0.19987356662750244
step: 90, loss: 0.15807819366455078
step: 100, loss: 0.1278819888830185
step: 110, loss: 0.12293700128793716
step: 120, loss: 0.1252184361219406
step: 130, loss: 0.08787443488836288
step: 140, loss: 0.17797888815402985
step: 150, loss: 0.11566317826509476
step: 160, loss: 0.10962295532226562
step: 170, loss: 0.051718004047870636
step: 180, loss: 0.10484974831342697
step: 190, loss: 0.11958208680152893
step: 200, loss: 0.05016765370965004
step: 210, loss: 0.06659258902072906
step: 220, loss: 0.05878474563360214
step: 230, loss: 0.06849246472120285
step: 240, loss: 0.1322319060564041
step: 250, loss: 0.1450261026620865
step: 260, loss: 0.10487287491559982
step: 270, loss: 0.23737239837646484
step: 280, loss: 0.050176527351140976
step: 290, loss: 0.10333748161792755
step: 300, loss: 0.11703675985336304
step: 310, loss: 0.06619051098823547
step: 320, loss: 0.08761642873287201
step: 330, loss: 0.08912710845470428
step: 340, loss: 0.036460991948843
step: 350, loss: 0.08210357278585434
epoch 3: dev_f1=0.8037383177570093, f1=0.7902869757174392, best_f1=0.7902869757174392
step: 0, loss: 0.04927550628781319
step: 10, loss: 0.09631615877151489
step: 20, loss: 0.1653568297624588
step: 30, loss: 0.12868312001228333
step: 40, loss: 0.13906532526016235
step: 50, loss: 0.0933263823390007
step: 60, loss: 0.08041268587112427
step: 70, loss: 0.07018781453371048
step: 80, loss: 0.15956781804561615
step: 90, loss: 0.11558151990175247
step: 100, loss: 0.06805768609046936
step: 110, loss: 0.07322379946708679
step: 120, loss: 0.10745368152856827
step: 130, loss: 0.1337253749370575
step: 140, loss: 0.12651582062244415
step: 150, loss: 0.1519707590341568
step: 160, loss: 0.08047717809677124
step: 170, loss: 0.19386503100395203
step: 180, loss: 0.09026023745536804
step: 190, loss: 0.11654882878065109
step: 200, loss: 0.10440927743911743
step: 210, loss: 0.09682522714138031
step: 220, loss: 0.04639443755149841
step: 230, loss: 0.11136561632156372
step: 240, loss: 0.15731751918792725
step: 250, loss: 0.020924532786011696
step: 260, loss: 0.2815658748149872
step: 270, loss: 0.12169688940048218
step: 280, loss: 0.1267879754304886
step: 290, loss: 0.0969916358590126
step: 300, loss: 0.04525085538625717
step: 310, loss: 0.06672927737236023
step: 320, loss: 0.08152157813310623
step: 330, loss: 0.10578864812850952
step: 340, loss: 0.12224575132131577
step: 350, loss: 0.05434860661625862
epoch 4: dev_f1=0.8229885057471265, f1=0.8227272727272728, best_f1=0.8227272727272728
step: 0, loss: 0.04468535631895065
step: 10, loss: 0.08912496268749237
step: 20, loss: 0.034607287496328354
step: 30, loss: 0.1205744817852974
step: 40, loss: 0.047956883907318115
step: 50, loss: 0.08662962913513184
step: 60, loss: 0.1375402808189392
step: 70, loss: 0.09393680840730667
step: 80, loss: 0.12410030514001846
step: 90, loss: 0.10479442775249481
step: 100, loss: 0.07133268564939499
step: 110, loss: 0.041750840842723846
step: 120, loss: 0.10038521885871887
step: 130, loss: 0.11775698512792587
step: 140, loss: 0.0666838139295578
step: 150, loss: 0.11571582406759262
step: 160, loss: 0.2136608064174652
step: 170, loss: 0.09330710768699646
step: 180, loss: 0.13739080727100372
step: 190, loss: 0.05655226856470108
step: 200, loss: 0.1704273521900177
step: 210, loss: 0.2145455777645111
step: 220, loss: 0.01623830758035183
step: 230, loss: 0.15315066277980804
step: 240, loss: 0.11251237988471985
step: 250, loss: 0.08645281195640564
step: 260, loss: 0.04363136738538742
step: 270, loss: 0.01855389028787613
step: 280, loss: 0.3014558255672455
step: 290, loss: 0.10093304514884949
step: 300, loss: 0.04753931984305382
step: 310, loss: 0.058310266584157944
step: 320, loss: 0.1344285011291504
step: 330, loss: 0.04428882896900177
step: 340, loss: 0.058387331664562225
step: 350, loss: 0.05291726812720299
epoch 5: dev_f1=0.834467120181406, f1=0.829596412556054, best_f1=0.829596412556054
step: 0, loss: 0.14501319825649261
step: 10, loss: 0.06900328397750854
step: 20, loss: 0.0796407014131546
step: 30, loss: 0.06455981731414795
step: 40, loss: 0.13274037837982178
step: 50, loss: 0.11774986237287521
step: 60, loss: 0.057726044207811356
step: 70, loss: 0.10715755075216293
step: 80, loss: 0.10128239542245865
step: 90, loss: 0.1821841597557068
step: 100, loss: 0.0037839082069694996
step: 110, loss: 0.048341114073991776
step: 120, loss: 0.17279468476772308
step: 130, loss: 0.08611512929201126
step: 140, loss: 0.08475697040557861
step: 150, loss: 0.20819604396820068
step: 160, loss: 0.09361021220684052
step: 170, loss: 0.1733473539352417
step: 180, loss: 0.094946950674057
step: 190, loss: 0.1167752668261528
step: 200, loss: 0.0686819851398468
step: 210, loss: 0.10162684321403503
step: 220, loss: 0.13450028002262115
step: 230, loss: 0.0837540552020073
step: 240, loss: 0.07018579542636871
step: 250, loss: 0.05929861217737198
step: 260, loss: 0.13216863572597504
step: 270, loss: 0.10167235136032104
step: 280, loss: 0.045531317591667175
step: 290, loss: 0.06877616047859192
step: 300, loss: 0.08297892659902573
step: 310, loss: 0.14533846080303192
step: 320, loss: 0.13028360903263092
step: 330, loss: 0.11591052263975143
step: 340, loss: 0.08093113452196121
step: 350, loss: 0.034543756395578384
epoch 6: dev_f1=0.8281938325991189, f1=0.802547770700637, best_f1=0.829596412556054
step: 0, loss: 0.023457497358322144
step: 10, loss: 0.015340598300099373
step: 20, loss: 0.11996807157993317
step: 30, loss: 0.11011693626642227
step: 40, loss: 0.14802314341068268
step: 50, loss: 0.05457279086112976
step: 60, loss: 0.04959859699010849
step: 70, loss: 0.08920028060674667
step: 80, loss: 0.2885896563529968
step: 90, loss: 0.1053699404001236
step: 100, loss: 0.14173442125320435
step: 110, loss: 0.18486429750919342
step: 120, loss: 0.06837435811758041
step: 130, loss: 0.1495773196220398
step: 140, loss: 0.0014966039452701807
step: 150, loss: 0.10966707020998001
step: 160, loss: 0.03889734670519829
step: 170, loss: 0.13598038256168365
step: 180, loss: 0.17341329157352448
step: 190, loss: 0.06347182393074036
step: 200, loss: 0.03656082600355148
step: 210, loss: 0.028044458478689194
step: 220, loss: 0.05875138193368912
step: 230, loss: 0.12051241844892502
step: 240, loss: 0.07115188986063004
step: 250, loss: 0.030632831156253815
step: 260, loss: 0.02899053879082203
step: 270, loss: 0.12531918287277222
step: 280, loss: 0.21747411787509918
step: 290, loss: 0.09603163599967957
step: 300, loss: 0.134330153465271
step: 310, loss: 0.13859611749649048
step: 320, loss: 0.08064913749694824
step: 330, loss: 0.18688616156578064
step: 340, loss: 0.08128546178340912
step: 350, loss: 0.02144448831677437
epoch 7: dev_f1=0.8205128205128204, f1=0.8036529680365296, best_f1=0.829596412556054
step: 0, loss: 0.06522147357463837
step: 10, loss: 0.20813922584056854
step: 20, loss: 0.027791475877165794
step: 30, loss: 0.044768303632736206
step: 40, loss: 0.07146093994379044
step: 50, loss: 0.008922969922423363
step: 60, loss: 0.08093868941068649
step: 70, loss: 0.12510129809379578
step: 80, loss: 0.09851907938718796
step: 90, loss: 0.06387610733509064
step: 100, loss: 0.08115048706531525
step: 110, loss: 0.11867422610521317
step: 120, loss: 0.020782535895705223
step: 130, loss: 0.034251827746629715
step: 140, loss: 0.08189352601766586
step: 150, loss: 0.09133797883987427
step: 160, loss: 0.08998386561870575
step: 170, loss: 0.1301538348197937
step: 180, loss: 0.09336969256401062
step: 190, loss: 0.09472189098596573
step: 200, loss: 0.053966276347637177
step: 210, loss: 0.05672602355480194
step: 220, loss: 0.07119022309780121
step: 230, loss: 0.1361144781112671
step: 240, loss: 0.06417523324489594
step: 250, loss: 0.0011670533567667007
step: 260, loss: 0.23454977571964264
step: 270, loss: 0.04704667627811432
step: 280, loss: 0.12360040843486786
step: 290, loss: 0.03616268187761307
step: 300, loss: 0.11195022612810135
step: 310, loss: 0.22421708703041077
step: 320, loss: 0.04566405341029167
step: 330, loss: 0.12803184986114502
step: 340, loss: 0.17635752260684967
step: 350, loss: 0.1259993463754654
epoch 8: dev_f1=0.8167053364269141, f1=0.8018018018018017, best_f1=0.829596412556054
step: 0, loss: 0.0785791426897049
step: 10, loss: 0.08164210617542267
step: 20, loss: 0.1367138922214508
step: 30, loss: 0.09148521721363068
step: 40, loss: 0.06046321988105774
step: 50, loss: 0.10115381330251694
step: 60, loss: 0.03725166991353035
step: 70, loss: 0.05885785073041916
step: 80, loss: 0.04318026453256607
step: 90, loss: 0.20660056173801422
step: 100, loss: 0.06330231577157974
step: 110, loss: 0.07828275859355927
step: 120, loss: 0.03708387538790703
step: 130, loss: 0.016734322533011436
step: 140, loss: 0.05373275279998779
step: 150, loss: 0.04530436545610428
step: 160, loss: 0.14192888140678406
step: 170, loss: 0.10073240101337433
step: 180, loss: 0.08317912369966507
step: 190, loss: 0.042392440140247345
step: 200, loss: 0.05868075042963028
step: 210, loss: 0.19654954969882965
step: 220, loss: 0.12844547629356384
step: 230, loss: 0.07598995417356491
step: 240, loss: 0.07714240252971649
step: 250, loss: 0.07399345934391022
step: 260, loss: 0.0930965393781662
step: 270, loss: 0.0983867347240448
step: 280, loss: 0.19253666698932648
step: 290, loss: 0.039938244968652725
step: 300, loss: 0.11547371000051498
step: 310, loss: 0.07447987794876099
step: 320, loss: 0.0010731280781328678
step: 330, loss: 0.020181361585855484
step: 340, loss: 0.30813178420066833
step: 350, loss: 0.04418380558490753
epoch 9: dev_f1=0.8438228438228438, f1=0.815165876777251, best_f1=0.815165876777251
step: 0, loss: 0.07925127446651459
step: 10, loss: 0.07192020118236542
step: 20, loss: 0.05004189535975456
step: 30, loss: 0.04668246954679489
step: 40, loss: 0.09087955951690674
step: 50, loss: 0.056056633591651917
step: 60, loss: 0.05888668820261955
step: 70, loss: 0.07536622136831284
step: 80, loss: 0.10149683803319931
step: 90, loss: 0.04568535089492798
step: 100, loss: 0.10318797826766968
step: 110, loss: 0.04649794474244118
step: 120, loss: 0.028341948986053467
step: 130, loss: 0.054267991334199905
step: 140, loss: 0.09033529460430145
step: 150, loss: 0.1027982085943222
step: 160, loss: 0.09855271130800247
step: 170, loss: 0.05285566300153732
step: 180, loss: 0.1596183478832245
step: 190, loss: 0.03768312931060791
step: 200, loss: 0.13471542298793793
step: 210, loss: 0.13148842751979828
step: 220, loss: 0.07607344537973404
step: 230, loss: 0.047592226415872574
step: 240, loss: 0.022419100627303123
step: 250, loss: 0.00018281179654877633
step: 260, loss: 0.0572558268904686
step: 270, loss: 0.11149071156978607
step: 280, loss: 0.13641764223575592
step: 290, loss: 0.0860816091299057
step: 300, loss: 0.12123730778694153
step: 310, loss: 0.16685189306735992
step: 320, loss: 0.1523994505405426
step: 330, loss: 0.1353890597820282
step: 340, loss: 0.029964614659547806
step: 350, loss: 0.02004990540444851
epoch 10: dev_f1=0.8221153846153845, f1=0.7923627684964201, best_f1=0.815165876777251
step: 0, loss: 0.15050606429576874
step: 10, loss: 0.15630163252353668
step: 20, loss: 0.08594831079244614
step: 30, loss: 0.12623189389705658
step: 40, loss: 0.047902174293994904
step: 50, loss: 0.10505776852369308
step: 60, loss: 0.05927914381027222
step: 70, loss: 0.06773746758699417
step: 80, loss: 0.09707260876893997
step: 90, loss: 0.03933315351605415
step: 100, loss: 0.11866642534732819
step: 110, loss: 0.026461709290742874
step: 120, loss: 0.0894923061132431
step: 130, loss: 0.07553912699222565
step: 140, loss: 0.07963776588439941
step: 150, loss: 0.05456053093075752
step: 160, loss: 0.08212248235940933
step: 170, loss: 0.07729047536849976
step: 180, loss: 0.038774523884058
step: 190, loss: 0.07475465536117554
step: 200, loss: 0.1321699470281601
step: 210, loss: 0.023483913391828537
step: 220, loss: 0.1016106903553009
step: 230, loss: 0.08769940584897995
step: 240, loss: 0.07676933705806732
step: 250, loss: 0.08037085831165314
step: 260, loss: 0.06324698776006699
step: 270, loss: 0.0761215016245842
step: 280, loss: 0.07250388711690903
step: 290, loss: 0.03303081914782524
step: 300, loss: 0.0642395094037056
step: 310, loss: 0.007049920037388802
step: 320, loss: 0.08419889956712723
step: 330, loss: 0.11249550431966782
step: 340, loss: 0.046821389347314835
step: 350, loss: 0.1678188145160675
epoch 11: dev_f1=0.8436018957345971, f1=0.7887323943661971, best_f1=0.815165876777251
step: 0, loss: 0.045098237693309784
step: 10, loss: 0.06993824988603592
step: 20, loss: 0.09125205874443054
step: 30, loss: 0.07449141144752502
step: 40, loss: 8.288653043564409e-05
step: 50, loss: 0.07900826632976532
step: 60, loss: 0.07803000509738922
step: 70, loss: 0.06330268085002899
step: 80, loss: 8.156449621310458e-05
step: 90, loss: 0.04430811479687691
step: 100, loss: 0.05867626890540123
step: 110, loss: 0.11110090464353561
step: 120, loss: 0.10577357560396194
step: 130, loss: 0.031525105237960815
step: 140, loss: 0.06762290000915527
step: 150, loss: 0.0774567723274231
step: 160, loss: 0.06319090723991394
step: 170, loss: 0.19401098787784576
step: 180, loss: 0.0538177490234375
step: 190, loss: 0.1728525310754776
step: 200, loss: 0.02345813810825348
step: 210, loss: 0.06492925435304642
step: 220, loss: 0.08367150276899338
step: 230, loss: 0.0676949992775917
step: 240, loss: 0.08173736184835434
step: 250, loss: 0.08823419362306595
step: 260, loss: 0.038180433213710785
step: 270, loss: 0.02240864560008049
step: 280, loss: 0.08541134744882584
step: 290, loss: 0.08579971641302109
step: 300, loss: 0.052394937723875046
step: 310, loss: 0.052328430116176605
step: 320, loss: 0.12688742578029633
step: 330, loss: 0.025280937552452087
step: 340, loss: 0.0695539340376854
step: 350, loss: 0.04804570972919464
epoch 12: dev_f1=0.8283752860411899, f1=0.7865168539325842, best_f1=0.815165876777251
step: 0, loss: 0.030937956646084785
step: 10, loss: 0.06420561671257019
step: 20, loss: 0.18199782073497772
step: 30, loss: 0.04967054724693298
step: 40, loss: 0.010470734909176826
step: 50, loss: 0.1278829425573349
step: 60, loss: 0.022158240899443626
step: 70, loss: 0.09138669073581696
step: 80, loss: 0.045196112245321274
step: 90, loss: 0.17580389976501465
step: 100, loss: 0.07258802652359009
step: 110, loss: 0.05100233107805252
step: 120, loss: 0.19879408180713654
step: 130, loss: 0.07131502777338028
step: 140, loss: 0.026353340595960617
step: 150, loss: 0.3004661798477173
step: 160, loss: 0.0799998790025711
step: 170, loss: 0.1888124942779541
step: 180, loss: 0.13035748898983002
step: 190, loss: 0.07290773093700409
step: 200, loss: 0.09661944955587387
step: 210, loss: 0.10765080899000168
step: 220, loss: 0.04242885485291481
step: 230, loss: 0.04792279750108719
step: 240, loss: 0.06548212468624115
step: 250, loss: 0.010465451516211033
step: 260, loss: 0.059195030480623245
step: 270, loss: 0.09605539590120316
step: 280, loss: 0.11034458130598068
step: 290, loss: 0.017475299537181854
step: 300, loss: 0.09990550577640533
step: 310, loss: 0.02161005325615406
step: 320, loss: 0.05553213506937027
step: 330, loss: 0.07674266397953033
step: 340, loss: 0.052025482058525085
step: 350, loss: 0.1116160973906517
epoch 13: dev_f1=0.8413793103448276, f1=0.7881548974943052, best_f1=0.815165876777251
step: 0, loss: 0.0658189207315445
step: 10, loss: 0.08515780419111252
step: 20, loss: 0.07140833139419556
step: 30, loss: 0.03900287672877312
step: 40, loss: 0.30406850576400757
step: 50, loss: 0.044641099870204926
step: 60, loss: 0.07720386981964111
step: 70, loss: 0.027231700718402863
step: 80, loss: 0.11904983967542648
step: 90, loss: 0.012256334535777569
step: 100, loss: 0.11199353635311127
step: 110, loss: 0.05850335210561752
step: 120, loss: 0.07413448393344879
step: 130, loss: 0.039840999990701675
step: 140, loss: 0.11343972384929657
step: 150, loss: 0.06281579285860062
step: 160, loss: 0.04570693150162697
step: 170, loss: 0.10396505147218704
step: 180, loss: 0.10404396057128906
step: 190, loss: 0.10675107687711716
step: 200, loss: 0.04855875298380852
step: 210, loss: 0.0959513857960701
step: 220, loss: 0.07238531112670898
step: 230, loss: 0.11430530250072479
step: 240, loss: 0.09550705552101135
step: 250, loss: 0.03818958252668381
step: 260, loss: 0.08986998349428177
step: 270, loss: 0.028290249407291412
step: 280, loss: 0.02470003254711628
step: 290, loss: 0.1211855486035347
step: 300, loss: 0.06400280445814133
step: 310, loss: 0.025836218148469925
step: 320, loss: 0.044680070132017136
step: 330, loss: 0.019597498700022697
step: 340, loss: 0.024337735027074814
step: 350, loss: 0.05567131191492081
epoch 14: dev_f1=0.8293838862559242, f1=0.8028503562945368, best_f1=0.815165876777251
step: 0, loss: 0.013690289109945297
step: 10, loss: 0.08848758786916733
step: 20, loss: 0.059527650475502014
step: 30, loss: 0.05660980939865112
step: 40, loss: 0.049620501697063446
step: 50, loss: 0.08156926929950714
step: 60, loss: 0.0729871615767479
step: 70, loss: 0.052290040999650955
step: 80, loss: 0.005491419695317745
step: 90, loss: 0.07876106351613998
step: 100, loss: 0.04864034429192543
step: 110, loss: 0.07825993001461029
step: 120, loss: 0.06359941512346268
step: 130, loss: 0.13156777620315552
step: 140, loss: 0.02735249698162079
step: 150, loss: 0.06352054327726364
step: 160, loss: 0.03979064151644707
step: 170, loss: 0.05353759974241257
step: 180, loss: 0.06836903840303421
step: 190, loss: 0.04947083070874214
step: 200, loss: 0.06464606523513794
step: 210, loss: 0.14297601580619812
step: 220, loss: 0.07150818407535553
step: 230, loss: 0.08590621501207352
step: 240, loss: 0.16397623717784882
step: 250, loss: 0.03282970190048218
step: 260, loss: 0.09447692334651947
step: 270, loss: 4.1054736357182264e-05
step: 280, loss: 0.13235414028167725
step: 290, loss: 0.06857692450284958
step: 300, loss: 0.08901061117649078
step: 310, loss: 0.10366946458816528
step: 320, loss: 0.06162072718143463
step: 330, loss: 0.13112476468086243
step: 340, loss: 0.06660311669111252
step: 350, loss: 0.024902569130063057
epoch 15: dev_f1=0.8246445497630333, f1=0.7912621359223301, best_f1=0.815165876777251
step: 0, loss: 0.013445530086755753
step: 10, loss: 0.10130085051059723
step: 20, loss: 0.07573580741882324
step: 30, loss: 0.01473958883434534
step: 40, loss: 0.024616822600364685
step: 50, loss: 0.08923588693141937
step: 60, loss: 0.04940022900700569
step: 70, loss: 0.06605600565671921
step: 80, loss: 0.045897021889686584
step: 90, loss: 0.08406234532594681
step: 100, loss: 0.06716259568929672
step: 110, loss: 0.016026856377720833
step: 120, loss: 0.04621238633990288
step: 130, loss: 0.017795320600271225
step: 140, loss: 0.18502464890480042
step: 150, loss: 0.09035284072160721
step: 160, loss: 0.007981647737324238
step: 170, loss: 0.13381700217723846
step: 180, loss: 0.0722966343164444
step: 190, loss: 0.055411338806152344
step: 200, loss: 0.034961577504873276
step: 210, loss: 0.07639825344085693
step: 220, loss: 0.10758654773235321
step: 230, loss: 0.11352667212486267
step: 240, loss: 0.02005886100232601
step: 250, loss: 0.028967974707484245
step: 260, loss: 0.06884487718343735
step: 270, loss: 0.03807159885764122
step: 280, loss: 0.014919490553438663
step: 290, loss: 0.051931094378232956
step: 300, loss: 0.07587762922048569
step: 310, loss: 0.05523526668548584
step: 320, loss: 0.12428466975688934
step: 330, loss: 0.11295082420110703
step: 340, loss: 0.018892459571361542
step: 350, loss: 0.014963803812861443
epoch 16: dev_f1=0.8329297820823245, f1=0.7970297029702972, best_f1=0.815165876777251
step: 0, loss: 0.15260478854179382
step: 10, loss: 0.0800062045454979
step: 20, loss: 0.041118815541267395
step: 30, loss: 0.011909513734281063
step: 40, loss: 0.11349218338727951
step: 50, loss: 4.16550574300345e-05
step: 60, loss: 0.1595204919576645
step: 70, loss: 0.03589596599340439
step: 80, loss: 0.186826691031456
step: 90, loss: 0.07749278843402863
step: 100, loss: 0.01542660966515541
step: 110, loss: 0.07808451354503632
step: 120, loss: 0.053008999675512314
step: 130, loss: 0.1516960710287094
step: 140, loss: 0.12057358026504517
step: 150, loss: 0.11481661349534988
step: 160, loss: 0.05675783008337021
step: 170, loss: 0.053696341812610626
step: 180, loss: 0.09192509204149246
step: 190, loss: 0.09494461119174957
step: 200, loss: 0.07793200016021729
step: 210, loss: 0.051563579589128494
step: 220, loss: 0.07899603247642517
step: 230, loss: 0.028017455711960793
step: 240, loss: 0.0705433338880539
step: 250, loss: 0.08374424278736115
step: 260, loss: 0.022871829569339752
step: 270, loss: 0.06659641116857529
step: 280, loss: 0.07642066478729248
step: 290, loss: 0.02968011610209942
step: 300, loss: 0.021447530016303062
step: 310, loss: 0.03955187276005745
step: 320, loss: 0.028005216270685196
step: 330, loss: 0.06633627414703369
step: 340, loss: 0.11079616099596024
step: 350, loss: 0.021061308681964874
epoch 17: dev_f1=0.8114558472553699, f1=0.7846889952153109, best_f1=0.815165876777251
step: 0, loss: 0.08980251103639603
step: 10, loss: 0.051060691475868225
step: 20, loss: 0.018789060413837433
step: 30, loss: 0.03748626634478569
step: 40, loss: 0.148018479347229
step: 50, loss: 0.04491806775331497
step: 60, loss: 0.08738133311271667
step: 70, loss: 0.08372162282466888
step: 80, loss: 0.12940777838230133
step: 90, loss: 0.08826607465744019
step: 100, loss: 0.06863068789243698
step: 110, loss: 0.044348131865262985
step: 120, loss: 2.2172594981384464e-05
step: 130, loss: 0.09374765306711197
step: 140, loss: 0.04325244575738907
step: 150, loss: 0.036285802721977234
step: 160, loss: 0.08200810104608536
step: 170, loss: 0.12676967680454254
step: 180, loss: 0.015811067074537277
step: 190, loss: 0.08795984089374542
step: 200, loss: 0.08308381587266922
step: 210, loss: 0.018298588693141937
step: 220, loss: 0.14863282442092896
step: 230, loss: 0.04220917448401451
step: 240, loss: 0.11146722733974457
step: 250, loss: 0.053739435970783234
step: 260, loss: 0.019137119874358177
step: 270, loss: 0.06652827560901642
step: 280, loss: 0.03369799628853798
step: 290, loss: 0.01925426349043846
step: 300, loss: 0.06325080990791321
step: 310, loss: 0.12339849025011063
step: 320, loss: 0.13200651109218597
step: 330, loss: 0.07622962445020676
step: 340, loss: 0.21130070090293884
step: 350, loss: 0.04108694940805435
epoch 18: dev_f1=0.8285714285714285, f1=0.7893462469733656, best_f1=0.815165876777251
step: 0, loss: 0.042931314557790756
step: 10, loss: 0.10816195607185364
step: 20, loss: 0.07044234126806259
step: 30, loss: 0.03147592023015022
step: 40, loss: 0.04230913147330284
step: 50, loss: 0.03929825499653816
step: 60, loss: 0.06301210820674896
step: 70, loss: 0.011935609392821789
step: 80, loss: 3.08704111375846e-05
step: 90, loss: 0.015844939276576042
step: 100, loss: 0.04903826862573624
step: 110, loss: 0.0326676219701767
step: 120, loss: 0.043455831706523895
step: 130, loss: 0.03367510810494423
step: 140, loss: 0.046193189918994904
step: 150, loss: 0.06715831160545349
step: 160, loss: 0.015963522717356682
step: 170, loss: 0.03094160370528698
step: 180, loss: 0.00010634216596372426
step: 190, loss: 0.026880254969000816
step: 200, loss: 0.028481779620051384
step: 210, loss: 0.14135833084583282
step: 220, loss: 0.06808467209339142
step: 230, loss: 0.06012347713112831
step: 240, loss: 2.9089707823004574e-05
step: 250, loss: 0.05056210979819298
step: 260, loss: 0.009479896165430546
step: 270, loss: 0.013263882137835026
step: 280, loss: 0.057391904294490814
step: 290, loss: 0.10077723860740662
step: 300, loss: 0.07808980345726013
step: 310, loss: 0.03852760046720505
step: 320, loss: 0.03811322897672653
step: 330, loss: 0.06854114681482315
step: 340, loss: 0.013260253705084324
step: 350, loss: 0.07958567142486572
epoch 19: dev_f1=0.832535885167464, f1=0.7892156862745098, best_f1=0.815165876777251
step: 0, loss: 0.014937853440642357
step: 10, loss: 0.05901435762643814
step: 20, loss: 0.06380569934844971
step: 30, loss: 0.03881505876779556
step: 40, loss: 0.06586648523807526
step: 50, loss: 6.372549978550524e-05
step: 60, loss: 0.06478356570005417
step: 70, loss: 0.07007388770580292
step: 80, loss: 0.014558342285454273
step: 90, loss: 0.04286855459213257
step: 100, loss: 2.7052405130234547e-05
step: 110, loss: 0.07238943874835968
step: 120, loss: 0.07534679025411606
step: 130, loss: 0.01822705566883087
step: 140, loss: 0.05490497872233391
step: 150, loss: 0.13524270057678223
step: 160, loss: 0.06423544883728027
step: 170, loss: 0.11359711736440659
step: 180, loss: 0.08811105787754059
step: 190, loss: 0.07784342020750046
step: 200, loss: 0.03123912215232849
step: 210, loss: 0.043902844190597534
step: 220, loss: 3.803240542765707e-05
step: 230, loss: 0.08203049004077911
step: 240, loss: 0.09699596464633942
step: 250, loss: 0.05858387425541878
step: 260, loss: 0.11337084323167801
step: 270, loss: 0.06651564687490463
step: 280, loss: 0.061144597828388214
step: 290, loss: 0.06387735903263092
step: 300, loss: 0.08771196007728577
step: 310, loss: 0.07342144101858139
step: 320, loss: 0.10989578068256378
step: 330, loss: 0.06395356357097626
step: 340, loss: 0.026879550889134407
step: 350, loss: 0.026273779571056366
epoch 20: dev_f1=0.832535885167464, f1=0.794188861985472, best_f1=0.815165876777251
