cuda
Device: cuda
step: 0, loss: 0.9058597683906555
step: 10, loss: 0.32102054357528687
step: 20, loss: 0.304845929145813
step: 30, loss: 0.17541751265525818
step: 40, loss: 0.4253796935081482
step: 50, loss: 0.34513384103775024
step: 60, loss: 0.562228798866272
step: 70, loss: 0.1635565161705017
step: 80, loss: 0.5011182427406311
step: 90, loss: 0.16735517978668213
step: 100, loss: 0.29907068610191345
step: 110, loss: 0.40751534700393677
step: 120, loss: 0.13229556381702423
step: 130, loss: 0.4090922772884369
step: 140, loss: 0.22206832468509674
step: 150, loss: 0.36694762110710144
step: 160, loss: 0.2426958829164505
step: 170, loss: 0.13774794340133667
step: 180, loss: 0.2938500642776489
step: 190, loss: 0.33420002460479736
step: 200, loss: 0.13026657700538635
step: 210, loss: 0.25332918763160706
step: 220, loss: 0.3530574142932892
step: 230, loss: 0.1541232317686081
step: 240, loss: 0.21968255937099457
step: 250, loss: 0.2545064389705658
step: 260, loss: 0.3859083950519562
step: 270, loss: 0.13770440220832825
step: 280, loss: 0.2805500626564026
step: 290, loss: 0.4009055495262146
step: 300, loss: 0.0776996836066246
step: 310, loss: 0.20963537693023682
step: 320, loss: 0.2563258409500122
step: 330, loss: 0.18182705342769623
step: 340, loss: 0.25392574071884155
step: 350, loss: 0.19749708473682404
epoch 1: dev_f1=0.7020785219399538, f1=0.6986301369863014, best_f1=0.6986301369863014
step: 0, loss: 0.2817545235157013
step: 10, loss: 0.03585846349596977
step: 20, loss: 0.22450101375579834
step: 30, loss: 0.1650923788547516
step: 40, loss: 0.08800181746482849
step: 50, loss: 0.38872578740119934
step: 60, loss: 0.12736637890338898
step: 70, loss: 0.15466603636741638
step: 80, loss: 0.242639422416687
step: 90, loss: 0.2674322724342346
step: 100, loss: 0.05197715759277344
step: 110, loss: 0.3406371772289276
step: 120, loss: 0.2089851051568985
step: 130, loss: 0.14077948033809662
step: 140, loss: 0.14851495623588562
step: 150, loss: 0.13470713794231415
step: 160, loss: 0.08547838032245636
step: 170, loss: 0.2768920660018921
step: 180, loss: 0.15282797813415527
step: 190, loss: 0.17528939247131348
step: 200, loss: 0.11941167712211609
step: 210, loss: 0.031042350456118584
step: 220, loss: 0.3043203353881836
step: 230, loss: 0.09155134111642838
step: 240, loss: 0.2066580206155777
step: 250, loss: 0.09403347223997116
step: 260, loss: 0.14878115057945251
step: 270, loss: 0.18128633499145508
step: 280, loss: 0.24334174394607544
step: 290, loss: 0.09938200563192368
step: 300, loss: 0.36269718408584595
step: 310, loss: 0.13429303467273712
step: 320, loss: 0.11485026031732559
step: 330, loss: 0.1911623775959015
step: 340, loss: 0.12472548335790634
step: 350, loss: 0.18237321078777313
epoch 2: dev_f1=0.7855421686746988, f1=0.7801418439716311, best_f1=0.7801418439716311
step: 0, loss: 0.12011105567216873
step: 10, loss: 0.11013386398553848
step: 20, loss: 0.05278223007917404
step: 30, loss: 0.1526169329881668
step: 40, loss: 0.1887987107038498
step: 50, loss: 0.051007628440856934
step: 60, loss: 0.11166825890541077
step: 70, loss: 0.07964704930782318
step: 80, loss: 0.12014009058475494
step: 90, loss: 0.19347591698169708
step: 100, loss: 0.14545008540153503
step: 110, loss: 0.10797462612390518
step: 120, loss: 0.06987354159355164
step: 130, loss: 0.1399255245923996
step: 140, loss: 0.1773912012577057
step: 150, loss: 0.17907574772834778
step: 160, loss: 0.13345396518707275
step: 170, loss: 0.029446672648191452
step: 180, loss: 0.07623108476400375
step: 190, loss: 0.08200482279062271
step: 200, loss: 0.0758437067270279
step: 210, loss: 0.09510846436023712
step: 220, loss: 0.10342306643724442
step: 230, loss: 0.07953488081693649
step: 240, loss: 0.16662131249904633
step: 250, loss: 0.12761099636554718
step: 260, loss: 0.13173127174377441
step: 270, loss: 0.141551673412323
step: 280, loss: 0.22485776245594025
step: 290, loss: 0.07102064043283463
step: 300, loss: 0.08413490653038025
step: 310, loss: 0.16657063364982605
step: 320, loss: 0.11525554209947586
step: 330, loss: 0.10059671849012375
step: 340, loss: 0.127431720495224
step: 350, loss: 0.1559172421693802
epoch 3: dev_f1=0.8101851851851851, f1=0.7828054298642534, best_f1=0.7828054298642534
step: 0, loss: 0.12115447223186493
step: 10, loss: 0.09825467318296432
step: 20, loss: 0.16716063022613525
step: 30, loss: 0.0678558349609375
step: 40, loss: 0.04627629369497299
step: 50, loss: 0.12732376158237457
step: 60, loss: 0.15156982839107513
step: 70, loss: 0.04053335636854172
step: 80, loss: 0.08308558911085129
step: 90, loss: 0.04679226875305176
step: 100, loss: 0.08066286891698837
step: 110, loss: 0.11534138768911362
step: 120, loss: 0.11986389756202698
step: 130, loss: 0.16798558831214905
step: 140, loss: 0.056138236075639725
step: 150, loss: 0.0931650921702385
step: 160, loss: 0.2491248995065689
step: 170, loss: 0.05493864789605141
step: 180, loss: 0.1462193876504898
step: 190, loss: 0.06430549174547195
step: 200, loss: 0.19244496524333954
step: 210, loss: 0.07229172438383102
step: 220, loss: 0.009322858415544033
step: 230, loss: 0.15498395264148712
step: 240, loss: 0.038760650902986526
step: 250, loss: 0.21617579460144043
step: 260, loss: 0.042866963893175125
step: 270, loss: 0.04546070471405983
step: 280, loss: 0.12574930489063263
step: 290, loss: 0.16214880347251892
step: 300, loss: 0.06094343215227127
step: 310, loss: 0.083209328353405
step: 320, loss: 0.17697656154632568
step: 330, loss: 0.1298786699771881
step: 340, loss: 0.08346865326166153
step: 350, loss: 0.13167133927345276
epoch 4: dev_f1=0.796420581655481, f1=0.7839643652561248, best_f1=0.7828054298642534
step: 0, loss: 0.11794816702604294
step: 10, loss: 0.013174171559512615
step: 20, loss: 0.4263328015804291
step: 30, loss: 0.06978411972522736
step: 40, loss: 0.04566513001918793
step: 50, loss: 0.0671016126871109
step: 60, loss: 0.14033524692058563
step: 70, loss: 0.18145452439785004
step: 80, loss: 0.04367479309439659
step: 90, loss: 0.11401330679655075
step: 100, loss: 0.0362531840801239
step: 110, loss: 0.10582205653190613
step: 120, loss: 0.042662329971790314
step: 130, loss: 0.06631704419851303
step: 140, loss: 0.08229925483465195
step: 150, loss: 0.11482700705528259
step: 160, loss: 0.20341067016124725
step: 170, loss: 0.18957845866680145
step: 180, loss: 0.078632652759552
step: 190, loss: 0.09609885513782501
step: 200, loss: 0.1664706915616989
step: 210, loss: 0.20023436844348907
step: 220, loss: 0.06084221974015236
step: 230, loss: 0.04398617148399353
step: 240, loss: 0.05917717143893242
step: 250, loss: 0.05799910053610802
step: 260, loss: 0.007210293784737587
step: 270, loss: 0.016459142789244652
step: 280, loss: 0.05865927040576935
step: 290, loss: 0.10853257030248642
step: 300, loss: 0.13709509372711182
step: 310, loss: 0.1904640644788742
step: 320, loss: 0.004105578176677227
step: 330, loss: 0.14997228980064392
step: 340, loss: 0.052426304668188095
step: 350, loss: 0.15250322222709656
epoch 5: dev_f1=0.7885985748218527, f1=0.7888631090487238, best_f1=0.7828054298642534
step: 0, loss: 0.056219432502985
step: 10, loss: 0.14229410886764526
step: 20, loss: 0.08360452950000763
step: 30, loss: 0.11187267303466797
step: 40, loss: 0.17033110558986664
step: 50, loss: 0.12870004773139954
step: 60, loss: 0.09665561467409134
step: 70, loss: 0.03948710113763809
step: 80, loss: 0.07329526543617249
step: 90, loss: 0.06686785817146301
step: 100, loss: 0.049088090658187866
step: 110, loss: 0.13707943260669708
step: 120, loss: 0.1541420966386795
step: 130, loss: 0.06541407108306885
step: 140, loss: 0.0640186071395874
step: 150, loss: 0.09435940533876419
step: 160, loss: 0.04549239203333855
step: 170, loss: 0.06337679922580719
step: 180, loss: 0.07488840073347092
step: 190, loss: 0.09457731992006302
step: 200, loss: 0.15014278888702393
step: 210, loss: 0.054336708039045334
step: 220, loss: 0.09437038749456406
step: 230, loss: 0.03990403935313225
step: 240, loss: 0.10021016746759415
step: 250, loss: 0.059177201241254807
step: 260, loss: 0.024355730041861534
step: 270, loss: 0.0888955220580101
step: 280, loss: 0.04111187160015106
step: 290, loss: 0.11649644374847412
step: 300, loss: 0.04966457933187485
step: 310, loss: 0.17774637043476105
step: 320, loss: 0.09333271533250809
step: 330, loss: 0.02606726624071598
step: 340, loss: 0.08253122866153717
step: 350, loss: 0.0760386511683464
epoch 6: dev_f1=0.8141592920353982, f1=0.7974137931034483, best_f1=0.7974137931034483
step: 0, loss: 0.07871390879154205
step: 10, loss: 0.13686928153038025
step: 20, loss: 0.08416423946619034
step: 30, loss: 0.09733827412128448
step: 40, loss: 0.04907708987593651
step: 50, loss: 0.012338210828602314
step: 60, loss: 0.09730345010757446
step: 70, loss: 0.09700591117143631
step: 80, loss: 0.11854799836874008
step: 90, loss: 0.06382156163454056
step: 100, loss: 0.016655534505844116
step: 110, loss: 0.10164539515972137
step: 120, loss: 0.12489169090986252
step: 130, loss: 0.058502405881881714
step: 140, loss: 0.11953530460596085
step: 150, loss: 0.10100078582763672
step: 160, loss: 0.12868812680244446
step: 170, loss: 0.021059980615973473
step: 180, loss: 0.0033067245967686176
step: 190, loss: 0.10166352242231369
step: 200, loss: 0.12210015207529068
step: 210, loss: 0.026798434555530548
step: 220, loss: 0.12496113032102585
step: 230, loss: 0.07630034536123276
step: 240, loss: 0.08768142759799957
step: 250, loss: 0.020289471372961998
step: 260, loss: 0.059321437031030655
step: 270, loss: 0.12318617105484009
step: 280, loss: 0.13631577789783478
step: 290, loss: 0.1188250184059143
step: 300, loss: 0.17043322324752808
step: 310, loss: 0.10210985690355301
step: 320, loss: 0.03095252253115177
step: 330, loss: 0.09214000403881073
step: 340, loss: 0.10656090825796127
step: 350, loss: 0.10761900991201401
epoch 7: dev_f1=0.8108108108108107, f1=0.7991071428571428, best_f1=0.7974137931034483
step: 0, loss: 0.06451776623725891
step: 10, loss: 0.099180668592453
step: 20, loss: 0.0832117572426796
step: 30, loss: 0.0979059711098671
step: 40, loss: 0.0965024009346962
step: 50, loss: 0.047123201191425323
step: 60, loss: 0.07837928086519241
step: 70, loss: 0.1173979714512825
step: 80, loss: 0.08463966101408005
step: 90, loss: 0.052261561155319214
step: 100, loss: 0.14173577725887299
step: 110, loss: 0.11222928762435913
step: 120, loss: 0.06286898255348206
step: 130, loss: 0.08343537151813507
step: 140, loss: 0.07336971908807755
step: 150, loss: 0.07810404896736145
step: 160, loss: 0.051131341606378555
step: 170, loss: 0.07475584000349045
step: 180, loss: 0.06812181323766708
step: 190, loss: 0.04846508800983429
step: 200, loss: 0.08756741136312485
step: 210, loss: 0.07536263763904572
step: 220, loss: 0.10028202831745148
step: 230, loss: 0.017785586416721344
step: 240, loss: 0.08262938261032104
step: 250, loss: 0.06352920085191727
step: 260, loss: 0.05395997315645218
step: 270, loss: 0.076331228017807
step: 280, loss: 0.18888120353221893
step: 290, loss: 0.19850021600723267
step: 300, loss: 0.1319587528705597
step: 310, loss: 0.04870147630572319
step: 320, loss: 0.08736536651849747
step: 330, loss: 0.02169998735189438
step: 340, loss: 0.055255092680454254
step: 350, loss: 0.060281526297330856
epoch 8: dev_f1=0.8057553956834533, f1=0.8215962441314554, best_f1=0.7974137931034483
step: 0, loss: 0.05584298074245453
step: 10, loss: 0.05915108323097229
step: 20, loss: 0.09352391213178635
step: 30, loss: 0.04857019707560539
step: 40, loss: 0.021520547568798065
step: 50, loss: 0.12582778930664062
step: 60, loss: 0.05529468506574631
step: 70, loss: 0.06697220355272293
step: 80, loss: 0.030907971784472466
step: 90, loss: 0.04010789841413498
step: 100, loss: 0.07175084948539734
step: 110, loss: 0.24465687572956085
step: 120, loss: 0.13857322931289673
step: 130, loss: 0.04283061996102333
step: 140, loss: 0.1406412422657013
step: 150, loss: 0.000500367081258446
step: 160, loss: 0.07475832104682922
step: 170, loss: 0.035180553793907166
step: 180, loss: 0.05758623778820038
step: 190, loss: 0.015390566550195217
step: 200, loss: 0.17442041635513306
step: 210, loss: 0.263436883687973
step: 220, loss: 0.0649687647819519
step: 230, loss: 0.030698392540216446
step: 240, loss: 0.13142207264900208
step: 250, loss: 0.05866922438144684
step: 260, loss: 0.06227569282054901
step: 270, loss: 0.0009728951845318079
step: 280, loss: 0.10671254247426987
step: 290, loss: 0.05012081190943718
step: 300, loss: 0.13078778982162476
step: 310, loss: 0.037676699459552765
step: 320, loss: 0.08507436513900757
step: 330, loss: 0.019148167222738266
step: 340, loss: 0.0335376113653183
step: 350, loss: 0.08162149041891098
epoch 9: dev_f1=0.8202764976958525, f1=0.8106904231625837, best_f1=0.8106904231625837
step: 0, loss: 0.03979639336466789
step: 10, loss: 0.08222678303718567
step: 20, loss: 0.07738453149795532
step: 30, loss: 0.09119030088186264
step: 40, loss: 0.021829314529895782
step: 50, loss: 0.057323865592479706
step: 60, loss: 0.12812022864818573
step: 70, loss: 0.02054406888782978
step: 80, loss: 0.08804420381784439
step: 90, loss: 0.08643104135990143
step: 100, loss: 0.16411636769771576
step: 110, loss: 0.13508862257003784
step: 120, loss: 0.04328379034996033
step: 130, loss: 0.07880706340074539
step: 140, loss: 0.12250815331935883
step: 150, loss: 0.041831668466329575
step: 160, loss: 0.0647164136171341
step: 170, loss: 0.03293197974562645
step: 180, loss: 0.14445988833904266
step: 190, loss: 0.07885225862264633
step: 200, loss: 0.06968919187784195
step: 210, loss: 0.043292086571455
step: 220, loss: 0.07574046403169632
step: 230, loss: 0.07117442786693573
step: 240, loss: 0.03345464915037155
step: 250, loss: 0.1275883913040161
step: 260, loss: 0.041499193757772446
step: 270, loss: 0.03250293433666229
step: 280, loss: 0.061131544411182404
step: 290, loss: 0.1064235270023346
step: 300, loss: 0.05801288038492203
step: 310, loss: 0.03223227337002754
step: 320, loss: 0.04413243755698204
step: 330, loss: 0.1382002830505371
step: 340, loss: 0.04841160774230957
step: 350, loss: 0.11249637603759766
epoch 10: dev_f1=0.8215962441314554, f1=0.8213457076566126, best_f1=0.8213457076566126
step: 0, loss: 0.05795411020517349
step: 10, loss: 0.06621671468019485
step: 20, loss: 0.06035734713077545
step: 30, loss: 0.11009043455123901
step: 40, loss: 0.10472355037927628
step: 50, loss: 0.21425609290599823
step: 60, loss: 0.0649491548538208
step: 70, loss: 0.10963223874568939
step: 80, loss: 0.022000208497047424
step: 90, loss: 0.05230822041630745
step: 100, loss: 0.05776968598365784
step: 110, loss: 0.0605667419731617
step: 120, loss: 0.07772578299045563
step: 130, loss: 0.06422949582338333
step: 140, loss: 0.06940567493438721
step: 150, loss: 0.07441245764493942
step: 160, loss: 0.030952421948313713
step: 170, loss: 0.06856627017259598
step: 180, loss: 0.04620121791958809
step: 190, loss: 0.12127458304166794
step: 200, loss: 0.1334541141986847
step: 210, loss: 0.07951058447360992
step: 220, loss: 0.10870323330163956
step: 230, loss: 0.17097380757331848
step: 240, loss: 0.05564792826771736
step: 250, loss: 0.042063940316438675
step: 260, loss: 0.04507966712117195
step: 270, loss: 0.11858613789081573
step: 280, loss: 0.0791119784116745
step: 290, loss: 0.09842099994421005
step: 300, loss: 0.07386884093284607
step: 310, loss: 0.15157875418663025
step: 320, loss: 0.06405844539403915
step: 330, loss: 0.14864932000637054
step: 340, loss: 0.10879577696323395
step: 350, loss: 0.09491075575351715
epoch 11: dev_f1=0.8352668213457077, f1=0.8175519630484988, best_f1=0.8175519630484988
step: 0, loss: 0.07564910501241684
step: 10, loss: 0.04998716339468956
step: 20, loss: 0.10297077894210815
step: 30, loss: 0.045191943645477295
step: 40, loss: 0.06992983818054199
step: 50, loss: 0.03268156200647354
step: 60, loss: 0.06111400946974754
step: 70, loss: 0.034366488456726074
step: 80, loss: 0.09199278056621552
step: 90, loss: 0.09891145676374435
step: 100, loss: 0.0865195095539093
step: 110, loss: 0.01361756306141615
step: 120, loss: 0.061426639556884766
step: 130, loss: 0.09285871684551239
step: 140, loss: 0.029651636257767677
step: 150, loss: 0.06910514086484909
step: 160, loss: 0.07570929825305939
step: 170, loss: 0.1600285768508911
step: 180, loss: 0.13168716430664062
step: 190, loss: 0.02535705640912056
step: 200, loss: 0.06720570474863052
step: 210, loss: 0.02074083685874939
step: 220, loss: 0.0826401636004448
step: 230, loss: 0.07822903245687485
step: 240, loss: 0.06226059049367905
step: 250, loss: 0.05120246112346649
step: 260, loss: 0.02924368530511856
step: 270, loss: 0.037159886211156845
step: 280, loss: 0.08599783480167389
step: 290, loss: 0.06195295974612236
step: 300, loss: 0.0036967380437999964
step: 310, loss: 0.024550726637244225
step: 320, loss: 0.04816345497965813
step: 330, loss: 0.04274237900972366
step: 340, loss: 0.08771242201328278
step: 350, loss: 0.032816994935274124
epoch 12: dev_f1=0.8129675810473815, f1=0.827930174563591, best_f1=0.8175519630484988
step: 0, loss: 0.07216765731573105
step: 10, loss: 0.13898667693138123
step: 20, loss: 0.1368882656097412
step: 30, loss: 0.13144703209400177
step: 40, loss: 0.09345626085996628
step: 50, loss: 0.0639987662434578
step: 60, loss: 0.00035519193625077605
step: 70, loss: 0.06155986711382866
step: 80, loss: 0.08882632106542587
step: 90, loss: 0.028930004686117172
step: 100, loss: 0.04049576073884964
step: 110, loss: 0.09236115217208862
step: 120, loss: 0.054633621126413345
step: 130, loss: 8.160525612765923e-05
step: 140, loss: 0.029562178999185562
step: 150, loss: 0.08237121999263763
step: 160, loss: 0.01826055906713009
step: 170, loss: 0.0482962429523468
step: 180, loss: 0.06840945780277252
step: 190, loss: 0.05716802924871445
step: 200, loss: 0.10330292582511902
step: 210, loss: 0.06916838139295578
step: 220, loss: 0.12563103437423706
step: 230, loss: 0.012544152326881886
step: 240, loss: 0.056078650057315826
step: 250, loss: 0.020682448521256447
step: 260, loss: 0.040839772671461105
step: 270, loss: 0.027587847784161568
step: 280, loss: 0.05715030059218407
step: 290, loss: 0.061632268130779266
step: 300, loss: 0.06249208003282547
step: 310, loss: 0.08162893354892731
step: 320, loss: 0.01616664044559002
step: 330, loss: 0.131159707903862
step: 340, loss: 0.060087885707616806
step: 350, loss: 0.10097280889749527
epoch 13: dev_f1=0.8114558472553699, f1=0.8266033254156769, best_f1=0.8175519630484988
step: 0, loss: 0.08259523659944534
step: 10, loss: 0.1066773384809494
step: 20, loss: 0.04930901899933815
step: 30, loss: 0.051024243235588074
step: 40, loss: 0.08698694407939911
step: 50, loss: 0.14067448675632477
step: 60, loss: 0.15070024132728577
step: 70, loss: 0.10749146342277527
step: 80, loss: 0.031842004507780075
step: 90, loss: 0.07681088149547577
step: 100, loss: 0.09357517957687378
step: 110, loss: 0.09637363255023956
step: 120, loss: 0.06998482346534729
step: 130, loss: 0.06577761471271515
step: 140, loss: 0.06354300677776337
step: 150, loss: 0.08642846345901489
step: 160, loss: 0.09991342574357986
step: 170, loss: 0.0853131115436554
step: 180, loss: 0.016826171427965164
step: 190, loss: 0.12338580191135406
step: 200, loss: 0.13058911263942719
step: 210, loss: 0.034220680594444275
step: 220, loss: 0.08222836256027222
step: 230, loss: 0.01425768993794918
step: 240, loss: 0.03623849153518677
step: 250, loss: 0.07206905633211136
step: 260, loss: 0.11662042140960693
step: 270, loss: 0.07056223601102829
step: 280, loss: 0.03561735525727272
step: 290, loss: 0.09445199370384216
step: 300, loss: 0.037620097398757935
step: 310, loss: 0.08707201480865479
step: 320, loss: 0.030104614794254303
step: 330, loss: 0.06059041991829872
step: 340, loss: 0.08325869590044022
step: 350, loss: 0.15419554710388184
epoch 14: dev_f1=0.8115942028985508, f1=0.8257756563245824, best_f1=0.8175519630484988
step: 0, loss: 0.09952862560749054
step: 10, loss: 0.12909726798534393
step: 20, loss: 0.15351413190364838
step: 30, loss: 0.08797852694988251
step: 40, loss: 0.06772267073392868
step: 50, loss: 0.01266647782176733
step: 60, loss: 0.03326918184757233
step: 70, loss: 0.09551098197698593
step: 80, loss: 0.09324238449335098
step: 90, loss: 0.08835863322019577
step: 100, loss: 0.01367857400327921
step: 110, loss: 0.012395174242556095
step: 120, loss: 0.022243326529860497
step: 130, loss: 0.13031494617462158
step: 140, loss: 0.03948969766497612
step: 150, loss: 0.03584347292780876
step: 160, loss: 0.06967365741729736
step: 170, loss: 0.0760190337896347
step: 180, loss: 0.11905274540185928
step: 190, loss: 0.04138217866420746
step: 200, loss: 0.0540253147482872
step: 210, loss: 0.03027969039976597
step: 220, loss: 0.11330141127109528
step: 230, loss: 0.21465162932872772
step: 240, loss: 0.09401801973581314
step: 250, loss: 0.057034675031900406
step: 260, loss: 0.07566438615322113
step: 270, loss: 0.09150762110948563
step: 280, loss: 0.12441989034414291
step: 290, loss: 0.08293765783309937
step: 300, loss: 0.041401997208595276
step: 310, loss: 0.04679848253726959
step: 320, loss: 0.05215585604310036
step: 330, loss: 0.06938639283180237
step: 340, loss: 0.07428028434515
step: 350, loss: 0.12641949951648712
epoch 15: dev_f1=0.8083140877598153, f1=0.8211009174311925, best_f1=0.8175519630484988
step: 0, loss: 0.06558859348297119
step: 10, loss: 0.09153300523757935
step: 20, loss: 0.07005595415830612
step: 30, loss: 0.06837381422519684
step: 40, loss: 0.08409040421247482
step: 50, loss: 0.15173204243183136
step: 60, loss: 0.04248756542801857
step: 70, loss: 0.010186037980020046
step: 80, loss: 0.022194990888237953
step: 90, loss: 0.04747319966554642
step: 100, loss: 0.0705438032746315
step: 110, loss: 0.08105410635471344
step: 120, loss: 0.16637259721755981
step: 130, loss: 0.052010707557201385
step: 140, loss: 0.050743695348501205
step: 150, loss: 0.06097841635346413
step: 160, loss: 0.07316174358129501
step: 170, loss: 0.05486033111810684
step: 180, loss: 0.00017145134916063398
step: 190, loss: 0.10011562705039978
step: 200, loss: 0.09727930277585983
step: 210, loss: 0.038500186055898666
step: 220, loss: 0.06326620280742645
step: 230, loss: 0.10669798403978348
step: 240, loss: 0.0978747308254242
step: 250, loss: 0.022774713113904
step: 260, loss: 0.039474617689847946
step: 270, loss: 0.034090764820575714
step: 280, loss: 0.0526391938328743
step: 290, loss: 0.04238543286919594
step: 300, loss: 0.011036430485546589
step: 310, loss: 0.070640429854393
step: 320, loss: 0.09032715857028961
step: 330, loss: 0.07094547897577286
step: 340, loss: 0.05874064192175865
step: 350, loss: 0.03528623282909393
epoch 16: dev_f1=0.8088235294117646, f1=0.8066037735849056, best_f1=0.8175519630484988
step: 0, loss: 0.07128182053565979
step: 10, loss: 0.05861341953277588
step: 20, loss: 0.036120615899562836
step: 30, loss: 0.07124992460012436
step: 40, loss: 0.1035807728767395
step: 50, loss: 0.0805632546544075
step: 60, loss: 0.11979130655527115
step: 70, loss: 0.07082108408212662
step: 80, loss: 0.03975723311305046
step: 90, loss: 0.048956096172332764
step: 100, loss: 0.00021741772070527077
step: 110, loss: 0.12050702422857285
step: 120, loss: 0.053309131413698196
step: 130, loss: 0.041250213980674744
step: 140, loss: 0.10103205591440201
step: 150, loss: 0.11704656481742859
step: 160, loss: 0.01967197097837925
step: 170, loss: 0.0679873675107956
step: 180, loss: 0.050347328186035156
step: 190, loss: 0.1282360702753067
step: 200, loss: 0.06833299994468689
step: 210, loss: 0.0879790335893631
step: 220, loss: 0.054731983691453934
step: 230, loss: 0.06620271503925323
step: 240, loss: 0.11829055100679398
step: 250, loss: 0.09866780042648315
step: 260, loss: 0.04190149903297424
step: 270, loss: 0.021769726648926735
step: 280, loss: 0.03686700761318207
step: 290, loss: 0.05649607628583908
step: 300, loss: 0.08341465890407562
step: 310, loss: 0.1217145025730133
step: 320, loss: 0.03216635063290596
step: 330, loss: 0.1159501001238823
step: 340, loss: 0.13240356743335724
step: 350, loss: 0.048403505235910416
epoch 17: dev_f1=0.8078602620087336, f1=0.8, best_f1=0.8175519630484988
step: 0, loss: 0.03527090698480606
step: 10, loss: 0.08670327812433243
step: 20, loss: 0.04916774481534958
step: 30, loss: 0.031258728355169296
step: 40, loss: 0.03651007264852524
step: 50, loss: 0.07014267146587372
step: 60, loss: 0.10257651656866074
step: 70, loss: 0.23138637840747833
step: 80, loss: 0.04434194415807724
step: 90, loss: 0.10577034205198288
step: 100, loss: 0.018903667107224464
step: 110, loss: 0.08744575828313828
step: 120, loss: 0.0491795688867569
step: 130, loss: 0.045303959399461746
step: 140, loss: 0.10138997435569763
step: 150, loss: 0.029809288680553436
step: 160, loss: 0.14653173089027405
step: 170, loss: 0.04141054302453995
step: 180, loss: 0.033592477440834045
step: 190, loss: 0.06059599667787552
step: 200, loss: 0.04720083996653557
step: 210, loss: 0.08487821370363235
step: 220, loss: 0.06496678292751312
step: 230, loss: 0.11847586184740067
step: 240, loss: 0.03263457864522934
step: 250, loss: 0.03257998079061508
step: 260, loss: 0.09325060993432999
step: 270, loss: 0.03186303377151489
step: 280, loss: 0.06705537438392639
step: 290, loss: 0.03135519474744797
step: 300, loss: 0.06814903020858765
step: 310, loss: 0.046901825815439224
step: 320, loss: 0.053639430552721024
step: 330, loss: 0.16017746925354004
step: 340, loss: 0.03514135628938675
step: 350, loss: 0.07847554236650467
epoch 18: dev_f1=0.7980295566502462, f1=0.8019559902200489, best_f1=0.8175519630484988
step: 0, loss: 0.08180641382932663
step: 10, loss: 0.07913380861282349
step: 20, loss: 0.05268110707402229
step: 30, loss: 0.03786715120077133
step: 40, loss: 0.036719053983688354
step: 50, loss: 0.034937575459480286
step: 60, loss: 0.042402464896440506
step: 70, loss: 0.024137187749147415
step: 80, loss: 0.013842449523508549
step: 90, loss: 0.04659849405288696
step: 100, loss: 0.08069250732660294
step: 110, loss: 0.08573654294013977
step: 120, loss: 0.07168307900428772
step: 130, loss: 0.028484810143709183
step: 140, loss: 0.03525364771485329
step: 150, loss: 0.040530841797590256
step: 160, loss: 0.08785280585289001
step: 170, loss: 0.03316005319356918
step: 180, loss: 0.09069238603115082
step: 190, loss: 0.07055966556072235
step: 200, loss: 0.06532708555459976
step: 210, loss: 0.04861124977469444
step: 220, loss: 0.15796074271202087
step: 230, loss: 0.05080568790435791
step: 240, loss: 0.04264954850077629
step: 250, loss: 0.01521792821586132
step: 260, loss: 0.04316028207540512
step: 270, loss: 0.13771243393421173
step: 280, loss: 0.012350666336715221
step: 290, loss: 0.05894675478339195
step: 300, loss: 0.10216259211301804
step: 310, loss: 0.053690288215875626
step: 320, loss: 0.08531259745359421
step: 330, loss: 0.029872393235564232
step: 340, loss: 0.07516549527645111
step: 350, loss: 0.0722581073641777
epoch 19: dev_f1=0.7960199004975125, f1=0.7960199004975125, best_f1=0.8175519630484988
step: 0, loss: 0.0503879152238369
step: 10, loss: 0.05588109418749809
step: 20, loss: 0.10228931903839111
step: 30, loss: 0.1131308376789093
step: 40, loss: 0.019824538379907608
step: 50, loss: 0.08283539861440659
step: 60, loss: 0.037705812603235245
step: 70, loss: 0.06825839728116989
step: 80, loss: 0.00667766947299242
step: 90, loss: 0.042376626282930374
step: 100, loss: 0.11365556716918945
step: 110, loss: 0.01012719701975584
step: 120, loss: 0.1365956962108612
step: 130, loss: 0.09575767070055008
step: 140, loss: 0.04348771274089813
step: 150, loss: 0.09440434724092484
step: 160, loss: 0.07761084288358688
step: 170, loss: 0.08002328127622604
step: 180, loss: 0.12978090345859528
step: 190, loss: 0.010886750183999538
step: 200, loss: 0.04117651656270027
step: 210, loss: 0.030069539323449135
step: 220, loss: 0.01731606386601925
step: 230, loss: 0.05412973463535309
step: 240, loss: 0.016248555853962898
step: 250, loss: 0.1077573150396347
step: 260, loss: 0.03570054471492767
step: 270, loss: 0.026789601892232895
step: 280, loss: 0.04719818755984306
step: 290, loss: 0.014955556951463223
step: 300, loss: 0.10910698026418686
step: 310, loss: 0.127829909324646
step: 320, loss: 0.10362214595079422
step: 330, loss: 0.05500635504722595
step: 340, loss: 0.031047390773892403
step: 350, loss: 0.14098739624023438
epoch 20: dev_f1=0.7941176470588236, f1=0.8019323671497586, best_f1=0.8175519630484988
