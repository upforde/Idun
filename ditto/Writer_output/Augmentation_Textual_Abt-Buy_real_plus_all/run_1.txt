cuda
Device: cuda
step: 0, loss: 0.5543488264083862
step: 10, loss: 0.3090856969356537
step: 20, loss: 0.08500955253839493
step: 30, loss: 0.4615650773048401
step: 40, loss: 0.41420304775238037
step: 50, loss: 0.3125901520252228
step: 60, loss: 0.18588761985301971
step: 70, loss: 0.4271600842475891
step: 80, loss: 0.39884185791015625
step: 90, loss: 0.26280686259269714
step: 100, loss: 0.33433663845062256
step: 110, loss: 0.3548685610294342
step: 120, loss: 0.34702908992767334
step: 130, loss: 0.2815309762954712
step: 140, loss: 0.3195820450782776
step: 150, loss: 0.3349281847476959
step: 160, loss: 0.433305948972702
step: 170, loss: 0.3128865659236908
step: 180, loss: 0.2860702872276306
step: 190, loss: 0.19180302321910858
step: 200, loss: 0.24076701700687408
step: 210, loss: 0.175951287150383
step: 220, loss: 0.04135272279381752
step: 230, loss: 0.2596365213394165
step: 240, loss: 0.11509812623262405
step: 250, loss: 0.20556196570396423
step: 260, loss: 0.16361404955387115
step: 270, loss: 0.15662986040115356
step: 280, loss: 0.2287193089723587
step: 290, loss: 0.10466843843460083
step: 300, loss: 0.11781563609838486
step: 310, loss: 0.09423206001520157
step: 320, loss: 0.1832684427499771
step: 330, loss: 0.15165120363235474
step: 340, loss: 0.1856909543275833
step: 350, loss: 0.08706264197826385
epoch 1: dev_f1=0.7299270072992701, f1=0.7470449172576832, best_f1=0.7470449172576832
step: 0, loss: 0.17466221749782562
step: 10, loss: 0.11877091974020004
step: 20, loss: 0.14770743250846863
step: 30, loss: 0.268669456243515
step: 40, loss: 0.19127057492733002
step: 50, loss: 0.10194649547338486
step: 60, loss: 0.13856132328510284
step: 70, loss: 0.1786007285118103
step: 80, loss: 0.21006202697753906
step: 90, loss: 0.22242668271064758
step: 100, loss: 0.10285025835037231
step: 110, loss: 0.14212486147880554
step: 120, loss: 0.11486415565013885
step: 130, loss: 0.17590491473674774
step: 140, loss: 0.11553087085485458
step: 150, loss: 0.1075713038444519
step: 160, loss: 0.1329585313796997
step: 170, loss: 0.10874756425619125
step: 180, loss: 0.18580995500087738
step: 190, loss: 0.11242803186178207
step: 200, loss: 0.12274379283189774
step: 210, loss: 0.23347912728786469
step: 220, loss: 0.09829860925674438
step: 230, loss: 0.053342148661613464
step: 240, loss: 0.14982078969478607
step: 250, loss: 0.16424937546253204
step: 260, loss: 0.11818931251764297
step: 270, loss: 0.17460006475448608
step: 280, loss: 0.14215780794620514
step: 290, loss: 0.08699532598257065
step: 300, loss: 0.08643369376659393
step: 310, loss: 0.23500603437423706
step: 320, loss: 0.056320592761039734
step: 330, loss: 0.07195659726858139
step: 340, loss: 0.21953809261322021
step: 350, loss: 0.16662020981311798
epoch 2: dev_f1=0.7695961995249406, f1=0.7592592592592593, best_f1=0.7592592592592593
step: 0, loss: 0.09048581123352051
step: 10, loss: 0.10622698068618774
step: 20, loss: 0.06864310801029205
step: 30, loss: 0.0901448205113411
step: 40, loss: 0.03613024204969406
step: 50, loss: 0.08660965412855148
step: 60, loss: 0.08252377063035965
step: 70, loss: 0.1225588396191597
step: 80, loss: 0.0928504467010498
step: 90, loss: 0.07830674946308136
step: 100, loss: 0.05839693173766136
step: 110, loss: 0.1324356347322464
step: 120, loss: 0.13778972625732422
step: 130, loss: 0.05923319235444069
step: 140, loss: 0.07096201926469803
step: 150, loss: 0.118605837225914
step: 160, loss: 0.15908753871917725
step: 170, loss: 0.05590929463505745
step: 180, loss: 0.20646676421165466
step: 190, loss: 0.0898931697010994
step: 200, loss: 0.08260716497898102
step: 210, loss: 0.08001190423965454
step: 220, loss: 0.042985688894987106
step: 230, loss: 0.05910583212971687
step: 240, loss: 0.1119467243552208
step: 250, loss: 0.07926081866025925
step: 260, loss: 0.13902980089187622
step: 270, loss: 0.167803555727005
step: 280, loss: 0.1459888368844986
step: 290, loss: 0.030138390138745308
step: 300, loss: 0.18048888444900513
step: 310, loss: 0.1592227816581726
step: 320, loss: 0.16557948291301727
step: 330, loss: 0.18366949260234833
step: 340, loss: 0.11817624419927597
step: 350, loss: 0.19064272940158844
epoch 3: dev_f1=0.8071748878923766, f1=0.7964989059080964, best_f1=0.7964989059080964
step: 0, loss: 0.263114869594574
step: 10, loss: 0.17867320775985718
step: 20, loss: 0.04967367649078369
step: 30, loss: 0.016236508265137672
step: 40, loss: 0.16410969197750092
step: 50, loss: 0.09884943813085556
step: 60, loss: 0.13437961041927338
step: 70, loss: 0.039423175156116486
step: 80, loss: 0.11268819123506546
step: 90, loss: 0.1875714212656021
step: 100, loss: 0.00699981115758419
step: 110, loss: 0.051787376403808594
step: 120, loss: 0.020862987264990807
step: 130, loss: 0.14262640476226807
step: 140, loss: 0.105766661465168
step: 150, loss: 0.13946260511875153
step: 160, loss: 0.3008608818054199
step: 170, loss: 0.17665094137191772
step: 180, loss: 0.12693586945533752
step: 190, loss: 0.1590758115053177
step: 200, loss: 0.1091049388051033
step: 210, loss: 0.12706242501735687
step: 220, loss: 0.08631674200296402
step: 230, loss: 0.1281592845916748
step: 240, loss: 0.2549133896827698
step: 250, loss: 0.11758455634117126
step: 260, loss: 0.2765558660030365
step: 270, loss: 0.16436472535133362
step: 280, loss: 0.2066904455423355
step: 290, loss: 0.1394330859184265
step: 300, loss: 0.06341292709112167
step: 310, loss: 0.07130694389343262
step: 320, loss: 0.12030309438705444
step: 330, loss: 0.14024583995342255
step: 340, loss: 0.11609211564064026
step: 350, loss: 0.09482142329216003
epoch 4: dev_f1=0.8156682027649769, f1=0.7824175824175823, best_f1=0.7824175824175823
step: 0, loss: 0.2051265835762024
step: 10, loss: 0.23762531578540802
step: 20, loss: 0.10506295412778854
step: 30, loss: 0.07683313637971878
step: 40, loss: 0.03816288709640503
step: 50, loss: 0.1578197330236435
step: 60, loss: 0.16758547723293304
step: 70, loss: 0.09159757941961288
step: 80, loss: 0.06141642853617668
step: 90, loss: 0.22298118472099304
step: 100, loss: 0.05413671210408211
step: 110, loss: 0.040720272809267044
step: 120, loss: 0.2134634405374527
step: 130, loss: 0.03827665373682976
step: 140, loss: 0.1446373462677002
step: 150, loss: 0.11907042562961578
step: 160, loss: 0.03914520889520645
step: 170, loss: 0.11677781492471695
step: 180, loss: 0.1159319207072258
step: 190, loss: 0.06276670843362808
step: 200, loss: 0.04512769728899002
step: 210, loss: 0.033585578203201294
step: 220, loss: 0.08740830421447754
step: 230, loss: 0.06202711537480354
step: 240, loss: 0.04503130167722702
step: 250, loss: 0.0484977662563324
step: 260, loss: 0.02130007930099964
step: 270, loss: 0.13025973737239838
step: 280, loss: 0.13320079445838928
step: 290, loss: 0.16560634970664978
step: 300, loss: 0.17217984795570374
step: 310, loss: 0.11698848009109497
step: 320, loss: 0.03478163853287697
step: 330, loss: 0.10277963429689407
step: 340, loss: 0.15668508410453796
step: 350, loss: 0.16457752883434296
epoch 5: dev_f1=0.8267898383371824, f1=0.8096280087527353, best_f1=0.8096280087527353
step: 0, loss: 0.013929519802331924
step: 10, loss: 0.04718181863427162
step: 20, loss: 0.06885988265275955
step: 30, loss: 0.034179434180259705
step: 40, loss: 0.013050302863121033
step: 50, loss: 0.08117489516735077
step: 60, loss: 0.10743345320224762
step: 70, loss: 0.07009513676166534
step: 80, loss: 0.04830339923501015
step: 90, loss: 0.08283616602420807
step: 100, loss: 0.1131582036614418
step: 110, loss: 0.04226668179035187
step: 120, loss: 0.07814302295446396
step: 130, loss: 0.08753310889005661
step: 140, loss: 0.07064544409513474
step: 150, loss: 0.0778106302022934
step: 160, loss: 0.17076081037521362
step: 170, loss: 0.07778019458055496
step: 180, loss: 0.06867054104804993
step: 190, loss: 0.14426261186599731
step: 200, loss: 0.08305735886096954
step: 210, loss: 0.07509897649288177
step: 220, loss: 0.15507619082927704
step: 230, loss: 0.07864310592412949
step: 240, loss: 0.10116498172283173
step: 250, loss: 0.03360402584075928
step: 260, loss: 0.11677622050046921
step: 270, loss: 0.07314258813858032
step: 280, loss: 0.10274609178304672
step: 290, loss: 0.051111526787281036
step: 300, loss: 0.11534353345632553
step: 310, loss: 0.08660221099853516
step: 320, loss: 0.08123555034399033
step: 330, loss: 0.06150943785905838
step: 340, loss: 0.11081189662218094
step: 350, loss: 0.1256662905216217
epoch 6: dev_f1=0.8341013824884792, f1=0.8078602620087336, best_f1=0.8078602620087336
step: 0, loss: 0.039323072880506516
step: 10, loss: 0.06731518357992172
step: 20, loss: 0.14841830730438232
step: 30, loss: 0.11616138368844986
step: 40, loss: 0.05808873102068901
step: 50, loss: 0.060163792222738266
step: 60, loss: 0.170838862657547
step: 70, loss: 0.11549855768680573
step: 80, loss: 0.0546128936111927
step: 90, loss: 0.06419471651315689
step: 100, loss: 0.10512194037437439
step: 110, loss: 0.06308813393115997
step: 120, loss: 0.04636458680033684
step: 130, loss: 0.10556397587060928
step: 140, loss: 0.14130038022994995
step: 150, loss: 0.09016542136669159
step: 160, loss: 0.09638219326734543
step: 170, loss: 0.14117592573165894
step: 180, loss: 0.0766289085149765
step: 190, loss: 0.05462871119379997
step: 200, loss: 0.1022830381989479
step: 210, loss: 0.06587791442871094
step: 220, loss: 0.10720524191856384
step: 230, loss: 0.1617385298013687
step: 240, loss: 0.037651900202035904
step: 250, loss: 0.01420780923217535
step: 260, loss: 0.08585984259843826
step: 270, loss: 0.08436166495084763
step: 280, loss: 0.07494530081748962
step: 290, loss: 0.11610500514507294
step: 300, loss: 0.05388389527797699
step: 310, loss: 0.05140557140111923
step: 320, loss: 0.16356128454208374
step: 330, loss: 0.041833486407995224
step: 340, loss: 0.09921533614397049
step: 350, loss: 0.03192822262644768
epoch 7: dev_f1=0.8423423423423423, f1=0.8211920529801324, best_f1=0.8211920529801324
step: 0, loss: 0.12693233788013458
step: 10, loss: 0.08379267156124115
step: 20, loss: 0.06593569368124008
step: 30, loss: 0.09737968444824219
step: 40, loss: 0.028015829622745514
step: 50, loss: 0.10215306282043457
step: 60, loss: 0.10192079097032547
step: 70, loss: 0.13571548461914062
step: 80, loss: 0.07879354804754257
step: 90, loss: 0.24403248727321625
step: 100, loss: 0.08778631687164307
step: 110, loss: 0.06979988515377045
step: 120, loss: 0.12900318205356598
step: 130, loss: 0.002217056229710579
step: 140, loss: 0.043872784823179245
step: 150, loss: 0.1428219974040985
step: 160, loss: 0.10864146053791046
step: 170, loss: 0.0667223259806633
step: 180, loss: 0.11182602494955063
step: 190, loss: 0.12906955182552338
step: 200, loss: 0.07482398301362991
step: 210, loss: 0.13959452509880066
step: 220, loss: 0.0750306099653244
step: 230, loss: 0.1093377023935318
step: 240, loss: 0.15676537156105042
step: 250, loss: 0.18530407547950745
step: 260, loss: 0.0529724657535553
step: 270, loss: 0.14920297265052795
step: 280, loss: 0.04114094749093056
step: 290, loss: 0.07573215663433075
step: 300, loss: 0.10717862844467163
step: 310, loss: 0.02858736366033554
step: 320, loss: 0.049206193536520004
step: 330, loss: 0.11615104228258133
step: 340, loss: 0.11265996098518372
step: 350, loss: 0.08122199028730392
epoch 8: dev_f1=0.8457943925233645, f1=0.8090909090909091, best_f1=0.8090909090909091
step: 0, loss: 0.09606696665287018
step: 10, loss: 0.13895222544670105
step: 20, loss: 0.09540686756372452
step: 30, loss: 0.1680125892162323
step: 40, loss: 0.07286432385444641
step: 50, loss: 0.16665208339691162
step: 60, loss: 0.10197548568248749
step: 70, loss: 0.01113873440772295
step: 80, loss: 0.023193296045064926
step: 90, loss: 0.1957940012216568
step: 100, loss: 0.04715451970696449
step: 110, loss: 0.08368269354104996
step: 120, loss: 0.10127528756856918
step: 130, loss: 0.142450213432312
step: 140, loss: 0.0726400837302208
step: 150, loss: 0.07516010850667953
step: 160, loss: 0.16138894855976105
step: 170, loss: 0.0766066312789917
step: 180, loss: 0.042353689670562744
step: 190, loss: 0.05769897997379303
step: 200, loss: 0.14457069337368011
step: 210, loss: 0.10719950497150421
step: 220, loss: 0.03820991888642311
step: 230, loss: 0.14320151507854462
step: 240, loss: 0.15604279935359955
step: 250, loss: 0.059917617589235306
step: 260, loss: 0.0364692322909832
step: 270, loss: 0.1257467120885849
step: 280, loss: 0.13788153231143951
step: 290, loss: 0.07189911603927612
step: 300, loss: 0.11639624834060669
step: 310, loss: 0.0552431121468544
step: 320, loss: 0.08920323103666306
step: 330, loss: 0.07651501893997192
step: 340, loss: 0.08101751655340195
step: 350, loss: 0.09178332984447479
epoch 9: dev_f1=0.8537735849056604, f1=0.8248847926267281, best_f1=0.8248847926267281
step: 0, loss: 0.07050839066505432
step: 10, loss: 0.04575897380709648
step: 20, loss: 0.02961648814380169
step: 30, loss: 0.03383960202336311
step: 40, loss: 0.05262702330946922
step: 50, loss: 0.11194828897714615
step: 60, loss: 0.08277875930070877
step: 70, loss: 0.03750292956829071
step: 80, loss: 0.020645981654524803
step: 90, loss: 0.0755339041352272
step: 100, loss: 0.12007466703653336
step: 110, loss: 0.17821189761161804
step: 120, loss: 0.12507539987564087
step: 130, loss: 0.08678392320871353
step: 140, loss: 0.10482115298509598
step: 150, loss: 0.05233994498848915
step: 160, loss: 0.08302239328622818
step: 170, loss: 0.02230015955865383
step: 180, loss: 0.033556416630744934
step: 190, loss: 0.07750635594129562
step: 200, loss: 0.08371901512145996
step: 210, loss: 0.10065866261720657
step: 220, loss: 0.09577371180057526
step: 230, loss: 0.03853486105799675
step: 240, loss: 0.10169892013072968
step: 250, loss: 0.07108341157436371
step: 260, loss: 0.14755696058273315
step: 270, loss: 0.06658808141946793
step: 280, loss: 0.032579828053712845
step: 290, loss: 0.11818042397499084
step: 300, loss: 0.02544522099196911
step: 310, loss: 0.09655940532684326
step: 320, loss: 0.02870236709713936
step: 330, loss: 0.120094895362854
step: 340, loss: 0.02031969465315342
step: 350, loss: 0.16400964558124542
epoch 10: dev_f1=0.819753086419753, f1=0.8175182481751825, best_f1=0.8248847926267281
step: 0, loss: 0.06669974327087402
step: 10, loss: 0.0614430271089077
step: 20, loss: 0.027994943782687187
step: 30, loss: 0.057240717113018036
step: 40, loss: 0.14265504479408264
step: 50, loss: 0.062012288719415665
step: 60, loss: 0.11711981892585754
step: 70, loss: 0.1725875288248062
step: 80, loss: 0.07146290689706802
step: 90, loss: 0.040697455406188965
step: 100, loss: 0.029258912429213524
step: 110, loss: 0.10644610971212387
step: 120, loss: 0.06912652403116226
step: 130, loss: 0.07726335525512695
step: 140, loss: 0.12662692368030548
step: 150, loss: 0.07327570021152496
step: 160, loss: 0.06610515713691711
step: 170, loss: 0.08643662929534912
step: 180, loss: 0.04415662959218025
step: 190, loss: 0.11403663456439972
step: 200, loss: 0.10686086863279343
step: 210, loss: 0.050782740116119385
step: 220, loss: 0.11745180189609528
step: 230, loss: 0.13964255154132843
step: 240, loss: 0.05241842567920685
step: 250, loss: 0.12002681195735931
step: 260, loss: 0.08864985406398773
step: 270, loss: 0.014950131066143513
step: 280, loss: 0.08255854994058609
step: 290, loss: 0.06642671674489975
step: 300, loss: 0.025559289380908012
step: 310, loss: 0.030040616169571877
step: 320, loss: 0.06584559381008148
step: 330, loss: 0.07666466385126114
step: 340, loss: 0.08448247611522675
step: 350, loss: 0.09084971994161606
epoch 11: dev_f1=0.8329411764705882, f1=0.7926267281105991, best_f1=0.8248847926267281
step: 0, loss: 0.12039481848478317
step: 10, loss: 0.05646785348653793
step: 20, loss: 0.09232744574546814
step: 30, loss: 0.05038374662399292
step: 40, loss: 0.04795508831739426
step: 50, loss: 0.15665538609027863
step: 60, loss: 0.09484484046697617
step: 70, loss: 0.0763254314661026
step: 80, loss: 0.03040260821580887
step: 90, loss: 0.09528099745512009
step: 100, loss: 0.11114554107189178
step: 110, loss: 0.12274812906980515
step: 120, loss: 0.051129456609487534
step: 130, loss: 0.09555907547473907
step: 140, loss: 0.11506780236959457
step: 150, loss: 0.0644981637597084
step: 160, loss: 0.21881192922592163
step: 170, loss: 0.07315325736999512
step: 180, loss: 0.05364573746919632
step: 190, loss: 0.13592858612537384
step: 200, loss: 0.07516790181398392
step: 210, loss: 0.06476432085037231
step: 220, loss: 0.07883977890014648
step: 230, loss: 0.06545014679431915
step: 240, loss: 0.10416053980588913
step: 250, loss: 0.19335265457630157
step: 260, loss: 0.06502363085746765
step: 270, loss: 0.10048074275255203
step: 280, loss: 0.0779276043176651
step: 290, loss: 0.03366352245211601
step: 300, loss: 0.09539446234703064
step: 310, loss: 0.01756262592971325
step: 320, loss: 0.058792974799871445
step: 330, loss: 0.16460230946540833
step: 340, loss: 0.027031205594539642
step: 350, loss: 0.09720355272293091
epoch 12: dev_f1=0.8537170263788968, f1=0.827906976744186, best_f1=0.8248847926267281
step: 0, loss: 0.037874091416597366
step: 10, loss: 0.10387963056564331
step: 20, loss: 0.024966124445199966
step: 30, loss: 0.09606324136257172
step: 40, loss: 0.10533561557531357
step: 50, loss: 0.08543851226568222
step: 60, loss: 0.09873855113983154
step: 70, loss: 0.1124536395072937
step: 80, loss: 0.039926476776599884
step: 90, loss: 0.08821175247430801
step: 100, loss: 0.09195875376462936
step: 110, loss: 0.15469695627689362
step: 120, loss: 0.036313530057668686
step: 130, loss: 0.07102182507514954
step: 140, loss: 0.032143913209438324
step: 150, loss: 0.0506555549800396
step: 160, loss: 0.059253886342048645
step: 170, loss: 0.1218257024884224
step: 180, loss: 0.04609096050262451
step: 190, loss: 0.12091635167598724
step: 200, loss: 0.052629388868808746
step: 210, loss: 0.037837035953998566
step: 220, loss: 0.030792566016316414
step: 230, loss: 0.012851591221988201
step: 240, loss: 0.10229112207889557
step: 250, loss: 0.07774978131055832
step: 260, loss: 0.10712245106697083
step: 270, loss: 0.07449756562709808
step: 280, loss: 0.07039833068847656
step: 290, loss: 0.07796218991279602
step: 300, loss: 0.039056871086359024
step: 310, loss: 0.11329611390829086
step: 320, loss: 0.08733238279819489
step: 330, loss: 0.06934256106615067
step: 340, loss: 0.04920468106865883
step: 350, loss: 0.08481886982917786
epoch 13: dev_f1=0.8557919621749409, f1=0.8283752860411899, best_f1=0.8283752860411899
step: 0, loss: 0.0003765784786082804
step: 10, loss: 0.08389925956726074
step: 20, loss: 0.08336986601352692
step: 30, loss: 0.05034661665558815
step: 40, loss: 0.032900646328926086
step: 50, loss: 0.11503840237855911
step: 60, loss: 0.04526592418551445
step: 70, loss: 0.047040849924087524
step: 80, loss: 0.129889115691185
step: 90, loss: 0.041857145726680756
step: 100, loss: 0.11690784990787506
step: 110, loss: 0.04352230206131935
step: 120, loss: 0.05852195993065834
step: 130, loss: 0.10744249820709229
step: 140, loss: 0.08853516727685928
step: 150, loss: 0.10470155626535416
step: 160, loss: 0.0906524658203125
step: 170, loss: 0.060116156935691833
step: 180, loss: 0.13445709645748138
step: 190, loss: 0.010317312553524971
step: 200, loss: 0.07218456268310547
step: 210, loss: 0.03505834564566612
step: 220, loss: 0.1130317822098732
step: 230, loss: 0.09465878456830978
step: 240, loss: 0.07849632203578949
step: 250, loss: 0.07377488911151886
step: 260, loss: 0.0380653515458107
step: 270, loss: 0.05005645379424095
step: 280, loss: 0.3145220875740051
step: 290, loss: 5.380356378736906e-05
step: 300, loss: 0.08713443577289581
step: 310, loss: 0.016690470278263092
step: 320, loss: 0.018861936405301094
step: 330, loss: 0.08278277516365051
step: 340, loss: 0.056187570095062256
step: 350, loss: 0.04396282136440277
epoch 14: dev_f1=0.847926267281106, f1=0.8126410835214447, best_f1=0.8283752860411899
step: 0, loss: 0.09325306862592697
step: 10, loss: 0.11358890682458878
step: 20, loss: 0.027385413646697998
step: 30, loss: 0.042015768587589264
step: 40, loss: 0.0381246842443943
step: 50, loss: 0.11681697517633438
step: 60, loss: 0.07017640769481659
step: 70, loss: 0.12803435325622559
step: 80, loss: 0.05563598871231079
step: 90, loss: 0.17396467924118042
step: 100, loss: 0.0408642515540123
step: 110, loss: 0.07326970994472504
step: 120, loss: 0.1279231458902359
step: 130, loss: 0.21268069744110107
step: 140, loss: 0.031618740409612656
step: 150, loss: 0.04135492816567421
step: 160, loss: 0.0961081013083458
step: 170, loss: 0.017843332141637802
step: 180, loss: 0.029566485434770584
step: 190, loss: 0.027819976210594177
step: 200, loss: 0.045439235866069794
step: 210, loss: 0.06305941939353943
step: 220, loss: 0.1350886970758438
step: 230, loss: 0.09267214685678482
step: 240, loss: 0.06749965250492096
step: 250, loss: 0.04356687143445015
step: 260, loss: 0.06102004647254944
step: 270, loss: 0.12390951067209244
step: 280, loss: 0.012365350499749184
step: 290, loss: 0.06346119195222855
step: 300, loss: 0.2333393543958664
step: 310, loss: 0.10291408747434616
step: 320, loss: 0.080548495054245
step: 330, loss: 0.07503257691860199
step: 340, loss: 0.054650988429784775
step: 350, loss: 0.06185049191117287
epoch 15: dev_f1=0.8125000000000001, f1=0.7956989247311829, best_f1=0.8283752860411899
step: 0, loss: 0.03644057735800743
step: 10, loss: 0.03314864635467529
step: 20, loss: 0.11457305401563644
step: 30, loss: 0.017793750390410423
step: 40, loss: 0.09537042677402496
step: 50, loss: 0.032359782606363297
step: 60, loss: 0.01643466018140316
step: 70, loss: 0.06437496095895767
step: 80, loss: 0.08395810425281525
step: 90, loss: 0.07086718082427979
step: 100, loss: 0.0289425328373909
step: 110, loss: 0.08076439797878265
step: 120, loss: 0.05890805646777153
step: 130, loss: 0.08477087318897247
step: 140, loss: 0.05098674073815346
step: 150, loss: 0.09075040370225906
step: 160, loss: 0.0449235774576664
step: 170, loss: 0.08230361342430115
step: 180, loss: 0.05655674636363983
step: 190, loss: 0.07411844283342361
step: 200, loss: 0.023924458771944046
step: 210, loss: 0.025322703644633293
step: 220, loss: 0.031717121601104736
step: 230, loss: 0.07971035689115524
step: 240, loss: 0.11994823813438416
step: 250, loss: 0.0319356769323349
step: 260, loss: 0.027066558599472046
step: 270, loss: 0.11777227371931076
step: 280, loss: 0.0231305044144392
step: 290, loss: 0.07743120193481445
step: 300, loss: 0.030726635828614235
step: 310, loss: 0.047157950699329376
step: 320, loss: 0.07761795073747635
step: 330, loss: 0.025087866932153702
step: 340, loss: 0.027567289769649506
step: 350, loss: 0.10477721691131592
epoch 16: dev_f1=0.8337349397590362, f1=0.7962085308056872, best_f1=0.8283752860411899
step: 0, loss: 0.10731808841228485
step: 10, loss: 0.034289177507162094
step: 20, loss: 0.08816948533058167
step: 30, loss: 0.04920806363224983
step: 40, loss: 0.168357715010643
step: 50, loss: 0.018695296719670296
step: 60, loss: 0.062184616923332214
step: 70, loss: 0.08019576966762543
step: 80, loss: 0.11761058121919632
step: 90, loss: 0.021620869636535645
step: 100, loss: 0.07937227189540863
step: 110, loss: 0.07008112967014313
step: 120, loss: 0.020398441702127457
step: 130, loss: 0.1196722537279129
step: 140, loss: 0.013722913339734077
step: 150, loss: 0.0770701915025711
step: 160, loss: 0.12973126769065857
step: 170, loss: 0.12158772349357605
step: 180, loss: 0.038770101964473724
step: 190, loss: 0.0008209277875721455
step: 200, loss: 0.05038867145776749
step: 210, loss: 0.007352975197136402
step: 220, loss: 0.06890317052602768
step: 230, loss: 0.05172988772392273
step: 240, loss: 0.14372923970222473
step: 250, loss: 0.01155604887753725
step: 260, loss: 0.13214989006519318
step: 270, loss: 0.08725555986166
step: 280, loss: 0.07712490856647491
step: 290, loss: 0.04876718297600746
step: 300, loss: 0.0709553137421608
step: 310, loss: 0.06316863000392914
step: 320, loss: 0.059439338743686676
step: 330, loss: 0.03849417343735695
step: 340, loss: 0.08181140571832657
step: 350, loss: 0.061770252883434296
epoch 17: dev_f1=0.8398058252427184, f1=0.8114558472553699, best_f1=0.8283752860411899
step: 0, loss: 0.05042567849159241
step: 10, loss: 0.04650302231311798
step: 20, loss: 0.021462438628077507
step: 30, loss: 0.041032180190086365
step: 40, loss: 0.08506840467453003
step: 50, loss: 0.10112462937831879
step: 60, loss: 0.034268636256456375
step: 70, loss: 0.15474076569080353
step: 80, loss: 0.029487058520317078
step: 90, loss: 0.026336567476391792
step: 100, loss: 0.07087262719869614
step: 110, loss: 0.12137293815612793
step: 120, loss: 0.05152801051735878
step: 130, loss: 0.017133763059973717
step: 140, loss: 0.04775325208902359
step: 150, loss: 5.939926631981507e-05
step: 160, loss: 0.060015078634023666
step: 170, loss: 0.020606650039553642
step: 180, loss: 0.12113038450479507
step: 190, loss: 0.029902122914791107
step: 200, loss: 0.08783300220966339
step: 210, loss: 0.10179584473371506
step: 220, loss: 0.02421231009066105
step: 230, loss: 0.10750748962163925
step: 240, loss: 0.02515171840786934
step: 250, loss: 0.06104382500052452
step: 260, loss: 0.1464746594429016
step: 270, loss: 0.08401665836572647
step: 280, loss: 0.07217898219823837
step: 290, loss: 0.058601927012205124
step: 300, loss: 0.11857368052005768
step: 310, loss: 0.03055807389318943
step: 320, loss: 0.04063185676932335
step: 330, loss: 0.136858731508255
step: 340, loss: 0.08590708673000336
step: 350, loss: 0.13670828938484192
epoch 18: dev_f1=0.8357487922705313, f1=0.8132387706855791, best_f1=0.8283752860411899
step: 0, loss: 0.11663486808538437
step: 10, loss: 0.011877055279910564
step: 20, loss: 0.05739809572696686
step: 30, loss: 0.1394486278295517
step: 40, loss: 0.08618613332509995
step: 50, loss: 0.08237718790769577
step: 60, loss: 0.02996930480003357
step: 70, loss: 0.07069963961839676
step: 80, loss: 0.05693443864583969
step: 90, loss: 0.05715852603316307
step: 100, loss: 0.017740784212946892
step: 110, loss: 0.032421331852674484
step: 120, loss: 0.04882015660405159
step: 130, loss: 0.018081849440932274
step: 140, loss: 0.06398777663707733
step: 150, loss: 0.1280737966299057
step: 160, loss: 0.05543498694896698
step: 170, loss: 0.04539572075009346
step: 180, loss: 0.004277622792869806
step: 190, loss: 0.09390685707330704
step: 200, loss: 0.05132771655917168
step: 210, loss: 0.07461591064929962
step: 220, loss: 0.029561005532741547
step: 230, loss: 0.10404150187969208
step: 240, loss: 0.10882476717233658
step: 250, loss: 0.008626554161310196
step: 260, loss: 0.012471125461161137
step: 270, loss: 0.10304103791713715
step: 280, loss: 0.07448679208755493
step: 290, loss: 0.03438689932227135
step: 300, loss: 0.007561114151030779
step: 310, loss: 0.07084856182336807
step: 320, loss: 0.1181023046374321
step: 330, loss: 0.030965324491262436
step: 340, loss: 0.024080295115709305
step: 350, loss: 0.09219115227460861
epoch 19: dev_f1=0.8304668304668303, f1=0.8066825775656326, best_f1=0.8283752860411899
step: 0, loss: 0.05214301124215126
step: 10, loss: 0.03463912010192871
step: 20, loss: 0.09417489171028137
step: 30, loss: 0.13888800144195557
step: 40, loss: 0.061733443289995193
step: 50, loss: 0.024310274049639702
step: 60, loss: 0.08459927141666412
step: 70, loss: 0.012186069041490555
step: 80, loss: 0.07453163713216782
step: 90, loss: 0.04146893322467804
step: 100, loss: 0.046664413064718246
step: 110, loss: 0.04011223837733269
step: 120, loss: 0.020581431686878204
step: 130, loss: 0.02699703350663185
step: 140, loss: 0.11135368049144745
step: 150, loss: 0.07765516638755798
step: 160, loss: 0.08155091106891632
step: 170, loss: 0.02325945533812046
step: 180, loss: 0.04545772075653076
step: 190, loss: 5.556916585192084e-05
step: 200, loss: 0.02213316410779953
step: 210, loss: 0.10509450733661652
step: 220, loss: 0.06338920444250107
step: 230, loss: 0.008479299023747444
step: 240, loss: 0.07862900197505951
step: 250, loss: 0.14150017499923706
step: 260, loss: 0.004035728517919779
step: 270, loss: 0.0471026711165905
step: 280, loss: 0.06165909767150879
step: 290, loss: 0.000408905470976606
step: 300, loss: 0.0727144405245781
step: 310, loss: 0.04275256395339966
step: 320, loss: 0.03314149007201195
step: 330, loss: 0.010452361777424812
step: 340, loss: 0.018961800262331963
step: 350, loss: 0.0802302286028862
epoch 20: dev_f1=0.8190954773869347, f1=0.8067632850241547, best_f1=0.8283752860411899
