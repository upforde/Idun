cuda
Device: cuda
step: 0, loss: 0.6026859283447266
step: 10, loss: 0.30671897530555725
step: 20, loss: 0.3697987198829651
step: 30, loss: 0.379532128572464
step: 40, loss: 0.4926180839538574
step: 50, loss: 0.4069727957248688
step: 60, loss: 0.1773887425661087
step: 70, loss: 0.26701006293296814
step: 80, loss: 0.2377382218837738
step: 90, loss: 0.3013979196548462
step: 100, loss: 0.28869032859802246
step: 110, loss: 0.3045637607574463
step: 120, loss: 0.1815827339887619
step: 130, loss: 0.31710121035575867
step: 140, loss: 0.3169075846672058
step: 150, loss: 0.2683086097240448
step: 160, loss: 0.24832342565059662
step: 170, loss: 0.17019693553447723
step: 180, loss: 0.18496057391166687
step: 190, loss: 0.18393336236476898
step: 200, loss: 0.20545105636119843
step: 210, loss: 0.21117259562015533
step: 220, loss: 0.11970323324203491
step: 230, loss: 0.14822439849376678
step: 240, loss: 0.21423915028572083
step: 250, loss: 0.2566949725151062
step: 260, loss: 0.14573189616203308
step: 270, loss: 0.15545392036437988
step: 280, loss: 0.2127344012260437
step: 290, loss: 0.24982227385044098
step: 300, loss: 0.22101366519927979
step: 310, loss: 0.15188972651958466
step: 320, loss: 0.16651803255081177
step: 330, loss: 0.0981634259223938
step: 340, loss: 0.24183836579322815
step: 350, loss: 0.35671210289001465
epoch 1: dev_f1=0.7395348837209301, f1=0.7264573991031391, best_f1=0.7264573991031391
step: 0, loss: 0.25364190340042114
step: 10, loss: 0.10879256576299667
step: 20, loss: 0.15560944378376007
step: 30, loss: 0.2046973705291748
step: 40, loss: 0.16723670065402985
step: 50, loss: 0.14131437242031097
step: 60, loss: 0.22964538633823395
step: 70, loss: 0.27854177355766296
step: 80, loss: 0.2117626667022705
step: 90, loss: 0.11730856448411942
step: 100, loss: 0.03845761716365814
step: 110, loss: 0.09733343124389648
step: 120, loss: 0.20175954699516296
step: 130, loss: 0.506578803062439
step: 140, loss: 0.10045070946216583
step: 150, loss: 0.2698318362236023
step: 160, loss: 0.20912742614746094
step: 170, loss: 0.22059544920921326
step: 180, loss: 0.2197066992521286
step: 190, loss: 0.09508803486824036
step: 200, loss: 0.22464653849601746
step: 210, loss: 0.09262087196111679
step: 220, loss: 0.1426464021205902
step: 230, loss: 0.23200301826000214
step: 240, loss: 0.08155127614736557
step: 250, loss: 0.2059195339679718
step: 260, loss: 0.09769946336746216
step: 270, loss: 0.06896985322237015
step: 280, loss: 0.1554621011018753
step: 290, loss: 0.16331946849822998
step: 300, loss: 0.17054134607315063
step: 310, loss: 0.0722532868385315
step: 320, loss: 0.26136237382888794
step: 330, loss: 0.24254345893859863
step: 340, loss: 0.24018153548240662
step: 350, loss: 0.23935428261756897
epoch 2: dev_f1=0.7682119205298014, f1=0.7114967462039046, best_f1=0.7114967462039046
step: 0, loss: 0.10324126482009888
step: 10, loss: 0.1389845758676529
step: 20, loss: 0.054927583783864975
step: 30, loss: 0.18686702847480774
step: 40, loss: 0.049485400319099426
step: 50, loss: 0.1201782152056694
step: 60, loss: 0.09587378054857254
step: 70, loss: 0.09882032126188278
step: 80, loss: 0.12041403353214264
step: 90, loss: 0.1253204047679901
step: 100, loss: 0.10207246243953705
step: 110, loss: 0.09752006828784943
step: 120, loss: 0.21088799834251404
step: 130, loss: 0.16272012889385223
step: 140, loss: 0.06420274823904037
step: 150, loss: 0.06453835964202881
step: 160, loss: 0.10217973589897156
step: 170, loss: 0.10172808915376663
step: 180, loss: 0.12164188176393509
step: 190, loss: 0.07773329317569733
step: 200, loss: 0.19616347551345825
step: 210, loss: 0.16582903265953064
step: 220, loss: 0.16135577857494354
step: 230, loss: 0.05069180205464363
step: 240, loss: 0.09482865035533905
step: 250, loss: 0.14104576408863068
step: 260, loss: 0.09157522767782211
step: 270, loss: 0.24904942512512207
step: 280, loss: 0.1696133315563202
step: 290, loss: 0.1718330979347229
step: 300, loss: 0.13884146511554718
step: 310, loss: 0.08503731340169907
step: 320, loss: 0.14093562960624695
step: 330, loss: 0.26099857687950134
step: 340, loss: 0.15355554223060608
step: 350, loss: 0.12329815328121185
epoch 3: dev_f1=0.8062360801781738, f1=0.7604395604395604, best_f1=0.7604395604395604
step: 0, loss: 0.1679202914237976
step: 10, loss: 0.0013979048235341907
step: 20, loss: 0.128022238612175
step: 30, loss: 0.10137789696455002
step: 40, loss: 0.09058256447315216
step: 50, loss: 0.06756618618965149
step: 60, loss: 0.05485808476805687
step: 70, loss: 0.025195764377713203
step: 80, loss: 0.08163166791200638
step: 90, loss: 0.11704075336456299
step: 100, loss: 0.14562062919139862
step: 110, loss: 0.056209761649370193
step: 120, loss: 0.11467678099870682
step: 130, loss: 0.035732246935367584
step: 140, loss: 0.1274745911359787
step: 150, loss: 0.06522568315267563
step: 160, loss: 0.08472856879234314
step: 170, loss: 0.11231166124343872
step: 180, loss: 0.07331741601228714
step: 190, loss: 0.0413653664290905
step: 200, loss: 0.05745118856430054
step: 210, loss: 0.09449046105146408
step: 220, loss: 0.08171354979276657
step: 230, loss: 0.08948829770088196
step: 240, loss: 0.2392996996641159
step: 250, loss: 0.11694998294115067
step: 260, loss: 0.09490542113780975
step: 270, loss: 0.16332487761974335
step: 280, loss: 0.187003493309021
step: 290, loss: 0.0907793790102005
step: 300, loss: 0.052351512014865875
step: 310, loss: 0.10409146547317505
step: 320, loss: 0.2400786280632019
step: 330, loss: 0.13272400200366974
step: 340, loss: 0.08416915684938431
step: 350, loss: 0.13540036976337433
epoch 4: dev_f1=0.838862559241706, f1=0.8238095238095239, best_f1=0.8238095238095239
step: 0, loss: 0.12157709896564484
step: 10, loss: 0.09126266092061996
step: 20, loss: 0.047494977712631226
step: 30, loss: 0.07031556963920593
step: 40, loss: 0.09840770810842514
step: 50, loss: 0.05744456499814987
step: 60, loss: 0.06724321842193604
step: 70, loss: 0.056658994406461716
step: 80, loss: 0.054217420518398285
step: 90, loss: 0.07924549281597137
step: 100, loss: 0.029458792880177498
step: 110, loss: 0.0879899114370346
step: 120, loss: 0.12995533645153046
step: 130, loss: 0.08669396489858627
step: 140, loss: 0.08343280106782913
step: 150, loss: 0.1520383358001709
step: 160, loss: 0.06776565313339233
step: 170, loss: 0.08538118004798889
step: 180, loss: 0.1150575503706932
step: 190, loss: 0.0631137266755104
step: 200, loss: 0.02561861276626587
step: 210, loss: 0.09854787588119507
step: 220, loss: 0.06281080842018127
step: 230, loss: 0.03275733068585396
step: 240, loss: 0.08345925807952881
step: 250, loss: 0.04531802982091904
step: 260, loss: 0.20603276789188385
step: 270, loss: 0.10360389202833176
step: 280, loss: 0.16534408926963806
step: 290, loss: 0.10461144149303436
step: 300, loss: 0.13127288222312927
step: 310, loss: 0.08692364394664764
step: 320, loss: 0.06861057877540588
step: 330, loss: 0.09459804743528366
step: 340, loss: 0.10518061369657516
step: 350, loss: 0.04000779613852501
epoch 5: dev_f1=0.8413461538461537, f1=0.8274231678486996, best_f1=0.8274231678486996
step: 0, loss: 0.06872823089361191
step: 10, loss: 0.13296054303646088
step: 20, loss: 0.18611456453800201
step: 30, loss: 0.08574409037828445
step: 40, loss: 0.11832267045974731
step: 50, loss: 0.10163236409425735
step: 60, loss: 0.02792850136756897
step: 70, loss: 0.11577652394771576
step: 80, loss: 0.03235847130417824
step: 90, loss: 0.039959561079740524
step: 100, loss: 0.13546721637248993
step: 110, loss: 0.101900115609169
step: 120, loss: 0.34934982657432556
step: 130, loss: 0.05089179426431656
step: 140, loss: 0.09907356649637222
step: 150, loss: 0.15067411959171295
step: 160, loss: 0.06436997652053833
step: 170, loss: 0.09492632746696472
step: 180, loss: 0.08267480880022049
step: 190, loss: 0.12774822115898132
step: 200, loss: 0.10815329104661942
step: 210, loss: 0.06653532385826111
step: 220, loss: 0.0008375109173357487
step: 230, loss: 0.19463694095611572
step: 240, loss: 0.11480344086885452
step: 250, loss: 0.03287100791931152
step: 260, loss: 0.031692780554294586
step: 270, loss: 0.0961776077747345
step: 280, loss: 0.1157008558511734
step: 290, loss: 0.0649784505367279
step: 300, loss: 0.1218762919306755
step: 310, loss: 0.11021135747432709
step: 320, loss: 0.16773228347301483
step: 330, loss: 0.05716821551322937
step: 340, loss: 0.06748074293136597
step: 350, loss: 0.12450364232063293
epoch 6: dev_f1=0.8304668304668303, f1=0.7862407862407862, best_f1=0.8274231678486996
step: 0, loss: 0.053950969129800797
step: 10, loss: 0.0324573814868927
step: 20, loss: 0.06893355399370193
step: 30, loss: 0.07231911271810532
step: 40, loss: 0.03296266868710518
step: 50, loss: 0.025896040722727776
step: 60, loss: 0.08294190466403961
step: 70, loss: 0.07310646772384644
step: 80, loss: 0.1309373378753662
step: 90, loss: 0.07314731180667877
step: 100, loss: 0.06520792096853256
step: 110, loss: 0.042697325348854065
step: 120, loss: 0.07067260891199112
step: 130, loss: 0.14053088426589966
step: 140, loss: 0.06968648731708527
step: 150, loss: 0.09975561499595642
step: 160, loss: 0.06751765310764313
step: 170, loss: 0.20752403140068054
step: 180, loss: 0.047274135053157806
step: 190, loss: 0.15552020072937012
step: 200, loss: 0.05723927542567253
step: 210, loss: 0.09413860738277435
step: 220, loss: 0.05891144275665283
step: 230, loss: 0.1154240071773529
step: 240, loss: 0.11325304210186005
step: 250, loss: 0.10996794700622559
step: 260, loss: 0.05617961287498474
step: 270, loss: 0.08017535507678986
step: 280, loss: 0.09482792019844055
step: 290, loss: 0.10885041207075119
step: 300, loss: 0.0014906820142641664
step: 310, loss: 0.10371284931898117
step: 320, loss: 0.08758029341697693
step: 330, loss: 0.1259968876838684
step: 340, loss: 0.06321480125188828
step: 350, loss: 0.03345100209116936
epoch 7: dev_f1=0.815, f1=0.794044665012407, best_f1=0.8274231678486996
step: 0, loss: 0.03792973607778549
step: 10, loss: 0.04375192150473595
step: 20, loss: 0.07681876420974731
step: 30, loss: 0.12143541872501373
step: 40, loss: 0.01889624446630478
step: 50, loss: 0.1140746921300888
step: 60, loss: 0.15310950577259064
step: 70, loss: 0.041409071534872055
step: 80, loss: 0.0798715353012085
step: 90, loss: 0.14191654324531555
step: 100, loss: 0.039581235498189926
step: 110, loss: 0.05418630316853523
step: 120, loss: 0.2447458803653717
step: 130, loss: 0.021635504439473152
step: 140, loss: 0.07610957324504852
step: 150, loss: 0.04750390723347664
step: 160, loss: 0.1375444531440735
step: 170, loss: 0.13867269456386566
step: 180, loss: 0.03943904489278793
step: 190, loss: 0.1699952483177185
step: 200, loss: 0.08824143558740616
step: 210, loss: 0.12212736159563065
step: 220, loss: 0.17347672581672668
step: 230, loss: 0.15380311012268066
step: 240, loss: 0.05833997577428818
step: 250, loss: 0.01498985756188631
step: 260, loss: 0.07507044821977615
step: 270, loss: 0.07500708103179932
step: 280, loss: 0.07946420460939407
step: 290, loss: 0.09959447383880615
step: 300, loss: 0.29088571667671204
step: 310, loss: 0.08094289898872375
step: 320, loss: 0.04052303731441498
step: 330, loss: 0.12093102186918259
step: 340, loss: 0.128046914935112
step: 350, loss: 0.1714683324098587
epoch 8: dev_f1=0.827250608272506, f1=0.7941176470588236, best_f1=0.8274231678486996
step: 0, loss: 0.07480323314666748
step: 10, loss: 0.16293266415596008
step: 20, loss: 0.06378109753131866
step: 30, loss: 0.14302639663219452
step: 40, loss: 0.1070178672671318
step: 50, loss: 0.06367187201976776
step: 60, loss: 0.017670920118689537
step: 70, loss: 0.18362544476985931
step: 80, loss: 0.0625562071800232
step: 90, loss: 0.06838634610176086
step: 100, loss: 0.03220713511109352
step: 110, loss: 0.02087416872382164
step: 120, loss: 0.10555510222911835
step: 130, loss: 0.08191019296646118
step: 140, loss: 0.10926033556461334
step: 150, loss: 0.09334838390350342
step: 160, loss: 0.04927361384034157
step: 170, loss: 0.07192327082157135
step: 180, loss: 0.1480768769979477
step: 190, loss: 0.05720754340291023
step: 200, loss: 0.13021084666252136
step: 210, loss: 0.07073279470205307
step: 220, loss: 0.12079232931137085
step: 230, loss: 0.22017279267311096
step: 240, loss: 0.19897854328155518
step: 250, loss: 0.09418489784002304
step: 260, loss: 0.06070075184106827
step: 270, loss: 0.11095467209815979
step: 280, loss: 0.038931749761104584
step: 290, loss: 0.12237055599689484
step: 300, loss: 0.06956911087036133
step: 310, loss: 0.12017752230167389
step: 320, loss: 0.16327689588069916
step: 330, loss: 0.14428460597991943
step: 340, loss: 0.129108265042305
step: 350, loss: 0.00043541431659832597
epoch 9: dev_f1=0.8405797101449275, f1=0.8229665071770335, best_f1=0.8274231678486996
step: 0, loss: 0.115322545170784
step: 10, loss: 0.028422417119145393
step: 20, loss: 0.02506537176668644
step: 30, loss: 0.10666882246732712
step: 40, loss: 0.07020951807498932
step: 50, loss: 0.051168251782655716
step: 60, loss: 0.04339669644832611
step: 70, loss: 0.10749495774507523
step: 80, loss: 0.07277195155620575
step: 90, loss: 0.08143388479948044
step: 100, loss: 0.04041452333331108
step: 110, loss: 0.08378066122531891
step: 120, loss: 0.06962272524833679
step: 130, loss: 0.08984874933958054
step: 140, loss: 0.030420735478401184
step: 150, loss: 0.046011000871658325
step: 160, loss: 0.0017391712171956897
step: 170, loss: 0.10004143416881561
step: 180, loss: 0.10198517888784409
step: 190, loss: 0.08478953689336777
step: 200, loss: 0.09712991863489151
step: 210, loss: 0.16422554850578308
step: 220, loss: 0.11277435719966888
step: 230, loss: 0.03278917819261551
step: 240, loss: 0.08518149703741074
step: 250, loss: 0.15597495436668396
step: 260, loss: 0.08420950174331665
step: 270, loss: 0.02838956192135811
step: 280, loss: 0.09157651662826538
step: 290, loss: 0.06173224002122879
step: 300, loss: 0.12693166732788086
step: 310, loss: 0.04677939787507057
step: 320, loss: 0.15523815155029297
step: 330, loss: 0.10122900456190109
step: 340, loss: 0.1257333904504776
step: 350, loss: 0.1529267579317093
epoch 10: dev_f1=0.822429906542056, f1=0.7924528301886793, best_f1=0.8274231678486996
step: 0, loss: 0.03882569074630737
step: 10, loss: 0.09376418590545654
step: 20, loss: 0.1086755245923996
step: 30, loss: 0.052797283977270126
step: 40, loss: 0.17175543308258057
step: 50, loss: 0.10382768511772156
step: 60, loss: 0.12571658194065094
step: 70, loss: 0.07774713635444641
step: 80, loss: 0.08985228836536407
step: 90, loss: 0.06377405673265457
step: 100, loss: 0.08283055573701859
step: 110, loss: 0.04364040866494179
step: 120, loss: 0.04876348003745079
step: 130, loss: 0.0524439737200737
step: 140, loss: 0.02789399027824402
step: 150, loss: 0.02215619385242462
step: 160, loss: 0.041184280067682266
step: 170, loss: 0.11755000799894333
step: 180, loss: 0.021753672510385513
step: 190, loss: 0.18041276931762695
step: 200, loss: 0.09483521431684494
step: 210, loss: 0.08387941122055054
step: 220, loss: 0.2570118010044098
step: 230, loss: 0.04751155152916908
step: 240, loss: 0.045463185757398605
step: 250, loss: 0.018978716805577278
step: 260, loss: 0.10198767483234406
step: 270, loss: 0.10906074196100235
step: 280, loss: 0.059585459530353546
step: 290, loss: 0.0867227166891098
step: 300, loss: 0.09889572858810425
step: 310, loss: 0.06140054762363434
step: 320, loss: 0.12435471266508102
step: 330, loss: 0.0992678552865982
step: 340, loss: 0.1295197606086731
step: 350, loss: 0.11668851971626282
epoch 11: dev_f1=0.8227571115973742, f1=0.8077753779697624, best_f1=0.8274231678486996
step: 0, loss: 0.06403226405382156
step: 10, loss: 0.10212252289056778
step: 20, loss: 0.12826912105083466
step: 30, loss: 0.046291057020425797
step: 40, loss: 0.089756540954113
step: 50, loss: 0.026875454932451248
step: 60, loss: 0.034841667860746384
step: 70, loss: 0.07842511683702469
step: 80, loss: 0.08015158772468567
step: 90, loss: 0.005297297611832619
step: 100, loss: 0.08882679045200348
step: 110, loss: 0.1104380190372467
step: 120, loss: 0.04309522733092308
step: 130, loss: 0.030233878642320633
step: 140, loss: 0.08051800727844238
step: 150, loss: 0.045825712382793427
step: 160, loss: 0.03458455577492714
step: 170, loss: 0.11562938988208771
step: 180, loss: 0.06832738220691681
step: 190, loss: 0.0009366546291857958
step: 200, loss: 0.05935017392039299
step: 210, loss: 0.1672411412000656
step: 220, loss: 0.1428479254245758
step: 230, loss: 0.14921249449253082
step: 240, loss: 0.12350331246852875
step: 250, loss: 0.10172266513109207
step: 260, loss: 0.09517096728086472
step: 270, loss: 0.07691251486539841
step: 280, loss: 0.03132108598947525
step: 290, loss: 0.03685355931520462
step: 300, loss: 0.024303045123815536
step: 310, loss: 0.0440734438598156
step: 320, loss: 0.13072684407234192
step: 330, loss: 0.13385429978370667
step: 340, loss: 0.045167360454797745
step: 350, loss: 0.035996805876493454
epoch 12: dev_f1=0.8184019370460048, f1=0.7740384615384616, best_f1=0.8274231678486996
step: 0, loss: 0.06021001935005188
step: 10, loss: 0.09777053445577621
step: 20, loss: 0.06780299544334412
step: 30, loss: 0.06860902905464172
step: 40, loss: 0.10013159364461899
step: 50, loss: 0.026236817240715027
step: 60, loss: 0.017774898558855057
step: 70, loss: 0.04229094088077545
step: 80, loss: 0.07222399115562439
step: 90, loss: 0.1115146279335022
step: 100, loss: 0.01008187048137188
step: 110, loss: 0.1075860932469368
step: 120, loss: 0.029226254671812057
step: 130, loss: 0.09345397353172302
step: 140, loss: 0.030646255239844322
step: 150, loss: 0.11944064497947693
step: 160, loss: 0.08911247551441193
step: 170, loss: 0.005311157554388046
step: 180, loss: 0.12305670976638794
step: 190, loss: 0.041836127638816833
step: 200, loss: 0.14950010180473328
step: 210, loss: 0.08618712425231934
step: 220, loss: 0.044325150549411774
step: 230, loss: 0.03928033635020256
step: 240, loss: 0.10154112428426743
step: 250, loss: 0.08848906308412552
step: 260, loss: 0.08619970828294754
step: 270, loss: 0.04034479707479477
step: 280, loss: 0.05357592925429344
step: 290, loss: 0.06201138719916344
step: 300, loss: 0.10126402974128723
step: 310, loss: 0.09655357152223587
step: 320, loss: 0.03918091580271721
step: 330, loss: 0.08921074867248535
step: 340, loss: 0.0367555245757103
step: 350, loss: 0.0563591904938221
epoch 13: dev_f1=0.8210023866348449, f1=0.7897196261682243, best_f1=0.8274231678486996
step: 0, loss: 0.10047250241041183
step: 10, loss: 0.01897159218788147
step: 20, loss: 0.029847832396626472
step: 30, loss: 0.04110283404588699
step: 40, loss: 0.04351507127285004
step: 50, loss: 0.08558566123247147
step: 60, loss: 0.03648143634200096
step: 70, loss: 0.04493340477347374
step: 80, loss: 0.03962341323494911
step: 90, loss: 0.019370637834072113
step: 100, loss: 0.049868226051330566
step: 110, loss: 0.09074723720550537
step: 120, loss: 0.05162479728460312
step: 130, loss: 0.08283929526805878
step: 140, loss: 0.11827346682548523
step: 150, loss: 0.013406701385974884
step: 160, loss: 0.009563155472278595
step: 170, loss: 0.12334748357534409
step: 180, loss: 0.04047480225563049
step: 190, loss: 0.07919351756572723
step: 200, loss: 0.10903120785951614
step: 210, loss: 0.05780941992998123
step: 220, loss: 0.12956087291240692
step: 230, loss: 0.038179993629455566
step: 240, loss: 0.038514453917741776
step: 250, loss: 0.026276426389813423
step: 260, loss: 0.023116569966077805
step: 270, loss: 0.07102537900209427
step: 280, loss: 0.10569728165864944
step: 290, loss: 0.06966930627822876
step: 300, loss: 0.008675065822899342
step: 310, loss: 0.07629916816949844
step: 320, loss: 0.086575448513031
step: 330, loss: 0.08802342414855957
step: 340, loss: 0.055352889001369476
step: 350, loss: 0.03228151798248291
epoch 14: dev_f1=0.8267326732673267, f1=0.8029925187032417, best_f1=0.8274231678486996
step: 0, loss: 0.05745958909392357
step: 10, loss: 0.0512106716632843
step: 20, loss: 0.041996393352746964
step: 30, loss: 0.1052209734916687
step: 40, loss: 0.016210166737437248
step: 50, loss: 0.12853682041168213
step: 60, loss: 0.041778720915317535
step: 70, loss: 0.03831589221954346
step: 80, loss: 0.013569086790084839
step: 90, loss: 0.11740880459547043
step: 100, loss: 0.061502426862716675
step: 110, loss: 0.10377448797225952
step: 120, loss: 0.10279063880443573
step: 130, loss: 0.14630334079265594
step: 140, loss: 0.08026275783777237
step: 150, loss: 0.12112994492053986
step: 160, loss: 0.02750856988132
step: 170, loss: 0.035841915756464005
step: 180, loss: 0.04727941006422043
step: 190, loss: 0.028757432475686073
step: 200, loss: 0.042154669761657715
step: 210, loss: 0.16865725815296173
step: 220, loss: 0.13070601224899292
step: 230, loss: 0.07465942203998566
step: 240, loss: 0.10159842669963837
step: 250, loss: 0.03227899968624115
step: 260, loss: 0.07809021323919296
step: 270, loss: 0.04735346883535385
step: 280, loss: 0.13975247740745544
step: 290, loss: 0.13518542051315308
step: 300, loss: 0.09030225872993469
step: 310, loss: 0.08143284171819687
step: 320, loss: 0.05980360135436058
step: 330, loss: 0.03767259418964386
step: 340, loss: 0.0482478104531765
step: 350, loss: 0.02875206060707569
epoch 15: dev_f1=0.8173076923076923, f1=0.780952380952381, best_f1=0.8274231678486996
step: 0, loss: 0.0844670981168747
step: 10, loss: 0.07162342220544815
step: 20, loss: 0.07248211652040482
step: 30, loss: 0.0924992561340332
step: 40, loss: 0.24338802695274353
step: 50, loss: 0.08365234732627869
step: 60, loss: 0.053838688880205154
step: 70, loss: 0.042460329830646515
step: 80, loss: 0.09211188554763794
step: 90, loss: 0.06428252160549164
step: 100, loss: 0.016104156151413918
step: 110, loss: 0.056734926998615265
step: 120, loss: 0.13448312878608704
step: 130, loss: 0.09752853959798813
step: 140, loss: 0.1169252097606659
step: 150, loss: 0.06675789505243301
step: 160, loss: 0.02021559327840805
step: 170, loss: 0.009844391606748104
step: 180, loss: 0.06242561712861061
step: 190, loss: 0.030487079173326492
step: 200, loss: 0.04922488331794739
step: 210, loss: 0.017459096387028694
step: 220, loss: 0.021311607211828232
step: 230, loss: 0.0993456318974495
step: 240, loss: 0.10037960112094879
step: 250, loss: 0.10849614441394806
step: 260, loss: 0.03860391676425934
step: 270, loss: 0.07387718558311462
step: 280, loss: 0.04347662255167961
step: 290, loss: 0.08402174711227417
step: 300, loss: 0.07421460002660751
step: 310, loss: 0.052438028156757355
step: 320, loss: 0.08293052762746811
step: 330, loss: 0.059190765023231506
step: 340, loss: 0.07192234694957733
step: 350, loss: 0.005492769181728363
epoch 16: dev_f1=0.8496420047732696, f1=0.8226950354609929, best_f1=0.8226950354609929
step: 0, loss: 0.13621769845485687
step: 10, loss: 0.07265444844961166
step: 20, loss: 0.053032685071229935
step: 30, loss: 0.05286744609475136
step: 40, loss: 0.045651379972696304
step: 50, loss: 0.05642007291316986
step: 60, loss: 0.028714952990412712
step: 70, loss: 0.06549354642629623
step: 80, loss: 0.03682558238506317
step: 90, loss: 0.00606080936267972
step: 100, loss: 0.06883755326271057
step: 110, loss: 0.07313521206378937
step: 120, loss: 0.0755983516573906
step: 130, loss: 0.04391629621386528
step: 140, loss: 0.07448101043701172
step: 150, loss: 0.23708459734916687
step: 160, loss: 0.036847613751888275
step: 170, loss: 2.588273309811484e-05
step: 180, loss: 0.0510980598628521
step: 190, loss: 0.0552888959646225
step: 200, loss: 0.0770348459482193
step: 210, loss: 0.11982576549053192
step: 220, loss: 0.05643128603696823
step: 230, loss: 0.09326853603124619
step: 240, loss: 0.09412141144275665
step: 250, loss: 0.1360812485218048
step: 260, loss: 0.0952083095908165
step: 270, loss: 2.0850118744419888e-05
step: 280, loss: 0.033260542899370193
step: 290, loss: 0.15347789227962494
step: 300, loss: 0.0883474200963974
step: 310, loss: 0.21429285407066345
step: 320, loss: 0.038550958037376404
step: 330, loss: 0.07602167874574661
step: 340, loss: 0.055936556309461594
step: 350, loss: 0.07339581847190857
epoch 17: dev_f1=0.838709677419355, f1=0.8137254901960784, best_f1=0.8226950354609929
step: 0, loss: 8.39666899992153e-05
step: 10, loss: 0.07767175137996674
step: 20, loss: 0.020522000268101692
step: 30, loss: 0.07327387481927872
step: 40, loss: 0.03890693560242653
step: 50, loss: 0.06197582185268402
step: 60, loss: 0.044488564133644104
step: 70, loss: 0.08613352477550507
step: 80, loss: 0.04724262282252312
step: 90, loss: 0.040111247450113297
step: 100, loss: 0.03527890145778656
step: 110, loss: 0.040060464292764664
step: 120, loss: 0.024163266643881798
step: 130, loss: 0.04722388833761215
step: 140, loss: 0.04186807572841644
step: 150, loss: 0.11025474220514297
step: 160, loss: 0.04188630357384682
step: 170, loss: 0.029831094667315483
step: 180, loss: 0.0657595694065094
step: 190, loss: 0.10133963823318481
step: 200, loss: 0.08637626469135284
step: 210, loss: 0.05454619228839874
step: 220, loss: 0.1260625571012497
step: 230, loss: 0.14622089266777039
step: 240, loss: 0.1185448095202446
step: 250, loss: 0.022514017298817635
step: 260, loss: 0.009315414354205132
step: 270, loss: 0.16215604543685913
step: 280, loss: 0.05717902630567551
step: 290, loss: 0.04632501304149628
step: 300, loss: 0.09827111661434174
step: 310, loss: 0.09027686715126038
step: 320, loss: 0.06917818635702133
step: 330, loss: 0.06992853432893753
step: 340, loss: 0.04606418311595917
step: 350, loss: 0.043659746646881104
epoch 18: dev_f1=0.8277511961722487, f1=0.8048192771084338, best_f1=0.8226950354609929
step: 0, loss: 0.04592730104923248
step: 10, loss: 0.07769328355789185
step: 20, loss: 0.06614551693201065
step: 30, loss: 0.07376015186309814
step: 40, loss: 0.05556188523769379
step: 50, loss: 0.1777614802122116
step: 60, loss: 0.08675532042980194
step: 70, loss: 0.05021104961633682
step: 80, loss: 0.04495035856962204
step: 90, loss: 0.07090777158737183
step: 100, loss: 0.05003465712070465
step: 110, loss: 0.0005691781407222152
step: 120, loss: 0.0490080900490284
step: 130, loss: 0.0009598363540135324
step: 140, loss: 0.07220188528299332
step: 150, loss: 0.05266750231385231
step: 160, loss: 0.05498642846941948
step: 170, loss: 0.13188761472702026
step: 180, loss: 0.05102033168077469
step: 190, loss: 0.052694693207740784
step: 200, loss: 0.06773620843887329
step: 210, loss: 0.125947043299675
step: 220, loss: 0.01638745330274105
step: 230, loss: 0.01841653138399124
step: 240, loss: 0.028924530372023582
step: 250, loss: 0.033858850598335266
step: 260, loss: 0.024427875876426697
step: 270, loss: 0.08262110501527786
step: 280, loss: 0.05398773401975632
step: 290, loss: 0.11721228063106537
step: 300, loss: 0.08071079105138779
step: 310, loss: 0.02857855334877968
step: 320, loss: 0.07326336950063705
step: 330, loss: 0.05402030423283577
step: 340, loss: 0.051299359649419785
step: 350, loss: 0.09030715376138687
epoch 19: dev_f1=0.8373205741626795, f1=0.8028846153846153, best_f1=0.8226950354609929
step: 0, loss: 0.06994491070508957
step: 10, loss: 0.054720938205718994
step: 20, loss: 0.06975791603326797
step: 30, loss: 0.02591242641210556
step: 40, loss: 0.010946405120193958
step: 50, loss: 0.059061288833618164
step: 60, loss: 2.022796070377808e-05
step: 70, loss: 0.22458748519420624
step: 80, loss: 0.05435160547494888
step: 90, loss: 0.14284583926200867
step: 100, loss: 0.121470145881176
step: 110, loss: 0.03380906209349632
step: 120, loss: 0.03459937870502472
step: 130, loss: 0.05885182321071625
step: 140, loss: 0.016198718920350075
step: 150, loss: 0.04303310811519623
step: 160, loss: 0.1503753960132599
step: 170, loss: 6.044559631845914e-05
step: 180, loss: 0.09017767757177353
step: 190, loss: 0.04446471482515335
step: 200, loss: 0.03326088562607765
step: 210, loss: 0.05534077063202858
step: 220, loss: 0.10186309367418289
step: 230, loss: 0.03790978714823723
step: 240, loss: 0.06738866120576859
step: 250, loss: 0.11174189299345016
step: 260, loss: 0.0034503075294196606
step: 270, loss: 0.06376740336418152
step: 280, loss: 0.02419528178870678
step: 290, loss: 0.043654851615428925
step: 300, loss: 0.03884648159146309
step: 310, loss: 0.07946069538593292
step: 320, loss: 0.0691448450088501
step: 330, loss: 0.05140417814254761
step: 340, loss: 0.08590909093618393
step: 350, loss: 0.09911387413740158
epoch 20: dev_f1=0.8321513002364066, f1=0.8018867924528301, best_f1=0.8226950354609929
