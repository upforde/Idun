cuda
Device: cuda
step: 0, loss: 0.6321182250976562
step: 10, loss: 0.32367539405822754
step: 20, loss: 0.3671959340572357
step: 30, loss: 0.24459208548069
step: 40, loss: 0.21958470344543457
step: 50, loss: 0.23980097472667694
step: 60, loss: 0.23382867872714996
step: 70, loss: 0.4497571587562561
step: 80, loss: 0.479998379945755
step: 90, loss: 0.21502670645713806
step: 100, loss: 0.2170112431049347
step: 110, loss: 0.14583660662174225
step: 120, loss: 0.2448812872171402
step: 130, loss: 0.38457196950912476
step: 140, loss: 0.40788474678993225
step: 150, loss: 0.21482951939105988
step: 160, loss: 0.15501157939434052
step: 170, loss: 0.17501860857009888
step: 180, loss: 0.2781125605106354
step: 190, loss: 0.30125460028648376
step: 200, loss: 0.36089590191841125
step: 210, loss: 0.06850306689739227
step: 220, loss: 0.1260594129562378
step: 230, loss: 0.18376819789409637
step: 240, loss: 0.13923804461956024
step: 250, loss: 0.17078757286071777
step: 260, loss: 0.47061586380004883
step: 270, loss: 0.15645717084407806
step: 280, loss: 0.17257314920425415
step: 290, loss: 0.3608975410461426
step: 300, loss: 0.2242244929075241
step: 310, loss: 0.30010396242141724
step: 320, loss: 0.0433938130736351
step: 330, loss: 0.15330010652542114
step: 340, loss: 0.2030317485332489
step: 350, loss: 0.15695424377918243
epoch 1: dev_f1=0.6367521367521368, f1=0.6859504132231405, best_f1=0.6859504132231405
step: 0, loss: 0.13397960364818573
step: 10, loss: 0.25391218066215515
step: 20, loss: 0.11543148756027222
step: 30, loss: 0.1534130573272705
step: 40, loss: 0.12863247096538544
step: 50, loss: 0.12872810661792755
step: 60, loss: 0.09753891825675964
step: 70, loss: 0.04553733021020889
step: 80, loss: 0.17332203686237335
step: 90, loss: 0.06790179014205933
step: 100, loss: 0.12072456628084183
step: 110, loss: 0.2583402097225189
step: 120, loss: 0.20570027828216553
step: 130, loss: 0.1174951046705246
step: 140, loss: 0.0852108895778656
step: 150, loss: 0.12182612717151642
step: 160, loss: 0.1431790590286255
step: 170, loss: 0.10550744086503983
step: 180, loss: 0.10466183722019196
step: 190, loss: 0.09236864745616913
step: 200, loss: 0.027895351871848106
step: 210, loss: 0.26072728633880615
step: 220, loss: 0.2419874519109726
step: 230, loss: 0.10071778297424316
step: 240, loss: 0.23417499661445618
step: 250, loss: 0.3599737286567688
step: 260, loss: 0.2170305848121643
step: 270, loss: 0.17417456209659576
step: 280, loss: 0.14548493921756744
step: 290, loss: 0.2862309515476227
step: 300, loss: 0.20272484421730042
step: 310, loss: 0.20738407969474792
step: 320, loss: 0.0961291566491127
step: 330, loss: 0.12493257969617844
step: 340, loss: 0.1298573911190033
step: 350, loss: 0.09505295753479004
epoch 2: dev_f1=0.7584745762711864, f1=0.7586206896551724, best_f1=0.7586206896551724
step: 0, loss: 0.16722789406776428
step: 10, loss: 0.0446368046104908
step: 20, loss: 0.074244923889637
step: 30, loss: 0.19057472050189972
step: 40, loss: 0.14156760275363922
step: 50, loss: 0.3573411703109741
step: 60, loss: 0.11105602979660034
step: 70, loss: 0.04302886500954628
step: 80, loss: 0.1374080628156662
step: 90, loss: 0.10086150467395782
step: 100, loss: 0.055799514055252075
step: 110, loss: 0.2300957590341568
step: 120, loss: 0.2409951537847519
step: 130, loss: 0.12950243055820465
step: 140, loss: 0.12237948924303055
step: 150, loss: 0.09256203472614288
step: 160, loss: 0.06835583597421646
step: 170, loss: 0.09210669994354248
step: 180, loss: 0.055822692811489105
step: 190, loss: 0.25028926134109497
step: 200, loss: 0.13408775627613068
step: 210, loss: 0.2562445402145386
step: 220, loss: 0.09820070117712021
step: 230, loss: 0.1569930911064148
step: 240, loss: 0.1484236717224121
step: 250, loss: 0.16322846710681915
step: 260, loss: 0.04162856191396713
step: 270, loss: 0.1635541021823883
step: 280, loss: 0.20355775952339172
step: 290, loss: 0.08477253466844559
step: 300, loss: 0.1418488621711731
step: 310, loss: 0.15569062530994415
step: 320, loss: 0.09072206914424896
step: 330, loss: 0.12454482167959213
step: 340, loss: 0.16637642681598663
step: 350, loss: 0.12843811511993408
epoch 3: dev_f1=0.7285067873303167, f1=0.7249466950959487, best_f1=0.7586206896551724
step: 0, loss: 0.14465594291687012
step: 10, loss: 0.0546703077852726
step: 20, loss: 0.010582351125776768
step: 30, loss: 0.09565294533967972
step: 40, loss: 0.06630115211009979
step: 50, loss: 0.08323513716459274
step: 60, loss: 0.3276965320110321
step: 70, loss: 0.19831573963165283
step: 80, loss: 0.2920076251029968
step: 90, loss: 0.16239959001541138
step: 100, loss: 0.2906411588191986
step: 110, loss: 0.12890391051769257
step: 120, loss: 0.08524564653635025
step: 130, loss: 0.03057342767715454
step: 140, loss: 0.020491698756814003
step: 150, loss: 0.05037348344922066
step: 160, loss: 0.08126252144575119
step: 170, loss: 0.10140182822942734
step: 180, loss: 0.1230289489030838
step: 190, loss: 0.15049214661121368
step: 200, loss: 0.05049344152212143
step: 210, loss: 0.08429678529500961
step: 220, loss: 0.13257868587970734
step: 230, loss: 0.17800305783748627
step: 240, loss: 0.11188021302223206
step: 250, loss: 0.0530209019780159
step: 260, loss: 0.054632868617773056
step: 270, loss: 0.11472003906965256
step: 280, loss: 0.068758524954319
step: 290, loss: 0.0898926630616188
step: 300, loss: 0.08801397681236267
step: 310, loss: 0.11646153032779694
step: 320, loss: 0.10901322215795517
step: 330, loss: 0.06827981770038605
step: 340, loss: 0.13777561485767365
step: 350, loss: 0.04675934091210365
epoch 4: dev_f1=0.7900677200902935, f1=0.7596566523605149, best_f1=0.7596566523605149
step: 0, loss: 0.055369358509778976
step: 10, loss: 0.07071256637573242
step: 20, loss: 0.10684575140476227
step: 30, loss: 0.053761452436447144
step: 40, loss: 0.12486822158098221
step: 50, loss: 0.10388755798339844
step: 60, loss: 0.1103045791387558
step: 70, loss: 0.06560678035020828
step: 80, loss: 0.08440051227807999
step: 90, loss: 0.04259122163057327
step: 100, loss: 0.0020793520379811525
step: 110, loss: 0.10098951309919357
step: 120, loss: 0.1224956139922142
step: 130, loss: 0.05446849390864372
step: 140, loss: 0.06330961734056473
step: 150, loss: 0.12314500659704208
step: 160, loss: 0.022593766450881958
step: 170, loss: 0.039097536355257034
step: 180, loss: 0.053728628903627396
step: 190, loss: 0.10332150012254715
step: 200, loss: 0.009433864615857601
step: 210, loss: 0.09435703605413437
step: 220, loss: 0.06448610126972198
step: 230, loss: 0.047213222831487656
step: 240, loss: 0.10151765495538712
step: 250, loss: 0.09045729786157608
step: 260, loss: 0.10890398919582367
step: 270, loss: 0.073250412940979
step: 280, loss: 0.042778171598911285
step: 290, loss: 0.06774649024009705
step: 300, loss: 0.09455858916044235
step: 310, loss: 0.2684875428676605
step: 320, loss: 0.131409153342247
step: 330, loss: 0.2938431203365326
step: 340, loss: 0.09833219647407532
step: 350, loss: 0.08993008732795715
epoch 5: dev_f1=0.8206278026905829, f1=0.7930283224400873, best_f1=0.7930283224400873
step: 0, loss: 0.09211615473031998
step: 10, loss: 0.12126977741718292
step: 20, loss: 0.08420342206954956
step: 30, loss: 0.07285988330841064
step: 40, loss: 0.016046158969402313
step: 50, loss: 0.1683296412229538
step: 60, loss: 0.09618901461362839
step: 70, loss: 0.055691905319690704
step: 80, loss: 0.08843454718589783
step: 90, loss: 0.05572262406349182
step: 100, loss: 0.1914558708667755
step: 110, loss: 0.16720274090766907
step: 120, loss: 0.12491126358509064
step: 130, loss: 0.03821318969130516
step: 140, loss: 0.07442790269851685
step: 150, loss: 0.13212355971336365
step: 160, loss: 0.1277519017457962
step: 170, loss: 0.10630736500024796
step: 180, loss: 0.03948792815208435
step: 190, loss: 0.03433651477098465
step: 200, loss: 0.06364627927541733
step: 210, loss: 0.20506662130355835
step: 220, loss: 0.2603524327278137
step: 230, loss: 0.08202313631772995
step: 240, loss: 0.002213084604591131
step: 250, loss: 0.10647694766521454
step: 260, loss: 0.1939316987991333
step: 270, loss: 0.03672916814684868
step: 280, loss: 0.19497089087963104
step: 290, loss: 0.0593038871884346
step: 300, loss: 0.0601908303797245
step: 310, loss: 0.1428857296705246
step: 320, loss: 0.11595277488231659
step: 330, loss: 0.08232204616069794
step: 340, loss: 0.08122573047876358
step: 350, loss: 0.14570409059524536
epoch 6: dev_f1=0.8329297820823245, f1=0.8215962441314554, best_f1=0.8215962441314554
step: 0, loss: 0.09752661734819412
step: 10, loss: 0.0802065059542656
step: 20, loss: 0.05493563413619995
step: 30, loss: 0.10129611194133759
step: 40, loss: 0.10525784641504288
step: 50, loss: 0.0356881208717823
step: 60, loss: 0.10392816364765167
step: 70, loss: 0.06447403877973557
step: 80, loss: 0.17758338153362274
step: 90, loss: 0.038141921162605286
step: 100, loss: 0.188355952501297
step: 110, loss: 0.06913959234952927
step: 120, loss: 0.16983795166015625
step: 130, loss: 0.027410564944148064
step: 140, loss: 0.14674359560012817
step: 150, loss: 0.09257897734642029
step: 160, loss: 0.10832074284553528
step: 170, loss: 0.10843447595834732
step: 180, loss: 0.00528999837115407
step: 190, loss: 0.0658116340637207
step: 200, loss: 0.05350731685757637
step: 210, loss: 0.09168597310781479
step: 220, loss: 0.03097272664308548
step: 230, loss: 0.10408411175012589
step: 240, loss: 0.3111538887023926
step: 250, loss: 0.08845532685518265
step: 260, loss: 0.04671015590429306
step: 270, loss: 0.11854957789182663
step: 280, loss: 0.10568922013044357
step: 290, loss: 0.05251589044928551
step: 300, loss: 0.1542610079050064
step: 310, loss: 0.08801504224538803
step: 320, loss: 0.045409560203552246
step: 330, loss: 0.028407040983438492
step: 340, loss: 0.1723729968070984
step: 350, loss: 0.13031044602394104
epoch 7: dev_f1=0.8296943231441049, f1=0.8043010752688172, best_f1=0.8215962441314554
step: 0, loss: 0.10939545184373856
step: 10, loss: 0.14657504856586456
step: 20, loss: 0.1096840426325798
step: 30, loss: 0.026468675583600998
step: 40, loss: 0.06384049355983734
step: 50, loss: 0.2111092507839203
step: 60, loss: 0.03077346459031105
step: 70, loss: 0.04162629693746567
step: 80, loss: 0.06678204238414764
step: 90, loss: 0.04875699430704117
step: 100, loss: 0.05653237923979759
step: 110, loss: 0.13244448602199554
step: 120, loss: 0.08549261093139648
step: 130, loss: 0.05679734796285629
step: 140, loss: 0.01937969960272312
step: 150, loss: 0.10182375460863113
step: 160, loss: 0.07510831952095032
step: 170, loss: 0.03555021435022354
step: 180, loss: 0.10203281044960022
step: 190, loss: 0.11704283952713013
step: 200, loss: 0.14382417500019073
step: 210, loss: 0.0978424921631813
step: 220, loss: 0.06494321674108505
step: 230, loss: 0.10170146822929382
step: 240, loss: 0.1482274979352951
step: 250, loss: 0.15641799569129944
step: 260, loss: 0.08320503681898117
step: 270, loss: 0.07370304316282272
step: 280, loss: 0.08334815502166748
step: 290, loss: 0.18207931518554688
step: 300, loss: 0.08594312518835068
step: 310, loss: 0.08413202315568924
step: 320, loss: 0.1234402284026146
step: 330, loss: 0.042949553579092026
step: 340, loss: 0.11437086015939713
step: 350, loss: 0.06360449641942978
epoch 8: dev_f1=0.8229665071770335, f1=0.8065268065268064, best_f1=0.8215962441314554
step: 0, loss: 0.1478608399629593
step: 10, loss: 0.13596442341804504
step: 20, loss: 0.059994108974933624
step: 30, loss: 0.12339622527360916
step: 40, loss: 0.16198211908340454
step: 50, loss: 0.08377557247877121
step: 60, loss: 0.11964499950408936
step: 70, loss: 0.11710283905267715
step: 80, loss: 0.09641843289136887
step: 90, loss: 0.04637235030531883
step: 100, loss: 0.13024815917015076
step: 110, loss: 0.044532742351293564
step: 120, loss: 0.016749897971749306
step: 130, loss: 0.04961200803518295
step: 140, loss: 0.021554484963417053
step: 150, loss: 0.01861078105866909
step: 160, loss: 0.09550654888153076
step: 170, loss: 0.1622115522623062
step: 180, loss: 0.061559516936540604
step: 190, loss: 0.027812344953417778
step: 200, loss: 0.10824589431285858
step: 210, loss: 0.05204722657799721
step: 220, loss: 0.1408926397562027
step: 230, loss: 0.0170401893556118
step: 240, loss: 0.1402657926082611
step: 250, loss: 0.11565320938825607
step: 260, loss: 0.06782355904579163
step: 270, loss: 0.11874039471149445
step: 280, loss: 0.08766334503889084
step: 290, loss: 0.02126155234873295
step: 300, loss: 0.11286168545484543
step: 310, loss: 0.07923956960439682
step: 320, loss: 0.07706398516893387
step: 330, loss: 0.14152415096759796
step: 340, loss: 0.0984305813908577
step: 350, loss: 0.15377412736415863
epoch 9: dev_f1=0.8132387706855791, f1=0.7906976744186047, best_f1=0.8215962441314554
step: 0, loss: 0.0974535420536995
step: 10, loss: 0.15655292570590973
step: 20, loss: 0.05504237860441208
step: 30, loss: 0.11265813559293747
step: 40, loss: 0.08882761001586914
step: 50, loss: 0.16054674983024597
step: 60, loss: 0.18610142171382904
step: 70, loss: 0.06593400985002518
step: 80, loss: 0.1496143639087677
step: 90, loss: 0.053613338619470596
step: 100, loss: 0.062339287251234055
step: 110, loss: 0.05181947350502014
step: 120, loss: 0.09152967482805252
step: 130, loss: 0.12842531502246857
step: 140, loss: 0.04904233291745186
step: 150, loss: 0.01376098208129406
step: 160, loss: 0.0550425685942173
step: 170, loss: 0.14579957723617554
step: 180, loss: 0.1040305495262146
step: 190, loss: 0.0976560190320015
step: 200, loss: 0.148699551820755
step: 210, loss: 0.10530409961938858
step: 220, loss: 0.039379436522722244
step: 230, loss: 0.08881789445877075
step: 240, loss: 0.09531138837337494
step: 250, loss: 0.07152245938777924
step: 260, loss: 0.1372860074043274
step: 270, loss: 0.05980447307229042
step: 280, loss: 0.1716393232345581
step: 290, loss: 0.0756465494632721
step: 300, loss: 0.10664914548397064
step: 310, loss: 0.06394513696432114
step: 320, loss: 0.09958379715681076
step: 330, loss: 0.07891661673784256
step: 340, loss: 0.06451137363910675
step: 350, loss: 0.021471304818987846
epoch 10: dev_f1=0.8179669030732861, f1=0.8091954022988505, best_f1=0.8215962441314554
step: 0, loss: 0.07477497309446335
step: 10, loss: 0.11542642116546631
step: 20, loss: 0.1073940098285675
step: 30, loss: 0.06573040038347244
step: 40, loss: 0.14498914778232574
step: 50, loss: 0.1635546237230301
step: 60, loss: 0.048222798854112625
step: 70, loss: 0.06840717792510986
step: 80, loss: 0.021962173283100128
step: 90, loss: 0.04385415092110634
step: 100, loss: 0.09343062341213226
step: 110, loss: 0.09150312095880508
step: 120, loss: 0.14197462797164917
step: 130, loss: 0.13309887051582336
step: 140, loss: 0.07111655920743942
step: 150, loss: 0.14285717904567719
step: 160, loss: 0.061774712055921555
step: 170, loss: 0.05512602999806404
step: 180, loss: 0.01834845542907715
step: 190, loss: 0.12429865449666977
step: 200, loss: 0.14033980667591095
step: 210, loss: 0.07998835295438766
step: 220, loss: 0.08031744509935379
step: 230, loss: 0.12296602874994278
step: 240, loss: 0.05691985785961151
step: 250, loss: 0.05285295471549034
step: 260, loss: 0.09281446784734726
step: 270, loss: 0.07507471740245819
step: 280, loss: 0.08395342528820038
step: 290, loss: 0.05072755739092827
step: 300, loss: 0.05587483197450638
step: 310, loss: 0.030988367274403572
step: 320, loss: 0.10238631069660187
step: 330, loss: 0.12112989276647568
step: 340, loss: 0.10451912134885788
step: 350, loss: 0.05724445730447769
epoch 11: dev_f1=0.8203883495145631, f1=0.7857142857142858, best_f1=0.8215962441314554
step: 0, loss: 0.08292985707521439
step: 10, loss: 0.09384683519601822
step: 20, loss: 0.050273340195417404
step: 30, loss: 0.025025896728038788
step: 40, loss: 0.11566191166639328
step: 50, loss: 0.03991546854376793
step: 60, loss: 0.07846939563751221
step: 70, loss: 0.03793628141283989
step: 80, loss: 0.06564635783433914
step: 90, loss: 0.1901119202375412
step: 100, loss: 0.07445241510868073
step: 110, loss: 0.04426116868853569
step: 120, loss: 0.04067974165081978
step: 130, loss: 0.0705239474773407
step: 140, loss: 0.01575746014714241
step: 150, loss: 0.15577568113803864
step: 160, loss: 0.06170734763145447
step: 170, loss: 0.15080735087394714
step: 180, loss: 0.05818849056959152
step: 190, loss: 0.045677848160266876
step: 200, loss: 0.15157435834407806
step: 210, loss: 0.10640738159418106
step: 220, loss: 0.048187512904405594
step: 230, loss: 0.10643977671861649
step: 240, loss: 0.027432003989815712
step: 250, loss: 0.08217532187700272
step: 260, loss: 0.1088557317852974
step: 270, loss: 0.15109728276729584
step: 280, loss: 0.06193850561976433
step: 290, loss: 0.17658717930316925
step: 300, loss: 0.116973377764225
step: 310, loss: 0.04807338863611221
step: 320, loss: 0.14310869574546814
step: 330, loss: 0.06709356606006622
step: 340, loss: 0.14432862401008606
step: 350, loss: 0.04081108793616295
epoch 12: dev_f1=0.8213457076566126, f1=0.8146453089244851, best_f1=0.8215962441314554
step: 0, loss: 0.030077096074819565
step: 10, loss: 0.1066489890217781
step: 20, loss: 0.06514228880405426
step: 30, loss: 0.07899131625890732
step: 40, loss: 0.043125733733177185
step: 50, loss: 0.05531397834420204
step: 60, loss: 0.0545775331556797
step: 70, loss: 0.055249836295843124
step: 80, loss: 0.11727343499660492
step: 90, loss: 0.10137859731912613
step: 100, loss: 0.12425711750984192
step: 110, loss: 0.06024419143795967
step: 120, loss: 0.05941881611943245
step: 130, loss: 0.09313996136188507
step: 140, loss: 0.03399338945746422
step: 150, loss: 0.07015136629343033
step: 160, loss: 0.0834290012717247
step: 170, loss: 0.07388673722743988
step: 180, loss: 0.07629673928022385
step: 190, loss: 0.12106535583734512
step: 200, loss: 0.025240307673811913
step: 210, loss: 0.015529263764619827
step: 220, loss: 0.12306583672761917
step: 230, loss: 0.06943715363740921
step: 240, loss: 0.069541797041893
step: 250, loss: 0.10462001711130142
step: 260, loss: 0.043008629232645035
step: 270, loss: 0.041736338287591934
step: 280, loss: 0.012707614339888096
step: 290, loss: 0.08216328918933868
step: 300, loss: 0.06974944472312927
step: 310, loss: 0.04339214414358139
step: 320, loss: 0.018515974283218384
step: 330, loss: 0.1826075315475464
step: 340, loss: 0.05505438521504402
step: 350, loss: 0.11995545029640198
epoch 13: dev_f1=0.8277511961722487, f1=0.8246445497630333, best_f1=0.8215962441314554
step: 0, loss: 0.08204440027475357
step: 10, loss: 0.05215320736169815
step: 20, loss: 0.06110529601573944
step: 30, loss: 0.09134668856859207
step: 40, loss: 0.07861000299453735
step: 50, loss: 0.08714137226343155
step: 60, loss: 0.0003375275991857052
step: 70, loss: 0.05822623893618584
step: 80, loss: 0.03205398842692375
step: 90, loss: 0.10717900842428207
step: 100, loss: 0.050377603620290756
step: 110, loss: 0.06287036091089249
step: 120, loss: 0.025832369923591614
step: 130, loss: 0.07626071572303772
step: 140, loss: 0.047634463757276535
step: 150, loss: 0.1659872978925705
step: 160, loss: 0.14304208755493164
step: 170, loss: 0.08200731128454208
step: 180, loss: 0.10874263197183609
step: 190, loss: 0.013020734302699566
step: 200, loss: 0.09490279853343964
step: 210, loss: 0.08464052528142929
step: 220, loss: 0.09202670305967331
step: 230, loss: 0.04694592207670212
step: 240, loss: 0.09893593937158585
step: 250, loss: 0.026768948882818222
step: 260, loss: 0.046293262392282486
step: 270, loss: 0.07711570709943771
step: 280, loss: 0.06008490175008774
step: 290, loss: 0.10337620973587036
step: 300, loss: 0.08622343838214874
step: 310, loss: 0.09267044067382812
step: 320, loss: 0.015296154655516148
step: 330, loss: 0.06633561104536057
step: 340, loss: 0.006850311532616615
step: 350, loss: 0.18879689276218414
epoch 14: dev_f1=0.8179669030732861, f1=0.8046511627906976, best_f1=0.8215962441314554
step: 0, loss: 0.03344269096851349
step: 10, loss: 0.020797818899154663
step: 20, loss: 0.137759730219841
step: 30, loss: 0.07277767360210419
step: 40, loss: 0.029120754450559616
step: 50, loss: 6.777617818443105e-05
step: 60, loss: 0.03865896910429001
step: 70, loss: 0.07461680471897125
step: 80, loss: 0.0372297428548336
step: 90, loss: 0.025271832942962646
step: 100, loss: 0.10214634984731674
step: 110, loss: 0.15286347270011902
step: 120, loss: 0.037311408668756485
step: 130, loss: 0.05908903107047081
step: 140, loss: 0.027899902313947678
step: 150, loss: 0.054465290158987045
step: 160, loss: 0.053940072655677795
step: 170, loss: 0.07340750843286514
step: 180, loss: 0.06813225150108337
step: 190, loss: 0.1118912547826767
step: 200, loss: 0.030561286956071854
step: 210, loss: 0.10711516439914703
step: 220, loss: 0.058655183762311935
step: 230, loss: 0.10192691534757614
step: 240, loss: 0.019256142899394035
step: 250, loss: 0.0776202455163002
step: 260, loss: 0.07679994404315948
step: 270, loss: 0.06908049434423447
step: 280, loss: 0.10030966997146606
step: 290, loss: 0.15509086847305298
step: 300, loss: 0.08454997837543488
step: 310, loss: 0.10243846476078033
step: 320, loss: 0.059462808072566986
step: 330, loss: 0.02413525991141796
step: 340, loss: 0.016677718609571457
step: 350, loss: 0.10944990813732147
epoch 15: dev_f1=0.8300970873786409, f1=0.8028169014084506, best_f1=0.8215962441314554
step: 0, loss: 0.022028475999832153
step: 10, loss: 0.06760867685079575
step: 20, loss: 0.08295787125825882
step: 30, loss: 0.07440683990716934
step: 40, loss: 0.06937208026647568
step: 50, loss: 0.04097658768296242
step: 60, loss: 0.052375923842191696
step: 70, loss: 0.06636835634708405
step: 80, loss: 0.031122222542762756
step: 90, loss: 0.12583188712596893
step: 100, loss: 0.07509505748748779
step: 110, loss: 0.04796518012881279
step: 120, loss: 0.09468699246644974
step: 130, loss: 0.07344977557659149
step: 140, loss: 0.06503865122795105
step: 150, loss: 0.03422728553414345
step: 160, loss: 0.04760615900158882
step: 170, loss: 0.07755845040082932
step: 180, loss: 0.08505203574895859
step: 190, loss: 0.04709247872233391
step: 200, loss: 0.01600160077214241
step: 210, loss: 0.07680903375148773
step: 220, loss: 0.057338230311870575
step: 230, loss: 0.02424437738955021
step: 240, loss: 0.09228792786598206
step: 250, loss: 0.01750849559903145
step: 260, loss: 0.10461209714412689
step: 270, loss: 0.11459209024906158
step: 280, loss: 0.09245362877845764
step: 290, loss: 0.0006107379449531436
step: 300, loss: 0.1272173970937729
step: 310, loss: 0.030421985313296318
step: 320, loss: 0.12246698141098022
step: 330, loss: 0.01755707524716854
step: 340, loss: 0.08955734223127365
step: 350, loss: 0.006176874041557312
epoch 16: dev_f1=0.8106796116504854, f1=0.7858823529411765, best_f1=0.8215962441314554
step: 0, loss: 0.013154618442058563
step: 10, loss: 0.14594429731369019
step: 20, loss: 0.08289794623851776
step: 30, loss: 0.06483948230743408
step: 40, loss: 0.030315980315208435
step: 50, loss: 0.15071579813957214
step: 60, loss: 0.07697603851556778
step: 70, loss: 0.10080644488334656
step: 80, loss: 0.04547913745045662
step: 90, loss: 0.04905552417039871
step: 100, loss: 0.10702383518218994
step: 110, loss: 0.064656563103199
step: 120, loss: 0.024199139326810837
step: 130, loss: 0.011995351873338223
step: 140, loss: 0.09332416206598282
step: 150, loss: 0.011220581829547882
step: 160, loss: 0.07265591621398926
step: 170, loss: 0.06088356301188469
step: 180, loss: 0.10091100633144379
step: 190, loss: 4.7363078920170665e-05
step: 200, loss: 0.0863327756524086
step: 210, loss: 0.05643545091152191
step: 220, loss: 0.00571037270128727
step: 230, loss: 0.021158821880817413
step: 240, loss: 0.06726677715778351
step: 250, loss: 0.005573909264057875
step: 260, loss: 0.09497063606977463
step: 270, loss: 0.04117408022284508
step: 280, loss: 0.13613128662109375
step: 290, loss: 0.051262397319078445
step: 300, loss: 0.1102059930562973
step: 310, loss: 0.041165128350257874
step: 320, loss: 0.05451589077711105
step: 330, loss: 0.08613664656877518
step: 340, loss: 0.07570553570985794
step: 350, loss: 0.10619553178548813
epoch 17: dev_f1=0.7980769230769231, f1=0.786046511627907, best_f1=0.8215962441314554
step: 0, loss: 0.03295689821243286
step: 10, loss: 0.13344953954219818
step: 20, loss: 0.06287767738103867
step: 30, loss: 0.07766186445951462
step: 40, loss: 0.002436192939057946
step: 50, loss: 0.0827169120311737
step: 60, loss: 0.15985092520713806
step: 70, loss: 0.07965435087680817
step: 80, loss: 0.03631608933210373
step: 90, loss: 0.014260814525187016
step: 100, loss: 0.09386003017425537
step: 110, loss: 0.019528064876794815
step: 120, loss: 0.030489441007375717
step: 130, loss: 0.06228449568152428
step: 140, loss: 5.324982339516282e-05
step: 150, loss: 0.04461204260587692
step: 160, loss: 0.10495831817388535
step: 170, loss: 0.09132759273052216
step: 180, loss: 0.07132898271083832
step: 190, loss: 0.14932852983474731
step: 200, loss: 0.11588229238986969
step: 210, loss: 0.013480477966368198
step: 220, loss: 0.039669789373874664
step: 230, loss: 0.04046408087015152
step: 240, loss: 0.06079923361539841
step: 250, loss: 0.04811461642384529
step: 260, loss: 0.1296122819185257
step: 270, loss: 0.09386632591485977
step: 280, loss: 0.15502558648586273
step: 290, loss: 0.03783216327428818
step: 300, loss: 0.043969083577394485
step: 310, loss: 0.039861176162958145
step: 320, loss: 0.030884303152561188
step: 330, loss: 0.1500985026359558
step: 340, loss: 0.09012024849653244
step: 350, loss: 0.0704079419374466
epoch 18: dev_f1=0.803970223325062, f1=0.7931873479318734, best_f1=0.8215962441314554
step: 0, loss: 0.018710026517510414
step: 10, loss: 0.02295919694006443
step: 20, loss: 0.060426730662584305
step: 30, loss: 0.006042785942554474
step: 40, loss: 0.0021094856783747673
step: 50, loss: 0.05464611202478409
step: 60, loss: 0.054455555975437164
step: 70, loss: 0.09830482304096222
step: 80, loss: 0.027193665504455566
step: 90, loss: 0.10820344090461731
step: 100, loss: 0.1451093703508377
step: 110, loss: 0.037331923842430115
step: 120, loss: 0.0249614380300045
step: 130, loss: 0.03455808758735657
step: 140, loss: 0.01019229181110859
step: 150, loss: 0.08954069018363953
step: 160, loss: 0.06840955466032028
step: 170, loss: 0.11123473942279816
step: 180, loss: 0.03875776380300522
step: 190, loss: 0.0023276973515748978
step: 200, loss: 0.07523272186517715
step: 210, loss: 0.05488429591059685
step: 220, loss: 0.08825153112411499
step: 230, loss: 0.0752311572432518
step: 240, loss: 0.06979882717132568
step: 250, loss: 0.03068079985678196
step: 260, loss: 0.012073607183992863
step: 270, loss: 0.04398960620164871
step: 280, loss: 0.04678906500339508
step: 290, loss: 0.038631871342659
step: 300, loss: 0.03467148542404175
step: 310, loss: 0.048129852861166
step: 320, loss: 0.174159973859787
step: 330, loss: 0.05162831395864487
step: 340, loss: 0.0568016953766346
step: 350, loss: 0.07288580387830734
epoch 19: dev_f1=0.8058968058968059, f1=0.79136690647482, best_f1=0.8215962441314554
step: 0, loss: 0.0002095723175443709
step: 10, loss: 0.058618851006031036
step: 20, loss: 0.016020867973566055
step: 30, loss: 0.047234196215867996
step: 40, loss: 0.07823873311281204
step: 50, loss: 0.01691725105047226
step: 60, loss: 0.07628648728132248
step: 70, loss: 0.08615867793560028
step: 80, loss: 0.10411990433931351
step: 90, loss: 0.16609324514865875
step: 100, loss: 0.09358283132314682
step: 110, loss: 0.06346996128559113
step: 120, loss: 0.028216512873768806
step: 130, loss: 0.09095287322998047
step: 140, loss: 0.030672188848257065
step: 150, loss: 0.05647459253668785
step: 160, loss: 0.04787186533212662
step: 170, loss: 0.039624620229005814
step: 180, loss: 0.03865945339202881
step: 190, loss: 0.04344385862350464
step: 200, loss: 0.09715117514133453
step: 210, loss: 0.0014263781486079097
step: 220, loss: 0.055067405104637146
step: 230, loss: 0.0960894525051117
step: 240, loss: 0.08033423870801926
step: 250, loss: 0.031549300998449326
step: 260, loss: 0.016646888107061386
step: 270, loss: 0.03329458460211754
step: 280, loss: 0.05806147679686546
step: 290, loss: 0.07167017459869385
step: 300, loss: 0.04934057220816612
step: 310, loss: 0.12381207942962646
step: 320, loss: 0.017081230878829956
step: 330, loss: 0.0830812007188797
step: 340, loss: 0.05583304539322853
step: 350, loss: 0.05001215636730194
epoch 20: dev_f1=0.800982800982801, f1=0.79136690647482, best_f1=0.8215962441314554
