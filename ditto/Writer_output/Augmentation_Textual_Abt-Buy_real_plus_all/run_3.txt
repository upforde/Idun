cuda
Device: cuda
step: 0, loss: 0.7376030683517456
step: 10, loss: 0.33922135829925537
step: 20, loss: 0.3279597759246826
step: 30, loss: 0.2975364327430725
step: 40, loss: 0.30441999435424805
step: 50, loss: 0.3731538653373718
step: 60, loss: 0.35908523201942444
step: 70, loss: 0.32019367814064026
step: 80, loss: 0.13949882984161377
step: 90, loss: 0.4030252993106842
step: 100, loss: 0.2866859436035156
step: 110, loss: 0.2949717044830322
step: 120, loss: 0.28150999546051025
step: 130, loss: 0.189401775598526
step: 140, loss: 0.4620899558067322
step: 150, loss: 0.2816772162914276
step: 160, loss: 0.31419694423675537
step: 170, loss: 0.36789366602897644
step: 180, loss: 0.1889197677373886
step: 190, loss: 0.15640346705913544
step: 200, loss: 0.17540240287780762
step: 210, loss: 0.14310923218727112
step: 220, loss: 0.2054632008075714
step: 230, loss: 0.058471351861953735
step: 240, loss: 0.0825638622045517
step: 250, loss: 0.3461552858352661
step: 260, loss: 0.16516578197479248
step: 270, loss: 0.28720471262931824
step: 280, loss: 0.11252855509519577
step: 290, loss: 0.16540034115314484
step: 300, loss: 0.1566869169473648
step: 310, loss: 0.04768368974328041
step: 320, loss: 0.0668240413069725
step: 330, loss: 0.1218007504940033
step: 340, loss: 0.15249255299568176
step: 350, loss: 0.1546006053686142
epoch 1: dev_f1=0.7291666666666666, f1=0.6906187624750498, best_f1=0.6906187624750498
step: 0, loss: 0.26503169536590576
step: 10, loss: 0.1970776468515396
step: 20, loss: 0.031232228502631187
step: 30, loss: 0.09113848209381104
step: 40, loss: 0.05482453107833862
step: 50, loss: 0.03851477429270744
step: 60, loss: 0.17197270691394806
step: 70, loss: 0.1044146716594696
step: 80, loss: 0.06977690011262894
step: 90, loss: 0.10711190104484558
step: 100, loss: 0.047504980117082596
step: 110, loss: 0.1825399547815323
step: 120, loss: 0.11323735862970352
step: 130, loss: 0.09868583083152771
step: 140, loss: 0.10940955579280853
step: 150, loss: 0.27706488966941833
step: 160, loss: 0.033279046416282654
step: 170, loss: 0.06269276142120361
step: 180, loss: 0.18296478688716888
step: 190, loss: 0.039612121880054474
step: 200, loss: 0.15833598375320435
step: 210, loss: 0.06980904191732407
step: 220, loss: 0.15188251435756683
step: 230, loss: 0.11043059080839157
step: 240, loss: 0.10505292564630508
step: 250, loss: 0.11815176904201508
step: 260, loss: 0.07948028296232224
step: 270, loss: 0.5104689598083496
step: 280, loss: 0.08426112681627274
step: 290, loss: 0.05998832359910011
step: 300, loss: 0.233050137758255
step: 310, loss: 0.1460353583097458
step: 320, loss: 0.08496032655239105
step: 330, loss: 0.13646936416625977
step: 340, loss: 0.13854306936264038
step: 350, loss: 0.1634501963853836
epoch 2: dev_f1=0.7643020594965675, f1=0.7429805615550756, best_f1=0.7429805615550756
step: 0, loss: 0.09183407574892044
step: 10, loss: 0.07258588820695877
step: 20, loss: 0.09410174936056137
step: 30, loss: 0.06436989456415176
step: 40, loss: 0.039698127657175064
step: 50, loss: 0.23983176052570343
step: 60, loss: 0.08496231585741043
step: 70, loss: 0.1355469673871994
step: 80, loss: 0.2760108411312103
step: 90, loss: 0.04900515824556351
step: 100, loss: 0.2020401805639267
step: 110, loss: 0.05150251090526581
step: 120, loss: 0.14998240768909454
step: 130, loss: 0.07400893419981003
step: 140, loss: 0.16064786911010742
step: 150, loss: 0.1008906438946724
step: 160, loss: 0.06683772802352905
step: 170, loss: 0.11965014785528183
step: 180, loss: 0.302124947309494
step: 190, loss: 0.13499003648757935
step: 200, loss: 0.05712442845106125
step: 210, loss: 0.10255011171102524
step: 220, loss: 0.08734166622161865
step: 230, loss: 0.06513345241546631
step: 240, loss: 0.1512034386396408
step: 250, loss: 0.108279749751091
step: 260, loss: 0.013800947926938534
step: 270, loss: 0.10816793143749237
step: 280, loss: 0.09247598052024841
step: 290, loss: 0.12288812547922134
step: 300, loss: 0.09844373911619186
step: 310, loss: 0.16999700665473938
step: 320, loss: 0.07572246342897415
step: 330, loss: 0.08924998342990875
step: 340, loss: 0.101271852850914
step: 350, loss: 0.22627732157707214
epoch 3: dev_f1=0.8099547511312217, f1=0.7824175824175823, best_f1=0.7824175824175823
step: 0, loss: 0.129123255610466
step: 10, loss: 0.06306395679712296
step: 20, loss: 0.1224481612443924
step: 30, loss: 0.12191993743181229
step: 40, loss: 0.08814510703086853
step: 50, loss: 0.12368176877498627
step: 60, loss: 0.08974701911211014
step: 70, loss: 0.10853548347949982
step: 80, loss: 0.028572890907526016
step: 90, loss: 0.13784635066986084
step: 100, loss: 0.06160479784011841
step: 110, loss: 0.1608097106218338
step: 120, loss: 0.018727263435721397
step: 130, loss: 0.033781662583351135
step: 140, loss: 0.14516833424568176
step: 150, loss: 0.09465517103672028
step: 160, loss: 0.13237014412879944
step: 170, loss: 0.16188490390777588
step: 180, loss: 0.06280725449323654
step: 190, loss: 0.09986723214387894
step: 200, loss: 0.07312478125095367
step: 210, loss: 0.06094405800104141
step: 220, loss: 0.15595288574695587
step: 230, loss: 0.09113875776529312
step: 240, loss: 0.12224388122558594
step: 250, loss: 0.17464900016784668
step: 260, loss: 0.13443602621555328
step: 270, loss: 0.11794351786375046
step: 280, loss: 0.0462556816637516
step: 290, loss: 0.07197047024965286
step: 300, loss: 0.022619444876909256
step: 310, loss: 0.06233510747551918
step: 320, loss: 0.1163574680685997
step: 330, loss: 0.17545846104621887
step: 340, loss: 0.07860962301492691
step: 350, loss: 0.08225073665380478
epoch 4: dev_f1=0.8213457076566126, f1=0.7930283224400873, best_f1=0.7930283224400873
step: 0, loss: 0.07885292172431946
step: 10, loss: 0.054092444479465485
step: 20, loss: 0.1173500046133995
step: 30, loss: 0.1260569989681244
step: 40, loss: 0.15479806065559387
step: 50, loss: 0.05499974265694618
step: 60, loss: 0.06281954795122147
step: 70, loss: 0.12311408668756485
step: 80, loss: 0.021079882979393005
step: 90, loss: 0.20112527906894684
step: 100, loss: 0.2571467459201813
step: 110, loss: 0.03619183972477913
step: 120, loss: 0.1784355342388153
step: 130, loss: 0.0633542463183403
step: 140, loss: 0.04232290759682655
step: 150, loss: 0.08589792996644974
step: 160, loss: 0.064902164041996
step: 170, loss: 0.10722420364618301
step: 180, loss: 0.30883198976516724
step: 190, loss: 0.0388898141682148
step: 200, loss: 0.06164710223674774
step: 210, loss: 0.11773208528757095
step: 220, loss: 0.03510501608252525
step: 230, loss: 0.05809454247355461
step: 240, loss: 0.07763584703207016
step: 250, loss: 0.126816064119339
step: 260, loss: 0.10219643265008926
step: 270, loss: 0.19212664663791656
step: 280, loss: 0.1126691997051239
step: 290, loss: 0.22802302241325378
step: 300, loss: 0.21471673250198364
step: 310, loss: 0.11479686945676804
step: 320, loss: 0.24379132688045502
step: 330, loss: 0.15619231760501862
step: 340, loss: 0.2173917293548584
step: 350, loss: 0.050627607852220535
epoch 5: dev_f1=0.8141176470588235, f1=0.8009049773755657, best_f1=0.7930283224400873
step: 0, loss: 0.08696434646844864
step: 10, loss: 0.07445172965526581
step: 20, loss: 0.05203039199113846
step: 30, loss: 0.07983940839767456
step: 40, loss: 0.05342995002865791
step: 50, loss: 0.10476960986852646
step: 60, loss: 0.03408302366733551
step: 70, loss: 0.128137469291687
step: 80, loss: 0.021498318761587143
step: 90, loss: 0.03470616415143013
step: 100, loss: 0.10650752484798431
step: 110, loss: 0.06849122047424316
step: 120, loss: 0.04978741332888603
step: 130, loss: 0.12904489040374756
step: 140, loss: 0.029275238513946533
step: 150, loss: 0.09933260828256607
step: 160, loss: 0.031305670738220215
step: 170, loss: 0.036304790526628494
step: 180, loss: 0.04593631625175476
step: 190, loss: 0.08094648271799088
step: 200, loss: 0.09161370247602463
step: 210, loss: 0.13610167801380157
step: 220, loss: 0.03180120885372162
step: 230, loss: 0.23726613819599152
step: 240, loss: 0.22657574713230133
step: 250, loss: 0.07372560352087021
step: 260, loss: 0.07337287813425064
step: 270, loss: 0.10035423189401627
step: 280, loss: 0.026174111291766167
step: 290, loss: 0.03656020760536194
step: 300, loss: 0.02450738474726677
step: 310, loss: 0.10958454012870789
step: 320, loss: 0.05699049308896065
step: 330, loss: 0.05686933174729347
step: 340, loss: 0.09609533846378326
step: 350, loss: 0.09847797453403473
epoch 6: dev_f1=0.7566265060240964, f1=0.7429906542056075, best_f1=0.7930283224400873
step: 0, loss: 0.061503905802965164
step: 10, loss: 0.08667918294668198
step: 20, loss: 0.15978536009788513
step: 30, loss: 0.19255293905735016
step: 40, loss: 0.08421528339385986
step: 50, loss: 0.11589379608631134
step: 60, loss: 0.2049226015806198
step: 70, loss: 0.14889280498027802
step: 80, loss: 0.02914690598845482
step: 90, loss: 0.10170917958021164
step: 100, loss: 0.1222628802061081
step: 110, loss: 0.03465103358030319
step: 120, loss: 0.07567167282104492
step: 130, loss: 0.10076775401830673
step: 140, loss: 0.10449299216270447
step: 150, loss: 0.11207945644855499
step: 160, loss: 0.11331719160079956
step: 170, loss: 0.09194930642843246
step: 180, loss: 0.048577480018138885
step: 190, loss: 0.1346823126077652
step: 200, loss: 0.05368422344326973
step: 210, loss: 0.07035810500383377
step: 220, loss: 0.0558633990585804
step: 230, loss: 0.06496026366949081
step: 240, loss: 0.02385610155761242
step: 250, loss: 0.08508624136447906
step: 260, loss: 0.028808817267417908
step: 270, loss: 0.03173796832561493
step: 280, loss: 0.0690106749534607
step: 290, loss: 0.12574651837348938
step: 300, loss: 0.08120468258857727
step: 310, loss: 0.08518680930137634
step: 320, loss: 0.06459850817918777
step: 330, loss: 0.07012775540351868
step: 340, loss: 0.1556207835674286
step: 350, loss: 0.1037677526473999
epoch 7: dev_f1=0.847926267281106, f1=0.7955056179775281, best_f1=0.7955056179775281
step: 0, loss: 0.0334022119641304
step: 10, loss: 0.17229562997817993
step: 20, loss: 0.07109420001506805
step: 30, loss: 0.09832598268985748
step: 40, loss: 0.058064382523298264
step: 50, loss: 0.101704441010952
step: 60, loss: 0.08558815717697144
step: 70, loss: 0.06035542115569115
step: 80, loss: 0.1500997096300125
step: 90, loss: 0.11591536551713943
step: 100, loss: 0.11138063669204712
step: 110, loss: 0.0518258735537529
step: 120, loss: 0.045678865164518356
step: 130, loss: 0.03585456684231758
step: 140, loss: 0.18273921310901642
step: 150, loss: 0.022352980449795723
step: 160, loss: 0.11714467406272888
step: 170, loss: 0.11310858279466629
step: 180, loss: 0.021465327590703964
step: 190, loss: 0.1581484079360962
step: 200, loss: 0.12174755334854126
step: 210, loss: 0.13987623155117035
step: 220, loss: 0.1171036958694458
step: 230, loss: 0.08393175154924393
step: 240, loss: 0.048707231879234314
step: 250, loss: 0.09389953315258026
step: 260, loss: 0.12343091517686844
step: 270, loss: 0.025631379336118698
step: 280, loss: 0.10942936688661575
step: 290, loss: 0.09904268383979797
step: 300, loss: 0.005600829608738422
step: 310, loss: 0.03576132282614708
step: 320, loss: 0.08534848690032959
step: 330, loss: 0.03784923255443573
step: 340, loss: 0.06118128448724747
step: 350, loss: 0.13321438431739807
epoch 8: dev_f1=0.8610478359908884, f1=0.8062360801781738, best_f1=0.8062360801781738
step: 0, loss: 0.06514962017536163
step: 10, loss: 0.03979623690247536
step: 20, loss: 0.08415243029594421
step: 30, loss: 0.08301927894353867
step: 40, loss: 0.04382406175136566
step: 50, loss: 0.12039954960346222
step: 60, loss: 0.11999815702438354
step: 70, loss: 0.11213712394237518
step: 80, loss: 0.07946119457483292
step: 90, loss: 0.06373585015535355
step: 100, loss: 0.03536250442266464
step: 110, loss: 0.1142558753490448
step: 120, loss: 0.08108822256326675
step: 130, loss: 0.11405271291732788
step: 140, loss: 0.15539179742336273
step: 150, loss: 0.07665570825338364
step: 160, loss: 0.020639536902308464
step: 170, loss: 0.07020541280508041
step: 180, loss: 0.08751948177814484
step: 190, loss: 0.1215999573469162
step: 200, loss: 0.06674234569072723
step: 210, loss: 0.11974138766527176
step: 220, loss: 0.057751867920160294
step: 230, loss: 0.038295675069093704
step: 240, loss: 0.08638704568147659
step: 250, loss: 0.06316572427749634
step: 260, loss: 0.10181698203086853
step: 270, loss: 0.1378335952758789
step: 280, loss: 0.060187216848134995
step: 290, loss: 0.07714206725358963
step: 300, loss: 0.1253434121608734
step: 310, loss: 0.0979895144701004
step: 320, loss: 0.050992801785469055
step: 330, loss: 0.11625464260578156
step: 340, loss: 0.07163646817207336
step: 350, loss: 0.13520728051662445
epoch 9: dev_f1=0.8310502283105023, f1=0.8099547511312217, best_f1=0.8062360801781738
step: 0, loss: 0.06498576700687408
step: 10, loss: 0.07461031526327133
step: 20, loss: 0.10833089798688889
step: 30, loss: 0.1183154433965683
step: 40, loss: 0.072178915143013
step: 50, loss: 0.06345531344413757
step: 60, loss: 0.09536679834127426
step: 70, loss: 0.09779760241508484
step: 80, loss: 0.10892084240913391
step: 90, loss: 0.062313634902238846
step: 100, loss: 0.041783057153224945
step: 110, loss: 0.06393566727638245
step: 120, loss: 0.02331993728876114
step: 130, loss: 0.10330692678689957
step: 140, loss: 0.10723213851451874
step: 150, loss: 0.09859482198953629
step: 160, loss: 0.14441680908203125
step: 170, loss: 0.07551153004169464
step: 180, loss: 0.14599744975566864
step: 190, loss: 0.15342405438423157
step: 200, loss: 0.08532318472862244
step: 210, loss: 0.07590756565332413
step: 220, loss: 0.0322749987244606
step: 230, loss: 0.13845381140708923
step: 240, loss: 0.07083870470523834
step: 250, loss: 0.21301409602165222
step: 260, loss: 0.03864339366555214
step: 270, loss: 0.12617278099060059
step: 280, loss: 0.1596418023109436
step: 290, loss: 0.053823310881853104
step: 300, loss: 0.07528160512447357
step: 310, loss: 0.10193537175655365
step: 320, loss: 0.06230059638619423
step: 330, loss: 0.105726458132267
step: 340, loss: 0.09946456551551819
step: 350, loss: 0.08813827484846115
epoch 10: dev_f1=0.836104513064133, f1=0.8202764976958525, best_f1=0.8062360801781738
step: 0, loss: 0.13578347861766815
step: 10, loss: 0.057647738605737686
step: 20, loss: 0.051141880452632904
step: 30, loss: 0.0772668793797493
step: 40, loss: 0.061884861439466476
step: 50, loss: 0.11571677029132843
step: 60, loss: 0.1419239044189453
step: 70, loss: 0.06394901871681213
step: 80, loss: 0.04172239080071449
step: 90, loss: 0.04833194240927696
step: 100, loss: 0.14156632125377655
step: 110, loss: 0.0452989861369133
step: 120, loss: 0.08448278158903122
step: 130, loss: 0.07451116293668747
step: 140, loss: 0.061478883028030396
step: 150, loss: 0.12455475330352783
step: 160, loss: 0.12716549634933472
step: 170, loss: 0.04736795276403427
step: 180, loss: 0.16542485356330872
step: 190, loss: 0.1431974321603775
step: 200, loss: 0.17561006546020508
step: 210, loss: 0.09309063851833344
step: 220, loss: 0.17356374859809875
step: 230, loss: 0.03919964283704758
step: 240, loss: 0.12873995304107666
step: 250, loss: 0.033855658024549484
step: 260, loss: 0.07689087092876434
step: 270, loss: 0.1843109279870987
step: 280, loss: 0.08876793086528778
step: 290, loss: 0.08045252412557602
step: 300, loss: 0.0487651489675045
step: 310, loss: 0.03225076571106911
step: 320, loss: 0.05698204040527344
step: 330, loss: 0.0004966395208612084
step: 340, loss: 0.10751322656869888
step: 350, loss: 0.11822375655174255
epoch 11: dev_f1=0.8253164556962025, f1=0.8203883495145631, best_f1=0.8062360801781738
step: 0, loss: 0.03278357535600662
step: 10, loss: 0.07091833651065826
step: 20, loss: 0.07368102669715881
step: 30, loss: 0.08338449150323868
step: 40, loss: 0.13761720061302185
step: 50, loss: 0.03315770626068115
step: 60, loss: 0.014858456328511238
step: 70, loss: 0.05065193027257919
step: 80, loss: 0.12254738807678223
step: 90, loss: 0.07390488684177399
step: 100, loss: 0.06791093945503235
step: 110, loss: 0.09596073627471924
step: 120, loss: 0.17939266562461853
step: 130, loss: 0.15903374552726746
step: 140, loss: 0.04754285514354706
step: 150, loss: 0.122007817029953
step: 160, loss: 0.01905669830739498
step: 170, loss: 0.0701141357421875
step: 180, loss: 0.05974194034934044
step: 190, loss: 0.1126827672123909
step: 200, loss: 0.06829284876585007
step: 210, loss: 0.11103171855211258
step: 220, loss: 0.08062781393527985
step: 230, loss: 0.00016095775936264545
step: 240, loss: 0.24690911173820496
step: 250, loss: 0.08303975313901901
step: 260, loss: 0.05832481384277344
step: 270, loss: 0.06679356098175049
step: 280, loss: 0.022973820567131042
step: 290, loss: 0.08805061876773834
step: 300, loss: 0.07668599486351013
step: 310, loss: 0.14204861223697662
step: 320, loss: 7.13688787072897e-05
step: 330, loss: 0.16236361861228943
step: 340, loss: 0.039924345910549164
step: 350, loss: 0.04712932929396629
epoch 12: dev_f1=0.8159203980099503, f1=0.8086124401913874, best_f1=0.8062360801781738
step: 0, loss: 0.08353623747825623
step: 10, loss: 0.00441789161413908
step: 20, loss: 0.16599886119365692
step: 30, loss: 0.05588807165622711
step: 40, loss: 0.024266637861728668
step: 50, loss: 0.02297963947057724
step: 60, loss: 0.1635122150182724
step: 70, loss: 0.03629627823829651
step: 80, loss: 0.11449182778596878
step: 90, loss: 0.0662141814827919
step: 100, loss: 0.07940748333930969
step: 110, loss: 0.1152578666806221
step: 120, loss: 0.02834307961165905
step: 130, loss: 0.0702391266822815
step: 140, loss: 0.018198102712631226
step: 150, loss: 0.07520779222249985
step: 160, loss: 0.09424316883087158
step: 170, loss: 0.04386536404490471
step: 180, loss: 0.014449373818933964
step: 190, loss: 0.13357296586036682
step: 200, loss: 0.08504568785429001
step: 210, loss: 0.026732316240668297
step: 220, loss: 0.05980914086103439
step: 230, loss: 0.08987462520599365
step: 240, loss: 0.005497973412275314
step: 250, loss: 0.08424876630306244
step: 260, loss: 0.027304604649543762
step: 270, loss: 0.14270877838134766
step: 280, loss: 0.06831056624650955
step: 290, loss: 0.14618796110153198
step: 300, loss: 0.101597361266613
step: 310, loss: 0.06895174831151962
step: 320, loss: 0.06601246446371078
step: 330, loss: 0.0980958342552185
step: 340, loss: 0.13323962688446045
step: 350, loss: 0.10667991638183594
epoch 13: dev_f1=0.8235294117647057, f1=0.802721088435374, best_f1=0.8062360801781738
step: 0, loss: 0.1963772028684616
step: 10, loss: 0.14684143662452698
step: 20, loss: 0.05045434460043907
step: 30, loss: 0.02935921959578991
step: 40, loss: 0.06265740841627121
step: 50, loss: 0.14522123336791992
step: 60, loss: 0.012875784188508987
step: 70, loss: 0.10246086865663528
step: 80, loss: 0.0785362496972084
step: 90, loss: 0.07407746464014053
step: 100, loss: 0.17319180071353912
step: 110, loss: 0.061071544885635376
step: 120, loss: 0.014005535282194614
step: 130, loss: 0.19369518756866455
step: 140, loss: 0.08085441589355469
step: 150, loss: 0.04153352603316307
step: 160, loss: 0.11945398151874542
step: 170, loss: 0.0613381452858448
step: 180, loss: 0.02103300206363201
step: 190, loss: 0.12469816207885742
step: 200, loss: 0.07494976371526718
step: 210, loss: 0.09955094009637833
step: 220, loss: 0.04969602823257446
step: 230, loss: 0.09559662640094757
step: 240, loss: 0.1231309175491333
step: 250, loss: 0.028020784258842468
step: 260, loss: 0.12230165302753448
step: 270, loss: 0.07408443838357925
step: 280, loss: 0.046675264835357666
step: 290, loss: 0.05313697084784508
step: 300, loss: 0.14752478897571564
step: 310, loss: 0.07383880019187927
step: 320, loss: 0.06643832474946976
step: 330, loss: 0.20402266085147858
step: 340, loss: 0.10856945812702179
step: 350, loss: 0.09227112680673599
epoch 14: dev_f1=0.8387096774193549, f1=0.8053691275167785, best_f1=0.8062360801781738
step: 0, loss: 0.06813757866621017
step: 10, loss: 0.10338043421506882
step: 20, loss: 0.08099339157342911
step: 30, loss: 0.06773652136325836
step: 40, loss: 0.20980161428451538
step: 50, loss: 0.038617465645074844
step: 60, loss: 0.0945306345820427
step: 70, loss: 0.07010962069034576
step: 80, loss: 0.021372102200984955
step: 90, loss: 0.04897521063685417
step: 100, loss: 0.17464002966880798
step: 110, loss: 0.14246656000614166
step: 120, loss: 0.05076998844742775
step: 130, loss: 0.05242961645126343
step: 140, loss: 0.039395421743392944
step: 150, loss: 0.06088254228234291
step: 160, loss: 0.021798809990286827
step: 170, loss: 0.0296009574085474
step: 180, loss: 0.07321837544441223
step: 190, loss: 0.0708005502820015
step: 200, loss: 0.0909983292222023
step: 210, loss: 0.026933951303362846
step: 220, loss: 0.013473911210894585
step: 230, loss: 0.07902060449123383
step: 240, loss: 0.07570970803499222
step: 250, loss: 0.08554462343454361
step: 260, loss: 0.029651779681444168
step: 270, loss: 0.03495078161358833
step: 280, loss: 0.06004853919148445
step: 290, loss: 0.049757715314626694
step: 300, loss: 0.0921395942568779
step: 310, loss: 0.09705127030611038
step: 320, loss: 0.07481137663125992
step: 330, loss: 0.09280034154653549
step: 340, loss: 0.13149748742580414
step: 350, loss: 0.04869738593697548
epoch 15: dev_f1=0.8372093023255814, f1=0.8070953436807096, best_f1=0.8062360801781738
step: 0, loss: 0.10198844224214554
step: 10, loss: 0.0431862473487854
step: 20, loss: 0.1068253219127655
step: 30, loss: 0.08160430938005447
step: 40, loss: 0.05678005889058113
step: 50, loss: 0.1127939224243164
step: 60, loss: 0.012493664398789406
step: 70, loss: 0.027228744700551033
step: 80, loss: 0.0357988215982914
step: 90, loss: 0.05783626809716225
step: 100, loss: 0.08659236878156662
step: 110, loss: 0.07397620379924774
step: 120, loss: 0.1338149905204773
step: 130, loss: 0.14562316238880157
step: 140, loss: 0.0718352198600769
step: 150, loss: 0.09798907488584518
step: 160, loss: 0.06268350780010223
step: 170, loss: 0.0759572684764862
step: 180, loss: 0.03457033261656761
step: 190, loss: 0.08924199640750885
step: 200, loss: 0.044173453003168106
step: 210, loss: 0.04926012083888054
step: 220, loss: 0.11209005862474442
step: 230, loss: 0.032362405210733414
step: 240, loss: 0.04149354249238968
step: 250, loss: 0.06365327537059784
step: 260, loss: 0.08320778608322144
step: 270, loss: 0.08318107575178146
step: 280, loss: 0.08546902984380722
step: 290, loss: 0.07250925898551941
step: 300, loss: 0.044279906898736954
step: 310, loss: 0.11304887384176254
step: 320, loss: 0.02770581841468811
step: 330, loss: 0.03969943895936012
step: 340, loss: 0.06681842356920242
step: 350, loss: 0.07948222011327744
epoch 16: dev_f1=0.8395604395604396, f1=0.8043010752688172, best_f1=0.8062360801781738
step: 0, loss: 0.1365942358970642
step: 10, loss: 0.0833144262433052
step: 20, loss: 0.07267268002033234
step: 30, loss: 0.06429193168878555
step: 40, loss: 0.11283495277166367
step: 50, loss: 0.04846645146608353
step: 60, loss: 0.06197483837604523
step: 70, loss: 0.046112943440675735
step: 80, loss: 0.08571945130825043
step: 90, loss: 0.016697170212864876
step: 100, loss: 0.03345045447349548
step: 110, loss: 0.12873436510562897
step: 120, loss: 0.10848499834537506
step: 130, loss: 0.029141774401068687
step: 140, loss: 0.04976409673690796
step: 150, loss: 0.030011652037501335
step: 160, loss: 0.09066946059465408
step: 170, loss: 0.13971856236457825
step: 180, loss: 0.05177462100982666
step: 190, loss: 0.18266983330249786
step: 200, loss: 0.024993427097797394
step: 210, loss: 0.019086401909589767
step: 220, loss: 0.06894749402999878
step: 230, loss: 0.022352682426571846
step: 240, loss: 0.03650711849331856
step: 250, loss: 0.04212647303938866
step: 260, loss: 0.027411529794335365
step: 270, loss: 0.04511084780097008
step: 280, loss: 0.027481969445943832
step: 290, loss: 0.1146489754319191
step: 300, loss: 0.14497581124305725
step: 310, loss: 0.048715006560087204
step: 320, loss: 0.06292049586772919
step: 330, loss: 0.16579069197177887
step: 340, loss: 0.00417028833180666
step: 350, loss: 0.08288127928972244
epoch 17: dev_f1=0.8340807174887893, f1=0.8165938864628821, best_f1=0.8062360801781738
step: 0, loss: 0.09675934910774231
step: 10, loss: 0.14327266812324524
step: 20, loss: 0.08876322209835052
step: 30, loss: 0.07966674119234085
step: 40, loss: 0.03555643558502197
step: 50, loss: 0.07683217525482178
step: 60, loss: 0.06250389665365219
step: 70, loss: 0.059140875935554504
step: 80, loss: 0.06642023473978043
step: 90, loss: 0.05273399129509926
step: 100, loss: 0.020210104063153267
step: 110, loss: 0.1128862127661705
step: 120, loss: 0.01851547695696354
step: 130, loss: 0.17742541432380676
step: 140, loss: 0.00029158269171603024
step: 150, loss: 0.08789384365081787
step: 160, loss: 0.06652256846427917
step: 170, loss: 0.07308037579059601
step: 180, loss: 0.0078815883025527
step: 190, loss: 0.05153391882777214
step: 200, loss: 0.032268229871988297
step: 210, loss: 0.0001173928685602732
step: 220, loss: 0.05422058701515198
step: 230, loss: 0.059776078909635544
step: 240, loss: 0.012481801211833954
step: 250, loss: 0.08010804653167725
step: 260, loss: 0.10067068040370941
step: 270, loss: 0.021443629637360573
step: 280, loss: 0.07048351317644119
step: 290, loss: 0.04169909283518791
step: 300, loss: 0.008419489488005638
step: 310, loss: 0.13687779009342194
step: 320, loss: 0.10904018580913544
step: 330, loss: 0.04324378818273544
step: 340, loss: 0.08055003732442856
step: 350, loss: 0.025036336854100227
epoch 18: dev_f1=0.8259860788863109, f1=0.8009049773755657, best_f1=0.8062360801781738
step: 0, loss: 0.009023774415254593
step: 10, loss: 0.024963324889540672
step: 20, loss: 0.00023294426500797272
step: 30, loss: 0.022549601271748543
step: 40, loss: 0.04908379912376404
step: 50, loss: 0.0938979908823967
step: 60, loss: 0.14545510709285736
step: 70, loss: 0.1742400825023651
step: 80, loss: 0.1122930571436882
step: 90, loss: 0.04982655867934227
step: 100, loss: 0.19058318436145782
step: 110, loss: 0.08485481142997742
step: 120, loss: 0.02243141643702984
step: 130, loss: 0.08194280415773392
step: 140, loss: 0.024579716846346855
step: 150, loss: 0.0687825083732605
step: 160, loss: 0.012391787953674793
step: 170, loss: 0.08187452703714371
step: 180, loss: 0.04700928553938866
step: 190, loss: 3.908085636794567e-05
step: 200, loss: 0.039951350539922714
step: 210, loss: 0.0337446928024292
step: 220, loss: 0.06929051876068115
step: 230, loss: 0.11631441116333008
step: 240, loss: 0.0911727324128151
step: 250, loss: 0.024348115548491478
step: 260, loss: 0.0008031174074858427
step: 270, loss: 0.036243099719285965
step: 280, loss: 0.08330420404672623
step: 290, loss: 0.03433976694941521
step: 300, loss: 0.04784293845295906
step: 310, loss: 0.07508082687854767
step: 320, loss: 0.09374778717756271
step: 330, loss: 0.026036981493234634
step: 340, loss: 0.042743340134620667
step: 350, loss: 0.05138908699154854
epoch 19: dev_f1=0.819753086419753, f1=0.7962085308056872, best_f1=0.8062360801781738
step: 0, loss: 0.02002738229930401
step: 10, loss: 0.050226710736751556
step: 20, loss: 0.026593226939439774
step: 30, loss: 0.03333863243460655
step: 40, loss: 0.11462543159723282
step: 50, loss: 0.11421762406826019
step: 60, loss: 0.05061997100710869
step: 70, loss: 0.08799834549427032
step: 80, loss: 0.06819012016057968
step: 90, loss: 0.07010523229837418
step: 100, loss: 0.09306715428829193
step: 110, loss: 0.04453186318278313
step: 120, loss: 3.364228177815676e-05
step: 130, loss: 0.02969357743859291
step: 140, loss: 0.014260243624448776
step: 150, loss: 0.0022313310764729977
step: 160, loss: 0.09018515050411224
step: 170, loss: 0.035130422562360764
step: 180, loss: 0.06518767029047012
step: 190, loss: 0.10185205936431885
step: 200, loss: 0.02345980890095234
step: 210, loss: 0.08254649490118027
step: 220, loss: 0.10446637123823166
step: 230, loss: 0.024117203429341316
step: 240, loss: 0.06975304335355759
step: 250, loss: 0.03081393986940384
step: 260, loss: 0.09751949459314346
step: 270, loss: 0.01020453404635191
step: 280, loss: 0.03543786332011223
step: 290, loss: 0.05678633227944374
step: 300, loss: 0.08408217132091522
step: 310, loss: 0.031819261610507965
step: 320, loss: 0.11143984645605087
step: 330, loss: 0.1154296025633812
step: 340, loss: 0.04991075396537781
step: 350, loss: 0.019769420847296715
epoch 20: dev_f1=0.8203883495145631, f1=0.7934272300469484, best_f1=0.8062360801781738
