cuda
Device: cuda
step: 0, loss: 0.5910184979438782
step: 10, loss: 0.31880709528923035
step: 20, loss: 0.3869650065898895
step: 30, loss: 0.37600499391555786
step: 40, loss: 0.5059669613838196
step: 50, loss: 0.40936315059661865
step: 60, loss: 0.17288151383399963
step: 70, loss: 0.2455623894929886
step: 80, loss: 0.24310918152332306
step: 90, loss: 0.30381274223327637
step: 100, loss: 0.3102335035800934
step: 110, loss: 0.24346280097961426
step: 120, loss: 0.21679902076721191
step: 130, loss: 0.27744629979133606
step: 140, loss: 0.21707671880722046
step: 150, loss: 0.23099534213542938
step: 160, loss: 0.22874553501605988
step: 170, loss: 0.1473599076271057
step: 180, loss: 0.21658632159233093
step: 190, loss: 0.12847428023815155
step: 200, loss: 0.3079587519168854
step: 210, loss: 0.36495932936668396
step: 220, loss: 0.15403872728347778
step: 230, loss: 0.12309284508228302
step: 240, loss: 0.1962077021598816
step: 250, loss: 0.2740649878978729
step: 260, loss: 0.1363818198442459
step: 270, loss: 0.13309474289417267
step: 280, loss: 0.2594737708568573
step: 290, loss: 0.2507839500904083
step: 300, loss: 0.20926189422607422
step: 310, loss: 0.16108748316764832
step: 320, loss: 0.16957801580429077
step: 330, loss: 0.06396923959255219
step: 340, loss: 0.26232418417930603
step: 350, loss: 0.2874058485031128
epoch 1: dev_f1=0.745, f1=0.7383177570093458, best_f1=0.7383177570093458
step: 0, loss: 0.20110256969928741
step: 10, loss: 0.08953602612018585
step: 20, loss: 0.11433836072683334
step: 30, loss: 0.24634487926959991
step: 40, loss: 0.1987261176109314
step: 50, loss: 0.2002282291650772
step: 60, loss: 0.18408061563968658
step: 70, loss: 0.32952645421028137
step: 80, loss: 0.203301340341568
step: 90, loss: 0.16805031895637512
step: 100, loss: 0.050265684723854065
step: 110, loss: 0.12291701883077621
step: 120, loss: 0.21366262435913086
step: 130, loss: 0.3073767125606537
step: 140, loss: 0.2602885365486145
step: 150, loss: 0.21975284814834595
step: 160, loss: 0.1244782879948616
step: 170, loss: 0.20207065343856812
step: 180, loss: 0.17346179485321045
step: 190, loss: 0.10222558677196503
step: 200, loss: 0.22037482261657715
step: 210, loss: 0.13985887169837952
step: 220, loss: 0.2938579320907593
step: 230, loss: 0.21104180812835693
step: 240, loss: 0.07419900596141815
step: 250, loss: 0.19128191471099854
step: 260, loss: 0.09692014753818512
step: 270, loss: 0.058267343789339066
step: 280, loss: 0.1395362913608551
step: 290, loss: 0.2003946751356125
step: 300, loss: 0.17064759135246277
step: 310, loss: 0.07170139998197556
step: 320, loss: 0.26993751525878906
step: 330, loss: 0.24528513848781586
step: 340, loss: 0.4151851534843445
step: 350, loss: 0.21851308643817902
epoch 2: dev_f1=0.7972027972027972, f1=0.7733333333333332, best_f1=0.7733333333333332
step: 0, loss: 0.0984509065747261
step: 10, loss: 0.07544992119073868
step: 20, loss: 0.046491265296936035
step: 30, loss: 0.20397010445594788
step: 40, loss: 0.06994955241680145
step: 50, loss: 0.12124325335025787
step: 60, loss: 0.13953374326229095
step: 70, loss: 0.06727444380521774
step: 80, loss: 0.10068104416131973
step: 90, loss: 0.09706030040979385
step: 100, loss: 0.10828351229429245
step: 110, loss: 0.10701504349708557
step: 120, loss: 0.11197111010551453
step: 130, loss: 0.17639872431755066
step: 140, loss: 0.04504547640681267
step: 150, loss: 0.07321712374687195
step: 160, loss: 0.0912867933511734
step: 170, loss: 0.0753389224410057
step: 180, loss: 0.11695078015327454
step: 190, loss: 0.0793168917298317
step: 200, loss: 0.13867174088954926
step: 210, loss: 0.07149967551231384
step: 220, loss: 0.09061314165592194
step: 230, loss: 0.05173960700631142
step: 240, loss: 0.12126366794109344
step: 250, loss: 0.18346427381038666
step: 260, loss: 0.12682360410690308
step: 270, loss: 0.15455971658229828
step: 280, loss: 0.1376706063747406
step: 290, loss: 0.15954865515232086
step: 300, loss: 0.10396473854780197
step: 310, loss: 0.04904522746801376
step: 320, loss: 0.1298147290945053
step: 330, loss: 0.1326121836900711
step: 340, loss: 0.18452675640583038
step: 350, loss: 0.14246153831481934
epoch 3: dev_f1=0.7754137115839244, f1=0.7623318385650224, best_f1=0.7733333333333332
step: 0, loss: 0.20130224525928497
step: 10, loss: 0.011763145215809345
step: 20, loss: 0.08599178493022919
step: 30, loss: 0.11761048436164856
step: 40, loss: 0.09323142468929291
step: 50, loss: 0.07540591061115265
step: 60, loss: 0.05061190575361252
step: 70, loss: 0.03464001789689064
step: 80, loss: 0.07783076912164688
step: 90, loss: 0.1642404943704605
step: 100, loss: 0.1506980061531067
step: 110, loss: 0.04671381413936615
step: 120, loss: 0.14039014279842377
step: 130, loss: 0.027265487238764763
step: 140, loss: 0.06958077102899551
step: 150, loss: 0.07319580018520355
step: 160, loss: 0.08304834365844727
step: 170, loss: 0.11964843422174454
step: 180, loss: 0.07864116132259369
step: 190, loss: 0.04041210189461708
step: 200, loss: 0.06230604648590088
step: 210, loss: 0.07854534685611725
step: 220, loss: 0.04994991049170494
step: 230, loss: 0.12599118053913116
step: 240, loss: 0.19616730511188507
step: 250, loss: 0.12704946100711823
step: 260, loss: 0.10578750818967819
step: 270, loss: 0.10851934552192688
step: 280, loss: 0.2886058986186981
step: 290, loss: 0.08700293302536011
step: 300, loss: 0.025830071419477463
step: 310, loss: 0.0877077504992485
step: 320, loss: 0.25662004947662354
step: 330, loss: 0.1300613433122635
step: 340, loss: 0.06882884353399277
step: 350, loss: 0.1640855073928833
epoch 4: dev_f1=0.8146341463414632, f1=0.8113207547169812, best_f1=0.8113207547169812
step: 0, loss: 0.1239638552069664
step: 10, loss: 0.0636996254324913
step: 20, loss: 0.0391959585249424
step: 30, loss: 0.08054900914430618
step: 40, loss: 0.10711514949798584
step: 50, loss: 0.08934744447469711
step: 60, loss: 0.07134660333395004
step: 70, loss: 0.07901579886674881
step: 80, loss: 0.052490171045064926
step: 90, loss: 0.13387934863567352
step: 100, loss: 0.03340592980384827
step: 110, loss: 0.10150069743394852
step: 120, loss: 0.14787563681602478
step: 130, loss: 0.10488932579755783
step: 140, loss: 0.05992499366402626
step: 150, loss: 0.15781967341899872
step: 160, loss: 0.07931189239025116
step: 170, loss: 0.08377347886562347
step: 180, loss: 0.12116100639104843
step: 190, loss: 0.054510749876499176
step: 200, loss: 0.00886126235127449
step: 210, loss: 0.13575784862041473
step: 220, loss: 0.05448313429951668
step: 230, loss: 0.03201722353696823
step: 240, loss: 0.08225684612989426
step: 250, loss: 0.045474324375391006
step: 260, loss: 0.12568628787994385
step: 270, loss: 0.1995542198419571
step: 280, loss: 0.15692035853862762
step: 290, loss: 0.06167637184262276
step: 300, loss: 0.1440972238779068
step: 310, loss: 0.0873216986656189
step: 320, loss: 0.061004482209682465
step: 330, loss: 0.11342420428991318
step: 340, loss: 0.12443207949399948
step: 350, loss: 0.044812656939029694
epoch 5: dev_f1=0.8081264108352145, f1=0.787878787878788, best_f1=0.8113207547169812
step: 0, loss: 0.07974646985530853
step: 10, loss: 0.10618772357702255
step: 20, loss: 0.0961359366774559
step: 30, loss: 0.075107142329216
step: 40, loss: 0.09809191524982452
step: 50, loss: 0.05573757737874985
step: 60, loss: 0.10889504849910736
step: 70, loss: 0.15398827195167542
step: 80, loss: 0.0371859148144722
step: 90, loss: 0.05157042294740677
step: 100, loss: 0.12783221900463104
step: 110, loss: 0.10658963024616241
step: 120, loss: 0.19816023111343384
step: 130, loss: 0.04084543138742447
step: 140, loss: 0.10425584018230438
step: 150, loss: 0.122643381357193
step: 160, loss: 0.032564036548137665
step: 170, loss: 0.08749374002218246
step: 180, loss: 0.08828053623437881
step: 190, loss: 0.18293292820453644
step: 200, loss: 0.09856432676315308
step: 210, loss: 0.04427555203437805
step: 220, loss: 0.00015505109331570566
step: 230, loss: 0.10135892033576965
step: 240, loss: 0.1245850920677185
step: 250, loss: 0.06899164617061615
step: 260, loss: 0.032097239047288895
step: 270, loss: 0.20247158408164978
step: 280, loss: 0.13539692759513855
step: 290, loss: 0.04222562909126282
step: 300, loss: 0.07237447798252106
step: 310, loss: 0.10255514085292816
step: 320, loss: 0.11935236304998398
step: 330, loss: 0.03924008458852768
step: 340, loss: 0.05700576677918434
step: 350, loss: 0.10928916186094284
epoch 6: dev_f1=0.8156682027649769, f1=0.8036529680365296, best_f1=0.8036529680365296
step: 0, loss: 0.05040201544761658
step: 10, loss: 0.026841899380087852
step: 20, loss: 0.016357634216547012
step: 30, loss: 0.052169106900691986
step: 40, loss: 0.018538668751716614
step: 50, loss: 0.03151801601052284
step: 60, loss: 0.0771055519580841
step: 70, loss: 0.07475616037845612
step: 80, loss: 0.11687841266393661
step: 90, loss: 0.07151425629854202
step: 100, loss: 0.03869056701660156
step: 110, loss: 0.05933990702033043
step: 120, loss: 0.14359408617019653
step: 130, loss: 0.1463848203420639
step: 140, loss: 0.06297890841960907
step: 150, loss: 0.08456385135650635
step: 160, loss: 0.055412132292985916
step: 170, loss: 0.18637116253376007
step: 180, loss: 0.03260444104671478
step: 190, loss: 0.1681022047996521
step: 200, loss: 0.048032477498054504
step: 210, loss: 0.08345980942249298
step: 220, loss: 0.05634607374668121
step: 230, loss: 0.11630348861217499
step: 240, loss: 0.08045534044504166
step: 250, loss: 0.11085505038499832
step: 260, loss: 0.05568627640604973
step: 270, loss: 0.06390676647424698
step: 280, loss: 0.10087365657091141
step: 290, loss: 0.11289865523576736
step: 300, loss: 0.00012951812823303044
step: 310, loss: 0.11746378242969513
step: 320, loss: 0.11802743375301361
step: 330, loss: 0.12502558529376984
step: 340, loss: 0.042669959366321564
step: 350, loss: 0.05475061386823654
epoch 7: dev_f1=0.8361858190709045, f1=0.8135593220338982, best_f1=0.8135593220338982
step: 0, loss: 0.04122806712985039
step: 10, loss: 0.06444908678531647
step: 20, loss: 0.06896395981311798
step: 30, loss: 0.12286195904016495
step: 40, loss: 0.055139392614364624
step: 50, loss: 0.13207150995731354
step: 60, loss: 0.145668625831604
step: 70, loss: 0.029733572155237198
step: 80, loss: 0.14376994967460632
step: 90, loss: 0.13669852912425995
step: 100, loss: 0.045629750937223434
step: 110, loss: 0.0771133229136467
step: 120, loss: 0.13971081376075745
step: 130, loss: 0.025552203878760338
step: 140, loss: 0.08622466772794724
step: 150, loss: 0.05258941650390625
step: 160, loss: 0.1741509735584259
step: 170, loss: 0.1306854784488678
step: 180, loss: 0.04164902865886688
step: 190, loss: 0.17807748913764954
step: 200, loss: 0.09478437155485153
step: 210, loss: 0.11919280141592026
step: 220, loss: 0.14535126090049744
step: 230, loss: 0.1657763421535492
step: 240, loss: 0.04437822848558426
step: 250, loss: 0.013227098621428013
step: 260, loss: 0.026732241734862328
step: 270, loss: 0.05801389738917351
step: 280, loss: 0.0773262307047844
step: 290, loss: 0.081301748752594
step: 300, loss: 0.14624306559562683
step: 310, loss: 0.06164715811610222
step: 320, loss: 0.04799485206604004
step: 330, loss: 0.13219188153743744
step: 340, loss: 0.14045070111751556
step: 350, loss: 0.1844233125448227
epoch 8: dev_f1=0.8, f1=0.7807228915662651, best_f1=0.8135593220338982
step: 0, loss: 0.07131628692150116
step: 10, loss: 0.15515965223312378
step: 20, loss: 0.0533159114420414
step: 30, loss: 0.16098524630069733
step: 40, loss: 0.1275661587715149
step: 50, loss: 0.07420333474874496
step: 60, loss: 0.022669604048132896
step: 70, loss: 0.15939557552337646
step: 80, loss: 0.05753627419471741
step: 90, loss: 0.06267604231834412
step: 100, loss: 0.05242299288511276
step: 110, loss: 0.02995082177221775
step: 120, loss: 0.10274496674537659
step: 130, loss: 0.0827517881989479
step: 140, loss: 0.10027899593114853
step: 150, loss: 0.12437181174755096
step: 160, loss: 0.04151596128940582
step: 170, loss: 0.07552897185087204
step: 180, loss: 0.17573001980781555
step: 190, loss: 0.06962476670742035
step: 200, loss: 0.12837162613868713
step: 210, loss: 0.05924305319786072
step: 220, loss: 0.13267546892166138
step: 230, loss: 0.2721160054206848
step: 240, loss: 0.1104932650923729
step: 250, loss: 0.10341663658618927
step: 260, loss: 0.08671487122774124
step: 270, loss: 0.12040344625711441
step: 280, loss: 0.04178556427359581
step: 290, loss: 0.1171925738453865
step: 300, loss: 0.07254623621702194
step: 310, loss: 0.10135435312986374
step: 320, loss: 0.14900733530521393
step: 330, loss: 0.16714149713516235
step: 340, loss: 0.12177929282188416
step: 350, loss: 0.00020895813941024244
epoch 9: dev_f1=0.8383838383838383, f1=0.8166259168704155, best_f1=0.8166259168704155
step: 0, loss: 0.12999030947685242
step: 10, loss: 0.028960561379790306
step: 20, loss: 0.025283129885792732
step: 30, loss: 0.10124822705984116
step: 40, loss: 0.08173792064189911
step: 50, loss: 0.035796910524368286
step: 60, loss: 0.0436423160135746
step: 70, loss: 0.07742956280708313
step: 80, loss: 0.08172420412302017
step: 90, loss: 0.08950594812631607
step: 100, loss: 0.03371542692184448
step: 110, loss: 0.09217076003551483
step: 120, loss: 0.10233565419912338
step: 130, loss: 0.07088493555784225
step: 140, loss: 0.017244724556803703
step: 150, loss: 0.14100104570388794
step: 160, loss: 0.005644978955388069
step: 170, loss: 0.11449656635522842
step: 180, loss: 0.09573576599359512
step: 190, loss: 0.08634179085493088
step: 200, loss: 0.10834299027919769
step: 210, loss: 0.13352777063846588
step: 220, loss: 0.09407123178243637
step: 230, loss: 0.028724685311317444
step: 240, loss: 0.09288765490055084
step: 250, loss: 0.098190076649189
step: 260, loss: 0.06544723361730576
step: 270, loss: 0.032820168882608414
step: 280, loss: 0.08915875852108002
step: 290, loss: 0.05952183157205582
step: 300, loss: 0.10005342960357666
step: 310, loss: 0.02459103614091873
step: 320, loss: 0.14320819079875946
step: 330, loss: 0.10784205049276352
step: 340, loss: 0.12088651955127716
step: 350, loss: 0.21411094069480896
epoch 10: dev_f1=0.8368421052631579, f1=0.7959183673469389, best_f1=0.8166259168704155
step: 0, loss: 0.0369626022875309
step: 10, loss: 0.11109849810600281
step: 20, loss: 0.127125084400177
step: 30, loss: 0.04216717556118965
step: 40, loss: 0.12789875268936157
step: 50, loss: 0.10966004431247711
step: 60, loss: 0.1847299188375473
step: 70, loss: 0.06198000907897949
step: 80, loss: 0.09052152931690216
step: 90, loss: 0.04085952043533325
step: 100, loss: 0.06391112506389618
step: 110, loss: 0.055973973125219345
step: 120, loss: 0.040457408875226974
step: 130, loss: 0.09927722811698914
step: 140, loss: 0.0506490021944046
step: 150, loss: 0.02461647428572178
step: 160, loss: 0.054181668907403946
step: 170, loss: 0.12278883159160614
step: 180, loss: 0.01807684451341629
step: 190, loss: 0.19949473440647125
step: 200, loss: 0.12357795238494873
step: 210, loss: 0.10308117419481277
step: 220, loss: 0.249991774559021
step: 230, loss: 0.04183240979909897
step: 240, loss: 0.03425229713320732
step: 250, loss: 0.0291582103818655
step: 260, loss: 0.08735112100839615
step: 270, loss: 0.11627548187971115
step: 280, loss: 0.053192414343357086
step: 290, loss: 0.06572465598583221
step: 300, loss: 0.19735616445541382
step: 310, loss: 0.03687499463558197
step: 320, loss: 0.14627915620803833
step: 330, loss: 0.06688534468412399
step: 340, loss: 0.13335387408733368
step: 350, loss: 0.1215779259800911
epoch 11: dev_f1=0.839622641509434, f1=0.8054298642533937, best_f1=0.8054298642533937
step: 0, loss: 0.06584304571151733
step: 10, loss: 0.07003101706504822
step: 20, loss: 0.1262994408607483
step: 30, loss: 0.046036843210458755
step: 40, loss: 0.0760190412402153
step: 50, loss: 0.017673371359705925
step: 60, loss: 0.03983496129512787
step: 70, loss: 0.0752624049782753
step: 80, loss: 0.0985659509897232
step: 90, loss: 0.009656056761741638
step: 100, loss: 0.0867898017168045
step: 110, loss: 0.1048334538936615
step: 120, loss: 0.02815157175064087
step: 130, loss: 0.031284149736166
step: 140, loss: 0.08730524033308029
step: 150, loss: 0.015239803120493889
step: 160, loss: 0.04259661212563515
step: 170, loss: 0.07021975517272949
step: 180, loss: 0.10498027503490448
step: 190, loss: 7.030030974419788e-05
step: 200, loss: 0.09714271128177643
step: 210, loss: 0.14943648874759674
step: 220, loss: 0.15968868136405945
step: 230, loss: 0.16529889404773712
step: 240, loss: 0.1182117909193039
step: 250, loss: 0.10925514996051788
step: 260, loss: 0.09226386994123459
step: 270, loss: 0.08452506363391876
step: 280, loss: 0.035842202603816986
step: 290, loss: 0.058641042560338974
step: 300, loss: 0.04226164147257805
step: 310, loss: 0.04139457643032074
step: 320, loss: 0.09586749970912933
step: 330, loss: 0.1595650017261505
step: 340, loss: 0.044396013021469116
step: 350, loss: 0.025920189917087555
epoch 12: dev_f1=0.8129675810473815, f1=0.7794117647058824, best_f1=0.8054298642533937
step: 0, loss: 0.06890292465686798
step: 10, loss: 0.08847276121377945
step: 20, loss: 0.06239638477563858
step: 30, loss: 0.067562036216259
step: 40, loss: 0.12339422851800919
step: 50, loss: 0.019152110442519188
step: 60, loss: 0.018665045499801636
step: 70, loss: 0.03166843205690384
step: 80, loss: 0.10913809388875961
step: 90, loss: 0.11423379182815552
step: 100, loss: 0.026978742331266403
step: 110, loss: 0.10672406852245331
step: 120, loss: 0.034001510590314865
step: 130, loss: 0.09110315144062042
step: 140, loss: 0.018868543207645416
step: 150, loss: 0.1261489987373352
step: 160, loss: 0.11666202545166016
step: 170, loss: 0.008558969013392925
step: 180, loss: 0.11825129389762878
step: 190, loss: 0.0658905953168869
step: 200, loss: 0.12571454048156738
step: 210, loss: 0.08881498128175735
step: 220, loss: 0.05544314533472061
step: 230, loss: 0.07620567083358765
step: 240, loss: 0.07999724894762039
step: 250, loss: 0.0898432582616806
step: 260, loss: 0.09412970393896103
step: 270, loss: 0.04648158699274063
step: 280, loss: 0.04295115917921066
step: 290, loss: 0.05017172172665596
step: 300, loss: 0.05011364072561264
step: 310, loss: 0.051043182611465454
step: 320, loss: 0.029675088822841644
step: 330, loss: 0.10752575844526291
step: 340, loss: 0.04008229821920395
step: 350, loss: 0.03776963800191879
epoch 13: dev_f1=0.8066825775656326, f1=0.8064516129032259, best_f1=0.8054298642533937
step: 0, loss: 0.12010864913463593
step: 10, loss: 0.017218323424458504
step: 20, loss: 0.026858124881982803
step: 30, loss: 0.050914425402879715
step: 40, loss: 0.0323396734893322
step: 50, loss: 0.06841954588890076
step: 60, loss: 0.008542781695723534
step: 70, loss: 0.03611093759536743
step: 80, loss: 0.05880890041589737
step: 90, loss: 0.01801125518977642
step: 100, loss: 0.056243281811475754
step: 110, loss: 0.08677826076745987
step: 120, loss: 0.05835294723510742
step: 130, loss: 0.11577584594488144
step: 140, loss: 0.08150673657655716
step: 150, loss: 0.011150915175676346
step: 160, loss: 0.004157646559178829
step: 170, loss: 0.10983868688344955
step: 180, loss: 0.0316975936293602
step: 190, loss: 0.0967637449502945
step: 200, loss: 0.12104681879281998
step: 210, loss: 0.06633458286523819
step: 220, loss: 0.1513492614030838
step: 230, loss: 0.033047422766685486
step: 240, loss: 0.04234981909394264
step: 250, loss: 0.0007901030476205051
step: 260, loss: 0.02820712700486183
step: 270, loss: 0.09541184455156326
step: 280, loss: 0.0790349543094635
step: 290, loss: 0.05887595936655998
step: 300, loss: 0.005828686058521271
step: 310, loss: 0.04118438437581062
step: 320, loss: 0.14050674438476562
step: 330, loss: 0.06945662945508957
step: 340, loss: 0.05083578824996948
step: 350, loss: 0.053886741399765015
epoch 14: dev_f1=0.8337595907928389, f1=0.8048780487804877, best_f1=0.8054298642533937
step: 0, loss: 0.05876009538769722
step: 10, loss: 0.06092853471636772
step: 20, loss: 0.03903289884328842
step: 30, loss: 0.08351507782936096
step: 40, loss: 0.018278073519468307
step: 50, loss: 0.13315533101558685
step: 60, loss: 0.04527370631694794
step: 70, loss: 0.039484478533267975
step: 80, loss: 0.017999591305851936
step: 90, loss: 0.09862232208251953
step: 100, loss: 0.06656642258167267
step: 110, loss: 0.08585662394762039
step: 120, loss: 0.126053586602211
step: 130, loss: 0.13770906627178192
step: 140, loss: 0.06305908411741257
step: 150, loss: 0.10235872119665146
step: 160, loss: 0.0068021914921700954
step: 170, loss: 0.062217939645051956
step: 180, loss: 0.06577416509389877
step: 190, loss: 0.04967573657631874
step: 200, loss: 0.025421034544706345
step: 210, loss: 0.102348692715168
step: 220, loss: 0.0958966463804245
step: 230, loss: 0.044709548354148865
step: 240, loss: 0.08994828164577484
step: 250, loss: 0.03737691044807434
step: 260, loss: 0.07722430676221848
step: 270, loss: 0.042981959879398346
step: 280, loss: 0.11718348413705826
step: 290, loss: 0.08996284008026123
step: 300, loss: 0.0925166979432106
step: 310, loss: 0.05309486761689186
step: 320, loss: 0.03992987796664238
step: 330, loss: 0.049360521137714386
step: 340, loss: 0.05885026976466179
step: 350, loss: 0.030888430774211884
epoch 15: dev_f1=0.8382352941176471, f1=0.7962085308056872, best_f1=0.8054298642533937
step: 0, loss: 0.08455107361078262
step: 10, loss: 0.054629530757665634
step: 20, loss: 0.0543961226940155
step: 30, loss: 0.15329718589782715
step: 40, loss: 0.04588417336344719
step: 50, loss: 0.07853297889232635
step: 60, loss: 0.04811776056885719
step: 70, loss: 0.05694819241762161
step: 80, loss: 0.12672647833824158
step: 90, loss: 0.05883317068219185
step: 100, loss: 0.02859954722225666
step: 110, loss: 0.05854541435837746
step: 120, loss: 0.08384370803833008
step: 130, loss: 0.08212386071681976
step: 140, loss: 0.09605081379413605
step: 150, loss: 0.07098810374736786
step: 160, loss: 0.0256513524800539
step: 170, loss: 0.01701008528470993
step: 180, loss: 0.05863752216100693
step: 190, loss: 0.03196210786700249
step: 200, loss: 0.05092732980847359
step: 210, loss: 0.02022687718272209
step: 220, loss: 0.012839983217418194
step: 230, loss: 0.11629190295934677
step: 240, loss: 0.06932209432125092
step: 250, loss: 0.10469622164964676
step: 260, loss: 0.022072602063417435
step: 270, loss: 0.0978580042719841
step: 280, loss: 0.03618153929710388
step: 290, loss: 0.07736659049987793
step: 300, loss: 0.08876105397939682
step: 310, loss: 0.06768740713596344
step: 320, loss: 0.05819731578230858
step: 330, loss: 0.16526667773723602
step: 340, loss: 0.05682182312011719
step: 350, loss: 0.008940336294472218
epoch 16: dev_f1=0.8390243902439024, f1=0.7944572748267898, best_f1=0.8054298642533937
step: 0, loss: 0.08520714938640594
step: 10, loss: 0.09436332434415817
step: 20, loss: 0.06320906430482864
step: 30, loss: 0.06735455244779587
step: 40, loss: 0.04674622416496277
step: 50, loss: 0.04374302923679352
step: 60, loss: 0.028598064556717873
step: 70, loss: 0.12628203630447388
step: 80, loss: 0.020020024850964546
step: 90, loss: 0.007402337621897459
step: 100, loss: 0.04927949979901314
step: 110, loss: 0.07740120589733124
step: 120, loss: 0.06127231940627098
step: 130, loss: 0.029807446524500847
step: 140, loss: 0.11572675406932831
step: 150, loss: 0.20846699178218842
step: 160, loss: 0.032573018223047256
step: 170, loss: 2.3528038582298905e-05
step: 180, loss: 0.06759963929653168
step: 190, loss: 0.1450846642255783
step: 200, loss: 0.09244749695062637
step: 210, loss: 0.09124596416950226
step: 220, loss: 0.029876895248889923
step: 230, loss: 0.10581934452056885
step: 240, loss: 0.15621845424175262
step: 250, loss: 0.15828216075897217
step: 260, loss: 0.08875288814306259
step: 270, loss: 3.1210809538606554e-05
step: 280, loss: 0.03262723609805107
step: 290, loss: 0.12752091884613037
step: 300, loss: 0.0971701517701149
step: 310, loss: 0.22275297343730927
step: 320, loss: 0.019901160150766373
step: 330, loss: 0.08021280169487
step: 340, loss: 0.0545954592525959
step: 350, loss: 0.04929053783416748
epoch 17: dev_f1=0.8431372549019608, f1=0.7785547785547785, best_f1=0.7785547785547785
step: 0, loss: 9.90316693787463e-05
step: 10, loss: 0.06642104685306549
step: 20, loss: 0.043084919452667236
step: 30, loss: 0.07589095830917358
step: 40, loss: 0.03769278526306152
step: 50, loss: 0.09512795507907867
step: 60, loss: 0.0575643889605999
step: 70, loss: 0.07242331653833389
step: 80, loss: 0.03425660356879234
step: 90, loss: 0.0509687215089798
step: 100, loss: 0.024035992100834846
step: 110, loss: 0.04835423827171326
step: 120, loss: 0.02362150512635708
step: 130, loss: 0.05766894295811653
step: 140, loss: 0.028777457773685455
step: 150, loss: 0.11510708928108215
step: 160, loss: 0.034508176147937775
step: 170, loss: 0.04407961666584015
step: 180, loss: 0.05034659802913666
step: 190, loss: 0.139373779296875
step: 200, loss: 0.08568470925092697
step: 210, loss: 0.07377427816390991
step: 220, loss: 0.1120627298951149
step: 230, loss: 0.16010858118534088
step: 240, loss: 0.12134276330471039
step: 250, loss: 0.031035076826810837
step: 260, loss: 0.031016597524285316
step: 270, loss: 0.10741735249757767
step: 280, loss: 0.04579928144812584
step: 290, loss: 0.0541994646191597
step: 300, loss: 0.07709119468927383
step: 310, loss: 0.11402226239442825
step: 320, loss: 0.053584273904561996
step: 330, loss: 0.07612058520317078
step: 340, loss: 0.036714036017656326
step: 350, loss: 0.039378222078084946
epoch 18: dev_f1=0.8361858190709045, f1=0.7868852459016392, best_f1=0.7785547785547785
step: 0, loss: 0.05868775397539139
step: 10, loss: 0.09637974947690964
step: 20, loss: 0.05933881178498268
step: 30, loss: 0.079048752784729
step: 40, loss: 0.06075829267501831
step: 50, loss: 0.13758879899978638
step: 60, loss: 0.08134312927722931
step: 70, loss: 0.04468848556280136
step: 80, loss: 0.054733552038669586
step: 90, loss: 0.07277573645114899
step: 100, loss: 0.049824297428131104
step: 110, loss: 6.635654426645488e-05
step: 120, loss: 0.026788469403982162
step: 130, loss: 1.5727935533504933e-05
step: 140, loss: 0.07921978831291199
step: 150, loss: 0.05106068402528763
step: 160, loss: 0.04962383210659027
step: 170, loss: 0.08530248701572418
step: 180, loss: 0.0545898899435997
step: 190, loss: 0.049195557832717896
step: 200, loss: 0.06471335887908936
step: 210, loss: 0.0977933332324028
step: 220, loss: 0.016605136916041374
step: 230, loss: 0.025763697922229767
step: 240, loss: 0.018669702112674713
step: 250, loss: 0.014133264310657978
step: 260, loss: 0.023866580799221992
step: 270, loss: 0.07080499827861786
step: 280, loss: 0.053038861602544785
step: 290, loss: 0.148244708776474
step: 300, loss: 0.09905312210321426
step: 310, loss: 0.03380908817052841
step: 320, loss: 0.08101260662078857
step: 330, loss: 0.049847476184368134
step: 340, loss: 0.031959448009729385
step: 350, loss: 0.09370346367359161
epoch 19: dev_f1=0.8426150121065376, f1=0.7793427230046948, best_f1=0.7785547785547785
step: 0, loss: 0.04412649944424629
step: 10, loss: 0.053882986307144165
step: 20, loss: 0.06318433582782745
step: 30, loss: 0.021901696920394897
step: 40, loss: 0.015929898247122765
step: 50, loss: 0.049123216420412064
step: 60, loss: 1.4535963600792456e-05
step: 70, loss: 0.083823062479496
step: 80, loss: 0.03602388873696327
step: 90, loss: 0.14248314499855042
step: 100, loss: 0.22470687329769135
step: 110, loss: 0.03483632951974869
step: 120, loss: 0.0350579097867012
step: 130, loss: 0.051558542996644974
step: 140, loss: 0.015682611614465714
step: 150, loss: 0.06699459254741669
step: 160, loss: 0.1794511079788208
step: 170, loss: 0.0001939952198881656
step: 180, loss: 0.07365494966506958
step: 190, loss: 0.04068923369050026
step: 200, loss: 0.04165683314204216
step: 210, loss: 0.07433158159255981
step: 220, loss: 0.10248397290706635
step: 230, loss: 0.04681205004453659
step: 240, loss: 0.056454602628946304
step: 250, loss: 0.09397874772548676
step: 260, loss: 0.0013036101590842009
step: 270, loss: 0.0850343406200409
step: 280, loss: 0.02987915836274624
step: 290, loss: 0.07546930760145187
step: 300, loss: 0.03809495270252228
step: 310, loss: 0.053534988313913345
step: 320, loss: 0.11339917778968811
step: 330, loss: 0.0589558444917202
step: 340, loss: 0.07605161517858505
step: 350, loss: 0.0868588462471962
epoch 20: dev_f1=0.8349514563106796, f1=0.7840375586854459, best_f1=0.7785547785547785
