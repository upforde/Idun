cuda
Device: cuda
step: 0, loss: 0.6924103498458862
step: 10, loss: 0.45392751693725586
step: 20, loss: 0.316403865814209
step: 30, loss: 0.30185726284980774
step: 40, loss: 0.14508989453315735
step: 50, loss: 0.25646209716796875
step: 60, loss: 0.24785493314266205
step: 70, loss: 0.46241241693496704
step: 80, loss: 0.13437464833259583
step: 90, loss: 0.2569657564163208
step: 100, loss: 0.0786983072757721
step: 110, loss: 0.24966196715831757
step: 120, loss: 0.13319197297096252
step: 130, loss: 0.3470059335231781
step: 140, loss: 0.15441268682479858
step: 150, loss: 0.3643527030944824
step: 160, loss: 0.17256508767604828
step: 170, loss: 0.33372533321380615
step: 180, loss: 0.23764261603355408
step: 190, loss: 0.30107179284095764
step: 200, loss: 0.34883376955986023
step: 210, loss: 0.1613008975982666
step: 220, loss: 0.29084575176239014
step: 230, loss: 0.18452046811580658
step: 240, loss: 0.16475588083267212
step: 250, loss: 0.18890444934368134
step: 260, loss: 0.20413252711296082
step: 270, loss: 0.295861154794693
step: 280, loss: 0.23439034819602966
step: 290, loss: 0.1547039896249771
step: 300, loss: 0.23739930987358093
step: 310, loss: 0.16743327677249908
step: 320, loss: 0.36884036660194397
step: 330, loss: 0.15340115129947662
step: 340, loss: 0.09317561239004135
step: 350, loss: 0.16317562758922577
epoch 1: dev_f1=0.6910569105691057, f1=0.6783625730994153, best_f1=0.6783625730994153
step: 0, loss: 0.19842562079429626
step: 10, loss: 0.04218674823641777
step: 20, loss: 0.17874348163604736
step: 30, loss: 0.22399011254310608
step: 40, loss: 0.0994756892323494
step: 50, loss: 0.20918457210063934
step: 60, loss: 0.12434636801481247
step: 70, loss: 0.19818377494812012
step: 80, loss: 0.1471189707517624
step: 90, loss: 0.07971601188182831
step: 100, loss: 0.08710820227861404
step: 110, loss: 0.07160092890262604
step: 120, loss: 0.06382983177900314
step: 130, loss: 0.13438290357589722
step: 140, loss: 0.05212783068418503
step: 150, loss: 0.07982760667800903
step: 160, loss: 0.19020935893058777
step: 170, loss: 0.14397293329238892
step: 180, loss: 0.0962824821472168
step: 190, loss: 0.13396437466144562
step: 200, loss: 0.246315598487854
step: 210, loss: 0.070591501891613
step: 220, loss: 0.12775544822216034
step: 230, loss: 0.23960742354393005
step: 240, loss: 0.16973134875297546
step: 250, loss: 0.29091012477874756
step: 260, loss: 0.1818392276763916
step: 270, loss: 0.13475573062896729
step: 280, loss: 0.1861800253391266
step: 290, loss: 0.18013471364974976
step: 300, loss: 0.13861271739006042
step: 310, loss: 0.09969203174114227
step: 320, loss: 0.19700713455677032
step: 330, loss: 0.033294156193733215
step: 340, loss: 0.1832726150751114
step: 350, loss: 0.11020339280366898
epoch 2: dev_f1=0.774617067833698, f1=0.7473460721868365, best_f1=0.7473460721868365
step: 0, loss: 0.32714077830314636
step: 10, loss: 0.12446855753660202
step: 20, loss: 0.038454487919807434
step: 30, loss: 0.12091608345508575
step: 40, loss: 0.1300175040960312
step: 50, loss: 0.09723224490880966
step: 60, loss: 0.07950644940137863
step: 70, loss: 0.036877479404211044
step: 80, loss: 0.08809614926576614
step: 90, loss: 0.0006629868876188993
step: 100, loss: 0.0567576065659523
step: 110, loss: 0.026624156162142754
step: 120, loss: 0.07656663656234741
step: 130, loss: 0.09253629297018051
step: 140, loss: 0.14921070635318756
step: 150, loss: 0.1081961840391159
step: 160, loss: 0.13912786543369293
step: 170, loss: 0.04322460666298866
step: 180, loss: 0.11380818486213684
step: 190, loss: 0.05871756002306938
step: 200, loss: 0.12103340029716492
step: 210, loss: 0.10019177198410034
step: 220, loss: 0.09147792309522629
step: 230, loss: 0.25099727511405945
step: 240, loss: 0.14610856771469116
step: 250, loss: 0.05804590508341789
step: 260, loss: 0.07676738500595093
step: 270, loss: 0.13110961019992828
step: 280, loss: 0.06489408016204834
step: 290, loss: 0.07447613775730133
step: 300, loss: 0.13495081663131714
step: 310, loss: 0.05564261972904205
step: 320, loss: 0.044202812016010284
step: 330, loss: 0.16655422747135162
step: 340, loss: 0.027234479784965515
step: 350, loss: 0.05447173863649368
epoch 3: dev_f1=0.7679671457905545, f1=0.7591836734693878, best_f1=0.7473460721868365
step: 0, loss: 0.12259314954280853
step: 10, loss: 0.06839695572853088
step: 20, loss: 0.08196431398391724
step: 30, loss: 0.034429050981998444
step: 40, loss: 0.036343060433864594
step: 50, loss: 0.07007443904876709
step: 60, loss: 0.14508987963199615
step: 70, loss: 0.16731862723827362
step: 80, loss: 0.097225621342659
step: 90, loss: 0.09945119172334671
step: 100, loss: 0.06399636715650558
step: 110, loss: 0.0021999701857566833
step: 120, loss: 0.13302534818649292
step: 130, loss: 0.0858335942029953
step: 140, loss: 0.18507370352745056
step: 150, loss: 0.11563940346240997
step: 160, loss: 0.030987247824668884
step: 170, loss: 0.09052705019712448
step: 180, loss: 0.09812804311513901
step: 190, loss: 0.15522976219654083
step: 200, loss: 0.06169453263282776
step: 210, loss: 0.1018589437007904
step: 220, loss: 0.22050343453884125
step: 230, loss: 0.14258673787117004
step: 240, loss: 0.02351803332567215
step: 250, loss: 0.10662692785263062
step: 260, loss: 0.25022026896476746
step: 270, loss: 0.13646137714385986
step: 280, loss: 0.10212558507919312
step: 290, loss: 0.10972427576780319
step: 300, loss: 0.1199694350361824
step: 310, loss: 0.16319330036640167
step: 320, loss: 0.0656236782670021
step: 330, loss: 0.0449085459113121
step: 340, loss: 0.10339681804180145
step: 350, loss: 0.10446309298276901
epoch 4: dev_f1=0.7777777777777778, f1=0.767816091954023, best_f1=0.767816091954023
step: 0, loss: 0.05217977985739708
step: 10, loss: 0.14432726800441742
step: 20, loss: 0.07158706337213516
step: 30, loss: 0.07138732075691223
step: 40, loss: 0.05178353562951088
step: 50, loss: 0.11500803381204605
step: 60, loss: 0.12988701462745667
step: 70, loss: 0.04207591712474823
step: 80, loss: 0.1207260936498642
step: 90, loss: 0.028507906943559647
step: 100, loss: 0.08111711591482162
step: 110, loss: 0.14801213145256042
step: 120, loss: 0.07429955899715424
step: 130, loss: 0.1570783108472824
step: 140, loss: 0.03676292300224304
step: 150, loss: 0.07328401505947113
step: 160, loss: 0.06125775724649429
step: 170, loss: 0.15310372412204742
step: 180, loss: 0.2241051346063614
step: 190, loss: 0.05176527053117752
step: 200, loss: 0.0657336413860321
step: 210, loss: 0.03924079239368439
step: 220, loss: 0.09029021859169006
step: 230, loss: 0.11103217303752899
step: 240, loss: 0.07566630095243454
step: 250, loss: 0.08849768340587616
step: 260, loss: 0.043583501130342484
step: 270, loss: 0.09534528851509094
step: 280, loss: 0.1167554259300232
step: 290, loss: 0.07388141006231308
step: 300, loss: 0.02834758162498474
step: 310, loss: 0.07272919267416
step: 320, loss: 0.08176886290311813
step: 330, loss: 0.118175208568573
step: 340, loss: 0.10933183133602142
step: 350, loss: 0.08664251118898392
epoch 5: dev_f1=0.8259860788863109, f1=0.7899543378995434, best_f1=0.7899543378995434
step: 0, loss: 0.15432648360729218
step: 10, loss: 0.05730028823018074
step: 20, loss: 0.11746834963560104
step: 30, loss: 0.10827955603599548
step: 40, loss: 0.06403975188732147
step: 50, loss: 0.07604922354221344
step: 60, loss: 0.14264613389968872
step: 70, loss: 0.13405215740203857
step: 80, loss: 0.05339527130126953
step: 90, loss: 0.046246692538261414
step: 100, loss: 0.0716293528676033
step: 110, loss: 0.04074856638908386
step: 120, loss: 0.10344046354293823
step: 130, loss: 0.03866495564579964
step: 140, loss: 0.04512590914964676
step: 150, loss: 0.0855875089764595
step: 160, loss: 0.06611822545528412
step: 170, loss: 0.1261225789785385
step: 180, loss: 0.020897911861538887
step: 190, loss: 0.07910726964473724
step: 200, loss: 0.18574275076389313
step: 210, loss: 0.22185000777244568
step: 220, loss: 0.1249178946018219
step: 230, loss: 0.0914454460144043
step: 240, loss: 0.12431232631206512
step: 250, loss: 0.049530696123838425
step: 260, loss: 0.0551716648042202
step: 270, loss: 0.173950657248497
step: 280, loss: 0.0648631602525711
step: 290, loss: 0.15603770315647125
step: 300, loss: 0.04727308824658394
step: 310, loss: 0.11333083361387253
step: 320, loss: 0.01821286603808403
step: 330, loss: 0.08404221385717392
step: 340, loss: 0.07089730352163315
step: 350, loss: 0.15725436806678772
epoch 6: dev_f1=0.8306997742663658, f1=0.8106904231625837, best_f1=0.8106904231625837
step: 0, loss: 0.04978848248720169
step: 10, loss: 0.031009163707494736
step: 20, loss: 0.04809700697660446
step: 30, loss: 0.12896400690078735
step: 40, loss: 0.053047485649585724
step: 50, loss: 0.14829984307289124
step: 60, loss: 0.13723376393318176
step: 70, loss: 0.1533137708902359
step: 80, loss: 0.15753886103630066
step: 90, loss: 0.12240317463874817
step: 100, loss: 0.08595458418130875
step: 110, loss: 0.05064886808395386
step: 120, loss: 0.09160397946834564
step: 130, loss: 0.07758428901433945
step: 140, loss: 0.06101197376847267
step: 150, loss: 0.188314288854599
step: 160, loss: 0.11134345829486847
step: 170, loss: 0.0935705229640007
step: 180, loss: 0.08362282812595367
step: 190, loss: 0.10866731405258179
step: 200, loss: 0.11441521346569061
step: 210, loss: 0.05986802652478218
step: 220, loss: 0.25161296129226685
step: 230, loss: 0.05643672123551369
step: 240, loss: 0.1165575161576271
step: 250, loss: 0.11719869822263718
step: 260, loss: 0.006706083193421364
step: 270, loss: 0.04290935769677162
step: 280, loss: 0.17954790592193604
step: 290, loss: 0.015167642384767532
step: 300, loss: 0.03603890538215637
step: 310, loss: 0.059193890541791916
step: 320, loss: 0.024606164544820786
step: 330, loss: 0.10034720599651337
step: 340, loss: 0.11891636997461319
step: 350, loss: 0.04542503505945206
epoch 7: dev_f1=0.8290598290598291, f1=0.7983367983367984, best_f1=0.8106904231625837
step: 0, loss: 0.019086742773652077
step: 10, loss: 0.13448190689086914
step: 20, loss: 0.11314686387777328
step: 30, loss: 0.08449912071228027
step: 40, loss: 0.07561054080724716
step: 50, loss: 0.10996455699205399
step: 60, loss: 0.0699378103017807
step: 70, loss: 0.07438036054372787
step: 80, loss: 0.021170303225517273
step: 90, loss: 0.11349663138389587
step: 100, loss: 0.123893603682518
step: 110, loss: 0.09567994624376297
step: 120, loss: 0.10981880873441696
step: 130, loss: 0.15859194099903107
step: 140, loss: 0.137703537940979
step: 150, loss: 0.08514652401208878
step: 160, loss: 0.07642711699008942
step: 170, loss: 0.05024087056517601
step: 180, loss: 0.03624115511775017
step: 190, loss: 0.04968331754207611
step: 200, loss: 0.047566723078489304
step: 210, loss: 0.05461461842060089
step: 220, loss: 0.09176363795995712
step: 230, loss: 0.1073206290602684
step: 240, loss: 0.1407693773508072
step: 250, loss: 0.056439660489559174
step: 260, loss: 0.04842855781316757
step: 270, loss: 0.04934079572558403
step: 280, loss: 0.024768950417637825
step: 290, loss: 0.19485607743263245
step: 300, loss: 0.10504592210054398
step: 310, loss: 0.1029454842209816
step: 320, loss: 0.08337879180908203
step: 330, loss: 0.06477571278810501
step: 340, loss: 0.06361259520053864
step: 350, loss: 0.051250189542770386
epoch 8: dev_f1=0.802721088435374, f1=0.8071748878923766, best_f1=0.8106904231625837
step: 0, loss: 0.14195889234542847
step: 10, loss: 0.02402307279407978
step: 20, loss: 0.024871276691555977
step: 30, loss: 0.22911149263381958
step: 40, loss: 0.037317823618650436
step: 50, loss: 0.037836797535419464
step: 60, loss: 0.05840582400560379
step: 70, loss: 0.05453068017959595
step: 80, loss: 0.07004406303167343
step: 90, loss: 0.07927169650793076
step: 100, loss: 0.1047315001487732
step: 110, loss: 0.08282624930143356
step: 120, loss: 0.010729518719017506
step: 130, loss: 0.057656094431877136
step: 140, loss: 0.2657640874385834
step: 150, loss: 0.08150895684957504
step: 160, loss: 0.08193262666463852
step: 170, loss: 0.0522976778447628
step: 180, loss: 0.04196769371628761
step: 190, loss: 0.11306072026491165
step: 200, loss: 0.10232105851173401
step: 210, loss: 0.15222935378551483
step: 220, loss: 7.079496572259814e-05
step: 230, loss: 0.08950893580913544
step: 240, loss: 0.06286923587322235
step: 250, loss: 0.061438824981451035
step: 260, loss: 0.08630241453647614
step: 270, loss: 0.07255486398935318
step: 280, loss: 0.056716762483119965
step: 290, loss: 0.05412297323346138
step: 300, loss: 0.1305193305015564
step: 310, loss: 0.08969155699014664
step: 320, loss: 0.07302936911582947
step: 330, loss: 0.031169362366199493
step: 340, loss: 0.03329465165734291
step: 350, loss: 0.05517175421118736
epoch 9: dev_f1=0.8253968253968255, f1=0.8, best_f1=0.8106904231625837
step: 0, loss: 0.13634108006954193
step: 10, loss: 0.06431402266025543
step: 20, loss: 0.08788792788982391
step: 30, loss: 0.12215572595596313
step: 40, loss: 0.0008270693942904472
step: 50, loss: 0.06588980555534363
step: 60, loss: 0.04553396254777908
step: 70, loss: 0.059432730078697205
step: 80, loss: 0.1129707619547844
step: 90, loss: 0.06392403692007065
step: 100, loss: 0.10678412765264511
step: 110, loss: 0.033760394901037216
step: 120, loss: 0.023021239787340164
step: 130, loss: 0.12838207185268402
step: 140, loss: 0.13360726833343506
step: 150, loss: 0.03343571722507477
step: 160, loss: 0.12156353145837784
step: 170, loss: 0.07334784418344498
step: 180, loss: 0.1525871604681015
step: 190, loss: 0.06122949346899986
step: 200, loss: 0.09434430301189423
step: 210, loss: 0.07566897571086884
step: 220, loss: 0.0408528707921505
step: 230, loss: 0.11666130274534225
step: 240, loss: 0.1664961725473404
step: 250, loss: 0.062218327075242996
step: 260, loss: 0.08662772923707962
step: 270, loss: 0.03865484520792961
step: 280, loss: 0.0540618970990181
step: 290, loss: 0.04158338904380798
step: 300, loss: 0.0745057687163353
step: 310, loss: 0.11218705028295517
step: 320, loss: 0.06072540953755379
step: 330, loss: 0.07205164432525635
step: 340, loss: 0.06588174402713776
step: 350, loss: 0.1027224138379097
epoch 10: dev_f1=0.8238213399503721, f1=0.8095238095238095, best_f1=0.8106904231625837
step: 0, loss: 0.12109623849391937
step: 10, loss: 0.06384139508008957
step: 20, loss: 0.0006037955172359943
step: 30, loss: 0.17759205400943756
step: 40, loss: 0.08265374600887299
step: 50, loss: 0.06041203811764717
step: 60, loss: 0.1409786492586136
step: 70, loss: 0.062781922519207
step: 80, loss: 0.2626960277557373
step: 90, loss: 0.04358278587460518
step: 100, loss: 0.09324617683887482
step: 110, loss: 0.05887920409440994
step: 120, loss: 0.04386638477444649
step: 130, loss: 0.17060960829257965
step: 140, loss: 0.05807369947433472
step: 150, loss: 0.047264229506254196
step: 160, loss: 0.03172461315989494
step: 170, loss: 0.06351155042648315
step: 180, loss: 0.05627061426639557
step: 190, loss: 0.11026756465435028
step: 200, loss: 0.08393750339746475
step: 210, loss: 0.02316385693848133
step: 220, loss: 0.06425543874502182
step: 230, loss: 0.10557524859905243
step: 240, loss: 0.12236588448286057
step: 250, loss: 0.02991246059536934
step: 260, loss: 0.037441935390233994
step: 270, loss: 0.1356886476278305
step: 280, loss: 0.07657770067453384
step: 290, loss: 0.0393681600689888
step: 300, loss: 0.00024562329053878784
step: 310, loss: 0.11936232447624207
step: 320, loss: 0.0007699606940150261
step: 330, loss: 0.10716317594051361
step: 340, loss: 0.09256677329540253
step: 350, loss: 0.06685541570186615
epoch 11: dev_f1=0.8303797468354431, f1=0.8232445520581113, best_f1=0.8106904231625837
step: 0, loss: 0.0677209421992302
step: 10, loss: 0.06386961787939072
step: 20, loss: 0.15389861166477203
step: 30, loss: 0.08852269500494003
step: 40, loss: 0.0684332400560379
step: 50, loss: 0.026558037847280502
step: 60, loss: 0.09199023991823196
step: 70, loss: 0.06238647922873497
step: 80, loss: 0.08938730508089066
step: 90, loss: 0.08431101590394974
step: 100, loss: 0.06557778269052505
step: 110, loss: 0.17848695814609528
step: 120, loss: 0.07781584560871124
step: 130, loss: 0.027647225186228752
step: 140, loss: 0.09894176572561264
step: 150, loss: 0.09530666470527649
step: 160, loss: 0.023707380518317223
step: 170, loss: 0.10613501071929932
step: 180, loss: 0.03450907766819
step: 190, loss: 0.06577040255069733
step: 200, loss: 0.04653076082468033
step: 210, loss: 0.13063015043735504
step: 220, loss: 0.10479988157749176
step: 230, loss: 0.04202575981616974
step: 240, loss: 0.0971180647611618
step: 250, loss: 0.013001770712435246
step: 260, loss: 0.06114551052451134
step: 270, loss: 0.030725792050361633
step: 280, loss: 0.07254628092050552
step: 290, loss: 0.10634414106607437
step: 300, loss: 0.09555619210004807
step: 310, loss: 0.1236247792840004
step: 320, loss: 0.16116099059581757
step: 330, loss: 0.06632164120674133
step: 340, loss: 0.14171643555164337
step: 350, loss: 0.11446904391050339
epoch 12: dev_f1=0.8333333333333333, f1=0.8271028037383177, best_f1=0.8271028037383177
step: 0, loss: 0.11693260073661804
step: 10, loss: 0.07685992866754532
step: 20, loss: 0.037724513560533524
step: 30, loss: 0.0850353017449379
step: 40, loss: 0.04586884006857872
step: 50, loss: 0.09078171849250793
step: 60, loss: 0.12110784649848938
step: 70, loss: 0.11361663043498993
step: 80, loss: 0.030307792127132416
step: 90, loss: 0.05075465515255928
step: 100, loss: 0.13112135231494904
step: 110, loss: 0.05724700912833214
step: 120, loss: 0.07435104995965958
step: 130, loss: 0.09325138479471207
step: 140, loss: 0.07459736615419388
step: 150, loss: 0.015977228060364723
step: 160, loss: 0.07925627380609512
step: 170, loss: 0.1337166130542755
step: 180, loss: 0.05521359294652939
step: 190, loss: 0.03244908154010773
step: 200, loss: 0.04706550016999245
step: 210, loss: 0.06108873337507248
step: 220, loss: 0.019906148314476013
step: 230, loss: 0.059019893407821655
step: 240, loss: 0.04616667702794075
step: 250, loss: 0.05674542486667633
step: 260, loss: 0.08357245475053787
step: 270, loss: 0.10804667323827744
step: 280, loss: 0.07213333994150162
step: 290, loss: 0.07717657089233398
step: 300, loss: 0.04477544501423836
step: 310, loss: 0.052319224923849106
step: 320, loss: 0.22963762283325195
step: 330, loss: 0.020473457872867584
step: 340, loss: 0.13502958416938782
step: 350, loss: 0.07599718123674393
epoch 13: dev_f1=0.8340807174887893, f1=0.8248337028824834, best_f1=0.8248337028824834
step: 0, loss: 0.0547192320227623
step: 10, loss: 0.08676777780056
step: 20, loss: 0.10183896124362946
step: 30, loss: 0.1160648763179779
step: 40, loss: 0.05625506117939949
step: 50, loss: 0.06232424080371857
step: 60, loss: 0.10403157025575638
step: 70, loss: 0.22912675142288208
step: 80, loss: 0.12794475257396698
step: 90, loss: 0.11180803924798965
step: 100, loss: 0.14555883407592773
step: 110, loss: 0.04457376152276993
step: 120, loss: 0.046497296541929245
step: 130, loss: 0.0493321493268013
step: 140, loss: 0.11140267550945282
step: 150, loss: 0.17993900179862976
step: 160, loss: 0.1542341262102127
step: 170, loss: 0.032567474991083145
step: 180, loss: 0.018051018938422203
step: 190, loss: 0.07740481197834015
step: 200, loss: 0.0654863640666008
step: 210, loss: 0.013790193013846874
step: 220, loss: 0.030827976763248444
step: 230, loss: 0.012287640944123268
step: 240, loss: 0.05757559463381767
step: 250, loss: 0.055100202560424805
step: 260, loss: 0.00178333290386945
step: 270, loss: 0.04768721014261246
step: 280, loss: 0.1315712183713913
step: 290, loss: 0.13184961676597595
step: 300, loss: 0.033255476504564285
step: 310, loss: 0.027711296454072
step: 320, loss: 0.10949955135583878
step: 330, loss: 0.03047664277255535
step: 340, loss: 0.08029086887836456
step: 350, loss: 0.0003816177777480334
epoch 14: dev_f1=0.8357487922705313, f1=0.8210023866348449, best_f1=0.8210023866348449
step: 0, loss: 0.05579249560832977
step: 10, loss: 0.060457993298769
step: 20, loss: 0.1569371074438095
step: 30, loss: 0.12299445271492004
step: 40, loss: 0.07810226082801819
step: 50, loss: 0.2615424394607544
step: 60, loss: 0.0003441624576225877
step: 70, loss: 0.03266521170735359
step: 80, loss: 0.12601301074028015
step: 90, loss: 0.14004608988761902
step: 100, loss: 0.028882533311843872
step: 110, loss: 0.10269626975059509
step: 120, loss: 0.08341008424758911
step: 130, loss: 0.07562118023633957
step: 140, loss: 0.05942397192120552
step: 150, loss: 0.13705186545848846
step: 160, loss: 0.10011574625968933
step: 170, loss: 0.02702637016773224
step: 180, loss: 0.08546612411737442
step: 190, loss: 0.06615666300058365
step: 200, loss: 0.042752813547849655
step: 210, loss: 0.14974451065063477
step: 220, loss: 0.0978957787156105
step: 230, loss: 0.09427952766418457
step: 240, loss: 0.04121629521250725
step: 250, loss: 0.03147565945982933
step: 260, loss: 0.0891098603606224
step: 270, loss: 0.04608071967959404
step: 280, loss: 0.06799193471670151
step: 290, loss: 0.00019932947179768234
step: 300, loss: 0.03342469781637192
step: 310, loss: 0.11629297584295273
step: 320, loss: 0.053324222564697266
step: 330, loss: 0.15592481195926666
step: 340, loss: 0.08194190263748169
step: 350, loss: 0.06856875121593475
epoch 15: dev_f1=0.828235294117647, f1=0.8235294117647057, best_f1=0.8210023866348449
step: 0, loss: 0.034649357199668884
step: 10, loss: 0.07508751004934311
step: 20, loss: 0.015540583990514278
step: 30, loss: 0.017204804345965385
step: 40, loss: 0.0927620604634285
step: 50, loss: 0.0859336256980896
step: 60, loss: 0.10758106410503387
step: 70, loss: 0.03145729750394821
step: 80, loss: 0.12221279740333557
step: 90, loss: 0.003690635785460472
step: 100, loss: 0.04384713992476463
step: 110, loss: 0.08187240362167358
step: 120, loss: 0.028042199090123177
step: 130, loss: 0.13907714188098907
step: 140, loss: 0.06171213835477829
step: 150, loss: 0.11674734950065613
step: 160, loss: 0.05849374085664749
step: 170, loss: 0.03363729268312454
step: 180, loss: 0.07820908725261688
step: 190, loss: 0.0027717554476112127
step: 200, loss: 0.10891898721456528
step: 210, loss: 0.05568712577223778
step: 220, loss: 0.04896789416670799
step: 230, loss: 0.04772969335317612
step: 240, loss: 0.026621943339705467
step: 250, loss: 0.009176181629300117
step: 260, loss: 0.04184163361787796
step: 270, loss: 0.08996295928955078
step: 280, loss: 0.06142687425017357
step: 290, loss: 0.02511962689459324
step: 300, loss: 0.060923341661691666
step: 310, loss: 0.009421123191714287
step: 320, loss: 0.05166061222553253
step: 330, loss: 0.05104153975844383
step: 340, loss: 0.1049422100186348
step: 350, loss: 0.013953487388789654
epoch 16: dev_f1=0.8312958435207823, f1=0.8380952380952381, best_f1=0.8210023866348449
step: 0, loss: 0.04234342649579048
step: 10, loss: 0.04098803550004959
step: 20, loss: 0.1010245680809021
step: 30, loss: 0.11592527478933334
step: 40, loss: 0.07777854055166245
step: 50, loss: 0.05268858000636101
step: 60, loss: 0.04515860602259636
step: 70, loss: 0.07000266015529633
step: 80, loss: 0.03480495885014534
step: 90, loss: 0.04573415592312813
step: 100, loss: 0.022944271564483643
step: 110, loss: 0.0519554540514946
step: 120, loss: 0.05080583319067955
step: 130, loss: 0.037249691784381866
step: 140, loss: 0.06708189845085144
step: 150, loss: 0.029895523563027382
step: 160, loss: 0.10534249246120453
step: 170, loss: 0.1357547789812088
step: 180, loss: 0.025997992604970932
step: 190, loss: 0.09279201924800873
step: 200, loss: 0.10289408266544342
step: 210, loss: 0.03241964429616928
step: 220, loss: 0.053608495742082596
step: 230, loss: 0.07899779826402664
step: 240, loss: 0.05503275990486145
step: 250, loss: 0.03121754713356495
step: 260, loss: 0.23298750817775726
step: 270, loss: 0.04986229166388512
step: 280, loss: 0.02387913316488266
step: 290, loss: 0.052855368703603745
step: 300, loss: 0.11080089956521988
step: 310, loss: 0.04586996138095856
step: 320, loss: 0.029677104204893112
step: 330, loss: 0.012596147134900093
step: 340, loss: 0.030014920979738235
step: 350, loss: 0.06011736020445824
epoch 17: dev_f1=0.8461538461538461, f1=0.8199052132701422, best_f1=0.8199052132701422
step: 0, loss: 0.014295235276222229
step: 10, loss: 0.04531269893050194
step: 20, loss: 0.08857302367687225
step: 30, loss: 0.004977774806320667
step: 40, loss: 0.09355692565441132
step: 50, loss: 0.06508570164442062
step: 60, loss: 0.03658774867653847
step: 70, loss: 0.01609192229807377
step: 80, loss: 0.04456787183880806
step: 90, loss: 0.07617567479610443
step: 100, loss: 0.16482475399971008
step: 110, loss: 0.12459030747413635
step: 120, loss: 0.07887940108776093
step: 130, loss: 0.029834246262907982
step: 140, loss: 0.07525354623794556
step: 150, loss: 0.018446840345859528
step: 160, loss: 0.057920198887586594
step: 170, loss: 0.034245945513248444
step: 180, loss: 7.782334432704374e-05
step: 190, loss: 0.08655224740505219
step: 200, loss: 0.05945033207535744
step: 210, loss: 0.10440953820943832
step: 220, loss: 0.00042175204725936055
step: 230, loss: 0.08947782218456268
step: 240, loss: 0.07185880094766617
step: 250, loss: 0.08137108385562897
step: 260, loss: 0.01794177107512951
step: 270, loss: 0.10508197546005249
step: 280, loss: 0.10156098753213882
step: 290, loss: 0.047391377389431
step: 300, loss: 0.08000615239143372
step: 310, loss: 0.043309759348630905
step: 320, loss: 0.0717737078666687
step: 330, loss: 0.0721084326505661
step: 340, loss: 0.10112587362527847
step: 350, loss: 0.05440622568130493
epoch 18: dev_f1=0.8312958435207823, f1=0.8337349397590362, best_f1=0.8199052132701422
step: 0, loss: 0.06802743673324585
step: 10, loss: 0.05462763458490372
step: 20, loss: 0.139124795794487
step: 30, loss: 0.045808374881744385
step: 40, loss: 0.0730474442243576
step: 50, loss: 0.12631361186504364
step: 60, loss: 0.03452441468834877
step: 70, loss: 0.06786375492811203
step: 80, loss: 0.00010982773528667167
step: 90, loss: 0.12454506009817123
step: 100, loss: 0.048215143382549286
step: 110, loss: 0.11712775379419327
step: 120, loss: 0.14401710033416748
step: 130, loss: 0.1136896163225174
step: 140, loss: 0.056066758930683136
step: 150, loss: 0.07671824842691422
step: 160, loss: 0.03089260309934616
step: 170, loss: 0.0843125507235527
step: 180, loss: 0.09135634452104568
step: 190, loss: 0.13806487619876862
step: 200, loss: 0.08417672663927078
step: 210, loss: 0.09738246351480484
step: 220, loss: 0.11650391668081284
step: 230, loss: 0.047213342040777206
step: 240, loss: 0.017680574208498
step: 250, loss: 0.0006515422137454152
step: 260, loss: 0.002783422591164708
step: 270, loss: 0.050633300095796585
step: 280, loss: 0.07135261595249176
step: 290, loss: 0.013557080179452896
step: 300, loss: 0.06333040446043015
step: 310, loss: 0.07062321901321411
step: 320, loss: 0.04339178651571274
step: 330, loss: 0.1404075175523758
step: 340, loss: 0.09862583875656128
step: 350, loss: 0.058567244559526443
epoch 19: dev_f1=0.8041237113402061, f1=0.8090452261306532, best_f1=0.8199052132701422
step: 0, loss: 0.00823574885725975
step: 10, loss: 0.08886727690696716
step: 20, loss: 0.04161751642823219
step: 30, loss: 0.09814421087503433
step: 40, loss: 0.0676649808883667
step: 50, loss: 0.11954329162836075
step: 60, loss: 0.05035942792892456
step: 70, loss: 0.0505780465900898
step: 80, loss: 0.00801569689065218
step: 90, loss: 0.014600751921534538
step: 100, loss: 0.05804445967078209
step: 110, loss: 0.054611723870038986
step: 120, loss: 0.0553155280649662
step: 130, loss: 0.09113211929798126
step: 140, loss: 0.1180357038974762
step: 150, loss: 0.023750629276037216
step: 160, loss: 0.12949039041996002
step: 170, loss: 0.026253215968608856
step: 180, loss: 0.032250527292490005
step: 190, loss: 0.14412595331668854
step: 200, loss: 0.04016692191362381
step: 210, loss: 0.1250305026769638
step: 220, loss: 0.07614780962467194
step: 230, loss: 0.09697456657886505
step: 240, loss: 0.03524070978164673
step: 250, loss: 0.0013410017127171159
step: 260, loss: 0.010517768561840057
step: 270, loss: 0.09446533769369125
step: 280, loss: 0.07323247939348221
step: 290, loss: 2.631837924127467e-05
step: 300, loss: 0.06330691277980804
step: 310, loss: 0.03955373913049698
step: 320, loss: 0.047472547739744186
step: 330, loss: 2.9667187845916487e-05
step: 340, loss: 0.02604510821402073
step: 350, loss: 0.05858783423900604
epoch 20: dev_f1=0.8287841191066997, f1=0.818627450980392, best_f1=0.8199052132701422
