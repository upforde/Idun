cuda
Device: cuda
step: 0, loss: 0.7411237955093384
step: 10, loss: 0.42231982946395874
step: 20, loss: 0.4280376732349396
step: 30, loss: 0.38542014360427856
step: 40, loss: 0.31141331791877747
step: 50, loss: 0.3096759617328644
step: 60, loss: 0.36763331294059753
step: 70, loss: 0.5473636984825134
step: 80, loss: 0.2695825397968292
step: 90, loss: 0.38351598381996155
step: 100, loss: 0.35184693336486816
step: 110, loss: 0.4121958613395691
step: 120, loss: 0.2904362678527832
step: 130, loss: 0.3445828855037689
step: 140, loss: 0.3759855031967163
step: 150, loss: 0.41326114535331726
step: 160, loss: 0.2965855300426483
step: 170, loss: 0.517646312713623
step: 180, loss: 0.10445615649223328
step: 190, loss: 0.23948189616203308
step: 200, loss: 0.25203630328178406
step: 210, loss: 0.1317255198955536
step: 220, loss: 0.2575855851173401
step: 230, loss: 0.16635000705718994
step: 240, loss: 0.26619088649749756
step: 250, loss: 0.1595713198184967
step: 260, loss: 0.292524129152298
step: 270, loss: 0.21085892617702484
step: 280, loss: 0.1254146695137024
step: 290, loss: 0.07450293004512787
step: 300, loss: 0.1886618584394455
step: 310, loss: 0.24295079708099365
step: 320, loss: 0.2998340427875519
step: 330, loss: 0.23332121968269348
step: 340, loss: 0.29528260231018066
step: 350, loss: 0.16935770213603973
epoch 1: dev_f1=0.7254509018036072, f1=0.7222222222222223, best_f1=0.7222222222222223
step: 0, loss: 0.19017603993415833
step: 10, loss: 0.1179332435131073
step: 20, loss: 0.11667099595069885
step: 30, loss: 0.13891111314296722
step: 40, loss: 0.11068226397037506
step: 50, loss: 0.25706353783607483
step: 60, loss: 0.08864545822143555
step: 70, loss: 0.087553009390831
step: 80, loss: 0.3061359226703644
step: 90, loss: 0.1491345465183258
step: 100, loss: 0.13339921832084656
step: 110, loss: 0.16816918551921844
step: 120, loss: 0.19576382637023926
step: 130, loss: 0.08158839493989944
step: 140, loss: 0.17557822167873383
step: 150, loss: 0.2026524394750595
step: 160, loss: 0.25975438952445984
step: 170, loss: 0.1303565353155136
step: 180, loss: 0.09194884449243546
step: 190, loss: 0.11966189742088318
step: 200, loss: 0.23936288058757782
step: 210, loss: 0.1049559935927391
step: 220, loss: 0.24284519255161285
step: 230, loss: 0.11733362078666687
step: 240, loss: 0.22516389191150665
step: 250, loss: 0.08021567761898041
step: 260, loss: 0.09346981346607208
step: 270, loss: 0.3921739161014557
step: 280, loss: 0.10693157464265823
step: 290, loss: 0.1118912473320961
step: 300, loss: 0.17505726218223572
step: 310, loss: 0.19336937367916107
step: 320, loss: 0.10653135180473328
step: 330, loss: 0.2050493359565735
step: 340, loss: 0.1649245172739029
step: 350, loss: 0.1072106882929802
epoch 2: dev_f1=0.7713625866050808, f1=0.7612612612612613, best_f1=0.7612612612612613
step: 0, loss: 0.1541374921798706
step: 10, loss: 0.0430661179125309
step: 20, loss: 0.11294082552194595
step: 30, loss: 0.021136337891221046
step: 40, loss: 0.09349081665277481
step: 50, loss: 0.1346525251865387
step: 60, loss: 0.06817804276943207
step: 70, loss: 0.14436142146587372
step: 80, loss: 0.0582708977162838
step: 90, loss: 0.09860832989215851
step: 100, loss: 0.1684633493423462
step: 110, loss: 0.06154618039727211
step: 120, loss: 0.1794784665107727
step: 130, loss: 0.13288913667201996
step: 140, loss: 0.11799736320972443
step: 150, loss: 0.08521152287721634
step: 160, loss: 0.07363175600767136
step: 170, loss: 0.13811379671096802
step: 180, loss: 0.05177029222249985
step: 190, loss: 0.15293964743614197
step: 200, loss: 0.13409850001335144
step: 210, loss: 0.041121236979961395
step: 220, loss: 0.015971742570400238
step: 230, loss: 0.16133150458335876
step: 240, loss: 0.12182871997356415
step: 250, loss: 0.09416192770004272
step: 260, loss: 0.14685451984405518
step: 270, loss: 0.046414632350206375
step: 280, loss: 0.1651850789785385
step: 290, loss: 0.03919210657477379
step: 300, loss: 0.1568395346403122
step: 310, loss: 0.05667077749967575
step: 320, loss: 0.11235164105892181
step: 330, loss: 0.08450613915920258
step: 340, loss: 0.18015077710151672
step: 350, loss: 0.0337243415415287
epoch 3: dev_f1=0.8105726872246697, f1=0.7991266375545852, best_f1=0.7991266375545852
step: 0, loss: 0.12660783529281616
step: 10, loss: 0.044680193066596985
step: 20, loss: 0.06814441084861755
step: 30, loss: 0.05224644020199776
step: 40, loss: 0.1438906043767929
step: 50, loss: 0.07314518839120865
step: 60, loss: 0.16372627019882202
step: 70, loss: 0.09865965694189072
step: 80, loss: 0.09231442213058472
step: 90, loss: 0.03981265425682068
step: 100, loss: 0.05460142716765404
step: 110, loss: 0.11003818362951279
step: 120, loss: 0.09939983487129211
step: 130, loss: 0.09328876435756683
step: 140, loss: 0.09502940624952316
step: 150, loss: 0.04571237415075302
step: 160, loss: 0.11035379022359848
step: 170, loss: 0.14023759961128235
step: 180, loss: 0.1118345856666565
step: 190, loss: 0.19718006253242493
step: 200, loss: 0.03181888535618782
step: 210, loss: 0.11787829548120499
step: 220, loss: 0.08269152045249939
step: 230, loss: 0.08313736319541931
step: 240, loss: 0.02487407624721527
step: 250, loss: 0.07871438562870026
step: 260, loss: 0.13279081881046295
step: 270, loss: 0.33712637424468994
step: 280, loss: 0.11378339678049088
step: 290, loss: 0.019798897206783295
step: 300, loss: 0.09700916707515717
step: 310, loss: 0.10672596096992493
step: 320, loss: 0.1364109367132187
step: 330, loss: 0.13312992453575134
step: 340, loss: 0.015786048024892807
step: 350, loss: 0.04474102705717087
epoch 4: dev_f1=0.7919463087248323, f1=0.7685774946921444, best_f1=0.7991266375545852
step: 0, loss: 0.12237175554037094
step: 10, loss: 0.3788846433162689
step: 20, loss: 0.05796465277671814
step: 30, loss: 0.03359556570649147
step: 40, loss: 0.41775617003440857
step: 50, loss: 0.1613621711730957
step: 60, loss: 0.062986359000206
step: 70, loss: 0.05535554513335228
step: 80, loss: 0.06958697736263275
step: 90, loss: 0.1420869678258896
step: 100, loss: 0.08806105703115463
step: 110, loss: 0.17148680984973907
step: 120, loss: 0.15208163857460022
step: 130, loss: 0.026112647727131844
step: 140, loss: 0.05900689214468002
step: 150, loss: 0.10752132534980774
step: 160, loss: 0.052527934312820435
step: 170, loss: 0.11039233207702637
step: 180, loss: 0.08687634021043777
step: 190, loss: 0.08018601685762405
step: 200, loss: 0.029291335493326187
step: 210, loss: 0.011100731790065765
step: 220, loss: 0.1271439790725708
step: 230, loss: 0.16926154494285583
step: 240, loss: 0.14778479933738708
step: 250, loss: 0.02006281353533268
step: 260, loss: 0.11423403769731522
step: 270, loss: 0.07246770709753036
step: 280, loss: 0.09323732554912567
step: 290, loss: 0.0703250840306282
step: 300, loss: 0.08899208903312683
step: 310, loss: 0.08934015035629272
step: 320, loss: 0.07278379052877426
step: 330, loss: 0.07046522200107574
step: 340, loss: 0.05345936119556427
step: 350, loss: 0.029986580833792686
epoch 5: dev_f1=0.8384279475982533, f1=0.7724425887265136, best_f1=0.7724425887265136
step: 0, loss: 0.03276028856635094
step: 10, loss: 0.14626438915729523
step: 20, loss: 0.1468704789876938
step: 30, loss: 0.082868292927742
step: 40, loss: 0.03518432006239891
step: 50, loss: 0.058301784098148346
step: 60, loss: 0.10305292904376984
step: 70, loss: 0.03535984456539154
step: 80, loss: 0.09856100380420685
step: 90, loss: 0.11638803035020828
step: 100, loss: 0.07010230422019958
step: 110, loss: 0.06719223409891129
step: 120, loss: 0.06596584618091583
step: 130, loss: 0.10296183079481125
step: 140, loss: 0.07613696902990341
step: 150, loss: 0.11575643718242645
step: 160, loss: 0.12172232568264008
step: 170, loss: 0.08325645327568054
step: 180, loss: 0.17066647112369537
step: 190, loss: 0.123283252120018
step: 200, loss: 0.10865423083305359
step: 210, loss: 0.07100726664066315
step: 220, loss: 0.005347253289073706
step: 230, loss: 0.14675039052963257
step: 240, loss: 0.13922534883022308
step: 250, loss: 0.1917324662208557
step: 260, loss: 0.060385141521692276
step: 270, loss: 0.21461279690265656
step: 280, loss: 0.025692889466881752
step: 290, loss: 0.07447993010282516
step: 300, loss: 0.04466139152646065
step: 310, loss: 0.10897935181856155
step: 320, loss: 0.1720050722360611
step: 330, loss: 0.11038121581077576
step: 340, loss: 0.1618606001138687
step: 350, loss: 0.07094424962997437
epoch 6: dev_f1=0.8406466512702079, f1=0.8193832599118943, best_f1=0.8193832599118943
step: 0, loss: 0.15720148384571075
step: 10, loss: 0.09491695463657379
step: 20, loss: 0.010676511563360691
step: 30, loss: 0.16856636106967926
step: 40, loss: 0.06877007335424423
step: 50, loss: 0.05367221683263779
step: 60, loss: 0.22937454283237457
step: 70, loss: 0.029227234423160553
step: 80, loss: 0.0627700611948967
step: 90, loss: 0.07776901870965958
step: 100, loss: 0.1925702691078186
step: 110, loss: 0.04336079955101013
step: 120, loss: 0.09053701162338257
step: 130, loss: 0.08680129796266556
step: 140, loss: 0.28974926471710205
step: 150, loss: 0.07566067576408386
step: 160, loss: 0.09353350847959518
step: 170, loss: 0.15690191090106964
step: 180, loss: 0.08356547355651855
step: 190, loss: 0.07029595971107483
step: 200, loss: 0.06845148652791977
step: 210, loss: 0.020036181434988976
step: 220, loss: 0.12557755410671234
step: 230, loss: 0.08598905056715012
step: 240, loss: 0.12894867360591888
step: 250, loss: 0.15845106542110443
step: 260, loss: 0.1275169551372528
step: 270, loss: 0.0390235111117363
step: 280, loss: 0.13864590227603912
step: 290, loss: 0.18051129579544067
step: 300, loss: 0.055775437504053116
step: 310, loss: 0.07945189625024796
step: 320, loss: 0.03575234115123749
step: 330, loss: 0.10818488150835037
step: 340, loss: 0.06991598010063171
step: 350, loss: 0.04470181465148926
epoch 7: dev_f1=0.8337468982630273, f1=0.7868852459016392, best_f1=0.8193832599118943
step: 0, loss: 0.07921243458986282
step: 10, loss: 0.07305613160133362
step: 20, loss: 0.013908526860177517
step: 30, loss: 0.06032339110970497
step: 40, loss: 0.054991722106933594
step: 50, loss: 0.05602782964706421
step: 60, loss: 0.023875094950199127
step: 70, loss: 0.0583585724234581
step: 80, loss: 0.0496877059340477
step: 90, loss: 0.06132010370492935
step: 100, loss: 0.09759367257356644
step: 110, loss: 0.07694526016712189
step: 120, loss: 0.1550421416759491
step: 130, loss: 0.06207636371254921
step: 140, loss: 0.09921927005052567
step: 150, loss: 0.10287021845579147
step: 160, loss: 0.05369585379958153
step: 170, loss: 0.08173145353794098
step: 180, loss: 0.001750535098835826
step: 190, loss: 0.12943169474601746
step: 200, loss: 0.07254980504512787
step: 210, loss: 0.12157696485519409
step: 220, loss: 0.08827876299619675
step: 230, loss: 0.0479547455906868
step: 240, loss: 0.14254829287528992
step: 250, loss: 0.11717799305915833
step: 260, loss: 0.05220087990164757
step: 270, loss: 0.06607839465141296
step: 280, loss: 0.03172064572572708
step: 290, loss: 0.1374708116054535
step: 300, loss: 0.08784660696983337
step: 310, loss: 0.08005647361278534
step: 320, loss: 0.1010994017124176
step: 330, loss: 0.030297214165329933
step: 340, loss: 0.04574984684586525
step: 350, loss: 0.11156754940748215
epoch 8: dev_f1=0.8390243902439024, f1=0.8038277511961723, best_f1=0.8193832599118943
step: 0, loss: 0.0386701337993145
step: 10, loss: 0.003578062169253826
step: 20, loss: 0.029163429513573647
step: 30, loss: 0.1368507742881775
step: 40, loss: 0.07234054803848267
step: 50, loss: 0.05788302421569824
step: 60, loss: 0.021810214966535568
step: 70, loss: 0.019675403833389282
step: 80, loss: 0.12526893615722656
step: 90, loss: 0.08300626277923584
step: 100, loss: 0.04269914701581001
step: 110, loss: 0.039858248084783554
step: 120, loss: 0.04746508598327637
step: 130, loss: 0.10429821163415909
step: 140, loss: 0.08584609627723694
step: 150, loss: 0.08078573644161224
step: 160, loss: 0.12961514294147491
step: 170, loss: 0.1226208508014679
step: 180, loss: 0.18854059278964996
step: 190, loss: 0.07568803429603577
step: 200, loss: 0.07148835062980652
step: 210, loss: 0.072101891040802
step: 220, loss: 0.10118060559034348
step: 230, loss: 0.11932066082954407
step: 240, loss: 0.002265841467306018
step: 250, loss: 0.08152789622545242
step: 260, loss: 0.04406803101301193
step: 270, loss: 0.1470668762922287
step: 280, loss: 0.040392592549324036
step: 290, loss: 0.09806698560714722
step: 300, loss: 0.0735640823841095
step: 310, loss: 0.023688476532697678
step: 320, loss: 0.080844946205616
step: 330, loss: 0.047171808779239655
step: 340, loss: 0.07977577298879623
step: 350, loss: 0.052776072174310684
epoch 9: dev_f1=0.8280871670702179, f1=0.8289156626506025, best_f1=0.8193832599118943
step: 0, loss: 0.041952453553676605
step: 10, loss: 0.0653800293803215
step: 20, loss: 0.0913504958152771
step: 30, loss: 0.02605993114411831
step: 40, loss: 0.08338069915771484
step: 50, loss: 0.10238219052553177
step: 60, loss: 0.03138544037938118
step: 70, loss: 0.0368247888982296
step: 80, loss: 0.17558620870113373
step: 90, loss: 0.09358593076467514
step: 100, loss: 0.010531602427363396
step: 110, loss: 0.06240319460630417
step: 120, loss: 0.01304031815379858
step: 130, loss: 0.06508282572031021
step: 140, loss: 0.05836765468120575
step: 150, loss: 0.01959155686199665
step: 160, loss: 0.03060544840991497
step: 170, loss: 0.059310320764780045
step: 180, loss: 0.060097236186265945
step: 190, loss: 0.024871740490198135
step: 200, loss: 0.05119166150689125
step: 210, loss: 0.07876116782426834
step: 220, loss: 0.11325240135192871
step: 230, loss: 0.06238593906164169
step: 240, loss: 0.19164180755615234
step: 250, loss: 0.039395011961460114
step: 260, loss: 0.07643439620733261
step: 270, loss: 0.06256012618541718
step: 280, loss: 0.11005595326423645
step: 290, loss: 0.056875236332416534
step: 300, loss: 0.0892077162861824
step: 310, loss: 0.04987253621220589
step: 320, loss: 0.08292195945978165
step: 330, loss: 0.1389130800962448
step: 340, loss: 0.10106747597455978
step: 350, loss: 0.03760775178670883
epoch 10: dev_f1=0.8411633109619687, f1=0.7711864406779663, best_f1=0.7711864406779663
step: 0, loss: 0.11613871902227402
step: 10, loss: 0.08966077864170074
step: 20, loss: 0.0673351138830185
step: 30, loss: 0.11411482840776443
step: 40, loss: 0.005542091093957424
step: 50, loss: 0.021957702934741974
step: 60, loss: 0.11542174220085144
step: 70, loss: 0.06513974815607071
step: 80, loss: 0.11773235350847244
step: 90, loss: 0.05880773440003395
step: 100, loss: 0.08538847416639328
step: 110, loss: 0.07730836421251297
step: 120, loss: 0.18388140201568604
step: 130, loss: 0.04561152681708336
step: 140, loss: 0.06355021148920059
step: 150, loss: 0.12564145028591156
step: 160, loss: 0.15921123325824738
step: 170, loss: 0.08889281004667282
step: 180, loss: 0.05087011680006981
step: 190, loss: 0.0642022117972374
step: 200, loss: 0.13341277837753296
step: 210, loss: 0.10932927578687668
step: 220, loss: 0.17502722144126892
step: 230, loss: 0.08651009947061539
step: 240, loss: 0.1599588245153427
step: 250, loss: 0.03672631457448006
step: 260, loss: 0.06218566372990608
step: 270, loss: 0.03982521593570709
step: 280, loss: 0.08499516546726227
step: 290, loss: 0.007585217710584402
step: 300, loss: 0.06558922678232193
step: 310, loss: 0.049551960080862045
step: 320, loss: 0.1561085283756256
step: 330, loss: 0.0594354122877121
step: 340, loss: 0.005525123327970505
step: 350, loss: 0.05894818156957626
epoch 11: dev_f1=0.8405797101449275, f1=0.8246445497630333, best_f1=0.7711864406779663
step: 0, loss: 0.004782916512340307
step: 10, loss: 0.057964444160461426
step: 20, loss: 0.05605112761259079
step: 30, loss: 0.10707759857177734
step: 40, loss: 0.11292777210474014
step: 50, loss: 0.07046348601579666
step: 60, loss: 0.0760178416967392
step: 70, loss: 0.05570979788899422
step: 80, loss: 0.06700323522090912
step: 90, loss: 0.08810773491859436
step: 100, loss: 0.0900900661945343
step: 110, loss: 0.023996220901608467
step: 120, loss: 0.1893368363380432
step: 130, loss: 0.0807984247803688
step: 140, loss: 0.04187796264886856
step: 150, loss: 0.09881591796875
step: 160, loss: 0.0788765549659729
step: 170, loss: 0.026008710265159607
step: 180, loss: 0.06580622494220734
step: 190, loss: 0.026452409103512764
step: 200, loss: 0.07002076506614685
step: 210, loss: 0.15059885382652283
step: 220, loss: 0.13158924877643585
step: 230, loss: 0.03182845190167427
step: 240, loss: 0.1572236269712448
step: 250, loss: 0.05941260606050491
step: 260, loss: 0.04579969495534897
step: 270, loss: 0.1611943244934082
step: 280, loss: 0.10324373096227646
step: 290, loss: 0.027964871376752853
step: 300, loss: 0.08119948953390121
step: 310, loss: 0.07775049656629562
step: 320, loss: 0.05306800827383995
step: 330, loss: 0.0818394124507904
step: 340, loss: 0.04401036724448204
step: 350, loss: 0.13537946343421936
epoch 12: dev_f1=0.8261851015801356, f1=0.7886710239651415, best_f1=0.7711864406779663
step: 0, loss: 0.06798354536294937
step: 10, loss: 0.010391650721430779
step: 20, loss: 0.03460446745157242
step: 30, loss: 0.13472938537597656
step: 40, loss: 0.08470635861158371
step: 50, loss: 0.027535906061530113
step: 60, loss: 0.15584583580493927
step: 70, loss: 0.19984810054302216
step: 80, loss: 0.14210356771945953
step: 90, loss: 0.043275684118270874
step: 100, loss: 0.0005177959683351219
step: 110, loss: 0.021651729941368103
step: 120, loss: 0.09553415328264236
step: 130, loss: 0.05341155454516411
step: 140, loss: 0.03369682654738426
step: 150, loss: 0.044443998485803604
step: 160, loss: 0.04795754700899124
step: 170, loss: 0.0766669437289238
step: 180, loss: 0.09916117787361145
step: 190, loss: 0.04699481278657913
step: 200, loss: 0.12475719302892685
step: 210, loss: 0.09641283750534058
step: 220, loss: 0.06585316359996796
step: 230, loss: 0.09498979151248932
step: 240, loss: 0.05911462754011154
step: 250, loss: 0.04714561998844147
step: 260, loss: 0.048934273421764374
step: 270, loss: 0.07250995934009552
step: 280, loss: 0.10568170249462128
step: 290, loss: 0.057250335812568665
step: 300, loss: 0.05955331027507782
step: 310, loss: 0.08685620874166489
step: 320, loss: 0.09044443070888519
step: 330, loss: 0.13436710834503174
step: 340, loss: 0.09635616093873978
step: 350, loss: 0.07959818840026855
epoch 13: dev_f1=0.8188235294117647, f1=0.8035714285714285, best_f1=0.7711864406779663
step: 0, loss: 0.008307668380439281
step: 10, loss: 0.002189509803429246
step: 20, loss: 0.11416686326265335
step: 30, loss: 0.07615204155445099
step: 40, loss: 0.06641185283660889
step: 50, loss: 0.031872935593128204
step: 60, loss: 0.02641814947128296
step: 70, loss: 0.11740541458129883
step: 80, loss: 0.14449146389961243
step: 90, loss: 0.04982162266969681
step: 100, loss: 0.12062405049800873
step: 110, loss: 0.08098825812339783
step: 120, loss: 0.09299354255199432
step: 130, loss: 0.11909344792366028
step: 140, loss: 0.07757269591093063
step: 150, loss: 0.0540032833814621
step: 160, loss: 0.08425472676753998
step: 170, loss: 0.12547454237937927
step: 180, loss: 0.07882378250360489
step: 190, loss: 0.07513672113418579
step: 200, loss: 0.09242285788059235
step: 210, loss: 0.1072748452425003
step: 220, loss: 0.012283668853342533
step: 230, loss: 0.03551190346479416
step: 240, loss: 0.07144433259963989
step: 250, loss: 0.05003809183835983
step: 260, loss: 0.08613331615924835
step: 270, loss: 0.11709003895521164
step: 280, loss: 0.1159074604511261
step: 290, loss: 0.0876854956150055
step: 300, loss: 0.06782067567110062
step: 310, loss: 0.04663452133536339
step: 320, loss: 0.09250107407569885
step: 330, loss: 0.1295035183429718
step: 340, loss: 0.027194269001483917
step: 350, loss: 0.06913430243730545
epoch 14: dev_f1=0.836027713625866, f1=0.8043956043956044, best_f1=0.7711864406779663
step: 0, loss: 0.06710291653871536
step: 10, loss: 0.0896250307559967
step: 20, loss: 0.049132633954286575
step: 30, loss: 0.023389579728245735
step: 40, loss: 0.05600729212164879
step: 50, loss: 0.016040241345763206
step: 60, loss: 0.17118175327777863
step: 70, loss: 0.13339486718177795
step: 80, loss: 0.21623989939689636
step: 90, loss: 0.011827385053038597
step: 100, loss: 0.1682099997997284
step: 110, loss: 0.17606523633003235
step: 120, loss: 0.06195933371782303
step: 130, loss: 0.05515427142381668
step: 140, loss: 0.06269574165344238
step: 150, loss: 0.059396110475063324
step: 160, loss: 0.06583134829998016
step: 170, loss: 0.07720699906349182
step: 180, loss: 0.09000028669834137
step: 190, loss: 0.045631084591150284
step: 200, loss: 0.1421995908021927
step: 210, loss: 0.10514076054096222
step: 220, loss: 0.019652849063277245
step: 230, loss: 0.13888919353485107
step: 240, loss: 0.064732126891613
step: 250, loss: 0.0939779207110405
step: 260, loss: 0.017823440954089165
step: 270, loss: 0.02341466397047043
step: 280, loss: 0.03856193646788597
step: 290, loss: 0.0932791456580162
step: 300, loss: 0.028054267168045044
step: 310, loss: 0.07368134707212448
step: 320, loss: 0.06599842011928558
step: 330, loss: 0.11509434878826141
step: 340, loss: 0.08447320014238358
step: 350, loss: 0.05324918031692505
epoch 15: dev_f1=0.8329519450800916, f1=0.7869565217391304, best_f1=0.7711864406779663
step: 0, loss: 0.131097674369812
step: 10, loss: 0.030708076432347298
step: 20, loss: 0.061553437262773514
step: 30, loss: 0.03232128545641899
step: 40, loss: 0.08212010562419891
step: 50, loss: 0.04198892414569855
step: 60, loss: 0.05663531646132469
step: 70, loss: 0.049679700285196304
step: 80, loss: 0.03455057367682457
step: 90, loss: 0.09304381161928177
step: 100, loss: 0.10587867349386215
step: 110, loss: 0.002110686618834734
step: 120, loss: 0.06908946484327316
step: 130, loss: 0.0737156942486763
step: 140, loss: 0.09391265362501144
step: 150, loss: 0.16493625938892365
step: 160, loss: 0.0875876396894455
step: 170, loss: 0.06776101887226105
step: 180, loss: 0.04575939103960991
step: 190, loss: 0.1352580040693283
step: 200, loss: 0.08551106601953506
step: 210, loss: 0.16143253445625305
step: 220, loss: 0.018041137605905533
step: 230, loss: 0.09325412660837173
step: 240, loss: 0.06407782435417175
step: 250, loss: 0.014450828544795513
step: 260, loss: 0.0841062068939209
step: 270, loss: 0.04387231171131134
step: 280, loss: 0.13487626612186432
step: 290, loss: 0.06895430386066437
step: 300, loss: 0.04054301232099533
step: 310, loss: 0.15381976962089539
step: 320, loss: 0.06717751920223236
step: 330, loss: 0.10779697448015213
step: 340, loss: 0.0002273683639941737
step: 350, loss: 0.10537929832935333
epoch 16: dev_f1=0.821852731591449, f1=0.7900677200902935, best_f1=0.7711864406779663
step: 0, loss: 0.02498728781938553
step: 10, loss: 0.08352666348218918
step: 20, loss: 8.529325714334846e-05
step: 30, loss: 0.0488358773291111
step: 40, loss: 0.023068925365805626
step: 50, loss: 0.12689369916915894
step: 60, loss: 0.08254878968000412
step: 70, loss: 0.10013531148433685
step: 80, loss: 0.10526851564645767
step: 90, loss: 0.050713974982500076
step: 100, loss: 0.04370015487074852
step: 110, loss: 0.04923943430185318
step: 120, loss: 0.07507295906543732
step: 130, loss: 0.010909215547144413
step: 140, loss: 0.13335943222045898
step: 150, loss: 0.1262514591217041
step: 160, loss: 0.07050769776105881
step: 170, loss: 0.05014238506555557
step: 180, loss: 0.0037753323558717966
step: 190, loss: 0.08184467256069183
step: 200, loss: 0.09069972485303879
step: 210, loss: 0.05681454762816429
step: 220, loss: 0.019940432161092758
step: 230, loss: 0.041193317621946335
step: 240, loss: 0.0050080521032214165
step: 250, loss: 0.023233382031321526
step: 260, loss: 0.005888334941118956
step: 270, loss: 0.0013194028288125992
step: 280, loss: 0.12154047191143036
step: 290, loss: 0.08322872221469879
step: 300, loss: 0.0840233862400055
step: 310, loss: 0.05053398385643959
step: 320, loss: 0.116301991045475
step: 330, loss: 0.055655207484960556
step: 340, loss: 0.15176670253276825
step: 350, loss: 0.0610426589846611
epoch 17: dev_f1=0.8302752293577982, f1=0.7816593886462883, best_f1=0.7711864406779663
step: 0, loss: 0.06781896948814392
step: 10, loss: 0.09584438800811768
step: 20, loss: 0.013335390947759151
step: 30, loss: 0.09061701595783234
step: 40, loss: 0.040362387895584106
step: 50, loss: 0.012050327844917774
step: 60, loss: 0.1309376209974289
step: 70, loss: 0.05962551012635231
step: 80, loss: 0.2110334038734436
step: 90, loss: 0.03816821798682213
step: 100, loss: 0.07042400538921356
step: 110, loss: 0.05011193826794624
step: 120, loss: 0.018907135352492332
step: 130, loss: 0.0777001827955246
step: 140, loss: 0.13756418228149414
step: 150, loss: 0.04136963188648224
step: 160, loss: 0.0440324991941452
step: 170, loss: 0.032138705253601074
step: 180, loss: 0.056382518261671066
step: 190, loss: 0.08662880957126617
step: 200, loss: 0.06539718806743622
step: 210, loss: 0.07450196146965027
step: 220, loss: 0.09458954632282257
step: 230, loss: 0.08723323792219162
step: 240, loss: 0.02239970676600933
step: 250, loss: 0.10495977848768234
step: 260, loss: 0.020370999351143837
step: 270, loss: 0.03656572848558426
step: 280, loss: 0.02826661802828312
step: 290, loss: 0.06719597429037094
step: 300, loss: 0.007217803969979286
step: 310, loss: 0.04279198497533798
step: 320, loss: 0.04872814565896988
step: 330, loss: 0.05274626240134239
step: 340, loss: 0.17035195231437683
step: 350, loss: 0.01390712521970272
epoch 18: dev_f1=0.794044665012407, f1=0.7790973871733967, best_f1=0.7711864406779663
step: 0, loss: 0.05581994354724884
step: 10, loss: 0.04543304443359375
step: 20, loss: 0.054832376539707184
step: 30, loss: 0.06999195367097855
step: 40, loss: 0.1114821657538414
step: 50, loss: 0.04334542527794838
step: 60, loss: 0.026432201266288757
step: 70, loss: 0.09776662290096283
step: 80, loss: 0.015080496668815613
step: 90, loss: 0.017310017719864845
step: 100, loss: 0.030198682099580765
step: 110, loss: 0.09387170523405075
step: 120, loss: 0.02121705748140812
step: 130, loss: 0.06637445837259293
step: 140, loss: 0.01741430163383484
step: 150, loss: 0.04259033501148224
step: 160, loss: 0.04361420497298241
step: 170, loss: 0.06439471989870071
step: 180, loss: 0.1134379655122757
step: 190, loss: 0.09026217460632324
step: 200, loss: 0.021339233964681625
step: 210, loss: 0.034804388880729675
step: 220, loss: 0.031846318393945694
step: 230, loss: 0.011376322247087955
step: 240, loss: 0.06908653676509857
step: 250, loss: 0.023397376760840416
step: 260, loss: 0.10911420732736588
step: 270, loss: 0.08903708308935165
step: 280, loss: 0.039090003818273544
step: 290, loss: 0.08283684402704239
step: 300, loss: 0.11679849028587341
step: 310, loss: 0.14877469837665558
step: 320, loss: 0.04759738966822624
step: 330, loss: 0.011764680035412312
step: 340, loss: 0.023693829774856567
step: 350, loss: 0.08555898070335388
epoch 19: dev_f1=0.8186046511627907, f1=0.7847533632286995, best_f1=0.7711864406779663
step: 0, loss: 0.035183265805244446
step: 10, loss: 0.0932249128818512
step: 20, loss: 0.07496636360883713
step: 30, loss: 0.1696777045726776
step: 40, loss: 0.0495314784348011
step: 50, loss: 0.05317213386297226
step: 60, loss: 0.015589127317070961
step: 70, loss: 0.07366127520799637
step: 80, loss: 0.0979805737733841
step: 90, loss: 0.035338371992111206
step: 100, loss: 0.020287886261940002
step: 110, loss: 0.006150944158434868
step: 120, loss: 0.09071642905473709
step: 130, loss: 0.08320434391498566
step: 140, loss: 0.04627300053834915
step: 150, loss: 0.0050153653137385845
step: 160, loss: 0.08913491666316986
step: 170, loss: 0.0677897036075592
step: 180, loss: 0.06880471110343933
step: 190, loss: 0.020471109077334404
step: 200, loss: 0.03275545313954353
step: 210, loss: 0.08520442992448807
step: 220, loss: 0.09259579330682755
step: 230, loss: 0.03680355101823807
step: 240, loss: 0.03465555980801582
step: 250, loss: 0.07343209534883499
step: 260, loss: 0.025226309895515442
step: 270, loss: 0.07712583988904953
step: 280, loss: 0.03496416658163071
step: 290, loss: 0.12366504222154617
step: 300, loss: 0.05773920565843582
step: 310, loss: 0.09465933591127396
step: 320, loss: 0.029689539223909378
step: 330, loss: 0.07886072993278503
step: 340, loss: 0.00895193312317133
step: 350, loss: 0.01548355259001255
epoch 20: dev_f1=0.8114558472553699, f1=0.7852193995381063, best_f1=0.7711864406779663
