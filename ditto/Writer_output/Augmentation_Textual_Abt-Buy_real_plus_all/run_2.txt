cuda
Device: cuda
step: 0, loss: 0.7275253534317017
step: 10, loss: 0.31685495376586914
step: 20, loss: 0.3131703734397888
step: 30, loss: 0.49645039439201355
step: 40, loss: 0.3691762089729309
step: 50, loss: 0.578045666217804
step: 60, loss: 0.41858458518981934
step: 70, loss: 0.43120667338371277
step: 80, loss: 0.299731969833374
step: 90, loss: 0.24222591519355774
step: 100, loss: 0.36093565821647644
step: 110, loss: 0.41280993819236755
step: 120, loss: 0.4111556112766266
step: 130, loss: 0.377959281206131
step: 140, loss: 0.1722361147403717
step: 150, loss: 0.1854933649301529
step: 160, loss: 0.17579667270183563
step: 170, loss: 0.10845672339200974
step: 180, loss: 0.22273743152618408
step: 190, loss: 0.21390953660011292
step: 200, loss: 0.20493637025356293
step: 210, loss: 0.08323367685079575
step: 220, loss: 0.1735142469406128
step: 230, loss: 0.2552788555622101
step: 240, loss: 0.13641636073589325
step: 250, loss: 0.24911080300807953
step: 260, loss: 0.07921309024095535
step: 270, loss: 0.19261164963245392
step: 280, loss: 0.11752686649560928
step: 290, loss: 0.14580237865447998
step: 300, loss: 0.05855199694633484
step: 310, loss: 0.18155530095100403
step: 320, loss: 0.12702837586402893
step: 330, loss: 0.086204394698143
step: 340, loss: 0.1679922193288803
step: 350, loss: 0.08642621338367462
epoch 1: dev_f1=0.7123893805309734, f1=0.7176220806794056, best_f1=0.7176220806794056
step: 0, loss: 0.14008691906929016
step: 10, loss: 0.12994292378425598
step: 20, loss: 0.10312951356172562
step: 30, loss: 0.11450783908367157
step: 40, loss: 0.19471877813339233
step: 50, loss: 0.08501537889242172
step: 60, loss: 0.12189102917909622
step: 70, loss: 0.15101107954978943
step: 80, loss: 0.06321292370557785
step: 90, loss: 0.2514156997203827
step: 100, loss: 0.23672297596931458
step: 110, loss: 0.17668963968753815
step: 120, loss: 0.10294292867183685
step: 130, loss: 0.19792865216732025
step: 140, loss: 0.12292515486478806
step: 150, loss: 0.13252153992652893
step: 160, loss: 0.3097739517688751
step: 170, loss: 0.08456463366746902
step: 180, loss: 0.10146594047546387
step: 190, loss: 0.038965679705142975
step: 200, loss: 0.07001063227653503
step: 210, loss: 0.18281547725200653
step: 220, loss: 0.334869921207428
step: 230, loss: 0.14833363890647888
step: 240, loss: 0.1562301367521286
step: 250, loss: 0.2262992560863495
step: 260, loss: 0.15224313735961914
step: 270, loss: 0.18702015280723572
step: 280, loss: 0.1460380256175995
step: 290, loss: 0.20932959020137787
step: 300, loss: 0.10084924846887589
step: 310, loss: 0.09095112979412079
step: 320, loss: 0.09481945633888245
step: 330, loss: 0.11306148022413254
step: 340, loss: 0.06650499999523163
step: 350, loss: 0.11512649804353714
epoch 2: dev_f1=0.757142857142857, f1=0.7575057736720553, best_f1=0.7575057736720553
step: 0, loss: 0.13897520303726196
step: 10, loss: 0.07325183600187302
step: 20, loss: 0.06136767566204071
step: 30, loss: 0.059160832315683365
step: 40, loss: 0.21866315603256226
step: 50, loss: 0.19373032450675964
step: 60, loss: 0.24052214622497559
step: 70, loss: 0.05095373094081879
step: 80, loss: 0.07168787717819214
step: 90, loss: 0.03779447823762894
step: 100, loss: 0.03556641563773155
step: 110, loss: 0.09869097918272018
step: 120, loss: 0.2503986656665802
step: 130, loss: 0.05503126606345177
step: 140, loss: 0.1009458601474762
step: 150, loss: 0.10806827992200851
step: 160, loss: 0.08646339178085327
step: 170, loss: 0.08373851329088211
step: 180, loss: 0.028414957225322723
step: 190, loss: 0.06443439424037933
step: 200, loss: 0.09590969979763031
step: 210, loss: 0.19345805048942566
step: 220, loss: 0.1311226338148117
step: 230, loss: 0.12106295675039291
step: 240, loss: 0.15596170723438263
step: 250, loss: 0.03586520254611969
step: 260, loss: 0.13463127613067627
step: 270, loss: 0.1699114441871643
step: 280, loss: 0.20007120072841644
step: 290, loss: 0.09051936864852905
step: 300, loss: 0.11183968186378479
step: 310, loss: 0.0500895231962204
step: 320, loss: 0.03315902128815651
step: 330, loss: 0.1012764424085617
step: 340, loss: 0.07855033874511719
step: 350, loss: 0.1624838262796402
epoch 3: dev_f1=0.8254716981132074, f1=0.7674943566591421, best_f1=0.7674943566591421
step: 0, loss: 0.12459377199411392
step: 10, loss: 0.18156826496124268
step: 20, loss: 0.3161831200122833
step: 30, loss: 0.015791362151503563
step: 40, loss: 0.07890628278255463
step: 50, loss: 0.06950389593839645
step: 60, loss: 0.2033793330192566
step: 70, loss: 0.13551560044288635
step: 80, loss: 0.07724780589342117
step: 90, loss: 0.06972140073776245
step: 100, loss: 0.13297592103481293
step: 110, loss: 0.026633180677890778
step: 120, loss: 0.28428006172180176
step: 130, loss: 0.14024540781974792
step: 140, loss: 0.03990668058395386
step: 150, loss: 0.08013805747032166
step: 160, loss: 0.06243966147303581
step: 170, loss: 0.31693920493125916
step: 180, loss: 0.05227101594209671
step: 190, loss: 0.1067403256893158
step: 200, loss: 0.2001301646232605
step: 210, loss: 0.15692591667175293
step: 220, loss: 0.06590051203966141
step: 230, loss: 0.1308610588312149
step: 240, loss: 0.1358034461736679
step: 250, loss: 0.05510642006993294
step: 260, loss: 0.34435901045799255
step: 270, loss: 0.039562519639730453
step: 280, loss: 0.054313402622938156
step: 290, loss: 0.1101217120885849
step: 300, loss: 0.09232030808925629
step: 310, loss: 0.10541629046201706
step: 320, loss: 0.09077316522598267
step: 330, loss: 0.10025012493133545
step: 340, loss: 0.1191272959113121
step: 350, loss: 0.10378585010766983
epoch 4: dev_f1=0.7945205479452053, f1=0.7655913978494623, best_f1=0.7674943566591421
step: 0, loss: 0.02278531901538372
step: 10, loss: 0.08530384302139282
step: 20, loss: 0.1350717693567276
step: 30, loss: 0.07795054465532303
step: 40, loss: 0.08059033751487732
step: 50, loss: 0.1210654005408287
step: 60, loss: 0.0399598591029644
step: 70, loss: 0.2215500771999359
step: 80, loss: 0.0411551296710968
step: 90, loss: 0.21024219691753387
step: 100, loss: 0.056472454220056534
step: 110, loss: 0.0553077794611454
step: 120, loss: 0.05236731097102165
step: 130, loss: 0.135727196931839
step: 140, loss: 0.04579959437251091
step: 150, loss: 0.0015043184394016862
step: 160, loss: 0.051160939037799835
step: 170, loss: 0.06536956876516342
step: 180, loss: 0.13479004800319672
step: 190, loss: 0.10698265582323074
step: 200, loss: 0.08221472799777985
step: 210, loss: 0.038308437913656235
step: 220, loss: 0.13540306687355042
step: 230, loss: 0.10490645468235016
step: 240, loss: 0.16724063456058502
step: 250, loss: 0.10785112529993057
step: 260, loss: 0.09135648608207703
step: 270, loss: 0.06297500431537628
step: 280, loss: 0.06586791574954987
step: 290, loss: 0.06594442576169968
step: 300, loss: 0.0214997511357069
step: 310, loss: 0.12586455047130585
step: 320, loss: 0.05212833359837532
step: 330, loss: 0.13964498043060303
step: 340, loss: 0.029754241928458214
step: 350, loss: 0.05366856977343559
epoch 5: dev_f1=0.8217391304347826, f1=0.7659574468085106, best_f1=0.7674943566591421
step: 0, loss: 0.17686772346496582
step: 10, loss: 0.06149202585220337
step: 20, loss: 0.03823576122522354
step: 30, loss: 0.08673612773418427
step: 40, loss: 0.06597629189491272
step: 50, loss: 0.10299556702375412
step: 60, loss: 0.036134012043476105
step: 70, loss: 0.06628924608230591
step: 80, loss: 0.14803986251354218
step: 90, loss: 0.0897781178355217
step: 100, loss: 0.06940297782421112
step: 110, loss: 0.13937509059906006
step: 120, loss: 0.14128580689430237
step: 130, loss: 0.07348445057868958
step: 140, loss: 0.2387535125017166
step: 150, loss: 0.10742989182472229
step: 160, loss: 0.05553022027015686
step: 170, loss: 0.07525285333395004
step: 180, loss: 0.1113535463809967
step: 190, loss: 0.03248859569430351
step: 200, loss: 0.07341402769088745
step: 210, loss: 0.10052289813756943
step: 220, loss: 0.06856005638837814
step: 230, loss: 0.05539350211620331
step: 240, loss: 0.06009498983621597
step: 250, loss: 0.04586908593773842
step: 260, loss: 0.12986767292022705
step: 270, loss: 0.1061539277434349
step: 280, loss: 0.11861918866634369
step: 290, loss: 0.07136201858520508
step: 300, loss: 0.07838218659162521
step: 310, loss: 0.07908657938241959
step: 320, loss: 0.06630080193281174
step: 330, loss: 0.06496278941631317
step: 340, loss: 0.10771492123603821
step: 350, loss: 0.0364082008600235
epoch 6: dev_f1=0.8380952380952381, f1=0.8215962441314554, best_f1=0.8215962441314554
step: 0, loss: 0.1001267209649086
step: 10, loss: 0.06223858892917633
step: 20, loss: 0.17129912972450256
step: 30, loss: 0.19796350598335266
step: 40, loss: 0.04168789088726044
step: 50, loss: 0.12753072381019592
step: 60, loss: 0.13600987195968628
step: 70, loss: 0.05315235257148743
step: 80, loss: 0.09581069648265839
step: 90, loss: 0.0281280055642128
step: 100, loss: 0.10517489910125732
step: 110, loss: 0.08963220566511154
step: 120, loss: 0.11860264837741852
step: 130, loss: 0.11389560252428055
step: 140, loss: 0.07229938358068466
step: 150, loss: 0.022708559408783913
step: 160, loss: 0.05466381087899208
step: 170, loss: 0.06804843991994858
step: 180, loss: 0.06780719757080078
step: 190, loss: 0.09017186611890793
step: 200, loss: 0.039709195494651794
step: 210, loss: 0.1002461165189743
step: 220, loss: 0.0512869618833065
step: 230, loss: 0.14743827283382416
step: 240, loss: 0.1602250337600708
step: 250, loss: 0.0571560338139534
step: 260, loss: 0.03404669091105461
step: 270, loss: 0.09543590992689133
step: 280, loss: 0.11956415325403214
step: 290, loss: 0.14368821680545807
step: 300, loss: 0.01729394681751728
step: 310, loss: 0.12018612027168274
step: 320, loss: 0.11031262576580048
step: 330, loss: 0.05490768700838089
step: 340, loss: 0.15132708847522736
step: 350, loss: 0.10521940886974335
epoch 7: dev_f1=0.8201754385964913, f1=0.7906976744186047, best_f1=0.8215962441314554
step: 0, loss: 0.05463108420372009
step: 10, loss: 0.047727394849061966
step: 20, loss: 0.07194981724023819
step: 30, loss: 0.10457871854305267
step: 40, loss: 0.20444773137569427
step: 50, loss: 0.09999445080757141
step: 60, loss: 0.0846354216337204
step: 70, loss: 0.08266196399927139
step: 80, loss: 0.018218420445919037
step: 90, loss: 0.15237998962402344
step: 100, loss: 0.09830251336097717
step: 110, loss: 0.05792628601193428
step: 120, loss: 0.08672590553760529
step: 130, loss: 0.0782996416091919
step: 140, loss: 0.00494253309443593
step: 150, loss: 0.09501344710588455
step: 160, loss: 0.045308917760849
step: 170, loss: 0.08536742627620697
step: 180, loss: 0.06341592222452164
step: 190, loss: 0.02060590870678425
step: 200, loss: 0.08642235398292542
step: 210, loss: 0.07372486591339111
step: 220, loss: 0.08397290110588074
step: 230, loss: 0.14959514141082764
step: 240, loss: 0.06445734202861786
step: 250, loss: 0.05956166982650757
step: 260, loss: 0.06628677994012833
step: 270, loss: 0.1232496127486229
step: 280, loss: 0.08484245836734772
step: 290, loss: 0.07563591003417969
step: 300, loss: 0.1068001389503479
step: 310, loss: 0.10037218034267426
step: 320, loss: 0.040364932268857956
step: 330, loss: 0.11721660941839218
step: 340, loss: 0.02755359373986721
step: 350, loss: 0.09280514717102051
epoch 8: dev_f1=0.8317757009345795, f1=0.8083140877598153, best_f1=0.8215962441314554
step: 0, loss: 0.05398743227124214
step: 10, loss: 0.05845401808619499
step: 20, loss: 0.013993135653436184
step: 30, loss: 0.05457020923495293
step: 40, loss: 0.10415057837963104
step: 50, loss: 0.09073464572429657
step: 60, loss: 0.039327703416347504
step: 70, loss: 0.07128500938415527
step: 80, loss: 0.0821346566081047
step: 90, loss: 0.07036077231168747
step: 100, loss: 0.02280478924512863
step: 110, loss: 0.05339520052075386
step: 120, loss: 0.07957492768764496
step: 130, loss: 0.07222875952720642
step: 140, loss: 0.05279630422592163
step: 150, loss: 0.0642792209982872
step: 160, loss: 0.03843517601490021
step: 170, loss: 0.06134531646966934
step: 180, loss: 0.09940813481807709
step: 190, loss: 0.029285289347171783
step: 200, loss: 0.07979320734739304
step: 210, loss: 0.17765584588050842
step: 220, loss: 0.0646926537156105
step: 230, loss: 0.044793255627155304
step: 240, loss: 0.1163816750049591
step: 250, loss: 0.10902546346187592
step: 260, loss: 0.10437780618667603
step: 270, loss: 0.11558803170919418
step: 280, loss: 0.0515766367316246
step: 290, loss: 0.157734677195549
step: 300, loss: 0.0418907105922699
step: 310, loss: 0.07083059847354889
step: 320, loss: 0.05079084262251854
step: 330, loss: 0.037499263882637024
step: 340, loss: 0.08221413940191269
step: 350, loss: 0.09853554517030716
epoch 9: dev_f1=0.8302752293577982, f1=0.8045977011494253, best_f1=0.8215962441314554
step: 0, loss: 0.06594391167163849
step: 10, loss: 0.0237833634018898
step: 20, loss: 0.0972738191485405
step: 30, loss: 0.09797375649213791
step: 40, loss: 0.18213659524917603
step: 50, loss: 0.07973183691501617
step: 60, loss: 0.054238054901361465
step: 70, loss: 0.021061262115836143
step: 80, loss: 0.06972536444664001
step: 90, loss: 0.12192201614379883
step: 100, loss: 0.03949206322431564
step: 110, loss: 0.05293635278940201
step: 120, loss: 0.2183636724948883
step: 130, loss: 0.08405383676290512
step: 140, loss: 0.04504784196615219
step: 150, loss: 0.03714818134903908
step: 160, loss: 0.10377706587314606
step: 170, loss: 0.12745046615600586
step: 180, loss: 0.0982413962483406
step: 190, loss: 0.06538879126310349
step: 200, loss: 0.10631315410137177
step: 210, loss: 0.1346491575241089
step: 220, loss: 0.12513624131679535
step: 230, loss: 0.02481105364859104
step: 240, loss: 0.053596142679452896
step: 250, loss: 0.09805212914943695
step: 260, loss: 0.06288288533687592
step: 270, loss: 0.07273303717374802
step: 280, loss: 0.15805405378341675
step: 290, loss: 0.12491104751825333
step: 300, loss: 0.04807038605213165
step: 310, loss: 0.08677925169467926
step: 320, loss: 0.04167766496539116
step: 330, loss: 0.04680391401052475
step: 340, loss: 0.07173148542642593
step: 350, loss: 0.06956584751605988
epoch 10: dev_f1=0.8192219679633866, f1=0.8044943820224719, best_f1=0.8215962441314554
step: 0, loss: 0.0999818965792656
step: 10, loss: 0.07953598350286484
step: 20, loss: 0.1283866912126541
step: 30, loss: 0.12376545369625092
step: 40, loss: 0.1343640685081482
step: 50, loss: 0.09769970178604126
step: 60, loss: 0.1254933774471283
step: 70, loss: 0.13782942295074463
step: 80, loss: 0.04892845079302788
step: 90, loss: 0.028130579739809036
step: 100, loss: 0.05203639715909958
step: 110, loss: 0.0747692734003067
step: 120, loss: 0.06157783791422844
step: 130, loss: 0.12470358610153198
step: 140, loss: 0.12945616245269775
step: 150, loss: 0.07893188297748566
step: 160, loss: 0.09013300389051437
step: 170, loss: 0.17123712599277496
step: 180, loss: 0.046073682606220245
step: 190, loss: 0.030598429962992668
step: 200, loss: 0.13503044843673706
step: 210, loss: 0.08395037055015564
step: 220, loss: 0.0591571070253849
step: 230, loss: 0.13016758859157562
step: 240, loss: 0.22196075320243835
step: 250, loss: 0.1550000160932541
step: 260, loss: 0.05218789353966713
step: 270, loss: 0.04038954898715019
step: 280, loss: 0.09079567342996597
step: 290, loss: 0.1236298605799675
step: 300, loss: 0.11337322741746902
step: 310, loss: 0.06617818772792816
step: 320, loss: 0.10901781171560287
step: 330, loss: 0.10610998421907425
step: 340, loss: 0.10585509985685349
step: 350, loss: 0.11079065501689911
epoch 11: dev_f1=0.836027713625866, f1=0.7982456140350878, best_f1=0.8215962441314554
step: 0, loss: 0.09639553725719452
step: 10, loss: 0.041783593595027924
step: 20, loss: 0.155561625957489
step: 30, loss: 0.025016605854034424
step: 40, loss: 0.10190484672784805
step: 50, loss: 0.09240758419036865
step: 60, loss: 0.06549298018217087
step: 70, loss: 0.02771969698369503
step: 80, loss: 0.008510186336934566
step: 90, loss: 0.020315110683441162
step: 100, loss: 0.04814761132001877
step: 110, loss: 0.008277878165245056
step: 120, loss: 0.051221080124378204
step: 130, loss: 0.08403585106134415
step: 140, loss: 0.07890113443136215
step: 150, loss: 0.047921691089868546
step: 160, loss: 0.11749853193759918
step: 170, loss: 0.07690676301717758
step: 180, loss: 0.17035439610481262
step: 190, loss: 0.13008613884449005
step: 200, loss: 0.01520302053540945
step: 210, loss: 0.053721364587545395
step: 220, loss: 0.10161211341619492
step: 230, loss: 0.05151396617293358
step: 240, loss: 0.09307427704334259
step: 250, loss: 0.10056156665086746
step: 260, loss: 0.11302129924297333
step: 270, loss: 0.08667425811290741
step: 280, loss: 0.06353446841239929
step: 290, loss: 0.03496740758419037
step: 300, loss: 0.09134582430124283
step: 310, loss: 0.05758744478225708
step: 320, loss: 0.09813859313726425
step: 330, loss: 0.0475555844604969
step: 340, loss: 0.06142853572964668
step: 350, loss: 0.04966481402516365
epoch 12: dev_f1=0.8337349397590362, f1=0.8045454545454546, best_f1=0.8215962441314554
step: 0, loss: 0.0365808829665184
step: 10, loss: 0.12017513811588287
step: 20, loss: 0.03562140464782715
step: 30, loss: 0.013659313321113586
step: 40, loss: 0.08628197759389877
step: 50, loss: 0.03789444640278816
step: 60, loss: 0.0009759487002156675
step: 70, loss: 0.0546254925429821
step: 80, loss: 0.11085494607686996
step: 90, loss: 0.01654326170682907
step: 100, loss: 0.053034476935863495
step: 110, loss: 0.11529987305402756
step: 120, loss: 0.08163122832775116
step: 130, loss: 0.07505672425031662
step: 140, loss: 0.19336488842964172
step: 150, loss: 0.09067829698324203
step: 160, loss: 0.026615140959620476
step: 170, loss: 0.05415960028767586
step: 180, loss: 0.06412835419178009
step: 190, loss: 0.045497238636016846
step: 200, loss: 0.14309880137443542
step: 210, loss: 0.11650112271308899
step: 220, loss: 0.06996076554059982
step: 230, loss: 0.11249037086963654
step: 240, loss: 0.13096655905246735
step: 250, loss: 0.05069692060351372
step: 260, loss: 0.07758647203445435
step: 270, loss: 0.10639026761054993
step: 280, loss: 0.03617718443274498
step: 290, loss: 0.11902915686368942
step: 300, loss: 0.08607642352581024
step: 310, loss: 0.11596948653459549
step: 320, loss: 0.022708062082529068
step: 330, loss: 0.04463706910610199
step: 340, loss: 0.009934068657457829
step: 350, loss: 0.04659261927008629
epoch 13: dev_f1=0.8425925925925926, f1=0.78125, best_f1=0.78125
step: 0, loss: 0.09780173748731613
step: 10, loss: 0.12895381450653076
step: 20, loss: 0.029854746535420418
step: 30, loss: 0.06781920045614243
step: 40, loss: 0.06863392889499664
step: 50, loss: 0.14765775203704834
step: 60, loss: 0.06527650356292725
step: 70, loss: 0.036987755447626114
step: 80, loss: 0.049932293593883514
step: 90, loss: 0.08581894636154175
step: 100, loss: 0.13959378004074097
step: 110, loss: 0.10929813981056213
step: 120, loss: 0.09460274875164032
step: 130, loss: 0.13010840117931366
step: 140, loss: 0.10305515676736832
step: 150, loss: 0.01260587852448225
step: 160, loss: 0.09723812341690063
step: 170, loss: 0.045602913945913315
step: 180, loss: 0.10521654784679413
step: 190, loss: 0.09625770151615143
step: 200, loss: 0.10810569673776627
step: 210, loss: 0.06883339583873749
step: 220, loss: 0.07980738580226898
step: 230, loss: 0.031729068607091904
step: 240, loss: 0.04657820239663124
step: 250, loss: 0.08184793591499329
step: 260, loss: 0.11160460859537125
step: 270, loss: 0.054557256400585175
step: 280, loss: 0.06641199439764023
step: 290, loss: 0.07858105003833771
step: 300, loss: 0.05749812722206116
step: 310, loss: 0.15692438185214996
step: 320, loss: 0.019370298832654953
step: 330, loss: 0.011944988742470741
step: 340, loss: 0.05932857468724251
step: 350, loss: 0.08258119970560074
epoch 14: dev_f1=0.8403755868544601, f1=0.801781737193764, best_f1=0.78125
step: 0, loss: 0.10911073535680771
step: 10, loss: 0.04747885465621948
step: 20, loss: 0.02010362781584263
step: 30, loss: 0.04003433510661125
step: 40, loss: 0.05199526250362396
step: 50, loss: 0.09959647804498672
step: 60, loss: 0.14592541754245758
step: 70, loss: 0.05574467033147812
step: 80, loss: 0.017337432131171227
step: 90, loss: 0.16977514326572418
step: 100, loss: 0.07633310556411743
step: 110, loss: 0.07695209980010986
step: 120, loss: 0.126328706741333
step: 130, loss: 0.04884351044893265
step: 140, loss: 0.07067456841468811
step: 150, loss: 0.07254838943481445
step: 160, loss: 0.13545796275138855
step: 170, loss: 0.0743432492017746
step: 180, loss: 0.023899123072624207
step: 190, loss: 0.023892492055892944
step: 200, loss: 0.026982132345438004
step: 210, loss: 0.06199656054377556
step: 220, loss: 0.11863333731889725
step: 230, loss: 0.027771037071943283
step: 240, loss: 0.028166987001895905
step: 250, loss: 0.04526810720562935
step: 260, loss: 0.1252618432044983
step: 270, loss: 0.037496332079172134
step: 280, loss: 0.060547176748514175
step: 290, loss: 0.06740590184926987
step: 300, loss: 0.05385312810540199
step: 310, loss: 0.12095486372709274
step: 320, loss: 0.10026967525482178
step: 330, loss: 0.01817525178194046
step: 340, loss: 0.011505400761961937
step: 350, loss: 0.10580479353666306
epoch 15: dev_f1=0.8341013824884792, f1=0.7713004484304932, best_f1=0.78125
step: 0, loss: 0.04608533903956413
step: 10, loss: 0.12989893555641174
step: 20, loss: 0.0487213172018528
step: 30, loss: 0.023444361984729767
step: 40, loss: 0.04920755699276924
step: 50, loss: 0.09240522235631943
step: 60, loss: 0.05175196751952171
step: 70, loss: 0.0700121596455574
step: 80, loss: 0.09565464407205582
step: 90, loss: 0.0471147783100605
step: 100, loss: 0.03352319449186325
step: 110, loss: 0.05481486767530441
step: 120, loss: 0.10072232782840729
step: 130, loss: 0.10912630707025528
step: 140, loss: 0.008091021329164505
step: 150, loss: 0.28336748480796814
step: 160, loss: 0.14166422188282013
step: 170, loss: 0.018117818981409073
step: 180, loss: 0.11603349447250366
step: 190, loss: 0.08890076726675034
step: 200, loss: 0.099510058760643
step: 210, loss: 0.02916661649942398
step: 220, loss: 0.04065050557255745
step: 230, loss: 0.13046948611736298
step: 240, loss: 0.10281354933977127
step: 250, loss: 0.2018926441669464
step: 260, loss: 0.03783976286649704
step: 270, loss: 0.069131039083004
step: 280, loss: 0.06653134524822235
step: 290, loss: 0.10780929774045944
step: 300, loss: 0.04524039477109909
step: 310, loss: 0.046902500092983246
step: 320, loss: 0.15944799780845642
step: 330, loss: 0.07816154509782791
step: 340, loss: 0.05752229318022728
step: 350, loss: 0.06724189221858978
epoch 16: dev_f1=0.8254716981132074, f1=0.7972972972972973, best_f1=0.78125
step: 0, loss: 0.09353343397378922
step: 10, loss: 0.028599482029676437
step: 20, loss: 0.027444396167993546
step: 30, loss: 0.078805111348629
step: 40, loss: 0.09672049432992935
step: 50, loss: 0.03626387566328049
step: 60, loss: 0.018432501703500748
step: 70, loss: 0.07793696969747543
step: 80, loss: 0.05082085728645325
step: 90, loss: 0.07599854469299316
step: 100, loss: 0.09150703996419907
step: 110, loss: 0.029269205406308174
step: 120, loss: 0.0841929242014885
step: 130, loss: 0.08827006071805954
step: 140, loss: 0.09492790699005127
step: 150, loss: 0.031075747683644295
step: 160, loss: 0.025581898167729378
step: 170, loss: 0.13036619126796722
step: 180, loss: 0.0012352194171398878
step: 190, loss: 0.04472605884075165
step: 200, loss: 0.0008463204721920192
step: 210, loss: 0.03830839693546295
step: 220, loss: 0.10596208274364471
step: 230, loss: 0.07143709063529968
step: 240, loss: 0.16007158160209656
step: 250, loss: 0.1443214863538742
step: 260, loss: 0.06685705482959747
step: 270, loss: 0.0362187922000885
step: 280, loss: 0.13327521085739136
step: 290, loss: 0.04665355756878853
step: 300, loss: 0.0726184993982315
step: 310, loss: 0.1336059868335724
step: 320, loss: 0.00017575564561411738
step: 330, loss: 0.08551911264657974
step: 340, loss: 0.057235825806856155
step: 350, loss: 0.07737292349338531
epoch 17: dev_f1=0.8291571753986333, f1=0.7820224719101124, best_f1=0.78125
step: 0, loss: 0.10096311569213867
step: 10, loss: 0.06410590559244156
step: 20, loss: 0.11978133022785187
step: 30, loss: 0.10678725689649582
step: 40, loss: 0.04920120909810066
step: 50, loss: 0.0026284612249583006
step: 60, loss: 0.009402523748576641
step: 70, loss: 0.05698138475418091
step: 80, loss: 0.038195736706256866
step: 90, loss: 0.013770224526524544
step: 100, loss: 0.07918918877840042
step: 110, loss: 0.0007578605436719954
step: 120, loss: 0.07209299504756927
step: 130, loss: 0.014159073121845722
step: 140, loss: 0.061039529740810394
step: 150, loss: 0.11075190454721451
step: 160, loss: 0.028714817017316818
step: 170, loss: 0.05691366270184517
step: 180, loss: 0.09575115144252777
step: 190, loss: 0.08291041105985641
step: 200, loss: 0.0472988560795784
step: 210, loss: 0.029599960893392563
step: 220, loss: 0.07297596335411072
step: 230, loss: 0.03466160595417023
step: 240, loss: 0.09511370956897736
step: 250, loss: 0.06883051991462708
step: 260, loss: 0.011809750460088253
step: 270, loss: 0.09913564473390579
step: 280, loss: 0.10026641935110092
step: 290, loss: 0.025797637179493904
step: 300, loss: 0.135460764169693
step: 310, loss: 0.010235975496470928
step: 320, loss: 0.13661989569664001
step: 330, loss: 0.06335196644067764
step: 340, loss: 0.0895514264702797
step: 350, loss: 0.10773435235023499
epoch 18: dev_f1=0.8181818181818181, f1=0.7806004618937643, best_f1=0.78125
step: 0, loss: 0.026677660644054413
step: 10, loss: 0.04437590390443802
step: 20, loss: 0.07323621958494186
step: 30, loss: 0.11649175733327866
step: 40, loss: 0.06743327528238297
step: 50, loss: 0.19328320026397705
step: 60, loss: 0.07829857617616653
step: 70, loss: 0.03739216551184654
step: 80, loss: 0.14653873443603516
step: 90, loss: 0.07923650741577148
step: 100, loss: 0.1012691929936409
step: 110, loss: 0.1281035989522934
step: 120, loss: 0.045071061700582504
step: 130, loss: 0.05720796808600426
step: 140, loss: 0.0007821908802725375
step: 150, loss: 0.027676783502101898
step: 160, loss: 3.123165151919238e-05
step: 170, loss: 0.018682170659303665
step: 180, loss: 0.06760857254266739
step: 190, loss: 0.1117815226316452
step: 200, loss: 0.12701284885406494
step: 210, loss: 0.13189241290092468
step: 220, loss: 0.10215303301811218
step: 230, loss: 0.052629560232162476
step: 240, loss: 0.07708021253347397
step: 250, loss: 0.08784219622612
step: 260, loss: 0.01927880570292473
step: 270, loss: 0.0970836952328682
step: 280, loss: 0.03431186452507973
step: 290, loss: 0.07526804506778717
step: 300, loss: 0.07625214755535126
step: 310, loss: 0.031261514872312546
step: 320, loss: 0.0627281591296196
step: 330, loss: 0.020399508997797966
step: 340, loss: 0.07012081891298294
step: 350, loss: 0.07186909019947052
epoch 19: dev_f1=0.8171021377672211, f1=0.7790432801822323, best_f1=0.78125
step: 0, loss: 0.07918468862771988
step: 10, loss: 0.010513723827898502
step: 20, loss: 0.010860110633075237
step: 30, loss: 0.14624378085136414
step: 40, loss: 0.06002403050661087
step: 50, loss: 0.09870758652687073
step: 60, loss: 0.10550177097320557
step: 70, loss: 0.029027536511421204
step: 80, loss: 0.03957702964544296
step: 90, loss: 0.021431099623441696
step: 100, loss: 0.008687183260917664
step: 110, loss: 0.028993424028158188
step: 120, loss: 0.07236586511135101
step: 130, loss: 0.023328550159931183
step: 140, loss: 0.07077302783727646
step: 150, loss: 0.04549286514520645
step: 160, loss: 0.05104764923453331
step: 170, loss: 0.1030726507306099
step: 180, loss: 0.009562523104250431
step: 190, loss: 0.09249073266983032
step: 200, loss: 0.06014076992869377
step: 210, loss: 0.1400311142206192
step: 220, loss: 0.1083570271730423
step: 230, loss: 0.048985548317432404
step: 240, loss: 0.08345144987106323
step: 250, loss: 0.012466802261769772
step: 260, loss: 0.07676460593938828
step: 270, loss: 0.05738627538084984
step: 280, loss: 0.06472688913345337
step: 290, loss: 0.040646713227033615
step: 300, loss: 0.13936375081539154
step: 310, loss: 0.023064464330673218
step: 320, loss: 0.09622752666473389
step: 330, loss: 0.05068563297390938
step: 340, loss: 0.04999958723783493
step: 350, loss: 0.16273902356624603
epoch 20: dev_f1=0.8166259168704155, f1=0.7830188679245284, best_f1=0.78125
