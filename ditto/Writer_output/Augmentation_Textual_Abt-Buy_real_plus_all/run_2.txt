cuda
Device: cuda
step: 0, loss: 0.9577064514160156
step: 10, loss: 0.2086300551891327
step: 20, loss: 0.088019959628582
step: 30, loss: 0.24023215472698212
step: 40, loss: 0.31209230422973633
step: 50, loss: 0.2282724380493164
step: 60, loss: 0.18953180313110352
step: 70, loss: 0.23684988915920258
step: 80, loss: 0.24105210602283478
step: 90, loss: 0.181946262717247
step: 100, loss: 0.3136948049068451
step: 110, loss: 0.4359961450099945
step: 120, loss: 0.36131715774536133
step: 130, loss: 0.3129807412624359
step: 140, loss: 0.25079262256622314
step: 150, loss: 0.28865060210227966
step: 160, loss: 0.3521077632904053
step: 170, loss: 0.16388140618801117
step: 180, loss: 0.3384856581687927
step: 190, loss: 0.17635639011859894
step: 200, loss: 0.3871278762817383
step: 210, loss: 0.36561521887779236
step: 220, loss: 0.1496540904045105
step: 230, loss: 0.4019733965396881
step: 240, loss: 0.23410318791866302
step: 250, loss: 0.2484063357114792
step: 260, loss: 0.2773553133010864
step: 270, loss: 0.2930940091609955
step: 280, loss: 0.23769846558570862
step: 290, loss: 0.4017573595046997
step: 300, loss: 0.41259852051734924
step: 310, loss: 0.18118499219417572
step: 320, loss: 0.2099124640226364
step: 330, loss: 0.20605812966823578
step: 340, loss: 0.2860619127750397
step: 350, loss: 0.14152595400810242
epoch 1: dev_f1=0.3320158102766798, f1=0.2663934426229508, best_f1=0.2663934426229508
step: 0, loss: 0.45982474088668823
step: 10, loss: 0.3992021679878235
step: 20, loss: 0.20619244873523712
step: 30, loss: 0.27263906598091125
step: 40, loss: 0.1255173236131668
step: 50, loss: 0.3123292922973633
step: 60, loss: 0.5099769830703735
step: 70, loss: 0.21091486513614655
step: 80, loss: 0.2584637701511383
step: 90, loss: 0.19722582399845123
step: 100, loss: 0.15655727684497833
step: 110, loss: 0.1805306375026703
step: 120, loss: 0.08062169700860977
step: 130, loss: 0.3796721398830414
step: 140, loss: 0.27167263627052307
step: 150, loss: 0.16815616190433502
step: 160, loss: 0.06726256757974625
step: 170, loss: 0.24143235385417938
step: 180, loss: 0.12663811445236206
step: 190, loss: 0.14250482618808746
step: 200, loss: 0.12956273555755615
step: 210, loss: 0.2339038848876953
step: 220, loss: 0.10508047044277191
step: 230, loss: 0.24706204235553741
step: 240, loss: 0.22196941077709198
step: 250, loss: 0.1495952606201172
step: 260, loss: 0.08462517708539963
step: 270, loss: 0.19017447531223297
step: 280, loss: 0.13423095643520355
step: 290, loss: 0.13396471738815308
step: 300, loss: 0.22108817100524902
step: 310, loss: 0.17172518372535706
step: 320, loss: 0.11779183149337769
step: 330, loss: 0.14628615975379944
step: 340, loss: 0.2630181610584259
step: 350, loss: 0.23321951925754547
epoch 2: dev_f1=0.6899563318777292, f1=0.6864406779661018, best_f1=0.6864406779661018
step: 0, loss: 0.13268449902534485
step: 10, loss: 0.1352037936449051
step: 20, loss: 0.09471799433231354
step: 30, loss: 0.11275378614664078
step: 40, loss: 0.09962627291679382
step: 50, loss: 0.23375999927520752
step: 60, loss: 0.1393953412771225
step: 70, loss: 0.08676155656576157
step: 80, loss: 0.1473534256219864
step: 90, loss: 0.1851547509431839
step: 100, loss: 0.3069988787174225
step: 110, loss: 0.3244686722755432
step: 120, loss: 0.08338326215744019
step: 130, loss: 0.20624341070652008
step: 140, loss: 0.07536065578460693
step: 150, loss: 0.10892385244369507
step: 160, loss: 0.08203523606061935
step: 170, loss: 0.15491166710853577
step: 180, loss: 0.12042911350727081
step: 190, loss: 0.1056889072060585
step: 200, loss: 0.07014601677656174
step: 210, loss: 0.12297747284173965
step: 220, loss: 0.2743203938007355
step: 230, loss: 0.17499876022338867
step: 240, loss: 0.05015411227941513
step: 250, loss: 0.12296654284000397
step: 260, loss: 0.1861332654953003
step: 270, loss: 0.1965864896774292
step: 280, loss: 0.0944942831993103
step: 290, loss: 0.1772490292787552
step: 300, loss: 0.14444191753864288
step: 310, loss: 0.1347251534461975
step: 320, loss: 0.13180695474147797
step: 330, loss: 0.10180822014808655
step: 340, loss: 0.09206269681453705
step: 350, loss: 0.15737544000148773
epoch 3: dev_f1=0.7596153846153846, f1=0.7627906976744185, best_f1=0.7627906976744185
step: 0, loss: 0.07675886154174805
step: 10, loss: 0.13115456700325012
step: 20, loss: 0.03739074245095253
step: 30, loss: 0.11292033642530441
step: 40, loss: 0.13356482982635498
step: 50, loss: 0.1046590581536293
step: 60, loss: 0.1183551624417305
step: 70, loss: 0.10221327841281891
step: 80, loss: 0.14813371002674103
step: 90, loss: 0.07651837170124054
step: 100, loss: 0.13870243728160858
step: 110, loss: 0.06105247139930725
step: 120, loss: 0.07485460489988327
step: 130, loss: 0.055749114602804184
step: 140, loss: 0.06420484185218811
step: 150, loss: 0.06614801287651062
step: 160, loss: 0.16215932369232178
step: 170, loss: 0.0842595249414444
step: 180, loss: 0.12180808931589127
step: 190, loss: 0.09433287382125854
step: 200, loss: 0.1052686870098114
step: 210, loss: 0.08629462867975235
step: 220, loss: 0.04894876107573509
step: 230, loss: 0.16525207459926605
step: 240, loss: 0.0699865072965622
step: 250, loss: 0.14831647276878357
step: 260, loss: 0.08360100537538528
step: 270, loss: 0.07572745531797409
step: 280, loss: 0.11635351181030273
step: 290, loss: 0.1494235247373581
step: 300, loss: 0.16293731331825256
step: 310, loss: 0.057972878217697144
step: 320, loss: 0.11609414964914322
step: 330, loss: 0.03956284373998642
step: 340, loss: 0.09754032641649246
step: 350, loss: 0.06151675432920456
epoch 4: dev_f1=0.7746478873239437, f1=0.7654867256637168, best_f1=0.7654867256637168
step: 0, loss: 0.06802532076835632
step: 10, loss: 0.10482364892959595
step: 20, loss: 0.11768884211778641
step: 30, loss: 0.07185608148574829
step: 40, loss: 0.14412769675254822
step: 50, loss: 0.12634095549583435
step: 60, loss: 0.10180974006652832
step: 70, loss: 0.0708591565489769
step: 80, loss: 0.03209500387310982
step: 90, loss: 0.002963999519124627
step: 100, loss: 0.14864696562290192
step: 110, loss: 0.11517883837223053
step: 120, loss: 0.08685365319252014
step: 130, loss: 0.22658976912498474
step: 140, loss: 0.09631314873695374
step: 150, loss: 0.08923190832138062
step: 160, loss: 0.070974200963974
step: 170, loss: 0.16969387233257294
step: 180, loss: 0.0645015612244606
step: 190, loss: 0.03473919257521629
step: 200, loss: 0.019471846520900726
step: 210, loss: 0.3437631130218506
step: 220, loss: 0.12766607105731964
step: 230, loss: 0.32925453782081604
step: 240, loss: 0.05603429675102234
step: 250, loss: 0.10438283532857895
step: 260, loss: 0.1395169496536255
step: 270, loss: 0.1520542949438095
step: 280, loss: 0.14532408118247986
step: 290, loss: 0.01892828196287155
step: 300, loss: 0.04536810517311096
step: 310, loss: 0.18788132071495056
step: 320, loss: 0.20176178216934204
step: 330, loss: 0.10520493239164352
step: 340, loss: 0.05240534245967865
step: 350, loss: 0.06451906263828278
epoch 5: dev_f1=0.7706013363028953, f1=0.7536842105263158, best_f1=0.7654867256637168
step: 0, loss: 0.1250000298023224
step: 10, loss: 0.11502472311258316
step: 20, loss: 0.07150592654943466
step: 30, loss: 0.15691739320755005
step: 40, loss: 0.057419970631599426
step: 50, loss: 0.06388112902641296
step: 60, loss: 0.06521883606910706
step: 70, loss: 0.12928687036037445
step: 80, loss: 0.014161628670990467
step: 90, loss: 0.04029424116015434
step: 100, loss: 0.1362796127796173
step: 110, loss: 0.0838412418961525
step: 120, loss: 0.01947917602956295
step: 130, loss: 0.18798746168613434
step: 140, loss: 0.046777620911598206
step: 150, loss: 0.02300366945564747
step: 160, loss: 0.16643911600112915
step: 170, loss: 0.0004016051534563303
step: 180, loss: 0.13097956776618958
step: 190, loss: 0.16256573796272278
step: 200, loss: 0.13261458277702332
step: 210, loss: 0.08323991298675537
step: 220, loss: 0.12843912839889526
step: 230, loss: 0.05114554986357689
step: 240, loss: 0.02770242653787136
step: 250, loss: 0.17380593717098236
step: 260, loss: 0.09328902512788773
step: 270, loss: 0.08975623548030853
step: 280, loss: 0.021178225055336952
step: 290, loss: 0.09758971631526947
step: 300, loss: 0.2310405820608139
step: 310, loss: 0.006496120244264603
step: 320, loss: 0.13563218712806702
step: 330, loss: 0.16149502992630005
step: 340, loss: 0.018911590799689293
step: 350, loss: 0.05398792400956154
epoch 6: dev_f1=0.7932692307692307, f1=0.7770114942528735, best_f1=0.7770114942528735
step: 0, loss: 0.04803299903869629
step: 10, loss: 0.10439279675483704
step: 20, loss: 0.011135577224195004
step: 30, loss: 0.15770559012889862
step: 40, loss: 0.1395946741104126
step: 50, loss: 0.10352086275815964
step: 60, loss: 0.1699894219636917
step: 70, loss: 0.07189373672008514
step: 80, loss: 0.028262631967663765
step: 90, loss: 0.09549842774868011
step: 100, loss: 0.0888022854924202
step: 110, loss: 0.11154553294181824
step: 120, loss: 0.06625288724899292
step: 130, loss: 0.20098546147346497
step: 140, loss: 0.15396785736083984
step: 150, loss: 0.04948894679546356
step: 160, loss: 0.04821682721376419
step: 170, loss: 0.049117472022771835
step: 180, loss: 0.13432565331459045
step: 190, loss: 0.08741829544305801
step: 200, loss: 0.08848672360181808
step: 210, loss: 0.07801274955272675
step: 220, loss: 0.08622279763221741
step: 230, loss: 0.13649088144302368
step: 240, loss: 0.106438547372818
step: 250, loss: 0.162411630153656
step: 260, loss: 0.04932888597249985
step: 270, loss: 0.07658229023218155
step: 280, loss: 0.14845900237560272
step: 290, loss: 0.025412511080503464
step: 300, loss: 0.07362422347068787
step: 310, loss: 0.1491030901670456
step: 320, loss: 0.09237438440322876
step: 330, loss: 0.06557159870862961
step: 340, loss: 0.05352142080664635
step: 350, loss: 0.054839007556438446
epoch 7: dev_f1=0.78125, f1=0.7699115044247787, best_f1=0.7770114942528735
step: 0, loss: 0.08938240259885788
step: 10, loss: 0.13459372520446777
step: 20, loss: 0.06541801244020462
step: 30, loss: 0.06976483017206192
step: 40, loss: 0.03965163230895996
step: 50, loss: 0.12314077466726303
step: 60, loss: 0.07459460198879242
step: 70, loss: 0.16644299030303955
step: 80, loss: 0.06872384250164032
step: 90, loss: 0.12607520818710327
step: 100, loss: 0.09372026473283768
step: 110, loss: 0.06634104251861572
step: 120, loss: 0.06806732714176178
step: 130, loss: 0.07121794670820236
step: 140, loss: 0.031493403017520905
step: 150, loss: 0.0740424171090126
step: 160, loss: 0.09303370863199234
step: 170, loss: 0.02150009572505951
step: 180, loss: 0.03831549733877182
step: 190, loss: 0.17969530820846558
step: 200, loss: 0.11088388413190842
step: 210, loss: 0.054678767919540405
step: 220, loss: 0.042524199932813644
step: 230, loss: 0.11738382279872894
step: 240, loss: 0.16519251465797424
step: 250, loss: 0.05263717100024223
step: 260, loss: 0.09944320470094681
step: 270, loss: 0.06431788206100464
step: 280, loss: 0.10123373568058014
step: 290, loss: 0.02025333046913147
step: 300, loss: 0.07191325724124908
step: 310, loss: 0.10833747684955597
step: 320, loss: 0.09740526974201202
step: 330, loss: 0.1561448574066162
step: 340, loss: 0.07941325008869171
step: 350, loss: 0.04703957960009575
epoch 8: dev_f1=0.7628361858190709, f1=0.7559808612440191, best_f1=0.7770114942528735
step: 0, loss: 0.0835239514708519
step: 10, loss: 0.08952346444129944
step: 20, loss: 0.12113412469625473
step: 30, loss: 0.008241510018706322
step: 40, loss: 0.07131291180849075
step: 50, loss: 0.06033025681972504
step: 60, loss: 0.15535758435726166
step: 70, loss: 0.0927414521574974
step: 80, loss: 0.02812606655061245
step: 90, loss: 0.06864171475172043
step: 100, loss: 0.05790296941995621
step: 110, loss: 0.17936263978481293
step: 120, loss: 0.05335573852062225
step: 130, loss: 0.0743258148431778
step: 140, loss: 0.11640163511037827
step: 150, loss: 0.1902545541524887
step: 160, loss: 0.09810947626829147
step: 170, loss: 0.0657879039645195
step: 180, loss: 0.11640772968530655
step: 190, loss: 0.05646013841032982
step: 200, loss: 0.0696001648902893
step: 210, loss: 0.16807827353477478
step: 220, loss: 0.17093411087989807
step: 230, loss: 0.08000241219997406
step: 240, loss: 0.08141117542982101
step: 250, loss: 0.17659731209278107
step: 260, loss: 0.021510299295186996
step: 270, loss: 0.03409074991941452
step: 280, loss: 0.005438110325485468
step: 290, loss: 0.13435615599155426
step: 300, loss: 0.00397050566971302
step: 310, loss: 0.12380338460206985
step: 320, loss: 0.016216352581977844
step: 330, loss: 0.1643325239419937
step: 340, loss: 0.06565559655427933
step: 350, loss: 0.07315508276224136
epoch 9: dev_f1=0.7818181818181817, f1=0.767816091954023, best_f1=0.7770114942528735
step: 0, loss: 0.01776585541665554
step: 10, loss: 0.08378396928310394
step: 20, loss: 0.07735272496938705
step: 30, loss: 0.025390900671482086
step: 40, loss: 0.12245304137468338
step: 50, loss: 0.07226507365703583
step: 60, loss: 0.1585129201412201
step: 70, loss: 0.07313289493322372
step: 80, loss: 0.11332198977470398
step: 90, loss: 0.1377638578414917
step: 100, loss: 0.03984089195728302
step: 110, loss: 0.05642836540937424
step: 120, loss: 0.0152947548776865
step: 130, loss: 0.057952750474214554
step: 140, loss: 0.07521600276231766
step: 150, loss: 0.0320676751434803
step: 160, loss: 0.0004906798712909222
step: 170, loss: 0.011139458045363426
step: 180, loss: 0.10440713912248611
step: 190, loss: 0.0885470062494278
step: 200, loss: 0.027687523514032364
step: 210, loss: 0.09464883804321289
step: 220, loss: 0.03954194113612175
step: 230, loss: 0.07016324996948242
step: 240, loss: 0.050163425505161285
step: 250, loss: 0.06638376414775848
step: 260, loss: 0.11249642074108124
step: 270, loss: 0.07846304774284363
step: 280, loss: 0.13246245682239532
step: 290, loss: 0.05159219726920128
step: 300, loss: 0.054892778396606445
step: 310, loss: 0.07546163350343704
step: 320, loss: 0.020266378298401833
step: 330, loss: 0.11056889593601227
step: 340, loss: 0.10643542557954788
step: 350, loss: 0.015497983433306217
epoch 10: dev_f1=0.7951219512195121, f1=0.7834101382488479, best_f1=0.7834101382488479
step: 0, loss: 0.08725136518478394
step: 10, loss: 0.08232032507658005
step: 20, loss: 0.07956065237522125
step: 30, loss: 0.01140554528683424
step: 40, loss: 0.09342966228723526
step: 50, loss: 0.02495615929365158
step: 60, loss: 0.009037886746227741
step: 70, loss: 0.013252627104520798
step: 80, loss: 0.12097395211458206
step: 90, loss: 0.08203459531068802
step: 100, loss: 0.03464242443442345
step: 110, loss: 0.1150582954287529
step: 120, loss: 0.09694522619247437
step: 130, loss: 0.06141383945941925
step: 140, loss: 0.22657394409179688
step: 150, loss: 0.0530829094350338
step: 160, loss: 0.09101126343011856
step: 170, loss: 0.10204645991325378
step: 180, loss: 0.08810637891292572
step: 190, loss: 0.06174246594309807
step: 200, loss: 0.060822173953056335
step: 210, loss: 0.044347722083330154
step: 220, loss: 0.0851348489522934
step: 230, loss: 0.13503144681453705
step: 240, loss: 0.17102956771850586
step: 250, loss: 0.06053953990340233
step: 260, loss: 0.12918508052825928
step: 270, loss: 0.041941069066524506
step: 280, loss: 0.08109227567911148
step: 290, loss: 0.10554834455251694
step: 300, loss: 0.13263154029846191
step: 310, loss: 0.02926468476653099
step: 320, loss: 0.0793045237660408
step: 330, loss: 0.1024334505200386
step: 340, loss: 0.13142885267734528
step: 350, loss: 0.3012687861919403
epoch 11: dev_f1=0.8058968058968059, f1=0.7813267813267812, best_f1=0.7813267813267812
step: 0, loss: 0.09764718264341354
step: 10, loss: 0.12974834442138672
step: 20, loss: 0.14365489780902863
step: 30, loss: 0.10516095906496048
step: 40, loss: 0.015346797183156013
step: 50, loss: 0.00042414074414409697
step: 60, loss: 0.08710960298776627
step: 70, loss: 0.13257555663585663
step: 80, loss: 0.04395454376935959
step: 90, loss: 0.11557085067033768
step: 100, loss: 0.04400055482983589
step: 110, loss: 0.13391231000423431
step: 120, loss: 0.05975957587361336
step: 130, loss: 0.07828851044178009
step: 140, loss: 0.08131713420152664
step: 150, loss: 0.10402961075305939
step: 160, loss: 0.12749695777893066
step: 170, loss: 0.027016326785087585
step: 180, loss: 0.07608399540185928
step: 190, loss: 0.10752472281455994
step: 200, loss: 0.04683844372630119
step: 210, loss: 0.04214061424136162
step: 220, loss: 0.04626639559864998
step: 230, loss: 0.10336201637983322
step: 240, loss: 0.020180629566311836
step: 250, loss: 0.11378113180398941
step: 260, loss: 0.09165766090154648
step: 270, loss: 0.20616133511066437
step: 280, loss: 0.05369644612073898
step: 290, loss: 0.0453057736158371
step: 300, loss: 0.08580578118562698
step: 310, loss: 0.14742061495780945
step: 320, loss: 0.08278872817754745
step: 330, loss: 0.16523754596710205
step: 340, loss: 0.09734553098678589
step: 350, loss: 0.0651082918047905
epoch 12: dev_f1=0.7875894988066825, f1=0.7790432801822323, best_f1=0.7813267813267812
step: 0, loss: 0.1374400407075882
step: 10, loss: 0.03460113704204559
step: 20, loss: 0.033208299428224564
step: 30, loss: 0.056336306035518646
step: 40, loss: 0.003251961199566722
step: 50, loss: 0.0592242032289505
step: 60, loss: 0.2088913768529892
step: 70, loss: 0.02066013589501381
step: 80, loss: 0.08118598163127899
step: 90, loss: 0.03854617848992348
step: 100, loss: 0.11508345603942871
step: 110, loss: 0.04533514752984047
step: 120, loss: 0.0744548812508583
step: 130, loss: 0.07667025923728943
step: 140, loss: 0.11188273131847382
step: 150, loss: 0.060695186257362366
step: 160, loss: 0.037450555711984634
step: 170, loss: 0.05810897424817085
step: 180, loss: 0.09102721512317657
step: 190, loss: 0.08191558718681335
step: 200, loss: 0.08136171102523804
step: 210, loss: 0.09703981876373291
step: 220, loss: 0.04193413257598877
step: 230, loss: 0.09203427284955978
step: 240, loss: 0.088852159678936
step: 250, loss: 0.11959382146596909
step: 260, loss: 0.09757227450609207
step: 270, loss: 0.03339039161801338
step: 280, loss: 0.06441399455070496
step: 290, loss: 0.14948174357414246
step: 300, loss: 0.0290277898311615
step: 310, loss: 0.14565815031528473
step: 320, loss: 0.05254628509283066
step: 330, loss: 0.05439356714487076
step: 340, loss: 0.020263753831386566
step: 350, loss: 0.08516451716423035
epoch 13: dev_f1=0.7729468599033817, f1=0.7767441860465116, best_f1=0.7813267813267812
step: 0, loss: 0.06279069185256958
step: 10, loss: 0.1322043538093567
step: 20, loss: 0.003761747619137168
step: 30, loss: 0.009913317859172821
step: 40, loss: 0.05181138962507248
step: 50, loss: 0.04049200937151909
step: 60, loss: 0.08965142071247101
step: 70, loss: 0.09375353902578354
step: 80, loss: 0.0798545628786087
step: 90, loss: 0.06111055985093117
step: 100, loss: 0.0878203958272934
step: 110, loss: 0.06014286354184151
step: 120, loss: 0.07052513211965561
step: 130, loss: 0.1378972977399826
step: 140, loss: 0.04076040908694267
step: 150, loss: 0.07496239244937897
step: 160, loss: 0.04985545948147774
step: 170, loss: 0.05891837179660797
step: 180, loss: 0.10403098911046982
step: 190, loss: 0.2025124579668045
step: 200, loss: 0.15102213621139526
step: 210, loss: 0.027523892000317574
step: 220, loss: 0.03412999212741852
step: 230, loss: 0.053960271179676056
step: 240, loss: 0.03130801394581795
step: 250, loss: 0.13552488386631012
step: 260, loss: 0.08330938965082169
step: 270, loss: 0.0319051593542099
step: 280, loss: 0.09102319926023483
step: 290, loss: 0.05436117947101593
step: 300, loss: 0.08616282790899277
step: 310, loss: 0.035312727093696594
step: 320, loss: 0.15250451862812042
step: 330, loss: 0.07106949388980865
step: 340, loss: 0.036910030990839005
step: 350, loss: 0.06721682101488113
epoch 14: dev_f1=0.8037383177570093, f1=0.7737556561085972, best_f1=0.7813267813267812
step: 0, loss: 0.04556799679994583
step: 10, loss: 0.07806282490491867
step: 20, loss: 0.03955578804016113
step: 30, loss: 0.18253114819526672
step: 40, loss: 0.04312586411833763
step: 50, loss: 0.06517018377780914
step: 60, loss: 0.029190517961978912
step: 70, loss: 0.16314943134784698
step: 80, loss: 0.06839217245578766
step: 90, loss: 0.12614591419696808
step: 100, loss: 0.09024535119533539
step: 110, loss: 0.08786086738109589
step: 120, loss: 0.05446217581629753
step: 130, loss: 0.022276269271969795
step: 140, loss: 0.10075442492961884
step: 150, loss: 0.045918479561805725
step: 160, loss: 0.10538560897111893
step: 170, loss: 0.09550220519304276
step: 180, loss: 0.04645667225122452
step: 190, loss: 0.005585418548434973
step: 200, loss: 0.041302599012851715
step: 210, loss: 0.08788175880908966
step: 220, loss: 0.11104585230350494
step: 230, loss: 0.15293045341968536
step: 240, loss: 0.08050636947154999
step: 250, loss: 0.051418669521808624
step: 260, loss: 0.033567409962415695
step: 270, loss: 0.055193495005369186
step: 280, loss: 0.08899246156215668
step: 290, loss: 0.0762372687458992
step: 300, loss: 0.17413641512393951
step: 310, loss: 0.07193559408187866
step: 320, loss: 0.11955637484788895
step: 330, loss: 0.09688472002744675
step: 340, loss: 0.020038828253746033
step: 350, loss: 0.06077759712934494
epoch 15: dev_f1=0.7807228915662651, f1=0.7834101382488479, best_f1=0.7813267813267812
step: 0, loss: 0.00031403108732774854
step: 10, loss: 0.0673733726143837
step: 20, loss: 0.05734757333993912
step: 30, loss: 0.06631936877965927
step: 40, loss: 0.02946857362985611
step: 50, loss: 0.16611473262310028
step: 60, loss: 0.09253410995006561
step: 70, loss: 0.07085949927568436
step: 80, loss: 0.10589245706796646
step: 90, loss: 0.0400192067027092
step: 100, loss: 0.02851751260459423
step: 110, loss: 0.05123134329915047
step: 120, loss: 0.0457892082631588
step: 130, loss: 0.0200657956302166
step: 140, loss: 0.049028266221284866
step: 150, loss: 0.02869993820786476
step: 160, loss: 0.036053482443094254
step: 170, loss: 0.0008354728342965245
step: 180, loss: 0.03544103726744652
step: 190, loss: 0.04476494342088699
step: 200, loss: 0.009403121657669544
step: 210, loss: 0.03984469547867775
step: 220, loss: 0.1039004698395729
step: 230, loss: 0.042516469955444336
step: 240, loss: 0.07001940160989761
step: 250, loss: 0.11528215557336807
step: 260, loss: 0.09000416845083237
step: 270, loss: 0.06833142042160034
step: 280, loss: 0.04527285322546959
step: 290, loss: 0.07606914639472961
step: 300, loss: 0.06727021187543869
step: 310, loss: 0.15961013734340668
step: 320, loss: 0.0008983818115666509
step: 330, loss: 0.01785345748066902
step: 340, loss: 0.09921051561832428
step: 350, loss: 0.06841854751110077
epoch 16: dev_f1=0.7980295566502462, f1=0.7749419953596287, best_f1=0.7813267813267812
step: 0, loss: 0.06722363084554672
step: 10, loss: 0.032917141914367676
step: 20, loss: 0.024296345189213753
step: 30, loss: 0.12439402937889099
step: 40, loss: 0.03840462490916252
step: 50, loss: 0.04391052946448326
step: 60, loss: 0.022069912403821945
step: 70, loss: 0.10971347987651825
step: 80, loss: 0.06760159879922867
step: 90, loss: 0.10070259869098663
step: 100, loss: 0.09207075089216232
step: 110, loss: 0.025916041806340218
step: 120, loss: 0.01831897720694542
step: 130, loss: 0.08614489436149597
step: 140, loss: 0.1367122381925583
step: 150, loss: 0.0362662635743618
step: 160, loss: 0.04991884529590607
step: 170, loss: 0.028555655851960182
step: 180, loss: 0.09331955015659332
step: 190, loss: 0.03630245476961136
step: 200, loss: 0.023406241089105606
step: 210, loss: 0.028460515663027763
step: 220, loss: 0.01809069514274597
step: 230, loss: 0.03179727867245674
step: 240, loss: 0.06383249163627625
step: 250, loss: 4.73421168862842e-05
step: 260, loss: 0.048345137387514114
step: 270, loss: 0.062239933758974075
step: 280, loss: 0.04840627312660217
step: 290, loss: 0.1525753140449524
step: 300, loss: 0.2794363796710968
step: 310, loss: 0.029661644250154495
step: 320, loss: 0.061552561819553375
step: 330, loss: 0.03198717162013054
step: 340, loss: 0.037842705845832825
step: 350, loss: 0.031134773045778275
epoch 17: dev_f1=0.8069306930693069, f1=0.7811764705882352, best_f1=0.7811764705882352
step: 0, loss: 0.038795821368694305
step: 10, loss: 0.18297643959522247
step: 20, loss: 0.06148301810026169
step: 30, loss: 0.08973685652017593
step: 40, loss: 0.00018543616170063615
step: 50, loss: 0.07794854789972305
step: 60, loss: 0.11701163649559021
step: 70, loss: 0.02604324370622635
step: 80, loss: 0.0571647547185421
step: 90, loss: 0.10907837748527527
step: 100, loss: 0.13327878713607788
step: 110, loss: 0.14110167324543
step: 120, loss: 0.06667312234640121
step: 130, loss: 0.0008617826388217509
step: 140, loss: 0.03833358734846115
step: 150, loss: 0.05625895410776138
step: 160, loss: 0.11001638323068619
step: 170, loss: 0.07567035406827927
step: 180, loss: 0.053087878972291946
step: 190, loss: 0.0647539347410202
step: 200, loss: 0.03667805716395378
step: 210, loss: 0.018464000895619392
step: 220, loss: 0.034221865236759186
step: 230, loss: 0.04084296151995659
step: 240, loss: 0.054321981966495514
step: 250, loss: 0.07193942368030548
step: 260, loss: 0.06435617804527283
step: 270, loss: 0.0838305652141571
step: 280, loss: 0.029079152271151543
step: 290, loss: 0.04217181354761124
step: 300, loss: 0.02779293991625309
step: 310, loss: 0.03695075958967209
step: 320, loss: 0.049623191356658936
step: 330, loss: 0.020052244886755943
step: 340, loss: 0.11728762835264206
step: 350, loss: 0.025055646896362305
epoch 18: dev_f1=0.8, f1=0.7670588235294118, best_f1=0.7811764705882352
step: 0, loss: 0.1003994345664978
step: 10, loss: 0.0003978613531216979
step: 20, loss: 0.0770682692527771
step: 30, loss: 0.09882694482803345
step: 40, loss: 0.09446161240339279
step: 50, loss: 0.04952750355005264
step: 60, loss: 0.11851233243942261
step: 70, loss: 0.021682199090719223
step: 80, loss: 0.05190327763557434
step: 90, loss: 0.08546009659767151
step: 100, loss: 0.09384352713823318
step: 110, loss: 0.010448489338159561
step: 120, loss: 0.040532130748033524
step: 130, loss: 0.059434060007333755
step: 140, loss: 0.05521233379840851
step: 150, loss: 0.020119957625865936
step: 160, loss: 0.021618280559778214
step: 170, loss: 0.03468592092394829
step: 180, loss: 4.6935860154917464e-05
step: 190, loss: 0.19424784183502197
step: 200, loss: 0.05041546747088432
step: 210, loss: 0.01976165920495987
step: 220, loss: 0.01594913750886917
step: 230, loss: 0.0024721575900912285
step: 240, loss: 0.027578730136156082
step: 250, loss: 0.07053108513355255
step: 260, loss: 0.06129062548279762
step: 270, loss: 0.01578436605632305
step: 280, loss: 0.0001589183375472203
step: 290, loss: 0.13774625957012177
step: 300, loss: 0.004870685748755932
step: 310, loss: 0.052468448877334595
step: 320, loss: 0.00013955196482129395
step: 330, loss: 0.14311206340789795
step: 340, loss: 0.014016189612448215
step: 350, loss: 0.051813483238220215
epoch 19: dev_f1=0.8067632850241547, f1=0.7785547785547785, best_f1=0.7811764705882352
step: 0, loss: 0.04513595253229141
step: 10, loss: 0.0903826430439949
step: 20, loss: 0.05599231645464897
step: 30, loss: 0.12623415887355804
step: 40, loss: 0.034506428986787796
step: 50, loss: 0.06315451115369797
step: 60, loss: 0.039827603846788406
step: 70, loss: 0.07975129783153534
step: 80, loss: 0.05289692059159279
step: 90, loss: 0.03934352099895477
step: 100, loss: 0.03245483338832855
step: 110, loss: 0.0682203620672226
step: 120, loss: 0.002760239876806736
step: 130, loss: 0.055705707520246506
step: 140, loss: 0.07864341884851456
step: 150, loss: 0.05079935863614082
step: 160, loss: 0.028047572821378708
step: 170, loss: 0.029227297753095627
step: 180, loss: 0.038845840841531754
step: 190, loss: 0.02754495106637478
step: 200, loss: 0.07798722386360168
step: 210, loss: 0.0790281668305397
step: 220, loss: 0.03159899264574051
step: 230, loss: 0.11509428918361664
step: 240, loss: 0.045354217290878296
step: 250, loss: 0.12890715897083282
step: 260, loss: 0.06081352382898331
step: 270, loss: 0.1500537246465683
step: 280, loss: 0.07310327142477036
step: 290, loss: 0.05961333215236664
step: 300, loss: 0.1007000282406807
step: 310, loss: 0.09096992015838623
step: 320, loss: 0.0775032564997673
step: 330, loss: 0.04921272024512291
step: 340, loss: 0.0005186516791582108
step: 350, loss: 0.062277909368276596
epoch 20: dev_f1=0.807785888077859, f1=0.7746478873239437, best_f1=0.7746478873239437
