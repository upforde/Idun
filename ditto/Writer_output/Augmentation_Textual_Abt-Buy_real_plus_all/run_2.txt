cuda
Device: cuda
step: 0, loss: 0.7449326515197754
step: 10, loss: 0.16498245298862457
step: 20, loss: 0.11190401017665863
step: 30, loss: 0.511748731136322
step: 40, loss: 0.3130459785461426
step: 50, loss: 0.23507167398929596
step: 60, loss: 0.23338329792022705
step: 70, loss: 0.3658151924610138
step: 80, loss: 0.4267585873603821
step: 90, loss: 0.42707908153533936
step: 100, loss: 0.29638487100601196
step: 110, loss: 0.5204905867576599
step: 120, loss: 0.4297378957271576
step: 130, loss: 0.3635496497154236
step: 140, loss: 0.18140466511249542
step: 150, loss: 0.4394596815109253
step: 160, loss: 0.3227637708187103
step: 170, loss: 0.41079190373420715
step: 180, loss: 0.3902149796485901
step: 190, loss: 0.36222270131111145
step: 200, loss: 0.3128858804702759
step: 210, loss: 0.5551695823669434
step: 220, loss: 0.21463647484779358
step: 230, loss: 0.2370193600654602
step: 240, loss: 0.1573297381401062
step: 250, loss: 0.26479053497314453
step: 260, loss: 0.2625029683113098
step: 270, loss: 0.30789875984191895
step: 280, loss: 0.17470698058605194
step: 290, loss: 0.1427726000547409
step: 300, loss: 0.2661014199256897
step: 310, loss: 0.15599659085273743
step: 320, loss: 0.09484648704528809
step: 330, loss: 0.12374361604452133
step: 340, loss: 0.11627689003944397
step: 350, loss: 0.16463929414749146
epoch 1: dev_f1=0.6528735632183909, f1=0.687089715536105, best_f1=0.687089715536105
step: 0, loss: 0.15845508873462677
step: 10, loss: 0.07447680830955505
step: 20, loss: 0.12293700128793716
step: 30, loss: 0.1776658296585083
step: 40, loss: 0.09392944723367691
step: 50, loss: 0.13950994610786438
step: 60, loss: 0.3252103924751282
step: 70, loss: 0.17280834913253784
step: 80, loss: 0.0791742131114006
step: 90, loss: 0.22582276165485382
step: 100, loss: 0.07696937024593353
step: 110, loss: 0.23049136996269226
step: 120, loss: 0.15563122928142548
step: 130, loss: 0.07580029219388962
step: 140, loss: 0.10065636783838272
step: 150, loss: 0.11182069033384323
step: 160, loss: 0.06973399966955185
step: 170, loss: 0.15041933953762054
step: 180, loss: 0.12878258526325226
step: 190, loss: 0.10933966934680939
step: 200, loss: 0.20614606142044067
step: 210, loss: 0.11175800114870071
step: 220, loss: 0.03423045948147774
step: 230, loss: 0.07134604454040527
step: 240, loss: 0.13410507142543793
step: 250, loss: 0.04803836718201637
step: 260, loss: 0.24763379991054535
step: 270, loss: 0.1029791384935379
step: 280, loss: 0.2773984968662262
step: 290, loss: 0.13353939354419708
step: 300, loss: 0.10008212178945541
step: 310, loss: 0.11789977550506592
step: 320, loss: 0.03934820368885994
step: 330, loss: 0.11120131611824036
step: 340, loss: 0.1339293271303177
step: 350, loss: 0.0939667671918869
epoch 2: dev_f1=0.7838983050847458, f1=0.7560975609756097, best_f1=0.7560975609756097
step: 0, loss: 0.12952551245689392
step: 10, loss: 0.046467117965221405
step: 20, loss: 0.14126551151275635
step: 30, loss: 0.029689667746424675
step: 40, loss: 0.06098100170493126
step: 50, loss: 0.10840770602226257
step: 60, loss: 0.08762592077255249
step: 70, loss: 0.035916443914175034
step: 80, loss: 0.10735152661800385
step: 90, loss: 0.14193929731845856
step: 100, loss: 0.12805265188217163
step: 110, loss: 0.09678635001182556
step: 120, loss: 0.02686937339603901
step: 130, loss: 0.1332651674747467
step: 140, loss: 0.07434738427400589
step: 150, loss: 0.06429202854633331
step: 160, loss: 0.09034249186515808
step: 170, loss: 0.042394641786813736
step: 180, loss: 0.19030234217643738
step: 190, loss: 0.10292978584766388
step: 200, loss: 0.01576957292854786
step: 210, loss: 0.2085578441619873
step: 220, loss: 0.14725039899349213
step: 230, loss: 0.1382739245891571
step: 240, loss: 0.06987501680850983
step: 250, loss: 0.038785889744758606
step: 260, loss: 0.12306918203830719
step: 270, loss: 0.12838995456695557
step: 280, loss: 0.05808023735880852
step: 290, loss: 0.032091930508613586
step: 300, loss: 0.10635822266340256
step: 310, loss: 0.17269892990589142
step: 320, loss: 0.06396279484033585
step: 330, loss: 0.0033083336893469095
step: 340, loss: 0.22312350571155548
step: 350, loss: 0.11465927958488464
epoch 3: dev_f1=0.7954022988505747, f1=0.7877461706783371, best_f1=0.7877461706783371
step: 0, loss: 0.13109761476516724
step: 10, loss: 0.08428706228733063
step: 20, loss: 0.07214996963739395
step: 30, loss: 0.19077590107917786
step: 40, loss: 0.1181095540523529
step: 50, loss: 0.07801685482263565
step: 60, loss: 0.0690678283572197
step: 70, loss: 0.00907024648040533
step: 80, loss: 0.11426816880702972
step: 90, loss: 0.09838040918111801
step: 100, loss: 0.11522222310304642
step: 110, loss: 0.09345702081918716
step: 120, loss: 0.16552358865737915
step: 130, loss: 0.08596295863389969
step: 140, loss: 0.03159727901220322
step: 150, loss: 0.06842119246721268
step: 160, loss: 0.04793896898627281
step: 170, loss: 0.11954399943351746
step: 180, loss: 0.055404018610715866
step: 190, loss: 0.10861002653837204
step: 200, loss: 0.05461345240473747
step: 210, loss: 0.08564382791519165
step: 220, loss: 0.1666867733001709
step: 230, loss: 0.08652664721012115
step: 240, loss: 0.1164376363158226
step: 250, loss: 0.08358032256364822
step: 260, loss: 0.15379561483860016
step: 270, loss: 0.040283724665641785
step: 280, loss: 0.03770262002944946
step: 290, loss: 0.13574281334877014
step: 300, loss: 0.07949623465538025
step: 310, loss: 0.07274200022220612
step: 320, loss: 0.06219920143485069
step: 330, loss: 0.11209921538829803
step: 340, loss: 0.12113233655691147
step: 350, loss: 0.046126365661621094
epoch 4: dev_f1=0.85, f1=0.823529411764706, best_f1=0.823529411764706
step: 0, loss: 0.06772743910551071
step: 10, loss: 0.14212723076343536
step: 20, loss: 0.06434599310159683
step: 30, loss: 0.045201972126960754
step: 40, loss: 0.0912405475974083
step: 50, loss: 0.10751724243164062
step: 60, loss: 0.10905444622039795
step: 70, loss: 0.15017884969711304
step: 80, loss: 0.026928167790174484
step: 90, loss: 0.16883401572704315
step: 100, loss: 0.08363966643810272
step: 110, loss: 0.14700213074684143
step: 120, loss: 0.1153058111667633
step: 130, loss: 0.38015082478523254
step: 140, loss: 0.128345787525177
step: 150, loss: 0.0507408082485199
step: 160, loss: 0.12044781446456909
step: 170, loss: 0.12686102092266083
step: 180, loss: 0.07421522587537766
step: 190, loss: 0.10792966932058334
step: 200, loss: 0.09941074997186661
step: 210, loss: 0.03278954327106476
step: 220, loss: 0.07504986226558685
step: 230, loss: 0.08796384185552597
step: 240, loss: 0.09886861592531204
step: 250, loss: 0.08552061021327972
step: 260, loss: 0.09512866288423538
step: 270, loss: 0.0836077407002449
step: 280, loss: 0.1169232502579689
step: 290, loss: 0.0797257050871849
step: 300, loss: 0.0962725281715393
step: 310, loss: 0.13560906052589417
step: 320, loss: 0.280746191740036
step: 330, loss: 0.11674248427152634
step: 340, loss: 0.09817623347043991
step: 350, loss: 0.10798105597496033
epoch 5: dev_f1=0.8235294117647057, f1=0.8047058823529412, best_f1=0.823529411764706
step: 0, loss: 0.1586001068353653
step: 10, loss: 0.09842958301305771
step: 20, loss: 0.08678730577230453
step: 30, loss: 0.17205174267292023
step: 40, loss: 0.09450329840183258
step: 50, loss: 0.0705762580037117
step: 60, loss: 0.06188395246863365
step: 70, loss: 0.06940750032663345
step: 80, loss: 0.08850465714931488
step: 90, loss: 0.08236847817897797
step: 100, loss: 0.14507311582565308
step: 110, loss: 0.030979251489043236
step: 120, loss: 0.0611879825592041
step: 130, loss: 0.10392560064792633
step: 140, loss: 0.04816954955458641
step: 150, loss: 0.057711195200681686
step: 160, loss: 0.15368489921092987
step: 170, loss: 0.05059211328625679
step: 180, loss: 0.023318540304899216
step: 190, loss: 0.04380841925740242
step: 200, loss: 0.0577874593436718
step: 210, loss: 0.052122704684734344
step: 220, loss: 0.09077320992946625
step: 230, loss: 0.0358709879219532
step: 240, loss: 0.08379536867141724
step: 250, loss: 0.045983582735061646
step: 260, loss: 0.046555761247873306
step: 270, loss: 0.03841768577694893
step: 280, loss: 0.10447085648775101
step: 290, loss: 0.14665772020816803
step: 300, loss: 0.006846408359706402
step: 310, loss: 0.08540083467960358
step: 320, loss: 0.2020997703075409
step: 330, loss: 0.10896573960781097
step: 340, loss: 0.20932407677173615
step: 350, loss: 0.12418558448553085
epoch 6: dev_f1=0.8367816091954023, f1=0.7834101382488479, best_f1=0.823529411764706
step: 0, loss: 0.041861627250909805
step: 10, loss: 0.04629986360669136
step: 20, loss: 0.048853226006031036
step: 30, loss: 0.09942366927862167
step: 40, loss: 0.09275979548692703
step: 50, loss: 0.11526079475879669
step: 60, loss: 0.003906732890754938
step: 70, loss: 0.04063328728079796
step: 80, loss: 0.1374501883983612
step: 90, loss: 0.047400545328855515
step: 100, loss: 0.13252253830432892
step: 110, loss: 0.014008373022079468
step: 120, loss: 0.05135749652981758
step: 130, loss: 0.07710140198469162
step: 140, loss: 0.07302921265363693
step: 150, loss: 0.2098860889673233
step: 160, loss: 0.13873063027858734
step: 170, loss: 0.043067969381809235
step: 180, loss: 0.08695798367261887
step: 190, loss: 0.07509317249059677
step: 200, loss: 0.1528424173593521
step: 210, loss: 0.09161125868558884
step: 220, loss: 0.07339565455913544
step: 230, loss: 0.10121773183345795
step: 240, loss: 0.019228432327508926
step: 250, loss: 0.022572657093405724
step: 260, loss: 0.08348352462053299
step: 270, loss: 0.08241898566484451
step: 280, loss: 0.09180064499378204
step: 290, loss: 0.07937780767679214
step: 300, loss: 0.06717722862958908
step: 310, loss: 0.15118356049060822
step: 320, loss: 0.08793149888515472
step: 330, loss: 0.052132438868284225
step: 340, loss: 0.11992114037275314
step: 350, loss: 0.09546592831611633
epoch 7: dev_f1=0.8140043763676149, f1=0.7829787234042553, best_f1=0.823529411764706
step: 0, loss: 0.0754399225115776
step: 10, loss: 0.11712087690830231
step: 20, loss: 0.07280722260475159
step: 30, loss: 0.12133998423814774
step: 40, loss: 0.012729370035231113
step: 50, loss: 0.12356620281934738
step: 60, loss: 0.03619670122861862
step: 70, loss: 0.07781382650136948
step: 80, loss: 0.07625263929367065
step: 90, loss: 0.10217006504535675
step: 100, loss: 0.019414735957980156
step: 110, loss: 0.028024470433592796
step: 120, loss: 0.08639513701200485
step: 130, loss: 0.043790023773908615
step: 140, loss: 0.08189363777637482
step: 150, loss: 0.08349279314279556
step: 160, loss: 0.20496731996536255
step: 170, loss: 0.11229557543992996
step: 180, loss: 0.020205335691571236
step: 190, loss: 0.13347391784191132
step: 200, loss: 0.11293699592351913
step: 210, loss: 0.10018228739500046
step: 220, loss: 0.08190666139125824
step: 230, loss: 0.0436583049595356
step: 240, loss: 0.0864640399813652
step: 250, loss: 0.16970942914485931
step: 260, loss: 0.1032312884926796
step: 270, loss: 0.05253731086850166
step: 280, loss: 0.06888390332460403
step: 290, loss: 0.06110803782939911
step: 300, loss: 0.022313114255666733
step: 310, loss: 0.09868297725915909
step: 320, loss: 0.10546310245990753
step: 330, loss: 0.1647406965494156
step: 340, loss: 0.042607955634593964
step: 350, loss: 0.06101014465093613
epoch 8: dev_f1=0.8286334056399133, f1=0.8095238095238095, best_f1=0.823529411764706
step: 0, loss: 0.060148805379867554
step: 10, loss: 0.07576040178537369
step: 20, loss: 0.12641961872577667
step: 30, loss: 0.07282796502113342
step: 40, loss: 0.12930813431739807
step: 50, loss: 0.09141793847084045
step: 60, loss: 0.0851561576128006
step: 70, loss: 0.06135990098118782
step: 80, loss: 0.05863531306385994
step: 90, loss: 0.07062388956546783
step: 100, loss: 0.04350459948182106
step: 110, loss: 0.07805272936820984
step: 120, loss: 0.011984565295279026
step: 130, loss: 0.06303688883781433
step: 140, loss: 0.03850037232041359
step: 150, loss: 0.09383071213960648
step: 160, loss: 0.08634103834629059
step: 170, loss: 0.08334134519100189
step: 180, loss: 0.05109263211488724
step: 190, loss: 0.15422536432743073
step: 200, loss: 0.13760381937026978
step: 210, loss: 0.11872879415750504
step: 220, loss: 0.08414062112569809
step: 230, loss: 0.07062826305627823
step: 240, loss: 0.08857879787683487
step: 250, loss: 0.12386667728424072
step: 260, loss: 0.06915333867073059
step: 270, loss: 0.1285521537065506
step: 280, loss: 0.0951031967997551
step: 290, loss: 0.058402080088853836
step: 300, loss: 0.05420850217342377
step: 310, loss: 0.033740218728780746
step: 320, loss: 0.1003955751657486
step: 330, loss: 0.11262616515159607
step: 340, loss: 0.18084822595119476
step: 350, loss: 0.11336943507194519
epoch 9: dev_f1=0.8391608391608392, f1=0.8047058823529412, best_f1=0.823529411764706
step: 0, loss: 0.05759336054325104
step: 10, loss: 0.00017012545140460134
step: 20, loss: 0.13054241240024567
step: 30, loss: 0.11494540423154831
step: 40, loss: 0.10628766566514969
step: 50, loss: 0.047312140464782715
step: 60, loss: 0.08643613755702972
step: 70, loss: 0.028539394959807396
step: 80, loss: 0.09850888699293137
step: 90, loss: 0.03261617571115494
step: 100, loss: 0.09123764932155609
step: 110, loss: 0.042127594351768494
step: 120, loss: 0.0071967244148254395
step: 130, loss: 0.06346193701028824
step: 140, loss: 0.12295185029506683
step: 150, loss: 0.0760502964258194
step: 160, loss: 0.06851815432310104
step: 170, loss: 0.01315365917980671
step: 180, loss: 0.07497768849134445
step: 190, loss: 0.0236749816685915
step: 200, loss: 0.063799649477005
step: 210, loss: 0.05096409097313881
step: 220, loss: 0.08588656783103943
step: 230, loss: 0.07615692913532257
step: 240, loss: 0.024176951497793198
step: 250, loss: 0.07154322415590286
step: 260, loss: 0.12367654591798782
step: 270, loss: 0.0074997348710894585
step: 280, loss: 0.12524071335792542
step: 290, loss: 0.016872558742761612
step: 300, loss: 0.15431511402130127
step: 310, loss: 0.09833629429340363
step: 320, loss: 0.2132822871208191
step: 330, loss: 0.09871919453144073
step: 340, loss: 0.11297840625047684
step: 350, loss: 0.1441473662853241
epoch 10: dev_f1=0.8413461538461537, f1=0.8066825775656326, best_f1=0.823529411764706
step: 0, loss: 0.061082493513822556
step: 10, loss: 0.10583222657442093
step: 20, loss: 0.028572212904691696
step: 30, loss: 0.03686605766415596
step: 40, loss: 0.18783430755138397
step: 50, loss: 0.06285886466503143
step: 60, loss: 0.07785478234291077
step: 70, loss: 0.11968347430229187
step: 80, loss: 0.0861193910241127
step: 90, loss: 0.05952850729227066
step: 100, loss: 0.10793649405241013
step: 110, loss: 0.05507034808397293
step: 120, loss: 0.04554412513971329
step: 130, loss: 0.10538287460803986
step: 140, loss: 0.01869070716202259
step: 150, loss: 0.050635967403650284
step: 160, loss: 0.02881564572453499
step: 170, loss: 0.05144553631544113
step: 180, loss: 0.0485924668610096
step: 190, loss: 0.10931596159934998
step: 200, loss: 0.057591188699007034
step: 210, loss: 0.11586086452007294
step: 220, loss: 0.34749430418014526
step: 230, loss: 0.06402658671140671
step: 240, loss: 0.05389189347624779
step: 250, loss: 0.05994173884391785
step: 260, loss: 0.0769260972738266
step: 270, loss: 0.000577622908167541
step: 280, loss: 0.18363924324512482
step: 290, loss: 0.11490065604448318
step: 300, loss: 0.09597155451774597
step: 310, loss: 0.029094673693180084
step: 320, loss: 0.10498330742120743
step: 330, loss: 0.16531774401664734
step: 340, loss: 0.06259019672870636
step: 350, loss: 0.00025992345763370395
epoch 11: dev_f1=0.8457943925233645, f1=0.8018648018648018, best_f1=0.823529411764706
step: 0, loss: 0.02118546888232231
step: 10, loss: 0.027296170592308044
step: 20, loss: 0.051176879554986954
step: 30, loss: 0.0855976864695549
step: 40, loss: 0.07700423896312714
step: 50, loss: 0.040990859270095825
step: 60, loss: 0.08022478222846985
step: 70, loss: 0.08956301957368851
step: 80, loss: 0.052100710570812225
step: 90, loss: 0.04608707129955292
step: 100, loss: 0.052047938108444214
step: 110, loss: 0.06320971995592117
step: 120, loss: 0.06899723410606384
step: 130, loss: 0.0532035157084465
step: 140, loss: 0.0772283673286438
step: 150, loss: 0.11915548890829086
step: 160, loss: 0.14796829223632812
step: 170, loss: 0.13670000433921814
step: 180, loss: 0.050935909152030945
step: 190, loss: 0.049449432641267776
step: 200, loss: 0.12525144219398499
step: 210, loss: 0.12123546004295349
step: 220, loss: 0.0658365786075592
step: 230, loss: 0.0708763599395752
step: 240, loss: 0.06748270243406296
step: 250, loss: 0.10998178273439407
step: 260, loss: 0.08653394132852554
step: 270, loss: 0.04190519452095032
step: 280, loss: 0.08269362151622772
step: 290, loss: 0.048691198229789734
step: 300, loss: 0.09600009024143219
step: 310, loss: 0.05932709574699402
step: 320, loss: 0.1105479821562767
step: 330, loss: 0.17613686621189117
step: 340, loss: 0.001312525593675673
step: 350, loss: 0.059233084321022034
epoch 12: dev_f1=0.8418604651162792, f1=0.8055555555555555, best_f1=0.823529411764706
step: 0, loss: 0.057240892201662064
step: 10, loss: 0.05711236968636513
step: 20, loss: 0.1148497611284256
step: 30, loss: 0.055828798562288284
step: 40, loss: 0.03764047846198082
step: 50, loss: 0.06859849393367767
step: 60, loss: 0.08297780901193619
step: 70, loss: 0.10775110125541687
step: 80, loss: 0.09730780869722366
step: 90, loss: 0.0005073038628324866
step: 100, loss: 0.041362881660461426
step: 110, loss: 0.013714549131691456
step: 120, loss: 0.06894120573997498
step: 130, loss: 0.09036466479301453
step: 140, loss: 0.017094576731324196
step: 150, loss: 0.05451280251145363
step: 160, loss: 0.065913625061512
step: 170, loss: 0.1534920632839203
step: 180, loss: 0.05037413537502289
step: 190, loss: 0.06078115478157997
step: 200, loss: 0.048898421227931976
step: 210, loss: 0.07085543870925903
step: 220, loss: 0.05412549525499344
step: 230, loss: 0.03503383323550224
step: 240, loss: 0.04222000017762184
step: 250, loss: 0.12090301513671875
step: 260, loss: 0.028994541615247726
step: 270, loss: 0.039074189960956573
step: 280, loss: 0.046967167407274246
step: 290, loss: 0.05468625947833061
step: 300, loss: 0.0696735605597496
step: 310, loss: 0.04322126507759094
step: 320, loss: 0.1145186796784401
step: 330, loss: 0.0943269431591034
step: 340, loss: 0.08988909423351288
step: 350, loss: 0.13602769374847412
epoch 13: dev_f1=0.8472222222222222, f1=0.8064516129032259, best_f1=0.823529411764706
step: 0, loss: 0.029772024601697922
step: 10, loss: 0.05784307420253754
step: 20, loss: 0.01740587130188942
step: 30, loss: 0.07860913127660751
step: 40, loss: 0.04095214605331421
step: 50, loss: 0.0603613555431366
step: 60, loss: 0.05454785004258156
step: 70, loss: 0.026552818715572357
step: 80, loss: 0.03457355126738548
step: 90, loss: 0.05058638006448746
step: 100, loss: 0.0921487957239151
step: 110, loss: 0.15749335289001465
step: 120, loss: 0.0018875779351219535
step: 130, loss: 0.17002815008163452
step: 140, loss: 0.07173234969377518
step: 150, loss: 0.05075909569859505
step: 160, loss: 0.09739310294389725
step: 170, loss: 0.047028400003910065
step: 180, loss: 0.0791294202208519
step: 190, loss: 0.056272171437740326
step: 200, loss: 0.0245219599455595
step: 210, loss: 0.018498659133911133
step: 220, loss: 0.04340050742030144
step: 230, loss: 0.02986212633550167
step: 240, loss: 0.06013520434498787
step: 250, loss: 0.08416970819234848
step: 260, loss: 0.12787465751171112
step: 270, loss: 0.0568043477833271
step: 280, loss: 0.12417629361152649
step: 290, loss: 0.12054213881492615
step: 300, loss: 0.09400802105665207
step: 310, loss: 0.13762547075748444
step: 320, loss: 0.01067437045276165
step: 330, loss: 0.09729573130607605
step: 340, loss: 0.08906175196170807
step: 350, loss: 0.11531384289264679
epoch 14: dev_f1=0.8252427184466019, f1=0.7921760391198044, best_f1=0.823529411764706
step: 0, loss: 0.018441569060087204
step: 10, loss: 0.04811835289001465
step: 20, loss: 0.07900819182395935
step: 30, loss: 0.13922598958015442
step: 40, loss: 0.13379698991775513
step: 50, loss: 0.09015072137117386
step: 60, loss: 0.09737347811460495
step: 70, loss: 0.04135783016681671
step: 80, loss: 0.04626746103167534
step: 90, loss: 0.04819270968437195
step: 100, loss: 0.07611986249685287
step: 110, loss: 0.08631002902984619
step: 120, loss: 0.04242611303925514
step: 130, loss: 0.05620083212852478
step: 140, loss: 0.04884560406208038
step: 150, loss: 0.04222823306918144
step: 160, loss: 0.07339504361152649
step: 170, loss: 0.029891878366470337
step: 180, loss: 0.09213945269584656
step: 190, loss: 0.00014373206067830324
step: 200, loss: 0.047468170523643494
step: 210, loss: 0.05339770019054413
step: 220, loss: 0.11231322586536407
step: 230, loss: 0.04000869765877724
step: 240, loss: 0.08918225765228271
step: 250, loss: 0.08628493547439575
step: 260, loss: 0.04193072393536568
step: 270, loss: 0.1336434781551361
step: 280, loss: 0.018335849046707153
step: 290, loss: 0.0582183301448822
step: 300, loss: 0.05451918765902519
step: 310, loss: 0.041346512734889984
step: 320, loss: 0.0571226067841053
step: 330, loss: 0.08992516994476318
step: 340, loss: 0.07531645148992538
step: 350, loss: 0.04695931077003479
epoch 15: dev_f1=0.8266033254156769, f1=0.8056872037914692, best_f1=0.823529411764706
step: 0, loss: 0.04770764708518982
step: 10, loss: 0.12205623090267181
step: 20, loss: 0.060130566358566284
step: 30, loss: 0.06295614689588547
step: 40, loss: 0.07805163413286209
step: 50, loss: 0.07748390734195709
step: 60, loss: 0.028484581038355827
step: 70, loss: 0.03873547911643982
step: 80, loss: 0.16787448525428772
step: 90, loss: 0.12704144418239594
step: 100, loss: 0.09570860117673874
step: 110, loss: 0.10136991739273071
step: 120, loss: 7.749982614768669e-05
step: 130, loss: 0.09272918105125427
step: 140, loss: 0.026871442794799805
step: 150, loss: 0.1522447168827057
step: 160, loss: 0.08473971486091614
step: 170, loss: 0.07909498363733292
step: 180, loss: 0.14703777432441711
step: 190, loss: 0.04640045762062073
step: 200, loss: 0.1718093454837799
step: 210, loss: 0.05012195557355881
step: 220, loss: 0.08418647944927216
step: 230, loss: 0.047391992062330246
step: 240, loss: 0.07110103219747543
step: 250, loss: 0.04445395991206169
step: 260, loss: 0.08376186341047287
step: 270, loss: 0.08163821697235107
step: 280, loss: 0.09622734040021896
step: 290, loss: 0.044116176664829254
step: 300, loss: 0.051318202167749405
step: 310, loss: 7.46324731153436e-05
step: 320, loss: 0.08544696867465973
step: 330, loss: 0.12524741888046265
step: 340, loss: 0.027522431686520576
step: 350, loss: 0.08101914077997208
epoch 16: dev_f1=0.8262910798122066, f1=0.8018223234624147, best_f1=0.823529411764706
step: 0, loss: 0.07363870739936829
step: 10, loss: 0.15259529650211334
step: 20, loss: 0.09343831986188889
step: 30, loss: 0.05149253457784653
step: 40, loss: 0.1252165138721466
step: 50, loss: 0.08351685851812363
step: 60, loss: 0.11575494706630707
step: 70, loss: 0.07706456631422043
step: 80, loss: 0.053398728370666504
step: 90, loss: 0.029507089406251907
step: 100, loss: 0.1273673176765442
step: 110, loss: 0.043954115360975266
step: 120, loss: 0.04541477933526039
step: 130, loss: 0.08215604722499847
step: 140, loss: 0.060549210757017136
step: 150, loss: 0.05160185322165489
step: 160, loss: 0.0079484973102808
step: 170, loss: 0.06448358297348022
step: 180, loss: 0.03028268739581108
step: 190, loss: 0.030710440129041672
step: 200, loss: 0.027806222438812256
step: 210, loss: 0.06306605041027069
step: 220, loss: 0.07517409324645996
step: 230, loss: 0.03197617456316948
step: 240, loss: 0.15892393887043
step: 250, loss: 0.06663428992033005
step: 260, loss: 0.06928073614835739
step: 270, loss: 0.07653714716434479
step: 280, loss: 0.031247712671756744
step: 290, loss: 0.06913091242313385
step: 300, loss: 0.0004744592006318271
step: 310, loss: 0.03393259271979332
step: 320, loss: 0.06944354623556137
step: 330, loss: 0.023720689117908478
step: 340, loss: 0.05436787009239197
step: 350, loss: 0.011004670523107052
epoch 17: dev_f1=0.8289156626506025, f1=0.8169014084507042, best_f1=0.823529411764706
step: 0, loss: 0.1217707097530365
step: 10, loss: 0.01580001600086689
step: 20, loss: 0.03553831949830055
step: 30, loss: 0.03427605330944061
step: 40, loss: 0.018033616244792938
step: 50, loss: 0.042524125427007675
step: 60, loss: 0.14657284319400787
step: 70, loss: 0.0769793689250946
step: 80, loss: 0.07642808556556702
step: 90, loss: 7.347248174482957e-05
step: 100, loss: 0.08115620911121368
step: 110, loss: 0.015147495083510876
step: 120, loss: 0.00911243911832571
step: 130, loss: 0.06072283163666725
step: 140, loss: 0.01995064876973629
step: 150, loss: 0.037743087857961655
step: 160, loss: 0.09226475656032562
step: 170, loss: 0.013470829464495182
step: 180, loss: 0.0726461336016655
step: 190, loss: 0.1050465852022171
step: 200, loss: 0.06467418372631073
step: 210, loss: 0.10714425891637802
step: 220, loss: 0.07439548522233963
step: 230, loss: 0.019335664808750153
step: 240, loss: 0.0807834267616272
step: 250, loss: 0.0442686453461647
step: 260, loss: 0.02226097881793976
step: 270, loss: 0.03954237326979637
step: 280, loss: 0.1198614314198494
step: 290, loss: 0.09608562290668488
step: 300, loss: 0.06716705858707428
step: 310, loss: 0.0627346932888031
step: 320, loss: 0.059732839465141296
step: 330, loss: 0.1611933410167694
step: 340, loss: 0.03996169939637184
step: 350, loss: 0.07994759827852249
epoch 18: dev_f1=0.815, f1=0.7910447761194029, best_f1=0.823529411764706
step: 0, loss: 0.07781647145748138
step: 10, loss: 0.09228570014238358
step: 20, loss: 0.09849554300308228
step: 30, loss: 0.018184863030910492
step: 40, loss: 0.03185886889696121
step: 50, loss: 0.03173219412565231
step: 60, loss: 3.451357770245522e-05
step: 70, loss: 0.07457683235406876
step: 80, loss: 0.10123595595359802
step: 90, loss: 0.040822505950927734
step: 100, loss: 0.09046193212270737
step: 110, loss: 0.016240494325757027
step: 120, loss: 0.009868845343589783
step: 130, loss: 0.07411357760429382
step: 140, loss: 0.0980684906244278
step: 150, loss: 0.057584043592214584
step: 160, loss: 0.05702080950140953
step: 170, loss: 0.11967328190803528
step: 180, loss: 0.012907523661851883
step: 190, loss: 0.01425329502671957
step: 200, loss: 0.029498934745788574
step: 210, loss: 0.046206701546907425
step: 220, loss: 0.00011533137148944661
step: 230, loss: 0.15003952383995056
step: 240, loss: 0.03528924286365509
step: 250, loss: 0.07491651177406311
step: 260, loss: 0.044562097638845444
step: 270, loss: 0.11667902022600174
step: 280, loss: 0.05676957964897156
step: 290, loss: 0.03573150187730789
step: 300, loss: 0.03589550033211708
step: 310, loss: 0.12879738211631775
step: 320, loss: 0.05875442549586296
step: 330, loss: 0.07045689225196838
step: 340, loss: 0.027289150282740593
step: 350, loss: 0.05065916106104851
epoch 19: dev_f1=0.8240963855421687, f1=0.8018867924528301, best_f1=0.823529411764706
step: 0, loss: 0.13219919800758362
step: 10, loss: 0.03506114333868027
step: 20, loss: 0.05429202690720558
step: 30, loss: 0.07105009257793427
step: 40, loss: 0.0367187075316906
step: 50, loss: 0.024050073698163033
step: 60, loss: 0.07319268584251404
step: 70, loss: 0.033246636390686035
step: 80, loss: 0.15655162930488586
step: 90, loss: 0.040488459169864655
step: 100, loss: 0.0442541167140007
step: 110, loss: 0.01831459067761898
step: 120, loss: 0.038951631635427475
step: 130, loss: 0.0658043622970581
step: 140, loss: 0.0251784585416317
step: 150, loss: 0.06345127522945404
step: 160, loss: 0.061545826494693756
step: 170, loss: 0.08021470159292221
step: 180, loss: 0.009413152933120728
step: 190, loss: 0.165371373295784
step: 200, loss: 0.034166306257247925
step: 210, loss: 0.009925668127834797
step: 220, loss: 0.06263300776481628
step: 230, loss: 0.022815831005573273
step: 240, loss: 0.08194006979465485
step: 250, loss: 0.01745537295937538
step: 260, loss: 0.04744851589202881
step: 270, loss: 0.06142992153763771
step: 280, loss: 0.06449846178293228
step: 290, loss: 0.048175450414419174
step: 300, loss: 0.07676873356103897
step: 310, loss: 0.04125835746526718
step: 320, loss: 0.041440267115831375
step: 330, loss: 0.0801917165517807
step: 340, loss: 0.021719448268413544
step: 350, loss: 0.06388336420059204
epoch 20: dev_f1=0.8146341463414632, f1=0.7932692307692307, best_f1=0.823529411764706
