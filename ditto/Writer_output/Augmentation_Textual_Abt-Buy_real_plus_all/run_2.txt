cuda
Device: cuda
step: 0, loss: 0.5742660164833069
step: 10, loss: 0.4956168830394745
step: 20, loss: 0.43707147240638733
step: 30, loss: 0.424211710691452
step: 40, loss: 0.35028076171875
step: 50, loss: 0.7192317843437195
step: 60, loss: 0.2623021900653839
step: 70, loss: 0.38071441650390625
step: 80, loss: 0.3674793243408203
step: 90, loss: 0.31735074520111084
step: 100, loss: 0.3074716627597809
step: 110, loss: 0.23547965288162231
step: 120, loss: 0.3216690719127655
step: 130, loss: 0.35807058215141296
step: 140, loss: 0.3344099819660187
step: 150, loss: 0.38449323177337646
step: 160, loss: 0.18370160460472107
step: 170, loss: 0.31426045298576355
step: 180, loss: 0.35624226927757263
step: 190, loss: 0.5474666357040405
step: 200, loss: 0.29239800572395325
step: 210, loss: 0.2971267104148865
step: 220, loss: 0.2682359218597412
step: 230, loss: 0.3449805974960327
step: 240, loss: 0.42951375246047974
step: 250, loss: 0.243650421500206
step: 260, loss: 0.21186463534832
step: 270, loss: 0.2142002433538437
step: 280, loss: 0.2569131553173065
step: 290, loss: 0.2605951428413391
step: 300, loss: 0.4238092601299286
step: 310, loss: 0.2568410634994507
step: 320, loss: 0.2974340617656708
step: 330, loss: 0.2592494785785675
step: 340, loss: 0.35157114267349243
step: 350, loss: 0.4279771149158478
epoch 1: dev_f1=0.3406754772393539, f1=0.2631578947368421, best_f1=0.2631578947368421
step: 0, loss: 0.19724608957767487
step: 10, loss: 0.4834592640399933
step: 20, loss: 0.26730507612228394
step: 30, loss: 0.25001585483551025
step: 40, loss: 0.15419363975524902
step: 50, loss: 0.2631462514400482
step: 60, loss: 0.292919784784317
step: 70, loss: 0.15891146659851074
step: 80, loss: 0.2654825747013092
step: 90, loss: 0.329323947429657
step: 100, loss: 0.2689068913459778
step: 110, loss: 0.2643123269081116
step: 120, loss: 0.2523394823074341
step: 130, loss: 0.20020976662635803
step: 140, loss: 0.32965177297592163
step: 150, loss: 0.12917472422122955
step: 160, loss: 0.1805146485567093
step: 170, loss: 0.2459983080625534
step: 180, loss: 0.11474569141864777
step: 190, loss: 0.16271209716796875
step: 200, loss: 0.12532588839530945
step: 210, loss: 0.10750433802604675
step: 220, loss: 0.20082750916481018
step: 230, loss: 0.22069217264652252
step: 240, loss: 0.10524116456508636
step: 250, loss: 0.10502136498689651
step: 260, loss: 0.3008888065814972
step: 270, loss: 0.16353893280029297
step: 280, loss: 0.14693254232406616
step: 290, loss: 0.1433969885110855
step: 300, loss: 0.13580317795276642
step: 310, loss: 0.10027676075696945
step: 320, loss: 0.09843969345092773
step: 330, loss: 0.40610024333000183
step: 340, loss: 0.2291584461927414
step: 350, loss: 0.3691733181476593
epoch 2: dev_f1=0.7114967462039046, f1=0.6974789915966386, best_f1=0.6974789915966386
step: 0, loss: 0.2744710445404053
step: 10, loss: 0.1009298786520958
step: 20, loss: 0.2475961595773697
step: 30, loss: 0.11069614440202713
step: 40, loss: 0.19193919003009796
step: 50, loss: 0.2444012612104416
step: 60, loss: 0.19464460015296936
step: 70, loss: 0.09186791628599167
step: 80, loss: 0.1367047131061554
step: 90, loss: 0.15961264073848724
step: 100, loss: 0.18142038583755493
step: 110, loss: 0.29031631350517273
step: 120, loss: 0.06643201410770416
step: 130, loss: 0.1566288024187088
step: 140, loss: 0.168035089969635
step: 150, loss: 0.052278678864240646
step: 160, loss: 0.09826114773750305
step: 170, loss: 0.1540883630514145
step: 180, loss: 0.0702875405550003
step: 190, loss: 0.05503134801983833
step: 200, loss: 0.02261386252939701
step: 210, loss: 0.2192138135433197
step: 220, loss: 0.15960870683193207
step: 230, loss: 0.1408122330904007
step: 240, loss: 0.09295382350683212
step: 250, loss: 0.21221311390399933
step: 260, loss: 0.07987117022275925
step: 270, loss: 0.2080782800912857
step: 280, loss: 0.178442120552063
step: 290, loss: 0.08517562597990036
step: 300, loss: 0.33967697620391846
step: 310, loss: 0.12005260586738586
step: 320, loss: 0.12695445120334625
step: 330, loss: 0.16630831360816956
step: 340, loss: 0.10405903309583664
step: 350, loss: 0.2115914523601532
epoch 3: dev_f1=0.7296137339055794, f1=0.7318087318087318, best_f1=0.7318087318087318
step: 0, loss: 0.18790173530578613
step: 10, loss: 0.1269543617963791
step: 20, loss: 0.17795468866825104
step: 30, loss: 0.18473128974437714
step: 40, loss: 0.06861680001020432
step: 50, loss: 0.07718424499034882
step: 60, loss: 0.08062756061553955
step: 70, loss: 0.13420593738555908
step: 80, loss: 0.10258418321609497
step: 90, loss: 0.0984717383980751
step: 100, loss: 0.0007409395184367895
step: 110, loss: 0.0381619818508625
step: 120, loss: 0.14267702400684357
step: 130, loss: 0.07483478635549545
step: 140, loss: 0.10357443988323212
step: 150, loss: 0.15258042514324188
step: 160, loss: 0.15075644850730896
step: 170, loss: 0.1090351939201355
step: 180, loss: 0.18816041946411133
step: 190, loss: 0.15098030865192413
step: 200, loss: 0.08518727123737335
step: 210, loss: 0.2567693293094635
step: 220, loss: 0.07757198810577393
step: 230, loss: 0.09246600419282913
step: 240, loss: 0.17650336027145386
step: 250, loss: 0.09027906507253647
step: 260, loss: 0.10915650427341461
step: 270, loss: 0.03950396552681923
step: 280, loss: 0.13365276157855988
step: 290, loss: 0.09132205694913864
step: 300, loss: 0.07940740883350372
step: 310, loss: 0.15313446521759033
step: 320, loss: 0.0765412226319313
step: 330, loss: 0.12426330894231796
step: 340, loss: 0.11911595612764359
step: 350, loss: 0.11710640788078308
epoch 4: dev_f1=0.8044943820224719, f1=0.7708779443254817, best_f1=0.7708779443254817
step: 0, loss: 0.08229587227106094
step: 10, loss: 0.18378213047981262
step: 20, loss: 0.07731080800294876
step: 30, loss: 0.06268417835235596
step: 40, loss: 0.15066808462142944
step: 50, loss: 0.18725353479385376
step: 60, loss: 0.08660553395748138
step: 70, loss: 0.16637709736824036
step: 80, loss: 0.15492679178714752
step: 90, loss: 0.11511626094579697
step: 100, loss: 0.1709873527288437
step: 110, loss: 0.07054801285266876
step: 120, loss: 0.11303915083408356
step: 130, loss: 0.02992086671292782
step: 140, loss: 0.03404521197080612
step: 150, loss: 0.12252403795719147
step: 160, loss: 0.0319240503013134
step: 170, loss: 0.03624755144119263
step: 180, loss: 0.0852886214852333
step: 190, loss: 0.17701399326324463
step: 200, loss: 0.08673768490552902
step: 210, loss: 0.20875702798366547
step: 220, loss: 0.0941154882311821
step: 230, loss: 0.08343307673931122
step: 240, loss: 0.25665849447250366
step: 250, loss: 0.09481336921453476
step: 260, loss: 0.02198583446443081
step: 270, loss: 0.1538442224264145
step: 280, loss: 0.07447250932455063
step: 290, loss: 0.11704953014850616
step: 300, loss: 0.11596949398517609
step: 310, loss: 0.08803162723779678
step: 320, loss: 0.08994431793689728
step: 330, loss: 0.11546418815851212
step: 340, loss: 0.17411130666732788
step: 350, loss: 0.08841371536254883
epoch 5: dev_f1=0.8171021377672211, f1=0.8126410835214447, best_f1=0.8126410835214447
step: 0, loss: 0.05516921356320381
step: 10, loss: 0.10219410806894302
step: 20, loss: 0.03209081292152405
step: 30, loss: 0.20891855657100677
step: 40, loss: 0.04602567106485367
step: 50, loss: 0.061895642429590225
step: 60, loss: 0.07036007940769196
step: 70, loss: 0.04609363153576851
step: 80, loss: 0.12105296552181244
step: 90, loss: 0.04304606840014458
step: 100, loss: 0.08028439432382584
step: 110, loss: 0.06060706824064255
step: 120, loss: 0.07478425651788712
step: 130, loss: 0.11571433395147324
step: 140, loss: 0.0846526101231575
step: 150, loss: 0.08942289650440216
step: 160, loss: 0.061619870364665985
step: 170, loss: 0.14516744017601013
step: 180, loss: 0.05212917923927307
step: 190, loss: 0.10664528608322144
step: 200, loss: 0.16807998716831207
step: 210, loss: 0.09861120581626892
step: 220, loss: 0.09680357575416565
step: 230, loss: 0.04993249103426933
step: 240, loss: 0.1271003782749176
step: 250, loss: 0.021855253726243973
step: 260, loss: 0.13133156299591064
step: 270, loss: 0.04216441512107849
step: 280, loss: 0.07660890370607376
step: 290, loss: 0.19039174914360046
step: 300, loss: 0.06090879067778587
step: 310, loss: 0.09258989244699478
step: 320, loss: 0.05816597491502762
step: 330, loss: 0.03491106629371643
step: 340, loss: 0.06015358865261078
step: 350, loss: 0.11736436188220978
epoch 6: dev_f1=0.8303797468354431, f1=0.8078817733990147, best_f1=0.8078817733990147
step: 0, loss: 0.11864564567804337
step: 10, loss: 0.07521287351846695
step: 20, loss: 0.13969536125659943
step: 30, loss: 0.09510993957519531
step: 40, loss: 0.128722682595253
step: 50, loss: 0.09997756034135818
step: 60, loss: 0.028797753155231476
step: 70, loss: 0.08165988326072693
step: 80, loss: 0.09347949177026749
step: 90, loss: 0.1108345165848732
step: 100, loss: 0.10943637043237686
step: 110, loss: 0.03222654014825821
step: 120, loss: 0.14635562896728516
step: 130, loss: 0.11695719510316849
step: 140, loss: 0.08450605720281601
step: 150, loss: 0.11102691292762756
step: 160, loss: 0.08972996473312378
step: 170, loss: 0.1447238028049469
step: 180, loss: 0.07562582939863205
step: 190, loss: 0.12607549130916595
step: 200, loss: 0.06914745271205902
step: 210, loss: 0.10598974674940109
step: 220, loss: 0.06719667464494705
step: 230, loss: 0.03135647252202034
step: 240, loss: 0.09895990043878555
step: 250, loss: 0.13669748604297638
step: 260, loss: 0.10137780755758286
step: 270, loss: 0.1662377417087555
step: 280, loss: 0.018539374694228172
step: 290, loss: 0.06309213489294052
step: 300, loss: 0.33327776193618774
step: 310, loss: 0.03766399621963501
step: 320, loss: 0.0693667083978653
step: 330, loss: 0.08237078040838242
step: 340, loss: 0.07031775265932083
step: 350, loss: 0.16030211746692657
epoch 7: dev_f1=0.8186046511627907, f1=0.7936507936507935, best_f1=0.8078817733990147
step: 0, loss: 0.0809415876865387
step: 10, loss: 0.08935549110174179
step: 20, loss: 0.12078221887350082
step: 30, loss: 0.13081422448158264
step: 40, loss: 0.07441981136798859
step: 50, loss: 0.07798883318901062
step: 60, loss: 0.05942181497812271
step: 70, loss: 0.12022469192743301
step: 80, loss: 0.11059188842773438
step: 90, loss: 0.034658823162317276
step: 100, loss: 0.06080576404929161
step: 110, loss: 0.11829574406147003
step: 120, loss: 0.10884153097867966
step: 130, loss: 0.1272919476032257
step: 140, loss: 0.11233031004667282
step: 150, loss: 0.12094637751579285
step: 160, loss: 0.01351654902100563
step: 170, loss: 0.1920987367630005
step: 180, loss: 0.05642317607998848
step: 190, loss: 0.13183334469795227
step: 200, loss: 0.10773679614067078
step: 210, loss: 0.16744565963745117
step: 220, loss: 0.15661174058914185
step: 230, loss: 0.034076884388923645
step: 240, loss: 0.07982756197452545
step: 250, loss: 0.10308320820331573
step: 260, loss: 0.286294549703598
step: 270, loss: 0.05709739029407501
step: 280, loss: 0.12371593713760376
step: 290, loss: 0.03849627077579498
step: 300, loss: 0.08129173517227173
step: 310, loss: 0.08074826747179031
step: 320, loss: 0.06622147560119629
step: 330, loss: 0.06879822164773941
step: 340, loss: 0.060859475284814835
step: 350, loss: 0.02109410986304283
epoch 8: dev_f1=0.8050632911392405, f1=0.7544303797468355, best_f1=0.8078817733990147
step: 0, loss: 0.042602576315402985
step: 10, loss: 0.08349623531103134
step: 20, loss: 0.03308582305908203
step: 30, loss: 0.11675231903791428
step: 40, loss: 0.1640700101852417
step: 50, loss: 0.1708446890115738
step: 60, loss: 0.028002284467220306
step: 70, loss: 0.1199696883559227
step: 80, loss: 0.0887296125292778
step: 90, loss: 0.10942080616950989
step: 100, loss: 0.09694559872150421
step: 110, loss: 0.07162799686193466
step: 120, loss: 0.11150223761796951
step: 130, loss: 0.13280752301216125
step: 140, loss: 0.2454669177532196
step: 150, loss: 0.1905243694782257
step: 160, loss: 0.12208473682403564
step: 170, loss: 0.06171521544456482
step: 180, loss: 0.15985332429409027
step: 190, loss: 0.17213992774486542
step: 200, loss: 0.05701112002134323
step: 210, loss: 0.06705819815397263
step: 220, loss: 0.052984707057476044
step: 230, loss: 0.03128914535045624
step: 240, loss: 0.06762700527906418
step: 250, loss: 0.11900616437196732
step: 260, loss: 0.09805986285209656
step: 270, loss: 0.12191226333379745
step: 280, loss: 0.0909353718161583
step: 290, loss: 0.1324467957019806
step: 300, loss: 0.07921675592660904
step: 310, loss: 0.0841560810804367
step: 320, loss: 0.07579298317432404
step: 330, loss: 0.05299784615635872
step: 340, loss: 0.1178736761212349
step: 350, loss: 0.0769408792257309
epoch 9: dev_f1=0.8353221957040573, f1=0.7834101382488479, best_f1=0.7834101382488479
step: 0, loss: 0.10489260405302048
step: 10, loss: 0.1204054057598114
step: 20, loss: 0.07512035220861435
step: 30, loss: 0.07608653604984283
step: 40, loss: 0.07677025347948074
step: 50, loss: 0.10648078471422195
step: 60, loss: 0.09042942523956299
step: 70, loss: 0.11681413650512695
step: 80, loss: 0.03689002990722656
step: 90, loss: 0.07569174468517303
step: 100, loss: 0.1860709935426712
step: 110, loss: 0.07513616234064102
step: 120, loss: 0.04328712821006775
step: 130, loss: 0.13126394152641296
step: 140, loss: 0.07570388913154602
step: 150, loss: 0.054975081235170364
step: 160, loss: 0.09560703486204147
step: 170, loss: 0.11685813963413239
step: 180, loss: 0.1289694458246231
step: 190, loss: 0.09136734902858734
step: 200, loss: 0.031959883868694305
step: 210, loss: 0.05671658366918564
step: 220, loss: 0.03716118261218071
step: 230, loss: 0.04974820464849472
step: 240, loss: 0.26548898220062256
step: 250, loss: 0.11392129957675934
step: 260, loss: 0.06669960916042328
step: 270, loss: 0.1205410361289978
step: 280, loss: 0.08131508529186249
step: 290, loss: 0.07244879752397537
step: 300, loss: 0.1970878690481186
step: 310, loss: 0.06954646110534668
step: 320, loss: 0.00026640217402018607
step: 330, loss: 0.10762900859117508
step: 340, loss: 0.10869371145963669
step: 350, loss: 0.041676051914691925
epoch 10: dev_f1=0.8333333333333334, f1=0.7937915742793792, best_f1=0.7834101382488479
step: 0, loss: 0.08497994393110275
step: 10, loss: 0.06937889009714127
step: 20, loss: 0.11773119121789932
step: 30, loss: 0.06632377952337265
step: 40, loss: 0.08513083308935165
step: 50, loss: 0.09868878126144409
step: 60, loss: 0.11165779829025269
step: 70, loss: 0.10969167202711105
step: 80, loss: 0.022900035604834557
step: 90, loss: 0.08943424373865128
step: 100, loss: 0.08265922963619232
step: 110, loss: 0.1451350301504135
step: 120, loss: 0.05852920562028885
step: 130, loss: 0.07581225037574768
step: 140, loss: 0.02174294926226139
step: 150, loss: 0.13409055769443512
step: 160, loss: 0.0655059963464737
step: 170, loss: 0.07007055729627609
step: 180, loss: 0.10563478618860245
step: 190, loss: 0.06012910604476929
step: 200, loss: 0.14123506844043732
step: 210, loss: 0.054923199117183685
step: 220, loss: 0.17639316618442535
step: 230, loss: 0.10524871945381165
step: 240, loss: 0.1309327781200409
step: 250, loss: 0.06220324710011482
step: 260, loss: 0.13353349268436432
step: 270, loss: 0.04324731230735779
step: 280, loss: 0.10600986331701279
step: 290, loss: 0.0452151745557785
step: 300, loss: 0.10323302447795868
step: 310, loss: 0.091291643679142
step: 320, loss: 0.07155401259660721
step: 330, loss: 0.10251521319150925
step: 340, loss: 0.07703938335180283
step: 350, loss: 0.06515082716941833
epoch 11: dev_f1=0.8257756563245824, f1=0.7842227378190254, best_f1=0.7834101382488479
step: 0, loss: 0.04230913519859314
step: 10, loss: 0.0514090359210968
step: 20, loss: 0.03850428760051727
step: 30, loss: 0.08425730466842651
step: 40, loss: 0.07864128053188324
step: 50, loss: 8.309548138640821e-05
step: 60, loss: 0.14207345247268677
step: 70, loss: 0.01877637952566147
step: 80, loss: 0.2023865282535553
step: 90, loss: 0.04487171396613121
step: 100, loss: 0.095914825797081
step: 110, loss: 0.11018649488687515
step: 120, loss: 0.10051175951957703
step: 130, loss: 0.08408419042825699
step: 140, loss: 0.12551596760749817
step: 150, loss: 0.038794197142124176
step: 160, loss: 0.07244236767292023
step: 170, loss: 0.10335870832204819
step: 180, loss: 0.029685022309422493
step: 190, loss: 0.27048900723457336
step: 200, loss: 0.06029227748513222
step: 210, loss: 0.09838560968637466
step: 220, loss: 0.08544527739286423
step: 230, loss: 0.0002342850057175383
step: 240, loss: 0.02402537688612938
step: 250, loss: 0.08969422429800034
step: 260, loss: 0.0620906688272953
step: 270, loss: 0.025396347045898438
step: 280, loss: 0.016041437163949013
step: 290, loss: 0.07453504949808121
step: 300, loss: 0.11551810055971146
step: 310, loss: 0.07554153352975845
step: 320, loss: 0.09354455769062042
step: 330, loss: 0.08713696151971817
step: 340, loss: 0.09946101903915405
step: 350, loss: 0.056221358478069305
epoch 12: dev_f1=0.8208955223880597, f1=0.813953488372093, best_f1=0.7834101382488479
step: 0, loss: 0.025875592604279518
step: 10, loss: 0.09606032073497772
step: 20, loss: 0.11923246085643768
step: 30, loss: 0.06910042464733124
step: 40, loss: 0.04312116280198097
step: 50, loss: 0.11322338879108429
step: 60, loss: 0.046589504927396774
step: 70, loss: 0.10007550567388535
step: 80, loss: 0.1470775604248047
step: 90, loss: 0.025002671405673027
step: 100, loss: 0.11483566462993622
step: 110, loss: 0.09184923022985458
step: 120, loss: 0.11705321818590164
step: 130, loss: 0.051476914435625076
step: 140, loss: 0.13328661024570465
step: 150, loss: 0.0698324590921402
step: 160, loss: 0.06287156045436859
step: 170, loss: 0.0036030965857207775
step: 180, loss: 0.07727929204702377
step: 190, loss: 0.05792246386408806
step: 200, loss: 0.03285853937268257
step: 210, loss: 0.10324827581644058
step: 220, loss: 0.10367003083229065
step: 230, loss: 0.08141583204269409
step: 240, loss: 0.04509090259671211
step: 250, loss: 0.036547139286994934
step: 260, loss: 0.15940797328948975
step: 270, loss: 0.07304500043392181
step: 280, loss: 0.06668487936258316
step: 290, loss: 0.0510261133313179
step: 300, loss: 0.12193343043327332
step: 310, loss: 0.10558350384235382
step: 320, loss: 0.0580289401113987
step: 330, loss: 0.03397698700428009
step: 340, loss: 0.08778563141822815
step: 350, loss: 0.13724958896636963
epoch 13: dev_f1=0.8286445012787724, f1=0.8030303030303031, best_f1=0.7834101382488479
step: 0, loss: 0.03555085510015488
step: 10, loss: 0.03399204462766647
step: 20, loss: 0.052452076226472855
step: 30, loss: 0.07319367676973343
step: 40, loss: 0.11635236442089081
step: 50, loss: 0.09318368881940842
step: 60, loss: 0.03181862458586693
step: 70, loss: 0.07883356511592865
step: 80, loss: 0.06729505211114883
step: 90, loss: 0.03455055505037308
step: 100, loss: 0.035472240298986435
step: 110, loss: 0.07616984099149704
step: 120, loss: 0.05181894078850746
step: 130, loss: 0.06254854798316956
step: 140, loss: 0.15020200610160828
step: 150, loss: 0.07413217425346375
step: 160, loss: 0.03726882115006447
step: 170, loss: 0.08353137969970703
step: 180, loss: 0.1312822699546814
step: 190, loss: 0.06817106902599335
step: 200, loss: 0.052347227931022644
step: 210, loss: 0.014995584264397621
step: 220, loss: 0.06894806772470474
step: 230, loss: 0.07560208439826965
step: 240, loss: 0.07158748805522919
step: 250, loss: 0.14352108538150787
step: 260, loss: 0.07377441227436066
step: 270, loss: 0.018984852358698845
step: 280, loss: 0.1445084810256958
step: 290, loss: 0.11975066363811493
step: 300, loss: 0.0802774652838707
step: 310, loss: 0.026550501585006714
step: 320, loss: 0.14921879768371582
step: 330, loss: 0.04448876902461052
step: 340, loss: 0.01403798721730709
step: 350, loss: 0.017565973103046417
epoch 14: dev_f1=0.8179669030732861, f1=0.7925407925407925, best_f1=0.7834101382488479
step: 0, loss: 0.07572551816701889
step: 10, loss: 0.04303727298974991
step: 20, loss: 0.07907691597938538
step: 30, loss: 0.016254475340247154
step: 40, loss: 0.09193968772888184
step: 50, loss: 0.17147260904312134
step: 60, loss: 0.05203450843691826
step: 70, loss: 0.11693130433559418
step: 80, loss: 0.04518433287739754
step: 90, loss: 0.055024489760398865
step: 100, loss: 0.041304800659418106
step: 110, loss: 0.05202970281243324
step: 120, loss: 0.07296082377433777
step: 130, loss: 0.11291968822479248
step: 140, loss: 0.07743143290281296
step: 150, loss: 0.023919863626360893
step: 160, loss: 0.060909952968358994
step: 170, loss: 0.12044248729944229
step: 180, loss: 0.06017705053091049
step: 190, loss: 0.05711797624826431
step: 200, loss: 0.12781502306461334
step: 210, loss: 0.0019087642431259155
step: 220, loss: 0.04520094022154808
step: 230, loss: 0.2422771453857422
step: 240, loss: 0.03020705096423626
step: 250, loss: 0.12144436687231064
step: 260, loss: 0.04759436100721359
step: 270, loss: 0.08208854496479034
step: 280, loss: 0.05850039795041084
step: 290, loss: 0.09898687899112701
step: 300, loss: 0.15814507007598877
step: 310, loss: 0.06176435202360153
step: 320, loss: 0.10984082520008087
step: 330, loss: 0.08922325819730759
step: 340, loss: 0.0980156809091568
step: 350, loss: 0.06997007131576538
epoch 15: dev_f1=0.8175182481751825, f1=0.7999999999999999, best_f1=0.7834101382488479
step: 0, loss: 0.1040184423327446
step: 10, loss: 0.020464153960347176
step: 20, loss: 0.09489608556032181
step: 30, loss: 0.11231107264757156
step: 40, loss: 0.059610284864902496
step: 50, loss: 0.028856590390205383
step: 60, loss: 0.06863341480493546
step: 70, loss: 0.023986417800188065
step: 80, loss: 0.10678472369909286
step: 90, loss: 0.03120771050453186
step: 100, loss: 0.045067425817251205
step: 110, loss: 0.031192760914564133
step: 120, loss: 0.052401166409254074
step: 130, loss: 7.077425107127056e-05
step: 140, loss: 0.027548281475901604
step: 150, loss: 0.08854469656944275
step: 160, loss: 0.05616862326860428
step: 170, loss: 0.15877574682235718
step: 180, loss: 0.07148193567991257
step: 190, loss: 0.0692753791809082
step: 200, loss: 0.0419907420873642
step: 210, loss: 0.07785416394472122
step: 220, loss: 0.02565283514559269
step: 230, loss: 0.08222625404596329
step: 240, loss: 0.012564396485686302
step: 250, loss: 0.1233924999833107
step: 260, loss: 0.1264163851737976
step: 270, loss: 0.0889551043510437
step: 280, loss: 0.051711555570364
step: 290, loss: 0.09509344398975372
step: 300, loss: 0.07826557755470276
step: 310, loss: 0.023486686870455742
step: 320, loss: 0.04317833110690117
step: 330, loss: 0.1150381937623024
step: 340, loss: 0.07238820940256119
step: 350, loss: 0.14749273657798767
epoch 16: dev_f1=0.8082901554404144, f1=0.779746835443038, best_f1=0.7834101382488479
step: 0, loss: 0.0750807523727417
step: 10, loss: 0.026724228635430336
step: 20, loss: 0.11115512251853943
step: 30, loss: 0.1476614624261856
step: 40, loss: 0.062057577073574066
step: 50, loss: 0.07631513476371765
step: 60, loss: 0.028241094201803207
step: 70, loss: 0.06471686065196991
step: 80, loss: 0.15398333966732025
step: 90, loss: 0.06815081089735031
step: 100, loss: 0.07617533951997757
step: 110, loss: 0.08366319537162781
step: 120, loss: 0.093879833817482
step: 130, loss: 0.13924534618854523
step: 140, loss: 0.11452741920948029
step: 150, loss: 0.19923420250415802
step: 160, loss: 3.641194780357182e-05
step: 170, loss: 0.13491831719875336
step: 180, loss: 0.1015915498137474
step: 190, loss: 0.12051869928836823
step: 200, loss: 0.058294396847486496
step: 210, loss: 0.09867899864912033
step: 220, loss: 0.11320406198501587
step: 230, loss: 0.09069820493459702
step: 240, loss: 0.09371599555015564
step: 250, loss: 0.1678001880645752
step: 260, loss: 0.06501128524541855
step: 270, loss: 0.06140260770916939
step: 280, loss: 0.1324128806591034
step: 290, loss: 0.03370557352900505
step: 300, loss: 0.05925757810473442
step: 310, loss: 0.06548759341239929
step: 320, loss: 0.038893893361091614
step: 330, loss: 0.03761076554656029
step: 340, loss: 0.2131047546863556
step: 350, loss: 0.037585966289043427
epoch 17: dev_f1=0.8181818181818181, f1=0.8056206088992974, best_f1=0.7834101382488479
step: 0, loss: 0.00012707951827906072
step: 10, loss: 0.07262691855430603
step: 20, loss: 0.03321737051010132
step: 30, loss: 0.013767310418188572
step: 40, loss: 0.10580186545848846
step: 50, loss: 0.031728025525808334
step: 60, loss: 0.1340981274843216
step: 70, loss: 0.11327660083770752
step: 80, loss: 0.03136670961976051
step: 90, loss: 0.04515979439020157
step: 100, loss: 0.06874667853116989
step: 110, loss: 0.04499350115656853
step: 120, loss: 0.05745011568069458
step: 130, loss: 0.0073540424928069115
step: 140, loss: 0.04136031121015549
step: 150, loss: 0.06926406919956207
step: 160, loss: 0.050644777715206146
step: 170, loss: 0.08457624912261963
step: 180, loss: 0.039791908115148544
step: 190, loss: 0.05473868548870087
step: 200, loss: 0.1123134195804596
step: 210, loss: 0.06834059208631516
step: 220, loss: 0.0005511713097803295
step: 230, loss: 0.056043948978185654
step: 240, loss: 0.08381412923336029
step: 250, loss: 0.08095590770244598
step: 260, loss: 0.10574132949113846
step: 270, loss: 0.07496264576911926
step: 280, loss: 0.0561801940202713
step: 290, loss: 0.0478714182972908
step: 300, loss: 0.06847655773162842
step: 310, loss: 0.028045687824487686
step: 320, loss: 0.10770205408334732
step: 330, loss: 0.05468679592013359
step: 340, loss: 0.02188047766685486
step: 350, loss: 0.024465231224894524
epoch 18: dev_f1=0.8159203980099503, f1=0.7980535279805353, best_f1=0.7834101382488479
step: 0, loss: 0.09206272661685944
step: 10, loss: 0.08655157685279846
step: 20, loss: 0.052511051297187805
step: 30, loss: 0.09406949579715729
step: 40, loss: 0.1050487756729126
step: 50, loss: 0.0630144402384758
step: 60, loss: 0.04045329615473747
step: 70, loss: 0.08146671950817108
step: 80, loss: 0.07249762117862701
step: 90, loss: 0.03225413337349892
step: 100, loss: 0.03218628838658333
step: 110, loss: 0.03746085241436958
step: 120, loss: 0.05690152943134308
step: 130, loss: 0.09519011527299881
step: 140, loss: 0.07841421663761139
step: 150, loss: 0.025650769472122192
step: 160, loss: 0.050973087549209595
step: 170, loss: 0.045926738530397415
step: 180, loss: 0.06456293165683746
step: 190, loss: 0.03709796816110611
step: 200, loss: 0.06470591574907303
step: 210, loss: 0.03207600861787796
step: 220, loss: 0.130703866481781
step: 230, loss: 0.09075404703617096
step: 240, loss: 0.031598903238773346
step: 250, loss: 0.05835992097854614
step: 260, loss: 0.06717700511217117
step: 270, loss: 0.05123604089021683
step: 280, loss: 0.029997099190950394
step: 290, loss: 0.12676456570625305
step: 300, loss: 0.1044289693236351
step: 310, loss: 0.02982586994767189
step: 320, loss: 0.11343743652105331
step: 330, loss: 0.09331093728542328
step: 340, loss: 0.16186299920082092
step: 350, loss: 0.022854959592223167
epoch 19: dev_f1=0.819753086419753, f1=0.7980769230769231, best_f1=0.7834101382488479
step: 0, loss: 0.12171676754951477
step: 10, loss: 0.12610773742198944
step: 20, loss: 0.10804663598537445
step: 30, loss: 0.09384019672870636
step: 40, loss: 0.09190067648887634
step: 50, loss: 3.9313417801167816e-05
step: 60, loss: 0.10446619987487793
step: 70, loss: 0.01683051697909832
step: 80, loss: 0.13273563981056213
step: 90, loss: 0.12245556712150574
step: 100, loss: 0.04506254196166992
step: 110, loss: 0.016598662361502647
step: 120, loss: 0.01938011310994625
step: 130, loss: 0.07515110820531845
step: 140, loss: 0.1250721961259842
step: 150, loss: 0.0945616140961647
step: 160, loss: 0.014841312542557716
step: 170, loss: 0.02030947245657444
step: 180, loss: 0.056723352521657944
step: 190, loss: 0.06516098231077194
step: 200, loss: 0.09742157906293869
step: 210, loss: 0.06259810924530029
step: 220, loss: 0.019643696025013924
step: 230, loss: 0.06932270526885986
step: 240, loss: 0.11458927392959595
step: 250, loss: 0.07015405595302582
step: 260, loss: 0.07865539193153381
step: 270, loss: 0.012803258374333382
step: 280, loss: 0.15118995308876038
step: 290, loss: 0.026060085743665695
step: 300, loss: 0.10942593216896057
step: 310, loss: 0.020331766456365585
step: 320, loss: 0.032472800463438034
step: 330, loss: 0.014552455395460129
step: 340, loss: 0.07618755102157593
step: 350, loss: 0.07028201967477798
epoch 20: dev_f1=0.8049999999999999, f1=0.7922705314009661, best_f1=0.7834101382488479
