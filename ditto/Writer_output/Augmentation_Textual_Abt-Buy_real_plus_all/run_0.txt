cuda
Device: cuda
step: 0, loss: 0.7088715434074402
step: 10, loss: 0.1696907877922058
step: 20, loss: 0.4316558837890625
step: 30, loss: 0.31160399317741394
step: 40, loss: 0.38260576128959656
step: 50, loss: 0.3194091320037842
step: 60, loss: 0.09335850179195404
step: 70, loss: 0.3060530424118042
step: 80, loss: 0.3138768970966339
step: 90, loss: 0.2870699465274811
step: 100, loss: 0.3689608573913574
step: 110, loss: 0.44861099123954773
step: 120, loss: 0.348721981048584
step: 130, loss: 0.2957899570465088
step: 140, loss: 0.3566499352455139
step: 150, loss: 0.4565236568450928
step: 160, loss: 0.35367608070373535
step: 170, loss: 0.1678558588027954
step: 180, loss: 0.32213088870048523
step: 190, loss: 0.33538827300071716
step: 200, loss: 0.48554712533950806
step: 210, loss: 0.42374494671821594
step: 220, loss: 0.31707823276519775
step: 230, loss: 0.32351934909820557
step: 240, loss: 0.21721814572811127
step: 250, loss: 0.29368892312049866
step: 260, loss: 0.25304925441741943
step: 270, loss: 0.1357554793357849
step: 280, loss: 0.1827356219291687
step: 290, loss: 0.1761624962091446
step: 300, loss: 0.1378817856311798
step: 310, loss: 0.14701195061206818
step: 320, loss: 0.2348431497812271
step: 330, loss: 0.30991441011428833
step: 340, loss: 0.1544339656829834
step: 350, loss: 0.16953521966934204
epoch 1: dev_f1=0.7185354691075515, f1=0.6989010989010989, best_f1=0.6989010989010989
step: 0, loss: 0.17899006605148315
step: 10, loss: 0.113625168800354
step: 20, loss: 0.23127910494804382
step: 30, loss: 0.3183349072933197
step: 40, loss: 0.15307746827602386
step: 50, loss: 0.08771935105323792
step: 60, loss: 0.16428472101688385
step: 70, loss: 0.19059818983078003
step: 80, loss: 0.19790540635585785
step: 90, loss: 0.09530975669622421
step: 100, loss: 0.20007319748401642
step: 110, loss: 0.12097056210041046
step: 120, loss: 0.23465308547019958
step: 130, loss: 0.14954547584056854
step: 140, loss: 0.09170716255903244
step: 150, loss: 0.0729716420173645
step: 160, loss: 0.15213871002197266
step: 170, loss: 0.1296357810497284
step: 180, loss: 0.08941618353128433
step: 190, loss: 0.1919863075017929
step: 200, loss: 0.23612305521965027
step: 210, loss: 0.06908077746629715
step: 220, loss: 0.0625818520784378
step: 230, loss: 0.08384037762880325
step: 240, loss: 0.12707552313804626
step: 250, loss: 0.11284303665161133
step: 260, loss: 0.21755823493003845
step: 270, loss: 0.19673646986484528
step: 280, loss: 0.09042038768529892
step: 290, loss: 0.18259410560131073
step: 300, loss: 0.15443724393844604
step: 310, loss: 0.10538440197706223
step: 320, loss: 0.2150639295578003
step: 330, loss: 0.17964936792850494
step: 340, loss: 0.405529648065567
step: 350, loss: 0.058018237352371216
epoch 2: dev_f1=0.7303609341825902, f1=0.7552742616033755, best_f1=0.7552742616033755
step: 0, loss: 0.07560979574918747
step: 10, loss: 0.052010420709848404
step: 20, loss: 0.020465640351176262
step: 30, loss: 0.08486049622297287
step: 40, loss: 0.10940782725811005
step: 50, loss: 0.09094329178333282
step: 60, loss: 0.08305744081735611
step: 70, loss: 0.17285461723804474
step: 80, loss: 0.14510172605514526
step: 90, loss: 0.1990758627653122
step: 100, loss: 0.2597314119338989
step: 110, loss: 0.10313516855239868
step: 120, loss: 0.12390396744012833
step: 130, loss: 0.1122671365737915
step: 140, loss: 0.08985213190317154
step: 150, loss: 0.037570904940366745
step: 160, loss: 0.20324811339378357
step: 170, loss: 0.11830845475196838
step: 180, loss: 0.32285770773887634
step: 190, loss: 0.12404222041368484
step: 200, loss: 0.07889141887426376
step: 210, loss: 0.11280612647533417
step: 220, loss: 0.17857439815998077
step: 230, loss: 0.04167952015995979
step: 240, loss: 0.10169746726751328
step: 250, loss: 0.1110827624797821
step: 260, loss: 0.10412320494651794
step: 270, loss: 0.10608653724193573
step: 280, loss: 0.09340446442365646
step: 290, loss: 0.03874308988451958
step: 300, loss: 0.1652943640947342
step: 310, loss: 0.061179742217063904
step: 320, loss: 0.0791890099644661
step: 330, loss: 0.10853011906147003
step: 340, loss: 0.1595022976398468
step: 350, loss: 0.11875628679990768
epoch 3: dev_f1=0.7910112359550562, f1=0.7662337662337663, best_f1=0.7662337662337663
step: 0, loss: 0.12187197804450989
step: 10, loss: 0.08202528953552246
step: 20, loss: 0.117462158203125
step: 30, loss: 0.17151519656181335
step: 40, loss: 0.17644812166690826
step: 50, loss: 0.02420946955680847
step: 60, loss: 0.15646621584892273
step: 70, loss: 0.0476660318672657
step: 80, loss: 0.06647750735282898
step: 90, loss: 0.060163285583257675
step: 100, loss: 0.02847987413406372
step: 110, loss: 0.11440165340900421
step: 120, loss: 0.0748649314045906
step: 130, loss: 0.0907808393239975
step: 140, loss: 0.11536715924739838
step: 150, loss: 0.051500048488378525
step: 160, loss: 0.06426283717155457
step: 170, loss: 0.11244530975818634
step: 180, loss: 0.17374329268932343
step: 190, loss: 0.0743337944149971
step: 200, loss: 0.08545664697885513
step: 210, loss: 0.07100134342908859
step: 220, loss: 0.11241583526134491
step: 230, loss: 0.16435682773590088
step: 240, loss: 0.1326388567686081
step: 250, loss: 0.09515920281410217
step: 260, loss: 0.1042739599943161
step: 270, loss: 0.10676343739032745
step: 280, loss: 0.181513249874115
step: 290, loss: 0.2550274729728699
step: 300, loss: 0.0578082837164402
step: 310, loss: 0.13763132691383362
step: 320, loss: 0.15402472019195557
step: 330, loss: 0.1229373887181282
step: 340, loss: 0.09292754530906677
step: 350, loss: 0.19381330907344818
epoch 4: dev_f1=0.8038740920096852, f1=0.8292682926829268, best_f1=0.8292682926829268
step: 0, loss: 0.06190737709403038
step: 10, loss: 0.07787514477968216
step: 20, loss: 0.044363878667354584
step: 30, loss: 0.10281874984502792
step: 40, loss: 0.11505488306283951
step: 50, loss: 0.06630915403366089
step: 60, loss: 0.07080614566802979
step: 70, loss: 0.0025401352904736996
step: 80, loss: 0.0893891230225563
step: 90, loss: 0.16114036738872528
step: 100, loss: 0.038011420518159866
step: 110, loss: 0.11935675144195557
step: 120, loss: 0.06686802953481674
step: 130, loss: 0.03191358223557472
step: 140, loss: 0.2615928649902344
step: 150, loss: 0.08877597749233246
step: 160, loss: 0.09787525981664658
step: 170, loss: 0.07602088898420334
step: 180, loss: 0.035811085253953934
step: 190, loss: 0.0009299367666244507
step: 200, loss: 0.0463089719414711
step: 210, loss: 0.05596116557717323
step: 220, loss: 0.08591219037771225
step: 230, loss: 0.05382092297077179
step: 240, loss: 0.09915488213300705
step: 250, loss: 0.09967183321714401
step: 260, loss: 0.0801670253276825
step: 270, loss: 0.07671519368886948
step: 280, loss: 0.04767175763845444
step: 290, loss: 0.07054516673088074
step: 300, loss: 0.13541726768016815
step: 310, loss: 0.07170487195253372
step: 320, loss: 0.13962595164775848
step: 330, loss: 0.06693520396947861
step: 340, loss: 0.13732370734214783
step: 350, loss: 0.13405244052410126
epoch 5: dev_f1=0.8134715025906737, f1=0.8186528497409326, best_f1=0.8186528497409326
step: 0, loss: 0.07940901070833206
step: 10, loss: 0.08266778290271759
step: 20, loss: 0.10250044614076614
step: 30, loss: 0.06264346092939377
step: 40, loss: 0.11064668744802475
step: 50, loss: 0.08506680279970169
step: 60, loss: 0.03955182060599327
step: 70, loss: 0.09202470630407333
step: 80, loss: 0.061798159033060074
step: 90, loss: 0.16436205804347992
step: 100, loss: 0.11342877894639969
step: 110, loss: 0.11901210993528366
step: 120, loss: 0.07893038541078568
step: 130, loss: 0.10862504690885544
step: 140, loss: 0.0910954475402832
step: 150, loss: 0.07487469911575317
step: 160, loss: 0.05285792425274849
step: 170, loss: 0.07869818806648254
step: 180, loss: 0.15406540036201477
step: 190, loss: 0.06250151991844177
step: 200, loss: 0.1906253844499588
step: 210, loss: 0.02981569990515709
step: 220, loss: 0.007586807943880558
step: 230, loss: 0.15353405475616455
step: 240, loss: 0.06126949563622475
step: 250, loss: 0.19117341935634613
step: 260, loss: 0.14459128677845
step: 270, loss: 0.08987752348184586
step: 280, loss: 0.029915690422058105
step: 290, loss: 0.11132191866636276
step: 300, loss: 0.06594180315732956
step: 310, loss: 0.06463901698589325
step: 320, loss: 0.1546657830476761
step: 330, loss: 0.07677142322063446
step: 340, loss: 0.06352677941322327
step: 350, loss: 0.22424733638763428
epoch 6: dev_f1=0.8112798264642084, f1=0.7820512820512822, best_f1=0.8186528497409326
step: 0, loss: 0.09102174639701843
step: 10, loss: 0.08158330619335175
step: 20, loss: 0.07255913317203522
step: 30, loss: 0.0795319601893425
step: 40, loss: 0.09786608070135117
step: 50, loss: 0.05701976269483566
step: 60, loss: 0.0536017045378685
step: 70, loss: 0.06887557357549667
step: 80, loss: 0.11230495572090149
step: 90, loss: 0.18343256413936615
step: 100, loss: 0.13774974644184113
step: 110, loss: 0.0879989042878151
step: 120, loss: 0.1283702254295349
step: 130, loss: 0.15479139983654022
step: 140, loss: 0.13830341398715973
step: 150, loss: 0.05786857753992081
step: 160, loss: 0.06447651982307434
step: 170, loss: 0.22033633291721344
step: 180, loss: 0.046738557517528534
step: 190, loss: 0.1099485382437706
step: 200, loss: 0.028373517096042633
step: 210, loss: 0.1578366607427597
step: 220, loss: 0.15407733619213104
step: 230, loss: 0.03308400511741638
step: 240, loss: 0.10304173827171326
step: 250, loss: 0.11841202527284622
step: 260, loss: 0.05523741990327835
step: 270, loss: 0.17757061123847961
step: 280, loss: 0.06344586610794067
step: 290, loss: 0.028832031413912773
step: 300, loss: 0.022174924612045288
step: 310, loss: 0.05364945903420448
step: 320, loss: 0.15780512988567352
step: 330, loss: 0.11653581261634827
step: 340, loss: 0.06797890365123749
step: 350, loss: 0.08041513711214066
epoch 7: dev_f1=0.8329177057356608, f1=0.8170426065162907, best_f1=0.8170426065162907
step: 0, loss: 0.06600616127252579
step: 10, loss: 0.03391887620091438
step: 20, loss: 0.05074057728052139
step: 30, loss: 0.04025741294026375
step: 40, loss: 0.05996311455965042
step: 50, loss: 0.05342891067266464
step: 60, loss: 0.08078627288341522
step: 70, loss: 0.060064803808927536
step: 80, loss: 0.08921875804662704
step: 90, loss: 0.15386962890625
step: 100, loss: 0.08164189755916595
step: 110, loss: 0.11498459428548813
step: 120, loss: 0.10710694640874863
step: 130, loss: 0.029837679117918015
step: 140, loss: 0.10933289676904678
step: 150, loss: 0.07598774135112762
step: 160, loss: 0.10736812651157379
step: 170, loss: 0.07849917560815811
step: 180, loss: 0.01012624055147171
step: 190, loss: 0.06155528873205185
step: 200, loss: 0.04233144596219063
step: 210, loss: 0.08242589235305786
step: 220, loss: 0.08855147659778595
step: 230, loss: 0.09332752227783203
step: 240, loss: 0.14648564159870148
step: 250, loss: 0.08395608514547348
step: 260, loss: 0.07193711400032043
step: 270, loss: 0.08649444580078125
step: 280, loss: 0.021159566938877106
step: 290, loss: 0.08725842088460922
step: 300, loss: 0.07722371816635132
step: 310, loss: 0.05491459369659424
step: 320, loss: 0.04232464358210564
step: 330, loss: 0.09508231282234192
step: 340, loss: 0.013973654247820377
step: 350, loss: 0.07014535367488861
epoch 8: dev_f1=0.8269662921348315, f1=0.7991071428571428, best_f1=0.8170426065162907
step: 0, loss: 0.03636958450078964
step: 10, loss: 0.07562775909900665
step: 20, loss: 0.025673069059848785
step: 30, loss: 0.07287487387657166
step: 40, loss: 0.050720635801553726
step: 50, loss: 0.033149898052215576
step: 60, loss: 0.028075499460101128
step: 70, loss: 0.04546716436743736
step: 80, loss: 0.06513046473264694
step: 90, loss: 0.06532733142375946
step: 100, loss: 0.06035942584276199
step: 110, loss: 0.12320272624492645
step: 120, loss: 0.06186731904745102
step: 130, loss: 0.056391313672065735
step: 140, loss: 0.13761211931705475
step: 150, loss: 0.03153903782367706
step: 160, loss: 0.08401213586330414
step: 170, loss: 0.025613294914364815
step: 180, loss: 0.04340456798672676
step: 190, loss: 0.11428029835224152
step: 200, loss: 0.004967684391885996
step: 210, loss: 0.04714182764291763
step: 220, loss: 0.0377030186355114
step: 230, loss: 0.09165985882282257
step: 240, loss: 0.08149485290050507
step: 250, loss: 0.11240781098604202
step: 260, loss: 0.06858934462070465
step: 270, loss: 0.07334212213754654
step: 280, loss: 0.06088223680853844
step: 290, loss: 0.07731042802333832
step: 300, loss: 0.06293541938066483
step: 310, loss: 0.14915716648101807
step: 320, loss: 0.10451090335845947
step: 330, loss: 0.06994304805994034
step: 340, loss: 0.09662008285522461
step: 350, loss: 0.10048410296440125
epoch 9: dev_f1=0.8246013667425968, f1=0.8080357142857143, best_f1=0.8170426065162907
step: 0, loss: 0.06101887300610542
step: 10, loss: 0.09031668305397034
step: 20, loss: 0.06295168399810791
step: 30, loss: 0.08042516559362411
step: 40, loss: 0.02643858641386032
step: 50, loss: 0.0806187093257904
step: 60, loss: 0.07018712908029556
step: 70, loss: 0.284440279006958
step: 80, loss: 0.05024946108460426
step: 90, loss: 0.08526939898729324
step: 100, loss: 0.03516930341720581
step: 110, loss: 0.09515348076820374
step: 120, loss: 0.1427048295736313
step: 130, loss: 0.09789086133241653
step: 140, loss: 0.02262081764638424
step: 150, loss: 0.08921307325363159
step: 160, loss: 0.2397572100162506
step: 170, loss: 0.1414596140384674
step: 180, loss: 0.07124613970518112
step: 190, loss: 0.15196825563907623
step: 200, loss: 0.13690035045146942
step: 210, loss: 0.03866077587008476
step: 220, loss: 0.05219753086566925
step: 230, loss: 0.06817051768302917
step: 240, loss: 0.05196448415517807
step: 250, loss: 0.011683352291584015
step: 260, loss: 0.03509936109185219
step: 270, loss: 0.12085191160440445
step: 280, loss: 0.09328965842723846
step: 290, loss: 0.0640951618552208
step: 300, loss: 0.19093415141105652
step: 310, loss: 0.14139582216739655
step: 320, loss: 0.00017406158440280706
step: 330, loss: 0.194006085395813
step: 340, loss: 0.11439340561628342
step: 350, loss: 0.03715286776423454
epoch 10: dev_f1=0.8153846153846153, f1=0.8030303030303031, best_f1=0.8170426065162907
step: 0, loss: 0.09647692739963531
step: 10, loss: 0.16206234693527222
step: 20, loss: 0.14957083761692047
step: 30, loss: 0.05208572372794151
step: 40, loss: 0.028309166431427002
step: 50, loss: 0.06228834390640259
step: 60, loss: 0.09212014079093933
step: 70, loss: 0.02280900627374649
step: 80, loss: 0.11319144070148468
step: 90, loss: 0.05438549444079399
step: 100, loss: 0.03340645879507065
step: 110, loss: 0.06514746695756912
step: 120, loss: 0.10687178373336792
step: 130, loss: 0.08416292071342468
step: 140, loss: 0.04204549267888069
step: 150, loss: 0.07462720572948456
step: 160, loss: 0.08988750725984573
step: 170, loss: 0.10094786435365677
step: 180, loss: 0.08941846340894699
step: 190, loss: 0.04822515323758125
step: 200, loss: 0.12164635211229324
step: 210, loss: 0.09363959729671478
step: 220, loss: 0.1821795254945755
step: 230, loss: 0.04351893439888954
step: 240, loss: 0.03186218440532684
step: 250, loss: 0.10218808054924011
step: 260, loss: 0.04407741129398346
step: 270, loss: 0.058098383247852325
step: 280, loss: 0.03681262582540512
step: 290, loss: 0.0977398157119751
step: 300, loss: 0.11437907069921494
step: 310, loss: 0.025205085054039955
step: 320, loss: 0.08403901010751724
step: 330, loss: 0.1427646428346634
step: 340, loss: 0.0693274512887001
step: 350, loss: 0.09052728116512299
epoch 11: dev_f1=0.8110599078341014, f1=0.7946428571428571, best_f1=0.8170426065162907
step: 0, loss: 0.16559940576553345
step: 10, loss: 0.21187318861484528
step: 20, loss: 0.06131511554121971
step: 30, loss: 0.07638854533433914
step: 40, loss: 0.013133622705936432
step: 50, loss: 0.07732315361499786
step: 60, loss: 0.014465956017374992
step: 70, loss: 0.04454822838306427
step: 80, loss: 0.06239936500787735
step: 90, loss: 0.024533359333872795
step: 100, loss: 0.13425183296203613
step: 110, loss: 0.09913118183612823
step: 120, loss: 0.11896150559186935
step: 130, loss: 0.0701160728931427
step: 140, loss: 0.07559576630592346
step: 150, loss: 0.043850719928741455
step: 160, loss: 0.045278165489435196
step: 170, loss: 0.04565287381410599
step: 180, loss: 0.06429526954889297
step: 190, loss: 0.09898795932531357
step: 200, loss: 0.13486187160015106
step: 210, loss: 0.06769037991762161
step: 220, loss: 0.07858049869537354
step: 230, loss: 0.07072677463293076
step: 240, loss: 0.0245132427662611
step: 250, loss: 0.006100162398070097
step: 260, loss: 0.0012607662938535213
step: 270, loss: 0.05817979946732521
step: 280, loss: 0.03427450358867645
step: 290, loss: 0.07903796434402466
step: 300, loss: 0.09498915821313858
step: 310, loss: 0.13300177454948425
step: 320, loss: 0.06557680666446686
step: 330, loss: 0.18812333047389984
step: 340, loss: 0.07787823677062988
step: 350, loss: 0.0971701517701149
epoch 12: dev_f1=0.8210023866348449, f1=0.8329297820823245, best_f1=0.8170426065162907
step: 0, loss: 0.05931178852915764
step: 10, loss: 0.03725562244653702
step: 20, loss: 0.09512894600629807
step: 30, loss: 0.06156693398952484
step: 40, loss: 0.011084438301622868
step: 50, loss: 0.1705775260925293
step: 60, loss: 0.02095365710556507
step: 70, loss: 0.14334240555763245
step: 80, loss: 0.10183191299438477
step: 90, loss: 0.1650230884552002
step: 100, loss: 0.16106218099594116
step: 110, loss: 0.12240707874298096
step: 120, loss: 0.053939491510391235
step: 130, loss: 0.08248350024223328
step: 140, loss: 0.03613802045583725
step: 150, loss: 0.06783173233270645
step: 160, loss: 0.08951019495725632
step: 170, loss: 0.012293996289372444
step: 180, loss: 0.12077753990888596
step: 190, loss: 0.015205681324005127
step: 200, loss: 0.12198799103498459
step: 210, loss: 0.12449084222316742
step: 220, loss: 0.08038849383592606
step: 230, loss: 0.017999840900301933
step: 240, loss: 0.03550927713513374
step: 250, loss: 0.05690354108810425
step: 260, loss: 0.06950344890356064
step: 270, loss: 0.03755568340420723
step: 280, loss: 0.03893176093697548
step: 290, loss: 0.06804213672876358
step: 300, loss: 0.07759007066488266
step: 310, loss: 0.09853825718164444
step: 320, loss: 0.03143161162734032
step: 330, loss: 0.10779347270727158
step: 340, loss: 0.0539836660027504
step: 350, loss: 0.06758751720190048
epoch 13: dev_f1=0.8082191780821918, f1=0.8081264108352145, best_f1=0.8170426065162907
step: 0, loss: 0.04043745994567871
step: 10, loss: 0.12265906482934952
step: 20, loss: 0.02124165929853916
step: 30, loss: 0.05696044862270355
step: 40, loss: 0.07608610391616821
step: 50, loss: 0.07336792349815369
step: 60, loss: 0.051433537155389786
step: 70, loss: 4.9018446588888764e-05
step: 80, loss: 0.10178892314434052
step: 90, loss: 0.06475913524627686
step: 100, loss: 0.11214246600866318
step: 110, loss: 0.02216961421072483
step: 120, loss: 0.03833291679620743
step: 130, loss: 0.020313521847128868
step: 140, loss: 0.01338240597397089
step: 150, loss: 0.02604159340262413
step: 160, loss: 0.06048796698451042
step: 170, loss: 0.06089140474796295
step: 180, loss: 0.10587099194526672
step: 190, loss: 0.2634817957878113
step: 200, loss: 0.13581153750419617
step: 210, loss: 0.07434731721878052
step: 220, loss: 0.09478654712438583
step: 230, loss: 0.1468607783317566
step: 240, loss: 0.04218650981783867
step: 250, loss: 0.07237747311592102
step: 260, loss: 0.12377803027629852
step: 270, loss: 0.11834216117858887
step: 280, loss: 0.03946094587445259
step: 290, loss: 0.036713387817144394
step: 300, loss: 0.1357562392950058
step: 310, loss: 0.06924460083246231
step: 320, loss: 0.10017766058444977
step: 330, loss: 0.11273355782032013
step: 340, loss: 0.08696029335260391
step: 350, loss: 0.08606722205877304
epoch 14: dev_f1=0.819047619047619, f1=0.8262910798122066, best_f1=0.8170426065162907
step: 0, loss: 0.05819954723119736
step: 10, loss: 0.09544598311185837
step: 20, loss: 0.04218258336186409
step: 30, loss: 0.0827069953083992
step: 40, loss: 0.03984283283352852
step: 50, loss: 0.07248545438051224
step: 60, loss: 0.11786309629678726
step: 70, loss: 0.10361457616090775
step: 80, loss: 0.06574855744838715
step: 90, loss: 0.043456800282001495
step: 100, loss: 0.022177528589963913
step: 110, loss: 0.011819709092378616
step: 120, loss: 0.08607974648475647
step: 130, loss: 0.09103283286094666
step: 140, loss: 0.07038114219903946
step: 150, loss: 0.061822958290576935
step: 160, loss: 0.0686778873205185
step: 170, loss: 0.04262741282582283
step: 180, loss: 0.02626153454184532
step: 190, loss: 0.11584765464067459
step: 200, loss: 0.047842837870121
step: 210, loss: 0.11592274904251099
step: 220, loss: 0.04969001188874245
step: 230, loss: 0.028195466846227646
step: 240, loss: 0.10083834826946259
step: 250, loss: 0.055331986397504807
step: 260, loss: 0.08537246286869049
step: 270, loss: 0.024441644549369812
step: 280, loss: 0.025323279201984406
step: 290, loss: 0.049233563244342804
step: 300, loss: 0.05765148624777794
step: 310, loss: 0.06464481353759766
step: 320, loss: 0.04206624627113342
step: 330, loss: 0.03773672878742218
step: 340, loss: 0.08026116341352463
step: 350, loss: 0.09084779024124146
epoch 15: dev_f1=0.794188861985472, f1=0.8028503562945368, best_f1=0.8170426065162907
step: 0, loss: 0.08113238960504532
step: 10, loss: 0.06775742769241333
step: 20, loss: 0.028199223801493645
step: 30, loss: 0.0541796013712883
step: 40, loss: 0.09029662609100342
step: 50, loss: 0.031703416258096695
step: 60, loss: 0.13941536843776703
step: 70, loss: 0.05837075039744377
step: 80, loss: 0.10864798724651337
step: 90, loss: 0.14361712336540222
step: 100, loss: 0.08251862972974777
step: 110, loss: 0.13427641987800598
step: 120, loss: 0.025566482916474342
step: 130, loss: 0.0707460343837738
step: 140, loss: 0.031469155102968216
step: 150, loss: 0.03280685842037201
step: 160, loss: 0.07092598080635071
step: 170, loss: 0.036282189190387726
step: 180, loss: 0.1879856437444687
step: 190, loss: 0.015070951543748379
step: 200, loss: 0.07608591020107269
step: 210, loss: 0.039857394993305206
step: 220, loss: 0.10985931754112244
step: 230, loss: 0.0479154959321022
step: 240, loss: 0.03285101801156998
step: 250, loss: 0.04377244412899017
step: 260, loss: 0.085781529545784
step: 270, loss: 0.03369862586259842
step: 280, loss: 0.08011788129806519
step: 290, loss: 0.03252922743558884
step: 300, loss: 0.07291648536920547
step: 310, loss: 0.0275765061378479
step: 320, loss: 0.06471741944551468
step: 330, loss: 0.10238079726696014
step: 340, loss: 0.059401363134384155
step: 350, loss: 5.4145413741935045e-05
epoch 16: dev_f1=0.8047058823529412, f1=0.8111888111888111, best_f1=0.8170426065162907
step: 0, loss: 0.02550385147333145
step: 10, loss: 0.03661741688847542
step: 20, loss: 0.059313274919986725
step: 30, loss: 0.09151457995176315
step: 40, loss: 0.08922617882490158
step: 50, loss: 0.04681464657187462
step: 60, loss: 0.055071622133255005
step: 70, loss: 0.0948902815580368
step: 80, loss: 0.05262567102909088
step: 90, loss: 0.07393021136522293
step: 100, loss: 0.06619870662689209
step: 110, loss: 0.09655716270208359
step: 120, loss: 0.11875683069229126
step: 130, loss: 0.04063155874609947
step: 140, loss: 0.11777973920106888
step: 150, loss: 0.08513595163822174
step: 160, loss: 0.05033993348479271
step: 170, loss: 0.09231753647327423
step: 180, loss: 0.08992421627044678
step: 190, loss: 0.15759660303592682
step: 200, loss: 0.028517751023173332
step: 210, loss: 0.08251335471868515
step: 220, loss: 0.08444462716579437
step: 230, loss: 0.13945336639881134
step: 240, loss: 0.1498516947031021
step: 250, loss: 0.0888342559337616
step: 260, loss: 0.03235409036278725
step: 270, loss: 0.05942190811038017
step: 280, loss: 0.033930547535419464
step: 290, loss: 0.057843077927827835
step: 300, loss: 0.02607262134552002
step: 310, loss: 0.01970010995864868
step: 320, loss: 0.07355327159166336
step: 330, loss: 0.08817236870527267
step: 340, loss: 0.07892976701259613
step: 350, loss: 0.022865334525704384
epoch 17: dev_f1=0.8066037735849056, f1=0.8028169014084506, best_f1=0.8170426065162907
step: 0, loss: 0.11796453595161438
step: 10, loss: 0.04676777124404907
step: 20, loss: 0.05254652351140976
step: 30, loss: 0.04241390898823738
step: 40, loss: 0.15919703245162964
step: 50, loss: 0.147153839468956
step: 60, loss: 0.020107224583625793
step: 70, loss: 0.07637190818786621
step: 80, loss: 0.03755827993154526
step: 90, loss: 0.12988784909248352
step: 100, loss: 0.17123495042324066
step: 110, loss: 0.027534110471606255
step: 120, loss: 0.12294193357229233
step: 130, loss: 0.09591326117515564
step: 140, loss: 0.03498270362615585
step: 150, loss: 0.041263557970523834
step: 160, loss: 0.0680578425526619
step: 170, loss: 0.10959019511938095
step: 180, loss: 0.14107438921928406
step: 190, loss: 0.04622642695903778
step: 200, loss: 0.01968330331146717
step: 210, loss: 0.007524581626057625
step: 220, loss: 0.1157861277461052
step: 230, loss: 0.017348753288388252
step: 240, loss: 0.08329971879720688
step: 250, loss: 0.11417602747678757
step: 260, loss: 0.1077604591846466
step: 270, loss: 0.08909212797880173
step: 280, loss: 0.011939400807023048
step: 290, loss: 0.08890178799629211
step: 300, loss: 4.7067729610716924e-05
step: 310, loss: 0.050479013472795486
step: 320, loss: 0.03199310600757599
step: 330, loss: 0.10756871849298477
step: 340, loss: 0.05865848436951637
step: 350, loss: 0.07570295035839081
epoch 18: dev_f1=0.8123515439429927, f1=0.810304449648712, best_f1=0.8170426065162907
step: 0, loss: 0.00011895597708644345
step: 10, loss: 0.056843530386686325
step: 20, loss: 0.03236205875873566
step: 30, loss: 0.12291409820318222
step: 40, loss: 0.038670770823955536
step: 50, loss: 0.025599658489227295
step: 60, loss: 0.06516031175851822
step: 70, loss: 0.08108308166265488
step: 80, loss: 0.1073380559682846
step: 90, loss: 0.04222514480352402
step: 100, loss: 0.0475732758641243
step: 110, loss: 0.08190710097551346
step: 120, loss: 0.05713006108999252
step: 130, loss: 0.07696900516748428
step: 140, loss: 0.03530473634600639
step: 150, loss: 0.09404409676790237
step: 160, loss: 0.09285138547420502
step: 170, loss: 0.07248077541589737
step: 180, loss: 0.07160662859678268
step: 190, loss: 0.05153762176632881
step: 200, loss: 0.010513851419091225
step: 210, loss: 0.09504742175340652
step: 220, loss: 0.0028012925758957863
step: 230, loss: 0.028188077732920647
step: 240, loss: 0.09377565234899521
step: 250, loss: 0.1894194334745407
step: 260, loss: 0.1015428826212883
step: 270, loss: 0.04549526795744896
step: 280, loss: 0.047312211245298386
step: 290, loss: 0.12037701904773712
step: 300, loss: 0.12296481430530548
step: 310, loss: 0.17741580307483673
step: 320, loss: 0.05218185856938362
step: 330, loss: 0.06620197743177414
step: 340, loss: 5.249232708592899e-05
step: 350, loss: 0.016990652307868004
epoch 19: dev_f1=0.8123515439429927, f1=0.812206572769953, best_f1=0.8170426065162907
step: 0, loss: 0.00014239987649489194
step: 10, loss: 0.09328491985797882
step: 20, loss: 0.04897515848278999
step: 30, loss: 0.10366985946893692
step: 40, loss: 0.060795318335294724
step: 50, loss: 0.0940166786313057
step: 60, loss: 0.017307598143815994
step: 70, loss: 0.043571338057518005
step: 80, loss: 0.04633267596364021
step: 90, loss: 0.09663984179496765
step: 100, loss: 0.06737171113491058
step: 110, loss: 0.03240317851305008
step: 120, loss: 0.051140397787094116
step: 130, loss: 0.05193325877189636
step: 140, loss: 0.03466236591339111
step: 150, loss: 0.06808511912822723
step: 160, loss: 0.16857004165649414
step: 170, loss: 0.04813295602798462
step: 180, loss: 0.10036037117242813
step: 190, loss: 0.034043535590171814
step: 200, loss: 0.11652945727109909
step: 210, loss: 0.06157444417476654
step: 220, loss: 0.09933125227689743
step: 230, loss: 0.10242946445941925
step: 240, loss: 0.05030268803238869
step: 250, loss: 0.05272121727466583
step: 260, loss: 0.1608743816614151
step: 270, loss: 0.025069497525691986
step: 280, loss: 0.05809639394283295
step: 290, loss: 0.07789839804172516
step: 300, loss: 0.049500200897455215
step: 310, loss: 0.0831187292933464
step: 320, loss: 0.0657283142209053
step: 330, loss: 0.023129533976316452
step: 340, loss: 0.062190618366003036
step: 350, loss: 0.06003445014357567
epoch 20: dev_f1=0.8038277511961723, f1=0.8056872037914692, best_f1=0.8170426065162907
