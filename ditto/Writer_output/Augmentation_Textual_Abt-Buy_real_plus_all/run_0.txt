cuda
Device: cuda
step: 0, loss: 0.5735340714454651
step: 10, loss: 0.4877285957336426
step: 20, loss: 0.22114025056362152
step: 30, loss: 0.4571990966796875
step: 40, loss: 0.37983477115631104
step: 50, loss: 0.47434526681900024
step: 60, loss: 0.35013726353645325
step: 70, loss: 0.541217029094696
step: 80, loss: 0.15562017261981964
step: 90, loss: 0.3951494097709656
step: 100, loss: 0.30761197209358215
step: 110, loss: 0.347342848777771
step: 120, loss: 0.3878742456436157
step: 130, loss: 0.3003905713558197
step: 140, loss: 0.2645243704319
step: 150, loss: 0.27713847160339355
step: 160, loss: 0.4255848824977875
step: 170, loss: 0.3034306764602661
step: 180, loss: 0.19516335427761078
step: 190, loss: 0.27809080481529236
step: 200, loss: 0.49023932218551636
step: 210, loss: 0.29915162920951843
step: 220, loss: 0.2680249810218811
step: 230, loss: 0.24795381724834442
step: 240, loss: 0.32297462224960327
step: 250, loss: 0.47207194566726685
step: 260, loss: 0.24823784828186035
step: 270, loss: 0.3527202010154724
step: 280, loss: 0.09215802699327469
step: 290, loss: 0.20676396787166595
step: 300, loss: 0.12420150637626648
step: 310, loss: 0.23727355897426605
step: 320, loss: 0.14637264609336853
step: 330, loss: 0.06765053421258926
step: 340, loss: 0.12936437129974365
step: 350, loss: 0.19611811637878418
epoch 1: dev_f1=0.6195652173913043, f1=0.624113475177305, best_f1=0.624113475177305
step: 0, loss: 0.17926271259784698
step: 10, loss: 0.30743613839149475
step: 20, loss: 0.12654703855514526
step: 30, loss: 0.10117825865745544
step: 40, loss: 0.08238546550273895
step: 50, loss: 0.07554980367422104
step: 60, loss: 0.11839863657951355
step: 70, loss: 0.12163195759057999
step: 80, loss: 0.07449587434530258
step: 90, loss: 0.10122944414615631
step: 100, loss: 0.19404418766498566
step: 110, loss: 0.13798373937606812
step: 120, loss: 0.0884471982717514
step: 130, loss: 0.07044859230518341
step: 140, loss: 0.12519162893295288
step: 150, loss: 0.152401864528656
step: 160, loss: 0.08273588865995407
step: 170, loss: 0.15589836239814758
step: 180, loss: 0.2713015079498291
step: 190, loss: 0.10431055724620819
step: 200, loss: 0.1301395744085312
step: 210, loss: 0.07713170349597931
step: 220, loss: 0.14667783677577972
step: 230, loss: 0.1078621968626976
step: 240, loss: 0.11425185948610306
step: 250, loss: 0.07136610895395279
step: 260, loss: 0.09889567643404007
step: 270, loss: 0.22769691050052643
step: 280, loss: 0.2498580664396286
step: 290, loss: 0.05479396507143974
step: 300, loss: 0.1728222370147705
step: 310, loss: 0.06135164946317673
step: 320, loss: 0.10161995887756348
step: 330, loss: 0.11139664798974991
step: 340, loss: 0.1230364665389061
step: 350, loss: 0.0928458571434021
epoch 2: dev_f1=0.7765726681127982, f1=0.7551867219917013, best_f1=0.7551867219917013
step: 0, loss: 0.09826868027448654
step: 10, loss: 0.33338409662246704
step: 20, loss: 0.2446240335702896
step: 30, loss: 0.2279086858034134
step: 40, loss: 0.17786189913749695
step: 50, loss: 0.08896433562040329
step: 60, loss: 0.05077076703310013
step: 70, loss: 0.07517694681882858
step: 80, loss: 0.024870801717042923
step: 90, loss: 0.13876493275165558
step: 100, loss: 0.1054723784327507
step: 110, loss: 0.0830225944519043
step: 120, loss: 0.014177881181240082
step: 130, loss: 0.1268022060394287
step: 140, loss: 0.10047618299722672
step: 150, loss: 0.17673896253108978
step: 160, loss: 0.1943942904472351
step: 170, loss: 0.16360816359519958
step: 180, loss: 0.10945146530866623
step: 190, loss: 0.05102569982409477
step: 200, loss: 0.06918313354253769
step: 210, loss: 0.1629251092672348
step: 220, loss: 0.06134370341897011
step: 230, loss: 0.11329128593206406
step: 240, loss: 0.06944360584020615
step: 250, loss: 0.0724543109536171
step: 260, loss: 0.03672012686729431
step: 270, loss: 0.10399807244539261
step: 280, loss: 0.20345552265644073
step: 290, loss: 0.11702732741832733
step: 300, loss: 0.20787426829338074
step: 310, loss: 0.07565249502658844
step: 320, loss: 0.08859670162200928
step: 330, loss: 0.08404736965894699
step: 340, loss: 0.05330366641283035
step: 350, loss: 0.14657503366470337
epoch 3: dev_f1=0.8169642857142858, f1=0.7709251101321585, best_f1=0.7709251101321585
step: 0, loss: 0.06736724078655243
step: 10, loss: 0.06853706389665604
step: 20, loss: 0.13612011075019836
step: 30, loss: 0.1250498741865158
step: 40, loss: 0.07955710589885712
step: 50, loss: 0.10263095796108246
step: 60, loss: 0.10635347664356232
step: 70, loss: 0.07331233471632004
step: 80, loss: 0.17758683860301971
step: 90, loss: 0.1307447999715805
step: 100, loss: 0.09528570622205734
step: 110, loss: 0.05656290054321289
step: 120, loss: 0.10497070103883743
step: 130, loss: 0.02195814996957779
step: 140, loss: 0.22673740983009338
step: 150, loss: 0.07528199255466461
step: 160, loss: 0.2304036021232605
step: 170, loss: 0.1353142410516739
step: 180, loss: 0.08286578208208084
step: 190, loss: 0.09056785702705383
step: 200, loss: 0.1520455926656723
step: 210, loss: 0.37075716257095337
step: 220, loss: 0.15486553311347961
step: 230, loss: 0.20808911323547363
step: 240, loss: 0.1117686778306961
step: 250, loss: 0.09330002963542938
step: 260, loss: 0.08124998211860657
step: 270, loss: 0.050648611038923264
step: 280, loss: 0.1059732660651207
step: 290, loss: 0.008924797177314758
step: 300, loss: 0.07229895889759064
step: 310, loss: 0.12934370338916779
step: 320, loss: 0.10088292509317398
step: 330, loss: 0.059607114642858505
step: 340, loss: 0.1536010056734085
step: 350, loss: 0.1350826472043991
epoch 4: dev_f1=0.8096385542168675, f1=0.7518072289156627, best_f1=0.7709251101321585
step: 0, loss: 0.05631639063358307
step: 10, loss: 0.06860244274139404
step: 20, loss: 0.014875993132591248
step: 30, loss: 0.06275230646133423
step: 40, loss: 0.226103737950325
step: 50, loss: 0.07066069543361664
step: 60, loss: 0.14345023036003113
step: 70, loss: 0.13233068585395813
step: 80, loss: 0.01246619038283825
step: 90, loss: 0.156646728515625
step: 100, loss: 0.10613079369068146
step: 110, loss: 0.10557948052883148
step: 120, loss: 0.12670999765396118
step: 130, loss: 0.03562892600893974
step: 140, loss: 0.050088997930288315
step: 150, loss: 0.04113617166876793
step: 160, loss: 0.07060519605875015
step: 170, loss: 0.01418810710310936
step: 180, loss: 0.054864633828401566
step: 190, loss: 0.09844183921813965
step: 200, loss: 0.20130665600299835
step: 210, loss: 0.13732923567295074
step: 220, loss: 0.08916454017162323
step: 230, loss: 0.1283494383096695
step: 240, loss: 0.08033941686153412
step: 250, loss: 0.13330109417438507
step: 260, loss: 0.13725988566875458
step: 270, loss: 0.09042785316705704
step: 280, loss: 0.11181042343378067
step: 290, loss: 0.14613790810108185
step: 300, loss: 0.11676536500453949
step: 310, loss: 0.06920639425516129
step: 320, loss: 0.2042054533958435
step: 330, loss: 0.05018187686800957
step: 340, loss: 0.03707972913980484
step: 350, loss: 0.11706700176000595
epoch 5: dev_f1=0.7931034482758621, f1=0.7817745803357313, best_f1=0.7709251101321585
step: 0, loss: 0.10065420717000961
step: 10, loss: 0.10953410714864731
step: 20, loss: 0.11109974980354309
step: 30, loss: 0.009903277270495892
step: 40, loss: 0.03935500979423523
step: 50, loss: 0.14737734198570251
step: 60, loss: 0.11446946859359741
step: 70, loss: 0.08563007414340973
step: 80, loss: 0.10982664674520493
step: 90, loss: 0.08204878866672516
step: 100, loss: 0.058392152190208435
step: 110, loss: 0.18061599135398865
step: 120, loss: 0.15713045001029968
step: 130, loss: 0.05181797593832016
step: 140, loss: 0.03462987765669823
step: 150, loss: 0.05639755725860596
step: 160, loss: 0.07327566295862198
step: 170, loss: 0.02732526883482933
step: 180, loss: 0.13366596400737762
step: 190, loss: 0.005668983329087496
step: 200, loss: 0.0838625580072403
step: 210, loss: 0.05047271028161049
step: 220, loss: 0.13352032005786896
step: 230, loss: 0.04392161965370178
step: 240, loss: 0.09803758561611176
step: 250, loss: 0.15676383674144745
step: 260, loss: 0.21127501130104065
step: 270, loss: 0.16051030158996582
step: 280, loss: 0.02901931293308735
step: 290, loss: 0.05732065066695213
step: 300, loss: 0.050044458359479904
step: 310, loss: 0.0643751248717308
step: 320, loss: 0.07890430092811584
step: 330, loss: 0.17015856504440308
step: 340, loss: 0.005887276493012905
step: 350, loss: 0.05891445279121399
epoch 6: dev_f1=0.8099999999999999, f1=0.7785888077858881, best_f1=0.7709251101321585
step: 0, loss: 0.04788782075047493
step: 10, loss: 0.053308676928281784
step: 20, loss: 0.10224691778421402
step: 30, loss: 0.09810648113489151
step: 40, loss: 0.10160686820745468
step: 50, loss: 0.03934363275766373
step: 60, loss: 0.05722033604979515
step: 70, loss: 0.13687466084957123
step: 80, loss: 0.04390114173293114
step: 90, loss: 0.0943857952952385
step: 100, loss: 0.05931860953569412
step: 110, loss: 0.11282709985971451
step: 120, loss: 0.14203953742980957
step: 130, loss: 0.125528022646904
step: 140, loss: 0.11566565930843353
step: 150, loss: 0.0857788696885109
step: 160, loss: 0.06878270208835602
step: 170, loss: 0.07710502296686172
step: 180, loss: 0.20399221777915955
step: 190, loss: 0.11296701431274414
step: 200, loss: 0.0983138307929039
step: 210, loss: 0.15689654648303986
step: 220, loss: 0.038214061409235
step: 230, loss: 0.11877414584159851
step: 240, loss: 0.026718057692050934
step: 250, loss: 0.14031316339969635
step: 260, loss: 0.0313110388815403
step: 270, loss: 0.21286502480506897
step: 280, loss: 0.11158719658851624
step: 290, loss: 0.11911197006702423
step: 300, loss: 0.0938006117939949
step: 310, loss: 0.12510910630226135
step: 320, loss: 0.13116326928138733
step: 330, loss: 0.04445056617259979
step: 340, loss: 0.10424578189849854
step: 350, loss: 0.06976130604743958
epoch 7: dev_f1=0.8337236533957846, f1=0.8093023255813954, best_f1=0.8093023255813954
step: 0, loss: 0.18565216660499573
step: 10, loss: 0.12823288142681122
step: 20, loss: 0.07334394007921219
step: 30, loss: 0.0729641392827034
step: 40, loss: 0.14580672979354858
step: 50, loss: 0.04667635262012482
step: 60, loss: 0.059621814638376236
step: 70, loss: 0.04193280264735222
step: 80, loss: 0.046561241149902344
step: 90, loss: 0.08063051849603653
step: 100, loss: 0.06498854607343674
step: 110, loss: 0.09794158488512039
step: 120, loss: 0.1455104798078537
step: 130, loss: 0.054056622087955475
step: 140, loss: 0.05120616778731346
step: 150, loss: 0.05983339622616768
step: 160, loss: 0.09151087701320648
step: 170, loss: 0.06013120710849762
step: 180, loss: 0.11152085661888123
step: 190, loss: 0.01310422271490097
step: 200, loss: 0.267626017332077
step: 210, loss: 0.09660718590021133
step: 220, loss: 0.10221066325902939
step: 230, loss: 0.03244839981198311
step: 240, loss: 0.10186246782541275
step: 250, loss: 0.1139497309923172
step: 260, loss: 0.024478651583194733
step: 270, loss: 0.053854282945394516
step: 280, loss: 0.06583090871572495
step: 290, loss: 0.1585789918899536
step: 300, loss: 0.05663880705833435
step: 310, loss: 0.09207803010940552
step: 320, loss: 0.06910723447799683
step: 330, loss: 0.0535813644528389
step: 340, loss: 0.07545465230941772
step: 350, loss: 0.04100640490651131
epoch 8: dev_f1=0.8229665071770335, f1=0.8056872037914692, best_f1=0.8093023255813954
step: 0, loss: 5.154497193871066e-05
step: 10, loss: 0.0794321820139885
step: 20, loss: 0.19677244126796722
step: 30, loss: 0.13449008762836456
step: 40, loss: 0.08488865196704865
step: 50, loss: 0.05374369025230408
step: 60, loss: 0.08952751010656357
step: 70, loss: 0.19697710871696472
step: 80, loss: 0.05524299293756485
step: 90, loss: 0.09453433752059937
step: 100, loss: 0.08988061547279358
step: 110, loss: 0.08542945235967636
step: 120, loss: 0.09107289463281631
step: 130, loss: 0.05377931520342827
step: 140, loss: 0.15537911653518677
step: 150, loss: 0.07191509008407593
step: 160, loss: 0.10630253702402115
step: 170, loss: 0.05963967368006706
step: 180, loss: 0.05839237570762634
step: 190, loss: 0.10670559853315353
step: 200, loss: 0.1137034073472023
step: 210, loss: 0.06950095295906067
step: 220, loss: 0.03540033847093582
step: 230, loss: 0.058059677481651306
step: 240, loss: 0.08267311006784439
step: 250, loss: 0.08211352676153183
step: 260, loss: 0.13018561899662018
step: 270, loss: 0.0012332756305113435
step: 280, loss: 0.1009502112865448
step: 290, loss: 0.0516434982419014
step: 300, loss: 0.12760311365127563
step: 310, loss: 0.11890088766813278
step: 320, loss: 0.04625042527914047
step: 330, loss: 0.06357212364673615
step: 340, loss: 0.07920421659946442
step: 350, loss: 0.10672802478075027
epoch 9: dev_f1=0.8194444444444444, f1=0.8026905829596412, best_f1=0.8093023255813954
step: 0, loss: 0.04512878879904747
step: 10, loss: 0.10295993089675903
step: 20, loss: 0.04531813785433769
step: 30, loss: 0.037484899163246155
step: 40, loss: 0.17652788758277893
step: 50, loss: 0.10155214369297028
step: 60, loss: 0.3668932020664215
step: 70, loss: 0.04525473713874817
step: 80, loss: 0.08991675823926926
step: 90, loss: 0.10858836024999619
step: 100, loss: 0.0675957053899765
step: 110, loss: 0.0005634936969727278
step: 120, loss: 0.08842525631189346
step: 130, loss: 0.0727737545967102
step: 140, loss: 0.055036649107933044
step: 150, loss: 0.05929248780012131
step: 160, loss: 0.09680396318435669
step: 170, loss: 0.07397471368312836
step: 180, loss: 0.06475602090358734
step: 190, loss: 0.0033937753178179264
step: 200, loss: 0.18018829822540283
step: 210, loss: 0.04863600805401802
step: 220, loss: 0.10179027169942856
step: 230, loss: 0.08884911239147186
step: 240, loss: 0.05775336176156998
step: 250, loss: 0.05553003028035164
step: 260, loss: 0.06344759464263916
step: 270, loss: 0.09915027022361755
step: 280, loss: 0.08768976479768753
step: 290, loss: 0.12518106400966644
step: 300, loss: 0.0920339897274971
step: 310, loss: 0.09079714119434357
step: 320, loss: 0.11622914671897888
step: 330, loss: 0.08126413077116013
step: 340, loss: 0.07155270874500275
step: 350, loss: 0.07140345126390457
epoch 10: dev_f1=0.8094117647058824, f1=0.8055555555555555, best_f1=0.8093023255813954
step: 0, loss: 0.06347712129354477
step: 10, loss: 0.021046357229351997
step: 20, loss: 0.09781841933727264
step: 30, loss: 0.048346880823373795
step: 40, loss: 0.09706604480743408
step: 50, loss: 0.03927253186702728
step: 60, loss: 0.10933960229158401
step: 70, loss: 0.06500037759542465
step: 80, loss: 0.0647357776761055
step: 90, loss: 0.018788544461131096
step: 100, loss: 0.11888232082128525
step: 110, loss: 0.048654887825250626
step: 120, loss: 0.11840644478797913
step: 130, loss: 0.09971767663955688
step: 140, loss: 0.0918477326631546
step: 150, loss: 0.0494353361427784
step: 160, loss: 0.041052304208278656
step: 170, loss: 0.08976416289806366
step: 180, loss: 0.10676740854978561
step: 190, loss: 0.07796864211559296
step: 200, loss: 0.00032229864154942334
step: 210, loss: 0.10798811167478561
step: 220, loss: 0.06304488331079483
step: 230, loss: 0.13089680671691895
step: 240, loss: 0.10435661673545837
step: 250, loss: 0.08594521135091782
step: 260, loss: 0.1822773665189743
step: 270, loss: 0.042127370834350586
step: 280, loss: 0.06471794843673706
step: 290, loss: 0.09245812147855759
step: 300, loss: 0.07547120004892349
step: 310, loss: 0.04126190394163132
step: 320, loss: 0.12515771389007568
step: 330, loss: 0.013882691040635109
step: 340, loss: 0.06963825970888138
step: 350, loss: 0.1653740555047989
epoch 11: dev_f1=0.8117359413202935, f1=0.7951807228915662, best_f1=0.8093023255813954
step: 0, loss: 0.09428302198648453
step: 10, loss: 0.1325421780347824
step: 20, loss: 0.036986395716667175
step: 30, loss: 0.025078414008021355
step: 40, loss: 0.04844331741333008
step: 50, loss: 0.04708094149827957
step: 60, loss: 0.08142224699258804
step: 70, loss: 0.0700903832912445
step: 80, loss: 0.021010829135775566
step: 90, loss: 0.12257768213748932
step: 100, loss: 0.09019085019826889
step: 110, loss: 0.05512060597538948
step: 120, loss: 0.09142064303159714
step: 130, loss: 0.08316491544246674
step: 140, loss: 0.008940483443439007
step: 150, loss: 0.07727861404418945
step: 160, loss: 0.04894005507230759
step: 170, loss: 0.0898965448141098
step: 180, loss: 0.0511263832449913
step: 190, loss: 0.03562653064727783
step: 200, loss: 0.06697430461645126
step: 210, loss: 0.13053418695926666
step: 220, loss: 0.12114723026752472
step: 230, loss: 0.1149946078658104
step: 240, loss: 0.1352842003107071
step: 250, loss: 0.06491845846176147
step: 260, loss: 0.032083019614219666
step: 270, loss: 0.04485071077942848
step: 280, loss: 0.050882283598184586
step: 290, loss: 0.09918458759784698
step: 300, loss: 0.06299015134572983
step: 310, loss: 0.022642463445663452
step: 320, loss: 0.10497450828552246
step: 330, loss: 0.0868760272860527
step: 340, loss: 0.08360016345977783
step: 350, loss: 0.040619153529405594
epoch 12: dev_f1=0.7892156862745098, f1=0.7764127764127765, best_f1=0.8093023255813954
step: 0, loss: 0.07973062992095947
step: 10, loss: 0.13674737513065338
step: 20, loss: 0.04483110085129738
step: 30, loss: 0.13286490738391876
step: 40, loss: 0.020248007029294968
step: 50, loss: 0.018598366528749466
step: 60, loss: 0.12222471088171005
step: 70, loss: 0.10331303626298904
step: 80, loss: 0.10322926938533783
step: 90, loss: 0.0472429096698761
step: 100, loss: 0.14213132858276367
step: 110, loss: 0.09034694731235504
step: 120, loss: 0.041993726044893265
step: 130, loss: 0.0005151060759089887
step: 140, loss: 0.10920605808496475
step: 150, loss: 0.09495818614959717
step: 160, loss: 0.09134043008089066
step: 170, loss: 0.09321708232164383
step: 180, loss: 0.13592295348644257
step: 190, loss: 0.07226605713367462
step: 200, loss: 0.034297600388526917
step: 210, loss: 0.03724132478237152
step: 220, loss: 0.050684332847595215
step: 230, loss: 0.06668109446763992
step: 240, loss: 0.059636250138282776
step: 250, loss: 0.03959931060671806
step: 260, loss: 0.07499102503061295
step: 270, loss: 0.09844730794429779
step: 280, loss: 0.17349648475646973
step: 290, loss: 0.06680389493703842
step: 300, loss: 0.1306873857975006
step: 310, loss: 0.06646636128425598
step: 320, loss: 0.11753245443105698
step: 330, loss: 0.021105799823999405
step: 340, loss: 0.05089479684829712
step: 350, loss: 0.015291295945644379
epoch 13: dev_f1=0.7999999999999999, f1=0.7897196261682243, best_f1=0.8093023255813954
step: 0, loss: 0.07172966748476028
step: 10, loss: 0.019604403525590897
step: 20, loss: 0.08697135746479034
step: 30, loss: 0.06956985592842102
step: 40, loss: 0.04398994520306587
step: 50, loss: 0.03711656108498573
step: 60, loss: 0.09081337600946426
step: 70, loss: 0.0730171650648117
step: 80, loss: 0.18813568353652954
step: 90, loss: 0.030338039621710777
step: 100, loss: 0.14457781612873077
step: 110, loss: 0.13155654072761536
step: 120, loss: 0.05276929587125778
step: 130, loss: 0.08377760648727417
step: 140, loss: 0.044987358152866364
step: 150, loss: 0.05295862257480621
step: 160, loss: 0.08617664128541946
step: 170, loss: 0.09293457120656967
step: 180, loss: 0.04592801257967949
step: 190, loss: 0.07292885333299637
step: 200, loss: 7.163379632402211e-05
step: 210, loss: 0.026338571682572365
step: 220, loss: 0.0003237217024434358
step: 230, loss: 0.04668356478214264
step: 240, loss: 0.02355983480811119
step: 250, loss: 0.1053895652294159
step: 260, loss: 0.06292689591646194
step: 270, loss: 0.09227300435304642
step: 280, loss: 0.013991758227348328
step: 290, loss: 0.015321542508900166
step: 300, loss: 0.07630831748247147
step: 310, loss: 0.07583983242511749
step: 320, loss: 0.09110696613788605
step: 330, loss: 0.070854552090168
step: 340, loss: 0.08823024481534958
step: 350, loss: 0.05081736668944359
epoch 14: dev_f1=0.8114558472553699, f1=0.8037825059101655, best_f1=0.8093023255813954
step: 0, loss: 0.11155959963798523
step: 10, loss: 0.06562419980764389
step: 20, loss: 0.05494300276041031
step: 30, loss: 0.1229485273361206
step: 40, loss: 0.06103363260626793
step: 50, loss: 0.13863004744052887
step: 60, loss: 0.02788630686700344
step: 70, loss: 0.06294892728328705
step: 80, loss: 0.07244529575109482
step: 90, loss: 0.038485750555992126
step: 100, loss: 0.02900015190243721
step: 110, loss: 0.024408578872680664
step: 120, loss: 0.06964866816997528
step: 130, loss: 0.05790172144770622
step: 140, loss: 0.09229058027267456
step: 150, loss: 0.09825267642736435
step: 160, loss: 0.16314570605754852
step: 170, loss: 0.06168206408619881
step: 180, loss: 0.0576365701854229
step: 190, loss: 0.019390635192394257
step: 200, loss: 0.04084789380431175
step: 210, loss: 0.05916614085435867
step: 220, loss: 0.042443178594112396
step: 230, loss: 0.05608882009983063
step: 240, loss: 0.07254370301961899
step: 250, loss: 0.0892559066414833
step: 260, loss: 0.05529925972223282
step: 270, loss: 0.10439237207174301
step: 280, loss: 0.10347726196050644
step: 290, loss: 0.03380857780575752
step: 300, loss: 2.1438640033011325e-05
step: 310, loss: 0.0408875048160553
step: 320, loss: 0.04323629289865494
step: 330, loss: 0.10021650791168213
step: 340, loss: 0.09915944188833237
step: 350, loss: 0.02091163769364357
epoch 15: dev_f1=0.8086124401913874, f1=0.813953488372093, best_f1=0.8093023255813954
step: 0, loss: 9.635929018259048e-05
step: 10, loss: 0.08276969194412231
step: 20, loss: 0.09537073969841003
step: 30, loss: 0.03231710568070412
step: 40, loss: 0.16112613677978516
step: 50, loss: 0.1142628937959671
step: 60, loss: 0.12507474422454834
step: 70, loss: 0.14237989485263824
step: 80, loss: 0.039096999913454056
step: 90, loss: 0.04426192119717598
step: 100, loss: 0.05672447010874748
step: 110, loss: 7.664263102924451e-05
step: 120, loss: 0.11493302136659622
step: 130, loss: 0.04415362328290939
step: 140, loss: 0.06920209527015686
step: 150, loss: 0.06268320232629776
step: 160, loss: 0.09412062913179398
step: 170, loss: 0.08174595236778259
step: 180, loss: 0.1253109723329544
step: 190, loss: 0.06389986723661423
step: 200, loss: 0.020015902817249298
step: 210, loss: 0.024437315762043
step: 220, loss: 0.09672689437866211
step: 230, loss: 0.17882293462753296
step: 240, loss: 0.1008862555027008
step: 250, loss: 0.03880532458424568
step: 260, loss: 0.09094110131263733
step: 270, loss: 0.10764937847852707
step: 280, loss: 0.02929903008043766
step: 290, loss: 0.04923339560627937
step: 300, loss: 0.02987600490450859
step: 310, loss: 0.09440312534570694
step: 320, loss: 0.056899357587099075
step: 330, loss: 0.07916544377803802
step: 340, loss: 0.13512341678142548
step: 350, loss: 0.03248541057109833
epoch 16: dev_f1=0.8038740920096852, f1=0.8076009501187648, best_f1=0.8093023255813954
step: 0, loss: 0.023164305835962296
step: 10, loss: 0.05191286653280258
step: 20, loss: 0.018167458474636078
step: 30, loss: 0.027759168297052383
step: 40, loss: 0.04997151345014572
step: 50, loss: 0.07120217382907867
step: 60, loss: 0.04046498239040375
step: 70, loss: 0.03900637850165367
step: 80, loss: 0.056589383631944656
step: 90, loss: 0.050477299839258194
step: 100, loss: 0.10300002247095108
step: 110, loss: 0.0256899856030941
step: 120, loss: 0.10663352906703949
step: 130, loss: 0.00967320241034031
step: 140, loss: 0.13250912725925446
step: 150, loss: 3.9067916077328846e-05
step: 160, loss: 0.0639619380235672
step: 170, loss: 0.08660372346639633
step: 180, loss: 0.06872338056564331
step: 190, loss: 0.052173588424921036
step: 200, loss: 0.032161831855773926
step: 210, loss: 0.017225466668605804
step: 220, loss: 0.05673278868198395
step: 230, loss: 0.044809021055698395
step: 240, loss: 0.13335300981998444
step: 250, loss: 0.0518757700920105
step: 260, loss: 0.05321068316698074
step: 270, loss: 0.06749069690704346
step: 280, loss: 0.02175731211900711
step: 290, loss: 0.07059294730424881
step: 300, loss: 3.96788636862766e-05
step: 310, loss: 0.07390439510345459
step: 320, loss: 0.03105274774134159
step: 330, loss: 0.08354802429676056
step: 340, loss: 0.00012150074326200411
step: 350, loss: 0.06504566222429276
epoch 17: dev_f1=0.8009367681498829, f1=0.8064516129032259, best_f1=0.8093023255813954
step: 0, loss: 0.0006024035392329097
step: 10, loss: 0.0725676640868187
step: 20, loss: 0.13146571815013885
step: 30, loss: 0.07085207104682922
step: 40, loss: 0.08291551470756531
step: 50, loss: 0.0534793995320797
step: 60, loss: 0.08042384684085846
step: 70, loss: 0.023606423288583755
step: 80, loss: 0.016216648742556572
step: 90, loss: 0.1262696385383606
step: 100, loss: 0.017125306650996208
step: 110, loss: 0.024984106421470642
step: 120, loss: 0.04880959540605545
step: 130, loss: 0.047030866146087646
step: 140, loss: 0.0503203310072422
step: 150, loss: 3.972701233578846e-05
step: 160, loss: 0.1464179903268814
step: 170, loss: 0.020745866000652313
step: 180, loss: 0.05305100232362747
step: 190, loss: 0.05242813006043434
step: 200, loss: 0.08141469210386276
step: 210, loss: 2.523820148780942e-05
step: 220, loss: 0.06282250583171844
step: 230, loss: 0.017519593238830566
step: 240, loss: 0.05318516492843628
step: 250, loss: 0.03133092075586319
step: 260, loss: 0.11167221516370773
step: 270, loss: 0.09616792947053909
step: 280, loss: 0.022525249049067497
step: 290, loss: 0.024148602038621902
step: 300, loss: 0.04651084169745445
step: 310, loss: 0.09098245948553085
step: 320, loss: 0.0744171068072319
step: 330, loss: 0.0707102119922638
step: 340, loss: 0.07507237046957016
step: 350, loss: 0.07672686129808426
epoch 18: dev_f1=0.8038740920096852, f1=0.8018867924528301, best_f1=0.8093023255813954
step: 0, loss: 0.06089009344577789
step: 10, loss: 0.04375515878200531
step: 20, loss: 0.048342589288949966
step: 30, loss: 0.03488992899656296
step: 40, loss: 0.042115263640880585
step: 50, loss: 0.05755435302853584
step: 60, loss: 0.02732396498322487
step: 70, loss: 0.011070874519646168
step: 80, loss: 0.0631798803806305
step: 90, loss: 0.07346108555793762
step: 100, loss: 0.08717331290245056
step: 110, loss: 0.017242345958948135
step: 120, loss: 0.08478403091430664
step: 130, loss: 0.09349721670150757
step: 140, loss: 0.0547386109828949
step: 150, loss: 0.14704003930091858
step: 160, loss: 0.10198314487934113
step: 170, loss: 0.05075357109308243
step: 180, loss: 0.0993824452161789
step: 190, loss: 0.023462750017642975
step: 200, loss: 0.007823091000318527
step: 210, loss: 0.03972162678837776
step: 220, loss: 0.14135417342185974
step: 230, loss: 0.04336550459265709
step: 240, loss: 0.07459775358438492
step: 250, loss: 0.01880178228020668
step: 260, loss: 0.002096931217238307
step: 270, loss: 0.05552556738257408
step: 280, loss: 0.036058563739061356
step: 290, loss: 0.08007122576236725
step: 300, loss: 0.10192146897315979
step: 310, loss: 0.03722210228443146
step: 320, loss: 0.0516611747443676
step: 330, loss: 0.06135077401995659
step: 340, loss: 0.036086276173591614
step: 350, loss: 0.020325521007180214
epoch 19: dev_f1=0.7952380952380952, f1=0.7990654205607476, best_f1=0.8093023255813954
step: 0, loss: 0.04327554255723953
step: 10, loss: 0.015363317914307117
step: 20, loss: 0.10496305674314499
step: 30, loss: 0.020074503496289253
step: 40, loss: 0.014486263506114483
step: 50, loss: 0.007108544465154409
step: 60, loss: 0.02909034490585327
step: 70, loss: 0.08417554199695587
step: 80, loss: 0.035165876150131226
step: 90, loss: 0.1303592324256897
step: 100, loss: 0.05579483136534691
step: 110, loss: 0.012296595610678196
step: 120, loss: 0.040513209998607635
step: 130, loss: 0.033106036484241486
step: 140, loss: 0.042444705963134766
step: 150, loss: 0.04790126904845238
step: 160, loss: 0.11155857145786285
step: 170, loss: 0.0828297883272171
step: 180, loss: 0.0467069149017334
step: 190, loss: 0.08205845206975937
step: 200, loss: 0.08337520807981491
step: 210, loss: 0.0901123508810997
step: 220, loss: 0.16095517575740814
step: 230, loss: 0.14024996757507324
step: 240, loss: 0.10833948105573654
step: 250, loss: 0.020403018221259117
step: 260, loss: 0.1176239401102066
step: 270, loss: 0.01978173293173313
step: 280, loss: 0.05290667712688446
step: 290, loss: 0.09412071108818054
step: 300, loss: 0.04480590298771858
step: 310, loss: 0.036124806851148605
step: 320, loss: 0.05306464433670044
step: 330, loss: 0.1473926454782486
step: 340, loss: 0.189069002866745
step: 350, loss: 0.07387426495552063
epoch 20: dev_f1=0.7853658536585365, f1=0.7894736842105263, best_f1=0.8093023255813954
