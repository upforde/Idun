cuda
Device: cuda
step: 0, loss: 0.5443382859230042
step: 10, loss: 0.2677512466907501
step: 20, loss: 0.31115540862083435
step: 30, loss: 0.3019941449165344
step: 40, loss: 0.4816223084926605
step: 50, loss: 0.24589793384075165
step: 60, loss: 0.46247798204421997
step: 70, loss: 0.2303897887468338
step: 80, loss: 0.2866138219833374
step: 90, loss: 0.14440132677555084
step: 100, loss: 0.4931877851486206
step: 110, loss: 0.31923654675483704
step: 120, loss: 0.37883514165878296
step: 130, loss: 0.31196328997612
step: 140, loss: 0.2295861691236496
step: 150, loss: 0.2713705897331238
step: 160, loss: 0.49964267015457153
step: 170, loss: 0.29993826150894165
step: 180, loss: 0.29688408970832825
step: 190, loss: 0.9686596989631653
step: 200, loss: 0.41909193992614746
step: 210, loss: 0.1768709272146225
step: 220, loss: 0.43631410598754883
step: 230, loss: 0.16284362971782684
step: 240, loss: 0.4850936830043793
step: 250, loss: 0.21477413177490234
step: 260, loss: 0.2920812964439392
step: 270, loss: 0.1889198273420334
step: 280, loss: 0.29670044779777527
step: 290, loss: 0.2318449169397354
step: 300, loss: 0.24813640117645264
step: 310, loss: 0.2789750099182129
step: 320, loss: 0.3177233934402466
step: 330, loss: 0.23419010639190674
step: 340, loss: 0.20935404300689697
step: 350, loss: 0.10384934395551682
epoch 1: dev_f1=0.7010309278350516, f1=0.6761710794297352, best_f1=0.6761710794297352
step: 0, loss: 0.21454313397407532
step: 10, loss: 0.23587317764759064
step: 20, loss: 0.15211716294288635
step: 30, loss: 0.25499624013900757
step: 40, loss: 0.1116209477186203
step: 50, loss: 0.129731222987175
step: 60, loss: 0.21664169430732727
step: 70, loss: 0.1434098333120346
step: 80, loss: 0.12482665479183197
step: 90, loss: 0.22150449454784393
step: 100, loss: 0.10916339606046677
step: 110, loss: 0.2223384529352188
step: 120, loss: 0.16901250183582306
step: 130, loss: 0.17344671487808228
step: 140, loss: 0.10717874020338058
step: 150, loss: 0.2120485156774521
step: 160, loss: 0.20024406909942627
step: 170, loss: 0.12507638335227966
step: 180, loss: 0.17843085527420044
step: 190, loss: 0.11831626296043396
step: 200, loss: 0.17809061706066132
step: 210, loss: 0.19309966266155243
step: 220, loss: 0.27595847845077515
step: 230, loss: 0.3817550539970398
step: 240, loss: 0.17640098929405212
step: 250, loss: 0.12043710052967072
step: 260, loss: 0.1635826975107193
step: 270, loss: 0.08111835271120071
step: 280, loss: 0.2350887954235077
step: 290, loss: 0.18358586728572845
step: 300, loss: 0.09400232136249542
step: 310, loss: 0.2690228819847107
step: 320, loss: 0.13527731597423553
step: 330, loss: 0.11775527149438858
step: 340, loss: 0.11278244853019714
step: 350, loss: 0.14292412996292114
epoch 2: dev_f1=0.7424593967517402, f1=0.7422222222222222, best_f1=0.7422222222222222
step: 0, loss: 0.13859783113002777
step: 10, loss: 0.10123107582330704
step: 20, loss: 0.13248291611671448
step: 30, loss: 0.15637674927711487
step: 40, loss: 0.2596619129180908
step: 50, loss: 0.15951964259147644
step: 60, loss: 0.3139895796775818
step: 70, loss: 0.11931589990854263
step: 80, loss: 0.09929591417312622
step: 90, loss: 0.14484165608882904
step: 100, loss: 0.0874219611287117
step: 110, loss: 0.026563329622149467
step: 120, loss: 0.19594520330429077
step: 130, loss: 0.07328599691390991
step: 140, loss: 0.09132900089025497
step: 150, loss: 0.08074262738227844
step: 160, loss: 0.04476841166615486
step: 170, loss: 0.07243384420871735
step: 180, loss: 0.05865487456321716
step: 190, loss: 0.14034029841423035
step: 200, loss: 0.08319538831710815
step: 210, loss: 0.48915281891822815
step: 220, loss: 0.19894875586032867
step: 230, loss: 0.10923595726490021
step: 240, loss: 0.09104609489440918
step: 250, loss: 0.008514592424035072
step: 260, loss: 0.0711103156208992
step: 270, loss: 0.2700299024581909
step: 280, loss: 0.06440586596727371
step: 290, loss: 0.1274307668209076
step: 300, loss: 0.19924157857894897
step: 310, loss: 0.019916856661438942
step: 320, loss: 0.07481458783149719
step: 330, loss: 0.10235796123743057
step: 340, loss: 0.12847091257572174
step: 350, loss: 0.2164689153432846
epoch 3: dev_f1=0.7821782178217821, f1=0.7865707434052758, best_f1=0.7865707434052758
step: 0, loss: 0.058298077434301376
step: 10, loss: 0.03216332197189331
step: 20, loss: 0.21583762764930725
step: 30, loss: 0.2217845618724823
step: 40, loss: 0.1499263346195221
step: 50, loss: 0.11129053682088852
step: 60, loss: 0.05254532769322395
step: 70, loss: 0.046469029039144516
step: 80, loss: 0.17662180960178375
step: 90, loss: 0.21522535383701324
step: 100, loss: 0.05835476890206337
step: 110, loss: 0.16123919188976288
step: 120, loss: 0.04686857759952545
step: 130, loss: 0.07293948531150818
step: 140, loss: 0.04468667879700661
step: 150, loss: 0.137502521276474
step: 160, loss: 0.08599793910980225
step: 170, loss: 0.07918841391801834
step: 180, loss: 0.0806877389550209
step: 190, loss: 0.06794340163469315
step: 200, loss: 0.03687957674264908
step: 210, loss: 0.09361594915390015
step: 220, loss: 0.12014289945363998
step: 230, loss: 0.02928488701581955
step: 240, loss: 0.15785741806030273
step: 250, loss: 0.08003988116979599
step: 260, loss: 0.07508934289216995
step: 270, loss: 0.12232574820518494
step: 280, loss: 0.12527857720851898
step: 290, loss: 0.06314215064048767
step: 300, loss: 0.22552040219306946
step: 310, loss: 0.07670523971319199
step: 320, loss: 0.06053837761282921
step: 330, loss: 0.1705418974161148
step: 340, loss: 0.15239745378494263
step: 350, loss: 0.0361618809401989
epoch 4: dev_f1=0.8299319727891158, f1=0.7922077922077922, best_f1=0.7922077922077922
step: 0, loss: 0.08842741698026657
step: 10, loss: 0.08679993450641632
step: 20, loss: 0.14300379157066345
step: 30, loss: 0.07901713252067566
step: 40, loss: 0.07980621606111526
step: 50, loss: 0.09111915528774261
step: 60, loss: 0.11228345334529877
step: 70, loss: 0.0968320295214653
step: 80, loss: 0.046747393906116486
step: 90, loss: 0.24351997673511505
step: 100, loss: 0.04897511377930641
step: 110, loss: 0.05918727070093155
step: 120, loss: 0.09969422221183777
step: 130, loss: 0.06684406846761703
step: 140, loss: 0.17791444063186646
step: 150, loss: 0.08302292972803116
step: 160, loss: 0.06599067896604538
step: 170, loss: 0.047646742314100266
step: 180, loss: 0.07060228288173676
step: 190, loss: 0.05657697468996048
step: 200, loss: 0.0985434502363205
step: 210, loss: 0.0966515988111496
step: 220, loss: 0.10334822535514832
step: 230, loss: 0.06787040084600449
step: 240, loss: 0.13584236800670624
step: 250, loss: 0.03704385459423065
step: 260, loss: 0.0764569416642189
step: 270, loss: 0.12350568175315857
step: 280, loss: 0.011208539828658104
step: 290, loss: 0.10609573125839233
step: 300, loss: 0.10596060752868652
step: 310, loss: 0.07325883954763412
step: 320, loss: 0.07308964431285858
step: 330, loss: 0.08722839504480362
step: 340, loss: 0.04954509809613228
step: 350, loss: 0.0804145485162735
epoch 5: dev_f1=0.8054298642533937, f1=0.7982456140350878, best_f1=0.7922077922077922
step: 0, loss: 0.1339356005191803
step: 10, loss: 0.13546843826770782
step: 20, loss: 0.12679889798164368
step: 30, loss: 0.08848350495100021
step: 40, loss: 0.04842682555317879
step: 50, loss: 0.0001597501104697585
step: 60, loss: 0.04202953726053238
step: 70, loss: 0.14217323064804077
step: 80, loss: 0.08263960480690002
step: 90, loss: 0.04526660963892937
step: 100, loss: 0.16680124402046204
step: 110, loss: 0.04198053106665611
step: 120, loss: 0.23403294384479523
step: 130, loss: 0.16869662702083588
step: 140, loss: 0.05462338402867317
step: 150, loss: 0.08122622966766357
step: 160, loss: 0.10370048135519028
step: 170, loss: 0.14275521039962769
step: 180, loss: 0.08784987032413483
step: 190, loss: 0.14094839990139008
step: 200, loss: 0.07545958459377289
step: 210, loss: 0.16719889640808105
step: 220, loss: 0.11952747404575348
step: 230, loss: 0.04372376576066017
step: 240, loss: 0.04891388490796089
step: 250, loss: 0.06990151107311249
step: 260, loss: 0.15663373470306396
step: 270, loss: 0.06478546559810638
step: 280, loss: 0.040741581469774246
step: 290, loss: 0.09380605816841125
step: 300, loss: 0.08580140024423599
step: 310, loss: 0.08759251981973648
step: 320, loss: 0.09344343841075897
step: 330, loss: 0.04926028847694397
step: 340, loss: 0.11979524046182632
step: 350, loss: 0.05548475310206413
epoch 6: dev_f1=0.8048780487804879, f1=0.7605633802816901, best_f1=0.7922077922077922
step: 0, loss: 0.11284644156694412
step: 10, loss: 0.11688217520713806
step: 20, loss: 0.05781314894556999
step: 30, loss: 0.0786808654665947
step: 40, loss: 0.010809408500790596
step: 50, loss: 0.19408690929412842
step: 60, loss: 0.08391612023115158
step: 70, loss: 0.05816490203142166
step: 80, loss: 0.09877990931272507
step: 90, loss: 0.11649789661169052
step: 100, loss: 0.0413619801402092
step: 110, loss: 0.13036879897117615
step: 120, loss: 0.0828206017613411
step: 130, loss: 0.0849851444363594
step: 140, loss: 0.061231549829244614
step: 150, loss: 0.1270267367362976
step: 160, loss: 0.06803308427333832
step: 170, loss: 0.15056096017360687
step: 180, loss: 0.07711309939622879
step: 190, loss: 0.04717160016298294
step: 200, loss: 0.18047353625297546
step: 210, loss: 0.1137455403804779
step: 220, loss: 0.05033685639500618
step: 230, loss: 0.21215499937534332
step: 240, loss: 0.0010588363511487842
step: 250, loss: 0.097634457051754
step: 260, loss: 0.025417204946279526
step: 270, loss: 0.05434402450919151
step: 280, loss: 0.1418137550354004
step: 290, loss: 0.06498284637928009
step: 300, loss: 0.0395367331802845
step: 310, loss: 0.0999261885881424
step: 320, loss: 0.10897575318813324
step: 330, loss: 0.1338573396205902
step: 340, loss: 0.11693751066923141
step: 350, loss: 0.12543010711669922
epoch 7: dev_f1=0.7999999999999999, f1=0.7799564270152506, best_f1=0.7922077922077922
step: 0, loss: 0.08320019394159317
step: 10, loss: 0.06128207966685295
step: 20, loss: 0.0003053151012863964
step: 30, loss: 0.14746296405792236
step: 40, loss: 0.13505765795707703
step: 50, loss: 0.04130005091428757
step: 60, loss: 0.03204139694571495
step: 70, loss: 0.18850046396255493
step: 80, loss: 0.08141195774078369
step: 90, loss: 0.14045365154743195
step: 100, loss: 0.06921755522489548
step: 110, loss: 0.03649669140577316
step: 120, loss: 0.12228695303201675
step: 130, loss: 0.14647206664085388
step: 140, loss: 0.08692281693220139
step: 150, loss: 0.10135795921087265
step: 160, loss: 0.19103144109249115
step: 170, loss: 0.1143694594502449
step: 180, loss: 0.04727684706449509
step: 190, loss: 0.07166361808776855
step: 200, loss: 0.050339311361312866
step: 210, loss: 0.11674826592206955
step: 220, loss: 0.05353724956512451
step: 230, loss: 0.1558724194765091
step: 240, loss: 0.08935598284006119
step: 250, loss: 0.11904123425483704
step: 260, loss: 0.049687206745147705
step: 270, loss: 0.11609868705272675
step: 280, loss: 0.042607489973306656
step: 290, loss: 0.03593701496720314
step: 300, loss: 0.04277617111802101
step: 310, loss: 0.22106744349002838
step: 320, loss: 0.17860619723796844
step: 330, loss: 0.03898727893829346
step: 340, loss: 0.0716869980096817
step: 350, loss: 0.124275803565979
epoch 8: dev_f1=0.8337129840546698, f1=0.8134831460674157, best_f1=0.8134831460674157
step: 0, loss: 0.1349470615386963
step: 10, loss: 0.07440288364887238
step: 20, loss: 0.06941431015729904
step: 30, loss: 0.0737665519118309
step: 40, loss: 0.021575411781668663
step: 50, loss: 0.018539156764745712
step: 60, loss: 0.10800308734178543
step: 70, loss: 0.08936293423175812
step: 80, loss: 0.10890716314315796
step: 90, loss: 0.091071717441082
step: 100, loss: 0.05771072581410408
step: 110, loss: 0.030648082494735718
step: 120, loss: 0.052032358944416046
step: 130, loss: 0.08655863255262375
step: 140, loss: 0.061968181282281876
step: 150, loss: 0.05625566840171814
step: 160, loss: 0.03095007687807083
step: 170, loss: 0.10031598061323166
step: 180, loss: 0.11057916283607483
step: 190, loss: 0.07483778148889542
step: 200, loss: 0.1692511886358261
step: 210, loss: 0.06730683892965317
step: 220, loss: 0.027706246823072433
step: 230, loss: 0.1898435354232788
step: 240, loss: 0.22959856688976288
step: 250, loss: 0.02921898290514946
step: 260, loss: 0.12081114947795868
step: 270, loss: 0.026861989870667458
step: 280, loss: 0.0655057281255722
step: 290, loss: 0.056586652994155884
step: 300, loss: 0.17826126515865326
step: 310, loss: 0.1212230920791626
step: 320, loss: 0.20739570260047913
step: 330, loss: 0.04012545570731163
step: 340, loss: 0.1734601855278015
step: 350, loss: 0.09881721436977386
epoch 9: dev_f1=0.8201754385964913, f1=0.7835497835497837, best_f1=0.8134831460674157
step: 0, loss: 0.1156744435429573
step: 10, loss: 0.18340834975242615
step: 20, loss: 0.10048986971378326
step: 30, loss: 0.05629333108663559
step: 40, loss: 0.043857887387275696
step: 50, loss: 0.06484021991491318
step: 60, loss: 0.05809485539793968
step: 70, loss: 0.09185438603162766
step: 80, loss: 0.08523131906986237
step: 90, loss: 0.19699834287166595
step: 100, loss: 0.0643913671374321
step: 110, loss: 0.07603498548269272
step: 120, loss: 0.019104812294244766
step: 130, loss: 0.010871644131839275
step: 140, loss: 0.0401071161031723
step: 150, loss: 0.04088791087269783
step: 160, loss: 0.07811655104160309
step: 170, loss: 0.07686489820480347
step: 180, loss: 0.0019176489440724254
step: 190, loss: 0.0591609813272953
step: 200, loss: 0.14505204558372498
step: 210, loss: 0.1352621167898178
step: 220, loss: 0.06220531836152077
step: 230, loss: 0.007100153714418411
step: 240, loss: 0.05484217405319214
step: 250, loss: 0.09336066246032715
step: 260, loss: 0.05643317848443985
step: 270, loss: 0.033637166023254395
step: 280, loss: 0.01786908693611622
step: 290, loss: 0.0763184130191803
step: 300, loss: 0.038188789039850235
step: 310, loss: 0.07804704457521439
step: 320, loss: 0.09919612854719162
step: 330, loss: 0.06346923857927322
step: 340, loss: 0.07069667428731918
step: 350, loss: 0.0998539999127388
epoch 10: dev_f1=0.8230088495575221, f1=0.8026315789473684, best_f1=0.8134831460674157
step: 0, loss: 0.08749254047870636
step: 10, loss: 0.1153721809387207
step: 20, loss: 0.06584114581346512
step: 30, loss: 0.023144619539380074
step: 40, loss: 0.07669571042060852
step: 50, loss: 0.03993501514196396
step: 60, loss: 0.03502696007490158
step: 70, loss: 0.0434417799115181
step: 80, loss: 0.09199889749288559
step: 90, loss: 0.0031209574081003666
step: 100, loss: 0.021525075659155846
step: 110, loss: 0.11210458725690842
step: 120, loss: 0.03634332865476608
step: 130, loss: 0.07534988969564438
step: 140, loss: 0.06469298154115677
step: 150, loss: 0.06871320307254791
step: 160, loss: 0.03891964256763458
step: 170, loss: 0.10304605215787888
step: 180, loss: 0.000560115382540971
step: 190, loss: 0.026124941185116768
step: 200, loss: 0.026420753449201584
step: 210, loss: 0.0762731283903122
step: 220, loss: 0.19191546738147736
step: 230, loss: 0.12245261669158936
step: 240, loss: 0.01951073668897152
step: 250, loss: 0.047730833292007446
step: 260, loss: 0.10765305906534195
step: 270, loss: 0.1586102396249771
step: 280, loss: 0.0673547014594078
step: 290, loss: 0.10208100825548172
step: 300, loss: 0.10822178423404694
step: 310, loss: 0.13920821249485016
step: 320, loss: 0.08656416833400726
step: 330, loss: 0.0777306780219078
step: 340, loss: 0.025945845991373062
step: 350, loss: 0.11718862503767014
epoch 11: dev_f1=0.8046511627906976, f1=0.7853881278538813, best_f1=0.8134831460674157
step: 0, loss: 0.088912732899189
step: 10, loss: 0.05395076051354408
step: 20, loss: 0.07725134491920471
step: 30, loss: 0.09466960281133652
step: 40, loss: 0.08744215220212936
step: 50, loss: 0.3039858341217041
step: 60, loss: 0.14443199336528778
step: 70, loss: 0.015067478641867638
step: 80, loss: 0.1016944870352745
step: 90, loss: 0.039205919951200485
step: 100, loss: 0.056414611637592316
step: 110, loss: 0.08366032689809799
step: 120, loss: 0.1025925949215889
step: 130, loss: 0.11435291916131973
step: 140, loss: 0.07025223970413208
step: 150, loss: 0.0670631155371666
step: 160, loss: 0.1971873641014099
step: 170, loss: 0.04294920340180397
step: 180, loss: 0.11866873502731323
step: 190, loss: 0.036269381642341614
step: 200, loss: 0.06373346596956253
step: 210, loss: 0.0404038168489933
step: 220, loss: 0.1404077708721161
step: 230, loss: 0.16367579996585846
step: 240, loss: 0.023248208686709404
step: 250, loss: 0.0045798905193805695
step: 260, loss: 0.07804033160209656
step: 270, loss: 0.13658994436264038
step: 280, loss: 0.05638571456074715
step: 290, loss: 0.05372462421655655
step: 300, loss: 0.10694880783557892
step: 310, loss: 0.07883203029632568
step: 320, loss: 0.09598048776388168
step: 330, loss: 0.11617378145456314
step: 340, loss: 0.11873745918273926
step: 350, loss: 0.06034371629357338
epoch 12: dev_f1=0.7990314769975787, f1=0.7902439024390243, best_f1=0.8134831460674157
step: 0, loss: 0.08663329482078552
step: 10, loss: 0.11526793986558914
step: 20, loss: 0.017348915338516235
step: 30, loss: 0.11946690082550049
step: 40, loss: 0.04985851049423218
step: 50, loss: 0.051178716123104095
step: 60, loss: 0.08803742378950119
step: 70, loss: 0.09631191939115524
step: 80, loss: 0.09843626618385315
step: 90, loss: 0.09161072224378586
step: 100, loss: 0.09694751352071762
step: 110, loss: 0.11660008132457733
step: 120, loss: 0.06772604584693909
step: 130, loss: 0.1065702810883522
step: 140, loss: 0.02408909983932972
step: 150, loss: 0.06468404084444046
step: 160, loss: 0.13142640888690948
step: 170, loss: 0.10672377049922943
step: 180, loss: 0.04579247161746025
step: 190, loss: 0.14014403522014618
step: 200, loss: 0.0846952274441719
step: 210, loss: 0.13593822717666626
step: 220, loss: 0.08459633588790894
step: 230, loss: 0.04022127017378807
step: 240, loss: 0.0417168103158474
step: 250, loss: 0.056041084229946136
step: 260, loss: 0.06465590745210648
step: 270, loss: 0.03490964323282242
step: 280, loss: 0.07988645881414413
step: 290, loss: 0.0017002641689032316
step: 300, loss: 0.07602212578058243
step: 310, loss: 0.06050139293074608
step: 320, loss: 0.0625479593873024
step: 330, loss: 0.025915680453181267
step: 340, loss: 0.0962844043970108
step: 350, loss: 0.1486266851425171
epoch 13: dev_f1=0.812206572769953, f1=0.8071748878923766, best_f1=0.8134831460674157
step: 0, loss: 0.09869644045829773
step: 10, loss: 0.06018276885151863
step: 20, loss: 0.09693016856908798
step: 30, loss: 0.03084300458431244
step: 40, loss: 0.09151989966630936
step: 50, loss: 0.02871095947921276
step: 60, loss: 0.0821671336889267
step: 70, loss: 0.0195204745978117
step: 80, loss: 0.057632122188806534
step: 90, loss: 0.056742437183856964
step: 100, loss: 0.1266872137784958
step: 110, loss: 0.05783453956246376
step: 120, loss: 0.07158441841602325
step: 130, loss: 0.05444357916712761
step: 140, loss: 0.06097211316227913
step: 150, loss: 0.023169847205281258
step: 160, loss: 0.042993877083063126
step: 170, loss: 0.06741677969694138
step: 180, loss: 0.021208226680755615
step: 190, loss: 0.06650125980377197
step: 200, loss: 0.03231756016612053
step: 210, loss: 0.013329911045730114
step: 220, loss: 0.03573930263519287
step: 230, loss: 0.08780601620674133
step: 240, loss: 0.07702858746051788
step: 250, loss: 0.09502949565649033
step: 260, loss: 0.06736426800489426
step: 270, loss: 0.08934613317251205
step: 280, loss: 0.08848068863153458
step: 290, loss: 0.13803084194660187
step: 300, loss: 0.11569909006357193
step: 310, loss: 0.02810285985469818
step: 320, loss: 0.09135202318429947
step: 330, loss: 0.04364928603172302
step: 340, loss: 0.07311510294675827
step: 350, loss: 0.04791048541665077
epoch 14: dev_f1=0.8127853881278538, f1=0.8026607538802661, best_f1=0.8134831460674157
step: 0, loss: 0.06060924753546715
step: 10, loss: 0.14832422137260437
step: 20, loss: 0.12257526814937592
step: 30, loss: 0.049162521958351135
step: 40, loss: 0.09390781819820404
step: 50, loss: 0.00017903349362313747
step: 60, loss: 0.0767996683716774
step: 70, loss: 0.05073562264442444
step: 80, loss: 0.052028436213731766
step: 90, loss: 0.014354844577610493
step: 100, loss: 0.04748343303799629
step: 110, loss: 0.06213498115539551
step: 120, loss: 0.08998564630746841
step: 130, loss: 0.08534479141235352
step: 140, loss: 0.08176663517951965
step: 150, loss: 0.0880916640162468
step: 160, loss: 0.12502692639827728
step: 170, loss: 0.0891607329249382
step: 180, loss: 0.0014757661847397685
step: 190, loss: 0.061309587210416794
step: 200, loss: 0.08483058959245682
step: 210, loss: 0.09567540884017944
step: 220, loss: 0.11307089775800705
step: 230, loss: 0.23838874697685242
step: 240, loss: 0.1360967755317688
step: 250, loss: 0.08973278850317001
step: 260, loss: 0.0918741375207901
step: 270, loss: 0.01339428499341011
step: 280, loss: 0.10549469292163849
step: 290, loss: 0.10762617737054825
step: 300, loss: 0.08255436271429062
step: 310, loss: 0.06621769070625305
step: 320, loss: 0.09371842443943024
step: 330, loss: 0.0389396958053112
step: 340, loss: 0.1139712780714035
step: 350, loss: 0.02468866854906082
epoch 15: dev_f1=0.8125000000000001, f1=0.7896995708154506, best_f1=0.8134831460674157
step: 0, loss: 0.06099070608615875
step: 10, loss: 0.059752825647592545
step: 20, loss: 0.08409386873245239
step: 30, loss: 0.06335621327161789
step: 40, loss: 0.030782874673604965
step: 50, loss: 0.08931980282068253
step: 60, loss: 0.05280810967087746
step: 70, loss: 0.13303641974925995
step: 80, loss: 0.09782258421182632
step: 90, loss: 0.09430787712335587
step: 100, loss: 0.10461043566465378
step: 110, loss: 0.03386346623301506
step: 120, loss: 0.038922764360904694
step: 130, loss: 0.00038540561217814684
step: 140, loss: 0.06362154334783554
step: 150, loss: 0.05961790308356285
step: 160, loss: 0.1038726195693016
step: 170, loss: 0.07196621596813202
step: 180, loss: 0.12271645665168762
step: 190, loss: 0.0940820649266243
step: 200, loss: 0.11541932076215744
step: 210, loss: 0.030365360900759697
step: 220, loss: 0.062289439141750336
step: 230, loss: 0.07262763381004333
step: 240, loss: 0.07971394062042236
step: 250, loss: 0.08626954257488251
step: 260, loss: 0.04869971051812172
step: 270, loss: 0.06732703000307083
step: 280, loss: 0.046175047755241394
step: 290, loss: 0.061114292591810226
step: 300, loss: 0.041856519877910614
step: 310, loss: 0.046108562499284744
step: 320, loss: 0.040015701204538345
step: 330, loss: 0.05254169926047325
step: 340, loss: 0.02662779577076435
step: 350, loss: 0.030752601101994514
epoch 16: dev_f1=0.8200455580865603, f1=0.801781737193764, best_f1=0.8134831460674157
step: 0, loss: 0.1121252253651619
step: 10, loss: 0.07659172266721725
step: 20, loss: 0.11202424019575119
step: 30, loss: 0.03862110897898674
step: 40, loss: 0.06892611086368561
step: 50, loss: 0.05291919782757759
step: 60, loss: 0.05129881575703621
step: 70, loss: 0.02966938354074955
step: 80, loss: 0.1203312799334526
step: 90, loss: 0.09442370384931564
step: 100, loss: 0.014542808756232262
step: 110, loss: 0.01174507848918438
step: 120, loss: 0.05381275340914726
step: 130, loss: 0.08366167545318604
step: 140, loss: 0.02763175405561924
step: 150, loss: 0.0647251084446907
step: 160, loss: 0.06892850995063782
step: 170, loss: 0.16261306405067444
step: 180, loss: 0.005327016115188599
step: 190, loss: 0.09800505638122559
step: 200, loss: 0.058471400290727615
step: 210, loss: 0.0033542204182595015
step: 220, loss: 0.07762288302183151
step: 230, loss: 0.0019635632634162903
step: 240, loss: 0.1278011053800583
step: 250, loss: 0.06381542980670929
step: 260, loss: 0.0673917829990387
step: 270, loss: 0.049928102642297745
step: 280, loss: 0.07858221232891083
step: 290, loss: 0.039039358496665955
step: 300, loss: 0.05711740255355835
step: 310, loss: 0.06848771125078201
step: 320, loss: 0.08582666516304016
step: 330, loss: 0.0040017589926719666
step: 340, loss: 0.0808534324169159
step: 350, loss: 3.349300823174417e-05
epoch 17: dev_f1=0.7921760391198044, f1=0.8038277511961723, best_f1=0.8134831460674157
step: 0, loss: 0.11049695312976837
step: 10, loss: 0.065981924533844
step: 20, loss: 0.007489603478461504
step: 30, loss: 0.06806793063879013
step: 40, loss: 0.05893271788954735
step: 50, loss: 0.055588990449905396
step: 60, loss: 0.05152450501918793
step: 70, loss: 0.06407254934310913
step: 80, loss: 0.025519924238324165
step: 90, loss: 0.1500655859708786
step: 100, loss: 0.024957654997706413
step: 110, loss: 0.06280958652496338
step: 120, loss: 0.15559150278568268
step: 130, loss: 0.11396411061286926
step: 140, loss: 0.03978227078914642
step: 150, loss: 0.05432950332760811
step: 160, loss: 0.13712511956691742
step: 170, loss: 0.030215149745345116
step: 180, loss: 0.19534389674663544
step: 190, loss: 0.08102957904338837
step: 200, loss: 0.05705660209059715
step: 210, loss: 0.15388016402721405
step: 220, loss: 0.00013257582031656057
step: 230, loss: 0.08395157754421234
step: 240, loss: 0.11786670982837677
step: 250, loss: 0.023165710270404816
step: 260, loss: 0.06619115173816681
step: 270, loss: 0.06693047285079956
step: 280, loss: 0.04261798411607742
step: 290, loss: 0.07816247642040253
step: 300, loss: 0.05136965960264206
step: 310, loss: 0.04122867062687874
step: 320, loss: 0.07111574709415436
step: 330, loss: 0.07863102108240128
step: 340, loss: 0.06354767829179764
step: 350, loss: 0.037274863570928574
epoch 18: dev_f1=0.8037383177570093, f1=0.7901785714285714, best_f1=0.8134831460674157
step: 0, loss: 0.0963490754365921
step: 10, loss: 0.06936518847942352
step: 20, loss: 0.06204090267419815
step: 30, loss: 0.029447704553604126
step: 40, loss: 0.09439922124147415
step: 50, loss: 0.10407685488462448
step: 60, loss: 0.05958052724599838
step: 70, loss: 0.055588994175195694
step: 80, loss: 0.08163556456565857
step: 90, loss: 0.08689788728952408
step: 100, loss: 0.0723460391163826
step: 110, loss: 0.08493557572364807
step: 120, loss: 0.05607054382562637
step: 130, loss: 0.024388732388615608
step: 140, loss: 0.12255966663360596
step: 150, loss: 0.11930980533361435
step: 160, loss: 0.08702366799116135
step: 170, loss: 0.06668689101934433
step: 180, loss: 0.09640379250049591
step: 190, loss: 0.06420712918043137
step: 200, loss: 0.017621800303459167
step: 210, loss: 0.044298429042100906
step: 220, loss: 0.0546589232981205
step: 230, loss: 0.02438458614051342
step: 240, loss: 0.049422699958086014
step: 250, loss: 0.09278589487075806
step: 260, loss: 0.002349309390410781
step: 270, loss: 0.016546158120036125
step: 280, loss: 0.09988101571798325
step: 290, loss: 0.06600631028413773
step: 300, loss: 0.09119746088981628
step: 310, loss: 0.021081291139125824
step: 320, loss: 0.018407605588436127
step: 330, loss: 0.0927891880273819
step: 340, loss: 0.14844383299350739
step: 350, loss: 0.020036282017827034
epoch 19: dev_f1=0.810304449648712, f1=0.7892376681614349, best_f1=0.8134831460674157
step: 0, loss: 0.0365167036652565
step: 10, loss: 0.041940391063690186
step: 20, loss: 0.03602220490574837
step: 30, loss: 0.023943305015563965
step: 40, loss: 0.03458613529801369
step: 50, loss: 0.016457121819257736
step: 60, loss: 0.11558324098587036
step: 70, loss: 0.01091983076184988
step: 80, loss: 0.005375649314373732
step: 90, loss: 0.10582627356052399
step: 100, loss: 0.01562783680856228
step: 110, loss: 0.00693680951371789
step: 120, loss: 0.0985463485121727
step: 130, loss: 0.01975918933749199
step: 140, loss: 0.03634323179721832
step: 150, loss: 0.02001410350203514
step: 160, loss: 0.08215221762657166
step: 170, loss: 0.02192017436027527
step: 180, loss: 0.12378640472888947
step: 190, loss: 0.020063823089003563
step: 200, loss: 8.18126427475363e-05
step: 210, loss: 0.03260447457432747
step: 220, loss: 0.022815123200416565
step: 230, loss: 0.07428190857172012
step: 240, loss: 0.024286048486828804
step: 250, loss: 0.1467927098274231
step: 260, loss: 0.05154542997479439
step: 270, loss: 0.031819749623537064
step: 280, loss: 0.08159693330526352
step: 290, loss: 0.1089770570397377
step: 300, loss: 0.05342510715126991
step: 310, loss: 0.026325279846787453
step: 320, loss: 0.04147753491997719
step: 330, loss: 0.0780569538474083
step: 340, loss: 0.06115735322237015
step: 350, loss: 0.044305469840765
epoch 20: dev_f1=0.8038277511961723, f1=0.7963386727688786, best_f1=0.8134831460674157
