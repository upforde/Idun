cuda
Device: cuda
step: 0, loss: 0.545643150806427
step: 10, loss: 0.2503235936164856
step: 20, loss: 0.31892654299736023
step: 30, loss: 0.25887003540992737
step: 40, loss: 0.4289039075374603
step: 50, loss: 0.3562605381011963
step: 60, loss: 0.33218857645988464
step: 70, loss: 0.09273041039705276
step: 80, loss: 0.20180116593837738
step: 90, loss: 0.35286012291908264
step: 100, loss: 0.22769461572170258
step: 110, loss: 0.09864415228366852
step: 120, loss: 0.17381897568702698
step: 130, loss: 0.1435283124446869
step: 140, loss: 0.3832797706127167
step: 150, loss: 0.2293100357055664
step: 160, loss: 0.19811895489692688
step: 170, loss: 0.1171058863401413
step: 180, loss: 0.14918462932109833
step: 190, loss: 0.2445528656244278
step: 200, loss: 0.11969684809446335
step: 210, loss: 0.13985127210617065
step: 220, loss: 0.22593511641025543
step: 230, loss: 0.15994837880134583
step: 240, loss: 0.15563510358333588
step: 250, loss: 0.11342333257198334
step: 260, loss: 0.2478608936071396
step: 270, loss: 0.1768099069595337
step: 280, loss: 0.2031111717224121
step: 290, loss: 0.292177677154541
step: 300, loss: 0.11818243563175201
step: 310, loss: 0.3228524923324585
step: 320, loss: 0.22298425436019897
step: 330, loss: 0.06146728992462158
step: 340, loss: 0.13560029864311218
step: 350, loss: 0.07170895487070084
step: 360, loss: 0.11806224286556244
step: 370, loss: 0.18018829822540283
step: 380, loss: 0.14600719511508942
step: 390, loss: 0.143312469124794
step: 400, loss: 0.04314155876636505
step: 410, loss: 0.08563908189535141
step: 420, loss: 0.19517073035240173
step: 430, loss: 0.07555720210075378
step: 440, loss: 0.19435934722423553
step: 450, loss: 0.1843184381723404
step: 460, loss: 0.2702031433582306
step: 470, loss: 0.1767807900905609
step: 480, loss: 0.06797061860561371
step: 490, loss: 0.05021942779421806
step: 500, loss: 0.2345188558101654
step: 510, loss: 0.13483251631259918
step: 520, loss: 0.22469620406627655
step: 530, loss: 0.22363203763961792
step: 540, loss: 0.19006618857383728
step: 550, loss: 0.1069054827094078
step: 560, loss: 0.04979797080159187
step: 570, loss: 0.22108876705169678
step: 580, loss: 0.08330170065164566
step: 590, loss: 0.16391819715499878
step: 600, loss: 0.15599432587623596
step: 610, loss: 0.06271441280841827
step: 620, loss: 0.09908852726221085
step: 630, loss: 0.16678960621356964
step: 640, loss: 0.15213212370872498
step: 650, loss: 0.05123966559767723
step: 660, loss: 0.018379146233201027
step: 670, loss: 0.10462033748626709
step: 680, loss: 0.15143315494060516
step: 690, loss: 0.08811266720294952
step: 700, loss: 0.11365773528814316
step: 710, loss: 0.09418124705553055
step: 720, loss: 0.014946210198104382
step: 730, loss: 0.1861681044101715
step: 740, loss: 0.1295519918203354
step: 750, loss: 0.22658728063106537
step: 760, loss: 0.1818338930606842
step: 770, loss: 0.1459031105041504
step: 780, loss: 0.06286431103944778
step: 790, loss: 0.11264132708311081
step: 800, loss: 0.1847507357597351
step: 810, loss: 0.13390900194644928
step: 820, loss: 0.06051281467080116
step: 830, loss: 0.18935851752758026
step: 840, loss: 0.05826294422149658
step: 850, loss: 0.1925908327102661
step: 860, loss: 0.17531993985176086
step: 870, loss: 0.08790931850671768
step: 880, loss: 0.29887184500694275
step: 890, loss: 0.14795255661010742
step: 900, loss: 0.11883573979139328
step: 910, loss: 0.1330486536026001
step: 920, loss: 0.1466270387172699
step: 930, loss: 0.08598701655864716
step: 940, loss: 0.1612260341644287
step: 950, loss: 0.07964130491018295
step: 960, loss: 0.08695123344659805
step: 970, loss: 0.06148270145058632
epoch 1: dev_f1=0.9333333333333333, f1=0.9336426914153132, best_f1=0.9336426914153132
step: 0, loss: 0.17700108885765076
step: 10, loss: 0.1146382987499237
step: 20, loss: 0.15567080676555634
step: 30, loss: 0.12263967841863632
step: 40, loss: 0.09639734029769897
step: 50, loss: 0.12524747848510742
step: 60, loss: 0.20072031021118164
step: 70, loss: 0.1618606448173523
step: 80, loss: 0.1091843843460083
step: 90, loss: 0.028278887271881104
step: 100, loss: 0.2258359044790268
step: 110, loss: 0.14947591722011566
step: 120, loss: 0.059709060937166214
step: 130, loss: 0.12853623926639557
step: 140, loss: 0.1957964152097702
step: 150, loss: 0.16178174316883087
step: 160, loss: 0.10662761330604553
step: 170, loss: 0.1642417013645172
step: 180, loss: 0.08074904978275299
step: 190, loss: 0.12355067580938339
step: 200, loss: 0.1593266874551773
step: 210, loss: 0.14761699736118317
step: 220, loss: 0.22146478295326233
step: 230, loss: 0.1282019019126892
step: 240, loss: 0.1835837960243225
step: 250, loss: 0.08348660916090012
step: 260, loss: 0.09525485336780548
step: 270, loss: 0.15379950404167175
step: 280, loss: 0.1322087198495865
step: 290, loss: 0.30068299174308777
step: 300, loss: 0.08818896859884262
step: 310, loss: 0.12084027379751205
step: 320, loss: 0.15165328979492188
step: 330, loss: 0.16915157437324524
step: 340, loss: 0.10501378774642944
step: 350, loss: 0.08917822688817978
step: 360, loss: 0.07664903253316879
step: 370, loss: 0.12619835138320923
step: 380, loss: 0.05845404788851738
step: 390, loss: 0.07998348772525787
step: 400, loss: 0.1346152126789093
step: 410, loss: 0.03824590519070625
step: 420, loss: 0.11547142267227173
step: 430, loss: 0.12642551958560944
step: 440, loss: 0.18407224118709564
step: 450, loss: 0.1212514340877533
step: 460, loss: 0.09644437581300735
step: 470, loss: 0.03952982649207115
step: 480, loss: 0.15319915115833282
step: 490, loss: 0.1383998543024063
step: 500, loss: 0.10931222140789032
step: 510, loss: 0.22053475677967072
step: 520, loss: 0.1481480598449707
step: 530, loss: 0.07381340116262436
step: 540, loss: 0.14836660027503967
step: 550, loss: 0.2441686987876892
step: 560, loss: 0.06980160623788834
step: 570, loss: 0.0749889388680458
step: 580, loss: 0.16247355937957764
step: 590, loss: 0.2030770182609558
step: 600, loss: 0.15872031450271606
step: 610, loss: 0.09877617657184601
step: 620, loss: 0.22219280898571014
step: 630, loss: 0.1777617186307907
step: 640, loss: 0.1317335069179535
step: 650, loss: 0.0996384471654892
step: 660, loss: 0.08908358961343765
step: 670, loss: 0.12262649834156036
step: 680, loss: 0.11762955784797668
step: 690, loss: 0.13128402829170227
step: 700, loss: 0.06070869043469429
step: 710, loss: 0.14601130783557892
step: 720, loss: 0.18028949201107025
step: 730, loss: 0.025916026905179024
step: 740, loss: 0.09990303218364716
step: 750, loss: 0.07509499788284302
step: 760, loss: 0.14213864505290985
step: 770, loss: 0.09337157011032104
step: 780, loss: 0.15528950095176697
step: 790, loss: 0.21788853406906128
step: 800, loss: 0.054625775665044785
step: 810, loss: 0.14045466482639313
step: 820, loss: 0.18301135301589966
step: 830, loss: 0.09392179548740387
step: 840, loss: 0.0490591824054718
step: 850, loss: 0.028663652017712593
step: 860, loss: 0.05894012004137039
step: 870, loss: 0.1601647287607193
step: 880, loss: 0.1728236973285675
step: 890, loss: 0.14052814245224
step: 900, loss: 0.15049110352993011
step: 910, loss: 0.21406881511211395
step: 920, loss: 0.190140500664711
step: 930, loss: 0.10707274824380875
step: 940, loss: 0.2267802506685257
step: 950, loss: 0.1432945877313614
step: 960, loss: 0.08858326077461243
step: 970, loss: 0.2308446317911148
epoch 2: dev_f1=0.8932913102206214, f1=0.8918797667115298, best_f1=0.9336426914153132
step: 0, loss: 0.13284270465373993
step: 10, loss: 0.08489453047513962
step: 20, loss: 0.10963734239339828
step: 30, loss: 0.030129551887512207
step: 40, loss: 0.08281217515468597
step: 50, loss: 0.10500328242778778
step: 60, loss: 0.12679189443588257
step: 70, loss: 0.08995802700519562
step: 80, loss: 0.10993202775716782
step: 90, loss: 0.07694562524557114
step: 100, loss: 0.15818803012371063
step: 110, loss: 0.13566990196704865
step: 120, loss: 0.14383678138256073
step: 130, loss: 0.07279554754495621
step: 140, loss: 0.0029403360094875097
step: 150, loss: 0.2284746915102005
step: 160, loss: 0.15406496822834015
step: 170, loss: 0.0688280314207077
step: 180, loss: 0.16424106061458588
step: 190, loss: 0.08703698962926865
step: 200, loss: 0.15337218344211578
step: 210, loss: 0.17039774358272552
step: 220, loss: 0.06689184159040451
step: 230, loss: 0.14368845522403717
step: 240, loss: 0.25940239429473877
step: 250, loss: 0.13397498428821564
step: 260, loss: 0.14226022362709045
step: 270, loss: 0.14721250534057617
step: 280, loss: 0.06217455118894577
step: 290, loss: 0.09001202881336212
step: 300, loss: 0.09546776115894318
step: 310, loss: 0.11822447925806046
step: 320, loss: 0.2616066634654999
step: 330, loss: 0.27446404099464417
step: 340, loss: 0.17561839520931244
step: 350, loss: 0.20264065265655518
step: 360, loss: 0.12985672056674957
step: 370, loss: 0.136027991771698
step: 380, loss: 0.11863334476947784
step: 390, loss: 0.0781385600566864
step: 400, loss: 0.14150694012641907
step: 410, loss: 0.13602600991725922
step: 420, loss: 0.08744721859693527
step: 430, loss: 0.08235511183738708
step: 440, loss: 0.09377668052911758
step: 450, loss: 0.16972453892230988
step: 460, loss: 0.09864015877246857
step: 470, loss: 0.03505135327577591
step: 480, loss: 0.049058396369218826
step: 490, loss: 0.13848885893821716
step: 500, loss: 0.11040373146533966
step: 510, loss: 0.22046977281570435
step: 520, loss: 0.1017460823059082
step: 530, loss: 0.11369211971759796
step: 540, loss: 0.31880444288253784
step: 550, loss: 0.08593742549419403
step: 560, loss: 0.10156522691249847
step: 570, loss: 0.08811582624912262
step: 580, loss: 0.10990052670240402
step: 590, loss: 0.13682813942432404
step: 600, loss: 0.12956884503364563
step: 610, loss: 0.3906920552253723
step: 620, loss: 0.11517012119293213
step: 630, loss: 0.17263461649417877
step: 640, loss: 0.35322773456573486
step: 650, loss: 0.12932732701301575
step: 660, loss: 0.09391046315431595
step: 670, loss: 0.09348317980766296
step: 680, loss: 0.13466420769691467
step: 690, loss: 0.011516720056533813
step: 700, loss: 0.06477852910757065
step: 710, loss: 0.07651282101869583
step: 720, loss: 0.17050909996032715
step: 730, loss: 0.14121617376804352
step: 740, loss: 0.08965913951396942
step: 750, loss: 0.20893019437789917
step: 760, loss: 0.3448581397533417
step: 770, loss: 0.019701065495610237
step: 780, loss: 0.08847815543413162
step: 790, loss: 0.07974840700626373
step: 800, loss: 0.08148625493049622
step: 810, loss: 0.18667209148406982
step: 820, loss: 0.21935483813285828
step: 830, loss: 0.16481004655361176
step: 840, loss: 0.1544148176908493
step: 850, loss: 0.0643320232629776
step: 860, loss: 0.07152342051267624
step: 870, loss: 0.18615062534809113
step: 880, loss: 0.20558997988700867
step: 890, loss: 0.08759018033742905
step: 900, loss: 0.40433382987976074
step: 910, loss: 0.14482763409614563
step: 920, loss: 0.01514734048396349
step: 930, loss: 0.20505070686340332
step: 940, loss: 0.12251511961221695
step: 950, loss: 0.13479264080524445
step: 960, loss: 0.12241191416978836
step: 970, loss: 0.1684076339006424
epoch 3: dev_f1=0.9367552703941339, f1=0.9362677670793214, best_f1=0.9362677670793214
step: 0, loss: 0.09652139246463776
step: 10, loss: 0.1063026562333107
step: 20, loss: 0.1767471432685852
step: 30, loss: 0.05161798745393753
step: 40, loss: 0.1168573796749115
step: 50, loss: 0.15416625142097473
step: 60, loss: 0.09823057055473328
step: 70, loss: 0.2059602439403534
step: 80, loss: 0.19735731184482574
step: 90, loss: 0.15741749107837677
step: 100, loss: 0.03617272898554802
step: 110, loss: 0.1348501741886139
step: 120, loss: 0.1064750924706459
step: 130, loss: 0.09819259494543076
step: 140, loss: 0.07429178059101105
step: 150, loss: 0.21576839685440063
step: 160, loss: 0.09560959786176682
step: 170, loss: 0.03044223226606846
step: 180, loss: 0.1431421935558319
step: 190, loss: 0.15887372195720673
step: 200, loss: 0.06865476816892624
step: 210, loss: 0.05019574612379074
step: 220, loss: 0.0860089510679245
step: 230, loss: 0.12231049686670303
step: 240, loss: 0.12010625749826431
step: 250, loss: 0.09661629796028137
step: 260, loss: 0.03338328003883362
step: 270, loss: 0.16535933315753937
step: 280, loss: 0.041759587824344635
step: 290, loss: 0.14300298690795898
step: 300, loss: 0.22881102561950684
step: 310, loss: 0.2203521430492401
step: 320, loss: 0.1000996083021164
step: 330, loss: 0.13245455920696259
step: 340, loss: 0.25639382004737854
step: 350, loss: 0.06302056461572647
step: 360, loss: 0.1751987487077713
step: 370, loss: 0.08646780252456665
step: 380, loss: 0.15768484771251678
step: 390, loss: 0.1472516655921936
step: 400, loss: 0.23604759573936462
step: 410, loss: 0.22303937375545502
step: 420, loss: 0.10857956111431122
step: 430, loss: 0.08610568940639496
step: 440, loss: 0.07157764583826065
step: 450, loss: 0.16800859570503235
step: 460, loss: 0.10705237835645676
step: 470, loss: 0.1723143309354782
step: 480, loss: 0.08584605157375336
step: 490, loss: 0.13762040436267853
step: 500, loss: 0.099767304956913
step: 510, loss: 0.10873576253652573
step: 520, loss: 0.2761211395263672
step: 530, loss: 0.13128595054149628
step: 540, loss: 0.10423982888460159
step: 550, loss: 0.27704840898513794
step: 560, loss: 0.13170480728149414
step: 570, loss: 0.17645899951457977
step: 580, loss: 0.16879765689373016
step: 590, loss: 0.08810608088970184
step: 600, loss: 0.07350993901491165
step: 610, loss: 0.18361006677150726
step: 620, loss: 0.07626385241746902
step: 630, loss: 0.061132628470659256
step: 640, loss: 0.09555620700120926
step: 650, loss: 0.013500283472239971
step: 660, loss: 0.1263936460018158
step: 670, loss: 0.16554999351501465
step: 680, loss: 0.16893459856510162
step: 690, loss: 0.1934591382741928
step: 700, loss: 0.07508151978254318
step: 710, loss: 0.16286319494247437
step: 720, loss: 0.08556384593248367
step: 730, loss: 0.11777153611183167
step: 740, loss: 0.030448587611317635
step: 750, loss: 0.09475673735141754
step: 760, loss: 0.14927054941654205
step: 770, loss: 0.039714619517326355
step: 780, loss: 0.04712119325995445
step: 790, loss: 0.09549255669116974
step: 800, loss: 0.1258721649646759
step: 810, loss: 0.09316258132457733
step: 820, loss: 0.14702878892421722
step: 830, loss: 0.10171230137348175
step: 840, loss: 0.13838082551956177
step: 850, loss: 0.08659715205430984
step: 860, loss: 0.0720629170536995
step: 870, loss: 0.03336567431688309
step: 880, loss: 0.15739905834197998
step: 890, loss: 0.11736898869276047
step: 900, loss: 0.1050683856010437
step: 910, loss: 0.18630221486091614
step: 920, loss: 0.10672392696142197
step: 930, loss: 0.07628728449344635
step: 940, loss: 0.14430983364582062
step: 950, loss: 0.07120754569768906
step: 960, loss: 0.11869210004806519
step: 970, loss: 0.17456640303134918
epoch 4: dev_f1=0.9304229195088677, f1=0.9187956204379562, best_f1=0.9362677670793214
step: 0, loss: 0.09723491221666336
step: 10, loss: 0.1237625777721405
step: 20, loss: 0.0824626162648201
step: 30, loss: 0.16564735770225525
step: 40, loss: 0.14495302736759186
step: 50, loss: 0.20613554120063782
step: 60, loss: 0.21782119572162628
step: 70, loss: 0.03970618173480034
step: 80, loss: 0.1233024075627327
step: 90, loss: 0.11954468488693237
step: 100, loss: 0.1252773106098175
step: 110, loss: 0.08234801143407822
step: 120, loss: 0.10813182592391968
step: 130, loss: 0.08229618519544601
step: 140, loss: 0.07557778060436249
step: 150, loss: 0.14978493750095367
step: 160, loss: 0.08862810581922531
step: 170, loss: 0.14342544972896576
step: 180, loss: 0.08138930797576904
step: 190, loss: 0.20016756653785706
step: 200, loss: 0.0888044610619545
step: 210, loss: 0.05071598291397095
step: 220, loss: 0.03842196986079216
step: 230, loss: 0.03587934374809265
step: 240, loss: 0.15195728838443756
step: 250, loss: 0.12110702693462372
step: 260, loss: 0.11764223128557205
step: 270, loss: 0.09042646735906601
step: 280, loss: 0.06957225501537323
step: 290, loss: 0.04935189336538315
step: 300, loss: 0.332085520029068
step: 310, loss: 0.10205689817667007
step: 320, loss: 0.068594790995121
step: 330, loss: 0.12662580609321594
step: 340, loss: 0.07931236177682877
step: 350, loss: 0.10379316657781601
step: 360, loss: 0.06236807629466057
step: 370, loss: 0.05215838551521301
step: 380, loss: 0.18563684821128845
step: 390, loss: 0.10654035955667496
step: 400, loss: 0.10522174835205078
step: 410, loss: 0.05617116764187813
step: 420, loss: 0.1724802851676941
step: 430, loss: 0.0810774490237236
step: 440, loss: 0.08256971091032028
step: 450, loss: 0.08944164961576462
step: 460, loss: 0.05521880462765694
step: 470, loss: 0.10125192254781723
step: 480, loss: 0.08863075077533722
step: 490, loss: 0.05077823996543884
step: 500, loss: 0.05736374855041504
step: 510, loss: 0.06750001013278961
step: 520, loss: 0.11386477202177048
step: 530, loss: 0.1358870267868042
step: 540, loss: 0.04659460484981537
step: 550, loss: 0.09039676934480667
step: 560, loss: 0.08257533609867096
step: 570, loss: 0.059018079191446304
step: 580, loss: 0.25051650404930115
step: 590, loss: 0.1539050042629242
step: 600, loss: 0.14269304275512695
step: 610, loss: 0.2211000919342041
step: 620, loss: 0.10533227771520615
step: 630, loss: 0.038487307727336884
step: 640, loss: 0.0908205434679985
step: 650, loss: 0.09047755599021912
step: 660, loss: 0.06922406703233719
step: 670, loss: 0.1192791536450386
step: 680, loss: 0.15817774832248688
step: 690, loss: 0.019053131341934204
step: 700, loss: 0.2250501662492752
step: 710, loss: 0.04189947992563248
step: 720, loss: 0.15227758884429932
step: 730, loss: 0.01022286992520094
step: 740, loss: 0.06325972825288773
step: 750, loss: 0.0698043555021286
step: 760, loss: 0.0029580160044133663
step: 770, loss: 0.2279122769832611
step: 780, loss: 0.07019547373056412
step: 790, loss: 0.18571561574935913
step: 800, loss: 0.20574362576007843
step: 810, loss: 0.09799344092607498
step: 820, loss: 0.1437358409166336
step: 830, loss: 0.09665452688932419
step: 840, loss: 0.06676165014505386
step: 850, loss: 0.13388051092624664
step: 860, loss: 0.19381053745746613
step: 870, loss: 0.059504084289073944
step: 880, loss: 0.09427329897880554
step: 890, loss: 0.15231193602085114
step: 900, loss: 0.15948379039764404
step: 910, loss: 0.058056432753801346
step: 920, loss: 0.07878722250461578
step: 930, loss: 0.07345044612884521
step: 940, loss: 0.16170866787433624
step: 950, loss: 0.1356777846813202
step: 960, loss: 0.03712878376245499
step: 970, loss: 0.14904923737049103
epoch 5: dev_f1=0.9305492510213346, f1=0.9298724954462659, best_f1=0.9362677670793214
step: 0, loss: 0.23742985725402832
step: 10, loss: 0.10555984079837799
step: 20, loss: 0.017918596044182777
step: 30, loss: 0.13994134962558746
step: 40, loss: 0.06011422723531723
step: 50, loss: 0.11686495691537857
step: 60, loss: 0.16292616724967957
step: 70, loss: 0.07509158551692963
step: 80, loss: 0.10999679565429688
step: 90, loss: 0.07580395042896271
step: 100, loss: 0.10788017511367798
step: 110, loss: 0.08819720149040222
step: 120, loss: 0.08531543612480164
step: 130, loss: 0.05897561460733414
step: 140, loss: 0.11287581920623779
step: 150, loss: 0.06318874657154083
step: 160, loss: 0.03876972571015358
step: 170, loss: 0.03612074255943298
step: 180, loss: 0.03066742978990078
step: 190, loss: 0.11045065522193909
step: 200, loss: 0.09805675595998764
step: 210, loss: 0.05637960880994797
step: 220, loss: 0.18312981724739075
step: 230, loss: 0.09903427958488464
step: 240, loss: 0.06297145783901215
step: 250, loss: 0.07040400803089142
step: 260, loss: 0.21116216480731964
step: 270, loss: 0.05565158277750015
step: 280, loss: 0.0841033086180687
step: 290, loss: 0.15406978130340576
step: 300, loss: 0.1115078255534172
step: 310, loss: 0.058940380811691284
step: 320, loss: 0.06337220221757889
step: 330, loss: 0.1537342369556427
step: 340, loss: 0.2376360297203064
step: 350, loss: 0.015637822449207306
step: 360, loss: 0.13902950286865234
step: 370, loss: 0.122309111058712
step: 380, loss: 0.08653227239847183
step: 390, loss: 0.09104769676923752
step: 400, loss: 0.21682976186275482
step: 410, loss: 0.14419013261795044
step: 420, loss: 0.07408924400806427
step: 430, loss: 0.17603278160095215
step: 440, loss: 0.05316285416483879
step: 450, loss: 0.14155660569667816
step: 460, loss: 0.1915794163942337
step: 470, loss: 0.06334000080823898
step: 480, loss: 0.14620162546634674
step: 490, loss: 0.15426985919475555
step: 500, loss: 0.07081808894872665
step: 510, loss: 0.12591135501861572
step: 520, loss: 0.23748399317264557
step: 530, loss: 0.04622470587491989
step: 540, loss: 0.11744379997253418
step: 550, loss: 0.09210856258869171
step: 560, loss: 0.017679458484053612
step: 570, loss: 0.0452394038438797
step: 580, loss: 0.07274017482995987
step: 590, loss: 0.1554439663887024
step: 600, loss: 0.17752721905708313
step: 610, loss: 0.09666359424591064
step: 620, loss: 0.2511586546897888
step: 630, loss: 0.12198015302419662
step: 640, loss: 0.13515551388263702
step: 650, loss: 0.049053676426410675
step: 660, loss: 0.04879588261246681
step: 670, loss: 0.1854233741760254
step: 680, loss: 0.1980014145374298
step: 690, loss: 0.1849518120288849
step: 700, loss: 0.10412412881851196
step: 710, loss: 0.11682534962892532
step: 720, loss: 0.0865563228726387
step: 730, loss: 0.11954911798238754
step: 740, loss: 0.09810120612382889
step: 750, loss: 0.19085924327373505
step: 760, loss: 0.07887588441371918
step: 770, loss: 0.23715044558048248
step: 780, loss: 0.03535600006580353
step: 790, loss: 0.11437509208917618
step: 800, loss: 0.16819581389427185
step: 810, loss: 0.12608163058757782
step: 820, loss: 0.17513085901737213
step: 830, loss: 0.15742263197898865
step: 840, loss: 0.04258207231760025
step: 850, loss: 0.08151594549417496
step: 860, loss: 0.11369729042053223
step: 870, loss: 0.16380110383033752
step: 880, loss: 0.07409579306840897
step: 890, loss: 0.12888489663600922
step: 900, loss: 0.09721094369888306
step: 910, loss: 0.09724072366952896
step: 920, loss: 0.09062566608190536
step: 930, loss: 0.017766563221812248
step: 940, loss: 0.14785811305046082
step: 950, loss: 0.10810849070549011
step: 960, loss: 0.08385667949914932
step: 970, loss: 0.14119434356689453
epoch 6: dev_f1=0.9357374017568193, f1=0.924860853432282, best_f1=0.9362677670793214
step: 0, loss: 0.134113609790802
step: 10, loss: 0.21713787317276
step: 20, loss: 0.04146958887577057
step: 30, loss: 0.07295640558004379
step: 40, loss: 0.03524935245513916
step: 50, loss: 0.0884246751666069
step: 60, loss: 0.1056128740310669
step: 70, loss: 0.052343204617500305
step: 80, loss: 0.09110800921916962
step: 90, loss: 0.020621247589588165
step: 100, loss: 0.03730634227395058
step: 110, loss: 0.08408726006746292
step: 120, loss: 0.09372866153717041
step: 130, loss: 0.0938018336892128
step: 140, loss: 0.12785476446151733
step: 150, loss: 0.09387669712305069
step: 160, loss: 0.017555467784404755
step: 170, loss: 0.14923499524593353
step: 180, loss: 0.05868447571992874
step: 190, loss: 0.0423588864505291
step: 200, loss: 0.12571975588798523
step: 210, loss: 0.024383390322327614
step: 220, loss: 0.05124780908226967
step: 230, loss: 0.0165200624614954
step: 240, loss: 0.2042761743068695
step: 250, loss: 0.13559582829475403
step: 260, loss: 0.1506778746843338
step: 270, loss: 0.10806221514940262
step: 280, loss: 0.20964188873767853
step: 290, loss: 0.021668273955583572
step: 300, loss: 0.13004854321479797
step: 310, loss: 0.05323025956749916
step: 320, loss: 0.17025861144065857
step: 330, loss: 0.07422999292612076
step: 340, loss: 0.03893323242664337
step: 350, loss: 0.11707610636949539
step: 360, loss: 0.0832798033952713
step: 370, loss: 0.024602117016911507
step: 380, loss: 0.014988399110734463
step: 390, loss: 0.10517127811908722
step: 400, loss: 0.020250361412763596
step: 410, loss: 0.1108025461435318
step: 420, loss: 0.078829824924469
step: 430, loss: 0.04452669993042946
step: 440, loss: 0.038627106696367264
step: 450, loss: 0.06667033582925797
step: 460, loss: 0.08105575293302536
step: 470, loss: 0.14336641132831573
step: 480, loss: 0.03925909474492073
step: 490, loss: 0.12439124286174774
step: 500, loss: 0.14833472669124603
step: 510, loss: 0.07411026954650879
step: 520, loss: 0.16808702051639557
step: 530, loss: 0.12419591099023819
step: 540, loss: 0.06964968889951706
step: 550, loss: 0.14569343626499176
step: 560, loss: 0.03091455064713955
step: 570, loss: 0.1653503179550171
step: 580, loss: 0.022889211773872375
step: 590, loss: 0.06694947928190231
step: 600, loss: 0.1597440540790558
step: 610, loss: 0.054975736886262894
step: 620, loss: 0.08037365227937698
step: 630, loss: 0.058921314775943756
step: 640, loss: 0.036600954830646515
step: 650, loss: 0.03716845437884331
step: 660, loss: 0.12715616822242737
step: 670, loss: 0.029581204056739807
step: 680, loss: 0.12067042291164398
step: 690, loss: 0.06716593354940414
step: 700, loss: 0.062034718692302704
step: 710, loss: 0.09855952858924866
step: 720, loss: 0.15194526314735413
step: 730, loss: 0.23069503903388977
step: 740, loss: 0.16201657056808472
step: 750, loss: 0.11506367474794388
step: 760, loss: 0.15862712264060974
step: 770, loss: 0.10986863821744919
step: 780, loss: 0.03586224466562271
step: 790, loss: 0.09378781914710999
step: 800, loss: 0.10060114413499832
step: 810, loss: 0.061385806649923325
step: 820, loss: 0.05228392407298088
step: 830, loss: 0.39297714829444885
step: 840, loss: 0.07771842926740646
step: 850, loss: 0.07460711896419525
step: 860, loss: 0.08599253743886948
step: 870, loss: 0.13666900992393494
step: 880, loss: 0.11460170149803162
step: 890, loss: 0.08316294103860855
step: 900, loss: 0.06641221791505814
step: 910, loss: 0.22295191884040833
step: 920, loss: 0.1125999316573143
step: 930, loss: 0.10227001458406448
step: 940, loss: 0.155975803732872
step: 950, loss: 0.05648861080408096
step: 960, loss: 0.05359102413058281
step: 970, loss: 0.1852230429649353
epoch 7: dev_f1=0.933768656716418, f1=0.9283402681460935, best_f1=0.9362677670793214
step: 0, loss: 0.06874900311231613
step: 10, loss: 0.07117091119289398
step: 20, loss: 0.06606582552194595
step: 30, loss: 0.16811704635620117
step: 40, loss: 0.06513642519712448
step: 50, loss: 0.09047522395849228
step: 60, loss: 0.10046441853046417
step: 70, loss: 0.09810584783554077
step: 80, loss: 0.11370538920164108
step: 90, loss: 0.13027475774288177
step: 100, loss: 0.11289653927087784
step: 110, loss: 0.1131899356842041
step: 120, loss: 0.035015128552913666
step: 130, loss: 0.04573078453540802
step: 140, loss: 0.07801155745983124
step: 150, loss: 0.052572354674339294
step: 160, loss: 0.04165433347225189
step: 170, loss: 0.16150161623954773
step: 180, loss: 0.14019297063350677
step: 190, loss: 0.14264293015003204
step: 200, loss: 0.017663225531578064
step: 210, loss: 0.06488335877656937
step: 220, loss: 0.07132720947265625
step: 230, loss: 0.12849202752113342
step: 240, loss: 0.117107093334198
step: 250, loss: 0.19486097991466522
step: 260, loss: 0.07845228910446167
step: 270, loss: 0.08264865726232529
step: 280, loss: 0.10035770386457443
step: 290, loss: 0.02874760515987873
step: 300, loss: 0.03575073182582855
step: 310, loss: 0.08560298383235931
step: 320, loss: 0.023768825456500053
step: 330, loss: 0.058537036180496216
step: 340, loss: 0.03653106838464737
step: 350, loss: 0.11444886773824692
step: 360, loss: 0.08773092925548553
step: 370, loss: 0.1648014783859253
step: 380, loss: 0.055701740086078644
step: 390, loss: 0.0616212822496891
step: 400, loss: 0.10268612205982208
step: 410, loss: 0.07978800684213638
step: 420, loss: 0.040399208664894104
step: 430, loss: 0.013563163578510284
step: 440, loss: 0.08927430957555771
step: 450, loss: 0.03592320531606674
step: 460, loss: 0.1091158464550972
step: 470, loss: 0.07093332707881927
step: 480, loss: 0.1342170387506485
step: 490, loss: 0.08907505869865417
step: 500, loss: 0.23456473648548126
step: 510, loss: 0.18389812111854553
step: 520, loss: 0.08110591024160385
step: 530, loss: 0.10660777986049652
step: 540, loss: 0.09096058458089828
step: 550, loss: 0.08098073303699493
step: 560, loss: 0.09750170260667801
step: 570, loss: 0.17735719680786133
step: 580, loss: 0.14691662788391113
step: 590, loss: 0.1594366729259491
step: 600, loss: 0.1787433624267578
step: 610, loss: 0.1194470077753067
step: 620, loss: 0.07403746992349625
step: 630, loss: 0.009395606815814972
step: 640, loss: 0.06138552725315094
step: 650, loss: 0.058398839086294174
step: 660, loss: 0.20319461822509766
step: 670, loss: 0.17059937119483948
step: 680, loss: 0.1523192673921585
step: 690, loss: 0.0722908154129982
step: 700, loss: 0.1420980840921402
step: 710, loss: 0.07868155092000961
step: 720, loss: 0.03497287631034851
step: 730, loss: 0.2132260501384735
step: 740, loss: 0.05258120596408844
step: 750, loss: 0.097598135471344
step: 760, loss: 0.03754962235689163
step: 770, loss: 0.1866789609193802
step: 780, loss: 0.019342515617609024
step: 790, loss: 0.1016634851694107
step: 800, loss: 0.10645689070224762
step: 810, loss: 0.10068799555301666
step: 820, loss: 0.09138251096010208
step: 830, loss: 0.14739194512367249
step: 840, loss: 0.16478198766708374
step: 850, loss: 0.05980755016207695
step: 860, loss: 0.08318477123975754
step: 870, loss: 0.09162048250436783
step: 880, loss: 0.06222831457853317
step: 890, loss: 0.13924890756607056
step: 900, loss: 0.12286703288555145
step: 910, loss: 0.07822310924530029
step: 920, loss: 0.17838525772094727
step: 930, loss: 0.12338187545537949
step: 940, loss: 0.038417212665081024
step: 950, loss: 0.022920381277799606
step: 960, loss: 0.04173962399363518
step: 970, loss: 0.10428686439990997
epoch 8: dev_f1=0.9333333333333335, f1=0.9216981132075471, best_f1=0.9362677670793214
step: 0, loss: 0.041192758828401566
step: 10, loss: 0.1275254637002945
step: 20, loss: 0.10750699043273926
step: 30, loss: 0.09278711676597595
step: 40, loss: 0.05794478952884674
step: 50, loss: 0.09551788866519928
step: 60, loss: 0.07454217970371246
step: 70, loss: 0.0234737116843462
step: 80, loss: 0.06590840220451355
step: 90, loss: 0.19402068853378296
step: 100, loss: 0.07809069752693176
step: 110, loss: 0.06095074862241745
step: 120, loss: 0.05224902555346489
step: 130, loss: 0.16163823008537292
step: 140, loss: 0.05343560501933098
step: 150, loss: 0.009268468245863914
step: 160, loss: 0.16359512507915497
step: 170, loss: 0.06594505161046982
step: 180, loss: 0.043163735419511795
step: 190, loss: 0.12321871519088745
step: 200, loss: 0.0980716198682785
step: 210, loss: 0.07913774251937866
step: 220, loss: 0.06132262945175171
step: 230, loss: 0.05852091684937477
step: 240, loss: 0.04198167473077774
step: 250, loss: 0.11399001628160477
step: 260, loss: 0.019943993538618088
step: 270, loss: 0.04913141205906868
step: 280, loss: 0.12373743951320648
step: 290, loss: 0.059205155819654465
step: 300, loss: 0.029286323115229607
step: 310, loss: 0.16836433112621307
step: 320, loss: 0.05174019932746887
step: 330, loss: 0.09844031929969788
step: 340, loss: 0.0960821583867073
step: 350, loss: 0.05672537535429001
step: 360, loss: 0.04668645188212395
step: 370, loss: 0.09120164066553116
step: 380, loss: 0.07673341035842896
step: 390, loss: 0.08551401644945145
step: 400, loss: 0.13413310050964355
step: 410, loss: 0.14414681494235992
step: 420, loss: 0.07157905399799347
step: 430, loss: 0.05178242549300194
step: 440, loss: 0.09311186522245407
step: 450, loss: 0.1766485720872879
step: 460, loss: 0.1397252380847931
step: 470, loss: 0.11730124801397324
step: 480, loss: 0.23104354739189148
step: 490, loss: 0.09966722875833511
step: 500, loss: 0.06766967475414276
step: 510, loss: 0.03569770231842995
step: 520, loss: 0.10156387835741043
step: 530, loss: 0.08677460253238678
step: 540, loss: 0.15643465518951416
step: 550, loss: 0.09509823471307755
step: 560, loss: 0.034241314977407455
step: 570, loss: 0.08547332882881165
step: 580, loss: 0.07504163682460785
step: 590, loss: 0.08982022106647491
step: 600, loss: 0.08397196233272552
step: 610, loss: 0.03790231794118881
step: 620, loss: 0.17650143802165985
step: 630, loss: 0.04952007532119751
step: 640, loss: 0.13322047889232635
step: 650, loss: 0.12521836161613464
step: 660, loss: 0.11333129554986954
step: 670, loss: 0.15154647827148438
step: 680, loss: 0.10577213764190674
step: 690, loss: 0.1333530843257904
step: 700, loss: 0.10486334562301636
step: 710, loss: 0.1039271205663681
step: 720, loss: 0.1857381910085678
step: 730, loss: 0.1678146868944168
step: 740, loss: 0.06433840841054916
step: 750, loss: 0.05835556611418724
step: 760, loss: 0.2079440802335739
step: 770, loss: 0.08577823638916016
step: 780, loss: 0.028701506555080414
step: 790, loss: 0.05431622266769409
step: 800, loss: 0.20688462257385254
step: 810, loss: 0.11073746532201767
step: 820, loss: 0.06627047806978226
step: 830, loss: 0.05165312439203262
step: 840, loss: 0.04905690997838974
step: 850, loss: 0.06425769627094269
step: 860, loss: 0.0529235415160656
step: 870, loss: 0.11425196379423141
step: 880, loss: 0.13526014983654022
step: 890, loss: 0.07510577142238617
step: 900, loss: 0.06427080184221268
step: 910, loss: 0.06333398818969727
step: 920, loss: 0.10780167579650879
step: 930, loss: 0.045173026621341705
step: 940, loss: 0.035155218094587326
step: 950, loss: 0.15507861971855164
step: 960, loss: 0.19211705029010773
step: 970, loss: 0.14549358189105988
epoch 9: dev_f1=0.9295134151887223, f1=0.9247606019151847, best_f1=0.9362677670793214
step: 0, loss: 0.08549583703279495
step: 10, loss: 0.08293300867080688
step: 20, loss: 0.08203181624412537
step: 30, loss: 0.14548276364803314
step: 40, loss: 0.09721431136131287
step: 50, loss: 0.20763784646987915
step: 60, loss: 0.048266876488924026
step: 70, loss: 0.09772882610559464
step: 80, loss: 0.08015843480825424
step: 90, loss: 0.0448804572224617
step: 100, loss: 0.0954662561416626
step: 110, loss: 0.0457397885620594
step: 120, loss: 0.026830166578292847
step: 130, loss: 0.07842516154050827
step: 140, loss: 0.062213391065597534
step: 150, loss: 0.05447006598114967
step: 160, loss: 0.07172871381044388
step: 170, loss: 0.15440398454666138
step: 180, loss: 0.06213999539613724
step: 190, loss: 0.026488540694117546
step: 200, loss: 0.05136591196060181
step: 210, loss: 0.053919658064842224
step: 220, loss: 0.04548419639468193
step: 230, loss: 0.09322109818458557
step: 240, loss: 0.08500871807336807
step: 250, loss: 0.07347708940505981
step: 260, loss: 0.13379082083702087
step: 270, loss: 0.1819693148136139
step: 280, loss: 0.03497471287846565
step: 290, loss: 0.009208694100379944
step: 300, loss: 0.036371130496263504
step: 310, loss: 0.08673534542322159
step: 320, loss: 0.08702268451452255
step: 330, loss: 0.16506369411945343
step: 340, loss: 0.09488213062286377
step: 350, loss: 0.04370966553688049
step: 360, loss: 0.04423658177256584
step: 370, loss: 0.02787219174206257
step: 380, loss: 0.06485592573881149
step: 390, loss: 0.08308246731758118
step: 400, loss: 0.163825124502182
step: 410, loss: 0.12447096407413483
step: 420, loss: 0.10107026994228363
step: 430, loss: 0.0984678789973259
step: 440, loss: 0.08147575706243515
step: 450, loss: 0.22599095106124878
step: 460, loss: 0.07318392395973206
step: 470, loss: 0.10318032652139664
step: 480, loss: 0.1249765008687973
step: 490, loss: 0.0606871135532856
step: 500, loss: 0.11819097399711609
step: 510, loss: 0.08886093646287918
step: 520, loss: 0.10201386362314224
step: 530, loss: 0.06969625502824783
step: 540, loss: 0.09163737297058105
step: 550, loss: 0.10160351544618607
step: 560, loss: 0.124297596514225
step: 570, loss: 0.03722545504570007
step: 580, loss: 0.04871247708797455
step: 590, loss: 0.050662651658058167
step: 600, loss: 0.08432085812091827
step: 610, loss: 0.09182827174663544
step: 620, loss: 0.11365050077438354
step: 630, loss: 0.09005482494831085
step: 640, loss: 0.1265282779932022
step: 650, loss: 0.18926846981048584
step: 660, loss: 0.14147008955478668
step: 670, loss: 0.07735462486743927
step: 680, loss: 0.1162298172712326
step: 690, loss: 0.2647014856338501
step: 700, loss: 0.05728791281580925
step: 710, loss: 0.07415588945150375
step: 720, loss: 0.12128748744726181
step: 730, loss: 0.09355515241622925
step: 740, loss: 0.13259823620319366
step: 750, loss: 0.06716576963663101
step: 760, loss: 0.11064175516366959
step: 770, loss: 0.09600931406021118
step: 780, loss: 0.0705007016658783
step: 790, loss: 0.10222986340522766
step: 800, loss: 0.10369854420423508
step: 810, loss: 0.07236430048942566
step: 820, loss: 0.1049826592206955
step: 830, loss: 0.09760937839746475
step: 840, loss: 0.07679685205221176
step: 850, loss: 0.036153994500637054
step: 860, loss: 0.06943482160568237
step: 870, loss: 0.15802335739135742
step: 880, loss: 0.09571366757154465
step: 890, loss: 0.11205384135246277
step: 900, loss: 0.027248471975326538
step: 910, loss: 0.11340488493442535
step: 920, loss: 0.05813923850655556
step: 930, loss: 0.03535589203238487
step: 940, loss: 0.2048504650592804
step: 950, loss: 0.11944983899593353
step: 960, loss: 0.043335966765880585
step: 970, loss: 0.00786388199776411
epoch 10: dev_f1=0.9338235294117647, f1=0.9267618608935975, best_f1=0.9362677670793214
step: 0, loss: 0.07220523804426193
step: 10, loss: 0.040166717022657394
step: 20, loss: 0.04785926640033722
step: 30, loss: 0.029001768678426743
step: 40, loss: 0.0867735892534256
step: 50, loss: 0.0930466428399086
step: 60, loss: 0.02276381477713585
step: 70, loss: 0.06240837275981903
step: 80, loss: 0.058686405420303345
step: 90, loss: 0.030225161463022232
step: 100, loss: 0.00715999398380518
step: 110, loss: 0.21880324184894562
step: 120, loss: 0.10678625851869583
step: 130, loss: 0.19249743223190308
step: 140, loss: 0.027908114716410637
step: 150, loss: 0.06076475605368614
step: 160, loss: 0.015967313200235367
step: 170, loss: 0.10098639130592346
step: 180, loss: 0.1098361685872078
step: 190, loss: 0.027627788484096527
step: 200, loss: 0.06944499909877777
step: 210, loss: 0.0704713836312294
step: 220, loss: 0.07901804149150848
step: 230, loss: 0.03697163984179497
step: 240, loss: 0.03982643783092499
step: 250, loss: 0.09438867121934891
step: 260, loss: 0.17196156084537506
step: 270, loss: 0.19454553723335266
step: 280, loss: 0.09070727974176407
step: 290, loss: 0.04561261832714081
step: 300, loss: 0.0721362754702568
step: 310, loss: 0.12386760860681534
step: 320, loss: 0.032654255628585815
step: 330, loss: 0.03459739685058594
step: 340, loss: 0.10661770403385162
step: 350, loss: 0.065610371530056
step: 360, loss: 0.12943819165229797
step: 370, loss: 0.07098409533500671
step: 380, loss: 0.08819413185119629
step: 390, loss: 0.04665589705109596
step: 400, loss: 0.06206769123673439
step: 410, loss: 0.031208347529172897
step: 420, loss: 0.029035024344921112
step: 430, loss: 0.13281437754631042
step: 440, loss: 0.10406466573476791
step: 450, loss: 0.04339125007390976
step: 460, loss: 0.09994781762361526
step: 470, loss: 0.06506277620792389
step: 480, loss: 0.16009429097175598
step: 490, loss: 0.05424483120441437
step: 500, loss: 0.12238592654466629
step: 510, loss: 0.07831161469221115
step: 520, loss: 0.11026541888713837
step: 530, loss: 0.047982312738895416
step: 540, loss: 0.03480115532875061
step: 550, loss: 0.13540902733802795
step: 560, loss: 0.08243575692176819
step: 570, loss: 0.10947038978338242
step: 580, loss: 0.09729529917240143
step: 590, loss: 0.16135267913341522
step: 600, loss: 0.06804677844047546
step: 610, loss: 0.12724843621253967
step: 620, loss: 0.17987102270126343
step: 630, loss: 0.06670036166906357
step: 640, loss: 0.07103627175092697
step: 650, loss: 0.09973116964101791
step: 660, loss: 0.10773725807666779
step: 670, loss: 0.026504775509238243
step: 680, loss: 0.02349213697016239
step: 690, loss: 0.12939374148845673
step: 700, loss: 0.07950412482023239
step: 710, loss: 0.1542859673500061
step: 720, loss: 0.0006492997636087239
step: 730, loss: 0.22949083149433136
step: 740, loss: 0.16534972190856934
step: 750, loss: 0.03558674082159996
step: 760, loss: 0.05064397677779198
step: 770, loss: 0.07848954945802689
step: 780, loss: 0.12079227715730667
step: 790, loss: 0.011823628097772598
step: 800, loss: 0.11716599017381668
step: 810, loss: 0.01575414277613163
step: 820, loss: 0.051616329699754715
step: 830, loss: 0.09534861147403717
step: 840, loss: 0.04083656892180443
step: 850, loss: 0.02024763636291027
step: 860, loss: 0.07728537917137146
step: 870, loss: 0.06655202805995941
step: 880, loss: 0.20326219499111176
step: 890, loss: 0.14676396548748016
step: 900, loss: 0.22022107243537903
step: 910, loss: 0.021543068811297417
step: 920, loss: 0.12446253001689911
step: 930, loss: 0.03581808879971504
step: 940, loss: 0.03580765426158905
step: 950, loss: 0.14094838500022888
step: 960, loss: 0.00936631578952074
step: 970, loss: 0.0262304674834013
epoch 11: dev_f1=0.9344490934449092, f1=0.9279404927940492, best_f1=0.9362677670793214
step: 0, loss: 0.10757243633270264
step: 10, loss: 0.061132967472076416
step: 20, loss: 0.05105676129460335
step: 30, loss: 0.17992620170116425
step: 40, loss: 0.05396310240030289
step: 50, loss: 0.14356741309165955
step: 60, loss: 0.005365926772356033
step: 70, loss: 0.16584137082099915
step: 80, loss: 0.06865323334932327
step: 90, loss: 0.09251962602138519
step: 100, loss: 0.04524999484419823
step: 110, loss: 0.025838494300842285
step: 120, loss: 0.07983600348234177
step: 130, loss: 0.07458370178937912
step: 140, loss: 0.04596305266022682
step: 150, loss: 0.06608778238296509
step: 160, loss: 0.07514891773462296
step: 170, loss: 0.03600421920418739
step: 180, loss: 0.11178445816040039
step: 190, loss: 0.18200531601905823
step: 200, loss: 0.030566083267331123
step: 210, loss: 0.05108823999762535
step: 220, loss: 0.014638008549809456
step: 230, loss: 0.059758637100458145
step: 240, loss: 0.08410171419382095
step: 250, loss: 0.1258133202791214
step: 260, loss: 0.024525340646505356
step: 270, loss: 0.13743603229522705
step: 280, loss: 0.04503575339913368
step: 290, loss: 0.020930957049131393
step: 300, loss: 0.030590353533625603
step: 310, loss: 0.0508931465446949
step: 320, loss: 0.05818456411361694
step: 330, loss: 0.04485068470239639
step: 340, loss: 0.12360280752182007
step: 350, loss: 0.10180757194757462
step: 360, loss: 0.04346909001469612
step: 370, loss: 0.15533685684204102
step: 380, loss: 0.019222473725676537
step: 390, loss: 0.05157242342829704
step: 400, loss: 0.08779827505350113
step: 410, loss: 0.022749532014131546
step: 420, loss: 0.03948220610618591
step: 430, loss: 0.13110624253749847
step: 440, loss: 0.18022580444812775
step: 450, loss: 0.10105524957180023
step: 460, loss: 0.1891094446182251
step: 470, loss: 0.10723177343606949
step: 480, loss: 0.08470621705055237
step: 490, loss: 0.06040146201848984
step: 500, loss: 0.12997618317604065
step: 510, loss: 0.08987750113010406
step: 520, loss: 0.0006738468073308468
step: 530, loss: 0.05295718088746071
step: 540, loss: 0.11930064857006073
step: 550, loss: 0.1579103320837021
step: 560, loss: 0.07083306461572647
step: 570, loss: 0.023812560364603996
step: 580, loss: 0.08818574994802475
step: 590, loss: 0.061197854578495026
step: 600, loss: 0.06040303409099579
step: 610, loss: 0.05465038865804672
step: 620, loss: 0.054726894944906235
step: 630, loss: 0.09052641689777374
step: 640, loss: 0.060289740562438965
step: 650, loss: 0.10265843570232391
step: 660, loss: 0.05708945170044899
step: 670, loss: 0.054677464067935944
step: 680, loss: 0.031032584607601166
step: 690, loss: 0.001992312027141452
step: 700, loss: 0.04589107632637024
step: 710, loss: 0.10898826271295547
step: 720, loss: 0.14732883870601654
step: 730, loss: 0.08739129453897476
step: 740, loss: 0.10284066945314407
step: 750, loss: 0.1768738478422165
step: 760, loss: 0.07724270224571228
step: 770, loss: 0.06809687614440918
step: 780, loss: 0.1321449875831604
step: 790, loss: 0.021595673635601997
step: 800, loss: 0.08868090808391571
step: 810, loss: 0.10472404956817627
step: 820, loss: 0.03240947797894478
step: 830, loss: 0.07326187193393707
step: 840, loss: 0.025178784504532814
step: 850, loss: 0.020958302542567253
step: 860, loss: 0.09614676237106323
step: 870, loss: 0.09470190852880478
step: 880, loss: 0.1304766982793808
step: 890, loss: 0.20388509333133698
step: 900, loss: 0.05580613389611244
step: 910, loss: 0.12398717552423477
step: 920, loss: 0.06289653480052948
step: 930, loss: 0.06179626286029816
step: 940, loss: 0.12181437760591507
step: 950, loss: 0.037242341786623
step: 960, loss: 0.15390795469284058
step: 970, loss: 0.14158569276332855
epoch 12: dev_f1=0.9312072892938498, f1=0.9231477220432581, best_f1=0.9362677670793214
step: 0, loss: 0.07524258643388748
step: 10, loss: 0.04430975019931793
step: 20, loss: 0.08149146288633347
step: 30, loss: 0.20216107368469238
step: 40, loss: 0.03540754318237305
step: 50, loss: 0.025217128917574883
step: 60, loss: 0.1300552785396576
step: 70, loss: 0.06476636976003647
step: 80, loss: 0.015943489968776703
step: 90, loss: 0.013769197277724743
step: 100, loss: 0.15882471203804016
step: 110, loss: 0.13372398912906647
step: 120, loss: 0.08665434271097183
step: 130, loss: 0.056202515959739685
step: 140, loss: 0.07651052623987198
step: 150, loss: 0.08824130892753601
step: 160, loss: 0.0338556207716465
step: 170, loss: 0.0639616847038269
step: 180, loss: 0.022811146453022957
step: 190, loss: 0.03826616331934929
step: 200, loss: 0.02593635767698288
step: 210, loss: 0.05383100360631943
step: 220, loss: 0.06807693094015121
step: 230, loss: 0.1015923023223877
step: 240, loss: 0.029884448274970055
step: 250, loss: 0.0901937186717987
step: 260, loss: 0.03260420262813568
step: 270, loss: 0.013085156679153442
step: 280, loss: 0.02354203164577484
step: 290, loss: 0.019413281232118607
step: 300, loss: 0.09886029362678528
step: 310, loss: 0.031972985714673996
step: 320, loss: 0.08275103569030762
step: 330, loss: 0.013746197335422039
step: 340, loss: 0.022679943591356277
step: 350, loss: 0.04635058715939522
step: 360, loss: 0.07509788870811462
step: 370, loss: 0.09841752797365189
step: 380, loss: 0.08615133911371231
step: 390, loss: 0.10366491228342056
step: 400, loss: 0.029965072870254517
step: 410, loss: 0.017003998160362244
step: 420, loss: 0.12737710773944855
step: 430, loss: 0.08742900937795639
step: 440, loss: 0.0387810654938221
step: 450, loss: 0.04869420453906059
step: 460, loss: 0.11601459234952927
step: 470, loss: 0.09955114126205444
step: 480, loss: 0.050421759486198425
step: 490, loss: 0.08627218753099442
step: 500, loss: 0.0081728370860219
step: 510, loss: 0.0654435083270073
step: 520, loss: 0.1308283656835556
step: 530, loss: 0.04421636462211609
step: 540, loss: 0.07677429914474487
step: 550, loss: 0.015757596120238304
step: 560, loss: 0.03244272992014885
step: 570, loss: 0.14262187480926514
step: 580, loss: 0.09686768800020218
step: 590, loss: 0.1336696892976761
step: 600, loss: 0.05589184910058975
step: 610, loss: 0.025410525500774384
step: 620, loss: 0.11089568585157394
step: 630, loss: 0.06474261730909348
step: 640, loss: 0.07433055341243744
step: 650, loss: 0.0929824709892273
step: 660, loss: 0.12870573997497559
step: 670, loss: 0.03824790567159653
step: 680, loss: 0.06414578855037689
step: 690, loss: 0.11403434723615646
step: 700, loss: 0.051025763154029846
step: 710, loss: 0.04419521614909172
step: 720, loss: 0.05280321463942528
step: 730, loss: 0.04534235596656799
step: 740, loss: 0.07814732939004898
step: 750, loss: 0.035774409770965576
step: 760, loss: 0.11564076691865921
step: 770, loss: 0.028429387137293816
step: 780, loss: 0.11239362508058548
step: 790, loss: 0.05492379888892174
step: 800, loss: 0.12754592299461365
step: 810, loss: 0.06914160400629044
step: 820, loss: 0.07645083218812943
step: 830, loss: 0.12610071897506714
step: 840, loss: 0.07354914397001266
step: 850, loss: 0.07475708425045013
step: 860, loss: 0.0606754869222641
step: 870, loss: 0.08470278978347778
step: 880, loss: 0.03287642449140549
step: 890, loss: 0.1182042583823204
step: 900, loss: 0.05014730989933014
step: 910, loss: 0.02606903947889805
step: 920, loss: 0.048613566905260086
step: 930, loss: 0.07914130389690399
step: 940, loss: 0.02819327637553215
step: 950, loss: 0.05938034504652023
step: 960, loss: 0.04120953381061554
step: 970, loss: 0.018429405987262726
epoch 13: dev_f1=0.9322820037105751, f1=0.9270784951230839, best_f1=0.9362677670793214
step: 0, loss: 0.08735604584217072
step: 10, loss: 0.08653208613395691
step: 20, loss: 0.08245956152677536
step: 30, loss: 0.04363396018743515
step: 40, loss: 0.03356547653675079
step: 50, loss: 0.025917187333106995
step: 60, loss: 0.13027425110340118
step: 70, loss: 0.05449310317635536
step: 80, loss: 0.08213485777378082
step: 90, loss: 0.052643392235040665
step: 100, loss: 0.08087151497602463
step: 110, loss: 0.04616274684667587
step: 120, loss: 0.03316982835531235
step: 130, loss: 0.043955568224191666
step: 140, loss: 0.029371162876486778
step: 150, loss: 0.06735768914222717
step: 160, loss: 0.06384067237377167
step: 170, loss: 0.0680086687207222
step: 180, loss: 0.05535079166293144
step: 190, loss: 0.025961535051465034
step: 200, loss: 0.09003135561943054
step: 210, loss: 0.035368215292692184
step: 220, loss: 0.25584298372268677
step: 230, loss: 0.10901547223329544
step: 240, loss: 0.027573740109801292
step: 250, loss: 0.007418365217745304
step: 260, loss: 0.07081866264343262
step: 270, loss: 0.1910417675971985
step: 280, loss: 0.032716430723667145
step: 290, loss: 0.025343729183077812
step: 300, loss: 0.08899866789579391
step: 310, loss: 0.0415557436645031
step: 320, loss: 0.0869435966014862
step: 330, loss: 0.016556086018681526
step: 340, loss: 0.03411298617720604
step: 350, loss: 0.06624092161655426
step: 360, loss: 0.05863052234053612
step: 370, loss: 8.015276398509741e-05
step: 380, loss: 0.07175734639167786
step: 390, loss: 0.04468892887234688
step: 400, loss: 0.02892431989312172
step: 410, loss: 0.05473858863115311
step: 420, loss: 0.011743538081645966
step: 430, loss: 0.04583519324660301
step: 440, loss: 0.017695382237434387
step: 450, loss: 0.012485717423260212
step: 460, loss: 0.06310185045003891
step: 470, loss: 0.044797636568546295
step: 480, loss: 0.09145395457744598
step: 490, loss: 0.03623200207948685
step: 500, loss: 0.044956810772418976
step: 510, loss: 0.01662301830947399
step: 520, loss: 0.00045972582302056253
step: 530, loss: 0.012928914278745651
step: 540, loss: 0.05076931044459343
step: 550, loss: 0.06557828933000565
step: 560, loss: 0.08761949837207794
step: 570, loss: 0.07619726657867432
step: 580, loss: 0.009800232015550137
step: 590, loss: 0.018530473113059998
step: 600, loss: 0.074839748442173
step: 610, loss: 0.04069572314620018
step: 620, loss: 0.09913361817598343
step: 630, loss: 0.0026824246160686016
step: 640, loss: 0.053103070706129074
step: 650, loss: 0.017993271350860596
step: 660, loss: 0.024006865918636322
step: 670, loss: 0.02315334975719452
step: 680, loss: 0.021627292037010193
step: 690, loss: 0.005552671849727631
step: 700, loss: 0.03451173007488251
step: 710, loss: 0.06571493297815323
step: 720, loss: 0.06309917569160461
step: 730, loss: 0.11716362833976746
step: 740, loss: 0.023056471720337868
step: 750, loss: 0.031849753111600876
step: 760, loss: 0.06306800991296768
step: 770, loss: 0.10158176720142365
step: 780, loss: 0.06815598905086517
step: 790, loss: 0.09155627340078354
step: 800, loss: 0.07368048280477524
step: 810, loss: 0.0017239856533706188
step: 820, loss: 0.023384680971503258
step: 830, loss: 0.05725053697824478
step: 840, loss: 0.033909086138010025
step: 850, loss: 0.10907325148582458
step: 860, loss: 0.0514228455722332
step: 870, loss: 0.017894446849822998
step: 880, loss: 0.06628738343715668
step: 890, loss: 0.06009327992796898
step: 900, loss: 0.05365004017949104
step: 910, loss: 0.046724192798137665
step: 920, loss: 0.08831208199262619
step: 930, loss: 0.13357515633106232
step: 940, loss: 0.0325448103249073
step: 950, loss: 0.11833836138248444
step: 960, loss: 0.03882380947470665
step: 970, loss: 5.923928983975202e-05
epoch 14: dev_f1=0.9272065514103731, f1=0.9159472966833259, best_f1=0.9362677670793214
step: 0, loss: 0.01667076162993908
step: 10, loss: 0.07711166888475418
step: 20, loss: 0.043889548629522324
step: 30, loss: 0.12647873163223267
step: 40, loss: 0.0246383436024189
step: 50, loss: 0.05781976133584976
step: 60, loss: 0.018459025770425797
step: 70, loss: 0.048493314534425735
step: 80, loss: 0.08222892135381699
step: 90, loss: 0.05243897810578346
step: 100, loss: 0.08143220841884613
step: 110, loss: 0.041563067585229874
step: 120, loss: 0.06420683860778809
step: 130, loss: 0.001201725215651095
step: 140, loss: 0.07050500065088272
step: 150, loss: 0.05661600083112717
step: 160, loss: 0.08953014016151428
step: 170, loss: 0.09840259701013565
step: 180, loss: 0.13184420764446259
step: 190, loss: 0.06013927236199379
step: 200, loss: 0.11625603586435318
step: 210, loss: 0.11446930468082428
step: 220, loss: 0.08072284609079361
step: 230, loss: 0.004173025023192167
step: 240, loss: 0.04953518137335777
step: 250, loss: 0.00018099510634783655
step: 260, loss: 0.049793142825365067
step: 270, loss: 0.004888008814305067
step: 280, loss: 0.22740180790424347
step: 290, loss: 0.02376774325966835
step: 300, loss: 0.08131255209445953
step: 310, loss: 0.009114173240959644
step: 320, loss: 0.040313299745321274
step: 330, loss: 0.08673711866140366
step: 340, loss: 0.004414897877722979
step: 350, loss: 0.04384216293692589
step: 360, loss: 0.08354491740465164
step: 370, loss: 0.08160130679607391
step: 380, loss: 0.031103765591979027
step: 390, loss: 0.03858121857047081
step: 400, loss: 0.006569082383066416
step: 410, loss: 0.05920432135462761
step: 420, loss: 0.009542250074446201
step: 430, loss: 0.022267917171120644
step: 440, loss: 0.00500722648575902
step: 450, loss: 0.042106833308935165
step: 460, loss: 0.03786678984761238
step: 470, loss: 0.04087884724140167
step: 480, loss: 0.05747390165925026
step: 490, loss: 0.021333152428269386
step: 500, loss: 0.038294073194265366
step: 510, loss: 0.03296532481908798
step: 520, loss: 0.015179346315562725
step: 530, loss: 0.05349818617105484
step: 540, loss: 0.057302430272102356
step: 550, loss: 0.04849320650100708
step: 560, loss: 0.07515064626932144
step: 570, loss: 0.06323494762182236
step: 580, loss: 0.007627593353390694
step: 590, loss: 0.06846572458744049
step: 600, loss: 0.03012772463262081
step: 610, loss: 0.056048423051834106
step: 620, loss: 0.027808761224150658
step: 630, loss: 0.030116496607661247
step: 640, loss: 0.07980861514806747
step: 650, loss: 0.10024086385965347
step: 660, loss: 0.04162311181426048
step: 670, loss: 0.044484157115221024
step: 680, loss: 0.02108282595872879
step: 690, loss: 0.06704868376255035
step: 700, loss: 0.10808064043521881
step: 710, loss: 0.1031370535492897
step: 720, loss: 0.009759870357811451
step: 730, loss: 0.030117271468043327
step: 740, loss: 0.04756113886833191
step: 750, loss: 0.04911428689956665
step: 760, loss: 0.08825793117284775
step: 770, loss: 0.06418844312429428
step: 780, loss: 0.10123182833194733
step: 790, loss: 0.026783596724271774
step: 800, loss: 0.0906234160065651
step: 810, loss: 0.0889497697353363
step: 820, loss: 0.04627973213791847
step: 830, loss: 0.0974552109837532
step: 840, loss: 0.1077265664935112
step: 850, loss: 0.13331854343414307
step: 860, loss: 0.113636814057827
step: 870, loss: 0.057636383920907974
step: 880, loss: 0.020154466852545738
step: 890, loss: 0.012515231966972351
step: 900, loss: 0.03579219430685043
step: 910, loss: 0.029466165229678154
step: 920, loss: 0.0167021956294775
step: 930, loss: 0.03641706705093384
step: 940, loss: 0.13540267944335938
step: 950, loss: 0.015039489604532719
step: 960, loss: 0.052968256175518036
step: 970, loss: 0.038948267698287964
epoch 15: dev_f1=0.9251386321626617, f1=0.912540490513651, best_f1=0.9362677670793214
step: 0, loss: 0.06884327530860901
step: 10, loss: 0.1117197573184967
step: 20, loss: 0.09423796832561493
step: 30, loss: 0.00777793675661087
step: 40, loss: 0.08665208518505096
step: 50, loss: 0.016998395323753357
step: 60, loss: 0.03917928785085678
step: 70, loss: 0.06254846602678299
step: 80, loss: 0.0959065854549408
step: 90, loss: 0.02154354192316532
step: 100, loss: 0.034914206713438034
step: 110, loss: 0.07041215896606445
step: 120, loss: 0.04286232963204384
step: 130, loss: 0.05895790085196495
step: 140, loss: 0.00047971849562600255
step: 150, loss: 0.029980622231960297
step: 160, loss: 0.05887093394994736
step: 170, loss: 0.09732101112604141
step: 180, loss: 0.03250238299369812
step: 190, loss: 0.06793859601020813
step: 200, loss: 0.05816848948597908
step: 210, loss: 0.03174654021859169
step: 220, loss: 0.04087528958916664
step: 230, loss: 0.020947258919477463
step: 240, loss: 0.08036407083272934
step: 250, loss: 0.11822962015867233
step: 260, loss: 0.05626877397298813
step: 270, loss: 0.022078359499573708
step: 280, loss: 0.06385359168052673
step: 290, loss: 0.09562229365110397
step: 300, loss: 0.039608605206012726
step: 310, loss: 0.15523721277713776
step: 320, loss: 0.12273577600717545
step: 330, loss: 0.16796010732650757
step: 340, loss: 0.05324529856443405
step: 350, loss: 0.2077229917049408
step: 360, loss: 0.0430462472140789
step: 370, loss: 0.09732545912265778
step: 380, loss: 0.042003240436315536
step: 390, loss: 0.049591876566410065
step: 400, loss: 0.03590890020132065
step: 410, loss: 0.03586501628160477
step: 420, loss: 0.07673805952072144
step: 430, loss: 0.05495055019855499
step: 440, loss: 0.08972088992595673
step: 450, loss: 0.020685754716396332
step: 460, loss: 5.311980567057617e-05
step: 470, loss: 0.0944572314620018
step: 480, loss: 0.08611663430929184
step: 490, loss: 0.034838829189538956
step: 500, loss: 0.14707475900650024
step: 510, loss: 0.003824646817520261
step: 520, loss: 0.10033025592565536
step: 530, loss: 0.0014897299697622657
step: 540, loss: 0.1293398141860962
step: 550, loss: 0.11086757481098175
step: 560, loss: 0.0014939907705411315
step: 570, loss: 0.12447932362556458
step: 580, loss: 0.04642312228679657
step: 590, loss: 0.008208726532757282
step: 600, loss: 0.01523907482624054
step: 610, loss: 0.05464572086930275
step: 620, loss: 0.00017464109987486154
step: 630, loss: 0.07511815428733826
step: 640, loss: 0.0444672591984272
step: 650, loss: 0.07695765048265457
step: 660, loss: 0.046666987240314484
step: 670, loss: 0.04293191432952881
step: 680, loss: 0.049606774002313614
step: 690, loss: 0.05168440192937851
step: 700, loss: 0.004092278890311718
step: 710, loss: 0.17187552154064178
step: 720, loss: 0.03780340030789375
step: 730, loss: 0.05988860875368118
step: 740, loss: 0.05996469035744667
step: 750, loss: 0.11877068877220154
step: 760, loss: 0.006908962037414312
step: 770, loss: 0.03366585075855255
step: 780, loss: 0.18763963878154755
step: 790, loss: 0.05028294026851654
step: 800, loss: 0.031124457716941833
step: 810, loss: 0.10536713898181915
step: 820, loss: 0.002816691529005766
step: 830, loss: 0.0653596818447113
step: 840, loss: 0.08115439862012863
step: 850, loss: 0.04800141602754593
step: 860, loss: 0.01558094285428524
step: 870, loss: 0.05882754549384117
step: 880, loss: 0.0003950549871660769
step: 890, loss: 0.02856380306184292
step: 900, loss: 0.0010568179422989488
step: 910, loss: 0.09470630437135696
step: 920, loss: 0.1410938799381256
step: 930, loss: 0.05535158887505531
step: 940, loss: 0.05891828238964081
step: 950, loss: 0.085135817527771
step: 960, loss: 0.06875571608543396
step: 970, loss: 0.05912972241640091
epoch 16: dev_f1=0.9263831732967536, f1=0.9208831646734131, best_f1=0.9362677670793214
step: 0, loss: 0.02249838039278984
step: 10, loss: 0.05970359221100807
step: 20, loss: 0.07629755139350891
step: 30, loss: 0.0009794686920940876
step: 40, loss: 0.05555250123143196
step: 50, loss: 0.001011194079183042
step: 60, loss: 0.0357230044901371
step: 70, loss: 0.08910568803548813
step: 80, loss: 0.004166950471699238
step: 90, loss: 0.04795090854167938
step: 100, loss: 0.03189835697412491
step: 110, loss: 0.10709138959646225
step: 120, loss: 0.04614347591996193
step: 130, loss: 0.08847633004188538
step: 140, loss: 0.07181612402200699
step: 150, loss: 0.05269492790102959
step: 160, loss: 0.06644567102193832
step: 170, loss: 0.02377348765730858
step: 180, loss: 0.05474307760596275
step: 190, loss: 0.049212198704481125
step: 200, loss: 0.1258421540260315
step: 210, loss: 0.06630940735340118
step: 220, loss: 0.028686881065368652
step: 230, loss: 0.05109936743974686
step: 240, loss: 0.08665228635072708
step: 250, loss: 0.013884147629141808
step: 260, loss: 0.026230253279209137
step: 270, loss: 0.038165297359228134
step: 280, loss: 0.023805156350135803
step: 290, loss: 0.029737582430243492
step: 300, loss: 0.0859023928642273
step: 310, loss: 0.06506548821926117
step: 320, loss: 0.02973979152739048
step: 330, loss: 0.07167765498161316
step: 340, loss: 0.030160851776599884
step: 350, loss: 0.06662528961896896
step: 360, loss: 0.12058194726705551
step: 370, loss: 0.06881958246231079
step: 380, loss: 4.0822294977260754e-05
step: 390, loss: 0.05978114530444145
step: 400, loss: 0.07875163853168488
step: 410, loss: 0.026042954996228218
step: 420, loss: 0.03747983276844025
step: 430, loss: 0.07183611392974854
step: 440, loss: 0.02004978060722351
step: 450, loss: 0.042635586112737656
step: 460, loss: 0.06825097650289536
step: 470, loss: 0.08070075511932373
step: 480, loss: 0.07567580789327621
step: 490, loss: 0.06592408567667007
step: 500, loss: 0.02704688534140587
step: 510, loss: 0.06052529811859131
step: 520, loss: 0.05420557036995888
step: 530, loss: 0.034337833523750305
step: 540, loss: 0.10262064635753632
step: 550, loss: 0.03292547166347504
step: 560, loss: 0.027819128707051277
step: 570, loss: 0.09107532352209091
step: 580, loss: 0.03709262236952782
step: 590, loss: 0.0633646547794342
step: 600, loss: 0.0442851185798645
step: 610, loss: 0.05395025759935379
step: 620, loss: 0.030116742476820946
step: 630, loss: 0.037373825907707214
step: 640, loss: 0.00022018374875187874
step: 650, loss: 0.0008603261667303741
step: 660, loss: 0.03904309496283531
step: 670, loss: 0.04022062569856644
step: 680, loss: 0.07253152132034302
step: 690, loss: 0.07224009186029434
step: 700, loss: 0.02180946059525013
step: 710, loss: 0.03731017932295799
step: 720, loss: 0.2021668553352356
step: 730, loss: 0.07546453177928925
step: 740, loss: 0.029982900246977806
step: 750, loss: 0.059401120990514755
step: 760, loss: 0.038041144609451294
step: 770, loss: 0.02690676413476467
step: 780, loss: 0.02838416025042534
step: 790, loss: 0.056312140077352524
step: 800, loss: 0.024281106889247894
step: 810, loss: 0.07236623764038086
step: 820, loss: 0.0227846447378397
step: 830, loss: 0.0861540287733078
step: 840, loss: 0.04996742308139801
step: 850, loss: 0.009011542424559593
step: 860, loss: 0.012632589787244797
step: 870, loss: 0.07323640584945679
step: 880, loss: 0.0470774807035923
step: 890, loss: 0.18716226518154144
step: 900, loss: 0.03502470627427101
step: 910, loss: 0.00010808228398673236
step: 920, loss: 0.02569323033094406
step: 930, loss: 0.22767621278762817
step: 940, loss: 0.026247071102261543
step: 950, loss: 0.06784426420927048
step: 960, loss: 0.09087278693914413
step: 970, loss: 0.04924902692437172
epoch 17: dev_f1=0.9273066169617894, f1=0.9266697804764129, best_f1=0.9362677670793214
step: 0, loss: 0.07338596880435944
step: 10, loss: 0.0032905656844377518
step: 20, loss: 0.09662170708179474
step: 30, loss: 0.032710663974285126
step: 40, loss: 0.039395771920681
step: 50, loss: 0.00010195757204201072
step: 60, loss: 0.1929921805858612
step: 70, loss: 0.09978518635034561
step: 80, loss: 0.06184615194797516
step: 90, loss: 0.019915256649255753
step: 100, loss: 0.02014916203916073
step: 110, loss: 0.019792964681982994
step: 120, loss: 0.09612690657377243
step: 130, loss: 0.0651104748249054
step: 140, loss: 0.02226337417960167
step: 150, loss: 0.020744595676660538
step: 160, loss: 0.029468001797795296
step: 170, loss: 0.006767755374312401
step: 180, loss: 0.023053457960486412
step: 190, loss: 0.030347947031259537
step: 200, loss: 0.03525572642683983
step: 210, loss: 0.07371559739112854
step: 220, loss: 0.029415540397167206
step: 230, loss: 0.07002189010381699
step: 240, loss: 0.0247268695384264
step: 250, loss: 0.01778707653284073
step: 260, loss: 0.07962458580732346
step: 270, loss: 1.4215103874448687e-05
step: 280, loss: 0.03238047659397125
step: 290, loss: 0.09029130637645721
step: 300, loss: 0.008504319004714489
step: 310, loss: 0.14529356360435486
step: 320, loss: 0.028241945430636406
step: 330, loss: 0.03916164115071297
step: 340, loss: 0.10359946638345718
step: 350, loss: 0.025991596281528473
step: 360, loss: 0.04546993598341942
step: 370, loss: 0.07245642691850662
step: 380, loss: 0.009580783545970917
step: 390, loss: 0.010189846158027649
step: 400, loss: 1.972020254470408e-05
step: 410, loss: 0.06431084126234055
step: 420, loss: 0.04326637089252472
step: 430, loss: 0.11896318197250366
step: 440, loss: 0.051785603165626526
step: 450, loss: 0.037770580500364304
step: 460, loss: 0.0003251087327953428
step: 470, loss: 0.026164308190345764
step: 480, loss: 0.08485869318246841
step: 490, loss: 0.02715246006846428
step: 500, loss: 0.07788404822349548
step: 510, loss: 0.12048749625682831
step: 520, loss: 0.05137857422232628
step: 530, loss: 0.14238062500953674
step: 540, loss: 0.01708289049565792
step: 550, loss: 0.10657615214586258
step: 560, loss: 4.613906639860943e-05
step: 570, loss: 0.043744515627622604
step: 580, loss: 0.020565692335367203
step: 590, loss: 0.131816565990448
step: 600, loss: 0.06598739326000214
step: 610, loss: 0.023616168648004532
step: 620, loss: 0.05351166054606438
step: 630, loss: 0.0761280283331871
step: 640, loss: 0.02186651900410652
step: 650, loss: 0.02222563698887825
step: 660, loss: 0.06364317238330841
step: 670, loss: 0.0008588107884861529
step: 680, loss: 0.14218561351299286
step: 690, loss: 0.024093886837363243
step: 700, loss: 0.017584562301635742
step: 710, loss: 0.08041369169950485
step: 720, loss: 0.06560317426919937
step: 730, loss: 0.07467924058437347
step: 740, loss: 0.027879344299435616
step: 750, loss: 0.09766268730163574
step: 760, loss: 0.14535725116729736
step: 770, loss: 0.13267886638641357
step: 780, loss: 0.06008545309305191
step: 790, loss: 6.168018444441259e-05
step: 800, loss: 0.047433849424123764
step: 810, loss: 0.11024860292673111
step: 820, loss: 0.10787113010883331
step: 830, loss: 0.0001363195915473625
step: 840, loss: 0.070611372590065
step: 850, loss: 0.0637601688504219
step: 860, loss: 0.027248769998550415
step: 870, loss: 0.018590673804283142
step: 880, loss: 0.08938547223806381
step: 890, loss: 0.0730409100651741
step: 900, loss: 0.04030676558613777
step: 910, loss: 0.03929108381271362
step: 920, loss: 0.07433765381574631
step: 930, loss: 0.07887344062328339
step: 940, loss: 0.06613335758447647
step: 950, loss: 0.04122655838727951
step: 960, loss: 0.07144972681999207
step: 970, loss: 0.05447809398174286
epoch 18: dev_f1=0.9258049463369109, f1=0.9245107176141659, best_f1=0.9362677670793214
step: 0, loss: 0.16097915172576904
step: 10, loss: 0.0007161470712162554
step: 20, loss: 0.03172098472714424
step: 30, loss: 4.8891990445554256e-05
step: 40, loss: 0.0851873904466629
step: 50, loss: 0.1452818512916565
step: 60, loss: 0.08755441009998322
step: 70, loss: 0.02976752072572708
step: 80, loss: 0.041190214455127716
step: 90, loss: 0.00034555757883936167
step: 100, loss: 8.183761383406818e-05
step: 110, loss: 0.03867219388484955
step: 120, loss: 0.050279319286346436
step: 130, loss: 0.03577224165201187
step: 140, loss: 0.10889624804258347
step: 150, loss: 0.02220367081463337
step: 160, loss: 0.028240224346518517
step: 170, loss: 0.05575772747397423
step: 180, loss: 0.018616538494825363
step: 190, loss: 0.04194973409175873
step: 200, loss: 0.04877525568008423
step: 210, loss: 0.05024707689881325
step: 220, loss: 0.012800266034901142
step: 230, loss: 0.0991610437631607
step: 240, loss: 0.02594687044620514
step: 250, loss: 0.0627221092581749
step: 260, loss: 0.02375459112226963
step: 270, loss: 0.08253166824579239
step: 280, loss: 0.10504728555679321
step: 290, loss: 0.10085029900074005
step: 300, loss: 0.08313357830047607
step: 310, loss: 0.022870656102895737
step: 320, loss: 0.058975446969270706
step: 330, loss: 0.053873151540756226
step: 340, loss: 2.2636857465840876e-05
step: 350, loss: 0.11216091364622116
step: 360, loss: 0.012028456665575504
step: 370, loss: 0.053810399025678635
step: 380, loss: 0.09851541370153427
step: 390, loss: 0.017743129283189774
step: 400, loss: 0.1032642275094986
step: 410, loss: 0.038332801312208176
step: 420, loss: 0.053689055144786835
step: 430, loss: 0.050119977444410324
step: 440, loss: 0.06373509019613266
step: 450, loss: 0.10464560240507126
step: 460, loss: 0.07571817189455032
step: 470, loss: 0.05707664415240288
step: 480, loss: 0.046534329652786255
step: 490, loss: 0.07796610891819
step: 500, loss: 0.03510913625359535
step: 510, loss: 0.03160376101732254
step: 520, loss: 0.04239674657583237
step: 530, loss: 0.04697403311729431
step: 540, loss: 0.024172235280275345
step: 550, loss: 0.12564429640769958
step: 560, loss: 0.05522920563817024
step: 570, loss: 0.04105765372514725
step: 580, loss: 0.0018521618330851197
step: 590, loss: 0.109585702419281
step: 600, loss: 0.04462907090783119
step: 610, loss: 0.09847093373537064
step: 620, loss: 0.10711000114679337
step: 630, loss: 0.019069941714406013
step: 640, loss: 0.12832176685333252
step: 650, loss: 0.03248468413949013
step: 660, loss: 0.025991151109337807
step: 670, loss: 0.052875008434057236
step: 680, loss: 0.04337766021490097
step: 690, loss: 0.035308338701725006
step: 700, loss: 0.007774563040584326
step: 710, loss: 0.02947189472615719
step: 720, loss: 0.0445995032787323
step: 730, loss: 0.04568188264966011
step: 740, loss: 0.055895403027534485
step: 750, loss: 6.57897544442676e-05
step: 760, loss: 0.12127133458852768
step: 770, loss: 0.03909584507346153
step: 780, loss: 0.012343484908342361
step: 790, loss: 0.038706809282302856
step: 800, loss: 0.04153052344918251
step: 810, loss: 0.060749929398298264
step: 820, loss: 0.025988876819610596
step: 830, loss: 0.044511210173368454
step: 840, loss: 0.0918310359120369
step: 850, loss: 0.08936794102191925
step: 860, loss: 0.11995439231395721
step: 870, loss: 0.05403776839375496
step: 880, loss: 0.052576858550310135
step: 890, loss: 0.1254730075597763
step: 900, loss: 0.040165919810533524
step: 910, loss: 0.1507035493850708
step: 920, loss: 0.060346025973558426
step: 930, loss: 0.05075232684612274
step: 940, loss: 0.007221398409456015
step: 950, loss: 0.024142155423760414
step: 960, loss: 0.01564926654100418
step: 970, loss: 0.02591877616941929
epoch 19: dev_f1=0.9263746505125815, f1=0.9231485794131347, best_f1=0.9362677670793214
step: 0, loss: 0.036422308534383774
step: 10, loss: 0.05008625611662865
step: 20, loss: 0.08205084502696991
step: 30, loss: 0.05241302773356438
step: 40, loss: 0.10033207386732101
step: 50, loss: 0.056903231889009476
step: 60, loss: 0.03817620500922203
step: 70, loss: 0.08895743638277054
step: 80, loss: 0.07581769675016403
step: 90, loss: 0.05268695205450058
step: 100, loss: 0.012271772138774395
step: 110, loss: 0.053487181663513184
step: 120, loss: 0.04884126037359238
step: 130, loss: 0.04757033288478851
step: 140, loss: 0.06801444292068481
step: 150, loss: 0.018642347306013107
step: 160, loss: 0.020279601216316223
step: 170, loss: 0.16456098854541779
step: 180, loss: 0.036560747772455215
step: 190, loss: 0.056078437715768814
step: 200, loss: 6.013661914039403e-05
step: 210, loss: 0.01858171820640564
step: 220, loss: 0.027219310402870178
step: 230, loss: 0.058129094541072845
step: 240, loss: 0.06274550408124924
step: 250, loss: 0.04974324256181717
step: 260, loss: 0.027971923351287842
step: 270, loss: 0.055718183517456055
step: 280, loss: 0.044217776507139206
step: 290, loss: 0.02759372442960739
step: 300, loss: 0.11705326288938522
step: 310, loss: 0.06180160492658615
step: 320, loss: 0.034128349274396896
step: 330, loss: 0.05310771241784096
step: 340, loss: 0.03190157189965248
step: 350, loss: 0.03615202382206917
step: 360, loss: 0.06797325611114502
step: 370, loss: 0.02161281928420067
step: 380, loss: 0.0455678254365921
step: 390, loss: 0.10239745676517487
step: 400, loss: 0.0756126269698143
step: 410, loss: 0.031935498118400574
step: 420, loss: 0.08571477234363556
step: 430, loss: 0.04730057716369629
step: 440, loss: 0.030875282362103462
step: 450, loss: 0.07417113333940506
step: 460, loss: 0.12361542880535126
step: 470, loss: 0.005926249083131552
step: 480, loss: 0.02206605300307274
step: 490, loss: 0.07298725843429565
step: 500, loss: 4.886286478722468e-05
step: 510, loss: 0.013520622625946999
step: 520, loss: 0.024924922734498978
step: 530, loss: 0.020595164969563484
step: 540, loss: 0.04549289122223854
step: 550, loss: 0.06112481653690338
step: 560, loss: 0.019799845293164253
step: 570, loss: 0.0754496157169342
step: 580, loss: 0.07320254296064377
step: 590, loss: 0.001126654795370996
step: 600, loss: 0.03318547457456589
step: 610, loss: 0.028819583356380463
step: 620, loss: 0.029865475371479988
step: 630, loss: 0.02001119591295719
step: 640, loss: 0.11363451182842255
step: 650, loss: 0.04238287732005119
step: 660, loss: 0.05438114330172539
step: 670, loss: 0.05463520810008049
step: 680, loss: 0.003965048119425774
step: 690, loss: 0.05508584529161453
step: 700, loss: 0.006145621184259653
step: 710, loss: 0.06069226190447807
step: 720, loss: 0.05576816573739052
step: 730, loss: 0.06917381286621094
step: 740, loss: 0.02014475129544735
step: 750, loss: 0.06300076097249985
step: 760, loss: 0.01790238916873932
step: 770, loss: 4.017494939034805e-05
step: 780, loss: 0.026059556752443314
step: 790, loss: 0.04484210163354874
step: 800, loss: 0.03144098073244095
step: 810, loss: 0.016864629462361336
step: 820, loss: 0.03084886446595192
step: 830, loss: 0.0560370497405529
step: 840, loss: 0.041638895869255066
step: 850, loss: 0.03579873964190483
step: 860, loss: 0.09192176163196564
step: 870, loss: 0.11062635481357574
step: 880, loss: 0.004208184313029051
step: 890, loss: 0.0228189155459404
step: 900, loss: 0.059290967881679535
step: 910, loss: 0.014220461249351501
step: 920, loss: 0.059813663363456726
step: 930, loss: 0.030310234054923058
step: 940, loss: 0.08872658759355545
step: 950, loss: 0.04770383611321449
step: 960, loss: 0.07273051142692566
step: 970, loss: 0.030253585427999496
epoch 20: dev_f1=0.9238721804511277, f1=0.924953095684803, best_f1=0.9362677670793214
