cuda
Device: cuda
step: 0, loss: 0.6603316068649292
step: 10, loss: 0.0052613765001297
step: 20, loss: 0.14288635551929474
step: 30, loss: 0.13765312731266022
step: 40, loss: 0.02240726165473461
step: 50, loss: 0.00910427886992693
step: 60, loss: 0.0163637213408947
step: 70, loss: 0.13101142644882202
step: 80, loss: 0.03314846381545067
step: 90, loss: 0.1274019181728363
step: 100, loss: 0.10358678549528122
step: 110, loss: 0.23249036073684692
step: 120, loss: 0.012374126352369785
step: 130, loss: 0.05026537552475929
step: 140, loss: 0.2422802895307541
step: 150, loss: 0.11508717387914658
step: 160, loss: 0.1697912961244583
step: 170, loss: 0.09089293330907822
step: 180, loss: 0.016735650599002838
step: 190, loss: 0.08885322511196136
step: 200, loss: 0.07885001599788666
step: 210, loss: 0.041793279349803925
step: 220, loss: 0.020068582147359848
step: 230, loss: 0.04464906081557274
step: 240, loss: 0.03317892551422119
step: 250, loss: 0.08776044100522995
step: 260, loss: 0.07539963722229004
step: 270, loss: 0.03027363307774067
step: 280, loss: 0.08293911069631577
step: 290, loss: 0.09159116446971893
step: 300, loss: 0.02584918588399887
step: 310, loss: 0.006840780843049288
step: 320, loss: 0.014070762321352959
step: 330, loss: 0.028162114322185516
step: 340, loss: 0.014847858808934689
step: 350, loss: 0.14206771552562714
step: 360, loss: 0.026509013026952744
step: 370, loss: 0.008913030847907066
step: 380, loss: 0.012392607517540455
step: 390, loss: 0.07531462609767914
step: 400, loss: 0.011036301963031292
step: 410, loss: 0.016756758093833923
step: 420, loss: 0.08118908852338791
step: 430, loss: 0.00907810777425766
step: 440, loss: 0.08507877588272095
epoch 1: dev_f1=0.8773062730627306, f1=0.8752276867030966, best_f1=0.8752276867030966
step: 0, loss: 0.008419327437877655
step: 10, loss: 0.1647718995809555
step: 20, loss: 0.04059433192014694
step: 30, loss: 0.034252021461725235
step: 40, loss: 0.0785117819905281
step: 50, loss: 0.013712789863348007
step: 60, loss: 0.01786879263818264
step: 70, loss: 0.01578340493142605
step: 80, loss: 0.016860458999872208
step: 90, loss: 0.021952614188194275
step: 100, loss: 0.008591280318796635
step: 110, loss: 0.17490048706531525
step: 120, loss: 0.023047970607876778
step: 130, loss: 0.008010544814169407
step: 140, loss: 0.02029229886829853
step: 150, loss: 0.07543455809354782
step: 160, loss: 0.13856488466262817
step: 170, loss: 0.17401160299777985
step: 180, loss: 0.09880226850509644
step: 190, loss: 0.008710388094186783
step: 200, loss: 0.09542027860879898
step: 210, loss: 0.01638043113052845
step: 220, loss: 0.020528513938188553
step: 230, loss: 0.006885123904794455
step: 240, loss: 0.028682908043265343
step: 250, loss: 0.024606557562947273
step: 260, loss: 0.021418888121843338
step: 270, loss: 0.018756559118628502
step: 280, loss: 0.01042369194328785
step: 290, loss: 0.0701444149017334
step: 300, loss: 0.11932581663131714
step: 310, loss: 0.01455830316990614
step: 320, loss: 0.17290149629116058
step: 330, loss: 0.027484450489282608
step: 340, loss: 0.12845759093761444
step: 350, loss: 0.020250320434570312
step: 360, loss: 0.03991707041859627
step: 370, loss: 0.025289788842201233
step: 380, loss: 0.013212679885327816
step: 390, loss: 0.025685442611575127
step: 400, loss: 0.056039825081825256
step: 410, loss: 0.018455924466252327
step: 420, loss: 0.012620748952031136
step: 430, loss: 0.16674736142158508
step: 440, loss: 0.004854247439652681
epoch 2: dev_f1=0.864015709376534, f1=0.8437040666340029, best_f1=0.8752276867030966
step: 0, loss: 0.06945390999317169
step: 10, loss: 0.0036236795131117105
step: 20, loss: 0.08360568434000015
step: 30, loss: 0.06448410451412201
step: 40, loss: 0.00230275746434927
step: 50, loss: 0.0437193401157856
step: 60, loss: 0.01060575619339943
step: 70, loss: 0.19244715571403503
step: 80, loss: 0.02601807191967964
step: 90, loss: 0.019167941063642502
step: 100, loss: 0.08980339020490646
step: 110, loss: 0.023702239617705345
step: 120, loss: 0.005696113221347332
step: 130, loss: 0.011975842528045177
step: 140, loss: 0.11713127791881561
step: 150, loss: 0.026262501254677773
step: 160, loss: 0.06529005616903305
step: 170, loss: 0.17658302187919617
step: 180, loss: 0.015878725796937943
step: 190, loss: 0.05292150005698204
step: 200, loss: 0.012167508713901043
step: 210, loss: 0.021843120455741882
step: 220, loss: 0.06734420359134674
step: 230, loss: 0.054966092109680176
step: 240, loss: 0.010165347717702389
step: 250, loss: 0.08555956929922104
step: 260, loss: 0.05616665259003639
step: 270, loss: 0.0034184923861175776
step: 280, loss: 0.07984179258346558
step: 290, loss: 0.030675064772367477
step: 300, loss: 0.020439036190509796
step: 310, loss: 0.01955173909664154
step: 320, loss: 0.14176379144191742
step: 330, loss: 0.07558147609233856
step: 340, loss: 0.06385718286037445
step: 350, loss: 0.02123858965933323
step: 360, loss: 0.03190113604068756
step: 370, loss: 0.02120109461247921
step: 380, loss: 0.05169690400362015
step: 390, loss: 0.09895067662000656
step: 400, loss: 0.15977396070957184
step: 410, loss: 0.016685567796230316
step: 420, loss: 0.1810695379972458
step: 430, loss: 0.03385016322135925
step: 440, loss: 0.0388210266828537
epoch 3: dev_f1=0.8469785575048732, f1=0.8552188552188552, best_f1=0.8752276867030966
step: 0, loss: 0.10049093514680862
step: 10, loss: 0.06318215280771255
step: 20, loss: 0.014651834964752197
step: 30, loss: 0.027704421430826187
step: 40, loss: 0.12402833253145218
step: 50, loss: 0.051075588911771774
step: 60, loss: 0.01432875357568264
step: 70, loss: 0.050608888268470764
step: 80, loss: 0.011420942842960358
step: 90, loss: 0.2802160382270813
step: 100, loss: 0.0130653977394104
step: 110, loss: 0.010111319832503796
step: 120, loss: 0.12963974475860596
step: 130, loss: 0.003006784012541175
step: 140, loss: 0.09346888959407806
step: 150, loss: 0.03616994991898537
step: 160, loss: 0.02455209195613861
step: 170, loss: 0.052691951394081116
step: 180, loss: 0.13017584383487701
step: 190, loss: 0.0766349732875824
step: 200, loss: 0.24236007034778595
step: 210, loss: 0.011304187588393688
step: 220, loss: 0.09247026592493057
step: 230, loss: 0.0025163565296679735
step: 240, loss: 0.10529813915491104
step: 250, loss: 0.018108747899532318
step: 260, loss: 0.017836591228842735
step: 270, loss: 0.04015904664993286
step: 280, loss: 0.027884775772690773
step: 290, loss: 0.013415207155048847
step: 300, loss: 0.07477027177810669
step: 310, loss: 0.07068686187267303
step: 320, loss: 0.06609593331813812
step: 330, loss: 0.057928845286369324
step: 340, loss: 0.08144833892583847
step: 350, loss: 0.15957342088222504
step: 360, loss: 0.038884080946445465
step: 370, loss: 0.09787486493587494
step: 380, loss: 0.0005444947746582329
step: 390, loss: 0.01788169890642166
step: 400, loss: 0.07676251232624054
step: 410, loss: 0.05160205811262131
step: 420, loss: 0.04547474533319473
step: 430, loss: 0.11996438354253769
step: 440, loss: 0.15987327694892883
epoch 4: dev_f1=0.8352561144439318, f1=0.844053678852383, best_f1=0.8752276867030966
step: 0, loss: 0.07828377932310104
step: 10, loss: 0.013092613779008389
step: 20, loss: 0.12034843862056732
step: 30, loss: 0.011030126363039017
step: 40, loss: 0.11141595244407654
step: 50, loss: 0.017311951145529747
step: 60, loss: 0.03431408479809761
step: 70, loss: 0.0808260440826416
step: 80, loss: 0.03626487776637077
step: 90, loss: 0.02929566241800785
step: 100, loss: 0.03999378904700279
step: 110, loss: 0.056400593370199203
step: 120, loss: 0.0166713185608387
step: 130, loss: 0.06087654456496239
step: 140, loss: 0.03397027403116226
step: 150, loss: 0.03701881319284439
step: 160, loss: 0.04402931034564972
step: 170, loss: 0.02216717042028904
step: 180, loss: 0.08404134213924408
step: 190, loss: 0.024037247523665428
step: 200, loss: 0.012001961469650269
step: 210, loss: 0.0015235329046845436
step: 220, loss: 0.02958451770246029
step: 230, loss: 0.01914496347308159
step: 240, loss: 0.03785986453294754
step: 250, loss: 0.01535540260374546
step: 260, loss: 0.11006419360637665
step: 270, loss: 0.035370517522096634
step: 280, loss: 0.03955409303307533
step: 290, loss: 0.007459747605025768
step: 300, loss: 0.0003036692796740681
step: 310, loss: 0.020265987142920494
step: 320, loss: 0.02053399570286274
step: 330, loss: 7.482168439310044e-05
step: 340, loss: 0.013749879784882069
step: 350, loss: 0.06352541595697403
step: 360, loss: 0.06816494464874268
step: 370, loss: 0.0149298757314682
step: 380, loss: 0.16701458394527435
step: 390, loss: 0.03883363679051399
step: 400, loss: 0.01746429316699505
step: 410, loss: 0.026848843321204185
step: 420, loss: 0.034564144909381866
step: 430, loss: 0.05579919368028641
step: 440, loss: 0.02232966385781765
epoch 5: dev_f1=0.7023255813953488, f1=0.7153536515238642, best_f1=0.8752276867030966
step: 0, loss: 0.0012246706755831838
step: 10, loss: 0.041041579097509384
step: 20, loss: 0.056302260607481
step: 30, loss: 0.03630809113383293
step: 40, loss: 0.07554035633802414
step: 50, loss: 0.09595651179552078
step: 60, loss: 0.012803918682038784
step: 70, loss: 0.011145380325615406
step: 80, loss: 0.02179250307381153
step: 90, loss: 0.003845636500045657
step: 100, loss: 0.04837861657142639
step: 110, loss: 0.046876903623342514
step: 120, loss: 0.09612519294023514
step: 130, loss: 0.017970982939004898
step: 140, loss: 0.060074582695961
step: 150, loss: 0.0001666126772761345
step: 160, loss: 0.28805631399154663
step: 170, loss: 0.00199191365391016
step: 180, loss: 0.08811583369970322
step: 190, loss: 0.021974463015794754
step: 200, loss: 0.0215609073638916
step: 210, loss: 0.01729089766740799
step: 220, loss: 0.06898815184831619
step: 230, loss: 0.015731213614344597
step: 240, loss: 0.026261448860168457
step: 250, loss: 0.02442237176001072
step: 260, loss: 0.03392990306019783
step: 270, loss: 0.21203096210956573
step: 280, loss: 0.003920847084373236
step: 290, loss: 0.0009581816848367453
step: 300, loss: 0.0016651622718200088
step: 310, loss: 0.013641711324453354
step: 320, loss: 0.08267475664615631
step: 330, loss: 0.10275479406118393
step: 340, loss: 0.03268682584166527
step: 350, loss: 0.0986478254199028
step: 360, loss: 0.004799869377166033
step: 370, loss: 0.0002666844520717859
step: 380, loss: 0.11183010041713715
step: 390, loss: 0.0030700138304382563
step: 400, loss: 0.0825844556093216
step: 410, loss: 0.0935739055275917
step: 420, loss: 0.10306956619024277
step: 430, loss: 0.06647289544343948
step: 440, loss: 0.01029878668487072
epoch 6: dev_f1=0.6464771322620518, f1=0.6391116594694632, best_f1=0.8752276867030966
step: 0, loss: 0.04566338658332825
step: 10, loss: 0.07487159222364426
step: 20, loss: 0.0006161246565170586
step: 30, loss: 0.026941344141960144
step: 40, loss: 0.052098698914051056
step: 50, loss: 0.14609470963478088
step: 60, loss: 0.015870114788413048
step: 70, loss: 0.028866125270724297
step: 80, loss: 0.001184927299618721
step: 90, loss: 0.011427262797951698
step: 100, loss: 0.013192495331168175
step: 110, loss: 0.04447739198803902
step: 120, loss: 0.0002879264357034117
step: 130, loss: 0.0015290484298020601
step: 140, loss: 0.03540640324354172
step: 150, loss: 0.03232830390334129
step: 160, loss: 0.05281146243214607
step: 170, loss: 0.05662388727068901
step: 180, loss: 0.020387452095746994
step: 190, loss: 0.04976658150553703
step: 200, loss: 0.08803271502256393
step: 210, loss: 0.08067210018634796
step: 220, loss: 0.0724935308098793
step: 230, loss: 0.0015212970320135355
step: 240, loss: 0.07617653906345367
step: 250, loss: 0.035745054483413696
step: 260, loss: 0.02428414113819599
step: 270, loss: 0.030494121834635735
step: 280, loss: 0.037449903786182404
step: 290, loss: 0.010082184337079525
step: 300, loss: 0.0034188725985586643
step: 310, loss: 0.03552817180752754
step: 320, loss: 0.0022480213083326817
step: 330, loss: 0.0001816350850276649
step: 340, loss: 0.012484249658882618
step: 350, loss: 0.0108703738078475
step: 360, loss: 0.01743544265627861
step: 370, loss: 3.933078914997168e-05
step: 380, loss: 0.00849540252238512
step: 390, loss: 0.009524303488433361
step: 400, loss: 0.09070401638746262
step: 410, loss: 0.014742150902748108
step: 420, loss: 0.10897213220596313
step: 430, loss: 0.08830630779266357
step: 440, loss: 0.023579295724630356
epoch 7: dev_f1=0.5126799177518849, f1=0.5307224848075626, best_f1=0.8752276867030966
step: 0, loss: 0.006974837742745876
step: 10, loss: 0.003190263407304883
step: 20, loss: 9.290652815252542e-05
step: 30, loss: 0.02944936417043209
step: 40, loss: 0.01665128767490387
step: 50, loss: 0.031336572021245956
step: 60, loss: 0.013483578339219093
step: 70, loss: 0.009893206879496574
step: 80, loss: 0.07956698536872864
step: 90, loss: 0.00964840967208147
step: 100, loss: 0.011154508218169212
step: 110, loss: 0.001226903055794537
step: 120, loss: 0.001696211053058505
step: 130, loss: 0.015784790739417076
step: 140, loss: 0.014188977889716625
step: 150, loss: 0.10611802339553833
step: 160, loss: 0.0191971343010664
step: 170, loss: 0.021867185831069946
step: 180, loss: 0.0036463183350861073
step: 190, loss: 0.04555720090866089
step: 200, loss: 0.020388362929224968
step: 210, loss: 0.023617826402187347
step: 220, loss: 0.027201218530535698
step: 230, loss: 0.004469680599868298
step: 240, loss: 0.012892661616206169
step: 250, loss: 0.041887443512678146
step: 260, loss: 0.05376622453331947
step: 270, loss: 0.0014116185484454036
step: 280, loss: 0.0011634775437414646
step: 290, loss: 0.007877601310610771
step: 300, loss: 0.00792699959129095
step: 310, loss: 0.024150792509317398
step: 320, loss: 0.0166646596044302
step: 330, loss: 0.024884136393666267
step: 340, loss: 0.0001557348296046257
step: 350, loss: 0.07096923887729645
step: 360, loss: 0.003252710448578
step: 370, loss: 0.04753711074590683
step: 380, loss: 0.09854630380868912
step: 390, loss: 0.005349068436771631
step: 400, loss: 0.04903827980160713
step: 410, loss: 0.007002487778663635
step: 420, loss: 0.03444530814886093
step: 430, loss: 0.03120534121990204
step: 440, loss: 0.01273046713322401
epoch 8: dev_f1=0.6766467065868262, f1=0.661904761904762, best_f1=0.8752276867030966
step: 0, loss: 0.004019765183329582
step: 10, loss: 0.07606419920921326
step: 20, loss: 0.008006436750292778
step: 30, loss: 0.010929192416369915
step: 40, loss: 0.08611378073692322
step: 50, loss: 0.0009432838414795697
step: 60, loss: 0.0611053965985775
step: 70, loss: 0.006907516624778509
step: 80, loss: 0.04855932667851448
step: 90, loss: 0.003102782880887389
step: 100, loss: 3.5765013308264315e-05
step: 110, loss: 0.04625137150287628
step: 120, loss: 0.0012813882203772664
step: 130, loss: 0.0005294003058224916
step: 140, loss: 0.05447414517402649
step: 150, loss: 0.00031169026624411345
step: 160, loss: 0.06040704622864723
step: 170, loss: 0.00186835415661335
step: 180, loss: 0.010245904326438904
step: 190, loss: 0.06609131395816803
step: 200, loss: 0.007145036943256855
step: 210, loss: 0.10409511625766754
step: 220, loss: 0.002056924859061837
step: 230, loss: 0.008403165265917778
step: 240, loss: 0.006289081647992134
step: 250, loss: 0.025397805497050285
step: 260, loss: 0.008419917896389961
step: 270, loss: 0.0032478547655045986
step: 280, loss: 0.006680369842797518
step: 290, loss: 0.00020369107369333506
step: 300, loss: 0.17016462981700897
step: 310, loss: 0.044989027082920074
step: 320, loss: 0.026473844423890114
step: 330, loss: 0.10121054202318192
step: 340, loss: 0.020364796742796898
step: 350, loss: 0.00032298266887664795
step: 360, loss: 0.03926381096243858
step: 370, loss: 0.01675264537334442
step: 380, loss: 0.037787679582834244
step: 390, loss: 0.02779088355600834
step: 400, loss: 0.021452991291880608
step: 410, loss: 0.0009177135652862489
step: 420, loss: 0.01823503151535988
step: 430, loss: 0.022197851911187172
step: 440, loss: 0.0001830932596931234
epoch 9: dev_f1=0.6053299492385787, f1=0.6053299492385787, best_f1=0.8752276867030966
step: 0, loss: 0.017984941601753235
step: 10, loss: 0.0032033207826316357
step: 20, loss: 0.08283434063196182
step: 30, loss: 0.10723035782575607
step: 40, loss: 0.09628380835056305
step: 50, loss: 0.013667256571352482
step: 60, loss: 0.0002435435017105192
step: 70, loss: 0.005327621940523386
step: 80, loss: 0.04079645499587059
step: 90, loss: 0.04987597465515137
step: 100, loss: 0.026809372007846832
step: 110, loss: 0.01273820549249649
step: 120, loss: 0.04497973620891571
step: 130, loss: 5.8429250202607363e-05
step: 140, loss: 5.6827295338734984e-05
step: 150, loss: 0.0001265636383322999
step: 160, loss: 0.06900425255298615
step: 170, loss: 0.00945883709937334
step: 180, loss: 0.060283876955509186
step: 190, loss: 0.0421474389731884
step: 200, loss: 3.6230485420674086e-05
step: 210, loss: 0.00012543326010927558
step: 220, loss: 0.008219379931688309
step: 230, loss: 0.008812899701297283
step: 240, loss: 0.009171904064714909
step: 250, loss: 3.914426633855328e-05
step: 260, loss: 1.837294257711619e-05
step: 270, loss: 0.0007649098988622427
step: 280, loss: 3.4613945899764076e-05
step: 290, loss: 0.0012298272922635078
step: 300, loss: 0.027749260887503624
step: 310, loss: 0.042701356112957
step: 320, loss: 0.16728852689266205
step: 330, loss: 0.0001862590725068003
step: 340, loss: 0.043420884758234024
step: 350, loss: 0.025786368176341057
step: 360, loss: 0.0002319048799108714
step: 370, loss: 0.006717314012348652
step: 380, loss: 0.07695867121219635
step: 390, loss: 0.0003529927635099739
step: 400, loss: 0.0003674703184515238
step: 410, loss: 0.07085481286048889
step: 420, loss: 0.007365678437054157
step: 430, loss: 0.07482055574655533
step: 440, loss: 0.013606428168714046
epoch 10: dev_f1=0.6785714285714285, f1=0.6706091070372561, best_f1=0.8752276867030966
step: 0, loss: 0.014363005757331848
step: 10, loss: 0.00012332831101957709
step: 20, loss: 0.00033965823240578175
step: 30, loss: 0.1015779972076416
step: 40, loss: 0.0024724833201617002
step: 50, loss: 0.03630468249320984
step: 60, loss: 0.0237816721200943
step: 70, loss: 0.014371518045663834
step: 80, loss: 0.00743997935205698
step: 90, loss: 0.0001156544967670925
step: 100, loss: 0.00030531021184287965
step: 110, loss: 0.05110746622085571
step: 120, loss: 0.0934235081076622
step: 130, loss: 0.04374159872531891
step: 140, loss: 0.12018254399299622
step: 150, loss: 5.5225427786353976e-05
step: 160, loss: 0.05093618109822273
step: 170, loss: 0.007370704784989357
step: 180, loss: 0.02329443208873272
step: 190, loss: 0.004614262841641903
step: 200, loss: 0.05988728255033493
step: 210, loss: 0.010497416369616985
step: 220, loss: 0.021183181554079056
step: 230, loss: 0.03409978747367859
step: 240, loss: 0.00156682962551713
step: 250, loss: 0.03264271467924118
step: 260, loss: 0.02823796682059765
step: 270, loss: 0.012667289935052395
step: 280, loss: 0.026638897135853767
step: 290, loss: 0.0003162151260767132
step: 300, loss: 0.035075973719358444
step: 310, loss: 0.004771507810801268
step: 320, loss: 3.443161040195264e-05
step: 330, loss: 2.4407656383118592e-05
step: 340, loss: 8.81521773408167e-05
step: 350, loss: 0.01659070886671543
step: 360, loss: 0.05990152060985565
step: 370, loss: 0.05316156521439552
step: 380, loss: 0.005503174848854542
step: 390, loss: 3.893372922902927e-05
step: 400, loss: 0.04350145906209946
step: 410, loss: 0.003670961130410433
step: 420, loss: 0.001076654763892293
step: 430, loss: 0.012292003259062767
step: 440, loss: 0.017260735854506493
epoch 11: dev_f1=0.5659881812212738, f1=0.5635648754914809, best_f1=0.8752276867030966
step: 0, loss: 0.0020025058183819056
step: 10, loss: 0.059612423181533813
step: 20, loss: 0.02048415318131447
step: 30, loss: 0.00616283668205142
step: 40, loss: 0.034030549228191376
step: 50, loss: 0.014486171305179596
step: 60, loss: 5.59281324967742e-05
step: 70, loss: 0.00031248488812707365
step: 80, loss: 0.00010410883987788111
step: 90, loss: 2.3677348508499563e-05
step: 100, loss: 0.00010419981845188886
step: 110, loss: 0.005258644465357065
step: 120, loss: 0.026846179738640785
step: 130, loss: 0.0021301081869751215
step: 140, loss: 0.008471813052892685
step: 150, loss: 0.009368632920086384
step: 160, loss: 0.006846518721431494
step: 170, loss: 0.10330209881067276
step: 180, loss: 0.07703689485788345
step: 190, loss: 0.009862462058663368
step: 200, loss: 0.0071116345934569836
step: 210, loss: 0.05963076278567314
step: 220, loss: 0.0515705868601799
step: 230, loss: 0.03672998771071434
step: 240, loss: 1.948670978890732e-05
step: 250, loss: 0.016497645527124405
step: 260, loss: 0.05682354420423508
step: 270, loss: 2.8481083063525148e-05
step: 280, loss: 0.10326708853244781
step: 290, loss: 0.005436611827462912
step: 300, loss: 0.0007147122523747385
step: 310, loss: 0.010562349110841751
step: 320, loss: 0.008401698432862759
step: 330, loss: 0.006255274172872305
step: 340, loss: 0.020242221653461456
step: 350, loss: 0.037899136543273926
step: 360, loss: 2.832578684319742e-05
step: 370, loss: 0.07273160666227341
step: 380, loss: 4.654255826608278e-05
step: 390, loss: 0.00016027939273044467
step: 400, loss: 0.031046230345964432
step: 410, loss: 0.12932363152503967
step: 420, loss: 0.10129650682210922
step: 430, loss: 0.058481115847826004
step: 440, loss: 0.018488915637135506
epoch 12: dev_f1=0.5098572399728076, f1=0.5369753497668222, best_f1=0.8752276867030966
step: 0, loss: 0.015153981745243073
step: 10, loss: 0.04450010135769844
step: 20, loss: 0.0031471136026084423
step: 30, loss: 0.017570078372955322
step: 40, loss: 0.007021455094218254
step: 50, loss: 0.0006153872818686068
step: 60, loss: 0.003801184007897973
step: 70, loss: 0.08391232788562775
step: 80, loss: 0.0747363492846489
step: 90, loss: 3.660247602965683e-05
step: 100, loss: 0.004136339761316776
step: 110, loss: 0.01248177420347929
step: 120, loss: 0.0035078427754342556
step: 130, loss: 8.680999599164352e-05
step: 140, loss: 2.02762948902091e-05
step: 150, loss: 0.0020006070844829082
step: 160, loss: 0.023378973826766014
step: 170, loss: 0.026370232924818993
step: 180, loss: 0.040198180824518204
step: 190, loss: 0.004376780241727829
step: 200, loss: 8.486495062243193e-05
step: 210, loss: 0.001598126022145152
step: 220, loss: 2.9278544388944283e-05
step: 230, loss: 3.512252078508027e-05
step: 240, loss: 0.03410087525844574
step: 250, loss: 0.027088038623332977
step: 260, loss: 0.002020875457674265
step: 270, loss: 0.01807863637804985
step: 280, loss: 0.002065248554572463
step: 290, loss: 0.10022298991680145
step: 300, loss: 0.08174954354763031
step: 310, loss: 0.0009822583524510264
step: 320, loss: 0.0003096144355367869
step: 330, loss: 0.007596712093800306
step: 340, loss: 0.0029304479248821735
step: 350, loss: 0.021038269624114037
step: 360, loss: 5.117366526974365e-05
step: 370, loss: 0.00010093302989844233
step: 380, loss: 0.013371463865041733
step: 390, loss: 0.002587068360298872
step: 400, loss: 0.014553128741681576
step: 410, loss: 0.005252657923847437
step: 420, loss: 3.422303052502684e-05
step: 430, loss: 0.00018307333812117577
step: 440, loss: 6.255975313251838e-05
epoch 13: dev_f1=0.4026646928201333, f1=0.40356083086053407, best_f1=0.8752276867030966
step: 0, loss: 0.05174968019127846
step: 10, loss: 2.6448415155755356e-05
step: 20, loss: 3.292887413408607e-05
step: 30, loss: 0.0011578183621168137
step: 40, loss: 0.0001880772178992629
step: 50, loss: 0.012736412696540356
step: 60, loss: 1.3228415809862781e-05
step: 70, loss: 0.07092554122209549
step: 80, loss: 0.004816925153136253
step: 90, loss: 0.0011014685733243823
step: 100, loss: 0.01711602322757244
step: 110, loss: 0.0001249316119356081
step: 120, loss: 3.730491880560294e-05
step: 130, loss: 0.003161999164149165
step: 140, loss: 0.007855391129851341
step: 150, loss: 0.016722528263926506
step: 160, loss: 0.0026022796519100666
step: 170, loss: 0.0001605758152436465
step: 180, loss: 0.013775553554296494
step: 190, loss: 0.008115466684103012
step: 200, loss: 3.122290218016133e-05
step: 210, loss: 0.00640019541606307
step: 220, loss: 0.004869283176958561
step: 230, loss: 0.023286767303943634
step: 240, loss: 0.013741794973611832
step: 250, loss: 1.652519677008968e-05
step: 260, loss: 0.00013547348498832434
step: 270, loss: 0.00011074679059674963
step: 280, loss: 0.03931533917784691
step: 290, loss: 0.001777028781361878
step: 300, loss: 2.341626532142982e-05
step: 310, loss: 1.963563590834383e-05
step: 320, loss: 0.0006687716813758016
step: 330, loss: 0.004563711117953062
step: 340, loss: 1.4956916857045144e-05
step: 350, loss: 0.0307823047041893
step: 360, loss: 0.05829774588346481
step: 370, loss: 0.0029043781105428934
step: 380, loss: 0.00689468951895833
step: 390, loss: 2.1594707504846156e-05
step: 400, loss: 0.060654692351818085
step: 410, loss: 0.019792599603533745
step: 420, loss: 0.09347330033779144
step: 430, loss: 0.00531504163518548
step: 440, loss: 0.06264019012451172
epoch 14: dev_f1=0.5966921119592874, f1=0.6005056890012642, best_f1=0.8752276867030966
step: 0, loss: 0.00016634856001473963
step: 10, loss: 0.008768357336521149
step: 20, loss: 0.00036091188667342067
step: 30, loss: 0.003116618376225233
step: 40, loss: 1.5023973901406862e-05
step: 50, loss: 0.010050732642412186
step: 60, loss: 0.031061239540576935
step: 70, loss: 2.7159749151906e-05
step: 80, loss: 1.6208592569455504e-05
step: 90, loss: 0.001210496760904789
step: 100, loss: 0.05730447918176651
step: 110, loss: 0.009263153187930584
step: 120, loss: 0.0014908818993717432
step: 130, loss: 0.012771399691700935
step: 140, loss: 4.0431674278806895e-05
step: 150, loss: 0.0034081421326845884
step: 160, loss: 0.056245289742946625
step: 170, loss: 0.04132548347115517
step: 180, loss: 0.0021264255046844482
step: 190, loss: 0.006784845143556595
step: 200, loss: 0.002859787316992879
step: 210, loss: 0.004754654597491026
step: 220, loss: 0.008084564469754696
step: 230, loss: 0.04606058448553085
step: 240, loss: 0.00034444453194737434
step: 250, loss: 0.019940944388508797
step: 260, loss: 0.148997962474823
step: 270, loss: 0.006042529828846455
step: 280, loss: 2.937239878519904e-05
step: 290, loss: 0.012818732298910618
step: 300, loss: 0.033013056963682175
step: 310, loss: 7.73774809204042e-05
step: 320, loss: 0.03832582011818886
step: 330, loss: 0.00021222667419351637
step: 340, loss: 0.00236986530944705
step: 350, loss: 0.03553612902760506
step: 360, loss: 0.10384766757488251
step: 370, loss: 0.020819557830691338
step: 380, loss: 1.949009674717672e-05
step: 390, loss: 1.5292125681298785e-05
step: 400, loss: 0.0006732177571393549
step: 410, loss: 0.019155845046043396
step: 420, loss: 3.841449142782949e-05
step: 430, loss: 0.00018139398889616132
step: 440, loss: 0.064947210252285
epoch 15: dev_f1=0.5429141716566867, f1=0.5561426684280053, best_f1=0.8752276867030966
step: 0, loss: 0.020592449232935905
step: 10, loss: 0.0004846423107665032
step: 20, loss: 0.005217753350734711
step: 30, loss: 0.00025763578014448285
step: 40, loss: 0.020427703857421875
step: 50, loss: 0.0008028916199691594
step: 60, loss: 0.0522160641849041
step: 70, loss: 0.0010354863479733467
step: 80, loss: 0.0022819035220891237
step: 90, loss: 0.055836375802755356
step: 100, loss: 1.45357807923574e-05
step: 110, loss: 0.08005981147289276
step: 120, loss: 0.029440514743328094
step: 130, loss: 0.003167329356074333
step: 140, loss: 0.03859228268265724
step: 150, loss: 0.021647294983267784
step: 160, loss: 3.961326365242712e-05
step: 170, loss: 0.0011434429325163364
step: 180, loss: 0.03415575623512268
step: 190, loss: 4.4972108298679814e-05
step: 200, loss: 0.009945604018867016
step: 210, loss: 0.0011053570779040456
step: 220, loss: 0.015534693375229836
step: 230, loss: 0.029116548597812653
step: 240, loss: 0.028614917770028114
step: 250, loss: 0.0006555864820256829
step: 260, loss: 0.0006771450862288475
step: 270, loss: 0.01000388152897358
step: 280, loss: 0.01419058721512556
step: 290, loss: 0.019880510866642
step: 300, loss: 0.033634837716817856
step: 310, loss: 4.9064452468883246e-05
step: 320, loss: 0.04519495368003845
step: 330, loss: 0.0018543183105066419
step: 340, loss: 0.0020459520164877176
step: 350, loss: 0.018947748467326164
step: 360, loss: 0.0017006939742714167
step: 370, loss: 0.000352893810486421
step: 380, loss: 0.00037651584716513753
step: 390, loss: 1.5873118172748946e-05
step: 400, loss: 1.0818178452609573e-05
step: 410, loss: 0.029635624960064888
step: 420, loss: 1.700170469121076e-05
step: 430, loss: 0.00912318006157875
step: 440, loss: 1.8353834093431942e-05
epoch 16: dev_f1=0.4436468054558507, f1=0.4599006387508872, best_f1=0.8752276867030966
step: 0, loss: 0.005585814826190472
step: 10, loss: 0.0007134944899007678
step: 20, loss: 0.041910573840141296
step: 30, loss: 0.00038473395397886634
step: 40, loss: 5.19817513122689e-05
step: 50, loss: 0.00026676966808736324
step: 60, loss: 0.011590921320021152
step: 70, loss: 0.00021636654855683446
step: 80, loss: 0.013591600582003593
step: 90, loss: 1.3377406503423117e-05
step: 100, loss: 0.0006664026877842844
step: 110, loss: 0.028270483016967773
step: 120, loss: 0.01608012244105339
step: 130, loss: 3.1913801649352536e-05
step: 140, loss: 0.01900925673544407
step: 150, loss: 0.00043687925790436566
step: 160, loss: 0.00047559975064359605
step: 170, loss: 0.0003080307797063142
step: 180, loss: 2.4842456696205772e-05
step: 190, loss: 0.009373032487928867
step: 200, loss: 4.415631701704115e-05
step: 210, loss: 0.0013010986149311066
step: 220, loss: 0.0024785466957837343
step: 230, loss: 0.003830139758065343
step: 240, loss: 1.0382326763647143e-05
step: 250, loss: 0.000207630917429924
step: 260, loss: 0.0005215120036154985
step: 270, loss: 0.03403587266802788
step: 280, loss: 0.00022510088456328958
step: 290, loss: 0.04552686586976051
step: 300, loss: 1.8860480849980377e-05
step: 310, loss: 0.014706031419336796
step: 320, loss: 0.0014396226033568382
step: 330, loss: 0.013080475851893425
step: 340, loss: 0.001161513035185635
step: 350, loss: 4.033769073430449e-05
step: 360, loss: 1.887155849544797e-05
step: 370, loss: 2.4023267542361282e-05
step: 380, loss: 0.04111840948462486
step: 390, loss: 2.9128977985237725e-05
step: 400, loss: 0.02672736532986164
step: 410, loss: 0.0037244625855237246
step: 420, loss: 0.021092401817440987
step: 430, loss: 1.7344671505270526e-05
step: 440, loss: 0.00013339886208996177
epoch 17: dev_f1=0.4450825556353194, f1=0.4620836286321757, best_f1=0.8752276867030966
step: 0, loss: 1.5768802768434398e-05
step: 10, loss: 0.017341751605272293
step: 20, loss: 0.06858394294977188
step: 30, loss: 1.4848676073597744e-05
step: 40, loss: 0.008855345658957958
step: 50, loss: 0.09003230929374695
step: 60, loss: 0.03535079583525658
step: 70, loss: 0.00026397494366392493
step: 80, loss: 0.001497922115959227
step: 90, loss: 0.0015422177966684103
step: 100, loss: 0.0005041522672399879
step: 110, loss: 0.0025975198950618505
step: 120, loss: 0.00135752372443676
step: 130, loss: 0.005393938161432743
step: 140, loss: 0.01572973094880581
step: 150, loss: 0.0010567792924121022
step: 160, loss: 0.043120868504047394
step: 170, loss: 1.2621179848792963e-05
step: 180, loss: 7.329822255996987e-05
step: 190, loss: 0.0006158349569886923
step: 200, loss: 0.19782409071922302
step: 210, loss: 0.0010191923938691616
step: 220, loss: 0.014272601343691349
step: 230, loss: 0.00035122421104460955
step: 240, loss: 0.022124089300632477
step: 250, loss: 0.0012150196125730872
step: 260, loss: 2.6699262889451347e-05
step: 270, loss: 0.001195415505208075
step: 280, loss: 0.0013000865001231432
step: 290, loss: 9.738442167872563e-05
step: 300, loss: 4.7433168219868094e-05
step: 310, loss: 0.0008515052031725645
step: 320, loss: 0.0039028162136673927
step: 330, loss: 1.0937381375697441e-05
step: 340, loss: 0.010823777876794338
step: 350, loss: 9.499440238869283e-06
step: 360, loss: 0.000561950437258929
step: 370, loss: 0.002417653566226363
step: 380, loss: 0.036056701093912125
step: 390, loss: 0.029424462467432022
step: 400, loss: 1.5984720448614098e-05
step: 410, loss: 0.008482558652758598
step: 420, loss: 0.0198273453861475
step: 430, loss: 0.0008302813512273133
step: 440, loss: 0.005660274997353554
epoch 18: dev_f1=0.4667609618104667, f1=0.4765897973445143, best_f1=0.8752276867030966
step: 0, loss: 1.9169818187947385e-05
step: 10, loss: 0.03113396279513836
step: 20, loss: 0.0014689108356833458
step: 30, loss: 3.2771607948234305e-05
step: 40, loss: 0.03306445851922035
step: 50, loss: 0.0025849947705864906
step: 60, loss: 0.0713852271437645
step: 70, loss: 1.2434868949640077e-05
step: 80, loss: 0.022904902696609497
step: 90, loss: 0.01328760664910078
step: 100, loss: 1.6036812667152844e-05
step: 110, loss: 0.023473279550671577
step: 120, loss: 0.00045913245412521064
step: 130, loss: 1.0613291124172974e-05
step: 140, loss: 0.000492004444822669
step: 150, loss: 0.007825681939721107
step: 160, loss: 0.00019432647968642414
step: 170, loss: 0.0004735873662866652
step: 180, loss: 3.5806595406029373e-05
step: 190, loss: 0.018311915919184685
step: 200, loss: 0.07656385004520416
step: 210, loss: 9.767656592885032e-06
step: 220, loss: 0.0192892923951149
step: 230, loss: 1.2446063010429498e-05
step: 240, loss: 0.005644103977829218
step: 250, loss: 0.0007637854432687163
step: 260, loss: 1.2770064131473191e-05
step: 270, loss: 0.0007854190771467984
step: 280, loss: 0.05676521360874176
step: 290, loss: 1.1920817087229807e-05
step: 300, loss: 0.00014058132364880294
step: 310, loss: 9.413127554580569e-05
step: 320, loss: 0.025579404085874557
step: 330, loss: 1.2632319339900278e-05
step: 340, loss: 0.000875060330145061
step: 350, loss: 0.0003237798227928579
step: 360, loss: 0.003881277982145548
step: 370, loss: 0.023412533104419708
step: 380, loss: 0.03735312446951866
step: 390, loss: 4.216768138576299e-05
step: 400, loss: 0.05427566543221474
step: 410, loss: 0.026071472093462944
step: 420, loss: 0.057073723524808884
step: 430, loss: 1.922510637086816e-05
step: 440, loss: 0.000702780089341104
epoch 19: dev_f1=0.4817927170868348, f1=0.4927536231884057, best_f1=0.8752276867030966
step: 0, loss: 0.031878769397735596
step: 10, loss: 0.00024275481700897217
step: 20, loss: 0.013405237346887589
step: 30, loss: 4.148462903685868e-05
step: 40, loss: 0.025872590020298958
step: 50, loss: 8.136615360854194e-05
step: 60, loss: 0.00034767130273394287
step: 70, loss: 1.9515357053023763e-05
step: 80, loss: 0.001609697239473462
step: 90, loss: 0.049114931374788284
step: 100, loss: 0.000532305974047631
step: 110, loss: 0.0010193759808316827
step: 120, loss: 1.5180224181676749e-05
step: 130, loss: 0.026309294626116753
step: 140, loss: 0.0326753705739975
step: 150, loss: 0.025803960859775543
step: 160, loss: 0.023066841065883636
step: 170, loss: 0.03242148086428642
step: 180, loss: 0.00044463403173722327
step: 190, loss: 1.9630815586424433e-05
step: 200, loss: 0.002029909985139966
step: 210, loss: 1.2751482245221268e-05
step: 220, loss: 0.0008106108289211988
step: 230, loss: 3.673989704111591e-05
step: 240, loss: 0.022447530180215836
step: 250, loss: 1.9548539057723247e-05
step: 260, loss: 0.032280080020427704
step: 270, loss: 0.0005174402613192797
step: 280, loss: 0.0002734040026552975
step: 290, loss: 1.3679033145308495e-05
step: 300, loss: 0.006497228983789682
step: 310, loss: 0.011332428082823753
step: 320, loss: 0.023814862594008446
step: 330, loss: 0.00015494211402256042
step: 340, loss: 0.023674387484788895
step: 350, loss: 0.012643711641430855
step: 360, loss: 0.004154919646680355
step: 370, loss: 0.00019250503100920469
step: 380, loss: 1.41782265927759e-05
step: 390, loss: 1.6480022168252617e-05
step: 400, loss: 5.18248816661071e-05
step: 410, loss: 0.0010835288558155298
step: 420, loss: 8.709688700037077e-06
step: 430, loss: 0.012876131571829319
step: 440, loss: 0.023945894092321396
epoch 20: dev_f1=0.47752808988764045, f1=0.49239280774550487, best_f1=0.8752276867030966
