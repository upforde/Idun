cuda
Device: cuda
step: 0, loss: 0.6337053775787354
step: 10, loss: 0.24109692871570587
step: 20, loss: 0.5173831582069397
step: 30, loss: 0.2966287434101105
step: 40, loss: 0.26187223196029663
step: 50, loss: 0.14135976135730743
step: 60, loss: 0.31666862964630127
step: 70, loss: 0.19152818620204926
step: 80, loss: 0.23048505187034607
step: 90, loss: 0.2274572104215622
step: 100, loss: 0.15802860260009766
step: 110, loss: 0.2079380750656128
step: 120, loss: 0.1129530519247055
step: 130, loss: 0.2410215139389038
step: 140, loss: 0.11251504719257355
step: 150, loss: 0.10726498067378998
step: 160, loss: 0.19635438919067383
step: 170, loss: 0.09225659817457199
step: 180, loss: 0.06646139174699783
step: 190, loss: 0.22538575530052185
step: 200, loss: 0.11017446964979172
step: 210, loss: 0.14952825009822845
step: 220, loss: 0.09160313010215759
step: 230, loss: 0.2438431978225708
step: 240, loss: 0.10598122328519821
step: 250, loss: 0.15824711322784424
step: 260, loss: 0.14385098218917847
step: 270, loss: 0.14294105768203735
step: 280, loss: 0.16321440041065216
step: 290, loss: 0.07542505860328674
step: 300, loss: 0.1688460409641266
step: 310, loss: 0.18058690428733826
step: 320, loss: 0.09065816551446915
step: 330, loss: 0.12969130277633667
step: 340, loss: 0.10823682695627213
step: 350, loss: 0.06536632776260376
step: 360, loss: 0.1243550106883049
step: 370, loss: 0.15045353770256042
step: 380, loss: 0.13182051479816437
step: 390, loss: 0.07811395823955536
step: 400, loss: 0.19109171628952026
step: 410, loss: 0.05866774171590805
step: 420, loss: 0.30126237869262695
step: 430, loss: 0.11251918226480484
step: 440, loss: 0.13625314831733704
step: 450, loss: 0.19338864088058472
step: 460, loss: 0.05930788442492485
step: 470, loss: 0.14979273080825806
step: 480, loss: 0.07658310979604721
step: 490, loss: 0.0906309187412262
step: 500, loss: 0.10241138935089111
step: 510, loss: 0.10387323051691055
step: 520, loss: 0.09157609194517136
step: 530, loss: 0.13457533717155457
step: 540, loss: 0.09017447382211685
step: 550, loss: 0.16526643931865692
step: 560, loss: 0.11470957100391388
step: 570, loss: 0.1597737818956375
step: 580, loss: 0.15420643985271454
step: 590, loss: 0.11106530576944351
step: 600, loss: 0.07710044085979462
step: 610, loss: 0.04740556702017784
step: 620, loss: 0.12844952940940857
step: 630, loss: 0.13570216298103333
step: 640, loss: 0.12294210493564606
step: 650, loss: 0.029918711632490158
step: 660, loss: 0.06355645507574081
step: 670, loss: 0.12373539060354233
step: 680, loss: 0.20713315904140472
step: 690, loss: 0.17249152064323425
step: 700, loss: 0.11380177736282349
step: 710, loss: 0.09477502107620239
step: 720, loss: 0.09183710068464279
step: 730, loss: 0.2789298892021179
step: 740, loss: 0.1011933982372284
step: 750, loss: 0.2154632806777954
step: 760, loss: 0.17318816483020782
step: 770, loss: 0.05533307045698166
step: 780, loss: 0.08471737802028656
step: 790, loss: 0.19246679544448853
step: 800, loss: 0.13699659705162048
step: 810, loss: 0.15097609162330627
step: 820, loss: 0.18005871772766113
step: 830, loss: 0.14895856380462646
step: 840, loss: 0.18878278136253357
step: 850, loss: 0.10858456045389175
step: 860, loss: 0.08985456079244614
step: 870, loss: 0.09122268855571747
step: 880, loss: 0.05752575024962425
step: 890, loss: 0.06666944921016693
step: 900, loss: 0.13285747170448303
step: 910, loss: 0.13010619580745697
step: 920, loss: 0.16907502710819244
step: 930, loss: 0.18089069426059723
step: 940, loss: 0.18734824657440186
step: 950, loss: 0.09135246276855469
step: 960, loss: 0.2167469710111618
step: 970, loss: 0.2942338287830353
epoch 1: dev_f1=0.919800634345265, f1=0.9235639981908639, best_f1=0.9235639981908639
step: 0, loss: 0.14589780569076538
step: 10, loss: 0.2566375732421875
step: 20, loss: 0.15524853765964508
step: 30, loss: 0.2059648036956787
step: 40, loss: 0.12418206036090851
step: 50, loss: 0.17388306558132172
step: 60, loss: 0.20243293046951294
step: 70, loss: 0.16311557590961456
step: 80, loss: 0.09170518070459366
step: 90, loss: 0.2574584186077118
step: 100, loss: 0.1792479306459427
step: 110, loss: 0.05615851655602455
step: 120, loss: 0.08514054864645004
step: 130, loss: 0.19721762835979462
step: 140, loss: 0.06500724703073502
step: 150, loss: 0.026135951280593872
step: 160, loss: 0.0813944935798645
step: 170, loss: 0.08701612800359726
step: 180, loss: 0.17900946736335754
step: 190, loss: 0.06540161371231079
step: 200, loss: 0.13687337934970856
step: 210, loss: 0.058296773582696915
step: 220, loss: 0.13786891102790833
step: 230, loss: 0.1364084631204605
step: 240, loss: 0.08079349994659424
step: 250, loss: 0.1954188346862793
step: 260, loss: 0.21734464168548584
step: 270, loss: 0.22982165217399597
step: 280, loss: 0.19937612116336823
step: 290, loss: 0.0760386735200882
step: 300, loss: 0.23041345179080963
step: 310, loss: 0.07569380849599838
step: 320, loss: 0.13407954573631287
step: 330, loss: 0.044748615473508835
step: 340, loss: 0.06662822514772415
step: 350, loss: 0.10377989709377289
step: 360, loss: 0.15143829584121704
step: 370, loss: 0.13259214162826538
step: 380, loss: 0.17133614420890808
step: 390, loss: 0.24022582173347473
step: 400, loss: 0.0746978223323822
step: 410, loss: 0.1987038552761078
step: 420, loss: 0.1904771476984024
step: 430, loss: 0.05963701382279396
step: 440, loss: 0.25007686018943787
step: 450, loss: 0.24883495271205902
step: 460, loss: 0.16023080050945282
step: 470, loss: 0.05699137598276138
step: 480, loss: 0.25041288137435913
step: 490, loss: 0.24846577644348145
step: 500, loss: 0.0755746141076088
step: 510, loss: 0.08587940037250519
step: 520, loss: 0.1456240862607956
step: 530, loss: 0.2156175822019577
step: 540, loss: 0.05622977018356323
step: 550, loss: 0.011325824074447155
step: 560, loss: 0.07627056539058685
step: 570, loss: 0.096861332654953
step: 580, loss: 0.14688120782375336
step: 590, loss: 0.07121387869119644
step: 600, loss: 0.14685142040252686
step: 610, loss: 0.055406976491212845
step: 620, loss: 0.08671284466981888
step: 630, loss: 0.2248782366514206
step: 640, loss: 0.10967559367418289
step: 650, loss: 0.1082892119884491
step: 660, loss: 0.1514224410057068
step: 670, loss: 0.18253874778747559
step: 680, loss: 0.1567647010087967
step: 690, loss: 0.22467540204524994
step: 700, loss: 0.09903585910797119
step: 710, loss: 0.1289573609828949
step: 720, loss: 0.1469491422176361
step: 730, loss: 0.12029356509447098
step: 740, loss: 0.15210245549678802
step: 750, loss: 0.036569882184267044
step: 760, loss: 0.17467617988586426
step: 770, loss: 0.2622038424015045
step: 780, loss: 0.023187320679426193
step: 790, loss: 0.08437573909759521
step: 800, loss: 0.1814403384923935
step: 810, loss: 0.19152234494686127
step: 820, loss: 0.04082682728767395
step: 830, loss: 0.12249298393726349
step: 840, loss: 0.29753217101097107
step: 850, loss: 0.12906548380851746
step: 860, loss: 0.07387878000736237
step: 870, loss: 0.058912064880132675
step: 880, loss: 0.003923595417290926
step: 890, loss: 0.14734841883182526
step: 900, loss: 0.18067464232444763
step: 910, loss: 0.17533139884471893
step: 920, loss: 0.09627217799425125
step: 930, loss: 0.10708259046077728
step: 940, loss: 0.10649247467517853
step: 950, loss: 0.22366751730442047
step: 960, loss: 0.14087477326393127
step: 970, loss: 0.18075980246067047
epoch 2: dev_f1=0.9201834862385322, f1=0.9167429094236048, best_f1=0.9167429094236048
step: 0, loss: 0.12445294111967087
step: 10, loss: 0.02300935611128807
step: 20, loss: 0.10967671871185303
step: 30, loss: 0.04359748959541321
step: 40, loss: 0.0820758044719696
step: 50, loss: 0.06224164739251137
step: 60, loss: 0.16051794588565826
step: 70, loss: 0.0954563170671463
step: 80, loss: 0.06119271740317345
step: 90, loss: 0.19266395270824432
step: 100, loss: 0.2442675232887268
step: 110, loss: 0.05280102789402008
step: 120, loss: 0.16309696435928345
step: 130, loss: 0.12662725150585175
step: 140, loss: 0.1125737801194191
step: 150, loss: 0.14062045514583588
step: 160, loss: 0.1552686095237732
step: 170, loss: 0.19783338904380798
step: 180, loss: 0.12026050686836243
step: 190, loss: 0.09701021015644073
step: 200, loss: 0.20200826227664948
step: 210, loss: 0.1351781189441681
step: 220, loss: 0.10333871096372604
step: 230, loss: 0.13272851705551147
step: 240, loss: 0.04526187852025032
step: 250, loss: 0.08631942421197891
step: 260, loss: 0.08479419350624084
step: 270, loss: 0.040068622678518295
step: 280, loss: 0.05094541981816292
step: 290, loss: 0.10145547986030579
step: 300, loss: 0.031703751534223557
step: 310, loss: 0.11981240659952164
step: 320, loss: 0.16564524173736572
step: 330, loss: 0.09598207473754883
step: 340, loss: 0.07372269034385681
step: 350, loss: 0.19191144406795502
step: 360, loss: 0.07020046561956406
step: 370, loss: 0.0815097764134407
step: 380, loss: 0.21569012105464935
step: 390, loss: 0.1093236580491066
step: 400, loss: 0.08705972135066986
step: 410, loss: 0.21381475031375885
step: 420, loss: 0.2063279002904892
step: 430, loss: 0.12337469309568405
step: 440, loss: 0.09742442518472672
step: 450, loss: 0.10665005445480347
step: 460, loss: 0.1934044510126114
step: 470, loss: 0.12957410514354706
step: 480, loss: 0.08376242965459824
step: 490, loss: 0.02342813089489937
step: 500, loss: 0.18569274246692657
step: 510, loss: 0.13319307565689087
step: 520, loss: 0.09752259403467178
step: 530, loss: 0.1641371101140976
step: 540, loss: 0.12825842201709747
step: 550, loss: 0.06829617917537689
step: 560, loss: 0.10266478359699249
step: 570, loss: 0.14805489778518677
step: 580, loss: 0.16572999954223633
step: 590, loss: 0.1238396018743515
step: 600, loss: 0.1254826784133911
step: 610, loss: 0.03544503077864647
step: 620, loss: 0.15318764746189117
step: 630, loss: 0.09312199801206589
step: 640, loss: 0.20039208233356476
step: 650, loss: 0.16997185349464417
step: 660, loss: 0.041249267756938934
step: 670, loss: 0.0328376367688179
step: 680, loss: 0.2151469588279724
step: 690, loss: 0.042464274913072586
step: 700, loss: 0.08608841150999069
step: 710, loss: 0.09449780732393265
step: 720, loss: 0.03592129424214363
step: 730, loss: 0.19390340149402618
step: 740, loss: 0.08344707638025284
step: 750, loss: 0.16497817635536194
step: 760, loss: 0.07311487942934036
step: 770, loss: 0.12858423590660095
step: 780, loss: 0.0914764329791069
step: 790, loss: 0.1761670708656311
step: 800, loss: 0.1184072494506836
step: 810, loss: 0.13219301402568817
step: 820, loss: 0.20723509788513184
step: 830, loss: 0.03798367828130722
step: 840, loss: 0.2389867603778839
step: 850, loss: 0.17201365530490875
step: 860, loss: 0.09057945758104324
step: 870, loss: 0.028510915115475655
step: 880, loss: 0.15268343687057495
step: 890, loss: 0.17318816483020782
step: 900, loss: 0.08994733542203903
step: 910, loss: 0.13212382793426514
step: 920, loss: 0.13260199129581451
step: 930, loss: 0.05885021388530731
step: 940, loss: 0.16751086711883545
step: 950, loss: 0.11512044072151184
step: 960, loss: 0.06367646157741547
step: 970, loss: 0.18639077246189117
epoch 3: dev_f1=0.9290382819794585, f1=0.9175593851886353, best_f1=0.9175593851886353
step: 0, loss: 0.11532118171453476
step: 10, loss: 0.1513962745666504
step: 20, loss: 0.059468965977430344
step: 30, loss: 0.08396198600530624
step: 40, loss: 0.06867623329162598
step: 50, loss: 0.27590411901474
step: 60, loss: 0.11911985278129578
step: 70, loss: 0.14805705845355988
step: 80, loss: 0.13920855522155762
step: 90, loss: 0.08810911327600479
step: 100, loss: 0.015276741236448288
step: 110, loss: 0.06810460984706879
step: 120, loss: 0.0659269317984581
step: 130, loss: 0.1605600267648697
step: 140, loss: 0.09928017854690552
step: 150, loss: 0.07117948681116104
step: 160, loss: 0.036417752504348755
step: 170, loss: 0.05750007927417755
step: 180, loss: 0.12489813566207886
step: 190, loss: 0.027417054399847984
step: 200, loss: 0.10766325145959854
step: 210, loss: 0.11600625514984131
step: 220, loss: 0.13498525321483612
step: 230, loss: 0.06375505030155182
step: 240, loss: 0.11060492694377899
step: 250, loss: 0.0721001997590065
step: 260, loss: 0.12372738122940063
step: 270, loss: 0.03275156766176224
step: 280, loss: 0.13269753754138947
step: 290, loss: 0.12109453976154327
step: 300, loss: 0.11168570816516876
step: 310, loss: 0.1406109780073166
step: 320, loss: 0.0553906075656414
step: 330, loss: 0.09409190714359283
step: 340, loss: 0.11093646287918091
step: 350, loss: 0.10276473313570023
step: 360, loss: 0.07406207919120789
step: 370, loss: 0.1449008285999298
step: 380, loss: 0.10207458585500717
step: 390, loss: 0.257766455411911
step: 400, loss: 0.05749061703681946
step: 410, loss: 0.17076453566551208
step: 420, loss: 0.09809044003486633
step: 430, loss: 0.06591129302978516
step: 440, loss: 0.06542596966028214
step: 450, loss: 0.18543176352977753
step: 460, loss: 0.09527012705802917
step: 470, loss: 0.12745778262615204
step: 480, loss: 0.09045439958572388
step: 490, loss: 0.10150597989559174
step: 500, loss: 0.07961346954107285
step: 510, loss: 0.12448015064001083
step: 520, loss: 0.21676160395145416
step: 530, loss: 0.03714517503976822
step: 540, loss: 0.16489672660827637
step: 550, loss: 0.0749930739402771
step: 560, loss: 0.13004472851753235
step: 570, loss: 0.17587506771087646
step: 580, loss: 0.0979747399687767
step: 590, loss: 0.060423702001571655
step: 600, loss: 0.11782810837030411
step: 610, loss: 0.10944420099258423
step: 620, loss: 0.21426130831241608
step: 630, loss: 0.10442844778299332
step: 640, loss: 0.11415944993495941
step: 650, loss: 0.04195278137922287
step: 660, loss: 0.1446862369775772
step: 670, loss: 0.10693103820085526
step: 680, loss: 0.3054738938808441
step: 690, loss: 0.12044117599725723
step: 700, loss: 0.0920792818069458
step: 710, loss: 0.15275174379348755
step: 720, loss: 0.14918352663516998
step: 730, loss: 0.09938247501850128
step: 740, loss: 0.08838105946779251
step: 750, loss: 0.10995965451002121
step: 760, loss: 0.06913453340530396
step: 770, loss: 0.09922359138727188
step: 780, loss: 0.13201579451560974
step: 790, loss: 0.11238767951726913
step: 800, loss: 0.14615000784397125
step: 810, loss: 0.07992516458034515
step: 820, loss: 0.1376541703939438
step: 830, loss: 0.11215351521968842
step: 840, loss: 0.13888156414031982
step: 850, loss: 0.1843799650669098
step: 860, loss: 0.07351916283369064
step: 870, loss: 0.288809210062027
step: 880, loss: 0.08433566242456436
step: 890, loss: 0.06291329115629196
step: 900, loss: 0.3494621813297272
step: 910, loss: 0.07032269239425659
step: 920, loss: 0.21985845267772675
step: 930, loss: 0.14951403439044952
step: 940, loss: 0.21124260127544403
step: 950, loss: 0.050658587366342545
step: 960, loss: 0.17998549342155457
step: 970, loss: 0.11592313647270203
epoch 4: dev_f1=0.9261495587552253, f1=0.9147072383586906, best_f1=0.9175593851886353
step: 0, loss: 0.12271058559417725
step: 10, loss: 0.1633620709180832
step: 20, loss: 0.04050759971141815
step: 30, loss: 0.03160499781370163
step: 40, loss: 0.08266705274581909
step: 50, loss: 0.1394386887550354
step: 60, loss: 0.06492718309164047
step: 70, loss: 0.01568971760571003
step: 80, loss: 0.1554131656885147
step: 90, loss: 0.17899541556835175
step: 100, loss: 0.05508458614349365
step: 110, loss: 0.1359073370695114
step: 120, loss: 0.12825362384319305
step: 130, loss: 0.09640855342149734
step: 140, loss: 0.09317640960216522
step: 150, loss: 0.0358738973736763
step: 160, loss: 0.16639886796474457
step: 170, loss: 0.20197974145412445
step: 180, loss: 0.0943552628159523
step: 190, loss: 0.25286856293678284
step: 200, loss: 0.18476766347885132
step: 210, loss: 0.07085718959569931
step: 220, loss: 0.2048587054014206
step: 230, loss: 0.12078698724508286
step: 240, loss: 0.19683247804641724
step: 250, loss: 0.13987848162651062
step: 260, loss: 0.12809185683727264
step: 270, loss: 0.01950400322675705
step: 280, loss: 0.06354677677154541
step: 290, loss: 0.13797129690647125
step: 300, loss: 0.048968661576509476
step: 310, loss: 0.04091421887278557
step: 320, loss: 0.008510061539709568
step: 330, loss: 0.1536029875278473
step: 340, loss: 0.10030058026313782
step: 350, loss: 0.16930712759494781
step: 360, loss: 0.1320604532957077
step: 370, loss: 0.09398242086172104
step: 380, loss: 0.10037253797054291
step: 390, loss: 0.05096176266670227
step: 400, loss: 0.14789022505283356
step: 410, loss: 0.11986096948385239
step: 420, loss: 0.08761170506477356
step: 430, loss: 0.12737277150154114
step: 440, loss: 0.030093522742390633
step: 450, loss: 0.07182054966688156
step: 460, loss: 0.09807837754487991
step: 470, loss: 0.1283503919839859
step: 480, loss: 0.12181389331817627
step: 490, loss: 0.10393872112035751
step: 500, loss: 0.03886483982205391
step: 510, loss: 0.034368015825748444
step: 520, loss: 0.07925524562597275
step: 530, loss: 0.1459987610578537
step: 540, loss: 0.08582314103841782
step: 550, loss: 0.09471970796585083
step: 560, loss: 0.10721182823181152
step: 570, loss: 0.0995882973074913
step: 580, loss: 0.1336229294538498
step: 590, loss: 0.08320799469947815
step: 600, loss: 0.062089499086141586
step: 610, loss: 0.07410625368356705
step: 620, loss: 0.08528797328472137
step: 630, loss: 0.028773430734872818
step: 640, loss: 0.15575803816318512
step: 650, loss: 0.1486297845840454
step: 660, loss: 0.1165214329957962
step: 670, loss: 0.10323360562324524
step: 680, loss: 0.1771584451198578
step: 690, loss: 0.05375931039452553
step: 700, loss: 0.07528600841760635
step: 710, loss: 0.08435115963220596
step: 720, loss: 0.27655813097953796
step: 730, loss: 0.042581021785736084
step: 740, loss: 0.06083241105079651
step: 750, loss: 0.046779830008745193
step: 760, loss: 0.045608650892972946
step: 770, loss: 0.08326030522584915
step: 780, loss: 0.054298464208841324
step: 790, loss: 0.12010660767555237
step: 800, loss: 0.07032129913568497
step: 810, loss: 0.05178745090961456
step: 820, loss: 0.05025176331400871
step: 830, loss: 0.1312488466501236
step: 840, loss: 0.07741809636354446
step: 850, loss: 0.08969752490520477
step: 860, loss: 0.13857203722000122
step: 870, loss: 0.08519615232944489
step: 880, loss: 0.07890590280294418
step: 890, loss: 0.0800778940320015
step: 900, loss: 0.14256012439727783
step: 910, loss: 0.1331842988729477
step: 920, loss: 0.22522559762001038
step: 930, loss: 0.08552740514278412
step: 940, loss: 0.049670133739709854
step: 950, loss: 0.03382664918899536
step: 960, loss: 0.07626795023679733
step: 970, loss: 0.1177886426448822
epoch 5: dev_f1=0.9314312011044639, f1=0.9242843951985227, best_f1=0.9242843951985227
step: 0, loss: 0.09713053703308105
step: 10, loss: 0.10416335612535477
step: 20, loss: 0.04858079552650452
step: 30, loss: 0.08110303431749344
step: 40, loss: 0.08687582612037659
step: 50, loss: 0.054051369428634644
step: 60, loss: 0.27210909128189087
step: 70, loss: 0.08513393253087997
step: 80, loss: 0.09060023725032806
step: 90, loss: 0.09920625388622284
step: 100, loss: 0.08839426934719086
step: 110, loss: 0.07386074960231781
step: 120, loss: 0.23002855479717255
step: 130, loss: 0.1183326244354248
step: 140, loss: 0.09480021893978119
step: 150, loss: 0.08932873606681824
step: 160, loss: 0.08999061584472656
step: 170, loss: 0.07266201078891754
step: 180, loss: 0.09595309942960739
step: 190, loss: 0.05481744557619095
step: 200, loss: 0.12498091161251068
step: 210, loss: 0.06687355041503906
step: 220, loss: 0.04796444997191429
step: 230, loss: 0.08763280510902405
step: 240, loss: 0.06941311806440353
step: 250, loss: 0.12432444840669632
step: 260, loss: 0.04703108221292496
step: 270, loss: 0.06689666956663132
step: 280, loss: 0.11537501215934753
step: 290, loss: 0.07073900103569031
step: 300, loss: 0.03076348640024662
step: 310, loss: 0.1672905683517456
step: 320, loss: 0.10453308373689651
step: 330, loss: 0.10995303839445114
step: 340, loss: 0.20979362726211548
step: 350, loss: 0.07870156317949295
step: 360, loss: 0.08118710666894913
step: 370, loss: 0.04606743901968002
step: 380, loss: 0.09250704199075699
step: 390, loss: 0.16586662828922272
step: 400, loss: 0.05591125413775444
step: 410, loss: 0.12631981074810028
step: 420, loss: 0.11366625130176544
step: 430, loss: 0.05877671018242836
step: 440, loss: 0.11879058182239532
step: 450, loss: 0.05127837136387825
step: 460, loss: 0.16902591288089752
step: 470, loss: 0.07221302390098572
step: 480, loss: 0.054044466465711594
step: 490, loss: 0.06155906617641449
step: 500, loss: 0.028353851288557053
step: 510, loss: 0.060986071825027466
step: 520, loss: 0.09597183763980865
step: 530, loss: 0.11254522204399109
step: 540, loss: 0.04006046801805496
step: 550, loss: 0.038225363940000534
step: 560, loss: 0.06830757111310959
step: 570, loss: 0.09929107129573822
step: 580, loss: 0.16654713451862335
step: 590, loss: 0.10687969624996185
step: 600, loss: 0.12233883142471313
step: 610, loss: 0.1256648451089859
step: 620, loss: 0.32262322306632996
step: 630, loss: 0.02778603881597519
step: 640, loss: 0.047182388603687286
step: 650, loss: 0.006946502719074488
step: 660, loss: 0.19500704109668732
step: 670, loss: 0.114966481924057
step: 680, loss: 0.10713377594947815
step: 690, loss: 0.12070885300636292
step: 700, loss: 0.07410440593957901
step: 710, loss: 0.11638355255126953
step: 720, loss: 0.13560785353183746
step: 730, loss: 0.11869063973426819
step: 740, loss: 0.05464360862970352
step: 750, loss: 0.1747133582830429
step: 760, loss: 0.0006151240668259561
step: 770, loss: 0.06210897117853165
step: 780, loss: 0.23124746978282928
step: 790, loss: 0.10854008048772812
step: 800, loss: 0.182684063911438
step: 810, loss: 0.1414889246225357
step: 820, loss: 0.09500376135110855
step: 830, loss: 0.10193918645381927
step: 840, loss: 0.10474397987127304
step: 850, loss: 0.10148947685956955
step: 860, loss: 0.08357803523540497
step: 870, loss: 0.09277070313692093
step: 880, loss: 0.07117920368909836
step: 890, loss: 0.1544012725353241
step: 900, loss: 0.06753076612949371
step: 910, loss: 0.04401860013604164
step: 920, loss: 0.20777399837970734
step: 930, loss: 0.12181415408849716
step: 940, loss: 0.025085967034101486
step: 950, loss: 0.19542817771434784
step: 960, loss: 0.0590675063431263
step: 970, loss: 0.06907968968153
epoch 6: dev_f1=0.9296296296296297, f1=0.9255813953488372, best_f1=0.9242843951985227
step: 0, loss: 0.05841103568673134
step: 10, loss: 0.08103661984205246
step: 20, loss: 0.08003083616495132
step: 30, loss: 0.08137783408164978
step: 40, loss: 0.15254686772823334
step: 50, loss: 0.015490463934838772
step: 60, loss: 0.11142382025718689
step: 70, loss: 0.14902791380882263
step: 80, loss: 0.09979380667209625
step: 90, loss: 0.04759344458580017
step: 100, loss: 0.09854671359062195
step: 110, loss: 0.023989573121070862
step: 120, loss: 0.15594981610774994
step: 130, loss: 0.10203199088573456
step: 140, loss: 0.17706847190856934
step: 150, loss: 0.0621965266764164
step: 160, loss: 0.11125700175762177
step: 170, loss: 0.038335517048835754
step: 180, loss: 0.08473526686429977
step: 190, loss: 0.10319621860980988
step: 200, loss: 0.08706435561180115
step: 210, loss: 0.06860419362783432
step: 220, loss: 0.1097295731306076
step: 230, loss: 0.09797589480876923
step: 240, loss: 0.1228354275226593
step: 250, loss: 0.10269029438495636
step: 260, loss: 0.04650219529867172
step: 270, loss: 0.06723298132419586
step: 280, loss: 0.09058874100446701
step: 290, loss: 0.1174248605966568
step: 300, loss: 0.17596550285816193
step: 310, loss: 0.031395360827445984
step: 320, loss: 0.06247462332248688
step: 330, loss: 0.01422949694097042
step: 340, loss: 0.07137510925531387
step: 350, loss: 0.13650506734848022
step: 360, loss: 0.05483804643154144
step: 370, loss: 0.051991645246744156
step: 380, loss: 0.03128773346543312
step: 390, loss: 0.14283780753612518
step: 400, loss: 0.106475330889225
step: 410, loss: 0.06780792772769928
step: 420, loss: 0.10730799287557602
step: 430, loss: 0.07357655465602875
step: 440, loss: 0.09000759571790695
step: 450, loss: 0.11372430622577667
step: 460, loss: 0.07355448603630066
step: 470, loss: 0.09333924204111099
step: 480, loss: 0.04506038874387741
step: 490, loss: 0.08693118393421173
step: 500, loss: 0.09212205559015274
step: 510, loss: 0.13048624992370605
step: 520, loss: 0.07527933269739151
step: 530, loss: 0.07013663649559021
step: 540, loss: 0.09791383147239685
step: 550, loss: 0.10668254643678665
step: 560, loss: 0.08008278906345367
step: 570, loss: 0.13585591316223145
step: 580, loss: 0.0622219517827034
step: 590, loss: 0.10374361276626587
step: 600, loss: 0.054418377578258514
step: 610, loss: 0.06129257008433342
step: 620, loss: 0.019963832572102547
step: 630, loss: 0.1022961288690567
step: 640, loss: 0.07728235423564911
step: 650, loss: 0.11816014349460602
step: 660, loss: 0.13212554156780243
step: 670, loss: 0.056879833340644836
step: 680, loss: 0.20581744611263275
step: 690, loss: 0.1070895567536354
step: 700, loss: 0.07892262935638428
step: 710, loss: 0.0975673720240593
step: 720, loss: 0.09846916794776917
step: 730, loss: 0.09227705746889114
step: 740, loss: 0.04150696098804474
step: 750, loss: 0.06471405923366547
step: 760, loss: 0.08297928422689438
step: 770, loss: 0.013219722546637058
step: 780, loss: 0.0782298892736435
step: 790, loss: 0.11261879652738571
step: 800, loss: 0.08466558903455734
step: 810, loss: 0.11657218635082245
step: 820, loss: 0.10366173833608627
step: 830, loss: 0.06593668460845947
step: 840, loss: 0.018151279538869858
step: 850, loss: 0.06260433793067932
step: 860, loss: 0.12652267515659332
step: 870, loss: 0.23406511545181274
step: 880, loss: 0.011795789003372192
step: 890, loss: 0.04569285362958908
step: 900, loss: 0.059545595198869705
step: 910, loss: 0.0430658683180809
step: 920, loss: 0.0902174860239029
step: 930, loss: 0.18360602855682373
step: 940, loss: 0.07250900566577911
step: 950, loss: 0.09088007360696793
step: 960, loss: 0.04156211391091347
step: 970, loss: 0.062251146882772446
epoch 7: dev_f1=0.9332096474953617, f1=0.9293023255813954, best_f1=0.9293023255813954
step: 0, loss: 0.03164753317832947
step: 10, loss: 0.09106127917766571
step: 20, loss: 0.09193055331707001
step: 30, loss: 0.06696269661188126
step: 40, loss: 0.029864072799682617
step: 50, loss: 0.1385839879512787
step: 60, loss: 0.06431493163108826
step: 70, loss: 0.08851141482591629
step: 80, loss: 0.08009189367294312
step: 90, loss: 0.02454761415719986
step: 100, loss: 0.04213511198759079
step: 110, loss: 0.1739782691001892
step: 120, loss: 0.1072988361120224
step: 130, loss: 0.0988144502043724
step: 140, loss: 0.08762530237436295
step: 150, loss: 0.07347093522548676
step: 160, loss: 0.1289423257112503
step: 170, loss: 0.07993479073047638
step: 180, loss: 0.047855671495199203
step: 190, loss: 0.05997901037335396
step: 200, loss: 0.06068064272403717
step: 210, loss: 0.07602620869874954
step: 220, loss: 0.0365687794983387
step: 230, loss: 0.1519971489906311
step: 240, loss: 0.17376863956451416
step: 250, loss: 0.09390806406736374
step: 260, loss: 0.06888040155172348
step: 270, loss: 0.1205812320113182
step: 280, loss: 0.051224060356616974
step: 290, loss: 0.056244272738695145
step: 300, loss: 0.13828425109386444
step: 310, loss: 0.05154638737440109
step: 320, loss: 0.036597929894924164
step: 330, loss: 0.06090642139315605
step: 340, loss: 0.03155085816979408
step: 350, loss: 0.08530895411968231
step: 360, loss: 0.0513436533510685
step: 370, loss: 0.044457945972681046
step: 380, loss: 0.10408592969179153
step: 390, loss: 0.07002203911542892
step: 400, loss: 0.07756385207176208
step: 410, loss: 0.038414936512708664
step: 420, loss: 0.07340949773788452
step: 430, loss: 0.10733217746019363
step: 440, loss: 0.08974146842956543
step: 450, loss: 0.1634669154882431
step: 460, loss: 0.12692315876483917
step: 470, loss: 0.08856387436389923
step: 480, loss: 0.045089058578014374
step: 490, loss: 0.12102539092302322
step: 500, loss: 0.030771974474191666
step: 510, loss: 0.15070994198322296
step: 520, loss: 0.17904552817344666
step: 530, loss: 0.04335224628448486
step: 540, loss: 0.02692941389977932
step: 550, loss: 0.0923587754368782
step: 560, loss: 0.15340924263000488
step: 570, loss: 0.05976983904838562
step: 580, loss: 0.11006418615579605
step: 590, loss: 0.009502092376351357
step: 600, loss: 0.09598443657159805
step: 610, loss: 0.051314957439899445
step: 620, loss: 0.11897747963666916
step: 630, loss: 0.033214058727025986
step: 640, loss: 0.07336179912090302
step: 650, loss: 0.09932546317577362
step: 660, loss: 0.10140339285135269
step: 670, loss: 0.07598399370908737
step: 680, loss: 0.0459185466170311
step: 690, loss: 0.1343039870262146
step: 700, loss: 0.10840995609760284
step: 710, loss: 0.1440768986940384
step: 720, loss: 0.0652160495519638
step: 730, loss: 0.11698894202709198
step: 740, loss: 0.11457114666700363
step: 750, loss: 0.0381617397069931
step: 760, loss: 0.029190534725785255
step: 770, loss: 0.08491890132427216
step: 780, loss: 0.02546776458621025
step: 790, loss: 0.05898803472518921
step: 800, loss: 0.12554776668548584
step: 810, loss: 0.02906789630651474
step: 820, loss: 0.17568327486515045
step: 830, loss: 0.19319485127925873
step: 840, loss: 0.08185770362615585
step: 850, loss: 0.0662151426076889
step: 860, loss: 0.26373156905174255
step: 870, loss: 0.0894719734787941
step: 880, loss: 0.10430283844470978
step: 890, loss: 0.10720165818929672
step: 900, loss: 0.07566285133361816
step: 910, loss: 0.04652748256921768
step: 920, loss: 0.10265309363603592
step: 930, loss: 0.016787253320217133
step: 940, loss: 0.014314856380224228
step: 950, loss: 0.060385800898075104
step: 960, loss: 0.11131422221660614
step: 970, loss: 0.05543981492519379
epoch 8: dev_f1=0.9262865090403337, f1=0.9227209625173529, best_f1=0.9293023255813954
step: 0, loss: 0.038577307015657425
step: 10, loss: 0.0713387131690979
step: 20, loss: 0.030517790466547012
step: 30, loss: 0.09957647323608398
step: 40, loss: 0.10588865727186203
step: 50, loss: 0.019201358780264854
step: 60, loss: 0.020192565396428108
step: 70, loss: 0.11135207116603851
step: 80, loss: 0.1436164230108261
step: 90, loss: 0.09914259612560272
step: 100, loss: 0.06384332478046417
step: 110, loss: 0.03463500365614891
step: 120, loss: 0.12290053814649582
step: 130, loss: 0.0984298512339592
step: 140, loss: 0.14526209235191345
step: 150, loss: 0.02040991745889187
step: 160, loss: 0.1616879105567932
step: 170, loss: 0.008174069225788116
step: 180, loss: 0.12330517917871475
step: 190, loss: 0.1019195169210434
step: 200, loss: 0.007289456203579903
step: 210, loss: 0.11556946486234665
step: 220, loss: 0.04693545028567314
step: 230, loss: 0.019361600279808044
step: 240, loss: 0.11743605136871338
step: 250, loss: 0.15938875079154968
step: 260, loss: 0.04614613205194473
step: 270, loss: 0.10472305119037628
step: 280, loss: 0.04445834457874298
step: 290, loss: 0.1512308269739151
step: 300, loss: 0.08789558708667755
step: 310, loss: 0.07780933380126953
step: 320, loss: 0.08741436153650284
step: 330, loss: 0.015880776569247246
step: 340, loss: 0.034360844641923904
step: 350, loss: 0.05151927098631859
step: 360, loss: 0.11221916228532791
step: 370, loss: 0.058845482766628265
step: 380, loss: 0.030548691749572754
step: 390, loss: 0.036044713109731674
step: 400, loss: 0.24058572947978973
step: 410, loss: 0.03684145584702492
step: 420, loss: 0.04661357030272484
step: 430, loss: 0.10371805727481842
step: 440, loss: 0.11753319203853607
step: 450, loss: 0.21691712737083435
step: 460, loss: 0.09560713917016983
step: 470, loss: 0.006803419440984726
step: 480, loss: 0.07392314821481705
step: 490, loss: 0.17448218166828156
step: 500, loss: 0.1141209676861763
step: 510, loss: 0.07425636053085327
step: 520, loss: 0.06022661551833153
step: 530, loss: 0.06073771044611931
step: 540, loss: 0.05120079219341278
step: 550, loss: 0.09583807736635208
step: 560, loss: 0.01955985650420189
step: 570, loss: 0.06299549341201782
step: 580, loss: 0.13627812266349792
step: 590, loss: 0.034100763499736786
step: 600, loss: 0.03410695865750313
step: 610, loss: 0.09736451506614685
step: 620, loss: 0.14406311511993408
step: 630, loss: 0.07742321491241455
step: 640, loss: 0.01720522716641426
step: 650, loss: 0.06572472304105759
step: 660, loss: 0.02302662841975689
step: 670, loss: 0.09165001660585403
step: 680, loss: 0.04295095056295395
step: 690, loss: 0.11166464537382126
step: 700, loss: 0.0075546251609921455
step: 710, loss: 0.0856427475810051
step: 720, loss: 0.08291011303663254
step: 730, loss: 0.1330982893705368
step: 740, loss: 0.21373556554317474
step: 750, loss: 0.028873957693576813
step: 760, loss: 0.1412084698677063
step: 770, loss: 0.08366438746452332
step: 780, loss: 0.14484213292598724
step: 790, loss: 0.03310184180736542
step: 800, loss: 0.12559473514556885
step: 810, loss: 0.06570879369974136
step: 820, loss: 0.08220747858285904
step: 830, loss: 0.08654278516769409
step: 840, loss: 0.09178255498409271
step: 850, loss: 0.14071287214756012
step: 860, loss: 0.040222860872745514
step: 870, loss: 0.0863458439707756
step: 880, loss: 0.1733465939760208
step: 890, loss: 0.15155595541000366
step: 900, loss: 0.06806005537509918
step: 910, loss: 0.08465561270713806
step: 920, loss: 0.1420154571533203
step: 930, loss: 0.11185495555400848
step: 940, loss: 0.13911879062652588
step: 950, loss: 0.036799658089876175
step: 960, loss: 0.05960533395409584
step: 970, loss: 0.056078504770994186
epoch 9: dev_f1=0.9327731092436975, f1=0.9231485794131347, best_f1=0.9293023255813954
step: 0, loss: 0.10391879081726074
step: 10, loss: 0.11578522622585297
step: 20, loss: 0.08971498161554337
step: 30, loss: 0.11234723776578903
step: 40, loss: 0.04146481677889824
step: 50, loss: 0.07482799887657166
step: 60, loss: 0.03448960930109024
step: 70, loss: 0.06749837100505829
step: 80, loss: 0.07093596458435059
step: 90, loss: 7.303960592253134e-05
step: 100, loss: 0.12526142597198486
step: 110, loss: 0.01322930958122015
step: 120, loss: 0.1489877849817276
step: 130, loss: 0.060017138719558716
step: 140, loss: 0.06906335055828094
step: 150, loss: 0.10309523344039917
step: 160, loss: 0.05194981396198273
step: 170, loss: 0.04461348056793213
step: 180, loss: 0.10370390862226486
step: 190, loss: 0.09897307306528091
step: 200, loss: 0.18630504608154297
step: 210, loss: 0.07370230555534363
step: 220, loss: 0.14226998388767242
step: 230, loss: 0.08395826071500778
step: 240, loss: 0.030117711052298546
step: 250, loss: 0.07388341426849365
step: 260, loss: 0.05154825374484062
step: 270, loss: 0.02948087826371193
step: 280, loss: 0.01397941168397665
step: 290, loss: 0.23970575630664825
step: 300, loss: 0.05507887154817581
step: 310, loss: 0.05922156572341919
step: 320, loss: 0.04939987510442734
step: 330, loss: 0.1585962325334549
step: 340, loss: 0.1708638221025467
step: 350, loss: 0.1941719353199005
step: 360, loss: 0.08561684936285019
step: 370, loss: 0.06446313112974167
step: 380, loss: 0.06845146417617798
step: 390, loss: 0.1332286298274994
step: 400, loss: 0.01730515994131565
step: 410, loss: 0.05736671760678291
step: 420, loss: 0.01527068018913269
step: 430, loss: 0.131270170211792
step: 440, loss: 0.08261209726333618
step: 450, loss: 0.12477915734052658
step: 460, loss: 0.0008348561823368073
step: 470, loss: 0.150182843208313
step: 480, loss: 0.039148490875959396
step: 490, loss: 0.05983910337090492
step: 500, loss: 0.2787771224975586
step: 510, loss: 0.1274213343858719
step: 520, loss: 0.045198433101177216
step: 530, loss: 0.08569794148206711
step: 540, loss: 0.04404659941792488
step: 550, loss: 0.07306057959794998
step: 560, loss: 0.038412027060985565
step: 570, loss: 0.0750492662191391
step: 580, loss: 0.0023637472186237574
step: 590, loss: 0.18418735265731812
step: 600, loss: 0.0621013306081295
step: 610, loss: 0.09514760971069336
step: 620, loss: 0.12646420300006866
step: 630, loss: 0.037220511585474014
step: 640, loss: 0.17546184360980988
step: 650, loss: 0.0345272533595562
step: 660, loss: 0.05957559123635292
step: 670, loss: 0.041740816086530685
step: 680, loss: 0.18809597194194794
step: 690, loss: 0.1584840714931488
step: 700, loss: 0.07390134036540985
step: 710, loss: 0.06835924088954926
step: 720, loss: 0.026472903788089752
step: 730, loss: 0.034994591027498245
step: 740, loss: 0.061750225722789764
step: 750, loss: 0.08617617934942245
step: 760, loss: 0.017796510830521584
step: 770, loss: 0.19258038699626923
step: 780, loss: 0.11255306750535965
step: 790, loss: 0.03632834553718567
step: 800, loss: 0.04023100063204765
step: 810, loss: 0.018071729689836502
step: 820, loss: 0.14608857035636902
step: 830, loss: 0.1113620474934578
step: 840, loss: 0.07010200619697571
step: 850, loss: 0.08687766641378403
step: 860, loss: 0.07924937456846237
step: 870, loss: 0.1293439418077469
step: 880, loss: 0.09657701104879379
step: 890, loss: 0.09624122828245163
step: 900, loss: 0.029779324308037758
step: 910, loss: 0.13242968916893005
step: 920, loss: 0.1609465628862381
step: 930, loss: 0.061455074697732925
step: 940, loss: 0.04810958728194237
step: 950, loss: 0.07095377892255783
step: 960, loss: 0.004070979543030262
step: 970, loss: 0.10276872664690018
epoch 10: dev_f1=0.9277777777777779, f1=0.9168580615525953, best_f1=0.9293023255813954
step: 0, loss: 0.0734318420290947
step: 10, loss: 0.03584780916571617
step: 20, loss: 0.046076368540525436
step: 30, loss: 0.035900749266147614
step: 40, loss: 0.14518101513385773
step: 50, loss: 0.1274106800556183
step: 60, loss: 0.029540706425905228
step: 70, loss: 0.09267585724592209
step: 80, loss: 0.13860264420509338
step: 90, loss: 0.05254608765244484
step: 100, loss: 0.07828281074762344
step: 110, loss: 0.08464713394641876
step: 120, loss: 0.07319319993257523
step: 130, loss: 0.03900974616408348
step: 140, loss: 0.010079323314130306
step: 150, loss: 0.03670091554522514
step: 160, loss: 0.034571319818496704
step: 170, loss: 0.08146153390407562
step: 180, loss: 0.07637162506580353
step: 190, loss: 0.13775421679019928
step: 200, loss: 0.21000789105892181
step: 210, loss: 0.07059797644615173
step: 220, loss: 0.11451243609189987
step: 230, loss: 0.04152025282382965
step: 240, loss: 0.07641714811325073
step: 250, loss: 0.14846892654895782
step: 260, loss: 0.07282160967588425
step: 270, loss: 0.004943246021866798
step: 280, loss: 0.051006902009248734
step: 290, loss: 0.11135465651750565
step: 300, loss: 0.012925824150443077
step: 310, loss: 0.18460886180400848
step: 320, loss: 0.08230876177549362
step: 330, loss: 0.1649187058210373
step: 340, loss: 0.15736325085163116
step: 350, loss: 0.07797720283269882
step: 360, loss: 0.1361742913722992
step: 370, loss: 0.0426584891974926
step: 380, loss: 0.07230056822299957
step: 390, loss: 0.04206252843141556
step: 400, loss: 0.026038173586130142
step: 410, loss: 0.13528373837471008
step: 420, loss: 0.07425253838300705
step: 430, loss: 0.13788959383964539
step: 440, loss: 0.05816410481929779
step: 450, loss: 0.08518053591251373
step: 460, loss: 0.1024153009057045
step: 470, loss: 0.05571179836988449
step: 480, loss: 0.15305113792419434
step: 490, loss: 0.039506688714027405
step: 500, loss: 0.12209197133779526
step: 510, loss: 0.06838572025299072
step: 520, loss: 0.11934592574834824
step: 530, loss: 0.07377583533525467
step: 540, loss: 0.09012044966220856
step: 550, loss: 0.04681652784347534
step: 560, loss: 0.05012598633766174
step: 570, loss: 0.09547939151525497
step: 580, loss: 0.05797185003757477
step: 590, loss: 0.1441543847322464
step: 600, loss: 0.035853657871484756
step: 610, loss: 0.018365560099482536
step: 620, loss: 0.07039544731378555
step: 630, loss: 0.10942545533180237
step: 640, loss: 0.0980350524187088
step: 650, loss: 0.04061957821249962
step: 660, loss: 0.01730252616107464
step: 670, loss: 0.08174190670251846
step: 680, loss: 0.008625280112028122
step: 690, loss: 0.14062368869781494
step: 700, loss: 0.1020549088716507
step: 710, loss: 0.032053083181381226
step: 720, loss: 0.1140277311205864
step: 730, loss: 0.04600207880139351
step: 740, loss: 0.089003786444664
step: 750, loss: 0.08165561407804489
step: 760, loss: 0.03234701231122017
step: 770, loss: 0.02946552447974682
step: 780, loss: 0.03713608533143997
step: 790, loss: 0.2109590321779251
step: 800, loss: 0.05689508095383644
step: 810, loss: 0.11135070770978928
step: 820, loss: 0.03379616513848305
step: 830, loss: 0.1158808171749115
step: 840, loss: 0.1097540631890297
step: 850, loss: 0.026736099272966385
step: 860, loss: 0.10009178519248962
step: 870, loss: 0.03821035847067833
step: 880, loss: 0.11138243973255157
step: 890, loss: 0.1158033087849617
step: 900, loss: 0.18079955875873566
step: 910, loss: 0.05636496841907501
step: 920, loss: 0.01465644035488367
step: 930, loss: 0.1343531608581543
step: 940, loss: 0.028813710436224937
step: 950, loss: 0.0796172022819519
step: 960, loss: 0.0455041229724884
step: 970, loss: 0.15060250461101532
epoch 11: dev_f1=0.9334557136301056, f1=0.9239981575310916, best_f1=0.9239981575310916
step: 0, loss: 0.0765625387430191
step: 10, loss: 0.09621250629425049
step: 20, loss: 0.007771069183945656
step: 30, loss: 0.2516966760158539
step: 40, loss: 0.11013263463973999
step: 50, loss: 0.06974481046199799
step: 60, loss: 0.06522676348686218
step: 70, loss: 0.02628842554986477
step: 80, loss: 0.0036156626883894205
step: 90, loss: 0.06414453685283661
step: 100, loss: 0.07063331454992294
step: 110, loss: 0.06478041410446167
step: 120, loss: 0.11803658306598663
step: 130, loss: 0.04211997240781784
step: 140, loss: 0.07598119974136353
step: 150, loss: 0.0236541498452425
step: 160, loss: 0.0394284650683403
step: 170, loss: 0.2019488364458084
step: 180, loss: 0.09016820043325424
step: 190, loss: 0.07867010682821274
step: 200, loss: 0.15851232409477234
step: 210, loss: 0.058921802788972855
step: 220, loss: 0.09358468651771545
step: 230, loss: 0.05557234585285187
step: 240, loss: 0.06492973864078522
step: 250, loss: 0.09122619777917862
step: 260, loss: 0.0981094241142273
step: 270, loss: 0.0821847915649414
step: 280, loss: 0.10046527534723282
step: 290, loss: 0.08860258758068085
step: 300, loss: 0.11505909264087677
step: 310, loss: 0.035536959767341614
step: 320, loss: 0.020543759688735008
step: 330, loss: 0.01616591028869152
step: 340, loss: 0.10802195221185684
step: 350, loss: 0.045428913086652756
step: 360, loss: 0.10266261547803879
step: 370, loss: 0.018794579431414604
step: 380, loss: 0.03057214990258217
step: 390, loss: 0.038783397525548935
step: 400, loss: 0.14713235199451447
step: 410, loss: 0.08579520136117935
step: 420, loss: 0.0002964056911878288
step: 430, loss: 0.07450058311223984
step: 440, loss: 0.029270019382238388
step: 450, loss: 0.08366753160953522
step: 460, loss: 0.08917303383350372
step: 470, loss: 0.02505829744040966
step: 480, loss: 0.10502753406763077
step: 490, loss: 0.017047861590981483
step: 500, loss: 0.06803353130817413
step: 510, loss: 0.0136908870190382
step: 520, loss: 0.20322778820991516
step: 530, loss: 0.10997463017702103
step: 540, loss: 0.013680702075362206
step: 550, loss: 0.12455260753631592
step: 560, loss: 0.05289391055703163
step: 570, loss: 0.055197373032569885
step: 580, loss: 0.038829099386930466
step: 590, loss: 0.00031377433333545923
step: 600, loss: 0.12286271899938583
step: 610, loss: 0.16001923382282257
step: 620, loss: 0.017016734927892685
step: 630, loss: 0.038373447954654694
step: 640, loss: 0.03490716218948364
step: 650, loss: 0.10954263061285019
step: 660, loss: 0.10104995965957642
step: 670, loss: 0.14000341296195984
step: 680, loss: 0.03178045526146889
step: 690, loss: 0.11821038275957108
step: 700, loss: 0.062407828867435455
step: 710, loss: 0.22013543546199799
step: 720, loss: 0.09284564852714539
step: 730, loss: 0.06384127587080002
step: 740, loss: 0.10930337011814117
step: 750, loss: 0.0611579455435276
step: 760, loss: 0.05765780434012413
step: 770, loss: 0.07688389718532562
step: 780, loss: 0.04867732152342796
step: 790, loss: 0.10277575254440308
step: 800, loss: 0.0744701474905014
step: 810, loss: 0.10991306602954865
step: 820, loss: 0.0734843835234642
step: 830, loss: 0.09678992629051208
step: 840, loss: 0.0370309054851532
step: 850, loss: 0.07149635255336761
step: 860, loss: 0.013779908418655396
step: 870, loss: 0.013044487684965134
step: 880, loss: 0.00018317981448490173
step: 890, loss: 0.058013323694467545
step: 900, loss: 0.039534613490104675
step: 910, loss: 0.07966213673353195
step: 920, loss: 0.041939958930015564
step: 930, loss: 0.0012024426832795143
step: 940, loss: 0.10795395076274872
step: 950, loss: 0.055105000734329224
step: 960, loss: 0.03797420114278793
step: 970, loss: 0.09100055694580078
epoch 12: dev_f1=0.9279778393351801, f1=0.919870310328856, best_f1=0.9239981575310916
step: 0, loss: 0.17041172087192535
step: 10, loss: 0.06079079955816269
step: 20, loss: 0.02535293437540531
step: 30, loss: 0.04857957735657692
step: 40, loss: 0.06952115893363953
step: 50, loss: 0.04922499880194664
step: 60, loss: 0.07316692918539047
step: 70, loss: 0.02360505424439907
step: 80, loss: 0.03946183621883392
step: 90, loss: 0.13522621989250183
step: 100, loss: 0.07978392392396927
step: 110, loss: 0.1502901166677475
step: 120, loss: 0.04617070034146309
step: 130, loss: 0.042177602648735046
step: 140, loss: 0.01122178602963686
step: 150, loss: 0.03881102055311203
step: 160, loss: 0.07121077924966812
step: 170, loss: 0.0213223397731781
step: 180, loss: 0.038310471922159195
step: 190, loss: 0.021036827936768532
step: 200, loss: 0.1002475842833519
step: 210, loss: 0.03354967013001442
step: 220, loss: 0.04738444834947586
step: 230, loss: 0.00038132723420858383
step: 240, loss: 0.15640419721603394
step: 250, loss: 0.05632641911506653
step: 260, loss: 0.0439140610396862
step: 270, loss: 0.05263173580169678
step: 280, loss: 0.09990876913070679
step: 290, loss: 0.022225266322493553
step: 300, loss: 0.04275383800268173
step: 310, loss: 0.06143032759428024
step: 320, loss: 0.018718626350164413
step: 330, loss: 0.07371547818183899
step: 340, loss: 0.05423814430832863
step: 350, loss: 0.22042584419250488
step: 360, loss: 0.043755725026130676
step: 370, loss: 0.04012811928987503
step: 380, loss: 0.09405229240655899
step: 390, loss: 0.14447671175003052
step: 400, loss: 0.0754852145910263
step: 410, loss: 0.06161048263311386
step: 420, loss: 0.05198993161320686
step: 430, loss: 0.05405692756175995
step: 440, loss: 0.04705405607819557
step: 450, loss: 0.07372954487800598
step: 460, loss: 0.01616976410150528
step: 470, loss: 0.021307578310370445
step: 480, loss: 0.0510321669280529
step: 490, loss: 0.054581962525844574
step: 500, loss: 0.049774423241615295
step: 510, loss: 0.11529094725847244
step: 520, loss: 0.03765127807855606
step: 530, loss: 0.06238478794693947
step: 540, loss: 0.0018588935490697622
step: 550, loss: 0.12411775439977646
step: 560, loss: 0.047818105667829514
step: 570, loss: 0.12040797621011734
step: 580, loss: 0.08113694190979004
step: 590, loss: 0.016319770365953445
step: 600, loss: 0.0586661733686924
step: 610, loss: 0.028232289478182793
step: 620, loss: 0.01343357190489769
step: 630, loss: 0.15320654213428497
step: 640, loss: 0.07913477718830109
step: 650, loss: 0.0238344743847847
step: 660, loss: 0.04418511688709259
step: 670, loss: 0.08366271108388901
step: 680, loss: 0.1315777748823166
step: 690, loss: 0.02115674875676632
step: 700, loss: 0.18157179653644562
step: 710, loss: 0.030106857419013977
step: 720, loss: 0.06392406672239304
step: 730, loss: 0.2273244559764862
step: 740, loss: 0.13246694207191467
step: 750, loss: 0.12040259689092636
step: 760, loss: 0.06373324990272522
step: 770, loss: 0.034271907061338425
step: 780, loss: 0.042437609285116196
step: 790, loss: 0.046911805868148804
step: 800, loss: 0.0782281756401062
step: 810, loss: 0.08352407068014145
step: 820, loss: 0.04075521230697632
step: 830, loss: 0.02143273688852787
step: 840, loss: 0.01786440797150135
step: 850, loss: 0.023813355714082718
step: 860, loss: 0.06195886805653572
step: 870, loss: 0.01692183129489422
step: 880, loss: 0.08215047419071198
step: 890, loss: 0.04357801005244255
step: 900, loss: 0.06055043637752533
step: 910, loss: 0.04212502762675285
step: 920, loss: 0.06600452214479446
step: 930, loss: 0.10882578790187836
step: 940, loss: 0.09629109501838684
step: 950, loss: 0.09802241623401642
step: 960, loss: 0.04629823565483093
step: 970, loss: 0.09114876389503479
epoch 13: dev_f1=0.9304713019132057, f1=0.9241507677989763, best_f1=0.9239981575310916
step: 0, loss: 0.03542450815439224
step: 10, loss: 0.07387226074934006
step: 20, loss: 0.003595390822738409
step: 30, loss: 0.09160283207893372
step: 40, loss: 0.03243951499462128
step: 50, loss: 0.17639397084712982
step: 60, loss: 0.03504173457622528
step: 70, loss: 0.019223567098379135
step: 80, loss: 0.08114488422870636
step: 90, loss: 0.024430662393569946
step: 100, loss: 0.04537379741668701
step: 110, loss: 0.04444871470332146
step: 120, loss: 0.11034833639860153
step: 130, loss: 0.011584406718611717
step: 140, loss: 0.04491255432367325
step: 150, loss: 0.04331372678279877
step: 160, loss: 0.04584629833698273
step: 170, loss: 0.013166421093046665
step: 180, loss: 0.13236144185066223
step: 190, loss: 0.04687458649277687
step: 200, loss: 0.044187210500240326
step: 210, loss: 0.1843598484992981
step: 220, loss: 0.03971201181411743
step: 230, loss: 0.030773429200053215
step: 240, loss: 0.10513313114643097
step: 250, loss: 0.007689322344958782
step: 260, loss: 0.10347932577133179
step: 270, loss: 0.023553989827632904
step: 280, loss: 0.060236718505620956
step: 290, loss: 0.08380080759525299
step: 300, loss: 0.05889897421002388
step: 310, loss: 0.06992485374212265
step: 320, loss: 0.07617781311273575
step: 330, loss: 0.024364402517676353
step: 340, loss: 0.019923996180295944
step: 350, loss: 0.02508821338415146
step: 360, loss: 0.12265346199274063
step: 370, loss: 0.01740947738289833
step: 380, loss: 0.07575330883264542
step: 390, loss: 0.12356751412153244
step: 400, loss: 0.06384405493736267
step: 410, loss: 0.07408193498849869
step: 420, loss: 0.061875417828559875
step: 430, loss: 0.06461621075868607
step: 440, loss: 0.05099400505423546
step: 450, loss: 0.007377771660685539
step: 460, loss: 0.03174322843551636
step: 470, loss: 0.03520707041025162
step: 480, loss: 0.10978461056947708
step: 490, loss: 0.018074387684464455
step: 500, loss: 0.16220760345458984
step: 510, loss: 0.16672049462795258
step: 520, loss: 0.07642529159784317
step: 530, loss: 0.1201493889093399
step: 540, loss: 0.019079020246863365
step: 550, loss: 0.053851500153541565
step: 560, loss: 0.0542595311999321
step: 570, loss: 0.09747481346130371
step: 580, loss: 0.14170613884925842
step: 590, loss: 0.018169494345784187
step: 600, loss: 0.08469997346401215
step: 610, loss: 0.027584146708250046
step: 620, loss: 0.05840759724378586
step: 630, loss: 0.0023289015516638756
step: 640, loss: 0.019102977588772774
step: 650, loss: 0.07803525030612946
step: 660, loss: 0.0422317236661911
step: 670, loss: 0.0434177964925766
step: 680, loss: 0.0855703055858612
step: 690, loss: 0.020192407071590424
step: 700, loss: 0.03130894526839256
step: 710, loss: 0.09537666290998459
step: 720, loss: 0.02136567421257496
step: 730, loss: 0.06808310747146606
step: 740, loss: 0.0790037140250206
step: 750, loss: 0.06801724433898926
step: 760, loss: 0.02585403062403202
step: 770, loss: 0.08443944901227951
step: 780, loss: 0.004344137851148844
step: 790, loss: 0.09988196194171906
step: 800, loss: 0.06610143929719925
step: 810, loss: 0.06061225384473801
step: 820, loss: 0.09404890239238739
step: 830, loss: 0.11284983158111572
step: 840, loss: 0.06568492203950882
step: 850, loss: 0.05229033902287483
step: 860, loss: 0.027111545205116272
step: 870, loss: 9.89018808468245e-05
step: 880, loss: 0.1046270951628685
step: 890, loss: 0.014439698308706284
step: 900, loss: 0.026009447872638702
step: 910, loss: 0.06684303283691406
step: 920, loss: 0.14457735419273376
step: 930, loss: 0.07630471885204315
step: 940, loss: 0.05937323346734047
step: 950, loss: 0.14008383452892303
step: 960, loss: 0.06350657343864441
step: 970, loss: 0.0006360872648656368
epoch 14: dev_f1=0.932274638019617, f1=0.9214218896164639, best_f1=0.9239981575310916
step: 0, loss: 0.03422554209828377
step: 10, loss: 0.03139623627066612
step: 20, loss: 0.036187030375003815
step: 30, loss: 0.028366858139634132
step: 40, loss: 0.07804067432880402
step: 50, loss: 0.06447482854127884
step: 60, loss: 0.041757747530937195
step: 70, loss: 0.012017185799777508
step: 80, loss: 0.019823115319013596
step: 90, loss: 0.0541209802031517
step: 100, loss: 0.1491420865058899
step: 110, loss: 0.00935244932770729
step: 120, loss: 0.048134829849004745
step: 130, loss: 0.04940631240606308
step: 140, loss: 0.053808726370334625
step: 150, loss: 0.17009073495864868
step: 160, loss: 0.12239789217710495
step: 170, loss: 0.022218190133571625
step: 180, loss: 0.04543589800596237
step: 190, loss: 0.00015071437519509345
step: 200, loss: 0.0631919801235199
step: 210, loss: 0.04236452281475067
step: 220, loss: 0.04724082723259926
step: 230, loss: 0.04174662381410599
step: 240, loss: 0.03646140918135643
step: 250, loss: 0.04289762303233147
step: 260, loss: 0.06812560558319092
step: 270, loss: 0.0883561447262764
step: 280, loss: 0.0819903090596199
step: 290, loss: 0.004821508191525936
step: 300, loss: 0.07710211724042892
step: 310, loss: 0.15249645709991455
step: 320, loss: 0.16391733288764954
step: 330, loss: 0.06810499727725983
step: 340, loss: 0.1766720712184906
step: 350, loss: 0.1287906914949417
step: 360, loss: 0.043761350214481354
step: 370, loss: 0.038885097950696945
step: 380, loss: 0.02809876576066017
step: 390, loss: 0.053599342703819275
step: 400, loss: 0.06387700140476227
step: 410, loss: 0.00012136750592617318
step: 420, loss: 0.06976085901260376
step: 430, loss: 0.08332468569278717
step: 440, loss: 0.0773235633969307
step: 450, loss: 0.04867516830563545
step: 460, loss: 0.03811688348650932
step: 470, loss: 0.02110978029668331
step: 480, loss: 0.02039170265197754
step: 490, loss: 0.020349565893411636
step: 500, loss: 0.062131259590387344
step: 510, loss: 0.049281030893325806
step: 520, loss: 0.059455547481775284
step: 530, loss: 0.0653189942240715
step: 540, loss: 0.06964826583862305
step: 550, loss: 0.0564345084130764
step: 560, loss: 0.0010379103478044271
step: 570, loss: 0.06330307573080063
step: 580, loss: 0.16488869488239288
step: 590, loss: 0.05962424725294113
step: 600, loss: 0.042657963931560516
step: 610, loss: 0.09112070500850677
step: 620, loss: 0.047444168478250504
step: 630, loss: 0.03941776975989342
step: 640, loss: 0.014296690002083778
step: 650, loss: 0.07635166496038437
step: 660, loss: 0.015567732974886894
step: 670, loss: 0.04918878152966499
step: 680, loss: 0.0416344590485096
step: 690, loss: 0.0015321808168664575
step: 700, loss: 0.14196063578128815
step: 710, loss: 0.03519035503268242
step: 720, loss: 0.08302884548902512
step: 730, loss: 0.03428531065583229
step: 740, loss: 0.042101792991161346
step: 750, loss: 0.07878657430410385
step: 760, loss: 0.0958174467086792
step: 770, loss: 0.04865042492747307
step: 780, loss: 0.05312313511967659
step: 790, loss: 0.06116665527224541
step: 800, loss: 0.08448117226362228
step: 810, loss: 0.012875168584287167
step: 820, loss: 0.043660521507263184
step: 830, loss: 0.12130367010831833
step: 840, loss: 0.0002383490209467709
step: 850, loss: 0.04197731986641884
step: 860, loss: 0.07738084346055984
step: 870, loss: 0.0004414558061398566
step: 880, loss: 0.04390083625912666
step: 890, loss: 0.0458238460123539
step: 900, loss: 0.13165180385112762
step: 910, loss: 0.09999360144138336
step: 920, loss: 0.024846237152814865
step: 930, loss: 0.008099811151623726
step: 940, loss: 0.0774732232093811
step: 950, loss: 0.0761132761836052
step: 960, loss: 0.04548673331737518
step: 970, loss: 0.04454904422163963
epoch 15: dev_f1=0.9279321714554876, f1=0.9198868991517437, best_f1=0.9239981575310916
step: 0, loss: 0.05284599959850311
step: 10, loss: 0.12078389525413513
step: 20, loss: 0.06700514256954193
step: 30, loss: 0.10084196925163269
step: 40, loss: 0.10814870893955231
step: 50, loss: 0.036434680223464966
step: 60, loss: 0.017140042036771774
step: 70, loss: 0.045059412717819214
step: 80, loss: 0.06527513265609741
step: 90, loss: 0.018134059384465218
step: 100, loss: 0.016768133267760277
step: 110, loss: 0.02995828166604042
step: 120, loss: 0.005546577740460634
step: 130, loss: 0.0005870690220035613
step: 140, loss: 0.048217419534921646
step: 150, loss: 0.09226047992706299
step: 160, loss: 0.08701317757368088
step: 170, loss: 0.10868951678276062
step: 180, loss: 4.5975117245689034e-05
step: 190, loss: 0.06496059894561768
step: 200, loss: 0.07525725662708282
step: 210, loss: 0.06130298972129822
step: 220, loss: 0.04440905153751373
step: 230, loss: 0.0012397837126627564
step: 240, loss: 0.10602254420518875
step: 250, loss: 4.27527011197526e-05
step: 260, loss: 0.12792405486106873
step: 270, loss: 0.0012406931491568685
step: 280, loss: 0.06323743611574173
step: 290, loss: 0.09288368374109268
step: 300, loss: 0.019289884716272354
step: 310, loss: 0.02890593372285366
step: 320, loss: 0.0644707977771759
step: 330, loss: 0.07504141330718994
step: 340, loss: 0.0033137695863842964
step: 350, loss: 0.0457366444170475
step: 360, loss: 0.03879056125879288
step: 370, loss: 0.03963562101125717
step: 380, loss: 0.08991064876317978
step: 390, loss: 0.10657783597707748
step: 400, loss: 0.0933714434504509
step: 410, loss: 0.04049069434404373
step: 420, loss: 0.04970082268118858
step: 430, loss: 0.07792472094297409
step: 440, loss: 0.008589445613324642
step: 450, loss: 0.056416191160678864
step: 460, loss: 0.022424058988690376
step: 470, loss: 0.05030526965856552
step: 480, loss: 0.03572850301861763
step: 490, loss: 0.043584972620010376
step: 500, loss: 0.03760597109794617
step: 510, loss: 0.08970233052968979
step: 520, loss: 0.0965171530842781
step: 530, loss: 0.030560610815882683
step: 540, loss: 0.049519095569849014
step: 550, loss: 0.02530447579920292
step: 560, loss: 0.021761534735560417
step: 570, loss: 0.03084816038608551
step: 580, loss: 0.03197987377643585
step: 590, loss: 0.06544293463230133
step: 600, loss: 0.14750976860523224
step: 610, loss: 0.010174554772675037
step: 620, loss: 0.03663463145494461
step: 630, loss: 0.05401873216032982
step: 640, loss: 0.0054155937395989895
step: 650, loss: 0.05610233545303345
step: 660, loss: 0.03252854198217392
step: 670, loss: 0.08479432761669159
step: 680, loss: 0.0706724151968956
step: 690, loss: 0.03262951225042343
step: 700, loss: 0.10336433351039886
step: 710, loss: 0.028638968244194984
step: 720, loss: 0.06646640598773956
step: 730, loss: 0.03375186398625374
step: 740, loss: 0.11017310619354248
step: 750, loss: 0.0645194724202156
step: 760, loss: 0.012839957140386105
step: 770, loss: 0.40562325716018677
step: 780, loss: 0.0902104526758194
step: 790, loss: 0.08731714636087418
step: 800, loss: 0.03873107209801674
step: 810, loss: 0.0035846452228724957
step: 820, loss: 0.07423245906829834
step: 830, loss: 0.19781151413917542
step: 840, loss: 0.11851603537797928
step: 850, loss: 0.053608961403369904
step: 860, loss: 0.03991003334522247
step: 870, loss: 0.000576391292270273
step: 880, loss: 0.056601427495479584
step: 890, loss: 0.019324302673339844
step: 900, loss: 0.08424658328294754
step: 910, loss: 0.0963519960641861
step: 920, loss: 0.06252572685480118
step: 930, loss: 0.1033049002289772
step: 940, loss: 0.040067046880722046
step: 950, loss: 0.035129379481077194
step: 960, loss: 0.000179672846570611
step: 970, loss: 0.07893956452608109
epoch 16: dev_f1=0.9296947271045328, f1=0.9232192414431082, best_f1=0.9239981575310916
step: 0, loss: 0.016779817640781403
step: 10, loss: 0.07125202566385269
step: 20, loss: 0.01811264269053936
step: 30, loss: 0.03555256873369217
step: 40, loss: 0.03706321865320206
step: 50, loss: 0.07707301527261734
step: 60, loss: 0.06318750232458115
step: 70, loss: 0.05681617930531502
step: 80, loss: 0.08946485072374344
step: 90, loss: 0.04290897771716118
step: 100, loss: 0.03530871868133545
step: 110, loss: 0.020395463332533836
step: 120, loss: 0.03253839164972305
step: 130, loss: 0.08768858015537262
step: 140, loss: 0.03995804861187935
step: 150, loss: 0.006684540305286646
step: 160, loss: 0.051036536693573
step: 170, loss: 0.030452078208327293
step: 180, loss: 0.030328989028930664
step: 190, loss: 0.07513924688100815
step: 200, loss: 0.08200918138027191
step: 210, loss: 0.02627435326576233
step: 220, loss: 0.09785249084234238
step: 230, loss: 0.03592211753129959
step: 240, loss: 0.05026699975132942
step: 250, loss: 0.019742602482438087
step: 260, loss: 0.06356778740882874
step: 270, loss: 0.06279022246599197
step: 280, loss: 0.07130102813243866
step: 290, loss: 0.03004780411720276
step: 300, loss: 0.04540820047259331
step: 310, loss: 0.0006513863336294889
step: 320, loss: 0.047767989337444305
step: 330, loss: 0.11351555585861206
step: 340, loss: 0.01751812919974327
step: 350, loss: 0.05574667081236839
step: 360, loss: 0.07150761038064957
step: 370, loss: 0.00012105063797207549
step: 380, loss: 0.022007953375577927
step: 390, loss: 0.0713716670870781
step: 400, loss: 0.037348467856645584
step: 410, loss: 0.03380386531352997
step: 420, loss: 0.107830710709095
step: 430, loss: 0.030912643298506737
step: 440, loss: 0.0646873340010643
step: 450, loss: 0.08906827121973038
step: 460, loss: 0.023160329088568687
step: 470, loss: 0.05402407422661781
step: 480, loss: 0.08550392091274261
step: 490, loss: 0.044914159923791885
step: 500, loss: 0.055281370878219604
step: 510, loss: 0.015010303817689419
step: 520, loss: 0.05624707415699959
step: 530, loss: 0.0008616326958872378
step: 540, loss: 0.09233343601226807
step: 550, loss: 0.09650770574808121
step: 560, loss: 0.059606242924928665
step: 570, loss: 0.025713030248880386
step: 580, loss: 0.04772531986236572
step: 590, loss: 0.010907852090895176
step: 600, loss: 0.022507591173052788
step: 610, loss: 0.09581679850816727
step: 620, loss: 0.013344702310860157
step: 630, loss: 0.017276404425501823
step: 640, loss: 0.06122966483235359
step: 650, loss: 0.007532645016908646
step: 660, loss: 0.023186717182397842
step: 670, loss: 0.03791302815079689
step: 680, loss: 0.11986619979143143
step: 690, loss: 0.06993833929300308
step: 700, loss: 0.04936812445521355
step: 710, loss: 0.08744466304779053
step: 720, loss: 0.049632757902145386
step: 730, loss: 0.026524685323238373
step: 740, loss: 0.11949655413627625
step: 750, loss: 0.13180923461914062
step: 760, loss: 0.03561374172568321
step: 770, loss: 0.060794897377491
step: 780, loss: 0.015503008849918842
step: 790, loss: 0.1870581954717636
step: 800, loss: 0.049752216786146164
step: 810, loss: 0.06600945442914963
step: 820, loss: 0.05664532259106636
step: 830, loss: 0.015906739979982376
step: 840, loss: 0.06607084721326828
step: 850, loss: 0.045948609709739685
step: 860, loss: 0.06215788796544075
step: 870, loss: 0.005195770878344774
step: 880, loss: 0.029955929145216942
step: 890, loss: 4.289612843422219e-05
step: 900, loss: 0.1925487220287323
step: 910, loss: 0.021202504634857178
step: 920, loss: 0.011497540399432182
step: 930, loss: 0.04132115840911865
step: 940, loss: 0.05206625163555145
step: 950, loss: 0.015099323354661465
step: 960, loss: 0.041807353496551514
step: 970, loss: 0.04869206249713898
epoch 17: dev_f1=0.9292364990689013, f1=0.9213587715216379, best_f1=0.9239981575310916
step: 0, loss: 0.044133275747299194
step: 10, loss: 0.056843988597393036
step: 20, loss: 0.0008065372239798307
step: 30, loss: 0.02283087931573391
step: 40, loss: 0.10784178227186203
step: 50, loss: 0.0199966412037611
step: 60, loss: 0.03558098152279854
step: 70, loss: 1.3566954294219613e-05
step: 80, loss: 0.00011078321404056624
step: 90, loss: 0.07668246328830719
step: 100, loss: 0.0005436117062345147
step: 110, loss: 0.0509565994143486
step: 120, loss: 0.03788246214389801
step: 130, loss: 0.017083236947655678
step: 140, loss: 0.020911965519189835
step: 150, loss: 0.08007732778787613
step: 160, loss: 0.046984944492578506
step: 170, loss: 0.13069427013397217
step: 180, loss: 0.016861122101545334
step: 190, loss: 0.045093197375535965
step: 200, loss: 3.3607910154387355e-05
step: 210, loss: 0.09543850272893906
step: 220, loss: 0.03132760897278786
step: 230, loss: 0.058323003351688385
step: 240, loss: 0.08288664370775223
step: 250, loss: 0.10602142661809921
step: 260, loss: 0.019087782129645348
step: 270, loss: 0.04631195217370987
step: 280, loss: 0.04237211495637894
step: 290, loss: 0.048924051225185394
step: 300, loss: 0.03860862925648689
step: 310, loss: 0.06904780864715576
step: 320, loss: 0.09323874861001968
step: 330, loss: 0.1270633488893509
step: 340, loss: 0.0451526902616024
step: 350, loss: 0.0018754593329504132
step: 360, loss: 0.0055520436726510525
step: 370, loss: 0.019810613244771957
step: 380, loss: 0.026713503524661064
step: 390, loss: 0.0485478900372982
step: 400, loss: 0.027234558016061783
step: 410, loss: 0.04061739146709442
step: 420, loss: 0.0656898096203804
step: 430, loss: 0.021139562129974365
step: 440, loss: 0.04146897792816162
step: 450, loss: 0.12115731090307236
step: 460, loss: 0.047987014055252075
step: 470, loss: 0.040680091828107834
step: 480, loss: 0.044637035578489304
step: 490, loss: 0.05990692600607872
step: 500, loss: 0.031008243560791016
step: 510, loss: 0.1358184963464737
step: 520, loss: 0.06641730666160583
step: 530, loss: 0.07603096216917038
step: 540, loss: 0.055387258529663086
step: 550, loss: 0.04698040708899498
step: 560, loss: 0.04830377548933029
step: 570, loss: 0.07528433203697205
step: 580, loss: 0.033307623118162155
step: 590, loss: 0.002572921570390463
step: 600, loss: 0.18814006447792053
step: 610, loss: 0.07222507148981094
step: 620, loss: 3.506206485326402e-05
step: 630, loss: 0.014464225620031357
step: 640, loss: 0.05449632927775383
step: 650, loss: 0.030959496274590492
step: 660, loss: 0.13115638494491577
step: 670, loss: 0.09829854220151901
step: 680, loss: 0.08944035321474075
step: 690, loss: 0.0005139969871379435
step: 700, loss: 0.08296044915914536
step: 710, loss: 0.012180887162685394
step: 720, loss: 0.05996880307793617
step: 730, loss: 0.04385702311992645
step: 740, loss: 0.10015172511339188
step: 750, loss: 0.045204225927591324
step: 760, loss: 0.0151283647865057
step: 770, loss: 0.0016504540108144283
step: 780, loss: 0.08214375376701355
step: 790, loss: 0.059570278972387314
step: 800, loss: 0.020542461425065994
step: 810, loss: 0.05734695494174957
step: 820, loss: 0.0001510507136117667
step: 830, loss: 0.07890301197767258
step: 840, loss: 0.10163884609937668
step: 850, loss: 0.08120818436145782
step: 860, loss: 0.21051917970180511
step: 870, loss: 0.07138153910636902
step: 880, loss: 0.06741046905517578
step: 890, loss: 0.01387758832424879
step: 900, loss: 0.03623034805059433
step: 910, loss: 0.10589268058538437
step: 920, loss: 0.00023637746926397085
step: 930, loss: 0.0842055082321167
step: 940, loss: 0.026676030829548836
step: 950, loss: 0.008337934501469135
step: 960, loss: 0.04576173797249794
step: 970, loss: 0.06170323118567467
epoch 18: dev_f1=0.9298823529411765, f1=0.9222065063649223, best_f1=0.9239981575310916
step: 0, loss: 0.06288093328475952
step: 10, loss: 0.12328747659921646
step: 20, loss: 0.05948570743203163
step: 30, loss: 0.15359042584896088
step: 40, loss: 0.022625036537647247
step: 50, loss: 0.058702126145362854
step: 60, loss: 0.02055586501955986
step: 70, loss: 0.0621148943901062
step: 80, loss: 0.08209207653999329
step: 90, loss: 0.13242748379707336
step: 100, loss: 0.039675988256931305
step: 110, loss: 0.006411689333617687
step: 120, loss: 0.0740506649017334
step: 130, loss: 0.02608531154692173
step: 140, loss: 0.02301357313990593
step: 150, loss: 0.02849697135388851
step: 160, loss: 0.04548026621341705
step: 170, loss: 0.02659280225634575
step: 180, loss: 5.4563213780056685e-05
step: 190, loss: 0.00013311517250258476
step: 200, loss: 0.04675598815083504
step: 210, loss: 0.0738593116402626
step: 220, loss: 0.03723086789250374
step: 230, loss: 0.05223516747355461
step: 240, loss: 8.67252892930992e-05
step: 250, loss: 0.03198657184839249
step: 260, loss: 0.04517550393939018
step: 270, loss: 0.008904303424060345
step: 280, loss: 0.10175510495901108
step: 290, loss: 0.08788087218999863
step: 300, loss: 0.037446897476911545
step: 310, loss: 0.03546544536948204
step: 320, loss: 0.03743385151028633
step: 330, loss: 0.022968608886003494
step: 340, loss: 0.06909371167421341
step: 350, loss: 0.07041668891906738
step: 360, loss: 0.04143558442592621
step: 370, loss: 0.02252902276813984
step: 380, loss: 0.038704194128513336
step: 390, loss: 0.01326548308134079
step: 400, loss: 0.0551363080739975
step: 410, loss: 0.013959682546555996
step: 420, loss: 0.030292591080069542
step: 430, loss: 0.03333665803074837
step: 440, loss: 0.03474967181682587
step: 450, loss: 0.04222378134727478
step: 460, loss: 0.054215967655181885
step: 470, loss: 0.02912435308098793
step: 480, loss: 0.0245563555508852
step: 490, loss: 0.09347320348024368
step: 500, loss: 0.0030934701208025217
step: 510, loss: 0.01864904724061489
step: 520, loss: 0.04315785691142082
step: 530, loss: 0.07526778429746628
step: 540, loss: 0.0325079970061779
step: 550, loss: 0.027454862371087074
step: 560, loss: 0.03588926047086716
step: 570, loss: 0.03215539827942848
step: 580, loss: 0.1252477467060089
step: 590, loss: 0.03913222625851631
step: 600, loss: 0.04064711183309555
step: 610, loss: 0.03439728543162346
step: 620, loss: 0.0001435069862054661
step: 630, loss: 0.1706611067056656
step: 640, loss: 0.021723836660385132
step: 650, loss: 0.2534606456756592
step: 660, loss: 0.01976022683084011
step: 670, loss: 0.06564120203256607
step: 680, loss: 0.13702179491519928
step: 690, loss: 0.06462857872247696
step: 700, loss: 0.053655024617910385
step: 710, loss: 0.09150402992963791
step: 720, loss: 0.062046755105257034
step: 730, loss: 0.0413862019777298
step: 740, loss: 0.042999040335416794
step: 750, loss: 0.0626150518655777
step: 760, loss: 0.01673537865281105
step: 770, loss: 0.09362123906612396
step: 780, loss: 0.07576115429401398
step: 790, loss: 0.08004079759120941
step: 800, loss: 0.0711776465177536
step: 810, loss: 0.03813087195158005
step: 820, loss: 0.00047595391515642405
step: 830, loss: 0.16365493834018707
step: 840, loss: 0.07890218496322632
step: 850, loss: 0.05723382160067558
step: 860, loss: 0.14143653213977814
step: 870, loss: 0.10407628864049911
step: 880, loss: 0.0029254043474793434
step: 890, loss: 0.04639231786131859
step: 900, loss: 0.05863889679312706
step: 910, loss: 0.0337548553943634
step: 920, loss: 0.08952422440052032
step: 930, loss: 0.06906740367412567
step: 940, loss: 0.05475952848792076
step: 950, loss: 0.09249788522720337
step: 960, loss: 0.02049635723233223
step: 970, loss: 0.03734665736556053
epoch 19: dev_f1=0.9300373134328358, f1=0.9182624941616068, best_f1=0.9239981575310916
step: 0, loss: 0.06773675978183746
step: 10, loss: 0.03983296453952789
step: 20, loss: 0.08043951541185379
step: 30, loss: 0.05335339531302452
step: 40, loss: 0.0198558047413826
step: 50, loss: 0.03056936152279377
step: 60, loss: 0.03817120939493179
step: 70, loss: 0.023736290633678436
step: 80, loss: 0.04857220873236656
step: 90, loss: 0.042176131159067154
step: 100, loss: 0.045113395899534225
step: 110, loss: 0.16146934032440186
step: 120, loss: 0.07377393543720245
step: 130, loss: 0.1102294847369194
step: 140, loss: 0.061494745314121246
step: 150, loss: 0.03428168222308159
step: 160, loss: 0.01667683944106102
step: 170, loss: 0.11928858608007431
step: 180, loss: 0.024620534852147102
step: 190, loss: 0.030658626928925514
step: 200, loss: 0.03379182890057564
step: 210, loss: 0.0783798024058342
step: 220, loss: 0.08916469663381577
step: 230, loss: 0.03915983438491821
step: 240, loss: 0.11178141087293625
step: 250, loss: 0.10985260456800461
step: 260, loss: 0.057562291622161865
step: 270, loss: 0.05059342086315155
step: 280, loss: 0.10657552629709244
step: 290, loss: 0.0378766804933548
step: 300, loss: 0.04786993935704231
step: 310, loss: 0.036044541746377945
step: 320, loss: 0.10872698575258255
step: 330, loss: 0.057599570602178574
step: 340, loss: 0.019653603434562683
step: 350, loss: 0.05893572419881821
step: 360, loss: 0.03944212198257446
step: 370, loss: 0.02470020204782486
step: 380, loss: 0.027101194486021996
step: 390, loss: 0.06540374457836151
step: 400, loss: 0.06090392917394638
step: 410, loss: 0.0018477258272469044
step: 420, loss: 0.151430144906044
step: 430, loss: 0.05183640122413635
step: 440, loss: 0.0162421315908432
step: 450, loss: 0.01866408810019493
step: 460, loss: 0.019316185265779495
step: 470, loss: 0.07588827610015869
step: 480, loss: 0.055410124361515045
step: 490, loss: 0.042499419301748276
step: 500, loss: 0.00032713369000703096
step: 510, loss: 0.030460454523563385
step: 520, loss: 0.021219704300165176
step: 530, loss: 0.02058747224509716
step: 540, loss: 0.08584566414356232
step: 550, loss: 0.04192092642188072
step: 560, loss: 0.06246083229780197
step: 570, loss: 0.057578835636377335
step: 580, loss: 0.04849276691675186
step: 590, loss: 0.04550616443157196
step: 600, loss: 0.06147623434662819
step: 610, loss: 0.09872689843177795
step: 620, loss: 0.010002989321947098
step: 630, loss: 0.0591004453599453
step: 640, loss: 0.0368155837059021
step: 650, loss: 0.05604024603962898
step: 660, loss: 0.020690549165010452
step: 670, loss: 0.00012299403897486627
step: 680, loss: 0.026935605332255363
step: 690, loss: 0.025584697723388672
step: 700, loss: 0.0680081769824028
step: 710, loss: 0.04035437852144241
step: 720, loss: 0.014433056116104126
step: 730, loss: 0.10115975141525269
step: 740, loss: 0.06740506738424301
step: 750, loss: 0.055816154927015305
step: 760, loss: 0.047070614993572235
step: 770, loss: 0.021178122609853745
step: 780, loss: 0.04182566702365875
step: 790, loss: 0.10957062244415283
step: 800, loss: 0.038762278854846954
step: 810, loss: 0.05610053613781929
step: 820, loss: 0.00039014581125229597
step: 830, loss: 0.03292722627520561
step: 840, loss: 0.028554385527968407
step: 850, loss: 0.03153900057077408
step: 860, loss: 0.04216022789478302
step: 870, loss: 0.1271134316921234
step: 880, loss: 0.06462225317955017
step: 890, loss: 0.013478613458573818
step: 900, loss: 0.07129595428705215
step: 910, loss: 0.09818631410598755
step: 920, loss: 0.05836852267384529
step: 930, loss: 0.0689888596534729
step: 940, loss: 0.043567955493927
step: 950, loss: 0.06687101721763611
step: 960, loss: 0.00021353148622438312
step: 970, loss: 0.04482986778020859
epoch 20: dev_f1=0.9308885754583921, f1=0.9213377296278851, best_f1=0.9239981575310916
