cuda
Device: cuda
step: 0, loss: 0.5410798192024231
step: 10, loss: 0.37366414070129395
step: 20, loss: 0.25152090191841125
step: 30, loss: 0.3496421277523041
step: 40, loss: 0.36029282212257385
step: 50, loss: 0.2882217764854431
step: 60, loss: 0.13645035028457642
step: 70, loss: 0.051336780190467834
step: 80, loss: 0.12463461607694626
step: 90, loss: 0.08733248710632324
step: 100, loss: 0.20893770456314087
step: 110, loss: 0.1068645641207695
step: 120, loss: 0.16257959604263306
step: 130, loss: 0.1536771059036255
step: 140, loss: 0.12791918218135834
step: 150, loss: 0.2480584979057312
step: 160, loss: 0.11267454922199249
step: 170, loss: 0.48650139570236206
step: 180, loss: 0.22210483253002167
step: 190, loss: 0.037749823182821274
step: 200, loss: 0.16240732371807098
step: 210, loss: 0.14148476719856262
step: 220, loss: 0.305762380361557
step: 230, loss: 0.07203719764947891
step: 240, loss: 0.11850687116384506
step: 250, loss: 0.13580456376075745
step: 260, loss: 0.14405959844589233
step: 270, loss: 0.1666320562362671
step: 280, loss: 0.16866393387317657
step: 290, loss: 0.13521039485931396
step: 300, loss: 0.18121537566184998
step: 310, loss: 0.20244765281677246
step: 320, loss: 0.10914521664381027
step: 330, loss: 0.17545939981937408
step: 340, loss: 0.09936564415693283
step: 350, loss: 0.1429486721754074
step: 360, loss: 0.07319474965333939
step: 370, loss: 0.12804454565048218
step: 380, loss: 0.1182185485959053
step: 390, loss: 0.1945137232542038
step: 400, loss: 0.06036001443862915
step: 410, loss: 0.1397886872291565
step: 420, loss: 0.12833115458488464
step: 430, loss: 0.12688672542572021
step: 440, loss: 0.16452255845069885
step: 450, loss: 0.09494364261627197
step: 460, loss: 0.16143745183944702
step: 470, loss: 0.2620041072368622
step: 480, loss: 0.05246654525399208
step: 490, loss: 0.11171118170022964
step: 500, loss: 0.08677636831998825
step: 510, loss: 0.43969330191612244
step: 520, loss: 0.12390673160552979
step: 530, loss: 0.17218081653118134
step: 540, loss: 0.13197481632232666
step: 550, loss: 0.28323349356651306
step: 560, loss: 0.08247394859790802
step: 570, loss: 0.051070183515548706
step: 580, loss: 0.28171756863594055
step: 590, loss: 0.09789057075977325
step: 600, loss: 0.3382495939731598
step: 610, loss: 0.19567376375198364
step: 620, loss: 0.17506587505340576
step: 630, loss: 0.20005397498607635
step: 640, loss: 0.21164259314537048
step: 650, loss: 0.2383994162082672
step: 660, loss: 0.03423399105668068
step: 670, loss: 0.2051011323928833
step: 680, loss: 0.07348215579986572
step: 690, loss: 0.0963275209069252
step: 700, loss: 0.28320425748825073
step: 710, loss: 0.15321509540081024
step: 720, loss: 0.1560313105583191
step: 730, loss: 0.10951295495033264
step: 740, loss: 0.12575432658195496
step: 750, loss: 0.19265325367450714
step: 760, loss: 0.188656285405159
step: 770, loss: 0.2143811136484146
step: 780, loss: 0.03597424179315567
step: 790, loss: 0.29847508668899536
step: 800, loss: 0.16726906597614288
step: 810, loss: 0.24456006288528442
step: 820, loss: 0.1712430864572525
step: 830, loss: 0.17196756601333618
step: 840, loss: 0.036598943173885345
step: 850, loss: 0.09752421081066132
step: 860, loss: 0.2527819275856018
step: 870, loss: 0.13624954223632812
step: 880, loss: 0.09229973703622818
step: 890, loss: 0.1644221544265747
step: 900, loss: 0.11236944794654846
step: 910, loss: 0.14132343232631683
step: 920, loss: 0.19180922210216522
step: 930, loss: 0.0732102170586586
step: 940, loss: 0.10736396163702011
step: 950, loss: 0.20591241121292114
step: 960, loss: 0.1132633164525032
step: 970, loss: 0.13067327439785004
epoch 1: dev_f1=0.9162516976007242, f1=0.910481331533963, best_f1=0.910481331533963
step: 0, loss: 0.14687617123126984
step: 10, loss: 0.11506393551826477
step: 20, loss: 0.11536066234111786
step: 30, loss: 0.2070596069097519
step: 40, loss: 0.08157607167959213
step: 50, loss: 0.07941709458827972
step: 60, loss: 0.17673146724700928
step: 70, loss: 0.08884622901678085
step: 80, loss: 0.32661375403404236
step: 90, loss: 0.1198798418045044
step: 100, loss: 0.2032538801431656
step: 110, loss: 0.03966183215379715
step: 120, loss: 0.04691426455974579
step: 130, loss: 0.031767550855875015
step: 140, loss: 0.0837334617972374
step: 150, loss: 0.2750207185745239
step: 160, loss: 0.16430309414863586
step: 170, loss: 0.19876743853092194
step: 180, loss: 0.15978330373764038
step: 190, loss: 0.06845497339963913
step: 200, loss: 0.11658517271280289
step: 210, loss: 0.09091927111148834
step: 220, loss: 0.08405172824859619
step: 230, loss: 0.16858088970184326
step: 240, loss: 0.21679680049419403
step: 250, loss: 0.10456898808479309
step: 260, loss: 0.04516591504216194
step: 270, loss: 0.16229276359081268
step: 280, loss: 0.1899772584438324
step: 290, loss: 0.17810934782028198
step: 300, loss: 0.08590967208147049
step: 310, loss: 0.12330153584480286
step: 320, loss: 0.15866698324680328
step: 330, loss: 0.24526400864124298
step: 340, loss: 0.07076156884431839
step: 350, loss: 0.08247459679841995
step: 360, loss: 0.11188321560621262
step: 370, loss: 0.06461766362190247
step: 380, loss: 0.09949389100074768
step: 390, loss: 0.0984458178281784
step: 400, loss: 0.07128821313381195
step: 410, loss: 0.23063267767429352
step: 420, loss: 0.029529256746172905
step: 430, loss: 0.05966213345527649
step: 440, loss: 0.09846335649490356
step: 450, loss: 0.20251820981502533
step: 460, loss: 0.07426460087299347
step: 470, loss: 0.2609889507293701
step: 480, loss: 0.14565977454185486
step: 490, loss: 0.21179232001304626
step: 500, loss: 0.1700925976037979
step: 510, loss: 0.09812752902507782
step: 520, loss: 0.20198236405849457
step: 530, loss: 0.13169530034065247
step: 540, loss: 0.07183059304952621
step: 550, loss: 0.1416272670030594
step: 560, loss: 0.21886257827281952
step: 570, loss: 0.022764546796679497
step: 580, loss: 0.10273537039756775
step: 590, loss: 0.19079086184501648
step: 600, loss: 0.10015701502561569
step: 610, loss: 0.14537139236927032
step: 620, loss: 0.08763226866722107
step: 630, loss: 0.1658768504858017
step: 640, loss: 0.23985768854618073
step: 650, loss: 0.0963788628578186
step: 660, loss: 0.07862674444913864
step: 670, loss: 0.22568462789058685
step: 680, loss: 0.13341619074344635
step: 690, loss: 0.13389143347740173
step: 700, loss: 0.12492432445287704
step: 710, loss: 0.12667636573314667
step: 720, loss: 0.17945435643196106
step: 730, loss: 0.13216988742351532
step: 740, loss: 0.06673578172922134
step: 750, loss: 0.215670645236969
step: 760, loss: 0.14269709587097168
step: 770, loss: 0.056521881371736526
step: 780, loss: 0.11065717786550522
step: 790, loss: 0.3154370188713074
step: 800, loss: 0.0811244398355484
step: 810, loss: 0.0707472711801529
step: 820, loss: 0.05782584473490715
step: 830, loss: 0.0766763836145401
step: 840, loss: 0.2332395315170288
step: 850, loss: 0.07232281565666199
step: 860, loss: 0.09382743388414383
step: 870, loss: 0.12434510886669159
step: 880, loss: 0.10768164694309235
step: 890, loss: 0.22549009323120117
step: 900, loss: 0.04468991607427597
step: 910, loss: 0.12073058634996414
step: 920, loss: 0.11678171902894974
step: 930, loss: 0.21187573671340942
step: 940, loss: 0.04922099784016609
step: 950, loss: 0.1703549325466156
step: 960, loss: 0.07572846114635468
step: 970, loss: 0.24933798611164093
epoch 2: dev_f1=0.9356505401596994, f1=0.927468413664015, best_f1=0.927468413664015
step: 0, loss: 0.126124307513237
step: 10, loss: 0.13383673131465912
step: 20, loss: 0.09696140885353088
step: 30, loss: 0.06499622017145157
step: 40, loss: 0.05576305836439133
step: 50, loss: 0.18743564188480377
step: 60, loss: 0.31329718232154846
step: 70, loss: 0.04748094826936722
step: 80, loss: 0.11573867499828339
step: 90, loss: 0.21705180406570435
step: 100, loss: 0.19335956871509552
step: 110, loss: 0.06531896442174911
step: 120, loss: 0.10267751663923264
step: 130, loss: 0.09702979028224945
step: 140, loss: 0.10024651885032654
step: 150, loss: 0.11399061977863312
step: 160, loss: 0.11053008586168289
step: 170, loss: 0.1601647585630417
step: 180, loss: 0.07765547186136246
step: 190, loss: 0.07906375825405121
step: 200, loss: 0.10059849172830582
step: 210, loss: 0.10693541914224625
step: 220, loss: 0.1332370489835739
step: 230, loss: 0.15921668708324432
step: 240, loss: 0.15550589561462402
step: 250, loss: 0.10863816738128662
step: 260, loss: 0.04725717380642891
step: 270, loss: 0.14832262694835663
step: 280, loss: 0.11121625453233719
step: 290, loss: 0.1672700196504593
step: 300, loss: 0.06426665186882019
step: 310, loss: 0.10351862013339996
step: 320, loss: 0.12212706357240677
step: 330, loss: 0.13325917720794678
step: 340, loss: 0.08001360297203064
step: 350, loss: 0.03342437371611595
step: 360, loss: 0.12531641125679016
step: 370, loss: 0.19352518022060394
step: 380, loss: 0.14116472005844116
step: 390, loss: 0.04282166436314583
step: 400, loss: 0.07068853825330734
step: 410, loss: 0.11771143972873688
step: 420, loss: 0.1240653544664383
step: 430, loss: 0.08447771519422531
step: 440, loss: 0.050739072263240814
step: 450, loss: 0.1262790411710739
step: 460, loss: 0.266730934381485
step: 470, loss: 0.055151473730802536
step: 480, loss: 0.32130885124206543
step: 490, loss: 0.10276290029287338
step: 500, loss: 0.13146886229515076
step: 510, loss: 0.05185636132955551
step: 520, loss: 0.15251316130161285
step: 530, loss: 0.09392920881509781
step: 540, loss: 0.15532781183719635
step: 550, loss: 0.09742023050785065
step: 560, loss: 0.14844366908073425
step: 570, loss: 0.15027804672718048
step: 580, loss: 0.08889183402061462
step: 590, loss: 0.05984332412481308
step: 600, loss: 0.07994372397661209
step: 610, loss: 0.14704449474811554
step: 620, loss: 0.1861962080001831
step: 630, loss: 0.0813356563448906
step: 640, loss: 0.16922707855701447
step: 650, loss: 0.14102382957935333
step: 660, loss: 0.11545617878437042
step: 670, loss: 0.22972245514392853
step: 680, loss: 0.14521367847919464
step: 690, loss: 0.022321792319417
step: 700, loss: 0.11028480529785156
step: 710, loss: 0.0359485000371933
step: 720, loss: 0.009125815704464912
step: 730, loss: 0.07878373563289642
step: 740, loss: 0.12897458672523499
step: 750, loss: 0.10314915329217911
step: 760, loss: 0.03541644662618637
step: 770, loss: 0.05508435517549515
step: 780, loss: 0.16133300960063934
step: 790, loss: 0.12235870212316513
step: 800, loss: 0.0885004922747612
step: 810, loss: 0.1790870726108551
step: 820, loss: 0.13103985786437988
step: 830, loss: 0.12343194335699081
step: 840, loss: 0.15251438319683075
step: 850, loss: 0.15203872323036194
step: 860, loss: 0.19949720799922943
step: 870, loss: 0.06283679604530334
step: 880, loss: 0.07445681095123291
step: 890, loss: 0.09726076573133469
step: 900, loss: 0.16917088627815247
step: 910, loss: 0.30090415477752686
step: 920, loss: 0.15852536261081696
step: 930, loss: 0.029167095199227333
step: 940, loss: 0.1864330917596817
step: 950, loss: 0.15104645490646362
step: 960, loss: 0.15860077738761902
step: 970, loss: 0.06322812288999557
epoch 3: dev_f1=0.9205328433624255, f1=0.9260273972602739, best_f1=0.927468413664015
step: 0, loss: 0.055154286324977875
step: 10, loss: 0.1559753715991974
step: 20, loss: 0.09257350116968155
step: 30, loss: 0.21013222634792328
step: 40, loss: 0.1610601246356964
step: 50, loss: 0.01704789511859417
step: 60, loss: 0.029406648129224777
step: 70, loss: 0.02696239948272705
step: 80, loss: 0.23245596885681152
step: 90, loss: 0.07609189301729202
step: 100, loss: 0.09341219812631607
step: 110, loss: 0.12878569960594177
step: 120, loss: 0.19859449565410614
step: 130, loss: 0.08216633647680283
step: 140, loss: 0.040584493428468704
step: 150, loss: 0.12782324850559235
step: 160, loss: 0.10074395686388016
step: 170, loss: 0.07162325084209442
step: 180, loss: 0.17935803532600403
step: 190, loss: 0.17352840304374695
step: 200, loss: 0.09133778512477875
step: 210, loss: 0.07807919383049011
step: 220, loss: 0.15274888277053833
step: 230, loss: 0.037634264677762985
step: 240, loss: 0.20595614612102509
step: 250, loss: 0.06047481298446655
step: 260, loss: 0.17132540047168732
step: 270, loss: 0.049397148191928864
step: 280, loss: 0.16411341726779938
step: 290, loss: 0.07540857046842575
step: 300, loss: 0.1482934057712555
step: 310, loss: 0.03879545256495476
step: 320, loss: 0.14653709530830383
step: 330, loss: 0.10299067944288254
step: 340, loss: 0.05660407617688179
step: 350, loss: 0.09147937595844269
step: 360, loss: 0.10971691459417343
step: 370, loss: 0.15921944379806519
step: 380, loss: 0.032976072281599045
step: 390, loss: 0.1932711899280548
step: 400, loss: 0.023190239444375038
step: 410, loss: 0.04110230132937431
step: 420, loss: 0.09067726135253906
step: 430, loss: 0.18526700139045715
step: 440, loss: 0.20424652099609375
step: 450, loss: 0.13036249577999115
step: 460, loss: 0.14987444877624512
step: 470, loss: 0.1507434844970703
step: 480, loss: 0.11913763731718063
step: 490, loss: 0.24276988208293915
step: 500, loss: 0.24554365873336792
step: 510, loss: 0.18781571090221405
step: 520, loss: 0.07793562859296799
step: 530, loss: 0.10902582854032516
step: 540, loss: 0.16789162158966064
step: 550, loss: 0.10178478807210922
step: 560, loss: 0.043460916727781296
step: 570, loss: 0.1533801406621933
step: 580, loss: 0.15493258833885193
step: 590, loss: 0.08275154232978821
step: 600, loss: 0.08514256775379181
step: 610, loss: 0.13890735805034637
step: 620, loss: 0.10163553804159164
step: 630, loss: 0.20061460137367249
step: 640, loss: 0.0906490832567215
step: 650, loss: 0.18794183433055878
step: 660, loss: 0.1513141244649887
step: 670, loss: 0.17763453722000122
step: 680, loss: 0.08793629705905914
step: 690, loss: 0.2976475656032562
step: 700, loss: 0.07113178819417953
step: 710, loss: 0.06952465325593948
step: 720, loss: 0.16586190462112427
step: 730, loss: 0.08956485241651535
step: 740, loss: 0.07163694500923157
step: 750, loss: 0.17732052505016327
step: 760, loss: 0.21344777941703796
step: 770, loss: 0.10597189515829086
step: 780, loss: 0.14225199818611145
step: 790, loss: 0.05047324672341347
step: 800, loss: 0.18840357661247253
step: 810, loss: 0.08314581960439682
step: 820, loss: 0.08525492250919342
step: 830, loss: 0.056511200964450836
step: 840, loss: 0.050879791378974915
step: 850, loss: 0.15099485218524933
step: 860, loss: 0.10761389881372452
step: 870, loss: 0.07608872652053833
step: 880, loss: 0.11174449324607849
step: 890, loss: 0.11007065325975418
step: 900, loss: 0.04377993941307068
step: 910, loss: 0.02336273156106472
step: 920, loss: 0.13822579383850098
step: 930, loss: 0.055810511112213135
step: 940, loss: 0.04839096963405609
step: 950, loss: 0.04417318105697632
step: 960, loss: 0.055554769933223724
step: 970, loss: 0.0896865501999855
epoch 4: dev_f1=0.9160649819494584, f1=0.9180624717066546, best_f1=0.927468413664015
step: 0, loss: 0.04613252356648445
step: 10, loss: 0.0843707025051117
step: 20, loss: 0.10758977383375168
step: 30, loss: 0.061900295317173004
step: 40, loss: 0.017969153821468353
step: 50, loss: 0.0380239337682724
step: 60, loss: 0.0908302292227745
step: 70, loss: 0.07929543405771255
step: 80, loss: 0.06425341963768005
step: 90, loss: 0.17093853652477264
step: 100, loss: 0.14407725632190704
step: 110, loss: 0.14193406701087952
step: 120, loss: 0.22895236313343048
step: 130, loss: 0.06739214807748795
step: 140, loss: 0.07932572066783905
step: 150, loss: 0.132674902677536
step: 160, loss: 0.11169875413179398
step: 170, loss: 0.12397286295890808
step: 180, loss: 0.0841532051563263
step: 190, loss: 0.1259128749370575
step: 200, loss: 0.09440375119447708
step: 210, loss: 0.08642222732305527
step: 220, loss: 0.12289506196975708
step: 230, loss: 0.35374173521995544
step: 240, loss: 0.06575855612754822
step: 250, loss: 0.10437346249818802
step: 260, loss: 0.05805132910609245
step: 270, loss: 0.019504299387335777
step: 280, loss: 0.03624122589826584
step: 290, loss: 0.01726876199245453
step: 300, loss: 0.11833884567022324
step: 310, loss: 0.18414463102817535
step: 320, loss: 0.11022105067968369
step: 330, loss: 0.11239945888519287
step: 340, loss: 0.013752167113125324
step: 350, loss: 0.16203217208385468
step: 360, loss: 0.08284948021173477
step: 370, loss: 0.2145310640335083
step: 380, loss: 0.10696157813072205
step: 390, loss: 0.029721364378929138
step: 400, loss: 0.14025980234146118
step: 410, loss: 0.18361467123031616
step: 420, loss: 0.08551471680402756
step: 430, loss: 0.05445117503404617
step: 440, loss: 0.1996840387582779
step: 450, loss: 0.03280465304851532
step: 460, loss: 0.10133562982082367
step: 470, loss: 0.07694750279188156
step: 480, loss: 0.09180878102779388
step: 490, loss: 0.07763370871543884
step: 500, loss: 0.03247903659939766
step: 510, loss: 0.15771247446537018
step: 520, loss: 0.05382682383060455
step: 530, loss: 0.05348357930779457
step: 540, loss: 0.1621684730052948
step: 550, loss: 0.15369488298892975
step: 560, loss: 0.22720187902450562
step: 570, loss: 0.0936947837471962
step: 580, loss: 0.05836256965994835
step: 590, loss: 0.12360645830631256
step: 600, loss: 0.08834066241979599
step: 610, loss: 0.030407262966036797
step: 620, loss: 0.02282262034714222
step: 630, loss: 0.12561194598674774
step: 640, loss: 0.13467520475387573
step: 650, loss: 0.05403394624590874
step: 660, loss: 0.03730088844895363
step: 670, loss: 0.05727347359061241
step: 680, loss: 0.019941002130508423
step: 690, loss: 0.067691370844841
step: 700, loss: 0.13545025885105133
step: 710, loss: 0.034302838146686554
step: 720, loss: 0.13949711620807648
step: 730, loss: 0.24361811578273773
step: 740, loss: 0.14670851826667786
step: 750, loss: 0.1629459410905838
step: 760, loss: 0.11430663615465164
step: 770, loss: 0.2299993932247162
step: 780, loss: 0.1239427924156189
step: 790, loss: 0.0982804223895073
step: 800, loss: 0.10088693350553513
step: 810, loss: 0.07640247046947479
step: 820, loss: 0.04079403355717659
step: 830, loss: 0.05141818895936012
step: 840, loss: 0.1426900178194046
step: 850, loss: 0.10591034591197968
step: 860, loss: 0.02080095373094082
step: 870, loss: 0.10724297165870667
step: 880, loss: 0.168544739484787
step: 890, loss: 0.21307373046875
step: 900, loss: 0.13077133893966675
step: 910, loss: 0.14968158304691315
step: 920, loss: 0.0562303327023983
step: 930, loss: 0.09497987478971481
step: 940, loss: 0.1740899682044983
step: 950, loss: 0.030715733766555786
step: 960, loss: 0.1718355417251587
step: 970, loss: 0.07126940786838531
epoch 5: dev_f1=0.9405356332274172, f1=0.9301688726608854, best_f1=0.9301688726608854
step: 0, loss: 0.036681585013866425
step: 10, loss: 0.0565141998231411
step: 20, loss: 0.06724288314580917
step: 30, loss: 0.20935192704200745
step: 40, loss: 0.1511744260787964
step: 50, loss: 0.08190517127513885
step: 60, loss: 0.15413746237754822
step: 70, loss: 0.19015537202358246
step: 80, loss: 0.0852656289935112
step: 90, loss: 0.12000418454408646
step: 100, loss: 0.062071558088064194
step: 110, loss: 0.15060219168663025
step: 120, loss: 0.0722992941737175
step: 130, loss: 0.11415082216262817
step: 140, loss: 0.07227788865566254
step: 150, loss: 0.10299256443977356
step: 160, loss: 0.19985608756542206
step: 170, loss: 0.03907250985503197
step: 180, loss: 0.04449648782610893
step: 190, loss: 0.03753536567091942
step: 200, loss: 0.05132322758436203
step: 210, loss: 0.055786535143852234
step: 220, loss: 0.08728069812059402
step: 230, loss: 0.03311983495950699
step: 240, loss: 0.1281851977109909
step: 250, loss: 0.04402976855635643
step: 260, loss: 0.10130754113197327
step: 270, loss: 0.08133005350828171
step: 280, loss: 0.0278533436357975
step: 290, loss: 0.032592155039310455
step: 300, loss: 0.07792813330888748
step: 310, loss: 0.11099603027105331
step: 320, loss: 0.09662292152643204
step: 330, loss: 0.15953859686851501
step: 340, loss: 0.0037852521054446697
step: 350, loss: 0.08173161745071411
step: 360, loss: 0.26635637879371643
step: 370, loss: 0.07459022104740143
step: 380, loss: 0.04660959541797638
step: 390, loss: 0.018415728583931923
step: 400, loss: 0.02485026605427265
step: 410, loss: 0.05478908494114876
step: 420, loss: 0.28258100152015686
step: 430, loss: 0.10363411903381348
step: 440, loss: 0.08498209714889526
step: 450, loss: 0.05026565119624138
step: 460, loss: 0.10792301595211029
step: 470, loss: 0.15673959255218506
step: 480, loss: 0.0016182856634259224
step: 490, loss: 0.12413997203111649
step: 500, loss: 0.11152409017086029
step: 510, loss: 0.06130071356892586
step: 520, loss: 0.13931889832019806
step: 530, loss: 0.10253594070672989
step: 540, loss: 0.13896998763084412
step: 550, loss: 0.05662961304187775
step: 560, loss: 0.00874292477965355
step: 570, loss: 0.1094268336892128
step: 580, loss: 0.0978730171918869
step: 590, loss: 0.11485660821199417
step: 600, loss: 0.058663174510002136
step: 610, loss: 0.07999402284622192
step: 620, loss: 0.10157746076583862
step: 630, loss: 0.06723044812679291
step: 640, loss: 0.08581478893756866
step: 650, loss: 0.07104936987161636
step: 660, loss: 0.05698084458708763
step: 670, loss: 0.04322471469640732
step: 680, loss: 0.09322204440832138
step: 690, loss: 0.1366048902273178
step: 700, loss: 0.09411007165908813
step: 710, loss: 0.052900370210409164
step: 720, loss: 0.10119715332984924
step: 730, loss: 0.06979690492153168
step: 740, loss: 0.02226411923766136
step: 750, loss: 0.09778010100126266
step: 760, loss: 0.08382822573184967
step: 770, loss: 0.02770145609974861
step: 780, loss: 0.057575374841690063
step: 790, loss: 0.050606619566679
step: 800, loss: 0.13720203936100006
step: 810, loss: 0.08962700515985489
step: 820, loss: 0.08490625768899918
step: 830, loss: 0.0926077589392662
step: 840, loss: 0.0515480600297451
step: 850, loss: 0.13453581929206848
step: 860, loss: 0.07671211659908295
step: 870, loss: 0.08674787729978561
step: 880, loss: 0.05775383487343788
step: 890, loss: 0.050273362547159195
step: 900, loss: 0.10107225179672241
step: 910, loss: 0.0886806845664978
step: 920, loss: 0.08781186491250992
step: 930, loss: 0.09747879952192307
step: 940, loss: 0.0288876760751009
step: 950, loss: 0.1419050097465515
step: 960, loss: 0.10505055636167526
step: 970, loss: 0.07435864210128784
epoch 6: dev_f1=0.9277326106594399, f1=0.9272727272727272, best_f1=0.9301688726608854
step: 0, loss: 0.052320972084999084
step: 10, loss: 0.05224596709012985
step: 20, loss: 0.08913616836071014
step: 30, loss: 0.10815419256687164
step: 40, loss: 0.07480264455080032
step: 50, loss: 0.235353484749794
step: 60, loss: 0.12736867368221283
step: 70, loss: 0.1332940310239792
step: 80, loss: 0.05019712448120117
step: 90, loss: 0.27116379141807556
step: 100, loss: 0.12305673956871033
step: 110, loss: 0.045919183641672134
step: 120, loss: 0.12870806455612183
step: 130, loss: 0.1065567210316658
step: 140, loss: 0.09222409874200821
step: 150, loss: 0.07103583961725235
step: 160, loss: 0.14430823922157288
step: 170, loss: 0.06113279238343239
step: 180, loss: 0.1017063558101654
step: 190, loss: 0.054237790405750275
step: 200, loss: 0.06592749059200287
step: 210, loss: 0.05309661850333214
step: 220, loss: 0.03963078185915947
step: 230, loss: 0.06932611763477325
step: 240, loss: 0.029570288956165314
step: 250, loss: 0.21957765519618988
step: 260, loss: 0.17387749254703522
step: 270, loss: 0.04152330756187439
step: 280, loss: 0.12112656235694885
step: 290, loss: 0.009668752551078796
step: 300, loss: 0.10292311012744904
step: 310, loss: 0.1397678107023239
step: 320, loss: 0.0978642925620079
step: 330, loss: 0.061157625168561935
step: 340, loss: 0.1372615396976471
step: 350, loss: 0.14468666911125183
step: 360, loss: 0.07287934422492981
step: 370, loss: 0.1347883641719818
step: 380, loss: 0.032751262187957764
step: 390, loss: 0.0591757670044899
step: 400, loss: 0.10802362859249115
step: 410, loss: 0.11608476936817169
step: 420, loss: 0.16410334408283234
step: 430, loss: 0.10886837542057037
step: 440, loss: 0.09688766300678253
step: 450, loss: 0.04693656787276268
step: 460, loss: 0.0535745769739151
step: 470, loss: 0.14407016336917877
step: 480, loss: 0.06300705671310425
step: 490, loss: 0.13845312595367432
step: 500, loss: 0.1095239445567131
step: 510, loss: 0.1549726277589798
step: 520, loss: 0.0655137449502945
step: 530, loss: 0.09356912225484848
step: 540, loss: 0.10347610712051392
step: 550, loss: 0.09550026059150696
step: 560, loss: 0.0482625849545002
step: 570, loss: 0.07316940277814865
step: 580, loss: 0.18305142223834991
step: 590, loss: 0.10410761833190918
step: 600, loss: 0.11304759979248047
step: 610, loss: 0.07977551966905594
step: 620, loss: 0.1122150644659996
step: 630, loss: 0.05603080242872238
step: 640, loss: 0.16971305012702942
step: 650, loss: 0.15199796855449677
step: 660, loss: 0.0780576542019844
step: 670, loss: 0.14003600180149078
step: 680, loss: 0.04180750995874405
step: 690, loss: 0.044724877923727036
step: 700, loss: 0.1116766408085823
step: 710, loss: 0.033326245844364166
step: 720, loss: 0.09948242455720901
step: 730, loss: 0.024562150239944458
step: 740, loss: 0.09453427791595459
step: 750, loss: 0.060402415692806244
step: 760, loss: 0.03385934606194496
step: 770, loss: 0.2784733176231384
step: 780, loss: 0.18564237654209137
step: 790, loss: 0.06861216574907303
step: 800, loss: 0.12654943764209747
step: 810, loss: 0.17064839601516724
step: 820, loss: 0.04331686720252037
step: 830, loss: 0.2362978160381317
step: 840, loss: 0.12077072262763977
step: 850, loss: 0.02713221311569214
step: 860, loss: 0.017516348510980606
step: 870, loss: 0.07041990756988525
step: 880, loss: 0.14162583649158478
step: 890, loss: 0.04226681962609291
step: 900, loss: 0.09137493371963501
step: 910, loss: 0.14687569439411163
step: 920, loss: 0.19336830079555511
step: 930, loss: 0.13301999866962433
step: 940, loss: 0.12172392010688782
step: 950, loss: 0.06261497735977173
step: 960, loss: 0.14975227415561676
step: 970, loss: 0.02096088044345379
epoch 7: dev_f1=0.9279700654817586, f1=0.9269662921348314, best_f1=0.9301688726608854
step: 0, loss: 0.04254710674285889
step: 10, loss: 0.0168064683675766
step: 20, loss: 0.22193042933940887
step: 30, loss: 0.086700938642025
step: 40, loss: 0.04123122617602348
step: 50, loss: 0.04839746281504631
step: 60, loss: 0.04348157346248627
step: 70, loss: 0.0521431490778923
step: 80, loss: 0.08935217559337616
step: 90, loss: 0.11036372929811478
step: 100, loss: 0.08956502377986908
step: 110, loss: 0.032213032245635986
step: 120, loss: 0.0184862669557333
step: 130, loss: 0.2067590057849884
step: 140, loss: 0.06966257095336914
step: 150, loss: 0.07884500920772552
step: 160, loss: 0.17270611226558685
step: 170, loss: 0.051466044038534164
step: 180, loss: 0.03493306413292885
step: 190, loss: 9.771020268090069e-05
step: 200, loss: 0.10989714413881302
step: 210, loss: 0.035507529973983765
step: 220, loss: 0.04035026952624321
step: 230, loss: 0.0315827876329422
step: 240, loss: 0.015375528484582901
step: 250, loss: 0.11057815700769424
step: 260, loss: 0.08419334888458252
step: 270, loss: 0.061365094035863876
step: 280, loss: 0.09125322103500366
step: 290, loss: 0.049728021025657654
step: 300, loss: 0.162288635969162
step: 310, loss: 0.03675899654626846
step: 320, loss: 0.04424918815493584
step: 330, loss: 0.04483933746814728
step: 340, loss: 0.028407253324985504
step: 350, loss: 0.1701868623495102
step: 360, loss: 0.08859433233737946
step: 370, loss: 0.03958875313401222
step: 380, loss: 0.01732940413057804
step: 390, loss: 0.10458382964134216
step: 400, loss: 0.03159874677658081
step: 410, loss: 0.07932648807764053
step: 420, loss: 0.007370118051767349
step: 430, loss: 0.09143851697444916
step: 440, loss: 0.14478784799575806
step: 450, loss: 0.035878825932741165
step: 460, loss: 0.10886932164430618
step: 470, loss: 0.07740703970193863
step: 480, loss: 0.03448154404759407
step: 490, loss: 0.1635551005601883
step: 500, loss: 0.21684205532073975
step: 510, loss: 0.10437403619289398
step: 520, loss: 0.10055261105298996
step: 530, loss: 0.027898704633116722
step: 540, loss: 0.060425277799367905
step: 550, loss: 0.05128895118832588
step: 560, loss: 0.022418420761823654
step: 570, loss: 0.06515181064605713
step: 580, loss: 0.0946321189403534
step: 590, loss: 0.15989330410957336
step: 600, loss: 0.09123545140028
step: 610, loss: 0.01938740164041519
step: 620, loss: 0.04711029306054115
step: 630, loss: 0.03096996434032917
step: 640, loss: 0.05989812687039375
step: 650, loss: 0.089137002825737
step: 660, loss: 0.17548848688602448
step: 670, loss: 0.058136437088251114
step: 680, loss: 0.10399363934993744
step: 690, loss: 0.02388821542263031
step: 700, loss: 0.15160627663135529
step: 710, loss: 0.24646586179733276
step: 720, loss: 0.12044069170951843
step: 730, loss: 0.12840311229228973
step: 740, loss: 0.2597948908805847
step: 750, loss: 0.021212374791502953
step: 760, loss: 0.048357799649238586
step: 770, loss: 0.024149147793650627
step: 780, loss: 0.05306108668446541
step: 790, loss: 0.016568981111049652
step: 800, loss: 0.1655684858560562
step: 810, loss: 0.11474696546792984
step: 820, loss: 0.12620079517364502
step: 830, loss: 0.07128879427909851
step: 840, loss: 0.10896617919206619
step: 850, loss: 0.03355060890316963
step: 860, loss: 0.0544869527220726
step: 870, loss: 0.0321638323366642
step: 880, loss: 0.10665427893400192
step: 890, loss: 0.17896372079849243
step: 900, loss: 0.04549112543463707
step: 910, loss: 0.04905928671360016
step: 920, loss: 0.0586717464029789
step: 930, loss: 0.10383699834346771
step: 940, loss: 0.15350325405597687
step: 950, loss: 0.06733711063861847
step: 960, loss: 0.11563710868358612
step: 970, loss: 0.08968420326709747
epoch 8: dev_f1=0.9221014492753623, f1=0.9176898590268303, best_f1=0.9301688726608854
step: 0, loss: 0.18421728909015656
step: 10, loss: 0.14332953095436096
step: 20, loss: 0.07499511539936066
step: 30, loss: 0.04789484292268753
step: 40, loss: 0.16374219954013824
step: 50, loss: 0.054487816989421844
step: 60, loss: 0.03856682777404785
step: 70, loss: 0.11148668825626373
step: 80, loss: 0.1371092051267624
step: 90, loss: 0.14584249258041382
step: 100, loss: 0.09041888266801834
step: 110, loss: 0.2030419260263443
step: 120, loss: 0.11084651201963425
step: 130, loss: 0.05998405069112778
step: 140, loss: 0.06300213932991028
step: 150, loss: 0.16136762499809265
step: 160, loss: 0.08527898043394089
step: 170, loss: 0.051419373601675034
step: 180, loss: 0.07398239523172379
step: 190, loss: 0.013398292474448681
step: 200, loss: 0.14017830789089203
step: 210, loss: 0.07605866342782974
step: 220, loss: 0.10108189284801483
step: 230, loss: 0.09439944475889206
step: 240, loss: 0.09223083406686783
step: 250, loss: 0.014026246964931488
step: 260, loss: 0.04250212386250496
step: 270, loss: 0.21119020879268646
step: 280, loss: 0.035262323915958405
step: 290, loss: 0.058687325567007065
step: 300, loss: 0.02996090054512024
step: 310, loss: 0.15942507982254028
step: 320, loss: 0.04050388187170029
step: 330, loss: 0.059033118188381195
step: 340, loss: 0.02339995466172695
step: 350, loss: 0.06705963611602783
step: 360, loss: 0.0432707779109478
step: 370, loss: 0.06599008291959763
step: 380, loss: 0.04750225692987442
step: 390, loss: 0.06362870335578918
step: 400, loss: 0.04983536899089813
step: 410, loss: 0.010771773755550385
step: 420, loss: 0.08204980939626694
step: 430, loss: 0.032858941704034805
step: 440, loss: 0.10344867408275604
step: 450, loss: 0.028007201850414276
step: 460, loss: 0.07072519510984421
step: 470, loss: 0.03416559845209122
step: 480, loss: 0.11940721422433853
step: 490, loss: 0.09647632390260696
step: 500, loss: 0.052834901958703995
step: 510, loss: 0.017864448949694633
step: 520, loss: 0.04756927490234375
step: 530, loss: 0.012881128117442131
step: 540, loss: 0.06910275667905807
step: 550, loss: 0.0776299312710762
step: 560, loss: 0.0371086485683918
step: 570, loss: 0.08717832714319229
step: 580, loss: 0.025309501215815544
step: 590, loss: 0.01821313425898552
step: 600, loss: 0.07302551716566086
step: 610, loss: 0.19922684133052826
step: 620, loss: 0.15314951539039612
step: 630, loss: 0.18329279124736786
step: 640, loss: 0.06819580495357513
step: 650, loss: 0.08890010416507721
step: 660, loss: 0.08457329124212265
step: 670, loss: 0.1350904256105423
step: 680, loss: 0.011121733114123344
step: 690, loss: 0.060660213232040405
step: 700, loss: 0.06321749836206436
step: 710, loss: 0.14254935085773468
step: 720, loss: 0.04560938477516174
step: 730, loss: 0.045508868992328644
step: 740, loss: 0.058230720460414886
step: 750, loss: 0.09425222873687744
step: 760, loss: 0.15133237838745117
step: 770, loss: 0.1426602452993393
step: 780, loss: 0.18895313143730164
step: 790, loss: 0.20254075527191162
step: 800, loss: 0.012861539609730244
step: 810, loss: 0.022453051060438156
step: 820, loss: 0.09875254333019257
step: 830, loss: 0.14702923595905304
step: 840, loss: 0.01622902601957321
step: 850, loss: 0.18836478888988495
step: 860, loss: 0.08663120120763779
step: 870, loss: 0.08102712780237198
step: 880, loss: 0.15183699131011963
step: 890, loss: 0.008823626674711704
step: 900, loss: 0.16463153064250946
step: 910, loss: 0.0662824958562851
step: 920, loss: 0.037956468760967255
step: 930, loss: 0.014599350281059742
step: 940, loss: 0.01948489621281624
step: 950, loss: 0.09554024785757065
step: 960, loss: 0.014575963839888573
step: 970, loss: 0.11469526588916779
epoch 9: dev_f1=0.9263351749539595, f1=0.9237170596393898, best_f1=0.9301688726608854
step: 0, loss: 0.04046936705708504
step: 10, loss: 0.11231086403131485
step: 20, loss: 0.12070225924253464
step: 30, loss: 0.16379791498184204
step: 40, loss: 0.04039100185036659
step: 50, loss: 0.0009584234212525189
step: 60, loss: 0.08294092118740082
step: 70, loss: 0.08990227431058884
step: 80, loss: 0.01610788330435753
step: 90, loss: 0.0930882915854454
step: 100, loss: 0.0741223469376564
step: 110, loss: 0.0027120027225464582
step: 120, loss: 0.04768159240484238
step: 130, loss: 0.14760035276412964
step: 140, loss: 0.01597723923623562
step: 150, loss: 0.13504695892333984
step: 160, loss: 0.08915397524833679
step: 170, loss: 0.15444476902484894
step: 180, loss: 0.14449380338191986
step: 190, loss: 0.023119298741221428
step: 200, loss: 0.13626347482204437
step: 210, loss: 0.137299582362175
step: 220, loss: 0.10103222727775574
step: 230, loss: 0.17588798701763153
step: 240, loss: 0.10680532455444336
step: 250, loss: 0.022252175956964493
step: 260, loss: 0.09227146953344345
step: 270, loss: 0.028076667338609695
step: 280, loss: 0.037173572927713394
step: 290, loss: 0.06746695190668106
step: 300, loss: 0.19947665929794312
step: 310, loss: 0.24659967422485352
step: 320, loss: 0.09046140313148499
step: 330, loss: 0.06289084255695343
step: 340, loss: 0.10149592161178589
step: 350, loss: 0.1594017595052719
step: 360, loss: 0.09829336404800415
step: 370, loss: 0.03891383856534958
step: 380, loss: 0.03953418880701065
step: 390, loss: 0.021037276834249496
step: 400, loss: 0.07544838637113571
step: 410, loss: 0.049484267830848694
step: 420, loss: 0.09827247262001038
step: 430, loss: 0.10155833512544632
step: 440, loss: 0.06265795230865479
step: 450, loss: 0.05229257792234421
step: 460, loss: 0.11088422685861588
step: 470, loss: 0.20480355620384216
step: 480, loss: 0.009559988975524902
step: 490, loss: 0.19245262444019318
step: 500, loss: 0.11039170622825623
step: 510, loss: 0.018487492576241493
step: 520, loss: 0.11087353527545929
step: 530, loss: 0.04024380445480347
step: 540, loss: 0.02668803185224533
step: 550, loss: 0.07077568024396896
step: 560, loss: 0.12082482874393463
step: 570, loss: 0.12260030955076218
step: 580, loss: 0.05511714145541191
step: 590, loss: 0.03217106685042381
step: 600, loss: 0.0559128113090992
step: 610, loss: 0.0676899179816246
step: 620, loss: 0.13146552443504333
step: 630, loss: 0.07787007838487625
step: 640, loss: 0.07607447355985641
step: 650, loss: 0.01543492078781128
step: 660, loss: 0.06325715035200119
step: 670, loss: 0.0841805562376976
step: 680, loss: 0.03637943044304848
step: 690, loss: 0.13244566321372986
step: 700, loss: 0.060341522097587585
step: 710, loss: 0.1549948751926422
step: 720, loss: 0.06876504421234131
step: 730, loss: 0.1355331987142563
step: 740, loss: 0.07889644056558609
step: 750, loss: 0.001242856727913022
step: 760, loss: 0.07341060787439346
step: 770, loss: 0.129386767745018
step: 780, loss: 0.0161630529910326
step: 790, loss: 0.08558446168899536
step: 800, loss: 0.03799368068575859
step: 810, loss: 0.07954598218202591
step: 820, loss: 0.05278991535305977
step: 830, loss: 0.10245074331760406
step: 840, loss: 0.1333528608083725
step: 850, loss: 0.10827737301588058
step: 860, loss: 0.09754923731088638
step: 870, loss: 0.14662957191467285
step: 880, loss: 0.10603480041027069
step: 890, loss: 0.08087026327848434
step: 900, loss: 0.07537738978862762
step: 910, loss: 0.06363131105899811
step: 920, loss: 0.13925202190876007
step: 930, loss: 0.04057548940181732
step: 940, loss: 0.1439933478832245
step: 950, loss: 0.0713573768734932
step: 960, loss: 0.041901472955942154
step: 970, loss: 0.036086831241846085
epoch 10: dev_f1=0.9255813953488372, f1=0.9257037378864791, best_f1=0.9301688726608854
step: 0, loss: 0.05222944915294647
step: 10, loss: 0.017719099298119545
step: 20, loss: 0.057184360921382904
step: 30, loss: 0.10987748205661774
step: 40, loss: 0.29279693961143494
step: 50, loss: 0.04110506922006607
step: 60, loss: 0.012524357996881008
step: 70, loss: 0.028838515281677246
step: 80, loss: 0.1275814324617386
step: 90, loss: 0.17505168914794922
step: 100, loss: 0.05356936901807785
step: 110, loss: 0.03599042817950249
step: 120, loss: 0.046385690569877625
step: 130, loss: 0.042007431387901306
step: 140, loss: 0.031644999980926514
step: 150, loss: 0.10243750363588333
step: 160, loss: 0.11494167149066925
step: 170, loss: 0.13585907220840454
step: 180, loss: 0.10909119248390198
step: 190, loss: 0.00459420308470726
step: 200, loss: 0.16887404024600983
step: 210, loss: 0.021202098578214645
step: 220, loss: 0.16792820394039154
step: 230, loss: 0.05423245579004288
step: 240, loss: 0.0905195027589798
step: 250, loss: 0.11676276475191116
step: 260, loss: 0.04314146190881729
step: 270, loss: 0.06870389729738235
step: 280, loss: 0.053970761597156525
step: 290, loss: 0.046778604388237
step: 300, loss: 0.0007307028281502426
step: 310, loss: 0.2358836829662323
step: 320, loss: 0.05672546848654747
step: 330, loss: 0.32026374340057373
step: 340, loss: 0.02211686596274376
step: 350, loss: 0.15381571650505066
step: 360, loss: 0.13893260061740875
step: 370, loss: 0.03935815021395683
step: 380, loss: 0.10925354808568954
step: 390, loss: 0.09979569166898727
step: 400, loss: 0.1506895124912262
step: 410, loss: 0.013387037441134453
step: 420, loss: 0.0522257536649704
step: 430, loss: 0.07329408079385757
step: 440, loss: 0.05307022109627724
step: 450, loss: 0.04521934688091278
step: 460, loss: 0.049340080469846725
step: 470, loss: 0.046570464968681335
step: 480, loss: 0.06410053372383118
step: 490, loss: 0.056004490703344345
step: 500, loss: 0.0804123505949974
step: 510, loss: 0.008496519178152084
step: 520, loss: 0.032730184495449066
step: 530, loss: 0.0287107452750206
step: 540, loss: 0.14467070996761322
step: 550, loss: 0.07488756626844406
step: 560, loss: 0.11092130839824677
step: 570, loss: 0.03900553286075592
step: 580, loss: 0.06733637303113937
step: 590, loss: 0.041558653116226196
step: 600, loss: 0.11359577625989914
step: 610, loss: 0.0017964030848816037
step: 620, loss: 0.03267468512058258
step: 630, loss: 0.17424741387367249
step: 640, loss: 0.07330754399299622
step: 650, loss: 0.02544029802083969
step: 660, loss: 0.09879768639802933
step: 670, loss: 0.04509013891220093
step: 680, loss: 0.0744602233171463
step: 690, loss: 0.047315776348114014
step: 700, loss: 0.12165294587612152
step: 710, loss: 0.062185026705265045
step: 720, loss: 0.0867188423871994
step: 730, loss: 0.014387302100658417
step: 740, loss: 0.12319652736186981
step: 750, loss: 0.0025743504520505667
step: 760, loss: 0.018973296508193016
step: 770, loss: 0.03423967584967613
step: 780, loss: 0.059815097600221634
step: 790, loss: 0.1303965151309967
step: 800, loss: 0.03628458455204964
step: 810, loss: 0.07049327343702316
step: 820, loss: 0.10356661677360535
step: 830, loss: 0.07747422158718109
step: 840, loss: 0.13919883966445923
step: 850, loss: 0.048457857221364975
step: 860, loss: 0.11726026237010956
step: 870, loss: 0.008410492911934853
step: 880, loss: 0.052397169172763824
step: 890, loss: 0.06735622882843018
step: 900, loss: 0.015814824029803276
step: 910, loss: 0.018397754058241844
step: 920, loss: 0.06136393919587135
step: 930, loss: 0.14053773880004883
step: 940, loss: 0.05852349475026131
step: 950, loss: 0.02910204418003559
step: 960, loss: 0.04057632386684418
step: 970, loss: 0.08550325781106949
epoch 11: dev_f1=0.9288702928870293, f1=0.9250814332247558, best_f1=0.9301688726608854
step: 0, loss: 0.06371986865997314
step: 10, loss: 0.0780123695731163
step: 20, loss: 0.05241731181740761
step: 30, loss: 0.04835543781518936
step: 40, loss: 0.05115265026688576
step: 50, loss: 0.04095723107457161
step: 60, loss: 0.019551031291484833
step: 70, loss: 0.048623066395521164
step: 80, loss: 0.14959947764873505
step: 90, loss: 0.06132831424474716
step: 100, loss: 0.09682673960924149
step: 110, loss: 0.02734719030559063
step: 120, loss: 0.059177663177251816
step: 130, loss: 0.04025386646389961
step: 140, loss: 0.0319015309214592
step: 150, loss: 0.006879222113639116
step: 160, loss: 0.13152436912059784
step: 170, loss: 0.04718957468867302
step: 180, loss: 0.07747307419776917
step: 190, loss: 0.06447168439626694
step: 200, loss: 0.12752197682857513
step: 210, loss: 0.05193287879228592
step: 220, loss: 0.12979966402053833
step: 230, loss: 0.04049874097108841
step: 240, loss: 0.15754340589046478
step: 250, loss: 0.030884722247719765
step: 260, loss: 0.05087447538971901
step: 270, loss: 0.03359472379088402
step: 280, loss: 0.023130180314183235
step: 290, loss: 0.045854635536670685
step: 300, loss: 0.09267652779817581
step: 310, loss: 0.11143618077039719
step: 320, loss: 0.1421256959438324
step: 330, loss: 0.18193396925926208
step: 340, loss: 0.03229359909892082
step: 350, loss: 0.11523062735795975
step: 360, loss: 0.04804932698607445
step: 370, loss: 0.07661960273981094
step: 380, loss: 0.10703658312559128
step: 390, loss: 0.04717407748103142
step: 400, loss: 0.0317765437066555
step: 410, loss: 0.07806413620710373
step: 420, loss: 0.03719426691532135
step: 430, loss: 0.020144905894994736
step: 440, loss: 0.019487246870994568
step: 450, loss: 0.06606318056583405
step: 460, loss: 0.13833235204219818
step: 470, loss: 0.09124506264925003
step: 480, loss: 0.05510392040014267
step: 490, loss: 0.05134330689907074
step: 500, loss: 0.0819040909409523
step: 510, loss: 0.07002732157707214
step: 520, loss: 0.04617198184132576
step: 530, loss: 0.061559222638607025
step: 540, loss: 0.10204868018627167
step: 550, loss: 0.05509498342871666
step: 560, loss: 0.05039322003722191
step: 570, loss: 0.028795789927244186
step: 580, loss: 0.0001936276094056666
step: 590, loss: 0.008642594330012798
step: 600, loss: 0.09223509579896927
step: 610, loss: 0.0013247840106487274
step: 620, loss: 0.1401345133781433
step: 630, loss: 0.0574755035340786
step: 640, loss: 0.029923513531684875
step: 650, loss: 0.03289181739091873
step: 660, loss: 0.1436464488506317
step: 670, loss: 0.12661585211753845
step: 680, loss: 0.05577944219112396
step: 690, loss: 0.09389107674360275
step: 700, loss: 0.07099080085754395
step: 710, loss: 0.05371104180812836
step: 720, loss: 0.07884558290243149
step: 730, loss: 0.0038970662280917168
step: 740, loss: 0.11295731365680695
step: 750, loss: 0.03180084004998207
step: 760, loss: 0.15470004081726074
step: 770, loss: 0.047636985778808594
step: 780, loss: 0.081709124147892
step: 790, loss: 0.02592431753873825
step: 800, loss: 0.02883840538561344
step: 810, loss: 0.034444138407707214
step: 820, loss: 0.08437873423099518
step: 830, loss: 0.20826435089111328
step: 840, loss: 0.05824439972639084
step: 850, loss: 0.07332971692085266
step: 860, loss: 0.03738686442375183
step: 870, loss: 0.07646585255861282
step: 880, loss: 0.17414231598377228
step: 890, loss: 0.04261994734406471
step: 900, loss: 0.047887302935123444
step: 910, loss: 0.02027428336441517
step: 920, loss: 0.06014043465256691
step: 930, loss: 0.039879024028778076
step: 940, loss: 0.0020995624363422394
step: 950, loss: 0.028803011402487755
step: 960, loss: 0.036658626049757004
step: 970, loss: 0.03025885857641697
epoch 12: dev_f1=0.9272137227630968, f1=0.9227906976744187, best_f1=0.9301688726608854
step: 0, loss: 0.03598574921488762
step: 10, loss: 0.09535587579011917
step: 20, loss: 0.1435280293226242
step: 30, loss: 0.024346614256501198
step: 40, loss: 0.0499720573425293
step: 50, loss: 0.028353611007332802
step: 60, loss: 0.08188485354185104
step: 70, loss: 0.06525291502475739
step: 80, loss: 0.04071551188826561
step: 90, loss: 0.06291987746953964
step: 100, loss: 0.1647304892539978
step: 110, loss: 0.17161421477794647
step: 120, loss: 0.06282135099172592
step: 130, loss: 0.015775617212057114
step: 140, loss: 0.03003099001944065
step: 150, loss: 0.17028623819351196
step: 160, loss: 0.11519216746091843
step: 170, loss: 0.038878608494997025
step: 180, loss: 0.03763991966843605
step: 190, loss: 0.04205320030450821
step: 200, loss: 0.008533673360943794
step: 210, loss: 0.020381588488817215
step: 220, loss: 0.06838951259851456
step: 230, loss: 0.09532564133405685
step: 240, loss: 0.0251275897026062
step: 250, loss: 0.01441880688071251
step: 260, loss: 0.0939924344420433
step: 270, loss: 0.05138060078024864
step: 280, loss: 0.04041539505124092
step: 290, loss: 0.16898736357688904
step: 300, loss: 0.0764455497264862
step: 310, loss: 0.10644108802080154
step: 320, loss: 0.039494581520557404
step: 330, loss: 0.042466647922992706
step: 340, loss: 0.10495297610759735
step: 350, loss: 0.06936875730752945
step: 360, loss: 0.023158950731158257
step: 370, loss: 0.12839354574680328
step: 380, loss: 0.03857019543647766
step: 390, loss: 0.003947107121348381
step: 400, loss: 0.07849934697151184
step: 410, loss: 0.03483237698674202
step: 420, loss: 0.0383366234600544
step: 430, loss: 0.09480264782905579
step: 440, loss: 0.09768371284008026
step: 450, loss: 0.019766785204410553
step: 460, loss: 0.04511787369847298
step: 470, loss: 0.029095614328980446
step: 480, loss: 0.16029855608940125
step: 490, loss: 0.09242460131645203
step: 500, loss: 0.03334426507353783
step: 510, loss: 0.022259967401623726
step: 520, loss: 0.06109810993075371
step: 530, loss: 0.0273362435400486
step: 540, loss: 0.05068636313080788
step: 550, loss: 0.068161740899086
step: 560, loss: 0.10462204366922379
step: 570, loss: 0.07066758722066879
step: 580, loss: 0.025969460606575012
step: 590, loss: 0.06132292002439499
step: 600, loss: 0.08263740688562393
step: 610, loss: 0.07735566794872284
step: 620, loss: 0.02654198929667473
step: 630, loss: 0.08802957832813263
step: 640, loss: 0.1515704095363617
step: 650, loss: 0.03791815787553787
step: 660, loss: 0.10112104564905167
step: 670, loss: 0.12611569464206696
step: 680, loss: 0.09422881156206131
step: 690, loss: 0.10497956722974777
step: 700, loss: 0.05703242868185043
step: 710, loss: 0.02740291878581047
step: 720, loss: 0.06595689803361893
step: 730, loss: 0.008416137658059597
step: 740, loss: 0.042013347148895264
step: 750, loss: 0.10314875841140747
step: 760, loss: 0.02486994117498398
step: 770, loss: 0.03657693788409233
step: 780, loss: 0.1632295548915863
step: 790, loss: 0.08901692926883698
step: 800, loss: 0.08321017026901245
step: 810, loss: 0.03815038129687309
step: 820, loss: 0.07919640839099884
step: 830, loss: 0.09290924668312073
step: 840, loss: 0.06960860639810562
step: 850, loss: 0.01515944954007864
step: 860, loss: 0.09626804292201996
step: 870, loss: 0.001035329420119524
step: 880, loss: 0.1072942465543747
step: 890, loss: 0.020600829273462296
step: 900, loss: 0.10827697813510895
step: 910, loss: 0.057678114622831345
step: 920, loss: 0.09512258321046829
step: 930, loss: 0.05357292294502258
step: 940, loss: 0.03446732833981514
step: 950, loss: 0.10829532891511917
step: 960, loss: 0.06824304163455963
step: 970, loss: 0.11930274218320847
epoch 13: dev_f1=0.9264504339881224, f1=0.9215236346948141, best_f1=0.9301688726608854
step: 0, loss: 0.036014992743730545
step: 10, loss: 0.10083101689815521
step: 20, loss: 0.037920232862234116
step: 30, loss: 0.07555153965950012
step: 40, loss: 0.12051068246364594
step: 50, loss: 0.05904939025640488
step: 60, loss: 0.05053892359137535
step: 70, loss: 0.01848985068500042
step: 80, loss: 0.0774790346622467
step: 90, loss: 0.013625139370560646
step: 100, loss: 0.002864919835701585
step: 110, loss: 0.0015805518487468362
step: 120, loss: 0.042417049407958984
step: 130, loss: 0.10805101692676544
step: 140, loss: 0.0711093470454216
step: 150, loss: 0.06439273059368134
step: 160, loss: 0.05376652628183365
step: 170, loss: 0.07255087792873383
step: 180, loss: 0.06234946846961975
step: 190, loss: 0.07671594619750977
step: 200, loss: 0.02526073344051838
step: 210, loss: 0.09809309244155884
step: 220, loss: 0.07235916703939438
step: 230, loss: 0.18399584293365479
step: 240, loss: 0.12091507762670517
step: 250, loss: 0.07260805368423462
step: 260, loss: 0.0033717001788318157
step: 270, loss: 0.04474532976746559
step: 280, loss: 0.13511040806770325
step: 290, loss: 0.10360415279865265
step: 300, loss: 0.07091087102890015
step: 310, loss: 0.06991595029830933
step: 320, loss: 0.06705322861671448
step: 330, loss: 0.035597797483205795
step: 340, loss: 0.02057243138551712
step: 350, loss: 0.03048357181251049
step: 360, loss: 0.019667452201247215
step: 370, loss: 0.07622963935136795
step: 380, loss: 0.00019008773961104453
step: 390, loss: 0.0848642885684967
step: 400, loss: 0.11183519661426544
step: 410, loss: 0.026060352101922035
step: 420, loss: 0.038978733122348785
step: 430, loss: 0.066909059882164
step: 440, loss: 0.10170416533946991
step: 450, loss: 0.06183883175253868
step: 460, loss: 0.035815101116895676
step: 470, loss: 0.05418558791279793
step: 480, loss: 0.00981059018522501
step: 490, loss: 0.02158218063414097
step: 500, loss: 0.10526299476623535
step: 510, loss: 0.0026915601920336485
step: 520, loss: 0.04960675165057182
step: 530, loss: 0.06293998658657074
step: 540, loss: 0.07607567310333252
step: 550, loss: 0.009046883322298527
step: 560, loss: 0.0009501372696831822
step: 570, loss: 0.028492819517850876
step: 580, loss: 0.03871581330895424
step: 590, loss: 0.04344765469431877
step: 600, loss: 0.07420337200164795
step: 610, loss: 0.08329839259386063
step: 620, loss: 0.14742735028266907
step: 630, loss: 0.0632784441113472
step: 640, loss: 0.01983843557536602
step: 650, loss: 0.07343019545078278
step: 660, loss: 0.09966721385717392
step: 670, loss: 0.0028298755642026663
step: 680, loss: 0.10357026755809784
step: 690, loss: 0.01937497965991497
step: 700, loss: 0.02305012010037899
step: 710, loss: 0.04007994756102562
step: 720, loss: 0.050503719598054886
step: 730, loss: 0.05509062483906746
step: 740, loss: 0.11672666668891907
step: 750, loss: 0.0181468203663826
step: 760, loss: 0.03550087660551071
step: 770, loss: 0.03676717355847359
step: 780, loss: 0.0032352940179407597
step: 790, loss: 0.05258464813232422
step: 800, loss: 0.051516253501176834
step: 810, loss: 0.06269778311252594
step: 820, loss: 0.061475031077861786
step: 830, loss: 0.017535831779241562
step: 840, loss: 0.0791907086968422
step: 850, loss: 0.004385082982480526
step: 860, loss: 0.022267553955316544
step: 870, loss: 0.031120741739869118
step: 880, loss: 0.15049482882022858
step: 890, loss: 0.03608039766550064
step: 900, loss: 0.10275253653526306
step: 910, loss: 0.055122435092926025
step: 920, loss: 0.06167635694146156
step: 930, loss: 0.05493095517158508
step: 940, loss: 0.07128523290157318
step: 950, loss: 0.09636038541793823
step: 960, loss: 0.2573963701725006
step: 970, loss: 0.10123252123594284
epoch 14: dev_f1=0.9249084249084248, f1=0.9206927985414768, best_f1=0.9301688726608854
step: 0, loss: 0.06229133531451225
step: 10, loss: 0.08176572620868683
step: 20, loss: 0.02782239392399788
step: 30, loss: 0.003415248356759548
step: 40, loss: 0.07152974605560303
step: 50, loss: 0.13719749450683594
step: 60, loss: 0.0011495195794850588
step: 70, loss: 0.04942846670746803
step: 80, loss: 0.043605949729681015
step: 90, loss: 0.02217259630560875
step: 100, loss: 0.03514064848423004
step: 110, loss: 0.09619032591581345
step: 120, loss: 0.023128125816583633
step: 130, loss: 0.02680123597383499
step: 140, loss: 0.0697803944349289
step: 150, loss: 0.04293686896562576
step: 160, loss: 0.04583180323243141
step: 170, loss: 0.05302025005221367
step: 180, loss: 0.038915641605854034
step: 190, loss: 0.13860298693180084
step: 200, loss: 0.03491482883691788
step: 210, loss: 0.021183589473366737
step: 220, loss: 0.04950197786092758
step: 230, loss: 0.03958059474825859
step: 240, loss: 0.04856539145112038
step: 250, loss: 0.025121064856648445
step: 260, loss: 0.03887559846043587
step: 270, loss: 0.06033971160650253
step: 280, loss: 0.0184053685516119
step: 290, loss: 0.019800277426838875
step: 300, loss: 0.05728243663907051
step: 310, loss: 0.07868199050426483
step: 320, loss: 0.001252713380381465
step: 330, loss: 0.07220731675624847
step: 340, loss: 0.03194475546479225
step: 350, loss: 0.08701808750629425
step: 360, loss: 0.04181786626577377
step: 370, loss: 0.04772412031888962
step: 380, loss: 0.08819796144962311
step: 390, loss: 0.05786905437707901
step: 400, loss: 0.05644131079316139
step: 410, loss: 0.07175581902265549
step: 420, loss: 0.0725359097123146
step: 430, loss: 0.009398545138537884
step: 440, loss: 0.027372710406780243
step: 450, loss: 0.015177876688539982
step: 460, loss: 0.09178619086742401
step: 470, loss: 0.05959542840719223
step: 480, loss: 0.09252829104661942
step: 490, loss: 0.1469830423593521
step: 500, loss: 0.06919587403535843
step: 510, loss: 0.003350653685629368
step: 520, loss: 0.03797686845064163
step: 530, loss: 0.16586193442344666
step: 540, loss: 0.05072729289531708
step: 550, loss: 0.06366267055273056
step: 560, loss: 0.02585548721253872
step: 570, loss: 0.04378814622759819
step: 580, loss: 0.05566999316215515
step: 590, loss: 0.07378357648849487
step: 600, loss: 0.08013098686933517
step: 610, loss: 0.006844717543572187
step: 620, loss: 0.026308026164770126
step: 630, loss: 0.00038641830906271935
step: 640, loss: 0.00015223812079057097
step: 650, loss: 0.0004376070573925972
step: 660, loss: 0.028246629983186722
step: 670, loss: 0.050705209374427795
step: 680, loss: 0.06291719526052475
step: 690, loss: 0.05582593381404877
step: 700, loss: 0.00047571424511261284
step: 710, loss: 0.05038083344697952
step: 720, loss: 0.0888485237956047
step: 730, loss: 0.032693490386009216
step: 740, loss: 0.08253475278615952
step: 750, loss: 0.02246057614684105
step: 760, loss: 0.15562397241592407
step: 770, loss: 0.022850235924124718
step: 780, loss: 0.01940161921083927
step: 790, loss: 0.09542066603899002
step: 800, loss: 0.15134185552597046
step: 810, loss: 0.0822579488158226
step: 820, loss: 0.048383697867393494
step: 830, loss: 0.08921712636947632
step: 840, loss: 0.0707397535443306
step: 850, loss: 0.043043289333581924
step: 860, loss: 0.019605858251452446
step: 870, loss: 0.011640562675893307
step: 880, loss: 0.08041040599346161
step: 890, loss: 0.01664060540497303
step: 900, loss: 0.10707760602235794
step: 910, loss: 0.034611042588949203
step: 920, loss: 0.06984373927116394
step: 930, loss: 0.03145302087068558
step: 940, loss: 0.04499293863773346
step: 950, loss: 0.00022450662800110877
step: 960, loss: 0.13183890283107758
step: 970, loss: 0.044628869742155075
epoch 15: dev_f1=0.9321016166281756, f1=0.9265588914549654, best_f1=0.9301688726608854
step: 0, loss: 0.130694180727005
step: 10, loss: 0.0612613745033741
step: 20, loss: 0.01762530580163002
step: 30, loss: 0.07100079208612442
step: 40, loss: 0.06837931275367737
step: 50, loss: 0.09709599614143372
step: 60, loss: 0.08586090803146362
step: 70, loss: 0.05319087207317352
step: 80, loss: 0.02447413094341755
step: 90, loss: 0.094881571829319
step: 100, loss: 0.10877801477909088
step: 110, loss: 0.030233655124902725
step: 120, loss: 0.08077769726514816
step: 130, loss: 0.04219445586204529
step: 140, loss: 0.03030853532254696
step: 150, loss: 0.03138342127203941
step: 160, loss: 0.09347610175609589
step: 170, loss: 0.13169743120670319
step: 180, loss: 0.05140407383441925
step: 190, loss: 0.01792593114078045
step: 200, loss: 0.030309442430734634
step: 210, loss: 0.0016122701345011592
step: 220, loss: 0.0270560160279274
step: 230, loss: 0.02105659991502762
step: 240, loss: 0.0314435213804245
step: 250, loss: 0.022963423281908035
step: 260, loss: 0.09984759986400604
step: 270, loss: 0.05678924545645714
step: 280, loss: 0.036344386637210846
step: 290, loss: 0.05166425183415413
step: 300, loss: 0.08315439522266388
step: 310, loss: 0.1170547753572464
step: 320, loss: 0.06750024110078812
step: 330, loss: 0.018511079251766205
step: 340, loss: 0.018438201397657394
step: 350, loss: 0.019970199093222618
step: 360, loss: 0.06144127622246742
step: 370, loss: 0.002194918692111969
step: 380, loss: 0.04750172048807144
step: 390, loss: 0.02133484184741974
step: 400, loss: 0.01963861472904682
step: 410, loss: 0.04884401336312294
step: 420, loss: 0.04498015344142914
step: 430, loss: 0.06500905007123947
step: 440, loss: 0.04769478738307953
step: 450, loss: 0.015540827997028828
step: 460, loss: 0.07116059213876724
step: 470, loss: 0.04692620411515236
step: 480, loss: 0.07134738564491272
step: 490, loss: 0.07808087766170502
step: 500, loss: 0.07089101523160934
step: 510, loss: 0.0005345895770005882
step: 520, loss: 0.06338667869567871
step: 530, loss: 0.02455608732998371
step: 540, loss: 0.037550050765275955
step: 550, loss: 0.03512544557452202
step: 560, loss: 0.04597516357898712
step: 570, loss: 0.10838616639375687
step: 580, loss: 0.01691606640815735
step: 590, loss: 0.1000618040561676
step: 600, loss: 0.04550555348396301
step: 610, loss: 0.07734063267707825
step: 620, loss: 0.13065452873706818
step: 630, loss: 0.0013313485542312264
step: 640, loss: 0.00010688041220419109
step: 650, loss: 0.07608841359615326
step: 660, loss: 0.01455348264425993
step: 670, loss: 0.03824625164270401
step: 680, loss: 0.0836443081498146
step: 690, loss: 0.018885688856244087
step: 700, loss: 0.060667261481285095
step: 710, loss: 0.1225142553448677
step: 720, loss: 0.044630374759435654
step: 730, loss: 0.06702018529176712
step: 740, loss: 0.057779841125011444
step: 750, loss: 0.060350336134433746
step: 760, loss: 0.12991204857826233
step: 770, loss: 0.12311288714408875
step: 780, loss: 0.0575505867600441
step: 790, loss: 0.0610412061214447
step: 800, loss: 0.07887782901525497
step: 810, loss: 0.06720352917909622
step: 820, loss: 0.10367818921804428
step: 830, loss: 0.03629453852772713
step: 840, loss: 0.033570725470781326
step: 850, loss: 0.07848220318555832
step: 860, loss: 0.07231976091861725
step: 870, loss: 0.037781503051519394
step: 880, loss: 0.09547192603349686
step: 890, loss: 0.09119771420955658
step: 900, loss: 0.024251947179436684
step: 910, loss: 0.06265856325626373
step: 920, loss: 0.056173231452703476
step: 930, loss: 0.06781665235757828
step: 940, loss: 0.07480726391077042
step: 950, loss: 0.0003855409740936011
step: 960, loss: 0.04966336116194725
step: 970, loss: 0.06640218943357468
epoch 16: dev_f1=0.9278734295020938, f1=0.924074074074074, best_f1=0.9301688726608854
step: 0, loss: 0.04071670025587082
step: 10, loss: 0.01719607599079609
step: 20, loss: 0.08846190571784973
step: 30, loss: 0.04731179028749466
step: 40, loss: 0.043180257081985474
step: 50, loss: 0.016374776139855385
step: 60, loss: 0.056775059551000595
step: 70, loss: 0.05040343105792999
step: 80, loss: 0.04539330303668976
step: 90, loss: 0.05283799394965172
step: 100, loss: 0.04691042751073837
step: 110, loss: 0.05477672442793846
step: 120, loss: 0.04921191558241844
step: 130, loss: 0.1638275682926178
step: 140, loss: 0.0003184215456712991
step: 150, loss: 0.07679791748523712
step: 160, loss: 0.08936147391796112
step: 170, loss: 0.04056597873568535
step: 180, loss: 0.18073680996894836
step: 190, loss: 0.1056637391448021
step: 200, loss: 0.01448084320873022
step: 210, loss: 0.17333365976810455
step: 220, loss: 0.025713223963975906
step: 230, loss: 0.14942339062690735
step: 240, loss: 0.04181138798594475
step: 250, loss: 0.0653492659330368
step: 260, loss: 0.05267069861292839
step: 270, loss: 0.007674583233892918
step: 280, loss: 0.08805239200592041
step: 290, loss: 0.05383594334125519
step: 300, loss: 0.018583808094263077
step: 310, loss: 0.006604996509850025
step: 320, loss: 0.026039615273475647
step: 330, loss: 0.07245047390460968
step: 340, loss: 0.1296854317188263
step: 350, loss: 0.11754489690065384
step: 360, loss: 0.015073563903570175
step: 370, loss: 0.001415915321558714
step: 380, loss: 0.06503593176603317
step: 390, loss: 0.08969283103942871
step: 400, loss: 0.04399547725915909
step: 410, loss: 0.041399870067834854
step: 420, loss: 0.05250566080212593
step: 430, loss: 0.07364533096551895
step: 440, loss: 0.10416572540998459
step: 450, loss: 0.05024399235844612
step: 460, loss: 0.03777483105659485
step: 470, loss: 0.023138925433158875
step: 480, loss: 0.07597120106220245
step: 490, loss: 0.0201597698032856
step: 500, loss: 0.029481282457709312
step: 510, loss: 0.07696331292390823
step: 520, loss: 0.056430697441101074
step: 530, loss: 0.04026723653078079
step: 540, loss: 0.018539177253842354
step: 550, loss: 0.017510583624243736
step: 560, loss: 0.03507257252931595
step: 570, loss: 0.07254566997289658
step: 580, loss: 0.028713863343000412
step: 590, loss: 0.05164637416601181
step: 600, loss: 0.04554291069507599
step: 610, loss: 0.0375501923263073
step: 620, loss: 0.020542681217193604
step: 630, loss: 0.0161229707300663
step: 640, loss: 0.0222815852612257
step: 650, loss: 0.15313978493213654
step: 660, loss: 0.018846046179533005
step: 670, loss: 0.0002888433518819511
step: 680, loss: 0.03162827342748642
step: 690, loss: 0.037212103605270386
step: 700, loss: 0.04249798133969307
step: 710, loss: 0.04374964162707329
step: 720, loss: 0.08308890461921692
step: 730, loss: 0.03761500120162964
step: 740, loss: 0.10885225236415863
step: 750, loss: 0.013720095157623291
step: 760, loss: 0.04704570770263672
step: 770, loss: 0.045056361705064774
step: 780, loss: 0.058233700692653656
step: 790, loss: 0.03105809912085533
step: 800, loss: 0.05929692089557648
step: 810, loss: 0.02160465344786644
step: 820, loss: 0.1483815461397171
step: 830, loss: 0.046335406601428986
step: 840, loss: 0.038796231150627136
step: 850, loss: 0.02955852448940277
step: 860, loss: 0.06075344234704971
step: 870, loss: 0.07433772087097168
step: 880, loss: 0.03228772059082985
step: 890, loss: 0.05600692331790924
step: 900, loss: 0.0720290020108223
step: 910, loss: 0.07729794830083847
step: 920, loss: 0.029034476727247238
step: 930, loss: 0.06706766039133072
step: 940, loss: 0.03722764924168587
step: 950, loss: 0.11774802953004837
step: 960, loss: 0.017754293978214264
step: 970, loss: 0.03243204578757286
epoch 17: dev_f1=0.9296296296296297, f1=0.9259944495837188, best_f1=0.9301688726608854
step: 0, loss: 0.025603897869586945
step: 10, loss: 0.07572704553604126
step: 20, loss: 0.029429476708173752
step: 30, loss: 0.04512317106127739
step: 40, loss: 0.05661411210894585
step: 50, loss: 0.03951705992221832
step: 60, loss: 0.03282896429300308
step: 70, loss: 0.03202289342880249
step: 80, loss: 0.04633041098713875
step: 90, loss: 0.029196517542004585
step: 100, loss: 0.03137363865971565
step: 110, loss: 0.024325527250766754
step: 120, loss: 4.087607157998718e-05
step: 130, loss: 0.05176577717065811
step: 140, loss: 0.0334622785449028
step: 150, loss: 0.0009347394807264209
step: 160, loss: 0.02698301337659359
step: 170, loss: 0.07959864288568497
step: 180, loss: 0.14940592646598816
step: 190, loss: 0.058117397129535675
step: 200, loss: 5.770759889855981e-05
step: 210, loss: 0.07172876596450806
step: 220, loss: 0.058688223361968994
step: 230, loss: 0.01212671585381031
step: 240, loss: 0.056385546922683716
step: 250, loss: 0.08792395144701004
step: 260, loss: 0.0005832759779877961
step: 270, loss: 0.04366021603345871
step: 280, loss: 0.007595148868858814
step: 290, loss: 0.06820378452539444
step: 300, loss: 0.04149618744850159
step: 310, loss: 0.05882292985916138
step: 320, loss: 0.08713963627815247
step: 330, loss: 0.03499774634838104
step: 340, loss: 0.014061618596315384
step: 350, loss: 0.02459299936890602
step: 360, loss: 0.00020218435383867472
step: 370, loss: 0.03931961581110954
step: 380, loss: 0.05683930963277817
step: 390, loss: 0.07413742691278458
step: 400, loss: 5.997510379529558e-05
step: 410, loss: 0.036052241921424866
step: 420, loss: 0.052928682416677475
step: 430, loss: 0.02199135534465313
step: 440, loss: 0.002504453295841813
step: 450, loss: 0.0001223339349962771
step: 460, loss: 0.05584406107664108
step: 470, loss: 0.031411007046699524
step: 480, loss: 0.08648049831390381
step: 490, loss: 0.019464759156107903
step: 500, loss: 0.0004889806732535362
step: 510, loss: 0.04313039407134056
step: 520, loss: 0.057452697306871414
step: 530, loss: 0.004008213058114052
step: 540, loss: 0.04163888841867447
step: 550, loss: 0.033108532428741455
step: 560, loss: 0.011804550886154175
step: 570, loss: 0.04667138680815697
step: 580, loss: 0.15518125891685486
step: 590, loss: 0.04365479573607445
step: 600, loss: 0.12621599435806274
step: 610, loss: 0.06361488997936249
step: 620, loss: 0.00024182505148928612
step: 630, loss: 0.01874568685889244
step: 640, loss: 0.10561031848192215
step: 650, loss: 0.039659760892391205
step: 660, loss: 0.021701309829950333
step: 670, loss: 0.03199736401438713
step: 680, loss: 0.0048877461813390255
step: 690, loss: 0.04307161271572113
step: 700, loss: 0.06795516610145569
step: 710, loss: 0.04515610635280609
step: 720, loss: 0.0005065189325250685
step: 730, loss: 0.0746341198682785
step: 740, loss: 0.0060407985001802444
step: 750, loss: 0.04759273678064346
step: 760, loss: 0.05507553741335869
step: 770, loss: 0.02829529158771038
step: 780, loss: 0.04018536955118179
step: 790, loss: 0.022125203162431717
step: 800, loss: 0.006378492806106806
step: 810, loss: 0.12903502583503723
step: 820, loss: 0.1637941300868988
step: 830, loss: 0.056950610131025314
step: 840, loss: 0.0015648762928321958
step: 850, loss: 0.019063737243413925
step: 860, loss: 0.09932389110326767
step: 870, loss: 0.13028693199157715
step: 880, loss: 0.08349668979644775
step: 890, loss: 0.018458180129528046
step: 900, loss: 0.00631746044382453
step: 910, loss: 0.02938537299633026
step: 920, loss: 0.11312846839427948
step: 930, loss: 0.04398589953780174
step: 940, loss: 0.018996119499206543
step: 950, loss: 0.013079842552542686
step: 960, loss: 0.011462689377367496
step: 970, loss: 0.03901143744587898
epoch 18: dev_f1=0.9281352747768906, f1=0.9231490159325211, best_f1=0.9301688726608854
step: 0, loss: 0.0996532067656517
step: 10, loss: 0.029568811878561974
step: 20, loss: 0.05118777975440025
step: 30, loss: 0.0021894981618970633
step: 40, loss: 0.09067825973033905
step: 50, loss: 0.0009222298976965249
step: 60, loss: 0.043844737112522125
step: 70, loss: 0.013910839334130287
step: 80, loss: 0.04958810284733772
step: 90, loss: 0.0689079612493515
step: 100, loss: 0.055061474442481995
step: 110, loss: 0.0010463102953508496
step: 120, loss: 0.12329928576946259
step: 130, loss: 0.09974145889282227
step: 140, loss: 0.05522859841585159
step: 150, loss: 0.03857067972421646
step: 160, loss: 0.07325844466686249
step: 170, loss: 0.07212553918361664
step: 180, loss: 0.06850452721118927
step: 190, loss: 0.04323249310255051
step: 200, loss: 0.028666255995631218
step: 210, loss: 0.07249440252780914
step: 220, loss: 0.05855816230177879
step: 230, loss: 0.03359518200159073
step: 240, loss: 0.1528061032295227
step: 250, loss: 0.08017700910568237
step: 260, loss: 0.00832928903400898
step: 270, loss: 4.722458470496349e-05
step: 280, loss: 0.07804126292467117
step: 290, loss: 0.0358692891895771
step: 300, loss: 0.0030569646041840315
step: 310, loss: 0.03517391160130501
step: 320, loss: 0.07718262076377869
step: 330, loss: 0.041804518550634384
step: 340, loss: 0.06452850997447968
step: 350, loss: 0.030581584200263023
step: 360, loss: 0.02975509501993656
step: 370, loss: 0.1207185685634613
step: 380, loss: 0.03225862607359886
step: 390, loss: 0.011695998720824718
step: 400, loss: 0.03901784494519234
step: 410, loss: 0.0557931512594223
step: 420, loss: 0.0062074726447463036
step: 430, loss: 0.00028320064302533865
step: 440, loss: 0.00013386027421802282
step: 450, loss: 0.014440497383475304
step: 460, loss: 0.05614595115184784
step: 470, loss: 0.07682488858699799
step: 480, loss: 0.04666292294859886
step: 490, loss: 0.06512036919593811
step: 500, loss: 0.023602042347192764
step: 510, loss: 0.027209164574742317
step: 520, loss: 0.08217043429613113
step: 530, loss: 0.01169686857610941
step: 540, loss: 0.04492911696434021
step: 550, loss: 0.06444393843412399
step: 560, loss: 0.09730954468250275
step: 570, loss: 0.05181387811899185
step: 580, loss: 4.63618416688405e-05
step: 590, loss: 0.053911276161670685
step: 600, loss: 0.042375724762678146
step: 610, loss: 0.05214953050017357
step: 620, loss: 0.04040367901325226
step: 630, loss: 0.027565663680434227
step: 640, loss: 0.016673138365149498
step: 650, loss: 0.047949645668268204
step: 660, loss: 0.03755233436822891
step: 670, loss: 0.08825141936540604
step: 680, loss: 0.050769101828336716
step: 690, loss: 0.040563881397247314
step: 700, loss: 0.025030072778463364
step: 710, loss: 0.038843583315610886
step: 720, loss: 0.02276104874908924
step: 730, loss: 0.07176484912633896
step: 740, loss: 0.04984971135854721
step: 750, loss: 0.1308593899011612
step: 760, loss: 0.06394723057746887
step: 770, loss: 0.05436723306775093
step: 780, loss: 0.05232420191168785
step: 790, loss: 0.01680343598127365
step: 800, loss: 0.0540965311229229
step: 810, loss: 0.07521801441907883
step: 820, loss: 0.07667261362075806
step: 830, loss: 0.05562863126397133
step: 840, loss: 0.07190053910017014
step: 850, loss: 0.11294278502464294
step: 860, loss: 0.019852662459015846
step: 870, loss: 0.07862697541713715
step: 880, loss: 0.027119778096675873
step: 890, loss: 0.054753635078668594
step: 900, loss: 0.03341533988714218
step: 910, loss: 0.044123534113168716
step: 920, loss: 0.03923969715833664
step: 930, loss: 0.05628589913249016
step: 940, loss: 0.0800023302435875
step: 950, loss: 0.049260254949331284
step: 960, loss: 0.07513115555047989
step: 970, loss: 0.02368544414639473
epoch 19: dev_f1=0.9240986717267552, f1=0.9195837275307474, best_f1=0.9301688726608854
step: 0, loss: 0.025343261659145355
step: 10, loss: 0.033874403685331345
step: 20, loss: 0.042570941150188446
step: 30, loss: 0.07785483449697495
step: 40, loss: 0.026892516762018204
step: 50, loss: 0.08091183006763458
step: 60, loss: 0.0176622923463583
step: 70, loss: 0.09440158307552338
step: 80, loss: 0.06671490520238876
step: 90, loss: 0.053114328533411026
step: 100, loss: 0.0001957819185918197
step: 110, loss: 0.06537666916847229
step: 120, loss: 0.09224534779787064
step: 130, loss: 0.04069029539823532
step: 140, loss: 0.0002822749665938318
step: 150, loss: 0.050127409398555756
step: 160, loss: 0.0001959067303687334
step: 170, loss: 0.022130588069558144
step: 180, loss: 0.015842624008655548
step: 190, loss: 0.00010428793757455423
step: 200, loss: 0.05459088459610939
step: 210, loss: 0.014853707514703274
step: 220, loss: 0.04110521450638771
step: 230, loss: 0.04928060993552208
step: 240, loss: 0.03899523243308067
step: 250, loss: 0.05669466033577919
step: 260, loss: 7.685239324928261e-06
step: 270, loss: 0.040356580168008804
step: 280, loss: 0.08485480397939682
step: 290, loss: 0.049410879611968994
step: 300, loss: 0.03777986764907837
step: 310, loss: 0.13688179850578308
step: 320, loss: 7.092609303072095e-05
step: 330, loss: 0.03524492308497429
step: 340, loss: 0.09650302678346634
step: 350, loss: 0.04367821663618088
step: 360, loss: 0.03034343011677265
step: 370, loss: 0.06895723938941956
step: 380, loss: 0.037553414702415466
step: 390, loss: 0.022774428129196167
step: 400, loss: 0.04555058479309082
step: 410, loss: 0.055747512727975845
step: 420, loss: 0.04397173970937729
step: 430, loss: 0.12443661689758301
step: 440, loss: 0.02477685920894146
step: 450, loss: 0.032275933772325516
step: 460, loss: 0.00042797328205779195
step: 470, loss: 0.026310104876756668
step: 480, loss: 0.051940448582172394
step: 490, loss: 0.08020499348640442
step: 500, loss: 0.0001428199466317892
step: 510, loss: 0.022216590121388435
step: 520, loss: 0.012599100358784199
step: 530, loss: 0.0001540621160529554
step: 540, loss: 0.06955060362815857
step: 550, loss: 0.061730045825242996
step: 560, loss: 0.02222832478582859
step: 570, loss: 0.021242817863821983
step: 580, loss: 0.0779753178358078
step: 590, loss: 0.0051867165602743626
step: 600, loss: 0.01575339026749134
step: 610, loss: 0.0012174281291663647
step: 620, loss: 0.014301072806119919
step: 630, loss: 0.09643861651420593
step: 640, loss: 0.0730477049946785
step: 650, loss: 0.039779357612133026
step: 660, loss: 0.0347793884575367
step: 670, loss: 0.02372307889163494
step: 680, loss: 0.008741232566535473
step: 690, loss: 0.06612787395715714
step: 700, loss: 0.04366975650191307
step: 710, loss: 0.07722782343626022
step: 720, loss: 0.03811268135905266
step: 730, loss: 0.03495790436863899
step: 740, loss: 0.04944495111703873
step: 750, loss: 0.05106595158576965
step: 760, loss: 0.04138218238949776
step: 770, loss: 0.03520571067929268
step: 780, loss: 0.010505013167858124
step: 790, loss: 0.2351645529270172
step: 800, loss: 0.025541234761476517
step: 810, loss: 0.02956424281001091
step: 820, loss: 0.04730004817247391
step: 830, loss: 0.01809946820139885
step: 840, loss: 0.0014642366440966725
step: 850, loss: 0.03148863464593887
step: 860, loss: 0.060058191418647766
step: 870, loss: 0.07336509227752686
step: 880, loss: 0.025449223816394806
step: 890, loss: 0.020937152206897736
step: 900, loss: 0.06838396936655045
step: 910, loss: 0.08290074020624161
step: 920, loss: 0.020296216011047363
step: 930, loss: 0.04518599808216095
step: 940, loss: 0.025830907747149467
step: 950, loss: 0.012781969271600246
step: 960, loss: 0.004039321560412645
step: 970, loss: 0.09111224114894867
epoch 20: dev_f1=0.924741298212606, f1=0.9235100891600189, best_f1=0.9301688726608854
