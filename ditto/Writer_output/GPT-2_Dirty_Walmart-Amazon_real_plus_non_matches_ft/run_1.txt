cuda
Device: cuda
step: 0, loss: 0.651669979095459
step: 10, loss: 0.23241646587848663
step: 20, loss: 0.3110441565513611
step: 30, loss: 0.41454410552978516
step: 40, loss: 0.08595173805952072
step: 50, loss: 0.23377245664596558
step: 60, loss: 0.2574191689491272
step: 70, loss: 0.07415279746055603
step: 80, loss: 0.15071433782577515
step: 90, loss: 0.15810629725456238
step: 100, loss: 0.14369644224643707
step: 110, loss: 0.13958591222763062
step: 120, loss: 0.14047065377235413
step: 130, loss: 0.045579228550195694
step: 140, loss: 0.1348617821931839
step: 150, loss: 0.5707876086235046
step: 160, loss: 0.1514827013015747
step: 170, loss: 0.3914988040924072
step: 180, loss: 0.3260462284088135
step: 190, loss: 0.15301594138145447
step: 200, loss: 0.014295579865574837
step: 210, loss: 0.1322391778230667
step: 220, loss: 0.22898346185684204
step: 230, loss: 0.13315176963806152
step: 240, loss: 0.21221862733364105
step: 250, loss: 0.08153380453586578
step: 260, loss: 0.20000261068344116
step: 270, loss: 0.21918442845344543
step: 280, loss: 0.29033422470092773
step: 290, loss: 0.1338871866464615
step: 300, loss: 0.1350974142551422
step: 310, loss: 0.03104652464389801
step: 320, loss: 0.03233332931995392
step: 330, loss: 0.03911196440458298
step: 340, loss: 0.16037645936012268
step: 350, loss: 0.11454937607049942
step: 360, loss: 0.26091715693473816
epoch 1: dev_f1=0.30804077010192527, f1=0.3, best_f1=0.3
step: 0, loss: 0.12183596938848495
step: 10, loss: 0.1915677934885025
step: 20, loss: 0.2769131064414978
step: 30, loss: 0.09694597125053406
step: 40, loss: 0.184355691075325
step: 50, loss: 0.3269503116607666
step: 60, loss: 0.15238916873931885
step: 70, loss: 0.14091601967811584
step: 80, loss: 0.2727724015712738
step: 90, loss: 0.1922420710325241
step: 100, loss: 0.11759503185749054
step: 110, loss: 0.14615832269191742
step: 120, loss: 0.0826713964343071
step: 130, loss: 0.0685998946428299
step: 140, loss: 0.0337732695043087
step: 150, loss: 0.12528878450393677
step: 160, loss: 0.27942967414855957
step: 170, loss: 0.18619464337825775
step: 180, loss: 0.26154303550720215
step: 190, loss: 0.1333080679178238
step: 200, loss: 0.13925206661224365
step: 210, loss: 0.11274845898151398
step: 220, loss: 0.12638668715953827
step: 230, loss: 0.21426188945770264
step: 240, loss: 0.20200857520103455
step: 250, loss: 0.19783207774162292
step: 260, loss: 0.2994392514228821
step: 270, loss: 0.17266546189785004
step: 280, loss: 0.06100263074040413
step: 290, loss: 0.1265285164117813
step: 300, loss: 0.17973440885543823
step: 310, loss: 0.13476569950580597
step: 320, loss: 0.15978990495204926
step: 330, loss: 0.12399686127901077
step: 340, loss: 0.18636620044708252
step: 350, loss: 0.18275712430477142
step: 360, loss: 0.016885612159967422
epoch 2: dev_f1=0.600461893764434, f1=0.608695652173913, best_f1=0.608695652173913
step: 0, loss: 0.16384932398796082
step: 10, loss: 0.034632571041584015
step: 20, loss: 0.09810696542263031
step: 30, loss: 0.2226332426071167
step: 40, loss: 0.05707325041294098
step: 50, loss: 0.12004386633634567
step: 60, loss: 0.0347784198820591
step: 70, loss: 0.16996382176876068
step: 80, loss: 0.0655805766582489
step: 90, loss: 0.03024161420762539
step: 100, loss: 0.014399957843124866
step: 110, loss: 0.12414582818746567
step: 120, loss: 0.1568630337715149
step: 130, loss: 0.006022138521075249
step: 140, loss: 0.052724242210388184
step: 150, loss: 0.07352683693170547
step: 160, loss: 0.07658402621746063
step: 170, loss: 0.10180385410785675
step: 180, loss: 0.010762320831418037
step: 190, loss: 0.174326553940773
step: 200, loss: 0.025489121675491333
step: 210, loss: 0.13135159015655518
step: 220, loss: 0.13562607765197754
step: 230, loss: 0.004950127098709345
step: 240, loss: 0.14030621945858002
step: 250, loss: 0.025467978790402412
step: 260, loss: 0.1668744534254074
step: 270, loss: 0.055115655064582825
step: 280, loss: 0.0544646717607975
step: 290, loss: 0.13276372849941254
step: 300, loss: 0.045175597071647644
step: 310, loss: 0.028715351596474648
step: 320, loss: 0.034522924572229385
step: 330, loss: 0.03460080921649933
step: 340, loss: 0.019010715186595917
step: 350, loss: 0.05576638504862785
step: 360, loss: 0.11958178132772446
epoch 3: dev_f1=0.5957446808510637, f1=0.5857519788918205, best_f1=0.608695652173913
step: 0, loss: 0.013715743087232113
step: 10, loss: 0.044114723801612854
step: 20, loss: 0.05469883605837822
step: 30, loss: 0.03422843664884567
step: 40, loss: 0.0551903061568737
step: 50, loss: 0.010285057127475739
step: 60, loss: 0.02950674667954445
step: 70, loss: 0.10652580857276917
step: 80, loss: 0.005896982736885548
step: 90, loss: 0.10330459475517273
step: 100, loss: 0.08667205274105072
step: 110, loss: 0.02088881842792034
step: 120, loss: 0.04332026094198227
step: 130, loss: 0.17493492364883423
step: 140, loss: 0.00557295186445117
step: 150, loss: 0.004200226627290249
step: 160, loss: 0.05282042175531387
step: 170, loss: 0.0016244755825027823
step: 180, loss: 0.13339562714099884
step: 190, loss: 0.041912198066711426
step: 200, loss: 0.01937086321413517
step: 210, loss: 0.14986908435821533
step: 220, loss: 0.08859816938638687
step: 230, loss: 0.022955479100346565
step: 240, loss: 0.03713254630565643
step: 250, loss: 0.09250729531049728
step: 260, loss: 0.00874901469796896
step: 270, loss: 0.023589450865983963
step: 280, loss: 0.10833533853292465
step: 290, loss: 0.02837110124528408
step: 300, loss: 0.10153236985206604
step: 310, loss: 0.03660828247666359
step: 320, loss: 0.044053029268980026
step: 330, loss: 0.014541583135724068
step: 340, loss: 0.012584243901073933
step: 350, loss: 0.015725260600447655
step: 360, loss: 0.1872614026069641
epoch 4: dev_f1=0.6469135802469136, f1=0.6347607052896725, best_f1=0.6347607052896725
step: 0, loss: 0.057313285768032074
step: 10, loss: 0.015069973655045033
step: 20, loss: 0.04079918563365936
step: 30, loss: 0.013595642521977425
step: 40, loss: 0.03307141363620758
step: 50, loss: 0.005395539104938507
step: 60, loss: 0.19474227726459503
step: 70, loss: 0.01563919149339199
step: 80, loss: 0.06321381032466888
step: 90, loss: 0.034591883420944214
step: 100, loss: 0.0004907292313873768
step: 110, loss: 0.06130245700478554
step: 120, loss: 0.12573140859603882
step: 130, loss: 0.003690598998218775
step: 140, loss: 0.02081184647977352
step: 150, loss: 0.06130624935030937
step: 160, loss: 0.1395546793937683
step: 170, loss: 0.04849911481142044
step: 180, loss: 0.03838922828435898
step: 190, loss: 0.04441985487937927
step: 200, loss: 0.039648499339818954
step: 210, loss: 0.01364459190517664
step: 220, loss: 0.08229481428861618
step: 230, loss: 0.024850836023688316
step: 240, loss: 0.030786434188485146
step: 250, loss: 0.001428923336789012
step: 260, loss: 0.002009978983551264
step: 270, loss: 0.25484001636505127
step: 280, loss: 0.013964123092591763
step: 290, loss: 0.007620986085385084
step: 300, loss: 0.021290011703968048
step: 310, loss: 0.021289614960551262
step: 320, loss: 0.006004431284964085
step: 330, loss: 0.03418701887130737
step: 340, loss: 0.00235020206309855
step: 350, loss: 0.007867041043937206
step: 360, loss: 0.01846315898001194
epoch 5: dev_f1=0.615, f1=0.6243654822335025, best_f1=0.6347607052896725
step: 0, loss: 0.009750058874487877
step: 10, loss: 0.014844151213765144
step: 20, loss: 0.0018648571567609906
step: 30, loss: 0.006568231154233217
step: 40, loss: 0.01794958859682083
step: 50, loss: 0.002683287486433983
step: 60, loss: 0.0027106795459985733
step: 70, loss: 0.027329878881573677
step: 80, loss: 0.010389309376478195
step: 90, loss: 0.0001864284131443128
step: 100, loss: 0.0030047548934817314
step: 110, loss: 0.09277910739183426
step: 120, loss: 0.004458419978618622
step: 130, loss: 0.02913476899266243
step: 140, loss: 0.04253584146499634
step: 150, loss: 0.010793101973831654
step: 160, loss: 0.003523916006088257
step: 170, loss: 0.0019577648490667343
step: 180, loss: 0.0649447813630104
step: 190, loss: 0.011090455576777458
step: 200, loss: 0.02361796796321869
step: 210, loss: 0.016009490936994553
step: 220, loss: 0.0005861573154106736
step: 230, loss: 0.0467953234910965
step: 240, loss: 0.0064458707347512245
step: 250, loss: 0.1983342319726944
step: 260, loss: 0.0503862090408802
step: 270, loss: 0.006044500973075628
step: 280, loss: 0.008544611744582653
step: 290, loss: 0.001577224349603057
step: 300, loss: 0.04408989101648331
step: 310, loss: 0.002472769236192107
step: 320, loss: 0.05722794681787491
step: 330, loss: 0.0034162478987127542
step: 340, loss: 0.015403767116367817
step: 350, loss: 0.06965244561433792
step: 360, loss: 0.01402248628437519
epoch 6: dev_f1=0.6365795724465558, f1=0.6435643564356435, best_f1=0.6347607052896725
step: 0, loss: 0.017296086996793747
step: 10, loss: 0.004229951649904251
step: 20, loss: 0.03325636312365532
step: 30, loss: 0.001879216986708343
step: 40, loss: 0.006523165851831436
step: 50, loss: 0.002603665692731738
step: 60, loss: 0.0007482399232685566
step: 70, loss: 0.013848311267793179
step: 80, loss: 0.008886398747563362
step: 90, loss: 0.0033284476958215237
step: 100, loss: 0.004285422619432211
step: 110, loss: 0.0016980080399662256
step: 120, loss: 0.04141926392912865
step: 130, loss: 0.01407393254339695
step: 140, loss: 0.07144327461719513
step: 150, loss: 0.01379067450761795
step: 160, loss: 0.001280921627767384
step: 170, loss: 0.07744510471820831
step: 180, loss: 0.040265683084726334
step: 190, loss: 0.016382034868001938
step: 200, loss: 0.004024932626634836
step: 210, loss: 0.020057039335370064
step: 220, loss: 0.008779382333159447
step: 230, loss: 0.0007785764173604548
step: 240, loss: 0.008365641348063946
step: 250, loss: 0.04080519080162048
step: 260, loss: 0.010171806439757347
step: 270, loss: 0.0010050773853436112
step: 280, loss: 0.01780286803841591
step: 290, loss: 0.008308855816721916
step: 300, loss: 0.03306245803833008
step: 310, loss: 0.012557613663375378
step: 320, loss: 0.01672532595694065
step: 330, loss: 0.033820148557424545
step: 340, loss: 0.030806053429841995
step: 350, loss: 0.17429067194461823
step: 360, loss: 0.09284317493438721
epoch 7: dev_f1=0.6574712643678161, f1=0.6118721461187214, best_f1=0.6118721461187214
step: 0, loss: 0.11641661822795868
step: 10, loss: 0.006781154777854681
step: 20, loss: 0.0037115251179784536
step: 30, loss: 0.0009333872585557401
step: 40, loss: 0.0007318979478441179
step: 50, loss: 0.00923341978341341
step: 60, loss: 0.00762393232434988
step: 70, loss: 0.0012129059759899974
step: 80, loss: 0.00152406538836658
step: 90, loss: 0.008140355348587036
step: 100, loss: 0.0022819547448307276
step: 110, loss: 0.01924287900328636
step: 120, loss: 0.03306354954838753
step: 130, loss: 0.0015138817252591252
step: 140, loss: 0.005702754482626915
step: 150, loss: 0.0012848338810727
step: 160, loss: 0.005274374969303608
step: 170, loss: 0.09128871560096741
step: 180, loss: 0.0067251319997012615
step: 190, loss: 0.03438494727015495
step: 200, loss: 0.012083813548088074
step: 210, loss: 0.003188144648447633
step: 220, loss: 0.0003013254317920655
step: 230, loss: 0.0008094973163679242
step: 240, loss: 0.0031679407693445683
step: 250, loss: 0.0023446353152394295
step: 260, loss: 0.03318601846694946
step: 270, loss: 0.007495757192373276
step: 280, loss: 0.013551493175327778
step: 290, loss: 0.00017753153224475682
step: 300, loss: 0.0003595991584006697
step: 310, loss: 0.0006017955020070076
step: 320, loss: 0.000951868889387697
step: 330, loss: 0.045851100236177444
step: 340, loss: 0.011449330486357212
step: 350, loss: 0.0019004871137440205
step: 360, loss: 0.01698777638375759
epoch 8: dev_f1=0.6294117647058824, f1=0.5414012738853504, best_f1=0.6118721461187214
step: 0, loss: 0.0038711128290742636
step: 10, loss: 0.018390728160738945
step: 20, loss: 0.010210546664893627
step: 30, loss: 0.011838654056191444
step: 40, loss: 0.006381177343428135
step: 50, loss: 0.0006938767619431019
step: 60, loss: 0.0011601492296904325
step: 70, loss: 0.0006777352537028491
step: 80, loss: 0.00028592790476977825
step: 90, loss: 0.0007905946695245802
step: 100, loss: 0.0005134473321959376
step: 110, loss: 0.0005976256215944886
step: 120, loss: 0.00012080172018613666
step: 130, loss: 0.0011599288554862142
step: 140, loss: 0.00042469569598324597
step: 150, loss: 0.000489116704557091
step: 160, loss: 0.0007845310028642416
step: 170, loss: 0.0006237758207134902
step: 180, loss: 0.031492359936237335
step: 190, loss: 0.0003849166678264737
step: 200, loss: 0.024316200986504555
step: 210, loss: 0.00018001561693381518
step: 220, loss: 0.0027590855024755
step: 230, loss: 0.0010723491432145238
step: 240, loss: 0.008062552660703659
step: 250, loss: 0.03342525660991669
step: 260, loss: 0.0016179095255210996
step: 270, loss: 0.002678967546671629
step: 280, loss: 0.0002700605255085975
step: 290, loss: 0.000500619295053184
step: 300, loss: 0.0002752524451352656
step: 310, loss: 0.020274009555578232
step: 320, loss: 9.289451554650441e-05
step: 330, loss: 0.0014685768401250243
step: 340, loss: 0.004541353322565556
step: 350, loss: 0.0006581769557669759
step: 360, loss: 0.0022355704568326473
epoch 9: dev_f1=0.6463414634146342, f1=0.5914634146341464, best_f1=0.6118721461187214
step: 0, loss: 0.00020406526164151728
step: 10, loss: 0.00011618680582614616
step: 20, loss: 0.0003555916191544384
step: 30, loss: 0.0001324090699199587
step: 40, loss: 0.07217714935541153
step: 50, loss: 0.007681733462959528
step: 60, loss: 0.0008558699046261609
step: 70, loss: 0.01098527479916811
step: 80, loss: 5.95479468756821e-05
step: 90, loss: 0.00015010802599135786
step: 100, loss: 0.0037391663063317537
step: 110, loss: 0.04968376085162163
step: 120, loss: 0.0006526466459035873
step: 130, loss: 0.0001565725397085771
step: 140, loss: 0.02123991772532463
step: 150, loss: 0.0034625919070094824
step: 160, loss: 0.001970085548236966
step: 170, loss: 0.00010584789561107755
step: 180, loss: 0.0006418601260520518
step: 190, loss: 0.0022332253865897655
step: 200, loss: 0.014226028695702553
step: 210, loss: 0.00014157673285808414
step: 220, loss: 0.0004571636382024735
step: 230, loss: 0.0010197104420512915
step: 240, loss: 0.0004266073810867965
step: 250, loss: 0.014538710005581379
step: 260, loss: 0.0014098581159487367
step: 270, loss: 0.01889854297041893
step: 280, loss: 0.0004967273562215269
step: 290, loss: 0.00029605565941892564
step: 300, loss: 0.0006631678552366793
step: 310, loss: 0.06822914630174637
step: 320, loss: 0.0004226528399158269
step: 330, loss: 0.11536698043346405
step: 340, loss: 0.0033831519540399313
step: 350, loss: 0.00013908806431572884
step: 360, loss: 0.010071775875985622
epoch 10: dev_f1=0.6366197183098592, f1=0.5875370919881306, best_f1=0.6118721461187214
step: 0, loss: 0.0011358214542269707
step: 10, loss: 0.0037024489138275385
step: 20, loss: 0.0020023207180202007
step: 30, loss: 3.942311377613805e-05
step: 40, loss: 0.0016762773739174008
step: 50, loss: 0.04929427430033684
step: 60, loss: 0.00861451867967844
step: 70, loss: 0.00013671457418240607
step: 80, loss: 0.00019156723283231258
step: 90, loss: 0.0006245984113775194
step: 100, loss: 0.0003307224833406508
step: 110, loss: 0.00047466313117183745
step: 120, loss: 0.008576498366892338
step: 130, loss: 0.0004379006859380752
step: 140, loss: 0.0004105583648197353
step: 150, loss: 0.0001488460839027539
step: 160, loss: 0.002981391968205571
step: 170, loss: 0.0067113772965967655
step: 180, loss: 0.0024435538798570633
step: 190, loss: 0.0006924379267729819
step: 200, loss: 0.0004112960596103221
step: 210, loss: 0.0020579469855874777
step: 220, loss: 0.004636874422430992
step: 230, loss: 0.00015406246529892087
step: 240, loss: 0.00210630614310503
step: 250, loss: 0.005632141605019569
step: 260, loss: 0.0003895115223713219
step: 270, loss: 0.00013432327250484377
step: 280, loss: 5.941175913903862e-05
step: 290, loss: 0.006324952468276024
step: 300, loss: 4.4793163397116587e-05
step: 310, loss: 9.545391367282718e-05
step: 320, loss: 0.004463206045329571
step: 330, loss: 0.0018770538736134768
step: 340, loss: 5.390144724515267e-05
step: 350, loss: 0.00013112257875036448
step: 360, loss: 0.00010368056973675266
epoch 11: dev_f1=0.636604774535809, f1=0.6280991735537189, best_f1=0.6118721461187214
step: 0, loss: 0.00011933549831155688
step: 10, loss: 0.0001106107811210677
step: 20, loss: 6.771171319996938e-05
step: 30, loss: 0.006855478044599295
step: 40, loss: 0.0008941593114286661
step: 50, loss: 0.00016253202920779586
step: 60, loss: 0.0007921347860246897
step: 70, loss: 0.09348452091217041
step: 80, loss: 2.6102175979758613e-05
step: 90, loss: 0.0021892357617616653
step: 100, loss: 0.10555143654346466
step: 110, loss: 0.00023071179748512805
step: 120, loss: 0.012921661138534546
step: 130, loss: 0.0042435298673808575
step: 140, loss: 0.00018884905148297548
step: 150, loss: 0.000124236976262182
step: 160, loss: 0.0282302163541317
step: 170, loss: 0.002434004796668887
step: 180, loss: 8.622751920484006e-05
step: 190, loss: 0.0001415140723111108
step: 200, loss: 0.07952076941728592
step: 210, loss: 0.0006095548742450774
step: 220, loss: 0.0019027998205274343
step: 230, loss: 0.05094136297702789
step: 240, loss: 0.0029849433340132236
step: 250, loss: 0.00446346215903759
step: 260, loss: 0.006046769209206104
step: 270, loss: 0.03478629142045975
step: 280, loss: 0.007055708207190037
step: 290, loss: 0.006248930469155312
step: 300, loss: 0.0007359759765677154
step: 310, loss: 3.196571924490854e-05
step: 320, loss: 0.0002713851281441748
step: 330, loss: 0.00022957574401516467
step: 340, loss: 0.00023207238700706512
step: 350, loss: 0.00020429947471711785
step: 360, loss: 0.00016274457448162138
epoch 12: dev_f1=0.6376021798365122, f1=0.6243093922651933, best_f1=0.6118721461187214
step: 0, loss: 0.00104554055724293
step: 10, loss: 0.0006918710423633456
step: 20, loss: 0.00014241819735616446
step: 30, loss: 0.002409509848803282
step: 40, loss: 0.0017889260780066252
step: 50, loss: 0.00015229947166517377
step: 60, loss: 2.548410884628538e-05
step: 70, loss: 0.002334780525416136
step: 80, loss: 0.0007409613463096321
step: 90, loss: 0.00033723496017046273
step: 100, loss: 4.297899067751132e-05
step: 110, loss: 0.00013249143376015127
step: 120, loss: 0.002347253728657961
step: 130, loss: 0.003050409024581313
step: 140, loss: 0.005370438098907471
step: 150, loss: 0.05551617220044136
step: 160, loss: 0.0022013301495462656
step: 170, loss: 6.081260653445497e-05
step: 180, loss: 0.0001104725306504406
step: 190, loss: 0.00015215175517369062
step: 200, loss: 0.00021438203111756593
step: 210, loss: 0.0005422906251624227
step: 220, loss: 0.0005192058742977679
step: 230, loss: 0.00010358849976910278
step: 240, loss: 0.009619194082915783
step: 250, loss: 4.3255557102384046e-05
step: 260, loss: 0.0003678698849398643
step: 270, loss: 0.0008434659102931619
step: 280, loss: 8.212513057515025e-05
step: 290, loss: 3.1029929232317954e-05
step: 300, loss: 0.009690453298389912
step: 310, loss: 0.000793751678429544
step: 320, loss: 9.95792870526202e-05
step: 330, loss: 6.189750274643302e-05
step: 340, loss: 6.603043584618717e-05
step: 350, loss: 0.0006273740436881781
step: 360, loss: 0.04444208741188049
epoch 13: dev_f1=0.6290322580645162, f1=0.6208791208791209, best_f1=0.6118721461187214
step: 0, loss: 3.928682781406678e-05
step: 10, loss: 6.820735143264756e-05
step: 20, loss: 0.00032161365379579365
step: 30, loss: 0.002529887715354562
step: 40, loss: 0.00034041664912365377
step: 50, loss: 0.013706294819712639
step: 60, loss: 0.00021169632964301854
step: 70, loss: 6.630456482525915e-05
step: 80, loss: 0.0005157957784831524
step: 90, loss: 4.7886944230413064e-05
step: 100, loss: 9.267879067920148e-05
step: 110, loss: 0.008646135218441486
step: 120, loss: 0.00010457313328515738
step: 130, loss: 0.00031787503394298255
step: 140, loss: 0.0002550666104070842
step: 150, loss: 0.0001745140179991722
step: 160, loss: 0.00011315949814161286
step: 170, loss: 8.193765097530559e-05
step: 180, loss: 0.00013957267219666392
step: 190, loss: 0.0006544794305227697
step: 200, loss: 2.3975226213224232e-05
step: 210, loss: 3.84621525881812e-05
step: 220, loss: 4.586259092320688e-05
step: 230, loss: 6.862941518193111e-05
step: 240, loss: 0.00010903499787673354
step: 250, loss: 0.0005214299890212715
step: 260, loss: 0.0010539247887209058
step: 270, loss: 0.00012645841343328357
step: 280, loss: 0.00012467695341911167
step: 290, loss: 5.389314901549369e-05
step: 300, loss: 5.595493712462485e-05
step: 310, loss: 9.634192247176543e-05
step: 320, loss: 0.0009781986009329557
step: 330, loss: 2.3386444809148088e-05
step: 340, loss: 0.0004877067112829536
step: 350, loss: 2.8378166462061927e-05
step: 360, loss: 0.0006200166535563767
epoch 14: dev_f1=0.631868131868132, f1=0.6201117318435755, best_f1=0.6118721461187214
step: 0, loss: 3.0482164220302366e-05
step: 10, loss: 2.740560012171045e-05
step: 20, loss: 4.024506779387593e-05
step: 30, loss: 0.0011611796217039227
step: 40, loss: 9.013497765408829e-05
step: 50, loss: 0.000880094594322145
step: 60, loss: 0.005598571617156267
step: 70, loss: 0.00017769182159099728
step: 80, loss: 0.00046562054194509983
step: 90, loss: 0.0007962471572682261
step: 100, loss: 3.390542769921012e-05
step: 110, loss: 2.6326066290494055e-05
step: 120, loss: 0.0003099844616372138
step: 130, loss: 6.302996189333498e-05
step: 140, loss: 0.00024341873358935118
step: 150, loss: 0.0017734392313286662
step: 160, loss: 0.002400142140686512
step: 170, loss: 0.0017065316205844283
step: 180, loss: 0.000416635419242084
step: 190, loss: 0.0006662292289547622
step: 200, loss: 0.0003145946830045432
step: 210, loss: 0.002052100608125329
step: 220, loss: 8.649723167764023e-05
step: 230, loss: 0.0004760502779390663
step: 240, loss: 4.575397906592116e-05
step: 250, loss: 0.018460672348737717
step: 260, loss: 2.626968671393115e-05
step: 270, loss: 4.192730921204202e-05
step: 280, loss: 0.0030679763294756413
step: 290, loss: 9.080665768124163e-05
step: 300, loss: 6.0651713283732533e-05
step: 310, loss: 0.00016652396880090237
step: 320, loss: 5.88996299484279e-05
step: 330, loss: 0.00015287206042557955
step: 340, loss: 4.072708179592155e-05
step: 350, loss: 0.00028931431006640196
step: 360, loss: 5.472380871651694e-05
epoch 15: dev_f1=0.6666666666666667, f1=0.6510416666666666, best_f1=0.6510416666666666
step: 0, loss: 0.11743304878473282
step: 10, loss: 7.524913235101849e-05
step: 20, loss: 0.00013080613280180842
step: 30, loss: 9.052412497112527e-05
step: 40, loss: 1.3388598745223135e-05
step: 50, loss: 0.00014793299487791955
step: 60, loss: 3.4516164305387065e-05
step: 70, loss: 8.26472751214169e-05
step: 80, loss: 9.456167026655748e-05
step: 90, loss: 0.00026911660097539425
step: 100, loss: 0.00033959277789108455
step: 110, loss: 6.73960312269628e-05
step: 120, loss: 3.681028465507552e-05
step: 130, loss: 9.638503979658708e-05
step: 140, loss: 7.07592917024158e-05
step: 150, loss: 0.0044966633431613445
step: 160, loss: 0.00011499432002892718
step: 170, loss: 3.8995789509499446e-05
step: 180, loss: 1.8551463654148392e-05
step: 190, loss: 0.0043563880026340485
step: 200, loss: 1.5195305422821548e-05
step: 210, loss: 0.0074142650701105595
step: 220, loss: 0.00020828947890549898
step: 230, loss: 2.32636411965359e-05
step: 240, loss: 5.490554394782521e-05
step: 250, loss: 1.5653500668122433e-05
step: 260, loss: 0.00012501003220677376
step: 270, loss: 5.308838080964051e-05
step: 280, loss: 0.00052965700160712
step: 290, loss: 0.000797478889580816
step: 300, loss: 0.00014744811051059514
step: 310, loss: 2.587474591564387e-05
step: 320, loss: 0.06801377236843109
step: 330, loss: 0.00013719432172365487
step: 340, loss: 0.001512798829935491
step: 350, loss: 2.1818612367496826e-05
step: 360, loss: 0.000488726538605988
epoch 16: dev_f1=0.6218487394957983, f1=0.6228571428571429, best_f1=0.6510416666666666
step: 0, loss: 8.245569915743545e-05
step: 10, loss: 0.0004599886015057564
step: 20, loss: 0.0018126324284821749
step: 30, loss: 5.121410868014209e-05
step: 40, loss: 0.00012071474338881671
step: 50, loss: 0.0005933096399530768
step: 60, loss: 4.033850200357847e-05
step: 70, loss: 4.911689757136628e-05
step: 80, loss: 2.797942579491064e-05
step: 90, loss: 4.111220550839789e-05
step: 100, loss: 2.1665724489139393e-05
step: 110, loss: 0.0048098498955369
step: 120, loss: 6.565963849425316e-05
step: 130, loss: 0.00029422881198115647
step: 140, loss: 3.887517232215032e-05
step: 150, loss: 0.12495050579309464
step: 160, loss: 3.258303695474751e-05
step: 170, loss: 3.354364525876008e-05
step: 180, loss: 4.015734521090053e-05
step: 190, loss: 0.001118018408305943
step: 200, loss: 0.0025798664428293705
step: 210, loss: 0.002048608148470521
step: 220, loss: 0.00044260371942073107
step: 230, loss: 0.0013258056715130806
step: 240, loss: 0.0002978148404508829
step: 250, loss: 7.919109339127317e-05
step: 260, loss: 0.00011092024215031415
step: 270, loss: 6.388116889866069e-05
step: 280, loss: 0.0013202734990045428
step: 290, loss: 0.0009671715670265257
step: 300, loss: 0.0001989115116884932
step: 310, loss: 3.598998591769487e-05
step: 320, loss: 6.777315866202116e-05
step: 330, loss: 0.00016805771156214178
step: 340, loss: 4.729848660645075e-05
step: 350, loss: 0.00044044616515748203
step: 360, loss: 9.871577640296891e-05
epoch 17: dev_f1=0.6418338108882521, f1=0.6076696165191741, best_f1=0.6510416666666666
step: 0, loss: 2.2707870812155306e-05
step: 10, loss: 0.00015196834283415228
step: 20, loss: 3.3349111618008465e-05
step: 30, loss: 0.0004122065438423306
step: 40, loss: 3.194532109773718e-05
step: 50, loss: 0.0001297700364375487
step: 60, loss: 0.0007923777448013425
step: 70, loss: 4.422839265316725e-05
step: 80, loss: 8.311531564686447e-05
step: 90, loss: 0.0008642052998766303
step: 100, loss: 0.0002704448997974396
step: 110, loss: 3.862525773001835e-05
step: 120, loss: 0.0004528075223788619
step: 130, loss: 2.1222031136858277e-05
step: 140, loss: 2.5245421056752093e-05
step: 150, loss: 0.002127173123881221
step: 160, loss: 0.0009136039298027754
step: 170, loss: 4.675142190535553e-05
step: 180, loss: 0.0019141677767038345
step: 190, loss: 6.833549559814855e-05
step: 200, loss: 5.9256908571114764e-05
step: 210, loss: 3.797850149567239e-05
step: 220, loss: 2.7796551876235753e-05
step: 230, loss: 5.1797684136545286e-05
step: 240, loss: 0.0008145052124746144
step: 250, loss: 1.3288011359691154e-05
step: 260, loss: 7.769623334752396e-05
step: 270, loss: 0.00012380033149383962
step: 280, loss: 0.0003111800760962069
step: 290, loss: 5.160428554518148e-05
step: 300, loss: 2.0365228920127265e-05
step: 310, loss: 3.897115311701782e-05
step: 320, loss: 5.7047353038797155e-05
step: 330, loss: 1.2751578651659656e-05
step: 340, loss: 2.1199830371188e-05
step: 350, loss: 8.929146861191839e-05
step: 360, loss: 0.008369935676455498
epoch 18: dev_f1=0.6231454005934718, f1=0.588235294117647, best_f1=0.6510416666666666
step: 0, loss: 0.001598927890881896
step: 10, loss: 0.0004333721590228379
step: 20, loss: 2.344243330298923e-05
step: 30, loss: 9.142187627730891e-05
step: 40, loss: 4.1640640120022e-05
step: 50, loss: 0.0013586141867563128
step: 60, loss: 0.005844753701239824
step: 70, loss: 0.0010883709182962775
step: 80, loss: 0.00032705647754482925
step: 90, loss: 9.356686496175826e-05
step: 100, loss: 2.7967142159468494e-05
step: 110, loss: 3.117035157629289e-05
step: 120, loss: 0.00010058057523565367
step: 130, loss: 3.1927487725624815e-05
step: 140, loss: 5.749823321821168e-05
step: 150, loss: 0.00020214033429510891
step: 160, loss: 0.0013641300611197948
step: 170, loss: 0.0001436376041965559
step: 180, loss: 0.0009681115043349564
step: 190, loss: 3.2373722206102684e-05
step: 200, loss: 1.8845450540538877e-05
step: 210, loss: 1.6819398297229782e-05
step: 220, loss: 3.847366679110564e-05
step: 230, loss: 3.656772241811268e-05
step: 240, loss: 5.719279943150468e-05
step: 250, loss: 5.943158976151608e-05
step: 260, loss: 3.635287066572346e-05
step: 270, loss: 2.7702917577698827e-05
step: 280, loss: 0.00033999999868683517
step: 290, loss: 2.293538818776142e-05
step: 300, loss: 0.027178319171071053
step: 310, loss: 0.00010180076787946746
step: 320, loss: 1.6193613191717304e-05
step: 330, loss: 0.0011061894474551082
step: 340, loss: 0.00041166236042045057
step: 350, loss: 7.04215926816687e-05
step: 360, loss: 2.990427310578525e-05
epoch 19: dev_f1=0.6275659824046921, f1=0.599388379204893, best_f1=0.6510416666666666
step: 0, loss: 0.0008275674772448838
step: 10, loss: 0.0001669299090281129
step: 20, loss: 7.332077802857384e-05
step: 30, loss: 3.6435045331018046e-05
step: 40, loss: 0.04316055774688721
step: 50, loss: 4.892936703981832e-05
step: 60, loss: 4.31073312938679e-05
step: 70, loss: 0.00275870761834085
step: 80, loss: 1.8458336853655055e-05
step: 90, loss: 5.6308759667444974e-05
step: 100, loss: 0.00042413591290824115
step: 110, loss: 4.0966235246742144e-05
step: 120, loss: 0.0002040739345829934
step: 130, loss: 0.00012403781875036657
step: 140, loss: 0.00028617808129638433
step: 150, loss: 0.00012195500312373042
step: 160, loss: 5.363968011806719e-05
step: 170, loss: 2.3148142645368353e-05
step: 180, loss: 0.0004704202292487025
step: 190, loss: 9.139585745288059e-05
step: 200, loss: 2.9451941372826695e-05
step: 210, loss: 1.5519348380621523e-05
step: 220, loss: 0.0005979762645438313
step: 230, loss: 5.894905189052224e-05
step: 240, loss: 7.464085501851514e-05
step: 250, loss: 1.7348236724501476e-05
step: 260, loss: 0.00012008249177597463
step: 270, loss: 3.9049064071150497e-05
step: 280, loss: 3.25792861985974e-05
step: 290, loss: 4.3446543713798746e-05
step: 300, loss: 6.116367148933932e-05
step: 310, loss: 1.2952741599292494e-05
step: 320, loss: 5.436070932773873e-05
step: 330, loss: 1.9199673261027783e-05
step: 340, loss: 4.4447955588111654e-05
step: 350, loss: 1.6979493011604063e-05
step: 360, loss: 4.696782707469538e-05
epoch 20: dev_f1=0.6376811594202899, f1=0.6047904191616766, best_f1=0.6510416666666666
