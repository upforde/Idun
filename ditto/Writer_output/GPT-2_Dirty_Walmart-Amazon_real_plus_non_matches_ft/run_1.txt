cuda
Device: cuda
step: 0, loss: 0.7239599227905273
step: 10, loss: 0.37496158480644226
step: 20, loss: 0.2501365840435028
step: 30, loss: 0.07256709784269333
step: 40, loss: 0.13424693048000336
step: 50, loss: 0.37401053309440613
step: 60, loss: 0.1399097889661789
step: 70, loss: 0.14323268830776215
step: 80, loss: 0.15587392449378967
step: 90, loss: 0.13134630024433136
step: 100, loss: 0.30488190054893494
step: 110, loss: 0.143076092004776
step: 120, loss: 0.032543014734983444
step: 130, loss: 0.08320562541484833
step: 140, loss: 0.2441502809524536
step: 150, loss: 0.1432354897260666
step: 160, loss: 0.1206253319978714
step: 170, loss: 0.11266449838876724
step: 180, loss: 0.07170964032411575
step: 190, loss: 0.02077425830066204
step: 200, loss: 0.2494954913854599
step: 210, loss: 0.01677190139889717
step: 220, loss: 0.15050026774406433
step: 230, loss: 0.13765983283519745
step: 240, loss: 0.034717969596385956
step: 250, loss: 0.22696571052074432
step: 260, loss: 0.11154571920633316
step: 270, loss: 0.14918147027492523
step: 280, loss: 0.00840623676776886
step: 290, loss: 0.17394183576107025
step: 300, loss: 0.0355464406311512
step: 310, loss: 0.17185930907726288
step: 320, loss: 0.13603520393371582
step: 330, loss: 0.16811566054821014
step: 340, loss: 0.07801736146211624
step: 350, loss: 0.12792985141277313
step: 360, loss: 0.25298646092414856
epoch 1: dev_f1=0.5484633569739952, f1=0.5437352245862884, best_f1=0.5437352245862884
step: 0, loss: 0.12066275626420975
step: 10, loss: 0.06590477377176285
step: 20, loss: 0.012774096801877022
step: 30, loss: 0.03712799400091171
step: 40, loss: 0.21247699856758118
step: 50, loss: 0.24266362190246582
step: 60, loss: 0.03629988059401512
step: 70, loss: 0.09407822042703629
step: 80, loss: 0.041828058660030365
step: 90, loss: 0.06984592974185944
step: 100, loss: 0.18116776645183563
step: 110, loss: 0.0564090758562088
step: 120, loss: 0.058767642825841904
step: 130, loss: 0.02436603419482708
step: 140, loss: 0.10450819134712219
step: 150, loss: 0.06033168360590935
step: 160, loss: 0.12352107465267181
step: 170, loss: 0.062377069145441055
step: 180, loss: 0.1311868131160736
step: 190, loss: 0.19766464829444885
step: 200, loss: 0.013897974044084549
step: 210, loss: 0.11032368242740631
step: 220, loss: 0.014312227256596088
step: 230, loss: 0.23361873626708984
step: 240, loss: 0.056593116372823715
step: 250, loss: 0.13264089822769165
step: 260, loss: 0.03050341084599495
step: 270, loss: 0.09551957249641418
step: 280, loss: 0.15498480200767517
step: 290, loss: 0.18433058261871338
step: 300, loss: 0.07636888325214386
step: 310, loss: 0.10741854459047318
step: 320, loss: 0.03424187749624252
step: 330, loss: 0.08427456021308899
step: 340, loss: 0.09054964780807495
step: 350, loss: 0.03514571115374565
step: 360, loss: 0.08540164679288864
epoch 2: dev_f1=0.6031746031746031, f1=0.6194690265486725, best_f1=0.6194690265486725
step: 0, loss: 0.08368489891290665
step: 10, loss: 0.12962986528873444
step: 20, loss: 0.08995321393013
step: 30, loss: 0.028759924694895744
step: 40, loss: 0.007543137297034264
step: 50, loss: 0.03358231484889984
step: 60, loss: 0.018423452973365784
step: 70, loss: 0.022324005141854286
step: 80, loss: 0.048741746693849564
step: 90, loss: 0.1412159502506256
step: 100, loss: 0.10864465683698654
step: 110, loss: 0.05115388706326485
step: 120, loss: 0.08370139449834824
step: 130, loss: 0.03454972058534622
step: 140, loss: 0.021971598267555237
step: 150, loss: 0.17478309571743011
step: 160, loss: 0.04611293971538544
step: 170, loss: 0.08571314066648483
step: 180, loss: 0.033800940960645676
step: 190, loss: 0.024046489968895912
step: 200, loss: 0.14725610613822937
step: 210, loss: 0.06257984787225723
step: 220, loss: 0.07457208633422852
step: 230, loss: 0.10840126872062683
step: 240, loss: 0.006306766532361507
step: 250, loss: 0.1129588931798935
step: 260, loss: 0.0723297968506813
step: 270, loss: 0.10558632761240005
step: 280, loss: 0.0391746461391449
step: 290, loss: 0.003138706786558032
step: 300, loss: 0.16905999183654785
step: 310, loss: 0.11581632494926453
step: 320, loss: 0.017803814262151718
step: 330, loss: 0.10990497469902039
step: 340, loss: 0.21910730004310608
step: 350, loss: 0.019918223842978477
step: 360, loss: 0.0018216557800769806
epoch 3: dev_f1=0.6810810810810811, f1=0.6666666666666666, best_f1=0.6666666666666666
step: 0, loss: 0.016807274892926216
step: 10, loss: 0.017292842268943787
step: 20, loss: 0.11893392354249954
step: 30, loss: 0.017806224524974823
step: 40, loss: 0.005314113572239876
step: 50, loss: 0.05858515202999115
step: 60, loss: 0.053082309663295746
step: 70, loss: 0.06272957473993301
step: 80, loss: 0.1041422188282013
step: 90, loss: 0.010552212595939636
step: 100, loss: 0.0012396052479743958
step: 110, loss: 0.011718414723873138
step: 120, loss: 0.11907712370157242
step: 130, loss: 0.01673617772758007
step: 140, loss: 0.021824564784765244
step: 150, loss: 0.1402483582496643
step: 160, loss: 0.013471556827425957
step: 170, loss: 0.040257807821035385
step: 180, loss: 0.08011803776025772
step: 190, loss: 0.12352639436721802
step: 200, loss: 0.0432150661945343
step: 210, loss: 0.04146260395646095
step: 220, loss: 0.004121941514313221
step: 230, loss: 0.029040804132819176
step: 240, loss: 0.04007987305521965
step: 250, loss: 0.04913554713129997
step: 260, loss: 0.0057257977314293385
step: 270, loss: 0.0916370078921318
step: 280, loss: 0.008355780504643917
step: 290, loss: 0.012021615169942379
step: 300, loss: 0.04414154961705208
step: 310, loss: 0.17898790538311005
step: 320, loss: 0.03212537243962288
step: 330, loss: 0.00981950480490923
step: 340, loss: 0.0029046887066215277
step: 350, loss: 0.013649201951920986
step: 360, loss: 0.038198910653591156
epoch 4: dev_f1=0.6745843230403801, f1=0.6697892271662764, best_f1=0.6666666666666666
step: 0, loss: 0.11917297542095184
step: 10, loss: 0.004442822188138962
step: 20, loss: 0.018353130668401718
step: 30, loss: 0.005804609972983599
step: 40, loss: 0.028254112228751183
step: 50, loss: 0.00023720621538814157
step: 60, loss: 0.007812613621354103
step: 70, loss: 0.0013021964114159346
step: 80, loss: 0.028762945905327797
step: 90, loss: 0.10414556413888931
step: 100, loss: 0.09237473458051682
step: 110, loss: 0.028454653918743134
step: 120, loss: 0.006456705275923014
step: 130, loss: 0.026252351701259613
step: 140, loss: 0.0016602445393800735
step: 150, loss: 0.0037387630436569452
step: 160, loss: 0.04503948614001274
step: 170, loss: 0.05026557296514511
step: 180, loss: 0.009138833731412888
step: 190, loss: 0.0010881792986765504
step: 200, loss: 0.013253972865641117
step: 210, loss: 0.1528138965368271
step: 220, loss: 0.01009325124323368
step: 230, loss: 0.03178439661860466
step: 240, loss: 0.011285020969808102
step: 250, loss: 0.0009020790457725525
step: 260, loss: 0.13524112105369568
step: 270, loss: 0.040350399911403656
step: 280, loss: 0.06251585483551025
step: 290, loss: 0.012881956994533539
step: 300, loss: 0.025463268160820007
step: 310, loss: 0.025243597105145454
step: 320, loss: 0.003023462602868676
step: 330, loss: 0.01677108369767666
step: 340, loss: 0.00914166122674942
step: 350, loss: 0.11736473441123962
step: 360, loss: 0.0020625265315175056
epoch 5: dev_f1=0.6649874055415617, f1=0.6830466830466831, best_f1=0.6666666666666666
step: 0, loss: 0.012120493687689304
step: 10, loss: 0.014689018949866295
step: 20, loss: 0.04051804915070534
step: 30, loss: 0.019624672830104828
step: 40, loss: 0.018337484449148178
step: 50, loss: 0.01991095393896103
step: 60, loss: 0.03816990926861763
step: 70, loss: 0.03802254796028137
step: 80, loss: 0.00624316930770874
step: 90, loss: 0.0005002078833058476
step: 100, loss: 0.03292207792401314
step: 110, loss: 0.011172515340149403
step: 120, loss: 0.00047620621626265347
step: 130, loss: 0.0025292551144957542
step: 140, loss: 0.04519033432006836
step: 150, loss: 0.039205051958560944
step: 160, loss: 0.006754773668944836
step: 170, loss: 0.013853145763278008
step: 180, loss: 0.017915423959493637
step: 190, loss: 0.004277530126273632
step: 200, loss: 0.00018417535466142
step: 210, loss: 0.001311923610046506
step: 220, loss: 0.0038540191017091274
step: 230, loss: 0.013000957667827606
step: 240, loss: 0.014842561446130276
step: 250, loss: 0.002032275078818202
step: 260, loss: 0.002713110065087676
step: 270, loss: 0.0041198330000042915
step: 280, loss: 0.004912273492664099
step: 290, loss: 0.001210346119478345
step: 300, loss: 0.00286136195063591
step: 310, loss: 0.0009060343727469444
step: 320, loss: 0.026081006973981857
step: 330, loss: 0.09185615181922913
step: 340, loss: 0.016523586586117744
step: 350, loss: 0.01124096754938364
step: 360, loss: 0.011499962769448757
epoch 6: dev_f1=0.6492146596858639, f1=0.6445012787723785, best_f1=0.6666666666666666
step: 0, loss: 0.02426079660654068
step: 10, loss: 0.0156147051602602
step: 20, loss: 0.0014522876590490341
step: 30, loss: 0.001972501166164875
step: 40, loss: 0.0322398878633976
step: 50, loss: 0.0037739796098321676
step: 60, loss: 0.014301908202469349
step: 70, loss: 0.0003975241561420262
step: 80, loss: 0.013438347727060318
step: 90, loss: 0.0007579058292321861
step: 100, loss: 0.0030925660394132137
step: 110, loss: 0.003880829317495227
step: 120, loss: 0.0488419346511364
step: 130, loss: 0.047222718596458435
step: 140, loss: 0.001201468170620501
step: 150, loss: 0.058650270104408264
step: 160, loss: 0.015992844477295876
step: 170, loss: 0.0007093013264238834
step: 180, loss: 0.006940606981515884
step: 190, loss: 0.0010747613850980997
step: 200, loss: 0.022296151146292686
step: 210, loss: 0.00031873807893134654
step: 220, loss: 0.0033033965155482292
step: 230, loss: 0.00037189654540270567
step: 240, loss: 0.001939204870723188
step: 250, loss: 0.00037252972833812237
step: 260, loss: 0.05798133835196495
step: 270, loss: 0.0009879713179543614
step: 280, loss: 0.009810158051550388
step: 290, loss: 0.0389118492603302
step: 300, loss: 0.00668500829488039
step: 310, loss: 0.001220368198119104
step: 320, loss: 0.007275290787220001
step: 330, loss: 0.026653334498405457
step: 340, loss: 0.012260856106877327
step: 350, loss: 0.008494600653648376
step: 360, loss: 0.0006989166140556335
epoch 7: dev_f1=0.6371681415929203, f1=0.6710816777041942, best_f1=0.6666666666666666
step: 0, loss: 0.001840235898271203
step: 10, loss: 0.006640051491558552
step: 20, loss: 0.002278617350384593
step: 30, loss: 0.01669979840517044
step: 40, loss: 0.00027240245253778994
step: 50, loss: 0.02903556451201439
step: 60, loss: 0.02589697763323784
step: 70, loss: 0.0001994504127651453
step: 80, loss: 0.004742030054330826
step: 90, loss: 0.0003132456331513822
step: 100, loss: 0.09234803915023804
step: 110, loss: 0.0235881470143795
step: 120, loss: 0.0034616640768945217
step: 130, loss: 0.04180441051721573
step: 140, loss: 0.001857492490671575
step: 150, loss: 0.0028561686631292105
step: 160, loss: 0.0011636674171313643
step: 170, loss: 0.008414031937718391
step: 180, loss: 0.0013365610502660275
step: 190, loss: 0.00110859505366534
step: 200, loss: 0.014420783147215843
step: 210, loss: 0.00014551234198734164
step: 220, loss: 0.014600241556763649
step: 230, loss: 0.0002661386097315699
step: 240, loss: 0.00046107269008643925
step: 250, loss: 0.0042908936738967896
step: 260, loss: 0.0005337933544069529
step: 270, loss: 0.06577672809362411
step: 280, loss: 0.0002552340447437018
step: 290, loss: 0.12084009498357773
step: 300, loss: 0.0033352819737046957
step: 310, loss: 0.007344616577029228
step: 320, loss: 0.012781990692019463
step: 330, loss: 0.0010593708138912916
step: 340, loss: 0.012708904221653938
step: 350, loss: 0.006785162258893251
step: 360, loss: 0.015732042491436005
epoch 8: dev_f1=0.6756756756756755, f1=0.6809651474530832, best_f1=0.6666666666666666
step: 0, loss: 0.00020221274462528527
step: 10, loss: 0.00044908933341503143
step: 20, loss: 0.0004347274953033775
step: 30, loss: 0.017697026953101158
step: 40, loss: 0.0005720402114093304
step: 50, loss: 0.0003591550048440695
step: 60, loss: 0.03345378488302231
step: 70, loss: 0.0007611895562149584
step: 80, loss: 0.002524525858461857
step: 90, loss: 0.0004231940256431699
step: 100, loss: 0.0006079480517655611
step: 110, loss: 0.11376125365495682
step: 120, loss: 0.02691689506173134
step: 130, loss: 0.0010971998563036323
step: 140, loss: 0.009119194000959396
step: 150, loss: 0.00018569876556284726
step: 160, loss: 0.0011952642817050219
step: 170, loss: 0.0023427221458405256
step: 180, loss: 9.184283408103511e-05
step: 190, loss: 0.003696907078847289
step: 200, loss: 0.005879946984350681
step: 210, loss: 0.0001430025149602443
step: 220, loss: 0.012108913622796535
step: 230, loss: 0.00023232391686178744
step: 240, loss: 0.01752709224820137
step: 250, loss: 0.19152824580669403
step: 260, loss: 0.08597966283559799
step: 270, loss: 0.005401134956628084
step: 280, loss: 0.002396724186837673
step: 290, loss: 0.0010072424774989486
step: 300, loss: 0.0023129170294851065
step: 310, loss: 0.0021356004290282726
step: 320, loss: 0.0030292700976133347
step: 330, loss: 0.05788208544254303
step: 340, loss: 0.0006138388416729867
step: 350, loss: 0.00225563021376729
step: 360, loss: 0.002236170694231987
epoch 9: dev_f1=0.6586102719033233, f1=0.6260869565217392, best_f1=0.6666666666666666
step: 0, loss: 0.0028650222811847925
step: 10, loss: 0.0024196698796004057
step: 20, loss: 0.0003244364052079618
step: 30, loss: 0.004138822667300701
step: 40, loss: 8.730836270842701e-05
step: 50, loss: 0.0016706547467038035
step: 60, loss: 0.0076050953939557076
step: 70, loss: 0.0029470757581293583
step: 80, loss: 0.004813534673303366
step: 90, loss: 0.0058166878297924995
step: 100, loss: 0.0002671443216968328
step: 110, loss: 0.03618662431836128
step: 120, loss: 0.0001506335975136608
step: 130, loss: 0.0001416402228642255
step: 140, loss: 0.0005180182051844895
step: 150, loss: 0.00013067240070085973
step: 160, loss: 0.00018665826064534485
step: 170, loss: 0.0002658468729350716
step: 180, loss: 0.0005805435939691961
step: 190, loss: 9.7019670647569e-05
step: 200, loss: 0.0005910012405365705
step: 210, loss: 0.0005542330327443779
step: 220, loss: 0.09421474486589432
step: 230, loss: 0.002749224193394184
step: 240, loss: 0.000913296127691865
step: 250, loss: 0.04570883885025978
step: 260, loss: 0.001326448516920209
step: 270, loss: 0.0009388928301632404
step: 280, loss: 0.01456192322075367
step: 290, loss: 0.020636819303035736
step: 300, loss: 0.01695810630917549
step: 310, loss: 0.004839526955038309
step: 320, loss: 0.001096331630833447
step: 330, loss: 0.007906695827841759
step: 340, loss: 0.0010924342786893249
step: 350, loss: 0.0008371684816665947
step: 360, loss: 0.00012015966785838827
epoch 10: dev_f1=0.6683804627249357, f1=0.6666666666666666, best_f1=0.6666666666666666
step: 0, loss: 0.0005268902750685811
step: 10, loss: 0.008398233912885189
step: 20, loss: 0.001609327271580696
step: 30, loss: 5.9960399084957317e-05
step: 40, loss: 0.0002710535773076117
step: 50, loss: 0.000490030157379806
step: 60, loss: 0.0002398324868408963
step: 70, loss: 0.012589230202138424
step: 80, loss: 0.0020580722484737635
step: 90, loss: 0.007023289334028959
step: 100, loss: 0.0013343238970264792
step: 110, loss: 0.0024099103175103664
step: 120, loss: 0.019040366634726524
step: 130, loss: 0.0004894182202406228
step: 140, loss: 0.00026776036247611046
step: 150, loss: 7.135883060982451e-05
step: 160, loss: 0.00010205432045040652
step: 170, loss: 0.00931900180876255
step: 180, loss: 0.00767294317483902
step: 190, loss: 0.0006666784174740314
step: 200, loss: 0.00011086384620284662
step: 210, loss: 0.0011235487181693316
step: 220, loss: 0.0010836587753146887
step: 230, loss: 0.0016842018812894821
step: 240, loss: 0.11392795294523239
step: 250, loss: 0.0005323095247149467
step: 260, loss: 0.002449910156428814
step: 270, loss: 0.00106656807474792
step: 280, loss: 6.709476292598993e-05
step: 290, loss: 0.0038973430637270212
step: 300, loss: 0.0011610869551077485
step: 310, loss: 0.0005085210432298481
step: 320, loss: 0.034922949969768524
step: 330, loss: 0.011914809234440327
step: 340, loss: 0.0006161897326819599
step: 350, loss: 0.00042276998283341527
step: 360, loss: 0.00017713634588290006
epoch 11: dev_f1=0.6463414634146342, f1=0.6135693215339233, best_f1=0.6666666666666666
step: 0, loss: 0.0008772395667620003
step: 10, loss: 0.0015083246398717165
step: 20, loss: 0.00034910530666820705
step: 30, loss: 7.912670116638765e-05
step: 40, loss: 0.0004302686720620841
step: 50, loss: 0.0010936014587059617
step: 60, loss: 7.89030673331581e-05
step: 70, loss: 9.237337508238852e-05
step: 80, loss: 0.000423877703724429
step: 90, loss: 0.08409654349088669
step: 100, loss: 0.0011399444192647934
step: 110, loss: 0.0005529812769964337
step: 120, loss: 0.00024202483473345637
step: 130, loss: 0.00020336131274234504
step: 140, loss: 0.00011028569133486599
step: 150, loss: 6.103694613557309e-05
step: 160, loss: 0.0006075878627598286
step: 170, loss: 0.001077932771295309
step: 180, loss: 0.00014725614164490253
step: 190, loss: 4.8640660679666325e-05
step: 200, loss: 0.00043314319918863475
step: 210, loss: 0.000585629662964493
step: 220, loss: 0.00010721060971263796
step: 230, loss: 8.580661233281717e-05
step: 240, loss: 0.00045962497824802995
step: 250, loss: 4.589131276588887e-05
step: 260, loss: 0.00016337331908289343
step: 270, loss: 3.8623096770606935e-05
step: 280, loss: 0.027141083031892776
step: 290, loss: 0.00015012476069387048
step: 300, loss: 0.0003150615084450692
step: 310, loss: 8.241274917963892e-05
step: 320, loss: 0.005866285413503647
step: 330, loss: 3.246110645704903e-05
step: 340, loss: 0.0001269404892809689
step: 350, loss: 0.0013044378720223904
step: 360, loss: 3.9871683839010075e-05
epoch 12: dev_f1=0.6233766233766233, f1=0.5974842767295597, best_f1=0.6666666666666666
step: 0, loss: 7.767731585772708e-05
step: 10, loss: 0.0002688232343643904
step: 20, loss: 0.00046535086585208774
step: 30, loss: 9.808539471123368e-05
step: 40, loss: 9.970594692276791e-05
step: 50, loss: 4.859469481743872e-05
step: 60, loss: 0.0021765390411019325
step: 70, loss: 0.0006251546437852085
step: 80, loss: 4.739254654850811e-05
step: 90, loss: 7.409133831970394e-05
step: 100, loss: 0.0042020538821816444
step: 110, loss: 0.00010701961582526565
step: 120, loss: 0.0020001810044050217
step: 130, loss: 0.0006101018516346812
step: 140, loss: 0.00014443212421610951
step: 150, loss: 0.005004991311579943
step: 160, loss: 0.00035439664497971535
step: 170, loss: 0.006122578401118517
step: 180, loss: 5.084323129267432e-05
step: 190, loss: 0.005459042266011238
step: 200, loss: 0.00015802438429091126
step: 210, loss: 4.552064638119191e-05
step: 220, loss: 0.0020247171632945538
step: 230, loss: 0.00013022405619267374
step: 240, loss: 0.0001117209394578822
step: 250, loss: 0.0012189114931970835
step: 260, loss: 3.6789828300243244e-05
step: 270, loss: 0.005375099368393421
step: 280, loss: 5.8852590882452205e-05
step: 290, loss: 0.00048172695096582174
step: 300, loss: 0.001921027316711843
step: 310, loss: 0.0007301615551114082
step: 320, loss: 3.3820298995124176e-05
step: 330, loss: 2.1535381165449508e-05
step: 340, loss: 0.00016352754028048366
step: 350, loss: 1.8745447960100137e-05
step: 360, loss: 0.0003388325567357242
epoch 13: dev_f1=0.7081081081081081, f1=0.7034120734908137, best_f1=0.7034120734908137
step: 0, loss: 0.00016976003826130182
step: 10, loss: 9.691546438261867e-05
step: 20, loss: 0.00042910969932563603
step: 30, loss: 0.0015589141985401511
step: 40, loss: 3.8846555980853736e-05
step: 50, loss: 2.424317608529236e-05
step: 60, loss: 0.00014176640252117068
step: 70, loss: 8.04707597126253e-05
step: 80, loss: 5.964780575595796e-05
step: 90, loss: 3.869764623232186e-05
step: 100, loss: 0.0004457728937268257
step: 110, loss: 4.2573552491376176e-05
step: 120, loss: 2.185210723837372e-05
step: 130, loss: 1.920348768180702e-05
step: 140, loss: 0.000511394115164876
step: 150, loss: 8.873471233528107e-05
step: 160, loss: 6.802513962611556e-05
step: 170, loss: 3.154083606204949e-05
step: 180, loss: 0.00018114114936906844
step: 190, loss: 0.0010344929760321975
step: 200, loss: 0.001312809414230287
step: 210, loss: 0.0002180831361329183
step: 220, loss: 3.595471935113892e-05
step: 230, loss: 0.0010544935939833522
step: 240, loss: 0.00020762863277923316
step: 250, loss: 0.00044757212162949145
step: 260, loss: 2.9666136470041238e-05
step: 270, loss: 3.355139779159799e-05
step: 280, loss: 4.156023351242766e-05
step: 290, loss: 0.0004441436904016882
step: 300, loss: 3.635637040133588e-05
step: 310, loss: 4.4103231630288064e-05
step: 320, loss: 0.0005467795417644083
step: 330, loss: 2.8962604119442403e-05
step: 340, loss: 2.1744104742538184e-05
step: 350, loss: 2.6216672267764807e-05
step: 360, loss: 2.5658982849563472e-05
epoch 14: dev_f1=0.6776859504132231, f1=0.6612903225806452, best_f1=0.7034120734908137
step: 0, loss: 0.00012180163321318105
step: 10, loss: 0.0022196925710886717
step: 20, loss: 4.3780775740742683e-05
step: 30, loss: 3.145013761240989e-05
step: 40, loss: 3.1026589567773044e-05
step: 50, loss: 0.0002383091632509604
step: 60, loss: 3.9706250390736386e-05
step: 70, loss: 3.491465758997947e-05
step: 80, loss: 0.00039579952135682106
step: 90, loss: 0.005411846097558737
step: 100, loss: 2.839669286913704e-05
step: 110, loss: 0.0021035089157521725
step: 120, loss: 0.0027221112977713346
step: 130, loss: 6.75757837598212e-05
step: 140, loss: 5.802112355013378e-05
step: 150, loss: 5.272702037473209e-05
step: 160, loss: 5.7494100474286824e-05
step: 170, loss: 0.00018369161989539862
step: 180, loss: 3.0266877729445696e-05
step: 190, loss: 0.0001133162368205376
step: 200, loss: 3.510270107653923e-05
step: 210, loss: 0.04209963604807854
step: 220, loss: 0.0006490492378361523
step: 230, loss: 0.0001427505922038108
step: 240, loss: 1.258394058822887e-05
step: 250, loss: 7.793041731929407e-05
step: 260, loss: 0.0011631854576990008
step: 270, loss: 9.29699235712178e-05
step: 280, loss: 4.143332989769988e-05
step: 290, loss: 7.189811731223017e-05
step: 300, loss: 0.001589386723935604
step: 310, loss: 0.0002144494792446494
step: 320, loss: 0.0001631911873118952
step: 330, loss: 0.00013756494445260614
step: 340, loss: 0.00014187494525685906
step: 350, loss: 0.00022563514357898384
step: 360, loss: 0.004049684852361679
epoch 15: dev_f1=0.6153846153846154, f1=0.6261398176291793, best_f1=0.7034120734908137
step: 0, loss: 0.000452014384791255
step: 10, loss: 6.63440878270194e-05
step: 20, loss: 0.00015411671483889222
step: 30, loss: 9.243869135389104e-05
step: 40, loss: 3.7496785807888955e-05
step: 50, loss: 0.0020224156323820353
step: 60, loss: 0.000735308974981308
step: 70, loss: 0.03441102057695389
step: 80, loss: 0.0001132119505200535
step: 90, loss: 0.0001886159589048475
step: 100, loss: 0.0005498469690792263
step: 110, loss: 0.0010952884331345558
step: 120, loss: 0.0002898403035942465
step: 130, loss: 8.798966882750392e-05
step: 140, loss: 6.707552529405802e-05
step: 150, loss: 0.002121017314493656
step: 160, loss: 5.21040492458269e-05
step: 170, loss: 5.631142994388938e-05
step: 180, loss: 0.0004972997703589499
step: 190, loss: 5.8719870139611885e-05
step: 200, loss: 0.0015806438168510795
step: 210, loss: 1.7452748579671606e-05
step: 220, loss: 4.5217610022518784e-05
step: 230, loss: 0.0005794930038973689
step: 240, loss: 0.0006919840234331787
step: 250, loss: 7.803438347764313e-05
step: 260, loss: 0.00014772301074117422
step: 270, loss: 0.0005081523559056222
step: 280, loss: 7.138292130548507e-05
step: 290, loss: 4.593741687131114e-05
step: 300, loss: 0.0001552088651806116
step: 310, loss: 0.0014363457448780537
step: 320, loss: 0.004936677403748035
step: 330, loss: 0.0004025001544505358
step: 340, loss: 0.000354717078153044
step: 350, loss: 0.003014013869687915
step: 360, loss: 0.0009143360075540841
epoch 16: dev_f1=0.6723646723646723, f1=0.6540540540540541, best_f1=0.7034120734908137
step: 0, loss: 0.0016805710038170218
step: 10, loss: 0.0006795041845180094
step: 20, loss: 5.075010994914919e-05
step: 30, loss: 0.00013143963587936014
step: 40, loss: 0.0003873879322782159
step: 50, loss: 0.00040380615973845124
step: 60, loss: 0.017771577462553978
step: 70, loss: 2.7591086109168828e-05
step: 80, loss: 0.0038453484885394573
step: 90, loss: 0.00020772057177964598
step: 100, loss: 0.0036734326276928186
step: 110, loss: 0.00015904141764622182
step: 120, loss: 2.8668691811617464e-05
step: 130, loss: 0.030136028304696083
step: 140, loss: 0.00039103045128285885
step: 150, loss: 0.00017143589502666146
step: 160, loss: 0.00045083279837854207
step: 170, loss: 0.00023129525652620941
step: 180, loss: 6.006248440826312e-05
step: 190, loss: 9.654869791120291e-05
step: 200, loss: 0.0011085686273872852
step: 210, loss: 4.544356488622725e-05
step: 220, loss: 0.00022526801330968738
step: 230, loss: 3.663990355562419e-05
step: 240, loss: 6.152054265839979e-05
step: 250, loss: 2.222051625722088e-05
step: 260, loss: 8.673465345054865e-05
step: 270, loss: 7.294367242138833e-05
step: 280, loss: 0.016530461609363556
step: 290, loss: 4.6021050366107374e-05
step: 300, loss: 3.45871812896803e-05
step: 310, loss: 5.969557969365269e-05
step: 320, loss: 0.00015258605708368123
step: 330, loss: 0.00032034897594712675
step: 340, loss: 0.0010956937912851572
step: 350, loss: 0.0006158867618069053
step: 360, loss: 0.0010093003511428833
epoch 17: dev_f1=0.6385542168674699, f1=0.632183908045977, best_f1=0.7034120734908137
step: 0, loss: 0.0035044532269239426
step: 10, loss: 1.6204779967665672e-05
step: 20, loss: 7.682506111450493e-05
step: 30, loss: 6.432020745705813e-05
step: 40, loss: 0.00027815523208118975
step: 50, loss: 3.225889304303564e-05
step: 60, loss: 2.2145701223053038e-05
step: 70, loss: 0.00011559855920495465
step: 80, loss: 0.00023409487039316446
step: 90, loss: 0.00011589392670430243
step: 100, loss: 2.1083980755065568e-05
step: 110, loss: 2.286499147885479e-05
step: 120, loss: 1.543372309242841e-05
step: 130, loss: 4.74196276627481e-05
step: 140, loss: 0.0007503331289626658
step: 150, loss: 8.319518383359537e-05
step: 160, loss: 0.00028256274526938796
step: 170, loss: 0.0005307606770657003
step: 180, loss: 7.841190381441265e-05
step: 190, loss: 0.0003186255053151399
step: 200, loss: 2.0070858226972632e-05
step: 210, loss: 0.0004407156666275114
step: 220, loss: 0.0011267568916082382
step: 230, loss: 1.613404856470879e-05
step: 240, loss: 0.00011933436326216906
step: 250, loss: 0.000288755283690989
step: 260, loss: 4.055596946272999e-05
step: 270, loss: 7.781885506119579e-05
step: 280, loss: 2.473086897225585e-05
step: 290, loss: 3.1067767849890515e-05
step: 300, loss: 4.06620092689991e-05
step: 310, loss: 0.0011427623685449362
step: 320, loss: 3.4330656490055844e-05
step: 330, loss: 3.028829632967245e-05
step: 340, loss: 6.307438161456957e-05
step: 350, loss: 0.0001049407001119107
step: 360, loss: 0.10284771025180817
epoch 18: dev_f1=0.660919540229885, f1=0.659217877094972, best_f1=0.7034120734908137
step: 0, loss: 2.8150627258582972e-05
step: 10, loss: 0.0004955450422130525
step: 20, loss: 5.002227771910839e-05
step: 30, loss: 0.0005497719976119697
step: 40, loss: 0.00012578074529301375
step: 50, loss: 0.0010243826545774937
step: 60, loss: 3.410653516766615e-05
step: 70, loss: 0.000738248520065099
step: 80, loss: 0.0001316725683864206
step: 90, loss: 0.00022172769240569323
step: 100, loss: 3.584387377486564e-05
step: 110, loss: 3.601486605475657e-05
step: 120, loss: 0.00018360334797762334
step: 130, loss: 5.825565676786937e-05
step: 140, loss: 3.0389041057787836e-05
step: 150, loss: 0.001602023490704596
step: 160, loss: 0.01702115125954151
step: 170, loss: 4.262794755049981e-05
step: 180, loss: 0.008878874592483044
step: 190, loss: 2.5707098757266067e-05
step: 200, loss: 0.00020376616157591343
step: 210, loss: 0.000129168969579041
step: 220, loss: 5.092166247777641e-05
step: 230, loss: 0.00921378843486309
step: 240, loss: 0.00026903284015133977
step: 250, loss: 0.04700511693954468
step: 260, loss: 0.00015929224900901318
step: 270, loss: 0.00029145259759388864
step: 280, loss: 0.002078678924590349
step: 290, loss: 0.0008151522488333285
step: 300, loss: 2.3792495994712226e-05
step: 310, loss: 0.005406905896961689
step: 320, loss: 5.446146315080114e-05
step: 330, loss: 0.0002918336249422282
step: 340, loss: 2.342757761653047e-05
step: 350, loss: 0.0023096727672964334
step: 360, loss: 8.65967886056751e-05
epoch 19: dev_f1=0.6666666666666667, f1=0.6721763085399448, best_f1=0.7034120734908137
step: 0, loss: 0.00010923892114078626
step: 10, loss: 0.0001173010969068855
step: 20, loss: 5.86387213843409e-05
step: 30, loss: 3.3583703043404967e-05
step: 40, loss: 6.143961945781484e-05
step: 50, loss: 2.5170638764393516e-05
step: 60, loss: 0.00014097233361098915
step: 70, loss: 0.012181106954813004
step: 80, loss: 1.9468074242467992e-05
step: 90, loss: 4.189865285297856e-05
step: 100, loss: 0.00012127146328566596
step: 110, loss: 5.428793519968167e-05
step: 120, loss: 0.0005926114390604198
step: 130, loss: 0.0009794506477192044
step: 140, loss: 0.00017089289030991495
step: 150, loss: 2.350870636291802e-05
step: 160, loss: 0.0001931082078954205
step: 170, loss: 1.8033739252132364e-05
step: 180, loss: 1.4670063137600664e-05
step: 190, loss: 2.367661363678053e-05
step: 200, loss: 9.062170283868909e-05
step: 210, loss: 4.24430072598625e-05
step: 220, loss: 0.0002029951720032841
step: 230, loss: 0.003493531374260783
step: 240, loss: 0.0001838327298173681
step: 250, loss: 0.0002729427069425583
step: 260, loss: 1.9702696590684354e-05
step: 270, loss: 9.036879055202007e-05
step: 280, loss: 0.00013140664668753743
step: 290, loss: 2.0082454284420237e-05
step: 300, loss: 3.086619108216837e-05
step: 310, loss: 2.0395413230289705e-05
step: 320, loss: 2.965717067127116e-05
step: 330, loss: 3.629716957220808e-05
step: 340, loss: 3.516722790664062e-05
step: 350, loss: 0.0003337646194268018
step: 360, loss: 3.534942879923619e-05
epoch 20: dev_f1=0.672463768115942, f1=0.659217877094972, best_f1=0.7034120734908137
cuda
Device: cuda
step: 0, loss: 0.7239599227905273
step: 10, loss: 0.37496158480644226
step: 20, loss: 0.2501365840435028
step: 30, loss: 0.07256709784269333
step: 40, loss: 0.13424693048000336
step: 50, loss: 0.37401053309440613
step: 60, loss: 0.1399097889661789
step: 70, loss: 0.14323268830776215
step: 80, loss: 0.15587392449378967
step: 90, loss: 0.13134630024433136
step: 100, loss: 0.30488190054893494
step: 110, loss: 0.143076092004776
step: 120, loss: 0.032543014734983444
step: 130, loss: 0.08320562541484833
step: 140, loss: 0.2441502809524536
step: 150, loss: 0.1432354897260666
step: 160, loss: 0.1206253319978714
step: 170, loss: 0.11266449838876724
step: 180, loss: 0.07170964032411575
step: 190, loss: 0.02077425830066204
step: 200, loss: 0.2494954913854599
step: 210, loss: 0.01677190139889717
step: 220, loss: 0.15050026774406433
step: 230, loss: 0.13765983283519745
step: 240, loss: 0.034717969596385956
step: 250, loss: 0.22696571052074432
step: 260, loss: 0.11154571920633316
step: 270, loss: 0.14918147027492523
step: 280, loss: 0.00840623676776886
step: 290, loss: 0.17394183576107025
step: 300, loss: 0.0355464406311512
step: 310, loss: 0.17185930907726288
step: 320, loss: 0.13603520393371582
step: 330, loss: 0.16811566054821014
step: 340, loss: 0.07801736146211624
step: 350, loss: 0.12792985141277313
step: 360, loss: 0.25298646092414856
epoch 1: dev_f1=0.5484633569739952, f1=0.5437352245862884, best_f1=0.5437352245862884
step: 0, loss: 0.12066275626420975
step: 10, loss: 0.06590477377176285
step: 20, loss: 0.012774096801877022
step: 30, loss: 0.03712799400091171
step: 40, loss: 0.21247699856758118
step: 50, loss: 0.24266362190246582
step: 60, loss: 0.03629988059401512
step: 70, loss: 0.09407822042703629
step: 80, loss: 0.041828058660030365
step: 90, loss: 0.06984592974185944
step: 100, loss: 0.18116776645183563
step: 110, loss: 0.0564090758562088
step: 120, loss: 0.058767642825841904
step: 130, loss: 0.02436603419482708
step: 140, loss: 0.10450819134712219
step: 150, loss: 0.06033168360590935
step: 160, loss: 0.12352107465267181
step: 170, loss: 0.062377069145441055
step: 180, loss: 0.1311868131160736
step: 190, loss: 0.19766464829444885
step: 200, loss: 0.013897974044084549
step: 210, loss: 0.11032368242740631
step: 220, loss: 0.014312227256596088
step: 230, loss: 0.23361873626708984
step: 240, loss: 0.056593116372823715
step: 250, loss: 0.13264089822769165
step: 260, loss: 0.03050341084599495
step: 270, loss: 0.09551957249641418
step: 280, loss: 0.15498480200767517
step: 290, loss: 0.18433058261871338
step: 300, loss: 0.07636888325214386
step: 310, loss: 0.10741854459047318
step: 320, loss: 0.03424187749624252
step: 330, loss: 0.08427456021308899
step: 340, loss: 0.09054964780807495
step: 350, loss: 0.03514571115374565
step: 360, loss: 0.08540164679288864
epoch 2: dev_f1=0.6031746031746031, f1=0.6194690265486725, best_f1=0.6194690265486725
step: 0, loss: 0.08368489891290665
step: 10, loss: 0.12962986528873444
step: 20, loss: 0.08995321393013
step: 30, loss: 0.028759924694895744
step: 40, loss: 0.007543137297034264
step: 50, loss: 0.03358231484889984
step: 60, loss: 0.018423452973365784
step: 70, loss: 0.022324005141854286
step: 80, loss: 0.048741746693849564
step: 90, loss: 0.1412159502506256
step: 100, loss: 0.10864465683698654
step: 110, loss: 0.05115388706326485
step: 120, loss: 0.08370139449834824
step: 130, loss: 0.03454972058534622
step: 140, loss: 0.021971598267555237
step: 150, loss: 0.17478309571743011
step: 160, loss: 0.04611293971538544
step: 170, loss: 0.08571314066648483
step: 180, loss: 0.033800940960645676
step: 190, loss: 0.024046489968895912
step: 200, loss: 0.14725610613822937
step: 210, loss: 0.06257984787225723
step: 220, loss: 0.07457208633422852
step: 230, loss: 0.10840126872062683
step: 240, loss: 0.006306766532361507
step: 250, loss: 0.1129588931798935
step: 260, loss: 0.0723297968506813
step: 270, loss: 0.10558632761240005
step: 280, loss: 0.0391746461391449
step: 290, loss: 0.003138706786558032
step: 300, loss: 0.16905999183654785
step: 310, loss: 0.11581632494926453
step: 320, loss: 0.017803814262151718
step: 330, loss: 0.10990497469902039
step: 340, loss: 0.21910730004310608
step: 350, loss: 0.019918223842978477
step: 360, loss: 0.0018216557800769806
epoch 3: dev_f1=0.6810810810810811, f1=0.6666666666666666, best_f1=0.6666666666666666
step: 0, loss: 0.016807274892926216
step: 10, loss: 0.017292842268943787
step: 20, loss: 0.11893392354249954
step: 30, loss: 0.017806224524974823
step: 40, loss: 0.005314113572239876
step: 50, loss: 0.05858515202999115
step: 60, loss: 0.053082309663295746
step: 70, loss: 0.06272957473993301
step: 80, loss: 0.1041422188282013
step: 90, loss: 0.010552212595939636
step: 100, loss: 0.0012396052479743958
step: 110, loss: 0.011718414723873138
step: 120, loss: 0.11907712370157242
step: 130, loss: 0.01673617772758007
step: 140, loss: 0.021824564784765244
step: 150, loss: 0.1402483582496643
step: 160, loss: 0.013471556827425957
step: 170, loss: 0.040257807821035385
step: 180, loss: 0.08011803776025772
step: 190, loss: 0.12352639436721802
step: 200, loss: 0.0432150661945343
step: 210, loss: 0.04146260395646095
step: 220, loss: 0.004121941514313221
step: 230, loss: 0.029040804132819176
step: 240, loss: 0.04007987305521965
step: 250, loss: 0.04913554713129997
step: 260, loss: 0.0057257977314293385
step: 270, loss: 0.0916370078921318
step: 280, loss: 0.008355780504643917
step: 290, loss: 0.012021615169942379
step: 300, loss: 0.04414154961705208
step: 310, loss: 0.17898790538311005
step: 320, loss: 0.03212537243962288
step: 330, loss: 0.00981950480490923
step: 340, loss: 0.0029046887066215277
step: 350, loss: 0.013649201951920986
step: 360, loss: 0.038198910653591156
epoch 4: dev_f1=0.6745843230403801, f1=0.6697892271662764, best_f1=0.6666666666666666
step: 0, loss: 0.11917297542095184
step: 10, loss: 0.004442822188138962
step: 20, loss: 0.018353130668401718
step: 30, loss: 0.005804609972983599
step: 40, loss: 0.028254112228751183
step: 50, loss: 0.00023720621538814157
step: 60, loss: 0.007812613621354103
step: 70, loss: 0.0013021964114159346
step: 80, loss: 0.028762945905327797
step: 90, loss: 0.10414556413888931
step: 100, loss: 0.09237473458051682
step: 110, loss: 0.028454653918743134
step: 120, loss: 0.006456705275923014
step: 130, loss: 0.026252351701259613
step: 140, loss: 0.0016602445393800735
step: 150, loss: 0.0037387630436569452
step: 160, loss: 0.04503948614001274
step: 170, loss: 0.05026557296514511
step: 180, loss: 0.009138833731412888
step: 190, loss: 0.0010881792986765504
step: 200, loss: 0.013253972865641117
step: 210, loss: 0.1528138965368271
step: 220, loss: 0.01009325124323368
step: 230, loss: 0.03178439661860466
step: 240, loss: 0.011285020969808102
step: 250, loss: 0.0009020790457725525
step: 260, loss: 0.13524112105369568
step: 270, loss: 0.040350399911403656
step: 280, loss: 0.06251585483551025
step: 290, loss: 0.012881956994533539
step: 300, loss: 0.025463268160820007
step: 310, loss: 0.025243597105145454
step: 320, loss: 0.003023462602868676
step: 330, loss: 0.01677108369767666
step: 340, loss: 0.00914166122674942
step: 350, loss: 0.11736473441123962
step: 360, loss: 0.0020625265315175056
epoch 5: dev_f1=0.6649874055415617, f1=0.6830466830466831, best_f1=0.6666666666666666
step: 0, loss: 0.012120493687689304
step: 10, loss: 0.014689018949866295
step: 20, loss: 0.04051804915070534
step: 30, loss: 0.019624672830104828
step: 40, loss: 0.018337484449148178
step: 50, loss: 0.01991095393896103
step: 60, loss: 0.03816990926861763
step: 70, loss: 0.03802254796028137
step: 80, loss: 0.00624316930770874
step: 90, loss: 0.0005002078833058476
step: 100, loss: 0.03292207792401314
step: 110, loss: 0.011172515340149403
step: 120, loss: 0.00047620621626265347
step: 130, loss: 0.0025292551144957542
step: 140, loss: 0.04519033432006836
step: 150, loss: 0.039205051958560944
step: 160, loss: 0.006754773668944836
step: 170, loss: 0.013853145763278008
step: 180, loss: 0.017915423959493637
step: 190, loss: 0.004277530126273632
step: 200, loss: 0.00018417535466142
step: 210, loss: 0.001311923610046506
step: 220, loss: 0.0038540191017091274
step: 230, loss: 0.013000957667827606
step: 240, loss: 0.014842561446130276
step: 250, loss: 0.002032275078818202
step: 260, loss: 0.002713110065087676
step: 270, loss: 0.0041198330000042915
step: 280, loss: 0.004912273492664099
step: 290, loss: 0.001210346119478345
step: 300, loss: 0.00286136195063591
step: 310, loss: 0.0009060343727469444
step: 320, loss: 0.026081006973981857
step: 330, loss: 0.09185615181922913
step: 340, loss: 0.016523586586117744
step: 350, loss: 0.01124096754938364
step: 360, loss: 0.011499962769448757
epoch 6: dev_f1=0.6492146596858639, f1=0.6445012787723785, best_f1=0.6666666666666666
step: 0, loss: 0.02426079660654068
step: 10, loss: 0.0156147051602602
step: 20, loss: 0.0014522876590490341
step: 30, loss: 0.001972501166164875
step: 40, loss: 0.0322398878633976
step: 50, loss: 0.0037739796098321676
step: 60, loss: 0.014301908202469349
step: 70, loss: 0.0003975241561420262
step: 80, loss: 0.013438347727060318
step: 90, loss: 0.0007579058292321861
step: 100, loss: 0.0030925660394132137
step: 110, loss: 0.003880829317495227
step: 120, loss: 0.0488419346511364
step: 130, loss: 0.047222718596458435
step: 140, loss: 0.001201468170620501
step: 150, loss: 0.058650270104408264
step: 160, loss: 0.015992844477295876
step: 170, loss: 0.0007093013264238834
step: 180, loss: 0.006940606981515884
step: 190, loss: 0.0010747613850980997
step: 200, loss: 0.022296151146292686
step: 210, loss: 0.00031873807893134654
step: 220, loss: 0.0033033965155482292
step: 230, loss: 0.00037189654540270567
step: 240, loss: 0.001939204870723188
step: 250, loss: 0.00037252972833812237
step: 260, loss: 0.05798133835196495
step: 270, loss: 0.0009879713179543614
step: 280, loss: 0.009810158051550388
step: 290, loss: 0.0389118492603302
step: 300, loss: 0.00668500829488039
step: 310, loss: 0.001220368198119104
step: 320, loss: 0.007275290787220001
step: 330, loss: 0.026653334498405457
step: 340, loss: 0.012260856106877327
step: 350, loss: 0.008494600653648376
step: 360, loss: 0.0006989166140556335
epoch 7: dev_f1=0.6371681415929203, f1=0.6710816777041942, best_f1=0.6666666666666666
step: 0, loss: 0.001840235898271203
step: 10, loss: 0.006640051491558552
step: 20, loss: 0.002278617350384593
step: 30, loss: 0.01669979840517044
step: 40, loss: 0.00027240245253778994
step: 50, loss: 0.02903556451201439
step: 60, loss: 0.02589697763323784
step: 70, loss: 0.0001994504127651453
step: 80, loss: 0.004742030054330826
step: 90, loss: 0.0003132456331513822
step: 100, loss: 0.09234803915023804
step: 110, loss: 0.0235881470143795
step: 120, loss: 0.0034616640768945217
step: 130, loss: 0.04180441051721573
step: 140, loss: 0.001857492490671575
step: 150, loss: 0.0028561686631292105
step: 160, loss: 0.0011636674171313643
step: 170, loss: 0.008414031937718391
step: 180, loss: 0.0013365610502660275
step: 190, loss: 0.00110859505366534
step: 200, loss: 0.014420783147215843
step: 210, loss: 0.00014551234198734164
step: 220, loss: 0.014600241556763649
step: 230, loss: 0.0002661386097315699
step: 240, loss: 0.00046107269008643925
step: 250, loss: 0.0042908936738967896
step: 260, loss: 0.0005337933544069529
step: 270, loss: 0.06577672809362411
step: 280, loss: 0.0002552340447437018
step: 290, loss: 0.12084009498357773
step: 300, loss: 0.0033352819737046957
step: 310, loss: 0.007344616577029228
step: 320, loss: 0.012781990692019463
step: 330, loss: 0.0010593708138912916
step: 340, loss: 0.012708904221653938
step: 350, loss: 0.006785162258893251
step: 360, loss: 0.015732042491436005
epoch 8: dev_f1=0.6756756756756755, f1=0.6809651474530832, best_f1=0.6666666666666666
step: 0, loss: 0.00020221274462528527
step: 10, loss: 0.00044908933341503143
step: 20, loss: 0.0004347274953033775
step: 30, loss: 0.017697026953101158
step: 40, loss: 0.0005720402114093304
step: 50, loss: 0.0003591550048440695
step: 60, loss: 0.03345378488302231
step: 70, loss: 0.0007611895562149584
step: 80, loss: 0.002524525858461857
step: 90, loss: 0.0004231940256431699
step: 100, loss: 0.0006079480517655611
step: 110, loss: 0.11376125365495682
step: 120, loss: 0.02691689506173134
step: 130, loss: 0.0010971998563036323
step: 140, loss: 0.009119194000959396
step: 150, loss: 0.00018569876556284726
step: 160, loss: 0.0011952642817050219
step: 170, loss: 0.0023427221458405256
step: 180, loss: 9.184283408103511e-05
step: 190, loss: 0.003696907078847289
step: 200, loss: 0.005879946984350681
step: 210, loss: 0.0001430025149602443
step: 220, loss: 0.012108913622796535
step: 230, loss: 0.00023232391686178744
step: 240, loss: 0.01752709224820137
step: 250, loss: 0.19152824580669403
step: 260, loss: 0.08597966283559799
step: 270, loss: 0.005401134956628084
step: 280, loss: 0.002396724186837673
step: 290, loss: 0.0010072424774989486
step: 300, loss: 0.0023129170294851065
step: 310, loss: 0.0021356004290282726
step: 320, loss: 0.0030292700976133347
step: 330, loss: 0.05788208544254303
step: 340, loss: 0.0006138388416729867
step: 350, loss: 0.00225563021376729
step: 360, loss: 0.002236170694231987
epoch 9: dev_f1=0.6586102719033233, f1=0.6260869565217392, best_f1=0.6666666666666666
step: 0, loss: 0.0028650222811847925
step: 10, loss: 0.0024196698796004057
step: 20, loss: 0.0003244364052079618
step: 30, loss: 0.004138822667300701
step: 40, loss: 8.730836270842701e-05
step: 50, loss: 0.0016706547467038035
step: 60, loss: 0.0076050953939557076
step: 70, loss: 0.0029470757581293583
step: 80, loss: 0.004813534673303366
step: 90, loss: 0.0058166878297924995
step: 100, loss: 0.0002671443216968328
step: 110, loss: 0.03618662431836128
step: 120, loss: 0.0001506335975136608
step: 130, loss: 0.0001416402228642255
step: 140, loss: 0.0005180182051844895
step: 150, loss: 0.00013067240070085973
step: 160, loss: 0.00018665826064534485
step: 170, loss: 0.0002658468729350716
step: 180, loss: 0.0005805435939691961
step: 190, loss: 9.7019670647569e-05
step: 200, loss: 0.0005910012405365705
step: 210, loss: 0.0005542330327443779
step: 220, loss: 0.09421474486589432
step: 230, loss: 0.002749224193394184
step: 240, loss: 0.000913296127691865
step: 250, loss: 0.04570883885025978
step: 260, loss: 0.001326448516920209
step: 270, loss: 0.0009388928301632404
step: 280, loss: 0.01456192322075367
step: 290, loss: 0.020636819303035736
step: 300, loss: 0.01695810630917549
step: 310, loss: 0.004839526955038309
step: 320, loss: 0.001096331630833447
step: 330, loss: 0.007906695827841759
step: 340, loss: 0.0010924342786893249
step: 350, loss: 0.0008371684816665947
step: 360, loss: 0.00012015966785838827
epoch 10: dev_f1=0.6683804627249357, f1=0.6666666666666666, best_f1=0.6666666666666666
step: 0, loss: 0.0005268902750685811
step: 10, loss: 0.008398233912885189
step: 20, loss: 0.001609327271580696
step: 30, loss: 5.9960399084957317e-05
step: 40, loss: 0.0002710535773076117
step: 50, loss: 0.000490030157379806
step: 60, loss: 0.0002398324868408963
step: 70, loss: 0.012589230202138424
step: 80, loss: 0.0020580722484737635
step: 90, loss: 0.007023289334028959
step: 100, loss: 0.0013343238970264792
step: 110, loss: 0.0024099103175103664
step: 120, loss: 0.019040366634726524
step: 130, loss: 0.0004894182202406228
step: 140, loss: 0.00026776036247611046
step: 150, loss: 7.135883060982451e-05
step: 160, loss: 0.00010205432045040652
step: 170, loss: 0.00931900180876255
step: 180, loss: 0.00767294317483902
step: 190, loss: 0.0006666784174740314
step: 200, loss: 0.00011086384620284662
step: 210, loss: 0.0011235487181693316
step: 220, loss: 0.0010836587753146887
step: 230, loss: 0.0016842018812894821
step: 240, loss: 0.11392795294523239
step: 250, loss: 0.0005323095247149467
step: 260, loss: 0.002449910156428814
step: 270, loss: 0.00106656807474792
step: 280, loss: 6.709476292598993e-05
step: 290, loss: 0.0038973430637270212
step: 300, loss: 0.0011610869551077485
step: 310, loss: 0.0005085210432298481
step: 320, loss: 0.034922949969768524
step: 330, loss: 0.011914809234440327
step: 340, loss: 0.0006161897326819599
step: 350, loss: 0.00042276998283341527
step: 360, loss: 0.00017713634588290006
epoch 11: dev_f1=0.6463414634146342, f1=0.6135693215339233, best_f1=0.6666666666666666
step: 0, loss: 0.0008772395667620003
step: 10, loss: 0.0015083246398717165
step: 20, loss: 0.00034910530666820705
step: 30, loss: 7.912670116638765e-05
step: 40, loss: 0.0004302686720620841
step: 50, loss: 0.0010936014587059617
step: 60, loss: 7.89030673331581e-05
step: 70, loss: 9.237337508238852e-05
step: 80, loss: 0.000423877703724429
step: 90, loss: 0.08409654349088669
step: 100, loss: 0.0011399444192647934
step: 110, loss: 0.0005529812769964337
step: 120, loss: 0.00024202483473345637
step: 130, loss: 0.00020336131274234504
step: 140, loss: 0.00011028569133486599
step: 150, loss: 6.103694613557309e-05
step: 160, loss: 0.0006075878627598286
step: 170, loss: 0.001077932771295309
step: 180, loss: 0.00014725614164490253
step: 190, loss: 4.8640660679666325e-05
step: 200, loss: 0.00043314319918863475
step: 210, loss: 0.000585629662964493
step: 220, loss: 0.00010721060971263796
step: 230, loss: 8.580661233281717e-05
step: 240, loss: 0.00045962497824802995
step: 250, loss: 4.589131276588887e-05
step: 260, loss: 0.00016337331908289343
step: 270, loss: 3.8623096770606935e-05
step: 280, loss: 0.027141083031892776
step: 290, loss: 0.00015012476069387048
step: 300, loss: 0.0003150615084450692
step: 310, loss: 8.241274917963892e-05
step: 320, loss: 0.005866285413503647
step: 330, loss: 3.246110645704903e-05
step: 340, loss: 0.0001269404892809689
step: 350, loss: 0.0013044378720223904
step: 360, loss: 3.9871683839010075e-05
epoch 12: dev_f1=0.6233766233766233, f1=0.5974842767295597, best_f1=0.6666666666666666
step: 0, loss: 7.767731585772708e-05
step: 10, loss: 0.0002688232343643904
step: 20, loss: 0.00046535086585208774
step: 30, loss: 9.808539471123368e-05
step: 40, loss: 9.970594692276791e-05
step: 50, loss: 4.859469481743872e-05
step: 60, loss: 0.0021765390411019325
step: 70, loss: 0.0006251546437852085
step: 80, loss: 4.739254654850811e-05
step: 90, loss: 7.409133831970394e-05
step: 100, loss: 0.0042020538821816444
step: 110, loss: 0.00010701961582526565
step: 120, loss: 0.0020001810044050217
step: 130, loss: 0.0006101018516346812
step: 140, loss: 0.00014443212421610951
step: 150, loss: 0.005004991311579943
step: 160, loss: 0.00035439664497971535
step: 170, loss: 0.006122578401118517
step: 180, loss: 5.084323129267432e-05
step: 190, loss: 0.005459042266011238
step: 200, loss: 0.00015802438429091126
step: 210, loss: 4.552064638119191e-05
step: 220, loss: 0.0020247171632945538
step: 230, loss: 0.00013022405619267374
step: 240, loss: 0.0001117209394578822
step: 250, loss: 0.0012189114931970835
step: 260, loss: 3.6789828300243244e-05
step: 270, loss: 0.005375099368393421
step: 280, loss: 5.8852590882452205e-05
step: 290, loss: 0.00048172695096582174
step: 300, loss: 0.001921027316711843
step: 310, loss: 0.0007301615551114082
step: 320, loss: 3.3820298995124176e-05
step: 330, loss: 2.1535381165449508e-05
step: 340, loss: 0.00016352754028048366
step: 350, loss: 1.8745447960100137e-05
step: 360, loss: 0.0003388325567357242
epoch 13: dev_f1=0.7081081081081081, f1=0.7034120734908137, best_f1=0.7034120734908137
step: 0, loss: 0.00016976003826130182
step: 10, loss: 9.691546438261867e-05
step: 20, loss: 0.00042910969932563603
step: 30, loss: 0.0015589141985401511
step: 40, loss: 3.8846555980853736e-05
step: 50, loss: 2.424317608529236e-05
step: 60, loss: 0.00014176640252117068
step: 70, loss: 8.04707597126253e-05
step: 80, loss: 5.964780575595796e-05
step: 90, loss: 3.869764623232186e-05
step: 100, loss: 0.0004457728937268257
step: 110, loss: 4.2573552491376176e-05
step: 120, loss: 2.185210723837372e-05
step: 130, loss: 1.920348768180702e-05
step: 140, loss: 0.000511394115164876
step: 150, loss: 8.873471233528107e-05
step: 160, loss: 6.802513962611556e-05
step: 170, loss: 3.154083606204949e-05
step: 180, loss: 0.00018114114936906844
step: 190, loss: 0.0010344929760321975
step: 200, loss: 0.001312809414230287
step: 210, loss: 0.0002180831361329183
step: 220, loss: 3.595471935113892e-05
step: 230, loss: 0.0010544935939833522
step: 240, loss: 0.00020762863277923316
step: 250, loss: 0.00044757212162949145
step: 260, loss: 2.9666136470041238e-05
step: 270, loss: 3.355139779159799e-05
step: 280, loss: 4.156023351242766e-05
step: 290, loss: 0.0004441436904016882
step: 300, loss: 3.635637040133588e-05
step: 310, loss: 4.4103231630288064e-05
step: 320, loss: 0.0005467795417644083
step: 330, loss: 2.8962604119442403e-05
step: 340, loss: 2.1744104742538184e-05
step: 350, loss: 2.6216672267764807e-05
step: 360, loss: 2.5658982849563472e-05
epoch 14: dev_f1=0.6776859504132231, f1=0.6612903225806452, best_f1=0.7034120734908137
step: 0, loss: 0.00012180163321318105
step: 10, loss: 0.0022196925710886717
step: 20, loss: 4.3780775740742683e-05
step: 30, loss: 3.145013761240989e-05
step: 40, loss: 3.1026589567773044e-05
step: 50, loss: 0.0002383091632509604
step: 60, loss: 3.9706250390736386e-05
step: 70, loss: 3.491465758997947e-05
step: 80, loss: 0.00039579952135682106
step: 90, loss: 0.005411846097558737
step: 100, loss: 2.839669286913704e-05
step: 110, loss: 0.0021035089157521725
step: 120, loss: 0.0027221112977713346
step: 130, loss: 6.75757837598212e-05
step: 140, loss: 5.802112355013378e-05
step: 150, loss: 5.272702037473209e-05
step: 160, loss: 5.7494100474286824e-05
step: 170, loss: 0.00018369161989539862
step: 180, loss: 3.0266877729445696e-05
step: 190, loss: 0.0001133162368205376
step: 200, loss: 3.510270107653923e-05
step: 210, loss: 0.04209963604807854
step: 220, loss: 0.0006490492378361523
step: 230, loss: 0.0001427505922038108
step: 240, loss: 1.258394058822887e-05
step: 250, loss: 7.793041731929407e-05
step: 260, loss: 0.0011631854576990008
step: 270, loss: 9.29699235712178e-05
step: 280, loss: 4.143332989769988e-05
step: 290, loss: 7.189811731223017e-05
step: 300, loss: 0.001589386723935604
step: 310, loss: 0.0002144494792446494
step: 320, loss: 0.0001631911873118952
step: 330, loss: 0.00013756494445260614
step: 340, loss: 0.00014187494525685906
step: 350, loss: 0.00022563514357898384
step: 360, loss: 0.004049684852361679
epoch 15: dev_f1=0.6153846153846154, f1=0.6261398176291793, best_f1=0.7034120734908137
step: 0, loss: 0.000452014384791255
step: 10, loss: 6.63440878270194e-05
step: 20, loss: 0.00015411671483889222
step: 30, loss: 9.243869135389104e-05
step: 40, loss: 3.7496785807888955e-05
step: 50, loss: 0.0020224156323820353
step: 60, loss: 0.000735308974981308
step: 70, loss: 0.03441102057695389
step: 80, loss: 0.0001132119505200535
step: 90, loss: 0.0001886159589048475
step: 100, loss: 0.0005498469690792263
step: 110, loss: 0.0010952884331345558
step: 120, loss: 0.0002898403035942465
step: 130, loss: 8.798966882750392e-05
step: 140, loss: 6.707552529405802e-05
step: 150, loss: 0.002121017314493656
step: 160, loss: 5.21040492458269e-05
step: 170, loss: 5.631142994388938e-05
step: 180, loss: 0.0004972997703589499
step: 190, loss: 5.8719870139611885e-05
step: 200, loss: 0.0015806438168510795
step: 210, loss: 1.7452748579671606e-05
step: 220, loss: 4.5217610022518784e-05
step: 230, loss: 0.0005794930038973689
step: 240, loss: 0.0006919840234331787
step: 250, loss: 7.803438347764313e-05
step: 260, loss: 0.00014772301074117422
step: 270, loss: 0.0005081523559056222
step: 280, loss: 7.138292130548507e-05
step: 290, loss: 4.593741687131114e-05
step: 300, loss: 0.0001552088651806116
step: 310, loss: 0.0014363457448780537
step: 320, loss: 0.004936677403748035
step: 330, loss: 0.0004025001544505358
step: 340, loss: 0.000354717078153044
step: 350, loss: 0.003014013869687915
step: 360, loss: 0.0009143360075540841
epoch 16: dev_f1=0.6723646723646723, f1=0.6540540540540541, best_f1=0.7034120734908137
step: 0, loss: 0.0016805710038170218
step: 10, loss: 0.0006795041845180094
step: 20, loss: 5.075010994914919e-05
step: 30, loss: 0.00013143963587936014
step: 40, loss: 0.0003873879322782159
step: 50, loss: 0.00040380615973845124
step: 60, loss: 0.017771577462553978
step: 70, loss: 2.7591086109168828e-05
step: 80, loss: 0.0038453484885394573
step: 90, loss: 0.00020772057177964598
step: 100, loss: 0.0036734326276928186
step: 110, loss: 0.00015904141764622182
step: 120, loss: 2.8668691811617464e-05
step: 130, loss: 0.030136028304696083
step: 140, loss: 0.00039103045128285885
step: 150, loss: 0.00017143589502666146
step: 160, loss: 0.00045083279837854207
step: 170, loss: 0.00023129525652620941
step: 180, loss: 6.006248440826312e-05
step: 190, loss: 9.654869791120291e-05
step: 200, loss: 0.0011085686273872852
step: 210, loss: 4.544356488622725e-05
step: 220, loss: 0.00022526801330968738
step: 230, loss: 3.663990355562419e-05
step: 240, loss: 6.152054265839979e-05
step: 250, loss: 2.222051625722088e-05
step: 260, loss: 8.673465345054865e-05
step: 270, loss: 7.294367242138833e-05
step: 280, loss: 0.016530461609363556
step: 290, loss: 4.6021050366107374e-05
step: 300, loss: 3.45871812896803e-05
step: 310, loss: 5.969557969365269e-05
step: 320, loss: 0.00015258605708368123
step: 330, loss: 0.00032034897594712675
step: 340, loss: 0.0010956937912851572
step: 350, loss: 0.0006158867618069053
step: 360, loss: 0.0010093003511428833
epoch 17: dev_f1=0.6385542168674699, f1=0.632183908045977, best_f1=0.7034120734908137
step: 0, loss: 0.0035044532269239426
step: 10, loss: 1.6204779967665672e-05
step: 20, loss: 7.682506111450493e-05
step: 30, loss: 6.432020745705813e-05
step: 40, loss: 0.00027815523208118975
step: 50, loss: 3.225889304303564e-05
step: 60, loss: 2.2145701223053038e-05
step: 70, loss: 0.00011559855920495465
step: 80, loss: 0.00023409487039316446
step: 90, loss: 0.00011589392670430243
step: 100, loss: 2.1083980755065568e-05
step: 110, loss: 2.286499147885479e-05
step: 120, loss: 1.543372309242841e-05
step: 130, loss: 4.74196276627481e-05
step: 140, loss: 0.0007503331289626658
step: 150, loss: 8.319518383359537e-05
step: 160, loss: 0.00028256274526938796
step: 170, loss: 0.0005307606770657003
step: 180, loss: 7.841190381441265e-05
step: 190, loss: 0.0003186255053151399
step: 200, loss: 2.0070858226972632e-05
step: 210, loss: 0.0004407156666275114
step: 220, loss: 0.0011267568916082382
step: 230, loss: 1.613404856470879e-05
step: 240, loss: 0.00011933436326216906
step: 250, loss: 0.000288755283690989
step: 260, loss: 4.055596946272999e-05
step: 270, loss: 7.781885506119579e-05
step: 280, loss: 2.473086897225585e-05
step: 290, loss: 3.1067767849890515e-05
step: 300, loss: 4.06620092689991e-05
step: 310, loss: 0.0011427623685449362
step: 320, loss: 3.4330656490055844e-05
step: 330, loss: 3.028829632967245e-05
step: 340, loss: 6.307438161456957e-05
step: 350, loss: 0.0001049407001119107
step: 360, loss: 0.10284771025180817
epoch 18: dev_f1=0.660919540229885, f1=0.659217877094972, best_f1=0.7034120734908137
step: 0, loss: 2.8150627258582972e-05
step: 10, loss: 0.0004955450422130525
step: 20, loss: 5.002227771910839e-05
step: 30, loss: 0.0005497719976119697
step: 40, loss: 0.00012578074529301375
step: 50, loss: 0.0010243826545774937
step: 60, loss: 3.410653516766615e-05
step: 70, loss: 0.000738248520065099
step: 80, loss: 0.0001316725683864206
step: 90, loss: 0.00022172769240569323
step: 100, loss: 3.584387377486564e-05
step: 110, loss: 3.601486605475657e-05
step: 120, loss: 0.00018360334797762334
step: 130, loss: 5.825565676786937e-05
step: 140, loss: 3.0389041057787836e-05
step: 150, loss: 0.001602023490704596
step: 160, loss: 0.01702115125954151
step: 170, loss: 4.262794755049981e-05
step: 180, loss: 0.008878874592483044
step: 190, loss: 2.5707098757266067e-05
step: 200, loss: 0.00020376616157591343
step: 210, loss: 0.000129168969579041
step: 220, loss: 5.092166247777641e-05
step: 230, loss: 0.00921378843486309
step: 240, loss: 0.00026903284015133977
step: 250, loss: 0.04700511693954468
step: 260, loss: 0.00015929224900901318
step: 270, loss: 0.00029145259759388864
step: 280, loss: 0.002078678924590349
step: 290, loss: 0.0008151522488333285
step: 300, loss: 2.3792495994712226e-05
step: 310, loss: 0.005406905896961689
step: 320, loss: 5.446146315080114e-05
step: 330, loss: 0.0002918336249422282
step: 340, loss: 2.342757761653047e-05
step: 350, loss: 0.0023096727672964334
step: 360, loss: 8.65967886056751e-05
epoch 19: dev_f1=0.6666666666666667, f1=0.6721763085399448, best_f1=0.7034120734908137
step: 0, loss: 0.00010923892114078626
step: 10, loss: 0.0001173010969068855
step: 20, loss: 5.86387213843409e-05
step: 30, loss: 3.3583703043404967e-05
step: 40, loss: 6.143961945781484e-05
step: 50, loss: 2.5170638764393516e-05
step: 60, loss: 0.00014097233361098915
step: 70, loss: 0.012181106954813004
step: 80, loss: 1.9468074242467992e-05
step: 90, loss: 4.189865285297856e-05
step: 100, loss: 0.00012127146328566596
step: 110, loss: 5.428793519968167e-05
step: 120, loss: 0.0005926114390604198
step: 130, loss: 0.0009794506477192044
step: 140, loss: 0.00017089289030991495
step: 150, loss: 2.350870636291802e-05
step: 160, loss: 0.0001931082078954205
step: 170, loss: 1.8033739252132364e-05
step: 180, loss: 1.4670063137600664e-05
step: 190, loss: 2.367661363678053e-05
step: 200, loss: 9.062170283868909e-05
step: 210, loss: 4.24430072598625e-05
step: 220, loss: 0.0002029951720032841
step: 230, loss: 0.003493531374260783
step: 240, loss: 0.0001838327298173681
step: 250, loss: 0.0002729427069425583
step: 260, loss: 1.9702696590684354e-05
step: 270, loss: 9.036879055202007e-05
step: 280, loss: 0.00013140664668753743
step: 290, loss: 2.0082454284420237e-05
step: 300, loss: 3.086619108216837e-05
step: 310, loss: 2.0395413230289705e-05
step: 320, loss: 2.965717067127116e-05
step: 330, loss: 3.629716957220808e-05
step: 340, loss: 3.516722790664062e-05
step: 350, loss: 0.0003337646194268018
step: 360, loss: 3.534942879923619e-05
epoch 20: dev_f1=0.672463768115942, f1=0.659217877094972, best_f1=0.7034120734908137
