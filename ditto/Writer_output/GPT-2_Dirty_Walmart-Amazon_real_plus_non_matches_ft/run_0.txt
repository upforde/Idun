cuda
Device: cuda
step: 0, loss: 0.6511185765266418
step: 10, loss: 0.1406146138906479
step: 20, loss: 0.23011904954910278
step: 30, loss: 0.13724558055400848
step: 40, loss: 0.2351866513490677
step: 50, loss: 0.13073888421058655
step: 60, loss: 0.22595292329788208
step: 70, loss: 0.48953139781951904
step: 80, loss: 0.15524598956108093
step: 90, loss: 0.22455480694770813
step: 100, loss: 0.2174156755208969
step: 110, loss: 0.11001833528280258
step: 120, loss: 0.12902647256851196
step: 130, loss: 0.0961054265499115
step: 140, loss: 0.2732429504394531
step: 150, loss: 0.302504301071167
step: 160, loss: 0.12372901290655136
step: 170, loss: 0.2149297297000885
step: 180, loss: 0.26347824931144714
step: 190, loss: 0.13643015921115875
step: 200, loss: 0.11738250404596329
step: 210, loss: 0.2162095457315445
step: 220, loss: 0.073809914290905
step: 230, loss: 0.21872948110103607
step: 240, loss: 0.11764869093894958
step: 250, loss: 0.10468030720949173
step: 260, loss: 0.11362820863723755
step: 270, loss: 0.10177827626466751
step: 280, loss: 0.15215274691581726
step: 290, loss: 0.046342842280864716
step: 300, loss: 0.06491643190383911
step: 310, loss: 0.25941935181617737
step: 320, loss: 0.19882948696613312
step: 330, loss: 0.15751765668392181
step: 340, loss: 0.06958440691232681
step: 350, loss: 0.15665459632873535
step: 360, loss: 0.21021434664726257
epoch 1: dev_f1=0.5588235294117647, f1=0.6010362694300518, best_f1=0.6010362694300518
step: 0, loss: 0.10985933244228363
step: 10, loss: 0.11265363544225693
step: 20, loss: 0.4324122369289398
step: 30, loss: 0.31130391359329224
step: 40, loss: 0.06234682351350784
step: 50, loss: 0.13203759491443634
step: 60, loss: 0.010526993311941624
step: 70, loss: 0.10894645005464554
step: 80, loss: 0.11053416132926941
step: 90, loss: 0.19181273877620697
step: 100, loss: 0.20656177401542664
step: 110, loss: 0.042939990758895874
step: 120, loss: 0.0022548348642885685
step: 130, loss: 0.15517239272594452
step: 140, loss: 0.10909154266119003
step: 150, loss: 0.1322028934955597
step: 160, loss: 0.014533866196870804
step: 170, loss: 0.15841631591320038
step: 180, loss: 0.10969375818967819
step: 190, loss: 0.18303264677524567
step: 200, loss: 0.12007702887058258
step: 210, loss: 0.08093705773353577
step: 220, loss: 0.06945090740919113
step: 230, loss: 0.03954005241394043
step: 240, loss: 0.207682266831398
step: 250, loss: 0.20185977220535278
step: 260, loss: 0.07937083393335342
step: 270, loss: 0.09313666820526123
step: 280, loss: 0.10062285512685776
step: 290, loss: 0.21541893482208252
step: 300, loss: 0.22993387281894684
step: 310, loss: 0.05240149796009064
step: 320, loss: 0.18254569172859192
step: 330, loss: 0.019470183178782463
step: 340, loss: 0.2146800309419632
step: 350, loss: 0.09769496321678162
step: 360, loss: 0.34279492497444153
epoch 2: dev_f1=0.6821705426356589, f1=0.675531914893617, best_f1=0.675531914893617
step: 0, loss: 0.0660019963979721
step: 10, loss: 0.08443642407655716
step: 20, loss: 0.2556035816669464
step: 30, loss: 0.08405982702970505
step: 40, loss: 0.016992300748825073
step: 50, loss: 0.4737606942653656
step: 60, loss: 0.13620832562446594
step: 70, loss: 0.030506549403071404
step: 80, loss: 0.041758809238672256
step: 90, loss: 0.035759855061769485
step: 100, loss: 0.078234001994133
step: 110, loss: 0.02628706768155098
step: 120, loss: 0.11982941627502441
step: 130, loss: 0.07951600849628448
step: 140, loss: 0.01418810710310936
step: 150, loss: 0.04927342012524605
step: 160, loss: 0.087599977850914
step: 170, loss: 0.04895782843232155
step: 180, loss: 0.01804988645017147
step: 190, loss: 0.007155994884669781
step: 200, loss: 0.05546776205301285
step: 210, loss: 0.005876289214938879
step: 220, loss: 0.002989014610648155
step: 230, loss: 0.1469486951828003
step: 240, loss: 0.00393643556162715
step: 250, loss: 0.009762795642018318
step: 260, loss: 0.03710668906569481
step: 270, loss: 0.013424052856862545
step: 280, loss: 0.09957701712846756
step: 290, loss: 0.11624446511268616
step: 300, loss: 0.03684527426958084
step: 310, loss: 0.009689750149846077
step: 320, loss: 0.010861135087907314
step: 330, loss: 0.09727940708398819
step: 340, loss: 0.09434444457292557
step: 350, loss: 0.0488048754632473
step: 360, loss: 0.17062260210514069
epoch 3: dev_f1=0.7095238095238094, f1=0.6763990267639902, best_f1=0.6763990267639902
step: 0, loss: 0.025581160560250282
step: 10, loss: 0.014303397387266159
step: 20, loss: 0.00484048668295145
step: 30, loss: 0.0029345001094043255
step: 40, loss: 0.21009695529937744
step: 50, loss: 0.28349632024765015
step: 60, loss: 0.12036474794149399
step: 70, loss: 0.13839507102966309
step: 80, loss: 0.024998849257826805
step: 90, loss: 0.0045170909725129604
step: 100, loss: 0.027020981535315514
step: 110, loss: 0.0442630760371685
step: 120, loss: 0.15611699223518372
step: 130, loss: 0.004165003541857004
step: 140, loss: 0.1130978912115097
step: 150, loss: 0.01012294739484787
step: 160, loss: 0.014177794568240643
step: 170, loss: 0.009286546148359776
step: 180, loss: 0.009930524975061417
step: 190, loss: 0.0013027453096583486
step: 200, loss: 0.03157315030694008
step: 210, loss: 0.10084747523069382
step: 220, loss: 0.012909564189612865
step: 230, loss: 0.007315490860491991
step: 240, loss: 0.036560215055942535
step: 250, loss: 0.003227523062378168
step: 260, loss: 0.01689116284251213
step: 270, loss: 0.00512795802205801
step: 280, loss: 0.00224723550491035
step: 290, loss: 0.006890282966196537
step: 300, loss: 0.003132062964141369
step: 310, loss: 0.07972963899374008
step: 320, loss: 0.000890552531927824
step: 330, loss: 0.05383637920022011
step: 340, loss: 0.0006392147042788565
step: 350, loss: 0.08844948559999466
step: 360, loss: 0.0639912411570549
epoch 4: dev_f1=0.7067669172932332, f1=0.7058823529411764, best_f1=0.6763990267639902
step: 0, loss: 0.002825732808560133
step: 10, loss: 0.00018683999951463193
step: 20, loss: 0.003018991556018591
step: 30, loss: 0.028286287561058998
step: 40, loss: 0.11257758736610413
step: 50, loss: 0.03902711719274521
step: 60, loss: 0.04693856090307236
step: 70, loss: 0.0118633434176445
step: 80, loss: 0.0006020355504006147
step: 90, loss: 0.0012855347013100982
step: 100, loss: 0.01196217630058527
step: 110, loss: 0.003074871376156807
step: 120, loss: 0.01612979732453823
step: 130, loss: 0.004168580286204815
step: 140, loss: 0.007447569631040096
step: 150, loss: 0.01726013980805874
step: 160, loss: 0.08553158491849899
step: 170, loss: 0.0210739653557539
step: 180, loss: 0.0014021832030266523
step: 190, loss: 0.02926022745668888
step: 200, loss: 0.0026508038863539696
step: 210, loss: 0.02223406545817852
step: 220, loss: 0.0029616612009704113
step: 230, loss: 0.2332541048526764
step: 240, loss: 0.07913991808891296
step: 250, loss: 0.03701827675104141
step: 260, loss: 0.0054387678392231464
step: 270, loss: 0.023205481469631195
step: 280, loss: 0.012887036427855492
step: 290, loss: 0.001286037266254425
step: 300, loss: 0.0028134784661233425
step: 310, loss: 0.002393170725554228
step: 320, loss: 0.015662696212530136
step: 330, loss: 0.016907306388020515
step: 340, loss: 0.0007926929974928498
step: 350, loss: 0.222306028008461
step: 360, loss: 0.005949769634753466
epoch 5: dev_f1=0.6846361185983827, f1=0.6684491978609626, best_f1=0.6763990267639902
step: 0, loss: 0.0025454869028180838
step: 10, loss: 0.011227436363697052
step: 20, loss: 0.01952182874083519
step: 30, loss: 0.0006186328828334808
step: 40, loss: 0.004422305151820183
step: 50, loss: 0.015167687088251114
step: 60, loss: 0.0006883142050355673
step: 70, loss: 0.03988036513328552
step: 80, loss: 0.0008529947372153401
step: 90, loss: 0.012408738024532795
step: 100, loss: 0.003644464071840048
step: 110, loss: 0.007184911053627729
step: 120, loss: 0.002034461824223399
step: 130, loss: 0.0003173247678205371
step: 140, loss: 0.0031430963426828384
step: 150, loss: 0.0016686313319951296
step: 160, loss: 0.00024311107699759305
step: 170, loss: 0.13960877060890198
step: 180, loss: 0.0016853353008627892
step: 190, loss: 0.004758624825626612
step: 200, loss: 0.006173230707645416
step: 210, loss: 0.0008294241852127016
step: 220, loss: 0.0009018112323246896
step: 230, loss: 0.0027080695144832134
step: 240, loss: 0.001371379941701889
step: 250, loss: 0.0007988652214407921
step: 260, loss: 0.08011312037706375
step: 270, loss: 0.0004820292233489454
step: 280, loss: 0.0005386255215853453
step: 290, loss: 0.0026455181650817394
step: 300, loss: 0.012919503264129162
step: 310, loss: 0.04858295992016792
step: 320, loss: 0.006129034794867039
step: 330, loss: 0.0015603428473696113
step: 340, loss: 0.01871700957417488
step: 350, loss: 0.001425833674147725
step: 360, loss: 0.0031889097299426794
epoch 6: dev_f1=0.6982543640897756, f1=0.6634146341463415, best_f1=0.6763990267639902
step: 0, loss: 0.011013499461114407
step: 10, loss: 0.029637210071086884
step: 20, loss: 0.0010411556577309966
step: 30, loss: 0.02729666978120804
step: 40, loss: 0.000320010120049119
step: 50, loss: 0.000498440582305193
step: 60, loss: 0.0006120241596363485
step: 70, loss: 0.0032214554958045483
step: 80, loss: 0.0010130610316991806
step: 90, loss: 0.0012371077900752425
step: 100, loss: 0.00098889647051692
step: 110, loss: 0.0031850216910243034
step: 120, loss: 0.00014388399722520262
step: 130, loss: 0.000302705739159137
step: 140, loss: 0.0036722663789987564
step: 150, loss: 0.0041337390430271626
step: 160, loss: 0.0001724477333482355
step: 170, loss: 0.00035572180058807135
step: 180, loss: 0.0002151242078980431
step: 190, loss: 8.175075345207006e-05
step: 200, loss: 0.0008209514780901372
step: 210, loss: 0.0007366782519966364
step: 220, loss: 0.00011302877828711644
step: 230, loss: 0.007984841242432594
step: 240, loss: 0.0010642212582752109
step: 250, loss: 0.015200944617390633
step: 260, loss: 0.0008646450005471706
step: 270, loss: 0.011299383826553822
step: 280, loss: 0.0013413005508482456
step: 290, loss: 0.00027541222516447306
step: 300, loss: 0.00014991294301580638
step: 310, loss: 0.0010374541161581874
step: 320, loss: 0.00375195499509573
step: 330, loss: 0.02991955727338791
step: 340, loss: 0.0006804562290199101
step: 350, loss: 0.003963662777096033
step: 360, loss: 0.1587761491537094
epoch 7: dev_f1=0.676923076923077, f1=0.6563307493540051, best_f1=0.6763990267639902
step: 0, loss: 0.004820200614631176
step: 10, loss: 0.021150825545191765
step: 20, loss: 0.003633934073150158
step: 30, loss: 0.06664746254682541
step: 40, loss: 0.00039229608955793083
step: 50, loss: 0.006219170987606049
step: 60, loss: 0.0032480331137776375
step: 70, loss: 0.0033567980863153934
step: 80, loss: 0.001552194356918335
step: 90, loss: 0.0043764542788267136
step: 100, loss: 0.0003644516982603818
step: 110, loss: 0.0011499148095026612
step: 120, loss: 0.011171214282512665
step: 130, loss: 0.002496476750820875
step: 140, loss: 0.03448398411273956
step: 150, loss: 0.17330265045166016
step: 160, loss: 0.0013134776381775737
step: 170, loss: 0.0005286365048959851
step: 180, loss: 0.0015170255210250616
step: 190, loss: 0.00703455088660121
step: 200, loss: 0.0017659018049016595
step: 210, loss: 0.011701259762048721
step: 220, loss: 0.005585046950727701
step: 230, loss: 0.0001599292445462197
step: 240, loss: 0.00020226444758009166
step: 250, loss: 0.00010334329272154719
step: 260, loss: 0.006168067455291748
step: 270, loss: 0.0057874564081430435
step: 280, loss: 0.010623629204928875
step: 290, loss: 0.0004439535550773144
step: 300, loss: 0.003356281667947769
step: 310, loss: 0.0031535006128251553
step: 320, loss: 0.028250018134713173
step: 330, loss: 0.0019276492530480027
step: 340, loss: 0.00047811144031584263
step: 350, loss: 0.0010713195661082864
step: 360, loss: 0.005051215644925833
epoch 8: dev_f1=0.6808510638297871, f1=0.6369047619047619, best_f1=0.6763990267639902
step: 0, loss: 0.00018241364159621298
step: 10, loss: 9.830885392148048e-05
step: 20, loss: 0.0029634239617735147
step: 30, loss: 0.01964486390352249
step: 40, loss: 0.0008880437235347927
step: 50, loss: 4.151053144596517e-05
step: 60, loss: 3.7907142541371286e-05
step: 70, loss: 0.00020287840743549168
step: 80, loss: 7.016131712589413e-05
step: 90, loss: 4.357203943072818e-05
step: 100, loss: 0.0005234167911112309
step: 110, loss: 0.0003054173430427909
step: 120, loss: 0.0003216950863134116
step: 130, loss: 0.0006163124344311655
step: 140, loss: 0.000282237830106169
step: 150, loss: 0.00010769895015982911
step: 160, loss: 7.050928252283484e-05
step: 170, loss: 0.056345678865909576
step: 180, loss: 0.0004393956915009767
step: 190, loss: 0.006158764474093914
step: 200, loss: 0.00012880691792815924
step: 210, loss: 0.00010861342889256775
step: 220, loss: 0.00029510381864383817
step: 230, loss: 0.00023498435621149838
step: 240, loss: 0.005907956510782242
step: 250, loss: 0.00046200689394026995
step: 260, loss: 0.048105865716934204
step: 270, loss: 0.006716020405292511
step: 280, loss: 0.0008196090930141509
step: 290, loss: 0.00020072761981282383
step: 300, loss: 0.00029961098334752023
step: 310, loss: 6.941068568266928e-05
step: 320, loss: 0.00018159253522753716
step: 330, loss: 0.0005338214104995131
step: 340, loss: 0.00045302521903067827
step: 350, loss: 0.003225860884413123
step: 360, loss: 0.13491402566432953
epoch 9: dev_f1=0.7176781002638523, f1=0.69, best_f1=0.69
step: 0, loss: 0.0010339377913624048
step: 10, loss: 0.0005825240514241159
step: 20, loss: 0.0007119806832633913
step: 30, loss: 0.0010744133032858372
step: 40, loss: 0.025035442784428596
step: 50, loss: 0.000255873630521819
step: 60, loss: 9.657267219154164e-05
step: 70, loss: 0.0001249401393579319
step: 80, loss: 0.0014053574996069074
step: 90, loss: 0.0036017168313264847
step: 100, loss: 0.00042775398469530046
step: 110, loss: 5.824768959428184e-05
step: 120, loss: 0.00012404796143528074
step: 130, loss: 0.012079736217856407
step: 140, loss: 0.0019540907815098763
step: 150, loss: 0.0033366563729941845
step: 160, loss: 0.00035904772812500596
step: 170, loss: 0.0003151020500808954
step: 180, loss: 0.00012714626791421324
step: 190, loss: 0.0014031418832018971
step: 200, loss: 0.01165952067822218
step: 210, loss: 0.00020280051103327423
step: 220, loss: 0.00023396928736474365
step: 230, loss: 0.021364469081163406
step: 240, loss: 0.0003658036876004189
step: 250, loss: 0.03575374558568001
step: 260, loss: 0.00024266322725452483
step: 270, loss: 0.00019289564806967974
step: 280, loss: 0.0004378540616016835
step: 290, loss: 5.660568785970099e-05
step: 300, loss: 0.0009700589580461383
step: 310, loss: 7.167410512920469e-05
step: 320, loss: 0.09707281738519669
step: 330, loss: 0.0025086326058954
step: 340, loss: 0.00023809605045244098
step: 350, loss: 0.00013678133836947381
step: 360, loss: 0.005304416641592979
epoch 10: dev_f1=0.7045454545454547, f1=0.6809651474530832, best_f1=0.69
step: 0, loss: 0.0004187577869743109
step: 10, loss: 0.03834360092878342
step: 20, loss: 0.0016567863058298826
step: 30, loss: 0.00024218672479037195
step: 40, loss: 0.0011723985662683845
step: 50, loss: 0.00013437509187497199
step: 60, loss: 0.00011770518904086202
step: 70, loss: 0.0006399066769517958
step: 80, loss: 0.0010482007637619972
step: 90, loss: 0.0009171899291686714
step: 100, loss: 0.006043413653969765
step: 110, loss: 0.00029637187253683805
step: 120, loss: 0.0010762239107862115
step: 130, loss: 0.00046476212446577847
step: 140, loss: 0.0037836087867617607
step: 150, loss: 0.000847689516376704
step: 160, loss: 0.0002620139275677502
step: 170, loss: 6.787687743781134e-05
step: 180, loss: 0.0003480698214843869
step: 190, loss: 0.0034475845750421286
step: 200, loss: 7.089684368111193e-05
step: 210, loss: 0.0005175085971131921
step: 220, loss: 0.00021462496079038829
step: 230, loss: 5.2497474825941026e-05
step: 240, loss: 0.00035643254523165524
step: 250, loss: 0.0010828104568645358
step: 260, loss: 0.00013785401824861765
step: 270, loss: 0.00014261953765526414
step: 280, loss: 0.00015917197742965072
step: 290, loss: 0.0002417166979284957
step: 300, loss: 0.00010010995902121067
step: 310, loss: 0.00010874390136450529
step: 320, loss: 0.0002557696425355971
step: 330, loss: 0.0009398595429956913
step: 340, loss: 0.0001997850340558216
step: 350, loss: 0.020990140736103058
step: 360, loss: 6.212343578226864e-05
epoch 11: dev_f1=0.6933333333333334, f1=0.6771653543307086, best_f1=0.69
step: 0, loss: 0.013507063500583172
step: 10, loss: 0.00022945378441363573
step: 20, loss: 3.793735595536418e-05
step: 30, loss: 3.144813308608718e-05
step: 40, loss: 0.00014545554586220533
step: 50, loss: 5.413069811766036e-05
step: 60, loss: 0.00020998765830881894
step: 70, loss: 0.0003106365038547665
step: 80, loss: 0.00023525724827777594
step: 90, loss: 0.00026170589262619615
step: 100, loss: 0.0046766079030931
step: 110, loss: 7.2508177254349e-05
step: 120, loss: 0.009304280392825603
step: 130, loss: 0.015271787531673908
step: 140, loss: 0.0009040154982358217
step: 150, loss: 0.0006229940336197615
step: 160, loss: 0.0001510495931142941
step: 170, loss: 0.00022314312809612602
step: 180, loss: 0.0006279623485170305
step: 190, loss: 0.000638334546238184
step: 200, loss: 0.00011570321657927707
step: 210, loss: 0.00023014997714199126
step: 220, loss: 0.008596046827733517
step: 230, loss: 0.00032657134579494596
step: 240, loss: 4.3307933083269745e-05
step: 250, loss: 0.006305123213678598
step: 260, loss: 0.00037551121204160154
step: 270, loss: 0.0005317999166436493
step: 280, loss: 0.0007193686906248331
step: 290, loss: 6.39439676888287e-05
step: 300, loss: 0.0006424854509532452
step: 310, loss: 0.00010280973219778389
step: 320, loss: 0.0019082514336332679
step: 330, loss: 0.0006499977898783982
step: 340, loss: 0.006561363581568003
step: 350, loss: 0.004514894913882017
step: 360, loss: 0.002594674238935113
epoch 12: dev_f1=0.6866485013623977, f1=0.6434316353887399, best_f1=0.69
step: 0, loss: 7.802061008987948e-05
step: 10, loss: 0.00024683287483640015
step: 20, loss: 0.00027100060833618045
step: 30, loss: 0.0005118475528433919
step: 40, loss: 0.001624705852009356
step: 50, loss: 0.000589684525039047
step: 60, loss: 0.00016131141455844045
step: 70, loss: 0.0006569122197106481
step: 80, loss: 0.00029892163001932204
step: 90, loss: 0.0009343074052594602
step: 100, loss: 0.0009438907727599144
step: 110, loss: 0.00014116718375589699
step: 120, loss: 0.001661376329138875
step: 130, loss: 0.005563899874687195
step: 140, loss: 0.0003967027587350458
step: 150, loss: 0.0002161742449970916
step: 160, loss: 0.000438453076640144
step: 170, loss: 0.0007183828274719417
step: 180, loss: 4.992565300199203e-05
step: 190, loss: 2.4664614102221094e-05
step: 200, loss: 0.0001633055362617597
step: 210, loss: 7.300431025214493e-05
step: 220, loss: 0.00013850787945557386
step: 230, loss: 0.0001756977435434237
step: 240, loss: 0.001542289974167943
step: 250, loss: 8.023317059269175e-05
step: 260, loss: 0.0047776950523257256
step: 270, loss: 9.715753549244255e-05
step: 280, loss: 0.0056473203003406525
step: 290, loss: 0.00023902546672616154
step: 300, loss: 9.8848991910927e-05
step: 310, loss: 0.00010302491864422336
step: 320, loss: 0.000890198047272861
step: 330, loss: 0.0001338510337518528
step: 340, loss: 0.00043202625238336623
step: 350, loss: 0.0008817604975774884
step: 360, loss: 0.02955044060945511
epoch 13: dev_f1=0.6534090909090908, f1=0.6327683615819208, best_f1=0.69
step: 0, loss: 0.0005255175055935979
step: 10, loss: 0.000652642862405628
step: 20, loss: 0.00010302594455424696
step: 30, loss: 7.718949927948415e-05
step: 40, loss: 0.001624686294235289
step: 50, loss: 4.211837222101167e-05
step: 60, loss: 0.0008576016989536583
step: 70, loss: 0.0003626616671681404
step: 80, loss: 0.0002505300799384713
step: 90, loss: 9.335402137367055e-05
step: 100, loss: 0.008183297701179981
step: 110, loss: 7.596983050461859e-05
step: 120, loss: 2.604224209790118e-05
step: 130, loss: 8.490706386510283e-05
step: 140, loss: 0.0005498607060872018
step: 150, loss: 6.379526166711003e-05
step: 160, loss: 0.0019495816668495536
step: 170, loss: 0.0009233226301148534
step: 180, loss: 0.00011550343333510682
step: 190, loss: 0.00018753501353785396
step: 200, loss: 0.009763922542333603
step: 210, loss: 0.0009118184098042548
step: 220, loss: 0.00012984516797587276
step: 230, loss: 0.0001046055622282438
step: 240, loss: 0.00012707871792372316
step: 250, loss: 3.698601358337328e-05
step: 260, loss: 8.92867537913844e-05
step: 270, loss: 0.00021135047427378595
step: 280, loss: 0.008909015916287899
step: 290, loss: 6.395510717993602e-05
step: 300, loss: 5.22866721439641e-05
step: 310, loss: 0.0003370330960024148
step: 320, loss: 0.001711499411612749
step: 330, loss: 0.00015462747251149267
step: 340, loss: 2.5651814212324098e-05
step: 350, loss: 0.0007547395071014762
step: 360, loss: 0.013165640644729137
epoch 14: dev_f1=0.7052631578947368, f1=0.6595744680851063, best_f1=0.69
step: 0, loss: 2.7089512514066882e-05
step: 10, loss: 0.027498601004481316
step: 20, loss: 3.1644009141018614e-05
step: 30, loss: 1.9542638256098144e-05
step: 40, loss: 2.5219664166797884e-05
step: 50, loss: 0.00014925208233762532
step: 60, loss: 0.00796637125313282
step: 70, loss: 0.00011939884279854596
step: 80, loss: 0.000330606650095433
step: 90, loss: 4.5500848500523716e-05
step: 100, loss: 0.003228844841942191
step: 110, loss: 3.237499913666397e-05
step: 120, loss: 0.00016407914517913014
step: 130, loss: 4.562274261843413e-05
step: 140, loss: 0.00010697694233385846
step: 150, loss: 0.000913403753656894
step: 160, loss: 5.2843261073576286e-05
step: 170, loss: 4.579160668072291e-05
step: 180, loss: 0.00020194295211695135
step: 190, loss: 9.982787014450878e-05
step: 200, loss: 0.00022643280681222677
step: 210, loss: 0.0002833724720403552
step: 220, loss: 0.0003068598743993789
step: 230, loss: 0.00022576874471269548
step: 240, loss: 0.00010385517089162022
step: 250, loss: 0.0014976345701143146
step: 260, loss: 0.0009579272009432316
step: 270, loss: 0.031689051538705826
step: 280, loss: 2.3416761905536987e-05
step: 290, loss: 0.0003067583020310849
step: 300, loss: 6.674610631307587e-05
step: 310, loss: 0.0017386807594448328
step: 320, loss: 0.0014272676780819893
step: 330, loss: 0.00031658040825277567
step: 340, loss: 2.7227411919739097e-05
step: 350, loss: 4.896615064353682e-05
step: 360, loss: 0.0015919666038826108
epoch 15: dev_f1=0.7172774869109948, f1=0.6822916666666666, best_f1=0.69
step: 0, loss: 0.00035437860060483217
step: 10, loss: 0.00023341311316471547
step: 20, loss: 7.992424070835114e-05
step: 30, loss: 0.00022789978538639843
step: 40, loss: 3.805145024671219e-05
step: 50, loss: 0.00024221692001447082
step: 60, loss: 4.353909389465116e-05
step: 70, loss: 6.008323180139996e-05
step: 80, loss: 2.1583980924333446e-05
step: 90, loss: 4.912200165563263e-05
step: 100, loss: 0.0003717815561685711
step: 110, loss: 6.193984881974757e-05
step: 120, loss: 0.00019847729708999395
step: 130, loss: 2.724238220253028e-05
step: 140, loss: 0.00034855445846915245
step: 150, loss: 0.00025892886333167553
step: 160, loss: 3.8305191992549226e-05
step: 170, loss: 0.00027068957570008934
step: 180, loss: 0.0002326757530681789
step: 190, loss: 7.925796671770513e-05
step: 200, loss: 3.416335675865412e-05
step: 210, loss: 0.0004152782785240561
step: 220, loss: 0.00014303364150691777
step: 230, loss: 6.996047159191221e-05
step: 240, loss: 2.9611655918415636e-05
step: 250, loss: 0.00012137804878875613
step: 260, loss: 3.707988798851147e-05
step: 270, loss: 0.0001918042980832979
step: 280, loss: 2.64672653429443e-05
step: 290, loss: 0.00027635565493255854
step: 300, loss: 2.5047647795872763e-05
step: 310, loss: 2.9223487217677757e-05
step: 320, loss: 2.2593472749576904e-05
step: 330, loss: 2.513012987037655e-05
step: 340, loss: 2.140524702554103e-05
step: 350, loss: 0.0006086723296903074
step: 360, loss: 5.350604624254629e-05
epoch 16: dev_f1=0.6646884272997032, f1=0.6428571428571428, best_f1=0.69
step: 0, loss: 0.00018340733367949724
step: 10, loss: 5.3317617130232975e-05
step: 20, loss: 6.595268496312201e-05
step: 30, loss: 4.790514140040614e-05
step: 40, loss: 2.7503028832143173e-05
step: 50, loss: 0.0003132123383693397
step: 60, loss: 0.0005722794448956847
step: 70, loss: 8.730126864975318e-05
step: 80, loss: 0.00013889337424188852
step: 90, loss: 5.6898385082604364e-05
step: 100, loss: 0.0003599038172978908
step: 110, loss: 2.614696313685272e-05
step: 120, loss: 7.579184602946043e-05
step: 130, loss: 9.937381400959566e-05
step: 140, loss: 2.8194264814374037e-05
step: 150, loss: 3.9276503230212256e-05
step: 160, loss: 3.0866460292600095e-05
step: 170, loss: 2.36400737776421e-05
step: 180, loss: 3.862365338136442e-05
step: 190, loss: 1.885715391836129e-05
step: 200, loss: 4.897184408036992e-05
step: 210, loss: 9.814653458306566e-05
step: 220, loss: 2.243694143544417e-05
step: 230, loss: 2.409091393928975e-05
step: 240, loss: 5.3053165174787864e-05
step: 250, loss: 4.9885318730957806e-05
step: 260, loss: 0.00038031136500649154
step: 270, loss: 3.564718281268142e-05
step: 280, loss: 0.009326118975877762
step: 290, loss: 0.0001387268421240151
step: 300, loss: 4.3129381083417684e-05
step: 310, loss: 8.65613910718821e-05
step: 320, loss: 0.00010453670984134078
step: 330, loss: 1.7165946701425128e-05
step: 340, loss: 5.688704550266266e-05
step: 350, loss: 5.441259781946428e-05
step: 360, loss: 0.1814645528793335
epoch 17: dev_f1=0.7022471910112359, f1=0.660968660968661, best_f1=0.69
step: 0, loss: 6.233860040083528e-05
step: 10, loss: 3.566028317436576e-05
step: 20, loss: 4.626950976671651e-05
step: 30, loss: 5.7659704907564446e-05
step: 40, loss: 4.9473899707663804e-05
step: 50, loss: 3.8993090129224584e-05
step: 60, loss: 7.000255573075265e-05
step: 70, loss: 7.140959496609867e-05
step: 80, loss: 2.7662463253363967e-05
step: 90, loss: 5.596081609837711e-05
step: 100, loss: 1.686041650827974e-05
step: 110, loss: 0.0228902455419302
step: 120, loss: 2.3944554413901642e-05
step: 130, loss: 0.00013057411706540734
step: 140, loss: 8.795366011327133e-05
step: 150, loss: 0.00024765802663750947
step: 160, loss: 3.5421151551418006e-05
step: 170, loss: 8.132970833685249e-05
step: 180, loss: 2.746551763266325e-05
step: 190, loss: 0.0002734350855462253
step: 200, loss: 6.990185647737235e-05
step: 210, loss: 2.6265937776770443e-05
step: 220, loss: 4.477767288335599e-05
step: 230, loss: 2.3260236048372462e-05
step: 240, loss: 0.000360789563274011
step: 250, loss: 2.392691749264486e-05
step: 260, loss: 1.7076557924156077e-05
step: 270, loss: 2.4705206669750623e-05
step: 280, loss: 4.9176909669768065e-05
step: 290, loss: 0.0010614653583616018
step: 300, loss: 4.881892164121382e-05
step: 310, loss: 3.99212513002567e-05
step: 320, loss: 4.143877231399529e-05
step: 330, loss: 2.8419039153959602e-05
step: 340, loss: 2.0000545191578567e-05
step: 350, loss: 3.388100230949931e-05
step: 360, loss: 0.0004584899579640478
epoch 18: dev_f1=0.6837606837606838, f1=0.6531791907514451, best_f1=0.69
step: 0, loss: 2.845255767169874e-05
step: 10, loss: 1.8052556697512046e-05
step: 20, loss: 3.788763569900766e-05
step: 30, loss: 2.2820644517196342e-05
step: 40, loss: 0.002013798337429762
step: 50, loss: 3.928066143998876e-05
step: 60, loss: 4.2161984310951084e-05
step: 70, loss: 0.0001749624643707648
step: 80, loss: 1.4517331692331936e-05
step: 90, loss: 0.00027701756334863603
step: 100, loss: 0.0010555924382060766
step: 110, loss: 8.460204844595864e-05
step: 120, loss: 5.616277121589519e-05
step: 130, loss: 1.5225088645820506e-05
step: 140, loss: 1.8119484593626112e-05
step: 150, loss: 0.00014652794925495982
step: 160, loss: 1.932271698024124e-05
step: 170, loss: 2.7785532438429072e-05
step: 180, loss: 0.00040953129064291716
step: 190, loss: 3.838377961074002e-05
step: 200, loss: 8.001611422514543e-05
step: 210, loss: 0.0004299366846680641
step: 220, loss: 4.38193601439707e-05
step: 230, loss: 6.030739314155653e-05
step: 240, loss: 3.787558671319857e-05
step: 250, loss: 2.6045374397654086e-05
step: 260, loss: 3.12321208184585e-05
step: 270, loss: 0.0002497478562872857
step: 280, loss: 0.00026394755695946515
step: 290, loss: 3.169619958498515e-05
step: 300, loss: 2.3684255211264826e-05
step: 310, loss: 1.9967250409536064e-05
step: 320, loss: 2.5811641535256058e-05
step: 330, loss: 3.8185055018402636e-05
step: 340, loss: 3.266068597440608e-05
step: 350, loss: 0.000330466398736462
step: 360, loss: 1.608936145203188e-05
epoch 19: dev_f1=0.6647564469914041, f1=0.6627906976744187, best_f1=0.69
step: 0, loss: 0.00010460341582074761
step: 10, loss: 2.9725590138696134e-05
step: 20, loss: 7.232935604406521e-05
step: 30, loss: 3.220221697119996e-05
step: 40, loss: 6.743343692505732e-05
step: 50, loss: 3.992700294475071e-05
step: 60, loss: 2.7580907044466585e-05
step: 70, loss: 2.8090562409488484e-05
step: 80, loss: 0.003016382921487093
step: 90, loss: 0.003986213356256485
step: 100, loss: 5.112534199724905e-05
step: 110, loss: 4.070577415404841e-05
step: 120, loss: 1.8972557882079855e-05
step: 130, loss: 2.601214509923011e-05
step: 140, loss: 0.005324188619852066
step: 150, loss: 3.9209317037602887e-05
step: 160, loss: 8.205500489566475e-05
step: 170, loss: 3.403968730708584e-05
step: 180, loss: 2.2403175535146147e-05
step: 190, loss: 3.0932696972740814e-05
step: 200, loss: 2.3341850464930758e-05
step: 210, loss: 2.2205795175977983e-05
step: 220, loss: 4.967136919731274e-05
step: 230, loss: 0.0004991294699721038
step: 240, loss: 0.00016623798001091927
step: 250, loss: 1.94493550225161e-05
step: 260, loss: 8.886407886166126e-05
step: 270, loss: 2.584890171419829e-05
step: 280, loss: 3.967146767536178e-05
step: 290, loss: 0.00013675971422344446
step: 300, loss: 5.105684249429032e-05
step: 310, loss: 0.000749958970118314
step: 320, loss: 0.0005106955068185925
step: 330, loss: 0.0001409268006682396
step: 340, loss: 0.00013795764243695885
step: 350, loss: 0.0003193613956682384
step: 360, loss: 8.299326873384416e-05
epoch 20: dev_f1=0.6724137931034484, f1=0.6588921282798833, best_f1=0.69
