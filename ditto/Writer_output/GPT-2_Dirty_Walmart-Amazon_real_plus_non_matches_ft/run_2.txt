cuda
Device: cuda
step: 0, loss: 0.8078793287277222
step: 10, loss: 0.24407340586185455
step: 20, loss: 0.1514868289232254
step: 30, loss: 0.2368467152118683
step: 40, loss: 0.14489254355430603
step: 50, loss: 0.24439850449562073
step: 60, loss: 0.2358284741640091
step: 70, loss: 0.23176825046539307
step: 80, loss: 0.1441953033208847
step: 90, loss: 0.14898474514484406
step: 100, loss: 0.23170042037963867
step: 110, loss: 0.3642207980155945
step: 120, loss: 0.12855519354343414
step: 130, loss: 0.2207086831331253
step: 140, loss: 0.038727056235075
step: 150, loss: 0.037844590842723846
step: 160, loss: 0.16155722737312317
step: 170, loss: 0.030168216675519943
step: 180, loss: 0.22970940172672272
step: 190, loss: 0.30210602283477783
step: 200, loss: 0.1339421421289444
step: 210, loss: 0.1358328014612198
step: 220, loss: 0.10272292047739029
step: 230, loss: 0.33814680576324463
step: 240, loss: 0.3014123737812042
step: 250, loss: 0.19160398840904236
step: 260, loss: 0.08320672065019608
step: 270, loss: 0.40622979402542114
step: 280, loss: 0.3603896200656891
step: 290, loss: 0.2450316995382309
step: 300, loss: 0.0791776105761528
step: 310, loss: 0.15877245366573334
step: 320, loss: 0.27211958169937134
step: 330, loss: 0.17654062807559967
step: 340, loss: 0.1976073682308197
step: 350, loss: 0.21289080381393433
step: 360, loss: 0.25104451179504395
epoch 1: dev_f1=0.4476744186046512, f1=0.4321329639889197, best_f1=0.4321329639889197
step: 0, loss: 0.12232495844364166
step: 10, loss: 0.24011510610580444
step: 20, loss: 0.05405505746603012
step: 30, loss: 0.13293050229549408
step: 40, loss: 0.12227031588554382
step: 50, loss: 0.21134501695632935
step: 60, loss: 0.059429019689559937
step: 70, loss: 0.11402300745248795
step: 80, loss: 0.2166612148284912
step: 90, loss: 0.05925772711634636
step: 100, loss: 0.30124375224113464
step: 110, loss: 0.10281883925199509
step: 120, loss: 0.07368697226047516
step: 130, loss: 0.35397660732269287
step: 140, loss: 0.07023138552904129
step: 150, loss: 0.04891281947493553
step: 160, loss: 0.07290366291999817
step: 170, loss: 0.07669170945882797
step: 180, loss: 0.05263878405094147
step: 190, loss: 0.1638520061969757
step: 200, loss: 0.05001407489180565
step: 210, loss: 0.09301237016916275
step: 220, loss: 0.04766901209950447
step: 230, loss: 0.1731947958469391
step: 240, loss: 0.12838147580623627
step: 250, loss: 0.04412199556827545
step: 260, loss: 0.008696972392499447
step: 270, loss: 0.13142099976539612
step: 280, loss: 0.27035146951675415
step: 290, loss: 0.11392273008823395
step: 300, loss: 0.09779329597949982
step: 310, loss: 0.18502748012542725
step: 320, loss: 0.09846389293670654
step: 330, loss: 0.05533149838447571
step: 340, loss: 0.07088471204042435
step: 350, loss: 0.04145180433988571
step: 360, loss: 0.21026493608951569
epoch 2: dev_f1=0.5876993166287016, f1=0.5594405594405595, best_f1=0.5594405594405595
step: 0, loss: 0.12000299245119095
step: 10, loss: 0.1068551242351532
step: 20, loss: 0.071239173412323
step: 30, loss: 0.11634539067745209
step: 40, loss: 0.04253976419568062
step: 50, loss: 0.21400125324726105
step: 60, loss: 0.189207062125206
step: 70, loss: 0.0574290007352829
step: 80, loss: 0.24978864192962646
step: 90, loss: 0.09501668065786362
step: 100, loss: 0.006084576714783907
step: 110, loss: 0.055257271975278854
step: 120, loss: 0.14903073012828827
step: 130, loss: 0.016464250162243843
step: 140, loss: 0.10718994587659836
step: 150, loss: 0.05228550732135773
step: 160, loss: 0.043016135692596436
step: 170, loss: 0.04944024607539177
step: 180, loss: 0.23481568694114685
step: 190, loss: 0.07114783674478531
step: 200, loss: 0.04661966860294342
step: 210, loss: 0.06382587552070618
step: 220, loss: 0.00871189497411251
step: 230, loss: 0.008580967783927917
step: 240, loss: 0.11619260907173157
step: 250, loss: 0.26270920038223267
step: 260, loss: 0.17906703054904938
step: 270, loss: 0.014017835259437561
step: 280, loss: 0.06715777516365051
step: 290, loss: 0.0669538751244545
step: 300, loss: 0.02629011869430542
step: 310, loss: 0.08755875378847122
step: 320, loss: 0.03729032352566719
step: 330, loss: 0.037100959569215775
step: 340, loss: 0.0537099689245224
step: 350, loss: 0.037951547652482986
step: 360, loss: 0.054840561002492905
epoch 3: dev_f1=0.657608695652174, f1=0.5945945945945946, best_f1=0.5945945945945946
step: 0, loss: 0.0751243308186531
step: 10, loss: 0.05375203117728233
step: 20, loss: 0.17683055996894836
step: 30, loss: 0.10209228843450546
step: 40, loss: 0.054743871092796326
step: 50, loss: 0.003679154673591256
step: 60, loss: 0.034143511205911636
step: 70, loss: 0.013419486582279205
step: 80, loss: 0.022563694044947624
step: 90, loss: 0.024192551150918007
step: 100, loss: 0.028013885021209717
step: 110, loss: 0.04042844474315643
step: 120, loss: 0.0030288887210190296
step: 130, loss: 0.013302084058523178
step: 140, loss: 0.15898190438747406
step: 150, loss: 0.008298017084598541
step: 160, loss: 0.006521994713693857
step: 170, loss: 0.16527381539344788
step: 180, loss: 0.028872119262814522
step: 190, loss: 0.033146534115076065
step: 200, loss: 0.053666532039642334
step: 210, loss: 0.002682165941223502
step: 220, loss: 0.01967996545135975
step: 230, loss: 0.11947494745254517
step: 240, loss: 0.08942711353302002
step: 250, loss: 0.007403294090181589
step: 260, loss: 0.3365486264228821
step: 270, loss: 0.05630731210112572
step: 280, loss: 0.0102283526211977
step: 290, loss: 0.025271400809288025
step: 300, loss: 0.07835361361503601
step: 310, loss: 0.16028983891010284
step: 320, loss: 0.13366827368736267
step: 330, loss: 0.1032257080078125
step: 340, loss: 0.08899679034948349
step: 350, loss: 0.0058006648905575275
step: 360, loss: 0.05769111216068268
epoch 4: dev_f1=0.6700767263427111, f1=0.6122448979591836, best_f1=0.6122448979591836
step: 0, loss: 0.02349591813981533
step: 10, loss: 0.011254648678004742
step: 20, loss: 0.007325369864702225
step: 30, loss: 0.1054982990026474
step: 40, loss: 0.021623685956001282
step: 50, loss: 0.1542823165655136
step: 60, loss: 0.026309683918952942
step: 70, loss: 0.039106450974941254
step: 80, loss: 0.018243739381432533
step: 90, loss: 0.002674991264939308
step: 100, loss: 0.0263530183583498
step: 110, loss: 0.004255630541592836
step: 120, loss: 0.029288718476891518
step: 130, loss: 0.001857111812569201
step: 140, loss: 0.031623028218746185
step: 150, loss: 0.17896880209445953
step: 160, loss: 0.004820732399821281
step: 170, loss: 0.0022211717441678047
step: 180, loss: 0.006379048340022564
step: 190, loss: 0.004808569792658091
step: 200, loss: 0.045951709151268005
step: 210, loss: 0.09441918879747391
step: 220, loss: 0.002398747717961669
step: 230, loss: 0.041796013712882996
step: 240, loss: 0.02029574289917946
step: 250, loss: 0.02930673025548458
step: 260, loss: 0.008433353155851364
step: 270, loss: 0.015289160422980785
step: 280, loss: 0.00041770495590753853
step: 290, loss: 0.003629320068284869
step: 300, loss: 0.009001193568110466
step: 310, loss: 0.037238866090774536
step: 320, loss: 0.08546341210603714
step: 330, loss: 0.02558842860162258
step: 340, loss: 0.016298318281769753
step: 350, loss: 0.1359509527683258
step: 360, loss: 0.1258922666311264
epoch 5: dev_f1=0.6682808716707022, f1=0.6195121951219513, best_f1=0.6122448979591836
step: 0, loss: 0.08025377243757248
step: 10, loss: 0.0032674146350473166
step: 20, loss: 0.08050987869501114
step: 30, loss: 0.019581854343414307
step: 40, loss: 0.001519595505669713
step: 50, loss: 0.006882192566990852
step: 60, loss: 0.01614539697766304
step: 70, loss: 0.0034706168808043003
step: 80, loss: 0.0017281122272834182
step: 90, loss: 0.000513300474267453
step: 100, loss: 0.0020177385304123163
step: 110, loss: 0.00520677724853158
step: 120, loss: 0.09916388243436813
step: 130, loss: 0.0006491274107247591
step: 140, loss: 0.0007128242286853492
step: 150, loss: 0.005906540900468826
step: 160, loss: 0.0005796178593300283
step: 170, loss: 0.012049144133925438
step: 180, loss: 0.0008736547897569835
step: 190, loss: 0.0031365342438220978
step: 200, loss: 0.005492586176842451
step: 210, loss: 0.0036737818736582994
step: 220, loss: 0.0026346726808696985
step: 230, loss: 0.0022812900133430958
step: 240, loss: 0.016512565314769745
step: 250, loss: 0.014596630819141865
step: 260, loss: 0.01006249152123928
step: 270, loss: 0.0050474838353693485
step: 280, loss: 0.002011976670473814
step: 290, loss: 0.05464794486761093
step: 300, loss: 0.07558173686265945
step: 310, loss: 0.06769100576639175
step: 320, loss: 0.025631893426179886
step: 330, loss: 0.011216705664992332
step: 340, loss: 0.009988774545490742
step: 350, loss: 0.002621138235554099
step: 360, loss: 0.08607897162437439
epoch 6: dev_f1=0.6612903225806452, f1=0.6507936507936508, best_f1=0.6122448979591836
step: 0, loss: 0.009331094101071358
step: 10, loss: 0.0025525917299091816
step: 20, loss: 0.08036147058010101
step: 30, loss: 0.005303271114826202
step: 40, loss: 0.007672455627471209
step: 50, loss: 0.11675654351711273
step: 60, loss: 0.005213654134422541
step: 70, loss: 0.1385471075773239
step: 80, loss: 0.011112363077700138
step: 90, loss: 0.009504090063273907
step: 100, loss: 0.004633794073015451
step: 110, loss: 0.0007410502294078469
step: 120, loss: 0.13393929600715637
step: 130, loss: 0.022234177216887474
step: 140, loss: 0.006244617514312267
step: 150, loss: 0.0853925496339798
step: 160, loss: 0.04609385505318642
step: 170, loss: 0.14436163008213043
step: 180, loss: 0.022390903905034065
step: 190, loss: 0.006764128338545561
step: 200, loss: 0.0358784981071949
step: 210, loss: 0.0017662547761574388
step: 220, loss: 0.0034607790876179934
step: 230, loss: 0.004822938237339258
step: 240, loss: 0.03446308895945549
step: 250, loss: 0.0026133605279028416
step: 260, loss: 0.0004939349601045251
step: 270, loss: 0.0012507467763498425
step: 280, loss: 0.012204845435917377
step: 290, loss: 0.0036522885784506798
step: 300, loss: 0.0053559038788080215
step: 310, loss: 0.04931395873427391
step: 320, loss: 0.0007073034066706896
step: 330, loss: 0.005677136592566967
step: 340, loss: 0.0007671870989724994
step: 350, loss: 0.005308188498020172
step: 360, loss: 0.0006474553374573588
epoch 7: dev_f1=0.6849315068493149, f1=0.6648351648351648, best_f1=0.6648351648351648
step: 0, loss: 0.003113153390586376
step: 10, loss: 0.005317298229783773
step: 20, loss: 0.028536591678857803
step: 30, loss: 0.0071416753344237804
step: 40, loss: 0.10511258244514465
step: 50, loss: 0.0014106028247624636
step: 60, loss: 0.0005663746851496398
step: 70, loss: 0.05783881992101669
step: 80, loss: 0.042142849415540695
step: 90, loss: 0.021776625886559486
step: 100, loss: 0.0009054505499079823
step: 110, loss: 0.0019229153404012322
step: 120, loss: 0.048247091472148895
step: 130, loss: 0.013377364724874496
step: 140, loss: 0.0054290033876895905
step: 150, loss: 0.004346610512584448
step: 160, loss: 0.004137951415032148
step: 170, loss: 0.004377862438559532
step: 180, loss: 0.002675228286534548
step: 190, loss: 0.00039716571336612105
step: 200, loss: 0.008704478852450848
step: 210, loss: 0.003436699276790023
step: 220, loss: 0.0011487207375466824
step: 230, loss: 0.08442340046167374
step: 240, loss: 0.025394529104232788
step: 250, loss: 0.0020889281295239925
step: 260, loss: 0.0012510939268395305
step: 270, loss: 0.0032573645003139973
step: 280, loss: 0.0005184608744457364
step: 290, loss: 0.14367930591106415
step: 300, loss: 0.007282277103513479
step: 310, loss: 0.0013641963014379144
step: 320, loss: 0.0023927753791213036
step: 330, loss: 0.0042237029410898685
step: 340, loss: 0.006406764965504408
step: 350, loss: 0.001166311907581985
step: 360, loss: 0.0007777505088597536
epoch 8: dev_f1=0.676470588235294, f1=0.6473429951690821, best_f1=0.6648351648351648
step: 0, loss: 0.00114379171282053
step: 10, loss: 0.004157810006290674
step: 20, loss: 0.00011411936429794878
step: 30, loss: 0.0011187581112608314
step: 40, loss: 0.0022606367710977793
step: 50, loss: 0.0032871670555323362
step: 60, loss: 0.008274411782622337
step: 70, loss: 0.03380235657095909
step: 80, loss: 0.07088236510753632
step: 90, loss: 0.0003393855004105717
step: 100, loss: 0.0178265031427145
step: 110, loss: 0.05704541504383087
step: 120, loss: 0.0005357430200092494
step: 130, loss: 0.053075969219207764
step: 140, loss: 0.00468610692769289
step: 150, loss: 0.22721825540065765
step: 160, loss: 0.4034643769264221
step: 170, loss: 0.008012395352125168
step: 180, loss: 0.003118018852546811
step: 190, loss: 0.0007130870362743735
step: 200, loss: 0.013907607644796371
step: 210, loss: 0.002297478960826993
step: 220, loss: 0.009235699661076069
step: 230, loss: 0.0009360744734294713
step: 240, loss: 0.0007136043859645724
step: 250, loss: 0.0007711631478741765
step: 260, loss: 0.0035501085221767426
step: 270, loss: 0.0005083539290353656
step: 280, loss: 0.0009081429452635348
step: 290, loss: 0.0013165358686819673
step: 300, loss: 0.010622759349644184
step: 310, loss: 0.013799818232655525
step: 320, loss: 0.005393119994550943
step: 330, loss: 0.0005965656600892544
step: 340, loss: 0.010683408938348293
step: 350, loss: 0.010092135518789291
step: 360, loss: 0.05126582458615303
epoch 9: dev_f1=0.6321525885558583, f1=0.6361185983827492, best_f1=0.6648351648351648
step: 0, loss: 0.0003052746469620615
step: 10, loss: 0.0008412405732087791
step: 20, loss: 0.00255645252764225
step: 30, loss: 0.0011639527510851622
step: 40, loss: 0.009493891149759293
step: 50, loss: 0.0002125521277775988
step: 60, loss: 0.000445212353952229
step: 70, loss: 0.0001608994061825797
step: 80, loss: 0.00015122548211365938
step: 90, loss: 0.003699950408190489
step: 100, loss: 0.0038960850797593594
step: 110, loss: 0.007204309571534395
step: 120, loss: 0.0010778382420539856
step: 130, loss: 0.08084283024072647
step: 140, loss: 0.0008081304840743542
step: 150, loss: 0.003134628525003791
step: 160, loss: 0.005170593969523907
step: 170, loss: 0.00017781995120458305
step: 180, loss: 0.001124837319366634
step: 190, loss: 0.0007453736034221947
step: 200, loss: 0.0007261068094521761
step: 210, loss: 0.006517586298286915
step: 220, loss: 0.002293971134349704
step: 230, loss: 0.00014038731751497835
step: 240, loss: 0.00015664417878724635
step: 250, loss: 0.0007848244276829064
step: 260, loss: 0.0009132393752224743
step: 270, loss: 0.0215131938457489
step: 280, loss: 0.004751001484692097
step: 290, loss: 0.0018946956843137741
step: 300, loss: 0.0006790244951844215
step: 310, loss: 0.002217487897723913
step: 320, loss: 0.01179658155888319
step: 330, loss: 0.04022641479969025
step: 340, loss: 0.004743771627545357
step: 350, loss: 8.472672925563529e-05
step: 360, loss: 0.0005784930544905365
epoch 10: dev_f1=0.6568627450980393, f1=0.6356968215158925, best_f1=0.6648351648351648
step: 0, loss: 0.0017910597380250692
step: 10, loss: 0.005580831319093704
step: 20, loss: 0.0017666234634816647
step: 30, loss: 0.0003067305951844901
step: 40, loss: 0.00012168445391580462
step: 50, loss: 0.00014669602387584746
step: 60, loss: 0.0011441265232861042
step: 70, loss: 0.00047450565034523606
step: 80, loss: 0.028552116826176643
step: 90, loss: 0.005133161321282387
step: 100, loss: 0.0011743860086426139
step: 110, loss: 0.003600033698603511
step: 120, loss: 0.00145219755358994
step: 130, loss: 0.0001389040262438357
step: 140, loss: 0.014237986877560616
step: 150, loss: 0.0010972463060170412
step: 160, loss: 7.653726061107591e-05
step: 170, loss: 0.00024941639276221395
step: 180, loss: 0.00020009798754472286
step: 190, loss: 0.05358210578560829
step: 200, loss: 0.00732650700956583
step: 210, loss: 0.0001086204283637926
step: 220, loss: 0.0032246101181954145
step: 230, loss: 0.00011633080430328846
step: 240, loss: 0.18623752892017365
step: 250, loss: 0.0010783910984173417
step: 260, loss: 0.0006374611984938383
step: 270, loss: 0.05670885369181633
step: 280, loss: 0.11864016950130463
step: 290, loss: 0.0017278512241318822
step: 300, loss: 0.05191590636968613
step: 310, loss: 0.0301573034375906
step: 320, loss: 0.000503647665027529
step: 330, loss: 0.0016798387514427304
step: 340, loss: 0.000565286201890558
step: 350, loss: 0.018221011385321617
step: 360, loss: 0.0009587149834260345
epoch 11: dev_f1=0.6618357487922706, f1=0.6486486486486486, best_f1=0.6648351648351648
step: 0, loss: 0.0022223370615392923
step: 10, loss: 0.0023384580854326487
step: 20, loss: 0.00046241871314123273
step: 30, loss: 8.970506314653903e-05
step: 40, loss: 0.0005629367660731077
step: 50, loss: 8.123899169731885e-05
step: 60, loss: 0.00370209407992661
step: 70, loss: 0.002242038492113352
step: 80, loss: 0.0003403677837923169
step: 90, loss: 0.005003068596124649
step: 100, loss: 0.014908159151673317
step: 110, loss: 0.00034272726043127477
step: 120, loss: 0.00016705994494259357
step: 130, loss: 0.0005982040893286467
step: 140, loss: 0.0052245971746742725
step: 150, loss: 0.00011450516467448324
step: 160, loss: 0.000645954511128366
step: 170, loss: 0.00040193088352680206
step: 180, loss: 0.0004251215432304889
step: 190, loss: 0.00035721491440199316
step: 200, loss: 0.0062386346980929375
step: 210, loss: 0.00011380656360415742
step: 220, loss: 0.0002182314492529258
step: 230, loss: 0.00025019070017151535
step: 240, loss: 0.00011880688543897122
step: 250, loss: 0.00022900717158336192
step: 260, loss: 0.0007084301323629916
step: 270, loss: 0.000698012881912291
step: 280, loss: 0.00012890479410998523
step: 290, loss: 0.0004055586759932339
step: 300, loss: 7.136876956792548e-05
step: 310, loss: 0.0006858506239950657
step: 320, loss: 0.0014347406104207039
step: 330, loss: 0.005740712396800518
step: 340, loss: 0.0005458562518469989
step: 350, loss: 0.00010714541713241488
step: 360, loss: 0.015433953143656254
epoch 12: dev_f1=0.6261398176291793, f1=0.6213017751479291, best_f1=0.6648351648351648
step: 0, loss: 0.00028797294362448156
step: 10, loss: 0.0002467705635353923
step: 20, loss: 0.11068526655435562
step: 30, loss: 0.0002445611171424389
step: 40, loss: 0.00015269475989043713
step: 50, loss: 0.0007221929845400155
step: 60, loss: 0.0002243723429273814
step: 70, loss: 0.00061172986170277
step: 80, loss: 0.0004435623995959759
step: 90, loss: 0.0021647715475410223
step: 100, loss: 0.0004943638341501355
step: 110, loss: 0.0003143967769574374
step: 120, loss: 0.00026346908998675644
step: 130, loss: 0.002215628745034337
step: 140, loss: 0.00042653409764170647
step: 150, loss: 0.00042760794167406857
step: 160, loss: 0.00390396430157125
step: 170, loss: 0.0011697504669427872
step: 180, loss: 0.00014505855506286025
step: 190, loss: 0.0006953084957785904
step: 200, loss: 7.401290349662304e-05
step: 210, loss: 7.877213647589087e-05
step: 220, loss: 0.0019909210968762636
step: 230, loss: 0.0017539090476930141
step: 240, loss: 0.0002126582694472745
step: 250, loss: 0.0029030009172856808
step: 260, loss: 0.0006473532994277775
step: 270, loss: 8.541416173102334e-05
step: 280, loss: 0.0023426187690347433
step: 290, loss: 0.0012334316270425916
step: 300, loss: 0.002476664027199149
step: 310, loss: 0.0005166535847820342
step: 320, loss: 9.712434984976426e-05
step: 330, loss: 0.001414313679561019
step: 340, loss: 0.0003966036019846797
step: 350, loss: 0.00016249464533757418
step: 360, loss: 0.0017375550232827663
epoch 13: dev_f1=0.6595744680851063, f1=0.6402116402116402, best_f1=0.6648351648351648
step: 0, loss: 0.0001761696330504492
step: 10, loss: 0.0004454512381926179
step: 20, loss: 0.0005419122171588242
step: 30, loss: 5.243156920187175e-05
step: 40, loss: 0.0002526623720768839
step: 50, loss: 0.00026212853845208883
step: 60, loss: 0.0006037363782525063
step: 70, loss: 0.005436402279883623
step: 80, loss: 0.00384338921867311
step: 90, loss: 0.0011041704565286636
step: 100, loss: 6.878862041048706e-05
step: 110, loss: 0.000684513186570257
step: 120, loss: 8.696103031979874e-05
step: 130, loss: 0.0013232295168563724
step: 140, loss: 0.0004535519110504538
step: 150, loss: 0.00044589737080968916
step: 160, loss: 0.000388656830182299
step: 170, loss: 0.0020964101422578096
step: 180, loss: 0.0028878238517791033
step: 190, loss: 0.024949118494987488
step: 200, loss: 0.00012325130228418857
step: 210, loss: 7.751941302558407e-05
step: 220, loss: 0.00017281333566643298
step: 230, loss: 0.00011259346501901746
step: 240, loss: 0.00010765437764348462
step: 250, loss: 3.3212912967428565e-05
step: 260, loss: 0.00020490761380642653
step: 270, loss: 0.0006471459637396038
step: 280, loss: 0.001088799792341888
step: 290, loss: 0.00011303991777822375
step: 300, loss: 0.00033444195287302136
step: 310, loss: 0.00014351477148011327
step: 320, loss: 0.0010431366972625256
step: 330, loss: 0.0005062113050371408
step: 340, loss: 0.000592449854593724
step: 350, loss: 0.00154207949526608
step: 360, loss: 0.009587230160832405
epoch 14: dev_f1=0.6376021798365122, f1=0.6321525885558583, best_f1=0.6648351648351648
step: 0, loss: 0.00022466042719315737
step: 10, loss: 0.0005696968291886151
step: 20, loss: 0.00031106366077437997
step: 30, loss: 0.00012549982056953013
step: 40, loss: 4.276651088730432e-05
step: 50, loss: 8.175710536306724e-05
step: 60, loss: 5.086844612378627e-05
step: 70, loss: 0.00011275401629973203
step: 80, loss: 0.000406255858251825
step: 90, loss: 9.799248800845817e-05
step: 100, loss: 7.595794886583462e-05
step: 110, loss: 0.00020175297686364502
step: 120, loss: 0.03246424347162247
step: 130, loss: 0.0004000432090833783
step: 140, loss: 0.001196661381982267
step: 150, loss: 0.001277139876037836
step: 160, loss: 0.0005503511056303978
step: 170, loss: 0.00014557431859429926
step: 180, loss: 6.508455408038571e-05
step: 190, loss: 7.352843385888264e-05
step: 200, loss: 0.003619522089138627
step: 210, loss: 0.00016568282444495708
step: 220, loss: 0.00040946007356978953
step: 230, loss: 5.1086011808365583e-05
step: 240, loss: 0.0003046966448891908
step: 250, loss: 0.00011626342893578112
step: 260, loss: 3.311660111648962e-05
step: 270, loss: 0.00010095361358253285
step: 280, loss: 9.843582665780559e-05
step: 290, loss: 0.00013281372957862914
step: 300, loss: 0.0127731217071414
step: 310, loss: 0.0005284412764012814
step: 320, loss: 5.216585486778058e-05
step: 330, loss: 0.00011071217159042135
step: 340, loss: 0.00012024010356981307
step: 350, loss: 0.026344871148467064
step: 360, loss: 0.14022885262966156
epoch 15: dev_f1=0.6649616368286445, f1=0.625, best_f1=0.6648351648351648
step: 0, loss: 0.02478325366973877
step: 10, loss: 0.00025918491883203387
step: 20, loss: 0.005394829902797937
step: 30, loss: 0.006223031785339117
step: 40, loss: 0.00041231102659367025
step: 50, loss: 4.491519939620048e-05
step: 60, loss: 0.003936569206416607
step: 70, loss: 0.0002140494907507673
step: 80, loss: 0.0014915079809725285
step: 90, loss: 5.531058195629157e-05
step: 100, loss: 0.00023338723985943943
step: 110, loss: 0.07715307921171188
step: 120, loss: 0.0014786660904064775
step: 130, loss: 0.00042185356141999364
step: 140, loss: 0.000287489325273782
step: 150, loss: 0.009683063253760338
step: 160, loss: 4.485950557864271e-05
step: 170, loss: 0.0033634051214903593
step: 180, loss: 3.147419192828238e-05
step: 190, loss: 0.00010366875358158723
step: 200, loss: 4.3598065531114116e-05
step: 210, loss: 0.0004604885762091726
step: 220, loss: 2.3769978724885732e-05
step: 230, loss: 3.5087039577774704e-05
step: 240, loss: 0.0008858414366841316
step: 250, loss: 0.0011680724564939737
step: 260, loss: 0.0012765292776748538
step: 270, loss: 0.0003288071311544627
step: 280, loss: 5.715099541703239e-05
step: 290, loss: 0.00015756818174850196
step: 300, loss: 3.438245039433241e-05
step: 310, loss: 5.3656174713978544e-05
step: 320, loss: 0.00019981098012067378
step: 330, loss: 0.0005119545385241508
step: 340, loss: 3.359629408805631e-05
step: 350, loss: 8.677618461661041e-05
step: 360, loss: 0.00011990351777058095
epoch 16: dev_f1=0.6547314578005116, f1=0.6315789473684211, best_f1=0.6648351648351648
step: 0, loss: 7.433883001795039e-05
step: 10, loss: 0.00021126196952536702
step: 20, loss: 3.734336496563628e-05
step: 30, loss: 0.000180956136318855
step: 40, loss: 0.06909352540969849
step: 50, loss: 9.457427222514525e-05
step: 60, loss: 2.616195888549555e-05
step: 70, loss: 0.00010535649198573083
step: 80, loss: 0.002478586044162512
step: 90, loss: 0.000841262866742909
step: 100, loss: 5.172429882804863e-05
step: 110, loss: 8.570688805775717e-05
step: 120, loss: 0.0001233553484780714
step: 130, loss: 0.00042987478082068264
step: 140, loss: 2.586390110081993e-05
step: 150, loss: 3.7273010093485937e-05
step: 160, loss: 0.00011278688907623291
step: 170, loss: 0.03031257353723049
step: 180, loss: 6.895238038850948e-05
step: 190, loss: 0.0011525668669492006
step: 200, loss: 0.00010067965922644362
step: 210, loss: 5.7831966842059046e-05
step: 220, loss: 8.104600419756025e-05
step: 230, loss: 5.816581688122824e-05
step: 240, loss: 0.00022601084492634982
step: 250, loss: 0.00015792014892213047
step: 260, loss: 8.558029367122799e-05
step: 270, loss: 0.01992861181497574
step: 280, loss: 6.425493484130129e-05
step: 290, loss: 0.0013986837584525347
step: 300, loss: 3.203105734428391e-05
step: 310, loss: 0.00038942377432249486
step: 320, loss: 0.00017858031787909567
step: 330, loss: 0.0006470174412243068
step: 340, loss: 0.002277346793562174
step: 350, loss: 4.7880414058454335e-05
step: 360, loss: 0.011209037154912949
epoch 17: dev_f1=0.6632124352331606, f1=0.6278481012658227, best_f1=0.6648351648351648
step: 0, loss: 0.00031146229594014585
step: 10, loss: 0.0003273657348472625
step: 20, loss: 0.0003853589005302638
step: 30, loss: 0.0024070132058113813
step: 40, loss: 2.6835588869289495e-05
step: 50, loss: 3.1304440199164674e-05
step: 60, loss: 2.7413032512413338e-05
step: 70, loss: 5.675059219356626e-05
step: 80, loss: 5.07730946992524e-05
step: 90, loss: 4.6841316361678764e-05
step: 100, loss: 0.0002490064362064004
step: 110, loss: 0.00793137401342392
step: 120, loss: 3.5660465073306113e-05
step: 130, loss: 0.0003378693654667586
step: 140, loss: 4.470485873753205e-05
step: 150, loss: 0.026644354686141014
step: 160, loss: 2.965159001178108e-05
step: 170, loss: 0.0002476766530890018
step: 180, loss: 4.0590086427982897e-05
step: 190, loss: 0.001807212014682591
step: 200, loss: 6.793472857680172e-05
step: 210, loss: 9.80534459813498e-05
step: 220, loss: 4.3748135794885457e-05
step: 230, loss: 0.00026392212021164596
step: 240, loss: 1.9192306353943422e-05
step: 250, loss: 0.0008286931551992893
step: 260, loss: 3.5522065445547923e-05
step: 270, loss: 0.0005100065027363598
step: 280, loss: 6.878599378978834e-05
step: 290, loss: 4.1053459426620975e-05
step: 300, loss: 0.00018916591943707317
step: 310, loss: 6.92268367856741e-05
step: 320, loss: 0.00022640771931037307
step: 330, loss: 2.4869314074749127e-05
step: 340, loss: 0.00027344413683749735
step: 350, loss: 3.74316077795811e-05
step: 360, loss: 0.00010168542212340981
epoch 18: dev_f1=0.6700251889168766, f1=0.6570048309178744, best_f1=0.6648351648351648
step: 0, loss: 8.661887841299176e-05
step: 10, loss: 0.0001383478956995532
step: 20, loss: 0.00015125449863262475
step: 30, loss: 0.0001468945265514776
step: 40, loss: 0.0001665750314714387
step: 50, loss: 0.00020231938106007874
step: 60, loss: 0.0006066774949431419
step: 70, loss: 0.00011763490329030901
step: 80, loss: 8.625900227343664e-05
step: 90, loss: 0.00024662737268954515
step: 100, loss: 0.0016255751252174377
step: 110, loss: 3.766048757825047e-05
step: 120, loss: 0.00041073234751820564
step: 130, loss: 9.119934111367911e-05
step: 140, loss: 6.68803186272271e-05
step: 150, loss: 0.00021215365268290043
step: 160, loss: 0.000246167357545346
step: 170, loss: 5.91530479141511e-05
step: 180, loss: 0.00012826191959902644
step: 190, loss: 0.0004356540448497981
step: 200, loss: 4.2743828089442104e-05
step: 210, loss: 2.172526001231745e-05
step: 220, loss: 0.00022572907619178295
step: 230, loss: 3.282189936726354e-05
step: 240, loss: 0.00016293559747282416
step: 250, loss: 0.00010338402353227139
step: 260, loss: 4.901815191260539e-05
step: 270, loss: 0.00012117018923163414
step: 280, loss: 0.00010498051415197551
step: 290, loss: 0.00015760576934553683
step: 300, loss: 0.00040575515595264733
step: 310, loss: 4.832347985939123e-05
step: 320, loss: 0.0004118893120903522
step: 330, loss: 6.051531818229705e-05
step: 340, loss: 4.45881778432522e-05
step: 350, loss: 9.16494318516925e-05
step: 360, loss: 0.0001068175261025317
epoch 19: dev_f1=0.6666666666666667, f1=0.6263736263736264, best_f1=0.6648351648351648
step: 0, loss: 9.194052108796313e-05
step: 10, loss: 5.3095493058208376e-05
step: 20, loss: 0.0004137171199545264
step: 30, loss: 0.00013009351096116006
step: 40, loss: 5.4251479014055803e-05
step: 50, loss: 0.00017162268341053277
step: 60, loss: 4.238341352902353e-05
step: 70, loss: 0.025153877213597298
step: 80, loss: 3.63070321327541e-05
step: 90, loss: 0.00012811129272449762
step: 100, loss: 9.538652375340462e-05
step: 110, loss: 7.505843677790835e-05
step: 120, loss: 4.287849151296541e-05
step: 130, loss: 9.371706255478784e-05
step: 140, loss: 4.733422247227281e-05
step: 150, loss: 0.00027274477179162204
step: 160, loss: 0.0004676172393374145
step: 170, loss: 0.0003568962565623224
step: 180, loss: 0.00011215310951229185
step: 190, loss: 0.0027229678817093372
step: 200, loss: 4.858676402363926e-05
step: 210, loss: 2.7408777896198444e-05
step: 220, loss: 4.733151581604034e-05
step: 230, loss: 4.978013748768717e-05
step: 240, loss: 5.485086876433343e-05
step: 250, loss: 5.0473456212785095e-05
step: 260, loss: 5.833019531564787e-05
step: 270, loss: 4.045375681016594e-05
step: 280, loss: 0.00011663924669846892
step: 290, loss: 5.475096986629069e-05
step: 300, loss: 8.455760689685121e-05
step: 310, loss: 8.508044993504882e-05
step: 320, loss: 5.93383374507539e-05
step: 330, loss: 2.275288716191426e-05
step: 340, loss: 0.00024058907001744956
step: 350, loss: 5.315408270689659e-05
step: 360, loss: 0.00022302704746834934
epoch 20: dev_f1=0.668555240793201, f1=0.6162464985994398, best_f1=0.6648351648351648
