cuda
Device: cuda
step: 0, loss: 0.6386885046958923
step: 10, loss: 0.37443965673446655
step: 20, loss: 0.36679306626319885
step: 30, loss: 0.0394127257168293
step: 40, loss: 0.3071601688861847
step: 50, loss: 0.1366567611694336
step: 60, loss: 0.44925376772880554
step: 70, loss: 0.30881884694099426
step: 80, loss: 0.22284568846225739
step: 90, loss: 0.11804914474487305
step: 100, loss: 0.14156638085842133
step: 110, loss: 0.44490087032318115
step: 120, loss: 0.2955045998096466
step: 130, loss: 0.2888592481613159
step: 140, loss: 0.12903566658496857
step: 150, loss: 0.2589382529258728
step: 160, loss: 0.26521793007850647
step: 170, loss: 0.0917515903711319
step: 180, loss: 0.17775288224220276
step: 190, loss: 0.1385488510131836
step: 200, loss: 0.15097735822200775
step: 210, loss: 0.1731085479259491
step: 220, loss: 0.061464495956897736
step: 230, loss: 0.14242298901081085
step: 240, loss: 0.25297385454177856
step: 250, loss: 0.16699810326099396
step: 260, loss: 0.2097046822309494
step: 270, loss: 0.08237903565168381
step: 280, loss: 0.18824502825737
step: 290, loss: 0.09360677003860474
step: 300, loss: 0.14318571984767914
step: 310, loss: 0.060537729412317276
step: 320, loss: 0.08679412305355072
step: 330, loss: 0.02474001608788967
step: 340, loss: 0.040024422109127045
step: 350, loss: 0.05797272548079491
step: 360, loss: 0.14423134922981262
epoch 1: dev_f1=0.6173469387755103, f1=0.6279683377308707, best_f1=0.6279683377308707
step: 0, loss: 0.06316746771335602
step: 10, loss: 0.1122010201215744
step: 20, loss: 0.17444904148578644
step: 30, loss: 0.0634477436542511
step: 40, loss: 0.061546750366687775
step: 50, loss: 0.25794368982315063
step: 60, loss: 0.1286984086036682
step: 70, loss: 0.42976322770118713
step: 80, loss: 0.06630291789770126
step: 90, loss: 0.0416744127869606
step: 100, loss: 0.0037008465733379126
step: 110, loss: 0.08013521879911423
step: 120, loss: 0.07149333506822586
step: 130, loss: 0.002095007337629795
step: 140, loss: 0.1545483022928238
step: 150, loss: 0.0720900148153305
step: 160, loss: 0.08083798736333847
step: 170, loss: 0.03842606768012047
step: 180, loss: 0.045841656625270844
step: 190, loss: 0.16940633952617645
step: 200, loss: 0.05067219212651253
step: 210, loss: 0.12713447213172913
step: 220, loss: 0.19453942775726318
step: 230, loss: 0.004396115895360708
step: 240, loss: 0.009286856278777122
step: 250, loss: 0.05875493213534355
step: 260, loss: 0.028627358376979828
step: 270, loss: 0.1053912565112114
step: 280, loss: 0.06245924159884453
step: 290, loss: 0.158063605427742
step: 300, loss: 0.006775264162570238
step: 310, loss: 0.035207439213991165
step: 320, loss: 0.12258019298315048
step: 330, loss: 0.29925885796546936
step: 340, loss: 0.12391461431980133
step: 350, loss: 0.15615728497505188
step: 360, loss: 0.07128477841615677
epoch 2: dev_f1=0.6602409638554216, f1=0.6292682926829267, best_f1=0.6292682926829267
step: 0, loss: 0.004729501437395811
step: 10, loss: 0.012896490283310413
step: 20, loss: 0.11441686749458313
step: 30, loss: 0.06680363416671753
step: 40, loss: 0.05710839107632637
step: 50, loss: 0.09232939034700394
step: 60, loss: 0.3239549696445465
step: 70, loss: 0.08217127621173859
step: 80, loss: 0.12804390490055084
step: 90, loss: 0.025572795420885086
step: 100, loss: 0.0450034961104393
step: 110, loss: 0.06488151848316193
step: 120, loss: 0.04731089621782303
step: 130, loss: 0.05195333808660507
step: 140, loss: 0.005930458195507526
step: 150, loss: 0.12052290141582489
step: 160, loss: 0.020622150972485542
step: 170, loss: 0.07580067217350006
step: 180, loss: 0.014485190622508526
step: 190, loss: 0.098786860704422
step: 200, loss: 0.13877704739570618
step: 210, loss: 0.11789824068546295
step: 220, loss: 0.004177509807050228
step: 230, loss: 0.09080816805362701
step: 240, loss: 0.09421201050281525
step: 250, loss: 0.20345239341259003
step: 260, loss: 0.006189570762217045
step: 270, loss: 0.013213287107646465
step: 280, loss: 0.03294578567147255
step: 290, loss: 0.019388560205698013
step: 300, loss: 0.09604205936193466
step: 310, loss: 0.04165508970618248
step: 320, loss: 0.015523823909461498
step: 330, loss: 0.0033512189984321594
step: 340, loss: 0.07262348383665085
step: 350, loss: 0.03263036161661148
step: 360, loss: 0.09246532618999481
epoch 3: dev_f1=0.6898263027295285, f1=0.6582914572864322, best_f1=0.6582914572864322
step: 0, loss: 0.02800009213387966
step: 10, loss: 0.05056547373533249
step: 20, loss: 0.07778891175985336
step: 30, loss: 0.030048053711652756
step: 40, loss: 0.008941763080656528
step: 50, loss: 0.049441877752542496
step: 60, loss: 0.016472365707159042
step: 70, loss: 0.042598407715559006
step: 80, loss: 0.015680808573961258
step: 90, loss: 0.030690312385559082
step: 100, loss: 0.06085957959294319
step: 110, loss: 0.0175616517663002
step: 120, loss: 0.022424809634685516
step: 130, loss: 0.1593260020017624
step: 140, loss: 0.10641314834356308
step: 150, loss: 0.0038638366386294365
step: 160, loss: 0.01355996448546648
step: 170, loss: 0.15420812368392944
step: 180, loss: 0.02825331687927246
step: 190, loss: 0.03194358944892883
step: 200, loss: 0.029455840587615967
step: 210, loss: 0.14472414553165436
step: 220, loss: 0.0629519373178482
step: 230, loss: 0.0010821992764249444
step: 240, loss: 0.011074835434556007
step: 250, loss: 0.007178817875683308
step: 260, loss: 0.012336861342191696
step: 270, loss: 0.0021034704986959696
step: 280, loss: 0.011455902829766273
step: 290, loss: 0.0030521133448928595
step: 300, loss: 0.05040004476904869
step: 310, loss: 0.04687514528632164
step: 320, loss: 0.005615046247839928
step: 330, loss: 0.0012271913001313806
step: 340, loss: 0.019943634048104286
step: 350, loss: 0.001988983014598489
step: 360, loss: 0.008042716421186924
epoch 4: dev_f1=0.7049608355091384, f1=0.645320197044335, best_f1=0.645320197044335
step: 0, loss: 0.0007796403951942921
step: 10, loss: 0.18416190147399902
step: 20, loss: 0.0074325609020888805
step: 30, loss: 0.01247452013194561
step: 40, loss: 0.003225331660360098
step: 50, loss: 0.07300375401973724
step: 60, loss: 0.0466117262840271
step: 70, loss: 0.010694519616663456
step: 80, loss: 0.006341786123812199
step: 90, loss: 0.002266102936118841
step: 100, loss: 0.05307486280798912
step: 110, loss: 0.0734778344631195
step: 120, loss: 0.08324790745973587
step: 130, loss: 0.013861329294741154
step: 140, loss: 0.0984487235546112
step: 150, loss: 0.009401372633874416
step: 160, loss: 0.01197244506329298
step: 170, loss: 0.06113174930214882
step: 180, loss: 0.0031354082748293877
step: 190, loss: 0.0035066783893853426
step: 200, loss: 0.0017583444714546204
step: 210, loss: 0.015646936371922493
step: 220, loss: 0.013241605833172798
step: 230, loss: 0.018611902371048927
step: 240, loss: 0.0952225998044014
step: 250, loss: 0.00458058575168252
step: 260, loss: 0.0022634139750152826
step: 270, loss: 0.03030719794332981
step: 280, loss: 0.002684165257960558
step: 290, loss: 0.02550388313829899
step: 300, loss: 0.011116961017251015
step: 310, loss: 0.01632828265428543
step: 320, loss: 0.01160486787557602
step: 330, loss: 0.01171337440609932
step: 340, loss: 0.009227713569998741
step: 350, loss: 0.01785285584628582
step: 360, loss: 0.020054593682289124
epoch 5: dev_f1=0.7229551451187335, f1=0.6805194805194804, best_f1=0.6805194805194804
step: 0, loss: 0.00986234936863184
step: 10, loss: 0.02225564233958721
step: 20, loss: 0.08383501321077347
step: 30, loss: 0.005422553978860378
step: 40, loss: 0.07496122270822525
step: 50, loss: 0.01256770920008421
step: 60, loss: 0.007077460642904043
step: 70, loss: 0.03911355882883072
step: 80, loss: 0.006699482910335064
step: 90, loss: 0.009004390798509121
step: 100, loss: 0.016538076102733612
step: 110, loss: 0.0028720854315906763
step: 120, loss: 0.0013513336889445782
step: 130, loss: 0.0054080006666481495
step: 140, loss: 0.05741192772984505
step: 150, loss: 0.0023303532507270575
step: 160, loss: 0.001152890850789845
step: 170, loss: 0.023506835103034973
step: 180, loss: 0.056702129542827606
step: 190, loss: 0.0008794172899797559
step: 200, loss: 0.06399369239807129
step: 210, loss: 0.0008293226128444076
step: 220, loss: 0.0020459420047700405
step: 230, loss: 0.0047447578981518745
step: 240, loss: 0.00039162213215604424
step: 250, loss: 0.0030318817589432
step: 260, loss: 0.00275509525090456
step: 270, loss: 0.00022304563026409596
step: 280, loss: 0.0005283316713757813
step: 290, loss: 0.0028515299782156944
step: 300, loss: 0.009128277190029621
step: 310, loss: 0.0006735425558872521
step: 320, loss: 0.004578942432999611
step: 330, loss: 0.027559449896216393
step: 340, loss: 0.15827973186969757
step: 350, loss: 0.06330433487892151
step: 360, loss: 0.0015747868455946445
epoch 6: dev_f1=0.7109974424552431, f1=0.6682926829268292, best_f1=0.6805194805194804
step: 0, loss: 0.03665153682231903
step: 10, loss: 0.03306322917342186
step: 20, loss: 0.0047829835675656796
step: 30, loss: 0.019198209047317505
step: 40, loss: 0.0006437643896788359
step: 50, loss: 0.0039063869044184685
step: 60, loss: 0.0005768800037913024
step: 70, loss: 0.0013451740378513932
step: 80, loss: 0.00934921856969595
step: 90, loss: 0.008107997477054596
step: 100, loss: 0.0026665295008569956
step: 110, loss: 0.0029843493830412626
step: 120, loss: 0.0004226642195135355
step: 130, loss: 0.0004168290179222822
step: 140, loss: 0.00021350687893573195
step: 150, loss: 0.0004185377329122275
step: 160, loss: 0.007101436611264944
step: 170, loss: 0.0009836924728006124
step: 180, loss: 0.007511487230658531
step: 190, loss: 0.010026617906987667
step: 200, loss: 0.0829460397362709
step: 210, loss: 0.05078871548175812
step: 220, loss: 0.0011437677312642336
step: 230, loss: 0.027513207867741585
step: 240, loss: 0.01610403135418892
step: 250, loss: 0.0011433454928919673
step: 260, loss: 0.00038144041900523007
step: 270, loss: 0.02382202073931694
step: 280, loss: 0.0009847665205597878
step: 290, loss: 0.005179878324270248
step: 300, loss: 0.013964202255010605
step: 310, loss: 0.0932348445057869
step: 320, loss: 0.005951664410531521
step: 330, loss: 0.003458817023783922
step: 340, loss: 0.023477137088775635
step: 350, loss: 0.02168526127934456
step: 360, loss: 0.011924677528440952
epoch 7: dev_f1=0.6914285714285714, f1=0.6465753424657535, best_f1=0.6805194805194804
step: 0, loss: 0.012499538250267506
step: 10, loss: 0.0013822318287566304
step: 20, loss: 0.009586198255419731
step: 30, loss: 0.008589524775743484
step: 40, loss: 0.0007833041017875075
step: 50, loss: 0.0033528506755828857
step: 60, loss: 0.0007044666563160717
step: 70, loss: 0.00011704715143423527
step: 80, loss: 0.0007490295683965087
step: 90, loss: 0.0027282889932394028
step: 100, loss: 0.0013338662683963776
step: 110, loss: 0.0015426967293024063
step: 120, loss: 0.017797118052840233
step: 130, loss: 0.0002410219021840021
step: 140, loss: 0.020990705117583275
step: 150, loss: 0.017895454540848732
step: 160, loss: 0.002993461210280657
step: 170, loss: 0.012488779611885548
step: 180, loss: 0.0013098203344270587
step: 190, loss: 0.0007654511136934161
step: 200, loss: 0.06654150784015656
step: 210, loss: 0.0011254195123910904
step: 220, loss: 0.0006399010890163481
step: 230, loss: 0.00039938653935678303
step: 240, loss: 0.001547476975247264
step: 250, loss: 0.005704123992472887
step: 260, loss: 0.004920815117657185
step: 270, loss: 0.000943898456171155
step: 280, loss: 0.008324334397912025
step: 290, loss: 0.0017791575519368052
step: 300, loss: 0.003047686070203781
step: 310, loss: 0.0016557180788367987
step: 320, loss: 0.006193873472511768
step: 330, loss: 0.0010644769063219428
step: 340, loss: 0.049424514174461365
step: 350, loss: 0.0011143061565235257
step: 360, loss: 0.005949834827333689
epoch 8: dev_f1=0.6492753623188405, f1=0.6300578034682082, best_f1=0.6805194805194804
step: 0, loss: 0.0613778680562973
step: 10, loss: 0.00038687471533194184
step: 20, loss: 0.004362205509096384
step: 30, loss: 0.026825690641999245
step: 40, loss: 0.0005729370750486851
step: 50, loss: 0.027581071481108665
step: 60, loss: 0.0013785518240183592
step: 70, loss: 0.04967839643359184
step: 80, loss: 0.002883709967136383
step: 90, loss: 0.000302759901387617
step: 100, loss: 0.025303365662693977
step: 110, loss: 0.00014742414350621402
step: 120, loss: 9.110875544138253e-05
step: 130, loss: 0.0002584210014902055
step: 140, loss: 0.0003426849143579602
step: 150, loss: 0.021348224952816963
step: 160, loss: 0.00223577581346035
step: 170, loss: 0.007775638718158007
step: 180, loss: 0.0026328677777200937
step: 190, loss: 0.025043761357665062
step: 200, loss: 0.0016763423336669803
step: 210, loss: 0.000170831466675736
step: 220, loss: 0.00031885801581665874
step: 230, loss: 0.00020545133156701922
step: 240, loss: 0.00012147110828664154
step: 250, loss: 0.02820560149848461
step: 260, loss: 0.00016679226246196777
step: 270, loss: 0.03780585899949074
step: 280, loss: 0.024451889097690582
step: 290, loss: 0.0073217055760324
step: 300, loss: 0.00016409896488767117
step: 310, loss: 0.0010677659884095192
step: 320, loss: 0.00012883883027825505
step: 330, loss: 0.017984412610530853
step: 340, loss: 0.22502318024635315
step: 350, loss: 0.010917521081864834
step: 360, loss: 0.006792055442929268
epoch 9: dev_f1=0.6906077348066297, f1=0.6502732240437159, best_f1=0.6805194805194804
step: 0, loss: 0.00011239138257224113
step: 10, loss: 0.00019571241864468902
step: 20, loss: 0.00021056385594420135
step: 30, loss: 0.00031078478787094355
step: 40, loss: 0.0003678685170598328
step: 50, loss: 0.0006322823464870453
step: 60, loss: 0.05078379809856415
step: 70, loss: 0.00029375197482295334
step: 80, loss: 0.005121512804180384
step: 90, loss: 0.0004951980081386864
step: 100, loss: 0.0005771698197349906
step: 110, loss: 0.00032617623219266534
step: 120, loss: 0.03202081099152565
step: 130, loss: 0.009021023288369179
step: 140, loss: 0.0002332394797122106
step: 150, loss: 0.003132118610665202
step: 160, loss: 0.00011126959725515917
step: 170, loss: 0.001805063453502953
step: 180, loss: 0.0003102445916738361
step: 190, loss: 0.005626562982797623
step: 200, loss: 0.0003121232148259878
step: 210, loss: 0.00046117472811602056
step: 220, loss: 0.0008677081787027419
step: 230, loss: 5.837117350893095e-05
step: 240, loss: 0.0004002298228442669
step: 250, loss: 0.00015655810420867056
step: 260, loss: 0.0008437128271907568
step: 270, loss: 0.00042107515037059784
step: 280, loss: 0.018348943442106247
step: 290, loss: 0.00079952651867643
step: 300, loss: 0.008843387477099895
step: 310, loss: 0.009742919355630875
step: 320, loss: 0.006178634241223335
step: 330, loss: 0.019824892282485962
step: 340, loss: 0.023012161254882812
step: 350, loss: 0.013916903175413609
step: 360, loss: 0.0007921797223389149
epoch 10: dev_f1=0.6906077348066297, f1=0.6448087431693988, best_f1=0.6805194805194804
step: 0, loss: 0.002067546360194683
step: 10, loss: 0.0008158301352523267
step: 20, loss: 0.00014308276877272874
step: 30, loss: 0.002337728627026081
step: 40, loss: 0.0004949237336404622
step: 50, loss: 0.02073177695274353
step: 60, loss: 0.0005168797797523439
step: 70, loss: 0.009302453137934208
step: 80, loss: 0.0009317704243585467
step: 90, loss: 0.003929814789444208
step: 100, loss: 0.017207302153110504
step: 110, loss: 0.0003431086952332407
step: 120, loss: 0.09922215342521667
step: 130, loss: 0.0005835727788507938
step: 140, loss: 0.00950722023844719
step: 150, loss: 0.00042704015504568815
step: 160, loss: 7.929874118417501e-05
step: 170, loss: 0.0014331908896565437
step: 180, loss: 0.001300143776461482
step: 190, loss: 0.0011139848502352834
step: 200, loss: 0.0013051185524091125
step: 210, loss: 0.00023677770514041185
step: 220, loss: 0.005340261850506067
step: 230, loss: 0.00017840291548054665
step: 240, loss: 7.243060827022418e-05
step: 250, loss: 0.002179164672270417
step: 260, loss: 0.0004273420781828463
step: 270, loss: 0.0099104605615139
step: 280, loss: 0.00027961391606368124
step: 290, loss: 0.012450897134840488
step: 300, loss: 0.00032457135966978967
step: 310, loss: 0.003791924100369215
step: 320, loss: 0.00041155776125378907
step: 330, loss: 0.0006560457404702902
step: 340, loss: 0.0018670362187549472
step: 350, loss: 0.001597616239450872
step: 360, loss: 0.0011108668986707926
epoch 11: dev_f1=0.6860158311345645, f1=0.6422976501305484, best_f1=0.6805194805194804
step: 0, loss: 0.0002647240471560508
step: 10, loss: 0.0011587833287194371
step: 20, loss: 0.00035221059806644917
step: 30, loss: 0.025934984907507896
step: 40, loss: 0.0030511710792779922
step: 50, loss: 7.643099525012076e-05
step: 60, loss: 8.013770275283605e-05
step: 70, loss: 0.024139994755387306
step: 80, loss: 4.77322973893024e-05
step: 90, loss: 8.502435957780108e-05
step: 100, loss: 0.0001947330601979047
step: 110, loss: 0.014375968836247921
step: 120, loss: 8.998507109936327e-05
step: 130, loss: 0.0003092527622357011
step: 140, loss: 7.252019713632762e-05
step: 150, loss: 0.0005841167876496911
step: 160, loss: 0.00043555075535550714
step: 170, loss: 0.00047203811118379235
step: 180, loss: 0.02769520692527294
step: 190, loss: 0.0002407912543276325
step: 200, loss: 0.0002995120012201369
step: 210, loss: 0.0001501827937318012
step: 220, loss: 0.002509893151000142
step: 230, loss: 0.018185263499617577
step: 240, loss: 4.0509155951440334e-05
step: 250, loss: 0.0005815306212753057
step: 260, loss: 3.7700418033637106e-05
step: 270, loss: 2.249673161713872e-05
step: 280, loss: 0.002310902811586857
step: 290, loss: 0.004297062288969755
step: 300, loss: 0.00034872785909101367
step: 310, loss: 0.0008309222175739706
step: 320, loss: 0.0008973091025836766
step: 330, loss: 0.0004940045764669776
step: 340, loss: 0.004203879740089178
step: 350, loss: 0.001996642677113414
step: 360, loss: 0.008981195278465748
epoch 12: dev_f1=0.6850828729281768, f1=0.6212534059945504, best_f1=0.6805194805194804
step: 0, loss: 0.00018720849766395986
step: 10, loss: 0.0006079175509512424
step: 20, loss: 0.0016343753086403012
step: 30, loss: 0.0002095316449413076
step: 40, loss: 0.00010330508666811511
step: 50, loss: 0.0006340635591186583
step: 60, loss: 5.2969116950407624e-05
step: 70, loss: 0.0025469325482845306
step: 80, loss: 2.800604488584213e-05
step: 90, loss: 0.0013149264268577099
step: 100, loss: 3.691852907650173e-05
step: 110, loss: 4.934672324452549e-05
step: 120, loss: 0.00045186554780229926
step: 130, loss: 0.00023892600438557565
step: 140, loss: 0.04098401963710785
step: 150, loss: 0.0001243894366780296
step: 160, loss: 0.00010348812793381512
step: 170, loss: 0.028643429279327393
step: 180, loss: 7.867995009291917e-05
step: 190, loss: 0.012017655186355114
step: 200, loss: 0.0002224247728008777
step: 210, loss: 0.0019050863338634372
step: 220, loss: 0.0008856214699335396
step: 230, loss: 0.00021932048548478633
step: 240, loss: 0.015775123611092567
step: 250, loss: 0.00030559266451746225
step: 260, loss: 0.00015236112812999636
step: 270, loss: 3.388770346646197e-05
step: 280, loss: 4.5554173993878067e-05
step: 290, loss: 0.0009389640181325376
step: 300, loss: 0.0017424842808395624
step: 310, loss: 7.915749301901087e-05
step: 320, loss: 0.0014951035846024752
step: 330, loss: 0.00011364909005351365
step: 340, loss: 0.00016888695245143026
step: 350, loss: 0.008198258467018604
step: 360, loss: 0.0002962882863357663
epoch 13: dev_f1=0.6740947075208913, f1=0.6422535211267607, best_f1=0.6805194805194804
step: 0, loss: 0.0008629409712739289
step: 10, loss: 0.00022295405506156385
step: 20, loss: 0.003337571397423744
step: 30, loss: 0.00012079159932909533
step: 40, loss: 2.0131197743467055e-05
step: 50, loss: 6.021735316608101e-05
step: 60, loss: 9.924484038492665e-05
step: 70, loss: 3.4295306249987334e-05
step: 80, loss: 5.625539779430255e-05
step: 90, loss: 0.00012638169573619962
step: 100, loss: 0.003958952613174915
step: 110, loss: 4.225630618748255e-05
step: 120, loss: 4.18840536440257e-05
step: 130, loss: 2.3670054360991344e-05
step: 140, loss: 0.02990853227674961
step: 150, loss: 6.793514330638573e-05
step: 160, loss: 0.00011329234257573262
step: 170, loss: 0.0008319932385347784
step: 180, loss: 5.286164378048852e-05
step: 190, loss: 6.31558068562299e-05
step: 200, loss: 3.994278813479468e-05
step: 210, loss: 4.5327724365051836e-05
step: 220, loss: 0.00012103849439881742
step: 230, loss: 0.0005627187201753259
step: 240, loss: 0.00018566704238764942
step: 250, loss: 8.875736966729164e-05
step: 260, loss: 0.0006022010347805917
step: 270, loss: 0.00021513145475182682
step: 280, loss: 5.94666380493436e-05
step: 290, loss: 0.06537503749132156
step: 300, loss: 0.0004953381139785051
step: 310, loss: 0.0038378024473786354
step: 320, loss: 3.6618741432903334e-05
step: 330, loss: 0.00030459894333034754
step: 340, loss: 0.011619465425610542
step: 350, loss: 0.005401161033660173
step: 360, loss: 8.962541323853657e-05
epoch 14: dev_f1=0.6939890710382514, f1=0.6575342465753425, best_f1=0.6805194805194804
step: 0, loss: 0.00011748262477340177
step: 10, loss: 3.8729849620722234e-05
step: 20, loss: 0.0006918027647770941
step: 30, loss: 6.190297426655889e-05
step: 40, loss: 0.00029870629077777267
step: 50, loss: 5.3574527555610985e-05
step: 60, loss: 6.327077426249161e-05
step: 70, loss: 5.3596755606122315e-05
step: 80, loss: 4.316572085372172e-05
step: 90, loss: 0.0001117185311159119
step: 100, loss: 0.0001506583794252947
step: 110, loss: 0.00016031764971558005
step: 120, loss: 0.006305707152932882
step: 130, loss: 0.0001319726143265143
step: 140, loss: 1.8894410459324718e-05
step: 150, loss: 4.455782618606463e-05
step: 160, loss: 1.7020687664626166e-05
step: 170, loss: 2.43589256569976e-05
step: 180, loss: 5.389692887547426e-05
step: 190, loss: 0.004500601440668106
step: 200, loss: 0.00017955740622710437
step: 210, loss: 0.00020998218678869307
step: 220, loss: 0.00010358191502746195
step: 230, loss: 3.784580258070491e-05
step: 240, loss: 0.0003190288844052702
step: 250, loss: 2.5129973437287845e-05
step: 260, loss: 0.1164688766002655
step: 270, loss: 5.174494435777888e-05
step: 280, loss: 0.0012451800284907222
step: 290, loss: 0.0004162983095739037
step: 300, loss: 9.621224307920784e-05
step: 310, loss: 0.001984798349440098
step: 320, loss: 0.00022870917746331543
step: 330, loss: 0.0005915798828937113
step: 340, loss: 0.00027300225337967277
step: 350, loss: 0.007681381888687611
step: 360, loss: 2.9439654099405743e-05
epoch 15: dev_f1=0.6869806094182824, f1=0.6555555555555556, best_f1=0.6805194805194804
step: 0, loss: 3.218928395654075e-05
step: 10, loss: 2.128563392034266e-05
step: 20, loss: 9.508042421657592e-05
step: 30, loss: 0.00012829701881855726
step: 40, loss: 0.00011060624819947407
step: 50, loss: 0.006598595529794693
step: 60, loss: 5.84882109251339e-05
step: 70, loss: 0.005879032425582409
step: 80, loss: 0.00011113053187727928
step: 90, loss: 2.6813295335159637e-05
step: 100, loss: 1.770974267856218e-05
step: 110, loss: 3.8184280128916726e-05
step: 120, loss: 4.196396912448108e-05
step: 130, loss: 0.0006102052284404635
step: 140, loss: 0.0006293109036050737
step: 150, loss: 8.677825826453045e-05
step: 160, loss: 0.00025225075660273433
step: 170, loss: 0.0002641331811901182
step: 180, loss: 0.0003346388111822307
step: 190, loss: 0.00023763258650433272
step: 200, loss: 0.00047354132402688265
step: 210, loss: 0.0002145520265912637
step: 220, loss: 8.355692989425734e-05
step: 230, loss: 4.319742583902553e-05
step: 240, loss: 9.11434690351598e-05
step: 250, loss: 0.00023506052093580365
step: 260, loss: 0.0011291680857539177
step: 270, loss: 0.0009035863331519067
step: 280, loss: 2.1903864762862213e-05
step: 290, loss: 2.965529893117491e-05
step: 300, loss: 0.025513028725981712
step: 310, loss: 1.4137367543298751e-05
step: 320, loss: 3.141867637168616e-05
step: 330, loss: 0.0001771875686245039
step: 340, loss: 0.00025760207790881395
step: 350, loss: 2.9688275390071794e-05
step: 360, loss: 0.0006705546984449029
epoch 16: dev_f1=0.6914285714285714, f1=0.6318840579710145, best_f1=0.6805194805194804
step: 0, loss: 0.0012304388219490647
step: 10, loss: 2.136717739631422e-05
step: 20, loss: 3.524203202687204e-05
step: 30, loss: 4.769573934026994e-05
step: 40, loss: 0.0027703463565558195
step: 50, loss: 3.803746949415654e-05
step: 60, loss: 0.04027615487575531
step: 70, loss: 3.373490471858531e-05
step: 80, loss: 6.241200026124716e-05
step: 90, loss: 0.001718146726489067
step: 100, loss: 2.039178434642963e-05
step: 110, loss: 6.888807547511533e-05
step: 120, loss: 0.00017487457080278546
step: 130, loss: 3.352775820530951e-05
step: 140, loss: 3.6186131183058023e-05
step: 150, loss: 4.414928480400704e-05
step: 160, loss: 2.515935557312332e-05
step: 170, loss: 0.006147497333586216
step: 180, loss: 0.003560681128874421
step: 190, loss: 0.00041906838305294514
step: 200, loss: 0.002401982434093952
step: 210, loss: 1.6316573237418197e-05
step: 220, loss: 4.582085239235312e-05
step: 230, loss: 0.0002946468011941761
step: 240, loss: 0.0008906055008992553
step: 250, loss: 3.6892412026645616e-05
step: 260, loss: 8.845262345857918e-05
step: 270, loss: 6.92306348355487e-05
step: 280, loss: 0.00021384072897490114
step: 290, loss: 3.799299884121865e-05
step: 300, loss: 2.116993891831953e-05
step: 310, loss: 5.029798194300383e-05
step: 320, loss: 0.00010570458107395098
step: 330, loss: 0.00012343408889137208
step: 340, loss: 0.0001250810018973425
step: 350, loss: 2.732002394623123e-05
step: 360, loss: 0.0001334711123490706
epoch 17: dev_f1=0.6997084548104956, f1=0.63905325443787, best_f1=0.6805194805194804
step: 0, loss: 7.9781559179537e-05
step: 10, loss: 2.8463833587011322e-05
step: 20, loss: 0.0026030063163489103
step: 30, loss: 0.0017740580951794982
step: 40, loss: 4.908519622404128e-05
step: 50, loss: 4.733587411465123e-05
step: 60, loss: 2.3535512809758075e-05
step: 70, loss: 0.00012406340101733804
step: 80, loss: 9.154302824754268e-05
step: 90, loss: 0.00012087146751582623
step: 100, loss: 2.9509898013202474e-05
step: 110, loss: 0.0003673764585983008
step: 120, loss: 3.468997238087468e-05
step: 130, loss: 1.9728424376808107e-05
step: 140, loss: 2.291281271027401e-05
step: 150, loss: 1.1946927770623006e-05
step: 160, loss: 1.7683469195617363e-05
step: 170, loss: 2.3263710318133235e-05
step: 180, loss: 2.1062278392491862e-05
step: 190, loss: 1.7515983927296475e-05
step: 200, loss: 2.421687349851709e-05
step: 210, loss: 0.000886526599060744
step: 220, loss: 2.260785549879074e-05
step: 230, loss: 2.7278725610813126e-05
step: 240, loss: 2.7933710953220725e-05
step: 250, loss: 0.0001198269019369036
step: 260, loss: 1.2371602679195348e-05
step: 270, loss: 1.572782093717251e-05
step: 280, loss: 2.9970544346724637e-05
step: 290, loss: 0.0002755635359790176
step: 300, loss: 2.8625061531784013e-05
step: 310, loss: 0.00015766201249789447
step: 320, loss: 4.509053542278707e-05
step: 330, loss: 0.00022378028370440006
step: 340, loss: 1.1932022971450351e-05
step: 350, loss: 5.099530244478956e-05
step: 360, loss: 7.210737385321409e-05
epoch 18: dev_f1=0.6839080459770115, f1=0.6279069767441862, best_f1=0.6805194805194804
step: 0, loss: 0.00019278773106634617
step: 10, loss: 4.49574290541932e-05
step: 20, loss: 4.026550959679298e-05
step: 30, loss: 2.1866391762159765e-05
step: 40, loss: 4.7400353651028126e-05
step: 50, loss: 2.6570725822239183e-05
step: 60, loss: 8.031427569221705e-05
step: 70, loss: 2.0071356630069204e-05
step: 80, loss: 2.6392341169412248e-05
step: 90, loss: 0.015027951449155807
step: 100, loss: 1.6822887118905783e-05
step: 110, loss: 1.9430535758147016e-05
step: 120, loss: 1.1287556844763458e-05
step: 130, loss: 4.79711452499032e-05
step: 140, loss: 6.697524804621935e-05
step: 150, loss: 1.8354112398810685e-05
step: 160, loss: 4.547449862002395e-05
step: 170, loss: 0.004605386406183243
step: 180, loss: 3.792893767240457e-05
step: 190, loss: 5.246803266345523e-05
step: 200, loss: 8.804780372884125e-05
step: 210, loss: 2.4243327061412856e-05
step: 220, loss: 0.0005246791406534612
step: 230, loss: 4.3731350160669535e-05
step: 240, loss: 2.1672885850421153e-05
step: 250, loss: 9.175997547572479e-05
step: 260, loss: 3.6190445825923234e-05
step: 270, loss: 3.3538584830239415e-05
step: 280, loss: 7.340335287153721e-05
step: 290, loss: 0.00020329754624981433
step: 300, loss: 9.83471363724675e-06
step: 310, loss: 3.371531784068793e-05
step: 320, loss: 1.838016032706946e-05
step: 330, loss: 2.8167438358650543e-05
step: 340, loss: 8.055354555835947e-05
step: 350, loss: 3.504412961774506e-05
step: 360, loss: 3.7796577089466155e-05
epoch 19: dev_f1=0.6929577464788733, f1=0.6379310344827587, best_f1=0.6805194805194804
step: 0, loss: 2.6606057872413658e-05
step: 10, loss: 1.9508437617332675e-05
step: 20, loss: 3.2775671570561826e-05
step: 30, loss: 6.242367089726031e-05
step: 40, loss: 4.560401430353522e-05
step: 50, loss: 0.0073411897756159306
step: 60, loss: 7.211838237708434e-05
step: 70, loss: 4.332371463533491e-05
step: 80, loss: 0.00321339163929224
step: 90, loss: 5.1152346713934094e-05
step: 100, loss: 1.8249456843477674e-05
step: 110, loss: 3.644924800028093e-05
step: 120, loss: 1.57576214405708e-05
step: 130, loss: 3.2115534850163385e-05
step: 140, loss: 1.7787780961953104e-05
step: 150, loss: 2.0093424609513022e-05
step: 160, loss: 7.634961366420612e-05
step: 170, loss: 2.7643585781333968e-05
step: 180, loss: 0.00019526573305483907
step: 190, loss: 8.197827992262319e-05
step: 200, loss: 2.5165642000501975e-05
step: 210, loss: 1.9765004253713414e-05
step: 220, loss: 0.0001416998275090009
step: 230, loss: 1.1637725947366562e-05
step: 240, loss: 0.0008091088966466486
step: 250, loss: 2.3084041458787397e-05
step: 260, loss: 0.0009195305174216628
step: 270, loss: 1.731072370603215e-05
step: 280, loss: 1.9124299797113054e-05
step: 290, loss: 3.3698601328069344e-05
step: 300, loss: 0.0018645903328433633
step: 310, loss: 0.00015538372099399567
step: 320, loss: 0.0002871757897082716
step: 330, loss: 2.1363819541875273e-05
step: 340, loss: 2.712254718062468e-05
step: 350, loss: 2.1333942640922032e-05
step: 360, loss: 1.6349966244888492e-05
epoch 20: dev_f1=0.6929577464788733, f1=0.6438746438746438, best_f1=0.6805194805194804
