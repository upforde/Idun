cuda
Device: cuda
step: 0, loss: 0.6342215538024902
step: 10, loss: 0.32472532987594604
step: 20, loss: 0.14621149003505707
step: 30, loss: 0.27375203371047974
step: 40, loss: 0.13428589701652527
step: 50, loss: 0.14545151591300964
step: 60, loss: 0.3916480243206024
step: 70, loss: 0.04584207385778427
step: 80, loss: 0.14522376656532288
step: 90, loss: 0.24130061268806458
step: 100, loss: 0.23712944984436035
step: 110, loss: 0.3092886209487915
step: 120, loss: 0.3014930188655853
step: 130, loss: 0.11789350211620331
step: 140, loss: 0.013423463329672813
step: 150, loss: 0.14747361838817596
step: 160, loss: 0.12432091683149338
step: 170, loss: 0.03950271010398865
step: 180, loss: 0.1977541446685791
step: 190, loss: 0.3994702696800232
step: 200, loss: 0.4101076126098633
step: 210, loss: 0.22333990037441254
step: 220, loss: 0.21555927395820618
step: 230, loss: 0.174358069896698
step: 240, loss: 0.17797636985778809
step: 250, loss: 0.08995559811592102
step: 260, loss: 0.10551141947507858
step: 270, loss: 0.1537446230649948
step: 280, loss: 0.011852146126329899
step: 290, loss: 0.13511930406093597
step: 300, loss: 0.013132179155945778
step: 310, loss: 0.1440334916114807
step: 320, loss: 0.16507473587989807
step: 330, loss: 0.13017836213111877
step: 340, loss: 0.08460190147161484
step: 350, loss: 0.08101726323366165
step: 360, loss: 0.10536856949329376
epoch 1: dev_f1=0.6010101010101009, f1=0.585, best_f1=0.585
step: 0, loss: 0.15949910879135132
step: 10, loss: 0.11433932185173035
step: 20, loss: 0.10847149044275284
step: 30, loss: 0.1958853304386139
step: 40, loss: 0.017209600657224655
step: 50, loss: 0.1451674997806549
step: 60, loss: 0.2981705665588379
step: 70, loss: 0.12592650949954987
step: 80, loss: 0.15269410610198975
step: 90, loss: 0.2159367799758911
step: 100, loss: 0.06787219643592834
step: 110, loss: 0.07714631408452988
step: 120, loss: 0.012166175991296768
step: 130, loss: 0.05717885494232178
step: 140, loss: 0.351644903421402
step: 150, loss: 0.28793689608573914
step: 160, loss: 0.25014206767082214
step: 170, loss: 0.09725072234869003
step: 180, loss: 0.09400880336761475
step: 190, loss: 0.061761803925037384
step: 200, loss: 0.0429731048643589
step: 210, loss: 0.035162199288606644
step: 220, loss: 0.3439790606498718
step: 230, loss: 0.06222422793507576
step: 240, loss: 0.1628607213497162
step: 250, loss: 0.09436109662055969
step: 260, loss: 0.008559522219002247
step: 270, loss: 0.10423734039068222
step: 280, loss: 0.06879787147045135
step: 290, loss: 0.15962573885917664
step: 300, loss: 0.05361103266477585
step: 310, loss: 0.12118415534496307
step: 320, loss: 0.05888396501541138
step: 330, loss: 0.02484147436916828
step: 340, loss: 0.13735491037368774
step: 350, loss: 0.1268877387046814
step: 360, loss: 0.2591646611690521
epoch 2: dev_f1=0.6595174262734586, f1=0.672, best_f1=0.672
step: 0, loss: 0.10545933246612549
step: 10, loss: 0.1729198843240738
step: 20, loss: 0.17979827523231506
step: 30, loss: 0.08496125787496567
step: 40, loss: 0.0025096486788243055
step: 50, loss: 0.06615244597196579
step: 60, loss: 0.08633235841989517
step: 70, loss: 0.029954954981803894
step: 80, loss: 0.005287633277475834
step: 90, loss: 0.0021146531216800213
step: 100, loss: 0.03175690397620201
step: 110, loss: 0.08208394050598145
step: 120, loss: 0.06801623851060867
step: 130, loss: 0.09944113343954086
step: 140, loss: 0.13923019170761108
step: 150, loss: 0.1873183399438858
step: 160, loss: 0.08429671823978424
step: 170, loss: 0.05387948825955391
step: 180, loss: 0.261748731136322
step: 190, loss: 0.06185401976108551
step: 200, loss: 0.05181701481342316
step: 210, loss: 0.00710479449480772
step: 220, loss: 0.042915068566799164
step: 230, loss: 0.19011756777763367
step: 240, loss: 0.06747300177812576
step: 250, loss: 0.022609692066907883
step: 260, loss: 0.07559393346309662
step: 270, loss: 0.00481247715651989
step: 280, loss: 0.048981860280036926
step: 290, loss: 0.05390189588069916
step: 300, loss: 0.0274344552308321
step: 310, loss: 0.0017972473287954926
step: 320, loss: 0.008117993362247944
step: 330, loss: 0.02417982928454876
step: 340, loss: 0.166884183883667
step: 350, loss: 0.029916677623987198
step: 360, loss: 0.04751892760396004
epoch 3: dev_f1=0.6631853785900783, f1=0.6582914572864322, best_f1=0.6582914572864322
step: 0, loss: 0.0757548063993454
step: 10, loss: 0.03988691791892052
step: 20, loss: 0.01909954473376274
step: 30, loss: 0.016843440011143684
step: 40, loss: 0.1265886127948761
step: 50, loss: 0.0358479842543602
step: 60, loss: 0.007286899723112583
step: 70, loss: 0.026824910193681717
step: 80, loss: 0.10615912079811096
step: 90, loss: 0.0006578270113095641
step: 100, loss: 0.04838506132364273
step: 110, loss: 0.025137942284345627
step: 120, loss: 0.0056462944485247135
step: 130, loss: 0.044472645968198776
step: 140, loss: 0.005365463905036449
step: 150, loss: 0.059537000954151154
step: 160, loss: 0.003228232264518738
step: 170, loss: 0.002629318740218878
step: 180, loss: 0.004411560948938131
step: 190, loss: 0.14892363548278809
step: 200, loss: 0.003281421959400177
step: 210, loss: 0.12836416065692902
step: 220, loss: 0.0250875074416399
step: 230, loss: 0.05215144529938698
step: 240, loss: 0.0540827177464962
step: 250, loss: 0.036509715020656586
step: 260, loss: 0.0103523600846529
step: 270, loss: 0.053610097616910934
step: 280, loss: 0.10525467246770859
step: 290, loss: 0.12921302020549774
step: 300, loss: 0.004362386651337147
step: 310, loss: 0.04221377521753311
step: 320, loss: 0.028783177956938744
step: 330, loss: 0.019936248660087585
step: 340, loss: 0.05783345177769661
step: 350, loss: 0.0032267228234559298
step: 360, loss: 0.12198594957590103
epoch 4: dev_f1=0.6527777777777778, f1=0.6590909090909092, best_f1=0.6582914572864322
step: 0, loss: 0.016434893012046814
step: 10, loss: 0.025608595460653305
step: 20, loss: 0.027904463931918144
step: 30, loss: 0.028251778334379196
step: 40, loss: 0.1158662810921669
step: 50, loss: 0.1397220343351364
step: 60, loss: 0.04782501980662346
step: 70, loss: 0.02187422476708889
step: 80, loss: 0.02228563465178013
step: 90, loss: 0.00492288451641798
step: 100, loss: 0.0012700121151283383
step: 110, loss: 0.0023317730519920588
step: 120, loss: 0.06366395950317383
step: 130, loss: 0.04912891238927841
step: 140, loss: 0.00788828544318676
step: 150, loss: 0.0015053749084472656
step: 160, loss: 0.014512862078845501
step: 170, loss: 0.010416604578495026
step: 180, loss: 0.015274504199624062
step: 190, loss: 0.006857472471892834
step: 200, loss: 0.0011747708776965737
step: 210, loss: 0.02466369979083538
step: 220, loss: 0.06792400032281876
step: 230, loss: 0.06011433154344559
step: 240, loss: 0.06379172205924988
step: 250, loss: 0.024926140904426575
step: 260, loss: 0.021724417805671692
step: 270, loss: 0.11498670279979706
step: 280, loss: 0.0101149408146739
step: 290, loss: 0.006213946733623743
step: 300, loss: 0.025319276377558708
step: 310, loss: 0.004857779014855623
step: 320, loss: 0.029839172959327698
step: 330, loss: 0.00571057852357626
step: 340, loss: 0.09653698652982712
step: 350, loss: 0.022870492190122604
step: 360, loss: 0.02388455905020237
epoch 5: dev_f1=0.6946778711484594, f1=0.7065527065527066, best_f1=0.7065527065527066
step: 0, loss: 0.017038289457559586
step: 10, loss: 0.02818218804895878
step: 20, loss: 0.04843801632523537
step: 30, loss: 0.037016112357378006
step: 40, loss: 0.006283733528107405
step: 50, loss: 0.06979990005493164
step: 60, loss: 0.054121389985084534
step: 70, loss: 0.03429720923304558
step: 80, loss: 0.00821162760257721
step: 90, loss: 0.03164410963654518
step: 100, loss: 0.0028345524333417416
step: 110, loss: 0.029284551739692688
step: 120, loss: 0.0024513101670891047
step: 130, loss: 0.19461259245872498
step: 140, loss: 0.004902568645775318
step: 150, loss: 0.0032222780864685774
step: 160, loss: 0.0030016235541552305
step: 170, loss: 0.0002772472507786006
step: 180, loss: 0.008226469159126282
step: 190, loss: 0.008994083851575851
step: 200, loss: 0.000777553184889257
step: 210, loss: 0.002014891244471073
step: 220, loss: 0.0013929654378443956
step: 230, loss: 0.0005691135302186012
step: 240, loss: 0.09421315044164658
step: 250, loss: 0.0029903054237365723
step: 260, loss: 0.09684941172599792
step: 270, loss: 0.12924407422542572
step: 280, loss: 0.04416520148515701
step: 290, loss: 0.034518782049417496
step: 300, loss: 0.02077273093163967
step: 310, loss: 0.00021682710212189704
step: 320, loss: 0.0048546199686825275
step: 330, loss: 0.002982888836413622
step: 340, loss: 0.0008137313998304307
step: 350, loss: 0.008498103357851505
step: 360, loss: 0.09566403180360794
epoch 6: dev_f1=0.6845238095238095, f1=0.617737003058104, best_f1=0.7065527065527066
step: 0, loss: 0.005091873463243246
step: 10, loss: 0.004355909768491983
step: 20, loss: 0.0006638891063630581
step: 30, loss: 0.0007453749421983957
step: 40, loss: 0.05933369696140289
step: 50, loss: 0.0015571308322250843
step: 60, loss: 0.01249187532812357
step: 70, loss: 0.001646297750994563
step: 80, loss: 0.012967279180884361
step: 90, loss: 0.06562351435422897
step: 100, loss: 0.0010249762563034892
step: 110, loss: 0.0023446560371667147
step: 120, loss: 0.0001833031710702926
step: 130, loss: 0.024300847202539444
step: 140, loss: 0.003922475501894951
step: 150, loss: 0.022381596267223358
step: 160, loss: 0.005446381401270628
step: 170, loss: 0.021259427070617676
step: 180, loss: 0.0002514207153581083
step: 190, loss: 0.0016097344923764467
step: 200, loss: 0.008651443757116795
step: 210, loss: 0.00013586218119598925
step: 220, loss: 0.0006508204387500882
step: 230, loss: 0.0012926430208608508
step: 240, loss: 0.0243501216173172
step: 250, loss: 0.025465067476034164
step: 260, loss: 0.018730521202087402
step: 270, loss: 0.013807789422571659
step: 280, loss: 0.01807020977139473
step: 290, loss: 0.05130176991224289
step: 300, loss: 0.007333827670663595
step: 310, loss: 0.00038966789725236595
step: 320, loss: 0.0003566606901586056
step: 330, loss: 0.004502961877733469
step: 340, loss: 0.0008966036839410663
step: 350, loss: 0.0005360601935535669
step: 360, loss: 0.018735965713858604
epoch 7: dev_f1=0.5686274509803922, f1=0.5882352941176471, best_f1=0.7065527065527066
step: 0, loss: 0.12480507045984268
step: 10, loss: 0.06607870012521744
step: 20, loss: 0.0019201734103262424
step: 30, loss: 0.015724612399935722
step: 40, loss: 0.023052992299199104
step: 50, loss: 0.0105344969779253
step: 60, loss: 0.0005140178836882114
step: 70, loss: 0.08050191402435303
step: 80, loss: 0.041474636644124985
step: 90, loss: 0.03700462728738785
step: 100, loss: 0.013273986987769604
step: 110, loss: 0.022937577217817307
step: 120, loss: 0.003906312398612499
step: 130, loss: 0.010029545985162258
step: 140, loss: 0.0010920960921794176
step: 150, loss: 0.022218193858861923
step: 160, loss: 0.0023227448109537363
step: 170, loss: 0.0029043115209788084
step: 180, loss: 0.00621161749586463
step: 190, loss: 0.0007270884234458208
step: 200, loss: 7.555191405117512e-05
step: 210, loss: 0.0003261358942836523
step: 220, loss: 0.0034326566383242607
step: 230, loss: 0.00041127370786853135
step: 240, loss: 0.023753341287374496
step: 250, loss: 0.0004691078211180866
step: 260, loss: 0.00032529691816307604
step: 270, loss: 0.08676019310951233
step: 280, loss: 0.0001313916000071913
step: 290, loss: 0.01066451333463192
step: 300, loss: 0.0007820920436643064
step: 310, loss: 0.0004101943923160434
step: 320, loss: 0.11460781842470169
step: 330, loss: 0.04158169776201248
step: 340, loss: 0.00042776696500368416
step: 350, loss: 0.0003471021191217005
step: 360, loss: 0.04648769274353981
epoch 8: dev_f1=0.6561679790026247, f1=0.6323907455012855, best_f1=0.7065527065527066
step: 0, loss: 0.04861365258693695
step: 10, loss: 0.018561972305178642
step: 20, loss: 0.000999246258288622
step: 30, loss: 0.0005193671095184982
step: 40, loss: 0.0004967771237716079
step: 50, loss: 0.01147186104208231
step: 60, loss: 0.0008308587712235749
step: 70, loss: 0.0001838542812038213
step: 80, loss: 0.0007673108484596014
step: 90, loss: 0.04099499434232712
step: 100, loss: 0.0023517683148384094
step: 110, loss: 0.0007981646922416985
step: 120, loss: 0.006685520987957716
step: 130, loss: 0.014445612207055092
step: 140, loss: 0.0021353852935135365
step: 150, loss: 0.0020431913435459137
step: 160, loss: 0.0005076855886727571
step: 170, loss: 0.018303612247109413
step: 180, loss: 0.0006667285924777389
step: 190, loss: 0.0004142827820032835
step: 200, loss: 0.00012529623927548528
step: 210, loss: 0.0013054204173386097
step: 220, loss: 0.0021137476433068514
step: 230, loss: 0.0001397457526763901
step: 240, loss: 0.000384062877856195
step: 250, loss: 0.007528798654675484
step: 260, loss: 0.09752548485994339
step: 270, loss: 0.00026497733779251575
step: 280, loss: 0.00024491798831149936
step: 290, loss: 0.009964222088456154
step: 300, loss: 0.000495685962960124
step: 310, loss: 0.014575323089957237
step: 320, loss: 0.015719864517450333
step: 330, loss: 0.01686103828251362
step: 340, loss: 0.014363646507263184
step: 350, loss: 0.008563730865716934
step: 360, loss: 0.0005970621714368463
epoch 9: dev_f1=0.6597402597402597, f1=0.6422976501305484, best_f1=0.7065527065527066
step: 0, loss: 0.001063744304701686
step: 10, loss: 0.00010561159433564171
step: 20, loss: 0.00010341629240429029
step: 30, loss: 0.004735104739665985
step: 40, loss: 0.0008557525579817593
step: 50, loss: 0.015393183566629887
step: 60, loss: 0.010633138939738274
step: 70, loss: 0.005072104278951883
step: 80, loss: 0.0018766146386042237
step: 90, loss: 0.00022605742560699582
step: 100, loss: 0.00024521659361198545
step: 110, loss: 0.0011722395429387689
step: 120, loss: 0.0003018540155608207
step: 130, loss: 0.00047608005115762353
step: 140, loss: 8.784949750406668e-05
step: 150, loss: 0.00011974274093518034
step: 160, loss: 0.0004993468173779547
step: 170, loss: 0.011116853915154934
step: 180, loss: 0.00015801159315742552
step: 190, loss: 0.002668260131031275
step: 200, loss: 0.008297757245600224
step: 210, loss: 0.00202184752561152
step: 220, loss: 7.341408490901813e-05
step: 230, loss: 0.031810909509658813
step: 240, loss: 0.0025106240063905716
step: 250, loss: 0.0463845320045948
step: 260, loss: 0.0012832868378609419
step: 270, loss: 0.0011990322964265943
step: 280, loss: 0.0002336465404368937
step: 290, loss: 0.00023549364414066076
step: 300, loss: 0.0008822337258607149
step: 310, loss: 0.011861435137689114
step: 320, loss: 0.0007939765346236527
step: 330, loss: 0.0037994105368852615
step: 340, loss: 0.00010840757749974728
step: 350, loss: 0.00038079803925938904
step: 360, loss: 0.0012698242207989097
epoch 10: dev_f1=0.6802030456852791, f1=0.6868686868686869, best_f1=0.7065527065527066
step: 0, loss: 0.0010312612866982818
step: 10, loss: 0.0017431406304240227
step: 20, loss: 0.0015017050318419933
step: 30, loss: 0.001099568442441523
step: 40, loss: 0.000237311702221632
step: 50, loss: 0.006221832241863012
step: 60, loss: 4.763614197145216e-05
step: 70, loss: 0.0001268464111490175
step: 80, loss: 0.0003434492682572454
step: 90, loss: 8.242217154474929e-05
step: 100, loss: 0.012070808559656143
step: 110, loss: 0.00016718776896595955
step: 120, loss: 0.000814816274214536
step: 130, loss: 0.0011725821532309055
step: 140, loss: 0.0008327340474352241
step: 150, loss: 0.001694527338258922
step: 160, loss: 0.0015964924823492765
step: 170, loss: 0.0020373507868498564
step: 180, loss: 0.0016255361260846257
step: 190, loss: 4.039533814648166e-05
step: 200, loss: 9.188462718157098e-05
step: 210, loss: 0.002418113872408867
step: 220, loss: 0.00637332396581769
step: 230, loss: 0.0010129318106919527
step: 240, loss: 0.000545356422662735
step: 250, loss: 0.008878284133970737
step: 260, loss: 0.00015593180432915688
step: 270, loss: 0.002793294843286276
step: 280, loss: 3.770987314055674e-05
step: 290, loss: 0.002509769517928362
step: 300, loss: 0.00016439457249362022
step: 310, loss: 0.0003252630413044244
step: 320, loss: 0.00020375223539303988
step: 330, loss: 0.00019244247232563794
step: 340, loss: 0.00036644970532506704
step: 350, loss: 0.0003624879173003137
step: 360, loss: 0.07089803367853165
epoch 11: dev_f1=0.6813725490196078, f1=0.6699751861042184, best_f1=0.7065527065527066
step: 0, loss: 0.03460156172513962
step: 10, loss: 0.002951046684756875
step: 20, loss: 0.000587636954151094
step: 30, loss: 0.0026835924945771694
step: 40, loss: 0.0015552487457171082
step: 50, loss: 0.00011657124559860677
step: 60, loss: 0.00033139315200969577
step: 70, loss: 0.022693993523716927
step: 80, loss: 0.0009488950599916279
step: 90, loss: 0.0004815942083951086
step: 100, loss: 0.005239690653979778
step: 110, loss: 4.924363747704774e-05
step: 120, loss: 0.00014467211440205574
step: 130, loss: 0.00018574191199149936
step: 140, loss: 0.00022577361960429698
step: 150, loss: 4.081969746039249e-05
step: 160, loss: 0.00013543697423301637
step: 170, loss: 0.00016902947390917689
step: 180, loss: 0.000513628008775413
step: 190, loss: 0.000296780897770077
step: 200, loss: 0.007474255748093128
step: 210, loss: 0.0009102898184210062
step: 220, loss: 0.0030263755470514297
step: 230, loss: 0.0010172028560191393
step: 240, loss: 0.0010870598489418626
step: 250, loss: 0.00024087012570817024
step: 260, loss: 0.0017965888837352395
step: 270, loss: 0.00030818444793112576
step: 280, loss: 0.0004382382030598819
step: 290, loss: 9.075735579244792e-05
step: 300, loss: 0.00013091186701785773
step: 310, loss: 0.00015221796638797969
step: 320, loss: 0.016946827992796898
step: 330, loss: 0.006913105025887489
step: 340, loss: 0.0024459105916321278
step: 350, loss: 0.06552451848983765
step: 360, loss: 7.799711602274328e-05
epoch 12: dev_f1=0.6762589928057554, f1=0.6714975845410628, best_f1=0.7065527065527066
step: 0, loss: 0.0006361895939335227
step: 10, loss: 0.0008007774013094604
step: 20, loss: 4.7939767682692036e-05
step: 30, loss: 3.194722012267448e-05
step: 40, loss: 0.000605268229264766
step: 50, loss: 0.00021647919493261725
step: 60, loss: 0.0002234710264019668
step: 70, loss: 0.00030853066709823906
step: 80, loss: 0.0013276116224005818
step: 90, loss: 0.00017463443509768695
step: 100, loss: 0.0010029907571151853
step: 110, loss: 0.001533017260953784
step: 120, loss: 9.3025628302712e-05
step: 130, loss: 0.000208833662327379
step: 140, loss: 0.00015207724936772138
step: 150, loss: 0.00019538222113624215
step: 160, loss: 0.00013988628052175045
step: 170, loss: 8.323455404024571e-05
step: 180, loss: 4.479672497836873e-05
step: 190, loss: 0.00010197666415479034
step: 200, loss: 0.0034902498591691256
step: 210, loss: 0.0012757631484419107
step: 220, loss: 0.00028778801788575947
step: 230, loss: 0.008151472546160221
step: 240, loss: 0.00018497600103728473
step: 250, loss: 0.06023925170302391
step: 260, loss: 6.969967944314703e-05
step: 270, loss: 0.003238820470869541
step: 280, loss: 0.06599144637584686
step: 290, loss: 0.00025474498397670686
step: 300, loss: 6.850960198789835e-05
step: 310, loss: 7.067861588438973e-05
step: 320, loss: 0.0003177016624249518
step: 330, loss: 0.0003441348089836538
step: 340, loss: 0.001177509780973196
step: 350, loss: 0.00036160717718303204
step: 360, loss: 0.0022607073187828064
epoch 13: dev_f1=0.6744186046511628, f1=0.629080118694362, best_f1=0.7065527065527066
step: 0, loss: 0.0020155496895313263
step: 10, loss: 0.0007724869647063315
step: 20, loss: 0.00020682196191046387
step: 30, loss: 0.0020342881325632334
step: 40, loss: 0.0007799534359946847
step: 50, loss: 7.137294596759602e-05
step: 60, loss: 6.244848918868229e-05
step: 70, loss: 0.0005190540687181056
step: 80, loss: 0.00027191886329092085
step: 90, loss: 0.0003234278119634837
step: 100, loss: 0.00011684495984809473
step: 110, loss: 0.0011913260677829385
step: 120, loss: 0.00011885105050168931
step: 130, loss: 0.00013932112779002637
step: 140, loss: 8.6116990132723e-05
step: 150, loss: 0.00010630310862325132
step: 160, loss: 0.0009723474504426122
step: 170, loss: 0.0004997216165065765
step: 180, loss: 0.0011389091378077865
step: 190, loss: 6.979551835684106e-05
step: 200, loss: 0.0008597586420364678
step: 210, loss: 0.0004417797608766705
step: 220, loss: 0.00016683194553479552
step: 230, loss: 0.0049178083427250385
step: 240, loss: 0.0001481039944337681
step: 250, loss: 0.00029148190515115857
step: 260, loss: 0.0002854274644050747
step: 270, loss: 0.002168352948501706
step: 280, loss: 0.0009006572072394192
step: 290, loss: 0.00015376486408058554
step: 300, loss: 0.00025358726270496845
step: 310, loss: 0.00012300816888455302
step: 320, loss: 0.0004885022644884884
step: 330, loss: 0.00047100058873184025
step: 340, loss: 0.00036360954982228577
step: 350, loss: 0.0008174799149855971
step: 360, loss: 0.00014978140825405717
epoch 14: dev_f1=0.6850828729281768, f1=0.651558073654391, best_f1=0.7065527065527066
step: 0, loss: 0.0008991984650492668
step: 10, loss: 0.00023132744536269456
step: 20, loss: 0.00044306591735221446
step: 30, loss: 0.0003682958777062595
step: 40, loss: 0.00045583254541270435
step: 50, loss: 0.0012211956782266498
step: 60, loss: 0.0005330303101800382
step: 70, loss: 9.22184408409521e-05
step: 80, loss: 0.0013030237751081586
step: 90, loss: 0.00017096531519200653
step: 100, loss: 0.00024134456180036068
step: 110, loss: 0.0005301967030391097
step: 120, loss: 0.00034579585189931095
step: 130, loss: 2.9850103601347655e-05
step: 140, loss: 0.0004652311035897583
step: 150, loss: 5.200037048780359e-05
step: 160, loss: 0.00016009369574021548
step: 170, loss: 0.00012527180660981685
step: 180, loss: 0.01750325784087181
step: 190, loss: 7.149214798118919e-05
step: 200, loss: 0.0013042085338383913
step: 210, loss: 0.00011582796287257224
step: 220, loss: 2.1345502318581566e-05
step: 230, loss: 4.5710563426837325e-05
step: 240, loss: 7.87414755905047e-05
step: 250, loss: 0.009608219377696514
step: 260, loss: 9.018894343171269e-05
step: 270, loss: 7.727327465545386e-05
step: 280, loss: 7.470565469702706e-05
step: 290, loss: 0.00013794131518807262
step: 300, loss: 8.791725849732757e-05
step: 310, loss: 0.00437132315710187
step: 320, loss: 4.61898889625445e-05
step: 330, loss: 3.692089012474753e-05
step: 340, loss: 7.155635103117675e-05
step: 350, loss: 4.245776653988287e-05
step: 360, loss: 0.00019222483388148248
epoch 15: dev_f1=0.6842105263157895, f1=0.6614173228346457, best_f1=0.7065527065527066
step: 0, loss: 0.00025946222012862563
step: 10, loss: 9.14590127649717e-05
step: 20, loss: 0.00019518226326908916
step: 30, loss: 0.00021829362958669662
step: 40, loss: 6.873904203530401e-05
step: 50, loss: 0.00010719554120441899
step: 60, loss: 0.00011559800623217598
step: 70, loss: 0.0003580580814741552
step: 80, loss: 0.00010786999337142333
step: 90, loss: 6.186636892380193e-05
step: 100, loss: 7.681843271711841e-05
step: 110, loss: 2.3535969376098365e-05
step: 120, loss: 0.0008608080679550767
step: 130, loss: 0.0010902609210461378
step: 140, loss: 0.13581497967243195
step: 150, loss: 0.00012049818178638816
step: 160, loss: 0.023065246641635895
step: 170, loss: 0.00037453899858519435
step: 180, loss: 3.5771518014371395e-05
step: 190, loss: 0.00011303923383820802
step: 200, loss: 0.000891863543074578
step: 210, loss: 0.00022719566186424345
step: 220, loss: 4.4624481233768165e-05
step: 230, loss: 0.10015401989221573
step: 240, loss: 0.00046195409959182143
step: 250, loss: 0.0003615554887801409
step: 260, loss: 7.75454900576733e-05
step: 270, loss: 0.00026740296743810177
step: 280, loss: 0.00010131762246601284
step: 290, loss: 0.00013720149581786245
step: 300, loss: 6.531970575451851e-05
step: 310, loss: 0.00013729077181778848
step: 320, loss: 0.0001708668569335714
step: 330, loss: 0.0001226476888405159
step: 340, loss: 0.0010702467989176512
step: 350, loss: 0.00011123417789349332
step: 360, loss: 0.0010537721682339907
epoch 16: dev_f1=0.6878306878306877, f1=0.6861702127659575, best_f1=0.7065527065527066
step: 0, loss: 0.0006614805897697806
step: 10, loss: 0.007401570677757263
step: 20, loss: 0.00010207037121290341
step: 30, loss: 9.006707114167511e-05
step: 40, loss: 0.0008599018910899758
step: 50, loss: 5.851078822161071e-05
step: 60, loss: 0.00016537297051399946
step: 70, loss: 3.299853051430546e-05
step: 80, loss: 6.892644887557253e-05
step: 90, loss: 6.0664082411676645e-05
step: 100, loss: 0.00018526775238569826
step: 110, loss: 0.00010749609646154568
step: 120, loss: 6.135511648608372e-05
step: 130, loss: 0.00014781109348405153
step: 140, loss: 0.0002488921454641968
step: 150, loss: 0.0013631698675453663
step: 160, loss: 9.009031055029482e-05
step: 170, loss: 0.0010488550178706646
step: 180, loss: 0.00012629400589503348
step: 190, loss: 9.89773398032412e-05
step: 200, loss: 5.4253239795798436e-05
step: 210, loss: 4.026943861390464e-05
step: 220, loss: 0.00043797813123092055
step: 230, loss: 2.9352657293202356e-05
step: 240, loss: 6.592232966795564e-05
step: 250, loss: 6.066988134989515e-05
step: 260, loss: 0.0036392330657690763
step: 270, loss: 6.705873238388449e-05
step: 280, loss: 0.0002995370014104992
step: 290, loss: 0.0007550318841822445
step: 300, loss: 0.0005087454919703305
step: 310, loss: 1.9017374143004417e-05
step: 320, loss: 4.783367694471963e-05
step: 330, loss: 0.0007819201564416289
step: 340, loss: 5.845672785653733e-05
step: 350, loss: 7.309125066967681e-05
step: 360, loss: 0.00011152793013025075
epoch 17: dev_f1=0.6629834254143646, f1=0.6648199445983378, best_f1=0.7065527065527066
step: 0, loss: 0.0005734270671382546
step: 10, loss: 7.807913061697036e-05
step: 20, loss: 3.938328882213682e-05
step: 30, loss: 0.0028138083871454
step: 40, loss: 0.005902016535401344
step: 50, loss: 0.002478579059243202
step: 60, loss: 2.2861078832647763e-05
step: 70, loss: 0.00010595784260658547
step: 80, loss: 0.0001369868405163288
step: 90, loss: 0.0007829212700016797
step: 100, loss: 6.464948819484562e-05
step: 110, loss: 3.879181167576462e-05
step: 120, loss: 1.528470966150053e-05
step: 130, loss: 1.9471790437819436e-05
step: 140, loss: 4.6722441766178235e-05
step: 150, loss: 4.381393955554813e-05
step: 160, loss: 7.424619980156422e-05
step: 170, loss: 0.00029022336821071804
step: 180, loss: 4.2532174120424315e-05
step: 190, loss: 0.00024427971220575273
step: 200, loss: 0.000620695878751576
step: 210, loss: 0.00040224590338766575
step: 220, loss: 3.362167626619339e-05
step: 230, loss: 0.0001805889478418976
step: 240, loss: 0.00013215998478699476
step: 250, loss: 0.00011361991346348077
step: 260, loss: 0.00014100936823524535
step: 270, loss: 4.949553112965077e-05
step: 280, loss: 2.7788853913079947e-05
step: 290, loss: 0.0001114591650548391
step: 300, loss: 5.6195902288891375e-05
step: 310, loss: 0.0001988654548767954
step: 320, loss: 6.631596625084057e-05
step: 330, loss: 2.8676236979663372e-05
step: 340, loss: 0.016729189082980156
step: 350, loss: 2.679837962205056e-05
step: 360, loss: 1.9769493519561365e-05
epoch 18: dev_f1=0.6684782608695653, f1=0.6868131868131868, best_f1=0.7065527065527066
step: 0, loss: 0.00014196999836713076
step: 10, loss: 4.659328988054767e-05
step: 20, loss: 1.6472778952447698e-05
step: 30, loss: 7.898792682681233e-05
step: 40, loss: 0.00016168432193808258
step: 50, loss: 2.5430801542825066e-05
step: 60, loss: 4.806143624591641e-05
step: 70, loss: 2.3222553863888606e-05
step: 80, loss: 2.9518081646529026e-05
step: 90, loss: 0.00010106928675668314
step: 100, loss: 2.9572836865554564e-05
step: 110, loss: 3.8075926568126306e-05
step: 120, loss: 3.373404615558684e-05
step: 130, loss: 1.6022253475966863e-05
step: 140, loss: 3.817138713202439e-05
step: 150, loss: 6.678984937025234e-05
step: 160, loss: 4.73150794277899e-05
step: 170, loss: 0.0015562204644083977
step: 180, loss: 5.030097236158326e-05
step: 190, loss: 0.00022103996889200062
step: 200, loss: 9.751258767209947e-05
step: 210, loss: 2.6876288757193834e-05
step: 220, loss: 0.0002011218311963603
step: 230, loss: 2.538642002036795e-05
step: 240, loss: 0.00011005483975168318
step: 250, loss: 4.276374602341093e-05
step: 260, loss: 2.5867053409456275e-05
step: 270, loss: 0.0034018743317574263
step: 280, loss: 2.7267587938695215e-05
step: 290, loss: 4.9127436795970425e-05
step: 300, loss: 4.213656211504713e-05
step: 310, loss: 2.110961031576153e-05
step: 320, loss: 1.6793421309557743e-05
step: 330, loss: 1.5258623534464277e-05
step: 340, loss: 0.00027452391805127263
step: 350, loss: 0.015410445630550385
step: 360, loss: 6.768423918401822e-05
epoch 19: dev_f1=0.6721311475409837, f1=0.6830601092896175, best_f1=0.7065527065527066
step: 0, loss: 5.136861727805808e-05
step: 10, loss: 2.2581398297916166e-05
step: 20, loss: 0.00027474318630993366
step: 30, loss: 0.0003625787503551692
step: 40, loss: 8.530793274985626e-05
step: 50, loss: 3.185486639267765e-05
step: 60, loss: 2.9932896723039448e-05
step: 70, loss: 2.4905202735681087e-05
step: 80, loss: 0.00015898652782198042
step: 90, loss: 3.588937033782713e-05
step: 100, loss: 5.861532554263249e-05
step: 110, loss: 2.1084562831674702e-05
step: 120, loss: 2.1580006432486698e-05
step: 130, loss: 4.9951166147366166e-05
step: 140, loss: 2.3669050278840587e-05
step: 150, loss: 0.0015507101779803634
step: 160, loss: 5.161374429007992e-05
step: 170, loss: 2.9565784643637016e-05
step: 180, loss: 9.922210301738232e-05
step: 190, loss: 8.38556734379381e-05
step: 200, loss: 1.2840976523875725e-05
step: 210, loss: 8.24738381197676e-05
step: 220, loss: 2.5006123905768618e-05
step: 230, loss: 8.573464583605528e-05
step: 240, loss: 0.0002620972227305174
step: 250, loss: 2.490619954187423e-05
step: 260, loss: 7.648357131984085e-05
step: 270, loss: 2.1386293155956082e-05
step: 280, loss: 4.949289359501563e-05
step: 290, loss: 4.985183113603853e-05
step: 300, loss: 1.3243298781162594e-05
step: 310, loss: 3.6865567381028086e-05
step: 320, loss: 5.934078944846988e-05
step: 330, loss: 1.7493504856247455e-05
step: 340, loss: 3.222526720492169e-05
step: 350, loss: 8.755475573707372e-05
step: 360, loss: 0.0001133314726757817
epoch 20: dev_f1=0.6666666666666667, f1=0.6666666666666667, best_f1=0.7065527065527066
