cuda
Device: cuda
step: 0, loss: 0.6846590042114258
step: 10, loss: 0.4491409957408905
step: 20, loss: 0.44362857937812805
step: 30, loss: 0.23670418560504913
step: 40, loss: 0.33593201637268066
step: 50, loss: 0.36246025562286377
step: 60, loss: 0.3121423125267029
step: 70, loss: 0.4220433533191681
step: 80, loss: 0.4207284152507782
step: 90, loss: 0.20316651463508606
step: 100, loss: 0.10993397235870361
step: 110, loss: 0.3837665021419525
step: 120, loss: 0.278632253408432
step: 130, loss: 0.428419291973114
step: 140, loss: 0.2390950322151184
step: 150, loss: 0.14654035866260529
step: 160, loss: 0.15857313573360443
step: 170, loss: 0.3176696002483368
step: 180, loss: 0.3121279180049896
step: 190, loss: 0.3073282539844513
step: 200, loss: 0.19333791732788086
step: 210, loss: 0.2033088356256485
step: 220, loss: 0.2193271815776825
step: 230, loss: 0.17762748897075653
step: 240, loss: 0.12205574661493301
step: 250, loss: 0.1917954534292221
step: 260, loss: 0.13384264707565308
step: 270, loss: 0.1537846326828003
step: 280, loss: 0.19319310784339905
step: 290, loss: 0.19311979413032532
step: 300, loss: 0.21672651171684265
step: 310, loss: 0.2004469335079193
step: 320, loss: 0.31327107548713684
step: 330, loss: 0.32521775364875793
step: 340, loss: 0.16936960816383362
step: 350, loss: 0.14653097093105316
step: 360, loss: 0.349216103553772
step: 370, loss: 0.09154673665761948
step: 380, loss: 0.1398865431547165
step: 390, loss: 0.12084688246250153
step: 400, loss: 0.5551694631576538
step: 410, loss: 0.15729595720767975
step: 420, loss: 0.18406958878040314
step: 430, loss: 0.12268078327178955
step: 440, loss: 0.14766450226306915
step: 450, loss: 0.22606226801872253
step: 460, loss: 0.2600533366203308
epoch 1: dev_f1=0.9707865168539327, f1=0.9400921658986175, best_f1=0.9400921658986175
step: 0, loss: 0.21698135137557983
step: 10, loss: 0.0721907839179039
step: 20, loss: 0.12882061302661896
step: 30, loss: 0.12901568412780762
step: 40, loss: 0.16046234965324402
step: 50, loss: 0.21629226207733154
step: 60, loss: 0.17508970201015472
step: 70, loss: 0.022983543574810028
step: 80, loss: 0.14327125251293182
step: 90, loss: 0.13544121384620667
step: 100, loss: 0.07665010541677475
step: 110, loss: 0.08297798782587051
step: 120, loss: 0.18290233612060547
step: 130, loss: 0.05254708230495453
step: 140, loss: 0.16029153764247894
step: 150, loss: 0.23296460509300232
step: 160, loss: 0.1583710014820099
step: 170, loss: 0.06727034598588943
step: 180, loss: 0.094327412545681
step: 190, loss: 0.05699964240193367
step: 200, loss: 0.11864135414361954
step: 210, loss: 0.0780593752861023
step: 220, loss: 0.1807599663734436
step: 230, loss: 0.3187400698661804
step: 240, loss: 0.27657240629196167
step: 250, loss: 0.188252255320549
step: 260, loss: 0.01788087747991085
step: 270, loss: 0.18961499631404877
step: 280, loss: 0.12410924583673477
step: 290, loss: 0.32589590549468994
step: 300, loss: 0.26159965991973877
step: 310, loss: 0.25094497203826904
step: 320, loss: 0.2788345515727997
step: 330, loss: 0.06380468606948853
step: 340, loss: 0.2613941431045532
step: 350, loss: 0.03921972215175629
step: 360, loss: 0.10587038844823837
step: 370, loss: 0.27717339992523193
step: 380, loss: 0.16168217360973358
step: 390, loss: 0.14892910420894623
step: 400, loss: 0.10810552537441254
step: 410, loss: 0.21380431950092316
step: 420, loss: 0.16587258875370026
step: 430, loss: 0.23312780261039734
step: 440, loss: 0.08088454604148865
step: 450, loss: 0.20965605974197388
step: 460, loss: 0.2704603374004364
epoch 2: dev_f1=0.9753914988814317, f1=0.9673790776152981, best_f1=0.9673790776152981
step: 0, loss: 0.052817799150943756
step: 10, loss: 0.09150897711515427
step: 20, loss: 0.08704157918691635
step: 30, loss: 0.030029714107513428
step: 40, loss: 0.025588832795619965
step: 50, loss: 0.24769066274166107
step: 60, loss: 0.051264435052871704
step: 70, loss: 0.0812944546341896
step: 80, loss: 0.08545486629009247
step: 90, loss: 0.17906013131141663
step: 100, loss: 0.10830283164978027
step: 110, loss: 0.24464769661426544
step: 120, loss: 0.047949254512786865
step: 130, loss: 0.04350113123655319
step: 140, loss: 0.010647726245224476
step: 150, loss: 0.05412745103240013
step: 160, loss: 0.0538661926984787
step: 170, loss: 0.1507849097251892
step: 180, loss: 0.10356300324201584
step: 190, loss: 0.029366590082645416
step: 200, loss: 0.276340126991272
step: 210, loss: 0.2483491152524948
step: 220, loss: 0.055741168558597565
step: 230, loss: 0.018187733367085457
step: 240, loss: 0.070254847407341
step: 250, loss: 0.030183319002389908
step: 260, loss: 0.03600780665874481
step: 270, loss: 0.07630792260169983
step: 280, loss: 0.01090240478515625
step: 290, loss: 0.07877176254987717
step: 300, loss: 0.024579117074608803
step: 310, loss: 0.08315395563840866
step: 320, loss: 0.25317421555519104
step: 330, loss: 0.06831463426351547
step: 340, loss: 0.07073837518692017
step: 350, loss: 0.23963218927383423
step: 360, loss: 0.08046377450227737
step: 370, loss: 0.17485284805297852
step: 380, loss: 0.1478019654750824
step: 390, loss: 0.021664677187800407
step: 400, loss: 0.12536154687404633
step: 410, loss: 0.0267991591244936
step: 420, loss: 0.030390210449695587
step: 430, loss: 0.0736701637506485
step: 440, loss: 0.07589532434940338
step: 450, loss: 0.052823081612586975
step: 460, loss: 0.13177788257598877
epoch 3: dev_f1=0.9681668496158068, f1=0.9680264608599779, best_f1=0.9673790776152981
step: 0, loss: 0.07269085198640823
step: 10, loss: 0.1451953649520874
step: 20, loss: 0.055975161492824554
step: 30, loss: 0.024262895807623863
step: 40, loss: 0.11955051869153976
step: 50, loss: 0.12927909195423126
step: 60, loss: 0.020472198724746704
step: 70, loss: 0.07970747351646423
step: 80, loss: 0.012264465913176537
step: 90, loss: 0.08733218163251877
step: 100, loss: 0.04825286567211151
step: 110, loss: 0.06953413784503937
step: 120, loss: 0.09160880744457245
step: 130, loss: 0.06709173321723938
step: 140, loss: 0.01516412291675806
step: 150, loss: 0.4583638608455658
step: 160, loss: 0.0416310615837574
step: 170, loss: 0.028297213837504387
step: 180, loss: 0.013755200430750847
step: 190, loss: 0.14424942433834076
step: 200, loss: 0.01447125431150198
step: 210, loss: 0.06543490290641785
step: 220, loss: 0.05599093809723854
step: 230, loss: 0.03779465705156326
step: 240, loss: 0.13918551802635193
step: 250, loss: 0.09733057022094727
step: 260, loss: 0.015872346237301826
step: 270, loss: 0.008233129978179932
step: 280, loss: 0.05136440694332123
step: 290, loss: 0.061646975576877594
step: 300, loss: 0.042070455849170685
step: 310, loss: 0.03701300919055939
step: 320, loss: 0.01473158597946167
step: 330, loss: 0.010286394506692886
step: 340, loss: 0.048788588494062424
step: 350, loss: 0.05587496981024742
step: 360, loss: 0.18622848391532898
step: 370, loss: 0.18544180691242218
step: 380, loss: 0.0360768586397171
step: 390, loss: 0.3061470091342926
step: 400, loss: 0.0910354033112526
step: 410, loss: 0.028756003826856613
step: 420, loss: 0.08358738571405411
step: 430, loss: 0.024960709735751152
step: 440, loss: 0.0045426213182508945
step: 450, loss: 0.07359706610441208
step: 460, loss: 0.01957235112786293
epoch 4: dev_f1=0.9798206278026906, f1=0.9718785151856018, best_f1=0.9718785151856018
step: 0, loss: 0.02477938123047352
step: 10, loss: 0.009353838860988617
step: 20, loss: 0.0062571377493441105
step: 30, loss: 0.25154757499694824
step: 40, loss: 0.006340810563415289
step: 50, loss: 0.08006516098976135
step: 60, loss: 0.011479872278869152
step: 70, loss: 0.03343961387872696
step: 80, loss: 0.011797580868005753
step: 90, loss: 0.020799344405531883
step: 100, loss: 0.026565227657556534
step: 110, loss: 0.007848863489925861
step: 120, loss: 0.07690595835447311
step: 130, loss: 0.0019256698433309793
step: 140, loss: 0.007982777431607246
step: 150, loss: 0.005373814608901739
step: 160, loss: 0.010424830950796604
step: 170, loss: 0.0609094463288784
step: 180, loss: 0.053875263780355453
step: 190, loss: 0.06172051280736923
step: 200, loss: 0.011386186815798283
step: 210, loss: 0.050221286714076996
step: 220, loss: 0.0032619761768728495
step: 230, loss: 0.04006734862923622
step: 240, loss: 0.0036123967729508877
step: 250, loss: 0.16269052028656006
step: 260, loss: 0.06827860325574875
step: 270, loss: 0.10084701329469681
step: 280, loss: 0.08200385421514511
step: 290, loss: 0.008878136053681374
step: 300, loss: 0.00600449088960886
step: 310, loss: 0.006708782631903887
step: 320, loss: 0.09895835071802139
step: 330, loss: 0.05707959085702896
step: 340, loss: 0.005395119544118643
step: 350, loss: 0.08249039947986603
step: 360, loss: 0.09139129519462585
step: 370, loss: 0.045872922986745834
step: 380, loss: 0.07789580523967743
step: 390, loss: 0.1205776259303093
step: 400, loss: 0.1680580973625183
step: 410, loss: 0.03374437615275383
step: 420, loss: 0.020246321335434914
step: 430, loss: 0.008566868491470814
step: 440, loss: 0.04777117446064949
step: 450, loss: 0.0016539039788767695
step: 460, loss: 0.11557354778051376
epoch 5: dev_f1=0.978675645342312, f1=0.976324689966178, best_f1=0.9718785151856018
step: 0, loss: 0.006910645868629217
step: 10, loss: 0.0019495883025228977
step: 20, loss: 0.002457529306411743
step: 30, loss: 0.00195723632350564
step: 40, loss: 0.0018781023100018501
step: 50, loss: 0.003763890592381358
step: 60, loss: 0.006394387688487768
step: 70, loss: 0.013332613743841648
step: 80, loss: 0.005302628967911005
step: 90, loss: 0.018312202766537666
step: 100, loss: 0.015708906576037407
step: 110, loss: 0.0038007141556590796
step: 120, loss: 0.056161075830459595
step: 130, loss: 0.008830694481730461
step: 140, loss: 0.025877494364976883
step: 150, loss: 0.0029298379085958004
step: 160, loss: 0.0043514990247786045
step: 170, loss: 0.002086654771119356
step: 180, loss: 0.011446799151599407
step: 190, loss: 0.018665699288249016
step: 200, loss: 0.004846054594963789
step: 210, loss: 0.01297217421233654
step: 220, loss: 0.022319797426462173
step: 230, loss: 0.013817674480378628
step: 240, loss: 0.04902714490890503
step: 250, loss: 0.001416842802427709
step: 260, loss: 0.004112956114113331
step: 270, loss: 0.05155391991138458
step: 280, loss: 0.003881675424054265
step: 290, loss: 0.004676174838095903
step: 300, loss: 0.0032756796572357416
step: 310, loss: 0.010364724323153496
step: 320, loss: 0.06878554075956345
step: 330, loss: 0.07444823533296585
step: 340, loss: 0.12611648440361023
step: 350, loss: 0.001391393132507801
step: 360, loss: 0.03339429199695587
step: 370, loss: 0.10145963728427887
step: 380, loss: 0.023426376283168793
step: 390, loss: 0.09805300086736679
step: 400, loss: 0.001633784850127995
step: 410, loss: 0.052336081862449646
step: 420, loss: 0.09825240820646286
step: 430, loss: 0.014450207352638245
step: 440, loss: 0.009468481875956059
step: 450, loss: 0.005290572997182608
step: 460, loss: 0.21362772583961487
epoch 6: dev_f1=0.984090909090909, f1=0.9594438006952491, best_f1=0.9594438006952491
step: 0, loss: 0.007882633246481419
step: 10, loss: 0.013453521765768528
step: 20, loss: 0.021030638366937637
step: 30, loss: 0.11413412541151047
step: 40, loss: 0.0018552246037870646
step: 50, loss: 0.022895371541380882
step: 60, loss: 0.010256117209792137
step: 70, loss: 0.006358742248266935
step: 80, loss: 0.001295879832468927
step: 90, loss: 0.006474857684224844
step: 100, loss: 0.0006606653332710266
step: 110, loss: 0.00039335276233032346
step: 120, loss: 0.0015987257938832045
step: 130, loss: 0.14638471603393555
step: 140, loss: 0.0011424365220591426
step: 150, loss: 0.0027648259419947863
step: 160, loss: 0.00574495829641819
step: 170, loss: 0.0036680311895906925
step: 180, loss: 0.10487396270036697
step: 190, loss: 0.0027349551673978567
step: 200, loss: 0.0037998745683580637
step: 210, loss: 0.010629763826727867
step: 220, loss: 0.007097703404724598
step: 230, loss: 0.003497747704386711
step: 240, loss: 0.009008652530610561
step: 250, loss: 0.0028878345619887114
step: 260, loss: 0.0020082120317965746
step: 270, loss: 0.02105354517698288
step: 280, loss: 0.0011980249546468258
step: 290, loss: 0.013961655087769032
step: 300, loss: 0.0006185882375575602
step: 310, loss: 0.009390910156071186
step: 320, loss: 0.0017400458455085754
step: 330, loss: 0.009431428276002407
step: 340, loss: 0.06854214519262314
step: 350, loss: 0.026562685146927834
step: 360, loss: 0.010249230079352856
step: 370, loss: 0.0364217646420002
step: 380, loss: 0.027184411883354187
step: 390, loss: 0.005718545988202095
step: 400, loss: 0.13593623042106628
step: 410, loss: 0.007642953656613827
step: 420, loss: 0.20708906650543213
step: 430, loss: 0.0149223068729043
step: 440, loss: 0.016837015748023987
step: 450, loss: 0.0019206703873351216
step: 460, loss: 0.027353284880518913
epoch 7: dev_f1=0.9810055865921787, f1=0.9765886287625419, best_f1=0.9594438006952491
step: 0, loss: 0.004564112517982721
step: 10, loss: 0.0011062424164265394
step: 20, loss: 0.0019887154921889305
step: 30, loss: 0.003404381452128291
step: 40, loss: 0.004742610268294811
step: 50, loss: 0.004391340538859367
step: 60, loss: 0.020010931417346
step: 70, loss: 0.0010698140831664205
step: 80, loss: 0.005664371419698
step: 90, loss: 0.0006336452788673341
step: 100, loss: 0.010740524157881737
step: 110, loss: 0.00031438557198271155
step: 120, loss: 0.003950783051550388
step: 130, loss: 0.0040635643526911736
step: 140, loss: 0.0020375570748001337
step: 150, loss: 0.039389099925756454
step: 160, loss: 0.0004239455156493932
step: 170, loss: 0.07208409905433655
step: 180, loss: 0.03480418771505356
step: 190, loss: 0.0021570574026554823
step: 200, loss: 0.06091800704598427
step: 210, loss: 0.11642768234014511
step: 220, loss: 0.027718324214220047
step: 230, loss: 0.0045371390879154205
step: 240, loss: 0.0009756280342116952
step: 250, loss: 0.0023888270370662212
step: 260, loss: 0.0010987730929628015
step: 270, loss: 0.023085758090019226
step: 280, loss: 0.0029594339430332184
step: 290, loss: 0.019341042265295982
step: 300, loss: 0.012227647006511688
step: 310, loss: 0.010965671390295029
step: 320, loss: 0.0004454410809557885
step: 330, loss: 0.0008604347240179777
step: 340, loss: 0.010888141579926014
step: 350, loss: 0.06475266069173813
step: 360, loss: 0.0014753822470083833
step: 370, loss: 0.001780030783265829
step: 380, loss: 0.0022488776594400406
step: 390, loss: 0.004587899427860975
step: 400, loss: 0.005895313806831837
step: 410, loss: 0.011468823999166489
step: 420, loss: 0.013709977269172668
step: 430, loss: 0.024272337555885315
step: 440, loss: 0.001341201364994049
step: 450, loss: 0.0840105339884758
step: 460, loss: 0.0019175921333953738
epoch 8: dev_f1=0.9829738933030647, f1=0.9621125143513203, best_f1=0.9594438006952491
step: 0, loss: 0.045135024935007095
step: 10, loss: 0.004795091226696968
step: 20, loss: 0.004160748329013586
step: 30, loss: 0.0006161070778034627
step: 40, loss: 0.002271493896842003
step: 50, loss: 0.000721497752238065
step: 60, loss: 0.006286018528044224
step: 70, loss: 0.001120783039368689
step: 80, loss: 0.0031557471957057714
step: 90, loss: 0.0004214686923660338
step: 100, loss: 0.0003617769980337471
step: 110, loss: 0.0008228127844631672
step: 120, loss: 0.016850462183356285
step: 130, loss: 0.003230528673157096
step: 140, loss: 0.0013912892900407314
step: 150, loss: 0.019315963611006737
step: 160, loss: 0.0011235387064516544
step: 170, loss: 0.00019817629072349519
step: 180, loss: 0.03287354111671448
step: 190, loss: 0.0003076487628277391
step: 200, loss: 0.0021160421893000603
step: 210, loss: 0.001320335315540433
step: 220, loss: 0.0005933334468863904
step: 230, loss: 0.07987313717603683
step: 240, loss: 0.0012093153782188892
step: 250, loss: 0.0058334521017968655
step: 260, loss: 0.03695300221443176
step: 270, loss: 0.0011918216478079557
step: 280, loss: 0.0022388207726180553
step: 290, loss: 0.0010865491349250078
step: 300, loss: 0.004005615599453449
step: 310, loss: 0.05208735540509224
step: 320, loss: 0.1183459609746933
step: 330, loss: 0.028290675953030586
step: 340, loss: 0.03801558539271355
step: 350, loss: 0.047556567937135696
step: 360, loss: 0.003980177454650402
step: 370, loss: 0.0027190910186618567
step: 380, loss: 0.06158274784684181
step: 390, loss: 0.0029317110311239958
step: 400, loss: 0.011234663426876068
step: 410, loss: 0.0011817165650427341
step: 420, loss: 0.07172646373510361
step: 430, loss: 0.05994177609682083
step: 440, loss: 0.019982334226369858
step: 450, loss: 0.0023489773739129305
step: 460, loss: 0.0189606174826622
epoch 9: dev_f1=0.987598647125141, f1=0.9670079635949943, best_f1=0.9670079635949943
step: 0, loss: 0.01689991168677807
step: 10, loss: 0.12202490121126175
step: 20, loss: 0.000409870088333264
step: 30, loss: 0.009009772911667824
step: 40, loss: 0.02320592850446701
step: 50, loss: 0.0017732740379869938
step: 60, loss: 0.00425331387668848
step: 70, loss: 0.0021718970965594053
step: 80, loss: 0.006146127358078957
step: 90, loss: 0.004566298797726631
step: 100, loss: 0.0006875550025142729
step: 110, loss: 0.0001660192501731217
step: 120, loss: 0.0007318687275983393
step: 130, loss: 0.011042102240025997
step: 140, loss: 0.00032462761737406254
step: 150, loss: 0.008843646384775639
step: 160, loss: 0.00274319457821548
step: 170, loss: 0.0005037684459239244
step: 180, loss: 0.005688011180609465
step: 190, loss: 0.0019757512491196394
step: 200, loss: 0.001119405496865511
step: 210, loss: 0.0004040806961711496
step: 220, loss: 0.16871003806591034
step: 230, loss: 0.09551560878753662
step: 240, loss: 0.003464438719674945
step: 250, loss: 0.024422936141490936
step: 260, loss: 0.07367680221796036
step: 270, loss: 0.013349900022149086
step: 280, loss: 0.01709526591002941
step: 290, loss: 0.003943705465644598
step: 300, loss: 0.16320806741714478
step: 310, loss: 0.007538063917309046
step: 320, loss: 0.0003214235184714198
step: 330, loss: 0.00018697600171435624
step: 340, loss: 0.002056491794064641
step: 350, loss: 0.00018875644309446216
step: 360, loss: 0.0014782935613766313
step: 370, loss: 0.013964110054075718
step: 380, loss: 0.0008857336943037808
step: 390, loss: 0.012793614529073238
step: 400, loss: 0.000200138078071177
step: 410, loss: 0.1022651344537735
step: 420, loss: 0.002567887306213379
step: 430, loss: 0.0005577491829171777
step: 440, loss: 0.00312027451582253
step: 450, loss: 0.0003413036174606532
step: 460, loss: 0.0496237650513649
epoch 10: dev_f1=0.9842696629213483, f1=0.9698996655518396, best_f1=0.9670079635949943
step: 0, loss: 0.015590417198836803
step: 10, loss: 9.009947825688869e-05
step: 20, loss: 0.00022928891121409833
step: 30, loss: 0.0200640968978405
step: 40, loss: 0.0001680039131315425
step: 50, loss: 0.0021587975788861513
step: 60, loss: 0.0002341584477107972
step: 70, loss: 0.014766082167625427
step: 80, loss: 0.0002303046203451231
step: 90, loss: 0.01319038961082697
step: 100, loss: 0.002519340720027685
step: 110, loss: 0.0012692896416410804
step: 120, loss: 0.05913769081234932
step: 130, loss: 0.0007119241636246443
step: 140, loss: 0.0002927520254161209
step: 150, loss: 0.0013889666879549623
step: 160, loss: 0.009275145828723907
step: 170, loss: 0.007923845201730728
step: 180, loss: 0.0003390272322576493
step: 190, loss: 0.0005103681469336152
step: 200, loss: 0.00019670538313221186
step: 210, loss: 0.00031059476896189153
step: 220, loss: 0.0012050970690324903
step: 230, loss: 0.0005189523799344897
step: 240, loss: 0.001220298116095364
step: 250, loss: 8.003709808690473e-05
step: 260, loss: 0.00027857552049681544
step: 270, loss: 0.0005081751733087003
step: 280, loss: 0.014972923323512077
step: 290, loss: 0.030666697770357132
step: 300, loss: 0.062300361692905426
step: 310, loss: 0.0035660723224282265
step: 320, loss: 0.0011623960454016924
step: 330, loss: 0.003115217899903655
step: 340, loss: 0.009256312623620033
step: 350, loss: 0.010020317509770393
step: 360, loss: 0.000985469901934266
step: 370, loss: 0.028154388070106506
step: 380, loss: 0.00032710013329051435
step: 390, loss: 0.0012782963458448648
step: 400, loss: 0.001118520158343017
step: 410, loss: 0.005544679705053568
step: 420, loss: 0.0011992153013125062
step: 430, loss: 0.0004829976533073932
step: 440, loss: 0.0005687463562935591
step: 450, loss: 0.009491771459579468
step: 460, loss: 0.0019348168279975653
epoch 11: dev_f1=0.9864864864864865, f1=0.9685393258426966, best_f1=0.9670079635949943
step: 0, loss: 0.006386349443346262
step: 10, loss: 0.0008487047743983567
step: 20, loss: 0.0007745081093162298
step: 30, loss: 0.04384030029177666
step: 40, loss: 0.0005366015830077231
step: 50, loss: 7.959741196827963e-05
step: 60, loss: 0.0011768864933401346
step: 70, loss: 9.292470349464566e-05
step: 80, loss: 0.003518193494528532
step: 90, loss: 0.004169171676039696
step: 100, loss: 0.004560633562505245
step: 110, loss: 0.0001379286841256544
step: 120, loss: 0.00023965717991814017
step: 130, loss: 8.698628516867757e-05
step: 140, loss: 0.001039797207340598
step: 150, loss: 6.187862891238183e-05
step: 160, loss: 0.00011446902499301359
step: 170, loss: 0.0003163264482282102
step: 180, loss: 0.00099870003759861
step: 190, loss: 0.0009642221266403794
step: 200, loss: 0.00039930653292685747
step: 210, loss: 0.00013603758998215199
step: 220, loss: 0.025157872587442398
step: 230, loss: 0.0003251396119594574
step: 240, loss: 0.001741893938742578
step: 250, loss: 9.056853014044464e-05
step: 260, loss: 0.0021825802978128195
step: 270, loss: 3.514327181619592e-05
step: 280, loss: 0.0010512887965887785
step: 290, loss: 0.00019942005746997893
step: 300, loss: 0.21230950951576233
step: 310, loss: 0.004900307860225439
step: 320, loss: 0.00021010775526519865
step: 330, loss: 0.00011374911264283583
step: 340, loss: 7.993460894795135e-05
step: 350, loss: 0.006157443393021822
step: 360, loss: 0.006497016176581383
step: 370, loss: 0.00012792141933459789
step: 380, loss: 0.0005814220639877021
step: 390, loss: 0.0010912902653217316
step: 400, loss: 0.0020350066479295492
step: 410, loss: 0.0006132715498097241
step: 420, loss: 0.0018553739646449685
step: 430, loss: 0.0006289488519541919
step: 440, loss: 0.0021409171167761087
step: 450, loss: 0.00012127442460041493
step: 460, loss: 0.05807775631546974
epoch 12: dev_f1=0.9864864864864865, f1=0.9696969696969697, best_f1=0.9670079635949943
step: 0, loss: 0.030292946845293045
step: 10, loss: 0.00015747906581964344
step: 20, loss: 0.018546087667346
step: 30, loss: 0.0031820398289710283
step: 40, loss: 0.0007817134610377252
step: 50, loss: 0.021363859996199608
step: 60, loss: 0.015200135298073292
step: 70, loss: 8.264655480161309e-05
step: 80, loss: 0.004414177034050226
step: 90, loss: 0.017600644379854202
step: 100, loss: 0.0019929828122258186
step: 110, loss: 0.00045581889571622014
step: 120, loss: 0.004875291604548693
step: 130, loss: 0.0004918776103295386
step: 140, loss: 0.0007298308191820979
step: 150, loss: 0.023517608642578125
step: 160, loss: 0.00013667972234543413
step: 170, loss: 0.008508321829140186
step: 180, loss: 0.0004386719665490091
step: 190, loss: 9.94679139694199e-05
step: 200, loss: 0.00020988554751966149
step: 210, loss: 0.07454586029052734
step: 220, loss: 0.00015093362890183926
step: 230, loss: 0.021022070199251175
step: 240, loss: 0.0022855999413877726
step: 250, loss: 0.02385932393372059
step: 260, loss: 0.0014086763840168715
step: 270, loss: 0.00035467659472487867
step: 280, loss: 0.00025050059775821865
step: 290, loss: 0.029513448476791382
step: 300, loss: 0.0013708716724067926
step: 310, loss: 4.437526149558835e-05
step: 320, loss: 0.0007302840822376311
step: 330, loss: 0.0008650923846289515
step: 340, loss: 0.04718022793531418
step: 350, loss: 0.0026251927483826876
step: 360, loss: 0.00011059871030738577
step: 370, loss: 0.01587262563407421
step: 380, loss: 0.00023636725381948054
step: 390, loss: 0.0013995160115882754
step: 400, loss: 0.0212218277156353
step: 410, loss: 0.00047953022294677794
step: 420, loss: 0.0007480622152797878
step: 430, loss: 0.0010202837875112891
step: 440, loss: 0.02615954726934433
step: 450, loss: 0.02291261777281761
step: 460, loss: 0.004727648105472326
epoch 13: dev_f1=0.9832026875699889, f1=0.9720670391061451, best_f1=0.9670079635949943
step: 0, loss: 0.001707258983515203
step: 10, loss: 0.005406971089541912
step: 20, loss: 0.001916468609124422
step: 30, loss: 0.0031358464621007442
step: 40, loss: 8.801271906122565e-05
step: 50, loss: 0.03281040117144585
step: 60, loss: 8.769733540248126e-05
step: 70, loss: 0.00024051991931628436
step: 80, loss: 9.331976616522297e-05
step: 90, loss: 0.0008949453476816416
step: 100, loss: 0.03718053549528122
step: 110, loss: 0.0002738882030826062
step: 120, loss: 0.0008927633170969784
step: 130, loss: 4.927106783725321e-05
step: 140, loss: 6.073069016565569e-05
step: 150, loss: 0.002159097231924534
step: 160, loss: 0.0006998496246524155
step: 170, loss: 8.790745778242126e-05
step: 180, loss: 6.516832945635542e-05
step: 190, loss: 0.00014092052879277617
step: 200, loss: 0.00011041739344364032
step: 210, loss: 0.00013617071090266109
step: 220, loss: 3.993016798631288e-05
step: 230, loss: 0.0011541543062776327
step: 240, loss: 0.001323149655945599
step: 250, loss: 0.0013666379963979125
step: 260, loss: 0.0011831740848720074
step: 270, loss: 0.0010715273674577475
step: 280, loss: 0.00014417145575862378
step: 290, loss: 0.00010616688086884096
step: 300, loss: 0.02725277841091156
step: 310, loss: 7.554938201792538e-05
step: 320, loss: 7.336372800637037e-05
step: 330, loss: 0.00023337402672041208
step: 340, loss: 6.376440433086827e-05
step: 350, loss: 0.04533909261226654
step: 360, loss: 5.8089666708838195e-05
step: 370, loss: 0.0005873036570847034
step: 380, loss: 0.012979957275092602
step: 390, loss: 8.088500908343121e-05
step: 400, loss: 0.00016940759087447077
step: 410, loss: 0.0061364746652543545
step: 420, loss: 0.011144442483782768
step: 430, loss: 0.005019774194806814
step: 440, loss: 4.421346238814294e-05
step: 450, loss: 2.492179010005202e-05
step: 460, loss: 0.0001995676866499707
epoch 14: dev_f1=0.9853107344632768, f1=0.9694224235560589, best_f1=0.9670079635949943
step: 0, loss: 6.608382682316005e-05
step: 10, loss: 0.00015305928536690772
step: 20, loss: 7.033570000203326e-05
step: 30, loss: 0.00036465286393649876
step: 40, loss: 0.0003218992205802351
step: 50, loss: 0.0006389489863067865
step: 60, loss: 0.0005703099886886775
step: 70, loss: 0.0068650804460048676
step: 80, loss: 0.003889882704243064
step: 90, loss: 5.3987772844266146e-05
step: 100, loss: 4.60494848084636e-05
step: 110, loss: 0.000154259309056215
step: 120, loss: 0.0005287890089675784
step: 130, loss: 0.0011065221624448895
step: 140, loss: 7.53454296500422e-05
step: 150, loss: 0.0007369350641965866
step: 160, loss: 0.002084231236949563
step: 170, loss: 0.00013185240095481277
step: 180, loss: 0.00017604767344892025
step: 190, loss: 6.840111745987087e-05
step: 200, loss: 0.000117470022814814
step: 210, loss: 0.038147956132888794
step: 220, loss: 0.0013266997411847115
step: 230, loss: 0.00012524407065939158
step: 240, loss: 0.0006975338328629732
step: 250, loss: 4.1274004615843296e-05
step: 260, loss: 6.577483873115852e-05
step: 270, loss: 0.00015739270020276308
step: 280, loss: 0.0002841453533619642
step: 290, loss: 0.0010375322308391333
step: 300, loss: 0.00011825883120764047
step: 310, loss: 0.004098996985703707
step: 320, loss: 0.0060257562436163425
step: 330, loss: 0.03714636340737343
step: 340, loss: 6.241298979148269e-05
step: 350, loss: 0.0003037767601199448
step: 360, loss: 4.335704943514429e-05
step: 370, loss: 0.000593733973801136
step: 380, loss: 3.077762812608853e-05
step: 390, loss: 0.0008052710327319801
step: 400, loss: 0.0005613110843114555
step: 410, loss: 0.0003145334776490927
step: 420, loss: 6.255347398109734e-05
step: 430, loss: 0.04345625638961792
step: 440, loss: 0.00027095695259049535
step: 450, loss: 6.816455424996093e-05
step: 460, loss: 0.0008826265693642199
epoch 15: dev_f1=0.9853438556933484, f1=0.971815107102593, best_f1=0.9670079635949943
step: 0, loss: 0.00046734046190977097
step: 10, loss: 0.0004322357417549938
step: 20, loss: 5.19304012414068e-05
step: 30, loss: 0.0029933240730315447
step: 40, loss: 0.0035552203189581633
step: 50, loss: 0.002819359302520752
step: 60, loss: 0.0003859304706566036
step: 70, loss: 0.0007379979942925274
step: 80, loss: 8.834534673951566e-05
step: 90, loss: 0.0001292759261559695
step: 100, loss: 6.28426278126426e-05
step: 110, loss: 7.861844642320648e-05
step: 120, loss: 0.0015824632719159126
step: 130, loss: 2.792029954434838e-05
step: 140, loss: 0.00021347776055335999
step: 150, loss: 0.011439791880548
step: 160, loss: 2.3919623345136642e-05
step: 170, loss: 5.3500400099437684e-05
step: 180, loss: 0.00022419288870878518
step: 190, loss: 2.517110260669142e-05
step: 200, loss: 0.00018522563914302737
step: 210, loss: 0.008470382541418076
step: 220, loss: 4.676374373957515e-05
step: 230, loss: 0.0012136423029005527
step: 240, loss: 0.00017713771376293153
step: 250, loss: 0.0045037176460027695
step: 260, loss: 0.0001082780581782572
step: 270, loss: 0.024828394874930382
step: 280, loss: 6.325128924800083e-05
step: 290, loss: 0.0007299413555301726
step: 300, loss: 2.948038854810875e-05
step: 310, loss: 0.00348011520691216
step: 320, loss: 0.0037216253113001585
step: 330, loss: 0.0015213025035336614
step: 340, loss: 0.03131397068500519
step: 350, loss: 0.00010696079698391259
step: 360, loss: 0.1120450496673584
step: 370, loss: 0.00011580934369703755
step: 380, loss: 8.000667730811983e-05
step: 390, loss: 0.004818276036530733
step: 400, loss: 0.020529622212052345
step: 410, loss: 0.00014937306696083397
step: 420, loss: 3.0679962947033346e-05
step: 430, loss: 0.0002003150584641844
step: 440, loss: 0.0456869937479496
step: 450, loss: 0.00020272514666430652
step: 460, loss: 0.00035213291994296014
epoch 16: dev_f1=0.9798206278026906, f1=0.9686800894854586, best_f1=0.9670079635949943
step: 0, loss: 4.98884437547531e-05
step: 10, loss: 0.00033108395291492343
step: 20, loss: 0.00020073572522960603
step: 30, loss: 0.0032052751630544662
step: 40, loss: 0.00023216812405735254
step: 50, loss: 0.0005156553816050291
step: 60, loss: 0.00047984294360503554
step: 70, loss: 2.4772587494226173e-05
step: 80, loss: 2.783096715575084e-05
step: 90, loss: 0.28715306520462036
step: 100, loss: 0.00046934105921536684
step: 110, loss: 3.5964883863925934e-05
step: 120, loss: 0.00016619324742350727
step: 130, loss: 0.0001848524552769959
step: 140, loss: 2.8113430744269863e-05
step: 150, loss: 0.0003516094875521958
step: 160, loss: 4.019622065243311e-05
step: 170, loss: 0.001097444910556078
step: 180, loss: 0.00017054069030564278
step: 190, loss: 7.56622976041399e-05
step: 200, loss: 6.344330904539675e-05
step: 210, loss: 3.597713657654822e-05
step: 220, loss: 4.2978972487617284e-05
step: 230, loss: 0.13337284326553345
step: 240, loss: 5.015230999561027e-05
step: 250, loss: 0.0010812045074999332
step: 260, loss: 0.0002136009425157681
step: 270, loss: 0.00012399650586303324
step: 280, loss: 4.004066431662068e-05
step: 290, loss: 0.001363706192933023
step: 300, loss: 4.857391104451381e-05
step: 310, loss: 4.9161171773448586e-05
step: 320, loss: 0.0014995443634688854
step: 330, loss: 0.010217713192105293
step: 340, loss: 3.969046156271361e-05
step: 350, loss: 0.00025161736994050443
step: 360, loss: 4.2848852899624035e-05
step: 370, loss: 2.4195165678975172e-05
step: 380, loss: 8.774374146014452e-05
step: 390, loss: 0.0004079533682670444
step: 400, loss: 0.02969946712255478
step: 410, loss: 0.002356180688366294
step: 420, loss: 4.867867028224282e-05
step: 430, loss: 0.0002462464035488665
step: 440, loss: 0.00012758786033373326
step: 450, loss: 0.001401460263878107
step: 460, loss: 9.486223279964179e-05
epoch 17: dev_f1=0.9776286353467561, f1=0.9698324022346367, best_f1=0.9670079635949943
step: 0, loss: 0.00085848179878667
step: 10, loss: 0.1053081527352333
step: 20, loss: 0.0002474097709637135
step: 30, loss: 3.753006603801623e-05
step: 40, loss: 0.00015239190543070436
step: 50, loss: 0.015185641124844551
step: 60, loss: 0.010666919872164726
step: 70, loss: 0.0011371702421456575
step: 80, loss: 5.461295950226486e-05
step: 90, loss: 0.00010736757394624874
step: 100, loss: 0.00011272348638158292
step: 110, loss: 0.00407423498108983
step: 120, loss: 0.00011558972619241104
step: 130, loss: 0.0004980388912372291
step: 140, loss: 0.00020700487948488444
step: 150, loss: 0.00018092404934577644
step: 160, loss: 4.682663711719215e-05
step: 170, loss: 0.00033824090496636927
step: 180, loss: 8.74003380886279e-05
step: 190, loss: 3.485243723844178e-05
step: 200, loss: 0.009134259074926376
step: 210, loss: 0.0002084038278553635
step: 220, loss: 3.368210309417918e-05
step: 230, loss: 9.681435767561197e-05
step: 240, loss: 0.00039625930367037654
step: 250, loss: 4.534193794825114e-05
step: 260, loss: 4.536803680821322e-05
step: 270, loss: 0.0005082876887172461
step: 280, loss: 3.286204082542099e-05
step: 290, loss: 6.613185541937128e-05
step: 300, loss: 0.0003694601182360202
step: 310, loss: 5.4552718211198226e-05
step: 320, loss: 0.00018969406664837152
step: 330, loss: 3.0843770218780264e-05
step: 340, loss: 6.905660848133266e-05
step: 350, loss: 0.0011846080888062716
step: 360, loss: 3.4096137824235484e-05
step: 370, loss: 3.3678486943244934e-05
step: 380, loss: 2.9316168365767226e-05
step: 390, loss: 0.00021522564929910004
step: 400, loss: 2.540205605328083e-05
step: 410, loss: 4.591806646203622e-05
step: 420, loss: 0.00019442626216914505
step: 430, loss: 5.2967989176977426e-05
step: 440, loss: 2.7245612727710977e-05
step: 450, loss: 0.00010690495400922373
step: 460, loss: 8.008226723177359e-05
epoch 18: dev_f1=0.9853107344632768, f1=0.9705882352941176, best_f1=0.9670079635949943
step: 0, loss: 0.00013280902931001037
step: 10, loss: 3.295926580904052e-05
step: 20, loss: 0.0002936877135653049
step: 30, loss: 0.00021425240265671164
step: 40, loss: 6.94295740686357e-05
step: 50, loss: 0.005098478868603706
step: 60, loss: 0.003839083481580019
step: 70, loss: 0.001170663395896554
step: 80, loss: 0.0009519851882942021
step: 90, loss: 0.0008533990476280451
step: 100, loss: 3.095143983955495e-05
step: 110, loss: 0.0010662934510037303
step: 120, loss: 8.0607169365976e-05
step: 130, loss: 2.4712337108212523e-05
step: 140, loss: 3.657407796708867e-05
step: 150, loss: 7.253668445628136e-05
step: 160, loss: 0.0003994872095063329
step: 170, loss: 0.01622546836733818
step: 180, loss: 1.6700249034329318e-05
step: 190, loss: 0.0001640495320316404
step: 200, loss: 0.00013445253716781735
step: 210, loss: 0.00013964534446131438
step: 220, loss: 5.909016908844933e-05
step: 230, loss: 0.03085365891456604
step: 240, loss: 0.00018731204909272492
step: 250, loss: 3.1417108402820304e-05
step: 260, loss: 0.0001657333195907995
step: 270, loss: 0.0068876007571816444
step: 280, loss: 8.220721792895347e-05
step: 290, loss: 0.00034960286575369537
step: 300, loss: 0.05108315125107765
step: 310, loss: 4.0767128666630015e-05
step: 320, loss: 6.745501741534099e-05
step: 330, loss: 0.00036504343734122813
step: 340, loss: 3.325328361825086e-05
step: 350, loss: 0.00970445852726698
step: 360, loss: 3.6226247175363824e-05
step: 370, loss: 2.2533893570653163e-05
step: 380, loss: 3.855112663586624e-05
step: 390, loss: 3.275868948549032e-05
step: 400, loss: 5.186724229133688e-05
step: 410, loss: 0.0005928922328166664
step: 420, loss: 3.082134571741335e-05
step: 430, loss: 2.954805313493125e-05
step: 440, loss: 9.286535350838676e-05
step: 450, loss: 0.003299236297607422
step: 460, loss: 0.00011699000606313348
epoch 19: dev_f1=0.9853768278965129, f1=0.9741282339707535, best_f1=0.9670079635949943
step: 0, loss: 4.8256548325298354e-05
step: 10, loss: 5.3440679039340466e-05
step: 20, loss: 2.099897938023787e-05
step: 30, loss: 3.869759530061856e-05
step: 40, loss: 1.5560359315713868e-05
step: 50, loss: 2.2965596144786105e-05
step: 60, loss: 2.2600655938731506e-05
step: 70, loss: 5.9676196542568505e-05
step: 80, loss: 8.981877181213349e-05
step: 90, loss: 1.7907195797306485e-05
step: 100, loss: 4.855844599660486e-05
step: 110, loss: 3.577105235308409e-05
step: 120, loss: 6.0124682931927964e-05
step: 130, loss: 3.059107984881848e-05
step: 140, loss: 0.00013088705600239336
step: 150, loss: 0.00011941981938434765
step: 160, loss: 0.000115231130621396
step: 170, loss: 4.7894547606119886e-05
step: 180, loss: 0.00012685007823165506
step: 190, loss: 1.5716797861387022e-05
step: 200, loss: 3.811912392848171e-05
step: 210, loss: 0.00025708507746458054
step: 220, loss: 4.679502308135852e-05
step: 230, loss: 5.234759009908885e-05
step: 240, loss: 0.00015658784832339734
step: 250, loss: 6.246271368581802e-05
step: 260, loss: 5.028005034546368e-05
step: 270, loss: 0.0014529909240081906
step: 280, loss: 6.653450691374019e-05
step: 290, loss: 0.00019460766634438187
step: 300, loss: 0.0024597656447440386
step: 310, loss: 0.00040140491910278797
step: 320, loss: 5.3370244131656364e-05
step: 330, loss: 0.007058380171656609
step: 340, loss: 0.0001956386404344812
step: 350, loss: 0.00023081025574356318
step: 360, loss: 5.874971247976646e-05
step: 370, loss: 2.9137843739590608e-05
step: 380, loss: 0.0002588194911368191
step: 390, loss: 6.59853030811064e-05
step: 400, loss: 6.840905552962795e-05
step: 410, loss: 9.976145520340651e-05
step: 420, loss: 0.00010598338849376887
step: 430, loss: 5.400906957220286e-05
step: 440, loss: 0.0003301957331132144
step: 450, loss: 2.1248686607577838e-05
step: 460, loss: 0.00010246528836432844
epoch 20: dev_f1=0.9853768278965129, f1=0.971815107102593, best_f1=0.9670079635949943
