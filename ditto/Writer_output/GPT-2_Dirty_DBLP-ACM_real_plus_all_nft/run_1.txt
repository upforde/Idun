cuda
Device: cuda
step: 0, loss: 0.9532933235168457
step: 10, loss: 0.600843071937561
step: 20, loss: 0.43246370553970337
step: 30, loss: 0.47160065174102783
step: 40, loss: 0.3020952045917511
step: 50, loss: 0.4506789743900299
step: 60, loss: 0.2463202178478241
step: 70, loss: 0.2696071267127991
step: 80, loss: 0.29807794094085693
step: 90, loss: 0.3478187918663025
step: 100, loss: 0.36304253339767456
step: 110, loss: 0.1010066568851471
step: 120, loss: 0.20487439632415771
step: 130, loss: 0.21527820825576782
step: 140, loss: 0.12272656708955765
step: 150, loss: 0.19390925765037537
step: 160, loss: 0.1336676925420761
step: 170, loss: 0.1287623792886734
step: 180, loss: 0.09816017746925354
step: 190, loss: 0.2710590064525604
step: 200, loss: 0.2701737880706787
step: 210, loss: 0.2605082094669342
step: 220, loss: 0.31151503324508667
step: 230, loss: 0.1477527618408203
step: 240, loss: 0.17760369181632996
step: 250, loss: 0.2358284592628479
step: 260, loss: 0.08722784370183945
step: 270, loss: 0.40541771054267883
step: 280, loss: 0.14486023783683777
step: 290, loss: 0.11845853179693222
step: 300, loss: 0.08460325747728348
step: 310, loss: 0.12164587527513504
step: 320, loss: 0.1118370071053505
step: 330, loss: 0.24424757063388824
step: 340, loss: 0.22152359783649445
step: 350, loss: 0.259836882352829
step: 360, loss: 0.34544625878334045
step: 370, loss: 0.20004016160964966
step: 380, loss: 0.36135783791542053
step: 390, loss: 0.39426207542419434
step: 400, loss: 0.2322980910539627
step: 410, loss: 0.22729991376399994
step: 420, loss: 0.18216338753700256
step: 430, loss: 0.22846320271492004
step: 440, loss: 0.17037907242774963
step: 450, loss: 0.43529000878334045
step: 460, loss: 0.1728726476430893
epoch 1: dev_f1=0.9730337078651685, f1=0.9774266365688488, best_f1=0.9774266365688488
step: 0, loss: 0.21474313735961914
step: 10, loss: 0.17514057457447052
step: 20, loss: 0.1808399111032486
step: 30, loss: 0.024818772450089455
step: 40, loss: 0.06808115541934967
step: 50, loss: 0.1677713245153427
step: 60, loss: 0.2015746533870697
step: 70, loss: 0.10398253053426743
step: 80, loss: 0.2041310966014862
step: 90, loss: 0.16337184607982635
step: 100, loss: 0.058530207723379135
step: 110, loss: 0.1786491721868515
step: 120, loss: 0.2345934957265854
step: 130, loss: 0.1933475136756897
step: 140, loss: 0.07109564542770386
step: 150, loss: 0.11283104121685028
step: 160, loss: 0.18149515986442566
step: 170, loss: 0.1315591186285019
step: 180, loss: 0.049493636935949326
step: 190, loss: 0.10756602883338928
step: 200, loss: 0.13584059476852417
step: 210, loss: 0.21433648467063904
step: 220, loss: 0.08595241606235504
step: 230, loss: 0.04872012138366699
step: 240, loss: 0.07337593287229538
step: 250, loss: 0.12272050976753235
step: 260, loss: 0.021106982603669167
step: 270, loss: 0.19428782165050507
step: 280, loss: 0.08998918533325195
step: 290, loss: 0.16183942556381226
step: 300, loss: 0.09198271483182907
step: 310, loss: 0.07711929082870483
step: 320, loss: 0.03789220377802849
step: 330, loss: 0.17807430028915405
step: 340, loss: 0.13990436494350433
step: 350, loss: 0.03834746778011322
step: 360, loss: 0.2087855488061905
step: 370, loss: 0.10572957992553711
step: 380, loss: 0.33626240491867065
step: 390, loss: 0.0700487270951271
step: 400, loss: 0.060970280319452286
step: 410, loss: 0.37699267268180847
step: 420, loss: 0.15848718583583832
step: 430, loss: 0.1471324861049652
step: 440, loss: 0.16983483731746674
step: 450, loss: 0.0845014899969101
step: 460, loss: 0.18304023146629333
epoch 2: dev_f1=0.9790055248618784, f1=0.9632107023411371, best_f1=0.9632107023411371
step: 0, loss: 0.04926085099577904
step: 10, loss: 0.15595754981040955
step: 20, loss: 0.1882753074169159
step: 30, loss: 0.0725105032324791
step: 40, loss: 0.0605059489607811
step: 50, loss: 0.10524559020996094
step: 60, loss: 0.2070644497871399
step: 70, loss: 0.1012522280216217
step: 80, loss: 0.1250898391008377
step: 90, loss: 0.274346262216568
step: 100, loss: 0.10916092246770859
step: 110, loss: 0.09889397770166397
step: 120, loss: 0.23713819682598114
step: 130, loss: 0.12641212344169617
step: 140, loss: 0.15151093900203705
step: 150, loss: 0.1361854076385498
step: 160, loss: 0.1555642932653427
step: 170, loss: 0.03251858800649643
step: 180, loss: 0.1056707575917244
step: 190, loss: 0.32428982853889465
step: 200, loss: 0.030719401314854622
step: 210, loss: 0.15812893211841583
step: 220, loss: 0.03231579437851906
step: 230, loss: 0.2155955731868744
step: 240, loss: 0.2011241465806961
step: 250, loss: 0.25735899806022644
step: 260, loss: 0.06205517053604126
step: 270, loss: 0.09404316544532776
step: 280, loss: 0.03347160667181015
step: 290, loss: 0.04156667739152908
step: 300, loss: 0.030043499544262886
step: 310, loss: 0.1780485212802887
step: 320, loss: 0.07967199385166168
step: 330, loss: 0.09371084719896317
step: 340, loss: 0.21296663582324982
step: 350, loss: 0.17276689410209656
step: 360, loss: 0.06728803366422653
step: 370, loss: 0.12912672758102417
step: 380, loss: 0.16372843086719513
step: 390, loss: 0.03579794988036156
step: 400, loss: 0.06753900647163391
step: 410, loss: 0.2085118144750595
step: 420, loss: 0.1469404697418213
step: 430, loss: 0.12667764723300934
step: 440, loss: 0.056341398507356644
step: 450, loss: 0.033599574118852615
step: 460, loss: 0.0741172730922699
epoch 3: dev_f1=0.9842696629213483, f1=0.9729119638826186, best_f1=0.9729119638826186
step: 0, loss: 0.03927583247423172
step: 10, loss: 0.020346106961369514
step: 20, loss: 0.05608702823519707
step: 30, loss: 0.004671911709010601
step: 40, loss: 0.033756569027900696
step: 50, loss: 0.009821394458413124
step: 60, loss: 0.06162611022591591
step: 70, loss: 0.07534975558519363
step: 80, loss: 0.04159194231033325
step: 90, loss: 0.017324209213256836
step: 100, loss: 0.0075438302010297775
step: 110, loss: 0.045651182532310486
step: 120, loss: 0.003818405559286475
step: 130, loss: 0.0069748274981975555
step: 140, loss: 0.06454747915267944
step: 150, loss: 0.05502774938941002
step: 160, loss: 0.1768983006477356
step: 170, loss: 0.026558764278888702
step: 180, loss: 0.3452014923095703
step: 190, loss: 0.023900287225842476
step: 200, loss: 0.14338630437850952
step: 210, loss: 0.01834258809685707
step: 220, loss: 0.013265172950923443
step: 230, loss: 0.03319243714213371
step: 240, loss: 0.2249569296836853
step: 250, loss: 0.07168009132146835
step: 260, loss: 0.04076215997338295
step: 270, loss: 0.15943755209445953
step: 280, loss: 0.03674975037574768
step: 290, loss: 0.04279955476522446
step: 300, loss: 0.08891363441944122
step: 310, loss: 0.09847889840602875
step: 320, loss: 0.0219655130058527
step: 330, loss: 0.031799424439668655
step: 340, loss: 0.053939808160066605
step: 350, loss: 0.11757192760705948
step: 360, loss: 0.050469834357500076
step: 370, loss: 0.01918783038854599
step: 380, loss: 0.09625383466482162
step: 390, loss: 0.05135316401720047
step: 400, loss: 0.4866766333580017
step: 410, loss: 0.018371783196926117
step: 420, loss: 0.036951661109924316
step: 430, loss: 0.03473996743559837
step: 440, loss: 0.005267259664833546
step: 450, loss: 0.058608055114746094
step: 460, loss: 0.03127497062087059
epoch 4: dev_f1=0.9864253393665158, f1=0.9612756264236902, best_f1=0.9612756264236902
step: 0, loss: 0.018006276339292526
step: 10, loss: 0.01306144893169403
step: 20, loss: 0.00981688592582941
step: 30, loss: 0.012396421283483505
step: 40, loss: 0.009454325772821903
step: 50, loss: 0.019991226494312286
step: 60, loss: 0.0029930146411061287
step: 70, loss: 0.004695450887084007
step: 80, loss: 0.019062286242842674
step: 90, loss: 0.00048629267257638276
step: 100, loss: 0.02294071391224861
step: 110, loss: 0.0014136623358353972
step: 120, loss: 0.015530765987932682
step: 130, loss: 0.02879461646080017
step: 140, loss: 0.07735635340213776
step: 150, loss: 0.02955908700823784
step: 160, loss: 0.13116545975208282
step: 170, loss: 0.011523519642651081
step: 180, loss: 0.2060391902923584
step: 190, loss: 0.014607408083975315
step: 200, loss: 0.10921991616487503
step: 210, loss: 0.028229715302586555
step: 220, loss: 0.03442450240254402
step: 230, loss: 0.024438971653580666
step: 240, loss: 0.0028248156886547804
step: 250, loss: 0.01229849923402071
step: 260, loss: 0.05288923159241676
step: 270, loss: 0.021184565499424934
step: 280, loss: 0.020205996930599213
step: 290, loss: 0.0023047735448926687
step: 300, loss: 0.0021197067108005285
step: 310, loss: 0.0412013866007328
step: 320, loss: 0.02884279564023018
step: 330, loss: 0.04724210500717163
step: 340, loss: 0.04170145466923714
step: 350, loss: 0.003930137027055025
step: 360, loss: 0.004392186179757118
step: 370, loss: 0.0637068822979927
step: 380, loss: 0.06052575260400772
step: 390, loss: 0.06982988864183426
step: 400, loss: 0.00991628784686327
step: 410, loss: 0.0009968973463401198
step: 420, loss: 0.17453573644161224
step: 430, loss: 0.08913635462522507
step: 440, loss: 0.015555372461676598
step: 450, loss: 0.05778849124908447
step: 460, loss: 0.09459608048200607
epoch 5: dev_f1=0.9863945578231292, f1=0.9635535307517085, best_f1=0.9612756264236902
step: 0, loss: 0.00907344650477171
step: 10, loss: 0.12781640887260437
step: 20, loss: 0.013097163289785385
step: 30, loss: 0.06329350173473358
step: 40, loss: 0.009314160794019699
step: 50, loss: 0.011901766993105412
step: 60, loss: 0.01447550393640995
step: 70, loss: 0.10629203170537949
step: 80, loss: 0.00991007685661316
step: 90, loss: 0.01230662688612938
step: 100, loss: 0.002370913978666067
step: 110, loss: 0.10909687727689743
step: 120, loss: 0.0006410255446098745
step: 130, loss: 0.0062547242268919945
step: 140, loss: 0.00041910450090654194
step: 150, loss: 0.006047149188816547
step: 160, loss: 0.060107920318841934
step: 170, loss: 0.0005911833140999079
step: 180, loss: 0.03166435286402702
step: 190, loss: 0.1867569088935852
step: 200, loss: 0.04260886460542679
step: 210, loss: 0.016213061287999153
step: 220, loss: 0.006366032641381025
step: 230, loss: 0.0004821153124794364
step: 240, loss: 0.0008747037500143051
step: 250, loss: 0.07876166701316833
step: 260, loss: 0.023953022435307503
step: 270, loss: 0.0056196535006165504
step: 280, loss: 0.0020508007146418095
step: 290, loss: 0.00977690052241087
step: 300, loss: 0.0013176711509004235
step: 310, loss: 0.0025976242031902075
step: 320, loss: 0.023416247218847275
step: 330, loss: 0.017017733305692673
step: 340, loss: 0.005021681543439627
step: 350, loss: 0.09790083020925522
step: 360, loss: 0.012253466993570328
step: 370, loss: 0.08962772786617279
step: 380, loss: 0.00032763785566203296
step: 390, loss: 0.015368416905403137
step: 400, loss: 0.0012591109843924642
step: 410, loss: 0.001568128471262753
step: 420, loss: 0.05393032729625702
step: 430, loss: 0.008209329098463058
step: 440, loss: 0.03438716381788254
step: 450, loss: 0.010863934643566608
step: 460, loss: 0.1668868213891983
epoch 6: dev_f1=0.9853768278965129, f1=0.9707207207207207, best_f1=0.9612756264236902
step: 0, loss: 0.017722992226481438
step: 10, loss: 0.010527350008487701
step: 20, loss: 0.0210985466837883
step: 30, loss: 0.06380756944417953
step: 40, loss: 0.00440790643915534
step: 50, loss: 0.0021413983777165413
step: 60, loss: 0.014149862341582775
step: 70, loss: 0.0017311583505943418
step: 80, loss: 0.010969643481075764
step: 90, loss: 0.001963288290426135
step: 100, loss: 0.17503774166107178
step: 110, loss: 0.12609753012657166
step: 120, loss: 0.006976996082812548
step: 130, loss: 0.10833494365215302
step: 140, loss: 0.0777164027094841
step: 150, loss: 0.006088110152631998
step: 160, loss: 0.06804009526968002
step: 170, loss: 0.002621493535116315
step: 180, loss: 0.005789006128907204
step: 190, loss: 0.0315619595348835
step: 200, loss: 0.009590947069227695
step: 210, loss: 0.01872972585260868
step: 220, loss: 0.0158382635563612
step: 230, loss: 0.00860538799315691
step: 240, loss: 0.0007137772045098245
step: 250, loss: 0.01050515379756689
step: 260, loss: 0.003787175752222538
step: 270, loss: 0.15175804495811462
step: 280, loss: 0.016604749485850334
step: 290, loss: 0.003658572444692254
step: 300, loss: 0.022697651758790016
step: 310, loss: 0.012427820824086666
step: 320, loss: 0.009243899025022984
step: 330, loss: 0.00584022281691432
step: 340, loss: 0.005193775985389948
step: 350, loss: 0.059862349182367325
step: 360, loss: 0.010497793555259705
step: 370, loss: 0.0018865048186853528
step: 380, loss: 0.01387813687324524
step: 390, loss: 0.004162920638918877
step: 400, loss: 0.000882396474480629
step: 410, loss: 0.10271871834993362
step: 420, loss: 0.0024715119507163763
step: 430, loss: 0.0006590704433619976
step: 440, loss: 0.013451572507619858
step: 450, loss: 0.00024822488194331527
step: 460, loss: 0.0013720866991207004
epoch 7: dev_f1=0.9820627802690582, f1=0.9718785151856018, best_f1=0.9612756264236902
step: 0, loss: 0.02829102799296379
step: 10, loss: 0.009570086374878883
step: 20, loss: 0.0008667305228300393
step: 30, loss: 0.0005780582432635128
step: 40, loss: 0.02286405675113201
step: 50, loss: 0.002010505413636565
step: 60, loss: 0.02894299104809761
step: 70, loss: 0.02441038377583027
step: 80, loss: 0.042772941291332245
step: 90, loss: 0.07824679464101791
step: 100, loss: 0.0013344602193683386
step: 110, loss: 0.011546582914888859
step: 120, loss: 0.014639299362897873
step: 130, loss: 0.02431992068886757
step: 140, loss: 0.0025612313766032457
step: 150, loss: 0.0008852750179357827
step: 160, loss: 0.04274456575512886
step: 170, loss: 0.005494519602507353
step: 180, loss: 0.015072884038090706
step: 190, loss: 0.0006391772185452282
step: 200, loss: 0.0007148684235289693
step: 210, loss: 0.0024699787609279156
step: 220, loss: 0.013296187855303288
step: 230, loss: 0.0007100724615156651
step: 240, loss: 0.005065534263849258
step: 250, loss: 0.003735253820195794
step: 260, loss: 0.02660045027732849
step: 270, loss: 0.0022869326639920473
step: 280, loss: 0.005458439234644175
step: 290, loss: 0.00044127958244644105
step: 300, loss: 0.01836462877690792
step: 310, loss: 0.0022897510789334774
step: 320, loss: 0.007748140022158623
step: 330, loss: 0.001327425125055015
step: 340, loss: 0.0017492923652753234
step: 350, loss: 0.02366865612566471
step: 360, loss: 0.06736185401678085
step: 370, loss: 0.00030473366496153176
step: 380, loss: 0.027087735012173653
step: 390, loss: 0.010808327235281467
step: 400, loss: 0.06879940629005432
step: 410, loss: 0.028772294521331787
step: 420, loss: 0.015248715877532959
step: 430, loss: 0.0029895962215960026
step: 440, loss: 0.003801866201683879
step: 450, loss: 0.053517088294029236
step: 460, loss: 0.003416778752580285
epoch 8: dev_f1=0.9843749999999999, f1=0.9731543624161074, best_f1=0.9612756264236902
step: 0, loss: 0.007173258811235428
step: 10, loss: 0.028510387986898422
step: 20, loss: 0.0015983838820829988
step: 30, loss: 0.20490872859954834
step: 40, loss: 0.007658934220671654
step: 50, loss: 0.0017102161655202508
step: 60, loss: 0.001681121182627976
step: 70, loss: 0.001728071365505457
step: 80, loss: 0.0007895123562775552
step: 90, loss: 0.04062435030937195
step: 100, loss: 0.021799379959702492
step: 110, loss: 0.018372898921370506
step: 120, loss: 0.004733216483145952
step: 130, loss: 0.006650439463555813
step: 140, loss: 0.0009160007466562092
step: 150, loss: 0.0020465694833546877
step: 160, loss: 0.009325917810201645
step: 170, loss: 0.00046453584218397737
step: 180, loss: 0.0009747323929332197
step: 190, loss: 0.0001640607079025358
step: 200, loss: 0.08018781244754791
step: 210, loss: 0.0022299354895949364
step: 220, loss: 0.004466688726097345
step: 230, loss: 0.0034574856981635094
step: 240, loss: 0.0029222748707979918
step: 250, loss: 0.006851132493466139
step: 260, loss: 0.0014638686552643776
step: 270, loss: 0.0034731070045381784
step: 280, loss: 0.0017276438884437084
step: 290, loss: 0.0007386449724435806
step: 300, loss: 0.001986798131838441
step: 310, loss: 0.06789598613977432
step: 320, loss: 0.0002471358166076243
step: 330, loss: 0.002961767604574561
step: 340, loss: 0.0008184955804608762
step: 350, loss: 0.006179588381201029
step: 360, loss: 0.0017263122135773301
step: 370, loss: 0.0025196196511387825
step: 380, loss: 0.0004149580199737102
step: 390, loss: 0.0005908830207772553
step: 400, loss: 0.1724861115217209
step: 410, loss: 0.006838817615061998
step: 420, loss: 0.0022519524209201336
step: 430, loss: 0.03828556835651398
step: 440, loss: 0.06133333221077919
step: 450, loss: 0.0007905340171419084
step: 460, loss: 0.00258889002725482
epoch 9: dev_f1=0.9876265466816648, f1=0.9775280898876404, best_f1=0.9775280898876404
step: 0, loss: 0.01056777685880661
step: 10, loss: 0.0007356127025559545
step: 20, loss: 0.008637755177915096
step: 30, loss: 0.005329260602593422
step: 40, loss: 0.00013739972200710326
step: 50, loss: 0.03644844517111778
step: 60, loss: 0.0012171609560027719
step: 70, loss: 0.002556099323555827
step: 80, loss: 0.000640246958937496
step: 90, loss: 0.0019494593143463135
step: 100, loss: 0.0009584844228811562
step: 110, loss: 0.0008784313686192036
step: 120, loss: 0.002445449586957693
step: 130, loss: 0.006341787986457348
step: 140, loss: 0.00017246228526346385
step: 150, loss: 0.0009709356818348169
step: 160, loss: 0.0006227729609236121
step: 170, loss: 0.000581169209908694
step: 180, loss: 0.0018320494564250112
step: 190, loss: 0.01081942394375801
step: 200, loss: 0.22100533545017242
step: 210, loss: 0.0005700751789845526
step: 220, loss: 0.0008607846684753895
step: 230, loss: 0.003593777073547244
step: 240, loss: 0.0006669457070529461
step: 250, loss: 0.003943170420825481
step: 260, loss: 5.860813325853087e-05
step: 270, loss: 0.002725952537730336
step: 280, loss: 0.0008721519843675196
step: 290, loss: 0.0003235330223105848
step: 300, loss: 0.015602889470756054
step: 310, loss: 0.0023579394910484552
step: 320, loss: 0.004000753629952669
step: 330, loss: 0.0001963590329978615
step: 340, loss: 0.0005032926565036178
step: 350, loss: 0.00011939030810026452
step: 360, loss: 0.012731190770864487
step: 370, loss: 0.0007343309698626399
step: 380, loss: 0.0024992702528834343
step: 390, loss: 0.0010481328936293721
step: 400, loss: 0.006627710536122322
step: 410, loss: 0.00031875038985162973
step: 420, loss: 0.0019922363571822643
step: 430, loss: 0.00051790481666103
step: 440, loss: 0.002269108546897769
step: 450, loss: 0.07825964689254761
step: 460, loss: 5.506638262886554e-05
epoch 10: dev_f1=0.9865168539325843, f1=0.9731543624161074, best_f1=0.9775280898876404
step: 0, loss: 0.00021683299564756453
step: 10, loss: 0.0028043983038514853
step: 20, loss: 0.001687456271611154
step: 30, loss: 0.0035618608817458153
step: 40, loss: 0.0020743058994412422
step: 50, loss: 0.0038956566713750362
step: 60, loss: 0.00020463886903598905
step: 70, loss: 0.00030520514701493084
step: 80, loss: 0.0007044114172458649
step: 90, loss: 0.010364560410380363
step: 100, loss: 0.009820074774324894
step: 110, loss: 0.00033865534351207316
step: 120, loss: 0.003741509048268199
step: 130, loss: 0.0009563164203427732
step: 140, loss: 0.0021365624852478504
step: 150, loss: 0.005588742904365063
step: 160, loss: 0.003659633919596672
step: 170, loss: 0.0001312643726123497
step: 180, loss: 0.002212424064055085
step: 190, loss: 0.0007753020618110895
step: 200, loss: 0.028389424085617065
step: 210, loss: 0.0014338151086121798
step: 220, loss: 0.0043569039553403854
step: 230, loss: 0.0020039004739373922
step: 240, loss: 0.000562335888389498
step: 250, loss: 0.001527842367067933
step: 260, loss: 0.0008949755574576557
step: 270, loss: 0.0013635909417644143
step: 280, loss: 0.0005087241879664361
step: 290, loss: 0.0005567899206653237
step: 300, loss: 0.00012534258712548763
step: 310, loss: 0.0007279464043676853
step: 320, loss: 5.234388663666323e-05
step: 330, loss: 0.013353914953768253
step: 340, loss: 0.0014412442687898874
step: 350, loss: 0.0024871102068573236
step: 360, loss: 0.0021903840824961662
step: 370, loss: 6.402377766789868e-05
step: 380, loss: 0.00014643420581705868
step: 390, loss: 0.0013425960205495358
step: 400, loss: 0.002598527353256941
step: 410, loss: 0.009256265126168728
step: 420, loss: 0.0006118446472100914
step: 430, loss: 0.020077725872397423
step: 440, loss: 0.01251065544784069
step: 450, loss: 0.000527987431269139
step: 460, loss: 0.03943907469511032
epoch 11: dev_f1=0.9864864864864865, f1=0.9706546275395034, best_f1=0.9775280898876404
step: 0, loss: 0.0013077931944280863
step: 10, loss: 0.01852908730506897
step: 20, loss: 0.0033810187596827745
step: 30, loss: 0.0009046941995620728
step: 40, loss: 0.0014194754185155034
step: 50, loss: 0.008621013723313808
step: 60, loss: 0.001116558793000877
step: 70, loss: 0.001605244935490191
step: 80, loss: 0.00038133651833049953
step: 90, loss: 0.009644526988267899
step: 100, loss: 0.001737662823870778
step: 110, loss: 0.0004106151172891259
step: 120, loss: 0.000561425753403455
step: 130, loss: 0.057899028062820435
step: 140, loss: 6.701306119794026e-05
step: 150, loss: 0.00032410051790066063
step: 160, loss: 0.0009329483727924526
step: 170, loss: 0.0005472695920616388
step: 180, loss: 0.006357180420309305
step: 190, loss: 0.0012325324350968003
step: 200, loss: 0.0015874735545367002
step: 210, loss: 0.003566805738955736
step: 220, loss: 0.005949122831225395
step: 230, loss: 0.022200748324394226
step: 240, loss: 6.858243432361633e-05
step: 250, loss: 0.00038010868593119085
step: 260, loss: 0.0001798900484573096
step: 270, loss: 0.0008697347366251051
step: 280, loss: 0.00011350771819707006
step: 290, loss: 0.0006890190998092294
step: 300, loss: 4.174864079686813e-05
step: 310, loss: 0.0009013854432851076
step: 320, loss: 0.0011997685069218278
step: 330, loss: 0.010962882079184055
step: 340, loss: 0.00013411336112767458
step: 350, loss: 0.002264495240524411
step: 360, loss: 0.0002217604487668723
step: 370, loss: 0.0010317767737433314
step: 380, loss: 0.00021335385099519044
step: 390, loss: 0.0011628747452050447
step: 400, loss: 0.0027747368440032005
step: 410, loss: 0.001474541611969471
step: 420, loss: 4.4300373701844364e-05
step: 430, loss: 0.00018102310423273593
step: 440, loss: 0.001842692494392395
step: 450, loss: 0.004691287875175476
step: 460, loss: 0.0020008778665214777
epoch 12: dev_f1=0.9853768278965129, f1=0.9730941704035874, best_f1=0.9775280898876404
step: 0, loss: 9.094805864151567e-05
step: 10, loss: 0.00014664145419374108
step: 20, loss: 0.0001618105743546039
step: 30, loss: 0.004287048242986202
step: 40, loss: 0.0005363582749851048
step: 50, loss: 0.0002497467794455588
step: 60, loss: 0.009545067325234413
step: 70, loss: 0.00018753063341137022
step: 80, loss: 7.435833686031401e-05
step: 90, loss: 3.6236466257832944e-05
step: 100, loss: 0.0002632438554428518
step: 110, loss: 0.04441095516085625
step: 120, loss: 0.00011147047916892916
step: 130, loss: 0.00024313674657605588
step: 140, loss: 6.836270040366799e-05
step: 150, loss: 0.00015830415941309184
step: 160, loss: 3.579410258680582e-05
step: 170, loss: 0.005470082629472017
step: 180, loss: 0.008593165315687656
step: 190, loss: 0.0013909117551520467
step: 200, loss: 0.0002115428651450202
step: 210, loss: 0.0011533488286659122
step: 220, loss: 0.0009632360888645053
step: 230, loss: 5.632666943711229e-05
step: 240, loss: 0.008552337996661663
step: 250, loss: 0.012780720368027687
step: 260, loss: 0.006951191928237677
step: 270, loss: 5.1751365390373394e-05
step: 280, loss: 0.00037084281211718917
step: 290, loss: 0.004050752613693476
step: 300, loss: 0.0013527360279113054
step: 310, loss: 0.0002629618102218956
step: 320, loss: 0.00013495607709046453
step: 330, loss: 0.00013084754755254835
step: 340, loss: 0.002928847214207053
step: 350, loss: 0.000457166344858706
step: 360, loss: 4.132646427024156e-05
step: 370, loss: 0.03037249483168125
step: 380, loss: 0.00033949172939173877
step: 390, loss: 0.0005912914639338851
step: 400, loss: 3.787217428907752e-05
step: 410, loss: 0.011366564780473709
step: 420, loss: 0.00010967992420773953
step: 430, loss: 0.000724001438356936
step: 440, loss: 7.137591455830261e-05
step: 450, loss: 0.00013501835928764194
step: 460, loss: 0.0029436659533530474
epoch 13: dev_f1=0.9831649831649831, f1=0.9720044792833147, best_f1=0.9775280898876404
step: 0, loss: 0.008942033164203167
step: 10, loss: 0.0014269994571805
step: 20, loss: 0.00010531870066188276
step: 30, loss: 0.00012026005424559116
step: 40, loss: 0.00048564973985776305
step: 50, loss: 0.004588190000504255
step: 60, loss: 0.003863561199977994
step: 70, loss: 0.0016296684043481946
step: 80, loss: 0.0006051142700016499
step: 90, loss: 4.065064786118455e-05
step: 100, loss: 0.0003945989010389894
step: 110, loss: 7.098283822415397e-05
step: 120, loss: 0.05050389841198921
step: 130, loss: 0.03227559104561806
step: 140, loss: 0.0005552566726692021
step: 150, loss: 0.0009612293797545135
step: 160, loss: 0.0001274227979592979
step: 170, loss: 0.0007278743432834744
step: 180, loss: 0.0006257286295294762
step: 190, loss: 0.0001243218721356243
step: 200, loss: 4.3530857510631904e-05
step: 210, loss: 0.00036597991129383445
step: 220, loss: 0.00020957115339115262
step: 230, loss: 0.00025167284184135497
step: 240, loss: 0.010865254327654839
step: 250, loss: 0.00025809905491769314
step: 260, loss: 0.001052779029123485
step: 270, loss: 0.00017755039152689278
step: 280, loss: 3.838260818156414e-05
step: 290, loss: 0.0001810260582715273
step: 300, loss: 0.0001937905908562243
step: 310, loss: 5.828004941577092e-05
step: 320, loss: 0.001034835004247725
step: 330, loss: 0.017702151089906693
step: 340, loss: 0.009516153484582901
step: 350, loss: 9.918947762344033e-05
step: 360, loss: 0.002246527001261711
step: 370, loss: 0.0001400486216880381
step: 380, loss: 0.000632694864179939
step: 390, loss: 0.0001042591902660206
step: 400, loss: 0.0003357395762577653
step: 410, loss: 0.029925063252449036
step: 420, loss: 0.00029351067496463656
step: 430, loss: 4.7903304221108556e-05
step: 440, loss: 6.309591844910756e-05
step: 450, loss: 0.0005200172890909016
step: 460, loss: 0.0003994072030764073
epoch 14: dev_f1=0.9844097995545658, f1=0.9658213891951488, best_f1=0.9775280898876404
step: 0, loss: 0.00017860991647467017
step: 10, loss: 0.00011356418690411374
step: 20, loss: 0.00045167701318860054
step: 30, loss: 0.188349649310112
step: 40, loss: 0.0012405645102262497
step: 50, loss: 0.00014103927242103964
step: 60, loss: 5.508286631084047e-05
step: 70, loss: 0.001116130268201232
step: 80, loss: 5.9121583035448566e-05
step: 90, loss: 0.001086398377083242
step: 100, loss: 0.011919823475182056
step: 110, loss: 0.00012354401405900717
step: 120, loss: 6.665335240541026e-05
step: 130, loss: 7.589163578813896e-05
step: 140, loss: 0.0002979917626362294
step: 150, loss: 5.6092467275448143e-05
step: 160, loss: 0.005218415055423975
step: 170, loss: 0.0016421166947111487
step: 180, loss: 0.00018720242951530963
step: 190, loss: 0.0004350341623649001
step: 200, loss: 0.003412434132769704
step: 210, loss: 8.78565406310372e-05
step: 220, loss: 7.670933700865135e-05
step: 230, loss: 0.00023129455803427845
step: 240, loss: 3.182770888088271e-05
step: 250, loss: 7.135415216907859e-05
step: 260, loss: 0.0002306880778633058
step: 270, loss: 0.0003477572463452816
step: 280, loss: 5.615522968582809e-05
step: 290, loss: 0.00023966825392562896
step: 300, loss: 0.007828774861991405
step: 310, loss: 7.9835117503535e-05
step: 320, loss: 0.12829381227493286
step: 330, loss: 0.0057687778025865555
step: 340, loss: 0.0018671416910365224
step: 350, loss: 4.862164132646285e-05
step: 360, loss: 0.0025432712864130735
step: 370, loss: 0.00018489366630092263
step: 380, loss: 0.006530566606670618
step: 390, loss: 0.00033438342506997287
step: 400, loss: 0.014966015703976154
step: 410, loss: 0.001139692380093038
step: 420, loss: 0.0016568491701036692
step: 430, loss: 0.0004245881282258779
step: 440, loss: 0.00011058667587349191
step: 450, loss: 0.0003964988572988659
step: 460, loss: 0.0007299294229596853
epoch 15: dev_f1=0.9854423292273236, f1=0.9742441209406495, best_f1=0.9775280898876404
step: 0, loss: 0.00036231111153028905
step: 10, loss: 0.00017020462837535888
step: 20, loss: 6.165779632283375e-05
step: 30, loss: 0.00010631301847752184
step: 40, loss: 6.671911251032725e-05
step: 50, loss: 0.0004363936895970255
step: 60, loss: 4.7641355195082724e-05
step: 70, loss: 0.0004331264353822917
step: 80, loss: 5.648915976053104e-05
step: 90, loss: 0.07111258804798126
step: 100, loss: 0.0007428409298881888
step: 110, loss: 0.00012324466661084443
step: 120, loss: 0.00020188873168081045
step: 130, loss: 7.443626236636192e-05
step: 140, loss: 2.5550360078341328e-05
step: 150, loss: 0.00028597027994692326
step: 160, loss: 0.0005342993536032736
step: 170, loss: 4.4169879402033985e-05
step: 180, loss: 0.0005476971855387092
step: 190, loss: 0.0003603053919505328
step: 200, loss: 5.239508755039424e-05
step: 210, loss: 0.022542089223861694
step: 220, loss: 0.00040511428960599005
step: 230, loss: 6.504701013909653e-05
step: 240, loss: 0.02115299552679062
step: 250, loss: 0.00159108592197299
step: 260, loss: 9.636548929847777e-05
step: 270, loss: 0.0018125427886843681
step: 280, loss: 0.0003806196909863502
step: 290, loss: 0.0001976817729882896
step: 300, loss: 0.004427887499332428
step: 310, loss: 5.9359394072089344e-05
step: 320, loss: 0.0002854216727428138
step: 330, loss: 7.104791438905522e-05
step: 340, loss: 0.0024505360051989555
step: 350, loss: 0.0001824506907723844
step: 360, loss: 9.829783084569499e-05
step: 370, loss: 8.364429231733084e-05
step: 380, loss: 1.5351673937402666e-05
step: 390, loss: 0.00244716415181756
step: 400, loss: 0.00028661591932177544
step: 410, loss: 9.090494859265164e-05
step: 420, loss: 3.911558451363817e-05
step: 430, loss: 0.0003366784658282995
step: 440, loss: 0.00016408265219070017
step: 450, loss: 0.0007539072539657354
step: 460, loss: 3.472218304523267e-05
epoch 16: dev_f1=0.9875706214689265, f1=0.9729119638826186, best_f1=0.9775280898876404
step: 0, loss: 3.091745747951791e-05
step: 10, loss: 0.0009947825456038117
step: 20, loss: 0.005915894638746977
step: 30, loss: 0.0021431457716971636
step: 40, loss: 2.6540830731391907e-05
step: 50, loss: 3.0049148335820064e-05
step: 60, loss: 1.8927594283013605e-05
step: 70, loss: 0.0002435657661408186
step: 80, loss: 8.166070620063692e-05
step: 90, loss: 0.009772365912795067
step: 100, loss: 3.15576653520111e-05
step: 110, loss: 5.6561177188996226e-05
step: 120, loss: 0.009326604194939137
step: 130, loss: 0.000245239440118894
step: 140, loss: 6.849302008049563e-05
step: 150, loss: 9.050856169778854e-05
step: 160, loss: 3.366110831848346e-05
step: 170, loss: 0.00013694634253624827
step: 180, loss: 6.450323417084292e-05
step: 190, loss: 0.00010727845074143261
step: 200, loss: 0.0018637150060385466
step: 210, loss: 0.0013146457495167851
step: 220, loss: 0.00023584948212374002
step: 230, loss: 0.0001486543333157897
step: 240, loss: 0.015748845413327217
step: 250, loss: 0.00013156321074347943
step: 260, loss: 0.00019110916764475405
step: 270, loss: 0.00014294656284619123
step: 280, loss: 0.0011328964028507471
step: 290, loss: 0.00021135731367394328
step: 300, loss: 1.886066274892073e-05
step: 310, loss: 1.8670494682737626e-05
step: 320, loss: 0.0003891020896844566
step: 330, loss: 0.00012036129919579253
step: 340, loss: 4.12095760111697e-05
step: 350, loss: 0.04867205768823624
step: 360, loss: 0.0013646133011206985
step: 370, loss: 9.685159602668136e-05
step: 380, loss: 4.204706056043506e-05
step: 390, loss: 0.00014841175288893282
step: 400, loss: 0.00012188739492557943
step: 410, loss: 6.576083251275122e-05
step: 420, loss: 9.936323476722464e-05
step: 430, loss: 0.00015110551612451673
step: 440, loss: 4.0438499127049e-05
step: 450, loss: 0.00010987282439600676
step: 460, loss: 8.15066450741142e-05
epoch 17: dev_f1=0.9865470852017937, f1=0.967670011148272, best_f1=0.9775280898876404
step: 0, loss: 8.006509597180411e-05
step: 10, loss: 0.00016849816893227398
step: 20, loss: 7.511406147386879e-05
step: 30, loss: 0.0001446076639695093
step: 40, loss: 0.0001965254487004131
step: 50, loss: 4.245039963279851e-05
step: 60, loss: 0.0001456548343412578
step: 70, loss: 1.9408311345614493e-05
step: 80, loss: 8.880871610017493e-05
step: 90, loss: 0.00640955101698637
step: 100, loss: 0.0009481628076173365
step: 110, loss: 0.00041056115878745914
step: 120, loss: 0.0002260710607515648
step: 130, loss: 8.24000671855174e-05
step: 140, loss: 2.0663621398853138e-05
step: 150, loss: 0.01242591068148613
step: 160, loss: 8.019871165743098e-05
step: 170, loss: 6.437834963435307e-05
step: 180, loss: 0.0011243665358051658
step: 190, loss: 1.29676209326135e-05
step: 200, loss: 5.021621109335683e-05
step: 210, loss: 1.791435352060944e-05
step: 220, loss: 3.0731902370462194e-05
step: 230, loss: 2.5539166017551906e-05
step: 240, loss: 0.0006432135123759508
step: 250, loss: 0.0004007747629657388
step: 260, loss: 0.00010807044600369409
step: 270, loss: 0.0007413154817186296
step: 280, loss: 5.919804607401602e-05
step: 290, loss: 6.730868335580453e-05
step: 300, loss: 0.0008216617279686034
step: 310, loss: 0.000701454933732748
step: 320, loss: 7.695424574194476e-05
step: 330, loss: 0.0004780854796990752
step: 340, loss: 3.172293145325966e-05
step: 350, loss: 1.8562677723821253e-05
step: 360, loss: 0.00010049603588413447
step: 370, loss: 4.492462539928965e-05
step: 380, loss: 0.00015519274165853858
step: 390, loss: 4.4424414227250963e-05
step: 400, loss: 1.2773892194672953e-05
step: 410, loss: 2.203814437962137e-05
step: 420, loss: 0.0013737274566665292
step: 430, loss: 3.873221794492565e-05
step: 440, loss: 0.0007479910273104906
step: 450, loss: 6.446411862270907e-05
step: 460, loss: 0.00026029933360405266
epoch 18: dev_f1=0.9865168539325843, f1=0.970917225950783, best_f1=0.9775280898876404
step: 0, loss: 7.088263373589143e-05
step: 10, loss: 0.006451380904763937
step: 20, loss: 4.1254392272094265e-05
step: 30, loss: 4.301651642890647e-05
step: 40, loss: 0.00108923832885921
step: 50, loss: 0.00015715579502284527
step: 60, loss: 5.211116513237357e-05
step: 70, loss: 0.0018561079632490873
step: 80, loss: 0.0002569777425378561
step: 90, loss: 2.7655110898194835e-05
step: 100, loss: 1.8879418348660693e-05
step: 110, loss: 0.00025911827106028795
step: 120, loss: 0.00011295976582914591
step: 130, loss: 0.00020604365272447467
step: 140, loss: 0.0003006637853104621
step: 150, loss: 1.7199352441821247e-05
step: 160, loss: 1.6178481018869206e-05
step: 170, loss: 3.2665844628354535e-05
step: 180, loss: 3.8403512007789686e-05
step: 190, loss: 0.0014168669003993273
step: 200, loss: 7.352727698162198e-05
step: 210, loss: 6.549017416546121e-05
step: 220, loss: 0.00044396831071935594
step: 230, loss: 0.0001725268375594169
step: 240, loss: 2.389298788330052e-05
step: 250, loss: 3.0669492844026536e-05
step: 260, loss: 0.00012037466512992978
step: 270, loss: 1.5422472642967477e-05
step: 280, loss: 3.31253650074359e-05
step: 290, loss: 7.258391997311264e-05
step: 300, loss: 0.0002749359991867095
step: 310, loss: 5.7548415497876704e-05
step: 320, loss: 0.00018303361139260232
step: 330, loss: 1.677464388194494e-05
step: 340, loss: 6.955875142011791e-05
step: 350, loss: 0.0015074018156155944
step: 360, loss: 0.00015117171278689057
step: 370, loss: 8.16088286228478e-05
step: 380, loss: 0.00019407394574955106
step: 390, loss: 1.703167254163418e-05
step: 400, loss: 3.442218076088466e-05
step: 410, loss: 2.5670033210190013e-05
step: 420, loss: 3.608620318118483e-05
step: 430, loss: 0.00016450627299491316
step: 440, loss: 0.0023044731933623552
step: 450, loss: 3.4542321373010054e-05
step: 460, loss: 0.0001316861598752439
epoch 19: dev_f1=0.9865470852017937, f1=0.9665924276169264, best_f1=0.9775280898876404
step: 0, loss: 1.8476732293493114e-05
step: 10, loss: 2.3323274945141748e-05
step: 20, loss: 4.4950455048820004e-05
step: 30, loss: 1.968406832020264e-05
step: 40, loss: 1.4613915482186712e-05
step: 50, loss: 2.9611623176606372e-05
step: 60, loss: 0.0003923497279174626
step: 70, loss: 0.0001563330733915791
step: 80, loss: 7.759768777759746e-05
step: 90, loss: 0.00030675012385472655
step: 100, loss: 1.6651749319862574e-05
step: 110, loss: 0.003097509266808629
step: 120, loss: 2.1151596229174174e-05
step: 130, loss: 3.0306762710097246e-05
step: 140, loss: 3.219389691366814e-05
step: 150, loss: 0.00137146539054811
step: 160, loss: 0.00023626830079592764
step: 170, loss: 0.00021894507517572492
step: 180, loss: 0.0009861629223451018
step: 190, loss: 0.03689703717827797
step: 200, loss: 4.523055758909322e-05
step: 210, loss: 0.0047491746954619884
step: 220, loss: 1.1421578165027313e-05
step: 230, loss: 0.0002581117150839418
step: 240, loss: 1.757191785145551e-05
step: 250, loss: 1.863321267592255e-05
step: 260, loss: 0.0003920082235708833
step: 270, loss: 6.333292549243197e-05
step: 280, loss: 0.000459634029539302
step: 290, loss: 9.557840530760586e-05
step: 300, loss: 2.5535477107041515e-05
step: 310, loss: 0.00027417190722189844
step: 320, loss: 7.008725515333936e-05
step: 330, loss: 0.0019599590450525284
step: 340, loss: 0.00015474052634090185
step: 350, loss: 0.00013847410446032882
step: 360, loss: 1.43347397170146e-05
step: 370, loss: 1.82685016625328e-05
step: 380, loss: 0.00022802033345215023
step: 390, loss: 4.8020901886047795e-05
step: 400, loss: 0.00020614363893400878
step: 410, loss: 8.665996574563906e-05
step: 420, loss: 0.00017558722174726427
step: 430, loss: 0.0013686935417354107
step: 440, loss: 8.685841748956591e-05
step: 450, loss: 7.2653972893022e-05
step: 460, loss: 5.049380342825316e-05
epoch 20: dev_f1=0.9876265466816648, f1=0.9719416386083053, best_f1=0.9775280898876404
