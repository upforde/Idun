cuda
Device: cuda
step: 0, loss: 0.5453400611877441
step: 10, loss: 0.5846863985061646
step: 20, loss: 0.45145297050476074
step: 30, loss: 0.4131894111633301
step: 40, loss: 0.15249554812908173
step: 50, loss: 0.35202786326408386
step: 60, loss: 0.4087822139263153
step: 70, loss: 0.28863024711608887
step: 80, loss: 0.2452566772699356
step: 90, loss: 0.24305495619773865
step: 100, loss: 0.1972634196281433
step: 110, loss: 0.32321909070014954
step: 120, loss: 0.3198705017566681
step: 130, loss: 0.2534160315990448
step: 140, loss: 0.21461597084999084
step: 150, loss: 0.2653849720954895
step: 160, loss: 0.32945340871810913
step: 170, loss: 0.22597700357437134
step: 180, loss: 0.20471912622451782
step: 190, loss: 0.22422441840171814
step: 200, loss: 0.21594944596290588
step: 210, loss: 0.3059931695461273
step: 220, loss: 0.1564541608095169
step: 230, loss: 0.06410954892635345
step: 240, loss: 0.1804960072040558
step: 250, loss: 0.3019653856754303
step: 260, loss: 0.3598648011684418
step: 270, loss: 0.35890722274780273
step: 280, loss: 0.3191775977611542
step: 290, loss: 0.2715124785900116
step: 300, loss: 0.167667955160141
step: 310, loss: 0.3820863664150238
step: 320, loss: 0.07603345811367035
step: 330, loss: 0.2603258192539215
step: 340, loss: 0.3630208373069763
step: 350, loss: 0.3317347466945648
step: 360, loss: 0.25564271211624146
step: 370, loss: 0.12537547945976257
step: 380, loss: 0.16830968856811523
step: 390, loss: 0.16775934398174286
step: 400, loss: 0.2767399549484253
step: 410, loss: 0.22700795531272888
step: 420, loss: 0.24339234828948975
step: 430, loss: 0.2242405116558075
step: 440, loss: 0.36064061522483826
step: 450, loss: 0.2696499228477478
step: 460, loss: 0.16995453834533691
epoch 1: dev_f1=0.9655172413793103, f1=0.9630459126539753, best_f1=0.9630459126539753
step: 0, loss: 0.04052533954381943
step: 10, loss: 0.05604587867856026
step: 20, loss: 0.5225849747657776
step: 30, loss: 0.15080025792121887
step: 40, loss: 0.32096800208091736
step: 50, loss: 0.2869816720485687
step: 60, loss: 0.09861978888511658
step: 70, loss: 0.10516700893640518
step: 80, loss: 0.05814798176288605
step: 90, loss: 0.1498192548751831
step: 100, loss: 0.1812991201877594
step: 110, loss: 0.2616095542907715
step: 120, loss: 0.08937563747167587
step: 130, loss: 0.15957839787006378
step: 140, loss: 0.09600643813610077
step: 150, loss: 0.1562568098306656
step: 160, loss: 0.08843304216861725
step: 170, loss: 0.06295254826545715
step: 180, loss: 0.015919452533125877
step: 190, loss: 0.15298911929130554
step: 200, loss: 0.17224103212356567
step: 210, loss: 0.18680338561534882
step: 220, loss: 0.0991130992770195
step: 230, loss: 0.09055618941783905
step: 240, loss: 0.1146915853023529
step: 250, loss: 0.3803367614746094
step: 260, loss: 0.19418583810329437
step: 270, loss: 0.16498638689517975
step: 280, loss: 0.07369188219308853
step: 290, loss: 0.090561643242836
step: 300, loss: 0.0132147753611207
step: 310, loss: 0.2774507403373718
step: 320, loss: 0.1439705193042755
step: 330, loss: 0.07090723514556885
step: 340, loss: 0.009386812336742878
step: 350, loss: 0.07681646198034286
step: 360, loss: 0.07197001576423645
step: 370, loss: 0.18121862411499023
step: 380, loss: 0.08225279301404953
step: 390, loss: 0.30812782049179077
step: 400, loss: 0.20234306156635284
step: 410, loss: 0.1443057358264923
step: 420, loss: 0.05573992058634758
step: 430, loss: 0.1873585730791092
step: 440, loss: 0.1063089370727539
step: 450, loss: 0.07066156715154648
step: 460, loss: 0.33922940492630005
epoch 2: dev_f1=0.9799107142857142, f1=0.9661399548532732, best_f1=0.9661399548532732
step: 0, loss: 0.07405876368284225
step: 10, loss: 0.16486753523349762
step: 20, loss: 0.17445971071720123
step: 30, loss: 0.015056543052196503
step: 40, loss: 0.038465533405542374
step: 50, loss: 0.0258799958974123
step: 60, loss: 0.04789959639310837
step: 70, loss: 0.03491783142089844
step: 80, loss: 0.22960752248764038
step: 90, loss: 0.08043557405471802
step: 100, loss: 0.03816507011651993
step: 110, loss: 0.10826332867145538
step: 120, loss: 0.05742017924785614
step: 130, loss: 0.03905804455280304
step: 140, loss: 0.1630939096212387
step: 150, loss: 0.058179061859846115
step: 160, loss: 0.10410516709089279
step: 170, loss: 0.008061629720032215
step: 180, loss: 0.1383993774652481
step: 190, loss: 0.11749838292598724
step: 200, loss: 0.053068261593580246
step: 210, loss: 0.1783582866191864
step: 220, loss: 0.026928745210170746
step: 230, loss: 0.09556750953197479
step: 240, loss: 0.15298615396022797
step: 250, loss: 0.07858753949403763
step: 260, loss: 0.252896785736084
step: 270, loss: 0.035177819430828094
step: 280, loss: 0.1824979931116104
step: 290, loss: 0.018340514972805977
step: 300, loss: 0.08812400698661804
step: 310, loss: 0.062170326709747314
step: 320, loss: 0.00835933443158865
step: 330, loss: 0.1906491070985794
step: 340, loss: 0.252927303314209
step: 350, loss: 0.08605540543794632
step: 360, loss: 0.06954937428236008
step: 370, loss: 0.11417817324399948
step: 380, loss: 0.01382217276841402
step: 390, loss: 0.10928039997816086
step: 400, loss: 0.041225582361221313
step: 410, loss: 0.030935754999518394
step: 420, loss: 0.16338860988616943
step: 430, loss: 0.03749191761016846
step: 440, loss: 0.04630212485790253
step: 450, loss: 0.0079943323507905
step: 460, loss: 0.02738415077328682
epoch 3: dev_f1=0.9798657718120806, f1=0.9753914988814317, best_f1=0.9661399548532732
step: 0, loss: 0.04242673143744469
step: 10, loss: 0.06430976092815399
step: 20, loss: 0.1325920969247818
step: 30, loss: 0.00917189009487629
step: 40, loss: 0.09390182048082352
step: 50, loss: 0.02641206979751587
step: 60, loss: 0.05564261972904205
step: 70, loss: 0.022891316562891006
step: 80, loss: 0.025639133527874947
step: 90, loss: 0.07915020734071732
step: 100, loss: 0.10343515872955322
step: 110, loss: 0.06190994754433632
step: 120, loss: 0.07155097275972366
step: 130, loss: 0.012674035504460335
step: 140, loss: 0.1811715066432953
step: 150, loss: 0.0038605935405939817
step: 160, loss: 0.02687043510377407
step: 170, loss: 0.039015304297208786
step: 180, loss: 0.03498315438628197
step: 190, loss: 0.022645236924290657
step: 200, loss: 0.032913584262132645
step: 210, loss: 0.06307259202003479
step: 220, loss: 0.04292430728673935
step: 230, loss: 0.1593279242515564
step: 240, loss: 0.05042372643947601
step: 250, loss: 0.02325693517923355
step: 260, loss: 0.15625323355197906
step: 270, loss: 0.09020917862653732
step: 280, loss: 0.022671282291412354
step: 290, loss: 0.0780540257692337
step: 300, loss: 0.2222370207309723
step: 310, loss: 0.029907645657658577
step: 320, loss: 0.040474992245435715
step: 330, loss: 0.04360935464501381
step: 340, loss: 0.025258537381887436
step: 350, loss: 0.07952538877725601
step: 360, loss: 0.013455742970108986
step: 370, loss: 0.07609537988901138
step: 380, loss: 0.009471780620515347
step: 390, loss: 0.04186367988586426
step: 400, loss: 0.16974572837352753
step: 410, loss: 0.09258295595645905
step: 420, loss: 0.03315519541501999
step: 430, loss: 0.06824468076229095
step: 440, loss: 0.011624152772128582
step: 450, loss: 0.05727635696530342
step: 460, loss: 0.01839662529528141
epoch 4: dev_f1=0.987709497206704, f1=0.9709821428571428, best_f1=0.9709821428571428
step: 0, loss: 0.018129987642169
step: 10, loss: 0.14640696346759796
step: 20, loss: 0.012916238978505135
step: 30, loss: 0.2502096891403198
step: 40, loss: 0.16067934036254883
step: 50, loss: 0.026363519951701164
step: 60, loss: 0.0500975139439106
step: 70, loss: 0.11275707930326462
step: 80, loss: 0.0026537904050201178
step: 90, loss: 0.05152597278356552
step: 100, loss: 0.04768740013241768
step: 110, loss: 0.04079505056142807
step: 120, loss: 0.023268230259418488
step: 130, loss: 0.10331007093191147
step: 140, loss: 0.006958628538995981
step: 150, loss: 0.0056333900429308414
step: 160, loss: 0.12226429581642151
step: 170, loss: 0.0042460206896066666
step: 180, loss: 0.010743211023509502
step: 190, loss: 0.006883967202156782
step: 200, loss: 0.0075279404409229755
step: 210, loss: 0.0064103445038199425
step: 220, loss: 0.0044435178861021996
step: 230, loss: 0.14488841593265533
step: 240, loss: 0.0755939781665802
step: 250, loss: 0.06548532098531723
step: 260, loss: 0.03640633448958397
step: 270, loss: 0.01904010772705078
step: 280, loss: 0.042162179946899414
step: 290, loss: 0.0037403684109449387
step: 300, loss: 0.16891762614250183
step: 310, loss: 0.010549705475568771
step: 320, loss: 0.14270952343940735
step: 330, loss: 0.047610413283109665
step: 340, loss: 0.048029087483882904
step: 350, loss: 0.12282926589250565
step: 360, loss: 0.005125148221850395
step: 370, loss: 0.014259099960327148
step: 380, loss: 0.15456703305244446
step: 390, loss: 0.10369355231523514
step: 400, loss: 0.024784350767731667
step: 410, loss: 0.012202657759189606
step: 420, loss: 0.006218733731657267
step: 430, loss: 0.09702172130346298
step: 440, loss: 0.06104220822453499
step: 450, loss: 0.037210863083601
step: 460, loss: 0.003305131569504738
epoch 5: dev_f1=0.9753363228699552, f1=0.9654403567447045, best_f1=0.9709821428571428
step: 0, loss: 0.013765212148427963
step: 10, loss: 0.018046697601675987
step: 20, loss: 0.0047637177631258965
step: 30, loss: 0.017621608451008797
step: 40, loss: 0.005438119173049927
step: 50, loss: 0.027655724436044693
step: 60, loss: 0.01677660085260868
step: 70, loss: 0.05838087201118469
step: 80, loss: 0.0027763191610574722
step: 90, loss: 0.007755599915981293
step: 100, loss: 0.005401143338531256
step: 110, loss: 0.005538275931030512
step: 120, loss: 0.014827020466327667
step: 130, loss: 0.00351058435626328
step: 140, loss: 0.01419756654649973
step: 150, loss: 0.053579963743686676
step: 160, loss: 0.13395211100578308
step: 170, loss: 0.0777442455291748
step: 180, loss: 0.20192591845989227
step: 190, loss: 0.03589256852865219
step: 200, loss: 0.0016272286884486675
step: 210, loss: 0.009917675517499447
step: 220, loss: 0.03492213413119316
step: 230, loss: 0.028281094506382942
step: 240, loss: 0.001114788930863142
step: 250, loss: 0.06752334535121918
step: 260, loss: 0.010627280920743942
step: 270, loss: 0.06307367980480194
step: 280, loss: 0.053569987416267395
step: 290, loss: 0.020607538521289825
step: 300, loss: 0.07068362087011337
step: 310, loss: 0.11085224151611328
step: 320, loss: 0.00204689078964293
step: 330, loss: 0.019544482231140137
step: 340, loss: 0.004599280655384064
step: 350, loss: 0.009764080867171288
step: 360, loss: 0.003065476194024086
step: 370, loss: 0.018991101533174515
step: 380, loss: 0.04509291797876358
step: 390, loss: 0.09145484119653702
step: 400, loss: 0.008441971614956856
step: 410, loss: 0.005851466674357653
step: 420, loss: 0.03167000412940979
step: 430, loss: 0.11219395697116852
step: 440, loss: 0.001408869051374495
step: 450, loss: 0.0193755105137825
step: 460, loss: 0.026876820251345634
epoch 6: dev_f1=0.9876819708846584, f1=0.9766407119021134, best_f1=0.9709821428571428
step: 0, loss: 0.005205849651247263
step: 10, loss: 0.03311774134635925
step: 20, loss: 0.0018780266400426626
step: 30, loss: 0.014632385224103928
step: 40, loss: 0.006201015319675207
step: 50, loss: 0.0003747638256754726
step: 60, loss: 0.08182132244110107
step: 70, loss: 0.006502422969788313
step: 80, loss: 0.010331958532333374
step: 90, loss: 0.009762241505086422
step: 100, loss: 0.0761328637599945
step: 110, loss: 0.006127884611487389
step: 120, loss: 0.0011918566888198256
step: 130, loss: 0.004663305357098579
step: 140, loss: 0.02297913283109665
step: 150, loss: 0.020755287259817123
step: 160, loss: 0.09938929229974747
step: 170, loss: 0.07174386084079742
step: 180, loss: 0.0015274385223165154
step: 190, loss: 0.10395458340644836
step: 200, loss: 0.16757075488567352
step: 210, loss: 0.04360625892877579
step: 220, loss: 0.006690519396215677
step: 230, loss: 0.033443182706832886
step: 240, loss: 0.0924447774887085
step: 250, loss: 0.034739233553409576
step: 260, loss: 0.0009652891894802451
step: 270, loss: 0.007853066548705101
step: 280, loss: 0.02060830593109131
step: 290, loss: 0.026395291090011597
step: 300, loss: 0.012804577127099037
step: 310, loss: 0.008958619087934494
step: 320, loss: 0.0026295501738786697
step: 330, loss: 0.0061057331040501595
step: 340, loss: 0.006182135082781315
step: 350, loss: 0.049044299870729446
step: 360, loss: 0.0019238459644839168
step: 370, loss: 0.0006597804604098201
step: 380, loss: 0.001082392642274499
step: 390, loss: 0.006693489849567413
step: 400, loss: 0.00882762111723423
step: 410, loss: 0.08526413142681122
step: 420, loss: 0.02142701856791973
step: 430, loss: 0.0010786621132865548
step: 440, loss: 0.017171703279018402
step: 450, loss: 0.07274278253316879
step: 460, loss: 0.10124742239713669
epoch 7: dev_f1=0.9799107142857142, f1=0.9700332963374029, best_f1=0.9709821428571428
step: 0, loss: 0.002059789141640067
step: 10, loss: 0.004355149809271097
step: 20, loss: 0.0031030483078211546
step: 30, loss: 0.006590176839381456
step: 40, loss: 0.003886526683345437
step: 50, loss: 0.0019247429445385933
step: 60, loss: 0.031066352501511574
step: 70, loss: 0.00801048707216978
step: 80, loss: 0.0004006645467597991
step: 90, loss: 0.10720404237508774
step: 100, loss: 0.013574166223406792
step: 110, loss: 0.0002091917849611491
step: 120, loss: 0.00020292021508794278
step: 130, loss: 0.00042297496111132205
step: 140, loss: 0.0007711034850217402
step: 150, loss: 0.0032618925906717777
step: 160, loss: 0.01487126387655735
step: 170, loss: 0.007394499611109495
step: 180, loss: 0.019143393263220787
step: 190, loss: 0.0002698664029594511
step: 200, loss: 0.004388619679957628
step: 210, loss: 0.01391137856990099
step: 220, loss: 0.0005022030672989786
step: 230, loss: 0.0019646333530545235
step: 240, loss: 0.00040517206070944667
step: 250, loss: 0.0026521864347159863
step: 260, loss: 0.0003141626075375825
step: 270, loss: 0.0038191629573702812
step: 280, loss: 0.002060167258605361
step: 290, loss: 0.0006561189657077193
step: 300, loss: 0.0018753930926322937
step: 310, loss: 0.14948073029518127
step: 320, loss: 0.0008820008370094001
step: 330, loss: 0.006775837391614914
step: 340, loss: 0.0023416890762746334
step: 350, loss: 0.0016590089071542025
step: 360, loss: 0.012815318070352077
step: 370, loss: 0.0013104588724672794
step: 380, loss: 0.0017121367854997516
step: 390, loss: 0.0029326032381504774
step: 400, loss: 0.0010946161346510053
step: 410, loss: 0.010920632630586624
step: 420, loss: 0.0059410566464066505
step: 430, loss: 0.006243973970413208
step: 440, loss: 0.0005312718567438424
step: 450, loss: 0.0022244825959205627
step: 460, loss: 0.001485908986069262
epoch 8: dev_f1=0.9820627802690582, f1=0.9742441209406495, best_f1=0.9709821428571428
step: 0, loss: 0.0023629539646208286
step: 10, loss: 0.0024482854641973972
step: 20, loss: 0.010316873900592327
step: 30, loss: 0.00418428611010313
step: 40, loss: 0.0007632108172401786
step: 50, loss: 0.004503178410232067
step: 60, loss: 0.000603906053584069
step: 70, loss: 0.00051956030074507
step: 80, loss: 0.0008383178501389921
step: 90, loss: 0.07231456786394119
step: 100, loss: 0.04523317888379097
step: 110, loss: 0.03626731410622597
step: 120, loss: 0.0011647648643702269
step: 130, loss: 0.0014507902087643743
step: 140, loss: 0.010039443150162697
step: 150, loss: 0.007693997118622065
step: 160, loss: 0.0018258632626384497
step: 170, loss: 0.06970786303281784
step: 180, loss: 0.01158241368830204
step: 190, loss: 0.010018166154623032
step: 200, loss: 0.003958226181566715
step: 210, loss: 0.0017062613042071462
step: 220, loss: 0.027130553498864174
step: 230, loss: 0.0007286721374839544
step: 240, loss: 0.0022024461068212986
step: 250, loss: 0.00014722005289513618
step: 260, loss: 0.059992894530296326
step: 270, loss: 0.0010097792837768793
step: 280, loss: 0.100745290517807
step: 290, loss: 0.00169136852491647
step: 300, loss: 0.0017352609429508448
step: 310, loss: 0.07549742609262466
step: 320, loss: 0.0005750167183578014
step: 330, loss: 0.004252252634614706
step: 340, loss: 0.003765887813642621
step: 350, loss: 0.03032303787767887
step: 360, loss: 0.006019091699272394
step: 370, loss: 0.003078608773648739
step: 380, loss: 0.02000311017036438
step: 390, loss: 0.017215127125382423
step: 400, loss: 0.002996307099238038
step: 410, loss: 0.005606514401733875
step: 420, loss: 0.033966194838285446
step: 430, loss: 0.004077500198036432
step: 440, loss: 0.18838655948638916
step: 450, loss: 0.01567140407860279
step: 460, loss: 0.06441929191350937
epoch 9: dev_f1=0.9886877828054299, f1=0.9751131221719457, best_f1=0.9751131221719457
step: 0, loss: 0.010402322746813297
step: 10, loss: 0.0017466035205870867
step: 20, loss: 0.002822541631758213
step: 30, loss: 0.028142563998699188
step: 40, loss: 0.0011803166707977653
step: 50, loss: 0.008958310820162296
step: 60, loss: 0.17391717433929443
step: 70, loss: 0.004151072818785906
step: 80, loss: 0.0007377472356893122
step: 90, loss: 0.0009026550105772913
step: 100, loss: 0.0028331985231488943
step: 110, loss: 0.0016482060309499502
step: 120, loss: 0.0046209730207920074
step: 130, loss: 0.00037722510751336813
step: 140, loss: 0.0002610361552797258
step: 150, loss: 0.0050439597107470036
step: 160, loss: 0.004536920692771673
step: 170, loss: 0.007352376356720924
step: 180, loss: 0.03532421961426735
step: 190, loss: 0.00094317935872823
step: 200, loss: 0.0001003033685265109
step: 210, loss: 0.0011902471305802464
step: 220, loss: 0.0003599931951612234
step: 230, loss: 0.00018849479965865612
step: 240, loss: 8.67849521455355e-05
step: 250, loss: 0.005506101995706558
step: 260, loss: 0.008695580996572971
step: 270, loss: 0.010738051496446133
step: 280, loss: 0.0032997997477650642
step: 290, loss: 3.685634510475211e-05
step: 300, loss: 0.0002610880183055997
step: 310, loss: 0.0006576961604878306
step: 320, loss: 0.00010184579150518402
step: 330, loss: 0.00018708342395257205
step: 340, loss: 0.0005394403706304729
step: 350, loss: 0.002072434639558196
step: 360, loss: 0.002224769676104188
step: 370, loss: 0.0010523323435336351
step: 380, loss: 0.00024124220362864435
step: 390, loss: 0.005220144987106323
step: 400, loss: 0.000378712808014825
step: 410, loss: 0.00014075147919356823
step: 420, loss: 0.0005721142515540123
step: 430, loss: 0.00300578773021698
step: 440, loss: 0.004844015929847956
step: 450, loss: 9.753760969033465e-05
step: 460, loss: 0.010958482511341572
epoch 10: dev_f1=0.9876543209876544, f1=0.9698996655518396, best_f1=0.9751131221719457
step: 0, loss: 0.005059839691966772
step: 10, loss: 0.0006135410512797534
step: 20, loss: 0.0024271232541650534
step: 30, loss: 0.001811404014006257
step: 40, loss: 0.0028074816800653934
step: 50, loss: 0.0003417920379433781
step: 60, loss: 0.001239942153915763
step: 70, loss: 0.002429649466648698
step: 80, loss: 0.0005136954132467508
step: 90, loss: 0.0009390819468535483
step: 100, loss: 0.00027999604935757816
step: 110, loss: 9.993857383960858e-05
step: 120, loss: 0.000644911895506084
step: 130, loss: 0.0002938169927801937
step: 140, loss: 0.003134026424959302
step: 150, loss: 0.020406663417816162
step: 160, loss: 0.0006935896235518157
step: 170, loss: 0.0009751447360031307
step: 180, loss: 0.00031092652352526784
step: 190, loss: 0.00014565260789822787
step: 200, loss: 0.0033323573879897594
step: 210, loss: 0.0647817999124527
step: 220, loss: 0.00559551315382123
step: 230, loss: 0.009667348116636276
step: 240, loss: 0.000483887386508286
step: 250, loss: 0.02667258121073246
step: 260, loss: 0.005298543255776167
step: 270, loss: 0.0003224467800464481
step: 280, loss: 0.00012223361409269273
step: 290, loss: 0.001220694393850863
step: 300, loss: 0.001773993019014597
step: 310, loss: 0.0008633443503640592
step: 320, loss: 0.00013934164599049836
step: 330, loss: 0.025445332750678062
step: 340, loss: 8.697007433511317e-05
step: 350, loss: 0.1310967355966568
step: 360, loss: 0.0001664887968217954
step: 370, loss: 0.0004902688087895513
step: 380, loss: 0.0007561292732134461
step: 390, loss: 0.0002461532421875745
step: 400, loss: 0.00011005067790392786
step: 410, loss: 0.0012378075625747442
step: 420, loss: 0.026683790609240532
step: 430, loss: 0.0002540947461966425
step: 440, loss: 0.07121312618255615
step: 450, loss: 0.00013738300185650587
step: 460, loss: 0.0026657767593860626
epoch 11: dev_f1=0.9831271091113611, f1=0.9740698985343857, best_f1=0.9751131221719457
step: 0, loss: 0.0008561547729186714
step: 10, loss: 0.0005685238284058869
step: 20, loss: 0.000144959834869951
step: 30, loss: 0.00028374517569318414
step: 40, loss: 0.029990583658218384
step: 50, loss: 0.0009725255076773465
step: 60, loss: 0.0007159662200137973
step: 70, loss: 9.45451611187309e-05
step: 80, loss: 0.001170497853308916
step: 90, loss: 0.0009431373910047114
step: 100, loss: 0.0011374305468052626
step: 110, loss: 0.0008791381260380149
step: 120, loss: 0.0001903834636323154
step: 130, loss: 0.0014663352631032467
step: 140, loss: 0.017840692773461342
step: 150, loss: 5.234297350398265e-05
step: 160, loss: 0.05376215651631355
step: 170, loss: 5.657815927406773e-05
step: 180, loss: 0.00019176934438291937
step: 190, loss: 0.00016271625645458698
step: 200, loss: 0.00019738914852496237
step: 210, loss: 0.000618613266851753
step: 220, loss: 4.4670337956631556e-05
step: 230, loss: 0.0004476034373510629
step: 240, loss: 0.10445187985897064
step: 250, loss: 0.0005533337825909257
step: 260, loss: 0.0001597366645000875
step: 270, loss: 0.001700018416158855
step: 280, loss: 0.01804484985768795
step: 290, loss: 0.000452360458439216
step: 300, loss: 0.000974046706687659
step: 310, loss: 0.001232360489666462
step: 320, loss: 0.00014183878374751657
step: 330, loss: 0.0055879857391119
step: 340, loss: 0.008146582171320915
step: 350, loss: 0.04538707807660103
step: 360, loss: 0.0005117263062857091
step: 370, loss: 0.00013456799206323922
step: 380, loss: 0.0047859507612884045
step: 390, loss: 0.004941246937960386
step: 400, loss: 0.0005748320836573839
step: 410, loss: 0.0065350886434316635
step: 420, loss: 0.0004382484476082027
step: 430, loss: 0.0005575146060436964
step: 440, loss: 0.0022690899204462767
step: 450, loss: 0.00041969004087150097
step: 460, loss: 0.0002661110193002969
epoch 12: dev_f1=0.9832402234636871, f1=0.9754464285714286, best_f1=0.9751131221719457
step: 0, loss: 0.0005842753453180194
step: 10, loss: 0.021380620077252388
step: 20, loss: 0.00043140436173416674
step: 30, loss: 0.0005088543402962387
step: 40, loss: 0.0006361486157402396
step: 50, loss: 0.0011285427026450634
step: 60, loss: 0.0027144516352564096
step: 70, loss: 0.001826481893658638
step: 80, loss: 0.06486541777849197
step: 90, loss: 0.0009681401425041258
step: 100, loss: 0.0001259612909052521
step: 110, loss: 0.00013472168939188123
step: 120, loss: 5.59436775802169e-05
step: 130, loss: 0.00012988131493330002
step: 140, loss: 8.541149145457894e-05
step: 150, loss: 9.688777208793908e-05
step: 160, loss: 0.0018525966443121433
step: 170, loss: 0.00029331824043765664
step: 180, loss: 0.0003623440570663661
step: 190, loss: 0.02162949927151203
step: 200, loss: 0.0031219145748764277
step: 210, loss: 0.041197437793016434
step: 220, loss: 0.015765557065606117
step: 230, loss: 0.0013486123643815517
step: 240, loss: 0.00016296688409056515
step: 250, loss: 0.004966970533132553
step: 260, loss: 9.499645238975063e-05
step: 270, loss: 0.0008795312605798244
step: 280, loss: 0.004532933235168457
step: 290, loss: 0.0003832262009382248
step: 300, loss: 0.004128108732402325
step: 310, loss: 0.00019800488371402025
step: 320, loss: 0.00033657188760116696
step: 330, loss: 6.678550562355667e-05
step: 340, loss: 0.001015828805975616
step: 350, loss: 0.00059599889209494
step: 360, loss: 0.0002928001922555268
step: 370, loss: 0.0002341118233744055
step: 380, loss: 0.0002388419525232166
step: 390, loss: 0.000504548370372504
step: 400, loss: 0.0005604716716334224
step: 410, loss: 8.938081737142056e-05
step: 420, loss: 0.00013021560152992606
step: 430, loss: 0.009290290996432304
step: 440, loss: 0.0019110707798972726
step: 450, loss: 0.0032646397594362497
step: 460, loss: 6.600027700187638e-05
epoch 13: dev_f1=0.9819819819819819, f1=0.971815107102593, best_f1=0.9751131221719457
step: 0, loss: 0.0001352820690954104
step: 10, loss: 6.427395419450477e-05
step: 20, loss: 0.0005499448743648827
step: 30, loss: 0.00041653128573670983
step: 40, loss: 0.0004108819121029228
step: 50, loss: 0.0024235928431153297
step: 60, loss: 0.0001780382008291781
step: 70, loss: 0.00012366044393274933
step: 80, loss: 0.0010174252092838287
step: 90, loss: 0.00041527667781338096
step: 100, loss: 0.0004953291499987245
step: 110, loss: 0.0005052151391282678
step: 120, loss: 7.525345426984131e-05
step: 130, loss: 0.00016141112428158522
step: 140, loss: 6.267343997024e-05
step: 150, loss: 0.00011113811342511326
step: 160, loss: 0.00013436183508019894
step: 170, loss: 4.143095065956004e-05
step: 180, loss: 0.0007179382373578846
step: 190, loss: 0.0006759002571925521
step: 200, loss: 0.00018599219038151205
step: 210, loss: 8.939556573750451e-05
step: 220, loss: 8.715617877896875e-05
step: 230, loss: 0.0001675247331149876
step: 240, loss: 0.000969690561760217
step: 250, loss: 0.0018939276924356818
step: 260, loss: 0.0006064941408112645
step: 270, loss: 9.833588410401717e-05
step: 280, loss: 0.03275343403220177
step: 290, loss: 6.761067197658122e-05
step: 300, loss: 4.9466594646219164e-05
step: 310, loss: 0.0002337526821065694
step: 320, loss: 0.00010598036169540137
step: 330, loss: 0.0026642107404768467
step: 340, loss: 0.0006101973121985793
step: 350, loss: 0.00014793557056691498
step: 360, loss: 0.0002617810678202659
step: 370, loss: 0.0011620501754805446
step: 380, loss: 9.443403541808948e-05
step: 390, loss: 0.00014035437197890133
step: 400, loss: 0.041693758219480515
step: 410, loss: 0.0001275124232051894
step: 420, loss: 0.0002968976623378694
step: 430, loss: 6.351477350108325e-05
step: 440, loss: 0.0001836691953940317
step: 450, loss: 8.622844325145707e-05
step: 460, loss: 0.005374889820814133
epoch 14: dev_f1=0.9819819819819819, f1=0.9685393258426966, best_f1=0.9751131221719457
step: 0, loss: 0.0005696768057532609
step: 10, loss: 0.0015730317682027817
step: 20, loss: 0.00024601281620562077
step: 30, loss: 0.0010465868981555104
step: 40, loss: 5.164960020920262e-05
step: 50, loss: 0.0002801594673655927
step: 60, loss: 0.00876291561871767
step: 70, loss: 4.60638984804973e-05
step: 80, loss: 7.523877138737589e-05
step: 90, loss: 6.506694626295939e-05
step: 100, loss: 6.053470497136004e-05
step: 110, loss: 7.951635052450001e-05
step: 120, loss: 8.776067261351272e-05
step: 130, loss: 0.00035507933353073895
step: 140, loss: 0.0813831090927124
step: 150, loss: 0.0001393069833284244
step: 160, loss: 0.0007867015083320439
step: 170, loss: 0.00012948911171406507
step: 180, loss: 0.0004996915813535452
step: 190, loss: 0.0001910838473122567
step: 200, loss: 0.004147220868617296
step: 210, loss: 0.003077381057664752
step: 220, loss: 0.00047447875840589404
step: 230, loss: 0.00045547698391601443
step: 240, loss: 0.0007317089475691319
step: 250, loss: 0.0009560707840137184
step: 260, loss: 0.06235741823911667
step: 270, loss: 0.003546718042343855
step: 280, loss: 0.000185327953658998
step: 290, loss: 0.00027435270021669567
step: 300, loss: 0.03965264931321144
step: 310, loss: 7.685276796109974e-05
step: 320, loss: 0.0006985273212194443
step: 330, loss: 4.606696529663168e-05
step: 340, loss: 0.0002192304964410141
step: 350, loss: 0.0013482208596542478
step: 360, loss: 0.00042201345786452293
step: 370, loss: 0.16978766024112701
step: 380, loss: 0.00029002982773818076
step: 390, loss: 0.0016314119566231966
step: 400, loss: 4.878179242950864e-05
step: 410, loss: 0.005027664825320244
step: 420, loss: 0.010069450363516808
step: 430, loss: 0.0006240866496227682
step: 440, loss: 0.0009171848651021719
step: 450, loss: 0.00021695975738111883
step: 460, loss: 0.00015678114141337574
epoch 15: dev_f1=0.9842696629213483, f1=0.9786276715410572, best_f1=0.9751131221719457
step: 0, loss: 0.02959984913468361
step: 10, loss: 5.8842233556788415e-05
step: 20, loss: 0.0004666793392971158
step: 30, loss: 0.00024617789313197136
step: 40, loss: 0.00012565824727062136
step: 50, loss: 0.0017198132118210196
step: 60, loss: 7.641399133717641e-05
step: 70, loss: 0.00036708489642478526
step: 80, loss: 0.031295452266931534
step: 90, loss: 6.975878932280466e-05
step: 100, loss: 0.00043886207276955247
step: 110, loss: 0.00014097396342549473
step: 120, loss: 9.806331945583224e-05
step: 130, loss: 0.0008364202221855521
step: 140, loss: 0.0008580610156059265
step: 150, loss: 0.0002570126380305737
step: 160, loss: 0.000306479079881683
step: 170, loss: 0.009272521361708641
step: 180, loss: 6.170920823933557e-05
step: 190, loss: 3.490446033538319e-05
step: 200, loss: 0.0023136218078434467
step: 210, loss: 0.0012947343057021499
step: 220, loss: 0.0001060429640347138
step: 230, loss: 0.0005556765245273709
step: 240, loss: 4.342679676483385e-05
step: 250, loss: 0.008248426951467991
step: 260, loss: 4.303570676711388e-05
step: 270, loss: 0.0001756033452693373
step: 280, loss: 0.00022683829593006521
step: 290, loss: 0.0006597683532163501
step: 300, loss: 5.385923941503279e-05
step: 310, loss: 0.0021634986624121666
step: 320, loss: 0.001340363989584148
step: 330, loss: 0.0003130852710455656
step: 340, loss: 2.6053623514599167e-05
step: 350, loss: 3.7330377381294966e-05
step: 360, loss: 6.936685531400144e-05
step: 370, loss: 3.2337597076548263e-05
step: 380, loss: 8.509925100952387e-05
step: 390, loss: 5.5229167628567666e-05
step: 400, loss: 8.506423910148442e-05
step: 410, loss: 0.000126068654935807
step: 420, loss: 0.00022096713655628264
step: 430, loss: 4.550305675365962e-05
step: 440, loss: 6.669494905509055e-05
step: 450, loss: 0.00015711229934822768
step: 460, loss: 0.00042713622679002583
epoch 16: dev_f1=0.9831271091113611, f1=0.9775280898876404, best_f1=0.9751131221719457
step: 0, loss: 9.965210483642295e-05
step: 10, loss: 4.680000711232424e-05
step: 20, loss: 0.0006574918515980244
step: 30, loss: 0.00044696233817376196
step: 40, loss: 2.856452738342341e-05
step: 50, loss: 2.1132944311830215e-05
step: 60, loss: 0.0001041196082951501
step: 70, loss: 0.050939545035362244
step: 80, loss: 0.0042534987442195415
step: 90, loss: 0.00014138597180135548
step: 100, loss: 7.666485180379823e-05
step: 110, loss: 0.004564682021737099
step: 120, loss: 0.0003281297395005822
step: 130, loss: 0.000107962368929293
step: 140, loss: 4.504318712861277e-05
step: 150, loss: 0.00021750919404439628
step: 160, loss: 9.345697617391124e-05
step: 170, loss: 0.010411351919174194
step: 180, loss: 3.578628457034938e-05
step: 190, loss: 0.03945300728082657
step: 200, loss: 0.0010311786318197846
step: 210, loss: 0.0007307325140573084
step: 220, loss: 8.197811985155568e-05
step: 230, loss: 0.00011544128210516647
step: 240, loss: 7.317854760913178e-05
step: 250, loss: 6.388534529833123e-05
step: 260, loss: 2.885513640649151e-05
step: 270, loss: 0.00020023690012749285
step: 280, loss: 4.6964392822701484e-05
step: 290, loss: 2.5506149540888146e-05
step: 300, loss: 3.119778193649836e-05
step: 310, loss: 3.493657277431339e-05
step: 320, loss: 7.404891221085563e-05
step: 330, loss: 4.0395385440206155e-05
step: 340, loss: 4.248407276463695e-05
step: 350, loss: 0.00010632287012413144
step: 360, loss: 0.0007663240539841354
step: 370, loss: 5.032338231103495e-05
step: 380, loss: 4.7296718548750505e-05
step: 390, loss: 4.5248980313772336e-05
step: 400, loss: 0.0007900403579697013
step: 410, loss: 7.470323907909915e-05
step: 420, loss: 0.0006460316362790763
step: 430, loss: 0.0007210406474769115
step: 440, loss: 0.01830071397125721
step: 450, loss: 1.7303656932199374e-05
step: 460, loss: 4.5976616092957556e-05
epoch 17: dev_f1=0.9809203142536477, f1=0.9742441209406495, best_f1=0.9751131221719457
step: 0, loss: 4.520979564404115e-05
step: 10, loss: 4.6539011236745864e-05
step: 20, loss: 0.00010193527850788087
step: 30, loss: 3.4869244700530544e-05
step: 40, loss: 0.013523204252123833
step: 50, loss: 2.2790532966610044e-05
step: 60, loss: 4.167437145952135e-05
step: 70, loss: 0.00011337970499880612
step: 80, loss: 0.012973572127521038
step: 90, loss: 2.8816864869440906e-05
step: 100, loss: 3.2563970307819545e-05
step: 110, loss: 4.744254329125397e-05
step: 120, loss: 0.00031346341711468995
step: 130, loss: 0.0065389093942940235
step: 140, loss: 4.898137922282331e-05
step: 150, loss: 5.758241604780778e-05
step: 160, loss: 0.00018915958935394883
step: 170, loss: 1.7951655536307953e-05
step: 180, loss: 0.001534629613161087
step: 190, loss: 3.522243059705943e-05
step: 200, loss: 3.186450703651644e-05
step: 210, loss: 4.5868826418882236e-05
step: 220, loss: 0.0051713185384869576
step: 230, loss: 1.2524316844064742e-05
step: 240, loss: 0.0003550643159542233
step: 250, loss: 2.2243013518163934e-05
step: 260, loss: 6.199445488164201e-05
step: 270, loss: 0.00011048716987716034
step: 280, loss: 6.840273272246122e-05
step: 290, loss: 5.167512426851317e-05
step: 300, loss: 1.60408417286817e-05
step: 310, loss: 1.940472975547891e-05
step: 320, loss: 0.013487594202160835
step: 330, loss: 0.00011815692414529622
step: 340, loss: 4.9300524551654235e-05
step: 350, loss: 9.488929936196655e-05
step: 360, loss: 3.0314733521663584e-05
step: 370, loss: 0.004960267338901758
step: 380, loss: 2.6735451683634892e-05
step: 390, loss: 0.0008833407191559672
step: 400, loss: 4.718064155895263e-05
step: 410, loss: 0.002201813505962491
step: 420, loss: 0.12229073792695999
step: 430, loss: 0.00035222797305323184
step: 440, loss: 0.002130570588633418
step: 450, loss: 0.0011983413714915514
step: 460, loss: 0.000841963745187968
epoch 18: dev_f1=0.9830890642615557, f1=0.9786276715410572, best_f1=0.9751131221719457
step: 0, loss: 0.00010470213601365685
step: 10, loss: 5.638364018523134e-05
step: 20, loss: 0.051947012543678284
step: 30, loss: 2.0827375919907354e-05
step: 40, loss: 0.00010460674820933491
step: 50, loss: 4.732196612167172e-05
step: 60, loss: 1.4345905583468266e-05
step: 70, loss: 6.720859528286383e-05
step: 80, loss: 3.85948660550639e-05
step: 90, loss: 4.326057023718022e-05
step: 100, loss: 4.612898555933498e-05
step: 110, loss: 8.891021570889279e-05
step: 120, loss: 0.018285810947418213
step: 130, loss: 0.005178556777536869
step: 140, loss: 0.00013365938502829522
step: 150, loss: 0.0005343972006812692
step: 160, loss: 0.00012901387526653707
step: 170, loss: 0.00013278017286211252
step: 180, loss: 0.00028761010617017746
step: 190, loss: 1.2196500392747112e-05
step: 200, loss: 4.876179446000606e-05
step: 210, loss: 4.567895666696131e-05
step: 220, loss: 5.060746843810193e-05
step: 230, loss: 9.103908087126911e-05
step: 240, loss: 0.00012519778101705015
step: 250, loss: 6.810320337535813e-05
step: 260, loss: 0.00017920942627824843
step: 270, loss: 0.00023396953474730253
step: 280, loss: 0.00014074830687604845
step: 290, loss: 0.00021925443434156477
step: 300, loss: 3.135415317956358e-05
step: 310, loss: 0.00010237208334729075
step: 320, loss: 0.00011814667232101783
step: 330, loss: 4.00670433009509e-05
step: 340, loss: 7.001945050433278e-05
step: 350, loss: 4.563663969747722e-05
step: 360, loss: 3.722668407135643e-05
step: 370, loss: 3.469278817647137e-05
step: 380, loss: 3.851337169180624e-05
step: 390, loss: 0.00021272554295137525
step: 400, loss: 2.4191458578570746e-05
step: 410, loss: 0.0005354288732632995
step: 420, loss: 7.850299152778462e-05
step: 430, loss: 0.00011860027734655887
step: 440, loss: 7.479113264707848e-05
step: 450, loss: 0.0003101866750512272
step: 460, loss: 3.1388022762257606e-05
epoch 19: dev_f1=0.980963045912654, f1=0.9764309764309763, best_f1=0.9751131221719457
step: 0, loss: 6.556339212693274e-05
step: 10, loss: 0.00011205769988009706
step: 20, loss: 4.6430493966909125e-05
step: 30, loss: 3.4776414395309985e-05
step: 40, loss: 2.00564772967482e-05
step: 50, loss: 2.85413862002315e-05
step: 60, loss: 3.794361327891238e-05
step: 70, loss: 8.4859442722518e-05
step: 80, loss: 9.019494609674439e-05
step: 90, loss: 0.0001292979286517948
step: 100, loss: 0.00015006137255113572
step: 110, loss: 0.011350658722221851
step: 120, loss: 0.003316714661195874
step: 130, loss: 5.44380527571775e-05
step: 140, loss: 0.000582758104428649
step: 150, loss: 3.870886212098412e-05
step: 160, loss: 3.294712951174006e-05
step: 170, loss: 2.680936813703738e-05
step: 180, loss: 0.0005106904427520931
step: 190, loss: 2.006780960073229e-05
step: 200, loss: 5.6349799706367776e-05
step: 210, loss: 0.00010421570914331824
step: 220, loss: 7.5875963375438e-05
step: 230, loss: 0.002665333915501833
step: 240, loss: 2.0797862816834822e-05
step: 250, loss: 1.8272217857884243e-05
step: 260, loss: 1.7653768736636266e-05
step: 270, loss: 2.3420294382958673e-05
step: 280, loss: 2.3244847398018464e-05
step: 290, loss: 4.866785820922814e-05
step: 300, loss: 0.0006391268689185381
step: 310, loss: 7.405413634842262e-05
step: 320, loss: 2.331185169168748e-05
step: 330, loss: 1.838766002038028e-05
step: 340, loss: 0.00013274644152261317
step: 350, loss: 3.914573244401254e-05
step: 360, loss: 7.157390791689977e-05
step: 370, loss: 9.122432675212622e-05
step: 380, loss: 3.126427691313438e-05
step: 390, loss: 0.0002413649344816804
step: 400, loss: 9.133180719800293e-05
step: 410, loss: 0.0007068848935887218
step: 420, loss: 6.231389852473512e-05
step: 430, loss: 0.00036778085632249713
step: 440, loss: 3.234859832446091e-05
step: 450, loss: 0.0001302157179452479
step: 460, loss: 0.00020873085304629058
epoch 20: dev_f1=0.980963045912654, f1=0.9764309764309763, best_f1=0.9751131221719457
