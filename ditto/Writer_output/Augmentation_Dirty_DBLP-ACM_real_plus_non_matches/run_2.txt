cuda
Device: cuda
step: 0, loss: 0.4745166599750519
step: 10, loss: 0.7550475597381592
step: 20, loss: 0.1686791330575943
step: 30, loss: 0.45852577686309814
step: 40, loss: 0.2560386061668396
step: 50, loss: 0.1067597046494484
step: 60, loss: 0.16072949767112732
step: 70, loss: 0.17745095491409302
step: 80, loss: 0.10614199191331863
step: 90, loss: 0.1565210521221161
step: 100, loss: 0.09205394238233566
step: 110, loss: 0.11730284243822098
step: 120, loss: 0.22690008580684662
step: 130, loss: 0.15942545235157013
step: 140, loss: 0.17819344997406006
step: 150, loss: 0.0914774090051651
step: 160, loss: 0.11277935653924942
step: 170, loss: 0.23212595283985138
step: 180, loss: 0.11185477674007416
step: 190, loss: 0.07466892153024673
step: 200, loss: 0.08404899388551712
step: 210, loss: 0.09983379393815994
step: 220, loss: 0.12073452770709991
step: 230, loss: 0.07963227480649948
step: 240, loss: 0.24205589294433594
step: 250, loss: 0.15171214938163757
step: 260, loss: 0.14845609664916992
step: 270, loss: 0.0646916925907135
step: 280, loss: 0.21574801206588745
step: 290, loss: 0.1346774399280548
step: 300, loss: 0.11851371824741364
step: 310, loss: 0.038453299552202225
step: 320, loss: 0.08812921494245529
step: 330, loss: 0.11320971697568893
step: 340, loss: 0.11182918399572372
step: 350, loss: 0.1297711431980133
step: 360, loss: 0.043459054082632065
step: 370, loss: 0.2644846439361572
step: 380, loss: 0.13238219916820526
step: 390, loss: 0.12195514887571335
step: 400, loss: 0.03697561100125313
step: 410, loss: 0.16975891590118408
step: 420, loss: 0.03342176973819733
epoch 1: dev_f1=0.9787234042553192, f1=0.9695603156708005, best_f1=0.9695603156708005
step: 0, loss: 0.1214008778333664
step: 10, loss: 0.07946652173995972
step: 20, loss: 0.1012815311551094
step: 30, loss: 0.15523871779441833
step: 40, loss: 0.19415342807769775
step: 50, loss: 0.09312741458415985
step: 60, loss: 0.0891297236084938
step: 70, loss: 0.07064998149871826
step: 80, loss: 0.052739985287189484
step: 90, loss: 0.006447795778512955
step: 100, loss: 0.14827170968055725
step: 110, loss: 0.08596881479024887
step: 120, loss: 0.07192452251911163
step: 130, loss: 0.14142875373363495
step: 140, loss: 0.11645636707544327
step: 150, loss: 0.12930452823638916
step: 160, loss: 0.059061795473098755
step: 170, loss: 0.08947718143463135
step: 180, loss: 0.018284987658262253
step: 190, loss: 0.1006474569439888
step: 200, loss: 0.054256848990917206
step: 210, loss: 0.10710277408361435
step: 220, loss: 0.03069915995001793
step: 230, loss: 0.0701444000005722
step: 240, loss: 0.11331497877836227
step: 250, loss: 0.31346872448921204
step: 260, loss: 0.19535039365291595
step: 270, loss: 0.09929896891117096
step: 280, loss: 0.130369633436203
step: 290, loss: 0.09368228912353516
step: 300, loss: 0.08481389284133911
step: 310, loss: 0.045148514211177826
step: 320, loss: 0.037328869104385376
step: 330, loss: 0.061376649886369705
step: 340, loss: 0.09672921895980835
step: 350, loss: 0.01409866102039814
step: 360, loss: 0.10822457820177078
step: 370, loss: 0.13274748623371124
step: 380, loss: 0.09590554237365723
step: 390, loss: 0.09705040603876114
step: 400, loss: 0.07160460203886032
step: 410, loss: 0.20406873524188995
step: 420, loss: 0.0635865181684494
epoch 2: dev_f1=0.9832402234636871, f1=0.978675645342312, best_f1=0.978675645342312
step: 0, loss: 0.08231396973133087
step: 10, loss: 0.10331331193447113
step: 20, loss: 0.018574994057416916
step: 30, loss: 0.079529769718647
step: 40, loss: 0.10123615711927414
step: 50, loss: 0.12346915155649185
step: 60, loss: 0.14513720571994781
step: 70, loss: 0.14593248069286346
step: 80, loss: 0.06562522798776627
step: 90, loss: 0.019271120429039
step: 100, loss: 0.19818969070911407
step: 110, loss: 0.08572375029325485
step: 120, loss: 0.031905703246593475
step: 130, loss: 0.08682546764612198
step: 140, loss: 0.10750345885753632
step: 150, loss: 0.01732502691447735
step: 160, loss: 0.15020550787448883
step: 170, loss: 0.09654053300619125
step: 180, loss: 0.03136589750647545
step: 190, loss: 0.07203268259763718
step: 200, loss: 0.10566070675849915
step: 210, loss: 0.0721212774515152
step: 220, loss: 0.08347944915294647
step: 230, loss: 0.027897372841835022
step: 240, loss: 0.008114974945783615
step: 250, loss: 0.043354831635951996
step: 260, loss: 0.030124632641673088
step: 270, loss: 0.07871363312005997
step: 280, loss: 0.20597170293331146
step: 290, loss: 0.1791696399450302
step: 300, loss: 0.055983442813158035
step: 310, loss: 0.10907915234565735
step: 320, loss: 0.06087164580821991
step: 330, loss: 0.10216806828975677
step: 340, loss: 0.0435827262699604
step: 350, loss: 0.0655939057469368
step: 360, loss: 0.11586296558380127
step: 370, loss: 0.2214442789554596
step: 380, loss: 0.05694740638136864
step: 390, loss: 0.03335052356123924
step: 400, loss: 0.04307756572961807
step: 410, loss: 0.014404301531612873
step: 420, loss: 0.07183682918548584
epoch 3: dev_f1=0.9898989898989898, f1=0.9799107142857142, best_f1=0.9799107142857142
step: 0, loss: 0.03779550641775131
step: 10, loss: 0.044715896248817444
step: 20, loss: 0.04780282452702522
step: 30, loss: 0.09115830808877945
step: 40, loss: 0.012380959466099739
step: 50, loss: 0.11761903017759323
step: 60, loss: 0.042272958904504776
step: 70, loss: 0.08997169882059097
step: 80, loss: 0.02991502359509468
step: 90, loss: 0.05176388472318649
step: 100, loss: 0.07122710347175598
step: 110, loss: 0.09147372841835022
step: 120, loss: 0.09863840788602829
step: 130, loss: 0.09462270885705948
step: 140, loss: 0.16018491983413696
step: 150, loss: 0.09624780714511871
step: 160, loss: 0.12098611146211624
step: 170, loss: 0.040595460683107376
step: 180, loss: 0.09865158796310425
step: 190, loss: 0.10457325726747513
step: 200, loss: 0.060003288090229034
step: 210, loss: 0.032307881861925125
step: 220, loss: 0.00832852441817522
step: 230, loss: 0.03600175306200981
step: 240, loss: 0.048971690237522125
step: 250, loss: 0.04147264361381531
step: 260, loss: 0.11615608632564545
step: 270, loss: 0.14908994734287262
step: 280, loss: 0.034296296536922455
step: 290, loss: 0.00621751369908452
step: 300, loss: 0.015962956473231316
step: 310, loss: 0.02339997887611389
step: 320, loss: 0.048350658267736435
step: 330, loss: 0.09588935226202011
step: 340, loss: 0.03787548094987869
step: 350, loss: 0.1369120478630066
step: 360, loss: 0.01862964779138565
step: 370, loss: 0.0972127765417099
step: 380, loss: 0.04569254815578461
step: 390, loss: 0.0690285861492157
step: 400, loss: 0.15449588000774384
step: 410, loss: 0.0002850763557944447
step: 420, loss: 0.0002808851713780314
epoch 4: dev_f1=0.9898074745186863, f1=0.9829738933030647, best_f1=0.9799107142857142
step: 0, loss: 0.08094535768032074
step: 10, loss: 0.09452053904533386
step: 20, loss: 0.0885385274887085
step: 30, loss: 0.013341221958398819
step: 40, loss: 0.09502683579921722
step: 50, loss: 0.1310986429452896
step: 60, loss: 0.1252962052822113
step: 70, loss: 0.12683366239070892
step: 80, loss: 0.06519393622875214
step: 90, loss: 0.07888862490653992
step: 100, loss: 0.018891971558332443
step: 110, loss: 0.08124179393053055
step: 120, loss: 0.11924266815185547
step: 130, loss: 0.07348082959651947
step: 140, loss: 0.14120453596115112
step: 150, loss: 0.12077309936285019
step: 160, loss: 0.08351097255945206
step: 170, loss: 0.0892842710018158
step: 180, loss: 0.13709625601768494
step: 190, loss: 0.09424765408039093
step: 200, loss: 0.0929030254483223
step: 210, loss: 0.07511445879936218
step: 220, loss: 0.03651227429509163
step: 230, loss: 0.12110769003629684
step: 240, loss: 0.08022379875183105
step: 250, loss: 0.08938070386648178
step: 260, loss: 0.03559283912181854
step: 270, loss: 0.14998091757297516
step: 280, loss: 0.027749162167310715
step: 290, loss: 0.038797441869974136
step: 300, loss: 0.0019466503290459514
step: 310, loss: 0.09284067153930664
step: 320, loss: 0.04386505112051964
step: 330, loss: 0.03286658227443695
step: 340, loss: 0.14254282414913177
step: 350, loss: 0.09790582209825516
step: 360, loss: 0.10755102336406708
step: 370, loss: 0.10367688536643982
step: 380, loss: 0.025006702169775963
step: 390, loss: 0.009166209027171135
step: 400, loss: 0.030108192935585976
step: 410, loss: 0.15122881531715393
step: 420, loss: 0.06295079737901688
epoch 5: dev_f1=0.9887640449438202, f1=0.9820224719101124, best_f1=0.9799107142857142
step: 0, loss: 0.005712530110031366
step: 10, loss: 0.13181300461292267
step: 20, loss: 0.20810997486114502
step: 30, loss: 0.15601366758346558
step: 40, loss: 0.1068437322974205
step: 50, loss: 0.06179119274020195
step: 60, loss: 0.03695739805698395
step: 70, loss: 0.05340676009654999
step: 80, loss: 0.0698150172829628
step: 90, loss: 0.018051855266094208
step: 100, loss: 0.13983629643917084
step: 110, loss: 0.13294659554958344
step: 120, loss: 0.21878564357757568
step: 130, loss: 0.13457131385803223
step: 140, loss: 0.09099623560905457
step: 150, loss: 0.07145994156599045
step: 160, loss: 0.042141836136579514
step: 170, loss: 0.0646812841296196
step: 180, loss: 0.17936313152313232
step: 190, loss: 0.02942933700978756
step: 200, loss: 0.16857337951660156
step: 210, loss: 0.010278663598001003
step: 220, loss: 0.11563711613416672
step: 230, loss: 0.07962746173143387
step: 240, loss: 0.07417097687721252
step: 250, loss: 0.0747782289981842
step: 260, loss: 0.00021088984794914722
step: 270, loss: 0.07191785424947739
step: 280, loss: 0.007804050110280514
step: 290, loss: 0.13884469866752625
step: 300, loss: 0.09733951091766357
step: 310, loss: 0.07193789631128311
step: 320, loss: 0.02376719005405903
step: 330, loss: 0.11784979701042175
step: 340, loss: 0.040993060916662216
step: 350, loss: 0.050256405025720596
step: 360, loss: 0.13431420922279358
step: 370, loss: 0.027653507888317108
step: 380, loss: 0.013797410763800144
step: 390, loss: 0.12819276750087738
step: 400, loss: 0.04767190292477608
step: 410, loss: 0.11714287102222443
step: 420, loss: 0.16945108771324158
epoch 6: dev_f1=0.9852774631936579, f1=0.9807037457434733, best_f1=0.9799107142857142
step: 0, loss: 0.07007631659507751
step: 10, loss: 0.018400298431515694
step: 20, loss: 0.1474040150642395
step: 30, loss: 0.06846261024475098
step: 40, loss: 0.07382364571094513
step: 50, loss: 0.07694293558597565
step: 60, loss: 0.09792586416006088
step: 70, loss: 0.11175050586462021
step: 80, loss: 0.08264568448066711
step: 90, loss: 0.13691149652004242
step: 100, loss: 0.010967934504151344
step: 110, loss: 0.09893212467432022
step: 120, loss: 0.25883597135543823
step: 130, loss: 0.05330631881952286
step: 140, loss: 0.06725241988897324
step: 150, loss: 0.12353138625621796
step: 160, loss: 0.0005094798980280757
step: 170, loss: 0.13237757980823517
step: 180, loss: 0.040613751858472824
step: 190, loss: 0.0521891824901104
step: 200, loss: 0.03362814709544182
step: 210, loss: 0.05988192558288574
step: 220, loss: 0.16523215174674988
step: 230, loss: 0.17324446141719818
step: 240, loss: 0.09671841561794281
step: 250, loss: 0.03398875519633293
step: 260, loss: 0.10479719191789627
step: 270, loss: 0.08737670630216599
step: 280, loss: 0.07349580526351929
step: 290, loss: 0.06853069365024567
step: 300, loss: 0.07823818922042847
step: 310, loss: 0.05115863308310509
step: 320, loss: 0.2963659167289734
step: 330, loss: 0.0027738772332668304
step: 340, loss: 0.05060231313109398
step: 350, loss: 0.017783382907509804
step: 360, loss: 0.08964438736438751
step: 370, loss: 0.09269270300865173
step: 380, loss: 0.20068340003490448
step: 390, loss: 0.0651128888130188
step: 400, loss: 0.12703000009059906
step: 410, loss: 0.010945464484393597
step: 420, loss: 0.05193702504038811
epoch 7: dev_f1=0.9888392857142857, f1=0.978865406006674, best_f1=0.9799107142857142
step: 0, loss: 0.029234645888209343
step: 10, loss: 0.10377485305070877
step: 20, loss: 0.08733244985342026
step: 30, loss: 0.0931566059589386
step: 40, loss: 0.012743283994495869
step: 50, loss: 0.16078628599643707
step: 60, loss: 0.08466844260692596
step: 70, loss: 0.02597937546670437
step: 80, loss: 0.006958887446671724
step: 90, loss: 0.0689626932144165
step: 100, loss: 0.065334253013134
step: 110, loss: 0.09028523415327072
step: 120, loss: 0.1442122757434845
step: 130, loss: 0.06911004334688187
step: 140, loss: 0.08580582588911057
step: 150, loss: 0.04142114147543907
step: 160, loss: 0.0346863716840744
step: 170, loss: 0.031764693558216095
step: 180, loss: 0.1242685541510582
step: 190, loss: 0.07645779103040695
step: 200, loss: 0.0796375498175621
step: 210, loss: 0.10276365280151367
step: 220, loss: 0.21096493303775787
step: 230, loss: 0.06666413694620132
step: 240, loss: 0.07192324101924896
step: 250, loss: 0.13109759986400604
step: 260, loss: 0.022766493260860443
step: 270, loss: 0.03348841145634651
step: 280, loss: 0.09143651276826859
step: 290, loss: 0.03931213170289993
step: 300, loss: 0.10028289258480072
step: 310, loss: 0.16868489980697632
step: 320, loss: 0.07231160253286362
step: 330, loss: 0.07382355630397797
step: 340, loss: 0.017538107931613922
step: 350, loss: 0.06872375309467316
step: 360, loss: 0.08429300785064697
step: 370, loss: 0.028263794258236885
step: 380, loss: 0.09530007094144821
step: 390, loss: 0.07701443880796432
step: 400, loss: 0.0171863604336977
step: 410, loss: 0.0306154265999794
step: 420, loss: 0.0501827746629715
epoch 8: dev_f1=0.9909502262443439, f1=0.9864253393665158, best_f1=0.9864253393665158
step: 0, loss: 0.05710688233375549
step: 10, loss: 0.06605686247348785
step: 20, loss: 0.04573672637343407
step: 30, loss: 0.009840045124292374
step: 40, loss: 0.06774498522281647
step: 50, loss: 0.01704900525510311
step: 60, loss: 0.06404388695955276
step: 70, loss: 0.10281724482774734
step: 80, loss: 0.1064244955778122
step: 90, loss: 0.03647607937455177
step: 100, loss: 0.09563542902469635
step: 110, loss: 0.018136659637093544
step: 120, loss: 0.021661963313817978
step: 130, loss: 0.01767890527844429
step: 140, loss: 0.09483231604099274
step: 150, loss: 0.3361227214336395
step: 160, loss: 0.08838396519422531
step: 170, loss: 0.025000102818012238
step: 180, loss: 0.09680258482694626
step: 190, loss: 0.03445589542388916
step: 200, loss: 0.20435577630996704
step: 210, loss: 0.09151138365268707
step: 220, loss: 0.009473503567278385
step: 230, loss: 0.0398695282638073
step: 240, loss: 0.14506591856479645
step: 250, loss: 0.10908381640911102
step: 260, loss: 0.017928101122379303
step: 270, loss: 0.12022984772920609
step: 280, loss: 0.08391249924898148
step: 290, loss: 0.03987785801291466
step: 300, loss: 0.03853192552924156
step: 310, loss: 0.08180821686983109
step: 320, loss: 0.11553874611854553
step: 330, loss: 0.04079499468207359
step: 340, loss: 0.04686535894870758
step: 350, loss: 0.023187950253486633
step: 360, loss: 0.09549517929553986
step: 370, loss: 0.007416314445436001
step: 380, loss: 0.05187710374593735
step: 390, loss: 0.00848926417529583
step: 400, loss: 0.050309520214796066
step: 410, loss: 0.021259140223264694
step: 420, loss: 0.08877168595790863
epoch 9: dev_f1=0.9887892376681614, f1=0.9854423292273236, best_f1=0.9864253393665158
step: 0, loss: 0.017448563128709793
step: 10, loss: 0.08300415426492691
step: 20, loss: 0.06546439975500107
step: 30, loss: 0.08955544978380203
step: 40, loss: 0.06772130727767944
step: 50, loss: 0.07945545762777328
step: 60, loss: 0.17676815390586853
step: 70, loss: 0.08483771234750748
step: 80, loss: 0.038603223860263824
step: 90, loss: 0.03995254635810852
step: 100, loss: 0.13263744115829468
step: 110, loss: 0.021046390756964684
step: 120, loss: 0.007683698553591967
step: 130, loss: 0.05138343945145607
step: 140, loss: 0.02310073748230934
step: 150, loss: 0.14218030869960785
step: 160, loss: 0.05310468748211861
step: 170, loss: 0.00027580861933529377
step: 180, loss: 0.07546742260456085
step: 190, loss: 0.005887683015316725
step: 200, loss: 0.05457040295004845
step: 210, loss: 0.07127002626657486
step: 220, loss: 0.1756068766117096
step: 230, loss: 0.049191251397132874
step: 240, loss: 0.09757962822914124
step: 250, loss: 0.02984563075006008
step: 260, loss: 0.04879799857735634
step: 270, loss: 0.12083820253610611
step: 280, loss: 0.0397292897105217
step: 290, loss: 0.0306246355175972
step: 300, loss: 0.07496289163827896
step: 310, loss: 0.035435862839221954
step: 320, loss: 0.0485912449657917
step: 330, loss: 0.031970296055078506
step: 340, loss: 0.04814749211072922
step: 350, loss: 0.11331706494092941
step: 360, loss: 0.04303410276770592
step: 370, loss: 0.018869586288928986
step: 380, loss: 0.07366650551557541
step: 390, loss: 0.007726929150521755
step: 400, loss: 0.13513723015785217
step: 410, loss: 0.056192126125097275
step: 420, loss: 0.1333049237728119
epoch 10: dev_f1=0.992108229988726, f1=0.9831271091113611, best_f1=0.9831271091113611
step: 0, loss: 0.03782908245921135
step: 10, loss: 0.07636144757270813
step: 20, loss: 0.07166039198637009
step: 30, loss: 0.059708353132009506
step: 40, loss: 0.15393486618995667
step: 50, loss: 0.02926407754421234
step: 60, loss: 0.07015901803970337
step: 70, loss: 0.059764180332422256
step: 80, loss: 0.043208662420511246
step: 90, loss: 0.06485159695148468
step: 100, loss: 0.045425403863191605
step: 110, loss: 0.013990961946547031
step: 120, loss: 7.121933595044538e-05
step: 130, loss: 0.08795739710330963
step: 140, loss: 0.021920442581176758
step: 150, loss: 0.13918745517730713
step: 160, loss: 0.08492942154407501
step: 170, loss: 0.0372532457113266
step: 180, loss: 0.04863610118627548
step: 190, loss: 0.05727119743824005
step: 200, loss: 0.08336975425481796
step: 210, loss: 0.11081745475530624
step: 220, loss: 0.020089033991098404
step: 230, loss: 0.13661333918571472
step: 240, loss: 0.06260852515697479
step: 250, loss: 0.06601487100124359
step: 260, loss: 0.019240086898207664
step: 270, loss: 0.06642389297485352
step: 280, loss: 0.14283965528011322
step: 290, loss: 0.08802038431167603
step: 300, loss: 0.10925505310297012
step: 310, loss: 0.10241900384426117
step: 320, loss: 0.052734583616256714
step: 330, loss: 0.04967973008751869
step: 340, loss: 0.13534818589687347
step: 350, loss: 0.02636646293103695
step: 360, loss: 0.11724524199962616
step: 370, loss: 0.0744202509522438
step: 380, loss: 0.009515630081295967
step: 390, loss: 0.1636894941329956
step: 400, loss: 0.06028904765844345
step: 410, loss: 0.06028880551457405
step: 420, loss: 0.049070727080106735
epoch 11: dev_f1=0.9898989898989898, f1=0.9796839729119639, best_f1=0.9831271091113611
step: 0, loss: 0.11041097342967987
step: 10, loss: 0.05729909986257553
step: 20, loss: 0.12670671939849854
step: 30, loss: 0.12229141592979431
step: 40, loss: 0.007032366469502449
step: 50, loss: 0.08906558901071548
step: 60, loss: 0.130682110786438
step: 70, loss: 0.07166601717472076
step: 80, loss: 0.06948668509721756
step: 90, loss: 0.008078856393694878
step: 100, loss: 0.07364225387573242
step: 110, loss: 0.005507559049874544
step: 120, loss: 0.05495408922433853
step: 130, loss: 0.04858134314417839
step: 140, loss: 0.08867380768060684
step: 150, loss: 0.16582684218883514
step: 160, loss: 0.03442564606666565
step: 170, loss: 0.007385130971670151
step: 180, loss: 0.03241925686597824
step: 190, loss: 0.049346718937158585
step: 200, loss: 0.07334673404693604
step: 210, loss: 0.037974752485752106
step: 220, loss: 0.05389009416103363
step: 230, loss: 0.06703676283359528
step: 240, loss: 0.05101766064763069
step: 250, loss: 0.0906638652086258
step: 260, loss: 0.08700626343488693
step: 270, loss: 0.06497997790575027
step: 280, loss: 0.1306913197040558
step: 290, loss: 0.013781460002064705
step: 300, loss: 0.0232524536550045
step: 310, loss: 0.04324319586157799
step: 320, loss: 0.05189921334385872
step: 330, loss: 0.08406319469213486
step: 340, loss: 0.10310579836368561
step: 350, loss: 0.10292025655508041
step: 360, loss: 0.015263590030372143
step: 370, loss: 0.0682162493467331
step: 380, loss: 0.06355395913124084
step: 390, loss: 0.04475990682840347
step: 400, loss: 0.0435246005654335
step: 410, loss: 0.21150369942188263
step: 420, loss: 0.08990272879600525
epoch 12: dev_f1=0.988814317673378, f1=0.978675645342312, best_f1=0.9831271091113611
step: 0, loss: 0.08443352580070496
step: 10, loss: 0.08595681190490723
step: 20, loss: 0.05486370623111725
step: 30, loss: 0.028891004621982574
step: 40, loss: 0.07571178674697876
step: 50, loss: 0.14514777064323425
step: 60, loss: 0.02285536751151085
step: 70, loss: 0.11982026696205139
step: 80, loss: 0.10981589555740356
step: 90, loss: 0.011340106837451458
step: 100, loss: 0.09189606457948685
step: 110, loss: 0.09930209070444107
step: 120, loss: 0.07946883887052536
step: 130, loss: 0.12434984743595123
step: 140, loss: 0.030301924794912338
step: 150, loss: 0.039797332137823105
step: 160, loss: 0.00764672365039587
step: 170, loss: 0.0885997861623764
step: 180, loss: 0.10925158858299255
step: 190, loss: 0.10293067991733551
step: 200, loss: 0.11438529938459396
step: 210, loss: 0.006145305000245571
step: 220, loss: 0.06708992272615433
step: 230, loss: 0.011342023499310017
step: 240, loss: 0.02230369672179222
step: 250, loss: 0.04036847874522209
step: 260, loss: 0.020662162452936172
step: 270, loss: 0.0514870323240757
step: 280, loss: 0.03680788725614548
step: 290, loss: 0.03767694532871246
step: 300, loss: 0.047243718057870865
step: 310, loss: 0.025199372321367264
step: 320, loss: 0.08144905418157578
step: 330, loss: 0.029648307710886
step: 340, loss: 0.017826898023486137
step: 350, loss: 0.059833280742168427
step: 360, loss: 0.029597343876957893
step: 370, loss: 0.06406064331531525
step: 380, loss: 0.04140477254986763
step: 390, loss: 0.002123877638950944
step: 400, loss: 0.029267575591802597
step: 410, loss: 0.05035442113876343
step: 420, loss: 0.02555151842534542
epoch 13: dev_f1=0.9898762654668166, f1=0.9807909604519773, best_f1=0.9831271091113611
step: 0, loss: 0.03425329551100731
step: 10, loss: 0.12241479754447937
step: 20, loss: 0.04653184488415718
step: 30, loss: 0.17955060303211212
step: 40, loss: 0.055506493896245956
step: 50, loss: 7.163849659264088e-05
step: 60, loss: 0.07652367651462555
step: 70, loss: 0.006338933482766151
step: 80, loss: 0.13988260924816132
step: 90, loss: 0.039299506694078445
step: 100, loss: 0.06273557990789413
step: 110, loss: 0.01476262230426073
step: 120, loss: 0.018219225108623505
step: 130, loss: 0.0948076918721199
step: 140, loss: 0.10458510369062424
step: 150, loss: 0.04141093045473099
step: 160, loss: 0.03033231943845749
step: 170, loss: 0.06588399410247803
step: 180, loss: 0.09036421030759811
step: 190, loss: 0.029359284788370132
step: 200, loss: 0.057020433247089386
step: 210, loss: 0.028245987370610237
step: 220, loss: 0.10365185141563416
step: 230, loss: 0.06325319409370422
step: 240, loss: 0.06684382259845734
step: 250, loss: 0.15124617516994476
step: 260, loss: 0.09293270856142044
step: 270, loss: 0.011199063621461391
step: 280, loss: 0.10403865575790405
step: 290, loss: 0.038688283413648605
step: 300, loss: 0.010587235912680626
step: 310, loss: 0.06500572711229324
step: 320, loss: 0.009045200422406197
step: 330, loss: 0.05362807959318161
step: 340, loss: 0.0481262132525444
step: 350, loss: 0.12764592468738556
step: 360, loss: 0.07269362360239029
step: 370, loss: 0.027845710515975952
step: 380, loss: 0.07268330454826355
step: 390, loss: 0.03514773026108742
step: 400, loss: 0.04657740145921707
step: 410, loss: 0.04650009423494339
step: 420, loss: 0.11813884973526001
epoch 14: dev_f1=0.987598647125141, f1=0.9853768278965129, best_f1=0.9831271091113611
step: 0, loss: 0.05147024244070053
step: 10, loss: 0.0014619595604017377
step: 20, loss: 0.11621362715959549
step: 30, loss: 0.023061512038111687
step: 40, loss: 0.04883469641208649
step: 50, loss: 0.04091393202543259
step: 60, loss: 0.12596002221107483
step: 70, loss: 0.08803398907184601
step: 80, loss: 0.01594465784728527
step: 90, loss: 0.004819995723664761
step: 100, loss: 0.013586454093456268
step: 110, loss: 0.03611050173640251
step: 120, loss: 0.059808291494846344
step: 130, loss: 0.013653096742928028
step: 140, loss: 0.3184686303138733
step: 150, loss: 0.17879308760166168
step: 160, loss: 0.020778721198439598
step: 170, loss: 0.014113543555140495
step: 180, loss: 0.009526005946099758
step: 190, loss: 0.0665709525346756
step: 200, loss: 0.03698623180389404
step: 210, loss: 0.07960052788257599
step: 220, loss: 0.07857175171375275
step: 230, loss: 0.04977874085307121
step: 240, loss: 0.0905662253499031
step: 250, loss: 0.0981481671333313
step: 260, loss: 0.0186312198638916
step: 270, loss: 0.029059048742055893
step: 280, loss: 0.021023375913500786
step: 290, loss: 0.1696402132511139
step: 300, loss: 0.013736570253968239
step: 310, loss: 0.04713093861937523
step: 320, loss: 0.019676774740219116
step: 330, loss: 0.05588874965906143
step: 340, loss: 0.13380712270736694
step: 350, loss: 0.0145409582182765
step: 360, loss: 0.07284494489431381
step: 370, loss: 0.046398114413022995
step: 380, loss: 0.12625230848789215
step: 390, loss: 0.046390365809202194
step: 400, loss: 0.009279935620725155
step: 410, loss: 0.06386002153158188
step: 420, loss: 0.04946041852235794
epoch 15: dev_f1=0.9876265466816648, f1=0.9842696629213483, best_f1=0.9831271091113611
step: 0, loss: 0.02193528227508068
step: 10, loss: 0.1609473079442978
step: 20, loss: 0.08857779204845428
step: 30, loss: 0.01082295086234808
step: 40, loss: 0.007150587625801563
step: 50, loss: 0.05239894986152649
step: 60, loss: 0.15052573382854462
step: 70, loss: 0.028658509254455566
step: 80, loss: 0.10129852592945099
step: 90, loss: 0.03420987352728844
step: 100, loss: 0.03907197713851929
step: 110, loss: 0.009226769208908081
step: 120, loss: 0.03751183673739433
step: 130, loss: 0.12057594954967499
step: 140, loss: 0.06809379160404205
step: 150, loss: 0.10181965678930283
step: 160, loss: 0.0009142369381152093
step: 170, loss: 0.14549008011817932
step: 180, loss: 0.04707621410489082
step: 190, loss: 0.06354334950447083
step: 200, loss: 0.010435226373374462
step: 210, loss: 0.18114817142486572
step: 220, loss: 0.03974992036819458
step: 230, loss: 0.06970320641994476
step: 240, loss: 0.0026879259385168552
step: 250, loss: 0.038653768599033356
step: 260, loss: 0.07271026074886322
step: 270, loss: 0.05193515494465828
step: 280, loss: 0.01595115289092064
step: 290, loss: 0.10584516823291779
step: 300, loss: 0.05114381015300751
step: 310, loss: 0.05707008019089699
step: 320, loss: 0.06171729788184166
step: 330, loss: 0.0948534682393074
step: 340, loss: 0.03297209367156029
step: 350, loss: 0.09710068255662918
step: 360, loss: 0.059329546988010406
step: 370, loss: 0.010759982280433178
step: 380, loss: 0.10334132611751556
step: 390, loss: 0.06557342410087585
step: 400, loss: 0.05916796252131462
step: 410, loss: 1.9229746612836607e-05
step: 420, loss: 0.06341271847486496
epoch 16: dev_f1=0.9898762654668166, f1=0.9842342342342343, best_f1=0.9831271091113611
step: 0, loss: 0.0906875804066658
step: 10, loss: 0.1469804346561432
step: 20, loss: 0.08112160116434097
step: 30, loss: 0.06694942712783813
step: 40, loss: 0.02869342640042305
step: 50, loss: 0.0009013456292450428
step: 60, loss: 0.044684067368507385
step: 70, loss: 0.010507676750421524
step: 80, loss: 0.0029954230412840843
step: 90, loss: 0.032590046525001526
step: 100, loss: 0.0779884085059166
step: 110, loss: 0.08367928117513657
step: 120, loss: 0.010251298546791077
step: 130, loss: 0.055979903787374496
step: 140, loss: 0.009162185713648796
step: 150, loss: 0.044248852878808975
step: 160, loss: 0.10634979605674744
step: 170, loss: 0.006086728069931269
step: 180, loss: 0.05916828662157059
step: 190, loss: 0.020802270621061325
step: 200, loss: 0.10097556561231613
step: 210, loss: 0.004083376377820969
step: 220, loss: 0.15651749074459076
step: 230, loss: 0.03925478830933571
step: 240, loss: 0.03230010345578194
step: 250, loss: 0.03721870854496956
step: 260, loss: 0.007024664897471666
step: 270, loss: 0.0047045061364769936
step: 280, loss: 0.16147607564926147
step: 290, loss: 0.004957766272127628
step: 300, loss: 0.00011931063636438921
step: 310, loss: 0.07511378824710846
step: 320, loss: 0.052250590175390244
step: 330, loss: 0.029211169108748436
step: 340, loss: 0.07002159208059311
step: 350, loss: 0.022582558915019035
step: 360, loss: 0.013205278664827347
step: 370, loss: 0.05067824199795723
step: 380, loss: 0.05569111928343773
step: 390, loss: 0.016245612874627113
step: 400, loss: 0.024491917341947556
step: 410, loss: 0.0456848181784153
step: 420, loss: 0.005160209722816944
epoch 17: dev_f1=0.9876265466816648, f1=0.9842696629213483, best_f1=0.9831271091113611
step: 0, loss: 0.0028351410292088985
step: 10, loss: 0.13307417929172516
step: 20, loss: 0.06133205071091652
step: 30, loss: 0.057056110352277756
step: 40, loss: 0.06370159238576889
step: 50, loss: 0.05662001296877861
step: 60, loss: 0.03924795612692833
step: 70, loss: 0.04178164154291153
step: 80, loss: 0.04081305116415024
step: 90, loss: 0.08824726939201355
step: 100, loss: 0.183018758893013
step: 110, loss: 0.0163460411131382
step: 120, loss: 0.056067828088998795
step: 130, loss: 0.041121918708086014
step: 140, loss: 0.08662552386522293
step: 150, loss: 0.07733242958784103
step: 160, loss: 0.06476294994354248
step: 170, loss: 0.0315338671207428
step: 180, loss: 0.09301617741584778
step: 190, loss: 0.0984601303935051
step: 200, loss: 0.10899534821510315
step: 210, loss: 0.030628154054284096
step: 220, loss: 0.004857946187257767
step: 230, loss: 0.03726058453321457
step: 240, loss: 0.022423155605793
step: 250, loss: 0.040722500532865524
step: 260, loss: 0.02290569804608822
step: 270, loss: 0.01761540398001671
step: 280, loss: 0.08923038840293884
step: 290, loss: 0.04579351469874382
step: 300, loss: 0.051540810614824295
step: 310, loss: 0.02901025116443634
step: 320, loss: 0.07710371166467667
step: 330, loss: 0.08620066940784454
step: 340, loss: 0.03470243141055107
step: 350, loss: 0.001971753081306815
step: 360, loss: 0.14422215521335602
step: 370, loss: 0.07287494093179703
step: 380, loss: 0.009947571903467178
step: 390, loss: 0.09625115245580673
step: 400, loss: 0.0005658785812556744
step: 410, loss: 0.01579921320080757
step: 420, loss: 0.11181562393903732
epoch 18: dev_f1=0.9898762654668166, f1=0.9843400447427293, best_f1=0.9831271091113611
step: 0, loss: 0.0029488527216017246
step: 10, loss: 0.12608236074447632
step: 20, loss: 0.03964545205235481
step: 30, loss: 0.024066342040896416
step: 40, loss: 0.04023115336894989
step: 50, loss: 0.006406733300536871
step: 60, loss: 0.0932559072971344
step: 70, loss: 0.05850794538855553
step: 80, loss: 0.15244613587856293
step: 90, loss: 0.0014246068894863129
step: 100, loss: 0.047779958695173264
step: 110, loss: 0.00022790308867115527
step: 120, loss: 0.037015486508607864
step: 130, loss: 0.03964695334434509
step: 140, loss: 0.0008937800885178149
step: 150, loss: 0.036965299397706985
step: 160, loss: 0.06609252840280533
step: 170, loss: 0.06365612894296646
step: 180, loss: 0.026950692757964134
step: 190, loss: 0.002769631566479802
step: 200, loss: 0.07973912358283997
step: 210, loss: 0.143345445394516
step: 220, loss: 0.029672227799892426
step: 230, loss: 0.037178754806518555
step: 240, loss: 0.0236391369253397
step: 250, loss: 0.12819921970367432
step: 260, loss: 0.0002515691739972681
step: 270, loss: 0.06516623497009277
step: 280, loss: 0.1573641002178192
step: 290, loss: 0.0737411305308342
step: 300, loss: 0.0030226586386561394
step: 310, loss: 0.04576229676604271
step: 320, loss: 0.08630964905023575
step: 330, loss: 0.007900605909526348
step: 340, loss: 0.023416757583618164
step: 350, loss: 0.03854427859187126
step: 360, loss: 0.054404281079769135
step: 370, loss: 0.12443247437477112
step: 380, loss: 0.14450594782829285
step: 390, loss: 0.0056184642016887665
step: 400, loss: 0.04121434688568115
step: 410, loss: 0.037764616310596466
step: 420, loss: 0.027666427195072174
epoch 19: dev_f1=0.9898762654668166, f1=0.9853768278965129, best_f1=0.9831271091113611
step: 0, loss: 0.06005483493208885
step: 10, loss: 0.03713114932179451
step: 20, loss: 0.01961979642510414
step: 30, loss: 0.10546501725912094
step: 40, loss: 0.05765920877456665
step: 50, loss: 0.01823907345533371
step: 60, loss: 0.0006229041027836502
step: 70, loss: 0.056516021490097046
step: 80, loss: 0.13451212644577026
step: 90, loss: 0.04028558358550072
step: 100, loss: 0.017575418576598167
step: 110, loss: 0.018679244443774223
step: 120, loss: 0.020928766578435898
step: 130, loss: 0.054199621081352234
step: 140, loss: 2.2086922399466857e-05
step: 150, loss: 0.020446117967367172
step: 160, loss: 0.04203423857688904
step: 170, loss: 0.02891037054359913
step: 180, loss: 0.05851367488503456
step: 190, loss: 0.059602003544569016
step: 200, loss: 0.022352144122123718
step: 210, loss: 0.016991231590509415
step: 220, loss: 0.03599289804697037
step: 230, loss: 0.0236629918217659
step: 240, loss: 0.003961064852774143
step: 250, loss: 0.034554339945316315
step: 260, loss: 0.05648762360215187
step: 270, loss: 0.01807905174791813
step: 280, loss: 0.0622330866754055
step: 290, loss: 0.043357692658901215
step: 300, loss: 0.01943315751850605
step: 310, loss: 0.0774594098329544
step: 320, loss: 0.043569620698690414
step: 330, loss: 0.08773860335350037
step: 340, loss: 0.0290803462266922
step: 350, loss: 0.048544060438871384
step: 360, loss: 0.023006848990917206
step: 370, loss: 0.040268588811159134
step: 380, loss: 0.0021393042989075184
step: 390, loss: 0.07561878114938736
step: 400, loss: 0.041755560785532
step: 410, loss: 0.012572516687214375
step: 420, loss: 0.023319296538829803
epoch 20: dev_f1=0.9898762654668166, f1=0.9842696629213483, best_f1=0.9831271091113611
