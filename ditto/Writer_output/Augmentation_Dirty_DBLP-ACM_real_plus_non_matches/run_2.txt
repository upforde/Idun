cuda
Device: cuda
step: 0, loss: 0.70655357837677
step: 10, loss: 0.5709572434425354
step: 20, loss: 0.2304733246564865
step: 30, loss: 0.33534109592437744
step: 40, loss: 0.1680920273065567
step: 50, loss: 0.10971540957689285
step: 60, loss: 0.19055306911468506
step: 70, loss: 0.17258232831954956
step: 80, loss: 0.164641335606575
step: 90, loss: 0.18154136836528778
step: 100, loss: 0.07623696327209473
step: 110, loss: 0.23331762850284576
step: 120, loss: 0.10464780032634735
step: 130, loss: 0.08789263665676117
step: 140, loss: 0.21405476331710815
step: 150, loss: 0.07669860124588013
step: 160, loss: 0.20436860620975494
step: 170, loss: 0.16925692558288574
step: 180, loss: 0.2394687980413437
step: 190, loss: 0.28237399458885193
step: 200, loss: 0.09405173361301422
step: 210, loss: 0.029340196400880814
step: 220, loss: 0.08899523317813873
step: 230, loss: 0.13054873049259186
step: 240, loss: 0.14099839329719543
step: 250, loss: 0.20662005245685577
step: 260, loss: 0.1443568468093872
step: 270, loss: 0.07382023334503174
step: 280, loss: 0.15461425483226776
step: 290, loss: 0.10402452200651169
step: 300, loss: 0.26718175411224365
step: 310, loss: 0.012941054999828339
step: 320, loss: 0.15076713263988495
step: 330, loss: 0.08707242459058762
step: 340, loss: 0.06266456842422485
step: 350, loss: 0.09752850234508514
step: 360, loss: 0.13286727666854858
step: 370, loss: 0.03264089673757553
step: 380, loss: 0.08763682097196579
step: 390, loss: 0.050238143652677536
step: 400, loss: 0.015485966578125954
step: 410, loss: 0.11326134204864502
step: 420, loss: 0.07292889058589935
epoch 1: dev_f1=0.9842696629213483, f1=0.9743589743589743, best_f1=0.9743589743589743
step: 0, loss: 0.06769133359193802
step: 10, loss: 0.017473770305514336
step: 20, loss: 0.029374923557043076
step: 30, loss: 0.11041385680437088
step: 40, loss: 0.07036875188350677
step: 50, loss: 0.059501808136701584
step: 60, loss: 0.10355080664157867
step: 70, loss: 0.07837309688329697
step: 80, loss: 0.0981680154800415
step: 90, loss: 0.0409235917031765
step: 100, loss: 0.20413146913051605
step: 110, loss: 0.0393575094640255
step: 120, loss: 0.027685871347784996
step: 130, loss: 0.0430019348859787
step: 140, loss: 0.04088598117232323
step: 150, loss: 0.0613383948802948
step: 160, loss: 0.23766715824604034
step: 170, loss: 0.08233612775802612
step: 180, loss: 0.008683006279170513
step: 190, loss: 0.10340560227632523
step: 200, loss: 0.02946888841688633
step: 210, loss: 0.019450718536973
step: 220, loss: 0.0329129658639431
step: 230, loss: 0.02060185745358467
step: 240, loss: 0.040382131934165955
step: 250, loss: 0.10223901271820068
step: 260, loss: 0.1462235301733017
step: 270, loss: 0.07602211833000183
step: 280, loss: 0.09859669208526611
step: 290, loss: 0.03930361941456795
step: 300, loss: 0.1027912050485611
step: 310, loss: 0.058068159967660904
step: 320, loss: 0.17769953608512878
step: 330, loss: 0.11648356914520264
step: 340, loss: 0.07033353298902512
step: 350, loss: 0.09288737922906876
step: 360, loss: 0.08155553042888641
step: 370, loss: 0.12362554669380188
step: 380, loss: 0.14873278141021729
step: 390, loss: 0.09798367321491241
step: 400, loss: 0.010778024792671204
step: 410, loss: 0.0768762156367302
step: 420, loss: 0.006364320870488882
epoch 2: dev_f1=0.9843400447427293, f1=0.9776286353467561, best_f1=0.9776286353467561
step: 0, loss: 0.08556870371103287
step: 10, loss: 0.034854114055633545
step: 20, loss: 0.029228122904896736
step: 30, loss: 0.09174942970275879
step: 40, loss: 0.03767864778637886
step: 50, loss: 0.20814792811870575
step: 60, loss: 0.10943344980478287
step: 70, loss: 0.22183944284915924
step: 80, loss: 0.06466321647167206
step: 90, loss: 0.09196951985359192
step: 100, loss: 0.1370028853416443
step: 110, loss: 0.08159671723842621
step: 120, loss: 0.05224640667438507
step: 130, loss: 0.15888924896717072
step: 140, loss: 0.1815880686044693
step: 150, loss: 0.07945270836353302
step: 160, loss: 0.1275886595249176
step: 170, loss: 0.017624132335186005
step: 180, loss: 0.028861884027719498
step: 190, loss: 0.13555079698562622
step: 200, loss: 0.07090865820646286
step: 210, loss: 0.0320313461124897
step: 220, loss: 0.016749754548072815
step: 230, loss: 0.05997823178768158
step: 240, loss: 0.06655824184417725
step: 250, loss: 0.05959800258278847
step: 260, loss: 0.060519296675920486
step: 270, loss: 0.11307637393474579
step: 280, loss: 0.03349548950791359
step: 290, loss: 0.026581361889839172
step: 300, loss: 0.06687738001346588
step: 310, loss: 0.11675897240638733
step: 320, loss: 0.06808585673570633
step: 330, loss: 0.018425699323415756
step: 340, loss: 0.17578637599945068
step: 350, loss: 0.10723694413900375
step: 360, loss: 0.07219350337982178
step: 370, loss: 0.13551752269268036
step: 380, loss: 0.1295260637998581
step: 390, loss: 0.06318380683660507
step: 400, loss: 0.13204199075698853
step: 410, loss: 0.014663886278867722
step: 420, loss: 0.01452925056219101
epoch 3: dev_f1=0.9843400447427293, f1=0.9722530521642618, best_f1=0.9776286353467561
step: 0, loss: 0.05588672682642937
step: 10, loss: 0.06428457796573639
step: 20, loss: 0.04014827311038971
step: 30, loss: 0.12144580483436584
step: 40, loss: 0.0637475997209549
step: 50, loss: 0.06533931195735931
step: 60, loss: 0.05058266967535019
step: 70, loss: 0.21377906203269958
step: 80, loss: 0.038437191396951675
step: 90, loss: 0.08590216934680939
step: 100, loss: 0.10876642167568207
step: 110, loss: 0.09231255203485489
step: 120, loss: 0.12987366318702698
step: 130, loss: 0.12043903023004532
step: 140, loss: 0.057032715529203415
step: 150, loss: 0.044659294188022614
step: 160, loss: 0.05668657273054123
step: 170, loss: 0.012565238401293755
step: 180, loss: 0.07479670643806458
step: 190, loss: 0.11180558800697327
step: 200, loss: 0.08813914656639099
step: 210, loss: 0.05841129645705223
step: 220, loss: 0.03215194493532181
step: 230, loss: 0.08965882658958435
step: 240, loss: 0.1734449416399002
step: 250, loss: 0.06768947839736938
step: 260, loss: 0.06420823931694031
step: 270, loss: 0.011892790906131268
step: 280, loss: 0.03546646609902382
step: 290, loss: 0.0789492130279541
step: 300, loss: 0.14308123290538788
step: 310, loss: 0.18567001819610596
step: 320, loss: 0.02936369739472866
step: 330, loss: 0.07272323220968246
step: 340, loss: 0.13735510408878326
step: 350, loss: 0.12869805097579956
step: 360, loss: 0.07457011193037033
step: 370, loss: 0.0782671719789505
step: 380, loss: 0.032174162566661835
step: 390, loss: 0.041899025440216064
step: 400, loss: 0.03424615040421486
step: 410, loss: 0.0781748816370964
step: 420, loss: 0.04831939563155174
epoch 4: dev_f1=0.9818594104308391, f1=0.9783845278725825, best_f1=0.9776286353467561
step: 0, loss: 0.012138962745666504
step: 10, loss: 0.0862651988863945
step: 20, loss: 0.08170240372419357
step: 30, loss: 0.07629481703042984
step: 40, loss: 0.027273327112197876
step: 50, loss: 0.0851958692073822
step: 60, loss: 0.017130974680185318
step: 70, loss: 0.039811644703149796
step: 80, loss: 0.14433635771274567
step: 90, loss: 0.08137437701225281
step: 100, loss: 0.02137676253914833
step: 110, loss: 0.12385980784893036
step: 120, loss: 0.04468115046620369
step: 130, loss: 0.07482746988534927
step: 140, loss: 0.11570023000240326
step: 150, loss: 0.06160316988825798
step: 160, loss: 0.12169039994478226
step: 170, loss: 0.036655325442552567
step: 180, loss: 0.06461046636104584
step: 190, loss: 0.03278350085020065
step: 200, loss: 0.006990750320255756
step: 210, loss: 0.0209901612251997
step: 220, loss: 0.01793268322944641
step: 230, loss: 0.04783811792731285
step: 240, loss: 0.11607793718576431
step: 250, loss: 0.012948350980877876
step: 260, loss: 0.013533294200897217
step: 270, loss: 0.06265609711408615
step: 280, loss: 0.07916223257780075
step: 290, loss: 0.06013484299182892
step: 300, loss: 0.13123953342437744
step: 310, loss: 0.056608375161886215
step: 320, loss: 0.17345145344734192
step: 330, loss: 0.0687006413936615
step: 340, loss: 0.0307865459471941
step: 350, loss: 0.03831753134727478
step: 360, loss: 0.14001448452472687
step: 370, loss: 0.09298025071620941
step: 380, loss: 0.01638476923108101
step: 390, loss: 0.3535512089729309
step: 400, loss: 0.10990028828382492
step: 410, loss: 0.00804111547768116
step: 420, loss: 0.04865480586886406
epoch 5: dev_f1=0.9887892376681614, f1=0.9788182831661093, best_f1=0.9788182831661093
step: 0, loss: 0.028793370351195335
step: 10, loss: 0.11429613828659058
step: 20, loss: 0.010186943225562572
step: 30, loss: 0.002241067588329315
step: 40, loss: 0.032411687076091766
step: 50, loss: 0.031244471669197083
step: 60, loss: 0.18382491171360016
step: 70, loss: 0.013941921293735504
step: 80, loss: 0.18716475367546082
step: 90, loss: 0.0817478746175766
step: 100, loss: 0.09592144191265106
step: 110, loss: 0.035509414970874786
step: 120, loss: 0.09349691867828369
step: 130, loss: 0.04712419584393501
step: 140, loss: 0.08553634583950043
step: 150, loss: 0.14709609746932983
step: 160, loss: 0.03370755910873413
step: 170, loss: 0.031771015375852585
step: 180, loss: 0.08404315263032913
step: 190, loss: 0.015825804322957993
step: 200, loss: 0.07922035455703735
step: 210, loss: 0.012859978713095188
step: 220, loss: 0.08816615492105484
step: 230, loss: 0.059385430067777634
step: 240, loss: 0.04369138926267624
step: 250, loss: 0.07492881268262863
step: 260, loss: 0.08197195082902908
step: 270, loss: 0.02158154919743538
step: 280, loss: 0.0007712651276960969
step: 290, loss: 0.022155512124300003
step: 300, loss: 0.027348896488547325
step: 310, loss: 0.07152816653251648
step: 320, loss: 0.0323089137673378
step: 330, loss: 0.11517377942800522
step: 340, loss: 0.0038588177412748337
step: 350, loss: 0.060940779745578766
step: 360, loss: 0.07308884710073471
step: 370, loss: 0.021299879997968674
step: 380, loss: 0.04532809928059578
step: 390, loss: 0.0273466557264328
step: 400, loss: 0.05293465405702591
step: 410, loss: 0.023775804787874222
step: 420, loss: 0.04393972083926201
epoch 6: dev_f1=0.9909502262443439, f1=0.9875706214689265, best_f1=0.9875706214689265
step: 0, loss: 0.028184572234749794
step: 10, loss: 0.22169271111488342
step: 20, loss: 0.02785603143274784
step: 30, loss: 0.03026767075061798
step: 40, loss: 0.0009466197225265205
step: 50, loss: 0.024924810975790024
step: 60, loss: 0.1858857125043869
step: 70, loss: 0.04530642181634903
step: 80, loss: 0.012675601989030838
step: 90, loss: 0.03095998615026474
step: 100, loss: 0.19558709859848022
step: 110, loss: 0.03301350399851799
step: 120, loss: 0.04084986075758934
step: 130, loss: 0.010526197962462902
step: 140, loss: 0.10706129670143127
step: 150, loss: 0.047039877623319626
step: 160, loss: 0.12468179315328598
step: 170, loss: 0.008557705208659172
step: 180, loss: 0.07507488876581192
step: 190, loss: 0.05372955650091171
step: 200, loss: 0.017174649983644485
step: 210, loss: 0.13167570531368256
step: 220, loss: 0.015439349226653576
step: 230, loss: 0.0195491760969162
step: 240, loss: 0.02607671357691288
step: 250, loss: 0.043972164392471313
step: 260, loss: 0.15512624382972717
step: 270, loss: 0.10406234115362167
step: 280, loss: 0.0626329705119133
step: 290, loss: 0.02890678122639656
step: 300, loss: 0.09585132449865341
step: 310, loss: 0.025011124089360237
step: 320, loss: 0.07970224320888519
step: 330, loss: 0.1635085940361023
step: 340, loss: 0.15702368319034576
step: 350, loss: 0.11768355220556259
step: 360, loss: 0.03466489166021347
step: 370, loss: 0.06654302775859833
step: 380, loss: 0.02289336919784546
step: 390, loss: 0.07463066279888153
step: 400, loss: 0.0022067774552851915
step: 410, loss: 0.05706379562616348
step: 420, loss: 0.16225510835647583
epoch 7: dev_f1=0.9898534385569334, f1=0.9831271091113611, best_f1=0.9875706214689265
step: 0, loss: 0.05850943177938461
step: 10, loss: 0.11006563156843185
step: 20, loss: 0.08101466298103333
step: 30, loss: 0.07338960468769073
step: 40, loss: 0.011532079428434372
step: 50, loss: 0.11245790868997574
step: 60, loss: 0.006317306775599718
step: 70, loss: 0.09659513831138611
step: 80, loss: 0.06275995820760727
step: 90, loss: 0.06083707511425018
step: 100, loss: 0.02932741679251194
step: 110, loss: 0.007100843358784914
step: 120, loss: 0.0783252865076065
step: 130, loss: 0.08142169564962387
step: 140, loss: 0.08214658498764038
step: 150, loss: 0.000375717063434422
step: 160, loss: 0.06189718469977379
step: 170, loss: 0.10921380668878555
step: 180, loss: 0.06301899254322052
step: 190, loss: 0.1816253662109375
step: 200, loss: 0.08535565435886383
step: 210, loss: 0.12927617132663727
step: 220, loss: 0.007287787739187479
step: 230, loss: 0.10900812596082687
step: 240, loss: 0.005629143677651882
step: 250, loss: 0.07528799772262573
step: 260, loss: 0.04621116444468498
step: 270, loss: 0.16641481220722198
step: 280, loss: 0.06916369497776031
step: 290, loss: 0.02990947850048542
step: 300, loss: 0.045412786304950714
step: 310, loss: 0.07198867201805115
step: 320, loss: 0.12629660964012146
step: 330, loss: 0.03815516456961632
step: 340, loss: 0.053620122373104095
step: 350, loss: 0.1366851031780243
step: 360, loss: 0.01578456349670887
step: 370, loss: 0.09308608621358871
step: 380, loss: 0.06390886008739471
step: 390, loss: 0.019812697544693947
step: 400, loss: 0.14488564431667328
step: 410, loss: 0.07092150300741196
step: 420, loss: 0.23045744001865387
epoch 8: dev_f1=0.9898762654668166, f1=0.9753914988814317, best_f1=0.9875706214689265
step: 0, loss: 0.028202909976243973
step: 10, loss: 0.020677033811807632
step: 20, loss: 0.07296105474233627
step: 30, loss: 0.013477626256644726
step: 40, loss: 0.06752707809209824
step: 50, loss: 0.030901886522769928
step: 60, loss: 0.01209551002830267
step: 70, loss: 0.09894318133592606
step: 80, loss: 0.061965227127075195
step: 90, loss: 0.075743168592453
step: 100, loss: 0.04556712508201599
step: 110, loss: 0.06391502916812897
step: 120, loss: 0.0028639137744903564
step: 130, loss: 0.03236210718750954
step: 140, loss: 0.013670816086232662
step: 150, loss: 0.04493241012096405
step: 160, loss: 0.06550165265798569
step: 170, loss: 0.020341483876109123
step: 180, loss: 0.08766040951013565
step: 190, loss: 0.0166525449603796
step: 200, loss: 0.016284098848700523
step: 210, loss: 0.07980464398860931
step: 220, loss: 0.006740523036569357
step: 230, loss: 0.14522923529148102
step: 240, loss: 0.046620722860097885
step: 250, loss: 0.02261461317539215
step: 260, loss: 0.07441704720258713
step: 270, loss: 0.0989069864153862
step: 280, loss: 0.08993447571992874
step: 290, loss: 0.03257936239242554
step: 300, loss: 0.092511385679245
step: 310, loss: 0.02007102034986019
step: 320, loss: 0.005243434105068445
step: 330, loss: 0.13255177438259125
step: 340, loss: 0.0686437338590622
step: 350, loss: 0.028878631070256233
step: 360, loss: 0.1107906848192215
step: 370, loss: 0.08922083675861359
step: 380, loss: 0.013783073052763939
step: 390, loss: 0.004077857825905085
step: 400, loss: 0.04484773799777031
step: 410, loss: 0.06511165201663971
step: 420, loss: 0.01884688436985016
epoch 9: dev_f1=0.9887133182844244, f1=0.9763779527559054, best_f1=0.9875706214689265
step: 0, loss: 0.13013170659542084
step: 10, loss: 0.09378276020288467
step: 20, loss: 3.5201257560402155e-05
step: 30, loss: 0.05887278914451599
step: 40, loss: 0.016603544354438782
step: 50, loss: 0.09696558117866516
step: 60, loss: 0.004894191399216652
step: 70, loss: 0.1765592396259308
step: 80, loss: 0.020918650552630424
step: 90, loss: 0.016599247232079506
step: 100, loss: 0.05443030223250389
step: 110, loss: 0.08453016728162766
step: 120, loss: 0.03467530757188797
step: 130, loss: 0.20855960249900818
step: 140, loss: 0.015987100079655647
step: 150, loss: 0.06580308824777603
step: 160, loss: 0.00797338504344225
step: 170, loss: 0.08865996450185776
step: 180, loss: 0.02974873036146164
step: 190, loss: 0.037946540862321854
step: 200, loss: 0.07655902206897736
step: 210, loss: 0.10512693226337433
step: 220, loss: 0.06822769343852997
step: 230, loss: 0.1537085324525833
step: 240, loss: 0.01301408838480711
step: 250, loss: 0.05190339684486389
step: 260, loss: 0.05286526679992676
step: 270, loss: 0.09536795318126678
step: 280, loss: 0.13230590522289276
step: 290, loss: 0.01604079082608223
step: 300, loss: 0.22796157002449036
step: 310, loss: 0.026539098471403122
step: 320, loss: 0.03251827508211136
step: 330, loss: 0.0962967500090599
step: 340, loss: 0.09658118337392807
step: 350, loss: 0.10910292714834213
step: 360, loss: 0.01454838551580906
step: 370, loss: 0.06272751837968826
step: 380, loss: 0.03463243693113327
step: 390, loss: 0.05412491410970688
step: 400, loss: 0.03523603826761246
step: 410, loss: 0.1008179783821106
step: 420, loss: 0.044334083795547485
epoch 10: dev_f1=0.987709497206704, f1=0.9799554565701558, best_f1=0.9875706214689265
step: 0, loss: 0.07284019142389297
step: 10, loss: 0.09360767155885696
step: 20, loss: 0.06295101344585419
step: 30, loss: 0.11263497918844223
step: 40, loss: 0.026699643582105637
step: 50, loss: 0.011564159765839577
step: 60, loss: 0.06128416582942009
step: 70, loss: 0.014113198034465313
step: 80, loss: 0.03146466985344887
step: 90, loss: 0.04085727408528328
step: 100, loss: 0.01847941428422928
step: 110, loss: 0.002390956971794367
step: 120, loss: 0.009357848204672337
step: 130, loss: 0.1183915063738823
step: 140, loss: 0.0280781090259552
step: 150, loss: 0.1514459103345871
step: 160, loss: 0.014458965510129929
step: 170, loss: 0.016908369958400726
step: 180, loss: 0.008222131058573723
step: 190, loss: 0.07380077242851257
step: 200, loss: 0.017598729580640793
step: 210, loss: 0.06782965362071991
step: 220, loss: 0.06901335716247559
step: 230, loss: 0.05177951604127884
step: 240, loss: 0.12002244591712952
step: 250, loss: 0.01443648524582386
step: 260, loss: 0.08968397974967957
step: 270, loss: 0.021430499851703644
step: 280, loss: 0.0479944609105587
step: 290, loss: 0.10296925157308578
step: 300, loss: 0.028460223227739334
step: 310, loss: 0.14285878837108612
step: 320, loss: 0.030656246468424797
step: 330, loss: 0.00831439159810543
step: 340, loss: 0.07040001451969147
step: 350, loss: 0.12349506467580795
step: 360, loss: 0.04783331975340843
step: 370, loss: 0.03918484225869179
step: 380, loss: 0.02067657932639122
step: 390, loss: 0.07684381306171417
step: 400, loss: 0.008753481321036816
step: 410, loss: 0.060026440769433975
step: 420, loss: 0.0071581401862204075
epoch 11: dev_f1=0.9921436588103255, f1=0.980963045912654, best_f1=0.980963045912654
step: 0, loss: 0.1047322228550911
step: 10, loss: 0.019451485946774483
step: 20, loss: 0.018509574234485626
step: 30, loss: 0.050262950360774994
step: 40, loss: 0.022120509296655655
step: 50, loss: 0.1032305657863617
step: 60, loss: 0.0905216783285141
step: 70, loss: 0.05090419575572014
step: 80, loss: 0.04944881796836853
step: 90, loss: 0.08004984259605408
step: 100, loss: 0.05535586550831795
step: 110, loss: 0.0651085376739502
step: 120, loss: 0.002245616866275668
step: 130, loss: 0.0008658619481138885
step: 140, loss: 0.059707287698984146
step: 150, loss: 0.02494625188410282
step: 160, loss: 0.11759121716022491
step: 170, loss: 0.032549723982810974
step: 180, loss: 0.023909231647849083
step: 190, loss: 0.05514275282621384
step: 200, loss: 0.007482792716473341
step: 210, loss: 0.0887097641825676
step: 220, loss: 0.013307127170264721
step: 230, loss: 0.13129116594791412
step: 240, loss: 0.10405655950307846
step: 250, loss: 0.014391161501407623
step: 260, loss: 0.02424241229891777
step: 270, loss: 0.03391149640083313
step: 280, loss: 0.005343361292034388
step: 290, loss: 0.014213298447430134
step: 300, loss: 0.12613363564014435
step: 310, loss: 0.06839139014482498
step: 320, loss: 0.03260616958141327
step: 330, loss: 0.014436797238886356
step: 340, loss: 0.09435052424669266
step: 350, loss: 0.31904634833335876
step: 360, loss: 0.07674195617437363
step: 370, loss: 0.11005711555480957
step: 380, loss: 0.0716114267706871
step: 390, loss: 0.03263932466506958
step: 400, loss: 0.011367161758244038
step: 410, loss: 0.02591259405016899
step: 420, loss: 0.01528189331293106
epoch 12: dev_f1=0.9876543209876544, f1=0.9776286353467561, best_f1=0.980963045912654
step: 0, loss: 0.02255261316895485
step: 10, loss: 0.04368869215250015
step: 20, loss: 0.0619950033724308
step: 30, loss: 0.044776223599910736
step: 40, loss: 0.008573341183364391
step: 50, loss: 0.03463321179151535
step: 60, loss: 0.07885657995939255
step: 70, loss: 0.07420862466096878
step: 80, loss: 0.05516837537288666
step: 90, loss: 0.006212111096829176
step: 100, loss: 0.006705368869006634
step: 110, loss: 0.059289053082466125
step: 120, loss: 0.061182714998722076
step: 130, loss: 0.011897845193743706
step: 140, loss: 0.00859140045940876
step: 150, loss: 0.026542769744992256
step: 160, loss: 0.016809940338134766
step: 170, loss: 0.02095942758023739
step: 180, loss: 0.03363029286265373
step: 190, loss: 0.022359969094395638
step: 200, loss: 0.05150613561272621
step: 210, loss: 0.06318766623735428
step: 220, loss: 0.021549254655838013
step: 230, loss: 0.12078328430652618
step: 240, loss: 0.03537428379058838
step: 250, loss: 0.028902944177389145
step: 260, loss: 0.017100118100643158
step: 270, loss: 0.03953384980559349
step: 280, loss: 0.05320470780134201
step: 290, loss: 0.10021799802780151
step: 300, loss: 0.028146885335445404
step: 310, loss: 0.072550930082798
step: 320, loss: 0.055996909737586975
step: 330, loss: 0.004418299533426762
step: 340, loss: 0.02130264975130558
step: 350, loss: 0.13439449667930603
step: 360, loss: 0.005637299735099077
step: 370, loss: 0.09557837247848511
step: 380, loss: 0.005017976276576519
step: 390, loss: 0.026967115700244904
step: 400, loss: 0.031491395086050034
step: 410, loss: 0.047169361263513565
step: 420, loss: 0.013128486461937428
epoch 13: dev_f1=0.9887892376681614, f1=0.9799107142857142, best_f1=0.980963045912654
step: 0, loss: 0.0029215412214398384
step: 10, loss: 0.045952051877975464
step: 20, loss: 0.06786647439002991
step: 30, loss: 0.05420275405049324
step: 40, loss: 3.2308562367688864e-05
step: 50, loss: 0.07454632222652435
step: 60, loss: 0.055432021617889404
step: 70, loss: 0.021270940080285072
step: 80, loss: 0.0027574636042118073
step: 90, loss: 0.021424759179353714
step: 100, loss: 0.13309365510940552
step: 110, loss: 0.008415854535996914
step: 120, loss: 0.1529487520456314
step: 130, loss: 0.016227222979068756
step: 140, loss: 0.05321449041366577
step: 150, loss: 0.14695286750793457
step: 160, loss: 0.03084973618388176
step: 170, loss: 0.03449295833706856
step: 180, loss: 0.0010300074936822057
step: 190, loss: 0.0898120254278183
step: 200, loss: 0.0019051394192501903
step: 210, loss: 0.03619575873017311
step: 220, loss: 0.005790744908154011
step: 230, loss: 0.023988835513591766
step: 240, loss: 0.003092528088018298
step: 250, loss: 0.094121053814888
step: 260, loss: 0.09420166909694672
step: 270, loss: 0.08830027282238007
step: 280, loss: 0.03560921922326088
step: 290, loss: 0.042946793138980865
step: 300, loss: 0.049469463527202606
step: 310, loss: 0.10731720179319382
step: 320, loss: 0.07430209964513779
step: 330, loss: 0.12289001047611237
step: 340, loss: 0.049971386790275574
step: 350, loss: 0.0830686166882515
step: 360, loss: 0.016467304900288582
step: 370, loss: 0.03524009883403778
step: 380, loss: 0.00013652662164531648
step: 390, loss: 0.0011085104197263718
step: 400, loss: 0.1054806262254715
step: 410, loss: 0.14979973435401917
step: 420, loss: 0.04157295823097229
epoch 14: dev_f1=0.9876819708846584, f1=0.9799554565701558, best_f1=0.980963045912654
step: 0, loss: 0.06849072128534317
step: 10, loss: 0.001808558008633554
step: 20, loss: 0.055452313274145126
step: 30, loss: 0.008552273735404015
step: 40, loss: 0.02362898364663124
step: 50, loss: 0.014108162373304367
step: 60, loss: 0.02117311581969261
step: 70, loss: 0.007574794348329306
step: 80, loss: 0.06005312502384186
step: 90, loss: 0.07450443506240845
step: 100, loss: 0.03307923674583435
step: 110, loss: 0.11492045223712921
step: 120, loss: 0.03489735722541809
step: 130, loss: 0.019816195592284203
step: 140, loss: 0.026465799659490585
step: 150, loss: 0.037304531782865524
step: 160, loss: 0.02417619340121746
step: 170, loss: 0.05861099809408188
step: 180, loss: 0.11320929229259491
step: 190, loss: 0.001395814586430788
step: 200, loss: 0.10250145196914673
step: 210, loss: 0.0641665905714035
step: 220, loss: 0.004513083957135677
step: 230, loss: 0.04533304274082184
step: 240, loss: 0.1094406470656395
step: 250, loss: 0.001317658694460988
step: 260, loss: 0.04318990558385849
step: 270, loss: 0.009934005327522755
step: 280, loss: 0.025657087564468384
step: 290, loss: 0.11573377996683121
step: 300, loss: 0.06511363387107849
step: 310, loss: 0.05765625461935997
step: 320, loss: 0.10344093292951584
step: 330, loss: 0.004819310270249844
step: 340, loss: 0.002424626611173153
step: 350, loss: 0.057536959648132324
step: 360, loss: 0.07729658484458923
step: 370, loss: 0.029313720762729645
step: 380, loss: 0.05731123313307762
step: 390, loss: 0.023848719894886017
step: 400, loss: 0.047223009169101715
step: 410, loss: 0.057245876640081406
step: 420, loss: 0.06362925469875336
epoch 15: dev_f1=0.9898989898989898, f1=0.9787709497206705, best_f1=0.980963045912654
step: 0, loss: 0.051290784031152725
step: 10, loss: 0.09341753274202347
step: 20, loss: 0.04852139577269554
step: 30, loss: 0.03767654299736023
step: 40, loss: 0.02185119315981865
step: 50, loss: 0.03227970749139786
step: 60, loss: 0.052053991705179214
step: 70, loss: 0.05306423455476761
step: 80, loss: 0.0005757614853791893
step: 90, loss: 0.06033310666680336
step: 100, loss: 0.021733922883868217
step: 110, loss: 0.011249433271586895
step: 120, loss: 0.0014629580546170473
step: 130, loss: 0.04926241934299469
step: 140, loss: 0.00769927678629756
step: 150, loss: 0.05534008890390396
step: 160, loss: 0.03582229092717171
step: 170, loss: 0.034766074270009995
step: 180, loss: 0.00028505345107987523
step: 190, loss: 0.0006298677762970328
step: 200, loss: 0.027935490012168884
step: 210, loss: 0.03784608468413353
step: 220, loss: 0.08146608620882034
step: 230, loss: 0.027381617575883865
step: 240, loss: 0.024037104099988937
step: 250, loss: 0.013515057042241096
step: 260, loss: 0.07860653102397919
step: 270, loss: 0.03865254297852516
step: 280, loss: 0.05321650207042694
step: 290, loss: 0.022189762443304062
step: 300, loss: 0.0007653162465430796
step: 310, loss: 0.03164881095290184
step: 320, loss: 0.0006494981935247779
step: 330, loss: 0.06665243208408356
step: 340, loss: 0.038286883383989334
step: 350, loss: 0.03463228419423103
step: 360, loss: 0.0068539343774318695
step: 370, loss: 0.006429477594792843
step: 380, loss: 0.0018442135769873857
step: 390, loss: 0.1155875027179718
step: 400, loss: 0.00014506746083498
step: 410, loss: 0.04315945878624916
step: 420, loss: 0.016550764441490173
epoch 16: dev_f1=0.9910112359550561, f1=0.9798206278026906, best_f1=0.980963045912654
step: 0, loss: 0.016385549679398537
step: 10, loss: 0.04317078739404678
step: 20, loss: 0.04694583639502525
step: 30, loss: 0.043725136667490005
step: 40, loss: 0.015897687524557114
step: 50, loss: 0.06453312188386917
step: 60, loss: 0.03260761499404907
step: 70, loss: 0.006189835723489523
step: 80, loss: 0.054199595004320145
step: 90, loss: 0.056314125657081604
step: 100, loss: 0.04829564690589905
step: 110, loss: 0.023070205003023148
step: 120, loss: 0.07630597054958344
step: 130, loss: 0.11685453355312347
step: 140, loss: 0.07032165676355362
step: 150, loss: 0.029881564900279045
step: 160, loss: 0.0005402768729254603
step: 170, loss: 0.031402360647916794
step: 180, loss: 0.00017015988123603165
step: 190, loss: 0.00202246499247849
step: 200, loss: 0.002137301489710808
step: 210, loss: 0.03684459999203682
step: 220, loss: 0.09210435301065445
step: 230, loss: 0.08138523995876312
step: 240, loss: 0.035728953778743744
step: 250, loss: 7.152885518735275e-05
step: 260, loss: 0.04071049392223358
step: 270, loss: 0.07997505366802216
step: 280, loss: 0.04693230241537094
step: 290, loss: 0.044563960283994675
step: 300, loss: 0.043347474187612534
step: 310, loss: 0.00016417301958426833
step: 320, loss: 0.031206784769892693
step: 330, loss: 0.04600540176033974
step: 340, loss: 0.0005194907425902784
step: 350, loss: 0.0028465932700783014
step: 360, loss: 0.0004667130415327847
step: 370, loss: 0.06650496274232864
step: 380, loss: 0.04553154855966568
step: 390, loss: 0.00021320917585399002
step: 400, loss: 0.021314425393939018
step: 410, loss: 0.024254441261291504
step: 420, loss: 0.024407953023910522
epoch 17: dev_f1=0.9910112359550561, f1=0.9798206278026906, best_f1=0.980963045912654
step: 0, loss: 0.059326209127902985
step: 10, loss: 0.000164551442139782
step: 20, loss: 0.01919637992978096
step: 30, loss: 0.02062765695154667
step: 40, loss: 0.015168549492955208
step: 50, loss: 0.02848387323319912
step: 60, loss: 0.04649287834763527
step: 70, loss: 0.04531145095825195
step: 80, loss: 0.02535824105143547
step: 90, loss: 0.023173995316028595
step: 100, loss: 0.03570934012532234
step: 110, loss: 0.0029831789433956146
step: 120, loss: 0.0009098678128793836
step: 130, loss: 0.032550420612096786
step: 140, loss: 0.02133842743933201
step: 150, loss: 0.038864485919475555
step: 160, loss: 0.017216404899954796
step: 170, loss: 0.015352481976151466
step: 180, loss: 0.04362243413925171
step: 190, loss: 0.06551820039749146
step: 200, loss: 0.06019459664821625
step: 210, loss: 0.03656280040740967
step: 220, loss: 0.039860960096120834
step: 230, loss: 0.032492801547050476
step: 240, loss: 0.06556567549705505
step: 250, loss: 0.014726311899721622
step: 260, loss: 0.07816507667303085
step: 270, loss: 1.2490791050367989e-05
step: 280, loss: 0.06507647037506104
step: 290, loss: 0.037539515644311905
step: 300, loss: 0.08319754153490067
step: 310, loss: 0.022860098630189896
step: 320, loss: 0.033696744590997696
step: 330, loss: 0.05631918087601662
step: 340, loss: 0.006607236806303263
step: 350, loss: 0.027904704213142395
step: 360, loss: 0.010293195955455303
step: 370, loss: 0.01888117752969265
step: 380, loss: 0.04584691673517227
step: 390, loss: 0.014096644707024097
step: 400, loss: 0.0182034894824028
step: 410, loss: 0.004139340482652187
step: 420, loss: 0.01907295174896717
epoch 18: dev_f1=0.990990990990991, f1=0.9798206278026906, best_f1=0.980963045912654
step: 0, loss: 0.0059362114407122135
step: 10, loss: 0.07594487071037292
step: 20, loss: 0.020899401977658272
step: 30, loss: 0.049511875957250595
step: 40, loss: 0.08366604149341583
step: 50, loss: 0.00031165944528765976
step: 60, loss: 0.0005606857012026012
step: 70, loss: 0.03961432725191116
step: 80, loss: 0.016119997948408127
step: 90, loss: 0.03842077776789665
step: 100, loss: 0.017527498304843903
step: 110, loss: 0.024467336013913155
step: 120, loss: 0.061346568167209625
step: 130, loss: 0.045335542410612106
step: 140, loss: 0.053198348730802536
step: 150, loss: 0.02118932083249092
step: 160, loss: 0.004187104292213917
step: 170, loss: 0.02301158383488655
step: 180, loss: 0.044164273887872696
step: 190, loss: 0.03961249440908432
step: 200, loss: 0.0251074880361557
step: 210, loss: 0.037547267973423004
step: 220, loss: 0.06612729281187057
step: 230, loss: 0.010983701795339584
step: 240, loss: 0.026337888091802597
step: 250, loss: 0.056325022131204605
step: 260, loss: 0.055323559790849686
step: 270, loss: 0.003105512587353587
step: 280, loss: 0.0873061791062355
step: 290, loss: 0.030802015215158463
step: 300, loss: 0.00012740070815198123
step: 310, loss: 0.019140643998980522
step: 320, loss: 0.041692450642585754
step: 330, loss: 0.00025219033705070615
step: 340, loss: 0.04737115651369095
step: 350, loss: 0.003961797337979078
step: 360, loss: 0.08259372413158417
step: 370, loss: 0.03279077261686325
step: 380, loss: 0.021288901567459106
step: 390, loss: 0.01183561235666275
step: 400, loss: 0.02373792789876461
step: 410, loss: 0.019413050264120102
step: 420, loss: 0.01821332797408104
epoch 19: dev_f1=0.9898762654668166, f1=0.9798206278026906, best_f1=0.980963045912654
step: 0, loss: 0.0312843881547451
step: 10, loss: 0.021850094199180603
step: 20, loss: 0.021097494289278984
step: 30, loss: 0.03532710298895836
step: 40, loss: 1.7769179976312444e-05
step: 50, loss: 0.07631827890872955
step: 60, loss: 0.04769573360681534
step: 70, loss: 0.030915018171072006
step: 80, loss: 0.025647759437561035
step: 90, loss: 0.04134591296315193
step: 100, loss: 0.04224150627851486
step: 110, loss: 0.00033435586374253035
step: 120, loss: 0.02145567163825035
step: 130, loss: 0.020185748115181923
step: 140, loss: 0.003833992639556527
step: 150, loss: 0.04290606081485748
step: 160, loss: 0.0002039150131167844
step: 170, loss: 0.021427270025014877
step: 180, loss: 0.07119978964328766
step: 190, loss: 0.09487947076559067
step: 200, loss: 0.0002517207758501172
step: 210, loss: 0.02376570925116539
step: 220, loss: 0.05083569139242172
step: 230, loss: 0.0462491475045681
step: 240, loss: 0.019741898402571678
step: 250, loss: 0.0002994492824655026
step: 260, loss: 0.0107100335881114
step: 270, loss: 0.06944132596254349
step: 280, loss: 0.018947619944810867
step: 290, loss: 0.018464919179677963
step: 300, loss: 0.07383928447961807
step: 310, loss: 0.03324558585882187
step: 320, loss: 0.04015929251909256
step: 330, loss: 0.000534420891199261
step: 340, loss: 0.023652981966733932
step: 350, loss: 0.030870547518134117
step: 360, loss: 0.047352977097034454
step: 370, loss: 0.02726716175675392
step: 380, loss: 0.021683409810066223
step: 390, loss: 0.04648023098707199
step: 400, loss: 0.016445346176624298
step: 410, loss: 0.02542111836373806
step: 420, loss: 0.040307968854904175
epoch 20: dev_f1=0.9898762654668166, f1=0.9798206278026906, best_f1=0.980963045912654
