cuda
Device: cuda
step: 0, loss: 0.8432631492614746
step: 10, loss: 0.1531892567873001
step: 20, loss: 0.2533068358898163
step: 30, loss: 0.41036415100097656
step: 40, loss: 0.23708964884281158
step: 50, loss: 0.27037960290908813
step: 60, loss: 0.12690091133117676
step: 70, loss: 0.1505611538887024
step: 80, loss: 0.18723848462104797
step: 90, loss: 0.14154165983200073
step: 100, loss: 0.12539370357990265
step: 110, loss: 0.11372771859169006
step: 120, loss: 0.15101151168346405
step: 130, loss: 0.09673741459846497
step: 140, loss: 0.07698572427034378
step: 150, loss: 0.020842090249061584
step: 160, loss: 0.1620447188615799
step: 170, loss: 0.13920047879219055
step: 180, loss: 0.09383822232484818
step: 190, loss: 0.051669828593730927
step: 200, loss: 0.06706429272890091
step: 210, loss: 0.07874500751495361
step: 220, loss: 0.06889093667268753
step: 230, loss: 0.14069682359695435
step: 240, loss: 0.18549686670303345
step: 250, loss: 0.19176407158374786
step: 260, loss: 0.23228704929351807
step: 270, loss: 0.1625162810087204
step: 280, loss: 0.12515071034431458
step: 290, loss: 0.03736298531293869
step: 300, loss: 0.026400234550237656
step: 310, loss: 0.029989589005708694
step: 320, loss: 0.17072641849517822
step: 330, loss: 0.0311098825186491
step: 340, loss: 0.02001059055328369
step: 350, loss: 0.07298462837934494
step: 360, loss: 0.06110979989171028
step: 370, loss: 0.14755859971046448
step: 380, loss: 0.16121111810207367
step: 390, loss: 0.06801903992891312
step: 400, loss: 0.058186016976833344
step: 410, loss: 0.09920832514762878
step: 420, loss: 0.03494302183389664
epoch 1: dev_f1=0.9409237379162192, f1=0.9370932754880695, best_f1=0.9370932754880695
step: 0, loss: 0.26748496294021606
step: 10, loss: 0.15758457779884338
step: 20, loss: 0.11242679506540298
step: 30, loss: 0.12812118232250214
step: 40, loss: 0.12874740362167358
step: 50, loss: 0.133836030960083
step: 60, loss: 0.13339953124523163
step: 70, loss: 0.08788827061653137
step: 80, loss: 0.07366617023944855
step: 90, loss: 0.08161532878875732
step: 100, loss: 0.03677654638886452
step: 110, loss: 0.0719699114561081
step: 120, loss: 0.030915517359972
step: 130, loss: 0.10907987505197525
step: 140, loss: 0.11941871792078018
step: 150, loss: 0.1332322061061859
step: 160, loss: 0.12975537776947021
step: 170, loss: 0.12811429798603058
step: 180, loss: 0.055456552654504776
step: 190, loss: 0.05175500363111496
step: 200, loss: 0.09248156100511551
step: 210, loss: 0.09208405017852783
step: 220, loss: 0.07343298196792603
step: 230, loss: 0.11753768473863602
step: 240, loss: 0.019711405038833618
step: 250, loss: 0.02710636518895626
step: 260, loss: 0.10864792764186859
step: 270, loss: 0.09676419198513031
step: 280, loss: 0.1496686041355133
step: 290, loss: 0.05054214969277382
step: 300, loss: 0.15698756277561188
step: 310, loss: 0.07471701502799988
step: 320, loss: 0.08466869592666626
step: 330, loss: 0.07022262364625931
step: 340, loss: 0.08725784718990326
step: 350, loss: 0.052502118051052094
step: 360, loss: 0.3422085642814636
step: 370, loss: 0.17044730484485626
step: 380, loss: 0.26752176880836487
step: 390, loss: 0.08919158577919006
step: 400, loss: 0.05666166543960571
step: 410, loss: 0.0673096776008606
step: 420, loss: 0.03096502274274826
epoch 2: dev_f1=0.9841628959276018, f1=0.9772209567198178, best_f1=0.9772209567198178
step: 0, loss: 0.19988614320755005
step: 10, loss: 0.2795262038707733
step: 20, loss: 0.14807219803333282
step: 30, loss: 0.06437424570322037
step: 40, loss: 0.2068462073802948
step: 50, loss: 0.09973875433206558
step: 60, loss: 0.11393635720014572
step: 70, loss: 0.06404434889554977
step: 80, loss: 0.07672906666994095
step: 90, loss: 0.10747510194778442
step: 100, loss: 0.05639886483550072
step: 110, loss: 0.1181795671582222
step: 120, loss: 0.12493713200092316
step: 130, loss: 0.05597786605358124
step: 140, loss: 0.05243733525276184
step: 150, loss: 0.06531931459903717
step: 160, loss: 0.05768705531954765
step: 170, loss: 0.07626304030418396
step: 180, loss: 0.1349366009235382
step: 190, loss: 0.20109304785728455
step: 200, loss: 0.05532043054699898
step: 210, loss: 0.09826402366161346
step: 220, loss: 0.11813806742429733
step: 230, loss: 0.014942770823836327
step: 240, loss: 0.11259520798921585
step: 250, loss: 0.14412304759025574
step: 260, loss: 0.08496890217065811
step: 270, loss: 0.05654151365160942
step: 280, loss: 0.18649417161941528
step: 290, loss: 0.05551893636584282
step: 300, loss: 0.09469155967235565
step: 310, loss: 0.104134701192379
step: 320, loss: 0.07625272870063782
step: 330, loss: 0.11930160969495773
step: 340, loss: 0.08068868517875671
step: 350, loss: 0.1982756406068802
step: 360, loss: 0.10266272723674774
step: 370, loss: 0.031403642147779465
step: 380, loss: 0.12215542793273926
step: 390, loss: 0.06009131297469139
step: 400, loss: 0.06586077064275742
step: 410, loss: 0.07279311120510101
step: 420, loss: 0.17117229104042053
epoch 3: dev_f1=0.9831271091113611, f1=0.9785794813979707, best_f1=0.9772209567198178
step: 0, loss: 0.02759612537920475
step: 10, loss: 0.13922813534736633
step: 20, loss: 0.1384427696466446
step: 30, loss: 0.0576864592730999
step: 40, loss: 0.03218299150466919
step: 50, loss: 0.08735048025846481
step: 60, loss: 0.016487378627061844
step: 70, loss: 0.06145760044455528
step: 80, loss: 0.01383289135992527
step: 90, loss: 0.2005143016576767
step: 100, loss: 0.11784829199314117
step: 110, loss: 0.15008874237537384
step: 120, loss: 0.06511759757995605
step: 130, loss: 0.09911001473665237
step: 140, loss: 0.018487751483917236
step: 150, loss: 0.13264405727386475
step: 160, loss: 0.13576167821884155
step: 170, loss: 0.05294852331280708
step: 180, loss: 0.07722418010234833
step: 190, loss: 0.037015192210674286
step: 200, loss: 0.02071184478700161
step: 210, loss: 0.03269702568650246
step: 220, loss: 0.03297411650419235
step: 230, loss: 0.23104679584503174
step: 240, loss: 0.04040883108973503
step: 250, loss: 0.022403251379728317
step: 260, loss: 0.07172416895627975
step: 270, loss: 0.05613121762871742
step: 280, loss: 0.2749200165271759
step: 290, loss: 0.016362907364964485
step: 300, loss: 0.07354021817445755
step: 310, loss: 0.22546204924583435
step: 320, loss: 0.10252167284488678
step: 330, loss: 0.10152765363454819
step: 340, loss: 0.053535096347332
step: 350, loss: 0.10752565413713455
step: 360, loss: 0.1011706218123436
step: 370, loss: 0.08027592301368713
step: 380, loss: 0.019295696169137955
step: 390, loss: 0.13891436159610748
step: 400, loss: 0.0813346728682518
step: 410, loss: 0.045605771243572235
step: 420, loss: 0.057039760053157806
epoch 4: dev_f1=0.9842342342342343, f1=0.9730337078651685, best_f1=0.9730337078651685
step: 0, loss: 0.05839188024401665
step: 10, loss: 0.05748995766043663
step: 20, loss: 0.16430991888046265
step: 30, loss: 0.00026133088977076113
step: 40, loss: 0.0766274705529213
step: 50, loss: 0.030989620834589005
step: 60, loss: 0.12029677629470825
step: 70, loss: 0.059896521270275116
step: 80, loss: 0.07607249915599823
step: 90, loss: 0.025828521698713303
step: 100, loss: 0.07640796899795532
step: 110, loss: 0.02888248860836029
step: 120, loss: 0.07088033109903336
step: 130, loss: 0.10133084654808044
step: 140, loss: 0.04905112460255623
step: 150, loss: 0.12231429666280746
step: 160, loss: 0.09739457070827484
step: 170, loss: 0.04474290460348129
step: 180, loss: 0.10141614824533463
step: 190, loss: 0.04640350118279457
step: 200, loss: 0.11819137632846832
step: 210, loss: 0.023096205666661263
step: 220, loss: 0.014858538284897804
step: 230, loss: 0.07288866490125656
step: 240, loss: 0.08435992151498795
step: 250, loss: 0.07371688634157181
step: 260, loss: 0.08611547946929932
step: 270, loss: 0.11465415358543396
step: 280, loss: 0.09117624163627625
step: 290, loss: 0.0699695497751236
step: 300, loss: 0.0444815419614315
step: 310, loss: 0.011193704791367054
step: 320, loss: 0.07277878373861313
step: 330, loss: 0.05932728946208954
step: 340, loss: 0.1283479928970337
step: 350, loss: 0.047707293182611465
step: 360, loss: 0.05853375792503357
step: 370, loss: 0.1294514387845993
step: 380, loss: 0.12802885472774506
step: 390, loss: 0.05689654126763344
step: 400, loss: 0.036471154540777206
step: 410, loss: 0.06923027336597443
step: 420, loss: 0.19256296753883362
epoch 5: dev_f1=0.9898305084745763, f1=0.9852774631936579, best_f1=0.9852774631936579
step: 0, loss: 0.0330752469599247
step: 10, loss: 0.06410826742649078
step: 20, loss: 0.01740945130586624
step: 30, loss: 0.09668391942977905
step: 40, loss: 0.02152855694293976
step: 50, loss: 0.016226833686232567
step: 60, loss: 0.0058877114206552505
step: 70, loss: 0.015428023412823677
step: 80, loss: 0.1063363179564476
step: 90, loss: 0.08210539817810059
step: 100, loss: 0.02503952570259571
step: 110, loss: 0.032355546951293945
step: 120, loss: 0.11136648058891296
step: 130, loss: 0.05686052143573761
step: 140, loss: 0.09012386947870255
step: 150, loss: 0.12884914875030518
step: 160, loss: 0.15632158517837524
step: 170, loss: 0.09752443432807922
step: 180, loss: 0.24714542925357819
step: 190, loss: 0.11499419063329697
step: 200, loss: 0.12793701887130737
step: 210, loss: 0.06633938103914261
step: 220, loss: 0.26350393891334534
step: 230, loss: 0.07686494290828705
step: 240, loss: 0.07462155073881149
step: 250, loss: 0.12613913416862488
step: 260, loss: 0.035624340176582336
step: 270, loss: 0.0954691469669342
step: 280, loss: 0.03839024528861046
step: 290, loss: 0.08989705890417099
step: 300, loss: 0.11310350894927979
step: 310, loss: 0.09051463007926941
step: 320, loss: 0.1631794422864914
step: 330, loss: 0.0632350742816925
step: 340, loss: 0.12652620673179626
step: 350, loss: 0.08351355046033859
step: 360, loss: 0.03823548182845116
step: 370, loss: 0.03995132073760033
step: 380, loss: 0.02020760253071785
step: 390, loss: 0.06014493852853775
step: 400, loss: 0.05014260485768318
step: 410, loss: 0.004384147003293037
step: 420, loss: 0.098975270986557
epoch 6: dev_f1=0.9898305084745763, f1=0.9820224719101124, best_f1=0.9852774631936579
step: 0, loss: 0.013606611639261246
step: 10, loss: 0.10077150911092758
step: 20, loss: 0.008009854704141617
step: 30, loss: 0.03272831812500954
step: 40, loss: 0.097842276096344
step: 50, loss: 0.07862872630357742
step: 60, loss: 0.08267182856798172
step: 70, loss: 0.08828543871641159
step: 80, loss: 0.006621283479034901
step: 90, loss: 0.03361594304442406
step: 100, loss: 0.13548307120800018
step: 110, loss: 0.05548630282282829
step: 120, loss: 0.05938025563955307
step: 130, loss: 0.016203993931412697
step: 140, loss: 0.08810513466596603
step: 150, loss: 0.09280478209257126
step: 160, loss: 0.02775578759610653
step: 170, loss: 0.17731475830078125
step: 180, loss: 0.14163000881671906
step: 190, loss: 0.03447859734296799
step: 200, loss: 0.04813500493764877
step: 210, loss: 0.030014093965291977
step: 220, loss: 0.0892312303185463
step: 230, loss: 0.08362403512001038
step: 240, loss: 0.015721002593636513
step: 250, loss: 0.02918315678834915
step: 260, loss: 0.10302940756082535
step: 270, loss: 0.0668044313788414
step: 280, loss: 0.08982778340578079
step: 290, loss: 0.05343468859791756
step: 300, loss: 0.0794227197766304
step: 310, loss: 0.09598853439092636
step: 320, loss: 0.16418811678886414
step: 330, loss: 0.007015249226242304
step: 340, loss: 0.002520808717235923
step: 350, loss: 0.16455240547657013
step: 360, loss: 0.05602199584245682
step: 370, loss: 0.014473088085651398
step: 380, loss: 0.09008127450942993
step: 390, loss: 0.047291066497564316
step: 400, loss: 0.13104812800884247
step: 410, loss: 0.04367257282137871
step: 420, loss: 0.08316029608249664
epoch 7: dev_f1=0.9887640449438202, f1=0.9799107142857142, best_f1=0.9852774631936579
step: 0, loss: 0.02800336666405201
step: 10, loss: 0.15578758716583252
step: 20, loss: 0.006449908949434757
step: 30, loss: 0.028914637863636017
step: 40, loss: 0.11057697981595993
step: 50, loss: 0.1273752897977829
step: 60, loss: 0.03050375171005726
step: 70, loss: 0.10006149113178253
step: 80, loss: 0.02976682037115097
step: 90, loss: 0.10948747396469116
step: 100, loss: 0.021200979128479958
step: 110, loss: 0.012063797563314438
step: 120, loss: 0.0839192196726799
step: 130, loss: 0.11066636443138123
step: 140, loss: 0.022720549255609512
step: 150, loss: 0.009929419495165348
step: 160, loss: 0.046517565846443176
step: 170, loss: 0.07503840327262878
step: 180, loss: 0.07914862781763077
step: 190, loss: 0.0059676277451217175
step: 200, loss: 0.06898197531700134
step: 210, loss: 0.09982539713382721
step: 220, loss: 0.006689183413982391
step: 230, loss: 0.07520441710948944
step: 240, loss: 0.033003322780132294
step: 250, loss: 0.14748388528823853
step: 260, loss: 0.11996613442897797
step: 270, loss: 0.11715047061443329
step: 280, loss: 0.0015083705075085163
step: 290, loss: 0.06359927356243134
step: 300, loss: 0.04103023558855057
step: 310, loss: 0.024422572925686836
step: 320, loss: 0.12802940607070923
step: 330, loss: 0.06627029925584793
step: 340, loss: 0.06482353806495667
step: 350, loss: 0.07193494588136673
step: 360, loss: 0.06888897716999054
step: 370, loss: 0.007751842029392719
step: 380, loss: 0.020602792501449585
step: 390, loss: 0.013272722251713276
step: 400, loss: 0.04339542239904404
step: 410, loss: 0.11805746704339981
step: 420, loss: 0.015151644125580788
epoch 8: dev_f1=0.9898762654668166, f1=0.9820627802690582, best_f1=0.9820627802690582
step: 0, loss: 0.004830264952033758
step: 10, loss: 0.00792871043086052
step: 20, loss: 0.038177862763404846
step: 30, loss: 0.01606830582022667
step: 40, loss: 0.11460466682910919
step: 50, loss: 0.07466523349285126
step: 60, loss: 0.05414711311459541
step: 70, loss: 0.06785121560096741
step: 80, loss: 0.18048296868801117
step: 90, loss: 0.03461422771215439
step: 100, loss: 0.11039021611213684
step: 110, loss: 0.017691798508167267
step: 120, loss: 0.08090858906507492
step: 130, loss: 0.04937738552689552
step: 140, loss: 0.13097314536571503
step: 150, loss: 0.060156721621751785
step: 160, loss: 0.05354038625955582
step: 170, loss: 0.06511291861534119
step: 180, loss: 0.06962479650974274
step: 190, loss: 0.17365358769893646
step: 200, loss: 0.02457057498395443
step: 210, loss: 0.06902329623699188
step: 220, loss: 0.028334077447652817
step: 230, loss: 0.13432729244232178
step: 240, loss: 0.04773511365056038
step: 250, loss: 0.13611002266407013
step: 260, loss: 0.13071388006210327
step: 270, loss: 0.07311524450778961
step: 280, loss: 0.019708437845110893
step: 290, loss: 0.08453594893217087
step: 300, loss: 0.07925760746002197
step: 310, loss: 0.13976719975471497
step: 320, loss: 0.1641301065683365
step: 330, loss: 0.015572527423501015
step: 340, loss: 0.044704511761665344
step: 350, loss: 0.06885671615600586
step: 360, loss: 0.06652285158634186
step: 370, loss: 0.100806325674057
step: 380, loss: 0.10640379786491394
step: 390, loss: 0.055967263877391815
step: 400, loss: 0.013173281215131283
step: 410, loss: 0.07486448436975479
step: 420, loss: 0.009294860064983368
epoch 9: dev_f1=0.9887640449438202, f1=0.9843400447427293, best_f1=0.9820627802690582
step: 0, loss: 0.08182252943515778
step: 10, loss: 0.03008274734020233
step: 20, loss: 0.11525201797485352
step: 30, loss: 0.07919354736804962
step: 40, loss: 0.08507875353097916
step: 50, loss: 0.013757538981735706
step: 60, loss: 0.004528282675892115
step: 70, loss: 0.11031452566385269
step: 80, loss: 0.14611725509166718
step: 90, loss: 0.21609410643577576
step: 100, loss: 0.021428542211651802
step: 110, loss: 0.03421454131603241
step: 120, loss: 0.05523868650197983
step: 130, loss: 0.040266986936330795
step: 140, loss: 0.07158917188644409
step: 150, loss: 0.18346069753170013
step: 160, loss: 0.034839123487472534
step: 170, loss: 0.00902913324534893
step: 180, loss: 0.007767436094582081
step: 190, loss: 0.08584554493427277
step: 200, loss: 0.011839170940220356
step: 210, loss: 0.013711796142160892
step: 220, loss: 0.04988698288798332
step: 230, loss: 0.07485635578632355
step: 240, loss: 0.0021088614594191313
step: 250, loss: 0.10601720213890076
step: 260, loss: 0.0676211342215538
step: 270, loss: 0.012771224603056908
step: 280, loss: 0.13860870897769928
step: 290, loss: 0.06927654147148132
step: 300, loss: 0.06069941818714142
step: 310, loss: 0.06065015494823456
step: 320, loss: 0.05747666954994202
step: 330, loss: 0.09404020756483078
step: 340, loss: 0.3010352849960327
step: 350, loss: 0.09872972220182419
step: 360, loss: 0.08523779362440109
step: 370, loss: 0.04698970913887024
step: 380, loss: 0.013544468209147453
step: 390, loss: 0.10369951277971268
step: 400, loss: 0.07779011130332947
step: 410, loss: 0.04941073805093765
step: 420, loss: 0.08344829827547073
epoch 10: dev_f1=0.9887640449438202, f1=0.9775280898876404, best_f1=0.9820627802690582
step: 0, loss: 0.03344757854938507
step: 10, loss: 0.062083881348371506
step: 20, loss: 0.03630753979086876
step: 30, loss: 0.08896107971668243
step: 40, loss: 0.05276750028133392
step: 50, loss: 0.06973840296268463
step: 60, loss: 0.0951310470700264
step: 70, loss: 0.014639930799603462
step: 80, loss: 0.1317923665046692
step: 90, loss: 0.009143887087702751
step: 100, loss: 0.07098976522684097
step: 110, loss: 0.04742046073079109
step: 120, loss: 0.06518194824457169
step: 130, loss: 0.0023344724904745817
step: 140, loss: 0.06166806071996689
step: 150, loss: 0.12023013830184937
step: 160, loss: 0.009006679058074951
step: 170, loss: 0.10931039601564407
step: 180, loss: 0.06184804439544678
step: 190, loss: 0.029803721234202385
step: 200, loss: 0.014746319502592087
step: 210, loss: 0.06902053207159042
step: 220, loss: 0.03475926071405411
step: 230, loss: 0.11196072399616241
step: 240, loss: 0.015646032989025116
step: 250, loss: 0.017358453944325447
step: 260, loss: 0.016704296693205833
step: 270, loss: 0.037749990820884705
step: 280, loss: 0.05499369278550148
step: 290, loss: 0.17039331793785095
step: 300, loss: 0.06804229319095612
step: 310, loss: 0.02999766916036606
step: 320, loss: 0.06666655093431473
step: 330, loss: 0.07722567766904831
step: 340, loss: 0.06352128088474274
step: 350, loss: 0.09135495126247406
step: 360, loss: 0.12878820300102234
step: 370, loss: 0.10363350808620453
step: 380, loss: 0.0351887121796608
step: 390, loss: 0.011057941243052483
step: 400, loss: 0.041777271777391434
step: 410, loss: 0.03198227658867836
step: 420, loss: 0.05769994109869003
epoch 11: dev_f1=0.9876819708846584, f1=0.978865406006674, best_f1=0.9820627802690582
step: 0, loss: 0.045228153467178345
step: 10, loss: 0.0838356539607048
step: 20, loss: 0.04052203893661499
step: 30, loss: 0.07550851255655289
step: 40, loss: 0.01253652386367321
step: 50, loss: 0.054302942007780075
step: 60, loss: 0.07058288902044296
step: 70, loss: 0.12861491739749908
step: 80, loss: 0.08899299055337906
step: 90, loss: 0.011447424069046974
step: 100, loss: 0.02024371735751629
step: 110, loss: 0.08108313381671906
step: 120, loss: 0.032257646322250366
step: 130, loss: 0.1398739069700241
step: 140, loss: 0.06124323233962059
step: 150, loss: 0.09224090725183487
step: 160, loss: 0.027921175584197044
step: 170, loss: 0.008786245249211788
step: 180, loss: 0.017393341287970543
step: 190, loss: 0.014846271835267544
step: 200, loss: 0.030489452183246613
step: 210, loss: 0.008893987163901329
step: 220, loss: 0.17552492022514343
step: 230, loss: 0.043038032948970795
step: 240, loss: 0.009933332912623882
step: 250, loss: 0.07125988602638245
step: 260, loss: 0.030242865905165672
step: 270, loss: 0.07251141965389252
step: 280, loss: 0.050527412444353104
step: 290, loss: 0.03125716745853424
step: 300, loss: 0.11649307608604431
step: 310, loss: 0.08987827599048615
step: 320, loss: 0.11194761842489243
step: 330, loss: 1.873394830909092e-05
step: 340, loss: 0.06539246439933777
step: 350, loss: 0.036919545382261276
step: 360, loss: 0.061468008905649185
step: 370, loss: 0.015523386187851429
step: 380, loss: 0.1485196352005005
step: 390, loss: 0.028147809207439423
step: 400, loss: 0.057450536638498306
step: 410, loss: 0.057150211185216904
step: 420, loss: 0.023978006094694138
epoch 12: dev_f1=0.992108229988726, f1=0.9820627802690582, best_f1=0.9820627802690582
step: 0, loss: 0.09762101620435715
step: 10, loss: 0.042486149817705154
step: 20, loss: 0.03632509708404541
step: 30, loss: 4.2969088099198416e-05
step: 40, loss: 0.07446707040071487
step: 50, loss: 0.07304433733224869
step: 60, loss: 0.034119926393032074
step: 70, loss: 0.028637215495109558
step: 80, loss: 0.0438128337264061
step: 90, loss: 0.0919673815369606
step: 100, loss: 0.06130906194448471
step: 110, loss: 0.04230025038123131
step: 120, loss: 0.0323604941368103
step: 130, loss: 0.031140796840190887
step: 140, loss: 0.00874182116240263
step: 150, loss: 0.12441669404506683
step: 160, loss: 0.08361148834228516
step: 170, loss: 0.10581211745738983
step: 180, loss: 0.031452376395463943
step: 190, loss: 0.200154110789299
step: 200, loss: 0.030051494017243385
step: 210, loss: 0.04059081897139549
step: 220, loss: 0.05873112380504608
step: 230, loss: 0.014774784445762634
step: 240, loss: 0.05945586785674095
step: 250, loss: 0.10178074240684509
step: 260, loss: 0.04979008808732033
step: 270, loss: 0.035828474909067154
step: 280, loss: 0.11346128582954407
step: 290, loss: 0.0077577922493219376
step: 300, loss: 0.06029336154460907
step: 310, loss: 0.01931866817176342
step: 320, loss: 0.00731985317543149
step: 330, loss: 0.021629303693771362
step: 340, loss: 0.002210575621575117
step: 350, loss: 0.03083941899240017
step: 360, loss: 0.0016454868018627167
step: 370, loss: 0.024722419679164886
step: 380, loss: 0.07769230008125305
step: 390, loss: 0.08781376481056213
step: 400, loss: 0.08390628546476364
step: 410, loss: 0.03458468243479729
step: 420, loss: 0.04544803872704506
epoch 13: dev_f1=0.9876819708846584, f1=0.9810479375696767, best_f1=0.9820627802690582
step: 0, loss: 0.044827040284872055
step: 10, loss: 0.04911442846059799
step: 20, loss: 0.04064491391181946
step: 30, loss: 0.05018981918692589
step: 40, loss: 0.002035006880760193
step: 50, loss: 0.06572115421295166
step: 60, loss: 0.0728321447968483
step: 70, loss: 0.0017439244547858834
step: 80, loss: 0.1443476378917694
step: 90, loss: 0.04440668970346451
step: 100, loss: 0.015283425338566303
step: 110, loss: 0.03683597594499588
step: 120, loss: 0.007530005183070898
step: 130, loss: 0.025049179792404175
step: 140, loss: 0.008609763346612453
step: 150, loss: 0.024829570204019547
step: 160, loss: 0.07158204913139343
step: 170, loss: 3.0410954423132353e-05
step: 180, loss: 0.04012710601091385
step: 190, loss: 0.10633613914251328
step: 200, loss: 0.07677803933620453
step: 210, loss: 0.028035320341587067
step: 220, loss: 0.005303665529936552
step: 230, loss: 0.010577552020549774
step: 240, loss: 0.059002358466386795
step: 250, loss: 0.009685380384325981
step: 260, loss: 0.05395729839801788
step: 270, loss: 1.32134973682696e-05
step: 280, loss: 0.0354403518140316
step: 290, loss: 0.19307266175746918
step: 300, loss: 0.0040513863787055016
step: 310, loss: 0.04548183083534241
step: 320, loss: 0.06735871732234955
step: 330, loss: 0.0482218936085701
step: 340, loss: 1.2725490705634002e-05
step: 350, loss: 0.14287151396274567
step: 360, loss: 0.07396451383829117
step: 370, loss: 0.04022418335080147
step: 380, loss: 0.08825773000717163
step: 390, loss: 0.09600675106048584
step: 400, loss: 0.025699857622385025
step: 410, loss: 0.040323562920093536
step: 420, loss: 0.006077078636735678
epoch 14: dev_f1=0.992108229988726, f1=0.9831649831649831, best_f1=0.9820627802690582
step: 0, loss: 0.051160022616386414
step: 10, loss: 0.0025087862741202116
step: 20, loss: 0.025445494800806046
step: 30, loss: 0.042504943907260895
step: 40, loss: 0.06278330832719803
step: 50, loss: 0.08192699402570724
step: 60, loss: 0.024653678759932518
step: 70, loss: 0.002010376425459981
step: 80, loss: 0.12801505625247955
step: 90, loss: 0.10583271831274033
step: 100, loss: 0.027504337951540947
step: 110, loss: 0.10312221944332123
step: 120, loss: 0.0015826051821932197
step: 130, loss: 0.009569699876010418
step: 140, loss: 0.06983975321054459
step: 150, loss: 0.0413118340075016
step: 160, loss: 0.027826810255646706
step: 170, loss: 0.03373672440648079
step: 180, loss: 0.021301399916410446
step: 190, loss: 0.07539255172014236
step: 200, loss: 0.08982053399085999
step: 210, loss: 0.04340438172221184
step: 220, loss: 0.05689794197678566
step: 230, loss: 0.00681810500100255
step: 240, loss: 0.07795358449220657
step: 250, loss: 0.11519590765237808
step: 260, loss: 0.027483761310577393
step: 270, loss: 0.04757131636142731
step: 280, loss: 0.022329749539494514
step: 290, loss: 0.009438087232410908
step: 300, loss: 0.03605915606021881
step: 310, loss: 0.0032314322888851166
step: 320, loss: 0.1445656418800354
step: 330, loss: 0.05608721822500229
step: 340, loss: 0.0028843428008258343
step: 350, loss: 0.04202989116311073
step: 360, loss: 0.05895192548632622
step: 370, loss: 0.1348636895418167
step: 380, loss: 0.009721489623188972
step: 390, loss: 0.05899522453546524
step: 400, loss: 0.09055104851722717
step: 410, loss: 2.9040016670478508e-05
step: 420, loss: 0.11056282371282578
epoch 15: dev_f1=0.990990990990991, f1=0.980963045912654, best_f1=0.9820627802690582
step: 0, loss: 0.01364778634160757
step: 10, loss: 0.031027719378471375
step: 20, loss: 0.003526094136759639
step: 30, loss: 0.07123987376689911
step: 40, loss: 0.09989669173955917
step: 50, loss: 0.021150516346096992
step: 60, loss: 0.23165123164653778
step: 70, loss: 0.03730876371264458
step: 80, loss: 0.051056332886219025
step: 90, loss: 0.029789743945002556
step: 100, loss: 0.051911819726228714
step: 110, loss: 0.06046876683831215
step: 120, loss: 0.05323418229818344
step: 130, loss: 0.0019431690452620387
step: 140, loss: 0.030610959976911545
step: 150, loss: 0.20242123305797577
step: 160, loss: 0.025678347796201706
step: 170, loss: 0.07063694298267365
step: 180, loss: 0.020968826487660408
step: 190, loss: 0.009016512893140316
step: 200, loss: 0.02014954946935177
step: 210, loss: 0.04215915873646736
step: 220, loss: 0.029476962983608246
step: 230, loss: 0.13479366898536682
step: 240, loss: 0.04008937254548073
step: 250, loss: 0.06843400001525879
step: 260, loss: 0.2820170819759369
step: 270, loss: 0.10930430889129639
step: 280, loss: 0.025404322892427444
step: 290, loss: 0.003716244362294674
step: 300, loss: 0.040051303803920746
step: 310, loss: 0.03843545913696289
step: 320, loss: 0.026408812031149864
step: 330, loss: 0.17053598165512085
step: 340, loss: 0.05067335069179535
step: 350, loss: 0.04981725662946701
step: 360, loss: 0.07708027958869934
step: 370, loss: 0.06363663822412491
step: 380, loss: 0.061225906014442444
step: 390, loss: 0.027650408446788788
step: 400, loss: 0.002732620108872652
step: 410, loss: 0.045868657529354095
step: 420, loss: 0.004324899986386299
epoch 16: dev_f1=0.992108229988726, f1=0.9842696629213483, best_f1=0.9820627802690582
step: 0, loss: 0.04446512833237648
step: 10, loss: 0.1046585738658905
step: 20, loss: 0.06543243676424026
step: 30, loss: 0.041924506425857544
step: 40, loss: 0.002700778190046549
step: 50, loss: 0.061971310526132584
step: 60, loss: 0.02464384213089943
step: 70, loss: 0.022926678881049156
step: 80, loss: 0.02521972730755806
step: 90, loss: 0.062078848481178284
step: 100, loss: 0.03343074396252632
step: 110, loss: 0.04122797027230263
step: 120, loss: 0.016616730019450188
step: 130, loss: 0.05762234702706337
step: 140, loss: 0.06988153606653214
step: 150, loss: 0.0010138548677787185
step: 160, loss: 0.018270542845129967
step: 170, loss: 0.04965509846806526
step: 180, loss: 0.00017437295173294842
step: 190, loss: 0.0763794407248497
step: 200, loss: 0.05931263417005539
step: 210, loss: 0.07402476668357849
step: 220, loss: 0.0693935826420784
step: 230, loss: 0.09921517968177795
step: 240, loss: 0.0007141972309909761
step: 250, loss: 0.09749399125576019
step: 260, loss: 0.033633891493082047
step: 270, loss: 0.07587865740060806
step: 280, loss: 0.0727376788854599
step: 290, loss: 0.003042567288503051
step: 300, loss: 0.0646257996559143
step: 310, loss: 0.009324277751147747
step: 320, loss: 0.029312461614608765
step: 330, loss: 0.0315244123339653
step: 340, loss: 0.03146176412701607
step: 350, loss: 0.03906707838177681
step: 360, loss: 0.004977216478437185
step: 370, loss: 0.0038771380204707384
step: 380, loss: 0.02947414480149746
step: 390, loss: 0.04783591255545616
step: 400, loss: 0.10243814438581467
step: 410, loss: 0.024066219106316566
step: 420, loss: 0.07752779126167297
epoch 17: dev_f1=0.990990990990991, f1=0.9842696629213483, best_f1=0.9820627802690582
step: 0, loss: 0.06637968868017197
step: 10, loss: 0.02697530761361122
step: 20, loss: 0.03134267032146454
step: 30, loss: 0.10429191589355469
step: 40, loss: 0.026047077029943466
step: 50, loss: 0.06600537151098251
step: 60, loss: 0.03469371423125267
step: 70, loss: 0.06079293042421341
step: 80, loss: 0.008668686263263226
step: 90, loss: 0.11050198972225189
step: 100, loss: 0.054750196635723114
step: 110, loss: 0.025748856365680695
step: 120, loss: 0.03785043954849243
step: 130, loss: 0.045932210981845856
step: 140, loss: 0.053124044090509415
step: 150, loss: 0.015744417905807495
step: 160, loss: 0.0263200756162405
step: 170, loss: 0.08079288899898529
step: 180, loss: 0.06235728785395622
step: 190, loss: 0.05059347301721573
step: 200, loss: 0.048744816333055496
step: 210, loss: 0.04182425141334534
step: 220, loss: 0.00028145889518782496
step: 230, loss: 0.04737100750207901
step: 240, loss: 0.021493658423423767
step: 250, loss: 0.104169100522995
step: 260, loss: 0.0775735005736351
step: 270, loss: 0.005528878886252642
step: 280, loss: 0.08447682112455368
step: 290, loss: 0.030033955350518227
step: 300, loss: 0.011926637031137943
step: 310, loss: 0.0005412936443462968
step: 320, loss: 0.057292815297842026
step: 330, loss: 0.0007816341239959002
step: 340, loss: 0.060591358691453934
step: 350, loss: 0.03244299069046974
step: 360, loss: 0.05599221959710121
step: 370, loss: 0.06049136444926262
step: 380, loss: 0.03295113146305084
step: 390, loss: 0.001548938569612801
step: 400, loss: 0.044702839106321335
step: 410, loss: 0.056118935346603394
step: 420, loss: 0.03438624367117882
epoch 18: dev_f1=0.9909706546275394, f1=0.9842342342342343, best_f1=0.9820627802690582
step: 0, loss: 0.021535618230700493
step: 10, loss: 0.013836155645549297
step: 20, loss: 0.028767401352524757
step: 30, loss: 0.13639815151691437
step: 40, loss: 0.013485216535627842
step: 50, loss: 0.00042018250678665936
step: 60, loss: 0.024924051016569138
step: 70, loss: 0.00036827410804107785
step: 80, loss: 0.09496666491031647
step: 90, loss: 0.07494644075632095
step: 100, loss: 0.015323983505368233
step: 110, loss: 0.00036962213926017284
step: 120, loss: 0.0266248919069767
step: 130, loss: 0.03848135843873024
step: 140, loss: 0.002952257404103875
step: 150, loss: 0.02580699510872364
step: 160, loss: 0.050288278609514236
step: 170, loss: 0.06218215450644493
step: 180, loss: 0.11483286321163177
step: 190, loss: 0.02746995911002159
step: 200, loss: 0.08893867582082748
step: 210, loss: 0.04912073165178299
step: 220, loss: 0.05639048293232918
step: 230, loss: 0.05616769939661026
step: 240, loss: 0.021811801940202713
step: 250, loss: 0.0005323306540958583
step: 260, loss: 0.022325733676552773
step: 270, loss: 0.061196357011795044
step: 280, loss: 0.018498485907912254
step: 290, loss: 0.00015368957247119397
step: 300, loss: 0.0012455370742827654
step: 310, loss: 0.04828588664531708
step: 320, loss: 0.002677219919860363
step: 330, loss: 0.07936542481184006
step: 340, loss: 0.0012800919357687235
step: 350, loss: 0.0662698745727539
step: 360, loss: 0.0178800281137228
step: 370, loss: 0.018657013773918152
step: 380, loss: 0.04287552833557129
step: 390, loss: 0.021590927615761757
step: 400, loss: 0.014975340105593204
step: 410, loss: 0.01777169108390808
step: 420, loss: 0.009787049144506454
epoch 19: dev_f1=0.9909706546275394, f1=0.9842342342342343, best_f1=0.9820627802690582
step: 0, loss: 0.00027068518102169037
step: 10, loss: 0.0004366789944469929
step: 20, loss: 0.021165233105421066
step: 30, loss: 0.013897866010665894
step: 40, loss: 0.046733081340789795
step: 50, loss: 0.0015450778882950544
step: 60, loss: 0.04832862317562103
step: 70, loss: 0.019670536741614342
step: 80, loss: 0.04733787104487419
step: 90, loss: 0.037690408527851105
step: 100, loss: 0.02057378552854061
step: 110, loss: 0.0006175889284349978
step: 120, loss: 0.05547947809100151
step: 130, loss: 0.02158830687403679
step: 140, loss: 0.0011567383771762252
step: 150, loss: 0.030533935874700546
step: 160, loss: 0.010502239689230919
step: 170, loss: 0.0009786374866962433
step: 180, loss: 0.026279695332050323
step: 190, loss: 0.06629513949155807
step: 200, loss: 0.030623145401477814
step: 210, loss: 0.014339006505906582
step: 220, loss: 0.05994228273630142
step: 230, loss: 0.044713906943798065
step: 240, loss: 0.01940847747027874
step: 250, loss: 0.003013049950823188
step: 260, loss: 0.037617914378643036
step: 270, loss: 0.032665546983480453
step: 280, loss: 0.0005489785107783973
step: 290, loss: 0.026411496102809906
step: 300, loss: 0.031137557700276375
step: 310, loss: 0.06714735925197601
step: 320, loss: 0.045865122228860855
step: 330, loss: 0.004524723161011934
step: 340, loss: 0.02262144908308983
step: 350, loss: 0.08569835871458054
step: 360, loss: 0.08493301272392273
step: 370, loss: 0.00397193618118763
step: 380, loss: 0.028693437576293945
step: 390, loss: 0.022744711488485336
step: 400, loss: 0.04063553363084793
step: 410, loss: 0.042236391454935074
step: 420, loss: 0.0017800894565880299
epoch 20: dev_f1=0.9909706546275394, f1=0.9853768278965129, best_f1=0.9820627802690582
