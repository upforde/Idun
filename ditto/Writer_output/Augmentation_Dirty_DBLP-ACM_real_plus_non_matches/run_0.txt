cuda
Device: cuda
step: 0, loss: 0.47928866744041443
step: 10, loss: 0.30977848172187805
step: 20, loss: 0.4237091541290283
step: 30, loss: 0.3828864097595215
step: 40, loss: 0.23027028143405914
step: 50, loss: 0.09030461311340332
step: 60, loss: 0.20372875034809113
step: 70, loss: 0.14236409962177277
step: 80, loss: 0.27730610966682434
step: 90, loss: 0.14065371453762054
step: 100, loss: 0.25920432806015015
step: 110, loss: 0.1139131709933281
step: 120, loss: 0.05220102518796921
step: 130, loss: 0.18393191695213318
step: 140, loss: 0.05991020426154137
step: 150, loss: 0.07089078426361084
step: 160, loss: 0.1818799078464508
step: 170, loss: 0.16966596245765686
step: 180, loss: 0.08157317340373993
step: 190, loss: 0.051980432122945786
step: 200, loss: 0.07865936309099197
step: 210, loss: 0.07315245270729065
step: 220, loss: 0.1598144918680191
step: 230, loss: 0.13395847380161285
step: 240, loss: 0.059358350932598114
step: 250, loss: 0.07908037304878235
step: 260, loss: 0.10253683477640152
step: 270, loss: 0.07294709980487823
step: 280, loss: 0.10294202715158463
step: 290, loss: 0.07569710910320282
step: 300, loss: 0.0861048623919487
step: 310, loss: 0.12007319182157516
step: 320, loss: 0.1381978541612625
step: 330, loss: 0.06703583151102066
step: 340, loss: 0.12352864444255829
step: 350, loss: 0.23676364123821259
step: 360, loss: 0.1294306367635727
step: 370, loss: 0.02971258945763111
step: 380, loss: 0.1677907407283783
step: 390, loss: 0.14676006138324738
step: 400, loss: 0.083641417324543
step: 410, loss: 0.1328822672367096
step: 420, loss: 0.0768490880727768
epoch 1: dev_f1=0.9830890642615557, f1=0.9739524348810873, best_f1=0.9739524348810873
step: 0, loss: 0.07741644233465195
step: 10, loss: 0.10088026523590088
step: 20, loss: 0.040580954402685165
step: 30, loss: 0.025579078122973442
step: 40, loss: 0.08246655762195587
step: 50, loss: 0.1219140961766243
step: 60, loss: 0.11814742535352707
step: 70, loss: 0.08501515537500381
step: 80, loss: 0.07837756723165512
step: 90, loss: 0.08330178260803223
step: 100, loss: 0.07306969165802002
step: 110, loss: 0.07260017096996307
step: 120, loss: 0.10219035297632217
step: 130, loss: 0.04966990649700165
step: 140, loss: 0.034274403005838394
step: 150, loss: 0.15181870758533478
step: 160, loss: 0.09163356572389603
step: 170, loss: 0.1806633025407791
step: 180, loss: 0.12354106456041336
step: 190, loss: 0.061629824340343475
step: 200, loss: 0.09207513928413391
step: 210, loss: 0.19617126882076263
step: 220, loss: 0.18286052346229553
step: 230, loss: 0.22214405238628387
step: 240, loss: 0.18224281072616577
step: 250, loss: 0.14697150886058807
step: 260, loss: 0.042191680520772934
step: 270, loss: 0.10580715537071228
step: 280, loss: 0.0420561321079731
step: 290, loss: 0.1067468449473381
step: 300, loss: 0.10451862215995789
step: 310, loss: 0.10010145604610443
step: 320, loss: 0.14585505425930023
step: 330, loss: 0.11094822734594345
step: 340, loss: 0.007387947291135788
step: 350, loss: 0.11439420282840729
step: 360, loss: 0.22399447858333588
step: 370, loss: 0.04474688693881035
step: 380, loss: 0.06415943801403046
step: 390, loss: 0.08185838162899017
step: 400, loss: 0.06686665117740631
step: 410, loss: 0.21039992570877075
step: 420, loss: 0.1470910608768463
epoch 2: dev_f1=0.9876265466816648, f1=0.9807037457434733, best_f1=0.9807037457434733
step: 0, loss: 0.09486670792102814
step: 10, loss: 0.028895266354084015
step: 20, loss: 0.12350022792816162
step: 30, loss: 0.16177596151828766
step: 40, loss: 0.08358694612979889
step: 50, loss: 0.06739374995231628
step: 60, loss: 0.022605760022997856
step: 70, loss: 0.06309401988983154
step: 80, loss: 0.07233630865812302
step: 90, loss: 0.12784093618392944
step: 100, loss: 0.07320281863212585
step: 110, loss: 0.1068551167845726
step: 120, loss: 0.02115643583238125
step: 130, loss: 0.18751683831214905
step: 140, loss: 0.09036311507225037
step: 150, loss: 0.17031322419643402
step: 160, loss: 0.08010520040988922
step: 170, loss: 0.06788480281829834
step: 180, loss: 0.07077455520629883
step: 190, loss: 0.07022189348936081
step: 200, loss: 0.020511632785201073
step: 210, loss: 0.017333799973130226
step: 220, loss: 0.12814852595329285
step: 230, loss: 0.08709746599197388
step: 240, loss: 0.006413638591766357
step: 250, loss: 0.08740177750587463
step: 260, loss: 0.07750141620635986
step: 270, loss: 0.04964139312505722
step: 280, loss: 0.2293144017457962
step: 290, loss: 0.0709841400384903
step: 300, loss: 0.16229373216629028
step: 310, loss: 0.0881781131029129
step: 320, loss: 0.030130766332149506
step: 330, loss: 0.12149124592542648
step: 340, loss: 0.08644506335258484
step: 350, loss: 0.08032649010419846
step: 360, loss: 0.07402446120977402
step: 370, loss: 0.028582025319337845
step: 380, loss: 0.035187844187021255
step: 390, loss: 0.10207804292440414
step: 400, loss: 0.18464216589927673
step: 410, loss: 0.06178566813468933
step: 420, loss: 0.04657093062996864
epoch 3: dev_f1=0.9876543209876544, f1=0.9842696629213483, best_f1=0.9842696629213483
step: 0, loss: 0.1362297683954239
step: 10, loss: 0.0443083681166172
step: 20, loss: 0.017959069460630417
step: 30, loss: 0.009500217624008656
step: 40, loss: 0.0954304188489914
step: 50, loss: 0.047484077513217926
step: 60, loss: 0.04813419282436371
step: 70, loss: 0.14000743627548218
step: 80, loss: 0.11618531495332718
step: 90, loss: 0.10050893574953079
step: 100, loss: 0.06663564592599869
step: 110, loss: 0.08297911286354065
step: 120, loss: 0.01450556144118309
step: 130, loss: 0.014035888016223907
step: 140, loss: 0.054264966398477554
step: 150, loss: 0.03655046969652176
step: 160, loss: 0.17707559466362
step: 170, loss: 0.06306392699480057
step: 180, loss: 0.02816152386367321
step: 190, loss: 0.15074077248573303
step: 200, loss: 0.03974999487400055
step: 210, loss: 0.12395014613866806
step: 220, loss: 0.05752526596188545
step: 230, loss: 0.0008591546793468297
step: 240, loss: 0.08919212967157364
step: 250, loss: 0.11283997446298599
step: 260, loss: 0.05434543639421463
step: 270, loss: 0.07949738204479218
step: 280, loss: 0.08411599695682526
step: 290, loss: 0.07769365608692169
step: 300, loss: 0.08490051329135895
step: 310, loss: 0.008417642675340176
step: 320, loss: 0.2629178762435913
step: 330, loss: 0.08329784870147705
step: 340, loss: 0.05527050793170929
step: 350, loss: 0.11733583360910416
step: 360, loss: 0.025449780747294426
step: 370, loss: 0.027974432334303856
step: 380, loss: 0.05563345551490784
step: 390, loss: 0.19466274976730347
step: 400, loss: 0.12479626387357712
step: 410, loss: 0.11439268290996552
step: 420, loss: 0.0671699121594429
epoch 4: dev_f1=0.9865771812080537, f1=0.9775784753363228, best_f1=0.9842696629213483
step: 0, loss: 0.024117374792695045
step: 10, loss: 0.05905343219637871
step: 20, loss: 0.03121672384440899
step: 30, loss: 0.09415145963430405
step: 40, loss: 0.059790562838315964
step: 50, loss: 0.04152009263634682
step: 60, loss: 0.02619459107518196
step: 70, loss: 0.09582517296075821
step: 80, loss: 0.10609173029661179
step: 90, loss: 0.050544314086437225
step: 100, loss: 0.05881178379058838
step: 110, loss: 0.0452607199549675
step: 120, loss: 0.10073012113571167
step: 130, loss: 0.03466231748461723
step: 140, loss: 0.08272039890289307
step: 150, loss: 0.0981115847826004
step: 160, loss: 0.1355413943529129
step: 170, loss: 0.015830572694540024
step: 180, loss: 0.07328304648399353
step: 190, loss: 0.009225833229720592
step: 200, loss: 0.061087898910045624
step: 210, loss: 0.033754948526620865
step: 220, loss: 0.08985139429569244
step: 230, loss: 0.01614483632147312
step: 240, loss: 0.1024402379989624
step: 250, loss: 0.044447436928749084
step: 260, loss: 0.024993792176246643
step: 270, loss: 0.15414075553417206
step: 280, loss: 0.034603916108608246
step: 290, loss: 0.14049027860164642
step: 300, loss: 0.13537950813770294
step: 310, loss: 0.07051046192646027
step: 320, loss: 0.11812238395214081
step: 330, loss: 0.08478591591119766
step: 340, loss: 0.088289774954319
step: 350, loss: 0.09223140776157379
step: 360, loss: 0.1380714625120163
step: 370, loss: 0.14200226962566376
step: 380, loss: 0.08072413504123688
step: 390, loss: 0.08659180998802185
step: 400, loss: 0.06452430039644241
step: 410, loss: 0.1574191004037857
step: 420, loss: 0.07357050478458405
epoch 5: dev_f1=0.988814317673378, f1=0.9787709497206705, best_f1=0.9787709497206705
step: 0, loss: 0.08811552822589874
step: 10, loss: 0.04340960085391998
step: 20, loss: 0.02872895635664463
step: 30, loss: 0.14001044631004333
step: 40, loss: 0.039324671030044556
step: 50, loss: 0.1184612363576889
step: 60, loss: 0.08004316687583923
step: 70, loss: 0.17097598314285278
step: 80, loss: 0.14619192481040955
step: 90, loss: 0.08159101754426956
step: 100, loss: 0.06396283954381943
step: 110, loss: 0.11677568405866623
step: 120, loss: 0.08491631597280502
step: 130, loss: 0.12834131717681885
step: 140, loss: 0.07118378579616547
step: 150, loss: 0.06394913792610168
step: 160, loss: 0.024321362376213074
step: 170, loss: 0.03296536207199097
step: 180, loss: 0.018201688304543495
step: 190, loss: 0.07317952066659927
step: 200, loss: 0.03759942203760147
step: 210, loss: 0.02025366947054863
step: 220, loss: 0.06564413011074066
step: 230, loss: 0.032760366797447205
step: 240, loss: 0.04210340231657028
step: 250, loss: 0.08696802705526352
step: 260, loss: 0.11440823972225189
step: 270, loss: 0.014846889302134514
step: 280, loss: 0.04569031298160553
step: 290, loss: 0.10624443739652634
step: 300, loss: 0.06368628144264221
step: 310, loss: 0.03936256095767021
step: 320, loss: 0.01954335905611515
step: 330, loss: 0.13943909108638763
step: 340, loss: 0.06809724122285843
step: 350, loss: 0.014183876104652882
step: 360, loss: 0.00017095889779739082
step: 370, loss: 0.04456084221601486
step: 380, loss: 0.07996254414319992
step: 390, loss: 0.15340587496757507
step: 400, loss: 0.11966771632432938
step: 410, loss: 0.097355917096138
step: 420, loss: 0.05896849185228348
epoch 6: dev_f1=0.9876543209876544, f1=0.9774774774774775, best_f1=0.9787709497206705
step: 0, loss: 0.10229790210723877
step: 10, loss: 0.16646155714988708
step: 20, loss: 0.03506389632821083
step: 30, loss: 0.09550639241933823
step: 40, loss: 0.03135352581739426
step: 50, loss: 0.07450812309980392
step: 60, loss: 0.0631294921040535
step: 70, loss: 0.20591431856155396
step: 80, loss: 0.06859041750431061
step: 90, loss: 0.1382293999195099
step: 100, loss: 0.13531270623207092
step: 110, loss: 0.021110888570547104
step: 120, loss: 0.0008572149090468884
step: 130, loss: 0.11398294568061829
step: 140, loss: 0.03898577764630318
step: 150, loss: 0.06449843943119049
step: 160, loss: 0.010370492935180664
step: 170, loss: 0.013590988703072071
step: 180, loss: 0.03431924059987068
step: 190, loss: 0.09133782982826233
step: 200, loss: 0.19609558582305908
step: 210, loss: 0.13292628526687622
step: 220, loss: 0.03444508835673332
step: 230, loss: 0.11470580101013184
step: 240, loss: 0.05670883506536484
step: 250, loss: 0.07644771039485931
step: 260, loss: 0.07193148136138916
step: 270, loss: 0.07611838728189468
step: 280, loss: 0.09167232364416122
step: 290, loss: 0.07925678044557571
step: 300, loss: 0.12977281212806702
step: 310, loss: 0.09785647690296173
step: 320, loss: 0.025850599631667137
step: 330, loss: 0.10543951392173767
step: 340, loss: 0.004817096050828695
step: 350, loss: 0.018753983080387115
step: 360, loss: 0.10979808866977692
step: 370, loss: 0.5150613784790039
step: 380, loss: 0.03622027486562729
step: 390, loss: 0.08028910309076309
step: 400, loss: 0.04060424119234085
step: 410, loss: 0.06471408903598785
step: 420, loss: 0.07793042808771133
epoch 7: dev_f1=0.9887387387387387, f1=0.9797297297297298, best_f1=0.9787709497206705
step: 0, loss: 0.0625380426645279
step: 10, loss: 0.09781267493963242
step: 20, loss: 0.016388051211833954
step: 30, loss: 0.18620601296424866
step: 40, loss: 0.04573312774300575
step: 50, loss: 0.0522858165204525
step: 60, loss: 0.03074580617249012
step: 70, loss: 0.06195713207125664
step: 80, loss: 0.02151666209101677
step: 90, loss: 0.06999918073415756
step: 100, loss: 0.02454429678618908
step: 110, loss: 0.05535278469324112
step: 120, loss: 0.0550583191215992
step: 130, loss: 0.006026791408658028
step: 140, loss: 0.11690369993448257
step: 150, loss: 0.1100042536854744
step: 160, loss: 0.07134018838405609
step: 170, loss: 0.06048130989074707
step: 180, loss: 0.05546720325946808
step: 190, loss: 0.006346608977764845
step: 200, loss: 0.1628844439983368
step: 210, loss: 0.11759450286626816
step: 220, loss: 0.050794679671525955
step: 230, loss: 0.05571489781141281
step: 240, loss: 0.07084951549768448
step: 250, loss: 0.021502330899238586
step: 260, loss: 0.11876225471496582
step: 270, loss: 0.11365942656993866
step: 280, loss: 0.059902604669332504
step: 290, loss: 0.020115802064538002
step: 300, loss: 0.20746007561683655
step: 310, loss: 0.09882541000843048
step: 320, loss: 0.011678183451294899
step: 330, loss: 0.08516143262386322
step: 340, loss: 0.12004754692316055
step: 350, loss: 0.09388463944196701
step: 360, loss: 0.09480778872966766
step: 370, loss: 0.010024613700807095
step: 380, loss: 0.06755171716213226
step: 390, loss: 0.1307595670223236
step: 400, loss: 0.03742317855358124
step: 410, loss: 0.11688164621591568
step: 420, loss: 0.030449919402599335
epoch 8: dev_f1=0.9887133182844244, f1=0.9852774631936579, best_f1=0.9787709497206705
step: 0, loss: 0.07789836078882217
step: 10, loss: 0.018716473132371902
step: 20, loss: 0.06309597194194794
step: 30, loss: 4.430424451129511e-05
step: 40, loss: 0.014626267366111279
step: 50, loss: 0.1497102677822113
step: 60, loss: 0.1302916258573532
step: 70, loss: 0.017571819946169853
step: 80, loss: 0.03743729367852211
step: 90, loss: 0.03451286256313324
step: 100, loss: 0.004163565579801798
step: 110, loss: 0.0939677283167839
step: 120, loss: 0.12060827761888504
step: 130, loss: 0.033687103539705276
step: 140, loss: 0.06378093361854553
step: 150, loss: 0.021514149382710457
step: 160, loss: 0.0021852171048521996
step: 170, loss: 0.009882046841084957
step: 180, loss: 0.07600492984056473
step: 190, loss: 0.045197743922472
step: 200, loss: 0.07372856140136719
step: 210, loss: 0.07135878503322601
step: 220, loss: 0.06619741022586823
step: 230, loss: 0.029411528259515762
step: 240, loss: 0.045630618929862976
step: 250, loss: 0.08938190340995789
step: 260, loss: 0.08767347037792206
step: 270, loss: 0.046773526817560196
step: 280, loss: 0.1045951098203659
step: 290, loss: 0.10997705906629562
step: 300, loss: 0.1106540858745575
step: 310, loss: 0.08088785409927368
step: 320, loss: 0.09226858615875244
step: 330, loss: 0.03368400037288666
step: 340, loss: 0.031910501420497894
step: 350, loss: 0.008340027183294296
step: 360, loss: 0.019884198904037476
step: 370, loss: 0.006583835929632187
step: 380, loss: 0.0067113833501935005
step: 390, loss: 0.023228323087096214
step: 400, loss: 0.0876743346452713
step: 410, loss: 0.04371463507413864
step: 420, loss: 0.13548533618450165
epoch 9: dev_f1=0.9898762654668166, f1=0.9797752808988766, best_f1=0.9797752808988766
step: 0, loss: 0.018646568059921265
step: 10, loss: 0.05150910094380379
step: 20, loss: 0.05327636003494263
step: 30, loss: 0.021262070164084435
step: 40, loss: 0.055585186928510666
step: 50, loss: 0.09354743361473083
step: 60, loss: 0.013493584468960762
step: 70, loss: 0.018359502777457237
step: 80, loss: 0.04929215833544731
step: 90, loss: 0.02095733769237995
step: 100, loss: 0.019433602690696716
step: 110, loss: 0.007374569308012724
step: 120, loss: 0.062224991619586945
step: 130, loss: 0.07914242893457413
step: 140, loss: 0.015448683872818947
step: 150, loss: 0.003362997667863965
step: 160, loss: 0.054275140166282654
step: 170, loss: 0.12201206386089325
step: 180, loss: 0.053957220166921616
step: 190, loss: 0.031646616756916046
step: 200, loss: 0.015474754385650158
step: 210, loss: 0.008564661256968975
step: 220, loss: 0.1998119205236435
step: 230, loss: 0.08503686636686325
step: 240, loss: 0.11297087371349335
step: 250, loss: 0.04333451762795448
step: 260, loss: 0.10685749351978302
step: 270, loss: 0.04407837614417076
step: 280, loss: 0.13590672612190247
step: 290, loss: 0.046577367931604385
step: 300, loss: 0.08034340292215347
step: 310, loss: 0.09141254425048828
step: 320, loss: 0.18960614502429962
step: 330, loss: 0.03335443139076233
step: 340, loss: 0.06038625165820122
step: 350, loss: 0.09150344878435135
step: 360, loss: 0.06358090788125992
step: 370, loss: 0.03962995857000351
step: 380, loss: 0.0805094763636589
step: 390, loss: 0.017022615298628807
step: 400, loss: 0.009782519191503525
step: 410, loss: 0.1166795939207077
step: 420, loss: 0.010485428385436535
epoch 10: dev_f1=0.9932735426008968, f1=0.9865771812080537, best_f1=0.9865771812080537
step: 0, loss: 0.011852329596877098
step: 10, loss: 0.07520294189453125
step: 20, loss: 0.1068485677242279
step: 30, loss: 0.10486821830272675
step: 40, loss: 0.030982181429862976
step: 50, loss: 0.019310053437948227
step: 60, loss: 0.005399457179009914
step: 70, loss: 0.07120105624198914
step: 80, loss: 0.05991421267390251
step: 90, loss: 0.039533719420433044
step: 100, loss: 0.0326596163213253
step: 110, loss: 0.11093322932720184
step: 120, loss: 0.06794285029172897
step: 130, loss: 0.10498646646738052
step: 140, loss: 0.04194844514131546
step: 150, loss: 0.0027435380034148693
step: 160, loss: 0.023329026997089386
step: 170, loss: 0.10918064415454865
step: 180, loss: 0.03291763365268707
step: 190, loss: 0.06805514544248581
step: 200, loss: 0.09105150401592255
step: 210, loss: 0.03844566270709038
step: 220, loss: 0.02384650893509388
step: 230, loss: 0.0490390881896019
step: 240, loss: 0.0570550300180912
step: 250, loss: 0.0012675519101321697
step: 260, loss: 0.12217526137828827
step: 270, loss: 0.07560126483440399
step: 280, loss: 0.08189687132835388
step: 290, loss: 0.006182272918522358
step: 300, loss: 0.018513480201363564
step: 310, loss: 0.031443700194358826
step: 320, loss: 0.00015600022743456066
step: 330, loss: 0.08822433650493622
step: 340, loss: 0.11621811240911484
step: 350, loss: 0.08354689180850983
step: 360, loss: 0.09891241043806076
step: 370, loss: 0.026509635150432587
step: 380, loss: 0.2236860692501068
step: 390, loss: 0.05372696742415428
step: 400, loss: 0.047564100474119186
step: 410, loss: 0.15227437019348145
step: 420, loss: 0.037422411143779755
epoch 11: dev_f1=0.9899216125419933, f1=0.983277591973244, best_f1=0.9865771812080537
step: 0, loss: 0.02563115581870079
step: 10, loss: 0.014807168394327164
step: 20, loss: 0.06326396763324738
step: 30, loss: 0.008439636789262295
step: 40, loss: 0.1253659427165985
step: 50, loss: 0.042530499398708344
step: 60, loss: 0.07809562981128693
step: 70, loss: 0.008009037934243679
step: 80, loss: 0.0009617466712370515
step: 90, loss: 0.027043815702199936
step: 100, loss: 0.006491611711680889
step: 110, loss: 0.0591612383723259
step: 120, loss: 0.08747474104166031
step: 130, loss: 0.05404863506555557
step: 140, loss: 0.028640074655413628
step: 150, loss: 0.03314211219549179
step: 160, loss: 0.0238345880061388
step: 170, loss: 0.05119618773460388
step: 180, loss: 0.03813675791025162
step: 190, loss: 0.05300763249397278
step: 200, loss: 0.07667385041713715
step: 210, loss: 0.04103616625070572
step: 220, loss: 0.055601149797439575
step: 230, loss: 0.06246764585375786
step: 240, loss: 0.05258570984005928
step: 250, loss: 0.023619437590241432
step: 260, loss: 0.06710581481456757
step: 270, loss: 0.02898825891315937
step: 280, loss: 0.0005453495541587472
step: 290, loss: 0.17722396552562714
step: 300, loss: 0.06720229983329773
step: 310, loss: 0.01902676373720169
step: 320, loss: 0.009745756164193153
step: 330, loss: 0.0005384958349168301
step: 340, loss: 0.1368095725774765
step: 350, loss: 0.00987520907074213
step: 360, loss: 0.10155485570430756
step: 370, loss: 0.027671337127685547
step: 380, loss: 0.07426609843969345
step: 390, loss: 0.14646250009536743
step: 400, loss: 0.04904969781637192
step: 410, loss: 0.013795435428619385
step: 420, loss: 0.05462257191538811
epoch 12: dev_f1=0.9898989898989898, f1=0.9820224719101124, best_f1=0.9865771812080537
step: 0, loss: 0.04804407060146332
step: 10, loss: 0.060156360268592834
step: 20, loss: 0.02050790749490261
step: 30, loss: 0.0037883054465055466
step: 40, loss: 0.026630602777004242
step: 50, loss: 0.056242138147354126
step: 60, loss: 0.06787464022636414
step: 70, loss: 0.05955229699611664
step: 80, loss: 0.02058018185198307
step: 90, loss: 0.06410941481590271
step: 100, loss: 0.0795920267701149
step: 110, loss: 0.023429814726114273
step: 120, loss: 0.11319676786661148
step: 130, loss: 0.0055093541741371155
step: 140, loss: 0.020834049209952354
step: 150, loss: 0.054847028106451035
step: 160, loss: 0.09035762399435043
step: 170, loss: 0.032420042902231216
step: 180, loss: 0.014724858105182648
step: 190, loss: 0.01694718562066555
step: 200, loss: 0.10645511001348495
step: 210, loss: 0.058775778859853745
step: 220, loss: 0.05619318038225174
step: 230, loss: 0.002605993067845702
step: 240, loss: 0.047660406678915024
step: 250, loss: 0.018455611541867256
step: 260, loss: 0.04401683434844017
step: 270, loss: 0.020413080230355263
step: 280, loss: 0.15422192215919495
step: 290, loss: 0.1243445873260498
step: 300, loss: 0.0254706721752882
step: 310, loss: 0.03878604248166084
step: 320, loss: 0.07987364381551743
step: 330, loss: 0.06930046528577805
step: 340, loss: 0.08155693858861923
step: 350, loss: 0.06508272141218185
step: 360, loss: 0.050050947815179825
step: 370, loss: 0.04821973666548729
step: 380, loss: 0.16161438822746277
step: 390, loss: 0.08292172849178314
step: 400, loss: 0.013478201813995838
step: 410, loss: 0.022714858874678612
step: 420, loss: 0.022375158965587616
epoch 13: dev_f1=0.9910313901345291, f1=0.9843400447427293, best_f1=0.9865771812080537
step: 0, loss: 0.05892563983798027
step: 10, loss: 0.012613334693014622
step: 20, loss: 0.02420831471681595
step: 30, loss: 0.16026151180267334
step: 40, loss: 0.0005040289834141731
step: 50, loss: 0.00638998206704855
step: 60, loss: 0.022692836821079254
step: 70, loss: 0.021973995491862297
step: 80, loss: 0.08515454083681107
step: 90, loss: 0.05190829187631607
step: 100, loss: 0.1003272607922554
step: 110, loss: 0.06433960795402527
step: 120, loss: 0.06452077627182007
step: 130, loss: 0.1274195909500122
step: 140, loss: 0.08646471053361893
step: 150, loss: 0.02097664773464203
step: 160, loss: 0.06102452054619789
step: 170, loss: 0.023799965158104897
step: 180, loss: 0.02735992893576622
step: 190, loss: 0.08832290768623352
step: 200, loss: 0.05223316699266434
step: 210, loss: 0.0009633529698476195
step: 220, loss: 0.11400175094604492
step: 230, loss: 0.022621678188443184
step: 240, loss: 0.017916712909936905
step: 250, loss: 0.07586835324764252
step: 260, loss: 0.11960505694150925
step: 270, loss: 0.02142537198960781
step: 280, loss: 0.08098503202199936
step: 290, loss: 0.03755766153335571
step: 300, loss: 0.013307923451066017
step: 310, loss: 0.07176575809717178
step: 320, loss: 0.03739457204937935
step: 330, loss: 0.025294097140431404
step: 340, loss: 0.020919419825077057
step: 350, loss: 0.02405237779021263
step: 360, loss: 0.03955518826842308
step: 370, loss: 0.07272817939519882
step: 380, loss: 0.03622705116868019
step: 390, loss: 0.019886376336216927
step: 400, loss: 0.038722772151231766
step: 410, loss: 0.02752702310681343
step: 420, loss: 0.0466347299516201
epoch 14: dev_f1=0.9910112359550561, f1=0.9843400447427293, best_f1=0.9865771812080537
step: 0, loss: 0.06867926567792892
step: 10, loss: 0.02130424790084362
step: 20, loss: 0.04355427250266075
step: 30, loss: 0.02221599966287613
step: 40, loss: 0.02498251013457775
step: 50, loss: 0.08086077868938446
step: 60, loss: 0.044476598501205444
step: 70, loss: 0.036655738949775696
step: 80, loss: 0.05947418510913849
step: 90, loss: 0.00024932631640695035
step: 100, loss: 0.06368572264909744
step: 110, loss: 0.04691614955663681
step: 120, loss: 0.020714007318019867
step: 130, loss: 0.05883470177650452
step: 140, loss: 0.009235763922333717
step: 150, loss: 0.025032805278897285
step: 160, loss: 0.03550346568226814
step: 170, loss: 0.04515625908970833
step: 180, loss: 0.0493074394762516
step: 190, loss: 0.07205788046121597
step: 200, loss: 0.050902217626571655
step: 210, loss: 0.03233686089515686
step: 220, loss: 0.06993064284324646
step: 230, loss: 0.04820045083761215
step: 240, loss: 0.024825453758239746
step: 250, loss: 0.07249915599822998
step: 260, loss: 0.10825850069522858
step: 270, loss: 0.09693536907434464
step: 280, loss: 0.022835472598671913
step: 290, loss: 0.10874655842781067
step: 300, loss: 0.09293915331363678
step: 310, loss: 0.08847460895776749
step: 320, loss: 0.04198750481009483
step: 330, loss: 0.10327126830816269
step: 340, loss: 0.041222453117370605
step: 350, loss: 0.011384649202227592
step: 360, loss: 0.04307611286640167
step: 370, loss: 0.09876823425292969
step: 380, loss: 0.04593664035201073
step: 390, loss: 0.022592714056372643
step: 400, loss: 0.0492478646337986
step: 410, loss: 0.032872553914785385
step: 420, loss: 0.0357135608792305
epoch 15: dev_f1=0.9921436588103255, f1=0.9854748603351955, best_f1=0.9865771812080537
step: 0, loss: 0.09220409393310547
step: 10, loss: 0.14854702353477478
step: 20, loss: 0.025195911526679993
step: 30, loss: 0.000261977082118392
step: 40, loss: 0.027249878272414207
step: 50, loss: 0.06990047544240952
step: 60, loss: 0.01576497033238411
step: 70, loss: 0.0010671672644093633
step: 80, loss: 0.04438586160540581
step: 90, loss: 0.009263456799089909
step: 100, loss: 0.017055412754416466
step: 110, loss: 0.08493281900882721
step: 120, loss: 0.0007597094518132508
step: 130, loss: 0.023090966045856476
step: 140, loss: 0.00010823644697666168
step: 150, loss: 0.022885242477059364
step: 160, loss: 0.014755621552467346
step: 170, loss: 0.048323407769203186
step: 180, loss: 0.03823301941156387
step: 190, loss: 0.018977154046297073
step: 200, loss: 0.018086180090904236
step: 210, loss: 0.05495490878820419
step: 220, loss: 0.07479104399681091
step: 230, loss: 0.06768099963665009
step: 240, loss: 0.06491796672344208
step: 250, loss: 0.0731167420744896
step: 260, loss: 0.06528618931770325
step: 270, loss: 0.0014694888377562165
step: 280, loss: 0.00020537682576104999
step: 290, loss: 0.06427577137947083
step: 300, loss: 0.00799561571329832
step: 310, loss: 0.0438300296664238
step: 320, loss: 0.11584655195474625
step: 330, loss: 0.0001379571622237563
step: 340, loss: 0.12236285954713821
step: 350, loss: 0.07484003901481628
step: 360, loss: 0.0002887281880248338
step: 370, loss: 0.05375826358795166
step: 380, loss: 0.04734199494123459
step: 390, loss: 0.04831496626138687
step: 400, loss: 0.0002932001370936632
step: 410, loss: 0.06789135932922363
step: 420, loss: 0.017469773069024086
epoch 16: dev_f1=0.9932584269662922, f1=0.9831271091113611, best_f1=0.9865771812080537
step: 0, loss: 0.022780481725931168
step: 10, loss: 0.04054783657193184
step: 20, loss: 0.033064693212509155
step: 30, loss: 0.007054861634969711
step: 40, loss: 0.03851785138249397
step: 50, loss: 0.022812362760305405
step: 60, loss: 0.03379971906542778
step: 70, loss: 0.07617168128490448
step: 80, loss: 0.032757844775915146
step: 90, loss: 0.08718892931938171
step: 100, loss: 0.0820908322930336
step: 110, loss: 0.02623576670885086
step: 120, loss: 0.06255606561899185
step: 130, loss: 0.05698748677968979
step: 140, loss: 0.09786675870418549
step: 150, loss: 0.09139029681682587
step: 160, loss: 0.0747000128030777
step: 170, loss: 0.07047183811664581
step: 180, loss: 0.001776812830939889
step: 190, loss: 0.010573639534413815
step: 200, loss: 0.016905248165130615
step: 210, loss: 0.028786564245820045
step: 220, loss: 0.048876214772462845
step: 230, loss: 0.02762429229915142
step: 240, loss: 0.012331041507422924
step: 250, loss: 0.00028879306046292186
step: 260, loss: 0.003525675507262349
step: 270, loss: 0.022901061922311783
step: 280, loss: 7.690595521125942e-05
step: 290, loss: 0.0057671633549034595
step: 300, loss: 0.00026927399449050426
step: 310, loss: 0.03780937194824219
step: 320, loss: 0.03545660525560379
step: 330, loss: 0.026778236031532288
step: 340, loss: 0.03836331143975258
step: 350, loss: 0.024564772844314575
step: 360, loss: 0.04499954730272293
step: 370, loss: 0.023767173290252686
step: 380, loss: 0.08090292662382126
step: 390, loss: 0.0001703820307739079
step: 400, loss: 0.04129241406917572
step: 410, loss: 0.01438923366367817
step: 420, loss: 0.044131506234407425
epoch 17: dev_f1=0.9921436588103255, f1=0.9854096520763187, best_f1=0.9865771812080537
step: 0, loss: 0.01536670234054327
step: 10, loss: 0.025617262348532677
step: 20, loss: 0.01105332002043724
step: 30, loss: 0.024152183905243874
step: 40, loss: 0.05586068704724312
step: 50, loss: 0.008670039474964142
step: 60, loss: 0.0582437589764595
step: 70, loss: 0.00019526813412085176
step: 80, loss: 0.026312602683901787
step: 90, loss: 0.0467558391392231
step: 100, loss: 0.001393185113556683
step: 110, loss: 0.00010306644253432751
step: 120, loss: 0.01772487722337246
step: 130, loss: 0.0312720388174057
step: 140, loss: 0.09217088669538498
step: 150, loss: 0.018795138224959373
step: 160, loss: 0.0023250849917531013
step: 170, loss: 0.03676902502775192
step: 180, loss: 8.027775766095147e-05
step: 190, loss: 0.059404172003269196
step: 200, loss: 0.02403724379837513
step: 210, loss: 0.04318501427769661
step: 220, loss: 0.00030001337290741503
step: 230, loss: 0.09162459522485733
step: 240, loss: 0.05181868001818657
step: 250, loss: 0.05143959820270538
step: 260, loss: 0.010629520751535892
step: 270, loss: 0.06759205460548401
step: 280, loss: 0.03701101988554001
step: 290, loss: 0.0006364535656757653
step: 300, loss: 0.049479320645332336
step: 310, loss: 0.0017282010521739721
step: 320, loss: 0.05601169168949127
step: 330, loss: 0.08075277507305145
step: 340, loss: 0.044141337275505066
step: 350, loss: 0.05169199779629707
step: 360, loss: 0.1027475893497467
step: 370, loss: 0.06538238376379013
step: 380, loss: 0.018057668581604958
step: 390, loss: 0.0007031822460703552
step: 400, loss: 0.03433717042207718
step: 410, loss: 0.0002674533170647919
step: 420, loss: 0.10245112329721451
epoch 18: dev_f1=0.9932584269662922, f1=0.984304932735426, best_f1=0.9865771812080537
step: 0, loss: 0.00462927995249629
step: 10, loss: 0.02081000618636608
step: 20, loss: 0.026469817385077477
step: 30, loss: 0.06588026881217957
step: 40, loss: 0.07764837890863419
step: 50, loss: 0.05096941441297531
step: 60, loss: 0.025055792182683945
step: 70, loss: 0.11016923934221268
step: 80, loss: 0.03240271657705307
step: 90, loss: 0.00010200601536780596
step: 100, loss: 0.00018385578005108982
step: 110, loss: 0.058692604303359985
step: 120, loss: 0.0760585218667984
step: 130, loss: 0.05449935048818588
step: 140, loss: 0.08065411448478699
step: 150, loss: 0.142783522605896
step: 160, loss: 0.01745201274752617
step: 170, loss: 0.020603986456990242
step: 180, loss: 0.038927823305130005
step: 190, loss: 0.04426279664039612
step: 200, loss: 0.034256789833307266
step: 210, loss: 0.042529162019491196
step: 220, loss: 0.015211640857160091
step: 230, loss: 0.05903630331158638
step: 240, loss: 0.02628127485513687
step: 250, loss: 0.07268338650465012
step: 260, loss: 0.09009768813848495
step: 270, loss: 0.012021373026072979
step: 280, loss: 0.022605160251259804
step: 290, loss: 0.0002792197628878057
step: 300, loss: 0.039823904633522034
step: 310, loss: 0.08462201058864594
step: 320, loss: 0.0001545562845421955
step: 330, loss: 0.04056750610470772
step: 340, loss: 0.0001871662534540519
step: 350, loss: 0.04107549041509628
step: 360, loss: 0.005305569618940353
step: 370, loss: 0.0232610572129488
step: 380, loss: 0.019166432321071625
step: 390, loss: 0.0001712408848106861
step: 400, loss: 0.017831401899456978
step: 410, loss: 0.035876791924238205
step: 420, loss: 0.01959298737347126
epoch 19: dev_f1=0.9921436588103255, f1=0.984304932735426, best_f1=0.9865771812080537
step: 0, loss: 0.02556474506855011
step: 10, loss: 0.0989532470703125
step: 20, loss: 0.048958588391542435
step: 30, loss: 0.025802483782172203
step: 40, loss: 0.00585394911468029
step: 50, loss: 0.022989219054579735
step: 60, loss: 0.11722343415021896
step: 70, loss: 0.04044552519917488
step: 80, loss: 0.019304709509015083
step: 90, loss: 0.00010243105498375371
step: 100, loss: 0.026004737243056297
step: 110, loss: 0.06801000982522964
step: 120, loss: 0.00022405770141631365
step: 130, loss: 0.00013211504847276956
step: 140, loss: 0.0654945895075798
step: 150, loss: 0.037074849009513855
step: 160, loss: 0.1053064614534378
step: 170, loss: 9.541068720864132e-05
step: 180, loss: 0.0015597038436681032
step: 190, loss: 0.10721436887979507
step: 200, loss: 0.05129632726311684
step: 210, loss: 0.04318815469741821
step: 220, loss: 0.004126165062189102
step: 230, loss: 0.026516923680901527
step: 240, loss: 0.06954435259103775
step: 250, loss: 0.020788945257663727
step: 260, loss: 0.023305146023631096
step: 270, loss: 0.04618057981133461
step: 280, loss: 0.03615206480026245
step: 290, loss: 0.07084954530000687
step: 300, loss: 0.08580417186021805
step: 310, loss: 0.020490329712629318
step: 320, loss: 0.015976576134562492
step: 330, loss: 0.0021229195408523083
step: 340, loss: 0.022684281691908836
step: 350, loss: 0.06920939683914185
step: 360, loss: 0.04264838993549347
step: 370, loss: 0.04480642080307007
step: 380, loss: 0.0003902901371475309
step: 390, loss: 0.04357046261429787
step: 400, loss: 0.00017207174096256495
step: 410, loss: 0.034952033311128616
step: 420, loss: 0.038368627429008484
epoch 20: dev_f1=0.9932584269662922, f1=0.984304932735426, best_f1=0.9865771812080537
