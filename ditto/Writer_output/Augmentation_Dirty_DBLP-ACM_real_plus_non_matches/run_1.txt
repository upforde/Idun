cuda
Device: cuda
step: 0, loss: 0.7225515246391296
step: 10, loss: 0.32033881545066833
step: 20, loss: 0.4445215165615082
step: 30, loss: 0.4057973623275757
step: 40, loss: 0.3095044791698456
step: 50, loss: 0.03409082815051079
step: 60, loss: 0.132197767496109
step: 70, loss: 0.1746102124452591
step: 80, loss: 0.14462575316429138
step: 90, loss: 0.20347456634044647
step: 100, loss: 0.1859213262796402
step: 110, loss: 0.17946864664554596
step: 120, loss: 0.2469100058078766
step: 130, loss: 0.0688788965344429
step: 140, loss: 0.13246600329875946
step: 150, loss: 0.19870945811271667
step: 160, loss: 0.10893252491950989
step: 170, loss: 0.1764240860939026
step: 180, loss: 0.08497145026922226
step: 190, loss: 0.15742391347885132
step: 200, loss: 0.3244848847389221
step: 210, loss: 0.06663579493761063
step: 220, loss: 0.09689268469810486
step: 230, loss: 0.10143338888883591
step: 240, loss: 0.12237546592950821
step: 250, loss: 0.07947255671024323
step: 260, loss: 0.06967494636774063
step: 270, loss: 0.1176028847694397
step: 280, loss: 0.07937239855527878
step: 290, loss: 0.1192050352692604
step: 300, loss: 0.09204258769750595
step: 310, loss: 0.10215842723846436
step: 320, loss: 0.18825939297676086
step: 330, loss: 0.05993965268135071
step: 340, loss: 0.06035611405968666
step: 350, loss: 0.13146355748176575
step: 360, loss: 0.24332529306411743
step: 370, loss: 0.17370569705963135
step: 380, loss: 0.204568549990654
step: 390, loss: 0.13557198643684387
step: 400, loss: 0.0877799317240715
step: 410, loss: 0.12159959226846695
step: 420, loss: 0.022512448951601982
epoch 1: dev_f1=0.984304932735426, f1=0.9708520179372198, best_f1=0.9708520179372198
step: 0, loss: 0.29795706272125244
step: 10, loss: 0.037261128425598145
step: 20, loss: 0.14370566606521606
step: 30, loss: 0.06284933537244797
step: 40, loss: 0.13259047269821167
step: 50, loss: 0.12387463450431824
step: 60, loss: 0.06569301337003708
step: 70, loss: 0.037386298179626465
step: 80, loss: 0.1607232242822647
step: 90, loss: 0.14634527266025543
step: 100, loss: 0.036273758858442307
step: 110, loss: 0.08360276371240616
step: 120, loss: 0.1343698352575302
step: 130, loss: 0.15042002499103546
step: 140, loss: 0.05310981720685959
step: 150, loss: 0.018395282328128815
step: 160, loss: 0.04708796739578247
step: 170, loss: 0.12963047623634338
step: 180, loss: 0.0032143148127943277
step: 190, loss: 0.14464235305786133
step: 200, loss: 0.09387629479169846
step: 210, loss: 0.13912247121334076
step: 220, loss: 0.05644608661532402
step: 230, loss: 0.09967397898435593
step: 240, loss: 0.07594764232635498
step: 250, loss: 0.1795239895582199
step: 260, loss: 0.15881739556789398
step: 270, loss: 0.07831381261348724
step: 280, loss: 0.07007893919944763
step: 290, loss: 0.16863872110843658
step: 300, loss: 0.11641845107078552
step: 310, loss: 0.11613260954618454
step: 320, loss: 0.10965023189783096
step: 330, loss: 0.1279708445072174
step: 340, loss: 0.14371788501739502
step: 350, loss: 0.10403710603713989
step: 360, loss: 0.09515778720378876
step: 370, loss: 0.049643535166978836
step: 380, loss: 0.01837695762515068
step: 390, loss: 0.15839622914791107
step: 400, loss: 0.047238532453775406
step: 410, loss: 0.0720902606844902
step: 420, loss: 0.09080896526575089
epoch 2: dev_f1=0.9808342728297633, f1=0.971815107102593, best_f1=0.9708520179372198
step: 0, loss: 0.042372893542051315
step: 10, loss: 0.07878857851028442
step: 20, loss: 0.05820353329181671
step: 30, loss: 0.14473967254161835
step: 40, loss: 0.06020105630159378
step: 50, loss: 0.016624443233013153
step: 60, loss: 0.14143779873847961
step: 70, loss: 0.08145898580551147
step: 80, loss: 0.04972740262746811
step: 90, loss: 0.07808062434196472
step: 100, loss: 0.14256814122200012
step: 110, loss: 0.11965622007846832
step: 120, loss: 0.09156492352485657
step: 130, loss: 0.10836699604988098
step: 140, loss: 0.032318562269210815
step: 150, loss: 0.04830927401781082
step: 160, loss: 0.11385326832532883
step: 170, loss: 0.05810104310512543
step: 180, loss: 0.014642490074038506
step: 190, loss: 0.05439184233546257
step: 200, loss: 0.07494758814573288
step: 210, loss: 0.01198852900415659
step: 220, loss: 0.05158466845750809
step: 230, loss: 0.11270439624786377
step: 240, loss: 0.24658937752246857
step: 250, loss: 0.09399068355560303
step: 260, loss: 0.09224743396043777
step: 270, loss: 0.00796887930482626
step: 280, loss: 0.14233876764774323
step: 290, loss: 0.08478457480669022
step: 300, loss: 0.024664459750056267
step: 310, loss: 0.09011580049991608
step: 320, loss: 0.05253591388463974
step: 330, loss: 0.09320221841335297
step: 340, loss: 0.12173627316951752
step: 350, loss: 0.13040447235107422
step: 360, loss: 0.08150538057088852
step: 370, loss: 0.22099871933460236
step: 380, loss: 0.02775636501610279
step: 390, loss: 0.044489502906799316
step: 400, loss: 0.12182760238647461
step: 410, loss: 0.0592900775372982
step: 420, loss: 0.060675233602523804
epoch 3: dev_f1=0.9898534385569334, f1=0.9830124575311437, best_f1=0.9830124575311437
step: 0, loss: 0.06012821942567825
step: 10, loss: 0.06069888174533844
step: 20, loss: 0.07836081832647324
step: 30, loss: 0.1148189902305603
step: 40, loss: 0.19030000269412994
step: 50, loss: 0.06254499405622482
step: 60, loss: 0.14728426933288574
step: 70, loss: 0.06432721018791199
step: 80, loss: 0.09691254794597626
step: 90, loss: 0.08562273532152176
step: 100, loss: 0.03226431831717491
step: 110, loss: 0.042719654738903046
step: 120, loss: 0.10338454693555832
step: 130, loss: 0.0381331592798233
step: 140, loss: 0.0966368168592453
step: 150, loss: 0.027292177081108093
step: 160, loss: 0.11114437133073807
step: 170, loss: 0.032219529151916504
step: 180, loss: 0.06732780486345291
step: 190, loss: 0.10058864951133728
step: 200, loss: 0.1218784749507904
step: 210, loss: 0.10742167383432388
step: 220, loss: 0.06325442343950272
step: 230, loss: 0.08809776604175568
step: 240, loss: 0.08589819073677063
step: 250, loss: 0.1395062953233719
step: 260, loss: 0.12808097898960114
step: 270, loss: 0.061983946710824966
step: 280, loss: 0.1691507250070572
step: 290, loss: 0.07730066776275635
step: 300, loss: 0.10094618052244186
step: 310, loss: 0.06287401914596558
step: 320, loss: 0.10410960018634796
step: 330, loss: 0.07272034138441086
step: 340, loss: 0.09292666614055634
step: 350, loss: 0.03028930351138115
step: 360, loss: 0.13224224746227264
step: 370, loss: 0.06905931979417801
step: 380, loss: 0.0546923503279686
step: 390, loss: 0.13685403764247894
step: 400, loss: 0.10265876352787018
step: 410, loss: 0.17736199498176575
step: 420, loss: 0.09577101469039917
epoch 4: dev_f1=0.9898074745186863, f1=0.9794988610478361, best_f1=0.9830124575311437
step: 0, loss: 0.09724411368370056
step: 10, loss: 0.01838498003780842
step: 20, loss: 0.07161693274974823
step: 30, loss: 0.12126659601926804
step: 40, loss: 0.0991070345044136
step: 50, loss: 0.02050730772316456
step: 60, loss: 0.2570244371891022
step: 70, loss: 0.14360174536705017
step: 80, loss: 0.1586039811372757
step: 90, loss: 0.13478906452655792
step: 100, loss: 0.18143019080162048
step: 110, loss: 0.0694991797208786
step: 120, loss: 0.05967509001493454
step: 130, loss: 0.06691157817840576
step: 140, loss: 0.04052383452653885
step: 150, loss: 0.06263724714517593
step: 160, loss: 0.17734801769256592
step: 170, loss: 0.0942130908370018
step: 180, loss: 0.1607484668493271
step: 190, loss: 0.13748960196971893
step: 200, loss: 0.05715913698077202
step: 210, loss: 0.05300236865878105
step: 220, loss: 0.04249000549316406
step: 230, loss: 0.010147511959075928
step: 240, loss: 0.034893643110990524
step: 250, loss: 0.1499987244606018
step: 260, loss: 0.01635212078690529
step: 270, loss: 0.13830912113189697
step: 280, loss: 0.12738046050071716
step: 290, loss: 0.046591855585575104
step: 300, loss: 0.25747641921043396
step: 310, loss: 0.21628014743328094
step: 320, loss: 0.24905070662498474
step: 330, loss: 0.18480396270751953
step: 340, loss: 0.08455000817775726
step: 350, loss: 0.05974078178405762
step: 360, loss: 0.06993293017148972
step: 370, loss: 0.02204386703670025
step: 380, loss: 0.02563919499516487
step: 390, loss: 0.0652189776301384
step: 400, loss: 0.06133051589131355
step: 410, loss: 0.07998302578926086
step: 420, loss: 0.024729682132601738
epoch 5: dev_f1=0.9854096520763187, f1=0.9787234042553192, best_f1=0.9830124575311437
step: 0, loss: 0.09320243448019028
step: 10, loss: 0.1028624027967453
step: 20, loss: 0.055807434022426605
step: 30, loss: 0.058024030178785324
step: 40, loss: 0.21866978704929352
step: 50, loss: 0.04372024163603783
step: 60, loss: 0.17463582754135132
step: 70, loss: 0.06115315109491348
step: 80, loss: 0.048793498426675797
step: 90, loss: 0.12568850815296173
step: 100, loss: 0.06000290811061859
step: 110, loss: 0.014840872958302498
step: 120, loss: 0.14975206553936005
step: 130, loss: 0.12317085266113281
step: 140, loss: 0.08674397319555283
step: 150, loss: 0.06661144644021988
step: 160, loss: 0.1215890571475029
step: 170, loss: 0.09995974600315094
step: 180, loss: 0.023144502192735672
step: 190, loss: 0.028131956234574318
step: 200, loss: 0.01978977397084236
step: 210, loss: 0.17515501379966736
step: 220, loss: 0.04452984780073166
step: 230, loss: 0.1934269219636917
step: 240, loss: 0.14970439672470093
step: 250, loss: 0.06475133448839188
step: 260, loss: 0.0087432274594903
step: 270, loss: 0.10112536698579788
step: 280, loss: 0.03574506565928459
step: 290, loss: 0.10771206766366959
step: 300, loss: 0.19599038362503052
step: 310, loss: 0.06837915629148483
step: 320, loss: 0.06622058153152466
step: 330, loss: 0.043485380709171295
step: 340, loss: 0.04600642994046211
step: 350, loss: 0.07829668372869492
step: 360, loss: 0.0698154866695404
step: 370, loss: 0.1177133247256279
step: 380, loss: 0.20726878941059113
step: 390, loss: 0.11245984584093094
step: 400, loss: 0.09954305738210678
step: 410, loss: 0.03648737818002701
step: 420, loss: 0.07773488759994507
epoch 6: dev_f1=0.9899216125419933, f1=0.9810055865921787, best_f1=0.9810055865921787
step: 0, loss: 0.06194637715816498
step: 10, loss: 0.059604234993457794
step: 20, loss: 0.06818430125713348
step: 30, loss: 0.07592073827981949
step: 40, loss: 0.04252010956406593
step: 50, loss: 0.03836861997842789
step: 60, loss: 0.07666829973459244
step: 70, loss: 0.01985369436442852
step: 80, loss: 0.009258448146283627
step: 90, loss: 0.02140803635120392
step: 100, loss: 0.169674351811409
step: 110, loss: 0.1060674786567688
step: 120, loss: 0.2642316222190857
step: 130, loss: 0.08188333362340927
step: 140, loss: 0.03690604493021965
step: 150, loss: 0.02217690274119377
step: 160, loss: 0.04445350170135498
step: 170, loss: 0.016823578625917435
step: 180, loss: 0.03635265305638313
step: 190, loss: 0.11830592155456543
step: 200, loss: 0.05231248587369919
step: 210, loss: 0.12488067150115967
step: 220, loss: 0.09640517830848694
step: 230, loss: 0.17653438448905945
step: 240, loss: 0.055787622928619385
step: 250, loss: 0.16856396198272705
step: 260, loss: 0.028614168986678123
step: 270, loss: 0.013724079355597496
step: 280, loss: 0.13856664299964905
step: 290, loss: 0.03483426570892334
step: 300, loss: 0.07150943577289581
step: 310, loss: 0.06838991492986679
step: 320, loss: 0.0218379944562912
step: 330, loss: 0.08911208063364029
step: 340, loss: 0.12203264236450195
step: 350, loss: 0.05879022553563118
step: 360, loss: 0.04660138487815857
step: 370, loss: 0.09689800441265106
step: 380, loss: 0.028531022369861603
step: 390, loss: 0.06792735308408737
step: 400, loss: 0.17228558659553528
step: 410, loss: 0.0768294632434845
step: 420, loss: 0.019779743626713753
epoch 7: dev_f1=0.9876265466816648, f1=0.9774266365688488, best_f1=0.9810055865921787
step: 0, loss: 0.01691388338804245
step: 10, loss: 0.05335721746087074
step: 20, loss: 0.09734997153282166
step: 30, loss: 0.06640125811100006
step: 40, loss: 0.19478267431259155
step: 50, loss: 0.09217290580272675
step: 60, loss: 0.022647444158792496
step: 70, loss: 0.07626674324274063
step: 80, loss: 0.03762197867035866
step: 90, loss: 0.1503455936908722
step: 100, loss: 0.08239664882421494
step: 110, loss: 0.0629618838429451
step: 120, loss: 0.003308388404548168
step: 130, loss: 0.02248918078839779
step: 140, loss: 0.04077095910906792
step: 150, loss: 0.08187349885702133
step: 160, loss: 0.0910751074552536
step: 170, loss: 0.038956962525844574
step: 180, loss: 0.1406703144311905
step: 190, loss: 0.06218333542346954
step: 200, loss: 0.00837157666683197
step: 210, loss: 0.06654244661331177
step: 220, loss: 0.0723387598991394
step: 230, loss: 0.16977855563163757
step: 240, loss: 0.08636412769556046
step: 250, loss: 0.009400773793458939
step: 260, loss: 0.18833975493907928
step: 270, loss: 0.07516799867153168
step: 280, loss: 0.08545123785734177
step: 290, loss: 0.06367215514183044
step: 300, loss: 0.06190626695752144
step: 310, loss: 0.14940765500068665
step: 320, loss: 0.027496222406625748
step: 330, loss: 0.06986323744058609
step: 340, loss: 0.15056666731834412
step: 350, loss: 0.058383647352457047
step: 360, loss: 0.1273590475320816
step: 370, loss: 0.0398789681494236
step: 380, loss: 0.013813551515340805
step: 390, loss: 0.11520394682884216
step: 400, loss: 0.08828327804803848
step: 410, loss: 0.03499044477939606
step: 420, loss: 0.005804761312901974
epoch 8: dev_f1=0.9909502262443439, f1=0.9829738933030647, best_f1=0.9829738933030647
step: 0, loss: 0.016107000410556793
step: 10, loss: 0.03716294467449188
step: 20, loss: 0.055076662451028824
step: 30, loss: 0.13059672713279724
step: 40, loss: 0.021303264424204826
step: 50, loss: 0.03550726920366287
step: 60, loss: 0.13129715621471405
step: 70, loss: 0.024085067212581635
step: 80, loss: 0.10553563386201859
step: 90, loss: 0.030375417321920395
step: 100, loss: 0.1380823701620102
step: 110, loss: 0.037716254591941833
step: 120, loss: 0.09649881720542908
step: 130, loss: 0.055753499269485474
step: 140, loss: 0.0021710461005568504
step: 150, loss: 0.11263831704854965
step: 160, loss: 0.13157814741134644
step: 170, loss: 0.07448697090148926
step: 180, loss: 0.05101754888892174
step: 190, loss: 0.0974295511841774
step: 200, loss: 0.09388335049152374
step: 210, loss: 0.09007615596055984
step: 220, loss: 0.06020848825573921
step: 230, loss: 0.02681572176516056
step: 240, loss: 0.08874574303627014
step: 250, loss: 0.07248761504888535
step: 260, loss: 0.06512368470430374
step: 270, loss: 0.07762394845485687
step: 280, loss: 0.14154453575611115
step: 290, loss: 0.039873842149972916
step: 300, loss: 0.05841691792011261
step: 310, loss: 0.056897688657045364
step: 320, loss: 0.06016271933913231
step: 330, loss: 0.08874636888504028
step: 340, loss: 0.03951239585876465
step: 350, loss: 0.014167094603180885
step: 360, loss: 0.014473257586359978
step: 370, loss: 0.08785394579172134
step: 380, loss: 0.0406961552798748
step: 390, loss: 0.07431171089410782
step: 400, loss: 0.10595787316560745
step: 410, loss: 0.006890006363391876
step: 420, loss: 0.10884782671928406
epoch 9: dev_f1=0.9854748603351955, f1=0.9752252252252253, best_f1=0.9829738933030647
step: 0, loss: 0.08341823518276215
step: 10, loss: 0.0192854106426239
step: 20, loss: 0.1970023363828659
step: 30, loss: 0.01744651049375534
step: 40, loss: 0.03861917182803154
step: 50, loss: 0.018011895939707756
step: 60, loss: 0.06071003898978233
step: 70, loss: 0.03195428103208542
step: 80, loss: 0.030242007225751877
step: 90, loss: 0.061259061098098755
step: 100, loss: 0.11554712802171707
step: 110, loss: 0.12797938287258148
step: 120, loss: 0.043720949441194534
step: 130, loss: 0.2158549576997757
step: 140, loss: 0.106297567486763
step: 150, loss: 0.0756479799747467
step: 160, loss: 0.11971453577280045
step: 170, loss: 0.025195982307195663
step: 180, loss: 0.08822779357433319
step: 190, loss: 0.05276891589164734
step: 200, loss: 0.09425182640552521
step: 210, loss: 0.011803559958934784
step: 220, loss: 0.012088972143828869
step: 230, loss: 0.014293935149908066
step: 240, loss: 0.04702165350317955
step: 250, loss: 0.07420842349529266
step: 260, loss: 0.13234464824199677
step: 270, loss: 0.03406772390007973
step: 280, loss: 0.07727444916963577
step: 290, loss: 0.09475278109312057
step: 300, loss: 0.07395985722541809
step: 310, loss: 0.05858992040157318
step: 320, loss: 0.06291210651397705
step: 330, loss: 0.2204514443874359
step: 340, loss: 0.028421156108379364
step: 350, loss: 0.09645961225032806
step: 360, loss: 0.09360436350107193
step: 370, loss: 0.07741159945726395
step: 380, loss: 0.06135709583759308
step: 390, loss: 0.05362486094236374
step: 400, loss: 0.052465248852968216
step: 410, loss: 0.11470622569322586
step: 420, loss: 0.12139691412448883
epoch 10: dev_f1=0.9887640449438202, f1=0.9785794813979707, best_f1=0.9829738933030647
step: 0, loss: 0.11633908003568649
step: 10, loss: 0.042030561715364456
step: 20, loss: 0.06964650750160217
step: 30, loss: 0.047498881816864014
step: 40, loss: 0.026369886472821236
step: 50, loss: 0.023682674393057823
step: 60, loss: 0.10503870993852615
step: 70, loss: 0.037700969725847244
step: 80, loss: 0.06715380400419235
step: 90, loss: 0.057697467505931854
step: 100, loss: 0.011387198232114315
step: 110, loss: 0.03207336738705635
step: 120, loss: 0.016811447218060493
step: 130, loss: 0.029525961726903915
step: 140, loss: 0.05595344305038452
step: 150, loss: 0.006293974816799164
step: 160, loss: 0.04016466811299324
step: 170, loss: 0.06970876455307007
step: 180, loss: 0.06560615450143814
step: 190, loss: 0.018079597502946854
step: 200, loss: 0.08790488541126251
step: 210, loss: 0.02457864210009575
step: 220, loss: 0.011181306093931198
step: 230, loss: 0.07471735030412674
step: 240, loss: 0.20293080806732178
step: 250, loss: 0.14344757795333862
step: 260, loss: 0.16148094832897186
step: 270, loss: 0.00863507017493248
step: 280, loss: 0.07853668183088303
step: 290, loss: 0.014464469626545906
step: 300, loss: 0.006718890741467476
step: 310, loss: 0.02813168242573738
step: 320, loss: 0.037204496562480927
step: 330, loss: 0.02805662527680397
step: 340, loss: 0.03757850453257561
step: 350, loss: 0.02143722027540207
step: 360, loss: 0.0019889390096068382
step: 370, loss: 0.11616262793540955
step: 380, loss: 0.020817426964640617
step: 390, loss: 0.006541184615343809
step: 400, loss: 0.01692676916718483
step: 410, loss: 0.08397874981164932
step: 420, loss: 0.047546613961458206
epoch 11: dev_f1=0.9853768278965129, f1=0.9740112994350283, best_f1=0.9829738933030647
step: 0, loss: 0.06067638471722603
step: 10, loss: 0.044165901839733124
step: 20, loss: 0.11114270985126495
step: 30, loss: 0.009604832157492638
step: 40, loss: 0.03412380814552307
step: 50, loss: 0.033969711512327194
step: 60, loss: 0.07497157156467438
step: 70, loss: 0.036778904497623444
step: 80, loss: 0.04798947274684906
step: 90, loss: 0.02911107800900936
step: 100, loss: 0.03566136583685875
step: 110, loss: 0.15679249167442322
step: 120, loss: 0.04944654181599617
step: 130, loss: 0.09609146416187286
step: 140, loss: 0.0554412342607975
step: 150, loss: 0.05029068887233734
step: 160, loss: 0.040119774639606476
step: 170, loss: 0.023503869771957397
step: 180, loss: 0.055254727602005005
step: 190, loss: 0.05861098691821098
step: 200, loss: 0.002747163875028491
step: 210, loss: 0.06868406385183334
step: 220, loss: 0.018832150846719742
step: 230, loss: 0.13926959037780762
step: 240, loss: 0.06363048404455185
step: 250, loss: 0.02660691924393177
step: 260, loss: 0.05117438733577728
step: 270, loss: 0.01132823433727026
step: 280, loss: 0.10746286809444427
step: 290, loss: 0.0221412293612957
step: 300, loss: 0.03996320441365242
step: 310, loss: 0.0756022036075592
step: 320, loss: 0.02899095229804516
step: 330, loss: 0.15141849219799042
step: 340, loss: 0.0498538576066494
step: 350, loss: 0.0870010033249855
step: 360, loss: 0.026841942220926285
step: 370, loss: 0.08937380462884903
step: 380, loss: 0.03456076234579086
step: 390, loss: 0.1795276701450348
step: 400, loss: 0.12315113842487335
step: 410, loss: 0.030153149738907814
step: 420, loss: 0.12249788641929626
epoch 12: dev_f1=0.9910514541387023, f1=0.9810055865921787, best_f1=0.9810055865921787
step: 0, loss: 0.026383958756923676
step: 10, loss: 0.13526485860347748
step: 20, loss: 0.030514560639858246
step: 30, loss: 0.021280735731124878
step: 40, loss: 0.01671241596341133
step: 50, loss: 0.05377328395843506
step: 60, loss: 0.002001560991629958
step: 70, loss: 0.07162196189165115
step: 80, loss: 0.032707616686820984
step: 90, loss: 0.014663713052868843
step: 100, loss: 0.02580701746046543
step: 110, loss: 0.05730981007218361
step: 120, loss: 0.0046659111976623535
step: 130, loss: 0.005249689798802137
step: 140, loss: 0.02426689863204956
step: 150, loss: 0.005530752241611481
step: 160, loss: 0.0810573399066925
step: 170, loss: 0.10406866669654846
step: 180, loss: 0.017216837033629417
step: 190, loss: 0.14573898911476135
step: 200, loss: 0.07038620859384537
step: 210, loss: 0.09633587300777435
step: 220, loss: 0.07310166954994202
step: 230, loss: 0.08229570835828781
step: 240, loss: 0.0759458988904953
step: 250, loss: 0.01635761372745037
step: 260, loss: 0.06551854312419891
step: 270, loss: 0.008602339774370193
step: 280, loss: 0.043621886521577835
step: 290, loss: 0.07947394251823425
step: 300, loss: 0.010766340419650078
step: 310, loss: 0.1256037801504135
step: 320, loss: 0.010567592456936836
step: 330, loss: 0.057945847511291504
step: 340, loss: 0.06162571907043457
step: 350, loss: 4.52206440968439e-05
step: 360, loss: 0.005869923625141382
step: 370, loss: 0.03674262389540672
step: 380, loss: 0.02144952490925789
step: 390, loss: 0.1899539977312088
step: 400, loss: 0.08203825354576111
step: 410, loss: 0.03526046872138977
step: 420, loss: 0.06612562388181686
epoch 13: dev_f1=0.9898305084745763, f1=0.9797297297297298, best_f1=0.9810055865921787
step: 0, loss: 0.024121390655636787
step: 10, loss: 0.047295473515987396
step: 20, loss: 0.029329409822821617
step: 30, loss: 0.023706188425421715
step: 40, loss: 0.05405643954873085
step: 50, loss: 0.0160161592066288
step: 60, loss: 0.06953532248735428
step: 70, loss: 0.08358587324619293
step: 80, loss: 0.014532291330397129
step: 90, loss: 0.012941550463438034
step: 100, loss: 0.08541322499513626
step: 110, loss: 0.05693890154361725
step: 120, loss: 2.2867872758070007e-05
step: 130, loss: 0.029397599399089813
step: 140, loss: 0.026480337604880333
step: 150, loss: 0.0800294578075409
step: 160, loss: 0.012162750586867332
step: 170, loss: 0.022284530103206635
step: 180, loss: 0.0097236018627882
step: 190, loss: 0.09621507674455643
step: 200, loss: 0.09664363414049149
step: 210, loss: 0.06724236160516739
step: 220, loss: 0.04991655796766281
step: 230, loss: 0.10222496837377548
step: 240, loss: 0.0727318748831749
step: 250, loss: 0.004918972961604595
step: 260, loss: 0.012333211489021778
step: 270, loss: 0.062201790511608124
step: 280, loss: 0.05286272615194321
step: 290, loss: 0.017871305346488953
step: 300, loss: 0.06196915730834007
step: 310, loss: 0.09726980328559875
step: 320, loss: 0.017447181046009064
step: 330, loss: 0.01299842819571495
step: 340, loss: 0.0211001206189394
step: 350, loss: 0.05426819249987602
step: 360, loss: 0.0334596261382103
step: 370, loss: 0.06870362162590027
step: 380, loss: 0.0740528479218483
step: 390, loss: 0.09384190291166306
step: 400, loss: 0.08355802297592163
step: 410, loss: 0.062170397490262985
step: 420, loss: 0.02526232786476612
epoch 14: dev_f1=0.9875424688561721, f1=0.9784824462061155, best_f1=0.9810055865921787
step: 0, loss: 0.0828549712896347
step: 10, loss: 0.04874444007873535
step: 20, loss: 0.03213466331362724
step: 30, loss: 0.03719564527273178
step: 40, loss: 0.059456318616867065
step: 50, loss: 3.597365503082983e-05
step: 60, loss: 0.041436996310949326
step: 70, loss: 0.020282568410038948
step: 80, loss: 0.04627865180373192
step: 90, loss: 0.058060646057128906
step: 100, loss: 0.08949755132198334
step: 110, loss: 0.03471662476658821
step: 120, loss: 0.021960264071822166
step: 130, loss: 0.024655912071466446
step: 140, loss: 0.042010050266981125
step: 150, loss: 0.008966120891273022
step: 160, loss: 0.11552172154188156
step: 170, loss: 0.07408486306667328
step: 180, loss: 0.044087257236242294
step: 190, loss: 0.047457996755838394
step: 200, loss: 0.03424905613064766
step: 210, loss: 0.023535534739494324
step: 220, loss: 0.02994680218398571
step: 230, loss: 0.002191149163991213
step: 240, loss: 0.00014882969844620675
step: 250, loss: 0.05613387003540993
step: 260, loss: 0.08692775666713715
step: 270, loss: 0.056952834129333496
step: 280, loss: 0.02338465489447117
step: 290, loss: 0.10968071222305298
step: 300, loss: 0.11242957413196564
step: 310, loss: 0.0539725199341774
step: 320, loss: 0.17491650581359863
step: 330, loss: 0.04291726276278496
step: 340, loss: 0.055728450417518616
step: 350, loss: 0.018902767449617386
step: 360, loss: 0.032338861376047134
step: 370, loss: 0.02206050232052803
step: 380, loss: 0.02880053222179413
step: 390, loss: 0.0637456551194191
step: 400, loss: 0.08620825409889221
step: 410, loss: 0.031446605920791626
step: 420, loss: 0.03879813477396965
epoch 15: dev_f1=0.987598647125141, f1=0.9809203142536477, best_f1=0.9810055865921787
step: 0, loss: 0.07529613375663757
step: 10, loss: 0.002918990794569254
step: 20, loss: 0.026164840906858444
step: 30, loss: 0.02327573299407959
step: 40, loss: 0.05973439663648605
step: 50, loss: 0.017498351633548737
step: 60, loss: 0.0025469004176557064
step: 70, loss: 0.02794012986123562
step: 80, loss: 0.015176990069448948
step: 90, loss: 0.02938392385840416
step: 100, loss: 0.023391855880618095
step: 110, loss: 0.07293428480625153
step: 120, loss: 0.20147718489170074
step: 130, loss: 0.012226860970258713
step: 140, loss: 0.01712288148701191
step: 150, loss: 0.0022917240858078003
step: 160, loss: 0.02640102431178093
step: 170, loss: 0.037519484758377075
step: 180, loss: 0.0808381512761116
step: 190, loss: 0.03938387334346771
step: 200, loss: 0.060908082872629166
step: 210, loss: 0.09334918856620789
step: 220, loss: 0.04864468425512314
step: 230, loss: 0.09787297248840332
step: 240, loss: 0.04181406646966934
step: 250, loss: 0.14820371568202972
step: 260, loss: 0.032094623893499374
step: 270, loss: 0.03014097549021244
step: 280, loss: 0.059711869806051254
step: 290, loss: 0.04812785983085632
step: 300, loss: 0.0609029121696949
step: 310, loss: 0.09607403725385666
step: 320, loss: 0.017192332074046135
step: 330, loss: 0.02055029757320881
step: 340, loss: 0.017513005062937737
step: 350, loss: 0.08601442724466324
step: 360, loss: 0.04364622011780739
step: 370, loss: 0.037028323858976364
step: 380, loss: 0.03404422849416733
step: 390, loss: 0.02386787161231041
step: 400, loss: 0.021083420142531395
step: 410, loss: 0.028958354145288467
step: 420, loss: 0.0001465714885853231
epoch 16: dev_f1=0.9863945578231292, f1=0.9785794813979707, best_f1=0.9810055865921787
step: 0, loss: 0.09359277784824371
step: 10, loss: 0.010393111035227776
step: 20, loss: 0.02165730483829975
step: 30, loss: 0.0015369713073596358
step: 40, loss: 0.08997876942157745
step: 50, loss: 0.04882458969950676
step: 60, loss: 0.05847381055355072
step: 70, loss: 0.02700200118124485
step: 80, loss: 0.03395824879407883
step: 90, loss: 0.023099025711417198
step: 100, loss: 0.050308164209127426
step: 110, loss: 0.03867582976818085
step: 120, loss: 0.06271415203809738
step: 130, loss: 0.009808246046304703
step: 140, loss: 0.01976344920694828
step: 150, loss: 0.050454605370759964
step: 160, loss: 0.044547662138938904
step: 170, loss: 0.0006741350516676903
step: 180, loss: 0.06907177716493607
step: 190, loss: 0.04744923114776611
step: 200, loss: 0.022874237969517708
step: 210, loss: 0.24399839341640472
step: 220, loss: 0.0635911375284195
step: 230, loss: 0.0790591612458229
step: 240, loss: 0.027293846011161804
step: 250, loss: 0.038738913834095
step: 260, loss: 0.016718190163373947
step: 270, loss: 0.04065537452697754
step: 280, loss: 0.045435305684804916
step: 290, loss: 0.0520239993929863
step: 300, loss: 0.08113231509923935
step: 310, loss: 0.035921502858400345
step: 320, loss: 0.012208926491439342
step: 330, loss: 0.050487566739320755
step: 340, loss: 0.08926098048686981
step: 350, loss: 0.031416554003953934
step: 360, loss: 0.000938938872423023
step: 370, loss: 0.051956892013549805
step: 380, loss: 0.0564248189330101
step: 390, loss: 0.00030475013772957027
step: 400, loss: 0.009854652918875217
step: 410, loss: 0.09209103882312775
step: 420, loss: 0.031369682401418686
epoch 17: dev_f1=0.9899441340782122, f1=0.9799107142857142, best_f1=0.9810055865921787
step: 0, loss: 0.08361538499593735
step: 10, loss: 0.06748057156801224
step: 20, loss: 0.027163054794073105
step: 30, loss: 0.044405993074178696
step: 40, loss: 0.044945117086172104
step: 50, loss: 0.07309038937091827
step: 60, loss: 0.06327623873949051
step: 70, loss: 0.09936078637838364
step: 80, loss: 0.0725482627749443
step: 90, loss: 0.05924341082572937
step: 100, loss: 0.021056029945611954
step: 110, loss: 0.06887322664260864
step: 120, loss: 0.0349934920668602
step: 130, loss: 0.023248659446835518
step: 140, loss: 0.027129458263516426
step: 150, loss: 0.00010917432518908754
step: 160, loss: 0.0005340579664334655
step: 170, loss: 0.07672198116779327
step: 180, loss: 0.014666237868368626
step: 190, loss: 0.01685904525220394
step: 200, loss: 0.05145096778869629
step: 210, loss: 0.08555683493614197
step: 220, loss: 0.05120966583490372
step: 230, loss: 0.04062623530626297
step: 240, loss: 0.09766808152198792
step: 250, loss: 0.02980753406882286
step: 260, loss: 0.006162760313600302
step: 270, loss: 0.09134909510612488
step: 280, loss: 0.1619083434343338
step: 290, loss: 0.00011537160025909543
step: 300, loss: 0.015908440575003624
step: 310, loss: 0.004048204980790615
step: 320, loss: 0.04983169212937355
step: 330, loss: 0.00020792169380001724
step: 340, loss: 0.034224312752485275
step: 350, loss: 0.04033288359642029
step: 360, loss: 0.029357003048062325
step: 370, loss: 0.023206640034914017
step: 380, loss: 0.09433063119649887
step: 390, loss: 0.011237903498113155
step: 400, loss: 0.015198810026049614
step: 410, loss: 0.04544970020651817
step: 420, loss: 2.1572053810814396e-05
epoch 18: dev_f1=0.9864559819413092, f1=0.9797297297297298, best_f1=0.9810055865921787
step: 0, loss: 0.061330292373895645
step: 10, loss: 8.80626030266285e-05
step: 20, loss: 0.04767452925443649
step: 30, loss: 0.01954299956560135
step: 40, loss: 0.03656112775206566
step: 50, loss: 0.008303100243210793
step: 60, loss: 0.0203532874584198
step: 70, loss: 0.052927788347005844
step: 80, loss: 0.0018368816236034036
step: 90, loss: 0.0007048174738883972
step: 100, loss: 0.0011231499956920743
step: 110, loss: 0.07934336364269257
step: 120, loss: 4.280843859305605e-05
step: 130, loss: 0.0005437540239654481
step: 140, loss: 0.08411051332950592
step: 150, loss: 0.044569648802280426
step: 160, loss: 0.1253863424062729
step: 170, loss: 0.033389683812856674
step: 180, loss: 0.007153062149882317
step: 190, loss: 0.09524042904376984
step: 200, loss: 0.04696128889918327
step: 210, loss: 0.029262585565447807
step: 220, loss: 0.10803908109664917
step: 230, loss: 0.06465718895196915
step: 240, loss: 0.09559126198291779
step: 250, loss: 0.05230201780796051
step: 260, loss: 0.021283261477947235
step: 270, loss: 0.09089763462543488
step: 280, loss: 0.053327810019254684
step: 290, loss: 0.07568427920341492
step: 300, loss: 0.04208569601178169
step: 310, loss: 0.07331910729408264
step: 320, loss: 0.00010237863170914352
step: 330, loss: 0.04242176562547684
step: 340, loss: 0.06656701117753983
step: 350, loss: 0.05442369729280472
step: 360, loss: 0.09201596677303314
step: 370, loss: 0.023378737270832062
step: 380, loss: 0.05892317742109299
step: 390, loss: 0.01200424786657095
step: 400, loss: 0.035602323710918427
step: 410, loss: 0.029372604563832283
step: 420, loss: 0.02681584842503071
epoch 19: dev_f1=0.9887387387387387, f1=0.9798206278026906, best_f1=0.9810055865921787
step: 0, loss: 0.07163096964359283
step: 10, loss: 0.02337687276303768
step: 20, loss: 0.05566985532641411
step: 30, loss: 0.06108534336090088
step: 40, loss: 0.029189182445406914
step: 50, loss: 0.00465815607458353
step: 60, loss: 0.0004903424996882677
step: 70, loss: 0.07803865522146225
step: 80, loss: 0.07477933913469315
step: 90, loss: 0.06863212585449219
step: 100, loss: 0.021179966628551483
step: 110, loss: 0.044037461280822754
step: 120, loss: 0.004338313825428486
step: 130, loss: 0.014391561970114708
step: 140, loss: 0.034012217074632645
step: 150, loss: 0.029931744560599327
step: 160, loss: 0.019007837399840355
step: 170, loss: 0.02979266829788685
step: 180, loss: 0.05813809111714363
step: 190, loss: 0.019803360104560852
step: 200, loss: 0.029640141874551773
step: 210, loss: 0.041538868099451065
step: 220, loss: 0.07665873318910599
step: 230, loss: 0.02539457194507122
step: 240, loss: 0.06636960804462433
step: 250, loss: 0.07628249377012253
step: 260, loss: 0.04475156590342522
step: 270, loss: 0.10973738878965378
step: 280, loss: 0.02800847217440605
step: 290, loss: 0.1064288467168808
step: 300, loss: 0.010676423087716103
step: 310, loss: 0.04351373016834259
step: 320, loss: 0.04369908571243286
step: 330, loss: 0.07552884519100189
step: 340, loss: 0.012089680880308151
step: 350, loss: 0.034607212990522385
step: 360, loss: 0.07333391159772873
step: 370, loss: 0.10118085891008377
step: 380, loss: 0.019790641963481903
step: 390, loss: 0.021140843629837036
step: 400, loss: 0.03830202668905258
step: 410, loss: 0.024486970156431198
step: 420, loss: 0.04304353520274162
epoch 20: dev_f1=0.987598647125141, f1=0.9797752808988766, best_f1=0.9810055865921787
