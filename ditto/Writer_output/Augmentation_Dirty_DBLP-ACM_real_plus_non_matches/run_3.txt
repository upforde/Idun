cuda
Device: cuda
step: 0, loss: 0.6755567789077759
step: 10, loss: 0.23205089569091797
step: 20, loss: 0.2167196422815323
step: 30, loss: 0.44177675247192383
step: 40, loss: 0.15514163672924042
step: 50, loss: 0.3358555734157562
step: 60, loss: 0.19645173847675323
step: 70, loss: 0.2231544554233551
step: 80, loss: 0.1102227047085762
step: 90, loss: 0.06716769933700562
step: 100, loss: 0.10618003457784653
step: 110, loss: 0.1298983246088028
step: 120, loss: 0.17774854600429535
step: 130, loss: 0.1252172887325287
step: 140, loss: 0.10062672197818756
step: 150, loss: 0.14839255809783936
step: 160, loss: 0.10679835826158524
step: 170, loss: 0.1490141600370407
step: 180, loss: 0.08589994162321091
step: 190, loss: 0.2019720822572708
step: 200, loss: 0.10430281609296799
step: 210, loss: 0.022174568846821785
step: 220, loss: 0.11096517741680145
step: 230, loss: 0.05767274275422096
step: 240, loss: 0.12569820880889893
step: 250, loss: 0.11496345698833466
step: 260, loss: 0.14150454103946686
step: 270, loss: 0.06780935078859329
step: 280, loss: 0.10775800049304962
step: 290, loss: 0.04125680401921272
step: 300, loss: 0.06150604411959648
step: 310, loss: 0.21494412422180176
step: 320, loss: 0.1799830198287964
step: 330, loss: 0.12653669714927673
step: 340, loss: 0.2307668924331665
step: 350, loss: 0.10228585451841354
step: 360, loss: 0.08046556264162064
step: 370, loss: 0.05023377388715744
step: 380, loss: 0.12515053153038025
step: 390, loss: 0.2161739021539688
step: 400, loss: 0.20338213443756104
step: 410, loss: 0.02220565639436245
step: 420, loss: 0.1112145408987999
epoch 1: dev_f1=0.9808342728297633, f1=0.9729119638826186, best_f1=0.9729119638826186
step: 0, loss: 0.25922712683677673
step: 10, loss: 0.12240306288003922
step: 20, loss: 0.09129785001277924
step: 30, loss: 0.055679984390735626
step: 40, loss: 0.1575930267572403
step: 50, loss: 0.17820419371128082
step: 60, loss: 0.12264490872621536
step: 70, loss: 0.04412832111120224
step: 80, loss: 0.16728715598583221
step: 90, loss: 0.17819130420684814
step: 100, loss: 0.10399807244539261
step: 110, loss: 0.06412914395332336
step: 120, loss: 0.06205790489912033
step: 130, loss: 0.20043089985847473
step: 140, loss: 0.0960979163646698
step: 150, loss: 0.012105445377528667
step: 160, loss: 0.1144692525267601
step: 170, loss: 0.07173473387956619
step: 180, loss: 0.23522710800170898
step: 190, loss: 0.10772272944450378
step: 200, loss: 0.09608417749404907
step: 210, loss: 0.076930932700634
step: 220, loss: 0.003417998319491744
step: 230, loss: 0.19089579582214355
step: 240, loss: 0.10230313986539841
step: 250, loss: 0.1801474541425705
step: 260, loss: 0.05648243799805641
step: 270, loss: 0.1006615161895752
step: 280, loss: 0.05133054405450821
step: 290, loss: 0.06423728168010712
step: 300, loss: 0.09015651792287827
step: 310, loss: 0.23557719588279724
step: 320, loss: 0.13932855427265167
step: 330, loss: 0.12936748564243317
step: 340, loss: 0.12234219163656235
step: 350, loss: 0.0407162643969059
step: 360, loss: 0.04003682732582092
step: 370, loss: 0.1677851378917694
step: 380, loss: 0.058875203132629395
step: 390, loss: 0.03188864141702652
step: 400, loss: 0.1640469878911972
step: 410, loss: 0.06518825888633728
step: 420, loss: 0.1409604847431183
epoch 2: dev_f1=0.9886877828054299, f1=0.9786276715410572, best_f1=0.9786276715410572
step: 0, loss: 0.12163518369197845
step: 10, loss: 0.062431156635284424
step: 20, loss: 0.07667948305606842
step: 30, loss: 0.0522947683930397
step: 40, loss: 0.07483930140733719
step: 50, loss: 0.06720250099897385
step: 60, loss: 0.03545738011598587
step: 70, loss: 0.14443473517894745
step: 80, loss: 0.1776989847421646
step: 90, loss: 0.17455768585205078
step: 100, loss: 0.10237716883420944
step: 110, loss: 0.11382877081632614
step: 120, loss: 0.012249816209077835
step: 130, loss: 0.2673550546169281
step: 140, loss: 0.028465408831834793
step: 150, loss: 0.019953250885009766
step: 160, loss: 0.07220882177352905
step: 170, loss: 0.09319589287042618
step: 180, loss: 0.043216101825237274
step: 190, loss: 0.20074711740016937
step: 200, loss: 0.10994942486286163
step: 210, loss: 0.07802735269069672
step: 220, loss: 0.04116024821996689
step: 230, loss: 0.07057147473096848
step: 240, loss: 0.1042301282286644
step: 250, loss: 0.10667067766189575
step: 260, loss: 0.01303969044238329
step: 270, loss: 0.05703162029385567
step: 280, loss: 0.27237680554389954
step: 290, loss: 0.06901190429925919
step: 300, loss: 0.14375440776348114
step: 310, loss: 0.15842758119106293
step: 320, loss: 0.03984018415212631
step: 330, loss: 0.049599722027778625
step: 340, loss: 0.07515209168195724
step: 350, loss: 0.08212346583604813
step: 360, loss: 0.06392354518175125
step: 370, loss: 0.1345684826374054
step: 380, loss: 0.07345091551542282
step: 390, loss: 0.06169090420007706
step: 400, loss: 0.02067127823829651
step: 410, loss: 0.02431931346654892
step: 420, loss: 0.08370164036750793
epoch 3: dev_f1=0.9842696629213483, f1=0.9727891156462585, best_f1=0.9786276715410572
step: 0, loss: 0.04047401621937752
step: 10, loss: 0.05882395803928375
step: 20, loss: 0.06943486630916595
step: 30, loss: 0.06643875688314438
step: 40, loss: 0.07148177921772003
step: 50, loss: 0.059364188462495804
step: 60, loss: 0.2654229402542114
step: 70, loss: 0.06159769371151924
step: 80, loss: 0.13393253087997437
step: 90, loss: 0.10310886055231094
step: 100, loss: 0.0444938950240612
step: 110, loss: 0.02059991843998432
step: 120, loss: 0.05950937047600746
step: 130, loss: 0.12099481374025345
step: 140, loss: 0.17948807775974274
step: 150, loss: 0.15752136707305908
step: 160, loss: 0.049497731029987335
step: 170, loss: 0.1838589310646057
step: 180, loss: 0.019045259803533554
step: 190, loss: 0.05211041122674942
step: 200, loss: 0.04791447892785072
step: 210, loss: 0.040518149733543396
step: 220, loss: 0.029634933918714523
step: 230, loss: 0.08007201552391052
step: 240, loss: 0.02580973133444786
step: 250, loss: 6.88912405166775e-05
step: 260, loss: 0.022138545289635658
step: 270, loss: 0.2385140061378479
step: 280, loss: 0.058953236788511276
step: 290, loss: 0.06638482213020325
step: 300, loss: 0.027151521295309067
step: 310, loss: 0.029994985088706017
step: 320, loss: 0.06776991486549377
step: 330, loss: 0.1437361240386963
step: 340, loss: 0.10269623249769211
step: 350, loss: 0.14794708788394928
step: 360, loss: 0.18781253695487976
step: 370, loss: 0.10801681876182556
step: 380, loss: 0.051313433796167374
step: 390, loss: 0.04171654209494591
step: 400, loss: 0.1304599940776825
step: 410, loss: 0.049396712332963943
step: 420, loss: 0.028131749480962753
epoch 4: dev_f1=0.9910313901345291, f1=0.9798206278026906, best_f1=0.9798206278026906
step: 0, loss: 0.036007851362228394
step: 10, loss: 0.06882364302873611
step: 20, loss: 0.01026590820401907
step: 30, loss: 0.014203772880136967
step: 40, loss: 0.22947187721729279
step: 50, loss: 0.15942203998565674
step: 60, loss: 0.24805501103401184
step: 70, loss: 0.11720595508813858
step: 80, loss: 0.03923875838518143
step: 90, loss: 0.07801760733127594
step: 100, loss: 0.13217151165008545
step: 110, loss: 0.0832749605178833
step: 120, loss: 0.04042189195752144
step: 130, loss: 0.07026999443769455
step: 140, loss: 0.13485607504844666
step: 150, loss: 0.04229126498103142
step: 160, loss: 0.064630426466465
step: 170, loss: 0.09054159373044968
step: 180, loss: 0.037083130329847336
step: 190, loss: 0.06265965104103088
step: 200, loss: 0.08088820427656174
step: 210, loss: 0.047911033034324646
step: 220, loss: 0.14925947785377502
step: 230, loss: 0.11637672036886215
step: 240, loss: 0.03415049985051155
step: 250, loss: 0.10207171738147736
step: 260, loss: 0.03970042243599892
step: 270, loss: 0.08792301267385483
step: 280, loss: 0.1039557233452797
step: 290, loss: 0.01122533529996872
step: 300, loss: 0.08613698184490204
step: 310, loss: 0.15625949203968048
step: 320, loss: 0.0693029835820198
step: 330, loss: 0.02592637576162815
step: 340, loss: 0.09496095031499863
step: 350, loss: 0.15161782503128052
step: 360, loss: 0.07670003175735474
step: 370, loss: 0.09368808567523956
step: 380, loss: 0.08213235437870026
step: 390, loss: 0.0401480533182621
step: 400, loss: 0.08288310468196869
step: 410, loss: 0.02814619243144989
step: 420, loss: 0.04643615707755089
epoch 5: dev_f1=0.9864864864864865, f1=0.9819004524886877, best_f1=0.9798206278026906
step: 0, loss: 0.07792830467224121
step: 10, loss: 0.055560313165187836
step: 20, loss: 0.010522458702325821
step: 30, loss: 0.1297905594110489
step: 40, loss: 0.10841363668441772
step: 50, loss: 0.05463486909866333
step: 60, loss: 0.01523127593100071
step: 70, loss: 0.1611921489238739
step: 80, loss: 0.14215224981307983
step: 90, loss: 0.12198379635810852
step: 100, loss: 0.059267785400152206
step: 110, loss: 0.0951659083366394
step: 120, loss: 0.015355485491454601
step: 130, loss: 0.12606070935726166
step: 140, loss: 0.04411311820149422
step: 150, loss: 0.07905630767345428
step: 160, loss: 0.16286246478557587
step: 170, loss: 0.02137267030775547
step: 180, loss: 0.1298396736383438
step: 190, loss: 0.06842049956321716
step: 200, loss: 0.04041462764143944
step: 210, loss: 0.0746847540140152
step: 220, loss: 0.031887706369161606
step: 230, loss: 0.026493659242987633
step: 240, loss: 0.14061881601810455
step: 250, loss: 0.06976133584976196
step: 260, loss: 0.03738921508193016
step: 270, loss: 0.031772200018167496
step: 280, loss: 0.08274780958890915
step: 290, loss: 0.08263927698135376
step: 300, loss: 0.00017345185915473849
step: 310, loss: 0.10070493817329407
step: 320, loss: 0.05982052534818649
step: 330, loss: 0.13362827897071838
step: 340, loss: 0.053022000938653946
step: 350, loss: 0.13237173855304718
step: 360, loss: 0.11940190196037292
step: 370, loss: 0.0761425644159317
step: 380, loss: 0.08911339938640594
step: 390, loss: 0.050649724900722504
step: 400, loss: 0.0065169790759682655
step: 410, loss: 0.07425887137651443
step: 420, loss: 0.11680152267217636
epoch 6: dev_f1=0.9866071428571428, f1=0.9831649831649831, best_f1=0.9798206278026906
step: 0, loss: 0.15926021337509155
step: 10, loss: 0.0948244258761406
step: 20, loss: 0.019640054553747177
step: 30, loss: 0.04718990623950958
step: 40, loss: 0.08348388969898224
step: 50, loss: 0.0891791582107544
step: 60, loss: 0.0253133624792099
step: 70, loss: 0.004150958266109228
step: 80, loss: 0.15701009333133698
step: 90, loss: 0.022308427840471268
step: 100, loss: 0.05061930790543556
step: 110, loss: 0.054098136723041534
step: 120, loss: 0.12692870199680328
step: 130, loss: 0.08913759142160416
step: 140, loss: 0.06012452021241188
step: 150, loss: 0.13473883271217346
step: 160, loss: 0.02342730015516281
step: 170, loss: 0.06910015642642975
step: 180, loss: 0.027261007577180862
step: 190, loss: 0.06457895785570145
step: 200, loss: 0.18675874173641205
step: 210, loss: 0.07371719926595688
step: 220, loss: 0.006889840122312307
step: 230, loss: 0.07452698051929474
step: 240, loss: 0.06859008222818375
step: 250, loss: 0.11296642571687698
step: 260, loss: 0.0449206605553627
step: 270, loss: 0.06466928869485855
step: 280, loss: 0.1334017813205719
step: 290, loss: 0.07471374422311783
step: 300, loss: 0.2039482593536377
step: 310, loss: 0.1544715166091919
step: 320, loss: 0.3936363756656647
step: 330, loss: 0.10821636021137238
step: 340, loss: 0.08130132406949997
step: 350, loss: 0.036846354603767395
step: 360, loss: 0.03219027444720268
step: 370, loss: 0.0861063003540039
step: 380, loss: 0.17269568145275116
step: 390, loss: 0.0062923370860517025
step: 400, loss: 0.10843665897846222
step: 410, loss: 0.048772744834423065
step: 420, loss: 0.07000857591629028
epoch 7: dev_f1=0.9898074745186863, f1=0.9807037457434733, best_f1=0.9798206278026906
step: 0, loss: 0.049941860139369965
step: 10, loss: 0.05936238914728165
step: 20, loss: 0.09757548570632935
step: 30, loss: 0.020725393667817116
step: 40, loss: 0.07243236899375916
step: 50, loss: 0.12318376451730728
step: 60, loss: 0.08932947367429733
step: 70, loss: 0.08708293735980988
step: 80, loss: 0.051134511828422546
step: 90, loss: 0.03218327835202217
step: 100, loss: 0.11109549552202225
step: 110, loss: 0.06947185099124908
step: 120, loss: 0.14502370357513428
step: 130, loss: 0.05700424686074257
step: 140, loss: 0.09599515050649643
step: 150, loss: 0.026513222604990005
step: 160, loss: 0.06405835598707199
step: 170, loss: 0.1103690043091774
step: 180, loss: 0.1293812096118927
step: 190, loss: 0.049961064010858536
step: 200, loss: 0.08023073524236679
step: 210, loss: 0.05972745269536972
step: 220, loss: 0.029464630410075188
step: 230, loss: 0.061376575380563736
step: 240, loss: 0.04280368611216545
step: 250, loss: 0.06192634254693985
step: 260, loss: 0.11914320290088654
step: 270, loss: 0.038197122514247894
step: 280, loss: 0.05028801038861275
step: 290, loss: 0.14323818683624268
step: 300, loss: 0.07215656340122223
step: 310, loss: 6.707145075779408e-05
step: 320, loss: 0.09537656605243683
step: 330, loss: 0.025735802948474884
step: 340, loss: 0.015089072287082672
step: 350, loss: 0.06515035033226013
step: 360, loss: 0.11557254940271378
step: 370, loss: 0.18254181742668152
step: 380, loss: 0.08104094862937927
step: 390, loss: 0.03380748629570007
step: 400, loss: 0.06453391909599304
step: 410, loss: 0.09159277379512787
step: 420, loss: 0.09837798029184341
epoch 8: dev_f1=0.9910112359550561, f1=0.9787709497206705, best_f1=0.9798206278026906
step: 0, loss: 0.1433117538690567
step: 10, loss: 0.06447909027338028
step: 20, loss: 0.0989624410867691
step: 30, loss: 0.10759305953979492
step: 40, loss: 0.07864146679639816
step: 50, loss: 0.08234775066375732
step: 60, loss: 0.09536426514387131
step: 70, loss: 0.10005973279476166
step: 80, loss: 0.05319172516465187
step: 90, loss: 0.1132221668958664
step: 100, loss: 0.14708997309207916
step: 110, loss: 0.04034746065735817
step: 120, loss: 0.15730053186416626
step: 130, loss: 0.04931327700614929
step: 140, loss: 0.09747777879238129
step: 150, loss: 0.06468881666660309
step: 160, loss: 0.02852093242108822
step: 170, loss: 0.05995820462703705
step: 180, loss: 0.02222961187362671
step: 190, loss: 0.008849536068737507
step: 200, loss: 0.054857417941093445
step: 210, loss: 0.043940287083387375
step: 220, loss: 0.15161250531673431
step: 230, loss: 0.04465559497475624
step: 240, loss: 0.09561741352081299
step: 250, loss: 0.13640211522579193
step: 260, loss: 0.021059833467006683
step: 270, loss: 0.021760182455182076
step: 280, loss: 0.06839779764413834
step: 290, loss: 0.1733153760433197
step: 300, loss: 0.012670631520450115
step: 310, loss: 0.056568313390016556
step: 320, loss: 0.04219149798154831
step: 330, loss: 0.038495857268571854
step: 340, loss: 0.013991076499223709
step: 350, loss: 0.008696884848177433
step: 360, loss: 0.04948081821203232
step: 370, loss: 0.0029050749726593494
step: 380, loss: 0.007459328975528479
step: 390, loss: 0.051320504397153854
step: 400, loss: 0.033425599336624146
step: 410, loss: 0.02585364505648613
step: 420, loss: 0.051912158727645874
epoch 9: dev_f1=0.9887892376681614, f1=0.9743589743589743, best_f1=0.9798206278026906
step: 0, loss: 0.01619044877588749
step: 10, loss: 0.014682683162391186
step: 20, loss: 0.02220846526324749
step: 30, loss: 0.04030529409646988
step: 40, loss: 0.01911025494337082
step: 50, loss: 0.0036331331357359886
step: 60, loss: 0.01883559674024582
step: 70, loss: 0.0614766888320446
step: 80, loss: 0.012408139184117317
step: 90, loss: 0.01700603775680065
step: 100, loss: 0.014648296870291233
step: 110, loss: 0.08541890233755112
step: 120, loss: 0.11818425357341766
step: 130, loss: 0.03344710171222687
step: 140, loss: 0.16626358032226562
step: 150, loss: 0.092682845890522
step: 160, loss: 0.0587385818362236
step: 170, loss: 0.008154951967298985
step: 180, loss: 0.12819787859916687
step: 190, loss: 0.038836173713207245
step: 200, loss: 0.07593941688537598
step: 210, loss: 0.008935000747442245
step: 220, loss: 0.09815505892038345
step: 230, loss: 0.07914623618125916
step: 240, loss: 0.02059750445187092
step: 250, loss: 0.05772764980792999
step: 260, loss: 0.08324545621871948
step: 270, loss: 0.054422929883003235
step: 280, loss: 0.013065209612250328
step: 290, loss: 0.006566579919308424
step: 300, loss: 0.03783181309700012
step: 310, loss: 0.01594085618853569
step: 320, loss: 0.03103385679423809
step: 330, loss: 0.007764614187180996
step: 340, loss: 0.17188671231269836
step: 350, loss: 0.10536108911037445
step: 360, loss: 0.026035193353891373
step: 370, loss: 0.06053189933300018
step: 380, loss: 0.014986359514296055
step: 390, loss: 0.03142350912094116
step: 400, loss: 0.034549448639154434
step: 410, loss: 0.012102482840418816
step: 420, loss: 0.07391770929098129
epoch 10: dev_f1=0.9921259842519685, f1=0.9820224719101124, best_f1=0.9820224719101124
step: 0, loss: 0.05074818432331085
step: 10, loss: 0.07755344361066818
step: 20, loss: 0.01618529111146927
step: 30, loss: 0.0457000769674778
step: 40, loss: 0.05344146862626076
step: 50, loss: 0.09381895512342453
step: 60, loss: 0.15311722457408905
step: 70, loss: 0.01650822162628174
step: 80, loss: 0.09005846083164215
step: 90, loss: 0.005491673015058041
step: 100, loss: 0.06362901628017426
step: 110, loss: 0.15581806004047394
step: 120, loss: 0.11926654726266861
step: 130, loss: 0.01413087360560894
step: 140, loss: 0.06903991848230362
step: 150, loss: 0.07177390158176422
step: 160, loss: 0.054001301527023315
step: 170, loss: 0.09861347824335098
step: 180, loss: 0.06821142882108688
step: 190, loss: 0.03629585728049278
step: 200, loss: 0.06858862936496735
step: 210, loss: 0.03423371911048889
step: 220, loss: 0.09805990755558014
step: 230, loss: 0.09771474450826645
step: 240, loss: 0.046528615057468414
step: 250, loss: 0.06374960392713547
step: 260, loss: 0.009005642496049404
step: 270, loss: 0.15829674899578094
step: 280, loss: 0.007443501614034176
step: 290, loss: 0.0770343616604805
step: 300, loss: 0.15135890245437622
step: 310, loss: 0.019114183261990547
step: 320, loss: 0.14469408988952637
step: 330, loss: 0.07598888128995895
step: 340, loss: 0.03695528581738472
step: 350, loss: 0.0038188560865819454
step: 360, loss: 0.2311110496520996
step: 370, loss: 0.024163611233234406
step: 380, loss: 0.05721883475780487
step: 390, loss: 0.04105733707547188
step: 400, loss: 0.002803120529279113
step: 410, loss: 0.06134660169482231
step: 420, loss: 0.05463964492082596
epoch 11: dev_f1=0.9910313901345291, f1=0.9799107142857142, best_f1=0.9820224719101124
step: 0, loss: 0.06823111325502396
step: 10, loss: 0.006367544177919626
step: 20, loss: 0.01258820854127407
step: 30, loss: 0.09121203422546387
step: 40, loss: 0.02229384332895279
step: 50, loss: 0.06796406209468842
step: 60, loss: 0.10167039930820465
step: 70, loss: 0.005443893373012543
step: 80, loss: 0.01830427348613739
step: 90, loss: 0.003124562557786703
step: 100, loss: 0.009727120399475098
step: 110, loss: 0.02876892499625683
step: 120, loss: 0.029707957059144974
step: 130, loss: 0.07193215191364288
step: 140, loss: 0.04298366606235504
step: 150, loss: 0.007329472806304693
step: 160, loss: 0.055872805416584015
step: 170, loss: 0.04561580345034599
step: 180, loss: 0.024604694917798042
step: 190, loss: 0.027037976309657097
step: 200, loss: 0.027293819934129715
step: 210, loss: 0.050307247787714005
step: 220, loss: 0.010789552703499794
step: 230, loss: 0.03258247673511505
step: 240, loss: 0.030430052429437637
step: 250, loss: 0.01699274405837059
step: 260, loss: 0.03675152733922005
step: 270, loss: 0.0658167377114296
step: 280, loss: 0.08326157927513123
step: 290, loss: 0.005616832058876753
step: 300, loss: 0.0621425099670887
step: 310, loss: 0.06778157502412796
step: 320, loss: 0.05429275333881378
step: 330, loss: 0.03792191669344902
step: 340, loss: 0.006883272901177406
step: 350, loss: 0.0029062998946756124
step: 360, loss: 7.024284423096105e-05
step: 370, loss: 0.016194460913538933
step: 380, loss: 0.10432904958724976
step: 390, loss: 0.062362153083086014
step: 400, loss: 0.06559030711650848
step: 410, loss: 0.06264112889766693
step: 420, loss: 0.09895788133144379
epoch 12: dev_f1=0.992108229988726, f1=0.9809203142536477, best_f1=0.9820224719101124
step: 0, loss: 0.07600673288106918
step: 10, loss: 0.031062792986631393
step: 20, loss: 0.01077256165444851
step: 30, loss: 0.0005491833435371518
step: 40, loss: 0.07328645884990692
step: 50, loss: 0.0594780370593071
step: 60, loss: 0.0013596867211163044
step: 70, loss: 0.1380358636379242
step: 80, loss: 0.05761803314089775
step: 90, loss: 0.0929378867149353
step: 100, loss: 0.045091111212968826
step: 110, loss: 0.13846954703330994
step: 120, loss: 0.044294387102127075
step: 130, loss: 0.31268906593322754
step: 140, loss: 0.015295472927391529
step: 150, loss: 0.07639554142951965
step: 160, loss: 0.15193334221839905
step: 170, loss: 0.0060052890330553055
step: 180, loss: 0.09627082198858261
step: 190, loss: 0.014138775877654552
step: 200, loss: 0.0544310137629509
step: 210, loss: 0.12547042965888977
step: 220, loss: 0.006402602419257164
step: 230, loss: 0.029552949592471123
step: 240, loss: 0.1423676759004593
step: 250, loss: 0.0017663887701928616
step: 260, loss: 0.0694970116019249
step: 270, loss: 0.0012756441719830036
step: 280, loss: 0.08257576078176498
step: 290, loss: 0.010685989633202553
step: 300, loss: 0.018882695585489273
step: 310, loss: 0.0024645125959068537
step: 320, loss: 0.003729159478098154
step: 330, loss: 0.03151945769786835
step: 340, loss: 0.049445461481809616
step: 350, loss: 0.07887087017297745
step: 360, loss: 0.1045016273856163
step: 370, loss: 0.03653353080153465
step: 380, loss: 0.024058377370238304
step: 390, loss: 0.04899222031235695
step: 400, loss: 0.0648774579167366
step: 410, loss: 0.042554035782814026
step: 420, loss: 0.021055908873677254
epoch 13: dev_f1=0.990990990990991, f1=0.9820627802690582, best_f1=0.9820224719101124
step: 0, loss: 0.003604915225878358
step: 10, loss: 0.04479675367474556
step: 20, loss: 0.0818781778216362
step: 30, loss: 0.06195526197552681
step: 40, loss: 0.06920535862445831
step: 50, loss: 0.01824812777340412
step: 60, loss: 0.03460134193301201
step: 70, loss: 0.0646403431892395
step: 80, loss: 0.09168150275945663
step: 90, loss: 0.10317020863294601
step: 100, loss: 0.05108256638050079
step: 110, loss: 0.015592292882502079
step: 120, loss: 0.0701892301440239
step: 130, loss: 0.021575171500444412
step: 140, loss: 0.0017961893463507295
step: 150, loss: 0.01955438405275345
step: 160, loss: 0.02636346034705639
step: 170, loss: 0.002874822588637471
step: 180, loss: 0.027488160878419876
step: 190, loss: 0.025755569338798523
step: 200, loss: 0.027552757412195206
step: 210, loss: 0.10081196576356888
step: 220, loss: 0.05209556594491005
step: 230, loss: 0.0755113810300827
step: 240, loss: 0.05233903229236603
step: 250, loss: 0.036487698554992676
step: 260, loss: 0.0002781144867185503
step: 270, loss: 0.03142410144209862
step: 280, loss: 0.08582986146211624
step: 290, loss: 0.07194403558969498
step: 300, loss: 0.08256129175424576
step: 310, loss: 0.07860096544027328
step: 320, loss: 0.010864295065402985
step: 330, loss: 0.05805261805653572
step: 340, loss: 0.06620628386735916
step: 350, loss: 0.1497146487236023
step: 360, loss: 0.04721163958311081
step: 370, loss: 0.08672928810119629
step: 380, loss: 0.0508856400847435
step: 390, loss: 0.02638062834739685
step: 400, loss: 0.036170292645692825
step: 410, loss: 0.005394916981458664
step: 420, loss: 0.034792713820934296
epoch 14: dev_f1=0.990990990990991, f1=0.9785794813979707, best_f1=0.9820224719101124
step: 0, loss: 0.03543674200773239
step: 10, loss: 0.10493900626897812
step: 20, loss: 0.07834941893815994
step: 30, loss: 0.002466698409989476
step: 40, loss: 0.008925549685955048
step: 50, loss: 0.1358509510755539
step: 60, loss: 0.10223308950662613
step: 70, loss: 0.06733735650777817
step: 80, loss: 0.05748222768306732
step: 90, loss: 0.028876464813947678
step: 100, loss: 0.004934578202664852
step: 110, loss: 0.03821656480431557
step: 120, loss: 0.03925066068768501
step: 130, loss: 0.001986290793865919
step: 140, loss: 0.09135768562555313
step: 150, loss: 0.022035427391529083
step: 160, loss: 0.07349827140569687
step: 170, loss: 0.05985036864876747
step: 180, loss: 0.028877580538392067
step: 190, loss: 0.04968008026480675
step: 200, loss: 0.03459896147251129
step: 210, loss: 0.0012133503332734108
step: 220, loss: 0.006663127336651087
step: 230, loss: 0.04213787987828255
step: 240, loss: 0.04639747366309166
step: 250, loss: 0.06197104603052139
step: 260, loss: 0.04128478094935417
step: 270, loss: 0.040188200771808624
step: 280, loss: 0.042835116386413574
step: 290, loss: 0.024237362667918205
step: 300, loss: 0.07345506548881531
step: 310, loss: 0.018350640311837196
step: 320, loss: 0.006592956837266684
step: 330, loss: 0.0390625074505806
step: 340, loss: 0.010583052411675453
step: 350, loss: 0.023273181170225143
step: 360, loss: 0.1130770593881607
step: 370, loss: 0.09980007261037827
step: 380, loss: 0.0007197795202955604
step: 390, loss: 0.04116550832986832
step: 400, loss: 0.1435600370168686
step: 410, loss: 0.04343429580330849
step: 420, loss: 0.022611500695347786
epoch 15: dev_f1=0.990990990990991, f1=0.9820224719101124, best_f1=0.9820224719101124
step: 0, loss: 0.07490947842597961
step: 10, loss: 0.0334131233394146
step: 20, loss: 0.09777674078941345
step: 30, loss: 0.04115225747227669
step: 40, loss: 0.01954115368425846
step: 50, loss: 0.0008668163791298866
step: 60, loss: 0.026258692145347595
step: 70, loss: 0.029293425381183624
step: 80, loss: 0.06310116499662399
step: 90, loss: 0.05711691081523895
step: 100, loss: 0.04067521169781685
step: 110, loss: 0.035997483879327774
step: 120, loss: 0.03859729319810867
step: 130, loss: 0.061903201043605804
step: 140, loss: 0.0004273603262845427
step: 150, loss: 0.03716135770082474
step: 160, loss: 0.04887140542268753
step: 170, loss: 0.0005773566663265228
step: 180, loss: 0.019849050790071487
step: 190, loss: 0.03321807086467743
step: 200, loss: 0.018591739237308502
step: 210, loss: 0.020716965198516846
step: 220, loss: 0.03735189139842987
step: 230, loss: 0.0001443282380932942
step: 240, loss: 0.06023197993636131
step: 250, loss: 0.06446434557437897
step: 260, loss: 0.03865598887205124
step: 270, loss: 0.0889226570725441
step: 280, loss: 0.03840296342968941
step: 290, loss: 0.041042473167181015
step: 300, loss: 0.0822693258523941
step: 310, loss: 0.006144668906927109
step: 320, loss: 8.45391332404688e-05
step: 330, loss: 0.09770683944225311
step: 340, loss: 0.06513167172670364
step: 350, loss: 0.017870625481009483
step: 360, loss: 0.04795147851109505
step: 370, loss: 0.08784705400466919
step: 380, loss: 0.07910280674695969
step: 390, loss: 0.1680198460817337
step: 400, loss: 0.09084141999483109
step: 410, loss: 0.00716444943100214
step: 420, loss: 0.00034620019141584635
epoch 16: dev_f1=0.9898762654668166, f1=0.9820627802690582, best_f1=0.9820224719101124
step: 0, loss: 0.10805939137935638
step: 10, loss: 0.021682269871234894
step: 20, loss: 0.020083069801330566
step: 30, loss: 0.0004402718914207071
step: 40, loss: 0.0008695620927028358
step: 50, loss: 0.00010057268082164228
step: 60, loss: 0.07717911899089813
step: 70, loss: 0.0512552373111248
step: 80, loss: 0.03992045298218727
step: 90, loss: 0.013435013592243195
step: 100, loss: 0.013585248962044716
step: 110, loss: 0.021513186395168304
step: 120, loss: 0.08067124336957932
step: 130, loss: 0.045509085059165955
step: 140, loss: 1.0698970072553493e-05
step: 150, loss: 0.04040812328457832
step: 160, loss: 0.04613165184855461
step: 170, loss: 0.02263459376990795
step: 180, loss: 0.07459001988172531
step: 190, loss: 0.10623933374881744
step: 200, loss: 0.016366859897971153
step: 210, loss: 0.005332657601684332
step: 220, loss: 0.0790376290678978
step: 230, loss: 0.024937761947512627
step: 240, loss: 0.002479391172528267
step: 250, loss: 0.12417677044868469
step: 260, loss: 0.05756741017103195
step: 270, loss: 0.04485806077718735
step: 280, loss: 0.048095282167196274
step: 290, loss: 0.01904316432774067
step: 300, loss: 0.06933222711086273
step: 310, loss: 0.08083644509315491
step: 320, loss: 0.03551173955202103
step: 330, loss: 0.03430597484111786
step: 340, loss: 0.029001977294683456
step: 350, loss: 0.0005996584077365696
step: 360, loss: 0.04524386301636696
step: 370, loss: 0.03777133673429489
step: 380, loss: 0.060556937009096146
step: 390, loss: 0.08455703407526016
step: 400, loss: 0.009243324398994446
step: 410, loss: 0.02241036482155323
step: 420, loss: 0.01743481494486332
epoch 17: dev_f1=0.990990990990991, f1=0.9820224719101124, best_f1=0.9820224719101124
step: 0, loss: 0.10611064732074738
step: 10, loss: 0.02448137290775776
step: 20, loss: 0.046645838767290115
step: 30, loss: 0.02891671285033226
step: 40, loss: 6.185082020238042e-05
step: 50, loss: 0.09423639625310898
step: 60, loss: 0.06840098649263382
step: 70, loss: 0.024093786254525185
step: 80, loss: 0.0001701443106867373
step: 90, loss: 0.08006211370229721
step: 100, loss: 0.05621027946472168
step: 110, loss: 0.06373288482427597
step: 120, loss: 0.022979680448770523
step: 130, loss: 0.05652443692088127
step: 140, loss: 0.15024007856845856
step: 150, loss: 0.00012138815509388223
step: 160, loss: 0.06442509591579437
step: 170, loss: 0.021765032783150673
step: 180, loss: 0.03210322558879852
step: 190, loss: 5.875304850633256e-05
step: 200, loss: 0.09286215156316757
step: 210, loss: 0.00012160900951130316
step: 220, loss: 0.00023334445722866803
step: 230, loss: 0.15942400693893433
step: 240, loss: 0.06642129272222519
step: 250, loss: 0.04090046510100365
step: 260, loss: 0.038351938128471375
step: 270, loss: 0.042958781123161316
step: 280, loss: 0.05264490470290184
step: 290, loss: 0.07819534093141556
step: 300, loss: 0.049436043947935104
step: 310, loss: 0.05293768644332886
step: 320, loss: 0.06649867445230484
step: 330, loss: 0.03823959454894066
step: 340, loss: 0.0002138750278390944
step: 350, loss: 0.022918246686458588
step: 360, loss: 0.00043138276669196784
step: 370, loss: 0.07859829813241959
step: 380, loss: 0.03839050233364105
step: 390, loss: 0.03463015705347061
step: 400, loss: 0.02079961821436882
step: 410, loss: 0.061871238052845
step: 420, loss: 0.00013695527741219848
epoch 18: dev_f1=0.9909706546275394, f1=0.9797752808988766, best_f1=0.9820224719101124
step: 0, loss: 1.3917480828240514e-05
step: 10, loss: 0.018902461975812912
step: 20, loss: 0.032254576683044434
step: 30, loss: 0.06361579149961472
step: 40, loss: 0.04090505093336105
step: 50, loss: 0.004680900368839502
step: 60, loss: 0.06528960913419724
step: 70, loss: 0.05866241455078125
step: 80, loss: 0.04282722622156143
step: 90, loss: 0.01605340652167797
step: 100, loss: 0.09151627123355865
step: 110, loss: 0.020009629428386688
step: 120, loss: 0.044563714414834976
step: 130, loss: 0.09705068916082382
step: 140, loss: 0.05428842827677727
step: 150, loss: 0.012436374090611935
step: 160, loss: 0.09609679877758026
step: 170, loss: 0.16334818303585052
step: 180, loss: 0.05645875260233879
step: 190, loss: 0.05282149836421013
step: 200, loss: 0.02176697924733162
step: 210, loss: 0.00013602431863546371
step: 220, loss: 0.018425410613417625
step: 230, loss: 0.018551966175436974
step: 240, loss: 0.10808549076318741
step: 250, loss: 0.10778649896383286
step: 260, loss: 4.7666446334915236e-05
step: 270, loss: 0.0005286611849442124
step: 280, loss: 0.05023469775915146
step: 290, loss: 0.02343468926846981
step: 300, loss: 0.0889231339097023
step: 310, loss: 0.022072523832321167
step: 320, loss: 0.023411152884364128
step: 330, loss: 0.08037447184324265
step: 340, loss: 0.05534093827009201
step: 350, loss: 0.09376632422208786
step: 360, loss: 0.01581614278256893
step: 370, loss: 0.10577911883592606
step: 380, loss: 0.06528620421886444
step: 390, loss: 0.016798093914985657
step: 400, loss: 0.024715308099985123
step: 410, loss: 0.0002245164505438879
step: 420, loss: 0.05430281534790993
epoch 19: dev_f1=0.990990990990991, f1=0.9820627802690582, best_f1=0.9820224719101124
step: 0, loss: 0.0297007504850626
step: 10, loss: 0.03510528802871704
step: 20, loss: 0.06836425513029099
step: 30, loss: 0.02213885821402073
step: 40, loss: 0.0716380625963211
step: 50, loss: 0.0775701254606247
step: 60, loss: 0.029930099844932556
step: 70, loss: 0.05020439252257347
step: 80, loss: 0.02042713202536106
step: 90, loss: 0.04269174858927727
step: 100, loss: 0.04861733689904213
step: 110, loss: 0.022081922739744186
step: 120, loss: 0.010953187942504883
step: 130, loss: 0.025490857660770416
step: 140, loss: 0.045994628220796585
step: 150, loss: 0.0002463230339344591
step: 160, loss: 0.0009134137071669102
step: 170, loss: 0.00013260013656690717
step: 180, loss: 0.06785833090543747
step: 190, loss: 0.042914409190416336
step: 200, loss: 0.0011087357997894287
step: 210, loss: 0.025988511741161346
step: 220, loss: 0.013924741186201572
step: 230, loss: 0.05064791068434715
step: 240, loss: 0.09711862355470657
step: 250, loss: 0.05746890604496002
step: 260, loss: 0.017676960676908493
step: 270, loss: 0.021496612578630447
step: 280, loss: 0.004091435112059116
step: 290, loss: 0.035398878157138824
step: 300, loss: 0.01978922449052334
step: 310, loss: 0.06649669259786606
step: 320, loss: 5.442582187242806e-05
step: 330, loss: 0.02957044169306755
step: 340, loss: 0.025971276685595512
step: 350, loss: 0.06998598575592041
step: 360, loss: 0.045498330146074295
step: 370, loss: 0.049889832735061646
step: 380, loss: 0.03590903803706169
step: 390, loss: 0.021726367995142937
step: 400, loss: 0.022224409505724907
step: 410, loss: 0.017289867624640465
step: 420, loss: 0.06289886683225632
epoch 20: dev_f1=0.990990990990991, f1=0.9797752808988766, best_f1=0.9820224719101124
