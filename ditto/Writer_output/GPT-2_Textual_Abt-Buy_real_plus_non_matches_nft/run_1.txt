cuda
Device: cuda
step: 0, loss: 0.4883875548839569
step: 10, loss: 0.07093247026205063
step: 20, loss: 0.1518680304288864
step: 30, loss: 0.0412495993077755
step: 40, loss: 0.112490713596344
step: 50, loss: 0.13972727954387665
step: 60, loss: 0.4089469611644745
step: 70, loss: 0.07343848049640656
step: 80, loss: 0.14253680408000946
step: 90, loss: 0.3006839156150818
step: 100, loss: 0.1527629792690277
step: 110, loss: 0.13668891787528992
step: 120, loss: 0.4083816111087799
step: 130, loss: 0.08952036499977112
step: 140, loss: 0.09279901534318924
step: 150, loss: 0.0670194998383522
step: 160, loss: 0.2656356990337372
step: 170, loss: 0.25671565532684326
step: 180, loss: 0.323154479265213
step: 190, loss: 0.04565409570932388
step: 200, loss: 0.37872907519340515
step: 210, loss: 0.2895435690879822
step: 220, loss: 0.34264105558395386
step: 230, loss: 0.13383853435516357
step: 240, loss: 0.31897127628326416
step: 250, loss: 0.2268543839454651
step: 260, loss: 0.17530083656311035
step: 270, loss: 0.1736437976360321
step: 280, loss: 0.06285038590431213
step: 290, loss: 0.21714147925376892
step: 300, loss: 0.3228945732116699
step: 310, loss: 0.1314632147550583
step: 320, loss: 0.13277460634708405
step: 330, loss: 0.2220497727394104
epoch 1: dev_f1=0.27104722792607805, f1=0.24646464646464641, best_f1=0.24646464646464641
step: 0, loss: 0.12637658417224884
step: 10, loss: 0.1248927190899849
step: 20, loss: 0.19951249659061432
step: 30, loss: 0.3655775785446167
step: 40, loss: 0.24166537821292877
step: 50, loss: 0.10846314579248428
step: 60, loss: 0.022940538823604584
step: 70, loss: 0.10946914553642273
step: 80, loss: 0.16657376289367676
step: 90, loss: 0.39518946409225464
step: 100, loss: 0.1640194058418274
step: 110, loss: 0.19722993671894073
step: 120, loss: 0.30114617943763733
step: 130, loss: 0.0842321589589119
step: 140, loss: 0.09020122140645981
step: 150, loss: 0.0706830695271492
step: 160, loss: 0.06726423650979996
step: 170, loss: 0.3543546795845032
step: 180, loss: 0.13438990712165833
step: 190, loss: 0.22858120501041412
step: 200, loss: 0.1430365890264511
step: 210, loss: 0.10253556817770004
step: 220, loss: 0.07285618782043457
step: 230, loss: 0.03709292784333229
step: 240, loss: 0.17342905700206757
step: 250, loss: 0.21892745792865753
step: 260, loss: 0.2830413281917572
step: 270, loss: 0.07438833266496658
step: 280, loss: 0.08870382606983185
step: 290, loss: 0.07032890617847443
step: 300, loss: 0.14234310388565063
step: 310, loss: 0.08597911149263382
step: 320, loss: 0.056190937757492065
step: 330, loss: 0.17139877378940582
epoch 2: dev_f1=0.7051282051282051, f1=0.708502024291498, best_f1=0.708502024291498
step: 0, loss: 0.12493053078651428
step: 10, loss: 0.16617855429649353
step: 20, loss: 0.06632483005523682
step: 30, loss: 0.17556940019130707
step: 40, loss: 0.08213768154382706
step: 50, loss: 0.003998751752078533
step: 60, loss: 0.020919909700751305
step: 70, loss: 0.0911773294210434
step: 80, loss: 0.008181293494999409
step: 90, loss: 0.015526057220995426
step: 100, loss: 0.05045019090175629
step: 110, loss: 0.09308959543704987
step: 120, loss: 0.06732671707868576
step: 130, loss: 0.05223933607339859
step: 140, loss: 0.0729437991976738
step: 150, loss: 0.1039963960647583
step: 160, loss: 0.010411679744720459
step: 170, loss: 0.02649638056755066
step: 180, loss: 0.02763383649289608
step: 190, loss: 0.0873490497469902
step: 200, loss: 0.008886638097465038
step: 210, loss: 0.0845966637134552
step: 220, loss: 0.15207402408123016
step: 230, loss: 0.03240435570478439
step: 240, loss: 0.06523670256137848
step: 250, loss: 0.13014890253543854
step: 260, loss: 0.05760230869054794
step: 270, loss: 0.13277827203273773
step: 280, loss: 0.16370631754398346
step: 290, loss: 0.14154478907585144
step: 300, loss: 0.08326427638530731
step: 310, loss: 0.03587048128247261
step: 320, loss: 0.0640937089920044
step: 330, loss: 0.18344667553901672
epoch 3: dev_f1=0.7533632286995516, f1=0.7577092511013217, best_f1=0.7577092511013217
step: 0, loss: 0.011289412155747414
step: 10, loss: 0.0319635272026062
step: 20, loss: 0.04470206797122955
step: 30, loss: 0.011349204927682877
step: 40, loss: 0.097496397793293
step: 50, loss: 0.13515684008598328
step: 60, loss: 0.013486090116202831
step: 70, loss: 0.044155534356832504
step: 80, loss: 0.003151878248900175
step: 90, loss: 0.03151843696832657
step: 100, loss: 0.02032201737165451
step: 110, loss: 0.029126523062586784
step: 120, loss: 0.01255275309085846
step: 130, loss: 0.0028494291473180056
step: 140, loss: 0.01760934852063656
step: 150, loss: 0.025454407557845116
step: 160, loss: 0.021787254139780998
step: 170, loss: 0.05414534732699394
step: 180, loss: 0.04570920765399933
step: 190, loss: 0.0066945599392056465
step: 200, loss: 0.016897037625312805
step: 210, loss: 0.21517851948738098
step: 220, loss: 0.007545172702521086
step: 230, loss: 0.006376202683895826
step: 240, loss: 0.007103907410055399
step: 250, loss: 0.10535094887018204
step: 260, loss: 0.02419934794306755
step: 270, loss: 0.0005041459808126092
step: 280, loss: 0.004059913568198681
step: 290, loss: 0.03678996115922928
step: 300, loss: 0.013240489177405834
step: 310, loss: 0.04339979588985443
step: 320, loss: 0.1103212907910347
step: 330, loss: 0.022125136107206345
epoch 4: dev_f1=0.7819905213270142, f1=0.7688787185354691, best_f1=0.7688787185354691
step: 0, loss: 0.014478156343102455
step: 10, loss: 0.03255491331219673
step: 20, loss: 0.0037480760365724564
step: 30, loss: 0.01054582092911005
step: 40, loss: 0.03632062301039696
step: 50, loss: 0.007406524382531643
step: 60, loss: 0.0206436924636364
step: 70, loss: 0.003241142490878701
step: 80, loss: 0.030558064579963684
step: 90, loss: 0.003417643252760172
step: 100, loss: 0.01775795966386795
step: 110, loss: 0.003033059649169445
step: 120, loss: 0.005406854674220085
step: 130, loss: 0.0541609525680542
step: 140, loss: 0.03008176013827324
step: 150, loss: 0.006473189685493708
step: 160, loss: 0.004864552523940802
step: 170, loss: 0.07705144584178925
step: 180, loss: 0.049156807363033295
step: 190, loss: 0.004954343196004629
step: 200, loss: 0.015337688848376274
step: 210, loss: 0.01905793882906437
step: 220, loss: 0.12054472416639328
step: 230, loss: 0.05994442477822304
step: 240, loss: 0.003808625740930438
step: 250, loss: 0.029862243682146072
step: 260, loss: 0.08441027998924255
step: 270, loss: 0.0010745053878054023
step: 280, loss: 0.12725050747394562
step: 290, loss: 0.0008336707833223045
step: 300, loss: 0.014052124693989754
step: 310, loss: 0.017652610316872597
step: 320, loss: 0.008147005923092365
step: 330, loss: 0.023203236982226372
epoch 5: dev_f1=0.8, f1=0.7738927738927739, best_f1=0.7738927738927739
step: 0, loss: 0.006175136659294367
step: 10, loss: 0.0014200302539393306
step: 20, loss: 0.009553239680826664
step: 30, loss: 0.0018919925205409527
step: 40, loss: 0.0050745136104524136
step: 50, loss: 0.009369170293211937
step: 60, loss: 0.0008040107204578817
step: 70, loss: 0.0003644295793492347
step: 80, loss: 0.009128095582127571
step: 90, loss: 0.002938515041023493
step: 100, loss: 0.040120527148246765
step: 110, loss: 0.02747078239917755
step: 120, loss: 0.02638310007750988
step: 130, loss: 0.013859116472303867
step: 140, loss: 0.0033333315514028072
step: 150, loss: 0.05952734500169754
step: 160, loss: 0.025958018377423286
step: 170, loss: 0.10160524398088455
step: 180, loss: 0.0029758750461041927
step: 190, loss: 0.0075531285256147385
step: 200, loss: 0.03575644642114639
step: 210, loss: 0.0003659284848254174
step: 220, loss: 0.0013799138832837343
step: 230, loss: 0.0827454924583435
step: 240, loss: 0.010644324123859406
step: 250, loss: 0.012929941527545452
step: 260, loss: 0.0011396629270166159
step: 270, loss: 0.0034092662390321493
step: 280, loss: 0.00452604191377759
step: 290, loss: 0.005673923064023256
step: 300, loss: 0.045910630375146866
step: 310, loss: 0.0004710694483947009
step: 320, loss: 0.021100759506225586
step: 330, loss: 0.015224426053464413
epoch 6: dev_f1=0.7488372093023257, f1=0.7610208816705337, best_f1=0.7738927738927739
step: 0, loss: 0.007248416543006897
step: 10, loss: 0.02670803666114807
step: 20, loss: 0.07742295414209366
step: 30, loss: 0.005666235461831093
step: 40, loss: 0.0035666574258357286
step: 50, loss: 0.010032715275883675
step: 60, loss: 0.00030765909468755126
step: 70, loss: 0.028045788407325745
step: 80, loss: 0.04971886798739433
step: 90, loss: 0.02550937794148922
step: 100, loss: 0.0005476860096678138
step: 110, loss: 0.010960279032588005
step: 120, loss: 0.00029024435207247734
step: 130, loss: 0.00824149139225483
step: 140, loss: 0.01900620572268963
step: 150, loss: 0.00022701919078826904
step: 160, loss: 0.0037656868807971478
step: 170, loss: 0.0068276505917310715
step: 180, loss: 0.012157591059803963
step: 190, loss: 0.003640049370005727
step: 200, loss: 0.03118353895843029
step: 210, loss: 0.00691929692402482
step: 220, loss: 0.005001412238925695
step: 230, loss: 0.04326358437538147
step: 240, loss: 0.01402723416686058
step: 250, loss: 0.00012028593482682481
step: 260, loss: 0.0018165174406021833
step: 270, loss: 0.0007475899183191359
step: 280, loss: 0.06308680027723312
step: 290, loss: 0.0036982751917093992
step: 300, loss: 0.03424356132745743
step: 310, loss: 0.0055740103125572205
step: 320, loss: 0.0008574706153012812
step: 330, loss: 0.0012052020756527781
epoch 7: dev_f1=0.7764127764127765, f1=0.7793427230046948, best_f1=0.7738927738927739
step: 0, loss: 0.007964616641402245
step: 10, loss: 0.00810380931943655
step: 20, loss: 0.0010086747352033854
step: 30, loss: 0.003478680271655321
step: 40, loss: 0.009576729498803616
step: 50, loss: 0.00019549258286133409
step: 60, loss: 0.0003394096274860203
step: 70, loss: 0.00748039223253727
step: 80, loss: 0.015021695755422115
step: 90, loss: 0.004379628226161003
step: 100, loss: 0.00159564265049994
step: 110, loss: 0.00044240368879400194
step: 120, loss: 0.00031486176885664463
step: 130, loss: 0.06253528594970703
step: 140, loss: 0.0012769711902365088
step: 150, loss: 0.004882374778389931
step: 160, loss: 0.0817626565694809
step: 170, loss: 0.00043620579526759684
step: 180, loss: 0.042979683727025986
step: 190, loss: 0.012506084516644478
step: 200, loss: 0.004176153335720301
step: 210, loss: 7.871969137340784e-05
step: 220, loss: 0.08236797153949738
step: 230, loss: 0.04257357493042946
step: 240, loss: 0.09159647673368454
step: 250, loss: 0.0019263497088104486
step: 260, loss: 0.1356242448091507
step: 270, loss: 0.024984708055853844
step: 280, loss: 0.0006866509793326259
step: 290, loss: 0.03801705315709114
step: 300, loss: 0.04438464716076851
step: 310, loss: 0.02468053437769413
step: 320, loss: 0.04884900152683258
step: 330, loss: 0.05617167428135872
epoch 8: dev_f1=0.7903614457831325, f1=0.756880733944954, best_f1=0.7738927738927739
step: 0, loss: 0.0018458374543115497
step: 10, loss: 0.0029421604704111814
step: 20, loss: 0.000209198915399611
step: 30, loss: 0.016784274950623512
step: 40, loss: 6.960175232961774e-05
step: 50, loss: 0.002160626230761409
step: 60, loss: 0.00016968761337921023
step: 70, loss: 0.03473799675703049
step: 80, loss: 0.0008928323513828218
step: 90, loss: 0.0002979754644911736
step: 100, loss: 0.08311477303504944
step: 110, loss: 0.004869949538260698
step: 120, loss: 0.03712901473045349
step: 130, loss: 0.0005641880561597645
step: 140, loss: 0.002188091166317463
step: 150, loss: 0.06594211608171463
step: 160, loss: 0.01717841438949108
step: 170, loss: 0.13131402432918549
step: 180, loss: 0.00044069511932320893
step: 190, loss: 0.0038095253985375166
step: 200, loss: 0.07642174512147903
step: 210, loss: 0.0143790477886796
step: 220, loss: 0.1022714301943779
step: 230, loss: 0.0035307828802615404
step: 240, loss: 0.001307728118263185
step: 250, loss: 0.0005524451844394207
step: 260, loss: 0.08594375848770142
step: 270, loss: 6.476299313362688e-05
step: 280, loss: 0.0003964163188356906
step: 290, loss: 0.0011999221751466393
step: 300, loss: 0.0001489350979682058
step: 310, loss: 0.0041799829341471195
step: 320, loss: 0.007098456844687462
step: 330, loss: 0.015742527320981026
epoch 9: dev_f1=0.807785888077859, f1=0.7889908256880733, best_f1=0.7889908256880733
step: 0, loss: 0.02016543224453926
step: 10, loss: 0.013869264163076878
step: 20, loss: 0.0015951241366565228
step: 30, loss: 0.00010966963600367308
step: 40, loss: 3.899907460436225e-05
step: 50, loss: 0.008360118605196476
step: 60, loss: 0.00012290780432522297
step: 70, loss: 0.001384610659442842
step: 80, loss: 0.0012528414372354746
step: 90, loss: 0.010720523074269295
step: 100, loss: 0.0011019635712727904
step: 110, loss: 0.009153569117188454
step: 120, loss: 6.296225910773501e-05
step: 130, loss: 0.004359106533229351
step: 140, loss: 0.11806920170783997
step: 150, loss: 0.0003641093207988888
step: 160, loss: 0.0016435316065326333
step: 170, loss: 0.005271240137517452
step: 180, loss: 0.00033320666989311576
step: 190, loss: 0.002109280787408352
step: 200, loss: 0.00048081178101710975
step: 210, loss: 0.001063768519088626
step: 220, loss: 0.003299267962574959
step: 230, loss: 8.337185863638297e-05
step: 240, loss: 0.00021963084873277694
step: 250, loss: 0.01305597648024559
step: 260, loss: 0.005726235918700695
step: 270, loss: 0.02751491777598858
step: 280, loss: 0.01729304902255535
step: 290, loss: 0.00022869750682730228
step: 300, loss: 0.0011072042398154736
step: 310, loss: 0.0018016743706539273
step: 320, loss: 0.00034657077048905194
step: 330, loss: 0.02910698391497135
epoch 10: dev_f1=0.7949999999999999, f1=0.7875894988066825, best_f1=0.7889908256880733
step: 0, loss: 0.00031193968607112765
step: 10, loss: 0.004012458026409149
step: 20, loss: 3.0594350391766056e-05
step: 30, loss: 0.00634028809145093
step: 40, loss: 4.774813714902848e-05
step: 50, loss: 0.004103585612028837
step: 60, loss: 0.0007590425084345043
step: 70, loss: 0.011408468708395958
step: 80, loss: 0.0006165597005747259
step: 90, loss: 0.0002231184917036444
step: 100, loss: 0.005941597744822502
step: 110, loss: 0.00048765214160084724
step: 120, loss: 0.005502278450876474
step: 130, loss: 0.00010443417704664171
step: 140, loss: 0.00015594266005791724
step: 150, loss: 0.00011095437366748229
step: 160, loss: 0.00042198903975076973
step: 170, loss: 0.00012963032349944115
step: 180, loss: 0.0002105520834447816
step: 190, loss: 0.00014458104851655662
step: 200, loss: 7.408649253193289e-05
step: 210, loss: 0.0003165800590068102
step: 220, loss: 0.0011854828335344791
step: 230, loss: 0.00014043203555047512
step: 240, loss: 0.008184864185750484
step: 250, loss: 0.00024941604351624846
step: 260, loss: 0.03325105458498001
step: 270, loss: 0.0004377108998596668
step: 280, loss: 0.00011295744479866698
step: 290, loss: 6.752101762685925e-05
step: 300, loss: 0.00012943574984092265
step: 310, loss: 0.004133581183850765
step: 320, loss: 0.018076909705996513
step: 330, loss: 0.01965322345495224
epoch 11: dev_f1=0.7989556135770236, f1=0.780361757105943, best_f1=0.7889908256880733
step: 0, loss: 0.0012585131917148829
step: 10, loss: 0.01511966623365879
step: 20, loss: 6.542487972183153e-05
step: 30, loss: 6.74424518365413e-05
step: 40, loss: 0.00041741979657672346
step: 50, loss: 7.451057899743319e-05
step: 60, loss: 0.0016132791060954332
step: 70, loss: 0.024090437218546867
step: 80, loss: 0.0070845563896000385
step: 90, loss: 0.0019352465169504285
step: 100, loss: 0.11487529426813126
step: 110, loss: 0.00018753271433524787
step: 120, loss: 0.061249710619449615
step: 130, loss: 0.01576494611799717
step: 140, loss: 0.001056560198776424
step: 150, loss: 0.0019722795113921165
step: 160, loss: 0.0003755484940484166
step: 170, loss: 0.03623892739415169
step: 180, loss: 0.06874334812164307
step: 190, loss: 0.0007386376964859664
step: 200, loss: 0.00019182372489012778
step: 210, loss: 0.04156297817826271
step: 220, loss: 0.0022459207102656364
step: 230, loss: 6.369014590745792e-05
step: 240, loss: 0.0069615584798157215
step: 250, loss: 0.03821778669953346
step: 260, loss: 0.00013745199248660356
step: 270, loss: 0.0002701121848076582
step: 280, loss: 7.370864477707073e-05
step: 290, loss: 0.0006032525561749935
step: 300, loss: 0.00919952429831028
step: 310, loss: 0.00011084343714173883
step: 320, loss: 0.00017282548651564866
step: 330, loss: 7.852468843339011e-05
epoch 12: dev_f1=0.7860696517412936, f1=0.7895981087470448, best_f1=0.7889908256880733
step: 0, loss: 0.007581901736557484
step: 10, loss: 0.00019932413124479353
step: 20, loss: 4.2886393202934414e-05
step: 30, loss: 9.277318167733029e-05
step: 40, loss: 0.00020369869889691472
step: 50, loss: 7.5240881415084e-05
step: 60, loss: 0.012209488078951836
step: 70, loss: 0.0001968315918929875
step: 80, loss: 5.688125020242296e-05
step: 90, loss: 0.00047926584375090897
step: 100, loss: 0.03398391604423523
step: 110, loss: 3.117806409136392e-05
step: 120, loss: 0.0007611432811245322
step: 130, loss: 9.093427797779441e-05
step: 140, loss: 4.2035779188154265e-05
step: 150, loss: 0.00031843697070144117
step: 160, loss: 0.00012770987814292312
step: 170, loss: 0.00010640927939675748
step: 180, loss: 0.00015491808881051838
step: 190, loss: 0.0016336521366611123
step: 200, loss: 0.00021459093841258436
step: 210, loss: 0.005711427889764309
step: 220, loss: 0.00021709190332330763
step: 230, loss: 0.0004943703534081578
step: 240, loss: 0.00013181344547774643
step: 250, loss: 0.0007683004369027913
step: 260, loss: 1.8365419236943126e-05
step: 270, loss: 0.004914911929517984
step: 280, loss: 0.028794120997190475
step: 290, loss: 0.010775475762784481
step: 300, loss: 0.011415354907512665
step: 310, loss: 0.0039444672875106335
step: 320, loss: 0.0013064822414889932
step: 330, loss: 0.006550017278641462
epoch 13: dev_f1=0.7906976744186047, f1=0.7761194029850746, best_f1=0.7889908256880733
step: 0, loss: 0.0018788095330819488
step: 10, loss: 0.007819242775440216
step: 20, loss: 0.002458721399307251
step: 30, loss: 0.0019732534419745207
step: 40, loss: 0.0005437264335341752
step: 50, loss: 0.0001868559920694679
step: 60, loss: 0.00033439064281992614
step: 70, loss: 0.0009643887169659138
step: 80, loss: 7.435868610627949e-05
step: 90, loss: 0.0004675624368246645
step: 100, loss: 0.0033110505901277065
step: 110, loss: 0.014025169424712658
step: 120, loss: 4.089657886652276e-05
step: 130, loss: 6.584851507795975e-05
step: 140, loss: 0.00014590482169296592
step: 150, loss: 0.05186924710869789
step: 160, loss: 0.0015846809837967157
step: 170, loss: 5.41688859811984e-05
step: 180, loss: 0.00039735744940117
step: 190, loss: 0.022808337584137917
step: 200, loss: 7.529783033533022e-05
step: 210, loss: 1.4413033568416722e-05
step: 220, loss: 0.097712941467762
step: 230, loss: 0.002367825247347355
step: 240, loss: 0.009097014553844929
step: 250, loss: 0.003051664913073182
step: 260, loss: 5.836178388562985e-05
step: 270, loss: 0.00031561838113702834
step: 280, loss: 0.0014387107221409678
step: 290, loss: 0.00022052164422348142
step: 300, loss: 0.00011368942068656906
step: 310, loss: 3.8353602576535195e-05
step: 320, loss: 8.242709009209648e-05
step: 330, loss: 2.149383544747252e-05
epoch 14: dev_f1=0.7688442211055277, f1=0.7766990291262136, best_f1=0.7889908256880733
step: 0, loss: 6.893327372381464e-05
step: 10, loss: 2.7007003154722042e-05
step: 20, loss: 0.0005703680799342692
step: 30, loss: 0.00111283827573061
step: 40, loss: 7.184450078057125e-05
step: 50, loss: 0.010383972898125648
step: 60, loss: 8.242824696935713e-05
step: 70, loss: 0.0010502863442525268
step: 80, loss: 0.00013612498878501356
step: 90, loss: 0.008950549177825451
step: 100, loss: 7.720372377661988e-05
step: 110, loss: 0.031536880880594254
step: 120, loss: 0.05342915281653404
step: 130, loss: 4.9616875912761316e-05
step: 140, loss: 4.430284388945438e-05
step: 150, loss: 0.0009226661059074104
step: 160, loss: 8.179703581845388e-05
step: 170, loss: 0.0003775910590775311
step: 180, loss: 4.7229033953044564e-05
step: 190, loss: 0.017638374119997025
step: 200, loss: 6.272549944696948e-05
step: 210, loss: 3.8385838706744835e-05
step: 220, loss: 0.0003569431137293577
step: 230, loss: 0.005388638470321894
step: 240, loss: 0.0002493757929187268
step: 250, loss: 0.008962541818618774
step: 260, loss: 0.00012608684482984245
step: 270, loss: 0.044627562165260315
step: 280, loss: 0.0026868104469031096
step: 290, loss: 5.046692240284756e-05
step: 300, loss: 0.00010574408952379599
step: 310, loss: 0.00029959800303913653
step: 320, loss: 7.436118903569877e-05
step: 330, loss: 2.5703091523610055e-05
epoch 15: dev_f1=0.7673267326732675, f1=0.7732696897374701, best_f1=0.7889908256880733
step: 0, loss: 4.166684811934829e-05
step: 10, loss: 0.0003278808726463467
step: 20, loss: 4.0069036913337186e-05
step: 30, loss: 0.00017332016432192177
step: 40, loss: 0.00019705886370502412
step: 50, loss: 0.00042890518670901656
step: 60, loss: 0.0004124922852497548
step: 70, loss: 0.0015438462141901255
step: 80, loss: 0.001010080915875733
step: 90, loss: 0.0009114652057178319
step: 100, loss: 0.0003397179825697094
step: 110, loss: 0.0003727741714101285
step: 120, loss: 0.004635783843696117
step: 130, loss: 0.0002129585191141814
step: 140, loss: 8.426192653132603e-05
step: 150, loss: 0.00027243816293776035
step: 160, loss: 0.0003824378363788128
step: 170, loss: 0.00028841805760748684
step: 180, loss: 0.002534121973440051
step: 190, loss: 0.0008594693499617279
step: 200, loss: 5.702049020328559e-05
step: 210, loss: 0.002778195310384035
step: 220, loss: 0.0002666412910912186
step: 230, loss: 0.00017045940330717713
step: 240, loss: 0.0026469489093869925
step: 250, loss: 0.028601858764886856
step: 260, loss: 6.418292468879372e-05
step: 270, loss: 0.0006878611748106778
step: 280, loss: 7.577584619866684e-05
step: 290, loss: 0.0007611624896526337
step: 300, loss: 0.00024094920081552118
step: 310, loss: 2.1747177015640773e-05
step: 320, loss: 0.00012890278594568372
step: 330, loss: 0.030191706493496895
epoch 16: dev_f1=0.786096256684492, f1=0.7888040712468193, best_f1=0.7889908256880733
step: 0, loss: 0.0008690258837305009
step: 10, loss: 0.0001431393320672214
step: 20, loss: 0.0015258673811331391
step: 30, loss: 0.00018621954950504005
step: 40, loss: 0.03985510393977165
step: 50, loss: 0.00010936465696431696
step: 60, loss: 0.0003625883546192199
step: 70, loss: 5.1938448450528085e-05
step: 80, loss: 5.191093805478886e-05
step: 90, loss: 0.00021019813721068203
step: 100, loss: 0.00019315691315568984
step: 110, loss: 7.082735100993887e-05
step: 120, loss: 0.0758475586771965
step: 130, loss: 0.05455883592367172
step: 140, loss: 0.002460445975884795
step: 150, loss: 6.198742630658671e-05
step: 160, loss: 0.005787994712591171
step: 170, loss: 5.9980553487548605e-05
step: 180, loss: 3.4128799597965553e-05
step: 190, loss: 0.00020834234601352364
step: 200, loss: 0.005070092156529427
step: 210, loss: 4.636746962205507e-05
step: 220, loss: 4.814164640265517e-05
step: 230, loss: 0.0006410630303435028
step: 240, loss: 0.004837685264647007
step: 250, loss: 0.0004695852694567293
step: 260, loss: 0.0003797159297391772
step: 270, loss: 3.685510455397889e-05
step: 280, loss: 0.10996975749731064
step: 290, loss: 2.7360902095097117e-05
step: 300, loss: 0.023861408233642578
step: 310, loss: 6.19892671238631e-05
step: 320, loss: 0.00016569085710216314
step: 330, loss: 4.065661414642818e-05
epoch 17: dev_f1=0.7837837837837839, f1=0.7758186397984886, best_f1=0.7889908256880733
step: 0, loss: 2.051070441666525e-05
step: 10, loss: 8.867628639563918e-05
step: 20, loss: 0.003915014211088419
step: 30, loss: 0.00021911122894380242
step: 40, loss: 0.00011693349370034412
step: 50, loss: 0.006945841480046511
step: 60, loss: 4.8966132453642786e-05
step: 70, loss: 0.0007396767032332718
step: 80, loss: 0.0006049536750651896
step: 90, loss: 0.00021210056729614735
step: 100, loss: 4.3229825678281486e-05
step: 110, loss: 7.058757182676345e-05
step: 120, loss: 9.019143180921674e-05
step: 130, loss: 4.032766446471214e-05
step: 140, loss: 0.0005383107927627861
step: 150, loss: 4.120354060432874e-05
step: 160, loss: 3.274974733358249e-05
step: 170, loss: 4.003881258540787e-05
step: 180, loss: 5.922123455093242e-05
step: 190, loss: 0.0010180624667555094
step: 200, loss: 0.0004611058975569904
step: 210, loss: 5.442383553599939e-05
step: 220, loss: 0.00011941863340325654
step: 230, loss: 0.0008138693519867957
step: 240, loss: 7.88651013863273e-05
step: 250, loss: 0.0001364347554044798
step: 260, loss: 0.00010817337897606194
step: 270, loss: 6.76430354360491e-05
step: 280, loss: 0.0001286096521653235
step: 290, loss: 0.002193682361394167
step: 300, loss: 0.01186245959252119
step: 310, loss: 3.58452889486216e-05
step: 320, loss: 5.853838592884131e-05
step: 330, loss: 6.662324449280277e-05
epoch 18: dev_f1=0.7816711590296497, f1=0.7664974619289341, best_f1=0.7889908256880733
step: 0, loss: 0.00024844813742674887
step: 10, loss: 4.66995443275664e-05
step: 20, loss: 4.03278972953558e-05
step: 30, loss: 0.00011308910325169563
step: 40, loss: 4.682037979364395e-05
step: 50, loss: 0.0008709859102964401
step: 60, loss: 0.0005066418088972569
step: 70, loss: 3.1210420274874195e-05
step: 80, loss: 2.3482358301407658e-05
step: 90, loss: 3.599221236072481e-05
step: 100, loss: 0.002004273934289813
step: 110, loss: 0.0004520611255429685
step: 120, loss: 0.0010938751511275768
step: 130, loss: 0.013247430324554443
step: 140, loss: 3.183711305609904e-05
step: 150, loss: 4.253162842360325e-05
step: 160, loss: 2.1218333131400868e-05
step: 170, loss: 0.0005436969804577529
step: 180, loss: 0.055287402123212814
step: 190, loss: 0.00014759371697437018
step: 200, loss: 1.359717316518072e-05
step: 210, loss: 0.00022002423065714538
step: 220, loss: 0.03077825903892517
step: 230, loss: 6.035634214640595e-05
step: 240, loss: 0.0016099680215120316
step: 250, loss: 3.0060784411034547e-05
step: 260, loss: 0.00012966063513886184
step: 270, loss: 4.634058859664947e-05
step: 280, loss: 3.267785723437555e-05
step: 290, loss: 0.00013285811292007565
step: 300, loss: 0.00019257456006016582
step: 310, loss: 2.7542475436348468e-05
step: 320, loss: 2.4536941054975614e-05
step: 330, loss: 0.00020853319438174367
epoch 19: dev_f1=0.786096256684492, f1=0.770408163265306, best_f1=0.7889908256880733
step: 0, loss: 5.033930574427359e-05
step: 10, loss: 0.0049764234572649
step: 20, loss: 1.728473034745548e-05
step: 30, loss: 1.7445257981307805e-05
step: 40, loss: 8.321359928231686e-05
step: 50, loss: 0.0046631768345832825
step: 60, loss: 0.00013284527813084424
step: 70, loss: 0.019073011353611946
step: 80, loss: 0.0016441135667264462
step: 90, loss: 0.00019711504864972085
step: 100, loss: 5.358639100450091e-05
step: 110, loss: 4.174423520453274e-05
step: 120, loss: 4.070158320246264e-05
step: 130, loss: 0.00021855978411622345
step: 140, loss: 1.3310289432411082e-05
step: 150, loss: 0.0005650653038173914
step: 160, loss: 4.534221443464048e-05
step: 170, loss: 1.5999543393263593e-05
step: 180, loss: 0.0011632011737674475
step: 190, loss: 5.9924812376266345e-05
step: 200, loss: 3.195323733962141e-05
step: 210, loss: 3.447935887379572e-05
step: 220, loss: 0.0008304768125526607
step: 230, loss: 8.487508603138849e-05
step: 240, loss: 3.2511696190340444e-05
step: 250, loss: 1.4442681276705116e-05
step: 260, loss: 0.0012156445300206542
step: 270, loss: 5.2397415856830776e-05
step: 280, loss: 2.7568134100874886e-05
step: 290, loss: 1.2650890312215779e-05
step: 300, loss: 0.015254072844982147
step: 310, loss: 5.966434036963619e-05
step: 320, loss: 0.0013865800574421883
step: 330, loss: 4.032122524222359e-05
epoch 20: dev_f1=0.7855297157622738, f1=0.775, best_f1=0.7889908256880733
