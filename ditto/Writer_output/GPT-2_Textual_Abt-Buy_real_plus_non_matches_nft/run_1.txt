cuda
Device: cuda
step: 0, loss: 0.6488931775093079
step: 10, loss: 0.3004859387874603
step: 20, loss: 0.1443338841199875
step: 30, loss: 0.2353404462337494
step: 40, loss: 0.1360485553741455
step: 50, loss: 0.22501958906650543
step: 60, loss: 0.2460722029209137
step: 70, loss: 0.22619792819023132
step: 80, loss: 0.17080369591712952
step: 90, loss: 0.1900474578142166
step: 100, loss: 0.04349663853645325
step: 110, loss: 0.15364210307598114
step: 120, loss: 0.13248786330223083
step: 130, loss: 0.14677560329437256
step: 140, loss: 0.283957839012146
step: 150, loss: 0.1450703889131546
step: 160, loss: 0.23711004853248596
step: 170, loss: 0.20587199926376343
step: 180, loss: 0.3167915344238281
step: 190, loss: 0.0739351287484169
step: 200, loss: 0.2537634074687958
step: 210, loss: 0.21285496652126312
step: 220, loss: 0.059183403849601746
step: 230, loss: 0.2546086013317108
step: 240, loss: 0.09828085452318192
step: 250, loss: 0.23840098083019257
step: 260, loss: 0.2159970998764038
step: 270, loss: 0.20232735574245453
step: 280, loss: 0.12610217928886414
step: 290, loss: 0.1036609560251236
step: 300, loss: 0.4241493344306946
step: 310, loss: 0.16727282106876373
step: 320, loss: 0.31178590655326843
step: 330, loss: 0.07475367188453674
epoch 1: dev_f1=0.2780638516992791, f1=0.2591093117408907, best_f1=0.2591093117408907
step: 0, loss: 0.1836865246295929
step: 10, loss: 0.05133056640625
step: 20, loss: 0.674302875995636
step: 30, loss: 0.220291405916214
step: 40, loss: 0.06240313500165939
step: 50, loss: 0.16215993463993073
step: 60, loss: 0.11413227766752243
step: 70, loss: 0.09185903519392014
step: 80, loss: 0.2461790144443512
step: 90, loss: 0.02897646091878414
step: 100, loss: 0.45774978399276733
step: 110, loss: 0.12612541019916534
step: 120, loss: 0.042388301342725754
step: 130, loss: 0.21223008632659912
step: 140, loss: 0.28237268328666687
step: 150, loss: 0.08592690527439117
step: 160, loss: 0.20557940006256104
step: 170, loss: 0.17353089153766632
step: 180, loss: 0.14062118530273438
step: 190, loss: 0.06012032926082611
step: 200, loss: 0.18235300481319427
step: 210, loss: 0.19909535348415375
step: 220, loss: 0.07485733181238174
step: 230, loss: 0.0878014788031578
step: 240, loss: 0.2370454967021942
step: 250, loss: 0.10396312922239304
step: 260, loss: 0.2281924933195114
step: 270, loss: 0.22115859389305115
step: 280, loss: 0.20084084570407867
step: 290, loss: 0.13464675843715668
step: 300, loss: 0.061002831906080246
step: 310, loss: 0.121403768658638
step: 320, loss: 0.06402317434549332
step: 330, loss: 0.18162807822227478
epoch 2: dev_f1=0.7463312368972744, f1=0.7, best_f1=0.7
step: 0, loss: 0.08450795710086823
step: 10, loss: 0.006772978231310844
step: 20, loss: 0.037125129252672195
step: 30, loss: 0.05037005618214607
step: 40, loss: 0.0776604562997818
step: 50, loss: 0.014551062136888504
step: 60, loss: 0.015329382382333279
step: 70, loss: 0.014040322974324226
step: 80, loss: 0.05184001103043556
step: 90, loss: 0.06925949454307556
step: 100, loss: 0.167459174990654
step: 110, loss: 0.04446528106927872
step: 120, loss: 0.1287725269794464
step: 130, loss: 0.0181280504912138
step: 140, loss: 0.1413792371749878
step: 150, loss: 0.004573950543999672
step: 160, loss: 0.09609775245189667
step: 170, loss: 0.11607091873884201
step: 180, loss: 0.03738256171345711
step: 190, loss: 0.08320401608943939
step: 200, loss: 0.006858469918370247
step: 210, loss: 0.034627098590135574
step: 220, loss: 0.0568397119641304
step: 230, loss: 0.04400160536170006
step: 240, loss: 0.14897054433822632
step: 250, loss: 0.1160406619310379
step: 260, loss: 0.01830260269343853
step: 270, loss: 0.1412600874900818
step: 280, loss: 0.03689039498567581
step: 290, loss: 0.04878288507461548
step: 300, loss: 0.04790916666388512
step: 310, loss: 0.14932259917259216
step: 320, loss: 0.09406154602766037
step: 330, loss: 0.04033432900905609
epoch 3: dev_f1=0.8030303030303031, f1=0.742014742014742, best_f1=0.742014742014742
step: 0, loss: 0.035047367215156555
step: 10, loss: 0.14622196555137634
step: 20, loss: 0.006279476918280125
step: 30, loss: 0.030027277767658234
step: 40, loss: 0.018331345170736313
step: 50, loss: 0.07710909843444824
step: 60, loss: 0.054712679237127304
step: 70, loss: 0.1104000136256218
step: 80, loss: 0.04062259569764137
step: 90, loss: 0.21132256090641022
step: 100, loss: 0.09644243121147156
step: 110, loss: 0.01655462756752968
step: 120, loss: 0.026400301605463028
step: 130, loss: 0.06479541957378387
step: 140, loss: 0.03062533773481846
step: 150, loss: 0.08978166431188583
step: 160, loss: 0.2171618938446045
step: 170, loss: 0.006965204142034054
step: 180, loss: 0.01111389696598053
step: 190, loss: 0.05116204172372818
step: 200, loss: 0.009458226151764393
step: 210, loss: 0.07824834436178207
step: 220, loss: 0.13324686884880066
step: 230, loss: 0.0035118339583277702
step: 240, loss: 0.05571277439594269
step: 250, loss: 0.004908401053398848
step: 260, loss: 0.013363703154027462
step: 270, loss: 0.014482859522104263
step: 280, loss: 0.009516122750937939
step: 290, loss: 0.025523057207465172
step: 300, loss: 0.10045824944972992
step: 310, loss: 0.0627366453409195
step: 320, loss: 0.08559057116508484
step: 330, loss: 0.09510861337184906
epoch 4: dev_f1=0.8105515587529976, f1=0.7599067599067598, best_f1=0.7599067599067598
step: 0, loss: 0.026727978140115738
step: 10, loss: 0.03035135567188263
step: 20, loss: 0.011544684879481792
step: 30, loss: 0.10958069562911987
step: 40, loss: 0.011732674203813076
step: 50, loss: 0.004172173794358969
step: 60, loss: 0.04596100375056267
step: 70, loss: 0.16679134964942932
step: 80, loss: 0.010286283679306507
step: 90, loss: 0.020927539095282555
step: 100, loss: 0.0033359962981194258
step: 110, loss: 0.046732787042856216
step: 120, loss: 0.023419475182890892
step: 130, loss: 0.011955187655985355
step: 140, loss: 0.014340393245220184
step: 150, loss: 0.003385960590094328
step: 160, loss: 0.006806368939578533
step: 170, loss: 0.04759842902421951
step: 180, loss: 0.016000129282474518
step: 190, loss: 0.01676500216126442
step: 200, loss: 0.03121032565832138
step: 210, loss: 0.003152610035613179
step: 220, loss: 0.04903751611709595
step: 230, loss: 0.030999450013041496
step: 240, loss: 0.054006464779376984
step: 250, loss: 0.08708465844392776
step: 260, loss: 0.015998532995581627
step: 270, loss: 0.0002951004425995052
step: 280, loss: 0.007318682037293911
step: 290, loss: 0.0011055551003664732
step: 300, loss: 0.11011876165866852
step: 310, loss: 0.03667010739445686
step: 320, loss: 0.1987905353307724
step: 330, loss: 0.009999915026128292
epoch 5: dev_f1=0.8060453400503778, f1=0.7581047381546135, best_f1=0.7599067599067598
step: 0, loss: 0.008384671062231064
step: 10, loss: 0.02261251024901867
step: 20, loss: 0.01727880910038948
step: 30, loss: 0.01073470339179039
step: 40, loss: 0.010913868434727192
step: 50, loss: 0.002533904043957591
step: 60, loss: 0.00276146805845201
step: 70, loss: 0.05889604240655899
step: 80, loss: 0.00797311868518591
step: 90, loss: 0.003337015863507986
step: 100, loss: 0.1112322211265564
step: 110, loss: 0.0781756117939949
step: 120, loss: 0.014050707221031189
step: 130, loss: 0.0662088692188263
step: 140, loss: 0.050693877041339874
step: 150, loss: 0.03811810538172722
step: 160, loss: 0.07739344984292984
step: 170, loss: 0.039050377905368805
step: 180, loss: 0.01759510301053524
step: 190, loss: 0.05389317497611046
step: 200, loss: 0.00022299416013993323
step: 210, loss: 0.031690165400505066
step: 220, loss: 0.0006387258181348443
step: 230, loss: 0.0020420437213033438
step: 240, loss: 0.0083170710131526
step: 250, loss: 0.032915569841861725
step: 260, loss: 0.009917094372212887
step: 270, loss: 0.004030444659292698
step: 280, loss: 0.03641185536980629
step: 290, loss: 0.0003733736521098763
step: 300, loss: 0.0034954927396029234
step: 310, loss: 0.007859199307858944
step: 320, loss: 0.013830739073455334
step: 330, loss: 0.004944159649312496
epoch 6: dev_f1=0.8428927680798006, f1=0.8361858190709045, best_f1=0.8361858190709045
step: 0, loss: 0.0011521236738190055
step: 10, loss: 0.034353144466876984
step: 20, loss: 0.006567145232111216
step: 30, loss: 0.019120091572403908
step: 40, loss: 0.014334681443870068
step: 50, loss: 0.0034331425558775663
step: 60, loss: 0.0518936924636364
step: 70, loss: 0.018694385886192322
step: 80, loss: 0.0024038157425820827
step: 90, loss: 0.0012798168463632464
step: 100, loss: 0.012835056520998478
step: 110, loss: 0.0007869041874073446
step: 120, loss: 0.14226029813289642
step: 130, loss: 0.0004263281880412251
step: 140, loss: 0.0006486723432317376
step: 150, loss: 0.004749655723571777
step: 160, loss: 0.00035860162461176515
step: 170, loss: 0.028510354459285736
step: 180, loss: 0.00021482715965248644
step: 190, loss: 0.001347418176010251
step: 200, loss: 0.06671340018510818
step: 210, loss: 0.014455487951636314
step: 220, loss: 0.0009419269626960158
step: 230, loss: 0.0018690178403630853
step: 240, loss: 0.003546717343851924
step: 250, loss: 0.0022674412466585636
step: 260, loss: 0.01893073320388794
step: 270, loss: 0.005482441745698452
step: 280, loss: 0.029909666627645493
step: 290, loss: 0.041783638298511505
step: 300, loss: 0.00024181882326956838
step: 310, loss: 0.009462148882448673
step: 320, loss: 0.02611631341278553
step: 330, loss: 0.008509818464517593
epoch 7: dev_f1=0.8321513002364066, f1=0.8, best_f1=0.8361858190709045
step: 0, loss: 0.00912376306951046
step: 10, loss: 0.002812859835103154
step: 20, loss: 0.00010862144699785858
step: 30, loss: 0.06665383279323578
step: 40, loss: 0.0011647621868178248
step: 50, loss: 0.0005959221161901951
step: 60, loss: 0.003766925074160099
step: 70, loss: 0.001204712432809174
step: 80, loss: 0.003064781194552779
step: 90, loss: 0.050411611795425415
step: 100, loss: 0.009762083180248737
step: 110, loss: 0.01595553755760193
step: 120, loss: 0.0033305296674370766
step: 130, loss: 0.002029627561569214
step: 140, loss: 0.010048179887235165
step: 150, loss: 0.021515512838959694
step: 160, loss: 0.0018209742847830057
step: 170, loss: 0.04723750054836273
step: 180, loss: 0.00048439702368341386
step: 190, loss: 0.0012472643284127116
step: 200, loss: 0.009260300546884537
step: 210, loss: 0.0005365065298974514
step: 220, loss: 8.516052184859291e-05
step: 230, loss: 0.0005521514685824513
step: 240, loss: 0.0008314027800224721
step: 250, loss: 0.0003685635165311396
step: 260, loss: 0.016978943720459938
step: 270, loss: 0.00045842098188586533
step: 280, loss: 0.02537870593369007
step: 290, loss: 0.0200343057513237
step: 300, loss: 0.005993572063744068
step: 310, loss: 0.00019329921633470803
step: 320, loss: 0.0011062400881201029
step: 330, loss: 0.01682761125266552
epoch 8: dev_f1=0.8321167883211679, f1=0.7872860635696822, best_f1=0.8361858190709045
step: 0, loss: 0.0035079638473689556
step: 10, loss: 0.0017234539845958352
step: 20, loss: 0.005184882786124945
step: 30, loss: 0.009007620625197887
step: 40, loss: 0.001120025641284883
step: 50, loss: 0.002676735632121563
step: 60, loss: 0.0010168076260015368
step: 70, loss: 0.005282403901219368
step: 80, loss: 0.035141877830028534
step: 90, loss: 0.006107026245445013
step: 100, loss: 0.00013426048099063337
step: 110, loss: 0.0005319771007634699
step: 120, loss: 0.009696152061223984
step: 130, loss: 0.0008524996810592711
step: 140, loss: 0.0003663092211354524
step: 150, loss: 0.028014644980430603
step: 160, loss: 0.0008310473058372736
step: 170, loss: 0.0019022691994905472
step: 180, loss: 9.137876622844487e-05
step: 190, loss: 0.0009465910843573511
step: 200, loss: 0.0004569167213048786
step: 210, loss: 0.03982285037636757
step: 220, loss: 0.16187137365341187
step: 230, loss: 0.00021608512906823307
step: 240, loss: 3.85739840567112e-05
step: 250, loss: 0.00022986895055510104
step: 260, loss: 0.006480158772319555
step: 270, loss: 0.0015200404450297356
step: 280, loss: 0.08642799407243729
step: 290, loss: 0.0005667691002599895
step: 300, loss: 0.002284588757902384
step: 310, loss: 0.00024245363601949066
step: 320, loss: 0.0013518085470423102
step: 330, loss: 0.014284873381257057
epoch 9: dev_f1=0.7980997624703088, f1=0.7918552036199096, best_f1=0.8361858190709045
step: 0, loss: 0.0025329950731247663
step: 10, loss: 0.004229898098856211
step: 20, loss: 0.005882966332137585
step: 30, loss: 0.0013970853760838509
step: 40, loss: 0.00013007919187657535
step: 50, loss: 0.030382106080651283
step: 60, loss: 0.026858391240239143
step: 70, loss: 0.00158818403724581
step: 80, loss: 0.0007240066188387573
step: 90, loss: 0.0041266921907663345
step: 100, loss: 0.007528277579694986
step: 110, loss: 0.0002660471072886139
step: 120, loss: 0.001544028171338141
step: 130, loss: 0.0069776964373886585
step: 140, loss: 0.00042356454650871456
step: 150, loss: 0.014873622916638851
step: 160, loss: 0.0027769573498517275
step: 170, loss: 0.03325770050287247
step: 180, loss: 9.42433180171065e-05
step: 190, loss: 0.00023544921714346856
step: 200, loss: 0.014492764137685299
step: 210, loss: 0.0005638477159664035
step: 220, loss: 0.006633547600358725
step: 230, loss: 4.113918839721009e-05
step: 240, loss: 0.00010115122131537646
step: 250, loss: 9.203125955536962e-05
step: 260, loss: 0.000250590848736465
step: 270, loss: 0.007482714019715786
step: 280, loss: 0.0018432392971590161
step: 290, loss: 0.0008195239352062345
step: 300, loss: 7.327173807425424e-05
step: 310, loss: 0.10647481679916382
step: 320, loss: 0.0003088732482865453
step: 330, loss: 0.00012545449135359377
epoch 10: dev_f1=0.8115183246073299, f1=0.8138957816377173, best_f1=0.8361858190709045
step: 0, loss: 9.394215885549784e-05
step: 10, loss: 0.00010461149940965697
step: 20, loss: 0.0002092409849865362
step: 30, loss: 0.0005618933355435729
step: 40, loss: 0.01979525201022625
step: 50, loss: 0.00154410139657557
step: 60, loss: 0.00650040851905942
step: 70, loss: 0.0008819744107313454
step: 80, loss: 0.003186386078596115
step: 90, loss: 0.019852986559271812
step: 100, loss: 0.0011060457909479737
step: 110, loss: 0.00026323014753870666
step: 120, loss: 0.0009227219852618873
step: 130, loss: 0.00010613614722387865
step: 140, loss: 0.0001543283142382279
step: 150, loss: 9.964377386495471e-05
step: 160, loss: 0.0018396740779280663
step: 170, loss: 0.04153231158852577
step: 180, loss: 0.00044965962297283113
step: 190, loss: 0.01608874648809433
step: 200, loss: 0.0005305838421918452
step: 210, loss: 0.0014004937838762999
step: 220, loss: 0.03278965502977371
step: 230, loss: 0.005224632099270821
step: 240, loss: 8.21856883703731e-05
step: 250, loss: 0.0005490707117132843
step: 260, loss: 3.2051026209956035e-05
step: 270, loss: 0.0011127118486911058
step: 280, loss: 0.00013979828509036452
step: 290, loss: 0.0001937746856128797
step: 300, loss: 0.002493320032954216
step: 310, loss: 0.00017382160876877606
step: 320, loss: 0.012797383591532707
step: 330, loss: 0.003240287071093917
epoch 11: dev_f1=0.8109452736318408, f1=0.79136690647482, best_f1=0.8361858190709045
step: 0, loss: 0.00011011290916940197
step: 10, loss: 0.03067079186439514
step: 20, loss: 0.0012736718636006117
step: 30, loss: 0.000679516582749784
step: 40, loss: 0.0032714582048356533
step: 50, loss: 0.00011156682739965618
step: 60, loss: 0.001968289725482464
step: 70, loss: 0.0011012390023097396
step: 80, loss: 6.870100332889706e-05
step: 90, loss: 6.660675717284903e-05
step: 100, loss: 0.0008554438827559352
step: 110, loss: 0.00025655640638433397
step: 120, loss: 9.840511484071612e-05
step: 130, loss: 0.002212260151281953
step: 140, loss: 0.006620422936975956
step: 150, loss: 0.013267507776618004
step: 160, loss: 0.0003425906761549413
step: 170, loss: 0.00987347960472107
step: 180, loss: 0.003686213633045554
step: 190, loss: 4.790943785337731e-05
step: 200, loss: 0.15783290565013885
step: 210, loss: 0.015295666642487049
step: 220, loss: 0.0027446546591818333
step: 230, loss: 0.0004566445422824472
step: 240, loss: 0.0029580756090581417
step: 250, loss: 0.02159123122692108
step: 260, loss: 0.00013928495172876865
step: 270, loss: 0.00063766457606107
step: 280, loss: 0.0053506214171648026
step: 290, loss: 0.00189941783901304
step: 300, loss: 0.0018258658237755299
step: 310, loss: 0.011510660871863365
step: 320, loss: 0.0011583466548472643
step: 330, loss: 0.00044497434282675385
epoch 12: dev_f1=0.8053333333333333, f1=0.7969924812030076, best_f1=0.8361858190709045
step: 0, loss: 0.009416312910616398
step: 10, loss: 0.008520025759935379
step: 20, loss: 0.004053428303450346
step: 30, loss: 0.0005415066843852401
step: 40, loss: 0.0002837854262907058
step: 50, loss: 0.0001442564243916422
step: 60, loss: 0.001188280526548624
step: 70, loss: 7.780086161801592e-05
step: 80, loss: 4.961025479133241e-05
step: 90, loss: 0.0005595040274783969
step: 100, loss: 0.06848223507404327
step: 110, loss: 0.00014182302402332425
step: 120, loss: 0.0022254695650190115
step: 130, loss: 0.002198419999331236
step: 140, loss: 0.0006497990107163787
step: 150, loss: 0.002852418227121234
step: 160, loss: 0.00027565215714275837
step: 170, loss: 0.00028843042673543096
step: 180, loss: 7.883002399466932e-05
step: 190, loss: 0.00021546609059441835
step: 200, loss: 0.00011912858462892473
step: 210, loss: 0.0003641463699750602
step: 220, loss: 9.420082642463967e-05
step: 230, loss: 0.00019668592722155154
step: 240, loss: 0.0001947752753039822
step: 250, loss: 0.001574740861542523
step: 260, loss: 6.779719842597842e-05
step: 270, loss: 5.583603706327267e-05
step: 280, loss: 0.020411500707268715
step: 290, loss: 0.00010248785838484764
step: 300, loss: 0.003625130280852318
step: 310, loss: 0.000682273821439594
step: 320, loss: 5.716815576306544e-05
step: 330, loss: 2.0372812286950648e-05
epoch 13: dev_f1=0.7947368421052633, f1=0.7769423558897243, best_f1=0.8361858190709045
step: 0, loss: 0.0005425633280538023
step: 10, loss: 4.897777398582548e-05
step: 20, loss: 0.0010705407476052642
step: 30, loss: 0.001642874674871564
step: 40, loss: 0.020885618403553963
step: 50, loss: 0.025976626202464104
step: 60, loss: 7.467727118637413e-05
step: 70, loss: 0.00016032499843277037
step: 80, loss: 0.0002530402271077037
step: 90, loss: 0.00012442753359209746
step: 100, loss: 4.287641786504537e-05
step: 110, loss: 0.0001485004322603345
step: 120, loss: 0.0010359237203374505
step: 130, loss: 0.0006465992191806436
step: 140, loss: 0.00023850657453294843
step: 150, loss: 0.0002698407042771578
step: 160, loss: 0.00017199436842929572
step: 170, loss: 0.009250679984688759
step: 180, loss: 7.158468361012638e-05
step: 190, loss: 0.0009766281582415104
step: 200, loss: 0.0002588138449937105
step: 210, loss: 0.00010711673530749977
step: 220, loss: 0.00018748067668639123
step: 230, loss: 3.684137845993973e-05
step: 240, loss: 0.02415565773844719
step: 250, loss: 0.0009676909539848566
step: 260, loss: 0.000778135028667748
step: 270, loss: 4.0789043850963935e-05
step: 280, loss: 0.009430287405848503
step: 290, loss: 0.00032476347405463457
step: 300, loss: 0.009647893719375134
step: 310, loss: 2.388216853432823e-05
step: 320, loss: 8.67728449520655e-05
step: 330, loss: 7.443328649969772e-05
epoch 14: dev_f1=0.826530612244898, f1=0.7980535279805353, best_f1=0.8361858190709045
step: 0, loss: 0.008557072840631008
step: 10, loss: 0.00024577724980190396
step: 20, loss: 5.2176306780893356e-05
step: 30, loss: 0.0010327876079827547
step: 40, loss: 0.0006046922062523663
step: 50, loss: 0.0007592792389914393
step: 60, loss: 0.003889248473569751
step: 70, loss: 6.820121052442119e-05
step: 80, loss: 5.372183659346774e-05
step: 90, loss: 0.00018763623666018248
step: 100, loss: 7.834041025489569e-05
step: 110, loss: 2.565522117947694e-05
step: 120, loss: 7.165307033574209e-05
step: 130, loss: 0.0020121182315051556
step: 140, loss: 3.149536132696085e-05
step: 150, loss: 2.8288570320000872e-05
step: 160, loss: 6.74826733302325e-05
step: 170, loss: 2.9357208404690027e-05
step: 180, loss: 0.00018066498159896582
step: 190, loss: 0.0003623982483986765
step: 200, loss: 0.0001360266760457307
step: 210, loss: 0.05346669629216194
step: 220, loss: 0.0014616706175729632
step: 230, loss: 1.6659279935993254e-05
step: 240, loss: 1.5914232790237293e-05
step: 250, loss: 0.00048064003931358457
step: 260, loss: 4.205647564958781e-05
step: 270, loss: 0.0004747615894302726
step: 280, loss: 0.0006316225626505911
step: 290, loss: 8.647534559713677e-05
step: 300, loss: 0.00298767676576972
step: 310, loss: 0.0001238242839463055
step: 320, loss: 0.00010786861821543425
step: 330, loss: 0.00022996545885689557
epoch 15: dev_f1=0.8215158924205379, f1=0.8047619047619048, best_f1=0.8361858190709045
step: 0, loss: 0.00022171575983520597
step: 10, loss: 0.0005042930133640766
step: 20, loss: 0.025126198306679726
step: 30, loss: 0.0003256157215218991
step: 40, loss: 0.0008596611442044377
step: 50, loss: 7.276013639057055e-05
step: 60, loss: 4.5132033847039565e-05
step: 70, loss: 6.861379370093346e-05
step: 80, loss: 0.0016565417172387242
step: 90, loss: 0.003965476527810097
step: 100, loss: 0.00010253156506223604
step: 110, loss: 0.00012336942018009722
step: 120, loss: 5.406086711445823e-05
step: 130, loss: 0.00022278103278949857
step: 140, loss: 0.0014903182163834572
step: 150, loss: 0.00021171710977796465
step: 160, loss: 0.0010880703339353204
step: 170, loss: 0.001045724144205451
step: 180, loss: 7.014651782810688e-05
step: 190, loss: 4.6516594011336565e-05
step: 200, loss: 0.00018092851678375155
step: 210, loss: 4.742621604236774e-05
step: 220, loss: 0.03561863675713539
step: 230, loss: 0.00023229407088365406
step: 240, loss: 5.57355560886208e-05
step: 250, loss: 0.00017563020810484886
step: 260, loss: 7.279445708263665e-05
step: 270, loss: 0.007997000589966774
step: 280, loss: 2.3487436919822358e-05
step: 290, loss: 0.0018177207093685865
step: 300, loss: 0.0008859597728587687
step: 310, loss: 0.00010041687346529216
step: 320, loss: 0.0002099896955769509
step: 330, loss: 0.00011151227954542264
epoch 16: dev_f1=0.813131313131313, f1=0.7802469135802469, best_f1=0.8361858190709045
step: 0, loss: 0.00011234649718971923
step: 10, loss: 2.006037175306119e-05
step: 20, loss: 0.00014362444926518947
step: 30, loss: 0.03023788146674633
step: 40, loss: 0.0006839227862656116
step: 50, loss: 0.0003013031673617661
step: 60, loss: 0.0004181322001386434
step: 70, loss: 6.53849056106992e-05
step: 80, loss: 0.00010195789946010336
step: 90, loss: 0.0005781976506114006
step: 100, loss: 5.1822604291373864e-05
step: 110, loss: 4.866719609708525e-05
step: 120, loss: 0.0002868250012397766
step: 130, loss: 0.0013288080226629972
step: 140, loss: 0.0036127539351582527
step: 150, loss: 0.0035109142772853374
step: 160, loss: 0.00017931972979567945
step: 170, loss: 0.00022771728981751949
step: 180, loss: 0.00017443016986362636
step: 190, loss: 0.00017735903384163976
step: 200, loss: 0.0014245674246922135
step: 210, loss: 0.000267634546617046
step: 220, loss: 5.9259109548293054e-05
step: 230, loss: 5.7764667872106656e-05
step: 240, loss: 0.007590263616293669
step: 250, loss: 6.668279092991725e-05
step: 260, loss: 0.0002771703584585339
step: 270, loss: 0.00023611096548847854
step: 280, loss: 0.0002621356397867203
step: 290, loss: 0.00022136956977192312
step: 300, loss: 0.00013724862947128713
step: 310, loss: 0.005174562335014343
step: 320, loss: 0.0001573366462253034
step: 330, loss: 0.0002237551670987159
epoch 17: dev_f1=0.8146341463414632, f1=0.8009478672985781, best_f1=0.8361858190709045
step: 0, loss: 4.455277303350158e-05
step: 10, loss: 0.00010898678738158196
step: 20, loss: 0.00020758614118676633
step: 30, loss: 6.582129572052509e-05
step: 40, loss: 0.038382042199373245
step: 50, loss: 9.008924826048315e-05
step: 60, loss: 4.507173798629083e-05
step: 70, loss: 0.00011907138832611963
step: 80, loss: 0.0004466570680961013
step: 90, loss: 0.19735771417617798
step: 100, loss: 0.00011766004172386602
step: 110, loss: 0.0004597027145791799
step: 120, loss: 0.007664866745471954
step: 130, loss: 0.0005002862890250981
step: 140, loss: 0.0010338134597986937
step: 150, loss: 0.00017015571938827634
step: 160, loss: 0.00019471836276352406
step: 170, loss: 0.04079849645495415
step: 180, loss: 0.0006664005341008306
step: 190, loss: 3.64348161383532e-05
step: 200, loss: 0.0003367955796420574
step: 210, loss: 0.001205746317282319
step: 220, loss: 0.0001539938966743648
step: 230, loss: 0.0019561112858355045
step: 240, loss: 0.0010155682684853673
step: 250, loss: 0.0016208243323490024
step: 260, loss: 0.0003468454524409026
step: 270, loss: 0.0001899562921607867
step: 280, loss: 0.00019878616149071604
step: 290, loss: 9.69841712503694e-05
step: 300, loss: 5.690258331014775e-05
step: 310, loss: 5.0954564358107746e-05
step: 320, loss: 5.10165627929382e-05
step: 330, loss: 4.000649641966447e-05
epoch 18: dev_f1=0.8181818181818181, f1=0.8028846153846153, best_f1=0.8361858190709045
step: 0, loss: 0.00029102261760272086
step: 10, loss: 0.0005412056343629956
step: 20, loss: 3.550295878085308e-05
step: 30, loss: 0.00023971333575900644
step: 40, loss: 0.0004059640923514962
step: 50, loss: 0.003770793555304408
step: 60, loss: 0.00014831451699137688
step: 70, loss: 0.0457683764398098
step: 80, loss: 4.14803325838875e-05
step: 90, loss: 0.0034247352741658688
step: 100, loss: 0.0008574138628318906
step: 110, loss: 0.02523564174771309
step: 120, loss: 1.8775206626742147e-05
step: 130, loss: 3.219132122467272e-05
step: 140, loss: 0.00017657542775850743
step: 150, loss: 0.0001264238526346162
step: 160, loss: 0.00020119162218179554
step: 170, loss: 0.021420607343316078
step: 180, loss: 0.014392110519111156
step: 190, loss: 3.178603947162628e-05
step: 200, loss: 0.0002167180646210909
step: 210, loss: 0.00033677215105853975
step: 220, loss: 9.035543189384043e-05
step: 230, loss: 4.997148425900377e-05
step: 240, loss: 0.0009506551432423294
step: 250, loss: 0.00026689618243835866
step: 260, loss: 0.06464357674121857
step: 270, loss: 4.656687815440819e-05
step: 280, loss: 5.1226910727564245e-05
step: 290, loss: 2.356176446483005e-05
step: 300, loss: 7.18611481715925e-05
step: 310, loss: 0.00012220669304952025
step: 320, loss: 6.459691940108314e-05
step: 330, loss: 0.0003649702703114599
epoch 19: dev_f1=0.7978723404255318, f1=0.7909319899244334, best_f1=0.8361858190709045
step: 0, loss: 5.6869863328756765e-05
step: 10, loss: 7.827350054867566e-05
step: 20, loss: 0.00011593823001021519
step: 30, loss: 0.00018546909268479794
step: 40, loss: 0.00016565520490985364
step: 50, loss: 9.795270307222381e-05
step: 60, loss: 0.00035229368950240314
step: 70, loss: 0.0047345636412501335
step: 80, loss: 0.010170756839215755
step: 90, loss: 0.00021243536320980638
step: 100, loss: 3.704884511535056e-05
step: 110, loss: 0.00042627457878552377
step: 120, loss: 0.00017592753283679485
step: 130, loss: 0.005647356156259775
step: 140, loss: 0.000293232558760792
step: 150, loss: 9.67984669841826e-05
step: 160, loss: 2.4139280867530033e-05
step: 170, loss: 2.909342583734542e-05
step: 180, loss: 7.594075577799231e-05
step: 190, loss: 0.0001726730406517163
step: 200, loss: 3.522380575304851e-05
step: 210, loss: 0.02440805733203888
step: 220, loss: 5.533726289286278e-05
step: 230, loss: 5.116160536999814e-05
step: 240, loss: 2.979296914418228e-05
step: 250, loss: 0.05034603923559189
step: 260, loss: 9.588480315869674e-05
step: 270, loss: 8.529129263479263e-05
step: 280, loss: 7.82427960075438e-05
step: 290, loss: 1.8678245396586135e-05
step: 300, loss: 4.076988261658698e-05
step: 310, loss: 0.00015044910833239555
step: 320, loss: 2.231028520327527e-05
step: 330, loss: 3.105635551037267e-05
epoch 20: dev_f1=0.8132992327365729, f1=0.8019323671497586, best_f1=0.8361858190709045
