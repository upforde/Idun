cuda
Device: cuda
step: 0, loss: 0.9444172978401184
step: 10, loss: 0.4861038029193878
step: 20, loss: 0.23731783032417297
step: 30, loss: 0.2438071370124817
step: 40, loss: 0.22905199229717255
step: 50, loss: 0.30382242798805237
step: 60, loss: 0.22693362832069397
step: 70, loss: 0.2208121120929718
step: 80, loss: 0.530856192111969
step: 90, loss: 0.06544455885887146
step: 100, loss: 0.04384072870016098
step: 110, loss: 0.15314233303070068
step: 120, loss: 0.5176730155944824
step: 130, loss: 0.20813214778900146
step: 140, loss: 0.21772123873233795
step: 150, loss: 0.1422795206308365
step: 160, loss: 0.1528751105070114
step: 170, loss: 0.12991945445537567
step: 180, loss: 0.14056448638439178
step: 190, loss: 0.29699966311454773
step: 200, loss: 0.1342555433511734
step: 210, loss: 0.2450380027294159
step: 220, loss: 0.05084439367055893
step: 230, loss: 0.08072519302368164
step: 240, loss: 0.03938913717865944
step: 250, loss: 0.1568612903356552
step: 260, loss: 0.17063499987125397
step: 270, loss: 0.20925481617450714
step: 280, loss: 0.40504151582717896
step: 290, loss: 0.15162330865859985
step: 300, loss: 0.11863352358341217
step: 310, loss: 0.027890194207429886
step: 320, loss: 0.16325174272060394
step: 330, loss: 0.1469988077878952
epoch 1: dev_f1=0.3024523160762943, f1=0.28843537414965986, best_f1=0.28843537414965986
step: 0, loss: 0.2573046088218689
step: 10, loss: 0.027220049872994423
step: 20, loss: 0.20243553817272186
step: 30, loss: 0.12872497737407684
step: 40, loss: 0.0884375050663948
step: 50, loss: 0.2588959038257599
step: 60, loss: 0.0364045649766922
step: 70, loss: 0.18152141571044922
step: 80, loss: 0.21585805714130402
step: 90, loss: 0.32641398906707764
step: 100, loss: 0.20116977393627167
step: 110, loss: 0.08749005198478699
step: 120, loss: 0.037387553602457047
step: 130, loss: 0.11195948719978333
step: 140, loss: 0.1505567878484726
step: 150, loss: 0.39529797434806824
step: 160, loss: 0.18979144096374512
step: 170, loss: 0.08171908557415009
step: 180, loss: 0.1284146010875702
step: 190, loss: 0.2609618306159973
step: 200, loss: 0.06078853830695152
step: 210, loss: 0.3003671169281006
step: 220, loss: 0.11858174204826355
step: 230, loss: 0.02515385113656521
step: 240, loss: 0.03514735400676727
step: 250, loss: 0.08151000738143921
step: 260, loss: 0.09703639149665833
step: 270, loss: 0.1385611891746521
step: 280, loss: 0.21228894591331482
step: 290, loss: 0.013389604166150093
step: 300, loss: 0.10697522759437561
step: 310, loss: 0.13799411058425903
step: 320, loss: 0.08294610679149628
step: 330, loss: 0.12345379590988159
epoch 2: dev_f1=0.556390977443609, f1=0.578005115089514, best_f1=0.578005115089514
step: 0, loss: 0.04382791370153427
step: 10, loss: 0.03880535438656807
step: 20, loss: 0.010678686201572418
step: 30, loss: 0.13213500380516052
step: 40, loss: 0.03417094051837921
step: 50, loss: 0.031296662986278534
step: 60, loss: 0.24494987726211548
step: 70, loss: 0.02522895857691765
step: 80, loss: 0.10003375262022018
step: 90, loss: 0.05599313974380493
step: 100, loss: 0.11729837954044342
step: 110, loss: 0.06715184450149536
step: 120, loss: 0.095180444419384
step: 130, loss: 0.12519173324108124
step: 140, loss: 0.1905500441789627
step: 150, loss: 0.051224712282419205
step: 160, loss: 0.0536089725792408
step: 170, loss: 0.1616457998752594
step: 180, loss: 0.3422461450099945
step: 190, loss: 0.10146526992321014
step: 200, loss: 0.14269623160362244
step: 210, loss: 0.04356412962079048
step: 220, loss: 0.05863753706216812
step: 230, loss: 0.0035394872538745403
step: 240, loss: 0.10824102908372879
step: 250, loss: 0.006603737827390432
step: 260, loss: 0.017629101872444153
step: 270, loss: 0.07630220055580139
step: 280, loss: 0.02852405048906803
step: 290, loss: 0.11602714657783508
step: 300, loss: 0.10051488876342773
step: 310, loss: 0.02897142805159092
step: 320, loss: 0.033124200999736786
step: 330, loss: 0.050669822841882706
epoch 3: dev_f1=0.7597254004576659, f1=0.7268408551068883, best_f1=0.7268408551068883
step: 0, loss: 0.06525033712387085
step: 10, loss: 0.05437927693128586
step: 20, loss: 0.05542035028338432
step: 30, loss: 0.004858776926994324
step: 40, loss: 0.04733140021562576
step: 50, loss: 0.07088080793619156
step: 60, loss: 0.08855924010276794
step: 70, loss: 0.01110990159213543
step: 80, loss: 0.029421813786029816
step: 90, loss: 0.13151668012142181
step: 100, loss: 0.02961253561079502
step: 110, loss: 0.1690310537815094
step: 120, loss: 0.02102113515138626
step: 130, loss: 0.11488524824380875
step: 140, loss: 0.020261012017726898
step: 150, loss: 0.05218198522925377
step: 160, loss: 0.01990477927029133
step: 170, loss: 0.009630297310650349
step: 180, loss: 0.02440636418759823
step: 190, loss: 0.11367028206586838
step: 200, loss: 0.07474047690629959
step: 210, loss: 0.027013925835490227
step: 220, loss: 0.3645850419998169
step: 230, loss: 0.06525146961212158
step: 240, loss: 0.04419966787099838
step: 250, loss: 0.05917806923389435
step: 260, loss: 0.01806577481329441
step: 270, loss: 0.1949586570262909
step: 280, loss: 0.029163993895053864
step: 290, loss: 0.08760467171669006
step: 300, loss: 0.06975815445184708
step: 310, loss: 0.02901269681751728
step: 320, loss: 0.02637200616300106
step: 330, loss: 0.16921699047088623
epoch 4: dev_f1=0.7674943566591421, f1=0.7674943566591421, best_f1=0.7674943566591421
step: 0, loss: 0.03838130459189415
step: 10, loss: 0.0037987842224538326
step: 20, loss: 0.07213466614484787
step: 30, loss: 0.06279835850000381
step: 40, loss: 0.08893099427223206
step: 50, loss: 0.06563913077116013
step: 60, loss: 0.05454760044813156
step: 70, loss: 0.0006159655167721212
step: 80, loss: 0.04032090678811073
step: 90, loss: 0.011036631651222706
step: 100, loss: 0.13126955926418304
step: 110, loss: 0.13562260568141937
step: 120, loss: 0.012562790885567665
step: 130, loss: 0.1035461574792862
step: 140, loss: 0.06578585505485535
step: 150, loss: 0.022436680272221565
step: 160, loss: 0.0031775624956935644
step: 170, loss: 0.014515443705022335
step: 180, loss: 0.044077057391405106
step: 190, loss: 0.010837960056960583
step: 200, loss: 0.170852392911911
step: 210, loss: 0.04685758054256439
step: 220, loss: 0.08505366742610931
step: 230, loss: 0.02223346009850502
step: 240, loss: 0.13700398802757263
step: 250, loss: 0.015932556241750717
step: 260, loss: 0.11057177186012268
step: 270, loss: 0.10070706158876419
step: 280, loss: 0.05829541012644768
step: 290, loss: 0.04602077975869179
step: 300, loss: 0.07249490916728973
step: 310, loss: 0.1063581183552742
step: 320, loss: 0.054974544793367386
step: 330, loss: 0.006031365133821964
epoch 5: dev_f1=0.7767441860465116, f1=0.7636363636363637, best_f1=0.7636363636363637
step: 0, loss: 0.004504486918449402
step: 10, loss: 0.03285898268222809
step: 20, loss: 0.0014067953452467918
step: 30, loss: 0.06671177595853806
step: 40, loss: 0.0009692080202512443
step: 50, loss: 0.003435129066929221
step: 60, loss: 0.003456437960267067
step: 70, loss: 0.000673711474519223
step: 80, loss: 0.0018161272164434195
step: 90, loss: 0.0011460621608421206
step: 100, loss: 0.04335896298289299
step: 110, loss: 0.1671942174434662
step: 120, loss: 0.002292229328304529
step: 130, loss: 0.0015828772448003292
step: 140, loss: 0.07041927427053452
step: 150, loss: 0.07423070818185806
step: 160, loss: 0.04374223202466965
step: 170, loss: 0.0024466020986437798
step: 180, loss: 0.005642097443342209
step: 190, loss: 0.00024598074378445745
step: 200, loss: 0.03538154810667038
step: 210, loss: 0.006994741037487984
step: 220, loss: 0.010758653283119202
step: 230, loss: 0.001698650186881423
step: 240, loss: 0.00042945294990204275
step: 250, loss: 0.01709059067070484
step: 260, loss: 0.018563099205493927
step: 270, loss: 0.0050799790769815445
step: 280, loss: 0.004736472386866808
step: 290, loss: 0.0010508253471925855
step: 300, loss: 0.03853820264339447
step: 310, loss: 0.036192215979099274
step: 320, loss: 0.0012479646829888225
step: 330, loss: 0.06640146672725677
epoch 6: dev_f1=0.7867298578199052, f1=0.7893569844789358, best_f1=0.7893569844789358
step: 0, loss: 0.007574943825602531
step: 10, loss: 0.03148433193564415
step: 20, loss: 0.00546896830201149
step: 30, loss: 0.07116098701953888
step: 40, loss: 0.029339753091335297
step: 50, loss: 0.002315624849870801
step: 60, loss: 0.009953663684427738
step: 70, loss: 0.009250597096979618
step: 80, loss: 0.004534940235316753
step: 90, loss: 0.019017957150936127
step: 100, loss: 0.0034111025743186474
step: 110, loss: 0.0017088771564885974
step: 120, loss: 0.04176250472664833
step: 130, loss: 0.010067304596304893
step: 140, loss: 0.0003677012282423675
step: 150, loss: 0.0017997261602431536
step: 160, loss: 0.0016721541760489345
step: 170, loss: 0.0026029301807284355
step: 180, loss: 0.0009169313125312328
step: 190, loss: 0.0552913062274456
step: 200, loss: 0.198682501912117
step: 210, loss: 0.00460633123293519
step: 220, loss: 0.006751800421625376
step: 230, loss: 0.0002683835045900196
step: 240, loss: 0.00022051452833693475
step: 250, loss: 0.00021037906117271632
step: 260, loss: 0.004451461602002382
step: 270, loss: 0.01004709117114544
step: 280, loss: 0.0007754344260320067
step: 290, loss: 0.003303773468360305
step: 300, loss: 0.007827970199286938
step: 310, loss: 0.001960656838491559
step: 320, loss: 0.0016783755272626877
step: 330, loss: 0.010193373076617718
epoch 7: dev_f1=0.7767441860465116, f1=0.7873303167420815, best_f1=0.7893569844789358
step: 0, loss: 0.026749469339847565
step: 10, loss: 0.008006339892745018
step: 20, loss: 0.0010397020960226655
step: 30, loss: 0.05419067293405533
step: 40, loss: 0.13078409433364868
step: 50, loss: 0.03503210470080376
step: 60, loss: 0.025381341576576233
step: 70, loss: 0.09917108714580536
step: 80, loss: 0.0008271094411611557
step: 90, loss: 0.0007869083783589303
step: 100, loss: 0.026200605556368828
step: 110, loss: 0.0007771765813231468
step: 120, loss: 0.0003963838389609009
step: 130, loss: 0.0011485746363177896
step: 140, loss: 0.02813398465514183
step: 150, loss: 0.00043016666313633323
step: 160, loss: 0.0013965992256999016
step: 170, loss: 0.0006181923672556877
step: 180, loss: 0.0003061383031308651
step: 190, loss: 0.00045329605927690864
step: 200, loss: 0.00031593930907547474
step: 210, loss: 0.0010658351238816977
step: 220, loss: 0.05701109394431114
step: 230, loss: 0.004830662161111832
step: 240, loss: 0.016857381910085678
step: 250, loss: 0.028871800750494003
step: 260, loss: 8.156039984896779e-05
step: 270, loss: 0.0001859990443335846
step: 280, loss: 0.00014787660620640963
step: 290, loss: 9.924494224833325e-05
step: 300, loss: 9.805407171370462e-05
step: 310, loss: 0.006552856415510178
step: 320, loss: 0.0008713810821063817
step: 330, loss: 0.00027874737861566246
epoch 8: dev_f1=0.7943262411347518, f1=0.7935034802784221, best_f1=0.7935034802784221
step: 0, loss: 0.0033232502173632383
step: 10, loss: 0.0026894365437328815
step: 20, loss: 0.0010884265648201108
step: 30, loss: 0.015897182747721672
step: 40, loss: 0.02805461920797825
step: 50, loss: 0.0005088103353045881
step: 60, loss: 3.763773929676972e-05
step: 70, loss: 0.00031450216192752123
step: 80, loss: 0.006478453055024147
step: 90, loss: 0.08450184762477875
step: 100, loss: 0.009792312979698181
step: 110, loss: 0.01962890289723873
step: 120, loss: 4.020905907964334e-05
step: 130, loss: 0.00014843115059193224
step: 140, loss: 0.011490248143672943
step: 150, loss: 0.09542524814605713
step: 160, loss: 0.08882208168506622
step: 170, loss: 3.1630435842089355e-05
step: 180, loss: 0.0024184128269553185
step: 190, loss: 0.020463712513446808
step: 200, loss: 0.005510969553142786
step: 210, loss: 0.021715546026825905
step: 220, loss: 0.011630658060312271
step: 230, loss: 0.033134616911411285
step: 240, loss: 0.11292103677988052
step: 250, loss: 0.002095192903652787
step: 260, loss: 0.00012418933329172432
step: 270, loss: 0.0012246430851519108
step: 280, loss: 0.005392611958086491
step: 290, loss: 0.008287654258310795
step: 300, loss: 0.0032803795766085386
step: 310, loss: 0.00524381035938859
step: 320, loss: 0.0008711997070349753
step: 330, loss: 0.06264033913612366
epoch 9: dev_f1=0.8040201005025125, f1=0.775, best_f1=0.775
step: 0, loss: 0.007645599544048309
step: 10, loss: 0.00042472383938729763
step: 20, loss: 4.264911694917828e-05
step: 30, loss: 0.0010084891691803932
step: 40, loss: 0.024876277893781662
step: 50, loss: 0.0008084176806733012
step: 60, loss: 0.10230366885662079
step: 70, loss: 0.0010928212432190776
step: 80, loss: 0.0010083874221891165
step: 90, loss: 0.0018859975971281528
step: 100, loss: 0.0013848338276147842
step: 110, loss: 0.011554589495062828
step: 120, loss: 0.0037496034055948257
step: 130, loss: 0.001291516236960888
step: 140, loss: 0.0027194744907319546
step: 150, loss: 0.0006885472103022039
step: 160, loss: 0.0015618973411619663
step: 170, loss: 0.025883642956614494
step: 180, loss: 0.009663009084761143
step: 190, loss: 0.0003315365465823561
step: 200, loss: 0.002724120393395424
step: 210, loss: 0.00018965326307807118
step: 220, loss: 0.001342558185569942
step: 230, loss: 0.0007842729683034122
step: 240, loss: 0.00016100618813652545
step: 250, loss: 0.00011565273598534986
step: 260, loss: 0.011776160448789597
step: 270, loss: 0.006059911567717791
step: 280, loss: 0.00039668995304964483
step: 290, loss: 0.0010936983162537217
step: 300, loss: 0.0024010459892451763
step: 310, loss: 0.0004139775119256228
step: 320, loss: 0.06838639825582504
step: 330, loss: 0.000364825566066429
epoch 10: dev_f1=0.7970660146699265, f1=0.7714285714285715, best_f1=0.775
step: 0, loss: 5.0816903240047395e-05
step: 10, loss: 0.001085422351025045
step: 20, loss: 0.006068286020308733
step: 30, loss: 0.09080807864665985
step: 40, loss: 0.0003793126088567078
step: 50, loss: 0.006197923794388771
step: 60, loss: 0.00017999211559072137
step: 70, loss: 0.014432326890528202
step: 80, loss: 0.001319354516454041
step: 90, loss: 0.00013477705942932516
step: 100, loss: 0.0009762589470483363
step: 110, loss: 0.0006350245676003397
step: 120, loss: 0.0017282803310081363
step: 130, loss: 0.020919350907206535
step: 140, loss: 0.00032656986149959266
step: 150, loss: 0.000379484670702368
step: 160, loss: 0.0014321795897558331
step: 170, loss: 0.009894187562167645
step: 180, loss: 0.00041741179302334785
step: 190, loss: 0.0008198253926821053
step: 200, loss: 5.4266201914288104e-05
step: 210, loss: 9.928628423949704e-05
step: 220, loss: 7.403703057207167e-05
step: 230, loss: 0.00526704266667366
step: 240, loss: 0.0018926863558590412
step: 250, loss: 0.00021538179134950042
step: 260, loss: 0.001117619452998042
step: 270, loss: 0.00010801887401612476
step: 280, loss: 6.516424036817625e-05
step: 290, loss: 7.919264317024499e-05
step: 300, loss: 0.2924574017524719
step: 310, loss: 0.0030589483212679625
step: 320, loss: 0.0070889233611524105
step: 330, loss: 0.0019793666433542967
epoch 11: dev_f1=0.807785888077859, f1=0.7652582159624414, best_f1=0.7652582159624414
step: 0, loss: 0.004674812778830528
step: 10, loss: 0.002281252760440111
step: 20, loss: 0.014310223050415516
step: 30, loss: 0.00030426509329117835
step: 40, loss: 0.0006075433338992298
step: 50, loss: 0.006234085187315941
step: 60, loss: 9.05248016351834e-05
step: 70, loss: 0.005396171472966671
step: 80, loss: 0.0028542682994157076
step: 90, loss: 0.0017905142158269882
step: 100, loss: 0.0025734524242579937
step: 110, loss: 0.00018947436183225363
step: 120, loss: 6.862719601485878e-05
step: 130, loss: 0.00017547800962347537
step: 140, loss: 0.03383917734026909
step: 150, loss: 0.0038082231767475605
step: 160, loss: 0.00020022955141030252
step: 170, loss: 0.00015207001706585288
step: 180, loss: 0.018434779718518257
step: 190, loss: 0.0001281161094084382
step: 200, loss: 8.509985491400585e-05
step: 210, loss: 0.0016398043371737003
step: 220, loss: 0.0052392794750630856
step: 230, loss: 0.04299352318048477
step: 240, loss: 0.00027392050833441317
step: 250, loss: 0.00033105805050581694
step: 260, loss: 0.028932660818099976
step: 270, loss: 8.731875277590007e-05
step: 280, loss: 2.9779197575408034e-05
step: 290, loss: 0.0001497170451330021
step: 300, loss: 0.00014867221761960536
step: 310, loss: 0.0005429111770354211
step: 320, loss: 0.00018840092525351793
step: 330, loss: 0.00011459670349722728
epoch 12: dev_f1=0.7990196078431373, f1=0.7769784172661871, best_f1=0.7652582159624414
step: 0, loss: 3.967532029491849e-05
step: 10, loss: 3.373476647539064e-05
step: 20, loss: 0.00021034173551015556
step: 30, loss: 3.692049358505756e-05
step: 40, loss: 0.0001961902598850429
step: 50, loss: 0.002108184387907386
step: 60, loss: 0.0001012437351164408
step: 70, loss: 0.0009864766616374254
step: 80, loss: 0.0003392813669051975
step: 90, loss: 1.968045035027899e-05
step: 100, loss: 0.02874702215194702
step: 110, loss: 0.00010576967906672508
step: 120, loss: 0.0008149421191774309
step: 130, loss: 0.00010752614616649225
step: 140, loss: 0.0001455772144254297
step: 150, loss: 9.363697608932853e-05
step: 160, loss: 0.00030423616408370435
step: 170, loss: 0.0004521417140495032
step: 180, loss: 4.330202500568703e-05
step: 190, loss: 0.0004529484431259334
step: 200, loss: 0.11214242875576019
step: 210, loss: 0.0004999324446544051
step: 220, loss: 0.00017997936811298132
step: 230, loss: 0.01699092425405979
step: 240, loss: 0.0001265548198716715
step: 250, loss: 0.0002490570768713951
step: 260, loss: 4.672526483773254e-05
step: 270, loss: 0.00017664278857409954
step: 280, loss: 8.11939753475599e-05
step: 290, loss: 4.8415749915875494e-05
step: 300, loss: 0.017714856192469597
step: 310, loss: 0.18378302454948425
step: 320, loss: 0.0002845165436156094
step: 330, loss: 0.0024426414165645838
epoch 13: dev_f1=0.8037383177570093, f1=0.782608695652174, best_f1=0.7652582159624414
step: 0, loss: 0.022856371477246284
step: 10, loss: 3.917108188034035e-05
step: 20, loss: 0.00011950634507229552
step: 30, loss: 0.0006719360826537013
step: 40, loss: 5.27804768353235e-05
step: 50, loss: 0.0019303051522001624
step: 60, loss: 5.230522947385907e-05
step: 70, loss: 0.0003731385513674468
step: 80, loss: 0.065977081656456
step: 90, loss: 8.430651359958574e-05
step: 100, loss: 7.491515134461224e-05
step: 110, loss: 0.027399271726608276
step: 120, loss: 0.0329391248524189
step: 130, loss: 0.06225930154323578
step: 140, loss: 0.00019858167797792703
step: 150, loss: 0.0006342678098008037
step: 160, loss: 0.00023764291836414486
step: 170, loss: 0.005223875865340233
step: 180, loss: 0.0012036804109811783
step: 190, loss: 0.0020076872315257788
step: 200, loss: 0.000184658492798917
step: 210, loss: 0.0001699368003755808
step: 220, loss: 0.015446947887539864
step: 230, loss: 4.757690476253629e-05
step: 240, loss: 4.759586590807885e-05
step: 250, loss: 8.510746556567028e-05
step: 260, loss: 0.0001422222121618688
step: 270, loss: 0.00010734730312833562
step: 280, loss: 0.0006643481901846826
step: 290, loss: 5.008896187064238e-05
step: 300, loss: 0.0005756331374868751
step: 310, loss: 0.009069706313312054
step: 320, loss: 0.01349345501512289
step: 330, loss: 0.0021160822361707687
epoch 14: dev_f1=0.7819548872180452, f1=0.7604938271604937, best_f1=0.7652582159624414
step: 0, loss: 0.015868058428168297
step: 10, loss: 2.252934245916549e-05
step: 20, loss: 0.000134746398543939
step: 30, loss: 0.0001825113722588867
step: 40, loss: 0.07630409300327301
step: 50, loss: 0.00034763626172207296
step: 60, loss: 0.00019261038687545806
step: 70, loss: 0.00033282136428169906
step: 80, loss: 0.00015150195395108312
step: 90, loss: 2.5919600375345908e-05
step: 100, loss: 0.0017316089943051338
step: 110, loss: 0.00017410438158549368
step: 120, loss: 0.0002307108516106382
step: 130, loss: 0.000916956108994782
step: 140, loss: 5.6020689953584224e-05
step: 150, loss: 3.561179983080365e-05
step: 160, loss: 4.173567140242085e-05
step: 170, loss: 2.858844345610123e-05
step: 180, loss: 0.00015410360356327146
step: 190, loss: 0.004301873501390219
step: 200, loss: 0.0001858648902270943
step: 210, loss: 0.00012397994578350335
step: 220, loss: 0.0003710028249770403
step: 230, loss: 0.02444656752049923
step: 240, loss: 0.00030275818426162004
step: 250, loss: 0.0005103319999761879
step: 260, loss: 0.10436879098415375
step: 270, loss: 0.0007360443705692887
step: 280, loss: 1.6774545656517148e-05
step: 290, loss: 0.001322909607551992
step: 300, loss: 0.00011448205623310059
step: 310, loss: 0.012246891856193542
step: 320, loss: 0.015137452632188797
step: 330, loss: 0.0494268536567688
epoch 15: dev_f1=0.8009592326139089, f1=0.7735849056603774, best_f1=0.7652582159624414
step: 0, loss: 8.358973718713969e-05
step: 10, loss: 0.000664557097479701
step: 20, loss: 0.0002837184874806553
step: 30, loss: 0.0005520389531739056
step: 40, loss: 5.4431882745120674e-05
step: 50, loss: 0.00015159143367782235
step: 60, loss: 0.031858522444963455
step: 70, loss: 0.0010620689718052745
step: 80, loss: 0.00011379967327229679
step: 90, loss: 0.018557313829660416
step: 100, loss: 0.0002786163240671158
step: 110, loss: 1.9762248484767042e-05
step: 120, loss: 0.00016028071695473045
step: 130, loss: 2.3709733795840293e-05
step: 140, loss: 0.00027973801479674876
step: 150, loss: 8.36070830700919e-05
step: 160, loss: 0.00033948279451578856
step: 170, loss: 3.3661712222965434e-05
step: 180, loss: 0.0001564796402817592
step: 190, loss: 0.0001529251312604174
step: 200, loss: 2.198611036874354e-05
step: 210, loss: 0.001676401705481112
step: 220, loss: 6.531030521728098e-05
step: 230, loss: 0.00119481747969985
step: 240, loss: 2.673410199349746e-05
step: 250, loss: 0.00010859516623895615
step: 260, loss: 7.811910472810268e-05
step: 270, loss: 5.2769846661249176e-05
step: 280, loss: 0.0003142117348033935
step: 290, loss: 0.00014396618644241244
step: 300, loss: 9.901983139570802e-05
step: 310, loss: 0.0001733744575176388
step: 320, loss: 0.005375474691390991
step: 330, loss: 0.0038158416282385588
epoch 16: dev_f1=0.8088235294117646, f1=0.7684964200477328, best_f1=0.7684964200477328
step: 0, loss: 4.641820487449877e-05
step: 10, loss: 2.1732015738962218e-05
step: 20, loss: 0.0037487316876649857
step: 30, loss: 7.322921010199934e-05
step: 40, loss: 0.00010701685096137226
step: 50, loss: 4.929646820528433e-05
step: 60, loss: 4.3063468183390796e-05
step: 70, loss: 0.0047704558819532394
step: 80, loss: 0.0001470486167818308
step: 90, loss: 5.535531454370357e-05
step: 100, loss: 0.000507657416164875
step: 110, loss: 0.000579248066060245
step: 120, loss: 2.3330512703978457e-05
step: 130, loss: 0.00017888897855300456
step: 140, loss: 5.1206559874117374e-05
step: 150, loss: 1.2896858606836759e-05
step: 160, loss: 0.000977992545813322
step: 170, loss: 1.1570678907446563e-05
step: 180, loss: 0.0001974826882360503
step: 190, loss: 4.4867356336908415e-05
step: 200, loss: 0.0009041763842105865
step: 210, loss: 5.7865479902829975e-05
step: 220, loss: 0.027751537039875984
step: 230, loss: 0.00018574384739622474
step: 240, loss: 0.0011856990167871118
step: 250, loss: 6.31581642664969e-05
step: 260, loss: 0.0003678257344290614
step: 270, loss: 3.846933032036759e-05
step: 280, loss: 3.529774767230265e-05
step: 290, loss: 0.00013801858585793525
step: 300, loss: 0.019610624760389328
step: 310, loss: 0.013943455182015896
step: 320, loss: 1.6126428818097338e-05
step: 330, loss: 0.016273057088255882
epoch 17: dev_f1=0.7898734177215191, f1=0.7651331719128328, best_f1=0.7684964200477328
step: 0, loss: 8.434652409050614e-05
step: 10, loss: 4.566123607219197e-05
step: 20, loss: 0.06262512505054474
step: 30, loss: 3.836809628410265e-05
step: 40, loss: 9.87409584922716e-05
step: 50, loss: 8.884967974154279e-05
step: 60, loss: 0.00021693669259548187
step: 70, loss: 2.4443834263365716e-05
step: 80, loss: 5.495676668942906e-05
step: 90, loss: 0.0044073197059333324
step: 100, loss: 0.00013045156083535403
step: 110, loss: 7.511833973694593e-05
step: 120, loss: 0.00014308486424852163
step: 130, loss: 1.3094289897708222e-05
step: 140, loss: 0.0009382149437442422
step: 150, loss: 0.0037754245568066835
step: 160, loss: 3.706929419422522e-05
step: 170, loss: 0.0003722301044035703
step: 180, loss: 0.007945300079882145
step: 190, loss: 1.7646041669650003e-05
step: 200, loss: 0.005204776767641306
step: 210, loss: 1.2528041224868502e-05
step: 220, loss: 5.595655966317281e-05
step: 230, loss: 0.00021482071315404028
step: 240, loss: 1.458065162296407e-05
step: 250, loss: 0.000257118052104488
step: 260, loss: 8.853031613398343e-05
step: 270, loss: 2.20190249820007e-05
step: 280, loss: 2.742327887972351e-05
step: 290, loss: 3.533864946803078e-05
step: 300, loss: 9.586671512806788e-05
step: 310, loss: 3.7113546568434685e-05
step: 320, loss: 2.9074984922772273e-05
step: 330, loss: 5.476443038787693e-05
epoch 18: dev_f1=0.7919799498746868, f1=0.7658536585365854, best_f1=0.7684964200477328
step: 0, loss: 0.0013222546549513936
step: 10, loss: 4.720593642559834e-05
step: 20, loss: 5.090443301014602e-05
step: 30, loss: 0.0001279704156331718
step: 40, loss: 1.4457692486757878e-05
step: 50, loss: 0.15856388211250305
step: 60, loss: 0.027281206101179123
step: 70, loss: 0.0006018874701112509
step: 80, loss: 0.0009682889212854207
step: 90, loss: 0.00011399971845094115
step: 100, loss: 0.00015246792463585734
step: 110, loss: 5.114774830872193e-05
step: 120, loss: 0.0007738246931694448
step: 130, loss: 0.006674106232821941
step: 140, loss: 9.232720185536891e-05
step: 150, loss: 0.002881827997043729
step: 160, loss: 0.0002656235883478075
step: 170, loss: 0.00013311752991285175
step: 180, loss: 0.00010432820999994874
step: 190, loss: 0.0028560932260006666
step: 200, loss: 2.8566284527187236e-05
step: 210, loss: 0.0008411042508669198
step: 220, loss: 6.2800660089124e-05
step: 230, loss: 0.0005576839321292937
step: 240, loss: 0.003473947523161769
step: 250, loss: 0.00016742867592256516
step: 260, loss: 0.00012068373325746506
step: 270, loss: 0.00024190955446101725
step: 280, loss: 4.89702433696948e-05
step: 290, loss: 6.0134912928333506e-05
step: 300, loss: 0.0003036399430129677
step: 310, loss: 4.067254485562444e-05
step: 320, loss: 1.1306181477266364e-05
step: 330, loss: 3.535971336532384e-05
epoch 19: dev_f1=0.7949367088607596, f1=0.7567567567567568, best_f1=0.7684964200477328
step: 0, loss: 5.961845090496354e-05
step: 10, loss: 5.521213824977167e-05
step: 20, loss: 0.009321155026555061
step: 30, loss: 2.9745606298092753e-05
step: 40, loss: 5.5031800002325326e-05
step: 50, loss: 7.798025762895122e-05
step: 60, loss: 0.00013570509327109903
step: 70, loss: 1.2658404557441827e-05
step: 80, loss: 3.18997263093479e-05
step: 90, loss: 0.0004538876237347722
step: 100, loss: 1.3004768334212713e-05
step: 110, loss: 9.240776125807315e-05
step: 120, loss: 1.212945153383771e-05
step: 130, loss: 0.22479774057865143
step: 140, loss: 4.9308921006741e-05
step: 150, loss: 3.084201307501644e-05
step: 160, loss: 0.00010719787678681314
step: 170, loss: 0.007736492902040482
step: 180, loss: 4.2064475564984605e-05
step: 190, loss: 0.0009728557779453695
step: 200, loss: 0.0129142627120018
step: 210, loss: 7.792167889419943e-05
step: 220, loss: 6.370753544615582e-05
step: 230, loss: 0.00018605661171022803
step: 240, loss: 0.0001365230418741703
step: 250, loss: 3.550501787685789e-05
step: 260, loss: 1.801122743927408e-05
step: 270, loss: 0.0007411457481794059
step: 280, loss: 3.245880361646414e-05
step: 290, loss: 4.381305552669801e-05
step: 300, loss: 0.0002494621148798615
step: 310, loss: 3.7886216887272894e-05
step: 320, loss: 0.00011348856787662953
step: 330, loss: 0.0006014868267811835
epoch 20: dev_f1=0.8058968058968059, f1=0.7732696897374701, best_f1=0.7684964200477328
