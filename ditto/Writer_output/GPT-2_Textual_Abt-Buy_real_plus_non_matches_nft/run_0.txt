cuda
Device: cuda
step: 0, loss: 0.5637450218200684
step: 10, loss: 0.13808585703372955
step: 20, loss: 0.4887624680995941
step: 30, loss: 0.26968473196029663
step: 40, loss: 0.2716899812221527
step: 50, loss: 0.16348423063755035
step: 60, loss: 0.03810889273881912
step: 70, loss: 0.13206066191196442
step: 80, loss: 0.0743962898850441
step: 90, loss: 0.05917643755674362
step: 100, loss: 0.30475008487701416
step: 110, loss: 0.1548834890127182
step: 120, loss: 0.05164356902241707
step: 130, loss: 0.0663033053278923
step: 140, loss: 0.14404118061065674
step: 150, loss: 0.11560369282960892
step: 160, loss: 0.12808646261692047
step: 170, loss: 0.12736566364765167
step: 180, loss: 0.2852218449115753
step: 190, loss: 0.26454710960388184
step: 200, loss: 0.2757808268070221
step: 210, loss: 0.19924145936965942
step: 220, loss: 0.33104532957077026
step: 230, loss: 0.042944878339767456
step: 240, loss: 0.13459911942481995
step: 250, loss: 0.20970483124256134
step: 260, loss: 0.18548919260501862
step: 270, loss: 0.21838761866092682
step: 280, loss: 0.22853296995162964
step: 290, loss: 0.24512165784835815
step: 300, loss: 0.15261395275592804
step: 310, loss: 0.3294536769390106
step: 320, loss: 0.47673994302749634
step: 330, loss: 0.39120811223983765
epoch 1: dev_f1=0.27037037037037037, f1=0.25830258302583026, best_f1=0.25830258302583026
step: 0, loss: 0.2373967468738556
step: 10, loss: 0.2578716278076172
step: 20, loss: 0.02363346517086029
step: 30, loss: 0.18969100713729858
step: 40, loss: 0.4137236177921295
step: 50, loss: 0.3424186706542969
step: 60, loss: 0.1637202352285385
step: 70, loss: 0.11468041688203812
step: 80, loss: 0.42090514302253723
step: 90, loss: 0.2248162180185318
step: 100, loss: 0.2742517292499542
step: 110, loss: 0.11946447193622589
step: 120, loss: 0.1483769416809082
step: 130, loss: 0.07437469810247421
step: 140, loss: 0.2157156765460968
step: 150, loss: 0.24931436777114868
step: 160, loss: 0.1350981891155243
step: 170, loss: 0.13842521607875824
step: 180, loss: 0.1189805343747139
step: 190, loss: 0.1927744448184967
step: 200, loss: 0.19257736206054688
step: 210, loss: 0.19832754135131836
step: 220, loss: 0.29795658588409424
step: 230, loss: 0.0725017711520195
step: 240, loss: 0.17304830253124237
step: 250, loss: 0.1612185388803482
step: 260, loss: 0.09326264262199402
step: 270, loss: 0.24791377782821655
step: 280, loss: 0.057262856513261795
step: 290, loss: 0.10524854063987732
step: 300, loss: 0.18894025683403015
step: 310, loss: 0.08246596157550812
step: 320, loss: 0.04064951464533806
step: 330, loss: 0.28156813979148865
epoch 2: dev_f1=0.70020964360587, f1=0.731006160164271, best_f1=0.731006160164271
step: 0, loss: 0.059818413108587265
step: 10, loss: 0.10886217653751373
step: 20, loss: 0.025352902710437775
step: 30, loss: 0.13761316239833832
step: 40, loss: 0.15344956517219543
step: 50, loss: 0.09079337865114212
step: 60, loss: 0.0604192391037941
step: 70, loss: 0.06745477765798569
step: 80, loss: 0.11619667708873749
step: 90, loss: 0.22559143602848053
step: 100, loss: 0.183856800198555
step: 110, loss: 0.08090881258249283
step: 120, loss: 0.10614141821861267
step: 130, loss: 0.08457949012517929
step: 140, loss: 0.042872752994298935
step: 150, loss: 0.06024077534675598
step: 160, loss: 0.09094975888729095
step: 170, loss: 0.1488122195005417
step: 180, loss: 0.07474831491708755
step: 190, loss: 0.09475129097700119
step: 200, loss: 0.22723735868930817
step: 210, loss: 0.08283623307943344
step: 220, loss: 0.17593476176261902
step: 230, loss: 0.05272365361452103
step: 240, loss: 0.0028780035208910704
step: 250, loss: 0.023544829338788986
step: 260, loss: 0.32446014881134033
step: 270, loss: 0.09227076917886734
step: 280, loss: 0.13511505722999573
step: 290, loss: 0.0024627079255878925
step: 300, loss: 0.07647266238927841
step: 310, loss: 0.0616181306540966
step: 320, loss: 0.04421967267990112
step: 330, loss: 0.0033376519568264484
epoch 3: dev_f1=0.8132387706855791, f1=0.7873303167420815, best_f1=0.7873303167420815
step: 0, loss: 0.2907009422779083
step: 10, loss: 0.07184723764657974
step: 20, loss: 0.03662187606096268
step: 30, loss: 0.0574096217751503
step: 40, loss: 0.11525191366672516
step: 50, loss: 0.002830612240359187
step: 60, loss: 0.13602600991725922
step: 70, loss: 0.006906109396368265
step: 80, loss: 0.12652450799942017
step: 90, loss: 0.11898533999919891
step: 100, loss: 0.032044824212789536
step: 110, loss: 0.04892024025321007
step: 120, loss: 0.015443220734596252
step: 130, loss: 0.0711495503783226
step: 140, loss: 0.015293320640921593
step: 150, loss: 0.15561869740486145
step: 160, loss: 0.015712186694145203
step: 170, loss: 0.05787987262010574
step: 180, loss: 0.04899804666638374
step: 190, loss: 0.016200201585888863
step: 200, loss: 0.01861778274178505
step: 210, loss: 0.03070085123181343
step: 220, loss: 0.16240033507347107
step: 230, loss: 0.019862070679664612
step: 240, loss: 0.014957251027226448
step: 250, loss: 0.04992850497364998
step: 260, loss: 0.019081352278590202
step: 270, loss: 0.02982291392982006
step: 280, loss: 0.11546704173088074
step: 290, loss: 0.018683819100260735
step: 300, loss: 0.1303110420703888
step: 310, loss: 0.21569685637950897
step: 320, loss: 0.14613878726959229
step: 330, loss: 0.05315379053354263
epoch 4: dev_f1=0.7962085308056872, f1=0.786046511627907, best_f1=0.7873303167420815
step: 0, loss: 0.2799578011035919
step: 10, loss: 0.06308290362358093
step: 20, loss: 0.14305877685546875
step: 30, loss: 0.013229628093540668
step: 40, loss: 0.09808062016963959
step: 50, loss: 0.009504484012722969
step: 60, loss: 0.004782630130648613
step: 70, loss: 0.08118297904729843
step: 80, loss: 0.001383255235850811
step: 90, loss: 0.05383326858282089
step: 100, loss: 0.0028251975309103727
step: 110, loss: 0.01942349784076214
step: 120, loss: 0.024675067514181137
step: 130, loss: 0.0021333072800189257
step: 140, loss: 0.07102999836206436
step: 150, loss: 0.09066837280988693
step: 160, loss: 0.05396748706698418
step: 170, loss: 0.1885969340801239
step: 180, loss: 0.023267574608325958
step: 190, loss: 0.004849354736506939
step: 200, loss: 0.007216456346213818
step: 210, loss: 0.09590847790241241
step: 220, loss: 0.008853714913129807
step: 230, loss: 0.06934546679258347
step: 240, loss: 0.013638866133987904
step: 250, loss: 0.015496516600251198
step: 260, loss: 0.021860621869564056
step: 270, loss: 0.0010154967894777656
step: 280, loss: 0.021317237988114357
step: 290, loss: 0.06076905503869057
step: 300, loss: 0.012873057276010513
step: 310, loss: 0.04526464641094208
step: 320, loss: 0.019147833809256554
step: 330, loss: 0.014151501469314098
epoch 5: dev_f1=0.8385542168674698, f1=0.7981438515081206, best_f1=0.7981438515081206
step: 0, loss: 0.020567966625094414
step: 10, loss: 0.06770967692136765
step: 20, loss: 0.011130159720778465
step: 30, loss: 0.009605656377971172
step: 40, loss: 0.020311089232563972
step: 50, loss: 0.0073450407944619656
step: 60, loss: 0.005819098558276892
step: 70, loss: 0.13905516266822815
step: 80, loss: 0.003842343343421817
step: 90, loss: 0.005337464157491922
step: 100, loss: 0.017331352457404137
step: 110, loss: 0.0050375089049339294
step: 120, loss: 0.01990721933543682
step: 130, loss: 0.0060092248022556305
step: 140, loss: 0.0009211230208165944
step: 150, loss: 0.18862317502498627
step: 160, loss: 0.04693671688437462
step: 170, loss: 0.0014467841247096658
step: 180, loss: 0.030801918357610703
step: 190, loss: 0.0889129713177681
step: 200, loss: 0.006859469227492809
step: 210, loss: 0.008759334683418274
step: 220, loss: 0.027497923001646996
step: 230, loss: 0.013946845196187496
step: 240, loss: 0.003032093634828925
step: 250, loss: 0.010606838390231133
step: 260, loss: 0.0025984961539506912
step: 270, loss: 0.003541128011420369
step: 280, loss: 0.0017519237007945776
step: 290, loss: 0.055697131901979446
step: 300, loss: 0.010666577145457268
step: 310, loss: 0.016800055280327797
step: 320, loss: 0.2607240080833435
step: 330, loss: 0.06500516831874847
epoch 6: dev_f1=0.8117359413202935, f1=0.8095238095238095, best_f1=0.7981438515081206
step: 0, loss: 0.0032561877742409706
step: 10, loss: 0.004395489580929279
step: 20, loss: 0.02270500361919403
step: 30, loss: 0.0039481124840676785
step: 40, loss: 0.00027532927924767137
step: 50, loss: 0.028230881318449974
step: 60, loss: 0.1478155255317688
step: 70, loss: 0.07496274262666702
step: 80, loss: 0.018201738595962524
step: 90, loss: 0.0038034797180444
step: 100, loss: 0.003593323053792119
step: 110, loss: 0.009271464310586452
step: 120, loss: 0.02468179352581501
step: 130, loss: 0.006669225171208382
step: 140, loss: 0.004920352250337601
step: 150, loss: 0.003453038167208433
step: 160, loss: 0.004544816445559263
step: 170, loss: 0.08847654610872269
step: 180, loss: 0.26554977893829346
step: 190, loss: 0.004497780464589596
step: 200, loss: 0.04943045973777771
step: 210, loss: 0.023005081340670586
step: 220, loss: 0.00306468247435987
step: 230, loss: 0.0023268284276127815
step: 240, loss: 0.11471810936927795
step: 250, loss: 0.06357251852750778
step: 260, loss: 0.04242350161075592
step: 270, loss: 0.007052991539239883
step: 280, loss: 0.008272347040474415
step: 290, loss: 0.03207387030124664
step: 300, loss: 0.050763484090566635
step: 310, loss: 0.010902421548962593
step: 320, loss: 0.020449457690119743
step: 330, loss: 0.0016284373123198748
epoch 7: dev_f1=0.7735849056603774, f1=0.7834101382488479, best_f1=0.7981438515081206
step: 0, loss: 0.007393607869744301
step: 10, loss: 0.0012324040289968252
step: 20, loss: 0.005931752733886242
step: 30, loss: 0.00038821366615593433
step: 40, loss: 0.0011779480846598744
step: 50, loss: 0.0177119392901659
step: 60, loss: 0.026508476585149765
step: 70, loss: 0.0503566674888134
step: 80, loss: 0.0180683396756649
step: 90, loss: 0.002868102630600333
step: 100, loss: 0.0076086027547717094
step: 110, loss: 0.13555963337421417
step: 120, loss: 0.00039808888686820865
step: 130, loss: 0.005059128161519766
step: 140, loss: 0.0007021630881354213
step: 150, loss: 0.0003673245955724269
step: 160, loss: 0.00068905227817595
step: 170, loss: 0.051588453352451324
step: 180, loss: 0.06813104450702667
step: 190, loss: 0.017205113545060158
step: 200, loss: 0.010611980222165585
step: 210, loss: 0.043545253574848175
step: 220, loss: 0.030084168538451195
step: 230, loss: 0.001190196955576539
step: 240, loss: 0.004208198748528957
step: 250, loss: 0.017427783459424973
step: 260, loss: 0.0016131616430357099
step: 270, loss: 0.022899318486452103
step: 280, loss: 0.003903546603396535
step: 290, loss: 0.007552258670330048
step: 300, loss: 0.010448569431900978
step: 310, loss: 0.0017629205249249935
step: 320, loss: 0.1401633769273758
step: 330, loss: 0.057485535740852356
epoch 8: dev_f1=0.8056872037914692, f1=0.8047058823529412, best_f1=0.7981438515081206
step: 0, loss: 0.07109233736991882
step: 10, loss: 0.13951753079891205
step: 20, loss: 0.022132206708192825
step: 30, loss: 0.1175067126750946
step: 40, loss: 0.00910735409706831
step: 50, loss: 0.009370231069624424
step: 60, loss: 0.0049820030108094215
step: 70, loss: 0.012722378596663475
step: 80, loss: 0.021469326689839363
step: 90, loss: 0.0003125547373201698
step: 100, loss: 7.054874004097655e-05
step: 110, loss: 0.0001293298410018906
step: 120, loss: 0.00031722127459943295
step: 130, loss: 0.03942997753620148
step: 140, loss: 0.000359221245162189
step: 150, loss: 0.003422582522034645
step: 160, loss: 0.009533865377306938
step: 170, loss: 0.007192137651145458
step: 180, loss: 0.002116634277626872
step: 190, loss: 0.007425014395266771
step: 200, loss: 0.0021457336843013763
step: 210, loss: 5.077778405393474e-05
step: 220, loss: 0.018058404326438904
step: 230, loss: 0.0046676998026669025
step: 240, loss: 0.22133471071720123
step: 250, loss: 0.00018232225556857884
step: 260, loss: 0.002799381036311388
step: 270, loss: 0.03527873381972313
step: 280, loss: 0.0007780625019222498
step: 290, loss: 0.046623434871435165
step: 300, loss: 0.007560966070741415
step: 310, loss: 0.004208627622574568
step: 320, loss: 0.00020542560378089547
step: 330, loss: 0.08048524707555771
epoch 9: dev_f1=0.8118811881188118, f1=0.7841191066997518, best_f1=0.7981438515081206
step: 0, loss: 0.09279689937829971
step: 10, loss: 0.005940541625022888
step: 20, loss: 0.0012797277886420488
step: 30, loss: 0.005080691538751125
step: 40, loss: 0.0057315225712955
step: 50, loss: 0.05032886564731598
step: 60, loss: 0.0293171014636755
step: 70, loss: 0.003995532635599375
step: 80, loss: 0.011026734486222267
step: 90, loss: 9.716591739561409e-05
step: 100, loss: 5.613715620711446e-05
step: 110, loss: 0.039730433374643326
step: 120, loss: 0.0005123239825479686
step: 130, loss: 0.0024754093028604984
step: 140, loss: 0.0003258917713537812
step: 150, loss: 0.00032936441130004823
step: 160, loss: 0.016680419445037842
step: 170, loss: 0.007163607981055975
step: 180, loss: 0.0005946793244220316
step: 190, loss: 0.0020243192557245493
step: 200, loss: 0.16917334496974945
step: 210, loss: 0.054814424365758896
step: 220, loss: 0.0022594307083636522
step: 230, loss: 0.0010861839400604367
step: 240, loss: 0.006793248001486063
step: 250, loss: 0.0001418498286511749
step: 260, loss: 0.1368950754404068
step: 270, loss: 0.007851570844650269
step: 280, loss: 0.00037777109537273645
step: 290, loss: 0.008266273885965347
step: 300, loss: 4.292859375709668e-05
step: 310, loss: 0.0003274406772106886
step: 320, loss: 0.012051315978169441
step: 330, loss: 0.0015544295310974121
epoch 10: dev_f1=0.8169014084507042, f1=0.8009367681498829, best_f1=0.7981438515081206
step: 0, loss: 0.026893507689237595
step: 10, loss: 0.0070574586279690266
step: 20, loss: 0.001679705805145204
step: 30, loss: 0.007749215234071016
step: 40, loss: 0.031791478395462036
step: 50, loss: 0.002467256737872958
step: 60, loss: 0.0005033615161664784
step: 70, loss: 0.010252566076815128
step: 80, loss: 0.00539396284148097
step: 90, loss: 0.0006148418178781867
step: 100, loss: 0.0006289707380346954
step: 110, loss: 0.0067402059212327
step: 120, loss: 0.0833091288805008
step: 130, loss: 0.0014187090564519167
step: 140, loss: 0.00011451302270870656
step: 150, loss: 0.0002472637570463121
step: 160, loss: 0.002330245915800333
step: 170, loss: 0.0005256419535726309
step: 180, loss: 0.0007816004217602313
step: 190, loss: 0.0011494181817397475
step: 200, loss: 2.576356018835213e-05
step: 210, loss: 7.752008968964219e-05
step: 220, loss: 0.0018771387403830886
step: 230, loss: 3.377245593583211e-05
step: 240, loss: 0.0004053227894473821
step: 250, loss: 0.0434541255235672
step: 260, loss: 0.00038934143958613276
step: 270, loss: 0.00046120528713800013
step: 280, loss: 0.0001997327635763213
step: 290, loss: 4.1918021452147514e-05
step: 300, loss: 0.0638972744345665
step: 310, loss: 0.18055592477321625
step: 320, loss: 0.0013745544711127877
step: 330, loss: 0.0013293332885950804
epoch 11: dev_f1=0.7832512315270935, f1=0.7726161369193154, best_f1=0.7981438515081206
step: 0, loss: 0.000142247648909688
step: 10, loss: 0.0005210407543927431
step: 20, loss: 0.0009869573405012488
step: 30, loss: 0.0024325808044523
step: 40, loss: 0.07497555762529373
step: 50, loss: 3.442432716838084e-05
step: 60, loss: 3.680800000438467e-05
step: 70, loss: 0.0013405042700469494
step: 80, loss: 0.0004516218032222241
step: 90, loss: 0.0011460620444267988
step: 100, loss: 0.0006097297300584614
step: 110, loss: 9.329389285994694e-05
step: 120, loss: 0.0008447234285995364
step: 130, loss: 0.0002723355428315699
step: 140, loss: 0.003342090407386422
step: 150, loss: 0.006530567072331905
step: 160, loss: 0.0002559651911724359
step: 170, loss: 0.1050826758146286
step: 180, loss: 0.0002798686036840081
step: 190, loss: 0.01308676041662693
step: 200, loss: 0.00011474720668047667
step: 210, loss: 0.00018913878011517227
step: 220, loss: 0.0010207431623712182
step: 230, loss: 0.00011696761066559702
step: 240, loss: 0.042927663773298264
step: 250, loss: 0.001642458839341998
step: 260, loss: 0.004814261570572853
step: 270, loss: 0.0003687882563099265
step: 280, loss: 0.005569551605731249
step: 290, loss: 0.0019857229199260473
step: 300, loss: 0.00028552606818266213
step: 310, loss: 5.918078022659756e-05
step: 320, loss: 0.06125288084149361
step: 330, loss: 0.00815635360777378
epoch 12: dev_f1=0.8162291169451074, f1=0.8018867924528301, best_f1=0.7981438515081206
step: 0, loss: 8.897999941837043e-05
step: 10, loss: 0.0006565291550941765
step: 20, loss: 0.004678595345467329
step: 30, loss: 0.00603603245690465
step: 40, loss: 0.0028043296188116074
step: 50, loss: 0.00011807208647951484
step: 60, loss: 0.0024347654543817043
step: 70, loss: 0.017727287486195564
step: 80, loss: 0.0024978730361908674
step: 90, loss: 0.000497606466524303
step: 100, loss: 0.00045073189539834857
step: 110, loss: 0.0015496432315558195
step: 120, loss: 0.0015923990868031979
step: 130, loss: 0.0021791676990687847
step: 140, loss: 0.0019260174594819546
step: 150, loss: 3.637937334133312e-05
step: 160, loss: 0.0004324617038946599
step: 170, loss: 0.00032785156508907676
step: 180, loss: 2.629929622344207e-05
step: 190, loss: 0.04364563524723053
step: 200, loss: 8.070953481364995e-05
step: 210, loss: 0.00683912867680192
step: 220, loss: 0.00022426588111557066
step: 230, loss: 0.00023474788758903742
step: 240, loss: 0.00040709058521315455
step: 250, loss: 0.011759881861507893
step: 260, loss: 0.0003690026933327317
step: 270, loss: 0.0009088204242289066
step: 280, loss: 6.22674124315381e-05
step: 290, loss: 0.00013282492000143975
step: 300, loss: 0.02272629179060459
step: 310, loss: 0.0003716347855515778
step: 320, loss: 0.030799904838204384
step: 330, loss: 0.00017270313401240855
epoch 13: dev_f1=0.7769784172661871, f1=0.7811764705882352, best_f1=0.7981438515081206
step: 0, loss: 0.00012991559924557805
step: 10, loss: 0.0006312510231509805
step: 20, loss: 0.02059285342693329
step: 30, loss: 0.0003540903271641582
step: 40, loss: 0.0002325498207937926
step: 50, loss: 0.04693805053830147
step: 60, loss: 0.0009864531457424164
step: 70, loss: 0.00013913025031797588
step: 80, loss: 0.000386972154956311
step: 90, loss: 0.016140645369887352
step: 100, loss: 0.004535385873168707
step: 110, loss: 0.0007652578060515225
step: 120, loss: 9.988702367991209e-05
step: 130, loss: 1.548588443256449e-05
step: 140, loss: 0.0005312436842359602
step: 150, loss: 4.1605544538469985e-05
step: 160, loss: 6.897431740071625e-05
step: 170, loss: 0.04452451318502426
step: 180, loss: 0.0020317919552326202
step: 190, loss: 0.002624190878123045
step: 200, loss: 0.0002593835524749011
step: 210, loss: 0.00012978765880689025
step: 220, loss: 0.00648175273090601
step: 230, loss: 0.00022040049952920526
step: 240, loss: 3.338071473990567e-05
step: 250, loss: 0.0015541000757366419
step: 260, loss: 0.000351243739714846
step: 270, loss: 0.0005212958785705268
step: 280, loss: 0.00013560520892497152
step: 290, loss: 0.001291135442443192
step: 300, loss: 5.151637742528692e-05
step: 310, loss: 0.001719956286251545
step: 320, loss: 0.0005000538658350706
step: 330, loss: 0.00021946517517790198
epoch 14: dev_f1=0.8203883495145631, f1=0.7980997624703088, best_f1=0.7981438515081206
step: 0, loss: 0.0004147963772993535
step: 10, loss: 0.007818848825991154
step: 20, loss: 0.00010494605521671474
step: 30, loss: 0.00015813006029929966
step: 40, loss: 7.621943223057315e-05
step: 50, loss: 0.00011496184743009508
step: 60, loss: 0.0004250270430929959
step: 70, loss: 5.2805709856329486e-05
step: 80, loss: 0.0016415207646787167
step: 90, loss: 0.0008655626443214715
step: 100, loss: 0.00033100301516242325
step: 110, loss: 0.0002608672948554158
step: 120, loss: 0.0004085891996510327
step: 130, loss: 4.9703201511874795e-05
step: 140, loss: 0.0003786693268921226
step: 150, loss: 8.197427814593539e-05
step: 160, loss: 4.4361706386553124e-05
step: 170, loss: 1.949384022736922e-05
step: 180, loss: 2.7256306566414423e-05
step: 190, loss: 7.825102511560544e-05
step: 200, loss: 9.575668082106858e-05
step: 210, loss: 0.006552277598530054
step: 220, loss: 0.04494526609778404
step: 230, loss: 0.0001249044289579615
step: 240, loss: 0.00011154748062836006
step: 250, loss: 0.00013437257439363748
step: 260, loss: 0.011781308799982071
step: 270, loss: 6.209245475474745e-05
step: 280, loss: 0.00022956343309488147
step: 290, loss: 6.572468555532396e-05
step: 300, loss: 0.00022339150018524379
step: 310, loss: 0.0001449044793844223
step: 320, loss: 0.0005127767799422145
step: 330, loss: 4.017140599898994e-05
epoch 15: dev_f1=0.8181818181818181, f1=0.7951807228915662, best_f1=0.7981438515081206
step: 0, loss: 0.00037563085788860917
step: 10, loss: 3.529139939928427e-05
step: 20, loss: 2.9481387173291296e-05
step: 30, loss: 0.00033414692734368145
step: 40, loss: 0.004882398527115583
step: 50, loss: 0.040681298822164536
step: 60, loss: 0.005503284279257059
step: 70, loss: 7.852265116525814e-05
step: 80, loss: 0.00016379602311644703
step: 90, loss: 0.00021495323744602501
step: 100, loss: 0.0003989218967035413
step: 110, loss: 0.0009543839260004461
step: 120, loss: 0.00016095176397357136
step: 130, loss: 0.00012898530985694379
step: 140, loss: 0.0001006413804134354
step: 150, loss: 0.001133248209953308
step: 160, loss: 0.00017480491078458726
step: 170, loss: 0.000183676223969087
step: 180, loss: 0.0010261430870741606
step: 190, loss: 0.00015389356121886522
step: 200, loss: 0.0017276708967983723
step: 210, loss: 0.05578094720840454
step: 220, loss: 0.0073732007294893265
step: 230, loss: 0.00024393413332290947
step: 240, loss: 0.002468694234266877
step: 250, loss: 0.00025846456992439926
step: 260, loss: 0.002469688421115279
step: 270, loss: 0.0001709164644125849
step: 280, loss: 0.0001897872134577483
step: 290, loss: 0.0005203671753406525
step: 300, loss: 0.0007401470793411136
step: 310, loss: 0.00017139117699116468
step: 320, loss: 0.00015133366105146706
step: 330, loss: 0.0005536274402402341
epoch 16: dev_f1=0.8167539267015707, f1=0.7684210526315789, best_f1=0.7981438515081206
step: 0, loss: 7.862439088057727e-05
step: 10, loss: 0.0004660380363930017
step: 20, loss: 0.0003618433838710189
step: 30, loss: 0.00016538865747861564
step: 40, loss: 0.00017846775881480426
step: 50, loss: 0.0012261138763278723
step: 60, loss: 8.074022480286658e-05
step: 70, loss: 0.00040341864223591983
step: 80, loss: 0.00013141421368345618
step: 90, loss: 0.0001670883211772889
step: 100, loss: 0.039982281625270844
step: 110, loss: 0.0015435069799423218
step: 120, loss: 0.0003855506656691432
step: 130, loss: 0.0007933999877423048
step: 140, loss: 0.0006538351881317794
step: 150, loss: 0.000285524147329852
step: 160, loss: 0.00022774214448872954
step: 170, loss: 0.0002426354039926082
step: 180, loss: 0.00011960496340179816
step: 190, loss: 0.000526038056705147
step: 200, loss: 0.0001721475418889895
step: 210, loss: 0.0008065429283306003
step: 220, loss: 0.00010990018927259371
step: 230, loss: 3.3809948945418e-05
step: 240, loss: 4.543923569144681e-05
step: 250, loss: 0.00019217981025576591
step: 260, loss: 0.0001039481649058871
step: 270, loss: 5.052732740296051e-05
step: 280, loss: 0.0003226887492928654
step: 290, loss: 0.00031248980667442083
step: 300, loss: 5.459110616357066e-05
step: 310, loss: 5.7341152569279075e-05
step: 320, loss: 3.569819455151446e-05
step: 330, loss: 0.04162779822945595
epoch 17: dev_f1=0.8203883495145631, f1=0.78743961352657, best_f1=0.7981438515081206
step: 0, loss: 0.005731220357120037
step: 10, loss: 0.00041728909127414227
step: 20, loss: 0.0028414016123861074
step: 30, loss: 0.0002509344194550067
step: 40, loss: 0.001598690520040691
step: 50, loss: 0.0009638218907639384
step: 60, loss: 0.00010817953443620354
step: 70, loss: 0.00011528785398695618
step: 80, loss: 8.705949585419148e-05
step: 90, loss: 0.00013070878048893064
step: 100, loss: 0.0020118721295148134
step: 110, loss: 0.0001488991256337613
step: 120, loss: 2.6583069484331645e-05
step: 130, loss: 8.23420486995019e-05
step: 140, loss: 0.00035607110476121306
step: 150, loss: 0.03517530858516693
step: 160, loss: 0.00026669102953746915
step: 170, loss: 0.0001480681385146454
step: 180, loss: 0.013169008307158947
step: 190, loss: 8.199759031413123e-05
step: 200, loss: 0.007349082268774509
step: 210, loss: 0.007733555510640144
step: 220, loss: 0.0006599186453968287
step: 230, loss: 0.0001284235913772136
step: 240, loss: 8.885269926395267e-05
step: 250, loss: 6.1390244809445e-05
step: 260, loss: 4.914750752504915e-05
step: 270, loss: 6.264759576879442e-05
step: 280, loss: 4.1934468754334375e-05
step: 290, loss: 0.00010247539466945454
step: 300, loss: 0.00014158972771838307
step: 310, loss: 3.029607978533022e-05
step: 320, loss: 4.836386870010756e-05
step: 330, loss: 3.732710683834739e-05
epoch 18: dev_f1=0.8126649076517151, f1=0.7740259740259741, best_f1=0.7981438515081206
step: 0, loss: 0.0032346148509532213
step: 10, loss: 6.793720967834815e-05
step: 20, loss: 4.10656284657307e-05
step: 30, loss: 5.0315604312345386e-05
step: 40, loss: 3.739989915629849e-05
step: 50, loss: 0.0017291437834501266
step: 60, loss: 8.74924153322354e-05
step: 70, loss: 2.714886431931518e-05
step: 80, loss: 0.0005429062293842435
step: 90, loss: 0.0037946440279483795
step: 100, loss: 4.52523490821477e-05
step: 110, loss: 2.980672252306249e-05
step: 120, loss: 0.0014421907253563404
step: 130, loss: 0.0002108897315338254
step: 140, loss: 0.00010611402103677392
step: 150, loss: 0.005249492358416319
step: 160, loss: 0.0001317504938924685
step: 170, loss: 3.100775575148873e-05
step: 180, loss: 9.1817848442588e-05
step: 190, loss: 0.0016524273669347167
step: 200, loss: 7.122082024579868e-05
step: 210, loss: 5.689456520485692e-05
step: 220, loss: 0.0002808162826113403
step: 230, loss: 5.275224975775927e-05
step: 240, loss: 0.00018292359891347587
step: 250, loss: 7.690044731134549e-05
step: 260, loss: 0.00011305519728921354
step: 270, loss: 0.00025323883164674044
step: 280, loss: 4.283002999727614e-05
step: 290, loss: 0.0001774165575625375
step: 300, loss: 0.007973841391503811
step: 310, loss: 3.630237915785983e-05
step: 320, loss: 6.714980554534122e-05
step: 330, loss: 9.660585055826232e-05
epoch 19: dev_f1=0.8129675810473815, f1=0.7931034482758621, best_f1=0.7981438515081206
step: 0, loss: 0.00011023115075659007
step: 10, loss: 0.0005451123579405248
step: 20, loss: 3.689608274726197e-05
step: 30, loss: 0.0030800967942923307
step: 40, loss: 0.0001457144389860332
step: 50, loss: 0.00012403455912135541
step: 60, loss: 9.245330147678033e-05
step: 70, loss: 9.733949264045805e-05
step: 80, loss: 6.312782352324575e-05
step: 90, loss: 6.607619434362277e-05
step: 100, loss: 8.401750528719276e-05
step: 110, loss: 0.00021880889835301787
step: 120, loss: 0.0004034691664855927
step: 130, loss: 0.020251713693141937
step: 140, loss: 0.00037681247340515256
step: 150, loss: 3.703655966091901e-05
step: 160, loss: 1.9553805032046512e-05
step: 170, loss: 7.033995643723756e-05
step: 180, loss: 4.885520684183575e-05
step: 190, loss: 0.00035034544998779893
step: 200, loss: 7.572476170025766e-05
step: 210, loss: 0.0003947288205381483
step: 220, loss: 0.0004170661559328437
step: 230, loss: 3.2601397833786905e-05
step: 240, loss: 6.206917896633968e-05
step: 250, loss: 0.00010075532918563113
step: 260, loss: 0.0012342571280896664
step: 270, loss: 0.0008499340619891882
step: 280, loss: 0.00030775938648730516
step: 290, loss: 0.00012135112774558365
step: 300, loss: 2.2194963094079867e-05
step: 310, loss: 0.00892387144267559
step: 320, loss: 1.676738065725658e-05
step: 330, loss: 0.002707442734390497
epoch 20: dev_f1=0.8129675810473815, f1=0.7931034482758621, best_f1=0.7981438515081206
