cuda
Device: cuda
step: 0, loss: 0.7324099540710449
step: 10, loss: 0.13324300944805145
step: 20, loss: 0.11264020204544067
step: 30, loss: 0.3116610050201416
step: 40, loss: 0.13693584501743317
step: 50, loss: 0.15639403462409973
step: 60, loss: 0.018909838050603867
step: 70, loss: 0.21915802359580994
step: 80, loss: 0.13022010028362274
step: 90, loss: 0.2161865532398224
step: 100, loss: 0.22686682641506195
step: 110, loss: 0.1586766093969345
step: 120, loss: 0.3181817829608917
step: 130, loss: 0.2994863986968994
step: 140, loss: 0.051055118441581726
step: 150, loss: 0.33905482292175293
step: 160, loss: 0.12350954860448837
step: 170, loss: 0.15764988958835602
step: 180, loss: 0.22774231433868408
step: 190, loss: 0.13464798033237457
step: 200, loss: 0.42456769943237305
step: 210, loss: 0.05821843817830086
step: 220, loss: 0.04689602553844452
step: 230, loss: 0.0414816178381443
step: 240, loss: 0.29598355293273926
step: 250, loss: 0.1401815563440323
step: 260, loss: 0.21434873342514038
step: 270, loss: 0.25314486026763916
step: 280, loss: 0.09390074014663696
step: 290, loss: 0.26429513096809387
step: 300, loss: 0.0552687831223011
step: 310, loss: 0.2212163656949997
step: 320, loss: 0.2743138372898102
step: 330, loss: 0.21276992559432983
epoch 1: dev_f1=0.36554621848739494, f1=0.31304347826086953, best_f1=0.31304347826086953
step: 0, loss: 0.04502268508076668
step: 10, loss: 0.23820741474628448
step: 20, loss: 0.16190455853939056
step: 30, loss: 0.21262745559215546
step: 40, loss: 0.23842895030975342
step: 50, loss: 0.11914777010679245
step: 60, loss: 0.0230120737105608
step: 70, loss: 0.10836086422204971
step: 80, loss: 0.1568383425474167
step: 90, loss: 0.10346055030822754
step: 100, loss: 0.10578151047229767
step: 110, loss: 0.11223870515823364
step: 120, loss: 0.034437235444784164
step: 130, loss: 0.03896414488554001
step: 140, loss: 0.035955820232629776
step: 150, loss: 0.14302659034729004
step: 160, loss: 0.044645894318819046
step: 170, loss: 0.09825097024440765
step: 180, loss: 0.11649744212627411
step: 190, loss: 0.31447866559028625
step: 200, loss: 0.04424475133419037
step: 210, loss: 0.10534322261810303
step: 220, loss: 0.07417270541191101
step: 230, loss: 0.05912819132208824
step: 240, loss: 0.1025809496641159
step: 250, loss: 0.04745076969265938
step: 260, loss: 0.13140729069709778
step: 270, loss: 0.05235767364501953
step: 280, loss: 0.05976337939500809
step: 290, loss: 0.08014129847288132
step: 300, loss: 0.04451598599553108
step: 310, loss: 0.1399705559015274
step: 320, loss: 0.17876748740673065
step: 330, loss: 0.11965743452310562
epoch 2: dev_f1=0.8054298642533937, f1=0.7775280898876404, best_f1=0.7775280898876404
step: 0, loss: 0.08844015747308731
step: 10, loss: 0.021677274256944656
step: 20, loss: 0.04973141476511955
step: 30, loss: 0.01818656362593174
step: 40, loss: 0.017459725961089134
step: 50, loss: 0.07780779153108597
step: 60, loss: 0.15091843903064728
step: 70, loss: 0.07534115016460419
step: 80, loss: 0.012982949614524841
step: 90, loss: 0.08814092725515366
step: 100, loss: 0.024884043261408806
step: 110, loss: 0.06020668148994446
step: 120, loss: 0.0062002502381801605
step: 130, loss: 0.005684117320924997
step: 140, loss: 0.02328682132065296
step: 150, loss: 0.057892438024282455
step: 160, loss: 0.022318344563245773
step: 170, loss: 0.054876502603292465
step: 180, loss: 0.03125043213367462
step: 190, loss: 0.045363690704107285
step: 200, loss: 0.0533096119761467
step: 210, loss: 0.021677818149328232
step: 220, loss: 0.010918023064732552
step: 230, loss: 0.13812163472175598
step: 240, loss: 0.06537241488695145
step: 250, loss: 0.013381162658333778
step: 260, loss: 0.08527466654777527
step: 270, loss: 0.05105277895927429
step: 280, loss: 0.010438320226967335
step: 290, loss: 0.07624008506536484
step: 300, loss: 0.0989641323685646
step: 310, loss: 0.021519802510738373
step: 320, loss: 0.06849105656147003
step: 330, loss: 0.05693880468606949
epoch 3: dev_f1=0.7990867579908676, f1=0.7550561797752808, best_f1=0.7775280898876404
step: 0, loss: 0.0683705061674118
step: 10, loss: 0.09704490005970001
step: 20, loss: 0.037223391234874725
step: 30, loss: 0.14489693939685822
step: 40, loss: 0.01798451505601406
step: 50, loss: 0.0067330654710531235
step: 60, loss: 0.009569483809173107
step: 70, loss: 0.0025065692607313395
step: 80, loss: 0.006249919068068266
step: 90, loss: 0.013415955007076263
step: 100, loss: 0.09284266084432602
step: 110, loss: 0.04411762207746506
step: 120, loss: 0.02190515026450157
step: 130, loss: 0.0022777041886001825
step: 140, loss: 0.08608414977788925
step: 150, loss: 0.05515670403838158
step: 160, loss: 0.0211886465549469
step: 170, loss: 0.012316558510065079
step: 180, loss: 0.002479243790730834
step: 190, loss: 0.0755680724978447
step: 200, loss: 0.06086478754878044
step: 210, loss: 0.0015770229510962963
step: 220, loss: 0.026851506903767586
step: 230, loss: 0.001579374191351235
step: 240, loss: 0.005688480567187071
step: 250, loss: 0.012659520842134953
step: 260, loss: 0.16803716123104095
step: 270, loss: 0.2735067307949066
step: 280, loss: 0.01479987520724535
step: 290, loss: 0.016641326248645782
step: 300, loss: 0.004539618268609047
step: 310, loss: 0.04331422224640846
step: 320, loss: 0.11885689198970795
step: 330, loss: 0.043557293713092804
epoch 4: dev_f1=0.8223350253807107, f1=0.7890818858560793, best_f1=0.7890818858560793
step: 0, loss: 0.07008384168148041
step: 10, loss: 0.006769781932234764
step: 20, loss: 0.006871447898447514
step: 30, loss: 0.020678797736763954
step: 40, loss: 0.01888342574238777
step: 50, loss: 0.004140221048146486
step: 60, loss: 0.0004379471647553146
step: 70, loss: 0.00028020417084917426
step: 80, loss: 0.09956276416778564
step: 90, loss: 0.1496054083108902
step: 100, loss: 0.018717624247074127
step: 110, loss: 0.00245932349935174
step: 120, loss: 0.0032646015752106905
step: 130, loss: 0.0191873200237751
step: 140, loss: 0.08330164104700089
step: 150, loss: 0.030710840597748756
step: 160, loss: 0.048532918095588684
step: 170, loss: 0.024059688672423363
step: 180, loss: 0.02889082580804825
step: 190, loss: 0.008779703639447689
step: 200, loss: 0.0011079820105805993
step: 210, loss: 0.014102181419730186
step: 220, loss: 0.001421419088728726
step: 230, loss: 0.07063234597444534
step: 240, loss: 0.0113016776740551
step: 250, loss: 0.02117561176419258
step: 260, loss: 0.016927039250731468
step: 270, loss: 0.12478470802307129
step: 280, loss: 0.0028883402701467276
step: 290, loss: 0.20706747472286224
step: 300, loss: 0.008438827469944954
step: 310, loss: 0.04058871790766716
step: 320, loss: 0.010944291949272156
step: 330, loss: 0.0059804306365549564
epoch 5: dev_f1=0.8031496062992126, f1=0.7643979057591622, best_f1=0.7890818858560793
step: 0, loss: 0.0031990387942641973
step: 10, loss: 0.002016713609918952
step: 20, loss: 0.013027655892074108
step: 30, loss: 0.020789487287402153
step: 40, loss: 0.00031182513339444995
step: 50, loss: 0.00128373468760401
step: 60, loss: 0.004357465077191591
step: 70, loss: 0.0004763587494380772
step: 80, loss: 0.0008855668711476028
step: 90, loss: 0.00352094741538167
step: 100, loss: 0.0019252662314102054
step: 110, loss: 0.0027098481077700853
step: 120, loss: 0.01573305018246174
step: 130, loss: 0.002673091134056449
step: 140, loss: 0.007917909882962704
step: 150, loss: 0.02064547874033451
step: 160, loss: 0.004403391852974892
step: 170, loss: 0.005697219632565975
step: 180, loss: 0.0006767132435925305
step: 190, loss: 0.006337080150842667
step: 200, loss: 0.0005511117051355541
step: 210, loss: 0.10651648044586182
step: 220, loss: 0.0007007205858826637
step: 230, loss: 0.0005079290131106973
step: 240, loss: 0.021496055647730827
step: 250, loss: 0.004082461819052696
step: 260, loss: 0.011258895508944988
step: 270, loss: 0.0005356818437576294
step: 280, loss: 0.016792844980955124
step: 290, loss: 0.029012862592935562
step: 300, loss: 0.0232748594135046
step: 310, loss: 0.11318133771419525
step: 320, loss: 0.0034864081535488367
step: 330, loss: 0.24272677302360535
epoch 6: dev_f1=0.8472906403940887, f1=0.8117359413202935, best_f1=0.8117359413202935
step: 0, loss: 0.00848302710801363
step: 10, loss: 0.017371920868754387
step: 20, loss: 0.00219098012894392
step: 30, loss: 0.02267437055706978
step: 40, loss: 0.007526167202740908
step: 50, loss: 0.01006088126450777
step: 60, loss: 0.0002011802716879174
step: 70, loss: 0.011333453468978405
step: 80, loss: 0.0010562280658632517
step: 90, loss: 0.0014545011799782515
step: 100, loss: 0.006817171815782785
step: 110, loss: 0.0002529916528146714
step: 120, loss: 0.0002259418834000826
step: 130, loss: 0.0011595615651458502
step: 140, loss: 0.00022237859957385808
step: 150, loss: 0.005287809297442436
step: 160, loss: 0.006516610272228718
step: 170, loss: 0.0012469134526327252
step: 180, loss: 0.00010491304419701919
step: 190, loss: 0.139983668923378
step: 200, loss: 0.00014000287046656013
step: 210, loss: 0.06775420159101486
step: 220, loss: 0.0008400829392485321
step: 230, loss: 0.12452652305364609
step: 240, loss: 0.09868735074996948
step: 250, loss: 0.004183555953204632
step: 260, loss: 0.0004752600216306746
step: 270, loss: 0.026553135365247726
step: 280, loss: 0.00438615120947361
step: 290, loss: 0.041990797966718674
step: 300, loss: 0.0008754764567129314
step: 310, loss: 0.011496690101921558
step: 320, loss: 0.004685102496296167
step: 330, loss: 0.013313780538737774
epoch 7: dev_f1=0.8369829683698297, f1=0.7799043062200957, best_f1=0.8117359413202935
step: 0, loss: 0.001415869570337236
step: 10, loss: 0.0006130766705609858
step: 20, loss: 0.0006629989366047084
step: 30, loss: 0.00039475824451074004
step: 40, loss: 0.06654419004917145
step: 50, loss: 0.055622491985559464
step: 60, loss: 5.939305265201256e-05
step: 70, loss: 0.09254427254199982
step: 80, loss: 0.0006703730905428529
step: 90, loss: 0.07511705160140991
step: 100, loss: 0.0032685380429029465
step: 110, loss: 0.0022190003655850887
step: 120, loss: 0.0008246524375863373
step: 130, loss: 0.0002765183162409812
step: 140, loss: 0.002897589933127165
step: 150, loss: 0.00017060065874829888
step: 160, loss: 0.02092411369085312
step: 170, loss: 0.0017858213977888227
step: 180, loss: 0.001721313688904047
step: 190, loss: 6.859118002466857e-05
step: 200, loss: 0.0004878751642536372
step: 210, loss: 0.0026196809485554695
step: 220, loss: 0.03855697065591812
step: 230, loss: 0.0006874968530610204
step: 240, loss: 0.008269018493592739
step: 250, loss: 0.0014465795829892159
step: 260, loss: 0.007810638286173344
step: 270, loss: 0.005764089059084654
step: 280, loss: 0.006334543228149414
step: 290, loss: 0.0003172986034769565
step: 300, loss: 0.006552024744451046
step: 310, loss: 0.0002238756133010611
step: 320, loss: 0.00010578741785138845
step: 330, loss: 0.0004933426971547306
epoch 8: dev_f1=0.8307692307692308, f1=0.7901234567901234, best_f1=0.8117359413202935
step: 0, loss: 0.0014173677191138268
step: 10, loss: 0.0006523834890685976
step: 20, loss: 0.014000996947288513
step: 30, loss: 0.015325423330068588
step: 40, loss: 0.0018815470393747091
step: 50, loss: 4.92140170536004e-05
step: 60, loss: 4.314813486416824e-05
step: 70, loss: 0.07266391068696976
step: 80, loss: 4.547996650217101e-05
step: 90, loss: 0.00036880598054267466
step: 100, loss: 0.00014282746997196227
step: 110, loss: 0.0003702660324051976
step: 120, loss: 0.001149228890426457
step: 130, loss: 0.01977105624973774
step: 140, loss: 0.000179833616130054
step: 150, loss: 0.00012923897884320468
step: 160, loss: 0.0001311259693466127
step: 170, loss: 0.000959938217420131
step: 180, loss: 0.0010109422728419304
step: 190, loss: 0.013079292140901089
step: 200, loss: 0.002880578627809882
step: 210, loss: 0.008084161207079887
step: 220, loss: 0.0007460450869984925
step: 230, loss: 0.00022724203881807625
step: 240, loss: 0.06064334511756897
step: 250, loss: 0.0004114661714993417
step: 260, loss: 0.001626142067834735
step: 270, loss: 0.00219164346344769
step: 280, loss: 0.00019446587248239666
step: 290, loss: 0.00015515669656451792
step: 300, loss: 0.0440291129052639
step: 310, loss: 0.0015323993284255266
step: 320, loss: 0.0005884303827770054
step: 330, loss: 0.0002523281436879188
epoch 9: dev_f1=0.8179551122194514, f1=0.7857142857142858, best_f1=0.8117359413202935
step: 0, loss: 0.0010103138629347086
step: 10, loss: 0.017227698117494583
step: 20, loss: 0.0001544212136650458
step: 30, loss: 0.02389230579137802
step: 40, loss: 0.0007401966140605509
step: 50, loss: 0.011745709925889969
step: 60, loss: 0.0012864897726103663
step: 70, loss: 0.014791907742619514
step: 80, loss: 0.00010441613994771615
step: 90, loss: 0.001065352582372725
step: 100, loss: 0.04013179615139961
step: 110, loss: 0.01301639061421156
step: 120, loss: 0.00018828402971848845
step: 130, loss: 0.0005907996674068272
step: 140, loss: 0.005965451244264841
step: 150, loss: 0.0059135849587619305
step: 160, loss: 0.0012029829667881131
step: 170, loss: 0.01060051005333662
step: 180, loss: 0.10129567235708237
step: 190, loss: 0.0008794625173322856
step: 200, loss: 4.5339871576288715e-05
step: 210, loss: 0.0003522152837831527
step: 220, loss: 9.682727250037715e-05
step: 230, loss: 0.02310001663863659
step: 240, loss: 0.028665034100413322
step: 250, loss: 0.0004287209885660559
step: 260, loss: 0.0008736124727874994
step: 270, loss: 3.67930369975511e-05
step: 280, loss: 0.02816717140376568
step: 290, loss: 0.009124906733632088
step: 300, loss: 0.00011723523493856192
step: 310, loss: 0.0008353102020919323
step: 320, loss: 0.0016783967148512602
step: 330, loss: 0.013516836799681187
epoch 10: dev_f1=0.797979797979798, f1=0.774818401937046, best_f1=0.8117359413202935
step: 0, loss: 0.01728661172091961
step: 10, loss: 0.022139202803373337
step: 20, loss: 0.00036815612111240625
step: 30, loss: 0.00016301085997838527
step: 40, loss: 0.06368784606456757
step: 50, loss: 0.00022230230388231575
step: 60, loss: 0.0003862166195176542
step: 70, loss: 0.0008685575448907912
step: 80, loss: 0.0015498865395784378
step: 90, loss: 0.0016456228913739324
step: 100, loss: 0.0002893182390835136
step: 110, loss: 0.00022744189482182264
step: 120, loss: 0.015940174460411072
step: 130, loss: 0.0022785873152315617
step: 140, loss: 0.008035107515752316
step: 150, loss: 4.526468910626136e-05
step: 160, loss: 0.00014839376672171056
step: 170, loss: 0.00057786371326074
step: 180, loss: 0.00020249192311894149
step: 190, loss: 0.00022699446708429605
step: 200, loss: 0.00864324253052473
step: 210, loss: 0.0002912763739004731
step: 220, loss: 0.0011816284386441112
step: 230, loss: 9.04748885659501e-05
step: 240, loss: 8.06806783657521e-05
step: 250, loss: 0.00025660297251306474
step: 260, loss: 0.00026437267661094666
step: 270, loss: 0.004701127763837576
step: 280, loss: 0.0057608154602348804
step: 290, loss: 6.489026418421417e-05
step: 300, loss: 5.138359119882807e-05
step: 310, loss: 0.005754897370934486
step: 320, loss: 0.0001591298496350646
step: 330, loss: 9.651131404098123e-05
epoch 11: dev_f1=0.7961630695443646, f1=0.771764705882353, best_f1=0.8117359413202935
step: 0, loss: 0.04665232077240944
step: 10, loss: 0.05721379444003105
step: 20, loss: 0.008924785070121288
step: 30, loss: 0.0004373341507744044
step: 40, loss: 0.0002923262945841998
step: 50, loss: 0.0009958629962056875
step: 60, loss: 0.00012833620712626725
step: 70, loss: 0.0002516609674785286
step: 80, loss: 0.006909823510795832
step: 90, loss: 0.00011526078742463142
step: 100, loss: 3.570945409592241e-05
step: 110, loss: 0.00010358144936617464
step: 120, loss: 9.167293319478631e-05
step: 130, loss: 0.029234629124403
step: 140, loss: 0.0011746982345357537
step: 150, loss: 0.0003936702851206064
step: 160, loss: 0.00014730606926605105
step: 170, loss: 0.00012246651749592274
step: 180, loss: 0.040394317358732224
step: 190, loss: 0.0007102643721736968
step: 200, loss: 0.009880761615931988
step: 210, loss: 0.005302597768604755
step: 220, loss: 0.007342074066400528
step: 230, loss: 0.00018396219820715487
step: 240, loss: 0.00024463472072966397
step: 250, loss: 0.0002448416198603809
step: 260, loss: 0.00019273215730208904
step: 270, loss: 0.006453270558267832
step: 280, loss: 6.744149868609384e-05
step: 290, loss: 0.0002373288880335167
step: 300, loss: 0.04643929749727249
step: 310, loss: 4.164937854511663e-05
step: 320, loss: 0.00030239662737585604
step: 330, loss: 0.0014325499068945646
epoch 12: dev_f1=0.8329048843187661, f1=0.8020050125313284, best_f1=0.8117359413202935
step: 0, loss: 0.0009883628226816654
step: 10, loss: 0.0012922000605612993
step: 20, loss: 0.00018968290532939136
step: 30, loss: 5.7396391639485955e-05
step: 40, loss: 0.0006966520450077951
step: 50, loss: 0.00016952060104813427
step: 60, loss: 0.00018769875168800354
step: 70, loss: 0.00019015335419680923
step: 80, loss: 0.013663280755281448
step: 90, loss: 0.00041634650551714003
step: 100, loss: 0.00024806216242723167
step: 110, loss: 2.368128662055824e-05
step: 120, loss: 7.009037653915584e-05
step: 130, loss: 0.00042511336505413055
step: 140, loss: 5.31066361872945e-05
step: 150, loss: 0.00019261256966274232
step: 160, loss: 0.0014803454978391528
step: 170, loss: 0.00040837927372194827
step: 180, loss: 0.009110941551625729
step: 190, loss: 0.006186738144606352
step: 200, loss: 0.002578585874289274
step: 210, loss: 0.00036720759817399085
step: 220, loss: 0.00043496908619999886
step: 230, loss: 0.0004962862585671246
step: 240, loss: 0.0013063655933365226
step: 250, loss: 0.0009864068124443293
step: 260, loss: 0.00020544417202472687
step: 270, loss: 0.003930156119167805
step: 280, loss: 0.004427080042660236
step: 290, loss: 0.0009228299604728818
step: 300, loss: 0.003154648467898369
step: 310, loss: 0.0011567585170269012
step: 320, loss: 0.0004312605015002191
step: 330, loss: 0.0010832484113052487
epoch 13: dev_f1=0.8162291169451074, f1=0.7660550458715597, best_f1=0.8117359413202935
step: 0, loss: 0.015903476625680923
step: 10, loss: 0.0004778703732881695
step: 20, loss: 0.0019245442235842347
step: 30, loss: 0.007641657255589962
step: 40, loss: 0.0015527892392128706
step: 50, loss: 0.005513932090252638
step: 60, loss: 1.8980150343850255e-05
step: 70, loss: 0.001976578263565898
step: 80, loss: 9.243961540050805e-05
step: 90, loss: 0.04577901214361191
step: 100, loss: 0.042596906423568726
step: 110, loss: 8.641260501462966e-05
step: 120, loss: 0.0003070926759392023
step: 130, loss: 0.012331443838775158
step: 140, loss: 4.219211405143142e-05
step: 150, loss: 0.04194644093513489
step: 160, loss: 0.00025470199761912227
step: 170, loss: 0.0006045061745680869
step: 180, loss: 0.00017973955255001783
step: 190, loss: 0.00022570256260223687
step: 200, loss: 3.985235161962919e-05
step: 210, loss: 8.813922613626346e-05
step: 220, loss: 5.5805507145123556e-05
step: 230, loss: 0.11218272894620895
step: 240, loss: 6.445432518376037e-05
step: 250, loss: 0.0012162518687546253
step: 260, loss: 0.005235406570136547
step: 270, loss: 8.980187703855336e-05
step: 280, loss: 0.00011045479186577722
step: 290, loss: 8.849114237818867e-05
step: 300, loss: 4.1067818528972566e-05
step: 310, loss: 2.8672515327343717e-05
step: 320, loss: 0.00821174867451191
step: 330, loss: 0.005745850037783384
epoch 14: dev_f1=0.7740259740259741, f1=0.7461928934010152, best_f1=0.8117359413202935
step: 0, loss: 0.0004493981250561774
step: 10, loss: 9.638429037295282e-05
step: 20, loss: 0.0017374259186908603
step: 30, loss: 0.00017626052431296557
step: 40, loss: 6.490996020147577e-05
step: 50, loss: 7.593045302201062e-05
step: 60, loss: 6.177496106829494e-05
step: 70, loss: 0.00024356276844628155
step: 80, loss: 5.725042865378782e-05
step: 90, loss: 9.025335020851344e-05
step: 100, loss: 3.6903744330629706e-05
step: 110, loss: 3.101919355685823e-05
step: 120, loss: 0.03383723273873329
step: 130, loss: 7.442366040777415e-05
step: 140, loss: 7.136057683965191e-05
step: 150, loss: 4.1942450479837134e-05
step: 160, loss: 4.8955174861475825e-05
step: 170, loss: 0.0011664620833471417
step: 180, loss: 2.967051841551438e-05
step: 190, loss: 7.463271322194487e-05
step: 200, loss: 3.128344542346895e-05
step: 210, loss: 2.0138491890975274e-05
step: 220, loss: 0.00017266230133827776
step: 230, loss: 0.0035919975489377975
step: 240, loss: 0.0003035453846678138
step: 250, loss: 0.00010465254308655858
step: 260, loss: 0.011773239821195602
step: 270, loss: 8.847336721373722e-05
step: 280, loss: 0.05112355947494507
step: 290, loss: 7.650338375242427e-05
step: 300, loss: 0.001968854572623968
step: 310, loss: 7.573489710921422e-05
step: 320, loss: 0.0005513604846782982
step: 330, loss: 0.00060268520610407
epoch 15: dev_f1=0.8232189973614776, f1=0.7801047120418847, best_f1=0.8117359413202935
step: 0, loss: 7.444196671713144e-05
step: 10, loss: 2.330405914108269e-05
step: 20, loss: 8.674034324940294e-05
step: 30, loss: 2.771038816717919e-05
step: 40, loss: 0.0002356801851419732
step: 50, loss: 0.011594031937420368
step: 60, loss: 4.935219476465136e-05
step: 70, loss: 8.810021245153621e-05
step: 80, loss: 7.782889588270336e-05
step: 90, loss: 0.0003317756054457277
step: 100, loss: 0.00011985744640696794
step: 110, loss: 5.0905793614219874e-05
step: 120, loss: 0.000542038178537041
step: 130, loss: 0.012937777675688267
step: 140, loss: 0.0001890953426482156
step: 150, loss: 0.00010451282287249342
step: 160, loss: 0.014238941483199596
step: 170, loss: 0.00037325770244933665
step: 180, loss: 3.004652535310015e-05
step: 190, loss: 4.8693211283534765e-05
step: 200, loss: 6.728730659233406e-05
step: 210, loss: 0.0010758553398773074
step: 220, loss: 0.1660740077495575
step: 230, loss: 0.00018403053400106728
step: 240, loss: 0.0010416415752843022
step: 250, loss: 0.0020276550203561783
step: 260, loss: 0.0007621650584042072
step: 270, loss: 0.00023022419190965593
step: 280, loss: 0.00021353052579797804
step: 290, loss: 0.00020510386093519628
step: 300, loss: 0.004915041849017143
step: 310, loss: 0.0007733314414508641
step: 320, loss: 4.641008854378015e-05
step: 330, loss: 4.2714542360045016e-05
epoch 16: dev_f1=0.8052631578947368, f1=0.7733333333333334, best_f1=0.8117359413202935
step: 0, loss: 7.539148646173999e-05
step: 10, loss: 0.055919766426086426
step: 20, loss: 0.00015721905219834298
step: 30, loss: 0.001579070696607232
step: 40, loss: 6.80761513649486e-05
step: 50, loss: 6.038896390236914e-05
step: 60, loss: 0.00034871548996306956
step: 70, loss: 0.00011042077676393092
step: 80, loss: 4.130429806536995e-05
step: 90, loss: 6.292892066994682e-05
step: 100, loss: 0.004005893599241972
step: 110, loss: 0.006038286257535219
step: 120, loss: 8.662256732350215e-05
step: 130, loss: 9.24605192267336e-05
step: 140, loss: 0.000580995692871511
step: 150, loss: 0.00022947471006773412
step: 160, loss: 0.020029112696647644
step: 170, loss: 5.4564501624554396e-05
step: 180, loss: 0.06558778882026672
step: 190, loss: 0.0001100007284549065
step: 200, loss: 0.00012283776595722884
step: 210, loss: 5.3446849051397294e-05
step: 220, loss: 4.5526045141741633e-05
step: 230, loss: 0.004161369986832142
step: 240, loss: 7.272760558407754e-05
step: 250, loss: 9.57627926254645e-05
step: 260, loss: 7.059777999529615e-05
step: 270, loss: 5.9064619563287124e-05
step: 280, loss: 0.00016862014308571815
step: 290, loss: 0.0008503348799422383
step: 300, loss: 0.00041928020073100924
step: 310, loss: 0.00011833743337774649
step: 320, loss: 0.008453438989818096
step: 330, loss: 0.00288679962977767
epoch 17: dev_f1=0.8124999999999999, f1=0.7857142857142858, best_f1=0.8117359413202935
step: 0, loss: 0.008072330616414547
step: 10, loss: 4.5302571379579604e-05
step: 20, loss: 0.01511973887681961
step: 30, loss: 0.0007053217850625515
step: 40, loss: 0.012814945541322231
step: 50, loss: 6.771818152628839e-05
step: 60, loss: 0.00027178815798833966
step: 70, loss: 0.0003164149820804596
step: 80, loss: 0.00020560190023388714
step: 90, loss: 0.00010766351624624804
step: 100, loss: 4.543738759821281e-05
step: 110, loss: 6.354282231768593e-05
step: 120, loss: 3.0426384910242632e-05
step: 130, loss: 9.433679224457592e-05
step: 140, loss: 0.00023233311367221177
step: 150, loss: 6.210432184161618e-05
step: 160, loss: 0.00011233532131882384
step: 170, loss: 0.00014136565732769668
step: 180, loss: 6.860238499939442e-05
step: 190, loss: 5.274462455417961e-05
step: 200, loss: 6.0794514865847304e-05
step: 210, loss: 0.0017384989187121391
step: 220, loss: 3.5421078791841865e-05
step: 230, loss: 5.718255852116272e-05
step: 240, loss: 4.2910884076263756e-05
step: 250, loss: 4.8200032324530184e-05
step: 260, loss: 6.199529889272526e-05
step: 270, loss: 0.00029038579668849707
step: 280, loss: 4.1696446714922786e-05
step: 290, loss: 0.00023471825988963246
step: 300, loss: 0.0038289648946374655
step: 310, loss: 4.985011764802039e-05
step: 320, loss: 0.00020652134844567627
step: 330, loss: 8.890407480066642e-05
epoch 18: dev_f1=0.8, f1=0.7922705314009661, best_f1=0.8117359413202935
step: 0, loss: 0.0006318238447420299
step: 10, loss: 2.0119692635489628e-05
step: 20, loss: 0.00013378677249420434
step: 30, loss: 6.325589492917061e-05
step: 40, loss: 5.977406908641569e-05
step: 50, loss: 0.0009449922363273799
step: 60, loss: 0.0007780020823702216
step: 70, loss: 0.0005586760817095637
step: 80, loss: 0.018523115664720535
step: 90, loss: 5.109752601129003e-05
step: 100, loss: 4.8982645239448175e-05
step: 110, loss: 0.0010670475894585252
step: 120, loss: 6.126840889919549e-05
step: 130, loss: 0.0002801779774017632
step: 140, loss: 0.00010977769125020131
step: 150, loss: 2.6727229851530865e-05
step: 160, loss: 2.957969445560593e-05
step: 170, loss: 9.777076775208116e-05
step: 180, loss: 2.4272771042888053e-05
step: 190, loss: 0.0015532714314758778
step: 200, loss: 0.02755313739180565
step: 210, loss: 0.00938475877046585
step: 220, loss: 7.93800936662592e-05
step: 230, loss: 8.488610183121637e-05
step: 240, loss: 1.3187417607696261e-05
step: 250, loss: 0.00038704610778950155
step: 260, loss: 8.438807708444074e-05
step: 270, loss: 0.0001806586078600958
step: 280, loss: 6.363380089169368e-05
step: 290, loss: 5.101958231534809e-05
step: 300, loss: 0.0016761794686317444
step: 310, loss: 3.113718776148744e-05
step: 320, loss: 6.562531052622944e-05
step: 330, loss: 1.2367858289508149e-05
epoch 19: dev_f1=0.801980198019802, f1=0.7951219512195121, best_f1=0.8117359413202935
step: 0, loss: 3.398704211576842e-05
step: 10, loss: 0.08066130429506302
step: 20, loss: 5.636159039568156e-05
step: 30, loss: 1.2095929378119763e-05
step: 40, loss: 9.105101344175637e-05
step: 50, loss: 0.0002569207572378218
step: 60, loss: 0.00713401148095727
step: 70, loss: 0.0003205904213245958
step: 80, loss: 0.003575780661776662
step: 90, loss: 1.7866206690086983e-05
step: 100, loss: 0.0010697736870497465
step: 110, loss: 2.501283051969949e-05
step: 120, loss: 6.261545786401257e-05
step: 130, loss: 0.0005703545757569373
step: 140, loss: 0.008913697674870491
step: 150, loss: 0.052819930016994476
step: 160, loss: 0.0001220225021825172
step: 170, loss: 5.79839943384286e-05
step: 180, loss: 4.8522637371206656e-05
step: 190, loss: 0.0003330693580210209
step: 200, loss: 5.748863986809738e-05
step: 210, loss: 0.011131624691188335
step: 220, loss: 3.48800458596088e-05
step: 230, loss: 7.711518264841288e-05
step: 240, loss: 3.500317325233482e-05
step: 250, loss: 3.581441706046462e-05
step: 260, loss: 7.151236786739901e-05
step: 270, loss: 0.00026598834665492177
step: 280, loss: 3.151760756736621e-05
step: 290, loss: 4.408944005263038e-05
step: 300, loss: 2.870927710318938e-05
step: 310, loss: 0.00020687039068434387
step: 320, loss: 0.0002145996259059757
step: 330, loss: 1.8328093574382365e-05
epoch 20: dev_f1=0.8, f1=0.7840375586854459, best_f1=0.8117359413202935
