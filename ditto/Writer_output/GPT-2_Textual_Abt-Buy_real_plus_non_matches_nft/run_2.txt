cuda
Device: cuda
step: 0, loss: 0.6784899234771729
step: 10, loss: 0.14543917775154114
step: 20, loss: 0.23711125552654266
step: 30, loss: 0.22726856172084808
step: 40, loss: 0.22553615272045135
step: 50, loss: 0.047700535506010056
step: 60, loss: 0.12707093358039856
step: 70, loss: 0.2182503342628479
step: 80, loss: 0.10244956612586975
step: 90, loss: 0.22880466282367706
step: 100, loss: 0.2455170899629593
step: 110, loss: 0.1349668800830841
step: 120, loss: 0.3306334912776947
step: 130, loss: 0.30423104763031006
step: 140, loss: 0.24179449677467346
step: 150, loss: 0.4800495505332947
step: 160, loss: 0.2935827374458313
step: 170, loss: 0.30018162727355957
step: 180, loss: 0.1687864065170288
step: 190, loss: 0.21004462242126465
step: 200, loss: 0.1362050622701645
step: 210, loss: 0.1586030274629593
step: 220, loss: 0.2420944720506668
step: 230, loss: 0.05532308667898178
step: 240, loss: 0.05669476464390755
step: 250, loss: 0.27704593539237976
step: 260, loss: 0.26462966203689575
step: 270, loss: 0.051194481551647186
step: 280, loss: 0.1781575083732605
step: 290, loss: 0.4202301800251007
step: 300, loss: 0.12237244099378586
step: 310, loss: 0.34708917140960693
step: 320, loss: 0.1385755091905594
step: 330, loss: 0.12547282874584198
epoch 1: dev_f1=0.4307178631051753, f1=0.37438423645320196, best_f1=0.37438423645320196
step: 0, loss: 0.13705362379550934
step: 10, loss: 0.18732140958309174
step: 20, loss: 0.18800264596939087
step: 30, loss: 0.1664528250694275
step: 40, loss: 0.2018631547689438
step: 50, loss: 0.07034031301736832
step: 60, loss: 0.17739060521125793
step: 70, loss: 0.23614314198493958
step: 80, loss: 0.046360407024621964
step: 90, loss: 0.09903877228498459
step: 100, loss: 0.014787571504712105
step: 110, loss: 0.033078525215387344
step: 120, loss: 0.24192291498184204
step: 130, loss: 0.292586088180542
step: 140, loss: 0.12782169878482819
step: 150, loss: 0.04618246480822563
step: 160, loss: 0.012573492713272572
step: 170, loss: 0.04969944804906845
step: 180, loss: 0.16718560457229614
step: 190, loss: 0.11293189972639084
step: 200, loss: 0.20669318735599518
step: 210, loss: 0.3784528076648712
step: 220, loss: 0.07407095283269882
step: 230, loss: 0.16049648821353912
step: 240, loss: 0.08810196071863174
step: 250, loss: 0.1361972540616989
step: 260, loss: 0.04434908553957939
step: 270, loss: 0.18011118471622467
step: 280, loss: 0.02564006671309471
step: 290, loss: 0.16802935302257538
step: 300, loss: 0.1125880777835846
step: 310, loss: 0.07340942323207855
step: 320, loss: 0.12447508424520493
step: 330, loss: 0.18456535041332245
epoch 2: dev_f1=0.7130044843049327, f1=0.6941431670281996, best_f1=0.6941431670281996
step: 0, loss: 0.047941870987415314
step: 10, loss: 0.2480984777212143
step: 20, loss: 0.10089285671710968
step: 30, loss: 0.044600196182727814
step: 40, loss: 0.05273786559700966
step: 50, loss: 0.04868136718869209
step: 60, loss: 0.08813950419425964
step: 70, loss: 0.05385298281908035
step: 80, loss: 0.05186256766319275
step: 90, loss: 0.06041356176137924
step: 100, loss: 0.01840396039187908
step: 110, loss: 0.039075788110494614
step: 120, loss: 0.05544052645564079
step: 130, loss: 0.12147127091884613
step: 140, loss: 0.16431529819965363
step: 150, loss: 0.02048131451010704
step: 160, loss: 0.10474313050508499
step: 170, loss: 0.07373597472906113
step: 180, loss: 0.10514932870864868
step: 190, loss: 0.056572325527668
step: 200, loss: 0.043525561690330505
step: 210, loss: 0.034478213638067245
step: 220, loss: 0.06266974657773972
step: 230, loss: 0.022844010964035988
step: 240, loss: 0.07505066692829132
step: 250, loss: 0.057931434363126755
step: 260, loss: 0.09681718051433563
step: 270, loss: 0.0022861871402710676
step: 280, loss: 0.07141576707363129
step: 290, loss: 0.016247155144810677
step: 300, loss: 0.05679288133978844
step: 310, loss: 0.1065337210893631
step: 320, loss: 0.07895071059465408
step: 330, loss: 0.01997547224164009
epoch 3: dev_f1=0.8151447661469933, f1=0.7930283224400873, best_f1=0.7930283224400873
step: 0, loss: 0.04340879246592522
step: 10, loss: 0.004200962372124195
step: 20, loss: 0.003865940496325493
step: 30, loss: 0.09948763996362686
step: 40, loss: 0.004948275163769722
step: 50, loss: 0.014754765667021275
step: 60, loss: 0.08366912603378296
step: 70, loss: 0.046159591525793076
step: 80, loss: 0.03621414303779602
step: 90, loss: 0.0007490112911909819
step: 100, loss: 0.0333072803914547
step: 110, loss: 0.002644576597958803
step: 120, loss: 0.13716056942939758
step: 130, loss: 0.049689821898937225
step: 140, loss: 0.09060501307249069
step: 150, loss: 0.017499195411801338
step: 160, loss: 0.099235899746418
step: 170, loss: 0.05057504028081894
step: 180, loss: 0.0015064572216942906
step: 190, loss: 0.023111851885914803
step: 200, loss: 0.007226519286632538
step: 210, loss: 0.027774207293987274
step: 220, loss: 0.004670383408665657
step: 230, loss: 0.033625971525907516
step: 240, loss: 0.02902635745704174
step: 250, loss: 0.006932899355888367
step: 260, loss: 0.008531256578862667
step: 270, loss: 0.009375751949846745
step: 280, loss: 0.01892075501382351
step: 290, loss: 0.04259592294692993
step: 300, loss: 0.03736618161201477
step: 310, loss: 0.0439278744161129
step: 320, loss: 0.017044976353645325
step: 330, loss: 0.05602342635393143
epoch 4: dev_f1=0.791469194312796, f1=0.7824074074074074, best_f1=0.7930283224400873
step: 0, loss: 0.038502663373947144
step: 10, loss: 0.011503969319164753
step: 20, loss: 0.06674979627132416
step: 30, loss: 0.019465738907456398
step: 40, loss: 0.02797538973391056
step: 50, loss: 0.034462545067071915
step: 60, loss: 0.057781852781772614
step: 70, loss: 0.002187581965699792
step: 80, loss: 0.08401346206665039
step: 90, loss: 0.05633152648806572
step: 100, loss: 0.0010698875412344933
step: 110, loss: 0.039213333278894424
step: 120, loss: 0.11870083212852478
step: 130, loss: 0.005121162161231041
step: 140, loss: 0.0014212215319275856
step: 150, loss: 0.0036098272539675236
step: 160, loss: 0.008581706322729588
step: 170, loss: 0.0016822085017338395
step: 180, loss: 0.02193448878824711
step: 190, loss: 0.011549398303031921
step: 200, loss: 0.06443676352500916
step: 210, loss: 0.0011273155687376857
step: 220, loss: 0.04411084204912186
step: 230, loss: 0.05534965917468071
step: 240, loss: 0.0011886463034898043
step: 250, loss: 0.0021928499918431044
step: 260, loss: 0.02329360693693161
step: 270, loss: 0.0028564161621034145
step: 280, loss: 0.015721047297120094
step: 290, loss: 0.00483686150982976
step: 300, loss: 0.011627351865172386
step: 310, loss: 0.011905872263014317
step: 320, loss: 0.008239217102527618
step: 330, loss: 0.0033756305929273367
epoch 5: dev_f1=0.7459207459207459, f1=0.7546296296296297, best_f1=0.7930283224400873
step: 0, loss: 0.009509225375950336
step: 10, loss: 0.0030549196526408195
step: 20, loss: 0.010535295121371746
step: 30, loss: 0.014343420043587685
step: 40, loss: 0.0747193992137909
step: 50, loss: 0.0015445250319316983
step: 60, loss: 0.012479562312364578
step: 70, loss: 0.014485969208180904
step: 80, loss: 0.001278422656469047
step: 90, loss: 0.035511333495378494
step: 100, loss: 0.004717733711004257
step: 110, loss: 0.002962982514873147
step: 120, loss: 0.006444282364100218
step: 130, loss: 0.004111070651561022
step: 140, loss: 0.010259171016514301
step: 150, loss: 0.024877959862351418
step: 160, loss: 0.0937979444861412
step: 170, loss: 0.0006126396474428475
step: 180, loss: 0.001374829444102943
step: 190, loss: 0.052836235612630844
step: 200, loss: 0.07625596225261688
step: 210, loss: 0.010715300217270851
step: 220, loss: 0.041864797472953796
step: 230, loss: 0.006738640833646059
step: 240, loss: 0.006028067786246538
step: 250, loss: 0.0020255595445632935
step: 260, loss: 0.001919314730912447
step: 270, loss: 0.00577616598457098
step: 280, loss: 0.006871427875012159
step: 290, loss: 0.015136504545807838
step: 300, loss: 0.16383561491966248
step: 310, loss: 0.05214694142341614
step: 320, loss: 0.0036390412133187056
step: 330, loss: 0.20405006408691406
epoch 6: dev_f1=0.7932692307692307, f1=0.7499999999999999, best_f1=0.7930283224400873
step: 0, loss: 0.0005017070798203349
step: 10, loss: 0.003409268567338586
step: 20, loss: 0.0004673483781516552
step: 30, loss: 0.0020388211123645306
step: 40, loss: 0.17568814754486084
step: 50, loss: 0.005329979583621025
step: 60, loss: 0.0007454807055182755
step: 70, loss: 0.00834822840988636
step: 80, loss: 0.0018086774507537484
step: 90, loss: 0.00012566926307044923
step: 100, loss: 0.007250417489558458
step: 110, loss: 0.003070998936891556
step: 120, loss: 0.17381830513477325
step: 130, loss: 0.002375195501372218
step: 140, loss: 0.0059191444888710976
step: 150, loss: 0.00892656110227108
step: 160, loss: 0.0028413550462573767
step: 170, loss: 0.0006997749442234635
step: 180, loss: 0.12022489309310913
step: 190, loss: 0.07048039883375168
step: 200, loss: 0.04212963953614235
step: 210, loss: 0.002832864411175251
step: 220, loss: 0.038516197353601456
step: 230, loss: 0.00033590890234336257
step: 240, loss: 0.0011699036695063114
step: 250, loss: 0.00856674462556839
step: 260, loss: 0.004682278260588646
step: 270, loss: 0.021080490201711655
step: 280, loss: 0.026318848133087158
step: 290, loss: 0.001801216509193182
step: 300, loss: 0.0005640521412715316
step: 310, loss: 0.17857268452644348
step: 320, loss: 0.007005931809544563
step: 330, loss: 0.0030859431717544794
epoch 7: dev_f1=0.7953488372093023, f1=0.7790432801822323, best_f1=0.7930283224400873
step: 0, loss: 0.029970522969961166
step: 10, loss: 0.021828001365065575
step: 20, loss: 0.007536220829933882
step: 30, loss: 0.10924199968576431
step: 40, loss: 0.007460291031748056
step: 50, loss: 0.008027088828384876
step: 60, loss: 0.004543859511613846
step: 70, loss: 0.048932965844869614
step: 80, loss: 0.003811581525951624
step: 90, loss: 0.0005796912591904402
step: 100, loss: 0.05388490483164787
step: 110, loss: 0.0003148756513837725
step: 120, loss: 0.0020556626841425896
step: 130, loss: 0.019184662029147148
step: 140, loss: 0.0007384591153822839
step: 150, loss: 0.011034517548978329
step: 160, loss: 0.0004121405945625156
step: 170, loss: 0.000360853475285694
step: 180, loss: 0.002756234025582671
step: 190, loss: 0.07675774395465851
step: 200, loss: 0.0016869055107235909
step: 210, loss: 0.003270577173680067
step: 220, loss: 0.008435867726802826
step: 230, loss: 0.00814378447830677
step: 240, loss: 4.717150659416802e-05
step: 250, loss: 0.006660834886133671
step: 260, loss: 9.966407378669828e-05
step: 270, loss: 0.004678761120885611
step: 280, loss: 0.0115115437656641
step: 290, loss: 0.0006602777866646647
step: 300, loss: 0.0006728347507305443
step: 310, loss: 0.04530203342437744
step: 320, loss: 0.0001836498558986932
step: 330, loss: 0.012880169786512852
epoch 8: dev_f1=0.7729468599033817, f1=0.7412935323383084, best_f1=0.7930283224400873
step: 0, loss: 0.007947093807160854
step: 10, loss: 0.08171986788511276
step: 20, loss: 0.00024069934443105012
step: 30, loss: 0.002345685614272952
step: 40, loss: 0.000620398495811969
step: 50, loss: 0.0008365761023014784
step: 60, loss: 0.0001032112049870193
step: 70, loss: 0.01887756958603859
step: 80, loss: 0.06019265204668045
step: 90, loss: 0.0023405065294355154
step: 100, loss: 4.9076075811171904e-05
step: 110, loss: 0.005426900926977396
step: 120, loss: 0.006285977549850941
step: 130, loss: 0.016149982810020447
step: 140, loss: 0.0002512474311515689
step: 150, loss: 0.0016930245328694582
step: 160, loss: 0.024289363995194435
step: 170, loss: 0.0008443578262813389
step: 180, loss: 0.0016679437831044197
step: 190, loss: 0.0021717373747378588
step: 200, loss: 0.00027997844154015183
step: 210, loss: 0.029157478362321854
step: 220, loss: 0.0033495137467980385
step: 230, loss: 0.019127443432807922
step: 240, loss: 0.0025113942101597786
step: 250, loss: 0.04222513735294342
step: 260, loss: 0.0003955158172175288
step: 270, loss: 0.013463002629578114
step: 280, loss: 0.004754248075187206
step: 290, loss: 0.009182475507259369
step: 300, loss: 0.127534419298172
step: 310, loss: 0.0017552628414705396
step: 320, loss: 0.00441698869690299
step: 330, loss: 0.009286744520068169
epoch 9: dev_f1=0.7611940298507462, f1=0.7642679900744417, best_f1=0.7930283224400873
step: 0, loss: 0.0001807495573302731
step: 10, loss: 0.0026231249794363976
step: 20, loss: 0.0049665034748613834
step: 30, loss: 5.339983181329444e-05
step: 40, loss: 0.00020655190746765584
step: 50, loss: 0.00025359317078255117
step: 60, loss: 0.011192691512405872
step: 70, loss: 0.000460433482658118
step: 80, loss: 0.001474579912610352
step: 90, loss: 0.0031676075886934996
step: 100, loss: 0.01639881357550621
step: 110, loss: 0.023053297773003578
step: 120, loss: 0.03445599228143692
step: 130, loss: 0.047739867120981216
step: 140, loss: 0.0011924111749976873
step: 150, loss: 0.011189086362719536
step: 160, loss: 8.907317533157766e-05
step: 170, loss: 0.01184923481196165
step: 180, loss: 0.00011522981367306784
step: 190, loss: 0.0020028208382427692
step: 200, loss: 6.909097282914445e-05
step: 210, loss: 0.0034365500323474407
step: 220, loss: 0.0036068230401724577
step: 230, loss: 0.008910390548408031
step: 240, loss: 0.00040261659887619317
step: 250, loss: 0.07327809184789658
step: 260, loss: 0.001140572945587337
step: 270, loss: 0.0005713011487387121
step: 280, loss: 0.0206342414021492
step: 290, loss: 0.000597017293330282
step: 300, loss: 0.002215375890955329
step: 310, loss: 0.0010244286386296153
step: 320, loss: 0.0004675775417126715
step: 330, loss: 0.00309932348318398
epoch 10: dev_f1=0.78125, f1=0.7609254498714653, best_f1=0.7930283224400873
step: 0, loss: 0.004177352879196405
step: 10, loss: 0.001151512609794736
step: 20, loss: 0.0004205164732411504
step: 30, loss: 0.0013877162709832191
step: 40, loss: 0.0009118792950175703
step: 50, loss: 0.0020643151365220547
step: 60, loss: 0.0045208800584077835
step: 70, loss: 0.00018302326498087496
step: 80, loss: 0.013102839700877666
step: 90, loss: 0.0005348978447727859
step: 100, loss: 0.003672149032354355
step: 110, loss: 0.00012432092626113445
step: 120, loss: 0.00040513850399293005
step: 130, loss: 0.005084195639938116
step: 140, loss: 0.0072683487087488174
step: 150, loss: 0.00032056632335297763
step: 160, loss: 0.00020941351249348372
step: 170, loss: 0.000994789064861834
step: 180, loss: 0.0002034707140410319
step: 190, loss: 0.0010200606193393469
step: 200, loss: 0.00027274482999928296
step: 210, loss: 0.0037800376303493977
step: 220, loss: 9.447652701055631e-05
step: 230, loss: 0.0005323844961822033
step: 240, loss: 3.087044751737267e-05
step: 250, loss: 3.978728273068555e-05
step: 260, loss: 0.00015720722149126232
step: 270, loss: 0.0002503240539226681
step: 280, loss: 0.00020427859271876514
step: 290, loss: 0.003645094111561775
step: 300, loss: 0.00023150339256972075
step: 310, loss: 8.656478166813031e-05
step: 320, loss: 0.00011615084804361686
step: 330, loss: 0.0018357117660343647
epoch 11: dev_f1=0.7696476964769647, f1=0.7513227513227513, best_f1=0.7930283224400873
step: 0, loss: 6.010127253830433e-05
step: 10, loss: 0.0004972494789399207
step: 20, loss: 0.0010129010770469904
step: 30, loss: 0.0018642363138496876
step: 40, loss: 0.007944390177726746
step: 50, loss: 0.0006379145197570324
step: 60, loss: 4.071277362527326e-05
step: 70, loss: 7.54673674236983e-05
step: 80, loss: 0.00013770311488769948
step: 90, loss: 0.0072496007196605206
step: 100, loss: 0.0007630055188201368
step: 110, loss: 0.0009752946789376438
step: 120, loss: 0.02010590396821499
step: 130, loss: 0.00036917621036991477
step: 140, loss: 0.008250128477811813
step: 150, loss: 0.0010882139904424548
step: 160, loss: 0.0022757938131690025
step: 170, loss: 0.0013645319268107414
step: 180, loss: 0.004687383305281401
step: 190, loss: 0.00056550552835688
step: 200, loss: 0.00015924042963888496
step: 210, loss: 0.0002705247316043824
step: 220, loss: 0.0002118302945746109
step: 230, loss: 0.00010936387843685225
step: 240, loss: 0.00019511001300998032
step: 250, loss: 0.000755523971747607
step: 260, loss: 0.001746262889355421
step: 270, loss: 0.0006788421305827796
step: 280, loss: 0.004326849710196257
step: 290, loss: 0.009168048389256
step: 300, loss: 4.6516968723153695e-05
step: 310, loss: 0.0005597607232630253
step: 320, loss: 0.0001368262164760381
step: 330, loss: 0.0015919730067253113
epoch 12: dev_f1=0.7941176470588236, f1=0.7628361858190709, best_f1=0.7930283224400873
step: 0, loss: 5.873771806363948e-05
step: 10, loss: 0.0018884304445236921
step: 20, loss: 0.001460460596717894
step: 30, loss: 0.003646092489361763
step: 40, loss: 0.002839606022462249
step: 50, loss: 7.262988947331905e-05
step: 60, loss: 0.011317703872919083
step: 70, loss: 0.007554568815976381
step: 80, loss: 0.04013704136013985
step: 90, loss: 0.0003729535674210638
step: 100, loss: 2.7279462301521562e-05
step: 110, loss: 0.00016616604989394546
step: 120, loss: 0.00939233135432005
step: 130, loss: 0.0006601456552743912
step: 140, loss: 1.366798642266076e-05
step: 150, loss: 0.0008213621913455427
step: 160, loss: 3.887084676534869e-05
step: 170, loss: 2.2220867322175764e-05
step: 180, loss: 0.008367285132408142
step: 190, loss: 2.9214863388915546e-05
step: 200, loss: 0.006038788240402937
step: 210, loss: 1.5791338228154927e-05
step: 220, loss: 0.00013481351197697222
step: 230, loss: 0.12286270409822464
step: 240, loss: 0.000563327397685498
step: 250, loss: 0.0005389715079218149
step: 260, loss: 0.0029993143398314714
step: 270, loss: 0.0017105380538851023
step: 280, loss: 0.0008015630301088095
step: 290, loss: 0.0002295115264132619
step: 300, loss: 0.0003578745818231255
step: 310, loss: 0.00262543186545372
step: 320, loss: 0.00017612369265407324
step: 330, loss: 0.09510718286037445
epoch 13: dev_f1=0.8093994778067886, f1=0.7700258397932818, best_f1=0.7930283224400873
step: 0, loss: 0.00035374259459786117
step: 10, loss: 0.000341783365001902
step: 20, loss: 0.001102458219975233
step: 30, loss: 0.0050246440805494785
step: 40, loss: 0.0037957397289574146
step: 50, loss: 0.04055599495768547
step: 60, loss: 1.5862144209677354e-05
step: 70, loss: 0.0003496563294902444
step: 80, loss: 0.00018602400086820126
step: 90, loss: 0.00023844014503993094
step: 100, loss: 0.0008949534385465086
step: 110, loss: 5.874936323380098e-05
step: 120, loss: 0.024579903110861778
step: 130, loss: 4.85183518321719e-05
step: 140, loss: 8.118359255604446e-05
step: 150, loss: 0.06321597844362259
step: 160, loss: 0.000423818186391145
step: 170, loss: 0.0012642936781048775
step: 180, loss: 2.4727552954573184e-05
step: 190, loss: 5.7760353229241446e-05
step: 200, loss: 0.00025909056421369314
step: 210, loss: 0.03039756789803505
step: 220, loss: 0.0016145686386153102
step: 230, loss: 5.2268962463131174e-05
step: 240, loss: 0.0004352197574917227
step: 250, loss: 0.0003018395509570837
step: 260, loss: 0.00014750407717656344
step: 270, loss: 0.0175176952034235
step: 280, loss: 3.704856862896122e-05
step: 290, loss: 0.0017517632804811
step: 300, loss: 0.000584154506213963
step: 310, loss: 9.01645325939171e-05
step: 320, loss: 2.4660912458784878e-05
step: 330, loss: 9.635989408707246e-05
epoch 14: dev_f1=0.7961630695443646, f1=0.8056206088992974, best_f1=0.7930283224400873
step: 0, loss: 0.013180170208215714
step: 10, loss: 0.00012228969717398286
step: 20, loss: 0.0007597383228130639
step: 30, loss: 0.000523009744938463
step: 40, loss: 0.01831095479428768
step: 50, loss: 0.01983453705906868
step: 60, loss: 3.907754580723122e-05
step: 70, loss: 0.030802642926573753
step: 80, loss: 3.622191070462577e-05
step: 90, loss: 6.131207192083821e-05
step: 100, loss: 0.0001483876258134842
step: 110, loss: 0.00010119409125763923
step: 120, loss: 0.00020478501392062753
step: 130, loss: 0.0002467156737111509
step: 140, loss: 3.968728560721502e-05
step: 150, loss: 0.00017061874677892774
step: 160, loss: 0.004007735289633274
step: 170, loss: 1.7933256458491087e-05
step: 180, loss: 0.009242711588740349
step: 190, loss: 0.007695009466260672
step: 200, loss: 4.479914787225425e-05
step: 210, loss: 4.57861133327242e-05
step: 220, loss: 0.0003430044453125447
step: 230, loss: 9.372158092446625e-05
step: 240, loss: 6.135125295259058e-05
step: 250, loss: 0.00012960851017851382
step: 260, loss: 0.0011387319536879659
step: 270, loss: 3.754827775992453e-05
step: 280, loss: 2.181860872951802e-05
step: 290, loss: 0.0009306177380494773
step: 300, loss: 3.764516077353619e-05
step: 310, loss: 0.0007249134359881282
step: 320, loss: 4.236412132740952e-05
step: 330, loss: 0.0086329635232687
epoch 15: dev_f1=0.7405247813411079, f1=0.7241379310344828, best_f1=0.7930283224400873
step: 0, loss: 0.000833364378195256
step: 10, loss: 0.006381193641573191
step: 20, loss: 5.262711420073174e-05
step: 30, loss: 7.973801257321611e-05
step: 40, loss: 6.289733573794365e-05
step: 50, loss: 0.00030708644771948457
step: 60, loss: 6.673502502962947e-05
step: 70, loss: 0.005837511736899614
step: 80, loss: 4.136138522881083e-05
step: 90, loss: 1.8327758880332112e-05
step: 100, loss: 0.0716409981250763
step: 110, loss: 0.002524466486647725
step: 120, loss: 1.992988291021902e-05
step: 130, loss: 0.0003790619084611535
step: 140, loss: 0.00023910606978461146
step: 150, loss: 6.105938518885523e-05
step: 160, loss: 9.419549314770848e-05
step: 170, loss: 0.008993121795356274
step: 180, loss: 0.00013564698747359216
step: 190, loss: 2.2306079699774273e-05
step: 200, loss: 6.130123074399307e-05
step: 210, loss: 0.00016022445925045758
step: 220, loss: 0.006387303117662668
step: 230, loss: 0.0012410167837515473
step: 240, loss: 9.485234477324411e-05
step: 250, loss: 3.053674299735576e-05
step: 260, loss: 4.8793521273182705e-05
step: 270, loss: 0.005502775311470032
step: 280, loss: 2.0600258721970022e-05
step: 290, loss: 7.719118730165064e-05
step: 300, loss: 0.00697900727391243
step: 310, loss: 4.1645183955552056e-05
step: 320, loss: 0.00013985714758746326
step: 330, loss: 0.01693853549659252
epoch 16: dev_f1=0.8186046511627907, f1=0.8046511627906976, best_f1=0.8046511627906976
step: 0, loss: 0.00012869354395661503
step: 10, loss: 0.00017246960487682372
step: 20, loss: 0.0001135096899815835
step: 30, loss: 0.0002759248309303075
step: 40, loss: 0.00021010196360293776
step: 50, loss: 8.096901729004458e-05
step: 60, loss: 0.006619023624807596
step: 70, loss: 0.033642593771219254
step: 80, loss: 0.00019324049935676157
step: 90, loss: 2.366563603573013e-05
step: 100, loss: 0.002672037109732628
step: 110, loss: 0.006428659427911043
step: 120, loss: 0.0009580282494425774
step: 130, loss: 0.002092407550662756
step: 140, loss: 2.0969013348803855e-05
step: 150, loss: 0.0002916532976087183
step: 160, loss: 4.723395250039175e-05
step: 170, loss: 4.5398664951790124e-05
step: 180, loss: 0.05376239866018295
step: 190, loss: 1.839879223552998e-05
step: 200, loss: 0.0001741679443512112
step: 210, loss: 0.00019318846170790493
step: 220, loss: 0.0018268126295879483
step: 230, loss: 7.812451804056764e-05
step: 240, loss: 0.0037222462706267834
step: 250, loss: 3.2720272429287434e-05
step: 260, loss: 0.00016386681818403304
step: 270, loss: 2.9235412512207404e-05
step: 280, loss: 4.088010609848425e-05
step: 290, loss: 1.2740307283820584e-05
step: 300, loss: 5.991538637317717e-05
step: 310, loss: 0.003710862249135971
step: 320, loss: 0.0006998975295573473
step: 330, loss: 0.0031359889544546604
epoch 17: dev_f1=0.7743589743589744, f1=0.7849999999999999, best_f1=0.8046511627906976
step: 0, loss: 0.00010993282194249332
step: 10, loss: 1.2289549886190798e-05
step: 20, loss: 1.1220482520002406e-05
step: 30, loss: 0.0016939968336373568
step: 40, loss: 4.1109862650046125e-05
step: 50, loss: 0.000641167105641216
step: 60, loss: 4.960005753673613e-05
step: 70, loss: 0.0007123328396119177
step: 80, loss: 3.478152211755514e-05
step: 90, loss: 0.0001263033045688644
step: 100, loss: 0.00014990163617767394
step: 110, loss: 0.0004111253656446934
step: 120, loss: 0.00014088698662817478
step: 130, loss: 0.0006571245612576604
step: 140, loss: 0.0009507928625680506
step: 150, loss: 4.165813879808411e-05
step: 160, loss: 0.0017306535737589002
step: 170, loss: 0.00045008608140051365
step: 180, loss: 5.6776370911393315e-05
step: 190, loss: 4.2844261770369485e-05
step: 200, loss: 0.00027401032275520265
step: 210, loss: 0.00040108233224600554
step: 220, loss: 0.005672411993145943
step: 230, loss: 0.0009377829846926033
step: 240, loss: 0.00020761940686497837
step: 250, loss: 4.565311974147335e-05
step: 260, loss: 0.00037190329749137163
step: 270, loss: 0.003481670981273055
step: 280, loss: 0.0010540193179622293
step: 290, loss: 0.004438755568116903
step: 300, loss: 0.0005978172412142158
step: 310, loss: 6.544658390339464e-05
step: 320, loss: 0.00016626941214781255
step: 330, loss: 0.00058836949756369
epoch 18: dev_f1=0.8009708737864077, f1=0.7796610169491525, best_f1=0.8046511627906976
step: 0, loss: 6.644910899922252e-05
step: 10, loss: 0.0011191822122782469
step: 20, loss: 0.000913619005586952
step: 30, loss: 2.4696833861526102e-05
step: 40, loss: 0.0006433505332097411
step: 50, loss: 0.0005631731473840773
step: 60, loss: 0.00033650887780822814
step: 70, loss: 1.5403722500195727e-05
step: 80, loss: 1.7623577150516212e-05
step: 90, loss: 8.601431909482926e-05
step: 100, loss: 8.505101141054183e-05
step: 110, loss: 0.0002372564049437642
step: 120, loss: 0.0077729192562401295
step: 130, loss: 0.0020475254859775305
step: 140, loss: 1.526589403511025e-05
step: 150, loss: 2.629499249451328e-05
step: 160, loss: 5.941265408182517e-05
step: 170, loss: 0.00024794184719212353
step: 180, loss: 0.001775428419932723
step: 190, loss: 3.0090604923316278e-05
step: 200, loss: 1.7656886484473944e-05
step: 210, loss: 2.4421338821412064e-05
step: 220, loss: 0.007274233270436525
step: 230, loss: 0.0002608067588880658
step: 240, loss: 6.205162208061665e-05
step: 250, loss: 2.764145210676361e-05
step: 260, loss: 0.0011600230354815722
step: 270, loss: 6.33784438832663e-05
step: 280, loss: 0.00030686211539432406
step: 290, loss: 0.0016730759525671601
step: 300, loss: 4.734199319500476e-05
step: 310, loss: 4.082027589902282e-05
step: 320, loss: 0.0003176370810251683
step: 330, loss: 6.918115104781464e-05
epoch 19: dev_f1=0.7777777777777778, f1=0.775, best_f1=0.8046511627906976
step: 0, loss: 4.61990712210536e-05
step: 10, loss: 0.00043877767166122794
step: 20, loss: 0.0001375381980324164
step: 30, loss: 0.0034996892791241407
step: 40, loss: 7.924200326669961e-05
step: 50, loss: 2.165036858059466e-05
step: 60, loss: 0.0002718835021369159
step: 70, loss: 8.095995872281492e-05
step: 80, loss: 1.5246921975631267e-05
step: 90, loss: 3.962706614402123e-05
step: 100, loss: 0.00012912735110148787
step: 110, loss: 0.0008537483518011868
step: 120, loss: 1.4297344023361802e-05
step: 130, loss: 0.00040208426071330905
step: 140, loss: 4.190280378679745e-05
step: 150, loss: 4.731930675916374e-05
step: 160, loss: 0.00014629826182499528
step: 170, loss: 0.0002892665797844529
step: 180, loss: 0.00015252947923727334
step: 190, loss: 0.0001706307230051607
step: 200, loss: 0.0006430059438571334
step: 210, loss: 3.404189192224294e-05
step: 220, loss: 1.4356964129547123e-05
step: 230, loss: 2.4774652047199197e-05
step: 240, loss: 0.0007291706860996783
step: 250, loss: 0.0002208192163379863
step: 260, loss: 0.00023388727277051657
step: 270, loss: 0.0002583608729764819
step: 280, loss: 2.1288466086843982e-05
step: 290, loss: 4.2502517317188904e-05
step: 300, loss: 0.003384944284334779
step: 310, loss: 5.964739466435276e-05
step: 320, loss: 3.94243688788265e-05
step: 330, loss: 1.7225047486135736e-05
epoch 20: dev_f1=0.7835051546391752, f1=0.7755102040816327, best_f1=0.8046511627906976
