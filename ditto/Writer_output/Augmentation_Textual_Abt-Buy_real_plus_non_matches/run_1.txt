cuda
Device: cuda
step: 0, loss: 0.5866715908050537
step: 10, loss: 0.272452175617218
step: 20, loss: 0.15045003592967987
step: 30, loss: 0.22874461114406586
step: 40, loss: 0.15744554996490479
step: 50, loss: 0.14976097643375397
step: 60, loss: 0.06457503139972687
step: 70, loss: 0.1337583214044571
step: 80, loss: 0.16319821774959564
step: 90, loss: 0.2409876137971878
step: 100, loss: 0.14278951287269592
step: 110, loss: 0.14769089221954346
step: 120, loss: 0.23902864754199982
step: 130, loss: 0.14059041440486908
step: 140, loss: 0.3293347656726837
step: 150, loss: 0.1563549041748047
step: 160, loss: 0.16128382086753845
step: 170, loss: 0.03773268312215805
step: 180, loss: 0.19158360362052917
step: 190, loss: 0.13576354086399078
step: 200, loss: 0.06629764288663864
step: 210, loss: 0.5700463056564331
step: 220, loss: 0.12756450474262238
step: 230, loss: 0.25147053599357605
step: 240, loss: 0.4266258776187897
step: 250, loss: 0.1933438628911972
step: 260, loss: 0.2892757058143616
step: 270, loss: 0.12887480854988098
step: 280, loss: 0.10801634937524796
step: 290, loss: 0.13708274066448212
step: 300, loss: 0.12443853914737701
step: 310, loss: 0.07279859483242035
step: 320, loss: 0.12068277597427368
step: 330, loss: 0.07750993967056274
epoch 1: dev_f1=0.635, f1=0.6426858513189448, best_f1=0.6426858513189448
step: 0, loss: 0.0993816927075386
step: 10, loss: 0.06755883246660233
step: 20, loss: 0.08019184321165085
step: 30, loss: 0.08655641227960587
step: 40, loss: 0.10039491951465607
step: 50, loss: 0.05939927697181702
step: 60, loss: 0.22780834138393402
step: 70, loss: 0.2594546973705292
step: 80, loss: 0.17469553649425507
step: 90, loss: 0.02733498439192772
step: 100, loss: 0.10119523853063583
step: 110, loss: 0.02388206124305725
step: 120, loss: 0.026161640882492065
step: 130, loss: 0.13403865694999695
step: 140, loss: 0.04306676611304283
step: 150, loss: 0.32159972190856934
step: 160, loss: 0.24318525195121765
step: 170, loss: 0.07123380899429321
step: 180, loss: 0.3239896595478058
step: 190, loss: 0.15258459746837616
step: 200, loss: 0.27616825699806213
step: 210, loss: 0.25053325295448303
step: 220, loss: 0.15918859839439392
step: 230, loss: 0.18716132640838623
step: 240, loss: 0.2073405385017395
step: 250, loss: 0.10256502777338028
step: 260, loss: 0.1740744709968567
step: 270, loss: 0.07466451823711395
step: 280, loss: 0.14146408438682556
step: 290, loss: 0.12136394530534744
step: 300, loss: 0.040320854634046555
step: 310, loss: 0.2873956561088562
step: 320, loss: 0.1052727997303009
step: 330, loss: 0.136845663189888
epoch 2: dev_f1=0.7232142857142858, f1=0.7004405286343612, best_f1=0.7004405286343612
step: 0, loss: 0.1668287068605423
step: 10, loss: 0.05528169125318527
step: 20, loss: 0.11430522799491882
step: 30, loss: 0.18811841309070587
step: 40, loss: 0.011930990032851696
step: 50, loss: 0.047845885157585144
step: 60, loss: 0.19920144975185394
step: 70, loss: 0.13616332411766052
step: 80, loss: 0.13692019879817963
step: 90, loss: 0.06526269018650055
step: 100, loss: 0.1519085317850113
step: 110, loss: 0.08481080830097198
step: 120, loss: 0.02698344737291336
step: 130, loss: 0.08001914620399475
step: 140, loss: 0.11814089119434357
step: 150, loss: 0.06368964910507202
step: 160, loss: 0.045154791325330734
step: 170, loss: 0.08470074087381363
step: 180, loss: 0.06733915954828262
step: 190, loss: 0.058274801820516586
step: 200, loss: 0.17280587553977966
step: 210, loss: 0.17050659656524658
step: 220, loss: 0.0450010821223259
step: 230, loss: 0.18541404604911804
step: 240, loss: 0.1434222012758255
step: 250, loss: 0.15880361199378967
step: 260, loss: 0.11574678868055344
step: 270, loss: 0.04456320032477379
step: 280, loss: 0.11628434807062149
step: 290, loss: 0.03452219069004059
step: 300, loss: 0.050659459084272385
step: 310, loss: 0.16063423454761505
step: 320, loss: 0.35861849784851074
step: 330, loss: 0.14892035722732544
epoch 3: dev_f1=0.7562642369020501, f1=0.755364806866953, best_f1=0.755364806866953
step: 0, loss: 0.05788016691803932
step: 10, loss: 0.11813531816005707
step: 20, loss: 0.15851527452468872
step: 30, loss: 0.10125988721847534
step: 40, loss: 0.21291302144527435
step: 50, loss: 0.02387022040784359
step: 60, loss: 0.04443782940506935
step: 70, loss: 0.05370238423347473
step: 80, loss: 0.06244485080242157
step: 90, loss: 0.07562978565692902
step: 100, loss: 0.161116361618042
step: 110, loss: 0.23079097270965576
step: 120, loss: 0.09422243386507034
step: 130, loss: 0.19402644038200378
step: 140, loss: 0.17436647415161133
step: 150, loss: 0.17758125066757202
step: 160, loss: 0.1686280518770218
step: 170, loss: 0.018428480252623558
step: 180, loss: 0.06361828744411469
step: 190, loss: 0.05778348073363304
step: 200, loss: 0.0527387298643589
step: 210, loss: 0.017497001215815544
step: 220, loss: 0.06178068369626999
step: 230, loss: 0.15622156858444214
step: 240, loss: 0.08629672974348068
step: 250, loss: 0.1582058221101761
step: 260, loss: 0.05866020917892456
step: 270, loss: 0.043867360800504684
step: 280, loss: 0.10635898262262344
step: 290, loss: 0.1313239187002182
step: 300, loss: 0.176355242729187
step: 310, loss: 0.0774424821138382
step: 320, loss: 0.12258730828762054
step: 330, loss: 0.09664738178253174
epoch 4: dev_f1=0.8183908045977012, f1=0.7956521739130435, best_f1=0.7956521739130435
step: 0, loss: 0.13606120645999908
step: 10, loss: 0.1182902604341507
step: 20, loss: 0.06334856152534485
step: 30, loss: 0.07057181000709534
step: 40, loss: 0.11173731088638306
step: 50, loss: 0.0329035148024559
step: 60, loss: 0.17619891464710236
step: 70, loss: 0.0897822305560112
step: 80, loss: 0.09738872945308685
step: 90, loss: 0.15824733674526215
step: 100, loss: 0.10605461150407791
step: 110, loss: 0.14266499876976013
step: 120, loss: 0.1255151927471161
step: 130, loss: 0.13305526971817017
step: 140, loss: 0.053838931024074554
step: 150, loss: 0.14954295754432678
step: 160, loss: 0.06742799282073975
step: 170, loss: 0.004954728297889233
step: 180, loss: 0.08402273803949356
step: 190, loss: 0.23240013420581818
step: 200, loss: 0.1151755079627037
step: 210, loss: 0.08836763352155685
step: 220, loss: 0.024247094988822937
step: 230, loss: 0.02818576991558075
step: 240, loss: 0.08267714083194733
step: 250, loss: 0.11616723984479904
step: 260, loss: 0.09087461233139038
step: 270, loss: 0.11973389983177185
step: 280, loss: 0.17584694921970367
step: 290, loss: 0.1843465268611908
step: 300, loss: 0.1466805338859558
step: 310, loss: 0.11238797754049301
step: 320, loss: 0.08851586282253265
step: 330, loss: 0.00014561800344381481
epoch 5: dev_f1=0.812206572769953, f1=0.7882882882882883, best_f1=0.7956521739130435
step: 0, loss: 0.0842236578464508
step: 10, loss: 0.09349433332681656
step: 20, loss: 0.020768925547599792
step: 30, loss: 0.04302779585123062
step: 40, loss: 0.16166804730892181
step: 50, loss: 0.11510612815618515
step: 60, loss: 0.08154148608446121
step: 70, loss: 0.11852125823497772
step: 80, loss: 0.15748363733291626
step: 90, loss: 0.12305594980716705
step: 100, loss: 0.11312174052000046
step: 110, loss: 0.08262871950864792
step: 120, loss: 0.07780535519123077
step: 130, loss: 0.15152327716350555
step: 140, loss: 0.06321389973163605
step: 150, loss: 0.07140302658081055
step: 160, loss: 0.07957948744297028
step: 170, loss: 0.09734486043453217
step: 180, loss: 0.09541274607181549
step: 190, loss: 0.08486763387918472
step: 200, loss: 0.12549462914466858
step: 210, loss: 0.15703481435775757
step: 220, loss: 0.06773006916046143
step: 230, loss: 0.10089610517024994
step: 240, loss: 0.12658077478408813
step: 250, loss: 0.0975649505853653
step: 260, loss: 0.08437114953994751
step: 270, loss: 0.05177310109138489
step: 280, loss: 0.12596631050109863
step: 290, loss: 0.03875689208507538
step: 300, loss: 0.14012089371681213
step: 310, loss: 0.05871565639972687
step: 320, loss: 0.07293635606765747
step: 330, loss: 0.10971729457378387
epoch 6: dev_f1=0.8054919908466818, f1=0.7873303167420815, best_f1=0.7956521739130435
step: 0, loss: 0.0729566290974617
step: 10, loss: 0.1262485831975937
step: 20, loss: 0.08977903425693512
step: 30, loss: 0.07074074447154999
step: 40, loss: 0.13060657680034637
step: 50, loss: 0.19535619020462036
step: 60, loss: 0.06894158571958542
step: 70, loss: 0.09439438581466675
step: 80, loss: 0.04887773096561432
step: 90, loss: 0.022424396127462387
step: 100, loss: 0.055853672325611115
step: 110, loss: 0.0708923265337944
step: 120, loss: 0.04758940264582634
step: 130, loss: 0.08567942678928375
step: 140, loss: 0.07649584114551544
step: 150, loss: 0.16172029078006744
step: 160, loss: 0.1683041900396347
step: 170, loss: 0.0607057586312294
step: 180, loss: 0.12785670161247253
step: 190, loss: 0.05323225259780884
step: 200, loss: 0.15111002326011658
step: 210, loss: 0.0940793827176094
step: 220, loss: 0.02649823948740959
step: 230, loss: 0.08683840930461884
step: 240, loss: 0.09019206464290619
step: 250, loss: 0.08964193612337112
step: 260, loss: 0.12264515459537506
step: 270, loss: 0.1153855249285698
step: 280, loss: 0.037151359021663666
step: 290, loss: 0.12253795564174652
step: 300, loss: 0.0997123122215271
step: 310, loss: 0.1019124686717987
step: 320, loss: 0.08065754920244217
step: 330, loss: 0.041104625910520554
epoch 7: dev_f1=0.8177339901477833, f1=0.8058252427184465, best_f1=0.7956521739130435
step: 0, loss: 0.12367647886276245
step: 10, loss: 0.06117770075798035
step: 20, loss: 0.0663820281624794
step: 30, loss: 0.06863590329885483
step: 40, loss: 0.0630556270480156
step: 50, loss: 0.1625322699546814
step: 60, loss: 0.09675491601228714
step: 70, loss: 0.11749708652496338
step: 80, loss: 0.09094109386205673
step: 90, loss: 0.10194619745016098
step: 100, loss: 0.08731181174516678
step: 110, loss: 0.1316482424736023
step: 120, loss: 0.06373253464698792
step: 130, loss: 0.11128538846969604
step: 140, loss: 0.376267671585083
step: 150, loss: 0.12520191073417664
step: 160, loss: 0.020983407273888588
step: 170, loss: 0.07726660370826721
step: 180, loss: 0.10996886342763901
step: 190, loss: 0.15938767790794373
step: 200, loss: 0.12665621936321259
step: 210, loss: 0.033943817019462585
step: 220, loss: 0.0980347990989685
step: 230, loss: 0.024283047765493393
step: 240, loss: 0.0016053314320743084
step: 250, loss: 0.05632736533880234
step: 260, loss: 0.12041356414556503
step: 270, loss: 0.15254215896129608
step: 280, loss: 0.10945087671279907
step: 290, loss: 0.06034810468554497
step: 300, loss: 0.10471537709236145
step: 310, loss: 0.04201611876487732
step: 320, loss: 0.07378332316875458
step: 330, loss: 0.09034572541713715
epoch 8: dev_f1=0.7942583732057416, f1=0.7616822429906542, best_f1=0.7956521739130435
step: 0, loss: 0.09884034097194672
step: 10, loss: 0.033052340149879456
step: 20, loss: 0.09743864089250565
step: 30, loss: 0.0708904042840004
step: 40, loss: 0.09871440380811691
step: 50, loss: 0.07024294137954712
step: 60, loss: 0.09678959846496582
step: 70, loss: 0.07150901854038239
step: 80, loss: 0.08258265256881714
step: 90, loss: 8.683592750458047e-05
step: 100, loss: 0.1658097207546234
step: 110, loss: 0.048306696116924286
step: 120, loss: 0.11135154217481613
step: 130, loss: 0.08998506516218185
step: 140, loss: 0.1472959667444229
step: 150, loss: 0.06967844814062119
step: 160, loss: 0.07389692962169647
step: 170, loss: 0.05326347053050995
step: 180, loss: 0.03990204259753227
step: 190, loss: 0.13556572794914246
step: 200, loss: 0.04882919788360596
step: 210, loss: 0.10271923243999481
step: 220, loss: 0.11391043663024902
step: 230, loss: 0.04647868871688843
step: 240, loss: 0.1218809112906456
step: 250, loss: 0.05845426023006439
step: 260, loss: 0.03681757673621178
step: 270, loss: 0.051390402019023895
step: 280, loss: 0.14625172317028046
step: 290, loss: 0.04540129750967026
step: 300, loss: 0.048260774463415146
step: 310, loss: 0.06393374502658844
step: 320, loss: 0.09329093992710114
step: 330, loss: 0.14239154756069183
epoch 9: dev_f1=0.8151898734177214, f1=0.7849999999999999, best_f1=0.7956521739130435
step: 0, loss: 0.07279404997825623
step: 10, loss: 0.12159261852502823
step: 20, loss: 0.1514902263879776
step: 30, loss: 0.04700397700071335
step: 40, loss: 0.13241297006607056
step: 50, loss: 0.11294980347156525
step: 60, loss: 0.060316070914268494
step: 70, loss: 0.07534980773925781
step: 80, loss: 0.1363985687494278
step: 90, loss: 0.05877361074090004
step: 100, loss: 0.08385035395622253
step: 110, loss: 0.1346226930618286
step: 120, loss: 0.03446546941995621
step: 130, loss: 0.06666283309459686
step: 140, loss: 0.11632022261619568
step: 150, loss: 0.10374967753887177
step: 160, loss: 0.12247316539287567
step: 170, loss: 0.02939029037952423
step: 180, loss: 0.03470653295516968
step: 190, loss: 0.16868022084236145
step: 200, loss: 0.07989025115966797
step: 210, loss: 0.13561409711837769
step: 220, loss: 0.19066627323627472
step: 230, loss: 0.06434562802314758
step: 240, loss: 0.10292327404022217
step: 250, loss: 0.15170419216156006
step: 260, loss: 0.1209268718957901
step: 270, loss: 0.15587258338928223
step: 280, loss: 0.02918093092739582
step: 290, loss: 0.0837993174791336
step: 300, loss: 0.06795677542686462
step: 310, loss: 0.0802440419793129
step: 320, loss: 0.11484702676534653
step: 330, loss: 0.037345804274082184
epoch 10: dev_f1=0.7900677200902935, f1=0.7740492170022372, best_f1=0.7956521739130435
step: 0, loss: 0.10496516525745392
step: 10, loss: 0.021471885964274406
step: 20, loss: 0.1434520184993744
step: 30, loss: 0.23490484058856964
step: 40, loss: 0.0509018748998642
step: 50, loss: 0.0632379949092865
step: 60, loss: 0.1047300174832344
step: 70, loss: 0.0683978721499443
step: 80, loss: 0.10830096900463104
step: 90, loss: 0.11748266220092773
step: 100, loss: 0.11281345039606094
step: 110, loss: 0.08508069813251495
step: 120, loss: 0.07162544876337051
step: 130, loss: 0.17778244614601135
step: 140, loss: 0.03848125785589218
step: 150, loss: 0.07893485575914383
step: 160, loss: 0.07696417719125748
step: 170, loss: 0.13579042255878448
step: 180, loss: 0.02751190960407257
step: 190, loss: 0.060037761926651
step: 200, loss: 0.06437699496746063
step: 210, loss: 0.12174463272094727
step: 220, loss: 0.1364585906267166
step: 230, loss: 0.08683694899082184
step: 240, loss: 0.0862627699971199
step: 250, loss: 0.07718939334154129
step: 260, loss: 0.10570909082889557
step: 270, loss: 0.0508340559899807
step: 280, loss: 0.10416442155838013
step: 290, loss: 0.020754853263497353
step: 300, loss: 0.1065208837389946
step: 310, loss: 0.10430368781089783
step: 320, loss: 0.061454277485609055
step: 330, loss: 0.09868145734071732
epoch 11: dev_f1=0.8438228438228438, f1=0.8146453089244851, best_f1=0.8146453089244851
step: 0, loss: 0.1538982093334198
step: 10, loss: 0.15282024443149567
step: 20, loss: 0.11689223349094391
step: 30, loss: 0.10733015090227127
step: 40, loss: 0.06346399337053299
step: 50, loss: 0.11073514074087143
step: 60, loss: 0.09921034425497055
step: 70, loss: 0.08296453952789307
step: 80, loss: 0.07901996374130249
step: 90, loss: 0.06627481430768967
step: 100, loss: 0.10794981569051743
step: 110, loss: 0.04645323008298874
step: 120, loss: 0.0003241261874791235
step: 130, loss: 0.08229696750640869
step: 140, loss: 0.11690337210893631
step: 150, loss: 0.037664808332920074
step: 160, loss: 0.07334038615226746
step: 170, loss: 0.14195020496845245
step: 180, loss: 0.018692223355174065
step: 190, loss: 0.053331900388002396
step: 200, loss: 0.04256056994199753
step: 210, loss: 0.2785811424255371
step: 220, loss: 0.052081093192100525
step: 230, loss: 0.06011909246444702
step: 240, loss: 0.07493308931589127
step: 250, loss: 0.04525067284703255
step: 260, loss: 0.12929968535900116
step: 270, loss: 0.0837518721818924
step: 280, loss: 0.09820607304573059
step: 290, loss: 0.20782126486301422
step: 300, loss: 0.07867424190044403
step: 310, loss: 0.02455831691622734
step: 320, loss: 0.11102380603551865
step: 330, loss: 0.11358708143234253
epoch 12: dev_f1=0.836104513064133, f1=0.8221709006928406, best_f1=0.8146453089244851
step: 0, loss: 0.02838267758488655
step: 10, loss: 0.015653148293495178
step: 20, loss: 0.09461963921785355
step: 30, loss: 0.08246028423309326
step: 40, loss: 0.11393114179372787
step: 50, loss: 0.05713704600930214
step: 60, loss: 0.05631439387798309
step: 70, loss: 0.057650115340948105
step: 80, loss: 0.03143705427646637
step: 90, loss: 0.07462172955274582
step: 100, loss: 0.0525272935628891
step: 110, loss: 0.0195519607514143
step: 120, loss: 0.12115273624658585
step: 130, loss: 0.0588252879679203
step: 140, loss: 0.030748188495635986
step: 150, loss: 0.04173586145043373
step: 160, loss: 0.025222616270184517
step: 170, loss: 0.050032176077365875
step: 180, loss: 0.059224724769592285
step: 190, loss: 0.0861058309674263
step: 200, loss: 0.09158129245042801
step: 210, loss: 0.06408285349607468
step: 220, loss: 0.07422039657831192
step: 230, loss: 0.07170947641134262
step: 240, loss: 0.06873980909585953
step: 250, loss: 0.06098056212067604
step: 260, loss: 0.05724853277206421
step: 270, loss: 0.1301226019859314
step: 280, loss: 0.11914227157831192
step: 290, loss: 0.07194501161575317
step: 300, loss: 0.09285280108451843
step: 310, loss: 0.027364831417798996
step: 320, loss: 0.1323300004005432
step: 330, loss: 0.08804420381784439
epoch 13: dev_f1=0.838862559241706, f1=0.8156682027649769, best_f1=0.8146453089244851
step: 0, loss: 0.016489818692207336
step: 10, loss: 0.03724675998091698
step: 20, loss: 0.01560480147600174
step: 30, loss: 0.04581340029835701
step: 40, loss: 0.0878349170088768
step: 50, loss: 0.07332032918930054
step: 60, loss: 0.09625162184238434
step: 70, loss: 0.1660403609275818
step: 80, loss: 0.09933557361364365
step: 90, loss: 0.026686962693929672
step: 100, loss: 0.03723014146089554
step: 110, loss: 0.03245020657777786
step: 120, loss: 0.07750502228736877
step: 130, loss: 0.055293429642915726
step: 140, loss: 0.032245129346847534
step: 150, loss: 0.17358432710170746
step: 160, loss: 0.07279423624277115
step: 170, loss: 0.061807453632354736
step: 180, loss: 0.026857690885663033
step: 190, loss: 0.08706776797771454
step: 200, loss: 0.1504923403263092
step: 210, loss: 0.1206706091761589
step: 220, loss: 0.055428534746170044
step: 230, loss: 0.05867520347237587
step: 240, loss: 0.08448825776576996
step: 250, loss: 0.1566811054944992
step: 260, loss: 0.060426101088523865
step: 270, loss: 0.10382106155157089
step: 280, loss: 0.04804166406393051
step: 290, loss: 0.036222077906131744
step: 300, loss: 0.15302258729934692
step: 310, loss: 0.06956346333026886
step: 320, loss: 0.045979030430316925
step: 330, loss: 0.1700516790151596
epoch 14: dev_f1=0.8321513002364066, f1=0.8165137614678899, best_f1=0.8146453089244851
step: 0, loss: 0.06737545132637024
step: 10, loss: 0.04695562645792961
step: 20, loss: 0.06983042508363724
step: 30, loss: 0.09974431246519089
step: 40, loss: 0.11970532685518265
step: 50, loss: 0.15414033830165863
step: 60, loss: 0.08636150509119034
step: 70, loss: 0.23271779716014862
step: 80, loss: 0.040502242743968964
step: 90, loss: 0.061443109065294266
step: 100, loss: 0.05779562145471573
step: 110, loss: 0.041833385825157166
step: 120, loss: 0.03324037045240402
step: 130, loss: 0.10108539462089539
step: 140, loss: 0.06407652050256729
step: 150, loss: 0.018984418362379074
step: 160, loss: 0.06109705939888954
step: 170, loss: 0.08880235254764557
step: 180, loss: 0.09146074205636978
step: 190, loss: 0.0625450611114502
step: 200, loss: 0.10721976310014725
step: 210, loss: 0.03018437884747982
step: 220, loss: 0.132387176156044
step: 230, loss: 0.10011471062898636
step: 240, loss: 0.09509343653917313
step: 250, loss: 0.1046517863869667
step: 260, loss: 0.14301885664463043
step: 270, loss: 0.02508622221648693
step: 280, loss: 0.08599190413951874
step: 290, loss: 0.08269790560007095
step: 300, loss: 0.21212589740753174
step: 310, loss: 0.0164045300334692
step: 320, loss: 0.10439290851354599
step: 330, loss: 0.028462059795856476
epoch 15: dev_f1=0.8305489260143198, f1=0.8026905829596412, best_f1=0.8146453089244851
step: 0, loss: 0.10163939744234085
step: 10, loss: 0.08541395515203476
step: 20, loss: 0.056089334189891815
step: 30, loss: 0.02857627347111702
step: 40, loss: 0.04257563501596451
step: 50, loss: 0.05933835357427597
step: 60, loss: 0.03823288530111313
step: 70, loss: 0.15052397549152374
step: 80, loss: 0.14538520574569702
step: 90, loss: 0.03355521336197853
step: 100, loss: 0.03829945996403694
step: 110, loss: 0.07632258534431458
step: 120, loss: 0.00011930921755265445
step: 130, loss: 0.14895664155483246
step: 140, loss: 0.14762720465660095
step: 150, loss: 0.07620324194431305
step: 160, loss: 0.07001525163650513
step: 170, loss: 0.032717619091272354
step: 180, loss: 0.07895483821630478
step: 190, loss: 0.04440683871507645
step: 200, loss: 0.06284637749195099
step: 210, loss: 0.07873295992612839
step: 220, loss: 0.0654168501496315
step: 230, loss: 0.12958838045597076
step: 240, loss: 0.061944760382175446
step: 250, loss: 0.13465037941932678
step: 260, loss: 0.07135164737701416
step: 270, loss: 0.08682149648666382
step: 280, loss: 0.08307487517595291
step: 290, loss: 0.1251223385334015
step: 300, loss: 0.029617732390761375
step: 310, loss: 0.06570380926132202
step: 320, loss: 0.18480856716632843
step: 330, loss: 0.0399005152285099
epoch 16: dev_f1=0.839622641509434, f1=0.802784222737819, best_f1=0.8146453089244851
step: 0, loss: 0.047986652702093124
step: 10, loss: 0.09514280408620834
step: 20, loss: 0.05988961458206177
step: 30, loss: 0.06875945627689362
step: 40, loss: 0.0431353859603405
step: 50, loss: 0.05054563656449318
step: 60, loss: 0.04430817812681198
step: 70, loss: 0.08408518135547638
step: 80, loss: 0.09858675301074982
step: 90, loss: 0.038757726550102234
step: 100, loss: 0.10703834146261215
step: 110, loss: 0.08755366504192352
step: 120, loss: 0.1710117906332016
step: 130, loss: 0.07800348103046417
step: 140, loss: 0.07721378654241562
step: 150, loss: 0.13901248574256897
step: 160, loss: 0.044662442058324814
step: 170, loss: 0.08856450766324997
step: 180, loss: 0.06154755502939224
step: 190, loss: 0.16230906546115875
step: 200, loss: 0.06177373230457306
step: 210, loss: 0.03806954249739647
step: 220, loss: 0.04132372513413429
step: 230, loss: 0.10793685168027878
step: 240, loss: 0.06521990895271301
step: 250, loss: 0.11517743766307831
step: 260, loss: 0.04344715550541878
step: 270, loss: 0.04468432068824768
step: 280, loss: 0.09116329997777939
step: 290, loss: 0.03996766731142998
step: 300, loss: 0.05042280629277229
step: 310, loss: 0.10882195830345154
step: 320, loss: 3.182129512424581e-05
step: 330, loss: 0.05604841560125351
epoch 17: dev_f1=0.8312958435207823, f1=0.8076923076923078, best_f1=0.8146453089244851
step: 0, loss: 0.08615568280220032
step: 10, loss: 0.04045257344841957
step: 20, loss: 0.068123959004879
step: 30, loss: 0.08875004202127457
step: 40, loss: 0.09950477629899979
step: 50, loss: 0.017591189593076706
step: 60, loss: 0.1029023751616478
step: 70, loss: 0.11540855467319489
step: 80, loss: 0.0037293815985322
step: 90, loss: 0.07158061116933823
step: 100, loss: 0.05417532101273537
step: 110, loss: 0.04424398019909859
step: 120, loss: 0.10632003843784332
step: 130, loss: 0.061824966222047806
step: 140, loss: 0.14265283942222595
step: 150, loss: 0.04173882305622101
step: 160, loss: 0.08759156614542007
step: 170, loss: 0.08012549579143524
step: 180, loss: 0.08076352626085281
step: 190, loss: 0.14689822494983673
step: 200, loss: 0.0799868106842041
step: 210, loss: 0.015412718057632446
step: 220, loss: 0.08764688670635223
step: 230, loss: 0.05871763080358505
step: 240, loss: 0.00934772938489914
step: 250, loss: 0.07800718396902084
step: 260, loss: 0.06211378052830696
step: 270, loss: 0.016442280262708664
step: 280, loss: 0.12514473497867584
step: 290, loss: 0.10530922561883926
step: 300, loss: 0.036866676062345505
step: 310, loss: 0.04319331422448158
step: 320, loss: 0.1288677155971527
step: 330, loss: 0.06866434961557388
epoch 18: dev_f1=0.8177339901477833, f1=0.7971360381861575, best_f1=0.8146453089244851
step: 0, loss: 0.1684367060661316
step: 10, loss: 0.03137030079960823
step: 20, loss: 0.0607760064303875
step: 30, loss: 0.13544471561908722
step: 40, loss: 0.033436864614486694
step: 50, loss: 0.04723804071545601
step: 60, loss: 0.07211358100175858
step: 70, loss: 0.01902218908071518
step: 80, loss: 0.044234782457351685
step: 90, loss: 0.09734563529491425
step: 100, loss: 0.0640513226389885
step: 110, loss: 0.07198863476514816
step: 120, loss: 0.061391063034534454
step: 130, loss: 0.03864845633506775
step: 140, loss: 0.16164037585258484
step: 150, loss: 0.035214051604270935
step: 160, loss: 0.028104450553655624
step: 170, loss: 0.06897439807653427
step: 180, loss: 0.03232307359576225
step: 190, loss: 0.07166938483715057
step: 200, loss: 0.09763465821743011
step: 210, loss: 0.031880952417850494
step: 220, loss: 0.10460051894187927
step: 230, loss: 0.03502202033996582
step: 240, loss: 0.08792345970869064
step: 250, loss: 0.08876264095306396
step: 260, loss: 0.08926892280578613
step: 270, loss: 0.07384485006332397
step: 280, loss: 0.005186996888369322
step: 290, loss: 0.11988555639982224
step: 300, loss: 0.09042389690876007
step: 310, loss: 0.05834123119711876
step: 320, loss: 0.08788716793060303
step: 330, loss: 0.1126914694905281
epoch 19: dev_f1=0.8238213399503721, f1=0.7990430622009569, best_f1=0.8146453089244851
step: 0, loss: 0.06545507162809372
step: 10, loss: 0.03405448794364929
step: 20, loss: 0.05135846510529518
step: 30, loss: 0.0841803103685379
step: 40, loss: 0.11006899923086166
step: 50, loss: 0.05201958119869232
step: 60, loss: 0.034135084599256516
step: 70, loss: 0.03784880414605141
step: 80, loss: 0.2072627991437912
step: 90, loss: 0.10637769103050232
step: 100, loss: 0.13201072812080383
step: 110, loss: 0.055594850331544876
step: 120, loss: 0.07081484794616699
step: 130, loss: 0.048675116151571274
step: 140, loss: 0.07101833820343018
step: 150, loss: 0.04121485352516174
step: 160, loss: 0.07213112711906433
step: 170, loss: 0.07935568690299988
step: 180, loss: 0.07487107813358307
step: 190, loss: 0.09819270670413971
step: 200, loss: 0.09469428658485413
step: 210, loss: 0.06818945705890656
step: 220, loss: 0.11210212111473083
step: 230, loss: 0.10224102437496185
step: 240, loss: 0.09739848226308823
step: 250, loss: 0.10790693014860153
step: 260, loss: 0.044756609946489334
step: 270, loss: 0.09243980050086975
step: 280, loss: 0.08229478448629379
step: 290, loss: 0.04634622484445572
step: 300, loss: 0.19491717219352722
step: 310, loss: 0.06623880565166473
step: 320, loss: 0.002463003620505333
step: 330, loss: 0.019706668332219124
epoch 20: dev_f1=0.8, f1=0.7862407862407862, best_f1=0.8146453089244851
