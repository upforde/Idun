cuda
Device: cuda
step: 0, loss: 0.6506571173667908
step: 10, loss: 0.3216972351074219
step: 20, loss: 0.1543768048286438
step: 30, loss: 0.3598943054676056
step: 40, loss: 0.3118802011013031
step: 50, loss: 0.14215703308582306
step: 60, loss: 0.07232851535081863
step: 70, loss: 0.1506737321615219
step: 80, loss: 0.10806770622730255
step: 90, loss: 0.35946857929229736
step: 100, loss: 0.35697248578071594
step: 110, loss: 0.07916760444641113
step: 120, loss: 0.28666651248931885
step: 130, loss: 0.2173241525888443
step: 140, loss: 0.12905195355415344
step: 150, loss: 0.13664421439170837
step: 160, loss: 0.20772403478622437
step: 170, loss: 0.17472173273563385
step: 180, loss: 0.18152983486652374
step: 190, loss: 0.21264493465423584
step: 200, loss: 0.19398267567157745
step: 210, loss: 0.15210601687431335
step: 220, loss: 0.11055678874254227
step: 230, loss: 0.29543283581733704
step: 240, loss: 0.3761541247367859
step: 250, loss: 0.10496874153614044
step: 260, loss: 0.37866485118865967
step: 270, loss: 0.1326562464237213
step: 280, loss: 0.24966645240783691
step: 290, loss: 0.2236866056919098
step: 300, loss: 0.13214011490345
step: 310, loss: 0.10889387130737305
step: 320, loss: 0.2237538993358612
step: 330, loss: 0.23085683584213257
epoch 1: dev_f1=0.6789838337182448, f1=0.7203579418344518, best_f1=0.7203579418344518
step: 0, loss: 0.15080000460147858
step: 10, loss: 0.1308002769947052
step: 20, loss: 0.1324872374534607
step: 30, loss: 0.07563754171133041
step: 40, loss: 0.0751199871301651
step: 50, loss: 0.3415042757987976
step: 60, loss: 0.166342094540596
step: 70, loss: 0.12485441565513611
step: 80, loss: 0.09142979234457016
step: 90, loss: 0.13991235196590424
step: 100, loss: 0.2255474030971527
step: 110, loss: 0.06911934912204742
step: 120, loss: 0.1806129813194275
step: 130, loss: 0.025715677067637444
step: 140, loss: 0.11734138429164886
step: 150, loss: 0.043248500674963
step: 160, loss: 0.17447252571582794
step: 170, loss: 0.1684322953224182
step: 180, loss: 0.08010461181402206
step: 190, loss: 0.12259181588888168
step: 200, loss: 0.2553084194660187
step: 210, loss: 0.06041932851076126
step: 220, loss: 0.09324725717306137
step: 230, loss: 0.2892276644706726
step: 240, loss: 0.20553083717823029
step: 250, loss: 0.16440483927726746
step: 260, loss: 0.19123610854148865
step: 270, loss: 0.25738853216171265
step: 280, loss: 0.09561190009117126
step: 290, loss: 0.1503658890724182
step: 300, loss: 0.21477437019348145
step: 310, loss: 0.19066423177719116
step: 320, loss: 0.1685105860233307
step: 330, loss: 0.1712704300880432
epoch 2: dev_f1=0.7583497053045186, f1=0.758893280632411, best_f1=0.758893280632411
step: 0, loss: 0.07581902295351028
step: 10, loss: 0.09496547281742096
step: 20, loss: 0.025405658408999443
step: 30, loss: 0.06963841617107391
step: 40, loss: 0.13315607607364655
step: 50, loss: 0.10641259700059891
step: 60, loss: 0.1639193296432495
step: 70, loss: 0.09653422981500626
step: 80, loss: 0.1336515098810196
step: 90, loss: 0.3035319745540619
step: 100, loss: 0.09518590569496155
step: 110, loss: 0.1373361349105835
step: 120, loss: 0.03729662671685219
step: 130, loss: 0.09065476804971695
step: 140, loss: 0.027853678911924362
step: 150, loss: 0.15571637451648712
step: 160, loss: 0.10088205337524414
step: 170, loss: 0.049962036311626434
step: 180, loss: 0.07867687940597534
step: 190, loss: 0.09940144419670105
step: 200, loss: 0.20756857097148895
step: 210, loss: 0.07805345952510834
step: 220, loss: 0.12512335181236267
step: 230, loss: 0.16419412195682526
step: 240, loss: 0.09954603761434555
step: 250, loss: 0.1354101002216339
step: 260, loss: 0.07446306943893433
step: 270, loss: 0.046019911766052246
step: 280, loss: 0.1883428692817688
step: 290, loss: 0.1286812424659729
step: 300, loss: 0.1466839760541916
step: 310, loss: 0.03598761186003685
step: 320, loss: 0.24365976452827454
step: 330, loss: 0.17829956114292145
epoch 3: dev_f1=0.794979079497908, f1=0.7759336099585062, best_f1=0.7759336099585062
step: 0, loss: 0.02951277792453766
step: 10, loss: 0.05414392054080963
step: 20, loss: 0.16412396728992462
step: 30, loss: 0.21028929948806763
step: 40, loss: 0.06750582903623581
step: 50, loss: 0.032851800322532654
step: 60, loss: 0.07303722202777863
step: 70, loss: 0.05030471086502075
step: 80, loss: 0.013423732481896877
step: 90, loss: 0.1451406180858612
step: 100, loss: 0.2011861652135849
step: 110, loss: 0.046827975660562515
step: 120, loss: 0.05192004144191742
step: 130, loss: 0.4387078583240509
step: 140, loss: 0.18396760523319244
step: 150, loss: 0.11926352232694626
step: 160, loss: 0.09152086079120636
step: 170, loss: 0.17764073610305786
step: 180, loss: 0.0525909885764122
step: 190, loss: 0.1119823157787323
step: 200, loss: 0.056618671864271164
step: 210, loss: 0.0716334879398346
step: 220, loss: 0.08282586187124252
step: 230, loss: 0.05831480771303177
step: 240, loss: 0.08774538338184357
step: 250, loss: 0.12893618643283844
step: 260, loss: 0.0639403909444809
step: 270, loss: 0.08399232476949692
step: 280, loss: 0.1677921712398529
step: 290, loss: 0.14008396863937378
step: 300, loss: 0.09425437450408936
step: 310, loss: 0.17972688376903534
step: 320, loss: 0.15597832202911377
step: 330, loss: 0.13918888568878174
epoch 4: dev_f1=0.8059701492537313, f1=0.8058968058968059, best_f1=0.8058968058968059
step: 0, loss: 0.04896945133805275
step: 10, loss: 0.05959263816475868
step: 20, loss: 0.2471739649772644
step: 30, loss: 0.16255950927734375
step: 40, loss: 0.04835394769906998
step: 50, loss: 0.05270432308316231
step: 60, loss: 0.09369104355573654
step: 70, loss: 0.17337991297245026
step: 80, loss: 0.10214313864707947
step: 90, loss: 0.11797250807285309
step: 100, loss: 0.09161659330129623
step: 110, loss: 0.23382745683193207
step: 120, loss: 0.1283937394618988
step: 130, loss: 0.104123555123806
step: 140, loss: 0.1710018813610077
step: 150, loss: 0.05836109444499016
step: 160, loss: 0.044888466596603394
step: 170, loss: 0.06272488832473755
step: 180, loss: 0.0014570994535461068
step: 190, loss: 0.05672798678278923
step: 200, loss: 0.016410745680332184
step: 210, loss: 0.10102777183055878
step: 220, loss: 0.05295014753937721
step: 230, loss: 0.14332149922847748
step: 240, loss: 0.06815320253372192
step: 250, loss: 0.12233710289001465
step: 260, loss: 0.12438863515853882
step: 270, loss: 0.026985295116901398
step: 280, loss: 0.07358980178833008
step: 290, loss: 0.13829492032527924
step: 300, loss: 0.08302415162324905
step: 310, loss: 0.09743136912584305
step: 320, loss: 0.0682072564959526
step: 330, loss: 0.15036886930465698
epoch 5: dev_f1=0.8167053364269141, f1=0.7734553775743708, best_f1=0.7734553775743708
step: 0, loss: 0.0868949443101883
step: 10, loss: 0.20153261721134186
step: 20, loss: 0.09217094630002975
step: 30, loss: 0.06175611913204193
step: 40, loss: 0.07413707673549652
step: 50, loss: 0.10287439078092575
step: 60, loss: 0.08988609164953232
step: 70, loss: 0.3682633340358734
step: 80, loss: 0.1393660008907318
step: 90, loss: 0.13632062077522278
step: 100, loss: 0.060027167201042175
step: 110, loss: 0.08789204061031342
step: 120, loss: 0.03668231889605522
step: 130, loss: 0.054229188710451126
step: 140, loss: 0.1456190049648285
step: 150, loss: 0.03242425248026848
step: 160, loss: 0.06296776980161667
step: 170, loss: 0.06683232635259628
step: 180, loss: 0.049648918211460114
step: 190, loss: 0.11431767046451569
step: 200, loss: 0.16905514895915985
step: 210, loss: 0.08292345702648163
step: 220, loss: 0.005507133435457945
step: 230, loss: 0.04497402906417847
step: 240, loss: 0.13798660039901733
step: 250, loss: 0.1085633710026741
step: 260, loss: 0.10026827454566956
step: 270, loss: 0.13555850088596344
step: 280, loss: 0.043082766234874725
step: 290, loss: 0.1102103441953659
step: 300, loss: 0.16021089255809784
step: 310, loss: 0.07308437675237656
step: 320, loss: 0.048482514917850494
step: 330, loss: 0.04515838995575905
epoch 6: dev_f1=0.8271028037383177, f1=0.7765237020316026, best_f1=0.7765237020316026
step: 0, loss: 0.10571015626192093
step: 10, loss: 0.06716116517782211
step: 20, loss: 0.08650092780590057
step: 30, loss: 0.10749565809965134
step: 40, loss: 0.07503669708967209
step: 50, loss: 0.049528468400239944
step: 60, loss: 0.16343843936920166
step: 70, loss: 0.17520980536937714
step: 80, loss: 0.10212786495685577
step: 90, loss: 0.10582498461008072
step: 100, loss: 0.14454641938209534
step: 110, loss: 0.0002721156633924693
step: 120, loss: 0.05575041100382805
step: 130, loss: 0.17929862439632416
step: 140, loss: 0.10023193061351776
step: 150, loss: 0.12795858085155487
step: 160, loss: 0.1865987628698349
step: 170, loss: 0.06327971071004868
step: 180, loss: 0.22280991077423096
step: 190, loss: 0.16463148593902588
step: 200, loss: 0.14215438067913055
step: 210, loss: 0.13824103772640228
step: 220, loss: 0.07713326066732407
step: 230, loss: 0.11737626045942307
step: 240, loss: 0.11570318043231964
step: 250, loss: 0.036377765238285065
step: 260, loss: 0.11837375164031982
step: 270, loss: 0.11010079085826874
step: 280, loss: 0.14052391052246094
step: 290, loss: 0.10603205114603043
step: 300, loss: 0.1247895285487175
step: 310, loss: 0.09594938158988953
step: 320, loss: 0.03230052813887596
step: 330, loss: 0.08467145264148712
epoch 7: dev_f1=0.827906976744186, f1=0.7737556561085972, best_f1=0.7737556561085972
step: 0, loss: 0.08174204081296921
step: 10, loss: 0.19456396996974945
step: 20, loss: 0.10290305316448212
step: 30, loss: 0.1356750726699829
step: 40, loss: 0.12247220426797867
step: 50, loss: 0.12087041139602661
step: 60, loss: 0.17625612020492554
step: 70, loss: 0.12161827832460403
step: 80, loss: 0.11790714412927628
step: 90, loss: 0.049601923674345016
step: 100, loss: 0.07542441040277481
step: 110, loss: 0.16351832449436188
step: 120, loss: 0.12613490223884583
step: 130, loss: 0.15179428458213806
step: 140, loss: 0.09101664274930954
step: 150, loss: 0.17634962499141693
step: 160, loss: 0.15382301807403564
step: 170, loss: 0.18201802670955658
step: 180, loss: 0.027607129886746407
step: 190, loss: 0.025917761027812958
step: 200, loss: 0.044926997274160385
step: 210, loss: 0.04019924998283386
step: 220, loss: 0.028878912329673767
step: 230, loss: 0.09361208975315094
step: 240, loss: 0.08629622310400009
step: 250, loss: 0.083489790558815
step: 260, loss: 0.014305448159575462
step: 270, loss: 0.13706618547439575
step: 280, loss: 0.09412603080272675
step: 290, loss: 0.18240764737129211
step: 300, loss: 0.09495368599891663
step: 310, loss: 0.12311486154794693
step: 320, loss: 0.10163688659667969
step: 330, loss: 0.08203284442424774
epoch 8: dev_f1=0.8091603053435115, f1=0.773067331670823, best_f1=0.7737556561085972
step: 0, loss: 0.1161206066608429
step: 10, loss: 0.17057740688323975
step: 20, loss: 0.09947801381349564
step: 30, loss: 0.10288649052381516
step: 40, loss: 0.1562928855419159
step: 50, loss: 0.20320993661880493
step: 60, loss: 0.10679085552692413
step: 70, loss: 0.0616033598780632
step: 80, loss: 0.14081478118896484
step: 90, loss: 0.13325704634189606
step: 100, loss: 0.1337154507637024
step: 110, loss: 0.08503802865743637
step: 120, loss: 0.07165002077817917
step: 130, loss: 0.06049993634223938
step: 140, loss: 0.02115962840616703
step: 150, loss: 0.059839535504579544
step: 160, loss: 0.1285555213689804
step: 170, loss: 0.03896264359354973
step: 180, loss: 0.15794406831264496
step: 190, loss: 0.07777240127325058
step: 200, loss: 0.11992616951465607
step: 210, loss: 0.1159767135977745
step: 220, loss: 0.03770272433757782
step: 230, loss: 0.08005468547344208
step: 240, loss: 0.07888229936361313
step: 250, loss: 0.151662215590477
step: 260, loss: 0.0426732674241066
step: 270, loss: 0.004652650561183691
step: 280, loss: 0.12717188894748688
step: 290, loss: 0.0982120931148529
step: 300, loss: 0.13493295013904572
step: 310, loss: 0.17265817523002625
step: 320, loss: 0.08414456248283386
step: 330, loss: 0.05983079969882965
epoch 9: dev_f1=0.821852731591449, f1=0.7871853546910755, best_f1=0.7737556561085972
step: 0, loss: 0.07946190237998962
step: 10, loss: 0.053952768445014954
step: 20, loss: 0.3477836847305298
step: 30, loss: 0.09638466686010361
step: 40, loss: 0.04082547873258591
step: 50, loss: 0.04421497508883476
step: 60, loss: 0.10646507143974304
step: 70, loss: 0.10335811972618103
step: 80, loss: 0.12668508291244507
step: 90, loss: 0.15613126754760742
step: 100, loss: 0.06238389387726784
step: 110, loss: 0.0840471163392067
step: 120, loss: 0.14938268065452576
step: 130, loss: 0.041742727160453796
step: 140, loss: 0.11009416729211807
step: 150, loss: 0.12646736204624176
step: 160, loss: 0.12747685611248016
step: 170, loss: 0.09001908451318741
step: 180, loss: 0.06259863078594208
step: 190, loss: 0.13050763309001923
step: 200, loss: 0.09641309082508087
step: 210, loss: 0.05767383053898811
step: 220, loss: 0.10935501009225845
step: 230, loss: 0.12099374830722809
step: 240, loss: 0.12329034507274628
step: 250, loss: 0.12903235852718353
step: 260, loss: 0.12450037896633148
step: 270, loss: 0.09312473982572556
step: 280, loss: 0.22256067395210266
step: 290, loss: 0.054481927305459976
step: 300, loss: 0.07151128351688385
step: 310, loss: 0.10912131518125534
step: 320, loss: 0.04334346577525139
step: 330, loss: 0.2525058090686798
epoch 10: dev_f1=0.8480392156862744, f1=0.8162291169451074, best_f1=0.8162291169451074
step: 0, loss: 0.10998902469873428
step: 10, loss: 0.06318533420562744
step: 20, loss: 0.11407797783613205
step: 30, loss: 0.09514525532722473
step: 40, loss: 0.06385591626167297
step: 50, loss: 0.027811536565423012
step: 60, loss: 0.07460148632526398
step: 70, loss: 0.10781282186508179
step: 80, loss: 0.04510394111275673
step: 90, loss: 0.02775191143155098
step: 100, loss: 0.07657571136951447
step: 110, loss: 0.09782298654317856
step: 120, loss: 0.12643566727638245
step: 130, loss: 0.11312907934188843
step: 140, loss: 0.0492173470556736
step: 150, loss: 0.05821339413523674
step: 160, loss: 0.060520388185977936
step: 170, loss: 0.12094151973724365
step: 180, loss: 0.15327662229537964
step: 190, loss: 0.09403359144926071
step: 200, loss: 0.03296565264463425
step: 210, loss: 0.1257830113172531
step: 220, loss: 0.10039311647415161
step: 230, loss: 0.1106271743774414
step: 240, loss: 0.2133239358663559
step: 250, loss: 0.13926537334918976
step: 260, loss: 0.15488581359386444
step: 270, loss: 0.057969819754362106
step: 280, loss: 0.1166394054889679
step: 290, loss: 0.10377187281847
step: 300, loss: 0.12783768773078918
step: 310, loss: 0.02059236913919449
step: 320, loss: 0.07018138468265533
step: 330, loss: 0.11924276500940323
epoch 11: dev_f1=0.8418604651162792, f1=0.8205128205128204, best_f1=0.8162291169451074
step: 0, loss: 0.01966015249490738
step: 10, loss: 0.12119127810001373
step: 20, loss: 0.07876113802194595
step: 30, loss: 0.16581963002681732
step: 40, loss: 0.13549473881721497
step: 50, loss: 0.08476543426513672
step: 60, loss: 0.2531110942363739
step: 70, loss: 0.04312829673290253
step: 80, loss: 0.13793495297431946
step: 90, loss: 0.13646861910820007
step: 100, loss: 0.11732609570026398
step: 110, loss: 0.08501096069812775
step: 120, loss: 0.04492653161287308
step: 130, loss: 0.12841573357582092
step: 140, loss: 0.10145145654678345
step: 150, loss: 0.0430741049349308
step: 160, loss: 0.06436176598072052
step: 170, loss: 0.10133768618106842
step: 180, loss: 0.13017047941684723
step: 190, loss: 0.026342807337641716
step: 200, loss: 0.13757693767547607
step: 210, loss: 0.12465263903141022
step: 220, loss: 0.08747965842485428
step: 230, loss: 0.18210329115390778
step: 240, loss: 0.0849689394235611
step: 250, loss: 0.13951732218265533
step: 260, loss: 0.08250100910663605
step: 270, loss: 0.0696832612156868
step: 280, loss: 0.02074606344103813
step: 290, loss: 0.05935409665107727
step: 300, loss: 0.12222269177436829
step: 310, loss: 0.05141366273164749
step: 320, loss: 0.09453672915697098
step: 330, loss: 0.10333286225795746
epoch 12: dev_f1=0.8530805687203792, f1=0.8162291169451074, best_f1=0.8162291169451074
step: 0, loss: 0.10542058199644089
step: 10, loss: 0.022604461759328842
step: 20, loss: 0.0391126312315464
step: 30, loss: 0.11043068021535873
step: 40, loss: 0.1477052867412567
step: 50, loss: 0.06419197469949722
step: 60, loss: 0.0736294612288475
step: 70, loss: 0.09551992267370224
step: 80, loss: 0.10835972428321838
step: 90, loss: 0.08769803494215012
step: 100, loss: 0.23068109154701233
step: 110, loss: 0.07216367870569229
step: 120, loss: 0.0687442272901535
step: 130, loss: 0.10303965210914612
step: 140, loss: 0.26804184913635254
step: 150, loss: 0.03907812386751175
step: 160, loss: 0.09154733270406723
step: 170, loss: 0.12140582501888275
step: 180, loss: 0.11010931432247162
step: 190, loss: 6.109358946559951e-05
step: 200, loss: 0.03478889912366867
step: 210, loss: 0.11668951064348221
step: 220, loss: 0.09234157204627991
step: 230, loss: 0.01652250438928604
step: 240, loss: 0.0972692146897316
step: 250, loss: 0.023440536111593246
step: 260, loss: 0.02155604027211666
step: 270, loss: 0.10463175177574158
step: 280, loss: 0.02793220989406109
step: 290, loss: 0.10805810242891312
step: 300, loss: 0.05336754024028778
step: 310, loss: 0.10149136185646057
step: 320, loss: 0.0967557355761528
step: 330, loss: 0.08084900677204132
epoch 13: dev_f1=0.8329177057356608, f1=0.8118811881188118, best_f1=0.8162291169451074
step: 0, loss: 0.19217798113822937
step: 10, loss: 0.08262301236391068
step: 20, loss: 0.12630142271518707
step: 30, loss: 0.0516720674932003
step: 40, loss: 0.1526748687028885
step: 50, loss: 0.1970776915550232
step: 60, loss: 0.06716001033782959
step: 70, loss: 0.04399773105978966
step: 80, loss: 0.09568841755390167
step: 90, loss: 0.07775518298149109
step: 100, loss: 0.06704097241163254
step: 110, loss: 0.05343857780098915
step: 120, loss: 0.02832523174583912
step: 130, loss: 0.06769648939371109
step: 140, loss: 0.12179826200008392
step: 150, loss: 0.021448582410812378
step: 160, loss: 0.07738325744867325
step: 170, loss: 0.04353968799114227
step: 180, loss: 0.11751914024353027
step: 190, loss: 0.018381372094154358
step: 200, loss: 0.05723736062645912
step: 210, loss: 0.07848166674375534
step: 220, loss: 0.0578242652118206
step: 230, loss: 0.1818004548549652
step: 240, loss: 0.013129619881510735
step: 250, loss: 0.04177187755703926
step: 260, loss: 0.09483392536640167
step: 270, loss: 0.08546136319637299
step: 280, loss: 0.10295406728982925
step: 290, loss: 0.11669476330280304
step: 300, loss: 0.033740125596523285
step: 310, loss: 0.043934766203165054
step: 320, loss: 0.09516087174415588
step: 330, loss: 0.05204399675130844
epoch 14: dev_f1=0.8235294117647057, f1=0.8120649651972157, best_f1=0.8162291169451074
step: 0, loss: 0.07156123220920563
step: 10, loss: 0.08393235504627228
step: 20, loss: 0.022684387862682343
step: 30, loss: 0.12008819729089737
step: 40, loss: 0.06361766904592514
step: 50, loss: 0.04717129468917847
step: 60, loss: 0.13537241518497467
step: 70, loss: 0.3591354191303253
step: 80, loss: 0.1351967751979828
step: 90, loss: 0.06860841810703278
step: 100, loss: 0.1048441007733345
step: 110, loss: 0.06509411334991455
step: 120, loss: 0.08908380568027496
step: 130, loss: 0.0625128224492073
step: 140, loss: 0.07499687373638153
step: 150, loss: 0.05829878896474838
step: 160, loss: 0.09746991097927094
step: 170, loss: 0.05776311084628105
step: 180, loss: 0.08843216300010681
step: 190, loss: 0.07613462954759598
step: 200, loss: 0.05302709713578224
step: 210, loss: 0.21116195619106293
step: 220, loss: 0.11016340553760529
step: 230, loss: 0.07620745897293091
step: 240, loss: 0.028317170217633247
step: 250, loss: 0.00025663923588581383
step: 260, loss: 0.09630101174116135
step: 270, loss: 0.06880684196949005
step: 280, loss: 0.06645120680332184
step: 290, loss: 0.02032097429037094
step: 300, loss: 0.2109413594007492
step: 310, loss: 0.10370822995901108
step: 320, loss: 0.11244034022092819
step: 330, loss: 0.11930710077285767
epoch 15: dev_f1=0.8211586901763224, f1=0.815, best_f1=0.8162291169451074
step: 0, loss: 0.11642799526453018
step: 10, loss: 0.08762723952531815
step: 20, loss: 0.11335253715515137
step: 30, loss: 0.050177089869976044
step: 40, loss: 0.1375918835401535
step: 50, loss: 0.06199028715491295
step: 60, loss: 0.056990716606378555
step: 70, loss: 0.10168717056512833
step: 80, loss: 0.06004192307591438
step: 90, loss: 0.08747212588787079
step: 100, loss: 0.07629438489675522
step: 110, loss: 0.05844349414110184
step: 120, loss: 0.10548117756843567
step: 130, loss: 0.1142493486404419
step: 140, loss: 0.04495161399245262
step: 150, loss: 0.05611564964056015
step: 160, loss: 0.08225991576910019
step: 170, loss: 0.050814077258110046
step: 180, loss: 0.08085451275110245
step: 190, loss: 0.06702753901481628
step: 200, loss: 0.1177050769329071
step: 210, loss: 0.04347611591219902
step: 220, loss: 0.025102071464061737
step: 230, loss: 0.03865762799978256
step: 240, loss: 0.05829070508480072
step: 250, loss: 0.14456607401371002
step: 260, loss: 0.08438023179769516
step: 270, loss: 0.09612368792295456
step: 280, loss: 0.04677454009652138
step: 290, loss: 0.08474565297365189
step: 300, loss: 0.05758180841803551
step: 310, loss: 0.09712802618741989
step: 320, loss: 0.03710968792438507
step: 330, loss: 0.06591912358999252
epoch 16: dev_f1=0.8368794326241136, f1=0.8148148148148148, best_f1=0.8162291169451074
step: 0, loss: 0.061002179980278015
step: 10, loss: 0.08246870338916779
step: 20, loss: 0.03607560694217682
step: 30, loss: 0.05964331328868866
step: 40, loss: 0.018842432647943497
step: 50, loss: 0.07693316787481308
step: 60, loss: 0.07039370387792587
step: 70, loss: 0.08251417428255081
step: 80, loss: 0.04890136048197746
step: 90, loss: 0.07777287065982819
step: 100, loss: 0.06475408375263214
step: 110, loss: 0.08952575922012329
step: 120, loss: 0.02620634064078331
step: 130, loss: 0.09478417038917542
step: 140, loss: 0.12431495636701584
step: 150, loss: 0.060808777809143066
step: 160, loss: 0.0948033258318901
step: 170, loss: 0.0055164978839457035
step: 180, loss: 0.030381932854652405
step: 190, loss: 0.09696701914072037
step: 200, loss: 0.11613456904888153
step: 210, loss: 0.07363321632146835
step: 220, loss: 0.06290256232023239
step: 230, loss: 0.06393363326787949
step: 240, loss: 0.04383840411901474
step: 250, loss: 0.049071937799453735
step: 260, loss: 0.10417168587446213
step: 270, loss: 0.014054212719202042
step: 280, loss: 0.08864918351173401
step: 290, loss: 0.026532700285315514
step: 300, loss: 0.08052921295166016
step: 310, loss: 0.08759424090385437
step: 320, loss: 0.09957736730575562
step: 330, loss: 0.08349232375621796
epoch 17: dev_f1=0.8385542168674698, f1=0.8266033254156769, best_f1=0.8162291169451074
step: 0, loss: 0.06405963748693466
step: 10, loss: 0.04731256514787674
step: 20, loss: 0.08385010808706284
step: 30, loss: 0.06038066744804382
step: 40, loss: 0.0851992592215538
step: 50, loss: 0.04444172605872154
step: 60, loss: 0.044759172946214676
step: 70, loss: 0.14272835850715637
step: 80, loss: 0.12764032185077667
step: 90, loss: 0.007527233101427555
step: 100, loss: 0.02532702498137951
step: 110, loss: 0.007149907294660807
step: 120, loss: 0.07936654984951019
step: 130, loss: 0.12192170321941376
step: 140, loss: 0.07660532742738724
step: 150, loss: 0.1167670264840126
step: 160, loss: 0.11860794574022293
step: 170, loss: 0.04968375712633133
step: 180, loss: 0.09813693910837173
step: 190, loss: 0.04567170888185501
step: 200, loss: 0.06593188643455505
step: 210, loss: 0.06066037714481354
step: 220, loss: 0.12192191183567047
step: 230, loss: 0.06394235044717789
step: 240, loss: 0.03150974214076996
step: 250, loss: 0.12050884962081909
step: 260, loss: 0.038347236812114716
step: 270, loss: 0.09662295132875443
step: 280, loss: 0.08603158593177795
step: 290, loss: 0.12069828063249588
step: 300, loss: 0.1535351574420929
step: 310, loss: 0.05624112859368324
step: 320, loss: 0.04141348600387573
step: 330, loss: 0.0654640644788742
epoch 18: dev_f1=0.835820895522388, f1=0.8226600985221675, best_f1=0.8162291169451074
step: 0, loss: 0.19036608934402466
step: 10, loss: 0.0800071507692337
step: 20, loss: 0.13734447956085205
step: 30, loss: 0.0811941847205162
step: 40, loss: 0.029876871034502983
step: 50, loss: 0.059119224548339844
step: 60, loss: 0.0002175529079977423
step: 70, loss: 0.04020613431930542
step: 80, loss: 0.05122124403715134
step: 90, loss: 0.08715824782848358
step: 100, loss: 0.01973261497914791
step: 110, loss: 0.053016841411590576
step: 120, loss: 0.056023139506578445
step: 130, loss: 0.0638090968132019
step: 140, loss: 0.10017044097185135
step: 150, loss: 0.029407961294054985
step: 160, loss: 0.06844617426395416
step: 170, loss: 0.10554908215999603
step: 180, loss: 0.05514013022184372
step: 190, loss: 0.14195376634597778
step: 200, loss: 0.037795379757881165
step: 210, loss: 0.10794860124588013
step: 220, loss: 0.1083727553486824
step: 230, loss: 0.12387368083000183
step: 240, loss: 0.10402662307024002
step: 250, loss: 0.058759551495313644
step: 260, loss: 0.11988133192062378
step: 270, loss: 0.15523794293403625
step: 280, loss: 0.023999564349651337
step: 290, loss: 0.004997855518013239
step: 300, loss: 0.008724872954189777
step: 310, loss: 0.06666255742311478
step: 320, loss: 0.12068425118923187
step: 330, loss: 0.0868571400642395
epoch 19: dev_f1=0.8316831683168316, f1=0.8235294117647058, best_f1=0.8162291169451074
step: 0, loss: 0.11315245181322098
step: 10, loss: 0.06825993955135345
step: 20, loss: 0.1369890719652176
step: 30, loss: 0.0889216735959053
step: 40, loss: 0.031934719532728195
step: 50, loss: 0.0428406223654747
step: 60, loss: 0.013914987444877625
step: 70, loss: 0.0713452622294426
step: 80, loss: 0.020304860547184944
step: 90, loss: 0.03907061740756035
step: 100, loss: 0.09839766472578049
step: 110, loss: 0.11971025913953781
step: 120, loss: 0.07667750865221024
step: 130, loss: 0.04166233912110329
step: 140, loss: 0.09206106513738632
step: 150, loss: 0.06390775740146637
step: 160, loss: 0.07451139390468597
step: 170, loss: 0.07766056805849075
step: 180, loss: 0.09466391801834106
step: 190, loss: 0.03861361742019653
step: 200, loss: 0.09666237235069275
step: 210, loss: 0.1106816977262497
step: 220, loss: 0.06878358125686646
step: 230, loss: 0.02901516854763031
step: 240, loss: 0.05353355035185814
step: 250, loss: 0.0684826672077179
step: 260, loss: 0.059386350214481354
step: 270, loss: 0.07298227399587631
step: 280, loss: 0.06546963006258011
step: 290, loss: 0.0677691325545311
step: 300, loss: 0.01986617036163807
step: 310, loss: 0.05264612287282944
step: 320, loss: 0.10245245695114136
step: 330, loss: 0.005600172095000744
epoch 20: dev_f1=0.8296296296296296, f1=0.8128078817733989, best_f1=0.8162291169451074
