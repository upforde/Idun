cuda
Device: cuda
step: 0, loss: 0.4328319728374481
step: 10, loss: 0.23414485156536102
step: 20, loss: 0.3396205008029938
step: 30, loss: 0.23009835183620453
step: 40, loss: 0.237441748380661
step: 50, loss: 0.27937546372413635
step: 60, loss: 0.12286104261875153
step: 70, loss: 0.10998980700969696
step: 80, loss: 0.2328764647245407
step: 90, loss: 0.06292998790740967
step: 100, loss: 0.23788979649543762
step: 110, loss: 0.14280909299850464
step: 120, loss: 0.2493225336074829
step: 130, loss: 0.2939716875553131
step: 140, loss: 0.05662699043750763
step: 150, loss: 0.28509098291397095
step: 160, loss: 0.30335408449172974
step: 170, loss: 0.34333014488220215
step: 180, loss: 0.14115431904792786
step: 190, loss: 0.2522803544998169
step: 200, loss: 0.19397974014282227
step: 210, loss: 0.07646039128303528
step: 220, loss: 0.693413496017456
step: 230, loss: 0.22950831055641174
step: 240, loss: 0.28436386585235596
step: 250, loss: 0.04398661106824875
step: 260, loss: 0.08236022293567657
step: 270, loss: 0.17238681018352509
step: 280, loss: 0.12511244416236877
step: 290, loss: 0.08170389384031296
step: 300, loss: 0.14655359089374542
step: 310, loss: 0.21965664625167847
step: 320, loss: 0.0750778391957283
step: 330, loss: 0.17166584730148315
epoch 1: dev_f1=0.6396396396396397, f1=0.631346578366446, best_f1=0.631346578366446
step: 0, loss: 0.11337591707706451
step: 10, loss: 0.06514503061771393
step: 20, loss: 0.12467930465936661
step: 30, loss: 0.05192594975233078
step: 40, loss: 0.12099193036556244
step: 50, loss: 0.3335924446582794
step: 60, loss: 0.09203290939331055
step: 70, loss: 0.0993361622095108
step: 80, loss: 0.07870491594076157
step: 90, loss: 0.11822929978370667
step: 100, loss: 0.15885582566261292
step: 110, loss: 0.15455655753612518
step: 120, loss: 0.18810664117336273
step: 130, loss: 0.06822448968887329
step: 140, loss: 0.10361416637897491
step: 150, loss: 0.15784750878810883
step: 160, loss: 0.13223879039287567
step: 170, loss: 0.029948102310299873
step: 180, loss: 0.16988711059093475
step: 190, loss: 0.1833188533782959
step: 200, loss: 0.07438187301158905
step: 210, loss: 0.08437800407409668
step: 220, loss: 0.038098160177469254
step: 230, loss: 0.09862377494573593
step: 240, loss: 0.1041155532002449
step: 250, loss: 0.07634533941745758
step: 260, loss: 0.1964176446199417
step: 270, loss: 0.16769517958164215
step: 280, loss: 0.07688160240650177
step: 290, loss: 0.08277831971645355
step: 300, loss: 0.11255121231079102
step: 310, loss: 0.11001615971326828
step: 320, loss: 0.05513213202357292
step: 330, loss: 0.16189894080162048
epoch 2: dev_f1=0.772093023255814, f1=0.7902869757174392, best_f1=0.7902869757174392
step: 0, loss: 0.09894780069589615
step: 10, loss: 0.14820656180381775
step: 20, loss: 0.07660485804080963
step: 30, loss: 0.16368722915649414
step: 40, loss: 0.09150825440883636
step: 50, loss: 0.10344371199607849
step: 60, loss: 0.12377442419528961
step: 70, loss: 0.07415241748094559
step: 80, loss: 0.07504639774560928
step: 90, loss: 0.2472306489944458
step: 100, loss: 0.020396864041686058
step: 110, loss: 0.13651937246322632
step: 120, loss: 0.1263798624277115
step: 130, loss: 0.15615466237068176
step: 140, loss: 0.12981906533241272
step: 150, loss: 0.11227085441350937
step: 160, loss: 0.09538667649030685
step: 170, loss: 0.10920154303312302
step: 180, loss: 0.09725319594144821
step: 190, loss: 0.06681054830551147
step: 200, loss: 0.06767304986715317
step: 210, loss: 0.1924862265586853
step: 220, loss: 0.1217724084854126
step: 230, loss: 0.12249528616666794
step: 240, loss: 0.17391371726989746
step: 250, loss: 0.059826042503118515
step: 260, loss: 0.05266839265823364
step: 270, loss: 0.10653363168239594
step: 280, loss: 0.2717829644680023
step: 290, loss: 0.14381246268749237
step: 300, loss: 0.08914825320243835
step: 310, loss: 0.052349191159009933
step: 320, loss: 0.030607718974351883
step: 330, loss: 0.1099487692117691
epoch 3: dev_f1=0.814977973568282, f1=0.7838983050847458, best_f1=0.7838983050847458
step: 0, loss: 0.10365491360425949
step: 10, loss: 0.07991669327020645
step: 20, loss: 0.044857628643512726
step: 30, loss: 0.19172701239585876
step: 40, loss: 0.052505772560834885
step: 50, loss: 0.15778565406799316
step: 60, loss: 0.14272046089172363
step: 70, loss: 0.18836243450641632
step: 80, loss: 0.27007949352264404
step: 90, loss: 0.14993682503700256
step: 100, loss: 0.10146781802177429
step: 110, loss: 0.16884592175483704
step: 120, loss: 0.09088823944330215
step: 130, loss: 0.0278789009898901
step: 140, loss: 0.03392312303185463
step: 150, loss: 0.0831727683544159
step: 160, loss: 0.0005992721999064088
step: 170, loss: 0.11293209344148636
step: 180, loss: 0.08403103053569794
step: 190, loss: 0.1263367384672165
step: 200, loss: 0.17472626268863678
step: 210, loss: 0.14414463937282562
step: 220, loss: 0.17425142228603363
step: 230, loss: 0.04055676609277725
step: 240, loss: 0.10015951842069626
step: 250, loss: 0.12292633950710297
step: 260, loss: 0.2243027687072754
step: 270, loss: 0.20913778245449066
step: 280, loss: 0.1408728063106537
step: 290, loss: 0.09076013416051865
step: 300, loss: 0.041433583945035934
step: 310, loss: 0.11285201460123062
step: 320, loss: 0.06569591909646988
step: 330, loss: 0.08552644401788712
epoch 4: dev_f1=0.7516778523489933, f1=0.7568710359408033, best_f1=0.7838983050847458
step: 0, loss: 0.0657460168004036
step: 10, loss: 0.06174197420477867
step: 20, loss: 0.08432731032371521
step: 30, loss: 0.05869869142770767
step: 40, loss: 0.12032070010900497
step: 50, loss: 0.15640997886657715
step: 60, loss: 0.1440289318561554
step: 70, loss: 0.15420156717300415
step: 80, loss: 0.11345672607421875
step: 90, loss: 0.0733901634812355
step: 100, loss: 0.07154987752437592
step: 110, loss: 0.07897013425827026
step: 120, loss: 0.09184665977954865
step: 130, loss: 0.059808969497680664
step: 140, loss: 0.09489461034536362
step: 150, loss: 0.22689419984817505
step: 160, loss: 0.05161411687731743
step: 170, loss: 0.17253603041172028
step: 180, loss: 0.029429638758301735
step: 190, loss: 0.1168217584490776
step: 200, loss: 0.09063515812158585
step: 210, loss: 0.1648067682981491
step: 220, loss: 0.07366496324539185
step: 230, loss: 0.06177126243710518
step: 240, loss: 0.47108888626098633
step: 250, loss: 0.0848291739821434
step: 260, loss: 0.08153688907623291
step: 270, loss: 0.033465318381786346
step: 280, loss: 0.07004629820585251
step: 290, loss: 0.12680141627788544
step: 300, loss: 0.1068892553448677
step: 310, loss: 0.08673912286758423
step: 320, loss: 0.04930786415934563
step: 330, loss: 0.15555895864963531
epoch 5: dev_f1=0.8008752735229759, f1=0.7735042735042735, best_f1=0.7838983050847458
step: 0, loss: 0.09671878814697266
step: 10, loss: 0.027596650645136833
step: 20, loss: 0.02049822360277176
step: 30, loss: 0.0195446964353323
step: 40, loss: 0.17380143702030182
step: 50, loss: 0.11294340342283249
step: 60, loss: 0.08808557689189911
step: 70, loss: 0.245597705245018
step: 80, loss: 0.05074325576424599
step: 90, loss: 0.06534931808710098
step: 100, loss: 0.07325384020805359
step: 110, loss: 0.09147363901138306
step: 120, loss: 0.08376942574977875
step: 130, loss: 0.1801709234714508
step: 140, loss: 0.09561282396316528
step: 150, loss: 0.07843036949634552
step: 160, loss: 0.04763713851571083
step: 170, loss: 0.12341059744358063
step: 180, loss: 0.08760067820549011
step: 190, loss: 0.08504864573478699
step: 200, loss: 0.0860363319516182
step: 210, loss: 0.0967300534248352
step: 220, loss: 0.06743001192808151
step: 230, loss: 0.07194146513938904
step: 240, loss: 0.054061781615018845
step: 250, loss: 0.1202935129404068
step: 260, loss: 0.05057290568947792
step: 270, loss: 0.1865735948085785
step: 280, loss: 0.11226578801870346
step: 290, loss: 0.07087650895118713
step: 300, loss: 0.12581510841846466
step: 310, loss: 0.017517803236842155
step: 320, loss: 0.0846393033862114
step: 330, loss: 0.11839694529771805
epoch 6: dev_f1=0.8325581395348837, f1=0.7973273942093541, best_f1=0.7973273942093541
step: 0, loss: 0.18483030796051025
step: 10, loss: 0.04594918340444565
step: 20, loss: 0.11050889641046524
step: 30, loss: 0.10356498509645462
step: 40, loss: 0.06341864168643951
step: 50, loss: 0.07319105416536331
step: 60, loss: 0.2700158655643463
step: 70, loss: 0.13581855595111847
step: 80, loss: 0.09694477170705795
step: 90, loss: 0.14479389786720276
step: 100, loss: 0.09847375005483627
step: 110, loss: 0.14100617170333862
step: 120, loss: 0.10685953497886658
step: 130, loss: 0.09454300999641418
step: 140, loss: 0.0013337956042960286
step: 150, loss: 0.16734853386878967
step: 160, loss: 0.0897708460688591
step: 170, loss: 0.1079929918050766
step: 180, loss: 0.042280420660972595
step: 190, loss: 0.02392861619591713
step: 200, loss: 0.159769207239151
step: 210, loss: 0.02876429259777069
step: 220, loss: 0.040632255375385284
step: 230, loss: 0.08710867911577225
step: 240, loss: 0.03957533836364746
step: 250, loss: 0.1788523644208908
step: 260, loss: 0.1078166589140892
step: 270, loss: 0.13366025686264038
step: 280, loss: 0.1914546936750412
step: 290, loss: 0.15729881823062897
step: 300, loss: 0.05573209002614021
step: 310, loss: 0.13377192616462708
step: 320, loss: 0.08832438290119171
step: 330, loss: 0.07082434743642807
epoch 7: dev_f1=0.8329297820823245, f1=0.812206572769953, best_f1=0.812206572769953
step: 0, loss: 0.1146862804889679
step: 10, loss: 0.06407623738050461
step: 20, loss: 0.09538360685110092
step: 30, loss: 0.23006375133991241
step: 40, loss: 0.05887067690491676
step: 50, loss: 0.11478007584810257
step: 60, loss: 0.0513421967625618
step: 70, loss: 0.08426381647586823
step: 80, loss: 0.11087235063314438
step: 90, loss: 0.011669755913317204
step: 100, loss: 0.09365478157997131
step: 110, loss: 0.08963197469711304
step: 120, loss: 0.24689607322216034
step: 130, loss: 0.12802158296108246
step: 140, loss: 0.10249731689691544
step: 150, loss: 0.11904987692832947
step: 160, loss: 0.06738538295030594
step: 170, loss: 0.12475022673606873
step: 180, loss: 0.11307025700807571
step: 190, loss: 0.10213922709226608
step: 200, loss: 0.11117804795503616
step: 210, loss: 0.1116052120923996
step: 220, loss: 0.07817572355270386
step: 230, loss: 0.014062382280826569
step: 240, loss: 0.10504022985696793
step: 250, loss: 0.06258707493543625
step: 260, loss: 0.030759720131754875
step: 270, loss: 0.024512628093361855
step: 280, loss: 0.03418966755270958
step: 290, loss: 0.17340046167373657
step: 300, loss: 0.009110388346016407
step: 310, loss: 0.03468912094831467
step: 320, loss: 0.15349310636520386
step: 330, loss: 0.06656341254711151
epoch 8: dev_f1=0.8229426433915212, f1=0.8058252427184465, best_f1=0.812206572769953
step: 0, loss: 0.05367739498615265
step: 10, loss: 0.08365834504365921
step: 20, loss: 0.054871074855327606
step: 30, loss: 0.04690266773104668
step: 40, loss: 0.08371838927268982
step: 50, loss: 0.10537702590227127
step: 60, loss: 0.08118471503257751
step: 70, loss: 0.1420116275548935
step: 80, loss: 0.13816982507705688
step: 90, loss: 0.0344528965651989
step: 100, loss: 0.08675835281610489
step: 110, loss: 0.10985579341650009
step: 120, loss: 0.11306513845920563
step: 130, loss: 0.05222214385867119
step: 140, loss: 0.10634935647249222
step: 150, loss: 0.07768312096595764
step: 160, loss: 0.09170178323984146
step: 170, loss: 0.04528505355119705
step: 180, loss: 0.15610890090465546
step: 190, loss: 0.10300975292921066
step: 200, loss: 0.06079213321208954
step: 210, loss: 0.16210496425628662
step: 220, loss: 0.07781346887350082
step: 230, loss: 0.1345156878232956
step: 240, loss: 0.11011895537376404
step: 250, loss: 0.0923275500535965
step: 260, loss: 0.04514564201235771
step: 270, loss: 0.09073396772146225
step: 280, loss: 0.08487524837255478
step: 290, loss: 0.10534965991973877
step: 300, loss: 0.1143299788236618
step: 310, loss: 0.019916510209441185
step: 320, loss: 0.05775720626115799
step: 330, loss: 0.1619051843881607
epoch 9: dev_f1=0.8345323741007193, f1=0.8094117647058824, best_f1=0.8094117647058824
step: 0, loss: 0.12337248027324677
step: 10, loss: 0.08331151306629181
step: 20, loss: 0.03768810257315636
step: 30, loss: 0.05769234895706177
step: 40, loss: 0.09290510416030884
step: 50, loss: 0.0609302781522274
step: 60, loss: 0.0001523799728602171
step: 70, loss: 0.12142709642648697
step: 80, loss: 0.0566650852560997
step: 90, loss: 0.0945860743522644
step: 100, loss: 0.11191242188215256
step: 110, loss: 0.20280291140079498
step: 120, loss: 0.08692429959774017
step: 130, loss: 0.10634392499923706
step: 140, loss: 0.003957440610975027
step: 150, loss: 0.19480963051319122
step: 160, loss: 0.08196806162595749
step: 170, loss: 0.08395631611347198
step: 180, loss: 0.08264759927988052
step: 190, loss: 0.13221363723278046
step: 200, loss: 0.0647866278886795
step: 210, loss: 0.14442497491836548
step: 220, loss: 0.0422147735953331
step: 230, loss: 0.028300819918513298
step: 240, loss: 0.012833306565880775
step: 250, loss: 0.09334579110145569
step: 260, loss: 0.0886920616030693
step: 270, loss: 0.11527998000383377
step: 280, loss: 0.1227899044752121
step: 290, loss: 0.08063475787639618
step: 300, loss: 0.2186642587184906
step: 310, loss: 0.1451975554227829
step: 320, loss: 0.1972653567790985
step: 330, loss: 0.03722713142633438
epoch 10: dev_f1=0.8421052631578948, f1=0.788546255506608, best_f1=0.788546255506608
step: 0, loss: 0.09533929079771042
step: 10, loss: 0.1443341225385666
step: 20, loss: 0.03340179845690727
step: 30, loss: 0.091843381524086
step: 40, loss: 0.11065512150526047
step: 50, loss: 0.07362782210111618
step: 60, loss: 0.09865362197160721
step: 70, loss: 0.0644344910979271
step: 80, loss: 0.13356642425060272
step: 90, loss: 0.017685936763882637
step: 100, loss: 0.04263433441519737
step: 110, loss: 0.16334335505962372
step: 120, loss: 0.05820338800549507
step: 130, loss: 0.10759681463241577
step: 140, loss: 0.05994678661227226
step: 150, loss: 0.11481297016143799
step: 160, loss: 0.030847439542412758
step: 170, loss: 0.03914523497223854
step: 180, loss: 0.11084730923175812
step: 190, loss: 0.12097277492284775
step: 200, loss: 0.1527436077594757
step: 210, loss: 0.06020120531320572
step: 220, loss: 0.1541854441165924
step: 230, loss: 0.07330353558063507
step: 240, loss: 0.06456530839204788
step: 250, loss: 0.1336037814617157
step: 260, loss: 0.03486621007323265
step: 270, loss: 0.21577578783035278
step: 280, loss: 0.08546368032693863
step: 290, loss: 0.11540453135967255
step: 300, loss: 0.03219406306743622
step: 310, loss: 0.042329322546720505
step: 320, loss: 0.10216040164232254
step: 330, loss: 0.13079200685024261
epoch 11: dev_f1=0.821852731591449, f1=0.8073394495412843, best_f1=0.788546255506608
step: 0, loss: 0.09123190492391586
step: 10, loss: 0.022251036018133163
step: 20, loss: 0.06884002685546875
step: 30, loss: 0.10226397961378098
step: 40, loss: 0.21134188771247864
step: 50, loss: 0.07106445729732513
step: 60, loss: 0.06226072832942009
step: 70, loss: 0.06924404203891754
step: 80, loss: 0.0207382645457983
step: 90, loss: 0.004750876687467098
step: 100, loss: 0.04666971415281296
step: 110, loss: 0.06135445088148117
step: 120, loss: 0.09159113466739655
step: 130, loss: 0.031222663819789886
step: 140, loss: 0.06216569244861603
step: 150, loss: 0.0687323585152626
step: 160, loss: 0.07253562659025192
step: 170, loss: 0.08802800625562668
step: 180, loss: 0.055629339069128036
step: 190, loss: 0.08265183866024017
step: 200, loss: 0.15339972078800201
step: 210, loss: 0.11993315815925598
step: 220, loss: 0.09517170488834381
step: 230, loss: 0.15269361436367035
step: 240, loss: 0.19957628846168518
step: 250, loss: 0.0799374133348465
step: 260, loss: 0.1555274873971939
step: 270, loss: 0.11669035255908966
step: 280, loss: 0.061811480671167374
step: 290, loss: 0.10457633435726166
step: 300, loss: 0.13333885371685028
step: 310, loss: 0.09883613884449005
step: 320, loss: 0.04696016013622284
step: 330, loss: 0.3496474623680115
epoch 12: dev_f1=0.8384074941451989, f1=0.8287037037037036, best_f1=0.788546255506608
step: 0, loss: 0.022781267762184143
step: 10, loss: 0.11609303951263428
step: 20, loss: 0.07007656246423721
step: 30, loss: 0.055221475660800934
step: 40, loss: 0.10536503046751022
step: 50, loss: 0.10105200856924057
step: 60, loss: 0.16156242787837982
step: 70, loss: 0.017924608662724495
step: 80, loss: 0.12322305887937546
step: 90, loss: 0.06155310943722725
step: 100, loss: 0.036926351487636566
step: 110, loss: 0.07104956358671188
step: 120, loss: 0.0805535539984703
step: 130, loss: 0.22501565515995026
step: 140, loss: 0.10340341925621033
step: 150, loss: 0.07433295994997025
step: 160, loss: 0.0761609897017479
step: 170, loss: 0.06351114809513092
step: 180, loss: 0.036781471222639084
step: 190, loss: 0.09006739407777786
step: 200, loss: 0.06606725603342056
step: 210, loss: 0.045169051736593246
step: 220, loss: 0.06493334472179413
step: 230, loss: 0.031709980219602585
step: 240, loss: 0.17993004620075226
step: 250, loss: 0.17639198899269104
step: 260, loss: 0.09880638867616653
step: 270, loss: 0.08589112758636475
step: 280, loss: 0.06335702538490295
step: 290, loss: 0.1685561090707779
step: 300, loss: 0.14917802810668945
step: 310, loss: 0.11525288224220276
step: 320, loss: 0.12523697316646576
step: 330, loss: 0.0001642766292206943
epoch 13: dev_f1=0.8423423423423423, f1=0.8248337028824834, best_f1=0.8248337028824834
step: 0, loss: 0.06931706517934799
step: 10, loss: 0.06267689168453217
step: 20, loss: 0.1138678640127182
step: 30, loss: 0.009946738369762897
step: 40, loss: 0.025580981746315956
step: 50, loss: 0.11892172694206238
step: 60, loss: 0.05168723687529564
step: 70, loss: 0.03806322440505028
step: 80, loss: 0.05133459344506264
step: 90, loss: 0.025807909667491913
step: 100, loss: 0.11081928759813309
step: 110, loss: 0.07860330492258072
step: 120, loss: 0.15220987796783447
step: 130, loss: 0.053894754499197006
step: 140, loss: 0.1099858358502388
step: 150, loss: 0.06747759133577347
step: 160, loss: 0.09200523793697357
step: 170, loss: 9.448381752008572e-05
step: 180, loss: 0.09908889979124069
step: 190, loss: 0.03846762329339981
step: 200, loss: 0.06847566366195679
step: 210, loss: 0.09389494359493256
step: 220, loss: 0.11979048699140549
step: 230, loss: 0.14030954241752625
step: 240, loss: 0.01722659170627594
step: 250, loss: 0.07221173495054245
step: 260, loss: 0.14716669917106628
step: 270, loss: 0.13925701379776
step: 280, loss: 0.044900014996528625
step: 290, loss: 0.0475429892539978
step: 300, loss: 0.058282606303691864
step: 310, loss: 0.1101624146103859
step: 320, loss: 0.02899295836687088
step: 330, loss: 0.11012889444828033
epoch 14: dev_f1=0.8018018018018017, f1=0.7751605995717346, best_f1=0.8248337028824834
step: 0, loss: 0.10575082153081894
step: 10, loss: 0.012183642946183681
step: 20, loss: 0.08390945941209793
step: 30, loss: 0.14114201068878174
step: 40, loss: 0.00034628817229531705
step: 50, loss: 0.08685530722141266
step: 60, loss: 0.09861146658658981
step: 70, loss: 0.07676319777965546
step: 80, loss: 0.07054581493139267
step: 90, loss: 0.0633426234126091
step: 100, loss: 0.07387646287679672
step: 110, loss: 0.013039782643318176
step: 120, loss: 0.09064196050167084
step: 130, loss: 0.03569416701793671
step: 140, loss: 0.07425138354301453
step: 150, loss: 0.0775570496916771
step: 160, loss: 0.06392527371644974
step: 170, loss: 0.10690496116876602
step: 180, loss: 0.053021591156721115
step: 190, loss: 0.12365887314081192
step: 200, loss: 0.12553605437278748
step: 210, loss: 0.07081525027751923
step: 220, loss: 0.0941610112786293
step: 230, loss: 0.07026995718479156
step: 240, loss: 0.03823564574122429
step: 250, loss: 0.11148227006196976
step: 260, loss: 0.09523770213127136
step: 270, loss: 0.10054715722799301
step: 280, loss: 0.08660449832677841
step: 290, loss: 0.015278897248208523
step: 300, loss: 0.1327241063117981
step: 310, loss: 0.13563024997711182
step: 320, loss: 0.00018060770526062697
step: 330, loss: 0.03378920629620552
epoch 15: dev_f1=0.8457943925233645, f1=0.834862385321101, best_f1=0.834862385321101
step: 0, loss: 0.06974318623542786
step: 10, loss: 0.09848873317241669
step: 20, loss: 0.00014694055425934494
step: 30, loss: 0.07701089233160019
step: 40, loss: 0.035397183150053024
step: 50, loss: 0.1457657665014267
step: 60, loss: 0.03931591287255287
step: 70, loss: 0.08856428414583206
step: 80, loss: 0.17420677840709686
step: 90, loss: 0.026672931388020515
step: 100, loss: 0.08649563789367676
step: 110, loss: 0.13392314314842224
step: 120, loss: 0.03435342013835907
step: 130, loss: 0.025169841945171356
step: 140, loss: 0.07496756315231323
step: 150, loss: 0.12197858095169067
step: 160, loss: 0.08746432512998581
step: 170, loss: 0.08450215309858322
step: 180, loss: 0.007810348644852638
step: 190, loss: 0.08291076123714447
step: 200, loss: 0.05588399991393089
step: 210, loss: 0.07278259843587875
step: 220, loss: 0.06599359214305878
step: 230, loss: 0.06394606828689575
step: 240, loss: 0.04447606950998306
step: 250, loss: 0.07577567547559738
step: 260, loss: 0.0897669792175293
step: 270, loss: 0.022884774953126907
step: 280, loss: 0.04369904473423958
step: 290, loss: 0.0983317568898201
step: 300, loss: 0.064570352435112
step: 310, loss: 0.18635521829128265
step: 320, loss: 0.05997774749994278
step: 330, loss: 0.05922101065516472
epoch 16: dev_f1=0.8321513002364066, f1=0.8259860788863109, best_f1=0.834862385321101
step: 0, loss: 0.02032129466533661
step: 10, loss: 0.10421621799468994
step: 20, loss: 0.060800909996032715
step: 30, loss: 0.05332613363862038
step: 40, loss: 0.11921770125627518
step: 50, loss: 0.157671719789505
step: 60, loss: 0.05625735968351364
step: 70, loss: 0.1383606195449829
step: 80, loss: 0.1143731102347374
step: 90, loss: 0.04240446910262108
step: 100, loss: 0.08044152706861496
step: 110, loss: 0.061610449105501175
step: 120, loss: 0.08547812700271606
step: 130, loss: 0.11811661720275879
step: 140, loss: 0.045040205121040344
step: 150, loss: 0.07059493660926819
step: 160, loss: 0.0628720298409462
step: 170, loss: 0.12147921323776245
step: 180, loss: 0.09011828154325485
step: 190, loss: 0.015793077647686005
step: 200, loss: 0.0740630030632019
step: 210, loss: 0.021552249789237976
step: 220, loss: 0.053984686732292175
step: 230, loss: 0.10242290049791336
step: 240, loss: 0.007134421728551388
step: 250, loss: 0.07573993504047394
step: 260, loss: 0.024230925366282463
step: 270, loss: 0.055954109877347946
step: 280, loss: 0.06446367502212524
step: 290, loss: 0.10620777308940887
step: 300, loss: 0.04375632107257843
step: 310, loss: 0.08947496861219406
step: 320, loss: 0.05975605547428131
step: 330, loss: 0.08430691063404083
epoch 17: dev_f1=0.8213457076566126, f1=0.8091954022988505, best_f1=0.834862385321101
step: 0, loss: 0.11261694878339767
step: 10, loss: 0.009475313127040863
step: 20, loss: 0.04198293760418892
step: 30, loss: 0.05771959200501442
step: 40, loss: 0.12909981608390808
step: 50, loss: 0.01367969624698162
step: 60, loss: 0.018034083768725395
step: 70, loss: 0.03322739899158478
step: 80, loss: 0.10738476365804672
step: 90, loss: 0.16979871690273285
step: 100, loss: 0.05907681584358215
step: 110, loss: 0.07622982561588287
step: 120, loss: 0.08301092684268951
step: 130, loss: 0.01221989095211029
step: 140, loss: 0.18091359734535217
step: 150, loss: 0.13550178706645966
step: 160, loss: 0.07112204283475876
step: 170, loss: 0.012589894235134125
step: 180, loss: 0.030365297570824623
step: 190, loss: 0.06722064316272736
step: 200, loss: 0.040342770516872406
step: 210, loss: 0.031952980905771255
step: 220, loss: 0.07363411039113998
step: 230, loss: 0.03681616485118866
step: 240, loss: 0.09982720017433167
step: 250, loss: 0.03578377515077591
step: 260, loss: 0.06363900005817413
step: 270, loss: 0.046164579689502716
step: 280, loss: 0.14014555513858795
step: 290, loss: 0.10335959494113922
step: 300, loss: 0.05796508491039276
step: 310, loss: 0.03931163251399994
step: 320, loss: 0.04169474542140961
step: 330, loss: 0.08656695485115051
epoch 18: dev_f1=0.8337236533957846, f1=0.8149882903981265, best_f1=0.834862385321101
step: 0, loss: 0.06165550649166107
step: 10, loss: 0.05864936113357544
step: 20, loss: 0.02760235220193863
step: 30, loss: 0.09889945387840271
step: 40, loss: 0.0317625030875206
step: 50, loss: 0.07850179076194763
step: 60, loss: 0.04561615735292435
step: 70, loss: 0.06723491847515106
step: 80, loss: 0.04486328363418579
step: 90, loss: 0.07340443879365921
step: 100, loss: 0.030753199011087418
step: 110, loss: 0.055092137306928635
step: 120, loss: 0.10628799349069595
step: 130, loss: 0.13604101538658142
step: 140, loss: 0.08433306217193604
step: 150, loss: 0.1077713891863823
step: 160, loss: 0.1233137920498848
step: 170, loss: 0.05831089988350868
step: 180, loss: 0.13866141438484192
step: 190, loss: 0.04019300639629364
step: 200, loss: 0.08621861040592194
step: 210, loss: 0.04553288221359253
step: 220, loss: 0.11236435920000076
step: 230, loss: 0.07040703296661377
step: 240, loss: 0.12402477115392685
step: 250, loss: 2.0123796275584027e-05
step: 260, loss: 0.07253039628267288
step: 270, loss: 0.03452504798769951
step: 280, loss: 0.059794846922159195
step: 290, loss: 0.06682166457176208
step: 300, loss: 0.04636678099632263
step: 310, loss: 0.06133440136909485
step: 320, loss: 0.04265609383583069
step: 330, loss: 0.008118911646306515
epoch 19: dev_f1=0.803970223325062, f1=0.8135593220338982, best_f1=0.834862385321101
step: 0, loss: 0.16079621016979218
step: 10, loss: 0.07145293056964874
step: 20, loss: 0.10997859388589859
step: 30, loss: 0.08297283202409744
step: 40, loss: 2.0574532754835673e-05
step: 50, loss: 0.1769946962594986
step: 60, loss: 0.04176262021064758
step: 70, loss: 2.459760980855208e-05
step: 80, loss: 0.04168553277850151
step: 90, loss: 0.05350722372531891
step: 100, loss: 0.009218847379088402
step: 110, loss: 0.05149354785680771
step: 120, loss: 0.06331641227006912
step: 130, loss: 0.0990145206451416
step: 140, loss: 0.044951677322387695
step: 150, loss: 0.06209225207567215
step: 160, loss: 0.09191201627254486
step: 170, loss: 0.013020781800150871
step: 180, loss: 0.09574561566114426
step: 190, loss: 0.09474806487560272
step: 200, loss: 0.08437612652778625
step: 210, loss: 0.09125111252069473
step: 220, loss: 0.0006024801987223327
step: 230, loss: 0.11246266961097717
step: 240, loss: 0.18285536766052246
step: 250, loss: 0.045405611395835876
step: 260, loss: 0.09517054259777069
step: 270, loss: 0.01822182536125183
step: 280, loss: 0.07579804956912994
step: 290, loss: 0.04439076408743858
step: 300, loss: 0.10422056913375854
step: 310, loss: 0.06810226291418076
step: 320, loss: 0.06233946606516838
step: 330, loss: 0.027480630204081535
epoch 20: dev_f1=0.8118811881188118, f1=0.8087167070217919, best_f1=0.834862385321101
