cuda
Device: cuda
step: 0, loss: 0.7490991353988647
step: 10, loss: 0.5141631960868835
step: 20, loss: 0.05082256719470024
step: 30, loss: 0.03734450787305832
step: 40, loss: 0.4284718334674835
step: 50, loss: 0.03153737261891365
step: 60, loss: 0.05069631338119507
step: 70, loss: 0.24363645911216736
step: 80, loss: 0.5315936803817749
step: 90, loss: 0.06755518913269043
step: 100, loss: 0.24644969403743744
step: 110, loss: 0.15316113829612732
step: 120, loss: 0.2144106775522232
step: 130, loss: 0.1979466676712036
step: 140, loss: 0.35597264766693115
step: 150, loss: 0.08522743731737137
step: 160, loss: 0.2964646518230438
step: 170, loss: 0.2782456576824188
step: 180, loss: 0.2872518002986908
step: 190, loss: 0.1857740730047226
step: 200, loss: 0.28106287121772766
step: 210, loss: 0.21780215203762054
step: 220, loss: 0.1579367220401764
step: 230, loss: 0.15696188807487488
step: 240, loss: 0.3552316129207611
step: 250, loss: 0.268038272857666
step: 260, loss: 0.2908935248851776
step: 270, loss: 0.2077796459197998
step: 280, loss: 0.11534642428159714
step: 290, loss: 0.08309409022331238
step: 300, loss: 0.225475013256073
step: 310, loss: 0.18069808185100555
step: 320, loss: 0.1328573375940323
step: 330, loss: 0.159128338098526
epoch 1: dev_f1=0.7056277056277056, f1=0.7078891257995735, best_f1=0.7078891257995735
step: 0, loss: 0.16367916762828827
step: 10, loss: 0.09140115231275558
step: 20, loss: 0.24347589910030365
step: 30, loss: 0.003807899309322238
step: 40, loss: 0.1312372088432312
step: 50, loss: 0.15029406547546387
step: 60, loss: 0.15081004798412323
step: 70, loss: 0.08720885962247849
step: 80, loss: 0.16914600133895874
step: 90, loss: 0.10544992983341217
step: 100, loss: 0.0908256247639656
step: 110, loss: 0.15075437724590302
step: 120, loss: 0.15270976722240448
step: 130, loss: 0.17358720302581787
step: 140, loss: 0.08345136791467667
step: 150, loss: 0.05777775123715401
step: 160, loss: 0.13238200545310974
step: 170, loss: 0.1087183952331543
step: 180, loss: 0.28627708554267883
step: 190, loss: 0.10637412220239639
step: 200, loss: 0.044856876134872437
step: 210, loss: 0.12287580221891403
step: 220, loss: 0.017240742221474648
step: 230, loss: 0.08209654688835144
step: 240, loss: 0.08817422389984131
step: 250, loss: 0.12414062023162842
step: 260, loss: 0.13785320520401
step: 270, loss: 0.20441681146621704
step: 280, loss: 0.09881441295146942
step: 290, loss: 0.06061721593141556
step: 300, loss: 0.22807587683200836
step: 310, loss: 0.1632741391658783
step: 320, loss: 0.1215701773762703
step: 330, loss: 0.12214970588684082
epoch 2: dev_f1=0.7973273942093541, f1=0.7672413793103448, best_f1=0.7672413793103448
step: 0, loss: 0.12250760197639465
step: 10, loss: 0.0875459834933281
step: 20, loss: 0.1142193078994751
step: 30, loss: 0.10181587934494019
step: 40, loss: 0.146653950214386
step: 50, loss: 0.133804053068161
step: 60, loss: 0.29088664054870605
step: 70, loss: 0.4077187478542328
step: 80, loss: 0.08438538014888763
step: 90, loss: 0.049057990312576294
step: 100, loss: 0.20281675457954407
step: 110, loss: 0.0809856578707695
step: 120, loss: 0.031528159976005554
step: 130, loss: 0.0644204244017601
step: 140, loss: 0.049444779753685
step: 150, loss: 0.042263809591531754
step: 160, loss: 0.06388816982507706
step: 170, loss: 0.28937870264053345
step: 180, loss: 0.2530969977378845
step: 190, loss: 0.008517893962562084
step: 200, loss: 0.11222303658723831
step: 210, loss: 0.11906001716852188
step: 220, loss: 0.18594905734062195
step: 230, loss: 0.19187510013580322
step: 240, loss: 0.2025991827249527
step: 250, loss: 0.08603906631469727
step: 260, loss: 0.06615597009658813
step: 270, loss: 0.2072688490152359
step: 280, loss: 0.06861715018749237
step: 290, loss: 0.039073023945093155
step: 300, loss: 0.11649291217327118
step: 310, loss: 0.07546795159578323
step: 320, loss: 0.34542912244796753
step: 330, loss: 0.14383810758590698
epoch 3: dev_f1=0.7923627684964201, f1=0.7550561797752808, best_f1=0.7672413793103448
step: 0, loss: 0.13819682598114014
step: 10, loss: 0.010932661592960358
step: 20, loss: 0.04435960575938225
step: 30, loss: 0.13858845829963684
step: 40, loss: 0.07625643163919449
step: 50, loss: 0.04152669012546539
step: 60, loss: 0.07405192404985428
step: 70, loss: 0.08788157999515533
step: 80, loss: 0.007046939805150032
step: 90, loss: 0.04188725724816322
step: 100, loss: 0.06530936807394028
step: 110, loss: 0.08679670095443726
step: 120, loss: 0.10702405124902725
step: 130, loss: 0.14916999638080597
step: 140, loss: 0.08904808014631271
step: 150, loss: 0.12321341782808304
step: 160, loss: 0.09208957850933075
step: 170, loss: 0.12332566827535629
step: 180, loss: 0.09016988426446915
step: 190, loss: 0.08841007202863693
step: 200, loss: 0.09203237295150757
step: 210, loss: 0.10346971452236176
step: 220, loss: 0.11569676548242569
step: 230, loss: 0.10135617107152939
step: 240, loss: 0.07220504432916641
step: 250, loss: 0.05616794899106026
step: 260, loss: 0.12538249790668488
step: 270, loss: 0.31927910447120667
step: 280, loss: 0.11517858505249023
step: 290, loss: 0.08691027015447617
step: 300, loss: 0.2065071314573288
step: 310, loss: 0.06367865204811096
step: 320, loss: 0.14728383719921112
step: 330, loss: 0.04811488464474678
epoch 4: dev_f1=0.808888888888889, f1=0.7787234042553193, best_f1=0.7787234042553193
step: 0, loss: 0.08572271466255188
step: 10, loss: 0.06609492003917694
step: 20, loss: 0.07174079120159149
step: 30, loss: 0.14703655242919922
step: 40, loss: 0.08004778623580933
step: 50, loss: 0.07608351856470108
step: 60, loss: 0.10562139004468918
step: 70, loss: 0.21537154912948608
step: 80, loss: 0.10067756474018097
step: 90, loss: 0.02424217015504837
step: 100, loss: 0.11138387769460678
step: 110, loss: 0.04288342967629433
step: 120, loss: 0.13159960508346558
step: 130, loss: 0.07982489466667175
step: 140, loss: 0.11324004083871841
step: 150, loss: 0.05558926239609718
step: 160, loss: 0.12212876230478287
step: 170, loss: 0.04980594664812088
step: 180, loss: 0.31386324763298035
step: 190, loss: 0.03687796741724014
step: 200, loss: 0.08154027163982391
step: 210, loss: 0.11722143739461899
step: 220, loss: 0.0659697949886322
step: 230, loss: 0.12205758690834045
step: 240, loss: 0.09548749774694443
step: 250, loss: 0.10196015238761902
step: 260, loss: 0.07678283005952835
step: 270, loss: 0.05819603428244591
step: 280, loss: 0.1028699278831482
step: 290, loss: 0.09496373683214188
step: 300, loss: 0.10889440029859543
step: 310, loss: 0.11210785061120987
step: 320, loss: 0.24363836646080017
step: 330, loss: 0.09160378575325012
epoch 5: dev_f1=0.8263736263736263, f1=0.7829787234042553, best_f1=0.7829787234042553
step: 0, loss: 0.08240491151809692
step: 10, loss: 0.14240679144859314
step: 20, loss: 0.08115657418966293
step: 30, loss: 0.09078038483858109
step: 40, loss: 0.20301879942417145
step: 50, loss: 0.08347772061824799
step: 60, loss: 0.10694602876901627
step: 70, loss: 0.1298835575580597
step: 80, loss: 0.048713378608226776
step: 90, loss: 0.0004062270454596728
step: 100, loss: 0.1222163736820221
step: 110, loss: 0.06871786713600159
step: 120, loss: 0.10445164144039154
step: 130, loss: 0.09660248458385468
step: 140, loss: 0.13037070631980896
step: 150, loss: 0.01709195040166378
step: 160, loss: 0.20282666385173798
step: 170, loss: 0.1025117039680481
step: 180, loss: 0.09048384428024292
step: 190, loss: 0.13938944041728973
step: 200, loss: 0.11768762767314911
step: 210, loss: 0.12312373518943787
step: 220, loss: 0.05124187096953392
step: 230, loss: 0.14355409145355225
step: 240, loss: 0.048886384814977646
step: 250, loss: 0.12128588557243347
step: 260, loss: 0.0780067965388298
step: 270, loss: 0.05626513436436653
step: 280, loss: 0.08963129669427872
step: 290, loss: 0.08623720705509186
step: 300, loss: 0.06575050204992294
step: 310, loss: 0.061053112149238586
step: 320, loss: 0.1148018166422844
step: 330, loss: 0.04174989089369774
epoch 6: dev_f1=0.8062360801781738, f1=0.7850877192982455, best_f1=0.7829787234042553
step: 0, loss: 0.03857796639204025
step: 10, loss: 0.12906385958194733
step: 20, loss: 0.14078184962272644
step: 30, loss: 0.03864245116710663
step: 40, loss: 0.09754031896591187
step: 50, loss: 0.04238693788647652
step: 60, loss: 0.06786426901817322
step: 70, loss: 0.07754723727703094
step: 80, loss: 0.049112237989902496
step: 90, loss: 0.06191261112689972
step: 100, loss: 0.15491175651550293
step: 110, loss: 0.11940782517194748
step: 120, loss: 0.09776786714792252
step: 130, loss: 0.13761146366596222
step: 140, loss: 0.08294953405857086
step: 150, loss: 0.04074352979660034
step: 160, loss: 0.019531378522515297
step: 170, loss: 0.07404801994562149
step: 180, loss: 0.13556243479251862
step: 190, loss: 0.12016108632087708
step: 200, loss: 0.05548291280865669
step: 210, loss: 0.07666108012199402
step: 220, loss: 0.04369793459773064
step: 230, loss: 0.06570994108915329
step: 240, loss: 0.057808756828308105
step: 250, loss: 0.03527850657701492
step: 260, loss: 0.04543444514274597
step: 270, loss: 0.14780573546886444
step: 280, loss: 0.14907386898994446
step: 290, loss: 0.06101004034280777
step: 300, loss: 0.061777789145708084
step: 310, loss: 0.13753265142440796
step: 320, loss: 0.07527551800012589
step: 330, loss: 0.07337719202041626
epoch 7: dev_f1=0.8199052132701422, f1=0.7904761904761904, best_f1=0.7829787234042553
step: 0, loss: 0.0915309339761734
step: 10, loss: 0.24634699523448944
step: 20, loss: 0.0418880358338356
step: 30, loss: 0.09695751219987869
step: 40, loss: 0.15542952716350555
step: 50, loss: 0.07491019368171692
step: 60, loss: 0.146121546626091
step: 70, loss: 0.11281593888998032
step: 80, loss: 0.03814723715186119
step: 90, loss: 0.0996132418513298
step: 100, loss: 0.08591362088918686
step: 110, loss: 0.020708564668893814
step: 120, loss: 0.028392113745212555
step: 130, loss: 0.08777865767478943
step: 140, loss: 0.09672749042510986
step: 150, loss: 0.0482352077960968
step: 160, loss: 0.05064929649233818
step: 170, loss: 0.13663695752620697
step: 180, loss: 0.08826426416635513
step: 190, loss: 0.04376717656850815
step: 200, loss: 0.04961065202951431
step: 210, loss: 0.1091722771525383
step: 220, loss: 0.026206936687231064
step: 230, loss: 0.17422416806221008
step: 240, loss: 0.05295363813638687
step: 250, loss: 0.06641587615013123
step: 260, loss: 0.118479423224926
step: 270, loss: 0.06707528233528137
step: 280, loss: 0.1447959542274475
step: 290, loss: 0.09574555605649948
step: 300, loss: 0.059997569769620895
step: 310, loss: 0.11065586656332016
step: 320, loss: 0.06804890185594559
step: 330, loss: 0.09232017397880554
epoch 8: dev_f1=0.8177570093457943, f1=0.7924528301886793, best_f1=0.7829787234042553
step: 0, loss: 0.0835840031504631
step: 10, loss: 0.07735717296600342
step: 20, loss: 0.0749276727437973
step: 30, loss: 0.02345818281173706
step: 40, loss: 0.06894641369581223
step: 50, loss: 0.09176966547966003
step: 60, loss: 0.09833718836307526
step: 70, loss: 0.06224967539310455
step: 80, loss: 0.08859387785196304
step: 90, loss: 0.17454393208026886
step: 100, loss: 0.14431728422641754
step: 110, loss: 0.06780089437961578
step: 120, loss: 0.09242768585681915
step: 130, loss: 0.07370896637439728
step: 140, loss: 0.14481264352798462
step: 150, loss: 0.09736178070306778
step: 160, loss: 0.027082769200205803
step: 170, loss: 0.015697993338108063
step: 180, loss: 0.04886956140398979
step: 190, loss: 0.022594863548874855
step: 200, loss: 0.08713770657777786
step: 210, loss: 0.041291914880275726
step: 220, loss: 0.11729604750871658
step: 230, loss: 0.040177956223487854
step: 240, loss: 0.10655474662780762
step: 250, loss: 0.15485721826553345
step: 260, loss: 0.12507928907871246
step: 270, loss: 0.14407776296138763
step: 280, loss: 0.12725389003753662
step: 290, loss: 0.08787921071052551
step: 300, loss: 0.03588308393955231
step: 310, loss: 0.14970920979976654
step: 320, loss: 0.13804611563682556
step: 330, loss: 0.08470471948385239
epoch 9: dev_f1=0.819753086419753, f1=0.8118811881188118, best_f1=0.7829787234042553
step: 0, loss: 0.08205247670412064
step: 10, loss: 0.01890483871102333
step: 20, loss: 0.049321506172418594
step: 30, loss: 0.11727460473775864
step: 40, loss: 0.1107352152466774
step: 50, loss: 0.0001071090591722168
step: 60, loss: 0.09642726927995682
step: 70, loss: 0.11189541965723038
step: 80, loss: 0.08534903824329376
step: 90, loss: 0.10230147838592529
step: 100, loss: 0.13467971980571747
step: 110, loss: 0.04679051786661148
step: 120, loss: 0.08562915027141571
step: 130, loss: 0.15652652084827423
step: 140, loss: 0.04109957441687584
step: 150, loss: 0.0733005553483963
step: 160, loss: 0.1031409278512001
step: 170, loss: 0.029137426987290382
step: 180, loss: 0.12603770196437836
step: 190, loss: 0.09210233390331268
step: 200, loss: 0.09415844082832336
step: 210, loss: 0.021866269409656525
step: 220, loss: 0.052698783576488495
step: 230, loss: 0.08971596509218216
step: 240, loss: 0.08254524320363998
step: 250, loss: 0.050617367029190063
step: 260, loss: 0.07326474040746689
step: 270, loss: 0.14851103723049164
step: 280, loss: 0.05218678340315819
step: 290, loss: 0.08834216743707657
step: 300, loss: 0.10338088870048523
step: 310, loss: 0.06241793930530548
step: 320, loss: 0.09253425896167755
step: 330, loss: 0.08350183814764023
epoch 10: dev_f1=0.7780678851174935, f1=0.7638190954773869, best_f1=0.7829787234042553
step: 0, loss: 0.05091950297355652
step: 10, loss: 0.0602337121963501
step: 20, loss: 0.2365657091140747
step: 30, loss: 0.07021979242563248
step: 40, loss: 0.004157556686550379
step: 50, loss: 0.15724025666713715
step: 60, loss: 0.08744775503873825
step: 70, loss: 0.10459326952695847
step: 80, loss: 0.04016784951090813
step: 90, loss: 0.06015203520655632
step: 100, loss: 0.05081019178032875
step: 110, loss: 0.1603091061115265
step: 120, loss: 0.11005507409572601
step: 130, loss: 0.13983111083507538
step: 140, loss: 0.09693027287721634
step: 150, loss: 0.16460202634334564
step: 160, loss: 0.14721114933490753
step: 170, loss: 0.1040179505944252
step: 180, loss: 0.07065147161483765
step: 190, loss: 0.05449442192912102
step: 200, loss: 0.1826760172843933
step: 210, loss: 0.12497347593307495
step: 220, loss: 0.15358874201774597
step: 230, loss: 0.06075602397322655
step: 240, loss: 0.0768875926733017
step: 250, loss: 0.13044437766075134
step: 260, loss: 0.1381363421678543
step: 270, loss: 0.17071418464183807
step: 280, loss: 0.03435744717717171
step: 290, loss: 0.04581234231591225
step: 300, loss: 0.07472150772809982
step: 310, loss: 0.06908527761697769
step: 320, loss: 0.062421634793281555
step: 330, loss: 0.0703834816813469
epoch 11: dev_f1=0.8183807439824946, f1=0.806941431670282, best_f1=0.7829787234042553
step: 0, loss: 0.12025278061628342
step: 10, loss: 0.08251149952411652
step: 20, loss: 0.04010947421193123
step: 30, loss: 0.13202562928199768
step: 40, loss: 0.043311554938554764
step: 50, loss: 0.11767492443323135
step: 60, loss: 0.0395313985645771
step: 70, loss: 0.017659299075603485
step: 80, loss: 0.014202091842889786
step: 90, loss: 0.08643997460603714
step: 100, loss: 0.03785691410303116
step: 110, loss: 0.03926271200180054
step: 120, loss: 0.05261623486876488
step: 130, loss: 0.03823510557413101
step: 140, loss: 0.1723954677581787
step: 150, loss: 0.06308504939079285
step: 160, loss: 0.0870320275425911
step: 170, loss: 0.12492170184850693
step: 180, loss: 0.0750184953212738
step: 190, loss: 0.11185228824615479
step: 200, loss: 0.14700371026992798
step: 210, loss: 0.1142631322145462
step: 220, loss: 0.14365778863430023
step: 230, loss: 0.026036718860268593
step: 240, loss: 0.04478100687265396
step: 250, loss: 0.20073693990707397
step: 260, loss: 0.09194182604551315
step: 270, loss: 0.07379909604787827
step: 280, loss: 0.15655502676963806
step: 290, loss: 0.04232211410999298
step: 300, loss: 0.03276796266436577
step: 310, loss: 0.13628843426704407
step: 320, loss: 0.05952555686235428
step: 330, loss: 0.04744487255811691
epoch 12: dev_f1=0.8221153846153845, f1=0.815347721822542, best_f1=0.7829787234042553
step: 0, loss: 0.06653618812561035
step: 10, loss: 0.04203876107931137
step: 20, loss: 0.07442770898342133
step: 30, loss: 0.019575756043195724
step: 40, loss: 0.09493133425712585
step: 50, loss: 0.13762381672859192
step: 60, loss: 0.03627985715866089
step: 70, loss: 0.18925447762012482
step: 80, loss: 0.08616442233324051
step: 90, loss: 0.03511414676904678
step: 100, loss: 0.11538072675466537
step: 110, loss: 0.1697705239057541
step: 120, loss: 0.04650180786848068
step: 130, loss: 0.1076178029179573
step: 140, loss: 0.08388485014438629
step: 150, loss: 0.07353978604078293
step: 160, loss: 0.07578129321336746
step: 170, loss: 0.09775976091623306
step: 180, loss: 0.06425309181213379
step: 190, loss: 0.08033787459135056
step: 200, loss: 0.10722572356462479
step: 210, loss: 0.02120363339781761
step: 220, loss: 0.030098458752036095
step: 230, loss: 0.08191407471895218
step: 240, loss: 0.04280758649110794
step: 250, loss: 0.07612769305706024
step: 260, loss: 0.02831645868718624
step: 270, loss: 0.0756598636507988
step: 280, loss: 0.03749430179595947
step: 290, loss: 0.13666093349456787
step: 300, loss: 0.14431731402873993
step: 310, loss: 0.16293419897556305
step: 320, loss: 0.04196071997284889
step: 330, loss: 0.024626823142170906
epoch 13: dev_f1=0.8368794326241136, f1=0.8101851851851851, best_f1=0.8101851851851851
step: 0, loss: 0.05996868014335632
step: 10, loss: 0.1073012501001358
step: 20, loss: 0.133549764752388
step: 30, loss: 0.14252495765686035
step: 40, loss: 0.10004165023565292
step: 50, loss: 0.05925324186682701
step: 60, loss: 0.09867057204246521
step: 70, loss: 0.04278260096907616
step: 80, loss: 0.08743254095315933
step: 90, loss: 0.03765961155295372
step: 100, loss: 0.059103045612573624
step: 110, loss: 0.09912461787462234
step: 120, loss: 0.10435909032821655
step: 130, loss: 0.00011159605492139235
step: 140, loss: 0.22114238142967224
step: 150, loss: 0.12032856792211533
step: 160, loss: 0.13520219922065735
step: 170, loss: 0.13007736206054688
step: 180, loss: 0.08228102326393127
step: 190, loss: 0.04330509528517723
step: 200, loss: 0.06043895706534386
step: 210, loss: 0.12214749306440353
step: 220, loss: 0.11907380819320679
step: 230, loss: 0.04078183323144913
step: 240, loss: 0.1131238043308258
step: 250, loss: 0.10521138459444046
step: 260, loss: 0.08863817155361176
step: 270, loss: 0.04927956312894821
step: 280, loss: 0.08453460782766342
step: 290, loss: 0.09120767563581467
step: 300, loss: 0.06658267974853516
step: 310, loss: 0.14465875923633575
step: 320, loss: 0.11010932922363281
step: 330, loss: 0.035296712070703506
epoch 14: dev_f1=0.8329411764705882, f1=0.8075117370892019, best_f1=0.8101851851851851
step: 0, loss: 0.06981613487005234
step: 10, loss: 0.07106994837522507
step: 20, loss: 0.03151268512010574
step: 30, loss: 0.06144136190414429
step: 40, loss: 0.09350020438432693
step: 50, loss: 0.07767864316701889
step: 60, loss: 0.006953503470867872
step: 70, loss: 0.07827737927436829
step: 80, loss: 0.10173405706882477
step: 90, loss: 0.0823512151837349
step: 100, loss: 6.606421084143221e-05
step: 110, loss: 0.10243237018585205
step: 120, loss: 0.05220338702201843
step: 130, loss: 0.08598336577415466
step: 140, loss: 0.08840043097734451
step: 150, loss: 0.04007892683148384
step: 160, loss: 0.08410493284463882
step: 170, loss: 0.000949149311054498
step: 180, loss: 0.047265198081731796
step: 190, loss: 0.023038426414132118
step: 200, loss: 0.07039889693260193
step: 210, loss: 0.08612094819545746
step: 220, loss: 0.09545040875673294
step: 230, loss: 0.11916586756706238
step: 240, loss: 0.12378889322280884
step: 250, loss: 0.07177667319774628
step: 260, loss: 0.14562426507472992
step: 270, loss: 0.05393749475479126
step: 280, loss: 0.13960903882980347
step: 290, loss: 0.12389713525772095
step: 300, loss: 0.08448833972215652
step: 310, loss: 0.07194258272647858
step: 320, loss: 0.026346944272518158
step: 330, loss: 0.06988216936588287
epoch 15: dev_f1=0.8264840182648402, f1=0.8165137614678899, best_f1=0.8101851851851851
step: 0, loss: 0.04687748849391937
step: 10, loss: 0.08804455399513245
step: 20, loss: 0.05403940752148628
step: 30, loss: 0.08218298852443695
step: 40, loss: 0.062125589698553085
step: 50, loss: 0.06481585651636124
step: 60, loss: 0.035725660622119904
step: 70, loss: 0.015080435201525688
step: 80, loss: 0.03139452263712883
step: 90, loss: 0.09714416414499283
step: 100, loss: 0.02636147104203701
step: 110, loss: 0.070538230240345
step: 120, loss: 0.0822705626487732
step: 130, loss: 0.056929364800453186
step: 140, loss: 0.0488722138106823
step: 150, loss: 0.10110002756118774
step: 160, loss: 0.1081889197230339
step: 170, loss: 0.05984001234173775
step: 180, loss: 0.06539785116910934
step: 190, loss: 0.08640367537736893
step: 200, loss: 0.08592770993709564
step: 210, loss: 0.026663538068532944
step: 220, loss: 0.12016250938177109
step: 230, loss: 0.11722145974636078
step: 240, loss: 0.035076748579740524
step: 250, loss: 0.12483174353837967
step: 260, loss: 0.03130344673991203
step: 270, loss: 0.07129820436239243
step: 280, loss: 0.08228857070207596
step: 290, loss: 0.14346323907375336
step: 300, loss: 0.03574250265955925
step: 310, loss: 0.056066595017910004
step: 320, loss: 0.05343114212155342
step: 330, loss: 0.08386313170194626
epoch 16: dev_f1=0.8288288288288289, f1=0.8200455580865603, best_f1=0.8101851851851851
step: 0, loss: 0.08898916840553284
step: 10, loss: 0.05218363180756569
step: 20, loss: 0.028023285791277885
step: 30, loss: 0.06887387484312057
step: 40, loss: 0.06686893850564957
step: 50, loss: 0.13698622584342957
step: 60, loss: 0.09648118168115616
step: 70, loss: 0.13396327197551727
step: 80, loss: 0.07377943396568298
step: 90, loss: 0.030209345743060112
step: 100, loss: 0.020562905818223953
step: 110, loss: 0.09101085364818573
step: 120, loss: 0.05626475065946579
step: 130, loss: 0.08367077261209488
step: 140, loss: 0.09654776751995087
step: 150, loss: 0.09601740539073944
step: 160, loss: 0.0162236075848341
step: 170, loss: 0.1084260419011116
step: 180, loss: 0.07369258254766464
step: 190, loss: 4.9071422836277634e-05
step: 200, loss: 0.05696931108832359
step: 210, loss: 0.06266381591558456
step: 220, loss: 0.1484169065952301
step: 230, loss: 0.07862492650747299
step: 240, loss: 0.08412458002567291
step: 250, loss: 0.09767031669616699
step: 260, loss: 0.09716422110795975
step: 270, loss: 0.0663892924785614
step: 280, loss: 0.014470198191702366
step: 290, loss: 0.06516849249601364
step: 300, loss: 0.1594986617565155
step: 310, loss: 0.047341905534267426
step: 320, loss: 0.06101139262318611
step: 330, loss: 0.06915605813264847
epoch 17: dev_f1=0.832535885167464, f1=0.8057553956834533, best_f1=0.8101851851851851
step: 0, loss: 0.07589065283536911
step: 10, loss: 0.025210775434970856
step: 20, loss: 0.00546735804527998
step: 30, loss: 0.12589865922927856
step: 40, loss: 0.01777198165655136
step: 50, loss: 0.08381016552448273
step: 60, loss: 0.07933110743761063
step: 70, loss: 0.08229206502437592
step: 80, loss: 0.07494641840457916
step: 90, loss: 0.07029914110898972
step: 100, loss: 0.04737190157175064
step: 110, loss: 0.10534001886844635
step: 120, loss: 0.050542157143354416
step: 130, loss: 0.10816167294979095
step: 140, loss: 0.08381739258766174
step: 150, loss: 0.100594662129879
step: 160, loss: 0.026462111622095108
step: 170, loss: 0.15969926118850708
step: 180, loss: 0.022439323365688324
step: 190, loss: 0.040164798498153687
step: 200, loss: 0.08646365255117416
step: 210, loss: 0.10257745534181595
step: 220, loss: 0.05858742818236351
step: 230, loss: 0.04458389803767204
step: 240, loss: 0.05343449488282204
step: 250, loss: 0.12024916708469391
step: 260, loss: 0.049101416021585464
step: 270, loss: 0.14176402986049652
step: 280, loss: 0.09481481462717056
step: 290, loss: 0.06391114741563797
step: 300, loss: 0.042660605162382126
step: 310, loss: 0.04476241022348404
step: 320, loss: 0.053967174142599106
step: 330, loss: 0.037212323397397995
epoch 18: dev_f1=0.8256880733944955, f1=0.8018648018648018, best_f1=0.8101851851851851
step: 0, loss: 0.10622189193964005
step: 10, loss: 0.09459418058395386
step: 20, loss: 0.07271257787942886
step: 30, loss: 0.012912428006529808
step: 40, loss: 0.07941951602697372
step: 50, loss: 0.058737676590681076
step: 60, loss: 0.142024427652359
step: 70, loss: 0.11512432992458344
step: 80, loss: 0.08690096437931061
step: 90, loss: 0.00021727375860791653
step: 100, loss: 0.04264284670352936
step: 110, loss: 0.02921680547297001
step: 120, loss: 0.10527211427688599
step: 130, loss: 0.04912147298455238
step: 140, loss: 0.04316646605730057
step: 150, loss: 0.054944463074207306
step: 160, loss: 0.09914819151163101
step: 170, loss: 0.009545172564685345
step: 180, loss: 0.024649113416671753
step: 190, loss: 0.08546880632638931
step: 200, loss: 0.08545558899641037
step: 210, loss: 0.07626694440841675
step: 220, loss: 0.0480094775557518
step: 230, loss: 0.08628671616315842
step: 240, loss: 0.06417781859636307
step: 250, loss: 0.15243981778621674
step: 260, loss: 0.02636491134762764
step: 270, loss: 0.13736675679683685
step: 280, loss: 0.042999267578125
step: 290, loss: 0.06973040103912354
step: 300, loss: 0.02541881427168846
step: 310, loss: 0.08686526119709015
step: 320, loss: 0.07538841664791107
step: 330, loss: 0.03455338254570961
epoch 19: dev_f1=0.8260869565217391, f1=0.7971014492753623, best_f1=0.8101851851851851
step: 0, loss: 0.04457272216677666
step: 10, loss: 0.06911391019821167
step: 20, loss: 0.09746292233467102
step: 30, loss: 0.07976868003606796
step: 40, loss: 0.09021732211112976
step: 50, loss: 0.07741473615169525
step: 60, loss: 0.07900384068489075
step: 70, loss: 0.08304127305746078
step: 80, loss: 0.019527431577444077
step: 90, loss: 0.06489035487174988
step: 100, loss: 0.03067503124475479
step: 110, loss: 0.05748129263520241
step: 120, loss: 0.0920538380742073
step: 130, loss: 0.07469573616981506
step: 140, loss: 0.030469860881567
step: 150, loss: 0.026842867955565453
step: 160, loss: 0.13683779537677765
step: 170, loss: 0.06063917651772499
step: 180, loss: 0.0715811476111412
step: 190, loss: 0.07101024687290192
step: 200, loss: 0.034108661115169525
step: 210, loss: 0.0774998590350151
step: 220, loss: 0.07988404482603073
step: 230, loss: 0.07374521344900131
step: 240, loss: 0.07718852162361145
step: 250, loss: 0.13978040218353271
step: 260, loss: 0.10531724989414215
step: 270, loss: 0.023364605382084846
step: 280, loss: 0.008694227784872055
step: 290, loss: 0.08570284396409988
step: 300, loss: 0.22028285264968872
step: 310, loss: 0.017215147614479065
step: 320, loss: 0.028699420392513275
step: 330, loss: 0.04139620438218117
epoch 20: dev_f1=0.827250608272506, f1=0.7961165048543688, best_f1=0.8101851851851851
