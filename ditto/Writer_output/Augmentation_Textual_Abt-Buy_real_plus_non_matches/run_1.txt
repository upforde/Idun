cuda
Device: cuda
step: 0, loss: 0.6701616644859314
step: 10, loss: 0.41946226358413696
step: 20, loss: 0.07377757877111435
step: 30, loss: 0.12992355227470398
step: 40, loss: 0.24836035072803497
step: 50, loss: 0.07563818246126175
step: 60, loss: 0.23196251690387726
step: 70, loss: 0.1439346969127655
step: 80, loss: 0.23650142550468445
step: 90, loss: 0.23239322006702423
step: 100, loss: 0.07973343133926392
step: 110, loss: 0.2433442622423172
step: 120, loss: 0.12829864025115967
step: 130, loss: 0.29219213128089905
step: 140, loss: 0.040735889226198196
step: 150, loss: 0.2512400448322296
step: 160, loss: 0.1585269272327423
step: 170, loss: 0.19695018231868744
step: 180, loss: 0.28173643350601196
step: 190, loss: 0.19570104777812958
step: 200, loss: 0.13082581758499146
step: 210, loss: 0.2131199687719345
step: 220, loss: 0.1830078661441803
step: 230, loss: 0.07893362641334534
step: 240, loss: 0.19822688400745392
step: 250, loss: 0.17115852236747742
step: 260, loss: 0.14041085541248322
step: 270, loss: 0.16725870966911316
step: 280, loss: 0.11775422841310501
step: 290, loss: 0.09934934228658676
step: 300, loss: 0.2724665105342865
step: 310, loss: 0.1430196911096573
step: 320, loss: 0.19703122973442078
step: 330, loss: 0.08846266567707062
epoch 1: dev_f1=0.7015945330296127, f1=0.7402597402597403, best_f1=0.7402597402597403
step: 0, loss: 0.19427205622196198
step: 10, loss: 0.07544787973165512
step: 20, loss: 0.07931530475616455
step: 30, loss: 0.1536017656326294
step: 40, loss: 0.2351755052804947
step: 50, loss: 0.07581990212202072
step: 60, loss: 0.05165508762001991
step: 70, loss: 0.17498761415481567
step: 80, loss: 0.09285163879394531
step: 90, loss: 0.28307974338531494
step: 100, loss: 0.07537505775690079
step: 110, loss: 0.015811802819371223
step: 120, loss: 0.05969050154089928
step: 130, loss: 0.04496204853057861
step: 140, loss: 0.03423161432147026
step: 150, loss: 0.039084527641534805
step: 160, loss: 0.1897733509540558
step: 170, loss: 0.15520747005939484
step: 180, loss: 0.09918474406003952
step: 190, loss: 0.13269856572151184
step: 200, loss: 0.18626011908054352
step: 210, loss: 0.11599468439817429
step: 220, loss: 0.109006367623806
step: 230, loss: 0.31810951232910156
step: 240, loss: 0.09578052163124084
step: 250, loss: 0.06995341926813126
step: 260, loss: 0.13890913128852844
step: 270, loss: 0.1609582006931305
step: 280, loss: 0.13336730003356934
step: 290, loss: 0.16350369155406952
step: 300, loss: 0.1035187616944313
step: 310, loss: 0.06365993618965149
step: 320, loss: 0.1277187466621399
step: 330, loss: 0.07316762208938599
epoch 2: dev_f1=0.6773547094188377, f1=0.6600790513833993, best_f1=0.7402597402597403
step: 0, loss: 0.14816385507583618
step: 10, loss: 0.08033614605665207
step: 20, loss: 0.12175028771162033
step: 30, loss: 0.05788412690162659
step: 40, loss: 0.13059179484844208
step: 50, loss: 0.10194496810436249
step: 60, loss: 0.047805506736040115
step: 70, loss: 0.09143088012933731
step: 80, loss: 0.10741809010505676
step: 90, loss: 0.10290900617837906
step: 100, loss: 0.09385894984006882
step: 110, loss: 0.12275902926921844
step: 120, loss: 0.08766955882310867
step: 130, loss: 0.07562408596277237
step: 140, loss: 0.03476646915078163
step: 150, loss: 0.10778459906578064
step: 160, loss: 0.05977443978190422
step: 170, loss: 0.0499005988240242
step: 180, loss: 0.15057189762592316
step: 190, loss: 0.10363523662090302
step: 200, loss: 0.06784246861934662
step: 210, loss: 0.029088355600833893
step: 220, loss: 0.07805343717336655
step: 230, loss: 0.1663518100976944
step: 240, loss: 0.14541608095169067
step: 250, loss: 0.1396985501050949
step: 260, loss: 0.10221011191606522
step: 270, loss: 0.09358806908130646
step: 280, loss: 0.15969090163707733
step: 290, loss: 0.0648384764790535
step: 300, loss: 0.40619945526123047
step: 310, loss: 0.05249932408332825
step: 320, loss: 0.16775768995285034
step: 330, loss: 0.23492638766765594
epoch 3: dev_f1=0.8144796380090498, f1=0.7829977628635346, best_f1=0.7829977628635346
step: 0, loss: 0.08229583501815796
step: 10, loss: 0.06448684632778168
step: 20, loss: 0.07651396095752716
step: 30, loss: 0.09367667138576508
step: 40, loss: 0.22865030169487
step: 50, loss: 0.1037212610244751
step: 60, loss: 0.03136347606778145
step: 70, loss: 0.025189362466335297
step: 80, loss: 0.35115864872932434
step: 90, loss: 0.0828561931848526
step: 100, loss: 0.029062610119581223
step: 110, loss: 0.14530684053897858
step: 120, loss: 0.14846886694431305
step: 130, loss: 0.1379782110452652
step: 140, loss: 0.09201055765151978
step: 150, loss: 0.14658448100090027
step: 160, loss: 0.058032404631376266
step: 170, loss: 0.15257608890533447
step: 180, loss: 0.1244678646326065
step: 190, loss: 0.05353975668549538
step: 200, loss: 0.10327588766813278
step: 210, loss: 0.10579971969127655
step: 220, loss: 0.12387309968471527
step: 230, loss: 0.1729625165462494
step: 240, loss: 0.26083821058273315
step: 250, loss: 0.07867170125246048
step: 260, loss: 0.17967693507671356
step: 270, loss: 0.11385615915060043
step: 280, loss: 0.1460597664117813
step: 290, loss: 0.20773309469223022
step: 300, loss: 0.11364156752824783
step: 310, loss: 0.15420523285865784
step: 320, loss: 0.04955175518989563
step: 330, loss: 0.19998717308044434
epoch 4: dev_f1=0.8106796116504854, f1=0.786206896551724, best_f1=0.7829977628635346
step: 0, loss: 0.16196370124816895
step: 10, loss: 0.13925719261169434
step: 20, loss: 0.07711327075958252
step: 30, loss: 0.1618913859128952
step: 40, loss: 0.080530546605587
step: 50, loss: 0.1451498121023178
step: 60, loss: 0.08211502432823181
step: 70, loss: 0.10092437267303467
step: 80, loss: 0.052827805280685425
step: 90, loss: 0.09559318423271179
step: 100, loss: 0.10778869688510895
step: 110, loss: 0.1036633774638176
step: 120, loss: 0.09949647635221481
step: 130, loss: 0.10606162250041962
step: 140, loss: 0.18255457282066345
step: 150, loss: 0.20869167149066925
step: 160, loss: 0.10012034326791763
step: 170, loss: 0.07453712821006775
step: 180, loss: 0.08491592854261398
step: 190, loss: 0.09850983321666718
step: 200, loss: 0.09435006231069565
step: 210, loss: 0.03729253262281418
step: 220, loss: 0.24416665732860565
step: 230, loss: 0.09536217898130417
step: 240, loss: 0.03570512309670448
step: 250, loss: 0.09695852547883987
step: 260, loss: 0.12128225713968277
step: 270, loss: 0.10295920073986053
step: 280, loss: 0.12973009049892426
step: 290, loss: 0.08803211897611618
step: 300, loss: 0.024057429283857346
step: 310, loss: 0.1241372674703598
step: 320, loss: 0.07540174573659897
step: 330, loss: 0.05357948690652847
epoch 5: dev_f1=0.8026607538802661, f1=0.7708779443254817, best_f1=0.7829977628635346
step: 0, loss: 0.09480571001768112
step: 10, loss: 0.19275793433189392
step: 20, loss: 0.12093076854944229
step: 30, loss: 0.04386343061923981
step: 40, loss: 0.30768081545829773
step: 50, loss: 0.0806269571185112
step: 60, loss: 0.07046449929475784
step: 70, loss: 0.06756515055894852
step: 80, loss: 0.06817460805177689
step: 90, loss: 0.08770009130239487
step: 100, loss: 0.17788782715797424
step: 110, loss: 0.06639430671930313
step: 120, loss: 0.141217902302742
step: 130, loss: 0.0047082300297915936
step: 140, loss: 0.05556662753224373
step: 150, loss: 0.07539346814155579
step: 160, loss: 0.06515846401453018
step: 170, loss: 0.11066911369562149
step: 180, loss: 0.07432425022125244
step: 190, loss: 0.08088410645723343
step: 200, loss: 0.14980736374855042
step: 210, loss: 0.06948893517255783
step: 220, loss: 0.12550371885299683
step: 230, loss: 0.07530393451452255
step: 240, loss: 0.03651272505521774
step: 250, loss: 0.07361237704753876
step: 260, loss: 0.11542292684316635
step: 270, loss: 0.05599112808704376
step: 280, loss: 0.09053456038236618
step: 290, loss: 0.15876466035842896
step: 300, loss: 0.14475254714488983
step: 310, loss: 0.07501548528671265
step: 320, loss: 0.10750602930784225
step: 330, loss: 0.06214955449104309
epoch 6: dev_f1=0.8144796380090498, f1=0.7876106194690266, best_f1=0.7829977628635346
step: 0, loss: 0.0393882654607296
step: 10, loss: 0.07371187955141068
step: 20, loss: 0.11636149138212204
step: 30, loss: 0.10036890208721161
step: 40, loss: 0.14566755294799805
step: 50, loss: 0.1870747208595276
step: 60, loss: 0.09959247708320618
step: 70, loss: 0.181344673037529
step: 80, loss: 0.06757107377052307
step: 90, loss: 0.05036909505724907
step: 100, loss: 0.051100172102451324
step: 110, loss: 0.06259257346391678
step: 120, loss: 0.13580280542373657
step: 130, loss: 0.21195463836193085
step: 140, loss: 0.1481194794178009
step: 150, loss: 0.1038752868771553
step: 160, loss: 0.08171898871660233
step: 170, loss: 0.11652836203575134
step: 180, loss: 0.11510784924030304
step: 190, loss: 0.06466031819581985
step: 200, loss: 0.0853651911020279
step: 210, loss: 0.057690445333719254
step: 220, loss: 0.10640787333250046
step: 230, loss: 0.1288110315799713
step: 240, loss: 0.06185535341501236
step: 250, loss: 0.09069829434156418
step: 260, loss: 0.12323778867721558
step: 270, loss: 0.02564145252108574
step: 280, loss: 0.021393848583102226
step: 290, loss: 0.10757358372211456
step: 300, loss: 0.058530084788799286
step: 310, loss: 0.094525046646595
step: 320, loss: 0.021349582821130753
step: 330, loss: 0.18674251437187195
epoch 7: dev_f1=0.8091954022988505, f1=0.7946428571428571, best_f1=0.7829977628635346
step: 0, loss: 0.028523465618491173
step: 10, loss: 0.12478126585483551
step: 20, loss: 0.15287503600120544
step: 30, loss: 0.12817272543907166
step: 40, loss: 0.09204257279634476
step: 50, loss: 0.06827598065137863
step: 60, loss: 0.10308658331632614
step: 70, loss: 0.1080966666340828
step: 80, loss: 0.08487236499786377
step: 90, loss: 0.21034136414527893
step: 100, loss: 0.088722825050354
step: 110, loss: 0.05748584866523743
step: 120, loss: 0.0977802649140358
step: 130, loss: 0.0706724151968956
step: 140, loss: 0.07675516605377197
step: 150, loss: 0.11906752735376358
step: 160, loss: 0.05933840572834015
step: 170, loss: 0.06688743829727173
step: 180, loss: 0.07030168920755386
step: 190, loss: 0.09851987659931183
step: 200, loss: 0.11028736084699631
step: 210, loss: 0.142649307847023
step: 220, loss: 0.02361123077571392
step: 230, loss: 0.1752895563840866
step: 240, loss: 0.07830391824245453
step: 250, loss: 0.07362556457519531
step: 260, loss: 0.14056849479675293
step: 270, loss: 0.08075889199972153
step: 280, loss: 0.14973369240760803
step: 290, loss: 0.1731880009174347
step: 300, loss: 0.20070333778858185
step: 310, loss: 0.02552339807152748
step: 320, loss: 0.07001145929098129
step: 330, loss: 0.06023556739091873
epoch 8: dev_f1=0.828054298642534, f1=0.8203991130820399, best_f1=0.8203991130820399
step: 0, loss: 0.10352291911840439
step: 10, loss: 0.1308671534061432
step: 20, loss: 0.0013782476307824254
step: 30, loss: 0.11315599828958511
step: 40, loss: 0.10679595917463303
step: 50, loss: 0.08220822364091873
step: 60, loss: 0.14506110548973083
step: 70, loss: 0.13964501023292542
step: 80, loss: 0.13375498354434967
step: 90, loss: 0.09601975232362747
step: 100, loss: 0.06124720722436905
step: 110, loss: 0.20182722806930542
step: 120, loss: 0.07426568865776062
step: 130, loss: 0.1153336763381958
step: 140, loss: 0.0997200608253479
step: 150, loss: 0.04733328893780708
step: 160, loss: 0.06947621703147888
step: 170, loss: 0.12200293689966202
step: 180, loss: 0.09964974969625473
step: 190, loss: 0.055849622935056686
step: 200, loss: 0.10139990597963333
step: 210, loss: 0.17036226391792297
step: 220, loss: 0.029761971905827522
step: 230, loss: 0.07372815161943436
step: 240, loss: 0.15481629967689514
step: 250, loss: 0.1116001233458519
step: 260, loss: 0.1281864494085312
step: 270, loss: 0.10676959156990051
step: 280, loss: 0.055773038417100906
step: 290, loss: 0.0306872446089983
step: 300, loss: 0.03983388468623161
step: 310, loss: 0.12620890140533447
step: 320, loss: 0.10419340431690216
step: 330, loss: 0.09217923134565353
epoch 9: dev_f1=0.8240963855421687, f1=0.7819905213270142, best_f1=0.8203991130820399
step: 0, loss: 0.04887613281607628
step: 10, loss: 0.18005351722240448
step: 20, loss: 0.08377858996391296
step: 30, loss: 0.03401197865605354
step: 40, loss: 0.06306657195091248
step: 50, loss: 0.02798614278435707
step: 60, loss: 0.05405428260564804
step: 70, loss: 0.1714402586221695
step: 80, loss: 0.09165564924478531
step: 90, loss: 0.1003805547952652
step: 100, loss: 0.07278336584568024
step: 110, loss: 0.09696755558252335
step: 120, loss: 0.09722881019115448
step: 130, loss: 0.07781423628330231
step: 140, loss: 0.11638987064361572
step: 150, loss: 0.1081533282995224
step: 160, loss: 0.136758491396904
step: 170, loss: 0.08207647502422333
step: 180, loss: 0.06541314721107483
step: 190, loss: 0.10521559417247772
step: 200, loss: 0.054434746503829956
step: 210, loss: 0.1729266345500946
step: 220, loss: 0.06446526944637299
step: 230, loss: 0.043416641652584076
step: 240, loss: 0.06879972666501999
step: 250, loss: 0.06064946576952934
step: 260, loss: 0.2613159716129303
step: 270, loss: 0.047581449151039124
step: 280, loss: 0.0746748223900795
step: 290, loss: 0.07868634164333344
step: 300, loss: 0.051952946931123734
step: 310, loss: 0.126196026802063
step: 320, loss: 0.02189083769917488
step: 330, loss: 0.05432986095547676
epoch 10: dev_f1=0.8352668213457077, f1=0.7945823927765238, best_f1=0.7945823927765238
step: 0, loss: 0.030919373035430908
step: 10, loss: 0.11163973808288574
step: 20, loss: 0.07601505517959595
step: 30, loss: 0.1970919966697693
step: 40, loss: 0.11958010494709015
step: 50, loss: 0.07902860641479492
step: 60, loss: 0.04774130508303642
step: 70, loss: 0.04936298727989197
step: 80, loss: 0.04320535063743591
step: 90, loss: 0.08527515083551407
step: 100, loss: 0.03806695342063904
step: 110, loss: 0.1852339506149292
step: 120, loss: 0.058340054005384445
step: 130, loss: 0.10499372333288193
step: 140, loss: 0.08900036662817001
step: 150, loss: 0.07984915375709534
step: 160, loss: 0.03961845487356186
step: 170, loss: 0.1309490203857422
step: 180, loss: 0.06912770867347717
step: 190, loss: 0.09779740124940872
step: 200, loss: 0.056012775748968124
step: 210, loss: 0.11376558244228363
step: 220, loss: 0.10284370183944702
step: 230, loss: 0.12918628752231598
step: 240, loss: 0.062118567526340485
step: 250, loss: 0.10083981603384018
step: 260, loss: 0.03191491961479187
step: 270, loss: 0.1472141444683075
step: 280, loss: 0.16656138002872467
step: 290, loss: 0.04185688868165016
step: 300, loss: 0.12594656646251678
step: 310, loss: 0.05638118460774422
step: 320, loss: 0.005098898895084858
step: 330, loss: 0.11197377741336823
epoch 11: dev_f1=0.8382687927107061, f1=0.7982456140350878, best_f1=0.7982456140350878
step: 0, loss: 0.05441528186202049
step: 10, loss: 0.06153402850031853
step: 20, loss: 0.09692081063985825
step: 30, loss: 0.13636505603790283
step: 40, loss: 0.08252357691526413
step: 50, loss: 0.011935603804886341
step: 60, loss: 0.061730094254016876
step: 70, loss: 0.09371352195739746
step: 80, loss: 0.10612079501152039
step: 90, loss: 0.023306403309106827
step: 100, loss: 0.06577635556459427
step: 110, loss: 0.11885830014944077
step: 120, loss: 0.05661071836948395
step: 130, loss: 0.03910895437002182
step: 140, loss: 0.07734673470258713
step: 150, loss: 0.056381504982709885
step: 160, loss: 0.13442149758338928
step: 170, loss: 0.0684942752122879
step: 180, loss: 0.00017606702749617398
step: 190, loss: 0.10456551611423492
step: 200, loss: 0.09663787484169006
step: 210, loss: 0.06439781188964844
step: 220, loss: 0.07876209914684296
step: 230, loss: 0.0825766921043396
step: 240, loss: 0.06019531935453415
step: 250, loss: 0.08622957766056061
step: 260, loss: 0.07266371697187424
step: 270, loss: 0.1566115766763687
step: 280, loss: 0.06735123693943024
step: 290, loss: 0.058997295796871185
step: 300, loss: 0.14812372624874115
step: 310, loss: 0.13970650732517242
step: 320, loss: 0.06386753171682358
step: 330, loss: 0.05245186761021614
epoch 12: dev_f1=0.8262910798122066, f1=0.7908045977011493, best_f1=0.7982456140350878
step: 0, loss: 0.07305346429347992
step: 10, loss: 0.07525119185447693
step: 20, loss: 0.05238074064254761
step: 30, loss: 0.0460987389087677
step: 40, loss: 0.07384645938873291
step: 50, loss: 0.17882981896400452
step: 60, loss: 0.11285316199064255
step: 70, loss: 0.0706140324473381
step: 80, loss: 0.12330969423055649
step: 90, loss: 0.10593747347593307
step: 100, loss: 0.11045467853546143
step: 110, loss: 0.07163005322217941
step: 120, loss: 0.07858523726463318
step: 130, loss: 0.07423324882984161
step: 140, loss: 0.08735941350460052
step: 150, loss: 0.026487044990062714
step: 160, loss: 0.09149260818958282
step: 170, loss: 0.0863596722483635
step: 180, loss: 0.10222522169351578
step: 190, loss: 0.04501444846391678
step: 200, loss: 0.1623990833759308
step: 210, loss: 0.1408761590719223
step: 220, loss: 0.0280405692756176
step: 230, loss: 0.10838582366704941
step: 240, loss: 0.02138948068022728
step: 250, loss: 0.04759085550904274
step: 260, loss: 0.05640793964266777
step: 270, loss: 0.07898443937301636
step: 280, loss: 0.11408880352973938
step: 290, loss: 0.021370042115449905
step: 300, loss: 0.15783508121967316
step: 310, loss: 0.013891755603253841
step: 320, loss: 0.10777153074741364
step: 330, loss: 0.08891359716653824
epoch 13: dev_f1=0.821256038647343, f1=0.7867298578199052, best_f1=0.7982456140350878
step: 0, loss: 0.07636228203773499
step: 10, loss: 0.06509284675121307
step: 20, loss: 0.0663144513964653
step: 30, loss: 0.040110163390636444
step: 40, loss: 0.06874257326126099
step: 50, loss: 0.06960129737854004
step: 60, loss: 0.09164156764745712
step: 70, loss: 0.0322473868727684
step: 80, loss: 0.008215626701712608
step: 90, loss: 0.034862861037254333
step: 100, loss: 0.05288410186767578
step: 110, loss: 0.039099667221307755
step: 120, loss: 0.15737183392047882
step: 130, loss: 0.04570644721388817
step: 140, loss: 0.03181278333067894
step: 150, loss: 0.07603681832551956
step: 160, loss: 0.09524061530828476
step: 170, loss: 0.04777125269174576
step: 180, loss: 0.022704172879457474
step: 190, loss: 0.040741048753261566
step: 200, loss: 0.0642426609992981
step: 210, loss: 0.14921315014362335
step: 220, loss: 0.06856586039066315
step: 230, loss: 0.10987167805433273
step: 240, loss: 0.09816592186689377
step: 250, loss: 0.10815274715423584
step: 260, loss: 0.10688051581382751
step: 270, loss: 0.09519537538290024
step: 280, loss: 0.032113805413246155
step: 290, loss: 0.08795451372861862
step: 300, loss: 0.08953775465488434
step: 310, loss: 0.11446106433868408
step: 320, loss: 0.05256045237183571
step: 330, loss: 0.11814708262681961
epoch 14: dev_f1=0.8309178743961353, f1=0.7842227378190254, best_f1=0.7982456140350878
step: 0, loss: 0.0438997820019722
step: 10, loss: 0.11431445181369781
step: 20, loss: 0.1250966489315033
step: 30, loss: 0.033875949680805206
step: 40, loss: 0.03828512504696846
step: 50, loss: 0.12463981658220291
step: 60, loss: 0.024074286222457886
step: 70, loss: 0.07739754766225815
step: 80, loss: 0.07759741693735123
step: 90, loss: 0.04177352041006088
step: 100, loss: 0.0884925127029419
step: 110, loss: 0.03272325173020363
step: 120, loss: 0.02836853638291359
step: 130, loss: 0.21752822399139404
step: 140, loss: 0.1447775512933731
step: 150, loss: 0.08620612323284149
step: 160, loss: 0.05587153136730194
step: 170, loss: 0.06107664853334427
step: 180, loss: 0.11704985052347183
step: 190, loss: 0.12843027710914612
step: 200, loss: 0.048134855926036835
step: 210, loss: 0.04060570150613785
step: 220, loss: 0.16632205247879028
step: 230, loss: 0.013660362921655178
step: 240, loss: 0.04393008351325989
step: 250, loss: 0.03759763017296791
step: 260, loss: 0.1736336499452591
step: 270, loss: 0.03920387849211693
step: 280, loss: 0.022165559232234955
step: 290, loss: 0.12790220975875854
step: 300, loss: 0.03638822212815285
step: 310, loss: 0.11917936056852341
step: 320, loss: 0.15878205001354218
step: 330, loss: 0.07089102268218994
epoch 15: dev_f1=0.8365384615384616, f1=0.7952380952380952, best_f1=0.7982456140350878
step: 0, loss: 0.10195630043745041
step: 10, loss: 0.14217980206012726
step: 20, loss: 0.09632120281457901
step: 30, loss: 0.07369663566350937
step: 40, loss: 0.10832636803388596
step: 50, loss: 0.07403533905744553
step: 60, loss: 0.05531032755970955
step: 70, loss: 0.03678591921925545
step: 80, loss: 0.04787909984588623
step: 90, loss: 0.10631907731294632
step: 100, loss: 0.08237847685813904
step: 110, loss: 0.09950429946184158
step: 120, loss: 0.02692517265677452
step: 130, loss: 0.04791581258177757
step: 140, loss: 0.14110291004180908
step: 150, loss: 0.0834236741065979
step: 160, loss: 0.022878283634781837
step: 170, loss: 0.07564746588468552
step: 180, loss: 0.00024478326668031514
step: 190, loss: 0.0328240804374218
step: 200, loss: 0.08916965126991272
step: 210, loss: 0.10745516419410706
step: 220, loss: 0.16008855402469635
step: 230, loss: 0.08934711664915085
step: 240, loss: 0.17119517922401428
step: 250, loss: 0.049704477190971375
step: 260, loss: 0.03346700593829155
step: 270, loss: 0.05803734064102173
step: 280, loss: 0.20476141571998596
step: 290, loss: 0.05741075798869133
step: 300, loss: 0.021505646407604218
step: 310, loss: 0.05814589187502861
step: 320, loss: 0.07377886027097702
step: 330, loss: 0.08030654489994049
epoch 16: dev_f1=0.828235294117647, f1=0.7972350230414745, best_f1=0.7982456140350878
step: 0, loss: 0.10968462377786636
step: 10, loss: 0.09257716685533524
step: 20, loss: 0.07646466791629791
step: 30, loss: 0.07889820635318756
step: 40, loss: 0.19700361788272858
step: 50, loss: 0.06051250547170639
step: 60, loss: 0.013172652572393417
step: 70, loss: 0.09569168835878372
step: 80, loss: 0.054495856165885925
step: 90, loss: 0.1423375904560089
step: 100, loss: 0.07381292432546616
step: 110, loss: 0.0732116773724556
step: 120, loss: 0.041211843490600586
step: 130, loss: 0.037389691919088364
step: 140, loss: 0.07051896303892136
step: 150, loss: 0.024508975446224213
step: 160, loss: 0.06374157220125198
step: 170, loss: 0.08717656880617142
step: 180, loss: 0.1441601663827896
step: 190, loss: 0.01358623057603836
step: 200, loss: 0.05064241588115692
step: 210, loss: 0.07480870932340622
step: 220, loss: 0.024395273998379707
step: 230, loss: 0.03657059371471405
step: 240, loss: 0.027550216764211655
step: 250, loss: 0.03550201281905174
step: 260, loss: 0.03254234790802002
step: 270, loss: 0.03549949824810028
step: 280, loss: 0.03162511810660362
step: 290, loss: 0.05984446033835411
step: 300, loss: 0.04447542503476143
step: 310, loss: 0.11637535691261292
step: 320, loss: 0.026028811931610107
step: 330, loss: 0.0677909106016159
epoch 17: dev_f1=0.8289156626506025, f1=0.7961165048543688, best_f1=0.7982456140350878
step: 0, loss: 2.7312762540532276e-05
step: 10, loss: 0.14483721554279327
step: 20, loss: 0.0969911590218544
step: 30, loss: 0.0543573722243309
step: 40, loss: 0.08408991247415543
step: 50, loss: 0.17657573521137238
step: 60, loss: 0.04732617363333702
step: 70, loss: 0.1121337041258812
step: 80, loss: 0.05586615204811096
step: 90, loss: 0.12640537321567535
step: 100, loss: 6.999477045610547e-05
step: 110, loss: 0.06037738546729088
step: 120, loss: 0.04377632588148117
step: 130, loss: 0.05760398879647255
step: 140, loss: 0.052980270236730576
step: 150, loss: 0.055515825748443604
step: 160, loss: 0.030230192467570305
step: 170, loss: 0.054350290447473526
step: 180, loss: 4.3629028368741274e-05
step: 190, loss: 0.042143434286117554
step: 200, loss: 0.03542312607169151
step: 210, loss: 0.06311742961406708
step: 220, loss: 0.07875527441501617
step: 230, loss: 0.14042535424232483
step: 240, loss: 0.1095801591873169
step: 250, loss: 0.08465665578842163
step: 260, loss: 0.1437578797340393
step: 270, loss: 0.06318477541208267
step: 280, loss: 0.10324875265359879
step: 290, loss: 0.0250843558460474
step: 300, loss: 0.0692872554063797
step: 310, loss: 0.07702893763780594
step: 320, loss: 0.033576685935258865
step: 330, loss: 0.06884878128767014
epoch 18: dev_f1=0.83, f1=0.7950617283950617, best_f1=0.7982456140350878
step: 0, loss: 0.055978693068027496
step: 10, loss: 0.033319417387247086
step: 20, loss: 0.1255759447813034
step: 30, loss: 0.07665719091892242
step: 40, loss: 0.054028112441301346
step: 50, loss: 0.13740988075733185
step: 60, loss: 0.01773335598409176
step: 70, loss: 0.06910000741481781
step: 80, loss: 0.027528736740350723
step: 90, loss: 0.05921579897403717
step: 100, loss: 4.108672874281183e-05
step: 110, loss: 0.04618611931800842
step: 120, loss: 0.04902724176645279
step: 130, loss: 0.08333925157785416
step: 140, loss: 0.04542846232652664
step: 150, loss: 0.0806872695684433
step: 160, loss: 0.1457846611738205
step: 170, loss: 0.04530694708228111
step: 180, loss: 0.07144348323345184
step: 190, loss: 0.0731930062174797
step: 200, loss: 0.10179035365581512
step: 210, loss: 0.11051582545042038
step: 220, loss: 0.15098895132541656
step: 230, loss: 0.06213103234767914
step: 240, loss: 0.10472240298986435
step: 250, loss: 0.07521361112594604
step: 260, loss: 0.035109493881464005
step: 270, loss: 0.13731929659843445
step: 280, loss: 0.028745897114276886
step: 290, loss: 0.09037065505981445
step: 300, loss: 0.12783484160900116
step: 310, loss: 0.06463072448968887
step: 320, loss: 0.013175412081182003
step: 330, loss: 0.024485722184181213
epoch 19: dev_f1=0.823529411764706, f1=0.7919799498746868, best_f1=0.7982456140350878
step: 0, loss: 0.10978975147008896
step: 10, loss: 0.04610699415206909
step: 20, loss: 0.025752989575266838
step: 30, loss: 0.06538490206003189
step: 40, loss: 0.05273609235882759
step: 50, loss: 0.047763172537088394
step: 60, loss: 0.09215812385082245
step: 70, loss: 2.5092762371059507e-05
step: 80, loss: 0.09519341588020325
step: 90, loss: 0.13627023994922638
step: 100, loss: 0.05653694272041321
step: 110, loss: 0.09074915945529938
step: 120, loss: 0.07208271324634552
step: 130, loss: 0.07276193797588348
step: 140, loss: 0.05081770569086075
step: 150, loss: 3.025883597729262e-05
step: 160, loss: 0.05673421919345856
step: 170, loss: 0.03960401564836502
step: 180, loss: 0.07166877388954163
step: 190, loss: 0.026919391006231308
step: 200, loss: 0.08010157942771912
step: 210, loss: 0.0823073536157608
step: 220, loss: 0.02864154800772667
step: 230, loss: 0.020290745422244072
step: 240, loss: 0.07348077744245529
step: 250, loss: 0.018417436629533768
step: 260, loss: 0.02387109585106373
step: 270, loss: 0.03385234251618385
step: 280, loss: 0.04390794038772583
step: 290, loss: 0.052129488438367844
step: 300, loss: 0.08856505155563354
step: 310, loss: 0.05044586956501007
step: 320, loss: 0.018534818664193153
step: 330, loss: 0.11363308131694794
epoch 20: dev_f1=0.8201438848920863, f1=0.7980769230769231, best_f1=0.7982456140350878
