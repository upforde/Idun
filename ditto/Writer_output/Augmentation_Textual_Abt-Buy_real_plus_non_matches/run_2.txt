cuda
Device: cuda
step: 0, loss: 0.5080612897872925
step: 10, loss: 0.41325855255126953
step: 20, loss: 0.3300633430480957
step: 30, loss: 0.06479411572217941
step: 40, loss: 0.3349407911300659
step: 50, loss: 0.1797018051147461
step: 60, loss: 0.3310813903808594
step: 70, loss: 0.2381046861410141
step: 80, loss: 0.243010476231575
step: 90, loss: 0.22051435708999634
step: 100, loss: 0.03910957649350166
step: 110, loss: 0.22085754573345184
step: 120, loss: 0.3035794794559479
step: 130, loss: 0.08594181388616562
step: 140, loss: 0.4721664488315582
step: 150, loss: 0.23015637695789337
step: 160, loss: 0.13982753455638885
step: 170, loss: 0.34176790714263916
step: 180, loss: 0.4270099401473999
step: 190, loss: 0.16631998121738434
step: 200, loss: 0.05032221972942352
step: 210, loss: 0.42525777220726013
step: 220, loss: 0.3177873492240906
step: 230, loss: 0.02356920950114727
step: 240, loss: 0.11512289941310883
step: 250, loss: 0.2826544940471649
step: 260, loss: 0.24920114874839783
step: 270, loss: 0.12206754088401794
step: 280, loss: 0.21778233349323273
step: 290, loss: 0.16123731434345245
step: 300, loss: 0.1376170814037323
step: 310, loss: 0.22695797681808472
step: 320, loss: 0.26391690969467163
step: 330, loss: 0.06911324709653854
epoch 1: dev_f1=0.6575342465753424, f1=0.6682808716707023, best_f1=0.6682808716707023
step: 0, loss: 0.08113814145326614
step: 10, loss: 0.003015980590134859
step: 20, loss: 0.057110417634248734
step: 30, loss: 0.11446166783571243
step: 40, loss: 0.18876685202121735
step: 50, loss: 0.10248422622680664
step: 60, loss: 0.286859929561615
step: 70, loss: 0.13559718430042267
step: 80, loss: 0.10967984795570374
step: 90, loss: 0.2187575101852417
step: 100, loss: 0.08723881095647812
step: 110, loss: 0.14525073766708374
step: 120, loss: 0.0615544393658638
step: 130, loss: 0.12314631789922714
step: 140, loss: 0.12938833236694336
step: 150, loss: 0.1408565640449524
step: 160, loss: 0.18305976688861847
step: 170, loss: 0.2802407741546631
step: 180, loss: 0.02612224593758583
step: 190, loss: 0.10555015504360199
step: 200, loss: 0.15129217505455017
step: 210, loss: 0.056663285940885544
step: 220, loss: 0.13104401528835297
step: 230, loss: 0.06229867413640022
step: 240, loss: 0.07761149853467941
step: 250, loss: 0.2916918992996216
step: 260, loss: 0.10986568033695221
step: 270, loss: 0.058800872415304184
step: 280, loss: 0.10723339766263962
step: 290, loss: 0.21784764528274536
step: 300, loss: 0.0869632363319397
step: 310, loss: 0.24401655793190002
step: 320, loss: 0.02205239050090313
step: 330, loss: 0.12228544801473618
epoch 2: dev_f1=0.7608200455580866, f1=0.7424892703862661, best_f1=0.7424892703862661
step: 0, loss: 0.1307709962129593
step: 10, loss: 0.05793231353163719
step: 20, loss: 0.09893503040075302
step: 30, loss: 0.1002594456076622
step: 40, loss: 0.05351123958826065
step: 50, loss: 0.12551574409008026
step: 60, loss: 0.0743100494146347
step: 70, loss: 0.11811942607164383
step: 80, loss: 0.07877207547426224
step: 90, loss: 0.19994045794010162
step: 100, loss: 0.10680229216814041
step: 110, loss: 0.06966717541217804
step: 120, loss: 0.04118335247039795
step: 130, loss: 0.3477504849433899
step: 140, loss: 0.06394899636507034
step: 150, loss: 0.0020041645038872957
step: 160, loss: 0.18360374867916107
step: 170, loss: 0.12084569782018661
step: 180, loss: 0.1351446658372879
step: 190, loss: 0.1933990716934204
step: 200, loss: 0.15634244680404663
step: 210, loss: 0.13849669694900513
step: 220, loss: 0.028511708602309227
step: 230, loss: 0.15060272812843323
step: 240, loss: 0.10779068619012833
step: 250, loss: 0.15564067661762238
step: 260, loss: 0.07903926819562912
step: 270, loss: 0.14144697785377502
step: 280, loss: 0.10016971826553345
step: 290, loss: 0.1497478485107422
step: 300, loss: 0.07285834103822708
step: 310, loss: 0.13612601161003113
step: 320, loss: 0.32163798809051514
step: 330, loss: 0.1854570060968399
epoch 3: dev_f1=0.8064516129032259, f1=0.7660550458715597, best_f1=0.7660550458715597
step: 0, loss: 0.0853857696056366
step: 10, loss: 0.17290370166301727
step: 20, loss: 0.07187042385339737
step: 30, loss: 0.034068215638399124
step: 40, loss: 0.06262334436178207
step: 50, loss: 0.16771507263183594
step: 60, loss: 0.24764196574687958
step: 70, loss: 0.18770645558834076
step: 80, loss: 0.0800323411822319
step: 90, loss: 0.09302402287721634
step: 100, loss: 0.18041084706783295
step: 110, loss: 0.02740302123129368
step: 120, loss: 0.04667050391435623
step: 130, loss: 0.0909794420003891
step: 140, loss: 0.04879831150174141
step: 150, loss: 0.13011100888252258
step: 160, loss: 0.08124171197414398
step: 170, loss: 0.16460774838924408
step: 180, loss: 0.1171640008687973
step: 190, loss: 0.10189218819141388
step: 200, loss: 0.10678298026323318
step: 210, loss: 0.23634350299835205
step: 220, loss: 0.08806831389665604
step: 230, loss: 0.12402089685201645
step: 240, loss: 0.09763257205486298
step: 250, loss: 0.03421367332339287
step: 260, loss: 0.23330490291118622
step: 270, loss: 0.14925546944141388
step: 280, loss: 0.043746888637542725
step: 290, loss: 0.09784313291311264
step: 300, loss: 0.1317775398492813
step: 310, loss: 0.0232563316822052
step: 320, loss: 0.0660773292183876
step: 330, loss: 0.0800861343741417
epoch 4: dev_f1=0.8138528138528138, f1=0.7692307692307693, best_f1=0.7692307692307693
step: 0, loss: 0.07770391553640366
step: 10, loss: 0.12640494108200073
step: 20, loss: 0.1197836846113205
step: 30, loss: 0.0617002472281456
step: 40, loss: 0.17771272361278534
step: 50, loss: 0.03285089507699013
step: 60, loss: 0.04630694165825844
step: 70, loss: 0.08506152033805847
step: 80, loss: 0.10628825426101685
step: 90, loss: 0.04387510567903519
step: 100, loss: 0.11636777222156525
step: 110, loss: 0.08240287750959396
step: 120, loss: 0.09742383658885956
step: 130, loss: 0.12810426950454712
step: 140, loss: 0.06828933209180832
step: 150, loss: 0.060640040785074234
step: 160, loss: 0.19515372812747955
step: 170, loss: 0.10134349763393402
step: 180, loss: 0.1287509649991989
step: 190, loss: 0.00037886406062170863
step: 200, loss: 0.1285782754421234
step: 210, loss: 0.14742660522460938
step: 220, loss: 0.20943284034729004
step: 230, loss: 0.05719135329127312
step: 240, loss: 0.08831291645765305
step: 250, loss: 0.05984028801321983
step: 260, loss: 0.09369919449090958
step: 270, loss: 0.12850818037986755
step: 280, loss: 0.1681336611509323
step: 290, loss: 0.01644786447286606
step: 300, loss: 0.10298796743154526
step: 310, loss: 0.05103786662220955
step: 320, loss: 0.16873717308044434
step: 330, loss: 0.1417890042066574
epoch 5: dev_f1=0.8037383177570093, f1=0.8028169014084506, best_f1=0.7692307692307693
step: 0, loss: 0.06078364700078964
step: 10, loss: 0.05677424371242523
step: 20, loss: 0.07696650177240372
step: 30, loss: 0.05489988997578621
step: 40, loss: 0.10766693204641342
step: 50, loss: 0.10130432993173599
step: 60, loss: 0.057779375463724136
step: 70, loss: 0.19023823738098145
step: 80, loss: 0.18776996433734894
step: 90, loss: 0.07318409532308578
step: 100, loss: 0.00036826584255322814
step: 110, loss: 0.021276887506246567
step: 120, loss: 0.024577321484684944
step: 130, loss: 0.11887809634208679
step: 140, loss: 0.04847228154540062
step: 150, loss: 0.09131033718585968
step: 160, loss: 0.1020403504371643
step: 170, loss: 0.17830556631088257
step: 180, loss: 0.20294764637947083
step: 190, loss: 0.150533527135849
step: 200, loss: 0.09917383641004562
step: 210, loss: 0.07943637669086456
step: 220, loss: 0.1391724795103073
step: 230, loss: 0.08747059106826782
step: 240, loss: 0.052262548357248306
step: 250, loss: 0.12435014545917511
step: 260, loss: 0.0663890615105629
step: 270, loss: 0.08529221266508102
step: 280, loss: 0.10161423683166504
step: 290, loss: 0.011124982498586178
step: 300, loss: 0.07670564204454422
step: 310, loss: 0.14185985922813416
step: 320, loss: 0.21226102113723755
step: 330, loss: 0.12497621774673462
epoch 6: dev_f1=0.8226600985221675, f1=0.8, best_f1=0.8
step: 0, loss: 0.09181506931781769
step: 10, loss: 0.09775495529174805
step: 20, loss: 0.19563764333724976
step: 30, loss: 0.1594877392053604
step: 40, loss: 0.06498593837022781
step: 50, loss: 0.18166151642799377
step: 60, loss: 0.08787329494953156
step: 70, loss: 0.1584894359111786
step: 80, loss: 0.12999816238880157
step: 90, loss: 0.001566380262374878
step: 100, loss: 0.10702569037675858
step: 110, loss: 0.11056483536958694
step: 120, loss: 0.1334090679883957
step: 130, loss: 0.10810814797878265
step: 140, loss: 0.20653624832630157
step: 150, loss: 0.056345339864492416
step: 160, loss: 0.036472138017416
step: 170, loss: 0.06948763877153397
step: 180, loss: 0.04529106244444847
step: 190, loss: 0.0001582834665896371
step: 200, loss: 0.12971726059913635
step: 210, loss: 0.11953070014715195
step: 220, loss: 0.10045119374990463
step: 230, loss: 0.03400641679763794
step: 240, loss: 0.25621262192726135
step: 250, loss: 0.07578005641698837
step: 260, loss: 0.07136955112218857
step: 270, loss: 0.13422182202339172
step: 280, loss: 0.07698994129896164
step: 290, loss: 0.193780317902565
step: 300, loss: 0.041631583124399185
step: 310, loss: 0.02069520764052868
step: 320, loss: 0.17907798290252686
step: 330, loss: 0.0731191486120224
epoch 7: dev_f1=0.8129330254041571, f1=0.801781737193764, best_f1=0.8
step: 0, loss: 0.08457779884338379
step: 10, loss: 0.10849717259407043
step: 20, loss: 0.052900280803442
step: 30, loss: 0.0942799299955368
step: 40, loss: 0.14915721118450165
step: 50, loss: 0.036553554236888885
step: 60, loss: 0.07827147841453552
step: 70, loss: 0.10126769542694092
step: 80, loss: 0.1631508618593216
step: 90, loss: 0.10515938699245453
step: 100, loss: 0.08671826124191284
step: 110, loss: 0.05495908483862877
step: 120, loss: 0.11477002501487732
step: 130, loss: 0.09535891562700272
step: 140, loss: 0.07182539999485016
step: 150, loss: 0.06928174942731857
step: 160, loss: 0.0004986894782632589
step: 170, loss: 0.06444479525089264
step: 180, loss: 0.06189043074846268
step: 190, loss: 0.13178879022598267
step: 200, loss: 0.11009730398654938
step: 210, loss: 0.10634107887744904
step: 220, loss: 0.12892308831214905
step: 230, loss: 0.11689865589141846
step: 240, loss: 0.09930172562599182
step: 250, loss: 0.12006393074989319
step: 260, loss: 0.09768079966306686
step: 270, loss: 0.18119852244853973
step: 280, loss: 0.08013053238391876
step: 290, loss: 0.12254861742258072
step: 300, loss: 0.04292602092027664
step: 310, loss: 0.16594626009464264
step: 320, loss: 0.07526221126317978
step: 330, loss: 0.05949641019105911
epoch 8: dev_f1=0.8296296296296296, f1=0.8029556650246306, best_f1=0.8029556650246306
step: 0, loss: 0.12208288162946701
step: 10, loss: 0.07014632970094681
step: 20, loss: 0.09027774631977081
step: 30, loss: 0.08129320293664932
step: 40, loss: 0.019307851791381836
step: 50, loss: 0.06476440280675888
step: 60, loss: 0.07544147968292236
step: 70, loss: 0.10039350390434265
step: 80, loss: 0.05034990608692169
step: 90, loss: 0.06767695397138596
step: 100, loss: 0.25643202662467957
step: 110, loss: 0.07070157676935196
step: 120, loss: 0.09291120618581772
step: 130, loss: 0.19578447937965393
step: 140, loss: 0.1146528348326683
step: 150, loss: 9.482783207204193e-05
step: 160, loss: 0.10156756639480591
step: 170, loss: 0.05439642816781998
step: 180, loss: 0.05843425169587135
step: 190, loss: 0.1437395215034485
step: 200, loss: 0.14928707480430603
step: 210, loss: 0.20640955865383148
step: 220, loss: 0.13947823643684387
step: 230, loss: 0.09869235754013062
step: 240, loss: 0.05576782301068306
step: 250, loss: 0.1122613325715065
step: 260, loss: 0.14176471531391144
step: 270, loss: 0.12538614869117737
step: 280, loss: 0.07591823488473892
step: 290, loss: 0.05930859223008156
step: 300, loss: 0.07780637592077255
step: 310, loss: 0.051091086119413376
step: 320, loss: 0.024531079456210136
step: 330, loss: 0.13470464944839478
epoch 9: dev_f1=0.8137931034482758, f1=0.788546255506608, best_f1=0.8029556650246306
step: 0, loss: 0.061951447278261185
step: 10, loss: 0.05189220979809761
step: 20, loss: 0.08697440475225449
step: 30, loss: 0.1718885749578476
step: 40, loss: 0.10644364356994629
step: 50, loss: 0.10842326283454895
step: 60, loss: 0.06111444532871246
step: 70, loss: 0.06705005466938019
step: 80, loss: 0.030908335000276566
step: 90, loss: 0.09088387340307236
step: 100, loss: 0.13921311497688293
step: 110, loss: 0.3524644076824188
step: 120, loss: 0.02037244290113449
step: 130, loss: 0.022139020264148712
step: 140, loss: 0.08449976146221161
step: 150, loss: 0.09823097288608551
step: 160, loss: 0.25775977969169617
step: 170, loss: 0.08426883816719055
step: 180, loss: 0.11448784172534943
step: 190, loss: 0.06441326439380646
step: 200, loss: 0.024875082075595856
step: 210, loss: 0.10023379325866699
step: 220, loss: 0.1029914990067482
step: 230, loss: 0.1079452857375145
step: 240, loss: 0.0376950241625309
step: 250, loss: 0.10554186999797821
step: 260, loss: 0.06997861713171005
step: 270, loss: 0.08971293270587921
step: 280, loss: 0.024755259975790977
step: 290, loss: 0.07076060026884079
step: 300, loss: 0.14747171103954315
step: 310, loss: 0.11313746869564056
step: 320, loss: 0.041043490171432495
step: 330, loss: 0.1236489862203598
epoch 10: dev_f1=0.8067632850241547, f1=0.8132387706855791, best_f1=0.8029556650246306
step: 0, loss: 0.10682285577058792
step: 10, loss: 0.04768964648246765
step: 20, loss: 0.021088317036628723
step: 30, loss: 0.0774478018283844
step: 40, loss: 0.12423816323280334
step: 50, loss: 0.06695371866226196
step: 60, loss: 0.1260446459054947
step: 70, loss: 0.12813444435596466
step: 80, loss: 0.03216009959578514
step: 90, loss: 0.11154009401798248
step: 100, loss: 0.06542614102363586
step: 110, loss: 0.055643461644649506
step: 120, loss: 0.03386469930410385
step: 130, loss: 0.03245155140757561
step: 140, loss: 0.10436020791530609
step: 150, loss: 0.036672379821538925
step: 160, loss: 0.11212222278118134
step: 170, loss: 0.03290623798966408
step: 180, loss: 0.03212793171405792
step: 190, loss: 0.17613068222999573
step: 200, loss: 0.14451415836811066
step: 210, loss: 0.06723958253860474
step: 220, loss: 0.08584247529506683
step: 230, loss: 0.0383630208671093
step: 240, loss: 0.14250044524669647
step: 250, loss: 0.07613271474838257
step: 260, loss: 0.033988140523433685
step: 270, loss: 0.21644748747348785
step: 280, loss: 0.12414472550153732
step: 290, loss: 0.020332513377070427
step: 300, loss: 0.1614144891500473
step: 310, loss: 0.12887239456176758
step: 320, loss: 0.1227295845746994
step: 330, loss: 0.08173071593046188
epoch 11: dev_f1=0.803970223325062, f1=0.7823960880195598, best_f1=0.8029556650246306
step: 0, loss: 0.04578368365764618
step: 10, loss: 0.12686112523078918
step: 20, loss: 0.07904107123613358
step: 30, loss: 0.02537916600704193
step: 40, loss: 0.10770606994628906
step: 50, loss: 0.13442809879779816
step: 60, loss: 0.11282588541507721
step: 70, loss: 0.07615038007497787
step: 80, loss: 0.11431005597114563
step: 90, loss: 0.11731524765491486
step: 100, loss: 0.03545737639069557
step: 110, loss: 0.07678519934415817
step: 120, loss: 0.06097463518381119
step: 130, loss: 0.0504269115626812
step: 140, loss: 0.09725018590688705
step: 150, loss: 0.12300772964954376
step: 160, loss: 0.05042080581188202
step: 170, loss: 0.10291365534067154
step: 180, loss: 0.08094119280576706
step: 190, loss: 0.0640973374247551
step: 200, loss: 0.11303956061601639
step: 210, loss: 0.08118191361427307
step: 220, loss: 0.1364998072385788
step: 230, loss: 0.13855163753032684
step: 240, loss: 0.11925022304058075
step: 250, loss: 0.08581600338220596
step: 260, loss: 0.06837455928325653
step: 270, loss: 0.06237722560763359
step: 280, loss: 0.11090235412120819
step: 290, loss: 0.0626901239156723
step: 300, loss: 0.024457234889268875
step: 310, loss: 0.10291080921888351
step: 320, loss: 0.10935366153717041
step: 330, loss: 0.08821297436952591
epoch 12: dev_f1=0.8132387706855791, f1=0.8111888111888111, best_f1=0.8029556650246306
step: 0, loss: 0.1607372909784317
step: 10, loss: 0.0406004898250103
step: 20, loss: 0.08839531987905502
step: 30, loss: 0.12016767263412476
step: 40, loss: 0.06993982940912247
step: 50, loss: 0.1481793224811554
step: 60, loss: 0.06705974787473679
step: 70, loss: 0.11166613548994064
step: 80, loss: 0.0488867349922657
step: 90, loss: 0.08483930677175522
step: 100, loss: 0.10241059213876724
step: 110, loss: 0.05550060421228409
step: 120, loss: 0.06493189930915833
step: 130, loss: 0.07647702842950821
step: 140, loss: 6.007681804476306e-05
step: 150, loss: 0.050082892179489136
step: 160, loss: 0.14016512036323547
step: 170, loss: 0.07858879864215851
step: 180, loss: 0.0879596471786499
step: 190, loss: 0.07015610486268997
step: 200, loss: 0.02039879746735096
step: 210, loss: 0.09093722701072693
step: 220, loss: 0.017407912760972977
step: 230, loss: 0.14406758546829224
step: 240, loss: 0.15231961011886597
step: 250, loss: 0.0663275420665741
step: 260, loss: 0.07937134802341461
step: 270, loss: 0.10265175253152847
step: 280, loss: 0.047310151159763336
step: 290, loss: 0.08136556297540665
step: 300, loss: 0.018950914964079857
step: 310, loss: 0.14475589990615845
step: 320, loss: 0.04498853534460068
step: 330, loss: 0.11820748448371887
epoch 13: dev_f1=0.8229885057471265, f1=0.7999999999999999, best_f1=0.8029556650246306
step: 0, loss: 0.0689835250377655
step: 10, loss: 0.10503195971250534
step: 20, loss: 0.10421020537614822
step: 30, loss: 0.014833260327577591
step: 40, loss: 0.05351313576102257
step: 50, loss: 0.06369579583406448
step: 60, loss: 0.047555070370435715
step: 70, loss: 0.023488633334636688
step: 80, loss: 0.14435148239135742
step: 90, loss: 0.11297746002674103
step: 100, loss: 0.0874633938074112
step: 110, loss: 0.08665654063224792
step: 120, loss: 0.04002673551440239
step: 130, loss: 0.07509572803974152
step: 140, loss: 0.05213942006230354
step: 150, loss: 0.06453018635511398
step: 160, loss: 0.1032213345170021
step: 170, loss: 0.19581112265586853
step: 180, loss: 0.11974567919969559
step: 190, loss: 0.03741738945245743
step: 200, loss: 0.08438359946012497
step: 210, loss: 0.11730692535638809
step: 220, loss: 0.13205814361572266
step: 230, loss: 0.06694350391626358
step: 240, loss: 0.08162669837474823
step: 250, loss: 0.11795513331890106
step: 260, loss: 0.06963410973548889
step: 270, loss: 0.07545951008796692
step: 280, loss: 0.0654400959610939
step: 290, loss: 0.05209002643823624
step: 300, loss: 0.032037943601608276
step: 310, loss: 0.04314820095896721
step: 320, loss: 0.06347451359033585
step: 330, loss: 0.05554437264800072
epoch 14: dev_f1=0.8259860788863109, f1=0.8126410835214447, best_f1=0.8029556650246306
step: 0, loss: 0.09511447697877884
step: 10, loss: 0.1005689948797226
step: 20, loss: 0.09393759816884995
step: 30, loss: 0.0284990593791008
step: 40, loss: 0.02880970947444439
step: 50, loss: 3.550517067196779e-05
step: 60, loss: 0.1398521363735199
step: 70, loss: 0.13738226890563965
step: 80, loss: 0.10354785621166229
step: 90, loss: 0.053309109061956406
step: 100, loss: 0.022837895900011063
step: 110, loss: 0.09395277500152588
step: 120, loss: 0.11328686028718948
step: 130, loss: 0.1716834455728531
step: 140, loss: 0.07615991681814194
step: 150, loss: 0.0752880722284317
step: 160, loss: 0.06970306485891342
step: 170, loss: 0.08733661472797394
step: 180, loss: 0.0227705966681242
step: 190, loss: 0.10500647872686386
step: 200, loss: 0.1153729036450386
step: 210, loss: 0.12015104293823242
step: 220, loss: 0.14322449266910553
step: 230, loss: 0.1234947219491005
step: 240, loss: 0.21085578203201294
step: 250, loss: 0.08298660814762115
step: 260, loss: 0.0750238448381424
step: 270, loss: 0.053086377680301666
step: 280, loss: 0.04700695723295212
step: 290, loss: 0.12058736383914948
step: 300, loss: 0.046065934002399445
step: 310, loss: 0.04377267509698868
step: 320, loss: 0.023596150800585747
step: 330, loss: 0.149521604180336
epoch 15: dev_f1=0.815, f1=0.759124087591241, best_f1=0.8029556650246306
step: 0, loss: 0.11470634490251541
step: 10, loss: 0.09685944020748138
step: 20, loss: 0.06326187402009964
step: 30, loss: 0.13985233008861542
step: 40, loss: 0.13972428441047668
step: 50, loss: 0.07537366449832916
step: 60, loss: 0.11302845180034637
step: 70, loss: 0.08128981292247772
step: 80, loss: 0.10759197175502777
step: 90, loss: 0.09156593680381775
step: 100, loss: 0.06024270877242088
step: 110, loss: 0.08016759157180786
step: 120, loss: 0.09655269235372543
step: 130, loss: 0.008533446118235588
step: 140, loss: 0.08348068594932556
step: 150, loss: 0.11560970544815063
step: 160, loss: 0.01200263760983944
step: 170, loss: 0.06049632653594017
step: 180, loss: 0.097232386469841
step: 190, loss: 0.11091573536396027
step: 200, loss: 0.038483116775751114
step: 210, loss: 0.08999476581811905
step: 220, loss: 0.05349927395582199
step: 230, loss: 0.056790389120578766
step: 240, loss: 0.09635333716869354
step: 250, loss: 0.062035609036684036
step: 260, loss: 0.08728384971618652
step: 270, loss: 0.009815906174480915
step: 280, loss: 0.10688602179288864
step: 290, loss: 0.10031929612159729
step: 300, loss: 0.07216408848762512
step: 310, loss: 0.07070564478635788
step: 320, loss: 0.11067847907543182
step: 330, loss: 0.031237969174981117
epoch 16: dev_f1=0.8146453089244851, f1=0.7973273942093541, best_f1=0.8029556650246306
step: 0, loss: 0.12989290058612823
step: 10, loss: 0.08283742517232895
step: 20, loss: 0.036250658333301544
step: 30, loss: 0.11559003591537476
step: 40, loss: 0.10352043807506561
step: 50, loss: 0.13830377161502838
step: 60, loss: 0.11117608100175858
step: 70, loss: 0.03815456107258797
step: 80, loss: 0.036250315606594086
step: 90, loss: 0.07227850705385208
step: 100, loss: 0.020437004044651985
step: 110, loss: 0.0874074175953865
step: 120, loss: 0.08370129764080048
step: 130, loss: 0.12957167625427246
step: 140, loss: 0.04913049191236496
step: 150, loss: 0.07044435292482376
step: 160, loss: 0.10913487523794174
step: 170, loss: 0.08136127144098282
step: 180, loss: 0.10935786366462708
step: 190, loss: 0.09375802427530289
step: 200, loss: 0.12273770570755005
step: 210, loss: 0.050563134253025055
step: 220, loss: 0.05479602888226509
step: 230, loss: 0.06283789873123169
step: 240, loss: 0.06193184107542038
step: 250, loss: 0.14862187206745148
step: 260, loss: 0.018358178436756134
step: 270, loss: 0.017270922660827637
step: 280, loss: 0.14175952970981598
step: 290, loss: 0.07148069888353348
step: 300, loss: 0.06607747077941895
step: 310, loss: 0.01380868535488844
step: 320, loss: 0.08612757176160812
step: 330, loss: 0.04168297350406647
epoch 17: dev_f1=0.8162291169451074, f1=0.7924528301886793, best_f1=0.8029556650246306
step: 0, loss: 0.02848757430911064
step: 10, loss: 0.019795885309576988
step: 20, loss: 0.1365204006433487
step: 30, loss: 0.029809962958097458
step: 40, loss: 0.13573206961154938
step: 50, loss: 0.034296222031116486
step: 60, loss: 0.02939535677433014
step: 70, loss: 0.137189581990242
step: 80, loss: 0.07104932516813278
step: 90, loss: 0.038443196564912796
step: 100, loss: 0.07562050223350525
step: 110, loss: 0.11013893783092499
step: 120, loss: 0.11635968089103699
step: 130, loss: 0.08154097199440002
step: 140, loss: 0.08446574956178665
step: 150, loss: 0.10030916333198547
step: 160, loss: 0.07927541434764862
step: 170, loss: 0.06586368381977081
step: 180, loss: 0.07259149104356766
step: 190, loss: 0.04970623925328255
step: 200, loss: 0.07353971153497696
step: 210, loss: 0.00012090917152818292
step: 220, loss: 0.10583260655403137
step: 230, loss: 0.1337123066186905
step: 240, loss: 0.06884024292230606
step: 250, loss: 0.027585096657276154
step: 260, loss: 0.09339151531457901
step: 270, loss: 0.043263908475637436
step: 280, loss: 0.031639404594898224
step: 290, loss: 0.061525117605924606
step: 300, loss: 0.17027461528778076
step: 310, loss: 0.10619597136974335
step: 320, loss: 1.4137364814814646e-05
step: 330, loss: 0.07647409290075302
epoch 18: dev_f1=0.8028846153846153, f1=0.7801418439716311, best_f1=0.8029556650246306
step: 0, loss: 0.071750707924366
step: 10, loss: 0.10553862154483795
step: 20, loss: 0.017132820561528206
step: 30, loss: 0.08990579843521118
step: 40, loss: 0.047531262040138245
step: 50, loss: 0.06581024080514908
step: 60, loss: 0.025552622973918915
step: 70, loss: 0.1015382930636406
step: 80, loss: 0.018192624673247337
step: 90, loss: 0.06278344243764877
step: 100, loss: 0.11906848847866058
step: 110, loss: 0.11712976545095444
step: 120, loss: 0.0010488996049389243
step: 130, loss: 0.05508981645107269
step: 140, loss: 0.015606843866407871
step: 150, loss: 0.08706560730934143
step: 160, loss: 0.060124509036540985
step: 170, loss: 0.0865505188703537
step: 180, loss: 0.06087537109851837
step: 190, loss: 0.06370088458061218
step: 200, loss: 0.0534914955496788
step: 210, loss: 0.05306458845734596
step: 220, loss: 0.10019951313734055
step: 230, loss: 0.07826407998800278
step: 240, loss: 0.04838753491640091
step: 250, loss: 0.10327664762735367
step: 260, loss: 0.10008301585912704
step: 270, loss: 0.09606655687093735
step: 280, loss: 0.062091611325740814
step: 290, loss: 0.08224154263734818
step: 300, loss: 0.08816832304000854
step: 310, loss: 0.049263034015893936
step: 320, loss: 0.02728315442800522
step: 330, loss: 0.17406347393989563
epoch 19: dev_f1=0.801007556675063, f1=0.7604938271604937, best_f1=0.8029556650246306
step: 0, loss: 0.12587223947048187
step: 10, loss: 0.12458816170692444
step: 20, loss: 0.045413270592689514
step: 30, loss: 0.07253030687570572
step: 40, loss: 8.263307972811162e-05
step: 50, loss: 0.027368372306227684
step: 60, loss: 0.054764214903116226
step: 70, loss: 0.0790041983127594
step: 80, loss: 0.12633103132247925
step: 90, loss: 0.06669054925441742
step: 100, loss: 0.07332295924425125
step: 110, loss: 0.1171751469373703
step: 120, loss: 0.0772273913025856
step: 130, loss: 0.03454713895916939
step: 140, loss: 0.00010546495468588546
step: 150, loss: 0.050034746527671814
step: 160, loss: 0.021470902487635612
step: 170, loss: 3.931210812879726e-05
step: 180, loss: 0.21097388863563538
step: 190, loss: 0.13757382333278656
step: 200, loss: 0.12373493611812592
step: 210, loss: 0.07249321788549423
step: 220, loss: 0.024051524698734283
step: 230, loss: 0.055638015270233154
step: 240, loss: 0.11881554871797562
step: 250, loss: 0.022642647847533226
step: 260, loss: 0.12224075198173523
step: 270, loss: 0.1817997545003891
step: 280, loss: 0.05605055019259453
step: 290, loss: 0.045539237558841705
step: 300, loss: 0.042108144611120224
step: 310, loss: 0.02722744271159172
step: 320, loss: 0.042581673711538315
step: 330, loss: 0.05432892218232155
epoch 20: dev_f1=0.8030303030303031, f1=0.7487437185929648, best_f1=0.8029556650246306
