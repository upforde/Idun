cuda
Device: cuda
step: 0, loss: 0.6097322106361389
step: 10, loss: 0.2495393306016922
step: 20, loss: 0.13836945593357086
step: 30, loss: 0.3163700997829437
step: 40, loss: 0.3233727514743805
step: 50, loss: 0.32789120078086853
step: 60, loss: 0.053858257830142975
step: 70, loss: 0.43405938148498535
step: 80, loss: 0.3103957176208496
step: 90, loss: 0.4277583062648773
step: 100, loss: 0.22710320353507996
step: 110, loss: 0.3378123641014099
step: 120, loss: 0.306441068649292
step: 130, loss: 0.13982421159744263
step: 140, loss: 0.14895974099636078
step: 150, loss: 0.02059609442949295
step: 160, loss: 0.42920422554016113
step: 170, loss: 0.14139868319034576
step: 180, loss: 0.1423720270395279
step: 190, loss: 0.5173355937004089
step: 200, loss: 0.08125616610050201
step: 210, loss: 0.03880992904305458
step: 220, loss: 0.13677267730236053
step: 230, loss: 0.32798418402671814
step: 240, loss: 0.21980507671833038
step: 250, loss: 0.236561119556427
step: 260, loss: 0.12788474559783936
step: 270, loss: 0.3346960246562958
step: 280, loss: 0.16867874562740326
step: 290, loss: 0.33578938245773315
step: 300, loss: 0.3143858313560486
step: 310, loss: 0.18851278722286224
step: 320, loss: 0.1714320033788681
step: 330, loss: 0.09053613245487213
epoch 1: dev_f1=0.4746835443037975, f1=0.4064516129032258, best_f1=0.4064516129032258
step: 0, loss: 0.44545137882232666
step: 10, loss: 0.14383918046951294
step: 20, loss: 0.08972617983818054
step: 30, loss: 0.1624428927898407
step: 40, loss: 0.24257899820804596
step: 50, loss: 0.09881531447172165
step: 60, loss: 0.2816197872161865
step: 70, loss: 0.042551007121801376
step: 80, loss: 0.24091532826423645
step: 90, loss: 0.0711161345243454
step: 100, loss: 0.19248321652412415
step: 110, loss: 0.21809789538383484
step: 120, loss: 0.09995829313993454
step: 130, loss: 0.04396049305796623
step: 140, loss: 0.22792257368564606
step: 150, loss: 0.10156632959842682
step: 160, loss: 0.22234098613262177
step: 170, loss: 0.22166074812412262
step: 180, loss: 0.06548436731100082
step: 190, loss: 0.15966199338436127
step: 200, loss: 0.18602170050144196
step: 210, loss: 0.09082441031932831
step: 220, loss: 0.28403884172439575
step: 230, loss: 0.13678377866744995
step: 240, loss: 0.08614131063222885
step: 250, loss: 0.14095386862754822
step: 260, loss: 0.07997963577508926
step: 270, loss: 0.08854810893535614
step: 280, loss: 0.08334297686815262
step: 290, loss: 0.03801317885518074
step: 300, loss: 0.2291889190673828
step: 310, loss: 0.09869664907455444
step: 320, loss: 0.39000919461250305
step: 330, loss: 0.0886530876159668
epoch 2: dev_f1=0.7793427230046948, f1=0.7544642857142856, best_f1=0.7544642857142856
step: 0, loss: 0.11136583238840103
step: 10, loss: 0.15283137559890747
step: 20, loss: 0.08862514048814774
step: 30, loss: 0.17418640851974487
step: 40, loss: 0.09733965992927551
step: 50, loss: 0.24576930701732635
step: 60, loss: 0.09569266438484192
step: 70, loss: 0.05227505788207054
step: 80, loss: 0.06971434503793716
step: 90, loss: 0.05734243988990784
step: 100, loss: 0.27208226919174194
step: 110, loss: 0.08749344944953918
step: 120, loss: 0.11750595271587372
step: 130, loss: 0.07576686143875122
step: 140, loss: 0.048360422253608704
step: 150, loss: 0.181544229388237
step: 160, loss: 0.26772481203079224
step: 170, loss: 0.15337571501731873
step: 180, loss: 0.1666969656944275
step: 190, loss: 0.07986089587211609
step: 200, loss: 0.14265227317810059
step: 210, loss: 0.25248897075653076
step: 220, loss: 0.2381613403558731
step: 230, loss: 0.07564965635538101
step: 240, loss: 0.05870984122157097
step: 250, loss: 0.2164025902748108
step: 260, loss: 0.05977104976773262
step: 270, loss: 0.11140204966068268
step: 280, loss: 0.07060530036687851
step: 290, loss: 0.06679153442382812
step: 300, loss: 0.04260369390249252
step: 310, loss: 0.060494277626276016
step: 320, loss: 0.09098003059625626
step: 330, loss: 0.15728573501110077
epoch 3: dev_f1=0.7974137931034483, f1=0.7551867219917013, best_f1=0.7551867219917013
step: 0, loss: 0.012910389341413975
step: 10, loss: 0.09440841525793076
step: 20, loss: 0.11225210875272751
step: 30, loss: 0.013872687704861164
step: 40, loss: 0.08668427169322968
step: 50, loss: 0.0543828122317791
step: 60, loss: 0.38748475909233093
step: 70, loss: 0.09940115362405777
step: 80, loss: 0.18425503373146057
step: 90, loss: 0.04229722544550896
step: 100, loss: 0.08177787810564041
step: 110, loss: 0.1054474264383316
step: 120, loss: 0.24459697306156158
step: 130, loss: 0.049659278243780136
step: 140, loss: 0.07592581957578659
step: 150, loss: 0.1457727551460266
step: 160, loss: 0.052228327840566635
step: 170, loss: 0.10028406977653503
step: 180, loss: 0.016788246110081673
step: 190, loss: 0.054953042417764664
step: 200, loss: 0.025841431692242622
step: 210, loss: 0.0775967612862587
step: 220, loss: 0.06917490065097809
step: 230, loss: 0.23878544569015503
step: 240, loss: 0.09731369465589523
step: 250, loss: 0.08937123417854309
step: 260, loss: 0.1181911751627922
step: 270, loss: 0.06363216787576675
step: 280, loss: 0.1331491321325302
step: 290, loss: 0.10062843561172485
step: 300, loss: 0.13557276129722595
step: 310, loss: 0.2704189121723175
step: 320, loss: 0.15604418516159058
step: 330, loss: 0.06516140699386597
epoch 4: dev_f1=0.8108108108108107, f1=0.7782608695652173, best_f1=0.7782608695652173
step: 0, loss: 0.14562298357486725
step: 10, loss: 0.12373282760381699
step: 20, loss: 0.06667082756757736
step: 30, loss: 0.03284124284982681
step: 40, loss: 0.0401306189596653
step: 50, loss: 0.09217280894517899
step: 60, loss: 0.010817887261509895
step: 70, loss: 0.057491328567266464
step: 80, loss: 0.1505713015794754
step: 90, loss: 0.11692190170288086
step: 100, loss: 0.12541821599006653
step: 110, loss: 0.20071670413017273
step: 120, loss: 0.04265265911817551
step: 130, loss: 0.09625324606895447
step: 140, loss: 0.02461625263094902
step: 150, loss: 0.16243501007556915
step: 160, loss: 0.08006768673658371
step: 170, loss: 0.11278926581144333
step: 180, loss: 0.11528348177671432
step: 190, loss: 0.08935610204935074
step: 200, loss: 0.06071927398443222
step: 210, loss: 0.15727943181991577
step: 220, loss: 0.10989182442426682
step: 230, loss: 0.05524221062660217
step: 240, loss: 0.3057561218738556
step: 250, loss: 0.13333839178085327
step: 260, loss: 0.10740485787391663
step: 270, loss: 0.09083502739667892
step: 280, loss: 0.13421426713466644
step: 290, loss: 0.1059621199965477
step: 300, loss: 0.0915452316403389
step: 310, loss: 0.05728405714035034
step: 320, loss: 0.08692297339439392
step: 330, loss: 0.13403725624084473
epoch 5: dev_f1=0.7813163481953291, f1=0.758909853249476, best_f1=0.7782608695652173
step: 0, loss: 0.0847695991396904
step: 10, loss: 0.06634484231472015
step: 20, loss: 0.10457928478717804
step: 30, loss: 0.12444724887609482
step: 40, loss: 0.08653054386377335
step: 50, loss: 0.15061664581298828
step: 60, loss: 0.07574975490570068
step: 70, loss: 0.16826480627059937
step: 80, loss: 0.0020872834138572216
step: 90, loss: 0.08185601979494095
step: 100, loss: 0.03970470651984215
step: 110, loss: 0.0019317904952913523
step: 120, loss: 0.08938723057508469
step: 130, loss: 0.08171965181827545
step: 140, loss: 0.02501169964671135
step: 150, loss: 0.04537706449627876
step: 160, loss: 0.10762251168489456
step: 170, loss: 0.18096475303173065
step: 180, loss: 0.09720408916473389
step: 190, loss: 0.04206244274973869
step: 200, loss: 0.09193305671215057
step: 210, loss: 0.14341862499713898
step: 220, loss: 0.12450570613145828
step: 230, loss: 0.17053517699241638
step: 240, loss: 0.09089537709951401
step: 250, loss: 0.10637816041707993
step: 260, loss: 0.1504041701555252
step: 270, loss: 0.06757530570030212
step: 280, loss: 0.141059011220932
step: 290, loss: 0.09756763279438019
step: 300, loss: 0.15937656164169312
step: 310, loss: 0.1681717187166214
step: 320, loss: 0.14121340215206146
step: 330, loss: 0.12396612763404846
epoch 6: dev_f1=0.7972350230414745, f1=0.7727272727272726, best_f1=0.7782608695652173
step: 0, loss: 0.13453815877437592
step: 10, loss: 0.08515554666519165
step: 20, loss: 0.053912725299596786
step: 30, loss: 0.23998327553272247
step: 40, loss: 0.0726514682173729
step: 50, loss: 0.10963458567857742
step: 60, loss: 0.06580523401498795
step: 70, loss: 0.06710071861743927
step: 80, loss: 0.04032628610730171
step: 90, loss: 0.009309199638664722
step: 100, loss: 0.10420085489749908
step: 110, loss: 0.04683912917971611
step: 120, loss: 0.12156207859516144
step: 130, loss: 0.059396468102931976
step: 140, loss: 0.07576777786016464
step: 150, loss: 0.08646083623170853
step: 160, loss: 0.08179102838039398
step: 170, loss: 0.08776765316724777
step: 180, loss: 0.11086338013410568
step: 190, loss: 0.07202041894197464
step: 200, loss: 0.12524116039276123
step: 210, loss: 0.09012558311223984
step: 220, loss: 0.05674074590206146
step: 230, loss: 0.0051857042126357555
step: 240, loss: 0.04296402633190155
step: 250, loss: 0.0015726705314591527
step: 260, loss: 0.0846145823597908
step: 270, loss: 0.06629544496536255
step: 280, loss: 0.03449075669050217
step: 290, loss: 0.09324073046445847
step: 300, loss: 0.13512635231018066
step: 310, loss: 0.15565639734268188
step: 320, loss: 0.10787560790777206
step: 330, loss: 0.11708083003759384
epoch 7: dev_f1=0.8267898383371824, f1=0.8018867924528301, best_f1=0.8018867924528301
step: 0, loss: 0.02405349723994732
step: 10, loss: 0.06321952491998672
step: 20, loss: 0.01461258064955473
step: 30, loss: 0.09291189908981323
step: 40, loss: 0.1506047397851944
step: 50, loss: 0.09972913563251495
step: 60, loss: 0.06559517979621887
step: 70, loss: 0.02916972152888775
step: 80, loss: 0.1916918158531189
step: 90, loss: 0.05904659628868103
step: 100, loss: 0.13043047487735748
step: 110, loss: 0.10697971284389496
step: 120, loss: 0.06633713841438293
step: 130, loss: 0.0282300878316164
step: 140, loss: 0.09763196855783463
step: 150, loss: 0.08796372264623642
step: 160, loss: 0.1629389077425003
step: 170, loss: 0.13574838638305664
step: 180, loss: 0.08766935020685196
step: 190, loss: 0.1589798778295517
step: 200, loss: 0.0690627247095108
step: 210, loss: 0.012737010605633259
step: 220, loss: 0.0402376614511013
step: 230, loss: 0.0391608290374279
step: 240, loss: 0.14961612224578857
step: 250, loss: 0.11239960044622421
step: 260, loss: 0.07058299332857132
step: 270, loss: 0.07215368747711182
step: 280, loss: 0.03258419781923294
step: 290, loss: 0.07171604037284851
step: 300, loss: 0.0801064595580101
step: 310, loss: 0.11314362287521362
step: 320, loss: 0.12128066271543503
step: 330, loss: 0.01764620654284954
epoch 8: dev_f1=0.8333333333333333, f1=0.794392523364486, best_f1=0.794392523364486
step: 0, loss: 0.08307590335607529
step: 10, loss: 0.09437590092420578
step: 20, loss: 0.12150730937719345
step: 30, loss: 0.05452944338321686
step: 40, loss: 0.10531806945800781
step: 50, loss: 0.0667368546128273
step: 60, loss: 0.17135778069496155
step: 70, loss: 0.05268354341387749
step: 80, loss: 0.04309839382767677
step: 90, loss: 0.0016550968866795301
step: 100, loss: 0.07478360086679459
step: 110, loss: 0.030228542163968086
step: 120, loss: 0.09962289035320282
step: 130, loss: 0.07008646428585052
step: 140, loss: 0.046092066913843155
step: 150, loss: 0.10770367085933685
step: 160, loss: 0.11005062609910965
step: 170, loss: 0.1368241012096405
step: 180, loss: 0.06081971898674965
step: 190, loss: 0.1264190673828125
step: 200, loss: 0.05489512160420418
step: 210, loss: 0.13039632141590118
step: 220, loss: 0.031272947788238525
step: 230, loss: 0.021613024175167084
step: 240, loss: 0.14336714148521423
step: 250, loss: 0.09047868102788925
step: 260, loss: 0.06298267096281052
step: 270, loss: 0.04514118656516075
step: 280, loss: 0.054215166717767715
step: 290, loss: 0.12912775576114655
step: 300, loss: 0.13980790972709656
step: 310, loss: 0.06905592232942581
step: 320, loss: 0.19515372812747955
step: 330, loss: 0.11985845118761063
epoch 9: dev_f1=0.8289156626506025, f1=0.7846889952153109, best_f1=0.794392523364486
step: 0, loss: 0.14817877113819122
step: 10, loss: 0.08091273158788681
step: 20, loss: 0.08953231573104858
step: 30, loss: 0.1274813860654831
step: 40, loss: 0.07555350661277771
step: 50, loss: 0.08832429349422455
step: 60, loss: 0.11535996943712234
step: 70, loss: 0.09403093159198761
step: 80, loss: 0.10305892676115036
step: 90, loss: 0.09685835242271423
step: 100, loss: 0.11988454312086105
step: 110, loss: 0.08565504103899002
step: 120, loss: 0.24507617950439453
step: 130, loss: 0.13575540482997894
step: 140, loss: 0.07664728164672852
step: 150, loss: 0.0648265853524208
step: 160, loss: 7.1251968620345e-05
step: 170, loss: 0.07806921750307083
step: 180, loss: 0.09091146290302277
step: 190, loss: 0.12270916253328323
step: 200, loss: 0.031789813190698624
step: 210, loss: 0.04937266930937767
step: 220, loss: 0.10243592411279678
step: 230, loss: 0.044590242207050323
step: 240, loss: 0.04161788150668144
step: 250, loss: 0.11724825203418732
step: 260, loss: 0.07258965820074081
step: 270, loss: 0.09225355088710785
step: 280, loss: 0.0588366761803627
step: 290, loss: 0.07798288762569427
step: 300, loss: 0.05944988131523132
step: 310, loss: 0.0176820270717144
step: 320, loss: 0.08069005608558655
step: 330, loss: 0.11736684292554855
epoch 10: dev_f1=0.8321513002364066, f1=0.7840375586854459, best_f1=0.794392523364486
step: 0, loss: 0.0009670491563156247
step: 10, loss: 0.13162867724895477
step: 20, loss: 0.1292984038591385
step: 30, loss: 0.10347292572259903
step: 40, loss: 0.05372319743037224
step: 50, loss: 0.03720103204250336
step: 60, loss: 0.1721714735031128
step: 70, loss: 0.06841347366571426
step: 80, loss: 0.10690494626760483
step: 90, loss: 0.13693112134933472
step: 100, loss: 0.06930139660835266
step: 110, loss: 0.10249415785074234
step: 120, loss: 0.022565001621842384
step: 130, loss: 0.07931950688362122
step: 140, loss: 0.0932341143488884
step: 150, loss: 0.2709783911705017
step: 160, loss: 0.09283685684204102
step: 170, loss: 0.07717446982860565
step: 180, loss: 0.06631772220134735
step: 190, loss: 0.039732083678245544
step: 200, loss: 0.11587629467248917
step: 210, loss: 0.12209546566009521
step: 220, loss: 0.14859920740127563
step: 230, loss: 0.16960325837135315
step: 240, loss: 0.08785545080900192
step: 250, loss: 0.04420628026127815
step: 260, loss: 0.09272265434265137
step: 270, loss: 0.0626336932182312
step: 280, loss: 0.10501698404550552
step: 290, loss: 0.04332849755883217
step: 300, loss: 0.10183433443307877
step: 310, loss: 0.0330001562833786
step: 320, loss: 0.08855113387107849
step: 330, loss: 0.07315128296613693
epoch 11: dev_f1=0.8175519630484988, f1=0.7954022988505747, best_f1=0.794392523364486
step: 0, loss: 0.11420712620019913
step: 10, loss: 0.07340773195028305
step: 20, loss: 0.07675333321094513
step: 30, loss: 0.040592316538095474
step: 40, loss: 0.058260925114154816
step: 50, loss: 0.10664544254541397
step: 60, loss: 0.15117484331130981
step: 70, loss: 0.09447461366653442
step: 80, loss: 0.03896407037973404
step: 90, loss: 0.10335662961006165
step: 100, loss: 4.425393126439303e-05
step: 110, loss: 0.13108226656913757
step: 120, loss: 0.12289519608020782
step: 130, loss: 0.09051632136106491
step: 140, loss: 0.03513314947485924
step: 150, loss: 0.1426454782485962
step: 160, loss: 0.04097537696361542
step: 170, loss: 0.06198019161820412
step: 180, loss: 0.05052366107702255
step: 190, loss: 4.5579930883832276e-05
step: 200, loss: 0.08446688950061798
step: 210, loss: 0.13703393936157227
step: 220, loss: 0.04291173815727234
step: 230, loss: 0.11003231257200241
step: 240, loss: 0.12366088479757309
step: 250, loss: 0.10170166939496994
step: 260, loss: 0.08202283829450607
step: 270, loss: 0.08776821196079254
step: 280, loss: 0.08400213718414307
step: 290, loss: 0.058208998292684555
step: 300, loss: 0.06248260289430618
step: 310, loss: 0.06128630414605141
step: 320, loss: 0.08398763835430145
step: 330, loss: 0.1316603571176529
epoch 12: dev_f1=0.8161434977578474, f1=0.7789934354485777, best_f1=0.794392523364486
step: 0, loss: 0.08952285349369049
step: 10, loss: 0.02688465639948845
step: 20, loss: 0.1230793446302414
step: 30, loss: 0.11495854705572128
step: 40, loss: 0.07503827661275864
step: 50, loss: 0.07959438115358353
step: 60, loss: 0.059440501034259796
step: 70, loss: 0.044039782136678696
step: 80, loss: 0.07173974812030792
step: 90, loss: 0.0901399776339531
step: 100, loss: 0.04890652000904083
step: 110, loss: 0.07993770390748978
step: 120, loss: 0.11425945907831192
step: 130, loss: 0.06439510732889175
step: 140, loss: 0.12230951339006424
step: 150, loss: 0.08927804976701736
step: 160, loss: 0.05889074504375458
step: 170, loss: 0.0918678492307663
step: 180, loss: 0.11168627440929413
step: 190, loss: 0.08031753450632095
step: 200, loss: 0.08169819414615631
step: 210, loss: 0.0850323736667633
step: 220, loss: 0.12965594232082367
step: 230, loss: 0.08344444632530212
step: 240, loss: 0.018519561737775803
step: 250, loss: 0.07387316972017288
step: 260, loss: 0.0726371705532074
step: 270, loss: 0.15933509171009064
step: 280, loss: 0.07485593110322952
step: 290, loss: 0.10551926493644714
step: 300, loss: 0.08699454367160797
step: 310, loss: 0.00028624056722037494
step: 320, loss: 0.05609746277332306
step: 330, loss: 0.11013228446245193
epoch 13: dev_f1=0.8055555555555555, f1=0.796420581655481, best_f1=0.794392523364486
step: 0, loss: 0.16674713790416718
step: 10, loss: 0.11720825731754303
step: 20, loss: 0.17538927495479584
step: 30, loss: 0.04282858967781067
step: 40, loss: 0.0717342346906662
step: 50, loss: 0.08155728131532669
step: 60, loss: 0.07719356566667557
step: 70, loss: 7.513188757002354e-05
step: 80, loss: 0.09093526005744934
step: 90, loss: 0.11586987972259521
step: 100, loss: 0.05727071687579155
step: 110, loss: 0.05324631929397583
step: 120, loss: 0.14808136224746704
step: 130, loss: 0.05236267298460007
step: 140, loss: 0.03510238975286484
step: 150, loss: 0.039566993713378906
step: 160, loss: 0.0483013391494751
step: 170, loss: 0.08932514488697052
step: 180, loss: 0.14732828736305237
step: 190, loss: 0.01487469207495451
step: 200, loss: 0.023027731105685234
step: 210, loss: 0.11717712134122849
step: 220, loss: 0.06246964633464813
step: 230, loss: 0.04002898931503296
step: 240, loss: 0.06350942701101303
step: 250, loss: 0.14730647206306458
step: 260, loss: 0.11452337354421616
step: 270, loss: 0.19091078639030457
step: 280, loss: 0.07524292171001434
step: 290, loss: 0.09131930768489838
step: 300, loss: 0.17819462716579437
step: 310, loss: 0.09267646819353104
step: 320, loss: 0.12771610915660858
step: 330, loss: 0.03793798387050629
epoch 14: dev_f1=0.7855421686746988, f1=0.7813953488372092, best_f1=0.794392523364486
step: 0, loss: 0.06294352561235428
step: 10, loss: 0.094466932117939
step: 20, loss: 0.07444293797016144
step: 30, loss: 0.10990141332149506
step: 40, loss: 0.12712985277175903
step: 50, loss: 0.061187565326690674
step: 60, loss: 0.060219164937734604
step: 70, loss: 0.1672906130552292
step: 80, loss: 0.08268491178750992
step: 90, loss: 0.09497924894094467
step: 100, loss: 0.03452229127287865
step: 110, loss: 0.0345703549683094
step: 120, loss: 0.1714366376399994
step: 130, loss: 0.12046637386083603
step: 140, loss: 0.13662829995155334
step: 150, loss: 0.06364577263593674
step: 160, loss: 0.05108974874019623
step: 170, loss: 0.027670064941048622
step: 180, loss: 0.09627357870340347
step: 190, loss: 0.04258786141872406
step: 200, loss: 0.06316705793142319
step: 210, loss: 0.10441657900810242
step: 220, loss: 0.052702248096466064
step: 230, loss: 0.16735216975212097
step: 240, loss: 0.04413672909140587
step: 250, loss: 0.09471583366394043
step: 260, loss: 0.16324524581432343
step: 270, loss: 0.02632793039083481
step: 280, loss: 0.07637391984462738
step: 290, loss: 0.07202860713005066
step: 300, loss: 0.030408285558223724
step: 310, loss: 0.055818378925323486
step: 320, loss: 0.034168750047683716
step: 330, loss: 0.01720384880900383
epoch 15: dev_f1=0.791469194312796, f1=0.7888631090487238, best_f1=0.794392523364486
step: 0, loss: 0.07148197293281555
step: 10, loss: 0.0739397406578064
step: 20, loss: 0.01938127726316452
step: 30, loss: 0.039138298481702805
step: 40, loss: 0.06527936458587646
step: 50, loss: 2.242968366772402e-05
step: 60, loss: 0.08500869572162628
step: 70, loss: 0.07473350316286087
step: 80, loss: 0.10044901072978973
step: 90, loss: 0.06482403725385666
step: 100, loss: 0.061071574687957764
step: 110, loss: 0.11129003018140793
step: 120, loss: 0.112294502556324
step: 130, loss: 0.05351841077208519
step: 140, loss: 0.0929267406463623
step: 150, loss: 0.12460045516490936
step: 160, loss: 0.058501847088336945
step: 170, loss: 0.11242739111185074
step: 180, loss: 0.047692593187093735
step: 190, loss: 0.049506280571222305
step: 200, loss: 0.01237161923199892
step: 210, loss: 0.09801290929317474
step: 220, loss: 0.08630115538835526
step: 230, loss: 0.09673946350812912
step: 240, loss: 0.09730419516563416
step: 250, loss: 0.025461606681346893
step: 260, loss: 0.06913568079471588
step: 270, loss: 0.04875237122178078
step: 280, loss: 0.02680295892059803
step: 290, loss: 0.029710182920098305
step: 300, loss: 0.061804454773664474
step: 310, loss: 0.09893321245908737
step: 320, loss: 0.1377863585948944
step: 330, loss: 0.06375899165868759
epoch 16: dev_f1=0.8038277511961723, f1=0.7990430622009569, best_f1=0.794392523364486
step: 0, loss: 0.0218346044421196
step: 10, loss: 0.03602157160639763
step: 20, loss: 0.05613083392381668
step: 30, loss: 0.048136305063962936
step: 40, loss: 0.047746703028678894
step: 50, loss: 0.1019030213356018
step: 60, loss: 0.06986213475465775
step: 70, loss: 0.1125064566731453
step: 80, loss: 0.08435250073671341
step: 90, loss: 0.05989450588822365
step: 100, loss: 0.09222547709941864
step: 110, loss: 0.06698353588581085
step: 120, loss: 0.08664041012525558
step: 130, loss: 0.07516658306121826
step: 140, loss: 0.09327871352434158
step: 150, loss: 0.06107617914676666
step: 160, loss: 0.04911554977297783
step: 170, loss: 0.11631052196025848
step: 180, loss: 0.024419698864221573
step: 190, loss: 0.1769890934228897
step: 200, loss: 0.10641243308782578
step: 210, loss: 0.1202664002776146
step: 220, loss: 0.056769728660583496
step: 230, loss: 0.18062587082386017
step: 240, loss: 0.10586269199848175
step: 250, loss: 0.11654434353113174
step: 260, loss: 0.04723382741212845
step: 270, loss: 0.07712725549936295
step: 280, loss: 0.04636223986744881
step: 290, loss: 0.11375222355127335
step: 300, loss: 0.12916581332683563
step: 310, loss: 0.016272811219096184
step: 320, loss: 0.0495738722383976
step: 330, loss: 0.11319038271903992
epoch 17: dev_f1=0.8130841121495326, f1=0.794392523364486, best_f1=0.794392523364486
step: 0, loss: 0.06516959518194199
step: 10, loss: 0.036771275103092194
step: 20, loss: 0.11672383546829224
step: 30, loss: 0.08726045489311218
step: 40, loss: 0.12229632586240768
step: 50, loss: 0.09429215639829636
step: 60, loss: 0.04752806946635246
step: 70, loss: 0.07390879839658737
step: 80, loss: 0.05716444551944733
step: 90, loss: 0.06249517202377319
step: 100, loss: 0.08418919891119003
step: 110, loss: 0.07763409614562988
step: 120, loss: 0.052294790744781494
step: 130, loss: 0.11156082898378372
step: 140, loss: 0.084001325070858
step: 150, loss: 0.07575511187314987
step: 160, loss: 0.1492389440536499
step: 170, loss: 0.0058555882424116135
step: 180, loss: 0.08796762675046921
step: 190, loss: 0.038520846515893936
step: 200, loss: 0.07008346915245056
step: 210, loss: 0.06156250089406967
step: 220, loss: 0.14609283208847046
step: 230, loss: 0.11137434095144272
step: 240, loss: 0.06564405560493469
step: 250, loss: 0.08877390623092651
step: 260, loss: 0.060310330241918564
step: 270, loss: 0.09372349083423615
step: 280, loss: 0.029148388653993607
step: 290, loss: 0.038865938782691956
step: 300, loss: 0.07723096013069153
step: 310, loss: 0.07730839401483536
step: 320, loss: 0.05008931830525398
step: 330, loss: 0.06969200074672699
epoch 18: dev_f1=0.8280871670702179, f1=0.7971014492753623, best_f1=0.794392523364486
step: 0, loss: 0.02869032695889473
step: 10, loss: 0.11270955950021744
step: 20, loss: 0.02912060171365738
step: 30, loss: 0.021983521059155464
step: 40, loss: 0.04733924940228462
step: 50, loss: 0.020921451970934868
step: 60, loss: 0.039849597960710526
step: 70, loss: 0.08210855722427368
step: 80, loss: 0.01971634104847908
step: 90, loss: 0.005138625856488943
step: 100, loss: 0.06885955482721329
step: 110, loss: 0.03350174427032471
step: 120, loss: 0.032509222626686096
step: 130, loss: 0.04209226742386818
step: 140, loss: 0.07631802558898926
step: 150, loss: 0.12991458177566528
step: 160, loss: 0.04567737132310867
step: 170, loss: 0.04955781623721123
step: 180, loss: 0.06934739649295807
step: 190, loss: 0.1242198720574379
step: 200, loss: 0.12294983118772507
step: 210, loss: 0.13468928635120392
step: 220, loss: 0.02309820055961609
step: 230, loss: 0.061878856271505356
step: 240, loss: 0.026326559484004974
step: 250, loss: 0.10608044266700745
step: 260, loss: 0.0828118547797203
step: 270, loss: 0.13374359905719757
step: 280, loss: 0.04289543628692627
step: 290, loss: 0.041178274899721146
step: 300, loss: 0.06931567937135696
step: 310, loss: 0.06200535595417023
step: 320, loss: 0.013212382793426514
step: 330, loss: 0.10735798627138138
epoch 19: dev_f1=0.8192771084337348, f1=0.8028503562945368, best_f1=0.794392523364486
step: 0, loss: 0.042529232800006866
step: 10, loss: 0.08014965057373047
step: 20, loss: 0.03171373903751373
step: 30, loss: 0.07357492297887802
step: 40, loss: 0.06798787415027618
step: 50, loss: 0.11405779421329498
step: 60, loss: 0.04678886756300926
step: 70, loss: 0.113675057888031
step: 80, loss: 0.02804330736398697
step: 90, loss: 0.11193213611841202
step: 100, loss: 0.10993114113807678
step: 110, loss: 0.032380569726228714
step: 120, loss: 0.023621531203389168
step: 130, loss: 0.05605270713567734
step: 140, loss: 0.0508115217089653
step: 150, loss: 0.05453319102525711
step: 160, loss: 0.05809933319687843
step: 170, loss: 0.1158263236284256
step: 180, loss: 0.0372905395925045
step: 190, loss: 0.061969511210918427
step: 200, loss: 0.05307384207844734
step: 210, loss: 0.05511627346277237
step: 220, loss: 0.0033694370649755
step: 230, loss: 0.02870146557688713
step: 240, loss: 0.10520661622285843
step: 250, loss: 0.05217071622610092
step: 260, loss: 0.026256252080202103
step: 270, loss: 0.11251245439052582
step: 280, loss: 0.02834734320640564
step: 290, loss: 0.11231759190559387
step: 300, loss: 0.012699414044618607
step: 310, loss: 0.11697768419981003
step: 320, loss: 0.05107707902789116
step: 330, loss: 0.03497034311294556
epoch 20: dev_f1=0.8184019370460048, f1=0.7980769230769231, best_f1=0.794392523364486
