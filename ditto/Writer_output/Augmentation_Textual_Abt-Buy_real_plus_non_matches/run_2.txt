cuda
Device: cuda
step: 0, loss: 0.84028160572052
step: 10, loss: 0.142917662858963
step: 20, loss: 0.1483839601278305
step: 30, loss: 0.5230201482772827
step: 40, loss: 0.23301050066947937
step: 50, loss: 0.45242851972579956
step: 60, loss: 0.14235174655914307
step: 70, loss: 0.40101438760757446
step: 80, loss: 0.15923959016799927
step: 90, loss: 0.04970099404454231
step: 100, loss: 0.13128861784934998
step: 110, loss: 0.08572345972061157
step: 120, loss: 0.12769636511802673
step: 130, loss: 0.2308083176612854
step: 140, loss: 0.2892740070819855
step: 150, loss: 0.036251988261938095
step: 160, loss: 0.42308276891708374
step: 170, loss: 0.1737576276063919
step: 180, loss: 0.34167230129241943
step: 190, loss: 0.39610883593559265
step: 200, loss: 0.2294621616601944
step: 210, loss: 0.5417191386222839
step: 220, loss: 0.19678430259227753
step: 230, loss: 0.1918831467628479
step: 240, loss: 0.05429680645465851
step: 250, loss: 0.03974314033985138
step: 260, loss: 0.1003769114613533
step: 270, loss: 0.21745187044143677
step: 280, loss: 0.11491312086582184
step: 290, loss: 0.10730598121881485
step: 300, loss: 0.16442525386810303
step: 310, loss: 0.19850163161754608
step: 320, loss: 0.14408491551876068
step: 330, loss: 0.2841462194919586
epoch 1: dev_f1=0.6582809224318659, f1=0.6505050505050505, best_f1=0.6505050505050505
step: 0, loss: 0.12001347541809082
step: 10, loss: 0.20070159435272217
step: 20, loss: 0.06068016216158867
step: 30, loss: 0.2072877585887909
step: 40, loss: 0.05481131747364998
step: 50, loss: 0.03801124542951584
step: 60, loss: 0.3041417896747589
step: 70, loss: 0.40631476044654846
step: 80, loss: 0.054687388241291046
step: 90, loss: 0.21847747266292572
step: 100, loss: 0.15360340476036072
step: 110, loss: 0.07287684828042984
step: 120, loss: 0.19182685017585754
step: 130, loss: 0.14601793885231018
step: 140, loss: 0.003961263224482536
step: 150, loss: 0.04107619449496269
step: 160, loss: 0.1835445612668991
step: 170, loss: 0.05685362592339516
step: 180, loss: 0.08331114798784256
step: 190, loss: 0.06924961507320404
step: 200, loss: 0.2631432116031647
step: 210, loss: 0.09833861887454987
step: 220, loss: 0.009711465798318386
step: 230, loss: 0.09710054844617844
step: 240, loss: 0.10504031181335449
step: 250, loss: 0.17686831951141357
step: 260, loss: 0.05599728971719742
step: 270, loss: 0.16947615146636963
step: 280, loss: 0.116271011531353
step: 290, loss: 0.1988295316696167
step: 300, loss: 0.10262918472290039
step: 310, loss: 0.12753358483314514
step: 320, loss: 0.18061277270317078
step: 330, loss: 0.02384459413588047
epoch 2: dev_f1=0.7716186252771619, f1=0.7602591792656588, best_f1=0.7602591792656588
step: 0, loss: 0.09705613553524017
step: 10, loss: 0.1589127480983734
step: 20, loss: 0.1697157770395279
step: 30, loss: 0.2353409081697464
step: 40, loss: 0.14264358580112457
step: 50, loss: 0.1070665493607521
step: 60, loss: 0.14514589309692383
step: 70, loss: 0.07802043110132217
step: 80, loss: 0.14178940653800964
step: 90, loss: 0.13364394009113312
step: 100, loss: 0.07986747473478317
step: 110, loss: 0.11562615633010864
step: 120, loss: 0.2971275746822357
step: 130, loss: 0.025157103314995766
step: 140, loss: 0.13919442892074585
step: 150, loss: 0.1057497188448906
step: 160, loss: 0.25880199670791626
step: 170, loss: 0.11744721978902817
step: 180, loss: 0.13888323307037354
step: 190, loss: 0.056523073464632034
step: 200, loss: 0.1295602172613144
step: 210, loss: 0.19014868140220642
step: 220, loss: 0.10429057478904724
step: 230, loss: 0.02773725613951683
step: 240, loss: 0.1663551926612854
step: 250, loss: 0.14422304928302765
step: 260, loss: 0.05971825122833252
step: 270, loss: 0.12522512674331665
step: 280, loss: 0.03745384141802788
step: 290, loss: 0.19045105576515198
step: 300, loss: 0.07236871868371964
step: 310, loss: 0.04739023745059967
step: 320, loss: 0.10885920375585556
step: 330, loss: 0.20336490869522095
epoch 3: dev_f1=0.7980049875311721, f1=0.7838479809976248, best_f1=0.7838479809976248
step: 0, loss: 0.04491305723786354
step: 10, loss: 0.08418846875429153
step: 20, loss: 0.16418907046318054
step: 30, loss: 0.0741213783621788
step: 40, loss: 0.11745582520961761
step: 50, loss: 0.12431858479976654
step: 60, loss: 0.04801914840936661
step: 70, loss: 0.12228511273860931
step: 80, loss: 0.0885782241821289
step: 90, loss: 0.0488414391875267
step: 100, loss: 0.03814798220992088
step: 110, loss: 0.10934919863939285
step: 120, loss: 0.08266258984804153
step: 130, loss: 0.07558010518550873
step: 140, loss: 0.1406097710132599
step: 150, loss: 0.09889358282089233
step: 160, loss: 0.22481819987297058
step: 170, loss: 0.1407812237739563
step: 180, loss: 0.19499659538269043
step: 190, loss: 0.0902719646692276
step: 200, loss: 0.1543128341436386
step: 210, loss: 0.07104447484016418
step: 220, loss: 0.057637110352516174
step: 230, loss: 0.041832778602838516
step: 240, loss: 0.27857938408851624
step: 250, loss: 0.09524571895599365
step: 260, loss: 0.169041246175766
step: 270, loss: 0.17087572813034058
step: 280, loss: 0.06836497783660889
step: 290, loss: 0.13537056744098663
step: 300, loss: 0.07473757863044739
step: 310, loss: 0.22224506735801697
step: 320, loss: 0.11425430327653885
step: 330, loss: 0.045141126960515976
epoch 4: dev_f1=0.8034934497816594, f1=0.7861771058315334, best_f1=0.7861771058315334
step: 0, loss: 0.12107940018177032
step: 10, loss: 0.05522499606013298
step: 20, loss: 0.012743120081722736
step: 30, loss: 0.026870498433709145
step: 40, loss: 0.11887844651937485
step: 50, loss: 0.061701852828264236
step: 60, loss: 0.02101355604827404
step: 70, loss: 0.06606467813253403
step: 80, loss: 0.05864725261926651
step: 90, loss: 0.14877812564373016
step: 100, loss: 0.12503989040851593
step: 110, loss: 0.07396384328603745
step: 120, loss: 0.057839684188365936
step: 130, loss: 0.05131284147500992
step: 140, loss: 0.12972164154052734
step: 150, loss: 0.1541614681482315
step: 160, loss: 0.10179045796394348
step: 170, loss: 0.3591574728488922
step: 180, loss: 0.08336231857538223
step: 190, loss: 0.06057233363389969
step: 200, loss: 0.15564462542533875
step: 210, loss: 0.12707486748695374
step: 220, loss: 0.07439097762107849
step: 230, loss: 0.1585753858089447
step: 240, loss: 0.0634748563170433
step: 250, loss: 0.14224743843078613
step: 260, loss: 0.24787625670433044
step: 270, loss: 0.11016779392957687
step: 280, loss: 0.12672318518161774
step: 290, loss: 0.05612718313932419
step: 300, loss: 0.0625852644443512
step: 310, loss: 0.05928732454776764
step: 320, loss: 0.05474182218313217
step: 330, loss: 0.0921555757522583
epoch 5: dev_f1=0.8163265306122449, f1=0.7685185185185185, best_f1=0.7685185185185185
step: 0, loss: 0.03450261428952217
step: 10, loss: 0.10076827555894852
step: 20, loss: 0.19465304911136627
step: 30, loss: 0.06975968927145004
step: 40, loss: 0.04367823153734207
step: 50, loss: 0.0879531055688858
step: 60, loss: 0.0588226392865181
step: 70, loss: 0.13417500257492065
step: 80, loss: 0.14757874608039856
step: 90, loss: 0.14076881110668182
step: 100, loss: 0.09428203105926514
step: 110, loss: 0.0709899514913559
step: 120, loss: 0.2364834100008011
step: 130, loss: 0.04981108009815216
step: 140, loss: 0.10690312087535858
step: 150, loss: 0.13986824452877045
step: 160, loss: 0.039954449981451035
step: 170, loss: 0.16906282305717468
step: 180, loss: 0.12485974282026291
step: 190, loss: 0.17416077852249146
step: 200, loss: 0.07297168672084808
step: 210, loss: 0.0007181034306995571
step: 220, loss: 0.23452769219875336
step: 230, loss: 0.13032367825508118
step: 240, loss: 0.109514981508255
step: 250, loss: 0.10346885025501251
step: 260, loss: 0.10180806368589401
step: 270, loss: 0.02842693403363228
step: 280, loss: 0.062334172427654266
step: 290, loss: 0.079628124833107
step: 300, loss: 0.006804074160754681
step: 310, loss: 0.08602570742368698
step: 320, loss: 0.09572066366672516
step: 330, loss: 0.14557938277721405
epoch 6: dev_f1=0.8157894736842106, f1=0.7758620689655172, best_f1=0.7685185185185185
step: 0, loss: 0.041216254234313965
step: 10, loss: 0.06303653866052628
step: 20, loss: 0.11962202936410904
step: 30, loss: 0.06580869108438492
step: 40, loss: 0.07466099411249161
step: 50, loss: 0.2535521686077118
step: 60, loss: 0.15438000857830048
step: 70, loss: 0.16836398839950562
step: 80, loss: 0.0904655009508133
step: 90, loss: 0.07971467077732086
step: 100, loss: 0.03288884460926056
step: 110, loss: 0.32178670167922974
step: 120, loss: 0.018659336492419243
step: 130, loss: 0.04939228668808937
step: 140, loss: 0.09093550592660904
step: 150, loss: 0.12919121980667114
step: 160, loss: 0.07976359874010086
step: 170, loss: 0.025437258183956146
step: 180, loss: 0.0574483722448349
step: 190, loss: 0.07192177325487137
step: 200, loss: 0.0053179142996668816
step: 210, loss: 0.17897361516952515
step: 220, loss: 0.04949039965867996
step: 230, loss: 0.15976634621620178
step: 240, loss: 0.13270416855812073
step: 250, loss: 0.0761428028345108
step: 260, loss: 0.07509144395589828
step: 270, loss: 0.06815094500780106
step: 280, loss: 0.2537584900856018
step: 290, loss: 0.1737329363822937
step: 300, loss: 0.07184547185897827
step: 310, loss: 0.059153370559215546
step: 320, loss: 0.12434976547956467
step: 330, loss: 0.16461239755153656
epoch 7: dev_f1=0.8164251207729469, f1=0.7924528301886793, best_f1=0.7924528301886793
step: 0, loss: 0.1002148985862732
step: 10, loss: 0.1330723762512207
step: 20, loss: 0.00013571229646913707
step: 30, loss: 0.05600309744477272
step: 40, loss: 0.023724636062979698
step: 50, loss: 0.11333227157592773
step: 60, loss: 0.0450456403195858
step: 70, loss: 0.12183313816785812
step: 80, loss: 0.031204862520098686
step: 90, loss: 0.07677209377288818
step: 100, loss: 0.13319917023181915
step: 110, loss: 0.1039217934012413
step: 120, loss: 0.05991962179541588
step: 130, loss: 0.047415319830179214
step: 140, loss: 0.09547096490859985
step: 150, loss: 0.0026980838738381863
step: 160, loss: 0.1890365183353424
step: 170, loss: 0.21790209412574768
step: 180, loss: 0.006863592658191919
step: 190, loss: 0.02190088853240013
step: 200, loss: 0.09566014260053635
step: 210, loss: 0.037126827985048294
step: 220, loss: 0.1036790981888771
step: 230, loss: 0.03582492470741272
step: 240, loss: 0.10558443516492844
step: 250, loss: 0.0020463671535253525
step: 260, loss: 0.042848434299230576
step: 270, loss: 0.09487093985080719
step: 280, loss: 0.1852722465991974
step: 290, loss: 0.1457042396068573
step: 300, loss: 0.11398722231388092
step: 310, loss: 0.05572099611163139
step: 320, loss: 0.09785318374633789
step: 330, loss: 0.13621212542057037
epoch 8: dev_f1=0.8257756563245824, f1=0.7971014492753623, best_f1=0.7971014492753623
step: 0, loss: 0.04439777508378029
step: 10, loss: 0.019723977893590927
step: 20, loss: 0.16529911756515503
step: 30, loss: 0.14908139407634735
step: 40, loss: 0.11973457783460617
step: 50, loss: 0.148086279630661
step: 60, loss: 0.04173365235328674
step: 70, loss: 0.10621828585863113
step: 80, loss: 0.14016284048557281
step: 90, loss: 0.08228445798158646
step: 100, loss: 0.11555080115795135
step: 110, loss: 0.0265700314193964
step: 120, loss: 0.14825810492038727
step: 130, loss: 0.05776745080947876
step: 140, loss: 0.12734034657478333
step: 150, loss: 0.10339993983507156
step: 160, loss: 0.1690153330564499
step: 170, loss: 0.13729766011238098
step: 180, loss: 0.06587202847003937
step: 190, loss: 0.0011977858375757933
step: 200, loss: 0.09850677102804184
step: 210, loss: 0.15305060148239136
step: 220, loss: 0.00065737369004637
step: 230, loss: 0.05011824145913124
step: 240, loss: 0.048140998929739
step: 250, loss: 0.10037263482809067
step: 260, loss: 0.1808549463748932
step: 270, loss: 0.07434647530317307
step: 280, loss: 0.16823752224445343
step: 290, loss: 0.06439642608165741
step: 300, loss: 0.10935282707214355
step: 310, loss: 0.13019923865795135
step: 320, loss: 0.04562315344810486
step: 330, loss: 0.1030144914984703
epoch 9: dev_f1=0.821256038647343, f1=0.8048192771084338, best_f1=0.7971014492753623
step: 0, loss: 0.16845488548278809
step: 10, loss: 0.06169939041137695
step: 20, loss: 0.12247210741043091
step: 30, loss: 0.06322823464870453
step: 40, loss: 0.02145625837147236
step: 50, loss: 0.04701761156320572
step: 60, loss: 0.09444166719913483
step: 70, loss: 0.07159630954265594
step: 80, loss: 0.14074233174324036
step: 90, loss: 0.100031778216362
step: 100, loss: 0.061918020248413086
step: 110, loss: 0.14912615716457367
step: 120, loss: 0.022192388772964478
step: 130, loss: 0.02183210663497448
step: 140, loss: 0.13031232357025146
step: 150, loss: 0.09061367064714432
step: 160, loss: 0.09019630402326584
step: 170, loss: 0.059201568365097046
step: 180, loss: 0.08841345459222794
step: 190, loss: 0.0012501428136602044
step: 200, loss: 0.05430559441447258
step: 210, loss: 0.11569907516241074
step: 220, loss: 0.16243848204612732
step: 230, loss: 0.023958396166563034
step: 240, loss: 0.021868182346224785
step: 250, loss: 0.06602781265974045
step: 260, loss: 0.021986166015267372
step: 270, loss: 0.0011753157014027238
step: 280, loss: 0.10277668386697769
step: 290, loss: 0.1129976287484169
step: 300, loss: 0.09165886044502258
step: 310, loss: 0.15363195538520813
step: 320, loss: 0.10401402413845062
step: 330, loss: 0.11578529328107834
epoch 10: dev_f1=0.8221153846153845, f1=0.7868852459016392, best_f1=0.7971014492753623
step: 0, loss: 0.07880374044179916
step: 10, loss: 0.06678362935781479
step: 20, loss: 0.08806810528039932
step: 30, loss: 0.10356061905622482
step: 40, loss: 0.1290913224220276
step: 50, loss: 0.06842006742954254
step: 60, loss: 0.23958720266819
step: 70, loss: 0.1100335419178009
step: 80, loss: 0.12592732906341553
step: 90, loss: 0.12692581117153168
step: 100, loss: 0.11508031189441681
step: 110, loss: 0.11533723771572113
step: 120, loss: 0.08156394213438034
step: 130, loss: 0.06227504089474678
step: 140, loss: 0.07413548976182938
step: 150, loss: 0.11864491552114487
step: 160, loss: 0.07105158269405365
step: 170, loss: 0.14485730230808258
step: 180, loss: 0.03610484302043915
step: 190, loss: 0.043208297342061996
step: 200, loss: 0.18790702521800995
step: 210, loss: 0.025101037696003914
step: 220, loss: 0.12108813226222992
step: 230, loss: 0.06611426174640656
step: 240, loss: 0.07429668307304382
step: 250, loss: 0.05117466300725937
step: 260, loss: 0.09780143946409225
step: 270, loss: 0.06307132542133331
step: 280, loss: 0.11585015803575516
step: 290, loss: 0.08957835286855698
step: 300, loss: 0.012539621442556381
step: 310, loss: 0.08103545755147934
step: 320, loss: 0.1302899718284607
step: 330, loss: 0.014747610315680504
epoch 11: dev_f1=0.8205128205128204, f1=0.7954022988505747, best_f1=0.7971014492753623
step: 0, loss: 0.09421216696500778
step: 10, loss: 0.1176280751824379
step: 20, loss: 0.09998022764921188
step: 30, loss: 0.09804340451955795
step: 40, loss: 0.17647439241409302
step: 50, loss: 0.13784141838550568
step: 60, loss: 0.036782387644052505
step: 70, loss: 0.016711914911866188
step: 80, loss: 0.0930323526263237
step: 90, loss: 0.06353817880153656
step: 100, loss: 0.0953885093331337
step: 110, loss: 0.1263187974691391
step: 120, loss: 0.011723998002707958
step: 130, loss: 0.09108944982290268
step: 140, loss: 0.05319195240736008
step: 150, loss: 0.05664413794875145
step: 160, loss: 0.06601749360561371
step: 170, loss: 0.09154754132032394
step: 180, loss: 0.08033709973096848
step: 190, loss: 0.08961786329746246
step: 200, loss: 0.12672601640224457
step: 210, loss: 0.092587910592556
step: 220, loss: 0.07852926105260849
step: 230, loss: 0.11434686928987503
step: 240, loss: 0.029357515275478363
step: 250, loss: 0.16116057336330414
step: 260, loss: 0.015681693330407143
step: 270, loss: 0.12354018539190292
step: 280, loss: 0.07286346703767776
step: 290, loss: 0.06681620329618454
step: 300, loss: 0.04549476131796837
step: 310, loss: 0.1294725388288498
step: 320, loss: 0.018098270520567894
step: 330, loss: 0.014585433527827263
epoch 12: dev_f1=0.8169014084507042, f1=0.7981438515081206, best_f1=0.7971014492753623
step: 0, loss: 0.07202523946762085
step: 10, loss: 0.05798594281077385
step: 20, loss: 0.07595885545015335
step: 30, loss: 0.11056254804134369
step: 40, loss: 0.014090759679675102
step: 50, loss: 0.05928298458456993
step: 60, loss: 0.09347189217805862
step: 70, loss: 0.07739502191543579
step: 80, loss: 0.1193389967083931
step: 90, loss: 0.12409678101539612
step: 100, loss: 0.17260625958442688
step: 110, loss: 0.08593038469552994
step: 120, loss: 0.09005974978208542
step: 130, loss: 0.02327844686806202
step: 140, loss: 0.028818435966968536
step: 150, loss: 0.04485652595758438
step: 160, loss: 0.047620587050914764
step: 170, loss: 0.14457854628562927
step: 180, loss: 0.06970921903848648
step: 190, loss: 0.14052465558052063
step: 200, loss: 0.04155777394771576
step: 210, loss: 0.003969444427639246
step: 220, loss: 0.052940815687179565
step: 230, loss: 0.09181807190179825
step: 240, loss: 0.14815178513526917
step: 250, loss: 0.14736300706863403
step: 260, loss: 0.0568777471780777
step: 270, loss: 0.0702824741601944
step: 280, loss: 0.03403744474053383
step: 290, loss: 0.09224993735551834
step: 300, loss: 0.10505615174770355
step: 310, loss: 0.12613391876220703
step: 320, loss: 0.10979777574539185
step: 330, loss: 0.1147751659154892
epoch 13: dev_f1=0.8119266055045871, f1=0.7873303167420815, best_f1=0.7971014492753623
step: 0, loss: 0.058512743562459946
step: 10, loss: 0.07623223960399628
step: 20, loss: 0.07434161752462387
step: 30, loss: 0.12681826949119568
step: 40, loss: 0.1693844497203827
step: 50, loss: 0.045693397521972656
step: 60, loss: 0.04625999182462692
step: 70, loss: 3.24016364174895e-05
step: 80, loss: 0.1088494285941124
step: 90, loss: 0.03536609932780266
step: 100, loss: 0.0809975415468216
step: 110, loss: 0.1145654171705246
step: 120, loss: 0.06823215633630753
step: 130, loss: 0.06919058412313461
step: 140, loss: 0.15992102026939392
step: 150, loss: 0.04692758247256279
step: 160, loss: 0.08637327700853348
step: 170, loss: 0.08107994496822357
step: 180, loss: 0.06271447986364365
step: 190, loss: 0.08883483707904816
step: 200, loss: 0.054590288549661636
step: 210, loss: 0.057586632668972015
step: 220, loss: 0.08642899990081787
step: 230, loss: 0.11234242469072342
step: 240, loss: 0.15146318078041077
step: 250, loss: 0.06124863773584366
step: 260, loss: 0.12031225860118866
step: 270, loss: 0.10462590306997299
step: 280, loss: 0.15416878461837769
step: 290, loss: 0.025014199316501617
step: 300, loss: 0.16480094194412231
step: 310, loss: 0.059398800134658813
step: 320, loss: 0.0414673276245594
step: 330, loss: 0.07549560815095901
epoch 14: dev_f1=0.8146453089244851, f1=0.7889908256880733, best_f1=0.7971014492753623
step: 0, loss: 0.04815353825688362
step: 10, loss: 0.14114737510681152
step: 20, loss: 0.05070579797029495
step: 30, loss: 0.09099692106246948
step: 40, loss: 0.020668383687734604
step: 50, loss: 0.08066798001527786
step: 60, loss: 0.04254315048456192
step: 70, loss: 0.34003302454948425
step: 80, loss: 0.057449642568826675
step: 90, loss: 0.14300142228603363
step: 100, loss: 0.08332435041666031
step: 110, loss: 0.08521221578121185
step: 120, loss: 0.048271507024765015
step: 130, loss: 0.07896487414836884
step: 140, loss: 0.08971142768859863
step: 150, loss: 0.1704646348953247
step: 160, loss: 0.15019477903842926
step: 170, loss: 0.11599214375019073
step: 180, loss: 0.1311318576335907
step: 190, loss: 0.05923278629779816
step: 200, loss: 0.07341784238815308
step: 210, loss: 0.09581724554300308
step: 220, loss: 0.07741782814264297
step: 230, loss: 0.029371798038482666
step: 240, loss: 0.1180800125002861
step: 250, loss: 0.11485445499420166
step: 260, loss: 0.1378207504749298
step: 270, loss: 0.0736585259437561
step: 280, loss: 0.08168154954910278
step: 290, loss: 0.061724260449409485
step: 300, loss: 0.1203228309750557
step: 310, loss: 0.053953032940626144
step: 320, loss: 0.05288318172097206
step: 330, loss: 0.036436885595321655
epoch 15: dev_f1=0.8283752860411899, f1=0.7990867579908676, best_f1=0.7990867579908676
step: 0, loss: 0.0656835287809372
step: 10, loss: 0.06609728932380676
step: 20, loss: 0.035599566996097565
step: 30, loss: 0.1198677197098732
step: 40, loss: 0.05210457369685173
step: 50, loss: 0.02744750678539276
step: 60, loss: 0.08538611233234406
step: 70, loss: 0.0636407807469368
step: 80, loss: 0.04661950096487999
step: 90, loss: 0.04309888184070587
step: 100, loss: 0.03397722169756889
step: 110, loss: 0.09481485933065414
step: 120, loss: 0.1283220499753952
step: 130, loss: 0.09302069246768951
step: 140, loss: 0.09755923599004745
step: 150, loss: 0.0739269033074379
step: 160, loss: 0.05844850093126297
step: 170, loss: 0.1403079777956009
step: 180, loss: 0.0966595932841301
step: 190, loss: 0.07657697051763535
step: 200, loss: 0.21561065316200256
step: 210, loss: 0.011521877720952034
step: 220, loss: 0.022141873836517334
step: 230, loss: 0.040402885526418686
step: 240, loss: 0.17369912564754486
step: 250, loss: 0.04383473843336105
step: 260, loss: 0.10546603798866272
step: 270, loss: 0.19771277904510498
step: 280, loss: 0.021143779158592224
step: 290, loss: 0.06909981369972229
step: 300, loss: 0.10542433708906174
step: 310, loss: 0.053420551121234894
step: 320, loss: 0.07373598217964172
step: 330, loss: 0.028797687962651253
epoch 16: dev_f1=0.8132387706855791, f1=0.7858823529411765, best_f1=0.7990867579908676
step: 0, loss: 0.08838550746440887
step: 10, loss: 0.04262109473347664
step: 20, loss: 0.045324619859457016
step: 30, loss: 0.08276937156915665
step: 40, loss: 0.07346289604902267
step: 50, loss: 0.05906074121594429
step: 60, loss: 0.1405802071094513
step: 70, loss: 0.06629036366939545
step: 80, loss: 0.0723244845867157
step: 90, loss: 0.021149661391973495
step: 100, loss: 0.027547530829906464
step: 110, loss: 0.04719996079802513
step: 120, loss: 0.09652712941169739
step: 130, loss: 0.11941869556903839
step: 140, loss: 0.05561982840299606
step: 150, loss: 0.06838931143283844
step: 160, loss: 0.12497580051422119
step: 170, loss: 0.09141422063112259
step: 180, loss: 0.06499636918306351
step: 190, loss: 0.057754818350076675
step: 200, loss: 0.003927743062376976
step: 210, loss: 0.0717206597328186
step: 220, loss: 0.0795610100030899
step: 230, loss: 0.13188201189041138
step: 240, loss: 0.030236108228564262
step: 250, loss: 0.09422963857650757
step: 260, loss: 0.07286615669727325
step: 270, loss: 0.014192314818501472
step: 280, loss: 0.11592705547809601
step: 290, loss: 0.05147546902298927
step: 300, loss: 0.05528859794139862
step: 310, loss: 0.06703167408704758
step: 320, loss: 0.0952027440071106
step: 330, loss: 0.09121670573949814
epoch 17: dev_f1=0.821852731591449, f1=0.7943262411347518, best_f1=0.7990867579908676
step: 0, loss: 0.11784090101718903
step: 10, loss: 0.12119802832603455
step: 20, loss: 0.06084630638360977
step: 30, loss: 0.16077180206775665
step: 40, loss: 0.09237948060035706
step: 50, loss: 0.04566764086484909
step: 60, loss: 0.08334662765264511
step: 70, loss: 0.04436604306101799
step: 80, loss: 0.04244907945394516
step: 90, loss: 0.0381692610681057
step: 100, loss: 0.16849960386753082
step: 110, loss: 0.06093805655837059
step: 120, loss: 0.13564978539943695
step: 130, loss: 0.15971118211746216
step: 140, loss: 0.043258726596832275
step: 150, loss: 0.10480307787656784
step: 160, loss: 0.08943099528551102
step: 170, loss: 0.01229364238679409
step: 180, loss: 0.09309527277946472
step: 190, loss: 0.0637897327542305
step: 200, loss: 0.05437523126602173
step: 210, loss: 0.06389446556568146
step: 220, loss: 0.10146058350801468
step: 230, loss: 0.07283567637205124
step: 240, loss: 0.11618641763925552
step: 250, loss: 0.048718832433223724
step: 260, loss: 0.005517315119504929
step: 270, loss: 0.11372242867946625
step: 280, loss: 0.0650911033153534
step: 290, loss: 0.08440262824296951
step: 300, loss: 0.06265591830015182
step: 310, loss: 0.210436150431633
step: 320, loss: 0.006552258040755987
step: 330, loss: 0.00980670191347599
epoch 18: dev_f1=0.8108108108108109, f1=0.8019323671497586, best_f1=0.7990867579908676
step: 0, loss: 0.13916060328483582
step: 10, loss: 0.09824828058481216
step: 20, loss: 0.01546426396816969
step: 30, loss: 0.04030240699648857
step: 40, loss: 0.04091429337859154
step: 50, loss: 0.1494007110595703
step: 60, loss: 0.08585955947637558
step: 70, loss: 0.03578755632042885
step: 80, loss: 0.07110900431871414
step: 90, loss: 0.07953377068042755
step: 100, loss: 0.08434212952852249
step: 110, loss: 0.14099039137363434
step: 120, loss: 2.7989271984552033e-05
step: 130, loss: 0.05314895510673523
step: 140, loss: 0.07011791318655014
step: 150, loss: 0.06225397810339928
step: 160, loss: 0.1131211519241333
step: 170, loss: 0.04815657436847687
step: 180, loss: 0.11850252002477646
step: 190, loss: 0.06688795983791351
step: 200, loss: 0.14165633916854858
step: 210, loss: 0.029671836644411087
step: 220, loss: 0.019120927900075912
step: 230, loss: 0.08324539661407471
step: 240, loss: 0.09876794368028641
step: 250, loss: 0.16833610832691193
step: 260, loss: 0.14677481353282928
step: 270, loss: 0.01712922938168049
step: 280, loss: 0.025485433638095856
step: 290, loss: 0.05370910465717316
step: 300, loss: 0.07214932143688202
step: 310, loss: 0.0742904543876648
step: 320, loss: 0.07329641282558441
step: 330, loss: 0.10640957951545715
epoch 19: dev_f1=0.8097560975609757, f1=0.7971014492753623, best_f1=0.7990867579908676
step: 0, loss: 0.061565741896629333
step: 10, loss: 0.07952029258012772
step: 20, loss: 0.022321686148643494
step: 30, loss: 0.03622329235076904
step: 40, loss: 0.1640089750289917
step: 50, loss: 0.08083226531744003
step: 60, loss: 0.11785218864679337
step: 70, loss: 0.08928018808364868
step: 80, loss: 0.033075813204050064
step: 90, loss: 0.1371614634990692
step: 100, loss: 0.11129026114940643
step: 110, loss: 0.060257550328969955
step: 120, loss: 0.08372226357460022
step: 130, loss: 0.04890316724777222
step: 140, loss: 0.07764160633087158
step: 150, loss: 0.07002236694097519
step: 160, loss: 0.14803901314735413
step: 170, loss: 0.004010441713035107
step: 180, loss: 0.10872478783130646
step: 190, loss: 0.14301533997058868
step: 200, loss: 0.08201313763856888
step: 210, loss: 0.08318701386451721
step: 220, loss: 0.06509745866060257
step: 230, loss: 0.06784097850322723
step: 240, loss: 0.08608635514974594
step: 250, loss: 0.0746663436293602
step: 260, loss: 0.050465889275074005
step: 270, loss: 0.07421679049730301
step: 280, loss: 0.06536883860826492
step: 290, loss: 0.012104028835892677
step: 300, loss: 0.06766513735055923
step: 310, loss: 0.008165731094777584
step: 320, loss: 0.028068765997886658
step: 330, loss: 0.13698896765708923
epoch 20: dev_f1=0.8166259168704155, f1=0.7990314769975787, best_f1=0.7990867579908676
