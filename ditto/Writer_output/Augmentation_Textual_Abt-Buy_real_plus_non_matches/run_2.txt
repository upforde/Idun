cuda
Device: cuda
step: 0, loss: 0.8868721723556519
step: 10, loss: 0.36524727940559387
step: 20, loss: 0.06462365388870239
step: 30, loss: 0.47648850083351135
step: 40, loss: 0.23717060685157776
step: 50, loss: 0.14534980058670044
step: 60, loss: 0.3253123164176941
step: 70, loss: 0.3122319281101227
step: 80, loss: 0.23190738260746002
step: 90, loss: 0.22483539581298828
step: 100, loss: 0.3924824297428131
step: 110, loss: 0.22125042974948883
step: 120, loss: 0.22894316911697388
step: 130, loss: 0.21981917321681976
step: 140, loss: 0.03181316703557968
step: 150, loss: 0.07497579604387283
step: 160, loss: 0.2279021441936493
step: 170, loss: 0.16097068786621094
step: 180, loss: 0.3544667065143585
step: 190, loss: 0.3436952531337738
step: 200, loss: 0.31947633624076843
step: 210, loss: 0.15799759328365326
step: 220, loss: 0.3010156452655792
step: 230, loss: 0.23438218235969543
step: 240, loss: 0.04464937373995781
step: 250, loss: 0.4238772690296173
step: 260, loss: 0.028179997578263283
step: 270, loss: 0.10790267586708069
step: 280, loss: 0.3046387732028961
step: 290, loss: 0.10626143962144852
step: 300, loss: 0.42106980085372925
step: 310, loss: 0.09936761111021042
step: 320, loss: 0.12963466346263885
step: 330, loss: 0.07387333363294601
epoch 1: dev_f1=0.6168674698795181, f1=0.6009174311926606, best_f1=0.6009174311926606
step: 0, loss: 0.2022586464881897
step: 10, loss: 0.12008760124444962
step: 20, loss: 0.3142731785774231
step: 30, loss: 0.15126414597034454
step: 40, loss: 0.10098370164632797
step: 50, loss: 0.15083825588226318
step: 60, loss: 0.22916178405284882
step: 70, loss: 0.22232355177402496
step: 80, loss: 0.03956850618124008
step: 90, loss: 0.1686621606349945
step: 100, loss: 0.18546898663043976
step: 110, loss: 0.1456269472837448
step: 120, loss: 0.024460965767502785
step: 130, loss: 0.0397854819893837
step: 140, loss: 0.12791045010089874
step: 150, loss: 0.2986496686935425
step: 160, loss: 0.26097571849823
step: 170, loss: 0.08724107593297958
step: 180, loss: 0.05275273695588112
step: 190, loss: 0.08709563314914703
step: 200, loss: 0.2062564641237259
step: 210, loss: 0.23713329434394836
step: 220, loss: 0.11165232211351395
step: 230, loss: 0.08455080538988113
step: 240, loss: 0.09720297157764435
step: 250, loss: 0.08785329014062881
step: 260, loss: 0.07545962929725647
step: 270, loss: 0.06476832926273346
step: 280, loss: 0.015428117476403713
step: 290, loss: 0.09023081511259079
step: 300, loss: 0.12211983650922775
step: 310, loss: 0.0920502319931984
step: 320, loss: 0.15165242552757263
step: 330, loss: 0.0807683989405632
epoch 2: dev_f1=0.7543424317617866, f1=0.7518072289156627, best_f1=0.7518072289156627
step: 0, loss: 0.2241034209728241
step: 10, loss: 0.1511327475309372
step: 20, loss: 0.06385935097932816
step: 30, loss: 0.25831976532936096
step: 40, loss: 0.05993443727493286
step: 50, loss: 0.06854882091283798
step: 60, loss: 0.11489793658256531
step: 70, loss: 0.0964849591255188
step: 80, loss: 0.10222222656011581
step: 90, loss: 0.08039233833551407
step: 100, loss: 0.18405236303806305
step: 110, loss: 0.07029799371957779
step: 120, loss: 0.10551588237285614
step: 130, loss: 0.11352952569723129
step: 140, loss: 0.023603133857250214
step: 150, loss: 0.16404137015342712
step: 160, loss: 0.05566239356994629
step: 170, loss: 0.11796829104423523
step: 180, loss: 0.07662325352430344
step: 190, loss: 0.12475962936878204
step: 200, loss: 0.12034613639116287
step: 210, loss: 0.2417128086090088
step: 220, loss: 0.16549566388130188
step: 230, loss: 0.1445942521095276
step: 240, loss: 0.0613691620528698
step: 250, loss: 0.024292808026075363
step: 260, loss: 0.17192301154136658
step: 270, loss: 0.17638520896434784
step: 280, loss: 0.05519513785839081
step: 290, loss: 0.31664058566093445
step: 300, loss: 0.10997536033391953
step: 310, loss: 0.13194844126701355
step: 320, loss: 0.0345822349190712
step: 330, loss: 0.04006660729646683
epoch 3: dev_f1=0.7499999999999999, f1=0.7610208816705337, best_f1=0.7518072289156627
step: 0, loss: 0.0631486251950264
step: 10, loss: 0.0640714094042778
step: 20, loss: 0.12656842172145844
step: 30, loss: 0.13115091621875763
step: 40, loss: 0.08375204354524612
step: 50, loss: 0.04641168192028999
step: 60, loss: 0.07274803519248962
step: 70, loss: 0.06229463592171669
step: 80, loss: 0.047275133430957794
step: 90, loss: 0.11368530243635178
step: 100, loss: 0.13996943831443787
step: 110, loss: 0.0682649314403534
step: 120, loss: 0.09168592840433121
step: 130, loss: 0.06192583590745926
step: 140, loss: 0.17608708143234253
step: 150, loss: 0.055339548736810684
step: 160, loss: 0.07693848758935928
step: 170, loss: 0.10840296745300293
step: 180, loss: 0.07440932095050812
step: 190, loss: 0.07920800894498825
step: 200, loss: 0.2036040872335434
step: 210, loss: 0.1834622174501419
step: 220, loss: 0.032758381217718124
step: 230, loss: 0.06461653858423233
step: 240, loss: 0.05973617359995842
step: 250, loss: 0.06223540008068085
step: 260, loss: 0.19222968816757202
step: 270, loss: 0.0406685546040535
step: 280, loss: 0.18200406432151794
step: 290, loss: 0.08082737773656845
step: 300, loss: 0.055652618408203125
step: 310, loss: 0.07901785522699356
step: 320, loss: 0.11437012255191803
step: 330, loss: 0.05175521969795227
epoch 4: dev_f1=0.8018648018648018, f1=0.782608695652174, best_f1=0.782608695652174
step: 0, loss: 0.09394223988056183
step: 10, loss: 0.054396022111177444
step: 20, loss: 0.16607467830181122
step: 30, loss: 0.08119358122348785
step: 40, loss: 0.05578483268618584
step: 50, loss: 0.07750828564167023
step: 60, loss: 0.13096675276756287
step: 70, loss: 0.1633765995502472
step: 80, loss: 0.09182245284318924
step: 90, loss: 0.03437124192714691
step: 100, loss: 0.029434865340590477
step: 110, loss: 0.15276964008808136
step: 120, loss: 0.05767213925719261
step: 130, loss: 0.13095563650131226
step: 140, loss: 0.0876428559422493
step: 150, loss: 0.11077573150396347
step: 160, loss: 0.2623480260372162
step: 170, loss: 0.09461796283721924
step: 180, loss: 0.08493015915155411
step: 190, loss: 0.1313900500535965
step: 200, loss: 0.13774360716342926
step: 210, loss: 0.06910429149866104
step: 220, loss: 0.10688651353120804
step: 230, loss: 0.16483117640018463
step: 240, loss: 0.028813503682613373
step: 250, loss: 0.14927884936332703
step: 260, loss: 0.08652009069919586
step: 270, loss: 0.07551275193691254
step: 280, loss: 0.03613527864217758
step: 290, loss: 0.12573882937431335
step: 300, loss: 0.0590442530810833
step: 310, loss: 0.06554058939218521
step: 320, loss: 0.04325172305107117
step: 330, loss: 0.18653948605060577
epoch 5: dev_f1=0.7652582159624414, f1=0.7770114942528735, best_f1=0.782608695652174
step: 0, loss: 0.10336518287658691
step: 10, loss: 0.07592625916004181
step: 20, loss: 0.06298542767763138
step: 30, loss: 0.07726602256298065
step: 40, loss: 0.21109257638454437
step: 50, loss: 0.10237053781747818
step: 60, loss: 0.08369256556034088
step: 70, loss: 0.11400443315505981
step: 80, loss: 0.06751488894224167
step: 90, loss: 0.1436685472726822
step: 100, loss: 0.059011977165937424
step: 110, loss: 0.11709415912628174
step: 120, loss: 0.13181863725185394
step: 130, loss: 0.15644194185733795
step: 140, loss: 0.09945511072874069
step: 150, loss: 0.0858350321650505
step: 160, loss: 0.041640494018793106
step: 170, loss: 0.026688361540436745
step: 180, loss: 0.07757649570703506
step: 190, loss: 0.09997010976076126
step: 200, loss: 0.09031613916158676
step: 210, loss: 0.1897141933441162
step: 220, loss: 0.08869956433773041
step: 230, loss: 0.09039510786533356
step: 240, loss: 0.08680243045091629
step: 250, loss: 0.18778063356876373
step: 260, loss: 0.09398002177476883
step: 270, loss: 0.05434979870915413
step: 280, loss: 0.017704162746667862
step: 290, loss: 0.058084987103939056
step: 300, loss: 0.13286177814006805
step: 310, loss: 0.39197126030921936
step: 320, loss: 0.14520308375358582
step: 330, loss: 0.027787761762738228
epoch 6: dev_f1=0.8117913832199547, f1=0.788546255506608, best_f1=0.788546255506608
step: 0, loss: 0.18772241473197937
step: 10, loss: 0.07649070769548416
step: 20, loss: 0.044768206775188446
step: 30, loss: 0.14546161890029907
step: 40, loss: 0.03101951628923416
step: 50, loss: 0.051452089101076126
step: 60, loss: 0.043457094579935074
step: 70, loss: 0.13116593658924103
step: 80, loss: 0.15864700078964233
step: 90, loss: 0.15509749948978424
step: 100, loss: 0.10460864007472992
step: 110, loss: 0.06742396950721741
step: 120, loss: 0.057138990610837936
step: 130, loss: 0.012616312131285667
step: 140, loss: 0.17629656195640564
step: 150, loss: 0.2436334639787674
step: 160, loss: 0.03996652737259865
step: 170, loss: 0.07590652257204056
step: 180, loss: 0.07487273961305618
step: 190, loss: 0.10886409878730774
step: 200, loss: 0.14396032691001892
step: 210, loss: 0.1231682300567627
step: 220, loss: 0.09225954860448837
step: 230, loss: 0.08493504673242569
step: 240, loss: 0.02453475445508957
step: 250, loss: 0.0741167962551117
step: 260, loss: 0.07750769704580307
step: 270, loss: 0.1167326420545578
step: 280, loss: 0.1717829406261444
step: 290, loss: 0.0888914242386818
step: 300, loss: 0.07873426377773285
step: 310, loss: 0.12235227227210999
step: 320, loss: 0.08331048488616943
step: 330, loss: 0.09954164177179337
epoch 7: dev_f1=0.8056206088992974, f1=0.7925407925407925, best_f1=0.788546255506608
step: 0, loss: 0.03095400519669056
step: 10, loss: 0.09426543861627579
step: 20, loss: 0.05147593095898628
step: 30, loss: 0.05277499184012413
step: 40, loss: 0.0808100774884224
step: 50, loss: 0.12199921160936356
step: 60, loss: 0.0812082514166832
step: 70, loss: 0.09534516930580139
step: 80, loss: 0.09975453466176987
step: 90, loss: 0.05778803676366806
step: 100, loss: 0.08783441036939621
step: 110, loss: 0.16076970100402832
step: 120, loss: 0.1825457364320755
step: 130, loss: 0.07306232303380966
step: 140, loss: 0.05450775846838951
step: 150, loss: 0.1203434094786644
step: 160, loss: 0.04779830202460289
step: 170, loss: 0.1274918168783188
step: 180, loss: 0.07561006397008896
step: 190, loss: 0.054630763828754425
step: 200, loss: 0.11249388754367828
step: 210, loss: 0.0461207814514637
step: 220, loss: 0.12556537985801697
step: 230, loss: 0.13180352747440338
step: 240, loss: 0.20789456367492676
step: 250, loss: 0.043672189116477966
step: 260, loss: 0.049854837357997894
step: 270, loss: 0.027065377682447433
step: 280, loss: 0.08216461539268494
step: 290, loss: 0.04244992509484291
step: 300, loss: 0.15784358978271484
step: 310, loss: 0.07340104132890701
step: 320, loss: 0.11403835564851761
step: 330, loss: 0.09655189514160156
epoch 8: dev_f1=0.8070175438596492, f1=0.7892156862745098, best_f1=0.788546255506608
step: 0, loss: 0.12508565187454224
step: 10, loss: 0.2722020447254181
step: 20, loss: 0.13422192633152008
step: 30, loss: 0.06664231419563293
step: 40, loss: 0.055396001785993576
step: 50, loss: 0.09477100521326065
step: 60, loss: 0.16858099400997162
step: 70, loss: 0.09033367037773132
step: 80, loss: 0.18348222970962524
step: 90, loss: 0.012999732978641987
step: 100, loss: 0.04540100693702698
step: 110, loss: 0.11679138988256454
step: 120, loss: 0.180428609251976
step: 130, loss: 0.10630062222480774
step: 140, loss: 0.06205092743039131
step: 150, loss: 0.13574883341789246
step: 160, loss: 0.1421850025653839
step: 170, loss: 0.09386713057756424
step: 180, loss: 0.13053175806999207
step: 190, loss: 0.13182035088539124
step: 200, loss: 0.09424443542957306
step: 210, loss: 0.08151909708976746
step: 220, loss: 0.10020071268081665
step: 230, loss: 0.0785476341843605
step: 240, loss: 0.08935073763132095
step: 250, loss: 0.1131032332777977
step: 260, loss: 0.05605638399720192
step: 270, loss: 0.0866660624742508
step: 280, loss: 0.09925734996795654
step: 290, loss: 0.07292044907808304
step: 300, loss: 0.04248783737421036
step: 310, loss: 0.10644342005252838
step: 320, loss: 0.06895443797111511
step: 330, loss: 0.15050148963928223
epoch 9: dev_f1=0.7939698492462312, f1=0.7931873479318734, best_f1=0.788546255506608
step: 0, loss: 0.09007930755615234
step: 10, loss: 0.0006485382909886539
step: 20, loss: 0.14283965528011322
step: 30, loss: 0.08243918418884277
step: 40, loss: 0.0758020281791687
step: 50, loss: 0.1319589614868164
step: 60, loss: 0.019839491695165634
step: 70, loss: 0.06844599545001984
step: 80, loss: 0.10222101956605911
step: 90, loss: 0.04888204112648964
step: 100, loss: 0.04882063344120979
step: 110, loss: 0.042937710881233215
step: 120, loss: 0.11558985710144043
step: 130, loss: 0.07565826922655106
step: 140, loss: 0.11663340777158737
step: 150, loss: 0.046698011457920074
step: 160, loss: 0.13140812516212463
step: 170, loss: 0.07083851099014282
step: 180, loss: 0.024899467825889587
step: 190, loss: 0.037864793092012405
step: 200, loss: 0.04609222337603569
step: 210, loss: 0.10663293302059174
step: 220, loss: 0.04917885363101959
step: 230, loss: 0.09671749919652939
step: 240, loss: 0.054594919085502625
step: 250, loss: 0.06431028991937637
step: 260, loss: 0.15821842849254608
step: 270, loss: 0.15165802836418152
step: 280, loss: 0.14910836517810822
step: 290, loss: 0.07176869362592697
step: 300, loss: 0.15256527066230774
step: 310, loss: 0.03563569486141205
step: 320, loss: 0.14599859714508057
step: 330, loss: 0.018375063315033913
epoch 10: dev_f1=0.8036117381489841, f1=0.7824175824175823, best_f1=0.788546255506608
step: 0, loss: 0.1785374879837036
step: 10, loss: 0.08505290746688843
step: 20, loss: 0.05957812815904617
step: 30, loss: 0.1054268628358841
step: 40, loss: 0.060232989490032196
step: 50, loss: 0.18883337080478668
step: 60, loss: 0.07762958109378815
step: 70, loss: 0.14559894800186157
step: 80, loss: 0.09119076281785965
step: 90, loss: 0.060694798827171326
step: 100, loss: 0.1669265627861023
step: 110, loss: 0.18744897842407227
step: 120, loss: 0.11386283487081528
step: 130, loss: 0.07215423136949539
step: 140, loss: 0.06610088795423508
step: 150, loss: 0.06328286975622177
step: 160, loss: 0.06052830442786217
step: 170, loss: 0.10473091155290604
step: 180, loss: 0.04483921825885773
step: 190, loss: 0.05000078305602074
step: 200, loss: 0.06094498187303543
step: 210, loss: 0.06821674108505249
step: 220, loss: 0.09601370245218277
step: 230, loss: 0.11533396691083908
step: 240, loss: 0.0730254054069519
step: 250, loss: 0.07648499310016632
step: 260, loss: 0.12950490415096283
step: 270, loss: 0.10329202562570572
step: 280, loss: 0.02759707160294056
step: 290, loss: 0.08743367344141006
step: 300, loss: 0.11826466023921967
step: 310, loss: 0.11136612296104431
step: 320, loss: 0.034755777567625046
step: 330, loss: 0.1659264862537384
epoch 11: dev_f1=0.8125000000000001, f1=0.811965811965812, best_f1=0.811965811965812
step: 0, loss: 0.053291916847229004
step: 10, loss: 0.11164896190166473
step: 20, loss: 0.08101483434438705
step: 30, loss: 0.06779365241527557
step: 40, loss: 0.16690632700920105
step: 50, loss: 0.067940853536129
step: 60, loss: 0.03055085614323616
step: 70, loss: 0.10346468538045883
step: 80, loss: 0.07708056271076202
step: 90, loss: 0.15663351118564606
step: 100, loss: 0.11139746755361557
step: 110, loss: 0.06872877478599548
step: 120, loss: 0.09256803244352341
step: 130, loss: 0.016347136348485947
step: 140, loss: 0.019273817539215088
step: 150, loss: 0.05975213274359703
step: 160, loss: 0.03904544189572334
step: 170, loss: 0.22605852782726288
step: 180, loss: 0.08242291957139969
step: 190, loss: 0.07361060380935669
step: 200, loss: 0.10292291641235352
step: 210, loss: 0.1966673880815506
step: 220, loss: 0.05532972887158394
step: 230, loss: 0.016428707167506218
step: 240, loss: 0.17829282581806183
step: 250, loss: 0.06235984340310097
step: 260, loss: 0.07835187762975693
step: 270, loss: 0.15160225331783295
step: 280, loss: 0.059789422899484634
step: 290, loss: 0.058438051491975784
step: 300, loss: 0.1185298040509224
step: 310, loss: 0.0723823830485344
step: 320, loss: 0.052701450884342194
step: 330, loss: 0.09550885111093521
epoch 12: dev_f1=0.801909307875895, f1=0.7944572748267898, best_f1=0.811965811965812
step: 0, loss: 0.12040172517299652
step: 10, loss: 0.018789982423186302
step: 20, loss: 0.03039935603737831
step: 30, loss: 7.617218216182664e-05
step: 40, loss: 0.08367381244897842
step: 50, loss: 0.0707736387848854
step: 60, loss: 0.019585033878684044
step: 70, loss: 0.040983837097883224
step: 80, loss: 0.2229778915643692
step: 90, loss: 0.14393532276153564
step: 100, loss: 0.06529271602630615
step: 110, loss: 0.07533140480518341
step: 120, loss: 0.038170378655195236
step: 130, loss: 0.12027978897094727
step: 140, loss: 0.0367431603372097
step: 150, loss: 0.09306400269269943
step: 160, loss: 0.1371689736843109
step: 170, loss: 0.07958653569221497
step: 180, loss: 0.1298374980688095
step: 190, loss: 0.030059386044740677
step: 200, loss: 0.04860579967498779
step: 210, loss: 0.08146578073501587
step: 220, loss: 0.057701196521520615
step: 230, loss: 0.0678456574678421
step: 240, loss: 0.06309714168310165
step: 250, loss: 0.15320894122123718
step: 260, loss: 0.11008044332265854
step: 270, loss: 0.08185987174510956
step: 280, loss: 0.09682077914476395
step: 290, loss: 0.05605541914701462
step: 300, loss: 0.17215417325496674
step: 310, loss: 0.09543857723474503
step: 320, loss: 0.2125399112701416
step: 330, loss: 0.0757741928100586
epoch 13: dev_f1=0.815165876777251, f1=0.791762013729977, best_f1=0.791762013729977
step: 0, loss: 0.20853134989738464
step: 10, loss: 0.05275287479162216
step: 20, loss: 0.06822960823774338
step: 30, loss: 0.11701875180006027
step: 40, loss: 0.06067294627428055
step: 50, loss: 0.05558256804943085
step: 60, loss: 0.0588846430182457
step: 70, loss: 0.02541603334248066
step: 80, loss: 0.0356871671974659
step: 90, loss: 0.09827791154384613
step: 100, loss: 0.14152507483959198
step: 110, loss: 0.10690771043300629
step: 120, loss: 0.08872102200984955
step: 130, loss: 0.19457630813121796
step: 140, loss: 0.1104072779417038
step: 150, loss: 0.08935852348804474
step: 160, loss: 0.025197284296154976
step: 170, loss: 0.047532808035612106
step: 180, loss: 0.13022737205028534
step: 190, loss: 0.08572487533092499
step: 200, loss: 0.06432230025529861
step: 210, loss: 0.11852473020553589
step: 220, loss: 0.08261334896087646
step: 230, loss: 0.08626903593540192
step: 240, loss: 0.17917628586292267
step: 250, loss: 0.06145133823156357
step: 260, loss: 0.07308869063854218
step: 270, loss: 0.03560442849993706
step: 280, loss: 0.15871204435825348
step: 290, loss: 0.0267128087580204
step: 300, loss: 0.13090629875659943
step: 310, loss: 0.06604234129190445
step: 320, loss: 0.1397940069437027
step: 330, loss: 0.05870305746793747
epoch 14: dev_f1=0.8076923076923078, f1=0.7990654205607476, best_f1=0.791762013729977
step: 0, loss: 0.03653865307569504
step: 10, loss: 0.10255781561136246
step: 20, loss: 0.16017194092273712
step: 30, loss: 0.038129497319459915
step: 40, loss: 0.07203926891088486
step: 50, loss: 0.02545624040067196
step: 60, loss: 0.048756957054138184
step: 70, loss: 0.07429400831460953
step: 80, loss: 0.22069120407104492
step: 90, loss: 0.07561745494604111
step: 100, loss: 0.10230052471160889
step: 110, loss: 0.05618993192911148
step: 120, loss: 0.10644977539777756
step: 130, loss: 0.0190255269408226
step: 140, loss: 0.04420716315507889
step: 150, loss: 0.0290120430290699
step: 160, loss: 0.05800304561853409
step: 170, loss: 0.040360547602176666
step: 180, loss: 0.13056312501430511
step: 190, loss: 0.08377844840288162
step: 200, loss: 0.08922149240970612
step: 210, loss: 0.06902133673429489
step: 220, loss: 0.16385439038276672
step: 230, loss: 0.13712462782859802
step: 240, loss: 0.12617914378643036
step: 250, loss: 0.1186821237206459
step: 260, loss: 0.06272603571414948
step: 270, loss: 0.02890462800860405
step: 280, loss: 0.07610034197568893
step: 290, loss: 0.07869800180196762
step: 300, loss: 0.08295585960149765
step: 310, loss: 0.009837908670306206
step: 320, loss: 0.09625811874866486
step: 330, loss: 0.01926208660006523
epoch 15: dev_f1=0.8, f1=0.7973568281938326, best_f1=0.791762013729977
step: 0, loss: 0.057334113866090775
step: 10, loss: 0.049902867525815964
step: 20, loss: 0.103358194231987
step: 30, loss: 0.061470162123441696
step: 40, loss: 0.06929049640893936
step: 50, loss: 0.05112205818295479
step: 60, loss: 0.07031217962503433
step: 70, loss: 0.15341241657733917
step: 80, loss: 0.03561195358633995
step: 90, loss: 0.10017817467451096
step: 100, loss: 0.0440804660320282
step: 110, loss: 6.975902942940593e-05
step: 120, loss: 0.0543387234210968
step: 130, loss: 0.10122053325176239
step: 140, loss: 0.06852975487709045
step: 150, loss: 0.09561530500650406
step: 160, loss: 0.09961079806089401
step: 170, loss: 0.0928860679268837
step: 180, loss: 0.010423453524708748
step: 190, loss: 0.07703100889921188
step: 200, loss: 0.071661576628685
step: 210, loss: 0.04647316411137581
step: 220, loss: 0.06458831578493118
step: 230, loss: 0.05995931103825569
step: 240, loss: 0.15155713260173798
step: 250, loss: 0.043549153953790665
step: 260, loss: 0.13937915861606598
step: 270, loss: 0.11640578508377075
step: 280, loss: 0.08114293962717056
step: 290, loss: 0.051835548132658005
step: 300, loss: 0.09198426455259323
step: 310, loss: 0.08571305125951767
step: 320, loss: 0.12535321712493896
step: 330, loss: 0.05508292838931084
epoch 16: dev_f1=0.8059701492537313, f1=0.7990314769975787, best_f1=0.791762013729977
step: 0, loss: 0.03817567229270935
step: 10, loss: 0.042223453521728516
step: 20, loss: 0.08799765259027481
step: 30, loss: 0.024496208876371384
step: 40, loss: 0.1428733915090561
step: 50, loss: 0.035797275602817535
step: 60, loss: 0.014955615624785423
step: 70, loss: 0.14530472457408905
step: 80, loss: 0.1094990223646164
step: 90, loss: 0.03849533572793007
step: 100, loss: 0.11124084889888763
step: 110, loss: 0.021656647324562073
step: 120, loss: 0.07987337559461594
step: 130, loss: 0.13214457035064697
step: 140, loss: 0.08024632930755615
step: 150, loss: 0.10147928446531296
step: 160, loss: 0.013531033881008625
step: 170, loss: 0.05850762501358986
step: 180, loss: 0.08865620195865631
step: 190, loss: 0.07851017266511917
step: 200, loss: 0.0605803020298481
step: 210, loss: 0.04764503240585327
step: 220, loss: 0.09256594628095627
step: 230, loss: 0.039764486253261566
step: 240, loss: 0.09127259999513626
step: 250, loss: 0.0848691388964653
step: 260, loss: 0.0003100718022324145
step: 270, loss: 0.11404457688331604
step: 280, loss: 0.06323310732841492
step: 290, loss: 0.04793586954474449
step: 300, loss: 0.05193344131112099
step: 310, loss: 0.04208702966570854
step: 320, loss: 0.021453378722071648
step: 330, loss: 0.04977487027645111
epoch 17: dev_f1=0.7889447236180904, f1=0.7961165048543688, best_f1=0.791762013729977
step: 0, loss: 0.14515812695026398
step: 10, loss: 0.0282488651573658
step: 20, loss: 0.004442995879799128
step: 30, loss: 0.062242504209280014
step: 40, loss: 0.043576132506132126
step: 50, loss: 0.06989248842000961
step: 60, loss: 0.1186918318271637
step: 70, loss: 0.06864864379167557
step: 80, loss: 0.10775230079889297
step: 90, loss: 0.10588683933019638
step: 100, loss: 0.12723517417907715
step: 110, loss: 0.04346565529704094
step: 120, loss: 0.021928729489445686
step: 130, loss: 0.07842127978801727
step: 140, loss: 0.0681309700012207
step: 150, loss: 0.08298714458942413
step: 160, loss: 0.023127160966396332
step: 170, loss: 0.07353372126817703
step: 180, loss: 0.0743018165230751
step: 190, loss: 0.17238643765449524
step: 200, loss: 0.18895727396011353
step: 210, loss: 0.17100802063941956
step: 220, loss: 0.04908626154065132
step: 230, loss: 0.04707223176956177
step: 240, loss: 0.05378365144133568
step: 250, loss: 0.08125235885381699
step: 260, loss: 0.13603299856185913
step: 270, loss: 0.08399096876382828
step: 280, loss: 0.038187477737665176
step: 290, loss: 0.058185018599033356
step: 300, loss: 0.1701197326183319
step: 310, loss: 0.03806360810995102
step: 320, loss: 0.026286209002137184
step: 330, loss: 0.12647750973701477
epoch 18: dev_f1=0.8, f1=0.8, best_f1=0.791762013729977
step: 0, loss: 0.0666755884885788
step: 10, loss: 0.09187892079353333
step: 20, loss: 0.042053014039993286
step: 30, loss: 0.05116800218820572
step: 40, loss: 0.08392619341611862
step: 50, loss: 0.037393879145383835
step: 60, loss: 0.05902351438999176
step: 70, loss: 0.07447057962417603
step: 80, loss: 0.03812152147293091
step: 90, loss: 0.028935987502336502
step: 100, loss: 0.0706031396985054
step: 110, loss: 0.023505231365561485
step: 120, loss: 0.09748134762048721
step: 130, loss: 0.00488475663587451
step: 140, loss: 0.08155237138271332
step: 150, loss: 0.08547955751419067
step: 160, loss: 0.11086738109588623
step: 170, loss: 0.04964224249124527
step: 180, loss: 0.059758853167295456
step: 190, loss: 0.011363941244781017
step: 200, loss: 0.05971347168087959
step: 210, loss: 0.03421419858932495
step: 220, loss: 0.11704465746879578
step: 230, loss: 0.06052233651280403
step: 240, loss: 0.1387912929058075
step: 250, loss: 0.00017191708320751786
step: 260, loss: 0.017497338354587555
step: 270, loss: 0.035460229963064194
step: 280, loss: 0.060717616230249405
step: 290, loss: 0.06544437259435654
step: 300, loss: 0.06426931917667389
step: 310, loss: 0.05469550937414169
step: 320, loss: 0.03266056254506111
step: 330, loss: 0.022621240466833115
epoch 19: dev_f1=0.794188861985472, f1=0.7990654205607476, best_f1=0.791762013729977
step: 0, loss: 0.08520065248012543
step: 10, loss: 0.04381987452507019
step: 20, loss: 0.09480585157871246
step: 30, loss: 0.07860073447227478
step: 40, loss: 0.08052828162908554
step: 50, loss: 0.0547301284968853
step: 60, loss: 0.006410229951143265
step: 70, loss: 0.14145256578922272
step: 80, loss: 0.029853183776140213
step: 90, loss: 0.05989747866988182
step: 100, loss: 0.07943791151046753
step: 110, loss: 0.042530931532382965
step: 120, loss: 0.03774883225560188
step: 130, loss: 0.03388405218720436
step: 140, loss: 0.0014298944734036922
step: 150, loss: 0.09953958541154861
step: 160, loss: 0.07426223903894424
step: 170, loss: 0.05008701607584953
step: 180, loss: 0.043958306312561035
step: 190, loss: 0.15511399507522583
step: 200, loss: 0.04830041527748108
step: 210, loss: 0.042741645127534866
step: 220, loss: 0.0711887925863266
step: 230, loss: 0.059055622667074203
step: 240, loss: 0.059595659375190735
step: 250, loss: 0.06091400980949402
step: 260, loss: 0.1596168726682663
step: 270, loss: 0.044001445174217224
step: 280, loss: 0.09071722626686096
step: 290, loss: 0.050965167582035065
step: 300, loss: 0.04988484084606171
step: 310, loss: 0.07981212437152863
step: 320, loss: 0.0809180811047554
step: 330, loss: 0.063740074634552
epoch 20: dev_f1=0.7961165048543688, f1=0.7990543735224587, best_f1=0.791762013729977
