cuda
Device: cuda
step: 0, loss: 0.5590143203735352
step: 10, loss: 0.1525925099849701
step: 20, loss: 0.1625152826309204
step: 30, loss: 0.2971366047859192
step: 40, loss: 0.4110024571418762
step: 50, loss: 0.4109632074832916
step: 60, loss: 0.1628553420305252
step: 70, loss: 0.12726089358329773
step: 80, loss: 0.10468428581953049
step: 90, loss: 0.23231077194213867
step: 100, loss: 0.2117050141096115
step: 110, loss: 0.3588356673717499
step: 120, loss: 0.23964306712150574
step: 130, loss: 0.33673152327537537
step: 140, loss: 0.33077576756477356
step: 150, loss: 0.040045469999313354
step: 160, loss: 0.21219320595264435
step: 170, loss: 0.24205853044986725
step: 180, loss: 0.06949910521507263
step: 190, loss: 0.16203834116458893
step: 200, loss: 0.09953710436820984
step: 210, loss: 0.0731743797659874
step: 220, loss: 0.19212175905704498
step: 230, loss: 0.17366160452365875
step: 240, loss: 0.03266742452979088
step: 250, loss: 0.12683433294296265
step: 260, loss: 0.1745765656232834
step: 270, loss: 0.19366662204265594
step: 280, loss: 0.17930565774440765
step: 290, loss: 0.17738698422908783
step: 300, loss: 0.15964403748512268
step: 310, loss: 0.22532300651073456
step: 320, loss: 0.09014551341533661
step: 330, loss: 0.145949587225914
epoch 1: dev_f1=0.6563706563706563, f1=0.6847195357833655, best_f1=0.6847195357833655
step: 0, loss: 0.14240875840187073
step: 10, loss: 0.11681012809276581
step: 20, loss: 0.14911125600337982
step: 30, loss: 0.22188791632652283
step: 40, loss: 0.042233530431985855
step: 50, loss: 0.14761735498905182
step: 60, loss: 0.09298072010278702
step: 70, loss: 0.07103117555379868
step: 80, loss: 0.025289535522460938
step: 90, loss: 0.017532125115394592
step: 100, loss: 0.21079586446285248
step: 110, loss: 0.07753902673721313
step: 120, loss: 0.10439439117908478
step: 130, loss: 0.07503120601177216
step: 140, loss: 0.1007067859172821
step: 150, loss: 0.13238437473773956
step: 160, loss: 0.019309312105178833
step: 170, loss: 0.10397513210773468
step: 180, loss: 0.1767192780971527
step: 190, loss: 0.12605991959571838
step: 200, loss: 0.16293062269687653
step: 210, loss: 0.11002560704946518
step: 220, loss: 0.1440696269273758
step: 230, loss: 0.12467455118894577
step: 240, loss: 0.050388045608997345
step: 250, loss: 0.08450601994991302
step: 260, loss: 0.14526039361953735
step: 270, loss: 0.24067233502864838
step: 280, loss: 0.22598543763160706
step: 290, loss: 0.11205326020717621
step: 300, loss: 0.031869713217020035
step: 310, loss: 0.07355886697769165
step: 320, loss: 0.06701110303401947
step: 330, loss: 0.1835019588470459
epoch 2: dev_f1=0.7926078028747433, f1=0.736220472440945, best_f1=0.736220472440945
step: 0, loss: 0.07876420021057129
step: 10, loss: 0.15855525434017181
step: 20, loss: 0.09187706559896469
step: 30, loss: 0.04364963620901108
step: 40, loss: 0.11537535488605499
step: 50, loss: 0.2590865194797516
step: 60, loss: 0.21082185208797455
step: 70, loss: 0.04166090115904808
step: 80, loss: 0.11807603389024734
step: 90, loss: 0.2059972584247589
step: 100, loss: 0.17552487552165985
step: 110, loss: 0.10799167305231094
step: 120, loss: 0.061113592237234116
step: 130, loss: 0.12569968402385712
step: 140, loss: 0.09551110118627548
step: 150, loss: 0.26659414172172546
step: 160, loss: 0.03231799975037575
step: 170, loss: 0.12919382750988007
step: 180, loss: 0.07470793277025223
step: 190, loss: 0.03649654611945152
step: 200, loss: 0.18845708668231964
step: 210, loss: 0.1525339037179947
step: 220, loss: 0.2039007991552353
step: 230, loss: 0.05685901269316673
step: 240, loss: 0.06408701092004776
step: 250, loss: 0.11293289065361023
step: 260, loss: 0.1653164029121399
step: 270, loss: 0.18019074201583862
step: 280, loss: 0.1793215125799179
step: 290, loss: 0.10074540227651596
step: 300, loss: 0.08123398572206497
step: 310, loss: 0.14218610525131226
step: 320, loss: 0.1123012900352478
step: 330, loss: 0.10046964138746262
epoch 3: dev_f1=0.8114558472553699, f1=0.8, best_f1=0.8
step: 0, loss: 0.14067858457565308
step: 10, loss: 0.05254198610782623
step: 20, loss: 0.11138865351676941
step: 30, loss: 0.11400213092565536
step: 40, loss: 0.3608537018299103
step: 50, loss: 0.0435822419822216
step: 60, loss: 0.02149195596575737
step: 70, loss: 0.07958059012889862
step: 80, loss: 0.03237468749284744
step: 90, loss: 0.0821484699845314
step: 100, loss: 0.13460494577884674
step: 110, loss: 0.12961721420288086
step: 120, loss: 0.09029306471347809
step: 130, loss: 0.10969038307666779
step: 140, loss: 0.2770700752735138
step: 150, loss: 0.0826815813779831
step: 160, loss: 0.185932919383049
step: 170, loss: 0.10293006896972656
step: 180, loss: 0.14527037739753723
step: 190, loss: 0.10315574705600739
step: 200, loss: 0.09621904790401459
step: 210, loss: 0.07635951787233353
step: 220, loss: 0.12658832967281342
step: 230, loss: 0.20358912646770477
step: 240, loss: 0.13476088643074036
step: 250, loss: 0.12449502944946289
step: 260, loss: 0.0320778451859951
step: 270, loss: 0.06914161890745163
step: 280, loss: 0.10830989480018616
step: 290, loss: 0.17614008486270905
step: 300, loss: 0.12143338471651077
step: 310, loss: 0.07284313440322876
step: 320, loss: 0.08499463647603989
step: 330, loss: 0.13032057881355286
epoch 4: dev_f1=0.8179775280898878, f1=0.7863247863247864, best_f1=0.7863247863247864
step: 0, loss: 0.04437914490699768
step: 10, loss: 0.06713210791349411
step: 20, loss: 0.007961583323776722
step: 30, loss: 0.11818841844797134
step: 40, loss: 0.09147375077009201
step: 50, loss: 0.04592987149953842
step: 60, loss: 0.14492641389369965
step: 70, loss: 0.17850187420845032
step: 80, loss: 0.17998336255550385
step: 90, loss: 0.11147928982973099
step: 100, loss: 0.11773191392421722
step: 110, loss: 0.04180976003408432
step: 120, loss: 0.1343359351158142
step: 130, loss: 0.11361605674028397
step: 140, loss: 0.06637169420719147
step: 150, loss: 0.03769740089774132
step: 160, loss: 0.10369651019573212
step: 170, loss: 0.0038517271168529987
step: 180, loss: 0.1060471162199974
step: 190, loss: 0.04193012788891792
step: 200, loss: 0.07640884071588516
step: 210, loss: 0.05029971897602081
step: 220, loss: 0.07701801508665085
step: 230, loss: 0.14486896991729736
step: 240, loss: 7.562391692772508e-05
step: 250, loss: 0.1029689833521843
step: 260, loss: 0.01379336416721344
step: 270, loss: 0.011473644524812698
step: 280, loss: 0.20453554391860962
step: 290, loss: 0.1208566427230835
step: 300, loss: 0.12709030508995056
step: 310, loss: 0.14239680767059326
step: 320, loss: 0.1298263520002365
step: 330, loss: 0.12600526213645935
epoch 5: dev_f1=0.8038277511961723, f1=0.7832167832167831, best_f1=0.7863247863247864
step: 0, loss: 0.16507849097251892
step: 10, loss: 0.08917181938886642
step: 20, loss: 0.2782498002052307
step: 30, loss: 0.09294445067644119
step: 40, loss: 0.13485771417617798
step: 50, loss: 0.27474281191825867
step: 60, loss: 0.06707863509654999
step: 70, loss: 0.024605466052889824
step: 80, loss: 0.09463074803352356
step: 90, loss: 0.05206480994820595
step: 100, loss: 0.13521148264408112
step: 110, loss: 0.10664575546979904
step: 120, loss: 0.0035050518345087767
step: 130, loss: 0.07514136284589767
step: 140, loss: 0.12211700528860092
step: 150, loss: 0.03157452493906021
step: 160, loss: 0.2248680144548416
step: 170, loss: 0.049035049974918365
step: 180, loss: 0.08117920905351639
step: 190, loss: 0.26468682289123535
step: 200, loss: 0.11343999207019806
step: 210, loss: 0.14525827765464783
step: 220, loss: 0.05882755666971207
step: 230, loss: 0.16914789378643036
step: 240, loss: 0.054222602397203445
step: 250, loss: 0.05466143414378166
step: 260, loss: 0.27812501788139343
step: 270, loss: 0.4190171957015991
step: 280, loss: 0.03799566999077797
step: 290, loss: 0.08147002756595612
step: 300, loss: 0.04811134189367294
step: 310, loss: 0.10668329149484634
step: 320, loss: 0.07885108143091202
step: 330, loss: 0.01958327740430832
epoch 6: dev_f1=0.8134831460674157, f1=0.7940552016985138, best_f1=0.7863247863247864
step: 0, loss: 0.12200719863176346
step: 10, loss: 0.05253448337316513
step: 20, loss: 0.07536496222019196
step: 30, loss: 0.08103127032518387
step: 40, loss: 0.03578545153141022
step: 50, loss: 0.12606759369373322
step: 60, loss: 0.04174191877245903
step: 70, loss: 0.0675123780965805
step: 80, loss: 0.05443543940782547
step: 90, loss: 0.10092172026634216
step: 100, loss: 0.1501438468694687
step: 110, loss: 0.19860097765922546
step: 120, loss: 0.08007186651229858
step: 130, loss: 0.10516933351755142
step: 140, loss: 0.060442157089710236
step: 150, loss: 0.04580918326973915
step: 160, loss: 0.07990574091672897
step: 170, loss: 0.17373256385326385
step: 180, loss: 0.06453356146812439
step: 190, loss: 0.06949932128190994
step: 200, loss: 0.05908593907952309
step: 210, loss: 0.1379624605178833
step: 220, loss: 0.08558917045593262
step: 230, loss: 0.04751437529921532
step: 240, loss: 0.12294778227806091
step: 250, loss: 0.09994310885667801
step: 260, loss: 0.10023003816604614
step: 270, loss: 0.11796145141124725
step: 280, loss: 0.00013006814697291702
step: 290, loss: 0.11658418923616409
step: 300, loss: 0.1492769867181778
step: 310, loss: 0.10582725703716278
step: 320, loss: 0.0552692636847496
step: 330, loss: 0.15023191273212433
epoch 7: dev_f1=0.8260869565217391, f1=0.8042553191489361, best_f1=0.8042553191489361
step: 0, loss: 0.05339610204100609
step: 10, loss: 0.11877250671386719
step: 20, loss: 0.055851563811302185
step: 30, loss: 0.0821252390742302
step: 40, loss: 0.14200901985168457
step: 50, loss: 0.06470183283090591
step: 60, loss: 0.08933204412460327
step: 70, loss: 0.018245114013552666
step: 80, loss: 0.05735290050506592
step: 90, loss: 0.06971772015094757
step: 100, loss: 0.1340278536081314
step: 110, loss: 0.08215848356485367
step: 120, loss: 0.14601600170135498
step: 130, loss: 0.08505752682685852
step: 140, loss: 0.14565697312355042
step: 150, loss: 0.16636806726455688
step: 160, loss: 0.1388128250837326
step: 170, loss: 0.1323470175266266
step: 180, loss: 0.06787335127592087
step: 190, loss: 0.07165078073740005
step: 200, loss: 0.1078590378165245
step: 210, loss: 0.0385436974465847
step: 220, loss: 0.03616669774055481
step: 230, loss: 0.09689126163721085
step: 240, loss: 0.10210893303155899
step: 250, loss: 0.07472743093967438
step: 260, loss: 0.10217438638210297
step: 270, loss: 0.09673921763896942
step: 280, loss: 0.09987694025039673
step: 290, loss: 0.042139723896980286
step: 300, loss: 0.08409291505813599
step: 310, loss: 0.1842670440673828
step: 320, loss: 0.149281844496727
step: 330, loss: 0.09153321385383606
epoch 8: dev_f1=0.8197424892703863, f1=0.7833333333333333, best_f1=0.8042553191489361
step: 0, loss: 0.034585531800985336
step: 10, loss: 0.16044387221336365
step: 20, loss: 0.10762288421392441
step: 30, loss: 0.12670736014842987
step: 40, loss: 0.04330252483487129
step: 50, loss: 0.06386004388332367
step: 60, loss: 0.12565088272094727
step: 70, loss: 0.07724413275718689
step: 80, loss: 0.042809586971998215
step: 90, loss: 0.12352275103330612
step: 100, loss: 0.05627358704805374
step: 110, loss: 0.0625106617808342
step: 120, loss: 0.10104535520076752
step: 130, loss: 0.07107587158679962
step: 140, loss: 0.10891576111316681
step: 150, loss: 0.06670799851417542
step: 160, loss: 0.05074926093220711
step: 170, loss: 0.07613709568977356
step: 180, loss: 0.075047068297863
step: 190, loss: 0.08440836519002914
step: 200, loss: 0.06562191247940063
step: 210, loss: 0.03880017250776291
step: 220, loss: 0.18145932257175446
step: 230, loss: 0.05696834623813629
step: 240, loss: 0.07900648564100266
step: 250, loss: 0.12398140877485275
step: 260, loss: 0.10156728327274323
step: 270, loss: 0.06738992035388947
step: 280, loss: 0.05345515161752701
step: 290, loss: 0.19204062223434448
step: 300, loss: 0.2560857832431793
step: 310, loss: 0.04458356276154518
step: 320, loss: 0.08324187248945236
step: 330, loss: 0.06407705694437027
epoch 9: dev_f1=0.8230088495575221, f1=0.7922912205567453, best_f1=0.8042553191489361
step: 0, loss: 0.08357013761997223
step: 10, loss: 0.05568951368331909
step: 20, loss: 0.08348928391933441
step: 30, loss: 0.14300651848316193
step: 40, loss: 0.20735198259353638
step: 50, loss: 0.06495407968759537
step: 60, loss: 0.03441101685166359
step: 70, loss: 0.19684764742851257
step: 80, loss: 0.15785227715969086
step: 90, loss: 0.04891793429851532
step: 100, loss: 0.17425134778022766
step: 110, loss: 0.15876445174217224
step: 120, loss: 0.044877324253320694
step: 130, loss: 0.2551925778388977
step: 140, loss: 0.04494273290038109
step: 150, loss: 0.09344689548015594
step: 160, loss: 0.043189920485019684
step: 170, loss: 0.16998550295829773
step: 180, loss: 0.10717754065990448
step: 190, loss: 0.04035547003149986
step: 200, loss: 0.13261748850345612
step: 210, loss: 0.14117954671382904
step: 220, loss: 0.23117144405841827
step: 230, loss: 0.16328252851963043
step: 240, loss: 0.1282358020544052
step: 250, loss: 0.13431450724601746
step: 260, loss: 0.12645725905895233
step: 270, loss: 0.16597358882427216
step: 280, loss: 0.037201594561338425
step: 290, loss: 0.032192278653383255
step: 300, loss: 0.11121339350938797
step: 310, loss: 0.0635870173573494
step: 320, loss: 0.15450800955295563
step: 330, loss: 0.10507520288228989
epoch 10: dev_f1=0.8164251207729469, f1=0.7962529274004684, best_f1=0.8042553191489361
step: 0, loss: 0.10140489786863327
step: 10, loss: 0.106536366045475
step: 20, loss: 0.09948462247848511
step: 30, loss: 0.0619705505669117
step: 40, loss: 0.10958150774240494
step: 50, loss: 0.12501507997512817
step: 60, loss: 0.28605422377586365
step: 70, loss: 0.14239980280399323
step: 80, loss: 0.10707392543554306
step: 90, loss: 0.06621041893959045
step: 100, loss: 0.0907689705491066
step: 110, loss: 0.07003545761108398
step: 120, loss: 0.08094562590122223
step: 130, loss: 0.052730899304151535
step: 140, loss: 0.06464724242687225
step: 150, loss: 0.058049775660037994
step: 160, loss: 0.09374289959669113
step: 170, loss: 0.0740751102566719
step: 180, loss: 0.1809682548046112
step: 190, loss: 0.16776412725448608
step: 200, loss: 0.04132614657282829
step: 210, loss: 0.028088733553886414
step: 220, loss: 0.1672106832265854
step: 230, loss: 0.07707194983959198
step: 240, loss: 0.12972985208034515
step: 250, loss: 0.08076394349336624
step: 260, loss: 0.08638782054185867
step: 270, loss: 0.023905670270323753
step: 280, loss: 0.15364231169223785
step: 290, loss: 0.05944603681564331
step: 300, loss: 0.061985574662685394
step: 310, loss: 0.08542972803115845
step: 320, loss: 0.11854629218578339
step: 330, loss: 0.11099192500114441
epoch 11: dev_f1=0.8251121076233184, f1=0.8103448275862069, best_f1=0.8042553191489361
step: 0, loss: 0.07071041315793991
step: 10, loss: 0.06427032500505447
step: 20, loss: 0.05997157469391823
step: 30, loss: 0.07746167480945587
step: 40, loss: 0.06915005296468735
step: 50, loss: 0.1261741667985916
step: 60, loss: 0.08637985587120056
step: 70, loss: 0.10647326707839966
step: 80, loss: 0.11055082082748413
step: 90, loss: 0.06723564863204956
step: 100, loss: 0.23499418795108795
step: 110, loss: 0.09697763621807098
step: 120, loss: 0.1088334172964096
step: 130, loss: 0.11417652666568756
step: 140, loss: 0.09132697433233261
step: 150, loss: 0.09258444607257843
step: 160, loss: 0.046797558665275574
step: 170, loss: 0.02155986987054348
step: 180, loss: 0.12025602161884308
step: 190, loss: 0.00032279061269946396
step: 200, loss: 0.05781999230384827
step: 210, loss: 0.07551779597997665
step: 220, loss: 0.09251024574041367
step: 230, loss: 0.013688554055988789
step: 240, loss: 0.025626353919506073
step: 250, loss: 0.06104011461138725
step: 260, loss: 0.16797277331352234
step: 270, loss: 0.11539657413959503
step: 280, loss: 0.08510689437389374
step: 290, loss: 0.0701700821518898
step: 300, loss: 0.05257647484540939
step: 310, loss: 0.13636626303195953
step: 320, loss: 0.1552833467721939
step: 330, loss: 0.10036655515432358
epoch 12: dev_f1=0.8309859154929576, f1=0.8144796380090498, best_f1=0.8144796380090498
step: 0, loss: 0.0780506432056427
step: 10, loss: 0.08030260354280472
step: 20, loss: 0.01996293105185032
step: 30, loss: 0.10356422513723373
step: 40, loss: 0.035346172749996185
step: 50, loss: 0.1293884962797165
step: 60, loss: 0.06745125353336334
step: 70, loss: 0.05794048309326172
step: 80, loss: 0.04959094896912575
step: 90, loss: 0.12525886297225952
step: 100, loss: 0.26195308566093445
step: 110, loss: 0.0540066659450531
step: 120, loss: 0.1427411586046219
step: 130, loss: 0.09789247065782547
step: 140, loss: 0.10498631000518799
step: 150, loss: 0.1029011681675911
step: 160, loss: 0.10841226577758789
step: 170, loss: 0.06271162629127502
step: 180, loss: 0.19759978353977203
step: 190, loss: 0.12267903983592987
step: 200, loss: 0.05510933697223663
step: 210, loss: 0.06669070571660995
step: 220, loss: 0.08010018616914749
step: 230, loss: 0.16267183423042297
step: 240, loss: 0.06092265620827675
step: 250, loss: 0.06394486129283905
step: 260, loss: 0.0955389216542244
step: 270, loss: 0.10789871960878372
step: 280, loss: 0.03500625491142273
step: 290, loss: 0.06284405291080475
step: 300, loss: 0.049916960299015045
step: 310, loss: 0.1726243644952774
step: 320, loss: 0.05915945768356323
step: 330, loss: 0.07457863539457321
epoch 13: dev_f1=0.828235294117647, f1=0.8288288288288289, best_f1=0.8144796380090498
step: 0, loss: 0.12548407912254333
step: 10, loss: 0.1571795791387558
step: 20, loss: 0.03450142592191696
step: 30, loss: 0.08249718695878983
step: 40, loss: 0.10222263634204865
step: 50, loss: 0.08301632106304169
step: 60, loss: 0.21090097725391388
step: 70, loss: 0.12331753224134445
step: 80, loss: 0.16527415812015533
step: 90, loss: 0.10143741220235825
step: 100, loss: 0.09733123332262039
step: 110, loss: 0.0432647243142128
step: 120, loss: 0.02028845250606537
step: 130, loss: 0.08677251636981964
step: 140, loss: 0.05328582972288132
step: 150, loss: 0.06492363661527634
step: 160, loss: 0.07067148387432098
step: 170, loss: 0.0731663703918457
step: 180, loss: 0.03379423916339874
step: 190, loss: 0.046859338879585266
step: 200, loss: 0.07997327297925949
step: 210, loss: 0.12239159643650055
step: 220, loss: 0.09724555909633636
step: 230, loss: 0.12115076184272766
step: 240, loss: 0.16939908266067505
step: 250, loss: 0.03297780454158783
step: 260, loss: 0.0641833022236824
step: 270, loss: 0.03332524001598358
step: 280, loss: 0.08948086947202682
step: 290, loss: 0.07358311116695404
step: 300, loss: 0.14343713223934174
step: 310, loss: 0.02584734931588173
step: 320, loss: 0.14141348004341125
step: 330, loss: 0.08688321709632874
epoch 14: dev_f1=0.803970223325062, f1=0.8164251207729469, best_f1=0.8144796380090498
step: 0, loss: 0.015755949541926384
step: 10, loss: 0.037794262170791626
step: 20, loss: 0.06198815628886223
step: 30, loss: 0.14059990644454956
step: 40, loss: 0.05948100611567497
step: 50, loss: 0.0496145561337471
step: 60, loss: 0.10710441321134567
step: 70, loss: 0.05969829112291336
step: 80, loss: 0.03943211957812309
step: 90, loss: 0.06636941432952881
step: 100, loss: 0.08691811561584473
step: 110, loss: 0.03216904029250145
step: 120, loss: 0.09807287156581879
step: 130, loss: 0.09349485486745834
step: 140, loss: 0.00047532087774015963
step: 150, loss: 0.10877148807048798
step: 160, loss: 0.10090085864067078
step: 170, loss: 0.04197486490011215
step: 180, loss: 0.14604175090789795
step: 190, loss: 0.05397769808769226
step: 200, loss: 0.05358637124300003
step: 210, loss: 0.13521364331245422
step: 220, loss: 0.07920321077108383
step: 230, loss: 0.11097095906734467
step: 240, loss: 0.062088288366794586
step: 250, loss: 0.0765661746263504
step: 260, loss: 0.18644651770591736
step: 270, loss: 0.1963358223438263
step: 280, loss: 4.991634705220349e-05
step: 290, loss: 0.09404031932353973
step: 300, loss: 0.11333464086055756
step: 310, loss: 0.09405726939439774
step: 320, loss: 0.07259539514780045
step: 330, loss: 0.11344973742961884
epoch 15: dev_f1=0.8433179723502305, f1=0.829596412556054, best_f1=0.829596412556054
step: 0, loss: 0.05785342678427696
step: 10, loss: 0.09205546975135803
step: 20, loss: 0.034610383212566376
step: 30, loss: 0.13297316431999207
step: 40, loss: 0.0295383520424366
step: 50, loss: 0.06057829037308693
step: 60, loss: 0.08213291317224503
step: 70, loss: 0.08013082295656204
step: 80, loss: 0.11111800372600555
step: 90, loss: 0.09809719026088715
step: 100, loss: 0.06524404883384705
step: 110, loss: 0.10829385370016098
step: 120, loss: 0.10546916723251343
step: 130, loss: 0.03797144070267677
step: 140, loss: 0.1001492440700531
step: 150, loss: 0.09997203946113586
step: 160, loss: 0.04999488219618797
step: 170, loss: 0.09764982759952545
step: 180, loss: 0.07964860647916794
step: 190, loss: 0.10005372017621994
step: 200, loss: 0.05640420690178871
step: 210, loss: 0.08431900292634964
step: 220, loss: 0.05926583334803581
step: 230, loss: 0.09624665975570679
step: 240, loss: 0.1021084189414978
step: 250, loss: 0.012023607268929482
step: 260, loss: 0.15199492871761322
step: 270, loss: 0.032143108546733856
step: 280, loss: 0.040468908846378326
step: 290, loss: 0.04301007091999054
step: 300, loss: 0.020346155390143394
step: 310, loss: 0.1750250905752182
step: 320, loss: 0.13134287297725677
step: 330, loss: 0.09374266117811203
epoch 16: dev_f1=0.8516746411483254, f1=0.8356807511737089, best_f1=0.8356807511737089
step: 0, loss: 0.06639939546585083
step: 10, loss: 0.10382857918739319
step: 20, loss: 0.04574627801775932
step: 30, loss: 0.05122996121644974
step: 40, loss: 0.06534971296787262
step: 50, loss: 0.014452782459557056
step: 60, loss: 0.023033134639263153
step: 70, loss: 0.04406451806426048
step: 80, loss: 0.00048627634532749653
step: 90, loss: 0.09072040021419525
step: 100, loss: 0.03157329931855202
step: 110, loss: 0.13775965571403503
step: 120, loss: 0.023254208266735077
step: 130, loss: 0.05049631744623184
step: 140, loss: 0.08747336268424988
step: 150, loss: 0.08185503631830215
step: 160, loss: 0.09678138792514801
step: 170, loss: 0.06715726107358932
step: 180, loss: 0.018503189086914062
step: 190, loss: 0.0009280466474592686
step: 200, loss: 0.12226088345050812
step: 210, loss: 0.09151764959096909
step: 220, loss: 0.02780015394091606
step: 230, loss: 0.061993055045604706
step: 240, loss: 0.09277535229921341
step: 250, loss: 0.04197461158037186
step: 260, loss: 0.00010766497143777087
step: 270, loss: 8.86926573002711e-05
step: 280, loss: 0.017323415726423264
step: 290, loss: 0.011405297555029392
step: 300, loss: 0.13397148251533508
step: 310, loss: 0.1323218196630478
step: 320, loss: 0.15835629403591156
step: 330, loss: 0.162235826253891
epoch 17: dev_f1=0.8443396226415094, f1=0.832183908045977, best_f1=0.8356807511737089
step: 0, loss: 0.046991828829050064
step: 10, loss: 0.1987282633781433
step: 20, loss: 0.04975336045026779
step: 30, loss: 0.08187515288591385
step: 40, loss: 0.09528850018978119
step: 50, loss: 0.05237402394413948
step: 60, loss: 0.05157148465514183
step: 70, loss: 0.25677812099456787
step: 80, loss: 0.0703902393579483
step: 90, loss: 0.09848247468471527
step: 100, loss: 0.08048812299966812
step: 110, loss: 0.05022139102220535
step: 120, loss: 0.06261305510997772
step: 130, loss: 0.0848085880279541
step: 140, loss: 0.11340251564979553
step: 150, loss: 0.029834914952516556
step: 160, loss: 0.07900599390268326
step: 170, loss: 0.04168060049414635
step: 180, loss: 0.0592367984354496
step: 190, loss: 0.05836223438382149
step: 200, loss: 0.03597927838563919
step: 210, loss: 0.0416889488697052
step: 220, loss: 0.049834348261356354
step: 230, loss: 0.08694517612457275
step: 240, loss: 0.02994845062494278
step: 250, loss: 0.0871313288807869
step: 260, loss: 0.14649517834186554
step: 270, loss: 0.029866717755794525
step: 280, loss: 0.04187942296266556
step: 290, loss: 0.03824377432465553
step: 300, loss: 0.028224751353263855
step: 310, loss: 0.03187631443142891
step: 320, loss: 0.09128963947296143
step: 330, loss: 0.0760677382349968
epoch 18: dev_f1=0.839907192575406, f1=0.8310502283105023, best_f1=0.8356807511737089
step: 0, loss: 0.07434183359146118
step: 10, loss: 0.0664372369647026
step: 20, loss: 0.028181083500385284
step: 30, loss: 0.016512282192707062
step: 40, loss: 0.03266838937997818
step: 50, loss: 0.08231491595506668
step: 60, loss: 0.096616730093956
step: 70, loss: 0.17283134162425995
step: 80, loss: 0.07638390362262726
step: 90, loss: 0.027792878448963165
step: 100, loss: 0.11395333707332611
step: 110, loss: 0.11913750320672989
step: 120, loss: 0.03302071616053581
step: 130, loss: 0.00012806705490220338
step: 140, loss: 0.20643532276153564
step: 150, loss: 0.08781511336565018
step: 160, loss: 0.01705903559923172
step: 170, loss: 0.06873257458209991
step: 180, loss: 0.06307555735111237
step: 190, loss: 0.06364165991544724
step: 200, loss: 0.09071815758943558
step: 210, loss: 0.034276071935892105
step: 220, loss: 0.033968161791563034
step: 230, loss: 0.05006635561585426
step: 240, loss: 0.08238928020000458
step: 250, loss: 0.16039900481700897
step: 260, loss: 0.05488881468772888
step: 270, loss: 0.032802823930978775
step: 280, loss: 0.0359526164829731
step: 290, loss: 0.09992674738168716
step: 300, loss: 0.04021588712930679
step: 310, loss: 0.09754880517721176
step: 320, loss: 0.03863149881362915
step: 330, loss: 0.11711829155683517
epoch 19: dev_f1=0.8157248157248157, f1=0.8257756563245824, best_f1=0.8356807511737089
step: 0, loss: 0.06170741841197014
step: 10, loss: 0.2650250792503357
step: 20, loss: 0.05672029033303261
step: 30, loss: 0.06939364969730377
step: 40, loss: 0.047917090356349945
step: 50, loss: 0.013929475098848343
step: 60, loss: 0.07458635419607162
step: 70, loss: 0.08890417963266373
step: 80, loss: 0.05739729106426239
step: 90, loss: 0.029584823176264763
step: 100, loss: 1.293039349548053e-05
step: 110, loss: 0.07112038135528564
step: 120, loss: 0.069844089448452
step: 130, loss: 0.02860822156071663
step: 140, loss: 0.022092897444963455
step: 150, loss: 0.05922062695026398
step: 160, loss: 0.049501240253448486
step: 170, loss: 0.1317591518163681
step: 180, loss: 0.10547143965959549
step: 190, loss: 3.427360570640303e-05
step: 200, loss: 0.037024322897195816
step: 210, loss: 0.18290439248085022
step: 220, loss: 0.06303878873586655
step: 230, loss: 0.05254910886287689
step: 240, loss: 0.03970919921994209
step: 250, loss: 0.05522942915558815
step: 260, loss: 0.08369840681552887
step: 270, loss: 0.05564291030168533
step: 280, loss: 0.08521885424852371
step: 290, loss: 0.01099626999348402
step: 300, loss: 0.08985543251037598
step: 310, loss: 0.04665055498480797
step: 320, loss: 0.04136701300740242
step: 330, loss: 0.19397391378879547
epoch 20: dev_f1=0.8203883495145631, f1=0.8293838862559242, best_f1=0.8356807511737089
