cuda
Device: cuda
step: 0, loss: 0.9466674327850342
step: 10, loss: 0.23384253680706024
step: 20, loss: 0.12281812727451324
step: 30, loss: 0.23005416989326477
step: 40, loss: 0.23295287787914276
step: 50, loss: 0.13965892791748047
step: 60, loss: 0.17506888508796692
step: 70, loss: 0.4127870798110962
step: 80, loss: 0.3079521954059601
step: 90, loss: 0.15503010153770447
step: 100, loss: 0.3111737370491028
step: 110, loss: 0.07096171379089355
step: 120, loss: 0.1494358330965042
step: 130, loss: 0.2393551468849182
step: 140, loss: 0.24711988866329193
step: 150, loss: 0.3068658411502838
step: 160, loss: 0.147833913564682
step: 170, loss: 0.17386946082115173
step: 180, loss: 0.19669640064239502
step: 190, loss: 0.06316380947828293
step: 200, loss: 0.14763346314430237
step: 210, loss: 0.0953473448753357
step: 220, loss: 0.20364119112491608
step: 230, loss: 0.1407415121793747
step: 240, loss: 0.05468831956386566
step: 250, loss: 0.32316699624061584
step: 260, loss: 0.06922581046819687
step: 270, loss: 0.12153278291225433
step: 280, loss: 0.15165142714977264
step: 290, loss: 0.04386478289961815
step: 300, loss: 0.12324713915586472
step: 310, loss: 0.11475121974945068
step: 320, loss: 0.08833813667297363
step: 330, loss: 0.11325368285179138
epoch 1: dev_f1=0.6964285714285714, f1=0.6893617021276596, best_f1=0.6893617021276596
step: 0, loss: 0.20651255548000336
step: 10, loss: 0.12857404351234436
step: 20, loss: 0.22189942002296448
step: 30, loss: 0.06786765903234482
step: 40, loss: 0.09201545268297195
step: 50, loss: 0.018790503963828087
step: 60, loss: 0.14239177107810974
step: 70, loss: 0.11846335977315903
step: 80, loss: 0.11094602197408676
step: 90, loss: 0.15583030879497528
step: 100, loss: 0.10051099956035614
step: 110, loss: 0.21679101884365082
step: 120, loss: 0.21569666266441345
step: 130, loss: 0.22852672636508942
step: 140, loss: 0.11098714172840118
step: 150, loss: 0.10446804016828537
step: 160, loss: 0.25408095121383667
step: 170, loss: 0.3287854492664337
step: 180, loss: 0.18809422850608826
step: 190, loss: 0.13087894022464752
step: 200, loss: 0.17349658906459808
step: 210, loss: 0.18985533714294434
step: 220, loss: 0.1320176124572754
step: 230, loss: 0.02241825871169567
step: 240, loss: 0.24271723628044128
step: 250, loss: 0.2771921753883362
step: 260, loss: 0.13958291709423065
step: 270, loss: 0.032641276717185974
step: 280, loss: 0.10270893573760986
step: 290, loss: 0.20643094182014465
step: 300, loss: 0.21003271639347076
step: 310, loss: 0.06727206707000732
step: 320, loss: 0.3009507954120636
step: 330, loss: 0.13665415346622467
epoch 2: dev_f1=0.7239819004524887, f1=0.7117903930131005, best_f1=0.7117903930131005
step: 0, loss: 0.04091702029109001
step: 10, loss: 0.21292781829833984
step: 20, loss: 0.17288504540920258
step: 30, loss: 0.14081500470638275
step: 40, loss: 0.1670055091381073
step: 50, loss: 0.03608413413167
step: 60, loss: 0.14420080184936523
step: 70, loss: 0.0780821219086647
step: 80, loss: 0.018989166244864464
step: 90, loss: 0.11007528007030487
step: 100, loss: 0.07085444033145905
step: 110, loss: 0.1253819465637207
step: 120, loss: 0.11012350767850876
step: 130, loss: 0.06856235861778259
step: 140, loss: 0.09721297025680542
step: 150, loss: 0.09534590691328049
step: 160, loss: 0.17463324964046478
step: 170, loss: 0.10075142234563828
step: 180, loss: 0.0744263157248497
step: 190, loss: 0.11175299435853958
step: 200, loss: 0.1661156415939331
step: 210, loss: 0.12402614951133728
step: 220, loss: 0.10371972620487213
step: 230, loss: 0.27420008182525635
step: 240, loss: 0.09247856587171555
step: 250, loss: 0.22831715643405914
step: 260, loss: 0.1890348345041275
step: 270, loss: 0.15000616014003754
step: 280, loss: 0.1065540760755539
step: 290, loss: 0.09837215393781662
step: 300, loss: 0.021257448941469193
step: 310, loss: 0.07536078989505768
step: 320, loss: 0.17999501526355743
step: 330, loss: 0.10434895753860474
epoch 3: dev_f1=0.8125000000000001, f1=0.7775377969762419, best_f1=0.7775377969762419
step: 0, loss: 0.08427172154188156
step: 10, loss: 0.08333505690097809
step: 20, loss: 0.08885151892900467
step: 30, loss: 0.07022015750408173
step: 40, loss: 0.18683834373950958
step: 50, loss: 0.06823188811540604
step: 60, loss: 0.12581825256347656
step: 70, loss: 0.036149587482213974
step: 80, loss: 0.04929086193442345
step: 90, loss: 0.17939618229866028
step: 100, loss: 0.16751804947853088
step: 110, loss: 0.05357888713479042
step: 120, loss: 0.08972619473934174
step: 130, loss: 0.11721568554639816
step: 140, loss: 0.12760044634342194
step: 150, loss: 0.1307182013988495
step: 160, loss: 0.23170991241931915
step: 170, loss: 0.05488109588623047
step: 180, loss: 0.032580193132162094
step: 190, loss: 0.40563029050827026
step: 200, loss: 0.11584696173667908
step: 210, loss: 0.08884607255458832
step: 220, loss: 0.05438262224197388
step: 230, loss: 0.07702114433050156
step: 240, loss: 0.05458105355501175
step: 250, loss: 0.07299818843603134
step: 260, loss: 0.12449407577514648
step: 270, loss: 0.0961468294262886
step: 280, loss: 0.13684575259685516
step: 290, loss: 0.016314826905727386
step: 300, loss: 0.2795277535915375
step: 310, loss: 0.18180865049362183
step: 320, loss: 0.0937582477927208
step: 330, loss: 0.14230813086032867
epoch 4: dev_f1=0.8390022675736961, f1=0.7922912205567453, best_f1=0.7922912205567453
step: 0, loss: 0.015117296017706394
step: 10, loss: 0.08712741732597351
step: 20, loss: 0.1840866357088089
step: 30, loss: 0.117296501994133
step: 40, loss: 0.13125352561473846
step: 50, loss: 0.03519029542803764
step: 60, loss: 0.09500911831855774
step: 70, loss: 0.12850455939769745
step: 80, loss: 0.03543872386217117
step: 90, loss: 0.059243179857730865
step: 100, loss: 0.10125807672739029
step: 110, loss: 0.12209708988666534
step: 120, loss: 0.05558294057846069
step: 130, loss: 0.06703262031078339
step: 140, loss: 0.15866240859031677
step: 150, loss: 0.14969868957996368
step: 160, loss: 0.08476068079471588
step: 170, loss: 0.12493741512298584
step: 180, loss: 0.047832321375608444
step: 190, loss: 0.059308696538209915
step: 200, loss: 0.06713305413722992
step: 210, loss: 0.158945232629776
step: 220, loss: 0.18475082516670227
step: 230, loss: 0.0501248836517334
step: 240, loss: 0.13618309795856476
step: 250, loss: 0.11195754259824753
step: 260, loss: 0.0345618762075901
step: 270, loss: 0.1636192351579666
step: 280, loss: 0.09254517406225204
step: 290, loss: 0.06475408375263214
step: 300, loss: 0.09372082352638245
step: 310, loss: 0.10323633253574371
step: 320, loss: 0.15604092180728912
step: 330, loss: 0.13062457740306854
epoch 5: dev_f1=0.8433179723502305, f1=0.801781737193764, best_f1=0.801781737193764
step: 0, loss: 0.11051249504089355
step: 10, loss: 0.0629597008228302
step: 20, loss: 0.02683296427130699
step: 30, loss: 0.0023851171135902405
step: 40, loss: 0.1121567115187645
step: 50, loss: 0.0970495343208313
step: 60, loss: 0.0759972557425499
step: 70, loss: 0.05418873205780983
step: 80, loss: 0.06493005156517029
step: 90, loss: 0.09626057744026184
step: 100, loss: 0.14605319499969482
step: 110, loss: 0.0743742287158966
step: 120, loss: 0.10468023270368576
step: 130, loss: 0.09527865052223206
step: 140, loss: 0.15039069950580597
step: 150, loss: 0.17910638451576233
step: 160, loss: 0.09896405786275864
step: 170, loss: 0.1987093687057495
step: 180, loss: 0.05895686522126198
step: 190, loss: 0.0912601426243782
step: 200, loss: 0.15958532691001892
step: 210, loss: 0.09389985352754593
step: 220, loss: 0.10738552361726761
step: 230, loss: 0.042183324694633484
step: 240, loss: 0.3753072917461395
step: 250, loss: 0.08685845136642456
step: 260, loss: 0.13818953931331635
step: 270, loss: 0.10490375757217407
step: 280, loss: 0.12801606953144073
step: 290, loss: 0.05714084208011627
step: 300, loss: 0.13702993094921112
step: 310, loss: 0.09551355987787247
step: 320, loss: 0.10929232835769653
step: 330, loss: 0.026524044573307037
epoch 6: dev_f1=0.8385542168674698, f1=0.8064516129032259, best_f1=0.801781737193764
step: 0, loss: 0.07337120920419693
step: 10, loss: 0.1884591281414032
step: 20, loss: 0.0996471643447876
step: 30, loss: 0.034329045563936234
step: 40, loss: 0.07056492567062378
step: 50, loss: 0.06062419340014458
step: 60, loss: 0.12608107924461365
step: 70, loss: 0.14684803783893585
step: 80, loss: 0.09958422929048538
step: 90, loss: 0.03403770551085472
step: 100, loss: 7.232360803755e-05
step: 110, loss: 0.06343134492635727
step: 120, loss: 0.18950559198856354
step: 130, loss: 0.12334683537483215
step: 140, loss: 0.0596739798784256
step: 150, loss: 0.08726852387189865
step: 160, loss: 0.10077778249979019
step: 170, loss: 0.09083560854196548
step: 180, loss: 0.04308374971151352
step: 190, loss: 0.11725501716136932
step: 200, loss: 0.12576712667942047
step: 210, loss: 0.03592006489634514
step: 220, loss: 0.16681793332099915
step: 230, loss: 0.058166928589344025
step: 240, loss: 0.11413835734128952
step: 250, loss: 0.05135270208120346
step: 260, loss: 0.10294871032238007
step: 270, loss: 0.10367732495069504
step: 280, loss: 0.06777083873748779
step: 290, loss: 0.11921973526477814
step: 300, loss: 0.0583854615688324
step: 310, loss: 0.16802968084812164
step: 320, loss: 0.02633608877658844
step: 330, loss: 0.09970536082983017
epoch 7: dev_f1=0.8194444444444444, f1=0.7789934354485777, best_f1=0.801781737193764
step: 0, loss: 0.05625643953680992
step: 10, loss: 0.11286178231239319
step: 20, loss: 0.12338440865278244
step: 30, loss: 0.06905822455883026
step: 40, loss: 0.12315364181995392
step: 50, loss: 0.041320014744997025
step: 60, loss: 0.07265225797891617
step: 70, loss: 0.04294392094016075
step: 80, loss: 0.04226794093847275
step: 90, loss: 0.07408405840396881
step: 100, loss: 0.08355448395013809
step: 110, loss: 0.016978010535240173
step: 120, loss: 0.13396917283535004
step: 130, loss: 0.025753576308488846
step: 140, loss: 0.16323347389698029
step: 150, loss: 0.09332440793514252
step: 160, loss: 0.1294465959072113
step: 170, loss: 0.12629882991313934
step: 180, loss: 0.05625654757022858
step: 190, loss: 0.11239222437143326
step: 200, loss: 0.0936029851436615
step: 210, loss: 0.0838339701294899
step: 220, loss: 0.06561660766601562
step: 230, loss: 0.0982949435710907
step: 240, loss: 0.14386996626853943
step: 250, loss: 0.06625441461801529
step: 260, loss: 0.14956213533878326
step: 270, loss: 0.10492626577615738
step: 280, loss: 0.07385306805372238
step: 290, loss: 0.08911669999361038
step: 300, loss: 0.08353731036186218
step: 310, loss: 0.06892702728509903
step: 320, loss: 0.16540776193141937
step: 330, loss: 0.13711152970790863
epoch 8: dev_f1=0.8117359413202935, f1=0.7834101382488479, best_f1=0.801781737193764
step: 0, loss: 0.10848493874073029
step: 10, loss: 0.05414322391152382
step: 20, loss: 0.07318628579378128
step: 30, loss: 0.07649773359298706
step: 40, loss: 0.06634935736656189
step: 50, loss: 0.029212750494480133
step: 60, loss: 0.0491626039147377
step: 70, loss: 0.1002805158495903
step: 80, loss: 0.06589049845933914
step: 90, loss: 0.31161922216415405
step: 100, loss: 0.11151633411645889
step: 110, loss: 0.10157348215579987
step: 120, loss: 0.07805854827165604
step: 130, loss: 0.02743837609887123
step: 140, loss: 0.022633859887719154
step: 150, loss: 0.07355661690235138
step: 160, loss: 0.14890941977500916
step: 170, loss: 0.04774791747331619
step: 180, loss: 0.07688190042972565
step: 190, loss: 0.0835285484790802
step: 200, loss: 0.09940929710865021
step: 210, loss: 0.10770497471094131
step: 220, loss: 0.12034763395786285
step: 230, loss: 0.03786284849047661
step: 240, loss: 0.3552263677120209
step: 250, loss: 0.11168355494737625
step: 260, loss: 0.09578216075897217
step: 270, loss: 0.0695241242647171
step: 280, loss: 0.08511722832918167
step: 290, loss: 0.14444604516029358
step: 300, loss: 0.12159477174282074
step: 310, loss: 0.03732535243034363
step: 320, loss: 0.1860283613204956
step: 330, loss: 0.08779478818178177
epoch 9: dev_f1=0.8206278026905829, f1=0.7929515418502202, best_f1=0.801781737193764
step: 0, loss: 0.10526570677757263
step: 10, loss: 0.12509988248348236
step: 20, loss: 0.0851188451051712
step: 30, loss: 0.033351749181747437
step: 40, loss: 0.024854710325598717
step: 50, loss: 0.048616521060466766
step: 60, loss: 0.17271123826503754
step: 70, loss: 0.12588241696357727
step: 80, loss: 0.0736260861158371
step: 90, loss: 0.08103315532207489
step: 100, loss: 0.17260654270648956
step: 110, loss: 0.07291361689567566
step: 120, loss: 0.06395142525434494
step: 130, loss: 0.0678350180387497
step: 140, loss: 0.11188448965549469
step: 150, loss: 0.02479063905775547
step: 160, loss: 0.03700010105967522
step: 170, loss: 0.04050278291106224
step: 180, loss: 0.0790899246931076
step: 190, loss: 0.04361074045300484
step: 200, loss: 0.11846335977315903
step: 210, loss: 0.0674419105052948
step: 220, loss: 0.059898387640714645
step: 230, loss: 0.13701656460762024
step: 240, loss: 0.02334762178361416
step: 250, loss: 0.07391130179166794
step: 260, loss: 0.06411942839622498
step: 270, loss: 0.018039412796497345
step: 280, loss: 0.06402339041233063
step: 290, loss: 0.05682786926627159
step: 300, loss: 0.06256207078695297
step: 310, loss: 0.0025362493470311165
step: 320, loss: 0.08410404622554779
step: 330, loss: 0.08943794667720795
epoch 10: dev_f1=0.8357487922705313, f1=0.8232558139534882, best_f1=0.801781737193764
step: 0, loss: 0.0946047455072403
step: 10, loss: 0.08209771662950516
step: 20, loss: 0.11784593760967255
step: 30, loss: 0.050185658037662506
step: 40, loss: 0.19661326706409454
step: 50, loss: 0.04559485614299774
step: 60, loss: 0.024069491773843765
step: 70, loss: 0.0798211619257927
step: 80, loss: 0.10070166736841202
step: 90, loss: 0.11936162412166595
step: 100, loss: 0.06714213639497757
step: 110, loss: 0.17857767641544342
step: 120, loss: 0.0021095809061080217
step: 130, loss: 0.06157656013965607
step: 140, loss: 0.05069154128432274
step: 150, loss: 0.06269621849060059
step: 160, loss: 0.07096924632787704
step: 170, loss: 0.2574903964996338
step: 180, loss: 0.05168873444199562
step: 190, loss: 0.21668004989624023
step: 200, loss: 0.03781365603208542
step: 210, loss: 0.09617943316698074
step: 220, loss: 0.10281537473201752
step: 230, loss: 0.07822687178850174
step: 240, loss: 0.12820947170257568
step: 250, loss: 0.14668959379196167
step: 260, loss: 0.09288391470909119
step: 270, loss: 0.10999689251184464
step: 280, loss: 0.07575783133506775
step: 290, loss: 0.13310042023658752
step: 300, loss: 0.0655650794506073
step: 310, loss: 0.16278567910194397
step: 320, loss: 0.05985983461141586
step: 330, loss: 0.02596486173570156
epoch 11: dev_f1=0.859122401847575, f1=0.829596412556054, best_f1=0.829596412556054
step: 0, loss: 0.0001517008786322549
step: 10, loss: 0.08287166804075241
step: 20, loss: 0.12688599526882172
step: 30, loss: 0.0911656841635704
step: 40, loss: 0.048615776002407074
step: 50, loss: 0.18044576048851013
step: 60, loss: 0.1192535012960434
step: 70, loss: 0.02658177725970745
step: 80, loss: 0.04412144050002098
step: 90, loss: 0.14103752374649048
step: 100, loss: 0.07187329977750778
step: 110, loss: 0.04368601739406586
step: 120, loss: 0.06611330807209015
step: 130, loss: 0.1320473998785019
step: 140, loss: 0.07877941429615021
step: 150, loss: 0.09292640537023544
step: 160, loss: 0.03427150845527649
step: 170, loss: 0.10453279316425323
step: 180, loss: 0.10544531792402267
step: 190, loss: 0.10329233855009079
step: 200, loss: 0.12768971920013428
step: 210, loss: 0.14032725989818573
step: 220, loss: 0.11773713678121567
step: 230, loss: 0.11553841829299927
step: 240, loss: 0.2646772563457489
step: 250, loss: 0.07486692070960999
step: 260, loss: 0.11024808883666992
step: 270, loss: 0.04039188101887703
step: 280, loss: 0.05483485013246536
step: 290, loss: 0.09939689934253693
step: 300, loss: 0.06760405004024506
step: 310, loss: 0.13994498550891876
step: 320, loss: 0.07427237927913666
step: 330, loss: 0.041071631014347076
epoch 12: dev_f1=0.7875647668393781, f1=0.7587939698492463, best_f1=0.829596412556054
step: 0, loss: 0.0019334172829985619
step: 10, loss: 0.06459818035364151
step: 20, loss: 0.0030719097703695297
step: 30, loss: 0.04554859548807144
step: 40, loss: 0.10850980877876282
step: 50, loss: 0.13864432275295258
step: 60, loss: 0.12804347276687622
step: 70, loss: 0.0793299674987793
step: 80, loss: 0.12531739473342896
step: 90, loss: 0.10018371790647507
step: 100, loss: 0.1244862750172615
step: 110, loss: 0.0947994589805603
step: 120, loss: 0.03149208799004555
step: 130, loss: 0.04236789420247078
step: 140, loss: 0.05803441256284714
step: 150, loss: 0.06589929759502411
step: 160, loss: 0.10878308117389679
step: 170, loss: 0.005149289965629578
step: 180, loss: 0.19866551458835602
step: 190, loss: 0.10876456648111343
step: 200, loss: 0.017763733863830566
step: 210, loss: 0.1894019991159439
step: 220, loss: 0.14941799640655518
step: 230, loss: 0.06913621723651886
step: 240, loss: 0.08236323297023773
step: 250, loss: 0.046334706246852875
step: 260, loss: 0.1439439207315445
step: 270, loss: 0.11880135536193848
step: 280, loss: 0.050704143941402435
step: 290, loss: 0.10897717624902725
step: 300, loss: 0.13039663434028625
step: 310, loss: 0.02540247142314911
step: 320, loss: 0.1466846913099289
step: 330, loss: 0.13903027772903442
epoch 13: dev_f1=0.8416289592760181, f1=0.8157894736842106, best_f1=0.829596412556054
step: 0, loss: 0.1397513449192047
step: 10, loss: 0.101751409471035
step: 20, loss: 0.026994755491614342
step: 30, loss: 0.04065321385860443
step: 40, loss: 0.03396129980683327
step: 50, loss: 0.06631842255592346
step: 60, loss: 0.08125409483909607
step: 70, loss: 0.07706814259290695
step: 80, loss: 0.04123225435614586
step: 90, loss: 0.2351337969303131
step: 100, loss: 0.11029412597417831
step: 110, loss: 0.07758976519107819
step: 120, loss: 0.09355701506137848
step: 130, loss: 0.0672932043671608
step: 140, loss: 0.10972615331411362
step: 150, loss: 0.1750568002462387
step: 160, loss: 0.053793955594301224
step: 170, loss: 0.08184770494699478
step: 180, loss: 0.11498559266328812
step: 190, loss: 0.11469627916812897
step: 200, loss: 0.0641542375087738
step: 210, loss: 0.13674460351467133
step: 220, loss: 0.006768874824047089
step: 230, loss: 0.04530011862516403
step: 240, loss: 0.05064910277724266
step: 250, loss: 0.01708623208105564
step: 260, loss: 0.05343819037079811
step: 270, loss: 0.09901870042085648
step: 280, loss: 0.043781720101833344
step: 290, loss: 0.053190942853689194
step: 300, loss: 0.038898177444934845
step: 310, loss: 0.05940445512533188
step: 320, loss: 0.00013383380428422242
step: 330, loss: 0.11787775903940201
epoch 14: dev_f1=0.8110599078341014, f1=0.8300220750551875, best_f1=0.829596412556054
step: 0, loss: 0.05314193293452263
step: 10, loss: 0.011432862840592861
step: 20, loss: 0.0709698498249054
step: 30, loss: 0.08376963436603546
step: 40, loss: 0.04547377675771713
step: 50, loss: 0.11304067820310593
step: 60, loss: 0.038258012384176254
step: 70, loss: 0.04894838482141495
step: 80, loss: 0.0604572631418705
step: 90, loss: 0.0987563356757164
step: 100, loss: 0.16441169381141663
step: 110, loss: 0.09149742126464844
step: 120, loss: 0.09113308787345886
step: 130, loss: 0.1358616054058075
step: 140, loss: 0.04227946698665619
step: 150, loss: 0.11550216376781464
step: 160, loss: 0.08838421106338501
step: 170, loss: 0.04938771203160286
step: 180, loss: 0.09179583936929703
step: 190, loss: 0.09351833909749985
step: 200, loss: 0.13807222247123718
step: 210, loss: 0.07657113671302795
step: 220, loss: 0.037129420787096024
step: 230, loss: 0.11779201030731201
step: 240, loss: 0.0965757817029953
step: 250, loss: 0.16335293650627136
step: 260, loss: 0.0638003796339035
step: 270, loss: 0.06802903860807419
step: 280, loss: 0.07294007390737534
step: 290, loss: 0.06916577368974686
step: 300, loss: 0.11827614903450012
step: 310, loss: 0.08682075887918472
step: 320, loss: 0.08643893152475357
step: 330, loss: 0.15207286179065704
epoch 15: dev_f1=0.803921568627451, f1=0.8075117370892019, best_f1=0.829596412556054
step: 0, loss: 0.10763808339834213
step: 10, loss: 0.14322718977928162
step: 20, loss: 0.0517132394015789
step: 30, loss: 0.08146633952856064
step: 40, loss: 0.05175667628645897
step: 50, loss: 0.09652324765920639
step: 60, loss: 0.011000014841556549
step: 70, loss: 0.02995871938765049
step: 80, loss: 0.026609579101204872
step: 90, loss: 0.11814730614423752
step: 100, loss: 0.02286968193948269
step: 110, loss: 0.10610254108905792
step: 120, loss: 0.09891964495182037
step: 130, loss: 0.13843736052513123
step: 140, loss: 0.02434990182518959
step: 150, loss: 0.12383361905813217
step: 160, loss: 0.17480948567390442
step: 170, loss: 0.06200150400400162
step: 180, loss: 0.0001283181773032993
step: 190, loss: 0.11508426070213318
step: 200, loss: 0.05685786157846451
step: 210, loss: 0.05547073483467102
step: 220, loss: 0.07140601426362991
step: 230, loss: 0.1433716118335724
step: 240, loss: 0.23458890616893768
step: 250, loss: 0.09751356393098831
step: 260, loss: 0.13434593379497528
step: 270, loss: 0.05579178407788277
step: 280, loss: 0.07069257646799088
step: 290, loss: 0.016256576403975487
step: 300, loss: 0.0898258239030838
step: 310, loss: 0.07804695516824722
step: 320, loss: 0.03166200965642929
step: 330, loss: 0.04844246432185173
epoch 16: dev_f1=0.8, f1=0.7990196078431373, best_f1=0.829596412556054
step: 0, loss: 0.045211873948574066
step: 10, loss: 0.10966673493385315
step: 20, loss: 0.10106804966926575
step: 30, loss: 0.10902108252048492
step: 40, loss: 0.04947461560368538
step: 50, loss: 0.08360057324171066
step: 60, loss: 0.03666087985038757
step: 70, loss: 0.032667603343725204
step: 80, loss: 0.07557813078165054
step: 90, loss: 0.02920195460319519
step: 100, loss: 0.06354508548974991
step: 110, loss: 0.13329383730888367
step: 120, loss: 0.055072735995054245
step: 130, loss: 0.08537977933883667
step: 140, loss: 0.06866871565580368
step: 150, loss: 0.05392908677458763
step: 160, loss: 0.02350393682718277
step: 170, loss: 0.09806611388921738
step: 180, loss: 0.05851518735289574
step: 190, loss: 0.1608201563358307
step: 200, loss: 0.05451969802379608
step: 210, loss: 0.08805298805236816
step: 220, loss: 0.0845547467470169
step: 230, loss: 0.15117646753787994
step: 240, loss: 0.06929846107959747
step: 250, loss: 0.0733887329697609
step: 260, loss: 0.07303670793771744
step: 270, loss: 0.13162727653980255
step: 280, loss: 0.12613630294799805
step: 290, loss: 0.060117583721876144
step: 300, loss: 0.1481044590473175
step: 310, loss: 0.03881704434752464
step: 320, loss: 0.05926346778869629
step: 330, loss: 0.03178879991173744
epoch 17: dev_f1=0.8028503562945368, f1=0.8081264108352145, best_f1=0.829596412556054
step: 0, loss: 0.06390580534934998
step: 10, loss: 0.059659700840711594
step: 20, loss: 0.11424639821052551
step: 30, loss: 0.07107856124639511
step: 40, loss: 0.18774932622909546
step: 50, loss: 0.07771721482276917
step: 60, loss: 0.052414361387491226
step: 70, loss: 0.09344208985567093
step: 80, loss: 0.02080010063946247
step: 90, loss: 0.07726865261793137
step: 100, loss: 0.05504888668656349
step: 110, loss: 0.04707414656877518
step: 120, loss: 0.017414787784218788
step: 130, loss: 0.2352062314748764
step: 140, loss: 0.07235609740018845
step: 150, loss: 0.047737907618284225
step: 160, loss: 0.08207142353057861
step: 170, loss: 0.10875539481639862
step: 180, loss: 0.06110706552863121
step: 190, loss: 0.07772816717624664
step: 200, loss: 0.10580526292324066
step: 210, loss: 0.08017198741436005
step: 220, loss: 0.05266345292329788
step: 230, loss: 0.10000145435333252
step: 240, loss: 0.042454373091459274
step: 250, loss: 0.06872659921646118
step: 260, loss: 0.14484433829784393
step: 270, loss: 0.08313513547182083
step: 280, loss: 0.07129040360450745
step: 290, loss: 6.995828152867034e-05
step: 300, loss: 0.07266552001237869
step: 310, loss: 0.0028881304897367954
step: 320, loss: 0.04565783962607384
step: 330, loss: 0.10142365843057632
epoch 18: dev_f1=0.7806122448979592, f1=0.7893462469733656, best_f1=0.829596412556054
step: 0, loss: 0.01934344321489334
step: 10, loss: 0.02358943037688732
step: 20, loss: 0.11773691326379776
step: 30, loss: 0.15244324505329132
step: 40, loss: 0.07173839211463928
step: 50, loss: 0.038606882095336914
step: 60, loss: 0.003100242931395769
step: 70, loss: 0.07210176438093185
step: 80, loss: 0.030896253883838654
step: 90, loss: 0.08842016756534576
step: 100, loss: 0.12061695754528046
step: 110, loss: 0.05523908510804176
step: 120, loss: 0.1106969341635704
step: 130, loss: 0.06562528014183044
step: 140, loss: 0.05260502174496651
step: 150, loss: 0.08611736446619034
step: 160, loss: 0.08590647578239441
step: 170, loss: 0.06928598135709763
step: 180, loss: 0.04952827841043472
step: 190, loss: 0.030985157936811447
step: 200, loss: 0.14154134690761566
step: 210, loss: 0.265801340341568
step: 220, loss: 0.08339787274599075
step: 230, loss: 0.10476353019475937
step: 240, loss: 0.16528932750225067
step: 250, loss: 0.043120451271533966
step: 260, loss: 0.01878645084798336
step: 270, loss: 0.05848435312509537
step: 280, loss: 0.06539130210876465
step: 290, loss: 0.04569927603006363
step: 300, loss: 0.030740395188331604
step: 310, loss: 0.06918018311262131
step: 320, loss: 0.10729536414146423
step: 330, loss: 0.031581055372953415
epoch 19: dev_f1=0.7949367088607596, f1=0.7912621359223301, best_f1=0.829596412556054
step: 0, loss: 0.06731975078582764
step: 10, loss: 0.038209572434425354
step: 20, loss: 0.044492606073617935
step: 30, loss: 0.04214310273528099
step: 40, loss: 0.07457952946424484
step: 50, loss: 0.055483605712652206
step: 60, loss: 0.07437524199485779
step: 70, loss: 0.0683763176202774
step: 80, loss: 0.03221821039915085
step: 90, loss: 0.08253374695777893
step: 100, loss: 0.019625989720225334
step: 110, loss: 0.09080331027507782
step: 120, loss: 0.01377672329545021
step: 130, loss: 0.13307787477970123
step: 140, loss: 0.010559202171862125
step: 150, loss: 0.002995147369801998
step: 160, loss: 0.015213209204375744
step: 170, loss: 0.07710887491703033
step: 180, loss: 0.039847347885370255
step: 190, loss: 0.17695051431655884
step: 200, loss: 0.02076338604092598
step: 210, loss: 0.021660709753632545
step: 220, loss: 0.055505428463220596
step: 230, loss: 0.08249381929636002
step: 240, loss: 0.09729377925395966
step: 250, loss: 0.037759386003017426
step: 260, loss: 0.08430378139019012
step: 270, loss: 0.05955073609948158
step: 280, loss: 0.1172613576054573
step: 290, loss: 0.08595612645149231
step: 300, loss: 0.013155685737729073
step: 310, loss: 0.09232062101364136
step: 320, loss: 0.003440623404458165
step: 330, loss: 0.020057853311300278
epoch 20: dev_f1=0.780361757105943, f1=0.7902439024390243, best_f1=0.829596412556054
