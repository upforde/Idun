cuda
Device: cuda
step: 0, loss: 0.6318931579589844
step: 10, loss: 0.32348760962486267
step: 20, loss: 0.2337838113307953
step: 30, loss: 0.15063199400901794
step: 40, loss: 0.2388603687286377
step: 50, loss: 0.24879705905914307
step: 60, loss: 0.14845703542232513
step: 70, loss: 0.31524720788002014
step: 80, loss: 0.13044151663780212
step: 90, loss: 0.15685667097568512
step: 100, loss: 0.13879592716693878
step: 110, loss: 0.12068682909011841
step: 120, loss: 0.2706431448459625
step: 130, loss: 0.32713085412979126
step: 140, loss: 0.27319157123565674
step: 150, loss: 0.11579093337059021
step: 160, loss: 0.2357538789510727
step: 170, loss: 0.12310013175010681
step: 180, loss: 0.13863620162010193
step: 190, loss: 0.3400566875934601
step: 200, loss: 0.21012967824935913
step: 210, loss: 0.14447367191314697
step: 220, loss: 0.2916247248649597
step: 230, loss: 0.05633692070841789
step: 240, loss: 0.3022559583187103
step: 250, loss: 0.150157630443573
step: 260, loss: 0.27377766370773315
step: 270, loss: 0.31647229194641113
step: 280, loss: 0.22108866274356842
step: 290, loss: 0.12410321831703186
step: 300, loss: 0.10702057182788849
step: 310, loss: 0.13952942192554474
step: 320, loss: 0.10829834640026093
step: 330, loss: 0.0738818496465683
epoch 1: dev_f1=0.6972477064220184, f1=0.7, best_f1=0.7
step: 0, loss: 0.1879579722881317
step: 10, loss: 0.12808261811733246
step: 20, loss: 0.017625808715820312
step: 30, loss: 0.052652668207883835
step: 40, loss: 0.02479904145002365
step: 50, loss: 0.1740032285451889
step: 60, loss: 0.1392602175474167
step: 70, loss: 0.06558544933795929
step: 80, loss: 0.2229173630475998
step: 90, loss: 0.15353848040103912
step: 100, loss: 0.08803421258926392
step: 110, loss: 0.08830185979604721
step: 120, loss: 0.12652122974395752
step: 130, loss: 0.08536399155855179
step: 140, loss: 0.08083617687225342
step: 150, loss: 0.07282523065805435
step: 160, loss: 0.101674385368824
step: 170, loss: 0.14128023386001587
step: 180, loss: 0.2417357861995697
step: 190, loss: 0.016694655641913414
step: 200, loss: 0.0786694660782814
step: 210, loss: 0.17901179194450378
step: 220, loss: 0.1292131394147873
step: 230, loss: 0.14026151597499847
step: 240, loss: 0.22926045954227448
step: 250, loss: 0.0821908563375473
step: 260, loss: 0.16950222849845886
step: 270, loss: 0.07906963676214218
step: 280, loss: 0.16896946728229523
step: 290, loss: 0.06263995915651321
step: 300, loss: 0.08027683943510056
step: 310, loss: 0.09511236101388931
step: 320, loss: 0.12088101357221603
step: 330, loss: 0.17714588344097137
epoch 2: dev_f1=0.7734553775743708, f1=0.7583148558758315, best_f1=0.7583148558758315
step: 0, loss: 0.2154909074306488
step: 10, loss: 0.07214175164699554
step: 20, loss: 0.08634382486343384
step: 30, loss: 0.1334318220615387
step: 40, loss: 0.14191122353076935
step: 50, loss: 0.14052686095237732
step: 60, loss: 0.07160654664039612
step: 70, loss: 0.0739499032497406
step: 80, loss: 0.05065833777189255
step: 90, loss: 0.10641930252313614
step: 100, loss: 0.14845025539398193
step: 110, loss: 0.11400756239891052
step: 120, loss: 0.2811594307422638
step: 130, loss: 0.20097972452640533
step: 140, loss: 0.03097533993422985
step: 150, loss: 0.10937056690454483
step: 160, loss: 0.1644616723060608
step: 170, loss: 0.13748987019062042
step: 180, loss: 0.30284127593040466
step: 190, loss: 0.09940141439437866
step: 200, loss: 0.2226010113954544
step: 210, loss: 0.13767385482788086
step: 220, loss: 0.04033619910478592
step: 230, loss: 0.17916230857372284
step: 240, loss: 0.1087161973118782
step: 250, loss: 0.21842436492443085
step: 260, loss: 0.10917270183563232
step: 270, loss: 0.08687875419855118
step: 280, loss: 0.07751193642616272
step: 290, loss: 0.16514484584331512
step: 300, loss: 0.11536134779453278
step: 310, loss: 0.15605302155017853
step: 320, loss: 0.16239537298679352
step: 330, loss: 0.10884079337120056
epoch 3: dev_f1=0.81104033970276, f1=0.7974413646055437, best_f1=0.7974413646055437
step: 0, loss: 0.061193984001874924
step: 10, loss: 0.23886524140834808
step: 20, loss: 0.08212225139141083
step: 30, loss: 0.056565333157777786
step: 40, loss: 0.061733346432447433
step: 50, loss: 0.05920213460922241
step: 60, loss: 0.15533919632434845
step: 70, loss: 0.12737053632736206
step: 80, loss: 0.0978405699133873
step: 90, loss: 0.25846055150032043
step: 100, loss: 0.17329348623752594
step: 110, loss: 0.08899319171905518
step: 120, loss: 0.10331130027770996
step: 130, loss: 0.15298262238502502
step: 140, loss: 0.10443325340747833
step: 150, loss: 0.14062245190143585
step: 160, loss: 0.23703822493553162
step: 170, loss: 0.0968603640794754
step: 180, loss: 0.11441532522439957
step: 190, loss: 0.105477474629879
step: 200, loss: 0.12157765030860901
step: 210, loss: 0.1422463208436966
step: 220, loss: 0.07632645219564438
step: 230, loss: 0.07400403171777725
step: 240, loss: 0.15324129164218903
step: 250, loss: 0.03561960160732269
step: 260, loss: 0.01399150863289833
step: 270, loss: 0.1984773576259613
step: 280, loss: 0.055689550936222076
step: 290, loss: 0.14975924789905548
step: 300, loss: 0.07641314715147018
step: 310, loss: 0.09003156423568726
step: 320, loss: 0.09855100512504578
step: 330, loss: 0.0836687684059143
epoch 4: dev_f1=0.7918552036199096, f1=0.7709251101321585, best_f1=0.7974413646055437
step: 0, loss: 0.12848687171936035
step: 10, loss: 0.10870036482810974
step: 20, loss: 0.10573037713766098
step: 30, loss: 0.04578937217593193
step: 40, loss: 0.055933814495801926
step: 50, loss: 0.11128512024879456
step: 60, loss: 0.08969403058290482
step: 70, loss: 0.07379002124071121
step: 80, loss: 0.2737860381603241
step: 90, loss: 0.04141184687614441
step: 100, loss: 0.06674232333898544
step: 110, loss: 0.1215728223323822
step: 120, loss: 0.0973254144191742
step: 130, loss: 0.0959186851978302
step: 140, loss: 0.11326637864112854
step: 150, loss: 0.08899027854204178
step: 160, loss: 0.11440250277519226
step: 170, loss: 0.14124999940395355
step: 180, loss: 0.19752253592014313
step: 190, loss: 0.06338738650083542
step: 200, loss: 0.18993979692459106
step: 210, loss: 0.08267288655042648
step: 220, loss: 0.034769997000694275
step: 230, loss: 0.021022887900471687
step: 240, loss: 0.07784375548362732
step: 250, loss: 0.05188944935798645
step: 260, loss: 0.09750158339738846
step: 270, loss: 0.1056976467370987
step: 280, loss: 0.10746236145496368
step: 290, loss: 0.08912716060876846
step: 300, loss: 0.05363328754901886
step: 310, loss: 0.11630631238222122
step: 320, loss: 0.07321664690971375
step: 330, loss: 0.12417365610599518
epoch 5: dev_f1=0.7853881278538813, f1=0.7982062780269058, best_f1=0.7974413646055437
step: 0, loss: 0.038501836359500885
step: 10, loss: 0.03694787621498108
step: 20, loss: 0.1676558405160904
step: 30, loss: 0.13475453853607178
step: 40, loss: 0.1619136482477188
step: 50, loss: 0.15778852999210358
step: 60, loss: 0.1531340777873993
step: 70, loss: 0.11353712528944016
step: 80, loss: 0.07223288714885712
step: 90, loss: 0.14420245587825775
step: 100, loss: 0.06449872255325317
step: 110, loss: 0.062424436211586
step: 120, loss: 0.08652957528829575
step: 130, loss: 0.1189054325222969
step: 140, loss: 0.1516501009464264
step: 150, loss: 0.11115420609712601
step: 160, loss: 0.040513940155506134
step: 170, loss: 0.07094872742891312
step: 180, loss: 0.17447975277900696
step: 190, loss: 0.054179731756448746
step: 200, loss: 0.08753854781389236
step: 210, loss: 0.08520746976137161
step: 220, loss: 0.12785549461841583
step: 230, loss: 0.003389430698007345
step: 240, loss: 0.18672877550125122
step: 250, loss: 0.11078877002000809
step: 260, loss: 0.11566552519798279
step: 270, loss: 0.13749603927135468
step: 280, loss: 0.22415858507156372
step: 290, loss: 0.13853710889816284
step: 300, loss: 0.10254586488008499
step: 310, loss: 0.1370987743139267
step: 320, loss: 0.11592673510313034
step: 330, loss: 0.0912175104022026
epoch 6: dev_f1=0.8185840707964601, f1=0.7860262008733624, best_f1=0.7860262008733624
step: 0, loss: 0.16221976280212402
step: 10, loss: 0.0456463024020195
step: 20, loss: 0.12828324735164642
step: 30, loss: 0.07427369803190231
step: 40, loss: 0.21655409038066864
step: 50, loss: 0.055739399045705795
step: 60, loss: 0.0285046249628067
step: 70, loss: 0.06970354169607162
step: 80, loss: 0.042649369686841965
step: 90, loss: 0.06684289872646332
step: 100, loss: 0.13594239950180054
step: 110, loss: 0.061571523547172546
step: 120, loss: 0.05039206147193909
step: 130, loss: 0.11079911887645721
step: 140, loss: 0.13034601509571075
step: 150, loss: 0.15863069891929626
step: 160, loss: 0.047946490347385406
step: 170, loss: 0.1494883894920349
step: 180, loss: 0.029543399810791016
step: 190, loss: 0.029271557927131653
step: 200, loss: 0.09793267399072647
step: 210, loss: 0.0859132930636406
step: 220, loss: 0.022290965542197227
step: 230, loss: 0.09889049828052521
step: 240, loss: 0.08710882812738419
step: 250, loss: 0.07133976370096207
step: 260, loss: 0.12329982966184616
step: 270, loss: 0.09413039684295654
step: 280, loss: 0.16964560747146606
step: 290, loss: 0.06813892722129822
step: 300, loss: 0.20441333949565887
step: 310, loss: 0.07748739421367645
step: 320, loss: 0.013744561932981014
step: 330, loss: 0.08498826622962952
epoch 7: dev_f1=0.8110599078341014, f1=0.7990867579908676, best_f1=0.7860262008733624
step: 0, loss: 0.1550934910774231
step: 10, loss: 0.10342033952474594
step: 20, loss: 0.14172285795211792
step: 30, loss: 0.13174587488174438
step: 40, loss: 0.08541075885295868
step: 50, loss: 0.09873407334089279
step: 60, loss: 0.09719450026750565
step: 70, loss: 0.11541003733873367
step: 80, loss: 0.09726060181856155
step: 90, loss: 0.04959184303879738
step: 100, loss: 0.07947937399148941
step: 110, loss: 0.06134115904569626
step: 120, loss: 0.14882928133010864
step: 130, loss: 0.042628493160009384
step: 140, loss: 0.10612599551677704
step: 150, loss: 0.051268838346004486
step: 160, loss: 0.039802949875593185
step: 170, loss: 0.1575780212879181
step: 180, loss: 0.06264214217662811
step: 190, loss: 0.1116667166352272
step: 200, loss: 0.13775677978992462
step: 210, loss: 0.19653944671154022
step: 220, loss: 0.07987398654222488
step: 230, loss: 0.12294293940067291
step: 240, loss: 0.04090910777449608
step: 250, loss: 0.17889449000358582
step: 260, loss: 0.03560074791312218
step: 270, loss: 0.049322620034217834
step: 280, loss: 0.10106442868709564
step: 290, loss: 0.03445323184132576
step: 300, loss: 0.1513330042362213
step: 310, loss: 0.074757881462574
step: 320, loss: 0.11108142137527466
step: 330, loss: 0.13400012254714966
epoch 8: dev_f1=0.8137254901960784, f1=0.8108108108108109, best_f1=0.7860262008733624
step: 0, loss: 0.08422784507274628
step: 10, loss: 0.10067082196474075
step: 20, loss: 0.027803508564829826
step: 30, loss: 0.05792124941945076
step: 40, loss: 0.00642543938010931
step: 50, loss: 0.11687399446964264
step: 60, loss: 0.10929282009601593
step: 70, loss: 0.13765962421894073
step: 80, loss: 0.07835683226585388
step: 90, loss: 0.04245344549417496
step: 100, loss: 0.11256703734397888
step: 110, loss: 0.08951595425605774
step: 120, loss: 0.05390293151140213
step: 130, loss: 0.04649461805820465
step: 140, loss: 0.0969587191939354
step: 150, loss: 0.09209716320037842
step: 160, loss: 0.03948557376861572
step: 170, loss: 0.059867922216653824
step: 180, loss: 0.0825231522321701
step: 190, loss: 0.09702995419502258
step: 200, loss: 0.05841312184929848
step: 210, loss: 0.12452427297830582
step: 220, loss: 0.06780269742012024
step: 230, loss: 0.24625489115715027
step: 240, loss: 0.0817646011710167
step: 250, loss: 0.111690454185009
step: 260, loss: 0.11404966562986374
step: 270, loss: 0.1761339157819748
step: 280, loss: 0.12581698596477509
step: 290, loss: 0.09977846592664719
step: 300, loss: 0.14460347592830658
step: 310, loss: 0.17411509156227112
step: 320, loss: 0.06063704192638397
step: 330, loss: 0.04752304032444954
epoch 9: dev_f1=0.8366890380313199, f1=0.7991071428571428, best_f1=0.7991071428571428
step: 0, loss: 0.19476920366287231
step: 10, loss: 0.024162672460079193
step: 20, loss: 0.08404025435447693
step: 30, loss: 0.14430156350135803
step: 40, loss: 0.10520254075527191
step: 50, loss: 0.05814309045672417
step: 60, loss: 0.037406377494335175
step: 70, loss: 0.14355726540088654
step: 80, loss: 0.08700847625732422
step: 90, loss: 0.16743764281272888
step: 100, loss: 0.08313781023025513
step: 110, loss: 0.0008547004545107484
step: 120, loss: 0.21267059445381165
step: 130, loss: 0.041236333549022675
step: 140, loss: 0.11398348957300186
step: 150, loss: 0.08445999771356583
step: 160, loss: 0.12373541295528412
step: 170, loss: 0.17274881899356842
step: 180, loss: 0.054050665348768234
step: 190, loss: 0.11596687883138657
step: 200, loss: 0.04160474240779877
step: 210, loss: 0.03256551921367645
step: 220, loss: 0.06556425243616104
step: 230, loss: 0.09102887660264969
step: 240, loss: 0.19311511516571045
step: 250, loss: 0.11830917000770569
step: 260, loss: 0.041265953332185745
step: 270, loss: 0.029623765498399734
step: 280, loss: 0.06674996018409729
step: 290, loss: 0.16783639788627625
step: 300, loss: 0.06886638700962067
step: 310, loss: 0.040679819881916046
step: 320, loss: 0.11160681396722794
step: 330, loss: 0.06430136412382126
epoch 10: dev_f1=0.8156682027649769, f1=0.7782805429864253, best_f1=0.7991071428571428
step: 0, loss: 0.08479081094264984
step: 10, loss: 0.13800938427448273
step: 20, loss: 0.08117751032114029
step: 30, loss: 0.0906289741396904
step: 40, loss: 0.07644195109605789
step: 50, loss: 0.11820980161428452
step: 60, loss: 0.046391263604164124
step: 70, loss: 0.10984721779823303
step: 80, loss: 0.034848444163799286
step: 90, loss: 0.07069958746433258
step: 100, loss: 0.11110370606184006
step: 110, loss: 0.04898204654455185
step: 120, loss: 0.07333305478096008
step: 130, loss: 0.06702390313148499
step: 140, loss: 0.16948729753494263
step: 150, loss: 0.05644528567790985
step: 160, loss: 0.20794522762298584
step: 170, loss: 0.08661830425262451
step: 180, loss: 0.07527025043964386
step: 190, loss: 0.17302252352237701
step: 200, loss: 0.07092875242233276
step: 210, loss: 0.09015810489654541
step: 220, loss: 0.049549657851457596
step: 230, loss: 0.2329867035150528
step: 240, loss: 0.05072375014424324
step: 250, loss: 0.07301996648311615
step: 260, loss: 0.09168355166912079
step: 270, loss: 0.1268683671951294
step: 280, loss: 0.1287543773651123
step: 290, loss: 0.022286761552095413
step: 300, loss: 0.059205230325460434
step: 310, loss: 0.0186169296503067
step: 320, loss: 0.18031562864780426
step: 330, loss: 0.0894944816827774
epoch 11: dev_f1=0.8227272727272728, f1=0.8054298642533937, best_f1=0.7991071428571428
step: 0, loss: 0.08199721574783325
step: 10, loss: 0.0879037007689476
step: 20, loss: 0.03423066437244415
step: 30, loss: 0.0584285631775856
step: 40, loss: 0.05538007989525795
step: 50, loss: 0.0685703307390213
step: 60, loss: 0.017400413751602173
step: 70, loss: 0.07773804664611816
step: 80, loss: 0.09854961186647415
step: 90, loss: 0.05869303271174431
step: 100, loss: 0.0634908676147461
step: 110, loss: 0.1654883772134781
step: 120, loss: 0.06388571858406067
step: 130, loss: 0.03348343446850777
step: 140, loss: 0.04819123074412346
step: 150, loss: 0.09609614312648773
step: 160, loss: 0.08476344496011734
step: 170, loss: 0.020226677879691124
step: 180, loss: 3.656300759757869e-05
step: 190, loss: 0.126127228140831
step: 200, loss: 0.07631507515907288
step: 210, loss: 0.061180658638477325
step: 220, loss: 0.06671006232500076
step: 230, loss: 0.06871658563613892
step: 240, loss: 0.0834551751613617
step: 250, loss: 0.0515587143599987
step: 260, loss: 0.10006155073642731
step: 270, loss: 0.12924326956272125
step: 280, loss: 0.07839890569448471
step: 290, loss: 0.17489950358867645
step: 300, loss: 0.07763392478227615
step: 310, loss: 0.14682522416114807
step: 320, loss: 0.10530778020620346
step: 330, loss: 0.1190696433186531
epoch 12: dev_f1=0.8094117647058824, f1=0.8047619047619048, best_f1=0.7991071428571428
step: 0, loss: 0.03420030698180199
step: 10, loss: 0.07739308476448059
step: 20, loss: 0.07134728133678436
step: 30, loss: 0.07490292191505432
step: 40, loss: 0.07108244299888611
step: 50, loss: 0.12543880939483643
step: 60, loss: 0.0169129129499197
step: 70, loss: 0.08677960932254791
step: 80, loss: 0.05790572240948677
step: 90, loss: 0.10320627689361572
step: 100, loss: 0.11456439644098282
step: 110, loss: 0.16121049225330353
step: 120, loss: 0.10241459310054779
step: 130, loss: 0.061924081295728683
step: 140, loss: 0.0909956768155098
step: 150, loss: 0.1132151335477829
step: 160, loss: 0.14107540249824524
step: 170, loss: 0.023769600316882133
step: 180, loss: 0.07638398557901382
step: 190, loss: 0.06853437423706055
step: 200, loss: 0.07011831551790237
step: 210, loss: 0.12688232958316803
step: 220, loss: 0.07342908531427383
step: 230, loss: 0.0758061334490776
step: 240, loss: 0.11019519716501236
step: 250, loss: 0.04920300096273422
step: 260, loss: 0.047958336770534515
step: 270, loss: 0.01844514161348343
step: 280, loss: 0.03808300942182541
step: 290, loss: 0.06856418401002884
step: 300, loss: 0.05476371943950653
step: 310, loss: 0.1197480708360672
step: 320, loss: 0.29784873127937317
step: 330, loss: 0.1469603031873703
epoch 13: dev_f1=0.8034188034188033, f1=0.794816414686825, best_f1=0.7991071428571428
step: 0, loss: 0.08778627961874008
step: 10, loss: 0.07139867544174194
step: 20, loss: 0.13274092972278595
step: 30, loss: 0.08310870826244354
step: 40, loss: 0.08822892606258392
step: 50, loss: 0.08036370575428009
step: 60, loss: 0.030255883932113647
step: 70, loss: 0.08771606534719467
step: 80, loss: 0.010610667057335377
step: 90, loss: 0.0265309140086174
step: 100, loss: 0.08211512863636017
step: 110, loss: 0.08577697724103928
step: 120, loss: 0.14947237074375153
step: 130, loss: 0.14409910142421722
step: 140, loss: 0.1434256136417389
step: 150, loss: 0.0027896487154066563
step: 160, loss: 0.1202516183257103
step: 170, loss: 0.07014775276184082
step: 180, loss: 0.139836385846138
step: 190, loss: 0.08122318238019943
step: 200, loss: 0.05460631474852562
step: 210, loss: 0.17899183928966522
step: 220, loss: 0.043707337230443954
step: 230, loss: 0.11321762949228287
step: 240, loss: 0.09233493357896805
step: 250, loss: 0.12621504068374634
step: 260, loss: 0.11937978863716125
step: 270, loss: 0.11036274582147598
step: 280, loss: 0.06216060742735863
step: 290, loss: 0.021963318809866905
step: 300, loss: 0.08118040859699249
step: 310, loss: 0.12180151045322418
step: 320, loss: 0.019207173958420753
step: 330, loss: 0.0545034259557724
epoch 14: dev_f1=0.8030303030303031, f1=0.8166259168704155, best_f1=0.7991071428571428
step: 0, loss: 0.0434671975672245
step: 10, loss: 0.018311748281121254
step: 20, loss: 0.023062825202941895
step: 30, loss: 0.051227420568466187
step: 40, loss: 0.15496723353862762
step: 50, loss: 0.12200857698917389
step: 60, loss: 0.1704428493976593
step: 70, loss: 0.045511405915021896
step: 80, loss: 0.09510044008493423
step: 90, loss: 0.09447779506444931
step: 100, loss: 0.09966659545898438
step: 110, loss: 0.13179880380630493
step: 120, loss: 0.06643477827310562
step: 130, loss: 0.10059787333011627
step: 140, loss: 0.031481530517339706
step: 150, loss: 0.06263139843940735
step: 160, loss: 0.11613456904888153
step: 170, loss: 0.05624254792928696
step: 180, loss: 0.10297656804323196
step: 190, loss: 0.029851816594600677
step: 200, loss: 0.09790229052305222
step: 210, loss: 0.07377299666404724
step: 220, loss: 0.08529011160135269
step: 230, loss: 0.10898035019636154
step: 240, loss: 0.09084013104438782
step: 250, loss: 0.06095687672495842
step: 260, loss: 0.10653611272573471
step: 270, loss: 0.12223003804683685
step: 280, loss: 0.05662432685494423
step: 290, loss: 0.18766216933727264
step: 300, loss: 0.011798849329352379
step: 310, loss: 0.09924888610839844
step: 320, loss: 0.061630405485630035
step: 330, loss: 0.049497708678245544
epoch 15: dev_f1=0.8049382716049382, f1=0.7931034482758621, best_f1=0.7991071428571428
step: 0, loss: 0.0722898468375206
step: 10, loss: 0.045378223061561584
step: 20, loss: 0.033492688089609146
step: 30, loss: 0.108190156519413
step: 40, loss: 0.11397124081850052
step: 50, loss: 0.048358917236328125
step: 60, loss: 0.11870896071195602
step: 70, loss: 0.09619726985692978
step: 80, loss: 0.10976672172546387
step: 90, loss: 0.06127212941646576
step: 100, loss: 0.11192024499177933
step: 110, loss: 0.08375425636768341
step: 120, loss: 0.1004445031285286
step: 130, loss: 0.1935337334871292
step: 140, loss: 0.09788869321346283
step: 150, loss: 0.06825606524944305
step: 160, loss: 0.06997907161712646
step: 170, loss: 0.043584275990724564
step: 180, loss: 0.15193746984004974
step: 190, loss: 0.01765565015375614
step: 200, loss: 0.14256292581558228
step: 210, loss: 0.15075500309467316
step: 220, loss: 0.05948149412870407
step: 230, loss: 0.029977262020111084
step: 240, loss: 0.10684183239936829
step: 250, loss: 0.12440609931945801
step: 260, loss: 0.045042555779218674
step: 270, loss: 0.054992858320474625
step: 280, loss: 0.0534142404794693
step: 290, loss: 0.08406783640384674
step: 300, loss: 0.09498774260282516
step: 310, loss: 0.16175583004951477
step: 320, loss: 0.14379803836345673
step: 330, loss: 0.04759691283106804
epoch 16: dev_f1=0.8129330254041571, f1=0.7824074074074074, best_f1=0.7991071428571428
step: 0, loss: 0.05131516233086586
step: 10, loss: 0.07010994851589203
step: 20, loss: 0.15324623882770538
step: 30, loss: 0.05402364209294319
step: 40, loss: 0.10823223739862442
step: 50, loss: 0.04681408032774925
step: 60, loss: 0.032784320414066315
step: 70, loss: 0.08970315009355545
step: 80, loss: 0.14384832978248596
step: 90, loss: 0.06703867018222809
step: 100, loss: 0.04036177322268486
step: 110, loss: 0.1273537129163742
step: 120, loss: 0.12895555794239044
step: 130, loss: 0.027486786246299744
step: 140, loss: 0.10461165010929108
step: 150, loss: 0.07506034523248672
step: 160, loss: 0.0338970385491848
step: 170, loss: 0.12295956164598465
step: 180, loss: 0.038429923355579376
step: 190, loss: 0.045907799154520035
step: 200, loss: 0.12829641997814178
step: 210, loss: 0.056786391884088516
step: 220, loss: 0.0013048003893345594
step: 230, loss: 0.13036736845970154
step: 240, loss: 3.5909080907003954e-05
step: 250, loss: 0.04376295953989029
step: 260, loss: 0.08167536556720734
step: 270, loss: 0.10466859489679337
step: 280, loss: 0.0431317575275898
step: 290, loss: 0.05329371243715286
step: 300, loss: 5.276043157209642e-05
step: 310, loss: 0.04528602957725525
step: 320, loss: 0.20287983119487762
step: 330, loss: 0.051895804703235626
epoch 17: dev_f1=0.8142857142857144, f1=0.8, best_f1=0.7991071428571428
step: 0, loss: 0.09831316769123077
step: 10, loss: 0.06390306353569031
step: 20, loss: 0.09730380773544312
step: 30, loss: 0.09043436497449875
step: 40, loss: 0.036858804523944855
step: 50, loss: 0.09557286649942398
step: 60, loss: 0.0965200886130333
step: 70, loss: 0.12656839191913605
step: 80, loss: 0.04817436635494232
step: 90, loss: 0.08246627449989319
step: 100, loss: 0.052795037627220154
step: 110, loss: 0.04547610133886337
step: 120, loss: 0.04174375906586647
step: 130, loss: 0.11580554395914078
step: 140, loss: 0.03986338526010513
step: 150, loss: 0.10236246883869171
step: 160, loss: 0.029965631663799286
step: 170, loss: 0.029237637296319008
step: 180, loss: 0.06871185451745987
step: 190, loss: 0.062083903700113297
step: 200, loss: 0.049661941826343536
step: 210, loss: 0.16304244101047516
step: 220, loss: 0.1010499969124794
step: 230, loss: 0.024463633075356483
step: 240, loss: 0.0325637049973011
step: 250, loss: 0.12904737889766693
step: 260, loss: 0.07454051822423935
step: 270, loss: 0.08727505058050156
step: 280, loss: 0.12540055811405182
step: 290, loss: 0.014902785420417786
step: 300, loss: 0.19746224582195282
step: 310, loss: 0.10720905661582947
step: 320, loss: 0.058728624135255814
step: 330, loss: 0.08096431940793991
epoch 18: dev_f1=0.8018648018648018, f1=0.8018867924528301, best_f1=0.7991071428571428
step: 0, loss: 0.08460033684968948
step: 10, loss: 0.09557653218507767
step: 20, loss: 0.019273288547992706
step: 30, loss: 0.10032785683870316
step: 40, loss: 0.08917722851037979
step: 50, loss: 0.03472135215997696
step: 60, loss: 0.12012562155723572
step: 70, loss: 0.028317419812083244
step: 80, loss: 0.012772650457918644
step: 90, loss: 0.032042667269706726
step: 100, loss: 0.08999977260828018
step: 110, loss: 0.02136709913611412
step: 120, loss: 0.15911491215229034
step: 130, loss: 0.014024684205651283
step: 140, loss: 0.055064909160137177
step: 150, loss: 0.04036905989050865
step: 160, loss: 0.06408050656318665
step: 170, loss: 0.0858868882060051
step: 180, loss: 0.09043481945991516
step: 190, loss: 0.13334015011787415
step: 200, loss: 0.04529355466365814
step: 210, loss: 0.16360221803188324
step: 220, loss: 0.07617324590682983
step: 230, loss: 0.02995237149298191
step: 240, loss: 0.02805713564157486
step: 250, loss: 0.12306255847215652
step: 260, loss: 0.013082749210298061
step: 270, loss: 0.0010617946973070502
step: 280, loss: 0.04577057436108589
step: 290, loss: 0.05402855575084686
step: 300, loss: 0.030505554750561714
step: 310, loss: 0.10016129165887833
step: 320, loss: 0.06830894947052002
step: 330, loss: 0.08785742521286011
epoch 19: dev_f1=0.7969924812030076, f1=0.7950617283950617, best_f1=0.7991071428571428
step: 0, loss: 0.06298434734344482
step: 10, loss: 0.022970205172896385
step: 20, loss: 0.07632303982973099
step: 30, loss: 0.03229166567325592
step: 40, loss: 0.08219288289546967
step: 50, loss: 0.08462575823068619
step: 60, loss: 0.06533345580101013
step: 70, loss: 0.10887624323368073
step: 80, loss: 0.18731552362442017
step: 90, loss: 0.07387179136276245
step: 100, loss: 0.07042151689529419
step: 110, loss: 0.05442386120557785
step: 120, loss: 0.06411191821098328
step: 130, loss: 0.09848509728908539
step: 140, loss: 0.06519864499568939
step: 150, loss: 0.029884474352002144
step: 160, loss: 0.049980442970991135
step: 170, loss: 0.014553639106452465
step: 180, loss: 0.07914862036705017
step: 190, loss: 0.03200305253267288
step: 200, loss: 0.14797146618366241
step: 210, loss: 0.09823836386203766
step: 220, loss: 0.05878617614507675
step: 230, loss: 0.04649645835161209
step: 240, loss: 0.10777473449707031
step: 250, loss: 0.12526865303516388
step: 260, loss: 0.08470801264047623
step: 270, loss: 0.12858876585960388
step: 280, loss: 0.02796955779194832
step: 290, loss: 0.07080522179603577
step: 300, loss: 0.0320676825940609
step: 310, loss: 0.04376962408423424
step: 320, loss: 0.08389000594615936
step: 330, loss: 0.014108991250395775
epoch 20: dev_f1=0.7930174563591021, f1=0.7980295566502462, best_f1=0.7991071428571428
