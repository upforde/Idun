cuda
Device: cuda
step: 0, loss: 0.8201072216033936
step: 10, loss: 0.42666253447532654
step: 20, loss: 0.14756084978580475
step: 30, loss: 0.2184865027666092
step: 40, loss: 0.06631264835596085
step: 50, loss: 0.3199080526828766
step: 60, loss: 0.30599167943000793
step: 70, loss: 0.22994202375411987
step: 80, loss: 0.22849926352500916
step: 90, loss: 0.30078232288360596
step: 100, loss: 0.1627482920885086
step: 110, loss: 0.15993395447731018
step: 120, loss: 0.12869344651699066
step: 130, loss: 0.3736707270145416
step: 140, loss: 0.31678059697151184
step: 150, loss: 0.24912941455841064
step: 160, loss: 0.5027318596839905
step: 170, loss: 0.1354847103357315
step: 180, loss: 0.24401314556598663
step: 190, loss: 0.21771055459976196
step: 200, loss: 0.17654329538345337
step: 210, loss: 0.04150359705090523
step: 220, loss: 0.1635725498199463
step: 230, loss: 0.24172547459602356
step: 240, loss: 0.52248215675354
step: 250, loss: 0.517100989818573
step: 260, loss: 0.22004640102386475
step: 270, loss: 0.14300420880317688
step: 280, loss: 0.220956951379776
step: 290, loss: 0.21467478573322296
step: 300, loss: 0.18496853113174438
step: 310, loss: 0.10671509057283401
step: 320, loss: 0.20048470795154572
step: 330, loss: 0.07953925430774689
epoch 1: dev_f1=0.5597014925373135, f1=0.5850091407678245, best_f1=0.5850091407678245
step: 0, loss: 0.07283730059862137
step: 10, loss: 0.15855340659618378
step: 20, loss: 0.117031529545784
step: 30, loss: 0.17920199036598206
step: 40, loss: 0.20542007684707642
step: 50, loss: 0.10300097614526749
step: 60, loss: 0.15759599208831787
step: 70, loss: 0.21573957800865173
step: 80, loss: 0.07873210310935974
step: 90, loss: 0.15669110417366028
step: 100, loss: 0.27328914403915405
step: 110, loss: 0.24730820953845978
step: 120, loss: 0.1520349085330963
step: 130, loss: 0.16832667589187622
step: 140, loss: 0.11743566393852234
step: 150, loss: 0.20996135473251343
step: 160, loss: 0.024398939684033394
step: 170, loss: 0.07355844974517822
step: 180, loss: 0.08545194566249847
step: 190, loss: 0.09109479188919067
step: 200, loss: 0.04708871245384216
step: 210, loss: 0.1438697874546051
step: 220, loss: 0.08648867905139923
step: 230, loss: 0.11043670773506165
step: 240, loss: 0.04715770483016968
step: 250, loss: 0.17811284959316254
step: 260, loss: 0.1756439357995987
step: 270, loss: 0.019577208906412125
step: 280, loss: 0.07298935204744339
step: 290, loss: 0.1425420045852661
step: 300, loss: 0.11739690601825714
step: 310, loss: 0.10968051850795746
step: 320, loss: 0.10991602391004562
step: 330, loss: 0.05143902823328972
epoch 2: dev_f1=0.7780320366132724, f1=0.7527839643652561, best_f1=0.7527839643652561
step: 0, loss: 0.12535282969474792
step: 10, loss: 0.06854693591594696
step: 20, loss: 0.0261137206107378
step: 30, loss: 0.06464207917451859
step: 40, loss: 0.04058276489377022
step: 50, loss: 0.011183258146047592
step: 60, loss: 0.0645524337887764
step: 70, loss: 0.11727945506572723
step: 80, loss: 0.18253344297409058
step: 90, loss: 0.05430353432893753
step: 100, loss: 0.19537460803985596
step: 110, loss: 0.16962510347366333
step: 120, loss: 0.11328373849391937
step: 130, loss: 0.06581434607505798
step: 140, loss: 0.035126637667417526
step: 150, loss: 0.06513958424329758
step: 160, loss: 0.10764442384243011
step: 170, loss: 0.17769020795822144
step: 180, loss: 0.11640845239162445
step: 190, loss: 0.05597938969731331
step: 200, loss: 0.33584433794021606
step: 210, loss: 0.04956328123807907
step: 220, loss: 0.1338486522436142
step: 230, loss: 0.08525194227695465
step: 240, loss: 0.1809941977262497
step: 250, loss: 0.05290089547634125
step: 260, loss: 0.08479077368974686
step: 270, loss: 0.1387777179479599
step: 280, loss: 0.07573795318603516
step: 290, loss: 0.04695083945989609
step: 300, loss: 0.17530159652233124
step: 310, loss: 0.10604201257228851
step: 320, loss: 0.09195400029420853
step: 330, loss: 0.07868829369544983
epoch 3: dev_f1=0.7973273942093541, f1=0.7666666666666666, best_f1=0.7666666666666666
step: 0, loss: 0.0837656632065773
step: 10, loss: 0.10318587720394135
step: 20, loss: 0.058886826038360596
step: 30, loss: 0.14297400414943695
step: 40, loss: 0.10568156093358994
step: 50, loss: 0.06505385041236877
step: 60, loss: 0.23415948450565338
step: 70, loss: 0.07844430953264236
step: 80, loss: 0.054088614881038666
step: 90, loss: 0.11559215188026428
step: 100, loss: 0.3274849057197571
step: 110, loss: 0.14724771678447723
step: 120, loss: 0.13509368896484375
step: 130, loss: 0.027167119085788727
step: 140, loss: 0.026664135977625847
step: 150, loss: 0.13365471363067627
step: 160, loss: 0.15202176570892334
step: 170, loss: 0.03927834704518318
step: 180, loss: 0.12570074200630188
step: 190, loss: 0.11997101455926895
step: 200, loss: 0.22761505842208862
step: 210, loss: 0.06977269053459167
step: 220, loss: 0.10922728478908539
step: 230, loss: 0.11280878633260727
step: 240, loss: 0.05950555577874184
step: 250, loss: 0.06427105516195297
step: 260, loss: 0.17291930317878723
step: 270, loss: 0.08244219422340393
step: 280, loss: 0.01832650788128376
step: 290, loss: 0.050179366022348404
step: 300, loss: 0.11769033223390579
step: 310, loss: 0.06674378365278244
step: 320, loss: 0.12110625207424164
step: 330, loss: 0.06249210610985756
epoch 4: dev_f1=0.7702702702702702, f1=0.778021978021978, best_f1=0.7666666666666666
step: 0, loss: 0.09493167698383331
step: 10, loss: 0.1106073260307312
step: 20, loss: 0.12100022286176682
step: 30, loss: 0.08690083026885986
step: 40, loss: 0.09394723176956177
step: 50, loss: 0.051230259239673615
step: 60, loss: 0.08698353916406631
step: 70, loss: 0.13394466042518616
step: 80, loss: 0.22385549545288086
step: 90, loss: 0.09001626819372177
step: 100, loss: 0.0664111003279686
step: 110, loss: 0.11425621062517166
step: 120, loss: 0.09787295013666153
step: 130, loss: 0.13069182634353638
step: 140, loss: 0.0654640644788742
step: 150, loss: 0.05865301191806793
step: 160, loss: 0.12246448546648026
step: 170, loss: 0.013999994844198227
step: 180, loss: 0.18243826925754547
step: 190, loss: 0.13427475094795227
step: 200, loss: 0.1476491540670395
step: 210, loss: 0.07393576949834824
step: 220, loss: 0.05626920238137245
step: 230, loss: 0.21077802777290344
step: 240, loss: 0.112162284553051
step: 250, loss: 0.15537738800048828
step: 260, loss: 0.028219185769557953
step: 270, loss: 0.11324050277471542
step: 280, loss: 0.06659581512212753
step: 290, loss: 0.11092802882194519
step: 300, loss: 0.11885260790586472
step: 310, loss: 0.06749291718006134
step: 320, loss: 0.035508692264556885
step: 330, loss: 0.06963979452848434
epoch 5: dev_f1=0.7964601769911506, f1=0.7792207792207791, best_f1=0.7666666666666666
step: 0, loss: 0.028657395392656326
step: 10, loss: 0.10366399586200714
step: 20, loss: 0.11202962696552277
step: 30, loss: 0.030601121485233307
step: 40, loss: 0.10611031204462051
step: 50, loss: 0.0671236589550972
step: 60, loss: 0.02059001848101616
step: 70, loss: 0.11379191279411316
step: 80, loss: 0.08413194864988327
step: 90, loss: 0.05809035897254944
step: 100, loss: 0.11971105635166168
step: 110, loss: 0.01108588557690382
step: 120, loss: 0.04961897432804108
step: 130, loss: 0.0708179622888565
step: 140, loss: 0.0934743583202362
step: 150, loss: 0.07046116888523102
step: 160, loss: 0.092326320707798
step: 170, loss: 0.042302753776311874
step: 180, loss: 0.06839348375797272
step: 190, loss: 0.18631644546985626
step: 200, loss: 0.0928596705198288
step: 210, loss: 0.1058698296546936
step: 220, loss: 0.02390330284833908
step: 230, loss: 0.1389210820198059
step: 240, loss: 0.1283845603466034
step: 250, loss: 0.1632874757051468
step: 260, loss: 0.09013737738132477
step: 270, loss: 0.15032024681568146
step: 280, loss: 0.20442385971546173
step: 290, loss: 0.02501825988292694
step: 300, loss: 0.07376259565353394
step: 310, loss: 0.11608900874853134
step: 320, loss: 0.094829261302948
step: 330, loss: 0.22371287643909454
epoch 6: dev_f1=0.8037383177570093, f1=0.7892376681614349, best_f1=0.7892376681614349
step: 0, loss: 0.16572776436805725
step: 10, loss: 0.07566803693771362
step: 20, loss: 0.05147405341267586
step: 30, loss: 0.169427752494812
step: 40, loss: 0.15089309215545654
step: 50, loss: 0.09258325397968292
step: 60, loss: 0.03804047405719757
step: 70, loss: 0.093231700360775
step: 80, loss: 0.12286251783370972
step: 90, loss: 0.10747144371271133
step: 100, loss: 0.12088168412446976
step: 110, loss: 0.09533285349607468
step: 120, loss: 0.1128704622387886
step: 130, loss: 0.05190151184797287
step: 140, loss: 0.12574289739131927
step: 150, loss: 0.08081428706645966
step: 160, loss: 0.04628867655992508
step: 170, loss: 0.11065439879894257
step: 180, loss: 0.1400652378797531
step: 190, loss: 0.04302920401096344
step: 200, loss: 0.10092603415250778
step: 210, loss: 0.040537748485803604
step: 220, loss: 0.057984985411167145
step: 230, loss: 0.10317828506231308
step: 240, loss: 0.01774229295551777
step: 250, loss: 0.167870432138443
step: 260, loss: 0.08143699169158936
step: 270, loss: 0.044350262731313705
step: 280, loss: 0.14115414023399353
step: 290, loss: 0.07348652929067612
step: 300, loss: 0.08235546201467514
step: 310, loss: 0.03279491513967514
step: 320, loss: 0.08616089075803757
step: 330, loss: 0.1034846380352974
epoch 7: dev_f1=0.8314087759815242, f1=0.7935034802784221, best_f1=0.7935034802784221
step: 0, loss: 0.057676032185554504
step: 10, loss: 0.07287991046905518
step: 20, loss: 0.14648456871509552
step: 30, loss: 0.05237444490194321
step: 40, loss: 0.1118210107088089
step: 50, loss: 0.15299540758132935
step: 60, loss: 0.12589354813098907
step: 70, loss: 0.04212699085474014
step: 80, loss: 0.09907857328653336
step: 90, loss: 0.0412873774766922
step: 100, loss: 0.023958967998623848
step: 110, loss: 0.1240229532122612
step: 120, loss: 0.1470809280872345
step: 130, loss: 0.08107444643974304
step: 140, loss: 0.03543166071176529
step: 150, loss: 0.048257626593112946
step: 160, loss: 0.08319675177335739
step: 170, loss: 0.10856464505195618
step: 180, loss: 0.06094398349523544
step: 190, loss: 0.16394181549549103
step: 200, loss: 0.08079373836517334
step: 210, loss: 0.11097969859838486
step: 220, loss: 0.15571478009223938
step: 230, loss: 0.07203388214111328
step: 240, loss: 0.02719902992248535
step: 250, loss: 0.14285814762115479
step: 260, loss: 0.10092691332101822
step: 270, loss: 0.08807186037302017
step: 280, loss: 0.03856027126312256
step: 290, loss: 0.1428942084312439
step: 300, loss: 0.1444484144449234
step: 310, loss: 0.1583765149116516
step: 320, loss: 0.08058863878250122
step: 330, loss: 0.0868588536977768
epoch 8: dev_f1=0.793859649122807, f1=0.7854077253218885, best_f1=0.7935034802784221
step: 0, loss: 0.024815114215016365
step: 10, loss: 0.030574047937989235
step: 20, loss: 0.0582621693611145
step: 30, loss: 0.13183246552944183
step: 40, loss: 0.08893635123968124
step: 50, loss: 0.12955696880817413
step: 60, loss: 0.05822433531284332
step: 70, loss: 0.0985071212053299
step: 80, loss: 0.11146729439496994
step: 90, loss: 0.15391187369823456
step: 100, loss: 0.08847630769014359
step: 110, loss: 0.0450279600918293
step: 120, loss: 0.07851472496986389
step: 130, loss: 0.10541024059057236
step: 140, loss: 0.04616068676114082
step: 150, loss: 0.0537809394299984
step: 160, loss: 0.06630894541740417
step: 170, loss: 0.14468087255954742
step: 180, loss: 0.027762319892644882
step: 190, loss: 0.045817695558071136
step: 200, loss: 0.06429681181907654
step: 210, loss: 0.18763874471187592
step: 220, loss: 0.12957356870174408
step: 230, loss: 0.14527998864650726
step: 240, loss: 0.0421474315226078
step: 250, loss: 0.05866560339927673
step: 260, loss: 0.13759846985340118
step: 270, loss: 0.10490737855434418
step: 280, loss: 0.014863100834190845
step: 290, loss: 0.09894764423370361
step: 300, loss: 0.10096507519483566
step: 310, loss: 0.1351119428873062
step: 320, loss: 0.06692320853471756
step: 330, loss: 0.08411698043346405
epoch 9: dev_f1=0.8093023255813954, f1=0.779510022271715, best_f1=0.7935034802784221
step: 0, loss: 0.10620257258415222
step: 10, loss: 0.09824717044830322
step: 20, loss: 0.024089567363262177
step: 30, loss: 0.06269089877605438
step: 40, loss: 0.10638964176177979
step: 50, loss: 0.12251094728708267
step: 60, loss: 0.0680621862411499
step: 70, loss: 0.04740079119801521
step: 80, loss: 0.08274427056312561
step: 90, loss: 0.07303131371736526
step: 100, loss: 0.05984301120042801
step: 110, loss: 0.14314144849777222
step: 120, loss: 0.08973551541566849
step: 130, loss: 0.06445206701755524
step: 140, loss: 0.0644114762544632
step: 150, loss: 0.19936774671077728
step: 160, loss: 0.08767695724964142
step: 170, loss: 0.073240265250206
step: 180, loss: 0.07488757371902466
step: 190, loss: 0.11568951606750488
step: 200, loss: 0.16600292921066284
step: 210, loss: 0.21490921080112457
step: 220, loss: 0.13657794892787933
step: 230, loss: 0.1222008764743805
step: 240, loss: 0.1349160373210907
step: 250, loss: 0.1553267538547516
step: 260, loss: 0.06552594155073166
step: 270, loss: 0.1562780737876892
step: 280, loss: 0.1602526307106018
step: 290, loss: 0.233723446726799
step: 300, loss: 0.04630244895815849
step: 310, loss: 0.06748277693986893
step: 320, loss: 0.04792186617851257
step: 330, loss: 0.07450004667043686
epoch 10: dev_f1=0.8086124401913874, f1=0.7830188679245284, best_f1=0.7935034802784221
step: 0, loss: 0.08368958532810211
step: 10, loss: 0.029221557080745697
step: 20, loss: 0.07099571079015732
step: 30, loss: 0.12394925206899643
step: 40, loss: 0.05521329492330551
step: 50, loss: 0.07006154209375381
step: 60, loss: 0.061345987021923065
step: 70, loss: 0.0900038480758667
step: 80, loss: 0.08820132911205292
step: 90, loss: 0.050624143332242966
step: 100, loss: 0.0757911205291748
step: 110, loss: 0.10788414627313614
step: 120, loss: 0.21875867247581482
step: 130, loss: 0.07249076664447784
step: 140, loss: 0.024541622027754784
step: 150, loss: 0.16367653012275696
step: 160, loss: 0.08148189634084702
step: 170, loss: 0.08270932734012604
step: 180, loss: 0.12513945996761322
step: 190, loss: 0.1319809854030609
step: 200, loss: 0.10304099321365356
step: 210, loss: 0.09952814877033234
step: 220, loss: 0.0740819126367569
step: 230, loss: 0.014728793874382973
step: 240, loss: 0.087370865046978
step: 250, loss: 0.059450723230838776
step: 260, loss: 0.07356877624988556
step: 270, loss: 0.043197378516197205
step: 280, loss: 0.07247276604175568
step: 290, loss: 0.15094925463199615
step: 300, loss: 0.0814930722117424
step: 310, loss: 0.07518992573022842
step: 320, loss: 0.14240187406539917
step: 330, loss: 0.17579936981201172
epoch 11: dev_f1=0.817351598173516, f1=0.7911111111111112, best_f1=0.7935034802784221
step: 0, loss: 0.09578318893909454
step: 10, loss: 0.0846702829003334
step: 20, loss: 0.037104588001966476
step: 30, loss: 0.02787048928439617
step: 40, loss: 0.04419275000691414
step: 50, loss: 0.05278625339269638
step: 60, loss: 0.024485142901539803
step: 70, loss: 0.08674805611371994
step: 80, loss: 0.022294925525784492
step: 90, loss: 0.01480095088481903
step: 100, loss: 0.08115997165441513
step: 110, loss: 0.07249069958925247
step: 120, loss: 0.13838927447795868
step: 130, loss: 0.048027120530605316
step: 140, loss: 0.12312393635511398
step: 150, loss: 0.022265935316681862
step: 160, loss: 0.1785958856344223
step: 170, loss: 0.1300879269838333
step: 180, loss: 0.10665324330329895
step: 190, loss: 0.05776352062821388
step: 200, loss: 0.13109761476516724
step: 210, loss: 0.17649038136005402
step: 220, loss: 0.05171353742480278
step: 230, loss: 0.08501704037189484
step: 240, loss: 0.07870807498693466
step: 250, loss: 0.16346843540668488
step: 260, loss: 0.10481996834278107
step: 270, loss: 0.14798912405967712
step: 280, loss: 0.12065128982067108
step: 290, loss: 0.039626043289899826
step: 300, loss: 0.09213892370462418
step: 310, loss: 0.03690827637910843
step: 320, loss: 0.08704814314842224
step: 330, loss: 0.09921926259994507
epoch 12: dev_f1=0.8192771084337348, f1=0.7811764705882352, best_f1=0.7935034802784221
step: 0, loss: 0.06443822383880615
step: 10, loss: 0.12769150733947754
step: 20, loss: 0.011197153478860855
step: 30, loss: 0.0616978295147419
step: 40, loss: 0.027557944878935814
step: 50, loss: 0.025091897696256638
step: 60, loss: 0.1217479333281517
step: 70, loss: 0.07212933897972107
step: 80, loss: 0.09644649922847748
step: 90, loss: 0.1507362425327301
step: 100, loss: 0.08111607283353806
step: 110, loss: 0.028413068503141403
step: 120, loss: 0.07116536051034927
step: 130, loss: 0.05444776639342308
step: 140, loss: 0.07265490293502808
step: 150, loss: 0.048632603138685226
step: 160, loss: 0.0906916931271553
step: 170, loss: 0.002006075344979763
step: 180, loss: 0.1737024188041687
step: 190, loss: 0.11301932483911514
step: 200, loss: 0.04623175784945488
step: 210, loss: 0.016939567402005196
step: 220, loss: 0.05300508439540863
step: 230, loss: 0.14209476113319397
step: 240, loss: 0.05178079381585121
step: 250, loss: 0.05801999568939209
step: 260, loss: 0.07043183594942093
step: 270, loss: 0.06259091198444366
step: 280, loss: 0.01855931244790554
step: 290, loss: 0.11535997688770294
step: 300, loss: 0.045269083231687546
step: 310, loss: 0.0941365510225296
step: 320, loss: 0.07056671380996704
step: 330, loss: 0.06307975202798843
epoch 13: dev_f1=0.8181818181818181, f1=0.788177339901478, best_f1=0.7935034802784221
step: 0, loss: 0.052963752299547195
step: 10, loss: 0.1123339831829071
step: 20, loss: 0.14327044785022736
step: 30, loss: 0.07615645229816437
step: 40, loss: 0.15480473637580872
step: 50, loss: 0.14298459887504578
step: 60, loss: 0.29521438479423523
step: 70, loss: 0.03619306534528732
step: 80, loss: 0.03406314551830292
step: 90, loss: 0.042880911380052567
step: 100, loss: 0.1061902567744255
step: 110, loss: 0.06328850239515305
step: 120, loss: 0.032860878854990005
step: 130, loss: 0.10362515598535538
step: 140, loss: 0.07399904727935791
step: 150, loss: 0.09295635670423508
step: 160, loss: 0.05361436679959297
step: 170, loss: 0.2220521718263626
step: 180, loss: 0.00486149312928319
step: 190, loss: 0.1921733021736145
step: 200, loss: 0.056367482990026474
step: 210, loss: 0.09392454475164413
step: 220, loss: 0.1459304541349411
step: 230, loss: 0.10199233889579773
step: 240, loss: 0.07500600069761276
step: 250, loss: 0.013427573256194592
step: 260, loss: 0.06955184787511826
step: 270, loss: 0.03844432532787323
step: 280, loss: 0.11858899891376495
step: 290, loss: 0.142039954662323
step: 300, loss: 0.0830877348780632
step: 310, loss: 0.05992220342159271
step: 320, loss: 0.1084078848361969
step: 330, loss: 0.05921535566449165
epoch 14: dev_f1=0.8229426433915212, f1=0.7892156862745098, best_f1=0.7935034802784221
step: 0, loss: 0.05704692006111145
step: 10, loss: 0.06275912374258041
step: 20, loss: 0.073330819606781
step: 30, loss: 0.07192420959472656
step: 40, loss: 0.03799763694405556
step: 50, loss: 0.12654909491539001
step: 60, loss: 0.03790293633937836
step: 70, loss: 0.014005960896611214
step: 80, loss: 0.08330778032541275
step: 90, loss: 0.10934916138648987
step: 100, loss: 0.046029768884181976
step: 110, loss: 0.047158997505903244
step: 120, loss: 0.03147484362125397
step: 130, loss: 0.09227157384157181
step: 140, loss: 0.07381779700517654
step: 150, loss: 0.07126603275537491
step: 160, loss: 0.12099503725767136
step: 170, loss: 0.06349340826272964
step: 180, loss: 0.06674445420503616
step: 190, loss: 0.04591337963938713
step: 200, loss: 0.1144842803478241
step: 210, loss: 0.07558685541152954
step: 220, loss: 0.01371022593230009
step: 230, loss: 0.0731891319155693
step: 240, loss: 0.066080242395401
step: 250, loss: 0.05367760732769966
step: 260, loss: 0.18437913060188293
step: 270, loss: 0.08148547261953354
step: 280, loss: 0.07160510867834091
step: 290, loss: 0.07077595591545105
step: 300, loss: 0.11612232029438019
step: 310, loss: 0.11153579503297806
step: 320, loss: 0.09782575815916061
step: 330, loss: 0.0858941301703453
epoch 15: dev_f1=0.8267326732673267, f1=0.7961165048543688, best_f1=0.7935034802784221
step: 0, loss: 0.07665223628282547
step: 10, loss: 0.07926001399755478
step: 20, loss: 0.019841421395540237
step: 30, loss: 0.03530930355191231
step: 40, loss: 0.06510722637176514
step: 50, loss: 0.04658344015479088
step: 60, loss: 0.13120277225971222
step: 70, loss: 0.06132457032799721
step: 80, loss: 0.042253848165273666
step: 90, loss: 0.08052544295787811
step: 100, loss: 0.05025702714920044
step: 110, loss: 0.06661263108253479
step: 120, loss: 0.049388349056243896
step: 130, loss: 0.039004478603601456
step: 140, loss: 0.028085358440876007
step: 150, loss: 0.06687434762716293
step: 160, loss: 0.12066357582807541
step: 170, loss: 0.08731898665428162
step: 180, loss: 0.09620557725429535
step: 190, loss: 0.04566120356321335
step: 200, loss: 0.1660504937171936
step: 210, loss: 0.0360713005065918
step: 220, loss: 0.08042562752962112
step: 230, loss: 0.06864824146032333
step: 240, loss: 0.06606711447238922
step: 250, loss: 0.15227648615837097
step: 260, loss: 0.04002729803323746
step: 270, loss: 0.06664236634969711
step: 280, loss: 0.055354539304971695
step: 290, loss: 0.12515859305858612
step: 300, loss: 0.04265759885311127
step: 310, loss: 0.02450530230998993
step: 320, loss: 0.07275746762752533
step: 330, loss: 0.06206640228629112
epoch 16: dev_f1=0.8076009501187648, f1=0.8045977011494253, best_f1=0.7935034802784221
step: 0, loss: 0.025853021070361137
step: 10, loss: 3.203258165740408e-05
step: 20, loss: 0.05057099089026451
step: 30, loss: 0.03515125811100006
step: 40, loss: 0.100664421916008
step: 50, loss: 0.07755690068006516
step: 60, loss: 0.09118872135877609
step: 70, loss: 0.09245486557483673
step: 80, loss: 0.11842026561498642
step: 90, loss: 0.028001904487609863
step: 100, loss: 0.029602671042084694
step: 110, loss: 0.06886520981788635
step: 120, loss: 0.10242845118045807
step: 130, loss: 0.07891881465911865
step: 140, loss: 0.07194554060697556
step: 150, loss: 0.18889698386192322
step: 160, loss: 0.08622430264949799
step: 170, loss: 0.013247953727841377
step: 180, loss: 0.022666556760668755
step: 190, loss: 0.10451625287532806
step: 200, loss: 0.05019938200712204
step: 210, loss: 0.023306984454393387
step: 220, loss: 0.058031778782606125
step: 230, loss: 0.03679380938410759
step: 240, loss: 0.08400722593069077
step: 250, loss: 0.1346873939037323
step: 260, loss: 0.009921756573021412
step: 270, loss: 0.12361402064561844
step: 280, loss: 0.10641016811132431
step: 290, loss: 0.08499626815319061
step: 300, loss: 0.1526258885860443
step: 310, loss: 0.0004339985316619277
step: 320, loss: 0.039067257195711136
step: 330, loss: 0.06732993572950363
epoch 17: dev_f1=0.820253164556962, f1=0.8020050125313284, best_f1=0.7935034802784221
step: 0, loss: 0.020682580769062042
step: 10, loss: 0.08043178170919418
step: 20, loss: 0.05260128155350685
step: 30, loss: 0.08189627528190613
step: 40, loss: 0.1030215322971344
step: 50, loss: 0.10508351027965546
step: 60, loss: 0.056569743901491165
step: 70, loss: 0.05693841353058815
step: 80, loss: 0.08406186103820801
step: 90, loss: 0.12338247895240784
step: 100, loss: 0.011448705568909645
step: 110, loss: 0.034510910511016846
step: 120, loss: 0.02550104632973671
step: 130, loss: 0.1592891812324524
step: 140, loss: 0.07635769993066788
step: 150, loss: 0.13990770280361176
step: 160, loss: 0.10169846564531326
step: 170, loss: 0.050995122641325
step: 180, loss: 0.020504632964730263
step: 190, loss: 0.041910067200660706
step: 200, loss: 0.06373532861471176
step: 210, loss: 0.13742654025554657
step: 220, loss: 0.091907799243927
step: 230, loss: 0.05531169846653938
step: 240, loss: 0.1015482172369957
step: 250, loss: 0.021804803982377052
step: 260, loss: 0.05995895341038704
step: 270, loss: 0.06360703706741333
step: 280, loss: 0.036699336022138596
step: 290, loss: 0.021720781922340393
step: 300, loss: 0.05386391654610634
step: 310, loss: 0.09592373669147491
step: 320, loss: 0.04689500853419304
step: 330, loss: 0.07431811839342117
epoch 18: dev_f1=0.8057553956834533, f1=0.7934272300469484, best_f1=0.7935034802784221
step: 0, loss: 0.04161125048995018
step: 10, loss: 0.17872676253318787
step: 20, loss: 0.11182060837745667
step: 30, loss: 0.11865568161010742
step: 40, loss: 0.030536580830812454
step: 50, loss: 0.02573336474597454
step: 60, loss: 0.13678616285324097
step: 70, loss: 0.07821105420589447
step: 80, loss: 0.09110257029533386
step: 90, loss: 0.05191042274236679
step: 100, loss: 0.05106061324477196
step: 110, loss: 0.022073756903409958
step: 120, loss: 0.010438797995448112
step: 130, loss: 0.12333260476589203
step: 140, loss: 0.059414517134428024
step: 150, loss: 0.09233018010854721
step: 160, loss: 0.04226912558078766
step: 170, loss: 0.07716060429811478
step: 180, loss: 0.08524572849273682
step: 190, loss: 0.04267025738954544
step: 200, loss: 0.137773334980011
step: 210, loss: 0.04468298703432083
step: 220, loss: 0.04797166585922241
step: 230, loss: 0.013918805867433548
step: 240, loss: 0.07359335571527481
step: 250, loss: 0.09313114732503891
step: 260, loss: 0.0774797797203064
step: 270, loss: 0.16736048460006714
step: 280, loss: 0.10316190123558044
step: 290, loss: 0.01722046546638012
step: 300, loss: 0.10752534121274948
step: 310, loss: 0.04088346287608147
step: 320, loss: 0.1549561768770218
step: 330, loss: 0.023040562868118286
epoch 19: dev_f1=0.7990430622009569, f1=0.7915690866510539, best_f1=0.7935034802784221
step: 0, loss: 0.02871055342257023
step: 10, loss: 0.14125503599643707
step: 20, loss: 0.0566033199429512
step: 30, loss: 0.05482638627290726
step: 40, loss: 0.11866843700408936
step: 50, loss: 0.06106901913881302
step: 60, loss: 0.04864569753408432
step: 70, loss: 0.10888192057609558
step: 80, loss: 0.057637955993413925
step: 90, loss: 0.05109686031937599
step: 100, loss: 0.04938603192567825
step: 110, loss: 0.07455474138259888
step: 120, loss: 0.0438365638256073
step: 130, loss: 0.20812666416168213
step: 140, loss: 0.05891311168670654
step: 150, loss: 0.03138914331793785
step: 160, loss: 0.04870478808879852
step: 170, loss: 0.034952759742736816
step: 180, loss: 0.028936097398400307
step: 190, loss: 0.12978768348693848
step: 200, loss: 0.018913932144641876
step: 210, loss: 0.05514799803495407
step: 220, loss: 0.0171737689524889
step: 230, loss: 0.006951505318284035
step: 240, loss: 0.025267764925956726
step: 250, loss: 0.028165390715003014
step: 260, loss: 0.03807668760418892
step: 270, loss: 0.021092349663376808
step: 280, loss: 0.06447532027959824
step: 290, loss: 0.07392708957195282
step: 300, loss: 0.05253768712282181
step: 310, loss: 0.04078821465373039
step: 320, loss: 0.07523728907108307
step: 330, loss: 0.05516680330038071
epoch 20: dev_f1=0.7971014492753623, f1=0.7943262411347518, best_f1=0.7935034802784221
