cuda
Device: cuda
step: 0, loss: 0.7134525179862976
step: 10, loss: 0.14591175317764282
step: 20, loss: 0.14823006093502045
step: 30, loss: 0.19492702186107635
step: 40, loss: 0.04250609502196312
step: 50, loss: 0.047020722180604935
step: 60, loss: 0.1574835479259491
step: 70, loss: 0.13925568759441376
step: 80, loss: 0.1788986325263977
step: 90, loss: 0.4717126488685608
step: 100, loss: 0.31337156891822815
step: 110, loss: 0.3950340449810028
step: 120, loss: 0.11934586614370346
step: 130, loss: 0.23128454387187958
step: 140, loss: 0.4719352424144745
step: 150, loss: 0.14646406471729279
step: 160, loss: 0.22458671033382416
step: 170, loss: 0.07855169475078583
step: 180, loss: 0.10107174515724182
step: 190, loss: 0.3975692391395569
step: 200, loss: 0.22586184740066528
step: 210, loss: 0.05878061801195145
step: 220, loss: 0.22209249436855316
step: 230, loss: 0.1241765096783638
step: 240, loss: 0.2594939172267914
step: 250, loss: 0.13545991480350494
step: 260, loss: 0.14655204117298126
step: 270, loss: 0.12350237369537354
step: 280, loss: 0.2196502983570099
step: 290, loss: 0.05668225511908531
step: 300, loss: 0.017619159072637558
step: 310, loss: 0.10248526930809021
step: 320, loss: 0.06135221943259239
step: 330, loss: 0.0890551507472992
epoch 1: dev_f1=0.656, f1=0.6758349705304519, best_f1=0.6758349705304519
step: 0, loss: 0.06269644945859909
step: 10, loss: 0.3922555148601532
step: 20, loss: 0.17385129630565643
step: 30, loss: 0.04844032973051071
step: 40, loss: 0.09079692512750626
step: 50, loss: 0.03264355659484863
step: 60, loss: 0.25391456484794617
step: 70, loss: 0.11235523223876953
step: 80, loss: 0.20256994664669037
step: 90, loss: 0.12115228176116943
step: 100, loss: 0.01604214683175087
step: 110, loss: 0.1483694165945053
step: 120, loss: 0.17841646075248718
step: 130, loss: 0.1223149299621582
step: 140, loss: 0.05716364458203316
step: 150, loss: 0.0801641196012497
step: 160, loss: 0.24589015543460846
step: 170, loss: 0.19148921966552734
step: 180, loss: 0.11212705075740814
step: 190, loss: 0.2410098761320114
step: 200, loss: 0.0892510637640953
step: 210, loss: 0.1277172565460205
step: 220, loss: 0.13479140400886536
step: 230, loss: 0.1419270783662796
step: 240, loss: 0.12702131271362305
step: 250, loss: 0.10663728415966034
step: 260, loss: 0.04170218110084534
step: 270, loss: 0.026845000684261322
step: 280, loss: 0.12657545506954193
step: 290, loss: 0.07553277909755707
step: 300, loss: 0.0822427049279213
step: 310, loss: 0.09576362371444702
step: 320, loss: 0.066163569688797
step: 330, loss: 0.14200839400291443
epoch 2: dev_f1=0.7953488372093023, f1=0.7744874715261958, best_f1=0.7744874715261958
step: 0, loss: 0.11685426533222198
step: 10, loss: 0.11144129186868668
step: 20, loss: 0.1440257430076599
step: 30, loss: 0.10989749431610107
step: 40, loss: 0.10339130461215973
step: 50, loss: 0.133417010307312
step: 60, loss: 0.18545357882976532
step: 70, loss: 0.204918771982193
step: 80, loss: 0.12800058722496033
step: 90, loss: 0.049062538892030716
step: 100, loss: 0.08394382148981094
step: 110, loss: 0.2630709409713745
step: 120, loss: 0.07531838864088058
step: 130, loss: 0.14990797638893127
step: 140, loss: 0.09937160462141037
step: 150, loss: 0.15618355572223663
step: 160, loss: 0.11950413882732391
step: 170, loss: 0.6573086380958557
step: 180, loss: 0.20601415634155273
step: 190, loss: 0.13512693345546722
step: 200, loss: 0.14831507205963135
step: 210, loss: 0.06696000695228577
step: 220, loss: 0.13214537501335144
step: 230, loss: 0.15210694074630737
step: 240, loss: 0.03158131614327431
step: 250, loss: 0.1302882730960846
step: 260, loss: 0.1148999035358429
step: 270, loss: 0.1409861296415329
step: 280, loss: 0.13210594654083252
step: 290, loss: 0.09170227497816086
step: 300, loss: 0.1316966414451599
step: 310, loss: 0.04940519109368324
step: 320, loss: 0.10631338506937027
step: 330, loss: 0.05340120941400528
epoch 3: dev_f1=0.7645569620253165, f1=0.7560975609756099, best_f1=0.7744874715261958
step: 0, loss: 0.006030449643731117
step: 10, loss: 0.0924740806221962
step: 20, loss: 0.06607513874769211
step: 30, loss: 0.04159265011548996
step: 40, loss: 0.04545542970299721
step: 50, loss: 0.07376141101121902
step: 60, loss: 0.027640003710985184
step: 70, loss: 0.15171004831790924
step: 80, loss: 0.0003741429536603391
step: 90, loss: 0.09450142085552216
step: 100, loss: 0.09000560641288757
step: 110, loss: 0.13065429031848907
step: 120, loss: 0.09892294555902481
step: 130, loss: 0.037462782114744186
step: 140, loss: 0.046900298446416855
step: 150, loss: 0.09472884982824326
step: 160, loss: 0.07555163651704788
step: 170, loss: 0.1263522505760193
step: 180, loss: 0.13737989962100983
step: 190, loss: 0.06202496960759163
step: 200, loss: 0.3602953553199768
step: 210, loss: 0.08446210622787476
step: 220, loss: 0.11453104764223099
step: 230, loss: 0.03843946009874344
step: 240, loss: 0.051373086869716644
step: 250, loss: 0.09467130154371262
step: 260, loss: 0.12908490002155304
step: 270, loss: 0.13652195036411285
step: 280, loss: 0.18679343163967133
step: 290, loss: 0.10232783108949661
step: 300, loss: 0.18536047637462616
step: 310, loss: 0.16589206457138062
step: 320, loss: 0.11087581515312195
step: 330, loss: 0.0649322047829628
epoch 4: dev_f1=0.7927927927927928, f1=0.7789934354485777, best_f1=0.7744874715261958
step: 0, loss: 0.07365039736032486
step: 10, loss: 0.022276511415839195
step: 20, loss: 0.06206871196627617
step: 30, loss: 0.020278148353099823
step: 40, loss: 0.19064468145370483
step: 50, loss: 0.07091204077005386
step: 60, loss: 0.13739170134067535
step: 70, loss: 0.04375188425183296
step: 80, loss: 0.1700427383184433
step: 90, loss: 0.06267062574625015
step: 100, loss: 0.06782273203134537
step: 110, loss: 0.1733155995607376
step: 120, loss: 0.131468266248703
step: 130, loss: 0.019770678132772446
step: 140, loss: 0.03633113205432892
step: 150, loss: 0.04589485749602318
step: 160, loss: 0.0021764799021184444
step: 170, loss: 0.0995391383767128
step: 180, loss: 0.0714108794927597
step: 190, loss: 0.09309758991003036
step: 200, loss: 0.04706261679530144
step: 210, loss: 0.07001057267189026
step: 220, loss: 0.25724610686302185
step: 230, loss: 0.10136337578296661
step: 240, loss: 0.04740462824702263
step: 250, loss: 0.07030557841062546
step: 260, loss: 0.10461405664682388
step: 270, loss: 0.13143426179885864
step: 280, loss: 0.22315484285354614
step: 290, loss: 0.0925668329000473
step: 300, loss: 0.08145974576473236
step: 310, loss: 0.1004507839679718
step: 320, loss: 0.12279536575078964
step: 330, loss: 0.11801809817552567
epoch 5: dev_f1=0.7706855791962176, f1=0.7757009345794393, best_f1=0.7744874715261958
step: 0, loss: 0.08085903525352478
step: 10, loss: 0.1516849547624588
step: 20, loss: 0.05969441682100296
step: 30, loss: 0.18164974451065063
step: 40, loss: 0.07813064754009247
step: 50, loss: 0.1581098437309265
step: 60, loss: 0.07754699140787125
step: 70, loss: 0.030965397134423256
step: 80, loss: 0.1461668461561203
step: 90, loss: 0.15091340243816376
step: 100, loss: 0.2285781055688858
step: 110, loss: 0.17824703454971313
step: 120, loss: 0.03907940909266472
step: 130, loss: 0.08736258000135422
step: 140, loss: 0.1910054087638855
step: 150, loss: 0.1314116269350052
step: 160, loss: 0.282103031873703
step: 170, loss: 0.019799889996647835
step: 180, loss: 0.12868517637252808
step: 190, loss: 0.03771961107850075
step: 200, loss: 0.10171240568161011
step: 210, loss: 0.14378716051578522
step: 220, loss: 0.14278173446655273
step: 230, loss: 0.025034600868821144
step: 240, loss: 0.16738425195217133
step: 250, loss: 0.07325109839439392
step: 260, loss: 0.08854517340660095
step: 270, loss: 0.16185362637043
step: 280, loss: 0.036615774035453796
step: 290, loss: 0.13178211450576782
step: 300, loss: 0.08219927549362183
step: 310, loss: 0.06163623929023743
step: 320, loss: 0.11091319471597672
step: 330, loss: 0.12581753730773926
epoch 6: dev_f1=0.7902869757174392, f1=0.7708779443254817, best_f1=0.7744874715261958
step: 0, loss: 0.05370370298624039
step: 10, loss: 0.09961017221212387
step: 20, loss: 0.04463324695825577
step: 30, loss: 0.128978431224823
step: 40, loss: 0.03481578454375267
step: 50, loss: 0.11666439473628998
step: 60, loss: 0.09265881776809692
step: 70, loss: 0.09605477005243301
step: 80, loss: 0.05533819645643234
step: 90, loss: 0.08624421060085297
step: 100, loss: 0.06596266478300095
step: 110, loss: 0.109788678586483
step: 120, loss: 0.20542050898075104
step: 130, loss: 0.04712197929620743
step: 140, loss: 0.16054333746433258
step: 150, loss: 0.046621959656476974
step: 160, loss: 0.1446794718503952
step: 170, loss: 0.08204896748065948
step: 180, loss: 0.08204658329486847
step: 190, loss: 0.09583696722984314
step: 200, loss: 0.0774095207452774
step: 210, loss: 0.0799940750002861
step: 220, loss: 0.10111062228679657
step: 230, loss: 0.05702359974384308
step: 240, loss: 0.07548422366380692
step: 250, loss: 0.027738386765122414
step: 260, loss: 0.01548275351524353
step: 270, loss: 0.03902241587638855
step: 280, loss: 0.07614260166883469
step: 290, loss: 0.04935788735747337
step: 300, loss: 0.09455419331789017
step: 310, loss: 0.11245837062597275
step: 320, loss: 0.07116242498159409
step: 330, loss: 0.14136067032814026
epoch 7: dev_f1=0.8047619047619048, f1=0.786206896551724, best_f1=0.786206896551724
step: 0, loss: 0.0449099987745285
step: 10, loss: 0.10548004508018494
step: 20, loss: 0.06524484604597092
step: 30, loss: 0.17603303492069244
step: 40, loss: 0.011293865740299225
step: 50, loss: 0.051420651376247406
step: 60, loss: 0.0694521963596344
step: 70, loss: 0.11326547712087631
step: 80, loss: 0.10188286006450653
step: 90, loss: 0.16940747201442719
step: 100, loss: 0.0783553496003151
step: 110, loss: 0.024125343188643456
step: 120, loss: 0.07605066150426865
step: 130, loss: 0.06408777087926865
step: 140, loss: 0.17408323287963867
step: 150, loss: 0.14989738166332245
step: 160, loss: 0.03237480670213699
step: 170, loss: 0.0323321558535099
step: 180, loss: 0.06983643770217896
step: 190, loss: 0.0642726719379425
step: 200, loss: 0.06287584453821182
step: 210, loss: 0.08462651818990707
step: 220, loss: 0.1172364205121994
step: 230, loss: 0.30387210845947266
step: 240, loss: 0.0229704137891531
step: 250, loss: 0.06944400072097778
step: 260, loss: 0.11893834173679352
step: 270, loss: 0.02665797807276249
step: 280, loss: 0.08739268779754639
step: 290, loss: 0.04274458438158035
step: 300, loss: 0.1301940381526947
step: 310, loss: 0.08992718160152435
step: 320, loss: 0.07060717791318893
step: 330, loss: 0.09863872081041336
epoch 8: dev_f1=0.8098765432098766, f1=0.7807228915662651, best_f1=0.7807228915662651
step: 0, loss: 0.10368866473436356
step: 10, loss: 0.04646081477403641
step: 20, loss: 0.03769046068191528
step: 30, loss: 0.08846034109592438
step: 40, loss: 0.10282634943723679
step: 50, loss: 0.0634302869439125
step: 60, loss: 0.026216136291623116
step: 70, loss: 0.049526117742061615
step: 80, loss: 0.13093943893909454
step: 90, loss: 0.17952431738376617
step: 100, loss: 0.06046527251601219
step: 110, loss: 0.010687800124287605
step: 120, loss: 0.15095670521259308
step: 130, loss: 0.07700260728597641
step: 140, loss: 0.12364163994789124
step: 150, loss: 0.08549921959638596
step: 160, loss: 0.09210368990898132
step: 170, loss: 0.05518098920583725
step: 180, loss: 0.1457640379667282
step: 190, loss: 0.06184547767043114
step: 200, loss: 0.10141035914421082
step: 210, loss: 0.08680597692728043
step: 220, loss: 0.07812263816595078
step: 230, loss: 0.04998490959405899
step: 240, loss: 0.17060481011867523
step: 250, loss: 0.08545110374689102
step: 260, loss: 0.05078927055001259
step: 270, loss: 0.16580727696418762
step: 280, loss: 0.11313894391059875
step: 290, loss: 0.19736221432685852
step: 300, loss: 0.08962599188089371
step: 310, loss: 0.07938729971647263
step: 320, loss: 0.00175322568975389
step: 330, loss: 0.10659753531217575
epoch 9: dev_f1=0.8168316831683169, f1=0.7961630695443646, best_f1=0.7961630695443646
step: 0, loss: 0.04013790562748909
step: 10, loss: 0.08584500104188919
step: 20, loss: 0.2667035162448883
step: 30, loss: 0.09958189725875854
step: 40, loss: 0.11091296374797821
step: 50, loss: 0.04473786801099777
step: 60, loss: 0.07680705934762955
step: 70, loss: 0.04451970383524895
step: 80, loss: 0.11371362209320068
step: 90, loss: 0.08326472342014313
step: 100, loss: 0.06253190338611603
step: 110, loss: 0.04380794242024422
step: 120, loss: 0.05893246456980705
step: 130, loss: 0.09568548947572708
step: 140, loss: 0.1221095621585846
step: 150, loss: 0.1264629065990448
step: 160, loss: 0.0866355299949646
step: 170, loss: 0.03124045766890049
step: 180, loss: 0.17430301010608673
step: 190, loss: 0.10464726388454437
step: 200, loss: 0.04849987104535103
step: 210, loss: 0.15727433562278748
step: 220, loss: 0.16215704381465912
step: 230, loss: 0.07625871151685715
step: 240, loss: 0.09952148795127869
step: 250, loss: 0.06494428962469101
step: 260, loss: 0.09326127171516418
step: 270, loss: 0.15991026163101196
step: 280, loss: 0.011599350720643997
step: 290, loss: 0.12608835101127625
step: 300, loss: 0.1238512173295021
step: 310, loss: 0.049619853496551514
step: 320, loss: 0.10426467657089233
step: 330, loss: 0.10059236735105515
epoch 10: dev_f1=0.808888888888889, f1=0.7809110629067245, best_f1=0.7961630695443646
step: 0, loss: 0.08691003173589706
step: 10, loss: 0.14175687730312347
step: 20, loss: 0.11120779812335968
step: 30, loss: 0.03189510852098465
step: 40, loss: 0.09426316618919373
step: 50, loss: 0.07865914702415466
step: 60, loss: 0.12428958714008331
step: 70, loss: 0.12690290808677673
step: 80, loss: 0.1396779716014862
step: 90, loss: 0.14940710365772247
step: 100, loss: 0.0743408352136612
step: 110, loss: 0.021877510473132133
step: 120, loss: 0.02186967432498932
step: 130, loss: 0.07541029900312424
step: 140, loss: 0.04998471215367317
step: 150, loss: 0.05041312426328659
step: 160, loss: 0.07504209876060486
step: 170, loss: 0.1882782280445099
step: 180, loss: 0.053526900708675385
step: 190, loss: 0.05792106315493584
step: 200, loss: 0.06033242121338844
step: 210, loss: 0.0760587826371193
step: 220, loss: 0.07133777439594269
step: 230, loss: 0.06516960263252258
step: 240, loss: 0.042498648166656494
step: 250, loss: 0.09593535214662552
step: 260, loss: 0.0852152407169342
step: 270, loss: 0.005380082875490189
step: 280, loss: 0.10581082850694656
step: 290, loss: 0.07457111030817032
step: 300, loss: 0.10501543432474136
step: 310, loss: 0.1220928430557251
step: 320, loss: 0.0658215880393982
step: 330, loss: 0.10724270343780518
epoch 11: dev_f1=0.7990430622009569, f1=0.7848699763593381, best_f1=0.7961630695443646
step: 0, loss: 0.08995770663022995
step: 10, loss: 0.07861711829900742
step: 20, loss: 0.07658576965332031
step: 30, loss: 0.1401854306459427
step: 40, loss: 0.09498976916074753
step: 50, loss: 0.03052362985908985
step: 60, loss: 0.044942982494831085
step: 70, loss: 0.10456354916095734
step: 80, loss: 0.18697792291641235
step: 90, loss: 0.12852643430233002
step: 100, loss: 0.10729573667049408
step: 110, loss: 0.08303631842136383
step: 120, loss: 0.05223647877573967
step: 130, loss: 0.09697486460208893
step: 140, loss: 0.07885575294494629
step: 150, loss: 0.08505557477474213
step: 160, loss: 0.12887558341026306
step: 170, loss: 0.08364880084991455
step: 180, loss: 0.058289531618356705
step: 190, loss: 0.02844778262078762
step: 200, loss: 0.0895499587059021
step: 210, loss: 0.111442431807518
step: 220, loss: 0.11390084028244019
step: 230, loss: 0.03382342308759689
step: 240, loss: 0.1227521076798439
step: 250, loss: 0.11809534579515457
step: 260, loss: 0.08444586396217346
step: 270, loss: 0.05934999883174896
step: 280, loss: 0.07006500661373138
step: 290, loss: 3.892034146701917e-05
step: 300, loss: 0.10550326108932495
step: 310, loss: 0.07031994313001633
step: 320, loss: 0.06993038207292557
step: 330, loss: 0.047281477600336075
epoch 12: dev_f1=0.8066825775656326, f1=0.7935034802784221, best_f1=0.7961630695443646
step: 0, loss: 0.15216226875782013
step: 10, loss: 0.10495579242706299
step: 20, loss: 0.05359536036849022
step: 30, loss: 0.029393546283245087
step: 40, loss: 0.07951673120260239
step: 50, loss: 0.022655675187706947
step: 60, loss: 0.03654379025101662
step: 70, loss: 0.078126460313797
step: 80, loss: 0.08751300722360611
step: 90, loss: 0.16989046335220337
step: 100, loss: 0.11774373799562454
step: 110, loss: 0.05066667124629021
step: 120, loss: 0.08153917640447617
step: 130, loss: 0.0469350628554821
step: 140, loss: 0.08744440972805023
step: 150, loss: 0.0587444007396698
step: 160, loss: 0.029213018715381622
step: 170, loss: 0.14548492431640625
step: 180, loss: 0.020556101575493813
step: 190, loss: 0.08953406661748886
step: 200, loss: 0.06152542680501938
step: 210, loss: 0.07051640003919601
step: 220, loss: 0.03473470360040665
step: 230, loss: 0.09707804769277573
step: 240, loss: 0.10625375807285309
step: 250, loss: 0.08771012723445892
step: 260, loss: 0.08562082052230835
step: 270, loss: 0.1562957912683487
step: 280, loss: 0.051208898425102234
step: 290, loss: 0.10930951684713364
step: 300, loss: 0.1174207553267479
step: 310, loss: 0.09251753985881805
step: 320, loss: 0.07165830582380295
step: 330, loss: 0.10294321179389954
epoch 13: dev_f1=0.817155756207675, f1=0.7928730512249442, best_f1=0.7928730512249442
step: 0, loss: 0.07471342384815216
step: 10, loss: 0.02784057706594467
step: 20, loss: 3.103412745986134e-05
step: 30, loss: 0.0412726104259491
step: 40, loss: 0.07042501866817474
step: 50, loss: 0.036380618810653687
step: 60, loss: 0.033338043838739395
step: 70, loss: 0.07662126421928406
step: 80, loss: 0.0351996012032032
step: 90, loss: 0.04142467677593231
step: 100, loss: 0.018428409472107887
step: 110, loss: 0.06786521524190903
step: 120, loss: 0.048047952353954315
step: 130, loss: 0.07293675094842911
step: 140, loss: 0.04802926257252693
step: 150, loss: 0.047642312943935394
step: 160, loss: 0.0625932365655899
step: 170, loss: 0.013758683577179909
step: 180, loss: 0.10886874794960022
step: 190, loss: 0.16038624942302704
step: 200, loss: 0.14069803059101105
step: 210, loss: 0.037318695336580276
step: 220, loss: 0.08957020193338394
step: 230, loss: 0.058277443051338196
step: 240, loss: 0.09104418009519577
step: 250, loss: 0.0880008414387703
step: 260, loss: 0.05476650968194008
step: 270, loss: 0.031686484813690186
step: 280, loss: 0.04185246676206589
step: 290, loss: 0.07997462898492813
step: 300, loss: 0.12859925627708435
step: 310, loss: 0.10163699090480804
step: 320, loss: 0.07689949870109558
step: 330, loss: 0.1192799061536789
epoch 14: dev_f1=0.8088235294117646, f1=0.7846889952153109, best_f1=0.7928730512249442
step: 0, loss: 0.11451669782400131
step: 10, loss: 0.04271524026989937
step: 20, loss: 0.11111107468605042
step: 30, loss: 0.0707261934876442
step: 40, loss: 0.06518062949180603
step: 50, loss: 0.042463283985853195
step: 60, loss: 0.07382599264383316
step: 70, loss: 0.09789791703224182
step: 80, loss: 0.050233788788318634
step: 90, loss: 0.045576971024274826
step: 100, loss: 0.09962093085050583
step: 110, loss: 0.0389157235622406
step: 120, loss: 0.06327615678310394
step: 130, loss: 0.13332602381706238
step: 140, loss: 0.0559852309525013
step: 150, loss: 0.09131419658660889
step: 160, loss: 0.0998145192861557
step: 170, loss: 0.08726903796195984
step: 180, loss: 0.039890438318252563
step: 190, loss: 0.13273867964744568
step: 200, loss: 0.019337769597768784
step: 210, loss: 0.14330430328845978
step: 220, loss: 0.15711137652397156
step: 230, loss: 0.13685163855552673
step: 240, loss: 0.12166251987218857
step: 250, loss: 0.06967957317829132
step: 260, loss: 0.0851021260023117
step: 270, loss: 0.0581793375313282
step: 280, loss: 0.05619002506136894
step: 290, loss: 0.035711705684661865
step: 300, loss: 0.07558002322912216
step: 310, loss: 0.08678914606571198
step: 320, loss: 0.07049258053302765
step: 330, loss: 0.08683270215988159
epoch 15: dev_f1=0.8229665071770335, f1=0.786206896551724, best_f1=0.786206896551724
step: 0, loss: 0.09903660416603088
step: 10, loss: 0.0035346769727766514
step: 20, loss: 0.08132565021514893
step: 30, loss: 0.11703123897314072
step: 40, loss: 0.13217325508594513
step: 50, loss: 0.0978723093867302
step: 60, loss: 0.10130181908607483
step: 70, loss: 0.0863393098115921
step: 80, loss: 0.04729191213846207
step: 90, loss: 0.1502765417098999
step: 100, loss: 0.06941652297973633
step: 110, loss: 0.00805988535284996
step: 120, loss: 0.028560856357216835
step: 130, loss: 0.08879055082798004
step: 140, loss: 0.03143664076924324
step: 150, loss: 0.01648988202214241
step: 160, loss: 0.004607945214956999
step: 170, loss: 0.0944628119468689
step: 180, loss: 0.04723820835351944
step: 190, loss: 0.030246233567595482
step: 200, loss: 0.0828833281993866
step: 210, loss: 0.034986261278390884
step: 220, loss: 0.1285553127527237
step: 230, loss: 0.13497014343738556
step: 240, loss: 0.10522057861089706
step: 250, loss: 0.0738188624382019
step: 260, loss: 0.074741892516613
step: 270, loss: 0.1261211782693863
step: 280, loss: 0.04638020321726799
step: 290, loss: 0.0533566027879715
step: 300, loss: 0.09921010583639145
step: 310, loss: 0.014815403148531914
step: 320, loss: 0.04218035563826561
step: 330, loss: 0.03717022389173508
epoch 16: dev_f1=0.8127853881278538, f1=0.7911111111111112, best_f1=0.786206896551724
step: 0, loss: 0.10149369388818741
step: 10, loss: 0.0442182831466198
step: 20, loss: 0.22662542760372162
step: 30, loss: 0.08654274791479111
step: 40, loss: 0.09469825774431229
step: 50, loss: 0.15077364444732666
step: 60, loss: 0.09103748202323914
step: 70, loss: 0.05911622568964958
step: 80, loss: 0.06353676319122314
step: 90, loss: 0.0778505951166153
step: 100, loss: 0.05105224624276161
step: 110, loss: 0.10718279331922531
step: 120, loss: 0.036600273102521896
step: 130, loss: 0.038915131241083145
step: 140, loss: 0.07828962057828903
step: 150, loss: 0.07822013646364212
step: 160, loss: 0.09188121557235718
step: 170, loss: 0.0334920659661293
step: 180, loss: 0.10270912200212479
step: 190, loss: 0.14993003010749817
step: 200, loss: 0.06527803093194962
step: 210, loss: 0.11391964554786682
step: 220, loss: 0.05921525880694389
step: 230, loss: 0.09173952043056488
step: 240, loss: 0.06721841543912888
step: 250, loss: 0.058827780187129974
step: 260, loss: 0.09384335577487946
step: 270, loss: 0.03233473747968674
step: 280, loss: 0.08507652580738068
step: 290, loss: 0.13247595727443695
step: 300, loss: 0.14571204781532288
step: 310, loss: 0.12124154716730118
step: 320, loss: 0.1253238320350647
step: 330, loss: 0.042271558195352554
epoch 17: dev_f1=0.8148148148148149, f1=0.7811764705882352, best_f1=0.786206896551724
step: 0, loss: 0.0020423559471964836
step: 10, loss: 0.15597331523895264
step: 20, loss: 0.04354438558220863
step: 30, loss: 0.09008273482322693
step: 40, loss: 0.03085935115814209
step: 50, loss: 0.014073224738240242
step: 60, loss: 0.05574362725019455
step: 70, loss: 0.04955793172121048
step: 80, loss: 0.1020459309220314
step: 90, loss: 0.14666058123111725
step: 100, loss: 0.10476955771446228
step: 110, loss: 0.03940551355481148
step: 120, loss: 0.055752430111169815
step: 130, loss: 0.12299402058124542
step: 140, loss: 0.06712701171636581
step: 150, loss: 0.09462948143482208
step: 160, loss: 0.03923337161540985
step: 170, loss: 0.10544823855161667
step: 180, loss: 0.051910191774368286
step: 190, loss: 0.11107928305864334
step: 200, loss: 0.12360163033008575
step: 210, loss: 0.01818801648914814
step: 220, loss: 0.02145056426525116
step: 230, loss: 0.06384473294019699
step: 240, loss: 0.014643743634223938
step: 250, loss: 0.1311238408088684
step: 260, loss: 0.0963783711194992
step: 270, loss: 0.06260788440704346
step: 280, loss: 0.040533922612667084
step: 290, loss: 0.05318726599216461
step: 300, loss: 0.0947103276848793
step: 310, loss: 0.06174663454294205
step: 320, loss: 0.11273492872714996
step: 330, loss: 0.08601949363946915
epoch 18: dev_f1=0.8058968058968059, f1=0.7732696897374701, best_f1=0.786206896551724
step: 0, loss: 0.12731584906578064
step: 10, loss: 0.07397621870040894
step: 20, loss: 0.04672304168343544
step: 30, loss: 0.04830688238143921
step: 40, loss: 0.10549844801425934
step: 50, loss: 0.03826110437512398
step: 60, loss: 0.04417748749256134
step: 70, loss: 0.11141498386859894
step: 80, loss: 0.09432414174079895
step: 90, loss: 0.0368419773876667
step: 100, loss: 0.05568224564194679
step: 110, loss: 0.06926422566175461
step: 120, loss: 0.08521460741758347
step: 130, loss: 0.06933926045894623
step: 140, loss: 0.06167524307966232
step: 150, loss: 0.12865005433559418
step: 160, loss: 0.11741079390048981
step: 170, loss: 0.16305489838123322
step: 180, loss: 0.13968336582183838
step: 190, loss: 0.12020757049322128
step: 200, loss: 0.13441020250320435
step: 210, loss: 0.026159847155213356
step: 220, loss: 0.04884720966219902
step: 230, loss: 0.0605926588177681
step: 240, loss: 0.06634724885225296
step: 250, loss: 0.0701221376657486
step: 260, loss: 0.09090331196784973
step: 270, loss: 0.16905662417411804
step: 280, loss: 0.03384780138731003
step: 290, loss: 1.5240018001350109e-05
step: 300, loss: 0.055532198399305344
step: 310, loss: 0.026174739003181458
step: 320, loss: 0.004096665419638157
step: 330, loss: 0.20573504269123077
epoch 19: dev_f1=0.8106796116504854, f1=0.7842227378190254, best_f1=0.786206896551724
step: 0, loss: 0.04554743692278862
step: 10, loss: 0.01950927823781967
step: 20, loss: 0.05626313388347626
step: 30, loss: 0.12357911467552185
step: 40, loss: 0.04744955524802208
step: 50, loss: 0.03546345606446266
step: 60, loss: 0.07337372750043869
step: 70, loss: 0.00712982565164566
step: 80, loss: 0.04104357957839966
step: 90, loss: 0.05996103584766388
step: 100, loss: 0.1395152509212494
step: 110, loss: 0.03495946526527405
step: 120, loss: 0.07612460106611252
step: 130, loss: 0.0579041913151741
step: 140, loss: 0.09216423332691193
step: 150, loss: 0.07503845542669296
step: 160, loss: 0.05401450768113136
step: 170, loss: 0.05912399664521217
step: 180, loss: 0.03243665397167206
step: 190, loss: 0.054888054728507996
step: 200, loss: 0.048695456236600876
step: 210, loss: 0.02866990491747856
step: 220, loss: 0.08238180726766586
step: 230, loss: 0.03986021503806114
step: 240, loss: 0.11716772615909576
step: 250, loss: 0.03831813856959343
step: 260, loss: 0.10367999225854874
step: 270, loss: 0.00693131797015667
step: 280, loss: 0.06105699762701988
step: 290, loss: 1.5228853953885846e-05
step: 300, loss: 0.0633959025144577
step: 310, loss: 0.08572760224342346
step: 320, loss: 0.18291190266609192
step: 330, loss: 0.057025644928216934
epoch 20: dev_f1=0.8108108108108109, f1=0.776470588235294, best_f1=0.786206896551724
