cuda
Device: cuda
step: 0, loss: 0.7787646055221558
step: 10, loss: 0.14515714347362518
step: 20, loss: 0.235264390707016
step: 30, loss: 0.24108025431632996
step: 40, loss: 0.3080066442489624
step: 50, loss: 0.23748059570789337
step: 60, loss: 0.03156212717294693
step: 70, loss: 0.39746060967445374
step: 80, loss: 0.2202114313840866
step: 90, loss: 0.23100855946540833
step: 100, loss: 0.19359071552753448
step: 110, loss: 0.07364807277917862
step: 120, loss: 0.02806694433093071
step: 130, loss: 0.3163995146751404
step: 140, loss: 0.27194520831108093
step: 150, loss: 0.5323364734649658
step: 160, loss: 0.10167745500802994
step: 170, loss: 0.09285762906074524
step: 180, loss: 0.1529703587293625
step: 190, loss: 0.4095084071159363
step: 200, loss: 0.16494697332382202
step: 210, loss: 0.16994114220142365
step: 220, loss: 0.06845264136791229
step: 230, loss: 0.1648845374584198
step: 240, loss: 0.09043389558792114
step: 250, loss: 0.035499442368745804
step: 260, loss: 0.260261595249176
step: 270, loss: 0.06451814621686935
step: 280, loss: 0.17549815773963928
step: 290, loss: 0.009353557601571083
step: 300, loss: 0.12882472574710846
step: 310, loss: 0.10370843857526779
step: 320, loss: 0.10701999068260193
step: 330, loss: 0.10271308571100235
epoch 1: dev_f1=0.6901098901098901, f1=0.715203426124197, best_f1=0.715203426124197
step: 0, loss: 0.1445755809545517
step: 10, loss: 0.09022490680217743
step: 20, loss: 0.31755879521369934
step: 30, loss: 0.13371987640857697
step: 40, loss: 0.04495522379875183
step: 50, loss: 0.1959284096956253
step: 60, loss: 0.05578836798667908
step: 70, loss: 0.13666044175624847
step: 80, loss: 0.15285588800907135
step: 90, loss: 0.1892499029636383
step: 100, loss: 0.11367448419332504
step: 110, loss: 0.16866376996040344
step: 120, loss: 0.1914503425359726
step: 130, loss: 0.20325550436973572
step: 140, loss: 0.13616842031478882
step: 150, loss: 0.1064348891377449
step: 160, loss: 0.12162697315216064
step: 170, loss: 0.09869332611560822
step: 180, loss: 0.09722509980201721
step: 190, loss: 0.11743298918008804
step: 200, loss: 0.05051431804895401
step: 210, loss: 0.16351085901260376
step: 220, loss: 0.16712504625320435
step: 230, loss: 0.2870236337184906
step: 240, loss: 0.1510523557662964
step: 250, loss: 0.14276541769504547
step: 260, loss: 0.23511053621768951
step: 270, loss: 0.09377241134643555
step: 280, loss: 0.47590404748916626
step: 290, loss: 0.11341169476509094
step: 300, loss: 0.10709840804338455
step: 310, loss: 0.2058844417333603
step: 320, loss: 0.07713738083839417
step: 330, loss: 0.08681972324848175
epoch 2: dev_f1=0.7672413793103448, f1=0.7758620689655172, best_f1=0.7758620689655172
step: 0, loss: 0.1609436422586441
step: 10, loss: 0.10236890614032745
step: 20, loss: 0.050963785499334335
step: 30, loss: 0.041317541152238846
step: 40, loss: 0.19580988585948944
step: 50, loss: 0.07082563638687134
step: 60, loss: 0.14663173258304596
step: 70, loss: 0.45904892683029175
step: 80, loss: 0.14315328001976013
step: 90, loss: 0.2801700234413147
step: 100, loss: 0.10190469771623611
step: 110, loss: 0.1535244882106781
step: 120, loss: 0.019648760557174683
step: 130, loss: 0.06972680985927582
step: 140, loss: 0.06802155077457428
step: 150, loss: 0.0874943733215332
step: 160, loss: 0.09325175732374191
step: 170, loss: 0.06851387023925781
step: 180, loss: 0.05073731765151024
step: 190, loss: 0.2544857859611511
step: 200, loss: 0.11492427438497543
step: 210, loss: 0.11266684532165527
step: 220, loss: 0.22179441154003143
step: 230, loss: 0.07652974128723145
step: 240, loss: 0.05614804849028587
step: 250, loss: 0.04614910110831261
step: 260, loss: 0.129532128572464
step: 270, loss: 0.11824259907007217
step: 280, loss: 0.14078819751739502
step: 290, loss: 0.13436195254325867
step: 300, loss: 0.22674815356731415
step: 310, loss: 0.06212561950087547
step: 320, loss: 0.14023171365261078
step: 330, loss: 0.08706693351268768
epoch 3: dev_f1=0.7611940298507462, f1=0.7729468599033817, best_f1=0.7758620689655172
step: 0, loss: 0.143787682056427
step: 10, loss: 0.06026432290673256
step: 20, loss: 0.15235240757465363
step: 30, loss: 0.16990548372268677
step: 40, loss: 0.1354706734418869
step: 50, loss: 0.14303071796894073
step: 60, loss: 0.0517563596367836
step: 70, loss: 0.13214842975139618
step: 80, loss: 0.12839578092098236
step: 90, loss: 0.04245668649673462
step: 100, loss: 0.04513092339038849
step: 110, loss: 0.07654497027397156
step: 120, loss: 0.1581261157989502
step: 130, loss: 0.284834623336792
step: 140, loss: 0.1171322911977768
step: 150, loss: 0.15252019464969635
step: 160, loss: 0.06989225000143051
step: 170, loss: 0.04007682949304581
step: 180, loss: 0.08926721662282944
step: 190, loss: 0.08212456107139587
step: 200, loss: 0.14137029647827148
step: 210, loss: 0.11062067002058029
step: 220, loss: 0.04842716082930565
step: 230, loss: 0.2018604874610901
step: 240, loss: 0.12077189236879349
step: 250, loss: 0.11313232779502869
step: 260, loss: 0.22447121143341064
step: 270, loss: 0.09461446106433868
step: 280, loss: 0.0725836232304573
step: 290, loss: 0.02036258950829506
step: 300, loss: 0.09705404192209244
step: 310, loss: 0.12804019451141357
step: 320, loss: 0.20230171084403992
step: 330, loss: 0.1158987358212471
epoch 4: dev_f1=0.7924528301886793, f1=0.7926267281105991, best_f1=0.7926267281105991
step: 0, loss: 0.15329666435718536
step: 10, loss: 0.07022663205862045
step: 20, loss: 0.04369382560253143
step: 30, loss: 0.0971059575676918
step: 40, loss: 0.0793134868144989
step: 50, loss: 0.07076211273670197
step: 60, loss: 0.1080893948674202
step: 70, loss: 0.09682130813598633
step: 80, loss: 0.08593340963125229
step: 90, loss: 0.11857952177524567
step: 100, loss: 0.07441703975200653
step: 110, loss: 0.11316416412591934
step: 120, loss: 0.13448266685009003
step: 130, loss: 0.10270485281944275
step: 140, loss: 0.05914677679538727
step: 150, loss: 0.1094651147723198
step: 160, loss: 0.10059157013893127
step: 170, loss: 0.20494431257247925
step: 180, loss: 0.14697939157485962
step: 190, loss: 0.11683918535709381
step: 200, loss: 0.33588042855262756
step: 210, loss: 0.09457758814096451
step: 220, loss: 0.07418542355298996
step: 230, loss: 0.06941147148609161
step: 240, loss: 0.15993478894233704
step: 250, loss: 0.03722085431218147
step: 260, loss: 0.08586655557155609
step: 270, loss: 0.14010865986347198
step: 280, loss: 0.1332821249961853
step: 290, loss: 0.0661388710141182
step: 300, loss: 0.09892261028289795
step: 310, loss: 0.15263620018959045
step: 320, loss: 0.24921880662441254
step: 330, loss: 0.04292325675487518
epoch 5: dev_f1=0.8130841121495326, f1=0.8110599078341014, best_f1=0.8110599078341014
step: 0, loss: 0.15513572096824646
step: 10, loss: 0.07408694922924042
step: 20, loss: 0.13304489850997925
step: 30, loss: 0.040109917521476746
step: 40, loss: 0.07708849757909775
step: 50, loss: 0.10010664165019989
step: 60, loss: 0.11073026806116104
step: 70, loss: 0.11268025636672974
step: 80, loss: 0.11182855069637299
step: 90, loss: 0.09332175552845001
step: 100, loss: 0.04067523777484894
step: 110, loss: 0.10661282390356064
step: 120, loss: 0.10621452331542969
step: 130, loss: 0.04134479537606239
step: 140, loss: 0.06420394778251648
step: 150, loss: 0.370278924703598
step: 160, loss: 0.10883532464504242
step: 170, loss: 0.15588432550430298
step: 180, loss: 0.07249489426612854
step: 190, loss: 0.046183936297893524
step: 200, loss: 0.08929850906133652
step: 210, loss: 0.12983424961566925
step: 220, loss: 0.18829722702503204
step: 230, loss: 0.19212952256202698
step: 240, loss: 0.09899548441171646
step: 250, loss: 0.0955754891037941
step: 260, loss: 0.07590893656015396
step: 270, loss: 0.03991297632455826
step: 280, loss: 0.033894311636686325
step: 290, loss: 0.05977983400225639
step: 300, loss: 0.1422235071659088
step: 310, loss: 0.13205084204673767
step: 320, loss: 0.08292728662490845
step: 330, loss: 0.0735911950469017
epoch 6: dev_f1=0.8243902439024391, f1=0.803921568627451, best_f1=0.803921568627451
step: 0, loss: 0.06892288476228714
step: 10, loss: 0.09350750595331192
step: 20, loss: 0.15035052597522736
step: 30, loss: 0.1694934219121933
step: 40, loss: 0.039261214435100555
step: 50, loss: 0.142259880900383
step: 60, loss: 0.06535769999027252
step: 70, loss: 0.06999021768569946
step: 80, loss: 0.07002346217632294
step: 90, loss: 0.07237664610147476
step: 100, loss: 0.09825990349054337
step: 110, loss: 0.022984379902482033
step: 120, loss: 0.08821355551481247
step: 130, loss: 0.08441542088985443
step: 140, loss: 0.05184810608625412
step: 150, loss: 0.02391420118510723
step: 160, loss: 0.04007171839475632
step: 170, loss: 0.08952169120311737
step: 180, loss: 0.07575510442256927
step: 190, loss: 0.13667799532413483
step: 200, loss: 0.07101892679929733
step: 210, loss: 0.09390819817781448
step: 220, loss: 0.12510983645915985
step: 230, loss: 0.1293008029460907
step: 240, loss: 0.12534698843955994
step: 250, loss: 0.0022265228908509016
step: 260, loss: 0.13179072737693787
step: 270, loss: 0.05658967047929764
step: 280, loss: 0.07140760123729706
step: 290, loss: 0.06168033927679062
step: 300, loss: 0.08099064975976944
step: 310, loss: 0.07385069131851196
step: 320, loss: 0.013459531590342522
step: 330, loss: 0.04417596757411957
epoch 7: dev_f1=0.8206278026905829, f1=0.800865800865801, best_f1=0.803921568627451
step: 0, loss: 0.1039387434720993
step: 10, loss: 0.11197683215141296
step: 20, loss: 0.12657509744167328
step: 30, loss: 0.11031854897737503
step: 40, loss: 0.11554864794015884
step: 50, loss: 0.05142221972346306
step: 60, loss: 0.03699157387018204
step: 70, loss: 0.05968201160430908
step: 80, loss: 0.05251796543598175
step: 90, loss: 0.08133065700531006
step: 100, loss: 0.05001535266637802
step: 110, loss: 0.04322149232029915
step: 120, loss: 0.09261330217123032
step: 130, loss: 0.14200137555599213
step: 140, loss: 0.05407513305544853
step: 150, loss: 0.1177152544260025
step: 160, loss: 0.09343327581882477
step: 170, loss: 0.1571984589099884
step: 180, loss: 0.04041174799203873
step: 190, loss: 0.05862721428275108
step: 200, loss: 0.06299830228090286
step: 210, loss: 0.06784768402576447
step: 220, loss: 0.12440402060747147
step: 230, loss: 0.1008857935667038
step: 240, loss: 0.08715897053480148
step: 250, loss: 0.02154015377163887
step: 260, loss: 0.11425358802080154
step: 270, loss: 0.08373676240444183
step: 280, loss: 0.07813859730958939
step: 290, loss: 0.05051027610898018
step: 300, loss: 0.050187669694423676
step: 310, loss: 0.0016783141763880849
step: 320, loss: 0.15076182782649994
step: 330, loss: 0.07860884815454483
epoch 8: dev_f1=0.8200455580865603, f1=0.806941431670282, best_f1=0.803921568627451
step: 0, loss: 0.07797567546367645
step: 10, loss: 0.09293027967214584
step: 20, loss: 0.08861416578292847
step: 30, loss: 0.0682457908987999
step: 40, loss: 0.1183285266160965
step: 50, loss: 0.015974929556250572
step: 60, loss: 0.09508844465017319
step: 70, loss: 0.048726510256528854
step: 80, loss: 0.14390525221824646
step: 90, loss: 0.1625857949256897
step: 100, loss: 0.10327284038066864
step: 110, loss: 0.04161984845995903
step: 120, loss: 0.07805424928665161
step: 130, loss: 0.1341284066438675
step: 140, loss: 0.09149140864610672
step: 150, loss: 0.21638937294483185
step: 160, loss: 0.046118732541799545
step: 170, loss: 0.04700750857591629
step: 180, loss: 0.0839357003569603
step: 190, loss: 0.09991858154535294
step: 200, loss: 0.1511450856924057
step: 210, loss: 0.1447230726480484
step: 220, loss: 0.11061488091945648
step: 230, loss: 0.0015612654387950897
step: 240, loss: 0.09550567716360092
step: 250, loss: 0.05884988605976105
step: 260, loss: 0.07593392580747604
step: 270, loss: 0.1347348690032959
step: 280, loss: 7.738298154436052e-05
step: 290, loss: 0.03628043830394745
step: 300, loss: 0.13505074381828308
step: 310, loss: 0.050073977559804916
step: 320, loss: 0.29972001910209656
step: 330, loss: 0.07850132137537003
epoch 9: dev_f1=0.8269662921348315, f1=0.8193832599118943, best_f1=0.8193832599118943
step: 0, loss: 0.10850860178470612
step: 10, loss: 0.04045933857560158
step: 20, loss: 0.0665537416934967
step: 30, loss: 0.017543625086545944
step: 40, loss: 0.09656231850385666
step: 50, loss: 0.047358497977256775
step: 60, loss: 0.018000295385718346
step: 70, loss: 0.0864817425608635
step: 80, loss: 0.09744395315647125
step: 90, loss: 0.11269163340330124
step: 100, loss: 0.018763916566967964
step: 110, loss: 0.09261888265609741
step: 120, loss: 0.09969636052846909
step: 130, loss: 0.07795324921607971
step: 140, loss: 0.07756296545267105
step: 150, loss: 3.730796743184328e-05
step: 160, loss: 0.09376270323991776
step: 170, loss: 0.11636129021644592
step: 180, loss: 0.06081505864858627
step: 190, loss: 0.08957657963037491
step: 200, loss: 0.0436810702085495
step: 210, loss: 0.07710772007703781
step: 220, loss: 0.08692694455385208
step: 230, loss: 0.10436207056045532
step: 240, loss: 0.05150221660733223
step: 250, loss: 0.1504123955965042
step: 260, loss: 0.05421629175543785
step: 270, loss: 0.09573133289813995
step: 280, loss: 0.06029334291815758
step: 290, loss: 0.06149641051888466
step: 300, loss: 0.062038980424404144
step: 310, loss: 0.07117556035518646
step: 320, loss: 0.08986267447471619
step: 330, loss: 0.054271575063467026
epoch 10: dev_f1=0.8083140877598153, f1=0.7866666666666666, best_f1=0.8193832599118943
step: 0, loss: 0.03469778224825859
step: 10, loss: 0.1397939771413803
step: 20, loss: 0.11398112028837204
step: 30, loss: 0.08080405741930008
step: 40, loss: 0.032644957304000854
step: 50, loss: 0.0918145403265953
step: 60, loss: 0.14793995022773743
step: 70, loss: 0.04765472933650017
step: 80, loss: 0.114543117582798
step: 90, loss: 0.05180061236023903
step: 100, loss: 0.12719962000846863
step: 110, loss: 0.07907500118017197
step: 120, loss: 0.04634096473455429
step: 130, loss: 0.08803828805685043
step: 140, loss: 0.04657997563481331
step: 150, loss: 0.10657714307308197
step: 160, loss: 0.08075102418661118
step: 170, loss: 0.029517270624637604
step: 180, loss: 0.0877760574221611
step: 190, loss: 0.04599642753601074
step: 200, loss: 0.01749996654689312
step: 210, loss: 0.09710124880075455
step: 220, loss: 0.010337996296584606
step: 230, loss: 0.05962175130844116
step: 240, loss: 0.02239702083170414
step: 250, loss: 0.07877145707607269
step: 260, loss: 0.10637809336185455
step: 270, loss: 0.10297933965921402
step: 280, loss: 0.07228416949510574
step: 290, loss: 0.053270697593688965
step: 300, loss: 0.01845318265259266
step: 310, loss: 0.08802589029073715
step: 320, loss: 0.04680151119828224
step: 330, loss: 0.14812497794628143
epoch 11: dev_f1=0.8253968253968255, f1=0.8026315789473684, best_f1=0.8193832599118943
step: 0, loss: 0.044254980981349945
step: 10, loss: 0.0843798816204071
step: 20, loss: 0.09930381923913956
step: 30, loss: 0.019713949412107468
step: 40, loss: 0.026503872126340866
step: 50, loss: 0.0026554374489933252
step: 60, loss: 0.14986950159072876
step: 70, loss: 0.18517619371414185
step: 80, loss: 0.037962403148412704
step: 90, loss: 0.10018079727888107
step: 100, loss: 0.05181471258401871
step: 110, loss: 0.04251255840063095
step: 120, loss: 0.1727898120880127
step: 130, loss: 0.023743886500597
step: 140, loss: 0.09527885168790817
step: 150, loss: 0.08081480860710144
step: 160, loss: 0.13107138872146606
step: 170, loss: 0.3564993441104889
step: 180, loss: 0.13499467074871063
step: 190, loss: 0.11110863834619522
step: 200, loss: 0.006875750608742237
step: 210, loss: 0.06947701424360275
step: 220, loss: 0.11575381457805634
step: 230, loss: 0.023630838841199875
step: 240, loss: 0.015067528001964092
step: 250, loss: 0.10755647718906403
step: 260, loss: 0.0675286278128624
step: 270, loss: 0.11002273857593536
step: 280, loss: 0.09099193662405014
step: 290, loss: 0.07905701547861099
step: 300, loss: 0.15633337199687958
step: 310, loss: 0.07889114320278168
step: 320, loss: 0.06737221032381058
step: 330, loss: 0.06689441949129105
epoch 12: dev_f1=0.8262910798122066, f1=0.8211009174311925, best_f1=0.8193832599118943
step: 0, loss: 0.16331467032432556
step: 10, loss: 0.05797494947910309
step: 20, loss: 0.04311775416135788
step: 30, loss: 0.1722126454114914
step: 40, loss: 0.050760094076395035
step: 50, loss: 0.033680230379104614
step: 60, loss: 0.006622019223868847
step: 70, loss: 0.0745450109243393
step: 80, loss: 0.05145914480090141
step: 90, loss: 0.025719519704580307
step: 100, loss: 0.0972069725394249
step: 110, loss: 0.06113862991333008
step: 120, loss: 0.11509738862514496
step: 130, loss: 0.07887048274278641
step: 140, loss: 0.07522403448820114
step: 150, loss: 0.050216153264045715
step: 160, loss: 0.03205821290612221
step: 170, loss: 0.0699203610420227
step: 180, loss: 0.10346187651157379
step: 190, loss: 0.0502668134868145
step: 200, loss: 0.13921129703521729
step: 210, loss: 0.15335100889205933
step: 220, loss: 0.004569006618112326
step: 230, loss: 0.07686634361743927
step: 240, loss: 0.11630184948444366
step: 250, loss: 0.04143679887056351
step: 260, loss: 0.11671075224876404
step: 270, loss: 0.15108607709407806
step: 280, loss: 0.0985662192106247
step: 290, loss: 0.0625152662396431
step: 300, loss: 0.09655551612377167
step: 310, loss: 0.08929941058158875
step: 320, loss: 0.07207620143890381
step: 330, loss: 0.07341575622558594
epoch 13: dev_f1=0.8292682926829268, f1=0.8066825775656326, best_f1=0.8066825775656326
step: 0, loss: 0.07190904766321182
step: 10, loss: 0.034137945622205734
step: 20, loss: 0.07201415300369263
step: 30, loss: 0.11351972073316574
step: 40, loss: 0.07794582098722458
step: 50, loss: 0.09718097746372223
step: 60, loss: 0.11256071925163269
step: 70, loss: 0.038414765149354935
step: 80, loss: 0.11997082084417343
step: 90, loss: 0.011838024482131004
step: 100, loss: 0.13172414898872375
step: 110, loss: 0.10797353088855743
step: 120, loss: 0.14424856007099152
step: 130, loss: 0.0542769655585289
step: 140, loss: 0.09742985665798187
step: 150, loss: 0.11414027214050293
step: 160, loss: 0.05921605974435806
step: 170, loss: 0.14854879677295685
step: 180, loss: 0.02117888815701008
step: 190, loss: 0.1354234516620636
step: 200, loss: 0.05067847669124603
step: 210, loss: 0.10136142373085022
step: 220, loss: 0.05119588226079941
step: 230, loss: 0.046156082302331924
step: 240, loss: 0.07249794155359268
step: 250, loss: 0.11206003278493881
step: 260, loss: 0.09833085536956787
step: 270, loss: 0.1598844677209854
step: 280, loss: 0.0727308988571167
step: 290, loss: 0.061166372150182724
step: 300, loss: 0.09601973742246628
step: 310, loss: 0.09517699480056763
step: 320, loss: 0.024782320484519005
step: 330, loss: 0.058026913553476334
epoch 14: dev_f1=0.8203883495145631, f1=0.812206572769953, best_f1=0.8066825775656326
step: 0, loss: 0.030650485306978226
step: 10, loss: 0.14104193449020386
step: 20, loss: 0.10060226172208786
step: 30, loss: 0.057861294597387314
step: 40, loss: 0.09130415320396423
step: 50, loss: 0.04446808621287346
step: 60, loss: 0.04010516032576561
step: 70, loss: 0.07666576653718948
step: 80, loss: 0.09885584563016891
step: 90, loss: 0.061942506581544876
step: 100, loss: 0.08183079957962036
step: 110, loss: 0.041904158890247345
step: 120, loss: 0.08634265512228012
step: 130, loss: 0.09610127657651901
step: 140, loss: 5.860875899088569e-05
step: 150, loss: 0.022103769704699516
step: 160, loss: 0.13430209457874298
step: 170, loss: 0.039655618369579315
step: 180, loss: 3.9785045373719186e-05
step: 190, loss: 0.10864725708961487
step: 200, loss: 0.06475183367729187
step: 210, loss: 0.08884554356336594
step: 220, loss: 0.09566578269004822
step: 230, loss: 0.057083360850811005
step: 240, loss: 0.15124130249023438
step: 250, loss: 0.019470831379294395
step: 260, loss: 0.0807015672326088
step: 270, loss: 0.12121627479791641
step: 280, loss: 0.0844043642282486
step: 290, loss: 0.11202249675989151
step: 300, loss: 0.09117872267961502
step: 310, loss: 0.1410074681043625
step: 320, loss: 0.03466715291142464
step: 330, loss: 0.06200843304395676
epoch 15: dev_f1=0.8285714285714285, f1=0.8009367681498829, best_f1=0.8066825775656326
step: 0, loss: 0.057778630405664444
step: 10, loss: 0.07425563782453537
step: 20, loss: 0.12241026759147644
step: 30, loss: 0.10569929331541061
step: 40, loss: 0.08131185919046402
step: 50, loss: 0.14399407804012299
step: 60, loss: 0.08282885700464249
step: 70, loss: 0.0618085078895092
step: 80, loss: 0.01621519774198532
step: 90, loss: 0.027816765010356903
step: 100, loss: 0.06172437593340874
step: 110, loss: 0.07223409414291382
step: 120, loss: 0.036093469709157944
step: 130, loss: 0.06334444135427475
step: 140, loss: 0.048593293875455856
step: 150, loss: 0.06543857604265213
step: 160, loss: 0.04588013142347336
step: 170, loss: 0.03361211717128754
step: 180, loss: 0.0442688874900341
step: 190, loss: 0.11446095257997513
step: 200, loss: 0.024042531847953796
step: 210, loss: 0.08891915529966354
step: 220, loss: 0.06708499044179916
step: 230, loss: 0.0505589097738266
step: 240, loss: 0.03655427694320679
step: 250, loss: 0.16456343233585358
step: 260, loss: 0.035743821412324905
step: 270, loss: 0.08195089548826218
step: 280, loss: 0.08536867052316666
step: 290, loss: 0.04410940036177635
step: 300, loss: 0.032136477530002594
step: 310, loss: 0.22215016186237335
step: 320, loss: 0.057199884206056595
step: 330, loss: 0.06525982171297073
epoch 16: dev_f1=0.8216704288939052, f1=0.7991169977924945, best_f1=0.8066825775656326
step: 0, loss: 0.07165499776601791
step: 10, loss: 0.0851479098200798
step: 20, loss: 0.08911558985710144
step: 30, loss: 0.012710662558674812
step: 40, loss: 0.1074596494436264
step: 50, loss: 0.09733137488365173
step: 60, loss: 0.0559919998049736
step: 70, loss: 0.027911359444260597
step: 80, loss: 0.041350264102220535
step: 90, loss: 0.048783332109451294
step: 100, loss: 0.08585623651742935
step: 110, loss: 0.15492181479930878
step: 120, loss: 0.07104021310806274
step: 130, loss: 0.14423194527626038
step: 140, loss: 0.020798923447728157
step: 150, loss: 0.11001935601234436
step: 160, loss: 0.03607077896595001
step: 170, loss: 0.05877359211444855
step: 180, loss: 0.12386655807495117
step: 190, loss: 0.034511007368564606
step: 200, loss: 0.07083536684513092
step: 210, loss: 0.0762215182185173
step: 220, loss: 0.034056778997182846
step: 230, loss: 0.014978877268731594
step: 240, loss: 0.07948657125234604
step: 250, loss: 0.053812865167856216
step: 260, loss: 0.03666812926530838
step: 270, loss: 0.08419553190469742
step: 280, loss: 0.17407125234603882
step: 290, loss: 0.0733589380979538
step: 300, loss: 0.07077359408140182
step: 310, loss: 0.022148245945572853
step: 320, loss: 0.09088346362113953
step: 330, loss: 0.12753136456012726
epoch 17: dev_f1=0.8223844282238442, f1=0.8105515587529976, best_f1=0.8066825775656326
step: 0, loss: 0.05918212607502937
step: 10, loss: 0.0996347963809967
step: 20, loss: 0.026467042043805122
step: 30, loss: 0.09658663719892502
step: 40, loss: 0.0828501284122467
step: 50, loss: 0.014844481833279133
step: 60, loss: 0.026304909959435463
step: 70, loss: 0.07198569178581238
step: 80, loss: 0.025004664435982704
step: 90, loss: 0.10414523631334305
step: 100, loss: 0.09044679999351501
step: 110, loss: 0.07929621636867523
step: 120, loss: 0.07190593332052231
step: 130, loss: 0.1559572070837021
step: 140, loss: 0.1120099425315857
step: 150, loss: 0.034444790333509445
step: 160, loss: 0.019924260675907135
step: 170, loss: 0.09026535600423813
step: 180, loss: 0.09799952059984207
step: 190, loss: 0.04622454568743706
step: 200, loss: 0.045569099485874176
step: 210, loss: 0.0391034334897995
step: 220, loss: 0.1247510313987732
step: 230, loss: 0.04747157543897629
step: 240, loss: 0.03514198586344719
step: 250, loss: 0.10182208567857742
step: 260, loss: 0.1704123169183731
step: 270, loss: 0.055891744792461395
step: 280, loss: 0.08470813184976578
step: 290, loss: 0.04385928437113762
step: 300, loss: 0.11511224508285522
step: 310, loss: 0.05841105803847313
step: 320, loss: 0.010587511584162712
step: 330, loss: 0.055863577872514725
epoch 18: dev_f1=0.8144578313253013, f1=0.7934272300469484, best_f1=0.8066825775656326
step: 0, loss: 0.09373275935649872
step: 10, loss: 0.08977339416742325
step: 20, loss: 0.07803557813167572
step: 30, loss: 0.101142518222332
step: 40, loss: 0.07568737119436264
step: 50, loss: 0.031184080988168716
step: 60, loss: 0.08331184089183807
step: 70, loss: 0.0848771333694458
step: 80, loss: 0.14351479709148407
step: 90, loss: 0.03536086156964302
step: 100, loss: 0.08094348758459091
step: 110, loss: 0.07202998548746109
step: 120, loss: 0.017316322773694992
step: 130, loss: 0.06875082850456238
step: 140, loss: 0.12248498946428299
step: 150, loss: 0.09551811218261719
step: 160, loss: 0.0711517184972763
step: 170, loss: 0.06609395146369934
step: 180, loss: 0.130375936627388
step: 190, loss: 0.129279226064682
step: 200, loss: 0.03814380243420601
step: 210, loss: 0.04409515857696533
step: 220, loss: 0.02931646630167961
step: 230, loss: 0.045758206397295
step: 240, loss: 0.10042431950569153
step: 250, loss: 0.10775422304868698
step: 260, loss: 0.05357679724693298
step: 270, loss: 0.05484504625201225
step: 280, loss: 0.04002627730369568
step: 290, loss: 0.052970562130212784
step: 300, loss: 0.12595467269420624
step: 310, loss: 0.04297371208667755
step: 320, loss: 0.05339520797133446
step: 330, loss: 0.03628731518983841
epoch 19: dev_f1=0.8, f1=0.7880299251870324, best_f1=0.8066825775656326
step: 0, loss: 0.10690829902887344
step: 10, loss: 0.13183225691318512
step: 20, loss: 0.036826085299253464
step: 30, loss: 0.10026849806308746
step: 40, loss: 0.0515001118183136
step: 50, loss: 0.011062645353376865
step: 60, loss: 0.05958588793873787
step: 70, loss: 0.013458717614412308
step: 80, loss: 0.12509608268737793
step: 90, loss: 0.08161057531833649
step: 100, loss: 0.09804850816726685
step: 110, loss: 0.04641516134142876
step: 120, loss: 0.07425796240568161
step: 130, loss: 0.025062186643481255
step: 140, loss: 0.16023758053779602
step: 150, loss: 0.05138364061713219
step: 160, loss: 0.07686303555965424
step: 170, loss: 0.098487988114357
step: 180, loss: 0.00031873778789304197
step: 190, loss: 0.17230600118637085
step: 200, loss: 0.13710886240005493
step: 210, loss: 0.15079455077648163
step: 220, loss: 0.07012585550546646
step: 230, loss: 0.16397476196289062
step: 240, loss: 0.0737491175532341
step: 250, loss: 0.05706300586462021
step: 260, loss: 0.07263702154159546
step: 270, loss: 0.07872943580150604
step: 280, loss: 0.020555227994918823
step: 290, loss: 0.15099495649337769
step: 300, loss: 0.08045691251754761
step: 310, loss: 0.1120055615901947
step: 320, loss: 0.017445608973503113
step: 330, loss: 0.06731032580137253
epoch 20: dev_f1=0.8029556650246306, f1=0.7971014492753623, best_f1=0.8066825775656326
