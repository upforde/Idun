cuda
Device: cuda
step: 0, loss: 0.6946988701820374
step: 10, loss: 0.22629141807556152
step: 20, loss: 0.1623709350824356
step: 30, loss: 0.33624258637428284
step: 40, loss: 0.24619346857070923
step: 50, loss: 0.15159042179584503
step: 60, loss: 0.1437806338071823
step: 70, loss: 0.1364651918411255
step: 80, loss: 0.3081396520137787
step: 90, loss: 0.055195409804582596
step: 100, loss: 0.38743430376052856
step: 110, loss: 0.23552405834197998
step: 120, loss: 0.24630141258239746
step: 130, loss: 0.3170533776283264
step: 140, loss: 0.333071768283844
step: 150, loss: 0.1311100423336029
step: 160, loss: 0.21495868265628815
step: 170, loss: 0.21253980696201324
step: 180, loss: 0.3422480821609497
step: 190, loss: 0.3044649660587311
step: 200, loss: 0.07963795214891434
step: 210, loss: 0.28412124514579773
step: 220, loss: 0.02146260440349579
step: 230, loss: 0.16523323953151703
step: 240, loss: 0.11854672431945801
step: 250, loss: 0.11177225410938263
step: 260, loss: 0.06898577511310577
step: 270, loss: 0.13303668797016144
step: 280, loss: 0.28381696343421936
step: 290, loss: 0.12169791758060455
step: 300, loss: 0.2243335247039795
step: 310, loss: 0.13232958316802979
step: 320, loss: 0.23181983828544617
step: 330, loss: 0.12803879380226135
epoch 1: dev_f1=0.6483516483516484, f1=0.6363636363636364, best_f1=0.6363636363636364
step: 0, loss: 0.08940749615430832
step: 10, loss: 0.15958629548549652
step: 20, loss: 0.17212003469467163
step: 30, loss: 0.04180926829576492
step: 40, loss: 0.09556645900011063
step: 50, loss: 0.17937971651554108
step: 60, loss: 0.19685308635234833
step: 70, loss: 0.16493850946426392
step: 80, loss: 0.10899261385202408
step: 90, loss: 0.07502797245979309
step: 100, loss: 0.2891009449958801
step: 110, loss: 0.03463558852672577
step: 120, loss: 0.18150733411312103
step: 130, loss: 0.06539691239595413
step: 140, loss: 0.0572170689702034
step: 150, loss: 0.09591255336999893
step: 160, loss: 0.0855586901307106
step: 170, loss: 0.16067852079868317
step: 180, loss: 0.02262810990214348
step: 190, loss: 0.11689383536577225
step: 200, loss: 0.15020248293876648
step: 210, loss: 0.13836804032325745
step: 220, loss: 0.19582988321781158
step: 230, loss: 0.158625066280365
step: 240, loss: 0.1394139677286148
step: 250, loss: 0.05756225809454918
step: 260, loss: 0.07267791777849197
step: 270, loss: 0.05460808053612709
step: 280, loss: 0.013592923060059547
step: 290, loss: 0.18115729093551636
step: 300, loss: 0.07799180597066879
step: 310, loss: 0.09660255163908005
step: 320, loss: 0.061325717717409134
step: 330, loss: 0.10358963161706924
epoch 2: dev_f1=0.7656903765690377, f1=0.7434343434343433, best_f1=0.7434343434343433
step: 0, loss: 0.06689328700304031
step: 10, loss: 0.059873323887586594
step: 20, loss: 0.10352092236280441
step: 30, loss: 0.06444060802459717
step: 40, loss: 0.1436793953180313
step: 50, loss: 0.14732494950294495
step: 60, loss: 0.028985030949115753
step: 70, loss: 0.04682088643312454
step: 80, loss: 0.06938821077346802
step: 90, loss: 0.09582345187664032
step: 100, loss: 0.0881224200129509
step: 110, loss: 0.18436872959136963
step: 120, loss: 0.09902584552764893
step: 130, loss: 0.02443462423980236
step: 140, loss: 0.03486163169145584
step: 150, loss: 0.07375645637512207
step: 160, loss: 0.12770651280879974
step: 170, loss: 0.10384134948253632
step: 180, loss: 0.14204145967960358
step: 190, loss: 0.07497160881757736
step: 200, loss: 0.07620013505220413
step: 210, loss: 0.08116200566291809
step: 220, loss: 0.10999909043312073
step: 230, loss: 0.10149375349283218
step: 240, loss: 0.09425776451826096
step: 250, loss: 0.04597155749797821
step: 260, loss: 0.06929132342338562
step: 270, loss: 0.1365298330783844
step: 280, loss: 0.12451434135437012
step: 290, loss: 0.09489511698484421
step: 300, loss: 0.16975060105323792
step: 310, loss: 0.07867781072854996
step: 320, loss: 0.05913308635354042
step: 330, loss: 0.09020408242940903
epoch 3: dev_f1=0.8018018018018017, f1=0.778021978021978, best_f1=0.778021978021978
step: 0, loss: 0.05014545097947121
step: 10, loss: 0.061337195336818695
step: 20, loss: 0.0765434056520462
step: 30, loss: 0.14160306751728058
step: 40, loss: 0.10043454170227051
step: 50, loss: 0.1261693388223648
step: 60, loss: 0.07733774930238724
step: 70, loss: 0.07473141700029373
step: 80, loss: 0.14277051389217377
step: 90, loss: 0.07756353169679642
step: 100, loss: 0.264108270406723
step: 110, loss: 0.12475037574768066
step: 120, loss: 0.024792173877358437
step: 130, loss: 0.16846886277198792
step: 140, loss: 0.06686484813690186
step: 150, loss: 0.10674276947975159
step: 160, loss: 0.12025903165340424
step: 170, loss: 0.1894323080778122
step: 180, loss: 0.06315451860427856
step: 190, loss: 0.1308300942182541
step: 200, loss: 0.09204743802547455
step: 210, loss: 0.12088672071695328
step: 220, loss: 0.1536550372838974
step: 230, loss: 0.0930902436375618
step: 240, loss: 0.14060334861278534
step: 250, loss: 0.05564142391085625
step: 260, loss: 0.13379135727882385
step: 270, loss: 0.13756467401981354
step: 280, loss: 0.1652180701494217
step: 290, loss: 0.2046874463558197
step: 300, loss: 0.14205534756183624
step: 310, loss: 0.0558936670422554
step: 320, loss: 0.09308572113513947
step: 330, loss: 0.0650935098528862
epoch 4: dev_f1=0.8026905829596412, f1=0.7757847533632286, best_f1=0.7757847533632286
step: 0, loss: 0.04092104732990265
step: 10, loss: 0.08905556797981262
step: 20, loss: 0.09571363031864166
step: 30, loss: 0.0952637791633606
step: 40, loss: 0.19759328663349152
step: 50, loss: 0.11332147568464279
step: 60, loss: 0.17145462334156036
step: 70, loss: 0.08520407974720001
step: 80, loss: 0.04620303958654404
step: 90, loss: 0.05741317570209503
step: 100, loss: 0.05723181739449501
step: 110, loss: 0.15655304491519928
step: 120, loss: 0.08061254769563675
step: 130, loss: 0.19344308972358704
step: 140, loss: 0.02550976164638996
step: 150, loss: 0.13593639433383942
step: 160, loss: 0.06043742224574089
step: 170, loss: 0.10585511475801468
step: 180, loss: 0.10076973587274551
step: 190, loss: 0.11395464092493057
step: 200, loss: 0.09171304106712341
step: 210, loss: 0.08928091078996658
step: 220, loss: 0.133301243185997
step: 230, loss: 0.03465466946363449
step: 240, loss: 0.09610464423894882
step: 250, loss: 0.13444972038269043
step: 260, loss: 0.0948898121714592
step: 270, loss: 0.2993312478065491
step: 280, loss: 0.11760321259498596
step: 290, loss: 0.08405599743127823
step: 300, loss: 0.15995670855045319
step: 310, loss: 0.1111307218670845
step: 320, loss: 0.062007755041122437
step: 330, loss: 0.05419014394283295
epoch 5: dev_f1=0.828235294117647, f1=0.8018867924528301, best_f1=0.8018867924528301
step: 0, loss: 0.08939243853092194
step: 10, loss: 0.10762304067611694
step: 20, loss: 0.1004384234547615
step: 30, loss: 0.12535041570663452
step: 40, loss: 0.07571787387132645
step: 50, loss: 0.025738367810845375
step: 60, loss: 0.07338795810937881
step: 70, loss: 0.10282174497842789
step: 80, loss: 0.11186965554952621
step: 90, loss: 0.019371118396520615
step: 100, loss: 0.11555440723896027
step: 110, loss: 0.05740956962108612
step: 120, loss: 0.06855329126119614
step: 130, loss: 0.10467980057001114
step: 140, loss: 0.07956767082214355
step: 150, loss: 0.13253933191299438
step: 160, loss: 0.09246215969324112
step: 170, loss: 0.0680578351020813
step: 180, loss: 0.16750964522361755
step: 190, loss: 0.04158210754394531
step: 200, loss: 0.15421651303768158
step: 210, loss: 0.1669905185699463
step: 220, loss: 0.09218329936265945
step: 230, loss: 0.13430723547935486
step: 240, loss: 0.06009889394044876
step: 250, loss: 0.108635313808918
step: 260, loss: 0.0660712942481041
step: 270, loss: 0.030103549361228943
step: 280, loss: 0.09722015261650085
step: 290, loss: 0.06665582209825516
step: 300, loss: 0.06751836836338043
step: 310, loss: 0.03997413069009781
step: 320, loss: 0.0726046934723854
step: 330, loss: 0.05373870208859444
epoch 6: dev_f1=0.7961630695443646, f1=0.7895981087470448, best_f1=0.8018867924528301
step: 0, loss: 0.1311250478029251
step: 10, loss: 0.057330239564180374
step: 20, loss: 0.050721876323223114
step: 30, loss: 0.11008576303720474
step: 40, loss: 0.038054268807172775
step: 50, loss: 0.05224405974149704
step: 60, loss: 0.18656665086746216
step: 70, loss: 0.2007271647453308
step: 80, loss: 0.09179471433162689
step: 90, loss: 0.23845680058002472
step: 100, loss: 0.038345158100128174
step: 110, loss: 0.12359847873449326
step: 120, loss: 0.12036390602588654
step: 130, loss: 0.13417856395244598
step: 140, loss: 0.02841252088546753
step: 150, loss: 0.07738421112298965
step: 160, loss: 0.21700972318649292
step: 170, loss: 0.09729324281215668
step: 180, loss: 0.0971669852733612
step: 190, loss: 0.09967143833637238
step: 200, loss: 0.0792711153626442
step: 210, loss: 0.10106900334358215
step: 220, loss: 0.07966957986354828
step: 230, loss: 0.09578707814216614
step: 240, loss: 0.17296850681304932
step: 250, loss: 0.10035182535648346
step: 260, loss: 0.07236941158771515
step: 270, loss: 0.10069575905799866
step: 280, loss: 0.1682145595550537
step: 290, loss: 0.040605418384075165
step: 300, loss: 0.12988096475601196
step: 310, loss: 0.10870811343193054
step: 320, loss: 0.07863058894872665
step: 330, loss: 0.0493888296186924
epoch 7: dev_f1=0.8134831460674157, f1=0.7973273942093541, best_f1=0.8018867924528301
step: 0, loss: 0.13708744943141937
step: 10, loss: 0.11959709972143173
step: 20, loss: 0.040002286434173584
step: 30, loss: 0.1478736251592636
step: 40, loss: 0.08750804513692856
step: 50, loss: 0.040759291499853134
step: 60, loss: 0.050533466041088104
step: 70, loss: 0.10550737380981445
step: 80, loss: 0.03020474500954151
step: 90, loss: 0.1656072735786438
step: 100, loss: 0.05788344889879227
step: 110, loss: 0.0712558925151825
step: 120, loss: 0.10021864622831345
step: 130, loss: 0.10963352024555206
step: 140, loss: 0.10313256084918976
step: 150, loss: 0.03161065652966499
step: 160, loss: 0.1864297091960907
step: 170, loss: 0.14542599022388458
step: 180, loss: 0.04108380153775215
step: 190, loss: 0.06513113528490067
step: 200, loss: 0.04037164896726608
step: 210, loss: 0.10405456274747849
step: 220, loss: 0.05848779156804085
step: 230, loss: 0.07686982303857803
step: 240, loss: 0.06461459398269653
step: 250, loss: 0.07734259217977524
step: 260, loss: 0.043521467596292496
step: 270, loss: 0.22210945188999176
step: 280, loss: 0.05727151408791542
step: 290, loss: 0.07245063036680222
step: 300, loss: 0.1262752115726471
step: 310, loss: 0.09259955585002899
step: 320, loss: 0.17174582183361053
step: 330, loss: 0.10745371878147125
epoch 8: dev_f1=0.8309178743961353, f1=0.79136690647482, best_f1=0.79136690647482
step: 0, loss: 0.07337729632854462
step: 10, loss: 0.02236958034336567
step: 20, loss: 0.14830754697322845
step: 30, loss: 0.038716573268175125
step: 40, loss: 0.14145612716674805
step: 50, loss: 0.04649887606501579
step: 60, loss: 0.15181905031204224
step: 70, loss: 0.2172769457101822
step: 80, loss: 0.159699946641922
step: 90, loss: 0.08711981773376465
step: 100, loss: 0.035495031625032425
step: 110, loss: 0.02867736853659153
step: 120, loss: 0.11997044086456299
step: 130, loss: 0.045322272926568985
step: 140, loss: 0.05551198869943619
step: 150, loss: 0.06482689827680588
step: 160, loss: 0.15416663885116577
step: 170, loss: 0.09314072132110596
step: 180, loss: 0.09311192482709885
step: 190, loss: 0.13578303158283234
step: 200, loss: 0.06802751868963242
step: 210, loss: 0.011785515584051609
step: 220, loss: 0.02666453830897808
step: 230, loss: 0.18407770991325378
step: 240, loss: 0.08845680952072144
step: 250, loss: 0.03563978895545006
step: 260, loss: 0.04084223508834839
step: 270, loss: 0.11779671907424927
step: 280, loss: 0.11238525062799454
step: 290, loss: 0.17591296136379242
step: 300, loss: 0.02462078630924225
step: 310, loss: 0.09017732739448547
step: 320, loss: 0.14036425948143005
step: 330, loss: 0.04318623244762421
epoch 9: dev_f1=0.8497652582159625, f1=0.8045977011494253, best_f1=0.8045977011494253
step: 0, loss: 0.170657217502594
step: 10, loss: 0.15832282602787018
step: 20, loss: 0.20386172831058502
step: 30, loss: 0.14285334944725037
step: 40, loss: 0.06791260093450546
step: 50, loss: 0.06191497668623924
step: 60, loss: 0.057087242603302
step: 70, loss: 0.09534178674221039
step: 80, loss: 0.041526492685079575
step: 90, loss: 0.04252007603645325
step: 100, loss: 0.07781540602445602
step: 110, loss: 0.10106589645147324
step: 120, loss: 0.04694691300392151
step: 130, loss: 0.07676497101783752
step: 140, loss: 0.048762813210487366
step: 150, loss: 0.13731500506401062
step: 160, loss: 0.07617755234241486
step: 170, loss: 0.061628784984350204
step: 180, loss: 0.08828667551279068
step: 190, loss: 0.17901846766471863
step: 200, loss: 0.0262884683907032
step: 210, loss: 0.059693288058042526
step: 220, loss: 0.03757811337709427
step: 230, loss: 0.0880894884467125
step: 240, loss: 0.1013360247015953
step: 250, loss: 0.02025393582880497
step: 260, loss: 0.07277850061655045
step: 270, loss: 0.08871787786483765
step: 280, loss: 0.004677509889006615
step: 290, loss: 0.07690959423780441
step: 300, loss: 0.035036519169807434
step: 310, loss: 0.0913219079375267
step: 320, loss: 0.11202305555343628
step: 330, loss: 0.08144953846931458
epoch 10: dev_f1=0.8402948402948404, f1=0.801980198019802, best_f1=0.8045977011494253
step: 0, loss: 0.08542529493570328
step: 10, loss: 0.1029871478676796
step: 20, loss: 0.06409542262554169
step: 30, loss: 0.09869907051324844
step: 40, loss: 0.08701644092798233
step: 50, loss: 0.09357967227697372
step: 60, loss: 0.030859678983688354
step: 70, loss: 0.07584048062562943
step: 80, loss: 0.09679319709539413
step: 90, loss: 0.06443095952272415
step: 100, loss: 0.0003460561274550855
step: 110, loss: 0.08078497648239136
step: 120, loss: 0.03844870999455452
step: 130, loss: 0.1016102060675621
step: 140, loss: 0.12180205434560776
step: 150, loss: 0.10691912472248077
step: 160, loss: 0.02395057864487171
step: 170, loss: 0.05436845123767853
step: 180, loss: 0.11625692993402481
step: 190, loss: 0.06347182393074036
step: 200, loss: 0.053006611764431
step: 210, loss: 0.14253224432468414
step: 220, loss: 0.03742115572094917
step: 230, loss: 0.07245578616857529
step: 240, loss: 0.03069857880473137
step: 250, loss: 0.07184026390314102
step: 260, loss: 0.00021541843307204545
step: 270, loss: 0.1111021563410759
step: 280, loss: 0.10480688512325287
step: 290, loss: 0.07174912840127945
step: 300, loss: 0.1831158697605133
step: 310, loss: 0.03597316890954971
step: 320, loss: 0.11949965357780457
step: 330, loss: 0.12418761849403381
epoch 11: dev_f1=0.8237885462555066, f1=0.8060344827586207, best_f1=0.8045977011494253
step: 0, loss: 0.09094712138175964
step: 10, loss: 0.10707276314496994
step: 20, loss: 0.07908526062965393
step: 30, loss: 0.07963364571332932
step: 40, loss: 0.1025327667593956
step: 50, loss: 0.03662790358066559
step: 60, loss: 0.13006535172462463
step: 70, loss: 0.03176169469952583
step: 80, loss: 0.06610840559005737
step: 90, loss: 0.12347304075956345
step: 100, loss: 0.11024604737758636
step: 110, loss: 0.11820834875106812
step: 120, loss: 0.14244692027568817
step: 130, loss: 0.023969167843461037
step: 140, loss: 0.0660514384508133
step: 150, loss: 0.0839889794588089
step: 160, loss: 0.054963476955890656
step: 170, loss: 0.00013937149196863174
step: 180, loss: 0.03230049088597298
step: 190, loss: 0.1510990411043167
step: 200, loss: 0.04782738536596298
step: 210, loss: 0.08527155965566635
step: 220, loss: 0.02358897589147091
step: 230, loss: 0.11636415868997574
step: 240, loss: 0.04934719577431679
step: 250, loss: 0.10199060291051865
step: 260, loss: 0.11280364543199539
step: 270, loss: 0.04642198979854584
step: 280, loss: 0.05238085612654686
step: 290, loss: 0.09318442642688751
step: 300, loss: 0.12326805293560028
step: 310, loss: 0.0993485301733017
step: 320, loss: 0.061554763466119766
step: 330, loss: 0.10402674973011017
epoch 12: dev_f1=0.8154897494305238, f1=0.817155756207675, best_f1=0.8045977011494253
step: 0, loss: 0.10310035198926926
step: 10, loss: 0.09282419085502625
step: 20, loss: 0.05032886937260628
step: 30, loss: 0.04479353502392769
step: 40, loss: 0.1119513213634491
step: 50, loss: 0.030528375878930092
step: 60, loss: 0.06582450866699219
step: 70, loss: 0.09946146607398987
step: 80, loss: 0.03522979095578194
step: 90, loss: 0.04769445210695267
step: 100, loss: 0.07721161842346191
step: 110, loss: 0.16969504952430725
step: 120, loss: 0.07752136141061783
step: 130, loss: 0.037494927644729614
step: 140, loss: 0.027293166145682335
step: 150, loss: 0.014852517284452915
step: 160, loss: 0.12775883078575134
step: 170, loss: 0.0920158252120018
step: 180, loss: 0.05594361200928688
step: 190, loss: 0.07468610256910324
step: 200, loss: 0.05204583704471588
step: 210, loss: 0.19068032503128052
step: 220, loss: 0.022054020315408707
step: 230, loss: 0.03320220485329628
step: 240, loss: 0.12161105871200562
step: 250, loss: 0.07923966646194458
step: 260, loss: 0.08538892865180969
step: 270, loss: 0.11501474678516388
step: 280, loss: 0.05744947865605354
step: 290, loss: 0.03391861170530319
step: 300, loss: 0.0674910843372345
step: 310, loss: 0.05788715183734894
step: 320, loss: 0.09136798977851868
step: 330, loss: 0.1493290364742279
epoch 13: dev_f1=0.8293838862559242, f1=0.8169014084507042, best_f1=0.8045977011494253
step: 0, loss: 0.052391767501831055
step: 10, loss: 0.10361583530902863
step: 20, loss: 0.07940240204334259
step: 30, loss: 0.12276089191436768
step: 40, loss: 0.11208125203847885
step: 50, loss: 0.037387873977422714
step: 60, loss: 0.05665835738182068
step: 70, loss: 0.03661623224616051
step: 80, loss: 0.07141803205013275
step: 90, loss: 0.021882357075810432
step: 100, loss: 0.09554571658372879
step: 110, loss: 0.08293826133012772
step: 120, loss: 0.17103159427642822
step: 130, loss: 0.07592413574457169
step: 140, loss: 0.048856109380722046
step: 150, loss: 0.06571363657712936
step: 160, loss: 0.08065927028656006
step: 170, loss: 0.10579868406057358
step: 180, loss: 0.05489351972937584
step: 190, loss: 0.09177886694669724
step: 200, loss: 0.07968166470527649
step: 210, loss: 0.14075437188148499
step: 220, loss: 0.040079303085803986
step: 230, loss: 0.10625118762254715
step: 240, loss: 0.06686557084321976
step: 250, loss: 0.0777849555015564
step: 260, loss: 0.062097884714603424
step: 270, loss: 0.09466740489006042
step: 280, loss: 0.053747717291116714
step: 290, loss: 0.0554020069539547
step: 300, loss: 0.03939351812005043
step: 310, loss: 0.11661703884601593
step: 320, loss: 0.07874371111392975
step: 330, loss: 0.17246684432029724
epoch 14: dev_f1=0.8337349397590362, f1=0.8201438848920863, best_f1=0.8045977011494253
step: 0, loss: 0.04187902808189392
step: 10, loss: 0.12599733471870422
step: 20, loss: 0.03929544612765312
step: 30, loss: 0.06584376841783524
step: 40, loss: 0.02939693070948124
step: 50, loss: 0.058275006711483
step: 60, loss: 0.03554440662264824
step: 70, loss: 0.09299872070550919
step: 80, loss: 0.20074479281902313
step: 90, loss: 0.05704541504383087
step: 100, loss: 0.04561362788081169
step: 110, loss: 0.05250419303774834
step: 120, loss: 0.08915645629167557
step: 130, loss: 0.053036730736494064
step: 140, loss: 0.021013716235756874
step: 150, loss: 0.03925967216491699
step: 160, loss: 5.2275980124250054e-05
step: 170, loss: 0.03021319769322872
step: 180, loss: 0.0932922437787056
step: 190, loss: 0.09698595106601715
step: 200, loss: 0.03419840335845947
step: 210, loss: 0.007971598766744137
step: 220, loss: 0.04270360991358757
step: 230, loss: 0.12663684785366058
step: 240, loss: 0.107683464884758
step: 250, loss: 0.11550771445035934
step: 260, loss: 0.04762197285890579
step: 270, loss: 0.029687734320759773
step: 280, loss: 0.03910012170672417
step: 290, loss: 0.05533803999423981
step: 300, loss: 0.05539579316973686
step: 310, loss: 0.08922263979911804
step: 320, loss: 0.1252945512533188
step: 330, loss: 0.038641393184661865
epoch 15: dev_f1=0.828235294117647, f1=0.8141176470588235, best_f1=0.8045977011494253
step: 0, loss: 0.0947304517030716
step: 10, loss: 0.028959931805729866
step: 20, loss: 0.09323692321777344
step: 30, loss: 0.1262100636959076
step: 40, loss: 0.04445923492312431
step: 50, loss: 0.09984788298606873
step: 60, loss: 0.09183542430400848
step: 70, loss: 0.10482990741729736
step: 80, loss: 0.018525149673223495
step: 90, loss: 0.045145466923713684
step: 100, loss: 0.015740884467959404
step: 110, loss: 0.05530325323343277
step: 120, loss: 0.06128339469432831
step: 130, loss: 0.38982316851615906
step: 140, loss: 0.01529933512210846
step: 150, loss: 0.0585751011967659
step: 160, loss: 0.11956412345170975
step: 170, loss: 0.10645030438899994
step: 180, loss: 0.04738049954175949
step: 190, loss: 0.05040743201971054
step: 200, loss: 0.038724612444639206
step: 210, loss: 0.07316718250513077
step: 220, loss: 0.10891509056091309
step: 230, loss: 0.06666255742311478
step: 240, loss: 0.07292108982801437
step: 250, loss: 0.0011178168933838606
step: 260, loss: 0.13747277855873108
step: 270, loss: 0.11684911698102951
step: 280, loss: 0.12542881071567535
step: 290, loss: 0.15450747311115265
step: 300, loss: 0.07955735921859741
step: 310, loss: 0.037794314324855804
step: 320, loss: 0.09000395983457565
step: 330, loss: 0.10850072652101517
epoch 16: dev_f1=0.8436724565756824, f1=0.8246913580246913, best_f1=0.8045977011494253
step: 0, loss: 0.08901466429233551
step: 10, loss: 0.13913965225219727
step: 20, loss: 0.04844805225729942
step: 30, loss: 0.06539406627416611
step: 40, loss: 0.038097165524959564
step: 50, loss: 0.051429618149995804
step: 60, loss: 0.06283604353666306
step: 70, loss: 0.11956468969583511
step: 80, loss: 0.038642287254333496
step: 90, loss: 0.000888204900547862
step: 100, loss: 0.07168689370155334
step: 110, loss: 0.044629137963056564
step: 120, loss: 0.09514961391687393
step: 130, loss: 0.0384998619556427
step: 140, loss: 0.01594155840575695
step: 150, loss: 0.07867629081010818
step: 160, loss: 0.030215468257665634
step: 170, loss: 0.023591872304677963
step: 180, loss: 0.10284538567066193
step: 190, loss: 0.021521955728530884
step: 200, loss: 0.011904883198440075
step: 210, loss: 0.06516395509243011
step: 220, loss: 0.08253420889377594
step: 230, loss: 0.07592375576496124
step: 240, loss: 0.09471957385540009
step: 250, loss: 0.08969221264123917
step: 260, loss: 0.07002900540828705
step: 270, loss: 0.04855620115995407
step: 280, loss: 0.029370984062552452
step: 290, loss: 0.04759051650762558
step: 300, loss: 0.08658258616924286
step: 310, loss: 0.049905452877283096
step: 320, loss: 0.07601809501647949
step: 330, loss: 0.11559931188821793
epoch 17: dev_f1=0.8352668213457077, f1=0.8167053364269141, best_f1=0.8045977011494253
step: 0, loss: 0.11831848323345184
step: 10, loss: 0.06440871208906174
step: 20, loss: 0.10397670418024063
step: 30, loss: 0.09959231317043304
step: 40, loss: 0.06432098895311356
step: 50, loss: 0.053419627249240875
step: 60, loss: 2.1051271687611006e-05
step: 70, loss: 0.07931879907846451
step: 80, loss: 0.09815781563520432
step: 90, loss: 0.07971633970737457
step: 100, loss: 0.09113294631242752
step: 110, loss: 0.027877844870090485
step: 120, loss: 0.15203100442886353
step: 130, loss: 0.05885991081595421
step: 140, loss: 0.0830138772726059
step: 150, loss: 0.023753013461828232
step: 160, loss: 0.02525908686220646
step: 170, loss: 0.11933460086584091
step: 180, loss: 0.07448466122150421
step: 190, loss: 2.1364159692893736e-05
step: 200, loss: 0.044564392417669296
step: 210, loss: 0.0514850839972496
step: 220, loss: 0.12005888670682907
step: 230, loss: 0.021418876945972443
step: 240, loss: 0.15539419651031494
step: 250, loss: 0.01733684167265892
step: 260, loss: 0.0314202718436718
step: 270, loss: 0.10280190408229828
step: 280, loss: 0.15060308575630188
step: 290, loss: 0.054688386619091034
step: 300, loss: 0.048967428505420685
step: 310, loss: 0.0990547314286232
step: 320, loss: 0.07118867337703705
step: 330, loss: 0.03698858618736267
epoch 18: dev_f1=0.8226950354609929, f1=0.8177570093457943, best_f1=0.8045977011494253
step: 0, loss: 0.04778967425227165
step: 10, loss: 0.019488636404275894
step: 20, loss: 0.024764735251665115
step: 30, loss: 0.004980677273124456
step: 40, loss: 0.11061611026525497
step: 50, loss: 0.11700466275215149
step: 60, loss: 2.05744436243549e-05
step: 70, loss: 0.06109729781746864
step: 80, loss: 0.07201516628265381
step: 90, loss: 0.07046037912368774
step: 100, loss: 0.05903102084994316
step: 110, loss: 0.087677963078022
step: 120, loss: 0.026734299957752228
step: 130, loss: 1.922971750900615e-05
step: 140, loss: 0.16481341421604156
step: 150, loss: 0.040489863604307175
step: 160, loss: 0.09547039866447449
step: 170, loss: 0.08875978738069534
step: 180, loss: 0.059817422181367874
step: 190, loss: 0.06537886708974838
step: 200, loss: 0.06590117514133453
step: 210, loss: 0.03539947047829628
step: 220, loss: 0.09013050049543381
step: 230, loss: 0.03890374302864075
step: 240, loss: 0.14260554313659668
step: 250, loss: 0.019841168075799942
step: 260, loss: 0.07184884697198868
step: 270, loss: 0.1120048463344574
step: 280, loss: 0.029692267999053
step: 290, loss: 0.023589937016367912
step: 300, loss: 0.04000917077064514
step: 310, loss: 0.030367836356163025
step: 320, loss: 0.03981240838766098
step: 330, loss: 3.0407387384912e-05
epoch 19: dev_f1=0.8087167070217919, f1=0.8096385542168675, best_f1=0.8045977011494253
step: 0, loss: 0.015099468640983105
step: 10, loss: 0.031297728419303894
step: 20, loss: 0.11371583491563797
step: 30, loss: 0.035075683146715164
step: 40, loss: 0.09979046881198883
step: 50, loss: 0.03762268275022507
step: 60, loss: 0.10228483378887177
step: 70, loss: 0.08122441917657852
step: 80, loss: 0.03445952758193016
step: 90, loss: 0.03321365639567375
step: 100, loss: 0.020585570484399796
step: 110, loss: 0.03716214746236801
step: 120, loss: 0.07933515310287476
step: 130, loss: 0.03746805340051651
step: 140, loss: 0.04192037135362625
step: 150, loss: 0.08572404086589813
step: 160, loss: 0.044286079704761505
step: 170, loss: 0.09687471389770508
step: 180, loss: 0.04489070177078247
step: 190, loss: 0.022699816152453423
step: 200, loss: 0.11043079942464828
step: 210, loss: 0.045522529631853104
step: 220, loss: 0.11183275282382965
step: 230, loss: 0.017469018697738647
step: 240, loss: 0.10750890523195267
step: 250, loss: 0.07653412967920303
step: 260, loss: 0.01908233016729355
step: 270, loss: 0.16796138882637024
step: 280, loss: 0.05024004727602005
step: 290, loss: 0.09906502068042755
step: 300, loss: 0.0783625915646553
step: 310, loss: 0.028986524790525436
step: 320, loss: 0.043914295732975006
step: 330, loss: 0.03608899563550949
epoch 20: dev_f1=0.8040201005025125, f1=0.8059701492537313, best_f1=0.8045977011494253
