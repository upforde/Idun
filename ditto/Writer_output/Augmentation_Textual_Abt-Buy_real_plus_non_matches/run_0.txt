cuda
Device: cuda
step: 0, loss: 0.5096718668937683
step: 10, loss: 0.153065487742424
step: 20, loss: 0.03372026979923248
step: 30, loss: 0.24697968363761902
step: 40, loss: 0.22441935539245605
step: 50, loss: 0.32941433787345886
step: 60, loss: 0.22842766344547272
step: 70, loss: 0.25117960572242737
step: 80, loss: 0.31141921877861023
step: 90, loss: 0.2511517405509949
step: 100, loss: 0.3155510723590851
step: 110, loss: 0.1301143318414688
step: 120, loss: 0.12973274290561676
step: 130, loss: 0.22985272109508514
step: 140, loss: 0.1559610515832901
step: 150, loss: 0.23748797178268433
step: 160, loss: 0.16100455820560455
step: 170, loss: 0.44654005765914917
step: 180, loss: 0.20091818273067474
step: 190, loss: 0.03893878683447838
step: 200, loss: 0.2866356670856476
step: 210, loss: 0.058113571256399155
step: 220, loss: 0.05527399480342865
step: 230, loss: 0.2634320557117462
step: 240, loss: 0.16331329941749573
step: 250, loss: 0.11134953796863556
step: 260, loss: 0.1469595730304718
step: 270, loss: 0.33152976632118225
step: 280, loss: 0.16581875085830688
step: 290, loss: 0.12173423171043396
step: 300, loss: 0.21987619996070862
step: 310, loss: 0.15928049385547638
step: 320, loss: 0.0364309698343277
step: 330, loss: 0.15517793595790863
epoch 1: dev_f1=0.6697459584295612, f1=0.6830357142857144, best_f1=0.6830357142857144
step: 0, loss: 0.08251111954450607
step: 10, loss: 0.0999944880604744
step: 20, loss: 0.06656644493341446
step: 30, loss: 0.11783417314291
step: 40, loss: 0.06280650198459625
step: 50, loss: 0.0871443897485733
step: 60, loss: 0.3984745442867279
step: 70, loss: 0.23670594394207
step: 80, loss: 0.1179034411907196
step: 90, loss: 0.13247790932655334
step: 100, loss: 0.16056811809539795
step: 110, loss: 0.08519086241722107
step: 120, loss: 0.16603006422519684
step: 130, loss: 0.05155772715806961
step: 140, loss: 0.18555888533592224
step: 150, loss: 0.03657368943095207
step: 160, loss: 0.14510059356689453
step: 170, loss: 0.15824788808822632
step: 180, loss: 0.11804792284965515
step: 190, loss: 0.10816874355077744
step: 200, loss: 0.13239628076553345
step: 210, loss: 0.043301839381456375
step: 220, loss: 0.08100283890962601
step: 230, loss: 0.168148472905159
step: 240, loss: 0.12311593443155289
step: 250, loss: 0.10419908910989761
step: 260, loss: 0.17321720719337463
step: 270, loss: 0.056663624942302704
step: 280, loss: 0.06197425723075867
step: 290, loss: 0.031819574534893036
step: 300, loss: 0.05214998126029968
step: 310, loss: 0.09989725053310394
step: 320, loss: 0.05097753554582596
step: 330, loss: 0.08202166855335236
epoch 2: dev_f1=0.7587719298245613, f1=0.7441860465116279, best_f1=0.7441860465116279
step: 0, loss: 0.06768274307250977
step: 10, loss: 0.18910852074623108
step: 20, loss: 0.06534990668296814
step: 30, loss: 0.05629676952958107
step: 40, loss: 0.13145439326763153
step: 50, loss: 0.112904854118824
step: 60, loss: 0.058362822979688644
step: 70, loss: 0.18028727173805237
step: 80, loss: 0.2033158391714096
step: 90, loss: 0.22783857583999634
step: 100, loss: 0.025321675464510918
step: 110, loss: 0.10708574205636978
step: 120, loss: 0.12617607414722443
step: 130, loss: 0.04154388979077339
step: 140, loss: 0.15593162178993225
step: 150, loss: 0.05863439664244652
step: 160, loss: 0.20032967627048492
step: 170, loss: 0.026277514174580574
step: 180, loss: 0.04510563984513283
step: 190, loss: 0.2856345772743225
step: 200, loss: 0.12367916107177734
step: 210, loss: 0.10441030561923981
step: 220, loss: 0.15995967388153076
step: 230, loss: 0.13073967397212982
step: 240, loss: 0.27167999744415283
step: 250, loss: 0.06681770831346512
step: 260, loss: 0.012898135930299759
step: 270, loss: 0.13285118341445923
step: 280, loss: 0.08217458426952362
step: 290, loss: 0.14899146556854248
step: 300, loss: 0.08334498107433319
step: 310, loss: 0.23692315816879272
step: 320, loss: 0.06053376942873001
step: 330, loss: 0.05449344962835312
epoch 3: dev_f1=0.7558386411889596, f1=0.7426160337552743, best_f1=0.7441860465116279
step: 0, loss: 0.08436082303524017
step: 10, loss: 0.0871218591928482
step: 20, loss: 0.04352410137653351
step: 30, loss: 0.10391180217266083
step: 40, loss: 0.10276594758033752
step: 50, loss: 0.10250125825405121
step: 60, loss: 0.13687559962272644
step: 70, loss: 0.1156364306807518
step: 80, loss: 0.06906555593013763
step: 90, loss: 0.0918978676199913
step: 100, loss: 0.07579636573791504
step: 110, loss: 0.12307379394769669
step: 120, loss: 0.15576346218585968
step: 130, loss: 0.06464958190917969
step: 140, loss: 0.11548042297363281
step: 150, loss: 0.08816169947385788
step: 160, loss: 0.08154289424419403
step: 170, loss: 0.08655018359422684
step: 180, loss: 0.18865258991718292
step: 190, loss: 0.37886685132980347
step: 200, loss: 0.044521983712911606
step: 210, loss: 0.05971989780664444
step: 220, loss: 0.0675470307469368
step: 230, loss: 0.1040872260928154
step: 240, loss: 0.049610789865255356
step: 250, loss: 0.029029589146375656
step: 260, loss: 0.08241930603981018
step: 270, loss: 0.07538255304098129
step: 280, loss: 0.065093494951725
step: 290, loss: 0.06271453946828842
step: 300, loss: 0.1455300748348236
step: 310, loss: 0.11994044482707977
step: 320, loss: 0.06388114392757416
step: 330, loss: 0.04631645604968071
epoch 4: dev_f1=0.7982646420824294, f1=0.7852494577006509, best_f1=0.7852494577006509
step: 0, loss: 0.09739449620246887
step: 10, loss: 0.15271787345409393
step: 20, loss: 0.045344822108745575
step: 30, loss: 0.02253711223602295
step: 40, loss: 0.1826649159193039
step: 50, loss: 0.021883785724639893
step: 60, loss: 0.059525664895772934
step: 70, loss: 0.06492802500724792
step: 80, loss: 0.16642138361930847
step: 90, loss: 0.08928745985031128
step: 100, loss: 0.07825590670108795
step: 110, loss: 0.08675462752580643
step: 120, loss: 0.06443020701408386
step: 130, loss: 0.09231232106685638
step: 140, loss: 0.04490366205573082
step: 150, loss: 0.17033103108406067
step: 160, loss: 0.1288144439458847
step: 170, loss: 0.003436016384512186
step: 180, loss: 0.039615143090486526
step: 190, loss: 0.08707460761070251
step: 200, loss: 0.07451236993074417
step: 210, loss: 0.027141787111759186
step: 220, loss: 0.1253192275762558
step: 230, loss: 0.063730388879776
step: 240, loss: 0.10202030092477798
step: 250, loss: 0.1458665281534195
step: 260, loss: 0.1428583711385727
step: 270, loss: 0.10681328922510147
step: 280, loss: 0.1730375736951828
step: 290, loss: 0.09655007719993591
step: 300, loss: 0.08772499859333038
step: 310, loss: 0.09617266803979874
step: 320, loss: 0.09875708073377609
step: 330, loss: 0.14712190628051758
epoch 5: dev_f1=0.7890818858560793, f1=0.8028846153846153, best_f1=0.7852494577006509
step: 0, loss: 0.03623943403363228
step: 10, loss: 0.11557525396347046
step: 20, loss: 0.09073388576507568
step: 30, loss: 0.045590467751026154
step: 40, loss: 0.14643079042434692
step: 50, loss: 0.1628817319869995
step: 60, loss: 0.2421930879354477
step: 70, loss: 0.08185514807701111
step: 80, loss: 0.06830967962741852
step: 90, loss: 0.023281367495656013
step: 100, loss: 0.1156042218208313
step: 110, loss: 0.03934652358293533
step: 120, loss: 0.04569119215011597
step: 130, loss: 0.09811341762542725
step: 140, loss: 0.06390918791294098
step: 150, loss: 0.06627344340085983
step: 160, loss: 0.05127434805035591
step: 170, loss: 0.05126643925905228
step: 180, loss: 0.055608320981264114
step: 190, loss: 0.08743394911289215
step: 200, loss: 0.12963268160820007
step: 210, loss: 0.045788079500198364
step: 220, loss: 0.39437538385391235
step: 230, loss: 0.07915928959846497
step: 240, loss: 0.13215197622776031
step: 250, loss: 0.06626129895448685
step: 260, loss: 0.09288642555475235
step: 270, loss: 0.07073845714330673
step: 280, loss: 0.0695107951760292
step: 290, loss: 0.08621498197317123
step: 300, loss: 0.08584921061992645
step: 310, loss: 0.10638157278299332
step: 320, loss: 0.05341974273324013
step: 330, loss: 0.07329107820987701
epoch 6: dev_f1=0.8133971291866029, f1=0.8158508158508158, best_f1=0.8158508158508158
step: 0, loss: 0.0653473511338234
step: 10, loss: 0.11035089939832687
step: 20, loss: 0.12037649005651474
step: 30, loss: 0.14276611804962158
step: 40, loss: 0.1868908703327179
step: 50, loss: 0.036551639437675476
step: 60, loss: 0.032925933599472046
step: 70, loss: 0.11212711036205292
step: 80, loss: 0.0791969820857048
step: 90, loss: 0.04595009237527847
step: 100, loss: 0.05077053979039192
step: 110, loss: 0.10004354268312454
step: 120, loss: 0.09741492569446564
step: 130, loss: 0.1331615000963211
step: 140, loss: 0.05356381833553314
step: 150, loss: 0.09714473783969879
step: 160, loss: 0.02092497982084751
step: 170, loss: 0.08137337863445282
step: 180, loss: 0.20164571702480316
step: 190, loss: 0.04224255681037903
step: 200, loss: 0.06600978225469589
step: 210, loss: 0.10757088661193848
step: 220, loss: 0.09481510519981384
step: 230, loss: 0.08912274986505508
step: 240, loss: 0.05432712659239769
step: 250, loss: 0.07662838697433472
step: 260, loss: 0.08153164386749268
step: 270, loss: 0.041244231164455414
step: 280, loss: 0.06785362958908081
step: 290, loss: 0.08614616096019745
step: 300, loss: 0.11323916167020798
step: 310, loss: 0.19902175664901733
step: 320, loss: 0.17169071733951569
step: 330, loss: 0.057038430124521255
epoch 7: dev_f1=0.8188235294117647, f1=0.8028169014084506, best_f1=0.8028169014084506
step: 0, loss: 0.04440651088953018
step: 10, loss: 0.12806081771850586
step: 20, loss: 0.07701622694730759
step: 30, loss: 0.06886551529169083
step: 40, loss: 0.1205725371837616
step: 50, loss: 0.00016318158304784447
step: 60, loss: 0.12155774980783463
step: 70, loss: 0.047001443803310394
step: 80, loss: 0.045863330364227295
step: 90, loss: 0.1083957627415657
step: 100, loss: 0.41069385409355164
step: 110, loss: 0.08328841626644135
step: 120, loss: 0.08366687595844269
step: 130, loss: 0.1125977411866188
step: 140, loss: 0.13591231405735016
step: 150, loss: 0.09027926623821259
step: 160, loss: 0.02581927366554737
step: 170, loss: 0.07641258835792542
step: 180, loss: 0.09432034194469452
step: 190, loss: 0.11416961252689362
step: 200, loss: 0.03828110173344612
step: 210, loss: 0.09280680865049362
step: 220, loss: 0.1361916959285736
step: 230, loss: 0.07689441740512848
step: 240, loss: 0.07030463218688965
step: 250, loss: 0.04927477613091469
step: 260, loss: 0.10083768516778946
step: 270, loss: 0.11994879692792892
step: 280, loss: 0.16141130030155182
step: 290, loss: 0.12828819453716278
step: 300, loss: 0.055445555597543716
step: 310, loss: 0.155395045876503
step: 320, loss: 0.07127389311790466
step: 330, loss: 0.05991721153259277
epoch 8: dev_f1=0.7919463087248323, f1=0.7761194029850746, best_f1=0.8028169014084506
step: 0, loss: 0.0710245743393898
step: 10, loss: 0.074516661465168
step: 20, loss: 0.07411132007837296
step: 30, loss: 0.08911129832267761
step: 40, loss: 0.14401522278785706
step: 50, loss: 0.08976591378450394
step: 60, loss: 0.14736926555633545
step: 70, loss: 0.08256157487630844
step: 80, loss: 0.08817360550165176
step: 90, loss: 0.09132009744644165
step: 100, loss: 0.0641263872385025
step: 110, loss: 0.04398365691304207
step: 120, loss: 0.13595695793628693
step: 130, loss: 0.06948641687631607
step: 140, loss: 0.08018160611391068
step: 150, loss: 0.12476037442684174
step: 160, loss: 0.09198760986328125
step: 170, loss: 0.11825374513864517
step: 180, loss: 0.0517621710896492
step: 190, loss: 0.14556506276130676
step: 200, loss: 0.11776414513587952
step: 210, loss: 0.056198086589574814
step: 220, loss: 0.13191662728786469
step: 230, loss: 0.12282491475343704
step: 240, loss: 0.06856442987918854
step: 250, loss: 0.09674031287431717
step: 260, loss: 0.08012595772743225
step: 270, loss: 0.0869273841381073
step: 280, loss: 0.0942179411649704
step: 290, loss: 0.06462576985359192
step: 300, loss: 0.10948003828525543
step: 310, loss: 0.08768606930971146
step: 320, loss: 0.024227574467658997
step: 330, loss: 0.08462731540203094
epoch 9: dev_f1=0.8009153318077803, f1=0.7982062780269058, best_f1=0.8028169014084506
step: 0, loss: 0.1215054988861084
step: 10, loss: 0.12143506109714508
step: 20, loss: 5.015538408770226e-05
step: 30, loss: 0.023673195391893387
step: 40, loss: 0.06739214807748795
step: 50, loss: 0.05861571803689003
step: 60, loss: 0.08919966220855713
step: 70, loss: 0.11580921709537506
step: 80, loss: 0.11223677545785904
step: 90, loss: 0.023810772225260735
step: 100, loss: 0.09141775220632553
step: 110, loss: 0.05213175714015961
step: 120, loss: 0.10830710828304291
step: 130, loss: 0.1127181351184845
step: 140, loss: 0.07860720902681351
step: 150, loss: 0.14953985810279846
step: 160, loss: 0.20100200176239014
step: 170, loss: 0.1032232865691185
step: 180, loss: 0.09275002777576447
step: 190, loss: 0.09900199621915817
step: 200, loss: 0.11963391304016113
step: 210, loss: 0.11280257999897003
step: 220, loss: 0.07512496411800385
step: 230, loss: 0.00023561443958897144
step: 240, loss: 0.10902753472328186
step: 250, loss: 0.07030541449785233
step: 260, loss: 0.09576067328453064
step: 270, loss: 0.08369635790586472
step: 280, loss: 0.09756837040185928
step: 290, loss: 0.09959860146045685
step: 300, loss: 0.04512423276901245
step: 310, loss: 0.06999394297599792
step: 320, loss: 0.07909496873617172
step: 330, loss: 0.059964586049318314
epoch 10: dev_f1=0.8111888111888111, f1=0.8066037735849056, best_f1=0.8028169014084506
step: 0, loss: 0.10129067301750183
step: 10, loss: 0.03808833286166191
step: 20, loss: 0.08787928521633148
step: 30, loss: 0.054677434265613556
step: 40, loss: 0.11119086295366287
step: 50, loss: 0.07069029659032822
step: 60, loss: 0.041551388800144196
step: 70, loss: 0.11898757517337799
step: 80, loss: 0.09642776846885681
step: 90, loss: 0.12828712165355682
step: 100, loss: 0.054895609617233276
step: 110, loss: 0.07467560470104218
step: 120, loss: 0.0678764060139656
step: 130, loss: 0.07311298698186874
step: 140, loss: 0.08927793055772781
step: 150, loss: 0.06979840248823166
step: 160, loss: 0.058070406317710876
step: 170, loss: 0.08624009788036346
step: 180, loss: 0.07407236844301224
step: 190, loss: 0.04592202231287956
step: 200, loss: 0.13908863067626953
step: 210, loss: 0.1387387365102768
step: 220, loss: 0.13007329404354095
step: 230, loss: 0.13372425734996796
step: 240, loss: 0.10746204853057861
step: 250, loss: 0.08500415831804276
step: 260, loss: 0.11784423887729645
step: 270, loss: 0.07543660700321198
step: 280, loss: 0.10699551552534103
step: 290, loss: 0.1316692978143692
step: 300, loss: 0.055824581533670425
step: 310, loss: 0.04559479281306267
step: 320, loss: 0.0655931681394577
step: 330, loss: 0.07188106328248978
epoch 11: dev_f1=0.8251121076233184, f1=0.8097345132743362, best_f1=0.8097345132743362
step: 0, loss: 0.07986827194690704
step: 10, loss: 0.08250615745782852
step: 20, loss: 0.04378563165664673
step: 30, loss: 0.15803954005241394
step: 40, loss: 0.03469434380531311
step: 50, loss: 0.08882183581590652
step: 60, loss: 0.04127458855509758
step: 70, loss: 0.1126541942358017
step: 80, loss: 0.0415579192340374
step: 90, loss: 0.09413889795541763
step: 100, loss: 0.03527367487549782
step: 110, loss: 0.09662417322397232
step: 120, loss: 0.09565728157758713
step: 130, loss: 0.04537975788116455
step: 140, loss: 0.08299335092306137
step: 150, loss: 0.03453890234231949
step: 160, loss: 0.06198883429169655
step: 170, loss: 0.12797081470489502
step: 180, loss: 0.03408375754952431
step: 190, loss: 0.14000950753688812
step: 200, loss: 0.10976111143827438
step: 210, loss: 0.10270734131336212
step: 220, loss: 0.09475162625312805
step: 230, loss: 0.2152039110660553
step: 240, loss: 0.11228546500205994
step: 250, loss: 0.19669109582901
step: 260, loss: 0.076886847615242
step: 270, loss: 0.0827823281288147
step: 280, loss: 0.08479239046573639
step: 290, loss: 0.0020758137106895447
step: 300, loss: 0.09672153741121292
step: 310, loss: 0.1764204502105713
step: 320, loss: 0.10501334071159363
step: 330, loss: 0.10179899632930756
epoch 12: dev_f1=0.8078817733990147, f1=0.8106796116504854, best_f1=0.8097345132743362
step: 0, loss: 0.08523276448249817
step: 10, loss: 0.11070824414491653
step: 20, loss: 0.011320810765028
step: 30, loss: 0.06173888221383095
step: 40, loss: 0.08382592350244522
step: 50, loss: 0.12453297525644302
step: 60, loss: 0.055176738649606705
step: 70, loss: 0.12474779039621353
step: 80, loss: 0.09435544162988663
step: 90, loss: 0.1012677252292633
step: 100, loss: 0.03520029038190842
step: 110, loss: 0.06401800364255905
step: 120, loss: 0.10449010133743286
step: 130, loss: 0.04947797581553459
step: 140, loss: 0.08800815045833588
step: 150, loss: 0.07475915551185608
step: 160, loss: 0.10979536175727844
step: 170, loss: 0.0792747288942337
step: 180, loss: 0.12461399286985397
step: 190, loss: 0.09217686951160431
step: 200, loss: 0.014505311846733093
step: 210, loss: 0.09023270756006241
step: 220, loss: 0.12270062416791916
step: 230, loss: 0.22208000719547272
step: 240, loss: 0.12882596254348755
step: 250, loss: 0.11306770890951157
step: 260, loss: 0.0696890577673912
step: 270, loss: 0.11053118854761124
step: 280, loss: 0.11664076149463654
step: 290, loss: 0.12310412526130676
step: 300, loss: 0.025532783940434456
step: 310, loss: 0.07891789823770523
step: 320, loss: 0.10929543524980545
step: 330, loss: 0.15983884036540985
epoch 13: dev_f1=0.819672131147541, f1=0.7981438515081206, best_f1=0.8097345132743362
step: 0, loss: 0.07705709338188171
step: 10, loss: 0.06805959343910217
step: 20, loss: 0.1251516193151474
step: 30, loss: 0.13397946953773499
step: 40, loss: 0.07846957445144653
step: 50, loss: 0.1224406361579895
step: 60, loss: 0.08915336430072784
step: 70, loss: 0.12766802310943604
step: 80, loss: 0.03997664526104927
step: 90, loss: 0.10220165550708771
step: 100, loss: 0.06360944360494614
step: 110, loss: 0.03808122128248215
step: 120, loss: 0.16417114436626434
step: 130, loss: 0.09007841348648071
step: 140, loss: 0.0758826807141304
step: 150, loss: 0.07343576103448868
step: 160, loss: 0.12363916635513306
step: 170, loss: 0.10502639412879944
step: 180, loss: 0.10917136818170547
step: 190, loss: 0.18256047368049622
step: 200, loss: 0.06774978339672089
step: 210, loss: 0.05462147668004036
step: 220, loss: 2.3502538169850595e-05
step: 230, loss: 0.10418207943439484
step: 240, loss: 0.038510214537382126
step: 250, loss: 0.11227113008499146
step: 260, loss: 0.09849122166633606
step: 270, loss: 0.11537665128707886
step: 280, loss: 0.11485403031110764
step: 290, loss: 0.14918720722198486
step: 300, loss: 0.06663507223129272
step: 310, loss: 0.11529850959777832
step: 320, loss: 0.14229364693164825
step: 330, loss: 0.058768097311258316
epoch 14: dev_f1=0.8213457076566126, f1=0.8083140877598153, best_f1=0.8097345132743362
step: 0, loss: 0.11883784830570221
step: 10, loss: 0.04281517118215561
step: 20, loss: 0.12084385752677917
step: 30, loss: 0.04927351698279381
step: 40, loss: 0.10385633260011673
step: 50, loss: 0.08904573321342468
step: 60, loss: 0.05199645087122917
step: 70, loss: 0.077204629778862
step: 80, loss: 0.19377969205379486
step: 90, loss: 0.06588643789291382
step: 100, loss: 0.11185745894908905
step: 110, loss: 0.10600060969591141
step: 120, loss: 0.10617849975824356
step: 130, loss: 0.07277850061655045
step: 140, loss: 0.039918385446071625
step: 150, loss: 0.09721599519252777
step: 160, loss: 0.11591851711273193
step: 170, loss: 0.09236539155244827
step: 180, loss: 0.017221208661794662
step: 190, loss: 0.1514122039079666
step: 200, loss: 0.16282179951667786
step: 210, loss: 0.041749149560928345
step: 220, loss: 0.012148798443377018
step: 230, loss: 0.05611259862780571
step: 240, loss: 0.10434209555387497
step: 250, loss: 0.06704264879226685
step: 260, loss: 0.07892578095197678
step: 270, loss: 0.052660562098026276
step: 280, loss: 0.08597736060619354
step: 290, loss: 0.07730314135551453
step: 300, loss: 0.051398761570453644
step: 310, loss: 0.18245108425617218
step: 320, loss: 0.10490916669368744
step: 330, loss: 0.09518080204725266
epoch 15: dev_f1=0.8156682027649769, f1=0.8090909090909091, best_f1=0.8097345132743362
step: 0, loss: 0.10477826744318008
step: 10, loss: 0.04845590516924858
step: 20, loss: 0.12603384256362915
step: 30, loss: 0.08805820345878601
step: 40, loss: 0.04248746857047081
step: 50, loss: 0.012753386050462723
step: 60, loss: 0.040379445999860764
step: 70, loss: 0.050492193549871445
step: 80, loss: 0.1116228774189949
step: 90, loss: 0.07017767429351807
step: 100, loss: 0.03741482272744179
step: 110, loss: 0.1190282478928566
step: 120, loss: 0.12681473791599274
step: 130, loss: 0.05583237111568451
step: 140, loss: 0.09958891570568085
step: 150, loss: 0.031143855303525925
step: 160, loss: 0.04183700308203697
step: 170, loss: 0.1277134269475937
step: 180, loss: 0.10404445976018906
step: 190, loss: 0.06480666249990463
step: 200, loss: 0.12258809804916382
step: 210, loss: 0.07501985877752304
step: 220, loss: 0.11943842470645905
step: 230, loss: 0.0778203010559082
step: 240, loss: 0.08098625391721725
step: 250, loss: 0.040684107691049576
step: 260, loss: 0.10346145182847977
step: 270, loss: 0.04217878356575966
step: 280, loss: 0.06175501272082329
step: 290, loss: 0.06077267974615097
step: 300, loss: 0.09999890625476837
step: 310, loss: 0.03408607840538025
step: 320, loss: 0.047325946390628815
step: 330, loss: 0.08057926595211029
epoch 16: dev_f1=0.8154897494305238, f1=0.8018018018018017, best_f1=0.8097345132743362
step: 0, loss: 0.06675849854946136
step: 10, loss: 0.13746018707752228
step: 20, loss: 0.039929669350385666
step: 30, loss: 0.039817262440919876
step: 40, loss: 0.06110336259007454
step: 50, loss: 0.0768466368317604
step: 60, loss: 0.14538006484508514
step: 70, loss: 0.05127082020044327
step: 80, loss: 0.03086150996387005
step: 90, loss: 0.05140967294573784
step: 100, loss: 0.06050010398030281
step: 110, loss: 0.014744765125215054
step: 120, loss: 0.031557802110910416
step: 130, loss: 0.10062291473150253
step: 140, loss: 0.089103564620018
step: 150, loss: 0.010469778440892696
step: 160, loss: 0.07915013283491135
step: 170, loss: 0.02291623316705227
step: 180, loss: 0.09554644674062729
step: 190, loss: 0.06620516628026962
step: 200, loss: 0.16334250569343567
step: 210, loss: 0.06088707968592644
step: 220, loss: 0.05026835575699806
step: 230, loss: 0.06936871260404587
step: 240, loss: 0.07301753759384155
step: 250, loss: 0.03172791376709938
step: 260, loss: 0.05533678084611893
step: 270, loss: 0.06526567786931992
step: 280, loss: 0.054926104843616486
step: 290, loss: 0.02296253852546215
step: 300, loss: 0.1309589147567749
step: 310, loss: 0.05458952113986015
step: 320, loss: 0.040232300758361816
step: 330, loss: 0.12717534601688385
epoch 17: dev_f1=0.8142857142857144, f1=0.8094117647058824, best_f1=0.8097345132743362
step: 0, loss: 0.18107318878173828
step: 10, loss: 0.06734336912631989
step: 20, loss: 0.06462042033672333
step: 30, loss: 0.019145062193274498
step: 40, loss: 0.08913639187812805
step: 50, loss: 0.03418410196900368
step: 60, loss: 0.09137250483036041
step: 70, loss: 0.11766915023326874
step: 80, loss: 0.11661842465400696
step: 90, loss: 0.08998454362154007
step: 100, loss: 0.10655800998210907
step: 110, loss: 0.07583142817020416
step: 120, loss: 0.06928543746471405
step: 130, loss: 0.0831344798207283
step: 140, loss: 0.1615014672279358
step: 150, loss: 0.11274851858615875
step: 160, loss: 0.047752637416124344
step: 170, loss: 0.046412304043769836
step: 180, loss: 0.17672017216682434
step: 190, loss: 0.12562964856624603
step: 200, loss: 0.07796675711870193
step: 210, loss: 0.031892139464616776
step: 220, loss: 0.0669260025024414
step: 230, loss: 0.013894387520849705
step: 240, loss: 0.01258653961122036
step: 250, loss: 0.0719718262553215
step: 260, loss: 0.14397309720516205
step: 270, loss: 0.03931368887424469
step: 280, loss: 0.11244888603687286
step: 290, loss: 0.021251708269119263
step: 300, loss: 0.09544562548398972
step: 310, loss: 0.04092313349246979
step: 320, loss: 2.8557464247569442e-05
step: 330, loss: 0.11859080195426941
epoch 18: dev_f1=0.8171021377672211, f1=0.8076009501187648, best_f1=0.8097345132743362
step: 0, loss: 0.02237405627965927
step: 10, loss: 0.030421851202845573
step: 20, loss: 0.12036172300577164
step: 30, loss: 0.09530960023403168
step: 40, loss: 0.018208742141723633
step: 50, loss: 0.09149059653282166
step: 60, loss: 0.010772326029837132
step: 70, loss: 0.024977009743452072
step: 80, loss: 0.04609895125031471
step: 90, loss: 0.1569303572177887
step: 100, loss: 0.10152909904718399
step: 110, loss: 0.11751578003168106
step: 120, loss: 0.08499874174594879
step: 130, loss: 0.060445431619882584
step: 140, loss: 0.09500861167907715
step: 150, loss: 0.09167926758527756
step: 160, loss: 0.07701663672924042
step: 170, loss: 0.01674029603600502
step: 180, loss: 0.10424039512872696
step: 190, loss: 0.040160682052373886
step: 200, loss: 0.05650876834988594
step: 210, loss: 0.03656476363539696
step: 220, loss: 0.02630717307329178
step: 230, loss: 0.07822290062904358
step: 240, loss: 2.4549299268983305e-05
step: 250, loss: 0.06896490603685379
step: 260, loss: 0.02128468081355095
step: 270, loss: 0.10367501527070999
step: 280, loss: 0.013898788020014763
step: 290, loss: 0.11536873877048492
step: 300, loss: 0.06324367225170135
step: 310, loss: 0.09452298283576965
step: 320, loss: 0.012408641166985035
step: 330, loss: 0.05565126985311508
epoch 19: dev_f1=0.801909307875895, f1=0.7894736842105263, best_f1=0.8097345132743362
step: 0, loss: 0.026164544746279716
step: 10, loss: 0.22734996676445007
step: 20, loss: 0.048919275403022766
step: 30, loss: 0.014288773760199547
step: 40, loss: 0.06654366850852966
step: 50, loss: 0.10285768657922745
step: 60, loss: 0.019756818190217018
step: 70, loss: 0.09716372191905975
step: 80, loss: 0.06894891709089279
step: 90, loss: 0.0668335109949112
step: 100, loss: 0.11765319108963013
step: 110, loss: 0.05578497424721718
step: 120, loss: 0.04601651430130005
step: 130, loss: 0.11210225522518158
step: 140, loss: 0.015262837521731853
step: 150, loss: 0.05247076600790024
step: 160, loss: 0.03527049720287323
step: 170, loss: 0.041525933891534805
step: 180, loss: 0.04621605947613716
step: 190, loss: 0.04224219545722008
step: 200, loss: 0.15104879438877106
step: 210, loss: 0.06937921047210693
step: 220, loss: 0.031154785305261612
step: 230, loss: 0.0704558715224266
step: 240, loss: 0.051129795610904694
step: 250, loss: 0.048697322607040405
step: 260, loss: 0.07377118617296219
step: 270, loss: 0.1553289294242859
step: 280, loss: 0.03306831419467926
step: 290, loss: 0.04493104666471481
step: 300, loss: 0.10281931608915329
step: 310, loss: 0.08154777437448502
step: 320, loss: 0.042623456567525864
step: 330, loss: 0.059287697076797485
epoch 20: dev_f1=0.8, f1=0.79136690647482, best_f1=0.8097345132743362
