cuda
Device: cuda
step: 0, loss: 0.8394134640693665
step: 10, loss: 0.2610377073287964
step: 20, loss: 0.3119429051876068
step: 30, loss: 0.6035585403442383
step: 40, loss: 0.3082674443721771
step: 50, loss: 0.23308338224887848
step: 60, loss: 0.24979262053966522
step: 70, loss: 0.496162086725235
step: 80, loss: 0.3662547469139099
step: 90, loss: 0.3035221993923187
step: 100, loss: 0.1837867796421051
step: 110, loss: 0.28463301062583923
step: 120, loss: 0.24305777251720428
step: 130, loss: 0.2749035358428955
step: 140, loss: 0.27483558654785156
step: 150, loss: 0.36441415548324585
step: 160, loss: 0.05080176517367363
step: 170, loss: 0.2638360559940338
step: 180, loss: 0.20006439089775085
step: 190, loss: 0.2984035909175873
step: 200, loss: 0.3729497492313385
step: 210, loss: 0.2956152558326721
step: 220, loss: 0.26068976521492004
step: 230, loss: 0.24278584122657776
step: 240, loss: 0.26533639430999756
step: 250, loss: 0.04213271662592888
step: 260, loss: 0.17463111877441406
step: 270, loss: 0.4357012212276459
step: 280, loss: 0.18202197551727295
step: 290, loss: 0.33570367097854614
step: 300, loss: 0.262813001871109
step: 310, loss: 0.23040497303009033
step: 320, loss: 0.49256089329719543
step: 330, loss: 0.17046818137168884
step: 340, loss: 0.2097904533147812
step: 350, loss: 0.17468851804733276
step: 360, loss: 0.10926000773906708
step: 370, loss: 0.2060791403055191
step: 380, loss: 0.3354359567165375
epoch 1: dev_f1=0.5766233766233766, f1=0.4524421593830334, best_f1=0.4524421593830334
step: 0, loss: 0.13183888792991638
step: 10, loss: 0.22947873175144196
step: 20, loss: 0.1650194525718689
step: 30, loss: 0.05071668326854706
step: 40, loss: 0.1764749139547348
step: 50, loss: 0.23976725339889526
step: 60, loss: 0.16560421884059906
step: 70, loss: 0.17233207821846008
step: 80, loss: 0.2284024953842163
step: 90, loss: 0.20650134980678558
step: 100, loss: 0.35718441009521484
step: 110, loss: 0.17812219262123108
step: 120, loss: 0.17036037147045135
step: 130, loss: 0.18272101879119873
step: 140, loss: 0.14350618422031403
step: 150, loss: 0.22215008735656738
step: 160, loss: 0.11416301131248474
step: 170, loss: 0.1072997897863388
step: 180, loss: 0.2362130731344223
step: 190, loss: 0.48618197441101074
step: 200, loss: 0.3302214443683624
step: 210, loss: 0.2394467145204544
step: 220, loss: 0.10333380848169327
step: 230, loss: 0.17551328241825104
step: 240, loss: 0.24053575098514557
step: 250, loss: 0.3279932737350464
step: 260, loss: 0.22203165292739868
step: 270, loss: 0.31661951541900635
step: 280, loss: 0.057402774691581726
step: 290, loss: 0.030204202979803085
step: 300, loss: 0.2068091630935669
step: 310, loss: 0.11841510236263275
step: 320, loss: 0.11226147413253784
step: 330, loss: 0.14632679522037506
step: 340, loss: 0.10010915994644165
step: 350, loss: 0.1506882756948471
step: 360, loss: 0.08868065476417542
step: 370, loss: 0.023062577471137047
step: 380, loss: 0.09302128106355667
epoch 2: dev_f1=0.7382198952879582, f1=0.6356164383561643, best_f1=0.6356164383561643
step: 0, loss: 0.12357895076274872
step: 10, loss: 0.128859743475914
step: 20, loss: 0.1803104281425476
step: 30, loss: 0.03579751029610634
step: 40, loss: 0.051025062799453735
step: 50, loss: 0.03111327812075615
step: 60, loss: 0.01665661856532097
step: 70, loss: 0.17859052121639252
step: 80, loss: 0.012000568211078644
step: 90, loss: 0.04161567986011505
step: 100, loss: 0.09475449472665787
step: 110, loss: 0.08658932894468307
step: 120, loss: 0.09985478222370148
step: 130, loss: 0.14453868567943573
step: 140, loss: 0.43824461102485657
step: 150, loss: 0.25087353587150574
step: 160, loss: 0.09129901975393295
step: 170, loss: 0.09077358990907669
step: 180, loss: 0.07187710702419281
step: 190, loss: 0.017681675031781197
step: 200, loss: 0.09385962039232254
step: 210, loss: 0.0467493012547493
step: 220, loss: 0.043858546763658524
step: 230, loss: 0.037097904831171036
step: 240, loss: 0.21424777805805206
step: 250, loss: 0.0645587295293808
step: 260, loss: 0.08953162282705307
step: 270, loss: 0.12889324128627777
step: 280, loss: 0.04661572724580765
step: 290, loss: 0.07853017002344131
step: 300, loss: 0.16472160816192627
step: 310, loss: 0.08468006551265717
step: 320, loss: 0.18355707824230194
step: 330, loss: 0.17561691999435425
step: 340, loss: 0.2919504642486572
step: 350, loss: 0.05100115016102791
step: 360, loss: 0.13591884076595306
step: 370, loss: 0.013902727514505386
step: 380, loss: 0.3322566747665405
epoch 3: dev_f1=0.7473684210526317, f1=0.6094182825484764, best_f1=0.6094182825484764
step: 0, loss: 0.06553105264902115
step: 10, loss: 0.02095801755785942
step: 20, loss: 0.1756342053413391
step: 30, loss: 0.17659549415111542
step: 40, loss: 0.04572189971804619
step: 50, loss: 0.09757009893655777
step: 60, loss: 0.11652761697769165
step: 70, loss: 0.006435427814722061
step: 80, loss: 0.04711142182350159
step: 90, loss: 0.018824294209480286
step: 100, loss: 0.09831942617893219
step: 110, loss: 0.4609767496585846
step: 120, loss: 0.140412837266922
step: 130, loss: 0.0035605807788670063
step: 140, loss: 0.01691420190036297
step: 150, loss: 0.030698996037244797
step: 160, loss: 0.16957657039165497
step: 170, loss: 0.1533225029706955
step: 180, loss: 0.045619428157806396
step: 190, loss: 0.040536027401685715
step: 200, loss: 0.05817650258541107
step: 210, loss: 0.11012192070484161
step: 220, loss: 0.09542897343635559
step: 230, loss: 0.01153955701738596
step: 240, loss: 0.03268028050661087
step: 250, loss: 0.04509635642170906
step: 260, loss: 0.021106932312250137
step: 270, loss: 0.055836960673332214
step: 280, loss: 0.10242865979671478
step: 290, loss: 0.12851832807064056
step: 300, loss: 0.21899564564228058
step: 310, loss: 0.005247277207672596
step: 320, loss: 0.023209260776638985
step: 330, loss: 0.048228491097688675
step: 340, loss: 0.05776234716176987
step: 350, loss: 0.021814590319991112
step: 360, loss: 0.04986840859055519
step: 370, loss: 0.03231995552778244
step: 380, loss: 0.13202817738056183
epoch 4: dev_f1=0.76, f1=0.5813953488372093, best_f1=0.5813953488372093
step: 0, loss: 0.11925376951694489
step: 10, loss: 0.008432525210082531
step: 20, loss: 0.008599845692515373
step: 30, loss: 0.004344375804066658
step: 40, loss: 0.02423500083386898
step: 50, loss: 0.0076917242258787155
step: 60, loss: 0.0702144205570221
step: 70, loss: 0.003777996636927128
step: 80, loss: 0.013968540355563164
step: 90, loss: 0.010472935624420643
step: 100, loss: 0.014523369260132313
step: 110, loss: 0.002400519559159875
step: 120, loss: 0.04490865021944046
step: 130, loss: 0.01475310605019331
step: 140, loss: 0.08637604862451553
step: 150, loss: 0.05572905018925667
step: 160, loss: 0.009610130451619625
step: 170, loss: 0.014986744150519371
step: 180, loss: 0.21796534955501556
step: 190, loss: 0.036605846136808395
step: 200, loss: 0.01538942288607359
step: 210, loss: 0.072371706366539
step: 220, loss: 0.027054473757743835
step: 230, loss: 0.062319278717041016
step: 240, loss: 0.03702563792467117
step: 250, loss: 0.014488034881651402
step: 260, loss: 0.020222699269652367
step: 270, loss: 0.14757350087165833
step: 280, loss: 0.07693368196487427
step: 290, loss: 0.010728457011282444
step: 300, loss: 0.009586547501385212
step: 310, loss: 0.03746947646141052
step: 320, loss: 0.07630196213722229
step: 330, loss: 0.017885107547044754
step: 340, loss: 0.07646822929382324
step: 350, loss: 0.007571099326014519
step: 360, loss: 0.012825517915189266
step: 370, loss: 0.28715458512306213
step: 380, loss: 0.1200048178434372
epoch 5: dev_f1=0.7524271844660194, f1=0.665, best_f1=0.5813953488372093
step: 0, loss: 0.011189497075974941
step: 10, loss: 0.017179341986775398
step: 20, loss: 0.043321091681718826
step: 30, loss: 0.0031098397448658943
step: 40, loss: 0.054196156561374664
step: 50, loss: 0.12206802517175674
step: 60, loss: 0.0057673039846122265
step: 70, loss: 0.047339070588350296
step: 80, loss: 0.0058797127567231655
step: 90, loss: 0.006021073553711176
step: 100, loss: 0.09317384660243988
step: 110, loss: 0.0023037560749799013
step: 120, loss: 0.0070036305114626884
step: 130, loss: 0.013227671384811401
step: 140, loss: 0.002435023430734873
step: 150, loss: 0.01060109306126833
step: 160, loss: 0.009555548429489136
step: 170, loss: 0.15992161631584167
step: 180, loss: 0.09233807772397995
step: 190, loss: 0.011592598631978035
step: 200, loss: 0.002331704366952181
step: 210, loss: 0.10785634815692902
step: 220, loss: 0.020233161747455597
step: 230, loss: 0.005583775229752064
step: 240, loss: 0.0019511168356984854
step: 250, loss: 0.01183865312486887
step: 260, loss: 0.04512256756424904
step: 270, loss: 0.13294000923633575
step: 280, loss: 0.010812366381287575
step: 290, loss: 0.055551085621118546
step: 300, loss: 0.0039509739726781845
step: 310, loss: 0.10209450870752335
step: 320, loss: 0.08242588490247726
step: 330, loss: 0.017372194677591324
step: 340, loss: 0.006168679799884558
step: 350, loss: 0.16741453111171722
step: 360, loss: 0.0696282684803009
step: 370, loss: 0.004487102385610342
step: 380, loss: 0.007000764831900597
epoch 6: dev_f1=0.745, f1=0.6243654822335025, best_f1=0.5813953488372093
step: 0, loss: 0.0019116973271593451
step: 10, loss: 0.005193231627345085
step: 20, loss: 0.02173646166920662
step: 30, loss: 0.017870260402560234
step: 40, loss: 0.007717532105743885
step: 50, loss: 0.0041811768896877766
step: 60, loss: 0.0371030755341053
step: 70, loss: 0.01920511946082115
step: 80, loss: 0.013370120897889137
step: 90, loss: 0.2287619262933731
step: 100, loss: 0.004560310859233141
step: 110, loss: 0.01114013884216547
step: 120, loss: 0.0005124793387949467
step: 130, loss: 0.006417634431272745
step: 140, loss: 0.014272186905145645
step: 150, loss: 0.10113181173801422
step: 160, loss: 0.004557911306619644
step: 170, loss: 0.03631224110722542
step: 180, loss: 0.0028591821901500225
step: 190, loss: 0.007169242482632399
step: 200, loss: 0.004835150670260191
step: 210, loss: 0.003985524643212557
step: 220, loss: 0.01527190487831831
step: 230, loss: 0.12769536674022675
step: 240, loss: 0.01733105443418026
step: 250, loss: 0.0018317019566893578
step: 260, loss: 0.020821498706936836
step: 270, loss: 0.0039798179641366005
step: 280, loss: 0.00040353270014747977
step: 290, loss: 0.0039276485331356525
step: 300, loss: 0.048424310982227325
step: 310, loss: 0.0024219322949647903
step: 320, loss: 0.004301229491829872
step: 330, loss: 0.020851485431194305
step: 340, loss: 0.06327853351831436
step: 350, loss: 0.10407191514968872
step: 360, loss: 0.013280751183629036
step: 370, loss: 0.019457656890153885
step: 380, loss: 0.01639159955084324
epoch 7: dev_f1=0.7578347578347578, f1=0.6460674157303371, best_f1=0.5813953488372093
step: 0, loss: 0.003306382102891803
step: 10, loss: 0.002164414618164301
step: 20, loss: 0.005719046574085951
step: 30, loss: 0.0022782781161367893
step: 40, loss: 0.003189580049365759
step: 50, loss: 0.014859559945762157
step: 60, loss: 0.055869486182928085
step: 70, loss: 0.011092329397797585
step: 80, loss: 0.0006044122856110334
step: 90, loss: 0.003969192039221525
step: 100, loss: 0.005555286537855864
step: 110, loss: 0.010508107021450996
step: 120, loss: 0.004719461314380169
step: 130, loss: 0.0007096573826856911
step: 140, loss: 0.00039426342118531466
step: 150, loss: 0.04260112717747688
step: 160, loss: 0.002655767137184739
step: 170, loss: 0.027320655062794685
step: 180, loss: 0.004781785886734724
step: 190, loss: 0.0907081663608551
step: 200, loss: 0.013912239111959934
step: 210, loss: 0.0014171403599902987
step: 220, loss: 0.03570178151130676
step: 230, loss: 0.007401642389595509
step: 240, loss: 0.006463616155087948
step: 250, loss: 0.0189068503677845
step: 260, loss: 0.0068273418582975864
step: 270, loss: 0.00040883803740143776
step: 280, loss: 0.12199389934539795
step: 290, loss: 0.002597912447527051
step: 300, loss: 0.000346323533449322
step: 310, loss: 0.0002986945037264377
step: 320, loss: 0.004442657809704542
step: 330, loss: 0.0008970912313088775
step: 340, loss: 0.0009084342746064067
step: 350, loss: 0.06524435430765152
step: 360, loss: 0.013610820285975933
step: 370, loss: 0.003491142997518182
step: 380, loss: 0.05630149692296982
epoch 8: dev_f1=0.7430025445292621, f1=0.6381909547738693, best_f1=0.5813953488372093
step: 0, loss: 0.002873768797144294
step: 10, loss: 0.0003100205212831497
step: 20, loss: 0.017037853598594666
step: 30, loss: 0.04076922684907913
step: 40, loss: 0.0009891724912449718
step: 50, loss: 0.0017800695495679975
step: 60, loss: 0.0007348501239903271
step: 70, loss: 0.00024465573369525373
step: 80, loss: 0.002437165006995201
step: 90, loss: 0.002455254318192601
step: 100, loss: 0.007536887191236019
step: 110, loss: 0.0004817852459382266
step: 120, loss: 0.00021085380285512656
step: 130, loss: 0.012443404644727707
step: 140, loss: 0.0016834188718348742
step: 150, loss: 0.004690254107117653
step: 160, loss: 0.0008033199119381607
step: 170, loss: 0.005736813880503178
step: 180, loss: 0.003206744324415922
step: 190, loss: 0.008436965756118298
step: 200, loss: 0.0065499404445290565
step: 210, loss: 0.0018653386505320668
step: 220, loss: 0.002669211244210601
step: 230, loss: 0.0010899025946855545
step: 240, loss: 0.0027376713696867228
step: 250, loss: 0.0002975046227220446
step: 260, loss: 0.0013128293212503195
step: 270, loss: 0.006456233095377684
step: 280, loss: 0.049252722412347794
step: 290, loss: 0.008384843356907368
step: 300, loss: 0.000696611066814512
step: 310, loss: 0.0582951121032238
step: 320, loss: 0.0009300364763475955
step: 330, loss: 0.0007797475554980338
step: 340, loss: 0.0022840783931314945
step: 350, loss: 0.000369897490600124
step: 360, loss: 0.002882780972868204
step: 370, loss: 0.13552306592464447
step: 380, loss: 0.0016511898720636964
epoch 9: dev_f1=0.7849462365591398, f1=0.6480446927374302, best_f1=0.6480446927374302
step: 0, loss: 0.002762424061074853
step: 10, loss: 0.06135384738445282
step: 20, loss: 0.03686223924160004
step: 30, loss: 0.0024145785719156265
step: 40, loss: 0.000602475949563086
step: 50, loss: 0.002698267111554742
step: 60, loss: 0.00046047967043705285
step: 70, loss: 0.002978753997012973
step: 80, loss: 0.0006407859036698937
step: 90, loss: 0.009357561357319355
step: 100, loss: 0.006111561320722103
step: 110, loss: 0.004996739327907562
step: 120, loss: 0.13856014609336853
step: 130, loss: 0.10477321594953537
step: 140, loss: 0.09825610369443893
step: 150, loss: 0.025740792974829674
step: 160, loss: 0.000998147763311863
step: 170, loss: 0.0006448676576837897
step: 180, loss: 0.002467323560267687
step: 190, loss: 0.0020015316549688578
step: 200, loss: 0.060867805033922195
step: 210, loss: 0.0008822024101391435
step: 220, loss: 0.0002229681849712506
step: 230, loss: 0.0022622973192483187
step: 240, loss: 0.0020941696129739285
step: 250, loss: 0.039415180683135986
step: 260, loss: 0.00030817859806120396
step: 270, loss: 0.025601906701922417
step: 280, loss: 0.004166418686509132
step: 290, loss: 0.011257221922278404
step: 300, loss: 0.0027145324274897575
step: 310, loss: 0.00014491616457235068
step: 320, loss: 0.04586881026625633
step: 330, loss: 0.0008343603694811463
step: 340, loss: 0.003967795986682177
step: 350, loss: 0.0030379274394363165
step: 360, loss: 0.004882285837084055
step: 370, loss: 0.0005920432740822434
step: 380, loss: 8.324388909386471e-05
epoch 10: dev_f1=0.7601078167115903, f1=0.6214689265536724, best_f1=0.6480446927374302
step: 0, loss: 0.007206819485872984
step: 10, loss: 0.00020214318647049367
step: 20, loss: 0.000488811288960278
step: 30, loss: 0.0014714421704411507
step: 40, loss: 0.08871723711490631
step: 50, loss: 0.001994065474718809
step: 60, loss: 0.003311907174065709
step: 70, loss: 0.0006110575632192194
step: 80, loss: 0.0014865651028230786
step: 90, loss: 0.0025774387177079916
step: 100, loss: 0.0017016885103657842
step: 110, loss: 0.0013359837466850877
step: 120, loss: 0.000259734399151057
step: 130, loss: 0.0021122503094375134
step: 140, loss: 0.0002155472757294774
step: 150, loss: 0.002482958836480975
step: 160, loss: 0.0008555428357794881
step: 170, loss: 0.015300103463232517
step: 180, loss: 0.0007799214799888432
step: 190, loss: 0.16099593043327332
step: 200, loss: 0.000463483011117205
step: 210, loss: 0.004776681307703257
step: 220, loss: 0.001257812837138772
step: 230, loss: 0.005226093344390392
step: 240, loss: 0.006956423632800579
step: 250, loss: 0.0022846339270472527
step: 260, loss: 0.000939881254453212
step: 270, loss: 0.04760254919528961
step: 280, loss: 0.0005298020550981164
step: 290, loss: 0.006202996242791414
step: 300, loss: 0.01875879243016243
step: 310, loss: 0.06341204792261124
step: 320, loss: 0.0023127570748329163
step: 330, loss: 0.0002657900331541896
step: 340, loss: 0.0003683442191686481
step: 350, loss: 0.012717020697891712
step: 360, loss: 6.27415138296783e-05
step: 370, loss: 0.010554111562669277
step: 380, loss: 0.0017920301761478186
epoch 11: dev_f1=0.7930174563591021, f1=0.689655172413793, best_f1=0.689655172413793
step: 0, loss: 0.0002780930371955037
step: 10, loss: 0.0038668799679726362
step: 20, loss: 0.002793391700834036
step: 30, loss: 0.04934357479214668
step: 40, loss: 0.013862241059541702
step: 50, loss: 0.07371975481510162
step: 60, loss: 0.00035559971001930535
step: 70, loss: 0.0002171162486774847
step: 80, loss: 0.00026229710783809423
step: 90, loss: 0.0024412290658801794
step: 100, loss: 9.163632785202935e-05
step: 110, loss: 0.0006084578344598413
step: 120, loss: 0.0008149810018949211
step: 130, loss: 0.001699798391200602
step: 140, loss: 0.009427208453416824
step: 150, loss: 0.000797351764049381
step: 160, loss: 0.00025241600815206766
step: 170, loss: 0.0006000892608426511
step: 180, loss: 0.014090982265770435
step: 190, loss: 0.002463268581777811
step: 200, loss: 0.005817287135869265
step: 210, loss: 0.0012928147334605455
step: 220, loss: 0.018147025257349014
step: 230, loss: 0.000518927990924567
step: 240, loss: 0.003952540922909975
step: 250, loss: 0.00018940896552521735
step: 260, loss: 0.0007424773648381233
step: 270, loss: 0.0004991028108634055
step: 280, loss: 0.0020586643368005753
step: 290, loss: 0.0037243280094116926
step: 300, loss: 0.00727149099111557
step: 310, loss: 0.0005798421916551888
step: 320, loss: 0.00019066354434471577
step: 330, loss: 0.07214104384183884
step: 340, loss: 0.0072242580354213715
step: 350, loss: 0.0008431365131400526
step: 360, loss: 0.0009095959831029177
step: 370, loss: 9.223020606441423e-05
step: 380, loss: 0.06927596777677536
epoch 12: dev_f1=0.7506297229219143, f1=0.6345177664974618, best_f1=0.689655172413793
step: 0, loss: 0.0026113614439964294
step: 10, loss: 0.0025305505841970444
step: 20, loss: 0.0011299208272248507
step: 30, loss: 0.00013294348900672048
step: 40, loss: 0.04817188158631325
step: 50, loss: 0.0014084483264014125
step: 60, loss: 0.001004665158689022
step: 70, loss: 0.0013204716378822923
step: 80, loss: 0.0001446696260245517
step: 90, loss: 0.00028434523846954107
step: 100, loss: 0.0008589634671807289
step: 110, loss: 0.053110092878341675
step: 120, loss: 0.0002512579958420247
step: 130, loss: 0.0016294679371640086
step: 140, loss: 0.0018511327216401696
step: 150, loss: 0.018283309414982796
step: 160, loss: 0.0007924616220407188
step: 170, loss: 0.0007776913698762655
step: 180, loss: 0.0006250524893403053
step: 190, loss: 0.024296419695019722
step: 200, loss: 0.0009147747186943889
step: 210, loss: 0.00064269476570189
step: 220, loss: 0.004095197189599276
step: 230, loss: 0.005836367607116699
step: 240, loss: 0.010282053612172604
step: 250, loss: 0.0005315420567058027
step: 260, loss: 0.00035805877996608615
step: 270, loss: 0.0008601751760579646
step: 280, loss: 0.0003459453582763672
step: 290, loss: 0.01083094161003828
step: 300, loss: 0.0011753445724025369
step: 310, loss: 0.00011787615221692249
step: 320, loss: 0.00028647814178839326
step: 330, loss: 0.0005293818539939821
step: 340, loss: 0.0010835708817467093
step: 350, loss: 0.014566483907401562
step: 360, loss: 0.00014106021262705326
step: 370, loss: 0.00020562304416671395
step: 380, loss: 0.0023406129330396652
epoch 13: dev_f1=0.745308310991957, f1=0.6298342541436465, best_f1=0.689655172413793
step: 0, loss: 0.0011268372181802988
step: 10, loss: 0.00036222589551471174
step: 20, loss: 0.00012399395927786827
step: 30, loss: 0.00044611230259761214
step: 40, loss: 0.00046723990817554295
step: 50, loss: 0.0004115719348192215
step: 60, loss: 0.0002893117198254913
step: 70, loss: 0.0002692835405468941
step: 80, loss: 0.0003390651836525649
step: 90, loss: 0.00023116420197766274
step: 100, loss: 0.00031344618764705956
step: 110, loss: 0.0003015898400917649
step: 120, loss: 0.00025450720568187535
step: 130, loss: 0.00014270248357206583
step: 140, loss: 0.0009220544598065317
step: 150, loss: 0.002487531630322337
step: 160, loss: 0.00010218185343546793
step: 170, loss: 0.0006167958490550518
step: 180, loss: 8.346886897925287e-05
step: 190, loss: 0.0003563966602087021
step: 200, loss: 0.0002627507783472538
step: 210, loss: 5.239366146270186e-05
step: 220, loss: 7.477481267414987e-05
step: 230, loss: 0.00010323405876988545
step: 240, loss: 0.0003153050201945007
step: 250, loss: 0.000873694836627692
step: 260, loss: 0.00026443813112564385
step: 270, loss: 5.7561548601370305e-05
step: 280, loss: 0.04829622432589531
step: 290, loss: 0.0014949943870306015
step: 300, loss: 0.00014858755457680672
step: 310, loss: 9.325972496299073e-05
step: 320, loss: 0.004929240792989731
step: 330, loss: 0.000645225343760103
step: 340, loss: 0.02675686962902546
step: 350, loss: 0.012636839412152767
step: 360, loss: 7.657389505766332e-05
step: 370, loss: 0.00012722649262286723
step: 380, loss: 0.00023177254479378462
epoch 14: dev_f1=0.7428571428571429, f1=0.6312684365781711, best_f1=0.689655172413793
step: 0, loss: 0.0038614231161773205
step: 10, loss: 0.0028491271659731865
step: 20, loss: 3.529922469169833e-05
step: 30, loss: 9.581831545801833e-05
step: 40, loss: 0.0007492746226489544
step: 50, loss: 8.538425754522905e-05
step: 60, loss: 0.00012343711568973958
step: 70, loss: 4.309757423470728e-05
step: 80, loss: 3.6732635635416955e-05
step: 90, loss: 0.012402237392961979
step: 100, loss: 0.0004703683080151677
step: 110, loss: 8.624930342193693e-05
step: 120, loss: 0.0021556299179792404
step: 130, loss: 0.0002625279303174466
step: 140, loss: 0.00017245604249183089
step: 150, loss: 0.00046522635966539383
step: 160, loss: 5.5912874813657254e-05
step: 170, loss: 0.00022201005776878446
step: 180, loss: 0.00016380689339712262
step: 190, loss: 0.0018523766193538904
step: 200, loss: 3.2154577638721094e-05
step: 210, loss: 0.00012907835480291396
step: 220, loss: 0.00013343784667085856
step: 230, loss: 3.34321812260896e-05
step: 240, loss: 6.33823437965475e-05
step: 250, loss: 0.00020246296480763704
step: 260, loss: 6.565014336956665e-05
step: 270, loss: 0.00012457587581593543
step: 280, loss: 0.005254180636256933
step: 290, loss: 5.691243495675735e-05
step: 300, loss: 3.601068601710722e-05
step: 310, loss: 7.719359564362094e-05
step: 320, loss: 3.6830406315857545e-05
step: 330, loss: 0.00012166557280579582
step: 340, loss: 0.0005626603960990906
step: 350, loss: 0.00028081031632609665
step: 360, loss: 4.162845289101824e-05
step: 370, loss: 6.83335165376775e-05
step: 380, loss: 0.0005087627214379609
epoch 15: dev_f1=0.7374005305039788, f1=0.592391304347826, best_f1=0.689655172413793
step: 0, loss: 0.00044754653936252
step: 10, loss: 0.00038773080450482666
step: 20, loss: 4.66513738501817e-05
step: 30, loss: 0.0002847423020284623
step: 40, loss: 0.0007022225181572139
step: 50, loss: 0.0008738702745176852
step: 60, loss: 5.284170401864685e-05
step: 70, loss: 1.9799563233391382e-05
step: 80, loss: 0.00025613754405640066
step: 90, loss: 9.31000686250627e-05
step: 100, loss: 0.016879796981811523
step: 110, loss: 5.9566042182268575e-05
step: 120, loss: 0.00017120488337241113
step: 130, loss: 6.720279634464532e-05
step: 140, loss: 0.0006096878205426037
step: 150, loss: 4.9674832553137094e-05
step: 160, loss: 6.830506026744843e-05
step: 170, loss: 2.342017978662625e-05
step: 180, loss: 0.00015945751511026174
step: 190, loss: 0.00019512012659106404
step: 200, loss: 7.338527939282358e-05
step: 210, loss: 0.0001630417100386694
step: 220, loss: 0.0026896619237959385
step: 230, loss: 0.00010954629397019744
step: 240, loss: 0.0007162931724451482
step: 250, loss: 7.57653615437448e-05
step: 260, loss: 0.0002661745820660144
step: 270, loss: 9.607925312593579e-05
step: 280, loss: 0.00016476934251841158
step: 290, loss: 8.309575059683993e-05
step: 300, loss: 2.594971374492161e-05
step: 310, loss: 0.00020057162328157574
step: 320, loss: 0.0003497235884424299
step: 330, loss: 0.0001364727650070563
step: 340, loss: 3.7299756513675675e-05
step: 350, loss: 2.356915319978725e-05
step: 360, loss: 4.634599827113561e-05
step: 370, loss: 3.66951608157251e-05
step: 380, loss: 0.00011428729339968413
epoch 16: dev_f1=0.7457627118644068, f1=0.5945945945945946, best_f1=0.689655172413793
step: 0, loss: 3.713010664796457e-05
step: 10, loss: 4.777738286065869e-05
step: 20, loss: 5.593313471763395e-05
step: 30, loss: 0.00010071025462821126
step: 40, loss: 4.114330295124091e-05
step: 50, loss: 0.00011435418127803132
step: 60, loss: 5.630286977975629e-05
step: 70, loss: 0.0005796330515295267
step: 80, loss: 0.00022546827676706016
step: 90, loss: 7.027691026451066e-05
step: 100, loss: 8.711062400834635e-05
step: 110, loss: 0.00010125752305611968
step: 120, loss: 8.530216291546822e-05
step: 130, loss: 5.682684786734171e-05
step: 140, loss: 0.0003502041508909315
step: 150, loss: 0.0017799286870285869
step: 160, loss: 4.648227695724927e-05
step: 170, loss: 5.177702769287862e-05
step: 180, loss: 2.475779729138594e-05
step: 190, loss: 0.0005532133509404957
step: 200, loss: 0.0004349697264842689
step: 210, loss: 0.00198156270198524
step: 220, loss: 5.038907693233341e-05
step: 230, loss: 6.760576070519164e-05
step: 240, loss: 7.83921277616173e-05
step: 250, loss: 0.00011140250717289746
step: 260, loss: 5.7629822549642995e-05
step: 270, loss: 0.003209141781553626
step: 280, loss: 0.0001317179703619331
step: 290, loss: 6.404233135981485e-05
step: 300, loss: 0.00018700156942941248
step: 310, loss: 0.0007319209980778396
step: 320, loss: 0.00013519202184397727
step: 330, loss: 7.108407589839771e-05
step: 340, loss: 6.156176095828414e-05
step: 350, loss: 0.0004690264177042991
step: 360, loss: 4.6745648432988673e-05
step: 370, loss: 0.0007951063453219831
step: 380, loss: 6.100098107708618e-05
epoch 17: dev_f1=0.7513513513513514, f1=0.5811965811965811, best_f1=0.689655172413793
step: 0, loss: 0.00017853299505077302
step: 10, loss: 5.670344035024755e-05
step: 20, loss: 8.240608440246433e-05
step: 30, loss: 0.00042046073940582573
step: 40, loss: 0.00013789829972665757
step: 50, loss: 7.134190673241392e-05
step: 60, loss: 0.00022312792134471238
step: 70, loss: 0.0002601933083496988
step: 80, loss: 5.7407585700275376e-05
step: 90, loss: 0.00014244213525671512
step: 100, loss: 0.0002133510570274666
step: 110, loss: 3.574458241928369e-05
step: 120, loss: 2.9574133804999292e-05
step: 130, loss: 6.243976531550288e-05
step: 140, loss: 5.650997263728641e-05
step: 150, loss: 0.00012553059787023813
step: 160, loss: 0.00011378103954484686
step: 170, loss: 3.345527875353582e-05
step: 180, loss: 5.8991001424146816e-05
step: 190, loss: 0.0011931016342714429
step: 200, loss: 7.410844409605488e-05
step: 210, loss: 0.0001352536492049694
step: 220, loss: 3.324318095110357e-05
step: 230, loss: 0.010983436368405819
step: 240, loss: 0.00012177548342151567
step: 250, loss: 0.0002960127021651715
step: 260, loss: 9.925814083544537e-05
step: 270, loss: 6.039697109372355e-05
step: 280, loss: 0.00019771679944824427
step: 290, loss: 0.00029649483622051775
step: 300, loss: 0.00035426081740297377
step: 310, loss: 2.9328250093385577e-05
step: 320, loss: 0.00013086579565424472
step: 330, loss: 0.0030683926306664944
step: 340, loss: 9.798476821742952e-05
step: 350, loss: 0.00014327492681331933
step: 360, loss: 0.00010465027298778296
step: 370, loss: 0.00010709503112593666
step: 380, loss: 0.0002467644808348268
epoch 18: dev_f1=0.7407407407407407, f1=0.5864197530864198, best_f1=0.689655172413793
step: 0, loss: 8.075138612184674e-05
step: 10, loss: 0.00015001508290879428
step: 20, loss: 3.5768276575254276e-05
step: 30, loss: 0.00036036642268300056
step: 40, loss: 3.469943112577312e-05
step: 50, loss: 3.6938021366950125e-05
step: 60, loss: 5.14043822477106e-05
step: 70, loss: 0.011415746062994003
step: 80, loss: 0.00036154844565317035
step: 90, loss: 3.085565913352184e-05
step: 100, loss: 3.2374860893469304e-05
step: 110, loss: 0.002292089397087693
step: 120, loss: 0.0006733062327839434
step: 130, loss: 4.722226003650576e-05
step: 140, loss: 6.157531606731936e-05
step: 150, loss: 2.339775164728053e-05
step: 160, loss: 7.211890624603257e-05
step: 170, loss: 0.0002590151852928102
step: 180, loss: 0.0002277687017340213
step: 190, loss: 0.0008150266949087381
step: 200, loss: 0.00043688109144568443
step: 210, loss: 0.0006649910355918109
step: 220, loss: 3.8607660826528445e-05
step: 230, loss: 0.0018132119439542294
step: 240, loss: 0.0001844009675551206
step: 250, loss: 7.341318996623158e-05
step: 260, loss: 8.286315278382972e-05
step: 270, loss: 0.00023349697585217655
step: 280, loss: 0.00019449448154773563
step: 290, loss: 5.076829984318465e-05
step: 300, loss: 0.0007401316543109715
step: 310, loss: 9.300267265643924e-05
step: 320, loss: 3.230087895644829e-05
step: 330, loss: 0.00013465022493619472
step: 340, loss: 3.66623789886944e-05
step: 350, loss: 5.215062265051529e-05
step: 360, loss: 6.798577669542283e-05
step: 370, loss: 4.6591660066042095e-05
step: 380, loss: 2.717871939239558e-05
epoch 19: dev_f1=0.738544474393531, f1=0.623229461756374, best_f1=0.689655172413793
step: 0, loss: 4.166497819824144e-05
step: 10, loss: 0.0002297062601428479
step: 20, loss: 0.00011051748151658103
step: 30, loss: 0.00028476890292949975
step: 40, loss: 0.00023777941532898694
step: 50, loss: 3.373111758264713e-05
step: 60, loss: 0.004181868862360716
step: 70, loss: 3.344043216202408e-05
step: 80, loss: 5.469153984449804e-05
step: 90, loss: 0.0005921675474382937
step: 100, loss: 5.930170664214529e-05
step: 110, loss: 0.00015181806520558894
step: 120, loss: 0.00010353668039897457
step: 130, loss: 0.00040200480725616217
step: 140, loss: 4.6408542402787134e-05
step: 150, loss: 0.00010942159860860556
step: 160, loss: 7.563465624116361e-05
step: 170, loss: 2.3800355847924948e-05
step: 180, loss: 0.002914262702688575
step: 190, loss: 6.843087612651289e-05
step: 200, loss: 2.4544966436224058e-05
step: 210, loss: 0.0004403895582072437
step: 220, loss: 7.19170129741542e-05
step: 230, loss: 4.9729969759937376e-05
step: 240, loss: 2.2451795302913524e-05
step: 250, loss: 1.9546270777937025e-05
step: 260, loss: 4.09196327382233e-05
step: 270, loss: 4.798199370270595e-05
step: 280, loss: 4.1588067688280717e-05
step: 290, loss: 0.00012970085663255304
step: 300, loss: 0.0001331295643467456
step: 310, loss: 6.818312976974994e-05
step: 320, loss: 2.6183992304140702e-05
step: 330, loss: 0.00029950347379781306
step: 340, loss: 3.828488115686923e-05
step: 350, loss: 0.00014062889385968447
step: 360, loss: 0.00017771880084183067
step: 370, loss: 8.488157618558034e-05
step: 380, loss: 6.502054020529613e-05
epoch 20: dev_f1=0.7413333333333334, f1=0.6239554317548747, best_f1=0.689655172413793
