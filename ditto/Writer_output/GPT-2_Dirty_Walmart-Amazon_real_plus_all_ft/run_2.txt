cuda
Device: cuda
step: 0, loss: 0.7544599175453186
step: 10, loss: 0.3673953711986542
step: 20, loss: 0.24331209063529968
step: 30, loss: 0.3180152475833893
step: 40, loss: 0.23994289338588715
step: 50, loss: 0.2750115692615509
step: 60, loss: 0.28219497203826904
step: 70, loss: 0.2198323756456375
step: 80, loss: 0.3990223705768585
step: 90, loss: 0.3458128571510315
step: 100, loss: 0.26213163137435913
step: 110, loss: 0.3949095904827118
step: 120, loss: 0.24831479787826538
step: 130, loss: 0.2422361671924591
step: 140, loss: 0.28390955924987793
step: 150, loss: 0.12878750264644623
step: 160, loss: 0.3263338506221771
step: 170, loss: 0.19103114306926727
step: 180, loss: 0.36227917671203613
step: 190, loss: 0.21986956894397736
step: 200, loss: 0.18321307003498077
step: 210, loss: 0.18241851031780243
step: 220, loss: 0.2622227966785431
step: 230, loss: 0.08500465750694275
step: 240, loss: 0.12146539241075516
step: 250, loss: 0.36943334341049194
step: 260, loss: 0.5077066421508789
step: 270, loss: 0.3144262433052063
step: 280, loss: 0.2388593554496765
step: 290, loss: 0.2426064908504486
step: 300, loss: 0.2163381427526474
step: 310, loss: 0.42539548873901367
step: 320, loss: 0.17177776992321014
step: 330, loss: 0.26539868116378784
step: 340, loss: 0.20981284976005554
step: 350, loss: 0.252878338098526
step: 360, loss: 0.1757245510816574
step: 370, loss: 0.3796229064464569
step: 380, loss: 0.15381143987178802
epoch 1: dev_f1=0.5149051490514904, f1=0.4057971014492754, best_f1=0.4057971014492754
step: 0, loss: 0.1277896910905838
step: 10, loss: 0.246959388256073
step: 20, loss: 0.10692935436964035
step: 30, loss: 0.29839324951171875
step: 40, loss: 0.16838862001895905
step: 50, loss: 0.2686527371406555
step: 60, loss: 0.07023714482784271
step: 70, loss: 0.17635244131088257
step: 80, loss: 0.17754705250263214
step: 90, loss: 0.1637433022260666
step: 100, loss: 0.17850345373153687
step: 110, loss: 0.13948744535446167
step: 120, loss: 0.24614760279655457
step: 130, loss: 0.13104908168315887
step: 140, loss: 0.49064895510673523
step: 150, loss: 0.15841077268123627
step: 160, loss: 0.5948812365531921
step: 170, loss: 0.16039519011974335
step: 180, loss: 0.18588697910308838
step: 190, loss: 0.1380128264427185
step: 200, loss: 0.2795100808143616
step: 210, loss: 0.3036040961742401
step: 220, loss: 0.1393740177154541
step: 230, loss: 0.0777738094329834
step: 240, loss: 0.21981453895568848
step: 250, loss: 0.18839029967784882
step: 260, loss: 0.14769107103347778
step: 270, loss: 0.2585219740867615
step: 280, loss: 0.07896944135427475
step: 290, loss: 0.033366333693265915
step: 300, loss: 0.022757474333047867
step: 310, loss: 0.30659061670303345
step: 320, loss: 0.23998083174228668
step: 330, loss: 0.1205519363284111
step: 340, loss: 0.03836144506931305
step: 350, loss: 0.3406240940093994
step: 360, loss: 0.073689304292202
step: 370, loss: 0.1001974567770958
step: 380, loss: 0.21654821932315826
epoch 2: dev_f1=0.6773333333333335, f1=0.5014409221902018, best_f1=0.5014409221902018
step: 0, loss: 0.05543087422847748
step: 10, loss: 0.20080530643463135
step: 20, loss: 0.13746699690818787
step: 30, loss: 0.07401008158922195
step: 40, loss: 0.19118168950080872
step: 50, loss: 0.07852689921855927
step: 60, loss: 0.08470799773931503
step: 70, loss: 0.13134242594242096
step: 80, loss: 0.22684094309806824
step: 90, loss: 0.06358976662158966
step: 100, loss: 0.2318599671125412
step: 110, loss: 0.058611419051885605
step: 120, loss: 0.2226945012807846
step: 130, loss: 0.07348965108394623
step: 140, loss: 0.11006495356559753
step: 150, loss: 0.28459861874580383
step: 160, loss: 0.03441765531897545
step: 170, loss: 0.023093275725841522
step: 180, loss: 0.06690690666437149
step: 190, loss: 0.12633974850177765
step: 200, loss: 0.11438757926225662
step: 210, loss: 0.1428387314081192
step: 220, loss: 0.16754770278930664
step: 230, loss: 0.08792097866535187
step: 240, loss: 0.08709530532360077
step: 250, loss: 0.30478373169898987
step: 260, loss: 0.1278342455625534
step: 270, loss: 0.02492312528192997
step: 280, loss: 0.07334818691015244
step: 290, loss: 0.11559975892305374
step: 300, loss: 0.07116810977458954
step: 310, loss: 0.014271109364926815
step: 320, loss: 0.1445411592721939
step: 330, loss: 0.01847381331026554
step: 340, loss: 0.04269677400588989
step: 350, loss: 0.14918282628059387
step: 360, loss: 0.04600375518202782
step: 370, loss: 0.044319987297058105
step: 380, loss: 0.16082145273685455
epoch 3: dev_f1=0.7616438356164383, f1=0.5903614457831325, best_f1=0.5903614457831325
step: 0, loss: 0.08256981521844864
step: 10, loss: 0.035145413130521774
step: 20, loss: 0.08740454167127609
step: 30, loss: 0.17194902896881104
step: 40, loss: 0.0380900539457798
step: 50, loss: 0.07339035719633102
step: 60, loss: 0.011612248606979847
step: 70, loss: 0.1233510673046112
step: 80, loss: 0.14558957517147064
step: 90, loss: 0.013893221504986286
step: 100, loss: 0.02017039619386196
step: 110, loss: 0.07012386620044708
step: 120, loss: 0.08271073549985886
step: 130, loss: 0.13316671550273895
step: 140, loss: 0.040133170783519745
step: 150, loss: 0.01922568678855896
step: 160, loss: 0.10506907105445862
step: 170, loss: 0.1542031615972519
step: 180, loss: 0.042656172066926956
step: 190, loss: 0.025485221296548843
step: 200, loss: 0.028542647138237953
step: 210, loss: 0.04113328829407692
step: 220, loss: 0.16389529407024384
step: 230, loss: 0.013753184117376804
step: 240, loss: 0.2327735275030136
step: 250, loss: 0.1624758392572403
step: 260, loss: 0.017831461504101753
step: 270, loss: 0.1310397982597351
step: 280, loss: 0.007037055678665638
step: 290, loss: 0.29811176657676697
step: 300, loss: 0.044152453541755676
step: 310, loss: 0.003206397872418165
step: 320, loss: 0.0422830730676651
step: 330, loss: 0.10072311013936996
step: 340, loss: 0.05065502971410751
step: 350, loss: 0.15593673288822174
step: 360, loss: 0.15762364864349365
step: 370, loss: 0.04057303071022034
step: 380, loss: 0.04285633936524391
epoch 4: dev_f1=0.7657142857142857, f1=0.5867507886435331, best_f1=0.5867507886435331
step: 0, loss: 0.1554626226425171
step: 10, loss: 0.016261432319879532
step: 20, loss: 0.08996889740228653
step: 30, loss: 0.12274397909641266
step: 40, loss: 0.023199744522571564
step: 50, loss: 0.0019336831755936146
step: 60, loss: 0.07056231796741486
step: 70, loss: 0.020938536152243614
step: 80, loss: 0.011827321723103523
step: 90, loss: 0.012437550351023674
step: 100, loss: 0.041963499039411545
step: 110, loss: 0.089896060526371
step: 120, loss: 0.03376859053969383
step: 130, loss: 0.007991445250809193
step: 140, loss: 0.009123161435127258
step: 150, loss: 0.022006923332810402
step: 160, loss: 0.2036607712507248
step: 170, loss: 0.010714623145759106
step: 180, loss: 0.06862576305866241
step: 190, loss: 0.020868655294179916
step: 200, loss: 0.06611569225788116
step: 210, loss: 0.013350093737244606
step: 220, loss: 0.03764316812157631
step: 230, loss: 0.022577691823244095
step: 240, loss: 0.0721096619963646
step: 250, loss: 0.009664002805948257
step: 260, loss: 0.013470661826431751
step: 270, loss: 0.053675804287195206
step: 280, loss: 0.01983119174838066
step: 290, loss: 0.10942038893699646
step: 300, loss: 0.13108614087104797
step: 310, loss: 0.08297260105609894
step: 320, loss: 0.0102353785187006
step: 330, loss: 0.03307317942380905
step: 340, loss: 0.023256681859493256
step: 350, loss: 0.017765533179044724
step: 360, loss: 0.06587035208940506
step: 370, loss: 0.00898391380906105
step: 380, loss: 0.08420928567647934
epoch 5: dev_f1=0.7244094488188976, f1=0.5263157894736842, best_f1=0.5867507886435331
step: 0, loss: 0.034279800951480865
step: 10, loss: 0.07425761967897415
step: 20, loss: 0.051428601145744324
step: 30, loss: 0.011579947546124458
step: 40, loss: 0.11826151609420776
step: 50, loss: 0.055706240236759186
step: 60, loss: 0.028874991461634636
step: 70, loss: 0.16954852640628815
step: 80, loss: 0.13290993869304657
step: 90, loss: 0.04264920577406883
step: 100, loss: 0.020691540092229843
step: 110, loss: 0.050416938960552216
step: 120, loss: 0.27918046712875366
step: 130, loss: 0.003775435034185648
step: 140, loss: 0.0037686980795115232
step: 150, loss: 0.18215185403823853
step: 160, loss: 0.003648363519459963
step: 170, loss: 0.007472554221749306
step: 180, loss: 0.003101770533248782
step: 190, loss: 0.004236273001879454
step: 200, loss: 0.021106107160449028
step: 210, loss: 0.051283255219459534
step: 220, loss: 0.06783036887645721
step: 230, loss: 0.027319740504026413
step: 240, loss: 0.0012545872014015913
step: 250, loss: 0.020545903593301773
step: 260, loss: 0.004858985543251038
step: 270, loss: 0.0010356245329603553
step: 280, loss: 0.007777652703225613
step: 290, loss: 0.14446064829826355
step: 300, loss: 0.08696696162223816
step: 310, loss: 0.004553218372166157
step: 320, loss: 0.004206153564155102
step: 330, loss: 0.0014975578524172306
step: 340, loss: 0.003416347550228238
step: 350, loss: 0.014177526347339153
step: 360, loss: 0.014183739200234413
step: 370, loss: 0.0022316481918096542
step: 380, loss: 0.010403669439256191
epoch 6: dev_f1=0.7712765957446809, f1=0.585635359116022, best_f1=0.585635359116022
step: 0, loss: 0.0010405706707388163
step: 10, loss: 0.0027785382699221373
step: 20, loss: 0.001879911171272397
step: 30, loss: 0.027716245502233505
step: 40, loss: 0.0770011693239212
step: 50, loss: 0.13588054478168488
step: 60, loss: 0.02106308937072754
step: 70, loss: 0.024923328310251236
step: 80, loss: 0.01807660423219204
step: 90, loss: 0.01085034292191267
step: 100, loss: 0.012104600667953491
step: 110, loss: 0.007706109434366226
step: 120, loss: 0.005954073276370764
step: 130, loss: 0.010608445852994919
step: 140, loss: 0.002817358123138547
step: 150, loss: 0.0028767564799636602
step: 160, loss: 0.001412144978530705
step: 170, loss: 0.0018144040368497372
step: 180, loss: 0.005803683772683144
step: 190, loss: 0.0039218426682055
step: 200, loss: 0.007431806530803442
step: 210, loss: 0.0038561751134693623
step: 220, loss: 0.0021358581725507975
step: 230, loss: 0.004963325336575508
step: 240, loss: 0.2051367610692978
step: 250, loss: 0.04492069408297539
step: 260, loss: 0.011612644419074059
step: 270, loss: 0.015817081555724144
step: 280, loss: 0.03244135528802872
step: 290, loss: 0.0006502685719169676
step: 300, loss: 0.000665895757265389
step: 310, loss: 0.0031009309459477663
step: 320, loss: 0.009853938594460487
step: 330, loss: 0.08850187808275223
step: 340, loss: 0.01597670093178749
step: 350, loss: 0.043915487825870514
step: 360, loss: 0.056035056710243225
step: 370, loss: 0.004634570330381393
step: 380, loss: 0.026044946163892746
epoch 7: dev_f1=0.7545219638242895, f1=0.6214689265536724, best_f1=0.585635359116022
step: 0, loss: 0.046745866537094116
step: 10, loss: 0.03630049154162407
step: 20, loss: 0.008378705009818077
step: 30, loss: 0.006403123959898949
step: 40, loss: 0.04439781233668327
step: 50, loss: 0.0012209805427119136
step: 60, loss: 0.10556982457637787
step: 70, loss: 0.007021108642220497
step: 80, loss: 0.003059175331145525
step: 90, loss: 0.0009930768283084035
step: 100, loss: 0.0037044130731374025
step: 110, loss: 0.02937074936926365
step: 120, loss: 0.055790457874536514
step: 130, loss: 0.01437052246183157
step: 140, loss: 0.01917833462357521
step: 150, loss: 0.22491306066513062
step: 160, loss: 0.003090948099270463
step: 170, loss: 0.008874019607901573
step: 180, loss: 0.09318802505731583
step: 190, loss: 0.001846800441853702
step: 200, loss: 0.033325642347335815
step: 210, loss: 0.04009309038519859
step: 220, loss: 0.0024650178384035826
step: 230, loss: 0.0041023800149559975
step: 240, loss: 0.0007297408301383257
step: 250, loss: 0.0007780383457429707
step: 260, loss: 0.1274821013212204
step: 270, loss: 0.0037260232493281364
step: 280, loss: 0.0004852601559832692
step: 290, loss: 0.022409381344914436
step: 300, loss: 0.0007280198624357581
step: 310, loss: 0.0008201450691558421
step: 320, loss: 0.06386376917362213
step: 330, loss: 0.0069151767529547215
step: 340, loss: 0.03319963067770004
step: 350, loss: 0.0018858577823266387
step: 360, loss: 0.013498986139893532
step: 370, loss: 0.008816785179078579
step: 380, loss: 0.03622175753116608
epoch 8: dev_f1=0.7633587786259541, f1=0.6683937823834197, best_f1=0.585635359116022
step: 0, loss: 0.08516404032707214
step: 10, loss: 0.005270487163215876
step: 20, loss: 0.001316289184615016
step: 30, loss: 0.02006145566701889
step: 40, loss: 0.006486416794359684
step: 50, loss: 0.0003851373912766576
step: 60, loss: 0.0003882492601405829
step: 70, loss: 0.014979057013988495
step: 80, loss: 0.08390043675899506
step: 90, loss: 0.002569598611444235
step: 100, loss: 0.0005356030305847526
step: 110, loss: 0.006239633541554213
step: 120, loss: 0.0011462209513410926
step: 130, loss: 0.0010590628953650594
step: 140, loss: 0.0580042339861393
step: 150, loss: 0.018899476155638695
step: 160, loss: 0.03952888026833534
step: 170, loss: 0.02612859383225441
step: 180, loss: 0.00024583181948401034
step: 190, loss: 0.01445818692445755
step: 200, loss: 0.004829456098377705
step: 210, loss: 0.004191935993731022
step: 220, loss: 0.005290580447763205
step: 230, loss: 0.0009562392369844019
step: 240, loss: 0.022560948505997658
step: 250, loss: 0.012924008071422577
step: 260, loss: 0.0010442902566865087
step: 270, loss: 0.0015384717844426632
step: 280, loss: 0.0034956932067871094
step: 290, loss: 0.0003678238426800817
step: 300, loss: 0.011253981851041317
step: 310, loss: 0.00022704704315401614
step: 320, loss: 0.021592838689684868
step: 330, loss: 0.016277870163321495
step: 340, loss: 0.002424829173833132
step: 350, loss: 0.0007927819387987256
step: 360, loss: 0.0021538319997489452
step: 370, loss: 0.014729971066117287
step: 380, loss: 0.0190731231123209
epoch 9: dev_f1=0.7333333333333334, f1=0.6073298429319371, best_f1=0.585635359116022
step: 0, loss: 0.0004139455850236118
step: 10, loss: 0.0006126281223259866
step: 20, loss: 0.0002283745416207239
step: 30, loss: 0.00042463038698770106
step: 40, loss: 0.0012226561084389687
step: 50, loss: 0.0003733892517630011
step: 60, loss: 0.014818507246673107
step: 70, loss: 0.017008282244205475
step: 80, loss: 0.0038872533477842808
step: 90, loss: 0.01621527597308159
step: 100, loss: 0.011419611051678658
step: 110, loss: 0.0005231225513853133
step: 120, loss: 0.0006855218671262264
step: 130, loss: 0.0005134398234076798
step: 140, loss: 0.0005090744816698134
step: 150, loss: 0.0002639868180267513
step: 160, loss: 0.0006818198598921299
step: 170, loss: 0.00028030225075781345
step: 180, loss: 0.005231533199548721
step: 190, loss: 0.0001722103334031999
step: 200, loss: 0.0003923435288015753
step: 210, loss: 0.004867649171501398
step: 220, loss: 0.0004316098056733608
step: 230, loss: 0.0037376752588897943
step: 240, loss: 0.0004385779320728034
step: 250, loss: 0.010092023760080338
step: 260, loss: 0.00021566564100794494
step: 270, loss: 0.0005211894167587161
step: 280, loss: 0.014644193463027477
step: 290, loss: 0.020029082894325256
step: 300, loss: 0.009143006056547165
step: 310, loss: 0.0017328301910310984
step: 320, loss: 0.007208629976958036
step: 330, loss: 0.0015580563340336084
step: 340, loss: 0.048751648515462875
step: 350, loss: 0.0024049568455666304
step: 360, loss: 0.0003564915677998215
step: 370, loss: 0.00014685452333651483
step: 380, loss: 0.0006339769461192191
epoch 10: dev_f1=0.7512953367875648, f1=0.6263736263736264, best_f1=0.585635359116022
step: 0, loss: 0.0012286927085369825
step: 10, loss: 0.0008771241991780698
step: 20, loss: 0.0010965528199449182
step: 30, loss: 0.002316300058737397
step: 40, loss: 0.00401727482676506
step: 50, loss: 0.006973060313612223
step: 60, loss: 0.007299944758415222
step: 70, loss: 0.005883526522666216
step: 80, loss: 0.0061906264163553715
step: 90, loss: 0.0017872772878035903
step: 100, loss: 0.0006966129294596612
step: 110, loss: 0.0044945464469492435
step: 120, loss: 0.0014721769839525223
step: 130, loss: 0.002930818824097514
step: 140, loss: 0.0004035375313833356
step: 150, loss: 0.004723930731415749
step: 160, loss: 0.0014570999192073941
step: 170, loss: 0.003653955878689885
step: 180, loss: 0.002589461160823703
step: 190, loss: 0.0015084219630807638
step: 200, loss: 0.001509765163064003
step: 210, loss: 0.002386881737038493
step: 220, loss: 0.001065271208062768
step: 230, loss: 0.0007908900151960552
step: 240, loss: 0.00014281427138485014
step: 250, loss: 0.0002349877031520009
step: 260, loss: 0.000636290293186903
step: 270, loss: 0.0001275537651963532
step: 280, loss: 0.0014762531500309706
step: 290, loss: 0.0030825173016637564
step: 300, loss: 0.0024157019797712564
step: 310, loss: 0.00010883513459702954
step: 320, loss: 0.00019168433209415525
step: 330, loss: 0.012532845139503479
step: 340, loss: 0.0008169858483597636
step: 350, loss: 0.0007862098282203078
step: 360, loss: 0.003148360876366496
step: 370, loss: 0.00023148651234805584
step: 380, loss: 0.00015736339264549315
epoch 11: dev_f1=0.753315649867374, f1=0.5842696629213484, best_f1=0.585635359116022
step: 0, loss: 0.003182400716468692
step: 10, loss: 0.0018881441792473197
step: 20, loss: 0.00023144624719861895
step: 30, loss: 0.00031109582050703466
step: 40, loss: 0.001251151436008513
step: 50, loss: 0.07924728840589523
step: 60, loss: 0.0031411806121468544
step: 70, loss: 0.007240384351462126
step: 80, loss: 0.000562715926207602
step: 90, loss: 0.0002725510857999325
step: 100, loss: 0.0018404917791485786
step: 110, loss: 0.0006784911965951324
step: 120, loss: 0.00014195858966559172
step: 130, loss: 8.637253631604835e-05
step: 140, loss: 0.0004234809020999819
step: 150, loss: 0.00278098089620471
step: 160, loss: 0.00026784223155118525
step: 170, loss: 0.0034897129517048597
step: 180, loss: 0.0005128335324116051
step: 190, loss: 0.0009378199465572834
step: 200, loss: 0.00018021171854343265
step: 210, loss: 0.0010673085926100612
step: 220, loss: 0.0008656858699396253
step: 230, loss: 0.00014547319733537734
step: 240, loss: 0.00019380063167773187
step: 250, loss: 0.01593891717493534
step: 260, loss: 0.00012594678264576942
step: 270, loss: 0.012244015000760555
step: 280, loss: 0.0001492653536843136
step: 290, loss: 0.006685405969619751
step: 300, loss: 0.023215385153889656
step: 310, loss: 0.00011247191287111491
step: 320, loss: 0.0014159738784655929
step: 330, loss: 0.0010117654455825686
step: 340, loss: 0.004894911777228117
step: 350, loss: 0.0002417104842606932
step: 360, loss: 0.00016251612396445125
step: 370, loss: 7.680479757254943e-05
step: 380, loss: 0.0006221404182724655
epoch 12: dev_f1=0.7553191489361701, f1=0.5959885386819485, best_f1=0.585635359116022
step: 0, loss: 0.0011980485869571567
step: 10, loss: 0.0011254895944148302
step: 20, loss: 0.0002733127912506461
step: 30, loss: 4.3587635445874184e-05
step: 40, loss: 0.00020490727911237627
step: 50, loss: 3.7124405935173854e-05
step: 60, loss: 0.0001751677191350609
step: 70, loss: 0.0465417318046093
step: 80, loss: 0.0014736574376001954
step: 90, loss: 0.00029915678896941245
step: 100, loss: 0.0017637269338592887
step: 110, loss: 0.0002906436857301742
step: 120, loss: 0.0938955694437027
step: 130, loss: 0.00017144321464002132
step: 140, loss: 0.00022849331435281783
step: 150, loss: 0.0013167373836040497
step: 160, loss: 0.00013975168985780329
step: 170, loss: 0.019754868000745773
step: 180, loss: 0.0010723929153755307
step: 190, loss: 4.0342234569834545e-05
step: 200, loss: 8.969828923000023e-05
step: 210, loss: 0.0014841171214357018
step: 220, loss: 0.001004670630209148
step: 230, loss: 0.0003931645769625902
step: 240, loss: 0.00012165656517026946
step: 250, loss: 0.0002802945382427424
step: 260, loss: 0.0001974570332095027
step: 270, loss: 0.0004967681597918272
step: 280, loss: 8.144012099364772e-05
step: 290, loss: 0.0022049113176763058
step: 300, loss: 0.009600246325135231
step: 310, loss: 0.00011176134285051376
step: 320, loss: 0.00013443453644867986
step: 330, loss: 0.00258749071508646
step: 340, loss: 0.0010482878424227238
step: 350, loss: 0.0015095982234925032
step: 360, loss: 0.018253080546855927
step: 370, loss: 0.00013271908392198384
step: 380, loss: 0.012476843781769276
epoch 13: dev_f1=0.7676767676767676, f1=0.6263157894736843, best_f1=0.585635359116022
step: 0, loss: 0.0008105713641270995
step: 10, loss: 0.00024803882115520537
step: 20, loss: 0.00034207606222480536
step: 30, loss: 0.0001907738042064011
step: 40, loss: 0.0011281814659014344
step: 50, loss: 0.0005679230089299381
step: 60, loss: 0.00014755142910871655
step: 70, loss: 9.527941438136622e-05
step: 80, loss: 0.0015933136455714703
step: 90, loss: 0.0001484482636442408
step: 100, loss: 7.11572211002931e-05
step: 110, loss: 0.0031817795243114233
step: 120, loss: 3.671070953714661e-05
step: 130, loss: 0.0007128911092877388
step: 140, loss: 0.005300433840602636
step: 150, loss: 0.0035838978365063667
step: 160, loss: 0.000497097207698971
step: 170, loss: 0.012821914628148079
step: 180, loss: 0.0015088665531948209
step: 190, loss: 0.00012881436850875616
step: 200, loss: 0.0008868749719113111
step: 210, loss: 0.0008416972123086452
step: 220, loss: 0.010192958638072014
step: 230, loss: 5.847806460224092e-05
step: 240, loss: 0.000445713842054829
step: 250, loss: 0.00029633985832333565
step: 260, loss: 0.0004910115385428071
step: 270, loss: 0.007341178599745035
step: 280, loss: 2.5640716557973064e-05
step: 290, loss: 5.917442467762157e-05
step: 300, loss: 0.0008239531889557838
step: 310, loss: 0.0006117064622230828
step: 320, loss: 8.100249397102743e-05
step: 330, loss: 0.00013955986651126295
step: 340, loss: 0.00017188623314723372
step: 350, loss: 0.0010068422416225076
step: 360, loss: 5.825352855026722e-05
step: 370, loss: 0.0002306545793544501
step: 380, loss: 0.006850902922451496
epoch 14: dev_f1=0.6607142857142857, f1=0.5477707006369427, best_f1=0.585635359116022
step: 0, loss: 0.00020502843835856766
step: 10, loss: 0.015619281679391861
step: 20, loss: 0.0007081920630298555
step: 30, loss: 0.00023915324709378183
step: 40, loss: 0.0006905206828378141
step: 50, loss: 0.00017925037536770105
step: 60, loss: 0.08632507175207138
step: 70, loss: 0.0005619722069241107
step: 80, loss: 0.00816500186920166
step: 90, loss: 0.0006555295549333096
step: 100, loss: 0.00011255622666794807
step: 110, loss: 0.0027203282807022333
step: 120, loss: 0.013795538805425167
step: 130, loss: 0.00020555590162985027
step: 140, loss: 0.00011978333350270987
step: 150, loss: 0.0003382383147254586
step: 160, loss: 4.2384330299682915e-05
step: 170, loss: 0.0020685698837041855
step: 180, loss: 0.0006959611782804132
step: 190, loss: 0.0005581845762208104
step: 200, loss: 0.00020459310326259583
step: 210, loss: 0.00015023766900412738
step: 220, loss: 8.075235382420942e-05
step: 230, loss: 0.008773460984230042
step: 240, loss: 6.99083466315642e-05
step: 250, loss: 0.0005497405654750764
step: 260, loss: 4.0935050492407754e-05
step: 270, loss: 0.00013045627565588802
step: 280, loss: 0.00020678179862443358
step: 290, loss: 0.0009115299326367676
step: 300, loss: 3.583609213819727e-05
step: 310, loss: 0.0009005485917441547
step: 320, loss: 5.495188815984875e-05
step: 330, loss: 0.003810666035860777
step: 340, loss: 0.002006452064961195
step: 350, loss: 0.042818985879421234
step: 360, loss: 0.0050858864560723305
step: 370, loss: 0.0006325379945337772
step: 380, loss: 5.971219434286468e-05
epoch 15: dev_f1=0.745308310991957, f1=0.6361031518624642, best_f1=0.585635359116022
step: 0, loss: 0.0020252589602023363
step: 10, loss: 0.00021825189469382167
step: 20, loss: 0.0003135243314318359
step: 30, loss: 0.00016756003606133163
step: 40, loss: 0.0061455657705664635
step: 50, loss: 0.0009160572080872953
step: 60, loss: 0.03825795650482178
step: 70, loss: 0.00013961353397462517
step: 80, loss: 0.0010716189863160253
step: 90, loss: 0.00016520972712896764
step: 100, loss: 0.003086454700678587
step: 110, loss: 0.003606714541092515
step: 120, loss: 0.000532916805241257
step: 130, loss: 0.0015880297869443893
step: 140, loss: 0.1360703557729721
step: 150, loss: 0.00014116085367277265
step: 160, loss: 0.000860314816236496
step: 170, loss: 0.00010211912012891844
step: 180, loss: 0.0004618763632606715
step: 190, loss: 6.45285690552555e-05
step: 200, loss: 0.00035303039476275444
step: 210, loss: 0.0002125832688761875
step: 220, loss: 0.00359502830542624
step: 230, loss: 0.0001928001584019512
step: 240, loss: 0.0002448716259095818
step: 250, loss: 0.001021378324367106
step: 260, loss: 0.0001459714985685423
step: 270, loss: 0.0011776142055168748
step: 280, loss: 0.01215366367250681
step: 290, loss: 0.00012665770191233605
step: 300, loss: 0.00012184400111436844
step: 310, loss: 3.129087053821422e-05
step: 320, loss: 8.285931835416704e-05
step: 330, loss: 9.249695722246543e-05
step: 340, loss: 0.0006787810125388205
step: 350, loss: 0.0003555840521585196
step: 360, loss: 2.6299872843082994e-05
step: 370, loss: 2.3051728931022808e-05
step: 380, loss: 0.0002605015179142356
epoch 16: dev_f1=0.7430025445292621, f1=0.6166666666666667, best_f1=0.585635359116022
step: 0, loss: 0.0008410449954681098
step: 10, loss: 9.813807264436036e-05
step: 20, loss: 0.0031823923345655203
step: 30, loss: 0.03486962616443634
step: 40, loss: 4.142985926591791e-05
step: 50, loss: 0.00016460249025840312
step: 60, loss: 0.0021179544273763895
step: 70, loss: 0.00023784257064107805
step: 80, loss: 0.00028947379905730486
step: 90, loss: 0.0027250663843005896
step: 100, loss: 0.003246230771765113
step: 110, loss: 0.0006466108607128263
step: 120, loss: 9.438082634005696e-05
step: 130, loss: 0.00021032406948506832
step: 140, loss: 0.0005775426980108023
step: 150, loss: 0.00013426374061964452
step: 160, loss: 4.183415148872882e-05
step: 170, loss: 0.0002786906261462718
step: 180, loss: 2.6992640414391644e-05
step: 190, loss: 0.00011561487190192565
step: 200, loss: 0.00028707386809401214
step: 210, loss: 4.1062001400860026e-05
step: 220, loss: 0.00017620109429117292
step: 230, loss: 8.636911661596969e-05
step: 240, loss: 0.0007374139968305826
step: 250, loss: 0.0033317033667117357
step: 260, loss: 0.00013308953202795237
step: 270, loss: 6.513659172924235e-05
step: 280, loss: 0.0028914716094732285
step: 290, loss: 0.0003845067403744906
step: 300, loss: 0.0008245721692219377
step: 310, loss: 0.0018346745055168867
step: 320, loss: 0.0030089751817286015
step: 330, loss: 0.00011161994916619733
step: 340, loss: 0.00011755813466152176
step: 350, loss: 0.0028933922294527292
step: 360, loss: 4.606590300682001e-05
step: 370, loss: 0.010798472911119461
step: 380, loss: 2.5610321245039813e-05
epoch 17: dev_f1=0.7591623036649214, f1=0.6228571428571429, best_f1=0.585635359116022
step: 0, loss: 0.00012238182534929365
step: 10, loss: 4.0863509639166296e-05
step: 20, loss: 8.389858703594655e-05
step: 30, loss: 3.6095389077672735e-05
step: 40, loss: 7.690864003961906e-05
step: 50, loss: 0.00016607156430836767
step: 60, loss: 0.0008529031765647233
step: 70, loss: 0.0001565765996929258
step: 80, loss: 5.9460591728566214e-05
step: 90, loss: 0.00024266343098133802
step: 100, loss: 0.002319237682968378
step: 110, loss: 0.000365480751497671
step: 120, loss: 3.3589021768420935e-05
step: 130, loss: 3.922451287508011e-05
step: 140, loss: 0.00015444365271832794
step: 150, loss: 3.6874451325275004e-05
step: 160, loss: 0.0025430098176002502
step: 170, loss: 3.276618372183293e-05
step: 180, loss: 0.0001483454689150676
step: 190, loss: 0.0006465556798502803
step: 200, loss: 0.0003625921963248402
step: 210, loss: 3.754531280719675e-05
step: 220, loss: 0.00015298342623282224
step: 230, loss: 9.640257485443726e-05
step: 240, loss: 0.0002834329498000443
step: 250, loss: 0.00013329947250895202
step: 260, loss: 6.613189907511696e-05
step: 270, loss: 0.00015923139289952815
step: 280, loss: 0.0001859792391769588
step: 290, loss: 3.7612018786603585e-05
step: 300, loss: 3.1120081985136494e-05
step: 310, loss: 0.000946053653024137
step: 320, loss: 2.9197723051765934e-05
step: 330, loss: 4.6685676352353767e-05
step: 340, loss: 0.0010502715595066547
step: 350, loss: 0.00033838010858744383
step: 360, loss: 0.0003343616263009608
step: 370, loss: 3.596596070565283e-05
step: 380, loss: 0.007439999841153622
epoch 18: dev_f1=0.746031746031746, f1=0.573913043478261, best_f1=0.585635359116022
step: 0, loss: 9.687676356406882e-05
step: 10, loss: 2.1110772649990395e-05
step: 20, loss: 0.00011855539923999459
step: 30, loss: 0.00013874431897420436
step: 40, loss: 4.777006324729882e-05
step: 50, loss: 0.00018645905947778374
step: 60, loss: 2.1554107661359012e-05
step: 70, loss: 4.586733484757133e-05
step: 80, loss: 0.0010906349634751678
step: 90, loss: 0.00027182954363524914
step: 100, loss: 2.5305072995251976e-05
step: 110, loss: 3.804414882324636e-05
step: 120, loss: 0.0001443917426513508
step: 130, loss: 2.4355154891964048e-05
step: 140, loss: 0.024942275136709213
step: 150, loss: 4.8990776122082025e-05
step: 160, loss: 0.00033427952439524233
step: 170, loss: 7.088141865096986e-05
step: 180, loss: 0.0007644485449418426
step: 190, loss: 4.0382463339483365e-05
step: 200, loss: 0.0008224844932556152
step: 210, loss: 0.002136659575626254
step: 220, loss: 9.83196368906647e-05
step: 230, loss: 0.00010381062747910619
step: 240, loss: 6.460752047132701e-05
step: 250, loss: 0.0001978499349206686
step: 260, loss: 0.00011358450137777254
step: 270, loss: 0.000120927368698176
step: 280, loss: 1.839894503063988e-05
step: 290, loss: 3.5450426366878673e-05
step: 300, loss: 5.317985778674483e-05
step: 310, loss: 0.00011495518265292048
step: 320, loss: 4.982604514225386e-05
step: 330, loss: 0.008326194249093533
step: 340, loss: 3.8457488699350506e-05
step: 350, loss: 2.776320616248995e-05
step: 360, loss: 0.000502411974593997
step: 370, loss: 3.126145020360127e-05
step: 380, loss: 0.0008338019251823425
epoch 19: dev_f1=0.7467362924281985, f1=0.603988603988604, best_f1=0.585635359116022
step: 0, loss: 5.8266959968023e-05
step: 10, loss: 0.0001513318275101483
step: 20, loss: 0.06624290347099304
step: 30, loss: 0.003304604906588793
step: 40, loss: 4.876230377703905e-05
step: 50, loss: 5.0219310651300475e-05
step: 60, loss: 4.45352889073547e-05
step: 70, loss: 5.047080776421353e-05
step: 80, loss: 8.445548883173615e-05
step: 90, loss: 0.00011959215044043958
step: 100, loss: 9.485855844104663e-05
step: 110, loss: 3.379597546881996e-05
step: 120, loss: 0.00010810929234139621
step: 130, loss: 4.520907168625854e-05
step: 140, loss: 2.7082080123363994e-05
step: 150, loss: 0.00011648481449810788
step: 160, loss: 0.0002796697954181582
step: 170, loss: 6.145628867670894e-05
step: 180, loss: 7.023358921287581e-05
step: 190, loss: 5.6392855185549706e-05
step: 200, loss: 4.886548776994459e-05
step: 210, loss: 7.386269862763584e-05
step: 220, loss: 2.4764764020801522e-05
step: 230, loss: 5.787513146060519e-05
step: 240, loss: 6.347701855702326e-05
step: 250, loss: 0.00025681720580905676
step: 260, loss: 3.834905874100514e-05
step: 270, loss: 3.5395849408814684e-05
step: 280, loss: 9.770917677087709e-05
step: 290, loss: 0.00029269198421388865
step: 300, loss: 0.0035560496617108583
step: 310, loss: 0.0004855383886024356
step: 320, loss: 0.00010746982297860086
step: 330, loss: 4.895392703474499e-05
step: 340, loss: 3.4196120395790786e-05
step: 350, loss: 0.00015061484009493142
step: 360, loss: 0.00010108556307386607
step: 370, loss: 7.598903903272003e-05
step: 380, loss: 8.713160059414804e-05
epoch 20: dev_f1=0.7461139896373058, f1=0.6101694915254237, best_f1=0.585635359116022
cuda
Device: cuda
step: 0, loss: 0.7544599175453186
step: 10, loss: 0.3673953711986542
step: 20, loss: 0.24331209063529968
step: 30, loss: 0.3180152475833893
step: 40, loss: 0.23994289338588715
step: 50, loss: 0.2750115692615509
step: 60, loss: 0.28219497203826904
step: 70, loss: 0.2198323756456375
step: 80, loss: 0.3990223705768585
step: 90, loss: 0.3458128571510315
step: 100, loss: 0.26213163137435913
step: 110, loss: 0.3949095904827118
step: 120, loss: 0.24831479787826538
step: 130, loss: 0.2422361671924591
step: 140, loss: 0.28390955924987793
step: 150, loss: 0.12878750264644623
step: 160, loss: 0.3263338506221771
step: 170, loss: 0.19103114306926727
step: 180, loss: 0.36227917671203613
step: 190, loss: 0.21986956894397736
step: 200, loss: 0.18321307003498077
step: 210, loss: 0.18241851031780243
step: 220, loss: 0.2622227966785431
step: 230, loss: 0.08500465750694275
step: 240, loss: 0.12146539241075516
step: 250, loss: 0.36943334341049194
step: 260, loss: 0.5077066421508789
step: 270, loss: 0.3144262433052063
step: 280, loss: 0.2388593554496765
step: 290, loss: 0.2426064908504486
step: 300, loss: 0.2163381427526474
step: 310, loss: 0.42539548873901367
step: 320, loss: 0.17177776992321014
step: 330, loss: 0.26539868116378784
step: 340, loss: 0.20981284976005554
step: 350, loss: 0.252878338098526
step: 360, loss: 0.1757245510816574
step: 370, loss: 0.3796229064464569
step: 380, loss: 0.15381143987178802
epoch 1: dev_f1=0.5149051490514904, f1=0.4057971014492754, best_f1=0.4057971014492754
step: 0, loss: 0.1277896910905838
step: 10, loss: 0.246959388256073
step: 20, loss: 0.10692935436964035
step: 30, loss: 0.29839324951171875
step: 40, loss: 0.16838862001895905
step: 50, loss: 0.2686527371406555
step: 60, loss: 0.07023714482784271
step: 70, loss: 0.17635244131088257
step: 80, loss: 0.17754705250263214
step: 90, loss: 0.1637433022260666
step: 100, loss: 0.17850345373153687
step: 110, loss: 0.13948744535446167
step: 120, loss: 0.24614760279655457
step: 130, loss: 0.13104908168315887
step: 140, loss: 0.49064895510673523
step: 150, loss: 0.15841077268123627
step: 160, loss: 0.5948812365531921
step: 170, loss: 0.16039519011974335
step: 180, loss: 0.18588697910308838
step: 190, loss: 0.1380128264427185
step: 200, loss: 0.2795100808143616
step: 210, loss: 0.3036040961742401
step: 220, loss: 0.1393740177154541
step: 230, loss: 0.0777738094329834
step: 240, loss: 0.21981453895568848
step: 250, loss: 0.18839029967784882
step: 260, loss: 0.14769107103347778
step: 270, loss: 0.2585219740867615
step: 280, loss: 0.07896944135427475
step: 290, loss: 0.033366333693265915
step: 300, loss: 0.022757474333047867
step: 310, loss: 0.30659061670303345
step: 320, loss: 0.23998083174228668
step: 330, loss: 0.1205519363284111
step: 340, loss: 0.03836144506931305
step: 350, loss: 0.3406240940093994
step: 360, loss: 0.073689304292202
step: 370, loss: 0.1001974567770958
step: 380, loss: 0.21654821932315826
epoch 2: dev_f1=0.6773333333333335, f1=0.5014409221902018, best_f1=0.5014409221902018
step: 0, loss: 0.05543087422847748
step: 10, loss: 0.20080530643463135
step: 20, loss: 0.13746699690818787
step: 30, loss: 0.07401008158922195
step: 40, loss: 0.19118168950080872
step: 50, loss: 0.07852689921855927
step: 60, loss: 0.08470799773931503
step: 70, loss: 0.13134242594242096
step: 80, loss: 0.22684094309806824
step: 90, loss: 0.06358976662158966
step: 100, loss: 0.2318599671125412
step: 110, loss: 0.058611419051885605
step: 120, loss: 0.2226945012807846
step: 130, loss: 0.07348965108394623
step: 140, loss: 0.11006495356559753
step: 150, loss: 0.28459861874580383
step: 160, loss: 0.03441765531897545
step: 170, loss: 0.023093275725841522
step: 180, loss: 0.06690690666437149
step: 190, loss: 0.12633974850177765
step: 200, loss: 0.11438757926225662
step: 210, loss: 0.1428387314081192
step: 220, loss: 0.16754770278930664
step: 230, loss: 0.08792097866535187
step: 240, loss: 0.08709530532360077
step: 250, loss: 0.30478373169898987
step: 260, loss: 0.1278342455625534
step: 270, loss: 0.02492312528192997
step: 280, loss: 0.07334818691015244
step: 290, loss: 0.11559975892305374
step: 300, loss: 0.07116810977458954
step: 310, loss: 0.014271109364926815
step: 320, loss: 0.1445411592721939
step: 330, loss: 0.01847381331026554
step: 340, loss: 0.04269677400588989
step: 350, loss: 0.14918282628059387
step: 360, loss: 0.04600375518202782
step: 370, loss: 0.044319987297058105
step: 380, loss: 0.16082145273685455
epoch 3: dev_f1=0.7616438356164383, f1=0.5903614457831325, best_f1=0.5903614457831325
step: 0, loss: 0.08256981521844864
step: 10, loss: 0.035145413130521774
step: 20, loss: 0.08740454167127609
step: 30, loss: 0.17194902896881104
step: 40, loss: 0.0380900539457798
step: 50, loss: 0.07339035719633102
step: 60, loss: 0.011612248606979847
step: 70, loss: 0.1233510673046112
step: 80, loss: 0.14558957517147064
step: 90, loss: 0.013893221504986286
step: 100, loss: 0.02017039619386196
step: 110, loss: 0.07012386620044708
step: 120, loss: 0.08271073549985886
step: 130, loss: 0.13316671550273895
step: 140, loss: 0.040133170783519745
step: 150, loss: 0.01922568678855896
step: 160, loss: 0.10506907105445862
step: 170, loss: 0.1542031615972519
step: 180, loss: 0.042656172066926956
step: 190, loss: 0.025485221296548843
step: 200, loss: 0.028542647138237953
step: 210, loss: 0.04113328829407692
step: 220, loss: 0.16389529407024384
step: 230, loss: 0.013753184117376804
step: 240, loss: 0.2327735275030136
step: 250, loss: 0.1624758392572403
step: 260, loss: 0.017831461504101753
step: 270, loss: 0.1310397982597351
step: 280, loss: 0.007037055678665638
step: 290, loss: 0.29811176657676697
step: 300, loss: 0.044152453541755676
step: 310, loss: 0.003206397872418165
step: 320, loss: 0.0422830730676651
step: 330, loss: 0.10072311013936996
step: 340, loss: 0.05065502971410751
step: 350, loss: 0.15593673288822174
step: 360, loss: 0.15762364864349365
step: 370, loss: 0.04057303071022034
step: 380, loss: 0.04285633936524391
epoch 4: dev_f1=0.7657142857142857, f1=0.5867507886435331, best_f1=0.5867507886435331
step: 0, loss: 0.1554626226425171
step: 10, loss: 0.016261432319879532
step: 20, loss: 0.08996889740228653
step: 30, loss: 0.12274397909641266
step: 40, loss: 0.023199744522571564
step: 50, loss: 0.0019336831755936146
step: 60, loss: 0.07056231796741486
step: 70, loss: 0.020938536152243614
step: 80, loss: 0.011827321723103523
step: 90, loss: 0.012437550351023674
step: 100, loss: 0.041963499039411545
step: 110, loss: 0.089896060526371
step: 120, loss: 0.03376859053969383
step: 130, loss: 0.007991445250809193
step: 140, loss: 0.009123161435127258
step: 150, loss: 0.022006923332810402
step: 160, loss: 0.2036607712507248
step: 170, loss: 0.010714623145759106
step: 180, loss: 0.06862576305866241
step: 190, loss: 0.020868655294179916
step: 200, loss: 0.06611569225788116
step: 210, loss: 0.013350093737244606
step: 220, loss: 0.03764316812157631
step: 230, loss: 0.022577691823244095
step: 240, loss: 0.0721096619963646
step: 250, loss: 0.009664002805948257
step: 260, loss: 0.013470661826431751
step: 270, loss: 0.053675804287195206
step: 280, loss: 0.01983119174838066
step: 290, loss: 0.10942038893699646
step: 300, loss: 0.13108614087104797
step: 310, loss: 0.08297260105609894
step: 320, loss: 0.0102353785187006
step: 330, loss: 0.03307317942380905
step: 340, loss: 0.023256681859493256
step: 350, loss: 0.017765533179044724
step: 360, loss: 0.06587035208940506
step: 370, loss: 0.00898391380906105
step: 380, loss: 0.08420928567647934
epoch 5: dev_f1=0.7244094488188976, f1=0.5263157894736842, best_f1=0.5867507886435331
step: 0, loss: 0.034279800951480865
step: 10, loss: 0.07425761967897415
step: 20, loss: 0.051428601145744324
step: 30, loss: 0.011579947546124458
step: 40, loss: 0.11826151609420776
step: 50, loss: 0.055706240236759186
step: 60, loss: 0.028874991461634636
step: 70, loss: 0.16954852640628815
step: 80, loss: 0.13290993869304657
step: 90, loss: 0.04264920577406883
step: 100, loss: 0.020691540092229843
step: 110, loss: 0.050416938960552216
step: 120, loss: 0.27918046712875366
step: 130, loss: 0.003775435034185648
step: 140, loss: 0.0037686980795115232
step: 150, loss: 0.18215185403823853
step: 160, loss: 0.003648363519459963
step: 170, loss: 0.007472554221749306
step: 180, loss: 0.003101770533248782
step: 190, loss: 0.004236273001879454
step: 200, loss: 0.021106107160449028
step: 210, loss: 0.051283255219459534
step: 220, loss: 0.06783036887645721
step: 230, loss: 0.027319740504026413
step: 240, loss: 0.0012545872014015913
step: 250, loss: 0.020545903593301773
step: 260, loss: 0.004858985543251038
step: 270, loss: 0.0010356245329603553
step: 280, loss: 0.007777652703225613
step: 290, loss: 0.14446064829826355
step: 300, loss: 0.08696696162223816
step: 310, loss: 0.004553218372166157
step: 320, loss: 0.004206153564155102
step: 330, loss: 0.0014975578524172306
step: 340, loss: 0.003416347550228238
step: 350, loss: 0.014177526347339153
step: 360, loss: 0.014183739200234413
step: 370, loss: 0.0022316481918096542
step: 380, loss: 0.010403669439256191
epoch 6: dev_f1=0.7712765957446809, f1=0.585635359116022, best_f1=0.585635359116022
step: 0, loss: 0.0010405706707388163
step: 10, loss: 0.0027785382699221373
step: 20, loss: 0.001879911171272397
step: 30, loss: 0.027716245502233505
step: 40, loss: 0.0770011693239212
step: 50, loss: 0.13588054478168488
step: 60, loss: 0.02106308937072754
step: 70, loss: 0.024923328310251236
step: 80, loss: 0.01807660423219204
step: 90, loss: 0.01085034292191267
step: 100, loss: 0.012104600667953491
step: 110, loss: 0.007706109434366226
step: 120, loss: 0.005954073276370764
step: 130, loss: 0.010608445852994919
step: 140, loss: 0.002817358123138547
step: 150, loss: 0.0028767564799636602
step: 160, loss: 0.001412144978530705
step: 170, loss: 0.0018144040368497372
step: 180, loss: 0.005803683772683144
step: 190, loss: 0.0039218426682055
step: 200, loss: 0.007431806530803442
step: 210, loss: 0.0038561751134693623
step: 220, loss: 0.0021358581725507975
step: 230, loss: 0.004963325336575508
step: 240, loss: 0.2051367610692978
step: 250, loss: 0.04492069408297539
step: 260, loss: 0.011612644419074059
step: 270, loss: 0.015817081555724144
step: 280, loss: 0.03244135528802872
step: 290, loss: 0.0006502685719169676
step: 300, loss: 0.000665895757265389
step: 310, loss: 0.0031009309459477663
step: 320, loss: 0.009853938594460487
step: 330, loss: 0.08850187808275223
step: 340, loss: 0.01597670093178749
step: 350, loss: 0.043915487825870514
step: 360, loss: 0.056035056710243225
step: 370, loss: 0.004634570330381393
step: 380, loss: 0.026044946163892746
epoch 7: dev_f1=0.7545219638242895, f1=0.6214689265536724, best_f1=0.585635359116022
step: 0, loss: 0.046745866537094116
step: 10, loss: 0.03630049154162407
step: 20, loss: 0.008378705009818077
step: 30, loss: 0.006403123959898949
step: 40, loss: 0.04439781233668327
step: 50, loss: 0.0012209805427119136
step: 60, loss: 0.10556982457637787
step: 70, loss: 0.007021108642220497
step: 80, loss: 0.003059175331145525
step: 90, loss: 0.0009930768283084035
step: 100, loss: 0.0037044130731374025
step: 110, loss: 0.02937074936926365
step: 120, loss: 0.055790457874536514
step: 130, loss: 0.01437052246183157
step: 140, loss: 0.01917833462357521
step: 150, loss: 0.22491306066513062
step: 160, loss: 0.003090948099270463
step: 170, loss: 0.008874019607901573
step: 180, loss: 0.09318802505731583
step: 190, loss: 0.001846800441853702
step: 200, loss: 0.033325642347335815
step: 210, loss: 0.04009309038519859
step: 220, loss: 0.0024650178384035826
step: 230, loss: 0.0041023800149559975
step: 240, loss: 0.0007297408301383257
step: 250, loss: 0.0007780383457429707
step: 260, loss: 0.1274821013212204
step: 270, loss: 0.0037260232493281364
step: 280, loss: 0.0004852601559832692
step: 290, loss: 0.022409381344914436
step: 300, loss: 0.0007280198624357581
step: 310, loss: 0.0008201450691558421
step: 320, loss: 0.06386376917362213
step: 330, loss: 0.0069151767529547215
step: 340, loss: 0.03319963067770004
step: 350, loss: 0.0018858577823266387
step: 360, loss: 0.013498986139893532
step: 370, loss: 0.008816785179078579
step: 380, loss: 0.03622175753116608
epoch 8: dev_f1=0.7633587786259541, f1=0.6683937823834197, best_f1=0.585635359116022
step: 0, loss: 0.08516404032707214
step: 10, loss: 0.005270487163215876
step: 20, loss: 0.001316289184615016
step: 30, loss: 0.02006145566701889
step: 40, loss: 0.006486416794359684
step: 50, loss: 0.0003851373912766576
step: 60, loss: 0.0003882492601405829
step: 70, loss: 0.014979057013988495
step: 80, loss: 0.08390043675899506
step: 90, loss: 0.002569598611444235
step: 100, loss: 0.0005356030305847526
step: 110, loss: 0.006239633541554213
step: 120, loss: 0.0011462209513410926
step: 130, loss: 0.0010590628953650594
step: 140, loss: 0.0580042339861393
step: 150, loss: 0.018899476155638695
step: 160, loss: 0.03952888026833534
step: 170, loss: 0.02612859383225441
step: 180, loss: 0.00024583181948401034
step: 190, loss: 0.01445818692445755
step: 200, loss: 0.004829456098377705
step: 210, loss: 0.004191935993731022
step: 220, loss: 0.005290580447763205
step: 230, loss: 0.0009562392369844019
step: 240, loss: 0.022560948505997658
step: 250, loss: 0.012924008071422577
step: 260, loss: 0.0010442902566865087
step: 270, loss: 0.0015384717844426632
step: 280, loss: 0.0034956932067871094
step: 290, loss: 0.0003678238426800817
step: 300, loss: 0.011253981851041317
step: 310, loss: 0.00022704704315401614
step: 320, loss: 0.021592838689684868
step: 330, loss: 0.016277870163321495
step: 340, loss: 0.002424829173833132
step: 350, loss: 0.0007927819387987256
step: 360, loss: 0.0021538319997489452
step: 370, loss: 0.014729971066117287
step: 380, loss: 0.0190731231123209
epoch 9: dev_f1=0.7333333333333334, f1=0.6073298429319371, best_f1=0.585635359116022
step: 0, loss: 0.0004139455850236118
step: 10, loss: 0.0006126281223259866
step: 20, loss: 0.0002283745416207239
step: 30, loss: 0.00042463038698770106
step: 40, loss: 0.0012226561084389687
step: 50, loss: 0.0003733892517630011
step: 60, loss: 0.014818507246673107
step: 70, loss: 0.017008282244205475
step: 80, loss: 0.0038872533477842808
step: 90, loss: 0.01621527597308159
step: 100, loss: 0.011419611051678658
step: 110, loss: 0.0005231225513853133
step: 120, loss: 0.0006855218671262264
step: 130, loss: 0.0005134398234076798
step: 140, loss: 0.0005090744816698134
step: 150, loss: 0.0002639868180267513
step: 160, loss: 0.0006818198598921299
step: 170, loss: 0.00028030225075781345
step: 180, loss: 0.005231533199548721
step: 190, loss: 0.0001722103334031999
step: 200, loss: 0.0003923435288015753
step: 210, loss: 0.004867649171501398
step: 220, loss: 0.0004316098056733608
step: 230, loss: 0.0037376752588897943
step: 240, loss: 0.0004385779320728034
step: 250, loss: 0.010092023760080338
step: 260, loss: 0.00021566564100794494
step: 270, loss: 0.0005211894167587161
step: 280, loss: 0.014644193463027477
step: 290, loss: 0.020029082894325256
step: 300, loss: 0.009143006056547165
step: 310, loss: 0.0017328301910310984
step: 320, loss: 0.007208629976958036
step: 330, loss: 0.0015580563340336084
step: 340, loss: 0.048751648515462875
step: 350, loss: 0.0024049568455666304
step: 360, loss: 0.0003564915677998215
step: 370, loss: 0.00014685452333651483
step: 380, loss: 0.0006339769461192191
epoch 10: dev_f1=0.7512953367875648, f1=0.6263736263736264, best_f1=0.585635359116022
step: 0, loss: 0.0012286927085369825
step: 10, loss: 0.0008771241991780698
step: 20, loss: 0.0010965528199449182
step: 30, loss: 0.002316300058737397
step: 40, loss: 0.00401727482676506
step: 50, loss: 0.006973060313612223
step: 60, loss: 0.007299944758415222
step: 70, loss: 0.005883526522666216
step: 80, loss: 0.0061906264163553715
step: 90, loss: 0.0017872772878035903
step: 100, loss: 0.0006966129294596612
step: 110, loss: 0.0044945464469492435
step: 120, loss: 0.0014721769839525223
step: 130, loss: 0.002930818824097514
step: 140, loss: 0.0004035375313833356
step: 150, loss: 0.004723930731415749
step: 160, loss: 0.0014570999192073941
step: 170, loss: 0.003653955878689885
step: 180, loss: 0.002589461160823703
step: 190, loss: 0.0015084219630807638
step: 200, loss: 0.001509765163064003
step: 210, loss: 0.002386881737038493
step: 220, loss: 0.001065271208062768
step: 230, loss: 0.0007908900151960552
step: 240, loss: 0.00014281427138485014
step: 250, loss: 0.0002349877031520009
step: 260, loss: 0.000636290293186903
step: 270, loss: 0.0001275537651963532
step: 280, loss: 0.0014762531500309706
step: 290, loss: 0.0030825173016637564
step: 300, loss: 0.0024157019797712564
step: 310, loss: 0.00010883513459702954
step: 320, loss: 0.00019168433209415525
step: 330, loss: 0.012532845139503479
step: 340, loss: 0.0008169858483597636
step: 350, loss: 0.0007862098282203078
step: 360, loss: 0.003148360876366496
step: 370, loss: 0.00023148651234805584
step: 380, loss: 0.00015736339264549315
epoch 11: dev_f1=0.753315649867374, f1=0.5842696629213484, best_f1=0.585635359116022
step: 0, loss: 0.003182400716468692
step: 10, loss: 0.0018881441792473197
step: 20, loss: 0.00023144624719861895
step: 30, loss: 0.00031109582050703466
step: 40, loss: 0.001251151436008513
step: 50, loss: 0.07924728840589523
step: 60, loss: 0.0031411806121468544
step: 70, loss: 0.007240384351462126
step: 80, loss: 0.000562715926207602
step: 90, loss: 0.0002725510857999325
step: 100, loss: 0.0018404917791485786
step: 110, loss: 0.0006784911965951324
step: 120, loss: 0.00014195858966559172
step: 130, loss: 8.637253631604835e-05
step: 140, loss: 0.0004234809020999819
step: 150, loss: 0.00278098089620471
step: 160, loss: 0.00026784223155118525
step: 170, loss: 0.0034897129517048597
step: 180, loss: 0.0005128335324116051
step: 190, loss: 0.0009378199465572834
step: 200, loss: 0.00018021171854343265
step: 210, loss: 0.0010673085926100612
step: 220, loss: 0.0008656858699396253
step: 230, loss: 0.00014547319733537734
step: 240, loss: 0.00019380063167773187
step: 250, loss: 0.01593891717493534
step: 260, loss: 0.00012594678264576942
step: 270, loss: 0.012244015000760555
step: 280, loss: 0.0001492653536843136
step: 290, loss: 0.006685405969619751
step: 300, loss: 0.023215385153889656
step: 310, loss: 0.00011247191287111491
step: 320, loss: 0.0014159738784655929
step: 330, loss: 0.0010117654455825686
step: 340, loss: 0.004894911777228117
step: 350, loss: 0.0002417104842606932
step: 360, loss: 0.00016251612396445125
step: 370, loss: 7.680479757254943e-05
step: 380, loss: 0.0006221404182724655
epoch 12: dev_f1=0.7553191489361701, f1=0.5959885386819485, best_f1=0.585635359116022
step: 0, loss: 0.0011980485869571567
step: 10, loss: 0.0011254895944148302
step: 20, loss: 0.0002733127912506461
step: 30, loss: 4.3587635445874184e-05
step: 40, loss: 0.00020490727911237627
step: 50, loss: 3.7124405935173854e-05
step: 60, loss: 0.0001751677191350609
step: 70, loss: 0.0465417318046093
step: 80, loss: 0.0014736574376001954
step: 90, loss: 0.00029915678896941245
step: 100, loss: 0.0017637269338592887
step: 110, loss: 0.0002906436857301742
step: 120, loss: 0.0938955694437027
step: 130, loss: 0.00017144321464002132
step: 140, loss: 0.00022849331435281783
step: 150, loss: 0.0013167373836040497
step: 160, loss: 0.00013975168985780329
step: 170, loss: 0.019754868000745773
step: 180, loss: 0.0010723929153755307
step: 190, loss: 4.0342234569834545e-05
step: 200, loss: 8.969828923000023e-05
step: 210, loss: 0.0014841171214357018
step: 220, loss: 0.001004670630209148
step: 230, loss: 0.0003931645769625902
step: 240, loss: 0.00012165656517026946
step: 250, loss: 0.0002802945382427424
step: 260, loss: 0.0001974570332095027
step: 270, loss: 0.0004967681597918272
step: 280, loss: 8.144012099364772e-05
step: 290, loss: 0.0022049113176763058
step: 300, loss: 0.009600246325135231
step: 310, loss: 0.00011176134285051376
step: 320, loss: 0.00013443453644867986
step: 330, loss: 0.00258749071508646
step: 340, loss: 0.0010482878424227238
step: 350, loss: 0.0015095982234925032
step: 360, loss: 0.018253080546855927
step: 370, loss: 0.00013271908392198384
step: 380, loss: 0.012476843781769276
epoch 13: dev_f1=0.7676767676767676, f1=0.6263157894736843, best_f1=0.585635359116022
step: 0, loss: 0.0008105713641270995
step: 10, loss: 0.00024803882115520537
step: 20, loss: 0.00034207606222480536
step: 30, loss: 0.0001907738042064011
step: 40, loss: 0.0011281814659014344
step: 50, loss: 0.0005679230089299381
step: 60, loss: 0.00014755142910871655
step: 70, loss: 9.527941438136622e-05
step: 80, loss: 0.0015933136455714703
step: 90, loss: 0.0001484482636442408
step: 100, loss: 7.11572211002931e-05
step: 110, loss: 0.0031817795243114233
step: 120, loss: 3.671070953714661e-05
step: 130, loss: 0.0007128911092877388
step: 140, loss: 0.005300433840602636
step: 150, loss: 0.0035838978365063667
step: 160, loss: 0.000497097207698971
step: 170, loss: 0.012821914628148079
step: 180, loss: 0.0015088665531948209
step: 190, loss: 0.00012881436850875616
step: 200, loss: 0.0008868749719113111
step: 210, loss: 0.0008416972123086452
step: 220, loss: 0.010192958638072014
step: 230, loss: 5.847806460224092e-05
step: 240, loss: 0.000445713842054829
step: 250, loss: 0.00029633985832333565
step: 260, loss: 0.0004910115385428071
step: 270, loss: 0.007341178599745035
step: 280, loss: 2.5640716557973064e-05
step: 290, loss: 5.917442467762157e-05
step: 300, loss: 0.0008239531889557838
step: 310, loss: 0.0006117064622230828
step: 320, loss: 8.100249397102743e-05
step: 330, loss: 0.00013955986651126295
step: 340, loss: 0.00017188623314723372
step: 350, loss: 0.0010068422416225076
step: 360, loss: 5.825352855026722e-05
step: 370, loss: 0.0002306545793544501
step: 380, loss: 0.006850902922451496
epoch 14: dev_f1=0.6607142857142857, f1=0.5477707006369427, best_f1=0.585635359116022
step: 0, loss: 0.00020502843835856766
step: 10, loss: 0.015619281679391861
step: 20, loss: 0.0007081920630298555
step: 30, loss: 0.00023915324709378183
step: 40, loss: 0.0006905206828378141
step: 50, loss: 0.00017925037536770105
step: 60, loss: 0.08632507175207138
step: 70, loss: 0.0005619722069241107
step: 80, loss: 0.00816500186920166
step: 90, loss: 0.0006555295549333096
step: 100, loss: 0.00011255622666794807
step: 110, loss: 0.0027203282807022333
step: 120, loss: 0.013795538805425167
step: 130, loss: 0.00020555590162985027
step: 140, loss: 0.00011978333350270987
step: 150, loss: 0.0003382383147254586
step: 160, loss: 4.2384330299682915e-05
step: 170, loss: 0.0020685698837041855
step: 180, loss: 0.0006959611782804132
step: 190, loss: 0.0005581845762208104
step: 200, loss: 0.00020459310326259583
step: 210, loss: 0.00015023766900412738
step: 220, loss: 8.075235382420942e-05
step: 230, loss: 0.008773460984230042
step: 240, loss: 6.99083466315642e-05
step: 250, loss: 0.0005497405654750764
step: 260, loss: 4.0935050492407754e-05
step: 270, loss: 0.00013045627565588802
step: 280, loss: 0.00020678179862443358
step: 290, loss: 0.0009115299326367676
step: 300, loss: 3.583609213819727e-05
step: 310, loss: 0.0009005485917441547
step: 320, loss: 5.495188815984875e-05
step: 330, loss: 0.003810666035860777
step: 340, loss: 0.002006452064961195
step: 350, loss: 0.042818985879421234
step: 360, loss: 0.0050858864560723305
step: 370, loss: 0.0006325379945337772
step: 380, loss: 5.971219434286468e-05
epoch 15: dev_f1=0.745308310991957, f1=0.6361031518624642, best_f1=0.585635359116022
step: 0, loss: 0.0020252589602023363
step: 10, loss: 0.00021825189469382167
step: 20, loss: 0.0003135243314318359
step: 30, loss: 0.00016756003606133163
step: 40, loss: 0.0061455657705664635
step: 50, loss: 0.0009160572080872953
step: 60, loss: 0.03825795650482178
step: 70, loss: 0.00013961353397462517
step: 80, loss: 0.0010716189863160253
step: 90, loss: 0.00016520972712896764
step: 100, loss: 0.003086454700678587
step: 110, loss: 0.003606714541092515
step: 120, loss: 0.000532916805241257
step: 130, loss: 0.0015880297869443893
step: 140, loss: 0.1360703557729721
step: 150, loss: 0.00014116085367277265
step: 160, loss: 0.000860314816236496
step: 170, loss: 0.00010211912012891844
step: 180, loss: 0.0004618763632606715
step: 190, loss: 6.45285690552555e-05
step: 200, loss: 0.00035303039476275444
step: 210, loss: 0.0002125832688761875
step: 220, loss: 0.00359502830542624
step: 230, loss: 0.0001928001584019512
step: 240, loss: 0.0002448716259095818
step: 250, loss: 0.001021378324367106
step: 260, loss: 0.0001459714985685423
step: 270, loss: 0.0011776142055168748
step: 280, loss: 0.01215366367250681
step: 290, loss: 0.00012665770191233605
step: 300, loss: 0.00012184400111436844
step: 310, loss: 3.129087053821422e-05
step: 320, loss: 8.285931835416704e-05
step: 330, loss: 9.249695722246543e-05
step: 340, loss: 0.0006787810125388205
step: 350, loss: 0.0003555840521585196
step: 360, loss: 2.6299872843082994e-05
step: 370, loss: 2.3051728931022808e-05
step: 380, loss: 0.0002605015179142356
epoch 16: dev_f1=0.7430025445292621, f1=0.6166666666666667, best_f1=0.585635359116022
step: 0, loss: 0.0008410449954681098
step: 10, loss: 9.813807264436036e-05
step: 20, loss: 0.0031823923345655203
step: 30, loss: 0.03486962616443634
step: 40, loss: 4.142985926591791e-05
step: 50, loss: 0.00016460249025840312
step: 60, loss: 0.0021179544273763895
step: 70, loss: 0.00023784257064107805
step: 80, loss: 0.00028947379905730486
step: 90, loss: 0.0027250663843005896
step: 100, loss: 0.003246230771765113
step: 110, loss: 0.0006466108607128263
step: 120, loss: 9.438082634005696e-05
step: 130, loss: 0.00021032406948506832
step: 140, loss: 0.0005775426980108023
step: 150, loss: 0.00013426374061964452
step: 160, loss: 4.183415148872882e-05
step: 170, loss: 0.0002786906261462718
step: 180, loss: 2.6992640414391644e-05
step: 190, loss: 0.00011561487190192565
step: 200, loss: 0.00028707386809401214
step: 210, loss: 4.1062001400860026e-05
step: 220, loss: 0.00017620109429117292
step: 230, loss: 8.636911661596969e-05
step: 240, loss: 0.0007374139968305826
step: 250, loss: 0.0033317033667117357
step: 260, loss: 0.00013308953202795237
step: 270, loss: 6.513659172924235e-05
step: 280, loss: 0.0028914716094732285
step: 290, loss: 0.0003845067403744906
step: 300, loss: 0.0008245721692219377
step: 310, loss: 0.0018346745055168867
step: 320, loss: 0.0030089751817286015
step: 330, loss: 0.00011161994916619733
step: 340, loss: 0.00011755813466152176
step: 350, loss: 0.0028933922294527292
step: 360, loss: 4.606590300682001e-05
step: 370, loss: 0.010798472911119461
step: 380, loss: 2.5610321245039813e-05
epoch 17: dev_f1=0.7591623036649214, f1=0.6228571428571429, best_f1=0.585635359116022
step: 0, loss: 0.00012238182534929365
step: 10, loss: 4.0863509639166296e-05
step: 20, loss: 8.389858703594655e-05
step: 30, loss: 3.6095389077672735e-05
step: 40, loss: 7.690864003961906e-05
step: 50, loss: 0.00016607156430836767
step: 60, loss: 0.0008529031765647233
step: 70, loss: 0.0001565765996929258
step: 80, loss: 5.9460591728566214e-05
step: 90, loss: 0.00024266343098133802
step: 100, loss: 0.002319237682968378
step: 110, loss: 0.000365480751497671
step: 120, loss: 3.3589021768420935e-05
step: 130, loss: 3.922451287508011e-05
step: 140, loss: 0.00015444365271832794
step: 150, loss: 3.6874451325275004e-05
step: 160, loss: 0.0025430098176002502
step: 170, loss: 3.276618372183293e-05
step: 180, loss: 0.0001483454689150676
step: 190, loss: 0.0006465556798502803
step: 200, loss: 0.0003625921963248402
step: 210, loss: 3.754531280719675e-05
step: 220, loss: 0.00015298342623282224
step: 230, loss: 9.640257485443726e-05
step: 240, loss: 0.0002834329498000443
step: 250, loss: 0.00013329947250895202
step: 260, loss: 6.613189907511696e-05
step: 270, loss: 0.00015923139289952815
step: 280, loss: 0.0001859792391769588
step: 290, loss: 3.7612018786603585e-05
step: 300, loss: 3.1120081985136494e-05
step: 310, loss: 0.000946053653024137
step: 320, loss: 2.9197723051765934e-05
step: 330, loss: 4.6685676352353767e-05
step: 340, loss: 0.0010502715595066547
step: 350, loss: 0.00033838010858744383
step: 360, loss: 0.0003343616263009608
step: 370, loss: 3.596596070565283e-05
step: 380, loss: 0.007439999841153622
epoch 18: dev_f1=0.746031746031746, f1=0.573913043478261, best_f1=0.585635359116022
step: 0, loss: 9.687676356406882e-05
step: 10, loss: 2.1110772649990395e-05
step: 20, loss: 0.00011855539923999459
step: 30, loss: 0.00013874431897420436
step: 40, loss: 4.777006324729882e-05
step: 50, loss: 0.00018645905947778374
step: 60, loss: 2.1554107661359012e-05
step: 70, loss: 4.586733484757133e-05
step: 80, loss: 0.0010906349634751678
step: 90, loss: 0.00027182954363524914
step: 100, loss: 2.5305072995251976e-05
step: 110, loss: 3.804414882324636e-05
step: 120, loss: 0.0001443917426513508
step: 130, loss: 2.4355154891964048e-05
step: 140, loss: 0.024942275136709213
step: 150, loss: 4.8990776122082025e-05
step: 160, loss: 0.00033427952439524233
step: 170, loss: 7.088141865096986e-05
step: 180, loss: 0.0007644485449418426
step: 190, loss: 4.0382463339483365e-05
step: 200, loss: 0.0008224844932556152
step: 210, loss: 0.002136659575626254
step: 220, loss: 9.83196368906647e-05
step: 230, loss: 0.00010381062747910619
step: 240, loss: 6.460752047132701e-05
step: 250, loss: 0.0001978499349206686
step: 260, loss: 0.00011358450137777254
step: 270, loss: 0.000120927368698176
step: 280, loss: 1.839894503063988e-05
step: 290, loss: 3.5450426366878673e-05
step: 300, loss: 5.317985778674483e-05
step: 310, loss: 0.00011495518265292048
step: 320, loss: 4.982604514225386e-05
step: 330, loss: 0.008326194249093533
step: 340, loss: 3.8457488699350506e-05
step: 350, loss: 2.776320616248995e-05
step: 360, loss: 0.000502411974593997
step: 370, loss: 3.126145020360127e-05
step: 380, loss: 0.0008338019251823425
epoch 19: dev_f1=0.7467362924281985, f1=0.603988603988604, best_f1=0.585635359116022
step: 0, loss: 5.8266959968023e-05
step: 10, loss: 0.0001513318275101483
step: 20, loss: 0.06624290347099304
step: 30, loss: 0.003304604906588793
step: 40, loss: 4.876230377703905e-05
step: 50, loss: 5.0219310651300475e-05
step: 60, loss: 4.45352889073547e-05
step: 70, loss: 5.047080776421353e-05
step: 80, loss: 8.445548883173615e-05
step: 90, loss: 0.00011959215044043958
step: 100, loss: 9.485855844104663e-05
step: 110, loss: 3.379597546881996e-05
step: 120, loss: 0.00010810929234139621
step: 130, loss: 4.520907168625854e-05
step: 140, loss: 2.7082080123363994e-05
step: 150, loss: 0.00011648481449810788
step: 160, loss: 0.0002796697954181582
step: 170, loss: 6.145628867670894e-05
step: 180, loss: 7.023358921287581e-05
step: 190, loss: 5.6392855185549706e-05
step: 200, loss: 4.886548776994459e-05
step: 210, loss: 7.386269862763584e-05
step: 220, loss: 2.4764764020801522e-05
step: 230, loss: 5.787513146060519e-05
step: 240, loss: 6.347701855702326e-05
step: 250, loss: 0.00025681720580905676
step: 260, loss: 3.834905874100514e-05
step: 270, loss: 3.5395849408814684e-05
step: 280, loss: 9.770917677087709e-05
step: 290, loss: 0.00029269198421388865
step: 300, loss: 0.0035560496617108583
step: 310, loss: 0.0004855383886024356
step: 320, loss: 0.00010746982297860086
step: 330, loss: 4.895392703474499e-05
step: 340, loss: 3.4196120395790786e-05
step: 350, loss: 0.00015061484009493142
step: 360, loss: 0.00010108556307386607
step: 370, loss: 7.598903903272003e-05
step: 380, loss: 8.713160059414804e-05
epoch 20: dev_f1=0.7461139896373058, f1=0.6101694915254237, best_f1=0.585635359116022
