cuda
Device: cuda
step: 0, loss: 0.6328826546669006
step: 10, loss: 0.6479628682136536
step: 20, loss: 0.22322499752044678
step: 30, loss: 0.22635795176029205
step: 40, loss: 0.30036166310310364
step: 50, loss: 0.3379296660423279
step: 60, loss: 0.34110748767852783
step: 70, loss: 0.24938276410102844
step: 80, loss: 0.06360795348882675
step: 90, loss: 0.2853391468524933
step: 100, loss: 0.27843502163887024
step: 110, loss: 0.23452900350093842
step: 120, loss: 0.5284700989723206
step: 130, loss: 0.23625947535037994
step: 140, loss: 0.19781722128391266
step: 150, loss: 0.3019693195819855
step: 160, loss: 0.12006910145282745
step: 170, loss: 0.22004421055316925
step: 180, loss: 0.22658851742744446
step: 190, loss: 0.43624284863471985
step: 200, loss: 0.1311171054840088
step: 210, loss: 0.3034113645553589
step: 220, loss: 0.3102070987224579
step: 230, loss: 0.39787015318870544
step: 240, loss: 0.5652651190757751
step: 250, loss: 0.3666418790817261
step: 260, loss: 0.2321016788482666
step: 270, loss: 0.40869393944740295
step: 280, loss: 0.22405952215194702
step: 290, loss: 0.21928735077381134
step: 300, loss: 0.22380150854587555
step: 310, loss: 0.21037107706069946
step: 320, loss: 0.12093459814786911
step: 330, loss: 0.2555508017539978
step: 340, loss: 0.31487518548965454
step: 350, loss: 0.2197178602218628
step: 360, loss: 0.2940342426300049
step: 370, loss: 0.24504119157791138
step: 380, loss: 0.17497821152210236
epoch 1: dev_f1=0.5723076923076923, f1=0.47468354430379744, best_f1=0.47468354430379744
step: 0, loss: 0.17544764280319214
step: 10, loss: 0.200911283493042
step: 20, loss: 0.16677461564540863
step: 30, loss: 0.21343082189559937
step: 40, loss: 0.04370933398604393
step: 50, loss: 0.30033645033836365
step: 60, loss: 0.23888139426708221
step: 70, loss: 0.15832091867923737
step: 80, loss: 0.10433310270309448
step: 90, loss: 0.16847151517868042
step: 100, loss: 0.36946824193000793
step: 110, loss: 0.15872932970523834
step: 120, loss: 0.2073032408952713
step: 130, loss: 0.07175832986831665
step: 140, loss: 0.18368208408355713
step: 150, loss: 0.3138521909713745
step: 160, loss: 0.16915754973888397
step: 170, loss: 0.17960281670093536
step: 180, loss: 0.08501061797142029
step: 190, loss: 0.21197474002838135
step: 200, loss: 0.12977485358715057
step: 210, loss: 0.338544100522995
step: 220, loss: 0.2799973785877228
step: 230, loss: 0.3336542546749115
step: 240, loss: 0.07519455254077911
step: 250, loss: 0.32707276940345764
step: 260, loss: 0.15755899250507355
step: 270, loss: 0.24618293344974518
step: 280, loss: 0.1214936375617981
step: 290, loss: 0.21899157762527466
step: 300, loss: 0.1711582988500595
step: 310, loss: 0.04322380572557449
step: 320, loss: 0.24506522715091705
step: 330, loss: 0.06276611238718033
step: 340, loss: 0.16188250482082367
step: 350, loss: 0.15481378138065338
step: 360, loss: 0.22657184302806854
step: 370, loss: 0.3763089179992676
step: 380, loss: 0.1794954091310501
epoch 2: dev_f1=0.7150259067357513, f1=0.5531914893617023, best_f1=0.5531914893617023
step: 0, loss: 0.15913760662078857
step: 10, loss: 0.10531534999608994
step: 20, loss: 0.05639037862420082
step: 30, loss: 0.10082229226827621
step: 40, loss: 0.06142211705446243
step: 50, loss: 0.09679092466831207
step: 60, loss: 0.07993019372224808
step: 70, loss: 0.11039762198925018
step: 80, loss: 0.17870336771011353
step: 90, loss: 0.14180438220500946
step: 100, loss: 0.025086358189582825
step: 110, loss: 0.20926235616207123
step: 120, loss: 0.3087082803249359
step: 130, loss: 0.12340214848518372
step: 140, loss: 0.2300703525543213
step: 150, loss: 0.031401488929986954
step: 160, loss: 0.12861420214176178
step: 170, loss: 0.1921868771314621
step: 180, loss: 0.06892868131399155
step: 190, loss: 0.055921170860528946
step: 200, loss: 0.19793078303337097
step: 210, loss: 0.06733758747577667
step: 220, loss: 0.09975703060626984
step: 230, loss: 0.25170838832855225
step: 240, loss: 0.026770122349262238
step: 250, loss: 0.14089728891849518
step: 260, loss: 0.05750300735235214
step: 270, loss: 0.08232086896896362
step: 280, loss: 0.20705963671207428
step: 290, loss: 0.2043417990207672
step: 300, loss: 0.059405144304037094
step: 310, loss: 0.07955380529165268
step: 320, loss: 0.22632813453674316
step: 330, loss: 0.040815569460392
step: 340, loss: 0.08847362548112869
step: 350, loss: 0.14982283115386963
step: 360, loss: 0.02368493191897869
step: 370, loss: 0.23887866735458374
step: 380, loss: 0.05837487056851387
epoch 3: dev_f1=0.7577937649880095, f1=0.6253229974160207, best_f1=0.6253229974160207
step: 0, loss: 0.21472886204719543
step: 10, loss: 0.04041264206171036
step: 20, loss: 0.07605977356433868
step: 30, loss: 0.10511273145675659
step: 40, loss: 0.05297587066888809
step: 50, loss: 0.07135416567325592
step: 60, loss: 0.1961996853351593
step: 70, loss: 0.1462422013282776
step: 80, loss: 0.028813570737838745
step: 90, loss: 0.07409439980983734
step: 100, loss: 0.18332765996456146
step: 110, loss: 0.07111740857362747
step: 120, loss: 0.03240194171667099
step: 130, loss: 0.24583286046981812
step: 140, loss: 0.018889611586928368
step: 150, loss: 0.13478751480579376
step: 160, loss: 0.06780978292226791
step: 170, loss: 0.04349270835518837
step: 180, loss: 0.15382812917232513
step: 190, loss: 0.05562546104192734
step: 200, loss: 0.16141833364963531
step: 210, loss: 0.04008230194449425
step: 220, loss: 0.016991684213280678
step: 230, loss: 0.02892000414431095
step: 240, loss: 0.00948302075266838
step: 250, loss: 0.19917942583560944
step: 260, loss: 0.018975861370563507
step: 270, loss: 0.01856394112110138
step: 280, loss: 0.10315178334712982
step: 290, loss: 0.04884156584739685
step: 300, loss: 0.27195167541503906
step: 310, loss: 0.013257380574941635
step: 320, loss: 0.019256047904491425
step: 330, loss: 0.06789270043373108
step: 340, loss: 0.10490608960390091
step: 350, loss: 0.08231417089700699
step: 360, loss: 0.007647029124200344
step: 370, loss: 0.08459073305130005
step: 380, loss: 0.21964876353740692
epoch 4: dev_f1=0.7616580310880829, f1=0.6541554959785524, best_f1=0.6541554959785524
step: 0, loss: 0.06016835570335388
step: 10, loss: 0.028690434992313385
step: 20, loss: 0.01992042176425457
step: 30, loss: 0.09708090126514435
step: 40, loss: 0.20661424100399017
step: 50, loss: 0.02612779475748539
step: 60, loss: 0.02888864278793335
step: 70, loss: 0.06152253597974777
step: 80, loss: 0.06910156458616257
step: 90, loss: 0.08205246925354004
step: 100, loss: 0.03990904241800308
step: 110, loss: 0.007665627636015415
step: 120, loss: 0.033804889768362045
step: 130, loss: 0.0030049204360693693
step: 140, loss: 0.06578975170850754
step: 150, loss: 0.03500569239258766
step: 160, loss: 0.011355699971318245
step: 170, loss: 0.002677713753655553
step: 180, loss: 0.014920906163752079
step: 190, loss: 0.13893912732601166
step: 200, loss: 0.06652004271745682
step: 210, loss: 0.01931079477071762
step: 220, loss: 0.09522618353366852
step: 230, loss: 0.004016028251498938
step: 240, loss: 0.056548990309238434
step: 250, loss: 0.034953609108924866
step: 260, loss: 0.00891620572656393
step: 270, loss: 0.029987407848238945
step: 280, loss: 0.06534839421510696
step: 290, loss: 0.05500693991780281
step: 300, loss: 0.005964875221252441
step: 310, loss: 0.011726398952305317
step: 320, loss: 0.06974129378795624
step: 330, loss: 0.006600349210202694
step: 340, loss: 0.0790317952632904
step: 350, loss: 0.01723906770348549
step: 360, loss: 0.033311761915683746
step: 370, loss: 0.14095507562160492
step: 380, loss: 0.0554841049015522
epoch 5: dev_f1=0.7611940298507462, f1=0.6969696969696969, best_f1=0.6541554959785524
step: 0, loss: 0.03080427646636963
step: 10, loss: 0.025598345324397087
step: 20, loss: 0.03471899777650833
step: 30, loss: 0.0010256089735776186
step: 40, loss: 0.06770987063646317
step: 50, loss: 0.16677658259868622
step: 60, loss: 0.051860444247722626
step: 70, loss: 0.18183614313602448
step: 80, loss: 0.0011553983204066753
step: 90, loss: 0.11785820126533508
step: 100, loss: 0.02305648662149906
step: 110, loss: 0.18106813728809357
step: 120, loss: 0.006960284896194935
step: 130, loss: 0.06776604801416397
step: 140, loss: 0.01017798949033022
step: 150, loss: 0.07861605286598206
step: 160, loss: 0.3626646101474762
step: 170, loss: 0.13384932279586792
step: 180, loss: 0.004014178644865751
step: 190, loss: 0.11743191629648209
step: 200, loss: 0.17217211425304413
step: 210, loss: 0.015701815485954285
step: 220, loss: 0.009285645559430122
step: 230, loss: 0.09348440170288086
step: 240, loss: 0.01811419241130352
step: 250, loss: 0.01850990206003189
step: 260, loss: 0.028866974636912346
step: 270, loss: 0.015151296742260456
step: 280, loss: 0.017430676147341728
step: 290, loss: 0.02716861478984356
step: 300, loss: 0.0335218608379364
step: 310, loss: 0.013524427078664303
step: 320, loss: 0.03265896439552307
step: 330, loss: 0.0567953959107399
step: 340, loss: 0.007733422331511974
step: 350, loss: 0.006280793342739344
step: 360, loss: 0.000532151258084923
step: 370, loss: 0.017628854140639305
step: 380, loss: 0.03166024759411812
epoch 6: dev_f1=0.7473684210526317, f1=0.675603217158177, best_f1=0.6541554959785524
step: 0, loss: 0.011250975541770458
step: 10, loss: 0.010034142062067986
step: 20, loss: 0.011751647107303143
step: 30, loss: 0.002502933843061328
step: 40, loss: 0.04461010545492172
step: 50, loss: 0.055891070514917374
step: 60, loss: 0.0020791799761354923
step: 70, loss: 0.01171823963522911
step: 80, loss: 0.009494466707110405
step: 90, loss: 0.015284297056496143
step: 100, loss: 0.03304583579301834
step: 110, loss: 0.007592576090246439
step: 120, loss: 0.0008752867579460144
step: 130, loss: 0.03152759373188019
step: 140, loss: 0.000579065119381994
step: 150, loss: 0.0010006100637838244
step: 160, loss: 0.056294996291399
step: 170, loss: 0.1054244264960289
step: 180, loss: 0.008754322305321693
step: 190, loss: 0.034246012568473816
step: 200, loss: 0.0008988627232611179
step: 210, loss: 0.043994661420583725
step: 220, loss: 0.0012391683412715793
step: 230, loss: 0.00048469111789017916
step: 240, loss: 0.13718688488006592
step: 250, loss: 0.018546296283602715
step: 260, loss: 0.017472662031650543
step: 270, loss: 0.00538341561332345
step: 280, loss: 0.01422182284295559
step: 290, loss: 0.010328101925551891
step: 300, loss: 0.00790287647396326
step: 310, loss: 0.00556029612198472
step: 320, loss: 0.07456715404987335
step: 330, loss: 0.052828676998615265
step: 340, loss: 0.009311401285231113
step: 350, loss: 0.011297221295535564
step: 360, loss: 0.002377726137638092
step: 370, loss: 0.04920011758804321
step: 380, loss: 0.09635300934314728
epoch 7: dev_f1=0.7175141242937854, f1=0.5571847507331378, best_f1=0.6541554959785524
step: 0, loss: 0.10628704726696014
step: 10, loss: 0.002856104401871562
step: 20, loss: 0.0029722701292485
step: 30, loss: 0.007698212284594774
step: 40, loss: 0.0125774210318923
step: 50, loss: 0.008797427639365196
step: 60, loss: 0.05668891221284866
step: 70, loss: 0.0005883150151930749
step: 80, loss: 0.1435481309890747
step: 90, loss: 0.11722691357135773
step: 100, loss: 0.012213703244924545
step: 110, loss: 0.008029937744140625
step: 120, loss: 0.001962688285857439
step: 130, loss: 0.0035018054768443108
step: 140, loss: 0.008413676172494888
step: 150, loss: 0.01941455714404583
step: 160, loss: 0.0004839843313675374
step: 170, loss: 0.06567741185426712
step: 180, loss: 0.003434431739151478
step: 190, loss: 0.002023502718657255
step: 200, loss: 0.06879810243844986
step: 210, loss: 0.0004133942711632699
step: 220, loss: 0.002509555546566844
step: 230, loss: 0.057921599596738815
step: 240, loss: 0.00957491621375084
step: 250, loss: 0.0018573650158941746
step: 260, loss: 0.0006450388464145362
step: 270, loss: 0.00011039287346648052
step: 280, loss: 0.0573013573884964
step: 290, loss: 0.010522457771003246
step: 300, loss: 0.0005634958506561816
step: 310, loss: 0.009708664380013943
step: 320, loss: 0.03352170065045357
step: 330, loss: 0.003758538281545043
step: 340, loss: 0.017390908673405647
step: 350, loss: 0.02105872519314289
step: 360, loss: 0.03013690747320652
step: 370, loss: 0.011625675484538078
step: 380, loss: 0.0013508446281775832
epoch 8: dev_f1=0.7272727272727272, f1=0.6222222222222222, best_f1=0.6541554959785524
step: 0, loss: 0.0024474631063640118
step: 10, loss: 0.0012904281029477715
step: 20, loss: 0.0005722696660086513
step: 30, loss: 0.06834189593791962
step: 40, loss: 0.0894547626376152
step: 50, loss: 0.0019737950060516596
step: 60, loss: 0.009878234937787056
step: 70, loss: 0.043203916400671005
step: 80, loss: 0.0003747997689060867
step: 90, loss: 0.06064562126994133
step: 100, loss: 0.001977021573111415
step: 110, loss: 0.007708356715738773
step: 120, loss: 0.011113710701465607
step: 130, loss: 0.0003650475409813225
step: 140, loss: 0.036555394530296326
step: 150, loss: 0.005298857111483812
step: 160, loss: 0.003160367952659726
step: 170, loss: 0.00997595302760601
step: 180, loss: 0.0005962505820207298
step: 190, loss: 0.0064137401059269905
step: 200, loss: 0.008150468580424786
step: 210, loss: 0.033066701143980026
step: 220, loss: 0.0001593888009665534
step: 230, loss: 0.04483223333954811
step: 240, loss: 0.001923257252201438
step: 250, loss: 0.009832221083343029
step: 260, loss: 0.003752115648239851
step: 270, loss: 0.00029959529638290405
step: 280, loss: 0.0037907108198851347
step: 290, loss: 0.00024609966203570366
step: 300, loss: 0.002293806988745928
step: 310, loss: 0.0017458997899666429
step: 320, loss: 0.0005111549398861825
step: 330, loss: 0.00024048892373684794
step: 340, loss: 0.1006544679403305
step: 350, loss: 0.0040773628279566765
step: 360, loss: 0.049574114382267
step: 370, loss: 0.12718774378299713
step: 380, loss: 0.04176333174109459
epoch 9: dev_f1=0.7088607594936709, f1=0.6217616580310881, best_f1=0.6541554959785524
step: 0, loss: 0.004558551590889692
step: 10, loss: 0.0028362954035401344
step: 20, loss: 0.0029228292405605316
step: 30, loss: 0.0009351110784336925
step: 40, loss: 0.009447243064641953
step: 50, loss: 0.02817864529788494
step: 60, loss: 0.00048319227062165737
step: 70, loss: 0.00023459472868125886
step: 80, loss: 0.0032896834891289473
step: 90, loss: 0.0006208367994986475
step: 100, loss: 0.0012430010829120874
step: 110, loss: 0.00242886901833117
step: 120, loss: 0.004604626912623644
step: 130, loss: 0.015002845786511898
step: 140, loss: 0.0010572242317721248
step: 150, loss: 0.00032657969859428704
step: 160, loss: 0.00099628244061023
step: 170, loss: 0.0011428925208747387
step: 180, loss: 0.0015062983147799969
step: 190, loss: 0.0006804611184634268
step: 200, loss: 0.000796720793005079
step: 210, loss: 0.05789180472493172
step: 220, loss: 0.0027698224876075983
step: 230, loss: 0.001170767587609589
step: 240, loss: 0.008859151974320412
step: 250, loss: 0.029711341485381126
step: 260, loss: 0.002321515465155244
step: 270, loss: 0.033282242715358734
step: 280, loss: 0.01827314682304859
step: 290, loss: 0.002493589650839567
step: 300, loss: 0.00029321559122763574
step: 310, loss: 0.0005430095479823649
step: 320, loss: 0.004730866756290197
step: 330, loss: 0.02692333236336708
step: 340, loss: 0.024240493774414062
step: 350, loss: 0.0010320619912818074
step: 360, loss: 0.20962312817573547
step: 370, loss: 0.0019763861782848835
step: 380, loss: 0.07990172505378723
epoch 10: dev_f1=0.7500000000000001, f1=0.6126126126126126, best_f1=0.6541554959785524
step: 0, loss: 0.001265628612600267
step: 10, loss: 0.0009487199713476002
step: 20, loss: 0.061162810772657394
step: 30, loss: 0.0031412686221301556
step: 40, loss: 0.005683628376573324
step: 50, loss: 0.0005496167577803135
step: 60, loss: 0.002283860696479678
step: 70, loss: 0.00030003811116330326
step: 80, loss: 0.00031201940146274865
step: 90, loss: 0.0010406237561255693
step: 100, loss: 0.003362478455528617
step: 110, loss: 0.00044350989628583193
step: 120, loss: 0.0010085710091516376
step: 130, loss: 0.014503215439617634
step: 140, loss: 0.04712342098355293
step: 150, loss: 0.0010776863200590014
step: 160, loss: 0.0037090403493493795
step: 170, loss: 0.025016218423843384
step: 180, loss: 0.00045179366134107113
step: 190, loss: 0.004127369727939367
step: 200, loss: 0.002088213339447975
step: 210, loss: 0.007831147871911526
step: 220, loss: 0.0006624184898100793
step: 230, loss: 0.00010475989256519824
step: 240, loss: 0.0015304980333894491
step: 250, loss: 0.17954660952091217
step: 260, loss: 0.0007173127378337085
step: 270, loss: 0.007560485042631626
step: 280, loss: 0.00428375881165266
step: 290, loss: 0.0045281220227479935
step: 300, loss: 0.004271932877600193
step: 310, loss: 0.06347852945327759
step: 320, loss: 0.009007065556943417
step: 330, loss: 0.0005825663683936
step: 340, loss: 0.009837927296757698
step: 350, loss: 0.0023907215800136328
step: 360, loss: 0.00022173898469191045
step: 370, loss: 0.0010612818878144026
step: 380, loss: 0.0001326521742157638
epoch 11: dev_f1=0.7310704960835509, f1=0.6437994722955146, best_f1=0.6541554959785524
step: 0, loss: 0.00044534727931022644
step: 10, loss: 0.003564593382179737
step: 20, loss: 0.00044229693594388664
step: 30, loss: 0.0004810010432265699
step: 40, loss: 0.08305723965167999
step: 50, loss: 0.002423669211566448
step: 60, loss: 0.0003114649443887174
step: 70, loss: 0.0015966551145538688
step: 80, loss: 0.004674982745200396
step: 90, loss: 0.0008645891211926937
step: 100, loss: 0.0009591340203769505
step: 110, loss: 0.0009634561720304191
step: 120, loss: 0.00032257006387226284
step: 130, loss: 9.954650158761069e-05
step: 140, loss: 0.004171042237430811
step: 150, loss: 0.010636517778038979
step: 160, loss: 0.0002650338865350932
step: 170, loss: 0.0014336934546008706
step: 180, loss: 0.01723984070122242
step: 190, loss: 0.00018442937289364636
step: 200, loss: 0.00024021310673560947
step: 210, loss: 0.06695327907800674
step: 220, loss: 0.005456792656332254
step: 230, loss: 0.06623628735542297
step: 240, loss: 0.005610979627817869
step: 250, loss: 0.0663294568657875
step: 260, loss: 0.010870493948459625
step: 270, loss: 0.11642391979694366
step: 280, loss: 0.0008048904128372669
step: 290, loss: 0.009847870096564293
step: 300, loss: 0.0004477074253372848
step: 310, loss: 0.00023488394799642265
step: 320, loss: 0.000355456315446645
step: 330, loss: 0.011069799773395061
step: 340, loss: 0.0004893451114185154
step: 350, loss: 0.0017264572670683265
step: 360, loss: 0.00025278652901761234
step: 370, loss: 0.050203271210193634
step: 380, loss: 0.044973310083150864
epoch 12: dev_f1=0.7262872628726287, f1=0.6408839779005525, best_f1=0.6541554959785524
step: 0, loss: 9.628620318835601e-05
step: 10, loss: 0.00020477923681028187
step: 20, loss: 0.0011144917225465178
step: 30, loss: 0.01189794298261404
step: 40, loss: 5.4846092098159716e-05
step: 50, loss: 0.0002074633666779846
step: 60, loss: 0.0031200225930660963
step: 70, loss: 0.0005818652571178973
step: 80, loss: 9.165832307189703e-05
step: 90, loss: 0.0011335404124110937
step: 100, loss: 0.0006320762913674116
step: 110, loss: 0.003395011182874441
step: 120, loss: 0.0006275441846810281
step: 130, loss: 0.011222739703953266
step: 140, loss: 0.00011880592501256615
step: 150, loss: 0.00012055357365170494
step: 160, loss: 0.00035816928721033037
step: 170, loss: 0.0008521797717548907
step: 180, loss: 0.04854992777109146
step: 190, loss: 0.0011475738137960434
step: 200, loss: 0.0003857857082039118
step: 210, loss: 0.00011576538963709027
step: 220, loss: 5.148400668986142e-05
step: 230, loss: 0.0009534448618069291
step: 240, loss: 4.877829269389622e-05
step: 250, loss: 0.0006972235278226435
step: 260, loss: 0.0002871245378628373
step: 270, loss: 0.0006641693762503564
step: 280, loss: 0.08320768177509308
step: 290, loss: 0.0003239523502998054
step: 300, loss: 0.0009147702367044985
step: 310, loss: 0.0021844515576958656
step: 320, loss: 0.0002857512154150754
step: 330, loss: 0.0005440479144454002
step: 340, loss: 0.04890943318605423
step: 350, loss: 0.0007026373059488833
step: 360, loss: 0.00015648822591174394
step: 370, loss: 5.098491601529531e-05
step: 380, loss: 0.015186874195933342
epoch 13: dev_f1=0.7413793103448276, f1=0.5994065281899109, best_f1=0.6541554959785524
step: 0, loss: 0.00013377872528508306
step: 10, loss: 0.00010669110633898526
step: 20, loss: 0.0027658166363835335
step: 30, loss: 0.031216856092214584
step: 40, loss: 0.0007144801784306765
step: 50, loss: 0.00020257527648936957
step: 60, loss: 0.0030201198533177376
step: 70, loss: 9.761492401594296e-05
step: 80, loss: 0.0007281917496584356
step: 90, loss: 0.011103889904916286
step: 100, loss: 0.0001657787652220577
step: 110, loss: 0.00039109104545786977
step: 120, loss: 0.00012831634376198053
step: 130, loss: 0.00029882523813284934
step: 140, loss: 0.00011093298235209659
step: 150, loss: 5.309185871738009e-05
step: 160, loss: 0.00010488507541595027
step: 170, loss: 0.00014960093540139496
step: 180, loss: 0.002749491250142455
step: 190, loss: 0.00010603972623357549
step: 200, loss: 0.00010268365440424532
step: 210, loss: 0.0004400185716804117
step: 220, loss: 0.0008492746273986995
step: 230, loss: 4.9931666580960155e-05
step: 240, loss: 0.00013841904001310468
step: 250, loss: 6.164285150589421e-05
step: 260, loss: 0.00013918463082518429
step: 270, loss: 5.204914486967027e-05
step: 280, loss: 0.010382600128650665
step: 290, loss: 0.0007678790134377778
step: 300, loss: 0.00010026434756582603
step: 310, loss: 0.002298112493008375
step: 320, loss: 0.0007019123295322061
step: 330, loss: 0.000639068428426981
step: 340, loss: 0.09639718383550644
step: 350, loss: 0.0017279526218771935
step: 360, loss: 0.0011171671794727445
step: 370, loss: 0.0006176602910272777
step: 380, loss: 0.025815017521381378
epoch 14: dev_f1=0.7272727272727273, f1=0.5921450151057402, best_f1=0.6541554959785524
step: 0, loss: 0.001632926519960165
step: 10, loss: 0.0026813005097210407
step: 20, loss: 0.0017451085150241852
step: 30, loss: 0.00011902397818630561
step: 40, loss: 0.00044662842992693186
step: 50, loss: 0.00019388168584555387
step: 60, loss: 0.0004919898346997797
step: 70, loss: 0.00028247240697965026
step: 80, loss: 8.815515320748091e-05
step: 90, loss: 0.0004566327261272818
step: 100, loss: 0.0003631026193033904
step: 110, loss: 0.0007543757674284279
step: 120, loss: 0.0009175037266686559
step: 130, loss: 0.001101019443012774
step: 140, loss: 0.001788894645869732
step: 150, loss: 0.0013646241277456284
step: 160, loss: 0.00034058719757013023
step: 170, loss: 0.0026412110310047865
step: 180, loss: 0.0011706957593560219
step: 190, loss: 0.00024623764329589903
step: 200, loss: 0.00038418496842496097
step: 210, loss: 0.030753033235669136
step: 220, loss: 0.0027880840934813023
step: 230, loss: 0.006814839318394661
step: 240, loss: 0.0008827661513350904
step: 250, loss: 0.007672308012843132
step: 260, loss: 0.002905511762946844
step: 270, loss: 7.595554779982194e-05
step: 280, loss: 0.00017611010116524994
step: 290, loss: 0.002960889833047986
step: 300, loss: 0.00015799450920894742
step: 310, loss: 0.0002737200993578881
step: 320, loss: 0.00013332725211512297
step: 330, loss: 0.0012033169623464346
step: 340, loss: 0.0033457214012742043
step: 350, loss: 4.5316002797335386e-05
step: 360, loss: 0.04410451650619507
step: 370, loss: 0.0003215390897821635
step: 380, loss: 0.0005020306562073529
epoch 15: dev_f1=0.7331536388140162, f1=0.6267806267806268, best_f1=0.6541554959785524
step: 0, loss: 0.00018370641919318587
step: 10, loss: 9.311677422374487e-05
step: 20, loss: 9.873424278339371e-05
step: 30, loss: 0.0005175654659979045
step: 40, loss: 0.0005482299602590501
step: 50, loss: 7.182641274994239e-05
step: 60, loss: 4.64148870378267e-05
step: 70, loss: 0.00041377823799848557
step: 80, loss: 0.000324585271300748
step: 90, loss: 8.066501322900876e-05
step: 100, loss: 0.0001247971667908132
step: 110, loss: 0.004755259025841951
step: 120, loss: 0.011532125063240528
step: 130, loss: 0.0011492924531921744
step: 140, loss: 3.633131564129144e-05
step: 150, loss: 0.007561157923191786
step: 160, loss: 0.0015497218118980527
step: 170, loss: 0.00017107932944782078
step: 180, loss: 6.688563007628545e-05
step: 190, loss: 0.00013289102935232222
step: 200, loss: 0.00011120874114567414
step: 210, loss: 0.1524965763092041
step: 220, loss: 0.00030474120285362005
step: 230, loss: 0.00022336984693538398
step: 240, loss: 0.0002832869940903038
step: 250, loss: 0.0019556977786123753
step: 260, loss: 4.960728983860463e-05
step: 270, loss: 0.0002248917007818818
step: 280, loss: 0.0002853827318176627
step: 290, loss: 0.02083636447787285
step: 300, loss: 8.010830788407475e-05
step: 310, loss: 9.25067433854565e-05
step: 320, loss: 0.0011444734409451485
step: 330, loss: 0.05209141969680786
step: 340, loss: 7.285404717549682e-05
step: 350, loss: 0.0007977126515470445
step: 360, loss: 0.0001673162478255108
step: 370, loss: 0.00024524214677512646
step: 380, loss: 0.006733058486133814
epoch 16: dev_f1=0.7407407407407407, f1=0.6253687315634219, best_f1=0.6541554959785524
step: 0, loss: 4.737435665447265e-05
step: 10, loss: 0.0010296482359990478
step: 20, loss: 6.217263580765575e-05
step: 30, loss: 0.00031071880948729813
step: 40, loss: 8.446640276815742e-05
step: 50, loss: 0.00026189893833361566
step: 60, loss: 9.535992285236716e-05
step: 70, loss: 0.00021377118537202477
step: 80, loss: 0.0007079661008901894
step: 90, loss: 0.0008995592361316085
step: 100, loss: 0.000411738088587299
step: 110, loss: 0.00020702919573523104
step: 120, loss: 0.000144513018312864
step: 130, loss: 0.0026149472687393427
step: 140, loss: 0.00019337949925102293
step: 150, loss: 0.005404314026236534
step: 160, loss: 0.0009447434567846358
step: 170, loss: 0.00019424529455136508
step: 180, loss: 0.002157940063625574
step: 190, loss: 0.0006843567825853825
step: 200, loss: 0.0008697552257217467
step: 210, loss: 4.0618808270664886e-05
step: 220, loss: 0.0001085274780052714
step: 230, loss: 0.001678028842434287
step: 240, loss: 0.00017740360635798424
step: 250, loss: 0.06033236160874367
step: 260, loss: 9.244668035535142e-05
step: 270, loss: 0.00032258639112114906
step: 280, loss: 3.7415025872178376e-05
step: 290, loss: 0.0001777917641447857
step: 300, loss: 0.0011624905746430159
step: 310, loss: 6.455300172092393e-05
step: 320, loss: 3.573905996745452e-05
step: 330, loss: 0.0002945880114566535
step: 340, loss: 5.0909056881209835e-05
step: 350, loss: 7.436018495354801e-05
step: 360, loss: 0.0008645987254567444
step: 370, loss: 0.00013345271872822195
step: 380, loss: 6.173645670060068e-05
epoch 17: dev_f1=0.7409470752089136, f1=0.6478873239436621, best_f1=0.6541554959785524
step: 0, loss: 0.00036455836379900575
step: 10, loss: 6.969755486352369e-05
step: 20, loss: 6.928263610461727e-05
step: 30, loss: 0.00042019496322609484
step: 40, loss: 6.297240179264918e-05
step: 50, loss: 0.002578980289399624
step: 60, loss: 0.0002807332493830472
step: 70, loss: 3.786570596275851e-05
step: 80, loss: 4.458156763575971e-05
step: 90, loss: 2.898165439546574e-05
step: 100, loss: 7.307265332201496e-05
step: 110, loss: 0.0001329132792307064
step: 120, loss: 3.039321381947957e-05
step: 130, loss: 2.8818163627875037e-05
step: 140, loss: 0.00017677017604000866
step: 150, loss: 7.381043542409316e-05
step: 160, loss: 0.0008197360439226031
step: 170, loss: 0.00020558395772241056
step: 180, loss: 0.00011684888886520639
step: 190, loss: 7.950430153869092e-05
step: 200, loss: 0.00016103804227896035
step: 210, loss: 3.561523408279754e-05
step: 220, loss: 0.0003276997013017535
step: 230, loss: 0.0002915715449489653
step: 240, loss: 8.337994222529233e-05
step: 250, loss: 0.004596622195094824
step: 260, loss: 0.001041445299051702
step: 270, loss: 6.598783511435613e-05
step: 280, loss: 0.00013650876644533128
step: 290, loss: 0.022374853491783142
step: 300, loss: 9.812271309783682e-05
step: 310, loss: 8.9205292169936e-05
step: 320, loss: 2.3919541490613483e-05
step: 330, loss: 0.00023478268121834844
step: 340, loss: 7.643816934432834e-05
step: 350, loss: 0.00044716158299706876
step: 360, loss: 7.124042167561129e-05
step: 370, loss: 0.05586125701665878
step: 380, loss: 4.629866452887654e-05
epoch 18: dev_f1=0.7344632768361581, f1=0.6436781609195402, best_f1=0.6541554959785524
step: 0, loss: 0.0036818450316786766
step: 10, loss: 0.00043089213431812823
step: 20, loss: 0.0014616457046940923
step: 30, loss: 6.060684972908348e-05
step: 40, loss: 0.0001439023035345599
step: 50, loss: 0.00014844311226624995
step: 60, loss: 5.667606455972418e-05
step: 70, loss: 5.139251516084187e-05
step: 80, loss: 0.00032109368476085365
step: 90, loss: 7.308699423447251e-05
step: 100, loss: 8.830002479953691e-05
step: 110, loss: 0.0001899416820378974
step: 120, loss: 0.00011180393630638719
step: 130, loss: 3.766466397792101e-05
step: 140, loss: 0.0007929361891001463
step: 150, loss: 2.8340649805613793e-05
step: 160, loss: 4.3575098970904946e-05
step: 170, loss: 0.00020461982057895511
step: 180, loss: 4.990231536794454e-05
step: 190, loss: 8.576072286814451e-05
step: 200, loss: 4.954839459969662e-05
step: 210, loss: 6.306571594905108e-05
step: 220, loss: 8.343120862264186e-05
step: 230, loss: 2.8020884201396257e-05
step: 240, loss: 2.9469751098076813e-05
step: 250, loss: 2.6359446565038525e-05
step: 260, loss: 5.378627247409895e-05
step: 270, loss: 0.00023742903431411833
step: 280, loss: 0.00016051145212259144
step: 290, loss: 2.9101160180289298e-05
step: 300, loss: 0.00010233163629891351
step: 310, loss: 0.00011458410881459713
step: 320, loss: 8.991125650936738e-05
step: 330, loss: 7.91535057942383e-05
step: 340, loss: 0.0008295582374557853
step: 350, loss: 0.01467152126133442
step: 360, loss: 3.019566611328628e-05
step: 370, loss: 8.030841127038002e-05
step: 380, loss: 6.928998482180759e-05
epoch 19: dev_f1=0.7382920110192837, f1=0.6440677966101694, best_f1=0.6541554959785524
step: 0, loss: 6.480437878053635e-05
step: 10, loss: 7.42657866794616e-05
step: 20, loss: 9.661691001383588e-05
step: 30, loss: 3.1328880140790716e-05
step: 40, loss: 0.0001821753685362637
step: 50, loss: 4.054034434375353e-05
step: 60, loss: 4.17356968682725e-05
step: 70, loss: 8.727519889362156e-05
step: 80, loss: 0.0002853034529834986
step: 90, loss: 5.6162152759497985e-05
step: 100, loss: 0.06211547181010246
step: 110, loss: 0.00014582979201804847
step: 120, loss: 9.140290057985112e-05
step: 130, loss: 2.6113313651876524e-05
step: 140, loss: 0.00013842603948432952
step: 150, loss: 5.506008164957166e-05
step: 160, loss: 0.00026939818053506315
step: 170, loss: 3.157412720611319e-05
step: 180, loss: 8.639760926598683e-05
step: 190, loss: 5.795968172606081e-05
step: 200, loss: 4.764966433867812e-05
step: 210, loss: 6.176460738060996e-05
step: 220, loss: 3.960041794925928e-05
step: 230, loss: 0.0013065326493233442
step: 240, loss: 6.990678957663476e-05
step: 250, loss: 6.432431837311015e-05
step: 260, loss: 6.946478242753074e-05
step: 270, loss: 3.8468435377581045e-05
step: 280, loss: 5.1886399887735024e-05
step: 290, loss: 4.0248167351819575e-05
step: 300, loss: 0.0004548384458757937
step: 310, loss: 3.979032044298947e-05
step: 320, loss: 4.7561108658555895e-05
step: 330, loss: 0.00019372573297005147
step: 340, loss: 8.459819946438074e-05
step: 350, loss: 3.0470851925201714e-05
step: 360, loss: 0.006932646967470646
step: 370, loss: 6.050724186934531e-05
step: 380, loss: 5.5241278460016474e-05
epoch 20: dev_f1=0.7298850574712643, f1=0.6318840579710145, best_f1=0.6541554959785524
