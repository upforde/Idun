cuda
Device: cuda
step: 0, loss: 0.714616596698761
step: 10, loss: 0.3076094388961792
step: 20, loss: 0.3617103099822998
step: 30, loss: 0.22210069000720978
step: 40, loss: 0.24542853236198425
step: 50, loss: 0.24400927126407623
step: 60, loss: 0.25367072224617004
step: 70, loss: 0.23648549616336823
step: 80, loss: 0.3005000352859497
step: 90, loss: 0.17102110385894775
step: 100, loss: 0.1392444521188736
step: 110, loss: 0.31241872906684875
step: 120, loss: 0.10587357729673386
step: 130, loss: 0.2656741738319397
step: 140, loss: 0.34502822160720825
step: 150, loss: 0.34835752844810486
step: 160, loss: 0.22780464589595795
step: 170, loss: 0.2517274022102356
step: 180, loss: 0.29820913076400757
step: 190, loss: 0.27209189534187317
step: 200, loss: 0.21956445276737213
step: 210, loss: 0.30828022956848145
step: 220, loss: 0.1370316743850708
step: 230, loss: 0.37312933802604675
step: 240, loss: 0.09524587541818619
step: 250, loss: 0.15667292475700378
step: 260, loss: 0.2788214087486267
step: 270, loss: 0.13808239996433258
step: 280, loss: 0.1841011643409729
step: 290, loss: 0.2950893044471741
step: 300, loss: 0.24090994894504547
step: 310, loss: 0.23060446977615356
step: 320, loss: 0.2287936806678772
step: 330, loss: 0.37493976950645447
step: 340, loss: 0.1587928980588913
step: 350, loss: 0.1295338273048401
step: 360, loss: 0.3535178303718567
step: 370, loss: 0.34660184383392334
step: 380, loss: 0.2917129397392273
epoch 1: dev_f1=0.5583756345177665, f1=0.5052083333333334, best_f1=0.5052083333333334
step: 0, loss: 0.19770538806915283
step: 10, loss: 0.16355903446674347
step: 20, loss: 0.17712479829788208
step: 30, loss: 0.2306569665670395
step: 40, loss: 0.3014570474624634
step: 50, loss: 0.14796948432922363
step: 60, loss: 0.15064111351966858
step: 70, loss: 0.05707830563187599
step: 80, loss: 0.023113597184419632
step: 90, loss: 0.18305683135986328
step: 100, loss: 0.17854246497154236
step: 110, loss: 0.18349504470825195
step: 120, loss: 0.0886545181274414
step: 130, loss: 0.0674932599067688
step: 140, loss: 0.2760266959667206
step: 150, loss: 0.10198509693145752
step: 160, loss: 0.15903732180595398
step: 170, loss: 0.16050401329994202
step: 180, loss: 0.33055150508880615
step: 190, loss: 0.18157272040843964
step: 200, loss: 0.14785248041152954
step: 210, loss: 0.09489264339208603
step: 220, loss: 0.15413932502269745
step: 230, loss: 0.0543597936630249
step: 240, loss: 0.09632660448551178
step: 250, loss: 0.27949008345603943
step: 260, loss: 0.14142511785030365
step: 270, loss: 0.14742279052734375
step: 280, loss: 0.28502127528190613
step: 290, loss: 0.11380551755428314
step: 300, loss: 0.101502925157547
step: 310, loss: 0.17870844900608063
step: 320, loss: 0.13194036483764648
step: 330, loss: 0.24100534617900848
step: 340, loss: 0.05782978981733322
step: 350, loss: 0.10154830664396286
step: 360, loss: 0.23954397439956665
step: 370, loss: 0.1697874367237091
step: 380, loss: 0.22193393111228943
epoch 2: dev_f1=0.7277936962750716, f1=0.608433734939759, best_f1=0.608433734939759
step: 0, loss: 0.14988794922828674
step: 10, loss: 0.19725875556468964
step: 20, loss: 0.00728894118219614
step: 30, loss: 0.041005689650774
step: 40, loss: 0.08385708928108215
step: 50, loss: 0.10616028308868408
step: 60, loss: 0.12654784321784973
step: 70, loss: 0.04631764069199562
step: 80, loss: 0.07320887595415115
step: 90, loss: 0.07451888173818588
step: 100, loss: 0.08538864552974701
step: 110, loss: 0.08446808159351349
step: 120, loss: 0.19139808416366577
step: 130, loss: 0.24667257070541382
step: 140, loss: 0.11108139902353287
step: 150, loss: 0.1487860083580017
step: 160, loss: 0.07924880087375641
step: 170, loss: 0.0252093356102705
step: 180, loss: 0.05284522846341133
step: 190, loss: 0.1865040510892868
step: 200, loss: 0.08125796169042587
step: 210, loss: 0.3129974603652954
step: 220, loss: 0.26018989086151123
step: 230, loss: 0.10035113245248795
step: 240, loss: 0.11665187031030655
step: 250, loss: 0.14891232550144196
step: 260, loss: 0.1388387233018875
step: 270, loss: 0.2277531772851944
step: 280, loss: 0.277937114238739
step: 290, loss: 0.16457439959049225
step: 300, loss: 0.10835781693458557
step: 310, loss: 0.030169783160090446
step: 320, loss: 0.0963982492685318
step: 330, loss: 0.03132789582014084
step: 340, loss: 0.20935922861099243
step: 350, loss: 0.0732799619436264
step: 360, loss: 0.1613001823425293
step: 370, loss: 0.09546373039484024
step: 380, loss: 0.04742090031504631
epoch 3: dev_f1=0.739795918367347, f1=0.6649214659685864, best_f1=0.6649214659685864
step: 0, loss: 0.1277211755514145
step: 10, loss: 0.060669850558042526
step: 20, loss: 0.057105652987957
step: 30, loss: 0.033290378749370575
step: 40, loss: 0.03695541247725487
step: 50, loss: 0.06341461837291718
step: 60, loss: 0.016208654269576073
step: 70, loss: 0.02000454254448414
step: 80, loss: 0.13745377957820892
step: 90, loss: 0.14675861597061157
step: 100, loss: 0.089908167719841
step: 110, loss: 0.013830793090164661
step: 120, loss: 0.20003779232501984
step: 130, loss: 0.006621313281357288
step: 140, loss: 0.23849964141845703
step: 150, loss: 0.007871250621974468
step: 160, loss: 0.013309997506439686
step: 170, loss: 0.104608915746212
step: 180, loss: 0.09161056578159332
step: 190, loss: 0.12879334390163422
step: 200, loss: 0.012070680037140846
step: 210, loss: 0.13433580100536346
step: 220, loss: 0.10538303107023239
step: 230, loss: 0.015823492780327797
step: 240, loss: 0.028646504506468773
step: 250, loss: 0.1663232296705246
step: 260, loss: 0.005011551547795534
step: 270, loss: 0.045522116124629974
step: 280, loss: 0.08783844113349915
step: 290, loss: 0.08784668147563934
step: 300, loss: 0.03288375586271286
step: 310, loss: 0.00622207997366786
step: 320, loss: 0.24662521481513977
step: 330, loss: 0.05402286723256111
step: 340, loss: 0.07301057875156403
step: 350, loss: 0.02783452719449997
step: 360, loss: 0.14453692734241486
step: 370, loss: 0.049951955676078796
step: 380, loss: 0.0008514209184795618
epoch 4: dev_f1=0.7423822714681441, f1=0.6554621848739497, best_f1=0.6554621848739497
step: 0, loss: 0.029261954128742218
step: 10, loss: 0.08558514714241028
step: 20, loss: 0.006728147156536579
step: 30, loss: 0.04974975436925888
step: 40, loss: 0.04952460899949074
step: 50, loss: 0.016007937490940094
step: 60, loss: 0.0022734084632247686
step: 70, loss: 0.10299956053495407
step: 80, loss: 0.009492866694927216
step: 90, loss: 0.11743950843811035
step: 100, loss: 0.0749460980296135
step: 110, loss: 0.1202186867594719
step: 120, loss: 0.1363842636346817
step: 130, loss: 0.08117349445819855
step: 140, loss: 0.08984711766242981
step: 150, loss: 0.005624689627438784
step: 160, loss: 0.013464145362377167
step: 170, loss: 0.14313817024230957
step: 180, loss: 0.0010220179101452231
step: 190, loss: 0.005780133884400129
step: 200, loss: 0.07519444078207016
step: 210, loss: 0.07451149821281433
step: 220, loss: 0.020827090367674828
step: 230, loss: 0.29629287123680115
step: 240, loss: 0.010168219916522503
step: 250, loss: 0.3064563572406769
step: 260, loss: 0.16467061638832092
step: 270, loss: 0.0726935863494873
step: 280, loss: 0.006803389173001051
step: 290, loss: 0.04295775666832924
step: 300, loss: 0.0290386900305748
step: 310, loss: 0.1318443864583969
step: 320, loss: 0.013310087844729424
step: 330, loss: 0.03961930796504021
step: 340, loss: 0.003792935749515891
step: 350, loss: 0.3158322870731354
step: 360, loss: 0.029964661225676537
step: 370, loss: 0.07744886726140976
step: 380, loss: 0.009525608271360397
epoch 5: dev_f1=0.7235142118863048, f1=0.5621621621621622, best_f1=0.6554621848739497
step: 0, loss: 0.005672077648341656
step: 10, loss: 0.005961413495242596
step: 20, loss: 0.017609287053346634
step: 30, loss: 0.009449833072721958
step: 40, loss: 0.0052305590361356735
step: 50, loss: 0.0036619696766138077
step: 60, loss: 0.007664738688617945
step: 70, loss: 0.0014371211873367429
step: 80, loss: 0.08081655949354172
step: 90, loss: 0.0010507403640076518
step: 100, loss: 0.04869760200381279
step: 110, loss: 0.06743013858795166
step: 120, loss: 0.03931222856044769
step: 130, loss: 0.013367935083806515
step: 140, loss: 0.011282868683338165
step: 150, loss: 0.00402420898899436
step: 160, loss: 0.03135228902101517
step: 170, loss: 0.0030692433938384056
step: 180, loss: 0.0390222892165184
step: 190, loss: 0.00519426167011261
step: 200, loss: 0.002177785150706768
step: 210, loss: 0.03297198936343193
step: 220, loss: 0.0929146409034729
step: 230, loss: 0.027360936626791954
step: 240, loss: 0.011267227120697498
step: 250, loss: 0.0017317483434453607
step: 260, loss: 0.032389238476753235
step: 270, loss: 0.043789561837911606
step: 280, loss: 0.006653967779129744
step: 290, loss: 0.013628454878926277
step: 300, loss: 0.004267742391675711
step: 310, loss: 0.01043847855180502
step: 320, loss: 0.04384385421872139
step: 330, loss: 0.0015636500902473927
step: 340, loss: 0.0683739185333252
step: 350, loss: 0.07336399704217911
step: 360, loss: 0.006301485933363438
step: 370, loss: 0.004254566039890051
step: 380, loss: 0.0400557704269886
epoch 6: dev_f1=0.7162534435261707, f1=0.6420454545454545, best_f1=0.6554621848739497
step: 0, loss: 0.007622815668582916
step: 10, loss: 0.021753311157226562
step: 20, loss: 0.03309500217437744
step: 30, loss: 0.0360097661614418
step: 40, loss: 0.003279972355812788
step: 50, loss: 0.004147666972130537
step: 60, loss: 0.024522244930267334
step: 70, loss: 0.002227932680398226
step: 80, loss: 0.006400962360203266
step: 90, loss: 0.00891038402915001
step: 100, loss: 0.008674531243741512
step: 110, loss: 0.000856068218126893
step: 120, loss: 0.006993292830884457
step: 130, loss: 0.003660893067717552
step: 140, loss: 0.018728185445070267
step: 150, loss: 0.049403633922338486
step: 160, loss: 0.04978538304567337
step: 170, loss: 0.020398544147610664
step: 180, loss: 0.004735681228339672
step: 190, loss: 0.11527792364358902
step: 200, loss: 0.03830130025744438
step: 210, loss: 0.02008514292538166
step: 220, loss: 0.07835665345191956
step: 230, loss: 0.04485159367322922
step: 240, loss: 0.009727247059345245
step: 250, loss: 0.001041789073497057
step: 260, loss: 0.007012035697698593
step: 270, loss: 0.0580056831240654
step: 280, loss: 0.1257203221321106
step: 290, loss: 0.02472684718668461
step: 300, loss: 0.005719499196857214
step: 310, loss: 0.014719340018928051
step: 320, loss: 0.01675887033343315
step: 330, loss: 0.06299560517072678
step: 340, loss: 0.023423105478286743
step: 350, loss: 0.0035594527143985033
step: 360, loss: 0.03584928438067436
step: 370, loss: 0.06436095386743546
step: 380, loss: 0.0017035508062690496
epoch 7: dev_f1=0.7277777777777779, f1=0.606060606060606, best_f1=0.6554621848739497
step: 0, loss: 0.0018851981731131673
step: 10, loss: 0.008775973692536354
step: 20, loss: 0.0016978096682578325
step: 30, loss: 0.0011855228804051876
step: 40, loss: 0.06062747910618782
step: 50, loss: 0.004543185234069824
step: 60, loss: 0.008082970045506954
step: 70, loss: 0.03909669816493988
step: 80, loss: 0.00030097318813204765
step: 90, loss: 0.015881069004535675
step: 100, loss: 0.0024687638506293297
step: 110, loss: 0.014850761741399765
step: 120, loss: 0.013965441845357418
step: 130, loss: 0.008494685404002666
step: 140, loss: 0.0010044914670288563
step: 150, loss: 0.00464710034430027
step: 160, loss: 0.11615751683712006
step: 170, loss: 0.004581600893288851
step: 180, loss: 0.0042182221077382565
step: 190, loss: 0.004141518846154213
step: 200, loss: 0.005291495937854052
step: 210, loss: 0.0011225888738408685
step: 220, loss: 0.06570696085691452
step: 230, loss: 0.00034114631125703454
step: 240, loss: 0.002424707869067788
step: 250, loss: 0.18304498493671417
step: 260, loss: 0.0025476531591266394
step: 270, loss: 0.0012001879513263702
step: 280, loss: 0.004827222321182489
step: 290, loss: 0.029446111992001534
step: 300, loss: 0.024873139336705208
step: 310, loss: 0.021970292553305626
step: 320, loss: 0.013792872428894043
step: 330, loss: 0.2984040379524231
step: 340, loss: 0.01095621194690466
step: 350, loss: 0.002778862603008747
step: 360, loss: 0.010407784022390842
step: 370, loss: 0.005602160003036261
step: 380, loss: 0.013731863349676132
epoch 8: dev_f1=0.697406340057637, f1=0.56875, best_f1=0.6554621848739497
step: 0, loss: 0.01342547032982111
step: 10, loss: 0.002426032442599535
step: 20, loss: 0.004880695138126612
step: 30, loss: 0.005310808774083853
step: 40, loss: 0.000181064591743052
step: 50, loss: 0.025331400334835052
step: 60, loss: 0.09071352332830429
step: 70, loss: 0.029430732131004333
step: 80, loss: 0.006897653453052044
step: 90, loss: 0.0017972828354686499
step: 100, loss: 0.031591467559337616
step: 110, loss: 0.13217346370220184
step: 120, loss: 0.006765482481569052
step: 130, loss: 0.0013823704794049263
step: 140, loss: 0.010296721011400223
step: 150, loss: 0.0007925045792944729
step: 160, loss: 0.00024205051886383444
step: 170, loss: 0.003917409107089043
step: 180, loss: 0.027420535683631897
step: 190, loss: 0.002000414300709963
step: 200, loss: 0.09346821904182434
step: 210, loss: 0.011420251801609993
step: 220, loss: 0.05631192401051521
step: 230, loss: 0.05072292685508728
step: 240, loss: 0.004626646637916565
step: 250, loss: 0.0005660148453898728
step: 260, loss: 0.0021959529258310795
step: 270, loss: 0.05205989256501198
step: 280, loss: 0.014347942546010017
step: 290, loss: 0.06671049445867538
step: 300, loss: 0.005000505596399307
step: 310, loss: 0.0002539486449677497
step: 320, loss: 0.2017875611782074
step: 330, loss: 0.0037305273581296206
step: 340, loss: 0.0023033088073134422
step: 350, loss: 0.0008309168042615056
step: 360, loss: 0.010364310815930367
step: 370, loss: 0.013928348198533058
step: 380, loss: 0.010490776039659977
epoch 9: dev_f1=0.732824427480916, f1=0.6117021276595745, best_f1=0.6554621848739497
step: 0, loss: 0.017747441306710243
step: 10, loss: 0.010625525377690792
step: 20, loss: 0.0004474570450838655
step: 30, loss: 0.0032416614703834057
step: 40, loss: 0.003074162406846881
step: 50, loss: 0.0009013425442390144
step: 60, loss: 0.003975153900682926
step: 70, loss: 0.005895579233765602
step: 80, loss: 0.004715165589004755
step: 90, loss: 0.016759118065238
step: 100, loss: 0.0022609622683376074
step: 110, loss: 0.08538002520799637
step: 120, loss: 0.004785188473761082
step: 130, loss: 0.00029050614102743566
step: 140, loss: 0.00043005478801205754
step: 150, loss: 0.01624578796327114
step: 160, loss: 0.0006111369002610445
step: 170, loss: 0.05848351866006851
step: 180, loss: 0.03704060614109039
step: 190, loss: 0.08893373608589172
step: 200, loss: 0.0028789567295461893
step: 210, loss: 0.0014894556952640414
step: 220, loss: 0.002864377573132515
step: 230, loss: 0.0004232620121911168
step: 240, loss: 0.006390648894011974
step: 250, loss: 0.001491206930950284
step: 260, loss: 0.0011950646294280887
step: 270, loss: 0.0002867085568141192
step: 280, loss: 0.001555180991999805
step: 290, loss: 0.0036708025727421045
step: 300, loss: 0.0013042408972978592
step: 310, loss: 0.0009110881946980953
step: 320, loss: 0.005338724236935377
step: 330, loss: 0.0007709030178375542
step: 340, loss: 0.049090996384620667
step: 350, loss: 0.0020500137470662594
step: 360, loss: 0.00019184770644642413
step: 370, loss: 0.00017469942395109683
step: 380, loss: 0.00038236082764342427
epoch 10: dev_f1=0.7524271844660194, f1=0.6315789473684211, best_f1=0.6315789473684211
step: 0, loss: 0.002678020391613245
step: 10, loss: 0.0010868993122130632
step: 20, loss: 0.004289066419005394
step: 30, loss: 0.0017993042711168528
step: 40, loss: 0.0030741088557988405
step: 50, loss: 0.0003433701058384031
step: 60, loss: 0.0003011755470652133
step: 70, loss: 0.004097708500921726
step: 80, loss: 0.017397191375494003
step: 90, loss: 0.0038514805492013693
step: 100, loss: 0.00027388520538806915
step: 110, loss: 0.0009834637166932225
step: 120, loss: 0.019745761528611183
step: 130, loss: 0.0005018297815695405
step: 140, loss: 0.19881582260131836
step: 150, loss: 0.0027988473884761333
step: 160, loss: 0.0362149253487587
step: 170, loss: 0.0022102107759565115
step: 180, loss: 0.0005700201145373285
step: 190, loss: 0.0005953589570708573
step: 200, loss: 0.018205633386969566
step: 210, loss: 0.0007870734552852809
step: 220, loss: 0.02484462596476078
step: 230, loss: 0.10425548255443573
step: 240, loss: 0.07776886224746704
step: 250, loss: 0.0008973577059805393
step: 260, loss: 0.0007183759589679539
step: 270, loss: 0.0006040034350007772
step: 280, loss: 0.0007959821377880871
step: 290, loss: 0.0013105570105835795
step: 300, loss: 0.002447781851515174
step: 310, loss: 0.0006557077285833657
step: 320, loss: 0.006986245978623629
step: 330, loss: 0.0004658335237763822
step: 340, loss: 0.00015537021681666374
step: 350, loss: 0.0002705361694097519
step: 360, loss: 0.0009179505286738276
step: 370, loss: 0.0008113320800475776
step: 380, loss: 0.029733385890722275
epoch 11: dev_f1=0.7563025210084034, f1=0.5947521865889213, best_f1=0.5947521865889213
step: 0, loss: 0.0009695702465251088
step: 10, loss: 0.00015143897326197475
step: 20, loss: 0.0008372694719582796
step: 30, loss: 0.00019915855955332518
step: 40, loss: 0.002057411940768361
step: 50, loss: 0.0026470620650798082
step: 60, loss: 0.0008908422314561903
step: 70, loss: 0.07913946360349655
step: 80, loss: 0.00016158797370735556
step: 90, loss: 0.0004846290103159845
step: 100, loss: 0.003413720754906535
step: 110, loss: 0.00224137119948864
step: 120, loss: 0.0012212826404720545
step: 130, loss: 0.00852152332663536
step: 140, loss: 0.003898863447830081
step: 150, loss: 0.0002823325921781361
step: 160, loss: 0.002770706545561552
step: 170, loss: 0.0033480278216302395
step: 180, loss: 0.0002157740091206506
step: 190, loss: 0.00022267390158958733
step: 200, loss: 0.0013951001456007361
step: 210, loss: 0.0012701406376436353
step: 220, loss: 0.0010491915745660663
step: 230, loss: 0.01718195155262947
step: 240, loss: 0.0009900336153805256
step: 250, loss: 0.0019080399069935083
step: 260, loss: 0.002680170116946101
step: 270, loss: 0.004750892985612154
step: 280, loss: 0.0010297594126313925
step: 290, loss: 0.0019534577149897814
step: 300, loss: 0.005495330784469843
step: 310, loss: 0.13539482653141022
step: 320, loss: 0.0004563826078083366
step: 330, loss: 0.0010318697895854712
step: 340, loss: 0.00029565137811005116
step: 350, loss: 0.0004477293405216187
step: 360, loss: 0.0009434669627808034
step: 370, loss: 0.0027715861797332764
step: 380, loss: 0.0007134326151572168
epoch 12: dev_f1=0.7084468664850135, f1=0.5845272206303725, best_f1=0.5947521865889213
step: 0, loss: 0.02118803933262825
step: 10, loss: 0.0006812670035287738
step: 20, loss: 0.0024791336618363857
step: 30, loss: 0.00016879184113349766
step: 40, loss: 0.0002602713357191533
step: 50, loss: 0.006683018058538437
step: 60, loss: 0.0006475254194810987
step: 70, loss: 0.005084413103759289
step: 80, loss: 0.0005073943175375462
step: 90, loss: 0.002335055498406291
step: 100, loss: 0.0002566134789958596
step: 110, loss: 0.00021970206580590457
step: 120, loss: 0.000270761433057487
step: 130, loss: 0.001218628603965044
step: 140, loss: 0.004840006120502949
step: 150, loss: 0.0005176588310860097
step: 160, loss: 0.0006689592846669257
step: 170, loss: 0.0012942471075803041
step: 180, loss: 0.00273648789152503
step: 190, loss: 0.0068539585918188095
step: 200, loss: 0.002008100040256977
step: 210, loss: 0.0116733955219388
step: 220, loss: 5.470954056363553e-05
step: 230, loss: 0.0001674820960033685
step: 240, loss: 0.00023918060469441116
step: 250, loss: 0.00032378267496824265
step: 260, loss: 0.013128546066582203
step: 270, loss: 0.00027391136973164976
step: 280, loss: 0.00018385742441751063
step: 290, loss: 0.005396320018917322
step: 300, loss: 0.0002178670692956075
step: 310, loss: 0.0004368051595520228
step: 320, loss: 0.0019233673810958862
step: 330, loss: 0.00025153064052574337
step: 340, loss: 0.0009719315567053854
step: 350, loss: 0.00012544673518277705
step: 360, loss: 0.0045542228035628796
step: 370, loss: 0.0006195774767547846
step: 380, loss: 0.0003031233209185302
epoch 13: dev_f1=0.7208672086720868, f1=0.6074498567335244, best_f1=0.5947521865889213
step: 0, loss: 0.00010743457823991776
step: 10, loss: 0.001325685065239668
step: 20, loss: 0.03039606660604477
step: 30, loss: 0.09791062772274017
step: 40, loss: 0.0006189799751155078
step: 50, loss: 0.0019338058773428202
step: 60, loss: 0.0008438991499133408
step: 70, loss: 0.0003463132889010012
step: 80, loss: 0.03713598474860191
step: 90, loss: 0.0002055510994978249
step: 100, loss: 0.007626034319400787
step: 110, loss: 0.027965320274233818
step: 120, loss: 0.004512977320700884
step: 130, loss: 0.0003491156385280192
step: 140, loss: 0.000978066585958004
step: 150, loss: 0.00030707797850482166
step: 160, loss: 0.00027633298304863274
step: 170, loss: 0.006564368028193712
step: 180, loss: 0.0020569488406181335
step: 190, loss: 0.00010438426397740841
step: 200, loss: 8.150966459652409e-05
step: 210, loss: 0.0016653182683512568
step: 220, loss: 0.001639166148379445
step: 230, loss: 0.0005374023457989097
step: 240, loss: 0.00046519923489540815
step: 250, loss: 0.00023048791626933962
step: 260, loss: 0.0015829724725335836
step: 270, loss: 0.0012261394876986742
step: 280, loss: 0.0005531698116101325
step: 290, loss: 0.00011187290510861203
step: 300, loss: 0.00010363767796661705
step: 310, loss: 6.980117905186489e-05
step: 320, loss: 8.71514348546043e-05
step: 330, loss: 0.07474135607481003
step: 340, loss: 5.626095662591979e-05
step: 350, loss: 4.1911815060302615e-05
step: 360, loss: 0.0015929724322631955
step: 370, loss: 0.00011553319200174883
step: 380, loss: 0.0014672240940853953
epoch 14: dev_f1=0.7382198952879582, f1=0.6525198938992043, best_f1=0.5947521865889213
step: 0, loss: 0.006868534255772829
step: 10, loss: 0.015519987791776657
step: 20, loss: 0.00015537241415586323
step: 30, loss: 0.010087152943015099
step: 40, loss: 0.0010723794111981988
step: 50, loss: 0.07834117114543915
step: 60, loss: 0.0005649304366670549
step: 70, loss: 0.00027501245494931936
step: 80, loss: 0.0002800564107019454
step: 90, loss: 0.021270575001835823
step: 100, loss: 0.0006877590203657746
step: 110, loss: 0.00125382118858397
step: 120, loss: 0.001072563580237329
step: 130, loss: 0.0007688853074796498
step: 140, loss: 0.024388471618294716
step: 150, loss: 0.011326421983540058
step: 160, loss: 0.002034627366811037
step: 170, loss: 8.52758894325234e-05
step: 180, loss: 0.0013331560185179114
step: 190, loss: 0.0005630400264635682
step: 200, loss: 0.00017129752086475492
step: 210, loss: 0.00017890811432152987
step: 220, loss: 0.008696505799889565
step: 230, loss: 0.00019104187958873808
step: 240, loss: 0.00011702343181241304
step: 250, loss: 0.0007211300544440746
step: 260, loss: 0.00016501783102285117
step: 270, loss: 0.00389119703322649
step: 280, loss: 0.004005396738648415
step: 290, loss: 6.279822264332324e-05
step: 300, loss: 0.0013547251001000404
step: 310, loss: 0.012813684530556202
step: 320, loss: 0.00045289602712728083
step: 330, loss: 0.09858396649360657
step: 340, loss: 9.335351205663756e-05
step: 350, loss: 0.0002561972651164979
step: 360, loss: 9.896863775793463e-05
step: 370, loss: 0.00016179536760319024
step: 380, loss: 0.0009181639761663973
epoch 15: dev_f1=0.7407407407407407, f1=0.656891495601173, best_f1=0.5947521865889213
step: 0, loss: 0.00026378093753010035
step: 10, loss: 0.002996135735884309
step: 20, loss: 0.0011135053355246782
step: 30, loss: 0.00039183758781291544
step: 40, loss: 0.00025429276865907013
step: 50, loss: 0.00038161344127729535
step: 60, loss: 0.0005494973156601191
step: 70, loss: 0.0002667571825440973
step: 80, loss: 0.0001862798526417464
step: 90, loss: 0.0007734232349321246
step: 100, loss: 0.005593038164079189
step: 110, loss: 0.0017435774207115173
step: 120, loss: 0.0004845028161071241
step: 130, loss: 0.0147836459800601
step: 140, loss: 0.00015657850599382073
step: 150, loss: 0.0013951294822618365
step: 160, loss: 0.00030769893783144653
step: 170, loss: 0.00015956872084643692
step: 180, loss: 0.00022392348910216242
step: 190, loss: 0.0013932713773101568
step: 200, loss: 0.00023671075177844614
step: 210, loss: 7.95493324403651e-05
step: 220, loss: 0.0001806542422855273
step: 230, loss: 0.00013916959869675338
step: 240, loss: 0.00033974312827922404
step: 250, loss: 0.0001646310993237421
step: 260, loss: 0.00023230105580296367
step: 270, loss: 0.00026488726143725216
step: 280, loss: 6.513316475320607e-05
step: 290, loss: 0.002481753472238779
step: 300, loss: 0.00010978832142427564
step: 310, loss: 0.00018728169379755855
step: 320, loss: 0.0001089910147129558
step: 330, loss: 0.00033262104261666536
step: 340, loss: 3.873802052112296e-05
step: 350, loss: 0.0006832439685240388
step: 360, loss: 0.03109675832092762
step: 370, loss: 0.0021539037115871906
step: 380, loss: 0.009648842737078667
epoch 16: dev_f1=0.7473684210526317, f1=0.6467391304347825, best_f1=0.5947521865889213
step: 0, loss: 0.0005120942951180041
step: 10, loss: 0.003451914992183447
step: 20, loss: 0.001530999317765236
step: 30, loss: 5.7046527217607945e-05
step: 40, loss: 4.3732226913562045e-05
step: 50, loss: 8.533491200068966e-05
step: 60, loss: 7.927042315714061e-05
step: 70, loss: 0.00013666773156728595
step: 80, loss: 0.004132849629968405
step: 90, loss: 4.606241418514401e-05
step: 100, loss: 6.448011117754504e-05
step: 110, loss: 0.0019002810586243868
step: 120, loss: 3.315017238492146e-05
step: 130, loss: 0.00016930764832068235
step: 140, loss: 0.00039231462869793177
step: 150, loss: 0.0005577643751166761
step: 160, loss: 0.0015958626754581928
step: 170, loss: 0.00013627897715196013
step: 180, loss: 0.002403132151812315
step: 190, loss: 0.0003200755163561553
step: 200, loss: 3.830486457445659e-05
step: 210, loss: 0.0002313565055374056
step: 220, loss: 7.262466533575207e-05
step: 230, loss: 4.864945003646426e-05
step: 240, loss: 0.00019902620988432318
step: 250, loss: 0.0010809871600940824
step: 260, loss: 0.00010672920325305313
step: 270, loss: 0.000589367002248764
step: 280, loss: 6.280038360273466e-05
step: 290, loss: 0.00011128088954137638
step: 300, loss: 0.00027105145272798836
step: 310, loss: 0.0006542174378409982
step: 320, loss: 0.007097611669450998
step: 330, loss: 0.0008895185892470181
step: 340, loss: 9.881560254143551e-05
step: 350, loss: 9.342321573058143e-05
step: 360, loss: 0.0008247100049629807
step: 370, loss: 0.009648355655372143
step: 380, loss: 0.00010897053289227188
epoch 17: dev_f1=0.7566137566137565, f1=0.6388888888888888, best_f1=0.6388888888888888
step: 0, loss: 7.011750130914152e-05
step: 10, loss: 0.019434873014688492
step: 20, loss: 0.0007483938825316727
step: 30, loss: 0.00010169949382543564
step: 40, loss: 0.0003493459662422538
step: 50, loss: 0.0020807755645364523
step: 60, loss: 0.0007943837554194033
step: 70, loss: 7.794079283485189e-05
step: 80, loss: 0.00042584186303429306
step: 90, loss: 3.190132702002302e-05
step: 100, loss: 5.068249811301939e-05
step: 110, loss: 0.0001055491593433544
step: 120, loss: 4.8338595661334693e-05
step: 130, loss: 0.0005716281593777239
step: 140, loss: 0.0033735150936990976
step: 150, loss: 0.002713423687964678
step: 160, loss: 0.0005245478241704404
step: 170, loss: 0.09014499187469482
step: 180, loss: 0.0034844328183680773
step: 190, loss: 0.00011081276170443743
step: 200, loss: 0.0004492496664170176
step: 210, loss: 0.0005589958745986223
step: 220, loss: 0.002104688435792923
step: 230, loss: 0.0038737915456295013
step: 240, loss: 0.00020617770496755838
step: 250, loss: 6.500707240775228e-05
step: 260, loss: 6.382209539879113e-05
step: 270, loss: 4.223555151838809e-05
step: 280, loss: 0.0014704139903187752
step: 290, loss: 0.00010494195157662034
step: 300, loss: 0.0012182685313746333
step: 310, loss: 0.00014661892782896757
step: 320, loss: 0.00011591026122914627
step: 330, loss: 8.3388906205073e-05
step: 340, loss: 0.00033248518593609333
step: 350, loss: 0.0002973146620206535
step: 360, loss: 0.0001402942871209234
step: 370, loss: 0.00022898655151948333
step: 380, loss: 0.00023872958263382316
epoch 18: dev_f1=0.7401129943502824, f1=0.6306306306306305, best_f1=0.6388888888888888
step: 0, loss: 0.04110684618353844
step: 10, loss: 0.011271137744188309
step: 20, loss: 0.00027981234597973526
step: 30, loss: 0.0006355919176712632
step: 40, loss: 0.0007170774624682963
step: 50, loss: 0.00022659121896140277
step: 60, loss: 9.777388913789764e-05
step: 70, loss: 0.0008473693742416799
step: 80, loss: 6.583480717381462e-05
step: 90, loss: 0.0004373293195385486
step: 100, loss: 0.0007271208451129496
step: 110, loss: 0.03712406009435654
step: 120, loss: 0.00017675850540399551
step: 130, loss: 6.299276719801128e-05
step: 140, loss: 5.23822454852052e-05
step: 150, loss: 0.0004574920458253473
step: 160, loss: 0.0004861451161559671
step: 170, loss: 0.00013373741239774972
step: 180, loss: 0.0005951603525318205
step: 190, loss: 0.00019210450409445912
step: 200, loss: 0.001919946982525289
step: 210, loss: 0.00045659136958420277
step: 220, loss: 5.100756243336946e-05
step: 230, loss: 9.199002670357004e-05
step: 240, loss: 5.154221798875369e-05
step: 250, loss: 5.5557444284204394e-05
step: 260, loss: 7.339558942476287e-05
step: 270, loss: 0.0003343842690810561
step: 280, loss: 3.8377820601454005e-05
step: 290, loss: 9.916225826600567e-05
step: 300, loss: 0.0002913016942329705
step: 310, loss: 0.00029294643900357187
step: 320, loss: 0.005583392456173897
step: 330, loss: 4.118427386856638e-05
step: 340, loss: 0.00013018342724535614
step: 350, loss: 0.00010078195919049904
step: 360, loss: 0.00019795566913671792
step: 370, loss: 0.0006590173579752445
step: 380, loss: 0.00016704171139281243
epoch 19: dev_f1=0.7329545454545454, f1=0.6066066066066066, best_f1=0.6388888888888888
step: 0, loss: 6.913808465469629e-05
step: 10, loss: 0.00012718771176878363
step: 20, loss: 0.00017331411072518677
step: 30, loss: 0.00045650932588614523
step: 40, loss: 0.0002661910839378834
step: 50, loss: 7.109141733963042e-05
step: 60, loss: 0.00013708083133678883
step: 70, loss: 6.926153582753614e-05
step: 80, loss: 0.00010285930329700932
step: 90, loss: 0.0007619588286615908
step: 100, loss: 8.112619980238378e-05
step: 110, loss: 0.0001172282500192523
step: 120, loss: 2.7185888029634953e-05
step: 130, loss: 0.00011010159505531192
step: 140, loss: 0.007416312582790852
step: 150, loss: 7.443231152137741e-05
step: 160, loss: 6.853776721982285e-05
step: 170, loss: 5.103335206513293e-05
step: 180, loss: 0.0007461332133971155
step: 190, loss: 0.0001435495214536786
step: 200, loss: 5.399758447310887e-05
step: 210, loss: 6.564122304553166e-05
step: 220, loss: 0.00019567334675230086
step: 230, loss: 0.0008610202348791063
step: 240, loss: 2.681008481886238e-05
step: 250, loss: 4.755341069540009e-05
step: 260, loss: 0.0005994353559799492
step: 270, loss: 8.069553587120026e-05
step: 280, loss: 0.00048833031905815
step: 290, loss: 0.00011308168177492917
step: 300, loss: 2.4369977836613543e-05
step: 310, loss: 7.621708937222138e-05
step: 320, loss: 0.0003259044315200299
step: 330, loss: 7.86382588557899e-05
step: 340, loss: 0.0001735467667458579
step: 350, loss: 0.00018181613995693624
step: 360, loss: 9.544597560307011e-05
step: 370, loss: 0.0008064659195952117
step: 380, loss: 0.0003960446920245886
epoch 20: dev_f1=0.7356948228882835, f1=0.6220930232558138, best_f1=0.6388888888888888
