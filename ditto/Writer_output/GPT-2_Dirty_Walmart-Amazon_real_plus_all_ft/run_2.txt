cuda
Device: cuda
step: 0, loss: 0.7831494808197021
step: 10, loss: 0.37721386551856995
step: 20, loss: 0.2348816841840744
step: 30, loss: 0.3054366707801819
step: 40, loss: 0.3053167760372162
step: 50, loss: 0.15581455826759338
step: 60, loss: 0.36411625146865845
step: 70, loss: 0.29224300384521484
step: 80, loss: 0.43261364102363586
step: 90, loss: 0.3034009039402008
step: 100, loss: 0.37367865443229675
step: 110, loss: 0.35847750306129456
step: 120, loss: 0.2474498152732849
step: 130, loss: 0.34494879841804504
step: 140, loss: 0.41472557187080383
step: 150, loss: 0.4092133939266205
step: 160, loss: 0.6556631922721863
step: 170, loss: 0.41951853036880493
step: 180, loss: 0.12914340198040009
step: 190, loss: 0.18087612092494965
step: 200, loss: 0.2325402796268463
step: 210, loss: 0.1756991147994995
step: 220, loss: 0.09836387634277344
step: 230, loss: 0.2550737261772156
step: 240, loss: 0.33680620789527893
step: 250, loss: 0.2158268392086029
step: 260, loss: 0.14741037786006927
step: 270, loss: 0.45456594228744507
step: 280, loss: 0.15394717454910278
step: 290, loss: 0.35968610644340515
step: 300, loss: 0.10607875138521194
step: 310, loss: 0.3034672141075134
step: 320, loss: 0.2287372350692749
step: 330, loss: 0.5968647003173828
step: 340, loss: 0.18075935542583466
step: 350, loss: 0.3347623348236084
step: 360, loss: 0.16163913905620575
step: 370, loss: 0.13473212718963623
step: 380, loss: 0.42760318517684937
epoch 1: dev_f1=0.466403162055336, f1=0.4230769230769231, best_f1=0.4230769230769231
step: 0, loss: 0.12669429183006287
step: 10, loss: 0.1936124861240387
step: 20, loss: 0.3106391727924347
step: 30, loss: 0.1276555359363556
step: 40, loss: 0.2216908484697342
step: 50, loss: 0.1875879317522049
step: 60, loss: 0.24419888854026794
step: 70, loss: 0.24103909730911255
step: 80, loss: 0.2367148995399475
step: 90, loss: 0.2831767499446869
step: 100, loss: 0.18891631066799164
step: 110, loss: 0.19442737102508545
step: 120, loss: 0.1834716647863388
step: 130, loss: 0.11753325909376144
step: 140, loss: 0.413382887840271
step: 150, loss: 0.11135084927082062
step: 160, loss: 0.21336837112903595
step: 170, loss: 0.12637634575366974
step: 180, loss: 0.2747732400894165
step: 190, loss: 0.591934859752655
step: 200, loss: 0.21719549596309662
step: 210, loss: 0.5729458332061768
step: 220, loss: 0.22976768016815186
step: 230, loss: 0.14670506119728088
step: 240, loss: 0.1716504842042923
step: 250, loss: 0.12099379301071167
step: 260, loss: 0.14503493905067444
step: 270, loss: 0.045836515724658966
step: 280, loss: 0.1406039595603943
step: 290, loss: 0.22409150004386902
step: 300, loss: 0.19388911128044128
step: 310, loss: 0.027859695255756378
step: 320, loss: 0.14767706394195557
step: 330, loss: 0.06325846910476685
step: 340, loss: 0.14225496351718903
step: 350, loss: 0.18424969911575317
step: 360, loss: 0.11449669301509857
step: 370, loss: 0.0721387043595314
step: 380, loss: 0.10014945268630981
epoch 2: dev_f1=0.7106598984771575, f1=0.611260053619303, best_f1=0.611260053619303
step: 0, loss: 0.23669551312923431
step: 10, loss: 0.17206504940986633
step: 20, loss: 0.0630611777305603
step: 30, loss: 0.1733117699623108
step: 40, loss: 0.0590062141418457
step: 50, loss: 0.057946041226387024
step: 60, loss: 0.12124866992235184
step: 70, loss: 0.04502127319574356
step: 80, loss: 0.06525790691375732
step: 90, loss: 0.13091865181922913
step: 100, loss: 0.02006668969988823
step: 110, loss: 0.07952836155891418
step: 120, loss: 0.03292686119675636
step: 130, loss: 0.09892641752958298
step: 140, loss: 0.08968556672334671
step: 150, loss: 0.16144193708896637
step: 160, loss: 0.011386381462216377
step: 170, loss: 0.21365243196487427
step: 180, loss: 0.10236414521932602
step: 190, loss: 0.16138046979904175
step: 200, loss: 0.16292446851730347
step: 210, loss: 0.11361916363239288
step: 220, loss: 0.13429602980613708
step: 230, loss: 0.141765296459198
step: 240, loss: 0.12284190952777863
step: 250, loss: 0.12629194557666779
step: 260, loss: 0.08283766359090805
step: 270, loss: 0.09823130816221237
step: 280, loss: 0.07445083558559418
step: 290, loss: 0.0724172368645668
step: 300, loss: 0.39507439732551575
step: 310, loss: 0.017262235283851624
step: 320, loss: 0.09418229758739471
step: 330, loss: 0.22499705851078033
step: 340, loss: 0.13317789137363434
step: 350, loss: 0.06698241084814072
step: 360, loss: 0.21998991072177887
step: 370, loss: 0.08645405620336533
step: 380, loss: 0.013407371006906033
epoch 3: dev_f1=0.7345844504021448, f1=0.5558739255014327, best_f1=0.5558739255014327
step: 0, loss: 0.13669000566005707
step: 10, loss: 0.041575707495212555
step: 20, loss: 0.03004937805235386
step: 30, loss: 0.04232863336801529
step: 40, loss: 0.07770758122205734
step: 50, loss: 0.02755586989223957
step: 60, loss: 0.07732529938220978
step: 70, loss: 0.2059500515460968
step: 80, loss: 0.07507017999887466
step: 90, loss: 0.06718021631240845
step: 100, loss: 0.006329461466521025
step: 110, loss: 0.04246997460722923
step: 120, loss: 0.12353570014238358
step: 130, loss: 0.03989488631486893
step: 140, loss: 0.022148119285702705
step: 150, loss: 0.0260159969329834
step: 160, loss: 0.004490163642913103
step: 170, loss: 0.00878293626010418
step: 180, loss: 0.3501775562763214
step: 190, loss: 0.01594718173146248
step: 200, loss: 0.10487775504589081
step: 210, loss: 0.022041549906134605
step: 220, loss: 0.026393521577119827
step: 230, loss: 0.015477979555726051
step: 240, loss: 0.14338593184947968
step: 250, loss: 0.04580315575003624
step: 260, loss: 0.014249916188418865
step: 270, loss: 0.05542786791920662
step: 280, loss: 0.03789808601140976
step: 290, loss: 0.1511753797531128
step: 300, loss: 0.10419134795665741
step: 310, loss: 0.040029674768447876
step: 320, loss: 0.24932464957237244
step: 330, loss: 0.08525560796260834
step: 340, loss: 0.0016975037287920713
step: 350, loss: 0.06134617328643799
step: 360, loss: 0.2738097310066223
step: 370, loss: 0.08516785502433777
step: 380, loss: 0.056348808109760284
epoch 4: dev_f1=0.716577540106952, f1=0.5859154929577465, best_f1=0.5558739255014327
step: 0, loss: 0.041717205196619034
step: 10, loss: 0.052907802164554596
step: 20, loss: 0.0324053131043911
step: 30, loss: 0.08107685297727585
step: 40, loss: 0.014106574468314648
step: 50, loss: 0.02419867366552353
step: 60, loss: 0.0181473046541214
step: 70, loss: 0.00724371150135994
step: 80, loss: 0.0419444777071476
step: 90, loss: 0.0031502158381044865
step: 100, loss: 0.02058246359229088
step: 110, loss: 0.1313972920179367
step: 120, loss: 0.011486807838082314
step: 130, loss: 0.12375500798225403
step: 140, loss: 0.055243395268917084
step: 150, loss: 0.007523461245000362
step: 160, loss: 0.013322790153324604
step: 170, loss: 0.11670979857444763
step: 180, loss: 0.03278101980686188
step: 190, loss: 0.004088183864951134
step: 200, loss: 0.02849850431084633
step: 210, loss: 0.15953491628170013
step: 220, loss: 0.0047346060164272785
step: 230, loss: 0.017358526587486267
step: 240, loss: 0.22515660524368286
step: 250, loss: 0.02464728243649006
step: 260, loss: 0.08616533875465393
step: 270, loss: 0.01311207190155983
step: 280, loss: 0.1749703735113144
step: 290, loss: 0.020224345847964287
step: 300, loss: 0.2242564558982849
step: 310, loss: 0.06805260479450226
step: 320, loss: 0.014564652927219868
step: 330, loss: 0.048560477793216705
step: 340, loss: 0.023150108754634857
step: 350, loss: 0.0054524182341992855
step: 360, loss: 0.04901301860809326
step: 370, loss: 0.006491956766694784
step: 380, loss: 0.014091547578573227
epoch 5: dev_f1=0.7555555555555555, f1=0.6272493573264781, best_f1=0.6272493573264781
step: 0, loss: 0.008749659173190594
step: 10, loss: 0.018302861601114273
step: 20, loss: 0.004132587928324938
step: 30, loss: 0.002689989050850272
step: 40, loss: 0.0203876756131649
step: 50, loss: 0.026159828528761864
step: 60, loss: 0.007377614267170429
step: 70, loss: 0.001829447690397501
step: 80, loss: 0.003241016762331128
step: 90, loss: 0.004250731784850359
step: 100, loss: 0.00597356166690588
step: 110, loss: 0.055405791848897934
step: 120, loss: 0.04531857371330261
step: 130, loss: 0.0693516880273819
step: 140, loss: 0.003808080917224288
step: 150, loss: 0.09546089917421341
step: 160, loss: 0.0016279469709843397
step: 170, loss: 0.029955536127090454
step: 180, loss: 0.003159903222694993
step: 190, loss: 0.045411501079797745
step: 200, loss: 0.027140555903315544
step: 210, loss: 0.0035243816673755646
step: 220, loss: 0.0066331056877970695
step: 230, loss: 0.08138766884803772
step: 240, loss: 0.12739740312099457
step: 250, loss: 0.006951437797397375
step: 260, loss: 0.0487888902425766
step: 270, loss: 0.05748726427555084
step: 280, loss: 0.05753495171666145
step: 290, loss: 0.018869396299123764
step: 300, loss: 0.004253569524735212
step: 310, loss: 0.0026137910317629576
step: 320, loss: 0.13354618847370148
step: 330, loss: 0.01790405623614788
step: 340, loss: 0.005255567375570536
step: 350, loss: 0.0659405067563057
step: 360, loss: 0.04171287640929222
step: 370, loss: 0.010893991217017174
step: 380, loss: 0.002731201471760869
epoch 6: dev_f1=0.7613941018766757, f1=0.5714285714285714, best_f1=0.5714285714285714
step: 0, loss: 0.11947382241487503
step: 10, loss: 0.0022607631981372833
step: 20, loss: 0.022739602252840996
step: 30, loss: 0.0008442547405138612
step: 40, loss: 0.003923345357179642
step: 50, loss: 0.0009109845268540084
step: 60, loss: 0.00031308236066251993
step: 70, loss: 0.005227888002991676
step: 80, loss: 0.15872451663017273
step: 90, loss: 0.002532901242375374
step: 100, loss: 0.01027803122997284
step: 110, loss: 0.0014961533015593886
step: 120, loss: 0.07270731031894684
step: 130, loss: 0.12061207741498947
step: 140, loss: 0.004548323806375265
step: 150, loss: 0.0031382604502141476
step: 160, loss: 0.011580722406506538
step: 170, loss: 0.03645651042461395
step: 180, loss: 0.0015568779781460762
step: 190, loss: 0.0009459118009544909
step: 200, loss: 0.009286550804972649
step: 210, loss: 0.001099994289688766
step: 220, loss: 0.13076236844062805
step: 230, loss: 0.03644915297627449
step: 240, loss: 0.022381383925676346
step: 250, loss: 0.011228201910853386
step: 260, loss: 0.0028172656893730164
step: 270, loss: 0.0021532948594540358
step: 280, loss: 0.01343673374503851
step: 290, loss: 0.00554283894598484
step: 300, loss: 0.04435335099697113
step: 310, loss: 0.001971537945792079
step: 320, loss: 0.036130279302597046
step: 330, loss: 0.006138049066066742
step: 340, loss: 0.03255930542945862
step: 350, loss: 0.019073065370321274
step: 360, loss: 0.006226553115993738
step: 370, loss: 0.09189286082983017
step: 380, loss: 0.014707135036587715
epoch 7: dev_f1=0.7708894878706198, f1=0.6413043478260869, best_f1=0.6413043478260869
step: 0, loss: 0.0017478310037404299
step: 10, loss: 0.06169773265719414
step: 20, loss: 0.010184253565967083
step: 30, loss: 0.049032341688871384
step: 40, loss: 0.0071434155106544495
step: 50, loss: 0.12852948904037476
step: 60, loss: 0.14669768512248993
step: 70, loss: 0.04734528064727783
step: 80, loss: 0.13581185042858124
step: 90, loss: 0.0006893950048834085
step: 100, loss: 0.0012496727285906672
step: 110, loss: 0.007967745885252953
step: 120, loss: 0.018932821229100227
step: 130, loss: 0.004369103815406561
step: 140, loss: 0.001067435136064887
step: 150, loss: 0.013269076123833656
step: 160, loss: 0.0008521471172571182
step: 170, loss: 0.0004897517501376569
step: 180, loss: 0.003301406977698207
step: 190, loss: 0.014557832852005959
step: 200, loss: 0.007519691716879606
step: 210, loss: 0.016721662133932114
step: 220, loss: 0.0015401928685605526
step: 230, loss: 0.0007458169129677117
step: 240, loss: 0.00829288735985756
step: 250, loss: 0.002164158271625638
step: 260, loss: 0.00021925391047261655
step: 270, loss: 0.006245318800210953
step: 280, loss: 0.03105214796960354
step: 290, loss: 0.0034979451447725296
step: 300, loss: 0.0033707204274833202
step: 310, loss: 0.0013850296381860971
step: 320, loss: 0.1609426885843277
step: 330, loss: 0.0009753399644978344
step: 340, loss: 0.0033557035494595766
step: 350, loss: 0.09662790596485138
step: 360, loss: 0.02399451844394207
step: 370, loss: 0.09674572199583054
step: 380, loss: 0.006552241742610931
epoch 8: dev_f1=0.7658536585365853, f1=0.6446700507614213, best_f1=0.6413043478260869
step: 0, loss: 0.003305750200524926
step: 10, loss: 0.00199030339717865
step: 20, loss: 0.001005458296276629
step: 30, loss: 0.012119890190660954
step: 40, loss: 0.0015817862004041672
step: 50, loss: 0.0014265341451391578
step: 60, loss: 0.00480983592569828
step: 70, loss: 0.0014947847230359912
step: 80, loss: 0.006266043055802584
step: 90, loss: 0.004263562615960836
step: 100, loss: 0.09916359186172485
step: 110, loss: 0.02045859768986702
step: 120, loss: 0.0012625802773982286
step: 130, loss: 0.0010585838463157415
step: 140, loss: 0.012504350394010544
step: 150, loss: 0.0004825181094929576
step: 160, loss: 0.010335423983633518
step: 170, loss: 0.009508224204182625
step: 180, loss: 0.06418795138597488
step: 190, loss: 0.0009302555117756128
step: 200, loss: 0.030603798106312752
step: 210, loss: 0.09265044331550598
step: 220, loss: 0.002051908988505602
step: 230, loss: 0.0010566322598606348
step: 240, loss: 0.0005815084441564977
step: 250, loss: 0.05557389184832573
step: 260, loss: 0.003675123443827033
step: 270, loss: 0.0006632510921917856
step: 280, loss: 0.0016756170662119985
step: 290, loss: 0.0003978975291829556
step: 300, loss: 0.012895933352410793
step: 310, loss: 0.07405704259872437
step: 320, loss: 0.0008434253395535052
step: 330, loss: 0.0004066531255375594
step: 340, loss: 0.0026997271925210953
step: 350, loss: 0.011608039028942585
step: 360, loss: 0.0019678438547998667
step: 370, loss: 0.0006130507099442184
step: 380, loss: 0.005763952620327473
epoch 9: dev_f1=0.7616438356164383, f1=0.6260869565217392, best_f1=0.6413043478260869
step: 0, loss: 0.002274562371894717
step: 10, loss: 0.023227956146001816
step: 20, loss: 0.0011927700834348798
step: 30, loss: 0.007380243856459856
step: 40, loss: 0.0007419788744300604
step: 50, loss: 0.013351550325751305
step: 60, loss: 0.004136997740715742
step: 70, loss: 0.0029606556054204702
step: 80, loss: 0.0012521876487880945
step: 90, loss: 0.00269545940682292
step: 100, loss: 0.001472507487051189
step: 110, loss: 0.0012586192460730672
step: 120, loss: 0.0023131261114031076
step: 130, loss: 0.002597623271867633
step: 140, loss: 0.00023792916908860207
step: 150, loss: 0.0008809476275928319
step: 160, loss: 0.04364674165844917
step: 170, loss: 0.0036492475774139166
step: 180, loss: 0.007938920520246029
step: 190, loss: 0.000506101583596319
step: 200, loss: 0.002836943604052067
step: 210, loss: 0.00027654171572066844
step: 220, loss: 0.018037309870123863
step: 230, loss: 0.007152126636356115
step: 240, loss: 0.0001302831369685009
step: 250, loss: 0.0008075378718785942
step: 260, loss: 0.0021560124587267637
step: 270, loss: 0.00011851438466692343
step: 280, loss: 0.0031205660197883844
step: 290, loss: 0.00021271681180223823
step: 300, loss: 0.0026189126074314117
step: 310, loss: 0.0004047543625347316
step: 320, loss: 0.0012050042860209942
step: 330, loss: 0.0014765557134523988
step: 340, loss: 0.005655812565237284
step: 350, loss: 0.0014281966723501682
step: 360, loss: 0.0024402549024671316
step: 370, loss: 0.0017720615724101663
step: 380, loss: 0.014777177944779396
epoch 10: dev_f1=0.7351351351351353, f1=0.5706051873198847, best_f1=0.6413043478260869
step: 0, loss: 0.00178425177000463
step: 10, loss: 0.0017502650152891874
step: 20, loss: 0.00035270239459350705
step: 30, loss: 0.00029695971170440316
step: 40, loss: 0.008098583668470383
step: 50, loss: 0.0005558067350648344
step: 60, loss: 0.00018009773339144886
step: 70, loss: 0.0005883036646991968
step: 80, loss: 0.00012777152005583048
step: 90, loss: 0.00010547575220698491
step: 100, loss: 0.0016484500374644995
step: 110, loss: 0.000130041255033575
step: 120, loss: 0.0017332419520244002
step: 130, loss: 0.0023425277322530746
step: 140, loss: 0.00038075316115282476
step: 150, loss: 0.00031092826975509524
step: 160, loss: 0.0006971309194341302
step: 170, loss: 0.005513868760317564
step: 180, loss: 0.0016571935266256332
step: 190, loss: 0.05396556854248047
step: 200, loss: 0.00434179836884141
step: 210, loss: 0.09029901772737503
step: 220, loss: 0.001079692505300045
step: 230, loss: 0.00046722954721190035
step: 240, loss: 0.0012777267256751657
step: 250, loss: 0.0015955728013068438
step: 260, loss: 0.00036201387410983443
step: 270, loss: 0.00421570660546422
step: 280, loss: 0.0004405220097396523
step: 290, loss: 0.0006326933507807553
step: 300, loss: 0.0004347337526269257
step: 310, loss: 0.00018349752645008266
step: 320, loss: 0.00025065886438824236
step: 330, loss: 0.00024611467961221933
step: 340, loss: 0.004810586106032133
step: 350, loss: 0.009911120869219303
step: 360, loss: 0.0019611648749560118
step: 370, loss: 0.0008397767087444663
step: 380, loss: 0.021021267399191856
epoch 11: dev_f1=0.7428571428571429, f1=0.6132596685082873, best_f1=0.6413043478260869
step: 0, loss: 0.0013338947901502252
step: 10, loss: 0.0009518970036879182
step: 20, loss: 0.0018588569946587086
step: 30, loss: 0.0024781150277704
step: 40, loss: 0.02130308374762535
step: 50, loss: 0.0003069528320338577
step: 60, loss: 0.006012676749378443
step: 70, loss: 0.012335475534200668
step: 80, loss: 0.0014931893674656749
step: 90, loss: 0.0009186379611492157
step: 100, loss: 0.00012736560893245041
step: 110, loss: 0.02338990569114685
step: 120, loss: 0.004990785848349333
step: 130, loss: 0.000355822267010808
step: 140, loss: 0.00024600003962405026
step: 150, loss: 0.03143075108528137
step: 160, loss: 0.0009626071550883353
step: 170, loss: 0.00011419686779845506
step: 180, loss: 0.0002786451659630984
step: 190, loss: 0.00017182721057906747
step: 200, loss: 0.0013358864234760404
step: 210, loss: 0.00123257574159652
step: 220, loss: 0.005172560457140207
step: 230, loss: 0.0002814781619235873
step: 240, loss: 0.001810312969610095
step: 250, loss: 0.00044107172288931906
step: 260, loss: 0.0004720912838820368
step: 270, loss: 0.004809251986443996
step: 280, loss: 0.0026288104709237814
step: 290, loss: 0.0002971838985104114
step: 300, loss: 0.007967471145093441
step: 310, loss: 0.0001761322346283123
step: 320, loss: 0.00013961885997559875
step: 330, loss: 0.00017703117919154465
step: 340, loss: 0.00024858786491677165
step: 350, loss: 0.0034305218141525984
step: 360, loss: 0.0015981702599674463
step: 370, loss: 0.059951409697532654
step: 380, loss: 0.0017617056146264076
epoch 12: dev_f1=0.7520891364902507, f1=0.592814371257485, best_f1=0.6413043478260869
step: 0, loss: 0.0003592345747165382
step: 10, loss: 0.0019743104930967093
step: 20, loss: 0.0006088495720177889
step: 30, loss: 0.008095278404653072
step: 40, loss: 0.0003276512725278735
step: 50, loss: 0.0007023810758255422
step: 60, loss: 0.00018069412908516824
step: 70, loss: 0.002786908531561494
step: 80, loss: 0.00040140023338608444
step: 90, loss: 8.485562284477055e-05
step: 100, loss: 0.0008826005505397916
step: 110, loss: 0.00031707348534837365
step: 120, loss: 0.00036669865949079394
step: 130, loss: 0.00020947378652635962
step: 140, loss: 0.00944594293832779
step: 150, loss: 0.004195759072899818
step: 160, loss: 0.00047196345985867083
step: 170, loss: 0.00010540809307713062
step: 180, loss: 0.0001594883797224611
step: 190, loss: 0.0016478104516863823
step: 200, loss: 0.09498461335897446
step: 210, loss: 0.00011985098535660654
step: 220, loss: 0.00011404851829865947
step: 230, loss: 0.016301555559039116
step: 240, loss: 0.0038746546488255262
step: 250, loss: 0.0023077160585671663
step: 260, loss: 0.0008831724990159273
step: 270, loss: 0.003703237744048238
step: 280, loss: 0.07413512468338013
step: 290, loss: 0.004529254976660013
step: 300, loss: 0.03384815528988838
step: 310, loss: 0.05244612321257591
step: 320, loss: 0.00013932281581219286
step: 330, loss: 0.001449285657145083
step: 340, loss: 0.045299187302589417
step: 350, loss: 0.00018320500385016203
step: 360, loss: 0.0002537905238568783
step: 370, loss: 0.00032539156381972134
step: 380, loss: 0.05120735242962837
epoch 13: dev_f1=0.776349614395887, f1=0.6210826210826211, best_f1=0.6210826210826211
step: 0, loss: 0.0029077024664729834
step: 10, loss: 0.00041207580943591893
step: 20, loss: 0.00012257922207936645
step: 30, loss: 0.00035919129732064903
step: 40, loss: 0.0007153814076445997
step: 50, loss: 0.0002187889040214941
step: 60, loss: 7.810152601450682e-05
step: 70, loss: 0.00024219948682002723
step: 80, loss: 0.005406535230576992
step: 90, loss: 7.07859217072837e-05
step: 100, loss: 5.578514901571907e-05
step: 110, loss: 0.00028697153902612627
step: 120, loss: 0.005906440783292055
step: 130, loss: 0.006102717947214842
step: 140, loss: 0.011396502144634724
step: 150, loss: 0.00031221137032844126
step: 160, loss: 0.06771460920572281
step: 170, loss: 0.00024299838696606457
step: 180, loss: 0.0007088473648764193
step: 190, loss: 0.00752154691144824
step: 200, loss: 0.0004035480087623
step: 210, loss: 0.00015937667922116816
step: 220, loss: 0.0002112082438543439
step: 230, loss: 0.00202206801623106
step: 240, loss: 0.00012671093281824142
step: 250, loss: 0.004570929333567619
step: 260, loss: 5.331576903699897e-05
step: 270, loss: 0.0059011103585362434
step: 280, loss: 8.755273302085698e-05
step: 290, loss: 0.00048021963448263705
step: 300, loss: 0.012347863987088203
step: 310, loss: 0.0003363530267961323
step: 320, loss: 0.19643618166446686
step: 330, loss: 7.285492029041052e-05
step: 340, loss: 0.01612081751227379
step: 350, loss: 0.0008387353736907244
step: 360, loss: 0.002903857734054327
step: 370, loss: 0.057186368852853775
step: 380, loss: 4.244017691235058e-05
epoch 14: dev_f1=0.7567567567567567, f1=0.6285714285714286, best_f1=0.6210826210826211
step: 0, loss: 9.628465340938419e-05
step: 10, loss: 0.0002524725568946451
step: 20, loss: 0.00024860765552148223
step: 30, loss: 0.0008084153523668647
step: 40, loss: 0.0058250026777386665
step: 50, loss: 0.0006057490245439112
step: 60, loss: 0.00020664108160417527
step: 70, loss: 0.00022760452702641487
step: 80, loss: 0.00012344191782176495
step: 90, loss: 0.000435713620390743
step: 100, loss: 0.001097561209462583
step: 110, loss: 5.380818038247526e-05
step: 120, loss: 0.00017044036940205842
step: 130, loss: 0.0001570151944179088
step: 140, loss: 0.0003616912290453911
step: 150, loss: 0.0003262989630457014
step: 160, loss: 0.005903676152229309
step: 170, loss: 5.720167246181518e-05
step: 180, loss: 0.0003974505525548011
step: 190, loss: 0.0009611860732547939
step: 200, loss: 0.0006234518950805068
step: 210, loss: 0.00023090689501259476
step: 220, loss: 0.0006476986454799771
step: 230, loss: 0.0002719474723562598
step: 240, loss: 0.004843861795961857
step: 250, loss: 3.567076055333018e-05
step: 260, loss: 0.00946838315576315
step: 270, loss: 0.002262124326080084
step: 280, loss: 0.03770693019032478
step: 290, loss: 0.0004430702538229525
step: 300, loss: 0.0014656574930995703
step: 310, loss: 0.00010519307397771627
step: 320, loss: 0.011812189593911171
step: 330, loss: 0.000586880196351558
step: 340, loss: 0.0008876234642229974
step: 350, loss: 0.00020476915233302861
step: 360, loss: 0.00045080960262566805
step: 370, loss: 0.00013133576430846006
step: 380, loss: 0.00027077909908257425
epoch 15: dev_f1=0.7727272727272727, f1=0.625668449197861, best_f1=0.6210826210826211
step: 0, loss: 0.0014242089819163084
step: 10, loss: 0.08686436712741852
step: 20, loss: 0.00845190230756998
step: 30, loss: 0.00011350221029715613
step: 40, loss: 0.0017961525591090322
step: 50, loss: 0.0012087872019037604
step: 60, loss: 0.0015766402939334512
step: 70, loss: 5.5721502576489e-05
step: 80, loss: 0.0009847983019426465
step: 90, loss: 0.0002514394000172615
step: 100, loss: 0.00935326050966978
step: 110, loss: 0.002933851210400462
step: 120, loss: 0.0002041551924776286
step: 130, loss: 0.00034379426506347954
step: 140, loss: 0.00016463917563669384
step: 150, loss: 7.850848487578332e-05
step: 160, loss: 0.00010727009066613391
step: 170, loss: 0.00011826184345409274
step: 180, loss: 7.87358294473961e-05
step: 190, loss: 6.26345063210465e-05
step: 200, loss: 0.00018064626783598214
step: 210, loss: 0.0003324534045532346
step: 220, loss: 0.0010470316046848893
step: 230, loss: 0.00013897848839405924
step: 240, loss: 0.00013545353431254625
step: 250, loss: 0.004108850844204426
step: 260, loss: 0.15940886735916138
step: 270, loss: 0.004485541023313999
step: 280, loss: 0.05593601614236832
step: 290, loss: 0.0002186290657846257
step: 300, loss: 0.0004000531625933945
step: 310, loss: 0.0003191007417626679
step: 320, loss: 0.0002897001104429364
step: 330, loss: 0.018747087568044662
step: 340, loss: 0.0016781400190666318
step: 350, loss: 0.00032631997601129115
step: 360, loss: 0.0004435080336406827
step: 370, loss: 0.00015707126294728369
step: 380, loss: 8.427378634223714e-05
epoch 16: dev_f1=0.745308310991957, f1=0.6069364161849712, best_f1=0.6210826210826211
step: 0, loss: 0.0012464667670428753
step: 10, loss: 0.00012570514809340239
step: 20, loss: 0.0001158328159363009
step: 30, loss: 0.0002090175257762894
step: 40, loss: 0.00010232214845018461
step: 50, loss: 0.002868719631806016
step: 60, loss: 7.825581269571558e-05
step: 70, loss: 0.0001372641563648358
step: 80, loss: 0.0003182732325512916
step: 90, loss: 0.0004599376115947962
step: 100, loss: 0.00011618071584962308
step: 110, loss: 0.00017580995336174965
step: 120, loss: 8.205501217162237e-05
step: 130, loss: 0.00017962961283046752
step: 140, loss: 0.0001920086215250194
step: 150, loss: 0.0006462515448220074
step: 160, loss: 9.625338861951604e-05
step: 170, loss: 5.5353018979076296e-05
step: 180, loss: 0.0020104367285966873
step: 190, loss: 0.0006470828084275126
step: 200, loss: 8.588856871938333e-05
step: 210, loss: 0.006348846480250359
step: 220, loss: 4.603595516528003e-05
step: 230, loss: 0.00024838122772052884
step: 240, loss: 9.186359966406599e-05
step: 250, loss: 8.684104250278324e-05
step: 260, loss: 0.0001156869693659246
step: 270, loss: 5.2403371228137985e-05
step: 280, loss: 6.421910075005144e-05
step: 290, loss: 6.494856643257663e-05
step: 300, loss: 4.269217970431782e-05
step: 310, loss: 0.00032946656574495137
step: 320, loss: 6.850076169939712e-05
step: 330, loss: 0.001864823279902339
step: 340, loss: 8.784644887782633e-05
step: 350, loss: 0.0003955829597543925
step: 360, loss: 5.390070145949721e-05
step: 370, loss: 6.198601477080956e-05
step: 380, loss: 0.00011506593727972358
epoch 17: dev_f1=0.753315649867374, f1=0.6005665722379604, best_f1=0.6210826210826211
step: 0, loss: 7.527138222940266e-05
step: 10, loss: 0.028697015717625618
step: 20, loss: 0.0005695936852134764
step: 30, loss: 0.0001102765672840178
step: 40, loss: 0.00010593370097922161
step: 50, loss: 0.00039962856681086123
step: 60, loss: 0.00023579101252835244
step: 70, loss: 3.9370734157273546e-05
step: 80, loss: 8.875989442458376e-05
step: 90, loss: 7.373611151706427e-05
step: 100, loss: 4.483379234443419e-05
step: 110, loss: 0.00010031843703472987
step: 120, loss: 0.0001685929310042411
step: 130, loss: 3.655124601209536e-05
step: 140, loss: 0.00013221624249126762
step: 150, loss: 0.004053018055856228
step: 160, loss: 0.0002046754671027884
step: 170, loss: 4.6462853788398206e-05
step: 180, loss: 0.0001948417047969997
step: 190, loss: 9.806540765566751e-05
step: 200, loss: 0.0002516780514270067
step: 210, loss: 7.423274655593559e-05
step: 220, loss: 0.0022184813860803843
step: 230, loss: 3.112341437372379e-05
step: 240, loss: 9.708410652820021e-05
step: 250, loss: 8.353014709427953e-05
step: 260, loss: 0.000683203455992043
step: 270, loss: 0.0001919807691592723
step: 280, loss: 0.0003377585671842098
step: 290, loss: 0.0002334477612748742
step: 300, loss: 9.027714258991182e-05
step: 310, loss: 0.00013180375390220433
step: 320, loss: 0.0001656022504903376
step: 330, loss: 8.29966229503043e-05
step: 340, loss: 0.0001908878330141306
step: 350, loss: 3.5034488973906264e-05
step: 360, loss: 0.00017280367319472134
step: 370, loss: 0.002727690152823925
step: 380, loss: 0.00026872396119870245
epoch 18: dev_f1=0.7588075880758809, f1=0.5885885885885886, best_f1=0.6210826210826211
step: 0, loss: 0.00017683931218925864
step: 10, loss: 0.00015172608254943043
step: 20, loss: 0.0002797698543872684
step: 30, loss: 0.00010374334669904783
step: 40, loss: 9.354316716780886e-05
step: 50, loss: 0.0001254063390661031
step: 60, loss: 0.0001348119549220428
step: 70, loss: 0.00012677197810262442
step: 80, loss: 0.00042254856089130044
step: 90, loss: 8.275930304080248e-05
step: 100, loss: 6.618512998102233e-05
step: 110, loss: 0.020276224240660667
step: 120, loss: 0.00028703256975859404
step: 130, loss: 0.0003682213427964598
step: 140, loss: 6.523687625303864e-05
step: 150, loss: 0.0007222099811770022
step: 160, loss: 0.0014001602539792657
step: 170, loss: 0.0006587154348380864
step: 180, loss: 0.00014122368884272873
step: 190, loss: 0.00030464748851954937
step: 200, loss: 5.961781062069349e-05
step: 210, loss: 0.0002580767322797328
step: 220, loss: 0.001035040826536715
step: 230, loss: 0.000180432791239582
step: 240, loss: 4.6912253310438246e-05
step: 250, loss: 0.0017794453306123614
step: 260, loss: 0.0009548602974973619
step: 270, loss: 0.0006521199247799814
step: 280, loss: 0.0007943487726151943
step: 290, loss: 0.0001536373601993546
step: 300, loss: 0.00010939580533886328
step: 310, loss: 0.00017588060291018337
step: 320, loss: 0.0001363136398140341
step: 330, loss: 4.194121356704272e-05
step: 340, loss: 3.7068813981022686e-05
step: 350, loss: 6.41130463918671e-05
step: 360, loss: 4.2045212467201054e-05
step: 370, loss: 6.600077904295176e-05
step: 380, loss: 3.908674625563435e-05
epoch 19: dev_f1=0.7634408602150539, f1=0.5773809523809523, best_f1=0.6210826210826211
step: 0, loss: 0.0006326762959361076
step: 10, loss: 0.0004408902896102518
step: 20, loss: 0.00021850345365237445
step: 30, loss: 0.00011464853014331311
step: 40, loss: 0.00028399177244864404
step: 50, loss: 0.0001411776611348614
step: 60, loss: 0.003346997080370784
step: 70, loss: 9.359014075016603e-05
step: 80, loss: 6.360132101690397e-05
step: 90, loss: 0.00025001028552651405
step: 100, loss: 0.00020055883214809
step: 110, loss: 0.00022924283985048532
step: 120, loss: 5.6741831940598786e-05
step: 130, loss: 0.00025779736461117864
step: 140, loss: 8.439493831247091e-05
step: 150, loss: 0.00020645557378884405
step: 160, loss: 4.562081812764518e-05
step: 170, loss: 0.0013106254627928138
step: 180, loss: 0.00022900688054505736
step: 190, loss: 0.0030746860429644585
step: 200, loss: 0.00023339982726611197
step: 210, loss: 9.024120663525537e-05
step: 220, loss: 0.00010827106598298997
step: 230, loss: 5.864281774847768e-05
step: 240, loss: 7.647663733223453e-05
step: 250, loss: 0.02785940282046795
step: 260, loss: 0.00012420960410963744
step: 270, loss: 0.00011942517448915169
step: 280, loss: 8.590833749622107e-05
step: 290, loss: 0.016900939866900444
step: 300, loss: 0.00012604144285432994
step: 310, loss: 4.944423562847078e-05
step: 320, loss: 0.00016388371295761317
step: 330, loss: 0.000130641448777169
step: 340, loss: 0.0009768973104655743
step: 350, loss: 5.699155371985398e-05
step: 360, loss: 4.620337494998239e-05
step: 370, loss: 0.00015843170695006847
step: 380, loss: 0.00011735627776943147
epoch 20: dev_f1=0.7639257294429709, f1=0.5944444444444444, best_f1=0.6210826210826211
