cuda
Device: cuda
step: 0, loss: 0.7124055624008179
step: 10, loss: 0.36651694774627686
step: 20, loss: 0.3798215091228485
step: 30, loss: 0.48123660683631897
step: 40, loss: 0.3606433570384979
step: 50, loss: 0.29156091809272766
step: 60, loss: 0.15486490726470947
step: 70, loss: 0.17588187754154205
step: 80, loss: 0.17627228796482086
step: 90, loss: 0.21878527104854584
step: 100, loss: 0.5178337693214417
step: 110, loss: 0.21642275154590607
step: 120, loss: 0.15897095203399658
step: 130, loss: 0.2158387303352356
step: 140, loss: 0.6713537573814392
step: 150, loss: 0.3002575635910034
step: 160, loss: 0.283039927482605
step: 170, loss: 0.31215396523475647
step: 180, loss: 0.47927016019821167
step: 190, loss: 0.19565196335315704
step: 200, loss: 0.35010096430778503
step: 210, loss: 0.327770859003067
step: 220, loss: 0.18887804448604584
step: 230, loss: 0.23207050561904907
step: 240, loss: 0.2801046073436737
step: 250, loss: 0.32342812418937683
step: 260, loss: 0.14730674028396606
step: 270, loss: 0.35134968161582947
step: 280, loss: 0.31862738728523254
step: 290, loss: 0.15976089239120483
step: 300, loss: 0.18812739849090576
step: 310, loss: 0.11389128118753433
step: 320, loss: 0.3066822588443756
step: 330, loss: 0.33145856857299805
step: 340, loss: 0.21227969229221344
step: 350, loss: 0.2978147864341736
step: 360, loss: 0.32618939876556396
step: 370, loss: 0.18930916488170624
step: 380, loss: 0.2139134556055069
epoch 1: dev_f1=0.5398773006134969, f1=0.4318936877076412, best_f1=0.4318936877076412
step: 0, loss: 0.18593929708003998
step: 10, loss: 0.061873648315668106
step: 20, loss: 0.12417315691709518
step: 30, loss: 0.0517670176923275
step: 40, loss: 0.12577028572559357
step: 50, loss: 0.1515355408191681
step: 60, loss: 0.21227066218852997
step: 70, loss: 0.13845066726207733
step: 80, loss: 0.06399205327033997
step: 90, loss: 0.12722176313400269
step: 100, loss: 0.10652315616607666
step: 110, loss: 0.3604075014591217
step: 120, loss: 0.20958827435970306
step: 130, loss: 0.018497243523597717
step: 140, loss: 0.1319117248058319
step: 150, loss: 0.15411639213562012
step: 160, loss: 0.23643474280834198
step: 170, loss: 0.20072248578071594
step: 180, loss: 0.047565244138240814
step: 190, loss: 0.265525758266449
step: 200, loss: 0.1451764553785324
step: 210, loss: 0.13333725929260254
step: 220, loss: 0.06964520364999771
step: 230, loss: 0.18062369525432587
step: 240, loss: 0.05980277806520462
step: 250, loss: 0.3726283609867096
step: 260, loss: 0.1620735377073288
step: 270, loss: 0.3983573317527771
step: 280, loss: 0.06414252519607544
step: 290, loss: 0.028764719143509865
step: 300, loss: 0.15752628445625305
step: 310, loss: 0.07165533304214478
step: 320, loss: 0.2618058919906616
step: 330, loss: 0.20932546257972717
step: 340, loss: 0.30321019887924194
step: 350, loss: 0.07873736321926117
step: 360, loss: 0.14764751493930817
step: 370, loss: 0.20398157835006714
step: 380, loss: 0.29121366143226624
epoch 2: dev_f1=0.6744186046511628, f1=0.5476923076923076, best_f1=0.5476923076923076
step: 0, loss: 0.18963679671287537
step: 10, loss: 0.03796149417757988
step: 20, loss: 0.04957626760005951
step: 30, loss: 0.1445624977350235
step: 40, loss: 0.06502386927604675
step: 50, loss: 0.08344065397977829
step: 60, loss: 0.08139313757419586
step: 70, loss: 0.21043217182159424
step: 80, loss: 0.07121019810438156
step: 90, loss: 0.13623130321502686
step: 100, loss: 0.2203308492898941
step: 110, loss: 0.11561286449432373
step: 120, loss: 0.20121634006500244
step: 130, loss: 0.08528979122638702
step: 140, loss: 0.049369458109140396
step: 150, loss: 0.016313541680574417
step: 160, loss: 0.12116333097219467
step: 170, loss: 0.23649238049983978
step: 180, loss: 0.13939768075942993
step: 190, loss: 0.05127983167767525
step: 200, loss: 0.03260687366127968
step: 210, loss: 0.09584607928991318
step: 220, loss: 0.11791947484016418
step: 230, loss: 0.1915525197982788
step: 240, loss: 0.048002418130636215
step: 250, loss: 0.11267226189374924
step: 260, loss: 0.03649946302175522
step: 270, loss: 0.12429406493902206
step: 280, loss: 0.08029630035161972
step: 290, loss: 0.07263365387916565
step: 300, loss: 0.06916493922472
step: 310, loss: 0.04268442094326019
step: 320, loss: 0.035598669201135635
step: 330, loss: 0.07098075747489929
step: 340, loss: 0.15441787242889404
step: 350, loss: 0.11624125391244888
step: 360, loss: 0.06929975003004074
step: 370, loss: 0.043457966297864914
step: 380, loss: 0.10211264342069626
epoch 3: dev_f1=0.7671957671957672, f1=0.6436170212765957, best_f1=0.6436170212765957
step: 0, loss: 0.039253152906894684
step: 10, loss: 0.029593076556921005
step: 20, loss: 0.028311174362897873
step: 30, loss: 0.0470159649848938
step: 40, loss: 0.12746880948543549
step: 50, loss: 0.14723306894302368
step: 60, loss: 0.25980517268180847
step: 70, loss: 0.061318233609199524
step: 80, loss: 0.09755632281303406
step: 90, loss: 0.0072333067655563354
step: 100, loss: 0.033269546926021576
step: 110, loss: 0.11999902129173279
step: 120, loss: 0.0688963532447815
step: 130, loss: 0.06651869416236877
step: 140, loss: 0.15156571567058563
step: 150, loss: 0.02057444117963314
step: 160, loss: 0.14363498985767365
step: 170, loss: 0.015286512672901154
step: 180, loss: 0.04103180021047592
step: 190, loss: 0.019595928490161896
step: 200, loss: 0.040377046912908554
step: 210, loss: 0.09687697142362595
step: 220, loss: 0.2550772428512573
step: 230, loss: 0.0756487250328064
step: 240, loss: 0.015878351405262947
step: 250, loss: 0.06559034436941147
step: 260, loss: 0.05565887689590454
step: 270, loss: 0.10614626854658127
step: 280, loss: 0.01371381152421236
step: 290, loss: 0.15997114777565002
step: 300, loss: 0.040424644947052
step: 310, loss: 0.07053950428962708
step: 320, loss: 0.04909432679414749
step: 330, loss: 0.055945899337530136
step: 340, loss: 0.026763256639242172
step: 350, loss: 0.0087627824395895
step: 360, loss: 0.009598053060472012
step: 370, loss: 0.11358212679624557
step: 380, loss: 0.0045615010894834995
epoch 4: dev_f1=0.6685714285714286, f1=0.5497076023391813, best_f1=0.6436170212765957
step: 0, loss: 0.16968680918216705
step: 10, loss: 0.04832267761230469
step: 20, loss: 0.022068379446864128
step: 30, loss: 0.11715833097696304
step: 40, loss: 0.019458049908280373
step: 50, loss: 0.04468532279133797
step: 60, loss: 0.009484149515628815
step: 70, loss: 0.032336656004190445
step: 80, loss: 0.08358101546764374
step: 90, loss: 0.009375353343784809
step: 100, loss: 0.008125817403197289
step: 110, loss: 0.038324929773807526
step: 120, loss: 0.0606805644929409
step: 130, loss: 0.004830778576433659
step: 140, loss: 0.0396900437772274
step: 150, loss: 0.014849630184471607
step: 160, loss: 0.256820946931839
step: 170, loss: 0.10098820924758911
step: 180, loss: 0.010044503957033157
step: 190, loss: 0.12121088057756424
step: 200, loss: 0.09722031652927399
step: 210, loss: 0.033439114689826965
step: 220, loss: 0.01896892674267292
step: 230, loss: 0.07015769183635712
step: 240, loss: 0.12999966740608215
step: 250, loss: 0.17375917732715607
step: 260, loss: 0.28022727370262146
step: 270, loss: 0.08800585567951202
step: 280, loss: 0.29228082299232483
step: 290, loss: 0.03415433689951897
step: 300, loss: 0.031917545944452286
step: 310, loss: 0.04764803126454353
step: 320, loss: 0.026089506223797798
step: 330, loss: 0.028615429997444153
step: 340, loss: 0.098000168800354
step: 350, loss: 0.09667984396219254
step: 360, loss: 0.016414906829595566
step: 370, loss: 0.014419338665902615
step: 380, loss: 0.039422180503606796
epoch 5: dev_f1=0.672463768115942, f1=0.5438066465256797, best_f1=0.6436170212765957
step: 0, loss: 0.024339528754353523
step: 10, loss: 0.005775874480605125
step: 20, loss: 0.0012830004561692476
step: 30, loss: 0.019972510635852814
step: 40, loss: 0.002732643624767661
step: 50, loss: 0.0244552344083786
step: 60, loss: 0.002168813021853566
step: 70, loss: 0.00437513180077076
step: 80, loss: 0.027092650532722473
step: 90, loss: 0.0030681362841278315
step: 100, loss: 0.02797464281320572
step: 110, loss: 0.04401693493127823
step: 120, loss: 0.011045928113162518
step: 130, loss: 0.011732794344425201
step: 140, loss: 0.09352052956819534
step: 150, loss: 0.10997337847948074
step: 160, loss: 0.012177512980997562
step: 170, loss: 0.017552450299263
step: 180, loss: 0.010854094289243221
step: 190, loss: 0.010046802461147308
step: 200, loss: 0.0008801554213277996
step: 210, loss: 0.18953430652618408
step: 220, loss: 0.03422292321920395
step: 230, loss: 0.0021581563632935286
step: 240, loss: 0.0038070979062467813
step: 250, loss: 0.022491559386253357
step: 260, loss: 0.005901360884308815
step: 270, loss: 0.03233671188354492
step: 280, loss: 0.0055289254523813725
step: 290, loss: 0.05218137428164482
step: 300, loss: 0.06008834391832352
step: 310, loss: 0.0025072183925658464
step: 320, loss: 0.003334468463435769
step: 330, loss: 0.003652672516182065
step: 340, loss: 0.0025996994227170944
step: 350, loss: 0.03015313111245632
step: 360, loss: 0.002156228059902787
step: 370, loss: 0.04411692917346954
step: 380, loss: 0.04533165320754051
epoch 6: dev_f1=0.7112299465240641, f1=0.6158038147138964, best_f1=0.6436170212765957
step: 0, loss: 0.005844871047884226
step: 10, loss: 0.02192000113427639
step: 20, loss: 0.007884201593697071
step: 30, loss: 0.0024627121165394783
step: 40, loss: 0.0024728034622967243
step: 50, loss: 0.004902664106339216
step: 60, loss: 0.139391228556633
step: 70, loss: 0.04700060561299324
step: 80, loss: 0.04237304627895355
step: 90, loss: 0.00514596700668335
step: 100, loss: 0.0012160601327195764
step: 110, loss: 0.02521754801273346
step: 120, loss: 0.043032970279455185
step: 130, loss: 0.013058274984359741
step: 140, loss: 0.019919687882065773
step: 150, loss: 0.018672993406653404
step: 160, loss: 0.009949155151844025
step: 170, loss: 0.000991516513749957
step: 180, loss: 0.00489262817427516
step: 190, loss: 0.0024138321168720722
step: 200, loss: 0.013047483749687672
step: 210, loss: 0.1826966106891632
step: 220, loss: 0.023126257583498955
step: 230, loss: 0.004919934086501598
step: 240, loss: 0.002858312800526619
step: 250, loss: 0.0024719038046896458
step: 260, loss: 0.002403923310339451
step: 270, loss: 0.011730962432920933
step: 280, loss: 0.002519509755074978
step: 290, loss: 0.028375139459967613
step: 300, loss: 0.007546365261077881
step: 310, loss: 0.0052725872956216335
step: 320, loss: 0.011942488141357899
step: 330, loss: 0.052159979939460754
step: 340, loss: 0.003300449112430215
step: 350, loss: 0.0056312535889446735
step: 360, loss: 0.09514625370502472
step: 370, loss: 0.025839373469352722
step: 380, loss: 0.005869335029274225
epoch 7: dev_f1=0.6871794871794872, f1=0.5839793281653747, best_f1=0.6436170212765957
step: 0, loss: 0.04864893853664398
step: 10, loss: 0.0073686037212610245
step: 20, loss: 0.02447798103094101
step: 30, loss: 0.018438519909977913
step: 40, loss: 0.1401459127664566
step: 50, loss: 0.0026774799916893244
step: 60, loss: 0.02576497383415699
step: 70, loss: 0.0013093870365992188
step: 80, loss: 0.0003012155939359218
step: 90, loss: 0.004718806128948927
step: 100, loss: 0.010193300433456898
step: 110, loss: 0.01029842346906662
step: 120, loss: 0.0006165899685584009
step: 130, loss: 0.006600101012736559
step: 140, loss: 0.014444268308579922
step: 150, loss: 0.0031142295338213444
step: 160, loss: 0.017945710569620132
step: 170, loss: 0.0023503394331783056
step: 180, loss: 0.006776715628802776
step: 190, loss: 0.0025933904107660055
step: 200, loss: 0.004396595060825348
step: 210, loss: 0.15586163103580475
step: 220, loss: 0.01669476181268692
step: 230, loss: 0.06430121511220932
step: 240, loss: 0.002120714168995619
step: 250, loss: 0.003361528040841222
step: 260, loss: 0.0602559894323349
step: 270, loss: 0.01674445904791355
step: 280, loss: 0.012441454455256462
step: 290, loss: 0.0004829753306694329
step: 300, loss: 0.007269051857292652
step: 310, loss: 0.001971483463421464
step: 320, loss: 0.0009997691959142685
step: 330, loss: 0.0020766023080796003
step: 340, loss: 0.008617673069238663
step: 350, loss: 0.003564339131116867
step: 360, loss: 0.014408787712454796
step: 370, loss: 0.1443503350019455
step: 380, loss: 0.010287185199558735
epoch 8: dev_f1=0.6347305389221556, f1=0.525, best_f1=0.6436170212765957
step: 0, loss: 0.05323655158281326
step: 10, loss: 0.011079947464168072
step: 20, loss: 0.002936099423095584
step: 30, loss: 0.0032808745745569468
step: 40, loss: 0.006721103098243475
step: 50, loss: 0.012224220670759678
step: 60, loss: 0.03090503253042698
step: 70, loss: 0.004321346990764141
step: 80, loss: 0.002466888865455985
step: 90, loss: 0.0065977065823972225
step: 100, loss: 0.035626716911792755
step: 110, loss: 0.0027585916686803102
step: 120, loss: 0.011652936227619648
step: 130, loss: 0.0012311912141740322
step: 140, loss: 0.0025423881597816944
step: 150, loss: 0.00031242927070707083
step: 160, loss: 0.007914712652564049
step: 170, loss: 0.006092059891670942
step: 180, loss: 0.0010919950436800718
step: 190, loss: 0.00018601542979013175
step: 200, loss: 0.2502734959125519
step: 210, loss: 0.09092804044485092
step: 220, loss: 0.008365007117390633
step: 230, loss: 0.0006829663761891425
step: 240, loss: 0.012403221800923347
step: 250, loss: 0.034492094069719315
step: 260, loss: 0.010489885695278645
step: 270, loss: 0.016319051384925842
step: 280, loss: 0.000557855935767293
step: 290, loss: 0.019341357052326202
step: 300, loss: 0.11288664489984512
step: 310, loss: 0.0008256006403826177
step: 320, loss: 0.0034480546601116657
step: 330, loss: 0.0009485819027759135
step: 340, loss: 0.001042485237121582
step: 350, loss: 0.006802352145314217
step: 360, loss: 0.0019042495405301452
step: 370, loss: 0.001457537873648107
step: 380, loss: 0.0004282342561054975
epoch 9: dev_f1=0.7282321899736147, f1=0.656, best_f1=0.6436170212765957
step: 0, loss: 0.0019026687368750572
step: 10, loss: 0.004783495329320431
step: 20, loss: 0.08800791203975677
step: 30, loss: 0.0005634254193864763
step: 40, loss: 0.0005723092472180724
step: 50, loss: 0.0002473292115610093
step: 60, loss: 0.000721212534699589
step: 70, loss: 0.021990103647112846
step: 80, loss: 0.006193419452756643
step: 90, loss: 0.021552041172981262
step: 100, loss: 0.002103930339217186
step: 110, loss: 0.01323438249528408
step: 120, loss: 0.0004642240237444639
step: 130, loss: 0.000461932533653453
step: 140, loss: 0.002106616273522377
step: 150, loss: 0.0005765746464021504
step: 160, loss: 0.02228791080415249
step: 170, loss: 0.034806571900844574
step: 180, loss: 0.001359831541776657
step: 190, loss: 0.021854359656572342
step: 200, loss: 0.01646106317639351
step: 210, loss: 0.0038903725799173117
step: 220, loss: 0.015650251880288124
step: 230, loss: 0.06440325081348419
step: 240, loss: 0.009103840216994286
step: 250, loss: 0.002051512710750103
step: 260, loss: 0.0006392062641680241
step: 270, loss: 0.001194443553686142
step: 280, loss: 0.004838794469833374
step: 290, loss: 0.005433983169496059
step: 300, loss: 0.00023425430117640644
step: 310, loss: 0.08809622377157211
step: 320, loss: 0.0024981016758829355
step: 330, loss: 0.0034028789959847927
step: 340, loss: 0.014963192865252495
step: 350, loss: 0.0038698322605341673
step: 360, loss: 0.000762720825150609
step: 370, loss: 0.00022939546033740044
step: 380, loss: 0.0009001744911074638
epoch 10: dev_f1=0.7206703910614525, f1=0.6023391812865497, best_f1=0.6436170212765957
step: 0, loss: 0.004322913009673357
step: 10, loss: 0.002971729263663292
step: 20, loss: 0.0005023389821872115
step: 30, loss: 0.01602344587445259
step: 40, loss: 0.005876155104488134
step: 50, loss: 0.02100263349711895
step: 60, loss: 0.00031563383527100086
step: 70, loss: 0.007023000158369541
step: 80, loss: 0.010159457102417946
step: 90, loss: 0.0013633818598464131
step: 100, loss: 0.0008213897235691547
step: 110, loss: 0.025146150961518288
step: 120, loss: 0.0023522202391177416
step: 130, loss: 0.005423791706562042
step: 140, loss: 0.00019319388957228512
step: 150, loss: 0.003640685696154833
step: 160, loss: 0.09714721143245697
step: 170, loss: 0.003538210643455386
step: 180, loss: 0.00013669917825609446
step: 190, loss: 0.00023310516553465277
step: 200, loss: 0.1243385449051857
step: 210, loss: 0.00016985819092951715
step: 220, loss: 0.00024948077043518424
step: 230, loss: 0.0032903256360441446
step: 240, loss: 0.0006541680777445436
step: 250, loss: 0.0004248155455570668
step: 260, loss: 0.0003379247209522873
step: 270, loss: 0.0005933556822128594
step: 280, loss: 0.015719281509518623
step: 290, loss: 0.001235567033290863
step: 300, loss: 0.00012992577103432268
step: 310, loss: 0.0018149942625313997
step: 320, loss: 0.05851374566555023
step: 330, loss: 0.00046159702469594777
step: 340, loss: 0.0017089780885726213
step: 350, loss: 0.004795979708433151
step: 360, loss: 0.001559982541948557
step: 370, loss: 0.0033894358202815056
step: 380, loss: 0.0012482490856200457
epoch 11: dev_f1=0.7120418848167539, f1=0.6058981233243967, best_f1=0.6436170212765957
step: 0, loss: 0.00011446957068983465
step: 10, loss: 0.0029082088731229305
step: 20, loss: 0.0008986610337160528
step: 30, loss: 0.000348483445122838
step: 40, loss: 0.0004624351568054408
step: 50, loss: 0.004099132493138313
step: 60, loss: 0.0001573067274875939
step: 70, loss: 0.00023005912953522056
step: 80, loss: 0.0008973595686256886
step: 90, loss: 0.07972199469804764
step: 100, loss: 0.00010197509982390329
step: 110, loss: 0.0014845345867797732
step: 120, loss: 0.0016232733614742756
step: 130, loss: 0.001825406332500279
step: 140, loss: 0.0014855964109301567
step: 150, loss: 0.0004013004363514483
step: 160, loss: 0.002482083858922124
step: 170, loss: 0.0007496303878724575
step: 180, loss: 0.0010520844953134656
step: 190, loss: 0.00039992513484321535
step: 200, loss: 0.0008455535280518234
step: 210, loss: 0.00043073963024653494
step: 220, loss: 0.00024848204338923097
step: 230, loss: 0.0009812870994210243
step: 240, loss: 0.00022891239495947957
step: 250, loss: 0.0002996200055349618
step: 260, loss: 0.0003693238249979913
step: 270, loss: 9.758309897733852e-05
step: 280, loss: 0.07930590957403183
step: 290, loss: 4.993427137378603e-05
step: 300, loss: 0.019564533606171608
step: 310, loss: 0.008273876272141933
step: 320, loss: 0.0023121510166674852
step: 330, loss: 0.017257334664463997
step: 340, loss: 0.0028662318363785744
step: 350, loss: 0.00017903225671034306
step: 360, loss: 0.000303423497825861
step: 370, loss: 0.0009423237643204629
step: 380, loss: 0.01687273383140564
epoch 12: dev_f1=0.6892655367231638, f1=0.580060422960725, best_f1=0.6436170212765957
step: 0, loss: 0.03552202507853508
step: 10, loss: 0.002015376230701804
step: 20, loss: 0.02322331815958023
step: 30, loss: 0.000483572919620201
step: 40, loss: 0.00014496667427010834
step: 50, loss: 0.00015628708933945745
step: 60, loss: 0.0001263798912987113
step: 70, loss: 0.00016300439892802387
step: 80, loss: 0.0009472478413954377
step: 90, loss: 0.018990671262145042
step: 100, loss: 0.0002139379212167114
step: 110, loss: 0.020710540935397148
step: 120, loss: 0.015316461212933064
step: 130, loss: 0.0002456060901749879
step: 140, loss: 0.0016426225192844868
step: 150, loss: 0.0032499798107892275
step: 160, loss: 0.01073866430670023
step: 170, loss: 0.0009252639720216393
step: 180, loss: 0.005128766410052776
step: 190, loss: 0.0028859965968877077
step: 200, loss: 0.0012279916554689407
step: 210, loss: 0.012392777018249035
step: 220, loss: 0.0004425946972332895
step: 230, loss: 0.0009019512217491865
step: 240, loss: 0.0002738676848821342
step: 250, loss: 0.00020991728524677455
step: 260, loss: 0.0003045799385290593
step: 270, loss: 0.0009980234317481518
step: 280, loss: 0.0001242755097337067
step: 290, loss: 0.0004420451878104359
step: 300, loss: 0.0049502113834023476
step: 310, loss: 0.0001822564663598314
step: 320, loss: 0.0003774444339796901
step: 330, loss: 0.00035468899295665324
step: 340, loss: 0.0005517284153029323
step: 350, loss: 0.009660091251134872
step: 360, loss: 0.006142576690763235
step: 370, loss: 0.0005132773076184094
step: 380, loss: 0.0004903287626802921
epoch 13: dev_f1=0.7086614173228346, f1=0.6149732620320856, best_f1=0.6436170212765957
step: 0, loss: 0.0008444300037808716
step: 10, loss: 0.0026446727570146322
step: 20, loss: 0.00025552650913596153
step: 30, loss: 0.00010760487202787772
step: 40, loss: 0.0001716511615086347
step: 50, loss: 0.0024969244841486216
step: 60, loss: 0.0034793224185705185
step: 70, loss: 0.02000022865831852
step: 80, loss: 0.006729813292622566
step: 90, loss: 0.00017493273480795324
step: 100, loss: 0.0018440926214680076
step: 110, loss: 0.00023109860194381326
step: 120, loss: 5.411886013462208e-05
step: 130, loss: 0.0014744376530870795
step: 140, loss: 0.06915590912103653
step: 150, loss: 0.00010106571426149458
step: 160, loss: 4.80262897326611e-05
step: 170, loss: 0.00012555318244267255
step: 180, loss: 0.00044445894309319556
step: 190, loss: 0.002136986004188657
step: 200, loss: 0.0024908315390348434
step: 210, loss: 0.0005644327029585838
step: 220, loss: 0.05380932614207268
step: 230, loss: 0.004183939192444086
step: 240, loss: 0.0005199272418394685
step: 250, loss: 0.0020695615094155073
step: 260, loss: 0.0022391737438738346
step: 270, loss: 9.111454710364342e-05
step: 280, loss: 0.00017719312745612115
step: 290, loss: 0.026105914264917374
step: 300, loss: 0.0001023113654810004
step: 310, loss: 0.00019158568466082215
step: 320, loss: 0.001106024137698114
step: 330, loss: 5.146603143657558e-05
step: 340, loss: 0.00826428271830082
step: 350, loss: 0.00024052000662777573
step: 360, loss: 0.0003579785116016865
step: 370, loss: 2.5759696654859e-05
step: 380, loss: 0.0006078257574699819
epoch 14: dev_f1=0.7354497354497355, f1=0.6033519553072626, best_f1=0.6436170212765957
step: 0, loss: 0.0009092535474337637
step: 10, loss: 4.5497348764911294e-05
step: 20, loss: 0.000693187233991921
step: 30, loss: 0.018156245350837708
step: 40, loss: 0.00027886489988304675
step: 50, loss: 0.0005762967630289495
step: 60, loss: 0.0010192906484007835
step: 70, loss: 0.004575968720018864
step: 80, loss: 0.010651294142007828
step: 90, loss: 9.908201172947884e-05
step: 100, loss: 8.1438927736599e-05
step: 110, loss: 0.010513881221413612
step: 120, loss: 0.0005558788543567061
step: 130, loss: 0.013308839872479439
step: 140, loss: 0.024197764694690704
step: 150, loss: 0.0004792011750396341
step: 160, loss: 0.008499371819198132
step: 170, loss: 0.00016964350652415305
step: 180, loss: 0.0005516340024769306
step: 190, loss: 0.0004951791488565505
step: 200, loss: 0.003553695511072874
step: 210, loss: 0.0001999720698222518
step: 220, loss: 0.0014298023888841271
step: 230, loss: 5.109401899971999e-05
step: 240, loss: 0.001195599907077849
step: 250, loss: 0.00046203998499549925
step: 260, loss: 0.03651938587427139
step: 270, loss: 0.002510863123461604
step: 280, loss: 0.02836466394364834
step: 290, loss: 0.011514679528772831
step: 300, loss: 0.0006137414020486176
step: 310, loss: 3.3503423765068874e-05
step: 320, loss: 4.29017236456275e-05
step: 330, loss: 0.038198549300432205
step: 340, loss: 0.0023368513211607933
step: 350, loss: 8.810152939986438e-05
step: 360, loss: 0.000503110873978585
step: 370, loss: 0.0012352017220109701
step: 380, loss: 0.0002668889646884054
epoch 15: dev_f1=0.6803519061583578, f1=0.5531914893617021, best_f1=0.6436170212765957
step: 0, loss: 0.02768857218325138
step: 10, loss: 0.0013546159025281668
step: 20, loss: 0.0003571526613086462
step: 30, loss: 0.0004535512125585228
step: 40, loss: 0.0003784390282817185
step: 50, loss: 0.0010424940846860409
step: 60, loss: 0.0057687642984092236
step: 70, loss: 0.000523642695043236
step: 80, loss: 0.002759493887424469
step: 90, loss: 0.00026051417808048427
step: 100, loss: 3.7821329897269607e-05
step: 110, loss: 0.0005529623012989759
step: 120, loss: 6.149810360511765e-05
step: 130, loss: 0.0001877248869277537
step: 140, loss: 4.0071103285299614e-05
step: 150, loss: 7.244940206874162e-05
step: 160, loss: 6.0714206483680755e-05
step: 170, loss: 0.0008745052036829293
step: 180, loss: 0.00014608082710765302
step: 190, loss: 2.7003803552361205e-05
step: 200, loss: 8.097654063021764e-05
step: 210, loss: 0.00015898399578873068
step: 220, loss: 0.00018148050003219396
step: 230, loss: 0.0004463244404178113
step: 240, loss: 0.0017169318161904812
step: 250, loss: 0.00017183195450343192
step: 260, loss: 5.947814497631043e-05
step: 270, loss: 4.2138577555306256e-05
step: 280, loss: 0.0011338439071550965
step: 290, loss: 8.944050932768732e-05
step: 300, loss: 0.002584935864433646
step: 310, loss: 0.00047653086949139833
step: 320, loss: 0.00011823703243862838
step: 330, loss: 0.017872605472803116
step: 340, loss: 0.0011177104897797108
step: 350, loss: 0.0005481454427354038
step: 360, loss: 0.0018983179470524192
step: 370, loss: 3.278532312833704e-05
step: 380, loss: 0.0010455329902470112
epoch 16: dev_f1=0.6840579710144928, f1=0.5575757575757575, best_f1=0.6436170212765957
step: 0, loss: 7.342933531617746e-05
step: 10, loss: 2.4012371795834042e-05
step: 20, loss: 0.0006567196105606854
step: 30, loss: 8.033257472561672e-05
step: 40, loss: 0.01032508909702301
step: 50, loss: 0.010410482063889503
step: 60, loss: 9.571547707309946e-05
step: 70, loss: 6.882771413074806e-05
step: 80, loss: 0.006114002782851458
step: 90, loss: 4.926415203954093e-05
step: 100, loss: 3.0542840249836445e-05
step: 110, loss: 0.00043077883310616016
step: 120, loss: 7.205831934697926e-05
step: 130, loss: 0.00032025109976530075
step: 140, loss: 0.0005196681013330817
step: 150, loss: 4.099743455299176e-05
step: 160, loss: 5.9216465160716325e-05
step: 170, loss: 0.00043941885815002024
step: 180, loss: 0.0005554372910410166
step: 190, loss: 0.03621527552604675
step: 200, loss: 0.00041603404679335654
step: 210, loss: 0.00017297410522587597
step: 220, loss: 0.00017625144391786307
step: 230, loss: 0.00030504344613291323
step: 240, loss: 0.00020767029491253197
step: 250, loss: 0.013245179317891598
step: 260, loss: 0.00010099162318510935
step: 270, loss: 0.013489709235727787
step: 280, loss: 0.23458148539066315
step: 290, loss: 0.0004955614567734301
step: 300, loss: 5.7457211369182914e-05
step: 310, loss: 0.00010127662244485691
step: 320, loss: 0.0003289160376880318
step: 330, loss: 0.0001310623629251495
step: 340, loss: 4.732325760414824e-05
step: 350, loss: 6.767860759282485e-05
step: 360, loss: 5.620396404992789e-05
step: 370, loss: 0.00024678598856553435
step: 380, loss: 0.00012814636284019798
epoch 17: dev_f1=0.7029972752043598, f1=0.5895953757225433, best_f1=0.6436170212765957
step: 0, loss: 0.0008919181418605149
step: 10, loss: 4.8910031182458624e-05
step: 20, loss: 6.562134512932971e-05
step: 30, loss: 0.000492135644890368
step: 40, loss: 0.0009101366740651429
step: 50, loss: 9.993934509111568e-05
step: 60, loss: 0.0011660077143460512
step: 70, loss: 0.0001956259220605716
step: 80, loss: 0.0006174877053126693
step: 90, loss: 0.00028598716016858816
step: 100, loss: 0.0002904184511862695
step: 110, loss: 3.371939965290949e-05
step: 120, loss: 0.008939090184867382
step: 130, loss: 0.000419405463617295
step: 140, loss: 0.0002836884232237935
step: 150, loss: 0.00014039331290405244
step: 160, loss: 0.00011738394823623821
step: 170, loss: 0.00027473625959828496
step: 180, loss: 0.00010427126107970253
step: 190, loss: 6.541730544995517e-05
step: 200, loss: 3.889805157086812e-05
step: 210, loss: 0.0002185641205869615
step: 220, loss: 0.0003878606657963246
step: 230, loss: 0.0034996357280761003
step: 240, loss: 0.0001588970044394955
step: 250, loss: 0.00029233135865069926
step: 260, loss: 6.6121450799983e-05
step: 270, loss: 5.735031299991533e-05
step: 280, loss: 7.860117329983041e-05
step: 290, loss: 0.0025306465104222298
step: 300, loss: 0.0003519327729009092
step: 310, loss: 6.255595508264378e-05
step: 320, loss: 0.00034511665580794215
step: 330, loss: 0.00016333186067640781
step: 340, loss: 0.0005524832522496581
step: 350, loss: 0.0003427318879403174
step: 360, loss: 5.88807524763979e-05
step: 370, loss: 9.027992200572044e-05
step: 380, loss: 0.00014645964256487787
epoch 18: dev_f1=0.7185929648241205, f1=0.6170212765957447, best_f1=0.6436170212765957
step: 0, loss: 0.002890257630497217
step: 10, loss: 9.736969514051452e-05
step: 20, loss: 0.0001970605953829363
step: 30, loss: 0.00013286662579048425
step: 40, loss: 7.006495434325188e-05
step: 50, loss: 0.0011865828419104218
step: 60, loss: 0.0004733373352792114
step: 70, loss: 0.009499697014689445
step: 80, loss: 3.237102646380663e-05
step: 90, loss: 4.793380503542721e-05
step: 100, loss: 3.8717691495548934e-05
step: 110, loss: 4.094976247870363e-05
step: 120, loss: 0.00034555900492705405
step: 130, loss: 0.00023333405260927975
step: 140, loss: 0.0002868414740078151
step: 150, loss: 0.0004006018571089953
step: 160, loss: 5.478869206854142e-05
step: 170, loss: 7.609074236825109e-05
step: 180, loss: 9.176840103464201e-05
step: 190, loss: 7.532948075095192e-05
step: 200, loss: 5.725773371523246e-05
step: 210, loss: 0.0017920230748131871
step: 220, loss: 0.004869286902248859
step: 230, loss: 0.003266699844971299
step: 240, loss: 0.0002662040351424366
step: 250, loss: 4.2165262129856274e-05
step: 260, loss: 0.00011365497630322352
step: 270, loss: 0.00012094355042790994
step: 280, loss: 7.807237125234678e-05
step: 290, loss: 5.9326655900804326e-05
step: 300, loss: 6.595663580810651e-05
step: 310, loss: 0.008747655898332596
step: 320, loss: 6.265545380301774e-05
step: 330, loss: 4.085887485416606e-05
step: 340, loss: 0.00013768482313025743
step: 350, loss: 0.00017571206262800843
step: 360, loss: 8.875071216607466e-05
step: 370, loss: 6.379687692970037e-05
step: 380, loss: 0.0007355168927460909
epoch 19: dev_f1=0.7062146892655367, f1=0.5773809523809523, best_f1=0.6436170212765957
step: 0, loss: 2.3580660126754083e-05
step: 10, loss: 0.000361037120455876
step: 20, loss: 9.166009112959728e-05
step: 30, loss: 4.688300032285042e-05
step: 40, loss: 3.510861279210076e-05
step: 50, loss: 0.00029232734232209623
step: 60, loss: 0.00010587076394585893
step: 70, loss: 6.703771941829473e-05
step: 80, loss: 6.807252793805674e-05
step: 90, loss: 0.0001435376616427675
step: 100, loss: 0.0003026857157237828
step: 110, loss: 8.057233935687691e-05
step: 120, loss: 4.187742160866037e-05
step: 130, loss: 0.0002362492959946394
step: 140, loss: 0.0023078001104295254
step: 150, loss: 6.303103873506188e-05
step: 160, loss: 0.0010478664189577103
step: 170, loss: 0.00013770023360848427
step: 180, loss: 2.537195905460976e-05
step: 190, loss: 9.695063636172563e-05
step: 200, loss: 0.00018774784984998405
step: 210, loss: 0.0013719634152948856
step: 220, loss: 0.0002523277944419533
step: 230, loss: 0.00010267036850564182
step: 240, loss: 0.0005774214514531195
step: 250, loss: 0.00443745031952858
step: 260, loss: 0.0016538564814254642
step: 270, loss: 0.00015481507580261678
step: 280, loss: 0.0001652040082262829
step: 290, loss: 0.006909801159054041
step: 300, loss: 4.639968756237067e-05
step: 310, loss: 5.8303357945987955e-05
step: 320, loss: 4.817979788640514e-05
step: 330, loss: 0.00018282515520695597
step: 340, loss: 4.3369840568630025e-05
step: 350, loss: 6.55155599815771e-05
step: 360, loss: 0.00026573502691462636
step: 370, loss: 7.968408317537978e-05
step: 380, loss: 7.788003131281585e-05
epoch 20: dev_f1=0.6971428571428572, f1=0.5662650602409639, best_f1=0.6436170212765957
