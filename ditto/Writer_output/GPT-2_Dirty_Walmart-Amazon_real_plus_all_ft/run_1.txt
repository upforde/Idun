cuda
Device: cuda
step: 0, loss: 0.7359522581100464
step: 10, loss: 0.3751235902309418
step: 20, loss: 0.38025400042533875
step: 30, loss: 0.3882414996623993
step: 40, loss: 0.1663217693567276
step: 50, loss: 0.2303968071937561
step: 60, loss: 0.44494324922561646
step: 70, loss: 0.2937839925289154
step: 80, loss: 0.2790628671646118
step: 90, loss: 0.4711335599422455
step: 100, loss: 0.3124655783176422
step: 110, loss: 0.44526752829551697
step: 120, loss: 0.2132411152124405
step: 130, loss: 0.22092865407466888
step: 140, loss: 0.1375495046377182
step: 150, loss: 0.28400444984436035
step: 160, loss: 0.3405876159667969
step: 170, loss: 0.2031044214963913
step: 180, loss: 0.2409171164035797
step: 190, loss: 0.32090437412261963
step: 200, loss: 0.30733200907707214
step: 210, loss: 0.2721244692802429
step: 220, loss: 0.2372172474861145
step: 230, loss: 0.17126339673995972
step: 240, loss: 0.33687639236450195
step: 250, loss: 0.3102358877658844
step: 260, loss: 0.12801791727542877
step: 270, loss: 0.28971800208091736
step: 280, loss: 0.24333328008651733
step: 290, loss: 0.2319381982088089
step: 300, loss: 0.16351522505283356
step: 310, loss: 0.039839886128902435
step: 320, loss: 0.38307687640190125
step: 330, loss: 0.379326730966568
step: 340, loss: 0.37195396423339844
step: 350, loss: 0.2636411786079407
step: 360, loss: 0.10160667449235916
step: 370, loss: 0.11271949112415314
step: 380, loss: 0.3434312343597412
epoch 1: dev_f1=0.4986595174262734, f1=0.36411609498680736, best_f1=0.36411609498680736
step: 0, loss: 0.2169872522354126
step: 10, loss: 0.21162845194339752
step: 20, loss: 0.2547054886817932
step: 30, loss: 0.128558948636055
step: 40, loss: 0.015431752428412437
step: 50, loss: 0.26135292649269104
step: 60, loss: 0.10879481583833694
step: 70, loss: 0.5071574449539185
step: 80, loss: 0.02169273979961872
step: 90, loss: 0.15621693432331085
step: 100, loss: 0.034113746136426926
step: 110, loss: 0.17545294761657715
step: 120, loss: 0.13877806067466736
step: 130, loss: 0.38764825463294983
step: 140, loss: 0.1866452693939209
step: 150, loss: 0.11724548041820526
step: 160, loss: 0.11988525092601776
step: 170, loss: 0.2563052475452423
step: 180, loss: 0.2107345312833786
step: 190, loss: 0.1449669450521469
step: 200, loss: 0.08422812074422836
step: 210, loss: 0.1898445338010788
step: 220, loss: 0.07835957407951355
step: 230, loss: 0.1532943695783615
step: 240, loss: 0.1294296383857727
step: 250, loss: 0.1933196634054184
step: 260, loss: 0.15219014883041382
step: 270, loss: 0.09010127931833267
step: 280, loss: 0.24441953003406525
step: 290, loss: 0.10018587112426758
step: 300, loss: 0.0625971332192421
step: 310, loss: 0.18821482360363007
step: 320, loss: 0.21626204252243042
step: 330, loss: 0.29406362771987915
step: 340, loss: 0.2583655118942261
step: 350, loss: 0.21569688618183136
step: 360, loss: 0.05736871808767319
step: 370, loss: 0.15903416275978088
step: 380, loss: 0.04466903209686279
epoch 2: dev_f1=0.7007672634271099, f1=0.6260387811634348, best_f1=0.6260387811634348
step: 0, loss: 0.11158226430416107
step: 10, loss: 0.18136729300022125
step: 20, loss: 0.056049130856990814
step: 30, loss: 0.14180195331573486
step: 40, loss: 0.0653500035405159
step: 50, loss: 0.012451967224478722
step: 60, loss: 0.0949224978685379
step: 70, loss: 0.11316274851560593
step: 80, loss: 0.08025743812322617
step: 90, loss: 0.10415586084127426
step: 100, loss: 0.28633493185043335
step: 110, loss: 0.08681169152259827
step: 120, loss: 0.2610125243663788
step: 130, loss: 0.023513024672865868
step: 140, loss: 0.10457616299390793
step: 150, loss: 0.014351476915180683
step: 160, loss: 0.06282953917980194
step: 170, loss: 0.1377849578857422
step: 180, loss: 0.041257455945014954
step: 190, loss: 0.25382885336875916
step: 200, loss: 0.07912032306194305
step: 210, loss: 0.007901731878519058
step: 220, loss: 0.15305238962173462
step: 230, loss: 0.1592022180557251
step: 240, loss: 0.12860007584095
step: 250, loss: 0.12632818520069122
step: 260, loss: 0.08091915398836136
step: 270, loss: 0.1178925484418869
step: 280, loss: 0.07314281165599823
step: 290, loss: 0.011263960972428322
step: 300, loss: 0.08297008275985718
step: 310, loss: 0.14616131782531738
step: 320, loss: 0.1420803666114807
step: 330, loss: 0.05717743933200836
step: 340, loss: 0.3508473336696625
step: 350, loss: 0.0536140538752079
step: 360, loss: 0.1359306424856186
step: 370, loss: 0.37207838892936707
step: 380, loss: 0.17669887840747833
epoch 3: dev_f1=0.7371273712737126, f1=0.5630498533724341, best_f1=0.5630498533724341
step: 0, loss: 0.10392848402261734
step: 10, loss: 0.1602053940296173
step: 20, loss: 0.06529469043016434
step: 30, loss: 0.04913966730237007
step: 40, loss: 0.030222153291106224
step: 50, loss: 0.0619710274040699
step: 60, loss: 0.010064114816486835
step: 70, loss: 0.0035293688997626305
step: 80, loss: 0.07928872108459473
step: 90, loss: 0.061394546180963516
step: 100, loss: 0.02861528843641281
step: 110, loss: 0.03011440299451351
step: 120, loss: 0.024054178968071938
step: 130, loss: 0.032353900372982025
step: 140, loss: 0.042371850460767746
step: 150, loss: 0.18667028844356537
step: 160, loss: 0.020092053338885307
step: 170, loss: 0.03401333466172218
step: 180, loss: 0.24234159290790558
step: 190, loss: 0.03534795343875885
step: 200, loss: 0.09756827354431152
step: 210, loss: 0.16933834552764893
step: 220, loss: 0.06928634643554688
step: 230, loss: 0.0667741522192955
step: 240, loss: 0.009857860393822193
step: 250, loss: 0.076198510825634
step: 260, loss: 0.05047035962343216
step: 270, loss: 0.12043289095163345
step: 280, loss: 0.18232005834579468
step: 290, loss: 0.03913723677396774
step: 300, loss: 0.020145868882536888
step: 310, loss: 0.032853901386260986
step: 320, loss: 0.05247130244970322
step: 330, loss: 0.014469978399574757
step: 340, loss: 0.07834123820066452
step: 350, loss: 0.007115681190043688
step: 360, loss: 0.02422204799950123
step: 370, loss: 0.12014834582805634
step: 380, loss: 0.03454139828681946
epoch 4: dev_f1=0.7493112947658401, f1=0.5747800586510264, best_f1=0.5747800586510264
step: 0, loss: 0.020853396505117416
step: 10, loss: 0.0019661460537463427
step: 20, loss: 0.014117531478404999
step: 30, loss: 0.0365666039288044
step: 40, loss: 0.027415720745921135
step: 50, loss: 0.005747207440435886
step: 60, loss: 0.17977428436279297
step: 70, loss: 0.01371424738317728
step: 80, loss: 0.08268306404352188
step: 90, loss: 0.0014449508162215352
step: 100, loss: 0.023734986782073975
step: 110, loss: 0.007177208084613085
step: 120, loss: 0.04659975692629814
step: 130, loss: 0.07991336286067963
step: 140, loss: 0.03458361327648163
step: 150, loss: 0.10438836365938187
step: 160, loss: 0.08050309866666794
step: 170, loss: 0.05052086338400841
step: 180, loss: 0.1378127783536911
step: 190, loss: 0.22183352708816528
step: 200, loss: 0.07372893393039703
step: 210, loss: 0.21305449306964874
step: 220, loss: 0.06463445723056793
step: 230, loss: 0.02233804762363434
step: 240, loss: 0.08943556994199753
step: 250, loss: 0.08585356920957565
step: 260, loss: 0.012020113877952099
step: 270, loss: 0.2016856074333191
step: 280, loss: 0.033714015036821365
step: 290, loss: 0.004942949861288071
step: 300, loss: 0.0805944874882698
step: 310, loss: 0.019262906163930893
step: 320, loss: 0.06811446696519852
step: 330, loss: 0.117189422249794
step: 340, loss: 0.004636934492737055
step: 350, loss: 0.003208837006241083
step: 360, loss: 0.013811055570840836
step: 370, loss: 0.0060310885310173035
step: 380, loss: 0.005422764923423529
epoch 5: dev_f1=0.7413333333333334, f1=0.5787965616045845, best_f1=0.5747800586510264
step: 0, loss: 0.08952709287405014
step: 10, loss: 0.019331851974129677
step: 20, loss: 0.02728823944926262
step: 30, loss: 0.0014179059071466327
step: 40, loss: 0.015528734773397446
step: 50, loss: 0.02753240242600441
step: 60, loss: 0.026042314246296883
step: 70, loss: 0.17965972423553467
step: 80, loss: 0.007337929680943489
step: 90, loss: 0.0022252905182540417
step: 100, loss: 0.09088923782110214
step: 110, loss: 0.004902323242276907
step: 120, loss: 0.0015395793598145247
step: 130, loss: 0.013108267448842525
step: 140, loss: 0.007167339324951172
step: 150, loss: 0.12087791413068771
step: 160, loss: 0.013383216224610806
step: 170, loss: 0.02245958335697651
step: 180, loss: 0.009313170798122883
step: 190, loss: 0.021016858518123627
step: 200, loss: 0.004089949652552605
step: 210, loss: 0.06459374725818634
step: 220, loss: 0.023880064487457275
step: 230, loss: 0.0009858048288151622
step: 240, loss: 0.007010896690189838
step: 250, loss: 0.01014822255820036
step: 260, loss: 0.005025644786655903
step: 270, loss: 0.01293018739670515
step: 280, loss: 0.054093122482299805
step: 290, loss: 0.02600819617509842
step: 300, loss: 0.0035842633806169033
step: 310, loss: 0.002940439386293292
step: 320, loss: 0.001223147613927722
step: 330, loss: 0.005481800064444542
step: 340, loss: 0.11492431163787842
step: 350, loss: 0.08615228533744812
step: 360, loss: 0.001987955067306757
step: 370, loss: 0.07271931320428848
step: 380, loss: 0.09742563962936401
epoch 6: dev_f1=0.7037974683544304, f1=0.6058981233243967, best_f1=0.5747800586510264
step: 0, loss: 0.057743385434150696
step: 10, loss: 0.003296066541224718
step: 20, loss: 0.005019846837967634
step: 30, loss: 0.008752262219786644
step: 40, loss: 0.0005939955008216202
step: 50, loss: 0.007471397519111633
step: 60, loss: 0.035600289702415466
step: 70, loss: 0.0017293094424530864
step: 80, loss: 0.016394207254052162
step: 90, loss: 0.0046942937187850475
step: 100, loss: 0.011843252927064896
step: 110, loss: 0.026749035343527794
step: 120, loss: 0.09060177952051163
step: 130, loss: 0.0008317363681271672
step: 140, loss: 0.00866443756967783
step: 150, loss: 0.002277984982356429
step: 160, loss: 0.030477426946163177
step: 170, loss: 0.0011801057262346148
step: 180, loss: 0.011500325985252857
step: 190, loss: 0.0005435590865090489
step: 200, loss: 0.00041124262497760355
step: 210, loss: 0.0023824400268495083
step: 220, loss: 0.14820414781570435
step: 230, loss: 0.008107844740152359
step: 240, loss: 0.0003986807423643768
step: 250, loss: 0.03259297460317612
step: 260, loss: 0.002254802267998457
step: 270, loss: 0.12345745414495468
step: 280, loss: 0.02076302282512188
step: 290, loss: 0.04360612481832504
step: 300, loss: 0.022333089262247086
step: 310, loss: 0.01749386638402939
step: 320, loss: 0.012132639065384865
step: 330, loss: 0.000865723064634949
step: 340, loss: 0.029615798965096474
step: 350, loss: 0.00617460859939456
step: 360, loss: 0.009051233530044556
step: 370, loss: 0.015367098152637482
step: 380, loss: 0.008257927373051643
epoch 7: dev_f1=0.75, f1=0.5824175824175823, best_f1=0.5824175824175823
step: 0, loss: 0.0015667948173359036
step: 10, loss: 0.0008670089300721884
step: 20, loss: 0.00025696586817502975
step: 30, loss: 0.0011343451915308833
step: 40, loss: 0.007661838084459305
step: 50, loss: 0.021617474034428596
step: 60, loss: 0.012574395164847374
step: 70, loss: 0.034107863903045654
step: 80, loss: 0.0004771939420606941
step: 90, loss: 0.05907173827290535
step: 100, loss: 0.0008470919565297663
step: 110, loss: 0.0061823176220059395
step: 120, loss: 0.00283680553548038
step: 130, loss: 0.0006648617563769221
step: 140, loss: 0.001597154070623219
step: 150, loss: 0.008996310643851757
step: 160, loss: 0.05936804041266441
step: 170, loss: 0.00712595647200942
step: 180, loss: 0.0303142499178648
step: 190, loss: 0.0019351107766851783
step: 200, loss: 0.051354944705963135
step: 210, loss: 0.001063271309249103
step: 220, loss: 0.004690867383033037
step: 230, loss: 0.009712638333439827
step: 240, loss: 0.005265370476990938
step: 250, loss: 0.05834876373410225
step: 260, loss: 0.020140063017606735
step: 270, loss: 0.004537234548479319
step: 280, loss: 0.0017960943514481187
step: 290, loss: 0.0012742775725200772
step: 300, loss: 0.002672935137525201
step: 310, loss: 0.1270488202571869
step: 320, loss: 0.007113934960216284
step: 330, loss: 0.0012831412022933364
step: 340, loss: 0.00034585612593218684
step: 350, loss: 0.0009924867190420628
step: 360, loss: 0.0037099658511579037
step: 370, loss: 0.005402257200330496
step: 380, loss: 0.03996049240231514
epoch 8: dev_f1=0.7401129943502824, f1=0.5987654320987654, best_f1=0.5824175824175823
step: 0, loss: 0.0042269229888916016
step: 10, loss: 0.0007157070795074105
step: 20, loss: 0.018216632306575775
step: 30, loss: 0.024115445092320442
step: 40, loss: 0.0038078855723142624
step: 50, loss: 0.1259125918149948
step: 60, loss: 0.00034730907646007836
step: 70, loss: 0.03324957937002182
step: 80, loss: 0.0012580550974234939
step: 90, loss: 0.0009373120265081525
step: 100, loss: 0.042282022535800934
step: 110, loss: 0.010089187882840633
step: 120, loss: 0.0009342152625322342
step: 130, loss: 0.0016757757402956486
step: 140, loss: 0.0018321039387956262
step: 150, loss: 0.001802620361559093
step: 160, loss: 0.0008685932261869311
step: 170, loss: 0.0007993282633833587
step: 180, loss: 0.00012846654863096774
step: 190, loss: 0.0002633297990541905
step: 200, loss: 0.01378239318728447
step: 210, loss: 0.003143025329336524
step: 220, loss: 0.004017188213765621
step: 230, loss: 0.027311569079756737
step: 240, loss: 0.017200788483023643
step: 250, loss: 0.030870988965034485
step: 260, loss: 0.003930951468646526
step: 270, loss: 0.005969769321382046
step: 280, loss: 0.01772061176598072
step: 290, loss: 0.009716072119772434
step: 300, loss: 0.0023388322442770004
step: 310, loss: 0.15049760043621063
step: 320, loss: 0.0157968420535326
step: 330, loss: 0.0007391043473035097
step: 340, loss: 0.005567391403019428
step: 350, loss: 0.0014297952875494957
step: 360, loss: 0.0006300121312960982
step: 370, loss: 0.005925545934587717
step: 380, loss: 0.00014053049380891025
epoch 9: dev_f1=0.707774798927614, f1=0.5875370919881306, best_f1=0.5824175824175823
step: 0, loss: 0.008396214805543423
step: 10, loss: 0.0003593337023630738
step: 20, loss: 0.00029410404385998845
step: 30, loss: 0.0020409205462783575
step: 40, loss: 0.0018343129195272923
step: 50, loss: 0.0003547344822436571
step: 60, loss: 0.0018957749707624316
step: 70, loss: 0.0073820860125124454
step: 80, loss: 0.0007779968436807394
step: 90, loss: 0.002406967105343938
step: 100, loss: 0.0019278980325907469
step: 110, loss: 0.0011470967438071966
step: 120, loss: 0.000326563254930079
step: 130, loss: 0.00029752476257272065
step: 140, loss: 0.006436238065361977
step: 150, loss: 0.1228986382484436
step: 160, loss: 0.003506018780171871
step: 170, loss: 0.0008993817027658224
step: 180, loss: 0.006527265999466181
step: 190, loss: 0.020276470109820366
step: 200, loss: 0.001838081981986761
step: 210, loss: 0.0025653664488345385
step: 220, loss: 0.010257218964397907
step: 230, loss: 0.00021280905639287084
step: 240, loss: 0.0008122472208924592
step: 250, loss: 0.004339362494647503
step: 260, loss: 0.019041424617171288
step: 270, loss: 0.0373222753405571
step: 280, loss: 0.002605833113193512
step: 290, loss: 0.0009552240953780711
step: 300, loss: 0.001766307046636939
step: 310, loss: 0.0009095986024476588
step: 320, loss: 0.0006025960319675505
step: 330, loss: 0.0016286899335682392
step: 340, loss: 0.06082655489444733
step: 350, loss: 0.0028087168466299772
step: 360, loss: 0.0247661042958498
step: 370, loss: 0.0002427295985398814
step: 380, loss: 0.00024015209055505693
epoch 10: dev_f1=0.7258064516129032, f1=0.6340057636887609, best_f1=0.5824175824175823
step: 0, loss: 0.0002910560870077461
step: 10, loss: 0.002376004122197628
step: 20, loss: 0.0023846605326980352
step: 30, loss: 0.004808633588254452
step: 40, loss: 0.0038167606107890606
step: 50, loss: 0.0019207632867619395
step: 60, loss: 0.003760905936360359
step: 70, loss: 0.028075911104679108
step: 80, loss: 0.02299567684531212
step: 90, loss: 0.000641820312011987
step: 100, loss: 0.0016635366482660174
step: 110, loss: 0.0003990418917965144
step: 120, loss: 0.0004558701766654849
step: 130, loss: 0.008777172304689884
step: 140, loss: 0.0004755879635922611
step: 150, loss: 0.00014500216639135033
step: 160, loss: 0.025003740563988686
step: 170, loss: 0.00185239443089813
step: 180, loss: 0.00014879713125992566
step: 190, loss: 0.00048550235806033015
step: 200, loss: 0.000299669336527586
step: 210, loss: 0.014255324378609657
step: 220, loss: 0.0026047045830637217
step: 230, loss: 0.0009805101435631514
step: 240, loss: 0.0004181295807939023
step: 250, loss: 0.0010569993173703551
step: 260, loss: 0.002307342365384102
step: 270, loss: 0.0013256652746349573
step: 280, loss: 0.00724530266597867
step: 290, loss: 0.006634692661464214
step: 300, loss: 0.0004045518289785832
step: 310, loss: 0.015992596745491028
step: 320, loss: 0.0025808680802583694
step: 330, loss: 0.0018246169202029705
step: 340, loss: 0.0006712345057167113
step: 350, loss: 0.0369361937046051
step: 360, loss: 0.011769435368478298
step: 370, loss: 0.01003221608698368
step: 380, loss: 0.001020179595798254
epoch 11: dev_f1=0.7115902964959568, f1=0.5581395348837208, best_f1=0.5824175824175823
step: 0, loss: 0.003295198315754533
step: 10, loss: 0.00020907247380819172
step: 20, loss: 0.00019987630366813391
step: 30, loss: 0.0008844650583341718
step: 40, loss: 0.00033213451388292015
step: 50, loss: 0.00041739793960005045
step: 60, loss: 0.001957142259925604
step: 70, loss: 0.0005175186088308692
step: 80, loss: 0.0009359901305288076
step: 90, loss: 0.012799129821360111
step: 100, loss: 0.00032715676934458315
step: 110, loss: 0.001487027620896697
step: 120, loss: 0.00028090516570955515
step: 130, loss: 0.000319169630529359
step: 140, loss: 0.0003622117219492793
step: 150, loss: 0.0017636549891903996
step: 160, loss: 0.004966212902218103
step: 170, loss: 0.000928727735299617
step: 180, loss: 0.0018952878890559077
step: 190, loss: 0.005457356106489897
step: 200, loss: 0.0008477724622935057
step: 210, loss: 0.0008783395169302821
step: 220, loss: 0.031490106135606766
step: 230, loss: 0.0005595490802079439
step: 240, loss: 0.00013342336751520634
step: 250, loss: 0.015070616267621517
step: 260, loss: 0.0006956788711249828
step: 270, loss: 0.0007947029662318528
step: 280, loss: 0.00012888239871244878
step: 290, loss: 0.0006736703217029572
step: 300, loss: 0.0021482184529304504
step: 310, loss: 0.00028328230837360024
step: 320, loss: 0.00023044997942633927
step: 330, loss: 0.0002243577182525769
step: 340, loss: 0.026131421327590942
step: 350, loss: 9.065945778274909e-05
step: 360, loss: 0.000767847872339189
step: 370, loss: 0.06193166598677635
step: 380, loss: 0.0003891142550855875
epoch 12: dev_f1=0.728813559322034, f1=0.5696594427244582, best_f1=0.5824175824175823
step: 0, loss: 0.000636827724520117
step: 10, loss: 0.002263518050312996
step: 20, loss: 0.0004003505746368319
step: 30, loss: 0.005859211087226868
step: 40, loss: 0.00017420650692656636
step: 50, loss: 0.0011330223642289639
step: 60, loss: 0.0005419208901003003
step: 70, loss: 0.006348608527332544
step: 80, loss: 0.0008635764243081212
step: 90, loss: 0.0021168715320527554
step: 100, loss: 0.005229287780821323
step: 110, loss: 0.003268435364589095
step: 120, loss: 0.018663529306650162
step: 130, loss: 0.00012043127208016813
step: 140, loss: 0.0034306864254176617
step: 150, loss: 0.0066026789136230946
step: 160, loss: 0.0006550902617163956
step: 170, loss: 0.0006103006307967007
step: 180, loss: 0.00039909695624373853
step: 190, loss: 0.00023105449508875608
step: 200, loss: 0.0002225108619313687
step: 210, loss: 0.0005282243946567178
step: 220, loss: 0.00026787008391693234
step: 230, loss: 0.0004860609769821167
step: 240, loss: 0.00016253367357421666
step: 250, loss: 0.0004026816168334335
step: 260, loss: 0.00019249951583333313
step: 270, loss: 0.0011929706670343876
step: 280, loss: 0.004733195528388023
step: 290, loss: 0.0037846053019165993
step: 300, loss: 0.000188940015505068
step: 310, loss: 0.0011538355611264706
step: 320, loss: 0.00029384694062173367
step: 330, loss: 0.007766290567815304
step: 340, loss: 0.0003728599695023149
step: 350, loss: 0.0010941216023638844
step: 360, loss: 0.00018167929374612868
step: 370, loss: 0.002042952459305525
step: 380, loss: 0.0011920157121494412
epoch 13: dev_f1=0.7403314917127072, f1=0.6076696165191741, best_f1=0.5824175824175823
step: 0, loss: 0.0002010233438340947
step: 10, loss: 0.00014199399447534233
step: 20, loss: 0.0003402148140594363
step: 30, loss: 0.0006830045604147017
step: 40, loss: 0.0032553430646657944
step: 50, loss: 0.003886496415361762
step: 60, loss: 0.0016079182969406247
step: 70, loss: 0.0002509204496163875
step: 80, loss: 0.00024050292267929763
step: 90, loss: 0.002366652712225914
step: 100, loss: 0.000586379028391093
step: 110, loss: 0.00025951434508897364
step: 120, loss: 0.0003071210812777281
step: 130, loss: 0.17117191851139069
step: 140, loss: 0.0005000800010748208
step: 150, loss: 0.0001250237983185798
step: 160, loss: 0.013599472120404243
step: 170, loss: 0.00019195792265236378
step: 180, loss: 0.00048019742825999856
step: 190, loss: 0.002374543808400631
step: 200, loss: 0.005379672162234783
step: 210, loss: 0.0006363681750372052
step: 220, loss: 0.0006417937111109495
step: 230, loss: 0.0002951884816866368
step: 240, loss: 0.026876164600253105
step: 250, loss: 0.002241223119199276
step: 260, loss: 0.002110288245603442
step: 270, loss: 0.0002415238559478894
step: 280, loss: 0.0001726393384160474
step: 290, loss: 0.0006816623499616981
step: 300, loss: 0.00440171780064702
step: 310, loss: 0.0005570154171437025
step: 320, loss: 0.000350179587258026
step: 330, loss: 0.0001088420904125087
step: 340, loss: 0.0003105984069406986
step: 350, loss: 0.005543329752981663
step: 360, loss: 0.0004327701753936708
step: 370, loss: 0.013687466271221638
step: 380, loss: 0.0006305096321739256
epoch 14: dev_f1=0.7164948453608248, f1=0.6132596685082873, best_f1=0.5824175824175823
step: 0, loss: 9.616989700589329e-05
step: 10, loss: 0.007959860377013683
step: 20, loss: 8.906494622351602e-05
step: 30, loss: 8.139439160004258e-05
step: 40, loss: 0.0004458548501133919
step: 50, loss: 0.003655192209407687
step: 60, loss: 0.0005357154877856374
step: 70, loss: 0.004910158924758434
step: 80, loss: 0.00038437399780377746
step: 90, loss: 0.0003083277551922947
step: 100, loss: 0.0005914978100918233
step: 110, loss: 0.00032798483152873814
step: 120, loss: 0.0003671499725896865
step: 130, loss: 0.00015897993580438197
step: 140, loss: 0.0001642224524402991
step: 150, loss: 0.0004907838883809745
step: 160, loss: 0.001769110793247819
step: 170, loss: 0.00018417835235595703
step: 180, loss: 0.0019817904103547335
step: 190, loss: 0.0001014765293803066
step: 200, loss: 0.008363546803593636
step: 210, loss: 0.00015536851424258202
step: 220, loss: 0.0010143761755898595
step: 230, loss: 0.00988781452178955
step: 240, loss: 0.0017244212795048952
step: 250, loss: 0.00016174808843061328
step: 260, loss: 0.00012011190847260877
step: 270, loss: 0.0001139658925239928
step: 280, loss: 9.415299427928403e-05
step: 290, loss: 0.00014010969607625157
step: 300, loss: 0.000564083456993103
step: 310, loss: 0.0003522590559441596
step: 320, loss: 0.00015070800145622343
step: 330, loss: 0.0003363431023899466
step: 340, loss: 0.0017171362414956093
step: 350, loss: 0.012473927810788155
step: 360, loss: 0.0021585733629763126
step: 370, loss: 0.0008965431479737163
step: 380, loss: 0.0032429592683911324
epoch 15: dev_f1=0.7150259067357513, f1=0.5826330532212886, best_f1=0.5824175824175823
step: 0, loss: 0.00015026233450043947
step: 10, loss: 0.0003112713457085192
step: 20, loss: 0.00016326559125445783
step: 30, loss: 0.00019241039990447462
step: 40, loss: 0.000121021039376501
step: 50, loss: 0.0006422085571102798
step: 60, loss: 0.00020244692859705538
step: 70, loss: 0.00012912333477288485
step: 80, loss: 0.07830094546079636
step: 90, loss: 0.0005867300787940621
step: 100, loss: 0.0012706867419183254
step: 110, loss: 0.0006935959681868553
step: 120, loss: 0.0007833297713659704
step: 130, loss: 0.00033645814983174205
step: 140, loss: 0.0008048517047427595
step: 150, loss: 8.251329563790932e-05
step: 160, loss: 0.0004307790077291429
step: 170, loss: 0.0002866732538677752
step: 180, loss: 0.00017092163034249097
step: 190, loss: 0.00039817276410758495
step: 200, loss: 0.004899449180811644
step: 210, loss: 0.0002971115172840655
step: 220, loss: 0.001073935884051025
step: 230, loss: 9.665056859375909e-05
step: 240, loss: 0.0002003730769501999
step: 250, loss: 0.0024102607276290655
step: 260, loss: 8.028781303437427e-05
step: 270, loss: 0.00016409336240030825
step: 280, loss: 8.79858635016717e-05
step: 290, loss: 0.0002689014654606581
step: 300, loss: 0.0008915250655263662
step: 310, loss: 0.0626448467373848
step: 320, loss: 0.00026486683054827154
step: 330, loss: 0.000454645196441561
step: 340, loss: 0.0001328121725236997
step: 350, loss: 7.740055298199877e-05
step: 360, loss: 0.0001498894125688821
step: 370, loss: 8.805992547422647e-05
step: 380, loss: 0.000311725540086627
epoch 16: dev_f1=0.722077922077922, f1=0.5819209039548022, best_f1=0.5824175824175823
step: 0, loss: 7.37416121410206e-05
step: 10, loss: 0.00030292465817183256
step: 20, loss: 0.0002590212388895452
step: 30, loss: 0.00010374670819146559
step: 40, loss: 0.0015869047492742538
step: 50, loss: 0.0005664820782840252
step: 60, loss: 0.00013666559243574739
step: 70, loss: 0.0001126455026678741
step: 80, loss: 0.000668879656586796
step: 90, loss: 0.0007021361961960793
step: 100, loss: 7.045277743600309e-05
step: 110, loss: 0.0001267934130737558
step: 120, loss: 0.0005913107888773084
step: 130, loss: 5.6523713283240795e-05
step: 140, loss: 0.0005100374110043049
step: 150, loss: 0.01239173486828804
step: 160, loss: 0.0001596426300238818
step: 170, loss: 0.00011055136565119028
step: 180, loss: 0.0005854068440385163
step: 190, loss: 6.039729851181619e-05
step: 200, loss: 0.018962927162647247
step: 210, loss: 0.0007159860688261688
step: 220, loss: 9.827610483625904e-05
step: 230, loss: 7.274754898389801e-05
step: 240, loss: 0.0030756231863051653
step: 250, loss: 9.295117342844605e-05
step: 260, loss: 0.00032528393785469234
step: 270, loss: 0.001548125292174518
step: 280, loss: 0.18618187308311462
step: 290, loss: 0.006437236908823252
step: 300, loss: 9.083461918635294e-05
step: 310, loss: 0.0001218679390149191
step: 320, loss: 9.046339255291969e-05
step: 330, loss: 6.410829519154504e-05
step: 340, loss: 9.379724360769615e-05
step: 350, loss: 0.0002484726719558239
step: 360, loss: 0.00018461585568729788
step: 370, loss: 8.588144555687904e-05
step: 380, loss: 0.0004797726287506521
epoch 17: dev_f1=0.7167630057803469, f1=0.5349544072948329, best_f1=0.5824175824175823
step: 0, loss: 0.0003765398287214339
step: 10, loss: 0.0016937019536271691
step: 20, loss: 0.00030426523881033063
step: 30, loss: 0.0006625581881962717
step: 40, loss: 0.00015733990585431457
step: 50, loss: 0.001381505629979074
step: 60, loss: 0.001037280890159309
step: 70, loss: 0.001809620065614581
step: 80, loss: 0.0009635590831749141
step: 90, loss: 0.00011316712334519252
step: 100, loss: 0.001266149221919477
step: 110, loss: 0.00047705770703032613
step: 120, loss: 0.00011713021376635879
step: 130, loss: 0.00015880285354796797
step: 140, loss: 9.463547758059576e-05
step: 150, loss: 5.426276766229421e-05
step: 160, loss: 0.010982295498251915
step: 170, loss: 0.002344871172681451
step: 180, loss: 0.00021158490562811494
step: 190, loss: 0.0009215330937877297
step: 200, loss: 0.0005986947217024863
step: 210, loss: 4.093580355402082e-05
step: 220, loss: 0.0006671790615655482
step: 230, loss: 0.004244885873049498
step: 240, loss: 0.00017002948152367026
step: 250, loss: 0.00010900398046942428
step: 260, loss: 0.0001323684409726411
step: 270, loss: 0.0021859705448150635
step: 280, loss: 0.00015347619773820043
step: 290, loss: 7.169778837123886e-05
step: 300, loss: 0.00053498859051615
step: 310, loss: 0.002344129839912057
step: 320, loss: 0.0019993402529507875
step: 330, loss: 0.00014229283260647207
step: 340, loss: 0.00019640219397842884
step: 350, loss: 0.0009896995034068823
step: 360, loss: 0.010707627050578594
step: 370, loss: 0.000951965746935457
step: 380, loss: 3.766158624785021e-05
epoch 18: dev_f1=0.7195767195767196, f1=0.5763688760806915, best_f1=0.5824175824175823
step: 0, loss: 7.414453284582123e-05
step: 10, loss: 0.00011679500312311575
step: 20, loss: 0.00016598618822172284
step: 30, loss: 0.004435067996382713
step: 40, loss: 8.495565271005034e-05
step: 50, loss: 0.001716210856102407
step: 60, loss: 0.014219142496585846
step: 70, loss: 0.00010890271369135007
step: 80, loss: 0.0007942661759443581
step: 90, loss: 0.000926465610973537
step: 100, loss: 0.00011684507626341656
step: 110, loss: 8.135761163430288e-05
step: 120, loss: 0.0003590211272239685
step: 130, loss: 4.895187521469779e-05
step: 140, loss: 0.002009726595133543
step: 150, loss: 0.0008392265881411731
step: 160, loss: 6.892683450132608e-05
step: 170, loss: 0.0008084909059107304
step: 180, loss: 9.749207674758509e-05
step: 190, loss: 0.04926912486553192
step: 200, loss: 5.949891055934131e-05
step: 210, loss: 0.0005857757059857249
step: 220, loss: 0.0004577243817038834
step: 230, loss: 0.00010723081504693255
step: 240, loss: 0.0008859647787176073
step: 250, loss: 0.0001897707988973707
step: 260, loss: 5.2628358389483765e-05
step: 270, loss: 0.00017354130977764726
step: 280, loss: 0.00024326698621734977
step: 290, loss: 0.00011722340423148125
step: 300, loss: 0.00038431366556324065
step: 310, loss: 0.00011967260070377961
step: 320, loss: 8.073873323155567e-05
step: 330, loss: 0.0001316426059929654
step: 340, loss: 5.9441001212690026e-05
step: 350, loss: 0.00023443652025889605
step: 360, loss: 6.305427814368159e-05
step: 370, loss: 0.00011449133307905868
step: 380, loss: 8.514946966897696e-05
epoch 19: dev_f1=0.7263427109974423, f1=0.5945945945945946, best_f1=0.5824175824175823
step: 0, loss: 6.027062045177445e-05
step: 10, loss: 0.002116958610713482
step: 20, loss: 5.501554187503643e-05
step: 30, loss: 0.00014803936937823892
step: 40, loss: 0.0001018320836010389
step: 50, loss: 8.132089715218171e-05
step: 60, loss: 6.313047924777493e-05
step: 70, loss: 6.115990254329517e-05
step: 80, loss: 0.004925833083689213
step: 90, loss: 0.00012127378431614488
step: 100, loss: 0.00033909056219272316
step: 110, loss: 0.0005284122889861465
step: 120, loss: 0.0006366910529322922
step: 130, loss: 0.20853924751281738
step: 140, loss: 0.00027269168640486896
step: 150, loss: 0.00026787223760038614
step: 160, loss: 0.00024621764896437526
step: 170, loss: 4.0060080209514126e-05
step: 180, loss: 6.25526299700141e-05
step: 190, loss: 7.192821794888005e-05
step: 200, loss: 0.0002937965327873826
step: 210, loss: 0.00011380612704670057
step: 220, loss: 0.0001062348746927455
step: 230, loss: 4.74063417641446e-05
step: 240, loss: 5.741743734688498e-05
step: 250, loss: 0.00010399670281913131
step: 260, loss: 8.313209400512278e-05
step: 270, loss: 7.33888809918426e-05
step: 280, loss: 0.0004361968021839857
step: 290, loss: 0.0001499092031735927
step: 300, loss: 0.0002093469083774835
step: 310, loss: 0.00010368389484938234
step: 320, loss: 0.0004528699500951916
step: 330, loss: 0.00019561260705813766
step: 340, loss: 4.467562030185945e-05
step: 350, loss: 0.00023662528838030994
step: 360, loss: 6.836980901425704e-05
step: 370, loss: 0.0019462531199678779
step: 380, loss: 9.359541581943631e-05
epoch 20: dev_f1=0.7263427109974423, f1=0.5940054495912807, best_f1=0.5824175824175823
