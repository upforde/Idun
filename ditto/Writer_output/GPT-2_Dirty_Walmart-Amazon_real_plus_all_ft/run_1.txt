cuda
Device: cuda
step: 0, loss: 0.7829904556274414
step: 10, loss: 0.23253701627254486
step: 20, loss: 0.4764588475227356
step: 30, loss: 0.14968043565750122
step: 40, loss: 0.4331763982772827
step: 50, loss: 0.3712637722492218
step: 60, loss: 0.3335006833076477
step: 70, loss: 0.2248123735189438
step: 80, loss: 0.42154431343078613
step: 90, loss: 0.36424607038497925
step: 100, loss: 0.38748839497566223
step: 110, loss: 0.34545671939849854
step: 120, loss: 0.256792277097702
step: 130, loss: 0.27302733063697815
step: 140, loss: 0.17985276877880096
step: 150, loss: 0.2282221019268036
step: 160, loss: 0.11676106601953506
step: 170, loss: 0.25592944025993347
step: 180, loss: 0.13600844144821167
step: 190, loss: 0.3030780851840973
step: 200, loss: 0.2828775644302368
step: 210, loss: 0.11694412678480148
step: 220, loss: 0.26277828216552734
step: 230, loss: 0.21061354875564575
step: 240, loss: 0.29112717509269714
step: 250, loss: 0.17403867840766907
step: 260, loss: 0.11874948441982269
step: 270, loss: 0.19464053213596344
step: 280, loss: 0.19225290417671204
step: 290, loss: 0.10939256101846695
step: 300, loss: 0.1980450451374054
step: 310, loss: 0.2027490735054016
step: 320, loss: 0.12315286695957184
step: 330, loss: 0.21093006432056427
step: 340, loss: 0.09981061518192291
step: 350, loss: 0.209598109126091
step: 360, loss: 0.31950849294662476
step: 370, loss: 0.2605743408203125
step: 380, loss: 0.4268241226673126
epoch 1: dev_f1=0.6365795724465558, f1=0.49253731343283585, best_f1=0.49253731343283585
step: 0, loss: 0.2689588665962219
step: 10, loss: 0.21987667679786682
step: 20, loss: 0.05860569328069687
step: 30, loss: 0.33269014954566956
step: 40, loss: 0.12991926074028015
step: 50, loss: 0.18830443918704987
step: 60, loss: 0.32362818717956543
step: 70, loss: 0.19653889536857605
step: 80, loss: 0.07809805124998093
step: 90, loss: 0.14968766272068024
step: 100, loss: 0.2112015038728714
step: 110, loss: 0.09733734279870987
step: 120, loss: 0.11690980195999146
step: 130, loss: 0.24455377459526062
step: 140, loss: 0.3008330762386322
step: 150, loss: 0.03855292499065399
step: 160, loss: 0.17285926640033722
step: 170, loss: 0.24247324466705322
step: 180, loss: 0.24177688360214233
step: 190, loss: 0.02096184343099594
step: 200, loss: 0.21586807072162628
step: 210, loss: 0.21154460310935974
step: 220, loss: 0.08327863365411758
step: 230, loss: 0.021641353145241737
step: 240, loss: 0.18636509776115417
step: 250, loss: 0.04793863371014595
step: 260, loss: 0.1908552348613739
step: 270, loss: 0.38974529504776
step: 280, loss: 0.03823111578822136
step: 290, loss: 0.10251908749341965
step: 300, loss: 0.04345942288637161
step: 310, loss: 0.32284265756607056
step: 320, loss: 0.07666900753974915
step: 330, loss: 0.08356328308582306
step: 340, loss: 0.21113969385623932
step: 350, loss: 0.07445606589317322
step: 360, loss: 0.024109330028295517
step: 370, loss: 0.12658730149269104
step: 380, loss: 0.18253019452095032
epoch 2: dev_f1=0.7117647058823529, f1=0.5969230769230769, best_f1=0.5969230769230769
step: 0, loss: 0.15497557818889618
step: 10, loss: 0.06806004792451859
step: 20, loss: 0.07101964950561523
step: 30, loss: 0.24300332367420197
step: 40, loss: 0.08637651801109314
step: 50, loss: 0.2146299183368683
step: 60, loss: 0.2187260091304779
step: 70, loss: 0.03303305432200432
step: 80, loss: 0.11588601768016815
step: 90, loss: 0.0637042373418808
step: 100, loss: 0.07036785781383514
step: 110, loss: 0.07284540683031082
step: 120, loss: 0.04080011323094368
step: 130, loss: 0.04334690421819687
step: 140, loss: 0.05799782648682594
step: 150, loss: 0.21989348530769348
step: 160, loss: 0.055806636810302734
step: 170, loss: 0.22936296463012695
step: 180, loss: 0.026582952588796616
step: 190, loss: 0.19606582820415497
step: 200, loss: 0.11353986710309982
step: 210, loss: 0.11739083379507065
step: 220, loss: 0.01822223886847496
step: 230, loss: 0.1544637382030487
step: 240, loss: 0.1468035876750946
step: 250, loss: 0.04915495216846466
step: 260, loss: 0.13776275515556335
step: 270, loss: 0.022670678794384003
step: 280, loss: 0.0903468206524849
step: 290, loss: 0.10292206704616547
step: 300, loss: 0.018834766000509262
step: 310, loss: 0.01734236441552639
step: 320, loss: 0.056729916483163834
step: 330, loss: 0.0817956030368805
step: 340, loss: 0.07735548913478851
step: 350, loss: 0.05062545835971832
step: 360, loss: 0.15828680992126465
step: 370, loss: 0.42056137323379517
step: 380, loss: 0.06267968565225601
epoch 3: dev_f1=0.7506426735218509, f1=0.6453333333333333, best_f1=0.6453333333333333
step: 0, loss: 0.070365309715271
step: 10, loss: 0.06202879548072815
step: 20, loss: 0.015379155986011028
step: 30, loss: 0.02644956298172474
step: 40, loss: 0.14128029346466064
step: 50, loss: 0.058369334787130356
step: 60, loss: 0.0829261764883995
step: 70, loss: 0.0035000722855329514
step: 80, loss: 0.022340213879942894
step: 90, loss: 0.018116995692253113
step: 100, loss: 0.06695209443569183
step: 110, loss: 0.2004859894514084
step: 120, loss: 0.01938461698591709
step: 130, loss: 0.19845139980316162
step: 140, loss: 0.019598929211497307
step: 150, loss: 0.017066819593310356
step: 160, loss: 0.17355866730213165
step: 170, loss: 0.09698360413312912
step: 180, loss: 0.029757993295788765
step: 190, loss: 0.10995616018772125
step: 200, loss: 0.01098034530878067
step: 210, loss: 0.021748267114162445
step: 220, loss: 0.03719031810760498
step: 230, loss: 0.10922405868768692
step: 240, loss: 0.05634578317403793
step: 250, loss: 0.08966469764709473
step: 260, loss: 0.04740303009748459
step: 270, loss: 0.13857878744602203
step: 280, loss: 0.13067050278186798
step: 290, loss: 0.02495541051030159
step: 300, loss: 0.01738854870200157
step: 310, loss: 0.08739934861660004
step: 320, loss: 0.07789811491966248
step: 330, loss: 0.03395196422934532
step: 340, loss: 0.013403046876192093
step: 350, loss: 0.006400729529559612
step: 360, loss: 0.18565188348293304
step: 370, loss: 0.03801969066262245
step: 380, loss: 0.05961858853697777
epoch 4: dev_f1=0.7197802197802198, f1=0.6391184573002755, best_f1=0.6453333333333333
step: 0, loss: 0.025448154658079147
step: 10, loss: 0.0028939726762473583
step: 20, loss: 0.03614189103245735
step: 30, loss: 0.025352394208312035
step: 40, loss: 0.0024628201499581337
step: 50, loss: 0.02397836744785309
step: 60, loss: 0.03131936863064766
step: 70, loss: 0.01591261848807335
step: 80, loss: 0.005942054092884064
step: 90, loss: 0.13672366738319397
step: 100, loss: 0.003618381917476654
step: 110, loss: 0.23284375667572021
step: 120, loss: 0.04404701665043831
step: 130, loss: 0.010821257717907429
step: 140, loss: 0.009156651794910431
step: 150, loss: 0.05348231643438339
step: 160, loss: 0.009727968834340572
step: 170, loss: 0.011410526931285858
step: 180, loss: 0.05257425084710121
step: 190, loss: 0.010377720929682255
step: 200, loss: 0.016953472048044205
step: 210, loss: 0.012271127663552761
step: 220, loss: 0.005663781426846981
step: 230, loss: 0.08700799942016602
step: 240, loss: 0.04640304669737816
step: 250, loss: 0.05046859383583069
step: 260, loss: 0.001092401915229857
step: 270, loss: 0.051188874989748
step: 280, loss: 0.17056627571582794
step: 290, loss: 0.03558896854519844
step: 300, loss: 0.18982800841331482
step: 310, loss: 0.0873219445347786
step: 320, loss: 0.053778912872076035
step: 330, loss: 0.09682636708021164
step: 340, loss: 0.03458976745605469
step: 350, loss: 0.054255370050668716
step: 360, loss: 0.01985456980764866
step: 370, loss: 0.021672334522008896
step: 380, loss: 0.03748531639575958
epoch 5: dev_f1=0.7226890756302521, f1=0.5855072463768116, best_f1=0.6453333333333333
step: 0, loss: 0.03020002506673336
step: 10, loss: 0.027476957067847252
step: 20, loss: 0.020301662385463715
step: 30, loss: 0.08443628251552582
step: 40, loss: 0.09349679946899414
step: 50, loss: 0.001548026455566287
step: 60, loss: 0.019564509391784668
step: 70, loss: 0.009043962694704533
step: 80, loss: 0.08019032329320908
step: 90, loss: 0.007169043179601431
step: 100, loss: 0.0433100089430809
step: 110, loss: 0.001132693258114159
step: 120, loss: 0.00040621423977427185
step: 130, loss: 0.08192408084869385
step: 140, loss: 0.0699474886059761
step: 150, loss: 0.024917613714933395
step: 160, loss: 0.005477546248584986
step: 170, loss: 0.05328933894634247
step: 180, loss: 0.024862902238965034
step: 190, loss: 0.015596088021993637
step: 200, loss: 0.0024719596840441227
step: 210, loss: 0.04106834530830383
step: 220, loss: 0.05217530205845833
step: 230, loss: 0.0023958401288837194
step: 240, loss: 0.008359875530004501
step: 250, loss: 0.032059621065855026
step: 260, loss: 0.006174816284328699
step: 270, loss: 0.04352860897779465
step: 280, loss: 0.0781572163105011
step: 290, loss: 0.05989979952573776
step: 300, loss: 0.07650742679834366
step: 310, loss: 0.012065104208886623
step: 320, loss: 0.0023979968391358852
step: 330, loss: 0.011157588101923466
step: 340, loss: 0.08466195315122604
step: 350, loss: 0.01689237356185913
step: 360, loss: 0.038367416709661484
step: 370, loss: 0.0017815101891756058
step: 380, loss: 0.020879704505205154
epoch 6: dev_f1=0.7480106100795757, f1=0.5989304812834224, best_f1=0.6453333333333333
step: 0, loss: 0.008652159944176674
step: 10, loss: 0.008214929141104221
step: 20, loss: 0.013693091459572315
step: 30, loss: 0.10738062113523483
step: 40, loss: 0.002848386764526367
step: 50, loss: 0.0019451950211077929
step: 60, loss: 0.007414370309561491
step: 70, loss: 0.0010636302176862955
step: 80, loss: 0.007185261696577072
step: 90, loss: 0.015199974179267883
step: 100, loss: 0.0029480860102921724
step: 110, loss: 0.0005884416168555617
step: 120, loss: 0.15455637872219086
step: 130, loss: 0.0018967040814459324
step: 140, loss: 0.061065420508384705
step: 150, loss: 0.09854301065206528
step: 160, loss: 0.005690067075192928
step: 170, loss: 0.07341551780700684
step: 180, loss: 0.016767213121056557
step: 190, loss: 0.0017128209583461285
step: 200, loss: 0.010258856229484081
step: 210, loss: 0.0007257344550453126
step: 220, loss: 0.004537684377282858
step: 230, loss: 0.11914905160665512
step: 240, loss: 0.1742587387561798
step: 250, loss: 0.0017938133096322417
step: 260, loss: 0.02104824036359787
step: 270, loss: 0.0016128753777593374
step: 280, loss: 0.0005060791736468673
step: 290, loss: 0.008838285692036152
step: 300, loss: 0.003968746401369572
step: 310, loss: 0.010533945634961128
step: 320, loss: 0.005010784603655338
step: 330, loss: 0.033461254090070724
step: 340, loss: 0.0006461541051976383
step: 350, loss: 0.011848651804029942
step: 360, loss: 0.0051862932741642
step: 370, loss: 0.001252991845831275
step: 380, loss: 0.0018713806057348847
epoch 7: dev_f1=0.7530562347188262, f1=0.6551724137931034, best_f1=0.6551724137931034
step: 0, loss: 0.002635180251672864
step: 10, loss: 0.01981407217681408
step: 20, loss: 0.001861993339844048
step: 30, loss: 0.00021243057562969625
step: 40, loss: 0.0007720848079770803
step: 50, loss: 0.03446102514863014
step: 60, loss: 0.0006708837463520467
step: 70, loss: 0.000696913804858923
step: 80, loss: 0.0003467004862613976
step: 90, loss: 0.0007526068366132677
step: 100, loss: 0.0019129689317196608
step: 110, loss: 0.14319905638694763
step: 120, loss: 0.0009004237363114953
step: 130, loss: 0.003315162379294634
step: 140, loss: 0.0021914453245699406
step: 150, loss: 0.018959157168865204
step: 160, loss: 0.019099421799182892
step: 170, loss: 0.04374799132347107
step: 180, loss: 0.008829357102513313
step: 190, loss: 0.0007993956678546965
step: 200, loss: 0.12580113112926483
step: 210, loss: 0.00981359276920557
step: 220, loss: 0.0026867701672017574
step: 230, loss: 0.002848709700629115
step: 240, loss: 0.0007890551351010799
step: 250, loss: 0.029951654374599457
step: 260, loss: 0.005700041074305773
step: 270, loss: 0.013897525146603584
step: 280, loss: 0.0016646342119202018
step: 290, loss: 0.0014153384836390615
step: 300, loss: 0.18750397861003876
step: 310, loss: 0.004752012901008129
step: 320, loss: 0.11248308420181274
step: 330, loss: 0.0022877759765833616
step: 340, loss: 0.012071979232132435
step: 350, loss: 0.014813057146966457
step: 360, loss: 0.0012554193381220102
step: 370, loss: 0.0058510927483439445
step: 380, loss: 0.004729514010250568
epoch 8: dev_f1=0.7185929648241205, f1=0.6123456790123456, best_f1=0.6551724137931034
step: 0, loss: 0.009898104704916477
step: 10, loss: 0.01451621949672699
step: 20, loss: 0.012177114374935627
step: 30, loss: 0.03128921985626221
step: 40, loss: 0.009331596083939075
step: 50, loss: 0.0006844515446573496
step: 60, loss: 0.0003678274806588888
step: 70, loss: 0.006363480351865292
step: 80, loss: 0.0006299878004938364
step: 90, loss: 0.0015216412721201777
step: 100, loss: 0.000985176651738584
step: 110, loss: 0.0010824849596247077
step: 120, loss: 0.00023785441590007395
step: 130, loss: 0.004768293350934982
step: 140, loss: 0.014499216340482235
step: 150, loss: 0.051138319075107574
step: 160, loss: 0.0011677456786856055
step: 170, loss: 0.0011801865184679627
step: 180, loss: 0.0013977978378534317
step: 190, loss: 0.017409181222319603
step: 200, loss: 0.0002254321298096329
step: 210, loss: 0.0018217235337942839
step: 220, loss: 0.002325603971257806
step: 230, loss: 0.12713882327079773
step: 240, loss: 0.0747792199254036
step: 250, loss: 0.1453641653060913
step: 260, loss: 0.0005930924671702087
step: 270, loss: 0.014379763044416904
step: 280, loss: 0.001271513057872653
step: 290, loss: 0.00044093269389122725
step: 300, loss: 0.005317049100995064
step: 310, loss: 0.03357500210404396
step: 320, loss: 0.09605289250612259
step: 330, loss: 0.0022230828180909157
step: 340, loss: 0.019008660688996315
step: 350, loss: 0.04838269576430321
step: 360, loss: 0.004987913649529219
step: 370, loss: 0.0011414812179282308
step: 380, loss: 0.007084976881742477
epoch 9: dev_f1=0.7080459770114941, f1=0.5945945945945946, best_f1=0.6551724137931034
step: 0, loss: 0.059304334223270416
step: 10, loss: 0.0031671312171965837
step: 20, loss: 0.00776123721152544
step: 30, loss: 0.005406254902482033
step: 40, loss: 0.0024879807606339455
step: 50, loss: 0.0006250935257412493
step: 60, loss: 0.01568652130663395
step: 70, loss: 0.000527454016264528
step: 80, loss: 0.024972012266516685
step: 90, loss: 0.010084149427711964
step: 100, loss: 0.0033541731536388397
step: 110, loss: 0.0006469889194704592
step: 120, loss: 0.0018883683951571584
step: 130, loss: 0.00016790538211353123
step: 140, loss: 0.0005975741078145802
step: 150, loss: 0.006493682041764259
step: 160, loss: 0.0011335999006405473
step: 170, loss: 0.004988568369299173
step: 180, loss: 0.0017085287254303694
step: 190, loss: 0.009227754548192024
step: 200, loss: 0.0071455552242696285
step: 210, loss: 0.048677265644073486
step: 220, loss: 0.0016344425966963172
step: 230, loss: 0.003767111338675022
step: 240, loss: 0.0020599528215825558
step: 250, loss: 0.0004887690884061158
step: 260, loss: 0.00026649117353372276
step: 270, loss: 0.00031166838016361
step: 280, loss: 0.0505547933280468
step: 290, loss: 0.16030283272266388
step: 300, loss: 0.00328980409540236
step: 310, loss: 0.0013605216518044472
step: 320, loss: 0.0036094014067202806
step: 330, loss: 0.0007385368808172643
step: 340, loss: 0.000617796613369137
step: 350, loss: 0.00043917365837842226
step: 360, loss: 0.0015802067937329412
step: 370, loss: 0.014698329381644726
step: 380, loss: 0.059076812118291855
epoch 10: dev_f1=0.7342465753424658, f1=0.5878962536023055, best_f1=0.6551724137931034
step: 0, loss: 0.0009330746834166348
step: 10, loss: 0.002961228834465146
step: 20, loss: 0.01773255504667759
step: 30, loss: 0.0026341713964939117
step: 40, loss: 0.0029171528294682503
step: 50, loss: 0.01175255049020052
step: 60, loss: 0.0024728744756430387
step: 70, loss: 0.0010140759404748678
step: 80, loss: 0.0007136244676075876
step: 90, loss: 0.0007540570804849267
step: 100, loss: 0.0019493130967020988
step: 110, loss: 0.0005793155287392437
step: 120, loss: 0.003971618600189686
step: 130, loss: 0.0990070253610611
step: 140, loss: 0.0012801672564819455
step: 150, loss: 0.0018391365883871913
step: 160, loss: 0.0014303206698969007
step: 170, loss: 0.0006375637021847069
step: 180, loss: 0.010359029285609722
step: 190, loss: 0.0008567205513827503
step: 200, loss: 0.003245970234274864
step: 210, loss: 0.0002669916138984263
step: 220, loss: 0.0009489224757999182
step: 230, loss: 0.0022116350010037422
step: 240, loss: 0.006578325293958187
step: 250, loss: 0.00042930131894536316
step: 260, loss: 0.0006657415651716292
step: 270, loss: 0.12467299401760101
step: 280, loss: 0.0004996240604668856
step: 290, loss: 0.0006298800581134856
step: 300, loss: 0.041082367300987244
step: 310, loss: 0.0014928432647138834
step: 320, loss: 0.00019604632689151913
step: 330, loss: 0.0004628477618098259
step: 340, loss: 0.01203826256096363
step: 350, loss: 0.0018849868793040514
step: 360, loss: 0.002045972039923072
step: 370, loss: 0.0019479321781545877
step: 380, loss: 0.0036793474573642015
epoch 11: dev_f1=0.7164179104477613, f1=0.6379746835443039, best_f1=0.6551724137931034
step: 0, loss: 0.0002668621309567243
step: 10, loss: 0.00045575067633762956
step: 20, loss: 0.06701669842004776
step: 30, loss: 0.0012621193891391158
step: 40, loss: 0.003238951787352562
step: 50, loss: 0.0038739058654755354
step: 60, loss: 0.0004404342034831643
step: 70, loss: 0.004619566258043051
step: 80, loss: 0.0014586186734959483
step: 90, loss: 0.0008197673014365137
step: 100, loss: 0.04010968655347824
step: 110, loss: 0.0010188865708187222
step: 120, loss: 0.002164185279980302
step: 130, loss: 0.0006481640157289803
step: 140, loss: 0.005724878516048193
step: 150, loss: 0.001917823450639844
step: 160, loss: 0.00021913982345722616
step: 170, loss: 0.0018577446462586522
step: 180, loss: 0.03156682103872299
step: 190, loss: 0.0018625889206305146
step: 200, loss: 0.0002286845410708338
step: 210, loss: 0.00016656283696647733
step: 220, loss: 0.0007226028246805072
step: 230, loss: 0.2137874960899353
step: 240, loss: 0.00112773641012609
step: 250, loss: 0.0002965795574709773
step: 260, loss: 0.07029854506254196
step: 270, loss: 0.0005904142744839191
step: 280, loss: 0.0001499535283073783
step: 290, loss: 0.11462149769067764
step: 300, loss: 0.0001751236995914951
step: 310, loss: 0.002593956422060728
step: 320, loss: 0.0010936384787783027
step: 330, loss: 0.054671015590429306
step: 340, loss: 9.096354915527627e-05
step: 350, loss: 0.00015566981164738536
step: 360, loss: 0.00045407915604300797
step: 370, loss: 0.02102016471326351
step: 380, loss: 0.001255204202607274
epoch 12: dev_f1=0.7305699481865285, f1=0.6505376344086021, best_f1=0.6551724137931034
step: 0, loss: 0.00013015259173698723
step: 10, loss: 0.02255803719162941
step: 20, loss: 0.00010301576548954472
step: 30, loss: 0.0031102460343390703
step: 40, loss: 0.00032674591057002544
step: 50, loss: 0.00019807661010418087
step: 60, loss: 0.0008663309854455292
step: 70, loss: 0.0006366246961988509
step: 80, loss: 0.00015351883484981954
step: 90, loss: 0.0007522468222305179
step: 100, loss: 0.01700402796268463
step: 110, loss: 0.021063007414340973
step: 120, loss: 0.0008384957327507436
step: 130, loss: 0.0006854714592918754
step: 140, loss: 0.00712396577000618
step: 150, loss: 0.0002001854300033301
step: 160, loss: 0.0006172345019876957
step: 170, loss: 0.00013655678776558489
step: 180, loss: 0.0004233454237692058
step: 190, loss: 7.978516077855602e-05
step: 200, loss: 9.983538620872423e-05
step: 210, loss: 0.00010656711674528196
step: 220, loss: 0.0019977486226707697
step: 230, loss: 0.030361037701368332
step: 240, loss: 0.0002806408447213471
step: 250, loss: 0.005067010410130024
step: 260, loss: 0.0015166670782491565
step: 270, loss: 0.0002917667734436691
step: 280, loss: 0.0012420634739100933
step: 290, loss: 0.0074929059483110905
step: 300, loss: 0.00725336791947484
step: 310, loss: 0.0003672412713058293
step: 320, loss: 0.0005413551116362214
step: 330, loss: 0.0020471331663429737
step: 340, loss: 9.928198414854705e-05
step: 350, loss: 0.010442410595715046
step: 360, loss: 0.0002649248344823718
step: 370, loss: 0.000492523075081408
step: 380, loss: 0.005685652140527964
epoch 13: dev_f1=0.7345844504021448, f1=0.5989010989010989, best_f1=0.6551724137931034
step: 0, loss: 0.007102999836206436
step: 10, loss: 0.004615597426891327
step: 20, loss: 0.0003100621688645333
step: 30, loss: 0.04958326369524002
step: 40, loss: 0.00040454661939293146
step: 50, loss: 0.00017702738114167005
step: 60, loss: 7.609122258145362e-05
step: 70, loss: 0.008916045539081097
step: 80, loss: 0.051089946180582047
step: 90, loss: 0.00016792246606200933
step: 100, loss: 0.0007350374944508076
step: 110, loss: 0.07211509346961975
step: 120, loss: 0.0011390607105568051
step: 130, loss: 0.00024533350369893014
step: 140, loss: 0.005339184310287237
step: 150, loss: 0.0017928475281223655
step: 160, loss: 0.0026962673291563988
step: 170, loss: 0.00024185323854908347
step: 180, loss: 0.0015058191493153572
step: 190, loss: 6.352215132210404e-05
step: 200, loss: 7.886376261012629e-05
step: 210, loss: 0.0005871380562894046
step: 220, loss: 0.00012259511277079582
step: 230, loss: 0.002080002101138234
step: 240, loss: 0.0012148446403443813
step: 250, loss: 8.150446228682995e-05
step: 260, loss: 0.0002938677207566798
step: 270, loss: 0.0010395122226327658
step: 280, loss: 0.027483941987156868
step: 290, loss: 0.0002552669320721179
step: 300, loss: 0.0009953591506928205
step: 310, loss: 0.0002931776689365506
step: 320, loss: 0.009656154550611973
step: 330, loss: 0.005688481964170933
step: 340, loss: 0.00033507717307657003
step: 350, loss: 0.003200642764568329
step: 360, loss: 0.10322464257478714
step: 370, loss: 0.0001792213588487357
step: 380, loss: 0.0004691587819252163
epoch 14: dev_f1=0.7456647398843931, f1=0.577639751552795, best_f1=0.6551724137931034
step: 0, loss: 9.624312951928005e-05
step: 10, loss: 0.005209789145737886
step: 20, loss: 0.015570973046123981
step: 30, loss: 0.0004535604966804385
step: 40, loss: 0.001149337855167687
step: 50, loss: 0.06019984558224678
step: 60, loss: 0.0005273137940093875
step: 70, loss: 0.00011107363388873637
step: 80, loss: 0.00025488316896371543
step: 90, loss: 0.002590480260550976
step: 100, loss: 0.0005185057525523007
step: 110, loss: 0.0001882952346932143
step: 120, loss: 0.00030814751517027617
step: 130, loss: 0.0013010022230446339
step: 140, loss: 0.0002924247528426349
step: 150, loss: 0.00014026369899511337
step: 160, loss: 8.47147821332328e-05
step: 170, loss: 0.00011105315934401006
step: 180, loss: 0.006130245979875326
step: 190, loss: 9.140759357251227e-05
step: 200, loss: 0.00013179931556805968
step: 210, loss: 0.000477264286018908
step: 220, loss: 0.03228738158941269
step: 230, loss: 0.00015809615433681756
step: 240, loss: 0.00024262195802293718
step: 250, loss: 0.0004526177071966231
step: 260, loss: 4.470128260436468e-05
step: 270, loss: 0.00018602790078148246
step: 280, loss: 5.4009389714337885e-05
step: 290, loss: 8.059378887992352e-05
step: 300, loss: 0.00019841002358589321
step: 310, loss: 0.0001381341862725094
step: 320, loss: 9.994980791816488e-05
step: 330, loss: 0.0014240298187360168
step: 340, loss: 0.00025480869226157665
step: 350, loss: 0.00023399098427034914
step: 360, loss: 7.870364788686857e-05
step: 370, loss: 0.00023546989541500807
step: 380, loss: 0.00023749753017909825
epoch 15: dev_f1=0.7397260273972603, f1=0.6432748538011697, best_f1=0.6551724137931034
step: 0, loss: 0.005329926498234272
step: 10, loss: 7.878299948060885e-05
step: 20, loss: 0.004381521139293909
step: 30, loss: 0.009012160822749138
step: 40, loss: 0.0001197477977257222
step: 50, loss: 0.00012856775720138103
step: 60, loss: 0.0002562877780292183
step: 70, loss: 4.6491826651617885e-05
step: 80, loss: 0.00017033213225658983
step: 90, loss: 7.302252197405323e-05
step: 100, loss: 8.427714055869728e-05
step: 110, loss: 0.0002122358710039407
step: 120, loss: 6.341301195789129e-05
step: 130, loss: 5.4026677389629185e-05
step: 140, loss: 0.00031881892937235534
step: 150, loss: 0.00011944452853640541
step: 160, loss: 8.341335342265666e-05
step: 170, loss: 6.429861241485924e-05
step: 180, loss: 0.0001319840521318838
step: 190, loss: 0.1336224228143692
step: 200, loss: 5.58708852622658e-05
step: 210, loss: 0.0001211730414070189
step: 220, loss: 0.00046517798909917474
step: 230, loss: 0.0004082544182892889
step: 240, loss: 0.00010880892659770325
step: 250, loss: 0.0002150946093024686
step: 260, loss: 8.258975140051916e-05
step: 270, loss: 7.784679473843426e-05
step: 280, loss: 7.156539504649118e-05
step: 290, loss: 0.0003377484972588718
step: 300, loss: 9.801489795790985e-05
step: 310, loss: 0.00012390222400426865
step: 320, loss: 0.00011165380419697613
step: 330, loss: 0.00014011409075465053
step: 340, loss: 0.0003065622295252979
step: 350, loss: 0.00029558586538769305
step: 360, loss: 0.0023245341144502163
step: 370, loss: 0.028891833499073982
step: 380, loss: 6.456320988945663e-05
epoch 16: dev_f1=0.7365439093484418, f1=0.6017699115044247, best_f1=0.6551724137931034
step: 0, loss: 0.0001663419243413955
step: 10, loss: 0.00022919119510333985
step: 20, loss: 0.00013007652887608856
step: 30, loss: 0.00020484821288846433
step: 40, loss: 0.00020700841560028493
step: 50, loss: 5.008303196518682e-05
step: 60, loss: 7.396531873382628e-05
step: 70, loss: 0.00023388411500491202
step: 80, loss: 0.000722263939678669
step: 90, loss: 0.000644047511741519
step: 100, loss: 0.00012162594794062898
step: 110, loss: 5.413982944446616e-05
step: 120, loss: 5.6206910812761635e-05
step: 130, loss: 0.02525579184293747
step: 140, loss: 0.0006364838336594403
step: 150, loss: 0.00010079696221509948
step: 160, loss: 0.00011853285104734823
step: 170, loss: 0.00044781036558561027
step: 180, loss: 5.532704381039366e-05
step: 190, loss: 5.788468479295261e-05
step: 200, loss: 0.0002659373276401311
step: 210, loss: 8.227558282669634e-05
step: 220, loss: 0.08682337403297424
step: 230, loss: 7.66858720453456e-05
step: 240, loss: 5.833792965859175e-05
step: 250, loss: 0.00010813752305693924
step: 260, loss: 4.8528781917411834e-05
step: 270, loss: 0.00042072689393535256
step: 280, loss: 0.00019461274496279657
step: 290, loss: 0.0013957733754068613
step: 300, loss: 0.00013101467629894614
step: 310, loss: 6.843425944680348e-05
step: 320, loss: 0.0011497363448143005
step: 330, loss: 6.960056634852663e-05
step: 340, loss: 7.502433436457068e-05
step: 350, loss: 0.00011750966223189607
step: 360, loss: 0.00013901259808335453
step: 370, loss: 8.270925172837451e-05
step: 380, loss: 0.0002604539622552693
epoch 17: dev_f1=0.7333333333333333, f1=0.6379310344827587, best_f1=0.6551724137931034
step: 0, loss: 0.00013632258924189955
step: 10, loss: 0.00010169867891818285
step: 20, loss: 5.6668366596568376e-05
step: 30, loss: 0.0006535752909258008
step: 40, loss: 6.519669113913551e-05
step: 50, loss: 0.00018000390264205635
step: 60, loss: 7.916811591712758e-05
step: 70, loss: 0.0001902491640066728
step: 80, loss: 0.00012108100054319948
step: 90, loss: 4.181019903626293e-05
step: 100, loss: 0.0008276879671029747
step: 110, loss: 7.620974065503106e-05
step: 120, loss: 9.67611777014099e-05
step: 130, loss: 0.00010425969230709597
step: 140, loss: 5.298574978951365e-05
step: 150, loss: 7.322354940697551e-05
step: 160, loss: 0.00010833853593794629
step: 170, loss: 0.00010849586396943778
step: 180, loss: 8.895325299818069e-05
step: 190, loss: 4.793838888872415e-05
step: 200, loss: 5.033930574427359e-05
step: 210, loss: 0.0001043402444338426
step: 220, loss: 0.0002746313693933189
step: 230, loss: 0.00014570931671187282
step: 240, loss: 0.000138610033900477
step: 250, loss: 0.0006025147158652544
step: 260, loss: 0.00011778441694332287
step: 270, loss: 0.00010659838881110772
step: 280, loss: 6.284033588599414e-05
step: 290, loss: 0.0002887153241317719
step: 300, loss: 0.011205616407096386
step: 310, loss: 0.0033098303247243166
step: 320, loss: 6.99710872140713e-05
step: 330, loss: 0.00022543332306668162
step: 340, loss: 0.00034016327117569745
step: 350, loss: 0.0001597308728378266
step: 360, loss: 0.0003487038775347173
step: 370, loss: 0.00021662119252141565
step: 380, loss: 4.8504349251743406e-05
epoch 18: dev_f1=0.7348066298342542, f1=0.6202898550724637, best_f1=0.6551724137931034
step: 0, loss: 0.00011904819257324561
step: 10, loss: 0.0004390678077470511
step: 20, loss: 0.0012895422987639904
step: 30, loss: 9.509445953881368e-05
step: 40, loss: 4.8778198106447235e-05
step: 50, loss: 0.0001424145739292726
step: 60, loss: 4.548937431536615e-05
step: 70, loss: 7.500241918023676e-05
step: 80, loss: 0.01407970953732729
step: 90, loss: 0.00010046212992165238
step: 100, loss: 0.0001862316858023405
step: 110, loss: 2.8028178348904476e-05
step: 120, loss: 6.015713370288722e-05
step: 130, loss: 0.00018438842380419374
step: 140, loss: 0.00017686096543911844
step: 150, loss: 0.00013823050539940596
step: 160, loss: 4.316207559895702e-05
step: 170, loss: 0.025041719898581505
step: 180, loss: 0.004197294358164072
step: 190, loss: 8.180845907190815e-05
step: 200, loss: 0.0001305104815401137
step: 210, loss: 0.00014407919661607593
step: 220, loss: 4.921983054373413e-05
step: 230, loss: 0.00014019674563314766
step: 240, loss: 0.00015379051910713315
step: 250, loss: 0.00016259420954156667
step: 260, loss: 0.00030037344549782574
step: 270, loss: 0.00047453580191358924
step: 280, loss: 4.83619915030431e-05
step: 290, loss: 0.00019044647342525423
step: 300, loss: 9.187843534164131e-05
step: 310, loss: 6.688589201075956e-05
step: 320, loss: 5.112586586619727e-05
step: 330, loss: 4.2388397559989244e-05
step: 340, loss: 0.0001106974232243374
step: 350, loss: 0.0006559494067914784
step: 360, loss: 0.012065877206623554
step: 370, loss: 4.468950646696612e-05
step: 380, loss: 4.855600855080411e-05
epoch 19: dev_f1=0.7344632768361581, f1=0.6024096385542168, best_f1=0.6551724137931034
step: 0, loss: 8.661109313834459e-05
step: 10, loss: 8.32545556477271e-05
step: 20, loss: 6.713540642522275e-05
step: 30, loss: 0.0004130396991968155
step: 40, loss: 7.497929618693888e-05
step: 50, loss: 0.002094422932714224
step: 60, loss: 5.916206646361388e-05
step: 70, loss: 0.00189526891335845
step: 80, loss: 0.00019643139967229217
step: 90, loss: 0.00022602156968787313
step: 100, loss: 0.00022369020734913647
step: 110, loss: 0.00011493545025587082
step: 120, loss: 6.470228981925175e-05
step: 130, loss: 9.819884871831164e-05
step: 140, loss: 8.328244439326227e-05
step: 150, loss: 7.884573278715834e-05
step: 160, loss: 0.00012891754158772528
step: 170, loss: 0.00013552278687711805
step: 180, loss: 6.919049337739125e-05
step: 190, loss: 5.262246122583747e-05
step: 200, loss: 0.0006396410753950477
step: 210, loss: 0.00012218802294228226
step: 220, loss: 7.50108010834083e-05
step: 230, loss: 7.169682066887617e-05
step: 240, loss: 8.942448766902089e-05
step: 250, loss: 4.795572749571875e-05
step: 260, loss: 0.00044456374598667026
step: 270, loss: 0.00019480226910673082
step: 280, loss: 0.00010273348743794486
step: 290, loss: 7.787230424582958e-05
step: 300, loss: 7.462306530214846e-05
step: 310, loss: 3.178296174155548e-05
step: 320, loss: 6.606178794754669e-05
step: 330, loss: 0.0007134303450584412
step: 340, loss: 0.0003025461337529123
step: 350, loss: 6.710099842166528e-05
step: 360, loss: 3.77319120161701e-05
step: 370, loss: 0.004050760064274073
step: 380, loss: 0.00023536686785519123
epoch 20: dev_f1=0.7362637362637363, f1=0.6306818181818182, best_f1=0.6551724137931034
