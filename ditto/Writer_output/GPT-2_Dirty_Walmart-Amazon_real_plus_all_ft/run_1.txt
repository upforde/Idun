cuda
Device: cuda
step: 0, loss: 0.6192551255226135
step: 10, loss: 0.16033396124839783
step: 20, loss: 0.30132701992988586
step: 30, loss: 0.19250425696372986
step: 40, loss: 0.19611430168151855
step: 50, loss: 0.08645923435688019
step: 60, loss: 0.17066755890846252
step: 70, loss: 0.30962884426116943
step: 80, loss: 0.4132351279258728
step: 90, loss: 0.4769294261932373
step: 100, loss: 0.3051721155643463
step: 110, loss: 0.35909855365753174
step: 120, loss: 0.23150797188282013
step: 130, loss: 0.5216301083564758
step: 140, loss: 0.31112000346183777
step: 150, loss: 0.28480178117752075
step: 160, loss: 0.2566171884536743
step: 170, loss: 0.39415422081947327
step: 180, loss: 0.33084434270858765
step: 190, loss: 0.43343231081962585
step: 200, loss: 0.37698206305503845
step: 210, loss: 0.2382425218820572
step: 220, loss: 0.2858624756336212
step: 230, loss: 0.2647038996219635
step: 240, loss: 0.14222097396850586
step: 250, loss: 0.28547006845474243
step: 260, loss: 0.27875572443008423
step: 270, loss: 0.2549216151237488
step: 280, loss: 0.27344971895217896
step: 290, loss: 0.30392351746559143
step: 300, loss: 0.14781279861927032
step: 310, loss: 0.24737557768821716
step: 320, loss: 0.15677691996097565
step: 330, loss: 0.13421237468719482
step: 340, loss: 0.18130572140216827
step: 350, loss: 0.18432208895683289
step: 360, loss: 0.4153643548488617
step: 370, loss: 0.24535706639289856
step: 380, loss: 0.36779525876045227
epoch 1: dev_f1=0.45901639344262296, f1=0.32163742690058483, best_f1=0.32163742690058483
step: 0, loss: 0.17169444262981415
step: 10, loss: 0.26126521825790405
step: 20, loss: 0.19146038591861725
step: 30, loss: 0.1467825025320053
step: 40, loss: 0.12487710267305374
step: 50, loss: 0.2248862385749817
step: 60, loss: 0.2872636914253235
step: 70, loss: 0.24965226650238037
step: 80, loss: 0.149833083152771
step: 90, loss: 0.11913980543613434
step: 100, loss: 0.23432132601737976
step: 110, loss: 0.12443574517965317
step: 120, loss: 0.15798723697662354
step: 130, loss: 0.12608955800533295
step: 140, loss: 0.10655783116817474
step: 150, loss: 0.2569620907306671
step: 160, loss: 0.1917203813791275
step: 170, loss: 0.24561531841754913
step: 180, loss: 0.22965218126773834
step: 190, loss: 0.16375674307346344
step: 200, loss: 0.4856955111026764
step: 210, loss: 0.20820342004299164
step: 220, loss: 0.03847220540046692
step: 230, loss: 0.18971461057662964
step: 240, loss: 0.46671193838119507
step: 250, loss: 0.1565467268228531
step: 260, loss: 0.13895079493522644
step: 270, loss: 0.14361348748207092
step: 280, loss: 0.2232678234577179
step: 290, loss: 0.0814119204878807
step: 300, loss: 0.1040891781449318
step: 310, loss: 0.26313138008117676
step: 320, loss: 0.11966311186552048
step: 330, loss: 0.10546369850635529
step: 340, loss: 0.1471620798110962
step: 350, loss: 0.10638900846242905
step: 360, loss: 0.3033131957054138
step: 370, loss: 0.24646782875061035
step: 380, loss: 0.2956230044364929
epoch 2: dev_f1=0.6777777777777778, f1=0.4329268292682927, best_f1=0.4329268292682927
step: 0, loss: 0.05551322549581528
step: 10, loss: 0.09552869945764542
step: 20, loss: 0.04372373968362808
step: 30, loss: 0.3087019920349121
step: 40, loss: 0.07356266677379608
step: 50, loss: 0.12253902852535248
step: 60, loss: 0.044786807149648666
step: 70, loss: 0.18771207332611084
step: 80, loss: 0.05772269517183304
step: 90, loss: 0.041575364768505096
step: 100, loss: 0.21423353254795074
step: 110, loss: 0.22522927820682526
step: 120, loss: 0.060539375990629196
step: 130, loss: 0.14854907989501953
step: 140, loss: 0.09270496666431427
step: 150, loss: 0.4011662006378174
step: 160, loss: 0.10899212956428528
step: 170, loss: 0.2129622846841812
step: 180, loss: 0.1083410233259201
step: 190, loss: 0.17905619740486145
step: 200, loss: 0.16783466935157776
step: 210, loss: 0.15536606311798096
step: 220, loss: 0.15952983498573303
step: 230, loss: 0.21590054035186768
step: 240, loss: 0.13133108615875244
step: 250, loss: 0.05034099891781807
step: 260, loss: 0.04741948843002319
step: 270, loss: 0.21420517563819885
step: 280, loss: 0.07124937325716019
step: 290, loss: 0.05501297488808632
step: 300, loss: 0.009728661738336086
step: 310, loss: 0.10699669271707535
step: 320, loss: 0.08203405886888504
step: 330, loss: 0.1747308224439621
step: 340, loss: 0.0867091715335846
step: 350, loss: 0.1223413422703743
step: 360, loss: 0.18971890211105347
step: 370, loss: 0.059960443526506424
step: 380, loss: 0.03292521834373474
epoch 3: dev_f1=0.6983372921615202, f1=0.5118733509234829, best_f1=0.5118733509234829
step: 0, loss: 0.008191619999706745
step: 10, loss: 0.1392027735710144
step: 20, loss: 0.02836724929511547
step: 30, loss: 0.25284475088119507
step: 40, loss: 0.02581125497817993
step: 50, loss: 0.016000032424926758
step: 60, loss: 0.03673597797751427
step: 70, loss: 0.03248751908540726
step: 80, loss: 0.04747263714671135
step: 90, loss: 0.04560835286974907
step: 100, loss: 0.06046145781874657
step: 110, loss: 0.006460148375481367
step: 120, loss: 0.08030962944030762
step: 130, loss: 0.1700487732887268
step: 140, loss: 0.022377818822860718
step: 150, loss: 0.10448741167783737
step: 160, loss: 0.3234140872955322
step: 170, loss: 0.04011016711592674
step: 180, loss: 0.047737300395965576
step: 190, loss: 0.02016891911625862
step: 200, loss: 0.021896924823522568
step: 210, loss: 0.23880288004875183
step: 220, loss: 0.12101390957832336
step: 230, loss: 0.10536154359579086
step: 240, loss: 0.06218145787715912
step: 250, loss: 0.015728963539004326
step: 260, loss: 0.02404484711587429
step: 270, loss: 0.01717766746878624
step: 280, loss: 0.028287041932344437
step: 290, loss: 0.2736703157424927
step: 300, loss: 0.03288005664944649
step: 310, loss: 0.02118310146033764
step: 320, loss: 0.10266606509685516
step: 330, loss: 0.009327391162514687
step: 340, loss: 0.16556179523468018
step: 350, loss: 0.05204718932509422
step: 360, loss: 0.016673743724822998
step: 370, loss: 0.2368030846118927
step: 380, loss: 0.09406724572181702
epoch 4: dev_f1=0.7342465753424658, f1=0.5531914893617021, best_f1=0.5531914893617021
step: 0, loss: 0.017623096704483032
step: 10, loss: 0.019103609025478363
step: 20, loss: 0.04126843065023422
step: 30, loss: 0.023138726130127907
step: 40, loss: 0.008366286754608154
step: 50, loss: 0.010508039966225624
step: 60, loss: 0.04571184888482094
step: 70, loss: 0.074607715010643
step: 80, loss: 0.009743123315274715
step: 90, loss: 0.037188492715358734
step: 100, loss: 0.06774823367595673
step: 110, loss: 0.01061843242496252
step: 120, loss: 0.01584264449775219
step: 130, loss: 0.01552367489784956
step: 140, loss: 0.00871607568114996
step: 150, loss: 0.1630965769290924
step: 160, loss: 0.04533721134066582
step: 170, loss: 0.16523109376430511
step: 180, loss: 0.1413499116897583
step: 190, loss: 0.03842975199222565
step: 200, loss: 0.009232987649738789
step: 210, loss: 0.06007949635386467
step: 220, loss: 0.014868157915771008
step: 230, loss: 0.055043525993824005
step: 240, loss: 0.07695925980806351
step: 250, loss: 0.043979763984680176
step: 260, loss: 0.006861163768917322
step: 270, loss: 0.10602131485939026
step: 280, loss: 0.04853110387921333
step: 290, loss: 0.06499595195055008
step: 300, loss: 0.018813835456967354
step: 310, loss: 0.006954841781407595
step: 320, loss: 0.03190654516220093
step: 330, loss: 0.024465195834636688
step: 340, loss: 0.04429434612393379
step: 350, loss: 0.08157538622617722
step: 360, loss: 0.2440200001001358
step: 370, loss: 0.008176296949386597
step: 380, loss: 0.015349011868238449
epoch 5: dev_f1=0.7244094488188976, f1=0.5444126074498566, best_f1=0.5531914893617021
step: 0, loss: 0.011576732620596886
step: 10, loss: 0.1597224324941635
step: 20, loss: 0.0053420946933329105
step: 30, loss: 0.0075699640437960625
step: 40, loss: 0.01454413216561079
step: 50, loss: 0.0065430812537670135
step: 60, loss: 0.09199227392673492
step: 70, loss: 0.11478117108345032
step: 80, loss: 0.004703042097389698
step: 90, loss: 0.06670450419187546
step: 100, loss: 0.03083016723394394
step: 110, loss: 0.030180862173438072
step: 120, loss: 0.022346515208482742
step: 130, loss: 0.011369045823812485
step: 140, loss: 0.05415734276175499
step: 150, loss: 0.005923132877796888
step: 160, loss: 0.0004570901801344007
step: 170, loss: 0.018906885758042336
step: 180, loss: 0.013843750581145287
step: 190, loss: 0.08887555450201035
step: 200, loss: 0.01470691617578268
step: 210, loss: 0.07398863136768341
step: 220, loss: 0.025367068126797676
step: 230, loss: 0.10262896120548248
step: 240, loss: 0.011434409767389297
step: 250, loss: 0.05359968543052673
step: 260, loss: 0.1316799372434616
step: 270, loss: 0.006111289374530315
step: 280, loss: 0.04636351764202118
step: 290, loss: 0.1089974120259285
step: 300, loss: 0.008752771653234959
step: 310, loss: 0.013375837355852127
step: 320, loss: 0.005314428359270096
step: 330, loss: 0.06874610483646393
step: 340, loss: 0.019700245931744576
step: 350, loss: 0.0021993061527609825
step: 360, loss: 0.014836405403912067
step: 370, loss: 0.025804396718740463
step: 380, loss: 0.0012252669548615813
epoch 6: dev_f1=0.7124010554089709, f1=0.6045197740112994, best_f1=0.5531914893617021
step: 0, loss: 0.09274023771286011
step: 10, loss: 0.07350358366966248
step: 20, loss: 0.0037536374293267727
step: 30, loss: 0.045290619134902954
step: 40, loss: 0.0014012299943715334
step: 50, loss: 0.0043902224861085415
step: 60, loss: 0.002533435123041272
step: 70, loss: 0.021837208420038223
step: 80, loss: 0.06412208080291748
step: 90, loss: 0.10762310773134232
step: 100, loss: 0.015086128376424313
step: 110, loss: 0.014878908172249794
step: 120, loss: 0.3528410792350769
step: 130, loss: 0.018015841022133827
step: 140, loss: 0.03703327849507332
step: 150, loss: 0.049917157739400864
step: 160, loss: 0.199093759059906
step: 170, loss: 0.002000074367970228
step: 180, loss: 0.02351529709994793
step: 190, loss: 0.008907172828912735
step: 200, loss: 0.03480249643325806
step: 210, loss: 0.05728781595826149
step: 220, loss: 0.05296303331851959
step: 230, loss: 0.0091744065284729
step: 240, loss: 0.0031848985236138105
step: 250, loss: 0.07192970812320709
step: 260, loss: 0.019573954865336418
step: 270, loss: 0.04864407703280449
step: 280, loss: 0.0024711182340979576
step: 290, loss: 0.018769197165966034
step: 300, loss: 0.0020811681170016527
step: 310, loss: 0.01941293105483055
step: 320, loss: 0.0524672269821167
step: 330, loss: 0.017429877072572708
step: 340, loss: 0.01374106202274561
step: 350, loss: 0.0007805589702911675
step: 360, loss: 0.01361605804413557
step: 370, loss: 0.009977064095437527
step: 380, loss: 0.006370137445628643
epoch 7: dev_f1=0.68, f1=0.5379746835443038, best_f1=0.5531914893617021
step: 0, loss: 0.0037618186324834824
step: 10, loss: 0.02518392913043499
step: 20, loss: 0.009841064922511578
step: 30, loss: 0.0034491191618144512
step: 40, loss: 0.0015172619605436921
step: 50, loss: 0.0029801016207784414
step: 60, loss: 0.0017632665112614632
step: 70, loss: 0.0023566577583551407
step: 80, loss: 0.004789533093571663
step: 90, loss: 0.0007726866751909256
step: 100, loss: 0.0015416902024298906
step: 110, loss: 0.0015880030114203691
step: 120, loss: 0.007785250898450613
step: 130, loss: 0.0031818498391658068
step: 140, loss: 0.020219266414642334
step: 150, loss: 0.002221972681581974
step: 160, loss: 0.0013540963409468532
step: 170, loss: 0.002261563204228878
step: 180, loss: 0.00090256636030972
step: 190, loss: 0.029708154499530792
step: 200, loss: 0.08437836915254593
step: 210, loss: 0.002688640495762229
step: 220, loss: 0.002451157895848155
step: 230, loss: 0.0010505558457225561
step: 240, loss: 0.016554879024624825
step: 250, loss: 0.0010848704259842634
step: 260, loss: 0.006739489268511534
step: 270, loss: 0.0008796602487564087
step: 280, loss: 0.002298269420862198
step: 290, loss: 0.12189588695764542
step: 300, loss: 0.005466810893267393
step: 310, loss: 0.07658512145280838
step: 320, loss: 0.000563836598303169
step: 330, loss: 0.001305287703871727
step: 340, loss: 0.005410338751971722
step: 350, loss: 0.005040076095610857
step: 360, loss: 0.0020098683889955282
step: 370, loss: 0.003067527199164033
step: 380, loss: 0.0029999769758433104
epoch 8: dev_f1=0.7277108433734939, f1=0.61340206185567, best_f1=0.5531914893617021
step: 0, loss: 0.001609164522960782
step: 10, loss: 0.0052108922973275185
step: 20, loss: 0.0006187644321471453
step: 30, loss: 0.011706916615366936
step: 40, loss: 0.005714631173759699
step: 50, loss: 0.022596925497055054
step: 60, loss: 0.08940327912569046
step: 70, loss: 0.0005460366955958307
step: 80, loss: 0.0691785141825676
step: 90, loss: 0.001219278434291482
step: 100, loss: 0.003178773447871208
step: 110, loss: 0.004530140198767185
step: 120, loss: 0.0023276591673493385
step: 130, loss: 0.0006802034331485629
step: 140, loss: 0.005340613424777985
step: 150, loss: 0.005880261771380901
step: 160, loss: 0.021719444543123245
step: 170, loss: 0.000644627318251878
step: 180, loss: 0.0035686951596289873
step: 190, loss: 0.09745427966117859
step: 200, loss: 0.04977297782897949
step: 210, loss: 0.11283715814352036
step: 220, loss: 0.003720278386026621
step: 230, loss: 0.009568791836500168
step: 240, loss: 0.005568161606788635
step: 250, loss: 0.002061509760096669
step: 260, loss: 0.027666151523590088
step: 270, loss: 0.006981088314205408
step: 280, loss: 0.01184871420264244
step: 290, loss: 0.06406888365745544
step: 300, loss: 0.001353824744001031
step: 310, loss: 0.0005267246742732823
step: 320, loss: 0.02699747495353222
step: 330, loss: 0.05665126442909241
step: 340, loss: 0.00395839661359787
step: 350, loss: 0.0016905018128454685
step: 360, loss: 0.0007742438465356827
step: 370, loss: 0.00040110634290613234
step: 380, loss: 0.0006354973302222788
epoch 9: dev_f1=0.7500000000000001, f1=0.5941176470588235, best_f1=0.5941176470588235
step: 0, loss: 0.0004405436629895121
step: 10, loss: 0.000270259624812752
step: 20, loss: 0.02612697146832943
step: 30, loss: 0.1439719945192337
step: 40, loss: 0.07612020522356033
step: 50, loss: 0.001329347025603056
step: 60, loss: 0.041544508188962936
step: 70, loss: 0.0007374960114248097
step: 80, loss: 7.01876197126694e-05
step: 90, loss: 0.001641129027120769
step: 100, loss: 0.053538449108600616
step: 110, loss: 0.0034476537257432938
step: 120, loss: 0.00018519896548241377
step: 130, loss: 0.0009808328468352556
step: 140, loss: 0.005214265082031488
step: 150, loss: 0.00834605097770691
step: 160, loss: 0.003910573199391365
step: 170, loss: 0.0031380970031023026
step: 180, loss: 0.09341197460889816
step: 190, loss: 0.09519577026367188
step: 200, loss: 0.010619745589792728
step: 210, loss: 0.0008586335461586714
step: 220, loss: 0.0005956111126579344
step: 230, loss: 0.006274230312556028
step: 240, loss: 0.0010029432596638799
step: 250, loss: 0.09892722964286804
step: 260, loss: 0.12651598453521729
step: 270, loss: 0.00046370140626095235
step: 280, loss: 0.000951792171690613
step: 290, loss: 0.007371914107352495
step: 300, loss: 0.0012736107455566525
step: 310, loss: 0.0019029087852686644
step: 320, loss: 0.0003477733989711851
step: 330, loss: 0.00029091144097037613
step: 340, loss: 0.0010155367199331522
step: 350, loss: 0.0011529760668054223
step: 360, loss: 0.000624452717602253
step: 370, loss: 0.0008041172986850142
step: 380, loss: 0.00045609709923155606
epoch 10: dev_f1=0.721763085399449, f1=0.5349544072948329, best_f1=0.5941176470588235
step: 0, loss: 0.0015330507885664701
step: 10, loss: 0.001311030238866806
step: 20, loss: 0.0020966092124581337
step: 30, loss: 0.01563071459531784
step: 40, loss: 0.006678170058876276
step: 50, loss: 0.0010105276014655828
step: 60, loss: 0.0009741930407471955
step: 70, loss: 0.025613954290747643
step: 80, loss: 0.001406034454703331
step: 90, loss: 0.000389074586564675
step: 100, loss: 0.004553820937871933
step: 110, loss: 0.004711727611720562
step: 120, loss: 0.0045544966123998165
step: 130, loss: 0.0007911379798315465
step: 140, loss: 0.0021858091931790113
step: 150, loss: 0.00847632810473442
step: 160, loss: 0.0736222192645073
step: 170, loss: 0.002737912116572261
step: 180, loss: 0.000348047906300053
step: 190, loss: 0.0017357628094032407
step: 200, loss: 0.0022126936819404364
step: 210, loss: 0.0002659203310031444
step: 220, loss: 0.0003129867254756391
step: 230, loss: 0.00039069433114491403
step: 240, loss: 0.0009704565163701773
step: 250, loss: 0.11484487354755402
step: 260, loss: 0.0003942931070923805
step: 270, loss: 0.01483654510229826
step: 280, loss: 0.0020657896529883146
step: 290, loss: 0.0004094239848200232
step: 300, loss: 0.0008505923324264586
step: 310, loss: 0.0004317332641221583
step: 320, loss: 0.001354841748252511
step: 330, loss: 0.00033587930374778807
step: 340, loss: 0.02014986425638199
step: 350, loss: 0.017659850418567657
step: 360, loss: 0.06755879521369934
step: 370, loss: 0.011457446031272411
step: 380, loss: 0.0012522959150373936
epoch 11: dev_f1=0.7253333333333334, f1=0.5853658536585366, best_f1=0.5941176470588235
step: 0, loss: 0.0027110425289720297
step: 10, loss: 0.01997847482562065
step: 20, loss: 0.02431788668036461
step: 30, loss: 0.0011402369709685445
step: 40, loss: 0.00015952897956594825
step: 50, loss: 0.000603992841206491
step: 60, loss: 0.012747019529342651
step: 70, loss: 0.0003937999135814607
step: 80, loss: 0.0031901493202894926
step: 90, loss: 0.0003873660461977124
step: 100, loss: 0.005921894684433937
step: 110, loss: 0.0026450413279235363
step: 120, loss: 0.017359336838126183
step: 130, loss: 0.0002640453167259693
step: 140, loss: 0.002674415474757552
step: 150, loss: 0.0021975161507725716
step: 160, loss: 0.001251404290087521
step: 170, loss: 0.004285005386918783
step: 180, loss: 0.13847370445728302
step: 190, loss: 0.0005203165346756577
step: 200, loss: 0.020243801176548004
step: 210, loss: 0.0016401360044255853
step: 220, loss: 0.0007574451738037169
step: 230, loss: 0.01894233003258705
step: 240, loss: 0.0008312586578540504
step: 250, loss: 0.0024464307352900505
step: 260, loss: 0.00021016204846091568
step: 270, loss: 0.0017551881028339267
step: 280, loss: 0.011033722199499607
step: 290, loss: 0.0040816208347678185
step: 300, loss: 0.0026322761550545692
step: 310, loss: 0.001925794524140656
step: 320, loss: 0.0031435657292604446
step: 330, loss: 0.0015434394590556622
step: 340, loss: 0.0006121335900388658
step: 350, loss: 0.0006872651865705848
step: 360, loss: 0.0013488172553479671
step: 370, loss: 0.0012852249201387167
step: 380, loss: 0.006069493014365435
epoch 12: dev_f1=0.716577540106952, f1=0.5714285714285714, best_f1=0.5941176470588235
step: 0, loss: 0.002231951802968979
step: 10, loss: 0.004140036646276712
step: 20, loss: 0.010064873844385147
step: 30, loss: 0.0007735923281870782
step: 40, loss: 0.0011426931014284492
step: 50, loss: 0.01199021190404892
step: 60, loss: 0.00038432786823250353
step: 70, loss: 0.0005540468264371157
step: 80, loss: 0.0002726213715504855
step: 90, loss: 0.0003422628215048462
step: 100, loss: 0.030788492411375046
step: 110, loss: 0.01843302696943283
step: 120, loss: 0.004658046644181013
step: 130, loss: 0.0011174571700394154
step: 140, loss: 0.00011325659579597414
step: 150, loss: 0.016802966594696045
step: 160, loss: 0.001621211296878755
step: 170, loss: 0.00014535228547174484
step: 180, loss: 0.0002759876661002636
step: 190, loss: 0.004433267284184694
step: 200, loss: 0.0002823413524311036
step: 210, loss: 0.0011687075020745397
step: 220, loss: 0.00018769850430544466
step: 230, loss: 0.008446051739156246
step: 240, loss: 0.029799310490489006
step: 250, loss: 0.0001231776550412178
step: 260, loss: 0.0002922528947237879
step: 270, loss: 0.00018929863290395588
step: 280, loss: 0.0006209636921994388
step: 290, loss: 0.0005078544490970671
step: 300, loss: 8.470802276860923e-05
step: 310, loss: 0.0002125618775608018
step: 320, loss: 0.0006369289476424456
step: 330, loss: 0.00022481179621536285
step: 340, loss: 0.000633112620562315
step: 350, loss: 0.00024019135162234306
step: 360, loss: 0.0006846524775028229
step: 370, loss: 0.000775159103795886
step: 380, loss: 0.0005371037987060845
epoch 13: dev_f1=0.6875, f1=0.5565749235474006, best_f1=0.5941176470588235
step: 0, loss: 0.0004556130152195692
step: 10, loss: 0.0001651772909099236
step: 20, loss: 0.0071920664049685
step: 30, loss: 0.00016332998347934335
step: 40, loss: 0.0002662529004737735
step: 50, loss: 0.00010179867240367457
step: 60, loss: 0.0005014194757677615
step: 70, loss: 0.00041510240407660604
step: 80, loss: 0.0001691360812401399
step: 90, loss: 6.49589637760073e-05
step: 100, loss: 0.0012126259971410036
step: 110, loss: 0.001256063929758966
step: 120, loss: 0.0003095012507401407
step: 130, loss: 0.001376379863359034
step: 140, loss: 0.0004625232832040638
step: 150, loss: 0.00018703292880672961
step: 160, loss: 0.0004929958377033472
step: 170, loss: 0.0024376551155000925
step: 180, loss: 0.002513106446713209
step: 190, loss: 0.004280741326510906
step: 200, loss: 0.00011638653086265549
step: 210, loss: 0.0007333873072639108
step: 220, loss: 0.0019686054438352585
step: 230, loss: 0.00016196738579310477
step: 240, loss: 0.00011061788245569915
step: 250, loss: 0.00016758247511461377
step: 260, loss: 0.007830256596207619
step: 270, loss: 0.004750573076307774
step: 280, loss: 0.0002274176076753065
step: 290, loss: 0.0004159223462920636
step: 300, loss: 0.0008429295849055052
step: 310, loss: 8.00653942860663e-05
step: 320, loss: 0.00012706461711786687
step: 330, loss: 0.00026240048464387655
step: 340, loss: 0.00045319448690861464
step: 350, loss: 8.111711213132367e-05
step: 360, loss: 0.0007858527824282646
step: 370, loss: 0.00036171049578115344
step: 380, loss: 0.005741477943956852
epoch 14: dev_f1=0.722077922077922, f1=0.5950413223140496, best_f1=0.5941176470588235
step: 0, loss: 0.00020532161579467356
step: 10, loss: 9.963291813619435e-05
step: 20, loss: 0.00011189324868610129
step: 30, loss: 0.0001590707979630679
step: 40, loss: 0.0011208211071789265
step: 50, loss: 0.00012936665734741837
step: 60, loss: 0.000142108227009885
step: 70, loss: 0.00014362813089974225
step: 80, loss: 0.0005260062171146274
step: 90, loss: 0.004044978879392147
step: 100, loss: 0.00013770576333627105
step: 110, loss: 0.00045498699182644486
step: 120, loss: 0.0010493213776499033
step: 130, loss: 8.720064943190664e-05
step: 140, loss: 0.00010847767407540232
step: 150, loss: 0.000110352695628535
step: 160, loss: 0.00020406072144396603
step: 170, loss: 0.0036134268157184124
step: 180, loss: 0.029122857376933098
step: 190, loss: 0.00018938191351480782
step: 200, loss: 0.0003432862285990268
step: 210, loss: 0.00017446967831347138
step: 220, loss: 0.0001059763235389255
step: 230, loss: 7.98600958660245e-05
step: 240, loss: 0.06791166961193085
step: 250, loss: 0.0015434690285474062
step: 260, loss: 0.00026283037732355297
step: 270, loss: 0.0005763791268691421
step: 280, loss: 0.00033797213109210134
step: 290, loss: 0.0013790465891361237
step: 300, loss: 0.00019194358901586384
step: 310, loss: 0.002608025213703513
step: 320, loss: 0.012777636758983135
step: 330, loss: 0.002090881811454892
step: 340, loss: 8.259563037427142e-05
step: 350, loss: 0.0001513749302830547
step: 360, loss: 0.00024945338373072445
step: 370, loss: 0.009273468516767025
step: 380, loss: 0.0003354724030941725
epoch 15: dev_f1=0.7286821705426356, f1=0.5932203389830509, best_f1=0.5941176470588235
step: 0, loss: 0.0005993668455630541
step: 10, loss: 8.79809886100702e-05
step: 20, loss: 0.004948995541781187
step: 30, loss: 0.002373415045440197
step: 40, loss: 0.00011155912216054276
step: 50, loss: 0.0003590477863326669
step: 60, loss: 0.050285469740629196
step: 70, loss: 4.732681190944277e-05
step: 80, loss: 0.0012163398787379265
step: 90, loss: 0.0003181779757142067
step: 100, loss: 4.39543800894171e-05
step: 110, loss: 0.00027463992591947317
step: 120, loss: 0.0002888062736019492
step: 130, loss: 2.3670019800192676e-05
step: 140, loss: 0.005179412197321653
step: 150, loss: 0.0024544172920286655
step: 160, loss: 0.005014551803469658
step: 170, loss: 0.0002445698482915759
step: 180, loss: 3.9578684663865715e-05
step: 190, loss: 7.612595800310373e-05
step: 200, loss: 5.532745490199886e-05
step: 210, loss: 4.259183333488181e-05
step: 220, loss: 0.000330540060531348
step: 230, loss: 0.0002476602385286242
step: 240, loss: 0.0011741139460355043
step: 250, loss: 3.340654802741483e-05
step: 260, loss: 0.00023198292183224112
step: 270, loss: 0.00028491346165537834
step: 280, loss: 3.833757364191115e-05
step: 290, loss: 0.023111475631594658
step: 300, loss: 0.00012324539420660585
step: 310, loss: 8.582803275203332e-05
step: 320, loss: 0.0020030001178383827
step: 330, loss: 0.00013724721793550998
step: 340, loss: 0.00015332212205976248
step: 350, loss: 2.7275986212771386e-05
step: 360, loss: 0.06474699825048447
step: 370, loss: 0.000231402154895477
step: 380, loss: 4.6704630221938714e-05
epoch 16: dev_f1=0.7234042553191489, f1=0.5590778097982709, best_f1=0.5941176470588235
step: 0, loss: 4.3211239244556054e-05
step: 10, loss: 0.002016801619902253
step: 20, loss: 2.7577412765822373e-05
step: 30, loss: 0.00011136520333820954
step: 40, loss: 3.284867125330493e-05
step: 50, loss: 0.002307519083842635
step: 60, loss: 0.0001373335107928142
step: 70, loss: 5.7156619732268155e-05
step: 80, loss: 4.548793367575854e-05
step: 90, loss: 0.00026126820011995733
step: 100, loss: 0.00013436941662803292
step: 110, loss: 8.264181087724864e-05
step: 120, loss: 5.546922693611123e-05
step: 130, loss: 0.0003503371262922883
step: 140, loss: 0.0007349040824919939
step: 150, loss: 0.000907584500964731
step: 160, loss: 3.194718374288641e-05
step: 170, loss: 0.001371981343254447
step: 180, loss: 9.365608275402337e-05
step: 190, loss: 0.05099247768521309
step: 200, loss: 5.215413330006413e-05
step: 210, loss: 6.958284939173609e-05
step: 220, loss: 0.0023871564771980047
step: 230, loss: 8.462009282084182e-05
step: 240, loss: 0.014098089188337326
step: 250, loss: 6.788477912778035e-05
step: 260, loss: 0.008239920251071453
step: 270, loss: 5.044338831794448e-05
step: 280, loss: 0.00023414468159899116
step: 290, loss: 0.0017036126228049397
step: 300, loss: 0.0008734302828088403
step: 310, loss: 0.0009319807286374271
step: 320, loss: 0.0006186988903209567
step: 330, loss: 8.10446435934864e-05
step: 340, loss: 0.0001946336415130645
step: 350, loss: 4.82858631585259e-05
step: 360, loss: 0.00010740772995632142
step: 370, loss: 0.0002081568818539381
step: 380, loss: 0.0003703115216922015
epoch 17: dev_f1=0.7277628032345013, f1=0.5787965616045845, best_f1=0.5941176470588235
step: 0, loss: 0.0007027420215308666
step: 10, loss: 0.0015594647265970707
step: 20, loss: 0.00021048194321338087
step: 30, loss: 0.00010695532546378672
step: 40, loss: 8.280961628770456e-05
step: 50, loss: 6.756506627425551e-05
step: 60, loss: 0.0003940551250707358
step: 70, loss: 0.0037197847850620747
step: 80, loss: 0.0001921278890222311
step: 90, loss: 0.00037772575160488486
step: 100, loss: 6.56748961773701e-05
step: 110, loss: 0.0006792604108341038
step: 120, loss: 0.000886909372638911
step: 130, loss: 5.573234739131294e-05
step: 140, loss: 7.211967749753967e-05
step: 150, loss: 7.25644058547914e-05
step: 160, loss: 9.094981214730069e-05
step: 170, loss: 0.00022085674572736025
step: 180, loss: 0.0029930954333394766
step: 190, loss: 6.980750913498923e-05
step: 200, loss: 0.0009153641876764596
step: 210, loss: 2.9282698960741982e-05
step: 220, loss: 0.0017040625680238008
step: 230, loss: 9.76796291070059e-05
step: 240, loss: 0.0149996941909194
step: 250, loss: 2.615825542306993e-05
step: 260, loss: 0.002350372727960348
step: 270, loss: 9.376532398164272e-05
step: 280, loss: 0.0003558305907063186
step: 290, loss: 0.001024790690280497
step: 300, loss: 0.0012540461029857397
step: 310, loss: 0.0019788697827607393
step: 320, loss: 0.00010321229638066143
step: 330, loss: 0.0016577703645452857
step: 340, loss: 0.017222829163074493
step: 350, loss: 0.0004964212421327829
step: 360, loss: 0.0010314201936125755
step: 370, loss: 3.6456134694162756e-05
step: 380, loss: 0.024755096063017845
epoch 18: dev_f1=0.736842105263158, f1=0.591549295774648, best_f1=0.5941176470588235
step: 0, loss: 3.0221461202017963e-05
step: 10, loss: 9.76540322881192e-05
step: 20, loss: 0.00015098157746251673
step: 30, loss: 7.166089199017733e-05
step: 40, loss: 6.478635623352602e-05
step: 50, loss: 0.00019044311193283647
step: 60, loss: 0.00037828751374036074
step: 70, loss: 7.392601401079446e-05
step: 80, loss: 0.0007977751665748656
step: 90, loss: 6.306581053650007e-05
step: 100, loss: 0.0010801220778375864
step: 110, loss: 7.397925946861506e-05
step: 120, loss: 2.808013596222736e-05
step: 130, loss: 5.1148294005542994e-05
step: 140, loss: 0.003367534140124917
step: 150, loss: 4.12213739764411e-05
step: 160, loss: 0.0003493331023491919
step: 170, loss: 4.351118695922196e-05
step: 180, loss: 7.479680789401755e-05
step: 190, loss: 7.42963093216531e-05
step: 200, loss: 6.086446956032887e-05
step: 210, loss: 0.0002553855301812291
step: 220, loss: 6.0540092817973346e-05
step: 230, loss: 0.0003256961063016206
step: 240, loss: 2.735386988206301e-05
step: 250, loss: 2.5997838747571222e-05
step: 260, loss: 0.00017275607388000935
step: 270, loss: 0.0009388083126395941
step: 280, loss: 0.0004425295046530664
step: 290, loss: 0.0007036852766759694
step: 300, loss: 0.00023410031280945987
step: 310, loss: 0.00017116819799412042
step: 320, loss: 9.690028673503548e-05
step: 330, loss: 0.00014492101036012173
step: 340, loss: 3.3130701922345906e-05
step: 350, loss: 1.7683694750303403e-05
step: 360, loss: 4.952091330778785e-05
step: 370, loss: 0.0002558226988185197
step: 380, loss: 0.0003758545499294996
epoch 19: dev_f1=0.736842105263158, f1=0.5842696629213484, best_f1=0.5941176470588235
step: 0, loss: 0.00012385411537252367
step: 10, loss: 0.005160101689398289
step: 20, loss: 0.1201641857624054
step: 30, loss: 0.0002477162051945925
step: 40, loss: 0.0002692766720429063
step: 50, loss: 0.00027563798357732594
step: 60, loss: 0.00014623664901591837
step: 70, loss: 0.0006836569518782198
step: 80, loss: 3.6472349165705964e-05
step: 90, loss: 0.000141423792229034
step: 100, loss: 0.00015687313862144947
step: 110, loss: 9.611529821995646e-05
step: 120, loss: 0.00014171248767524958
step: 130, loss: 0.0013306248001754284
step: 140, loss: 0.0006207537371665239
step: 150, loss: 0.00028494896832853556
step: 160, loss: 0.007106895558536053
step: 170, loss: 9.534673881717026e-05
step: 180, loss: 0.00013866345398128033
step: 190, loss: 4.234378502587788e-05
step: 200, loss: 9.74334980128333e-05
step: 210, loss: 7.283407467184588e-05
step: 220, loss: 4.4088134018238634e-05
step: 230, loss: 0.0008530946797691286
step: 240, loss: 0.00011634931433945894
step: 250, loss: 0.00019761986914090812
step: 260, loss: 0.0001737403217703104
step: 270, loss: 0.0009136234293691814
step: 280, loss: 0.005988412536680698
step: 290, loss: 0.00011686037032632157
step: 300, loss: 5.113686347613111e-05
step: 310, loss: 0.00012294536281842738
step: 320, loss: 6.809599290136248e-05
step: 330, loss: 0.00024289474822580814
step: 340, loss: 0.0006968884263187647
step: 350, loss: 0.005930782295763493
step: 360, loss: 0.0002462250122334808
step: 370, loss: 0.00016103344387374818
step: 380, loss: 0.0003463544126134366
epoch 20: dev_f1=0.736842105263158, f1=0.576271186440678, best_f1=0.5941176470588235
