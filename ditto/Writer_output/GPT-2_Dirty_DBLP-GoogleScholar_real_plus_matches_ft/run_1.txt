cuda
Device: cuda
step: 0, loss: 0.6838337779045105
step: 10, loss: 0.6978874206542969
step: 20, loss: 0.5441272258758545
step: 30, loss: 0.6516948342323303
step: 40, loss: 0.49850520491600037
step: 50, loss: 0.4755583703517914
step: 60, loss: 0.3125387728214264
step: 70, loss: 0.1592467576265335
step: 80, loss: 0.43066707253456116
step: 90, loss: 0.2543756067752838
step: 100, loss: 0.41321539878845215
step: 110, loss: 0.3423280715942383
step: 120, loss: 0.3656434714794159
step: 130, loss: 0.31822535395622253
step: 140, loss: 0.145608052611351
step: 150, loss: 0.4141979217529297
step: 160, loss: 0.20019927620887756
step: 170, loss: 0.3831949532032013
step: 180, loss: 0.23375581204891205
step: 190, loss: 0.15000128746032715
step: 200, loss: 0.23715339601039886
step: 210, loss: 0.13883008062839508
step: 220, loss: 0.22087149322032928
step: 230, loss: 0.23422235250473022
step: 240, loss: 0.16164958477020264
step: 250, loss: 0.1743144392967224
step: 260, loss: 0.1692720353603363
step: 270, loss: 0.24103660881519318
step: 280, loss: 0.2894385755062103
step: 290, loss: 0.07868406921625137
step: 300, loss: 0.1426200121641159
step: 310, loss: 0.200218066573143
step: 320, loss: 0.17724616825580597
step: 330, loss: 0.06729613244533539
step: 340, loss: 0.0719379335641861
step: 350, loss: 0.08160821348428726
step: 360, loss: 0.025219794362783432
step: 370, loss: 0.18493273854255676
step: 380, loss: 0.02035306580364704
step: 390, loss: 0.2603897154331207
step: 400, loss: 0.13869839906692505
step: 410, loss: 0.21294625103473663
step: 420, loss: 0.032117631286382675
step: 430, loss: 0.07730226963758469
step: 440, loss: 0.02940693311393261
step: 450, loss: 0.23950469493865967
step: 460, loss: 0.05172253027558327
step: 470, loss: 0.1699323207139969
step: 480, loss: 0.04418354481458664
step: 490, loss: 0.21605217456817627
step: 500, loss: 0.2161151021718979
step: 510, loss: 0.09257013350725174
step: 520, loss: 0.15179288387298584
step: 530, loss: 0.02073429338634014
step: 540, loss: 0.19271942973136902
step: 550, loss: 0.02817533165216446
step: 560, loss: 0.12681911885738373
step: 570, loss: 0.3191494941711426
step: 580, loss: 0.06076086312532425
step: 590, loss: 0.06197100505232811
step: 600, loss: 0.15561527013778687
step: 610, loss: 0.18686655163764954
step: 620, loss: 0.05481310933828354
step: 630, loss: 0.1603177785873413
epoch 1: dev_f1=0.9309556470050298, f1=0.9388127853881278, best_f1=0.9388127853881278
step: 0, loss: 0.03557296842336655
step: 10, loss: 0.2113569974899292
step: 20, loss: 0.056993529200553894
step: 30, loss: 0.16281850636005402
step: 40, loss: 0.1413639485836029
step: 50, loss: 0.31895703077316284
step: 60, loss: 0.08606839179992676
step: 70, loss: 0.02050969749689102
step: 80, loss: 0.009883797727525234
step: 90, loss: 0.2243104726076126
step: 100, loss: 0.012376380153000355
step: 110, loss: 0.10287584364414215
step: 120, loss: 0.016862420365214348
step: 130, loss: 0.055905528366565704
step: 140, loss: 0.1037662997841835
step: 150, loss: 0.04870976507663727
step: 160, loss: 0.01945403777062893
step: 170, loss: 0.03824213892221451
step: 180, loss: 0.033735308796167374
step: 190, loss: 0.09232168644666672
step: 200, loss: 0.01632308028638363
step: 210, loss: 0.06210389733314514
step: 220, loss: 0.039141945540905
step: 230, loss: 0.024461066350340843
step: 240, loss: 0.05890483036637306
step: 250, loss: 0.009058302268385887
step: 260, loss: 0.08854764699935913
step: 270, loss: 0.07342933863401413
step: 280, loss: 0.12718871235847473
step: 290, loss: 0.03969411179423332
step: 300, loss: 0.1362275630235672
step: 310, loss: 0.023230426013469696
step: 320, loss: 0.23364169895648956
step: 330, loss: 0.015272807329893112
step: 340, loss: 0.13767234981060028
step: 350, loss: 0.016437875106930733
step: 360, loss: 0.026272766292095184
step: 370, loss: 0.1044086217880249
step: 380, loss: 0.011074716225266457
step: 390, loss: 0.1777462363243103
step: 400, loss: 0.17744089663028717
step: 410, loss: 0.09124002605676651
step: 420, loss: 0.10205826908349991
step: 430, loss: 0.0598822757601738
step: 440, loss: 0.019990216940641403
step: 450, loss: 0.07062181830406189
step: 460, loss: 0.006659697275608778
step: 470, loss: 0.01920287124812603
step: 480, loss: 0.16122347116470337
step: 490, loss: 0.27214285731315613
step: 500, loss: 0.15043044090270996
step: 510, loss: 0.026222867891192436
step: 520, loss: 0.05250639468431473
step: 530, loss: 0.07783427834510803
step: 540, loss: 0.012887634336948395
step: 550, loss: 0.2043089121580124
step: 560, loss: 0.036723364144563675
step: 570, loss: 0.014047832228243351
step: 580, loss: 0.027434824034571648
step: 590, loss: 0.04611596837639809
step: 600, loss: 0.1493869572877884
step: 610, loss: 0.05501704663038254
step: 620, loss: 0.031650327146053314
step: 630, loss: 0.07719104737043381
epoch 2: dev_f1=0.9455560725919032, f1=0.9484440315838365, best_f1=0.9484440315838365
step: 0, loss: 0.027285972610116005
step: 10, loss: 0.06742224842309952
step: 20, loss: 0.008945774286985397
step: 30, loss: 0.003817671677097678
step: 40, loss: 0.010728607885539532
step: 50, loss: 0.06395146250724792
step: 60, loss: 0.017954953014850616
step: 70, loss: 0.02518898993730545
step: 80, loss: 0.009448097087442875
step: 90, loss: 0.07236717641353607
step: 100, loss: 0.015060355886816978
step: 110, loss: 0.08822428435087204
step: 120, loss: 0.03546063229441643
step: 130, loss: 0.016470668837428093
step: 140, loss: 0.04352375864982605
step: 150, loss: 0.014998747035861015
step: 160, loss: 0.02717573568224907
step: 170, loss: 0.009519959799945354
step: 180, loss: 0.007036188617348671
step: 190, loss: 0.09721159189939499
step: 200, loss: 0.04409652203321457
step: 210, loss: 0.15081234276294708
step: 220, loss: 0.01215117983520031
step: 230, loss: 0.003277624724432826
step: 240, loss: 0.02616221271455288
step: 250, loss: 0.009632852859795094
step: 260, loss: 0.02079453505575657
step: 270, loss: 0.16203360259532928
step: 280, loss: 0.0260019488632679
step: 290, loss: 0.01610076241195202
step: 300, loss: 0.08505493402481079
step: 310, loss: 0.048415519297122955
step: 320, loss: 0.01799280010163784
step: 330, loss: 0.03383782505989075
step: 340, loss: 0.025404267013072968
step: 350, loss: 0.008579319342970848
step: 360, loss: 0.018197031691670418
step: 370, loss: 0.09095992892980576
step: 380, loss: 0.05004848539829254
step: 390, loss: 0.07918015122413635
step: 400, loss: 0.023515433073043823
step: 410, loss: 0.017481569200754166
step: 420, loss: 0.03349800035357475
step: 430, loss: 0.014405504800379276
step: 440, loss: 0.02053702250123024
step: 450, loss: 0.052300844341516495
step: 460, loss: 0.13778075575828552
step: 470, loss: 0.023335857316851616
step: 480, loss: 0.10389648377895355
step: 490, loss: 0.09223712235689163
step: 500, loss: 0.1873084008693695
step: 510, loss: 0.06253132969141006
step: 520, loss: 0.14867791533470154
step: 530, loss: 0.06902774423360825
step: 540, loss: 0.022417783737182617
step: 550, loss: 0.2715882956981659
step: 560, loss: 0.013277832418680191
step: 570, loss: 0.02297896146774292
step: 580, loss: 0.07984450459480286
step: 590, loss: 0.024916276335716248
step: 600, loss: 0.005629921332001686
step: 610, loss: 0.005260120145976543
step: 620, loss: 0.0795229971408844
step: 630, loss: 0.021960360929369926
epoch 3: dev_f1=0.9491682070240297, f1=0.9455216989843028, best_f1=0.9455216989843028
step: 0, loss: 0.04236244410276413
step: 10, loss: 0.045603882521390915
step: 20, loss: 0.013301784172654152
step: 30, loss: 0.01010845322161913
step: 40, loss: 0.05474739149212837
step: 50, loss: 0.06336065381765366
step: 60, loss: 0.1613648682832718
step: 70, loss: 0.011371124535799026
step: 80, loss: 0.011569633148610592
step: 90, loss: 0.022844528779387474
step: 100, loss: 0.014248072169721127
step: 110, loss: 0.014202192425727844
step: 120, loss: 0.014253171160817146
step: 130, loss: 0.009961824864149094
step: 140, loss: 0.0035837008617818356
step: 150, loss: 0.004074496682733297
step: 160, loss: 0.12972025573253632
step: 170, loss: 0.06148447468876839
step: 180, loss: 0.004021257162094116
step: 190, loss: 0.10148224234580994
step: 200, loss: 0.009461585432291031
step: 210, loss: 0.005144013091921806
step: 220, loss: 0.0009163077338598669
step: 230, loss: 0.002756922971457243
step: 240, loss: 0.094937264919281
step: 250, loss: 0.03901239112019539
step: 260, loss: 0.009589589200913906
step: 270, loss: 0.0010368340881541371
step: 280, loss: 0.12162327766418457
step: 290, loss: 0.005195022094994783
step: 300, loss: 0.00048020383110269904
step: 310, loss: 0.10814841836690903
step: 320, loss: 0.008351091295480728
step: 330, loss: 0.005817613564431667
step: 340, loss: 0.003324426943436265
step: 350, loss: 0.04315708205103874
step: 360, loss: 0.054948098957538605
step: 370, loss: 0.010391764342784882
step: 380, loss: 0.19830895960330963
step: 390, loss: 0.013457674533128738
step: 400, loss: 0.09273799508810043
step: 410, loss: 0.060770295560359955
step: 420, loss: 0.03461223468184471
step: 430, loss: 0.009469972923398018
step: 440, loss: 0.010419870726764202
step: 450, loss: 0.015667397528886795
step: 460, loss: 0.003863659920170903
step: 470, loss: 0.004669140558689833
step: 480, loss: 0.0011742380447685719
step: 490, loss: 0.0767984688282013
step: 500, loss: 0.061968084424734116
step: 510, loss: 0.012221756391227245
step: 520, loss: 0.03846701979637146
step: 530, loss: 0.0996442437171936
step: 540, loss: 0.004660030826926231
step: 550, loss: 0.06191185861825943
step: 560, loss: 0.15938562154769897
step: 570, loss: 0.022874342277646065
step: 580, loss: 0.09843474626541138
step: 590, loss: 0.017815468832850456
step: 600, loss: 0.012560173869132996
step: 610, loss: 0.04634713754057884
step: 620, loss: 0.006318130996078253
step: 630, loss: 0.001047506695613265
epoch 4: dev_f1=0.9443929564411491, f1=0.9371482176360225, best_f1=0.9455216989843028
step: 0, loss: 0.00265049422159791
step: 10, loss: 0.004845936316996813
step: 20, loss: 0.0037578989285975695
step: 30, loss: 0.0014149164780974388
step: 40, loss: 0.0029177337419241667
step: 50, loss: 0.026981018483638763
step: 60, loss: 0.06617387384176254
step: 70, loss: 0.004150667693465948
step: 80, loss: 0.022891193628311157
step: 90, loss: 0.06359565258026123
step: 100, loss: 0.008211283944547176
step: 110, loss: 0.02108405902981758
step: 120, loss: 0.011603744700551033
step: 130, loss: 0.0220028143376112
step: 140, loss: 0.0018986506620422006
step: 150, loss: 0.031011639162898064
step: 160, loss: 0.0017153645167127252
step: 170, loss: 0.012297124601900578
step: 180, loss: 0.0013459485489875078
step: 190, loss: 0.017082903534173965
step: 200, loss: 0.00725537771359086
step: 210, loss: 0.0015373151982203126
step: 220, loss: 0.049678873270750046
step: 230, loss: 0.046339377760887146
step: 240, loss: 0.13929538428783417
step: 250, loss: 0.004831645637750626
step: 260, loss: 0.0016678192187100649
step: 270, loss: 0.0009242783999070525
step: 280, loss: 0.04535011947154999
step: 290, loss: 0.0035185329616069794
step: 300, loss: 0.003235061652958393
step: 310, loss: 0.21015381813049316
step: 320, loss: 0.042317017912864685
step: 330, loss: 0.01586959883570671
step: 340, loss: 0.005388166755437851
step: 350, loss: 0.07395678758621216
step: 360, loss: 0.0004709517816081643
step: 370, loss: 0.02571588009595871
step: 380, loss: 0.0013940285425633192
step: 390, loss: 0.06678134948015213
step: 400, loss: 0.0014482372207567096
step: 410, loss: 0.006830211263149977
step: 420, loss: 0.0016284891171380877
step: 430, loss: 0.005818371661007404
step: 440, loss: 0.01777506247162819
step: 450, loss: 0.003281143493950367
step: 460, loss: 0.0027493045199662447
step: 470, loss: 0.01307114027440548
step: 480, loss: 0.024458318948745728
step: 490, loss: 0.0005170046351850033
step: 500, loss: 0.010199986398220062
step: 510, loss: 0.06320510804653168
step: 520, loss: 0.023831231519579887
step: 530, loss: 0.0021921617444604635
step: 540, loss: 0.0006000602152198553
step: 550, loss: 0.004945224151015282
step: 560, loss: 0.018159810453653336
step: 570, loss: 0.024805301800370216
step: 580, loss: 0.0018880380084738135
step: 590, loss: 0.05168137326836586
step: 600, loss: 0.019322870299220085
step: 610, loss: 0.0008193530375137925
step: 620, loss: 0.0016341819427907467
step: 630, loss: 0.003505981992930174
epoch 5: dev_f1=0.9465861588481189, f1=0.9307298930729893, best_f1=0.9455216989843028
step: 0, loss: 0.0008513338398188353
step: 10, loss: 0.029222611337900162
step: 20, loss: 0.02177572250366211
step: 30, loss: 0.010437844321131706
step: 40, loss: 0.003669164841994643
step: 50, loss: 0.0007913400186225772
step: 60, loss: 0.000687671301420778
step: 70, loss: 0.004014178179204464
step: 80, loss: 0.0009408469195477664
step: 90, loss: 0.0026064012199640274
step: 100, loss: 0.0009017076226882637
step: 110, loss: 0.00043626310070976615
step: 120, loss: 0.0030767933931201696
step: 130, loss: 0.04016481339931488
step: 140, loss: 0.0038155843503773212
step: 150, loss: 0.010936384089291096
step: 160, loss: 0.00473785912618041
step: 170, loss: 0.0023620002903044224
step: 180, loss: 0.0002944186271633953
step: 190, loss: 0.0006506051868200302
step: 200, loss: 0.0024166435468941927
step: 210, loss: 0.0016180897364392877
step: 220, loss: 0.07255154103040695
step: 230, loss: 0.000637575110886246
step: 240, loss: 0.02841882035136223
step: 250, loss: 0.038397904485464096
step: 260, loss: 0.0060864840634167194
step: 270, loss: 0.0010115839540958405
step: 280, loss: 0.001156906597316265
step: 290, loss: 0.007989127188920975
step: 300, loss: 0.002480879658833146
step: 310, loss: 0.00025929207913577557
step: 320, loss: 0.0021569388918578625
step: 330, loss: 0.0008769548148848116
step: 340, loss: 0.009376906789839268
step: 350, loss: 0.0007232869975268841
step: 360, loss: 0.001375756342895329
step: 370, loss: 0.001724952831864357
step: 380, loss: 0.0022429947275668383
step: 390, loss: 0.021856188774108887
step: 400, loss: 0.006154866889119148
step: 410, loss: 0.13164393603801727
step: 420, loss: 0.004850374534726143
step: 430, loss: 0.002860795008018613
step: 440, loss: 0.0003735199279617518
step: 450, loss: 0.010958878323435783
step: 460, loss: 0.005434366874396801
step: 470, loss: 0.016331477090716362
step: 480, loss: 0.0046216752380132675
step: 490, loss: 0.002128506312146783
step: 500, loss: 0.009753131307661533
step: 510, loss: 0.02410302869975567
step: 520, loss: 0.0013791205128654838
step: 530, loss: 0.055114831775426865
step: 540, loss: 0.0024514722172170877
step: 550, loss: 0.0017909827874973416
step: 560, loss: 0.0034317225217819214
step: 570, loss: 0.014830647967755795
step: 580, loss: 0.0012302033137530088
step: 590, loss: 0.004810763988643885
step: 600, loss: 0.0024063747841864824
step: 610, loss: 0.002279740758240223
step: 620, loss: 0.0025429255329072475
step: 630, loss: 0.0003196180041413754
epoch 6: dev_f1=0.9467787114845938, f1=0.9369453526389537, best_f1=0.9455216989843028
step: 0, loss: 0.0002928076428361237
step: 10, loss: 0.000597544654738158
step: 20, loss: 0.0056082867085933685
step: 30, loss: 0.0067215366289019585
step: 40, loss: 0.002877649152651429
step: 50, loss: 0.005406470037996769
step: 60, loss: 0.026766568422317505
step: 70, loss: 0.0006139283650554717
step: 80, loss: 0.0005601012380793691
step: 90, loss: 0.02326410822570324
step: 100, loss: 0.00851893424987793
step: 110, loss: 0.054606176912784576
step: 120, loss: 0.0053518409840762615
step: 130, loss: 0.010031997226178646
step: 140, loss: 0.00038029460120014846
step: 150, loss: 0.0011184331960976124
step: 160, loss: 0.017702022567391396
step: 170, loss: 0.00048555745161138475
step: 180, loss: 0.0016198677476495504
step: 190, loss: 0.0004046772373840213
step: 200, loss: 0.00046056610881350935
step: 210, loss: 0.0038069067522883415
step: 220, loss: 0.005054735112935305
step: 230, loss: 0.0008292963611893356
step: 240, loss: 0.004194614943116903
step: 250, loss: 0.0036316411569714546
step: 260, loss: 0.01631147786974907
step: 270, loss: 0.00047716242261230946
step: 280, loss: 0.0005323837976902723
step: 290, loss: 0.0003637589397840202
step: 300, loss: 0.00928761437535286
step: 310, loss: 0.0033794688060879707
step: 320, loss: 0.0009064735495485365
step: 330, loss: 0.001482835621573031
step: 340, loss: 0.0007444006041623652
step: 350, loss: 0.00017613537784200162
step: 360, loss: 0.08558885008096695
step: 370, loss: 0.00010483645019121468
step: 380, loss: 0.013803619891405106
step: 390, loss: 0.06034491956233978
step: 400, loss: 0.0748620554804802
step: 410, loss: 0.027296198531985283
step: 420, loss: 0.00020267401123419404
step: 430, loss: 0.01060819998383522
step: 440, loss: 0.0013444017386063933
step: 450, loss: 0.016132162883877754
step: 460, loss: 0.0139998784288764
step: 470, loss: 0.0014465067069977522
step: 480, loss: 0.029177842661738396
step: 490, loss: 0.0027991957031190395
step: 500, loss: 0.09412595629692078
step: 510, loss: 0.16521427035331726
step: 520, loss: 0.1342073231935501
step: 530, loss: 0.003912920132279396
step: 540, loss: 0.005536278709769249
step: 550, loss: 0.08519504964351654
step: 560, loss: 0.002992494497448206
step: 570, loss: 0.0022919168695807457
step: 580, loss: 0.0012843427248299122
step: 590, loss: 0.0007618854288011789
step: 600, loss: 0.0012983886990696192
step: 610, loss: 0.0006819633417762816
step: 620, loss: 0.0002343393862247467
step: 630, loss: 0.004129698034375906
epoch 7: dev_f1=0.9489322191272052, f1=0.9394919168591224, best_f1=0.9455216989843028
step: 0, loss: 0.0006976481527090073
step: 10, loss: 0.0005337168695405126
step: 20, loss: 0.0016872670967131853
step: 30, loss: 0.0038663148880004883
step: 40, loss: 0.002262287540361285
step: 50, loss: 0.00026840620557777584
step: 60, loss: 0.000200544367544353
step: 70, loss: 0.002703632926568389
step: 80, loss: 0.00011543363507371396
step: 90, loss: 0.0003820463898591697
step: 100, loss: 0.008187832310795784
step: 110, loss: 0.00019588319992180914
step: 120, loss: 0.23438699543476105
step: 130, loss: 0.0006001506699249148
step: 140, loss: 8.303655340569094e-05
step: 150, loss: 0.053510408848524094
step: 160, loss: 0.009592079557478428
step: 170, loss: 0.08444152772426605
step: 180, loss: 0.004440935328602791
step: 190, loss: 0.001838556258007884
step: 200, loss: 0.007639134302735329
step: 210, loss: 0.015658650547266006
step: 220, loss: 0.026073453947901726
step: 230, loss: 0.003973168320953846
step: 240, loss: 0.0012377356179058552
step: 250, loss: 0.0003878811257891357
step: 260, loss: 0.003550466150045395
step: 270, loss: 0.00013964006211608648
step: 280, loss: 0.0004804542404599488
step: 290, loss: 0.0008573498344048858
step: 300, loss: 0.08705255389213562
step: 310, loss: 0.0013286665780469775
step: 320, loss: 0.00033972214441746473
step: 330, loss: 0.0005897704395465553
step: 340, loss: 0.01043608970940113
step: 350, loss: 0.021302441135048866
step: 360, loss: 0.002354786265641451
step: 370, loss: 0.009763109497725964
step: 380, loss: 0.0030582370236516
step: 390, loss: 0.00015029110363684595
step: 400, loss: 0.0003921687894035131
step: 410, loss: 0.01116928644478321
step: 420, loss: 0.0003573146532289684
step: 430, loss: 0.016935352236032486
step: 440, loss: 0.030397821217775345
step: 450, loss: 0.0006718661752529442
step: 460, loss: 0.0014197928830981255
step: 470, loss: 0.0005047756712883711
step: 480, loss: 0.06690606474876404
step: 490, loss: 0.0008188877836801112
step: 500, loss: 0.001691073994152248
step: 510, loss: 0.0021023598965257406
step: 520, loss: 0.09916325658559799
step: 530, loss: 0.00014785541861783713
step: 540, loss: 0.005092864856123924
step: 550, loss: 0.004765983670949936
step: 560, loss: 0.005652222782373428
step: 570, loss: 0.004249333404004574
step: 580, loss: 0.012632074765861034
step: 590, loss: 0.0004924767999909818
step: 600, loss: 0.005442438647150993
step: 610, loss: 0.025761371478438377
step: 620, loss: 0.00021041215222794563
step: 630, loss: 0.0013934337766841054
epoch 8: dev_f1=0.9460465116279071, f1=0.9420491423273065, best_f1=0.9455216989843028
step: 0, loss: 0.0005842754035256803
step: 10, loss: 0.004981128498911858
step: 20, loss: 0.0005123477312736213
step: 30, loss: 0.00022396382701117545
step: 40, loss: 0.0005525273154489696
step: 50, loss: 0.008259722031652927
step: 60, loss: 0.0001546673447592184
step: 70, loss: 0.0013087692204862833
step: 80, loss: 0.0007701525464653969
step: 90, loss: 0.0005073622451163828
step: 100, loss: 0.0008909147582016885
step: 110, loss: 0.003351242747157812
step: 120, loss: 0.01092067826539278
step: 130, loss: 0.0005152313387952745
step: 140, loss: 0.010972295887768269
step: 150, loss: 0.0010324422037228942
step: 160, loss: 0.00013507387484423816
step: 170, loss: 0.00017174075765069574
step: 180, loss: 0.010364658199250698
step: 190, loss: 0.00017032997857313603
step: 200, loss: 0.009619473479688168
step: 210, loss: 0.0005935177323408425
step: 220, loss: 0.0002267637464683503
step: 230, loss: 0.00031248386949300766
step: 240, loss: 0.0020351202692836523
step: 250, loss: 0.00034496394800953567
step: 260, loss: 0.0005141063593327999
step: 270, loss: 0.002558572683483362
step: 280, loss: 0.00020681075693573803
step: 290, loss: 0.03830505535006523
step: 300, loss: 0.03745492175221443
step: 310, loss: 0.0014913157792761922
step: 320, loss: 0.00016223524289671332
step: 330, loss: 0.0008847798453643918
step: 340, loss: 0.0032245509792119265
step: 350, loss: 0.00016245964798144996
step: 360, loss: 0.004563165828585625
step: 370, loss: 0.0003768758906517178
step: 380, loss: 0.002768982434645295
step: 390, loss: 0.00021658671903423965
step: 400, loss: 0.03449913114309311
step: 410, loss: 0.00021835639199707657
step: 420, loss: 0.0001196066805277951
step: 430, loss: 0.0001680474088061601
step: 440, loss: 0.03362245112657547
step: 450, loss: 0.002208139980211854
step: 460, loss: 0.00563987297937274
step: 470, loss: 0.007392322178930044
step: 480, loss: 0.04636354371905327
step: 490, loss: 0.0022828581277281046
step: 500, loss: 0.00023700146994087845
step: 510, loss: 0.0004127862921450287
step: 520, loss: 0.0026289625093340874
step: 530, loss: 0.022388068959116936
step: 540, loss: 0.008090906776487827
step: 550, loss: 0.02875506319105625
step: 560, loss: 0.001183031126856804
step: 570, loss: 0.01196037232875824
step: 580, loss: 0.012821713462471962
step: 590, loss: 0.0021586455404758453
step: 600, loss: 0.0008285984513349831
step: 610, loss: 0.00028592965099960566
step: 620, loss: 0.00020648707868531346
step: 630, loss: 0.001167868496850133
epoch 9: dev_f1=0.948405253283302, f1=0.9411210551106923, best_f1=0.9455216989843028
step: 0, loss: 0.023877300322055817
step: 10, loss: 0.008695329539477825
step: 20, loss: 0.000290260068140924
step: 30, loss: 0.0010093592572957277
step: 40, loss: 0.003955688793212175
step: 50, loss: 0.0012252280721440911
step: 60, loss: 0.000288844428723678
step: 70, loss: 0.0001050487844622694
step: 80, loss: 0.0012117865262553096
step: 90, loss: 0.0006518478621728718
step: 100, loss: 0.00014170607028063387
step: 110, loss: 7.214874494820833e-05
step: 120, loss: 0.0002443054399918765
step: 130, loss: 0.00039370221202261746
step: 140, loss: 0.0001176426958409138
step: 150, loss: 0.0006307472358457744
step: 160, loss: 0.00023203100136015564
step: 170, loss: 0.029741549864411354
step: 180, loss: 0.0003894341643899679
step: 190, loss: 0.00021804432617500424
step: 200, loss: 0.00014863353862892836
step: 210, loss: 0.00010325078619644046
step: 220, loss: 0.002127018291503191
step: 230, loss: 8.85409681359306e-05
step: 240, loss: 0.002277425955981016
step: 250, loss: 0.00010508068226044998
step: 260, loss: 0.0001429795811418444
step: 270, loss: 0.005438033025711775
step: 280, loss: 0.0006742317928001285
step: 290, loss: 6.366903835441917e-05
step: 300, loss: 0.00033550470834597945
step: 310, loss: 0.0001620168040972203
step: 320, loss: 0.0008231272222474217
step: 330, loss: 4.4041036744602025e-05
step: 340, loss: 0.00022360158618539572
step: 350, loss: 0.0003011470253113657
step: 360, loss: 9.059115109266713e-05
step: 370, loss: 0.001989862648770213
step: 380, loss: 4.274172897567041e-05
step: 390, loss: 0.0005605850601568818
step: 400, loss: 0.0003697230713441968
step: 410, loss: 4.441975033842027e-05
step: 420, loss: 9.031435911310837e-05
step: 430, loss: 0.002115606563165784
step: 440, loss: 5.806256740470417e-05
step: 450, loss: 0.08605503290891647
step: 460, loss: 0.0013573680771514773
step: 470, loss: 0.08251683413982391
step: 480, loss: 0.002454398898407817
step: 490, loss: 0.0001336706627625972
step: 500, loss: 0.0001277175615541637
step: 510, loss: 0.00016932719154283404
step: 520, loss: 0.0008485453436151147
step: 530, loss: 0.0011026510037481785
step: 540, loss: 0.00030594709096476436
step: 550, loss: 0.0015603486681357026
step: 560, loss: 0.004045384936034679
step: 570, loss: 4.568742588162422e-05
step: 580, loss: 0.0007791227544657886
step: 590, loss: 0.0003253389149904251
step: 600, loss: 0.000864896981511265
step: 610, loss: 5.8031699154525995e-05
step: 620, loss: 0.00012510077795013785
step: 630, loss: 0.012866360135376453
epoch 10: dev_f1=0.9477611940298507, f1=0.9406264609630668, best_f1=0.9455216989843028
step: 0, loss: 0.04537335783243179
step: 10, loss: 0.024249913170933723
step: 20, loss: 0.0004574888735078275
step: 30, loss: 0.0011885754065588117
step: 40, loss: 0.00019567344861570746
step: 50, loss: 0.014868751168251038
step: 60, loss: 0.00022510347480420023
step: 70, loss: 0.03245212882757187
step: 80, loss: 0.02135414630174637
step: 90, loss: 0.002273429650813341
step: 100, loss: 0.01464438159018755
step: 110, loss: 0.00011657243157969788
step: 120, loss: 6.832006329204887e-05
step: 130, loss: 0.0003462876775301993
step: 140, loss: 0.00010917944018729031
step: 150, loss: 0.028316790238022804
step: 160, loss: 0.003985647112131119
step: 170, loss: 0.00035001078504137695
step: 180, loss: 0.000582310778554529
step: 190, loss: 0.0003067948273383081
step: 200, loss: 9.972838597605005e-05
step: 210, loss: 6.580794433830306e-05
step: 220, loss: 0.00011643815378192812
step: 230, loss: 7.32106709619984e-05
step: 240, loss: 0.002235120628029108
step: 250, loss: 0.00011651793465716764
step: 260, loss: 0.0004784796910826117
step: 270, loss: 0.002051122486591339
step: 280, loss: 5.835400952491909e-05
step: 290, loss: 0.012499194592237473
step: 300, loss: 9.95692826109007e-05
step: 310, loss: 0.00014804245438426733
step: 320, loss: 0.00020712606783490628
step: 330, loss: 0.0023407568223774433
step: 340, loss: 0.00011909395107068121
step: 350, loss: 3.8589059840887785e-05
step: 360, loss: 0.0001015704037854448
step: 370, loss: 0.009039524011313915
step: 380, loss: 0.00020043026597704738
step: 390, loss: 0.0007186252041719854
step: 400, loss: 6.206188845681027e-05
step: 410, loss: 0.00023360303021036088
step: 420, loss: 0.00014694375568069518
step: 430, loss: 0.000159630726557225
step: 440, loss: 0.00011374192399671301
step: 450, loss: 0.0001703488960629329
step: 460, loss: 0.003816436044871807
step: 470, loss: 0.0001471786672482267
step: 480, loss: 0.0018199681071564555
step: 490, loss: 0.0006905363406985998
step: 500, loss: 0.00016030434926506132
step: 510, loss: 5.354368840926327e-05
step: 520, loss: 0.0048831673339009285
step: 530, loss: 0.0002900574472732842
step: 540, loss: 0.0004401756450533867
step: 550, loss: 5.2649796998593956e-05
step: 560, loss: 0.00014069040480535477
step: 570, loss: 0.0007102135568857193
step: 580, loss: 0.0006152964779175818
step: 590, loss: 0.00218173093162477
step: 600, loss: 0.0001877945032902062
step: 610, loss: 0.0002725518133956939
step: 620, loss: 0.0003685247793328017
step: 630, loss: 0.001208193600177765
epoch 11: dev_f1=0.9490740740740741, f1=0.9445738239403819, best_f1=0.9455216989843028
step: 0, loss: 9.732307080412284e-05
step: 10, loss: 0.00034232845064252615
step: 20, loss: 0.0014231826644390821
step: 30, loss: 0.00010633061901899055
step: 40, loss: 0.003924036864191294
step: 50, loss: 0.0013219264801591635
step: 60, loss: 5.2355422667460516e-05
step: 70, loss: 0.004320364445447922
step: 80, loss: 0.00021226081298664212
step: 90, loss: 0.0029673748649656773
step: 100, loss: 0.00014380192442331463
step: 110, loss: 0.0006690124864690006
step: 120, loss: 0.0008497122908011079
step: 130, loss: 0.0071124788373708725
step: 140, loss: 0.0040868534706532955
step: 150, loss: 0.00018223110237158835
step: 160, loss: 0.0004066985275130719
step: 170, loss: 0.027746113017201424
step: 180, loss: 0.00010781718447105959
step: 190, loss: 0.0002570811484474689
step: 200, loss: 0.0003036200359929353
step: 210, loss: 0.00014140002895146608
step: 220, loss: 0.00023538914683740586
step: 230, loss: 0.0006291077588684857
step: 240, loss: 0.000249809178058058
step: 250, loss: 0.00035620169364847243
step: 260, loss: 8.911093755159527e-05
step: 270, loss: 0.00016433770360890776
step: 280, loss: 0.007334350608289242
step: 290, loss: 0.00016891176346689463
step: 300, loss: 0.022293712943792343
step: 310, loss: 0.0010233604116365314
step: 320, loss: 0.008464138954877853
step: 330, loss: 0.00015387752500828356
step: 340, loss: 9.930361557053402e-05
step: 350, loss: 0.003036260837689042
step: 360, loss: 0.00026902445824816823
step: 370, loss: 0.00015224133676383644
step: 380, loss: 0.00016102110384963453
step: 390, loss: 0.0005065108998678625
step: 400, loss: 0.0036864979192614555
step: 410, loss: 0.020850621163845062
step: 420, loss: 0.00015888064808677882
step: 430, loss: 0.00023837675689719617
step: 440, loss: 0.0007259761332534254
step: 450, loss: 0.0003050672821700573
step: 460, loss: 0.00025453008129261434
step: 470, loss: 0.0023888428695499897
step: 480, loss: 0.00029902305686846375
step: 490, loss: 0.00029795296723023057
step: 500, loss: 0.00023230914666783065
step: 510, loss: 8.958346006693318e-05
step: 520, loss: 0.0020635328255593777
step: 530, loss: 0.006953095551580191
step: 540, loss: 0.019947335124015808
step: 550, loss: 0.0002291706477990374
step: 560, loss: 0.00863082055002451
step: 570, loss: 0.00014120344712864608
step: 580, loss: 0.000450830819318071
step: 590, loss: 0.0002984019520226866
step: 600, loss: 0.0005793190211988986
step: 610, loss: 0.00128817034419626
step: 620, loss: 0.000582890585064888
step: 630, loss: 7.339244621107355e-05
epoch 12: dev_f1=0.9476635514018692, f1=0.9444184960298926, best_f1=0.9455216989843028
step: 0, loss: 5.400196823757142e-05
step: 10, loss: 0.0008980217971839011
step: 20, loss: 0.00013021357881370932
step: 30, loss: 0.00022946497483644634
step: 40, loss: 0.00013839649909641594
step: 50, loss: 0.0005349894054234028
step: 60, loss: 8.63935420056805e-05
step: 70, loss: 0.0002663451014086604
step: 80, loss: 0.0011588252382352948
step: 90, loss: 0.00027023881557397544
step: 100, loss: 0.00013013930583838373
step: 110, loss: 7.818204176146537e-05
step: 120, loss: 0.0013496329775080085
step: 130, loss: 0.0007657486712560058
step: 140, loss: 0.0004218121466692537
step: 150, loss: 0.0003335450601298362
step: 160, loss: 0.00017164528253488243
step: 170, loss: 0.0002092787326546386
step: 180, loss: 0.007154685445129871
step: 190, loss: 0.00010434731666464359
step: 200, loss: 0.006720546633005142
step: 210, loss: 0.00012621762289199978
step: 220, loss: 4.8984333261614665e-05
step: 230, loss: 0.00014557430404238403
step: 240, loss: 0.00013971720181871206
step: 250, loss: 0.0008498290553689003
step: 260, loss: 6.339054380077869e-05
step: 270, loss: 0.0003957496664952487
step: 280, loss: 4.421594712766819e-05
step: 290, loss: 0.0008301016059704125
step: 300, loss: 0.0002202990435762331
step: 310, loss: 0.00020577909890562296
step: 320, loss: 0.00155711080878973
step: 330, loss: 2.730566484387964e-05
step: 340, loss: 8.132768562063575e-05
step: 350, loss: 3.6036857636645436e-05
step: 360, loss: 0.0019909474067389965
step: 370, loss: 2.8519541956484318e-05
step: 380, loss: 0.00013854620920028538
step: 390, loss: 0.00011654769332380965
step: 400, loss: 0.014620459638535976
step: 410, loss: 0.0010203326819464564
step: 420, loss: 8.243149204645306e-05
step: 430, loss: 0.0032794042490422726
step: 440, loss: 0.0007856947486288846
step: 450, loss: 6.111664697527885e-05
step: 460, loss: 5.5928197980392724e-05
step: 470, loss: 0.00016487027460243553
step: 480, loss: 0.0001552049070596695
step: 490, loss: 0.00015616121527273208
step: 500, loss: 7.222227577585727e-05
step: 510, loss: 0.022232720628380775
step: 520, loss: 0.00018825367442332208
step: 530, loss: 0.012260164134204388
step: 540, loss: 7.110789010766894e-05
step: 550, loss: 9.843212319537997e-05
step: 560, loss: 5.615897316602059e-05
step: 570, loss: 5.095872256788425e-05
step: 580, loss: 4.98185763717629e-05
step: 590, loss: 0.00021567087969742715
step: 600, loss: 0.00011586595792323351
step: 610, loss: 0.00010249455226585269
step: 620, loss: 0.00018502218881621957
step: 630, loss: 7.151786849135533e-05
epoch 13: dev_f1=0.9499298081422555, f1=0.9439252336448598, best_f1=0.9439252336448598
step: 0, loss: 4.0983857616083696e-05
step: 10, loss: 5.259725367068313e-05
step: 20, loss: 8.402912499150261e-05
step: 30, loss: 0.0003062646137550473
step: 40, loss: 0.0009244640823453665
step: 50, loss: 0.00014555449888575822
step: 60, loss: 0.0003251822490710765
step: 70, loss: 7.018290489213541e-05
step: 80, loss: 0.00014419425860978663
step: 90, loss: 0.0003257304197177291
step: 100, loss: 8.872698526829481e-05
step: 110, loss: 0.00013244248111732304
step: 120, loss: 3.86178980988916e-05
step: 130, loss: 0.00015334134513977915
step: 140, loss: 0.002694849157705903
step: 150, loss: 9.8167329269927e-05
step: 160, loss: 0.00010207523155258968
step: 170, loss: 0.024553850293159485
step: 180, loss: 4.542080932878889e-05
step: 190, loss: 6.776348891435191e-05
step: 200, loss: 6.55582407489419e-05
step: 210, loss: 0.0004567915457300842
step: 220, loss: 0.011748801916837692
step: 230, loss: 0.028357069939374924
step: 240, loss: 6.291720637818798e-05
step: 250, loss: 7.198233652161434e-05
step: 260, loss: 0.00021882027795072645
step: 270, loss: 8.407860150327906e-05
step: 280, loss: 9.862572187557817e-05
step: 290, loss: 7.619748794240877e-05
step: 300, loss: 0.00015389692271128297
step: 310, loss: 0.008313705213367939
step: 320, loss: 5.0947110139532015e-05
step: 330, loss: 0.00015528527728747576
step: 340, loss: 0.0012338231317698956
step: 350, loss: 8.201536547858268e-05
step: 360, loss: 0.0011643008328974247
step: 370, loss: 6.648382259299979e-05
step: 380, loss: 3.8458088965853676e-05
step: 390, loss: 0.004764179233461618
step: 400, loss: 8.174585673259571e-05
step: 410, loss: 5.815401891595684e-05
step: 420, loss: 0.001003543147817254
step: 430, loss: 9.868751658359542e-05
step: 440, loss: 7.556641503470019e-05
step: 450, loss: 6.076456338632852e-05
step: 460, loss: 0.02211034670472145
step: 470, loss: 0.0006212522275745869
step: 480, loss: 9.313329792348668e-05
step: 490, loss: 7.42412667023018e-05
step: 500, loss: 0.0009744182461872697
step: 510, loss: 7.198539969976991e-05
step: 520, loss: 0.004529659636318684
step: 530, loss: 0.00010948755516437814
step: 540, loss: 0.02217208780348301
step: 550, loss: 0.006590362172573805
step: 560, loss: 0.0003150964912492782
step: 570, loss: 5.156593397259712e-05
step: 580, loss: 0.007765810936689377
step: 590, loss: 5.030870306654833e-05
step: 600, loss: 9.200991917168722e-05
step: 610, loss: 6.75486444379203e-05
step: 620, loss: 0.00013345706975087523
step: 630, loss: 0.00017961367848329246
epoch 14: dev_f1=0.9475620975160993, f1=0.9430670339761248, best_f1=0.9439252336448598
step: 0, loss: 7.377340807579458e-05
step: 10, loss: 0.00020597245020326227
step: 20, loss: 0.00014453046605922282
step: 30, loss: 0.0005511270719580352
step: 40, loss: 4.889097544946708e-05
step: 50, loss: 0.0002694384893402457
step: 60, loss: 0.00027981449966318905
step: 70, loss: 3.1328931072494015e-05
step: 80, loss: 8.806122787063941e-05
step: 90, loss: 5.5008611525408924e-05
step: 100, loss: 0.0002591340453363955
step: 110, loss: 0.00013413431588560343
step: 120, loss: 3.032272979908157e-05
step: 130, loss: 4.5009859604761004e-05
step: 140, loss: 0.001219473546370864
step: 150, loss: 0.0011618706630542874
step: 160, loss: 0.03662138059735298
step: 170, loss: 6.0553189541678876e-05
step: 180, loss: 0.0017592449439689517
step: 190, loss: 0.0007037723553366959
step: 200, loss: 5.232732655713335e-05
step: 210, loss: 5.462393528432585e-05
step: 220, loss: 0.00037803908344358206
step: 230, loss: 0.000707927334588021
step: 240, loss: 8.567333861719817e-05
step: 250, loss: 0.00337405176833272
step: 260, loss: 4.7653324145358056e-05
step: 270, loss: 0.0005409236182458699
step: 280, loss: 3.765321525861509e-05
step: 290, loss: 0.0002121172146871686
step: 300, loss: 0.00010486957762623206
step: 310, loss: 0.00015677357441745698
step: 320, loss: 0.0014801895013079047
step: 330, loss: 0.003693691687658429
step: 340, loss: 3.9983777242014185e-05
step: 350, loss: 0.11383356153964996
step: 360, loss: 4.639584949472919e-05
step: 370, loss: 0.00010254848893964663
step: 380, loss: 0.00020129859331063926
step: 390, loss: 0.008451642468571663
step: 400, loss: 4.813561463379301e-05
step: 410, loss: 2.863856207113713e-05
step: 420, loss: 6.759843381587416e-05
step: 430, loss: 2.6991780032403767e-05
step: 440, loss: 4.0624188841320574e-05
step: 450, loss: 0.0014132701326161623
step: 460, loss: 0.0016173365293070674
step: 470, loss: 0.0009052956011146307
step: 480, loss: 3.4055330615956336e-05
step: 490, loss: 1.985181552299764e-05
step: 500, loss: 3.311632463010028e-05
step: 510, loss: 0.00025571469450369477
step: 520, loss: 4.563434049487114e-05
step: 530, loss: 4.527734199655242e-05
step: 540, loss: 0.0035314348060637712
step: 550, loss: 0.0005484361900016665
step: 560, loss: 0.00011554973752936348
step: 570, loss: 3.365084921824746e-05
step: 580, loss: 0.0005165678448975086
step: 590, loss: 4.470870044315234e-05
step: 600, loss: 9.164396760752425e-05
step: 610, loss: 2.528299592086114e-05
step: 620, loss: 0.0007228154572658241
step: 630, loss: 8.802009688224643e-05
epoch 15: dev_f1=0.9470260223048327, f1=0.9405756731662025, best_f1=0.9439252336448598
step: 0, loss: 4.7845227527432144e-05
step: 10, loss: 2.544652124925051e-05
step: 20, loss: 1.635752596484963e-05
step: 30, loss: 4.609253301168792e-05
step: 40, loss: 0.0002654964046087116
step: 50, loss: 0.00010157860378967598
step: 60, loss: 0.000258459011092782
step: 70, loss: 4.385902502690442e-05
step: 80, loss: 0.0069534676149487495
step: 90, loss: 2.7148669687449e-05
step: 100, loss: 1.750856972648762e-05
step: 110, loss: 6.819407281000167e-05
step: 120, loss: 3.498633304843679e-05
step: 130, loss: 0.00014600466238334775
step: 140, loss: 0.0008729294058866799
step: 150, loss: 3.208079215255566e-05
step: 160, loss: 3.9919494156492874e-05
step: 170, loss: 0.0006733308546245098
step: 180, loss: 0.00021630845731124282
step: 190, loss: 2.8232783733983524e-05
step: 200, loss: 3.627111800597049e-05
step: 210, loss: 9.270951704820618e-05
step: 220, loss: 4.986323619959876e-05
step: 230, loss: 0.00018555221322458237
step: 240, loss: 2.2589747459278442e-05
step: 250, loss: 2.263069836772047e-05
step: 260, loss: 5.836519994772971e-05
step: 270, loss: 4.9056874559028074e-05
step: 280, loss: 3.919339724234305e-05
step: 290, loss: 0.00012979831080883741
step: 300, loss: 3.0396520742215216e-05
step: 310, loss: 5.2027036872459576e-05
step: 320, loss: 4.778566653840244e-05
step: 330, loss: 2.7026144380215555e-05
step: 340, loss: 8.656457794131711e-05
step: 350, loss: 0.0010362465400248766
step: 360, loss: 5.4862703109392896e-05
step: 370, loss: 5.084234362584539e-05
step: 380, loss: 6.693532486679032e-05
step: 390, loss: 4.5639186282642186e-05
step: 400, loss: 2.308118018845562e-05
step: 410, loss: 0.00037556435563601553
step: 420, loss: 0.002432706532999873
step: 430, loss: 9.583491191733629e-05
step: 440, loss: 7.89423065725714e-05
step: 450, loss: 5.8856920077232644e-05
step: 460, loss: 4.612686825566925e-05
step: 470, loss: 0.0002134699752787128
step: 480, loss: 1.838769094320014e-05
step: 490, loss: 0.0009151178528554738
step: 500, loss: 2.166191188734956e-05
step: 510, loss: 1.9941186110372655e-05
step: 520, loss: 6.632036820519716e-05
step: 530, loss: 4.8198129661614075e-05
step: 540, loss: 0.04348550736904144
step: 550, loss: 5.175064143259078e-05
step: 560, loss: 0.0001303544413531199
step: 570, loss: 0.006442985497415066
step: 580, loss: 3.261705205659382e-05
step: 590, loss: 5.842837708769366e-05
step: 600, loss: 2.750257044681348e-05
step: 610, loss: 0.0025751322973519564
step: 620, loss: 5.379387948778458e-05
step: 630, loss: 0.0006449461216107011
epoch 16: dev_f1=0.9474174034434621, f1=0.9455053563111318, best_f1=0.9439252336448598
step: 0, loss: 0.0002100351412082091
step: 10, loss: 0.0066100540570914745
step: 20, loss: 4.468041879590601e-05
step: 30, loss: 1.9840588720398955e-05
step: 40, loss: 4.354664997663349e-05
step: 50, loss: 0.022999415174126625
step: 60, loss: 3.487346111796796e-05
step: 70, loss: 3.2385505619458854e-05
step: 80, loss: 4.563531183521263e-05
step: 90, loss: 7.744892354821786e-05
step: 100, loss: 0.0001739728031679988
step: 110, loss: 0.00498273316770792
step: 120, loss: 0.0015248724957928061
step: 130, loss: 6.621411012019962e-05
step: 140, loss: 5.552645234274678e-05
step: 150, loss: 0.000492340768687427
step: 160, loss: 0.00010921479406533763
step: 170, loss: 3.0240031264838763e-05
step: 180, loss: 3.9256716263480484e-05
step: 190, loss: 0.0012525315396487713
step: 200, loss: 2.2567388441530056e-05
step: 210, loss: 4.1518684156471863e-05
step: 220, loss: 6.673263851553202e-05
step: 230, loss: 5.0031987484544516e-05
step: 240, loss: 0.0023513019550591707
step: 250, loss: 3.828549597528763e-05
step: 260, loss: 2.189676342823077e-05
step: 270, loss: 0.005372008308768272
step: 280, loss: 0.00019677015370689332
step: 290, loss: 3.070640377700329e-05
step: 300, loss: 2.8053687856299803e-05
step: 310, loss: 0.0011879723751917481
step: 320, loss: 1.654009975027293e-05
step: 330, loss: 3.345814548083581e-05
step: 340, loss: 0.02491198107600212
step: 350, loss: 0.0001186942245112732
step: 360, loss: 2.5792871383600868e-05
step: 370, loss: 2.4768884031800553e-05
step: 380, loss: 0.00037898230948485434
step: 390, loss: 2.253749335068278e-05
step: 400, loss: 7.771638047415763e-05
step: 410, loss: 0.0003133862919639796
step: 420, loss: 2.9588787583634257e-05
step: 430, loss: 0.00019427145889494568
step: 440, loss: 3.946511060348712e-05
step: 450, loss: 0.0004339210281614214
step: 460, loss: 0.00014575402019545436
step: 470, loss: 3.8307382055791095e-05
step: 480, loss: 3.563614882295951e-05
step: 490, loss: 0.0001679910346865654
step: 500, loss: 0.0008341553038917482
step: 510, loss: 3.423549424041994e-05
step: 520, loss: 0.0003672193852253258
step: 530, loss: 0.000310502975480631
step: 540, loss: 8.918278763303533e-05
step: 550, loss: 6.132835551397875e-05
step: 560, loss: 3.1506922823609784e-05
step: 570, loss: 1.7519689208711497e-05
step: 580, loss: 0.0001136307546403259
step: 590, loss: 1.860008342191577e-05
step: 600, loss: 0.005952947307378054
step: 610, loss: 4.194101711618714e-05
step: 620, loss: 0.0001530521985841915
step: 630, loss: 5.6164819397963583e-05
epoch 17: dev_f1=0.945387792565397, f1=0.9451865499769692, best_f1=0.9439252336448598
step: 0, loss: 2.4582624973845668e-05
step: 10, loss: 0.0005238562007434666
step: 20, loss: 3.9803395338822156e-05
step: 30, loss: 0.00019642444385681301
step: 40, loss: 5.6154858611989766e-05
step: 50, loss: 3.516447759466246e-05
step: 60, loss: 0.000121249322546646
step: 70, loss: 3.126782030449249e-05
step: 80, loss: 1.887184589577373e-05
step: 90, loss: 0.0004408583336044103
step: 100, loss: 3.9134964026743546e-05
step: 110, loss: 4.367476503830403e-05
step: 120, loss: 5.34633691131603e-05
step: 130, loss: 0.00011256325524300337
step: 140, loss: 2.740127092693001e-05
step: 150, loss: 2.5979070414905436e-05
step: 160, loss: 3.5679080610862e-05
step: 170, loss: 0.2374884933233261
step: 180, loss: 0.00016629966557957232
step: 190, loss: 0.0008051390177570283
step: 200, loss: 9.631404827814549e-05
step: 210, loss: 0.0002059067483060062
step: 220, loss: 0.00028948980616405606
step: 230, loss: 0.00022682180861011147
step: 240, loss: 8.28988995635882e-05
step: 250, loss: 2.800206493702717e-05
step: 260, loss: 0.0032220170833170414
step: 270, loss: 2.2567013729712926e-05
step: 280, loss: 2.486552511982154e-05
step: 290, loss: 5.83933579036966e-05
step: 300, loss: 1.9598457583924755e-05
step: 310, loss: 0.0006180504569783807
step: 320, loss: 0.002999447053298354
step: 330, loss: 5.390758451540023e-05
step: 340, loss: 6.774334178771824e-05
step: 350, loss: 0.0002908778842538595
step: 360, loss: 0.00025384477339684963
step: 370, loss: 0.0001648120814934373
step: 380, loss: 4.857487147091888e-05
step: 390, loss: 8.098638500086963e-05
step: 400, loss: 0.011181228794157505
step: 410, loss: 2.3714501367066987e-05
step: 420, loss: 0.0003526157815940678
step: 430, loss: 8.656180580146611e-05
step: 440, loss: 2.5680858016130514e-05
step: 450, loss: 5.028051964472979e-05
step: 460, loss: 8.653698751004413e-05
step: 470, loss: 0.002966826781630516
step: 480, loss: 0.0015973781701177359
step: 490, loss: 0.00032932183239609003
step: 500, loss: 0.00016285844321828336
step: 510, loss: 1.3328929526323918e-05
step: 520, loss: 0.0018465510802343488
step: 530, loss: 0.0017736662412062287
step: 540, loss: 3.269922672188841e-05
step: 550, loss: 2.1349011149141006e-05
step: 560, loss: 2.5493094653938897e-05
step: 570, loss: 2.411685636616312e-05
step: 580, loss: 3.3481170248705894e-05
step: 590, loss: 0.0002406606072327122
step: 600, loss: 0.0001594496425241232
step: 610, loss: 2.1617248421534896e-05
step: 620, loss: 4.002456262242049e-05
step: 630, loss: 5.5177770263981074e-05
epoch 18: dev_f1=0.9485396383866481, f1=0.9409576940957695, best_f1=0.9439252336448598
step: 0, loss: 1.6472640709253028e-05
step: 10, loss: 1.5731669918750413e-05
step: 20, loss: 1.5336816431954503e-05
step: 30, loss: 0.0012622287031263113
step: 40, loss: 0.0011373028391972184
step: 50, loss: 5.111597420182079e-05
step: 60, loss: 2.6362304197391495e-05
step: 70, loss: 2.7808124286821112e-05
step: 80, loss: 1.813796188798733e-05
step: 90, loss: 0.0004111042362637818
step: 100, loss: 1.8883210941567086e-05
step: 110, loss: 1.208847425004933e-05
step: 120, loss: 1.6372272511944175e-05
step: 130, loss: 8.400061778957024e-05
step: 140, loss: 2.0324740034993738e-05
step: 150, loss: 2.0265109924366698e-05
step: 160, loss: 1.4707296031701844e-05
step: 170, loss: 1.9140086806146428e-05
step: 180, loss: 0.002099341247230768
step: 190, loss: 1.472961957915686e-05
step: 200, loss: 1.877890645118896e-05
step: 210, loss: 0.0001624855794943869
step: 220, loss: 3.909913721145131e-05
step: 230, loss: 1.7396700059180148e-05
step: 240, loss: 2.5185905542457476e-05
step: 250, loss: 0.03219589591026306
step: 260, loss: 2.1337960788514465e-05
step: 270, loss: 3.008788189617917e-05
step: 280, loss: 1.6573503671679646e-05
step: 290, loss: 0.0020907633006572723
step: 300, loss: 0.0001915867323987186
step: 310, loss: 2.4995262720040046e-05
step: 320, loss: 0.0034316100645810366
step: 330, loss: 2.3586708266520873e-05
step: 340, loss: 0.0014290153048932552
step: 350, loss: 2.3844506358727813e-05
step: 360, loss: 2.2361653464031406e-05
step: 370, loss: 3.179037958034314e-05
step: 380, loss: 5.713095742976293e-05
step: 390, loss: 2.4630940970382653e-05
step: 400, loss: 0.0004916423931717873
step: 410, loss: 2.182166645070538e-05
step: 420, loss: 2.6585450541460887e-05
step: 430, loss: 2.8202297471580096e-05
step: 440, loss: 1.5571429685223848e-05
step: 450, loss: 7.413301500491798e-05
step: 460, loss: 0.0002976546820718795
step: 470, loss: 0.0003995915758423507
step: 480, loss: 3.164886584272608e-05
step: 490, loss: 7.573631592094898e-05
step: 500, loss: 2.697025593079161e-05
step: 510, loss: 2.902804953919258e-05
step: 520, loss: 9.440084977541119e-05
step: 530, loss: 0.00016010664694476873
step: 540, loss: 2.4414748622803017e-05
step: 550, loss: 0.0025898171588778496
step: 560, loss: 1.873040855571162e-05
step: 570, loss: 0.00039847989683039486
step: 580, loss: 2.4999344532261603e-05
step: 590, loss: 8.198589057428762e-05
step: 600, loss: 2.6980073016602546e-05
step: 610, loss: 0.0009992021368816495
step: 620, loss: 0.002626245841383934
step: 630, loss: 2.351329203520436e-05
epoch 19: dev_f1=0.9489322191272052, f1=0.9445738239403819, best_f1=0.9439252336448598
step: 0, loss: 2.8999653295613825e-05
step: 10, loss: 1.5508170690736733e-05
step: 20, loss: 3.846054823952727e-05
step: 30, loss: 9.546543878968805e-05
step: 40, loss: 6.114501593401656e-05
step: 50, loss: 2.3170863642008044e-05
step: 60, loss: 6.900243170093745e-05
step: 70, loss: 2.1840874978806823e-05
step: 80, loss: 4.447763421921991e-05
step: 90, loss: 4.414806608110666e-05
step: 100, loss: 4.8832625907380134e-05
step: 110, loss: 1.739316576276906e-05
step: 120, loss: 0.0001287253835471347
step: 130, loss: 2.1258396373013966e-05
step: 140, loss: 1.7750446204445325e-05
step: 150, loss: 1.8804832507157698e-05
step: 160, loss: 0.00020525589934550226
step: 170, loss: 2.1583482521236874e-05
step: 180, loss: 2.4805305656627752e-05
step: 190, loss: 1.4308659046946559e-05
step: 200, loss: 2.292453427799046e-05
step: 210, loss: 2.161362863262184e-05
step: 220, loss: 0.0015320623060688376
step: 230, loss: 1.5314457414206117e-05
step: 240, loss: 4.1931391024263576e-05
step: 250, loss: 0.004224839154630899
step: 260, loss: 2.166946796933189e-05
step: 270, loss: 2.141587174264714e-05
step: 280, loss: 1.742633139656391e-05
step: 290, loss: 2.019429302890785e-05
step: 300, loss: 1.7579306586412713e-05
step: 310, loss: 2.7565605705603957e-05
step: 320, loss: 1.7437769201933406e-05
step: 330, loss: 3.2228141208179295e-05
step: 340, loss: 5.06758333358448e-05
step: 350, loss: 0.0005193290999159217
step: 360, loss: 0.029294399544596672
step: 370, loss: 2.9014176107011735e-05
step: 380, loss: 5.190468073124066e-05
step: 390, loss: 2.7100424631498754e-05
step: 400, loss: 0.0008530369959771633
step: 410, loss: 2.8761349312844686e-05
step: 420, loss: 0.019579865038394928
step: 430, loss: 5.155813414603472e-05
step: 440, loss: 2.1463993107317947e-05
step: 450, loss: 1.7333328287350014e-05
step: 460, loss: 2.2962040020502172e-05
step: 470, loss: 0.009099427610635757
step: 480, loss: 0.00011401994561310858
step: 490, loss: 1.7284881323575974e-05
step: 500, loss: 1.677454747550655e-05
step: 510, loss: 1.4301206647360232e-05
step: 520, loss: 1.236784828506643e-05
step: 530, loss: 1.5061142221384216e-05
step: 540, loss: 7.059197378112003e-05
step: 550, loss: 2.8519509214675054e-05
step: 560, loss: 0.00012688808783423156
step: 570, loss: 0.00010542962263571098
step: 580, loss: 2.2071042621973902e-05
step: 590, loss: 2.4448141630273312e-05
step: 600, loss: 0.0005024944548495114
step: 610, loss: 1.4897235814714804e-05
step: 620, loss: 2.3784370569046587e-05
step: 630, loss: 3.181467764079571e-05
epoch 20: dev_f1=0.9493258949325895, f1=0.9436947417403444, best_f1=0.9439252336448598
cuda
Device: cuda
step: 0, loss: 0.6898083686828613
step: 10, loss: 0.7382684946060181
step: 20, loss: 0.5835580825805664
step: 30, loss: 0.6908411383628845
step: 40, loss: 0.5750232934951782
step: 50, loss: 0.6408663988113403
step: 60, loss: 0.3800826072692871
step: 70, loss: 0.22109994292259216
step: 80, loss: 0.5565656423568726
step: 90, loss: 0.3989022970199585
step: 100, loss: 0.3404427766799927
step: 110, loss: 0.3531050980091095
step: 120, loss: 0.45754608511924744
step: 130, loss: 0.45752832293510437
step: 140, loss: 0.15154385566711426
step: 150, loss: 0.3814123570919037
step: 160, loss: 0.32113364338874817
step: 170, loss: 0.24898353219032288
step: 180, loss: 0.4702284038066864
step: 190, loss: 0.1810496300458908
step: 200, loss: 0.14784979820251465
step: 210, loss: 0.13150884211063385
step: 220, loss: 0.09932062774896622
step: 230, loss: 0.2240438610315323
step: 240, loss: 0.3192748427391052
step: 250, loss: 0.06785547733306885
step: 260, loss: 0.1732613891363144
step: 270, loss: 0.28516191244125366
step: 280, loss: 0.09051083773374557
step: 290, loss: 0.0633091852068901
step: 300, loss: 0.27952805161476135
step: 310, loss: 0.20290197432041168
step: 320, loss: 0.07214498519897461
step: 330, loss: 0.024871475994586945
step: 340, loss: 0.016326898708939552
step: 350, loss: 0.17132043838500977
step: 360, loss: 0.044076044112443924
step: 370, loss: 0.11954302340745926
step: 380, loss: 0.019591383635997772
step: 390, loss: 0.22892658412456512
step: 400, loss: 0.1024937555193901
step: 410, loss: 0.22969165444374084
step: 420, loss: 0.024890493601560593
step: 430, loss: 0.056907977908849716
step: 440, loss: 0.030432920902967453
step: 450, loss: 0.2182116061449051
step: 460, loss: 0.032932132482528687
step: 470, loss: 0.04891635477542877
step: 480, loss: 0.0944410040974617
step: 490, loss: 0.2729843556880951
step: 500, loss: 0.06245412304997444
step: 510, loss: 0.0630737692117691
step: 520, loss: 0.09496258944272995
step: 530, loss: 0.011329765431582928
step: 540, loss: 0.24093230068683624
step: 550, loss: 0.07886814326047897
step: 560, loss: 0.1703041046857834
step: 570, loss: 0.23722442984580994
step: 580, loss: 0.15502424538135529
step: 590, loss: 0.10516971349716187
step: 600, loss: 0.20114313066005707
step: 610, loss: 0.33516886830329895
step: 620, loss: 0.04600978270173073
step: 630, loss: 0.04601243510842323
epoch 1: dev_f1=0.9377018920166128, f1=0.9384756657483929, best_f1=0.9384756657483929
step: 0, loss: 0.01998802274465561
step: 10, loss: 0.2962391972541809
step: 20, loss: 0.03326107934117317
step: 30, loss: 0.032450564205646515
step: 40, loss: 0.1265491247177124
step: 50, loss: 0.2645553946495056
step: 60, loss: 0.08431629836559296
step: 70, loss: 0.044659607112407684
step: 80, loss: 0.015039896592497826
step: 90, loss: 0.22829732298851013
step: 100, loss: 0.00481813121587038
step: 110, loss: 0.10920016467571259
step: 120, loss: 0.007765943184494972
step: 130, loss: 0.01650184392929077
step: 140, loss: 0.04791479930281639
step: 150, loss: 0.027344662696123123
step: 160, loss: 0.054347287863492966
step: 170, loss: 0.018869759514927864
step: 180, loss: 0.018679605796933174
step: 190, loss: 0.09772023558616638
step: 200, loss: 0.04213569685816765
step: 210, loss: 0.11153262108564377
step: 220, loss: 0.03290747478604317
step: 230, loss: 0.06262204796075821
step: 240, loss: 0.150282084941864
step: 250, loss: 0.017980564385652542
step: 260, loss: 0.08299374580383301
step: 270, loss: 0.09137635678052902
step: 280, loss: 0.13997507095336914
step: 290, loss: 0.08456979691982269
step: 300, loss: 0.0645393505692482
step: 310, loss: 0.011353937909007072
step: 320, loss: 0.2337028831243515
step: 330, loss: 0.022440915927290916
step: 340, loss: 0.04690856486558914
step: 350, loss: 0.006237351801246405
step: 360, loss: 0.025808950886130333
step: 370, loss: 0.15818051993846893
step: 380, loss: 0.010256452485918999
step: 390, loss: 0.14045172929763794
step: 400, loss: 0.2321779429912567
step: 410, loss: 0.09038213640451431
step: 420, loss: 0.11530832946300507
step: 430, loss: 0.08785831928253174
step: 440, loss: 0.030940650030970573
step: 450, loss: 0.1010400652885437
step: 460, loss: 0.01646376959979534
step: 470, loss: 0.019364740699529648
step: 480, loss: 0.21750763058662415
step: 490, loss: 0.2794346809387207
step: 500, loss: 0.1297501176595688
step: 510, loss: 0.12653830647468567
step: 520, loss: 0.05310460552573204
step: 530, loss: 0.18945756554603577
step: 540, loss: 0.0174372848123312
step: 550, loss: 0.18045498430728912
step: 560, loss: 0.049264684319496155
step: 570, loss: 0.03624092787504196
step: 580, loss: 0.014190033078193665
step: 590, loss: 0.038813527673482895
step: 600, loss: 0.18172362446784973
step: 610, loss: 0.10903377830982208
step: 620, loss: 0.0537957027554512
step: 630, loss: 0.04450814053416252
epoch 2: dev_f1=0.9428440786465478, f1=0.9364426154549611, best_f1=0.9364426154549611
step: 0, loss: 0.007645466364920139
step: 10, loss: 0.05208919197320938
step: 20, loss: 0.005555001553148031
step: 30, loss: 0.005044437944889069
step: 40, loss: 0.003038282273337245
step: 50, loss: 0.009212550707161427
step: 60, loss: 0.03974713012576103
step: 70, loss: 0.0036642770282924175
step: 80, loss: 0.02065455913543701
step: 90, loss: 0.018433820456266403
step: 100, loss: 0.02516741305589676
step: 110, loss: 0.07077296078205109
step: 120, loss: 0.037188246846199036
step: 130, loss: 0.03607121482491493
step: 140, loss: 0.04084712639451027
step: 150, loss: 0.028105823323130608
step: 160, loss: 0.012094927951693535
step: 170, loss: 0.005450962111353874
step: 180, loss: 0.008179103024303913
step: 190, loss: 0.014593660831451416
step: 200, loss: 0.013218954205513
step: 210, loss: 0.26470106840133667
step: 220, loss: 0.007183609530329704
step: 230, loss: 0.004140071105211973
step: 240, loss: 0.08053935319185257
step: 250, loss: 0.044209275394678116
step: 260, loss: 0.12054690718650818
step: 270, loss: 0.10667533427476883
step: 280, loss: 0.009034654125571251
step: 290, loss: 0.02158498764038086
step: 300, loss: 0.03577851504087448
step: 310, loss: 0.018350031226873398
step: 320, loss: 0.167230486869812
step: 330, loss: 0.07733713090419769
step: 340, loss: 0.03274204209446907
step: 350, loss: 0.03171313926577568
step: 360, loss: 0.0021614129655063152
step: 370, loss: 0.013464733958244324
step: 380, loss: 0.027937298640608788
step: 390, loss: 0.05689927935600281
step: 400, loss: 0.007775742560625076
step: 410, loss: 0.08095002919435501
step: 420, loss: 0.01357326004654169
step: 430, loss: 0.02665000967681408
step: 440, loss: 0.1011529192328453
step: 450, loss: 0.008025387302041054
step: 460, loss: 0.054831355810165405
step: 470, loss: 0.0193835087120533
step: 480, loss: 0.18115781247615814
step: 490, loss: 0.11445071548223495
step: 500, loss: 0.11397270113229752
step: 510, loss: 0.0910908505320549
step: 520, loss: 0.12286365032196045
step: 530, loss: 0.044680386781692505
step: 540, loss: 0.022026579827070236
step: 550, loss: 0.27146291732788086
step: 560, loss: 0.016440486535429955
step: 570, loss: 0.0033464955631643534
step: 580, loss: 0.04683677479624748
step: 590, loss: 0.01493910513818264
step: 600, loss: 0.0803595706820488
step: 610, loss: 0.032167889177799225
step: 620, loss: 0.08193962275981903
step: 630, loss: 0.013154849410057068
epoch 3: dev_f1=0.9437269372693727, f1=0.93666204345816, best_f1=0.93666204345816
step: 0, loss: 0.0804370865225792
step: 10, loss: 0.0358671210706234
step: 20, loss: 0.004908114206045866
step: 30, loss: 0.015087651088833809
step: 40, loss: 0.0678858831524849
step: 50, loss: 0.015939263626933098
step: 60, loss: 0.022832894697785378
step: 70, loss: 0.005911714863032103
step: 80, loss: 0.02668803557753563
step: 90, loss: 0.0024370290338993073
step: 100, loss: 0.0019107222324237227
step: 110, loss: 0.013794798403978348
step: 120, loss: 0.0025601014494895935
step: 130, loss: 0.003983471542596817
step: 140, loss: 0.0445728525519371
step: 150, loss: 0.0036631105467677116
step: 160, loss: 0.16581177711486816
step: 170, loss: 0.004304316360503435
step: 180, loss: 0.005738106556236744
step: 190, loss: 0.08674702793359756
step: 200, loss: 0.022437946870923042
step: 210, loss: 0.2264227420091629
step: 220, loss: 0.002044499618932605
step: 230, loss: 0.005208767019212246
step: 240, loss: 0.031110530719161034
step: 250, loss: 0.005379362031817436
step: 260, loss: 0.1814901977777481
step: 270, loss: 0.0015750644961372018
step: 280, loss: 0.12329717725515366
step: 290, loss: 0.010225907899439335
step: 300, loss: 0.004407315514981747
step: 310, loss: 0.014311026781797409
step: 320, loss: 0.01714431867003441
step: 330, loss: 0.010053647682070732
step: 340, loss: 0.006202892865985632
step: 350, loss: 0.09843483567237854
step: 360, loss: 0.031266048550605774
step: 370, loss: 0.006116621196269989
step: 380, loss: 0.07253037393093109
step: 390, loss: 0.002582852728664875
step: 400, loss: 0.2361571192741394
step: 410, loss: 0.06033569574356079
step: 420, loss: 0.007879478856921196
step: 430, loss: 0.0016302651492878795
step: 440, loss: 0.03371322900056839
step: 450, loss: 0.03030356578528881
step: 460, loss: 0.001739862491376698
step: 470, loss: 0.0017625323962420225
step: 480, loss: 0.00055655901087448
step: 490, loss: 0.02297668159008026
step: 500, loss: 0.015430662781000137
step: 510, loss: 0.007823762483894825
step: 520, loss: 0.09359297156333923
step: 530, loss: 0.022242790088057518
step: 540, loss: 0.003188884584233165
step: 550, loss: 0.08782564848661423
step: 560, loss: 0.007101060822606087
step: 570, loss: 0.05061797425150871
step: 580, loss: 0.03403144329786301
step: 590, loss: 0.0977015271782875
step: 600, loss: 0.02471875213086605
step: 610, loss: 0.014654438942670822
step: 620, loss: 0.007271879818290472
step: 630, loss: 0.0016215810319408774
epoch 4: dev_f1=0.9430291801760075, f1=0.937847866419295, best_f1=0.93666204345816
step: 0, loss: 0.0014985048910602927
step: 10, loss: 0.004799279384315014
step: 20, loss: 0.004348858259618282
step: 30, loss: 0.0025685543660074472
step: 40, loss: 0.0007963745738379657
step: 50, loss: 0.0017210803925991058
step: 60, loss: 0.027910521253943443
step: 70, loss: 0.004065078683197498
step: 80, loss: 0.006485342048108578
step: 90, loss: 0.0422942116856575
step: 100, loss: 0.004212717059999704
step: 110, loss: 0.009509633295238018
step: 120, loss: 0.0015262544620782137
step: 130, loss: 0.003137713996693492
step: 140, loss: 0.004892949014902115
step: 150, loss: 0.0024321479722857475
step: 160, loss: 0.0010590476449579
step: 170, loss: 0.011142360046505928
step: 180, loss: 0.024204788729548454
step: 190, loss: 0.007900509051978588
step: 200, loss: 0.0023362068459391594
step: 210, loss: 0.002604232868179679
step: 220, loss: 0.0589030496776104
step: 230, loss: 0.027252553030848503
step: 240, loss: 0.1345624476671219
step: 250, loss: 0.003939660266041756
step: 260, loss: 0.0026939883828163147
step: 270, loss: 0.027343744412064552
step: 280, loss: 0.04548966512084007
step: 290, loss: 0.058914486318826675
step: 300, loss: 0.018169712275266647
step: 310, loss: 0.13094840943813324
step: 320, loss: 0.04514233022928238
step: 330, loss: 0.06242893636226654
step: 340, loss: 0.017031406983733177
step: 350, loss: 0.04211600497364998
step: 360, loss: 0.0006702959071844816
step: 370, loss: 0.0019797030836343765
step: 380, loss: 0.0015763714909553528
step: 390, loss: 0.008798103779554367
step: 400, loss: 0.015041125006973743
step: 410, loss: 0.011090156622231007
step: 420, loss: 0.0006068575894460082
step: 430, loss: 0.009866048581898212
step: 440, loss: 0.011249534785747528
step: 450, loss: 0.00617609778419137
step: 460, loss: 0.009897277690470219
step: 470, loss: 0.0010246713645756245
step: 480, loss: 0.0017374532762914896
step: 490, loss: 0.0017321392660960555
step: 500, loss: 0.002799742156639695
step: 510, loss: 0.0023841210640966892
step: 520, loss: 0.004542719107121229
step: 530, loss: 0.08774883300065994
step: 540, loss: 0.004824857693165541
step: 550, loss: 0.002712848363444209
step: 560, loss: 0.0008597680716775358
step: 570, loss: 0.0020855783950537443
step: 580, loss: 0.0008383653475902975
step: 590, loss: 0.011692870408296585
step: 600, loss: 0.005078769288957119
step: 610, loss: 0.0006050573429092765
step: 620, loss: 0.0016383019974455237
step: 630, loss: 0.0008416164782829583
epoch 5: dev_f1=0.941230911614993, f1=0.9374130737134909, best_f1=0.93666204345816
step: 0, loss: 0.025648320093750954
step: 10, loss: 0.00920949038118124
step: 20, loss: 0.023402033373713493
step: 30, loss: 0.0003251207817811519
step: 40, loss: 0.012747509405016899
step: 50, loss: 0.0012362400302663445
step: 60, loss: 0.0011561826104298234
step: 70, loss: 0.00048005813732743263
step: 80, loss: 0.009515583515167236
step: 90, loss: 0.000622284016571939
step: 100, loss: 0.00018985597125720233
step: 110, loss: 0.0009250985458493233
step: 120, loss: 0.002440453739836812
step: 130, loss: 0.001038017449900508
step: 140, loss: 0.006809644401073456
step: 150, loss: 0.003524942323565483
step: 160, loss: 0.00025204455596394837
step: 170, loss: 0.021274127066135406
step: 180, loss: 0.00031425085035152733
step: 190, loss: 0.0006960567552596331
step: 200, loss: 0.0003754240751732141
step: 210, loss: 0.01969210058450699
step: 220, loss: 0.02682846039533615
step: 230, loss: 0.00029842296498827636
step: 240, loss: 0.015253418125212193
step: 250, loss: 0.005708734504878521
step: 260, loss: 0.0043666004203259945
step: 270, loss: 0.011585760861635208
step: 280, loss: 0.001776320394128561
step: 290, loss: 0.019622530788183212
step: 300, loss: 0.02965528890490532
step: 310, loss: 0.004296476952731609
step: 320, loss: 0.008483008481562138
step: 330, loss: 0.0004956317716278136
step: 340, loss: 0.00024730400764383376
step: 350, loss: 0.0002967089822050184
step: 360, loss: 0.0012985599460080266
step: 370, loss: 0.015509022399783134
step: 380, loss: 0.020849907770752907
step: 390, loss: 0.0009536741999909282
step: 400, loss: 0.0021060744766145945
step: 410, loss: 0.12311726063489914
step: 420, loss: 0.0006143912323750556
step: 430, loss: 0.0012089274823665619
step: 440, loss: 0.0009362114942632616
step: 450, loss: 0.01120294351130724
step: 460, loss: 0.005045412108302116
step: 470, loss: 0.006031149532645941
step: 480, loss: 0.017177065834403038
step: 490, loss: 0.0032641964498907328
step: 500, loss: 0.09659585356712341
step: 510, loss: 0.01820790208876133
step: 520, loss: 0.0035278324503451586
step: 530, loss: 0.026406971737742424
step: 540, loss: 0.004132576286792755
step: 550, loss: 0.0010946865659207106
step: 560, loss: 0.06153002381324768
step: 570, loss: 0.00144430052023381
step: 580, loss: 0.0055082920007407665
step: 590, loss: 0.009078002534806728
step: 600, loss: 0.008539329282939434
step: 610, loss: 0.005638502538204193
step: 620, loss: 0.002358995145186782
step: 630, loss: 0.0002914612996391952
epoch 6: dev_f1=0.9481132075471699, f1=0.9422348484848484, best_f1=0.9422348484848484
step: 0, loss: 0.00036831386387348175
step: 10, loss: 0.0015236338367685676
step: 20, loss: 0.05517434701323509
step: 30, loss: 0.0003979711327701807
step: 40, loss: 0.00398271344602108
step: 50, loss: 0.004200188908725977
step: 60, loss: 0.008114834316074848
step: 70, loss: 0.00024269458663184196
step: 80, loss: 0.011132234707474709
step: 90, loss: 0.062400396913290024
step: 100, loss: 0.0013373368419706821
step: 110, loss: 0.08192868530750275
step: 120, loss: 0.046939026564359665
step: 130, loss: 0.008683161810040474
step: 140, loss: 0.0005739265470765531
step: 150, loss: 0.003569688182324171
step: 160, loss: 0.03394437953829765
step: 170, loss: 0.002277419902384281
step: 180, loss: 0.025785310193896294
step: 190, loss: 0.0009213267476297915
step: 200, loss: 0.004405765328556299
step: 210, loss: 0.004208887927234173
step: 220, loss: 0.0010314475512132049
step: 230, loss: 0.007684672717005014
step: 240, loss: 0.0056997621431946754
step: 250, loss: 0.002038265112787485
step: 260, loss: 0.004236406646668911
step: 270, loss: 0.00027309011784382164
step: 280, loss: 0.0002753018634393811
step: 290, loss: 0.0010611267061904073
step: 300, loss: 0.004378125071525574
step: 310, loss: 0.0039653480052948
step: 320, loss: 0.004184267483651638
step: 330, loss: 0.0004904214874841273
step: 340, loss: 0.04531722143292427
step: 350, loss: 0.0008175180410034955
step: 360, loss: 0.0003385137824807316
step: 370, loss: 0.0005016055074520409
step: 380, loss: 0.0010750662768259645
step: 390, loss: 0.04868912324309349
step: 400, loss: 0.0013279012637212873
step: 410, loss: 0.012841989286243916
step: 420, loss: 7.38790477043949e-05
step: 430, loss: 0.027387456968426704
step: 440, loss: 0.0023554819636046886
step: 450, loss: 0.009493269957602024
step: 460, loss: 0.0029563670977950096
step: 470, loss: 0.000541267974767834
step: 480, loss: 0.0018176655285060406
step: 490, loss: 8.835092739900574e-05
step: 500, loss: 0.0018352948827669024
step: 510, loss: 0.1710924208164215
step: 520, loss: 0.04005784913897514
step: 530, loss: 0.0007519720820710063
step: 540, loss: 0.0013058203039690852
step: 550, loss: 0.0013291536597535014
step: 560, loss: 0.00021099878358654678
step: 570, loss: 0.0015253224410116673
step: 580, loss: 9.894155664369464e-05
step: 590, loss: 0.0005620418814942241
step: 600, loss: 0.005808847025036812
step: 610, loss: 0.00017827404371928424
step: 620, loss: 0.0001841123157646507
step: 630, loss: 0.00041459326166659594
epoch 7: dev_f1=0.9310504396112911, f1=0.9195722919572292, best_f1=0.9422348484848484
step: 0, loss: 0.001363369170576334
step: 10, loss: 0.0007437778986059129
step: 20, loss: 0.002367231994867325
step: 30, loss: 0.0032957380171865225
step: 40, loss: 0.000398727017454803
step: 50, loss: 0.0016010347753763199
step: 60, loss: 0.0005098604597151279
step: 70, loss: 0.00030320786754600704
step: 80, loss: 0.014993752352893353
step: 90, loss: 0.0002882672124542296
step: 100, loss: 0.005824496038258076
step: 110, loss: 0.006760598160326481
step: 120, loss: 0.0065687717869877815
step: 130, loss: 0.005144454538822174
step: 140, loss: 0.002436125883832574
step: 150, loss: 0.013968974351882935
step: 160, loss: 0.00020541345293167979
step: 170, loss: 0.12634070217609406
step: 180, loss: 0.1857035905122757
step: 190, loss: 0.000816335785202682
step: 200, loss: 0.00017720375035423785
step: 210, loss: 0.001972600817680359
step: 220, loss: 0.001466506626456976
step: 230, loss: 0.014598654583096504
step: 240, loss: 0.000838138977997005
step: 250, loss: 0.00017944791761692613
step: 260, loss: 0.015766922384500504
step: 270, loss: 0.0009454951505176723
step: 280, loss: 0.0004485933459363878
step: 290, loss: 0.00486273318529129
step: 300, loss: 0.18300242722034454
step: 310, loss: 0.005261565558612347
step: 320, loss: 0.03495197743177414
step: 330, loss: 0.0003931691462639719
step: 340, loss: 0.00019571257871575654
step: 350, loss: 0.0011720774928107858
step: 360, loss: 0.0010857140878215432
step: 370, loss: 0.011275854893028736
step: 380, loss: 0.005932491738349199
step: 390, loss: 0.0005650405655615032
step: 400, loss: 0.0006819237605668604
step: 410, loss: 0.02313702180981636
step: 420, loss: 0.0023134120274335146
step: 430, loss: 0.010642318986356258
step: 440, loss: 0.057347074151039124
step: 450, loss: 0.0018349982565268874
step: 460, loss: 0.00023730791872367263
step: 470, loss: 0.0010738327400758862
step: 480, loss: 0.002351581584662199
step: 490, loss: 0.0028031538240611553
step: 500, loss: 0.0005480594700202346
step: 510, loss: 0.0006857719854451716
step: 520, loss: 0.09404999017715454
step: 530, loss: 0.0009788668248802423
step: 540, loss: 0.00035832333378493786
step: 550, loss: 0.0025300204288214445
step: 560, loss: 0.00011813499440904707
step: 570, loss: 0.003357667475938797
step: 580, loss: 0.01830943115055561
step: 590, loss: 0.000343445164617151
step: 600, loss: 0.0003664894320536405
step: 610, loss: 0.00042354303877800703
step: 620, loss: 0.0031149338465183973
step: 630, loss: 0.0026214555837213993
epoch 8: dev_f1=0.9457221711131555, f1=0.9418282548476454, best_f1=0.9422348484848484
step: 0, loss: 0.00012027483171550557
step: 10, loss: 0.008539693430066109
step: 20, loss: 0.0016839442541822791
step: 30, loss: 0.01265947800129652
step: 40, loss: 0.048816978931427
step: 50, loss: 0.00047676393296569586
step: 60, loss: 0.0010999302612617612
step: 70, loss: 0.0008959260303527117
step: 80, loss: 0.0034416525159031153
step: 90, loss: 0.0007724734605289996
step: 100, loss: 0.00015703256940469146
step: 110, loss: 0.00040123224607668817
step: 120, loss: 0.003636714071035385
step: 130, loss: 0.00305150356143713
step: 140, loss: 0.0018295544432476163
step: 150, loss: 0.0015579480677843094
step: 160, loss: 0.000124496960779652
step: 170, loss: 6.90285669406876e-05
step: 180, loss: 0.007256376091390848
step: 190, loss: 9.888542990665883e-05
step: 200, loss: 0.012324296869337559
step: 210, loss: 0.016565676778554916
step: 220, loss: 0.0006263236282393336
step: 230, loss: 0.0005243858904577792
step: 240, loss: 0.000523043388966471
step: 250, loss: 0.00011306723899906501
step: 260, loss: 0.00017210307123605162
step: 270, loss: 0.00032318319426849484
step: 280, loss: 0.0008113860385492444
step: 290, loss: 0.0020402392838150263
step: 300, loss: 0.003372844774276018
step: 310, loss: 0.0001624090800760314
step: 320, loss: 0.0006717709475196898
step: 330, loss: 0.0009130467660725117
step: 340, loss: 0.07793277502059937
step: 350, loss: 0.006165475118905306
step: 360, loss: 0.002952293958514929
step: 370, loss: 0.0008928072638809681
step: 380, loss: 0.0001420288026565686
step: 390, loss: 0.0003251239540986717
step: 400, loss: 0.0002352793380850926
step: 410, loss: 0.0002518822730053216
step: 420, loss: 7.518525671912357e-05
step: 430, loss: 0.00029832276050001383
step: 440, loss: 0.00021283990645315498
step: 450, loss: 0.0003181263746228069
step: 460, loss: 0.0036374435294419527
step: 470, loss: 0.0027437973767518997
step: 480, loss: 0.03276669979095459
step: 490, loss: 0.0016197359655052423
step: 500, loss: 8.90506271389313e-05
step: 510, loss: 0.00021825671137776226
step: 520, loss: 0.004395825322717428
step: 530, loss: 0.0002692377893254161
step: 540, loss: 0.0008457980584353209
step: 550, loss: 0.0264715738594532
step: 560, loss: 0.004987259395420551
step: 570, loss: 0.007720147725194693
step: 580, loss: 0.08835402131080627
step: 590, loss: 0.0015431432984769344
step: 600, loss: 0.004269610624760389
step: 610, loss: 0.0018037196714431047
step: 620, loss: 0.00031085748923942447
step: 630, loss: 0.0007720842259004712
epoch 9: dev_f1=0.9488714877936435, f1=0.9488243430152145, best_f1=0.9488243430152145
step: 0, loss: 0.006971205584704876
step: 10, loss: 0.013937097042798996
step: 20, loss: 0.0055481805466115475
step: 30, loss: 0.0013244292931631207
step: 40, loss: 0.0002477834059391171
step: 50, loss: 0.0044292365200817585
step: 60, loss: 0.00010934891906799749
step: 70, loss: 0.00032364821527153254
step: 80, loss: 0.0017744679935276508
step: 90, loss: 0.0011320215417072177
step: 100, loss: 0.0001536135678179562
step: 110, loss: 0.0032428752165287733
step: 120, loss: 0.0014251747634261847
step: 130, loss: 0.0032371836714446545
step: 140, loss: 0.00038461736403405666
step: 150, loss: 0.0004391124239191413
step: 160, loss: 0.0003968897508457303
step: 170, loss: 0.029599424451589584
step: 180, loss: 0.001135046943090856
step: 190, loss: 0.0021070996299386024
step: 200, loss: 0.0011335678864270449
step: 210, loss: 0.00020133264479227364
step: 220, loss: 0.0007369439699687064
step: 230, loss: 0.020848190411925316
step: 240, loss: 5.733657599193975e-05
step: 250, loss: 0.00010512820881558582
step: 260, loss: 0.0005183465545997024
step: 270, loss: 0.004763262812048197
step: 280, loss: 0.0001674976374488324
step: 290, loss: 0.0005745574017055333
step: 300, loss: 0.002883241046220064
step: 310, loss: 0.00013436192239169031
step: 320, loss: 0.0004834088613279164
step: 330, loss: 0.00043616723269224167
step: 340, loss: 0.00010184550046687946
step: 350, loss: 0.0038881655782461166
step: 360, loss: 5.4866981372470036e-05
step: 370, loss: 6.461737939389423e-05
step: 380, loss: 0.0005849659210070968
step: 390, loss: 0.0002672187692951411
step: 400, loss: 0.00027939354185946286
step: 410, loss: 6.94419359206222e-05
step: 420, loss: 3.1679144740337506e-05
step: 430, loss: 0.003834925591945648
step: 440, loss: 0.0014595018001273274
step: 450, loss: 0.00010166128049604595
step: 460, loss: 0.00037018858711235225
step: 470, loss: 0.007107576820999384
step: 480, loss: 0.0005529229529201984
step: 490, loss: 0.003288665786385536
step: 500, loss: 0.057221006602048874
step: 510, loss: 0.0005789573187939823
step: 520, loss: 0.0003633818414527923
step: 530, loss: 0.000640185025986284
step: 540, loss: 0.0020713284611701965
step: 550, loss: 0.00045589040382765234
step: 560, loss: 0.005046938080340624
step: 570, loss: 0.00017012222087942064
step: 580, loss: 0.025470932945609093
step: 590, loss: 0.00043666435522027314
step: 600, loss: 0.0007612343179062009
step: 610, loss: 0.0004351555835455656
step: 620, loss: 0.00010668499453458935
step: 630, loss: 0.00017578547704033554
epoch 10: dev_f1=0.9414455626715461, f1=0.9319945230488362, best_f1=0.9488243430152145
step: 0, loss: 0.04869595915079117
step: 10, loss: 0.007798397447913885
step: 20, loss: 0.0001285171165363863
step: 30, loss: 0.0005866152932867408
step: 40, loss: 0.010787377133965492
step: 50, loss: 0.00015512372192461044
step: 60, loss: 5.527756366063841e-05
step: 70, loss: 0.006469778250902891
step: 80, loss: 0.003633087035268545
step: 90, loss: 7.046975952107459e-05
step: 100, loss: 0.0009916117414832115
step: 110, loss: 0.00010761031444417313
step: 120, loss: 0.0003373445651959628
step: 130, loss: 0.007717034313827753
step: 140, loss: 7.54405336920172e-05
step: 150, loss: 0.0005186016205698252
step: 160, loss: 0.0002234005369246006
step: 170, loss: 0.00031141730141825974
step: 180, loss: 0.0018940254813060164
step: 190, loss: 0.00032759254099801183
step: 200, loss: 5.97762773395516e-05
step: 210, loss: 4.91711834911257e-05
step: 220, loss: 0.001380711211822927
step: 230, loss: 9.816501551540568e-05
step: 240, loss: 8.412402530666441e-05
step: 250, loss: 0.00039846147410571575
step: 260, loss: 0.0009396583773195744
step: 270, loss: 0.0029267293866723776
step: 280, loss: 0.027307596057653427
step: 290, loss: 0.08215053379535675
step: 300, loss: 0.0009750002645887434
step: 310, loss: 0.002196584828197956
step: 320, loss: 0.06457339972257614
step: 330, loss: 0.0010338391875848174
step: 340, loss: 0.0004274994716979563
step: 350, loss: 0.0002482042764313519
step: 360, loss: 0.00010885437950491905
step: 370, loss: 0.006267094053328037
step: 380, loss: 0.0018821778940036893
step: 390, loss: 0.0013146125711500645
step: 400, loss: 0.0006674874457530677
step: 410, loss: 0.00018655152234714478
step: 420, loss: 6.814342486904934e-05
step: 430, loss: 0.0001059978167177178
step: 440, loss: 0.0006927840295247734
step: 450, loss: 0.00033853325294330716
step: 460, loss: 0.0005103279836475849
step: 470, loss: 0.00018482530140317976
step: 480, loss: 0.0011936615919694304
step: 490, loss: 0.041349269449710846
step: 500, loss: 0.008327261544764042
step: 510, loss: 0.010315928608179092
step: 520, loss: 0.0037013913970440626
step: 530, loss: 0.00017037600628100336
step: 540, loss: 0.0003750455507542938
step: 550, loss: 9.836198296397924e-05
step: 560, loss: 0.00030443895957432687
step: 570, loss: 8.905114373192191e-05
step: 580, loss: 0.0003427792398724705
step: 590, loss: 0.005394877400249243
step: 600, loss: 0.0025663599371910095
step: 610, loss: 0.00023952950141392648
step: 620, loss: 0.00012512078683357686
step: 630, loss: 0.002747961785644293
epoch 11: dev_f1=0.9473197781885397, f1=0.9467345993515517, best_f1=0.9488243430152145
step: 0, loss: 0.00010391674732090905
step: 10, loss: 6.679646321572363e-05
step: 20, loss: 0.0005725579103454947
step: 30, loss: 0.00015327839355450124
step: 40, loss: 0.026668529957532883
step: 50, loss: 0.011525245383381844
step: 60, loss: 9.997432061936706e-05
step: 70, loss: 4.792700565303676e-05
step: 80, loss: 0.00015950232045724988
step: 90, loss: 0.000683698570355773
step: 100, loss: 5.426246571005322e-05
step: 110, loss: 0.00026710203383117914
step: 120, loss: 0.002019012812525034
step: 130, loss: 0.01800484023988247
step: 140, loss: 0.0013454752042889595
step: 150, loss: 0.0006149773253127933
step: 160, loss: 9.508037328487262e-05
step: 170, loss: 0.07427413761615753
step: 180, loss: 0.0008085636654868722
step: 190, loss: 0.00020068070443812758
step: 200, loss: 0.000572444696445018
step: 210, loss: 0.003218014957383275
step: 220, loss: 0.0037191282026469707
step: 230, loss: 0.004054080694913864
step: 240, loss: 0.00046264351112768054
step: 250, loss: 0.0016934697050601244
step: 260, loss: 0.0006909047951921821
step: 270, loss: 0.012790441513061523
step: 280, loss: 0.0003465857880655676
step: 290, loss: 0.00015149354294408113
step: 300, loss: 0.006971259601414204
step: 310, loss: 0.002625816036015749
step: 320, loss: 0.001716195372864604
step: 330, loss: 0.0004173539928160608
step: 340, loss: 6.761915574315935e-05
step: 350, loss: 3.5698114515980706e-05
step: 360, loss: 0.0002381173544563353
step: 370, loss: 0.00013607919390778989
step: 380, loss: 0.030808405950665474
step: 390, loss: 0.00029976508812978864
step: 400, loss: 0.0708584263920784
step: 410, loss: 0.00018325270502828062
step: 420, loss: 0.0004911480355076492
step: 430, loss: 0.00036859570536762476
step: 440, loss: 0.0007025790982879698
step: 450, loss: 0.000397704541683197
step: 460, loss: 0.00035366430529393256
step: 470, loss: 0.0033247845713049173
step: 480, loss: 0.0012323223054409027
step: 490, loss: 0.024704866111278534
step: 500, loss: 0.00015107770741451532
step: 510, loss: 0.0005219511222094297
step: 520, loss: 0.00283647608011961
step: 530, loss: 0.011418967507779598
step: 540, loss: 0.0010962339583784342
step: 550, loss: 8.33379162941128e-05
step: 560, loss: 4.8176716518355533e-05
step: 570, loss: 0.0001730365038383752
step: 580, loss: 0.00017272775585297495
step: 590, loss: 4.599264866556041e-05
step: 600, loss: 6.457488052546978e-05
step: 610, loss: 0.0019930219277739525
step: 620, loss: 0.0008512514177709818
step: 630, loss: 0.00012053368118358776
epoch 12: dev_f1=0.9479981592268752, f1=0.9478541762805722, best_f1=0.9488243430152145
step: 0, loss: 0.0021317359060049057
step: 10, loss: 6.376611418090761e-05
step: 20, loss: 0.00020242856408003718
step: 30, loss: 0.00015665525279473513
step: 40, loss: 0.0009841695427894592
step: 50, loss: 0.0006765600992366672
step: 60, loss: 0.0002845199778676033
step: 70, loss: 0.00030949857318773866
step: 80, loss: 0.00017433188622817397
step: 90, loss: 8.141452417476103e-05
step: 100, loss: 9.914244583342224e-05
step: 110, loss: 6.812490755692124e-05
step: 120, loss: 0.0003890632069669664
step: 130, loss: 0.0012083513429388404
step: 140, loss: 0.0001019502233248204
step: 150, loss: 0.000103846745332703
step: 160, loss: 5.3911819122731686e-05
step: 170, loss: 0.0011336224852129817
step: 180, loss: 0.003925737924873829
step: 190, loss: 5.9300436987541616e-05
step: 200, loss: 0.00010465909872436896
step: 210, loss: 0.00020163303997833282
step: 220, loss: 6.273342296481133e-05
step: 230, loss: 9.442737064091489e-05
step: 240, loss: 0.0005864425329491496
step: 250, loss: 8.070805051829666e-05
step: 260, loss: 3.855173781630583e-05
step: 270, loss: 0.022234316915273666
step: 280, loss: 7.488868141081184e-05
step: 290, loss: 0.0030053078662604094
step: 300, loss: 0.0009562968043610454
step: 310, loss: 0.0017410380532965064
step: 320, loss: 0.0009434553794562817
step: 330, loss: 6.080474122427404e-05
step: 340, loss: 0.012847946025431156
step: 350, loss: 8.82292224559933e-05
step: 360, loss: 0.0005165491602383554
step: 370, loss: 3.401802678126842e-05
step: 380, loss: 0.0011442675022408366
step: 390, loss: 0.035318177193403244
step: 400, loss: 0.011180579662322998
step: 410, loss: 9.848314221017063e-05
step: 420, loss: 0.0008250317769125104
step: 430, loss: 0.028997834771871567
step: 440, loss: 0.0001722742017591372
step: 450, loss: 3.5686680348590016e-05
step: 460, loss: 2.727941500779707e-05
step: 470, loss: 6.998005846980959e-05
step: 480, loss: 2.3219163267640397e-05
step: 490, loss: 3.6415884096641093e-05
step: 500, loss: 2.3766911908751354e-05
step: 510, loss: 4.658587931771763e-05
step: 520, loss: 0.00013316780677996576
step: 530, loss: 0.00019058040925301611
step: 540, loss: 0.0002733377041295171
step: 550, loss: 3.1294544896809384e-05
step: 560, loss: 0.0006901392480358481
step: 570, loss: 4.359189188107848e-05
step: 580, loss: 5.700564361177385e-05
step: 590, loss: 2.8132570150773972e-05
step: 600, loss: 0.00017043987463694066
step: 610, loss: 3.642008232418448e-05
step: 620, loss: 0.00030755094485357404
step: 630, loss: 0.00010480478522367775
epoch 13: dev_f1=0.9495136637332099, f1=0.946927374301676, best_f1=0.946927374301676
step: 0, loss: 5.9592999605229124e-05
step: 10, loss: 0.00042692842544056475
step: 20, loss: 2.2119700588518754e-05
step: 30, loss: 1.6622041584923863e-05
step: 40, loss: 1.9166345737176016e-05
step: 50, loss: 1.809347486414481e-05
step: 60, loss: 0.00041518258512951434
step: 70, loss: 5.714572762371972e-05
step: 80, loss: 3.741070395335555e-05
step: 90, loss: 0.0002726924722082913
step: 100, loss: 2.654838317539543e-05
step: 110, loss: 0.0007119777728803456
step: 120, loss: 1.9456929294392467e-05
step: 130, loss: 5.131833313498646e-05
step: 140, loss: 2.918187965406105e-05
step: 150, loss: 2.2097998225945048e-05
step: 160, loss: 2.586960545158945e-05
step: 170, loss: 0.006097950506955385
step: 180, loss: 4.012327190139331e-05
step: 190, loss: 3.4171567676821724e-05
step: 200, loss: 1.8451077266945504e-05
step: 210, loss: 2.4530436348868534e-05
step: 220, loss: 4.375275602797046e-05
step: 230, loss: 0.014704842120409012
step: 240, loss: 4.253356746630743e-05
step: 250, loss: 3.0434033760684542e-05
step: 260, loss: 0.004846276715397835
step: 270, loss: 0.00015017199621070176
step: 280, loss: 0.00010319365537725389
step: 290, loss: 3.8834263250464574e-05
step: 300, loss: 2.3707103537162766e-05
step: 310, loss: 0.004073035903275013
step: 320, loss: 5.208385846344754e-05
step: 330, loss: 9.759675594978034e-05
step: 340, loss: 0.0002048621536232531
step: 350, loss: 2.13863531826064e-05
step: 360, loss: 3.64569277735427e-05
step: 370, loss: 2.9588632969534956e-05
step: 380, loss: 1.735954538162332e-05
step: 390, loss: 2.1732572349719703e-05
step: 400, loss: 3.284770355094224e-05
step: 410, loss: 1.8998664017999545e-05
step: 420, loss: 0.00022769202769268304
step: 430, loss: 2.405368650215678e-05
step: 440, loss: 0.00024013107758946717
step: 450, loss: 0.0003324119606986642
step: 460, loss: 0.005511630326509476
step: 470, loss: 1.5202763279376086e-05
step: 480, loss: 4.381222606752999e-05
step: 490, loss: 1.7102638594224118e-05
step: 500, loss: 2.09953013836639e-05
step: 510, loss: 2.1446016035042703e-05
step: 520, loss: 0.006395504344254732
step: 530, loss: 5.130984936840832e-05
step: 540, loss: 0.0021516818087548018
step: 550, loss: 5.601999509963207e-05
step: 560, loss: 3.488135916995816e-05
step: 570, loss: 2.7885798772331327e-05
step: 580, loss: 0.003649418242275715
step: 590, loss: 1.589934436196927e-05
step: 600, loss: 0.0005337984766811132
step: 610, loss: 1.7258975276490673e-05
step: 620, loss: 0.0015453132800757885
step: 630, loss: 1.3951097571407445e-05
epoch 14: dev_f1=0.9498389323515877, f1=0.9468331021729081, best_f1=0.9468331021729081
step: 0, loss: 6.34020398138091e-05
step: 10, loss: 4.917370097246021e-05
step: 20, loss: 2.014231722569093e-05
step: 30, loss: 1.4401834960153792e-05
step: 40, loss: 1.7735837900545448e-05
step: 50, loss: 0.00030176734435372055
step: 60, loss: 1.6413465345976874e-05
step: 70, loss: 2.0674837287515402e-05
step: 80, loss: 2.2429037926485762e-05
step: 90, loss: 0.0021867547184228897
step: 100, loss: 1.5902931409073062e-05
step: 110, loss: 2.2124040697235614e-05
step: 120, loss: 7.998069486347958e-05
step: 130, loss: 5.689629688276909e-05
step: 140, loss: 2.8881207981612533e-05
step: 150, loss: 0.0003806401218753308
step: 160, loss: 0.04190724343061447
step: 170, loss: 4.089747744728811e-05
step: 180, loss: 0.00016995257465168834
step: 190, loss: 0.0019946787506341934
step: 200, loss: 0.14269010722637177
step: 210, loss: 7.259279664140195e-05
step: 220, loss: 2.565168142609764e-05
step: 230, loss: 1.8037664631265216e-05
step: 240, loss: 7.887539686635137e-05
step: 250, loss: 0.0039497786201536655
step: 260, loss: 4.526449993136339e-05
step: 270, loss: 0.0032573638018220663
step: 280, loss: 0.006410871632397175
step: 290, loss: 4.194430584902875e-05
step: 300, loss: 2.8922380806761794e-05
step: 310, loss: 0.19334393739700317
step: 320, loss: 0.0040720063261687756
step: 330, loss: 0.0026860928628593683
step: 340, loss: 0.0029502729885280132
step: 350, loss: 4.070128852617927e-05
step: 360, loss: 2.0127443349338137e-05
step: 370, loss: 2.086875610984862e-05
step: 380, loss: 0.0004797913716174662
step: 390, loss: 0.008314266800880432
step: 400, loss: 3.020384428964462e-05
step: 410, loss: 2.3476144633605145e-05
step: 420, loss: 2.1636044039041735e-05
step: 430, loss: 1.8808748791343533e-05
step: 440, loss: 0.005884308833628893
step: 450, loss: 0.0015241531655192375
step: 460, loss: 0.0005714499857276678
step: 470, loss: 9.069095540326089e-05
step: 480, loss: 0.0002192934916820377
step: 490, loss: 1.6290536223095842e-05
step: 500, loss: 2.4936543923104182e-05
step: 510, loss: 0.00010107299749506637
step: 520, loss: 0.00046121631748974323
step: 530, loss: 4.132534741074778e-05
step: 540, loss: 0.0012853004736825824
step: 550, loss: 3.642677984316833e-05
step: 560, loss: 3.0371045795618556e-05
step: 570, loss: 3.40072947437875e-05
step: 580, loss: 1.897246875159908e-05
step: 590, loss: 0.003763156710192561
step: 600, loss: 5.2124483772786334e-05
step: 610, loss: 1.712126686470583e-05
step: 620, loss: 2.0984227376175113e-05
step: 630, loss: 4.715651084552519e-05
epoch 15: dev_f1=0.9511854951185496, f1=0.9478098788443615, best_f1=0.9478098788443615
step: 0, loss: 3.1130577553994954e-05
step: 10, loss: 2.156526352337096e-05
step: 20, loss: 2.541255162213929e-05
step: 30, loss: 0.00015241651271935552
step: 40, loss: 0.00012279278598725796
step: 50, loss: 2.968546687043272e-05
step: 60, loss: 4.434818765730597e-05
step: 70, loss: 1.94941385416314e-05
step: 80, loss: 0.0006004312308505177
step: 90, loss: 5.926756057306193e-05
step: 100, loss: 5.615506597678177e-05
step: 110, loss: 4.164866913924925e-05
step: 120, loss: 6.335502257570624e-05
step: 130, loss: 7.30933461454697e-05
step: 140, loss: 0.0003959355235565454
step: 150, loss: 9.921614400809631e-05
step: 160, loss: 2.1356558136176318e-05
step: 170, loss: 0.000875201600138098
step: 180, loss: 4.3520700273802504e-05
step: 190, loss: 2.7106842026114464e-05
step: 200, loss: 0.00028142071096226573
step: 210, loss: 6.257844506762922e-05
step: 220, loss: 0.00020571608911268413
step: 230, loss: 3.0070970751694404e-05
step: 240, loss: 2.390836198173929e-05
step: 250, loss: 1.9263223293819465e-05
step: 260, loss: 3.5164866858394817e-05
step: 270, loss: 2.1349160306272097e-05
step: 280, loss: 6.694447074551135e-05
step: 290, loss: 3.350091355969198e-05
step: 300, loss: 1.7810400095186196e-05
step: 310, loss: 3.5834262234857306e-05
step: 320, loss: 1.8957625798066147e-05
step: 330, loss: 0.004976172000169754
step: 340, loss: 3.925850978703238e-05
step: 350, loss: 5.7041997933993116e-05
step: 360, loss: 0.0017467981670051813
step: 370, loss: 5.1096569222863764e-05
step: 380, loss: 2.3122367565520108e-05
step: 390, loss: 2.3550814148620702e-05
step: 400, loss: 0.00031155068427324295
step: 410, loss: 0.00026970382896251976
step: 420, loss: 0.002839888446033001
step: 430, loss: 4.791883475263603e-05
step: 440, loss: 3.884446414303966e-05
step: 450, loss: 0.00013129795843269676
step: 460, loss: 2.4079801733023487e-05
step: 470, loss: 5.6358505389653146e-05
step: 480, loss: 2.341306935704779e-05
step: 490, loss: 0.0019796183332800865
step: 500, loss: 2.704436337808147e-05
step: 510, loss: 5.388175122789107e-05
step: 520, loss: 2.954454430437181e-05
step: 530, loss: 3.0129360311548226e-05
step: 540, loss: 0.03187798336148262
step: 550, loss: 3.951990947825834e-05
step: 560, loss: 4.0544466173741966e-05
step: 570, loss: 0.0010285202879458666
step: 580, loss: 5.195473204366863e-05
step: 590, loss: 9.317572403233498e-05
step: 600, loss: 2.4385357392020524e-05
step: 610, loss: 8.24903545435518e-05
step: 620, loss: 0.0004309485957492143
step: 630, loss: 2.8750921046594158e-05
epoch 16: dev_f1=0.9498141263940519, f1=0.9478098788443615, best_f1=0.9478098788443615
step: 0, loss: 9.757607040228322e-05
step: 10, loss: 0.0027221557684242725
step: 20, loss: 0.0001692362129688263
step: 30, loss: 0.0014739502221345901
step: 40, loss: 4.029039337183349e-05
step: 50, loss: 3.8465193938463926e-05
step: 60, loss: 7.389185338979587e-05
step: 70, loss: 2.089489316858817e-05
step: 80, loss: 7.14984635123983e-05
step: 90, loss: 2.3264065021066926e-05
step: 100, loss: 2.1814970750710927e-05
step: 110, loss: 0.0001504687825217843
step: 120, loss: 0.00341094471514225
step: 130, loss: 0.00016089364362414926
step: 140, loss: 6.80820012348704e-05
step: 150, loss: 0.0010906215757131577
step: 160, loss: 3.228204514016397e-05
step: 170, loss: 1.6961086657829583e-05
step: 180, loss: 2.49588174483506e-05
step: 190, loss: 4.03079939133022e-05
step: 200, loss: 6.528146332129836e-05
step: 210, loss: 0.0002193985419580713
step: 220, loss: 2.504081385268364e-05
step: 230, loss: 0.00018915552936960012
step: 240, loss: 0.0011793107260018587
step: 250, loss: 0.0006806621677242219
step: 260, loss: 0.00029275668202899396
step: 270, loss: 0.0019129379652440548
step: 280, loss: 2.5990564608946443e-05
step: 290, loss: 0.0008154070819728076
step: 300, loss: 2.1028941773693077e-05
step: 310, loss: 0.00014392033335752785
step: 320, loss: 4.593701669364236e-05
step: 330, loss: 4.039282430312596e-05
step: 340, loss: 0.10354217141866684
step: 350, loss: 2.0049164959345944e-05
step: 360, loss: 0.00010484936501597986
step: 370, loss: 0.02263239584863186
step: 380, loss: 9.741495159687474e-05
step: 390, loss: 2.3640210201847367e-05
step: 400, loss: 2.1829748220625333e-05
step: 410, loss: 0.00037150472053326666
step: 420, loss: 2.251156183774583e-05
step: 430, loss: 0.0028271586634218693
step: 440, loss: 0.00013695996312890202
step: 450, loss: 0.024922821670770645
step: 460, loss: 4.6094726712908596e-05
step: 470, loss: 3.850557186524384e-05
step: 480, loss: 5.495726509252563e-05
step: 490, loss: 4.24494210164994e-05
step: 500, loss: 0.0007720172870904207
step: 510, loss: 3.671356898848899e-05
step: 520, loss: 0.0003262899990659207
step: 530, loss: 0.08805444091558456
step: 540, loss: 2.632978794281371e-05
step: 550, loss: 2.557731386332307e-05
step: 560, loss: 3.287436629761942e-05
step: 570, loss: 2.0369552657939494e-05
step: 580, loss: 6.1571947298944e-05
step: 590, loss: 2.8147109333076514e-05
step: 600, loss: 0.0020504866261035204
step: 610, loss: 0.000282605440588668
step: 620, loss: 6.939575541764498e-05
step: 630, loss: 2.998735726578161e-05
epoch 17: dev_f1=0.9489655172413793, f1=0.9462068965517241, best_f1=0.9478098788443615
step: 0, loss: 2.502954339433927e-05
step: 10, loss: 0.0007096670451574028
step: 20, loss: 2.7644637157209218e-05
step: 30, loss: 0.0014714235439896584
step: 40, loss: 3.160422420478426e-05
step: 50, loss: 0.00018170046678278595
step: 60, loss: 5.695363870472647e-05
step: 70, loss: 2.2518986952491105e-05
step: 80, loss: 3.2201132853515446e-05
step: 90, loss: 2.76472965197172e-05
step: 100, loss: 7.320889562834054e-05
step: 110, loss: 0.0001504682732047513
step: 120, loss: 0.0002155657857656479
step: 130, loss: 8.369731222046539e-05
step: 140, loss: 4.152619658270851e-05
step: 150, loss: 2.2630654711974785e-05
step: 160, loss: 0.0002949448535218835
step: 170, loss: 0.0010621253168210387
step: 180, loss: 0.00037472753319889307
step: 190, loss: 6.171860877657309e-05
step: 200, loss: 6.043556277290918e-05
step: 210, loss: 7.69093821872957e-05
step: 220, loss: 0.0010478782933205366
step: 230, loss: 4.930164504912682e-05
step: 240, loss: 4.696035830420442e-05
step: 250, loss: 9.100070019485429e-05
step: 260, loss: 0.01413436233997345
step: 270, loss: 3.647709672804922e-05
step: 280, loss: 2.410222077742219e-05
step: 290, loss: 0.0010100968647748232
step: 300, loss: 0.00012409577902872115
step: 310, loss: 0.0010471987770870328
step: 320, loss: 0.0026423342060297728
step: 330, loss: 3.431225195527077e-05
step: 340, loss: 0.00019488745601847768
step: 350, loss: 0.005088236648589373
step: 360, loss: 4.8352354497183114e-05
step: 370, loss: 0.00014623036258853972
step: 380, loss: 0.0001616594527149573
step: 390, loss: 0.00024857217795215547
step: 400, loss: 0.034029845148324966
step: 410, loss: 2.8985728931729682e-05
step: 420, loss: 0.0002696623851079494
step: 430, loss: 0.005790183786302805
step: 440, loss: 2.806474185490515e-05
step: 450, loss: 0.00023436166520696133
step: 460, loss: 3.165255839121528e-05
step: 470, loss: 0.0007244274602271616
step: 480, loss: 0.001972096972167492
step: 490, loss: 3.495209602988325e-05
step: 500, loss: 0.0007660340634174645
step: 510, loss: 4.196152076474391e-05
step: 520, loss: 0.0005364620592445135
step: 530, loss: 0.006802054587751627
step: 540, loss: 3.2099575037136674e-05
step: 550, loss: 3.303082485217601e-05
step: 560, loss: 2.1826108422828838e-05
step: 570, loss: 4.100708611076698e-05
step: 580, loss: 3.8785401557106525e-05
step: 590, loss: 6.981966726016253e-05
step: 600, loss: 2.0973095161025412e-05
step: 610, loss: 4.4314347178442404e-05
step: 620, loss: 0.001084167161025107
step: 630, loss: 4.042397631565109e-05
epoch 18: dev_f1=0.9467345993515517, f1=0.9439035697728326, best_f1=0.9478098788443615
step: 0, loss: 5.806702029076405e-05
step: 10, loss: 3.176391328452155e-05
step: 20, loss: 1.71026294992771e-05
step: 30, loss: 0.008697022683918476
step: 40, loss: 0.0002954755909740925
step: 50, loss: 4.4687938498100266e-05
step: 60, loss: 0.003983912989497185
step: 70, loss: 3.857604679069482e-05
step: 80, loss: 3.637836198322475e-05
step: 90, loss: 0.00012697602505795658
step: 100, loss: 4.6493289119098336e-05
step: 110, loss: 3.6393503251019865e-05
step: 120, loss: 5.4475487559102476e-05
step: 130, loss: 8.604487084085122e-05
step: 140, loss: 2.8869999368907884e-05
step: 150, loss: 4.502755109569989e-05
step: 160, loss: 0.00021437086979858577
step: 170, loss: 3.2728788937674835e-05
step: 180, loss: 0.000654359522741288
step: 190, loss: 7.458511390723288e-05
step: 200, loss: 5.2058498113183305e-05
step: 210, loss: 0.0005507845780812204
step: 220, loss: 2.930203299911227e-05
step: 230, loss: 3.2104402635013685e-05
step: 240, loss: 4.96919710712973e-05
step: 250, loss: 0.03196556866168976
step: 260, loss: 5.617166607407853e-05
step: 270, loss: 5.615869304165244e-05
step: 280, loss: 3.683748946059495e-05
step: 290, loss: 0.0028237393125891685
step: 300, loss: 5.981178765068762e-05
step: 310, loss: 6.335137004498392e-05
step: 320, loss: 0.0018195291049778461
step: 330, loss: 3.3528438507346436e-05
step: 340, loss: 0.0019090301357209682
step: 350, loss: 2.0481364117586054e-05
step: 360, loss: 0.0020159196574240923
step: 370, loss: 0.0010652969358488917
step: 380, loss: 0.0006806892924942076
step: 390, loss: 4.791629180544987e-05
step: 400, loss: 0.0014044437557458878
step: 410, loss: 0.0002324112138012424
step: 420, loss: 2.9708164220210165e-05
step: 430, loss: 6.722097168676555e-05
step: 440, loss: 2.1166544684092514e-05
step: 450, loss: 3.9703223592368886e-05
step: 460, loss: 2.668699926289264e-05
step: 470, loss: 0.0009719204972498119
step: 480, loss: 8.288784738397226e-05
step: 490, loss: 6.82707250234671e-05
step: 500, loss: 0.00019909146067220718
step: 510, loss: 0.0007017788593657315
step: 520, loss: 3.946278593502939e-05
step: 530, loss: 2.7584770577959716e-05
step: 540, loss: 0.0007112915045581758
step: 550, loss: 0.004248311277478933
step: 560, loss: 2.0976805899408646e-05
step: 570, loss: 0.008504267781972885
step: 580, loss: 4.123786493437365e-05
step: 590, loss: 0.003370052669197321
step: 600, loss: 2.3904705813038163e-05
step: 610, loss: 0.0013262712163850665
step: 620, loss: 0.0013014404103159904
step: 630, loss: 2.5092545911320485e-05
epoch 19: dev_f1=0.9488372093023255, f1=0.9454545454545454, best_f1=0.9478098788443615
step: 0, loss: 0.0003582948702387512
step: 10, loss: 2.421012322884053e-05
step: 20, loss: 3.677024142234586e-05
step: 30, loss: 0.0006711286259815097
step: 40, loss: 1.8391550838714465e-05
step: 50, loss: 1.9490471458993852e-05
step: 60, loss: 7.6879165135324e-05
step: 70, loss: 2.771894469333347e-05
step: 80, loss: 2.10251564567443e-05
step: 90, loss: 3.706433926708996e-05
step: 100, loss: 9.796355880098417e-05
step: 110, loss: 1.618250462342985e-05
step: 120, loss: 3.1822160963201895e-05
step: 130, loss: 2.351316470594611e-05
step: 140, loss: 3.417336120037362e-05
step: 150, loss: 1.9594677723944187e-05
step: 160, loss: 4.6758104872424155e-05
step: 170, loss: 2.1874469894100912e-05
step: 180, loss: 0.00013784343900624663
step: 190, loss: 1.8659737179405056e-05
step: 200, loss: 0.0001020901690935716
step: 210, loss: 1.9386121493880637e-05
step: 220, loss: 0.01759929768741131
step: 230, loss: 2.8367008781060576e-05
step: 240, loss: 0.0005127657204866409
step: 250, loss: 0.0015292977914214134
step: 260, loss: 3.481455132714473e-05
step: 270, loss: 1.5523135516559705e-05
step: 280, loss: 2.8593840397661552e-05
step: 290, loss: 3.334268694743514e-05
step: 300, loss: 1.4807893421675544e-05
step: 310, loss: 2.0101268091821112e-05
step: 320, loss: 2.6247398636769503e-05
step: 330, loss: 0.01831175573170185
step: 340, loss: 0.0001588229788467288
step: 350, loss: 0.00018345295393373817
step: 360, loss: 0.005580712575465441
step: 370, loss: 5.4606622143182904e-05
step: 380, loss: 4.4466130930231884e-05
step: 390, loss: 2.22171929635806e-05
step: 400, loss: 0.000477071589557454
step: 410, loss: 2.962952021334786e-05
step: 420, loss: 0.03894737735390663
step: 430, loss: 1.8905637261923403e-05
step: 440, loss: 3.191215364495292e-05
step: 450, loss: 2.0287649022066034e-05
step: 460, loss: 7.611743058077991e-05
step: 470, loss: 0.0034752078354358673
step: 480, loss: 0.0001472105795983225
step: 490, loss: 2.1095973352203146e-05
step: 500, loss: 1.7519800167065114e-05
step: 510, loss: 0.00010024703806266189
step: 520, loss: 1.70765688380925e-05
step: 530, loss: 2.6462963433004916e-05
step: 540, loss: 0.0006931095849722624
step: 550, loss: 3.186060712323524e-05
step: 560, loss: 4.887313116341829e-05
step: 570, loss: 2.179616058128886e-05
step: 580, loss: 2.284672882524319e-05
step: 590, loss: 3.103408380411565e-05
step: 600, loss: 0.002013900550082326
step: 610, loss: 2.9220109354355372e-05
step: 620, loss: 1.893541048048064e-05
step: 630, loss: 5.452784898807295e-05
epoch 20: dev_f1=0.9483960948396094, f1=0.9450651769087525, best_f1=0.9478098788443615
