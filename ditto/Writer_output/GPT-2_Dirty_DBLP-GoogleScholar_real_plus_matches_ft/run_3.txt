cuda
Device: cuda
step: 0, loss: 0.6895426511764526
step: 10, loss: 0.6323467493057251
step: 20, loss: 0.6516785621643066
step: 30, loss: 0.5279977321624756
step: 40, loss: 0.46743395924568176
step: 50, loss: 0.3674650192260742
step: 60, loss: 0.31332507729530334
step: 70, loss: 0.41230660676956177
step: 80, loss: 0.4849901795387268
step: 90, loss: 0.2888983488082886
step: 100, loss: 0.2865158021450043
step: 110, loss: 0.46212729811668396
step: 120, loss: 0.34760725498199463
step: 130, loss: 0.27590739727020264
step: 140, loss: 0.19260744750499725
step: 150, loss: 0.23573701083660126
step: 160, loss: 0.19452953338623047
step: 170, loss: 0.26117801666259766
step: 180, loss: 0.19550833106040955
step: 190, loss: 0.17710746824741364
step: 200, loss: 0.11105377972126007
step: 210, loss: 0.1806863397359848
step: 220, loss: 0.02922246791422367
step: 230, loss: 0.07484015077352524
step: 240, loss: 0.17981721460819244
step: 250, loss: 0.09974177181720734
step: 260, loss: 0.08256243169307709
step: 270, loss: 0.424186646938324
step: 280, loss: 0.05762931704521179
step: 290, loss: 0.1281951516866684
step: 300, loss: 0.027661478146910667
step: 310, loss: 0.36218634247779846
step: 320, loss: 0.0872483104467392
step: 330, loss: 0.14939552545547485
step: 340, loss: 0.28084704279899597
step: 350, loss: 0.050828967243433
step: 360, loss: 0.02662920206785202
step: 370, loss: 0.08085088431835175
step: 380, loss: 0.08222892135381699
step: 390, loss: 0.04362955316901207
step: 400, loss: 0.1165703535079956
step: 410, loss: 0.21098104119300842
step: 420, loss: 0.1743302047252655
step: 430, loss: 0.059515293687582016
step: 440, loss: 0.12070731073617935
step: 450, loss: 0.11374098807573318
step: 460, loss: 0.24743101000785828
step: 470, loss: 0.17039906978607178
step: 480, loss: 0.0862068235874176
step: 490, loss: 0.05263213440775871
step: 500, loss: 0.07494105398654938
step: 510, loss: 0.12732888758182526
step: 520, loss: 0.052549466490745544
step: 530, loss: 0.1525210291147232
step: 540, loss: 0.09753742069005966
step: 550, loss: 0.13859690725803375
step: 560, loss: 0.041326384991407394
step: 570, loss: 0.133907750248909
step: 580, loss: 0.07259013503789902
step: 590, loss: 0.04725411906838417
step: 600, loss: 0.08231490850448608
step: 610, loss: 0.1942867487668991
step: 620, loss: 0.08470477163791656
step: 630, loss: 0.14615970849990845
epoch 1: dev_f1=0.9401392111368909, f1=0.9447282861124013, best_f1=0.9447282861124013
step: 0, loss: 0.055370599031448364
step: 10, loss: 0.06020401045680046
step: 20, loss: 0.08961457759141922
step: 30, loss: 0.08589006215333939
step: 40, loss: 0.01005252543836832
step: 50, loss: 0.007777925115078688
step: 60, loss: 0.05626975744962692
step: 70, loss: 0.11867526918649673
step: 80, loss: 0.04924444481730461
step: 90, loss: 0.044600676745176315
step: 100, loss: 0.04615493491292
step: 110, loss: 0.0883450135588646
step: 120, loss: 0.035926785320043564
step: 130, loss: 0.08756428211927414
step: 140, loss: 0.03931903466582298
step: 150, loss: 0.13308273255825043
step: 160, loss: 0.05321388319134712
step: 170, loss: 0.09652741998434067
step: 180, loss: 0.0159345380961895
step: 190, loss: 0.02841583453118801
step: 200, loss: 0.006321189925074577
step: 210, loss: 0.03665786609053612
step: 220, loss: 0.09192521870136261
step: 230, loss: 0.07766352593898773
step: 240, loss: 0.01108458824455738
step: 250, loss: 0.090430349111557
step: 260, loss: 0.05987616628408432
step: 270, loss: 0.045683376491069794
step: 280, loss: 0.09142139554023743
step: 290, loss: 0.09359799325466156
step: 300, loss: 0.05160733312368393
step: 310, loss: 0.008181696757674217
step: 320, loss: 0.14903762936592102
step: 330, loss: 0.015733815729618073
step: 340, loss: 0.17281490564346313
step: 350, loss: 0.043828897178173065
step: 360, loss: 0.03617975488305092
step: 370, loss: 0.17509223520755768
step: 380, loss: 0.02850854955613613
step: 390, loss: 0.06402850151062012
step: 400, loss: 0.07916932553052902
step: 410, loss: 0.032218385487794876
step: 420, loss: 0.20459416508674622
step: 430, loss: 0.023573365062475204
step: 440, loss: 0.03205951675772667
step: 450, loss: 0.02392672188580036
step: 460, loss: 0.02606211230158806
step: 470, loss: 0.07439025491476059
step: 480, loss: 0.22581154108047485
step: 490, loss: 0.11351235210895538
step: 500, loss: 0.03320515155792236
step: 510, loss: 0.05519133061170578
step: 520, loss: 0.04845768213272095
step: 530, loss: 0.0944385975599289
step: 540, loss: 0.0168837308883667
step: 550, loss: 0.05448152497410774
step: 560, loss: 0.0537794828414917
step: 570, loss: 0.020120033994317055
step: 580, loss: 0.11292748898267746
step: 590, loss: 0.1828879565000534
step: 600, loss: 0.12439766526222229
step: 610, loss: 0.02232985943555832
step: 620, loss: 0.05225555598735809
step: 630, loss: 0.013461083173751831
epoch 2: dev_f1=0.9456221198156683, f1=0.9401392111368909, best_f1=0.9401392111368909
step: 0, loss: 0.002910899231210351
step: 10, loss: 0.02519405633211136
step: 20, loss: 0.043631237000226974
step: 30, loss: 0.1258367896080017
step: 40, loss: 0.012159816920757294
step: 50, loss: 0.05644489824771881
step: 60, loss: 0.07311751693487167
step: 70, loss: 0.015429627150297165
step: 80, loss: 0.023945819586515427
step: 90, loss: 0.16239313781261444
step: 100, loss: 0.18051718175411224
step: 110, loss: 0.05026502534747124
step: 120, loss: 0.22688978910446167
step: 130, loss: 0.02990022487938404
step: 140, loss: 0.04827151820063591
step: 150, loss: 0.05372294411063194
step: 160, loss: 0.0723898783326149
step: 170, loss: 0.026022618636488914
step: 180, loss: 0.013387983664870262
step: 190, loss: 0.1718820184469223
step: 200, loss: 0.008594433777034283
step: 210, loss: 0.006175586953759193
step: 220, loss: 0.043049588799476624
step: 230, loss: 0.003448449308052659
step: 240, loss: 0.011299826204776764
step: 250, loss: 0.009084728546440601
step: 260, loss: 0.00764112826436758
step: 270, loss: 0.022583993151783943
step: 280, loss: 0.04634915664792061
step: 290, loss: 0.0037522308994084597
step: 300, loss: 0.08507296442985535
step: 310, loss: 0.031289175152778625
step: 320, loss: 0.010895603336393833
step: 330, loss: 0.0881558284163475
step: 340, loss: 0.11589448153972626
step: 350, loss: 0.032816436141729355
step: 360, loss: 0.18334974348545074
step: 370, loss: 0.042488373816013336
step: 380, loss: 0.022996626794338226
step: 390, loss: 0.007442552130669355
step: 400, loss: 0.04109745845198631
step: 410, loss: 0.08994188904762268
step: 420, loss: 0.004520281217992306
step: 430, loss: 0.0450328029692173
step: 440, loss: 0.15498660504817963
step: 450, loss: 0.014933009631931782
step: 460, loss: 0.12356563657522202
step: 470, loss: 0.02761255018413067
step: 480, loss: 0.10516972094774246
step: 490, loss: 0.0057594976387917995
step: 500, loss: 0.0026453216560184956
step: 510, loss: 0.009373718872666359
step: 520, loss: 0.07158928364515305
step: 530, loss: 0.033681049942970276
step: 540, loss: 0.006971502676606178
step: 550, loss: 0.009151442907750607
step: 560, loss: 0.02949698641896248
step: 570, loss: 0.004505520220845938
step: 580, loss: 0.18179447948932648
step: 590, loss: 0.009626945480704308
step: 600, loss: 0.012835499830543995
step: 610, loss: 0.05338926240801811
step: 620, loss: 0.014446807093918324
step: 630, loss: 0.010028203949332237
epoch 3: dev_f1=0.9509259259259258, f1=0.9406264609630668, best_f1=0.9406264609630668
step: 0, loss: 0.0039534796960651875
step: 10, loss: 0.006364195607602596
step: 20, loss: 0.0016617369838058949
step: 30, loss: 0.03459968417882919
step: 40, loss: 0.0034895127173513174
step: 50, loss: 0.234910786151886
step: 60, loss: 0.0016722952714189887
step: 70, loss: 0.0016006738878786564
step: 80, loss: 0.005173491779714823
step: 90, loss: 0.021027904003858566
step: 100, loss: 0.011640634387731552
step: 110, loss: 0.024637708440423012
step: 120, loss: 0.01167209167033434
step: 130, loss: 0.22111518681049347
step: 140, loss: 0.05132781341671944
step: 150, loss: 0.13494472205638885
step: 160, loss: 0.12747439742088318
step: 170, loss: 0.025315331295132637
step: 180, loss: 0.0017731323605403304
step: 190, loss: 0.0006049670046195388
step: 200, loss: 0.12380067259073257
step: 210, loss: 0.002211210085079074
step: 220, loss: 0.02607434242963791
step: 230, loss: 0.005087861325591803
step: 240, loss: 0.15282276272773743
step: 250, loss: 0.005020317155867815
step: 260, loss: 0.030832527205348015
step: 270, loss: 0.00391954043880105
step: 280, loss: 0.0009604414226487279
step: 290, loss: 0.03283778205513954
step: 300, loss: 0.0033111991360783577
step: 310, loss: 0.016947954893112183
step: 320, loss: 0.026363607496023178
step: 330, loss: 0.005767520982772112
step: 340, loss: 0.09245549887418747
step: 350, loss: 0.002085823565721512
step: 360, loss: 0.008919579908251762
step: 370, loss: 0.007596871349960566
step: 380, loss: 0.020636336877942085
step: 390, loss: 0.0018377016531303525
step: 400, loss: 0.009387032128870487
step: 410, loss: 0.0013196357758715749
step: 420, loss: 0.20030851662158966
step: 430, loss: 0.018085284158587456
step: 440, loss: 0.028977127745747566
step: 450, loss: 0.05158870294690132
step: 460, loss: 0.0022967332042753696
step: 470, loss: 0.022536640986800194
step: 480, loss: 0.04375319927930832
step: 490, loss: 0.030163178220391273
step: 500, loss: 0.01013884972780943
step: 510, loss: 0.03864981606602669
step: 520, loss: 0.007878362201154232
step: 530, loss: 0.011024478822946548
step: 540, loss: 0.2178223878145218
step: 550, loss: 0.026890074834227562
step: 560, loss: 0.2297351360321045
step: 570, loss: 0.012150797061622143
step: 580, loss: 0.11535326391458511
step: 590, loss: 0.10989009588956833
step: 600, loss: 0.005360012874007225
step: 610, loss: 0.045693617314100266
step: 620, loss: 0.0072824121452867985
step: 630, loss: 0.0007199868559837341
epoch 4: dev_f1=0.9521575984990619, f1=0.9402352941176471, best_f1=0.9402352941176471
step: 0, loss: 0.0028770549688488245
step: 10, loss: 0.011040613986551762
step: 20, loss: 0.002511997940018773
step: 30, loss: 0.006487242877483368
step: 40, loss: 0.002324520144611597
step: 50, loss: 0.0010251502972096205
step: 60, loss: 0.007841641083359718
step: 70, loss: 0.0012147671077400446
step: 80, loss: 0.001981842564418912
step: 90, loss: 0.0797218531370163
step: 100, loss: 0.02559923753142357
step: 110, loss: 0.006311821285635233
step: 120, loss: 0.0020058918744325638
step: 130, loss: 0.010154463350772858
step: 140, loss: 0.002809210680425167
step: 150, loss: 0.010285288095474243
step: 160, loss: 0.015915630385279655
step: 170, loss: 0.0021689063869416714
step: 180, loss: 0.001243742648512125
step: 190, loss: 0.021839605644345284
step: 200, loss: 0.043149255216121674
step: 210, loss: 0.0011179755674675107
step: 220, loss: 0.003826185129582882
step: 230, loss: 0.13874775171279907
step: 240, loss: 0.0014079110696911812
step: 250, loss: 0.06548157334327698
step: 260, loss: 0.0025222015101462603
step: 270, loss: 0.018736064434051514
step: 280, loss: 0.0021001326385885477
step: 290, loss: 0.007752455770969391
step: 300, loss: 0.10622318089008331
step: 310, loss: 0.0057105980813503265
step: 320, loss: 0.002272551879286766
step: 330, loss: 0.09590192139148712
step: 340, loss: 0.0052452655509114265
step: 350, loss: 0.003446943825110793
step: 360, loss: 0.003350538434460759
step: 370, loss: 0.004910135176032782
step: 380, loss: 0.047792401164770126
step: 390, loss: 0.03436988592147827
step: 400, loss: 0.001722119515761733
step: 410, loss: 0.019296754151582718
step: 420, loss: 0.033432427793741226
step: 430, loss: 0.005901638884097338
step: 440, loss: 0.00047520367661491036
step: 450, loss: 0.003024548990651965
step: 460, loss: 0.023584144189953804
step: 470, loss: 0.08378247916698456
step: 480, loss: 0.03218739852309227
step: 490, loss: 0.00030983169563114643
step: 500, loss: 0.0025337841361761093
step: 510, loss: 0.09943842887878418
step: 520, loss: 0.0008130685891956091
step: 530, loss: 0.00576191209256649
step: 540, loss: 0.021604212000966072
step: 550, loss: 0.013463935814797878
step: 560, loss: 0.07713954895734787
step: 570, loss: 0.025643279775977135
step: 580, loss: 0.0009983781492337584
step: 590, loss: 0.008647928945720196
step: 600, loss: 0.2210579216480255
step: 610, loss: 0.004006839357316494
step: 620, loss: 0.08512302488088608
step: 630, loss: 0.011755023151636124
epoch 5: dev_f1=0.939282428702852, f1=0.9333950046253469, best_f1=0.9402352941176471
step: 0, loss: 0.002399669960141182
step: 10, loss: 0.0027333167381584644
step: 20, loss: 0.004572021774947643
step: 30, loss: 0.003910690546035767
step: 40, loss: 0.001281872158870101
step: 50, loss: 0.0018230181885883212
step: 60, loss: 0.00021832092897966504
step: 70, loss: 0.0011850305600091815
step: 80, loss: 0.0007157747750170529
step: 90, loss: 0.0002882232947740704
step: 100, loss: 0.1704709678888321
step: 110, loss: 0.0012156206648796797
step: 120, loss: 0.006556694395840168
step: 130, loss: 0.00034086123923771083
step: 140, loss: 0.010770964436233044
step: 150, loss: 0.000643536914139986
step: 160, loss: 0.00014021233073435724
step: 170, loss: 0.0004842319176532328
step: 180, loss: 0.004454413428902626
step: 190, loss: 0.003360455622896552
step: 200, loss: 0.004602368921041489
step: 210, loss: 0.0015739038353785872
step: 220, loss: 0.0009665872785262764
step: 230, loss: 0.0003301297838333994
step: 240, loss: 0.00016653061902616173
step: 250, loss: 0.0006322533590719104
step: 260, loss: 0.0003428514755796641
step: 270, loss: 0.013708182610571384
step: 280, loss: 0.0011383823584765196
step: 290, loss: 0.004583149682730436
step: 300, loss: 0.1208663284778595
step: 310, loss: 0.004945551976561546
step: 320, loss: 0.0006860806024633348
step: 330, loss: 0.0002918207901529968
step: 340, loss: 0.00175119296181947
step: 350, loss: 0.011888588778674603
step: 360, loss: 0.000808400334790349
step: 370, loss: 0.03857223689556122
step: 380, loss: 0.029218006879091263
step: 390, loss: 0.0034449640661478043
step: 400, loss: 0.005827590357512236
step: 410, loss: 0.0011976637179031968
step: 420, loss: 0.00043072880362160504
step: 430, loss: 0.0016716066747903824
step: 440, loss: 0.0016491092974320054
step: 450, loss: 0.0071284836158156395
step: 460, loss: 0.021971767768263817
step: 470, loss: 0.002267456380650401
step: 480, loss: 0.001174079137854278
step: 490, loss: 0.003359900787472725
step: 500, loss: 0.01721894182264805
step: 510, loss: 0.004506450146436691
step: 520, loss: 0.005061508622020483
step: 530, loss: 0.0014846401754766703
step: 540, loss: 0.20344528555870056
step: 550, loss: 0.0750964879989624
step: 560, loss: 0.02238452434539795
step: 570, loss: 0.004610871896147728
step: 580, loss: 0.08750364184379578
step: 590, loss: 0.001094054663553834
step: 600, loss: 0.07137782126665115
step: 610, loss: 0.0005854280898347497
step: 620, loss: 0.007002259138971567
step: 630, loss: 0.00036154978442937136
epoch 6: dev_f1=0.934640522875817, f1=0.9323237103644108, best_f1=0.9402352941176471
step: 0, loss: 0.03258858993649483
step: 10, loss: 0.030715301632881165
step: 20, loss: 0.0004798683221451938
step: 30, loss: 0.012704206630587578
step: 40, loss: 0.0039845677092671394
step: 50, loss: 0.0025264418218284845
step: 60, loss: 0.0031160118523985147
step: 70, loss: 0.0003333953791297972
step: 80, loss: 0.00028794590616598725
step: 90, loss: 0.0013064454542472959
step: 100, loss: 0.0028483830392360687
step: 110, loss: 0.0007558060460723937
step: 120, loss: 0.004274129867553711
step: 130, loss: 0.00019407228683121502
step: 140, loss: 0.0019017840968444943
step: 150, loss: 0.0011637938441708684
step: 160, loss: 8.722825441509485e-05
step: 170, loss: 0.0013258613180369139
step: 180, loss: 0.0005445490824058652
step: 190, loss: 0.07950156927108765
step: 200, loss: 0.0006129133980721235
step: 210, loss: 0.0006477551651187241
step: 220, loss: 0.0018500193255022168
step: 230, loss: 0.00029569861362688243
step: 240, loss: 0.028601523488759995
step: 250, loss: 0.0002517630928196013
step: 260, loss: 0.006880653090775013
step: 270, loss: 0.0003800759732257575
step: 280, loss: 0.000943692575674504
step: 290, loss: 0.14252446591854095
step: 300, loss: 0.07461944222450256
step: 310, loss: 0.0010172227630391717
step: 320, loss: 0.06348079442977905
step: 330, loss: 0.053877923637628555
step: 340, loss: 0.00099737080745399
step: 350, loss: 0.0055093225091695786
step: 360, loss: 0.02181391231715679
step: 370, loss: 0.020139139145612717
step: 380, loss: 0.02382475882768631
step: 390, loss: 0.0017058176454156637
step: 400, loss: 0.004609479568898678
step: 410, loss: 0.01098885852843523
step: 420, loss: 0.003578628646209836
step: 430, loss: 0.0005803131498396397
step: 440, loss: 0.00685315765440464
step: 450, loss: 0.0008859724621288478
step: 460, loss: 0.0005181385204195976
step: 470, loss: 0.006864615716040134
step: 480, loss: 0.0012766094878315926
step: 490, loss: 0.0017045574495568871
step: 500, loss: 0.10596427321434021
step: 510, loss: 0.00022648378217127174
step: 520, loss: 0.00036553313839249313
step: 530, loss: 0.024536654353141785
step: 540, loss: 0.002151387045159936
step: 550, loss: 0.005982177797704935
step: 560, loss: 0.00041909748688340187
step: 570, loss: 0.000639198231510818
step: 580, loss: 0.0031851879321038723
step: 590, loss: 0.06222258880734444
step: 600, loss: 0.0022081416100263596
step: 610, loss: 0.0020341251511126757
step: 620, loss: 0.03871268779039383
step: 630, loss: 0.0003820275596808642
epoch 7: dev_f1=0.9405045216563541, f1=0.9307214524605829, best_f1=0.9402352941176471
step: 0, loss: 0.0004531168669927865
step: 10, loss: 0.0014645812334492803
step: 20, loss: 0.00014234526315703988
step: 30, loss: 0.00026314466958865523
step: 40, loss: 0.008787842467427254
step: 50, loss: 0.0010808843653649092
step: 60, loss: 0.0004641160776372999
step: 70, loss: 0.0006199316121637821
step: 80, loss: 0.0001430968550266698
step: 90, loss: 0.0018865568563342094
step: 100, loss: 0.00019678556418512017
step: 110, loss: 0.0007655477966181934
step: 120, loss: 0.00012675841571763158
step: 130, loss: 0.0004653213545680046
step: 140, loss: 0.00016085691459011286
step: 150, loss: 0.00012599170440807939
step: 160, loss: 0.09731204807758331
step: 170, loss: 0.0001012972352327779
step: 180, loss: 0.00023015300394035876
step: 190, loss: 0.00011837231431854889
step: 200, loss: 0.0003507385263219476
step: 210, loss: 0.002300508553162217
step: 220, loss: 0.0004272573278285563
step: 230, loss: 0.05488209426403046
step: 240, loss: 0.10057796537876129
step: 250, loss: 0.009576965123414993
step: 260, loss: 0.0009264611289836466
step: 270, loss: 0.003825099440291524
step: 280, loss: 0.0040021319873631
step: 290, loss: 0.020129671320319176
step: 300, loss: 0.0006003013695590198
step: 310, loss: 0.0007043443038128316
step: 320, loss: 0.000285350251942873
step: 330, loss: 0.09271463006734848
step: 340, loss: 0.0025310020428150892
step: 350, loss: 0.0024388665333390236
step: 360, loss: 0.0006301365792751312
step: 370, loss: 0.0010658686514943838
step: 380, loss: 0.003157487139105797
step: 390, loss: 0.0010568585712462664
step: 400, loss: 0.00014806081890128553
step: 410, loss: 0.001666524331085384
step: 420, loss: 0.000651053967885673
step: 430, loss: 0.00025378153077326715
step: 440, loss: 0.00021655431191902608
step: 450, loss: 0.0007517135818488896
step: 460, loss: 0.002564377384260297
step: 470, loss: 7.452194404322654e-05
step: 480, loss: 0.00010378032311564311
step: 490, loss: 0.007315259892493486
step: 500, loss: 9.647278056945652e-05
step: 510, loss: 0.0008686523651704192
step: 520, loss: 0.00014477336662821472
step: 530, loss: 7.603248377563432e-05
step: 540, loss: 0.04989229515194893
step: 550, loss: 0.0016482092905789614
step: 560, loss: 0.0033537521958351135
step: 570, loss: 0.0008225574856624007
step: 580, loss: 0.036234255880117416
step: 590, loss: 0.00701600406318903
step: 600, loss: 0.0003409826604183763
step: 610, loss: 0.000677680189255625
step: 620, loss: 0.0070429276674985886
step: 630, loss: 0.0004755547270178795
epoch 8: dev_f1=0.9353932584269663, f1=0.9265054528212423, best_f1=0.9402352941176471
step: 0, loss: 0.10702083259820938
step: 10, loss: 0.0009017559932544827
step: 20, loss: 0.0019934307783842087
step: 30, loss: 0.0017551254713907838
step: 40, loss: 0.0019780348520725965
step: 50, loss: 0.001969912787899375
step: 60, loss: 0.0009087368962354958
step: 70, loss: 0.0016548327403143048
step: 80, loss: 0.010180676355957985
step: 90, loss: 0.0008540181443095207
step: 100, loss: 0.0012187917018309236
step: 110, loss: 0.0016176104545593262
step: 120, loss: 0.011959229595959187
step: 130, loss: 0.014740659855306149
step: 140, loss: 0.00834659580141306
step: 150, loss: 0.00014324333460535854
step: 160, loss: 0.00011689751408994198
step: 170, loss: 0.06049729138612747
step: 180, loss: 0.0940551608800888
step: 190, loss: 0.002686884719878435
step: 200, loss: 0.012794246897101402
step: 210, loss: 0.0007532856543548405
step: 220, loss: 0.0009310654131695628
step: 230, loss: 0.0002074235089821741
step: 240, loss: 0.0012161304475739598
step: 250, loss: 0.00015268287097569555
step: 260, loss: 0.014003763906657696
step: 270, loss: 0.0008218602160923183
step: 280, loss: 0.0005481017869897187
step: 290, loss: 0.00013703682634513825
step: 300, loss: 0.0014861603267490864
step: 310, loss: 0.00013318326091393828
step: 320, loss: 0.000592998752836138
step: 330, loss: 0.0003888998762704432
step: 340, loss: 0.00046095476136542857
step: 350, loss: 0.018452925607562065
step: 360, loss: 0.0008813480962999165
step: 370, loss: 0.00012465428153518587
step: 380, loss: 0.0005433570477180183
step: 390, loss: 0.03894006088376045
step: 400, loss: 0.018368292599916458
step: 410, loss: 0.005195874720811844
step: 420, loss: 0.0007110302685759962
step: 430, loss: 8.228271326515824e-05
step: 440, loss: 0.0004442426434252411
step: 450, loss: 0.0001319915900239721
step: 460, loss: 0.003671413753181696
step: 470, loss: 0.0010387543588876724
step: 480, loss: 0.03477266803383827
step: 490, loss: 9.60993638727814e-05
step: 500, loss: 0.0007123829564079642
step: 510, loss: 0.004161339718848467
step: 520, loss: 0.02637666091322899
step: 530, loss: 0.013093885034322739
step: 540, loss: 0.004348566755652428
step: 550, loss: 0.0067916251718997955
step: 560, loss: 0.0011698893504217267
step: 570, loss: 0.0001798335142666474
step: 580, loss: 0.0024855746887624264
step: 590, loss: 0.00012307307042647153
step: 600, loss: 0.019832171499729156
step: 610, loss: 0.001476538716815412
step: 620, loss: 0.0012204875238239765
step: 630, loss: 0.00033752183662727475
epoch 9: dev_f1=0.9452830188679245, f1=0.9345351043643263, best_f1=0.9402352941176471
step: 0, loss: 0.0006961542530916631
step: 10, loss: 0.0003811840433627367
step: 20, loss: 0.0009937216527760029
step: 30, loss: 0.00012469135981518775
step: 40, loss: 0.0001435651065548882
step: 50, loss: 0.00041852801223285496
step: 60, loss: 0.00036556931445375085
step: 70, loss: 0.00033507522311992943
step: 80, loss: 0.0030030806083232164
step: 90, loss: 0.00022740097483620048
step: 100, loss: 0.0004773815453518182
step: 110, loss: 0.002289200434461236
step: 120, loss: 0.0024260717909783125
step: 130, loss: 0.029531246051192284
step: 140, loss: 0.00028569181449711323
step: 150, loss: 0.020944681018590927
step: 160, loss: 0.00028683413984254
step: 170, loss: 0.0002541246067266911
step: 180, loss: 0.00012800449621863663
step: 190, loss: 0.001290466752834618
step: 200, loss: 0.006032629869878292
step: 210, loss: 0.00015583208005409688
step: 220, loss: 0.008456161245703697
step: 230, loss: 8.343460649484769e-05
step: 240, loss: 0.00033026185701601207
step: 250, loss: 0.00020534147915896028
step: 260, loss: 0.044000010937452316
step: 270, loss: 0.011417227797210217
step: 280, loss: 5.693065395462327e-05
step: 290, loss: 0.00013294069503899664
step: 300, loss: 8.270163380075246e-05
step: 310, loss: 0.00025728470063768327
step: 320, loss: 0.000700738572049886
step: 330, loss: 0.0018938059220090508
step: 340, loss: 0.0008644930785521865
step: 350, loss: 0.0006936874706298113
step: 360, loss: 6.547694647451863e-05
step: 370, loss: 0.0008115449454635382
step: 380, loss: 0.0007834756979718804
step: 390, loss: 0.042093101888895035
step: 400, loss: 0.0002507330500520766
step: 410, loss: 0.00015795871149748564
step: 420, loss: 0.0038643903099000454
step: 430, loss: 0.0001572389155626297
step: 440, loss: 0.00022424403869081289
step: 450, loss: 0.0033706019166857004
step: 460, loss: 0.00019836788123939186
step: 470, loss: 0.00011190114310011268
step: 480, loss: 0.00154116190969944
step: 490, loss: 0.0007749598007649183
step: 500, loss: 0.00015256997721735388
step: 510, loss: 0.0002284492366015911
step: 520, loss: 0.0006847743643447757
step: 530, loss: 0.00021593656856566668
step: 540, loss: 0.00017192841914948076
step: 550, loss: 0.0002871391479857266
step: 560, loss: 0.004897448234260082
step: 570, loss: 0.0005405994015745819
step: 580, loss: 0.0007337395800277591
step: 590, loss: 0.00013014045543968678
step: 600, loss: 0.006160676013678312
step: 610, loss: 0.0016630633035674691
step: 620, loss: 0.0054359580390155315
step: 630, loss: 0.17259380221366882
epoch 10: dev_f1=0.9496470588235294, f1=0.9368520263901979, best_f1=0.9402352941176471
step: 0, loss: 0.0003134762228000909
step: 10, loss: 0.009903001599013805
step: 20, loss: 0.009474609978497028
step: 30, loss: 0.0003890084335580468
step: 40, loss: 0.00017157293041236699
step: 50, loss: 0.012049848213791847
step: 60, loss: 0.00035900797229260206
step: 70, loss: 0.0025227791629731655
step: 80, loss: 0.00016523932572454214
step: 90, loss: 0.00016998467617668211
step: 100, loss: 0.00014971359632909298
step: 110, loss: 6.362301064655185e-05
step: 120, loss: 0.00015641914797015488
step: 130, loss: 0.0001739480358082801
step: 140, loss: 0.00011531339259818196
step: 150, loss: 7.343032484641299e-05
step: 160, loss: 0.0020214810501784086
step: 170, loss: 0.04511534050107002
step: 180, loss: 0.0010589977027848363
step: 190, loss: 0.00024271795700769871
step: 200, loss: 0.00046528971870429814
step: 210, loss: 0.025515116751194
step: 220, loss: 5.8476158301346004e-05
step: 230, loss: 9.38335942919366e-05
step: 240, loss: 0.0011220384621992707
step: 250, loss: 0.01860363781452179
step: 260, loss: 0.00010648062016116455
step: 270, loss: 0.0012166328961029649
step: 280, loss: 0.0002918950922321528
step: 290, loss: 0.0002559682761784643
step: 300, loss: 0.0012270316947251558
step: 310, loss: 0.005524922162294388
step: 320, loss: 0.00032375389127992094
step: 330, loss: 0.00022294200607575476
step: 340, loss: 0.00023232355306390673
step: 350, loss: 0.00015738321235403419
step: 360, loss: 0.00013545532419811934
step: 370, loss: 0.029305672273039818
step: 380, loss: 5.414334373199381e-05
step: 390, loss: 0.0005605873302556574
step: 400, loss: 0.00010556833876762539
step: 410, loss: 0.0009399429545737803
step: 420, loss: 0.0022560947109013796
step: 430, loss: 0.0028803313616663218
step: 440, loss: 0.13192519545555115
step: 450, loss: 0.00019936799071729183
step: 460, loss: 0.0002551064535509795
step: 470, loss: 0.00020335034059826285
step: 480, loss: 0.0017314061988145113
step: 490, loss: 0.0036588346119970083
step: 500, loss: 0.0001695932005532086
step: 510, loss: 0.00028834500699304044
step: 520, loss: 6.790853512939066e-05
step: 530, loss: 0.0008182030287571251
step: 540, loss: 0.0005214149714447558
step: 550, loss: 0.006106805521994829
step: 560, loss: 0.00017346523236483335
step: 570, loss: 0.0013747313059866428
step: 580, loss: 0.008600986562669277
step: 590, loss: 0.0066459812223911285
step: 600, loss: 0.00038819442852400243
step: 610, loss: 0.00015356764197349548
step: 620, loss: 0.000280898530036211
step: 630, loss: 0.0008053086930885911
epoch 11: dev_f1=0.9483167377904219, f1=0.9384835479256081, best_f1=0.9402352941176471
step: 0, loss: 0.00012844146112911403
step: 10, loss: 0.027047816663980484
step: 20, loss: 0.00028294933144934475
step: 30, loss: 0.002672820817679167
step: 40, loss: 0.0009826060850173235
step: 50, loss: 0.000956038071308285
step: 60, loss: 0.00028321921126917005
step: 70, loss: 0.001094707869924605
step: 80, loss: 0.00017594963719602674
step: 90, loss: 0.09290013462305069
step: 100, loss: 0.00022032627020962536
step: 110, loss: 0.000543213274795562
step: 120, loss: 0.008434000425040722
step: 130, loss: 0.0009059945587068796
step: 140, loss: 0.00030984822660684586
step: 150, loss: 0.00044810250983573496
step: 160, loss: 8.9199747890234e-05
step: 170, loss: 0.00017210653459187597
step: 180, loss: 0.0003248079738114029
step: 190, loss: 0.13688133656978607
step: 200, loss: 0.0013975704787299037
step: 210, loss: 0.00015240622451528907
step: 220, loss: 0.00047470771824009717
step: 230, loss: 0.0003503147454466671
step: 240, loss: 0.00014375954924616963
step: 250, loss: 0.002469685859978199
step: 260, loss: 0.00045611977111548185
step: 270, loss: 9.232730371877551e-05
step: 280, loss: 0.00016845003119669855
step: 290, loss: 0.0018369742901995778
step: 300, loss: 0.00032607882167212665
step: 310, loss: 0.00017167264013551176
step: 320, loss: 6.574623694177717e-05
step: 330, loss: 0.00020545924780890346
step: 340, loss: 5.478551611304283e-05
step: 350, loss: 0.00010403349733678624
step: 360, loss: 0.0053910501301288605
step: 370, loss: 0.0001643452123971656
step: 380, loss: 0.00015077655552886426
step: 390, loss: 0.00015022447041701525
step: 400, loss: 0.0004984070546925068
step: 410, loss: 0.03546247258782387
step: 420, loss: 0.0003737170482054353
step: 430, loss: 0.0011329231783747673
step: 440, loss: 0.00012570814578793943
step: 450, loss: 0.004055151715874672
step: 460, loss: 0.00041113150655291975
step: 470, loss: 0.00013501598732545972
step: 480, loss: 0.00010028665565187111
step: 490, loss: 0.0002379878715146333
step: 500, loss: 0.0004987320280633867
step: 510, loss: 0.0004425048246048391
step: 520, loss: 0.00016828495427034795
step: 530, loss: 0.006749531254172325
step: 540, loss: 0.00015352945774793625
step: 550, loss: 0.0001509351859567687
step: 560, loss: 0.0007504666573368013
step: 570, loss: 0.0005081543349660933
step: 580, loss: 0.00017689785454422235
step: 590, loss: 0.008622054941952229
step: 600, loss: 0.001830513123422861
step: 610, loss: 0.0002053042990155518
step: 620, loss: 9.489199874224141e-05
step: 630, loss: 0.004423534031957388
epoch 12: dev_f1=0.9404274670304685, f1=0.9391304347826086, best_f1=0.9402352941176471
step: 0, loss: 0.0004483640077523887
step: 10, loss: 0.0009408697369508445
step: 20, loss: 0.00033014710061252117
step: 30, loss: 6.232428859220818e-05
step: 40, loss: 0.00020894588669762015
step: 50, loss: 0.008299387991428375
step: 60, loss: 7.318131974898279e-05
step: 70, loss: 6.504252087324858e-05
step: 80, loss: 0.0013720006681978703
step: 90, loss: 3.174243465764448e-05
step: 100, loss: 3.309790190542117e-05
step: 110, loss: 9.423604205949232e-05
step: 120, loss: 8.613582031102851e-05
step: 130, loss: 0.0005385642871260643
step: 140, loss: 0.0007150586461648345
step: 150, loss: 0.00019692241039592773
step: 160, loss: 4.7301371523644775e-05
step: 170, loss: 0.0002473540953360498
step: 180, loss: 7.047630060696974e-05
step: 190, loss: 0.0003119126777164638
step: 200, loss: 6.852092337794602e-05
step: 210, loss: 0.0002118398988386616
step: 220, loss: 0.00020268229127395898
step: 230, loss: 2.9082450055284426e-05
step: 240, loss: 0.0015126357320696115
step: 250, loss: 0.0014063888229429722
step: 260, loss: 7.684519368922338e-05
step: 270, loss: 0.0019128116546198726
step: 280, loss: 0.00029932521283626556
step: 290, loss: 0.00014733296120539308
step: 300, loss: 4.884196096099913e-05
step: 310, loss: 0.000364914711099118
step: 320, loss: 0.0026049299631267786
step: 330, loss: 0.00010483826918061823
step: 340, loss: 0.00011947348684770986
step: 350, loss: 7.701076538069174e-05
step: 360, loss: 6.561727059306577e-05
step: 370, loss: 7.560302037745714e-05
step: 380, loss: 0.0025271824561059475
step: 390, loss: 0.00012511688692029566
step: 400, loss: 0.00012118136510252953
step: 410, loss: 0.0025152654852718115
step: 420, loss: 0.006336663383990526
step: 430, loss: 0.0005418100045062602
step: 440, loss: 0.003551413770765066
step: 450, loss: 0.0001381793263135478
step: 460, loss: 0.0022994172759354115
step: 470, loss: 0.0002893214114010334
step: 480, loss: 0.004386004991829395
step: 490, loss: 0.00010568982543190941
step: 500, loss: 0.001352616585791111
step: 510, loss: 0.0003449219511821866
step: 520, loss: 0.0001523025712231174
step: 530, loss: 0.000170840386999771
step: 540, loss: 0.0004621134721674025
step: 550, loss: 0.002247160067781806
step: 560, loss: 0.00037455331766977906
step: 570, loss: 6.809795740991831e-05
step: 580, loss: 0.009430281817913055
step: 590, loss: 0.00012850041093770415
step: 600, loss: 6.746399594703689e-05
step: 610, loss: 0.00018164397624786943
step: 620, loss: 0.0036850841715931892
step: 630, loss: 9.75652365013957e-05
epoch 13: dev_f1=0.9472222222222223, f1=0.9365671641791044, best_f1=0.9402352941176471
step: 0, loss: 0.0004199709219392389
step: 10, loss: 0.0006549040554091334
step: 20, loss: 5.407827484305017e-05
step: 30, loss: 9.951512038242072e-05
step: 40, loss: 0.008316603489220142
step: 50, loss: 0.007179174106568098
step: 60, loss: 8.1213831435889e-05
step: 70, loss: 6.629570998484269e-05
step: 80, loss: 0.00011119263945147395
step: 90, loss: 0.002217933302745223
step: 100, loss: 3.412223304621875e-05
step: 110, loss: 0.024665972217917442
step: 120, loss: 0.0017935836222022772
step: 130, loss: 0.00012170954141765833
step: 140, loss: 9.771304030437022e-05
step: 150, loss: 0.00017948189633898437
step: 160, loss: 0.00014235670096240938
step: 170, loss: 0.0004913217853754759
step: 180, loss: 9.502291504759341e-05
step: 190, loss: 7.943371019791812e-05
step: 200, loss: 0.0001552192261442542
step: 210, loss: 0.00018978197476826608
step: 220, loss: 0.0006068533402867615
step: 230, loss: 0.002387566491961479
step: 240, loss: 0.00163954624440521
step: 250, loss: 6.206733087310567e-05
step: 260, loss: 9.749207674758509e-05
step: 270, loss: 0.003728032810613513
step: 280, loss: 4.895158781437203e-05
step: 290, loss: 0.13544079661369324
step: 300, loss: 3.269208173151128e-05
step: 310, loss: 6.0962836869293824e-05
step: 320, loss: 0.003305974882096052
step: 330, loss: 0.00017823804228100926
step: 340, loss: 0.00010145905253011733
step: 350, loss: 9.574036812409759e-05
step: 360, loss: 3.204391759936698e-05
step: 370, loss: 3.7514309951802716e-05
step: 380, loss: 0.00010385549830971286
step: 390, loss: 0.0005641821189783514
step: 400, loss: 8.988378249341622e-05
step: 410, loss: 0.00013328329077921808
step: 420, loss: 0.00015775444626342505
step: 430, loss: 0.0016943189548328519
step: 440, loss: 7.15610949555412e-05
step: 450, loss: 0.0006942806649021804
step: 460, loss: 0.00010122646926902235
step: 470, loss: 0.0017738230526447296
step: 480, loss: 0.00019025045912712812
step: 490, loss: 3.582825229386799e-05
step: 500, loss: 4.541202724794857e-05
step: 510, loss: 0.00026607734616845846
step: 520, loss: 2.6046713173855096e-05
step: 530, loss: 0.00020874162146355957
step: 540, loss: 2.4474760721204802e-05
step: 550, loss: 5.361165676731616e-05
step: 560, loss: 4.439194890437648e-05
step: 570, loss: 4.0742572309682146e-05
step: 580, loss: 0.0020427850540727377
step: 590, loss: 3.1972569559002295e-05
step: 600, loss: 0.00011247863585595042
step: 610, loss: 0.0002867362345568836
step: 620, loss: 3.6419911339180544e-05
step: 630, loss: 0.00013134190521668643
epoch 14: dev_f1=0.9490740740740741, f1=0.945845004668534, best_f1=0.9402352941176471
step: 0, loss: 0.00024873402435332537
step: 10, loss: 2.6113595595234074e-05
step: 20, loss: 0.0012010774808004498
step: 30, loss: 4.074145545018837e-05
step: 40, loss: 7.233214273583144e-05
step: 50, loss: 0.017501479014754295
step: 60, loss: 0.00042035276419483125
step: 70, loss: 2.9153310606488958e-05
step: 80, loss: 0.0002552813966758549
step: 90, loss: 3.224850297556259e-05
step: 100, loss: 3.62449063686654e-05
step: 110, loss: 4.757771603181027e-05
step: 120, loss: 0.00016545817197766155
step: 130, loss: 4.8596855776850134e-05
step: 140, loss: 0.00012222009536344558
step: 150, loss: 0.00013622999540530145
step: 160, loss: 8.206874917959794e-05
step: 170, loss: 0.00010888891119975597
step: 180, loss: 6.74024413456209e-05
step: 190, loss: 9.01601742953062e-05
step: 200, loss: 4.1769613744691014e-05
step: 210, loss: 3.248266875743866e-05
step: 220, loss: 0.0013664859579876065
step: 230, loss: 0.000280476437183097
step: 240, loss: 3.532077607815154e-05
step: 250, loss: 0.0011249263770878315
step: 260, loss: 0.00016063559451140463
step: 270, loss: 0.015740524977445602
step: 280, loss: 8.679558231960982e-05
step: 290, loss: 3.1071122066350654e-05
step: 300, loss: 0.0019868314266204834
step: 310, loss: 8.364808309124783e-05
step: 320, loss: 3.399063280085102e-05
step: 330, loss: 2.864666203095112e-05
step: 340, loss: 3.850810753647238e-05
step: 350, loss: 0.00010469332482898608
step: 360, loss: 3.5433338780421764e-05
step: 370, loss: 0.00017063682025764138
step: 380, loss: 0.00013965048128739
step: 390, loss: 2.4500261133653112e-05
step: 400, loss: 2.611331728985533e-05
step: 410, loss: 5.7098463003057986e-05
step: 420, loss: 4.994084156351164e-05
step: 430, loss: 4.44834258814808e-05
step: 440, loss: 7.718057895544916e-05
step: 450, loss: 2.410570414212998e-05
step: 460, loss: 2.6463851099833846e-05
step: 470, loss: 0.00013420831237453967
step: 480, loss: 0.00012418584083206952
step: 490, loss: 0.0005726795643568039
step: 500, loss: 0.0014879360096529126
step: 510, loss: 0.00015582474588882178
step: 520, loss: 1.84026484930655e-05
step: 530, loss: 9.94010188151151e-05
step: 540, loss: 4.826509757549502e-05
step: 550, loss: 0.1247883290052414
step: 560, loss: 7.221588748507202e-05
step: 570, loss: 0.00011894497583853081
step: 580, loss: 0.002793201245367527
step: 590, loss: 5.5009484640322626e-05
step: 600, loss: 1.989261909329798e-05
step: 610, loss: 0.002895317506045103
step: 620, loss: 0.0005897178780287504
step: 630, loss: 9.331722685601562e-05
epoch 15: dev_f1=0.9509116409537166, f1=0.9418989135569201, best_f1=0.9402352941176471
step: 0, loss: 0.01464818324893713
step: 10, loss: 0.00044579393579624593
step: 20, loss: 0.0003474405384622514
step: 30, loss: 4.1596849769121036e-05
step: 40, loss: 0.00010033111902885139
step: 50, loss: 0.08486013114452362
step: 60, loss: 0.0003185956447850913
step: 70, loss: 3.297093644505367e-05
step: 80, loss: 5.0190315960207954e-05
step: 90, loss: 5.878675801795907e-05
step: 100, loss: 0.0009880425641313195
step: 110, loss: 0.0001269684435101226
step: 120, loss: 0.00032909499714151025
step: 130, loss: 3.844397360808216e-05
step: 140, loss: 0.014071018435060978
step: 150, loss: 0.0012064394541084766
step: 160, loss: 7.696338434470817e-05
step: 170, loss: 0.0010167183354496956
step: 180, loss: 4.710589928436093e-05
step: 190, loss: 0.011599605903029442
step: 200, loss: 2.9387741960817948e-05
step: 210, loss: 0.0002834137121681124
step: 220, loss: 5.995991523377597e-05
step: 230, loss: 5.000352757633664e-05
step: 240, loss: 0.0001941480441018939
step: 250, loss: 0.001509385067038238
step: 260, loss: 0.0032875121105462313
step: 270, loss: 5.146671901457012e-05
step: 280, loss: 0.0006782970740459859
step: 290, loss: 2.4988687073346227e-05
step: 300, loss: 0.00030991199309937656
step: 310, loss: 4.694941526395269e-05
step: 320, loss: 5.790518116555177e-05
step: 330, loss: 2.8616781492019072e-05
step: 340, loss: 4.025935413665138e-05
step: 350, loss: 0.006193830631673336
step: 360, loss: 2.139741445716936e-05
step: 370, loss: 4.369343878352083e-05
step: 380, loss: 0.0004145955026615411
step: 390, loss: 0.000626646913588047
step: 400, loss: 0.00016216291987802833
step: 410, loss: 2.787514495139476e-05
step: 420, loss: 2.409426997473929e-05
step: 430, loss: 6.108670640969649e-05
step: 440, loss: 2.887018672481645e-05
step: 450, loss: 0.030014464631676674
step: 460, loss: 8.396818157052621e-05
step: 470, loss: 1.994108606595546e-05
step: 480, loss: 0.0011263840133324265
step: 490, loss: 4.7186615120153874e-05
step: 500, loss: 0.00016838812734931707
step: 510, loss: 2.0246645362931304e-05
step: 520, loss: 0.00586567772552371
step: 530, loss: 0.0002633082040119916
step: 540, loss: 2.764063174254261e-05
step: 550, loss: 2.4511888113920577e-05
step: 560, loss: 0.00012030785728711635
step: 570, loss: 3.699570515891537e-05
step: 580, loss: 4.0882536268327385e-05
step: 590, loss: 0.00010116939665749669
step: 600, loss: 6.802185089327395e-05
step: 610, loss: 0.00044275345862843096
step: 620, loss: 3.2659478165442124e-05
step: 630, loss: 4.234260995872319e-05
epoch 16: dev_f1=0.9507735583684951, f1=0.9412322274881517, best_f1=0.9402352941176471
step: 0, loss: 2.8615193514269777e-05
step: 10, loss: 2.197855974372942e-05
step: 20, loss: 1.857775350799784e-05
step: 30, loss: 0.00036508330958895385
step: 40, loss: 5.262915510684252e-05
step: 50, loss: 6.987448432482779e-05
step: 60, loss: 0.005925165489315987
step: 70, loss: 6.488005601568148e-05
step: 80, loss: 1.6368716387660243e-05
step: 90, loss: 0.0001447217509848997
step: 100, loss: 2.9132599593140185e-05
step: 110, loss: 0.0024694877211004496
step: 120, loss: 3.088804805884138e-05
step: 130, loss: 4.463827644940466e-05
step: 140, loss: 1.580244133947417e-05
step: 150, loss: 0.02990414947271347
step: 160, loss: 0.0005108646000735462
step: 170, loss: 0.00013538991333916783
step: 180, loss: 4.24771751568187e-05
step: 190, loss: 0.0005737660103477538
step: 200, loss: 2.0611478248611093e-05
step: 210, loss: 0.00017856610065791756
step: 220, loss: 5.3611202019965276e-05
step: 230, loss: 0.0001743028697092086
step: 240, loss: 2.7248412152403034e-05
step: 250, loss: 0.006696444004774094
step: 260, loss: 0.00015939386503305286
step: 270, loss: 0.00012740318197757006
step: 280, loss: 3.693053804454394e-05
step: 290, loss: 0.03888612613081932
step: 300, loss: 0.00015529879601672292
step: 310, loss: 7.311685476452112e-05
step: 320, loss: 4.8630005039740354e-05
step: 330, loss: 0.00012857289402745664
step: 340, loss: 2.0849978682235815e-05
step: 350, loss: 7.790705421939492e-05
step: 360, loss: 2.2224705389817245e-05
step: 370, loss: 2.3405453248415142e-05
step: 380, loss: 5.368917845771648e-05
step: 390, loss: 0.00011347176041454077
step: 400, loss: 6.908861541887745e-05
step: 410, loss: 9.822261927183717e-05
step: 420, loss: 3.449968426139094e-05
step: 430, loss: 3.0784027330810204e-05
step: 440, loss: 6.874906830489635e-05
step: 450, loss: 1.695725768513512e-05
step: 460, loss: 0.000515497347805649
step: 470, loss: 1.4293795175035484e-05
step: 480, loss: 2.4541250240872614e-05
step: 490, loss: 2.526770367694553e-05
step: 500, loss: 0.0015272472519427538
step: 510, loss: 1.4927107258699834e-05
step: 520, loss: 5.067413439974189e-05
step: 530, loss: 7.249621558003128e-05
step: 540, loss: 2.337902333238162e-05
step: 550, loss: 1.979576700250618e-05
step: 560, loss: 8.571617945563048e-05
step: 570, loss: 0.00010900256893364713
step: 580, loss: 1.7009369912557304e-05
step: 590, loss: 6.746050348738208e-05
step: 600, loss: 4.3314361391821876e-05
step: 610, loss: 1.9654275092761964e-05
step: 620, loss: 1.763511863828171e-05
step: 630, loss: 1.4692379409098066e-05
epoch 17: dev_f1=0.9497206703910613, f1=0.947565543071161, best_f1=0.9402352941176471
step: 0, loss: 3.107825978077017e-05
step: 10, loss: 2.3498583686887287e-05
step: 20, loss: 1.6998274077195674e-05
step: 30, loss: 4.6805191232124344e-05
step: 40, loss: 3.407302210689522e-05
step: 50, loss: 6.510543607873842e-05
step: 60, loss: 1.4889848898747005e-05
step: 70, loss: 3.2013438612921163e-05
step: 80, loss: 2.8661563192144968e-05
step: 90, loss: 7.932629523565993e-05
step: 100, loss: 0.0006398226832970977
step: 110, loss: 1.706903458398301e-05
step: 120, loss: 0.00018355752399656922
step: 130, loss: 3.446699702180922e-05
step: 140, loss: 3.668975114123896e-05
step: 150, loss: 0.0001006945240078494
step: 160, loss: 1.751224772306159e-05
step: 170, loss: 0.00013937630865257233
step: 180, loss: 0.0022753505036234856
step: 190, loss: 3.3736829209374264e-05
step: 200, loss: 2.394722105236724e-05
step: 210, loss: 0.0006598699255846441
step: 220, loss: 0.000348378176568076
step: 230, loss: 5.740233609685674e-05
step: 240, loss: 1.993726436921861e-05
step: 250, loss: 2.4753895559115335e-05
step: 260, loss: 0.0012814265210181475
step: 270, loss: 1.686037467152346e-05
step: 280, loss: 2.6041961973533034e-05
step: 290, loss: 3.072788967983797e-05
step: 300, loss: 4.908517803414725e-05
step: 310, loss: 0.14774802327156067
step: 320, loss: 0.003639576490968466
step: 330, loss: 1.8890612409450114e-05
step: 340, loss: 3.083279079874046e-05
step: 350, loss: 0.001059537986293435
step: 360, loss: 0.0028063757345080376
step: 370, loss: 0.0009245198452845216
step: 380, loss: 0.00031071490957401693
step: 390, loss: 0.008383939042687416
step: 400, loss: 0.0006976258009672165
step: 410, loss: 2.8139256755821407e-05
step: 420, loss: 5.611320011666976e-05
step: 430, loss: 0.011367266066372395
step: 440, loss: 3.6609060771297663e-05
step: 450, loss: 4.086984336026944e-05
step: 460, loss: 0.013589154928922653
step: 470, loss: 2.8109403501730412e-05
step: 480, loss: 3.0772844183957204e-05
step: 490, loss: 4.943492604070343e-05
step: 500, loss: 2.7308980861562304e-05
step: 510, loss: 2.415773633401841e-05
step: 520, loss: 0.0001101737143471837
step: 530, loss: 0.0013462577480822802
step: 540, loss: 7.026048842817545e-05
step: 550, loss: 1.8618673493620008e-05
step: 560, loss: 1.7221687812707387e-05
step: 570, loss: 3.1643321563024074e-05
step: 580, loss: 1.1410485058149789e-05
step: 590, loss: 2.099903576890938e-05
step: 600, loss: 6.0798254708060995e-05
step: 610, loss: 5.492008131113835e-05
step: 620, loss: 2.3673183022765443e-05
step: 630, loss: 7.42968259146437e-05
epoch 18: dev_f1=0.9479606188466948, f1=0.9400660689004247, best_f1=0.9402352941176471
step: 0, loss: 8.559538400731981e-05
step: 10, loss: 1.543365760880988e-05
step: 20, loss: 2.5139164790743962e-05
step: 30, loss: 1.8126853319699876e-05
step: 40, loss: 7.746799383312464e-05
step: 50, loss: 0.00013156744535081089
step: 60, loss: 3.502538311295211e-05
step: 70, loss: 4.197619637125172e-05
step: 80, loss: 4.498690759646706e-05
step: 90, loss: 4.619874744093977e-05
step: 100, loss: 0.00033350259764119983
step: 110, loss: 4.436305243871175e-05
step: 120, loss: 2.057047822745517e-05
step: 130, loss: 2.4194527213694528e-05
step: 140, loss: 2.2749592972104438e-05
step: 150, loss: 0.00014916174404788762
step: 160, loss: 3.9010388718452305e-05
step: 170, loss: 1.5172920939221513e-05
step: 180, loss: 1.560875534778461e-05
step: 190, loss: 3.883005047100596e-05
step: 200, loss: 1.946419433807023e-05
step: 210, loss: 1.944552786881104e-05
step: 220, loss: 3.133926657028496e-05
step: 230, loss: 1.7612841475056484e-05
step: 240, loss: 4.4940632506040856e-05
step: 250, loss: 1.5456011169590056e-05
step: 260, loss: 0.00284286355599761
step: 270, loss: 0.00017066141299437732
step: 280, loss: 2.015274003497325e-05
step: 290, loss: 0.053931284695863724
step: 300, loss: 1.5906667613307945e-05
step: 310, loss: 4.571463432512246e-05
step: 320, loss: 0.0002902226697187871
step: 330, loss: 0.00024853754439391196
step: 340, loss: 0.0001049321872415021
step: 350, loss: 0.013481473550200462
step: 360, loss: 4.021060885861516e-05
step: 370, loss: 2.286469862156082e-05
step: 380, loss: 1.9590665033319965e-05
step: 390, loss: 1.5202620488707907e-05
step: 400, loss: 0.0005631743697449565
step: 410, loss: 5.362365482142195e-05
step: 420, loss: 0.00010554288746789098
step: 430, loss: 0.00011239478772040457
step: 440, loss: 1.7232854588655755e-05
step: 450, loss: 6.976807344472036e-05
step: 460, loss: 2.432131441310048e-05
step: 470, loss: 2.4291497538797557e-05
step: 480, loss: 8.005122072063386e-05
step: 490, loss: 0.00042287868564017117
step: 500, loss: 1.9266622985014692e-05
step: 510, loss: 1.9762101146625355e-05
step: 520, loss: 2.413521724520251e-05
step: 530, loss: 0.00010644505528034642
step: 540, loss: 2.7974472686764784e-05
step: 550, loss: 0.001543977065011859
step: 560, loss: 5.184185647522099e-05
step: 570, loss: 5.669435267918743e-05
step: 580, loss: 6.8460481998045e-05
step: 590, loss: 2.7267948098597117e-05
step: 600, loss: 1.5057434211485088e-05
step: 610, loss: 1.5850817362661473e-05
step: 620, loss: 4.583261761581525e-05
step: 630, loss: 2.7818805392598733e-05
epoch 19: dev_f1=0.9480037140204272, f1=0.9457436856875585, best_f1=0.9402352941176471
step: 0, loss: 5.329904524842277e-05
step: 10, loss: 1.4211856978363357e-05
step: 20, loss: 1.7515954823466018e-05
step: 30, loss: 2.4343922632397152e-05
step: 40, loss: 1.8819819160853513e-05
step: 50, loss: 1.8901358998846263e-05
step: 60, loss: 5.954464722890407e-05
step: 70, loss: 3.809923509834334e-05
step: 80, loss: 1.2259823961358052e-05
step: 90, loss: 1.3604625564767048e-05
step: 100, loss: 0.0002526109165046364
step: 110, loss: 3.245894185965881e-05
step: 120, loss: 0.00022018900199327618
step: 130, loss: 7.737457053735852e-05
step: 140, loss: 2.7733993192669004e-05
step: 150, loss: 2.110288551193662e-05
step: 160, loss: 2.9493749025277793e-05
step: 170, loss: 1.7113721696659923e-05
step: 180, loss: 1.2867009900219273e-05
step: 190, loss: 0.00018957795691676438
step: 200, loss: 4.5979282731423154e-05
step: 210, loss: 1.5560346582788043e-05
step: 220, loss: 2.8145539545221254e-05
step: 230, loss: 0.0027615230064839125
step: 240, loss: 4.3644464312819764e-05
step: 250, loss: 0.00026338640600442886
step: 260, loss: 1.4606698641728144e-05
step: 270, loss: 1.2837206668336876e-05
step: 280, loss: 2.480548937455751e-05
step: 290, loss: 2.1084493710077368e-05
step: 300, loss: 1.4703530723636504e-05
step: 310, loss: 1.4494962670141831e-05
step: 320, loss: 2.7057139959651977e-05
step: 330, loss: 1.762017927831039e-05
step: 340, loss: 2.033541204582434e-05
step: 350, loss: 1.718820203677751e-05
step: 360, loss: 0.00011397110210964456
step: 370, loss: 0.00014627193741034716
step: 380, loss: 2.018697705352679e-05
step: 390, loss: 7.066368561936542e-05
step: 400, loss: 1.9247874661232345e-05
step: 410, loss: 1.7262655092054047e-05
step: 420, loss: 1.7936286894837394e-05
step: 430, loss: 8.487203740514815e-05
step: 440, loss: 1.4982956599851605e-05
step: 450, loss: 3.9394977648044005e-05
step: 460, loss: 1.9218367015128024e-05
step: 470, loss: 0.00026234163669869304
step: 480, loss: 0.0019535019528120756
step: 490, loss: 4.101945523871109e-05
step: 500, loss: 2.3487098587793298e-05
step: 510, loss: 1.3671568922291044e-05
step: 520, loss: 3.98317861254327e-05
step: 530, loss: 1.6390991731896065e-05
step: 540, loss: 2.4334181944141164e-05
step: 550, loss: 7.834420102881268e-05
step: 560, loss: 3.75095296476502e-05
step: 570, loss: 1.800770769477822e-05
step: 580, loss: 1.372384031128604e-05
step: 590, loss: 1.5508167052757926e-05
step: 600, loss: 1.4800390090385918e-05
step: 610, loss: 0.0027003574650734663
step: 620, loss: 2.024268360401038e-05
step: 630, loss: 4.138485383009538e-05
epoch 20: dev_f1=0.9492787342950209, f1=0.9465791940018744, best_f1=0.9402352941176471
cuda
Device: cuda
step: 0, loss: 0.6781069040298462
step: 10, loss: 0.6226350665092468
step: 20, loss: 0.6405413150787354
step: 30, loss: 0.46348392963409424
step: 40, loss: 0.493309885263443
step: 50, loss: 0.3197076618671417
step: 60, loss: 0.3133156895637512
step: 70, loss: 0.4100848436355591
step: 80, loss: 0.44832098484039307
step: 90, loss: 0.2999529540538788
step: 100, loss: 0.2542968690395355
step: 110, loss: 0.3506958484649658
step: 120, loss: 0.3022722899913788
step: 130, loss: 0.3334592878818512
step: 140, loss: 0.14158298075199127
step: 150, loss: 0.170957550406456
step: 160, loss: 0.33087942004203796
step: 170, loss: 0.20430293679237366
step: 180, loss: 0.11856109648942947
step: 190, loss: 0.2610825002193451
step: 200, loss: 0.09290221333503723
step: 210, loss: 0.27207422256469727
step: 220, loss: 0.028474504128098488
step: 230, loss: 0.15188737213611603
step: 240, loss: 0.04290829598903656
step: 250, loss: 0.18838351964950562
step: 260, loss: 0.12245902419090271
step: 270, loss: 0.43877559900283813
step: 280, loss: 0.050364844501018524
step: 290, loss: 0.1180206909775734
step: 300, loss: 0.02907479740679264
step: 310, loss: 0.39179542660713196
step: 320, loss: 0.2593807280063629
step: 330, loss: 0.04660141468048096
step: 340, loss: 0.26845765113830566
step: 350, loss: 0.03355938941240311
step: 360, loss: 0.031979724764823914
step: 370, loss: 0.06122966110706329
step: 380, loss: 0.060726869851350784
step: 390, loss: 0.0647975280880928
step: 400, loss: 0.2158319503068924
step: 410, loss: 0.21382835507392883
step: 420, loss: 0.24607808887958527
step: 430, loss: 0.05839697644114494
step: 440, loss: 0.11265137046575546
step: 450, loss: 0.14423762261867523
step: 460, loss: 0.37456461787223816
step: 470, loss: 0.14164477586746216
step: 480, loss: 0.10615076869726181
step: 490, loss: 0.10405756533145905
step: 500, loss: 0.0481206513941288
step: 510, loss: 0.14298422634601593
step: 520, loss: 0.10771020501852036
step: 530, loss: 0.1258581280708313
step: 540, loss: 0.09266029298305511
step: 550, loss: 0.2454785257577896
step: 560, loss: 0.054238464683294296
step: 570, loss: 0.18463188409805298
step: 580, loss: 0.0732714906334877
step: 590, loss: 0.03985651955008507
step: 600, loss: 0.09238366782665253
step: 610, loss: 0.13241925835609436
step: 620, loss: 0.15710733830928802
step: 630, loss: 0.05460578575730324
epoch 1: dev_f1=0.9383057090239412, f1=0.9439853076216713, best_f1=0.9439853076216713
step: 0, loss: 0.03306431695818901
step: 10, loss: 0.03608982264995575
step: 20, loss: 0.09693270176649094
step: 30, loss: 0.09474162012338638
step: 40, loss: 0.00900166854262352
step: 50, loss: 0.06925351172685623
step: 60, loss: 0.042510736733675
step: 70, loss: 0.10543006658554077
step: 80, loss: 0.03050100803375244
step: 90, loss: 0.04920854791998863
step: 100, loss: 0.033782973885536194
step: 110, loss: 0.008263550698757172
step: 120, loss: 0.04414621368050575
step: 130, loss: 0.0643719807267189
step: 140, loss: 0.03458426520228386
step: 150, loss: 0.11881110817193985
step: 160, loss: 0.02197309583425522
step: 170, loss: 0.07470832020044327
step: 180, loss: 0.01655050739645958
step: 190, loss: 0.03951933607459068
step: 200, loss: 0.0073500205762684345
step: 210, loss: 0.10562419146299362
step: 220, loss: 0.09497203677892685
step: 230, loss: 0.1340729296207428
step: 240, loss: 0.07472890615463257
step: 250, loss: 0.048155274242162704
step: 260, loss: 0.04842870309948921
step: 270, loss: 0.02738984115421772
step: 280, loss: 0.03693247213959694
step: 290, loss: 0.22468611598014832
step: 300, loss: 0.032192349433898926
step: 310, loss: 0.01294643059372902
step: 320, loss: 0.12397488206624985
step: 330, loss: 0.018701773136854172
step: 340, loss: 0.20390287041664124
step: 350, loss: 0.028474899008870125
step: 360, loss: 0.03867116570472717
step: 370, loss: 0.21951229870319366
step: 380, loss: 0.01828989014029503
step: 390, loss: 0.0825958177447319
step: 400, loss: 0.03581457585096359
step: 410, loss: 0.012082821689546108
step: 420, loss: 0.21413768827915192
step: 430, loss: 0.0723433569073677
step: 440, loss: 0.014453727751970291
step: 450, loss: 0.03836829587817192
step: 460, loss: 0.04647967591881752
step: 470, loss: 0.08433742076158524
step: 480, loss: 0.07417245209217072
step: 490, loss: 0.10923642665147781
step: 500, loss: 0.016504229977726936
step: 510, loss: 0.041566938161849976
step: 520, loss: 0.18007561564445496
step: 530, loss: 0.04603209346532822
step: 540, loss: 0.042317427694797516
step: 550, loss: 0.07131648063659668
step: 560, loss: 0.10101726651191711
step: 570, loss: 0.18805962800979614
step: 580, loss: 0.1393384486436844
step: 590, loss: 0.1494370400905609
step: 600, loss: 0.14403030276298523
step: 610, loss: 0.02628971077501774
step: 620, loss: 0.06106553226709366
step: 630, loss: 0.007960264571011066
epoch 2: dev_f1=0.940959409594096, f1=0.9332096474953617, best_f1=0.9332096474953617
step: 0, loss: 0.005138241220265627
step: 10, loss: 0.02798435278236866
step: 20, loss: 0.03895494341850281
step: 30, loss: 0.05324588343501091
step: 40, loss: 0.04390436410903931
step: 50, loss: 0.017514411360025406
step: 60, loss: 0.006491870619356632
step: 70, loss: 0.02147255465388298
step: 80, loss: 0.016737496480345726
step: 90, loss: 0.13942570984363556
step: 100, loss: 0.3241196274757385
step: 110, loss: 0.07158954441547394
step: 120, loss: 0.02937815710902214
step: 130, loss: 0.014488122425973415
step: 140, loss: 0.04527440294623375
step: 150, loss: 0.03638006001710892
step: 160, loss: 0.12577763199806213
step: 170, loss: 0.0815524011850357
step: 180, loss: 0.17169061303138733
step: 190, loss: 0.14775201678276062
step: 200, loss: 0.004245935007929802
step: 210, loss: 0.003944028168916702
step: 220, loss: 0.05192148685455322
step: 230, loss: 0.026279713958501816
step: 240, loss: 0.017907138913869858
step: 250, loss: 0.03184889256954193
step: 260, loss: 0.016049256548285484
step: 270, loss: 0.1297566145658493
step: 280, loss: 0.019962182268500328
step: 290, loss: 0.007576232776045799
step: 300, loss: 0.042214855551719666
step: 310, loss: 0.1585366278886795
step: 320, loss: 0.010913695208728313
step: 330, loss: 0.03960677608847618
step: 340, loss: 0.11750277876853943
step: 350, loss: 0.05410033464431763
step: 360, loss: 0.11793901771306992
step: 370, loss: 0.018042322248220444
step: 380, loss: 0.025471072643995285
step: 390, loss: 0.007561577949672937
step: 400, loss: 0.020665161311626434
step: 410, loss: 0.02653105929493904
step: 420, loss: 0.007601277437061071
step: 430, loss: 0.05714668333530426
step: 440, loss: 0.05609354376792908
step: 450, loss: 0.0035673489328473806
step: 460, loss: 0.001431681914255023
step: 470, loss: 0.02205021306872368
step: 480, loss: 0.16987918317317963
step: 490, loss: 0.03240593522787094
step: 500, loss: 0.01154492236673832
step: 510, loss: 0.018273435533046722
step: 520, loss: 0.06894108653068542
step: 530, loss: 0.057311683893203735
step: 540, loss: 0.021861840039491653
step: 550, loss: 0.01464179065078497
step: 560, loss: 0.039982736110687256
step: 570, loss: 0.009342631325125694
step: 580, loss: 0.1254240721464157
step: 590, loss: 0.018350977450609207
step: 600, loss: 0.019534822553396225
step: 610, loss: 0.014323596842586994
step: 620, loss: 0.03160880133509636
step: 630, loss: 0.011915378272533417
epoch 3: dev_f1=0.9395050412465628, f1=0.9320477502295683, best_f1=0.9332096474953617
step: 0, loss: 0.0027968301437795162
step: 10, loss: 0.0012534033739939332
step: 20, loss: 0.005364243872463703
step: 30, loss: 0.06821972876787186
step: 40, loss: 0.020557986572384834
step: 50, loss: 0.10299097001552582
step: 60, loss: 0.0015376346418634057
step: 70, loss: 0.0019179318333044648
step: 80, loss: 0.003352061379700899
step: 90, loss: 0.004000644199550152
step: 100, loss: 0.012873171828687191
step: 110, loss: 0.0063066640868783
step: 120, loss: 0.004110522568225861
step: 130, loss: 0.24842143058776855
step: 140, loss: 0.04863728955388069
step: 150, loss: 0.02579619362950325
step: 160, loss: 0.15470372140407562
step: 170, loss: 0.021952832117676735
step: 180, loss: 0.006861593574285507
step: 190, loss: 0.001223630621097982
step: 200, loss: 0.11654335260391235
step: 210, loss: 0.029686735942959785
step: 220, loss: 0.017462197691202164
step: 230, loss: 0.00168892543297261
step: 240, loss: 0.10388810187578201
step: 250, loss: 0.07825066894292831
step: 260, loss: 0.025183413177728653
step: 270, loss: 0.0064145103096961975
step: 280, loss: 0.00388941983692348
step: 290, loss: 0.010930312797427177
step: 300, loss: 0.0040967282839119434
step: 310, loss: 0.03079240955412388
step: 320, loss: 0.014161999337375164
step: 330, loss: 0.01695319265127182
step: 340, loss: 0.35269278287887573
step: 350, loss: 0.026554130017757416
step: 360, loss: 0.03286977484822273
step: 370, loss: 0.007085762452334166
step: 380, loss: 0.010096672922372818
step: 390, loss: 0.002184034325182438
step: 400, loss: 0.010900190100073814
step: 410, loss: 0.010926023125648499
step: 420, loss: 0.06339046359062195
step: 430, loss: 0.0036407955922186375
step: 440, loss: 0.023064328357577324
step: 450, loss: 0.051771461963653564
step: 460, loss: 0.0307625625282526
step: 470, loss: 0.02983178198337555
step: 480, loss: 0.027704978361725807
step: 490, loss: 0.006584173068404198
step: 500, loss: 0.0035698541905730963
step: 510, loss: 0.0683952271938324
step: 520, loss: 0.001249580061994493
step: 530, loss: 0.007983695715665817
step: 540, loss: 0.23498544096946716
step: 550, loss: 0.0763171836733818
step: 560, loss: 0.2184579223394394
step: 570, loss: 0.008571960031986237
step: 580, loss: 0.0904378816485405
step: 590, loss: 0.06822977215051651
step: 600, loss: 0.011967845261096954
step: 610, loss: 0.07893805205821991
step: 620, loss: 0.0022664894349873066
step: 630, loss: 0.001185483648441732
epoch 4: dev_f1=0.9283372365339578, f1=0.9279026217228464, best_f1=0.9332096474953617
step: 0, loss: 0.017780514433979988
step: 10, loss: 0.012629487551748753
step: 20, loss: 0.006642159074544907
step: 30, loss: 0.032121170312166214
step: 40, loss: 0.10216721892356873
step: 50, loss: 0.0008259167661890388
step: 60, loss: 0.005123739130795002
step: 70, loss: 0.0018996334401890635
step: 80, loss: 0.0008586252224631608
step: 90, loss: 0.07614780217409134
step: 100, loss: 0.004285970702767372
step: 110, loss: 0.0016043793875724077
step: 120, loss: 0.006361735053360462
step: 130, loss: 0.0025567736010998487
step: 140, loss: 0.0016548486892133951
step: 150, loss: 0.01648591458797455
step: 160, loss: 0.001086782431229949
step: 170, loss: 0.007021698635071516
step: 180, loss: 0.02405744232237339
step: 190, loss: 0.0007418067543767393
step: 200, loss: 0.07863673567771912
step: 210, loss: 0.0013317964039742947
step: 220, loss: 0.013834838755428791
step: 230, loss: 0.08326452225446701
step: 240, loss: 0.011644318699836731
step: 250, loss: 0.14934153854846954
step: 260, loss: 0.018832674250006676
step: 270, loss: 0.03790481388568878
step: 280, loss: 0.0014570095809176564
step: 290, loss: 0.015646956861019135
step: 300, loss: 0.21274591982364655
step: 310, loss: 0.004320809151977301
step: 320, loss: 0.001299127354286611
step: 330, loss: 0.006580631248652935
step: 340, loss: 0.005399125162512064
step: 350, loss: 0.0014189615612849593
step: 360, loss: 0.007739764638245106
step: 370, loss: 0.0720469057559967
step: 380, loss: 0.07365995645523071
step: 390, loss: 0.012449773028492928
step: 400, loss: 0.009048601612448692
step: 410, loss: 0.03776108846068382
step: 420, loss: 0.14285744726657867
step: 430, loss: 0.009863744489848614
step: 440, loss: 0.012417417950928211
step: 450, loss: 0.05121472850441933
step: 460, loss: 0.030671803280711174
step: 470, loss: 0.0022458203602582216
step: 480, loss: 0.17706580460071564
step: 490, loss: 0.0024489935021847486
step: 500, loss: 0.004470955580472946
step: 510, loss: 0.07471039891242981
step: 520, loss: 0.00723428325727582
step: 530, loss: 0.012190468609333038
step: 540, loss: 0.0010159602388739586
step: 550, loss: 0.01979847252368927
step: 560, loss: 0.008558154106140137
step: 570, loss: 0.004516522865742445
step: 580, loss: 0.00917412992566824
step: 590, loss: 0.03446308150887489
step: 600, loss: 0.08111314475536346
step: 610, loss: 0.003607854014262557
step: 620, loss: 0.056183476001024246
step: 630, loss: 0.025843150913715363
epoch 5: dev_f1=0.943778801843318, f1=0.9406307977736549, best_f1=0.9406307977736549
step: 0, loss: 0.00140219961758703
step: 10, loss: 0.009036404080688953
step: 20, loss: 0.004880860913544893
step: 30, loss: 0.0023873811587691307
step: 40, loss: 0.19113072752952576
step: 50, loss: 0.001073419232852757
step: 60, loss: 0.00044011673890054226
step: 70, loss: 0.0011568235931918025
step: 80, loss: 0.0048721120692789555
step: 90, loss: 0.0008573827217333019
step: 100, loss: 0.013995187357068062
step: 110, loss: 0.0009793138597160578
step: 120, loss: 0.005877435673028231
step: 130, loss: 0.005057175178080797
step: 140, loss: 0.00035081998794339597
step: 150, loss: 0.0012712804600596428
step: 160, loss: 0.0004230976919643581
step: 170, loss: 0.3051518499851227
step: 180, loss: 0.08477717638015747
step: 190, loss: 0.0014600529102608562
step: 200, loss: 0.05334627255797386
step: 210, loss: 0.015254062600433826
step: 220, loss: 0.0008280860492959619
step: 230, loss: 0.0006120554753579199
step: 240, loss: 0.00024765529087744653
step: 250, loss: 0.009144585579633713
step: 260, loss: 0.0014118046965450048
step: 270, loss: 0.11766155064105988
step: 280, loss: 0.0023801035713404417
step: 290, loss: 0.002098972210660577
step: 300, loss: 0.0190143920481205
step: 310, loss: 0.00046678149374201894
step: 320, loss: 0.00683559849858284
step: 330, loss: 0.0033014335203915834
step: 340, loss: 0.001519234967418015
step: 350, loss: 0.014109503477811813
step: 360, loss: 0.001813095179386437
step: 370, loss: 0.016751758754253387
step: 380, loss: 0.005048960447311401
step: 390, loss: 0.002268094103783369
step: 400, loss: 0.0016864701174199581
step: 410, loss: 0.005071080755442381
step: 420, loss: 0.0029188923072069883
step: 430, loss: 0.001989060780033469
step: 440, loss: 0.0006718381191603839
step: 450, loss: 0.0015720675000920892
step: 460, loss: 0.0006490314844995737
step: 470, loss: 0.0007232400821521878
step: 480, loss: 0.0024454311933368444
step: 490, loss: 0.0017709739040583372
step: 500, loss: 0.0009547477820888162
step: 510, loss: 0.0010641911067068577
step: 520, loss: 0.0019226549193263054
step: 530, loss: 0.02917097881436348
step: 540, loss: 0.028519948944449425
step: 550, loss: 0.017293408513069153
step: 560, loss: 0.0007089574937708676
step: 570, loss: 0.0012822626158595085
step: 580, loss: 0.001250607892870903
step: 590, loss: 0.0014454626943916082
step: 600, loss: 0.06624504178762436
step: 610, loss: 0.0006927968352101743
step: 620, loss: 0.004343755543231964
step: 630, loss: 0.0017366037936881185
epoch 6: dev_f1=0.9396914446002805, f1=0.928909952606635, best_f1=0.9406307977736549
step: 0, loss: 0.002732211258262396
step: 10, loss: 0.03997078910470009
step: 20, loss: 0.0023835368920117617
step: 30, loss: 0.006352064199745655
step: 40, loss: 0.15576016902923584
step: 50, loss: 0.0018872893415391445
step: 60, loss: 0.00269600423052907
step: 70, loss: 0.0005355101311579347
step: 80, loss: 0.0003496745484881103
step: 90, loss: 0.00040119478944689035
step: 100, loss: 0.12766921520233154
step: 110, loss: 0.0011613942915573716
step: 120, loss: 0.023344704881310463
step: 130, loss: 0.08222375065088272
step: 140, loss: 0.04723140224814415
step: 150, loss: 0.0020812288857996464
step: 160, loss: 0.003588958876207471
step: 170, loss: 0.0013232051860541105
step: 180, loss: 0.00803580041974783
step: 190, loss: 0.007375925779342651
step: 200, loss: 0.0013941582292318344
step: 210, loss: 0.0006549354293383658
step: 220, loss: 0.0005785251269116998
step: 230, loss: 0.0002730186388362199
step: 240, loss: 0.001388825592584908
step: 250, loss: 0.00023236536071635783
step: 260, loss: 0.0008530705817975104
step: 270, loss: 0.0002953037910629064
step: 280, loss: 0.0003902709577232599
step: 290, loss: 0.0004691684152930975
step: 300, loss: 0.0010964279063045979
step: 310, loss: 0.0027334638871252537
step: 320, loss: 0.00028700943221338093
step: 330, loss: 0.11470112204551697
step: 340, loss: 0.0004347453359514475
step: 350, loss: 0.014355933293700218
step: 360, loss: 0.0008036414510570467
step: 370, loss: 0.03370936959981918
step: 380, loss: 0.0007758730789646506
step: 390, loss: 0.0002747944963630289
step: 400, loss: 0.0061596776358783245
step: 410, loss: 0.0027610021643340588
step: 420, loss: 0.003211032832041383
step: 430, loss: 0.0003231786540709436
step: 440, loss: 0.03787245228886604
step: 450, loss: 0.00067060039145872
step: 460, loss: 0.0001236020470969379
step: 470, loss: 0.10708597302436829
step: 480, loss: 0.006326523143798113
step: 490, loss: 0.015630682930350304
step: 500, loss: 0.0009349830215796828
step: 510, loss: 0.00016620158567093313
step: 520, loss: 0.007092827931046486
step: 530, loss: 0.00045455782674252987
step: 540, loss: 0.0014899802627041936
step: 550, loss: 0.08173482865095139
step: 560, loss: 0.0028224668931216
step: 570, loss: 0.0011085356818512082
step: 580, loss: 0.027018072083592415
step: 590, loss: 0.0009230702999047935
step: 600, loss: 0.0011511115590110421
step: 610, loss: 0.016470663249492645
step: 620, loss: 0.0005310154519975185
step: 630, loss: 0.000480274495203048
epoch 7: dev_f1=0.934844192634561, f1=0.9324515824279641, best_f1=0.9406307977736549
step: 0, loss: 0.0008888698648661375
step: 10, loss: 0.0003087400400545448
step: 20, loss: 0.0007243672152981162
step: 30, loss: 0.0007041528588160872
step: 40, loss: 0.017673686146736145
step: 50, loss: 0.0011589523637667298
step: 60, loss: 0.011228365823626518
step: 70, loss: 0.013688629493117332
step: 80, loss: 0.0006763094570487738
step: 90, loss: 0.05315296724438667
step: 100, loss: 0.0006667672423645854
step: 110, loss: 0.0005897332448512316
step: 120, loss: 0.000864239817019552
step: 130, loss: 0.0006897950079292059
step: 140, loss: 0.032104820013046265
step: 150, loss: 0.0017148219048976898
step: 160, loss: 0.02451552264392376
step: 170, loss: 0.00031494282302446663
step: 180, loss: 0.00021328055299818516
step: 190, loss: 0.00026724935742095113
step: 200, loss: 0.021219957619905472
step: 210, loss: 0.00032758526504039764
step: 220, loss: 0.00019406234787311405
step: 230, loss: 0.027793608605861664
step: 240, loss: 0.048859525471925735
step: 250, loss: 0.0004802485345862806
step: 260, loss: 0.019485339522361755
step: 270, loss: 0.00019881472690030932
step: 280, loss: 0.002499071881175041
step: 290, loss: 0.0006339015089906752
step: 300, loss: 0.013052355498075485
step: 310, loss: 0.00036846462171524763
step: 320, loss: 0.0004634721262846142
step: 330, loss: 0.00767594575881958
step: 340, loss: 0.0019837997388094664
step: 350, loss: 0.0008142406586557627
step: 360, loss: 0.00029711786191910505
step: 370, loss: 0.005807745736092329
step: 380, loss: 0.0008346018730662763
step: 390, loss: 0.00248480006121099
step: 400, loss: 0.0024863407015800476
step: 410, loss: 0.0009060267475433648
step: 420, loss: 0.000506665906868875
step: 430, loss: 0.00027687332476489246
step: 440, loss: 0.00030584659543819726
step: 450, loss: 0.0057544284500181675
step: 460, loss: 0.03131374716758728
step: 470, loss: 0.04403151944279671
step: 480, loss: 0.0004459328774828464
step: 490, loss: 0.0005510972114279866
step: 500, loss: 0.0005950907943770289
step: 510, loss: 0.00048606397467665374
step: 520, loss: 0.0009023106540553272
step: 530, loss: 0.01240137591958046
step: 540, loss: 0.020749621093273163
step: 550, loss: 0.00740418303757906
step: 560, loss: 0.005440316163003445
step: 570, loss: 0.0005778053309768438
step: 580, loss: 0.025295935571193695
step: 590, loss: 0.007247982546687126
step: 600, loss: 0.00026842477382160723
step: 610, loss: 0.00026895705377683043
step: 620, loss: 0.0008157158154062927
step: 630, loss: 0.00027719110948964953
epoch 8: dev_f1=0.9387564282374942, f1=0.929007992477668, best_f1=0.9406307977736549
step: 0, loss: 0.0012082360917702317
step: 10, loss: 0.0001362704497296363
step: 20, loss: 0.0010009174002334476
step: 30, loss: 0.008927006274461746
step: 40, loss: 0.00013521002256311476
step: 50, loss: 0.0003660781658254564
step: 60, loss: 0.000437452137703076
step: 70, loss: 0.00022591560264118016
step: 80, loss: 0.00013554826728068292
step: 90, loss: 0.0003324697900097817
step: 100, loss: 0.0007434873841702938
step: 110, loss: 0.0005696270382031798
step: 120, loss: 0.0012572557898238301
step: 130, loss: 0.013878962956368923
step: 140, loss: 0.007398840505629778
step: 150, loss: 0.00011093905777670443
step: 160, loss: 0.0008413431351073086
step: 170, loss: 0.00015620551130268723
step: 180, loss: 0.0005722914938814938
step: 190, loss: 0.0003231338632758707
step: 200, loss: 0.00025317829567939043
step: 210, loss: 0.0001070592479663901
step: 220, loss: 0.00029182297294028103
step: 230, loss: 0.0024358320515602827
step: 240, loss: 0.1008399948477745
step: 250, loss: 0.00014918572560418397
step: 260, loss: 0.015590835362672806
step: 270, loss: 0.00017420228687115014
step: 280, loss: 0.0010422954801470041
step: 290, loss: 8.709755638847128e-05
step: 300, loss: 0.0018669452983886003
step: 310, loss: 0.007108707446604967
step: 320, loss: 0.008930948562920094
step: 330, loss: 0.0026184653397649527
step: 340, loss: 0.009044491685926914
step: 350, loss: 0.02142651192843914
step: 360, loss: 0.0021322527900338173
step: 370, loss: 0.022217722609639168
step: 380, loss: 0.001142062246799469
step: 390, loss: 0.00018397925305180252
step: 400, loss: 0.0012673056917265058
step: 410, loss: 0.0006173700094223022
step: 420, loss: 0.00011370167339919135
step: 430, loss: 8.703571802470833e-05
step: 440, loss: 0.0003742840781342238
step: 450, loss: 0.0013167551951482892
step: 460, loss: 0.0004684843879658729
step: 470, loss: 0.023673614487051964
step: 480, loss: 0.0003158172476105392
step: 490, loss: 0.0007094856700859964
step: 500, loss: 0.0008671715622767806
step: 510, loss: 0.00037560920463874936
step: 520, loss: 0.004048108123242855
step: 530, loss: 0.001603181124664843
step: 540, loss: 0.0016530118882656097
step: 550, loss: 0.0007853271090425551
step: 560, loss: 0.003319907234981656
step: 570, loss: 0.0006117391749285161
step: 580, loss: 0.0008274633437395096
step: 590, loss: 0.01648501493036747
step: 600, loss: 0.0022385921329259872
step: 610, loss: 0.00022390240337699652
step: 620, loss: 0.008785057812929153
step: 630, loss: 0.0005005827406421304
epoch 9: dev_f1=0.9420631182289213, f1=0.9385052034058656, best_f1=0.9406307977736549
step: 0, loss: 0.00042810963350348175
step: 10, loss: 0.0004652771749533713
step: 20, loss: 0.0003310851752758026
step: 30, loss: 0.040002353489398956
step: 40, loss: 8.326194802066311e-05
step: 50, loss: 0.0850243866443634
step: 60, loss: 0.0008670949609950185
step: 70, loss: 0.001115545746870339
step: 80, loss: 0.001887258025817573
step: 90, loss: 0.0018576383590698242
step: 100, loss: 0.000129236068460159
step: 110, loss: 0.0013025164371356368
step: 120, loss: 0.003024454228579998
step: 130, loss: 0.00023675280681345612
step: 140, loss: 0.00026135091320611537
step: 150, loss: 0.0008936580852605402
step: 160, loss: 4.929466376779601e-05
step: 170, loss: 0.002042434411123395
step: 180, loss: 0.0007013660506345332
step: 190, loss: 0.0095225740224123
step: 200, loss: 0.0008025448187254369
step: 210, loss: 0.027318406850099564
step: 220, loss: 0.0011962954886257648
step: 230, loss: 7.183470734162256e-05
step: 240, loss: 0.0012546501820906997
step: 250, loss: 0.00013655246584676206
step: 260, loss: 0.0866297259926796
step: 270, loss: 0.0008318057516589761
step: 280, loss: 9.798822429729626e-05
step: 290, loss: 0.00017373690207023174
step: 300, loss: 4.866812378168106e-05
step: 310, loss: 0.0003305886930320412
step: 320, loss: 0.0002628236834425479
step: 330, loss: 0.004638580605387688
step: 340, loss: 0.0007019373588263988
step: 350, loss: 0.00024826210574246943
step: 360, loss: 0.0033357287757098675
step: 370, loss: 0.00019762241572607309
step: 380, loss: 0.0018708489369601011
step: 390, loss: 0.0008083273423835635
step: 400, loss: 0.0003565353690646589
step: 410, loss: 9.366486483486369e-05
step: 420, loss: 5.361611329135485e-05
step: 430, loss: 6.313875201158226e-05
step: 440, loss: 0.0010646730661392212
step: 450, loss: 0.0009276614873670042
step: 460, loss: 0.0020631446968764067
step: 470, loss: 0.000465198332676664
step: 480, loss: 0.0004451745480764657
step: 490, loss: 0.0014575152890756726
step: 500, loss: 0.0007098009809851646
step: 510, loss: 0.03340054675936699
step: 520, loss: 0.013620134443044662
step: 530, loss: 0.0005021479446440935
step: 540, loss: 0.0011536944657564163
step: 550, loss: 0.0002857344807125628
step: 560, loss: 0.04226436838507652
step: 570, loss: 0.00012915852130390704
step: 580, loss: 0.0017599122365936637
step: 590, loss: 0.00011988821643171832
step: 600, loss: 0.0006357210222631693
step: 610, loss: 0.010053359903395176
step: 620, loss: 0.0005892790504731238
step: 630, loss: 0.00036652685957960784
epoch 10: dev_f1=0.9415067852129153, f1=0.9413970932958275, best_f1=0.9406307977736549
step: 0, loss: 0.0006500785821117461
step: 10, loss: 0.0016860252944752574
step: 20, loss: 0.0007874530274420977
step: 30, loss: 0.03430374711751938
step: 40, loss: 0.0001068677956936881
step: 50, loss: 0.0005455869832076132
step: 60, loss: 0.0013740791473537683
step: 70, loss: 0.0002334924938622862
step: 80, loss: 0.03098624013364315
step: 90, loss: 0.00015967230137903243
step: 100, loss: 0.0004343812761362642
step: 110, loss: 0.00034290982875972986
step: 120, loss: 0.0004570871533360332
step: 130, loss: 0.004749695770442486
step: 140, loss: 7.76678862166591e-05
step: 150, loss: 0.005068968515843153
step: 160, loss: 0.0016739851562306285
step: 170, loss: 0.0005360939539968967
step: 180, loss: 0.0007355027482844889
step: 190, loss: 0.0003158359613735229
step: 200, loss: 0.00019917923782486469
step: 210, loss: 0.003111578058451414
step: 220, loss: 0.0008622868335805833
step: 230, loss: 0.0001584795245435089
step: 240, loss: 0.011177139356732368
step: 250, loss: 0.0003613329026848078
step: 260, loss: 0.0017024008557200432
step: 270, loss: 0.0025246816221624613
step: 280, loss: 0.000992689630948007
step: 290, loss: 0.0005282896454446018
step: 300, loss: 0.0006618867628276348
step: 310, loss: 0.005421460140496492
step: 320, loss: 0.014409802854061127
step: 330, loss: 0.0006115453434176743
step: 340, loss: 0.0001600368705112487
step: 350, loss: 0.004480474162846804
step: 360, loss: 0.0003653482417576015
step: 370, loss: 8.679771417519078e-05
step: 380, loss: 8.304359653266147e-05
step: 390, loss: 0.07350651174783707
step: 400, loss: 0.00228782813064754
step: 410, loss: 0.008607684634625912
step: 420, loss: 0.00010553681931924075
step: 430, loss: 0.010765585117042065
step: 440, loss: 0.11192161589860916
step: 450, loss: 0.00044973709736950696
step: 460, loss: 0.026466524228453636
step: 470, loss: 0.00011014009942300618
step: 480, loss: 0.0013138842768967152
step: 490, loss: 9.076367132365704e-05
step: 500, loss: 8.213976252591237e-05
step: 510, loss: 0.0033205472864210606
step: 520, loss: 0.009454168379306793
step: 530, loss: 0.0541650652885437
step: 540, loss: 0.0029265598859637976
step: 550, loss: 0.00194175832439214
step: 560, loss: 0.000371068948879838
step: 570, loss: 0.008841860108077526
step: 580, loss: 0.00018638026085682213
step: 590, loss: 0.00035753982956521213
step: 600, loss: 0.007877740077674389
step: 610, loss: 0.0007822091574780643
step: 620, loss: 0.0006321649998426437
step: 630, loss: 0.0007062541553750634
epoch 11: dev_f1=0.9466911764705882, f1=0.94362292051756, best_f1=0.94362292051756
step: 0, loss: 0.002709490479901433
step: 10, loss: 0.00044391921255737543
step: 20, loss: 0.00024614582071080804
step: 30, loss: 0.0042747328989207745
step: 40, loss: 0.0013410511892288923
step: 50, loss: 0.0009724177070893347
step: 60, loss: 0.0006798575050197542
step: 70, loss: 0.00010629931057337672
step: 80, loss: 0.0002879758249036968
step: 90, loss: 0.04498032107949257
step: 100, loss: 0.0007585679413750768
step: 110, loss: 0.00011754481238313019
step: 120, loss: 0.005861631128937006
step: 130, loss: 0.0001768695656210184
step: 140, loss: 0.0036803879775106907
step: 150, loss: 0.10492003709077835
step: 160, loss: 0.0011615529656410217
step: 170, loss: 0.00014343387738335878
step: 180, loss: 0.03091590665280819
step: 190, loss: 0.10014469921588898
step: 200, loss: 0.0006014129030518234
step: 210, loss: 0.00010024754010373726
step: 220, loss: 0.012285856530070305
step: 230, loss: 7.081628427840769e-05
step: 240, loss: 0.0010340693406760693
step: 250, loss: 0.00035550890606828034
step: 260, loss: 0.00039188333903439343
step: 270, loss: 0.00020807127293664962
step: 280, loss: 8.029791933950037e-05
step: 290, loss: 0.000208450568607077
step: 300, loss: 0.0032295063138008118
step: 310, loss: 9.051942470250651e-05
step: 320, loss: 4.822066694032401e-05
step: 330, loss: 0.00011518443352542818
step: 340, loss: 0.0003118450113106519
step: 350, loss: 0.0018716416088864207
step: 360, loss: 0.0001227382308570668
step: 370, loss: 0.00039994242251850665
step: 380, loss: 0.013278806582093239
step: 390, loss: 8.679535676492378e-05
step: 400, loss: 0.0003453190438449383
step: 410, loss: 0.06373896449804306
step: 420, loss: 0.00023680689628235996
step: 430, loss: 0.003003826830536127
step: 440, loss: 0.0004169647581875324
step: 450, loss: 0.0003093624545726925
step: 460, loss: 0.001407332718372345
step: 470, loss: 0.00013403013872448355
step: 480, loss: 0.00023181467258837074
step: 490, loss: 0.03127419576048851
step: 500, loss: 0.0001371320686303079
step: 510, loss: 7.613626075908542e-05
step: 520, loss: 0.0002444622805342078
step: 530, loss: 7.631989865330979e-05
step: 540, loss: 8.918620005715638e-05
step: 550, loss: 0.0003015928959939629
step: 560, loss: 0.0009493438992649317
step: 570, loss: 0.008386368863284588
step: 580, loss: 0.00017524458235129714
step: 590, loss: 7.233519136207178e-05
step: 600, loss: 0.0018582054181024432
step: 610, loss: 0.0003255064657423645
step: 620, loss: 9.449457138543949e-05
step: 630, loss: 0.00021496540284715593
epoch 12: dev_f1=0.9441860465116279, f1=0.9445221445221446, best_f1=0.94362292051756
step: 0, loss: 8.623459143564105e-05
step: 10, loss: 0.00019858742598444223
step: 20, loss: 8.128006447805092e-05
step: 30, loss: 6.260740337893367e-05
step: 40, loss: 0.00017986982129514217
step: 50, loss: 0.0018641166388988495
step: 60, loss: 0.0005343534867279232
step: 70, loss: 0.00015808231546543539
step: 80, loss: 0.001579774310812354
step: 90, loss: 0.00010823533375514671
step: 100, loss: 6.27370027359575e-05
step: 110, loss: 0.000506153388414532
step: 120, loss: 0.0001488995476393029
step: 130, loss: 0.0003813692892435938
step: 140, loss: 6.0472233599284664e-05
step: 150, loss: 0.00012832587526645511
step: 160, loss: 7.353300316026434e-05
step: 170, loss: 0.0007520908256992698
step: 180, loss: 0.00015403880388475955
step: 190, loss: 4.991767127648927e-05
step: 200, loss: 0.0002498782705515623
step: 210, loss: 0.0002544964081607759
step: 220, loss: 4.200035982648842e-05
step: 230, loss: 0.00024457238032482564
step: 240, loss: 0.0002652520779520273
step: 250, loss: 5.0722574087558314e-05
step: 260, loss: 9.517908620182425e-05
step: 270, loss: 2.836736894096248e-05
step: 280, loss: 6.083483822294511e-05
step: 290, loss: 0.00013979188224766403
step: 300, loss: 2.371841219428461e-05
step: 310, loss: 0.00025774366804398596
step: 320, loss: 4.352522228145972e-05
step: 330, loss: 3.615223613451235e-05
step: 340, loss: 2.2805805201642215e-05
step: 350, loss: 2.9179616831243038e-05
step: 360, loss: 2.559203130658716e-05
step: 370, loss: 6.548520468641073e-05
step: 380, loss: 0.00013726558245252818
step: 390, loss: 3.4993747249245644e-05
step: 400, loss: 2.1427431420306675e-05
step: 410, loss: 4.741502561955713e-05
step: 420, loss: 7.532334711868316e-05
step: 430, loss: 2.338696867809631e-05
step: 440, loss: 3.165616362821311e-05
step: 450, loss: 0.000670792069286108
step: 460, loss: 0.00015155911387410015
step: 470, loss: 0.001199125312268734
step: 480, loss: 0.0009052930399775505
step: 490, loss: 0.00026621893630363047
step: 500, loss: 2.790169855870772e-05
step: 510, loss: 0.00013778659922536463
step: 520, loss: 0.0015673090238124132
step: 530, loss: 0.0006548507953993976
step: 540, loss: 0.00017898899386636913
step: 550, loss: 0.0012198679614812136
step: 560, loss: 0.00828029029071331
step: 570, loss: 7.048311090329662e-05
step: 580, loss: 8.245449134847149e-05
step: 590, loss: 0.0009864032035693526
step: 600, loss: 0.000138314557261765
step: 610, loss: 0.0023525271099060774
step: 620, loss: 0.00011431187886046246
step: 630, loss: 0.00035614389344118536
epoch 13: dev_f1=0.9430670339761248, f1=0.9416666666666667, best_f1=0.94362292051756
step: 0, loss: 0.00049501535249874
step: 10, loss: 5.957078610663302e-05
step: 20, loss: 4.4908912968821824e-05
step: 30, loss: 7.920940697658807e-05
step: 40, loss: 0.006013751029968262
step: 50, loss: 4.388833622215316e-05
step: 60, loss: 3.425269460421987e-05
step: 70, loss: 8.899415843188763e-05
step: 80, loss: 6.148143438622355e-05
step: 90, loss: 0.00024951991508714855
step: 100, loss: 2.705518636503257e-05
step: 110, loss: 8.342246292158961e-05
step: 120, loss: 6.218131602508947e-05
step: 130, loss: 3.491951065370813e-05
step: 140, loss: 9.792035416467115e-05
step: 150, loss: 0.00714512262493372
step: 160, loss: 0.00013629329623654485
step: 170, loss: 0.00022157264174893498
step: 180, loss: 0.003966567572206259
step: 190, loss: 0.0004690710629802197
step: 200, loss: 0.0002979267737828195
step: 210, loss: 0.032501768320798874
step: 220, loss: 0.0001652275095693767
step: 230, loss: 4.4741027522832155e-05
step: 240, loss: 0.00025399340665899217
step: 250, loss: 0.000841194880194962
step: 260, loss: 0.00015157861344050616
step: 270, loss: 0.004571332596242428
step: 280, loss: 2.3297250663745217e-05
step: 290, loss: 0.0005097173852846026
step: 300, loss: 7.731302321190014e-05
step: 310, loss: 3.665856274892576e-05
step: 320, loss: 0.0004278419364709407
step: 330, loss: 2.9402192012639716e-05
step: 340, loss: 0.0004987888969480991
step: 350, loss: 0.0003889158251695335
step: 360, loss: 2.4545493943151087e-05
step: 370, loss: 2.855690399883315e-05
step: 380, loss: 0.00015721928502898663
step: 390, loss: 4.771964086103253e-05
step: 400, loss: 3.106660733465105e-05
step: 410, loss: 0.00013707601465284824
step: 420, loss: 0.0327889509499073
step: 430, loss: 0.004255831241607666
step: 440, loss: 4.275580431567505e-05
step: 450, loss: 0.003294695634394884
step: 460, loss: 5.2329382015159354e-05
step: 470, loss: 0.0002517022076062858
step: 480, loss: 0.00011594282841542736
step: 490, loss: 3.062815812882036e-05
step: 500, loss: 6.475839472841471e-05
step: 510, loss: 9.088746446650475e-05
step: 520, loss: 2.553597732912749e-05
step: 530, loss: 5.200072337174788e-05
step: 540, loss: 3.853058296954259e-05
step: 550, loss: 2.9655864636879414e-05
step: 560, loss: 6.46011540084146e-05
step: 570, loss: 0.00024123990442603827
step: 580, loss: 0.001912901527248323
step: 590, loss: 1.7374548406223767e-05
step: 600, loss: 0.0025480862241238356
step: 610, loss: 0.00016476538439746946
step: 620, loss: 6.681505328742787e-05
step: 630, loss: 0.002421821467578411
epoch 14: dev_f1=0.9416091954022988, f1=0.9423165666820489, best_f1=0.94362292051756
step: 0, loss: 9.503271576249972e-05
step: 10, loss: 5.553976370720193e-05
step: 20, loss: 0.000911687791813165
step: 30, loss: 4.7487104893662035e-05
step: 40, loss: 0.000831694167573005
step: 50, loss: 0.010365486145019531
step: 60, loss: 0.00034009755472652614
step: 70, loss: 6.4585663494654e-05
step: 80, loss: 8.277376036858186e-05
step: 90, loss: 3.0210967452148907e-05
step: 100, loss: 5.3036339522805065e-05
step: 110, loss: 6.091771138017066e-05
step: 120, loss: 0.0012792791239917278
step: 130, loss: 8.019451342988759e-05
step: 140, loss: 0.0001170015093521215
step: 150, loss: 0.006977836601436138
step: 160, loss: 0.00020387070253491402
step: 170, loss: 0.00016634284111205488
step: 180, loss: 0.00014879368245601654
step: 190, loss: 5.514206350198947e-05
step: 200, loss: 0.00039050806662999094
step: 210, loss: 3.086533979512751e-05
step: 220, loss: 0.008541678078472614
step: 230, loss: 0.01972690224647522
step: 240, loss: 4.495653774938546e-05
step: 250, loss: 2.1773816115455702e-05
step: 260, loss: 8.441264799330384e-05
step: 270, loss: 0.00019946850079577416
step: 280, loss: 0.0001345951750408858
step: 290, loss: 3.372304490767419e-05
step: 300, loss: 8.221416646847501e-05
step: 310, loss: 6.899646541569382e-05
step: 320, loss: 5.74654113734141e-05
step: 330, loss: 3.610989369917661e-05
step: 340, loss: 0.003546167630702257
step: 350, loss: 0.006790099665522575
step: 360, loss: 2.8352269509923644e-05
step: 370, loss: 4.0718892705626786e-05
step: 380, loss: 0.00505946995690465
step: 390, loss: 1.496806180512067e-05
step: 400, loss: 3.689724690048024e-05
step: 410, loss: 0.002776622073724866
step: 420, loss: 0.0005984619492664933
step: 430, loss: 0.0003815095988102257
step: 440, loss: 0.0005352319567464292
step: 450, loss: 2.4381439288845286e-05
step: 460, loss: 3.469849252724089e-05
step: 470, loss: 4.7692617954453453e-05
step: 480, loss: 0.003063071519136429
step: 490, loss: 0.0010283051524311304
step: 500, loss: 2.3107388187781908e-05
step: 510, loss: 5.745015005231835e-05
step: 520, loss: 0.00018528205691836774
step: 530, loss: 0.00018975268176291138
step: 540, loss: 4.9304151616524905e-05
step: 550, loss: 5.825589323649183e-05
step: 560, loss: 0.0009354559588246047
step: 570, loss: 0.0016742898151278496
step: 580, loss: 5.8087502111447975e-05
step: 590, loss: 7.589977758470923e-05
step: 600, loss: 5.697654705727473e-05
step: 610, loss: 0.13589408993721008
step: 620, loss: 7.210572221083567e-05
step: 630, loss: 5.996556137688458e-05
epoch 15: dev_f1=0.9429622815087396, f1=0.9391705069124424, best_f1=0.94362292051756
step: 0, loss: 0.0003907465434167534
step: 10, loss: 8.474768401356414e-05
step: 20, loss: 7.309266220545396e-05
step: 30, loss: 2.8620343073271215e-05
step: 40, loss: 3.0724320822628215e-05
step: 50, loss: 6.183814548421651e-05
step: 60, loss: 0.0030964768957346678
step: 70, loss: 2.591247539385222e-05
step: 80, loss: 3.357464447617531e-05
step: 90, loss: 7.096158515196294e-05
step: 100, loss: 3.2376749004470184e-05
step: 110, loss: 2.083511571981944e-05
step: 120, loss: 0.00024958327412605286
step: 130, loss: 0.00035511134774424136
step: 140, loss: 0.0018397181993350387
step: 150, loss: 0.014014378190040588
step: 160, loss: 3.498273144941777e-05
step: 170, loss: 9.444269380765036e-05
step: 180, loss: 6.0534537624334916e-05
step: 190, loss: 6.442266021622345e-05
step: 200, loss: 2.964869054267183e-05
step: 210, loss: 0.0019096866017207503
step: 220, loss: 6.422689330065623e-05
step: 230, loss: 0.00012741881073452532
step: 240, loss: 4.9539972678758204e-05
step: 250, loss: 0.0015035835094749928
step: 260, loss: 4.7762492613401264e-05
step: 270, loss: 2.909698559960816e-05
step: 280, loss: 0.0014953111531212926
step: 290, loss: 0.00010863393254112452
step: 300, loss: 0.0002687112137209624
step: 310, loss: 0.00010579235095065087
step: 320, loss: 3.307716178824194e-05
step: 330, loss: 9.462769230594859e-05
step: 340, loss: 4.0091155824484304e-05
step: 350, loss: 3.732593540917151e-05
step: 360, loss: 3.454531542956829e-05
step: 370, loss: 9.40253958106041e-05
step: 380, loss: 8.055247599259019e-05
step: 390, loss: 0.00020090321777388453
step: 400, loss: 6.273922917898744e-05
step: 410, loss: 5.8160279877483845e-05
step: 420, loss: 2.5625562557252124e-05
step: 430, loss: 5.185452027944848e-05
step: 440, loss: 0.0006475584232248366
step: 450, loss: 3.9004557038424537e-05
step: 460, loss: 4.980161247658543e-05
step: 470, loss: 3.501098763081245e-05
step: 480, loss: 0.00021010289492551237
step: 490, loss: 0.0016969910357147455
step: 500, loss: 0.00013039333862252533
step: 510, loss: 2.1926400222582743e-05
step: 520, loss: 0.000143933852086775
step: 530, loss: 0.00047877454198896885
step: 540, loss: 0.00012012846127618104
step: 550, loss: 5.74060577491764e-05
step: 560, loss: 4.362454274087213e-05
step: 570, loss: 4.1728770156623796e-05
step: 580, loss: 3.0670580599689856e-05
step: 590, loss: 0.00019257543317507952
step: 600, loss: 0.00020685180788859725
step: 610, loss: 8.213128603529185e-05
step: 620, loss: 2.7211324777454138e-05
step: 630, loss: 0.0013929788256064057
epoch 16: dev_f1=0.941447671738128, f1=0.939435968562182, best_f1=0.94362292051756
step: 0, loss: 2.336823490622919e-05
step: 10, loss: 5.40693145012483e-05
step: 20, loss: 1.6383615729864687e-05
step: 30, loss: 5.770666030002758e-05
step: 40, loss: 0.001584129175171256
step: 50, loss: 4.88935511384625e-05
step: 60, loss: 0.002727231942117214
step: 70, loss: 0.00010081206710310653
step: 80, loss: 5.351407889975235e-05
step: 90, loss: 4.219346010359004e-05
step: 100, loss: 3.6221503250999376e-05
step: 110, loss: 3.012147317349445e-05
step: 120, loss: 7.482283399440348e-05
step: 130, loss: 2.6273630282958038e-05
step: 140, loss: 1.4245373677113093e-05
step: 150, loss: 0.000408534164307639
step: 160, loss: 2.1032505173934624e-05
step: 170, loss: 9.090798994293436e-05
step: 180, loss: 0.012788512744009495
step: 190, loss: 0.0005541821010410786
step: 200, loss: 4.530612568487413e-05
step: 210, loss: 0.0007477860199287534
step: 220, loss: 1.6454439901281148e-05
step: 230, loss: 0.0003840994613710791
step: 240, loss: 2.0298733943491243e-05
step: 250, loss: 0.0017969579203054309
step: 260, loss: 1.6115427570184693e-05
step: 270, loss: 1.7698557712719776e-05
step: 280, loss: 9.828569454839453e-05
step: 290, loss: 0.03289594128727913
step: 300, loss: 6.308229058049619e-05
step: 310, loss: 3.279929660493508e-05
step: 320, loss: 0.0001106712588807568
step: 330, loss: 2.6831083232536912e-05
step: 340, loss: 4.85511809529271e-05
step: 350, loss: 6.380448758136481e-05
step: 360, loss: 2.0585588572430424e-05
step: 370, loss: 1.778802470653318e-05
step: 380, loss: 7.065653335303068e-05
step: 390, loss: 1.7109994587372057e-05
step: 400, loss: 5.051638436270878e-05
step: 410, loss: 2.2771828298573382e-05
step: 420, loss: 1.6420784959336743e-05
step: 430, loss: 2.2280491975834593e-05
step: 440, loss: 0.00031457870500162244
step: 450, loss: 2.894365752581507e-05
step: 460, loss: 0.0001749528310028836
step: 470, loss: 3.072411709581502e-05
step: 480, loss: 1.762004649208393e-05
step: 490, loss: 1.6417137885582633e-05
step: 500, loss: 0.0003079894231632352
step: 510, loss: 2.4772487449808978e-05
step: 520, loss: 3.8261034205788746e-05
step: 530, loss: 8.369707938982174e-05
step: 540, loss: 1.8559025193098933e-05
step: 550, loss: 2.084245534206275e-05
step: 560, loss: 2.857121216948144e-05
step: 570, loss: 9.755206701811403e-05
step: 580, loss: 1.8339304006076418e-05
step: 590, loss: 2.2943451767787337e-05
step: 600, loss: 1.880476702353917e-05
step: 610, loss: 2.6463167159818113e-05
step: 620, loss: 2.2816038836026564e-05
step: 630, loss: 5.116448301123455e-05
epoch 17: dev_f1=0.9441624365482235, f1=0.9463955637707948, best_f1=0.94362292051756
step: 0, loss: 2.8961938369320706e-05
step: 10, loss: 1.9490293198032305e-05
step: 20, loss: 1.4852534150122665e-05
step: 30, loss: 3.6661433114204556e-05
step: 40, loss: 1.812321352190338e-05
step: 50, loss: 5.9745398175437e-05
step: 60, loss: 1.3112919077684637e-05
step: 70, loss: 2.369134199398104e-05
step: 80, loss: 1.872294524218887e-05
step: 90, loss: 3.0143195544951595e-05
step: 100, loss: 2.9238106435514055e-05
step: 110, loss: 2.0160649000899866e-05
step: 120, loss: 8.382203668588772e-05
step: 130, loss: 0.00011591365182539448
step: 140, loss: 3.131933408440091e-05
step: 150, loss: 0.0001614520006114617
step: 160, loss: 1.5035057003842667e-05
step: 170, loss: 0.007578220218420029
step: 180, loss: 0.04510148614645004
step: 190, loss: 2.3985889129107818e-05
step: 200, loss: 5.402956958278082e-05
step: 210, loss: 6.307462899712846e-05
step: 220, loss: 5.398812936618924e-05
step: 230, loss: 2.727510036493186e-05
step: 240, loss: 1.948284261743538e-05
step: 250, loss: 1.8093463950208388e-05
step: 260, loss: 0.0014853434404358268
step: 270, loss: 1.3600888451037463e-05
step: 280, loss: 2.107703039655462e-05
step: 290, loss: 1.9940876882174052e-05
step: 300, loss: 7.958249625517055e-05
step: 310, loss: 0.07931101322174072
step: 320, loss: 0.008859432302415371
step: 330, loss: 3.377421307959594e-05
step: 340, loss: 3.9488120819441974e-05
step: 350, loss: 0.00012311678437981755
step: 360, loss: 0.005311096087098122
step: 370, loss: 2.1751271560788155e-05
step: 380, loss: 4.583575719152577e-05
step: 390, loss: 0.005765811540186405
step: 400, loss: 2.2373234969563782e-05
step: 410, loss: 1.648788202146534e-05
step: 420, loss: 1.3686579222849105e-05
step: 430, loss: 0.003488564630970359
step: 440, loss: 3.759761602850631e-05
step: 450, loss: 0.002086700638756156
step: 460, loss: 0.004244021140038967
step: 470, loss: 2.6849784262594767e-05
step: 480, loss: 3.945920616388321e-05
step: 490, loss: 3.1924846553010866e-05
step: 500, loss: 6.77326024742797e-05
step: 510, loss: 2.168381070077885e-05
step: 520, loss: 2.1288948119035922e-05
step: 530, loss: 3.5831537388730794e-05
step: 540, loss: 1.3843063243257347e-05
step: 550, loss: 1.4126128007774241e-05
step: 560, loss: 1.5299487131414935e-05
step: 570, loss: 0.00013899445184506476
step: 580, loss: 2.2260464902501553e-05
step: 590, loss: 0.00012151807459304109
step: 600, loss: 1.3057022442808375e-05
step: 610, loss: 0.004042414948344231
step: 620, loss: 0.00010988688154611737
step: 630, loss: 1.7773027138900943e-05
epoch 18: dev_f1=0.9430670339761248, f1=0.9458218549127642, best_f1=0.94362292051756
step: 0, loss: 1.939712637977209e-05
step: 10, loss: 1.5705641999375075e-05
step: 20, loss: 1.3343881619221065e-05
step: 30, loss: 3.50589762092568e-05
step: 40, loss: 4.303380410419777e-05
step: 50, loss: 3.4759050322463736e-05
step: 60, loss: 9.52509290073067e-05
step: 70, loss: 0.00010520563228055835
step: 80, loss: 8.090961637208238e-05
step: 90, loss: 6.622754881391302e-05
step: 100, loss: 1.7620299331611022e-05
step: 110, loss: 6.910071533638984e-05
step: 120, loss: 2.7711601433111355e-05
step: 130, loss: 1.2978779523109552e-05
step: 140, loss: 0.0002734401205088943
step: 150, loss: 3.936594657716341e-05
step: 160, loss: 1.8987333533004858e-05
step: 170, loss: 1.3880282494938001e-05
step: 180, loss: 1.1779276064771693e-05
step: 190, loss: 0.00013459016918204725
step: 200, loss: 1.7016851415974088e-05
step: 210, loss: 1.201021768792998e-05
step: 220, loss: 1.6163849068107083e-05
step: 230, loss: 1.1790463759098202e-05
step: 240, loss: 1.830568362493068e-05
step: 250, loss: 1.3716352441406343e-05
step: 260, loss: 0.009429548867046833
step: 270, loss: 1.2181603779026773e-05
step: 280, loss: 1.449862520530587e-05
step: 290, loss: 0.07399725168943405
step: 300, loss: 1.6979518477455713e-05
step: 310, loss: 1.6700196283636615e-05
step: 320, loss: 0.00010479018237674609
step: 330, loss: 1.61412863235455e-05
step: 340, loss: 1.43198631121777e-05
step: 350, loss: 0.03353758901357651
step: 360, loss: 7.405746873700991e-05
step: 370, loss: 1.4807837942498736e-05
step: 380, loss: 1.4819019270362332e-05
step: 390, loss: 0.002487044082954526
step: 400, loss: 0.0010669545736163855
step: 410, loss: 1.2867008990724571e-05
step: 420, loss: 2.884477908082772e-05
step: 430, loss: 3.705116978380829e-05
step: 440, loss: 3.33234274876304e-05
step: 450, loss: 1.2256096852070186e-05
step: 460, loss: 1.3388451407081448e-05
step: 470, loss: 1.7012956959661096e-05
step: 480, loss: 0.007905351929366589
step: 490, loss: 7.135805208235979e-05
step: 500, loss: 2.6518095182836987e-05
step: 510, loss: 2.756495086941868e-05
step: 520, loss: 1.9341126971994527e-05
step: 530, loss: 1.5552801414742135e-05
step: 540, loss: 2.2462341803475283e-05
step: 550, loss: 0.002418329706415534
step: 560, loss: 0.0010809567756950855
step: 570, loss: 5.21089750691317e-05
step: 580, loss: 2.0703857444459572e-05
step: 590, loss: 0.004782324656844139
step: 600, loss: 1.9616714780568145e-05
step: 610, loss: 1.3556209523812868e-05
step: 620, loss: 1.2874495041614864e-05
step: 630, loss: 3.095739521086216e-05
epoch 19: dev_f1=0.9438305709023942, f1=0.9455216989843028, best_f1=0.94362292051756
step: 0, loss: 2.5634935809648596e-05
step: 10, loss: 1.4681202628707979e-05
step: 20, loss: 0.0003747169685084373
step: 30, loss: 1.4971763448556885e-05
step: 40, loss: 2.0019082512590103e-05
step: 50, loss: 2.529535413486883e-05
step: 60, loss: 8.961437561083585e-05
step: 70, loss: 8.56331389513798e-05
step: 80, loss: 1.683391928963829e-05
step: 90, loss: 1.1056592484237626e-05
step: 100, loss: 1.5862118743825704e-05
step: 110, loss: 1.2900532965431921e-05
step: 120, loss: 0.0016585745615884662
step: 130, loss: 4.8182708269450814e-05
step: 140, loss: 1.5113311746972613e-05
step: 150, loss: 3.060510425711982e-05
step: 160, loss: 0.0011852509342133999
step: 170, loss: 2.0697283616755158e-05
step: 180, loss: 1.2121990039304364e-05
step: 190, loss: 0.0001931142614921555
step: 200, loss: 1.2777641131833661e-05
step: 210, loss: 2.5430479581700638e-05
step: 220, loss: 0.00010933475277852267
step: 230, loss: 1.98550787899876e-05
step: 240, loss: 1.2915457773488015e-05
step: 250, loss: 2.5788644052227028e-05
step: 260, loss: 1.1864963198604528e-05
step: 270, loss: 1.8819013348547742e-05
step: 280, loss: 1.8640777852851897e-05
step: 290, loss: 0.001266522565856576
step: 300, loss: 2.3576254534418695e-05
step: 310, loss: 3.847140396828763e-05
step: 320, loss: 1.5273464669007808e-05
step: 330, loss: 2.8656122594838962e-05
step: 340, loss: 2.2216578145162202e-05
step: 350, loss: 1.4945680959499441e-05
step: 360, loss: 2.0283565390855074e-05
step: 370, loss: 2.9640212233061902e-05
step: 380, loss: 8.930726471589878e-05
step: 390, loss: 0.0007484782836399972
step: 400, loss: 2.594655961729586e-05
step: 410, loss: 1.4744423424417619e-05
step: 420, loss: 1.3515215869119857e-05
step: 430, loss: 0.0022287569008767605
step: 440, loss: 1.4833948625891935e-05
step: 450, loss: 3.866223414661363e-05
step: 460, loss: 1.403303031111136e-05
step: 470, loss: 1.4141077372187283e-05
step: 480, loss: 0.004908101167529821
step: 490, loss: 1.4334720617625862e-05
step: 500, loss: 2.235466308775358e-05
step: 510, loss: 3.7728226743638515e-05
step: 520, loss: 1.2446086657291744e-05
step: 530, loss: 4.701538273366168e-05
step: 540, loss: 1.4565710444003344e-05
step: 550, loss: 1.5705605619587004e-05
step: 560, loss: 2.619020415295381e-05
step: 570, loss: 2.8214373742230237e-05
step: 580, loss: 6.992658018134534e-05
step: 590, loss: 2.8820702937082388e-05
step: 600, loss: 1.2423736734490376e-05
step: 610, loss: 1.4401722182810772e-05
step: 620, loss: 1.4658718100690749e-05
step: 630, loss: 4.086199260200374e-05
epoch 20: dev_f1=0.9417163836622304, f1=0.9415554532903819, best_f1=0.94362292051756
