cuda
Device: cuda
step: 0, loss: 0.9518048167228699
step: 10, loss: 0.7415700554847717
step: 20, loss: 0.6672101616859436
step: 30, loss: 0.1977817565202713
step: 40, loss: 0.530689537525177
step: 50, loss: 0.3918144106864929
step: 60, loss: 0.24855740368366241
step: 70, loss: 0.31178227066993713
step: 80, loss: 0.45958656072616577
step: 90, loss: 0.19599904119968414
step: 100, loss: 0.3240284323692322
step: 110, loss: 0.2102731615304947
step: 120, loss: 0.18690191209316254
step: 130, loss: 0.40238064527511597
step: 140, loss: 0.22886821627616882
step: 150, loss: 0.20168974995613098
step: 160, loss: 0.15984028577804565
step: 170, loss: 0.09290421009063721
step: 180, loss: 0.16439351439476013
step: 190, loss: 0.21222637593746185
step: 200, loss: 0.19748687744140625
step: 210, loss: 0.23853038251399994
step: 220, loss: 0.23757852613925934
step: 230, loss: 0.09624221175909042
step: 240, loss: 0.08508101850748062
step: 250, loss: 0.15441080927848816
step: 260, loss: 0.20925883948802948
step: 270, loss: 0.12544173002243042
step: 280, loss: 0.18354618549346924
step: 290, loss: 0.16459904611110687
step: 300, loss: 0.06754684448242188
step: 310, loss: 0.1725163757801056
step: 320, loss: 0.17519943416118622
step: 330, loss: 0.16099479794502258
step: 340, loss: 0.22648093104362488
step: 350, loss: 0.15869897603988647
step: 360, loss: 0.0816342830657959
step: 370, loss: 0.13192875683307648
step: 380, loss: 0.16785724461078644
step: 390, loss: 0.0565900020301342
step: 400, loss: 0.002126712119206786
step: 410, loss: 0.03213519603013992
step: 420, loss: 0.06494159996509552
step: 430, loss: 0.22313596308231354
step: 440, loss: 0.12958036363124847
step: 450, loss: 0.26578670740127563
step: 460, loss: 0.15745672583580017
step: 470, loss: 0.14769047498703003
step: 480, loss: 0.15760456025600433
step: 490, loss: 0.07128501683473587
step: 500, loss: 0.026199452579021454
step: 510, loss: 0.18927960097789764
step: 520, loss: 0.3531336486339569
step: 530, loss: 0.10951216518878937
step: 540, loss: 0.1664159893989563
step: 550, loss: 0.10967397689819336
step: 560, loss: 0.01064232550561428
step: 570, loss: 0.07444380223751068
step: 580, loss: 0.07987724989652634
step: 590, loss: 0.16921882331371307
step: 600, loss: 0.12593069672584534
step: 610, loss: 0.1633015275001526
step: 620, loss: 0.09684719145298004
step: 630, loss: 0.27788665890693665
step: 640, loss: 0.20168225467205048
step: 650, loss: 0.03952975571155548
step: 660, loss: 0.09246277064085007
step: 670, loss: 0.012579589150846004
step: 680, loss: 0.18563075363636017
step: 690, loss: 0.0253851767629385
step: 700, loss: 0.06240996718406677
step: 710, loss: 0.03213605657219887
step: 720, loss: 0.13205772638320923
step: 730, loss: 0.09964705258607864
step: 740, loss: 0.1183106005191803
step: 750, loss: 0.027109766378998756
step: 760, loss: 0.1251215934753418
step: 770, loss: 0.2686564028263092
step: 780, loss: 0.21873749792575836
step: 790, loss: 0.15663646161556244
step: 800, loss: 0.029586801305413246
step: 810, loss: 0.029359858483076096
step: 820, loss: 0.13262102007865906
step: 830, loss: 0.12939666211605072
step: 840, loss: 0.23395800590515137
step: 850, loss: 0.07414161413908005
step: 860, loss: 0.2640847861766815
step: 870, loss: 0.06031578779220581
step: 880, loss: 0.27580389380455017
step: 890, loss: 0.12114906311035156
step: 900, loss: 0.12875115871429443
step: 910, loss: 0.16899271309375763
step: 920, loss: 0.025934094563126564
step: 930, loss: 0.16112717986106873
step: 940, loss: 0.08112668246030807
step: 950, loss: 0.06269162148237228
step: 960, loss: 0.06773045659065247
step: 970, loss: 0.08583494275808334
step: 980, loss: 0.04457803815603256
step: 990, loss: 0.07204920798540115
step: 1000, loss: 0.15974168479442596
step: 1010, loss: 0.15428650379180908
step: 1020, loss: 0.10607846081256866
step: 1030, loss: 0.13268223404884338
step: 1040, loss: 0.07473568618297577
step: 1050, loss: 0.04534272104501724
step: 1060, loss: 0.1536336988210678
step: 1070, loss: 0.13389013707637787
epoch 1: dev_f1=0.921803127874885, f1=0.9200367647058824, best_f1=0.9200367647058824
step: 0, loss: 0.16694748401641846
step: 10, loss: 0.25414031744003296
step: 20, loss: 0.17535167932510376
step: 30, loss: 0.04419775307178497
step: 40, loss: 0.07062143087387085
step: 50, loss: 0.04606584832072258
step: 60, loss: 0.060843244194984436
step: 70, loss: 0.01433479692786932
step: 80, loss: 0.08168189227581024
step: 90, loss: 0.04083145409822464
step: 100, loss: 0.09561161696910858
step: 110, loss: 0.17243118584156036
step: 120, loss: 0.018938856199383736
step: 130, loss: 0.04307975992560387
step: 140, loss: 0.1261170655488968
step: 150, loss: 0.009235485456883907
step: 160, loss: 0.09605409950017929
step: 170, loss: 0.11143709719181061
step: 180, loss: 0.06560036540031433
step: 190, loss: 0.05012786388397217
step: 200, loss: 0.04370570927858353
step: 210, loss: 0.04243866726756096
step: 220, loss: 0.1819053441286087
step: 230, loss: 0.257235586643219
step: 240, loss: 0.08563300967216492
step: 250, loss: 0.030753664672374725
step: 260, loss: 0.07923584431409836
step: 270, loss: 0.1366472840309143
step: 280, loss: 0.09198839962482452
step: 290, loss: 0.1548415869474411
step: 300, loss: 0.08370707929134369
step: 310, loss: 0.20529066026210785
step: 320, loss: 0.052886612713336945
step: 330, loss: 0.08742741495370865
step: 340, loss: 0.09677638858556747
step: 350, loss: 0.0895506739616394
step: 360, loss: 0.10476159304380417
step: 370, loss: 0.08697547018527985
step: 380, loss: 0.194009929895401
step: 390, loss: 0.10746817290782928
step: 400, loss: 0.049936823546886444
step: 410, loss: 0.07244264334440231
step: 420, loss: 0.06648316979408264
step: 430, loss: 0.0857909768819809
step: 440, loss: 0.13273614645004272
step: 450, loss: 0.08093806356191635
step: 460, loss: 0.04166688024997711
step: 470, loss: 0.15835097432136536
step: 480, loss: 0.04396022483706474
step: 490, loss: 0.0713731124997139
step: 500, loss: 0.14368851482868195
step: 510, loss: 0.036088500171899796
step: 520, loss: 0.11950048804283142
step: 530, loss: 0.04866520315408707
step: 540, loss: 0.06796407699584961
step: 550, loss: 0.019974039867520332
step: 560, loss: 0.11430869251489639
step: 570, loss: 0.1401192843914032
step: 580, loss: 0.06265516579151154
step: 590, loss: 0.02108316868543625
step: 600, loss: 0.06682340800762177
step: 610, loss: 0.14133262634277344
step: 620, loss: 0.07734496146440506
step: 630, loss: 0.0512668676674366
step: 640, loss: 0.10651976615190506
step: 650, loss: 0.13235050439834595
step: 660, loss: 0.08167488127946854
step: 670, loss: 0.1842658370733261
step: 680, loss: 0.052577342838048935
step: 690, loss: 0.1794934719800949
step: 700, loss: 0.08427827805280685
step: 710, loss: 0.10030540823936462
step: 720, loss: 0.04931856691837311
step: 730, loss: 0.07430846989154816
step: 740, loss: 0.1123218685388565
step: 750, loss: 0.2790432572364807
step: 760, loss: 0.030420659109950066
step: 770, loss: 0.06861895322799683
step: 780, loss: 0.10672090202569962
step: 790, loss: 0.08297775685787201
step: 800, loss: 0.23536434769630432
step: 810, loss: 0.07746383547782898
step: 820, loss: 0.1698906123638153
step: 830, loss: 0.16931819915771484
step: 840, loss: 0.07383361458778381
step: 850, loss: 0.19568045437335968
step: 860, loss: 0.024544626474380493
step: 870, loss: 0.0911615714430809
step: 880, loss: 0.12760885059833527
step: 890, loss: 0.033795420080423355
step: 900, loss: 0.07085224986076355
step: 910, loss: 0.0668082982301712
step: 920, loss: 0.10827677696943283
step: 930, loss: 0.005322838202118874
step: 940, loss: 0.1415625959634781
step: 950, loss: 0.08947736769914627
step: 960, loss: 0.016764549538493156
step: 970, loss: 0.031563304364681244
step: 980, loss: 0.20473581552505493
step: 990, loss: 0.09555661678314209
step: 1000, loss: 0.03213772177696228
step: 1010, loss: 0.10172873735427856
step: 1020, loss: 0.027365388348698616
step: 1030, loss: 0.04948855936527252
step: 1040, loss: 0.059047672897577286
step: 1050, loss: 0.05565590411424637
step: 1060, loss: 0.052985697984695435
step: 1070, loss: 0.11214254796504974
epoch 2: dev_f1=0.9336470588235295, f1=0.9260299625468165, best_f1=0.9260299625468165
step: 0, loss: 0.029529238119721413
step: 10, loss: 0.11152902990579605
step: 20, loss: 0.08242896944284439
step: 30, loss: 0.06716834008693695
step: 40, loss: 0.0072599146515131
step: 50, loss: 0.00012564404460135847
step: 60, loss: 0.025050397962331772
step: 70, loss: 0.03152962028980255
step: 80, loss: 0.0317254513502121
step: 90, loss: 0.1839485466480255
step: 100, loss: 0.22732050716876984
step: 110, loss: 0.0032664372120052576
step: 120, loss: 0.08664730191230774
step: 130, loss: 0.020709997043013573
step: 140, loss: 0.019772911444306374
step: 150, loss: 0.024028627201914787
step: 160, loss: 0.08563536405563354
step: 170, loss: 0.09086475521326065
step: 180, loss: 0.23106639087200165
step: 190, loss: 0.031396809965372086
step: 200, loss: 0.08239053189754486
step: 210, loss: 0.006156096234917641
step: 220, loss: 0.09064619243144989
step: 230, loss: 0.09762623906135559
step: 240, loss: 0.026486128568649292
step: 250, loss: 0.06950850039720535
step: 260, loss: 0.019793156534433365
step: 270, loss: 0.12178536504507065
step: 280, loss: 0.12529203295707703
step: 290, loss: 0.18881309032440186
step: 300, loss: 0.04165688529610634
step: 310, loss: 0.05690004304051399
step: 320, loss: 0.041862603276968
step: 330, loss: 0.023932963609695435
step: 340, loss: 0.012481804937124252
step: 350, loss: 0.19368723034858704
step: 360, loss: 0.14438636600971222
step: 370, loss: 0.09449931979179382
step: 380, loss: 0.08557315915822983
step: 390, loss: 0.12890177965164185
step: 400, loss: 0.0766754224896431
step: 410, loss: 0.00950128585100174
step: 420, loss: 0.025173677131533623
step: 430, loss: 0.23082289099693298
step: 440, loss: 0.09935009479522705
step: 450, loss: 0.08798322826623917
step: 460, loss: 0.1223527044057846
step: 470, loss: 0.09330138564109802
step: 480, loss: 0.03195410594344139
step: 490, loss: 0.1702442616224289
step: 500, loss: 0.04089415445923805
step: 510, loss: 0.061258796602487564
step: 520, loss: 0.06293584406375885
step: 530, loss: 0.09410873800516129
step: 540, loss: 0.03238163888454437
step: 550, loss: 0.06416234374046326
step: 560, loss: 0.0680839866399765
step: 570, loss: 0.04899557679891586
step: 580, loss: 0.022816399112343788
step: 590, loss: 0.122950978577137
step: 600, loss: 0.08039212226867676
step: 610, loss: 0.060337819159030914
step: 620, loss: 0.11646797508001328
step: 630, loss: 0.09527761489152908
step: 640, loss: 0.0917472094297409
step: 650, loss: 0.07630035281181335
step: 660, loss: 0.1885671466588974
step: 670, loss: 0.15317115187644958
step: 680, loss: 0.027236536145210266
step: 690, loss: 0.08970659226179123
step: 700, loss: 0.07031167298555374
step: 710, loss: 0.028519282117486
step: 720, loss: 0.20977763831615448
step: 730, loss: 0.0849829688668251
step: 740, loss: 0.009881571866571903
step: 750, loss: 0.03830853849649429
step: 760, loss: 0.19321951270103455
step: 770, loss: 0.26228269934654236
step: 780, loss: 0.01116496417671442
step: 790, loss: 0.1295214593410492
step: 800, loss: 0.02044648677110672
step: 810, loss: 0.09393411874771118
step: 820, loss: 0.04806622862815857
step: 830, loss: 0.032238759100437164
step: 840, loss: 0.04970398172736168
step: 850, loss: 0.06044181063771248
step: 860, loss: 0.04412217065691948
step: 870, loss: 0.09169509261846542
step: 880, loss: 0.17684197425842285
step: 890, loss: 0.05020766705274582
step: 900, loss: 0.07612821459770203
step: 910, loss: 0.02528746798634529
step: 920, loss: 0.02572040632367134
step: 930, loss: 0.09362127631902695
step: 940, loss: 0.17487238347530365
step: 950, loss: 0.07333939522504807
step: 960, loss: 0.11571753770112991
step: 970, loss: 0.10640044510364532
step: 980, loss: 0.2387334406375885
step: 990, loss: 0.04371309652924538
step: 1000, loss: 0.06854286044836044
step: 1010, loss: 0.11998388916254044
step: 1020, loss: 0.02205793187022209
step: 1030, loss: 0.042501289397478104
step: 1040, loss: 0.03153909742832184
step: 1050, loss: 0.07933291792869568
step: 1060, loss: 0.02155638486146927
step: 1070, loss: 0.0978977382183075
epoch 3: dev_f1=0.9429097605893186, f1=0.9336384439359268, best_f1=0.9336384439359268
step: 0, loss: 0.03533925488591194
step: 10, loss: 0.01901615783572197
step: 20, loss: 0.08002221584320068
step: 30, loss: 0.06766358017921448
step: 40, loss: 0.00420571630820632
step: 50, loss: 0.07369206100702286
step: 60, loss: 0.1000715047121048
step: 70, loss: 0.08089000731706619
step: 80, loss: 0.08400510996580124
step: 90, loss: 0.07048528641462326
step: 100, loss: 0.03395438939332962
step: 110, loss: 0.09940265864133835
step: 120, loss: 0.07014515995979309
step: 130, loss: 0.003952863626182079
step: 140, loss: 0.01017957367002964
step: 150, loss: 0.025113673880696297
step: 160, loss: 0.0903383195400238
step: 170, loss: 0.057483091950416565
step: 180, loss: 0.04924267157912254
step: 190, loss: 0.058087173849344254
step: 200, loss: 0.006078230682760477
step: 210, loss: 0.10336662083864212
step: 220, loss: 0.0754823312163353
step: 230, loss: 0.08959288895130157
step: 240, loss: 0.01958928257226944
step: 250, loss: 0.15858690440654755
step: 260, loss: 0.010060654953122139
step: 270, loss: 0.03037104941904545
step: 280, loss: 0.017667623236775398
step: 290, loss: 0.167313352227211
step: 300, loss: 0.052858058363199234
step: 310, loss: 0.05958408862352371
step: 320, loss: 0.10251585394144058
step: 330, loss: 0.09049165993928909
step: 340, loss: 0.023198070004582405
step: 350, loss: 0.041594214737415314
step: 360, loss: 0.16906338930130005
step: 370, loss: 0.12674908339977264
step: 380, loss: 0.03996475785970688
step: 390, loss: 0.008476587012410164
step: 400, loss: 0.024908922612667084
step: 410, loss: 0.039748139679431915
step: 420, loss: 0.1306448131799698
step: 430, loss: 0.035541970282793045
step: 440, loss: 0.04213820397853851
step: 450, loss: 0.012857237830758095
step: 460, loss: 0.13634949922561646
step: 470, loss: 0.04420219734311104
step: 480, loss: 0.05624547228217125
step: 490, loss: 0.10315654426813126
step: 500, loss: 0.14440718293190002
step: 510, loss: 0.08955471962690353
step: 520, loss: 0.02872171252965927
step: 530, loss: 0.02370290830731392
step: 540, loss: 0.04469931870698929
step: 550, loss: 0.11265437304973602
step: 560, loss: 0.025092093273997307
step: 570, loss: 0.012743509374558926
step: 580, loss: 0.009568331763148308
step: 590, loss: 0.10723874717950821
step: 600, loss: 0.06725721806287766
step: 610, loss: 0.03481747955083847
step: 620, loss: 0.05901780351996422
step: 630, loss: 0.16296261548995972
step: 640, loss: 0.030441969633102417
step: 650, loss: 0.12393853813409805
step: 660, loss: 0.3654423654079437
step: 670, loss: 0.12272365391254425
step: 680, loss: 0.1528158187866211
step: 690, loss: 0.18817630410194397
step: 700, loss: 0.017385147511959076
step: 710, loss: 0.0677102655172348
step: 720, loss: 0.06403295695781708
step: 730, loss: 0.04263404756784439
step: 740, loss: 0.0375758558511734
step: 750, loss: 0.009177095256745815
step: 760, loss: 0.12217501550912857
step: 770, loss: 0.06552775949239731
step: 780, loss: 0.07598015666007996
step: 790, loss: 0.02354104444384575
step: 800, loss: 0.013657663948833942
step: 810, loss: 0.027315281331539154
step: 820, loss: 0.005026120692491531
step: 830, loss: 0.029484054073691368
step: 840, loss: 0.1599069982767105
step: 850, loss: 0.03703116998076439
step: 860, loss: 0.03640177473425865
step: 870, loss: 0.1404772251844406
step: 880, loss: 0.06561672687530518
step: 890, loss: 0.05970435589551926
step: 900, loss: 0.08862054347991943
step: 910, loss: 0.12473727017641068
step: 920, loss: 0.0631023496389389
step: 930, loss: 0.13264381885528564
step: 940, loss: 0.055910658091306686
step: 950, loss: 0.07345477491617203
step: 960, loss: 0.11563470959663391
step: 970, loss: 0.08851362764835358
step: 980, loss: 0.06485889106988907
step: 990, loss: 0.042211856693029404
step: 1000, loss: 0.31675171852111816
step: 1010, loss: 0.10713956505060196
step: 1020, loss: 0.07765264809131622
step: 1030, loss: 0.061759889125823975
step: 1040, loss: 0.03967089578509331
step: 1050, loss: 0.09072394669055939
step: 1060, loss: 0.0032058905344456434
step: 1070, loss: 0.042901232838630676
epoch 4: dev_f1=0.9214611872146119, f1=0.9154545454545453, best_f1=0.9336384439359268
step: 0, loss: 0.016822287812829018
step: 10, loss: 0.037846408784389496
step: 20, loss: 0.07653443515300751
step: 30, loss: 0.07722160220146179
step: 40, loss: 0.05986243113875389
step: 50, loss: 0.09821654856204987
step: 60, loss: 0.02240646257996559
step: 70, loss: 0.011602813377976418
step: 80, loss: 0.03304270654916763
step: 90, loss: 0.04601666331291199
step: 100, loss: 0.005805123597383499
step: 110, loss: 0.0536375530064106
step: 120, loss: 0.077424556016922
step: 130, loss: 0.16038362681865692
step: 140, loss: 0.05585877597332001
step: 150, loss: 0.07893982529640198
step: 160, loss: 0.09648870676755905
step: 170, loss: 0.043931372463703156
step: 180, loss: 0.032857511192560196
step: 190, loss: 0.027837133035063744
step: 200, loss: 0.1046258732676506
step: 210, loss: 0.058555975556373596
step: 220, loss: 0.0650818943977356
step: 230, loss: 0.03019420988857746
step: 240, loss: 0.01936117559671402
step: 250, loss: 0.0308529082685709
step: 260, loss: 0.02739543840289116
step: 270, loss: 0.03109877184033394
step: 280, loss: 0.00028614126495085657
step: 290, loss: 0.09269053488969803
step: 300, loss: 0.08300373703241348
step: 310, loss: 0.08366496115922928
step: 320, loss: 0.05123033747076988
step: 330, loss: 0.10526786744594574
step: 340, loss: 0.003941111266613007
step: 350, loss: 0.03234679251909256
step: 360, loss: 0.07079372555017471
step: 370, loss: 0.04526697099208832
step: 380, loss: 0.03895808011293411
step: 390, loss: 0.20961681008338928
step: 400, loss: 0.019727014005184174
step: 410, loss: 0.020660100504755974
step: 420, loss: 0.08258042484521866
step: 430, loss: 0.05871446803212166
step: 440, loss: 0.052859582006931305
step: 450, loss: 0.06895842403173447
step: 460, loss: 0.07502322643995285
step: 470, loss: 0.08052296936511993
step: 480, loss: 0.014039352536201477
step: 490, loss: 0.15135367214679718
step: 500, loss: 0.06993754953145981
step: 510, loss: 0.05786196142435074
step: 520, loss: 0.019018014892935753
step: 530, loss: 0.013766366057097912
step: 540, loss: 0.02837158739566803
step: 550, loss: 0.009696933440864086
step: 560, loss: 0.07447397708892822
step: 570, loss: 0.06508607417345047
step: 580, loss: 0.11804627627134323
step: 590, loss: 0.050972357392311096
step: 600, loss: 0.0350818932056427
step: 610, loss: 0.0009582116617821157
step: 620, loss: 0.08025722205638885
step: 630, loss: 0.09129957109689713
step: 640, loss: 0.07889379560947418
step: 650, loss: 0.0067941839806735516
step: 660, loss: 0.05410677194595337
step: 670, loss: 0.019550535827875137
step: 680, loss: 0.0519760437309742
step: 690, loss: 0.10231662541627884
step: 700, loss: 0.11391018331050873
step: 710, loss: 0.16734115779399872
step: 720, loss: 0.12967641651630402
step: 730, loss: 0.07114192843437195
step: 740, loss: 0.032475393265485764
step: 750, loss: 0.011974958702921867
step: 760, loss: 0.06292274594306946
step: 770, loss: 0.021866507828235626
step: 780, loss: 0.027778172865509987
step: 790, loss: 0.12483293563127518
step: 800, loss: 0.12532687187194824
step: 810, loss: 0.12621429562568665
step: 820, loss: 0.03036641515791416
step: 830, loss: 0.0427340604364872
step: 840, loss: 0.06395065039396286
step: 850, loss: 0.04054062440991402
step: 860, loss: 0.05565613880753517
step: 870, loss: 0.0693637877702713
step: 880, loss: 0.058827146887779236
step: 890, loss: 0.05694577842950821
step: 900, loss: 0.09749849885702133
step: 910, loss: 0.017300644889473915
step: 920, loss: 0.0019782190211117268
step: 930, loss: 0.07173354923725128
step: 940, loss: 0.024078477174043655
step: 950, loss: 0.026747530326247215
step: 960, loss: 0.012846741825342178
step: 970, loss: 0.1432962417602539
step: 980, loss: 0.11428423970937729
step: 990, loss: 0.009421071968972683
step: 1000, loss: 0.05576227605342865
step: 1010, loss: 0.15770843625068665
step: 1020, loss: 0.007419884670525789
step: 1030, loss: 0.056266117841005325
step: 1040, loss: 0.012219387106597424
step: 1050, loss: 0.015788396820425987
step: 1060, loss: 0.08770465105772018
step: 1070, loss: 0.020131438970565796
epoch 5: dev_f1=0.9363261566651397, f1=0.9326047358834245, best_f1=0.9336384439359268
step: 0, loss: 0.04913530498743057
step: 10, loss: 0.0009500356391072273
step: 20, loss: 0.06118194758892059
step: 30, loss: 0.12012333422899246
step: 40, loss: 0.08484605699777603
step: 50, loss: 0.023898500949144363
step: 60, loss: 0.10279179364442825
step: 70, loss: 0.02617967128753662
step: 80, loss: 0.032162997871637344
step: 90, loss: 0.025131706148386
step: 100, loss: 0.03334718570113182
step: 110, loss: 0.055028002709150314
step: 120, loss: 0.0521494559943676
step: 130, loss: 0.14845213294029236
step: 140, loss: 0.059976544231176376
step: 150, loss: 0.15767373144626617
step: 160, loss: 0.07987548410892487
step: 170, loss: 0.07708898186683655
step: 180, loss: 0.03633370250463486
step: 190, loss: 0.06176365911960602
step: 200, loss: 0.10780496895313263
step: 210, loss: 0.051798295229673386
step: 220, loss: 0.007204520981758833
step: 230, loss: 0.05264287069439888
step: 240, loss: 0.07581844180822372
step: 250, loss: 0.07224542647600174
step: 260, loss: 0.08545459806919098
step: 270, loss: 0.007972496561706066
step: 280, loss: 0.057962581515312195
step: 290, loss: 0.13932441174983978
step: 300, loss: 0.007196005433797836
step: 310, loss: 0.12013910710811615
step: 320, loss: 0.05035695433616638
step: 330, loss: 0.006807664409279823
step: 340, loss: 0.061148110777139664
step: 350, loss: 0.03547613322734833
step: 360, loss: 0.0919993668794632
step: 370, loss: 0.1455029845237732
step: 380, loss: 0.07042553275823593
step: 390, loss: 0.0033295657485723495
step: 400, loss: 0.004038737155497074
step: 410, loss: 0.0283892210572958
step: 420, loss: 0.001438155653886497
step: 430, loss: 0.010132411494851112
step: 440, loss: 0.052104730159044266
step: 450, loss: 0.08289676904678345
step: 460, loss: 0.020040730014443398
step: 470, loss: 0.08080969005823135
step: 480, loss: 0.09046974033117294
step: 490, loss: 0.02861436828970909
step: 500, loss: 0.02341022901237011
step: 510, loss: 0.01263983454555273
step: 520, loss: 0.1001078188419342
step: 530, loss: 0.05860777199268341
step: 540, loss: 0.06923417001962662
step: 550, loss: 0.021612798795104027
step: 560, loss: 0.20492258667945862
step: 570, loss: 0.03425584360957146
step: 580, loss: 0.017686130478978157
step: 590, loss: 0.06792605668306351
step: 600, loss: 0.014861347153782845
step: 610, loss: 0.051971953362226486
step: 620, loss: 0.037105850875377655
step: 630, loss: 0.014707352966070175
step: 640, loss: 0.03251855447888374
step: 650, loss: 0.06883308291435242
step: 660, loss: 0.061903223395347595
step: 670, loss: 0.04105450585484505
step: 680, loss: 0.02115705981850624
step: 690, loss: 0.042843177914619446
step: 700, loss: 0.0901046097278595
step: 710, loss: 0.03135308995842934
step: 720, loss: 0.005109824240207672
step: 730, loss: 0.020069759339094162
step: 740, loss: 0.008368786424398422
step: 750, loss: 0.014889378100633621
step: 760, loss: 0.03178904950618744
step: 770, loss: 0.010026204399764538
step: 780, loss: 0.026233309879899025
step: 790, loss: 0.04550691321492195
step: 800, loss: 0.14550407230854034
step: 810, loss: 0.1191936656832695
step: 820, loss: 0.034565821290016174
step: 830, loss: 0.14425356686115265
step: 840, loss: 0.01110883429646492
step: 850, loss: 0.18612247705459595
step: 860, loss: 0.10078649967908859
step: 870, loss: 0.06334629654884338
step: 880, loss: 0.10999002307653427
step: 890, loss: 0.058892957866191864
step: 900, loss: 0.03589244186878204
step: 910, loss: 0.04697392135858536
step: 920, loss: 0.017755113542079926
step: 930, loss: 0.026344146579504013
step: 940, loss: 0.05891698598861694
step: 950, loss: 0.03801098093390465
step: 960, loss: 0.18954028189182281
step: 970, loss: 0.03867621347308159
step: 980, loss: 0.1005750522017479
step: 990, loss: 0.12456334382295609
step: 1000, loss: 0.09231065213680267
step: 1010, loss: 0.03160873055458069
step: 1020, loss: 0.06570688635110855
step: 1030, loss: 0.018132099881768227
step: 1040, loss: 0.03926032409071922
step: 1050, loss: 0.04372473433613777
step: 1060, loss: 0.060022175312042236
step: 1070, loss: 0.03846503049135208
epoch 6: dev_f1=0.9416705552963137, f1=0.9333950046253469, best_f1=0.9336384439359268
step: 0, loss: 0.03147093206644058
step: 10, loss: 0.03613080456852913
step: 20, loss: 0.025637436658143997
step: 30, loss: 0.06449902057647705
step: 40, loss: 0.02603946439921856
step: 50, loss: 0.10457304120063782
step: 60, loss: 0.009271984919905663
step: 70, loss: 0.03636949509382248
step: 80, loss: 0.06505878269672394
step: 90, loss: 0.11023427546024323
step: 100, loss: 0.10117783397436142
step: 110, loss: 0.03835006803274155
step: 120, loss: 0.06946038454771042
step: 130, loss: 0.18301749229431152
step: 140, loss: 0.0317174568772316
step: 150, loss: 0.00821924302726984
step: 160, loss: 0.06836177408695221
step: 170, loss: 0.03565549850463867
step: 180, loss: 0.0562027283012867
step: 190, loss: 0.1412329226732254
step: 200, loss: 0.03256043791770935
step: 210, loss: 0.08774293214082718
step: 220, loss: 0.05865591764450073
step: 230, loss: 0.07407717406749725
step: 240, loss: 0.05787160247564316
step: 250, loss: 0.024770721793174744
step: 260, loss: 0.0214858241379261
step: 270, loss: 0.12856034934520721
step: 280, loss: 0.0632447600364685
step: 290, loss: 0.07119300216436386
step: 300, loss: 0.06946168839931488
step: 310, loss: 0.059245988726615906
step: 320, loss: 0.015596144832670689
step: 330, loss: 0.00971614196896553
step: 340, loss: 0.09356223046779633
step: 350, loss: 0.036021772772073746
step: 360, loss: 0.16102878749370575
step: 370, loss: 0.002718256087973714
step: 380, loss: 0.0061444551683962345
step: 390, loss: 0.07408999651670456
step: 400, loss: 0.1029999852180481
step: 410, loss: 0.04779999330639839
step: 420, loss: 0.10943370312452316
step: 430, loss: 0.045538533478975296
step: 440, loss: 0.17444565892219543
step: 450, loss: 0.05132989212870598
step: 460, loss: 0.00043673362233676016
step: 470, loss: 0.10496222972869873
step: 480, loss: 0.020466160029172897
step: 490, loss: 0.0010098647326231003
step: 500, loss: 0.1388656049966812
step: 510, loss: 0.014551256783306599
step: 520, loss: 0.010330911725759506
step: 530, loss: 0.0759902223944664
step: 540, loss: 0.0759841725230217
step: 550, loss: 0.09286076575517654
step: 560, loss: 0.054245565086603165
step: 570, loss: 0.06344002485275269
step: 580, loss: 0.01325818058103323
step: 590, loss: 0.04033753275871277
step: 600, loss: 0.01799752749502659
step: 610, loss: 0.02979709580540657
step: 620, loss: 0.008489486761391163
step: 630, loss: 0.02456258051097393
step: 640, loss: 0.014826937578618526
step: 650, loss: 0.09776222705841064
step: 660, loss: 0.022559355944395065
step: 670, loss: 0.06916549056768417
step: 680, loss: 0.0493110828101635
step: 690, loss: 0.06678914278745651
step: 700, loss: 0.01871320977807045
step: 710, loss: 0.013723497278988361
step: 720, loss: 0.08023886382579803
step: 730, loss: 0.05196531489491463
step: 740, loss: 0.04986969009041786
step: 750, loss: 0.1116982027888298
step: 760, loss: 0.09094640612602234
step: 770, loss: 0.0647534504532814
step: 780, loss: 0.0002796528278850019
step: 790, loss: 0.09756620228290558
step: 800, loss: 0.05431045591831207
step: 810, loss: 0.1296137124300003
step: 820, loss: 0.04051421582698822
step: 830, loss: 0.0013407710939645767
step: 840, loss: 0.02750493586063385
step: 850, loss: 0.06402404606342316
step: 860, loss: 0.01742004230618477
step: 870, loss: 0.10397211462259293
step: 880, loss: 0.038347046822309494
step: 890, loss: 0.03317052125930786
step: 900, loss: 0.049919214099645615
step: 910, loss: 0.021563153713941574
step: 920, loss: 0.051062438637018204
step: 930, loss: 0.0004552683385554701
step: 940, loss: 0.014042285270988941
step: 950, loss: 0.06415600329637527
step: 960, loss: 0.030135128647089005
step: 970, loss: 0.039955686777830124
step: 980, loss: 0.05599958449602127
step: 990, loss: 0.06830846518278122
step: 1000, loss: 9.39105375437066e-05
step: 1010, loss: 0.10908910632133484
step: 1020, loss: 0.023182885721325874
step: 1030, loss: 0.029273098334670067
step: 1040, loss: 0.0764956921339035
step: 1050, loss: 0.059434425085783005
step: 1060, loss: 0.054670996963977814
step: 1070, loss: 0.08976060897111893
epoch 7: dev_f1=0.9266266728195662, f1=0.9274965800273598, best_f1=0.9336384439359268
step: 0, loss: 0.04405902326107025
step: 10, loss: 0.11963052302598953
step: 20, loss: 0.1345738023519516
step: 30, loss: 0.01603757031261921
step: 40, loss: 9.533950651530176e-05
step: 50, loss: 0.015270022675395012
step: 60, loss: 0.05613165721297264
step: 70, loss: 0.04865647852420807
step: 80, loss: 0.06918339431285858
step: 90, loss: 0.04210290685296059
step: 100, loss: 0.05330541729927063
step: 110, loss: 0.081375852227211
step: 120, loss: 0.0426035150885582
step: 130, loss: 0.040797632187604904
step: 140, loss: 0.007959950715303421
step: 150, loss: 0.07356122881174088
step: 160, loss: 0.024001967161893845
step: 170, loss: 0.12871211767196655
step: 180, loss: 0.0018876878311857581
step: 190, loss: 0.018555616959929466
step: 200, loss: 0.015036378055810928
step: 210, loss: 0.00034691314795054495
step: 220, loss: 0.04524493217468262
step: 230, loss: 0.010263940319418907
step: 240, loss: 0.009317612275481224
step: 250, loss: 0.04377540200948715
step: 260, loss: 0.04220633953809738
step: 270, loss: 0.10762608051300049
step: 280, loss: 0.04598959535360336
step: 290, loss: 0.1816735565662384
step: 300, loss: 0.06413082033395767
step: 310, loss: 0.008240710943937302
step: 320, loss: 0.054343413561582565
step: 330, loss: 0.07118111848831177
step: 340, loss: 0.039372313767671585
step: 350, loss: 0.005156719125807285
step: 360, loss: 0.02356962114572525
step: 370, loss: 0.05026274546980858
step: 380, loss: 0.08748897910118103
step: 390, loss: 0.011461246758699417
step: 400, loss: 0.0396573543548584
step: 410, loss: 0.10435321927070618
step: 420, loss: 0.14183926582336426
step: 430, loss: 0.03051293082535267
step: 440, loss: 0.046141114085912704
step: 450, loss: 0.021781323477625847
step: 460, loss: 0.0005013429326936603
step: 470, loss: 0.027620580047369003
step: 480, loss: 0.07113402336835861
step: 490, loss: 5.982964648865163e-05
step: 500, loss: 0.21175071597099304
step: 510, loss: 0.006947425194084644
step: 520, loss: 0.029064513742923737
step: 530, loss: 0.11567855626344681
step: 540, loss: 0.001532096299342811
step: 550, loss: 0.04654846340417862
step: 560, loss: 0.014600589871406555
step: 570, loss: 0.08381259441375732
step: 580, loss: 0.08232381939888
step: 590, loss: 0.10447703301906586
step: 600, loss: 0.01882331073284149
step: 610, loss: 0.021118685603141785
step: 620, loss: 0.0047543589025735855
step: 630, loss: 0.04084576293826103
step: 640, loss: 0.014632395468652248
step: 650, loss: 0.02210751175880432
step: 660, loss: 0.04888386279344559
step: 670, loss: 0.014908014796674252
step: 680, loss: 0.015862833708524704
step: 690, loss: 0.06666445732116699
step: 700, loss: 0.0010343367466703057
step: 710, loss: 5.128766133566387e-05
step: 720, loss: 0.010003137402236462
step: 730, loss: 0.0087240906432271
step: 740, loss: 0.11496374011039734
step: 750, loss: 0.14984352886676788
step: 760, loss: 0.009600168094038963
step: 770, loss: 0.07671301811933517
step: 780, loss: 0.07540618628263474
step: 790, loss: 0.11797686666250229
step: 800, loss: 0.04166710004210472
step: 810, loss: 0.12460541725158691
step: 820, loss: 0.10483739525079727
step: 830, loss: 0.028814256191253662
step: 840, loss: 0.05792517960071564
step: 850, loss: 0.0005041760159656405
step: 860, loss: 0.07225070893764496
step: 870, loss: 0.14517027139663696
step: 880, loss: 0.07483979314565659
step: 890, loss: 0.04286270961165428
step: 900, loss: 0.038320716470479965
step: 910, loss: 0.020338289439678192
step: 920, loss: 0.006770156789571047
step: 930, loss: 0.012012512423098087
step: 940, loss: 0.053146205842494965
step: 950, loss: 0.06394733488559723
step: 960, loss: 0.08301294595003128
step: 970, loss: 0.10013221949338913
step: 980, loss: 0.05058903619647026
step: 990, loss: 0.0011083040153607726
step: 1000, loss: 0.08713545650243759
step: 1010, loss: 0.06159394606947899
step: 1020, loss: 0.059196703135967255
step: 1030, loss: 0.04088665172457695
step: 1040, loss: 0.10359179973602295
step: 1050, loss: 0.09004318714141846
step: 1060, loss: 0.03765297681093216
step: 1070, loss: 0.0180519949644804
epoch 8: dev_f1=0.9333945796968306, f1=0.9305492510213346, best_f1=0.9336384439359268
step: 0, loss: 0.04136863350868225
step: 10, loss: 0.0110232038423419
step: 20, loss: 0.04597235471010208
step: 30, loss: 0.14066492021083832
step: 40, loss: 0.01227294746786356
step: 50, loss: 0.07678479701280594
step: 60, loss: 0.00182196288369596
step: 70, loss: 0.05762795731425285
step: 80, loss: 0.005947360303252935
step: 90, loss: 0.0060994261875748634
step: 100, loss: 0.015776250511407852
step: 110, loss: 0.005543905775994062
step: 120, loss: 0.07187014818191528
step: 130, loss: 0.08678074926137924
step: 140, loss: 0.028223615139722824
step: 150, loss: 0.09607473015785217
step: 160, loss: 0.0448189377784729
step: 170, loss: 0.04904314875602722
step: 180, loss: 0.011533289216458797
step: 190, loss: 0.02330275997519493
step: 200, loss: 0.007277584634721279
step: 210, loss: 0.052252110093832016
step: 220, loss: 0.017017653211951256
step: 230, loss: 0.011111295782029629
step: 240, loss: 0.00011757147149182856
step: 250, loss: 0.008248955942690372
step: 260, loss: 0.12028324604034424
step: 270, loss: 0.07187630981206894
step: 280, loss: 0.0681021586060524
step: 290, loss: 0.07312009483575821
step: 300, loss: 0.04845379665493965
step: 310, loss: 0.002026066416874528
step: 320, loss: 2.843018046405632e-05
step: 330, loss: 0.030224809423089027
step: 340, loss: 0.012985101900994778
step: 350, loss: 0.05459556728601456
step: 360, loss: 0.0778939425945282
step: 370, loss: 0.06671272963285446
step: 380, loss: 0.0738227516412735
step: 390, loss: 0.0009405792807228863
step: 400, loss: 0.033517442643642426
step: 410, loss: 0.03207444027066231
step: 420, loss: 0.03209005668759346
step: 430, loss: 0.04384183511137962
step: 440, loss: 0.04808301106095314
step: 450, loss: 0.018799833953380585
step: 460, loss: 0.04071832448244095
step: 470, loss: 0.006223655305802822
step: 480, loss: 0.046649020165205
step: 490, loss: 0.023771407082676888
step: 500, loss: 0.005267016589641571
step: 510, loss: 0.006496461573988199
step: 520, loss: 0.11457616090774536
step: 530, loss: 0.019351406022906303
step: 540, loss: 0.028577368706464767
step: 550, loss: 0.03190888091921806
step: 560, loss: 0.025651536881923676
step: 570, loss: 0.0013749742647632957
step: 580, loss: 0.1493968814611435
step: 590, loss: 0.0005810790462419391
step: 600, loss: 0.08414674550294876
step: 610, loss: 0.10706287622451782
step: 620, loss: 0.0875144973397255
step: 630, loss: 0.0096690459176898
step: 640, loss: 0.03174450993537903
step: 650, loss: 0.023734157904982567
step: 660, loss: 0.00012086397327948362
step: 670, loss: 0.0433037206530571
step: 680, loss: 0.004628549795597792
step: 690, loss: 0.08608373254537582
step: 700, loss: 0.025886014103889465
step: 710, loss: 0.07941285520792007
step: 720, loss: 0.1744491308927536
step: 730, loss: 0.1411135345697403
step: 740, loss: 0.059561837464571
step: 750, loss: 0.02101564221084118
step: 760, loss: 0.03783323988318443
step: 770, loss: 0.005203347187489271
step: 780, loss: 0.0526389554142952
step: 790, loss: 0.05163682624697685
step: 800, loss: 0.04320799186825752
step: 810, loss: 0.006073357537388802
step: 820, loss: 0.06993428617715836
step: 830, loss: 0.02103964425623417
step: 840, loss: 0.10350168496370316
step: 850, loss: 0.04435169696807861
step: 860, loss: 0.11973161995410919
step: 870, loss: 0.03365671634674072
step: 880, loss: 0.030727604404091835
step: 890, loss: 0.009826838038861752
step: 900, loss: 0.02146931365132332
step: 910, loss: 0.00861106812953949
step: 920, loss: 0.01829218491911888
step: 930, loss: 0.10317203402519226
step: 940, loss: 0.00849947053939104
step: 950, loss: 0.031801268458366394
step: 960, loss: 0.06353111565113068
step: 970, loss: 0.03461981937289238
step: 980, loss: 0.06858476996421814
step: 990, loss: 0.023676253855228424
step: 1000, loss: 0.0734902024269104
step: 1010, loss: 0.026388011872768402
step: 1020, loss: 0.044177714735269547
step: 1030, loss: 0.017911233007907867
step: 1040, loss: 0.04384005069732666
step: 1050, loss: 0.0008079565595835447
step: 1060, loss: 0.05200247839093208
step: 1070, loss: 0.0647360160946846
epoch 9: dev_f1=0.9378852536747273, f1=0.9303857008466604, best_f1=0.9336384439359268
step: 0, loss: 0.007953711785376072
step: 10, loss: 0.04080364853143692
step: 20, loss: 0.002500021131709218
step: 30, loss: 0.031049495562911034
step: 40, loss: 0.07045484334230423
step: 50, loss: 0.0075333914719522
step: 60, loss: 0.019207585602998734
step: 70, loss: 0.02362745627760887
step: 80, loss: 0.008998808450996876
step: 90, loss: 0.03282829374074936
step: 100, loss: 0.006024764385074377
step: 110, loss: 0.002291940851137042
step: 120, loss: 0.03371832147240639
step: 130, loss: 0.05024547129869461
step: 140, loss: 0.03658398613333702
step: 150, loss: 0.04018270969390869
step: 160, loss: 0.10463428497314453
step: 170, loss: 0.01895034685730934
step: 180, loss: 0.031169217079877853
step: 190, loss: 0.04320595785975456
step: 200, loss: 0.052960965782403946
step: 210, loss: 0.14315761625766754
step: 220, loss: 0.009261717088520527
step: 230, loss: 0.03631684184074402
step: 240, loss: 0.08439871668815613
step: 250, loss: 0.02489326521754265
step: 260, loss: 0.022982724010944366
step: 270, loss: 0.03608401119709015
step: 280, loss: 0.04215702787041664
step: 290, loss: 0.015230090357363224
step: 300, loss: 0.12983141839504242
step: 310, loss: 0.0030818977393209934
step: 320, loss: 0.05738019570708275
step: 330, loss: 0.0510588213801384
step: 340, loss: 0.07311292737722397
step: 350, loss: 0.08783896267414093
step: 360, loss: 0.001335579203441739
step: 370, loss: 0.07396029680967331
step: 380, loss: 0.014434301294386387
step: 390, loss: 0.057824913412332535
step: 400, loss: 0.003869301173835993
step: 410, loss: 0.007955068722367287
step: 420, loss: 0.1155020147562027
step: 430, loss: 0.0013368870131671429
step: 440, loss: 0.05277450382709503
step: 450, loss: 0.1383236199617386
step: 460, loss: 0.02470991387963295
step: 470, loss: 0.02732032723724842
step: 480, loss: 0.08803047239780426
step: 490, loss: 0.0008839672664180398
step: 500, loss: 0.02695140615105629
step: 510, loss: 0.0363602377474308
step: 520, loss: 0.05149915814399719
step: 530, loss: 0.0002839593798853457
step: 540, loss: 0.04086759313941002
step: 550, loss: 0.13930705189704895
step: 560, loss: 0.00119632703717798
step: 570, loss: 0.0826609656214714
step: 580, loss: 0.00012807206076104194
step: 590, loss: 0.03166086971759796
step: 600, loss: 0.0006771329790353775
step: 610, loss: 0.07036463916301727
step: 620, loss: 0.08162300288677216
step: 630, loss: 0.052386119961738586
step: 640, loss: 0.007663218304514885
step: 650, loss: 0.007722392212599516
step: 660, loss: 0.054501816630363464
step: 670, loss: 0.0012344159185886383
step: 680, loss: 0.014192618429660797
step: 690, loss: 0.05229002237319946
step: 700, loss: 0.03823293372988701
step: 710, loss: 0.0030947201885282993
step: 720, loss: 0.011162396520376205
step: 730, loss: 0.0512675903737545
step: 740, loss: 0.060285404324531555
step: 750, loss: 0.0530984029173851
step: 760, loss: 0.062268611043691635
step: 770, loss: 0.042438607662916183
step: 780, loss: 0.026216737926006317
step: 790, loss: 0.02419253997504711
step: 800, loss: 0.04353572428226471
step: 810, loss: 0.03292464464902878
step: 820, loss: 0.08578730374574661
step: 830, loss: 0.006148454267531633
step: 840, loss: 0.05269472301006317
step: 850, loss: 0.003274595132097602
step: 860, loss: 0.0010990111622959375
step: 870, loss: 0.031648047268390656
step: 880, loss: 0.008957956917583942
step: 890, loss: 0.01837684027850628
step: 900, loss: 0.0030977041460573673
step: 910, loss: 0.14000333845615387
step: 920, loss: 0.0398138128221035
step: 930, loss: 0.16422520577907562
step: 940, loss: 0.025392139330506325
step: 950, loss: 0.04334048181772232
step: 960, loss: 0.017775967717170715
step: 970, loss: 0.05175502598285675
step: 980, loss: 0.04720069095492363
step: 990, loss: 0.09328455477952957
step: 1000, loss: 0.07672623544931412
step: 1010, loss: 0.03670009598135948
step: 1020, loss: 0.05314071103930473
step: 1030, loss: 0.059851858764886856
step: 1040, loss: 0.02509981393814087
step: 1050, loss: 0.12352712452411652
step: 1060, loss: 0.03703261911869049
step: 1070, loss: 0.002108063083142042
epoch 10: dev_f1=0.9423347398030943, f1=0.9278734295020938, best_f1=0.9336384439359268
step: 0, loss: 0.04224273934960365
step: 10, loss: 0.0825415775179863
step: 20, loss: 0.0034481713082641363
step: 30, loss: 0.0009965981589630246
step: 40, loss: 0.05920424684882164
step: 50, loss: 0.016353774815797806
step: 60, loss: 0.0015071099624037743
step: 70, loss: 0.030633114278316498
step: 80, loss: 0.04207485541701317
step: 90, loss: 0.0304503683000803
step: 100, loss: 0.036090392619371414
step: 110, loss: 0.004729465581476688
step: 120, loss: 0.06326189637184143
step: 130, loss: 0.011062459088861942
step: 140, loss: 0.049917254596948624
step: 150, loss: 0.019873326644301414
step: 160, loss: 0.053560495376586914
step: 170, loss: 0.0020920117385685444
step: 180, loss: 0.020683016628026962
step: 190, loss: 0.0002960283600259572
step: 200, loss: 0.02939518168568611
step: 210, loss: 0.03191550821065903
step: 220, loss: 0.039285216480493546
step: 230, loss: 0.03479423001408577
step: 240, loss: 0.04846225306391716
step: 250, loss: 0.1127699464559555
step: 260, loss: 0.04714353382587433
step: 270, loss: 0.02442046068608761
step: 280, loss: 0.040189117193222046
step: 290, loss: 0.013446509838104248
step: 300, loss: 0.02249469980597496
step: 310, loss: 0.07836107909679413
step: 320, loss: 0.01492157019674778
step: 330, loss: 0.006246630102396011
step: 340, loss: 0.02339516207575798
step: 350, loss: 0.03250967711210251
step: 360, loss: 0.10358566790819168
step: 370, loss: 0.02831604890525341
step: 380, loss: 0.09160615503787994
step: 390, loss: 0.011885561048984528
step: 400, loss: 0.0018561681499704719
step: 410, loss: 0.08637893199920654
step: 420, loss: 0.05208482965826988
step: 430, loss: 0.023307915776968002
step: 440, loss: 0.02226824127137661
step: 450, loss: 0.010883171111345291
step: 460, loss: 0.04546612501144409
step: 470, loss: 0.06589898467063904
step: 480, loss: 0.08827235549688339
step: 490, loss: 0.17031610012054443
step: 500, loss: 0.021363239735364914
step: 510, loss: 0.06207941100001335
step: 520, loss: 0.017376292496919632
step: 530, loss: 0.02096416987478733
step: 540, loss: 0.01699121855199337
step: 550, loss: 0.00021208800899330527
step: 560, loss: 0.13381600379943848
step: 570, loss: 0.017119580879807472
step: 580, loss: 0.0019286297028884292
step: 590, loss: 0.016267502680420876
step: 600, loss: 0.0783916711807251
step: 610, loss: 0.14805956184864044
step: 620, loss: 0.04608690366148949
step: 630, loss: 0.04183194413781166
step: 640, loss: 0.044065844267606735
step: 650, loss: 0.016948744654655457
step: 660, loss: 0.03804926574230194
step: 670, loss: 0.043206121772527695
step: 680, loss: 0.0005299932672642171
step: 690, loss: 0.0052973018027842045
step: 700, loss: 0.0030964650213718414
step: 710, loss: 0.0648593157529831
step: 720, loss: 0.04777193441987038
step: 730, loss: 0.0072679296135902405
step: 740, loss: 0.011795413680374622
step: 750, loss: 0.013870751485228539
step: 760, loss: 0.009013828821480274
step: 770, loss: 0.012767048552632332
step: 780, loss: 0.009251927025616169
step: 790, loss: 0.015560240484774113
step: 800, loss: 0.05821521580219269
step: 810, loss: 0.013153735548257828
step: 820, loss: 0.10237859189510345
step: 830, loss: 0.17711763083934784
step: 840, loss: 0.013193289749324322
step: 850, loss: 0.02395753003656864
step: 860, loss: 0.00012470227375160903
step: 870, loss: 0.03803224116563797
step: 880, loss: 0.08043480664491653
step: 890, loss: 0.12011536955833435
step: 900, loss: 0.010031919926404953
step: 910, loss: 0.03240949660539627
step: 920, loss: 0.013323144987225533
step: 930, loss: 0.05278675630688667
step: 940, loss: 0.07904031127691269
step: 950, loss: 0.07417088001966476
step: 960, loss: 0.028409264981746674
step: 970, loss: 0.1359996199607849
step: 980, loss: 0.02280135080218315
step: 990, loss: 0.040658559650182724
step: 1000, loss: 0.03977984935045242
step: 1010, loss: 0.004457119386643171
step: 1020, loss: 0.08903191983699799
step: 1030, loss: 0.03382177650928497
step: 1040, loss: 0.030483117327094078
step: 1050, loss: 0.054359566420316696
step: 1060, loss: 0.053024157881736755
step: 1070, loss: 0.00022960382921155542
epoch 11: dev_f1=0.9389671361502347, f1=0.9313404950957496, best_f1=0.9336384439359268
step: 0, loss: 0.0004608393646776676
step: 10, loss: 0.00020939439127687365
step: 20, loss: 0.04240850359201431
step: 30, loss: 0.013612048700451851
step: 40, loss: 0.005531026981770992
step: 50, loss: 0.020741932094097137
step: 60, loss: 0.046396199613809586
step: 70, loss: 0.07037976384162903
step: 80, loss: 0.027712389826774597
step: 90, loss: 0.0817921981215477
step: 100, loss: 7.713639934081584e-05
step: 110, loss: 0.00026798126054927707
step: 120, loss: 0.009613310918211937
step: 130, loss: 0.003478746162727475
step: 140, loss: 0.039201799780130386
step: 150, loss: 0.009680009447038174
step: 160, loss: 0.0005799488862976432
step: 170, loss: 0.030436087399721146
step: 180, loss: 0.00010654852667357773
step: 190, loss: 0.0327322743833065
step: 200, loss: 0.04643615335226059
step: 210, loss: 0.03217180073261261
step: 220, loss: 0.039908137172460556
step: 230, loss: 0.03721928969025612
step: 240, loss: 0.04045179486274719
step: 250, loss: 0.012274154461920261
step: 260, loss: 0.06605463474988937
step: 270, loss: 0.05520952492952347
step: 280, loss: 0.04670705646276474
step: 290, loss: 0.0019546435214579105
step: 300, loss: 0.019875772297382355
step: 310, loss: 0.17754867672920227
step: 320, loss: 0.0710381418466568
step: 330, loss: 0.10392449796199799
step: 340, loss: 0.0008549675112590194
step: 350, loss: 0.02105097286403179
step: 360, loss: 0.009119082242250443
step: 370, loss: 0.02990281954407692
step: 380, loss: 0.021580561995506287
step: 390, loss: 0.032071396708488464
step: 400, loss: 0.016057461500167847
step: 410, loss: 0.011363022029399872
step: 420, loss: 0.05221891030669212
step: 430, loss: 0.02742031402885914
step: 440, loss: 0.04270545393228531
step: 450, loss: 0.04937414452433586
step: 460, loss: 0.001004162011668086
step: 470, loss: 0.03381068632006645
step: 480, loss: 0.00024756405036896467
step: 490, loss: 0.021296748891472816
step: 500, loss: 0.04100809618830681
step: 510, loss: 0.024624112993478775
step: 520, loss: 0.08046145737171173
step: 530, loss: 0.10217303037643433
step: 540, loss: 0.12025830149650574
step: 550, loss: 0.0130506232380867
step: 560, loss: 0.08167990297079086
step: 570, loss: 0.044862646609544754
step: 580, loss: 0.012535368092358112
step: 590, loss: 0.043971650302410126
step: 600, loss: 0.02375209704041481
step: 610, loss: 0.03880954906344414
step: 620, loss: 0.041181523352861404
step: 630, loss: 0.07204736769199371
step: 640, loss: 0.07040029764175415
step: 650, loss: 0.0007570646703243256
step: 660, loss: 0.006495082750916481
step: 670, loss: 0.04727933928370476
step: 680, loss: 0.041847940534353256
step: 690, loss: 0.0854053795337677
step: 700, loss: 0.057353612035512924
step: 710, loss: 0.004676748998463154
step: 720, loss: 0.0004031951248180121
step: 730, loss: 0.044010013341903687
step: 740, loss: 0.051319438964128494
step: 750, loss: 9.226692782249302e-05
step: 760, loss: 0.020964087918400764
step: 770, loss: 0.025992555543780327
step: 780, loss: 0.013422222808003426
step: 790, loss: 0.10214190185070038
step: 800, loss: 0.05106339603662491
step: 810, loss: 0.011860743165016174
step: 820, loss: 0.025974171236157417
step: 830, loss: 0.03482405096292496
step: 840, loss: 0.05303897708654404
step: 850, loss: 0.09907801449298859
step: 860, loss: 0.00011135303793707862
step: 870, loss: 0.08042939752340317
step: 880, loss: 0.10235567390918732
step: 890, loss: 0.030678147450089455
step: 900, loss: 0.003698642598465085
step: 910, loss: 0.08522443473339081
step: 920, loss: 0.08488190919160843
step: 930, loss: 0.07234548777341843
step: 940, loss: 0.059618182480335236
step: 950, loss: 0.07045707106590271
step: 960, loss: 0.018776852637529373
step: 970, loss: 0.00016711567877791822
step: 980, loss: 0.04317143186926842
step: 990, loss: 3.3703818189678714e-05
step: 1000, loss: 0.011061975732445717
step: 1010, loss: 0.07733948528766632
step: 1020, loss: 0.026324911043047905
step: 1030, loss: 0.0019333874806761742
step: 1040, loss: 0.02235623076558113
step: 1050, loss: 0.024961000308394432
step: 1060, loss: 0.01611103117465973
step: 1070, loss: 0.04335751011967659
epoch 12: dev_f1=0.9380863039399624, f1=0.9320297951582867, best_f1=0.9336384439359268
step: 0, loss: 0.002299870830029249
step: 10, loss: 5.606924241874367e-05
step: 20, loss: 0.02332955412566662
step: 30, loss: 0.0009179773624055088
step: 40, loss: 0.08030891418457031
step: 50, loss: 0.01848192699253559
step: 60, loss: 0.0246062520891428
step: 70, loss: 0.048611633479595184
step: 80, loss: 0.0002964283339679241
step: 90, loss: 0.01907261088490486
step: 100, loss: 0.06248416751623154
step: 110, loss: 0.011522091925144196
step: 120, loss: 0.014940205961465836
step: 130, loss: 0.04947831854224205
step: 140, loss: 0.015394809655845165
step: 150, loss: 5.51243283553049e-05
step: 160, loss: 0.023671533912420273
step: 170, loss: 0.013059028424322605
step: 180, loss: 0.018499277532100677
step: 190, loss: 0.012148207053542137
step: 200, loss: 0.06336900591850281
step: 210, loss: 0.0008344645611941814
step: 220, loss: 0.04064544290304184
step: 230, loss: 0.02995404601097107
step: 240, loss: 0.0007453259895555675
step: 250, loss: 0.11965542286634445
step: 260, loss: 0.008453956805169582
step: 270, loss: 0.08124777674674988
step: 280, loss: 0.029134677723050117
step: 290, loss: 0.017407452687621117
step: 300, loss: 0.012847025878727436
step: 310, loss: 0.002777470275759697
step: 320, loss: 0.10922493785619736
step: 330, loss: 0.022693069651722908
step: 340, loss: 0.05142153799533844
step: 350, loss: 0.016280606389045715
step: 360, loss: 0.00022559400531463325
step: 370, loss: 0.08118965476751328
step: 380, loss: 0.031252678483724594
step: 390, loss: 0.0008105281740427017
step: 400, loss: 0.007425002288073301
step: 410, loss: 0.0016485166270285845
step: 420, loss: 0.0014606406912207603
step: 430, loss: 0.0050640711560845375
step: 440, loss: 0.048992447555065155
step: 450, loss: 0.009866137988865376
step: 460, loss: 0.021762898191809654
step: 470, loss: 0.048721712082624435
step: 480, loss: 0.04043673351407051
step: 490, loss: 0.041591860353946686
step: 500, loss: 0.04623837396502495
step: 510, loss: 0.03994222357869148
step: 520, loss: 0.09176864475011826
step: 530, loss: 0.05896579846739769
step: 540, loss: 0.04053262993693352
step: 550, loss: 0.021627232432365417
step: 560, loss: 0.10246937721967697
step: 570, loss: 0.06248460337519646
step: 580, loss: 0.058409448713064194
step: 590, loss: 0.03908129036426544
step: 600, loss: 0.0011826372938230634
step: 610, loss: 0.06049126014113426
step: 620, loss: 0.06477291136980057
step: 630, loss: 0.05151938274502754
step: 640, loss: 0.24985896050930023
step: 650, loss: 0.06369765847921371
step: 660, loss: 0.0482642762362957
step: 670, loss: 0.02254217304289341
step: 680, loss: 0.05111246183514595
step: 690, loss: 0.02187802456319332
step: 700, loss: 0.03347984328866005
step: 710, loss: 0.0657801628112793
step: 720, loss: 0.040790509432554245
step: 730, loss: 0.05121505260467529
step: 740, loss: 0.0416005440056324
step: 750, loss: 0.0014528173487633467
step: 760, loss: 0.05664443224668503
step: 770, loss: 0.07268178462982178
step: 780, loss: 0.0002247330266982317
step: 790, loss: 0.0007628241437487304
step: 800, loss: 0.054185427725315094
step: 810, loss: 0.03287772834300995
step: 820, loss: 0.008989841677248478
step: 830, loss: 0.06564059108495712
step: 840, loss: 0.01395174115896225
step: 850, loss: 0.00039494154043495655
step: 860, loss: 0.06120341643691063
step: 870, loss: 0.00017906029825098813
step: 880, loss: 0.018282070755958557
step: 890, loss: 0.04358142986893654
step: 900, loss: 0.002747827675193548
step: 910, loss: 0.0005627538193948567
step: 920, loss: 0.017771106213331223
step: 930, loss: 0.051440998911857605
step: 940, loss: 0.03869255632162094
step: 950, loss: 0.060886941850185394
step: 960, loss: 0.03875192254781723
step: 970, loss: 0.023240448907017708
step: 980, loss: 0.02538878470659256
step: 990, loss: 0.00022731098579242826
step: 1000, loss: 0.041008029133081436
step: 1010, loss: 0.030955154448747635
step: 1020, loss: 0.010595027357339859
step: 1030, loss: 0.047938790172338486
step: 1040, loss: 0.049100860953330994
step: 1050, loss: 0.027452487498521805
step: 1060, loss: 0.0007950622239150107
step: 1070, loss: 0.014387140981853008
epoch 13: dev_f1=0.9384544192503471, f1=0.934065934065934, best_f1=0.9336384439359268
step: 0, loss: 0.00033112935489043593
step: 10, loss: 0.020975587889552116
step: 20, loss: 0.019948186352849007
step: 30, loss: 0.03122836910188198
step: 40, loss: 0.0002133892703568563
step: 50, loss: 0.0367872454226017
step: 60, loss: 0.004827054217457771
step: 70, loss: 0.0001323045144090429
step: 80, loss: 0.007438233587890863
step: 90, loss: 0.0001086896809283644
step: 100, loss: 0.0058461022563278675
step: 110, loss: 0.01809634082019329
step: 120, loss: 0.016987325623631477
step: 130, loss: 0.002654756186529994
step: 140, loss: 1.4394331628864165e-05
step: 150, loss: 0.07764236629009247
step: 160, loss: 0.0005680875619873405
step: 170, loss: 0.05042918771505356
step: 180, loss: 0.02810570038855076
step: 190, loss: 0.029367348179221153
step: 200, loss: 0.09495773166418076
step: 210, loss: 0.03316371142864227
step: 220, loss: 0.04012541100382805
step: 230, loss: 0.02348257042467594
step: 240, loss: 0.025472119450569153
step: 250, loss: 0.025933723896741867
step: 260, loss: 0.018878214061260223
step: 270, loss: 0.09188965708017349
step: 280, loss: 0.012725959531962872
step: 290, loss: 0.00021514085528906435
step: 300, loss: 0.023332759737968445
step: 310, loss: 0.09402339160442352
step: 320, loss: 0.022194772958755493
step: 330, loss: 0.034865859895944595
step: 340, loss: 0.01992998644709587
step: 350, loss: 0.019571715965867043
step: 360, loss: 0.02691875398159027
step: 370, loss: 0.06584251672029495
step: 380, loss: 0.07183993607759476
step: 390, loss: 0.021298063918948174
step: 400, loss: 0.06012408062815666
step: 410, loss: 0.04011048749089241
step: 420, loss: 0.016992956399917603
step: 430, loss: 5.172686360310763e-05
step: 440, loss: 0.02054568938910961
step: 450, loss: 0.03564109653234482
step: 460, loss: 0.00024309437139891088
step: 470, loss: 0.023271718993782997
step: 480, loss: 0.022873876616358757
step: 490, loss: 0.03760385140776634
step: 500, loss: 0.002011618111282587
step: 510, loss: 0.04460061714053154
step: 520, loss: 0.02452779933810234
step: 530, loss: 0.07490082830190659
step: 540, loss: 0.011281718499958515
step: 550, loss: 0.0007220923434942961
step: 560, loss: 0.029625937342643738
step: 570, loss: 0.05035907030105591
step: 580, loss: 0.05056491866707802
step: 590, loss: 0.09112884104251862
step: 600, loss: 0.0471663624048233
step: 610, loss: 0.10714074969291687
step: 620, loss: 0.011518647894263268
step: 630, loss: 0.021547779440879822
step: 640, loss: 0.017445148900151253
step: 650, loss: 0.0015730380546301603
step: 660, loss: 0.03849223628640175
step: 670, loss: 0.037854429334402084
step: 680, loss: 0.025694414973258972
step: 690, loss: 0.014890107326209545
step: 700, loss: 6.236252374947071e-05
step: 710, loss: 0.036815352737903595
step: 720, loss: 0.03181833401322365
step: 730, loss: 0.090174101293087
step: 740, loss: 0.04027320444583893
step: 750, loss: 0.03727070987224579
step: 760, loss: 0.08565479516983032
step: 770, loss: 0.0006681928061880171
step: 780, loss: 0.07998023927211761
step: 790, loss: 0.032773301005363464
step: 800, loss: 0.0033337599597871304
step: 810, loss: 0.04754958301782608
step: 820, loss: 0.0022131905425339937
step: 830, loss: 0.0007609165040776134
step: 840, loss: 0.02965530939400196
step: 850, loss: 0.056650277227163315
step: 860, loss: 0.04708747938275337
step: 870, loss: 0.023791249841451645
step: 880, loss: 0.04866138845682144
step: 890, loss: 0.03180285915732384
step: 900, loss: 0.017166871577501297
step: 910, loss: 0.00012595485895872116
step: 920, loss: 0.04994373023509979
step: 930, loss: 0.012327577918767929
step: 940, loss: 0.07139907032251358
step: 950, loss: 0.02212873287498951
step: 960, loss: 0.04103140905499458
step: 970, loss: 0.022903937846422195
step: 980, loss: 0.025157691910862923
step: 990, loss: 0.01818006858229637
step: 1000, loss: 0.0026326242368668318
step: 1010, loss: 0.04072657972574234
step: 1020, loss: 0.06876839697360992
step: 1030, loss: 0.016316423192620277
step: 1040, loss: 0.00029800497577525675
step: 1050, loss: 0.0014966711169108748
step: 1060, loss: 0.0013247451279312372
step: 1070, loss: 0.01691547967493534
epoch 14: dev_f1=0.9361305361305362, f1=0.9303826648224988, best_f1=0.9336384439359268
step: 0, loss: 0.0446394644677639
step: 10, loss: 0.03867797553539276
step: 20, loss: 0.0446711964905262
step: 30, loss: 0.018337320536375046
step: 40, loss: 0.04163353890180588
step: 50, loss: 7.411461410811171e-05
step: 60, loss: 0.07591243833303452
step: 70, loss: 0.020835110917687416
step: 80, loss: 0.00040503661148250103
step: 90, loss: 3.560648110578768e-05
step: 100, loss: 0.02609960548579693
step: 110, loss: 0.0489160530269146
step: 120, loss: 0.06624087691307068
step: 130, loss: 0.035935528576374054
step: 140, loss: 0.00040864699985831976
step: 150, loss: 0.019862599670886993
step: 160, loss: 0.05917517840862274
step: 170, loss: 0.0034976424649357796
step: 180, loss: 0.016924699768424034
step: 190, loss: 0.019866272807121277
step: 200, loss: 0.007345503196120262
step: 210, loss: 8.597004489274696e-05
step: 220, loss: 0.00015442837320733815
step: 230, loss: 0.06594254076480865
step: 240, loss: 0.047774042934179306
step: 250, loss: 0.0229136161506176
step: 260, loss: 0.00022204926062840968
step: 270, loss: 0.005081507842987776
step: 280, loss: 0.02632509171962738
step: 290, loss: 0.01690138690173626
step: 300, loss: 0.03361687809228897
step: 310, loss: 0.0008110750932246447
step: 320, loss: 0.026529796421527863
step: 330, loss: 0.07752787321805954
step: 340, loss: 0.002358661498874426
step: 350, loss: 0.04685422033071518
step: 360, loss: 0.03159800171852112
step: 370, loss: 0.045773088932037354
step: 380, loss: 0.04025940224528313
step: 390, loss: 0.05924570560455322
step: 400, loss: 0.018727995455265045
step: 410, loss: 0.01689923368394375
step: 420, loss: 0.04980621486902237
step: 430, loss: 0.12726889550685883
step: 440, loss: 0.02846521884202957
step: 450, loss: 0.030753858387470245
step: 460, loss: 0.02176406979560852
step: 470, loss: 0.0020680036395788193
step: 480, loss: 0.011578358709812164
step: 490, loss: 0.024587422609329224
step: 500, loss: 0.0013094795867800713
step: 510, loss: 0.00026757537852972746
step: 520, loss: 0.008372912183403969
step: 530, loss: 0.004880028776824474
step: 540, loss: 2.6493502446101047e-05
step: 550, loss: 0.0007815536810085177
step: 560, loss: 0.024891534820199013
step: 570, loss: 0.0036606979556381702
step: 580, loss: 0.01567857526242733
step: 590, loss: 0.030702505260705948
step: 600, loss: 0.03535108640789986
step: 610, loss: 0.03476526960730553
step: 620, loss: 0.026162443682551384
step: 630, loss: 0.06039116904139519
step: 640, loss: 0.02024366706609726
step: 650, loss: 0.02407928928732872
step: 660, loss: 0.022395668551325798
step: 670, loss: 0.058975789695978165
step: 680, loss: 0.03450900688767433
step: 690, loss: 0.04199590906500816
step: 700, loss: 0.07503627985715866
step: 710, loss: 0.05577791854739189
step: 720, loss: 0.06337746232748032
step: 730, loss: 0.0571766160428524
step: 740, loss: 0.02305246889591217
step: 750, loss: 0.02621421217918396
step: 760, loss: 0.0194412674754858
step: 770, loss: 0.0001929091231431812
step: 780, loss: 0.0614190511405468
step: 790, loss: 0.025152914226055145
step: 800, loss: 0.060090240091085434
step: 810, loss: 0.0031626708805561066
step: 820, loss: 0.014773733913898468
step: 830, loss: 0.02196832373738289
step: 840, loss: 0.00044363614870235324
step: 850, loss: 0.0008618257706984878
step: 860, loss: 0.00019920861814171076
step: 870, loss: 0.01166463177651167
step: 880, loss: 0.016416650265455246
step: 890, loss: 0.05209730565547943
step: 900, loss: 0.06264515966176987
step: 910, loss: 0.09190748631954193
step: 920, loss: 0.12429823726415634
step: 930, loss: 0.01774810254573822
step: 940, loss: 0.05266787111759186
step: 950, loss: 0.0026184055022895336
step: 960, loss: 0.05889767035841942
step: 970, loss: 0.04366404190659523
step: 980, loss: 0.02259606309235096
step: 990, loss: 0.014776896685361862
step: 1000, loss: 0.00596697349101305
step: 1010, loss: 0.014657505787909031
step: 1020, loss: 0.03457126393914223
step: 1030, loss: 0.022595249116420746
step: 1040, loss: 0.05916742607951164
step: 1050, loss: 0.014905574731528759
step: 1060, loss: 0.10778190940618515
step: 1070, loss: 0.047115713357925415
epoch 15: dev_f1=0.9392111368909513, f1=0.9365225390984362, best_f1=0.9336384439359268
step: 0, loss: 0.028963448479771614
step: 10, loss: 0.0252535343170166
step: 20, loss: 0.02887595072388649
step: 30, loss: 0.05135868862271309
step: 40, loss: 0.04520862549543381
step: 50, loss: 0.0004410000692587346
step: 60, loss: 0.0009703452815301716
step: 70, loss: 0.05545978993177414
step: 80, loss: 0.007200575899332762
step: 90, loss: 0.03535789996385574
step: 100, loss: 0.011075535789132118
step: 110, loss: 0.021010173484683037
step: 120, loss: 0.03349816054105759
step: 130, loss: 1.7769179976312444e-05
step: 140, loss: 0.023382076993584633
step: 150, loss: 0.0027074760291725397
step: 160, loss: 0.07926952838897705
step: 170, loss: 0.026954570785164833
step: 180, loss: 0.02567431330680847
step: 190, loss: 0.05364254117012024
step: 200, loss: 0.04541347920894623
step: 210, loss: 0.001076051965355873
step: 220, loss: 0.058916304260492325
step: 230, loss: 0.03300724923610687
step: 240, loss: 0.04346751049160957
step: 250, loss: 0.07333538681268692
step: 260, loss: 0.01800953410565853
step: 270, loss: 0.02179097943007946
step: 280, loss: 0.019586734473705292
step: 290, loss: 0.11130651831626892
step: 300, loss: 0.018671207129955292
step: 310, loss: 0.07480935007333755
step: 320, loss: 0.028646696358919144
step: 330, loss: 0.03385292738676071
step: 340, loss: 0.06630335748195648
step: 350, loss: 0.012189432978630066
step: 360, loss: 0.0005128422635607421
step: 370, loss: 2.053985917882528e-05
step: 380, loss: 0.025503918528556824
step: 390, loss: 0.09262567013502121
step: 400, loss: 0.023526443168520927
step: 410, loss: 0.000150753854541108
step: 420, loss: 0.09430669248104095
step: 430, loss: 0.013124646618962288
step: 440, loss: 0.042125847190618515
step: 450, loss: 0.05383827164769173
step: 460, loss: 0.022488994523882866
step: 470, loss: 0.010141034610569477
step: 480, loss: 0.06159090995788574
step: 490, loss: 0.02841893769800663
step: 500, loss: 0.07586746662855148
step: 510, loss: 0.00015067841741256416
step: 520, loss: 0.02286270260810852
step: 530, loss: 0.00033882452407851815
step: 540, loss: 0.0018905007746070623
step: 550, loss: 0.023757051676511765
step: 560, loss: 0.05672675743699074
step: 570, loss: 0.001226219697855413
step: 580, loss: 0.0884602889418602
step: 590, loss: 0.11466120928525925
step: 600, loss: 0.023406893014907837
step: 610, loss: 0.02085096575319767
step: 620, loss: 0.07549696415662766
step: 630, loss: 0.02822011150419712
step: 640, loss: 0.009918094612658024
step: 650, loss: 0.027813851833343506
step: 660, loss: 0.13972267508506775
step: 670, loss: 0.032193057239055634
step: 680, loss: 0.0015372036723420024
step: 690, loss: 0.00018002744764089584
step: 700, loss: 0.03544329106807709
step: 710, loss: 0.0005142427398823202
step: 720, loss: 0.06252164393663406
step: 730, loss: 0.06849148869514465
step: 740, loss: 0.039756372570991516
step: 750, loss: 0.057747967541217804
step: 760, loss: 2.0391304133227095e-05
step: 770, loss: 0.032303765416145325
step: 780, loss: 0.04125285521149635
step: 790, loss: 0.05062596872448921
step: 800, loss: 0.0750042125582695
step: 810, loss: 0.035874348133802414
step: 820, loss: 0.004024038091301918
step: 830, loss: 0.00021606171503663063
step: 840, loss: 0.03382152318954468
step: 850, loss: 0.021115774288773537
step: 860, loss: 0.05610796809196472
step: 870, loss: 0.000687263032887131
step: 880, loss: 0.0261885616928339
step: 890, loss: 0.07444804161787033
step: 900, loss: 0.00656393077224493
step: 910, loss: 9.885115287033841e-05
step: 920, loss: 0.015012584626674652
step: 930, loss: 0.06147933378815651
step: 940, loss: 0.024000205099582672
step: 950, loss: 0.022485531866550446
step: 960, loss: 0.017692340537905693
step: 970, loss: 0.05133448541164398
step: 980, loss: 0.0549854077398777
step: 990, loss: 0.010191804729402065
step: 1000, loss: 3.380469570402056e-05
step: 1010, loss: 1.134341709985165e-05
step: 1020, loss: 0.02465216815471649
step: 1030, loss: 0.017458459362387657
step: 1040, loss: 0.03657512739300728
step: 1050, loss: 0.00013624917482957244
step: 1060, loss: 0.028051912784576416
step: 1070, loss: 0.024642808362841606
epoch 16: dev_f1=0.9340245051837888, f1=0.927536231884058, best_f1=0.9336384439359268
step: 0, loss: 0.012998418882489204
step: 10, loss: 0.005156250670552254
step: 20, loss: 0.016403960064053535
step: 30, loss: 0.01311550848186016
step: 40, loss: 0.022822894155979156
step: 50, loss: 0.010097142308950424
step: 60, loss: 1.8994785932591185e-05
step: 70, loss: 0.00032645813189446926
step: 80, loss: 0.031747329980134964
step: 90, loss: 0.06059327349066734
step: 100, loss: 8.033205813262612e-05
step: 110, loss: 0.009667092002928257
step: 120, loss: 0.03173012658953667
step: 130, loss: 0.046905238181352615
step: 140, loss: 0.00018757546786218882
step: 150, loss: 0.010624265298247337
step: 160, loss: 0.05089696869254112
step: 170, loss: 0.02375957928597927
step: 180, loss: 0.020482482388615608
step: 190, loss: 0.001842355472035706
step: 200, loss: 0.002499721711501479
step: 210, loss: 1.6305224562529474e-05
step: 220, loss: 0.023944612592458725
step: 230, loss: 9.564062202116475e-05
step: 240, loss: 0.027514243498444557
step: 250, loss: 0.027672262862324715
step: 260, loss: 0.04070448875427246
step: 270, loss: 0.01469196006655693
step: 280, loss: 0.00011564759188331664
step: 290, loss: 0.07157178968191147
step: 300, loss: 0.07217899709939957
step: 310, loss: 0.0003757722151931375
step: 320, loss: 0.03187847509980202
step: 330, loss: 0.03869609162211418
step: 340, loss: 0.07275813072919846
step: 350, loss: 0.020759794861078262
step: 360, loss: 0.04741351306438446
step: 370, loss: 0.013500833883881569
step: 380, loss: 0.03420589864253998
step: 390, loss: 0.08346980065107346
step: 400, loss: 0.00116387486923486
step: 410, loss: 0.05790046602487564
step: 420, loss: 0.04175311699509621
step: 430, loss: 4.8010759201133624e-05
step: 440, loss: 4.146675928495824e-05
step: 450, loss: 0.017951494082808495
step: 460, loss: 0.02461054176092148
step: 470, loss: 0.047694601118564606
step: 480, loss: 0.02382626384496689
step: 490, loss: 0.02043721452355385
step: 500, loss: 0.02181355655193329
step: 510, loss: 0.0782150998711586
step: 520, loss: 0.10564129054546356
step: 530, loss: 0.0004105519619770348
step: 540, loss: 0.00011203432222828269
step: 550, loss: 3.433262827456929e-05
step: 560, loss: 0.04682411998510361
step: 570, loss: 0.01701474003493786
step: 580, loss: 0.011187572032213211
step: 590, loss: 0.06437676399946213
step: 600, loss: 0.023927893489599228
step: 610, loss: 1.9192195395589806e-05
step: 620, loss: 1.529198925709352e-05
step: 630, loss: 0.0003468669601716101
step: 640, loss: 0.005554766859859228
step: 650, loss: 5.512706047738902e-05
step: 660, loss: 0.027721568942070007
step: 670, loss: 0.00017732408014126122
step: 680, loss: 0.09719722718000412
step: 690, loss: 0.003938989248126745
step: 700, loss: 0.023354267701506615
step: 710, loss: 0.02712639793753624
step: 720, loss: 1.3634406968776602e-05
step: 730, loss: 0.02055944874882698
step: 740, loss: 0.04542212560772896
step: 750, loss: 0.020683733746409416
step: 760, loss: 0.035406842827796936
step: 770, loss: 0.02494107000529766
step: 780, loss: 0.00010467902757227421
step: 790, loss: 0.02342165634036064
step: 800, loss: 0.02903030440211296
step: 810, loss: 0.10911477357149124
step: 820, loss: 0.02594919130206108
step: 830, loss: 0.037652041763067245
step: 840, loss: 0.030356690287590027
step: 850, loss: 0.0001658308901824057
step: 860, loss: 0.02566312812268734
step: 870, loss: 0.014612022787332535
step: 880, loss: 1.9985312974313274e-05
step: 890, loss: 0.02984447591006756
step: 900, loss: 0.054643455892801285
step: 910, loss: 0.007507367059588432
step: 920, loss: 0.004466151352971792
step: 930, loss: 0.022993875667452812
step: 940, loss: 0.06569408625364304
step: 950, loss: 0.04610737785696983
step: 960, loss: 0.08601502329111099
step: 970, loss: 0.026987703517079353
step: 980, loss: 0.07399111241102219
step: 990, loss: 0.01678331382572651
step: 1000, loss: 0.021137302741408348
step: 1010, loss: 0.07792423665523529
step: 1020, loss: 0.01489904336631298
step: 1030, loss: 0.019453633576631546
step: 1040, loss: 0.1324506402015686
step: 1050, loss: 0.07337475568056107
step: 1060, loss: 0.046603552997112274
step: 1070, loss: 0.05439117178320885
epoch 17: dev_f1=0.940959409594096, f1=0.9325378614043139, best_f1=0.9336384439359268
step: 0, loss: 0.04361918196082115
step: 10, loss: 0.052179109305143356
step: 20, loss: 0.02232612669467926
step: 30, loss: 0.00021818287495989352
step: 40, loss: 0.00043667558929882944
step: 50, loss: 0.06558208167552948
step: 60, loss: 0.022289372980594635
step: 70, loss: 0.04762691631913185
step: 80, loss: 0.007391145918518305
step: 90, loss: 0.00017630420916248113
step: 100, loss: 0.03811971843242645
step: 110, loss: 6.933930853847414e-05
step: 120, loss: 0.055803317576646805
step: 130, loss: 0.08080273121595383
step: 140, loss: 0.061456359922885895
step: 150, loss: 0.03417055681347847
step: 160, loss: 0.007232070900499821
step: 170, loss: 4.024232111987658e-05
step: 180, loss: 0.08112380653619766
step: 190, loss: 0.021451620385050774
step: 200, loss: 0.01695678010582924
step: 210, loss: 0.0003399599518161267
step: 220, loss: 0.04192427918314934
step: 230, loss: 0.0008351625292561948
step: 240, loss: 0.00022277179232332855
step: 250, loss: 0.0225632693618536
step: 260, loss: 0.051887936890125275
step: 270, loss: 0.0008157854899764061
step: 280, loss: 2.3832606530049816e-05
step: 290, loss: 0.0823633223772049
step: 300, loss: 0.01438988745212555
step: 310, loss: 0.01869005151093006
step: 320, loss: 9.12608447833918e-05
step: 330, loss: 0.0378434918820858
step: 340, loss: 0.00012018540292046964
step: 350, loss: 1.3150099221093114e-05
step: 360, loss: 0.000741513620596379
step: 370, loss: 0.08840048313140869
step: 380, loss: 0.051921941339969635
step: 390, loss: 0.0650610700249672
step: 400, loss: 1.3760946785623673e-05
step: 410, loss: 0.021318752318620682
step: 420, loss: 1.3641706573253032e-05
step: 430, loss: 0.04647167772054672
step: 440, loss: 0.060331523418426514
step: 450, loss: 0.02117992751300335
step: 460, loss: 0.011255936697125435
step: 470, loss: 0.028842676430940628
step: 480, loss: 0.056560903787612915
step: 490, loss: 1.4800190001551528e-05
step: 500, loss: 0.07600529491901398
step: 510, loss: 1.9254732251283713e-05
step: 520, loss: 4.2142542952205986e-05
step: 530, loss: 0.040293145924806595
step: 540, loss: 0.013232235796749592
step: 550, loss: 0.038223594427108765
step: 560, loss: 0.061595894396305084
step: 570, loss: 0.030839286744594574
step: 580, loss: 0.07930447906255722
step: 590, loss: 0.21728642284870148
step: 600, loss: 0.027497172355651855
step: 610, loss: 0.031227029860019684
step: 620, loss: 0.04832606762647629
step: 630, loss: 0.003248381894081831
step: 640, loss: 0.024136796593666077
step: 650, loss: 0.12151991575956345
step: 660, loss: 0.05882910639047623
step: 670, loss: 0.0020488945301622152
step: 680, loss: 0.0001377909939037636
step: 690, loss: 0.02552645467221737
step: 700, loss: 3.293300687801093e-05
step: 710, loss: 0.008129095658659935
step: 720, loss: 0.0001894146262202412
step: 730, loss: 0.05400584638118744
step: 740, loss: 0.02356155961751938
step: 750, loss: 0.03587856516242027
step: 760, loss: 0.017025325447320938
step: 770, loss: 0.026425253599882126
step: 780, loss: 0.0021578026935458183
step: 790, loss: 1.9534816601662897e-05
step: 800, loss: 7.087400445016101e-05
step: 810, loss: 0.019785260781645775
step: 820, loss: 0.001246464205905795
step: 830, loss: 0.020601514726877213
step: 840, loss: 0.05823342874646187
step: 850, loss: 3.9920505514601246e-05
step: 860, loss: 0.077056385576725
step: 870, loss: 0.02647242695093155
step: 880, loss: 0.03445345163345337
step: 890, loss: 0.01640622690320015
step: 900, loss: 0.023499291390180588
step: 910, loss: 0.01708434335887432
step: 920, loss: 0.06278158724308014
step: 930, loss: 0.003817138960584998
step: 940, loss: 0.026518598198890686
step: 950, loss: 4.199022441753186e-05
step: 960, loss: 0.023477567359805107
step: 970, loss: 0.043904583901166916
step: 980, loss: 0.024374213069677353
step: 990, loss: 4.167088263784535e-05
step: 1000, loss: 0.022433480247855186
step: 1010, loss: 0.021485034376382828
step: 1020, loss: 0.003515944117680192
step: 1030, loss: 0.016212359070777893
step: 1040, loss: 0.02290724217891693
step: 1050, loss: 0.03235899284482002
step: 1060, loss: 0.04373425990343094
step: 1070, loss: 0.015226628631353378
epoch 18: dev_f1=0.9360112097150864, f1=0.9311778290993071, best_f1=0.9336384439359268
step: 0, loss: 0.058432869613170624
step: 10, loss: 0.028720753267407417
step: 20, loss: 0.030192198231816292
step: 30, loss: 7.029639527900144e-05
step: 40, loss: 0.03913373500108719
step: 50, loss: 0.02867784909904003
step: 60, loss: 0.05827781930565834
step: 70, loss: 0.056716568768024445
step: 80, loss: 3.723233749042265e-05
step: 90, loss: 0.014236681163311005
step: 100, loss: 0.030875643715262413
step: 110, loss: 1.3418291018751916e-05
step: 120, loss: 2.7913483791053295e-05
step: 130, loss: 0.013494282029569149
step: 140, loss: 1.6048266843426973e-05
step: 150, loss: 0.07378538697957993
step: 160, loss: 0.04052165523171425
step: 170, loss: 3.0804902053205296e-05
step: 180, loss: 0.00018711562734097242
step: 190, loss: 0.060020335018634796
step: 200, loss: 0.024224702268838882
step: 210, loss: 0.0835660770535469
step: 220, loss: 0.003967897966504097
step: 230, loss: 0.02053268998861313
step: 240, loss: 0.05094606429338455
step: 250, loss: 0.021572967991232872
step: 260, loss: 0.026456421241164207
step: 270, loss: 0.061046503484249115
step: 280, loss: 3.589890184230171e-05
step: 290, loss: 0.020453592762351036
step: 300, loss: 0.022255318239331245
step: 310, loss: 0.026131795719265938
step: 320, loss: 0.00011137033288832754
step: 330, loss: 0.04241139814257622
step: 340, loss: 0.002228307304903865
step: 350, loss: 0.017891736701130867
step: 360, loss: 0.016195029020309448
step: 370, loss: 0.0001838088792283088
step: 380, loss: 0.025215275585651398
step: 390, loss: 0.0008852341561578214
step: 400, loss: 0.00011282460764050484
step: 410, loss: 0.034239042550325394
step: 420, loss: 0.012002689763903618
step: 430, loss: 5.32448357262183e-05
step: 440, loss: 0.03589007630944252
step: 450, loss: 9.897568816086277e-05
step: 460, loss: 4.872305362368934e-05
step: 470, loss: 0.09379750490188599
step: 480, loss: 0.021754251793026924
step: 490, loss: 0.013735290616750717
step: 500, loss: 0.018459169194102287
step: 510, loss: 2.6845693355426192e-05
step: 520, loss: 1.4908241610100958e-05
step: 530, loss: 0.054521992802619934
step: 540, loss: 2.4575296265538782e-05
step: 550, loss: 0.04631339758634567
step: 560, loss: 0.007631131447851658
step: 570, loss: 0.09243370592594147
step: 580, loss: 0.000112135850940831
step: 590, loss: 0.061570942401885986
step: 600, loss: 0.06556224077939987
step: 610, loss: 0.023286301642656326
step: 620, loss: 0.024313166737556458
step: 630, loss: 0.01861526444554329
step: 640, loss: 0.00014730016118846834
step: 650, loss: 0.03987262770533562
step: 660, loss: 0.03420782834291458
step: 670, loss: 0.052679888904094696
step: 680, loss: 0.03933798149228096
step: 690, loss: 0.027328673750162125
step: 700, loss: 0.020208965986967087
step: 710, loss: 2.7427093300502747e-05
step: 720, loss: 0.02577119693160057
step: 730, loss: 0.040130265057086945
step: 740, loss: 0.02007105201482773
step: 750, loss: 0.05056805536150932
step: 760, loss: 2.8500453481683508e-05
step: 770, loss: 0.03994012624025345
step: 780, loss: 0.06686834990978241
step: 790, loss: 0.1456146091222763
step: 800, loss: 0.022938398644328117
step: 810, loss: 0.003206914057955146
step: 820, loss: 0.015981802716851234
step: 830, loss: 0.08324873447418213
step: 840, loss: 0.001759566250257194
step: 850, loss: 0.04199991747736931
step: 860, loss: 0.024872008711099625
step: 870, loss: 0.014899613335728645
step: 880, loss: 5.8690162404673174e-05
step: 890, loss: 0.022673703730106354
step: 900, loss: 0.04499673470854759
step: 910, loss: 8.388130663661286e-05
step: 920, loss: 0.04038098081946373
step: 930, loss: 0.03409632667899132
step: 940, loss: 0.0045969560742378235
step: 950, loss: 4.766316124005243e-05
step: 960, loss: 0.0025506603997200727
step: 970, loss: 0.06789463013410568
step: 980, loss: 0.047678928822278976
step: 990, loss: 0.052155882120132446
step: 1000, loss: 0.01913468912243843
step: 1010, loss: 0.06626316159963608
step: 1020, loss: 0.00034683916601352394
step: 1030, loss: 0.04806496202945709
step: 1040, loss: 0.02563144825398922
step: 1050, loss: 0.016177115961909294
step: 1060, loss: 0.02272701822221279
step: 1070, loss: 0.051772039383649826
epoch 19: dev_f1=0.9363295880149813, f1=0.9329608938547487, best_f1=0.9336384439359268
step: 0, loss: 0.0001833791029639542
step: 10, loss: 0.00016594628687016666
step: 20, loss: 0.0001033721273415722
step: 30, loss: 9.289381705457345e-05
step: 40, loss: 0.048318780958652496
step: 50, loss: 4.8605372285237536e-05
step: 60, loss: 0.01675691083073616
step: 70, loss: 0.02575230412185192
step: 80, loss: 0.026896057650446892
step: 90, loss: 0.020179668441414833
step: 100, loss: 0.03546372428536415
step: 110, loss: 0.08609423041343689
step: 120, loss: 0.017915481701493263
step: 130, loss: 1.9456529116723686e-05
step: 140, loss: 0.059580687433481216
step: 150, loss: 0.04694003611803055
step: 160, loss: 0.061785466969013214
step: 170, loss: 6.133817078080028e-05
step: 180, loss: 0.015775198116898537
step: 190, loss: 0.04079702869057655
step: 200, loss: 0.00037490020622499287
step: 210, loss: 0.019635649397969246
step: 220, loss: 0.088948555290699
step: 230, loss: 0.08812657743692398
step: 240, loss: 0.022411562502384186
step: 250, loss: 2.7714657335309312e-05
step: 260, loss: 0.050226110965013504
step: 270, loss: 0.03326962888240814
step: 280, loss: 0.04042178392410278
step: 290, loss: 0.01692548207938671
step: 300, loss: 0.13424749672412872
step: 310, loss: 0.03558235988020897
step: 320, loss: 0.0548066608607769
step: 330, loss: 0.015289894305169582
step: 340, loss: 2.580765612947289e-05
step: 350, loss: 0.04865795001387596
step: 360, loss: 4.1901934309862554e-05
step: 370, loss: 0.020751478150486946
step: 380, loss: 0.0004464966768864542
step: 390, loss: 0.046716734766960144
step: 400, loss: 0.023249613121151924
step: 410, loss: 4.1034258174477145e-05
step: 420, loss: 0.04340314120054245
step: 430, loss: 0.05886836349964142
step: 440, loss: 0.003310091095045209
step: 450, loss: 0.036070216447114944
step: 460, loss: 0.018412142992019653
step: 470, loss: 9.089172817766666e-05
step: 480, loss: 0.024589091539382935
step: 490, loss: 0.028430981561541557
step: 500, loss: 0.040480196475982666
step: 510, loss: 0.02358999289572239
step: 520, loss: 1.0609539458528161e-05
step: 530, loss: 0.00013263270375318825
step: 540, loss: 0.04278014227747917
step: 550, loss: 3.155098602292128e-05
step: 560, loss: 0.06178056076169014
step: 570, loss: 0.04789593815803528
step: 580, loss: 0.09510236233472824
step: 590, loss: 0.07038915157318115
step: 600, loss: 0.004106676671653986
step: 610, loss: 0.03910597413778305
step: 620, loss: 0.0002226085780421272
step: 630, loss: 0.0019587574061006308
step: 640, loss: 0.00020612952357623726
step: 650, loss: 2.7077046979684383e-05
step: 660, loss: 0.024226199835538864
step: 670, loss: 0.04407041147351265
step: 680, loss: 0.00036497993278317153
step: 690, loss: 0.03714601323008537
step: 700, loss: 0.01818574033677578
step: 710, loss: 0.00014300268958322704
step: 720, loss: 0.0811547115445137
step: 730, loss: 0.01875762827694416
step: 740, loss: 0.023058010265231133
step: 750, loss: 0.014363938011229038
step: 760, loss: 0.049483995884656906
step: 770, loss: 0.016696101054549217
step: 780, loss: 0.03281134366989136
step: 790, loss: 0.04168454557657242
step: 800, loss: 2.1660896891262382e-05
step: 810, loss: 0.029183514416217804
step: 820, loss: 9.458706335863099e-05
step: 830, loss: 0.03633022680878639
step: 840, loss: 0.024487487971782684
step: 850, loss: 0.020863136276602745
step: 860, loss: 0.04810912162065506
step: 870, loss: 0.018491661176085472
step: 880, loss: 0.08221270889043808
step: 890, loss: 0.0474947951734066
step: 900, loss: 0.03902371600270271
step: 910, loss: 1.635358239582274e-05
step: 920, loss: 0.017965177074074745
step: 930, loss: 1.927744051499758e-05
step: 940, loss: 0.05186501517891884
step: 950, loss: 0.0007107582641765475
step: 960, loss: 0.03218059614300728
step: 970, loss: 2.4975881387945265e-05
step: 980, loss: 0.006834805011749268
step: 990, loss: 0.06394053250551224
step: 1000, loss: 0.0722019374370575
step: 1010, loss: 0.023343442007899284
step: 1020, loss: 0.0010992931202054024
step: 1030, loss: 0.003432135796174407
step: 1040, loss: 0.00027347050490789115
step: 1050, loss: 0.020958684384822845
step: 1060, loss: 0.001783086103387177
step: 1070, loss: 0.05024131014943123
epoch 20: dev_f1=0.9390243902439025, f1=0.9328358208955224, best_f1=0.9336384439359268
