cuda
Device: cuda
step: 0, loss: 0.5519745349884033
step: 10, loss: 0.49218934774398804
step: 20, loss: 0.388243168592453
step: 30, loss: 0.32414570450782776
step: 40, loss: 0.3704736530780792
step: 50, loss: 0.2151799201965332
step: 60, loss: 0.33444684743881226
step: 70, loss: 0.2555813789367676
step: 80, loss: 0.18913139402866364
step: 90, loss: 0.15869486331939697
step: 100, loss: 0.1276649385690689
step: 110, loss: 0.29534581303596497
step: 120, loss: 0.15888835489749908
step: 130, loss: 0.21291206777095795
step: 140, loss: 0.18905384838581085
step: 150, loss: 0.17459836602210999
step: 160, loss: 0.10479419678449631
step: 170, loss: 0.24982209503650665
step: 180, loss: 0.10459893941879272
step: 190, loss: 0.11947780847549438
step: 200, loss: 0.24218504130840302
step: 210, loss: 0.12977519631385803
step: 220, loss: 0.0967559814453125
step: 230, loss: 0.1634252369403839
step: 240, loss: 0.25045228004455566
step: 250, loss: 0.29779860377311707
step: 260, loss: 0.1970481276512146
step: 270, loss: 0.11858168989419937
step: 280, loss: 0.134046733379364
step: 290, loss: 0.16955703496932983
step: 300, loss: 0.10611201822757721
step: 310, loss: 0.11389311403036118
step: 320, loss: 0.18745091557502747
step: 330, loss: 0.157682865858078
step: 340, loss: 0.09990953654050827
step: 350, loss: 0.13301461935043335
step: 360, loss: 0.26475122570991516
step: 370, loss: 0.12698839604854584
step: 380, loss: 0.152108296751976
step: 390, loss: 0.09854567795991898
step: 400, loss: 0.09143833070993423
step: 410, loss: 0.11453675478696823
step: 420, loss: 0.12829294800758362
step: 430, loss: 0.1099102571606636
step: 440, loss: 0.23870980739593506
step: 450, loss: 0.2650007903575897
step: 460, loss: 0.10886222869157791
step: 470, loss: 0.1121511459350586
step: 480, loss: 0.07016440480947495
step: 490, loss: 0.33372998237609863
step: 500, loss: 0.235248863697052
step: 510, loss: 0.09801346063613892
step: 520, loss: 0.15025284886360168
step: 530, loss: 0.15015922486782074
step: 540, loss: 0.17253966629505157
step: 550, loss: 0.0777243971824646
step: 560, loss: 0.06568099558353424
step: 570, loss: 0.06545654684305191
step: 580, loss: 0.14575915038585663
step: 590, loss: 0.20461110770702362
step: 600, loss: 0.10898660123348236
step: 610, loss: 0.15504330396652222
step: 620, loss: 0.10596974939107895
step: 630, loss: 0.029545573517680168
step: 640, loss: 0.08082781732082367
step: 650, loss: 0.17273040115833282
step: 660, loss: 0.2160854935646057
step: 670, loss: 0.13975465297698975
step: 680, loss: 0.15515615046024323
step: 690, loss: 0.09797919541597366
step: 700, loss: 0.10335969179868698
step: 710, loss: 0.11210045218467712
step: 720, loss: 0.16192278265953064
step: 730, loss: 0.2831694185733795
step: 740, loss: 0.09866108745336533
step: 750, loss: 0.13939400017261505
step: 760, loss: 0.1866167187690735
step: 770, loss: 0.1336590051651001
step: 780, loss: 0.04684968665242195
step: 790, loss: 0.11755717545747757
step: 800, loss: 0.15337513387203217
step: 810, loss: 0.27084800601005554
step: 820, loss: 0.09061414748430252
step: 830, loss: 0.15333274006843567
step: 840, loss: 0.11314839124679565
step: 850, loss: 0.08831849694252014
step: 860, loss: 0.25395554304122925
step: 870, loss: 0.2650401294231415
step: 880, loss: 0.24987630546092987
step: 890, loss: 0.1373124122619629
step: 900, loss: 0.1564638763666153
step: 910, loss: 0.14612959325313568
step: 920, loss: 0.1358543038368225
step: 930, loss: 0.15982268750667572
step: 940, loss: 0.07778855413198471
step: 950, loss: 0.0691801905632019
step: 960, loss: 0.05045541375875473
step: 970, loss: 0.06371376663446426
step: 980, loss: 0.048709701746702194
step: 990, loss: 0.12005779147148132
step: 1000, loss: 0.04423421621322632
step: 1010, loss: 0.11229883134365082
step: 1020, loss: 0.09384908527135849
step: 1030, loss: 0.1751689910888672
step: 1040, loss: 0.052749887108802795
step: 1050, loss: 0.08782593905925751
step: 1060, loss: 0.17503881454467773
step: 1070, loss: 0.04778114706277847
epoch 1: dev_f1=0.9238673517048108, f1=0.9303826648224988, best_f1=0.9303826648224988
step: 0, loss: 0.0412394255399704
step: 10, loss: 0.07263514399528503
step: 20, loss: 0.3449324071407318
step: 30, loss: 0.11111759394407272
step: 40, loss: 0.07479150593280792
step: 50, loss: 0.040428776293992996
step: 60, loss: 0.03413517028093338
step: 70, loss: 0.0667484924197197
step: 80, loss: 0.1113567128777504
step: 90, loss: 0.058069296181201935
step: 100, loss: 0.0202778447419405
step: 110, loss: 0.06088917329907417
step: 120, loss: 0.08947443962097168
step: 130, loss: 0.0389072448015213
step: 140, loss: 0.06497322767972946
step: 150, loss: 0.164683997631073
step: 160, loss: 0.10516532510519028
step: 170, loss: 0.07055079936981201
step: 180, loss: 0.09032851457595825
step: 190, loss: 0.01912813074886799
step: 200, loss: 0.06914982199668884
step: 210, loss: 0.06076214089989662
step: 220, loss: 0.10179790109395981
step: 230, loss: 0.24604102969169617
step: 240, loss: 0.13345223665237427
step: 250, loss: 0.11558054387569427
step: 260, loss: 0.015682129189372063
step: 270, loss: 0.07358495146036148
step: 280, loss: 0.11434384435415268
step: 290, loss: 0.10920871049165726
step: 300, loss: 0.05606081336736679
step: 310, loss: 0.19173358380794525
step: 320, loss: 0.09178643673658371
step: 330, loss: 0.00495646009221673
step: 340, loss: 0.06966117769479752
step: 350, loss: 0.02776227705180645
step: 360, loss: 0.05666624382138252
step: 370, loss: 0.09122797101736069
step: 380, loss: 0.11549120396375656
step: 390, loss: 0.019503388553857803
step: 400, loss: 0.09568465501070023
step: 410, loss: 0.08012944459915161
step: 420, loss: 0.04782303422689438
step: 430, loss: 0.03528572991490364
step: 440, loss: 0.10546804964542389
step: 450, loss: 0.20067258179187775
step: 460, loss: 0.06382523477077484
step: 470, loss: 0.07593797892332077
step: 480, loss: 0.21802031993865967
step: 490, loss: 0.1073363721370697
step: 500, loss: 0.08924026042222977
step: 510, loss: 0.07982926815748215
step: 520, loss: 0.09094558656215668
step: 530, loss: 0.2035265415906906
step: 540, loss: 0.13505719602108002
step: 550, loss: 0.2031908631324768
step: 560, loss: 0.049585264176130295
step: 570, loss: 0.07611271739006042
step: 580, loss: 0.04513731971383095
step: 590, loss: 0.030006201937794685
step: 600, loss: 0.05009368062019348
step: 610, loss: 0.057993486523628235
step: 620, loss: 0.100981704890728
step: 630, loss: 0.03448901325464249
step: 640, loss: 0.09373782575130463
step: 650, loss: 0.10057762265205383
step: 660, loss: 0.12848985195159912
step: 670, loss: 0.0224523413926363
step: 680, loss: 0.02611079439520836
step: 690, loss: 0.039858199656009674
step: 700, loss: 0.06332125514745712
step: 710, loss: 0.09353785961866379
step: 720, loss: 0.18331459164619446
step: 730, loss: 0.030236605554819107
step: 740, loss: 0.0491340309381485
step: 750, loss: 0.07609985023736954
step: 760, loss: 0.014878480695188046
step: 770, loss: 0.09343641996383667
step: 780, loss: 0.1785297393798828
step: 790, loss: 0.09990671277046204
step: 800, loss: 0.08405841141939163
step: 810, loss: 0.026853851974010468
step: 820, loss: 0.06116403266787529
step: 830, loss: 0.07895052433013916
step: 840, loss: 0.0835806280374527
step: 850, loss: 0.08160817623138428
step: 860, loss: 0.12839801609516144
step: 870, loss: 0.10950125753879547
step: 880, loss: 0.09275377541780472
step: 890, loss: 0.15813879668712616
step: 900, loss: 0.16472119092941284
step: 910, loss: 0.036096759140491486
step: 920, loss: 0.10284420102834702
step: 930, loss: 0.2079094648361206
step: 940, loss: 0.0016758207930251956
step: 950, loss: 0.043985120952129364
step: 960, loss: 0.1647682934999466
step: 970, loss: 0.12525078654289246
step: 980, loss: 0.022956231608986855
step: 990, loss: 0.23232319951057434
step: 1000, loss: 0.15296950936317444
step: 1010, loss: 0.13064569234848022
step: 1020, loss: 0.08834971487522125
step: 1030, loss: 0.07618910074234009
step: 1040, loss: 0.0885930135846138
step: 1050, loss: 0.0553508959710598
step: 1060, loss: 0.22283758223056793
step: 1070, loss: 0.016358427703380585
epoch 2: dev_f1=0.9289772727272728, f1=0.9185882352941176, best_f1=0.9185882352941176
step: 0, loss: 0.07128053158521652
step: 10, loss: 0.07286372780799866
step: 20, loss: 0.27236127853393555
step: 30, loss: 0.026965513825416565
step: 40, loss: 0.06648637354373932
step: 50, loss: 0.12654370069503784
step: 60, loss: 0.021191749721765518
step: 70, loss: 0.02175121381878853
step: 80, loss: 0.08345181494951248
step: 90, loss: 0.018479840829968452
step: 100, loss: 0.13149555027484894
step: 110, loss: 0.16594570875167847
step: 120, loss: 0.052202727645635605
step: 130, loss: 0.1351032853126526
step: 140, loss: 0.04889657720923424
step: 150, loss: 0.1037810891866684
step: 160, loss: 0.01808878779411316
step: 170, loss: 0.03194791451096535
step: 180, loss: 0.0772443488240242
step: 190, loss: 0.16601717472076416
step: 200, loss: 0.025578511878848076
step: 210, loss: 0.13013425469398499
step: 220, loss: 0.021120548248291016
step: 230, loss: 0.07638506591320038
step: 240, loss: 0.08950565755367279
step: 250, loss: 0.13876596093177795
step: 260, loss: 0.024321483448147774
step: 270, loss: 0.04401423782110214
step: 280, loss: 0.060287948697805405
step: 290, loss: 0.05860377848148346
step: 300, loss: 0.13691240549087524
step: 310, loss: 0.03525562584400177
step: 320, loss: 0.0159677192568779
step: 330, loss: 0.08504383265972137
step: 340, loss: 0.13135609030723572
step: 350, loss: 0.10696448385715485
step: 360, loss: 0.015064965933561325
step: 370, loss: 0.09181103110313416
step: 380, loss: 0.02944164350628853
step: 390, loss: 0.13572941720485687
step: 400, loss: 0.04345676675438881
step: 410, loss: 0.08755462616682053
step: 420, loss: 0.0665145143866539
step: 430, loss: 0.15284858644008636
step: 440, loss: 0.07566872239112854
step: 450, loss: 0.07297499477863312
step: 460, loss: 0.0835435763001442
step: 470, loss: 0.06519812345504761
step: 480, loss: 0.11483535915613174
step: 490, loss: 0.09928812086582184
step: 500, loss: 0.07494841516017914
step: 510, loss: 0.16912761330604553
step: 520, loss: 0.12336856126785278
step: 530, loss: 0.06236555799841881
step: 540, loss: 0.058367833495140076
step: 550, loss: 0.02657531574368477
step: 560, loss: 0.09301680326461792
step: 570, loss: 0.008302314206957817
step: 580, loss: 0.04184101149439812
step: 590, loss: 0.06406950950622559
step: 600, loss: 0.03477151319384575
step: 610, loss: 0.08700288087129593
step: 620, loss: 0.04346945881843567
step: 630, loss: 0.09473812580108643
step: 640, loss: 0.18740427494049072
step: 650, loss: 0.10081477463245392
step: 660, loss: 0.06862270832061768
step: 670, loss: 0.09603142738342285
step: 680, loss: 0.015333399176597595
step: 690, loss: 0.1677163541316986
step: 700, loss: 0.058115869760513306
step: 710, loss: 0.03422597050666809
step: 720, loss: 0.07863478362560272
step: 730, loss: 0.0029167975299060345
step: 740, loss: 0.020994802936911583
step: 750, loss: 0.0609721913933754
step: 760, loss: 0.15282042324543
step: 770, loss: 0.0436164028942585
step: 780, loss: 0.1691504567861557
step: 790, loss: 0.025951707735657692
step: 800, loss: 0.09629058837890625
step: 810, loss: 0.06738806515932083
step: 820, loss: 0.029692836105823517
step: 830, loss: 0.11764127761125565
step: 840, loss: 0.09152434021234512
step: 850, loss: 0.02549624629318714
step: 860, loss: 0.1977773904800415
step: 870, loss: 0.007193267345428467
step: 880, loss: 0.00417347252368927
step: 890, loss: 0.11243429034948349
step: 900, loss: 0.06868162006139755
step: 910, loss: 0.029349200427532196
step: 920, loss: 0.023640086874365807
step: 930, loss: 0.04413694515824318
step: 940, loss: 0.011589789763092995
step: 950, loss: 0.013771357014775276
step: 960, loss: 0.03429008275270462
step: 970, loss: 0.025083571672439575
step: 980, loss: 0.08109956979751587
step: 990, loss: 0.02379731833934784
step: 1000, loss: 0.18901944160461426
step: 1010, loss: 0.12891101837158203
step: 1020, loss: 0.05805843695998192
step: 1030, loss: 0.012148276902735233
step: 1040, loss: 0.06561843305826187
step: 1050, loss: 0.049419570714235306
step: 1060, loss: 0.09761922061443329
step: 1070, loss: 0.06687238812446594
epoch 3: dev_f1=0.9350529709811147, f1=0.9324137931034482, best_f1=0.9324137931034482
step: 0, loss: 0.05962700769305229
step: 10, loss: 0.04967094585299492
step: 20, loss: 0.05821036547422409
step: 30, loss: 0.0789070650935173
step: 40, loss: 0.12768106162548065
step: 50, loss: 0.06196895241737366
step: 60, loss: 0.038154855370521545
step: 70, loss: 0.06090370938181877
step: 80, loss: 0.0676000565290451
step: 90, loss: 0.06554695218801498
step: 100, loss: 0.0053470563143491745
step: 110, loss: 0.03994971141219139
step: 120, loss: 0.027782706543803215
step: 130, loss: 0.02573934942483902
step: 140, loss: 0.08004613220691681
step: 150, loss: 0.07739384472370148
step: 160, loss: 0.030476706102490425
step: 170, loss: 0.02434465102851391
step: 180, loss: 0.1156228557229042
step: 190, loss: 0.07778357714414597
step: 200, loss: 0.02286599949002266
step: 210, loss: 0.04687951132655144
step: 220, loss: 0.028250914067029953
step: 230, loss: 0.019745033234357834
step: 240, loss: 0.030121345072984695
step: 250, loss: 0.0396551638841629
step: 260, loss: 0.034244660288095474
step: 270, loss: 0.06737188249826431
step: 280, loss: 0.02607060968875885
step: 290, loss: 0.06045635789632797
step: 300, loss: 0.09987178444862366
step: 310, loss: 0.024872176349163055
step: 320, loss: 0.08205630630254745
step: 330, loss: 0.004370471928268671
step: 340, loss: 0.15338899195194244
step: 350, loss: 0.09159821271896362
step: 360, loss: 0.04591268301010132
step: 370, loss: 0.09868607670068741
step: 380, loss: 0.001175038400106132
step: 390, loss: 0.058982014656066895
step: 400, loss: 0.14687500894069672
step: 410, loss: 0.043745994567871094
step: 420, loss: 0.05680667608976364
step: 430, loss: 0.11225278675556183
step: 440, loss: 0.04403379186987877
step: 450, loss: 0.027756182476878166
step: 460, loss: 0.0020191429648548365
step: 470, loss: 0.1893029510974884
step: 480, loss: 0.025202594697475433
step: 490, loss: 0.01880420371890068
step: 500, loss: 0.06641951203346252
step: 510, loss: 0.1657288819551468
step: 520, loss: 0.26990780234336853
step: 530, loss: 0.20447386801242828
step: 540, loss: 0.08041369915008545
step: 550, loss: 0.09299490600824356
step: 560, loss: 0.06136217713356018
step: 570, loss: 0.18792401254177094
step: 580, loss: 0.09218494594097137
step: 590, loss: 0.11838185042142868
step: 600, loss: 0.05358909070491791
step: 610, loss: 0.10620888322591782
step: 620, loss: 0.03429669886827469
step: 630, loss: 0.007320207543671131
step: 640, loss: 0.21562349796295166
step: 650, loss: 0.04295798018574715
step: 660, loss: 0.053434956818819046
step: 670, loss: 0.07395976781845093
step: 680, loss: 0.1459357738494873
step: 690, loss: 0.07796527445316315
step: 700, loss: 0.07255095988512039
step: 710, loss: 0.02848062850534916
step: 720, loss: 0.024489205330610275
step: 730, loss: 0.06825682520866394
step: 740, loss: 0.09856944531202316
step: 750, loss: 0.09037379920482635
step: 760, loss: 0.06158487871289253
step: 770, loss: 0.13094979524612427
step: 780, loss: 0.09593930840492249
step: 790, loss: 0.052658144384622574
step: 800, loss: 0.02818707376718521
step: 810, loss: 0.02522215060889721
step: 820, loss: 0.025404945015907288
step: 830, loss: 0.023486141115427017
step: 840, loss: 0.08115646988153458
step: 850, loss: 0.10490062832832336
step: 860, loss: 0.14359748363494873
step: 870, loss: 0.06714636832475662
step: 880, loss: 0.0005872285109944642
step: 890, loss: 0.03868124261498451
step: 900, loss: 0.07537472993135452
step: 910, loss: 0.10285042971372604
step: 920, loss: 0.04840683564543724
step: 930, loss: 0.10654686391353607
step: 940, loss: 0.06790336221456528
step: 950, loss: 0.11615094542503357
step: 960, loss: 0.09020992368459702
step: 970, loss: 0.025391411036252975
step: 980, loss: 0.010168550536036491
step: 990, loss: 0.030740072950720787
step: 1000, loss: 0.10074956715106964
step: 1010, loss: 0.07119830697774887
step: 1020, loss: 0.07366390526294708
step: 1030, loss: 0.10697954893112183
step: 1040, loss: 0.13926728069782257
step: 1050, loss: 0.04187888652086258
step: 1060, loss: 0.025608770549297333
step: 1070, loss: 0.0627838596701622
epoch 4: dev_f1=0.9301675977653632, f1=0.925290023201856, best_f1=0.9324137931034482
step: 0, loss: 0.09526210278272629
step: 10, loss: 0.03270013630390167
step: 20, loss: 0.079657644033432
step: 30, loss: 0.030283218249678612
step: 40, loss: 0.07686647027730942
step: 50, loss: 0.06417039036750793
step: 60, loss: 0.025417514145374298
step: 70, loss: 0.10640707612037659
step: 80, loss: 0.005102222785353661
step: 90, loss: 0.1713184118270874
step: 100, loss: 0.16805170476436615
step: 110, loss: 0.019689815118908882
step: 120, loss: 0.14860525727272034
step: 130, loss: 0.08184738457202911
step: 140, loss: 0.09767893701791763
step: 150, loss: 0.035543330013751984
step: 160, loss: 0.09137730300426483
step: 170, loss: 0.07687286287546158
step: 180, loss: 0.023697610944509506
step: 190, loss: 0.10142754763364792
step: 200, loss: 0.13135430216789246
step: 210, loss: 0.015150477178394794
step: 220, loss: 0.02286989986896515
step: 230, loss: 0.037572626024484634
step: 240, loss: 0.09813185036182404
step: 250, loss: 0.009168755263090134
step: 260, loss: 0.00821802206337452
step: 270, loss: 0.13034966588020325
step: 280, loss: 0.08011627197265625
step: 290, loss: 0.06082175672054291
step: 300, loss: 0.10819052159786224
step: 310, loss: 0.060784898698329926
step: 320, loss: 0.013321999460458755
step: 330, loss: 0.017674703150987625
step: 340, loss: 0.025814805179834366
step: 350, loss: 0.07944155484437943
step: 360, loss: 0.1090429425239563
step: 370, loss: 0.031474094837903976
step: 380, loss: 0.030527163296937943
step: 390, loss: 0.17630302906036377
step: 400, loss: 0.14395806193351746
step: 410, loss: 0.03843248263001442
step: 420, loss: 0.08461102843284607
step: 430, loss: 0.07090182602405548
step: 440, loss: 0.05210493132472038
step: 450, loss: 0.02740061841905117
step: 460, loss: 0.027391210198402405
step: 470, loss: 0.021001061424613
step: 480, loss: 0.019508635625243187
step: 490, loss: 0.13984158635139465
step: 500, loss: 0.008692876435816288
step: 510, loss: 0.09182245284318924
step: 520, loss: 0.06927748769521713
step: 530, loss: 0.037664253264665604
step: 540, loss: 0.008769446052610874
step: 550, loss: 0.011081548407673836
step: 560, loss: 0.07540883868932724
step: 570, loss: 0.050895243883132935
step: 580, loss: 0.07393425703048706
step: 590, loss: 0.15781331062316895
step: 600, loss: 0.016743972897529602
step: 610, loss: 0.05084904655814171
step: 620, loss: 0.006816809996962547
step: 630, loss: 0.027408041059970856
step: 640, loss: 0.030054481700062752
step: 650, loss: 0.02182050794363022
step: 660, loss: 0.003277524607256055
step: 670, loss: 0.10786984860897064
step: 680, loss: 0.15315696597099304
step: 690, loss: 0.012687628157436848
step: 700, loss: 0.15799212455749512
step: 710, loss: 0.013505518436431885
step: 720, loss: 0.0340794213116169
step: 730, loss: 0.02829219214618206
step: 740, loss: 0.026598244905471802
step: 750, loss: 0.07629965245723724
step: 760, loss: 0.02650832012295723
step: 770, loss: 0.15653261542320251
step: 780, loss: 0.004945706110447645
step: 790, loss: 0.11876795440912247
step: 800, loss: 0.02973448857665062
step: 810, loss: 0.04066678509116173
step: 820, loss: 0.13519728183746338
step: 830, loss: 0.0791664570569992
step: 840, loss: 0.07412324845790863
step: 850, loss: 0.02585231512784958
step: 860, loss: 0.08609983325004578
step: 870, loss: 0.037362124770879745
step: 880, loss: 0.00420350581407547
step: 890, loss: 0.08689799904823303
step: 900, loss: 0.022741859778761864
step: 910, loss: 0.039810992777347565
step: 920, loss: 0.07719206064939499
step: 930, loss: 0.13101686537265778
step: 940, loss: 0.08090905100107193
step: 950, loss: 0.0283801406621933
step: 960, loss: 0.0402107760310173
step: 970, loss: 0.11559884250164032
step: 980, loss: 0.11066931486129761
step: 990, loss: 0.16389182209968567
step: 1000, loss: 0.03890981897711754
step: 1010, loss: 0.042043957859277725
step: 1020, loss: 0.12175364792346954
step: 1030, loss: 0.018324105069041252
step: 1040, loss: 0.015218934044241905
step: 1050, loss: 0.010719530284404755
step: 1060, loss: 0.14005276560783386
step: 1070, loss: 0.15231968462467194
epoch 5: dev_f1=0.9326568265682658, f1=0.9234296194406236, best_f1=0.9324137931034482
step: 0, loss: 0.01699903979897499
step: 10, loss: 0.040543414652347565
step: 20, loss: 0.030970178544521332
step: 30, loss: 0.015584469772875309
step: 40, loss: 0.009626799263060093
step: 50, loss: 0.1466609686613083
step: 60, loss: 0.08320488035678864
step: 70, loss: 0.10562636703252792
step: 80, loss: 0.055751021951436996
step: 90, loss: 0.07845737785100937
step: 100, loss: 0.07118436694145203
step: 110, loss: 0.019953440874814987
step: 120, loss: 0.00014613248640671372
step: 130, loss: 0.07253532111644745
step: 140, loss: 0.08851179480552673
step: 150, loss: 0.09987258166074753
step: 160, loss: 0.02716689743101597
step: 170, loss: 0.0844796895980835
step: 180, loss: 0.0261104516685009
step: 190, loss: 0.03908728063106537
step: 200, loss: 0.018986904993653297
step: 210, loss: 0.054103363305330276
step: 220, loss: 0.06026616320014
step: 230, loss: 0.04160093516111374
step: 240, loss: 0.05352342501282692
step: 250, loss: 0.09940560907125473
step: 260, loss: 0.18775303661823273
step: 270, loss: 0.027542710304260254
step: 280, loss: 0.0850328877568245
step: 290, loss: 0.08847492933273315
step: 300, loss: 0.024686450138688087
step: 310, loss: 0.05905472859740257
step: 320, loss: 0.09078275412321091
step: 330, loss: 0.09447778016328812
step: 340, loss: 0.029669204726815224
step: 350, loss: 0.10076860338449478
step: 360, loss: 0.1097416803240776
step: 370, loss: 0.08061105757951736
step: 380, loss: 0.019283317029476166
step: 390, loss: 0.11928996443748474
step: 400, loss: 0.08206973224878311
step: 410, loss: 0.08483591675758362
step: 420, loss: 0.026368167251348495
step: 430, loss: 0.06974679231643677
step: 440, loss: 0.1171964779496193
step: 450, loss: 0.0615229532122612
step: 460, loss: 0.10643263161182404
step: 470, loss: 0.04766468703746796
step: 480, loss: 0.06621073186397552
step: 490, loss: 0.089790478348732
step: 500, loss: 0.07828269898891449
step: 510, loss: 0.1195991039276123
step: 520, loss: 0.009667353704571724
step: 530, loss: 0.09919373691082001
step: 540, loss: 0.08025862276554108
step: 550, loss: 0.07763272523880005
step: 560, loss: 0.0446656197309494
step: 570, loss: 0.13774578273296356
step: 580, loss: 0.15469352900981903
step: 590, loss: 0.04254186898469925
step: 600, loss: 0.13102546334266663
step: 610, loss: 0.11528151482343674
step: 620, loss: 0.009850317612290382
step: 630, loss: 0.008631751872599125
step: 640, loss: 0.06864795833826065
step: 650, loss: 0.03359195962548256
step: 660, loss: 0.05495644360780716
step: 670, loss: 0.0018915676046162844
step: 680, loss: 0.02004939876496792
step: 690, loss: 0.12485118955373764
step: 700, loss: 0.03306705877184868
step: 710, loss: 0.042156562209129333
step: 720, loss: 0.14270006120204926
step: 730, loss: 0.08831964433193207
step: 740, loss: 0.022194311022758484
step: 750, loss: 0.1275806874036789
step: 760, loss: 0.09942443668842316
step: 770, loss: 0.03659729287028313
step: 780, loss: 0.03537241369485855
step: 790, loss: 0.02486022189259529
step: 800, loss: 0.09023790806531906
step: 810, loss: 0.08787659555673599
step: 820, loss: 0.04685215279459953
step: 830, loss: 0.01007271558046341
step: 840, loss: 0.08710096031427383
step: 850, loss: 0.003961584065109491
step: 860, loss: 0.08376384526491165
step: 870, loss: 0.19519197940826416
step: 880, loss: 0.04366645589470863
step: 890, loss: 0.1603483408689499
step: 900, loss: 0.06147566810250282
step: 910, loss: 0.05168914422392845
step: 920, loss: 0.0008418784709647298
step: 930, loss: 0.13928622007369995
step: 940, loss: 0.07050053775310516
step: 950, loss: 0.052008822560310364
step: 960, loss: 0.1476404070854187
step: 970, loss: 0.0773971900343895
step: 980, loss: 0.11196287721395493
step: 990, loss: 0.06464678049087524
step: 1000, loss: 0.08576872199773788
step: 1010, loss: 0.08952774107456207
step: 1020, loss: 0.05213376134634018
step: 1030, loss: 0.022462181746959686
step: 1040, loss: 0.035747162997722626
step: 1050, loss: 0.1114216297864914
step: 1060, loss: 0.0143667533993721
step: 1070, loss: 0.23173367977142334
epoch 6: dev_f1=0.9313815187557181, f1=0.924056389267849, best_f1=0.9324137931034482
step: 0, loss: 0.036892861127853394
step: 10, loss: 0.035107433795928955
step: 20, loss: 0.05528086796402931
step: 30, loss: 0.025317294523119926
step: 40, loss: 0.014921199530363083
step: 50, loss: 0.043771158903837204
step: 60, loss: 0.12109872698783875
step: 70, loss: 0.15668365359306335
step: 80, loss: 0.27406030893325806
step: 90, loss: 0.10968661308288574
step: 100, loss: 0.08369369804859161
step: 110, loss: 0.009424418210983276
step: 120, loss: 0.08012101799249649
step: 130, loss: 0.0005547268665395677
step: 140, loss: 8.66883565322496e-05
step: 150, loss: 0.11485815048217773
step: 160, loss: 0.06937018781900406
step: 170, loss: 0.010552579537034035
step: 180, loss: 0.056784555315971375
step: 190, loss: 0.14399385452270508
step: 200, loss: 0.019099494442343712
step: 210, loss: 0.00536029739305377
step: 220, loss: 0.029624996706843376
step: 230, loss: 0.11671893298625946
step: 240, loss: 0.06018943712115288
step: 250, loss: 0.06553985923528671
step: 260, loss: 0.03320387005805969
step: 270, loss: 0.21353629231452942
step: 280, loss: 0.035140275955200195
step: 290, loss: 0.0008275513537228107
step: 300, loss: 0.023952992632985115
step: 310, loss: 0.09562934935092926
step: 320, loss: 0.024283798411488533
step: 330, loss: 0.0652230978012085
step: 340, loss: 0.02628207951784134
step: 350, loss: 0.04347667843103409
step: 360, loss: 0.008854049257934093
step: 370, loss: 0.02072562463581562
step: 380, loss: 0.051763471215963364
step: 390, loss: 0.07024827599525452
step: 400, loss: 0.06892596930265427
step: 410, loss: 0.1632665991783142
step: 420, loss: 0.009298005141317844
step: 430, loss: 0.05708576738834381
step: 440, loss: 0.11371752619743347
step: 450, loss: 0.02242547646164894
step: 460, loss: 0.12364036589860916
step: 470, loss: 0.03345770388841629
step: 480, loss: 0.09273295104503632
step: 490, loss: 0.0047941734082996845
step: 500, loss: 0.0091469157487154
step: 510, loss: 0.016756007447838783
step: 520, loss: 0.009242796339094639
step: 530, loss: 0.07687141001224518
step: 540, loss: 0.05384085699915886
step: 550, loss: 0.06460041552782059
step: 560, loss: 0.04152372479438782
step: 570, loss: 0.027176696807146072
step: 580, loss: 0.08586869388818741
step: 590, loss: 0.06818444281816483
step: 600, loss: 0.012536777183413506
step: 610, loss: 0.006445766426622868
step: 620, loss: 0.06976261734962463
step: 630, loss: 0.22643372416496277
step: 640, loss: 0.0891154408454895
step: 650, loss: 0.004634620621800423
step: 660, loss: 0.1312468945980072
step: 670, loss: 0.012696397490799427
step: 680, loss: 0.00744539825245738
step: 690, loss: 0.1440289318561554
step: 700, loss: 0.08043331652879715
step: 710, loss: 0.08527487516403198
step: 720, loss: 0.01411163154989481
step: 730, loss: 0.038056012243032455
step: 740, loss: 0.11062552779912949
step: 750, loss: 0.02646258845925331
step: 760, loss: 0.06968528777360916
step: 770, loss: 0.04434720799326897
step: 780, loss: 0.0058043343015015125
step: 790, loss: 0.0936456173658371
step: 800, loss: 0.08710445463657379
step: 810, loss: 0.037761807441711426
step: 820, loss: 0.039365753531455994
step: 830, loss: 0.0006465830956585705
step: 840, loss: 0.014352770522236824
step: 850, loss: 0.058687541633844376
step: 860, loss: 0.07095117121934891
step: 870, loss: 0.03479635715484619
step: 880, loss: 0.10257135331630707
step: 890, loss: 0.02743850089609623
step: 900, loss: 0.0592106468975544
step: 910, loss: 0.06836904585361481
step: 920, loss: 0.07512932270765305
step: 930, loss: 0.07795397192239761
step: 940, loss: 0.07964501529932022
step: 950, loss: 0.07899807393550873
step: 960, loss: 0.020934833213686943
step: 970, loss: 0.04016457870602608
step: 980, loss: 0.07502829283475876
step: 990, loss: 0.004232846200466156
step: 1000, loss: 0.07112839818000793
step: 1010, loss: 0.026960400864481926
step: 1020, loss: 0.14650309085845947
step: 1030, loss: 0.031199995428323746
step: 1040, loss: 0.11772342026233673
step: 1050, loss: 0.00533746974542737
step: 1060, loss: 0.03744208812713623
step: 1070, loss: 0.004172915127128363
epoch 7: dev_f1=0.9412861136999067, f1=0.9351251158480075, best_f1=0.9351251158480075
step: 0, loss: 0.018372222781181335
step: 10, loss: 0.09626290947198868
step: 20, loss: 0.07646789401769638
step: 30, loss: 9.047707862919196e-05
step: 40, loss: 0.05263017490506172
step: 50, loss: 0.05331641808152199
step: 60, loss: 0.03866972774267197
step: 70, loss: 0.057550542056560516
step: 80, loss: 0.025382086634635925
step: 90, loss: 0.04255392774939537
step: 100, loss: 0.07273896038532257
step: 110, loss: 0.09554263204336166
step: 120, loss: 0.021916480734944344
step: 130, loss: 0.024317260831594467
step: 140, loss: 0.06856851279735565
step: 150, loss: 0.07762788236141205
step: 160, loss: 0.0535857230424881
step: 170, loss: 0.012861387804150581
step: 180, loss: 0.0797097384929657
step: 190, loss: 0.008355865254998207
step: 200, loss: 0.01123584434390068
step: 210, loss: 0.12477406859397888
step: 220, loss: 0.0507846400141716
step: 230, loss: 0.09989511966705322
step: 240, loss: 0.08929436653852463
step: 250, loss: 0.021061386913061142
step: 260, loss: 0.032125528901815414
step: 270, loss: 0.045190565288066864
step: 280, loss: 0.007484511937946081
step: 290, loss: 0.03831501305103302
step: 300, loss: 0.04195041209459305
step: 310, loss: 0.15878285467624664
step: 320, loss: 0.012733623385429382
step: 330, loss: 0.03153907507658005
step: 340, loss: 0.00839658547192812
step: 350, loss: 0.015926793217658997
step: 360, loss: 0.06220945715904236
step: 370, loss: 0.00661664642393589
step: 380, loss: 0.04260530695319176
step: 390, loss: 0.001502012717537582
step: 400, loss: 0.09073350578546524
step: 410, loss: 0.00016129185678437352
step: 420, loss: 0.05297987163066864
step: 430, loss: 0.18973734974861145
step: 440, loss: 0.07113105058670044
step: 450, loss: 0.030236676335334778
step: 460, loss: 0.03210156410932541
step: 470, loss: 0.05599231645464897
step: 480, loss: 0.06139934062957764
step: 490, loss: 0.04807806387543678
step: 500, loss: 0.004747332073748112
step: 510, loss: 0.011919297277927399
step: 520, loss: 0.10830742120742798
step: 530, loss: 0.19648513197898865
step: 540, loss: 0.08071187138557434
step: 550, loss: 0.07121089845895767
step: 560, loss: 0.02420101687312126
step: 570, loss: 0.005332093220204115
step: 580, loss: 0.033111460506916046
step: 590, loss: 0.02032899297773838
step: 600, loss: 0.06895656883716583
step: 610, loss: 0.14310026168823242
step: 620, loss: 0.024684526026248932
step: 630, loss: 0.15993425250053406
step: 640, loss: 0.01884746365249157
step: 650, loss: 0.03905784711241722
step: 660, loss: 0.031013736501336098
step: 670, loss: 0.05338484048843384
step: 680, loss: 0.016636349260807037
step: 690, loss: 0.00041555415373295546
step: 700, loss: 0.06849371641874313
step: 710, loss: 0.029218273237347603
step: 720, loss: 0.017233720049262047
step: 730, loss: 0.03266333416104317
step: 740, loss: 0.00727973273023963
step: 750, loss: 0.07957242429256439
step: 760, loss: 0.14683502912521362
step: 770, loss: 0.02994489297270775
step: 780, loss: 0.055418889969587326
step: 790, loss: 0.05782598257064819
step: 800, loss: 0.015219339169561863
step: 810, loss: 0.08504850417375565
step: 820, loss: 0.04092095419764519
step: 830, loss: 0.04972236230969429
step: 840, loss: 0.004443126264959574
step: 850, loss: 0.1044572964310646
step: 860, loss: 0.052720535546541214
step: 870, loss: 0.07957658916711807
step: 880, loss: 0.014727682806551456
step: 890, loss: 0.07025019824504852
step: 900, loss: 0.08096867054700851
step: 910, loss: 0.014733378775417805
step: 920, loss: 0.024906478822231293
step: 930, loss: 0.022144589573144913
step: 940, loss: 0.007856770418584347
step: 950, loss: 0.013265276327729225
step: 960, loss: 0.004686387721449137
step: 970, loss: 0.09416232258081436
step: 980, loss: 0.018681809306144714
step: 990, loss: 0.08865166455507278
step: 1000, loss: 0.08836875110864639
step: 1010, loss: 0.05744296312332153
step: 1020, loss: 0.0027312436141073704
step: 1030, loss: 0.02783382311463356
step: 1040, loss: 0.008222631178796291
step: 1050, loss: 0.05523012951016426
step: 1060, loss: 0.07779572159051895
step: 1070, loss: 0.06925266981124878
epoch 8: dev_f1=0.937528921795465, f1=0.9319227230910764, best_f1=0.9351251158480075
step: 0, loss: 0.016389163210988045
step: 10, loss: 0.07593169808387756
step: 20, loss: 0.01746060512959957
step: 30, loss: 0.005768045783042908
step: 40, loss: 0.031112821772694588
step: 50, loss: 0.04735887795686722
step: 60, loss: 0.05948704108595848
step: 70, loss: 0.09735633432865143
step: 80, loss: 0.02846686542034149
step: 90, loss: 0.04987595975399017
step: 100, loss: 0.07402978092432022
step: 110, loss: 0.035578906536102295
step: 120, loss: 0.08790487051010132
step: 130, loss: 0.00016287404287140816
step: 140, loss: 0.16856242716312408
step: 150, loss: 0.03354036808013916
step: 160, loss: 0.09427261352539062
step: 170, loss: 0.06736330687999725
step: 180, loss: 0.018780136480927467
step: 190, loss: 0.016146190464496613
step: 200, loss: 0.1854255050420761
step: 210, loss: 0.011285227723419666
step: 220, loss: 0.01287437230348587
step: 230, loss: 0.0032089308369904757
step: 240, loss: 0.04161643236875534
step: 250, loss: 0.03647066280245781
step: 260, loss: 0.10369616001844406
step: 270, loss: 0.1233629584312439
step: 280, loss: 0.018627339974045753
step: 290, loss: 0.04448484629392624
step: 300, loss: 0.0040511758998036385
step: 310, loss: 0.009043986909091473
step: 320, loss: 0.03494059294462204
step: 330, loss: 0.039850328117609024
step: 340, loss: 0.07412164658308029
step: 350, loss: 0.0064300671219825745
step: 360, loss: 0.031205929815769196
step: 370, loss: 0.061586033552885056
step: 380, loss: 0.04831516742706299
step: 390, loss: 0.03781940042972565
step: 400, loss: 0.0006038995343260467
step: 410, loss: 0.019121892750263214
step: 420, loss: 0.014785615727305412
step: 430, loss: 0.0434221476316452
step: 440, loss: 0.03654739633202553
step: 450, loss: 0.016943104565143585
step: 460, loss: 0.012643749825656414
step: 470, loss: 0.06413821876049042
step: 480, loss: 0.11512015759944916
step: 490, loss: 0.07798796892166138
step: 500, loss: 0.027480345219373703
step: 510, loss: 0.039184797555208206
step: 520, loss: 0.03330119326710701
step: 530, loss: 0.08772322535514832
step: 540, loss: 0.008985253050923347
step: 550, loss: 0.06142941862344742
step: 560, loss: 0.07488630712032318
step: 570, loss: 0.014866238459944725
step: 580, loss: 0.08761316537857056
step: 590, loss: 0.04496346786618233
step: 600, loss: 0.03028843179345131
step: 610, loss: 0.021679149940609932
step: 620, loss: 0.006967560853809118
step: 630, loss: 0.010104955174028873
step: 640, loss: 0.026845989748835564
step: 650, loss: 0.056098662316799164
step: 660, loss: 0.04956177994608879
step: 670, loss: 0.09759430587291718
step: 680, loss: 0.10495912283658981
step: 690, loss: 0.06248842179775238
step: 700, loss: 0.06236550584435463
step: 710, loss: 0.042710259556770325
step: 720, loss: 0.07623577862977982
step: 730, loss: 0.02509378269314766
step: 740, loss: 0.08928964287042618
step: 750, loss: 0.01753547601401806
step: 760, loss: 0.022047720849514008
step: 770, loss: 0.10273037105798721
step: 780, loss: 0.00426728930324316
step: 790, loss: 0.10987860709428787
step: 800, loss: 0.03184996545314789
step: 810, loss: 0.0035827357787638903
step: 820, loss: 0.11354191601276398
step: 830, loss: 0.024284925311803818
step: 840, loss: 0.03892817348241806
step: 850, loss: 0.18887925148010254
step: 860, loss: 0.05359886959195137
step: 870, loss: 0.027439765632152557
step: 880, loss: 0.06279504299163818
step: 890, loss: 0.01915915310382843
step: 900, loss: 0.0674554705619812
step: 910, loss: 0.10295512527227402
step: 920, loss: 0.07712548971176147
step: 930, loss: 0.07403828203678131
step: 940, loss: 0.03279474005103111
step: 950, loss: 0.00338241015560925
step: 960, loss: 0.008231455460190773
step: 970, loss: 0.016619069501757622
step: 980, loss: 0.07166030257940292
step: 990, loss: 0.05291597545146942
step: 1000, loss: 0.00039079022826626897
step: 1010, loss: 0.006753058638423681
step: 1020, loss: 0.04036124795675278
step: 1030, loss: 0.042790379375219345
step: 1040, loss: 0.09743857383728027
step: 1050, loss: 0.09123700112104416
step: 1060, loss: 0.05563430115580559
step: 1070, loss: 0.09862331300973892
epoch 9: dev_f1=0.9271461716937355, f1=0.9207373271889401, best_f1=0.9351251158480075
step: 0, loss: 0.008925599977374077
step: 10, loss: 0.21523748338222504
step: 20, loss: 0.016101840883493423
step: 30, loss: 0.055954258888959885
step: 40, loss: 0.037638723850250244
step: 50, loss: 0.008955651894211769
step: 60, loss: 0.04254790022969246
step: 70, loss: 0.06574470549821854
step: 80, loss: 0.09672616422176361
step: 90, loss: 0.015926579013466835
step: 100, loss: 0.11752483248710632
step: 110, loss: 0.010191245004534721
step: 120, loss: 0.017183702439069748
step: 130, loss: 0.009661130607128143
step: 140, loss: 0.02896733582019806
step: 150, loss: 8.3320883277338e-05
step: 160, loss: 0.017764396965503693
step: 170, loss: 0.004889338277280331
step: 180, loss: 0.0348229855298996
step: 190, loss: 0.054954975843429565
step: 200, loss: 0.021330339834094048
step: 210, loss: 0.120086669921875
step: 220, loss: 0.05082492530345917
step: 230, loss: 0.0543891116976738
step: 240, loss: 0.07821671664714813
step: 250, loss: 0.12591823935508728
step: 260, loss: 0.006064293440431356
step: 270, loss: 0.0806983932852745
step: 280, loss: 0.05417165160179138
step: 290, loss: 0.019744114950299263
step: 300, loss: 0.030378300696611404
step: 310, loss: 0.024455854669213295
step: 320, loss: 0.09445003420114517
step: 330, loss: 0.07100284844636917
step: 340, loss: 0.184407040476799
step: 350, loss: 0.039323244243860245
step: 360, loss: 0.04197734221816063
step: 370, loss: 0.02481878735125065
step: 380, loss: 0.07617023587226868
step: 390, loss: 0.004902631975710392
step: 400, loss: 0.018444914370775223
step: 410, loss: 0.003699644235894084
step: 420, loss: 0.010240846313536167
step: 430, loss: 0.08007314801216125
step: 440, loss: 0.06877492368221283
step: 450, loss: 0.07282117009162903
step: 460, loss: 0.05354754626750946
step: 470, loss: 0.11061262339353561
step: 480, loss: 0.02534753642976284
step: 490, loss: 0.0943712368607521
step: 500, loss: 0.048250406980514526
step: 510, loss: 0.051525432616472244
step: 520, loss: 0.06017153710126877
step: 530, loss: 0.06527567654848099
step: 540, loss: 0.1025911197066307
step: 550, loss: 0.11340643465518951
step: 560, loss: 0.003832716727629304
step: 570, loss: 0.005853431299328804
step: 580, loss: 0.029649686068296432
step: 590, loss: 0.14434070885181427
step: 600, loss: 0.09162147343158722
step: 610, loss: 0.05940840393304825
step: 620, loss: 0.048968371003866196
step: 630, loss: 0.01473679207265377
step: 640, loss: 0.06703964620828629
step: 650, loss: 0.020683422684669495
step: 660, loss: 0.011078908108174801
step: 670, loss: 0.044562872499227524
step: 680, loss: 0.2190154790878296
step: 690, loss: 0.09978286176919937
step: 700, loss: 0.017445527017116547
step: 710, loss: 0.006350852083414793
step: 720, loss: 0.013342069461941719
step: 730, loss: 0.029946431517601013
step: 740, loss: 0.01326366513967514
step: 750, loss: 0.0001250750501640141
step: 760, loss: 0.048451803624629974
step: 770, loss: 0.04665117710828781
step: 780, loss: 0.04622932896018028
step: 790, loss: 0.0020428267307579517
step: 800, loss: 0.011906012892723083
step: 810, loss: 0.004028181545436382
step: 820, loss: 0.027741894125938416
step: 830, loss: 0.0024009717162698507
step: 840, loss: 0.017591457813978195
step: 850, loss: 0.02128332108259201
step: 860, loss: 0.025043511763215065
step: 870, loss: 0.037105999886989594
step: 880, loss: 0.005563116632401943
step: 890, loss: 0.061726249754428864
step: 900, loss: 0.013905239291489124
step: 910, loss: 0.014285488054156303
step: 920, loss: 0.07517532259225845
step: 930, loss: 0.012125902809202671
step: 940, loss: 0.09219840914011002
step: 950, loss: 0.0362064465880394
step: 960, loss: 0.04409795626997948
step: 970, loss: 0.0071273669600486755
step: 980, loss: 0.04023435711860657
step: 990, loss: 0.06690367311239243
step: 1000, loss: 0.022671634331345558
step: 1010, loss: 0.02832929603755474
step: 1020, loss: 0.06090592220425606
step: 1030, loss: 0.09332090616226196
step: 1040, loss: 0.06426306813955307
step: 1050, loss: 0.021014712750911713
step: 1060, loss: 0.024896319955587387
step: 1070, loss: 0.004707642365247011
epoch 10: dev_f1=0.93202062822316, f1=0.9263256687001408, best_f1=0.9351251158480075
step: 0, loss: 0.03698713332414627
step: 10, loss: 0.03168993815779686
step: 20, loss: 0.0023203552700579166
step: 30, loss: 0.004049172159284353
step: 40, loss: 0.07262706011533737
step: 50, loss: 0.006800154224038124
step: 60, loss: 0.07206147909164429
step: 70, loss: 0.06203126162290573
step: 80, loss: 0.04300307855010033
step: 90, loss: 0.027428608387708664
step: 100, loss: 0.02754259668290615
step: 110, loss: 3.4982651413884014e-05
step: 120, loss: 0.0037393197417259216
step: 130, loss: 0.263967901468277
step: 140, loss: 0.1046575978398323
step: 150, loss: 0.08476472645998001
step: 160, loss: 0.025119561702013016
step: 170, loss: 0.02894115075469017
step: 180, loss: 0.03693942353129387
step: 190, loss: 0.0032962351106107235
step: 200, loss: 0.02113826386630535
step: 210, loss: 0.0007156831561587751
step: 220, loss: 0.008607693947851658
step: 230, loss: 0.0572294183075428
step: 240, loss: 0.019475199282169342
step: 250, loss: 0.023656433448195457
step: 260, loss: 0.025706924498081207
step: 270, loss: 0.09036040306091309
step: 280, loss: 3.240031946916133e-05
step: 290, loss: 0.05892648175358772
step: 300, loss: 0.0069235460832715034
step: 310, loss: 0.08681942522525787
step: 320, loss: 0.0004057678743265569
step: 330, loss: 0.0013992871390655637
step: 340, loss: 0.04253479465842247
step: 350, loss: 0.04532001540064812
step: 360, loss: 0.030368318781256676
step: 370, loss: 0.011410791426897049
step: 380, loss: 0.08292070776224136
step: 390, loss: 0.14511486887931824
step: 400, loss: 0.05756314843893051
step: 410, loss: 6.136433512438089e-05
step: 420, loss: 0.016487475484609604
step: 430, loss: 0.026276174932718277
step: 440, loss: 0.04242783412337303
step: 450, loss: 0.0010658294195309281
step: 460, loss: 0.08237335085868835
step: 470, loss: 0.07691919803619385
step: 480, loss: 0.011400017887353897
step: 490, loss: 0.04145476222038269
step: 500, loss: 0.05370143800973892
step: 510, loss: 0.04558337479829788
step: 520, loss: 0.05401339381933212
step: 530, loss: 0.013661324977874756
step: 540, loss: 0.009692357853055
step: 550, loss: 0.04092450067400932
step: 560, loss: 0.12223315238952637
step: 570, loss: 0.10416664928197861
step: 580, loss: 0.06144498288631439
step: 590, loss: 0.050582405179739
step: 600, loss: 0.010586163960397243
step: 610, loss: 0.08069358021020889
step: 620, loss: 0.055775657296180725
step: 630, loss: 0.056471697986125946
step: 640, loss: 0.010622911155223846
step: 650, loss: 0.00460328022018075
step: 660, loss: 0.04930441081523895
step: 670, loss: 0.04034187272191048
step: 680, loss: 0.019253134727478027
step: 690, loss: 0.01961899921298027
step: 700, loss: 0.03123658522963524
step: 710, loss: 0.09877683967351913
step: 720, loss: 0.039998989552259445
step: 730, loss: 3.398049739189446e-05
step: 740, loss: 0.06184045970439911
step: 750, loss: 0.13499018549919128
step: 760, loss: 0.015555884689092636
step: 770, loss: 0.011433964595198631
step: 780, loss: 0.008401896804571152
step: 790, loss: 0.0063132415525615215
step: 800, loss: 0.023183491080999374
step: 810, loss: 0.113799087703228
step: 820, loss: 0.022932231426239014
step: 830, loss: 0.0010432811686769128
step: 840, loss: 0.14812670648097992
step: 850, loss: 0.08261148631572723
step: 860, loss: 0.0023989605251699686
step: 870, loss: 0.0849352553486824
step: 880, loss: 0.005629163701087236
step: 890, loss: 0.015857724472880363
step: 900, loss: 0.10800953209400177
step: 910, loss: 0.013655648566782475
step: 920, loss: 0.03487629070878029
step: 930, loss: 0.019891204312443733
step: 940, loss: 0.0004475167952477932
step: 950, loss: 0.08938948065042496
step: 960, loss: 0.0325077623128891
step: 970, loss: 0.00895691104233265
step: 980, loss: 0.0363025963306427
step: 990, loss: 0.06912312656641006
step: 1000, loss: 0.0021736996714025736
step: 1010, loss: 0.0104441549628973
step: 1020, loss: 0.02825888991355896
step: 1030, loss: 0.04462173208594322
step: 1040, loss: 0.039905909448862076
step: 1050, loss: 0.02632231079041958
step: 1060, loss: 0.0788770467042923
step: 1070, loss: 0.08291538059711456
epoch 11: dev_f1=0.9326614750343564, f1=0.9332121762835075, best_f1=0.9351251158480075
step: 0, loss: 0.017045825719833374
step: 10, loss: 0.05456189811229706
step: 20, loss: 0.04234636574983597
step: 30, loss: 0.034396298229694366
step: 40, loss: 0.020595824345946312
step: 50, loss: 0.013653871603310108
step: 60, loss: 0.042754728347063065
step: 70, loss: 3.755634679691866e-05
step: 80, loss: 0.06658907979726791
step: 90, loss: 9.48061715462245e-05
step: 100, loss: 0.04321557655930519
step: 110, loss: 0.03419695794582367
step: 120, loss: 0.029237883165478706
step: 130, loss: 4.110391819267534e-05
step: 140, loss: 0.06007589027285576
step: 150, loss: 0.026926405727863312
step: 160, loss: 0.07153462618589401
step: 170, loss: 0.020817304030060768
step: 180, loss: 0.024518568068742752
step: 190, loss: 0.17560040950775146
step: 200, loss: 0.08233153820037842
step: 210, loss: 0.014090212062001228
step: 220, loss: 0.02584172785282135
step: 230, loss: 4.052100484841503e-05
step: 240, loss: 0.047019343823194504
step: 250, loss: 0.08625365793704987
step: 260, loss: 0.014884207397699356
step: 270, loss: 0.05750530585646629
step: 280, loss: 0.018065478652715683
step: 290, loss: 0.011954927816987038
step: 300, loss: 0.0006454105023294687
step: 310, loss: 0.06106560304760933
step: 320, loss: 0.0015367022715508938
step: 330, loss: 0.10438936203718185
step: 340, loss: 0.02107558771967888
step: 350, loss: 0.027735035866498947
step: 360, loss: 4.259339038981125e-05
step: 370, loss: 0.028797851875424385
step: 380, loss: 0.04468325152993202
step: 390, loss: 0.03950514644384384
step: 400, loss: 0.06742895394563675
step: 410, loss: 0.04575330391526222
step: 420, loss: 0.017354661598801613
step: 430, loss: 0.08687261492013931
step: 440, loss: 0.0045390259474515915
step: 450, loss: 0.0009185600792989135
step: 460, loss: 0.0002312622091267258
step: 470, loss: 0.07782722264528275
step: 480, loss: 0.020600510761141777
step: 490, loss: 0.015614031814038754
step: 500, loss: 0.008737917058169842
step: 510, loss: 0.03458515927195549
step: 520, loss: 0.015307300724089146
step: 530, loss: 0.004763543605804443
step: 540, loss: 0.05012013018131256
step: 550, loss: 0.004814280197024345
step: 560, loss: 0.0434257909655571
step: 570, loss: 0.06875471770763397
step: 580, loss: 0.004849455319344997
step: 590, loss: 0.051276613026857376
step: 600, loss: 0.03113909438252449
step: 610, loss: 0.06809557974338531
step: 620, loss: 0.02877689339220524
step: 630, loss: 0.03833489492535591
step: 640, loss: 0.05108404904603958
step: 650, loss: 0.05499805510044098
step: 660, loss: 0.030790310353040695
step: 670, loss: 0.04807644709944725
step: 680, loss: 0.0035778572782874107
step: 690, loss: 0.017111171036958694
step: 700, loss: 0.009249487891793251
step: 710, loss: 0.08531495928764343
step: 720, loss: 0.018666813150048256
step: 730, loss: 0.0235275961458683
step: 740, loss: 0.03218240663409233
step: 750, loss: 0.07708074897527695
step: 760, loss: 0.011854641139507294
step: 770, loss: 0.06501639634370804
step: 780, loss: 0.047083668410778046
step: 790, loss: 0.01459377259016037
step: 800, loss: 0.03916293382644653
step: 810, loss: 0.10195694863796234
step: 820, loss: 0.003940137103199959
step: 830, loss: 0.0027814425993710756
step: 840, loss: 0.0635308027267456
step: 850, loss: 0.010700407437980175
step: 860, loss: 0.0555046908557415
step: 870, loss: 0.032662034034729004
step: 880, loss: 0.004026365000754595
step: 890, loss: 0.07473354041576385
step: 900, loss: 0.009720062837004662
step: 910, loss: 0.08699005842208862
step: 920, loss: 0.008917216211557388
step: 930, loss: 0.025518547743558884
step: 940, loss: 0.0029593966901302338
step: 950, loss: 0.0844227522611618
step: 960, loss: 0.015624885447323322
step: 970, loss: 0.053434375673532486
step: 980, loss: 0.023845475167036057
step: 990, loss: 0.0002642873441800475
step: 1000, loss: 0.1375053972005844
step: 1010, loss: 0.04632952809333801
step: 1020, loss: 0.04030899703502655
step: 1030, loss: 0.05556344985961914
step: 1040, loss: 1.696106482995674e-05
step: 1050, loss: 0.07721531391143799
step: 1060, loss: 0.029209110885858536
step: 1070, loss: 0.11103367805480957
epoch 12: dev_f1=0.9315960912052118, f1=0.9242916860195076, best_f1=0.9351251158480075
step: 0, loss: 0.022354844957590103
step: 10, loss: 0.0673857256770134
step: 20, loss: 0.041761208325624466
step: 30, loss: 0.0061911107040941715
step: 40, loss: 4.61497729702387e-05
step: 50, loss: 0.007052520755678415
step: 60, loss: 0.005579523742198944
step: 70, loss: 0.04167342558503151
step: 80, loss: 0.005477298051118851
step: 90, loss: 0.011387779377400875
step: 100, loss: 0.08634945005178452
step: 110, loss: 1.4699878192914184e-05
step: 120, loss: 2.2045680452720262e-05
step: 130, loss: 0.030264761298894882
step: 140, loss: 0.055378176271915436
step: 150, loss: 0.14100538194179535
step: 160, loss: 0.014737023040652275
step: 170, loss: 0.046449098736047745
step: 180, loss: 0.0014473196351900697
step: 190, loss: 0.008640044368803501
step: 200, loss: 0.04476947709918022
step: 210, loss: 0.07058047503232956
step: 220, loss: 0.020610418170690536
step: 230, loss: 0.06883939355611801
step: 240, loss: 0.00145199173130095
step: 250, loss: 5.350952051230706e-05
step: 260, loss: 0.03691057115793228
step: 270, loss: 0.02357078157365322
step: 280, loss: 0.06118663772940636
step: 290, loss: 0.005555839743465185
step: 300, loss: 0.012780332006514072
step: 310, loss: 9.960499301087111e-05
step: 320, loss: 3.2349540560971946e-05
step: 330, loss: 0.07237104326486588
step: 340, loss: 0.049370765686035156
step: 350, loss: 0.02288220077753067
step: 360, loss: 0.00011687223013723269
step: 370, loss: 0.08887773007154465
step: 380, loss: 0.0470363050699234
step: 390, loss: 0.017752962186932564
step: 400, loss: 0.007705541793256998
step: 410, loss: 0.01922772079706192
step: 420, loss: 0.047958530485630035
step: 430, loss: 0.032948654145002365
step: 440, loss: 0.07598885148763657
step: 450, loss: 0.061360713094472885
step: 460, loss: 0.012574213556945324
step: 470, loss: 0.04023498669266701
step: 480, loss: 2.679907629499212e-05
step: 490, loss: 0.0175054632127285
step: 500, loss: 2.4865958039299585e-05
step: 510, loss: 0.031976714730262756
step: 520, loss: 5.25451177963987e-05
step: 530, loss: 0.061103083193302155
step: 540, loss: 0.05143390968441963
step: 550, loss: 0.03319132700562477
step: 560, loss: 0.05344516411423683
step: 570, loss: 0.1518775224685669
step: 580, loss: 0.0009786236332729459
step: 590, loss: 0.03889622539281845
step: 600, loss: 0.006544030737131834
step: 610, loss: 0.07328380644321442
step: 620, loss: 0.06065366417169571
step: 630, loss: 0.02167476899921894
step: 640, loss: 0.1554792821407318
step: 650, loss: 0.03287862241268158
step: 660, loss: 0.016371065750718117
step: 670, loss: 0.010909071192145348
step: 680, loss: 0.12845122814178467
step: 690, loss: 0.06637333333492279
step: 700, loss: 0.05653354898095131
step: 710, loss: 0.060421328991651535
step: 720, loss: 0.061421480029821396
step: 730, loss: 0.01113962009549141
step: 740, loss: 0.01159757561981678
step: 750, loss: 0.024876482784748077
step: 760, loss: 0.026246439665555954
step: 770, loss: 0.03355177119374275
step: 780, loss: 0.19727720320224762
step: 790, loss: 0.03774136304855347
step: 800, loss: 2.7066445909440517e-05
step: 810, loss: 0.04063268005847931
step: 820, loss: 0.1167055144906044
step: 830, loss: 0.25454291701316833
step: 840, loss: 0.0351259745657444
step: 850, loss: 0.012663943693041801
step: 860, loss: 0.10922154039144516
step: 870, loss: 0.09623485058546066
step: 880, loss: 0.020953377708792686
step: 890, loss: 0.03254257142543793
step: 900, loss: 0.058187831193208694
step: 910, loss: 0.03976799175143242
step: 920, loss: 0.03998188301920891
step: 930, loss: 0.030047914013266563
step: 940, loss: 0.03714665398001671
step: 950, loss: 0.0016722176223993301
step: 960, loss: 0.01767083629965782
step: 970, loss: 0.04656378924846649
step: 980, loss: 0.009780828841030598
step: 990, loss: 0.041249409317970276
step: 1000, loss: 0.010756739415228367
step: 1010, loss: 0.1127641499042511
step: 1020, loss: 0.017245929688215256
step: 1030, loss: 0.018926354125142097
step: 1040, loss: 0.018084000796079636
step: 1050, loss: 0.01880238763988018
step: 1060, loss: 0.07456696778535843
step: 1070, loss: 0.056716326624155045
epoch 13: dev_f1=0.9311475409836065, f1=0.9299065420560748, best_f1=0.9351251158480075
step: 0, loss: 0.010624390095472336
step: 10, loss: 0.0029548443853855133
step: 20, loss: 0.05791527405381203
step: 30, loss: 0.08402299135923386
step: 40, loss: 0.1642661988735199
step: 50, loss: 0.0011439590016379952
step: 60, loss: 0.0012870634673163295
step: 70, loss: 0.03712340071797371
step: 80, loss: 0.022000068798661232
step: 90, loss: 0.025861427187919617
step: 100, loss: 0.06079921871423721
step: 110, loss: 0.0008196509443223476
step: 120, loss: 0.049791108816862106
step: 130, loss: 0.02616221457719803
step: 140, loss: 0.019414937123656273
step: 150, loss: 0.02815113216638565
step: 160, loss: 0.048923835158348083
step: 170, loss: 0.07308119535446167
step: 180, loss: 0.08809545636177063
step: 190, loss: 0.03967614471912384
step: 200, loss: 0.03692440688610077
step: 210, loss: 0.02158544212579727
step: 220, loss: 0.08939913660287857
step: 230, loss: 0.06788668781518936
step: 240, loss: 0.21037450432777405
step: 250, loss: 0.05476267635822296
step: 260, loss: 0.055469922721385956
step: 270, loss: 0.008314973674714565
step: 280, loss: 0.10507487505674362
step: 290, loss: 0.03166726976633072
step: 300, loss: 0.031276535242795944
step: 310, loss: 0.02977464348077774
step: 320, loss: 0.0322955884039402
step: 330, loss: 0.05684349313378334
step: 340, loss: 0.06436822563409805
step: 350, loss: 0.036016471683979034
step: 360, loss: 0.0033831149339675903
step: 370, loss: 0.04673442617058754
step: 380, loss: 0.04622256010770798
step: 390, loss: 0.03922506421804428
step: 400, loss: 0.034253522753715515
step: 410, loss: 0.06180603429675102
step: 420, loss: 0.08267403393983841
step: 430, loss: 0.013301247730851173
step: 440, loss: 0.0203084759414196
step: 450, loss: 0.024760814383625984
step: 460, loss: 0.09912484884262085
step: 470, loss: 0.058400508016347885
step: 480, loss: 0.00014705274952575564
step: 490, loss: 0.009033429436385632
step: 500, loss: 8.296141459140927e-05
step: 510, loss: 0.026673920452594757
step: 520, loss: 0.0008362146909348667
step: 530, loss: 7.965163968037814e-05
step: 540, loss: 0.043639712035655975
step: 550, loss: 0.13925504684448242
step: 560, loss: 0.03558642044663429
step: 570, loss: 0.02559533715248108
step: 580, loss: 0.027609478682279587
step: 590, loss: 0.003474255558103323
step: 600, loss: 0.028367826715111732
step: 610, loss: 0.028493912890553474
step: 620, loss: 0.00013851004769094288
step: 630, loss: 0.02794814482331276
step: 640, loss: 0.00013406506332103163
step: 650, loss: 0.02569742687046528
step: 660, loss: 0.020560981705784798
step: 670, loss: 0.0194303710013628
step: 680, loss: 0.057323478162288666
step: 690, loss: 0.03968137875199318
step: 700, loss: 0.024503599852323532
step: 710, loss: 0.03414516896009445
step: 720, loss: 0.005360642913728952
step: 730, loss: 0.00025277669192291796
step: 740, loss: 0.003262121696025133
step: 750, loss: 0.002774965250864625
step: 760, loss: 4.6829831262584776e-05
step: 770, loss: 0.0909593477845192
step: 780, loss: 0.05867316201329231
step: 790, loss: 0.012494035065174103
step: 800, loss: 0.05761583894491196
step: 810, loss: 0.035452693700790405
step: 820, loss: 0.00045002324623055756
step: 830, loss: 0.005432615987956524
step: 840, loss: 0.002024497138336301
step: 850, loss: 0.0007882374920882285
step: 860, loss: 0.002017943188548088
step: 870, loss: 0.00013825821224600077
step: 880, loss: 0.01328582875430584
step: 890, loss: 0.02403191849589348
step: 900, loss: 0.00027390080504119396
step: 910, loss: 0.044926196336746216
step: 920, loss: 0.05072065442800522
step: 930, loss: 0.012979469262063503
step: 940, loss: 0.12929312884807587
step: 950, loss: 0.010013402439653873
step: 960, loss: 0.06567433476448059
step: 970, loss: 0.08696947991847992
step: 980, loss: 0.00019367549975868315
step: 990, loss: 0.018993433564901352
step: 1000, loss: 0.022880919277668
step: 1010, loss: 0.021686866879463196
step: 1020, loss: 0.046853724867105484
step: 1030, loss: 0.021644296124577522
step: 1040, loss: 0.03452631086111069
step: 1050, loss: 0.016586141660809517
step: 1060, loss: 0.15046195685863495
step: 1070, loss: 0.003979898989200592
epoch 14: dev_f1=0.9343410486537552, f1=0.9271274094969439, best_f1=0.9351251158480075
step: 0, loss: 0.028132468461990356
step: 10, loss: 0.08241613209247589
step: 20, loss: 0.016600918024778366
step: 30, loss: 0.018152078613638878
step: 40, loss: 0.03336005285382271
step: 50, loss: 2.6425597752677277e-05
step: 60, loss: 0.019633421674370766
step: 70, loss: 0.04954947158694267
step: 80, loss: 0.0011512706987559795
step: 90, loss: 0.024752605706453323
step: 100, loss: 0.023842860013246536
step: 110, loss: 0.0002427442086627707
step: 120, loss: 0.008725526742637157
step: 130, loss: 1.2595099178724922e-05
step: 140, loss: 0.03109661675989628
step: 150, loss: 0.025382250547409058
step: 160, loss: 0.014363577589392662
step: 170, loss: 0.0005129499477334321
step: 180, loss: 0.001363032148219645
step: 190, loss: 0.005927148275077343
step: 200, loss: 0.05195736140012741
step: 210, loss: 0.058935150504112244
step: 220, loss: 0.0525377131998539
step: 230, loss: 0.02592666633427143
step: 240, loss: 0.04832318052649498
step: 250, loss: 0.2004816234111786
step: 260, loss: 0.029175937175750732
step: 270, loss: 1.1455193998699542e-05
step: 280, loss: 0.019902853295207024
step: 290, loss: 0.03810019791126251
step: 300, loss: 0.018170181661844254
step: 310, loss: 0.021615849807858467
step: 320, loss: 0.07441520690917969
step: 330, loss: 0.021656086668372154
step: 340, loss: 0.03637414425611496
step: 350, loss: 0.0003691383171826601
step: 360, loss: 0.07248986512422562
step: 370, loss: 0.038118261843919754
step: 380, loss: 0.05870816111564636
step: 390, loss: 0.0553312785923481
step: 400, loss: 0.0006223098607733846
step: 410, loss: 0.07080329954624176
step: 420, loss: 0.07056030631065369
step: 430, loss: 2.796776607283391e-05
step: 440, loss: 1.8603450371301733e-05
step: 450, loss: 0.058880217373371124
step: 460, loss: 0.09049411118030548
step: 470, loss: 0.047620270401239395
step: 480, loss: 0.05258616805076599
step: 490, loss: 0.07415910810232162
step: 500, loss: 0.02586233615875244
step: 510, loss: 3.6517580156214535e-05
step: 520, loss: 0.001515722367912531
step: 530, loss: 0.06563941389322281
step: 540, loss: 0.035401713103055954
step: 550, loss: 0.025334125384688377
step: 560, loss: 0.06853503733873367
step: 570, loss: 0.022685181349515915
step: 580, loss: 0.01846112310886383
step: 590, loss: 0.027042405679821968
step: 600, loss: 0.07726076245307922
step: 610, loss: 0.03787454217672348
step: 620, loss: 0.04133829474449158
step: 630, loss: 0.04595116525888443
step: 640, loss: 0.020956212654709816
step: 650, loss: 3.276098141213879e-05
step: 660, loss: 0.0003620669012889266
step: 670, loss: 0.09128547459840775
step: 680, loss: 0.025439342483878136
step: 690, loss: 0.01765434257686138
step: 700, loss: 0.006185137201100588
step: 710, loss: 0.01941860467195511
step: 720, loss: 0.026053017005324364
step: 730, loss: 0.02043890208005905
step: 740, loss: 0.0013938667252659798
step: 750, loss: 0.06496509909629822
step: 760, loss: 0.03805478662252426
step: 770, loss: 0.16277869045734406
step: 780, loss: 0.00025149472639895976
step: 790, loss: 3.813104922301136e-05
step: 800, loss: 0.050655584782361984
step: 810, loss: 0.05025559291243553
step: 820, loss: 0.033416375517845154
step: 830, loss: 0.014595944434404373
step: 840, loss: 0.1304190754890442
step: 850, loss: 0.001394377090036869
step: 860, loss: 0.018498973920941353
step: 870, loss: 0.052965905517339706
step: 880, loss: 0.04782116413116455
step: 890, loss: 0.051039256155490875
step: 900, loss: 0.07561345398426056
step: 910, loss: 0.019719308242201805
step: 920, loss: 0.02324485406279564
step: 930, loss: 0.032465968281030655
step: 940, loss: 0.025583770126104355
step: 950, loss: 0.008122092112898827
step: 960, loss: 0.10420999675989151
step: 970, loss: 0.038704343140125275
step: 980, loss: 0.06824830174446106
step: 990, loss: 0.01651645079255104
step: 1000, loss: 5.433158730738796e-05
step: 1010, loss: 0.01418513897806406
step: 1020, loss: 0.028088338673114777
step: 1030, loss: 0.07562454789876938
step: 1040, loss: 0.00020874320762231946
step: 1050, loss: 0.023071322590112686
step: 1060, loss: 0.02930591069161892
step: 1070, loss: 0.020395642146468163
epoch 15: dev_f1=0.9363086936308694, f1=0.9341923607915326, best_f1=0.9351251158480075
step: 0, loss: 0.006903581786900759
step: 10, loss: 0.023275837302207947
step: 20, loss: 0.005327931139618158
step: 30, loss: 0.01609642244875431
step: 40, loss: 0.03354908525943756
step: 50, loss: 8.983158477349207e-05
step: 60, loss: 0.03323162719607353
step: 70, loss: 0.03259570524096489
step: 80, loss: 0.0026312933769077063
step: 90, loss: 1.4051483049115632e-05
step: 100, loss: 2.3627948394278064e-05
step: 110, loss: 0.12783800065517426
step: 120, loss: 0.04354846104979515
step: 130, loss: 0.033386122435331345
step: 140, loss: 0.04942350462079048
step: 150, loss: 0.029350632801651955
step: 160, loss: 0.02744479663670063
step: 170, loss: 0.020688559859991074
step: 180, loss: 0.011647947132587433
step: 190, loss: 0.01664930395781994
step: 200, loss: 0.0002906056761275977
step: 210, loss: 0.01740884967148304
step: 220, loss: 0.00012321723625063896
step: 230, loss: 0.03807460516691208
step: 240, loss: 0.02574990689754486
step: 250, loss: 0.021643275395035744
step: 260, loss: 0.016767213121056557
step: 270, loss: 0.006555693224072456
step: 280, loss: 6.471751112258062e-05
step: 290, loss: 0.010626343078911304
step: 300, loss: 0.005098122172057629
step: 310, loss: 0.03791854530572891
step: 320, loss: 0.04796573892235756
step: 330, loss: 0.011510481126606464
step: 340, loss: 0.05461586266756058
step: 350, loss: 2.014937490457669e-05
step: 360, loss: 0.046939101070165634
step: 370, loss: 8.87093847268261e-05
step: 380, loss: 0.03277505561709404
step: 390, loss: 0.00020038180809933692
step: 400, loss: 0.1117401123046875
step: 410, loss: 0.06618707627058029
step: 420, loss: 0.00012998355668969452
step: 430, loss: 0.06852865219116211
step: 440, loss: 2.2216272554942407e-05
step: 450, loss: 0.027819832786917686
step: 460, loss: 0.030891641974449158
step: 470, loss: 0.05573059618473053
step: 480, loss: 0.0357791967689991
step: 490, loss: 0.0023256316781044006
step: 500, loss: 0.037461113184690475
step: 510, loss: 0.08022283017635345
step: 520, loss: 0.023537836968898773
step: 530, loss: 0.04764352738857269
step: 540, loss: 0.023280730471014977
step: 550, loss: 0.02438710257411003
step: 560, loss: 0.02920588292181492
step: 570, loss: 0.016654202714562416
step: 580, loss: 0.055940285325050354
step: 590, loss: 2.7132487957715057e-05
step: 600, loss: 0.040893979370594025
step: 610, loss: 0.07639246433973312
step: 620, loss: 6.445021426770836e-05
step: 630, loss: 0.016283372417092323
step: 640, loss: 0.07555299997329712
step: 650, loss: 0.02037506178021431
step: 660, loss: 0.0032746712677180767
step: 670, loss: 0.01988309808075428
step: 680, loss: 0.053254544734954834
step: 690, loss: 0.15975421667099
step: 700, loss: 4.951915980200283e-05
step: 710, loss: 0.0003731046454049647
step: 720, loss: 0.033644624054431915
step: 730, loss: 0.00011094594083260745
step: 740, loss: 0.009039677679538727
step: 750, loss: 0.03771043196320534
step: 760, loss: 0.026260852813720703
step: 770, loss: 0.023835834115743637
step: 780, loss: 0.017979763448238373
step: 790, loss: 0.036514315754175186
step: 800, loss: 0.019707858562469482
step: 810, loss: 0.020495688542723656
step: 820, loss: 0.1071416363120079
step: 830, loss: 0.017466029152274132
step: 840, loss: 0.03302812948822975
step: 850, loss: 0.020303236320614815
step: 860, loss: 0.008278926834464073
step: 870, loss: 1.750835872371681e-05
step: 880, loss: 0.047092992812395096
step: 890, loss: 0.044107042253017426
step: 900, loss: 0.06713637709617615
step: 910, loss: 0.06069953367114067
step: 920, loss: 0.0001743561588227749
step: 930, loss: 0.011431664228439331
step: 940, loss: 0.09278761595487595
step: 950, loss: 6.617415056098253e-05
step: 960, loss: 0.04981694743037224
step: 970, loss: 0.09057344496250153
step: 980, loss: 0.023773662745952606
step: 990, loss: 1.4885832570143975e-05
step: 1000, loss: 0.019788874313235283
step: 1010, loss: 0.07793086022138596
step: 1020, loss: 0.04353341460227966
step: 1030, loss: 0.04081518203020096
step: 1040, loss: 0.027918577194213867
step: 1050, loss: 0.01774020865559578
step: 1060, loss: 2.5170273147523403e-05
step: 1070, loss: 0.05446167662739754
epoch 16: dev_f1=0.9350411710887466, f1=0.9258079198907602, best_f1=0.9351251158480075
step: 0, loss: 0.012230856344103813
step: 10, loss: 0.014226588420569897
step: 20, loss: 0.03360521420836449
step: 30, loss: 0.020837627351284027
step: 40, loss: 0.0026018426287919283
step: 50, loss: 0.02293427288532257
step: 60, loss: 0.05995119735598564
step: 70, loss: 0.026312313973903656
step: 80, loss: 0.035580750554800034
step: 90, loss: 0.016069358214735985
step: 100, loss: 0.033349670469760895
step: 110, loss: 0.12204090505838394
step: 120, loss: 0.030291665345430374
step: 130, loss: 0.04415605589747429
step: 140, loss: 0.0013319958234205842
step: 150, loss: 0.016093825921416283
step: 160, loss: 0.06485123187303543
step: 170, loss: 0.0015129940584301949
step: 180, loss: 0.04736144095659256
step: 190, loss: 0.019304830580949783
step: 200, loss: 0.023613402619957924
step: 210, loss: 7.344005280174315e-05
step: 220, loss: 8.744620572542772e-05
step: 230, loss: 0.001171137671917677
step: 240, loss: 0.04026014730334282
step: 250, loss: 0.07486189901828766
step: 260, loss: 0.012143624946475029
step: 270, loss: 0.02253299579024315
step: 280, loss: 8.833534957375377e-05
step: 290, loss: 0.022565552964806557
step: 300, loss: 0.019034534692764282
step: 310, loss: 0.025192763656377792
step: 320, loss: 0.05881791561841965
step: 330, loss: 2.7158650482306257e-05
step: 340, loss: 0.033231254667043686
step: 350, loss: 0.05465655401349068
step: 360, loss: 0.05958288908004761
step: 370, loss: 3.296871727798134e-05
step: 380, loss: 1.1205565897398628e-05
step: 390, loss: 0.07395075261592865
step: 400, loss: 0.04009757936000824
step: 410, loss: 0.018594445660710335
step: 420, loss: 0.00039017238304950297
step: 430, loss: 0.03368252143263817
step: 440, loss: 0.012643864378333092
step: 450, loss: 9.755127393873408e-05
step: 460, loss: 0.020275913178920746
step: 470, loss: 0.03043612465262413
step: 480, loss: 4.0535836888011545e-05
step: 490, loss: 0.01199096255004406
step: 500, loss: 0.03356378152966499
step: 510, loss: 0.01902250200510025
step: 520, loss: 0.03284890204668045
step: 530, loss: 0.022294098511338234
step: 540, loss: 0.10111913830041885
step: 550, loss: 8.473818888887763e-05
step: 560, loss: 9.419913112651557e-05
step: 570, loss: 0.025854643434286118
step: 580, loss: 0.04822227731347084
step: 590, loss: 0.025683794170618057
step: 600, loss: 0.005350000225007534
step: 610, loss: 0.000719801289960742
step: 620, loss: 0.042495664209127426
step: 630, loss: 2.5381847081007436e-05
step: 640, loss: 5.362066804082133e-05
step: 650, loss: 0.027013607323169708
step: 660, loss: 0.000329084403347224
step: 670, loss: 0.0020101473201066256
step: 680, loss: 1.3012294402869884e-05
step: 690, loss: 2.4440170818706974e-05
step: 700, loss: 0.053619373589754105
step: 710, loss: 0.01439659483730793
step: 720, loss: 0.027873635292053223
step: 730, loss: 0.0005216973950155079
step: 740, loss: 0.01406083907932043
step: 750, loss: 0.038509782403707504
step: 760, loss: 1.7008744180202484e-05
step: 770, loss: 1.3157219655113295e-05
step: 780, loss: 0.022127879783511162
step: 790, loss: 0.02427314594388008
step: 800, loss: 0.030248908326029778
step: 810, loss: 0.022279556840658188
step: 820, loss: 0.06450775265693665
step: 830, loss: 0.00026067104772664607
step: 840, loss: 0.03139761835336685
step: 850, loss: 0.0019781081937253475
step: 860, loss: 0.0005328761180862784
step: 870, loss: 0.08053302764892578
step: 880, loss: 0.01009841077029705
step: 890, loss: 0.02405145764350891
step: 900, loss: 0.0021119886077940464
step: 910, loss: 0.0336393266916275
step: 920, loss: 2.0030282030347735e-05
step: 930, loss: 0.03350095823407173
step: 940, loss: 0.04912523180246353
step: 950, loss: 0.08947773277759552
step: 960, loss: 0.0427955761551857
step: 970, loss: 0.022740349173545837
step: 980, loss: 0.04875697195529938
step: 990, loss: 0.0001759491569828242
step: 1000, loss: 0.05591266229748726
step: 1010, loss: 0.07527931779623032
step: 1020, loss: 0.0064142439514398575
step: 1030, loss: 0.00010493334411876276
step: 1040, loss: 0.07251393049955368
step: 1050, loss: 0.030626028776168823
step: 1060, loss: 0.017132246866822243
step: 1070, loss: 0.06394759565591812
epoch 17: dev_f1=0.9355294117647059, f1=0.9264432029795159, best_f1=0.9351251158480075
step: 0, loss: 0.04951039329171181
step: 10, loss: 0.01928311213850975
step: 20, loss: 0.022661924362182617
step: 30, loss: 0.01599140837788582
step: 40, loss: 0.01945214904844761
step: 50, loss: 4.6507862862199545e-05
step: 60, loss: 0.0255732499063015
step: 70, loss: 0.022866951301693916
step: 80, loss: 0.0653749629855156
step: 90, loss: 0.0007718570996075869
step: 100, loss: 0.03520617634057999
step: 110, loss: 0.0010181836551055312
step: 120, loss: 0.018522806465625763
step: 130, loss: 0.0402136892080307
step: 140, loss: 0.06448569893836975
step: 150, loss: 0.04458607733249664
step: 160, loss: 0.05765640735626221
step: 170, loss: 0.045050229877233505
step: 180, loss: 0.030317317694425583
step: 190, loss: 9.196162864100188e-05
step: 200, loss: 0.023378657177090645
step: 210, loss: 0.02444770187139511
step: 220, loss: 1.4595428183383774e-05
step: 230, loss: 0.0013035750016570091
step: 240, loss: 0.0003297555085737258
step: 250, loss: 0.016655512154102325
step: 260, loss: 1.584316123626195e-05
step: 270, loss: 0.005638052709400654
step: 280, loss: 0.030071912333369255
step: 290, loss: 8.311699639307335e-05
step: 300, loss: 0.019762994721531868
step: 310, loss: 0.04327404871582985
step: 320, loss: 9.837310062721372e-05
step: 330, loss: 0.059639833867549896
step: 340, loss: 2.0260762539692223e-05
step: 350, loss: 0.019406653940677643
step: 360, loss: 0.09564705193042755
step: 370, loss: 0.019806647673249245
step: 380, loss: 0.05676541104912758
step: 390, loss: 0.01805167831480503
step: 400, loss: 9.403307194588706e-05
step: 410, loss: 0.04676048830151558
step: 420, loss: 0.05464504286646843
step: 430, loss: 0.04166553542017937
step: 440, loss: 2.5809024009504355e-05
step: 450, loss: 6.28105626674369e-05
step: 460, loss: 5.945024167886004e-05
step: 470, loss: 0.0005343373049981892
step: 480, loss: 8.965929737314582e-05
step: 490, loss: 0.031087461858987808
step: 500, loss: 0.06314385682344437
step: 510, loss: 1.2915359548060223e-05
step: 520, loss: 0.0042281849309802055
step: 530, loss: 1.7117288734880276e-05
step: 540, loss: 0.07017328590154648
step: 550, loss: 0.01741499826312065
step: 560, loss: 0.014699454419314861
step: 570, loss: 1.6055726518970914e-05
step: 580, loss: 1.4114734767645132e-05
step: 590, loss: 5.423841503215954e-05
step: 600, loss: 0.06611932814121246
step: 610, loss: 0.023994997143745422
step: 620, loss: 0.021226953715085983
step: 630, loss: 1.2412481737555936e-05
step: 640, loss: 0.0114842988550663
step: 650, loss: 0.05881603807210922
step: 660, loss: 0.006611957214772701
step: 670, loss: 0.024677181616425514
step: 680, loss: 0.043119750916957855
step: 690, loss: 0.01799139566719532
step: 700, loss: 0.00011820517829619348
step: 710, loss: 0.009157951921224594
step: 720, loss: 0.0134007902815938
step: 730, loss: 0.07186008989810944
step: 740, loss: 2.0149289412074722e-05
step: 750, loss: 2.3914106350275688e-05
step: 760, loss: 0.04437883198261261
step: 770, loss: 0.020541546866297722
step: 780, loss: 0.05748140811920166
step: 790, loss: 0.05803360417485237
step: 800, loss: 0.015074029564857483
step: 810, loss: 0.040419433265924454
step: 820, loss: 0.038193151354789734
step: 830, loss: 0.014726975932717323
step: 840, loss: 0.017644505947828293
step: 850, loss: 0.030430682003498077
step: 860, loss: 0.024972958490252495
step: 870, loss: 2.33480786846485e-05
step: 880, loss: 0.03961975499987602
step: 890, loss: 0.02914317138493061
step: 900, loss: 0.04925208166241646
step: 910, loss: 0.025418657809495926
step: 920, loss: 0.10445915907621384
step: 930, loss: 0.046612698584795
step: 940, loss: 0.04721006378531456
step: 950, loss: 0.00016190813039429486
step: 960, loss: 5.249755849945359e-05
step: 970, loss: 0.024283595383167267
step: 980, loss: 0.019124014303088188
step: 990, loss: 0.019335517659783363
step: 1000, loss: 0.016038432717323303
step: 1010, loss: 0.04039483889937401
step: 1020, loss: 0.04629078879952431
step: 1030, loss: 0.05572688579559326
step: 1040, loss: 0.05393637344241142
step: 1050, loss: 0.05125533416867256
step: 1060, loss: 1.2501920537033584e-05
step: 1070, loss: 0.000859717489220202
epoch 18: dev_f1=0.93202062822316, f1=0.9266480965645311, best_f1=0.9351251158480075
step: 0, loss: 1.1548175280040596e-05
step: 10, loss: 0.050353020429611206
step: 20, loss: 1.8104348782799207e-05
step: 30, loss: 0.04655078426003456
step: 40, loss: 0.020271901041269302
step: 50, loss: 0.025741523131728172
step: 60, loss: 2.1743337129009888e-05
step: 70, loss: 0.05665102228522301
step: 80, loss: 0.06294422596693039
step: 90, loss: 0.0720275491476059
step: 100, loss: 0.03238404542207718
step: 110, loss: 1.7429654690204188e-05
step: 120, loss: 1.2334299754002132e-05
step: 130, loss: 2.2521706341649406e-05
step: 140, loss: 0.017881043255329132
step: 150, loss: 0.033611588180065155
step: 160, loss: 1.3869014765077736e-05
step: 170, loss: 0.10301212966442108
step: 180, loss: 0.05719318613409996
step: 190, loss: 0.02098059467971325
step: 200, loss: 0.021092761307954788
step: 210, loss: 0.03199068084359169
step: 220, loss: 0.041068028658628464
step: 230, loss: 0.09016440808773041
step: 240, loss: 0.10216283053159714
step: 250, loss: 0.022535787895321846
step: 260, loss: 0.020944703370332718
step: 270, loss: 0.028757242485880852
step: 280, loss: 0.025866029784083366
step: 290, loss: 6.236603803699836e-05
step: 300, loss: 0.02299954742193222
step: 310, loss: 2.6528696253080852e-05
step: 320, loss: 0.039057161659002304
step: 330, loss: 0.015279887244105339
step: 340, loss: 3.869707143167034e-05
step: 350, loss: 0.023782318457961082
step: 360, loss: 0.048234015703201294
step: 370, loss: 0.047656890004873276
step: 380, loss: 0.013221551664173603
step: 390, loss: 0.08102826774120331
step: 400, loss: 0.0122078787535429
step: 410, loss: 0.04669016972184181
step: 420, loss: 8.24241287773475e-05
step: 430, loss: 0.01186597254127264
step: 440, loss: 0.016797835007309914
step: 450, loss: 0.07511912286281586
step: 460, loss: 0.010373705066740513
step: 470, loss: 0.05997258797287941
step: 480, loss: 0.020582055673003197
step: 490, loss: 0.04755494371056557
step: 500, loss: 0.02340548299252987
step: 510, loss: 0.021833136677742004
step: 520, loss: 0.0496695376932621
step: 530, loss: 0.0011817325139418244
step: 540, loss: 0.04335101321339607
step: 550, loss: 0.06342530250549316
step: 560, loss: 1.9162160242558457e-05
step: 570, loss: 1.42341423270409e-05
step: 580, loss: 0.09643103927373886
step: 590, loss: 0.0014368341071531177
step: 600, loss: 4.349568553152494e-05
step: 610, loss: 0.035691872239112854
step: 620, loss: 0.05962487682700157
step: 630, loss: 0.022317174822092056
step: 640, loss: 0.038143716752529144
step: 650, loss: 0.0026919629890471697
step: 660, loss: 0.020185302942991257
step: 670, loss: 0.026747575029730797
step: 680, loss: 0.004300866741687059
step: 690, loss: 0.03257930278778076
step: 700, loss: 0.02131332829594612
step: 710, loss: 0.05875338986515999
step: 720, loss: 0.01772955060005188
step: 730, loss: 0.017028609290719032
step: 740, loss: 0.014037922956049442
step: 750, loss: 0.06216656416654587
step: 760, loss: 0.0001913317828439176
step: 770, loss: 0.024350754916667938
step: 780, loss: 0.024002082645893097
step: 790, loss: 0.017108077183365822
step: 800, loss: 2.1693826056434773e-05
step: 810, loss: 0.00764541607350111
step: 820, loss: 0.1066465824842453
step: 830, loss: 1.5370222172350623e-05
step: 840, loss: 0.02193775400519371
step: 850, loss: 0.00016783844330348074
step: 860, loss: 0.04286092892289162
step: 870, loss: 0.006236085668206215
step: 880, loss: 0.07849346846342087
step: 890, loss: 0.07042992860078812
step: 900, loss: 0.08070497959852219
step: 910, loss: 0.04700126126408577
step: 920, loss: 0.0011563064763322473
step: 930, loss: 0.030002545565366745
step: 940, loss: 0.019926436245441437
step: 950, loss: 0.04682483896613121
step: 960, loss: 0.028635263442993164
step: 970, loss: 0.01575503870844841
step: 980, loss: 0.023641599342226982
step: 990, loss: 0.0014730130787938833
step: 1000, loss: 0.0008009242010302842
step: 1010, loss: 3.177754842909053e-05
step: 1020, loss: 0.06303049623966217
step: 1030, loss: 0.01841055229306221
step: 1040, loss: 0.01868322864174843
step: 1050, loss: 0.000145232945214957
step: 1060, loss: 0.02108936198055744
step: 1070, loss: 0.026178352534770966
epoch 19: dev_f1=0.9330819981149858, f1=0.926829268292683, best_f1=0.9351251158480075
step: 0, loss: 2.395399314991664e-05
step: 10, loss: 0.015597069635987282
step: 20, loss: 0.017213186249136925
step: 30, loss: 0.010030996054410934
step: 40, loss: 0.02286313660442829
step: 50, loss: 0.015919383615255356
step: 60, loss: 0.019205495715141296
step: 70, loss: 0.021323582157492638
step: 80, loss: 0.02572275698184967
step: 90, loss: 0.013239271938800812
step: 100, loss: 0.03342181444168091
step: 110, loss: 0.03148902580142021
step: 120, loss: 0.08404937386512756
step: 130, loss: 0.0028156249318271875
step: 140, loss: 0.04122990369796753
step: 150, loss: 0.02580668404698372
step: 160, loss: 0.09844356030225754
step: 170, loss: 0.023699428886175156
step: 180, loss: 0.009919035248458385
step: 190, loss: 1.4904637282597832e-05
step: 200, loss: 0.024604473263025284
step: 210, loss: 1.128006806538906e-05
step: 220, loss: 2.3545671865576878e-05
step: 230, loss: 0.018312672153115273
step: 240, loss: 0.026920322328805923
step: 250, loss: 0.03563989698886871
step: 260, loss: 0.06400597840547562
step: 270, loss: 0.04285198450088501
step: 280, loss: 0.021013274788856506
step: 290, loss: 0.0035443452652543783
step: 300, loss: 0.016424549743533134
step: 310, loss: 0.0002379364159423858
step: 320, loss: 0.00028052605921402574
step: 330, loss: 0.10751689225435257
step: 340, loss: 2.9729571906500496e-05
step: 350, loss: 0.044034913182258606
step: 360, loss: 2.262633825012017e-05
step: 370, loss: 1.3612057955469936e-05
step: 380, loss: 0.00806173775345087
step: 390, loss: 1.0862850103876553e-05
step: 400, loss: 0.04432404413819313
step: 410, loss: 1.8513861505198292e-05
step: 420, loss: 0.00018332120089326054
step: 430, loss: 0.01673424430191517
step: 440, loss: 2.1475041648955084e-05
step: 450, loss: 4.407389133120887e-05
step: 460, loss: 0.04240091145038605
step: 470, loss: 0.032050721347332
step: 480, loss: 0.022193100303411484
step: 490, loss: 0.061134494841098785
step: 500, loss: 0.02124907821416855
step: 510, loss: 3.847963307634927e-05
step: 520, loss: 2.0291166947572492e-05
step: 530, loss: 0.017451465129852295
step: 540, loss: 2.6607754989527166e-05
step: 550, loss: 0.05190263316035271
step: 560, loss: 0.041488148272037506
step: 570, loss: 0.02272968739271164
step: 580, loss: 1.3932410183770116e-05
step: 590, loss: 5.368339770939201e-05
step: 600, loss: 0.0670468732714653
step: 610, loss: 0.060494765639305115
step: 620, loss: 2.4429951736237854e-05
step: 630, loss: 0.002519513014703989
step: 640, loss: 0.03720565140247345
step: 650, loss: 0.05411503463983536
step: 660, loss: 0.0038438676856458187
step: 670, loss: 0.00039049508632160723
step: 680, loss: 0.02404153160750866
step: 690, loss: 1.1619075849012006e-05
step: 700, loss: 1.7929447494680062e-05
step: 710, loss: 0.025069572031497955
step: 720, loss: 6.622500222874805e-05
step: 730, loss: 0.027200942859053612
step: 740, loss: 0.045292388647794724
step: 750, loss: 0.02190539613366127
step: 760, loss: 1.5113158951862715e-05
step: 770, loss: 0.02906080335378647
step: 780, loss: 0.01605401188135147
step: 790, loss: 0.019149433821439743
step: 800, loss: 0.0012244575191289186
step: 810, loss: 0.0328047014772892
step: 820, loss: 0.0015034994576126337
step: 830, loss: 0.030173474922776222
step: 840, loss: 0.023572804406285286
step: 850, loss: 3.2859021303011104e-05
step: 860, loss: 0.00778540875762701
step: 870, loss: 0.020231425762176514
step: 880, loss: 0.11542186886072159
step: 890, loss: 8.769277883402538e-06
step: 900, loss: 0.041910067200660706
step: 910, loss: 0.018486853688955307
step: 920, loss: 0.00011641084711300209
step: 930, loss: 0.059763651341199875
step: 940, loss: 0.03593975678086281
step: 950, loss: 0.02796184830367565
step: 960, loss: 0.03161969780921936
step: 970, loss: 0.02363748848438263
step: 980, loss: 1.896100366138853e-05
step: 990, loss: 0.06911704689264297
step: 1000, loss: 0.024541623890399933
step: 1010, loss: 0.05829745531082153
step: 1020, loss: 1.697194602456875e-05
step: 1030, loss: 0.036100275814533234
step: 1040, loss: 0.01973591186106205
step: 1050, loss: 0.05294763669371605
step: 1060, loss: 0.08344180881977081
step: 1070, loss: 2.1553769329329953e-05
epoch 20: dev_f1=0.933083762283575, f1=0.9272137227630968, best_f1=0.9351251158480075
