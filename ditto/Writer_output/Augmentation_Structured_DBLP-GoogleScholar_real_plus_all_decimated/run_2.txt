cuda
Device: cuda
step: 0, loss: 0.6758318543434143
step: 10, loss: 0.41150686144828796
step: 20, loss: 0.47317296266555786
step: 30, loss: 0.3582739531993866
step: 40, loss: 0.10786914080381393
step: 50, loss: 0.10441850870847702
step: 60, loss: 0.2805268466472626
step: 70, loss: 0.16380928456783295
step: 80, loss: 0.3250594437122345
step: 90, loss: 0.18361788988113403
step: 100, loss: 0.34300315380096436
step: 110, loss: 0.14574885368347168
step: 120, loss: 0.43295109272003174
step: 130, loss: 0.25463613867759705
step: 140, loss: 0.16456864774227142
step: 150, loss: 0.287553608417511
step: 160, loss: 0.18535195291042328
step: 170, loss: 0.15317679941654205
step: 180, loss: 0.186173215508461
step: 190, loss: 0.2141989767551422
step: 200, loss: 0.02356453239917755
step: 210, loss: 0.034689683467149734
step: 220, loss: 0.2699693441390991
step: 230, loss: 0.05091357231140137
step: 240, loss: 0.16476167738437653
step: 250, loss: 0.08150401711463928
step: 260, loss: 0.06208990886807442
step: 270, loss: 0.13697728514671326
step: 280, loss: 0.09902473539113998
step: 290, loss: 0.1962260603904724
step: 300, loss: 0.31619715690612793
step: 310, loss: 0.07192134112119675
step: 320, loss: 0.19147934019565582
step: 330, loss: 0.15198564529418945
step: 340, loss: 0.15674535930156708
step: 350, loss: 0.18343037366867065
step: 360, loss: 0.06331563740968704
step: 370, loss: 0.24868309497833252
step: 380, loss: 0.03106085956096649
step: 390, loss: 0.051192764192819595
step: 400, loss: 0.020771214738488197
step: 410, loss: 0.04035753384232521
step: 420, loss: 0.18282106518745422
step: 430, loss: 0.22209013998508453
step: 440, loss: 0.09177853912115097
step: 450, loss: 0.15410162508487701
step: 460, loss: 0.1043047085404396
step: 470, loss: 0.047078851610422134
step: 480, loss: 0.08208315074443817
step: 490, loss: 0.054781630635261536
step: 500, loss: 0.01691340282559395
step: 510, loss: 0.030585506930947304
step: 520, loss: 0.07151465862989426
step: 530, loss: 0.19926467537879944
step: 540, loss: 0.17893414199352264
step: 550, loss: 0.06754001975059509
step: 560, loss: 0.11242605000734329
step: 570, loss: 0.05490417033433914
step: 580, loss: 0.2114608883857727
step: 590, loss: 0.06013787165284157
step: 600, loss: 0.03349488601088524
step: 610, loss: 0.05067623779177666
step: 620, loss: 0.034380294382572174
step: 630, loss: 0.023279625922441483
step: 640, loss: 0.01095629297196865
step: 650, loss: 0.07026706635951996
step: 660, loss: 0.13651248812675476
step: 670, loss: 0.0320524163544178
step: 680, loss: 0.11429955065250397
step: 690, loss: 0.1521006077528
step: 700, loss: 0.0952707976102829
step: 710, loss: 0.09407726675271988
step: 720, loss: 0.09962201118469238
step: 730, loss: 0.10615897178649902
step: 740, loss: 0.07542368769645691
step: 750, loss: 0.036888137459754944
step: 760, loss: 0.00908120721578598
step: 770, loss: 0.06422257423400879
step: 780, loss: 0.0698314979672432
step: 790, loss: 0.023235782980918884
step: 800, loss: 0.1080620139837265
step: 810, loss: 0.0775618851184845
step: 820, loss: 0.039365254342556
step: 830, loss: 0.07160328328609467
step: 840, loss: 0.12695452570915222
step: 850, loss: 0.14554886519908905
step: 860, loss: 0.10082294791936874
step: 870, loss: 0.1918090581893921
step: 880, loss: 0.03240789845585823
step: 890, loss: 0.11117507517337799
step: 900, loss: 0.09947269409894943
step: 910, loss: 0.036066312342882156
step: 920, loss: 0.21996256709098816
step: 930, loss: 0.09515491873025894
step: 940, loss: 0.021097242832183838
step: 950, loss: 0.11341708153486252
step: 960, loss: 0.10095992684364319
step: 970, loss: 0.1352558583021164
step: 980, loss: 0.07822869718074799
step: 990, loss: 0.06137910857796669
step: 1000, loss: 0.1670815646648407
step: 1010, loss: 0.1932789385318756
step: 1020, loss: 0.13471472263336182
step: 1030, loss: 0.13249759376049042
step: 1040, loss: 0.09892915189266205
step: 1050, loss: 0.07904265075922012
step: 1060, loss: 0.10414845496416092
step: 1070, loss: 0.14662575721740723
epoch 1: dev_f1=0.9390581717451523, f1=0.9351127473538886, best_f1=0.9351127473538886
step: 0, loss: 0.025194847956299782
step: 10, loss: 0.38398176431655884
step: 20, loss: 0.06293118000030518
step: 30, loss: 0.06608786433935165
step: 40, loss: 0.2680168151855469
step: 50, loss: 0.07389649748802185
step: 60, loss: 0.07323357462882996
step: 70, loss: 0.01618112623691559
step: 80, loss: 0.049417417496442795
step: 90, loss: 0.08018740266561508
step: 100, loss: 0.14064644277095795
step: 110, loss: 0.1517869532108307
step: 120, loss: 0.022409386932849884
step: 130, loss: 0.22408796846866608
step: 140, loss: 0.07833299785852432
step: 150, loss: 0.19184169173240662
step: 160, loss: 0.03441901504993439
step: 170, loss: 0.02105972170829773
step: 180, loss: 0.044610586017370224
step: 190, loss: 0.03248355910181999
step: 200, loss: 0.09678065031766891
step: 210, loss: 0.05361688509583473
step: 220, loss: 0.07134820520877838
step: 230, loss: 0.06248544156551361
step: 240, loss: 0.11375388503074646
step: 250, loss: 0.06743291765451431
step: 260, loss: 0.12686479091644287
step: 270, loss: 0.1583642214536667
step: 280, loss: 0.017934275791049004
step: 290, loss: 0.043742306530475616
step: 300, loss: 0.12032961845397949
step: 310, loss: 0.03812193498015404
step: 320, loss: 0.11969926208257675
step: 330, loss: 0.017151549458503723
step: 340, loss: 0.13841545581817627
step: 350, loss: 0.11550834029912949
step: 360, loss: 0.1076807826757431
step: 370, loss: 0.129475399851799
step: 380, loss: 0.10990637540817261
step: 390, loss: 0.17906668782234192
step: 400, loss: 0.09834818542003632
step: 410, loss: 0.13191623985767365
step: 420, loss: 0.03615814447402954
step: 430, loss: 0.029732491821050644
step: 440, loss: 0.05672859027981758
step: 450, loss: 0.015800058841705322
step: 460, loss: 0.14349840581417084
step: 470, loss: 0.07080841809511185
step: 480, loss: 0.1431274116039276
step: 490, loss: 0.06430870294570923
step: 500, loss: 0.013890883885324001
step: 510, loss: 0.05908866226673126
step: 520, loss: 0.10298264771699905
step: 530, loss: 0.05228666216135025
step: 540, loss: 0.027017870917916298
step: 550, loss: 0.15937906503677368
step: 560, loss: 0.013575605116784573
step: 570, loss: 0.07039150595664978
step: 580, loss: 0.09864060580730438
step: 590, loss: 0.10380194336175919
step: 600, loss: 0.014351483434438705
step: 610, loss: 0.15501511096954346
step: 620, loss: 0.04056212678551674
step: 630, loss: 0.06778953969478607
step: 640, loss: 0.08668575435876846
step: 650, loss: 0.042048268020153046
step: 660, loss: 0.07256955653429031
step: 670, loss: 0.14481225609779358
step: 680, loss: 0.1314789205789566
step: 690, loss: 0.16565415263175964
step: 700, loss: 0.13849525153636932
step: 710, loss: 0.0226241834461689
step: 720, loss: 0.06674232333898544
step: 730, loss: 0.11464589834213257
step: 740, loss: 0.15725184977054596
step: 750, loss: 0.2926922142505646
step: 760, loss: 0.06132382154464722
step: 770, loss: 0.19232405722141266
step: 780, loss: 0.07393550127744675
step: 790, loss: 0.10744185000658035
step: 800, loss: 0.04409128427505493
step: 810, loss: 0.01930956356227398
step: 820, loss: 0.0396588072180748
step: 830, loss: 0.018519634380936623
step: 840, loss: 0.03330109640955925
step: 850, loss: 0.08584894239902496
step: 860, loss: 0.1682167798280716
step: 870, loss: 0.05007348582148552
step: 880, loss: 0.04805690795183182
step: 890, loss: 0.23537932336330414
step: 900, loss: 0.10042645782232285
step: 910, loss: 0.059104062616825104
step: 920, loss: 0.0641956627368927
step: 930, loss: 0.15017588436603546
step: 940, loss: 0.07716317474842072
step: 950, loss: 0.11061248183250427
step: 960, loss: 0.1022787019610405
step: 970, loss: 0.01352103054523468
step: 980, loss: 0.06688934564590454
step: 990, loss: 0.04579745605587959
step: 1000, loss: 0.0885668471455574
step: 1010, loss: 0.08264584094285965
step: 1020, loss: 0.06969813257455826
step: 1030, loss: 0.021622637286782265
step: 1040, loss: 0.013200866989791393
step: 1050, loss: 0.07276524603366852
step: 1060, loss: 0.048763811588287354
step: 1070, loss: 0.11215023696422577
epoch 2: dev_f1=0.9280373831775701, f1=0.9340196537201684, best_f1=0.9351127473538886
step: 0, loss: 0.06690359860658646
step: 10, loss: 0.02672688476741314
step: 20, loss: 0.021319998428225517
step: 30, loss: 0.0745357945561409
step: 40, loss: 0.09443136304616928
step: 50, loss: 0.11578653752803802
step: 60, loss: 0.06740855425596237
step: 70, loss: 0.05129314213991165
step: 80, loss: 0.05834561958909035
step: 90, loss: 0.03504727780818939
step: 100, loss: 0.03518567979335785
step: 110, loss: 0.04686129093170166
step: 120, loss: 0.03671984001994133
step: 130, loss: 0.16677139699459076
step: 140, loss: 0.018055777996778488
step: 150, loss: 0.08838549256324768
step: 160, loss: 0.13254593312740326
step: 170, loss: 0.14854013919830322
step: 180, loss: 0.12645302712917328
step: 190, loss: 0.007827632129192352
step: 200, loss: 0.026660872623324394
step: 210, loss: 0.412258118391037
step: 220, loss: 0.1396264135837555
step: 230, loss: 0.021182291209697723
step: 240, loss: 0.047165028750896454
step: 250, loss: 0.051529958844184875
step: 260, loss: 0.030099481344223022
step: 270, loss: 0.10087505728006363
step: 280, loss: 0.02057790942490101
step: 290, loss: 0.09878929704427719
step: 300, loss: 0.032654739916324615
step: 310, loss: 0.19311796128749847
step: 320, loss: 0.01042164396494627
step: 330, loss: 0.10396169126033783
step: 340, loss: 0.08867689222097397
step: 350, loss: 0.070627860724926
step: 360, loss: 0.026938024908304214
step: 370, loss: 0.030236925929784775
step: 380, loss: 0.14480066299438477
step: 390, loss: 0.08513381332159042
step: 400, loss: 0.04833640530705452
step: 410, loss: 0.11582902818918228
step: 420, loss: 0.0690368264913559
step: 430, loss: 0.14504745602607727
step: 440, loss: 0.14950208365917206
step: 450, loss: 0.06203845143318176
step: 460, loss: 0.008238885551691055
step: 470, loss: 0.08088758587837219
step: 480, loss: 0.041526585817337036
step: 490, loss: 0.011139114387333393
step: 500, loss: 0.020050615072250366
step: 510, loss: 0.04254789277911186
step: 520, loss: 0.022092146798968315
step: 530, loss: 0.13566632568836212
step: 540, loss: 0.13680841028690338
step: 550, loss: 0.17589536309242249
step: 560, loss: 0.01741051860153675
step: 570, loss: 0.1311514526605606
step: 580, loss: 0.015215705148875713
step: 590, loss: 0.0026652843225747347
step: 600, loss: 0.08992485702037811
step: 610, loss: 0.1480707824230194
step: 620, loss: 0.025541292503476143
step: 630, loss: 0.045697033405303955
step: 640, loss: 0.06792689114809036
step: 650, loss: 0.08662521839141846
step: 660, loss: 0.16334785521030426
step: 670, loss: 0.10305826365947723
step: 680, loss: 0.03210455924272537
step: 690, loss: 0.028593167662620544
step: 700, loss: 0.08434373885393143
step: 710, loss: 0.02500784583389759
step: 720, loss: 0.0657920390367508
step: 730, loss: 0.03707728162407875
step: 740, loss: 0.05695408955216408
step: 750, loss: 0.0006893181707710028
step: 760, loss: 0.10446780174970627
step: 770, loss: 0.046553969383239746
step: 780, loss: 0.06518318504095078
step: 790, loss: 0.06330377608537674
step: 800, loss: 0.08342929929494858
step: 810, loss: 0.11782155930995941
step: 820, loss: 0.08961404860019684
step: 830, loss: 0.033726420253515244
step: 840, loss: 0.019260620698332787
step: 850, loss: 0.0857577994465828
step: 860, loss: 0.15004213154315948
step: 870, loss: 0.07718439400196075
step: 880, loss: 0.04204075410962105
step: 890, loss: 0.03797273710370064
step: 900, loss: 0.10212250798940659
step: 910, loss: 0.14338889718055725
step: 920, loss: 0.14519143104553223
step: 930, loss: 0.01644287258386612
step: 940, loss: 0.047046251595020294
step: 950, loss: 0.09659246355295181
step: 960, loss: 0.19589047133922577
step: 970, loss: 0.03345296531915665
step: 980, loss: 0.0801389291882515
step: 990, loss: 0.00781587790697813
step: 1000, loss: 0.15081924200057983
step: 1010, loss: 0.14783991873264313
step: 1020, loss: 0.035561785101890564
step: 1030, loss: 0.10889825969934464
step: 1040, loss: 0.02907184325158596
step: 1050, loss: 0.016382860019803047
step: 1060, loss: 0.010138379409909248
step: 1070, loss: 0.21166397631168365
epoch 3: dev_f1=0.9317972350230416, f1=0.9260273972602739, best_f1=0.9351127473538886
step: 0, loss: 0.14771591126918793
step: 10, loss: 0.031103650107979774
step: 20, loss: 0.2077283412218094
step: 30, loss: 0.02973100170493126
step: 40, loss: 0.10079744458198547
step: 50, loss: 0.08046125620603561
step: 60, loss: 0.041028644889593124
step: 70, loss: 0.02835521288216114
step: 80, loss: 0.041280750185251236
step: 90, loss: 0.1871315985918045
step: 100, loss: 0.021285708993673325
step: 110, loss: 0.05642678961157799
step: 120, loss: 0.09360040724277496
step: 130, loss: 0.06657679378986359
step: 140, loss: 0.031187936663627625
step: 150, loss: 0.06597403436899185
step: 160, loss: 0.25171735882759094
step: 170, loss: 0.04994770139455795
step: 180, loss: 0.0489642396569252
step: 190, loss: 0.15403252840042114
step: 200, loss: 0.06175020709633827
step: 210, loss: 0.1897856742143631
step: 220, loss: 0.05221601948142052
step: 230, loss: 0.02614934742450714
step: 240, loss: 0.023598812520503998
step: 250, loss: 0.016552582383155823
step: 260, loss: 0.010504466481506824
step: 270, loss: 0.014104673638939857
step: 280, loss: 0.04597627744078636
step: 290, loss: 0.1409980058670044
step: 300, loss: 0.2949248254299164
step: 310, loss: 0.1782422810792923
step: 320, loss: 0.050536852329969406
step: 330, loss: 0.14638815820217133
step: 340, loss: 0.00869115348905325
step: 350, loss: 0.09874043613672256
step: 360, loss: 0.016678962856531143
step: 370, loss: 0.03009958006441593
step: 380, loss: 0.060715436935424805
step: 390, loss: 0.03939369320869446
step: 400, loss: 0.01805584691464901
step: 410, loss: 0.07798895984888077
step: 420, loss: 0.013506566174328327
step: 430, loss: 0.07855796813964844
step: 440, loss: 0.005497706588357687
step: 450, loss: 0.029525771737098694
step: 460, loss: 0.10048865526914597
step: 470, loss: 0.15142059326171875
step: 480, loss: 0.029377929866313934
step: 490, loss: 0.0755394697189331
step: 500, loss: 0.06924279779195786
step: 510, loss: 0.10492654144763947
step: 520, loss: 0.08257447928190231
step: 530, loss: 0.06351049989461899
step: 540, loss: 0.04122990742325783
step: 550, loss: 0.04571612551808357
step: 560, loss: 0.062395621091127396
step: 570, loss: 0.002954993164166808
step: 580, loss: 0.019965985789895058
step: 590, loss: 0.19178631901741028
step: 600, loss: 0.05005281791090965
step: 610, loss: 0.034149400889873505
step: 620, loss: 0.01803750917315483
step: 630, loss: 0.18656936287879944
step: 640, loss: 0.15153630077838898
step: 650, loss: 0.10608154535293579
step: 660, loss: 0.06689334660768509
step: 670, loss: 0.28255364298820496
step: 680, loss: 0.06526201218366623
step: 690, loss: 0.1442641168832779
step: 700, loss: 0.01860244758427143
step: 710, loss: 0.1892252266407013
step: 720, loss: 0.10169518738985062
step: 730, loss: 0.12823447585105896
step: 740, loss: 0.06485693156719208
step: 750, loss: 0.028989404439926147
step: 760, loss: 0.14300063252449036
step: 770, loss: 0.06704559922218323
step: 780, loss: 0.047246985137462616
step: 790, loss: 0.034999310970306396
step: 800, loss: 0.019052620977163315
step: 810, loss: 0.014422023668885231
step: 820, loss: 0.08319186419248581
step: 830, loss: 0.020634829998016357
step: 840, loss: 0.03644323721528053
step: 850, loss: 0.035639114677906036
step: 860, loss: 0.04165150597691536
step: 870, loss: 0.02129494398832321
step: 880, loss: 0.06370210647583008
step: 890, loss: 0.005707271862775087
step: 900, loss: 0.08670864254236221
step: 910, loss: 0.02375049889087677
step: 920, loss: 0.04125427082180977
step: 930, loss: 0.13217014074325562
step: 940, loss: 0.18730127811431885
step: 950, loss: 0.012034742161631584
step: 960, loss: 0.033733490854501724
step: 970, loss: 0.07253365218639374
step: 980, loss: 0.07702148705720901
step: 990, loss: 0.16360247135162354
step: 1000, loss: 0.05088958144187927
step: 1010, loss: 0.10262248665094376
step: 1020, loss: 0.08211244642734528
step: 1030, loss: 0.029027393087744713
step: 1040, loss: 0.08847548067569733
step: 1050, loss: 0.19523678719997406
step: 1060, loss: 0.13815869390964508
step: 1070, loss: 0.24746167659759521
epoch 4: dev_f1=0.9394629039599454, f1=0.9397371998187584, best_f1=0.9397371998187584
step: 0, loss: 0.023937594145536423
step: 10, loss: 0.011064949445426464
step: 20, loss: 0.04316573217511177
step: 30, loss: 0.015997447073459625
step: 40, loss: 0.09823424369096756
step: 50, loss: 0.03574804589152336
step: 60, loss: 0.2233939915895462
step: 70, loss: 0.09284021705389023
step: 80, loss: 0.027598226442933083
step: 90, loss: 8.368453563889489e-05
step: 100, loss: 0.03525310754776001
step: 110, loss: 0.0016323673771694303
step: 120, loss: 0.05664500594139099
step: 130, loss: 0.129550039768219
step: 140, loss: 0.027271822094917297
step: 150, loss: 0.057362522929906845
step: 160, loss: 0.004663549829274416
step: 170, loss: 0.16510169208049774
step: 180, loss: 0.006110172253102064
step: 190, loss: 0.023971695452928543
step: 200, loss: 0.09822152554988861
step: 210, loss: 0.10474821925163269
step: 220, loss: 0.025975003838539124
step: 230, loss: 0.0507456436753273
step: 240, loss: 0.012053128331899643
step: 250, loss: 0.058112312108278275
step: 260, loss: 0.010186734609305859
step: 270, loss: 0.020286353304982185
step: 280, loss: 0.011093813925981522
step: 290, loss: 0.07268299162387848
step: 300, loss: 0.007554796990007162
step: 310, loss: 0.047478530555963516
step: 320, loss: 0.012851046398282051
step: 330, loss: 0.13443666696548462
step: 340, loss: 0.1591401994228363
step: 350, loss: 0.18302875757217407
step: 360, loss: 0.03041788563132286
step: 370, loss: 0.03659845516085625
step: 380, loss: 0.07080218940973282
step: 390, loss: 0.21310652792453766
step: 400, loss: 0.04269786551594734
step: 410, loss: 0.027969015762209892
step: 420, loss: 0.0171000137925148
step: 430, loss: 0.04259477183222771
step: 440, loss: 0.06686707586050034
step: 450, loss: 0.12999387085437775
step: 460, loss: 0.10824917256832123
step: 470, loss: 0.06108210235834122
step: 480, loss: 0.146832674741745
step: 490, loss: 0.01293992716819048
step: 500, loss: 0.02822844497859478
step: 510, loss: 0.011988253332674503
step: 520, loss: 0.07177674025297165
step: 530, loss: 0.12306459993124008
step: 540, loss: 0.0859123170375824
step: 550, loss: 0.01845795102417469
step: 560, loss: 0.03460771590471268
step: 570, loss: 0.068404421210289
step: 580, loss: 0.024622734636068344
step: 590, loss: 0.0536758154630661
step: 600, loss: 0.04150530323386192
step: 610, loss: 0.07991660386323929
step: 620, loss: 0.020455125719308853
step: 630, loss: 0.010443267412483692
step: 640, loss: 0.08936120569705963
step: 650, loss: 0.09049710631370544
step: 660, loss: 0.14730794727802277
step: 670, loss: 0.14925052225589752
step: 680, loss: 0.027028119191527367
step: 690, loss: 0.08687050640583038
step: 700, loss: 0.03646739572286606
step: 710, loss: 0.011814109049737453
step: 720, loss: 0.08189328014850616
step: 730, loss: 0.06426001340150833
step: 740, loss: 0.0930655375123024
step: 750, loss: 0.006405672989785671
step: 760, loss: 0.020645540207624435
step: 770, loss: 0.10715462267398834
step: 780, loss: 0.07166174799203873
step: 790, loss: 0.06497690081596375
step: 800, loss: 0.00666899373754859
step: 810, loss: 0.10466472804546356
step: 820, loss: 0.10290546715259552
step: 830, loss: 0.031226057559251785
step: 840, loss: 0.011407054960727692
step: 850, loss: 0.12856240570545197
step: 860, loss: 0.014644968323409557
step: 870, loss: 0.0629858449101448
step: 880, loss: 0.03376093879342079
step: 890, loss: 0.1569807380437851
step: 900, loss: 0.0874084010720253
step: 910, loss: 0.09180154651403427
step: 920, loss: 0.03615201637148857
step: 930, loss: 0.07515782117843628
step: 940, loss: 0.12714409828186035
step: 950, loss: 0.10173492133617401
step: 960, loss: 0.03302929922938347
step: 970, loss: 0.10434122383594513
step: 980, loss: 0.007329437416046858
step: 990, loss: 0.08479173481464386
step: 1000, loss: 0.09407785534858704
step: 1010, loss: 0.04333975911140442
step: 1020, loss: 0.06885644048452377
step: 1030, loss: 0.022789493203163147
step: 1040, loss: 0.015226047486066818
step: 1050, loss: 0.05701834335923195
step: 1060, loss: 0.02302212081849575
step: 1070, loss: 0.030233781784772873
epoch 5: dev_f1=0.9331463300607761, f1=0.9311627906976745, best_f1=0.9397371998187584
step: 0, loss: 0.01758924312889576
step: 10, loss: 0.02222299389541149
step: 20, loss: 0.00755485612899065
step: 30, loss: 0.1759873330593109
step: 40, loss: 0.053706053644418716
step: 50, loss: 0.09456884115934372
step: 60, loss: 0.013895181007683277
step: 70, loss: 0.06829091161489487
step: 80, loss: 0.09117915481328964
step: 90, loss: 0.0059309424832463264
step: 100, loss: 0.03461255133152008
step: 110, loss: 0.0833878442645073
step: 120, loss: 0.16159462928771973
step: 130, loss: 0.020511025562882423
step: 140, loss: 0.03911006823182106
step: 150, loss: 0.09727946668863297
step: 160, loss: 0.08687974512577057
step: 170, loss: 0.058340735733509064
step: 180, loss: 0.07693514972925186
step: 190, loss: 0.054040491580963135
step: 200, loss: 0.01414146926254034
step: 210, loss: 0.09802796691656113
step: 220, loss: 0.00505614560097456
step: 230, loss: 0.014183488674461842
step: 240, loss: 0.09094913303852081
step: 250, loss: 0.02259986102581024
step: 260, loss: 0.11382302641868591
step: 270, loss: 0.12266260385513306
step: 280, loss: 0.03083820454776287
step: 290, loss: 0.041974589228630066
step: 300, loss: 0.05998879671096802
step: 310, loss: 0.033881109207868576
step: 320, loss: 0.01476234756410122
step: 330, loss: 0.00029156875098124146
step: 340, loss: 0.009793486446142197
step: 350, loss: 0.11488409340381622
step: 360, loss: 0.023928703740239143
step: 370, loss: 0.014286721125245094
step: 380, loss: 0.05334954708814621
step: 390, loss: 0.016982551664114
step: 400, loss: 0.013497736304998398
step: 410, loss: 0.019000625237822533
step: 420, loss: 0.013848844915628433
step: 430, loss: 0.014252507127821445
step: 440, loss: 0.17875434458255768
step: 450, loss: 0.023491671308875084
step: 460, loss: 0.02974075824022293
step: 470, loss: 0.009042630903422832
step: 480, loss: 0.026664765551686287
step: 490, loss: 0.02246229723095894
step: 500, loss: 0.09152665734291077
step: 510, loss: 0.12509675323963165
step: 520, loss: 0.02952473983168602
step: 530, loss: 0.10568583011627197
step: 540, loss: 0.06100406497716904
step: 550, loss: 0.02744690701365471
step: 560, loss: 0.18187366425991058
step: 570, loss: 0.023844469338655472
step: 580, loss: 0.20919062197208405
step: 590, loss: 0.04595613852143288
step: 600, loss: 0.10722815990447998
step: 610, loss: 0.12747448682785034
step: 620, loss: 0.05307936295866966
step: 630, loss: 0.1143500879406929
step: 640, loss: 0.028457004576921463
step: 650, loss: 0.05096195265650749
step: 660, loss: 0.2098764032125473
step: 670, loss: 0.10046648979187012
step: 680, loss: 0.04415367171168327
step: 690, loss: 0.09633296728134155
step: 700, loss: 0.08264777064323425
step: 710, loss: 0.014603665098547935
step: 720, loss: 0.04239575192332268
step: 730, loss: 0.15097926557064056
step: 740, loss: 0.03126661479473114
step: 750, loss: 0.029102245345711708
step: 760, loss: 0.0031713340431451797
step: 770, loss: 0.10442505031824112
step: 780, loss: 0.018664062023162842
step: 790, loss: 0.0010074973106384277
step: 800, loss: 0.030243199318647385
step: 810, loss: 0.09048262983560562
step: 820, loss: 0.0727459192276001
step: 830, loss: 0.08214598894119263
step: 840, loss: 0.0557338185608387
step: 850, loss: 0.10410185903310776
step: 860, loss: 0.1260848343372345
step: 870, loss: 0.0546877421438694
step: 880, loss: 0.011926899664103985
step: 890, loss: 0.03901809826493263
step: 900, loss: 0.0659426748752594
step: 910, loss: 0.2090665102005005
step: 920, loss: 0.03162962943315506
step: 930, loss: 0.08926764130592346
step: 940, loss: 0.07144460082054138
step: 950, loss: 0.08093803375959396
step: 960, loss: 0.009476019069552422
step: 970, loss: 0.09207382053136826
step: 980, loss: 0.00013418290473055094
step: 990, loss: 0.02863967977464199
step: 1000, loss: 0.005872819572687149
step: 1010, loss: 0.057100195437669754
step: 1020, loss: 0.05644577369093895
step: 1030, loss: 0.0030898009426891804
step: 1040, loss: 0.017198624089360237
step: 1050, loss: 0.07674610614776611
step: 1060, loss: 0.08497720956802368
step: 1070, loss: 0.0155657222494483
epoch 6: dev_f1=0.9311594202898551, f1=0.928798185941043, best_f1=0.9397371998187584
step: 0, loss: 0.010776523500680923
step: 10, loss: 0.05670667067170143
step: 20, loss: 0.007539501879364252
step: 30, loss: 0.024873895570635796
step: 40, loss: 0.07847249507904053
step: 50, loss: 0.07763579487800598
step: 60, loss: 0.0644383504986763
step: 70, loss: 0.021330835297703743
step: 80, loss: 0.017134057357907295
step: 90, loss: 0.2021574079990387
step: 100, loss: 0.04427264630794525
step: 110, loss: 0.06935995817184448
step: 120, loss: 0.09367130696773529
step: 130, loss: 0.01732092723250389
step: 140, loss: 0.052490703761577606
step: 150, loss: 0.05352377891540527
step: 160, loss: 0.019027210772037506
step: 170, loss: 0.10687639564275742
step: 180, loss: 0.0073290178552269936
step: 190, loss: 0.014368914999067783
step: 200, loss: 0.038734838366508484
step: 210, loss: 0.014648902229964733
step: 220, loss: 0.04601745679974556
step: 230, loss: 0.06533642113208771
step: 240, loss: 0.013486374169588089
step: 250, loss: 0.011837220750749111
step: 260, loss: 0.021122826263308525
step: 270, loss: 0.04915507510304451
step: 280, loss: 0.13495329022407532
step: 290, loss: 0.12277058511972427
step: 300, loss: 0.13499394059181213
step: 310, loss: 0.11443541944026947
step: 320, loss: 0.20551928877830505
step: 330, loss: 0.01387293916195631
step: 340, loss: 0.05744539201259613
step: 350, loss: 0.034746184945106506
step: 360, loss: 0.0845382958650589
step: 370, loss: 0.011013813316822052
step: 380, loss: 0.033226191997528076
step: 390, loss: 0.05779392272233963
step: 400, loss: 0.0994405746459961
step: 410, loss: 0.10280037671327591
step: 420, loss: 0.07291337847709656
step: 430, loss: 0.08132042735815048
step: 440, loss: 0.04647389054298401
step: 450, loss: 0.1771065592765808
step: 460, loss: 0.09954588860273361
step: 470, loss: 0.10680379718542099
step: 480, loss: 0.03699219599366188
step: 490, loss: 0.032170504331588745
step: 500, loss: 0.005787142552435398
step: 510, loss: 0.0428926981985569
step: 520, loss: 0.0788218304514885
step: 530, loss: 0.009548185393214226
step: 540, loss: 0.08624850958585739
step: 550, loss: 0.08183713257312775
step: 560, loss: 0.019038083031773567
step: 570, loss: 0.026400959119200706
step: 580, loss: 0.012084150686860085
step: 590, loss: 0.1471518576145172
step: 600, loss: 0.013795601204037666
step: 610, loss: 0.018571745604276657
step: 620, loss: 0.07028596848249435
step: 630, loss: 0.08980385959148407
step: 640, loss: 0.08789695799350739
step: 650, loss: 0.06529203802347183
step: 660, loss: 0.07954277843236923
step: 670, loss: 0.00653858482837677
step: 680, loss: 0.027485013008117676
step: 690, loss: 0.07378736883401871
step: 700, loss: 0.06715286523103714
step: 710, loss: 0.02295144647359848
step: 720, loss: 0.06955840438604355
step: 730, loss: 0.06702548265457153
step: 740, loss: 0.005070697981864214
step: 750, loss: 0.09555424004793167
step: 760, loss: 0.048129837960004807
step: 770, loss: 0.1043679416179657
step: 780, loss: 0.07467993348836899
step: 790, loss: 0.030041681602597237
step: 800, loss: 0.008762311190366745
step: 810, loss: 0.09318600594997406
step: 820, loss: 0.01302616111934185
step: 830, loss: 0.01239087525755167
step: 840, loss: 0.06707055121660233
step: 850, loss: 0.08429580926895142
step: 860, loss: 0.09313206374645233
step: 870, loss: 0.012211237102746964
step: 880, loss: 0.05985482782125473
step: 890, loss: 0.06554070115089417
step: 900, loss: 0.09021315723657608
step: 910, loss: 0.029693301767110825
step: 920, loss: 0.050420403480529785
step: 930, loss: 0.07428513467311859
step: 940, loss: 0.04573183134198189
step: 950, loss: 0.01396101713180542
step: 960, loss: 0.061159420758485794
step: 970, loss: 0.008827770128846169
step: 980, loss: 0.07810595631599426
step: 990, loss: 0.041882146149873734
step: 1000, loss: 0.04772995412349701
step: 1010, loss: 0.04006550833582878
step: 1020, loss: 0.2795148491859436
step: 1030, loss: 0.012663126923143864
step: 1040, loss: 0.04630404710769653
step: 1050, loss: 0.014505407772958279
step: 1060, loss: 0.0867360383272171
step: 1070, loss: 0.10770566761493683
epoch 7: dev_f1=0.9387942936033133, f1=0.93666204345816, best_f1=0.9397371998187584
step: 0, loss: 0.0050125629641115665
step: 10, loss: 0.01897743158042431
step: 20, loss: 0.15810255706310272
step: 30, loss: 0.06129251420497894
step: 40, loss: 0.032057248055934906
step: 50, loss: 0.044029369950294495
step: 60, loss: 0.0669412910938263
step: 70, loss: 0.09844587743282318
step: 80, loss: 0.10550449043512344
step: 90, loss: 0.07114435732364655
step: 100, loss: 0.013673963956534863
step: 110, loss: 0.041709888726472855
step: 120, loss: 0.01234228815883398
step: 130, loss: 0.01781158708035946
step: 140, loss: 0.000597369100432843
step: 150, loss: 0.0638752430677414
step: 160, loss: 0.06736647337675095
step: 170, loss: 0.09665937721729279
step: 180, loss: 0.06843824684619904
step: 190, loss: 0.031355004757642746
step: 200, loss: 0.019631335511803627
step: 210, loss: 0.00547759048640728
step: 220, loss: 0.021569687873125076
step: 230, loss: 1.9136541595798917e-05
step: 240, loss: 0.037623438984155655
step: 250, loss: 0.07160847634077072
step: 260, loss: 0.09233417361974716
step: 270, loss: 0.0712728351354599
step: 280, loss: 0.013774535618722439
step: 290, loss: 0.11002449691295624
step: 300, loss: 0.037790048867464066
step: 310, loss: 0.008129417896270752
step: 320, loss: 0.011090565472841263
step: 330, loss: 0.04306577146053314
step: 340, loss: 0.05535005033016205
step: 350, loss: 0.03290810063481331
step: 360, loss: 0.0023385612294077873
step: 370, loss: 0.0002820138761308044
step: 380, loss: 0.03759750723838806
step: 390, loss: 0.022164683789014816
step: 400, loss: 0.013752060942351818
step: 410, loss: 0.016421224921941757
step: 420, loss: 0.0547015555202961
step: 430, loss: 0.021569805219769478
step: 440, loss: 0.07335806638002396
step: 450, loss: 0.04799538850784302
step: 460, loss: 0.00751277431845665
step: 470, loss: 0.014263086020946503
step: 480, loss: 0.03597106784582138
step: 490, loss: 0.11660419404506683
step: 500, loss: 0.31904032826423645
step: 510, loss: 0.04899642989039421
step: 520, loss: 0.03697723522782326
step: 530, loss: 0.09297698736190796
step: 540, loss: 0.04633763059973717
step: 550, loss: 0.027615010738372803
step: 560, loss: 0.04641732573509216
step: 570, loss: 0.017186859622597694
step: 580, loss: 0.027667777612805367
step: 590, loss: 0.043195050209760666
step: 600, loss: 0.017788073047995567
step: 610, loss: 0.008600876666605473
step: 620, loss: 0.010214203968644142
step: 630, loss: 0.0790432021021843
step: 640, loss: 0.10435798019170761
step: 650, loss: 0.02714512310922146
step: 660, loss: 0.00971286278218031
step: 670, loss: 0.1413334608078003
step: 680, loss: 0.06461019814014435
step: 690, loss: 0.009709736332297325
step: 700, loss: 0.2008863240480423
step: 710, loss: 0.11603464186191559
step: 720, loss: 0.06227661296725273
step: 730, loss: 0.06589807569980621
step: 740, loss: 0.06212243810296059
step: 750, loss: 0.06503918021917343
step: 760, loss: 0.05866716802120209
step: 770, loss: 0.10823744535446167
step: 780, loss: 0.05945796146988869
step: 790, loss: 0.08151797205209732
step: 800, loss: 0.09880289435386658
step: 810, loss: 0.0014956804225221276
step: 820, loss: 0.000271105527644977
step: 830, loss: 0.055673833936452866
step: 840, loss: 0.011900540441274643
step: 850, loss: 0.018545102328062057
step: 860, loss: 0.0029796515591442585
step: 870, loss: 0.02564268745481968
step: 880, loss: 0.08192512392997742
step: 890, loss: 0.028260672464966774
step: 900, loss: 0.03654690831899643
step: 910, loss: 0.05212867259979248
step: 920, loss: 0.026815032586455345
step: 930, loss: 0.00801471620798111
step: 940, loss: 0.0048833806067705154
step: 950, loss: 0.05278320237994194
step: 960, loss: 0.011725034564733505
step: 970, loss: 0.03224281594157219
step: 980, loss: 0.040431875735521317
step: 990, loss: 0.08115630596876144
step: 1000, loss: 0.002082285238429904
step: 1010, loss: 0.02594612166285515
step: 1020, loss: 0.05650248005986214
step: 1030, loss: 0.06559278070926666
step: 1040, loss: 0.0523529015481472
step: 1050, loss: 0.13534264266490936
step: 1060, loss: 0.07899028062820435
step: 1070, loss: 0.024354152381420135
epoch 8: dev_f1=0.9327188940092166, f1=0.9357374017568193, best_f1=0.9397371998187584
step: 0, loss: 0.05284254252910614
step: 10, loss: 0.01685597561299801
step: 20, loss: 0.06628185510635376
step: 30, loss: 4.160911339567974e-05
step: 40, loss: 0.08933904021978378
step: 50, loss: 0.0012329001910984516
step: 60, loss: 0.0210280641913414
step: 70, loss: 0.26500189304351807
step: 80, loss: 0.0780373215675354
step: 90, loss: 0.16874422132968903
step: 100, loss: 0.005060472525656223
step: 110, loss: 0.01963123120367527
step: 120, loss: 0.049529701471328735
step: 130, loss: 0.03728436306118965
step: 140, loss: 0.011085591278970242
step: 150, loss: 0.09729280322790146
step: 160, loss: 0.07122582942247391
step: 170, loss: 0.06511581689119339
step: 180, loss: 0.014413552358746529
step: 190, loss: 0.01617412082850933
step: 200, loss: 0.012833536602556705
step: 210, loss: 0.013313066214323044
step: 220, loss: 0.08336640894412994
step: 230, loss: 0.08765039592981339
step: 240, loss: 0.04900271072983742
step: 250, loss: 0.03695450723171234
step: 260, loss: 0.09489455819129944
step: 270, loss: 0.04624972864985466
step: 280, loss: 0.004809767007827759
step: 290, loss: 0.0076404656283557415
step: 300, loss: 0.07156451791524887
step: 310, loss: 0.03862404823303223
step: 320, loss: 0.03140829876065254
step: 330, loss: 0.04283709451556206
step: 340, loss: 0.0011662128381431103
step: 350, loss: 0.03763479366898537
step: 360, loss: 0.07671654969453812
step: 370, loss: 0.05603162571787834
step: 380, loss: 0.09975365549325943
step: 390, loss: 0.07080210745334625
step: 400, loss: 0.05023566260933876
step: 410, loss: 0.05719546228647232
step: 420, loss: 0.03864603489637375
step: 430, loss: 0.16317811608314514
step: 440, loss: 0.008156311698257923
step: 450, loss: 0.04893171414732933
step: 460, loss: 0.02560589835047722
step: 470, loss: 0.009862283244729042
step: 480, loss: 0.02544906549155712
step: 490, loss: 0.020368997007608414
step: 500, loss: 0.0994093120098114
step: 510, loss: 0.010469877161085606
step: 520, loss: 0.07312773168087006
step: 530, loss: 0.015883918851614
step: 540, loss: 0.02335273288190365
step: 550, loss: 0.017303001135587692
step: 560, loss: 0.017385749146342278
step: 570, loss: 0.011349275708198547
step: 580, loss: 0.006989550311118364
step: 590, loss: 0.031399477273225784
step: 600, loss: 0.040308818221092224
step: 610, loss: 0.018283898010849953
step: 620, loss: 0.02309807762503624
step: 630, loss: 0.025476420298218727
step: 640, loss: 0.032357245683670044
step: 650, loss: 0.01215691864490509
step: 660, loss: 0.007060124538838863
step: 670, loss: 0.017738239839673042
step: 680, loss: 0.0782916396856308
step: 690, loss: 0.0010663014836609364
step: 700, loss: 0.003500607330352068
step: 710, loss: 0.019552486017346382
step: 720, loss: 0.15153071284294128
step: 730, loss: 0.02224573865532875
step: 740, loss: 0.05682973936200142
step: 750, loss: 0.04495386406779289
step: 760, loss: 0.056655410677194595
step: 770, loss: 0.02499416097998619
step: 780, loss: 0.11464032530784607
step: 790, loss: 0.1160210371017456
step: 800, loss: 0.011080891825258732
step: 810, loss: 0.059717897325754166
step: 820, loss: 0.06822378188371658
step: 830, loss: 0.048061639070510864
step: 840, loss: 0.11616522073745728
step: 850, loss: 0.1476665884256363
step: 860, loss: 0.04241669178009033
step: 870, loss: 0.03389044478535652
step: 880, loss: 0.010330951772630215
step: 890, loss: 0.01931525208055973
step: 900, loss: 0.03230917081236839
step: 910, loss: 0.002089228481054306
step: 920, loss: 0.05321445316076279
step: 930, loss: 0.0827372595667839
step: 940, loss: 0.011884604580700397
step: 950, loss: 0.04639142006635666
step: 960, loss: 0.04645925387740135
step: 970, loss: 0.1614755094051361
step: 980, loss: 0.021242013201117516
step: 990, loss: 0.003968836273998022
step: 1000, loss: 0.015453459694981575
step: 1010, loss: 0.021689975634217262
step: 1020, loss: 0.05434462055563927
step: 1030, loss: 0.036532942205667496
step: 1040, loss: 0.06310476362705231
step: 1050, loss: 0.09968442469835281
step: 1060, loss: 0.03629928082227707
step: 1070, loss: 0.15029743313789368
epoch 9: dev_f1=0.9297597042513862, f1=0.9210890632210429, best_f1=0.9397371998187584
step: 0, loss: 0.06176546588540077
step: 10, loss: 0.04965290054678917
step: 20, loss: 0.00705003272742033
step: 30, loss: 0.061529189348220825
step: 40, loss: 0.03779655694961548
step: 50, loss: 7.242587889777496e-05
step: 60, loss: 0.05274595692753792
step: 70, loss: 0.0018330567982047796
step: 80, loss: 0.056816983968019485
step: 90, loss: 0.049017783254384995
step: 100, loss: 0.024327082559466362
step: 110, loss: 0.013754435814917088
step: 120, loss: 0.08081627637147903
step: 130, loss: 0.06495963037014008
step: 140, loss: 0.004499159753322601
step: 150, loss: 0.01544940285384655
step: 160, loss: 0.10651865601539612
step: 170, loss: 0.002865923335775733
step: 180, loss: 0.044786691665649414
step: 190, loss: 0.0005882105906493962
step: 200, loss: 0.082696832716465
step: 210, loss: 0.005341270472854376
step: 220, loss: 0.001840873621404171
step: 230, loss: 0.07258391380310059
step: 240, loss: 0.00020766798115801066
step: 250, loss: 0.0002888923045247793
step: 260, loss: 0.032042246311903
step: 270, loss: 0.0028822626918554306
step: 280, loss: 0.023345153778791428
step: 290, loss: 0.0031327474862337112
step: 300, loss: 0.004504385404288769
step: 310, loss: 0.13367176055908203
step: 320, loss: 0.08520104736089706
step: 330, loss: 0.03671073168516159
step: 340, loss: 0.021759826689958572
step: 350, loss: 0.02362133376300335
step: 360, loss: 0.07310838997364044
step: 370, loss: 0.003116605570539832
step: 380, loss: 0.09788253903388977
step: 390, loss: 0.06549372524023056
step: 400, loss: 0.01456113625317812
step: 410, loss: 0.161209374666214
step: 420, loss: 0.019970089197158813
step: 430, loss: 0.010972454212605953
step: 440, loss: 0.0054847970604896545
step: 450, loss: 0.056494224816560745
step: 460, loss: 0.0022860791068524122
step: 470, loss: 0.06371248513460159
step: 480, loss: 0.029128102585673332
step: 490, loss: 0.0331249013543129
step: 500, loss: 0.02988092042505741
step: 510, loss: 0.01473727822303772
step: 520, loss: 0.04802440106868744
step: 530, loss: 0.008729884400963783
step: 540, loss: 0.010972721502184868
step: 550, loss: 0.08346738666296005
step: 560, loss: 0.12189756333827972
step: 570, loss: 0.023167600855231285
step: 580, loss: 0.1220298558473587
step: 590, loss: 0.028405724093317986
step: 600, loss: 0.00045819857041351497
step: 610, loss: 0.0796264111995697
step: 620, loss: 0.03587905690073967
step: 630, loss: 0.023920007050037384
step: 640, loss: 0.047678980976343155
step: 650, loss: 0.04687132686376572
step: 660, loss: 0.026619456708431244
step: 670, loss: 0.038026127964258194
step: 680, loss: 0.05806346982717514
step: 690, loss: 0.04171926528215408
step: 700, loss: 0.01662020944058895
step: 710, loss: 0.0465572364628315
step: 720, loss: 0.05607207119464874
step: 730, loss: 3.0169598176144063e-05
step: 740, loss: 0.036166924983263016
step: 750, loss: 0.006822818890213966
step: 760, loss: 0.03333702310919762
step: 770, loss: 0.06427640467882156
step: 780, loss: 0.019097886979579926
step: 790, loss: 0.0335916131734848
step: 800, loss: 0.0627535954117775
step: 810, loss: 0.048403847962617874
step: 820, loss: 0.10997781902551651
step: 830, loss: 0.030104530975222588
step: 840, loss: 0.03970131650567055
step: 850, loss: 0.12590016424655914
step: 860, loss: 1.591425643709954e-05
step: 870, loss: 0.06916431337594986
step: 880, loss: 0.005495206452906132
step: 890, loss: 0.053977031260728836
step: 900, loss: 0.015376870520412922
step: 910, loss: 0.0712830051779747
step: 920, loss: 0.06861237436532974
step: 930, loss: 0.05300597473978996
step: 940, loss: 0.018592430278658867
step: 950, loss: 0.006763731129467487
step: 960, loss: 0.0423191599547863
step: 970, loss: 0.08691930770874023
step: 980, loss: 0.09633474797010422
step: 990, loss: 0.04004216939210892
step: 1000, loss: 0.045003388077020645
step: 1010, loss: 0.058378227055072784
step: 1020, loss: 0.1255180388689041
step: 1030, loss: 0.06678327172994614
step: 1040, loss: 0.019006075337529182
step: 1050, loss: 0.023730788379907608
step: 1060, loss: 0.0037478446029126644
step: 1070, loss: 0.06640201061964035
epoch 10: dev_f1=0.934752429430819, f1=0.9322820037105751, best_f1=0.9397371998187584
step: 0, loss: 0.03235260769724846
step: 10, loss: 0.16428257524967194
step: 20, loss: 0.05754717066884041
step: 30, loss: 0.009832044132053852
step: 40, loss: 0.03595764562487602
step: 50, loss: 0.013285837136209011
step: 60, loss: 0.0820319876074791
step: 70, loss: 0.036046192049980164
step: 80, loss: 0.0202869214117527
step: 90, loss: 0.03590964153409004
step: 100, loss: 0.019964177161455154
step: 110, loss: 0.03310990333557129
step: 120, loss: 0.02849377691745758
step: 130, loss: 0.000460124050732702
step: 140, loss: 0.016991833224892616
step: 150, loss: 0.003319414099678397
step: 160, loss: 0.0999549925327301
step: 170, loss: 0.08391773700714111
step: 180, loss: 0.044943731278181076
step: 190, loss: 0.0763806402683258
step: 200, loss: 0.029139652848243713
step: 210, loss: 0.03505131974816322
step: 220, loss: 0.08532023429870605
step: 230, loss: 0.005988202057778835
step: 240, loss: 0.050820015370845795
step: 250, loss: 0.083060622215271
step: 260, loss: 0.0964687168598175
step: 270, loss: 0.06832274794578552
step: 280, loss: 0.024206575006246567
step: 290, loss: 0.03969021514058113
step: 300, loss: 0.05377975478768349
step: 310, loss: 0.04247763007879257
step: 320, loss: 0.03316862881183624
step: 330, loss: 0.010520490817725658
step: 340, loss: 0.0685935989022255
step: 350, loss: 0.03985772281885147
step: 360, loss: 0.0019778134301304817
step: 370, loss: 0.05749465525150299
step: 380, loss: 0.0013988030841574073
step: 390, loss: 0.05669640004634857
step: 400, loss: 0.11237935721874237
step: 410, loss: 0.00017555136582814157
step: 420, loss: 0.02667389065027237
step: 430, loss: 0.010898166336119175
step: 440, loss: 0.06657174974679947
step: 450, loss: 0.019330790266394615
step: 460, loss: 0.04945339262485504
step: 470, loss: 0.04697344824671745
step: 480, loss: 7.118392386473715e-05
step: 490, loss: 0.002971303416416049
step: 500, loss: 0.03672311082482338
step: 510, loss: 0.04899293929338455
step: 520, loss: 2.9442970117088407e-05
step: 530, loss: 0.023282809183001518
step: 540, loss: 0.05703626200556755
step: 550, loss: 0.07050900161266327
step: 560, loss: 0.10309574753046036
step: 570, loss: 0.048422425985336304
step: 580, loss: 0.027118217200040817
step: 590, loss: 0.00011758840264519677
step: 600, loss: 0.10537340492010117
step: 610, loss: 0.02233215421438217
step: 620, loss: 0.0012863583397120237
step: 630, loss: 0.03983520716428757
step: 640, loss: 0.002619541250169277
step: 650, loss: 0.0454796701669693
step: 660, loss: 0.009742647409439087
step: 670, loss: 0.0563490130007267
step: 680, loss: 0.04382846876978874
step: 690, loss: 0.02825232595205307
step: 700, loss: 2.894731005653739e-05
step: 710, loss: 0.023168573155999184
step: 720, loss: 0.08132500946521759
step: 730, loss: 0.06646963208913803
step: 740, loss: 0.2370653748512268
step: 750, loss: 0.041252363473176956
step: 760, loss: 0.007709569297730923
step: 770, loss: 0.06894002854824066
step: 780, loss: 0.0967293530702591
step: 790, loss: 0.0038437501061707735
step: 800, loss: 0.04446639120578766
step: 810, loss: 0.02879496105015278
step: 820, loss: 0.026670532301068306
step: 830, loss: 0.014894812367856503
step: 840, loss: 0.040005069226026535
step: 850, loss: 0.0037818856071680784
step: 860, loss: 0.041792046278715134
step: 870, loss: 0.02152462676167488
step: 880, loss: 0.029525436460971832
step: 890, loss: 0.024444319307804108
step: 900, loss: 0.04025803878903389
step: 910, loss: 0.030757354572415352
step: 920, loss: 0.0023079728707671165
step: 930, loss: 0.031767524778842926
step: 940, loss: 0.0021302723325788975
step: 950, loss: 5.733812940889038e-05
step: 960, loss: 0.031650345772504807
step: 970, loss: 0.023397821933031082
step: 980, loss: 0.057179972529411316
step: 990, loss: 0.03952217102050781
step: 1000, loss: 0.017914697527885437
step: 1010, loss: 0.010107208974659443
step: 1020, loss: 0.004307146184146404
step: 1030, loss: 0.11129967123270035
step: 1040, loss: 0.007919665426015854
step: 1050, loss: 0.04788645729422569
step: 1060, loss: 0.12185665220022202
step: 1070, loss: 0.04222467541694641
epoch 11: dev_f1=0.929889298892989, f1=0.9314942528735632, best_f1=0.9397371998187584
step: 0, loss: 0.006114867981523275
step: 10, loss: 0.015547169372439384
step: 20, loss: 0.014226210303604603
step: 30, loss: 0.03728121519088745
step: 40, loss: 0.027549300342798233
step: 50, loss: 0.09363014996051788
step: 60, loss: 0.021686336025595665
step: 70, loss: 0.010826483368873596
step: 80, loss: 0.04272419586777687
step: 90, loss: 0.019126737490296364
step: 100, loss: 0.04666774719953537
step: 110, loss: 0.02137216553092003
step: 120, loss: 0.06391897052526474
step: 130, loss: 0.004710000474005938
step: 140, loss: 0.05408940091729164
step: 150, loss: 0.00016789032088126987
step: 160, loss: 0.021054718643426895
step: 170, loss: 0.050941284745931625
step: 180, loss: 0.07878310233354568
step: 190, loss: 0.04900330305099487
step: 200, loss: 0.04619564116001129
step: 210, loss: 0.031600337475538254
step: 220, loss: 0.021629510447382927
step: 230, loss: 0.010588851757347584
step: 240, loss: 0.004514343570917845
step: 250, loss: 0.031704433262348175
step: 260, loss: 0.010226736776530743
step: 270, loss: 0.018102847039699554
step: 280, loss: 0.057707395404577255
step: 290, loss: 5.834154217154719e-05
step: 300, loss: 0.002156384289264679
step: 310, loss: 0.1454797238111496
step: 320, loss: 0.09754214435815811
step: 330, loss: 0.011430681683123112
step: 340, loss: 0.05060091242194176
step: 350, loss: 0.005803599953651428
step: 360, loss: 0.07406961917877197
step: 370, loss: 0.04148335009813309
step: 380, loss: 0.04121369123458862
step: 390, loss: 0.04051588475704193
step: 400, loss: 0.08181912451982498
step: 410, loss: 0.0006068435613997281
step: 420, loss: 0.056550364941358566
step: 430, loss: 0.06112641096115112
step: 440, loss: 0.01896512135863304
step: 450, loss: 0.006457242649048567
step: 460, loss: 0.009425075724720955
step: 470, loss: 0.0012734493939206004
step: 480, loss: 0.041969481855630875
step: 490, loss: 1.3720119568461087e-05
step: 500, loss: 0.034695643931627274
step: 510, loss: 0.06767050921916962
step: 520, loss: 0.0004964246763847768
step: 530, loss: 0.01976034604012966
step: 540, loss: 0.020335456356406212
step: 550, loss: 0.0235532708466053
step: 560, loss: 0.053910788148641586
step: 570, loss: 0.04264380782842636
step: 580, loss: 0.0020021747332066298
step: 590, loss: 0.02569698728621006
step: 600, loss: 0.030080055817961693
step: 610, loss: 0.03565901517868042
step: 620, loss: 0.09817520529031754
step: 630, loss: 0.01062453631311655
step: 640, loss: 0.012442657724022865
step: 650, loss: 0.014197926968336105
step: 660, loss: 0.03319490700960159
step: 670, loss: 0.03560338169336319
step: 680, loss: 0.06256214529275894
step: 690, loss: 0.002321072854101658
step: 700, loss: 0.02368767559528351
step: 710, loss: 0.040913987904787064
step: 720, loss: 0.008798561058938503
step: 730, loss: 0.08832824230194092
step: 740, loss: 0.050192639231681824
step: 750, loss: 0.03263034299015999
step: 760, loss: 0.0021828950848430395
step: 770, loss: 0.03089144080877304
step: 780, loss: 0.05460039898753166
step: 790, loss: 0.004837317857891321
step: 800, loss: 0.006645568180829287
step: 810, loss: 0.010920402593910694
step: 820, loss: 0.058666449040174484
step: 830, loss: 0.001677522319369018
step: 840, loss: 0.05882292613387108
step: 850, loss: 0.03628694638609886
step: 860, loss: 0.0861496552824974
step: 870, loss: 0.07443574070930481
step: 880, loss: 0.01323191449046135
step: 890, loss: 0.08286212384700775
step: 900, loss: 0.010248612612485886
step: 910, loss: 0.05305596441030502
step: 920, loss: 0.0001791163085727021
step: 930, loss: 0.001145020010881126
step: 940, loss: 0.03590128943324089
step: 950, loss: 0.03181217983365059
step: 960, loss: 0.013333200477063656
step: 970, loss: 0.03927428647875786
step: 980, loss: 0.04416349530220032
step: 990, loss: 0.039818499237298965
step: 1000, loss: 0.021647075191140175
step: 1010, loss: 0.05670496076345444
step: 1020, loss: 0.037099387496709824
step: 1030, loss: 0.03725283220410347
step: 1040, loss: 0.004724379628896713
step: 1050, loss: 0.10372506082057953
step: 1060, loss: 0.028009124100208282
step: 1070, loss: 0.04330223798751831
epoch 12: dev_f1=0.9317865429234339, f1=0.9336426914153132, best_f1=0.9397371998187584
step: 0, loss: 0.04186432436108589
step: 10, loss: 0.02660723403096199
step: 20, loss: 4.0309474570676684e-05
step: 30, loss: 0.00030826329020783305
step: 40, loss: 0.04327690973877907
step: 50, loss: 0.005504830274730921
step: 60, loss: 0.00027368622249923646
step: 70, loss: 0.007668942678719759
step: 80, loss: 0.012521722353994846
step: 90, loss: 0.029484866186976433
step: 100, loss: 0.051628194749355316
step: 110, loss: 0.015097364783287048
step: 120, loss: 0.0003447695926297456
step: 130, loss: 0.002769337734207511
step: 140, loss: 0.028490804135799408
step: 150, loss: 0.0006399877020157874
step: 160, loss: 0.0003529200912453234
step: 170, loss: 0.02161698415875435
step: 180, loss: 0.07060229778289795
step: 190, loss: 0.1120212972164154
step: 200, loss: 0.062012914568185806
step: 210, loss: 0.036113422363996506
step: 220, loss: 0.02805081382393837
step: 230, loss: 0.052563704550266266
step: 240, loss: 0.17389555275440216
step: 250, loss: 0.04335913434624672
step: 260, loss: 0.06992688030004501
step: 270, loss: 0.09188372641801834
step: 280, loss: 0.0971422791481018
step: 290, loss: 0.02065434493124485
step: 300, loss: 0.0011422765674069524
step: 310, loss: 6.695636693621054e-05
step: 320, loss: 0.0009600406629033387
step: 330, loss: 0.03806326538324356
step: 340, loss: 0.02360854484140873
step: 350, loss: 0.09110131114721298
step: 360, loss: 0.13353446125984192
step: 370, loss: 0.0402311347424984
step: 380, loss: 0.027842285111546516
step: 390, loss: 0.0025667857844382524
step: 400, loss: 0.0004028440162073821
step: 410, loss: 0.01170347724109888
step: 420, loss: 0.16131460666656494
step: 430, loss: 0.027635179460048676
step: 440, loss: 0.022958695888519287
step: 450, loss: 0.019109245389699936
step: 460, loss: 0.008686559274792671
step: 470, loss: 0.04217711463570595
step: 480, loss: 0.028683429583907127
step: 490, loss: 0.04521360248327255
step: 500, loss: 0.02201465144753456
step: 510, loss: 3.90075147151947e-05
step: 520, loss: 0.020973006263375282
step: 530, loss: 0.0009046668419614434
step: 540, loss: 0.07796826958656311
step: 550, loss: 0.05319376289844513
step: 560, loss: 0.05059241130948067
step: 570, loss: 0.05397878959774971
step: 580, loss: 0.017161285504698753
step: 590, loss: 0.04564042016863823
step: 600, loss: 0.036636270582675934
step: 610, loss: 0.030101489275693893
step: 620, loss: 0.0068436358124017715
step: 630, loss: 0.04103673994541168
step: 640, loss: 0.0236071664839983
step: 650, loss: 0.02511126734316349
step: 660, loss: 0.0016383043257519603
step: 670, loss: 0.012545660138130188
step: 680, loss: 0.05836964026093483
step: 690, loss: 0.07375805079936981
step: 700, loss: 0.09394356608390808
step: 710, loss: 0.007907013408839703
step: 720, loss: 0.06406188756227493
step: 730, loss: 0.027334053069353104
step: 740, loss: 0.029368840157985687
step: 750, loss: 0.10096801072359085
step: 760, loss: 0.08634500950574875
step: 770, loss: 0.1283801943063736
step: 780, loss: 0.00019551640434656292
step: 790, loss: 0.027244271710515022
step: 800, loss: 0.04323306307196617
step: 810, loss: 0.02209940366446972
step: 820, loss: 0.000575705140363425
step: 830, loss: 0.020706485956907272
step: 840, loss: 0.00030842129490338266
step: 850, loss: 0.025895856320858
step: 860, loss: 0.03864019736647606
step: 870, loss: 0.036998920142650604
step: 880, loss: 0.06551460176706314
step: 890, loss: 1.823114689614158e-05
step: 900, loss: 0.02215813845396042
step: 910, loss: 0.03620396926999092
step: 920, loss: 0.013738414272665977
step: 930, loss: 0.052277397364377975
step: 940, loss: 0.06794052571058273
step: 950, loss: 3.53670293407049e-05
step: 960, loss: 0.01280679926276207
step: 970, loss: 0.03626205399632454
step: 980, loss: 0.056805361062288284
step: 990, loss: 0.027720404788851738
step: 1000, loss: 0.041047047823667526
step: 1010, loss: 0.061226509511470795
step: 1020, loss: 0.031527552753686905
step: 1030, loss: 0.020416053012013435
step: 1040, loss: 0.24246066808700562
step: 1050, loss: 0.14809800684452057
step: 1060, loss: 0.055555619299411774
step: 1070, loss: 0.008428237400949001
epoch 13: dev_f1=0.929245283018868, f1=0.9237248479176415, best_f1=0.9397371998187584
step: 0, loss: 0.0061650569550693035
step: 10, loss: 0.0018997220322489738
step: 20, loss: 0.08812537044286728
step: 30, loss: 0.00012633641017600894
step: 40, loss: 0.06150813400745392
step: 50, loss: 0.013002169318497181
step: 60, loss: 0.019014805555343628
step: 70, loss: 0.007885848172008991
step: 80, loss: 0.017907677218317986
step: 90, loss: 0.017894677817821503
step: 100, loss: 0.0737241581082344
step: 110, loss: 0.000217080902075395
step: 120, loss: 0.020887048915028572
step: 130, loss: 5.83871515118517e-05
step: 140, loss: 0.0002082763094222173
step: 150, loss: 0.0424581877887249
step: 160, loss: 0.005327282473444939
step: 170, loss: 0.10493286699056625
step: 180, loss: 0.031295955181121826
step: 190, loss: 0.006207558326423168
step: 200, loss: 0.04158080369234085
step: 210, loss: 0.045373301953077316
step: 220, loss: 0.01046055555343628
step: 230, loss: 0.10366590321063995
step: 240, loss: 0.0006744718994013965
step: 250, loss: 0.3081474304199219
step: 260, loss: 0.011675643734633923
step: 270, loss: 0.0004070622962899506
step: 280, loss: 0.045537207275629044
step: 290, loss: 0.024824127554893494
step: 300, loss: 0.018083442002534866
step: 310, loss: 0.029738785699009895
step: 320, loss: 0.026040401309728622
step: 330, loss: 0.020587336272001266
step: 340, loss: 0.019783224910497665
step: 350, loss: 0.016740690916776657
step: 360, loss: 0.030056040734052658
step: 370, loss: 0.0047308942303061485
step: 380, loss: 0.029522985219955444
step: 390, loss: 0.0021211167331784964
step: 400, loss: 0.0316489040851593
step: 410, loss: 0.03292093053460121
step: 420, loss: 0.036622196435928345
step: 430, loss: 0.02293786033987999
step: 440, loss: 0.017153047025203705
step: 450, loss: 0.0391000397503376
step: 460, loss: 0.002418168820440769
step: 470, loss: 9.102710464503616e-05
step: 480, loss: 0.04563751816749573
step: 490, loss: 0.004448610357940197
step: 500, loss: 0.021475398913025856
step: 510, loss: 0.07967088371515274
step: 520, loss: 0.017375990748405457
step: 530, loss: 0.019894666969776154
step: 540, loss: 0.000529183482285589
step: 550, loss: 0.06961357593536377
step: 560, loss: 0.024536380544304848
step: 570, loss: 0.008707159198820591
step: 580, loss: 0.0411478616297245
step: 590, loss: 0.06999637186527252
step: 600, loss: 0.023872410878539085
step: 610, loss: 0.0001593820925336331
step: 620, loss: 0.0011082960991188884
step: 630, loss: 0.015845516696572304
step: 640, loss: 0.08415906131267548
step: 650, loss: 0.021147213876247406
step: 660, loss: 0.030252620577812195
step: 670, loss: 0.010831809602677822
step: 680, loss: 0.04693401977419853
step: 690, loss: 5.71066266275011e-05
step: 700, loss: 0.1068943440914154
step: 710, loss: 0.0001659118861425668
step: 720, loss: 0.003015770809724927
step: 730, loss: 0.04859193041920662
step: 740, loss: 0.11727334558963776
step: 750, loss: 0.026389118283987045
step: 760, loss: 0.0542670413851738
step: 770, loss: 0.004577836021780968
step: 780, loss: 0.016795963048934937
step: 790, loss: 0.017879793420433998
step: 800, loss: 0.02528264932334423
step: 810, loss: 0.022284703329205513
step: 820, loss: 2.684638457139954e-05
step: 830, loss: 0.0718071386218071
step: 840, loss: 0.03143744915723801
step: 850, loss: 0.018767165020108223
step: 860, loss: 0.027236970141530037
step: 870, loss: 0.0960533395409584
step: 880, loss: 0.009642996825277805
step: 890, loss: 0.02513905242085457
step: 900, loss: 0.0014585101744160056
step: 910, loss: 0.09041967242956161
step: 920, loss: 0.047024205327034
step: 930, loss: 0.026436209678649902
step: 940, loss: 0.0013997791102156043
step: 950, loss: 0.04364902898669243
step: 960, loss: 0.03677918016910553
step: 970, loss: 0.02521100454032421
step: 980, loss: 0.0005453065386973321
step: 990, loss: 0.010430529713630676
step: 1000, loss: 0.00019086965767201036
step: 1010, loss: 0.033392708748579025
step: 1020, loss: 0.04709666967391968
step: 1030, loss: 0.005944112781435251
step: 1040, loss: 0.0030421107076108456
step: 1050, loss: 0.0033628118690103292
step: 1060, loss: 0.031458329409360886
step: 1070, loss: 0.015104567632079124
epoch 14: dev_f1=0.9321478708469817, f1=0.927806241266884, best_f1=0.9397371998187584
step: 0, loss: 0.00020918180234730244
step: 10, loss: 7.943396485643461e-05
step: 20, loss: 0.02108064666390419
step: 30, loss: 0.0009671213920228183
step: 40, loss: 0.0030431379564106464
step: 50, loss: 0.00048126772162504494
step: 60, loss: 0.05788503214716911
step: 70, loss: 0.00024330534506589174
step: 80, loss: 0.02766021527349949
step: 90, loss: 0.028124557808041573
step: 100, loss: 0.0005105685559101403
step: 110, loss: 0.00010907784599112347
step: 120, loss: 0.018780628219246864
step: 130, loss: 0.02264963835477829
step: 140, loss: 0.0007247989997267723
step: 150, loss: 0.00025667771114967763
step: 160, loss: 0.0032225993927568197
step: 170, loss: 0.028501514345407486
step: 180, loss: 0.004355843644589186
step: 190, loss: 0.01879795826971531
step: 200, loss: 0.023702025413513184
step: 210, loss: 0.01987435668706894
step: 220, loss: 0.00011028160952264443
step: 230, loss: 0.004061347804963589
step: 240, loss: 0.06257320940494537
step: 250, loss: 1.523626360722119e-05
step: 260, loss: 0.00018213911971542984
step: 270, loss: 0.056174136698246
step: 280, loss: 0.01912851631641388
step: 290, loss: 0.009127456694841385
step: 300, loss: 0.07481890916824341
step: 310, loss: 0.034484148025512695
step: 320, loss: 0.020564556121826172
step: 330, loss: 0.005308086052536964
step: 340, loss: 0.0654284805059433
step: 350, loss: 0.02205241657793522
step: 360, loss: 0.037186961621046066
step: 370, loss: 0.06092040613293648
step: 380, loss: 1.3664227481058333e-05
step: 390, loss: 0.017604028806090355
step: 400, loss: 0.046950433403253555
step: 410, loss: 9.524000051897019e-05
step: 420, loss: 0.09633718430995941
step: 430, loss: 0.0751470997929573
step: 440, loss: 0.05593385919928551
step: 450, loss: 0.020508665591478348
step: 460, loss: 0.028008373454213142
step: 470, loss: 6.190480780787766e-05
step: 480, loss: 0.08252174407243729
step: 490, loss: 0.01854870654642582
step: 500, loss: 0.057618170976638794
step: 510, loss: 0.016828658059239388
step: 520, loss: 0.020199665799736977
step: 530, loss: 0.17125529050827026
step: 540, loss: 0.025811148807406425
step: 550, loss: 0.018042907118797302
step: 560, loss: 0.06138036027550697
step: 570, loss: 0.0305790975689888
step: 580, loss: 0.05925625190138817
step: 590, loss: 0.00033555718255229294
step: 600, loss: 0.007567317225039005
step: 610, loss: 0.00017226417548954487
step: 620, loss: 0.046996280550956726
step: 630, loss: 0.02308601886034012
step: 640, loss: 0.0013081225333735347
step: 650, loss: 0.046695537865161896
step: 660, loss: 0.041733648627996445
step: 670, loss: 0.044581089168787
step: 680, loss: 0.04190712049603462
step: 690, loss: 0.00010517059854464605
step: 700, loss: 0.018667303025722504
step: 710, loss: 0.02650633081793785
step: 720, loss: 0.03237146884202957
step: 730, loss: 0.05226118117570877
step: 740, loss: 0.020378459244966507
step: 750, loss: 0.01885121874511242
step: 760, loss: 0.008589274249970913
step: 770, loss: 0.020657675340771675
step: 780, loss: 0.05804477259516716
step: 790, loss: 6.48392378934659e-05
step: 800, loss: 0.020888516679406166
step: 810, loss: 0.04132718965411186
step: 820, loss: 0.07616202533245087
step: 830, loss: 0.043990232050418854
step: 840, loss: 0.0011232717661187053
step: 850, loss: 0.03327987715601921
step: 860, loss: 0.04112475737929344
step: 870, loss: 0.008752127178013325
step: 880, loss: 0.05276457965373993
step: 890, loss: 0.06333912909030914
step: 900, loss: 0.00811511930078268
step: 910, loss: 0.01845313049852848
step: 920, loss: 0.0015506595373153687
step: 930, loss: 0.029131893068552017
step: 940, loss: 0.05230947956442833
step: 950, loss: 0.01927262917160988
step: 960, loss: 0.06656334549188614
step: 970, loss: 0.05298760160803795
step: 980, loss: 0.0001809076638892293
step: 990, loss: 0.04329442232847214
step: 1000, loss: 0.003277622628957033
step: 1010, loss: 0.07025305926799774
step: 1020, loss: 0.0221953634172678
step: 1030, loss: 0.00016534898895770311
step: 1040, loss: 0.020191313698887825
step: 1050, loss: 0.03263968229293823
step: 1060, loss: 0.010412320494651794
step: 1070, loss: 0.03305315971374512
epoch 15: dev_f1=0.9296947271045328, f1=0.923076923076923, best_f1=0.9397371998187584
step: 0, loss: 0.0036556946579366922
step: 10, loss: 0.0012811219785362482
step: 20, loss: 0.0037444711197167635
step: 30, loss: 0.019990945234894753
step: 40, loss: 0.0006337125087156892
step: 50, loss: 0.02108798176050186
step: 60, loss: 0.002705455059185624
step: 70, loss: 0.03797721117734909
step: 80, loss: 0.03396731987595558
step: 90, loss: 0.02248937077820301
step: 100, loss: 0.08400758355855942
step: 110, loss: 0.05457182973623276
step: 120, loss: 0.07440952211618423
step: 130, loss: 0.016729120165109634
step: 140, loss: 0.023741690441966057
step: 150, loss: 0.038857173174619675
step: 160, loss: 0.016432009637355804
step: 170, loss: 0.0005924389115534723
step: 180, loss: 0.0714956596493721
step: 190, loss: 0.03245798125863075
step: 200, loss: 0.03858509287238121
step: 210, loss: 0.01828143000602722
step: 220, loss: 0.010868385434150696
step: 230, loss: 0.0703074187040329
step: 240, loss: 0.022178081795573235
step: 250, loss: 0.04909167066216469
step: 260, loss: 0.05238598585128784
step: 270, loss: 0.04738064855337143
step: 280, loss: 0.020781679078936577
step: 290, loss: 5.509558104677126e-05
step: 300, loss: 0.01389960665255785
step: 310, loss: 0.04982325807213783
step: 320, loss: 0.019065532833337784
step: 330, loss: 0.01780126802623272
step: 340, loss: 0.023389598354697227
step: 350, loss: 0.014893307350575924
step: 360, loss: 3.38394966092892e-05
step: 370, loss: 3.8381509511964396e-05
step: 380, loss: 0.0597849115729332
step: 390, loss: 0.028218118473887444
step: 400, loss: 0.043904077261686325
step: 410, loss: 0.1369423121213913
step: 420, loss: 0.011571263894438744
step: 430, loss: 5.1384013204369694e-05
step: 440, loss: 1.6990712538245134e-05
step: 450, loss: 0.00013006897643208504
step: 460, loss: 0.04625618830323219
step: 470, loss: 0.09202875196933746
step: 480, loss: 0.07607940584421158
step: 490, loss: 0.09988294541835785
step: 500, loss: 0.018880996853113174
step: 510, loss: 0.02163175493478775
step: 520, loss: 0.0503719300031662
step: 530, loss: 9.549274545861408e-05
step: 540, loss: 0.011658119969069958
step: 550, loss: 0.0007922302465885878
step: 560, loss: 0.00011354260641383007
step: 570, loss: 0.093996062874794
step: 580, loss: 0.09113402664661407
step: 590, loss: 0.040995042771101
step: 600, loss: 0.04941181838512421
step: 610, loss: 0.02557019330561161
step: 620, loss: 0.0006652178708463907
step: 630, loss: 0.025619996711611748
step: 640, loss: 4.897553299088031e-05
step: 650, loss: 0.0001342573668807745
step: 660, loss: 0.01269414834678173
step: 670, loss: 0.03558391332626343
step: 680, loss: 0.08360867202281952
step: 690, loss: 8.216709829866886e-05
step: 700, loss: 0.0005203354521654546
step: 710, loss: 0.06954094022512436
step: 720, loss: 0.023658281192183495
step: 730, loss: 0.00015252480807248503
step: 740, loss: 0.028219766914844513
step: 750, loss: 9.914668771671131e-05
step: 760, loss: 0.0010787458159029484
step: 770, loss: 0.028364848345518112
step: 780, loss: 0.03052506595849991
step: 790, loss: 0.04053964465856552
step: 800, loss: 0.0813196450471878
step: 810, loss: 2.55129489232786e-05
step: 820, loss: 0.028073199093341827
step: 830, loss: 0.05569500848650932
step: 840, loss: 0.05063818395137787
step: 850, loss: 0.07249835878610611
step: 860, loss: 0.020154835656285286
step: 870, loss: 0.015548036433756351
step: 880, loss: 0.05313701927661896
step: 890, loss: 0.004216534551233053
step: 900, loss: 0.020052393898367882
step: 910, loss: 0.0027819143142551184
step: 920, loss: 0.0012941653840243816
step: 930, loss: 0.02933472953736782
step: 940, loss: 0.015549497678875923
step: 950, loss: 0.027063623070716858
step: 960, loss: 0.04768092930316925
step: 970, loss: 0.017600135877728462
step: 980, loss: 0.0377739816904068
step: 990, loss: 3.641042349045165e-05
step: 1000, loss: 0.009451034478843212
step: 1010, loss: 0.00010512036533327773
step: 1020, loss: 0.03891824558377266
step: 1030, loss: 0.0010917183244600892
step: 1040, loss: 0.12303579598665237
step: 1050, loss: 0.044845033437013626
step: 1060, loss: 0.0163206048309803
step: 1070, loss: 0.06295792758464813
epoch 16: dev_f1=0.933826931975937, f1=0.9243542435424354, best_f1=0.9397371998187584
step: 0, loss: 0.05912470072507858
step: 10, loss: 0.04872343689203262
step: 20, loss: 0.0667634904384613
step: 30, loss: 0.05595178157091141
step: 40, loss: 0.04873061925172806
step: 50, loss: 0.023744486272335052
step: 60, loss: 0.04711657389998436
step: 70, loss: 8.839301153784618e-05
step: 80, loss: 0.03263355419039726
step: 90, loss: 0.0012251579901203513
step: 100, loss: 6.188700353959575e-05
step: 110, loss: 2.366169610468205e-05
step: 120, loss: 5.654369670082815e-05
step: 130, loss: 0.12303754687309265
step: 140, loss: 0.019675010815262794
step: 150, loss: 0.00025056273443624377
step: 160, loss: 0.02490568533539772
step: 170, loss: 0.06337953358888626
step: 180, loss: 0.00013947549450676888
step: 190, loss: 0.06063031405210495
step: 200, loss: 2.9591852580779232e-05
step: 210, loss: 0.026864489540457726
step: 220, loss: 0.062492672353982925
step: 230, loss: 0.018538402393460274
step: 240, loss: 0.024257812649011612
step: 250, loss: 0.04168761149048805
step: 260, loss: 0.01920650340616703
step: 270, loss: 0.025013376027345657
step: 280, loss: 0.06033167615532875
step: 290, loss: 0.06473397463560104
step: 300, loss: 0.022607803344726562
step: 310, loss: 0.08907924592494965
step: 320, loss: 1.6785867046564817e-05
step: 330, loss: 0.06911810487508774
step: 340, loss: 0.0004692802031058818
step: 350, loss: 0.03353235498070717
step: 360, loss: 0.0004137952928431332
step: 370, loss: 4.3225198169238865e-05
step: 380, loss: 0.0026792834978550673
step: 390, loss: 0.025164034217596054
step: 400, loss: 0.05449856445193291
step: 410, loss: 0.0006247889832593501
step: 420, loss: 0.0005147077026776969
step: 430, loss: 0.0013832806143909693
step: 440, loss: 0.06408201158046722
step: 450, loss: 0.043772242963314056
step: 460, loss: 0.07379988580942154
step: 470, loss: 0.003930510953068733
step: 480, loss: 0.03614991530776024
step: 490, loss: 8.680215978529304e-05
step: 500, loss: 4.862213972955942e-05
step: 510, loss: 0.02382293902337551
step: 520, loss: 0.0004518349887803197
step: 530, loss: 0.012122426182031631
step: 540, loss: 3.395585372345522e-05
step: 550, loss: 0.021372800692915916
step: 560, loss: 3.504316191538237e-05
step: 570, loss: 0.09575259685516357
step: 580, loss: 0.02484583668410778
step: 590, loss: 0.02477969415485859
step: 600, loss: 0.024446876719594002
step: 610, loss: 0.0009921141900122166
step: 620, loss: 0.00012963969493284822
step: 630, loss: 0.021460993215441704
step: 640, loss: 5.2341300033731386e-05
step: 650, loss: 0.09100384265184402
step: 660, loss: 0.0003980670007877052
step: 670, loss: 0.010517222806811333
step: 680, loss: 0.000919373647775501
step: 690, loss: 0.0030575613491237164
step: 700, loss: 0.0702868402004242
step: 710, loss: 6.446662882808596e-05
step: 720, loss: 4.837840242544189e-05
step: 730, loss: 0.07929727435112
step: 740, loss: 0.017837554216384888
step: 750, loss: 0.024237094447016716
step: 760, loss: 0.03756337612867355
step: 770, loss: 0.029593298211693764
step: 780, loss: 0.04476653039455414
step: 790, loss: 0.01837301440536976
step: 800, loss: 6.353566277539358e-05
step: 810, loss: 1.3891431080992334e-05
step: 820, loss: 0.023949265480041504
step: 830, loss: 0.021149849519133568
step: 840, loss: 1.7910828319145367e-05
step: 850, loss: 0.02492137812077999
step: 860, loss: 1.9083696315647103e-05
step: 870, loss: 0.03639047220349312
step: 880, loss: 0.022916896268725395
step: 890, loss: 7.641972479177639e-05
step: 900, loss: 0.05364978313446045
step: 910, loss: 0.0016513722948729992
step: 920, loss: 1.4580515198758803e-05
step: 930, loss: 0.00013725091412197798
step: 940, loss: 0.00015224934031721205
step: 950, loss: 0.08925791829824448
step: 960, loss: 8.839365909807384e-05
step: 970, loss: 0.024499274790287018
step: 980, loss: 0.04457230493426323
step: 990, loss: 0.0005010592867620289
step: 1000, loss: 0.029935291036963463
step: 1010, loss: 0.08579430729150772
step: 1020, loss: 0.00020136831153649837
step: 1030, loss: 0.016999874264001846
step: 1040, loss: 0.01448657177388668
step: 1050, loss: 0.04837260767817497
step: 1060, loss: 7.207683665910736e-05
step: 1070, loss: 0.022284356877207756
epoch 17: dev_f1=0.9284403669724771, f1=0.9260948905109488, best_f1=0.9397371998187584
step: 0, loss: 6.279916851781309e-05
step: 10, loss: 0.05326884984970093
step: 20, loss: 0.03507308289408684
step: 30, loss: 1.373121722281212e-05
step: 40, loss: 0.031100532039999962
step: 50, loss: 0.02483283542096615
step: 60, loss: 0.02239949069917202
step: 70, loss: 3.020189978997223e-05
step: 80, loss: 0.02626950293779373
step: 90, loss: 0.052639368921518326
step: 100, loss: 0.025588085874915123
step: 110, loss: 0.02768118679523468
step: 120, loss: 2.524080264265649e-05
step: 130, loss: 3.467038186499849e-05
step: 140, loss: 0.013796660117805004
step: 150, loss: 0.015176751650869846
step: 160, loss: 0.014551344327628613
step: 170, loss: 0.010664363391697407
step: 180, loss: 0.05013792961835861
step: 190, loss: 3.821731297648512e-05
step: 200, loss: 0.02585737593472004
step: 210, loss: 0.025523336604237556
step: 220, loss: 0.07256527245044708
step: 230, loss: 4.016175080323592e-05
step: 240, loss: 0.0447232685983181
step: 250, loss: 0.012239092960953712
step: 260, loss: 0.012228460982441902
step: 270, loss: 1.138439984060824e-05
step: 280, loss: 2.844955088221468e-05
step: 290, loss: 0.03465595841407776
step: 300, loss: 0.01838318258523941
step: 310, loss: 0.03993618115782738
step: 320, loss: 0.04919394850730896
step: 330, loss: 0.06715410202741623
step: 340, loss: 2.1877714971196838e-05
step: 350, loss: 0.041317857801914215
step: 360, loss: 0.05444588139653206
step: 370, loss: 0.045427415519952774
step: 380, loss: 0.019058166071772575
step: 390, loss: 0.04163215681910515
step: 400, loss: 0.021372979506850243
step: 410, loss: 0.0694316104054451
step: 420, loss: 0.0009962578769773245
step: 430, loss: 0.030013564974069595
step: 440, loss: 0.09888546168804169
step: 450, loss: 2.7972288080491126e-05
step: 460, loss: 0.00514658959582448
step: 470, loss: 0.016131579875946045
step: 480, loss: 0.04080629348754883
step: 490, loss: 0.04486774653196335
step: 500, loss: 0.12402912974357605
step: 510, loss: 0.043576430529356
step: 520, loss: 0.03321896493434906
step: 530, loss: 0.06317521631717682
step: 540, loss: 0.018867524340748787
step: 550, loss: 0.03991900011897087
step: 560, loss: 0.020969567820429802
step: 570, loss: 0.03729705512523651
step: 580, loss: 0.026441605761647224
step: 590, loss: 0.008247990161180496
step: 600, loss: 1.5455732864211313e-05
step: 610, loss: 0.014660782180726528
step: 620, loss: 0.025871122255921364
step: 630, loss: 0.021488429978489876
step: 640, loss: 0.03360576182603836
step: 650, loss: 7.274502422660589e-05
step: 660, loss: 5.5589240218978375e-05
step: 670, loss: 0.12436798214912415
step: 680, loss: 0.02217215858399868
step: 690, loss: 0.03449924662709236
step: 700, loss: 0.000425721169449389
step: 710, loss: 0.02050577662885189
step: 720, loss: 0.06243336573243141
step: 730, loss: 0.021308142691850662
step: 740, loss: 0.04322829470038414
step: 750, loss: 0.046890199184417725
step: 760, loss: 5.159955981071107e-05
step: 770, loss: 0.024557143449783325
step: 780, loss: 0.023110447451472282
step: 790, loss: 0.056290727108716965
step: 800, loss: 0.025178086012601852
step: 810, loss: 3.291087705292739e-05
step: 820, loss: 0.02512851171195507
step: 830, loss: 0.004963202867656946
step: 840, loss: 5.5844648159109056e-05
step: 850, loss: 0.0216059647500515
step: 860, loss: 0.04819761589169502
step: 870, loss: 0.03463314101099968
step: 880, loss: 9.379428956890479e-05
step: 890, loss: 0.00030740612419322133
step: 900, loss: 0.08799140900373459
step: 910, loss: 0.06381348520517349
step: 920, loss: 0.0026593198999762535
step: 930, loss: 0.022531216964125633
step: 940, loss: 0.048411302268505096
step: 950, loss: 0.017132733017206192
step: 960, loss: 0.015599445439875126
step: 970, loss: 2.797474735416472e-05
step: 980, loss: 0.06387148052453995
step: 990, loss: 0.02097415365278721
step: 1000, loss: 0.00013376858260016888
step: 1010, loss: 0.00033667689422145486
step: 1020, loss: 1.7165744793601334e-05
step: 1030, loss: 1.3630576177092735e-05
step: 1040, loss: 0.11475301533937454
step: 1050, loss: 0.022497503086924553
step: 1060, loss: 0.03646347299218178
step: 1070, loss: 0.022912969812750816
epoch 18: dev_f1=0.9319227230910764, f1=0.9268069533394326, best_f1=0.9397371998187584
step: 0, loss: 0.044351812452077866
step: 10, loss: 0.00015126726066228002
step: 20, loss: 0.04328261688351631
step: 30, loss: 0.01598714292049408
step: 40, loss: 0.02146756649017334
step: 50, loss: 0.00038991737528704107
step: 60, loss: 0.022451382130384445
step: 70, loss: 2.7613345082500018e-05
step: 80, loss: 0.027895724400877953
step: 90, loss: 8.242038893513381e-05
step: 100, loss: 0.02425512671470642
step: 110, loss: 0.0018976745195686817
step: 120, loss: 0.054801080375909805
step: 130, loss: 0.0002838457003235817
step: 140, loss: 0.016682786867022514
step: 150, loss: 0.02345884218811989
step: 160, loss: 1.7094705981435254e-05
step: 170, loss: 0.0012918615248054266
step: 180, loss: 0.08374379575252533
step: 190, loss: 1.0538775313762017e-05
step: 200, loss: 5.7298457249999046e-05
step: 210, loss: 0.0005310626002028584
step: 220, loss: 0.00042558359564282
step: 230, loss: 0.03890453279018402
step: 240, loss: 0.0026711407117545605
step: 250, loss: 0.010586435906589031
step: 260, loss: 0.052066851407289505
step: 270, loss: 0.018362680450081825
step: 280, loss: 3.6516867112368345e-05
step: 290, loss: 0.0213019996881485
step: 300, loss: 0.05857570096850395
step: 310, loss: 0.08313504606485367
step: 320, loss: 0.0011558191617950797
step: 330, loss: 0.03755143657326698
step: 340, loss: 0.04814327880740166
step: 350, loss: 0.02948618493974209
step: 360, loss: 1.7541675333632156e-05
step: 370, loss: 0.022144537419080734
step: 380, loss: 0.09293147921562195
step: 390, loss: 1.242731923412066e-05
step: 400, loss: 0.025937382131814957
step: 410, loss: 0.050263188779354095
step: 420, loss: 0.09602484852075577
step: 430, loss: 0.03196610137820244
step: 440, loss: 0.04332827404141426
step: 450, loss: 0.000491587445139885
step: 460, loss: 0.019194940105080605
step: 470, loss: 0.02246692031621933
step: 480, loss: 0.02015204168856144
step: 490, loss: 1.5895484466454946e-05
step: 500, loss: 0.043573684990406036
step: 510, loss: 0.06999918073415756
step: 520, loss: 0.000437707407400012
step: 530, loss: 0.05903857573866844
step: 540, loss: 0.021516941487789154
step: 550, loss: 0.04735434055328369
step: 560, loss: 0.02188134752213955
step: 570, loss: 9.838424375629984e-06
step: 580, loss: 0.027695011347532272
step: 590, loss: 0.22829784452915192
step: 600, loss: 0.006440097000449896
step: 610, loss: 0.02637680619955063
step: 620, loss: 0.01516389474272728
step: 630, loss: 0.06135319918394089
step: 640, loss: 0.041376467794179916
step: 650, loss: 0.03299980238080025
step: 660, loss: 0.04308827221393585
step: 670, loss: 1.772426548996009e-05
step: 680, loss: 0.03672273829579353
step: 690, loss: 0.06184270977973938
step: 700, loss: 1.9132236047880724e-05
step: 710, loss: 1.1145958524139132e-05
step: 720, loss: 0.0671590119600296
step: 730, loss: 0.061634428799152374
step: 740, loss: 6.754900823580101e-05
step: 750, loss: 0.022824522107839584
step: 760, loss: 0.025086019188165665
step: 770, loss: 0.022420231252908707
step: 780, loss: 0.03330204263329506
step: 790, loss: 0.004980374593287706
step: 800, loss: 0.019380293786525726
step: 810, loss: 0.05559157207608223
step: 820, loss: 0.016818365082144737
step: 830, loss: 3.0101531592663378e-05
step: 840, loss: 0.020185308530926704
step: 850, loss: 0.061016008257865906
step: 860, loss: 0.03141813725233078
step: 870, loss: 0.03769177943468094
step: 880, loss: 0.07324060052633286
step: 890, loss: 0.05221868306398392
step: 900, loss: 0.026964891701936722
step: 910, loss: 0.024634916335344315
step: 920, loss: 4.6774490328971297e-05
step: 930, loss: 0.015483878552913666
step: 940, loss: 0.04526475444436073
step: 950, loss: 0.023347562178969383
step: 960, loss: 0.023973045870661736
step: 970, loss: 0.028696445748209953
step: 980, loss: 0.02046678587794304
step: 990, loss: 0.00010020346962846816
step: 1000, loss: 1.2904264622193296e-05
step: 1010, loss: 0.00012895280087832361
step: 1020, loss: 0.05012243986129761
step: 1030, loss: 0.00044074744801037014
step: 1040, loss: 0.0023367241956293583
step: 1050, loss: 0.02066873013973236
step: 1060, loss: 7.671218190807849e-05
step: 1070, loss: 0.04857652261853218
epoch 19: dev_f1=0.9290681502086231, f1=0.9260450160771704, best_f1=0.9397371998187584
step: 0, loss: 1.928518759086728e-05
step: 10, loss: 0.04013876989483833
step: 20, loss: 0.00047451441059820354
step: 30, loss: 0.02406114712357521
step: 40, loss: 1.977326610358432e-05
step: 50, loss: 0.08832360059022903
step: 60, loss: 0.046178534626960754
step: 70, loss: 0.026178525760769844
step: 80, loss: 2.2391432139556855e-05
step: 90, loss: 4.994816117687151e-05
step: 100, loss: 0.04379386827349663
step: 110, loss: 3.856479816022329e-05
step: 120, loss: 0.056330882012844086
step: 130, loss: 0.019592853263020515
step: 140, loss: 0.051097702234983444
step: 150, loss: 0.04207656905055046
step: 160, loss: 0.0006350438925437629
step: 170, loss: 0.007736507337540388
step: 180, loss: 0.08420130610466003
step: 190, loss: 0.012001264840364456
step: 200, loss: 5.8608489780453965e-05
step: 210, loss: 0.00010814309644047171
step: 220, loss: 0.07797043025493622
step: 230, loss: 0.0366201177239418
step: 240, loss: 0.021373389288783073
step: 250, loss: 3.873561217915267e-05
step: 260, loss: 0.0249831173568964
step: 270, loss: 1.659177360124886e-05
step: 280, loss: 0.030710620805621147
step: 290, loss: 3.94865965063218e-05
step: 300, loss: 0.01987580396234989
step: 310, loss: 0.04187392070889473
step: 320, loss: 0.05743672698736191
step: 330, loss: 0.014576749876141548
step: 340, loss: 5.8177905884804204e-05
step: 350, loss: 0.030154338106513023
step: 360, loss: 0.034839432686567307
step: 370, loss: 3.475082849035971e-05
step: 380, loss: 3.303875564597547e-05
step: 390, loss: 2.8268956157262437e-05
step: 400, loss: 0.023761961609125137
step: 410, loss: 1.9083852748735808e-05
step: 420, loss: 0.04125180467963219
step: 430, loss: 1.9221230104449205e-05
step: 440, loss: 0.018596481531858444
step: 450, loss: 0.05842093750834465
step: 460, loss: 0.0010397210717201233
step: 470, loss: 0.0137809868901968
step: 480, loss: 0.0016014274442568421
step: 490, loss: 0.04111999273300171
step: 500, loss: 0.05239580571651459
step: 510, loss: 0.04742525890469551
step: 520, loss: 3.291374378022738e-05
step: 530, loss: 0.018829574808478355
step: 540, loss: 0.025053855031728745
step: 550, loss: 0.019071483984589577
step: 560, loss: 0.06887796521186829
step: 570, loss: 7.293515955097973e-05
step: 580, loss: 3.21462175634224e-05
step: 590, loss: 0.00033179527963511646
step: 600, loss: 0.000372426729882136
step: 610, loss: 3.3332726161461323e-05
step: 620, loss: 1.234922183357412e-05
step: 630, loss: 3.2961594115477055e-05
step: 640, loss: 0.05235883221030235
step: 650, loss: 3.3762960811145604e-05
step: 660, loss: 0.00018914281099569052
step: 670, loss: 1.1797866136475932e-05
step: 680, loss: 9.01885941857472e-05
step: 690, loss: 0.02727142721414566
step: 700, loss: 0.025546573102474213
step: 710, loss: 0.04793192818760872
step: 720, loss: 0.020092444494366646
step: 730, loss: 0.058396752923727036
step: 740, loss: 3.1439485610462725e-05
step: 750, loss: 0.0192001573741436
step: 760, loss: 0.04802877455949783
step: 770, loss: 0.025587594136595726
step: 780, loss: 0.045674726366996765
step: 790, loss: 0.03294080123305321
step: 800, loss: 3.9676506276009604e-05
step: 810, loss: 0.017602769657969475
step: 820, loss: 0.04273942485451698
step: 830, loss: 0.0002465246943756938
step: 840, loss: 7.023224316071719e-05
step: 850, loss: 0.04182417318224907
step: 860, loss: 0.01728922314941883
step: 870, loss: 3.5325145290698856e-05
step: 880, loss: 0.006387633271515369
step: 890, loss: 0.02192600443959236
step: 900, loss: 0.019323375076055527
step: 910, loss: 2.163921089959331e-05
step: 920, loss: 0.026130808517336845
step: 930, loss: 4.007923780591227e-05
step: 940, loss: 0.09209790080785751
step: 950, loss: 3.7423156754812226e-05
step: 960, loss: 0.0062956614419817924
step: 970, loss: 0.02310914918780327
step: 980, loss: 0.06407815963029861
step: 990, loss: 0.01581764779984951
step: 1000, loss: 0.000265406328253448
step: 1010, loss: 0.010165263898670673
step: 1020, loss: 0.02486814185976982
step: 1030, loss: 0.021054869517683983
step: 1040, loss: 0.03836435079574585
step: 1050, loss: 0.025844041258096695
step: 1060, loss: 0.07190725207328796
step: 1070, loss: 2.496932756912429e-05
epoch 20: dev_f1=0.9294990723562152, f1=0.9259770114942528, best_f1=0.9397371998187584
