cuda
Device: cuda
step: 0, loss: 0.575830340385437
step: 10, loss: 0.43106043338775635
step: 20, loss: 0.17121045291423798
step: 30, loss: 0.5353100895881653
step: 40, loss: 0.2396223247051239
step: 50, loss: 0.34118035435676575
step: 60, loss: 0.2521172761917114
step: 70, loss: 0.25813159346580505
step: 80, loss: 0.2801112234592438
step: 90, loss: 0.402982234954834
step: 100, loss: 0.2229929268360138
step: 110, loss: 0.21848876774311066
step: 120, loss: 0.26195335388183594
step: 130, loss: 0.3102967441082001
step: 140, loss: 0.4170253574848175
step: 150, loss: 0.24456536769866943
step: 160, loss: 0.24285955727100372
step: 170, loss: 0.2623901665210724
step: 180, loss: 0.16250455379486084
step: 190, loss: 0.2716013193130493
step: 200, loss: 0.3339386284351349
step: 210, loss: 0.4523034989833832
step: 220, loss: 0.14993435144424438
step: 230, loss: 0.2300260365009308
step: 240, loss: 0.30667954683303833
step: 250, loss: 0.13007354736328125
step: 260, loss: 0.2419217973947525
step: 270, loss: 0.12498883903026581
step: 280, loss: 0.2538139820098877
step: 290, loss: 0.20613358914852142
step: 300, loss: 0.34163039922714233
step: 310, loss: 0.24247139692306519
step: 320, loss: 0.35467249155044556
step: 330, loss: 0.18666887283325195
step: 340, loss: 0.13204942643642426
step: 350, loss: 0.1489948332309723
epoch 1: dev_f1=0.6733668341708543, f1=0.6650124069478909, best_f1=0.6650124069478909
step: 0, loss: 0.2085130661725998
step: 10, loss: 0.06532979011535645
step: 20, loss: 0.18734793365001678
step: 30, loss: 0.2279348373413086
step: 40, loss: 0.21739204227924347
step: 50, loss: 0.14428086578845978
step: 60, loss: 0.1294430047273636
step: 70, loss: 0.24251246452331543
step: 80, loss: 0.08758079260587692
step: 90, loss: 0.1388111263513565
step: 100, loss: 0.07563653588294983
step: 110, loss: 0.11756289005279541
step: 120, loss: 0.17312955856323242
step: 130, loss: 0.1924646496772766
step: 140, loss: 0.18153256177902222
step: 150, loss: 0.11880356818437576
step: 160, loss: 0.24377970397472382
step: 170, loss: 0.17222197353839874
step: 180, loss: 0.0750105082988739
step: 190, loss: 0.2733158767223358
step: 200, loss: 0.22027581930160522
step: 210, loss: 0.22718960046768188
step: 220, loss: 0.04377277195453644
step: 230, loss: 0.21108871698379517
step: 240, loss: 0.08505207300186157
step: 250, loss: 0.25633102655410767
step: 260, loss: 0.21303516626358032
step: 270, loss: 0.18418475985527039
step: 280, loss: 0.06950643658638
step: 290, loss: 0.12261852622032166
step: 300, loss: 0.15373282134532928
step: 310, loss: 0.11620671302080154
step: 320, loss: 0.07384105026721954
step: 330, loss: 0.18215085566043854
step: 340, loss: 0.1981792449951172
step: 350, loss: 0.1317586749792099
epoch 2: dev_f1=0.7753086419753086, f1=0.7298578199052131, best_f1=0.7298578199052131
step: 0, loss: 0.05167187377810478
step: 10, loss: 0.0935218408703804
step: 20, loss: 0.07358002662658691
step: 30, loss: 0.10351263731718063
step: 40, loss: 0.03970613330602646
step: 50, loss: 0.05137656629085541
step: 60, loss: 0.060183070600032806
step: 70, loss: 0.2673642635345459
step: 80, loss: 0.0747024267911911
step: 90, loss: 0.15274520218372345
step: 100, loss: 0.045942097902297974
step: 110, loss: 0.08246638625860214
step: 120, loss: 0.16251301765441895
step: 130, loss: 0.1518596112728119
step: 140, loss: 0.12085462361574173
step: 150, loss: 0.15447790920734406
step: 160, loss: 0.09171802550554276
step: 170, loss: 0.12051818519830704
step: 180, loss: 0.040207188576459885
step: 190, loss: 0.06806731969118118
step: 200, loss: 0.04670624062418938
step: 210, loss: 0.16390682756900787
step: 220, loss: 0.11154670268297195
step: 230, loss: 0.10511095821857452
step: 240, loss: 0.08026342839002609
step: 250, loss: 0.017840268090367317
step: 260, loss: 0.12185120582580566
step: 270, loss: 0.3123795986175537
step: 280, loss: 0.08468401432037354
step: 290, loss: 0.1654287576675415
step: 300, loss: 0.11322430521249771
step: 310, loss: 0.06418208032846451
step: 320, loss: 0.13530680537223816
step: 330, loss: 0.022892845794558525
step: 340, loss: 0.10273049026727676
step: 350, loss: 0.20844101905822754
epoch 3: dev_f1=0.7952941176470588, f1=0.7603686635944701, best_f1=0.7603686635944701
step: 0, loss: 0.03205329552292824
step: 10, loss: 0.13570882380008698
step: 20, loss: 0.11422625184059143
step: 30, loss: 0.04703579843044281
step: 40, loss: 0.05355418100953102
step: 50, loss: 0.05758645012974739
step: 60, loss: 0.10025811940431595
step: 70, loss: 0.03271498531103134
step: 80, loss: 0.008469820022583008
step: 90, loss: 0.05547095462679863
step: 100, loss: 0.0017402339726686478
step: 110, loss: 0.06625505536794662
step: 120, loss: 0.030839795246720314
step: 130, loss: 0.012774468399584293
step: 140, loss: 0.034529827535152435
step: 150, loss: 0.049038223922252655
step: 160, loss: 0.09766852110624313
step: 170, loss: 0.015555343590676785
step: 180, loss: 0.09245907515287399
step: 190, loss: 0.019438503310084343
step: 200, loss: 0.1436205506324768
step: 210, loss: 0.11711207032203674
step: 220, loss: 0.019966144114732742
step: 230, loss: 0.06074622645974159
step: 240, loss: 0.0876661092042923
step: 250, loss: 0.023656493052840233
step: 260, loss: 0.034200768917798996
step: 270, loss: 0.025673964992165565
step: 280, loss: 0.002015615114942193
step: 290, loss: 0.03122669644653797
step: 300, loss: 0.006415808107703924
step: 310, loss: 0.10785284638404846
step: 320, loss: 0.17588773369789124
step: 330, loss: 0.009581493213772774
step: 340, loss: 0.14243976771831512
step: 350, loss: 0.042972467839717865
epoch 4: dev_f1=0.7688311688311689, f1=0.7210526315789473, best_f1=0.7603686635944701
step: 0, loss: 0.03867403417825699
step: 10, loss: 0.05639604106545448
step: 20, loss: 0.05831912159919739
step: 30, loss: 0.04204067215323448
step: 40, loss: 0.03461787477135658
step: 50, loss: 0.0497937947511673
step: 60, loss: 0.0214526504278183
step: 70, loss: 0.0031587497796863317
step: 80, loss: 0.0691644549369812
step: 90, loss: 0.019449982792139053
step: 100, loss: 0.017833715304732323
step: 110, loss: 0.017857251688838005
step: 120, loss: 0.010781992226839066
step: 130, loss: 0.011858050711452961
step: 140, loss: 0.00740515161305666
step: 150, loss: 0.011790449731051922
step: 160, loss: 0.15892522037029266
step: 170, loss: 0.0931965634226799
step: 180, loss: 0.018922843039035797
step: 190, loss: 0.12523116171360016
step: 200, loss: 0.0036705341190099716
step: 210, loss: 0.05670088902115822
step: 220, loss: 0.018769629299640656
step: 230, loss: 0.023033063858747482
step: 240, loss: 0.020792705938220024
step: 250, loss: 0.10022461414337158
step: 260, loss: 0.11580276489257812
step: 270, loss: 0.10626032948493958
step: 280, loss: 0.057639263570308685
step: 290, loss: 0.18817909061908722
step: 300, loss: 0.007357209920883179
step: 310, loss: 0.004656635690480471
step: 320, loss: 0.0005174300749786198
step: 330, loss: 0.003386993892490864
step: 340, loss: 0.0590851716697216
step: 350, loss: 0.048558179289102554
epoch 5: dev_f1=0.7591623036649214, f1=0.6976744186046512, best_f1=0.7603686635944701
step: 0, loss: 0.004332945216447115
step: 10, loss: 0.09930043667554855
step: 20, loss: 0.013592454604804516
step: 30, loss: 0.011291265487670898
step: 40, loss: 0.0014458021614700556
step: 50, loss: 0.028472697362303734
step: 60, loss: 0.006821837741881609
step: 70, loss: 0.023970896378159523
step: 80, loss: 0.009064046666026115
step: 90, loss: 0.024023419246077538
step: 100, loss: 0.12721489369869232
step: 110, loss: 0.0026024822145700455
step: 120, loss: 0.11473535746335983
step: 130, loss: 0.08616474270820618
step: 140, loss: 0.004346110392361879
step: 150, loss: 0.0016704888548702002
step: 160, loss: 0.0019455004949122667
step: 170, loss: 0.02445777878165245
step: 180, loss: 0.08110984414815903
step: 190, loss: 0.004705820232629776
step: 200, loss: 0.07268540561199188
step: 210, loss: 0.012441180646419525
step: 220, loss: 0.21116581559181213
step: 230, loss: 0.011681564152240753
step: 240, loss: 0.032522253692150116
step: 250, loss: 0.06882622838020325
step: 260, loss: 0.06799086183309555
step: 270, loss: 0.0006258482462726533
step: 280, loss: 0.11059140413999557
step: 290, loss: 0.017179490998387337
step: 300, loss: 0.04004311189055443
step: 310, loss: 0.005679750349372625
step: 320, loss: 0.016146548092365265
step: 330, loss: 0.02300870604813099
step: 340, loss: 0.16811244189739227
step: 350, loss: 0.004346085712313652
epoch 6: dev_f1=0.7855530474040632, f1=0.763888888888889, best_f1=0.7603686635944701
step: 0, loss: 0.02554182894527912
step: 10, loss: 0.0142871905118227
step: 20, loss: 0.01693076826632023
step: 30, loss: 0.021560130640864372
step: 40, loss: 0.0027989225927740335
step: 50, loss: 0.014026978984475136
step: 60, loss: 0.005456325598061085
step: 70, loss: 0.0032408374827355146
step: 80, loss: 0.05077511444687843
step: 90, loss: 0.009326468221843243
step: 100, loss: 0.13551588356494904
step: 110, loss: 0.009405301883816719
step: 120, loss: 0.008033780381083488
step: 130, loss: 0.005396663211286068
step: 140, loss: 0.009773306548595428
step: 150, loss: 0.01646965742111206
step: 160, loss: 0.008273564279079437
step: 170, loss: 0.008273615501821041
step: 180, loss: 0.0011506679002195597
step: 190, loss: 0.006927734240889549
step: 200, loss: 0.07879099994897842
step: 210, loss: 0.005305350758135319
step: 220, loss: 0.008828828111290932
step: 230, loss: 0.1635642796754837
step: 240, loss: 0.007357427384704351
step: 250, loss: 0.008737322874367237
step: 260, loss: 0.13073313236236572
step: 270, loss: 0.037910096347332
step: 280, loss: 0.039677973836660385
step: 290, loss: 0.001110784593038261
step: 300, loss: 0.007517487742006779
step: 310, loss: 0.004531355109065771
step: 320, loss: 0.01401532907038927
step: 330, loss: 0.0016450613038614392
step: 340, loss: 0.0862182229757309
step: 350, loss: 0.029370596632361412
epoch 7: dev_f1=0.7849999999999999, f1=0.7688564476885645, best_f1=0.7603686635944701
step: 0, loss: 0.003566525876522064
step: 10, loss: 0.06604758650064468
step: 20, loss: 0.006259107030928135
step: 30, loss: 0.005526324268430471
step: 40, loss: 0.0014182282611727715
step: 50, loss: 0.0003531169204507023
step: 60, loss: 0.0012091638054698706
step: 70, loss: 0.002111894078552723
step: 80, loss: 0.0019513934385031462
step: 90, loss: 0.0011197903659194708
step: 100, loss: 0.01127647701650858
step: 110, loss: 0.001060008187778294
step: 120, loss: 0.0002798191271722317
step: 130, loss: 0.05231195688247681
step: 140, loss: 0.037195928394794464
step: 150, loss: 0.0005708800163120031
step: 160, loss: 0.003220362588763237
step: 170, loss: 0.0014665030175819993
step: 180, loss: 0.0021038211416453123
step: 190, loss: 0.1999957263469696
step: 200, loss: 0.019189100712537766
step: 210, loss: 0.0005326415412127972
step: 220, loss: 0.003124322509393096
step: 230, loss: 0.005340842064470053
step: 240, loss: 0.0006335137295536697
step: 250, loss: 0.04125014692544937
step: 260, loss: 0.16142426431179047
step: 270, loss: 0.004926822613924742
step: 280, loss: 0.022264335304498672
step: 290, loss: 0.10067079961299896
step: 300, loss: 0.006496710702776909
step: 310, loss: 0.0040399497374892235
step: 320, loss: 0.010949023999273777
step: 330, loss: 0.045284293591976166
step: 340, loss: 0.005541282240301371
step: 350, loss: 0.09303496778011322
epoch 8: dev_f1=0.7884615384615384, f1=0.7505827505827506, best_f1=0.7603686635944701
step: 0, loss: 0.00162121606990695
step: 10, loss: 0.0015634291339665651
step: 20, loss: 0.004562427289783955
step: 30, loss: 0.015211203135550022
step: 40, loss: 0.0036515584215521812
step: 50, loss: 0.0030670533888041973
step: 60, loss: 0.0003573419526219368
step: 70, loss: 0.00039539148565381765
step: 80, loss: 0.0020857099443674088
step: 90, loss: 0.008901996538043022
step: 100, loss: 0.05475036799907684
step: 110, loss: 0.0014144249726086855
step: 120, loss: 0.07620061188936234
step: 130, loss: 0.011588363908231258
step: 140, loss: 0.00815519131720066
step: 150, loss: 0.006116990000009537
step: 160, loss: 0.009167102165520191
step: 170, loss: 0.15003085136413574
step: 180, loss: 0.00246420968323946
step: 190, loss: 0.0013345092302188277
step: 200, loss: 0.00021845453011337668
step: 210, loss: 0.0011925074504688382
step: 220, loss: 0.0009429848869331181
step: 230, loss: 0.002659349702298641
step: 240, loss: 0.003204992040991783
step: 250, loss: 0.004134444519877434
step: 260, loss: 0.03659189119935036
step: 270, loss: 0.1351633220911026
step: 280, loss: 7.800480670994148e-05
step: 290, loss: 0.01674405299127102
step: 300, loss: 0.00041093016625382006
step: 310, loss: 0.00021928695787210017
step: 320, loss: 0.001838250202126801
step: 330, loss: 0.021510904654860497
step: 340, loss: 0.011010637506842613
step: 350, loss: 0.0047045256942510605
epoch 9: dev_f1=0.770408163265306, f1=0.7336683417085427, best_f1=0.7603686635944701
step: 0, loss: 0.001729272771626711
step: 10, loss: 0.0006964466883800924
step: 20, loss: 0.17075805366039276
step: 30, loss: 0.00888417661190033
step: 40, loss: 0.0002583155583124608
step: 50, loss: 0.0020215297117829323
step: 60, loss: 0.007174736354500055
step: 70, loss: 0.0006724310806021094
step: 80, loss: 0.0014809174463152885
step: 90, loss: 0.0153055340051651
step: 100, loss: 0.0019625958520919085
step: 110, loss: 0.004434176720678806
step: 120, loss: 0.03483181819319725
step: 130, loss: 0.0001446139212930575
step: 140, loss: 0.0014586696634069085
step: 150, loss: 0.0006159787881188095
step: 160, loss: 0.0011630429653450847
step: 170, loss: 0.015032991766929626
step: 180, loss: 0.0007336920825764537
step: 190, loss: 0.10607782006263733
step: 200, loss: 0.0033729749266058207
step: 210, loss: 0.01709282398223877
step: 220, loss: 0.00041846840758807957
step: 230, loss: 0.001739871921017766
step: 240, loss: 0.0007892053108662367
step: 250, loss: 0.0004911033902317286
step: 260, loss: 0.0002324166416656226
step: 270, loss: 0.013696786016225815
step: 280, loss: 0.13030898571014404
step: 290, loss: 0.05244923755526543
step: 300, loss: 0.07020661979913712
step: 310, loss: 0.0008485873695462942
step: 320, loss: 0.0033936386462301016
step: 330, loss: 0.001822862890549004
step: 340, loss: 0.10458965599536896
step: 350, loss: 0.034137237817049026
epoch 10: dev_f1=0.7819905213270142, f1=0.7383177570093458, best_f1=0.7603686635944701
step: 0, loss: 0.0003409053897485137
step: 10, loss: 0.009709890931844711
step: 20, loss: 0.0037636863999068737
step: 30, loss: 0.0036564478650689125
step: 40, loss: 0.0032749376259744167
step: 50, loss: 0.0007837498560547829
step: 60, loss: 0.0006143327336758375
step: 70, loss: 0.0009896059054881334
step: 80, loss: 0.0007202696288004518
step: 90, loss: 0.0011053740745410323
step: 100, loss: 0.01074060145765543
step: 110, loss: 0.0004148306034039706
step: 120, loss: 0.0013667498715221882
step: 130, loss: 0.0031814826652407646
step: 140, loss: 0.003995039034634829
step: 150, loss: 0.04348617419600487
step: 160, loss: 0.00020269863307476044
step: 170, loss: 0.031901244074106216
step: 180, loss: 0.0007214451907202601
step: 190, loss: 0.007743891328573227
step: 200, loss: 0.00014852701860945672
step: 210, loss: 0.0015338544035330415
step: 220, loss: 0.003366527846083045
step: 230, loss: 0.01023627258837223
step: 240, loss: 0.010737288743257523
step: 250, loss: 0.02674342691898346
step: 260, loss: 0.009445936419069767
step: 270, loss: 0.08377330750226974
step: 280, loss: 0.0468972846865654
step: 290, loss: 0.0661131739616394
step: 300, loss: 0.0529162771999836
step: 310, loss: 0.00299351685680449
step: 320, loss: 0.002201588824391365
step: 330, loss: 0.00045602265163324773
step: 340, loss: 0.0028093853034079075
step: 350, loss: 0.059874437749385834
epoch 11: dev_f1=0.7659574468085106, f1=0.7028301886792453, best_f1=0.7603686635944701
step: 0, loss: 0.0011149580823257565
step: 10, loss: 0.00028472032863646746
step: 20, loss: 0.0008712857961654663
step: 30, loss: 0.016606779769062996
step: 40, loss: 0.0001184358770842664
step: 50, loss: 0.00012539629824459553
step: 60, loss: 0.013543893583118916
step: 70, loss: 0.0003543312195688486
step: 80, loss: 8.440064266324043e-05
step: 90, loss: 0.000498356472235173
step: 100, loss: 0.009861535392701626
step: 110, loss: 0.0002335334720555693
step: 120, loss: 0.0003762442502193153
step: 130, loss: 0.00014805758837610483
step: 140, loss: 0.006187062244862318
step: 150, loss: 0.0002180234296247363
step: 160, loss: 0.0005401212256401777
step: 170, loss: 0.0002814004838000983
step: 180, loss: 0.0001693836529739201
step: 190, loss: 0.0001545544364489615
step: 200, loss: 0.00010493653098819777
step: 210, loss: 0.1570197343826294
step: 220, loss: 8.695999713381752e-05
step: 230, loss: 0.01649688556790352
step: 240, loss: 0.0004468770930543542
step: 250, loss: 0.0002853650657925755
step: 260, loss: 0.0009506797068752348
step: 270, loss: 0.17303137481212616
step: 280, loss: 0.011217163875699043
step: 290, loss: 0.10269885510206223
step: 300, loss: 7.979106885613874e-05
step: 310, loss: 0.008913727477192879
step: 320, loss: 0.0005521513521671295
step: 330, loss: 0.00042622737237252295
step: 340, loss: 0.0013760573929175735
step: 350, loss: 0.002498036716133356
epoch 12: dev_f1=0.8102564102564102, f1=0.7295918367346939, best_f1=0.7295918367346939
step: 0, loss: 0.0016611919272691011
step: 10, loss: 0.001138020190410316
step: 20, loss: 0.006166371982544661
step: 30, loss: 0.009627099148929119
step: 40, loss: 0.005881700664758682
step: 50, loss: 0.0012823634315282106
step: 60, loss: 0.0004784143529832363
step: 70, loss: 0.00016045503434725106
step: 80, loss: 0.003897010115906596
step: 90, loss: 9.883134043775499e-05
step: 100, loss: 0.010196064598858356
step: 110, loss: 0.000591087038628757
step: 120, loss: 0.00035866786492988467
step: 130, loss: 0.00018326622375752777
step: 140, loss: 0.004624052904546261
step: 150, loss: 0.0015778873348608613
step: 160, loss: 0.0004540325899142772
step: 170, loss: 0.0006248896243050694
step: 180, loss: 0.021484103053808212
step: 190, loss: 0.0028304446022957563
step: 200, loss: 0.0013673296198248863
step: 210, loss: 0.0037020649760961533
step: 220, loss: 8.117394463624805e-05
step: 230, loss: 0.03355519473552704
step: 240, loss: 0.00042488810140639544
step: 250, loss: 7.970923616085202e-05
step: 260, loss: 0.000854966405313462
step: 270, loss: 0.0012872510123997927
step: 280, loss: 0.0002826568961609155
step: 290, loss: 0.00044780666939914227
step: 300, loss: 0.0018233123701065779
step: 310, loss: 0.00016941098147071898
step: 320, loss: 0.004203661810606718
step: 330, loss: 0.000406931183533743
step: 340, loss: 0.0010325988987460732
step: 350, loss: 0.0018016030080616474
epoch 13: dev_f1=0.8169014084507042, f1=0.7230046948356808, best_f1=0.7230046948356808
step: 0, loss: 0.00043008956708945334
step: 10, loss: 0.0009790790500119328
step: 20, loss: 0.033373307436704636
step: 30, loss: 0.0001579487434355542
step: 40, loss: 0.0009242845699191093
step: 50, loss: 0.00036674868897534907
step: 60, loss: 0.0004260103451088071
step: 70, loss: 0.0002395179617451504
step: 80, loss: 0.000984463607892394
step: 90, loss: 0.00022441775945480913
step: 100, loss: 0.009732603095471859
step: 110, loss: 0.0012429568450897932
step: 120, loss: 0.0010096201440319419
step: 130, loss: 0.0003306361613795161
step: 140, loss: 0.0032124118879437447
step: 150, loss: 0.006844154559075832
step: 160, loss: 7.558226207038388e-05
step: 170, loss: 0.00300833722576499
step: 180, loss: 6.859749555587769e-05
step: 190, loss: 0.00010531768930377439
step: 200, loss: 0.0006487459759227931
step: 210, loss: 0.012622322887182236
step: 220, loss: 0.00029324140632525086
step: 230, loss: 0.011085210368037224
step: 240, loss: 0.00028181582456454635
step: 250, loss: 3.91474568459671e-05
step: 260, loss: 0.0005065498990006745
step: 270, loss: 7.475719758076593e-05
step: 280, loss: 0.003182671731337905
step: 290, loss: 0.0006456103292293847
step: 300, loss: 0.014157217927277088
step: 310, loss: 0.00019779507420025766
step: 320, loss: 0.00015166930097620934
step: 330, loss: 0.003520535072311759
step: 340, loss: 4.863805588684045e-05
step: 350, loss: 0.00011284456559224054
epoch 14: dev_f1=0.8123393316195373, f1=0.7167919799498748, best_f1=0.7230046948356808
step: 0, loss: 0.00017905513232108206
step: 10, loss: 0.0008973543299362063
step: 20, loss: 0.000257387786405161
step: 30, loss: 0.00012018520646961406
step: 40, loss: 0.012055736035108566
step: 50, loss: 0.005154891405254602
step: 60, loss: 0.007789261173456907
step: 70, loss: 4.4924257963430136e-05
step: 80, loss: 4.433607682585716e-05
step: 90, loss: 2.7443647923064418e-05
step: 100, loss: 0.002172870095819235
step: 110, loss: 0.24388717114925385
step: 120, loss: 0.00027929674251936376
step: 130, loss: 0.00021546286006923765
step: 140, loss: 0.005950198974460363
step: 150, loss: 0.0007542265811935067
step: 160, loss: 7.628501043654978e-05
step: 170, loss: 0.008469105698168278
step: 180, loss: 0.00027954354300163686
step: 190, loss: 0.0007078166236169636
step: 200, loss: 0.054830778390169144
step: 210, loss: 0.0031353149097412825
step: 220, loss: 0.000461152900243178
step: 230, loss: 0.00027107956702820957
step: 240, loss: 0.006301086861640215
step: 250, loss: 0.00047667542821727693
step: 260, loss: 0.00016676838276907802
step: 270, loss: 0.001831142813898623
step: 280, loss: 9.983201016439125e-05
step: 290, loss: 0.0003577661409508437
step: 300, loss: 0.002098323544487357
step: 310, loss: 0.00012316809443291277
step: 320, loss: 0.0014270046958699822
step: 330, loss: 0.00018386184819974005
step: 340, loss: 0.0001592719927430153
step: 350, loss: 0.001148648327216506
epoch 15: dev_f1=0.8048780487804877, f1=0.7307692307692307, best_f1=0.7230046948356808
step: 0, loss: 0.277998149394989
step: 10, loss: 0.0025947359390556812
step: 20, loss: 0.0007194956997409463
step: 30, loss: 0.0002732453867793083
step: 40, loss: 0.0033570032101124525
step: 50, loss: 0.00039725395618006587
step: 60, loss: 0.00013549355207942426
step: 70, loss: 0.00010595643834676594
step: 80, loss: 0.0010036979801952839
step: 90, loss: 0.004520822316408157
step: 100, loss: 0.00022413054830394685
step: 110, loss: 0.00012584892101585865
step: 120, loss: 0.0006391401984728873
step: 130, loss: 0.022414295002818108
step: 140, loss: 0.0026333103887736797
step: 150, loss: 0.028453895822167397
step: 160, loss: 3.376848326297477e-05
step: 170, loss: 4.115454794373363e-05
step: 180, loss: 0.0009328738087788224
step: 190, loss: 0.00018472669762559235
step: 200, loss: 0.00014281179755926132
step: 210, loss: 0.00043356959940865636
step: 220, loss: 4.314972466090694e-05
step: 230, loss: 0.005342577584087849
step: 240, loss: 6.413718074327335e-05
step: 250, loss: 5.159217107575387e-05
step: 260, loss: 0.0004145241400692612
step: 270, loss: 0.0007334236288443208
step: 280, loss: 0.003790413960814476
step: 290, loss: 0.00013350472727324814
step: 300, loss: 6.270333688007668e-05
step: 310, loss: 0.0005428678123280406
step: 320, loss: 0.00019010028336197138
step: 330, loss: 0.0003798531542997807
step: 340, loss: 0.00031964736990630627
step: 350, loss: 0.00023415398027282208
epoch 16: dev_f1=0.8049382716049382, f1=0.7365853658536585, best_f1=0.7230046948356808
step: 0, loss: 0.00021540946909226477
step: 10, loss: 0.016266029328107834
step: 20, loss: 0.00011975044617429376
step: 30, loss: 0.0003640307404566556
step: 40, loss: 7.70075639593415e-05
step: 50, loss: 0.00011213219113415107
step: 60, loss: 4.0260674722958356e-05
step: 70, loss: 0.0006761763361282647
step: 80, loss: 0.00018200775957666337
step: 90, loss: 0.0001224540756084025
step: 100, loss: 0.0014072509948164225
step: 110, loss: 0.00013152975589036942
step: 120, loss: 0.0002169528161175549
step: 130, loss: 4.613099372363649e-05
step: 140, loss: 8.953226642915979e-05
step: 150, loss: 0.0009943386539816856
step: 160, loss: 0.004754561465233564
step: 170, loss: 0.00018752546748146415
step: 180, loss: 7.671536150155589e-05
step: 190, loss: 0.04481344670057297
step: 200, loss: 4.5437314838636667e-05
step: 210, loss: 0.00024240967468358576
step: 220, loss: 0.053682293742895126
step: 230, loss: 0.000892906915396452
step: 240, loss: 0.04269186779856682
step: 250, loss: 0.0002646025677677244
step: 260, loss: 0.0018698667408898473
step: 270, loss: 0.00031421141466125846
step: 280, loss: 0.002631426090374589
step: 290, loss: 6.23621090198867e-05
step: 300, loss: 0.017040103673934937
step: 310, loss: 0.0003107168304268271
step: 320, loss: 0.00016255011723842472
step: 330, loss: 3.555968578439206e-05
step: 340, loss: 0.0002257708110846579
step: 350, loss: 3.730719618033618e-05
epoch 17: dev_f1=0.8021680216802168, f1=0.7387862796833774, best_f1=0.7230046948356808
step: 0, loss: 0.00017229052900802344
step: 10, loss: 0.0005350878927856684
step: 20, loss: 0.0001620717375772074
step: 30, loss: 0.00024932355154305696
step: 40, loss: 4.726498809759505e-05
step: 50, loss: 0.00028116884641349316
step: 60, loss: 0.0002013269840972498
step: 70, loss: 0.020762916654348373
step: 80, loss: 4.786221688846126e-05
step: 90, loss: 4.431585330166854e-05
step: 100, loss: 0.00010588138684397563
step: 110, loss: 0.0018517847638577223
step: 120, loss: 0.00015920640726108104
step: 130, loss: 9.705549746286124e-05
step: 140, loss: 0.0004575267666950822
step: 150, loss: 0.010314316488802433
step: 160, loss: 0.00017552971257828176
step: 170, loss: 5.1583228923846036e-05
step: 180, loss: 0.00011752525460906327
step: 190, loss: 0.0002129825297743082
step: 200, loss: 0.0035608767066150904
step: 210, loss: 8.06673924671486e-05
step: 220, loss: 0.0040044235065579414
step: 230, loss: 2.942898208857514e-05
step: 240, loss: 9.800647239899263e-05
step: 250, loss: 5.7315544836455956e-05
step: 260, loss: 0.0026758196763694286
step: 270, loss: 0.0053239320404827595
step: 280, loss: 4.712242662208155e-05
step: 290, loss: 0.000916884804610163
step: 300, loss: 0.00010504816600587219
step: 310, loss: 9.453355596633628e-05
step: 320, loss: 0.00039654792635701597
step: 330, loss: 6.040806692908518e-05
step: 340, loss: 9.019688150146976e-05
step: 350, loss: 4.959186117048375e-05
epoch 18: dev_f1=0.7970297029702972, f1=0.7331670822942644, best_f1=0.7230046948356808
step: 0, loss: 4.445556260179728e-05
step: 10, loss: 0.00011597813863772899
step: 20, loss: 0.0001228829933097586
step: 30, loss: 3.225556429242715e-05
step: 40, loss: 0.00032500468660146
step: 50, loss: 0.00019636967044789344
step: 60, loss: 0.021848442032933235
step: 70, loss: 6.524437048938125e-05
step: 80, loss: 0.0001052539810189046
step: 90, loss: 5.7954355725087225e-05
step: 100, loss: 6.067695721867494e-05
step: 110, loss: 0.009651890024542809
step: 120, loss: 6.946238863747567e-05
step: 130, loss: 4.324132896726951e-05
step: 140, loss: 8.587024785811082e-05
step: 150, loss: 8.380595681956038e-05
step: 160, loss: 7.867067324696109e-05
step: 170, loss: 0.00011777169856941327
step: 180, loss: 0.00022338583949021995
step: 190, loss: 0.00015526506467722356
step: 200, loss: 0.00022974183957558125
step: 210, loss: 4.212227213429287e-05
step: 220, loss: 0.0002656875003594905
step: 230, loss: 0.00013033048890065402
step: 240, loss: 7.21510368748568e-05
step: 250, loss: 0.00019453192362561822
step: 260, loss: 0.0001815639843698591
step: 270, loss: 3.3235377486562356e-05
step: 280, loss: 4.162283585174009e-05
step: 290, loss: 5.961626811767928e-05
step: 300, loss: 0.014576587826013565
step: 310, loss: 0.002473896834999323
step: 320, loss: 7.00243836035952e-05
step: 330, loss: 0.00026610089116729796
step: 340, loss: 3.4535503800725564e-05
step: 350, loss: 9.450959623791277e-05
epoch 19: dev_f1=0.7919799498746868, f1=0.7336683417085427, best_f1=0.7230046948356808
step: 0, loss: 6.451352965086699e-05
step: 10, loss: 5.5662894737906754e-05
step: 20, loss: 0.005619124975055456
step: 30, loss: 0.00035138180828653276
step: 40, loss: 0.0008646238129585981
step: 50, loss: 0.00013284148008096963
step: 60, loss: 4.684073064709082e-05
step: 70, loss: 6.232361920410767e-05
step: 80, loss: 0.0010404634522274137
step: 90, loss: 4.043594890390523e-05
step: 100, loss: 0.0001206513843499124
step: 110, loss: 0.0014071617042645812
step: 120, loss: 9.618147305445746e-05
step: 130, loss: 4.2067051253980026e-05
step: 140, loss: 0.000114546186523512
step: 150, loss: 0.00011522578279254958
step: 160, loss: 0.005020003765821457
step: 170, loss: 6.77077696309425e-05
step: 180, loss: 0.00027300496003590524
step: 190, loss: 0.0005242893239483237
step: 200, loss: 0.000193163868971169
step: 210, loss: 0.001257165102288127
step: 220, loss: 3.455379555816762e-05
step: 230, loss: 5.587101622950286e-05
step: 240, loss: 0.00015508475189562887
step: 250, loss: 9.347991726826876e-05
step: 260, loss: 0.011286680586636066
step: 270, loss: 9.985408541979268e-05
step: 280, loss: 0.001782229752279818
step: 290, loss: 8.380205690627918e-05
step: 300, loss: 5.5326239817077294e-05
step: 310, loss: 0.0002173369430238381
step: 320, loss: 5.7554716477170587e-05
step: 330, loss: 0.0002469902974553406
step: 340, loss: 0.0001006236343528144
step: 350, loss: 4.6008241042727605e-05
epoch 20: dev_f1=0.7910447761194029, f1=0.7331670822942644, best_f1=0.7230046948356808
