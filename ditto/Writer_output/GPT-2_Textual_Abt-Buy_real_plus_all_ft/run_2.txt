cuda
Device: cuda
step: 0, loss: 0.6877678632736206
step: 10, loss: 0.46401315927505493
step: 20, loss: 0.2948356866836548
step: 30, loss: 0.26287180185317993
step: 40, loss: 0.317901611328125
step: 50, loss: 0.3061199188232422
step: 60, loss: 0.22996482253074646
step: 70, loss: 0.5201752185821533
step: 80, loss: 0.24694213271141052
step: 90, loss: 0.14375415444374084
step: 100, loss: 0.28131017088890076
step: 110, loss: 0.3007672429084778
step: 120, loss: 0.31137511134147644
step: 130, loss: 0.14438888430595398
step: 140, loss: 0.16749019920825958
step: 150, loss: 0.29007187485694885
step: 160, loss: 0.29518261551856995
step: 170, loss: 0.19104662537574768
step: 180, loss: 0.2723984718322754
step: 190, loss: 0.3650204539299011
step: 200, loss: 0.2510688006877899
step: 210, loss: 0.24836628139019012
step: 220, loss: 0.15751266479492188
step: 230, loss: 0.24880380928516388
step: 240, loss: 0.224897563457489
step: 250, loss: 0.18946321308612823
step: 260, loss: 0.15384678542613983
step: 270, loss: 0.2762749493122101
step: 280, loss: 0.26023757457733154
step: 290, loss: 0.2867914140224457
step: 300, loss: 0.08944601565599442
step: 310, loss: 0.17818009853363037
step: 320, loss: 0.1381906121969223
step: 330, loss: 0.1283222883939743
step: 340, loss: 0.1626727432012558
step: 350, loss: 0.22164979577064514
epoch 1: dev_f1=0.7162790697674418, f1=0.6778846153846154, best_f1=0.6778846153846154
step: 0, loss: 0.05459978058934212
step: 10, loss: 0.14908044040203094
step: 20, loss: 0.18532952666282654
step: 30, loss: 0.22013963758945465
step: 40, loss: 0.29605942964553833
step: 50, loss: 0.158512681722641
step: 60, loss: 0.10325504094362259
step: 70, loss: 0.1600944846868515
step: 80, loss: 0.2527734637260437
step: 90, loss: 0.09441769868135452
step: 100, loss: 0.205983504652977
step: 110, loss: 0.12188169360160828
step: 120, loss: 0.13237707316875458
step: 130, loss: 0.15560023486614227
step: 140, loss: 0.10553401708602905
step: 150, loss: 0.14272421598434448
step: 160, loss: 0.190359964966774
step: 170, loss: 0.12041112780570984
step: 180, loss: 0.2757771909236908
step: 190, loss: 0.20609986782073975
step: 200, loss: 0.07580900937318802
step: 210, loss: 0.12123499810695648
step: 220, loss: 0.544948160648346
step: 230, loss: 0.27169468998908997
step: 240, loss: 0.12713445723056793
step: 250, loss: 0.1769583374261856
step: 260, loss: 0.3082009255886078
step: 270, loss: 0.14166401326656342
step: 280, loss: 0.058473505079746246
step: 290, loss: 0.19366703927516937
step: 300, loss: 0.07259039580821991
step: 310, loss: 0.3879275918006897
step: 320, loss: 0.07830265909433365
step: 330, loss: 0.12702661752700806
step: 340, loss: 0.2053830921649933
step: 350, loss: 0.13203854858875275
epoch 2: dev_f1=0.7648456057007125, f1=0.7322654462242564, best_f1=0.7322654462242564
step: 0, loss: 0.10879325866699219
step: 10, loss: 0.24380594491958618
step: 20, loss: 0.07645726948976517
step: 30, loss: 0.020529747009277344
step: 40, loss: 0.046495482325553894
step: 50, loss: 0.009486963972449303
step: 60, loss: 0.14405439794063568
step: 70, loss: 0.0884946882724762
step: 80, loss: 0.15410099923610687
step: 90, loss: 0.10586269199848175
step: 100, loss: 0.05983073264360428
step: 110, loss: 0.21243609488010406
step: 120, loss: 0.030229050666093826
step: 130, loss: 0.10250454396009445
step: 140, loss: 0.1472366452217102
step: 150, loss: 0.08005272597074509
step: 160, loss: 0.1873130351305008
step: 170, loss: 0.05566946789622307
step: 180, loss: 0.03196774050593376
step: 190, loss: 0.16669030487537384
step: 200, loss: 0.09586098790168762
step: 210, loss: 0.050664711743593216
step: 220, loss: 0.10478638112545013
step: 230, loss: 0.22328981757164001
step: 240, loss: 0.05420908331871033
step: 250, loss: 0.26626479625701904
step: 260, loss: 0.024987174198031425
step: 270, loss: 0.1118408590555191
step: 280, loss: 0.0563063807785511
step: 290, loss: 0.16289056837558746
step: 300, loss: 0.22970035672187805
step: 310, loss: 0.0452503003180027
step: 320, loss: 0.019458020105957985
step: 330, loss: 0.1550045907497406
step: 340, loss: 0.16247676312923431
step: 350, loss: 0.09856195747852325
epoch 3: dev_f1=0.7505518763796908, f1=0.7396061269146608, best_f1=0.7322654462242564
step: 0, loss: 0.024532195180654526
step: 10, loss: 0.028622467070817947
step: 20, loss: 0.0968482568860054
step: 30, loss: 0.0626865103840828
step: 40, loss: 0.06268182396888733
step: 50, loss: 0.032386794686317444
step: 60, loss: 0.18969488143920898
step: 70, loss: 0.027601178735494614
step: 80, loss: 0.023100493475794792
step: 90, loss: 0.14395947754383087
step: 100, loss: 0.0451069213449955
step: 110, loss: 0.030444618314504623
step: 120, loss: 0.09242715686559677
step: 130, loss: 0.04830388352274895
step: 140, loss: 0.15342804789543152
step: 150, loss: 0.03692389652132988
step: 160, loss: 0.018672043457627296
step: 170, loss: 0.13745127618312836
step: 180, loss: 0.03313794359564781
step: 190, loss: 0.0179281085729599
step: 200, loss: 0.08972185105085373
step: 210, loss: 0.010868584737181664
step: 220, loss: 0.08535006642341614
step: 230, loss: 0.21282438933849335
step: 240, loss: 0.15483596920967102
step: 250, loss: 0.06354129314422607
step: 260, loss: 0.028612611815333366
step: 270, loss: 0.03955394774675369
step: 280, loss: 0.09219083189964294
step: 290, loss: 0.1004503071308136
step: 300, loss: 0.0342935211956501
step: 310, loss: 0.1213950589299202
step: 320, loss: 0.08293411880731583
step: 330, loss: 0.021725982427597046
step: 340, loss: 0.01286857109516859
step: 350, loss: 0.004522814881056547
epoch 4: dev_f1=0.7932692307692307, f1=0.7692307692307693, best_f1=0.7692307692307693
step: 0, loss: 0.015143049880862236
step: 10, loss: 0.02063155360519886
step: 20, loss: 0.3035985231399536
step: 30, loss: 0.056614529341459274
step: 40, loss: 0.08097704499959946
step: 50, loss: 0.03682022541761398
step: 60, loss: 0.016683518886566162
step: 70, loss: 0.006914565805345774
step: 80, loss: 0.15200366079807281
step: 90, loss: 0.00875528622418642
step: 100, loss: 0.013076811097562313
step: 110, loss: 0.016378194093704224
step: 120, loss: 0.0075608124025166035
step: 130, loss: 0.009607725776731968
step: 140, loss: 0.05694420263171196
step: 150, loss: 0.03433484211564064
step: 160, loss: 0.03104504756629467
step: 170, loss: 0.029041221365332603
step: 180, loss: 0.04112108796834946
step: 190, loss: 0.03806763142347336
step: 200, loss: 0.015641573816537857
step: 210, loss: 0.05302282050251961
step: 220, loss: 0.0391685888171196
step: 230, loss: 0.0032478380016982555
step: 240, loss: 0.1305217742919922
step: 250, loss: 0.25525912642478943
step: 260, loss: 0.0008416997734457254
step: 270, loss: 0.405926376581192
step: 280, loss: 0.028077784925699234
step: 290, loss: 0.08071541786193848
step: 300, loss: 0.005665181670337915
step: 310, loss: 0.17048196494579315
step: 320, loss: 0.04668257758021355
step: 330, loss: 0.0184029433876276
step: 340, loss: 0.00705303717404604
step: 350, loss: 0.0061236838810145855
epoch 5: dev_f1=0.8171021377672211, f1=0.7589498806682576, best_f1=0.7589498806682576
step: 0, loss: 0.03536030277609825
step: 10, loss: 0.0060721151530742645
step: 20, loss: 0.00440947012975812
step: 30, loss: 0.008033746853470802
step: 40, loss: 0.04023575410246849
step: 50, loss: 0.016775859519839287
step: 60, loss: 0.057011157274246216
step: 70, loss: 0.04118682071566582
step: 80, loss: 0.00873891357332468
step: 90, loss: 0.01595166139304638
step: 100, loss: 0.0013200686080381274
step: 110, loss: 0.002203241689130664
step: 120, loss: 0.10154279321432114
step: 130, loss: 0.029304619878530502
step: 140, loss: 0.09616605937480927
step: 150, loss: 0.02322401851415634
step: 160, loss: 0.005353347398340702
step: 170, loss: 0.03135225549340248
step: 180, loss: 0.0007924519013613462
step: 190, loss: 0.10718939453363419
step: 200, loss: 0.0026539708487689495
step: 210, loss: 0.012469158507883549
step: 220, loss: 0.000997446826659143
step: 230, loss: 0.004644634667783976
step: 240, loss: 0.061172422021627426
step: 250, loss: 0.004341892432421446
step: 260, loss: 0.0026628209743648767
step: 270, loss: 0.02103435806930065
step: 280, loss: 0.004247499164193869
step: 290, loss: 0.009068435989320278
step: 300, loss: 0.13046161830425262
step: 310, loss: 0.057726576924324036
step: 320, loss: 0.05329769849777222
step: 330, loss: 0.05041401833295822
step: 340, loss: 0.09980118274688721
step: 350, loss: 0.010443460196256638
epoch 6: dev_f1=0.7785547785547785, f1=0.7599067599067598, best_f1=0.7589498806682576
step: 0, loss: 0.002893278608098626
step: 10, loss: 0.027439357712864876
step: 20, loss: 0.005773329176008701
step: 30, loss: 0.033793576061725616
step: 40, loss: 0.004363498650491238
step: 50, loss: 0.023698749020695686
step: 60, loss: 0.09789353609085083
step: 70, loss: 0.0016663451679050922
step: 80, loss: 0.0013617450604215264
step: 90, loss: 0.029780246317386627
step: 100, loss: 0.05662175267934799
step: 110, loss: 0.13164708018302917
step: 120, loss: 0.06913135200738907
step: 130, loss: 0.0012487169587984681
step: 140, loss: 0.0006818649126216769
step: 150, loss: 0.0011668871156871319
step: 160, loss: 0.0028426898643374443
step: 170, loss: 0.003124331124126911
step: 180, loss: 0.0045849974267184734
step: 190, loss: 0.00853199977427721
step: 200, loss: 0.07287974655628204
step: 210, loss: 0.04880509153008461
step: 220, loss: 0.01953682117164135
step: 230, loss: 0.004583428613841534
step: 240, loss: 0.005383750423789024
step: 250, loss: 0.02644198015332222
step: 260, loss: 0.013111647218465805
step: 270, loss: 0.07082162797451019
step: 280, loss: 0.011022799648344517
step: 290, loss: 0.03179401531815529
step: 300, loss: 0.0011212470708414912
step: 310, loss: 0.002134606707841158
step: 320, loss: 0.05499023571610451
step: 330, loss: 0.0065431976690888405
step: 340, loss: 0.011071514338254929
step: 350, loss: 0.005728486459702253
epoch 7: dev_f1=0.7695961995249406, f1=0.7541766109785203, best_f1=0.7589498806682576
step: 0, loss: 0.0007801268948242068
step: 10, loss: 0.02390129864215851
step: 20, loss: 0.012718877755105495
step: 30, loss: 0.033840131014585495
step: 40, loss: 0.00033240774064324796
step: 50, loss: 0.0031796947587281466
step: 60, loss: 0.0030375586356967688
step: 70, loss: 0.03551626205444336
step: 80, loss: 0.01470276154577732
step: 90, loss: 0.004933727905154228
step: 100, loss: 0.0012627292890101671
step: 110, loss: 0.019334295764565468
step: 120, loss: 0.0003044158802367747
step: 130, loss: 0.0005980712594464421
step: 140, loss: 0.06784026324748993
step: 150, loss: 0.004400934092700481
step: 160, loss: 0.008099396713078022
step: 170, loss: 0.00039651760016568005
step: 180, loss: 0.0008155341492965817
step: 190, loss: 0.049769170582294464
step: 200, loss: 0.0025663713458925486
step: 210, loss: 0.006967728491872549
step: 220, loss: 0.0091619361191988
step: 230, loss: 0.005877102725207806
step: 240, loss: 0.0011663984041661024
step: 250, loss: 0.015209746547043324
step: 260, loss: 0.11940284073352814
step: 270, loss: 0.023277901113033295
step: 280, loss: 0.06133555620908737
step: 290, loss: 0.022360607981681824
step: 300, loss: 4.390126923681237e-05
step: 310, loss: 0.030089927837252617
step: 320, loss: 0.010724862106144428
step: 330, loss: 0.013933740556240082
step: 340, loss: 0.004679617937654257
step: 350, loss: 0.005884728394448757
epoch 8: dev_f1=0.7628865979381445, f1=0.7551020408163266, best_f1=0.7589498806682576
step: 0, loss: 0.0005331100546754897
step: 10, loss: 0.0009788665920495987
step: 20, loss: 0.00038583940477110445
step: 30, loss: 0.0021067054476588964
step: 40, loss: 0.0019944484811276197
step: 50, loss: 0.0032505160197615623
step: 60, loss: 0.006355942692607641
step: 70, loss: 0.008574331179261208
step: 80, loss: 0.0005491069750860333
step: 90, loss: 0.009188895113766193
step: 100, loss: 0.0006410201312974095
step: 110, loss: 0.003987924195826054
step: 120, loss: 0.0007518152706325054
step: 130, loss: 0.0037315126974135637
step: 140, loss: 0.00022748750052414834
step: 150, loss: 0.0038045223336666822
step: 160, loss: 0.0001641605340410024
step: 170, loss: 0.0002853893965948373
step: 180, loss: 0.028099799528717995
step: 190, loss: 0.04798140004277229
step: 200, loss: 0.007552115246653557
step: 210, loss: 0.0003448885981924832
step: 220, loss: 0.0033150743693113327
step: 230, loss: 0.0012983070919290185
step: 240, loss: 0.000747310696169734
step: 250, loss: 0.009977188892662525
step: 260, loss: 0.0010318607091903687
step: 270, loss: 0.003987762611359358
step: 280, loss: 0.03350111097097397
step: 290, loss: 0.010835276916623116
step: 300, loss: 0.05959438160061836
step: 310, loss: 0.00013894520816393197
step: 320, loss: 0.0007270404603332281
step: 330, loss: 0.00013788792421109974
step: 340, loss: 0.0025350884534418583
step: 350, loss: 0.006590484641492367
epoch 9: dev_f1=0.7952380952380952, f1=0.7688679245283018, best_f1=0.7589498806682576
step: 0, loss: 0.0006898589781485498
step: 10, loss: 0.007257366552948952
step: 20, loss: 0.0027778740040957928
step: 30, loss: 0.006149374879896641
step: 40, loss: 0.1407684087753296
step: 50, loss: 0.0004280976136215031
step: 60, loss: 0.007809292990714312
step: 70, loss: 0.002308693714439869
step: 80, loss: 0.004126609303057194
step: 90, loss: 0.0005221674218773842
step: 100, loss: 0.003572175744920969
step: 110, loss: 0.0016675834776833653
step: 120, loss: 0.00036612493568100035
step: 130, loss: 0.0011368943378329277
step: 140, loss: 0.0024926061742007732
step: 150, loss: 0.0019445515936240554
step: 160, loss: 0.004646426532417536
step: 170, loss: 0.0014104993315413594
step: 180, loss: 0.0007523426902480423
step: 190, loss: 0.006099036894738674
step: 200, loss: 6.837098771939054e-05
step: 210, loss: 0.0013132543535903096
step: 220, loss: 0.0002464190765749663
step: 230, loss: 0.000304265646263957
step: 240, loss: 0.11348798871040344
step: 250, loss: 0.0053346119821071625
step: 260, loss: 0.0004602890694513917
step: 270, loss: 0.007100808899849653
step: 280, loss: 0.007189441006630659
step: 290, loss: 0.003029203275218606
step: 300, loss: 0.0018009919440373778
step: 310, loss: 0.03524141013622284
step: 320, loss: 0.08501256257295609
step: 330, loss: 0.00011783325317082927
step: 340, loss: 0.0007238326361402869
step: 350, loss: 0.048441074788570404
epoch 10: dev_f1=0.7935034802784221, f1=0.7597254004576659, best_f1=0.7589498806682576
step: 0, loss: 0.0021338702645152807
step: 10, loss: 0.013444202952086926
step: 20, loss: 0.0029377443715929985
step: 30, loss: 0.0002513128856662661
step: 40, loss: 0.000499043962918222
step: 50, loss: 0.002810741774737835
step: 60, loss: 0.005572521593421698
step: 70, loss: 0.00798894464969635
step: 80, loss: 0.032224494963884354
step: 90, loss: 0.0010874089784920216
step: 100, loss: 0.0003163132641930133
step: 110, loss: 0.0006515128770843148
step: 120, loss: 0.003738472703844309
step: 130, loss: 0.0006886306218802929
step: 140, loss: 0.0029470461886376143
step: 150, loss: 0.00039518997073173523
step: 160, loss: 0.00047021033242344856
step: 170, loss: 0.0005440590321086347
step: 180, loss: 0.003216384444385767
step: 190, loss: 0.0037462112959474325
step: 200, loss: 0.0004046628891956061
step: 210, loss: 0.011332763358950615
step: 220, loss: 0.0008811047300696373
step: 230, loss: 0.010069554671645164
step: 240, loss: 0.004110417794436216
step: 250, loss: 0.013569481670856476
step: 260, loss: 0.00011646313942037523
step: 270, loss: 0.005598403979092836
step: 280, loss: 0.23079913854599
step: 290, loss: 0.0012198981130495667
step: 300, loss: 0.0013929033884778619
step: 310, loss: 0.002022957196459174
step: 320, loss: 0.0012843712465837598
step: 330, loss: 0.03307884931564331
step: 340, loss: 0.00044633433572016656
step: 350, loss: 0.0003424747264944017
epoch 11: dev_f1=0.7643979057591622, f1=0.7329842931937172, best_f1=0.7589498806682576
step: 0, loss: 0.00020095505169592798
step: 10, loss: 0.012291040271520615
step: 20, loss: 0.017279330641031265
step: 30, loss: 0.0002042605192400515
step: 40, loss: 0.001320972223766148
step: 50, loss: 0.00080397556303069
step: 60, loss: 0.0002469150349497795
step: 70, loss: 0.019121404737234116
step: 80, loss: 0.0028389552608132362
step: 90, loss: 0.0005657011060975492
step: 100, loss: 0.08820852637290955
step: 110, loss: 0.0024495983961969614
step: 120, loss: 0.0029488233849406242
step: 130, loss: 0.02660181000828743
step: 140, loss: 0.047320183366537094
step: 150, loss: 0.006920666433870792
step: 160, loss: 0.07507167011499405
step: 170, loss: 0.0008774206507951021
step: 180, loss: 9.559159661876038e-05
step: 190, loss: 0.0006584238726645708
step: 200, loss: 0.00031712313648313284
step: 210, loss: 0.04503648728132248
step: 220, loss: 0.04550860449671745
step: 230, loss: 0.00023554387735202909
step: 240, loss: 0.0005495134391821921
step: 250, loss: 0.0002452115004416555
step: 260, loss: 0.0014903403352946043
step: 270, loss: 0.0002977561089210212
step: 280, loss: 0.0003722140390891582
step: 290, loss: 8.55255639180541e-05
step: 300, loss: 0.020846541970968246
step: 310, loss: 0.0006373290671035647
step: 320, loss: 6.174537702463567e-05
step: 330, loss: 0.0004435668233782053
step: 340, loss: 0.007695086766034365
step: 350, loss: 0.0005016620852984488
epoch 12: dev_f1=0.7892156862745098, f1=0.7530562347188264, best_f1=0.7589498806682576
step: 0, loss: 0.00018318997172173113
step: 10, loss: 0.0006897813873365521
step: 20, loss: 0.00037253659684211016
step: 30, loss: 0.0001391285622958094
step: 40, loss: 0.0009331383625976741
step: 50, loss: 0.0001708731142571196
step: 60, loss: 0.0017833942547440529
step: 70, loss: 0.00029613979859277606
step: 80, loss: 0.0003219200880266726
step: 90, loss: 0.00011429003643570468
step: 100, loss: 0.00024396114167757332
step: 110, loss: 0.00034223354305140674
step: 120, loss: 0.000585481058806181
step: 130, loss: 0.0002566378389019519
step: 140, loss: 0.00026177093968726695
step: 150, loss: 0.0005705988733097911
step: 160, loss: 0.000538277963642031
step: 170, loss: 0.004467676393687725
step: 180, loss: 0.00036531922523863614
step: 190, loss: 0.00012453638191800565
step: 200, loss: 0.023471251130104065
step: 210, loss: 0.004524511285126209
step: 220, loss: 0.00013627888984046876
step: 230, loss: 0.0003767874732147902
step: 240, loss: 0.0059187039732933044
step: 250, loss: 0.0003719136002473533
step: 260, loss: 0.0014327012468129396
step: 270, loss: 0.0008070868789218366
step: 280, loss: 0.003097380045801401
step: 290, loss: 0.0018085490446537733
step: 300, loss: 0.013911779969930649
step: 310, loss: 0.000984102487564087
step: 320, loss: 0.0001320987503277138
step: 330, loss: 0.00028368920902721584
step: 340, loss: 0.00021651045244652778
step: 350, loss: 0.0027005544397979975
epoch 13: dev_f1=0.7915690866510539, f1=0.756880733944954, best_f1=0.7589498806682576
step: 0, loss: 0.002601783024147153
step: 10, loss: 0.00019210422760806978
step: 20, loss: 0.0012616689782589674
step: 30, loss: 0.010966363362967968
step: 40, loss: 7.472463039448485e-05
step: 50, loss: 8.414573676418513e-05
step: 60, loss: 0.00012092213000869378
step: 70, loss: 0.0001241923455381766
step: 80, loss: 4.170120882918127e-05
step: 90, loss: 0.0001773669064277783
step: 100, loss: 0.0006943636108189821
step: 110, loss: 9.832943032961339e-05
step: 120, loss: 0.027673693373799324
step: 130, loss: 0.019573824480175972
step: 140, loss: 6.047054921509698e-05
step: 150, loss: 0.015313470736145973
step: 160, loss: 0.002974605420604348
step: 170, loss: 9.817557292990386e-05
step: 180, loss: 4.228743273415603e-05
step: 190, loss: 6.54739560559392e-05
step: 200, loss: 1.9583590983529575e-05
step: 210, loss: 6.253035098779947e-05
step: 220, loss: 0.0002565117320045829
step: 230, loss: 0.0002220919996034354
step: 240, loss: 0.021213574334979057
step: 250, loss: 0.00010239025868941098
step: 260, loss: 0.00011398033529985696
step: 270, loss: 0.0037777188699692488
step: 280, loss: 2.4489459974574856e-05
step: 290, loss: 0.0002654156123753637
step: 300, loss: 0.00029477261705324054
step: 310, loss: 0.0045070042833685875
step: 320, loss: 0.0024229823611676693
step: 330, loss: 4.960678415955044e-05
step: 340, loss: 0.00015415229427162558
step: 350, loss: 0.0014803677331656218
epoch 14: dev_f1=0.8058252427184465, f1=0.7487922705314008, best_f1=0.7589498806682576
step: 0, loss: 0.027959248051047325
step: 10, loss: 0.00011528179311426356
step: 20, loss: 0.00013566510460805148
step: 30, loss: 0.007963894866406918
step: 40, loss: 0.00042043387657031417
step: 50, loss: 0.000546330469660461
step: 60, loss: 0.00042447203304618597
step: 70, loss: 0.00021705958351958543
step: 80, loss: 0.0004123549733776599
step: 90, loss: 0.00025661723338998854
step: 100, loss: 0.0538225919008255
step: 110, loss: 0.0050226980820298195
step: 120, loss: 0.03523162007331848
step: 130, loss: 0.0008907673181965947
step: 140, loss: 0.0008704867213964462
step: 150, loss: 9.15105119929649e-05
step: 160, loss: 0.0013143771793693304
step: 170, loss: 0.00017529861361254007
step: 180, loss: 0.0008924328139983118
step: 190, loss: 0.0015986758517101407
step: 200, loss: 0.00033332392922602594
step: 210, loss: 0.000202679424546659
step: 220, loss: 0.0004954321775585413
step: 230, loss: 0.0008079438121058047
step: 240, loss: 0.00023020997468847781
step: 250, loss: 0.0022412114776670933
step: 260, loss: 0.0007705065654590726
step: 270, loss: 0.0022703297436237335
step: 280, loss: 0.04561329632997513
step: 290, loss: 0.0033446080051362514
step: 300, loss: 0.006326467730104923
step: 310, loss: 0.0007754020625725389
step: 320, loss: 0.0005878470255993307
step: 330, loss: 0.008733592927455902
step: 340, loss: 0.00012058726861141622
step: 350, loss: 0.003073565661907196
epoch 15: dev_f1=0.7980535279805353, f1=0.7607655502392345, best_f1=0.7589498806682576
step: 0, loss: 0.0001607973681529984
step: 10, loss: 0.0002466729492880404
step: 20, loss: 0.00029404135420918465
step: 30, loss: 0.00952768325805664
step: 40, loss: 0.0005808669375255704
step: 50, loss: 0.018535293638706207
step: 60, loss: 0.00010074867168441415
step: 70, loss: 6.235855107661337e-05
step: 80, loss: 0.0056951092556118965
step: 90, loss: 0.00010684152948670089
step: 100, loss: 0.053536612540483475
step: 110, loss: 0.015926042571663857
step: 120, loss: 0.009793567471206188
step: 130, loss: 8.837177301757038e-05
step: 140, loss: 8.784570673014969e-05
step: 150, loss: 0.000209358666324988
step: 160, loss: 6.416910764528438e-05
step: 170, loss: 0.00017400408978573978
step: 180, loss: 0.0011142247822135687
step: 190, loss: 0.03281118720769882
step: 200, loss: 0.00010954845492960885
step: 210, loss: 0.0004082299710717052
step: 220, loss: 0.0013059522025287151
step: 230, loss: 0.0007731199730187654
step: 240, loss: 5.000987584935501e-05
step: 250, loss: 3.3541185985086486e-05
step: 260, loss: 3.419639324420132e-05
step: 270, loss: 7.565780833829194e-05
step: 280, loss: 2.1944690161035396e-05
step: 290, loss: 0.0002990479697473347
step: 300, loss: 6.947493238840252e-05
step: 310, loss: 5.669540405506268e-05
step: 320, loss: 0.0003933112311642617
step: 330, loss: 7.625505531905219e-05
step: 340, loss: 0.001700368826277554
step: 350, loss: 0.014457174576818943
epoch 16: dev_f1=0.797979797979798, f1=0.7654320987654322, best_f1=0.7589498806682576
step: 0, loss: 2.5860137611743994e-05
step: 10, loss: 7.186231232481077e-05
step: 20, loss: 8.213243563659489e-05
step: 30, loss: 2.951429269160144e-05
step: 40, loss: 0.00015928280481602997
step: 50, loss: 0.00018506681954022497
step: 60, loss: 0.001045669661834836
step: 70, loss: 5.2481402235571295e-05
step: 80, loss: 0.009549767710268497
step: 90, loss: 0.0427015982568264
step: 100, loss: 0.0002563917078077793
step: 110, loss: 2.713659341679886e-05
step: 120, loss: 0.00016846046491991729
step: 130, loss: 2.6184210582869127e-05
step: 140, loss: 0.0003337936941534281
step: 150, loss: 0.0004081906226929277
step: 160, loss: 0.0023030289448797703
step: 170, loss: 0.0010471190325915813
step: 180, loss: 0.001147376256994903
step: 190, loss: 0.00010739476419985294
step: 200, loss: 7.760605512885377e-05
step: 210, loss: 0.002414102666079998
step: 220, loss: 7.08912339177914e-05
step: 230, loss: 0.013697362504899502
step: 240, loss: 0.01063090842217207
step: 250, loss: 7.660936535103247e-05
step: 260, loss: 6.414193921955302e-05
step: 270, loss: 8.259147580247372e-05
step: 280, loss: 0.0005025818245485425
step: 290, loss: 0.061713799834251404
step: 300, loss: 0.0007524644606746733
step: 310, loss: 5.8025882026413456e-05
step: 320, loss: 0.00012131658149883151
step: 330, loss: 6.923651380930096e-05
step: 340, loss: 0.00017237436259165406
step: 350, loss: 0.006041533779352903
epoch 17: dev_f1=0.8126520681265207, f1=0.748235294117647, best_f1=0.7589498806682576
step: 0, loss: 0.00016050781414378434
step: 10, loss: 0.00012855608656536788
step: 20, loss: 5.7032204495044425e-05
step: 30, loss: 0.0005700039910152555
step: 40, loss: 0.00017112260684370995
step: 50, loss: 0.0008155874675139785
step: 60, loss: 0.019607771188020706
step: 70, loss: 0.011817249469459057
step: 80, loss: 0.0013077137991786003
step: 90, loss: 0.012195296585559845
step: 100, loss: 8.931079355534166e-05
step: 110, loss: 7.610255852341652e-05
step: 120, loss: 0.0024973719846457243
step: 130, loss: 0.00015412882203236222
step: 140, loss: 5.6879543990362436e-05
step: 150, loss: 0.00026544893626123667
step: 160, loss: 0.00024278927594423294
step: 170, loss: 0.0007701721624471247
step: 180, loss: 0.00012689639697782695
step: 190, loss: 0.0011679845629259944
step: 200, loss: 5.0366892537567765e-05
step: 210, loss: 0.00203823228366673
step: 220, loss: 0.016315853223204613
step: 230, loss: 0.000954771414399147
step: 240, loss: 9.13531839614734e-05
step: 250, loss: 0.0006668278947472572
step: 260, loss: 0.0005044860881753266
step: 270, loss: 8.473944035358727e-05
step: 280, loss: 0.00018602030468173325
step: 290, loss: 0.00022788485512137413
step: 300, loss: 0.0007901627686806023
step: 310, loss: 6.021087392582558e-05
step: 320, loss: 0.0012820111587643623
step: 330, loss: 0.014001716859638691
step: 340, loss: 0.00045920119737274945
step: 350, loss: 0.0008881292887963355
epoch 18: dev_f1=0.7929292929292929, f1=0.7753086419753086, best_f1=0.7589498806682576
step: 0, loss: 0.00023919757222756743
step: 10, loss: 0.0002969123888760805
step: 20, loss: 5.7797195040620863e-05
step: 30, loss: 0.005973575171083212
step: 40, loss: 0.00019716731912922114
step: 50, loss: 0.00045972736552357674
step: 60, loss: 0.00018942655879072845
step: 70, loss: 0.0013790820958092809
step: 80, loss: 9.58727760007605e-05
step: 90, loss: 0.0005407784483395517
step: 100, loss: 0.0003806111344601959
step: 110, loss: 0.025266777724027634
step: 120, loss: 0.009940310381352901
step: 130, loss: 2.5148639906547032e-05
step: 140, loss: 0.002270774682983756
step: 150, loss: 2.9335380531847477e-05
step: 160, loss: 0.00019657892698887736
step: 170, loss: 0.0012078492436558008
step: 180, loss: 0.00011855285265482962
step: 190, loss: 0.0033200408797711134
step: 200, loss: 4.9617690820014104e-05
step: 210, loss: 0.00016662527923472226
step: 220, loss: 4.210477709420957e-05
step: 230, loss: 0.017111072316765785
step: 240, loss: 0.0019542945083230734
step: 250, loss: 0.00016939686611294746
step: 260, loss: 0.00022207315487321466
step: 270, loss: 6.92300163791515e-05
step: 280, loss: 0.0057268706150352955
step: 290, loss: 0.00031426185159944
step: 300, loss: 0.00010676313831936568
step: 310, loss: 0.0007612155750393867
step: 320, loss: 0.0002233638515463099
step: 330, loss: 0.00010013216524384916
step: 340, loss: 5.521182538359426e-05
step: 350, loss: 0.007115534972399473
epoch 19: dev_f1=0.798994974874372, f1=0.7518796992481204, best_f1=0.7589498806682576
step: 0, loss: 0.008341978304088116
step: 10, loss: 0.00017990874766837806
step: 20, loss: 9.423910523764789e-05
step: 30, loss: 0.00027047310140915215
step: 40, loss: 4.22741322836373e-05
step: 50, loss: 3.018863935722038e-05
step: 60, loss: 9.950147796189412e-05
step: 70, loss: 0.0026353702414780855
step: 80, loss: 0.0001732397940941155
step: 90, loss: 0.0006657082703895867
step: 100, loss: 5.7165540056303144e-05
step: 110, loss: 0.00016636383952572942
step: 120, loss: 1.943431925610639e-05
step: 130, loss: 0.00046012175153009593
step: 140, loss: 0.00018801346595864743
step: 150, loss: 3.9859412936493754e-05
step: 160, loss: 5.380428774515167e-05
step: 170, loss: 2.1755020497948863e-05
step: 180, loss: 4.356448698672466e-05
step: 190, loss: 3.9506769098807126e-05
step: 200, loss: 0.00011722684575943276
step: 210, loss: 0.00021575910795945674
step: 220, loss: 0.0001061339644365944
step: 230, loss: 8.164203609339893e-05
step: 240, loss: 0.00040811533108353615
step: 250, loss: 0.031915731728076935
step: 260, loss: 7.739471038803458e-05
step: 270, loss: 0.0012068860232830048
step: 280, loss: 0.00015522541070822626
step: 290, loss: 9.106512152357027e-05
step: 300, loss: 0.002736232941970229
step: 310, loss: 4.964437539456412e-05
step: 320, loss: 5.866791616426781e-05
step: 330, loss: 2.6344319849158637e-05
step: 340, loss: 6.608638796024024e-05
step: 350, loss: 7.214968354674056e-05
epoch 20: dev_f1=0.801007556675063, f1=0.7487437185929648, best_f1=0.7589498806682576
