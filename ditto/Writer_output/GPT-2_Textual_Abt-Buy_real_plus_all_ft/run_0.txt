cuda
Device: cuda
step: 0, loss: 1.0537792444229126
step: 10, loss: 0.4808608293533325
step: 20, loss: 0.4444005489349365
step: 30, loss: 0.50751793384552
step: 40, loss: 0.31845760345458984
step: 50, loss: 0.4561441242694855
step: 60, loss: 0.31582197546958923
step: 70, loss: 0.15115436911582947
step: 80, loss: 0.3724900782108307
step: 90, loss: 0.3720402717590332
step: 100, loss: 0.2831089496612549
step: 110, loss: 0.5502097606658936
step: 120, loss: 0.14805597066879272
step: 130, loss: 0.26011309027671814
step: 140, loss: 0.32326287031173706
step: 150, loss: 0.30180057883262634
step: 160, loss: 0.298293799161911
step: 170, loss: 0.3241655230522156
step: 180, loss: 0.19409628212451935
step: 190, loss: 0.26351580023765564
step: 200, loss: 0.32334470748901367
step: 210, loss: 0.2657788097858429
step: 220, loss: 0.5920798778533936
step: 230, loss: 0.14981190860271454
step: 240, loss: 0.22979868948459625
step: 250, loss: 0.4447668492794037
step: 260, loss: 0.18997544050216675
step: 270, loss: 0.2660949230194092
step: 280, loss: 0.2744022607803345
step: 290, loss: 0.6232364177703857
step: 300, loss: 0.23944005370140076
step: 310, loss: 0.2493554800748825
step: 320, loss: 0.16661080718040466
step: 330, loss: 0.22312559187412262
step: 340, loss: 0.14934465289115906
step: 350, loss: 0.22076544165611267
epoch 1: dev_f1=0.7220902612826603, f1=0.672686230248307, best_f1=0.672686230248307
step: 0, loss: 0.24075999855995178
step: 10, loss: 0.11659856885671616
step: 20, loss: 0.17276401817798615
step: 30, loss: 0.06011347845196724
step: 40, loss: 0.26224052906036377
step: 50, loss: 0.22476738691329956
step: 60, loss: 0.4539962112903595
step: 70, loss: 0.31995606422424316
step: 80, loss: 0.2774733006954193
step: 90, loss: 0.2696797549724579
step: 100, loss: 0.17440514266490936
step: 110, loss: 0.14822307229042053
step: 120, loss: 0.331788033246994
step: 130, loss: 0.2665596306324005
step: 140, loss: 0.15439459681510925
step: 150, loss: 0.18927998840808868
step: 160, loss: 0.16754133999347687
step: 170, loss: 0.20036977529525757
step: 180, loss: 0.27102819085121155
step: 190, loss: 0.08298775553703308
step: 200, loss: 0.20863109827041626
step: 210, loss: 0.05414852499961853
step: 220, loss: 0.345220148563385
step: 230, loss: 0.2629774808883667
step: 240, loss: 0.1839400976896286
step: 250, loss: 0.16333933174610138
step: 260, loss: 0.12258519977331161
step: 270, loss: 0.2375899851322174
step: 280, loss: 0.049983225762844086
step: 290, loss: 0.1360412836074829
step: 300, loss: 0.03411150723695755
step: 310, loss: 0.1472354531288147
step: 320, loss: 0.03813697770237923
step: 330, loss: 0.17832514643669128
step: 340, loss: 0.06202291324734688
step: 350, loss: 0.03740962967276573
epoch 2: dev_f1=0.729528535980149, f1=0.6885245901639344, best_f1=0.6885245901639344
step: 0, loss: 0.03599048778414726
step: 10, loss: 0.2671244442462921
step: 20, loss: 0.11294584721326828
step: 30, loss: 0.08652272820472717
step: 40, loss: 0.15268030762672424
step: 50, loss: 0.06096425652503967
step: 60, loss: 0.19264979660511017
step: 70, loss: 0.23288580775260925
step: 80, loss: 0.12147622555494308
step: 90, loss: 0.026777584105730057
step: 100, loss: 0.09891757369041443
step: 110, loss: 0.06452125310897827
step: 120, loss: 0.061435312032699585
step: 130, loss: 0.0777481198310852
step: 140, loss: 0.028303619474172592
step: 150, loss: 0.06480729579925537
step: 160, loss: 0.033850524574518204
step: 170, loss: 0.19423796236515045
step: 180, loss: 0.04141157120466232
step: 190, loss: 0.022993866354227066
step: 200, loss: 0.07932985574007034
step: 210, loss: 0.1276954561471939
step: 220, loss: 0.11258948594331741
step: 230, loss: 0.04259643331170082
step: 240, loss: 0.13184726238250732
step: 250, loss: 0.10561691969633102
step: 260, loss: 0.037680186331272125
step: 270, loss: 0.15417161583900452
step: 280, loss: 0.1760697066783905
step: 290, loss: 0.020536648109555244
step: 300, loss: 0.10834817588329315
step: 310, loss: 0.02732096053659916
step: 320, loss: 0.2403903305530548
step: 330, loss: 0.12298072874546051
step: 340, loss: 0.1798545867204666
step: 350, loss: 0.07354212552309036
epoch 3: dev_f1=0.7378640776699028, f1=0.7247058823529412, best_f1=0.7247058823529412
step: 0, loss: 0.0368044339120388
step: 10, loss: 0.0723097026348114
step: 20, loss: 0.014031360857188702
step: 30, loss: 0.0031109866686165333
step: 40, loss: 0.0070956130512058735
step: 50, loss: 0.0824044942855835
step: 60, loss: 0.025320492684841156
step: 70, loss: 0.021341092884540558
step: 80, loss: 0.12895002961158752
step: 90, loss: 0.015796251595020294
step: 100, loss: 0.02044375240802765
step: 110, loss: 0.11331783980131149
step: 120, loss: 0.03410150110721588
step: 130, loss: 0.09178047627210617
step: 140, loss: 0.006091495975852013
step: 150, loss: 0.09407809376716614
step: 160, loss: 0.049496810883283615
step: 170, loss: 0.19544772803783417
step: 180, loss: 0.06781107932329178
step: 190, loss: 0.016630947589874268
step: 200, loss: 0.02300514280796051
step: 210, loss: 0.03624070808291435
step: 220, loss: 0.037605125457048416
step: 230, loss: 0.0459442064166069
step: 240, loss: 0.04953175038099289
step: 250, loss: 0.06505602598190308
step: 260, loss: 0.016542227938771248
step: 270, loss: 0.02955898828804493
step: 280, loss: 0.011849379166960716
step: 290, loss: 0.03274849057197571
step: 300, loss: 0.04839295893907547
step: 310, loss: 0.008482600562274456
step: 320, loss: 0.12383946776390076
step: 330, loss: 0.01880757510662079
step: 340, loss: 0.0615123026072979
step: 350, loss: 0.001298646442592144
epoch 4: dev_f1=0.7715736040609138, f1=0.7554479418886199, best_f1=0.7554479418886199
step: 0, loss: 0.028517993167042732
step: 10, loss: 0.01767985336482525
step: 20, loss: 0.03304275497794151
step: 30, loss: 0.0454513244330883
step: 40, loss: 0.08885163068771362
step: 50, loss: 0.0062820790335536
step: 60, loss: 0.009040704928338528
step: 70, loss: 0.013497643172740936
step: 80, loss: 0.014300035312771797
step: 90, loss: 0.0016534755704924464
step: 100, loss: 0.0619734451174736
step: 110, loss: 0.011541303247213364
step: 120, loss: 0.06148906052112579
step: 130, loss: 0.030210481956601143
step: 140, loss: 0.04009351506829262
step: 150, loss: 0.0066534290090203285
step: 160, loss: 0.0075596109963953495
step: 170, loss: 0.006435396149754524
step: 180, loss: 0.0191913153976202
step: 190, loss: 0.00291926646605134
step: 200, loss: 0.023438414558768272
step: 210, loss: 0.003993701189756393
step: 220, loss: 0.016891177743673325
step: 230, loss: 0.05684477463364601
step: 240, loss: 0.18809634447097778
step: 250, loss: 0.05102519690990448
step: 260, loss: 0.03246016800403595
step: 270, loss: 0.025745118036866188
step: 280, loss: 0.007649809587746859
step: 290, loss: 0.1658444106578827
step: 300, loss: 0.005759717430919409
step: 310, loss: 0.008220857009291649
step: 320, loss: 0.006710590794682503
step: 330, loss: 0.02342233993113041
step: 340, loss: 0.09885840862989426
step: 350, loss: 0.06456281244754791
epoch 5: dev_f1=0.7554585152838427, f1=0.7379912663755459, best_f1=0.7554479418886199
step: 0, loss: 0.024006979539990425
step: 10, loss: 0.0019672918133437634
step: 20, loss: 0.006784165743738413
step: 30, loss: 0.0397818461060524
step: 40, loss: 0.010866107419133186
step: 50, loss: 0.06588337570428848
step: 60, loss: 0.0024987284559756517
step: 70, loss: 0.01495454739779234
step: 80, loss: 0.045401133596897125
step: 90, loss: 0.019395096227526665
step: 100, loss: 0.05639621987938881
step: 110, loss: 0.0560777373611927
step: 120, loss: 0.0020213250536471605
step: 130, loss: 0.10720308870077133
step: 140, loss: 0.04168035835027695
step: 150, loss: 0.03443508222699165
step: 160, loss: 0.030025074258446693
step: 170, loss: 0.11229506134986877
step: 180, loss: 0.01421063207089901
step: 190, loss: 0.022341379895806313
step: 200, loss: 0.005231225863099098
step: 210, loss: 0.006681669969111681
step: 220, loss: 0.143268883228302
step: 230, loss: 0.05003726854920387
step: 240, loss: 0.05443872511386871
step: 250, loss: 0.012268123216927052
step: 260, loss: 0.029087083414196968
step: 270, loss: 0.041736166924238205
step: 280, loss: 0.09833664447069168
step: 290, loss: 0.028797002509236336
step: 300, loss: 0.0024244096130132675
step: 310, loss: 0.0617775060236454
step: 320, loss: 0.0011497718514874578
step: 330, loss: 0.014532681554555893
step: 340, loss: 0.012254118919372559
step: 350, loss: 0.046934302896261215
epoch 6: dev_f1=0.76056338028169, f1=0.7330316742081447, best_f1=0.7554479418886199
step: 0, loss: 0.00029646774055436254
step: 10, loss: 0.058926958590745926
step: 20, loss: 0.03495202586054802
step: 30, loss: 0.00818414706736803
step: 40, loss: 0.00232698698528111
step: 50, loss: 0.019307631999254227
step: 60, loss: 0.001261597266420722
step: 70, loss: 0.01704488880932331
step: 80, loss: 0.027766741812229156
step: 90, loss: 0.013274839147925377
step: 100, loss: 0.005689993035048246
step: 110, loss: 0.00038597366074100137
step: 120, loss: 0.0008890564204193652
step: 130, loss: 0.0011311420239508152
step: 140, loss: 0.02344517782330513
step: 150, loss: 0.007906886748969555
step: 160, loss: 0.06932761520147324
step: 170, loss: 0.0002636474964674562
step: 180, loss: 0.02160673588514328
step: 190, loss: 0.01657022535800934
step: 200, loss: 0.13176272809505463
step: 210, loss: 0.12702392041683197
step: 220, loss: 0.08708897233009338
step: 230, loss: 0.0031723869033157825
step: 240, loss: 0.0068605924025177956
step: 250, loss: 0.1059969887137413
step: 260, loss: 0.02261010929942131
step: 270, loss: 0.1415947824716568
step: 280, loss: 0.011012105271220207
step: 290, loss: 0.0007927375845611095
step: 300, loss: 0.008459220640361309
step: 310, loss: 0.004862841218709946
step: 320, loss: 0.004114141222089529
step: 330, loss: 0.01300535537302494
step: 340, loss: 0.02488047443330288
step: 350, loss: 0.04090995341539383
epoch 7: dev_f1=0.7673860911270983, f1=0.7499999999999999, best_f1=0.7554479418886199
step: 0, loss: 0.004461167845875025
step: 10, loss: 0.0020398972555994987
step: 20, loss: 0.04388190433382988
step: 30, loss: 0.014921344816684723
step: 40, loss: 0.004255875013768673
step: 50, loss: 0.0015160075854510069
step: 60, loss: 0.01625058799982071
step: 70, loss: 0.034712065011262894
step: 80, loss: 0.0684865266084671
step: 90, loss: 0.040121275931596756
step: 100, loss: 0.22834321856498718
step: 110, loss: 0.0072447932325303555
step: 120, loss: 0.002499424386769533
step: 130, loss: 0.0008829020662233233
step: 140, loss: 0.0011852384777739644
step: 150, loss: 0.0006864222232252359
step: 160, loss: 0.010242577642202377
step: 170, loss: 0.0005448171286843717
step: 180, loss: 0.008353807032108307
step: 190, loss: 0.05799448862671852
step: 200, loss: 0.003053246531635523
step: 210, loss: 0.00385447614826262
step: 220, loss: 0.026132332161068916
step: 230, loss: 0.00039302377263084054
step: 240, loss: 0.1335255652666092
step: 250, loss: 0.006109635811299086
step: 260, loss: 0.04683198779821396
step: 270, loss: 0.0007898606127128005
step: 280, loss: 0.000428809697041288
step: 290, loss: 0.01839251071214676
step: 300, loss: 0.015218003652989864
step: 310, loss: 0.0032151793129742146
step: 320, loss: 0.061462417244911194
step: 330, loss: 0.012654900550842285
step: 340, loss: 0.002049233764410019
step: 350, loss: 0.0038503578398376703
epoch 8: dev_f1=0.7898734177215191, f1=0.7563451776649747, best_f1=0.7563451776649747
step: 0, loss: 0.005446864292025566
step: 10, loss: 0.0012482458259910345
step: 20, loss: 0.0011034770868718624
step: 30, loss: 0.0037538413889706135
step: 40, loss: 0.0002556224353611469
step: 50, loss: 0.0017823035595938563
step: 60, loss: 0.0007903471705503762
step: 70, loss: 0.0028239272069185972
step: 80, loss: 0.0014208103530108929
step: 90, loss: 0.021437523886561394
step: 100, loss: 0.0008702237973921001
step: 110, loss: 0.0010310984216630459
step: 120, loss: 0.020076872780919075
step: 130, loss: 0.0021319012157619
step: 140, loss: 0.0004396851873025298
step: 150, loss: 0.0012663441011682153
step: 160, loss: 0.029549403116106987
step: 170, loss: 0.0007363832555711269
step: 180, loss: 0.0020566077437251806
step: 190, loss: 0.0031005442142486572
step: 200, loss: 0.01712837815284729
step: 210, loss: 0.00013604084961116314
step: 220, loss: 0.0006516227149404585
step: 230, loss: 0.021854661405086517
step: 240, loss: 0.05723503977060318
step: 250, loss: 0.0012452874798327684
step: 260, loss: 0.012697079218924046
step: 270, loss: 0.00010059775377158076
step: 280, loss: 0.000466653989860788
step: 290, loss: 0.00979706272482872
step: 300, loss: 0.0018721326487138867
step: 310, loss: 0.029569733887910843
step: 320, loss: 0.0010043610818684101
step: 330, loss: 0.0003452069649938494
step: 340, loss: 0.07363283634185791
step: 350, loss: 0.015444454737007618
epoch 9: dev_f1=0.7676767676767677, f1=0.7153284671532846, best_f1=0.7563451776649747
step: 0, loss: 0.002648170106112957
step: 10, loss: 0.005124792922288179
step: 20, loss: 0.008243481628596783
step: 30, loss: 0.003077179193496704
step: 40, loss: 0.005981833208352327
step: 50, loss: 0.003473035991191864
step: 60, loss: 0.050976790487766266
step: 70, loss: 0.020056532695889473
step: 80, loss: 0.00018544954946264625
step: 90, loss: 0.0038747452199459076
step: 100, loss: 0.0009289223235100508
step: 110, loss: 0.001159129897132516
step: 120, loss: 0.002095645759254694
step: 130, loss: 0.00016496446914970875
step: 140, loss: 0.004775035660713911
step: 150, loss: 0.0008247948135249317
step: 160, loss: 0.0010966530535370111
step: 170, loss: 0.002217997796833515
step: 180, loss: 0.0014271725667640567
step: 190, loss: 0.000721410964615643
step: 200, loss: 0.0012146426597610116
step: 210, loss: 0.024443956092000008
step: 220, loss: 0.027852008119225502
step: 230, loss: 0.0017083125421777368
step: 240, loss: 0.014315832406282425
step: 250, loss: 0.019427413120865822
step: 260, loss: 0.0005594572867266834
step: 270, loss: 0.026649223640561104
step: 280, loss: 0.0003972288977820426
step: 290, loss: 0.04046918451786041
step: 300, loss: 0.026146354153752327
step: 310, loss: 6.0828613641206175e-05
step: 320, loss: 0.03250553831458092
step: 330, loss: 0.0005289780092425644
step: 340, loss: 0.0073105948977172375
step: 350, loss: 6.188923725858331e-05
epoch 10: dev_f1=0.7783505154639175, f1=0.7448979591836735, best_f1=0.7563451776649747
step: 0, loss: 0.00021325091074686497
step: 10, loss: 0.0003528199449647218
step: 20, loss: 0.00029423265368677676
step: 30, loss: 0.0012868914054706693
step: 40, loss: 0.07767271250486374
step: 50, loss: 0.010161660611629486
step: 60, loss: 0.003221028484404087
step: 70, loss: 0.0032751187682151794
step: 80, loss: 0.003953702747821808
step: 90, loss: 0.011045422405004501
step: 100, loss: 0.0005449590971693397
step: 110, loss: 0.0033949841745197773
step: 120, loss: 0.0014630891382694244
step: 130, loss: 0.005777610931545496
step: 140, loss: 0.0009659604402258992
step: 150, loss: 7.742848538327962e-05
step: 160, loss: 0.0003237902419641614
step: 170, loss: 0.00010230994666926563
step: 180, loss: 0.0018969620577991009
step: 190, loss: 0.013319797813892365
step: 200, loss: 0.00617913156747818
step: 210, loss: 0.0011153455125167966
step: 220, loss: 0.00035147907328791916
step: 230, loss: 0.0008072371128946543
step: 240, loss: 0.18794924020767212
step: 250, loss: 0.0009645137470215559
step: 260, loss: 0.002140210010111332
step: 270, loss: 0.005729375407099724
step: 280, loss: 0.0017651068046689034
step: 290, loss: 0.004486670717597008
step: 300, loss: 0.0018599710892885923
step: 310, loss: 0.0004359278245829046
step: 320, loss: 0.013562106527388096
step: 330, loss: 0.0020101964473724365
step: 340, loss: 0.0009568548412062228
step: 350, loss: 0.00809564534574747
epoch 11: dev_f1=0.7676767676767677, f1=0.7487684729064039, best_f1=0.7563451776649747
step: 0, loss: 0.0005663087940774858
step: 10, loss: 0.00016866018995642662
step: 20, loss: 0.011791357770562172
step: 30, loss: 0.0012837558751925826
step: 40, loss: 0.001881028525531292
step: 50, loss: 0.0005752230645157397
step: 60, loss: 0.0007190077449195087
step: 70, loss: 0.07932809740304947
step: 80, loss: 0.00043308260501362383
step: 90, loss: 0.002910946263000369
step: 100, loss: 0.004752269480377436
step: 110, loss: 0.00022886539227329195
step: 120, loss: 0.0020845422986894846
step: 130, loss: 0.11293439567089081
step: 140, loss: 0.012706216424703598
step: 150, loss: 0.02248450182378292
step: 160, loss: 0.017418596893548965
step: 170, loss: 0.0032913112081587315
step: 180, loss: 0.0002455737558193505
step: 190, loss: 0.0007498498889617622
step: 200, loss: 0.0001703922898741439
step: 210, loss: 0.002071618800982833
step: 220, loss: 0.003344433382153511
step: 230, loss: 0.004191992804408073
step: 240, loss: 0.0004786541103385389
step: 250, loss: 0.036435846239328384
step: 260, loss: 0.0007435876759700477
step: 270, loss: 0.0014983587898314
step: 280, loss: 0.06722038984298706
step: 290, loss: 0.0008919881074689329
step: 300, loss: 0.0002490691840648651
step: 310, loss: 0.0009491026867181063
step: 320, loss: 0.00011338631884427741
step: 330, loss: 0.009300997480750084
step: 340, loss: 3.179807390552014e-05
step: 350, loss: 0.060694534331560135
epoch 12: dev_f1=0.7589743589743588, f1=0.7358024691358026, best_f1=0.7563451776649747
step: 0, loss: 0.0021610583644360304
step: 10, loss: 0.0011127518955618143
step: 20, loss: 0.0001225210289703682
step: 30, loss: 0.00038983064587228
step: 40, loss: 3.8219070120248944e-05
step: 50, loss: 0.00034941238118335605
step: 60, loss: 0.02887773886322975
step: 70, loss: 0.0032274110708385706
step: 80, loss: 0.02344769611954689
step: 90, loss: 0.00043962104246020317
step: 100, loss: 0.005106640048325062
step: 110, loss: 0.00020941505499649793
step: 120, loss: 0.0009820450795814395
step: 130, loss: 0.00015492677630390972
step: 140, loss: 0.002010197378695011
step: 150, loss: 0.23806732892990112
step: 160, loss: 0.003382959170266986
step: 170, loss: 0.010869856923818588
step: 180, loss: 0.000999358599074185
step: 190, loss: 0.00027201182092539966
step: 200, loss: 0.007801634259521961
step: 210, loss: 0.0006894678226672113
step: 220, loss: 0.0026042142417281866
step: 230, loss: 0.004137727897614241
step: 240, loss: 0.0004567436408251524
step: 250, loss: 0.0061583565548062325
step: 260, loss: 0.0003558402240741998
step: 270, loss: 0.0004891222924925387
step: 280, loss: 0.005135961342602968
step: 290, loss: 0.03278231620788574
step: 300, loss: 0.005421084817498922
step: 310, loss: 0.0034541261848062277
step: 320, loss: 0.006643418222665787
step: 330, loss: 0.001479906844906509
step: 340, loss: 0.0020002457313239574
step: 350, loss: 0.003032993758097291
epoch 13: dev_f1=0.7726161369193154, f1=0.7378640776699028, best_f1=0.7563451776649747
step: 0, loss: 0.006303764414042234
step: 10, loss: 0.0004720661963801831
step: 20, loss: 0.0009523595217615366
step: 30, loss: 0.0014707118971273303
step: 40, loss: 0.016572482883930206
step: 50, loss: 0.0002851357567124069
step: 60, loss: 0.0004073331947438419
step: 70, loss: 0.00026786685339175165
step: 80, loss: 0.00015325711865443736
step: 90, loss: 0.018327051773667336
step: 100, loss: 0.0008069878676906228
step: 110, loss: 0.002885570051148534
step: 120, loss: 0.022433442994952202
step: 130, loss: 0.001227930886670947
step: 140, loss: 7.111328886821866e-05
step: 150, loss: 0.0011116991518065333
step: 160, loss: 0.0032949298620224
step: 170, loss: 0.00032564872526563704
step: 180, loss: 0.0004984873230569065
step: 190, loss: 0.07012978941202164
step: 200, loss: 0.008946388959884644
step: 210, loss: 0.00041349700768478215
step: 220, loss: 0.047258537262678146
step: 230, loss: 0.04200039058923721
step: 240, loss: 0.0022536609321832657
step: 250, loss: 0.0021993310656398535
step: 260, loss: 0.00011149297642987221
step: 270, loss: 0.014250854030251503
step: 280, loss: 0.0008354104938916862
step: 290, loss: 0.009459747932851315
step: 300, loss: 0.0002589514770079404
step: 310, loss: 0.05429685115814209
step: 320, loss: 0.0007318927091546357
step: 330, loss: 0.002339527476578951
step: 340, loss: 0.00032833361183293164
step: 350, loss: 0.029022743925452232
epoch 14: dev_f1=0.7713498622589533, f1=0.75, best_f1=0.7563451776649747
step: 0, loss: 0.008113198913633823
step: 10, loss: 0.06569638848304749
step: 20, loss: 0.005172721575945616
step: 30, loss: 0.0004665117303375155
step: 40, loss: 0.03624128922820091
step: 50, loss: 0.011111375875771046
step: 60, loss: 0.0001305733749177307
step: 70, loss: 0.0008835846674628556
step: 80, loss: 0.0019087495747953653
step: 90, loss: 0.0004031051357742399
step: 100, loss: 0.004822759889066219
step: 110, loss: 0.004499336704611778
step: 120, loss: 0.006634263321757317
step: 130, loss: 6.119836325524375e-05
step: 140, loss: 0.00012569161481224
step: 150, loss: 0.0013292268849909306
step: 160, loss: 0.0033620677422732115
step: 170, loss: 0.003108968259766698
step: 180, loss: 3.9576083509018645e-05
step: 190, loss: 0.000308744958601892
step: 200, loss: 0.0007761779706925154
step: 210, loss: 0.0001237892865901813
step: 220, loss: 0.0004118017095606774
step: 230, loss: 0.00019232070189900696
step: 240, loss: 0.0001812866685213521
step: 250, loss: 3.762323103728704e-05
step: 260, loss: 0.06848842650651932
step: 270, loss: 0.007052907254546881
step: 280, loss: 0.0005690656253136694
step: 290, loss: 0.0018888040212914348
step: 300, loss: 9.86306622507982e-05
step: 310, loss: 0.009246369823813438
step: 320, loss: 0.0002580393338575959
step: 330, loss: 0.0004019766638521105
step: 340, loss: 9.897982818074524e-05
step: 350, loss: 0.000680978992022574
epoch 15: dev_f1=0.7545219638242895, f1=0.7444168734491315, best_f1=0.7563451776649747
step: 0, loss: 0.00010575111082289368
step: 10, loss: 0.11571608483791351
step: 20, loss: 0.002609632909297943
step: 30, loss: 0.008473604917526245
step: 40, loss: 0.000274251913651824
step: 50, loss: 0.0006808812613599002
step: 60, loss: 0.010641525499522686
step: 70, loss: 5.007264917367138e-05
step: 80, loss: 0.0009602539939805865
step: 90, loss: 0.08987768739461899
step: 100, loss: 0.00023161136778071523
step: 110, loss: 0.0004792467807419598
step: 120, loss: 0.0003224346728529781
step: 130, loss: 0.0003262961108703166
step: 140, loss: 0.000297940568998456
step: 150, loss: 0.00017328500689473003
step: 160, loss: 0.000343049323419109
step: 170, loss: 0.0003191200958099216
step: 180, loss: 0.00024047127226367593
step: 190, loss: 0.00021549964731093496
step: 200, loss: 0.16047228872776031
step: 210, loss: 0.0005126033211126924
step: 220, loss: 0.001276796800084412
step: 230, loss: 0.0006762135890312493
step: 240, loss: 0.00046721837134100497
step: 250, loss: 0.000706265214830637
step: 260, loss: 0.00020983419381082058
step: 270, loss: 0.0034131924621760845
step: 280, loss: 0.0001254822127521038
step: 290, loss: 0.00013287931506056339
step: 300, loss: 0.00022070083650760353
step: 310, loss: 0.0016082556685432792
step: 320, loss: 0.004168604034930468
step: 330, loss: 0.0676073431968689
step: 340, loss: 0.031562503427267075
step: 350, loss: 0.004337618593126535
epoch 16: dev_f1=0.779746835443038, f1=0.7525252525252526, best_f1=0.7563451776649747
step: 0, loss: 0.0001536815834697336
step: 10, loss: 4.6798184484941885e-05
step: 20, loss: 0.0001448605180485174
step: 30, loss: 9.43704362725839e-05
step: 40, loss: 0.00014010112499818206
step: 50, loss: 0.0004912173608317971
step: 60, loss: 4.076345430803485e-05
step: 70, loss: 0.0001921840594150126
step: 80, loss: 0.009075604379177094
step: 90, loss: 0.0006275504129007459
step: 100, loss: 0.0008107366156764328
step: 110, loss: 0.00012355130456853658
step: 120, loss: 4.990856905351393e-05
step: 130, loss: 0.00046003449824638665
step: 140, loss: 4.6237266360549256e-05
step: 150, loss: 0.001926402561366558
step: 160, loss: 5.120650530443527e-05
step: 170, loss: 9.831620991462842e-05
step: 180, loss: 0.0002361699880566448
step: 190, loss: 0.0002504688745830208
step: 200, loss: 0.0004506657423917204
step: 210, loss: 0.0005096810637041926
step: 220, loss: 0.00011974365770583972
step: 230, loss: 0.0004990871530026197
step: 240, loss: 0.00017473570187576115
step: 250, loss: 0.0008661149768158793
step: 260, loss: 0.0002489645266905427
step: 270, loss: 0.0008233679691329598
step: 280, loss: 0.0002203865587944165
step: 290, loss: 0.0152733838185668
step: 300, loss: 0.0003284070990048349
step: 310, loss: 0.00010311298683518544
step: 320, loss: 0.00012664678797591478
step: 330, loss: 0.00021344015840440989
step: 340, loss: 7.337157876463607e-05
step: 350, loss: 8.784696547081694e-05
epoch 17: dev_f1=0.7726161369193154, f1=0.7482014388489209, best_f1=0.7563451776649747
step: 0, loss: 0.00019884023640770465
step: 10, loss: 0.004368629772216082
step: 20, loss: 0.000142058968776837
step: 30, loss: 0.00010581439710222185
step: 40, loss: 0.00018216928583569825
step: 50, loss: 0.00013820288586430252
step: 60, loss: 0.0194795373827219
step: 70, loss: 0.0001252984075108543
step: 80, loss: 0.004746215417981148
step: 90, loss: 0.0004379361344035715
step: 100, loss: 0.00070074392715469
step: 110, loss: 0.0031803022138774395
step: 120, loss: 6.527360528707504e-05
step: 130, loss: 0.00014708282833453268
step: 140, loss: 0.0002892026968766004
step: 150, loss: 0.0001699300919426605
step: 160, loss: 7.429137622239068e-05
step: 170, loss: 0.0001082286107703112
step: 180, loss: 0.0011258897138759494
step: 190, loss: 9.936596325132996e-05
step: 200, loss: 0.0012870404170826077
step: 210, loss: 0.00025863852351903915
step: 220, loss: 0.00018317966896574944
step: 230, loss: 6.894295802339911e-05
step: 240, loss: 5.3126779675949365e-05
step: 250, loss: 0.0001406235824106261
step: 260, loss: 6.738245429005474e-05
step: 270, loss: 0.01019359566271305
step: 280, loss: 0.00010296110121998936
step: 290, loss: 8.582751615904272e-05
step: 300, loss: 0.0013364696642383933
step: 310, loss: 4.922660446027294e-05
step: 320, loss: 0.0016429857350885868
step: 330, loss: 7.621835538884625e-05
step: 340, loss: 0.0014980272389948368
step: 350, loss: 0.00018592200649436563
epoch 18: dev_f1=0.7774798927613941, f1=0.7331536388140161, best_f1=0.7563451776649747
step: 0, loss: 0.0035699668806046247
step: 10, loss: 0.006209895014762878
step: 20, loss: 3.953813939006068e-05
step: 30, loss: 5.791218427475542e-05
step: 40, loss: 0.00203110184520483
step: 50, loss: 5.903209967073053e-05
step: 60, loss: 4.193323911749758e-05
step: 70, loss: 0.00024259569181594998
step: 80, loss: 9.982725168811157e-05
step: 90, loss: 3.099074092460796e-05
step: 100, loss: 4.502508818404749e-05
step: 110, loss: 6.314112397376448e-05
step: 120, loss: 0.00016458275786135346
step: 130, loss: 0.00010744366591097787
step: 140, loss: 0.0007853634306229651
step: 150, loss: 0.001364804687909782
step: 160, loss: 0.001868956838734448
step: 170, loss: 0.0012600605841726065
step: 180, loss: 0.011716049164533615
step: 190, loss: 0.0015086468774825335
step: 200, loss: 0.0003195989120285958
step: 210, loss: 0.020525502040982246
step: 220, loss: 0.0001269572676392272
step: 230, loss: 0.00011517620441736653
step: 240, loss: 0.06246719881892204
step: 250, loss: 0.0007794193224981427
step: 260, loss: 0.00021799879323225468
step: 270, loss: 0.0025795544497668743
step: 280, loss: 0.0008152782684192061
step: 290, loss: 6.87147185089998e-05
step: 300, loss: 0.0003802598803304136
step: 310, loss: 0.0008001609821803868
step: 320, loss: 4.2415565985720605e-05
step: 330, loss: 4.757883652928285e-05
step: 340, loss: 0.0006709498120471835
step: 350, loss: 0.0038812877610325813
epoch 19: dev_f1=0.7645569620253165, f1=0.7360406091370559, best_f1=0.7563451776649747
step: 0, loss: 0.0003565233782865107
step: 10, loss: 5.730394696001895e-05
step: 20, loss: 2.9823704608133994e-05
step: 30, loss: 7.035405724309385e-05
step: 40, loss: 0.0003108486416749656
step: 50, loss: 0.00014980754349380732
step: 60, loss: 0.00011430316226324067
step: 70, loss: 0.00034693151246756315
step: 80, loss: 0.00010580368689261377
step: 90, loss: 0.00011041427933378145
step: 100, loss: 0.0015323355328291655
step: 110, loss: 0.0004263054288458079
step: 120, loss: 0.00022717611864209175
step: 130, loss: 0.00048418150981888175
step: 140, loss: 0.0011234204284846783
step: 150, loss: 4.940145299769938e-05
step: 160, loss: 0.00029515038477256894
step: 170, loss: 0.0426475927233696
step: 180, loss: 5.239898746367544e-05
step: 190, loss: 7.728823402430862e-05
step: 200, loss: 4.094414543942548e-05
step: 210, loss: 0.00015020888531580567
step: 220, loss: 0.000107747116999235
step: 230, loss: 4.9676382332108915e-05
step: 240, loss: 3.298623050795868e-05
step: 250, loss: 0.0020186167676001787
step: 260, loss: 0.0008944375440478325
step: 270, loss: 0.00039105385076254606
step: 280, loss: 0.000514682091306895
step: 290, loss: 0.003813206683844328
step: 300, loss: 0.05754014849662781
step: 310, loss: 0.00017875796766020358
step: 320, loss: 0.0034971670247614384
step: 330, loss: 0.0005476075457409024
step: 340, loss: 0.0002097144169965759
step: 350, loss: 0.0001896219328045845
epoch 20: dev_f1=0.772378516624041, f1=0.7282051282051282, best_f1=0.7563451776649747
