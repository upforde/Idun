cuda
Device: cuda
step: 0, loss: 0.7364063262939453
step: 10, loss: 0.4251256287097931
step: 20, loss: 0.3704201281070709
step: 30, loss: 0.3787938356399536
step: 40, loss: 0.08831192553043365
step: 50, loss: 0.23938687145709991
step: 60, loss: 0.2715480923652649
step: 70, loss: 0.22721539437770844
step: 80, loss: 0.24323345720767975
step: 90, loss: 0.5495262145996094
step: 100, loss: 0.5171228647232056
step: 110, loss: 0.3188117742538452
step: 120, loss: 0.46360132098197937
step: 130, loss: 0.13879387080669403
step: 140, loss: 0.23860473930835724
step: 150, loss: 0.547796368598938
step: 160, loss: 0.16951152682304382
step: 170, loss: 0.37813445925712585
step: 180, loss: 0.27558305859565735
step: 190, loss: 0.18162760138511658
step: 200, loss: 0.3047465980052948
step: 210, loss: 0.3056110739707947
step: 220, loss: 0.3383362293243408
step: 230, loss: 0.17977850139141083
step: 240, loss: 0.2444705367088318
step: 250, loss: 0.2182537317276001
step: 260, loss: 0.1704792082309723
step: 270, loss: 0.2976166307926178
step: 280, loss: 0.17246368527412415
step: 290, loss: 0.2589898109436035
step: 300, loss: 0.3402988314628601
step: 310, loss: 0.2121882289648056
step: 320, loss: 0.1356387585401535
step: 330, loss: 0.13696196675300598
step: 340, loss: 0.2128884345293045
step: 350, loss: 0.29129424691200256
epoch 1: dev_f1=0.7465437788018434, f1=0.6991150442477877, best_f1=0.6991150442477877
step: 0, loss: 0.06430044025182724
step: 10, loss: 0.14790257811546326
step: 20, loss: 0.4844914674758911
step: 30, loss: 0.1215655580163002
step: 40, loss: 0.15535058081150055
step: 50, loss: 0.13027094304561615
step: 60, loss: 0.07269524037837982
step: 70, loss: 0.06974315643310547
step: 80, loss: 0.10542909055948257
step: 90, loss: 0.17671282589435577
step: 100, loss: 0.1724749058485031
step: 110, loss: 0.11178648471832275
step: 120, loss: 0.08345136791467667
step: 130, loss: 0.15973247587680817
step: 140, loss: 0.161624014377594
step: 150, loss: 0.1790957897901535
step: 160, loss: 0.13616842031478882
step: 170, loss: 0.18554893136024475
step: 180, loss: 0.40712106227874756
step: 190, loss: 0.14336036145687103
step: 200, loss: 0.27714091539382935
step: 210, loss: 0.1531982272863388
step: 220, loss: 0.21114328503608704
step: 230, loss: 0.16792039573192596
step: 240, loss: 0.2129855453968048
step: 250, loss: 0.2636678218841553
step: 260, loss: 0.11112795025110245
step: 270, loss: 0.151169091463089
step: 280, loss: 0.3188079297542572
step: 290, loss: 0.13547535240650177
step: 300, loss: 0.20892977714538574
step: 310, loss: 0.10359735041856766
step: 320, loss: 0.27603617310523987
step: 330, loss: 0.0871565192937851
step: 340, loss: 0.07260655611753464
step: 350, loss: 0.2079431265592575
epoch 2: dev_f1=0.7397260273972603, f1=0.7209302325581395, best_f1=0.6991150442477877
step: 0, loss: 0.13039763271808624
step: 10, loss: 0.1331222802400589
step: 20, loss: 0.016353178769350052
step: 30, loss: 0.23710297048091888
step: 40, loss: 0.13986599445343018
step: 50, loss: 0.2798883020877838
step: 60, loss: 0.022397736087441444
step: 70, loss: 0.196477010846138
step: 80, loss: 0.04226580262184143
step: 90, loss: 0.1588938683271408
step: 100, loss: 0.006992638576775789
step: 110, loss: 0.04752187430858612
step: 120, loss: 0.1778867542743683
step: 130, loss: 0.10119036585092545
step: 140, loss: 0.042215604335069656
step: 150, loss: 0.2584628164768219
step: 160, loss: 0.10701891779899597
step: 170, loss: 0.09408979117870331
step: 180, loss: 0.13716913759708405
step: 190, loss: 0.07310789078474045
step: 200, loss: 0.05726004019379616
step: 210, loss: 0.0419357493519783
step: 220, loss: 0.13345867395401
step: 230, loss: 0.09848801046609879
step: 240, loss: 0.19888539612293243
step: 250, loss: 0.015299912542104721
step: 260, loss: 0.11161675304174423
step: 270, loss: 0.04125447943806648
step: 280, loss: 0.047152478247880936
step: 290, loss: 0.15000119805335999
step: 300, loss: 0.09836073964834213
step: 310, loss: 0.0084492526948452
step: 320, loss: 0.010698172263801098
step: 330, loss: 0.1721038818359375
step: 340, loss: 0.33186402916908264
step: 350, loss: 0.04837799817323685
epoch 3: dev_f1=0.7575757575757577, f1=0.7268817204301075, best_f1=0.7268817204301075
step: 0, loss: 0.03128654882311821
step: 10, loss: 0.011062180623412132
step: 20, loss: 0.03485678508877754
step: 30, loss: 0.03599611297249794
step: 40, loss: 0.006928457412868738
step: 50, loss: 0.042044248431921005
step: 60, loss: 0.08962845057249069
step: 70, loss: 0.2148773968219757
step: 80, loss: 0.07267116755247116
step: 90, loss: 0.0505928136408329
step: 100, loss: 0.024617187678813934
step: 110, loss: 0.05894821137189865
step: 120, loss: 0.04562809690833092
step: 130, loss: 0.03793489933013916
step: 140, loss: 0.2347315400838852
step: 150, loss: 0.028586886823177338
step: 160, loss: 0.0882524773478508
step: 170, loss: 0.002179232891649008
step: 180, loss: 0.0184935312718153
step: 190, loss: 0.13304990530014038
step: 200, loss: 0.09734198451042175
step: 210, loss: 0.030478181317448616
step: 220, loss: 0.031338199973106384
step: 230, loss: 0.05183175578713417
step: 240, loss: 0.06995147466659546
step: 250, loss: 0.02109345979988575
step: 260, loss: 0.09377659857273102
step: 270, loss: 0.05783084034919739
step: 280, loss: 0.019848249852657318
step: 290, loss: 0.03517249971628189
step: 300, loss: 0.009423361159861088
step: 310, loss: 0.10037733614444733
step: 320, loss: 0.047249939292669296
step: 330, loss: 0.11359623819589615
step: 340, loss: 0.021484384313225746
step: 350, loss: 0.09375932067632675
epoch 4: dev_f1=0.7806122448979592, f1=0.7445255474452555, best_f1=0.7445255474452555
step: 0, loss: 0.07103068381547928
step: 10, loss: 0.01947161927819252
step: 20, loss: 0.031237123534083366
step: 30, loss: 0.06821281462907791
step: 40, loss: 0.017165161669254303
step: 50, loss: 0.14414282143115997
step: 60, loss: 0.009530008770525455
step: 70, loss: 0.0721590593457222
step: 80, loss: 0.03855886310338974
step: 90, loss: 0.03187723457813263
step: 100, loss: 0.14864668250083923
step: 110, loss: 0.004158840049058199
step: 120, loss: 0.004274008795619011
step: 130, loss: 0.03864292427897453
step: 140, loss: 0.12539300322532654
step: 150, loss: 0.04935355857014656
step: 160, loss: 0.01461272407323122
step: 170, loss: 0.021434234455227852
step: 180, loss: 0.04946781322360039
step: 190, loss: 0.18674597144126892
step: 200, loss: 0.01155065931379795
step: 210, loss: 0.03850552439689636
step: 220, loss: 0.0509280189871788
step: 230, loss: 0.09369569271802902
step: 240, loss: 0.014155951328575611
step: 250, loss: 0.013874249532818794
step: 260, loss: 0.0873565599322319
step: 270, loss: 0.010301066562533379
step: 280, loss: 0.06087774410843849
step: 290, loss: 0.014768830500543118
step: 300, loss: 0.09516443312168121
step: 310, loss: 0.0602584183216095
step: 320, loss: 0.020521296188235283
step: 330, loss: 0.008420380763709545
step: 340, loss: 0.03616778180003166
step: 350, loss: 0.006964645814150572
epoch 5: dev_f1=0.7990196078431373, f1=0.7499999999999999, best_f1=0.7499999999999999
step: 0, loss: 0.16868817806243896
step: 10, loss: 0.05298802629113197
step: 20, loss: 0.024968530982732773
step: 30, loss: 0.026627067476511
step: 40, loss: 0.007439311593770981
step: 50, loss: 0.007556383032351732
step: 60, loss: 0.00429148692637682
step: 70, loss: 0.006426508538424969
step: 80, loss: 0.007227786350995302
step: 90, loss: 0.013910844922065735
step: 100, loss: 0.018638206645846367
step: 110, loss: 0.015412586741149426
step: 120, loss: 0.10333050042390823
step: 130, loss: 0.010326424613595009
step: 140, loss: 0.03291991353034973
step: 150, loss: 0.10961075872182846
step: 160, loss: 0.007764303125441074
step: 170, loss: 0.08099910616874695
step: 180, loss: 0.0017592062940821052
step: 190, loss: 0.020450836047530174
step: 200, loss: 0.0005895938957110047
step: 210, loss: 0.01362875197082758
step: 220, loss: 0.02038080431520939
step: 230, loss: 0.00884780753403902
step: 240, loss: 0.040257375687360764
step: 250, loss: 0.0021974556148052216
step: 260, loss: 0.01974451169371605
step: 270, loss: 0.0052322749979794025
step: 280, loss: 0.005549137946218252
step: 290, loss: 0.006857094820588827
step: 300, loss: 0.2766232192516327
step: 310, loss: 0.04871572181582451
step: 320, loss: 0.061357125639915466
step: 330, loss: 0.0018894030945375562
step: 340, loss: 0.021965278312563896
step: 350, loss: 0.019140833988785744
epoch 6: dev_f1=0.7806122448979592, f1=0.712871287128713, best_f1=0.7499999999999999
step: 0, loss: 0.02035989612340927
step: 10, loss: 0.006556288339197636
step: 20, loss: 0.005845869891345501
step: 30, loss: 0.01729213260114193
step: 40, loss: 0.05759624391794205
step: 50, loss: 0.007516740821301937
step: 60, loss: 0.0033767581917345524
step: 70, loss: 0.01058642752468586
step: 80, loss: 0.2166724056005478
step: 90, loss: 0.028979936614632607
step: 100, loss: 0.00524501595646143
step: 110, loss: 0.008759596385061741
step: 120, loss: 0.0031567395199090242
step: 130, loss: 0.03388088196516037
step: 140, loss: 0.07854359596967697
step: 150, loss: 0.01803223229944706
step: 160, loss: 0.0014454112388193607
step: 170, loss: 0.10666090250015259
step: 180, loss: 0.12252674996852875
step: 190, loss: 0.026250658556818962
step: 200, loss: 0.013248632661998272
step: 210, loss: 0.038485683500766754
step: 220, loss: 0.006493924651294947
step: 230, loss: 0.05989476665854454
step: 240, loss: 0.0025617117062211037
step: 250, loss: 0.007442352827638388
step: 260, loss: 0.0007231581839732826
step: 270, loss: 0.0013191010802984238
step: 280, loss: 0.06293927878141403
step: 290, loss: 0.08808375895023346
step: 300, loss: 0.0374981053173542
step: 310, loss: 0.07370419055223465
step: 320, loss: 0.003818851662799716
step: 330, loss: 0.0008522114367224276
step: 340, loss: 0.02130971848964691
step: 350, loss: 0.043868087232112885
epoch 7: dev_f1=0.794188861985472, f1=0.7272727272727274, best_f1=0.7499999999999999
step: 0, loss: 0.007608610671013594
step: 10, loss: 0.012799745425581932
step: 20, loss: 0.00019772638916037977
step: 30, loss: 0.011852209456264973
step: 40, loss: 0.0019163298420608044
step: 50, loss: 0.0034613260067999363
step: 60, loss: 0.01525923702865839
step: 70, loss: 0.014727004803717136
step: 80, loss: 0.001399424159899354
step: 90, loss: 0.001638574292883277
step: 100, loss: 0.039546918123960495
step: 110, loss: 0.017208091914653778
step: 120, loss: 0.008207774721086025
step: 130, loss: 0.003261571517214179
step: 140, loss: 0.0011623282916843891
step: 150, loss: 0.007103133946657181
step: 160, loss: 0.00030873253126628697
step: 170, loss: 0.0468059778213501
step: 180, loss: 0.008529732003808022
step: 190, loss: 0.026903480291366577
step: 200, loss: 0.03939194232225418
step: 210, loss: 0.0025131150614470243
step: 220, loss: 0.0017464854754507542
step: 230, loss: 0.02719339355826378
step: 240, loss: 0.0016478599281981587
step: 250, loss: 0.0019901806954294443
step: 260, loss: 0.018052469938993454
step: 270, loss: 0.0009413602529093623
step: 280, loss: 0.027086922898888588
step: 290, loss: 0.008885292336344719
step: 300, loss: 0.0003642356605269015
step: 310, loss: 0.14666809141635895
step: 320, loss: 0.06660237163305283
step: 330, loss: 0.017111653462052345
step: 340, loss: 0.008130496367812157
step: 350, loss: 0.00036399310920387506
epoch 8: dev_f1=0.7836538461538461, f1=0.7178329571106095, best_f1=0.7499999999999999
step: 0, loss: 0.00850674882531166
step: 10, loss: 0.003022382967174053
step: 20, loss: 0.0033859650138765574
step: 30, loss: 0.004685554187744856
step: 40, loss: 0.04011797159910202
step: 50, loss: 0.00781846884638071
step: 60, loss: 0.010256041772663593
step: 70, loss: 0.000344728643540293
step: 80, loss: 0.0006100073806010187
step: 90, loss: 0.0005211585084907711
step: 100, loss: 0.0011852222960442305
step: 110, loss: 0.002317444421350956
step: 120, loss: 0.0021023317240178585
step: 130, loss: 0.0013025320367887616
step: 140, loss: 0.0011501818662509322
step: 150, loss: 0.07453586161136627
step: 160, loss: 0.0029730615206062794
step: 170, loss: 0.01707233116030693
step: 180, loss: 0.03179793059825897
step: 190, loss: 0.003221799386665225
step: 200, loss: 0.0009319306118413806
step: 210, loss: 0.0022464795038104057
step: 220, loss: 0.004165601916611195
step: 230, loss: 0.004070191644132137
step: 240, loss: 0.0035435606259852648
step: 250, loss: 0.007464399561285973
step: 260, loss: 0.007396375760436058
step: 270, loss: 0.0014503891579806805
step: 280, loss: 0.007034782320261002
step: 290, loss: 0.0410606749355793
step: 300, loss: 0.012779835611581802
step: 310, loss: 0.013758327811956406
step: 320, loss: 0.002914144191890955
step: 330, loss: 0.00016004846838768572
step: 340, loss: 0.0005287601379677653
step: 350, loss: 0.0015036530094221234
epoch 9: dev_f1=0.7526881720430108, f1=0.7244094488188977, best_f1=0.7499999999999999
step: 0, loss: 0.0006728937150910497
step: 10, loss: 0.0013691462809219956
step: 20, loss: 0.000933401461225003
step: 30, loss: 0.0026745698414742947
step: 40, loss: 0.08797892928123474
step: 50, loss: 0.015830514952540398
step: 60, loss: 0.005041289608925581
step: 70, loss: 0.0006088176160119474
step: 80, loss: 0.0003130302648060024
step: 90, loss: 0.0012253003660589457
step: 100, loss: 0.0008190866792574525
step: 110, loss: 0.0015287116402760148
step: 120, loss: 0.0015868243062868714
step: 130, loss: 0.010758865624666214
step: 140, loss: 0.00084952253382653
step: 150, loss: 0.0005419054650701582
step: 160, loss: 0.005644876975566149
step: 170, loss: 0.0007134901825338602
step: 180, loss: 0.14380978047847748
step: 190, loss: 0.0011347181862220168
step: 200, loss: 0.0060247378423810005
step: 210, loss: 0.01910342089831829
step: 220, loss: 0.0002680840261746198
step: 230, loss: 0.006508743390440941
step: 240, loss: 0.003461315995082259
step: 250, loss: 0.044382479041814804
step: 260, loss: 0.013670330867171288
step: 270, loss: 0.005815352313220501
step: 280, loss: 0.009876852855086327
step: 290, loss: 0.017109813168644905
step: 300, loss: 0.00023120715923141688
step: 310, loss: 0.0012014905223622918
step: 320, loss: 0.00013584115367848426
step: 330, loss: 0.0007588184671476483
step: 340, loss: 0.0005999025306664407
step: 350, loss: 0.018084652721881866
epoch 10: dev_f1=0.778894472361809, f1=0.7215496368038741, best_f1=0.7499999999999999
step: 0, loss: 5.869939559488557e-05
step: 10, loss: 0.001518816570751369
step: 20, loss: 0.00013452883285935968
step: 30, loss: 0.002335452940315008
step: 40, loss: 0.0016145160188898444
step: 50, loss: 0.0001511355076218024
step: 60, loss: 0.004847710952162743
step: 70, loss: 0.03169015794992447
step: 80, loss: 0.0002557339903432876
step: 90, loss: 0.11485405266284943
step: 100, loss: 0.0011987260077148676
step: 110, loss: 0.009726065210998058
step: 120, loss: 0.00038883244269527495
step: 130, loss: 0.0011571041541174054
step: 140, loss: 0.001745041343383491
step: 150, loss: 0.002545160474255681
step: 160, loss: 0.001697990228421986
step: 170, loss: 0.008581955917179585
step: 180, loss: 0.0005583155434578657
step: 190, loss: 0.010511358268558979
step: 200, loss: 0.00018484483007341623
step: 210, loss: 0.0009306688443757594
step: 220, loss: 0.0013874988071620464
step: 230, loss: 0.00020777636382263154
step: 240, loss: 0.007830556482076645
step: 250, loss: 0.00029879447538405657
step: 260, loss: 0.023533567786216736
step: 270, loss: 0.1952839195728302
step: 280, loss: 0.18545272946357727
step: 290, loss: 0.0012878973502665758
step: 300, loss: 0.0033905080053955317
step: 310, loss: 0.0018387304153293371
step: 320, loss: 0.0038837604224681854
step: 330, loss: 8.815313049126416e-05
step: 340, loss: 0.00012575196160469204
step: 350, loss: 0.010602738708257675
epoch 11: dev_f1=0.7875894988066825, f1=0.7388235294117647, best_f1=0.7499999999999999
step: 0, loss: 5.885448990738951e-05
step: 10, loss: 0.004094323609024286
step: 20, loss: 8.446881838608533e-05
step: 30, loss: 0.004103275015950203
step: 40, loss: 0.015326947905123234
step: 50, loss: 0.02343720570206642
step: 60, loss: 0.05962814390659332
step: 70, loss: 0.001634508022107184
step: 80, loss: 0.0005399352521635592
step: 90, loss: 0.0022753386292606592
step: 100, loss: 0.0003045750199817121
step: 110, loss: 0.00043543591164052486
step: 120, loss: 0.0015550922835245728
step: 130, loss: 0.00014381440996658057
step: 140, loss: 0.007958871312439442
step: 150, loss: 0.00038002413930371404
step: 160, loss: 0.0003314402129035443
step: 170, loss: 0.00010467060201335698
step: 180, loss: 0.0028265644796192646
step: 190, loss: 0.030477365478873253
step: 200, loss: 0.15653525292873383
step: 210, loss: 5.5697943025734276e-05
step: 220, loss: 0.0008013140759430826
step: 230, loss: 0.00569155253469944
step: 240, loss: 0.011678425595164299
step: 250, loss: 0.0010011312551796436
step: 260, loss: 0.004378336947411299
step: 270, loss: 0.0017290929099544883
step: 280, loss: 0.012006021104753017
step: 290, loss: 0.00038267209311015904
step: 300, loss: 0.0004787590296473354
step: 310, loss: 0.0046601672656834126
step: 320, loss: 0.022960210219025612
step: 330, loss: 0.012918349355459213
step: 340, loss: 0.004369609989225864
step: 350, loss: 0.010026133619248867
epoch 12: dev_f1=0.7676240208877285, f1=0.7474747474747476, best_f1=0.7499999999999999
step: 0, loss: 6.720038072671741e-05
step: 10, loss: 0.002839446533471346
step: 20, loss: 0.0027788919396698475
step: 30, loss: 0.00022165307018440217
step: 40, loss: 0.038710206747055054
step: 50, loss: 0.0009215991012752056
step: 60, loss: 0.001020869822241366
step: 70, loss: 0.004218324087560177
step: 80, loss: 4.4074524339521304e-05
step: 90, loss: 0.043617647141218185
step: 100, loss: 0.00037297094240784645
step: 110, loss: 0.04855537414550781
step: 120, loss: 6.720882811350748e-05
step: 130, loss: 0.00020110691548325121
step: 140, loss: 0.005153816659003496
step: 150, loss: 0.00014873305917717516
step: 160, loss: 0.002215932123363018
step: 170, loss: 0.00914058368653059
step: 180, loss: 0.00013261068670544773
step: 190, loss: 0.00017818239575717598
step: 200, loss: 0.001537027768790722
step: 210, loss: 0.0005851502064615488
step: 220, loss: 0.011793927289545536
step: 230, loss: 0.00035017705522477627
step: 240, loss: 0.00013300521823111922
step: 250, loss: 6.515671702800319e-05
step: 260, loss: 0.0011955432128161192
step: 270, loss: 0.00014760847261641175
step: 280, loss: 0.00011354620801284909
step: 290, loss: 0.007289610803127289
step: 300, loss: 0.0017286724178120494
step: 310, loss: 0.0005976792308501899
step: 320, loss: 0.00014180965081322938
step: 330, loss: 0.008711371570825577
step: 340, loss: 0.0010094154858961701
step: 350, loss: 0.0028944446239620447
epoch 13: dev_f1=0.7651715039577837, f1=0.7208121827411168, best_f1=0.7499999999999999
step: 0, loss: 0.0006388491601683199
step: 10, loss: 0.0007786022615619004
step: 20, loss: 0.009029091335833073
step: 30, loss: 0.00012579321628436446
step: 40, loss: 0.0028931377455592155
step: 50, loss: 0.00047822584747336805
step: 60, loss: 0.0002741863136179745
step: 70, loss: 0.00030543594039045274
step: 80, loss: 0.00017480853421147913
step: 90, loss: 7.046011160127819e-05
step: 100, loss: 0.00013723391748499125
step: 110, loss: 0.0023471631575375795
step: 120, loss: 0.007623946759849787
step: 130, loss: 0.0005850016605108976
step: 140, loss: 0.0018083244794979692
step: 150, loss: 0.0025317836552858353
step: 160, loss: 0.0009635089663788676
step: 170, loss: 0.0004189673054497689
step: 180, loss: 0.01569075509905815
step: 190, loss: 0.0012745419517159462
step: 200, loss: 0.006497702561318874
step: 210, loss: 0.00010687852773116902
step: 220, loss: 0.07011003792285919
step: 230, loss: 0.012120828032493591
step: 240, loss: 0.001582189230248332
step: 250, loss: 0.013734925538301468
step: 260, loss: 0.09237266331911087
step: 270, loss: 0.00039142591413110495
step: 280, loss: 0.007297845557332039
step: 290, loss: 0.0009860319551080465
step: 300, loss: 0.0002276068989885971
step: 310, loss: 0.00033332910970784724
step: 320, loss: 2.415792187093757e-05
step: 330, loss: 6.329719326458871e-05
step: 340, loss: 0.000463884964119643
step: 350, loss: 0.00026704586343839765
epoch 14: dev_f1=0.7951219512195121, f1=0.748235294117647, best_f1=0.7499999999999999
step: 0, loss: 0.00022254633950069547
step: 10, loss: 0.0035954508930444717
step: 20, loss: 0.022174200043082237
step: 30, loss: 0.01754472218453884
step: 40, loss: 0.00033967956551350653
step: 50, loss: 5.6797998695401475e-05
step: 60, loss: 0.0001123357578762807
step: 70, loss: 0.00028418819420039654
step: 80, loss: 8.700591570232064e-05
step: 90, loss: 8.239637827500701e-05
step: 100, loss: 0.014871695078909397
step: 110, loss: 0.000160032301209867
step: 120, loss: 0.007172140758484602
step: 130, loss: 0.009735213592648506
step: 140, loss: 0.03685880824923515
step: 150, loss: 0.00050737289711833
step: 160, loss: 0.0014534540241584182
step: 170, loss: 0.00013461978232953697
step: 180, loss: 0.0002521244459785521
step: 190, loss: 0.002140569966286421
step: 200, loss: 0.006382171530276537
step: 210, loss: 7.157960499171168e-05
step: 220, loss: 0.00046750984620302916
step: 230, loss: 6.780540570616722e-05
step: 240, loss: 0.0002613637479953468
step: 250, loss: 0.0003627097757998854
step: 260, loss: 0.024672243744134903
step: 270, loss: 0.0002154382673325017
step: 280, loss: 0.00037400462315417826
step: 290, loss: 0.002617573132738471
step: 300, loss: 0.00012850569328293204
step: 310, loss: 0.006681334227323532
step: 320, loss: 0.00012309016892686486
step: 330, loss: 5.847121065016836e-05
step: 340, loss: 0.002660186728462577
step: 350, loss: 0.013799441047012806
epoch 15: dev_f1=0.7708333333333335, f1=0.7549999999999999, best_f1=0.7499999999999999
step: 0, loss: 0.00016345453332178295
step: 10, loss: 0.0001621950214030221
step: 20, loss: 5.630763916997239e-05
step: 30, loss: 0.005185880232602358
step: 40, loss: 0.00015698680363129824
step: 50, loss: 0.0005194403347559273
step: 60, loss: 0.0019835010170936584
step: 70, loss: 0.016910145059227943
step: 80, loss: 0.008964319713413715
step: 90, loss: 0.00010069082782138139
step: 100, loss: 0.00015494012041017413
step: 110, loss: 0.1280229240655899
step: 120, loss: 8.18718399386853e-05
step: 130, loss: 5.2130748372292146e-05
step: 140, loss: 0.0002591667289379984
step: 150, loss: 0.09241204708814621
step: 160, loss: 6.603103247471154e-05
step: 170, loss: 6.190731801325455e-05
step: 180, loss: 0.0016925220843404531
step: 190, loss: 7.95427622506395e-05
step: 200, loss: 0.0009770819451659918
step: 210, loss: 2.678396958799567e-05
step: 220, loss: 9.272257739212364e-05
step: 230, loss: 8.798421185929328e-05
step: 240, loss: 8.193239773390815e-05
step: 250, loss: 0.12431498616933823
step: 260, loss: 0.00010504016245249659
step: 270, loss: 0.00013254435907583684
step: 280, loss: 0.0010407372610643506
step: 290, loss: 7.841240585548803e-05
step: 300, loss: 3.5257835406810045e-05
step: 310, loss: 3.587106039049104e-05
step: 320, loss: 0.026000328361988068
step: 330, loss: 0.006173660513013601
step: 340, loss: 5.3786654461873695e-05
step: 350, loss: 0.0008269806276075542
epoch 16: dev_f1=0.7774936061381074, f1=0.7438423645320198, best_f1=0.7499999999999999
step: 0, loss: 0.022305138409137726
step: 10, loss: 7.192903285613284e-05
step: 20, loss: 0.00016852642875164747
step: 30, loss: 0.013797408901154995
step: 40, loss: 0.00039207516238093376
step: 50, loss: 0.00015963969053700566
step: 60, loss: 0.00044310797238722444
step: 70, loss: 0.000784548232331872
step: 80, loss: 0.05913642793893814
step: 90, loss: 0.001338292728178203
step: 100, loss: 0.001232190988957882
step: 110, loss: 0.010938208550214767
step: 120, loss: 0.10541874915361404
step: 130, loss: 0.000717552553396672
step: 140, loss: 0.00677633797749877
step: 150, loss: 0.0005999739514663815
step: 160, loss: 0.00021136808209121227
step: 170, loss: 3.845054379780777e-05
step: 180, loss: 0.0006907165516167879
step: 190, loss: 0.0005063136341050267
step: 200, loss: 0.06780774146318436
step: 210, loss: 0.00027048340416513383
step: 220, loss: 0.00010030933481175452
step: 230, loss: 0.010462175123393536
step: 240, loss: 0.01721254363656044
step: 250, loss: 7.105566328391433e-05
step: 260, loss: 0.00011690100654959679
step: 270, loss: 0.00014385342365130782
step: 280, loss: 0.0008072403143160045
step: 290, loss: 0.0019384317565709352
step: 300, loss: 0.011041753925383091
step: 310, loss: 0.00015979520685505122
step: 320, loss: 0.0007134402985684574
step: 330, loss: 0.00011760528286686167
step: 340, loss: 0.01911013200879097
step: 350, loss: 0.034620579332113266
epoch 17: dev_f1=0.7493112947658404, f1=0.7374005305039788, best_f1=0.7499999999999999
step: 0, loss: 0.0001348658261122182
step: 10, loss: 4.070073555340059e-05
step: 20, loss: 0.00045997698907740414
step: 30, loss: 0.005061815958470106
step: 40, loss: 0.006676236167550087
step: 50, loss: 0.0054539949633181095
step: 60, loss: 0.00012232409790158272
step: 70, loss: 4.445802915142849e-05
step: 80, loss: 5.168663483345881e-05
step: 90, loss: 0.025362621992826462
step: 100, loss: 4.303482637624256e-05
step: 110, loss: 0.0018609719118103385
step: 120, loss: 0.000308341346681118
step: 130, loss: 6.452195520978421e-05
step: 140, loss: 0.00018290706793777645
step: 150, loss: 0.0011428467696532607
step: 160, loss: 0.0001099373257602565
step: 170, loss: 0.00028875094722025096
step: 180, loss: 0.0020832945592701435
step: 190, loss: 4.18237796111498e-05
step: 200, loss: 2.8758875487255864e-05
step: 210, loss: 0.0002562806766945869
step: 220, loss: 0.0001681991998339072
step: 230, loss: 0.10714162886142731
step: 240, loss: 0.000420267169829458
step: 250, loss: 6.030005533830263e-05
step: 260, loss: 9.169642726192251e-05
step: 270, loss: 5.380502625484951e-05
step: 280, loss: 0.031261853873729706
step: 290, loss: 0.00018899879069067538
step: 300, loss: 0.002240778412669897
step: 310, loss: 0.00014348721015267074
step: 320, loss: 0.00013064485392533243
step: 330, loss: 6.297192885540426e-05
step: 340, loss: 5.145499380887486e-05
step: 350, loss: 0.0006352185737341642
epoch 18: dev_f1=0.7801047120418847, f1=0.7575757575757577, best_f1=0.7499999999999999
step: 0, loss: 0.0004657777608372271
step: 10, loss: 0.00017164472956210375
step: 20, loss: 0.0042228312231600285
step: 30, loss: 0.0004729017673525959
step: 40, loss: 0.00037943938514217734
step: 50, loss: 0.0007117060595192015
step: 60, loss: 0.0006482290918938816
step: 70, loss: 0.0012020603753626347
step: 80, loss: 9.279676305595785e-05
step: 90, loss: 0.00012663083907682449
step: 100, loss: 8.804886601865292e-05
step: 110, loss: 0.0003700092784129083
step: 120, loss: 7.683216972509399e-05
step: 130, loss: 0.00013255381782073528
step: 140, loss: 5.4572457884205505e-05
step: 150, loss: 0.03917764872312546
step: 160, loss: 0.00921418983489275
step: 170, loss: 0.00015039395657368004
step: 180, loss: 0.0004591830656863749
step: 190, loss: 9.58276359597221e-05
step: 200, loss: 6.424209277611226e-05
step: 210, loss: 0.001541011850349605
step: 220, loss: 0.00011532113421708345
step: 230, loss: 0.0002582544693723321
step: 240, loss: 0.0008662319742143154
step: 250, loss: 0.008324050344526768
step: 260, loss: 2.6746000003186055e-05
step: 270, loss: 8.146885375026613e-05
step: 280, loss: 9.246139961760491e-05
step: 290, loss: 0.0016319382702931762
step: 300, loss: 6.145174847915769e-05
step: 310, loss: 2.790437611110974e-05
step: 320, loss: 0.005002741701900959
step: 330, loss: 7.929921412141994e-05
step: 340, loss: 0.0033802029211074114
step: 350, loss: 0.08632569015026093
epoch 19: dev_f1=0.7830687830687831, f1=0.7487179487179487, best_f1=0.7499999999999999
step: 0, loss: 7.249324698932469e-05
step: 10, loss: 0.0011649716179817915
step: 20, loss: 0.0036202475894242525
step: 30, loss: 0.00019476066518109292
step: 40, loss: 0.0191023126244545
step: 50, loss: 0.00021719861251767725
step: 60, loss: 0.0005314791342243552
step: 70, loss: 0.0017915434436872602
step: 80, loss: 0.00013966945698484778
step: 90, loss: 0.00012601485650520772
step: 100, loss: 0.04171879217028618
step: 110, loss: 0.005771359894424677
step: 120, loss: 0.000189436279470101
step: 130, loss: 6.041162123437971e-05
step: 140, loss: 0.0007151125464588404
step: 150, loss: 6.849351484561339e-05
step: 160, loss: 0.002092495560646057
step: 170, loss: 0.00013854725693818182
step: 180, loss: 0.0010925097158178687
step: 190, loss: 0.00048147491179406643
step: 200, loss: 2.209796912211459e-05
step: 210, loss: 8.33776211948134e-05
step: 220, loss: 0.00019235553918406367
step: 230, loss: 0.002653764095157385
step: 240, loss: 4.7121127863647416e-05
step: 250, loss: 0.000447894970420748
step: 260, loss: 4.868935138802044e-05
step: 270, loss: 0.0006925606867298484
step: 280, loss: 3.880027725244872e-05
step: 290, loss: 7.005076622590423e-05
step: 300, loss: 0.0005476425867527723
step: 310, loss: 0.001418430358171463
step: 320, loss: 0.0003900066076312214
step: 330, loss: 0.0005736324237659574
step: 340, loss: 0.0005530209164135158
step: 350, loss: 0.017363104969263077
epoch 20: dev_f1=0.7801047120418847, f1=0.7575757575757577, best_f1=0.7499999999999999
