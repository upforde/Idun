cuda
Device: cuda
step: 0, loss: 0.7605901956558228
step: 10, loss: 0.4098445177078247
step: 20, loss: 0.23806394636631012
step: 30, loss: 0.31416311860084534
step: 40, loss: 0.37742099165916443
step: 50, loss: 0.1697961688041687
step: 60, loss: 0.1691262423992157
step: 70, loss: 0.4527810215950012
step: 80, loss: 0.49453192949295044
step: 90, loss: 0.3858186602592468
step: 100, loss: 0.35087624192237854
step: 110, loss: 0.34999123215675354
step: 120, loss: 0.5382483005523682
step: 130, loss: 0.3091457486152649
step: 140, loss: 0.2938367426395416
step: 150, loss: 0.47197088599205017
step: 160, loss: 0.5890539884567261
step: 170, loss: 0.30724069476127625
step: 180, loss: 0.4996448755264282
step: 190, loss: 0.20688390731811523
step: 200, loss: 0.09464285522699356
step: 210, loss: 0.24333402514457703
step: 220, loss: 0.15361352264881134
step: 230, loss: 0.16530874371528625
step: 240, loss: 0.33357489109039307
step: 250, loss: 0.4741676449775696
step: 260, loss: 0.21670891344547272
step: 270, loss: 0.24489808082580566
step: 280, loss: 0.21245668828487396
step: 290, loss: 0.13700875639915466
step: 300, loss: 0.27806463837623596
step: 310, loss: 0.2264803647994995
step: 320, loss: 0.234188973903656
step: 330, loss: 0.18872369825839996
step: 340, loss: 0.2162376344203949
step: 350, loss: 0.13334402441978455
epoch 1: dev_f1=0.7104622871046229, f1=0.6325581395348837, best_f1=0.6325581395348837
step: 0, loss: 0.14882895350456238
step: 10, loss: 0.37205660343170166
step: 20, loss: 0.1888468712568283
step: 30, loss: 0.07069789618253708
step: 40, loss: 0.20810630917549133
step: 50, loss: 0.13577157258987427
step: 60, loss: 0.29980552196502686
step: 70, loss: 0.09367511421442032
step: 80, loss: 0.20708350837230682
step: 90, loss: 0.13252335786819458
step: 100, loss: 0.26814186573028564
step: 110, loss: 0.06156332418322563
step: 120, loss: 0.2287370264530182
step: 130, loss: 0.21871858835220337
step: 140, loss: 0.249578058719635
step: 150, loss: 0.14637629687786102
step: 160, loss: 0.14768198132514954
step: 170, loss: 0.19523856043815613
step: 180, loss: 0.18467405438423157
step: 190, loss: 0.11146626621484756
step: 200, loss: 0.11578065901994705
step: 210, loss: 0.17559775710105896
step: 220, loss: 0.11902135610580444
step: 230, loss: 0.2306491732597351
step: 240, loss: 0.12905484437942505
step: 250, loss: 0.09544119238853455
step: 260, loss: 0.18134427070617676
step: 270, loss: 0.1521366536617279
step: 280, loss: 0.2522977888584137
step: 290, loss: 0.14902999997138977
step: 300, loss: 0.12157299369573593
step: 310, loss: 0.2165972739458084
step: 320, loss: 0.11314741522073746
step: 330, loss: 0.14861826598644257
step: 340, loss: 0.048861805349588394
step: 350, loss: 0.15318679809570312
epoch 2: dev_f1=0.7426160337552743, f1=0.6762295081967212, best_f1=0.6762295081967212
step: 0, loss: 0.054819293320178986
step: 10, loss: 0.05107280611991882
step: 20, loss: 0.07966654747724533
step: 30, loss: 0.0733356773853302
step: 40, loss: 0.06165880337357521
step: 50, loss: 0.015644971281290054
step: 60, loss: 0.1740177720785141
step: 70, loss: 0.03689082711935043
step: 80, loss: 0.06050264835357666
step: 90, loss: 0.07715212553739548
step: 100, loss: 0.16569775342941284
step: 110, loss: 0.10055164992809296
step: 120, loss: 0.12481198459863663
step: 130, loss: 0.11575090140104294
step: 140, loss: 0.10734148323535919
step: 150, loss: 0.04141740873456001
step: 160, loss: 0.05055991932749748
step: 170, loss: 0.25880494713783264
step: 180, loss: 0.20466230809688568
step: 190, loss: 0.09986171126365662
step: 200, loss: 0.1495896875858307
step: 210, loss: 0.15016061067581177
step: 220, loss: 0.12295504659414291
step: 230, loss: 0.1553712785243988
step: 240, loss: 0.011724251322448254
step: 250, loss: 0.1768520027399063
step: 260, loss: 0.17993725836277008
step: 270, loss: 0.052592575550079346
step: 280, loss: 0.13528284430503845
step: 290, loss: 0.09146426618099213
step: 300, loss: 0.21654771268367767
step: 310, loss: 0.056516293436288834
step: 320, loss: 0.04869306832551956
step: 330, loss: 0.08086329698562622
step: 340, loss: 0.18678978085517883
step: 350, loss: 0.10432153940200806
epoch 3: dev_f1=0.7654867256637168, f1=0.7074235807860262, best_f1=0.7074235807860262
step: 0, loss: 0.06339991092681885
step: 10, loss: 0.01956268586218357
step: 20, loss: 0.01599041186273098
step: 30, loss: 0.0395580492913723
step: 40, loss: 0.034070130437612534
step: 50, loss: 0.03440829738974571
step: 60, loss: 0.023991743102669716
step: 70, loss: 0.0430101715028286
step: 80, loss: 0.07094115763902664
step: 90, loss: 0.0075447759591042995
step: 100, loss: 0.15744392573833466
step: 110, loss: 0.0034392739180475473
step: 120, loss: 0.007418820168823004
step: 130, loss: 0.15370571613311768
step: 140, loss: 0.004625878296792507
step: 150, loss: 0.18391723930835724
step: 160, loss: 0.01880742236971855
step: 170, loss: 0.1081705242395401
step: 180, loss: 0.023603295907378197
step: 190, loss: 0.06273698806762695
step: 200, loss: 0.01588214747607708
step: 210, loss: 0.026195252314209938
step: 220, loss: 0.033348869532346725
step: 230, loss: 0.13074737787246704
step: 240, loss: 0.016243331134319305
step: 250, loss: 0.16662777960300446
step: 260, loss: 0.11912207305431366
step: 270, loss: 0.056143589317798615
step: 280, loss: 0.054684944450855255
step: 290, loss: 0.029827628284692764
step: 300, loss: 0.02957509271800518
step: 310, loss: 0.058354105800390244
step: 320, loss: 0.27152806520462036
step: 330, loss: 0.06854216009378433
step: 340, loss: 0.11809631437063217
step: 350, loss: 0.1013886108994484
epoch 4: dev_f1=0.7628361858190709, f1=0.729064039408867, best_f1=0.7074235807860262
step: 0, loss: 0.016722723841667175
step: 10, loss: 0.26685431599617004
step: 20, loss: 0.009957791306078434
step: 30, loss: 0.07936002314090729
step: 40, loss: 0.009270770475268364
step: 50, loss: 0.03551069647073746
step: 60, loss: 0.052604783326387405
step: 70, loss: 0.06191322207450867
step: 80, loss: 0.061280302703380585
step: 90, loss: 0.011073751375079155
step: 100, loss: 0.0944678783416748
step: 110, loss: 0.005262237973511219
step: 120, loss: 0.09169098734855652
step: 130, loss: 0.05365531146526337
step: 140, loss: 0.01944063790142536
step: 150, loss: 0.02742418833076954
step: 160, loss: 0.032638587057590485
step: 170, loss: 0.06664644926786423
step: 180, loss: 0.011476422660052776
step: 190, loss: 0.019047800451517105
step: 200, loss: 0.03759857267141342
step: 210, loss: 0.029257850721478462
step: 220, loss: 0.07446010410785675
step: 230, loss: 0.17818443477153778
step: 240, loss: 0.02116653136909008
step: 250, loss: 0.012324461713433266
step: 260, loss: 0.054430849850177765
step: 270, loss: 0.08058688044548035
step: 280, loss: 0.014008579775691032
step: 290, loss: 0.006508904509246349
step: 300, loss: 0.0319657064974308
step: 310, loss: 0.006061032880097628
step: 320, loss: 0.14589901268482208
step: 330, loss: 0.057946715503931046
step: 340, loss: 0.14761972427368164
step: 350, loss: 0.08317190408706665
epoch 5: dev_f1=0.7953488372093023, f1=0.7610208816705337, best_f1=0.7610208816705337
step: 0, loss: 0.007248840294778347
step: 10, loss: 0.027987491339445114
step: 20, loss: 0.008319982327520847
step: 30, loss: 0.0044427369721233845
step: 40, loss: 0.0016022355994209647
step: 50, loss: 0.03156318515539169
step: 60, loss: 0.20700514316558838
step: 70, loss: 0.010160716250538826
step: 80, loss: 0.1135295033454895
step: 90, loss: 0.07263301312923431
step: 100, loss: 0.012350361794233322
step: 110, loss: 0.08376733213663101
step: 120, loss: 0.12050599604845047
step: 130, loss: 0.006533099338412285
step: 140, loss: 0.03820950165390968
step: 150, loss: 0.012466982938349247
step: 160, loss: 0.010905501432716846
step: 170, loss: 0.000677409814670682
step: 180, loss: 0.04370937496423721
step: 190, loss: 0.005520261358469725
step: 200, loss: 0.027698799967765808
step: 210, loss: 0.017249586060643196
step: 220, loss: 0.005711237899959087
step: 230, loss: 0.057180725038051605
step: 240, loss: 0.001450899406336248
step: 250, loss: 0.012877585366368294
step: 260, loss: 0.006903119385242462
step: 270, loss: 0.010104970075190067
step: 280, loss: 0.05005795136094093
step: 290, loss: 0.0571623332798481
step: 300, loss: 0.021097809076309204
step: 310, loss: 0.0990842804312706
step: 320, loss: 0.04835834726691246
step: 330, loss: 0.0009596634190529585
step: 340, loss: 0.010258307680487633
step: 350, loss: 0.006791222840547562
epoch 6: dev_f1=0.7719298245614035, f1=0.712468193384224, best_f1=0.7610208816705337
step: 0, loss: 0.009447718970477581
step: 10, loss: 0.0006806515739299357
step: 20, loss: 0.002106272615492344
step: 30, loss: 0.008784853853285313
step: 40, loss: 0.0002838428190443665
step: 50, loss: 0.0012780171819031239
step: 60, loss: 0.00017603962623979896
step: 70, loss: 0.004564991220831871
step: 80, loss: 0.007294690702110529
step: 90, loss: 0.0030305064283311367
step: 100, loss: 0.0013702982105314732
step: 110, loss: 0.004328237846493721
step: 120, loss: 0.0653151422739029
step: 130, loss: 0.004721306264400482
step: 140, loss: 0.012829117476940155
step: 150, loss: 0.0018329833401367068
step: 160, loss: 0.16937854886054993
step: 170, loss: 0.013865319080650806
step: 180, loss: 0.0013660688418895006
step: 190, loss: 0.04740136116743088
step: 200, loss: 0.005944219883531332
step: 210, loss: 0.028762077912688255
step: 220, loss: 0.009886011481285095
step: 230, loss: 0.002313068835064769
step: 240, loss: 0.008532227016985416
step: 250, loss: 0.0003335086803417653
step: 260, loss: 0.0012337862281128764
step: 270, loss: 0.0017666699131950736
step: 280, loss: 0.006914564408361912
step: 290, loss: 0.03889457508921623
step: 300, loss: 0.0002663554041646421
step: 310, loss: 0.01986616477370262
step: 320, loss: 0.034563686698675156
step: 330, loss: 0.0035432856529951096
step: 340, loss: 0.009997500106692314
step: 350, loss: 0.004883599933236837
epoch 7: dev_f1=0.7708333333333335, f1=0.6970509383378016, best_f1=0.7610208816705337
step: 0, loss: 0.001517408643849194
step: 10, loss: 0.0033285710960626602
step: 20, loss: 0.001749945105984807
step: 30, loss: 0.01007197704166174
step: 40, loss: 0.004437642637640238
step: 50, loss: 0.00876204390078783
step: 60, loss: 0.04416349157691002
step: 70, loss: 0.0005979680572636425
step: 80, loss: 0.006012651138007641
step: 90, loss: 0.020014377310872078
step: 100, loss: 0.07497398555278778
step: 110, loss: 0.10032658278942108
step: 120, loss: 0.0074983807280659676
step: 130, loss: 0.07284195721149445
step: 140, loss: 0.049855977296829224
step: 150, loss: 0.006349219940602779
step: 160, loss: 0.044404350221157074
step: 170, loss: 0.0027513469103723764
step: 180, loss: 0.012166582979261875
step: 190, loss: 0.003124641254544258
step: 200, loss: 0.001548750209622085
step: 210, loss: 0.0003443440073169768
step: 220, loss: 0.00888938456773758
step: 230, loss: 0.012840536423027515
step: 240, loss: 0.0007762025343254209
step: 250, loss: 0.011617529205977917
step: 260, loss: 0.007339581847190857
step: 270, loss: 0.030583593994379044
step: 280, loss: 0.15935881435871124
step: 290, loss: 0.11882492899894714
step: 300, loss: 0.0736856758594513
step: 310, loss: 0.08682393282651901
step: 320, loss: 0.000497073691803962
step: 330, loss: 0.0009851824725046754
step: 340, loss: 0.0007467785617336631
step: 350, loss: 0.0006890492513775826
epoch 8: dev_f1=0.7682119205298014, f1=0.7149122807017544, best_f1=0.7610208816705337
step: 0, loss: 0.002195250242948532
step: 10, loss: 0.002371111186221242
step: 20, loss: 0.03312927111983299
step: 30, loss: 0.04688448831439018
step: 40, loss: 0.019135724753141403
step: 50, loss: 0.005922580603510141
step: 60, loss: 0.030326757580041885
step: 70, loss: 0.0008701509796082973
step: 80, loss: 0.004369865171611309
step: 90, loss: 0.00033429564791731536
step: 100, loss: 0.007269039750099182
step: 110, loss: 0.00047588450252078474
step: 120, loss: 0.04237256571650505
step: 130, loss: 0.0015078965807333589
step: 140, loss: 0.0006700355443172157
step: 150, loss: 0.015077061019837856
step: 160, loss: 0.002805391326546669
step: 170, loss: 0.020176149904727936
step: 180, loss: 0.010415042750537395
step: 190, loss: 0.0006200985517352819
step: 200, loss: 0.0006156224990263581
step: 210, loss: 0.00024380217655561864
step: 220, loss: 0.00391232268884778
step: 230, loss: 0.00416257930919528
step: 240, loss: 0.049820370972156525
step: 250, loss: 0.018041595816612244
step: 260, loss: 0.00029056938365101814
step: 270, loss: 0.003671093611046672
step: 280, loss: 0.0012248907005414367
step: 290, loss: 0.09286129474639893
step: 300, loss: 0.014218517579138279
step: 310, loss: 0.01499992422759533
step: 320, loss: 0.0009235460311174393
step: 330, loss: 0.007666895166039467
step: 340, loss: 0.04241631552577019
step: 350, loss: 0.007948108948767185
epoch 9: dev_f1=0.7680000000000001, f1=0.7123287671232877, best_f1=0.7610208816705337
step: 0, loss: 0.013134812004864216
step: 10, loss: 0.0010886662639677525
step: 20, loss: 0.05664348229765892
step: 30, loss: 0.01540748868137598
step: 40, loss: 0.013693386688828468
step: 50, loss: 0.011696793138980865
step: 60, loss: 0.017731305211782455
step: 70, loss: 0.04183410108089447
step: 80, loss: 0.00025983265368267894
step: 90, loss: 0.0011674382258206606
step: 100, loss: 0.0011726341908797622
step: 110, loss: 0.0007921641226857901
step: 120, loss: 0.0012047303607687354
step: 130, loss: 0.00010522296361159533
step: 140, loss: 0.03168148547410965
step: 150, loss: 0.03222452104091644
step: 160, loss: 0.0006908824434503913
step: 170, loss: 0.0024195644073188305
step: 180, loss: 0.05384426191449165
step: 190, loss: 0.006045990157872438
step: 200, loss: 0.00024538274738006294
step: 210, loss: 0.004415865056216717
step: 220, loss: 0.0015252941520884633
step: 230, loss: 0.0013173352926969528
step: 240, loss: 0.0013829785166308284
step: 250, loss: 0.00021101189486216754
step: 260, loss: 0.00018988183001056314
step: 270, loss: 0.0022973911836743355
step: 280, loss: 0.0011539642000570893
step: 290, loss: 0.0033745323307812214
step: 300, loss: 0.0006063927430659533
step: 310, loss: 0.00045586275518871844
step: 320, loss: 0.07228086143732071
step: 330, loss: 0.0010663957800716162
step: 340, loss: 0.04808218777179718
step: 350, loss: 0.012129834853112698
epoch 10: dev_f1=0.7647058823529412, f1=0.7325301204819279, best_f1=0.7610208816705337
step: 0, loss: 0.0005508014583028853
step: 10, loss: 5.5072981922421604e-05
step: 20, loss: 0.0006711900932714343
step: 30, loss: 0.022217288613319397
step: 40, loss: 0.06068338826298714
step: 50, loss: 0.002841376233845949
step: 60, loss: 0.038379669189453125
step: 70, loss: 0.00042859400855377316
step: 80, loss: 0.00019451351545285434
step: 90, loss: 0.003467385657131672
step: 100, loss: 0.000510173907969147
step: 110, loss: 0.000440767063992098
step: 120, loss: 0.011721300892531872
step: 130, loss: 0.005289814434945583
step: 140, loss: 0.007708318065851927
step: 150, loss: 0.0030533752869814634
step: 160, loss: 0.008053804747760296
step: 170, loss: 0.0002772232983261347
step: 180, loss: 0.0009601610363461077
step: 190, loss: 0.0013558028731495142
step: 200, loss: 0.0007972482708282769
step: 210, loss: 0.03460337966680527
step: 220, loss: 0.022182581946253777
step: 230, loss: 0.0008820449002087116
step: 240, loss: 0.00019458774477243423
step: 250, loss: 0.00039460803964175284
step: 260, loss: 0.004790081176906824
step: 270, loss: 0.016519609838724136
step: 280, loss: 0.00037568644620478153
step: 290, loss: 0.00018536622519604862
step: 300, loss: 0.005441378802061081
step: 310, loss: 0.0004974599578417838
step: 320, loss: 0.00010787051724037156
step: 330, loss: 0.013493425212800503
step: 340, loss: 0.00033251833519898355
step: 350, loss: 0.00037778215482831
epoch 11: dev_f1=0.7587939698492463, f1=0.7185929648241206, best_f1=0.7610208816705337
step: 0, loss: 0.0006806469755247235
step: 10, loss: 7.571597234345973e-05
step: 20, loss: 0.00016682088607922196
step: 30, loss: 0.1843426376581192
step: 40, loss: 0.0007006850210018456
step: 50, loss: 0.006773980800062418
step: 60, loss: 0.0011501287808641791
step: 70, loss: 0.00019883234926965088
step: 80, loss: 0.004071840550750494
step: 90, loss: 0.0031126749236136675
step: 100, loss: 0.0003150612465105951
step: 110, loss: 0.026273705065250397
step: 120, loss: 0.008242648094892502
step: 130, loss: 0.00015798934327904135
step: 140, loss: 0.0002628567162901163
step: 150, loss: 0.00013694883091375232
step: 160, loss: 0.0004216200904920697
step: 170, loss: 0.0002152837987523526
step: 180, loss: 0.0004441564960870892
step: 190, loss: 0.0008060658583417535
step: 200, loss: 0.0015371371991932392
step: 210, loss: 0.0013527822447940707
step: 220, loss: 0.0005671397084370255
step: 230, loss: 0.0007324175676330924
step: 240, loss: 0.004720318131148815
step: 250, loss: 0.028860464692115784
step: 260, loss: 0.008544870652258396
step: 270, loss: 0.0001808118831831962
step: 280, loss: 0.0007093547028489411
step: 290, loss: 0.0011883301194757223
step: 300, loss: 8.139893179759383e-05
step: 310, loss: 0.0006787661113776267
step: 320, loss: 0.0001470434363000095
step: 330, loss: 0.00041823097853921354
step: 340, loss: 0.0002704804646782577
step: 350, loss: 0.00033994190744124353
epoch 12: dev_f1=0.7545219638242895, f1=0.7193877551020408, best_f1=0.7610208816705337
step: 0, loss: 0.00015312040341086686
step: 10, loss: 0.00022916124726179987
step: 20, loss: 0.0038801711052656174
step: 30, loss: 0.00010290184582117945
step: 40, loss: 0.0038854859303683043
step: 50, loss: 0.006412914022803307
step: 60, loss: 8.451130270259455e-05
step: 70, loss: 0.0005241302424110472
step: 80, loss: 4.340167288319208e-05
step: 90, loss: 0.0001399802858941257
step: 100, loss: 0.000137593291583471
step: 110, loss: 0.0003638787311501801
step: 120, loss: 0.02518094889819622
step: 130, loss: 0.00012823169527109712
step: 140, loss: 0.00015346459986176342
step: 150, loss: 0.009942848235368729
step: 160, loss: 0.00047807052033022046
step: 170, loss: 5.445707211038098e-05
step: 180, loss: 4.4726806663675234e-05
step: 190, loss: 0.000174154614796862
step: 200, loss: 0.00011499803804326802
step: 210, loss: 5.831825183122419e-05
step: 220, loss: 6.383863365044817e-05
step: 230, loss: 9.633648733142763e-05
step: 240, loss: 0.0012227133847773075
step: 250, loss: 0.000400770251872018
step: 260, loss: 0.00010982742242049426
step: 270, loss: 9.252123709302396e-05
step: 280, loss: 7.712495425948873e-05
step: 290, loss: 0.00022828330111224204
step: 300, loss: 8.911468466976658e-05
step: 310, loss: 0.0002007754665100947
step: 320, loss: 0.0006178539479151368
step: 330, loss: 0.00011093141802120954
step: 340, loss: 8.328068361151963e-05
step: 350, loss: 0.008228608407080173
epoch 13: dev_f1=0.7532467532467533, f1=0.7244897959183674, best_f1=0.7610208816705337
step: 0, loss: 0.0005654216511175036
step: 10, loss: 0.0212338175624609
step: 20, loss: 0.008270176127552986
step: 30, loss: 0.00614881282672286
step: 40, loss: 0.0002036745718214661
step: 50, loss: 0.0005325209349393845
step: 60, loss: 0.0003610272833611816
step: 70, loss: 0.11573290824890137
step: 80, loss: 0.0009272202732972801
step: 90, loss: 0.0010637891246005893
step: 100, loss: 0.007038694806396961
step: 110, loss: 0.000509181059896946
step: 120, loss: 0.0001346984936390072
step: 130, loss: 0.00019168565631844103
step: 140, loss: 0.00016795798728708178
step: 150, loss: 0.002678029239177704
step: 160, loss: 0.001173282158561051
step: 170, loss: 0.00022730078489985317
step: 180, loss: 0.0009675255278125405
step: 190, loss: 0.0042959111742675304
step: 200, loss: 0.0065743327140808105
step: 210, loss: 0.0007286217296496034
step: 220, loss: 0.0006884714821353555
step: 230, loss: 0.0010775692062452435
step: 240, loss: 0.019773799926042557
step: 250, loss: 5.6829972891137004e-05
step: 260, loss: 0.0021699918434023857
step: 270, loss: 0.0001668002805672586
step: 280, loss: 0.00017046129505615681
step: 290, loss: 0.0001828056265367195
step: 300, loss: 0.0016583411488682032
step: 310, loss: 0.0002310628624400124
step: 320, loss: 0.0002957844117190689
step: 330, loss: 0.00024408371245954186
step: 340, loss: 0.00011247353540966287
step: 350, loss: 0.0009704330586828291
epoch 14: dev_f1=0.7857142857142857, f1=0.7291666666666666, best_f1=0.7610208816705337
step: 0, loss: 0.0001563521072966978
step: 10, loss: 0.00020248658256605268
step: 20, loss: 0.0010863825445994735
step: 30, loss: 0.0011538384715095162
step: 40, loss: 0.013845479115843773
step: 50, loss: 0.004002168774604797
step: 60, loss: 0.004840905778110027
step: 70, loss: 0.0012187953107059002
step: 80, loss: 0.00012523379700724036
step: 90, loss: 0.0006333963247016072
step: 100, loss: 0.00042549881618469954
step: 110, loss: 0.0001320623850915581
step: 120, loss: 7.153370097512379e-05
step: 130, loss: 0.0005087536410428584
step: 140, loss: 0.0007201516418717802
step: 150, loss: 0.00024065478646662086
step: 160, loss: 0.001201891340315342
step: 170, loss: 0.0006400243146345019
step: 180, loss: 0.0003884508623741567
step: 190, loss: 0.0005037508090026677
step: 200, loss: 0.0002940295380540192
step: 210, loss: 0.00046832647058181465
step: 220, loss: 7.803167682141066e-05
step: 230, loss: 0.003360323840752244
step: 240, loss: 0.0019035279983654618
step: 250, loss: 0.0007374368142336607
step: 260, loss: 0.006519909016788006
step: 270, loss: 0.03284343704581261
step: 280, loss: 0.006121549289673567
step: 290, loss: 4.4520031224237755e-05
step: 300, loss: 0.00022413152328226715
step: 310, loss: 0.03219065070152283
step: 320, loss: 0.001155397854745388
step: 330, loss: 0.00011562735016923398
step: 340, loss: 0.00012995181896258146
step: 350, loss: 0.004229419399052858
epoch 15: dev_f1=0.7721179624664879, f1=0.7292225201072388, best_f1=0.7610208816705337
step: 0, loss: 0.00013400166062638164
step: 10, loss: 9.946178033715114e-05
step: 20, loss: 7.229732727864757e-05
step: 30, loss: 0.0006060645682737231
step: 40, loss: 0.0001445140951545909
step: 50, loss: 0.01577659882605076
step: 60, loss: 5.553522350965068e-05
step: 70, loss: 0.0001358400477329269
step: 80, loss: 0.0015801890986040235
step: 90, loss: 0.0002643788466230035
step: 100, loss: 8.434645860688761e-05
step: 110, loss: 0.003959342837333679
step: 120, loss: 9.320576646132395e-05
step: 130, loss: 0.00016705405141692609
step: 140, loss: 0.010153197683393955
step: 150, loss: 4.397852171678096e-05
step: 160, loss: 0.00019839890592265874
step: 170, loss: 0.0028149031568318605
step: 180, loss: 0.0004221698036417365
step: 190, loss: 0.003183609340339899
step: 200, loss: 0.00018039812857750803
step: 210, loss: 0.0019713977817445993
step: 220, loss: 0.000261540524661541
step: 230, loss: 0.00024204907822422683
step: 240, loss: 5.342019358067773e-05
step: 250, loss: 0.011718827299773693
step: 260, loss: 5.024247366236523e-05
step: 270, loss: 0.00010406207729829475
step: 280, loss: 0.00026260819868184626
step: 290, loss: 7.960770017234609e-05
step: 300, loss: 5.9915630117757246e-05
step: 310, loss: 0.0022628665901720524
step: 320, loss: 0.007819506339728832
step: 330, loss: 0.001151766162365675
step: 340, loss: 0.00012457741831894964
step: 350, loss: 0.0001471322466386482
epoch 16: dev_f1=0.782608695652174, f1=0.7405541561712846, best_f1=0.7610208816705337
step: 0, loss: 0.0005265373038128018
step: 10, loss: 7.548584108008072e-05
step: 20, loss: 0.00015404648729600012
step: 30, loss: 0.00011209293006686494
step: 40, loss: 7.347048085648566e-05
step: 50, loss: 0.0026338547468185425
step: 60, loss: 0.01339676696807146
step: 70, loss: 0.00012984639033675194
step: 80, loss: 5.8195328165311366e-05
step: 90, loss: 5.667641744366847e-05
step: 100, loss: 0.03460682928562164
step: 110, loss: 0.00012622581562027335
step: 120, loss: 0.0010975691257044673
step: 130, loss: 0.0008056180085986853
step: 140, loss: 0.00021325612033251673
step: 150, loss: 0.027369389310479164
step: 160, loss: 0.00020099725225009024
step: 170, loss: 0.0003729478339664638
step: 180, loss: 7.694890518905595e-05
step: 190, loss: 0.0003402109141461551
step: 200, loss: 0.006978388410061598
step: 210, loss: 3.5273311368655413e-05
step: 220, loss: 0.0032372362911701202
step: 230, loss: 5.118458648212254e-05
step: 240, loss: 0.001109954435378313
step: 250, loss: 0.0005997627740725875
step: 260, loss: 0.00021048680355306715
step: 270, loss: 0.00012150095426477492
step: 280, loss: 0.0003343189018778503
step: 290, loss: 5.0968850700883195e-05
step: 300, loss: 0.008343422785401344
step: 310, loss: 2.5968583940993994e-05
step: 320, loss: 0.0003356497618369758
step: 330, loss: 0.000403795565944165
step: 340, loss: 0.00030079815769568086
step: 350, loss: 0.00013432771083898842
epoch 17: dev_f1=0.7737226277372263, f1=0.7250608272506082, best_f1=0.7610208816705337
step: 0, loss: 0.0001934247848112136
step: 10, loss: 0.00016190852329600602
step: 20, loss: 5.3310723160393536e-05
step: 30, loss: 0.00038230849895626307
step: 40, loss: 3.5608940379461274e-05
step: 50, loss: 0.0001099428118322976
step: 60, loss: 0.00011285919026704505
step: 70, loss: 0.002534400438889861
step: 80, loss: 6.354159995680675e-05
step: 90, loss: 0.001307192724198103
step: 100, loss: 6.808710168115795e-05
step: 110, loss: 0.00012609106488525867
step: 120, loss: 9.108304948313162e-05
step: 130, loss: 0.0009666600963100791
step: 140, loss: 9.997706365538761e-05
step: 150, loss: 4.366536813904531e-05
step: 160, loss: 0.03130299597978592
step: 170, loss: 0.0008111659553833306
step: 180, loss: 0.00017280035535804927
step: 190, loss: 7.168175943661481e-05
step: 200, loss: 0.0001305298210354522
step: 210, loss: 0.0003740162937901914
step: 220, loss: 0.0007324146572500467
step: 230, loss: 0.0001038613190758042
step: 240, loss: 0.00010173371993005276
step: 250, loss: 0.0025363743770867586
step: 260, loss: 7.004925282672048e-05
step: 270, loss: 0.00018608776736073196
step: 280, loss: 0.000188081365195103
step: 290, loss: 0.002629494061693549
step: 300, loss: 7.967989949975163e-05
step: 310, loss: 0.00021046320034656674
step: 320, loss: 0.001182573614642024
step: 330, loss: 0.00026384909870103
step: 340, loss: 9.24256892176345e-05
step: 350, loss: 0.0001511673181084916
epoch 18: dev_f1=0.7855421686746988, f1=0.7405660377358491, best_f1=0.7610208816705337
step: 0, loss: 0.0026061886455863714
step: 10, loss: 3.8949983718339354e-05
step: 20, loss: 0.0002906534937210381
step: 30, loss: 0.00016324441821780056
step: 40, loss: 0.001618557027541101
step: 50, loss: 0.005839535966515541
step: 60, loss: 5.335418609320186e-05
step: 70, loss: 0.0001379406312480569
step: 80, loss: 0.014545576646924019
step: 90, loss: 9.603157377569005e-05
step: 100, loss: 0.00026055259513668716
step: 110, loss: 0.0004378889861982316
step: 120, loss: 0.00016841183241922408
step: 130, loss: 0.00019369901565369219
step: 140, loss: 0.00013994771870784461
step: 150, loss: 6.331127951852977e-05
step: 160, loss: 0.0008498728857375681
step: 170, loss: 5.012310066376813e-05
step: 180, loss: 0.00017327321984339505
step: 190, loss: 0.003064333228394389
step: 200, loss: 6.678588397335261e-05
step: 210, loss: 8.043354318942875e-05
step: 220, loss: 0.00015973750851117074
step: 230, loss: 0.0002722540812101215
step: 240, loss: 3.92107613151893e-05
step: 250, loss: 0.0004418321477714926
step: 260, loss: 0.0001752231764839962
step: 270, loss: 0.00022365919721778482
step: 280, loss: 7.152504258556291e-05
step: 290, loss: 6.589748954866081e-05
step: 300, loss: 0.0016896604793146253
step: 310, loss: 6.776207737857476e-05
step: 320, loss: 4.852409256272949e-05
step: 330, loss: 0.00013216501974966377
step: 340, loss: 9.245386172551662e-05
step: 350, loss: 0.0004388769157230854
epoch 19: dev_f1=0.7763496143958869, f1=0.7295918367346939, best_f1=0.7610208816705337
step: 0, loss: 0.0023639146238565445
step: 10, loss: 0.00015422378783114254
step: 20, loss: 0.00012233262532390654
step: 30, loss: 0.005189887247979641
step: 40, loss: 6.325267895590514e-05
step: 50, loss: 0.10723721235990524
step: 60, loss: 4.1624396544648334e-05
step: 70, loss: 4.3832362280227244e-05
step: 80, loss: 5.056746522313915e-05
step: 90, loss: 5.441667963168584e-05
step: 100, loss: 0.02838626690208912
step: 110, loss: 0.016609668731689453
step: 120, loss: 0.00026440893998369575
step: 130, loss: 3.3112253731815144e-05
step: 140, loss: 9.821214189287275e-05
step: 150, loss: 0.0011173862731084228
step: 160, loss: 6.87806896166876e-05
step: 170, loss: 0.00015876111865509301
step: 180, loss: 0.00013499052147381008
step: 190, loss: 0.00012128042726544663
step: 200, loss: 0.00060203269822523
step: 210, loss: 5.005283310310915e-05
step: 220, loss: 4.789758531842381e-05
step: 230, loss: 0.0004908182309009135
step: 240, loss: 0.0003458973078522831
step: 250, loss: 5.7334473240189254e-05
step: 260, loss: 9.086463251151145e-05
step: 270, loss: 0.00012712778698187321
step: 280, loss: 0.05894314870238304
step: 290, loss: 5.357573172659613e-05
step: 300, loss: 0.0001376260770484805
step: 310, loss: 2.7100804800284095e-05
step: 320, loss: 5.7915567595046014e-05
step: 330, loss: 6.880927685415372e-05
step: 340, loss: 7.152547186706215e-05
step: 350, loss: 0.00016740623686928302
epoch 20: dev_f1=0.7830423940149626, f1=0.7259259259259259, best_f1=0.7610208816705337
