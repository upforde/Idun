cuda
Device: cuda
step: 0, loss: 0.7911645174026489
step: 10, loss: 0.19314230978488922
step: 20, loss: 0.23857733607292175
step: 30, loss: 0.23598572611808777
step: 40, loss: 0.23572921752929688
step: 50, loss: 0.13784566521644592
step: 60, loss: 0.24819335341453552
step: 70, loss: 0.15100902318954468
step: 80, loss: 0.30546072125434875
step: 90, loss: 0.1838359236717224
step: 100, loss: 0.28433606028556824
step: 110, loss: 0.2289174348115921
step: 120, loss: 0.3636047840118408
step: 130, loss: 0.4340468645095825
step: 140, loss: 0.2285403609275818
step: 150, loss: 0.2029314935207367
step: 160, loss: 0.32769668102264404
step: 170, loss: 0.11614406853914261
step: 180, loss: 0.38935238122940063
step: 190, loss: 0.18833954632282257
step: 200, loss: 0.18748870491981506
step: 210, loss: 0.5001187920570374
step: 220, loss: 0.25996553897857666
step: 230, loss: 0.10284027457237244
step: 240, loss: 0.17028935253620148
step: 250, loss: 0.18725056946277618
step: 260, loss: 0.14167974889278412
step: 270, loss: 0.29414504766464233
step: 280, loss: 0.309891939163208
step: 290, loss: 0.22850637137889862
step: 300, loss: 0.2329617440700531
step: 310, loss: 0.1004939153790474
step: 320, loss: 0.3421176075935364
step: 330, loss: 0.619500458240509
step: 340, loss: 0.2630174160003662
step: 350, loss: 0.2897716462612152
step: 360, loss: 0.10381074994802475
step: 370, loss: 0.7907800674438477
step: 380, loss: 0.1379915326833725
epoch 1: dev_f1=0.597752808988764, f1=0.41849148418491483, best_f1=0.41849148418491483
step: 0, loss: 0.30414536595344543
step: 10, loss: 0.09104182571172714
step: 20, loss: 0.11991965770721436
step: 30, loss: 0.1350676566362381
step: 40, loss: 0.13773472607135773
step: 50, loss: 0.2670445740222931
step: 60, loss: 0.37328270077705383
step: 70, loss: 0.2814997732639313
step: 80, loss: 0.29047197103500366
step: 90, loss: 0.17443735897541046
step: 100, loss: 0.0767301395535469
step: 110, loss: 0.2169872522354126
step: 120, loss: 0.3028881549835205
step: 130, loss: 0.2410709410905838
step: 140, loss: 0.11424668878316879
step: 150, loss: 0.20566242933273315
step: 160, loss: 0.07619635760784149
step: 170, loss: 0.2099221795797348
step: 180, loss: 0.14814960956573486
step: 190, loss: 0.0455513671040535
step: 200, loss: 0.16281196475028992
step: 210, loss: 0.10560514032840729
step: 220, loss: 0.2214372158050537
step: 230, loss: 0.074190154671669
step: 240, loss: 0.2945496141910553
step: 250, loss: 0.1667729616165161
step: 260, loss: 0.08269545435905457
step: 270, loss: 0.24772903323173523
step: 280, loss: 0.296957403421402
step: 290, loss: 0.33320802450180054
step: 300, loss: 0.21456770598888397
step: 310, loss: 0.21391263604164124
step: 320, loss: 0.1002419963479042
step: 330, loss: 0.16847382485866547
step: 340, loss: 0.18675681948661804
step: 350, loss: 0.07978838682174683
step: 360, loss: 0.14869166910648346
step: 370, loss: 0.14991885423660278
step: 380, loss: 0.3396419584751129
epoch 2: dev_f1=0.7589498806682579, f1=0.5776699029126213, best_f1=0.5776699029126213
step: 0, loss: 0.17706334590911865
step: 10, loss: 0.23761501908302307
step: 20, loss: 0.10729940235614777
step: 30, loss: 0.29758068919181824
step: 40, loss: 0.06436631083488464
step: 50, loss: 0.16702352464199066
step: 60, loss: 0.09049586206674576
step: 70, loss: 0.10035207122564316
step: 80, loss: 0.19065551459789276
step: 90, loss: 0.19396379590034485
step: 100, loss: 0.0752713605761528
step: 110, loss: 0.21918721497058868
step: 120, loss: 0.19862307608127594
step: 130, loss: 0.2132255584001541
step: 140, loss: 0.13965892791748047
step: 150, loss: 0.2572318911552429
step: 160, loss: 0.4904765486717224
step: 170, loss: 0.38478031754493713
step: 180, loss: 0.37624678015708923
step: 190, loss: 0.13229571282863617
step: 200, loss: 0.036682479083538055
step: 210, loss: 0.18645930290222168
step: 220, loss: 0.03855769708752632
step: 230, loss: 0.24111518263816833
step: 240, loss: 0.1523333489894867
step: 250, loss: 0.1028827652335167
step: 260, loss: 0.15524296462535858
step: 270, loss: 0.04051700234413147
step: 280, loss: 0.17792651057243347
step: 290, loss: 0.20131494104862213
step: 300, loss: 0.14308416843414307
step: 310, loss: 0.0881245955824852
step: 320, loss: 0.11846443265676498
step: 330, loss: 0.24355556070804596
step: 340, loss: 0.15480181574821472
step: 350, loss: 0.391965389251709
step: 360, loss: 0.14865803718566895
step: 370, loss: 0.3250361979007721
step: 380, loss: 0.21935446560382843
epoch 3: dev_f1=0.7872340425531915, f1=0.6149425287356322, best_f1=0.6149425287356322
step: 0, loss: 0.0882035344839096
step: 10, loss: 0.08642330765724182
step: 20, loss: 0.13826043903827667
step: 30, loss: 0.04397124424576759
step: 40, loss: 0.2813953757286072
step: 50, loss: 0.029904723167419434
step: 60, loss: 0.20029889047145844
step: 70, loss: 0.05881091207265854
step: 80, loss: 0.12031368166208267
step: 90, loss: 0.11484599113464355
step: 100, loss: 0.07373549789190292
step: 110, loss: 0.12319673597812653
step: 120, loss: 0.04331812635064125
step: 130, loss: 0.057953670620918274
step: 140, loss: 0.1805756390094757
step: 150, loss: 0.0684567242860794
step: 160, loss: 0.07215475291013718
step: 170, loss: 0.04059571400284767
step: 180, loss: 0.05559420585632324
step: 190, loss: 0.010775472968816757
step: 200, loss: 0.039041534066200256
step: 210, loss: 0.03583618625998497
step: 220, loss: 0.08063457161188126
step: 230, loss: 0.021203521639108658
step: 240, loss: 0.03747458755970001
step: 250, loss: 0.15009132027626038
step: 260, loss: 0.07758419960737228
step: 270, loss: 0.10189802944660187
step: 280, loss: 0.08810113370418549
step: 290, loss: 0.07712919265031815
step: 300, loss: 0.07544784247875214
step: 310, loss: 0.11424469202756882
step: 320, loss: 0.1899474561214447
step: 330, loss: 0.169998899102211
step: 340, loss: 0.11353252828121185
step: 350, loss: 0.12746374309062958
step: 360, loss: 0.16777771711349487
step: 370, loss: 0.14791494607925415
step: 380, loss: 0.10630493611097336
epoch 4: dev_f1=0.7999999999999999, f1=0.5921450151057402, best_f1=0.5921450151057402
step: 0, loss: 0.04105451703071594
step: 10, loss: 0.11093990504741669
step: 20, loss: 0.0315321683883667
step: 30, loss: 0.004330647177994251
step: 40, loss: 0.07773243635892868
step: 50, loss: 0.010830559767782688
step: 60, loss: 0.004604751244187355
step: 70, loss: 0.06023062765598297
step: 80, loss: 0.058737631887197495
step: 90, loss: 0.03356163203716278
step: 100, loss: 0.19142593443393707
step: 110, loss: 0.12112513184547424
step: 120, loss: 0.06190178170800209
step: 130, loss: 0.12470319122076035
step: 140, loss: 0.022227566689252853
step: 150, loss: 0.1483422964811325
step: 160, loss: 0.21017709374427795
step: 170, loss: 0.004982168320566416
step: 180, loss: 0.033893290907144547
step: 190, loss: 0.17453835904598236
step: 200, loss: 0.011292793788015842
step: 210, loss: 0.02501079998910427
step: 220, loss: 0.034294240176677704
step: 230, loss: 0.13097092509269714
step: 240, loss: 0.14126229286193848
step: 250, loss: 0.13982181251049042
step: 260, loss: 0.21684470772743225
step: 270, loss: 0.2927379310131073
step: 280, loss: 0.07119818776845932
step: 290, loss: 0.10134419798851013
step: 300, loss: 0.04267067089676857
step: 310, loss: 0.003778761252760887
step: 320, loss: 0.025438431650400162
step: 330, loss: 0.03130394592881203
step: 340, loss: 0.20097006857395172
step: 350, loss: 0.044713106006383896
step: 360, loss: 0.012502477504312992
step: 370, loss: 0.16059137880802155
step: 380, loss: 0.15992224216461182
epoch 5: dev_f1=0.812807881773399, f1=0.6788511749347258, best_f1=0.6788511749347258
step: 0, loss: 0.038634952157735825
step: 10, loss: 0.030729196965694427
step: 20, loss: 0.05523752048611641
step: 30, loss: 0.013876625336706638
step: 40, loss: 0.01583293452858925
step: 50, loss: 0.017720364034175873
step: 60, loss: 0.05063769966363907
step: 70, loss: 0.02947411686182022
step: 80, loss: 0.06304933875799179
step: 90, loss: 0.08581489324569702
step: 100, loss: 0.06036427244544029
step: 110, loss: 0.004654525313526392
step: 120, loss: 0.17457246780395508
step: 130, loss: 0.020394638180732727
step: 140, loss: 0.023380663245916367
step: 150, loss: 0.0071249897591769695
step: 160, loss: 0.0988004207611084
step: 170, loss: 0.002380737103521824
step: 180, loss: 0.035244863480329514
step: 190, loss: 0.03014935366809368
step: 200, loss: 0.15611936151981354
step: 210, loss: 0.11056745052337646
step: 220, loss: 0.0664190798997879
step: 230, loss: 0.1951456516981125
step: 240, loss: 0.07122770696878433
step: 250, loss: 0.2917798161506653
step: 260, loss: 0.0838763490319252
step: 270, loss: 0.008208814077079296
step: 280, loss: 0.027259882539510727
step: 290, loss: 0.1273108869791031
step: 300, loss: 0.023769615218043327
step: 310, loss: 0.012960368767380714
step: 320, loss: 0.013004010543227196
step: 330, loss: 0.08699964731931686
step: 340, loss: 0.07435686886310577
step: 350, loss: 0.07571030408143997
step: 360, loss: 0.01235502865165472
step: 370, loss: 0.026284467428922653
step: 380, loss: 0.09630967676639557
epoch 6: dev_f1=0.801007556675063, f1=0.6525198938992043, best_f1=0.6788511749347258
step: 0, loss: 0.04016035422682762
step: 10, loss: 0.0013573908945545554
step: 20, loss: 0.09209632128477097
step: 30, loss: 0.0637015551328659
step: 40, loss: 0.05199969559907913
step: 50, loss: 0.0011392318410798907
step: 60, loss: 0.01903105527162552
step: 70, loss: 0.06226785108447075
step: 80, loss: 0.0010632046032696962
step: 90, loss: 0.005143509246408939
step: 100, loss: 0.01919424720108509
step: 110, loss: 0.001656058244407177
step: 120, loss: 0.022765429690480232
step: 130, loss: 0.17219550907611847
step: 140, loss: 0.0014615809777751565
step: 150, loss: 0.01751401647925377
step: 160, loss: 0.030027858912944794
step: 170, loss: 0.0011447030119597912
step: 180, loss: 0.0032779427710920572
step: 190, loss: 0.08966381102800369
step: 200, loss: 0.019772490486502647
step: 210, loss: 0.012986952438950539
step: 220, loss: 0.15474127233028412
step: 230, loss: 0.012441124767065048
step: 240, loss: 0.04903363063931465
step: 250, loss: 0.002108687534928322
step: 260, loss: 0.07665834575891495
step: 270, loss: 0.014771069400012493
step: 280, loss: 0.007064523175358772
step: 290, loss: 0.18277713656425476
step: 300, loss: 0.03679106757044792
step: 310, loss: 0.006594908889383078
step: 320, loss: 0.008189362473785877
step: 330, loss: 0.011871579103171825
step: 340, loss: 0.0034085859078913927
step: 350, loss: 0.01441335491836071
step: 360, loss: 0.011034637689590454
step: 370, loss: 0.006099325604736805
step: 380, loss: 0.0010530182626098394
epoch 7: dev_f1=0.802919708029197, f1=0.670299727520436, best_f1=0.6788511749347258
step: 0, loss: 0.006765348371118307
step: 10, loss: 0.06519781798124313
step: 20, loss: 0.0011354865273460746
step: 30, loss: 0.006753814406692982
step: 40, loss: 0.05016377195715904
step: 50, loss: 0.022338170558214188
step: 60, loss: 0.033360157161951065
step: 70, loss: 0.0007237144163809717
step: 80, loss: 0.0014215137343853712
step: 90, loss: 0.06328839063644409
step: 100, loss: 0.01850704662501812
step: 110, loss: 0.004457974340766668
step: 120, loss: 0.023048456758260727
step: 130, loss: 0.028158674016594887
step: 140, loss: 0.005944935139268637
step: 150, loss: 0.010917775332927704
step: 160, loss: 0.004748281091451645
step: 170, loss: 0.011328174732625484
step: 180, loss: 0.03330345079302788
step: 190, loss: 0.0008753089350648224
step: 200, loss: 0.022253982722759247
step: 210, loss: 0.003676681313663721
step: 220, loss: 0.0009182845242321491
step: 230, loss: 0.013383593410253525
step: 240, loss: 0.06790357828140259
step: 250, loss: 0.09719524532556534
step: 260, loss: 0.002930929884314537
step: 270, loss: 0.003927677869796753
step: 280, loss: 0.005512975621968508
step: 290, loss: 0.09790561348199844
step: 300, loss: 0.13982535898685455
step: 310, loss: 0.006408661138266325
step: 320, loss: 0.020555106922984123
step: 330, loss: 0.046654291450977325
step: 340, loss: 0.03382805734872818
step: 350, loss: 0.009035077877342701
step: 360, loss: 0.0426303930580616
step: 370, loss: 0.02488502860069275
step: 380, loss: 0.024283327162265778
epoch 8: dev_f1=0.7862407862407863, f1=0.6757493188010899, best_f1=0.6788511749347258
step: 0, loss: 0.028706606477499008
step: 10, loss: 0.009162215515971184
step: 20, loss: 0.039984505623579025
step: 30, loss: 0.00428010942414403
step: 40, loss: 0.004341442137956619
step: 50, loss: 0.005937015637755394
step: 60, loss: 0.005046631209552288
step: 70, loss: 0.018029717728495598
step: 80, loss: 0.028343237936496735
step: 90, loss: 0.0013039426412433386
step: 100, loss: 0.011185754090547562
step: 110, loss: 0.00027906143805012107
step: 120, loss: 0.003508409019559622
step: 130, loss: 0.022458449006080627
step: 140, loss: 0.007978026755154133
step: 150, loss: 0.017040830105543137
step: 160, loss: 0.0005310894339345396
step: 170, loss: 0.04179252311587334
step: 180, loss: 0.030017657205462456
step: 190, loss: 0.04735361039638519
step: 200, loss: 0.0011976128444075584
step: 210, loss: 0.0043206228874623775
step: 220, loss: 0.019488748162984848
step: 230, loss: 0.004059091210365295
step: 240, loss: 0.0124285276979208
step: 250, loss: 0.00227795890532434
step: 260, loss: 0.012245485559105873
step: 270, loss: 0.01708873175084591
step: 280, loss: 0.012559310533106327
step: 290, loss: 0.0020330327097326517
step: 300, loss: 0.12884747982025146
step: 310, loss: 0.005822708830237389
step: 320, loss: 0.0003438518906477839
step: 330, loss: 0.004551870748400688
step: 340, loss: 0.011091365478932858
step: 350, loss: 0.0006917613791301847
step: 360, loss: 0.0008485719445161521
step: 370, loss: 0.0004860909830313176
step: 380, loss: 0.0019460818730294704
epoch 9: dev_f1=0.7810026385224274, f1=0.6473988439306357, best_f1=0.6788511749347258
step: 0, loss: 0.00176130305044353
step: 10, loss: 0.0019594831392169
step: 20, loss: 0.005691345315426588
step: 30, loss: 0.005410163663327694
step: 40, loss: 0.0017206287011504173
step: 50, loss: 0.004254493862390518
step: 60, loss: 0.0005535648670047522
step: 70, loss: 0.042797595262527466
step: 80, loss: 0.03554113954305649
step: 90, loss: 0.002370279049500823
step: 100, loss: 0.06823115795850754
step: 110, loss: 0.0011236430145800114
step: 120, loss: 0.009534575045108795
step: 130, loss: 0.006176524795591831
step: 140, loss: 0.03752344846725464
step: 150, loss: 0.006698518991470337
step: 160, loss: 0.11814788728952408
step: 170, loss: 0.002429384272545576
step: 180, loss: 0.019184570759534836
step: 190, loss: 0.0014383839443325996
step: 200, loss: 0.07732228189706802
step: 210, loss: 0.02287818118929863
step: 220, loss: 0.0025388626381754875
step: 230, loss: 0.008276981301605701
step: 240, loss: 0.032310716807842255
step: 250, loss: 0.020740358158946037
step: 260, loss: 0.001971478806808591
step: 270, loss: 0.0014915174106135964
step: 280, loss: 0.0011679665185511112
step: 290, loss: 0.038918182253837585
step: 300, loss: 0.000856864033266902
step: 310, loss: 0.010965615510940552
step: 320, loss: 0.12400946021080017
step: 330, loss: 0.008794768713414669
step: 340, loss: 0.011761264875531197
step: 350, loss: 0.004123164340853691
step: 360, loss: 0.019106125459074974
step: 370, loss: 0.10718385875225067
step: 380, loss: 0.002612633863463998
epoch 10: dev_f1=0.7342465753424658, f1=0.5611940298507463, best_f1=0.6788511749347258
step: 0, loss: 0.00014223424659576267
step: 10, loss: 0.003442728891968727
step: 20, loss: 0.002538624918088317
step: 30, loss: 0.005704110022634268
step: 40, loss: 0.030113954097032547
step: 50, loss: 0.007622029632329941
step: 60, loss: 0.002093071350827813
step: 70, loss: 0.0025425858329981565
step: 80, loss: 0.0015155323781073093
step: 90, loss: 0.000421506236307323
step: 100, loss: 0.00030638501630164683
step: 110, loss: 0.003944460302591324
step: 120, loss: 0.0009409536141902208
step: 130, loss: 0.00040547834942117333
step: 140, loss: 0.0020771652925759554
step: 150, loss: 0.00046062012552283704
step: 160, loss: 0.0032930197194218636
step: 170, loss: 0.00021308856958057731
step: 180, loss: 0.006528863217681646
step: 190, loss: 0.001812692265957594
step: 200, loss: 0.00019533306476660073
step: 210, loss: 0.11937316507101059
step: 220, loss: 0.03239770606160164
step: 230, loss: 0.0008996603428386152
step: 240, loss: 0.050326280295848846
step: 250, loss: 0.0016155310440808535
step: 260, loss: 0.05748418718576431
step: 270, loss: 0.002037665108218789
step: 280, loss: 0.028081340715289116
step: 290, loss: 0.00316223013214767
step: 300, loss: 0.0003172144351992756
step: 310, loss: 0.08730033040046692
step: 320, loss: 0.13957230746746063
step: 330, loss: 0.0003078053123317659
step: 340, loss: 0.0006029506330378354
step: 350, loss: 0.0009699729853309691
step: 360, loss: 0.021642737090587616
step: 370, loss: 0.0002585547335911542
step: 380, loss: 0.016133753582835197
epoch 11: dev_f1=0.7769423558897243, f1=0.6358695652173914, best_f1=0.6788511749347258
step: 0, loss: 0.005028060171753168
step: 10, loss: 0.0009108007070608437
step: 20, loss: 0.00041805641376413405
step: 30, loss: 0.001475063618272543
step: 40, loss: 0.041205406188964844
step: 50, loss: 0.0016261088894680142
step: 60, loss: 0.00037698453525081277
step: 70, loss: 0.002510692924261093
step: 80, loss: 0.009175099432468414
step: 90, loss: 0.002432518173009157
step: 100, loss: 0.0428687147796154
step: 110, loss: 0.007862462662160397
step: 120, loss: 0.0005641174502670765
step: 130, loss: 0.00472285458818078
step: 140, loss: 9.405950549989939e-05
step: 150, loss: 0.0005918913520872593
step: 160, loss: 0.0025196000933647156
step: 170, loss: 0.006573734804987907
step: 180, loss: 0.010693386197090149
step: 190, loss: 0.005743423942476511
step: 200, loss: 0.00334866251796484
step: 210, loss: 0.003145578084513545
step: 220, loss: 0.03230901435017586
step: 230, loss: 0.03800879046320915
step: 240, loss: 0.0025879344902932644
step: 250, loss: 0.003167095361277461
step: 260, loss: 0.000619152735453099
step: 270, loss: 0.0010105660185217857
step: 280, loss: 0.0020331840496510267
step: 290, loss: 0.016230987384915352
step: 300, loss: 0.001089513418264687
step: 310, loss: 0.005405384115874767
step: 320, loss: 0.0002294835721841082
step: 330, loss: 0.0015202662907540798
step: 340, loss: 0.001462458400055766
step: 350, loss: 0.0005287005915306509
step: 360, loss: 0.006143525242805481
step: 370, loss: 0.0018232418224215508
step: 380, loss: 0.0013431990519165993
epoch 12: dev_f1=0.8020050125313284, f1=0.6629526462395543, best_f1=0.6788511749347258
step: 0, loss: 0.0008740694029256701
step: 10, loss: 0.016299834474921227
step: 20, loss: 0.00012622114445548505
step: 30, loss: 0.0036970898509025574
step: 40, loss: 0.005108552053570747
step: 50, loss: 0.021417712792754173
step: 60, loss: 0.00023721954494249076
step: 70, loss: 0.004455857910215855
step: 80, loss: 0.008811750449240208
step: 90, loss: 0.00025982537772506475
step: 100, loss: 0.00020319127361290157
step: 110, loss: 0.00021204636141192168
step: 120, loss: 0.0011883389670401812
step: 130, loss: 0.0008813819731585681
step: 140, loss: 0.008944171480834484
step: 150, loss: 0.0001446894311811775
step: 160, loss: 0.00032322018523700535
step: 170, loss: 0.0006324149435386062
step: 180, loss: 0.014226213097572327
step: 190, loss: 0.0008680307073518634
step: 200, loss: 5.1838713261531666e-05
step: 210, loss: 0.007520652841776609
step: 220, loss: 0.0011584049789234996
step: 230, loss: 0.0015020821010693908
step: 240, loss: 0.0019893439020961523
step: 250, loss: 0.0013293646043166518
step: 260, loss: 0.0013025823282077909
step: 270, loss: 0.006148809567093849
step: 280, loss: 0.00011716501467162743
step: 290, loss: 0.0035548999439924955
step: 300, loss: 7.589707820443437e-05
step: 310, loss: 0.00010146875138161704
step: 320, loss: 0.0013876943849027157
step: 330, loss: 7.660881237825379e-05
step: 340, loss: 0.02744155190885067
step: 350, loss: 0.005260078236460686
step: 360, loss: 0.0029449649155139923
step: 370, loss: 0.06811998039484024
step: 380, loss: 0.08662456274032593
epoch 13: dev_f1=0.7839195979899498, f1=0.6225895316804407, best_f1=0.6788511749347258
step: 0, loss: 0.0008162196027114987
step: 10, loss: 0.006705503910779953
step: 20, loss: 0.010075347498059273
step: 30, loss: 9.959875023923814e-05
step: 40, loss: 0.00016867119120433927
step: 50, loss: 0.00013196606596466154
step: 60, loss: 0.0005109000485390425
step: 70, loss: 0.0002482206909917295
step: 80, loss: 0.0013179040979593992
step: 90, loss: 0.002982198726385832
step: 100, loss: 0.0001609514292795211
step: 110, loss: 0.02080998755991459
step: 120, loss: 0.0004883305518887937
step: 130, loss: 0.0001619251852389425
step: 140, loss: 0.023521313443779945
step: 150, loss: 0.0002618294092826545
step: 160, loss: 0.0007695393869653344
step: 170, loss: 7.847248343750834e-05
step: 180, loss: 0.00019038686878047884
step: 190, loss: 0.000540631590411067
step: 200, loss: 9.887338819680735e-05
step: 210, loss: 0.0008868246804922819
step: 220, loss: 0.0008473638445138931
step: 230, loss: 0.03184964135289192
step: 240, loss: 0.0023756090085953474
step: 250, loss: 0.0001925511023728177
step: 260, loss: 0.00019370221707504243
step: 270, loss: 0.00032293342519551516
step: 280, loss: 0.0007305838516913354
step: 290, loss: 0.0021606609225273132
step: 300, loss: 0.005237200763076544
step: 310, loss: 0.0003054041007999331
step: 320, loss: 0.00017740234034135938
step: 330, loss: 0.0004728118365164846
step: 340, loss: 0.0008143000886775553
step: 350, loss: 0.00018065239419229329
step: 360, loss: 0.00017615832621231675
step: 370, loss: 0.0006140259210951626
step: 380, loss: 0.00011850185546791181
epoch 14: dev_f1=0.7677725118483413, f1=0.6456692913385826, best_f1=0.6788511749347258
step: 0, loss: 0.00028744785231538117
step: 10, loss: 0.010656936094164848
step: 20, loss: 0.0005445043789222836
step: 30, loss: 0.0004206333542242646
step: 40, loss: 0.0029713294934481382
step: 50, loss: 0.06849368661642075
step: 60, loss: 0.00012548787344712764
step: 70, loss: 0.00017536561063025147
step: 80, loss: 0.0007164006237871945
step: 90, loss: 0.0002511451893951744
step: 100, loss: 0.006955166347324848
step: 110, loss: 0.0003952599363401532
step: 120, loss: 8.564497693441808e-05
step: 130, loss: 0.00042492817738093436
step: 140, loss: 0.0021172459237277508
step: 150, loss: 0.00026386193349026144
step: 160, loss: 0.000373921386199072
step: 170, loss: 0.00019243294082116336
step: 180, loss: 0.000354448682628572
step: 190, loss: 0.000648563145659864
step: 200, loss: 0.0016356451669707894
step: 210, loss: 0.008676194585859776
step: 220, loss: 0.0009674661559984088
step: 230, loss: 0.001050798804499209
step: 240, loss: 0.00545049924403429
step: 250, loss: 0.0009710309095680714
step: 260, loss: 0.0005980986170470715
step: 270, loss: 0.00012617219181265682
step: 280, loss: 0.0015118691371753812
step: 290, loss: 0.06423165649175644
step: 300, loss: 0.0015582881169393659
step: 310, loss: 0.0009131371625699103
step: 320, loss: 0.0011727410601451993
step: 330, loss: 0.005608314648270607
step: 340, loss: 0.00010734664829215035
step: 350, loss: 0.06833773851394653
step: 360, loss: 0.0005394620820879936
step: 370, loss: 0.0010693870717659593
step: 380, loss: 0.0005013635382056236
epoch 15: dev_f1=0.7790055248618786, f1=0.6018808777429467, best_f1=0.6788511749347258
step: 0, loss: 0.0007167447474785149
step: 10, loss: 0.0017015753546729684
step: 20, loss: 0.00019415869610384107
step: 30, loss: 0.00019430980319157243
step: 40, loss: 0.000476301705930382
step: 50, loss: 0.0001132302131736651
step: 60, loss: 0.003075876971706748
step: 70, loss: 5.326103564584628e-05
step: 80, loss: 8.808627899270505e-05
step: 90, loss: 0.06212038919329643
step: 100, loss: 0.0010445016669109464
step: 110, loss: 0.0005343231023289263
step: 120, loss: 0.0004674340889323503
step: 130, loss: 0.0006569296238012612
step: 140, loss: 0.0001730017684167251
step: 150, loss: 0.0006073919357731938
step: 160, loss: 0.0005899710231460631
step: 170, loss: 0.007081237155944109
step: 180, loss: 0.002958447439596057
step: 190, loss: 0.0015709371073171496
step: 200, loss: 0.0015031752409413457
step: 210, loss: 0.0008926254813559353
step: 220, loss: 0.010998766869306564
step: 230, loss: 0.017536906525492668
step: 240, loss: 0.0002121452707797289
step: 250, loss: 8.79355866345577e-05
step: 260, loss: 0.00044895970495417714
step: 270, loss: 0.0007368808728642762
step: 280, loss: 0.0017100453842431307
step: 290, loss: 0.0003884019679389894
step: 300, loss: 6.653182208538055e-05
step: 310, loss: 0.003301771357655525
step: 320, loss: 0.0019500714261084795
step: 330, loss: 0.0001919696369441226
step: 340, loss: 0.00011629641812760383
step: 350, loss: 0.0033269112464040518
step: 360, loss: 7.839475438231602e-05
step: 370, loss: 0.0014942828565835953
step: 380, loss: 0.00045104153105057776
epoch 16: dev_f1=0.7872340425531915, f1=0.633720930232558, best_f1=0.6788511749347258
step: 0, loss: 7.180763350334018e-05
step: 10, loss: 0.0008799451170489192
step: 20, loss: 0.005894436035305262
step: 30, loss: 0.0005425370181910694
step: 40, loss: 0.0021450468339025974
step: 50, loss: 0.0004053875745739788
step: 60, loss: 0.003802740713581443
step: 70, loss: 7.281313446583226e-05
step: 80, loss: 0.0011597747216001153
step: 90, loss: 0.0026202010922133923
step: 100, loss: 0.0019787573255598545
step: 110, loss: 0.0004755870904773474
step: 120, loss: 0.0006343569257296622
step: 130, loss: 0.018571332097053528
step: 140, loss: 0.002026776084676385
step: 150, loss: 0.00047351850662380457
step: 160, loss: 0.0005643084878101945
step: 170, loss: 0.002363478532060981
step: 180, loss: 6.796450907131657e-05
step: 190, loss: 0.0037310083862394094
step: 200, loss: 0.0004117910866625607
step: 210, loss: 0.0011611267691478133
step: 220, loss: 0.0012452179798856378
step: 230, loss: 8.294303552247584e-05
step: 240, loss: 0.0002676258736755699
step: 250, loss: 0.0010161123936995864
step: 260, loss: 8.286140655400231e-05
step: 270, loss: 0.0006806865567341447
step: 280, loss: 0.00015050987713038921
step: 290, loss: 0.0006437379634007812
step: 300, loss: 7.150074816308916e-05
step: 310, loss: 0.0004135100753046572
step: 320, loss: 0.0001856635935837403
step: 330, loss: 0.0003985714865848422
step: 340, loss: 0.003510124981403351
step: 350, loss: 0.0003493519907351583
step: 360, loss: 0.0003457093262113631
step: 370, loss: 0.001413334277458489
step: 380, loss: 0.001055194647051394
epoch 17: dev_f1=0.7906976744186047, f1=0.6379310344827587, best_f1=0.6788511749347258
step: 0, loss: 0.0010712884832173586
step: 10, loss: 0.005101323127746582
step: 20, loss: 0.0001731882948661223
step: 30, loss: 9.128513192990795e-05
step: 40, loss: 0.0017451338935643435
step: 50, loss: 0.00013108080020174384
step: 60, loss: 0.0002680598117876798
step: 70, loss: 0.0005369980935938656
step: 80, loss: 0.00025690929032862186
step: 90, loss: 0.00020872360619250685
step: 100, loss: 0.002107134787365794
step: 110, loss: 0.00015872585936449468
step: 120, loss: 0.0002201890165451914
step: 130, loss: 0.00018908936181105673
step: 140, loss: 0.00019399945449549705
step: 150, loss: 0.001100432826206088
step: 160, loss: 4.790837556356564e-05
step: 170, loss: 0.0001485643588239327
step: 180, loss: 0.00025948038091883063
step: 190, loss: 0.00010558359645074233
step: 200, loss: 0.000423206714913249
step: 210, loss: 5.3401352488435805e-05
step: 220, loss: 0.0005571353249251842
step: 230, loss: 0.0008175242692232132
step: 240, loss: 7.033324800431728e-05
step: 250, loss: 0.0010388478403910995
step: 260, loss: 0.025463810190558434
step: 270, loss: 0.002638577949255705
step: 280, loss: 0.0006123349885456264
step: 290, loss: 0.00028119009220972657
step: 300, loss: 0.0008646441274322569
step: 310, loss: 0.00013800534361507744
step: 320, loss: 0.00050605449359864
step: 330, loss: 0.00020814398885704577
step: 340, loss: 0.00010199692042078823
step: 350, loss: 0.0008271208498626947
step: 360, loss: 0.000315902812872082
step: 370, loss: 0.0008804160170257092
step: 380, loss: 0.00035870811552740633
epoch 18: dev_f1=0.7897435897435896, f1=0.6309859154929577, best_f1=0.6788511749347258
step: 0, loss: 0.0001198844620375894
step: 10, loss: 8.233791595557705e-05
step: 20, loss: 9.872978989733383e-05
step: 30, loss: 0.00019569831783883274
step: 40, loss: 0.00012506780331023037
step: 50, loss: 0.0003312881453894079
step: 60, loss: 0.0002723958750721067
step: 70, loss: 0.00017632018716540188
step: 80, loss: 0.0009235059260390699
step: 90, loss: 8.371840522158891e-05
step: 100, loss: 0.0005831844755448401
step: 110, loss: 0.00010899472545133904
step: 120, loss: 0.00019942010112572461
step: 130, loss: 0.00012598824105225503
step: 140, loss: 0.00012656024773605168
step: 150, loss: 0.00023740713368169963
step: 160, loss: 0.0005783640663139522
step: 170, loss: 4.8793182941153646e-05
step: 180, loss: 6.597700121346861e-05
step: 190, loss: 0.0002140137949027121
step: 200, loss: 3.909904989995994e-05
step: 210, loss: 0.00036127306520938873
step: 220, loss: 0.00012396203237585723
step: 230, loss: 0.00021781436225865036
step: 240, loss: 0.00047052549780346453
step: 250, loss: 0.011678921058773994
step: 260, loss: 0.0005067713791504502
step: 270, loss: 8.944128057919443e-05
step: 280, loss: 8.41325891087763e-05
step: 290, loss: 7.916928007034585e-05
step: 300, loss: 0.00525432825088501
step: 310, loss: 0.0004129493026994169
step: 320, loss: 0.00013056914031039923
step: 330, loss: 0.0016302005387842655
step: 340, loss: 0.00028952525462955236
step: 350, loss: 0.00023106027219910175
step: 360, loss: 0.0012290205340832472
step: 370, loss: 0.00027992017567157745
step: 380, loss: 0.00024260723148472607
epoch 19: dev_f1=0.7866323907455013, f1=0.6477272727272727, best_f1=0.6788511749347258
step: 0, loss: 0.0004392134433146566
step: 10, loss: 0.002823302522301674
step: 20, loss: 0.00017572303477209061
step: 30, loss: 5.738705294788815e-05
step: 40, loss: 4.804759373655543e-05
step: 50, loss: 9.543728083372116e-05
step: 60, loss: 0.00040749041363596916
step: 70, loss: 0.0001512576563982293
step: 80, loss: 4.679953781305812e-05
step: 90, loss: 0.029700256884098053
step: 100, loss: 0.00031685264548286796
step: 110, loss: 8.860143861966208e-05
step: 120, loss: 0.0014149454655125737
step: 130, loss: 8.185595652321354e-05
step: 140, loss: 7.692358485655859e-05
step: 150, loss: 0.00021246806136332452
step: 160, loss: 0.00024086626945063472
step: 170, loss: 0.0003622497897595167
step: 180, loss: 4.209754115436226e-05
step: 190, loss: 0.00015620302292518318
step: 200, loss: 4.747063576360233e-05
step: 210, loss: 0.0015392914647236466
step: 220, loss: 0.0002600481384433806
step: 230, loss: 0.00015433088992722332
step: 240, loss: 3.097493390669115e-05
step: 250, loss: 0.00019369211804587394
step: 260, loss: 0.0004545218253042549
step: 270, loss: 0.0002255877188872546
step: 280, loss: 6.889281212352216e-05
step: 290, loss: 0.0011749566765502095
step: 300, loss: 0.0016499519115313888
step: 310, loss: 0.0002577741106506437
step: 320, loss: 0.00018831330817192793
step: 330, loss: 0.007609859108924866
step: 340, loss: 0.0001156504949904047
step: 350, loss: 0.00038641312858089805
step: 360, loss: 0.0001778558798832819
step: 370, loss: 3.184290835633874e-05
step: 380, loss: 7.367072248598561e-05
epoch 20: dev_f1=0.7855297157622738, f1=0.6402266288951841, best_f1=0.6788511749347258
