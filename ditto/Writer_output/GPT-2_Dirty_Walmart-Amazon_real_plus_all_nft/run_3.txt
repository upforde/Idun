cuda
Device: cuda
step: 0, loss: 1.1226979494094849
step: 10, loss: 0.157085582613945
step: 20, loss: 0.313394695520401
step: 30, loss: 0.1700172871351242
step: 40, loss: 0.12878909707069397
step: 50, loss: 0.3059599995613098
step: 60, loss: 0.1992778778076172
step: 70, loss: 0.31327757239341736
step: 80, loss: 0.23582187294960022
step: 90, loss: 0.2333851456642151
step: 100, loss: 0.2295670509338379
step: 110, loss: 0.13726317882537842
step: 120, loss: 0.3823273777961731
step: 130, loss: 0.36817023158073425
step: 140, loss: 0.2525717616081238
step: 150, loss: 0.15891751646995544
step: 160, loss: 0.22191403806209564
step: 170, loss: 0.30203667283058167
step: 180, loss: 0.28331223130226135
step: 190, loss: 0.21782901883125305
step: 200, loss: 0.12687192857265472
step: 210, loss: 0.48209086060523987
step: 220, loss: 0.4865409731864929
step: 230, loss: 0.5371912121772766
step: 240, loss: 0.2613794505596161
step: 250, loss: 0.4149709641933441
step: 260, loss: 0.165619894862175
step: 270, loss: 0.2663881778717041
step: 280, loss: 0.21564719080924988
step: 290, loss: 0.3871433138847351
step: 300, loss: 0.20786944031715393
step: 310, loss: 0.3845422565937042
step: 320, loss: 0.20501424372196198
step: 330, loss: 0.24914821982383728
step: 340, loss: 0.29989850521087646
step: 350, loss: 0.4634052813053131
step: 360, loss: 0.21473132073879242
step: 370, loss: 0.2729554772377014
step: 380, loss: 0.27574944496154785
epoch 1: dev_f1=0.5943152454780362, f1=0.4776902887139108, best_f1=0.4776902887139108
step: 0, loss: 0.2541474997997284
step: 10, loss: 0.26126936078071594
step: 20, loss: 0.49976646900177
step: 30, loss: 0.11856997013092041
step: 40, loss: 0.08557701855897903
step: 50, loss: 0.7327666878700256
step: 60, loss: 0.0964202880859375
step: 70, loss: 0.37411606311798096
step: 80, loss: 0.20959383249282837
step: 90, loss: 0.14847710728645325
step: 100, loss: 0.2282554805278778
step: 110, loss: 0.17217400670051575
step: 120, loss: 0.2732320725917816
step: 130, loss: 0.1359052062034607
step: 140, loss: 0.1076447069644928
step: 150, loss: 0.14308291673660278
step: 160, loss: 0.3076995313167572
step: 170, loss: 0.29029548168182373
step: 180, loss: 0.19022303819656372
step: 190, loss: 0.2723149359226227
step: 200, loss: 0.3475821912288666
step: 210, loss: 0.24324698746204376
step: 220, loss: 0.08206992596387863
step: 230, loss: 0.1114068329334259
step: 240, loss: 0.23701848089694977
step: 250, loss: 0.34418049454689026
step: 260, loss: 0.22108496725559235
step: 270, loss: 0.1830858439207077
step: 280, loss: 0.052457261830568314
step: 290, loss: 0.12163642048835754
step: 300, loss: 0.23781448602676392
step: 310, loss: 0.414416640996933
step: 320, loss: 0.1275791972875595
step: 330, loss: 0.16868409514427185
step: 340, loss: 0.0750330239534378
step: 350, loss: 0.3432142734527588
step: 360, loss: 0.10403961688280106
step: 370, loss: 0.34727081656455994
step: 380, loss: 0.07864105701446533
epoch 2: dev_f1=0.6954177897574124, f1=0.4070796460176991, best_f1=0.4070796460176991
step: 0, loss: 0.1299683302640915
step: 10, loss: 0.2041751742362976
step: 20, loss: 0.1546923965215683
step: 30, loss: 0.01628522388637066
step: 40, loss: 0.1599138379096985
step: 50, loss: 0.17138823866844177
step: 60, loss: 0.20447669923305511
step: 70, loss: 0.04471238702535629
step: 80, loss: 0.08067649602890015
step: 90, loss: 0.15208402276039124
step: 100, loss: 0.05931105092167854
step: 110, loss: 0.10237675160169601
step: 120, loss: 0.11393354833126068
step: 130, loss: 0.09195365756750107
step: 140, loss: 0.06855980306863785
step: 150, loss: 0.09722038358449936
step: 160, loss: 0.05838790163397789
step: 170, loss: 0.0461290068924427
step: 180, loss: 0.12653811275959015
step: 190, loss: 0.1651313304901123
step: 200, loss: 0.059199996292591095
step: 210, loss: 0.12014473229646683
step: 220, loss: 0.20328009128570557
step: 230, loss: 0.13192296028137207
step: 240, loss: 0.5090311765670776
step: 250, loss: 0.23186315596103668
step: 260, loss: 0.12018632888793945
step: 270, loss: 0.13719385862350464
step: 280, loss: 0.0738508552312851
step: 290, loss: 0.19707827270030975
step: 300, loss: 0.13426467776298523
step: 310, loss: 0.1362171620130539
step: 320, loss: 0.25126174092292786
step: 330, loss: 0.1043388620018959
step: 340, loss: 0.12195109575986862
step: 350, loss: 0.19157497584819794
step: 360, loss: 0.16927063465118408
step: 370, loss: 0.08524639159440994
step: 380, loss: 0.04018048197031021
epoch 3: dev_f1=0.8053333333333333, f1=0.6348314606741573, best_f1=0.6348314606741573
step: 0, loss: 0.12677700817584991
step: 10, loss: 0.07051713764667511
step: 20, loss: 0.16337360441684723
step: 30, loss: 0.029763570055365562
step: 40, loss: 0.25417590141296387
step: 50, loss: 0.3090859353542328
step: 60, loss: 0.15155456960201263
step: 70, loss: 0.15117953717708588
step: 80, loss: 0.10211089998483658
step: 90, loss: 0.08345106989145279
step: 100, loss: 0.10032764822244644
step: 110, loss: 0.06785741448402405
step: 120, loss: 0.2212090939283371
step: 130, loss: 0.12135736644268036
step: 140, loss: 0.1312960535287857
step: 150, loss: 0.13415731489658356
step: 160, loss: 0.18566817045211792
step: 170, loss: 0.02726530283689499
step: 180, loss: 0.08071392774581909
step: 190, loss: 0.029552007094025612
step: 200, loss: 0.1372189074754715
step: 210, loss: 0.3354707360267639
step: 220, loss: 0.13138632476329803
step: 230, loss: 0.25008708238601685
step: 240, loss: 0.07095910608768463
step: 250, loss: 0.19986063241958618
step: 260, loss: 0.149643674492836
step: 270, loss: 0.32873809337615967
step: 280, loss: 0.1356155276298523
step: 290, loss: 0.13946570456027985
step: 300, loss: 0.1687515676021576
step: 310, loss: 0.04068581014871597
step: 320, loss: 0.19638898968696594
step: 330, loss: 0.17310547828674316
step: 340, loss: 0.045621637254953384
step: 350, loss: 0.14147083461284637
step: 360, loss: 0.03573914244771004
step: 370, loss: 0.10285258293151855
step: 380, loss: 0.17070096731185913
epoch 4: dev_f1=0.8043478260869565, f1=0.5443425076452599, best_f1=0.6348314606741573
step: 0, loss: 0.02134881541132927
step: 10, loss: 0.11575310677289963
step: 20, loss: 0.08413757383823395
step: 30, loss: 0.135509192943573
step: 40, loss: 0.08658260852098465
step: 50, loss: 0.02137213759124279
step: 60, loss: 0.05328432098031044
step: 70, loss: 0.02025509811937809
step: 80, loss: 0.09300035983324051
step: 90, loss: 0.039249058812856674
step: 100, loss: 0.05003136023879051
step: 110, loss: 0.23743993043899536
step: 120, loss: 0.025368377566337585
step: 130, loss: 0.014684668742120266
step: 140, loss: 0.05575961992144585
step: 150, loss: 0.12508811056613922
step: 160, loss: 0.1531158834695816
step: 170, loss: 0.1386997550725937
step: 180, loss: 0.1184668242931366
step: 190, loss: 0.1572510302066803
step: 200, loss: 0.047462236136198044
step: 210, loss: 0.10884363204240799
step: 220, loss: 0.1078881248831749
step: 230, loss: 0.08251526951789856
step: 240, loss: 0.11400792747735977
step: 250, loss: 0.23279781639575958
step: 260, loss: 0.15669690072536469
step: 270, loss: 0.2574041187763214
step: 280, loss: 0.07367617636919022
step: 290, loss: 0.20434053242206573
step: 300, loss: 0.14658856391906738
step: 310, loss: 0.08418247103691101
step: 320, loss: 0.23511245846748352
step: 330, loss: 0.013367662206292152
step: 340, loss: 0.04577590152621269
step: 350, loss: 0.07661877572536469
step: 360, loss: 0.20206423103809357
step: 370, loss: 0.027328282594680786
step: 380, loss: 0.025790013372898102
epoch 5: dev_f1=0.8, f1=0.5403726708074534, best_f1=0.6348314606741573
step: 0, loss: 0.02048666961491108
step: 10, loss: 0.07957235723733902
step: 20, loss: 0.05982712283730507
step: 30, loss: 0.013464264571666718
step: 40, loss: 0.04991818964481354
step: 50, loss: 0.10995479673147202
step: 60, loss: 0.07760966569185257
step: 70, loss: 0.0334896557033062
step: 80, loss: 0.013870707713067532
step: 90, loss: 0.02850508689880371
step: 100, loss: 0.03423367813229561
step: 110, loss: 0.01871691271662712
step: 120, loss: 0.11757635325193405
step: 130, loss: 0.05400240793824196
step: 140, loss: 0.07105670124292374
step: 150, loss: 0.19682152569293976
step: 160, loss: 0.009679468348622322
step: 170, loss: 0.12667164206504822
step: 180, loss: 0.030306877568364143
step: 190, loss: 0.005998336710035801
step: 200, loss: 0.008317342028021812
step: 210, loss: 0.015795251354575157
step: 220, loss: 0.01198014710098505
step: 230, loss: 0.09638305753469467
step: 240, loss: 0.037384551018476486
step: 250, loss: 0.048612743616104126
step: 260, loss: 0.06671988219022751
step: 270, loss: 0.0712280347943306
step: 280, loss: 0.13087378442287445
step: 290, loss: 0.011874889954924583
step: 300, loss: 0.03602731600403786
step: 310, loss: 0.004241742193698883
step: 320, loss: 0.07726401090621948
step: 330, loss: 0.02924877032637596
step: 340, loss: 0.028446922078728676
step: 350, loss: 0.038920093327760696
step: 360, loss: 0.048372961580753326
step: 370, loss: 0.12788838148117065
step: 380, loss: 0.10219129920005798
epoch 6: dev_f1=0.8177083333333333, f1=0.6227544910179642, best_f1=0.6227544910179642
step: 0, loss: 0.05206355080008507
step: 10, loss: 0.004413892515003681
step: 20, loss: 0.10042863339185715
step: 30, loss: 0.025233648717403412
step: 40, loss: 0.054682377725839615
step: 50, loss: 0.06712985783815384
step: 60, loss: 0.1186596155166626
step: 70, loss: 0.005831428803503513
step: 80, loss: 0.0783960148692131
step: 90, loss: 0.005357514135539532
step: 100, loss: 0.005348258186131716
step: 110, loss: 0.061809491366147995
step: 120, loss: 0.016223549842834473
step: 130, loss: 0.25296521186828613
step: 140, loss: 0.22825570404529572
step: 150, loss: 0.1380804181098938
step: 160, loss: 0.012593753635883331
step: 170, loss: 0.011109458282589912
step: 180, loss: 0.016471050679683685
step: 190, loss: 0.06604412198066711
step: 200, loss: 0.012830588035285473
step: 210, loss: 0.006528052035719156
step: 220, loss: 0.019765790551900864
step: 230, loss: 0.2141820192337036
step: 240, loss: 0.014376584440469742
step: 250, loss: 0.11156612634658813
step: 260, loss: 0.006770651787519455
step: 270, loss: 0.022746171802282333
step: 280, loss: 0.14416493475437164
step: 290, loss: 0.009698688052594662
step: 300, loss: 0.018415674567222595
step: 310, loss: 0.24594910442829132
step: 320, loss: 0.03728882968425751
step: 330, loss: 0.0303952693939209
step: 340, loss: 0.007952345535159111
step: 350, loss: 0.05282576009631157
step: 360, loss: 0.02040473185479641
step: 370, loss: 0.1732213795185089
step: 380, loss: 0.07826836407184601
epoch 7: dev_f1=0.8020565552699229, f1=0.6158357771260997, best_f1=0.6227544910179642
step: 0, loss: 0.06255979090929031
step: 10, loss: 0.010047783143818378
step: 20, loss: 0.012145640328526497
step: 30, loss: 0.048787400126457214
step: 40, loss: 0.009372495114803314
step: 50, loss: 0.022300710901618004
step: 60, loss: 0.015101660043001175
step: 70, loss: 0.022145573049783707
step: 80, loss: 0.011070838198065758
step: 90, loss: 0.003013066714629531
step: 100, loss: 0.015987848863005638
step: 110, loss: 0.00852497573941946
step: 120, loss: 0.10794135928153992
step: 130, loss: 0.002070849761366844
step: 140, loss: 0.021457772701978683
step: 150, loss: 0.02852538414299488
step: 160, loss: 0.007788664661347866
step: 170, loss: 0.06593481451272964
step: 180, loss: 0.007924826815724373
step: 190, loss: 0.033302005380392075
step: 200, loss: 0.005022308323532343
step: 210, loss: 0.04606811702251434
step: 220, loss: 0.02406623400747776
step: 230, loss: 0.004938163794577122
step: 240, loss: 0.015139743685722351
step: 250, loss: 0.0025725062005221844
step: 260, loss: 0.0036369566805660725
step: 270, loss: 0.023373402655124664
step: 280, loss: 0.04435204714536667
step: 290, loss: 0.09868097305297852
step: 300, loss: 0.03685925900936127
step: 310, loss: 0.05212835967540741
step: 320, loss: 0.14994825422763824
step: 330, loss: 0.003336638445034623
step: 340, loss: 0.001925228745676577
step: 350, loss: 0.013571654446423054
step: 360, loss: 0.0005699211615137756
step: 370, loss: 0.0035784104838967323
step: 380, loss: 0.002498443704098463
epoch 8: dev_f1=0.8184143222506393, f1=0.6253687315634219, best_f1=0.6253687315634219
step: 0, loss: 0.09181541204452515
step: 10, loss: 0.0013071062276139855
step: 20, loss: 0.0032946807332336903
step: 30, loss: 0.03010539337992668
step: 40, loss: 0.0015832940116524696
step: 50, loss: 0.0009266891865991056
step: 60, loss: 0.004123140126466751
step: 70, loss: 0.0018408168107271194
step: 80, loss: 0.004858090076595545
step: 90, loss: 0.006955056916922331
step: 100, loss: 0.005691044963896275
step: 110, loss: 0.042844370007514954
step: 120, loss: 0.0010741769801825285
step: 130, loss: 0.006699800956994295
step: 140, loss: 0.008366722613573074
step: 150, loss: 0.03174299746751785
step: 160, loss: 0.009647968225181103
step: 170, loss: 0.00141765340231359
step: 180, loss: 0.009466158226132393
step: 190, loss: 0.0035922566894441843
step: 200, loss: 0.009735818952322006
step: 210, loss: 0.0026333429850637913
step: 220, loss: 0.076055146753788
step: 230, loss: 0.03480171039700508
step: 240, loss: 0.012525366619229317
step: 250, loss: 0.0013824135530740023
step: 260, loss: 0.0488097220659256
step: 270, loss: 0.0009204663801938295
step: 280, loss: 0.026370113715529442
step: 290, loss: 0.005078847520053387
step: 300, loss: 0.011897686868906021
step: 310, loss: 0.02440180815756321
step: 320, loss: 0.0042500258423388
step: 330, loss: 0.0013014724245294929
step: 340, loss: 0.003711370751261711
step: 350, loss: 0.0015166671946644783
step: 360, loss: 0.031492963433265686
step: 370, loss: 0.007753687910735607
step: 380, loss: 0.04630421847105026
epoch 9: dev_f1=0.8, f1=0.6376021798365122, best_f1=0.6253687315634219
step: 0, loss: 0.004112519323825836
step: 10, loss: 0.0035863369703292847
step: 20, loss: 0.03166789561510086
step: 30, loss: 0.0017828232375904918
step: 40, loss: 0.002995043992996216
step: 50, loss: 0.0332505963742733
step: 60, loss: 0.0019295844249427319
step: 70, loss: 0.0003089727833867073
step: 80, loss: 0.0005193807301111519
step: 90, loss: 0.02532929554581642
step: 100, loss: 0.010128797963261604
step: 110, loss: 0.0020435680635273457
step: 120, loss: 0.02079266682267189
step: 130, loss: 0.0010053644655272365
step: 140, loss: 0.003014247864484787
step: 150, loss: 0.000789420388173312
step: 160, loss: 0.0020968534518033266
step: 170, loss: 0.0014827470295131207
step: 180, loss: 0.0017449998995289207
step: 190, loss: 0.13655073940753937
step: 200, loss: 0.0015914676478132606
step: 210, loss: 0.0035635256208479404
step: 220, loss: 0.000666261010337621
step: 230, loss: 0.11541545391082764
step: 240, loss: 0.023117391392588615
step: 250, loss: 0.11958959698677063
step: 260, loss: 0.005916069261729717
step: 270, loss: 0.0017872501630336046
step: 280, loss: 0.02203071303665638
step: 290, loss: 0.0005458458326756954
step: 300, loss: 0.00020884799596387893
step: 310, loss: 0.022903725504875183
step: 320, loss: 0.00939699076116085
step: 330, loss: 0.004079568665474653
step: 340, loss: 0.002991397399455309
step: 350, loss: 0.001740944804623723
step: 360, loss: 0.023683732375502586
step: 370, loss: 0.000693496607709676
step: 380, loss: 0.0012708837166428566
epoch 10: dev_f1=0.8136482939632546, f1=0.6409495548961425, best_f1=0.6253687315634219
step: 0, loss: 0.006983652710914612
step: 10, loss: 0.0027436274103820324
step: 20, loss: 0.0015936020063236356
step: 30, loss: 0.006254083011299372
step: 40, loss: 0.00036712142173200846
step: 50, loss: 0.0013986392877995968
step: 60, loss: 0.007623184937983751
step: 70, loss: 0.002258126623928547
step: 80, loss: 0.0012389218900352716
step: 90, loss: 0.0022060414776206017
step: 100, loss: 0.0015022681327536702
step: 110, loss: 0.029938045889139175
step: 120, loss: 0.00518218195065856
step: 130, loss: 0.0011976280948147178
step: 140, loss: 0.015835890546441078
step: 150, loss: 0.0005724593065679073
step: 160, loss: 0.11877085268497467
step: 170, loss: 0.0046723452396690845
step: 180, loss: 0.004007076844573021
step: 190, loss: 0.03939753770828247
step: 200, loss: 0.008596117608249187
step: 210, loss: 0.0003970597463194281
step: 220, loss: 0.0060068159364163876
step: 230, loss: 0.004128364846110344
step: 240, loss: 0.00242187874391675
step: 250, loss: 0.0030577864963561296
step: 260, loss: 0.02628796175122261
step: 270, loss: 0.0005232531111687422
step: 280, loss: 0.007861066609621048
step: 290, loss: 0.004789525177329779
step: 300, loss: 0.01841764897108078
step: 310, loss: 0.0037750203628093004
step: 320, loss: 0.00014712668780703098
step: 330, loss: 0.03925790265202522
step: 340, loss: 0.03791159391403198
step: 350, loss: 0.0038109971210360527
step: 360, loss: 0.09886643290519714
step: 370, loss: 0.005469931289553642
step: 380, loss: 0.001735192839987576
epoch 11: dev_f1=0.8021108179419525, f1=0.6097560975609756, best_f1=0.6253687315634219
step: 0, loss: 0.0007230946212075651
step: 10, loss: 0.007376454770565033
step: 20, loss: 0.0004853545979131013
step: 30, loss: 0.0029721141327172518
step: 40, loss: 0.05526699498295784
step: 50, loss: 0.002203580690547824
step: 60, loss: 0.000781892566010356
step: 70, loss: 0.000378355965949595
step: 80, loss: 0.0006840796559117734
step: 90, loss: 0.0005310794222168624
step: 100, loss: 0.0004092642047908157
step: 110, loss: 0.00016239761316683143
step: 120, loss: 0.01415372546762228
step: 130, loss: 0.0023602312430739403
step: 140, loss: 0.0020164723973721266
step: 150, loss: 0.02029331400990486
step: 160, loss: 0.001870851032435894
step: 170, loss: 0.007892318069934845
step: 180, loss: 0.0007010619738139212
step: 190, loss: 0.0006273864419199526
step: 200, loss: 0.00014134465891402215
step: 210, loss: 0.00010308076161891222
step: 220, loss: 0.0010122210951521993
step: 230, loss: 0.0002139122225344181
step: 240, loss: 0.025311937555670738
step: 250, loss: 0.0011820290237665176
step: 260, loss: 0.009309890680015087
step: 270, loss: 0.04882592707872391
step: 280, loss: 0.003990645986050367
step: 290, loss: 0.18223413825035095
step: 300, loss: 0.0008166320621967316
step: 310, loss: 0.0007642015116289258
step: 320, loss: 0.010319219902157784
step: 330, loss: 0.0034193838946521282
step: 340, loss: 0.003932537045329809
step: 350, loss: 0.0011893934570252895
step: 360, loss: 0.010022773407399654
step: 370, loss: 0.000534660299308598
step: 380, loss: 0.00022500468185171485
epoch 12: dev_f1=0.8010471204188483, f1=0.5914634146341464, best_f1=0.6253687315634219
step: 0, loss: 0.00020582915749400854
step: 10, loss: 0.0009902766905725002
step: 20, loss: 0.014193236827850342
step: 30, loss: 0.0006145152729004622
step: 40, loss: 0.002730894135311246
step: 50, loss: 0.0005422585527412593
step: 60, loss: 0.003464761422947049
step: 70, loss: 0.0007272273651324213
step: 80, loss: 0.018173135817050934
step: 90, loss: 0.0060454439371824265
step: 100, loss: 0.0035663216840475798
step: 110, loss: 0.003979658707976341
step: 120, loss: 0.011359743773937225
step: 130, loss: 0.0007100094808265567
step: 140, loss: 0.002004216890782118
step: 150, loss: 0.001040845294483006
step: 160, loss: 0.0009220530628226697
step: 170, loss: 0.018007872626185417
step: 180, loss: 0.0027409661561250687
step: 190, loss: 0.0011868654983118176
step: 200, loss: 0.015818312764167786
step: 210, loss: 0.0002624625922180712
step: 220, loss: 0.021929265931248665
step: 230, loss: 0.018905512988567352
step: 240, loss: 0.012139546684920788
step: 250, loss: 0.0022488387767225504
step: 260, loss: 0.00018160537001676857
step: 270, loss: 0.0009294402552768588
step: 280, loss: 0.00011000184895237908
step: 290, loss: 0.00015523475303780288
step: 300, loss: 0.0005045199650339782
step: 310, loss: 0.0246421005576849
step: 320, loss: 0.00016720792336855084
step: 330, loss: 0.0008054457721300423
step: 340, loss: 0.0007778239087201655
step: 350, loss: 0.0009796767262741923
step: 360, loss: 0.0002536579850129783
step: 370, loss: 0.0006027139024809003
step: 380, loss: 0.05706040561199188
epoch 13: dev_f1=0.7924528301886792, f1=0.5615141955835963, best_f1=0.6253687315634219
step: 0, loss: 0.0009209698182530701
step: 10, loss: 0.00024508897331543267
step: 20, loss: 0.00026776990853250027
step: 30, loss: 0.0012861762661486864
step: 40, loss: 0.002702070400118828
step: 50, loss: 0.0021559649612754583
step: 60, loss: 0.0004853995342273265
step: 70, loss: 0.0007187022129073739
step: 80, loss: 0.0001615458750165999
step: 90, loss: 0.0006763027049601078
step: 100, loss: 0.003192509524524212
step: 110, loss: 0.00043720946996472776
step: 120, loss: 0.0009755189530551434
step: 130, loss: 0.0018459175480529666
step: 140, loss: 0.09989319741725922
step: 150, loss: 8.848042489262298e-05
step: 160, loss: 0.000253358855843544
step: 170, loss: 0.07425615936517715
step: 180, loss: 0.00016564819088671356
step: 190, loss: 0.0010567643912509084
step: 200, loss: 0.0005445354036055505
step: 210, loss: 0.00018211935821454972
step: 220, loss: 0.00019660814723465592
step: 230, loss: 0.044196512550115585
step: 240, loss: 0.0025730589404702187
step: 250, loss: 0.012948627583682537
step: 260, loss: 0.003401445224881172
step: 270, loss: 0.0018843187717720866
step: 280, loss: 0.011334922164678574
step: 290, loss: 0.0033660943154245615
step: 300, loss: 0.0015884119784459472
step: 310, loss: 0.0018124619964510202
step: 320, loss: 0.001502640312537551
step: 330, loss: 0.002623050007969141
step: 340, loss: 0.001362248556688428
step: 350, loss: 0.001284889760427177
step: 360, loss: 0.0005149306380189955
step: 370, loss: 0.026435205712914467
step: 380, loss: 0.0065284064039587975
epoch 14: dev_f1=0.7968337730870713, f1=0.5896656534954406, best_f1=0.6253687315634219
step: 0, loss: 0.00035222017322666943
step: 10, loss: 0.0009898702846840024
step: 20, loss: 0.0003645288525149226
step: 30, loss: 0.0028619063086807728
step: 40, loss: 0.0017589775379747152
step: 50, loss: 0.0005572119262069464
step: 60, loss: 0.00025499335606582463
step: 70, loss: 0.009529968723654747
step: 80, loss: 0.0022462238557636738
step: 90, loss: 0.0014495077775791287
step: 100, loss: 0.001396172447130084
step: 110, loss: 0.00033084029564633965
step: 120, loss: 0.0006359150866046548
step: 130, loss: 0.0004528662539087236
step: 140, loss: 0.029061470180749893
step: 150, loss: 0.013832920230925083
step: 160, loss: 0.0014124619774520397
step: 170, loss: 0.03884713351726532
step: 180, loss: 0.0029550029430538416
step: 190, loss: 0.00012484150647651404
step: 200, loss: 0.0009020816651172936
step: 210, loss: 0.0008300471818074584
step: 220, loss: 0.0004190979234408587
step: 230, loss: 0.0017281065229326487
step: 240, loss: 0.0022106291726231575
step: 250, loss: 0.004619065672159195
step: 260, loss: 0.0007120046066120267
step: 270, loss: 0.0003102936316281557
step: 280, loss: 0.014305690303444862
step: 290, loss: 0.0005535667878575623
step: 300, loss: 0.0006410991190932691
step: 310, loss: 0.0001850856060627848
step: 320, loss: 0.004252423066645861
step: 330, loss: 0.0009763915440998971
step: 340, loss: 0.0009420659043826163
step: 350, loss: 0.001353982137516141
step: 360, loss: 0.00033102877205237746
step: 370, loss: 0.00023815561144147068
step: 380, loss: 0.00021772485342808068
epoch 15: dev_f1=0.8050632911392406, f1=0.6131805157593123, best_f1=0.6253687315634219
step: 0, loss: 0.00047191514750011265
step: 10, loss: 0.0029323180206120014
step: 20, loss: 0.0004511109727900475
step: 30, loss: 0.00031742776627652347
step: 40, loss: 0.0003290965687483549
step: 50, loss: 0.0012229389976710081
step: 60, loss: 0.0002570577780716121
step: 70, loss: 5.120494097354822e-05
step: 80, loss: 0.0005565572646446526
step: 90, loss: 0.00043740280671045184
step: 100, loss: 0.0016209996538236737
step: 110, loss: 0.0005802190280519426
step: 120, loss: 0.0003537540615070611
step: 130, loss: 0.000730749627109617
step: 140, loss: 0.0010889183031395078
step: 150, loss: 0.0005321491044014692
step: 160, loss: 0.000257774576311931
step: 170, loss: 0.0005648582591675222
step: 180, loss: 0.00017141956777777523
step: 190, loss: 0.00773556949570775
step: 200, loss: 0.0006216943729668856
step: 210, loss: 0.001324777607806027
step: 220, loss: 0.00048256301670335233
step: 230, loss: 0.0018754173070192337
step: 240, loss: 6.846411270089447e-05
step: 250, loss: 0.0006073926924727857
step: 260, loss: 0.00013274831871967763
step: 270, loss: 0.000118511903565377
step: 280, loss: 0.003045987570658326
step: 290, loss: 0.0825774222612381
step: 300, loss: 0.0003069868835154921
step: 310, loss: 0.0002251439291285351
step: 320, loss: 0.0003543476341292262
step: 330, loss: 0.0013266875175759196
step: 340, loss: 0.00011722510680556297
step: 350, loss: 0.003550556255504489
step: 360, loss: 0.001122264307923615
step: 370, loss: 0.00010401742474641651
step: 380, loss: 0.0003735792706720531
epoch 16: dev_f1=0.8157894736842105, f1=0.5773809523809523, best_f1=0.6253687315634219
step: 0, loss: 0.001355582382529974
step: 10, loss: 0.00026253354735672474
step: 20, loss: 6.849074998172e-05
step: 30, loss: 0.0008081849082373083
step: 40, loss: 0.00026766571681946516
step: 50, loss: 0.004410513211041689
step: 60, loss: 0.0002853257756214589
step: 70, loss: 7.234824443003163e-05
step: 80, loss: 6.482455501100048e-05
step: 90, loss: 0.012040522880852222
step: 100, loss: 0.00012870148930232972
step: 110, loss: 0.00012029044592054561
step: 120, loss: 0.00010331906378269196
step: 130, loss: 0.00019875886209774762
step: 140, loss: 0.0003948757366742939
step: 150, loss: 0.0006057589198462665
step: 160, loss: 9.898384450934827e-05
step: 170, loss: 7.654039654880762e-05
step: 180, loss: 0.0002489235484972596
step: 190, loss: 0.000168341095559299
step: 200, loss: 0.000404854683438316
step: 210, loss: 7.232889765873551e-05
step: 220, loss: 0.00043875639676116407
step: 230, loss: 7.716995605733246e-05
step: 240, loss: 0.0001773207332007587
step: 250, loss: 6.526668585138395e-05
step: 260, loss: 0.00025863826158456504
step: 270, loss: 0.00013382890028879046
step: 280, loss: 0.000255629129242152
step: 290, loss: 0.00017702518380247056
step: 300, loss: 0.00119600142352283
step: 310, loss: 0.001083677401766181
step: 320, loss: 0.00036312194424681365
step: 330, loss: 0.0008085870649665594
step: 340, loss: 0.0011302653001621366
step: 350, loss: 0.00044634920777752995
step: 360, loss: 0.0021216371096670628
step: 370, loss: 0.0003516470023896545
step: 380, loss: 0.0016515760216861963
epoch 17: dev_f1=0.8110831234256927, f1=0.6481994459833795, best_f1=0.6253687315634219
step: 0, loss: 0.00032701590680517256
step: 10, loss: 0.00041653154767118394
step: 20, loss: 0.0005645338096655905
step: 30, loss: 0.0003343750722706318
step: 40, loss: 0.000248185358941555
step: 50, loss: 0.00016364212206099182
step: 60, loss: 0.0001254282979061827
step: 70, loss: 0.012968044728040695
step: 80, loss: 0.001729072886519134
step: 90, loss: 0.00012874319509137422
step: 100, loss: 0.0030558560974895954
step: 110, loss: 0.00022561551304534078
step: 120, loss: 0.00920442771166563
step: 130, loss: 0.0006079229060560465
step: 140, loss: 0.0003034744877368212
step: 150, loss: 0.001140515087172389
step: 160, loss: 0.00017132602806668729
step: 170, loss: 0.00010305052273906767
step: 180, loss: 0.0005892083281651139
step: 190, loss: 0.00010638903040671721
step: 200, loss: 0.00046360655687749386
step: 210, loss: 0.00014118450053501874
step: 220, loss: 0.000506290583871305
step: 230, loss: 0.0002006969734793529
step: 240, loss: 0.007114638574421406
step: 250, loss: 0.0002926777524407953
step: 260, loss: 0.0002001658285735175
step: 270, loss: 0.000350717717083171
step: 280, loss: 0.00011849420116050169
step: 290, loss: 0.00015877802798058838
step: 300, loss: 0.00035522726830095053
step: 310, loss: 0.00033412661287002265
step: 320, loss: 3.78434378944803e-05
step: 330, loss: 0.001642330433242023
step: 340, loss: 8.407541463384405e-05
step: 350, loss: 9.604556544218212e-05
step: 360, loss: 0.00023414245515596122
step: 370, loss: 0.0012589679099619389
step: 380, loss: 0.00010736149124568328
epoch 18: dev_f1=0.8125, f1=0.6279069767441862, best_f1=0.6253687315634219
step: 0, loss: 0.00037481897743418813
step: 10, loss: 0.0001805658102966845
step: 20, loss: 0.0002366220869589597
step: 30, loss: 0.00016132155724335462
step: 40, loss: 5.893872366868891e-05
step: 50, loss: 4.828000601264648e-05
step: 60, loss: 0.00012930232333019376
step: 70, loss: 0.0004229828482493758
step: 80, loss: 0.00010242317512165755
step: 90, loss: 0.0003779671969823539
step: 100, loss: 0.0004187950398772955
step: 110, loss: 0.00012347125448286533
step: 120, loss: 0.00016294473607558757
step: 130, loss: 0.007127473130822182
step: 140, loss: 0.0002586276095826179
step: 150, loss: 5.1781411457341164e-05
step: 160, loss: 0.0006559136672876775
step: 170, loss: 8.914554200600833e-05
step: 180, loss: 0.0004306377377361059
step: 190, loss: 0.006228015758097172
step: 200, loss: 0.000145716083352454
step: 210, loss: 0.00011928085586987436
step: 220, loss: 0.0016648308373987675
step: 230, loss: 0.003471922595053911
step: 240, loss: 0.00045615009730681777
step: 250, loss: 0.001363055082038045
step: 260, loss: 0.00015041786537040025
step: 270, loss: 8.639439329272136e-05
step: 280, loss: 0.0002550682402215898
step: 290, loss: 0.0001729833020363003
step: 300, loss: 0.0001563971018185839
step: 310, loss: 0.00012062565656378865
step: 320, loss: 0.00022611586609855294
step: 330, loss: 0.00011266474757576361
step: 340, loss: 0.00012305486598052084
step: 350, loss: 0.00017516087973490357
step: 360, loss: 0.00020600248535629362
step: 370, loss: 0.0003429876232985407
step: 380, loss: 0.00010471091081853956
epoch 19: dev_f1=0.8103896103896104, f1=0.632183908045977, best_f1=0.6253687315634219
step: 0, loss: 0.0012210604036226869
step: 10, loss: 3.569455293472856e-05
step: 20, loss: 0.00010256107634631917
step: 30, loss: 9.764407150214538e-05
step: 40, loss: 7.31775289750658e-05
step: 50, loss: 0.0001214757066918537
step: 60, loss: 0.10737679898738861
step: 70, loss: 7.364174962276593e-05
step: 80, loss: 0.00012726527347695082
step: 90, loss: 0.0005326308310031891
step: 100, loss: 5.1282990170875564e-05
step: 110, loss: 0.00014105286390986294
step: 120, loss: 7.382675539702177e-05
step: 130, loss: 8.255668944912031e-05
step: 140, loss: 0.048102039843797684
step: 150, loss: 6.298476364463568e-05
step: 160, loss: 0.00020079601381439716
step: 170, loss: 0.0001710441429167986
step: 180, loss: 0.05002867430448532
step: 190, loss: 0.0002132457448169589
step: 200, loss: 0.0001078135464922525
step: 210, loss: 0.00028309019398875535
step: 220, loss: 0.00010512213339097798
step: 230, loss: 0.000812297803349793
step: 240, loss: 0.0008670326787978411
step: 250, loss: 0.028836796060204506
step: 260, loss: 7.240538252517581e-05
step: 270, loss: 7.927793194539845e-05
step: 280, loss: 6.196869071573019e-05
step: 290, loss: 0.0006327390437945724
step: 300, loss: 6.354796641971916e-05
step: 310, loss: 0.00011964502482442185
step: 320, loss: 0.000221174574107863
step: 330, loss: 0.00017783396469894797
step: 340, loss: 0.0002448582381475717
step: 350, loss: 0.0001152194818132557
step: 360, loss: 0.00020091209444217384
step: 370, loss: 0.00011394441389711574
step: 380, loss: 0.00010210197069682181
epoch 20: dev_f1=0.8132992327365729, f1=0.6495726495726496, best_f1=0.6253687315634219
