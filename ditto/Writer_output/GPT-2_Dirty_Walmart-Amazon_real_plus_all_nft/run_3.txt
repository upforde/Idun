cuda
Device: cuda
step: 0, loss: 0.6650329828262329
step: 10, loss: 0.3193863034248352
step: 20, loss: 0.1718011200428009
step: 30, loss: 0.1456182450056076
step: 40, loss: 0.3905232548713684
step: 50, loss: 0.42164039611816406
step: 60, loss: 0.29409563541412354
step: 70, loss: 0.23676767945289612
step: 80, loss: 0.3778650462627411
step: 90, loss: 0.3102361559867859
step: 100, loss: 0.26009348034858704
step: 110, loss: 0.20107881724834442
step: 120, loss: 0.400241494178772
step: 130, loss: 0.2143249213695526
step: 140, loss: 0.36137908697128296
step: 150, loss: 0.12273987382650375
step: 160, loss: 0.3666837513446808
step: 170, loss: 0.22102844715118408
step: 180, loss: 0.3741031289100647
step: 190, loss: 0.23130130767822266
step: 200, loss: 0.2880633771419525
step: 210, loss: 0.2870379388332367
step: 220, loss: 0.1928260177373886
step: 230, loss: 0.30943238735198975
step: 240, loss: 0.47658443450927734
step: 250, loss: 0.4688396751880646
step: 260, loss: 0.3115586042404175
step: 270, loss: 0.34384989738464355
step: 280, loss: 0.3754364252090454
step: 290, loss: 0.250387966632843
step: 300, loss: 0.19190236926078796
step: 310, loss: 0.24933715164661407
step: 320, loss: 0.10645560920238495
step: 330, loss: 0.3714474141597748
step: 340, loss: 0.3425821363925934
step: 350, loss: 0.1575622707605362
step: 360, loss: 0.2734929025173187
step: 370, loss: 0.1662811040878296
step: 380, loss: 0.22273312509059906
epoch 1: dev_f1=0.5714285714285715, f1=0.45176470588235296, best_f1=0.45176470588235296
step: 0, loss: 0.1846887618303299
step: 10, loss: 0.36273807287216187
step: 20, loss: 0.15332575142383575
step: 30, loss: 0.1110326275229454
step: 40, loss: 0.22756579518318176
step: 50, loss: 0.3458636403083801
step: 60, loss: 0.3368466794490814
step: 70, loss: 0.24142639338970184
step: 80, loss: 0.1653326451778412
step: 90, loss: 0.20541687309741974
step: 100, loss: 0.303151398897171
step: 110, loss: 0.21746382117271423
step: 120, loss: 0.13143689930438995
step: 130, loss: 0.17390607297420502
step: 140, loss: 0.2547115683555603
step: 150, loss: 0.1721906214952469
step: 160, loss: 0.042159147560596466
step: 170, loss: 0.33032265305519104
step: 180, loss: 0.15699928998947144
step: 190, loss: 0.27131783962249756
step: 200, loss: 0.33724018931388855
step: 210, loss: 0.2283017486333847
step: 220, loss: 0.1393870860338211
step: 230, loss: 0.11023075878620148
step: 240, loss: 0.24503618478775024
step: 250, loss: 0.19207027554512024
step: 260, loss: 0.13371914625167847
step: 270, loss: 0.25145983695983887
step: 280, loss: 0.1209801509976387
step: 290, loss: 0.107369065284729
step: 300, loss: 0.2544570863246918
step: 310, loss: 0.29406556487083435
step: 320, loss: 0.15272396802902222
step: 330, loss: 0.2346704602241516
step: 340, loss: 0.05627092346549034
step: 350, loss: 0.13764195144176483
step: 360, loss: 0.21005426347255707
step: 370, loss: 0.11307690292596817
step: 380, loss: 0.1079588308930397
epoch 2: dev_f1=0.7582417582417582, f1=0.5222551928783383, best_f1=0.5222551928783383
step: 0, loss: 0.06749394536018372
step: 10, loss: 0.21574245393276215
step: 20, loss: 0.20036347210407257
step: 30, loss: 0.219643697142601
step: 40, loss: 0.06998509168624878
step: 50, loss: 0.18495234847068787
step: 60, loss: 0.2738853693008423
step: 70, loss: 0.2298726886510849
step: 80, loss: 0.05470537766814232
step: 90, loss: 0.13644248247146606
step: 100, loss: 0.03808894008398056
step: 110, loss: 0.10287158936262131
step: 120, loss: 0.11038747429847717
step: 130, loss: 0.21513834595680237
step: 140, loss: 0.43235042691230774
step: 150, loss: 0.09609608352184296
step: 160, loss: 0.11597353219985962
step: 170, loss: 0.17650583386421204
step: 180, loss: 0.05508149787783623
step: 190, loss: 0.20026567578315735
step: 200, loss: 0.19325341284275055
step: 210, loss: 0.19525045156478882
step: 220, loss: 0.5314417481422424
step: 230, loss: 0.09425537288188934
step: 240, loss: 0.09523618966341019
step: 250, loss: 0.08701607584953308
step: 260, loss: 0.26489925384521484
step: 270, loss: 0.22820410132408142
step: 280, loss: 0.08518873900175095
step: 290, loss: 0.11327075958251953
step: 300, loss: 0.13604816794395447
step: 310, loss: 0.20192334055900574
step: 320, loss: 0.07543585449457169
step: 330, loss: 0.1488885134458542
step: 340, loss: 0.15900734066963196
step: 350, loss: 0.11271671205759048
step: 360, loss: 0.2692520022392273
step: 370, loss: 0.04958934336900711
step: 380, loss: 0.06566589325666428
epoch 3: dev_f1=0.7880434782608696, f1=0.5278592375366568, best_f1=0.5278592375366568
step: 0, loss: 0.14800308644771576
step: 10, loss: 0.05622192844748497
step: 20, loss: 0.04145411029458046
step: 30, loss: 0.20104096829891205
step: 40, loss: 0.2370077222585678
step: 50, loss: 0.15273112058639526
step: 60, loss: 0.07859057933092117
step: 70, loss: 0.08716857433319092
step: 80, loss: 0.1714559644460678
step: 90, loss: 0.08048307150602341
step: 100, loss: 0.0034876042045652866
step: 110, loss: 0.12234009057283401
step: 120, loss: 0.13632962107658386
step: 130, loss: 0.03078739531338215
step: 140, loss: 0.09542697668075562
step: 150, loss: 0.12479673326015472
step: 160, loss: 0.12648919224739075
step: 170, loss: 0.20197756588459015
step: 180, loss: 0.053943172097206116
step: 190, loss: 0.1127522736787796
step: 200, loss: 0.008221893571317196
step: 210, loss: 0.09566570073366165
step: 220, loss: 0.08755593746900558
step: 230, loss: 0.16557472944259644
step: 240, loss: 0.020580830052495003
step: 250, loss: 0.022047603502869606
step: 260, loss: 0.194520503282547
step: 270, loss: 0.150038942694664
step: 280, loss: 0.024126868695020676
step: 290, loss: 0.19458246231079102
step: 300, loss: 0.0961819589138031
step: 310, loss: 0.07547717541456223
step: 320, loss: 0.15967951714992523
step: 330, loss: 0.10980663448572159
step: 340, loss: 0.10923528671264648
step: 350, loss: 0.12476830929517746
step: 360, loss: 0.014575319364666939
step: 370, loss: 0.13696664571762085
step: 380, loss: 0.2441079467535019
epoch 4: dev_f1=0.7753086419753086, f1=0.5833333333333333, best_f1=0.5278592375366568
step: 0, loss: 0.02995692752301693
step: 10, loss: 0.08852724730968475
step: 20, loss: 0.00773002952337265
step: 30, loss: 0.015339476987719536
step: 40, loss: 0.022150808945298195
step: 50, loss: 0.028417613357305527
step: 60, loss: 0.08211454749107361
step: 70, loss: 0.046184662729501724
step: 80, loss: 0.006172655615955591
step: 90, loss: 0.12061246484518051
step: 100, loss: 0.11050713062286377
step: 110, loss: 0.044272635132074356
step: 120, loss: 0.014071525074541569
step: 130, loss: 0.15913617610931396
step: 140, loss: 0.24658411741256714
step: 150, loss: 0.0028232084587216377
step: 160, loss: 0.028601760044693947
step: 170, loss: 0.1730247139930725
step: 180, loss: 0.061534423381090164
step: 190, loss: 0.058969657868146896
step: 200, loss: 0.03987083211541176
step: 210, loss: 0.13301683962345123
step: 220, loss: 0.04175962507724762
step: 230, loss: 0.04874654859304428
step: 240, loss: 0.04401782155036926
step: 250, loss: 0.0045853182673454285
step: 260, loss: 0.28083592653274536
step: 270, loss: 0.013952582143247128
step: 280, loss: 0.06922424584627151
step: 290, loss: 0.05127396062016487
step: 300, loss: 0.08606907725334167
step: 310, loss: 0.09695181250572205
step: 320, loss: 0.13412870466709137
step: 330, loss: 0.06864216178655624
step: 340, loss: 0.0060577006079256535
step: 350, loss: 0.039707545191049576
step: 360, loss: 0.021259788423776627
step: 370, loss: 0.042131539434194565
step: 380, loss: 0.07822711765766144
epoch 5: dev_f1=0.7780678851174935, f1=0.5389221556886228, best_f1=0.5278592375366568
step: 0, loss: 0.06510671973228455
step: 10, loss: 0.2552236318588257
step: 20, loss: 0.061911147087812424
step: 30, loss: 0.07657695561647415
step: 40, loss: 0.0027796768117696047
step: 50, loss: 0.11464440077543259
step: 60, loss: 0.14000655710697174
step: 70, loss: 0.06163106858730316
step: 80, loss: 0.035594772547483444
step: 90, loss: 0.007726018782705069
step: 100, loss: 0.06282766163349152
step: 110, loss: 0.17727507650852203
step: 120, loss: 0.06074690818786621
step: 130, loss: 0.013661044649779797
step: 140, loss: 0.008617742918431759
step: 150, loss: 0.07624698430299759
step: 160, loss: 0.04112336039543152
step: 170, loss: 0.003778145182877779
step: 180, loss: 0.09901993721723557
step: 190, loss: 0.013931523077189922
step: 200, loss: 0.19656401872634888
step: 210, loss: 0.05935792997479439
step: 220, loss: 0.044929467141628265
step: 230, loss: 0.07928750663995743
step: 240, loss: 0.0061391605995595455
step: 250, loss: 0.03507934883236885
step: 260, loss: 0.0641540065407753
step: 270, loss: 0.019265953451395035
step: 280, loss: 0.0427299328148365
step: 290, loss: 0.007801863830536604
step: 300, loss: 0.07356644421815872
step: 310, loss: 0.02664264477789402
step: 320, loss: 0.0021345089189708233
step: 330, loss: 0.16969192028045654
step: 340, loss: 0.05678392946720123
step: 350, loss: 0.0222073532640934
step: 360, loss: 0.012043753638863564
step: 370, loss: 0.022066576406359673
step: 380, loss: 0.022562386468052864
epoch 6: dev_f1=0.7828282828282827, f1=0.5698630136986302, best_f1=0.5278592375366568
step: 0, loss: 0.09986696392297745
step: 10, loss: 0.16132387518882751
step: 20, loss: 0.012924011796712875
step: 30, loss: 0.036810439079999924
step: 40, loss: 0.014249034225940704
step: 50, loss: 0.027196643874049187
step: 60, loss: 0.002724821912124753
step: 70, loss: 0.007415257394313812
step: 80, loss: 0.07786126434803009
step: 90, loss: 0.008368813432753086
step: 100, loss: 0.007984345778822899
step: 110, loss: 0.0234677754342556
step: 120, loss: 0.11938650906085968
step: 130, loss: 0.0008113370859064162
step: 140, loss: 0.015443609096109867
step: 150, loss: 0.02212386764585972
step: 160, loss: 0.026186281815171242
step: 170, loss: 0.004051249474287033
step: 180, loss: 0.03297600522637367
step: 190, loss: 0.07589005678892136
step: 200, loss: 0.2179533690214157
step: 210, loss: 0.12893235683441162
step: 220, loss: 0.12315226346254349
step: 230, loss: 0.03822062909603119
step: 240, loss: 0.015627438202500343
step: 250, loss: 0.06789928674697876
step: 260, loss: 0.018508465960621834
step: 270, loss: 0.05571432039141655
step: 280, loss: 0.005550932604819536
step: 290, loss: 0.023796096444129944
step: 300, loss: 0.007326483726501465
step: 310, loss: 0.04228479415178299
step: 320, loss: 0.003043662989512086
step: 330, loss: 0.002999548800289631
step: 340, loss: 0.00771685317158699
step: 350, loss: 0.21459540724754333
step: 360, loss: 0.046371616423130035
step: 370, loss: 0.01800241880118847
step: 380, loss: 0.0034449801314622164
epoch 7: dev_f1=0.7828418230563003, f1=0.5077399380804954, best_f1=0.5278592375366568
step: 0, loss: 0.012537452392280102
step: 10, loss: 0.03829001635313034
step: 20, loss: 0.0012250271392986178
step: 30, loss: 0.023966271430253983
step: 40, loss: 0.019026048481464386
step: 50, loss: 0.02751311846077442
step: 60, loss: 0.12265122681856155
step: 70, loss: 0.07871189713478088
step: 80, loss: 0.0016346379416063428
step: 90, loss: 0.004017741419374943
step: 100, loss: 0.0025323776062577963
step: 110, loss: 0.0005052538472227752
step: 120, loss: 0.1867179572582245
step: 130, loss: 0.03326939046382904
step: 140, loss: 0.050559572875499725
step: 150, loss: 0.019482754170894623
step: 160, loss: 0.035403359681367874
step: 170, loss: 0.10744116455316544
step: 180, loss: 0.007937428541481495
step: 190, loss: 0.0010347209172323346
step: 200, loss: 0.0012670285068452358
step: 210, loss: 0.022069083526730537
step: 220, loss: 0.004252238664776087
step: 230, loss: 0.0033471586648374796
step: 240, loss: 0.001608342514373362
step: 250, loss: 0.0036532741505652666
step: 260, loss: 0.16252097487449646
step: 270, loss: 0.0106841204687953
step: 280, loss: 0.0038468423299491405
step: 290, loss: 0.006736519746482372
step: 300, loss: 0.004938291385769844
step: 310, loss: 0.057607077062129974
step: 320, loss: 0.030539387837052345
step: 330, loss: 0.0015059462748467922
step: 340, loss: 0.10039665549993515
step: 350, loss: 0.0031868619844317436
step: 360, loss: 0.06861038506031036
step: 370, loss: 0.0028931042179465294
step: 380, loss: 0.01081889308989048
epoch 8: dev_f1=0.7989690721649483, f1=0.6084507042253521, best_f1=0.6084507042253521
step: 0, loss: 0.026114439591765404
step: 10, loss: 0.02630329690873623
step: 20, loss: 0.025579290464520454
step: 30, loss: 0.0006484017358161509
step: 40, loss: 0.009191312827169895
step: 50, loss: 0.00034126665559597313
step: 60, loss: 0.002409040229395032
step: 70, loss: 0.003412845777347684
step: 80, loss: 0.017962051555514336
step: 90, loss: 0.0004277181869838387
step: 100, loss: 0.0037022733595222235
step: 110, loss: 0.004276110790669918
step: 120, loss: 0.0011319898767396808
step: 130, loss: 0.044055160135030746
step: 140, loss: 0.08092339336872101
step: 150, loss: 0.0056235892698168755
step: 160, loss: 0.000597570848185569
step: 170, loss: 0.0008751173154450953
step: 180, loss: 0.021667039021849632
step: 190, loss: 0.00046993992873467505
step: 200, loss: 0.00306314742192626
step: 210, loss: 0.00016022346972022206
step: 220, loss: 0.05476030707359314
step: 230, loss: 0.002647456480190158
step: 240, loss: 0.0006470289663411677
step: 250, loss: 0.0885111540555954
step: 260, loss: 0.0024592590052634478
step: 270, loss: 0.017072683200240135
step: 280, loss: 0.003410357516258955
step: 290, loss: 0.02864123322069645
step: 300, loss: 0.003652875078842044
step: 310, loss: 0.031215406954288483
step: 320, loss: 0.03837943077087402
step: 330, loss: 0.05428403243422508
step: 340, loss: 0.003993123769760132
step: 350, loss: 0.002546470845118165
step: 360, loss: 0.0022934172302484512
step: 370, loss: 0.004566156305372715
step: 380, loss: 0.0004620703693944961
epoch 9: dev_f1=0.784, f1=0.5238095238095238, best_f1=0.6084507042253521
step: 0, loss: 0.03153518587350845
step: 10, loss: 0.000878816528711468
step: 20, loss: 0.01129027921706438
step: 30, loss: 0.07666125893592834
step: 40, loss: 0.07426470518112183
step: 50, loss: 0.0211909431964159
step: 60, loss: 0.019444547593593597
step: 70, loss: 0.05371212586760521
step: 80, loss: 0.011791477911174297
step: 90, loss: 0.021680010482668877
step: 100, loss: 0.0035670120269060135
step: 110, loss: 0.0085895461961627
step: 120, loss: 0.0004488384583964944
step: 130, loss: 0.0548817403614521
step: 140, loss: 0.08748245984315872
step: 150, loss: 0.12009052187204361
step: 160, loss: 0.11721986532211304
step: 170, loss: 0.005994748789817095
step: 180, loss: 0.04062534496188164
step: 190, loss: 0.0019674785435199738
step: 200, loss: 0.021975768730044365
step: 210, loss: 0.04590266942977905
step: 220, loss: 0.008802046068012714
step: 230, loss: 0.03298281133174896
step: 240, loss: 0.025944309309124947
step: 250, loss: 0.0009398324182257056
step: 260, loss: 0.014054517261683941
step: 270, loss: 0.004772551823407412
step: 280, loss: 0.004679654259234667
step: 290, loss: 0.0004282822192180902
step: 300, loss: 0.02456570230424404
step: 310, loss: 0.0005490012699738145
step: 320, loss: 0.005833636503666639
step: 330, loss: 0.09148404747247696
step: 340, loss: 0.009751653298735619
step: 350, loss: 0.005571985151618719
step: 360, loss: 0.0037392026279121637
step: 370, loss: 0.0026959399692714214
step: 380, loss: 0.0011511214543133974
epoch 10: dev_f1=0.7978436657681941, f1=0.57703081232493, best_f1=0.6084507042253521
step: 0, loss: 0.008895576931536198
step: 10, loss: 0.0023482341784983873
step: 20, loss: 0.00030372082255780697
step: 30, loss: 0.003731139237061143
step: 40, loss: 0.0023269380908459425
step: 50, loss: 0.006472001783549786
step: 60, loss: 0.001196888042613864
step: 70, loss: 0.0017879422521218657
step: 80, loss: 0.016242938116192818
step: 90, loss: 0.016247309744358063
step: 100, loss: 0.0008075701189227402
step: 110, loss: 0.06068062037229538
step: 120, loss: 0.0018267894629389048
step: 130, loss: 0.002672164933755994
step: 140, loss: 0.00251992279663682
step: 150, loss: 0.009354228153824806
step: 160, loss: 0.0008606041083112359
step: 170, loss: 0.00141007115598768
step: 180, loss: 0.0009060991578735411
step: 190, loss: 0.01421872153878212
step: 200, loss: 0.011285172775387764
step: 210, loss: 0.0016574966721236706
step: 220, loss: 0.1756168007850647
step: 230, loss: 0.12247441709041595
step: 240, loss: 0.022088896483182907
step: 250, loss: 0.0014169015921652317
step: 260, loss: 0.01551460288465023
step: 270, loss: 0.06307625025510788
step: 280, loss: 0.01589801162481308
step: 290, loss: 0.004333546385169029
step: 300, loss: 0.00024632143322378397
step: 310, loss: 0.013195512816309929
step: 320, loss: 0.0010516386246308684
step: 330, loss: 0.007620058488100767
step: 340, loss: 0.0004237350367475301
step: 350, loss: 0.0008135705138556659
step: 360, loss: 0.0010404890635982156
step: 370, loss: 7.843165803933516e-05
step: 380, loss: 0.000251313264016062
epoch 11: dev_f1=0.7904509283819628, f1=0.6022727272727272, best_f1=0.6084507042253521
step: 0, loss: 0.00015624085790477693
step: 10, loss: 0.0006019690190441906
step: 20, loss: 0.038589708507061005
step: 30, loss: 0.0283797699958086
step: 40, loss: 0.003848548047244549
step: 50, loss: 0.00965367816388607
step: 60, loss: 0.00017820876382756978
step: 70, loss: 0.0014141238061711192
step: 80, loss: 0.00804691668599844
step: 90, loss: 0.00043385958997532725
step: 100, loss: 0.0006983429775573313
step: 110, loss: 0.018000230193138123
step: 120, loss: 0.001669590943492949
step: 130, loss: 0.0001876880560303107
step: 140, loss: 0.0004463863151613623
step: 150, loss: 0.0012855224777013063
step: 160, loss: 0.005428456235677004
step: 170, loss: 0.029466232284903526
step: 180, loss: 0.00018829198961611837
step: 190, loss: 0.00036073237424716353
step: 200, loss: 0.0022663730196654797
step: 210, loss: 0.00022878844174556434
step: 220, loss: 0.0010672900825738907
step: 230, loss: 0.0002088271576212719
step: 240, loss: 0.002169182989746332
step: 250, loss: 0.001125111011788249
step: 260, loss: 0.007830615155398846
step: 270, loss: 0.0011497581144794822
step: 280, loss: 0.035835444927215576
step: 290, loss: 0.00046917254803702235
step: 300, loss: 0.0003651499282568693
step: 310, loss: 0.0003440680739004165
step: 320, loss: 0.004776705522090197
step: 330, loss: 0.007244427688419819
step: 340, loss: 0.0005833324394188821
step: 350, loss: 0.0002005819114856422
step: 360, loss: 0.005063665099442005
step: 370, loss: 0.1043914183974266
step: 380, loss: 0.004029935225844383
epoch 12: dev_f1=0.7774798927613942, f1=0.5689655172413793, best_f1=0.6084507042253521
step: 0, loss: 0.00023749694810248911
step: 10, loss: 0.0012044647010043263
step: 20, loss: 0.0006248956196941435
step: 30, loss: 0.00031829543877393007
step: 40, loss: 0.00042580527951940894
step: 50, loss: 0.00022278621327131987
step: 60, loss: 0.025624357163906097
step: 70, loss: 0.0017297884915024042
step: 80, loss: 0.008537537418305874
step: 90, loss: 0.0002108890184899792
step: 100, loss: 0.01155063696205616
step: 110, loss: 0.0005272154230624437
step: 120, loss: 0.00020533581846393645
step: 130, loss: 0.0013543590903282166
step: 140, loss: 0.0006296733627095819
step: 150, loss: 0.0013849653769284487
step: 160, loss: 0.016077706590294838
step: 170, loss: 0.0016484248917549849
step: 180, loss: 0.0012717079371213913
step: 190, loss: 0.0004866643575951457
step: 200, loss: 0.000530034361872822
step: 210, loss: 0.00022228404122870415
step: 220, loss: 0.00018974982958752662
step: 230, loss: 0.0019964531529694796
step: 240, loss: 0.00014027957513462752
step: 250, loss: 0.0011529948096722364
step: 260, loss: 0.00011944577272515744
step: 270, loss: 0.0010085385292768478
step: 280, loss: 0.0005671207909472287
step: 290, loss: 0.0002187099598813802
step: 300, loss: 0.00039041973650455475
step: 310, loss: 0.0011648965300992131
step: 320, loss: 0.0024320008233189583
step: 330, loss: 0.05689569190144539
step: 340, loss: 0.0028737320099025965
step: 350, loss: 0.0006083866464905441
step: 360, loss: 6.8098001065664e-05
step: 370, loss: 0.0005024902638979256
step: 380, loss: 0.04301845282316208
epoch 13: dev_f1=0.7733333333333333, f1=0.5842696629213484, best_f1=0.6084507042253521
step: 0, loss: 0.0010418794117867947
step: 10, loss: 0.03712477162480354
step: 20, loss: 0.0003797518147621304
step: 30, loss: 0.0029299864545464516
step: 40, loss: 0.003026422578841448
step: 50, loss: 0.019060347229242325
step: 60, loss: 0.0001303462777286768
step: 70, loss: 0.01569022797048092
step: 80, loss: 0.0004178104572929442
step: 90, loss: 0.0012335338396951556
step: 100, loss: 0.0006772092892788351
step: 110, loss: 0.00035345961805433035
step: 120, loss: 0.0006370546761900187
step: 130, loss: 0.04202849045395851
step: 140, loss: 0.00020278722513467073
step: 150, loss: 0.006647536065429449
step: 160, loss: 0.00038423907244578004
step: 170, loss: 0.00033339174115099013
step: 180, loss: 0.000103125894383993
step: 190, loss: 0.00019681906269397587
step: 200, loss: 0.021194688975811005
step: 210, loss: 0.001080400892533362
step: 220, loss: 0.0003203052037861198
step: 230, loss: 0.0003456176782492548
step: 240, loss: 0.003575913840904832
step: 250, loss: 0.001133810030296445
step: 260, loss: 0.00020641191804315895
step: 270, loss: 0.057970013469457626
step: 280, loss: 0.006072815973311663
step: 290, loss: 0.011577120050787926
step: 300, loss: 0.0005146994953975081
step: 310, loss: 0.00044660476851277053
step: 320, loss: 0.0005021660472266376
step: 330, loss: 0.0015694143949076533
step: 340, loss: 0.02245025895535946
step: 350, loss: 0.00017543224385008216
step: 360, loss: 0.0008468047017231584
step: 370, loss: 0.0002302807115484029
step: 380, loss: 0.0006161762285046279
epoch 14: dev_f1=0.7909604519774011, f1=0.6158536585365854, best_f1=0.6084507042253521
step: 0, loss: 0.0001231096248375252
step: 10, loss: 0.0005837781936861575
step: 20, loss: 0.00016204710118472576
step: 30, loss: 0.04106123745441437
step: 40, loss: 0.0016478362958878279
step: 50, loss: 6.590881093870848e-05
step: 60, loss: 0.00038433223380707204
step: 70, loss: 0.03437373787164688
step: 80, loss: 8.928168244892731e-05
step: 90, loss: 0.0002475045039318502
step: 100, loss: 0.0003933362022507936
step: 110, loss: 0.00011206765339011326
step: 120, loss: 6.271546590141952e-05
step: 130, loss: 0.0003572781861294061
step: 140, loss: 0.00032821233617141843
step: 150, loss: 0.00032639779965393245
step: 160, loss: 4.754059773404151e-05
step: 170, loss: 0.0011456136126071215
step: 180, loss: 0.01884385012090206
step: 190, loss: 0.0004778343718498945
step: 200, loss: 0.007820640690624714
step: 210, loss: 0.00035051198210567236
step: 220, loss: 0.0012137445155531168
step: 230, loss: 8.788133709458634e-05
step: 240, loss: 0.00014474500494543463
step: 250, loss: 0.00017342758656013757
step: 260, loss: 0.0031447948422282934
step: 270, loss: 0.0003737116348929703
step: 280, loss: 0.0025249654427170753
step: 290, loss: 0.00011159722635056823
step: 300, loss: 0.00012220069766044617
step: 310, loss: 8.809132850728929e-05
step: 320, loss: 7.929841376608238e-05
step: 330, loss: 0.1539921760559082
step: 340, loss: 9.091039100894704e-05
step: 350, loss: 9.090368985198438e-05
step: 360, loss: 0.0002452070766594261
step: 370, loss: 0.00010786196071421728
step: 380, loss: 0.0018155646976083517
epoch 15: dev_f1=0.7878787878787877, f1=0.5921450151057402, best_f1=0.6084507042253521
step: 0, loss: 0.04351699724793434
step: 10, loss: 0.06887341290712357
step: 20, loss: 0.00024072008091025054
step: 30, loss: 0.0009886141633614898
step: 40, loss: 0.0030535783153027296
step: 50, loss: 0.00025668792659416795
step: 60, loss: 0.00020458833023440093
step: 70, loss: 0.0076639968901872635
step: 80, loss: 0.00022298312978819013
step: 90, loss: 0.003605959936976433
step: 100, loss: 0.00047559692757204175
step: 110, loss: 0.00023067214351613075
step: 120, loss: 0.005990741308778524
step: 130, loss: 0.001967136049643159
step: 140, loss: 0.00012069762306055054
step: 150, loss: 0.01888224296271801
step: 160, loss: 0.00020790359121747315
step: 170, loss: 0.00208035740070045
step: 180, loss: 0.0016575590707361698
step: 190, loss: 0.001411810633726418
step: 200, loss: 0.00029605263262055814
step: 210, loss: 9.000620775623247e-05
step: 220, loss: 0.003971906844526529
step: 230, loss: 0.0001513375318609178
step: 240, loss: 0.00014314259169623256
step: 250, loss: 4.7465826355619356e-05
step: 260, loss: 0.0014147829497233033
step: 270, loss: 0.00028154690517112613
step: 280, loss: 0.0003477582649793476
step: 290, loss: 0.00020228604262229055
step: 300, loss: 7.781320164212957e-05
step: 310, loss: 0.0008752144640311599
step: 320, loss: 0.00026340311160311103
step: 330, loss: 0.00013883516658097506
step: 340, loss: 0.006866927724331617
step: 350, loss: 0.000404223712394014
step: 360, loss: 5.735806917073205e-05
step: 370, loss: 0.00012045294715790078
step: 380, loss: 0.0002517156535759568
epoch 16: dev_f1=0.7774798927613942, f1=0.6074498567335244, best_f1=0.6084507042253521
step: 0, loss: 0.0007938642520457506
step: 10, loss: 0.001593397231772542
step: 20, loss: 0.0005011362954974174
step: 30, loss: 0.000176135465153493
step: 40, loss: 0.0003547611995600164
step: 50, loss: 0.000512570608407259
step: 60, loss: 0.0009721628157421947
step: 70, loss: 5.805540786241181e-05
step: 80, loss: 6.549051613546908e-05
step: 90, loss: 0.011339343152940273
step: 100, loss: 0.0005994266830384731
step: 110, loss: 0.00010073503653984517
step: 120, loss: 0.00018443234148435295
step: 130, loss: 0.0003210098366253078
step: 140, loss: 0.0002664382045622915
step: 150, loss: 0.0001965322153409943
step: 160, loss: 0.015387997962534428
step: 170, loss: 0.0005983830196782947
step: 180, loss: 0.0028706276789307594
step: 190, loss: 0.205827534198761
step: 200, loss: 0.00027630882686935365
step: 210, loss: 0.0011516312370076776
step: 220, loss: 0.00047109348815865815
step: 230, loss: 0.0004072955925948918
step: 240, loss: 0.0009083450422622263
step: 250, loss: 7.367924263235182e-05
step: 260, loss: 0.006400578189641237
step: 270, loss: 8.3579019701574e-05
step: 280, loss: 0.00015332316979765892
step: 290, loss: 0.0001694737875368446
step: 300, loss: 0.00012670700380112976
step: 310, loss: 0.00012205565144540742
step: 320, loss: 5.772006625193171e-05
step: 330, loss: 0.00014992458454798907
step: 340, loss: 8.853474719217047e-05
step: 350, loss: 0.0002557469124440104
step: 360, loss: 0.0007761651650071144
step: 370, loss: 8.522205462213606e-05
step: 380, loss: 0.00030734704341739416
epoch 17: dev_f1=0.779220779220779, f1=0.6050420168067228, best_f1=0.6084507042253521
step: 0, loss: 5.996537220198661e-05
step: 10, loss: 0.000147283572005108
step: 20, loss: 0.0001293900131713599
step: 30, loss: 6.246163684409112e-05
step: 40, loss: 8.518862159689888e-05
step: 50, loss: 0.00020335269800852984
step: 60, loss: 0.001860985648818314
step: 70, loss: 0.0003071543760597706
step: 80, loss: 0.00014718793681822717
step: 90, loss: 3.5471275623422116e-05
step: 100, loss: 6.584332732018083e-05
step: 110, loss: 0.0033098203130066395
step: 120, loss: 0.00019195841741748154
step: 130, loss: 0.00046916346764191985
step: 140, loss: 0.00011915834329556674
step: 150, loss: 0.0010578740620985627
step: 160, loss: 0.0010755141265690327
step: 170, loss: 0.0002365017426200211
step: 180, loss: 0.00026353495195508003
step: 190, loss: 0.00021270271099638194
step: 200, loss: 0.0001552965841256082
step: 210, loss: 8.473764319205657e-05
step: 220, loss: 0.00012673859600909054
step: 230, loss: 7.160668610595167e-05
step: 240, loss: 0.00023098074598237872
step: 250, loss: 0.09150397032499313
step: 260, loss: 0.00012278452049940825
step: 270, loss: 0.00019005005015060306
step: 280, loss: 0.00019550665456335992
step: 290, loss: 5.665775461238809e-05
step: 300, loss: 0.0001540566299809143
step: 310, loss: 0.00029236299451440573
step: 320, loss: 0.00013753556413576007
step: 330, loss: 5.223571861279197e-05
step: 340, loss: 6.70024091959931e-05
step: 350, loss: 0.0002437902585370466
step: 360, loss: 7.286947220563889e-05
step: 370, loss: 0.00015893331146799028
step: 380, loss: 0.0004534968174993992
epoch 18: dev_f1=0.7780678851174935, f1=0.6045197740112994, best_f1=0.6084507042253521
step: 0, loss: 0.0001420574844814837
step: 10, loss: 0.0002885089779738337
step: 20, loss: 7.190291944425553e-05
step: 30, loss: 6.326603033812717e-05
step: 40, loss: 0.00014270828978624195
step: 50, loss: 6.65451807435602e-05
step: 60, loss: 0.0034212083555758
step: 70, loss: 0.00011008854926330969
step: 80, loss: 4.916804391541518e-05
step: 90, loss: 9.65631115832366e-05
step: 100, loss: 0.0007681319839321077
step: 110, loss: 0.0025211290922015905
step: 120, loss: 0.00011756187450373545
step: 130, loss: 6.739830860169604e-05
step: 140, loss: 0.0001379302702844143
step: 150, loss: 5.6065982789732516e-05
step: 160, loss: 7.790280506014824e-05
step: 170, loss: 4.079798236489296e-05
step: 180, loss: 0.04018445312976837
step: 190, loss: 6.385795859387144e-05
step: 200, loss: 6.219404167495668e-05
step: 210, loss: 6.49098728899844e-05
step: 220, loss: 0.0001857130991993472
step: 230, loss: 5.8976540458388627e-05
step: 240, loss: 6.013626261847094e-05
step: 250, loss: 9.284082625526935e-05
step: 260, loss: 0.00012224868987686932
step: 270, loss: 0.00013664520520251244
step: 280, loss: 4.422741403686814e-05
step: 290, loss: 0.0001849969703471288
step: 300, loss: 0.000143634679261595
step: 310, loss: 0.000462473341031
step: 320, loss: 0.003760033519938588
step: 330, loss: 7.153367187129334e-05
step: 340, loss: 0.0002576959377620369
step: 350, loss: 0.0002671346301212907
step: 360, loss: 7.714213279541582e-05
step: 370, loss: 3.3701900974847376e-05
step: 380, loss: 0.00038259505527094007
epoch 19: dev_f1=0.7745358090185677, f1=0.5953757225433527, best_f1=0.6084507042253521
step: 0, loss: 4.690257628681138e-05
step: 10, loss: 7.022600038908422e-05
step: 20, loss: 0.00010581946844467893
step: 30, loss: 0.00017700371972750872
step: 40, loss: 0.00019883397908415645
step: 50, loss: 0.00020158903498668224
step: 60, loss: 6.415411917259917e-05
step: 70, loss: 4.5114546082913876e-05
step: 80, loss: 0.00017151694919448346
step: 90, loss: 0.1359938234090805
step: 100, loss: 0.00023366363893728703
step: 110, loss: 0.0003636217734310776
step: 120, loss: 6.628072151215747e-05
step: 130, loss: 0.0005369872087612748
step: 140, loss: 0.09177300333976746
step: 150, loss: 0.0011332203866913915
step: 160, loss: 0.00025555180036462843
step: 170, loss: 0.00010415938595542684
step: 180, loss: 0.0005278725875541568
step: 190, loss: 0.03887348249554634
step: 200, loss: 0.0006063437322154641
step: 210, loss: 7.872441346989945e-05
step: 220, loss: 4.66034616692923e-05
step: 230, loss: 0.00010655455116648227
step: 240, loss: 0.001315814908593893
step: 250, loss: 0.0028178899083286524
step: 260, loss: 0.0003970409161411226
step: 270, loss: 7.976998313097283e-05
step: 280, loss: 9.225017856806517e-05
step: 290, loss: 0.00020575206144712865
step: 300, loss: 5.2425075409701094e-05
step: 310, loss: 0.00010314927203580737
step: 320, loss: 0.0003386542375665158
step: 330, loss: 7.481056672986597e-05
step: 340, loss: 0.0007895964081399143
step: 350, loss: 0.005642032250761986
step: 360, loss: 6.473485700553283e-05
step: 370, loss: 0.00010405785724287853
step: 380, loss: 0.00017547768948134035
epoch 20: dev_f1=0.7783505154639175, f1=0.6055555555555556, best_f1=0.6084507042253521
