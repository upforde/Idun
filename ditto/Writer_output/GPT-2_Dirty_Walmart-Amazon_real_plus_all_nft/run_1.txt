cuda
Device: cuda
step: 0, loss: 0.5993349552154541
step: 10, loss: 0.3230588436126709
step: 20, loss: 0.30872201919555664
step: 30, loss: 0.38972678780555725
step: 40, loss: 0.37498822808265686
step: 50, loss: 0.1534557193517685
step: 60, loss: 0.24772323668003082
step: 70, loss: 0.4082149267196655
step: 80, loss: 0.3652818500995636
step: 90, loss: 0.29975882172584534
step: 100, loss: 0.41961726546287537
step: 110, loss: 0.36684098839759827
step: 120, loss: 0.3675072491168976
step: 130, loss: 0.6913721561431885
step: 140, loss: 0.23202672600746155
step: 150, loss: 0.5250771641731262
step: 160, loss: 0.20309649407863617
step: 170, loss: 0.34248024225234985
step: 180, loss: 0.21507444977760315
step: 190, loss: 0.28246089816093445
step: 200, loss: 0.2052990347146988
step: 210, loss: 0.2897112965583801
step: 220, loss: 0.24915756285190582
step: 230, loss: 0.21881206333637238
step: 240, loss: 0.22985811531543732
step: 250, loss: 0.4487460255622864
step: 260, loss: 0.37928318977355957
step: 270, loss: 0.20612414181232452
step: 280, loss: 0.24044190347194672
step: 290, loss: 0.3192560076713562
step: 300, loss: 0.5615261197090149
step: 310, loss: 0.5017072558403015
step: 320, loss: 0.28293490409851074
step: 330, loss: 0.2591310143470764
step: 340, loss: 0.14936399459838867
step: 350, loss: 0.23524102568626404
step: 360, loss: 0.10633432865142822
step: 370, loss: 0.4544370770454407
step: 380, loss: 0.20731227099895477
epoch 1: dev_f1=0.5350877192982456, f1=0.3572984749455338, best_f1=0.3572984749455338
step: 0, loss: 0.24182173609733582
step: 10, loss: 0.24625985324382782
step: 20, loss: 0.17909447848796844
step: 30, loss: 0.26909124851226807
step: 40, loss: 0.16890119016170502
step: 50, loss: 0.13701669871807098
step: 60, loss: 0.11372923851013184
step: 70, loss: 0.33483514189720154
step: 80, loss: 0.31755247712135315
step: 90, loss: 0.1310533732175827
step: 100, loss: 0.1977325826883316
step: 110, loss: 0.02574341371655464
step: 120, loss: 0.348335325717926
step: 130, loss: 0.13010627031326294
step: 140, loss: 0.10303130745887756
step: 150, loss: 0.261456161737442
step: 160, loss: 0.19392430782318115
step: 170, loss: 0.10132372379302979
step: 180, loss: 0.2431567907333374
step: 190, loss: 0.1803879737854004
step: 200, loss: 0.552035391330719
step: 210, loss: 0.21577088534832
step: 220, loss: 0.1103779524564743
step: 230, loss: 0.21422246098518372
step: 240, loss: 0.029517628252506256
step: 250, loss: 0.21715161204338074
step: 260, loss: 0.0990915596485138
step: 270, loss: 0.2009337991476059
step: 280, loss: 0.28176718950271606
step: 290, loss: 0.2472117692232132
step: 300, loss: 0.22350405156612396
step: 310, loss: 0.2712584435939789
step: 320, loss: 0.252948522567749
step: 330, loss: 0.2972413897514343
step: 340, loss: 0.2439032942056656
step: 350, loss: 0.2748039662837982
step: 360, loss: 0.2874442934989929
step: 370, loss: 0.09664928168058395
step: 380, loss: 0.13980995118618011
epoch 2: dev_f1=0.7188264058679708, f1=0.5320665083135391, best_f1=0.5320665083135391
step: 0, loss: 0.11001880466938019
step: 10, loss: 0.026912882924079895
step: 20, loss: 0.2668323814868927
step: 30, loss: 0.05824656039476395
step: 40, loss: 0.1913481205701828
step: 50, loss: 0.09727324545383453
step: 60, loss: 0.07419011741876602
step: 70, loss: 0.07108956575393677
step: 80, loss: 0.23322665691375732
step: 90, loss: 0.09676411002874374
step: 100, loss: 0.10990619659423828
step: 110, loss: 0.22486315667629242
step: 120, loss: 0.30027303099632263
step: 130, loss: 0.28138595819473267
step: 140, loss: 0.2630765736103058
step: 150, loss: 0.22445811331272125
step: 160, loss: 0.10042105615139008
step: 170, loss: 0.23022159934043884
step: 180, loss: 0.16738151013851166
step: 190, loss: 0.1821836680173874
step: 200, loss: 0.07427746802568436
step: 210, loss: 0.09187795221805573
step: 220, loss: 0.35927385091781616
step: 230, loss: 0.025078730657696724
step: 240, loss: 0.1485336571931839
step: 250, loss: 0.1439870148897171
step: 260, loss: 0.2002202868461609
step: 270, loss: 0.3256663680076599
step: 280, loss: 0.2627035677433014
step: 290, loss: 0.10165464878082275
step: 300, loss: 0.02682790532708168
step: 310, loss: 0.21390265226364136
step: 320, loss: 0.13496489822864532
step: 330, loss: 0.1480230987071991
step: 340, loss: 0.10019439458847046
step: 350, loss: 0.06835340708494186
step: 360, loss: 0.254847913980484
step: 370, loss: 0.16883966326713562
step: 380, loss: 0.2675378620624542
epoch 3: dev_f1=0.760204081632653, f1=0.5722070844686649, best_f1=0.5722070844686649
step: 0, loss: 0.30163195729255676
step: 10, loss: 0.2944963276386261
step: 20, loss: 0.19531261920928955
step: 30, loss: 0.21553108096122742
step: 40, loss: 0.17793914675712585
step: 50, loss: 0.06027982383966446
step: 60, loss: 0.05229644477367401
step: 70, loss: 0.14999260008335114
step: 80, loss: 0.2953174114227295
step: 90, loss: 0.00994089525192976
step: 100, loss: 0.10676281899213791
step: 110, loss: 0.08495029807090759
step: 120, loss: 0.1242297887802124
step: 130, loss: 0.24416925013065338
step: 140, loss: 0.2558561861515045
step: 150, loss: 0.08406473696231842
step: 160, loss: 0.006190865766257048
step: 170, loss: 0.09293423593044281
step: 180, loss: 0.29170194268226624
step: 190, loss: 0.07914477586746216
step: 200, loss: 0.11379013955593109
step: 210, loss: 0.10367728769779205
step: 220, loss: 0.036388229578733444
step: 230, loss: 0.28666752576828003
step: 240, loss: 0.15698455274105072
step: 250, loss: 0.230479896068573
step: 260, loss: 0.13084924221038818
step: 270, loss: 0.045600321143865585
step: 280, loss: 0.24298352003097534
step: 290, loss: 0.1531996726989746
step: 300, loss: 0.0944451093673706
step: 310, loss: 0.1831611841917038
step: 320, loss: 0.17079751193523407
step: 330, loss: 0.03852600231766701
step: 340, loss: 0.22841084003448486
step: 350, loss: 0.0372295007109642
step: 360, loss: 0.0876375362277031
step: 370, loss: 0.05792085453867912
step: 380, loss: 0.06265677511692047
epoch 4: dev_f1=0.7842105263157894, f1=0.5577464788732395, best_f1=0.5577464788732395
step: 0, loss: 0.2714325189590454
step: 10, loss: 0.05659973993897438
step: 20, loss: 0.016004176810383797
step: 30, loss: 0.04742036014795303
step: 40, loss: 0.12559957802295685
step: 50, loss: 0.06383197009563446
step: 60, loss: 0.04284542798995972
step: 70, loss: 0.024839818477630615
step: 80, loss: 0.045662395656108856
step: 90, loss: 0.015977893024683
step: 100, loss: 0.05063742399215698
step: 110, loss: 0.05751124024391174
step: 120, loss: 0.09805887192487717
step: 130, loss: 0.0427401103079319
step: 140, loss: 0.03889193758368492
step: 150, loss: 0.1442403942346573
step: 160, loss: 0.09267465770244598
step: 170, loss: 0.04235870763659477
step: 180, loss: 0.2018531858921051
step: 190, loss: 0.049182213842868805
step: 200, loss: 0.22612111270427704
step: 210, loss: 0.20515961945056915
step: 220, loss: 0.09123353660106659
step: 230, loss: 0.09636062383651733
step: 240, loss: 0.12083844840526581
step: 250, loss: 0.05758208408951759
step: 260, loss: 0.05040254071354866
step: 270, loss: 0.08718612045049667
step: 280, loss: 0.056953463703393936
step: 290, loss: 0.09936906397342682
step: 300, loss: 0.12138579040765762
step: 310, loss: 0.23480553925037384
step: 320, loss: 0.0623585507273674
step: 330, loss: 0.09101223945617676
step: 340, loss: 0.32317015528678894
step: 350, loss: 0.10074985027313232
step: 360, loss: 0.08641474694013596
step: 370, loss: 0.036058276891708374
step: 380, loss: 0.0285947322845459
epoch 5: dev_f1=0.8076923076923077, f1=0.6259541984732825, best_f1=0.6259541984732825
step: 0, loss: 0.1310880184173584
step: 10, loss: 0.013665352016687393
step: 20, loss: 0.051276545971632004
step: 30, loss: 0.04756999760866165
step: 40, loss: 0.014734387397766113
step: 50, loss: 0.026076311245560646
step: 60, loss: 0.18442657589912415
step: 70, loss: 0.007212483324110508
step: 80, loss: 0.022801727056503296
step: 90, loss: 0.22610482573509216
step: 100, loss: 0.028902491554617882
step: 110, loss: 0.04848848655819893
step: 120, loss: 0.051919061690568924
step: 130, loss: 0.01118298340588808
step: 140, loss: 0.053822051733732224
step: 150, loss: 0.04234018921852112
step: 160, loss: 0.014920246787369251
step: 170, loss: 0.10449216514825821
step: 180, loss: 0.015469355508685112
step: 190, loss: 0.024476585909724236
step: 200, loss: 0.1582803726196289
step: 210, loss: 0.010333743877708912
step: 220, loss: 0.021703505888581276
step: 230, loss: 0.0016353889368474483
step: 240, loss: 0.16997185349464417
step: 250, loss: 0.027905844151973724
step: 260, loss: 0.028178220614790916
step: 270, loss: 0.016269942745566368
step: 280, loss: 0.18594658374786377
step: 290, loss: 0.188799187541008
step: 300, loss: 0.06794361025094986
step: 310, loss: 0.2623962163925171
step: 320, loss: 0.0766524225473404
step: 330, loss: 0.023721639066934586
step: 340, loss: 0.09226758778095245
step: 350, loss: 0.10862628370523453
step: 360, loss: 0.010714340955018997
step: 370, loss: 0.09726005047559738
step: 380, loss: 0.020718995481729507
epoch 6: dev_f1=0.8302872062663187, f1=0.6028985507246377, best_f1=0.6028985507246377
step: 0, loss: 0.012370802462100983
step: 10, loss: 0.007162058260291815
step: 20, loss: 0.04893387854099274
step: 30, loss: 0.027660058811306953
step: 40, loss: 0.06763607263565063
step: 50, loss: 0.06236279010772705
step: 60, loss: 0.037168607115745544
step: 70, loss: 0.01705961488187313
step: 80, loss: 0.009394589811563492
step: 90, loss: 0.14546723663806915
step: 100, loss: 0.0019204966956749558
step: 110, loss: 0.19156908988952637
step: 120, loss: 0.004854894708842039
step: 130, loss: 0.09405753016471863
step: 140, loss: 0.04030749201774597
step: 150, loss: 0.07684874534606934
step: 160, loss: 0.026201020926237106
step: 170, loss: 0.033118780702352524
step: 180, loss: 0.0038697905838489532
step: 190, loss: 0.059278037399053574
step: 200, loss: 0.05478556454181671
step: 210, loss: 0.048557430505752563
step: 220, loss: 0.07397019118070602
step: 230, loss: 0.012258060276508331
step: 240, loss: 0.001913868123665452
step: 250, loss: 0.004668522160500288
step: 260, loss: 0.07497120648622513
step: 270, loss: 0.047808460891246796
step: 280, loss: 0.04673835262656212
step: 290, loss: 0.07807587087154388
step: 300, loss: 0.060673877596855164
step: 310, loss: 0.07318621128797531
step: 320, loss: 0.004790638107806444
step: 330, loss: 0.09541310369968414
step: 340, loss: 0.010609264485538006
step: 350, loss: 0.11180533468723297
step: 360, loss: 0.007268723100423813
step: 370, loss: 0.10305378586053848
step: 380, loss: 0.016517993062734604
epoch 7: dev_f1=0.8165374677002584, f1=0.6225895316804407, best_f1=0.6028985507246377
step: 0, loss: 0.012695081532001495
step: 10, loss: 0.02759966440498829
step: 20, loss: 0.03413286805152893
step: 30, loss: 0.0021235866006463766
step: 40, loss: 0.009564435109496117
step: 50, loss: 0.0077537293545901775
step: 60, loss: 0.011218434199690819
step: 70, loss: 0.08558864891529083
step: 80, loss: 0.022391173988580704
step: 90, loss: 0.007096287794411182
step: 100, loss: 0.004157773219048977
step: 110, loss: 0.01918412558734417
step: 120, loss: 0.09296740591526031
step: 130, loss: 0.10937252640724182
step: 140, loss: 0.017404276877641678
step: 150, loss: 0.013743771240115166
step: 160, loss: 0.012989443726837635
step: 170, loss: 0.009261555969715118
step: 180, loss: 0.0023269164375960827
step: 190, loss: 0.006610922981053591
step: 200, loss: 0.0025945447850972414
step: 210, loss: 0.005009348504245281
step: 220, loss: 0.0016528082778677344
step: 230, loss: 0.057061463594436646
step: 240, loss: 0.00033675998565740883
step: 250, loss: 0.08688928931951523
step: 260, loss: 0.043101873248815536
step: 270, loss: 0.021678263321518898
step: 280, loss: 0.02396651916205883
step: 290, loss: 0.004313261713832617
step: 300, loss: 0.014421762898564339
step: 310, loss: 0.02244315668940544
step: 320, loss: 0.000380147248506546
step: 330, loss: 0.1352120339870453
step: 340, loss: 0.014793619513511658
step: 350, loss: 0.0031696383375674486
step: 360, loss: 0.014029965735971928
step: 370, loss: 0.02098412998020649
step: 380, loss: 0.04400794208049774
epoch 8: dev_f1=0.8146214099216709, f1=0.6011560693641619, best_f1=0.6028985507246377
step: 0, loss: 0.007068353239446878
step: 10, loss: 0.005952275823801756
step: 20, loss: 0.0005392940365709364
step: 30, loss: 0.0017591101350262761
step: 40, loss: 0.001239916542544961
step: 50, loss: 0.009206769056618214
step: 60, loss: 0.00957501120865345
step: 70, loss: 0.0007709531928412616
step: 80, loss: 0.02126108482480049
step: 90, loss: 0.006519473623484373
step: 100, loss: 0.00417985999956727
step: 110, loss: 0.21770186722278595
step: 120, loss: 0.0005012454348616302
step: 130, loss: 0.10192728042602539
step: 140, loss: 0.0758572444319725
step: 150, loss: 0.05180805176496506
step: 160, loss: 0.0024288513232022524
step: 170, loss: 0.0030105561017990112
step: 180, loss: 0.0010252157226204872
step: 190, loss: 0.004059464670717716
step: 200, loss: 0.03181719407439232
step: 210, loss: 0.0011534132063388824
step: 220, loss: 0.018838584423065186
step: 230, loss: 0.021173527464270592
step: 240, loss: 0.006347610615193844
step: 250, loss: 0.0017625964246690273
step: 260, loss: 0.050370462238788605
step: 270, loss: 0.046638570725917816
step: 280, loss: 0.06137675791978836
step: 290, loss: 0.011254934594035149
step: 300, loss: 0.004207562189549208
step: 310, loss: 0.008909516036510468
step: 320, loss: 0.061932384967803955
step: 330, loss: 0.08977198600769043
step: 340, loss: 0.02844468131661415
step: 350, loss: 0.0068994686007499695
step: 360, loss: 0.003176984144374728
step: 370, loss: 0.002129396889358759
step: 380, loss: 0.026170868426561356
epoch 9: dev_f1=0.8244680851063829, f1=0.6202898550724637, best_f1=0.6028985507246377
step: 0, loss: 0.0017644255422055721
step: 10, loss: 0.05087464675307274
step: 20, loss: 0.04383871704339981
step: 30, loss: 0.07235512882471085
step: 40, loss: 0.0059030246920883656
step: 50, loss: 0.15154054760932922
step: 60, loss: 0.003288594074547291
step: 70, loss: 0.0009203820372931659
step: 80, loss: 0.0012635716702789068
step: 90, loss: 0.013067769818007946
step: 100, loss: 0.0037687451113015413
step: 110, loss: 0.003949805162847042
step: 120, loss: 0.011105057783424854
step: 130, loss: 0.012613794766366482
step: 140, loss: 0.0012101414613425732
step: 150, loss: 0.00031313797808252275
step: 160, loss: 0.006929481402039528
step: 170, loss: 0.019873030483722687
step: 180, loss: 0.05020870268344879
step: 190, loss: 0.0010912499856203794
step: 200, loss: 0.09543298184871674
step: 210, loss: 0.08157929033041
step: 220, loss: 0.0013756935950368643
step: 230, loss: 0.0008177915005944669
step: 240, loss: 0.010363834910094738
step: 250, loss: 0.005091291852295399
step: 260, loss: 0.01957063563168049
step: 270, loss: 0.0008700238540768623
step: 280, loss: 0.009374788962304592
step: 290, loss: 0.0009352232445962727
step: 300, loss: 0.007968246936798096
step: 310, loss: 0.03429829701781273
step: 320, loss: 0.005820746999233961
step: 330, loss: 0.005357326008379459
step: 340, loss: 0.023644138127565384
step: 350, loss: 0.002873284975066781
step: 360, loss: 0.004836326465010643
step: 370, loss: 0.02803572081029415
step: 380, loss: 0.0040426068007946014
epoch 10: dev_f1=0.8188976377952756, f1=0.6175637393767704, best_f1=0.6028985507246377
step: 0, loss: 0.007994434796273708
step: 10, loss: 0.018526369705796242
step: 20, loss: 0.0005136314430274069
step: 30, loss: 0.009553550742566586
step: 40, loss: 0.00801373366266489
step: 50, loss: 0.0016931724967435002
step: 60, loss: 0.00048693519784137607
step: 70, loss: 0.0025172813329845667
step: 80, loss: 0.00045299893827177584
step: 90, loss: 0.003732363460585475
step: 100, loss: 0.026485636830329895
step: 110, loss: 0.0024115308187901974
step: 120, loss: 0.003486516885459423
step: 130, loss: 0.0031307905446738005
step: 140, loss: 0.0014740630285814404
step: 150, loss: 0.0013377424329519272
step: 160, loss: 0.0015083597972989082
step: 170, loss: 0.002559835324063897
step: 180, loss: 0.007301113568246365
step: 190, loss: 0.005579420831054449
step: 200, loss: 0.0077280267141759396
step: 210, loss: 0.002352687530219555
step: 220, loss: 0.010429192334413528
step: 230, loss: 0.00319324410520494
step: 240, loss: 0.036773499101400375
step: 250, loss: 0.018561124801635742
step: 260, loss: 0.012439461424946785
step: 270, loss: 0.007786812260746956
step: 280, loss: 0.0181224774569273
step: 290, loss: 0.02534400299191475
step: 300, loss: 0.0018515571719035506
step: 310, loss: 0.10667063295841217
step: 320, loss: 0.0002143699093721807
step: 330, loss: 0.02500002644956112
step: 340, loss: 0.001176001620478928
step: 350, loss: 0.042000699788331985
step: 360, loss: 0.003605898702517152
step: 370, loss: 0.010296597145497799
step: 380, loss: 0.0013854412827640772
epoch 11: dev_f1=0.8090452261306532, f1=0.6253369272237197, best_f1=0.6028985507246377
step: 0, loss: 0.001734508783556521
step: 10, loss: 0.006860900670289993
step: 20, loss: 0.0022119125351309776
step: 30, loss: 0.03612295165657997
step: 40, loss: 0.0014154113596305251
step: 50, loss: 0.0036861964035779238
step: 60, loss: 0.0006577951717190444
step: 70, loss: 0.022402312606573105
step: 80, loss: 0.005462178960442543
step: 90, loss: 0.011892287991940975
step: 100, loss: 0.0012741393875330687
step: 110, loss: 0.05520934611558914
step: 120, loss: 0.000586723443120718
step: 130, loss: 0.0011263638734817505
step: 140, loss: 0.00552771519869566
step: 150, loss: 0.006550053600221872
step: 160, loss: 0.0004615772340912372
step: 170, loss: 0.005649421829730272
step: 180, loss: 0.2092691957950592
step: 190, loss: 0.005974097643047571
step: 200, loss: 0.060201358050107956
step: 210, loss: 0.002437372924759984
step: 220, loss: 9.522395703243092e-05
step: 230, loss: 0.0006936772842891514
step: 240, loss: 0.08157539367675781
step: 250, loss: 0.001366807846352458
step: 260, loss: 0.0009790471522137523
step: 270, loss: 0.0015530266100540757
step: 280, loss: 0.00025011386605910957
step: 290, loss: 0.0006151192937977612
step: 300, loss: 0.007576530333608389
step: 310, loss: 0.000513496226631105
step: 320, loss: 0.00010468082473380491
step: 330, loss: 0.006754367612302303
step: 340, loss: 0.0005999950226396322
step: 350, loss: 0.00018023009761236608
step: 360, loss: 0.02863987907767296
step: 370, loss: 0.005018210969865322
step: 380, loss: 0.003449162235483527
epoch 12: dev_f1=0.7980049875311721, f1=0.6333333333333333, best_f1=0.6028985507246377
step: 0, loss: 0.004175909794867039
step: 10, loss: 0.012629331089556217
step: 20, loss: 0.00601962162181735
step: 30, loss: 0.010066056624054909
step: 40, loss: 0.004062912426888943
step: 50, loss: 0.0026434382889419794
step: 60, loss: 0.003591484623029828
step: 70, loss: 0.0026931839529424906
step: 80, loss: 0.0003025639452971518
step: 90, loss: 0.0010047088144347072
step: 100, loss: 0.00018538856238592416
step: 110, loss: 0.02417701855301857
step: 120, loss: 0.00039358940557576716
step: 130, loss: 0.00028276434750296175
step: 140, loss: 0.04359618201851845
step: 150, loss: 0.0002764918317552656
step: 160, loss: 0.002600807696580887
step: 170, loss: 0.0026026929263025522
step: 180, loss: 0.0013541015796363354
step: 190, loss: 0.0003292298933956772
step: 200, loss: 0.00026936925132758915
step: 210, loss: 0.0006960178725421429
step: 220, loss: 0.0025539409834891558
step: 230, loss: 0.0004523511743173003
step: 240, loss: 0.00013524075620807707
step: 250, loss: 0.0003345826407894492
step: 260, loss: 0.020814120769500732
step: 270, loss: 0.03078794665634632
step: 280, loss: 0.00021764913981314749
step: 290, loss: 0.008228491991758347
step: 300, loss: 0.0001776761346263811
step: 310, loss: 0.0005111636128276587
step: 320, loss: 0.0001006629754556343
step: 330, loss: 0.00013983937969896942
step: 340, loss: 0.0024326718412339687
step: 350, loss: 0.010206921026110649
step: 360, loss: 0.009069441817700863
step: 370, loss: 0.0004013703146483749
step: 380, loss: 0.0008202464086934924
epoch 13: dev_f1=0.8140703517587939, f1=0.663013698630137, best_f1=0.6028985507246377
step: 0, loss: 0.00011885485582752153
step: 10, loss: 0.013649356551468372
step: 20, loss: 0.13515503704547882
step: 30, loss: 0.0036801376845687628
step: 40, loss: 0.0008947530877776444
step: 50, loss: 0.004932702053338289
step: 60, loss: 0.00023380055790767074
step: 70, loss: 0.03115859255194664
step: 80, loss: 0.0014606983168050647
step: 90, loss: 0.00045845218119211495
step: 100, loss: 0.13395939767360687
step: 110, loss: 0.0021168249659240246
step: 120, loss: 0.0008116007084026933
step: 130, loss: 0.008493480272591114
step: 140, loss: 0.0009887834312394261
step: 150, loss: 0.023102248087525368
step: 160, loss: 0.0060469647869467735
step: 170, loss: 0.0024529919028282166
step: 180, loss: 0.00029063640977256
step: 190, loss: 0.030973732471466064
step: 200, loss: 0.0016752914525568485
step: 210, loss: 0.00018584793724585325
step: 220, loss: 0.0003953981213271618
step: 230, loss: 0.0010334068210795522
step: 240, loss: 0.0005863181431777775
step: 250, loss: 0.0008180480217561126
step: 260, loss: 0.00026556148077361286
step: 270, loss: 0.0006250024889595807
step: 280, loss: 0.0003764892171602696
step: 290, loss: 0.0003910392115358263
step: 300, loss: 0.0022775933612138033
step: 310, loss: 0.001436708145774901
step: 320, loss: 0.003607455175369978
step: 330, loss: 0.0013310399372130632
step: 340, loss: 0.001010662061162293
step: 350, loss: 0.06488057971000671
step: 360, loss: 0.0012302574468776584
step: 370, loss: 0.002517788205295801
step: 380, loss: 0.002627519890666008
epoch 14: dev_f1=0.8214285714285714, f1=0.6478873239436621, best_f1=0.6028985507246377
step: 0, loss: 0.013182022608816624
step: 10, loss: 0.00025867464137263596
step: 20, loss: 0.0033114254474639893
step: 30, loss: 0.0004177972150500864
step: 40, loss: 0.0007328764186240733
step: 50, loss: 0.00023836577020119876
step: 60, loss: 5.9119509387528524e-05
step: 70, loss: 0.00034205050906166434
step: 80, loss: 0.00023591351055074483
step: 90, loss: 0.002622435102239251
step: 100, loss: 0.00039891008054837584
step: 110, loss: 0.0017753945430740714
step: 120, loss: 0.00025382841704413295
step: 130, loss: 0.0009340604883618653
step: 140, loss: 0.005317949689924717
step: 150, loss: 0.0005165449110791087
step: 160, loss: 0.006571056786924601
step: 170, loss: 0.00012096427235519513
step: 180, loss: 0.0010833743726834655
step: 190, loss: 0.005203382112085819
step: 200, loss: 0.00113617442548275
step: 210, loss: 0.0003739420499186963
step: 220, loss: 0.006937704980373383
step: 230, loss: 0.0004011738928966224
step: 240, loss: 0.0004432742134667933
step: 250, loss: 0.000307693233480677
step: 260, loss: 0.0006811090279370546
step: 270, loss: 0.000270382734015584
step: 280, loss: 0.022955119609832764
step: 290, loss: 0.0001496731274528429
step: 300, loss: 0.10917120426893234
step: 310, loss: 0.09258744865655899
step: 320, loss: 0.0008211151580326259
step: 330, loss: 0.0004070210852660239
step: 340, loss: 0.00029806490056216717
step: 350, loss: 0.002532206242904067
step: 360, loss: 0.0007399105816148221
step: 370, loss: 0.0001333054096903652
step: 380, loss: 0.0022032184060662985
epoch 15: dev_f1=0.810126582278481, f1=0.6592797783933517, best_f1=0.6028985507246377
step: 0, loss: 0.01457201223820448
step: 10, loss: 0.00319303129799664
step: 20, loss: 0.0009155586594715714
step: 30, loss: 0.0003053699037991464
step: 40, loss: 0.00030672436696477234
step: 50, loss: 0.00011052501940866932
step: 60, loss: 0.0028147357515990734
step: 70, loss: 0.0009178632753901184
step: 80, loss: 0.00011682188051054254
step: 90, loss: 0.03992530331015587
step: 100, loss: 0.005090775899589062
step: 110, loss: 0.0022455425933003426
step: 120, loss: 0.00014932781050447375
step: 130, loss: 0.05549399554729462
step: 140, loss: 0.0069832466542720795
step: 150, loss: 0.0007698047556914389
step: 160, loss: 0.00031428164220415056
step: 170, loss: 0.0028216952923685312
step: 180, loss: 0.0004147345316596329
step: 190, loss: 0.05157540366053581
step: 200, loss: 0.0006982567720115185
step: 210, loss: 0.0004664494772441685
step: 220, loss: 0.002254806226119399
step: 230, loss: 0.00399145158007741
step: 240, loss: 0.0038138392847031355
step: 250, loss: 0.004196545109152794
step: 260, loss: 0.0001391774567309767
step: 270, loss: 0.00014727753296028823
step: 280, loss: 0.00037108114338479936
step: 290, loss: 0.02110034041106701
step: 300, loss: 0.0019026814261451364
step: 310, loss: 0.003883483586832881
step: 320, loss: 0.001651401398703456
step: 330, loss: 0.0002175206900574267
step: 340, loss: 0.001254663453437388
step: 350, loss: 0.023834358900785446
step: 360, loss: 5.2850842621410266e-05
step: 370, loss: 0.0005609812214970589
step: 380, loss: 0.0012000806163996458
epoch 16: dev_f1=0.8123393316195373, f1=0.6498599439775911, best_f1=0.6028985507246377
step: 0, loss: 0.00028999996720813215
step: 10, loss: 0.0001496688782935962
step: 20, loss: 0.0005619158619083464
step: 30, loss: 0.0004250218626111746
step: 40, loss: 0.00020929175661876798
step: 50, loss: 0.0005170662770979106
step: 60, loss: 0.0014750827103853226
step: 70, loss: 0.0003581955679692328
step: 80, loss: 0.002084643580019474
step: 90, loss: 0.002992831403389573
step: 100, loss: 0.00028018199373036623
step: 110, loss: 0.0008539205882698298
step: 120, loss: 0.0006017889245413244
step: 130, loss: 0.0002451527107041329
step: 140, loss: 0.00012978103768546134
step: 150, loss: 9.77550953393802e-05
step: 160, loss: 0.0006305144634097815
step: 170, loss: 0.00018839607946574688
step: 180, loss: 0.0033155407290905714
step: 190, loss: 0.00016827599029056728
step: 200, loss: 0.00021733890753239393
step: 210, loss: 0.0001738943246891722
step: 220, loss: 0.03399180248379707
step: 230, loss: 0.0003944815543945879
step: 240, loss: 0.004803885705769062
step: 250, loss: 0.0004337563004810363
step: 260, loss: 0.0004018083564005792
step: 270, loss: 0.0007833380368538201
step: 280, loss: 0.00016694297664798796
step: 290, loss: 0.00020336681336630136
step: 300, loss: 0.00032644151360727847
step: 310, loss: 0.06369408965110779
step: 320, loss: 0.00013282496365718544
step: 330, loss: 0.09627813845872879
step: 340, loss: 0.0010593858314678073
step: 350, loss: 0.0005040057003498077
step: 360, loss: 0.0010904247174039483
step: 370, loss: 0.000528855191078037
step: 380, loss: 0.00010212994675384834
epoch 17: dev_f1=0.8053333333333333, f1=0.5784615384615385, best_f1=0.6028985507246377
step: 0, loss: 0.00038192319334484637
step: 10, loss: 0.012076332233846188
step: 20, loss: 0.000938151846639812
step: 30, loss: 0.003613091306760907
step: 40, loss: 0.00010045996168628335
step: 50, loss: 0.0018612691201269627
step: 60, loss: 0.0036225314252078533
step: 70, loss: 0.0001027681355481036
step: 80, loss: 0.0010868330718949437
step: 90, loss: 0.0004877852916251868
step: 100, loss: 0.00011924246791750193
step: 110, loss: 0.0055387080647051334
step: 120, loss: 0.0008449993911199272
step: 130, loss: 0.0016242697602137923
step: 140, loss: 0.012792670167982578
step: 150, loss: 0.0018196799792349339
step: 160, loss: 0.0008424648549407721
step: 170, loss: 0.00016845425125211477
step: 180, loss: 0.000368692068150267
step: 190, loss: 0.0006558021414093673
step: 200, loss: 0.0002183030592277646
step: 210, loss: 0.0004223926807753742
step: 220, loss: 0.0002864218258764595
step: 230, loss: 0.00011050137254642323
step: 240, loss: 0.00015215335588436574
step: 250, loss: 0.08698072284460068
step: 260, loss: 0.0011317121097818017
step: 270, loss: 0.0033116776030510664
step: 280, loss: 0.0001384552742820233
step: 290, loss: 0.00017847237177193165
step: 300, loss: 0.00020223073079250753
step: 310, loss: 0.01980138197541237
step: 320, loss: 0.0002241910988232121
step: 330, loss: 0.0001560416421853006
step: 340, loss: 0.0007159921224229038
step: 350, loss: 0.004431847017258406
step: 360, loss: 0.01467518787831068
step: 370, loss: 0.0006459971191361547
step: 380, loss: 0.00030314092873595655
epoch 18: dev_f1=0.8062015503875969, f1=0.6330532212885155, best_f1=0.6028985507246377
step: 0, loss: 0.0007111818995326757
step: 10, loss: 0.009090526029467583
step: 20, loss: 9.77710951701738e-05
step: 30, loss: 0.00029917791835032403
step: 40, loss: 0.0003912584506906569
step: 50, loss: 0.007396860979497433
step: 60, loss: 0.0001362786570098251
step: 70, loss: 0.0001771463721524924
step: 80, loss: 0.00020556719391606748
step: 90, loss: 0.0002287523093400523
step: 100, loss: 0.00014053622726351023
step: 110, loss: 4.013869693153538e-05
step: 120, loss: 8.405757398577407e-05
step: 130, loss: 0.0004103262326680124
step: 140, loss: 0.0002949819026980549
step: 150, loss: 0.00026248610811308026
step: 160, loss: 0.00015270333096850663
step: 170, loss: 0.00017251218378078192
step: 180, loss: 0.00039434651262126863
step: 190, loss: 0.00028242197004146874
step: 200, loss: 0.00036212350823916495
step: 210, loss: 0.0009163035429082811
step: 220, loss: 8.918411185732111e-05
step: 230, loss: 0.00038097158540040255
step: 240, loss: 0.012154747731983662
step: 250, loss: 0.000548636366147548
step: 260, loss: 0.00013805435446556658
step: 270, loss: 0.00018411039491184056
step: 280, loss: 0.00010897771426243708
step: 290, loss: 0.0019994359463453293
step: 300, loss: 0.00021770437888335437
step: 310, loss: 0.00023653947573620826
step: 320, loss: 0.0002049797330982983
step: 330, loss: 0.0004909363342449069
step: 340, loss: 0.0012875017710030079
step: 350, loss: 0.0021580467000603676
step: 360, loss: 0.0037354971282184124
step: 370, loss: 0.00021138113515917212
step: 380, loss: 0.00012382019485812634
epoch 19: dev_f1=0.8128342245989304, f1=0.5802469135802469, best_f1=0.6028985507246377
step: 0, loss: 0.0039680516347289085
step: 10, loss: 0.0011786562390625477
step: 20, loss: 0.00010765136539703235
step: 30, loss: 0.00017734985158313066
step: 40, loss: 0.0014419411309063435
step: 50, loss: 0.00027435808442533016
step: 60, loss: 0.0016015656292438507
step: 70, loss: 0.00045429018791764975
step: 80, loss: 0.0014583035372197628
step: 90, loss: 0.0001736233534757048
step: 100, loss: 0.009284735657274723
step: 110, loss: 0.00769457221031189
step: 120, loss: 0.0052889082580804825
step: 130, loss: 0.13933920860290527
step: 140, loss: 0.0002346564142499119
step: 150, loss: 0.00148907455150038
step: 160, loss: 0.0001549458538647741
step: 170, loss: 0.0006114092539064586
step: 180, loss: 0.0002292879216838628
step: 190, loss: 0.0001476731413276866
step: 200, loss: 0.00014783300866838545
step: 210, loss: 0.0002851167810149491
step: 220, loss: 9.509504161542282e-05
step: 230, loss: 0.00014526861195918173
step: 240, loss: 0.0006776180816814303
step: 250, loss: 4.635522054741159e-05
step: 260, loss: 0.00043212054879404604
step: 270, loss: 0.0002665399224497378
step: 280, loss: 0.00675756623968482
step: 290, loss: 0.01345879677683115
step: 300, loss: 0.0009170070989057422
step: 310, loss: 0.04553590342402458
step: 320, loss: 0.0001465548702981323
step: 330, loss: 0.00011045555584132671
step: 340, loss: 0.00024097634013742208
step: 350, loss: 0.00019708293257281184
step: 360, loss: 0.0003381549322512001
step: 370, loss: 0.00014519003161694854
step: 380, loss: 0.00011148853809572756
epoch 20: dev_f1=0.8130081300813009, f1=0.5723270440251572, best_f1=0.6028985507246377
