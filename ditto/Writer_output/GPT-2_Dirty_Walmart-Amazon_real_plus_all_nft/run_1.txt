cuda
Device: cuda
step: 0, loss: 0.7109742760658264
step: 10, loss: 0.38459068536758423
step: 20, loss: 0.16963277757167816
step: 30, loss: 0.33687716722488403
step: 40, loss: 0.36909452080726624
step: 50, loss: 0.35343146324157715
step: 60, loss: 0.41234660148620605
step: 70, loss: 0.10405008494853973
step: 80, loss: 0.3852202296257019
step: 90, loss: 0.4152732491493225
step: 100, loss: 0.1709369719028473
step: 110, loss: 0.11306634545326233
step: 120, loss: 0.4275696873664856
step: 130, loss: 0.1532864272594452
step: 140, loss: 0.40945324301719666
step: 150, loss: 0.33711278438568115
step: 160, loss: 0.14650559425354004
step: 170, loss: 0.16999869048595428
step: 180, loss: 0.2931745946407318
step: 190, loss: 0.09456447511911392
step: 200, loss: 0.15566658973693848
step: 210, loss: 0.4355321526527405
step: 220, loss: 0.40549153089523315
step: 230, loss: 0.230683833360672
step: 240, loss: 0.278629869222641
step: 250, loss: 0.1669689267873764
step: 260, loss: 0.17810675501823425
step: 270, loss: 0.0713120847940445
step: 280, loss: 0.3298496901988983
step: 290, loss: 0.22400881350040436
step: 300, loss: 0.3078160881996155
step: 310, loss: 0.1833808273077011
step: 320, loss: 0.2807730734348297
step: 330, loss: 0.2686624825000763
step: 340, loss: 0.2674345374107361
step: 350, loss: 0.20167477428913116
step: 360, loss: 0.34839674830436707
step: 370, loss: 0.1463174968957901
step: 380, loss: 0.2406170815229416
epoch 1: dev_f1=0.5541561712846347, f1=0.3701657458563536, best_f1=0.3701657458563536
step: 0, loss: 0.22044479846954346
step: 10, loss: 0.2844058573246002
step: 20, loss: 0.2430228888988495
step: 30, loss: 0.18188804388046265
step: 40, loss: 0.09798119962215424
step: 50, loss: 0.2419978529214859
step: 60, loss: 0.11976519227027893
step: 70, loss: 0.22035938501358032
step: 80, loss: 0.2149079293012619
step: 90, loss: 0.2604745924472809
step: 100, loss: 0.1406417340040207
step: 110, loss: 0.15207116305828094
step: 120, loss: 0.19408510625362396
step: 130, loss: 0.46015626192092896
step: 140, loss: 0.33811885118484497
step: 150, loss: 0.1861015409231186
step: 160, loss: 0.22401034832000732
step: 170, loss: 0.3478568494319916
step: 180, loss: 0.17540724575519562
step: 190, loss: 0.2420031726360321
step: 200, loss: 0.2031017541885376
step: 210, loss: 0.1942460834980011
step: 220, loss: 0.13455456495285034
step: 230, loss: 0.15537145733833313
step: 240, loss: 0.15442229807376862
step: 250, loss: 0.09618814289569855
step: 260, loss: 0.1489778310060501
step: 270, loss: 0.24284933507442474
step: 280, loss: 0.0705079436302185
step: 290, loss: 0.22509309649467468
step: 300, loss: 0.26477134227752686
step: 310, loss: 0.34244009852409363
step: 320, loss: 0.24885888397693634
step: 330, loss: 0.11045879125595093
step: 340, loss: 0.21388542652130127
step: 350, loss: 0.16078832745552063
step: 360, loss: 0.16829653084278107
step: 370, loss: 0.22793012857437134
step: 380, loss: 0.073265440762043
epoch 2: dev_f1=0.7281795511221945, f1=0.4919786096256685, best_f1=0.4919786096256685
step: 0, loss: 0.19948332011699677
step: 10, loss: 0.33915528655052185
step: 20, loss: 0.05781559646129608
step: 30, loss: 0.18188121914863586
step: 40, loss: 0.17425259947776794
step: 50, loss: 0.08718908578157425
step: 60, loss: 0.2873022258281708
step: 70, loss: 0.11149385571479797
step: 80, loss: 0.08088850229978561
step: 90, loss: 0.18487995862960815
step: 100, loss: 0.22218002378940582
step: 110, loss: 0.11749861389398575
step: 120, loss: 0.14979438483715057
step: 130, loss: 0.24515195190906525
step: 140, loss: 0.1790778785943985
step: 150, loss: 0.4214663505554199
step: 160, loss: 0.08486317843198776
step: 170, loss: 0.06938404589891434
step: 180, loss: 0.1259276121854782
step: 190, loss: 0.09951985627412796
step: 200, loss: 0.08509126305580139
step: 210, loss: 0.11090831458568573
step: 220, loss: 0.0497865155339241
step: 230, loss: 0.22611284255981445
step: 240, loss: 0.22956740856170654
step: 250, loss: 0.0789148211479187
step: 260, loss: 0.16984739899635315
step: 270, loss: 0.2988426685333252
step: 280, loss: 0.0782129094004631
step: 290, loss: 0.15478456020355225
step: 300, loss: 0.17593535780906677
step: 310, loss: 0.19132840633392334
step: 320, loss: 0.10235186666250229
step: 330, loss: 0.060453228652477264
step: 340, loss: 0.09890910238027573
step: 350, loss: 0.20580868422985077
step: 360, loss: 0.03192440792918205
step: 370, loss: 0.14485472440719604
step: 380, loss: 0.10378871113061905
epoch 3: dev_f1=0.7626666666666667, f1=0.4491017964071856, best_f1=0.4491017964071856
step: 0, loss: 0.11432725191116333
step: 10, loss: 0.10630679130554199
step: 20, loss: 0.08847684413194656
step: 30, loss: 0.023256244137883186
step: 40, loss: 0.4332242012023926
step: 50, loss: 0.14026953279972076
step: 60, loss: 0.040583230555057526
step: 70, loss: 0.2112044394016266
step: 80, loss: 0.02373392879962921
step: 90, loss: 0.15423275530338287
step: 100, loss: 0.05827604606747627
step: 110, loss: 0.21109887957572937
step: 120, loss: 0.12405776977539062
step: 130, loss: 0.1180150955915451
step: 140, loss: 0.03972235694527626
step: 150, loss: 0.13562001287937164
step: 160, loss: 0.09524501115083694
step: 170, loss: 0.042956482619047165
step: 180, loss: 0.07872628420591354
step: 190, loss: 0.09862121194601059
step: 200, loss: 0.16316162049770355
step: 210, loss: 0.3018510639667511
step: 220, loss: 0.2780216932296753
step: 230, loss: 0.061890676617622375
step: 240, loss: 0.2321108877658844
step: 250, loss: 0.019726373255252838
step: 260, loss: 0.22912055253982544
step: 270, loss: 0.061966415494680405
step: 280, loss: 0.033462151885032654
step: 290, loss: 0.08262568712234497
step: 300, loss: 0.033878035843372345
step: 310, loss: 0.08899874240159988
step: 320, loss: 0.19344106316566467
step: 330, loss: 0.08975908160209656
step: 340, loss: 0.030323317274451256
step: 350, loss: 0.048516128212213516
step: 360, loss: 0.15364018082618713
step: 370, loss: 0.07418039441108704
step: 380, loss: 0.20351247489452362
epoch 4: dev_f1=0.7864583333333334, f1=0.5428571428571427, best_f1=0.5428571428571427
step: 0, loss: 0.0771959125995636
step: 10, loss: 0.10941658169031143
step: 20, loss: 0.046742815524339676
step: 30, loss: 0.04505458474159241
step: 40, loss: 0.0271177776157856
step: 50, loss: 0.035568609833717346
step: 60, loss: 0.12417998164892197
step: 70, loss: 0.0331951305270195
step: 80, loss: 0.06100904941558838
step: 90, loss: 0.07705509662628174
step: 100, loss: 0.1536015272140503
step: 110, loss: 0.04770561307668686
step: 120, loss: 0.056123897433280945
step: 130, loss: 0.02426157146692276
step: 140, loss: 0.033293358981609344
step: 150, loss: 0.12086386233568192
step: 160, loss: 0.05005214735865593
step: 170, loss: 0.04768382012844086
step: 180, loss: 0.16169285774230957
step: 190, loss: 0.012383517809212208
step: 200, loss: 0.013228821568191051
step: 210, loss: 0.09760179370641708
step: 220, loss: 0.07370468974113464
step: 230, loss: 0.2019551396369934
step: 240, loss: 0.04390684515237808
step: 250, loss: 0.07013540714979172
step: 260, loss: 0.013948790729045868
step: 270, loss: 0.0759357437491417
step: 280, loss: 0.08856081962585449
step: 290, loss: 0.07086506485939026
step: 300, loss: 0.11941265314817429
step: 310, loss: 0.2430059015750885
step: 320, loss: 0.08241236954927444
step: 330, loss: 0.024593913927674294
step: 340, loss: 0.038856033235788345
step: 350, loss: 0.19616670906543732
step: 360, loss: 0.06572353839874268
step: 370, loss: 0.21168820559978485
step: 380, loss: 0.13665597140789032
epoch 5: dev_f1=0.8108108108108106, f1=0.5508982035928144, best_f1=0.5508982035928144
step: 0, loss: 0.10415703058242798
step: 10, loss: 0.011911057867109776
step: 20, loss: 0.03354032337665558
step: 30, loss: 0.03896674886345863
step: 40, loss: 0.11429844796657562
step: 50, loss: 0.02104366011917591
step: 60, loss: 0.027241555973887444
step: 70, loss: 0.10976596176624298
step: 80, loss: 0.07403629273176193
step: 90, loss: 0.1308460831642151
step: 100, loss: 0.01826123148202896
step: 110, loss: 0.24152937531471252
step: 120, loss: 0.03831568732857704
step: 130, loss: 0.09426281601190567
step: 140, loss: 0.015918083488941193
step: 150, loss: 0.19066213071346283
step: 160, loss: 0.012248131446540356
step: 170, loss: 0.03944975510239601
step: 180, loss: 0.0037440634332597256
step: 190, loss: 0.009480834938585758
step: 200, loss: 0.026223262771964073
step: 210, loss: 0.0652976855635643
step: 220, loss: 0.03154988959431648
step: 230, loss: 0.02892640233039856
step: 240, loss: 0.08919575810432434
step: 250, loss: 0.03247468173503876
step: 260, loss: 0.1486438661813736
step: 270, loss: 0.01962205395102501
step: 280, loss: 0.1295224279165268
step: 290, loss: 0.0699845552444458
step: 300, loss: 0.04157455265522003
step: 310, loss: 0.045302197337150574
step: 320, loss: 0.06589281558990479
step: 330, loss: 0.09521559625864029
step: 340, loss: 0.0853363499045372
step: 350, loss: 0.020424561575055122
step: 360, loss: 0.0561818964779377
step: 370, loss: 0.06633413583040237
step: 380, loss: 0.0067191291600465775
epoch 6: dev_f1=0.8235294117647058, f1=0.5477707006369427, best_f1=0.5477707006369427
step: 0, loss: 0.046651020646095276
step: 10, loss: 0.01756320148706436
step: 20, loss: 0.019475407898426056
step: 30, loss: 0.004548013675957918
step: 40, loss: 0.014566496014595032
step: 50, loss: 0.024149024859070778
step: 60, loss: 0.026983138173818588
step: 70, loss: 0.13531123101711273
step: 80, loss: 0.02763601951301098
step: 90, loss: 0.0023861913941800594
step: 100, loss: 0.052642371505498886
step: 110, loss: 0.056175753474235535
step: 120, loss: 0.07288584858179092
step: 130, loss: 0.049298178404569626
step: 140, loss: 0.03808040916919708
step: 150, loss: 0.0056911250576376915
step: 160, loss: 0.002514162100851536
step: 170, loss: 0.05433596670627594
step: 180, loss: 0.023184318095445633
step: 190, loss: 0.193831667304039
step: 200, loss: 0.04932693764567375
step: 210, loss: 0.01275849062949419
step: 220, loss: 0.0019072084687650204
step: 230, loss: 0.026522748172283173
step: 240, loss: 0.054548464715480804
step: 250, loss: 0.03621815890073776
step: 260, loss: 0.08396218717098236
step: 270, loss: 0.04709402099251747
step: 280, loss: 0.019107097759842873
step: 290, loss: 0.02505416050553322
step: 300, loss: 0.025120096281170845
step: 310, loss: 0.12720559537410736
step: 320, loss: 0.14694635570049286
step: 330, loss: 0.09255421161651611
step: 340, loss: 0.011787638068199158
step: 350, loss: 0.014106102287769318
step: 360, loss: 0.03168501704931259
step: 370, loss: 0.0070054312236607075
step: 380, loss: 0.040142711251974106
epoch 7: dev_f1=0.7967479674796748, f1=0.5090909090909091, best_f1=0.5477707006369427
step: 0, loss: 0.029177891090512276
step: 10, loss: 0.12580634653568268
step: 20, loss: 0.0091923289000988
step: 30, loss: 0.007294936571270227
step: 40, loss: 0.0023262074682861567
step: 50, loss: 0.008544223383069038
step: 60, loss: 0.06361663341522217
step: 70, loss: 0.06070685386657715
step: 80, loss: 0.0004629834438674152
step: 90, loss: 0.10116171836853027
step: 100, loss: 0.06927620619535446
step: 110, loss: 0.010975908488035202
step: 120, loss: 0.0009320962126366794
step: 130, loss: 0.003420711262151599
step: 140, loss: 0.12225306779146194
step: 150, loss: 0.054571956396102905
step: 160, loss: 0.0010131917661055923
step: 170, loss: 0.004377616103738546
step: 180, loss: 0.03794322907924652
step: 190, loss: 0.005150464829057455
step: 200, loss: 0.10209228843450546
step: 210, loss: 0.010896760039031506
step: 220, loss: 0.029979677870869637
step: 230, loss: 0.0008897135267034173
step: 240, loss: 0.0034506942611187696
step: 250, loss: 0.01677754707634449
step: 260, loss: 0.005432265345007181
step: 270, loss: 0.04719673842191696
step: 280, loss: 0.0881824642419815
step: 290, loss: 0.0011367114493623376
step: 300, loss: 0.03681974858045578
step: 310, loss: 0.007117907982319593
step: 320, loss: 0.022102639079093933
step: 330, loss: 0.012509615160524845
step: 340, loss: 0.11172549426555634
step: 350, loss: 0.06619912385940552
step: 360, loss: 0.01122007891535759
step: 370, loss: 0.012539100833237171
step: 380, loss: 0.0535261407494545
epoch 8: dev_f1=0.8010899182561309, f1=0.458204334365325, best_f1=0.5477707006369427
step: 0, loss: 0.0022533023729920387
step: 10, loss: 0.023052383214235306
step: 20, loss: 0.01350878830999136
step: 30, loss: 0.018751390278339386
step: 40, loss: 0.11276447027921677
step: 50, loss: 0.0004719942808151245
step: 60, loss: 0.005384902935475111
step: 70, loss: 0.0015216483734548092
step: 80, loss: 0.06729978322982788
step: 90, loss: 0.00584848877042532
step: 100, loss: 0.0011349826818332076
step: 110, loss: 0.054366450756788254
step: 120, loss: 0.020849794149398804
step: 130, loss: 0.013987946324050426
step: 140, loss: 0.08444994688034058
step: 150, loss: 0.005648463033139706
step: 160, loss: 0.004432770889252424
step: 170, loss: 0.002855375874787569
step: 180, loss: 0.007188752293586731
step: 190, loss: 0.014618419110774994
step: 200, loss: 0.0006850120844319463
step: 210, loss: 0.004377315286546946
step: 220, loss: 0.07357192784547806
step: 230, loss: 0.033299520611763
step: 240, loss: 0.004375857301056385
step: 250, loss: 0.05834135785698891
step: 260, loss: 0.011945885606110096
step: 270, loss: 0.0007597033982165158
step: 280, loss: 0.05392618849873543
step: 290, loss: 0.17428912222385406
step: 300, loss: 0.004821962211281061
step: 310, loss: 0.0011041387915611267
step: 320, loss: 0.04533911123871803
step: 330, loss: 0.003519963938742876
step: 340, loss: 0.0015281321248039603
step: 350, loss: 0.014262134209275246
step: 360, loss: 0.0038516551721841097
step: 370, loss: 0.033975232392549515
step: 380, loss: 0.0287544596940279
epoch 9: dev_f1=0.8060453400503779, f1=0.6277777777777778, best_f1=0.5477707006369427
step: 0, loss: 0.0017565225716680288
step: 10, loss: 0.0017860319931060076
step: 20, loss: 0.01296067051589489
step: 30, loss: 0.003374524647369981
step: 40, loss: 0.0032261074520647526
step: 50, loss: 0.007409082725644112
step: 60, loss: 0.001975543098524213
step: 70, loss: 0.0026564113795757294
step: 80, loss: 0.014995330944657326
step: 90, loss: 0.05164579674601555
step: 100, loss: 0.1318543702363968
step: 110, loss: 0.0007495845202356577
step: 120, loss: 0.0006906591588631272
step: 130, loss: 0.05518605560064316
step: 140, loss: 0.007860979065299034
step: 150, loss: 0.046127401292324066
step: 160, loss: 0.0009393186774104834
step: 170, loss: 0.004345982801169157
step: 180, loss: 0.0010698821861296892
step: 190, loss: 0.0022698012180626392
step: 200, loss: 0.000561328197363764
step: 210, loss: 0.00034522500936873257
step: 220, loss: 0.0007933371816761792
step: 230, loss: 0.015558011829853058
step: 240, loss: 0.046062152832746506
step: 250, loss: 0.09819871932268143
step: 260, loss: 0.007721057627350092
step: 270, loss: 0.00079482386354357
step: 280, loss: 0.000568930699955672
step: 290, loss: 0.0013617118820548058
step: 300, loss: 0.04504822567105293
step: 310, loss: 0.03712492063641548
step: 320, loss: 0.010656940750777721
step: 330, loss: 0.029527124017477036
step: 340, loss: 0.012999733909964561
step: 350, loss: 0.034087661653757095
step: 360, loss: 0.052824873477220535
step: 370, loss: 0.23003390431404114
step: 380, loss: 0.00740732392296195
epoch 10: dev_f1=0.8195121951219512, f1=0.6422976501305484, best_f1=0.5477707006369427
step: 0, loss: 0.01651112176477909
step: 10, loss: 0.007506974507123232
step: 20, loss: 0.0008128260960802436
step: 30, loss: 0.0016690127085894346
step: 40, loss: 0.01728753186762333
step: 50, loss: 0.0007306356565095484
step: 60, loss: 0.0004312416131142527
step: 70, loss: 0.0013251162599772215
step: 80, loss: 0.005587965715676546
step: 90, loss: 0.004929086659103632
step: 100, loss: 0.0019118648488074541
step: 110, loss: 0.005928901024162769
step: 120, loss: 0.00020834118186030537
step: 130, loss: 0.009730019606649876
step: 140, loss: 0.008354177698493004
step: 150, loss: 0.002179796574637294
step: 160, loss: 0.0038090164307504892
step: 170, loss: 0.06412152200937271
step: 180, loss: 0.0008085513836704195
step: 190, loss: 0.0016275027301162481
step: 200, loss: 0.0005517942481674254
step: 210, loss: 0.00972435437142849
step: 220, loss: 0.0018774046329781413
step: 230, loss: 0.00046424937318079174
step: 240, loss: 0.001903895870782435
step: 250, loss: 0.14542855322360992
step: 260, loss: 0.0005698615568690002
step: 270, loss: 0.06747665256261826
step: 280, loss: 0.00024666148237884045
step: 290, loss: 0.00017060250684153289
step: 300, loss: 0.0012291667517274618
step: 310, loss: 0.002724836813285947
step: 320, loss: 0.00035394451697357
step: 330, loss: 0.014317505992949009
step: 340, loss: 0.0007105302647687495
step: 350, loss: 0.0011420672526583076
step: 360, loss: 0.0012387919705361128
step: 370, loss: 0.0017686131177470088
step: 380, loss: 0.004428304266184568
epoch 11: dev_f1=0.8153846153846155, f1=0.6132596685082873, best_f1=0.5477707006369427
step: 0, loss: 0.001529004075564444
step: 10, loss: 0.048244040459394455
step: 20, loss: 0.0035222265869379044
step: 30, loss: 0.013976458460092545
step: 40, loss: 0.00022160139633342624
step: 50, loss: 0.0028000841848552227
step: 60, loss: 0.0051188161596655846
step: 70, loss: 0.017514970153570175
step: 80, loss: 0.0031503259669989347
step: 90, loss: 0.001120676752179861
step: 100, loss: 0.0002633785188663751
step: 110, loss: 0.001059956499375403
step: 120, loss: 0.0007922029471956193
step: 130, loss: 0.01776728220283985
step: 140, loss: 0.05689622834324837
step: 150, loss: 0.00027193792629987
step: 160, loss: 0.0021284723188728094
step: 170, loss: 0.0393378809094429
step: 180, loss: 0.023701362311840057
step: 190, loss: 0.0004244923184160143
step: 200, loss: 0.012947944924235344
step: 210, loss: 0.0017923185368999839
step: 220, loss: 0.002312809694558382
step: 230, loss: 0.0011007385328412056
step: 240, loss: 0.0016238614916801453
step: 250, loss: 0.004337746184319258
step: 260, loss: 0.003657940775156021
step: 270, loss: 0.0013205278664827347
step: 280, loss: 0.007303192280232906
step: 290, loss: 0.0028069911058992147
step: 300, loss: 0.029471946880221367
step: 310, loss: 0.002568675670772791
step: 320, loss: 0.00415004650130868
step: 330, loss: 0.006352739408612251
step: 340, loss: 0.11010464280843735
step: 350, loss: 0.010988470166921616
step: 360, loss: 0.0005416162312030792
step: 370, loss: 0.0019619029480963945
step: 380, loss: 0.00045746759860776365
epoch 12: dev_f1=0.7979274611398963, f1=0.6051873198847263, best_f1=0.5477707006369427
step: 0, loss: 0.0018595489673316479
step: 10, loss: 0.0011686432408168912
step: 20, loss: 0.0011331288842484355
step: 30, loss: 0.003713109064847231
step: 40, loss: 0.0010412491392344236
step: 50, loss: 0.00048458922537975013
step: 60, loss: 0.0011271813418716192
step: 70, loss: 0.000757017987780273
step: 80, loss: 0.005288539454340935
step: 90, loss: 0.0009499667794443667
step: 100, loss: 0.0014575684908777475
step: 110, loss: 0.002421331824734807
step: 120, loss: 0.003979173023253679
step: 130, loss: 0.000700137228704989
step: 140, loss: 5.601427983492613e-05
step: 150, loss: 0.0008331837016157806
step: 160, loss: 0.0002579927968326956
step: 170, loss: 0.003329558065161109
step: 180, loss: 0.0008292706334032118
step: 190, loss: 0.007539409212768078
step: 200, loss: 0.0018868030747398734
step: 210, loss: 0.031267907470464706
step: 220, loss: 0.0022977187763899565
step: 230, loss: 0.00018782084225676954
step: 240, loss: 0.046825509518384933
step: 250, loss: 0.3012983798980713
step: 260, loss: 0.003141802502796054
step: 270, loss: 0.005662570707499981
step: 280, loss: 0.0011170130455866456
step: 290, loss: 0.016251815482974052
step: 300, loss: 0.002935851691290736
step: 310, loss: 0.0004901522188447416
step: 320, loss: 0.014155087061226368
step: 330, loss: 0.0005397030035965145
step: 340, loss: 0.0009210962452925742
step: 350, loss: 6.0550501075340435e-05
step: 360, loss: 0.00036874724901281297
step: 370, loss: 0.0032731459941715
step: 380, loss: 0.0008416968048550189
epoch 13: dev_f1=0.820253164556962, f1=0.6229508196721311, best_f1=0.5477707006369427
step: 0, loss: 0.0005548601038753986
step: 10, loss: 0.00034767042961902916
step: 20, loss: 0.03748266026377678
step: 30, loss: 0.00016234823851846159
step: 40, loss: 0.006485230289399624
step: 50, loss: 0.0004598670348059386
step: 60, loss: 0.0025009592063724995
step: 70, loss: 0.012138981372117996
step: 80, loss: 0.003983266185969114
step: 90, loss: 0.001992356264963746
step: 100, loss: 0.005295674316585064
step: 110, loss: 0.002768169855698943
step: 120, loss: 0.0012914113467559218
step: 130, loss: 0.003668071236461401
step: 140, loss: 0.00040799842099659145
step: 150, loss: 0.00274792592972517
step: 160, loss: 0.005272717215120792
step: 170, loss: 0.025726472958922386
step: 180, loss: 0.014210463501513004
step: 190, loss: 0.002462090225890279
step: 200, loss: 0.002075572032481432
step: 210, loss: 0.00797666423022747
step: 220, loss: 0.0012604055227711797
step: 230, loss: 0.005320358090102673
step: 240, loss: 3.0457338652922772e-05
step: 250, loss: 0.0006479267030954361
step: 260, loss: 0.0002043926651822403
step: 270, loss: 0.004293335136026144
step: 280, loss: 0.0002494043728802353
step: 290, loss: 0.00015153684944380075
step: 300, loss: 0.003246661741286516
step: 310, loss: 0.0020868375431746244
step: 320, loss: 0.0003425822069402784
step: 330, loss: 0.009844782762229443
step: 340, loss: 0.0005617234273813665
step: 350, loss: 0.00021713683963753283
step: 360, loss: 5.1353876187931746e-05
step: 370, loss: 0.00013415577996056527
step: 380, loss: 0.00039594442932866514
epoch 14: dev_f1=0.8010610079575596, f1=0.5568862275449102, best_f1=0.5477707006369427
step: 0, loss: 0.0005379084614105523
step: 10, loss: 0.001087192795239389
step: 20, loss: 0.10510862618684769
step: 30, loss: 0.0007713058148510754
step: 40, loss: 0.0001465659443056211
step: 50, loss: 0.00021129824745003134
step: 60, loss: 0.0018380933906883001
step: 70, loss: 0.0018703257665038109
step: 80, loss: 0.00023565252195112407
step: 90, loss: 0.008484676480293274
step: 100, loss: 0.0059936936013400555
step: 110, loss: 0.015652455389499664
step: 120, loss: 0.004908341448754072
step: 130, loss: 0.00048423733096569777
step: 140, loss: 0.000950259156525135
step: 150, loss: 0.002780493814498186
step: 160, loss: 0.010806641541421413
step: 170, loss: 0.007738793268799782
step: 180, loss: 0.0003097997105214745
step: 190, loss: 0.0003722268156707287
step: 200, loss: 0.0001980004453798756
step: 210, loss: 0.0001625750446692109
step: 220, loss: 0.0005669287056662142
step: 230, loss: 0.0018707358976826072
step: 240, loss: 7.792097312631086e-05
step: 250, loss: 7.086824916768819e-05
step: 260, loss: 0.00019124546088278294
step: 270, loss: 0.0018787774024531245
step: 280, loss: 0.0002742312790360302
step: 290, loss: 0.0020893816836178303
step: 300, loss: 0.00446726381778717
step: 310, loss: 0.005691720172762871
step: 320, loss: 0.001961711561307311
step: 330, loss: 0.05347423255443573
step: 340, loss: 0.00325292581692338
step: 350, loss: 0.00181071856059134
step: 360, loss: 0.0003186047251801938
step: 370, loss: 0.002233897801488638
step: 380, loss: 0.001097959466278553
epoch 15: dev_f1=0.8181818181818181, f1=0.5362776025236593, best_f1=0.5477707006369427
step: 0, loss: 0.0003362538118381053
step: 10, loss: 7.120994268916547e-05
step: 20, loss: 0.00039999725413508713
step: 30, loss: 0.00045074045192450285
step: 40, loss: 0.007453247904777527
step: 50, loss: 0.0007010214030742645
step: 60, loss: 0.0002869979362003505
step: 70, loss: 0.0018595407018437982
step: 80, loss: 0.0009374387445859611
step: 90, loss: 7.395294960588217e-05
step: 100, loss: 0.002035464160144329
step: 110, loss: 0.0010272904764860868
step: 120, loss: 0.0003827060281764716
step: 130, loss: 0.00011352849105605856
step: 140, loss: 0.0001950437726918608
step: 150, loss: 4.2252660932717845e-05
step: 160, loss: 0.0012951763346791267
step: 170, loss: 0.0054438915103673935
step: 180, loss: 0.0005620595766231418
step: 190, loss: 0.0005214736447669566
step: 200, loss: 0.0032231078948825598
step: 210, loss: 0.0003418686392251402
step: 220, loss: 0.0017929465975612402
step: 230, loss: 0.0014834718313068151
step: 240, loss: 0.00030484952731058
step: 250, loss: 0.007210236508399248
step: 260, loss: 0.00012792313646059483
step: 270, loss: 0.0001496978511568159
step: 280, loss: 0.0010323359165340662
step: 290, loss: 0.004270366858690977
step: 300, loss: 0.00016147033602464944
step: 310, loss: 0.00016452580166514963
step: 320, loss: 8.346069080289453e-05
step: 330, loss: 0.006105090491473675
step: 340, loss: 0.00028413068503141403
step: 350, loss: 6.680975639028475e-05
step: 360, loss: 0.02934427745640278
step: 370, loss: 0.007835849188268185
step: 380, loss: 0.01221474353224039
epoch 16: dev_f1=0.7979539641943734, f1=0.6174863387978142, best_f1=0.5477707006369427
step: 0, loss: 0.0032211346551775932
step: 10, loss: 0.0004659137630369514
step: 20, loss: 0.0006551594706252217
step: 30, loss: 0.001251662033610046
step: 40, loss: 0.00011377714690752327
step: 50, loss: 0.039205584675073624
step: 60, loss: 0.008694808930158615
step: 70, loss: 0.00414227694272995
step: 80, loss: 0.0010017097229138017
step: 90, loss: 0.0004073832824360579
step: 100, loss: 0.0011926848674193025
step: 110, loss: 0.06509623676538467
step: 120, loss: 0.007809543516486883
step: 130, loss: 0.00036942941369488835
step: 140, loss: 0.00023882868117652833
step: 150, loss: 0.0001814385032048449
step: 160, loss: 0.00019304546003695577
step: 170, loss: 0.009297442622482777
step: 180, loss: 0.00035769218811765313
step: 190, loss: 0.0018705561524257064
step: 200, loss: 0.0032067124266177416
step: 210, loss: 0.0014742766506969929
step: 220, loss: 0.00017378570919390768
step: 230, loss: 0.0005512951756827533
step: 240, loss: 4.643818465410732e-05
step: 250, loss: 0.0009432722581550479
step: 260, loss: 0.0002667151275090873
step: 270, loss: 0.00042425471474416554
step: 280, loss: 0.00014603677846025676
step: 290, loss: 0.022993534803390503
step: 300, loss: 0.0013169572921469808
step: 310, loss: 4.8451438487973064e-05
step: 320, loss: 0.0009770778706297278
step: 330, loss: 0.07682707160711288
step: 340, loss: 8.274176070699468e-05
step: 350, loss: 0.00013259511615615338
step: 360, loss: 6.624955858569592e-05
step: 370, loss: 0.00013169882004149258
step: 380, loss: 6.791314081056044e-05
epoch 17: dev_f1=0.7823834196891192, f1=0.6096866096866097, best_f1=0.5477707006369427
step: 0, loss: 0.00013172869512345642
step: 10, loss: 0.00046316825319081545
step: 20, loss: 0.00016903724463190883
step: 30, loss: 0.0053591360338032246
step: 40, loss: 0.00012851333303842694
step: 50, loss: 0.00018891535000875592
step: 60, loss: 0.0005324794910848141
step: 70, loss: 0.0011187870986759663
step: 80, loss: 0.0006516114226542413
step: 90, loss: 0.0015830625779926777
step: 100, loss: 0.0003139922919217497
step: 110, loss: 9.339798270957544e-05
step: 120, loss: 0.0014978203689679503
step: 130, loss: 5.211757525103167e-05
step: 140, loss: 0.000692506495397538
step: 150, loss: 0.00012655489263124764
step: 160, loss: 0.00015696299669798464
step: 170, loss: 4.861803608946502e-05
step: 180, loss: 0.0015379959950223565
step: 190, loss: 0.0002805459953378886
step: 200, loss: 0.0001320220617344603
step: 210, loss: 5.7178411225322634e-05
step: 220, loss: 6.565073999809101e-05
step: 230, loss: 0.00025793982786126435
step: 240, loss: 0.00030844577122479677
step: 250, loss: 0.0001810065150493756
step: 260, loss: 0.0013705258024856448
step: 270, loss: 0.00024127072538249195
step: 280, loss: 0.00011340713535901159
step: 290, loss: 0.000431555206887424
step: 300, loss: 0.00015530416567344218
step: 310, loss: 0.017765164375305176
step: 320, loss: 0.00012300715025048703
step: 330, loss: 0.00020009060972370207
step: 340, loss: 0.0003462430613581091
step: 350, loss: 0.0004240903363097459
step: 360, loss: 0.00012951347162015736
step: 370, loss: 3.1975298043107614e-05
step: 380, loss: 0.0005170910735614598
epoch 18: dev_f1=0.7969924812030076, f1=0.6246575342465753, best_f1=0.5477707006369427
step: 0, loss: 2.979758028232027e-05
step: 10, loss: 0.00014802490477450192
step: 20, loss: 0.004993913695216179
step: 30, loss: 0.0005592019879259169
step: 40, loss: 9.296945063397288e-05
step: 50, loss: 0.000849493604619056
step: 60, loss: 0.003319504437968135
step: 70, loss: 0.00026443719980306923
step: 80, loss: 0.00011334997543599457
step: 90, loss: 9.141799091594294e-05
step: 100, loss: 0.0007498907507397234
step: 110, loss: 0.00016213097842410207
step: 120, loss: 0.0006526170182041824
step: 130, loss: 6.62046586512588e-05
step: 140, loss: 0.0016918900655582547
step: 150, loss: 4.690486821345985e-05
step: 160, loss: 0.0014297246234491467
step: 170, loss: 0.00023804443480912596
step: 180, loss: 0.00014213118993211538
step: 190, loss: 0.0027706357650458813
step: 200, loss: 0.0002926326997112483
step: 210, loss: 0.00021621439373120666
step: 220, loss: 0.00013916418538428843
step: 230, loss: 0.0009457667474634945
step: 240, loss: 0.011774045415222645
step: 250, loss: 0.001057975459843874
step: 260, loss: 0.00024092420062515885
step: 270, loss: 0.0002811299345921725
step: 280, loss: 4.6700512029929087e-05
step: 290, loss: 9.963120828615502e-05
step: 300, loss: 0.0001658880792092532
step: 310, loss: 0.14989471435546875
step: 320, loss: 0.0033870129846036434
step: 330, loss: 0.006667468696832657
step: 340, loss: 0.00010769209620775655
step: 350, loss: 0.00010809754894580692
step: 360, loss: 0.0016520562348887324
step: 370, loss: 0.00013670993212144822
step: 380, loss: 0.0010242831194773316
epoch 19: dev_f1=0.7969924812030076, f1=0.6174863387978142, best_f1=0.5477707006369427
step: 0, loss: 0.005801567807793617
step: 10, loss: 0.00013224573922343552
step: 20, loss: 0.0002181585441576317
step: 30, loss: 0.004425615072250366
step: 40, loss: 0.0008860676316544414
step: 50, loss: 0.00045705525553785264
step: 60, loss: 0.0002902232517953962
step: 70, loss: 0.0005741975619457662
step: 80, loss: 0.0002927333989646286
step: 90, loss: 9.841252904152498e-05
step: 100, loss: 5.7701876357896253e-05
step: 110, loss: 0.00024086213670670986
step: 120, loss: 0.0001475557655794546
step: 130, loss: 0.0001056080000125803
step: 140, loss: 0.00010136775381397456
step: 150, loss: 9.87498351605609e-05
step: 160, loss: 4.034589073853567e-05
step: 170, loss: 0.00015326807624660432
step: 180, loss: 3.420430948608555e-05
step: 190, loss: 0.00035689142532646656
step: 200, loss: 0.00013200716057326645
step: 210, loss: 6.968489469727501e-05
step: 220, loss: 2.564429996709805e-05
step: 230, loss: 0.0006762021803297102
step: 240, loss: 9.114856948144734e-05
step: 250, loss: 0.0003946651704609394
step: 260, loss: 0.002782952506095171
step: 270, loss: 0.0009153534774668515
step: 280, loss: 0.0008844995754770935
step: 290, loss: 0.00025287055177614093
step: 300, loss: 0.00179312436375767
step: 310, loss: 0.00012825155863538384
step: 320, loss: 0.0005330419517122209
step: 330, loss: 9.104082710109651e-05
step: 340, loss: 0.0003329169994685799
step: 350, loss: 5.632264583255164e-05
step: 360, loss: 0.0002753481676336378
step: 370, loss: 0.00043471186654642224
step: 380, loss: 0.00016741963918320835
epoch 20: dev_f1=0.7958656330749353, f1=0.6051873198847263, best_f1=0.5477707006369427
