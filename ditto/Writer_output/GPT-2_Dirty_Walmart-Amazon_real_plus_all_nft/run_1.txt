cuda
Device: cuda
step: 0, loss: 0.8263697624206543
step: 10, loss: 0.5503553748130798
step: 20, loss: 0.2509267032146454
step: 30, loss: 0.07231616228818893
step: 40, loss: 0.24383947253227234
step: 50, loss: 0.16662253439426422
step: 60, loss: 0.16200724244117737
step: 70, loss: 0.23364335298538208
step: 80, loss: 0.37994635105133057
step: 90, loss: 0.30073368549346924
step: 100, loss: 0.22779439389705658
step: 110, loss: 0.2902489900588989
step: 120, loss: 0.3023466467857361
step: 130, loss: 0.3364558219909668
step: 140, loss: 0.3785918951034546
step: 150, loss: 0.35458430647850037
step: 160, loss: 0.21452493965625763
step: 170, loss: 0.2908339500427246
step: 180, loss: 0.2934795618057251
step: 190, loss: 0.355657160282135
step: 200, loss: 0.35355833172798157
step: 210, loss: 0.3346971571445465
step: 220, loss: 0.4546148180961609
step: 230, loss: 0.3433767557144165
step: 240, loss: 0.28949111700057983
step: 250, loss: 0.27085965871810913
step: 260, loss: 0.21293999254703522
step: 270, loss: 0.3441464900970459
step: 280, loss: 0.14658427238464355
step: 290, loss: 0.20647189021110535
step: 300, loss: 0.3493439853191376
step: 310, loss: 0.12141214311122894
step: 320, loss: 0.2989242672920227
step: 330, loss: 0.5013904571533203
step: 340, loss: 0.26108047366142273
step: 350, loss: 0.2686525285243988
step: 360, loss: 0.2833194136619568
step: 370, loss: 0.29510045051574707
step: 380, loss: 0.3524388372898102
epoch 1: dev_f1=0.5011494252873564, f1=0.3201970443349753, best_f1=0.3201970443349753
step: 0, loss: 0.21099291741847992
step: 10, loss: 0.363007128238678
step: 20, loss: 0.06141454726457596
step: 30, loss: 0.22202599048614502
step: 40, loss: 0.38407790660858154
step: 50, loss: 0.07760018110275269
step: 60, loss: 0.11913087218999863
step: 70, loss: 0.2456960827112198
step: 80, loss: 0.3139919638633728
step: 90, loss: 0.28388702869415283
step: 100, loss: 0.2518424093723297
step: 110, loss: 0.17370563745498657
step: 120, loss: 0.20812349021434784
step: 130, loss: 0.3010139465332031
step: 140, loss: 0.21353979408740997
step: 150, loss: 0.2537686824798584
step: 160, loss: 0.11095650494098663
step: 170, loss: 0.3986799716949463
step: 180, loss: 0.1571219116449356
step: 190, loss: 0.21348457038402557
step: 200, loss: 0.23202747106552124
step: 210, loss: 0.22435450553894043
step: 220, loss: 0.2139754295349121
step: 230, loss: 0.17585337162017822
step: 240, loss: 0.1393362432718277
step: 250, loss: 0.4117150604724884
step: 260, loss: 0.15208639204502106
step: 270, loss: 0.20384015142917633
step: 280, loss: 0.21055307984352112
step: 290, loss: 0.2129751294851303
step: 300, loss: 0.13792017102241516
step: 310, loss: 0.14426976442337036
step: 320, loss: 0.22445856034755707
step: 330, loss: 0.24148064851760864
step: 340, loss: 0.13414150476455688
step: 350, loss: 0.3305279016494751
step: 360, loss: 0.12088785320520401
step: 370, loss: 0.1397724449634552
step: 380, loss: 0.08399275690317154
epoch 2: dev_f1=0.7132169576059851, f1=0.4739583333333333, best_f1=0.4739583333333333
step: 0, loss: 0.10626126080751419
step: 10, loss: 0.18166714906692505
step: 20, loss: 0.18543538451194763
step: 30, loss: 0.024898551404476166
step: 40, loss: 0.20645231008529663
step: 50, loss: 0.022842079401016235
step: 60, loss: 0.11541785299777985
step: 70, loss: 0.17227302491664886
step: 80, loss: 0.20663480460643768
step: 90, loss: 0.18574166297912598
step: 100, loss: 0.09760477393865585
step: 110, loss: 0.04775456339120865
step: 120, loss: 0.2569722831249237
step: 130, loss: 0.24135632812976837
step: 140, loss: 0.22261330485343933
step: 150, loss: 0.1413360834121704
step: 160, loss: 0.10884663462638855
step: 170, loss: 0.07542646676301956
step: 180, loss: 0.2742745876312256
step: 190, loss: 0.1698792576789856
step: 200, loss: 0.12302786111831665
step: 210, loss: 0.019319532439112663
step: 220, loss: 0.24734462797641754
step: 230, loss: 0.3105352222919464
step: 240, loss: 0.18747232854366302
step: 250, loss: 0.21949104964733124
step: 260, loss: 0.2032867968082428
step: 270, loss: 0.11350597441196442
step: 280, loss: 0.33801543712615967
step: 290, loss: 0.2827390730381012
step: 300, loss: 0.13211050629615784
step: 310, loss: 0.17734839022159576
step: 320, loss: 0.0686347633600235
step: 330, loss: 0.12947453558444977
step: 340, loss: 0.11250437051057816
step: 350, loss: 0.16365812718868256
step: 360, loss: 0.20771701633930206
step: 370, loss: 0.08649247884750366
step: 380, loss: 0.1639113575220108
epoch 3: dev_f1=0.7757255936675462, f1=0.4955752212389381, best_f1=0.4955752212389381
step: 0, loss: 0.18696229159832
step: 10, loss: 0.14506781101226807
step: 20, loss: 0.09821799397468567
step: 30, loss: 0.013698181137442589
step: 40, loss: 0.43338340520858765
step: 50, loss: 0.09739553183317184
step: 60, loss: 0.0919644683599472
step: 70, loss: 0.15477345883846283
step: 80, loss: 0.1148182824254036
step: 90, loss: 0.02014094404876232
step: 100, loss: 0.00991501659154892
step: 110, loss: 0.20084691047668457
step: 120, loss: 0.16016843914985657
step: 130, loss: 0.062463920563459396
step: 140, loss: 0.0762503370642662
step: 150, loss: 0.13932132720947266
step: 160, loss: 0.1494053453207016
step: 170, loss: 0.06025506183505058
step: 180, loss: 0.119090735912323
step: 190, loss: 0.1648482233285904
step: 200, loss: 0.09572845697402954
step: 210, loss: 0.19636420905590057
step: 220, loss: 0.06900233030319214
step: 230, loss: 0.13726162910461426
step: 240, loss: 0.025041112676262856
step: 250, loss: 0.005446583032608032
step: 260, loss: 0.019972342997789383
step: 270, loss: 0.06053570657968521
step: 280, loss: 0.0979396402835846
step: 290, loss: 0.07255841791629791
step: 300, loss: 0.034964971244335175
step: 310, loss: 0.027028892189264297
step: 320, loss: 0.022577594965696335
step: 330, loss: 0.2615082561969757
step: 340, loss: 0.10245148837566376
step: 350, loss: 0.04968543350696564
step: 360, loss: 0.16712374985218048
step: 370, loss: 0.09146753698587418
step: 380, loss: 0.025746475905179977
epoch 4: dev_f1=0.7760416666666666, f1=0.5071225071225071, best_f1=0.5071225071225071
step: 0, loss: 0.04532698541879654
step: 10, loss: 0.03715577349066734
step: 20, loss: 0.05519742891192436
step: 30, loss: 0.14989039301872253
step: 40, loss: 0.24234670400619507
step: 50, loss: 0.049460966140031815
step: 60, loss: 0.008854716084897518
step: 70, loss: 0.06082430109381676
step: 80, loss: 0.031735941767692566
step: 90, loss: 0.031455203890800476
step: 100, loss: 0.22813750803470612
step: 110, loss: 0.024010339751839638
step: 120, loss: 0.09582147002220154
step: 130, loss: 0.01673400215804577
step: 140, loss: 0.2627388834953308
step: 150, loss: 0.011943074874579906
step: 160, loss: 0.036041680723428726
step: 170, loss: 0.10260359197854996
step: 180, loss: 0.20980849862098694
step: 190, loss: 0.04090264067053795
step: 200, loss: 0.09677548706531525
step: 210, loss: 0.11567240953445435
step: 220, loss: 0.0889311209321022
step: 230, loss: 0.12641684710979462
step: 240, loss: 0.07340363413095474
step: 250, loss: 0.05878979712724686
step: 260, loss: 0.03386383131146431
step: 270, loss: 0.12506945431232452
step: 280, loss: 0.04861506074666977
step: 290, loss: 0.23312228918075562
step: 300, loss: 0.10179653763771057
step: 310, loss: 0.12350665032863617
step: 320, loss: 0.0362870879471302
step: 330, loss: 0.13902375102043152
step: 340, loss: 0.06641729921102524
step: 350, loss: 0.13617415726184845
step: 360, loss: 0.09242203831672668
step: 370, loss: 0.12681953608989716
step: 380, loss: 0.0995783880352974
epoch 5: dev_f1=0.7786259541984734, f1=0.5408450704225352, best_f1=0.5408450704225352
step: 0, loss: 0.02707941085100174
step: 10, loss: 0.07103902101516724
step: 20, loss: 0.13306401669979095
step: 30, loss: 0.021108360961079597
step: 40, loss: 0.011377365328371525
step: 50, loss: 0.018770890310406685
step: 60, loss: 0.0021153055131435394
step: 70, loss: 0.09363038837909698
step: 80, loss: 0.012099085375666618
step: 90, loss: 0.02352007105946541
step: 100, loss: 0.02635699138045311
step: 110, loss: 0.007631055079400539
step: 120, loss: 0.04279957711696625
step: 130, loss: 0.12479185312986374
step: 140, loss: 0.04043155536055565
step: 150, loss: 0.015176898799836636
step: 160, loss: 0.119339220225811
step: 170, loss: 0.004591124132275581
step: 180, loss: 0.014477170072495937
step: 190, loss: 0.1992846578359604
step: 200, loss: 0.006838808301836252
step: 210, loss: 0.08811619877815247
step: 220, loss: 0.002400172408670187
step: 230, loss: 0.004254008177667856
step: 240, loss: 0.022626861929893494
step: 250, loss: 0.05581994354724884
step: 260, loss: 0.11756519228219986
step: 270, loss: 0.01214471086859703
step: 280, loss: 0.035087864845991135
step: 290, loss: 0.010505234822630882
step: 300, loss: 0.013217362575232983
step: 310, loss: 0.03435675427317619
step: 320, loss: 0.009644254110753536
step: 330, loss: 0.208719864487648
step: 340, loss: 0.03671719878911972
step: 350, loss: 0.01687484420835972
step: 360, loss: 0.1297389566898346
step: 370, loss: 0.014786441810429096
step: 380, loss: 0.06267713755369186
epoch 6: dev_f1=0.8021390374331551, f1=0.5189504373177842, best_f1=0.5189504373177842
step: 0, loss: 0.005133224651217461
step: 10, loss: 0.03516576811671257
step: 20, loss: 0.005350577179342508
step: 30, loss: 0.04410068690776825
step: 40, loss: 0.1039561778306961
step: 50, loss: 0.0014713063137605786
step: 60, loss: 0.027324268594384193
step: 70, loss: 0.013500716537237167
step: 80, loss: 0.004390084650367498
step: 90, loss: 0.026132697239518166
step: 100, loss: 0.006206179037690163
step: 110, loss: 0.0383298434317112
step: 120, loss: 0.041116222739219666
step: 130, loss: 0.07345911860466003
step: 140, loss: 0.023492444306612015
step: 150, loss: 0.034801799803972244
step: 160, loss: 0.01264283712953329
step: 170, loss: 0.008746196515858173
step: 180, loss: 0.01873919926583767
step: 190, loss: 0.010108278132975101
step: 200, loss: 0.02158312126994133
step: 210, loss: 0.14371152222156525
step: 220, loss: 0.005001976154744625
step: 230, loss: 0.0033855782821774483
step: 240, loss: 0.004816538654267788
step: 250, loss: 0.0014943938003852963
step: 260, loss: 0.007046644110232592
step: 270, loss: 0.027460316196084023
step: 280, loss: 0.07465236634016037
step: 290, loss: 0.004874018486589193
step: 300, loss: 0.09638290852308273
step: 310, loss: 0.07606132328510284
step: 320, loss: 0.017862971872091293
step: 330, loss: 0.012859983369708061
step: 340, loss: 0.007557649165391922
step: 350, loss: 0.06487654894590378
step: 360, loss: 0.12077849358320236
step: 370, loss: 0.08702241629362106
step: 380, loss: 0.04963674768805504
epoch 7: dev_f1=0.7939698492462313, f1=0.5852272727272727, best_f1=0.5189504373177842
step: 0, loss: 0.04621923714876175
step: 10, loss: 0.00856673251837492
step: 20, loss: 0.12981389462947845
step: 30, loss: 0.0758950337767601
step: 40, loss: 0.0027428539469838142
step: 50, loss: 0.007788831368088722
step: 60, loss: 0.008939721621572971
step: 70, loss: 0.002762589370831847
step: 80, loss: 0.007342091295868158
step: 90, loss: 0.001076093758456409
step: 100, loss: 0.003355274209752679
step: 110, loss: 0.0014367668190971017
step: 120, loss: 0.08862513303756714
step: 130, loss: 0.004374317359179258
step: 140, loss: 0.16004405915737152
step: 150, loss: 0.05302133783698082
step: 160, loss: 0.020581480115652084
step: 170, loss: 0.0024540754966437817
step: 180, loss: 0.035946592688560486
step: 190, loss: 0.0005726490635424852
step: 200, loss: 0.015963511541485786
step: 210, loss: 0.007920131087303162
step: 220, loss: 0.020843151956796646
step: 230, loss: 0.032833755016326904
step: 240, loss: 0.002170246560126543
step: 250, loss: 0.004487712401896715
step: 260, loss: 0.009818126447498798
step: 270, loss: 0.03446945175528526
step: 280, loss: 0.0009081631433218718
step: 290, loss: 0.05249534919857979
step: 300, loss: 0.03832579031586647
step: 310, loss: 0.0012393536744639277
step: 320, loss: 0.004376294557005167
step: 330, loss: 0.00411888025701046
step: 340, loss: 0.04004726558923721
step: 350, loss: 0.006390233524143696
step: 360, loss: 0.007516805082559586
step: 370, loss: 0.06028023734688759
step: 380, loss: 0.0051192352548241615
epoch 8: dev_f1=0.7761194029850746, f1=0.5783783783783782, best_f1=0.5189504373177842
step: 0, loss: 0.04609731584787369
step: 10, loss: 0.01175780687481165
step: 20, loss: 0.024085624143481255
step: 30, loss: 0.006699437741190195
step: 40, loss: 0.0013654849026352167
step: 50, loss: 0.0020252868998795748
step: 60, loss: 0.03718293085694313
step: 70, loss: 0.0020018930081278086
step: 80, loss: 0.04855303466320038
step: 90, loss: 0.0011818972416222095
step: 100, loss: 0.0030225913506001234
step: 110, loss: 0.004511887673288584
step: 120, loss: 0.000681056350003928
step: 130, loss: 0.057973410934209824
step: 140, loss: 0.0004728869826067239
step: 150, loss: 0.039572685956954956
step: 160, loss: 0.026772506535053253
step: 170, loss: 0.0007129708537831903
step: 180, loss: 0.0008990423521026969
step: 190, loss: 0.013754414394497871
step: 200, loss: 0.0035072339233011007
step: 210, loss: 0.0027038613334298134
step: 220, loss: 0.020207924768328667
step: 230, loss: 0.038526374846696854
step: 240, loss: 0.005089139100164175
step: 250, loss: 0.001537956646643579
step: 260, loss: 0.05390653759241104
step: 270, loss: 0.020691674202680588
step: 280, loss: 0.014804210513830185
step: 290, loss: 0.0006403924780897796
step: 300, loss: 0.004748078528791666
step: 310, loss: 0.0009077666327357292
step: 320, loss: 0.10506005585193634
step: 330, loss: 0.016318760812282562
step: 340, loss: 0.00795147754251957
step: 350, loss: 0.006019214168190956
step: 360, loss: 0.0770886093378067
step: 370, loss: 0.0045206593349576
step: 380, loss: 0.007905502803623676
epoch 9: dev_f1=0.7826086956521738, f1=0.5107692307692308, best_f1=0.5189504373177842
step: 0, loss: 0.004155443049967289
step: 10, loss: 0.01083630695939064
step: 20, loss: 0.015587028115987778
step: 30, loss: 0.00039609873783774674
step: 40, loss: 0.030982431024312973
step: 50, loss: 0.005556653253734112
step: 60, loss: 0.006939151789993048
step: 70, loss: 0.009266095235943794
step: 80, loss: 0.005446163006126881
step: 90, loss: 0.0010065772803500295
step: 100, loss: 0.000993682537227869
step: 110, loss: 0.01669185608625412
step: 120, loss: 0.0008116009994409978
step: 130, loss: 0.019925404340028763
step: 140, loss: 0.03181108832359314
step: 150, loss: 0.0017556999810039997
step: 160, loss: 0.002453756285831332
step: 170, loss: 0.0011876769131049514
step: 180, loss: 0.0035129596944898367
step: 190, loss: 0.10301970690488815
step: 200, loss: 0.005504316184669733
step: 210, loss: 0.0004420128825586289
step: 220, loss: 0.005223249550908804
step: 230, loss: 0.010523163713514805
step: 240, loss: 0.0005484963767230511
step: 250, loss: 0.0023220262955874205
step: 260, loss: 0.011697998270392418
step: 270, loss: 0.015590503811836243
step: 280, loss: 0.023014886304736137
step: 290, loss: 0.025947589427232742
step: 300, loss: 0.00027116815908811986
step: 310, loss: 0.20647045969963074
step: 320, loss: 0.021767761558294296
step: 330, loss: 0.0034380038268864155
step: 340, loss: 0.001766567351296544
step: 350, loss: 0.0028105133678764105
step: 360, loss: 0.007931610569357872
step: 370, loss: 0.11843568086624146
step: 380, loss: 0.1059364601969719
epoch 10: dev_f1=0.7903614457831326, f1=0.6276595744680851, best_f1=0.5189504373177842
step: 0, loss: 0.0007883270154707134
step: 10, loss: 0.017100492492318153
step: 20, loss: 0.0025334772653877735
step: 30, loss: 0.0006867342162877321
step: 40, loss: 0.0710722804069519
step: 50, loss: 0.0002993390371557325
step: 60, loss: 0.005358948837965727
step: 70, loss: 0.027103852480649948
step: 80, loss: 0.0004578287189360708
step: 90, loss: 0.008517117239534855
step: 100, loss: 0.002295644721016288
step: 110, loss: 0.11685526371002197
step: 120, loss: 0.002444107783958316
step: 130, loss: 0.025044415146112442
step: 140, loss: 0.09297686070203781
step: 150, loss: 0.023734968155622482
step: 160, loss: 0.00045572721865028143
step: 170, loss: 0.0006825054879300296
step: 180, loss: 0.0015011978102847934
step: 190, loss: 0.02095075510442257
step: 200, loss: 0.10565977543592453
step: 210, loss: 0.0005647316575050354
step: 220, loss: 0.0040067462250590324
step: 230, loss: 0.0010578136425465345
step: 240, loss: 0.00011909809109056368
step: 250, loss: 0.0012111574178561568
step: 260, loss: 0.000325553584843874
step: 270, loss: 0.0019824830815196037
step: 280, loss: 0.0008880096720531583
step: 290, loss: 0.015185387805104256
step: 300, loss: 0.0009041315643116832
step: 310, loss: 0.0014431237941607833
step: 320, loss: 0.04496488720178604
step: 330, loss: 0.0007084820535965264
step: 340, loss: 0.0065105934627354145
step: 350, loss: 0.005466369446367025
step: 360, loss: 0.0004105675616301596
step: 370, loss: 0.006710409186780453
step: 380, loss: 0.051150254905223846
epoch 11: dev_f1=0.7830423940149626, f1=0.5973333333333334, best_f1=0.5189504373177842
step: 0, loss: 0.0005150808719918132
step: 10, loss: 0.0002771852887235582
step: 20, loss: 0.0007144928094930947
step: 30, loss: 0.008369800634682178
step: 40, loss: 0.0992121696472168
step: 50, loss: 0.0003147310053464025
step: 60, loss: 0.0034560193307697773
step: 70, loss: 0.0024714823812246323
step: 80, loss: 0.002628201385959983
step: 90, loss: 0.0013867306988686323
step: 100, loss: 0.0004922215593978763
step: 110, loss: 0.025438368320465088
step: 120, loss: 0.002968805143609643
step: 130, loss: 0.035175882279872894
step: 140, loss: 0.0015709801809862256
step: 150, loss: 0.0005562612204812467
step: 160, loss: 0.0005625854828394949
step: 170, loss: 0.0009680782677605748
step: 180, loss: 0.019933773204684258
step: 190, loss: 0.00023384782252833247
step: 200, loss: 0.00020699559536296874
step: 210, loss: 0.0003321512776892632
step: 220, loss: 0.0005557542317546904
step: 230, loss: 0.0004582449037116021
step: 240, loss: 0.00021528382785618305
step: 250, loss: 0.0005956074455752969
step: 260, loss: 0.0011528012109920382
step: 270, loss: 0.004005567170679569
step: 280, loss: 0.002295576734468341
step: 290, loss: 0.003583980957046151
step: 300, loss: 0.003259617369621992
step: 310, loss: 0.00260739354416728
step: 320, loss: 0.0450487956404686
step: 330, loss: 0.0005151431541889906
step: 340, loss: 0.01647735945880413
step: 350, loss: 0.032425761222839355
step: 360, loss: 0.003964913543313742
step: 370, loss: 0.0002968808403238654
step: 380, loss: 0.00013857826706953347
epoch 12: dev_f1=0.7893333333333333, f1=0.5454545454545454, best_f1=0.5189504373177842
step: 0, loss: 0.00037826731568202376
step: 10, loss: 0.0030213980935513973
step: 20, loss: 0.0011095809750258923
step: 30, loss: 0.00030090444488450885
step: 40, loss: 0.00034979343763552606
step: 50, loss: 0.001646494958549738
step: 60, loss: 0.0017432566964998841
step: 70, loss: 0.0003278348012827337
step: 80, loss: 9.940846939571202e-05
step: 90, loss: 0.0009670770959928632
step: 100, loss: 0.00010633328929543495
step: 110, loss: 0.007850974798202515
step: 120, loss: 9.307329310104251e-05
step: 130, loss: 0.00021121313329786062
step: 140, loss: 0.0003068727965001017
step: 150, loss: 0.00013458171451929957
step: 160, loss: 0.0002727530663833022
step: 170, loss: 0.0004575798229780048
step: 180, loss: 0.00045674960711039603
step: 190, loss: 0.0008308783289976418
step: 200, loss: 0.002742270240560174
step: 210, loss: 0.0003674801264423877
step: 220, loss: 0.0001394716528011486
step: 230, loss: 0.0016158639919012785
step: 240, loss: 0.0009342455887235701
step: 250, loss: 0.0002789754362311214
step: 260, loss: 0.000546492519788444
step: 270, loss: 0.025422751903533936
step: 280, loss: 0.0002870495954994112
step: 290, loss: 0.0005589478532783687
step: 300, loss: 0.006373345386236906
step: 310, loss: 0.00036071031354367733
step: 320, loss: 0.0003966314543504268
step: 330, loss: 0.00198712688870728
step: 340, loss: 0.0004092477320227772
step: 350, loss: 0.00019493437139317393
step: 360, loss: 0.002863815752789378
step: 370, loss: 0.00034673031768761575
step: 380, loss: 0.0054556080140173435
epoch 13: dev_f1=0.7924528301886792, f1=0.5723076923076923, best_f1=0.5189504373177842
step: 0, loss: 0.0012868698686361313
step: 10, loss: 0.00029412194271571934
step: 20, loss: 0.00019088746921624988
step: 30, loss: 0.0002563835878390819
step: 40, loss: 0.0012638914631679654
step: 50, loss: 6.30164795438759e-05
step: 60, loss: 0.003823075909167528
step: 70, loss: 0.00028532271971926093
step: 80, loss: 0.00013670128828380257
step: 90, loss: 0.0009714754996821284
step: 100, loss: 0.001975669991225004
step: 110, loss: 0.0001606381410965696
step: 120, loss: 0.0013683614088222384
step: 130, loss: 8.435746713075787e-05
step: 140, loss: 7.503364759031683e-05
step: 150, loss: 0.0007060547359287739
step: 160, loss: 6.317291990853846e-05
step: 170, loss: 0.0033011632040143013
step: 180, loss: 0.0001810999820008874
step: 190, loss: 0.00027595815481618047
step: 200, loss: 0.001513221301138401
step: 210, loss: 0.00026676629204303026
step: 220, loss: 7.991530583240092e-05
step: 230, loss: 0.0010519326897338033
step: 240, loss: 0.005100420210510492
step: 250, loss: 0.011407146230340004
step: 260, loss: 0.0004436984017957002
step: 270, loss: 0.00032447068952023983
step: 280, loss: 0.0029080614913254976
step: 290, loss: 0.00017283292254433036
step: 300, loss: 0.004889811854809523
step: 310, loss: 0.0006194757879711688
step: 320, loss: 0.0006113155395723879
step: 330, loss: 0.0003443790483288467
step: 340, loss: 0.01185249537229538
step: 350, loss: 0.00016026363300625235
step: 360, loss: 6.16173492744565e-05
step: 370, loss: 4.034684025100432e-05
step: 380, loss: 0.009439180605113506
epoch 14: dev_f1=0.7841191066997518, f1=0.6229508196721311, best_f1=0.5189504373177842
step: 0, loss: 4.7561621613567695e-05
step: 10, loss: 0.0013261032290756702
step: 20, loss: 0.00036192432162351906
step: 30, loss: 0.00022146131959743798
step: 40, loss: 0.0015622054925188422
step: 50, loss: 0.000144240926601924
step: 60, loss: 0.001378778018988669
step: 70, loss: 6.225406104931608e-05
step: 80, loss: 0.0001574007183080539
step: 90, loss: 8.900980901671574e-05
step: 100, loss: 0.0015795432263985276
step: 110, loss: 0.0022308938205242157
step: 120, loss: 0.0004014147270936519
step: 130, loss: 0.00047389164683409035
step: 140, loss: 0.0007959908107295632
step: 150, loss: 0.0001122558896895498
step: 160, loss: 0.0008145271567627788
step: 170, loss: 0.0005151714431121945
step: 180, loss: 0.0011993999360129237
step: 190, loss: 0.01768256537616253
step: 200, loss: 0.055715758353471756
step: 210, loss: 0.00017958832904696465
step: 220, loss: 0.0005250989925116301
step: 230, loss: 0.0022873198613524437
step: 240, loss: 0.00177544797770679
step: 250, loss: 0.00029505550628528
step: 260, loss: 0.0003600332420319319
step: 270, loss: 0.0337749682366848
step: 280, loss: 0.0002269791002618149
step: 290, loss: 0.001940596499480307
step: 300, loss: 8.342743967659771e-05
step: 310, loss: 0.00023243877512868494
step: 320, loss: 0.0003680815570987761
step: 330, loss: 0.0006864031311124563
step: 340, loss: 0.006799180060625076
step: 350, loss: 0.00027657917235046625
step: 360, loss: 0.0008112008217722178
step: 370, loss: 0.02529277466237545
step: 380, loss: 0.0001832390553317964
epoch 15: dev_f1=0.7919799498746868, f1=0.5459610027855154, best_f1=0.5189504373177842
step: 0, loss: 0.0001470907445764169
step: 10, loss: 4.162835466559045e-05
step: 20, loss: 0.00018206139793619514
step: 30, loss: 4.052917574881576e-05
step: 40, loss: 0.014546512626111507
step: 50, loss: 0.00024620365002192557
step: 60, loss: 0.0020927046425640583
step: 70, loss: 0.0001551055902382359
step: 80, loss: 0.000280204665614292
step: 90, loss: 0.0001525092957308516
step: 100, loss: 7.243351137731224e-05
step: 110, loss: 0.0008817650377750397
step: 120, loss: 4.6502347686327994e-05
step: 130, loss: 0.0002385830448474735
step: 140, loss: 2.1848507458344102e-05
step: 150, loss: 0.0014509882312268019
step: 160, loss: 6.793227657908574e-05
step: 170, loss: 0.00015952071407809854
step: 180, loss: 0.0007545494008809328
step: 190, loss: 5.387125929701142e-05
step: 200, loss: 0.00011481843102956191
step: 210, loss: 8.919189713196829e-05
step: 220, loss: 0.00012607505777850747
step: 230, loss: 0.03051065281033516
step: 240, loss: 0.0023464979603886604
step: 250, loss: 0.0012400170089676976
step: 260, loss: 0.0001227614702656865
step: 270, loss: 7.520974759245291e-05
step: 280, loss: 0.0037873650435358286
step: 290, loss: 0.00018516945419833064
step: 300, loss: 0.00010296057007508352
step: 310, loss: 0.0010492716683074832
step: 320, loss: 0.00044755294220522046
step: 330, loss: 0.0005991712096147239
step: 340, loss: 0.001571203931234777
step: 350, loss: 0.00013814622070640326
step: 360, loss: 0.0004029041447211057
step: 370, loss: 0.00019108070409856737
step: 380, loss: 3.578325777198188e-05
epoch 16: dev_f1=0.7969543147208122, f1=0.591549295774648, best_f1=0.5189504373177842
step: 0, loss: 6.82833488099277e-05
step: 10, loss: 0.0005836753989569843
step: 20, loss: 0.0001386520016239956
step: 30, loss: 7.616108632646501e-05
step: 40, loss: 0.00042119776480831206
step: 50, loss: 0.0006974927382543683
step: 60, loss: 0.000556925602722913
step: 70, loss: 0.00012222457735333592
step: 80, loss: 0.004535445477813482
step: 90, loss: 6.326597940642387e-05
step: 100, loss: 0.0005903873825445771
step: 110, loss: 0.00045321747893467546
step: 120, loss: 0.0001449244882678613
step: 130, loss: 0.0011578414123505354
step: 140, loss: 8.20959685370326e-05
step: 150, loss: 0.000195925502339378
step: 160, loss: 0.004084502346813679
step: 170, loss: 0.00012114606943214312
step: 180, loss: 5.698471068171784e-05
step: 190, loss: 0.0010217640083283186
step: 200, loss: 5.957204848527908e-05
step: 210, loss: 0.00012271710147615522
step: 220, loss: 0.00011737277964130044
step: 230, loss: 3.756017395062372e-05
step: 240, loss: 0.00012637929467018694
step: 250, loss: 3.25114160659723e-05
step: 260, loss: 0.00023727827647235245
step: 270, loss: 0.00036029217881150544
step: 280, loss: 0.00015429752238560468
step: 290, loss: 0.001535059534944594
step: 300, loss: 4.6059565647738054e-05
step: 310, loss: 0.00011437064677011222
step: 320, loss: 3.8312871765810996e-05
step: 330, loss: 0.00014321845083031803
step: 340, loss: 0.0013243758585304022
step: 350, loss: 0.005593668203800917
step: 360, loss: 5.510263508767821e-05
step: 370, loss: 0.003516022814437747
step: 380, loss: 3.9053993532434106e-05
epoch 17: dev_f1=0.8, f1=0.6077348066298343, best_f1=0.5189504373177842
step: 0, loss: 3.883241879520938e-05
step: 10, loss: 0.00011227421055082232
step: 20, loss: 0.0023400974459946156
step: 30, loss: 4.48287719336804e-05
step: 40, loss: 0.0001925424876390025
step: 50, loss: 6.128814857220277e-05
step: 60, loss: 0.003019781084731221
step: 70, loss: 0.011339684017002583
step: 80, loss: 0.0001575662608956918
step: 90, loss: 8.599675493314862e-05
step: 100, loss: 0.002855803817510605
step: 110, loss: 2.903676977439318e-05
step: 120, loss: 7.978608482517302e-05
step: 130, loss: 6.573113932972774e-05
step: 140, loss: 0.00045284966472536325
step: 150, loss: 0.004260798916220665
step: 160, loss: 0.0001481490908190608
step: 170, loss: 0.0009523196495138109
step: 180, loss: 5.408632569015026e-05
step: 190, loss: 1.700938264548313e-05
step: 200, loss: 0.00019504997180774808
step: 210, loss: 0.0007600673707202077
step: 220, loss: 0.0001839480100898072
step: 230, loss: 7.3948860517703e-05
step: 240, loss: 0.0016495187301188707
step: 250, loss: 0.00014204811304807663
step: 260, loss: 0.0002447859733365476
step: 270, loss: 0.0001467052788939327
step: 280, loss: 7.743466267129406e-05
step: 290, loss: 0.0001138758088927716
step: 300, loss: 8.821549272397533e-05
step: 310, loss: 0.0267941877245903
step: 320, loss: 9.867457265499979e-05
step: 330, loss: 0.00017883362306747586
step: 340, loss: 0.007854030467569828
step: 350, loss: 0.00014931221085134894
step: 360, loss: 0.00011869824083987623
step: 370, loss: 5.6724984460743144e-05
step: 380, loss: 5.797528137918562e-05
epoch 18: dev_f1=0.7878787878787878, f1=0.5944444444444444, best_f1=0.5189504373177842
step: 0, loss: 2.4582541300333105e-05
step: 10, loss: 0.002143427263945341
step: 20, loss: 8.503704884788021e-05
step: 30, loss: 0.0001860977936303243
step: 40, loss: 0.00014129385817795992
step: 50, loss: 0.0005381009541451931
step: 60, loss: 0.000302318629110232
step: 70, loss: 7.363668555626646e-05
step: 80, loss: 2.2355021428666078e-05
step: 90, loss: 2.4094631953630596e-05
step: 100, loss: 0.00345684215426445
step: 110, loss: 0.00016113567107822746
step: 120, loss: 0.0002683037891983986
step: 130, loss: 7.48595703043975e-05
step: 140, loss: 4.036524842376821e-05
step: 150, loss: 0.005010505206882954
step: 160, loss: 6.081608808017336e-05
step: 170, loss: 5.8289322623750195e-05
step: 180, loss: 0.004210887011140585
step: 190, loss: 0.00729141803458333
step: 200, loss: 4.725597318611108e-05
step: 210, loss: 0.00014626845950260758
step: 220, loss: 0.00027580198366194963
step: 230, loss: 5.445863280328922e-05
step: 240, loss: 0.0002753167354967445
step: 250, loss: 4.1877676267176867e-05
step: 260, loss: 9.575541480444372e-05
step: 270, loss: 0.0003253378963563591
step: 280, loss: 0.001109275035560131
step: 290, loss: 0.0003207346599083394
step: 300, loss: 6.982509512454271e-05
step: 310, loss: 4.4871732825413346e-05
step: 320, loss: 4.94944688398391e-05
step: 330, loss: 6.580413901247084e-05
step: 340, loss: 0.0002409216103842482
step: 350, loss: 0.0004277093685232103
step: 360, loss: 0.0005791714647784829
step: 370, loss: 0.0001680179120739922
step: 380, loss: 6.730245513608679e-05
epoch 19: dev_f1=0.7871287128712872, f1=0.5879120879120879, best_f1=0.5189504373177842
step: 0, loss: 0.00011923038255190477
step: 10, loss: 0.00026152373175136745
step: 20, loss: 5.305081867845729e-05
step: 30, loss: 3.826807369478047e-05
step: 40, loss: 0.000869286828674376
step: 50, loss: 0.000281437678495422
step: 60, loss: 0.00024589727399870753
step: 70, loss: 5.840827361680567e-05
step: 80, loss: 0.00021919151186011732
step: 90, loss: 5.943440191913396e-05
step: 100, loss: 4.365548011264764e-05
step: 110, loss: 8.85024928720668e-05
step: 120, loss: 7.93046347098425e-05
step: 130, loss: 0.00019854700076393783
step: 140, loss: 0.0001364484487567097
step: 150, loss: 0.00017418495554011315
step: 160, loss: 5.99814229644835e-05
step: 170, loss: 0.0013542519882321358
step: 180, loss: 0.00010325012408429757
step: 190, loss: 0.00010033880244009197
step: 200, loss: 7.043952791718766e-05
step: 210, loss: 0.00023548923491034657
step: 220, loss: 0.0010887297103181481
step: 230, loss: 3.0203273126971908e-05
step: 240, loss: 2.4381024559261277e-05
step: 250, loss: 0.00012883578892797232
step: 260, loss: 0.00038546769064851105
step: 270, loss: 8.323260408360511e-05
step: 280, loss: 4.798468216904439e-05
step: 290, loss: 5.440865061245859e-05
step: 300, loss: 0.001099277171306312
step: 310, loss: 9.86831946647726e-05
step: 320, loss: 6.811963976360857e-05
step: 330, loss: 0.0007858300232328475
step: 340, loss: 2.7874877559952438e-05
step: 350, loss: 0.00011493495549075305
step: 360, loss: 6.20981736574322e-05
step: 370, loss: 0.00013630966714117676
step: 380, loss: 8.573415834689513e-05
epoch 20: dev_f1=0.7869674185463658, f1=0.5966850828729282, best_f1=0.5189504373177842
