cuda
Device: cuda
step: 0, loss: 0.6508384943008423
step: 10, loss: 0.2368658483028412
step: 20, loss: 0.49724361300468445
step: 30, loss: 0.44631442427635193
step: 40, loss: 0.2282305210828781
step: 50, loss: 0.3788992762565613
step: 60, loss: 0.3014693260192871
step: 70, loss: 0.310244083404541
step: 80, loss: 0.5144693851470947
step: 90, loss: 0.225162535905838
step: 100, loss: 0.2332005500793457
step: 110, loss: 0.3020249903202057
step: 120, loss: 0.35833895206451416
step: 130, loss: 0.24238863587379456
step: 140, loss: 0.26647046208381653
step: 150, loss: 0.3329416513442993
step: 160, loss: 0.41859006881713867
step: 170, loss: 0.19901888072490692
step: 180, loss: 0.3553400933742523
step: 190, loss: 0.1833486407995224
step: 200, loss: 0.3922163248062134
step: 210, loss: 0.21395255625247955
step: 220, loss: 0.41922464966773987
step: 230, loss: 0.06565608829259872
step: 240, loss: 0.14173530042171478
step: 250, loss: 0.23269231617450714
step: 260, loss: 0.3085763156414032
step: 270, loss: 0.17361867427825928
step: 280, loss: 0.24986302852630615
step: 290, loss: 0.22613435983657837
step: 300, loss: 0.34473916888237
step: 310, loss: 0.3043808341026306
step: 320, loss: 0.30796489119529724
step: 330, loss: 0.17301511764526367
step: 340, loss: 0.1216936782002449
step: 350, loss: 0.32040852308273315
step: 360, loss: 0.24252577126026154
step: 370, loss: 0.33564630150794983
step: 380, loss: 0.22736981511116028
epoch 1: dev_f1=0.5907990314769975, f1=0.45433255269320844, best_f1=0.45433255269320844
step: 0, loss: 0.35072267055511475
step: 10, loss: 0.3759970963001251
step: 20, loss: 0.14006514847278595
step: 30, loss: 0.14063143730163574
step: 40, loss: 0.32535791397094727
step: 50, loss: 0.3247092068195343
step: 60, loss: 0.240121990442276
step: 70, loss: 0.34927594661712646
step: 80, loss: 0.19280782341957092
step: 90, loss: 0.2386249601840973
step: 100, loss: 0.29597753286361694
step: 110, loss: 0.26698824763298035
step: 120, loss: 0.18998561799526215
step: 130, loss: 0.09076236188411713
step: 140, loss: 0.45982158184051514
step: 150, loss: 0.25623854994773865
step: 160, loss: 0.09209521114826202
step: 170, loss: 0.14637619256973267
step: 180, loss: 0.16741777956485748
step: 190, loss: 0.08563625067472458
step: 200, loss: 0.20158754289150238
step: 210, loss: 0.46344971656799316
step: 220, loss: 0.2979758381843567
step: 230, loss: 0.16984252631664276
step: 240, loss: 0.1509513109922409
step: 250, loss: 0.2051735669374466
step: 260, loss: 0.21351571381092072
step: 270, loss: 0.0766686350107193
step: 280, loss: 0.21606306731700897
step: 290, loss: 0.1038312241435051
step: 300, loss: 0.0642186775803566
step: 310, loss: 0.15879443287849426
step: 320, loss: 0.09002434462308884
step: 330, loss: 0.17765729129314423
step: 340, loss: 0.05442231148481369
step: 350, loss: 0.22803519666194916
step: 360, loss: 0.3030051589012146
step: 370, loss: 0.19331879913806915
step: 380, loss: 0.122173972427845
epoch 2: dev_f1=0.751219512195122, f1=0.5728900255754475, best_f1=0.5728900255754475
step: 0, loss: 0.20728415250778198
step: 10, loss: 0.13947564363479614
step: 20, loss: 0.06601577252149582
step: 30, loss: 0.16535474359989166
step: 40, loss: 0.08585610240697861
step: 50, loss: 0.3527362048625946
step: 60, loss: 0.05348305031657219
step: 70, loss: 0.09353219717741013
step: 80, loss: 0.10953274369239807
step: 90, loss: 0.038945287466049194
step: 100, loss: 0.1162300556898117
step: 110, loss: 0.17694191634655
step: 120, loss: 0.12220152467489243
step: 130, loss: 0.09486468881368637
step: 140, loss: 0.012251931242644787
step: 150, loss: 0.2644893229007721
step: 160, loss: 0.2237539142370224
step: 170, loss: 0.0705612450838089
step: 180, loss: 0.2149830311536789
step: 190, loss: 0.19899673759937286
step: 200, loss: 0.16127565503120422
step: 210, loss: 0.0740530788898468
step: 220, loss: 0.11755669116973877
step: 230, loss: 0.08985704183578491
step: 240, loss: 0.14026889204978943
step: 250, loss: 0.08024998009204865
step: 260, loss: 0.1458429992198944
step: 270, loss: 0.10123993456363678
step: 280, loss: 0.08731398731470108
step: 290, loss: 0.20231232047080994
step: 300, loss: 0.09537073969841003
step: 310, loss: 0.07555673271417618
step: 320, loss: 0.1428876370191574
step: 330, loss: 0.2773321866989136
step: 340, loss: 0.25672218203544617
step: 350, loss: 0.25470584630966187
step: 360, loss: 0.17634746432304382
step: 370, loss: 0.14312639832496643
step: 380, loss: 0.1863091140985489
epoch 3: dev_f1=0.8062827225130891, f1=0.47852760736196315, best_f1=0.47852760736196315
step: 0, loss: 0.20734958350658417
step: 10, loss: 0.08442534506320953
step: 20, loss: 0.038358062505722046
step: 30, loss: 0.039133843034505844
step: 40, loss: 0.01359315775334835
step: 50, loss: 0.20601306855678558
step: 60, loss: 0.19376544654369354
step: 70, loss: 0.11817727237939835
step: 80, loss: 0.007601630873978138
step: 90, loss: 0.15111911296844482
step: 100, loss: 0.18888096511363983
step: 110, loss: 0.04397805780172348
step: 120, loss: 0.31179192662239075
step: 130, loss: 0.10840169340372086
step: 140, loss: 0.21870353817939758
step: 150, loss: 0.09664495289325714
step: 160, loss: 0.0796944722533226
step: 170, loss: 0.003454291494563222
step: 180, loss: 0.02512643113732338
step: 190, loss: 0.12387330830097198
step: 200, loss: 0.03844482824206352
step: 210, loss: 0.04497619718313217
step: 220, loss: 0.0966646671295166
step: 230, loss: 0.15555237233638763
step: 240, loss: 0.26192614436149597
step: 250, loss: 0.058435872197151184
step: 260, loss: 0.08929400146007538
step: 270, loss: 0.1028800904750824
step: 280, loss: 0.00844374019652605
step: 290, loss: 0.031746190041303635
step: 300, loss: 0.1593133956193924
step: 310, loss: 0.015468128956854343
step: 320, loss: 0.04666433855891228
step: 330, loss: 0.06473354250192642
step: 340, loss: 0.027240822091698647
step: 350, loss: 0.01277195569127798
step: 360, loss: 0.11095037311315536
step: 370, loss: 0.06718933582305908
step: 380, loss: 0.3111609220504761
epoch 4: dev_f1=0.7699530516431926, f1=0.5885286783042394, best_f1=0.47852760736196315
step: 0, loss: 0.0866686999797821
step: 10, loss: 0.05459774285554886
step: 20, loss: 0.0820370689034462
step: 30, loss: 0.12344083189964294
step: 40, loss: 0.055356018245220184
step: 50, loss: 0.15026742219924927
step: 60, loss: 0.01512971892952919
step: 70, loss: 0.018530357629060745
step: 80, loss: 0.15844878554344177
step: 90, loss: 0.1545744389295578
step: 100, loss: 0.03441076725721359
step: 110, loss: 0.10935264080762863
step: 120, loss: 0.03309504687786102
step: 130, loss: 0.0601552277803421
step: 140, loss: 0.2031092643737793
step: 150, loss: 0.00520233903080225
step: 160, loss: 0.11251350492238998
step: 170, loss: 0.10707387328147888
step: 180, loss: 0.25835564732551575
step: 190, loss: 0.046371959149837494
step: 200, loss: 0.020310645923018456
step: 210, loss: 0.02015039138495922
step: 220, loss: 0.11164034157991409
step: 230, loss: 0.015979694202542305
step: 240, loss: 0.041328489780426025
step: 250, loss: 0.01844574138522148
step: 260, loss: 0.0874783843755722
step: 270, loss: 0.10282669216394424
step: 280, loss: 0.034266870468854904
step: 290, loss: 0.12550927698612213
step: 300, loss: 0.07397791743278503
step: 310, loss: 0.1337786614894867
step: 320, loss: 0.2301681935787201
step: 330, loss: 0.0367707684636116
step: 340, loss: 0.02596934325993061
step: 350, loss: 0.018197953701019287
step: 360, loss: 0.10442173480987549
step: 370, loss: 0.06690097600221634
step: 380, loss: 0.20866379141807556
epoch 5: dev_f1=0.7864077669902912, f1=0.6543535620052771, best_f1=0.47852760736196315
step: 0, loss: 0.04835495725274086
step: 10, loss: 0.09148837625980377
step: 20, loss: 0.0737486258149147
step: 30, loss: 0.07129056006669998
step: 40, loss: 0.009022979997098446
step: 50, loss: 0.013074507005512714
step: 60, loss: 0.05462140217423439
step: 70, loss: 0.07235304266214371
step: 80, loss: 0.0311159435659647
step: 90, loss: 0.07652262598276138
step: 100, loss: 0.02627384662628174
step: 110, loss: 0.030752113088965416
step: 120, loss: 0.05408359691500664
step: 130, loss: 0.0074472613632678986
step: 140, loss: 0.0558602437376976
step: 150, loss: 0.15435680747032166
step: 160, loss: 0.028744854032993317
step: 170, loss: 0.12548959255218506
step: 180, loss: 0.08474178612232208
step: 190, loss: 0.01736176386475563
step: 200, loss: 0.001288986299186945
step: 210, loss: 0.045508451759815216
step: 220, loss: 0.04295887053012848
step: 230, loss: 0.0160047709941864
step: 240, loss: 0.027253836393356323
step: 250, loss: 0.018479397520422935
step: 260, loss: 0.015070064924657345
step: 270, loss: 0.2918611466884613
step: 280, loss: 0.04288795217871666
step: 290, loss: 0.10640613734722137
step: 300, loss: 0.006354780402034521
step: 310, loss: 0.11862315237522125
step: 320, loss: 0.03245813772082329
step: 330, loss: 0.022860229015350342
step: 340, loss: 0.11672742664813995
step: 350, loss: 0.030664725229144096
step: 360, loss: 0.0574885830283165
step: 370, loss: 0.018903903663158417
step: 380, loss: 0.01394210197031498
epoch 6: dev_f1=0.7745098039215685, f1=0.6299212598425197, best_f1=0.47852760736196315
step: 0, loss: 0.029962383210659027
step: 10, loss: 0.03299904987215996
step: 20, loss: 0.07359185069799423
step: 30, loss: 0.003026057733222842
step: 40, loss: 0.04151869937777519
step: 50, loss: 0.026341818273067474
step: 60, loss: 0.001677660970017314
step: 70, loss: 0.29967519640922546
step: 80, loss: 0.014376519247889519
step: 90, loss: 0.03557062894105911
step: 100, loss: 0.036704353988170624
step: 110, loss: 0.008929758332669735
step: 120, loss: 0.02077983319759369
step: 130, loss: 0.0046461112797260284
step: 140, loss: 0.19057156145572662
step: 150, loss: 0.001486243330873549
step: 160, loss: 0.016313442960381508
step: 170, loss: 0.004906546790152788
step: 180, loss: 0.02951119840145111
step: 190, loss: 0.02558465488255024
step: 200, loss: 0.0027109261136502028
step: 210, loss: 0.009396166540682316
step: 220, loss: 0.1385183036327362
step: 230, loss: 0.0009616455063223839
step: 240, loss: 0.004749609157443047
step: 250, loss: 0.04848902300000191
step: 260, loss: 0.03060511127114296
step: 270, loss: 0.12524482607841492
step: 280, loss: 0.04809608310461044
step: 290, loss: 0.08004049211740494
step: 300, loss: 0.00887862965464592
step: 310, loss: 0.006512761581689119
step: 320, loss: 0.010159597732126713
step: 330, loss: 0.14738880097866058
step: 340, loss: 0.01835326850414276
step: 350, loss: 0.03366624563932419
step: 360, loss: 0.07589728385210037
step: 370, loss: 0.0021235523745417595
step: 380, loss: 0.009904098697006702
epoch 7: dev_f1=0.7795698924731183, f1=0.5941176470588235, best_f1=0.47852760736196315
step: 0, loss: 0.005627461243420839
step: 10, loss: 0.01495218463242054
step: 20, loss: 0.03650464862585068
step: 30, loss: 0.00837949849665165
step: 40, loss: 0.00034319068072363734
step: 50, loss: 0.00566512206569314
step: 60, loss: 0.0072242505848407745
step: 70, loss: 0.0032690432853996754
step: 80, loss: 0.016583841294050217
step: 90, loss: 0.014058149419724941
step: 100, loss: 0.008901451714336872
step: 110, loss: 0.01955013908445835
step: 120, loss: 0.07991914451122284
step: 130, loss: 0.015742482617497444
step: 140, loss: 0.024822495877742767
step: 150, loss: 0.00042371771996840835
step: 160, loss: 0.012410382740199566
step: 170, loss: 0.0021575000137090683
step: 180, loss: 0.006095786113291979
step: 190, loss: 0.0077384100295603275
step: 200, loss: 0.01070151012390852
step: 210, loss: 0.023225700482726097
step: 220, loss: 0.0006714924820698798
step: 230, loss: 0.14627030491828918
step: 240, loss: 0.02467234991490841
step: 250, loss: 0.05180772766470909
step: 260, loss: 0.02253393456339836
step: 270, loss: 0.0180065855383873
step: 280, loss: 0.0406426377594471
step: 290, loss: 0.011707196943461895
step: 300, loss: 0.07374788820743561
step: 310, loss: 0.03473566845059395
step: 320, loss: 0.04790617898106575
step: 330, loss: 0.028583498671650887
step: 340, loss: 0.016031231731176376
step: 350, loss: 0.04644586518406868
step: 360, loss: 0.15415705740451813
step: 370, loss: 0.023187799379229546
step: 380, loss: 0.0442536398768425
epoch 8: dev_f1=0.7885117493472584, f1=0.5752688172043011, best_f1=0.47852760736196315
step: 0, loss: 0.001192443072795868
step: 10, loss: 0.04505911096930504
step: 20, loss: 0.04828890413045883
step: 30, loss: 0.21504804491996765
step: 40, loss: 0.02647840417921543
step: 50, loss: 0.004997045733034611
step: 60, loss: 0.041898198425769806
step: 70, loss: 0.062071673572063446
step: 80, loss: 0.19996611773967743
step: 90, loss: 0.10424702614545822
step: 100, loss: 0.11126398295164108
step: 110, loss: 0.012587555684149265
step: 120, loss: 0.015379115007817745
step: 130, loss: 0.05647285655140877
step: 140, loss: 0.04130661115050316
step: 150, loss: 0.0015346395084634423
step: 160, loss: 0.0015342689584940672
step: 170, loss: 0.0030948917847126722
step: 180, loss: 0.009498433209955692
step: 190, loss: 0.012885386124253273
step: 200, loss: 0.006743252743035555
step: 210, loss: 0.019981469959020615
step: 220, loss: 0.0006570639088749886
step: 230, loss: 0.021495122462511063
step: 240, loss: 0.00463631097227335
step: 250, loss: 0.002496509114280343
step: 260, loss: 0.005010293330997229
step: 270, loss: 0.00045257320743985474
step: 280, loss: 0.008783464320003986
step: 290, loss: 0.003912135027348995
step: 300, loss: 0.05039132386445999
step: 310, loss: 0.013883666135370731
step: 320, loss: 0.0025569950230419636
step: 330, loss: 0.011248363181948662
step: 340, loss: 0.0019087876426056027
step: 350, loss: 0.0013793203979730606
step: 360, loss: 0.002618841826915741
step: 370, loss: 0.007847563363611698
step: 380, loss: 0.0032933582551777363
epoch 9: dev_f1=0.7810026385224274, f1=0.6112759643916914, best_f1=0.47852760736196315
step: 0, loss: 0.00959849264472723
step: 10, loss: 0.0041670710779726505
step: 20, loss: 0.021491793915629387
step: 30, loss: 0.0014949190663173795
step: 40, loss: 0.0002896426885854453
step: 50, loss: 0.0052751097828149796
step: 60, loss: 0.007860780693590641
step: 70, loss: 0.0019721195567399263
step: 80, loss: 0.0005949008627794683
step: 90, loss: 0.01022396795451641
step: 100, loss: 0.0031117922626435757
step: 110, loss: 0.11445724219083786
step: 120, loss: 0.01450435258448124
step: 130, loss: 0.0039032630156725645
step: 140, loss: 0.003139318898320198
step: 150, loss: 0.0013862503692507744
step: 160, loss: 0.0008578614797443151
step: 170, loss: 0.0006544330390170217
step: 180, loss: 0.0003120911424048245
step: 190, loss: 0.04351849481463432
step: 200, loss: 0.000810821948107332
step: 210, loss: 0.004541338421404362
step: 220, loss: 0.0004397984012030065
step: 230, loss: 0.023347029462456703
step: 240, loss: 0.012078171595931053
step: 250, loss: 0.0007255323580466211
step: 260, loss: 0.028136998414993286
step: 270, loss: 0.05464605987071991
step: 280, loss: 0.0006506106583401561
step: 290, loss: 0.000786186836194247
step: 300, loss: 0.02403084747493267
step: 310, loss: 0.003536253934726119
step: 320, loss: 0.001877973903901875
step: 330, loss: 0.003197974059730768
step: 340, loss: 0.0033449437469244003
step: 350, loss: 0.00040986205567605793
step: 360, loss: 0.0006331404438242316
step: 370, loss: 0.006867177318781614
step: 380, loss: 0.0017734604189172387
epoch 10: dev_f1=0.7550000000000001, f1=0.5944444444444444, best_f1=0.47852760736196315
step: 0, loss: 0.0038964785635471344
step: 10, loss: 0.00543629564344883
step: 20, loss: 0.1286410689353943
step: 30, loss: 0.0009769570315256715
step: 40, loss: 0.0014124715235084295
step: 50, loss: 0.002134611364454031
step: 60, loss: 0.0003333424683660269
step: 70, loss: 0.0016539503121748567
step: 80, loss: 0.02182113565504551
step: 90, loss: 0.0942237377166748
step: 100, loss: 0.010380236431956291
step: 110, loss: 0.0018618230242282152
step: 120, loss: 0.019449777901172638
step: 130, loss: 0.004008568823337555
step: 140, loss: 0.0040002851746976376
step: 150, loss: 0.029729455709457397
step: 160, loss: 0.0008932981290854514
step: 170, loss: 0.009241770952939987
step: 180, loss: 0.010788211598992348
step: 190, loss: 0.01735226809978485
step: 200, loss: 0.005201689433306456
step: 210, loss: 0.0004849048564210534
step: 220, loss: 0.0002588213828857988
step: 230, loss: 0.002036570804193616
step: 240, loss: 0.006399848032742739
step: 250, loss: 0.00033668303512968123
step: 260, loss: 0.0008645047200843692
step: 270, loss: 0.07787860184907913
step: 280, loss: 0.0002033062046393752
step: 290, loss: 0.001998825231567025
step: 300, loss: 0.0482977069914341
step: 310, loss: 0.00044701743172481656
step: 320, loss: 0.03871063515543938
step: 330, loss: 0.0005178229184821248
step: 340, loss: 0.0002830693556461483
step: 350, loss: 0.001831076224334538
step: 360, loss: 0.00023301683540921658
step: 370, loss: 0.010330362245440483
step: 380, loss: 0.002267424250021577
epoch 11: dev_f1=0.7751937984496123, f1=0.6242774566473989, best_f1=0.47852760736196315
step: 0, loss: 0.0034221606329083443
step: 10, loss: 0.11413103342056274
step: 20, loss: 0.0037922984920442104
step: 30, loss: 0.000687061867211014
step: 40, loss: 0.001004350371658802
step: 50, loss: 0.0016457566525787115
step: 60, loss: 0.005979353561997414
step: 70, loss: 0.000339655380230397
step: 80, loss: 0.02757180482149124
step: 90, loss: 0.001555224764160812
step: 100, loss: 0.0022369311191141605
step: 110, loss: 0.0007261871942318976
step: 120, loss: 0.0009752433397807181
step: 130, loss: 0.030495041981339455
step: 140, loss: 0.000574883830267936
step: 150, loss: 0.0018126505892723799
step: 160, loss: 0.012758222408592701
step: 170, loss: 0.0008187774219550192
step: 180, loss: 9.369172767037526e-05
step: 190, loss: 0.0037139987107366323
step: 200, loss: 0.001297465991228819
step: 210, loss: 0.0007194065256044269
step: 220, loss: 0.0008605507318861783
step: 230, loss: 0.011244981549680233
step: 240, loss: 0.05648629367351532
step: 250, loss: 0.0004903223016299307
step: 260, loss: 0.05366847664117813
step: 270, loss: 0.001994228456169367
step: 280, loss: 0.00017941377882380038
step: 290, loss: 0.018647249788045883
step: 300, loss: 0.009518676437437534
step: 310, loss: 0.0007789088413119316
step: 320, loss: 0.001083692186512053
step: 330, loss: 0.0007490178686566651
step: 340, loss: 0.006506874691694975
step: 350, loss: 0.0006318613886833191
step: 360, loss: 0.0011218204163014889
step: 370, loss: 0.00040421728044748306
step: 380, loss: 0.0033823130652308464
epoch 12: dev_f1=0.779746835443038, f1=0.6502732240437159, best_f1=0.47852760736196315
step: 0, loss: 0.0009250467992387712
step: 10, loss: 0.0005788737325929105
step: 20, loss: 0.031141558662056923
step: 30, loss: 0.0007610528846271336
step: 40, loss: 0.001240729819983244
step: 50, loss: 0.0015454802196472883
step: 60, loss: 0.0011456088395789266
step: 70, loss: 0.0010119314538314939
step: 80, loss: 0.001780340913683176
step: 90, loss: 0.004679775796830654
step: 100, loss: 0.00021541975729633123
step: 110, loss: 0.0012041585287079215
step: 120, loss: 0.0001466871763113886
step: 130, loss: 0.0008735326700843871
step: 140, loss: 0.015717176720499992
step: 150, loss: 0.00030523951863870025
step: 160, loss: 0.0005440152017399669
step: 170, loss: 0.0014778866898268461
step: 180, loss: 0.01056373305618763
step: 190, loss: 8.195981354219839e-05
step: 200, loss: 0.00018193577125202864
step: 210, loss: 0.003539738245308399
step: 220, loss: 0.0009645349346101284
step: 230, loss: 0.0021860988344997168
step: 240, loss: 0.07762007415294647
step: 250, loss: 0.03835911676287651
step: 260, loss: 0.0003840354329440743
step: 270, loss: 0.0006654046010226011
step: 280, loss: 0.0004970937152393162
step: 290, loss: 0.0027951980009675026
step: 300, loss: 0.00103674060665071
step: 310, loss: 0.000602708721999079
step: 320, loss: 0.0019889387767761946
step: 330, loss: 0.0008335227030329406
step: 340, loss: 0.00180926569737494
step: 350, loss: 0.0033423167187720537
step: 360, loss: 0.03289172425866127
step: 370, loss: 0.0010221365373581648
step: 380, loss: 0.0011091377818956971
epoch 13: dev_f1=0.7629427792915532, f1=0.5864197530864198, best_f1=0.47852760736196315
step: 0, loss: 0.0006303011323325336
step: 10, loss: 0.00023463611432816833
step: 20, loss: 0.012211723253130913
step: 30, loss: 0.0006233584717847407
step: 40, loss: 0.004772729240357876
step: 50, loss: 0.0020993126090615988
step: 60, loss: 0.0006946921348571777
step: 70, loss: 0.00021051111980341375
step: 80, loss: 0.0008131841314025223
step: 90, loss: 0.00014739502512384206
step: 100, loss: 0.00012356358638498932
step: 110, loss: 0.0005418272921815515
step: 120, loss: 0.007358075585216284
step: 130, loss: 0.0016279740957543254
step: 140, loss: 0.13816265761852264
step: 150, loss: 0.0010319693246856332
step: 160, loss: 0.00012690397852566093
step: 170, loss: 0.0005871817702427506
step: 180, loss: 0.0016483149956911802
step: 190, loss: 6.692267925245687e-05
step: 200, loss: 0.0010061466600745916
step: 210, loss: 0.00046320934779942036
step: 220, loss: 0.00010234487126581371
step: 230, loss: 0.00015142475604079664
step: 240, loss: 0.00024364142154809088
step: 250, loss: 0.00022821604216005653
step: 260, loss: 0.005485574249178171
step: 270, loss: 0.0005463914130814373
step: 280, loss: 0.010119326412677765
step: 290, loss: 9.398195834364742e-05
step: 300, loss: 0.005321795586496592
step: 310, loss: 0.0027250079438090324
step: 320, loss: 0.0003430914366617799
step: 330, loss: 0.00031835550907999277
step: 340, loss: 0.031576257199048996
step: 350, loss: 0.0005510632763616741
step: 360, loss: 0.20373325049877167
step: 370, loss: 0.00416585523635149
step: 380, loss: 0.00016375762061215937
epoch 14: dev_f1=0.7774798927613942, f1=0.6035502958579881, best_f1=0.47852760736196315
step: 0, loss: 0.00020477805810514838
step: 10, loss: 0.00020437678904272616
step: 20, loss: 0.00021499890135601163
step: 30, loss: 0.00019183832046110183
step: 40, loss: 6.978691817494109e-05
step: 50, loss: 0.00016189066809602082
step: 60, loss: 7.188347808551043e-05
step: 70, loss: 0.0016238196985796094
step: 80, loss: 0.00016390893142670393
step: 90, loss: 0.0001346257922705263
step: 100, loss: 0.0006553635466843843
step: 110, loss: 0.00010392444528406486
step: 120, loss: 0.003838395234197378
step: 130, loss: 0.0011406177654862404
step: 140, loss: 0.0014942953130230308
step: 150, loss: 0.021374648436903954
step: 160, loss: 0.006820387206971645
step: 170, loss: 8.995783719001338e-05
step: 180, loss: 0.0008490865002386272
step: 190, loss: 0.0018409456824883819
step: 200, loss: 0.000663268263451755
step: 210, loss: 0.00024050468346104026
step: 220, loss: 0.0011239908635616302
step: 230, loss: 0.00010270010534441099
step: 240, loss: 0.0029210869688540697
step: 250, loss: 0.003033913904801011
step: 260, loss: 0.0027670322451740503
step: 270, loss: 0.0013905836967751384
step: 280, loss: 0.0027333947364240885
step: 290, loss: 0.0033017098903656006
step: 300, loss: 0.002026536501944065
step: 310, loss: 0.006514820270240307
step: 320, loss: 0.001860394491814077
step: 330, loss: 0.00010203519923379645
step: 340, loss: 0.00025395231205038726
step: 350, loss: 0.00012408240581862628
step: 360, loss: 0.0003593247674871236
step: 370, loss: 0.0019846416544169188
step: 380, loss: 0.0013803234323859215
epoch 15: dev_f1=0.7703703703703704, f1=0.6510416666666666, best_f1=0.47852760736196315
step: 0, loss: 0.01598690077662468
step: 10, loss: 0.00018975342391058803
step: 20, loss: 6.97424984537065e-05
step: 30, loss: 0.000888357637450099
step: 40, loss: 0.000381325779017061
step: 50, loss: 0.0029812748543918133
step: 60, loss: 0.007467842660844326
step: 70, loss: 0.00020198860147502273
step: 80, loss: 0.00010456403106218204
step: 90, loss: 0.00011930702748941258
step: 100, loss: 0.00015132944099605083
step: 110, loss: 0.00012111229443689808
step: 120, loss: 7.856839511077851e-05
step: 130, loss: 0.0006519054877571762
step: 140, loss: 0.00035753034171648324
step: 150, loss: 0.00034546927781775594
step: 160, loss: 0.009930799715220928
step: 170, loss: 0.0003602679062169045
step: 180, loss: 0.001640368951484561
step: 190, loss: 8.273065031971782e-05
step: 200, loss: 6.76384152029641e-05
step: 210, loss: 0.030570445582270622
step: 220, loss: 0.006380402948707342
step: 230, loss: 0.0004424966173246503
step: 240, loss: 0.0006640397477895021
step: 250, loss: 0.00011591409565880895
step: 260, loss: 0.0003709407174028456
step: 270, loss: 0.039889756590127945
step: 280, loss: 0.005379496142268181
step: 290, loss: 0.0025570609141141176
step: 300, loss: 0.0012220608768984675
step: 310, loss: 0.00012759149831254035
step: 320, loss: 0.0015940509038046002
step: 330, loss: 0.0005149631178937852
step: 340, loss: 0.00027279084315523505
step: 350, loss: 0.0020186754409223795
step: 360, loss: 0.00016918370965868235
step: 370, loss: 0.00022939129848964512
step: 380, loss: 0.000127190665807575
epoch 16: dev_f1=0.7657142857142857, f1=0.49664429530201337, best_f1=0.47852760736196315
step: 0, loss: 5.7346056564711034e-05
step: 10, loss: 0.006237992085516453
step: 20, loss: 0.0017967085586860776
step: 30, loss: 8.887598960427567e-05
step: 40, loss: 5.9212761698290706e-05
step: 50, loss: 9.660980140324682e-05
step: 60, loss: 0.0001899160270113498
step: 70, loss: 0.00014577181718777865
step: 80, loss: 0.0032713506370782852
step: 90, loss: 0.002500188071280718
step: 100, loss: 8.902542322175577e-05
step: 110, loss: 0.00010640152322594076
step: 120, loss: 0.0034004992339760065
step: 130, loss: 0.0001564730191603303
step: 140, loss: 0.0012337176594883204
step: 150, loss: 0.0002847869473043829
step: 160, loss: 0.014407416805624962
step: 170, loss: 0.000158844530233182
step: 180, loss: 0.0010879364563152194
step: 190, loss: 0.00011768559488700703
step: 200, loss: 0.00011349247506586835
step: 210, loss: 0.09420076012611389
step: 220, loss: 0.0003234697796870023
step: 230, loss: 0.0021383424755185843
step: 240, loss: 0.0006032787496224046
step: 250, loss: 0.00210105930455029
step: 260, loss: 5.2691517339553684e-05
step: 270, loss: 0.0010192689951509237
step: 280, loss: 0.00033264621743001044
step: 290, loss: 0.00031160717480815947
step: 300, loss: 0.0036385960411280394
step: 310, loss: 0.0005027086590416729
step: 320, loss: 0.000737200491130352
step: 330, loss: 0.00015653014997951686
step: 340, loss: 0.00010094723984366283
step: 350, loss: 0.000264940841589123
step: 360, loss: 0.00014687840302940458
step: 370, loss: 8.076462836470455e-05
step: 380, loss: 0.00020731810946017504
epoch 17: dev_f1=0.772845953002611, f1=0.6171428571428571, best_f1=0.47852760736196315
step: 0, loss: 4.4362917833495885e-05
step: 10, loss: 0.0003809830523096025
step: 20, loss: 0.00024046777980402112
step: 30, loss: 0.0005660659517161548
step: 40, loss: 0.0001999390806304291
step: 50, loss: 0.001072095357812941
step: 60, loss: 0.0022955138701945543
step: 70, loss: 6.750618922524154e-05
step: 80, loss: 0.0003910439554601908
step: 90, loss: 9.02778992895037e-05
step: 100, loss: 0.00025010426179505885
step: 110, loss: 0.001232474809512496
step: 120, loss: 9.527841029921547e-05
step: 130, loss: 0.0004120566009078175
step: 140, loss: 0.00011029546294594184
step: 150, loss: 9.902706369757652e-05
step: 160, loss: 0.00013810205564368516
step: 170, loss: 0.0004840475448872894
step: 180, loss: 0.0006191489519551396
step: 190, loss: 8.81516098161228e-05
step: 200, loss: 0.0004183744022157043
step: 210, loss: 6.0923794080736116e-05
step: 220, loss: 0.00012200458877487108
step: 230, loss: 0.010012893006205559
step: 240, loss: 0.0004183318233117461
step: 250, loss: 0.01066641230136156
step: 260, loss: 4.1359093302162364e-05
step: 270, loss: 0.00048433156916871667
step: 280, loss: 0.0015160258626565337
step: 290, loss: 9.976699948310852e-05
step: 300, loss: 7.629438914591447e-05
step: 310, loss: 0.00035586385638453066
step: 320, loss: 4.333633842179552e-05
step: 330, loss: 0.00023249152582138777
step: 340, loss: 0.0003194955934304744
step: 350, loss: 0.0005530413473024964
step: 360, loss: 0.00010196270886808634
step: 370, loss: 8.827531564747915e-05
step: 380, loss: 0.00010217938688583672
epoch 18: dev_f1=0.7708333333333334, f1=0.6353591160220994, best_f1=0.47852760736196315
step: 0, loss: 0.011076655238866806
step: 10, loss: 5.463881461764686e-05
step: 20, loss: 0.05737435817718506
step: 30, loss: 0.00024195258447434753
step: 40, loss: 4.8592275561532006e-05
step: 50, loss: 0.00020214461255818605
step: 60, loss: 3.057227877434343e-05
step: 70, loss: 0.0023032238241285086
step: 80, loss: 0.0003373004437889904
step: 90, loss: 0.00020802606013603508
step: 100, loss: 0.0019511610735207796
step: 110, loss: 8.165655162883922e-05
step: 120, loss: 0.00013676093658432364
step: 130, loss: 5.9064732340630144e-05
step: 140, loss: 4.430478293215856e-05
step: 150, loss: 0.038737520575523376
step: 160, loss: 0.0001303416647715494
step: 170, loss: 0.00044925633119419217
step: 180, loss: 0.0014949431642889977
step: 190, loss: 8.976093522505835e-05
step: 200, loss: 0.0001315109693678096
step: 210, loss: 5.6104010582203045e-05
step: 220, loss: 0.0011937007075175643
step: 230, loss: 0.00011147834447911009
step: 240, loss: 2.757005495368503e-05
step: 250, loss: 8.233382686739787e-05
step: 260, loss: 8.207933569792658e-05
step: 270, loss: 0.006794312037527561
step: 280, loss: 0.005364187993109226
step: 290, loss: 0.0001213995783473365
step: 300, loss: 0.00011277360317762941
step: 310, loss: 6.096746074035764e-05
step: 320, loss: 0.0006039612926542759
step: 330, loss: 9.979333844967186e-05
step: 340, loss: 3.697910869959742e-05
step: 350, loss: 0.00015175937733147293
step: 360, loss: 0.00781968142837286
step: 370, loss: 0.00034304556902498007
step: 380, loss: 0.00012074279220541939
epoch 19: dev_f1=0.7641025641025642, f1=0.6373626373626373, best_f1=0.47852760736196315
step: 0, loss: 0.018948253244161606
step: 10, loss: 9.729374869493768e-05
step: 20, loss: 5.783401502412744e-05
step: 30, loss: 0.001287329476326704
step: 40, loss: 0.007355458103120327
step: 50, loss: 0.00019755434186663479
step: 60, loss: 0.00012815975060220808
step: 70, loss: 0.00011714114953065291
step: 80, loss: 0.012019440531730652
step: 90, loss: 0.0009041863959282637
step: 100, loss: 0.006009142380207777
step: 110, loss: 0.0003012728411704302
step: 120, loss: 0.000616627570707351
step: 130, loss: 3.189070412190631e-05
step: 140, loss: 0.0001352582621620968
step: 150, loss: 5.134679304319434e-05
step: 160, loss: 0.001268260646611452
step: 170, loss: 0.0004221157869324088
step: 180, loss: 6.617317558266222e-05
step: 190, loss: 0.0006598006002604961
step: 200, loss: 9.290821617469192e-05
step: 210, loss: 0.07413386553525925
step: 220, loss: 0.00010552188177825883
step: 230, loss: 0.0006777245434932411
step: 240, loss: 0.0011319350451231003
step: 250, loss: 0.010281221941113472
step: 260, loss: 0.000869206094648689
step: 270, loss: 0.007380257826298475
step: 280, loss: 0.007854102179408073
step: 290, loss: 0.000122587094665505
step: 300, loss: 0.01677466370165348
step: 310, loss: 5.01717186125461e-05
step: 320, loss: 4.8238060117000714e-05
step: 330, loss: 4.2469928303034976e-05
step: 340, loss: 0.0016213878989219666
step: 350, loss: 4.621457264875062e-05
step: 360, loss: 3.175669189658947e-05
step: 370, loss: 0.000907104229554534
step: 380, loss: 7.488876872230321e-05
epoch 20: dev_f1=0.7772020725388601, f1=0.6330532212885155, best_f1=0.47852760736196315
