cuda
Device: cuda
step: 0, loss: 0.8329637050628662
step: 10, loss: 0.41723933815956116
step: 20, loss: 0.25812628865242004
step: 30, loss: 0.3048112690448761
step: 40, loss: 0.15812745690345764
step: 50, loss: 0.300656795501709
step: 60, loss: 0.30989187955856323
step: 70, loss: 0.30676791071891785
step: 80, loss: 0.2329588681459427
step: 90, loss: 0.1509270817041397
step: 100, loss: 0.3676930367946625
step: 110, loss: 0.15532171726226807
step: 120, loss: 0.22626198828220367
step: 130, loss: 0.387060284614563
step: 140, loss: 0.23354949057102203
step: 150, loss: 0.41117557883262634
step: 160, loss: 0.12605975568294525
step: 170, loss: 0.510443925857544
step: 180, loss: 0.34920790791511536
step: 190, loss: 0.1671295017004013
step: 200, loss: 0.24098798632621765
step: 210, loss: 0.24816752970218658
step: 220, loss: 0.29693707823753357
step: 230, loss: 0.22897152602672577
step: 240, loss: 0.3161012530326843
step: 250, loss: 0.34186819195747375
step: 260, loss: 0.30055299401283264
step: 270, loss: 0.20236393809318542
step: 280, loss: 0.3014506697654724
step: 290, loss: 0.20341074466705322
step: 300, loss: 0.2830343544483185
step: 310, loss: 0.2213248759508133
step: 320, loss: 0.16813968122005463
step: 330, loss: 0.2063644677400589
step: 340, loss: 0.17867586016654968
step: 350, loss: 0.35005617141723633
step: 360, loss: 0.3217586278915405
step: 370, loss: 0.1846795529127121
step: 380, loss: 0.3530479669570923
epoch 1: dev_f1=0.5708245243128964, f1=0.35604395604395606, best_f1=0.35604395604395606
step: 0, loss: 0.23277470469474792
step: 10, loss: 0.19017907977104187
step: 20, loss: 0.06719851493835449
step: 30, loss: 0.22143854200839996
step: 40, loss: 0.16712912917137146
step: 50, loss: 0.14085133373737335
step: 60, loss: 0.19233140349388123
step: 70, loss: 0.21999530494213104
step: 80, loss: 0.1979018598794937
step: 90, loss: 0.36351585388183594
step: 100, loss: 0.13647498190402985
step: 110, loss: 0.3911392390727997
step: 120, loss: 0.21063931286334991
step: 130, loss: 0.12354470789432526
step: 140, loss: 0.2343856394290924
step: 150, loss: 0.26004958152770996
step: 160, loss: 0.30227410793304443
step: 170, loss: 0.33796948194503784
step: 180, loss: 0.2426803857088089
step: 190, loss: 0.3668838143348694
step: 200, loss: 0.22589676082134247
step: 210, loss: 0.3011220097541809
step: 220, loss: 0.30964475870132446
step: 230, loss: 0.12655895948410034
step: 240, loss: 0.11935750395059586
step: 250, loss: 0.06647960841655731
step: 260, loss: 0.1920381784439087
step: 270, loss: 0.3024576008319855
step: 280, loss: 0.08704840391874313
step: 290, loss: 0.14296212792396545
step: 300, loss: 0.2803010940551758
step: 310, loss: 0.20116189122200012
step: 320, loss: 0.19941310584545135
step: 330, loss: 0.38675373792648315
step: 340, loss: 0.19345325231552124
step: 350, loss: 0.188267782330513
step: 360, loss: 0.2822612524032593
step: 370, loss: 0.08342044800519943
step: 380, loss: 0.23947326838970184
epoch 2: dev_f1=0.7041564792176039, f1=0.48663101604278075, best_f1=0.48663101604278075
step: 0, loss: 0.14285914599895477
step: 10, loss: 0.4324096143245697
step: 20, loss: 0.08043330907821655
step: 30, loss: 0.14429472386837006
step: 40, loss: 0.3427446782588959
step: 50, loss: 0.21943534910678864
step: 60, loss: 0.09900406748056412
step: 70, loss: 0.3130951225757599
step: 80, loss: 0.04796697199344635
step: 90, loss: 0.1300746351480484
step: 100, loss: 0.12089929729700089
step: 110, loss: 0.2044174075126648
step: 120, loss: 0.11488047242164612
step: 130, loss: 0.08303795009851456
step: 140, loss: 0.146105095744133
step: 150, loss: 0.11892241984605789
step: 160, loss: 0.07667616009712219
step: 170, loss: 0.04199415072798729
step: 180, loss: 0.18533280491828918
step: 190, loss: 0.3381056487560272
step: 200, loss: 0.47242864966392517
step: 210, loss: 0.04525456577539444
step: 220, loss: 0.12488521635532379
step: 230, loss: 0.09195626527070999
step: 240, loss: 0.09346623718738556
step: 250, loss: 0.26227307319641113
step: 260, loss: 0.19554604589939117
step: 270, loss: 0.18371084332466125
step: 280, loss: 0.11309774219989777
step: 290, loss: 0.1340414583683014
step: 300, loss: 0.16629363596439362
step: 310, loss: 0.2004956305027008
step: 320, loss: 0.19529402256011963
step: 330, loss: 0.049455367028713226
step: 340, loss: 0.19733062386512756
step: 350, loss: 0.11087135970592499
step: 360, loss: 0.04827849194407463
step: 370, loss: 0.17289820313453674
step: 380, loss: 0.3693978786468506
epoch 3: dev_f1=0.7626262626262625, f1=0.49142857142857144, best_f1=0.49142857142857144
step: 0, loss: 0.09989061206579208
step: 10, loss: 0.07250896841287613
step: 20, loss: 0.08881659805774689
step: 30, loss: 0.03201497346162796
step: 40, loss: 0.05817510932683945
step: 50, loss: 0.14571209251880646
step: 60, loss: 0.01639854721724987
step: 70, loss: 0.03834803029894829
step: 80, loss: 0.08404704183340073
step: 90, loss: 0.03488902002573013
step: 100, loss: 0.08150549978017807
step: 110, loss: 0.16649696230888367
step: 120, loss: 0.03772404417395592
step: 130, loss: 0.10735473781824112
step: 140, loss: 0.04567401111125946
step: 150, loss: 0.23487302660942078
step: 160, loss: 0.2366432398557663
step: 170, loss: 0.22989536821842194
step: 180, loss: 0.125310480594635
step: 190, loss: 0.03909112885594368
step: 200, loss: 0.0884903073310852
step: 210, loss: 0.024100463837385178
step: 220, loss: 0.1923537701368332
step: 230, loss: 0.22855216264724731
step: 240, loss: 0.16154740750789642
step: 250, loss: 0.14934873580932617
step: 260, loss: 0.0998062938451767
step: 270, loss: 0.05079813674092293
step: 280, loss: 0.09656497091054916
step: 290, loss: 0.03798864409327507
step: 300, loss: 0.12064266949892044
step: 310, loss: 0.062309227883815765
step: 320, loss: 0.07940824329853058
step: 330, loss: 0.07354068756103516
step: 340, loss: 0.03836573660373688
step: 350, loss: 0.30951762199401855
step: 360, loss: 0.035862475633621216
step: 370, loss: 0.02322693169116974
step: 380, loss: 0.14583498239517212
epoch 4: dev_f1=0.7917737789203083, f1=0.5434782608695653, best_f1=0.5434782608695653
step: 0, loss: 0.07764768600463867
step: 10, loss: 0.052725329995155334
step: 20, loss: 0.03459906578063965
step: 30, loss: 0.03771676495671272
step: 40, loss: 0.05441269651055336
step: 50, loss: 0.07425053417682648
step: 60, loss: 0.03919575363397598
step: 70, loss: 0.09636180847883224
step: 80, loss: 0.00988948717713356
step: 90, loss: 0.08673020452260971
step: 100, loss: 0.24915817379951477
step: 110, loss: 0.06834697723388672
step: 120, loss: 0.027301812544465065
step: 130, loss: 0.15901753306388855
step: 140, loss: 0.013164374977350235
step: 150, loss: 0.04367860406637192
step: 160, loss: 0.1359448879957199
step: 170, loss: 0.07837187498807907
step: 180, loss: 0.006059059873223305
step: 190, loss: 0.08713959902524948
step: 200, loss: 0.07325480133295059
step: 210, loss: 0.14761295914649963
step: 220, loss: 0.16033165156841278
step: 230, loss: 0.015803461894392967
step: 240, loss: 0.06640563905239105
step: 250, loss: 0.07506827265024185
step: 260, loss: 0.008578685112297535
step: 270, loss: 0.1568579524755478
step: 280, loss: 0.02880408987402916
step: 290, loss: 0.009068249724805355
step: 300, loss: 0.1128077581524849
step: 310, loss: 0.03530089184641838
step: 320, loss: 0.09257054328918457
step: 330, loss: 0.038636334240436554
step: 340, loss: 0.024109408259391785
step: 350, loss: 0.03026271052658558
step: 360, loss: 0.05483121797442436
step: 370, loss: 0.10574329644441605
step: 380, loss: 0.06184278428554535
epoch 5: dev_f1=0.7494033412887827, f1=0.539440203562341, best_f1=0.5434782608695653
step: 0, loss: 0.09534257650375366
step: 10, loss: 0.016205063089728355
step: 20, loss: 0.04903773218393326
step: 30, loss: 0.005571292247623205
step: 40, loss: 0.018915770575404167
step: 50, loss: 0.01159122958779335
step: 60, loss: 0.014097962528467178
step: 70, loss: 0.07900778204202652
step: 80, loss: 0.037710629403591156
step: 90, loss: 0.11392886191606522
step: 100, loss: 0.019176553934812546
step: 110, loss: 0.03619846701622009
step: 120, loss: 0.006725079379975796
step: 130, loss: 0.18777209520339966
step: 140, loss: 0.06271816790103912
step: 150, loss: 0.045165590941905975
step: 160, loss: 0.009614204987883568
step: 170, loss: 0.02082028239965439
step: 180, loss: 0.006531527265906334
step: 190, loss: 0.01657734252512455
step: 200, loss: 0.038452085107564926
step: 210, loss: 0.020663252100348473
step: 220, loss: 0.09961827099323273
step: 230, loss: 0.006225307937711477
step: 240, loss: 0.026712657883763313
step: 250, loss: 0.028368869796395302
step: 260, loss: 0.024233778938651085
step: 270, loss: 0.02169366553425789
step: 280, loss: 0.07782654464244843
step: 290, loss: 0.08509116619825363
step: 300, loss: 0.04701012000441551
step: 310, loss: 0.0032735192216932774
step: 320, loss: 0.014666283503174782
step: 330, loss: 0.00974711962044239
step: 340, loss: 0.04227186739444733
step: 350, loss: 0.002463073004037142
step: 360, loss: 0.009834113530814648
step: 370, loss: 0.12520372867584229
step: 380, loss: 0.15844234824180603
epoch 6: dev_f1=0.7550000000000001, f1=0.568421052631579, best_f1=0.5434782608695653
step: 0, loss: 0.07734094560146332
step: 10, loss: 0.031233366578817368
step: 20, loss: 0.04443934187293053
step: 30, loss: 0.015337957069277763
step: 40, loss: 0.006181429605931044
step: 50, loss: 0.0028820002917200327
step: 60, loss: 0.08502185344696045
step: 70, loss: 0.016564391553401947
step: 80, loss: 0.022339442744851112
step: 90, loss: 0.1278011053800583
step: 100, loss: 0.031510788947343826
step: 110, loss: 0.004402862396091223
step: 120, loss: 0.008004188537597656
step: 130, loss: 0.001489361748099327
step: 140, loss: 0.025845656171441078
step: 150, loss: 0.011867391876876354
step: 160, loss: 0.06500481069087982
step: 170, loss: 0.14708012342453003
step: 180, loss: 0.012192759662866592
step: 190, loss: 0.029098806902766228
step: 200, loss: 0.007006270345300436
step: 210, loss: 0.25488466024398804
step: 220, loss: 0.0498528853058815
step: 230, loss: 0.002607071539387107
step: 240, loss: 0.0954553559422493
step: 250, loss: 0.02929324470460415
step: 260, loss: 0.005107846576720476
step: 270, loss: 0.01915653981268406
step: 280, loss: 0.031318530440330505
step: 290, loss: 0.014125621877610683
step: 300, loss: 0.012127066031098366
step: 310, loss: 0.038678109645843506
step: 320, loss: 0.05506667122244835
step: 330, loss: 0.00609371904283762
step: 340, loss: 0.023580938577651978
step: 350, loss: 0.04264656454324722
step: 360, loss: 0.06541947275400162
step: 370, loss: 0.048315733671188354
step: 380, loss: 0.005591328255832195
epoch 7: dev_f1=0.7823834196891192, f1=0.5706371191135734, best_f1=0.5434782608695653
step: 0, loss: 0.023057449609041214
step: 10, loss: 0.0007367446669377387
step: 20, loss: 0.0036245693918317556
step: 30, loss: 0.04323435574769974
step: 40, loss: 0.26110848784446716
step: 50, loss: 0.08785080909729004
step: 60, loss: 0.005570508074015379
step: 70, loss: 0.024364754557609558
step: 80, loss: 0.025802869349718094
step: 90, loss: 0.034188758581876755
step: 100, loss: 0.0015336557989940047
step: 110, loss: 0.003315460868179798
step: 120, loss: 0.13503822684288025
step: 130, loss: 0.07691936939954758
step: 140, loss: 0.0032888883724808693
step: 150, loss: 0.002195916371420026
step: 160, loss: 0.00242579635232687
step: 170, loss: 0.027036506682634354
step: 180, loss: 0.07906210422515869
step: 190, loss: 0.014835933223366737
step: 200, loss: 0.006828555837273598
step: 210, loss: 0.019654229283332825
step: 220, loss: 0.013166408985853195
step: 230, loss: 0.0030403409618884325
step: 240, loss: 0.1818838119506836
step: 250, loss: 0.00603349506855011
step: 260, loss: 0.013618958182632923
step: 270, loss: 0.012709904462099075
step: 280, loss: 0.026683196425437927
step: 290, loss: 0.08864935487508774
step: 300, loss: 0.02351023256778717
step: 310, loss: 0.003806101158261299
step: 320, loss: 0.0018416261300444603
step: 330, loss: 0.010722964070737362
step: 340, loss: 0.035665422677993774
step: 350, loss: 0.01910628378391266
step: 360, loss: 0.06880456954240799
step: 370, loss: 0.019378148019313812
step: 380, loss: 0.003555567702278495
epoch 8: dev_f1=0.7669902912621359, f1=0.6004962779156328, best_f1=0.5434782608695653
step: 0, loss: 0.004093189723789692
step: 10, loss: 0.006423895712941885
step: 20, loss: 0.013570684939622879
step: 30, loss: 0.048260413110256195
step: 40, loss: 0.02556735649704933
step: 50, loss: 0.0022391313686966896
step: 60, loss: 0.00035378424217924476
step: 70, loss: 0.017009107396006584
step: 80, loss: 0.0008206709171645343
step: 90, loss: 0.0019068971741944551
step: 100, loss: 0.002412258880212903
step: 110, loss: 0.08937085419893265
step: 120, loss: 0.0416702963411808
step: 130, loss: 0.0056034596636891365
step: 140, loss: 0.010048646479845047
step: 150, loss: 0.0006571421399712563
step: 160, loss: 0.07972342520952225
step: 170, loss: 0.009436989203095436
step: 180, loss: 0.004479269962757826
step: 190, loss: 0.0017925860593095422
step: 200, loss: 0.0023510237224400043
step: 210, loss: 0.000665442377794534
step: 220, loss: 0.002081754384562373
step: 230, loss: 0.015412249602377415
step: 240, loss: 0.06970673054456711
step: 250, loss: 0.06756661087274551
step: 260, loss: 0.00045712609426118433
step: 270, loss: 0.05660558119416237
step: 280, loss: 0.02166135050356388
step: 290, loss: 0.0013413960114121437
step: 300, loss: 0.0015335164498537779
step: 310, loss: 0.0644296333193779
step: 320, loss: 0.003529824549332261
step: 330, loss: 0.012872959487140179
step: 340, loss: 0.019043922424316406
step: 350, loss: 0.003935331478714943
step: 360, loss: 0.001054543536156416
step: 370, loss: 0.003391882171854377
step: 380, loss: 0.0016933527076616883
epoch 9: dev_f1=0.739946380697051, f1=0.5058823529411764, best_f1=0.5434782608695653
step: 0, loss: 0.007142762653529644
step: 10, loss: 0.0007313019596040249
step: 20, loss: 0.009668808430433273
step: 30, loss: 0.0019195983186364174
step: 40, loss: 0.00015479086141567677
step: 50, loss: 0.2642705738544464
step: 60, loss: 0.0010260549606755376
step: 70, loss: 0.0002424908016109839
step: 80, loss: 0.004639322403818369
step: 90, loss: 0.0012290272861719131
step: 100, loss: 0.026915961876511574
step: 110, loss: 0.00036846098373644054
step: 120, loss: 0.001886146143078804
step: 130, loss: 0.0010544228134676814
step: 140, loss: 0.0008903688285499811
step: 150, loss: 0.0007518809870816767
step: 160, loss: 0.014211109839379787
step: 170, loss: 0.0002020263345912099
step: 180, loss: 0.001244955463334918
step: 190, loss: 0.0014616309199482203
step: 200, loss: 0.1099548414349556
step: 210, loss: 0.042051076889038086
step: 220, loss: 0.002845615614205599
step: 230, loss: 0.2400718480348587
step: 240, loss: 0.001027423539198935
step: 250, loss: 0.013549202121794224
step: 260, loss: 0.002460230141878128
step: 270, loss: 0.0002769201819319278
step: 280, loss: 0.06958332657814026
step: 290, loss: 0.0028743103612214327
step: 300, loss: 0.00246413960121572
step: 310, loss: 0.007089526392519474
step: 320, loss: 0.0008547373581677675
step: 330, loss: 0.00621968787163496
step: 340, loss: 0.05688610300421715
step: 350, loss: 0.008012267760932446
step: 360, loss: 0.004402452614158392
step: 370, loss: 0.004725499078631401
step: 380, loss: 0.0016258021350950003
epoch 10: dev_f1=0.7336956521739131, f1=0.5454545454545454, best_f1=0.5434782608695653
step: 0, loss: 0.0011806321563199162
step: 10, loss: 0.0012109228409826756
step: 20, loss: 0.04383799061179161
step: 30, loss: 0.0006598735926672816
step: 40, loss: 0.002150452695786953
step: 50, loss: 0.004479947965592146
step: 60, loss: 0.0008937628590501845
step: 70, loss: 0.08780166506767273
step: 80, loss: 0.0009997227462008595
step: 90, loss: 0.021698052063584328
step: 100, loss: 0.010126948356628418
step: 110, loss: 0.00023417521151714027
step: 120, loss: 0.0005283193895593286
step: 130, loss: 0.028800100088119507
step: 140, loss: 0.002248616423457861
step: 150, loss: 0.003920021932572126
step: 160, loss: 0.0013228337047621608
step: 170, loss: 0.0001927418925333768
step: 180, loss: 0.004066823981702328
step: 190, loss: 0.003368217730894685
step: 200, loss: 0.0040214769542217255
step: 210, loss: 0.001357624656520784
step: 220, loss: 0.022752268239855766
step: 230, loss: 0.03834806755185127
step: 240, loss: 0.027415409684181213
step: 250, loss: 0.0008810240542516112
step: 260, loss: 0.14541764557361603
step: 270, loss: 0.001866908511146903
step: 280, loss: 0.000806074938736856
step: 290, loss: 0.002116740681231022
step: 300, loss: 0.0007001758785918355
step: 310, loss: 0.027034824714064598
step: 320, loss: 0.24107487499713898
step: 330, loss: 0.0004713606904260814
step: 340, loss: 0.008843526244163513
step: 350, loss: 0.014851474203169346
step: 360, loss: 0.0015307886060327291
step: 370, loss: 0.002968447282910347
step: 380, loss: 0.004609634168446064
epoch 11: dev_f1=0.7382198952879582, f1=0.5653333333333334, best_f1=0.5434782608695653
step: 0, loss: 0.029426423832774162
step: 10, loss: 0.04390822723507881
step: 20, loss: 0.0015466999029740691
step: 30, loss: 0.00514465244486928
step: 40, loss: 0.03509168326854706
step: 50, loss: 0.0007069676648825407
step: 60, loss: 0.020474223420023918
step: 70, loss: 0.0038409146945923567
step: 80, loss: 0.05954772233963013
step: 90, loss: 0.0017355805030092597
step: 100, loss: 0.0032941384706646204
step: 110, loss: 0.0024020960554480553
step: 120, loss: 0.0006080393213778734
step: 130, loss: 0.0033562015742063522
step: 140, loss: 0.022284934297204018
step: 150, loss: 0.003418835811316967
step: 160, loss: 0.0002811529266182333
step: 170, loss: 0.0020987503230571747
step: 180, loss: 0.00013196856889408082
step: 190, loss: 0.0017082716803997755
step: 200, loss: 0.0003439006977714598
step: 210, loss: 0.021914392709732056
step: 220, loss: 0.00017341594502795488
step: 230, loss: 0.0004569549928419292
step: 240, loss: 0.000941479520406574
step: 250, loss: 0.0005474306526593864
step: 260, loss: 0.000696761067956686
step: 270, loss: 0.0018988384399563074
step: 280, loss: 0.024414466693997383
step: 290, loss: 0.0005716560990549624
step: 300, loss: 0.00020037732610944659
step: 310, loss: 0.0007634652429260314
step: 320, loss: 0.0005193527322262526
step: 330, loss: 0.00019573500321712345
step: 340, loss: 0.0006659132777713239
step: 350, loss: 0.015163097530603409
step: 360, loss: 0.10574862360954285
step: 370, loss: 0.00423190975561738
step: 380, loss: 0.19328638911247253
epoch 12: dev_f1=0.7117794486215538, f1=0.6020942408376964, best_f1=0.5434782608695653
step: 0, loss: 0.0036646982189267874
step: 10, loss: 0.0664098933339119
step: 20, loss: 0.1030794084072113
step: 30, loss: 0.0005382564850151539
step: 40, loss: 0.0004115777846891433
step: 50, loss: 0.00013928048429079354
step: 60, loss: 0.0058151111006736755
step: 70, loss: 0.0013170449528843164
step: 80, loss: 0.023105217143893242
step: 90, loss: 0.0006837886176072061
step: 100, loss: 0.0015342265833169222
step: 110, loss: 0.0014923032140359282
step: 120, loss: 0.002302206587046385
step: 130, loss: 0.009887165389955044
step: 140, loss: 0.0011387203121557832
step: 150, loss: 0.00046767122694291174
step: 160, loss: 0.014367198571562767
step: 170, loss: 0.00011158543929923326
step: 180, loss: 0.00023443593818228692
step: 190, loss: 0.0016026414232328534
step: 200, loss: 0.000979274045675993
step: 210, loss: 0.01028104405850172
step: 220, loss: 0.0655740424990654
step: 230, loss: 0.00014615272812079638
step: 240, loss: 8.533299842383713e-05
step: 250, loss: 0.0001259530254174024
step: 260, loss: 0.08324670046567917
step: 270, loss: 0.0037725288420915604
step: 280, loss: 0.0004010013653896749
step: 290, loss: 0.0001390367979183793
step: 300, loss: 0.0003014022659044713
step: 310, loss: 0.0040146284736692905
step: 320, loss: 0.0002408754953648895
step: 330, loss: 0.00015666527906432748
step: 340, loss: 0.0010642379056662321
step: 350, loss: 0.0004941828083246946
step: 360, loss: 0.2786993086338043
step: 370, loss: 0.0005266343941912055
step: 380, loss: 0.00047214922960847616
epoch 13: dev_f1=0.745679012345679, f1=0.5974025974025974, best_f1=0.5434782608695653
step: 0, loss: 0.001387567725032568
step: 10, loss: 0.012727100402116776
step: 20, loss: 0.002703836653381586
step: 30, loss: 0.0005998177221044898
step: 40, loss: 0.0006083030020818114
step: 50, loss: 0.00013211692566983402
step: 60, loss: 0.0006647258414886892
step: 70, loss: 0.005752713419497013
step: 80, loss: 0.001755701843649149
step: 90, loss: 0.00016193794726859778
step: 100, loss: 0.00048296505701728165
step: 110, loss: 0.00034042951301671565
step: 120, loss: 0.0001414396974723786
step: 130, loss: 0.0005114901578053832
step: 140, loss: 0.0006536917644552886
step: 150, loss: 0.001421952503733337
step: 160, loss: 0.006609728559851646
step: 170, loss: 0.0007243104046210647
step: 180, loss: 0.012995263561606407
step: 190, loss: 0.0007752513629384339
step: 200, loss: 0.09317423403263092
step: 210, loss: 0.0005975390085950494
step: 220, loss: 0.0017276548314839602
step: 230, loss: 0.001005039899609983
step: 240, loss: 0.0016865141224116087
step: 250, loss: 0.00028658739756792784
step: 260, loss: 0.030614828690886497
step: 270, loss: 0.0001769127557054162
step: 280, loss: 0.003641152288764715
step: 290, loss: 0.00047415070002898574
step: 300, loss: 0.0003606696263886988
step: 310, loss: 0.0011784015223383904
step: 320, loss: 0.011598840355873108
step: 330, loss: 0.00013367911742534488
step: 340, loss: 0.0010142215760424733
step: 350, loss: 0.0014464110136032104
step: 360, loss: 0.0003261557430960238
step: 370, loss: 0.002832480240613222
step: 380, loss: 0.001044685603119433
epoch 14: dev_f1=0.7371273712737126, f1=0.5697674418604651, best_f1=0.5434782608695653
step: 0, loss: 0.0002840020752046257
step: 10, loss: 0.0005761199863627553
step: 20, loss: 0.00022359784634318203
step: 30, loss: 0.00038145770668052137
step: 40, loss: 0.0007237739046104252
step: 50, loss: 0.002110568340867758
step: 60, loss: 0.0001106004201574251
step: 70, loss: 0.0009238732745870948
step: 80, loss: 0.002517292508855462
step: 90, loss: 0.00012076344137312844
step: 100, loss: 0.00016663341375533491
step: 110, loss: 0.001623487682081759
step: 120, loss: 0.00010809462401084602
step: 130, loss: 0.0007201633416116238
step: 140, loss: 0.0002858717052731663
step: 150, loss: 0.002354702912271023
step: 160, loss: 0.0021498866844922304
step: 170, loss: 0.0013197300722822547
step: 180, loss: 0.0009671481093391776
step: 190, loss: 0.0004919185303151608
step: 200, loss: 0.00044240918941795826
step: 210, loss: 0.0112438490614295
step: 220, loss: 8.996345422929153e-05
step: 230, loss: 0.00011975983943557367
step: 240, loss: 0.0005732525023631752
step: 250, loss: 0.0029096051584929228
step: 260, loss: 0.001969433156773448
step: 270, loss: 0.00020297062292229384
step: 280, loss: 0.0005068689351901412
step: 290, loss: 0.0034467026125639677
step: 300, loss: 0.0011728043900802732
step: 310, loss: 0.00016811715613584965
step: 320, loss: 0.00024507121997885406
step: 330, loss: 0.00017444683180656284
step: 340, loss: 0.0001923058443935588
step: 350, loss: 0.00010448587272549048
step: 360, loss: 0.00014883237599860877
step: 370, loss: 0.00026996000087819993
step: 380, loss: 0.014639521948993206
epoch 15: dev_f1=0.7210526315789473, f1=0.6, best_f1=0.5434782608695653
step: 0, loss: 0.0001086005286197178
step: 10, loss: 0.00602735998108983
step: 20, loss: 0.00014627639029640704
step: 30, loss: 8.00636553321965e-05
step: 40, loss: 8.838767826091498e-05
step: 50, loss: 0.0009212453733198345
step: 60, loss: 7.67844176152721e-05
step: 70, loss: 0.00029775258735753596
step: 80, loss: 0.0001550251035951078
step: 90, loss: 0.0028752987273037434
step: 100, loss: 0.00045947861508466303
step: 110, loss: 0.00041266638436354697
step: 120, loss: 0.0002811664598993957
step: 130, loss: 0.002126116771250963
step: 140, loss: 0.0006126287044025958
step: 150, loss: 0.000810804485809058
step: 160, loss: 0.0005531704518944025
step: 170, loss: 0.0002968772023450583
step: 180, loss: 8.006331336218864e-05
step: 190, loss: 0.0012366436421871185
step: 200, loss: 0.00019888777751475573
step: 210, loss: 0.001592093612998724
step: 220, loss: 8.095234807115048e-05
step: 230, loss: 4.883575820713304e-05
step: 240, loss: 5.762176442658529e-05
step: 250, loss: 0.00019188213627785444
step: 260, loss: 0.0002659930323716253
step: 270, loss: 0.00024572474649176
step: 280, loss: 0.0004913557204417884
step: 290, loss: 0.00012838709517382085
step: 300, loss: 0.00033550700754858553
step: 310, loss: 8.651323878439143e-05
step: 320, loss: 0.0005179748986847699
step: 330, loss: 0.00030490796780213714
step: 340, loss: 0.0012776758521795273
step: 350, loss: 0.00010754067625384778
step: 360, loss: 0.005265610292553902
step: 370, loss: 6.136347656138241e-05
step: 380, loss: 0.000595995516050607
epoch 16: dev_f1=0.7381546134663343, f1=0.6230366492146596, best_f1=0.5434782608695653
step: 0, loss: 0.0002488511090632528
step: 10, loss: 0.002005920046940446
step: 20, loss: 0.026723233982920647
step: 30, loss: 0.00013344611215870827
step: 40, loss: 0.00222029653377831
step: 50, loss: 0.0010347164934501052
step: 60, loss: 0.0005229804082773626
step: 70, loss: 0.00013306115579325706
step: 80, loss: 0.0003590428677853197
step: 90, loss: 0.0005731619312427938
step: 100, loss: 0.0006589402910321951
step: 110, loss: 0.0004346978385001421
step: 120, loss: 0.0002005710412049666
step: 130, loss: 0.0002132514346158132
step: 140, loss: 0.00010849061072804034
step: 150, loss: 0.0001605147117516026
step: 160, loss: 0.005511367227882147
step: 170, loss: 0.00032660344731993973
step: 180, loss: 7.716523396084085e-05
step: 190, loss: 0.00019014264398720115
step: 200, loss: 0.00016231457993853837
step: 210, loss: 4.940823055221699e-05
step: 220, loss: 0.00023553057690151036
step: 230, loss: 0.008669614791870117
step: 240, loss: 3.487836875137873e-05
step: 250, loss: 0.001176984515041113
step: 260, loss: 8.552967483410612e-05
step: 270, loss: 9.780773689271882e-05
step: 280, loss: 0.0005728657124564052
step: 290, loss: 0.00011284073843853548
step: 300, loss: 0.00010282012226525694
step: 310, loss: 0.0008565136813558638
step: 320, loss: 0.00019335551769472659
step: 330, loss: 0.0010442731436342
step: 340, loss: 0.0001721978042041883
step: 350, loss: 0.003072059713304043
step: 360, loss: 0.00837472453713417
step: 370, loss: 0.0012002578005194664
step: 380, loss: 0.0010292730294167995
epoch 17: dev_f1=0.7598944591029023, f1=0.6170798898071626, best_f1=0.5434782608695653
step: 0, loss: 0.00017132458742707968
step: 10, loss: 0.00022100110072642565
step: 20, loss: 0.0006863242015242577
step: 30, loss: 0.0007214669603854418
step: 40, loss: 0.00036966014886274934
step: 50, loss: 0.0004521200607996434
step: 60, loss: 5.998293636366725e-05
step: 70, loss: 0.0007198595558293164
step: 80, loss: 0.0003809030167758465
step: 90, loss: 0.0003643019590526819
step: 100, loss: 0.026015685871243477
step: 110, loss: 7.159506640164182e-05
step: 120, loss: 0.006518134381622076
step: 130, loss: 6.516453140648082e-05
step: 140, loss: 0.001476094825193286
step: 150, loss: 0.00018195346638094634
step: 160, loss: 2.6974121283274144e-05
step: 170, loss: 0.00012749648885801435
step: 180, loss: 0.0002833777980413288
step: 190, loss: 0.0004311888769734651
step: 200, loss: 0.00010194179048994556
step: 210, loss: 0.014705393463373184
step: 220, loss: 0.0006407913751900196
step: 230, loss: 0.0001170677351183258
step: 240, loss: 0.0008755881572142243
step: 250, loss: 0.00016103936650324613
step: 260, loss: 0.11584994941949844
step: 270, loss: 0.0007617514347657561
step: 280, loss: 0.0021028397604823112
step: 290, loss: 0.0015512768877670169
step: 300, loss: 7.18834635335952e-05
step: 310, loss: 0.0008925995207391679
step: 320, loss: 0.0006222605588845909
step: 330, loss: 7.918837945908308e-05
step: 340, loss: 6.598728941753507e-05
step: 350, loss: 6.858249253127724e-05
step: 360, loss: 0.00010316231055185199
step: 370, loss: 0.00011929677566513419
step: 380, loss: 0.00014678650768473744
epoch 18: dev_f1=0.7570332480818414, f1=0.610079575596817, best_f1=0.5434782608695653
step: 0, loss: 3.2859785278560594e-05
step: 10, loss: 0.0019700280390679836
step: 20, loss: 7.229709444800392e-05
step: 30, loss: 0.00028453601407818496
step: 40, loss: 0.0008594334358349442
step: 50, loss: 0.0005573286907747388
step: 60, loss: 5.1597304263850674e-05
step: 70, loss: 0.00013574815238825977
step: 80, loss: 5.347109618014656e-05
step: 90, loss: 0.00016969142598100007
step: 100, loss: 0.00019954366143792868
step: 110, loss: 7.060480857035145e-05
step: 120, loss: 0.00014297477900981903
step: 130, loss: 0.0004828631936106831
step: 140, loss: 0.0003559308825060725
step: 150, loss: 0.006709295324981213
step: 160, loss: 0.005055324174463749
step: 170, loss: 0.0004149675660301
step: 180, loss: 0.00027533111278899014
step: 190, loss: 0.00017510814359411597
step: 200, loss: 0.00027186263469047844
step: 210, loss: 0.000395164213841781
step: 220, loss: 0.0005967135657556355
step: 230, loss: 0.0004978931974619627
step: 240, loss: 0.0017197170527651906
step: 250, loss: 0.00011372670269338414
step: 260, loss: 3.45695843861904e-05
step: 270, loss: 0.00026402194635011256
step: 280, loss: 0.00144300889223814
step: 290, loss: 0.00018596758309286088
step: 300, loss: 8.041737601161003e-05
step: 310, loss: 0.001972684869542718
step: 320, loss: 0.00020269847300369292
step: 330, loss: 0.0003306712897028774
step: 340, loss: 0.004655453376471996
step: 350, loss: 0.002605680376291275
step: 360, loss: 5.158860221854411e-05
step: 370, loss: 0.02543189376592636
step: 380, loss: 0.0002908666792791337
epoch 19: dev_f1=0.741687979539642, f1=0.608695652173913, best_f1=0.5434782608695653
step: 0, loss: 9.400355338584632e-05
step: 10, loss: 9.692722233012319e-05
step: 20, loss: 0.00028335017850622535
step: 30, loss: 0.00011093604553025216
step: 40, loss: 8.197646820917726e-05
step: 50, loss: 0.00018755116616375744
step: 60, loss: 0.00016360715380869806
step: 70, loss: 0.00017737835878506303
step: 80, loss: 0.00031867128564044833
step: 90, loss: 0.0008001159294508398
step: 100, loss: 0.00013772181409876794
step: 110, loss: 0.0039447699673473835
step: 120, loss: 0.0002555383834987879
step: 130, loss: 0.00011998372065136209
step: 140, loss: 5.982540096738376e-05
step: 150, loss: 6.893512181704864e-05
step: 160, loss: 0.0001959954242920503
step: 170, loss: 0.0002141601435141638
step: 180, loss: 9.023729944601655e-05
step: 190, loss: 6.397519609890878e-05
step: 200, loss: 0.00016223367128986865
step: 210, loss: 0.00023192031949292868
step: 220, loss: 0.002952060429379344
step: 230, loss: 0.000311525072902441
step: 240, loss: 0.0011004889383912086
step: 250, loss: 7.004816143307835e-05
step: 260, loss: 4.5248703827383e-05
step: 270, loss: 6.633915472775698e-05
step: 280, loss: 0.00012972389231435955
step: 290, loss: 0.00017234859114978462
step: 300, loss: 0.00031091063283383846
step: 310, loss: 0.00020501580729614943
step: 320, loss: 0.000557495397515595
step: 330, loss: 6.787756865378469e-05
step: 340, loss: 3.659570938907564e-05
step: 350, loss: 0.00011119217379018664
step: 360, loss: 0.0007863232749514282
step: 370, loss: 2.5528786864015274e-05
step: 380, loss: 0.0017586656613275409
epoch 20: dev_f1=0.7411167512690356, f1=0.6124661246612466, best_f1=0.5434782608695653
