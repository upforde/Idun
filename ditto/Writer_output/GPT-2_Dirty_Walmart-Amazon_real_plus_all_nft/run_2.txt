cuda
Device: cuda
step: 0, loss: 0.7348559498786926
step: 10, loss: 0.1671135425567627
step: 20, loss: 0.3768101930618286
step: 30, loss: 0.2949260473251343
step: 40, loss: 0.299496591091156
step: 50, loss: 0.31705242395401
step: 60, loss: 0.30945447087287903
step: 70, loss: 0.4281565248966217
step: 80, loss: 0.3700028955936432
step: 90, loss: 0.24457351863384247
step: 100, loss: 0.44677114486694336
step: 110, loss: 0.14233970642089844
step: 120, loss: 0.23156529664993286
step: 130, loss: 0.2588771879673004
step: 140, loss: 0.24947749078273773
step: 150, loss: 0.22671465575695038
step: 160, loss: 0.4003961980342865
step: 170, loss: 0.44084158539772034
step: 180, loss: 0.22811727225780487
step: 190, loss: 0.25963032245635986
step: 200, loss: 0.2447173297405243
step: 210, loss: 0.24765215814113617
step: 220, loss: 0.19748085737228394
step: 230, loss: 0.3837055563926697
step: 240, loss: 0.294905424118042
step: 250, loss: 0.13708320260047913
step: 260, loss: 0.29128319025039673
step: 270, loss: 0.1296369880437851
step: 280, loss: 0.32921120524406433
step: 290, loss: 0.23260453343391418
step: 300, loss: 0.10126902908086777
step: 310, loss: 0.4307956397533417
step: 320, loss: 0.4551849663257599
step: 330, loss: 0.11998416483402252
step: 340, loss: 0.20415325462818146
step: 350, loss: 0.36380907893180847
step: 360, loss: 0.17590123414993286
step: 370, loss: 0.30159300565719604
step: 380, loss: 0.38568389415740967
epoch 1: dev_f1=0.6420454545454545, f1=0.478386167146974, best_f1=0.478386167146974
step: 0, loss: 0.35885459184646606
step: 10, loss: 0.1675303876399994
step: 20, loss: 0.16380575299263
step: 30, loss: 0.3696500062942505
step: 40, loss: 0.13937491178512573
step: 50, loss: 0.23589615523815155
step: 60, loss: 0.2657422125339508
step: 70, loss: 0.11439643055200577
step: 80, loss: 0.1731317937374115
step: 90, loss: 0.15404902398586273
step: 100, loss: 0.3263949751853943
step: 110, loss: 0.10866071283817291
step: 120, loss: 0.19791199266910553
step: 130, loss: 0.4139699339866638
step: 140, loss: 0.34095653891563416
step: 150, loss: 0.31716376543045044
step: 160, loss: 0.2930056154727936
step: 170, loss: 0.11496339738368988
step: 180, loss: 0.15464740991592407
step: 190, loss: 0.23795431852340698
step: 200, loss: 0.36828505992889404
step: 210, loss: 0.16071131825447083
step: 220, loss: 0.19360297918319702
step: 230, loss: 0.2094990462064743
step: 240, loss: 0.14479249715805054
step: 250, loss: 0.16717319190502167
step: 260, loss: 0.19378778338432312
step: 270, loss: 0.05601523444056511
step: 280, loss: 0.1673683077096939
step: 290, loss: 0.16175708174705505
step: 300, loss: 0.2596498727798462
step: 310, loss: 0.6090060472488403
step: 320, loss: 0.13500052690505981
step: 330, loss: 0.2227672040462494
step: 340, loss: 0.1623271107673645
step: 350, loss: 0.42401763796806335
step: 360, loss: 0.0882006287574768
step: 370, loss: 0.2979854345321655
step: 380, loss: 0.03419860824942589
epoch 2: dev_f1=0.7604166666666666, f1=0.5824175824175823, best_f1=0.5824175824175823
step: 0, loss: 0.14869681000709534
step: 10, loss: 0.27909034490585327
step: 20, loss: 0.11009145528078079
step: 30, loss: 0.2906258702278137
step: 40, loss: 0.253530353307724
step: 50, loss: 0.14045046269893646
step: 60, loss: 0.06356756389141083
step: 70, loss: 0.04262935370206833
step: 80, loss: 0.25409868359565735
step: 90, loss: 0.14810895919799805
step: 100, loss: 0.10159508138895035
step: 110, loss: 0.08739105612039566
step: 120, loss: 0.25342461466789246
step: 130, loss: 0.15324068069458008
step: 140, loss: 0.20117947459220886
step: 150, loss: 0.0506012924015522
step: 160, loss: 0.11574017256498337
step: 170, loss: 0.17129558324813843
step: 180, loss: 0.059170667082071304
step: 190, loss: 0.1308753341436386
step: 200, loss: 0.11582261323928833
step: 210, loss: 0.11565103381872177
step: 220, loss: 0.07876913249492645
step: 230, loss: 0.14011690020561218
step: 240, loss: 0.05090528354048729
step: 250, loss: 0.03357475623488426
step: 260, loss: 0.072524294257164
step: 270, loss: 0.10750395804643631
step: 280, loss: 0.041032493114471436
step: 290, loss: 0.17156651616096497
step: 300, loss: 0.07053407281637192
step: 310, loss: 0.20289954543113708
step: 320, loss: 0.2072700709104538
step: 330, loss: 0.18107818067073822
step: 340, loss: 0.11658140271902084
step: 350, loss: 0.14562168717384338
step: 360, loss: 0.12234484404325485
step: 370, loss: 0.20227721333503723
step: 380, loss: 0.2490963339805603
epoch 3: dev_f1=0.7874015748031497, f1=0.5791044776119403, best_f1=0.5791044776119403
step: 0, loss: 0.3057638704776764
step: 10, loss: 0.04298439994454384
step: 20, loss: 0.13711991906166077
step: 30, loss: 0.14381422102451324
step: 40, loss: 0.09790753573179245
step: 50, loss: 0.0038773342967033386
step: 60, loss: 0.013146104291081429
step: 70, loss: 0.5226560831069946
step: 80, loss: 0.08327186852693558
step: 90, loss: 0.03792831301689148
step: 100, loss: 0.30264633893966675
step: 110, loss: 0.051291823387145996
step: 120, loss: 0.1823231279850006
step: 130, loss: 0.01991802081465721
step: 140, loss: 0.0388975627720356
step: 150, loss: 0.1278098225593567
step: 160, loss: 0.10520568490028381
step: 170, loss: 0.12352131307125092
step: 180, loss: 0.06498350948095322
step: 190, loss: 0.15178325772285461
step: 200, loss: 0.11800762265920639
step: 210, loss: 0.027942372485995293
step: 220, loss: 0.027484798803925514
step: 230, loss: 0.0625232383608818
step: 240, loss: 0.3071657121181488
step: 250, loss: 0.14802680909633636
step: 260, loss: 0.05860041454434395
step: 270, loss: 0.015681637451052666
step: 280, loss: 0.14855988323688507
step: 290, loss: 0.08672820776700974
step: 300, loss: 0.024242276325821877
step: 310, loss: 0.2552397847175598
step: 320, loss: 0.05934435874223709
step: 330, loss: 0.08879003673791885
step: 340, loss: 0.2543000876903534
step: 350, loss: 0.09566372632980347
step: 360, loss: 0.05234161764383316
step: 370, loss: 0.02436111867427826
step: 380, loss: 0.15175701677799225
epoch 4: dev_f1=0.8009950248756219, f1=0.6410256410256411, best_f1=0.6410256410256411
step: 0, loss: 0.011263407766819
step: 10, loss: 0.0994620993733406
step: 20, loss: 0.03537062183022499
step: 30, loss: 0.11470881849527359
step: 40, loss: 0.12243683636188507
step: 50, loss: 0.10310161858797073
step: 60, loss: 0.27909615635871887
step: 70, loss: 0.061892926692962646
step: 80, loss: 0.008388793095946312
step: 90, loss: 0.05422676354646683
step: 100, loss: 0.056954365223646164
step: 110, loss: 0.09129838645458221
step: 120, loss: 0.01807866431772709
step: 130, loss: 0.05137914791703224
step: 140, loss: 0.10790490359067917
step: 150, loss: 0.0573204904794693
step: 160, loss: 0.3467456102371216
step: 170, loss: 0.16164575517177582
step: 180, loss: 0.09298142790794373
step: 190, loss: 0.11293664574623108
step: 200, loss: 0.06891744583845139
step: 210, loss: 0.028181402012705803
step: 220, loss: 0.046882618218660355
step: 230, loss: 0.017010655254125595
step: 240, loss: 0.1246517151594162
step: 250, loss: 0.021443068981170654
step: 260, loss: 0.033895138651132584
step: 270, loss: 0.12112347781658173
step: 280, loss: 0.044029202312231064
step: 290, loss: 0.009501107968389988
step: 300, loss: 0.04862559214234352
step: 310, loss: 0.0818210244178772
step: 320, loss: 0.07225601375102997
step: 330, loss: 0.0705973207950592
step: 340, loss: 0.09854352474212646
step: 350, loss: 0.05881216377019882
step: 360, loss: 0.03659779205918312
step: 370, loss: 0.10936908423900604
step: 380, loss: 0.014823682606220245
epoch 5: dev_f1=0.8116710875331565, f1=0.6477272727272727, best_f1=0.6477272727272727
step: 0, loss: 0.07598868012428284
step: 10, loss: 0.10415107756853104
step: 20, loss: 0.020812377333641052
step: 30, loss: 0.0030407989397644997
step: 40, loss: 0.15089601278305054
step: 50, loss: 0.0015645651146769524
step: 60, loss: 0.11494506150484085
step: 70, loss: 0.021113229915499687
step: 80, loss: 0.018804820254445076
step: 90, loss: 0.06989751011133194
step: 100, loss: 0.1663047969341278
step: 110, loss: 0.00782543420791626
step: 120, loss: 0.04307127371430397
step: 130, loss: 0.001129835145547986
step: 140, loss: 0.1446985900402069
step: 150, loss: 0.12261399626731873
step: 160, loss: 0.008959101513028145
step: 170, loss: 0.13979439437389374
step: 180, loss: 0.00930848065763712
step: 190, loss: 0.0029575913213193417
step: 200, loss: 0.04331345111131668
step: 210, loss: 0.01651374064385891
step: 220, loss: 0.0236160047352314
step: 230, loss: 0.034847717732191086
step: 240, loss: 0.12948110699653625
step: 250, loss: 0.034219179302453995
step: 260, loss: 0.04813551902770996
step: 270, loss: 0.03131365031003952
step: 280, loss: 0.0019658280070871115
step: 290, loss: 0.002665470354259014
step: 300, loss: 0.018038969486951828
step: 310, loss: 0.013286862522363663
step: 320, loss: 0.004502508789300919
step: 330, loss: 0.2703361213207245
step: 340, loss: 0.020056884735822678
step: 350, loss: 0.09423410147428513
step: 360, loss: 0.02627093531191349
step: 370, loss: 0.019523093476891518
step: 380, loss: 0.11806045472621918
epoch 6: dev_f1=0.8099173553719008, f1=0.5868263473053893, best_f1=0.6477272727272727
step: 0, loss: 0.00933796912431717
step: 10, loss: 0.04612154886126518
step: 20, loss: 0.06456949561834335
step: 30, loss: 0.018042972311377525
step: 40, loss: 0.004721181001514196
step: 50, loss: 0.012710120528936386
step: 60, loss: 0.17351965606212616
step: 70, loss: 0.014446166343986988
step: 80, loss: 0.014139845035970211
step: 90, loss: 0.015907056629657745
step: 100, loss: 0.011394646018743515
step: 110, loss: 0.013261163607239723
step: 120, loss: 0.01197842787951231
step: 130, loss: 0.02506111189723015
step: 140, loss: 0.004076479468494654
step: 150, loss: 0.04535600543022156
step: 160, loss: 0.06644604355096817
step: 170, loss: 0.0005874828202649951
step: 180, loss: 0.0024092658422887325
step: 190, loss: 0.008101770654320717
step: 200, loss: 0.01018929947167635
step: 210, loss: 0.012240379117429256
step: 220, loss: 0.026215938851237297
step: 230, loss: 0.02867451310157776
step: 240, loss: 0.04700123518705368
step: 250, loss: 0.012020312249660492
step: 260, loss: 0.022688033059239388
step: 270, loss: 0.004786443430930376
step: 280, loss: 0.1065693274140358
step: 290, loss: 0.06684347242116928
step: 300, loss: 0.006843997165560722
step: 310, loss: 0.06851738691329956
step: 320, loss: 0.06128620728850365
step: 330, loss: 0.028949467465281487
step: 340, loss: 0.015609984286129475
step: 350, loss: 0.01987459696829319
step: 360, loss: 0.040036436170339584
step: 370, loss: 0.0021504343021661043
step: 380, loss: 0.039578430354595184
epoch 7: dev_f1=0.8191489361702128, f1=0.6352941176470588, best_f1=0.6352941176470588
step: 0, loss: 0.018421262502670288
step: 10, loss: 0.008227416314184666
step: 20, loss: 0.006572585087269545
step: 30, loss: 0.05207498371601105
step: 40, loss: 0.006513302214443684
step: 50, loss: 0.011180042289197445
step: 60, loss: 0.050552573055028915
step: 70, loss: 0.005165570881217718
step: 80, loss: 0.06546081602573395
step: 90, loss: 0.010996127501130104
step: 100, loss: 0.00296043511480093
step: 110, loss: 0.0022456482984125614
step: 120, loss: 0.0073217651806771755
step: 130, loss: 0.006177337374538183
step: 140, loss: 0.010421750135719776
step: 150, loss: 0.013911298476159573
step: 160, loss: 0.003148170653730631
step: 170, loss: 0.00016540000797249377
step: 180, loss: 0.0004108909342903644
step: 190, loss: 0.006677116267383099
step: 200, loss: 0.0023721368052065372
step: 210, loss: 0.05891167372465134
step: 220, loss: 0.00954928807914257
step: 230, loss: 0.02288264036178589
step: 240, loss: 0.018857456743717194
step: 250, loss: 0.0016261059790849686
step: 260, loss: 0.00985983107239008
step: 270, loss: 0.025006357580423355
step: 280, loss: 0.01400342583656311
step: 290, loss: 0.012237210758030415
step: 300, loss: 0.0043791658245027065
step: 310, loss: 0.0513775534927845
step: 320, loss: 0.002143906895071268
step: 330, loss: 0.0026108110323548317
step: 340, loss: 0.001143428380601108
step: 350, loss: 0.01596578024327755
step: 360, loss: 0.0035202689468860626
step: 370, loss: 0.013861543498933315
step: 380, loss: 0.10399910062551498
epoch 8: dev_f1=0.7949999999999999, f1=0.6648793565683646, best_f1=0.6352941176470588
step: 0, loss: 0.035943374037742615
step: 10, loss: 0.0008143337909132242
step: 20, loss: 0.11229290813207626
step: 30, loss: 0.03623130917549133
step: 40, loss: 0.0036770040169358253
step: 50, loss: 0.004466606769710779
step: 60, loss: 0.016560515388846397
step: 70, loss: 0.0028974220622330904
step: 80, loss: 0.0882311537861824
step: 90, loss: 0.053010012954473495
step: 100, loss: 0.0007854498107917607
step: 110, loss: 0.010047989897429943
step: 120, loss: 0.002345970831811428
step: 130, loss: 0.002553369849920273
step: 140, loss: 0.00018220017955172807
step: 150, loss: 0.001693743048235774
step: 160, loss: 0.004590007476508617
step: 170, loss: 0.0037163589149713516
step: 180, loss: 0.27077335119247437
step: 190, loss: 0.019397741183638573
step: 200, loss: 0.00038794783176854253
step: 210, loss: 0.007728930097073317
step: 220, loss: 0.001126076327636838
step: 230, loss: 0.00045916606904938817
step: 240, loss: 0.001497230608947575
step: 250, loss: 0.02062303200364113
step: 260, loss: 0.06517097353935242
step: 270, loss: 0.02834540233016014
step: 280, loss: 0.004614748526364565
step: 290, loss: 0.0006896120612509549
step: 300, loss: 0.008808820508420467
step: 310, loss: 0.005563788115978241
step: 320, loss: 0.0007384393247775733
step: 330, loss: 0.0030747633427381516
step: 340, loss: 0.0026753221172839403
step: 350, loss: 0.0026398354675620794
step: 360, loss: 0.009836938232183456
step: 370, loss: 0.026719337329268456
step: 380, loss: 0.04552539065480232
epoch 9: dev_f1=0.8253164556962026, f1=0.6563307493540051, best_f1=0.6563307493540051
step: 0, loss: 0.005156293045729399
step: 10, loss: 0.011098459362983704
step: 20, loss: 0.0016915244050323963
step: 30, loss: 0.020750246942043304
step: 40, loss: 0.007661775220185518
step: 50, loss: 0.00042374568874947727
step: 60, loss: 0.003296824172139168
step: 70, loss: 0.0012572506675496697
step: 80, loss: 0.0013392847031354904
step: 90, loss: 0.0014599866699427366
step: 100, loss: 0.0009950516978278756
step: 110, loss: 0.0021940513979643583
step: 120, loss: 0.0006974777206778526
step: 130, loss: 0.043641459196805954
step: 140, loss: 0.13397890329360962
step: 150, loss: 0.0010787543142214417
step: 160, loss: 0.0016233300557360053
step: 170, loss: 0.08186283707618713
step: 180, loss: 0.01868966780602932
step: 190, loss: 0.002005922608077526
step: 200, loss: 0.0028263633139431477
step: 210, loss: 0.002605690388008952
step: 220, loss: 0.003127211704850197
step: 230, loss: 0.0021517660934478045
step: 240, loss: 0.013575190678238869
step: 250, loss: 0.00020049110753461719
step: 260, loss: 0.014733252115547657
step: 270, loss: 0.0014046685537323356
step: 280, loss: 0.004008562304079533
step: 290, loss: 0.0026392689906060696
step: 300, loss: 0.034531574696302414
step: 310, loss: 0.0037035918794572353
step: 320, loss: 0.028377411887049675
step: 330, loss: 0.040987201035022736
step: 340, loss: 0.00039798245416022837
step: 350, loss: 0.003230200381949544
step: 360, loss: 0.0015022377483546734
step: 370, loss: 0.0030917529948055744
step: 380, loss: 0.007237338926643133
epoch 10: dev_f1=0.8075880758807588, f1=0.6548672566371682, best_f1=0.6563307493540051
step: 0, loss: 0.001293231500312686
step: 10, loss: 0.03255169093608856
step: 20, loss: 0.02914634719491005
step: 30, loss: 0.004373549483716488
step: 40, loss: 0.000539285596460104
step: 50, loss: 0.0011133900843560696
step: 60, loss: 0.0005706786178052425
step: 70, loss: 0.025955121964216232
step: 80, loss: 0.00014950074546504766
step: 90, loss: 0.0014573902590200305
step: 100, loss: 0.0008063066634349525
step: 110, loss: 0.00020916461653541774
step: 120, loss: 0.006636413279920816
step: 130, loss: 0.0003708148142322898
step: 140, loss: 0.003339697839692235
step: 150, loss: 0.003664030460640788
step: 160, loss: 0.0014340179041028023
step: 170, loss: 0.005946857389062643
step: 180, loss: 0.0019787161145359278
step: 190, loss: 0.05329713597893715
step: 200, loss: 0.0004224040312692523
step: 210, loss: 0.008085830137133598
step: 220, loss: 0.0017628140049055219
step: 230, loss: 0.0016957377083599567
step: 240, loss: 0.0007238616817630827
step: 250, loss: 0.0025012169498950243
step: 260, loss: 0.04459388926625252
step: 270, loss: 0.001985145965591073
step: 280, loss: 0.00021421450946945697
step: 290, loss: 0.001719730906188488
step: 300, loss: 0.022901486605405807
step: 310, loss: 0.0007970762671902776
step: 320, loss: 0.0008909512544050813
step: 330, loss: 0.0003145498631056398
step: 340, loss: 0.0003309970779810101
step: 350, loss: 0.011302128434181213
step: 360, loss: 0.002523742849007249
step: 370, loss: 0.0008400115184485912
step: 380, loss: 0.0005744986119680107
epoch 11: dev_f1=0.8186528497409327, f1=0.6811989100817438, best_f1=0.6563307493540051
step: 0, loss: 0.028377914801239967
step: 10, loss: 0.0019154209876433015
step: 20, loss: 0.006962542422115803
step: 30, loss: 0.0001440222840756178
step: 40, loss: 0.040617264807224274
step: 50, loss: 0.00021724666294176131
step: 60, loss: 0.0052486807107925415
step: 70, loss: 0.0006813235813751817
step: 80, loss: 0.00036642816849052906
step: 90, loss: 0.011885991320014
step: 100, loss: 0.01644843816757202
step: 110, loss: 0.10346199572086334
step: 120, loss: 0.01895117573440075
step: 130, loss: 0.0009153552819043398
step: 140, loss: 0.002217585686594248
step: 150, loss: 0.02003779448568821
step: 160, loss: 0.006491351872682571
step: 170, loss: 0.015272852033376694
step: 180, loss: 0.0006005943287163973
step: 190, loss: 0.0055494061671197414
step: 200, loss: 0.0008296589367091656
step: 210, loss: 0.0069095660001039505
step: 220, loss: 0.002125438302755356
step: 230, loss: 0.0013028387911617756
step: 240, loss: 0.0017238979926332831
step: 250, loss: 0.0025786561891436577
step: 260, loss: 0.0006680356455035508
step: 270, loss: 0.00025797143462114036
step: 280, loss: 0.001295889844186604
step: 290, loss: 0.09141391515731812
step: 300, loss: 0.020714756101369858
step: 310, loss: 0.0019339476712048054
step: 320, loss: 0.00196329178288579
step: 330, loss: 0.00017154050874523818
step: 340, loss: 0.00020324200158938766
step: 350, loss: 0.00017503288108855486
step: 360, loss: 0.028934458270668983
step: 370, loss: 0.004179739393293858
step: 380, loss: 0.0006521596806123853
epoch 12: dev_f1=0.8148148148148148, f1=0.6477272727272727, best_f1=0.6563307493540051
step: 0, loss: 0.0013236174127086997
step: 10, loss: 0.00017176303663291037
step: 20, loss: 0.00155124522279948
step: 30, loss: 0.0006064584013074636
step: 40, loss: 0.0042904033325612545
step: 50, loss: 0.00045149485231377184
step: 60, loss: 0.002985988277941942
step: 70, loss: 0.0005215253331698477
step: 80, loss: 0.00889771431684494
step: 90, loss: 0.0007434897124767303
step: 100, loss: 0.0008944903966039419
step: 110, loss: 0.16758231818675995
step: 120, loss: 0.00031242927070707083
step: 130, loss: 0.008132154121994972
step: 140, loss: 0.0005609779036603868
step: 150, loss: 0.0002044414432020858
step: 160, loss: 0.0001824572536861524
step: 170, loss: 0.001665865071117878
step: 180, loss: 0.0008144984603859484
step: 190, loss: 0.000104075028502848
step: 200, loss: 8.502164564561099e-05
step: 210, loss: 0.001083456096239388
step: 220, loss: 0.00030572721152566373
step: 230, loss: 0.0004564530390780419
step: 240, loss: 0.000184271702892147
step: 250, loss: 6.414115341613069e-05
step: 260, loss: 4.139333395869471e-05
step: 270, loss: 0.00012323420378379524
step: 280, loss: 0.04432913661003113
step: 290, loss: 0.0023986492305994034
step: 300, loss: 0.006557758431881666
step: 310, loss: 0.0015926285414025187
step: 320, loss: 0.0012420760467648506
step: 330, loss: 0.0269846823066473
step: 340, loss: 0.0008186441264115274
step: 350, loss: 0.0041483016684651375
step: 360, loss: 0.005338920280337334
step: 370, loss: 0.0001897126785479486
step: 380, loss: 0.0437171645462513
epoch 13: dev_f1=0.7908163265306122, f1=0.6495726495726496, best_f1=0.6563307493540051
step: 0, loss: 0.0012515742564573884
step: 10, loss: 0.01190854236483574
step: 20, loss: 0.0006325496942736208
step: 30, loss: 0.0006431831861846149
step: 40, loss: 0.0002912087948061526
step: 50, loss: 0.0005524337757378817
step: 60, loss: 0.006139883305877447
step: 70, loss: 0.00012175909068901092
step: 80, loss: 0.00038136501098051667
step: 90, loss: 0.014887159690260887
step: 100, loss: 0.00048604284529574215
step: 110, loss: 0.001155838486738503
step: 120, loss: 0.0003540708858054131
step: 130, loss: 0.0018667832482606173
step: 140, loss: 0.0020078173838555813
step: 150, loss: 0.0023156339302659035
step: 160, loss: 0.0004897842300124466
step: 170, loss: 0.0035642858128994703
step: 180, loss: 0.0008371039875783026
step: 190, loss: 0.008765744045376778
step: 200, loss: 0.003391468431800604
step: 210, loss: 0.00010023445793194696
step: 220, loss: 0.0005179252475500107
step: 230, loss: 0.0012392873177304864
step: 240, loss: 0.00036657077725976706
step: 250, loss: 0.0004899906343780458
step: 260, loss: 0.00019053778669331223
step: 270, loss: 6.925190973561257e-05
step: 280, loss: 0.00022852481924928725
step: 290, loss: 0.001576918875798583
step: 300, loss: 0.0031740230042487383
step: 310, loss: 0.006298320833593607
step: 320, loss: 0.00014331658894661814
step: 330, loss: 0.00019051044364459813
step: 340, loss: 0.0001291090447921306
step: 350, loss: 9.28302324609831e-05
step: 360, loss: 0.007735459133982658
step: 370, loss: 0.00010507774277357385
step: 380, loss: 0.012837078422307968
epoch 14: dev_f1=0.8105263157894735, f1=0.6552706552706553, best_f1=0.6563307493540051
step: 0, loss: 0.00018913968233391643
step: 10, loss: 0.0004707940388470888
step: 20, loss: 0.0020690783858299255
step: 30, loss: 0.000900478451512754
step: 40, loss: 7.049168925732374e-05
step: 50, loss: 0.00013024652434978634
step: 60, loss: 0.00010816435678862035
step: 70, loss: 0.0005363108357414603
step: 80, loss: 0.0006065946072340012
step: 90, loss: 0.00019057687313761562
step: 100, loss: 0.0004364347842056304
step: 110, loss: 0.001399516360834241
step: 120, loss: 0.00010044487862614915
step: 130, loss: 0.00018904056923929602
step: 140, loss: 0.00012828756007365882
step: 150, loss: 0.0009056144044734538
step: 160, loss: 0.0005219528102315962
step: 170, loss: 0.0002327021211385727
step: 180, loss: 0.00019076030002906919
step: 190, loss: 0.0013935333117842674
step: 200, loss: 0.00014477124204859138
step: 210, loss: 0.005184795241802931
step: 220, loss: 0.0005424918490462005
step: 230, loss: 0.0024102535098791122
step: 240, loss: 0.00019187973521184176
step: 250, loss: 0.0010853736894205213
step: 260, loss: 0.06196412444114685
step: 270, loss: 0.00013818110164720565
step: 280, loss: 7.467770774383098e-05
step: 290, loss: 0.00045351608423516154
step: 300, loss: 0.0010718449484556913
step: 310, loss: 0.0010954305762425065
step: 320, loss: 6.492366082966328e-05
step: 330, loss: 0.026064250618219376
step: 340, loss: 0.0055717541836202145
step: 350, loss: 8.919199899537489e-05
step: 360, loss: 8.118300320347771e-05
step: 370, loss: 0.00014651005039922893
step: 380, loss: 0.00020317101734690368
epoch 15: dev_f1=0.7947368421052631, f1=0.6570605187319885, best_f1=0.6563307493540051
step: 0, loss: 0.0002689939574338496
step: 10, loss: 0.0001531896268716082
step: 20, loss: 9.024089376907796e-05
step: 30, loss: 0.01027124747633934
step: 40, loss: 0.0005621133022941649
step: 50, loss: 0.004311989527195692
step: 60, loss: 0.00014488607121165842
step: 70, loss: 0.001519129378721118
step: 80, loss: 0.00013142013631295413
step: 90, loss: 0.0001319577422691509
step: 100, loss: 0.0002891099429689348
step: 110, loss: 0.07537712901830673
step: 120, loss: 0.0008896809304133058
step: 130, loss: 0.0018655953463166952
step: 140, loss: 0.0002777384070213884
step: 150, loss: 0.028107114136219025
step: 160, loss: 0.0008655119454488158
step: 170, loss: 0.00020459803636185825
step: 180, loss: 0.0003473373071756214
step: 190, loss: 0.0002269646938657388
step: 200, loss: 0.00019163289107382298
step: 210, loss: 0.007663874886929989
step: 220, loss: 0.0003037244896404445
step: 230, loss: 0.00016365121700800955
step: 240, loss: 0.00028166003176011145
step: 250, loss: 0.0063086748123168945
step: 260, loss: 0.00013834674609825015
step: 270, loss: 0.008011178113520145
step: 280, loss: 0.00026118478854186833
step: 290, loss: 0.0005849373992532492
step: 300, loss: 5.5018030252540484e-05
step: 310, loss: 0.005742713343352079
step: 320, loss: 0.0007246225140988827
step: 330, loss: 0.001791662652976811
step: 340, loss: 0.00022386726050172
step: 350, loss: 0.00025935209123417735
step: 360, loss: 0.08462782949209213
step: 370, loss: 0.001793573726899922
step: 380, loss: 0.00020387473341543227
epoch 16: dev_f1=0.8, f1=0.6776859504132231, best_f1=0.6563307493540051
step: 0, loss: 0.0005041451076976955
step: 10, loss: 0.00019713249639607966
step: 20, loss: 6.393543299054727e-05
step: 30, loss: 0.00018842612917069346
step: 40, loss: 0.0002461058902554214
step: 50, loss: 0.0001668417826294899
step: 60, loss: 0.0014503111597150564
step: 70, loss: 0.0008957739337347448
step: 80, loss: 0.005882058292627335
step: 90, loss: 0.001562116201967001
step: 100, loss: 0.00014925443974789232
step: 110, loss: 0.00382802146486938
step: 120, loss: 0.0005206703208386898
step: 130, loss: 0.00010717828263295814
step: 140, loss: 0.00021099112927913666
step: 150, loss: 0.0011380274081602693
step: 160, loss: 0.0009328174637630582
step: 170, loss: 0.0013625231804326177
step: 180, loss: 6.635326280957088e-05
step: 190, loss: 5.607238199445419e-05
step: 200, loss: 0.0001350957463728264
step: 210, loss: 7.226841989904642e-05
step: 220, loss: 0.0001056520632118918
step: 230, loss: 0.0007676175446249545
step: 240, loss: 0.0023289888631552458
step: 250, loss: 0.001166294445283711
step: 260, loss: 0.0001571219472680241
step: 270, loss: 8.258329762611538e-05
step: 280, loss: 0.00016825237253215164
step: 290, loss: 4.6435947297140956e-05
step: 300, loss: 4.7307887143688276e-05
step: 310, loss: 0.01717420108616352
step: 320, loss: 0.0001326053316006437
step: 330, loss: 0.00015391357010230422
step: 340, loss: 0.00010570594895398244
step: 350, loss: 8.704125502845272e-05
step: 360, loss: 0.0005429140874184668
step: 370, loss: 0.00017278574523516
step: 380, loss: 0.000276251434115693
epoch 17: dev_f1=0.8086253369272237, f1=0.6196319018404907, best_f1=0.6563307493540051
step: 0, loss: 0.0010460963239893317
step: 10, loss: 0.008548635058104992
step: 20, loss: 0.00016470879199914634
step: 30, loss: 9.90650660241954e-05
step: 40, loss: 0.001973654143512249
step: 50, loss: 0.00028796889819204807
step: 60, loss: 9.018917626235634e-05
step: 70, loss: 7.279588317032903e-05
step: 80, loss: 0.0005227160290814936
step: 90, loss: 0.00023410777794197202
step: 100, loss: 0.0001459074701415375
step: 110, loss: 9.953456174116582e-05
step: 120, loss: 0.00018199719488620758
step: 130, loss: 0.0002243191411253065
step: 140, loss: 0.0005504856235347688
step: 150, loss: 0.0001093287646654062
step: 160, loss: 6.547754310304299e-05
step: 170, loss: 0.007559309247881174
step: 180, loss: 0.0001829555694712326
step: 190, loss: 0.0007044347003102303
step: 200, loss: 0.000360320060281083
step: 210, loss: 0.001676192507147789
step: 220, loss: 0.005480656400322914
step: 230, loss: 0.0012369256000965834
step: 240, loss: 5.901580516365357e-05
step: 250, loss: 4.50402767455671e-05
step: 260, loss: 6.321557884803042e-05
step: 270, loss: 0.0158984437584877
step: 280, loss: 0.000249026546953246
step: 290, loss: 0.041605573147535324
step: 300, loss: 0.00048130418872460723
step: 310, loss: 0.00022183054534252733
step: 320, loss: 0.0001311642408836633
step: 330, loss: 0.020199351012706757
step: 340, loss: 0.0002889616007450968
step: 350, loss: 0.0011575145181268454
step: 360, loss: 0.0023030927404761314
step: 370, loss: 0.00015456894470844418
step: 380, loss: 0.0003034373512491584
epoch 18: dev_f1=0.8162162162162163, f1=0.608433734939759, best_f1=0.6563307493540051
step: 0, loss: 4.865923256147653e-05
step: 10, loss: 8.261997572844848e-05
step: 20, loss: 0.00013884504733141512
step: 30, loss: 3.890164953190833e-05
step: 40, loss: 0.00027322256937623024
step: 50, loss: 0.00029538245871663094
step: 60, loss: 6.22450461378321e-05
step: 70, loss: 5.643329131999053e-05
step: 80, loss: 0.000874243036378175
step: 90, loss: 0.0002092977665597573
step: 100, loss: 0.007897423580288887
step: 110, loss: 0.00018696309416554868
step: 120, loss: 0.00027231703279539943
step: 130, loss: 0.007415466476231813
step: 140, loss: 8.968792099040002e-05
step: 150, loss: 0.0004535525804385543
step: 160, loss: 8.294277358800173e-05
step: 170, loss: 0.00010551072773523629
step: 180, loss: 0.00011770601122407243
step: 190, loss: 0.0002640576858539134
step: 200, loss: 9.382549615111202e-05
step: 210, loss: 0.00012519002484623343
step: 220, loss: 0.0008412336464971304
step: 230, loss: 0.08547487109899521
step: 240, loss: 9.99621843220666e-05
step: 250, loss: 4.949242793372832e-05
step: 260, loss: 0.0008435941417701542
step: 270, loss: 0.00026174058439210057
step: 280, loss: 7.292945520021021e-05
step: 290, loss: 0.00029693980468437076
step: 300, loss: 0.0007214375655166805
step: 310, loss: 0.00010623767593642697
step: 320, loss: 5.40409964742139e-05
step: 330, loss: 0.00043143355287611485
step: 340, loss: 0.0032610653433948755
step: 350, loss: 0.00012158882600488141
step: 360, loss: 0.0025519656483083963
step: 370, loss: 4.5878208766225725e-05
step: 380, loss: 3.57614153472241e-05
epoch 19: dev_f1=0.8176795580110496, f1=0.5875, best_f1=0.6563307493540051
step: 0, loss: 0.0010401004692539573
step: 10, loss: 0.00016961892833933234
step: 20, loss: 0.00013579096412286162
step: 30, loss: 5.172810415388085e-05
step: 40, loss: 0.00013786691124550998
step: 50, loss: 0.00012503251491580158
step: 60, loss: 0.00084323575720191
step: 70, loss: 0.00010695953096728772
step: 80, loss: 3.925917189917527e-05
step: 90, loss: 0.002031695330515504
step: 100, loss: 0.002100758720189333
step: 110, loss: 3.060935705434531e-05
step: 120, loss: 0.004327921196818352
step: 130, loss: 0.0002008641167776659
step: 140, loss: 0.0003476073034107685
step: 150, loss: 6.000838038744405e-05
step: 160, loss: 0.0002259797474835068
step: 170, loss: 7.952451414894313e-05
step: 180, loss: 0.015661947429180145
step: 190, loss: 7.446324889315292e-05
step: 200, loss: 0.0008137089316733181
step: 210, loss: 3.6562112654792145e-05
step: 220, loss: 0.00434005307033658
step: 230, loss: 6.570852565346286e-05
step: 240, loss: 3.678876601043157e-05
step: 250, loss: 0.0002785427204798907
step: 260, loss: 0.001942125498317182
step: 270, loss: 0.00013137170753907412
step: 280, loss: 0.0009701249073259532
step: 290, loss: 0.00027665612287819386
step: 300, loss: 0.059612661600112915
step: 310, loss: 0.00016497090109623969
step: 320, loss: 0.002031519077718258
step: 330, loss: 6.224331445991993e-05
step: 340, loss: 0.00026223371969535947
step: 350, loss: 4.107650966034271e-05
step: 360, loss: 8.441317186225206e-05
step: 370, loss: 9.35105636017397e-05
step: 380, loss: 0.00014666553761344403
epoch 20: dev_f1=0.8184281842818427, f1=0.60790273556231, best_f1=0.6563307493540051
