cuda
Device: cuda
step: 0, loss: 0.5800337791442871
step: 10, loss: 0.44590452313423157
step: 20, loss: 0.35985973477363586
step: 30, loss: 0.356528103351593
step: 40, loss: 0.40323302149772644
step: 50, loss: 0.26180410385131836
step: 60, loss: 0.2558915615081787
step: 70, loss: 0.22325432300567627
step: 80, loss: 0.3485419750213623
step: 90, loss: 0.3851466774940491
step: 100, loss: 0.16919027268886566
step: 110, loss: 0.1102055162191391
step: 120, loss: 0.1379324495792389
step: 130, loss: 0.14246444404125214
step: 140, loss: 0.18188104033470154
step: 150, loss: 0.24818336963653564
step: 160, loss: 0.07643035799264908
step: 170, loss: 0.27557137608528137
step: 180, loss: 0.14670202136039734
step: 190, loss: 0.16367065906524658
step: 200, loss: 0.2535019814968109
step: 210, loss: 0.12604136765003204
step: 220, loss: 0.2673291563987732
step: 230, loss: 0.23683935403823853
step: 240, loss: 0.07765123248100281
step: 250, loss: 0.03511631861329079
step: 260, loss: 0.10709992796182632
step: 270, loss: 0.13553071022033691
step: 280, loss: 0.11292549967765808
step: 290, loss: 0.09014417976140976
step: 300, loss: 0.11403867602348328
step: 310, loss: 0.14675793051719666
step: 320, loss: 0.1360224485397339
step: 330, loss: 0.078923299908638
step: 340, loss: 0.09803168475627899
step: 350, loss: 0.173224076628685
step: 360, loss: 0.11534637212753296
step: 370, loss: 0.13821658492088318
step: 380, loss: 0.12356401234865189
step: 390, loss: 0.044474974274635315
step: 400, loss: 0.06840630620718002
step: 410, loss: 0.1318034827709198
step: 420, loss: 0.06182386353611946
step: 430, loss: 0.06909071654081345
step: 440, loss: 0.07940386235713959
step: 450, loss: 0.0926654115319252
step: 460, loss: 0.06760770827531815
step: 470, loss: 0.11755238473415375
step: 480, loss: 0.0837324932217598
step: 490, loss: 0.09563341736793518
step: 500, loss: 0.10264527797698975
step: 510, loss: 0.1848793774843216
step: 520, loss: 0.15902116894721985
step: 530, loss: 0.12598158419132233
step: 540, loss: 0.07483194768428802
step: 550, loss: 0.32758861780166626
step: 560, loss: 0.12751038372516632
step: 570, loss: 0.1043146476149559
step: 580, loss: 0.048901792615652084
step: 590, loss: 0.014771856367588043
step: 600, loss: 0.01895083487033844
step: 610, loss: 0.11212684214115143
step: 620, loss: 0.1603258103132248
step: 630, loss: 0.15042853355407715
step: 640, loss: 0.08339647948741913
step: 650, loss: 0.11684112995862961
step: 660, loss: 0.22261637449264526
step: 670, loss: 0.15394312143325806
step: 680, loss: 0.18683218955993652
step: 690, loss: 0.046039287000894547
step: 700, loss: 0.24324573576450348
step: 710, loss: 0.19035759568214417
step: 720, loss: 0.039167992770671844
step: 730, loss: 0.052888140082359314
step: 740, loss: 0.09469065070152283
step: 750, loss: 0.08135930448770523
step: 760, loss: 0.14276494085788727
step: 770, loss: 0.14128796756267548
step: 780, loss: 0.07714899629354477
step: 790, loss: 0.09695388376712799
step: 800, loss: 0.3131757080554962
step: 810, loss: 0.0518464557826519
step: 820, loss: 0.17274802923202515
step: 830, loss: 0.13880759477615356
step: 840, loss: 0.23604203760623932
step: 850, loss: 0.030615385621786118
step: 860, loss: 0.050977569073438644
step: 870, loss: 0.24074654281139374
step: 880, loss: 0.03810504078865051
step: 890, loss: 0.13259518146514893
step: 900, loss: 0.07329656183719635
step: 910, loss: 0.07195717096328735
step: 920, loss: 0.09061858057975769
step: 930, loss: 0.09562998265028
step: 940, loss: 0.04894707351922989
step: 950, loss: 0.09506584703922272
step: 960, loss: 0.099435955286026
step: 970, loss: 0.11471855640411377
step: 980, loss: 0.19075344502925873
step: 990, loss: 0.06260032206773758
step: 1000, loss: 0.11276184767484665
step: 1010, loss: 0.117701955139637
step: 1020, loss: 0.07900655269622803
step: 1030, loss: 0.09286820143461227
step: 1040, loss: 0.17033137381076813
step: 1050, loss: 0.0623285137116909
step: 1060, loss: 0.12669599056243896
step: 1070, loss: 0.1074429377913475
epoch 1: dev_f1=0.9271644525881814, f1=0.9294492489758761, best_f1=0.9294492489758761
step: 0, loss: 0.06196046620607376
step: 10, loss: 0.09705020487308502
step: 20, loss: 0.09969045966863632
step: 30, loss: 0.21465934813022614
step: 40, loss: 0.046526048332452774
step: 50, loss: 0.07036463916301727
step: 60, loss: 0.03923257440328598
step: 70, loss: 0.1256098449230194
step: 80, loss: 0.17588266730308533
step: 90, loss: 0.1063401997089386
step: 100, loss: 0.03406045213341713
step: 110, loss: 0.12607479095458984
step: 120, loss: 0.10734882950782776
step: 130, loss: 0.03330998495221138
step: 140, loss: 0.10198790580034256
step: 150, loss: 0.06453347206115723
step: 160, loss: 0.04877268522977829
step: 170, loss: 0.10841941833496094
step: 180, loss: 0.15412788093090057
step: 190, loss: 0.08474324643611908
step: 200, loss: 0.0817304328083992
step: 210, loss: 0.15538857877254486
step: 220, loss: 0.10604927688837051
step: 230, loss: 0.1954641491174698
step: 240, loss: 0.11663270741701126
step: 250, loss: 0.13459192216396332
step: 260, loss: 0.18360087275505066
step: 270, loss: 0.07835060358047485
step: 280, loss: 0.09434796124696732
step: 290, loss: 0.07260419428348541
step: 300, loss: 0.02022268809378147
step: 310, loss: 0.10916659981012344
step: 320, loss: 0.03153091296553612
step: 330, loss: 0.1315951645374298
step: 340, loss: 0.15577496588230133
step: 350, loss: 0.04844163730740547
step: 360, loss: 0.06422026455402374
step: 370, loss: 0.0742020532488823
step: 380, loss: 0.05173325911164284
step: 390, loss: 0.02407761663198471
step: 400, loss: 0.13252973556518555
step: 410, loss: 0.03713682293891907
step: 420, loss: 0.07670728117227554
step: 430, loss: 0.05277023836970329
step: 440, loss: 0.12428835779428482
step: 450, loss: 0.10567814111709595
step: 460, loss: 0.027157660573720932
step: 470, loss: 0.16315321624279022
step: 480, loss: 0.07428814470767975
step: 490, loss: 0.11670876294374466
step: 500, loss: 0.25488728284835815
step: 510, loss: 0.14068537950515747
step: 520, loss: 0.12870165705680847
step: 530, loss: 0.0257529616355896
step: 540, loss: 0.008907018229365349
step: 550, loss: 0.11275289207696915
step: 560, loss: 0.02346719615161419
step: 570, loss: 0.06807947158813477
step: 580, loss: 0.05849892273545265
step: 590, loss: 0.03640389442443848
step: 600, loss: 0.11722815036773682
step: 610, loss: 0.10933475941419601
step: 620, loss: 0.04479065537452698
step: 630, loss: 0.07275336980819702
step: 640, loss: 0.10263538360595703
step: 650, loss: 0.06449612975120544
step: 660, loss: 0.20484066009521484
step: 670, loss: 0.11301672458648682
step: 680, loss: 0.11730626225471497
step: 690, loss: 0.13645383715629578
step: 700, loss: 0.07354374974966049
step: 710, loss: 0.09706482291221619
step: 720, loss: 0.017110487446188927
step: 730, loss: 0.10327506810426712
step: 740, loss: 0.08115735650062561
step: 750, loss: 0.07234083861112595
step: 760, loss: 0.22013460099697113
step: 770, loss: 0.07748808711767197
step: 780, loss: 0.13064080476760864
step: 790, loss: 0.024071138352155685
step: 800, loss: 0.023212481290102005
step: 810, loss: 0.1370553821325302
step: 820, loss: 0.045586250722408295
step: 830, loss: 0.08683400601148605
step: 840, loss: 0.09999589622020721
step: 850, loss: 0.21196912229061127
step: 860, loss: 0.09885291755199432
step: 870, loss: 0.0010846845107153058
step: 880, loss: 0.05356970056891441
step: 890, loss: 0.16675934195518494
step: 900, loss: 0.046843789517879486
step: 910, loss: 0.09942203015089035
step: 920, loss: 0.03373517096042633
step: 930, loss: 0.1336251199245453
step: 940, loss: 0.1415526419878006
step: 950, loss: 0.04072043299674988
step: 960, loss: 0.047901466488838196
step: 970, loss: 0.08330829441547394
step: 980, loss: 0.15510308742523193
step: 990, loss: 0.0800737589597702
step: 1000, loss: 0.08520469069480896
step: 1010, loss: 0.08113414794206619
step: 1020, loss: 0.07027043402194977
step: 1030, loss: 0.09123484045267105
step: 1040, loss: 0.16045579314231873
step: 1050, loss: 0.08979310095310211
step: 1060, loss: 0.05449071153998375
step: 1070, loss: 0.13216787576675415
epoch 2: dev_f1=0.9204705882352942, f1=0.9204119850187266, best_f1=0.9294492489758761
step: 0, loss: 0.03317609801888466
step: 10, loss: 0.019670384004712105
step: 20, loss: 0.08629646897315979
step: 30, loss: 0.294553279876709
step: 40, loss: 0.032731615006923676
step: 50, loss: 0.030899956822395325
step: 60, loss: 0.025248974561691284
step: 70, loss: 0.11718194931745529
step: 80, loss: 0.04692723974585533
step: 90, loss: 0.028607238084077835
step: 100, loss: 0.03714274242520332
step: 110, loss: 0.05230024829506874
step: 120, loss: 0.01696327142417431
step: 130, loss: 0.015112323686480522
step: 140, loss: 0.01887126825749874
step: 150, loss: 0.09787394851446152
step: 160, loss: 0.015219250693917274
step: 170, loss: 0.019563322886824608
step: 180, loss: 0.050758764147758484
step: 190, loss: 0.10125464200973511
step: 200, loss: 0.03197092190384865
step: 210, loss: 0.13562016189098358
step: 220, loss: 0.1036386713385582
step: 230, loss: 0.15509642660617828
step: 240, loss: 0.06726986914873123
step: 250, loss: 0.04876086115837097
step: 260, loss: 0.08277548104524612
step: 270, loss: 0.059683315455913544
step: 280, loss: 0.04354097321629524
step: 290, loss: 0.13296282291412354
step: 300, loss: 0.10418760776519775
step: 310, loss: 0.005732654593884945
step: 320, loss: 0.10402942448854446
step: 330, loss: 0.055521685630083084
step: 340, loss: 0.09676530212163925
step: 350, loss: 0.03839867189526558
step: 360, loss: 0.03910595178604126
step: 370, loss: 0.0632903203368187
step: 380, loss: 0.1434241533279419
step: 390, loss: 0.07073216140270233
step: 400, loss: 0.21312840282917023
step: 410, loss: 0.07598259299993515
step: 420, loss: 0.06552427262067795
step: 430, loss: 0.1047116294503212
step: 440, loss: 0.06305846571922302
step: 450, loss: 0.015696367248892784
step: 460, loss: 0.10805289447307587
step: 470, loss: 0.027209632098674774
step: 480, loss: 0.10748335719108582
step: 490, loss: 0.05065905302762985
step: 500, loss: 0.06030198559165001
step: 510, loss: 0.18661130964756012
step: 520, loss: 0.1004737839102745
step: 530, loss: 0.08450780808925629
step: 540, loss: 0.022667743265628815
step: 550, loss: 0.07608509808778763
step: 560, loss: 0.029420899227261543
step: 570, loss: 0.007108891848474741
step: 580, loss: 0.03554404526948929
step: 590, loss: 0.13557468354701996
step: 600, loss: 0.08578585833311081
step: 610, loss: 0.05082983896136284
step: 620, loss: 0.1938014030456543
step: 630, loss: 0.01594921573996544
step: 640, loss: 0.028692318126559258
step: 650, loss: 0.03514065593481064
step: 660, loss: 0.04250462353229523
step: 670, loss: 0.10294665396213531
step: 680, loss: 0.060564812272787094
step: 690, loss: 0.04209592565894127
step: 700, loss: 0.03613525256514549
step: 710, loss: 0.1514938920736313
step: 720, loss: 0.16575558483600616
step: 730, loss: 0.014922112226486206
step: 740, loss: 0.06290723383426666
step: 750, loss: 0.16118837893009186
step: 760, loss: 0.053379230201244354
step: 770, loss: 0.03482964634895325
step: 780, loss: 0.15302935242652893
step: 790, loss: 0.06479358673095703
step: 800, loss: 0.014813975431025028
step: 810, loss: 0.02574409358203411
step: 820, loss: 0.10018619149923325
step: 830, loss: 0.19696077704429626
step: 840, loss: 0.07742445915937424
step: 850, loss: 0.05679554492235184
step: 860, loss: 0.09440014511346817
step: 870, loss: 0.0646309182047844
step: 880, loss: 0.16808058321475983
step: 890, loss: 0.0022683788556605577
step: 900, loss: 0.2071000337600708
step: 910, loss: 0.09474700689315796
step: 920, loss: 0.010690744034945965
step: 930, loss: 0.10450740158557892
step: 940, loss: 0.06443643569946289
step: 950, loss: 0.2323724925518036
step: 960, loss: 0.07720004767179489
step: 970, loss: 0.07655598968267441
step: 980, loss: 0.1312166005373001
step: 990, loss: 0.036368463188409805
step: 1000, loss: 0.07953958213329315
step: 1010, loss: 0.09699461609125137
step: 1020, loss: 0.03756318986415863
step: 1030, loss: 0.019423630088567734
step: 1040, loss: 0.05842779204249382
step: 1050, loss: 0.14929212629795074
step: 1060, loss: 0.0728924423456192
step: 1070, loss: 0.04457772150635719
epoch 3: dev_f1=0.9347014925373135, f1=0.9372967951695309, best_f1=0.9372967951695309
step: 0, loss: 0.05326254665851593
step: 10, loss: 0.04639463499188423
step: 20, loss: 0.09377306699752808
step: 30, loss: 0.12262360006570816
step: 40, loss: 0.13245777785778046
step: 50, loss: 0.07164555788040161
step: 60, loss: 0.05473688989877701
step: 70, loss: 0.12107935547828674
step: 80, loss: 0.019321393221616745
step: 90, loss: 0.09111708402633667
step: 100, loss: 0.00918847881257534
step: 110, loss: 0.0627087652683258
step: 120, loss: 0.11969435214996338
step: 130, loss: 0.06636699289083481
step: 140, loss: 0.08270635455846786
step: 150, loss: 0.007847700268030167
step: 160, loss: 0.04656529054045677
step: 170, loss: 0.03399785980582237
step: 180, loss: 0.021176941692829132
step: 190, loss: 0.05005591735243797
step: 200, loss: 0.23879298567771912
step: 210, loss: 0.02090434916317463
step: 220, loss: 0.15398719906806946
step: 230, loss: 0.024626286700367928
step: 240, loss: 0.050548821687698364
step: 250, loss: 0.031119221821427345
step: 260, loss: 0.12643234431743622
step: 270, loss: 0.0315377339720726
step: 280, loss: 0.003079576650634408
step: 290, loss: 0.07363986223936081
step: 300, loss: 0.13957691192626953
step: 310, loss: 0.0767863467335701
step: 320, loss: 0.1326710730791092
step: 330, loss: 0.1368708461523056
step: 340, loss: 0.04762040451169014
step: 350, loss: 0.03376454859972
step: 360, loss: 0.01958831399679184
step: 370, loss: 0.0713941901922226
step: 380, loss: 0.08825067430734634
step: 390, loss: 0.09302320331335068
step: 400, loss: 0.11173693090677261
step: 410, loss: 0.057433053851127625
step: 420, loss: 0.12792666256427765
step: 430, loss: 0.09605900198221207
step: 440, loss: 0.04755017161369324
step: 450, loss: 0.08759678155183792
step: 460, loss: 0.02568165771663189
step: 470, loss: 0.09687629342079163
step: 480, loss: 0.09734243154525757
step: 490, loss: 0.07216966897249222
step: 500, loss: 0.047641728073358536
step: 510, loss: 0.12741254270076752
step: 520, loss: 0.05652797594666481
step: 530, loss: 0.09712957590818405
step: 540, loss: 0.11902407556772232
step: 550, loss: 0.07965762913227081
step: 560, loss: 0.12519040703773499
step: 570, loss: 0.0715840682387352
step: 580, loss: 0.050563521683216095
step: 590, loss: 0.079045370221138
step: 600, loss: 0.00037900227471254766
step: 610, loss: 0.008706810884177685
step: 620, loss: 0.04230625182390213
step: 630, loss: 0.11921980232000351
step: 640, loss: 0.09855569154024124
step: 650, loss: 0.1650337129831314
step: 660, loss: 0.05473035201430321
step: 670, loss: 0.058501847088336945
step: 680, loss: 0.11122799664735794
step: 690, loss: 0.010182415135204792
step: 700, loss: 0.04655734822154045
step: 710, loss: 0.15479914844036102
step: 720, loss: 0.049252767115831375
step: 730, loss: 0.0473095178604126
step: 740, loss: 0.14646828174591064
step: 750, loss: 0.021888962015509605
step: 760, loss: 0.00547986663877964
step: 770, loss: 0.05251488834619522
step: 780, loss: 0.09544635564088821
step: 790, loss: 0.07954579591751099
step: 800, loss: 0.061289649456739426
step: 810, loss: 0.06639645248651505
step: 820, loss: 0.08405496925115585
step: 830, loss: 0.07292850315570831
step: 840, loss: 0.1617649495601654
step: 850, loss: 0.12179772555828094
step: 860, loss: 0.027366064488887787
step: 870, loss: 0.032817259430885315
step: 880, loss: 0.16086086630821228
step: 890, loss: 0.12894174456596375
step: 900, loss: 0.01814907416701317
step: 910, loss: 0.010134288109838963
step: 920, loss: 0.019225439056754112
step: 930, loss: 0.01649216189980507
step: 940, loss: 0.013622155413031578
step: 950, loss: 0.04390726238489151
step: 960, loss: 0.06377305090427399
step: 970, loss: 0.07845938950777054
step: 980, loss: 0.049131352454423904
step: 990, loss: 0.08678341656923294
step: 1000, loss: 0.0438617505133152
step: 1010, loss: 0.18307042121887207
step: 1020, loss: 0.09178006649017334
step: 1030, loss: 0.02468159981071949
step: 1040, loss: 0.12247886508703232
step: 1050, loss: 0.0867469534277916
step: 1060, loss: 0.09054223448038101
step: 1070, loss: 0.028748631477355957
epoch 4: dev_f1=0.9348025711662074, f1=0.9387755102040816, best_f1=0.9387755102040816
step: 0, loss: 0.18820172548294067
step: 10, loss: 0.02958260104060173
step: 20, loss: 0.025122804567217827
step: 30, loss: 0.049219708889722824
step: 40, loss: 0.004186535719782114
step: 50, loss: 0.07938016206026077
step: 60, loss: 0.06628108769655228
step: 70, loss: 0.018311908468604088
step: 80, loss: 0.03885379061102867
step: 90, loss: 0.16344965994358063
step: 100, loss: 0.18663722276687622
step: 110, loss: 0.06056252494454384
step: 120, loss: 0.20665597915649414
step: 130, loss: 0.08324411511421204
step: 140, loss: 0.006624172441661358
step: 150, loss: 0.014344504103064537
step: 160, loss: 0.017244039103388786
step: 170, loss: 0.12436313182115555
step: 180, loss: 0.1082410141825676
step: 190, loss: 0.07372772693634033
step: 200, loss: 0.017264539375901222
step: 210, loss: 0.07373006641864777
step: 220, loss: 0.0033867547754198313
step: 230, loss: 0.14693452417850494
step: 240, loss: 0.05376965180039406
step: 250, loss: 0.013606447726488113
step: 260, loss: 0.07245217263698578
step: 270, loss: 0.10196700692176819
step: 280, loss: 0.13548824191093445
step: 290, loss: 0.012380873784422874
step: 300, loss: 0.10918626189231873
step: 310, loss: 0.007545886095613241
step: 320, loss: 0.09842298179864883
step: 330, loss: 0.03093651682138443
step: 340, loss: 0.03145731985569
step: 350, loss: 0.11454087495803833
step: 360, loss: 0.05921148136258125
step: 370, loss: 0.06438452005386353
step: 380, loss: 0.07709518820047379
step: 390, loss: 0.023041684180498123
step: 400, loss: 0.13193190097808838
step: 410, loss: 0.04762845113873482
step: 420, loss: 0.13258299231529236
step: 430, loss: 0.06939209252595901
step: 440, loss: 0.09657767415046692
step: 450, loss: 0.024399451911449432
step: 460, loss: 0.12196259945631027
step: 470, loss: 0.06917338818311691
step: 480, loss: 0.0189678855240345
step: 490, loss: 0.15265056490898132
step: 500, loss: 0.028754165396094322
step: 510, loss: 0.10971514135599136
step: 520, loss: 0.00811469741165638
step: 530, loss: 0.4348651170730591
step: 540, loss: 0.0741446241736412
step: 550, loss: 0.15841230750083923
step: 560, loss: 0.08710891008377075
step: 570, loss: 0.03210967779159546
step: 580, loss: 0.013946586288511753
step: 590, loss: 0.12858855724334717
step: 600, loss: 0.03692182898521423
step: 610, loss: 0.06694407761096954
step: 620, loss: 0.049120258539915085
step: 630, loss: 0.020537737756967545
step: 640, loss: 0.029184777289628983
step: 650, loss: 0.09982293844223022
step: 660, loss: 0.08877109736204147
step: 670, loss: 0.12367254495620728
step: 680, loss: 0.1525222212076187
step: 690, loss: 0.08989118784666061
step: 700, loss: 0.03390878066420555
step: 710, loss: 0.06669048964977264
step: 720, loss: 0.006877018138766289
step: 730, loss: 0.13958682119846344
step: 740, loss: 0.009379204362630844
step: 750, loss: 0.06913158297538757
step: 760, loss: 0.05497647076845169
step: 770, loss: 0.043271005153656006
step: 780, loss: 0.17606733739376068
step: 790, loss: 0.011274266988039017
step: 800, loss: 0.09592755883932114
step: 810, loss: 0.11805819720029831
step: 820, loss: 0.06566157191991806
step: 830, loss: 0.10271335393190384
step: 840, loss: 0.056798212230205536
step: 850, loss: 0.023124389350414276
step: 860, loss: 0.030131077393889427
step: 870, loss: 0.19821564853191376
step: 880, loss: 0.018877873197197914
step: 890, loss: 0.10525595396757126
step: 900, loss: 0.03372664004564285
step: 910, loss: 0.10699981451034546
step: 920, loss: 0.034939173609018326
step: 930, loss: 0.05520915240049362
step: 940, loss: 0.12255821377038956
step: 950, loss: 0.031189342960715294
step: 960, loss: 0.007239607162773609
step: 970, loss: 0.1251494586467743
step: 980, loss: 0.08706727623939514
step: 990, loss: 0.013921412639319897
step: 1000, loss: 0.015809541568160057
step: 1010, loss: 0.05525989830493927
step: 1020, loss: 0.013923080638051033
step: 1030, loss: 0.08630720525979996
step: 1040, loss: 0.0782313346862793
step: 1050, loss: 0.08371329307556152
step: 1060, loss: 0.10501527786254883
step: 1070, loss: 0.07747264951467514
epoch 5: dev_f1=0.935933147632312, f1=0.9383402874362541, best_f1=0.9383402874362541
step: 0, loss: 0.13932377099990845
step: 10, loss: 0.030792299658060074
step: 20, loss: 0.07877711206674576
step: 30, loss: 0.06685245037078857
step: 40, loss: 0.041028834879398346
step: 50, loss: 0.06742671132087708
step: 60, loss: 0.20629577338695526
step: 70, loss: 0.12418773770332336
step: 80, loss: 0.06098192185163498
step: 90, loss: 0.030716916546225548
step: 100, loss: 0.057222526520490646
step: 110, loss: 0.052155181765556335
step: 120, loss: 0.03585401549935341
step: 130, loss: 0.07306454330682755
step: 140, loss: 0.045395951718091965
step: 150, loss: 0.011684929952025414
step: 160, loss: 0.04665932431817055
step: 170, loss: 0.03279339522123337
step: 180, loss: 0.06515374034643173
step: 190, loss: 0.04861966520547867
step: 200, loss: 0.012176902033388615
step: 210, loss: 0.01122304331511259
step: 220, loss: 0.04560735449194908
step: 230, loss: 0.08872755616903305
step: 240, loss: 0.016510389745235443
step: 250, loss: 0.009855941869318485
step: 260, loss: 0.01738547347486019
step: 270, loss: 0.10013103485107422
step: 280, loss: 0.004371659830212593
step: 290, loss: 0.027809876948595047
step: 300, loss: 0.017649143934249878
step: 310, loss: 0.07583050429821014
step: 320, loss: 0.02471752092242241
step: 330, loss: 0.0049300482496619225
step: 340, loss: 0.13061900436878204
step: 350, loss: 0.028485342860221863
step: 360, loss: 0.1257096379995346
step: 370, loss: 0.10803945362567902
step: 380, loss: 0.05417151004076004
step: 390, loss: 0.03096729703247547
step: 400, loss: 0.05135399103164673
step: 410, loss: 0.03773310407996178
step: 420, loss: 0.07027073949575424
step: 430, loss: 0.0006938498700037599
step: 440, loss: 0.0145172830671072
step: 450, loss: 0.023940959945321083
step: 460, loss: 0.1235186904668808
step: 470, loss: 0.015530404634773731
step: 480, loss: 0.03838396444916725
step: 490, loss: 0.1418517529964447
step: 500, loss: 0.07136242836713791
step: 510, loss: 0.02614467777311802
step: 520, loss: 0.062280673533678055
step: 530, loss: 0.06981756538152695
step: 540, loss: 0.0939064770936966
step: 550, loss: 0.007420056499540806
step: 560, loss: 0.03630288690328598
step: 570, loss: 0.12776042520999908
step: 580, loss: 0.0011644205078482628
step: 590, loss: 0.1013273298740387
step: 600, loss: 0.1189323216676712
step: 610, loss: 0.09736762940883636
step: 620, loss: 0.1481517255306244
step: 630, loss: 0.15709054470062256
step: 640, loss: 0.019585810601711273
step: 650, loss: 0.029563384130597115
step: 660, loss: 0.03699116408824921
step: 670, loss: 0.0020244629122316837
step: 680, loss: 0.10158326476812363
step: 690, loss: 0.049883779138326645
step: 700, loss: 0.07173900306224823
step: 710, loss: 0.007266403175890446
step: 720, loss: 0.02176823653280735
step: 730, loss: 0.04216384142637253
step: 740, loss: 0.009796303696930408
step: 750, loss: 0.05046532303094864
step: 760, loss: 0.015823666006326675
step: 770, loss: 0.08312249183654785
step: 780, loss: 0.054728660732507706
step: 790, loss: 0.060170289129018784
step: 800, loss: 0.09166182577610016
step: 810, loss: 0.007559482473880053
step: 820, loss: 0.2195223569869995
step: 830, loss: 0.11067350953817368
step: 840, loss: 0.04666692763566971
step: 850, loss: 0.04104054719209671
step: 860, loss: 0.15054476261138916
step: 870, loss: 0.029536031186580658
step: 880, loss: 0.07863889634609222
step: 890, loss: 0.02435031160712242
step: 900, loss: 0.22351644933223724
step: 910, loss: 0.05033273994922638
step: 920, loss: 0.007231404073536396
step: 930, loss: 0.059827014803886414
step: 940, loss: 0.120302215218544
step: 950, loss: 0.011900200508534908
step: 960, loss: 0.005704565905034542
step: 970, loss: 0.05757864564657211
step: 980, loss: 0.12765400111675262
step: 990, loss: 0.18073707818984985
step: 1000, loss: 0.08561386168003082
step: 1010, loss: 0.06806926429271698
step: 1020, loss: 0.09030759334564209
step: 1030, loss: 0.087179034948349
step: 1040, loss: 0.02908027172088623
step: 1050, loss: 0.013460304588079453
step: 1060, loss: 0.08959723263978958
step: 1070, loss: 0.06854911893606186
epoch 6: dev_f1=0.9307107733571749, f1=0.9242492155983864, best_f1=0.9383402874362541
step: 0, loss: 0.13379381597042084
step: 10, loss: 0.08011773973703384
step: 20, loss: 0.03849572315812111
step: 30, loss: 0.0235278457403183
step: 40, loss: 0.11010719835758209
step: 50, loss: 0.03613411635160446
step: 60, loss: 0.0503363311290741
step: 70, loss: 0.2195299118757248
step: 80, loss: 0.019923176616430283
step: 90, loss: 0.015746386721730232
step: 100, loss: 0.0773719847202301
step: 110, loss: 8.901602996047586e-05
step: 120, loss: 0.0993608832359314
step: 130, loss: 0.06127845123410225
step: 140, loss: 0.013919062912464142
step: 150, loss: 0.06118747964501381
step: 160, loss: 0.07733568549156189
step: 170, loss: 0.10695812106132507
step: 180, loss: 0.04018614813685417
step: 190, loss: 0.015927311033010483
step: 200, loss: 0.04636712744832039
step: 210, loss: 0.1658240556716919
step: 220, loss: 0.013713653199374676
step: 230, loss: 0.04646282270550728
step: 240, loss: 0.008254378102719784
step: 250, loss: 0.030659731477499008
step: 260, loss: 0.07982170581817627
step: 270, loss: 0.17564426362514496
step: 280, loss: 0.0180377047508955
step: 290, loss: 0.012562761083245277
step: 300, loss: 0.09778150916099548
step: 310, loss: 0.36502590775489807
step: 320, loss: 0.0871070995926857
step: 330, loss: 0.0830465778708458
step: 340, loss: 0.017570583149790764
step: 350, loss: 0.038693495094776154
step: 360, loss: 0.08964110165834427
step: 370, loss: 0.06411731988191605
step: 380, loss: 0.016364553943276405
step: 390, loss: 0.10538872331380844
step: 400, loss: 0.021232161670923233
step: 410, loss: 0.0825677439570427
step: 420, loss: 0.008720887824892998
step: 430, loss: 0.1164572536945343
step: 440, loss: 0.011631055735051632
step: 450, loss: 0.06873790919780731
step: 460, loss: 0.09565712511539459
step: 470, loss: 0.024407701566815376
step: 480, loss: 0.0260419063270092
step: 490, loss: 0.012218083254992962
step: 500, loss: 0.017463326454162598
step: 510, loss: 0.057079918682575226
step: 520, loss: 0.09274770319461823
step: 530, loss: 0.1531982570886612
step: 540, loss: 0.07348863780498505
step: 550, loss: 0.011544878594577312
step: 560, loss: 0.015987342223525047
step: 570, loss: 0.1661948710680008
step: 580, loss: 0.023771319538354874
step: 590, loss: 0.1156967431306839
step: 600, loss: 0.06672138720750809
step: 610, loss: 0.06806833297014236
step: 620, loss: 0.04582170769572258
step: 630, loss: 0.023652661591768265
step: 640, loss: 0.005390441045165062
step: 650, loss: 0.00028211355675011873
step: 660, loss: 0.01020263321697712
step: 670, loss: 0.10626395791769028
step: 680, loss: 0.10348334163427353
step: 690, loss: 0.039743419736623764
step: 700, loss: 0.012616828083992004
step: 710, loss: 0.00726383738219738
step: 720, loss: 0.0032563484273850918
step: 730, loss: 0.029103200882673264
step: 740, loss: 0.024909237399697304
step: 750, loss: 0.09290001541376114
step: 760, loss: 0.006331637501716614
step: 770, loss: 0.019770000129938126
step: 780, loss: 0.08090174943208694
step: 790, loss: 0.07750169932842255
step: 800, loss: 0.10690475255250931
step: 810, loss: 0.06974879652261734
step: 820, loss: 0.13908478617668152
step: 830, loss: 0.1429155319929123
step: 840, loss: 0.1337936818599701
step: 850, loss: 0.13772661983966827
step: 860, loss: 0.07410037517547607
step: 870, loss: 0.13259506225585938
step: 880, loss: 0.012511258944869041
step: 890, loss: 0.029947329312562943
step: 900, loss: 0.09609773010015488
step: 910, loss: 0.025840649381279945
step: 920, loss: 0.01713472232222557
step: 930, loss: 0.06816866993904114
step: 940, loss: 0.10863043367862701
step: 950, loss: 0.052222840487957
step: 960, loss: 0.011628707870841026
step: 970, loss: 0.008898654021322727
step: 980, loss: 0.02565833553671837
step: 990, loss: 0.0547807477414608
step: 1000, loss: 0.04665253683924675
step: 1010, loss: 0.09476568549871445
step: 1020, loss: 0.06835314631462097
step: 1030, loss: 0.08450013399124146
step: 1040, loss: 0.013924788683652878
step: 1050, loss: 0.006821169052273035
step: 1060, loss: 0.09106960892677307
step: 1070, loss: 0.09751761704683304
epoch 7: dev_f1=0.9386814200092208, f1=0.9324817518248174, best_f1=0.9324817518248174
step: 0, loss: 0.06384797394275665
step: 10, loss: 0.10015199333429337
step: 20, loss: 0.09637380391359329
step: 30, loss: 0.01987900212407112
step: 40, loss: 0.0624883770942688
step: 50, loss: 0.012617582455277443
step: 60, loss: 0.05085437744855881
step: 70, loss: 0.04187167435884476
step: 80, loss: 0.04915088415145874
step: 90, loss: 0.02171947807073593
step: 100, loss: 0.021888315677642822
step: 110, loss: 0.04670484736561775
step: 120, loss: 0.020726259797811508
step: 130, loss: 0.12075988948345184
step: 140, loss: 0.08465147018432617
step: 150, loss: 0.0002136558323400095
step: 160, loss: 0.145297110080719
step: 170, loss: 0.03714678809046745
step: 180, loss: 0.026077408343553543
step: 190, loss: 0.08042632788419724
step: 200, loss: 0.10220374912023544
step: 210, loss: 0.03190063312649727
step: 220, loss: 0.018620915710926056
step: 230, loss: 0.08758699148893356
step: 240, loss: 0.06819193065166473
step: 250, loss: 0.024892456829547882
step: 260, loss: 0.13108961284160614
step: 270, loss: 0.02242877334356308
step: 280, loss: 0.17536988854408264
step: 290, loss: 0.022507404908537865
step: 300, loss: 0.06085304543375969
step: 310, loss: 0.03620341792702675
step: 320, loss: 0.06474482268095016
step: 330, loss: 0.025179585441946983
step: 340, loss: 0.03462425619363785
step: 350, loss: 0.01627143658697605
step: 360, loss: 0.03993398696184158
step: 370, loss: 0.07976356148719788
step: 380, loss: 0.11711739748716354
step: 390, loss: 0.09886457026004791
step: 400, loss: 0.0973920002579689
step: 410, loss: 0.057647861540317535
step: 420, loss: 0.013508967123925686
step: 430, loss: 0.030583178624510765
step: 440, loss: 0.035233207046985626
step: 450, loss: 0.13400039076805115
step: 460, loss: 0.05925515294075012
step: 470, loss: 0.027927249670028687
step: 480, loss: 0.060994021594524384
step: 490, loss: 0.024830888956785202
step: 500, loss: 0.008296387270092964
step: 510, loss: 0.13988426327705383
step: 520, loss: 0.09683851897716522
step: 530, loss: 0.016393793746829033
step: 540, loss: 0.08857787400484085
step: 550, loss: 0.008612149395048618
step: 560, loss: 0.04556562751531601
step: 570, loss: 0.022711168974637985
step: 580, loss: 0.06181969866156578
step: 590, loss: 0.013887987472116947
step: 600, loss: 0.004670852329581976
step: 610, loss: 0.014325183816254139
step: 620, loss: 0.07424598187208176
step: 630, loss: 0.06966304779052734
step: 640, loss: 0.023403547704219818
step: 650, loss: 0.04301237687468529
step: 660, loss: 0.027203615754842758
step: 670, loss: 0.11942706257104874
step: 680, loss: 0.08480992168188095
step: 690, loss: 0.009492547251284122
step: 700, loss: 0.06679295748472214
step: 710, loss: 0.005839063785970211
step: 720, loss: 0.007345004007220268
step: 730, loss: 0.06295453757047653
step: 740, loss: 0.07715022563934326
step: 750, loss: 0.06985694915056229
step: 760, loss: 0.015159424394369125
step: 770, loss: 0.14791379868984222
step: 780, loss: 0.02320866473019123
step: 790, loss: 0.030185440555214882
step: 800, loss: 0.045405980199575424
step: 810, loss: 0.12972505390644073
step: 820, loss: 0.14824321866035461
step: 830, loss: 0.013758807443082333
step: 840, loss: 0.015059123747050762
step: 850, loss: 0.09614568203687668
step: 860, loss: 0.0713038444519043
step: 870, loss: 0.056193117052316666
step: 880, loss: 0.03442276269197464
step: 890, loss: 0.05194106325507164
step: 900, loss: 0.0009227526024915278
step: 910, loss: 0.01362832635641098
step: 920, loss: 0.016608085483312607
step: 930, loss: 0.02226240374147892
step: 940, loss: 0.05111496523022652
step: 950, loss: 0.09359464049339294
step: 960, loss: 0.2559431493282318
step: 970, loss: 0.044271908700466156
step: 980, loss: 0.019166504964232445
step: 990, loss: 0.08279187977313995
step: 1000, loss: 0.031035391613841057
step: 1010, loss: 0.12227749079465866
step: 1020, loss: 0.04044996574521065
step: 1030, loss: 0.014937845058739185
step: 1040, loss: 0.10803800821304321
step: 1050, loss: 0.010127714835107327
step: 1060, loss: 0.005545565392822027
step: 1070, loss: 0.06748567521572113
epoch 8: dev_f1=0.9394495412844037, f1=0.9360919540229884, best_f1=0.9360919540229884
step: 0, loss: 0.013896999880671501
step: 10, loss: 0.07217119634151459
step: 20, loss: 0.057097114622592926
step: 30, loss: 0.026392731815576553
step: 40, loss: 0.011283359490334988
step: 50, loss: 0.0995459109544754
step: 60, loss: 0.05156619846820831
step: 70, loss: 0.1599740982055664
step: 80, loss: 0.0667930543422699
step: 90, loss: 0.05346984416246414
step: 100, loss: 0.023304233327507973
step: 110, loss: 0.08637576550245285
step: 120, loss: 0.022840913385152817
step: 130, loss: 0.05834275484085083
step: 140, loss: 0.01872396469116211
step: 150, loss: 0.007136484608054161
step: 160, loss: 0.012804899364709854
step: 170, loss: 0.03465434908866882
step: 180, loss: 0.18580016493797302
step: 190, loss: 0.02122931368649006
step: 200, loss: 0.0639401227235794
step: 210, loss: 0.035223349928855896
step: 220, loss: 0.03278737887740135
step: 230, loss: 0.018954435363411903
step: 240, loss: 0.02745930291712284
step: 250, loss: 0.048605628311634064
step: 260, loss: 0.009321019053459167
step: 270, loss: 0.026266515254974365
step: 280, loss: 0.23201417922973633
step: 290, loss: 0.08569350093603134
step: 300, loss: 0.06951886415481567
step: 310, loss: 0.04231888800859451
step: 320, loss: 0.02668667957186699
step: 330, loss: 0.019489631056785583
step: 340, loss: 0.010663708671927452
step: 350, loss: 0.18981999158859253
step: 360, loss: 0.09791157394647598
step: 370, loss: 0.03920920938253403
step: 380, loss: 0.031341973692178726
step: 390, loss: 0.03599350526928902
step: 400, loss: 0.08400318026542664
step: 410, loss: 0.0020868319552391768
step: 420, loss: 0.008542612195014954
step: 430, loss: 0.04721999168395996
step: 440, loss: 0.10344963520765305
step: 450, loss: 0.009774763137102127
step: 460, loss: 0.1610940545797348
step: 470, loss: 0.048550594598054886
step: 480, loss: 0.03284711763262749
step: 490, loss: 0.02711459994316101
step: 500, loss: 0.03128908947110176
step: 510, loss: 0.01740763895213604
step: 520, loss: 0.03314363583922386
step: 530, loss: 0.07764428108930588
step: 540, loss: 0.029449839144945145
step: 550, loss: 0.09714347124099731
step: 560, loss: 0.07437995076179504
step: 570, loss: 0.04013938456773758
step: 580, loss: 0.06596972793340683
step: 590, loss: 0.09474404156208038
step: 600, loss: 0.021777093410491943
step: 610, loss: 0.011397045105695724
step: 620, loss: 0.10939091444015503
step: 630, loss: 0.09231963753700256
step: 640, loss: 0.09005787968635559
step: 650, loss: 0.08802808076143265
step: 660, loss: 0.019398188218474388
step: 670, loss: 0.051422711461782455
step: 680, loss: 0.07771061360836029
step: 690, loss: 0.11065798252820969
step: 700, loss: 0.09602522104978561
step: 710, loss: 0.003697556909173727
step: 720, loss: 0.007393302861601114
step: 730, loss: 0.005383800715208054
step: 740, loss: 0.03600307181477547
step: 750, loss: 0.051901452243328094
step: 760, loss: 0.0076147085055708885
step: 770, loss: 0.056685399264097214
step: 780, loss: 0.020895525813102722
step: 790, loss: 0.006492813117802143
step: 800, loss: 0.004615330137312412
step: 810, loss: 0.11960921436548233
step: 820, loss: 0.01513742282986641
step: 830, loss: 0.09001161903142929
step: 840, loss: 0.04500380530953407
step: 850, loss: 0.026837462559342384
step: 860, loss: 0.0010020984336733818
step: 870, loss: 0.014664395712316036
step: 880, loss: 0.00010049828415503725
step: 890, loss: 0.11634063720703125
step: 900, loss: 0.05917268991470337
step: 910, loss: 0.06011977791786194
step: 920, loss: 0.013702744618058205
step: 930, loss: 0.012639273889362812
step: 940, loss: 0.11066850274801254
step: 950, loss: 0.01977457106113434
step: 960, loss: 0.04426246136426926
step: 970, loss: 0.03174750879406929
step: 980, loss: 0.1372348815202713
step: 990, loss: 0.01954890415072441
step: 1000, loss: 0.011989176273345947
step: 1010, loss: 0.0886690765619278
step: 1020, loss: 0.15472525358200073
step: 1030, loss: 0.1601545214653015
step: 1040, loss: 0.18731608986854553
step: 1050, loss: 0.013781541958451271
step: 1060, loss: 0.019183196127414703
step: 1070, loss: 0.20102907717227936
epoch 9: dev_f1=0.9311926605504587, f1=0.9284085727314182, best_f1=0.9360919540229884
step: 0, loss: 0.0104641979560256
step: 10, loss: 0.0010848119854927063
step: 20, loss: 0.04225124791264534
step: 30, loss: 0.1815340667963028
step: 40, loss: 0.011689355596899986
step: 50, loss: 0.0746195986866951
step: 60, loss: 0.04884766787290573
step: 70, loss: 0.08481276035308838
step: 80, loss: 0.0020312040578573942
step: 90, loss: 0.10376906394958496
step: 100, loss: 0.022300979122519493
step: 110, loss: 0.04701484367251396
step: 120, loss: 0.039438601583242416
step: 130, loss: 0.008431391790509224
step: 140, loss: 0.06121916323900223
step: 150, loss: 0.15730905532836914
step: 160, loss: 0.03791600465774536
step: 170, loss: 0.06380291283130646
step: 180, loss: 0.10285726934671402
step: 190, loss: 0.030856631696224213
step: 200, loss: 0.06428182125091553
step: 210, loss: 0.021459383890032768
step: 220, loss: 0.011982625350356102
step: 230, loss: 0.027407655492424965
step: 240, loss: 0.00604130607098341
step: 250, loss: 0.0028597547207027674
step: 260, loss: 0.11911413818597794
step: 270, loss: 0.10396858304738998
step: 280, loss: 0.06622906029224396
step: 290, loss: 0.001068092999048531
step: 300, loss: 0.18022577464580536
step: 310, loss: 0.06820249557495117
step: 320, loss: 0.06278840452432632
step: 330, loss: 0.07805350422859192
step: 340, loss: 0.08551737666130066
step: 350, loss: 0.017463162541389465
step: 360, loss: 0.0200824998319149
step: 370, loss: 0.008581403642892838
step: 380, loss: 0.011632483452558517
step: 390, loss: 0.038270771503448486
step: 400, loss: 0.06681136786937714
step: 410, loss: 0.000789051060564816
step: 420, loss: 0.09738960862159729
step: 430, loss: 0.0058197579346597195
step: 440, loss: 0.009217509999871254
step: 450, loss: 0.011157425120472908
step: 460, loss: 0.058609671890735626
step: 470, loss: 0.07963606715202332
step: 480, loss: 0.04321175813674927
step: 490, loss: 0.01692110113799572
step: 500, loss: 0.019332675263285637
step: 510, loss: 0.1006329283118248
step: 520, loss: 0.020425213500857353
step: 530, loss: 0.018937963992357254
step: 540, loss: 0.030629124492406845
step: 550, loss: 0.018420960754156113
step: 560, loss: 0.08365863561630249
step: 570, loss: 0.0441797710955143
step: 580, loss: 0.15160606801509857
step: 590, loss: 0.016151897609233856
step: 600, loss: 0.02968768961727619
step: 610, loss: 0.012207815423607826
step: 620, loss: 0.10740648210048676
step: 630, loss: 0.06741666048765182
step: 640, loss: 0.09048071503639221
step: 650, loss: 0.05074802786111832
step: 660, loss: 0.07613463699817657
step: 670, loss: 0.025240981951355934
step: 680, loss: 0.09347622841596603
step: 690, loss: 0.11865060031414032
step: 700, loss: 0.1697467863559723
step: 710, loss: 0.03031976707279682
step: 720, loss: 0.014037703163921833
step: 730, loss: 0.056555405259132385
step: 740, loss: 0.02570309303700924
step: 750, loss: 0.07962517440319061
step: 760, loss: 0.01025719940662384
step: 770, loss: 0.007151868660002947
step: 780, loss: 0.05183064192533493
step: 790, loss: 0.00837941374629736
step: 800, loss: 0.057978834956884384
step: 810, loss: 0.09380236268043518
step: 820, loss: 0.01634259708225727
step: 830, loss: 0.04040951654314995
step: 840, loss: 0.036710966378450394
step: 850, loss: 0.05189688503742218
step: 860, loss: 0.0516032911837101
step: 870, loss: 0.021645337343215942
step: 880, loss: 0.00707090413197875
step: 890, loss: 0.04215303063392639
step: 900, loss: 0.016232505440711975
step: 910, loss: 0.01958194188773632
step: 920, loss: 0.03859055042266846
step: 930, loss: 0.05412193760275841
step: 940, loss: 0.09288941323757172
step: 950, loss: 0.010513914749026299
step: 960, loss: 0.032629452645778656
step: 970, loss: 0.020240087062120438
step: 980, loss: 0.02923223376274109
step: 990, loss: 0.02743011899292469
step: 1000, loss: 0.09421058744192123
step: 1010, loss: 0.03418261930346489
step: 1020, loss: 0.01880418136715889
step: 1030, loss: 0.008510641753673553
step: 1040, loss: 0.058417804539203644
step: 1050, loss: 0.03640381619334221
step: 1060, loss: 0.1244562491774559
step: 1070, loss: 0.07426450401544571
epoch 10: dev_f1=0.9306008383791335, f1=0.9327691584391161, best_f1=0.9360919540229884
step: 0, loss: 0.1153566837310791
step: 10, loss: 0.04778267815709114
step: 20, loss: 7.261383871082217e-05
step: 30, loss: 0.03061312437057495
step: 40, loss: 0.01205880381166935
step: 50, loss: 0.05355675891041756
step: 60, loss: 0.04512551426887512
step: 70, loss: 0.04658885300159454
step: 80, loss: 0.26608216762542725
step: 90, loss: 0.06463661789894104
step: 100, loss: 0.033042456954717636
step: 110, loss: 0.03464294224977493
step: 120, loss: 0.01580362394452095
step: 130, loss: 0.044701896607875824
step: 140, loss: 0.06155204400420189
step: 150, loss: 0.1157117560505867
step: 160, loss: 0.08822578936815262
step: 170, loss: 0.04176381602883339
step: 180, loss: 0.017475662752985954
step: 190, loss: 0.00019855501886922866
step: 200, loss: 0.14681772887706757
step: 210, loss: 0.04006429761648178
step: 220, loss: 0.04641366004943848
step: 230, loss: 0.00026823251391761005
step: 240, loss: 0.01579609513282776
step: 250, loss: 0.12439758330583572
step: 260, loss: 0.01358659565448761
step: 270, loss: 6.946220673853531e-05
step: 280, loss: 0.04409858584403992
step: 290, loss: 0.09335436671972275
step: 300, loss: 2.5375024051754735e-05
step: 310, loss: 0.0890006572008133
step: 320, loss: 3.4269287425559014e-05
step: 330, loss: 0.09941229969263077
step: 340, loss: 0.011810004711151123
step: 350, loss: 0.03513730317354202
step: 360, loss: 0.007005584426224232
step: 370, loss: 0.04384005069732666
step: 380, loss: 0.008320416323840618
step: 390, loss: 0.03540085256099701
step: 400, loss: 0.18127329647541046
step: 410, loss: 0.008338511921465397
step: 420, loss: 0.0249040350317955
step: 430, loss: 0.015552597120404243
step: 440, loss: 0.11372630298137665
step: 450, loss: 0.028809450566768646
step: 460, loss: 0.015237347222864628
step: 470, loss: 0.009605219587683678
step: 480, loss: 0.12073173373937607
step: 490, loss: 0.09536393731832504
step: 500, loss: 0.022693321108818054
step: 510, loss: 0.02803077921271324
step: 520, loss: 0.005053205881267786
step: 530, loss: 0.1193651333451271
step: 540, loss: 0.17894317209720612
step: 550, loss: 0.024447452276945114
step: 560, loss: 0.11355514079332352
step: 570, loss: 0.01316467672586441
step: 580, loss: 0.0423927865922451
step: 590, loss: 0.0713714212179184
step: 600, loss: 0.06437509506940842
step: 610, loss: 0.06637652218341827
step: 620, loss: 0.06078748404979706
step: 630, loss: 0.003227603156119585
step: 640, loss: 0.0001536307972855866
step: 650, loss: 0.02948506362736225
step: 660, loss: 1.620843067939859e-05
step: 670, loss: 0.019790811464190483
step: 680, loss: 0.005297244992107153
step: 690, loss: 0.040092580020427704
step: 700, loss: 0.02162092924118042
step: 710, loss: 0.025495726615190506
step: 720, loss: 0.07268215715885162
step: 730, loss: 0.04566841945052147
step: 740, loss: 0.053274478763341904
step: 750, loss: 0.0703180730342865
step: 760, loss: 0.01116790622472763
step: 770, loss: 0.004289081785827875
step: 780, loss: 0.018071724101901054
step: 790, loss: 0.03702934831380844
step: 800, loss: 0.08804314583539963
step: 810, loss: 0.1446363776922226
step: 820, loss: 0.04837526008486748
step: 830, loss: 0.08845498412847519
step: 840, loss: 0.10780718177556992
step: 850, loss: 0.025041041895747185
step: 860, loss: 0.010808494873344898
step: 870, loss: 0.011024772189557552
step: 880, loss: 0.12232685089111328
step: 890, loss: 0.019926555454730988
step: 900, loss: 0.06964121013879776
step: 910, loss: 0.06897662580013275
step: 920, loss: 0.040835633873939514
step: 930, loss: 0.056063391268253326
step: 940, loss: 0.08165479451417923
step: 950, loss: 6.570520781679079e-05
step: 960, loss: 0.02165129967033863
step: 970, loss: 0.06323623657226562
step: 980, loss: 0.0021669892594218254
step: 990, loss: 0.04363015666604042
step: 1000, loss: 0.040281228721141815
step: 1010, loss: 0.04470393806695938
step: 1020, loss: 0.04776431992650032
step: 1030, loss: 0.02727060578763485
step: 1040, loss: 0.0019718194380402565
step: 1050, loss: 0.11093150824308395
step: 1060, loss: 0.0678815022110939
step: 1070, loss: 0.04593101516366005
epoch 11: dev_f1=0.9353049907578558, f1=0.9308755760368663, best_f1=0.9360919540229884
step: 0, loss: 0.04587060958147049
step: 10, loss: 0.007169907446950674
step: 20, loss: 0.05763626843690872
step: 30, loss: 0.049185898154973984
step: 40, loss: 0.021000098437070847
step: 50, loss: 0.01523938961327076
step: 60, loss: 0.004857382737100124
step: 70, loss: 0.0172162763774395
step: 80, loss: 0.029915332794189453
step: 90, loss: 0.00291162496432662
step: 100, loss: 0.00712291756644845
step: 110, loss: 0.04859121888875961
step: 120, loss: 0.07134836912155151
step: 130, loss: 0.04920226335525513
step: 140, loss: 0.03811538591980934
step: 150, loss: 0.010460478253662586
step: 160, loss: 0.01337502896785736
step: 170, loss: 0.06902412325143814
step: 180, loss: 0.028644606471061707
step: 190, loss: 0.005151442717760801
step: 200, loss: 0.05571594461798668
step: 210, loss: 0.016546480357646942
step: 220, loss: 0.06649335473775864
step: 230, loss: 0.05973830074071884
step: 240, loss: 0.023787029087543488
step: 250, loss: 0.016241813078522682
step: 260, loss: 0.003850863315165043
step: 270, loss: 0.03223629295825958
step: 280, loss: 0.05108706280589104
step: 290, loss: 0.09301093220710754
step: 300, loss: 0.039134301245212555
step: 310, loss: 0.014245577156543732
step: 320, loss: 0.0532880462706089
step: 330, loss: 0.016007764264941216
step: 340, loss: 0.06259593367576599
step: 350, loss: 0.09335584938526154
step: 360, loss: 3.60625381290447e-05
step: 370, loss: 0.009746703319251537
step: 380, loss: 0.01631179451942444
step: 390, loss: 0.02272302471101284
step: 400, loss: 0.026531247422099113
step: 410, loss: 0.028948558494448662
step: 420, loss: 0.06249646842479706
step: 430, loss: 0.0493105910718441
step: 440, loss: 0.03695327416062355
step: 450, loss: 0.08571992069482803
step: 460, loss: 0.044615332037210464
step: 470, loss: 0.027982337400317192
step: 480, loss: 0.014615078456699848
step: 490, loss: 0.0487179160118103
step: 500, loss: 0.00899668037891388
step: 510, loss: 0.017925119027495384
step: 520, loss: 0.055868037045001984
step: 530, loss: 0.014071177691221237
step: 540, loss: 0.00044553857878781855
step: 550, loss: 0.04334133863449097
step: 560, loss: 0.006172815337777138
step: 570, loss: 0.012073992751538754
step: 580, loss: 0.03763285651803017
step: 590, loss: 0.0002479793329257518
step: 600, loss: 0.016862718388438225
step: 610, loss: 0.005219367798417807
step: 620, loss: 0.014683203771710396
step: 630, loss: 0.1163061335682869
step: 640, loss: 0.0455237478017807
step: 650, loss: 0.04396462067961693
step: 660, loss: 0.021933535113930702
step: 670, loss: 0.08888106048107147
step: 680, loss: 0.02556103840470314
step: 690, loss: 0.09037931263446808
step: 700, loss: 0.012082234025001526
step: 710, loss: 0.08038856089115143
step: 720, loss: 0.0012848068727180362
step: 730, loss: 0.020380329340696335
step: 740, loss: 0.06984137743711472
step: 750, loss: 0.17428706586360931
step: 760, loss: 0.024812588468194008
step: 770, loss: 0.17802384495735168
step: 780, loss: 0.007107563316822052
step: 790, loss: 0.007979804649949074
step: 800, loss: 0.0075299968011677265
step: 810, loss: 0.1934073567390442
step: 820, loss: 2.052183663181495e-05
step: 830, loss: 0.045620452612638474
step: 840, loss: 0.0015391167253255844
step: 850, loss: 0.00883172731846571
step: 860, loss: 0.06284085661172867
step: 870, loss: 0.037773311138153076
step: 880, loss: 0.04881766065955162
step: 890, loss: 0.010728560388088226
step: 900, loss: 0.10167830437421799
step: 910, loss: 0.04541439190506935
step: 920, loss: 0.10721703618764877
step: 930, loss: 0.05218696966767311
step: 940, loss: 0.050106797367334366
step: 950, loss: 0.0070892684161663055
step: 960, loss: 0.031362660229206085
step: 970, loss: 0.04289710521697998
step: 980, loss: 0.03709791973233223
step: 990, loss: 0.022519689053297043
step: 1000, loss: 0.0450686514377594
step: 1010, loss: 0.0037275671493262053
step: 1020, loss: 0.08624085038900375
step: 1030, loss: 0.0022968158591538668
step: 1040, loss: 5.8644389355322346e-05
step: 1050, loss: 0.16960275173187256
step: 1060, loss: 0.05989912897348404
step: 1070, loss: 0.020916560664772987
epoch 12: dev_f1=0.9321016166281756, f1=0.9314179796107508, best_f1=0.9360919540229884
step: 0, loss: 0.07087019830942154
step: 10, loss: 0.015751175582408905
step: 20, loss: 0.010447309352457523
step: 30, loss: 0.01741848886013031
step: 40, loss: 0.12231633067131042
step: 50, loss: 0.026043038815259933
step: 60, loss: 0.10114537924528122
step: 70, loss: 0.06049405038356781
step: 80, loss: 0.050395719707012177
step: 90, loss: 0.08411822468042374
step: 100, loss: 0.01089084055274725
step: 110, loss: 0.00016279199917335063
step: 120, loss: 0.05801470950245857
step: 130, loss: 0.045553114265203476
step: 140, loss: 0.05937260761857033
step: 150, loss: 0.037960946559906006
step: 160, loss: 0.03937803581357002
step: 170, loss: 0.03500405699014664
step: 180, loss: 0.0016006751684471965
step: 190, loss: 0.024282699450850487
step: 200, loss: 0.054614678025245667
step: 210, loss: 0.07719185203313828
step: 220, loss: 0.009632489643990993
step: 230, loss: 0.02760813571512699
step: 240, loss: 0.0008816677727736533
step: 250, loss: 0.03530008718371391
step: 260, loss: 0.01968546211719513
step: 270, loss: 6.882358866278082e-05
step: 280, loss: 0.06596978008747101
step: 290, loss: 0.03326926752924919
step: 300, loss: 0.007727043703198433
step: 310, loss: 0.05295928940176964
step: 320, loss: 0.02931801974773407
step: 330, loss: 0.02997903898358345
step: 340, loss: 0.052719295024871826
step: 350, loss: 0.05333679914474487
step: 360, loss: 0.0008811095030978322
step: 370, loss: 0.06246207654476166
step: 380, loss: 0.11065316200256348
step: 390, loss: 0.04794439673423767
step: 400, loss: 0.014082444831728935
step: 410, loss: 0.009517373517155647
step: 420, loss: 0.016420191153883934
step: 430, loss: 0.03521245718002319
step: 440, loss: 0.05674855038523674
step: 450, loss: 5.9868947573704645e-05
step: 460, loss: 0.03922434151172638
step: 470, loss: 0.037345390766859055
step: 480, loss: 0.026948781684041023
step: 490, loss: 0.09015088528394699
step: 500, loss: 2.3993237846298143e-05
step: 510, loss: 0.06597840785980225
step: 520, loss: 0.013710612431168556
step: 530, loss: 0.0117436982691288
step: 540, loss: 0.08150005340576172
step: 550, loss: 0.042992085218429565
step: 560, loss: 0.0716961920261383
step: 570, loss: 0.03406314179301262
step: 580, loss: 0.051569513976573944
step: 590, loss: 0.039499688893556595
step: 600, loss: 0.02525857649743557
step: 610, loss: 0.008130740374326706
step: 620, loss: 0.07458453625440598
step: 630, loss: 0.03741355612874031
step: 640, loss: 0.025874299928545952
step: 650, loss: 0.0026525838766247034
step: 660, loss: 0.059468358755111694
step: 670, loss: 0.036526355892419815
step: 680, loss: 0.03276437893509865
step: 690, loss: 0.03500400856137276
step: 700, loss: 0.017840592190623283
step: 710, loss: 0.003895045956596732
step: 720, loss: 0.0387883223593235
step: 730, loss: 0.0272145364433527
step: 740, loss: 0.02255571447312832
step: 750, loss: 0.17413096129894257
step: 760, loss: 0.02765848860144615
step: 770, loss: 0.14423075318336487
step: 780, loss: 0.004167118109762669
step: 790, loss: 0.005641797091811895
step: 800, loss: 0.03473541513085365
step: 810, loss: 0.07215390354394913
step: 820, loss: 0.06159751117229462
step: 830, loss: 0.010697717778384686
step: 840, loss: 0.04868690297007561
step: 850, loss: 0.031418342143297195
step: 860, loss: 0.04619444161653519
step: 870, loss: 0.03284091129899025
step: 880, loss: 0.030378343537449837
step: 890, loss: 0.03752186894416809
step: 900, loss: 0.031003352254629135
step: 910, loss: 0.054056692868471146
step: 920, loss: 0.04245628044009209
step: 930, loss: 0.02550405077636242
step: 940, loss: 0.005985412746667862
step: 950, loss: 9.142485214397311e-05
step: 960, loss: 0.04611113667488098
step: 970, loss: 0.02648572437465191
step: 980, loss: 0.0038626359310001135
step: 990, loss: 0.0008373910095542669
step: 1000, loss: 0.04650811478495598
step: 1010, loss: 0.04301504045724869
step: 1020, loss: 0.055799148976802826
step: 1030, loss: 0.04544650390744209
step: 1040, loss: 0.0009611587738618255
step: 1050, loss: 0.020144023001194
step: 1060, loss: 0.004497833084315062
step: 1070, loss: 0.024510519579052925
epoch 13: dev_f1=0.9344490934449092, f1=0.9348729792147806, best_f1=0.9360919540229884
step: 0, loss: 0.004059156868606806
step: 10, loss: 0.041160061955451965
step: 20, loss: 0.02799960784614086
step: 30, loss: 0.04062328860163689
step: 40, loss: 0.003102538175880909
step: 50, loss: 0.013809943571686745
step: 60, loss: 0.0021786829456686974
step: 70, loss: 0.03032306395471096
step: 80, loss: 0.0030781819950789213
step: 90, loss: 0.004932721611112356
step: 100, loss: 0.06893843412399292
step: 110, loss: 0.029933834448456764
step: 120, loss: 0.009278631769120693
step: 130, loss: 0.07973836362361908
step: 140, loss: 0.04116596281528473
step: 150, loss: 0.02032977156341076
step: 160, loss: 0.002404066501185298
step: 170, loss: 0.021826449781656265
step: 180, loss: 6.300435052253306e-05
step: 190, loss: 0.046997807919979095
step: 200, loss: 0.04474470391869545
step: 210, loss: 0.06883137673139572
step: 220, loss: 0.0011044584680348635
step: 230, loss: 0.0018034718232229352
step: 240, loss: 0.00015173364954534918
step: 250, loss: 0.004524270072579384
step: 260, loss: 0.0005148103809915483
step: 270, loss: 0.08276981860399246
step: 280, loss: 0.0299074649810791
step: 290, loss: 0.04123581200838089
step: 300, loss: 1.415959013684187e-05
step: 310, loss: 0.08672221004962921
step: 320, loss: 0.0038417417090386152
step: 330, loss: 0.04469172656536102
step: 340, loss: 0.010932240635156631
step: 350, loss: 0.03692775219678879
step: 360, loss: 0.026140479370951653
step: 370, loss: 0.022236155346035957
step: 380, loss: 0.02026424929499626
step: 390, loss: 0.0013289442285895348
step: 400, loss: 0.020004522055387497
step: 410, loss: 0.07638061046600342
step: 420, loss: 0.04241890460252762
step: 430, loss: 0.02684168890118599
step: 440, loss: 0.0012530256062746048
step: 450, loss: 0.006885719485580921
step: 460, loss: 0.06055380776524544
step: 470, loss: 0.0018660725327208638
step: 480, loss: 0.027542689815163612
step: 490, loss: 0.036512862890958786
step: 500, loss: 0.006554164458066225
step: 510, loss: 0.012517265975475311
step: 520, loss: 0.02720612660050392
step: 530, loss: 0.01876484975218773
step: 540, loss: 0.08455207943916321
step: 550, loss: 0.07120093703269958
step: 560, loss: 0.0031633577309548855
step: 570, loss: 0.04444325342774391
step: 580, loss: 0.10334421694278717
step: 590, loss: 0.10787142813205719
step: 600, loss: 0.04744517430663109
step: 610, loss: 0.019012821838259697
step: 620, loss: 0.020190171897411346
step: 630, loss: 0.03378065302968025
step: 640, loss: 0.0004603250417858362
step: 650, loss: 0.007868261076509953
step: 660, loss: 0.009045970626175404
step: 670, loss: 0.00329328840598464
step: 680, loss: 0.05970844253897667
step: 690, loss: 0.00583950150758028
step: 700, loss: 0.057370271533727646
step: 710, loss: 0.018931705504655838
step: 720, loss: 0.007768283132463694
step: 730, loss: 0.04178828373551369
step: 740, loss: 0.006826218217611313
step: 750, loss: 0.04569156467914581
step: 760, loss: 0.05675883963704109
step: 770, loss: 0.0005736993043683469
step: 780, loss: 0.03675978258252144
step: 790, loss: 2.0033838154631667e-05
step: 800, loss: 0.0027800779789686203
step: 810, loss: 0.09442377090454102
step: 820, loss: 0.0007320664590224624
step: 830, loss: 0.010455623269081116
step: 840, loss: 0.04048237204551697
step: 850, loss: 0.009422434493899345
step: 860, loss: 0.11740702390670776
step: 870, loss: 0.021860815584659576
step: 880, loss: 0.03503076732158661
step: 890, loss: 1.4293719686975237e-05
step: 900, loss: 0.04137672856450081
step: 910, loss: 0.12345656007528305
step: 920, loss: 0.00012964998313691467
step: 930, loss: 0.025507479906082153
step: 940, loss: 0.026268040761351585
step: 950, loss: 0.017596455290913582
step: 960, loss: 0.08462841063737869
step: 970, loss: 0.053710199892520905
step: 980, loss: 2.4394576030317694e-05
step: 990, loss: 0.021563054993748665
step: 1000, loss: 0.02120368368923664
step: 1010, loss: 0.029585644602775574
step: 1020, loss: 0.040790919214487076
step: 1030, loss: 0.028286956250667572
step: 1040, loss: 0.11988583952188492
step: 1050, loss: 0.10957439243793488
step: 1060, loss: 0.021889518946409225
step: 1070, loss: 0.015757350251078606
epoch 14: dev_f1=0.9247211895910781, f1=0.9282428702851886, best_f1=0.9360919540229884
step: 0, loss: 0.005023127421736717
step: 10, loss: 0.03719945624470711
step: 20, loss: 0.02442147396504879
step: 30, loss: 0.07441144436597824
step: 40, loss: 0.010276025161147118
step: 50, loss: 0.02409595251083374
step: 60, loss: 0.02526017837226391
step: 70, loss: 0.06900806725025177
step: 80, loss: 0.09744153916835785
step: 90, loss: 0.09954892843961716
step: 100, loss: 0.015560577623546124
step: 110, loss: 0.09956717491149902
step: 120, loss: 0.0726008266210556
step: 130, loss: 0.010706128552556038
step: 140, loss: 0.004476950503885746
step: 150, loss: 0.019616279751062393
step: 160, loss: 0.015311064198613167
step: 170, loss: 0.043617475777864456
step: 180, loss: 2.5675542929093353e-05
step: 190, loss: 0.00781373679637909
step: 200, loss: 0.0185684934258461
step: 210, loss: 0.0001140566382673569
step: 220, loss: 0.011037117801606655
step: 230, loss: 0.07207749038934708
step: 240, loss: 0.04476664587855339
step: 250, loss: 0.03747604787349701
step: 260, loss: 0.0009053079993464053
step: 270, loss: 0.060934051871299744
step: 280, loss: 0.024693287909030914
step: 290, loss: 0.017877517268061638
step: 300, loss: 0.03816213458776474
step: 310, loss: 0.05517037212848663
step: 320, loss: 0.027424795553088188
step: 330, loss: 0.09216559678316116
step: 340, loss: 0.027080034837126732
step: 350, loss: 0.013151716440916061
step: 360, loss: 0.1224793940782547
step: 370, loss: 0.00011837250349344686
step: 380, loss: 0.02080591581761837
step: 390, loss: 0.13695202767848969
step: 400, loss: 0.04873179644346237
step: 410, loss: 0.07280609011650085
step: 420, loss: 0.023872464895248413
step: 430, loss: 0.027701083570718765
step: 440, loss: 0.024063583463430405
step: 450, loss: 0.030219843611121178
step: 460, loss: 0.0053385114297270775
step: 470, loss: 0.022906063124537468
step: 480, loss: 0.017820609733462334
step: 490, loss: 0.001096810563467443
step: 500, loss: 0.12979908287525177
step: 510, loss: 0.05125636234879494
step: 520, loss: 0.038684822618961334
step: 530, loss: 0.02947312407195568
step: 540, loss: 0.05196976661682129
step: 550, loss: 0.001661802758462727
step: 560, loss: 0.04217461869120598
step: 570, loss: 0.00014704470231663436
step: 580, loss: 0.07234781980514526
step: 590, loss: 0.0992245152592659
step: 600, loss: 0.01100226305425167
step: 610, loss: 0.02623140998184681
step: 620, loss: 0.02644316665828228
step: 630, loss: 0.017755571752786636
step: 640, loss: 0.04309496656060219
step: 650, loss: 0.06396292895078659
step: 660, loss: 0.03634214773774147
step: 670, loss: 0.00017268651572521776
step: 680, loss: 0.048367638140916824
step: 690, loss: 0.0923929363489151
step: 700, loss: 0.051490843296051025
step: 710, loss: 0.06644325703382492
step: 720, loss: 0.004308142699301243
step: 730, loss: 0.02112116664648056
step: 740, loss: 0.1828039288520813
step: 750, loss: 8.95518169272691e-05
step: 760, loss: 0.0278623104095459
step: 770, loss: 0.017832856625318527
step: 780, loss: 0.09865156561136246
step: 790, loss: 0.0222947858273983
step: 800, loss: 0.024028154090046883
step: 810, loss: 0.08224055916070938
step: 820, loss: 0.023395603522658348
step: 830, loss: 2.6649000574252568e-05
step: 840, loss: 0.024761268869042397
step: 850, loss: 0.007135493215173483
step: 860, loss: 0.01762981526553631
step: 870, loss: 0.04265746474266052
step: 880, loss: 0.02109650708734989
step: 890, loss: 0.015798475593328476
step: 900, loss: 0.06051347032189369
step: 910, loss: 3.8176316593308e-05
step: 920, loss: 0.05886692926287651
step: 930, loss: 0.030885498970746994
step: 940, loss: 0.017631448805332184
step: 950, loss: 0.026619406417012215
step: 960, loss: 0.03317936882376671
step: 970, loss: 0.001177286496385932
step: 980, loss: 0.07459067553281784
step: 990, loss: 0.0014467829605564475
step: 1000, loss: 0.018828576430678368
step: 1010, loss: 0.071982242166996
step: 1020, loss: 0.013961773365736008
step: 1030, loss: 0.0423470214009285
step: 1040, loss: 0.03847794607281685
step: 1050, loss: 0.05853058397769928
step: 1060, loss: 0.03199039399623871
step: 1070, loss: 0.07639386504888535
epoch 15: dev_f1=0.9337068160597572, f1=0.9325267566309912, best_f1=0.9360919540229884
step: 0, loss: 0.013090389780700207
step: 10, loss: 0.0007669805781915784
step: 20, loss: 0.06220640614628792
step: 30, loss: 0.045808516442775726
step: 40, loss: 0.014819487929344177
step: 50, loss: 0.0006035667029209435
step: 60, loss: 0.02482752688229084
step: 70, loss: 0.04522307217121124
step: 80, loss: 0.03586897253990173
step: 90, loss: 0.03764897584915161
step: 100, loss: 0.00032675653346814215
step: 110, loss: 0.014525391161441803
step: 120, loss: 0.04117297753691673
step: 130, loss: 0.007142205722630024
step: 140, loss: 0.0727347657084465
step: 150, loss: 2.830203084158711e-05
step: 160, loss: 0.017826754599809647
step: 170, loss: 0.0007975508342497051
step: 180, loss: 0.05797501280903816
step: 190, loss: 0.036361366510391235
step: 200, loss: 0.059824056923389435
step: 210, loss: 0.1656721532344818
step: 220, loss: 0.07045008987188339
step: 230, loss: 0.03751206398010254
step: 240, loss: 0.06304556131362915
step: 250, loss: 0.0001723207242321223
step: 260, loss: 0.03480346500873566
step: 270, loss: 0.0011781556531786919
step: 280, loss: 0.023634962737560272
step: 290, loss: 4.0718354284763336e-05
step: 300, loss: 0.015438880771398544
step: 310, loss: 5.7668774388730526e-05
step: 320, loss: 6.16175530012697e-05
step: 330, loss: 0.06354191899299622
step: 340, loss: 0.08505396544933319
step: 350, loss: 0.08049587905406952
step: 360, loss: 0.0009104701457545161
step: 370, loss: 0.0001328726066276431
step: 380, loss: 0.04711765795946121
step: 390, loss: 6.208802369656041e-05
step: 400, loss: 0.05471699684858322
step: 410, loss: 0.0001221816783072427
step: 420, loss: 0.05735941603779793
step: 430, loss: 0.045749977231025696
step: 440, loss: 0.004287420306354761
step: 450, loss: 0.028810573741793633
step: 460, loss: 0.17685389518737793
step: 470, loss: 0.001040874165482819
step: 480, loss: 0.035452950745821
step: 490, loss: 0.02449905127286911
step: 500, loss: 0.03579050302505493
step: 510, loss: 0.021665051579475403
step: 520, loss: 0.1366819143295288
step: 530, loss: 0.03998277336359024
step: 540, loss: 0.026282912120223045
step: 550, loss: 0.01327283214777708
step: 560, loss: 0.04077862948179245
step: 570, loss: 0.07262840121984482
step: 580, loss: 3.050995474040974e-05
step: 590, loss: 0.05085473135113716
step: 600, loss: 6.260511872824281e-05
step: 610, loss: 0.018490759655833244
step: 620, loss: 0.0214301198720932
step: 630, loss: 0.04060547798871994
step: 640, loss: 0.02364279143512249
step: 650, loss: 0.002785158809274435
step: 660, loss: 0.022004384547472
step: 670, loss: 0.021015867590904236
step: 680, loss: 0.05115371569991112
step: 690, loss: 0.13793595135211945
step: 700, loss: 4.162061304668896e-05
step: 710, loss: 0.0850573256611824
step: 720, loss: 0.004340024199336767
step: 730, loss: 0.0706770271062851
step: 740, loss: 0.024553658440709114
step: 750, loss: 0.04966007545590401
step: 760, loss: 0.007648784667253494
step: 770, loss: 0.0013354193652048707
step: 780, loss: 0.00010212430061073974
step: 790, loss: 0.0346539169549942
step: 800, loss: 3.044040931854397e-05
step: 810, loss: 0.009935149922966957
step: 820, loss: 0.00031155211036093533
step: 830, loss: 0.037622880190610886
step: 840, loss: 0.01712028868496418
step: 850, loss: 0.001605069963261485
step: 860, loss: 0.03936218470335007
step: 870, loss: 0.04822898283600807
step: 880, loss: 0.06388679146766663
step: 890, loss: 0.04601377248764038
step: 900, loss: 0.003094467567279935
step: 910, loss: 0.020312661305069923
step: 920, loss: 0.024459434673190117
step: 930, loss: 0.0652979388833046
step: 940, loss: 0.042144354432821274
step: 950, loss: 0.03972091153264046
step: 960, loss: 0.034539900720119476
step: 970, loss: 0.022761045023798943
step: 980, loss: 0.0006353365606628358
step: 990, loss: 2.7689702619682066e-05
step: 1000, loss: 0.009930109605193138
step: 1010, loss: 2.8361617296468467e-05
step: 1020, loss: 0.0002788132696878165
step: 1030, loss: 0.02724538743495941
step: 1040, loss: 0.038762107491493225
step: 1050, loss: 0.0036887486930936575
step: 1060, loss: 0.025087643414735794
step: 1070, loss: 0.06776763498783112
epoch 16: dev_f1=0.9292929292929294, f1=0.9304229195088677, best_f1=0.9360919540229884
step: 0, loss: 0.0029644814785569906
step: 10, loss: 0.02750200405716896
step: 20, loss: 0.03004670888185501
step: 30, loss: 0.0002854369522538036
step: 40, loss: 2.0488449081312865e-05
step: 50, loss: 0.02855575457215309
step: 60, loss: 0.030939051881432533
step: 70, loss: 0.03292326256632805
step: 80, loss: 0.011406869627535343
step: 90, loss: 0.009394719265401363
step: 100, loss: 0.03326896205544472
step: 110, loss: 0.005875251721590757
step: 120, loss: 0.03609049692749977
step: 130, loss: 8.978110417956486e-05
step: 140, loss: 8.45001995912753e-05
step: 150, loss: 0.03439253941178322
step: 160, loss: 0.037134185433387756
step: 170, loss: 0.015171103179454803
step: 180, loss: 0.03752761334180832
step: 190, loss: 0.0015535682905465364
step: 200, loss: 0.003878291929140687
step: 210, loss: 5.6628399761393666e-05
step: 220, loss: 4.075281322002411e-05
step: 230, loss: 0.031107954680919647
step: 240, loss: 0.02173050306737423
step: 250, loss: 0.06296683102846146
step: 260, loss: 0.029586752876639366
step: 270, loss: 0.0015045094769448042
step: 280, loss: 0.03788915276527405
step: 290, loss: 0.03358116000890732
step: 300, loss: 0.017021680250763893
step: 310, loss: 0.020787104964256287
step: 320, loss: 0.002265507122501731
step: 330, loss: 0.038885265588760376
step: 340, loss: 0.022141458466649055
step: 350, loss: 0.0005243596388027072
step: 360, loss: 8.903766865842044e-05
step: 370, loss: 0.05239618197083473
step: 380, loss: 0.0007718791021034122
step: 390, loss: 0.04120046645402908
step: 400, loss: 1.0285456482961308e-05
step: 410, loss: 2.7393476557335816e-05
step: 420, loss: 0.022993577644228935
step: 430, loss: 0.05145698040723801
step: 440, loss: 0.015270421281456947
step: 450, loss: 0.047867029905319214
step: 460, loss: 1.7821199435275048e-05
step: 470, loss: 0.00762918358668685
step: 480, loss: 0.03874192759394646
step: 490, loss: 0.02524474263191223
step: 500, loss: 0.04490124434232712
step: 510, loss: 0.0015150714898481965
step: 520, loss: 0.03040364198386669
step: 530, loss: 0.036900028586387634
step: 540, loss: 0.026986774057149887
step: 550, loss: 0.0646497830748558
step: 560, loss: 0.04005808383226395
step: 570, loss: 0.022282980382442474
step: 580, loss: 0.041978027671575546
step: 590, loss: 5.568737105932087e-05
step: 600, loss: 0.019610727205872536
step: 610, loss: 6.750500324415043e-05
step: 620, loss: 0.03584933653473854
step: 630, loss: 0.0009514412377029657
step: 640, loss: 0.03239380568265915
step: 650, loss: 0.0747833400964737
step: 660, loss: 0.004341167863458395
step: 670, loss: 0.05216097831726074
step: 680, loss: 0.02798362262547016
step: 690, loss: 0.07268302142620087
step: 700, loss: 0.0006959259044378996
step: 710, loss: 0.12125059217214584
step: 720, loss: 0.00023819431953597814
step: 730, loss: 0.021166523918509483
step: 740, loss: 0.054925985634326935
step: 750, loss: 0.12746642529964447
step: 760, loss: 0.08220624178647995
step: 770, loss: 5.9687015891540796e-05
step: 780, loss: 0.023437269032001495
step: 790, loss: 0.012739471159875393
step: 800, loss: 0.04292358458042145
step: 810, loss: 0.08501867949962616
step: 820, loss: 2.423161276965402e-05
step: 830, loss: 0.049519363790750504
step: 840, loss: 0.023986872285604477
step: 850, loss: 1.3246969501778949e-05
step: 860, loss: 0.020298082381486893
step: 870, loss: 0.0002578331041149795
step: 880, loss: 0.02325129508972168
step: 890, loss: 0.0337628610432148
step: 900, loss: 0.022006813436746597
step: 910, loss: 0.00016181655519176275
step: 920, loss: 0.034565191715955734
step: 930, loss: 0.020602449774742126
step: 940, loss: 0.04508235305547714
step: 950, loss: 0.03372704237699509
step: 960, loss: 0.042478810995817184
step: 970, loss: 0.03619598224759102
step: 980, loss: 0.043448980897665024
step: 990, loss: 0.025819340720772743
step: 1000, loss: 0.04804015904664993
step: 1010, loss: 0.023073891177773476
step: 1020, loss: 1.908042759168893e-05
step: 1030, loss: 0.001984375063329935
step: 1040, loss: 0.049297869205474854
step: 1050, loss: 0.04215370863676071
step: 1060, loss: 6.203515658853576e-05
step: 1070, loss: 0.002455072244629264
epoch 17: dev_f1=0.9305555555555556, f1=0.9307657038055936, best_f1=0.9360919540229884
step: 0, loss: 0.049894336611032486
step: 10, loss: 0.03270133584737778
step: 20, loss: 0.0012124726781621575
step: 30, loss: 0.01785762794315815
step: 40, loss: 0.025430552661418915
step: 50, loss: 1.4241583812690806e-05
step: 60, loss: 3.58687830157578e-05
step: 70, loss: 0.021516067907214165
step: 80, loss: 0.001976938918232918
step: 90, loss: 0.03249463438987732
step: 100, loss: 0.05414734035730362
step: 110, loss: 0.0004490103165153414
step: 120, loss: 0.02229587733745575
step: 130, loss: 0.005826062988489866
step: 140, loss: 0.0057151406072080135
step: 150, loss: 0.014371376484632492
step: 160, loss: 0.04143967851996422
step: 170, loss: 0.06074608489871025
step: 180, loss: 0.05965662747621536
step: 190, loss: 0.03125903010368347
step: 200, loss: 1.3507741641660687e-05
step: 210, loss: 0.0018833589274436235
step: 220, loss: 0.0006023343885317445
step: 230, loss: 1.780231650627684e-05
step: 240, loss: 1.2636050996661652e-05
step: 250, loss: 0.018604421988129616
step: 260, loss: 0.05243086814880371
step: 270, loss: 0.0011484388960525393
step: 280, loss: 0.0392504446208477
step: 290, loss: 0.04268115758895874
step: 300, loss: 0.00010568862489890307
step: 310, loss: 0.02429167367517948
step: 320, loss: 0.029485337436199188
step: 330, loss: 0.0005240591708570719
step: 340, loss: 0.008892390877008438
step: 350, loss: 3.667914279503748e-05
step: 360, loss: 0.04825294762849808
step: 370, loss: 0.04010951519012451
step: 380, loss: 0.006868056952953339
step: 390, loss: 0.022991372272372246
step: 400, loss: 0.021228214725852013
step: 410, loss: 0.05364547297358513
step: 420, loss: 0.010907795280218124
step: 430, loss: 0.025899119675159454
step: 440, loss: 0.02845742367208004
step: 450, loss: 1.8494682080927305e-05
step: 460, loss: 0.051849618554115295
step: 470, loss: 0.022798240184783936
step: 480, loss: 0.023099631071090698
step: 490, loss: 0.037559106945991516
step: 500, loss: 6.169436528580263e-05
step: 510, loss: 0.04704878851771355
step: 520, loss: 0.023508572950959206
step: 530, loss: 0.004525956232100725
step: 540, loss: 6.0874172049807385e-05
step: 550, loss: 0.02774687111377716
step: 560, loss: 0.07342654466629028
step: 570, loss: 0.00014392659068107605
step: 580, loss: 0.014407234266400337
step: 590, loss: 0.007334030698984861
step: 600, loss: 0.021184135228395462
step: 610, loss: 0.02495044656097889
step: 620, loss: 0.019888781011104584
step: 630, loss: 0.03877924382686615
step: 640, loss: 3.398994158487767e-05
step: 650, loss: 0.02145111933350563
step: 660, loss: 0.00897612888365984
step: 670, loss: 0.018156515434384346
step: 680, loss: 0.020818976685404778
step: 690, loss: 5.197132850298658e-05
step: 700, loss: 0.044641513377428055
step: 710, loss: 0.22915491461753845
step: 720, loss: 0.0415043979883194
step: 730, loss: 0.031027227640151978
step: 740, loss: 0.05062418058514595
step: 750, loss: 0.036894749850034714
step: 760, loss: 0.00010136640048585832
step: 770, loss: 0.03993292152881622
step: 780, loss: 0.03169078379869461
step: 790, loss: 0.02861800417304039
step: 800, loss: 0.01806800253689289
step: 810, loss: 0.0620182529091835
step: 820, loss: 4.031386197311804e-05
step: 830, loss: 0.016630226746201515
step: 840, loss: 6.517377914860845e-05
step: 850, loss: 0.02713502198457718
step: 860, loss: 0.036526862531900406
step: 870, loss: 0.0188048854470253
step: 880, loss: 0.050137970596551895
step: 890, loss: 0.0009275007178075612
step: 900, loss: 2.0774974473170005e-05
step: 910, loss: 0.00010826962534338236
step: 920, loss: 0.02332792617380619
step: 930, loss: 2.5202496544807218e-05
step: 940, loss: 0.0006719867815263569
step: 950, loss: 0.04583922401070595
step: 960, loss: 1.4032817489351146e-05
step: 970, loss: 2.878286613849923e-05
step: 980, loss: 0.019303418695926666
step: 990, loss: 0.03791121765971184
step: 1000, loss: 2.093086004606448e-05
step: 1010, loss: 0.00010060987551696599
step: 1020, loss: 8.72667005751282e-05
step: 1030, loss: 0.11158837378025055
step: 1040, loss: 0.05298193544149399
step: 1050, loss: 0.08184020966291428
step: 1060, loss: 0.00012421468272805214
step: 1070, loss: 0.048570696264505386
epoch 18: dev_f1=0.9289363678588016, f1=0.9294605809128631, best_f1=0.9360919540229884
step: 0, loss: 0.032334912568330765
step: 10, loss: 0.04876098781824112
step: 20, loss: 0.05949801579117775
step: 30, loss: 0.025439428165555
step: 40, loss: 0.03187214955687523
step: 50, loss: 1.770583367033396e-05
step: 60, loss: 0.00018663267837837338
step: 70, loss: 0.024435080587863922
step: 80, loss: 0.008303305134177208
step: 90, loss: 0.021224237978458405
step: 100, loss: 1.063189029082423e-05
step: 110, loss: 0.00843818485736847
step: 120, loss: 0.018485035747289658
step: 130, loss: 0.039794258773326874
step: 140, loss: 1.0490348358871415e-05
step: 150, loss: 0.06270601600408554
step: 160, loss: 0.019756892696022987
step: 170, loss: 0.047867707908153534
step: 180, loss: 0.02029113471508026
step: 190, loss: 0.021329112350940704
step: 200, loss: 9.774405043572187e-05
step: 210, loss: 0.029562706127762794
step: 220, loss: 0.027282897382974625
step: 230, loss: 1.3977060916658957e-05
step: 240, loss: 0.0412437841296196
step: 250, loss: 9.22748222365044e-06
step: 260, loss: 0.041441090404987335
step: 270, loss: 0.0058361683040857315
step: 280, loss: 2.129977656295523e-05
step: 290, loss: 0.021458681672811508
step: 300, loss: 0.04138708487153053
step: 310, loss: 0.07294156402349472
step: 320, loss: 7.650036423001438e-05
step: 330, loss: 0.014305601827800274
step: 340, loss: 0.08372985571622849
step: 350, loss: 0.026596440002322197
step: 360, loss: 0.027937956154346466
step: 370, loss: 0.03315623849630356
step: 380, loss: 3.0451075872406363e-05
step: 390, loss: 0.0516214556992054
step: 400, loss: 0.028436753898859024
step: 410, loss: 0.0662413090467453
step: 420, loss: 3.5713863326236606e-05
step: 430, loss: 0.03030821494758129
step: 440, loss: 3.5940953239332885e-05
step: 450, loss: 0.03474961593747139
step: 460, loss: 0.0006747583975084126
step: 470, loss: 0.029075875878334045
step: 480, loss: 0.008183382451534271
step: 490, loss: 1.3056946954748128e-05
step: 500, loss: 0.008202988654375076
step: 510, loss: 0.01798289828002453
step: 520, loss: 0.0289328470826149
step: 530, loss: 0.0008076984668150544
step: 540, loss: 0.013608500361442566
step: 550, loss: 0.06715410947799683
step: 560, loss: 2.2368025383912027e-05
step: 570, loss: 0.08774055540561676
step: 580, loss: 0.010712691582739353
step: 590, loss: 0.010812243446707726
step: 600, loss: 0.0372253842651844
step: 610, loss: 0.09744883328676224
step: 620, loss: 0.02094375342130661
step: 630, loss: 0.01616581529378891
step: 640, loss: 0.00031575298635289073
step: 650, loss: 0.040584463626146317
step: 660, loss: 0.0002897540689446032
step: 670, loss: 1.0948489034490194e-05
step: 680, loss: 1.3906262211094145e-05
step: 690, loss: 0.0519971027970314
step: 700, loss: 0.058179378509521484
step: 710, loss: 1.231934038514737e-05
step: 720, loss: 0.013251595199108124
step: 730, loss: 0.0183271374553442
step: 740, loss: 0.030940867960453033
step: 750, loss: 0.06953572481870651
step: 760, loss: 0.027981478720903397
step: 770, loss: 0.027443047612905502
step: 780, loss: 0.020180847495794296
step: 790, loss: 0.04963018000125885
step: 800, loss: 0.044234514236450195
step: 810, loss: 0.009195988066494465
step: 820, loss: 0.03524809703230858
step: 830, loss: 0.058931007981300354
step: 840, loss: 9.403537114849314e-05
step: 850, loss: 0.0006179124466143548
step: 860, loss: 0.00019491941202431917
step: 870, loss: 0.027821889147162437
step: 880, loss: 2.1963433027849533e-05
step: 890, loss: 0.05034653842449188
step: 900, loss: 0.008566038683056831
step: 910, loss: 0.0033862097188830376
step: 920, loss: 0.16796286404132843
step: 930, loss: 4.042478758492507e-05
step: 940, loss: 0.057929735630750656
step: 950, loss: 0.07325724512338638
step: 960, loss: 4.33040113421157e-05
step: 970, loss: 0.00716544222086668
step: 980, loss: 0.017966823652386665
step: 990, loss: 0.018884260207414627
step: 1000, loss: 0.057113371789455414
step: 1010, loss: 0.02769658900797367
step: 1020, loss: 0.02226988971233368
step: 1030, loss: 0.015719661489129066
step: 1040, loss: 1.866658749349881e-05
step: 1050, loss: 0.0004200818366371095
step: 1060, loss: 0.03070967085659504
step: 1070, loss: 0.01976025104522705
epoch 19: dev_f1=0.9285714285714285, f1=0.9317972350230416, best_f1=0.9360919540229884
step: 0, loss: 0.022304655984044075
step: 10, loss: 0.03325383737683296
step: 20, loss: 0.01989215426146984
step: 30, loss: 0.03863232955336571
step: 40, loss: 0.05583639442920685
step: 50, loss: 4.6135955926729366e-05
step: 60, loss: 1.5746511053293943e-05
step: 70, loss: 0.02088073454797268
step: 80, loss: 7.51362822484225e-05
step: 90, loss: 0.01613352820277214
step: 100, loss: 0.0002217648143414408
step: 110, loss: 0.019803091883659363
step: 120, loss: 0.0669751837849617
step: 130, loss: 0.028086338192224503
step: 140, loss: 1.2062349924235605e-05
step: 150, loss: 5.1466282457113266e-05
step: 160, loss: 0.014828833751380444
step: 170, loss: 1.891646570584271e-05
step: 180, loss: 2.3638674974790774e-05
step: 190, loss: 0.03300011530518532
step: 200, loss: 2.235356078017503e-05
step: 210, loss: 0.026510540395975113
step: 220, loss: 1.931725455506239e-05
step: 230, loss: 0.0015879175625741482
step: 240, loss: 3.253329487051815e-05
step: 250, loss: 0.02562129870057106
step: 260, loss: 3.652363739092834e-05
step: 270, loss: 0.03609669208526611
step: 280, loss: 0.0031682660337537527
step: 290, loss: 0.03500349819660187
step: 300, loss: 9.760196007846389e-06
step: 310, loss: 0.11990203708410263
step: 320, loss: 0.04932667687535286
step: 330, loss: 1.713164419925306e-05
step: 340, loss: 0.02643435262143612
step: 350, loss: 0.033618248999118805
step: 360, loss: 0.021328356117010117
step: 370, loss: 0.05573732778429985
step: 380, loss: 0.0003836489631794393
step: 390, loss: 0.00034611698356457055
step: 400, loss: 0.0005801439401693642
step: 410, loss: 0.033921610563993454
step: 420, loss: 0.01105340477079153
step: 430, loss: 0.024699227884411812
step: 440, loss: 0.042419735342264175
step: 450, loss: 1.9705914382939227e-05
step: 460, loss: 0.06412576884031296
step: 470, loss: 0.02951018512248993
step: 480, loss: 4.266995165380649e-05
step: 490, loss: 0.020766958594322205
step: 500, loss: 3.0435692679020576e-05
step: 510, loss: 0.06627664715051651
step: 520, loss: 0.0012182928621768951
step: 530, loss: 0.0251340139657259
step: 540, loss: 0.04569172114133835
step: 550, loss: 0.028246205300092697
step: 560, loss: 1.3984446923132055e-05
step: 570, loss: 0.0224296934902668
step: 580, loss: 0.02012006752192974
step: 590, loss: 0.04161791875958443
step: 600, loss: 0.051940642297267914
step: 610, loss: 3.279518932686187e-05
step: 620, loss: 0.036599721759557724
step: 630, loss: 0.01737236976623535
step: 640, loss: 2.2652911866316572e-05
step: 650, loss: 0.02021266147494316
step: 660, loss: 0.04293620213866234
step: 670, loss: 0.026343148201704025
step: 680, loss: 1.8521717720432207e-05
step: 690, loss: 0.02376277558505535
step: 700, loss: 3.109344470431097e-05
step: 710, loss: 1.782880826795008e-05
step: 720, loss: 2.5472247216384858e-05
step: 730, loss: 2.3520065951743163e-05
step: 740, loss: 0.02271907776594162
step: 750, loss: 6.829997437307611e-05
step: 760, loss: 3.5196891985833645e-05
step: 770, loss: 0.022589148953557014
step: 780, loss: 7.634527719346806e-05
step: 790, loss: 1.617117777641397e-05
step: 800, loss: 0.026589563116431236
step: 810, loss: 0.026729999110102654
step: 820, loss: 0.0067033590748906136
step: 830, loss: 0.016128547489643097
step: 840, loss: 0.004923027474433184
step: 850, loss: 0.005070132669061422
step: 860, loss: 0.0818280279636383
step: 870, loss: 0.06650789827108383
step: 880, loss: 2.7613194106379524e-05
step: 890, loss: 0.04009239375591278
step: 900, loss: 0.0008843570249155164
step: 910, loss: 2.8466543881222606e-05
step: 920, loss: 0.025888368487358093
step: 930, loss: 0.002177773742005229
step: 940, loss: 0.01836157590150833
step: 950, loss: 9.193957339448389e-06
step: 960, loss: 0.07082439213991165
step: 970, loss: 0.043811097741127014
step: 980, loss: 0.02647613175213337
step: 990, loss: 0.02427770011126995
step: 1000, loss: 0.021231019869446754
step: 1010, loss: 6.913699326105416e-05
step: 1020, loss: 0.04831820726394653
step: 1030, loss: 0.03645068407058716
step: 1040, loss: 0.03725404664874077
step: 1050, loss: 0.06353836506605148
step: 1060, loss: 0.013320351019501686
step: 1070, loss: 3.0637020245194435e-05
epoch 20: dev_f1=0.9263059701492538, f1=0.9292649098474343, best_f1=0.9360919540229884
