cuda
Device: cuda
step: 0, loss: 0.778507649898529
step: 10, loss: 0.36220669746398926
step: 20, loss: 0.29194876551628113
step: 30, loss: 0.29956433176994324
step: 40, loss: 0.3894599378108978
step: 50, loss: 0.3625969886779785
step: 60, loss: 0.2500339150428772
step: 70, loss: 0.2854062020778656
step: 80, loss: 0.22614724934101105
step: 90, loss: 0.299064040184021
step: 100, loss: 0.4195457696914673
step: 110, loss: 0.16555052995681763
step: 120, loss: 0.15979520976543427
step: 130, loss: 0.3046319782733917
step: 140, loss: 0.20505107939243317
step: 150, loss: 0.24684040248394012
step: 160, loss: 0.39099231362342834
step: 170, loss: 0.13685527443885803
step: 180, loss: 0.15469463169574738
step: 190, loss: 0.1588210165500641
step: 200, loss: 0.2869344651699066
step: 210, loss: 0.2517625391483307
step: 220, loss: 0.18546736240386963
step: 230, loss: 0.0789128914475441
step: 240, loss: 0.2999642491340637
step: 250, loss: 0.10546346753835678
step: 260, loss: 0.3339076042175293
step: 270, loss: 0.050099462270736694
step: 280, loss: 0.3487802743911743
step: 290, loss: 0.08333069831132889
step: 300, loss: 0.1425836980342865
step: 310, loss: 0.4123484194278717
step: 320, loss: 0.0719991996884346
step: 330, loss: 0.021641433238983154
step: 340, loss: 0.14844821393489838
step: 350, loss: 0.16255338490009308
step: 360, loss: 0.1502283662557602
step: 370, loss: 0.1677343100309372
step: 380, loss: 0.09968572854995728
step: 390, loss: 0.129168301820755
step: 400, loss: 0.13569839298725128
step: 410, loss: 0.16632768511772156
step: 420, loss: 0.1079246774315834
step: 430, loss: 0.11944802105426788
step: 440, loss: 0.0967828705906868
step: 450, loss: 0.054967015981674194
step: 460, loss: 0.22874408960342407
step: 470, loss: 0.11913567036390305
step: 480, loss: 0.13256694376468658
step: 490, loss: 0.13954508304595947
step: 500, loss: 0.0986422598361969
step: 510, loss: 0.040190842002630234
step: 520, loss: 0.050761789083480835
step: 530, loss: 0.24063079059123993
step: 540, loss: 0.14616955816745758
step: 550, loss: 0.09304920583963394
step: 560, loss: 0.15959134697914124
step: 570, loss: 0.043107107281684875
step: 580, loss: 0.009335792623460293
step: 590, loss: 0.1837817132472992
step: 600, loss: 0.226658433675766
step: 610, loss: 0.23423820734024048
step: 620, loss: 0.134720116853714
step: 630, loss: 0.10509445518255234
step: 640, loss: 0.0861206129193306
step: 650, loss: 0.1114649623632431
step: 660, loss: 0.1201392188668251
step: 670, loss: 0.054724179208278656
step: 680, loss: 0.27532121539115906
step: 690, loss: 0.09249553829431534
step: 700, loss: 0.11771165579557419
step: 710, loss: 0.12333453446626663
step: 720, loss: 0.09632659703493118
step: 730, loss: 0.09265279024839401
step: 740, loss: 0.15252785384655
step: 750, loss: 0.28987106680870056
step: 760, loss: 0.024028867483139038
step: 770, loss: 0.024720538407564163
step: 780, loss: 0.16226695477962494
step: 790, loss: 0.20347900688648224
step: 800, loss: 0.1529209315776825
step: 810, loss: 0.34564918279647827
step: 820, loss: 0.03883381932973862
step: 830, loss: 0.10541602224111557
step: 840, loss: 0.08036574721336365
step: 850, loss: 0.09542924910783768
step: 860, loss: 0.09360155463218689
step: 870, loss: 0.06628076732158661
step: 880, loss: 0.06028503179550171
step: 890, loss: 0.050760604441165924
step: 900, loss: 0.04060573875904083
step: 910, loss: 0.07972800731658936
step: 920, loss: 0.13188673555850983
step: 930, loss: 0.040535297244787216
step: 940, loss: 0.08160519599914551
step: 950, loss: 0.05451676994562149
step: 960, loss: 0.21612992882728577
step: 970, loss: 0.16466814279556274
step: 980, loss: 0.10366079956293106
step: 990, loss: 0.08377579599618912
step: 1000, loss: 0.17406755685806274
step: 1010, loss: 0.20862224698066711
step: 1020, loss: 0.2256656140089035
step: 1030, loss: 0.07048463821411133
step: 1040, loss: 0.24650953710079193
step: 1050, loss: 0.08317553251981735
step: 1060, loss: 0.16648033261299133
step: 1070, loss: 0.024311956018209457
epoch 1: dev_f1=0.9307021569527306, f1=0.9242009132420091, best_f1=0.9242009132420091
step: 0, loss: 0.16853868961334229
step: 10, loss: 0.18566860258579254
step: 20, loss: 0.12682221829891205
step: 30, loss: 0.12713320553302765
step: 40, loss: 0.2259131371974945
step: 50, loss: 0.00871796440333128
step: 60, loss: 0.06491318345069885
step: 70, loss: 0.03100936859846115
step: 80, loss: 0.1959887444972992
step: 90, loss: 0.26654481887817383
step: 100, loss: 0.12177617102861404
step: 110, loss: 0.11223409324884415
step: 120, loss: 0.15707135200500488
step: 130, loss: 0.10601776093244553
step: 140, loss: 0.12657380104064941
step: 150, loss: 0.015975898131728172
step: 160, loss: 0.06224726140499115
step: 170, loss: 0.11214255541563034
step: 180, loss: 0.09794632345438004
step: 190, loss: 0.10207342356443405
step: 200, loss: 0.10384315997362137
step: 210, loss: 0.044990573078393936
step: 220, loss: 0.10618885606527328
step: 230, loss: 0.0919240340590477
step: 240, loss: 0.12759017944335938
step: 250, loss: 0.042884327471256256
step: 260, loss: 0.0721159279346466
step: 270, loss: 0.0661567896604538
step: 280, loss: 0.03129498288035393
step: 290, loss: 0.08456084132194519
step: 300, loss: 0.07389260828495026
step: 310, loss: 0.004437637981027365
step: 320, loss: 0.11485284566879272
step: 330, loss: 0.10046672821044922
step: 340, loss: 0.0178474560379982
step: 350, loss: 0.09835941344499588
step: 360, loss: 0.28630301356315613
step: 370, loss: 0.0497567318379879
step: 380, loss: 0.22763046622276306
step: 390, loss: 0.12184704095125198
step: 400, loss: 0.055757954716682434
step: 410, loss: 0.13963572680950165
step: 420, loss: 0.12377538532018661
step: 430, loss: 0.01978764310479164
step: 440, loss: 0.08924835175275803
step: 450, loss: 0.049632422626018524
step: 460, loss: 0.05897989124059677
step: 470, loss: 0.11078155040740967
step: 480, loss: 0.02880946546792984
step: 490, loss: 0.019536413252353668
step: 500, loss: 0.07315963506698608
step: 510, loss: 0.06929544359445572
step: 520, loss: 0.16304069757461548
step: 530, loss: 0.09504777193069458
step: 540, loss: 0.011269561015069485
step: 550, loss: 0.06411038339138031
step: 560, loss: 0.055786821991205215
step: 570, loss: 0.05925314873456955
step: 580, loss: 0.020216738805174828
step: 590, loss: 0.03917428106069565
step: 600, loss: 0.0982593521475792
step: 610, loss: 0.0524141751229763
step: 620, loss: 0.04601920023560524
step: 630, loss: 0.20476429164409637
step: 640, loss: 0.12133422493934631
step: 650, loss: 0.07748610526323318
step: 660, loss: 0.23814448714256287
step: 670, loss: 0.05205456167459488
step: 680, loss: 0.022220514714717865
step: 690, loss: 0.13396815955638885
step: 700, loss: 0.26839393377304077
step: 710, loss: 0.029402414336800575
step: 720, loss: 0.07936471700668335
step: 730, loss: 0.06689241528511047
step: 740, loss: 0.18203513324260712
step: 750, loss: 0.13113637268543243
step: 760, loss: 0.07251007109880447
step: 770, loss: 0.06184757128357887
step: 780, loss: 0.13732559978961945
step: 790, loss: 0.09847705811262131
step: 800, loss: 0.1035882830619812
step: 810, loss: 0.015576581470668316
step: 820, loss: 0.056270916014909744
step: 830, loss: 0.11669710278511047
step: 840, loss: 0.10773861408233643
step: 850, loss: 0.07941246032714844
step: 860, loss: 0.07178197801113129
step: 870, loss: 0.0647096261382103
step: 880, loss: 0.10130611062049866
step: 890, loss: 0.09238116443157196
step: 900, loss: 0.10069834440946579
step: 910, loss: 0.02138587087392807
step: 920, loss: 0.07131469994783401
step: 930, loss: 0.05552496016025543
step: 940, loss: 0.11805439740419388
step: 950, loss: 0.09976254403591156
step: 960, loss: 0.04414903372526169
step: 970, loss: 0.21265947818756104
step: 980, loss: 0.08740568906068802
step: 990, loss: 0.06103779003024101
step: 1000, loss: 0.07675398141145706
step: 1010, loss: 0.02988535538315773
step: 1020, loss: 0.026918262243270874
step: 1030, loss: 0.2791217565536499
step: 1040, loss: 0.014646782539784908
step: 1050, loss: 0.241999551653862
step: 1060, loss: 0.13005249202251434
step: 1070, loss: 0.06978343427181244
epoch 2: dev_f1=0.9330254041570438, f1=0.9291266575217191, best_f1=0.9291266575217191
step: 0, loss: 0.04593043029308319
step: 10, loss: 0.07706961035728455
step: 20, loss: 0.01513889990746975
step: 30, loss: 0.17461788654327393
step: 40, loss: 0.11269872635602951
step: 50, loss: 0.036869484931230545
step: 60, loss: 0.10401534289121628
step: 70, loss: 0.09214508533477783
step: 80, loss: 0.018402162939310074
step: 90, loss: 0.07669222354888916
step: 100, loss: 0.2253836840391159
step: 110, loss: 0.06265274435281754
step: 120, loss: 0.20603574812412262
step: 130, loss: 0.06338099390268326
step: 140, loss: 0.07441714406013489
step: 150, loss: 0.055837951600551605
step: 160, loss: 0.10271639376878738
step: 170, loss: 0.04359396919608116
step: 180, loss: 0.006282777525484562
step: 190, loss: 0.1103493943810463
step: 200, loss: 0.04776745289564133
step: 210, loss: 0.02290065586566925
step: 220, loss: 0.04887518659234047
step: 230, loss: 0.22223636507987976
step: 240, loss: 0.02321000210940838
step: 250, loss: 0.14073187112808228
step: 260, loss: 0.010263538919389248
step: 270, loss: 0.005258161574602127
step: 280, loss: 0.06698694080114365
step: 290, loss: 0.01656273379921913
step: 300, loss: 0.03215673938393593
step: 310, loss: 0.009967049583792686
step: 320, loss: 0.09757203608751297
step: 330, loss: 0.17577910423278809
step: 340, loss: 0.045103300362825394
step: 350, loss: 0.11927921324968338
step: 360, loss: 0.1136663407087326
step: 370, loss: 0.08261086046695709
step: 380, loss: 0.050106924027204514
step: 390, loss: 0.013438086025416851
step: 400, loss: 0.10892459750175476
step: 410, loss: 0.055967751890420914
step: 420, loss: 0.05377404764294624
step: 430, loss: 0.15226663649082184
step: 440, loss: 0.17597559094429016
step: 450, loss: 0.06795719265937805
step: 460, loss: 0.10244543850421906
step: 470, loss: 0.07353982329368591
step: 480, loss: 0.09211386740207672
step: 490, loss: 0.0945838913321495
step: 500, loss: 0.060580573976039886
step: 510, loss: 0.11792091280221939
step: 520, loss: 0.1015295460820198
step: 530, loss: 0.2072584331035614
step: 540, loss: 0.0347406342625618
step: 550, loss: 0.06636103987693787
step: 560, loss: 0.16749092936515808
step: 570, loss: 0.15442655980587006
step: 580, loss: 0.020590055733919144
step: 590, loss: 0.0806807279586792
step: 600, loss: 0.06422534584999084
step: 610, loss: 0.06680214405059814
step: 620, loss: 0.03577756881713867
step: 630, loss: 0.060061074793338776
step: 640, loss: 0.1500180959701538
step: 650, loss: 0.09833303093910217
step: 660, loss: 0.12892396748065948
step: 670, loss: 0.077070452272892
step: 680, loss: 0.0605238638818264
step: 690, loss: 0.13751649856567383
step: 700, loss: 0.07262200862169266
step: 710, loss: 0.24115566909313202
step: 720, loss: 0.09558805078268051
step: 730, loss: 0.11005090177059174
step: 740, loss: 0.02595505304634571
step: 750, loss: 0.0763760656118393
step: 760, loss: 0.06727557629346848
step: 770, loss: 0.06523624807596207
step: 780, loss: 0.05708460137248039
step: 790, loss: 0.005792292300611734
step: 800, loss: 0.045047421008348465
step: 810, loss: 0.16597679257392883
step: 820, loss: 0.045529406517744064
step: 830, loss: 0.01735832542181015
step: 840, loss: 0.113691046833992
step: 850, loss: 0.07943645119667053
step: 860, loss: 0.12674231827259064
step: 870, loss: 0.17548085749149323
step: 880, loss: 0.020666737109422684
step: 890, loss: 0.08426805585622787
step: 900, loss: 0.05416871979832649
step: 910, loss: 0.032199326902627945
step: 920, loss: 0.11902745813131332
step: 930, loss: 0.05805128812789917
step: 940, loss: 0.13803069293498993
step: 950, loss: 0.08914118260145187
step: 960, loss: 0.11886732280254364
step: 970, loss: 0.07750796526670456
step: 980, loss: 0.06919224560260773
step: 990, loss: 0.01628352515399456
step: 1000, loss: 0.1337728649377823
step: 1010, loss: 0.10170648247003555
step: 1020, loss: 0.11038866639137268
step: 1030, loss: 0.101188525557518
step: 1040, loss: 0.10099001228809357
step: 1050, loss: 0.18595047295093536
step: 1060, loss: 0.08449304848909378
step: 1070, loss: 0.14710365235805511
epoch 3: dev_f1=0.9360146252285192, f1=0.9304229195088677, best_f1=0.9304229195088677
step: 0, loss: 0.06438309699296951
step: 10, loss: 0.14060236513614655
step: 20, loss: 0.014116463251411915
step: 30, loss: 0.12095694988965988
step: 40, loss: 0.036765504628419876
step: 50, loss: 0.020807914435863495
step: 60, loss: 0.014659665524959564
step: 70, loss: 0.025728421285748482
step: 80, loss: 0.06426015496253967
step: 90, loss: 0.018147140741348267
step: 100, loss: 0.26323169469833374
step: 110, loss: 0.08995356410741806
step: 120, loss: 0.04639830440282822
step: 130, loss: 0.06403394788503647
step: 140, loss: 0.09170432388782501
step: 150, loss: 0.08484050631523132
step: 160, loss: 0.0684162825345993
step: 170, loss: 0.07984141260385513
step: 180, loss: 0.041454799473285675
step: 190, loss: 0.23371298611164093
step: 200, loss: 0.13792447745800018
step: 210, loss: 0.04781835153698921
step: 220, loss: 0.08374331146478653
step: 230, loss: 0.07862041145563126
step: 240, loss: 0.39348846673965454
step: 250, loss: 0.02231316827237606
step: 260, loss: 0.04859941452741623
step: 270, loss: 0.12759371101856232
step: 280, loss: 0.07532376796007156
step: 290, loss: 0.005228232592344284
step: 300, loss: 0.024283885955810547
step: 310, loss: 0.031935807317495346
step: 320, loss: 0.03716176003217697
step: 330, loss: 0.14947821199893951
step: 340, loss: 0.07363685965538025
step: 350, loss: 0.1023329347372055
step: 360, loss: 0.08166863024234772
step: 370, loss: 0.012891631573438644
step: 380, loss: 0.030325615778565407
step: 390, loss: 0.09197000414133072
step: 400, loss: 0.09026453644037247
step: 410, loss: 0.07473604381084442
step: 420, loss: 0.04601982608437538
step: 430, loss: 0.10866887867450714
step: 440, loss: 0.2173188328742981
step: 450, loss: 0.10986451804637909
step: 460, loss: 0.06900297105312347
step: 470, loss: 0.07463937997817993
step: 480, loss: 0.026399441063404083
step: 490, loss: 0.04926835745573044
step: 500, loss: 0.08328800648450851
step: 510, loss: 0.09673775732517242
step: 520, loss: 0.02251284010708332
step: 530, loss: 0.07958080619573593
step: 540, loss: 0.026193028315901756
step: 550, loss: 0.04763835296034813
step: 560, loss: 0.11184192448854446
step: 570, loss: 0.01578327640891075
step: 580, loss: 0.13952067494392395
step: 590, loss: 0.021102946251630783
step: 600, loss: 0.1540064662694931
step: 610, loss: 0.10214418172836304
step: 620, loss: 0.11668746918439865
step: 630, loss: 0.084199920296669
step: 640, loss: 0.0059591601602733135
step: 650, loss: 0.03563781827688217
step: 660, loss: 0.06526929140090942
step: 670, loss: 0.03017977438867092
step: 680, loss: 0.09675261378288269
step: 690, loss: 0.08293739706277847
step: 700, loss: 0.021525798365473747
step: 710, loss: 0.019641952589154243
step: 720, loss: 0.009903546422719955
step: 730, loss: 0.07682186365127563
step: 740, loss: 0.11366867274045944
step: 750, loss: 0.15287654101848602
step: 760, loss: 0.10207144170999527
step: 770, loss: 0.06919597834348679
step: 780, loss: 0.03846828639507294
step: 790, loss: 0.060421496629714966
step: 800, loss: 0.040002234280109406
step: 810, loss: 0.07878681272268295
step: 820, loss: 0.03577147051692009
step: 830, loss: 0.12228008359670639
step: 840, loss: 0.17528881132602692
step: 850, loss: 0.09432533383369446
step: 860, loss: 0.07242249697446823
step: 870, loss: 0.00046886428026482463
step: 880, loss: 0.06549949944019318
step: 890, loss: 0.0676407739520073
step: 900, loss: 0.039971571415662766
step: 910, loss: 0.11393701285123825
step: 920, loss: 0.13714182376861572
step: 930, loss: 0.012781178578734398
step: 940, loss: 0.11158906668424606
step: 950, loss: 0.1021047830581665
step: 960, loss: 0.10049748420715332
step: 970, loss: 0.17169691622257233
step: 980, loss: 0.08203761279582977
step: 990, loss: 0.06992656737565994
step: 1000, loss: 0.013998501002788544
step: 1010, loss: 0.04961322993040085
step: 1020, loss: 0.06329325586557388
step: 1030, loss: 0.1274222731590271
step: 1040, loss: 0.06112126260995865
step: 1050, loss: 0.08753623068332672
step: 1060, loss: 0.04002863168716431
step: 1070, loss: 0.07691656798124313
epoch 4: dev_f1=0.9289719626168225, f1=0.9308755760368663, best_f1=0.9304229195088677
step: 0, loss: 0.022876562550663948
step: 10, loss: 0.09782887250185013
step: 20, loss: 0.0292276069521904
step: 30, loss: 0.08776845037937164
step: 40, loss: 0.023044053465127945
step: 50, loss: 0.011974574998021126
step: 60, loss: 0.014462107792496681
step: 70, loss: 0.010298160836100578
step: 80, loss: 0.1796087920665741
step: 90, loss: 0.014125356450676918
step: 100, loss: 0.012986024841666222
step: 110, loss: 0.0010539181530475616
step: 120, loss: 0.06639429926872253
step: 130, loss: 0.10218024998903275
step: 140, loss: 0.015164818614721298
step: 150, loss: 0.02295222505927086
step: 160, loss: 0.019676022231578827
step: 170, loss: 0.25211095809936523
step: 180, loss: 0.12155493348836899
step: 190, loss: 0.10903538018465042
step: 200, loss: 0.06743209809064865
step: 210, loss: 0.021215524524450302
step: 220, loss: 0.002131600631400943
step: 230, loss: 0.015965880826115608
step: 240, loss: 0.11553573608398438
step: 250, loss: 0.004747828934341669
step: 260, loss: 0.03531292825937271
step: 270, loss: 0.16728562116622925
step: 280, loss: 0.07710853219032288
step: 290, loss: 0.05439554527401924
step: 300, loss: 0.18661004304885864
step: 310, loss: 0.06575436145067215
step: 320, loss: 0.07268589735031128
step: 330, loss: 0.06466933339834213
step: 340, loss: 0.0140891307964921
step: 350, loss: 0.08892986178398132
step: 360, loss: 0.07972481101751328
step: 370, loss: 0.13658949732780457
step: 380, loss: 0.02407294325530529
step: 390, loss: 0.04734823852777481
step: 400, loss: 0.08578993380069733
step: 410, loss: 0.01955236867070198
step: 420, loss: 0.04526172950863838
step: 430, loss: 0.012526264414191246
step: 440, loss: 0.12067537009716034
step: 450, loss: 0.028909631073474884
step: 460, loss: 0.008591828867793083
step: 470, loss: 0.06246601790189743
step: 480, loss: 0.09462787210941315
step: 490, loss: 0.02795771136879921
step: 500, loss: 0.019533827900886536
step: 510, loss: 0.026126280426979065
step: 520, loss: 0.0652102679014206
step: 530, loss: 0.0833466500043869
step: 540, loss: 0.027642568573355675
step: 550, loss: 0.0812549963593483
step: 560, loss: 0.04953518137335777
step: 570, loss: 0.11240227520465851
step: 580, loss: 0.08098980784416199
step: 590, loss: 0.16079120337963104
step: 600, loss: 0.20306307077407837
step: 610, loss: 0.0635746493935585
step: 620, loss: 0.021923065185546875
step: 630, loss: 0.059404823929071426
step: 640, loss: 0.023739270865917206
step: 650, loss: 0.018261510878801346
step: 660, loss: 0.09419264644384384
step: 670, loss: 0.03324762359261513
step: 680, loss: 0.014408971183001995
step: 690, loss: 0.06378301978111267
step: 700, loss: 0.017160659655928612
step: 710, loss: 0.07621096819639206
step: 720, loss: 0.015102003701031208
step: 730, loss: 0.06749304383993149
step: 740, loss: 0.08194491267204285
step: 750, loss: 0.024726685136556625
step: 760, loss: 0.16055363416671753
step: 770, loss: 0.12565509974956512
step: 780, loss: 0.02663625404238701
step: 790, loss: 0.008766860701143742
step: 800, loss: 0.11300875246524811
step: 810, loss: 0.006470587570220232
step: 820, loss: 0.017978809773921967
step: 830, loss: 0.12402692437171936
step: 840, loss: 0.05840986594557762
step: 850, loss: 0.06114641949534416
step: 860, loss: 0.041552841663360596
step: 870, loss: 0.0072187818586826324
step: 880, loss: 0.024168333038687706
step: 890, loss: 0.03176388144493103
step: 900, loss: 0.08859901875257492
step: 910, loss: 0.0017858082428574562
step: 920, loss: 0.14667420089244843
step: 930, loss: 0.004136981908231974
step: 940, loss: 0.02535419911146164
step: 950, loss: 0.24049408733844757
step: 960, loss: 0.17435824871063232
step: 970, loss: 0.09886065870523453
step: 980, loss: 0.15464794635772705
step: 990, loss: 0.04678048565983772
step: 1000, loss: 0.056576330214738846
step: 1010, loss: 0.007502796594053507
step: 1020, loss: 0.026546703651547432
step: 1030, loss: 0.08629900217056274
step: 1040, loss: 0.011144552379846573
step: 1050, loss: 0.13542518019676208
step: 1060, loss: 0.11806683242321014
step: 1070, loss: 0.029204867780208588
epoch 5: dev_f1=0.9335167354424576, f1=0.9213993639254885, best_f1=0.9304229195088677
step: 0, loss: 0.08083134889602661
step: 10, loss: 0.045965131372213364
step: 20, loss: 0.05916794016957283
step: 30, loss: 0.11211466044187546
step: 40, loss: 0.17620405554771423
step: 50, loss: 0.1425882875919342
step: 60, loss: 0.04773953929543495
step: 70, loss: 0.11972182989120483
step: 80, loss: 0.007600080221891403
step: 90, loss: 0.18440495431423187
step: 100, loss: 0.07219613343477249
step: 110, loss: 0.13986502587795258
step: 120, loss: 0.051103994250297546
step: 130, loss: 0.06699926406145096
step: 140, loss: 0.055691659450531006
step: 150, loss: 0.060429856181144714
step: 160, loss: 0.019415587186813354
step: 170, loss: 0.009494881145656109
step: 180, loss: 0.0037572355940937996
step: 190, loss: 0.011003542691469193
step: 200, loss: 0.07078158110380173
step: 210, loss: 0.017190612852573395
step: 220, loss: 0.025156209245324135
step: 230, loss: 0.1209293007850647
step: 240, loss: 0.16258321702480316
step: 250, loss: 0.0749635100364685
step: 260, loss: 0.024134092032909393
step: 270, loss: 0.06375197321176529
step: 280, loss: 0.011973673477768898
step: 290, loss: 0.02935907058417797
step: 300, loss: 0.025389935821294785
step: 310, loss: 0.07797311246395111
step: 320, loss: 0.013472912833094597
step: 330, loss: 0.013827667571604252
step: 340, loss: 0.006641279440373182
step: 350, loss: 0.07714181393384933
step: 360, loss: 0.08572188764810562
step: 370, loss: 0.027327794581651688
step: 380, loss: 0.025125259533524513
step: 390, loss: 0.011524192988872528
step: 400, loss: 0.01596585288643837
step: 410, loss: 0.03211596980690956
step: 420, loss: 0.10797201842069626
step: 430, loss: 0.0026650892104953527
step: 440, loss: 0.054323192685842514
step: 450, loss: 0.10435040295124054
step: 460, loss: 0.014140489511191845
step: 470, loss: 0.05706574767827988
step: 480, loss: 0.06241488829255104
step: 490, loss: 0.015311582013964653
step: 500, loss: 0.06403251737356186
step: 510, loss: 0.18703986704349518
step: 520, loss: 0.0820939913392067
step: 530, loss: 0.05101777985692024
step: 540, loss: 0.1421976536512375
step: 550, loss: 0.07839137315750122
step: 560, loss: 0.031181467697024345
step: 570, loss: 0.016603639349341393
step: 580, loss: 0.06248978152871132
step: 590, loss: 0.01216223742812872
step: 600, loss: 0.09247193485498428
step: 610, loss: 0.052730992436409
step: 620, loss: 0.10953158140182495
step: 630, loss: 0.030092475935816765
step: 640, loss: 0.020849332213401794
step: 650, loss: 0.005094307474792004
step: 660, loss: 0.3497992753982544
step: 670, loss: 0.15243159234523773
step: 680, loss: 0.07087498903274536
step: 690, loss: 0.01963304542005062
step: 700, loss: 0.09371034801006317
step: 710, loss: 0.016319794580340385
step: 720, loss: 0.13205407559871674
step: 730, loss: 0.16403044760227203
step: 740, loss: 0.017027348279953003
step: 750, loss: 0.004322639666497707
step: 760, loss: 0.015861893072724342
step: 770, loss: 0.07866857945919037
step: 780, loss: 0.09550923109054565
step: 790, loss: 0.03396878018975258
step: 800, loss: 0.02298561856150627
step: 810, loss: 0.017004940658807755
step: 820, loss: 0.06766775995492935
step: 830, loss: 0.06467544287443161
step: 840, loss: 0.07164328545331955
step: 850, loss: 0.04263787344098091
step: 860, loss: 0.10978161543607712
step: 870, loss: 0.018304644152522087
step: 880, loss: 0.09400207549333572
step: 890, loss: 0.12736010551452637
step: 900, loss: 0.014479056000709534
step: 910, loss: 0.02839450165629387
step: 920, loss: 0.10699853301048279
step: 930, loss: 0.15426497161388397
step: 940, loss: 0.13243833184242249
step: 950, loss: 0.05547777935862541
step: 960, loss: 0.05707584321498871
step: 970, loss: 0.09241078048944473
step: 980, loss: 0.09197238087654114
step: 990, loss: 0.09007124602794647
step: 1000, loss: 0.11160125583410263
step: 1010, loss: 0.07305954396724701
step: 1020, loss: 0.047680411487817764
step: 1030, loss: 0.0860714465379715
step: 1040, loss: 0.012040683999657631
step: 1050, loss: 0.06344525516033173
step: 1060, loss: 0.09438911080360413
step: 1070, loss: 0.037615012377500534
epoch 6: dev_f1=0.9401553220648697, f1=0.9385525716886665, best_f1=0.9385525716886665
step: 0, loss: 0.03476355969905853
step: 10, loss: 0.026339057832956314
step: 20, loss: 0.14730173349380493
step: 30, loss: 0.1155548021197319
step: 40, loss: 0.025302166119217873
step: 50, loss: 0.01296042837202549
step: 60, loss: 0.021778704598546028
step: 70, loss: 0.09470632672309875
step: 80, loss: 0.11375325173139572
step: 90, loss: 0.01162551250308752
step: 100, loss: 0.10382972657680511
step: 110, loss: 0.17265096306800842
step: 120, loss: 0.006173177622258663
step: 130, loss: 0.06826075166463852
step: 140, loss: 0.05477147921919823
step: 150, loss: 0.0631418526172638
step: 160, loss: 0.014410426840186119
step: 170, loss: 0.014027245342731476
step: 180, loss: 0.004366892855614424
step: 190, loss: 0.11966664344072342
step: 200, loss: 0.07410978525876999
step: 210, loss: 0.07625722140073776
step: 220, loss: 0.07157140970230103
step: 230, loss: 0.01674778014421463
step: 240, loss: 0.05394600331783295
step: 250, loss: 0.05777508765459061
step: 260, loss: 0.1352553516626358
step: 270, loss: 0.021051734685897827
step: 280, loss: 0.0066955117508769035
step: 290, loss: 0.12291259318590164
step: 300, loss: 0.05278399959206581
step: 310, loss: 0.07376040518283844
step: 320, loss: 0.015063892118632793
step: 330, loss: 0.03773265331983566
step: 340, loss: 0.03865837678313255
step: 350, loss: 0.005860631819814444
step: 360, loss: 0.052193693816661835
step: 370, loss: 0.08281286805868149
step: 380, loss: 0.0850006639957428
step: 390, loss: 0.038600943982601166
step: 400, loss: 0.05443490669131279
step: 410, loss: 0.06582460552453995
step: 420, loss: 0.12078644335269928
step: 430, loss: 0.05047450587153435
step: 440, loss: 0.08579190820455551
step: 450, loss: 0.15443669259548187
step: 460, loss: 0.014501151628792286
step: 470, loss: 0.1790456473827362
step: 480, loss: 0.017124701291322708
step: 490, loss: 0.011533179320394993
step: 500, loss: 0.022448483854532242
step: 510, loss: 0.11309824138879776
step: 520, loss: 0.011935947462916374
step: 530, loss: 0.036625344306230545
step: 540, loss: 0.030800748616456985
step: 550, loss: 0.0061198086477816105
step: 560, loss: 0.26804623007774353
step: 570, loss: 0.03341634199023247
step: 580, loss: 0.010193306021392345
step: 590, loss: 0.09321916103363037
step: 600, loss: 0.04200384020805359
step: 610, loss: 0.04393458738923073
step: 620, loss: 0.04122457280755043
step: 630, loss: 0.09168882668018341
step: 640, loss: 0.007550205569714308
step: 650, loss: 0.024712756276130676
step: 660, loss: 0.0030017890967428684
step: 670, loss: 0.04218652471899986
step: 680, loss: 0.03763213008642197
step: 690, loss: 0.037291377782821655
step: 700, loss: 0.028297994285821915
step: 710, loss: 0.03823310136795044
step: 720, loss: 0.016874225810170174
step: 730, loss: 0.08247838169336319
step: 740, loss: 0.09106045216321945
step: 750, loss: 0.020864607766270638
step: 760, loss: 0.06701309978961945
step: 770, loss: 0.021183321252465248
step: 780, loss: 0.1440165936946869
step: 790, loss: 0.0749998390674591
step: 800, loss: 0.059074658900499344
step: 810, loss: 0.08249220997095108
step: 820, loss: 0.055696651339530945
step: 830, loss: 0.042491115629673004
step: 840, loss: 0.06383101642131805
step: 850, loss: 0.009707710705697536
step: 860, loss: 0.03781827539205551
step: 870, loss: 0.03977235406637192
step: 880, loss: 0.0003961600596085191
step: 890, loss: 0.036373868584632874
step: 900, loss: 0.06096231937408447
step: 910, loss: 0.07654189318418503
step: 920, loss: 0.11442185938358307
step: 930, loss: 0.05452065169811249
step: 940, loss: 0.007669421378523111
step: 950, loss: 0.07212453335523605
step: 960, loss: 0.07853715121746063
step: 970, loss: 0.01238819770514965
step: 980, loss: 0.08767981082201004
step: 990, loss: 0.04605502262711525
step: 1000, loss: 0.029864560812711716
step: 1010, loss: 0.006368021015077829
step: 1020, loss: 0.17140063643455505
step: 1030, loss: 0.04354805499315262
step: 1040, loss: 0.1407259702682495
step: 1050, loss: 0.10817088931798935
step: 1060, loss: 0.030489914119243622
step: 1070, loss: 0.00023386858811136335
epoch 7: dev_f1=0.9366742596810934, f1=0.9379247847757136, best_f1=0.9385525716886665
step: 0, loss: 0.025196164846420288
step: 10, loss: 0.0632881373167038
step: 20, loss: 0.0320562869310379
step: 30, loss: 0.06138325110077858
step: 40, loss: 0.010543929412961006
step: 50, loss: 0.02234349213540554
step: 60, loss: 0.023124150931835175
step: 70, loss: 0.0932779386639595
step: 80, loss: 0.01782834902405739
step: 90, loss: 0.04856117442250252
step: 100, loss: 0.031301867216825485
step: 110, loss: 0.026217356324195862
step: 120, loss: 0.03985867649316788
step: 130, loss: 0.09405789524316788
step: 140, loss: 0.046267423778772354
step: 150, loss: 0.04449936002492905
step: 160, loss: 0.03410232067108154
step: 170, loss: 0.12273027747869492
step: 180, loss: 0.1810372769832611
step: 190, loss: 0.16280153393745422
step: 200, loss: 0.045670878142118454
step: 210, loss: 0.057659927755594254
step: 220, loss: 0.07664084434509277
step: 230, loss: 0.10887537151575089
step: 240, loss: 0.13648737967014313
step: 250, loss: 0.01786331832408905
step: 260, loss: 0.022635389119386673
step: 270, loss: 0.015339897945523262
step: 280, loss: 0.08996941149234772
step: 290, loss: 0.004737875424325466
step: 300, loss: 0.089178167283535
step: 310, loss: 0.032582417130470276
step: 320, loss: 0.07831444591283798
step: 330, loss: 0.025091588497161865
step: 340, loss: 0.009531327523291111
step: 350, loss: 0.09098515659570694
step: 360, loss: 4.1196050005964935e-05
step: 370, loss: 0.008613799698650837
step: 380, loss: 0.02366858720779419
step: 390, loss: 0.16647593677043915
step: 400, loss: 0.05126192048192024
step: 410, loss: 0.08420783281326294
step: 420, loss: 6.326565926428884e-05
step: 430, loss: 0.12823237478733063
step: 440, loss: 0.04239087924361229
step: 450, loss: 0.03481939062476158
step: 460, loss: 0.046415120363235474
step: 470, loss: 0.02527341991662979
step: 480, loss: 0.011776275932788849
step: 490, loss: 0.030999483540654182
step: 500, loss: 0.10039815306663513
step: 510, loss: 0.1455920785665512
step: 520, loss: 0.01863124407827854
step: 530, loss: 0.03075842186808586
step: 540, loss: 0.07640006393194199
step: 550, loss: 0.05433645471930504
step: 560, loss: 0.057647619396448135
step: 570, loss: 0.07851874083280563
step: 580, loss: 0.03900943696498871
step: 590, loss: 0.008798440918326378
step: 600, loss: 0.02691308781504631
step: 610, loss: 0.041081611067056656
step: 620, loss: 0.03835657238960266
step: 630, loss: 0.02979041077196598
step: 640, loss: 0.014234947971999645
step: 650, loss: 0.10153304040431976
step: 660, loss: 0.042711347341537476
step: 670, loss: 0.07223141193389893
step: 680, loss: 0.051986292004585266
step: 690, loss: 0.008676056750118732
step: 700, loss: 0.031653571873903275
step: 710, loss: 0.12292926013469696
step: 720, loss: 0.08444567769765854
step: 730, loss: 0.01900225505232811
step: 740, loss: 0.002684430917724967
step: 750, loss: 0.06774746626615524
step: 760, loss: 0.06374557316303253
step: 770, loss: 0.07189062982797623
step: 780, loss: 0.022307854145765305
step: 790, loss: 0.040383242070674896
step: 800, loss: 0.003820032812654972
step: 810, loss: 0.04952671006321907
step: 820, loss: 0.06940148025751114
step: 830, loss: 0.013440735638141632
step: 840, loss: 0.09152441471815109
step: 850, loss: 0.0030233950819820166
step: 860, loss: 0.08917736262083054
step: 870, loss: 0.007538959383964539
step: 880, loss: 0.02427845075726509
step: 890, loss: 0.05087123438715935
step: 900, loss: 0.07015282660722733
step: 910, loss: 0.05012869834899902
step: 920, loss: 0.06266725808382034
step: 930, loss: 0.05954582989215851
step: 940, loss: 0.0020016541238874197
step: 950, loss: 0.04991813749074936
step: 960, loss: 0.025104722008109093
step: 970, loss: 0.019379835575819016
step: 980, loss: 0.03839171677827835
step: 990, loss: 0.04593075066804886
step: 1000, loss: 0.01615920104086399
step: 1010, loss: 0.11865073442459106
step: 1020, loss: 0.0884719118475914
step: 1030, loss: 0.09399308264255524
step: 1040, loss: 0.06874459981918335
step: 1050, loss: 0.08040952682495117
step: 1060, loss: 0.02038106881082058
step: 1070, loss: 0.07559265196323395
epoch 8: dev_f1=0.9406934306569343, f1=0.9316432775011317, best_f1=0.9316432775011317
step: 0, loss: 0.02789546735584736
step: 10, loss: 0.07517805695533752
step: 20, loss: 0.05679263547062874
step: 30, loss: 0.027542799711227417
step: 40, loss: 0.10141633450984955
step: 50, loss: 0.1324647217988968
step: 60, loss: 0.024585513398051262
step: 70, loss: 0.05438088998198509
step: 80, loss: 0.012771455571055412
step: 90, loss: 0.0024965174961835146
step: 100, loss: 0.03280961886048317
step: 110, loss: 0.06525623798370361
step: 120, loss: 0.3125033974647522
step: 130, loss: 0.04643692448735237
step: 140, loss: 0.03906719386577606
step: 150, loss: 0.030713580548763275
step: 160, loss: 0.014280742034316063
step: 170, loss: 0.06067012622952461
step: 180, loss: 0.03488306701183319
step: 190, loss: 0.10623526573181152
step: 200, loss: 0.13058863580226898
step: 210, loss: 0.016476284712553024
step: 220, loss: 0.016624614596366882
step: 230, loss: 0.0052542719058692455
step: 240, loss: 0.024553382769227028
step: 250, loss: 0.06040026247501373
step: 260, loss: 0.07237586379051208
step: 270, loss: 0.14721183478832245
step: 280, loss: 0.014419913291931152
step: 290, loss: 0.048248063772916794
step: 300, loss: 0.021486273035407066
step: 310, loss: 0.08686211705207825
step: 320, loss: 0.03322632238268852
step: 330, loss: 0.07043859362602234
step: 340, loss: 0.026845458894968033
step: 350, loss: 0.06453131884336472
step: 360, loss: 6.338247476378456e-05
step: 370, loss: 0.05209812894463539
step: 380, loss: 0.053268495947122574
step: 390, loss: 0.13259382545948029
step: 400, loss: 0.15106706321239471
step: 410, loss: 0.019404418766498566
step: 420, loss: 0.029706571251153946
step: 430, loss: 0.12901391088962555
step: 440, loss: 0.023414449766278267
step: 450, loss: 0.03963671252131462
step: 460, loss: 0.04696662724018097
step: 470, loss: 0.05200330168008804
step: 480, loss: 0.011212578043341637
step: 490, loss: 0.12949901819229126
step: 500, loss: 0.022248657420277596
step: 510, loss: 0.0496785044670105
step: 520, loss: 0.06348105520009995
step: 530, loss: 0.04733598977327347
step: 540, loss: 0.016254693269729614
step: 550, loss: 0.050007786601781845
step: 560, loss: 0.10999840497970581
step: 570, loss: 0.07675237208604813
step: 580, loss: 0.048730846494436264
step: 590, loss: 0.005214361473917961
step: 600, loss: 0.03890160471200943
step: 610, loss: 0.03049268014729023
step: 620, loss: 0.012551669962704182
step: 630, loss: 0.018639907240867615
step: 640, loss: 0.11737161874771118
step: 650, loss: 0.054988253861665726
step: 660, loss: 0.05851227045059204
step: 670, loss: 0.08883775025606155
step: 680, loss: 0.07289832085371017
step: 690, loss: 0.010536481626331806
step: 700, loss: 0.042749498039484024
step: 710, loss: 0.007272559218108654
step: 720, loss: 0.050806641578674316
step: 730, loss: 0.09938029199838638
step: 740, loss: 0.017767833545804024
step: 750, loss: 0.11521933227777481
step: 760, loss: 0.004483060445636511
step: 770, loss: 0.02102733589708805
step: 780, loss: 0.02512974664568901
step: 790, loss: 0.019281383603811264
step: 800, loss: 0.05580615997314453
step: 810, loss: 0.2433951497077942
step: 820, loss: 0.04343286529183388
step: 830, loss: 0.05158919841051102
step: 840, loss: 0.11838964372873306
step: 850, loss: 0.02213246002793312
step: 860, loss: 0.01582716405391693
step: 870, loss: 0.019998162984848022
step: 880, loss: 0.15699297189712524
step: 890, loss: 0.1639874279499054
step: 900, loss: 0.052972953766584396
step: 910, loss: 0.006964197847992182
step: 920, loss: 0.041475117206573486
step: 930, loss: 0.044104453176259995
step: 940, loss: 0.04479094594717026
step: 950, loss: 0.0016665891744196415
step: 960, loss: 0.02701367251574993
step: 970, loss: 0.03993130102753639
step: 980, loss: 0.047601643949747086
step: 990, loss: 0.07980361580848694
step: 1000, loss: 0.06678886711597443
step: 1010, loss: 0.08169273287057877
step: 1020, loss: 0.02360452152788639
step: 1030, loss: 0.050436340272426605
step: 1040, loss: 0.15889152884483337
step: 1050, loss: 0.029611608013510704
step: 1060, loss: 0.02145114354789257
step: 1070, loss: 0.06286244094371796
epoch 9: dev_f1=0.9330855018587362, f1=0.934622467771639, best_f1=0.9316432775011317
step: 0, loss: 0.01635497435927391
step: 10, loss: 0.062314148992300034
step: 20, loss: 0.08372795581817627
step: 30, loss: 0.01910652406513691
step: 40, loss: 0.0034161380026489496
step: 50, loss: 0.021867668256163597
step: 60, loss: 0.0023174171801656485
step: 70, loss: 0.07525449246168137
step: 80, loss: 0.08452629297971725
step: 90, loss: 0.10941192507743835
step: 100, loss: 0.034585874527692795
step: 110, loss: 0.01876959018409252
step: 120, loss: 0.011334522627294064
step: 130, loss: 0.017412874847650528
step: 140, loss: 0.05555323138833046
step: 150, loss: 0.06113677844405174
step: 160, loss: 0.006879965774714947
step: 170, loss: 0.036800190806388855
step: 180, loss: 0.060570359230041504
step: 190, loss: 0.04622279852628708
step: 200, loss: 0.05702866613864899
step: 210, loss: 0.05769912526011467
step: 220, loss: 0.004652183502912521
step: 230, loss: 0.006366605870425701
step: 240, loss: 0.09976205974817276
step: 250, loss: 0.012660380452871323
step: 260, loss: 0.045872580260038376
step: 270, loss: 0.011243877001106739
step: 280, loss: 0.10095100104808807
step: 290, loss: 0.0005560090648941696
step: 300, loss: 0.0479368194937706
step: 310, loss: 0.029512295499444008
step: 320, loss: 0.043977417051792145
step: 330, loss: 0.028162803500890732
step: 340, loss: 0.00020042512915097177
step: 350, loss: 0.06250446289777756
step: 360, loss: 0.08347038179636002
step: 370, loss: 0.06759142130613327
step: 380, loss: 0.005292368121445179
step: 390, loss: 0.08998347818851471
step: 400, loss: 0.12422604113817215
step: 410, loss: 0.07963289320468903
step: 420, loss: 0.04307668283581734
step: 430, loss: 0.03867848962545395
step: 440, loss: 0.03606823831796646
step: 450, loss: 0.06452120840549469
step: 460, loss: 0.03980457782745361
step: 470, loss: 0.013812567107379436
step: 480, loss: 0.030687354505062103
step: 490, loss: 0.08346425741910934
step: 500, loss: 0.04031244292855263
step: 510, loss: 0.01943119801580906
step: 520, loss: 0.0657837837934494
step: 530, loss: 0.0071349493227899075
step: 540, loss: 0.006942000240087509
step: 550, loss: 0.09798192232847214
step: 560, loss: 0.04398813471198082
step: 570, loss: 0.005163947120308876
step: 580, loss: 0.037467848509550095
step: 590, loss: 0.05489788204431534
step: 600, loss: 0.06051687151193619
step: 610, loss: 0.005175446160137653
step: 620, loss: 0.01221335120499134
step: 630, loss: 0.06773047149181366
step: 640, loss: 0.05205731466412544
step: 650, loss: 0.06958989799022675
step: 660, loss: 0.06671397387981415
step: 670, loss: 0.02550922892987728
step: 680, loss: 0.04089200124144554
step: 690, loss: 0.050220828503370285
step: 700, loss: 0.0009797447128221393
step: 710, loss: 0.04799884557723999
step: 720, loss: 0.04161816090345383
step: 730, loss: 0.06540009379386902
step: 740, loss: 0.0298040471971035
step: 750, loss: 0.008909858763217926
step: 760, loss: 0.09299604594707489
step: 770, loss: 0.03475070372223854
step: 780, loss: 0.049762144684791565
step: 790, loss: 0.16427290439605713
step: 800, loss: 0.06189078465104103
step: 810, loss: 0.01383746974170208
step: 820, loss: 0.03812289983034134
step: 830, loss: 0.08856676518917084
step: 840, loss: 0.048570744693279266
step: 850, loss: 0.030256373807787895
step: 860, loss: 0.02866625413298607
step: 870, loss: 0.014778480865061283
step: 880, loss: 0.07834230363368988
step: 890, loss: 0.12366004288196564
step: 900, loss: 0.007967575453221798
step: 910, loss: 0.06534687429666519
step: 920, loss: 0.037303484976291656
step: 930, loss: 0.026622246950864792
step: 940, loss: 0.0645226240158081
step: 950, loss: 0.04995354264974594
step: 960, loss: 0.038508616387844086
step: 970, loss: 0.10259491205215454
step: 980, loss: 0.03973492607474327
step: 990, loss: 0.10976976156234741
step: 1000, loss: 0.01566549576818943
step: 1010, loss: 0.013048458844423294
step: 1020, loss: 0.004664437845349312
step: 1030, loss: 0.056395821273326874
step: 1040, loss: 8.681633335072547e-05
step: 1050, loss: 0.015356604009866714
step: 1060, loss: 0.037012990564107895
step: 1070, loss: 0.04070034623146057
epoch 10: dev_f1=0.9376422394173873, f1=0.9356884057971016, best_f1=0.9316432775011317
step: 0, loss: 0.04984167963266373
step: 10, loss: 0.03180917352437973
step: 20, loss: 0.04338621720671654
step: 30, loss: 0.02325419895350933
step: 40, loss: 0.0057428209111094475
step: 50, loss: 0.005005397833883762
step: 60, loss: 0.027819106355309486
step: 70, loss: 0.001524322316981852
step: 80, loss: 0.07645384967327118
step: 90, loss: 0.03522427752614021
step: 100, loss: 0.004333618097007275
step: 110, loss: 0.009450509212911129
step: 120, loss: 0.026111576706171036
step: 130, loss: 0.04488580301403999
step: 140, loss: 0.038105081766843796
step: 150, loss: 0.0010009438265115023
step: 160, loss: 0.1267746388912201
step: 170, loss: 0.03298190236091614
step: 180, loss: 0.06079684942960739
step: 190, loss: 0.0032739334274083376
step: 200, loss: 0.039415519684553146
step: 210, loss: 0.047180235385894775
step: 220, loss: 0.03662458062171936
step: 230, loss: 0.2114965319633484
step: 240, loss: 0.0047294823452830315
step: 250, loss: 0.09648991376161575
step: 260, loss: 0.02362043410539627
step: 270, loss: 0.07069751620292664
step: 280, loss: 0.045301929116249084
step: 290, loss: 0.022967519238591194
step: 300, loss: 0.015396509319543839
step: 310, loss: 0.0033401448745280504
step: 320, loss: 0.0010272114304825664
step: 330, loss: 0.029810162261128426
step: 340, loss: 0.06402390450239182
step: 350, loss: 0.022496607154607773
step: 360, loss: 0.04200650006532669
step: 370, loss: 0.02614331990480423
step: 380, loss: 0.00023579844855703413
step: 390, loss: 0.002124339109286666
step: 400, loss: 0.03475570306181908
step: 410, loss: 0.09130274504423141
step: 420, loss: 0.017196880653500557
step: 430, loss: 0.02052367478609085
step: 440, loss: 0.04678194597363472
step: 450, loss: 0.008526809513568878
step: 460, loss: 0.000221136913751252
step: 470, loss: 0.021236494183540344
step: 480, loss: 0.06740526854991913
step: 490, loss: 0.022813254967331886
step: 500, loss: 0.02159535326063633
step: 510, loss: 0.009682044386863708
step: 520, loss: 0.0001858166797319427
step: 530, loss: 0.05598820373415947
step: 540, loss: 0.023243935778737068
step: 550, loss: 0.02920650877058506
step: 560, loss: 0.02908967062830925
step: 570, loss: 0.0026881203521043062
step: 580, loss: 0.07570293545722961
step: 590, loss: 0.11264722049236298
step: 600, loss: 0.00978962704539299
step: 610, loss: 0.035264842212200165
step: 620, loss: 0.016115549951791763
step: 630, loss: 0.00017180007125716656
step: 640, loss: 0.006923678331077099
step: 650, loss: 0.0001112468889914453
step: 660, loss: 2.9334723876672797e-05
step: 670, loss: 0.0012452700175344944
step: 680, loss: 0.033131882548332214
step: 690, loss: 0.036090247333049774
step: 700, loss: 0.04184659197926521
step: 710, loss: 0.06852319091558456
step: 720, loss: 0.2030486762523651
step: 730, loss: 0.06816774606704712
step: 740, loss: 0.02620072290301323
step: 750, loss: 0.00722210668027401
step: 760, loss: 0.09624361991882324
step: 770, loss: 0.12310558557510376
step: 780, loss: 0.008024916052818298
step: 790, loss: 0.061447933316230774
step: 800, loss: 0.02355068176984787
step: 810, loss: 0.010994800366461277
step: 820, loss: 0.22850735485553741
step: 830, loss: 0.002447163686156273
step: 840, loss: 0.0025913428980857134
step: 850, loss: 0.017201967537403107
step: 860, loss: 0.00429350882768631
step: 870, loss: 0.19332389533519745
step: 880, loss: 0.06089410185813904
step: 890, loss: 0.020508894696831703
step: 900, loss: 0.042654864490032196
step: 910, loss: 0.03788939490914345
step: 920, loss: 0.06890232115983963
step: 930, loss: 0.05566499009728432
step: 940, loss: 0.044838156551122665
step: 950, loss: 0.08357102423906326
step: 960, loss: 0.01484861969947815
step: 970, loss: 0.08914854377508163
step: 980, loss: 0.08272179216146469
step: 990, loss: 0.05465235561132431
step: 1000, loss: 0.09461776912212372
step: 1010, loss: 0.020693641155958176
step: 1020, loss: 0.07173148542642593
step: 1030, loss: 0.11627580970525742
step: 1040, loss: 0.015595946460962296
step: 1050, loss: 0.13639453053474426
step: 1060, loss: 0.05817052349448204
step: 1070, loss: 0.08556317538022995
epoch 11: dev_f1=0.936111111111111, f1=0.9274563820018366, best_f1=0.9316432775011317
step: 0, loss: 0.008112171664834023
step: 10, loss: 0.010285299271345139
step: 20, loss: 0.006611856631934643
step: 30, loss: 0.05036125332117081
step: 40, loss: 0.0002063192514469847
step: 50, loss: 0.04013160988688469
step: 60, loss: 0.02776150405406952
step: 70, loss: 0.04747127369046211
step: 80, loss: 0.026487180963158607
step: 90, loss: 0.09164352715015411
step: 100, loss: 0.04301891848444939
step: 110, loss: 0.04904802143573761
step: 120, loss: 0.024788636714220047
step: 130, loss: 0.0010869338875636458
step: 140, loss: 0.01996968686580658
step: 150, loss: 0.0011015351628884673
step: 160, loss: 0.04520915448665619
step: 170, loss: 0.06312829256057739
step: 180, loss: 0.10717233270406723
step: 190, loss: 0.053917620331048965
step: 200, loss: 0.052691422402858734
step: 210, loss: 0.0010855994187295437
step: 220, loss: 0.02272307686507702
step: 230, loss: 0.018701372668147087
step: 240, loss: 0.01588619314134121
step: 250, loss: 0.0009173162397928536
step: 260, loss: 0.02508978731930256
step: 270, loss: 0.02177744358778
step: 280, loss: 0.02661047875881195
step: 290, loss: 3.3995413105003536e-05
step: 300, loss: 0.00027904516900889575
step: 310, loss: 0.0040065026842057705
step: 320, loss: 0.0050497958436608315
step: 330, loss: 0.009883859194815159
step: 340, loss: 0.031002571806311607
step: 350, loss: 0.06638550013303757
step: 360, loss: 0.008694441057741642
step: 370, loss: 0.04744073376059532
step: 380, loss: 0.07497274875640869
step: 390, loss: 0.011597907170653343
step: 400, loss: 0.029536819085478783
step: 410, loss: 0.0736955851316452
step: 420, loss: 0.12282279133796692
step: 430, loss: 0.02818690985441208
step: 440, loss: 0.029269561171531677
step: 450, loss: 0.06438402831554413
step: 460, loss: 0.0021231931168586016
step: 470, loss: 0.06265154480934143
step: 480, loss: 0.03212091699242592
step: 490, loss: 0.06916535645723343
step: 500, loss: 0.2169976830482483
step: 510, loss: 0.0031046192161738873
step: 520, loss: 0.05425414815545082
step: 530, loss: 0.0742470920085907
step: 540, loss: 0.06544572114944458
step: 550, loss: 0.0683932676911354
step: 560, loss: 0.0564986988902092
step: 570, loss: 0.07427489757537842
step: 580, loss: 0.02882315218448639
step: 590, loss: 0.05842816084623337
step: 600, loss: 0.010041968896985054
step: 610, loss: 0.10545475780963898
step: 620, loss: 0.08823128789663315
step: 630, loss: 0.15796607732772827
step: 640, loss: 0.0034279697574675083
step: 650, loss: 0.007192506454885006
step: 660, loss: 0.009010347537696362
step: 670, loss: 0.02539273351430893
step: 680, loss: 0.010826686397194862
step: 690, loss: 0.006047829985618591
step: 700, loss: 0.02492520771920681
step: 710, loss: 0.06447761505842209
step: 720, loss: 0.0016938208136707544
step: 730, loss: 0.051025938242673874
step: 740, loss: 0.01858767494559288
step: 750, loss: 0.017389291897416115
step: 760, loss: 0.0002545497554820031
step: 770, loss: 0.013682330958545208
step: 780, loss: 0.06826096028089523
step: 790, loss: 0.026590313762426376
step: 800, loss: 0.05789361521601677
step: 810, loss: 0.0010685698362067342
step: 820, loss: 0.03538113087415695
step: 830, loss: 0.09305918216705322
step: 840, loss: 0.0005332720465958118
step: 850, loss: 0.019041502848267555
step: 860, loss: 9.895742550725117e-05
step: 870, loss: 0.056369513273239136
step: 880, loss: 0.1663358509540558
step: 890, loss: 0.07457444071769714
step: 900, loss: 0.018686912953853607
step: 910, loss: 0.114991195499897
step: 920, loss: 0.22222435474395752
step: 930, loss: 0.02677163854241371
step: 940, loss: 0.17946606874465942
step: 950, loss: 0.021141743287444115
step: 960, loss: 0.0593421533703804
step: 970, loss: 0.050548162311315536
step: 980, loss: 0.03893289715051651
step: 990, loss: 0.015440643765032291
step: 1000, loss: 0.0018154616700485349
step: 1010, loss: 0.07475050538778305
step: 1020, loss: 0.039482831954956055
step: 1030, loss: 0.03424632549285889
step: 1040, loss: 0.032353632152080536
step: 1050, loss: 0.030407406389713287
step: 1060, loss: 0.01723436638712883
step: 1070, loss: 0.0006810012273490429
epoch 12: dev_f1=0.9340609367894498, f1=0.93, best_f1=0.9316432775011317
step: 0, loss: 0.12075091153383255
step: 10, loss: 0.010733107104897499
step: 20, loss: 0.0021309496369212866
step: 30, loss: 0.0007743246387690306
step: 40, loss: 0.05095379054546356
step: 50, loss: 0.06421296298503876
step: 60, loss: 0.03792683407664299
step: 70, loss: 0.001059131696820259
step: 80, loss: 0.10250198841094971
step: 90, loss: 0.03122018277645111
step: 100, loss: 0.04288028925657272
step: 110, loss: 0.04754933342337608
step: 120, loss: 0.023105785250663757
step: 130, loss: 0.015137582086026669
step: 140, loss: 0.01859772391617298
step: 150, loss: 0.003809419460594654
step: 160, loss: 0.07450813800096512
step: 170, loss: 0.0548969991505146
step: 180, loss: 0.02284293808043003
step: 190, loss: 0.050405245274305344
step: 200, loss: 0.0002867328003048897
step: 210, loss: 0.03305390477180481
step: 220, loss: 0.06453310698270798
step: 230, loss: 0.000127597784739919
step: 240, loss: 0.00064703548559919
step: 250, loss: 7.932489097584039e-05
step: 260, loss: 3.266211206209846e-05
step: 270, loss: 0.03433459624648094
step: 280, loss: 0.13336506485939026
step: 290, loss: 0.0006362596759572625
step: 300, loss: 0.0026560805272310972
step: 310, loss: 4.1462881199549884e-05
step: 320, loss: 0.1081346943974495
step: 330, loss: 0.09840428084135056
step: 340, loss: 0.0017510580364614725
step: 350, loss: 0.022024814039468765
step: 360, loss: 0.001783389481715858
step: 370, loss: 0.009855623356997967
step: 380, loss: 0.01017522718757391
step: 390, loss: 0.0826466903090477
step: 400, loss: 0.059288300573825836
step: 410, loss: 0.017301535233855247
step: 420, loss: 0.16922694444656372
step: 430, loss: 0.019849175587296486
step: 440, loss: 0.002976099494844675
step: 450, loss: 0.022671064361929893
step: 460, loss: 0.11093654483556747
step: 470, loss: 0.0037555417511612177
step: 480, loss: 0.010086128488183022
step: 490, loss: 0.03916831687092781
step: 500, loss: 0.028062691912055016
step: 510, loss: 0.0035831909626722336
step: 520, loss: 0.0551680363714695
step: 530, loss: 0.057424820959568024
step: 540, loss: 0.01460654754191637
step: 550, loss: 0.0006393822841346264
step: 560, loss: 0.08778545260429382
step: 570, loss: 0.0016268600011244416
step: 580, loss: 0.05890613794326782
step: 590, loss: 0.05875880643725395
step: 600, loss: 0.07442042231559753
step: 610, loss: 0.04315507039427757
step: 620, loss: 0.07064509391784668
step: 630, loss: 0.03640525043010712
step: 640, loss: 0.07082731276750565
step: 650, loss: 0.04274483770132065
step: 660, loss: 0.017259463667869568
step: 670, loss: 0.014491939917206764
step: 680, loss: 0.08859219402074814
step: 690, loss: 0.03320616856217384
step: 700, loss: 0.038895972073078156
step: 710, loss: 0.05531417578458786
step: 720, loss: 0.000982022611424327
step: 730, loss: 0.026208488270640373
step: 740, loss: 0.02320764772593975
step: 750, loss: 0.0352446585893631
step: 760, loss: 0.027682403102517128
step: 770, loss: 0.027958910912275314
step: 780, loss: 0.05140575021505356
step: 790, loss: 0.04346044734120369
step: 800, loss: 0.043852798640728
step: 810, loss: 0.05933399498462677
step: 820, loss: 0.06780191510915756
step: 830, loss: 0.03221824765205383
step: 840, loss: 0.06739535182714462
step: 850, loss: 0.0009181532077491283
step: 860, loss: 0.00944722443819046
step: 870, loss: 0.08744096010923386
step: 880, loss: 0.03177962452173233
step: 890, loss: 0.058576636016368866
step: 900, loss: 0.07551989704370499
step: 910, loss: 0.011148203164339066
step: 920, loss: 9.029658394865692e-05
step: 930, loss: 0.0006349427858367562
step: 940, loss: 0.039220377802848816
step: 950, loss: 0.05753742903470993
step: 960, loss: 0.08166579902172089
step: 970, loss: 0.13756993412971497
step: 980, loss: 0.019992772489786148
step: 990, loss: 0.0549662746489048
step: 1000, loss: 0.00342951831407845
step: 1010, loss: 1.8771233953884803e-05
step: 1020, loss: 0.015524410642683506
step: 1030, loss: 0.038653403520584106
step: 1040, loss: 0.03651334345340729
step: 1050, loss: 0.10734055936336517
step: 1060, loss: 0.0669485330581665
step: 1070, loss: 0.02656947635114193
epoch 13: dev_f1=0.9364426154549611, f1=0.9331514324693042, best_f1=0.9316432775011317
step: 0, loss: 0.061355676501989365
step: 10, loss: 0.029149116948246956
step: 20, loss: 0.022780418395996094
step: 30, loss: 0.023349814116954803
step: 40, loss: 0.020219430327415466
step: 50, loss: 0.05472010374069214
step: 60, loss: 0.00037760878331027925
step: 70, loss: 0.031162263825535774
step: 80, loss: 0.28716716170310974
step: 90, loss: 0.007450431119650602
step: 100, loss: 0.03531230241060257
step: 110, loss: 0.026809504255652428
step: 120, loss: 0.049663905054330826
step: 130, loss: 0.023523086681962013
step: 140, loss: 7.541948434663936e-05
step: 150, loss: 0.0012054479448124766
step: 160, loss: 0.03235577046871185
step: 170, loss: 0.00018142524641007185
step: 180, loss: 0.018378054723143578
step: 190, loss: 0.03264069929718971
step: 200, loss: 0.0022233675699681044
step: 210, loss: 0.021901648491621017
step: 220, loss: 0.01846948266029358
step: 230, loss: 0.013564431108534336
step: 240, loss: 0.023792188614606857
step: 250, loss: 0.0019653604831546545
step: 260, loss: 0.039298638701438904
step: 270, loss: 0.004858100321143866
step: 280, loss: 0.05283389613032341
step: 290, loss: 0.00012197293835924938
step: 300, loss: 0.033360932022333145
step: 310, loss: 0.03187032788991928
step: 320, loss: 0.04676452651619911
step: 330, loss: 0.003537380136549473
step: 340, loss: 0.00038695192779414356
step: 350, loss: 0.0323609821498394
step: 360, loss: 0.027052447199821472
step: 370, loss: 0.03248390182852745
step: 380, loss: 0.018960582092404366
step: 390, loss: 0.05316948890686035
step: 400, loss: 0.03185216709971428
step: 410, loss: 0.036857448518276215
step: 420, loss: 0.015900153666734695
step: 430, loss: 0.0069168563932180405
step: 440, loss: 0.031046917662024498
step: 450, loss: 0.0014354564482346177
step: 460, loss: 0.0372520387172699
step: 470, loss: 0.026936467736959457
step: 480, loss: 0.00012203305232105777
step: 490, loss: 0.039677951484918594
step: 500, loss: 0.042868804186582565
step: 510, loss: 0.02011578530073166
step: 520, loss: 0.00027522625168785453
step: 530, loss: 0.08985143899917603
step: 540, loss: 0.020045790821313858
step: 550, loss: 0.10306153446435928
step: 560, loss: 0.060718610882759094
step: 570, loss: 0.030526723712682724
step: 580, loss: 0.01953570358455181
step: 590, loss: 0.03255912661552429
step: 600, loss: 0.11114576458930969
step: 610, loss: 0.07051253318786621
step: 620, loss: 0.04482823237776756
step: 630, loss: 0.02422523871064186
step: 640, loss: 0.054811082780361176
step: 650, loss: 0.16017748415470123
step: 660, loss: 0.043973956257104874
step: 670, loss: 0.0480395071208477
step: 680, loss: 0.0291494969278574
step: 690, loss: 0.017840635031461716
step: 700, loss: 0.0019495926098898053
step: 710, loss: 0.0010369204683229327
step: 720, loss: 0.022506529465317726
step: 730, loss: 0.12918493151664734
step: 740, loss: 0.04164756461977959
step: 750, loss: 0.03135638311505318
step: 760, loss: 2.772043262666557e-05
step: 770, loss: 0.0457555316388607
step: 780, loss: 0.0005069063627161086
step: 790, loss: 0.03218202665448189
step: 800, loss: 0.04887530207633972
step: 810, loss: 8.696360600879416e-05
step: 820, loss: 0.008902093395590782
step: 830, loss: 5.1820599765051156e-05
step: 840, loss: 2.7478979973238893e-05
step: 850, loss: 0.016063980758190155
step: 860, loss: 0.004385432228446007
step: 870, loss: 8.644044282846153e-05
step: 880, loss: 9.054604743141681e-05
step: 890, loss: 0.05297466367483139
step: 900, loss: 0.01448559295386076
step: 910, loss: 0.04876285791397095
step: 920, loss: 0.12149953097105026
step: 930, loss: 0.010480359196662903
step: 940, loss: 0.06631126254796982
step: 950, loss: 0.042315807193517685
step: 960, loss: 0.046653587371110916
step: 970, loss: 0.0707324966788292
step: 980, loss: 0.02036372944712639
step: 990, loss: 0.020435774698853493
step: 1000, loss: 0.04124045372009277
step: 1010, loss: 0.047862790524959564
step: 1020, loss: 0.09591064602136612
step: 1030, loss: 0.07016462087631226
step: 1040, loss: 0.03172154724597931
step: 1050, loss: 5.9251065977150574e-05
step: 1060, loss: 0.04233194515109062
step: 1070, loss: 0.04696515575051308
epoch 14: dev_f1=0.9318497913769124, f1=0.9304467987102718, best_f1=0.9316432775011317
step: 0, loss: 0.02730514109134674
step: 10, loss: 0.006334126926958561
step: 20, loss: 0.0854552611708641
step: 30, loss: 0.27312496304512024
step: 40, loss: 0.017147349193692207
step: 50, loss: 0.036641933023929596
step: 60, loss: 0.04316199570894241
step: 70, loss: 0.1614951193332672
step: 80, loss: 0.028579039499163628
step: 90, loss: 0.02456308715045452
step: 100, loss: 0.0018713109893724322
step: 110, loss: 0.05092581361532211
step: 120, loss: 0.10764014720916748
step: 130, loss: 0.01828896999359131
step: 140, loss: 0.04323265701532364
step: 150, loss: 0.035480841994285583
step: 160, loss: 0.02075483836233616
step: 170, loss: 0.0004783859185408801
step: 180, loss: 0.06095653772354126
step: 190, loss: 0.024162868037819862
step: 200, loss: 0.02870527096092701
step: 210, loss: 0.07745035737752914
step: 220, loss: 3.362807910889387e-05
step: 230, loss: 0.022332442924380302
step: 240, loss: 0.021329930052161217
step: 250, loss: 0.001522580161690712
step: 260, loss: 0.025334512814879417
step: 270, loss: 0.013543311506509781
step: 280, loss: 0.06879045814275742
step: 290, loss: 0.025747081264853477
step: 300, loss: 0.025604695081710815
step: 310, loss: 0.017763210460543633
step: 320, loss: 0.05723237246274948
step: 330, loss: 0.019754352048039436
step: 340, loss: 0.052480023354291916
step: 350, loss: 0.005498034879565239
step: 360, loss: 0.039376188069581985
step: 370, loss: 0.00011172933591296896
step: 380, loss: 0.00012889994832221419
step: 390, loss: 0.04914943873882294
step: 400, loss: 0.020946107804775238
step: 410, loss: 0.005452022422105074
step: 420, loss: 0.0003902043972630054
step: 430, loss: 0.07864594459533691
step: 440, loss: 0.029820291325449944
step: 450, loss: 0.03084384649991989
step: 460, loss: 0.030509568750858307
step: 470, loss: 0.0001944475807249546
step: 480, loss: 0.0014590859645977616
step: 490, loss: 0.00961911492049694
step: 500, loss: 0.06189974397420883
step: 510, loss: 0.037968676537275314
step: 520, loss: 0.051601894199848175
step: 530, loss: 2.9110864488757215e-05
step: 540, loss: 1.9846453142235987e-05
step: 550, loss: 0.017204130068421364
step: 560, loss: 0.00011103347060270607
step: 570, loss: 0.004528766497969627
step: 580, loss: 0.04276878386735916
step: 590, loss: 0.0003248725552111864
step: 600, loss: 0.04668769985437393
step: 610, loss: 0.057228147983551025
step: 620, loss: 0.02045821025967598
step: 630, loss: 0.0378761887550354
step: 640, loss: 0.0003851839283015579
step: 650, loss: 0.017320768907666206
step: 660, loss: 0.0005642245523631573
step: 670, loss: 0.00011029929737560451
step: 680, loss: 0.0179348886013031
step: 690, loss: 0.04527442157268524
step: 700, loss: 0.04486142843961716
step: 710, loss: 0.020581653341650963
step: 720, loss: 0.026997271925210953
step: 730, loss: 0.1215210109949112
step: 740, loss: 0.04532390087842941
step: 750, loss: 0.031257979571819305
step: 760, loss: 0.043211691081523895
step: 770, loss: 0.028592385351657867
step: 780, loss: 0.02993169240653515
step: 790, loss: 0.05355808883905411
step: 800, loss: 8.76971025718376e-05
step: 810, loss: 0.003473961493000388
step: 820, loss: 0.05181197449564934
step: 830, loss: 0.04646510258316994
step: 840, loss: 0.0012262541567906737
step: 850, loss: 0.00012587528908625245
step: 860, loss: 0.0013608470326289535
step: 870, loss: 0.004484678152948618
step: 880, loss: 0.00027362481341697276
step: 890, loss: 0.033628735691308975
step: 900, loss: 0.04709004983305931
step: 910, loss: 0.0004589050658978522
step: 920, loss: 6.503162876470014e-05
step: 930, loss: 0.01896890066564083
step: 940, loss: 0.02136325091123581
step: 950, loss: 8.433572656940669e-05
step: 960, loss: 0.05700327083468437
step: 970, loss: 0.05354221537709236
step: 980, loss: 0.03887384757399559
step: 990, loss: 0.045059047639369965
step: 1000, loss: 0.017946278676390648
step: 1010, loss: 0.03109261579811573
step: 1020, loss: 0.04148655757308006
step: 1030, loss: 0.056167155504226685
step: 1040, loss: 0.029315730556845665
step: 1050, loss: 0.051161400973796844
step: 1060, loss: 0.001256550196558237
step: 1070, loss: 4.228145189699717e-05
epoch 15: dev_f1=0.932904411764706, f1=0.9299129638112689, best_f1=0.9316432775011317
step: 0, loss: 0.00021518723224289715
step: 10, loss: 0.0406033918261528
step: 20, loss: 0.049484722316265106
step: 30, loss: 0.00011551348870852962
step: 40, loss: 0.035536374896764755
step: 50, loss: 0.003110328456386924
step: 60, loss: 0.014751031063497066
step: 70, loss: 0.029043251648545265
step: 80, loss: 0.018803151324391365
step: 90, loss: 0.0012304607080295682
step: 100, loss: 0.06600761413574219
step: 110, loss: 0.018009992316365242
step: 120, loss: 0.03365438058972359
step: 130, loss: 2.8055663278792053e-05
step: 140, loss: 0.03203054890036583
step: 150, loss: 0.05696361884474754
step: 160, loss: 0.009808588773012161
step: 170, loss: 0.01680411584675312
step: 180, loss: 0.03655022382736206
step: 190, loss: 0.034269265830516815
step: 200, loss: 0.019388357177376747
step: 210, loss: 0.022002195939421654
step: 220, loss: 0.03263137862086296
step: 230, loss: 3.760251638595946e-05
step: 240, loss: 0.012276056222617626
step: 250, loss: 0.17632357776165009
step: 260, loss: 1.7702146578812972e-05
step: 270, loss: 0.021374955773353577
step: 280, loss: 0.0422142893075943
step: 290, loss: 0.018108012154698372
step: 300, loss: 0.026291709393262863
step: 310, loss: 0.03248468413949013
step: 320, loss: 0.007067532278597355
step: 330, loss: 0.0402558408677578
step: 340, loss: 0.057742103934288025
step: 350, loss: 0.15573257207870483
step: 360, loss: 0.0015192520804703236
step: 370, loss: 6.491527892649174e-05
step: 380, loss: 0.07744815945625305
step: 390, loss: 0.0002671357069630176
step: 400, loss: 6.304722046479583e-05
step: 410, loss: 0.06433911621570587
step: 420, loss: 0.012803776189684868
step: 430, loss: 0.00021501090668607503
step: 440, loss: 0.07180751115083694
step: 450, loss: 0.03183251619338989
step: 460, loss: 0.000272097357083112
step: 470, loss: 0.006650663446635008
step: 480, loss: 0.049865275621414185
step: 490, loss: 0.0036845591384917498
step: 500, loss: 0.003969953395426273
step: 510, loss: 0.08196607977151871
step: 520, loss: 0.04631097614765167
step: 530, loss: 0.026157286018133163
step: 540, loss: 0.011607863940298557
step: 550, loss: 0.01569422148168087
step: 560, loss: 0.004688027314841747
step: 570, loss: 0.0389193557202816
step: 580, loss: 0.01685589924454689
step: 590, loss: 0.017128897830843925
step: 600, loss: 0.0014591396320611238
step: 610, loss: 0.04027159512042999
step: 620, loss: 0.0280702393501997
step: 630, loss: 0.001847272040322423
step: 640, loss: 0.04617580026388168
step: 650, loss: 0.017268788069486618
step: 660, loss: 0.019774142652750015
step: 670, loss: 0.1065865084528923
step: 680, loss: 0.016255224123597145
step: 690, loss: 0.0007931416621431708
step: 700, loss: 0.021500572562217712
step: 710, loss: 0.001948739169165492
step: 720, loss: 0.041983868926763535
step: 730, loss: 0.05877290293574333
step: 740, loss: 0.00020015175687149167
step: 750, loss: 0.06600847095251083
step: 760, loss: 0.0011179622961208224
step: 770, loss: 0.05152253806591034
step: 780, loss: 0.039668936282396317
step: 790, loss: 0.05078773573040962
step: 800, loss: 0.0004137860960327089
step: 810, loss: 0.019602753221988678
step: 820, loss: 0.01637616567313671
step: 830, loss: 0.026210829615592957
step: 840, loss: 4.540606460068375e-05
step: 850, loss: 0.0475519634783268
step: 860, loss: 0.06778332591056824
step: 870, loss: 0.018896663561463356
step: 880, loss: 0.03558975085616112
step: 890, loss: 0.034000296145677567
step: 900, loss: 0.006224057637155056
step: 910, loss: 0.028990967199206352
step: 920, loss: 0.038703810423612595
step: 930, loss: 0.03516678512096405
step: 940, loss: 0.11603923887014389
step: 950, loss: 0.020039798691868782
step: 960, loss: 0.000997814116999507
step: 970, loss: 0.0010922076180577278
step: 980, loss: 0.07676766812801361
step: 990, loss: 0.02153034321963787
step: 1000, loss: 0.0006763460114598274
step: 1010, loss: 0.021877221763134003
step: 1020, loss: 0.0018818433163687587
step: 1030, loss: 0.023438096046447754
step: 1040, loss: 0.11812679469585419
step: 1050, loss: 0.02667175978422165
step: 1060, loss: 0.03183579072356224
step: 1070, loss: 0.016405014321208
epoch 16: dev_f1=0.9284043051006083, f1=0.9322191272051997, best_f1=0.9316432775011317
step: 0, loss: 0.05128831788897514
step: 10, loss: 0.10196420550346375
step: 20, loss: 0.012920182198286057
step: 30, loss: 0.023173760622739792
step: 40, loss: 0.0007195380749180913
step: 50, loss: 0.023724384605884552
step: 60, loss: 0.01712062954902649
step: 70, loss: 3.0042558137211017e-05
step: 80, loss: 0.007032123859971762
step: 90, loss: 0.18750976026058197
step: 100, loss: 0.056435465812683105
step: 110, loss: 9.072631655726582e-05
step: 120, loss: 0.03282538056373596
step: 130, loss: 0.0011675216956064105
step: 140, loss: 0.047415390610694885
step: 150, loss: 0.02441125176846981
step: 160, loss: 0.06606657058000565
step: 170, loss: 6.975192809477448e-05
step: 180, loss: 0.02149726077914238
step: 190, loss: 0.0006954039563424885
step: 200, loss: 0.029665760695934296
step: 210, loss: 0.0007157293148338795
step: 220, loss: 0.022265590727329254
step: 230, loss: 0.027582800015807152
step: 240, loss: 0.012182594276964664
step: 250, loss: 0.00011855383490910754
step: 260, loss: 1.9280976630398072e-05
step: 270, loss: 0.02780843898653984
step: 280, loss: 0.019362030550837517
step: 290, loss: 0.015274259261786938
step: 300, loss: 0.0013760690344497561
step: 310, loss: 0.013427375815808773
step: 320, loss: 0.118587426841259
step: 330, loss: 0.0014140766579657793
step: 340, loss: 0.00027383811539039016
step: 350, loss: 0.0011793653247877955
step: 360, loss: 0.01724478416144848
step: 370, loss: 0.023525750264525414
step: 380, loss: 0.10259942710399628
step: 390, loss: 0.02392747439444065
step: 400, loss: 0.05447257310152054
step: 410, loss: 0.046077027916908264
step: 420, loss: 0.01800115779042244
step: 430, loss: 0.05778159946203232
step: 440, loss: 0.0357595719397068
step: 450, loss: 0.0152811910957098
step: 460, loss: 0.015687767416238785
step: 470, loss: 0.06895574927330017
step: 480, loss: 0.026244860142469406
step: 490, loss: 0.017076024785637856
step: 500, loss: 0.033278822898864746
step: 510, loss: 0.03331037238240242
step: 520, loss: 0.06906414777040482
step: 530, loss: 0.046689145267009735
step: 540, loss: 0.03401150181889534
step: 550, loss: 8.847006392898038e-05
step: 560, loss: 0.02146116830408573
step: 570, loss: 0.019147392362356186
step: 580, loss: 0.00016498009790666401
step: 590, loss: 2.051087358267978e-05
step: 600, loss: 0.06450677663087845
step: 610, loss: 2.0380593923619017e-05
step: 620, loss: 0.002500406000763178
step: 630, loss: 0.026179790496826172
step: 640, loss: 0.00021240519708953798
step: 650, loss: 0.014864279888570309
step: 660, loss: 0.00019709498155862093
step: 670, loss: 0.10244651138782501
step: 680, loss: 0.011876903474330902
step: 690, loss: 0.043739497661590576
step: 700, loss: 0.0807948112487793
step: 710, loss: 0.048245858401060104
step: 720, loss: 7.65928634791635e-05
step: 730, loss: 0.022994672879576683
step: 740, loss: 0.002416974399238825
step: 750, loss: 0.0004972828319296241
step: 760, loss: 0.036202091723680496
step: 770, loss: 0.005997596308588982
step: 780, loss: 0.009099846705794334
step: 790, loss: 0.02102757804095745
step: 800, loss: 0.024159979075193405
step: 810, loss: 0.04447083920240402
step: 820, loss: 0.0003659757203422487
step: 830, loss: 0.09325968474149704
step: 840, loss: 0.049564145505428314
step: 850, loss: 0.02508378028869629
step: 860, loss: 0.04720466583967209
step: 870, loss: 0.025441966950893402
step: 880, loss: 0.10218166559934616
step: 890, loss: 0.022020772099494934
step: 900, loss: 0.021687863394618034
step: 910, loss: 0.026692869141697884
step: 920, loss: 0.029990069568157196
step: 930, loss: 0.01886925846338272
step: 940, loss: 0.023283934220671654
step: 950, loss: 0.012718118727207184
step: 960, loss: 0.00015573772543575615
step: 970, loss: 0.04711126163601875
step: 980, loss: 0.05024651810526848
step: 990, loss: 0.009675159119069576
step: 1000, loss: 0.04154065623879433
step: 1010, loss: 0.043186869472265244
step: 1020, loss: 0.0004184737044852227
step: 1030, loss: 0.11036518961191177
step: 1040, loss: 0.056854166090488434
step: 1050, loss: 0.09011048078536987
step: 1060, loss: 0.0975981205701828
step: 1070, loss: 0.028231419622898102
epoch 17: dev_f1=0.9299242424242424, f1=0.9301227573182248, best_f1=0.9316432775011317
step: 0, loss: 8.760811033425853e-05
step: 10, loss: 0.0013787327334284782
step: 20, loss: 0.016193725168704987
step: 30, loss: 0.00018373322382103652
step: 40, loss: 0.019412143155932426
step: 50, loss: 0.035543520003557205
step: 60, loss: 9.864485036814585e-06
step: 70, loss: 0.06877026706933975
step: 80, loss: 0.003908795304596424
step: 90, loss: 0.08495862036943436
step: 100, loss: 0.01572505198419094
step: 110, loss: 0.03265335410833359
step: 120, loss: 0.04563844949007034
step: 130, loss: 0.0005358074558898807
step: 140, loss: 0.0727730542421341
step: 150, loss: 0.00011439899390097708
step: 160, loss: 0.025715256109833717
step: 170, loss: 0.029437074437737465
step: 180, loss: 0.024313023313879967
step: 190, loss: 0.0001508453715359792
step: 200, loss: 0.05728396400809288
step: 210, loss: 0.012872803956270218
step: 220, loss: 2.5433944756514393e-05
step: 230, loss: 2.1232941435300745e-05
step: 240, loss: 2.4093786123557948e-05
step: 250, loss: 1.5638475815649144e-05
step: 260, loss: 0.00014656124403700233
step: 270, loss: 0.0001277043775189668
step: 280, loss: 0.06731776148080826
step: 290, loss: 0.043365757912397385
step: 300, loss: 0.04181315004825592
step: 310, loss: 0.03432633355259895
step: 320, loss: 0.0006063718465156853
step: 330, loss: 0.06355234235525131
step: 340, loss: 0.04183565452694893
step: 350, loss: 0.02272949554026127
step: 360, loss: 0.0002473731874488294
step: 370, loss: 2.2462614651885815e-05
step: 380, loss: 0.06268230080604553
step: 390, loss: 0.04973270744085312
step: 400, loss: 0.048860784620046616
step: 410, loss: 0.006868754979223013
step: 420, loss: 0.025143787264823914
step: 430, loss: 0.056600891053676605
step: 440, loss: 0.03432035818696022
step: 450, loss: 0.02114463597536087
step: 460, loss: 0.049921948462724686
step: 470, loss: 0.027666443958878517
step: 480, loss: 0.058617714792490005
step: 490, loss: 0.00015507120406255126
step: 500, loss: 0.014743857085704803
step: 510, loss: 0.06130257248878479
step: 520, loss: 0.020073583349585533
step: 530, loss: 4.599938984028995e-05
step: 540, loss: 0.07662177085876465
step: 550, loss: 0.025985974818468094
step: 560, loss: 0.022032655775547028
step: 570, loss: 0.024080952629446983
step: 580, loss: 0.000519058492500335
step: 590, loss: 4.6167253458406776e-05
step: 600, loss: 2.751356987573672e-05
step: 610, loss: 0.06446731090545654
step: 620, loss: 0.0060626547783613205
step: 630, loss: 0.0001979750522878021
step: 640, loss: 0.020039420574903488
step: 650, loss: 0.08000515401363373
step: 660, loss: 0.048069067299366
step: 670, loss: 0.0009670815779827535
step: 680, loss: 0.04027658328413963
step: 690, loss: 0.00014471470785792917
step: 700, loss: 0.02768934704363346
step: 710, loss: 0.06613555550575256
step: 720, loss: 0.01728580892086029
step: 730, loss: 0.03283674642443657
step: 740, loss: 4.59588882222306e-05
step: 750, loss: 0.02406010776758194
step: 760, loss: 0.0372529961168766
step: 770, loss: 0.03657538443803787
step: 780, loss: 0.024088893085718155
step: 790, loss: 0.017565913498401642
step: 800, loss: 0.00038057033088989556
step: 810, loss: 0.0777469351887703
step: 820, loss: 0.0415484793484211
step: 830, loss: 0.01909293793141842
step: 840, loss: 0.022397099062800407
step: 850, loss: 0.000987174571491778
step: 860, loss: 0.045566316694021225
step: 870, loss: 0.013087260536849499
step: 880, loss: 0.01798682101070881
step: 890, loss: 0.0007938953931443393
step: 900, loss: 0.08448873460292816
step: 910, loss: 0.00014798161282669753
step: 920, loss: 1.926624827319756e-05
step: 930, loss: 0.027496129274368286
step: 940, loss: 0.0021252890583127737
step: 950, loss: 0.023515740409493446
step: 960, loss: 7.46050282032229e-05
step: 970, loss: 3.708276926772669e-05
step: 980, loss: 0.013840701431035995
step: 990, loss: 0.03405529260635376
step: 1000, loss: 0.009607266634702682
step: 1010, loss: 0.00013997771020513028
step: 1020, loss: 0.024881497025489807
step: 1030, loss: 4.732284651254304e-05
step: 1040, loss: 0.04705597087740898
step: 1050, loss: 0.024761635810136795
step: 1060, loss: 0.03886071965098381
step: 1070, loss: 4.5427197619574144e-05
epoch 18: dev_f1=0.9279026217228464, f1=0.9280074314909429, best_f1=0.9316432775011317
step: 0, loss: 0.06346282362937927
step: 10, loss: 7.156989886425436e-05
step: 20, loss: 0.02949187159538269
step: 30, loss: 0.04714767262339592
step: 40, loss: 0.037603385746479034
step: 50, loss: 1.3257977116154507e-05
step: 60, loss: 0.021533193066716194
step: 70, loss: 0.08134660124778748
step: 80, loss: 0.01887141913175583
step: 90, loss: 0.07740266621112823
step: 100, loss: 0.015311292372643948
step: 110, loss: 3.0084001991781406e-05
step: 120, loss: 0.0008902320405468345
step: 130, loss: 0.05201023817062378
step: 140, loss: 0.04218482971191406
step: 150, loss: 0.025132017210125923
step: 160, loss: 0.049505580216646194
step: 170, loss: 0.015626395121216774
step: 180, loss: 0.08072316646575928
step: 190, loss: 0.024999994784593582
step: 200, loss: 0.02802545763552189
step: 210, loss: 0.005012147594243288
step: 220, loss: 0.062489595264196396
step: 230, loss: 0.011323586106300354
step: 240, loss: 0.016299866139888763
step: 250, loss: 0.04653680697083473
step: 260, loss: 0.008803721517324448
step: 270, loss: 0.07294181734323502
step: 280, loss: 0.005132140126079321
step: 290, loss: 0.058071620762348175
step: 300, loss: 0.0026292218826711178
step: 310, loss: 0.032776955515146255
step: 320, loss: 0.0160648413002491
step: 330, loss: 0.0001817800512071699
step: 340, loss: 0.00012504550977610052
step: 350, loss: 0.04243653640151024
step: 360, loss: 0.023675644770264626
step: 370, loss: 0.07513522356748581
step: 380, loss: 0.042956214398145676
step: 390, loss: 0.020203011110424995
step: 400, loss: 0.012049635872244835
step: 410, loss: 0.05267391726374626
step: 420, loss: 0.06440068781375885
step: 430, loss: 0.023879704996943474
step: 440, loss: 0.03350309655070305
step: 450, loss: 0.023552512750029564
step: 460, loss: 0.046408381313085556
step: 470, loss: 0.06240900978446007
step: 480, loss: 0.0442577488720417
step: 490, loss: 6.304755515884608e-05
step: 500, loss: 0.0676552876830101
step: 510, loss: 0.020980359986424446
step: 520, loss: 0.027949782088398933
step: 530, loss: 0.07257495075464249
step: 540, loss: 0.033398162573575974
step: 550, loss: 0.039922215044498444
step: 560, loss: 2.0633462554542348e-05
step: 570, loss: 0.0010209528263658285
step: 580, loss: 0.066688172519207
step: 590, loss: 0.07535162568092346
step: 600, loss: 0.020797591656446457
step: 610, loss: 0.06649607419967651
step: 620, loss: 0.0001953651080839336
step: 630, loss: 0.00016814094851724803
step: 640, loss: 0.00023656997655052692
step: 650, loss: 0.0202920101583004
step: 660, loss: 4.5282155042514205e-05
step: 670, loss: 0.06430457532405853
step: 680, loss: 0.03709600865840912
step: 690, loss: 0.030157608911395073
step: 700, loss: 0.04675476625561714
step: 710, loss: 0.0001664815645199269
step: 720, loss: 0.039652157574892044
step: 730, loss: 0.048129044473171234
step: 740, loss: 0.05508005991578102
step: 750, loss: 0.00807354599237442
step: 760, loss: 0.03871672600507736
step: 770, loss: 0.023502053692936897
step: 780, loss: 0.013444424606859684
step: 790, loss: 0.04562503844499588
step: 800, loss: 0.052330806851387024
step: 810, loss: 1.3645498256664723e-05
step: 820, loss: 0.043444354087114334
step: 830, loss: 0.029649866744875908
step: 840, loss: 0.03058556094765663
step: 850, loss: 0.04587670415639877
step: 860, loss: 0.022236548364162445
step: 870, loss: 0.015872491523623466
step: 880, loss: 0.04767964035272598
step: 890, loss: 0.015783296898007393
step: 900, loss: 0.01903529465198517
step: 910, loss: 0.037563201040029526
step: 920, loss: 0.018956229090690613
step: 930, loss: 0.00021383390412665904
step: 940, loss: 0.021426904946565628
step: 950, loss: 0.07232366502285004
step: 960, loss: 0.024485165253281593
step: 970, loss: 0.021629629656672478
step: 980, loss: 0.04214806482195854
step: 990, loss: 0.021491697058081627
step: 1000, loss: 0.0005679764435626566
step: 1010, loss: 0.09598162770271301
step: 1020, loss: 0.034555014222860336
step: 1030, loss: 0.021893978118896484
step: 1040, loss: 8.2588434452191e-05
step: 1050, loss: 0.03519580885767937
step: 1060, loss: 0.02628764882683754
step: 1070, loss: 0.036232031881809235
epoch 19: dev_f1=0.9297347603536529, f1=0.9298245614035088, best_f1=0.9316432775011317
step: 0, loss: 0.00029490256565622985
step: 10, loss: 0.00894673727452755
step: 20, loss: 1.6264251826214604e-05
step: 30, loss: 2.0767622118000872e-05
step: 40, loss: 1.1227841241634451e-05
step: 50, loss: 0.021103523671627045
step: 60, loss: 0.03426774591207504
step: 70, loss: 0.012749161571264267
step: 80, loss: 2.0219897123752162e-05
step: 90, loss: 0.02215256355702877
step: 100, loss: 0.017777694389224052
step: 110, loss: 0.04990336298942566
step: 120, loss: 0.019288020208477974
step: 130, loss: 0.019261928275227547
step: 140, loss: 0.02377047762274742
step: 150, loss: 0.01439692359417677
step: 160, loss: 0.00013455953740049154
step: 170, loss: 0.019125305116176605
step: 180, loss: 0.043026912957429886
step: 190, loss: 2.2305830498225987e-05
step: 200, loss: 0.05166352912783623
step: 210, loss: 0.0008640240994282067
step: 220, loss: 0.0004996428615413606
step: 230, loss: 0.0001880224299384281
step: 240, loss: 0.07561849057674408
step: 250, loss: 0.00010469320841366425
step: 260, loss: 0.004400403704494238
step: 270, loss: 0.02880709245800972
step: 280, loss: 0.034966930747032166
step: 290, loss: 0.0004929961869493127
step: 300, loss: 0.049206335097551346
step: 310, loss: 1.1738150533346925e-05
step: 320, loss: 0.021899376064538956
step: 330, loss: 3.4208344004582614e-05
step: 340, loss: 0.08759286999702454
step: 350, loss: 0.0012487928615882993
step: 360, loss: 0.010257947258651257
step: 370, loss: 0.0022406219504773617
step: 380, loss: 0.06602030247449875
step: 390, loss: 0.027444349601864815
step: 400, loss: 0.04023773595690727
step: 410, loss: 0.02661723643541336
step: 420, loss: 2.3406402760883793e-05
step: 430, loss: 2.3795571905793622e-05
step: 440, loss: 0.03485599160194397
step: 450, loss: 0.02066446654498577
step: 460, loss: 0.0001462778018321842
step: 470, loss: 7.34263812773861e-05
step: 480, loss: 0.041074369102716446
step: 490, loss: 0.020991375669836998
step: 500, loss: 0.06625575572252274
step: 510, loss: 0.00011439142690505832
step: 520, loss: 0.00014356159954331815
step: 530, loss: 2.5115685275522992e-05
step: 540, loss: 0.023453498259186745
step: 550, loss: 0.014723001047968864
step: 560, loss: 0.0001168981907540001
step: 570, loss: 4.8749065172160044e-05
step: 580, loss: 1.6192989278351888e-05
step: 590, loss: 0.1963023543357849
step: 600, loss: 0.05750957876443863
step: 610, loss: 0.04382985830307007
step: 620, loss: 0.01495354063808918
step: 630, loss: 0.017302025109529495
step: 640, loss: 0.026763468980789185
step: 650, loss: 0.026137161999940872
step: 660, loss: 2.213744846812915e-05
step: 670, loss: 0.015398592688143253
step: 680, loss: 0.052414003759622574
step: 690, loss: 2.12850372918183e-05
step: 700, loss: 1.8789836758514866e-05
step: 710, loss: 0.022323234006762505
step: 720, loss: 0.018122849985957146
step: 730, loss: 0.05834660679101944
step: 740, loss: 0.00022236806398723274
step: 750, loss: 0.04210086166858673
step: 760, loss: 0.022778058424592018
step: 770, loss: 0.042142175137996674
step: 780, loss: 0.016820035874843597
step: 790, loss: 0.06286713480949402
step: 800, loss: 0.03590146452188492
step: 810, loss: 0.07909775525331497
step: 820, loss: 0.031162280589342117
step: 830, loss: 2.2529493435285985e-05
step: 840, loss: 0.009724141098558903
step: 850, loss: 0.0271595511585474
step: 860, loss: 0.01932678185403347
step: 870, loss: 0.04382244125008583
step: 880, loss: 0.00016589679580647498
step: 890, loss: 0.023919200524687767
step: 900, loss: 0.02223299629986286
step: 910, loss: 0.023417849093675613
step: 920, loss: 0.00029728413210250437
step: 930, loss: 0.023370107635855675
step: 940, loss: 0.021331124007701874
step: 950, loss: 0.05157258361577988
step: 960, loss: 0.019111914560198784
step: 970, loss: 0.034437838941812515
step: 980, loss: 0.05699437856674194
step: 990, loss: 0.02447623386979103
step: 1000, loss: 0.0026222080923616886
step: 1010, loss: 2.821316957124509e-05
step: 1020, loss: 0.02099340781569481
step: 1030, loss: 0.06983616948127747
step: 1040, loss: 0.0015968731604516506
step: 1050, loss: 0.004209738224744797
step: 1060, loss: 0.04322860762476921
step: 1070, loss: 1.3090228094370104e-05
epoch 20: dev_f1=0.9279999999999999, f1=0.9266697804764129, best_f1=0.9316432775011317
