cuda
Device: cuda
step: 0, loss: 0.7597442865371704
step: 10, loss: 0.37048542499542236
step: 20, loss: 0.3976574242115021
step: 30, loss: 0.40327054262161255
step: 40, loss: 0.5970680117607117
step: 50, loss: 0.490771621465683
step: 60, loss: 0.37844616174697876
step: 70, loss: 0.17393168807029724
step: 80, loss: 0.328525185585022
step: 90, loss: 0.25765272974967957
step: 100, loss: 0.29117482900619507
step: 110, loss: 0.16289253532886505
step: 120, loss: 0.15744350850582123
step: 130, loss: 0.11073701083660126
step: 140, loss: 0.19269129633903503
step: 150, loss: 0.04534139484167099
step: 160, loss: 0.12658920884132385
step: 170, loss: 0.20267313718795776
step: 180, loss: 0.21457405388355255
step: 190, loss: 0.21940810978412628
step: 200, loss: 0.107950858771801
step: 210, loss: 0.1335456818342209
step: 220, loss: 0.16687045991420746
step: 230, loss: 0.21143752336502075
step: 240, loss: 0.14090155065059662
step: 250, loss: 0.3911706209182739
step: 260, loss: 0.22406774759292603
step: 270, loss: 0.2524276673793793
step: 280, loss: 0.20256073772907257
step: 290, loss: 0.09501121938228607
step: 300, loss: 0.18098069727420807
step: 310, loss: 0.13930931687355042
step: 320, loss: 0.1501092165708542
step: 330, loss: 0.00450885109603405
step: 340, loss: 0.10252010822296143
step: 350, loss: 0.06895731389522552
step: 360, loss: 0.13384200632572174
step: 370, loss: 0.06779513508081436
step: 380, loss: 0.03763272613286972
step: 390, loss: 0.20327706634998322
step: 400, loss: 0.1029721274971962
step: 410, loss: 0.2088095247745514
step: 420, loss: 0.13614611327648163
step: 430, loss: 0.09096628427505493
step: 440, loss: 0.06308430433273315
step: 450, loss: 0.1350606083869934
step: 460, loss: 0.06927574425935745
step: 470, loss: 0.08783812075853348
step: 480, loss: 0.1527431607246399
step: 490, loss: 0.1528332531452179
step: 500, loss: 0.028557708486914635
step: 510, loss: 0.19758346676826477
step: 520, loss: 0.036049529910087585
step: 530, loss: 0.07835058122873306
step: 540, loss: 0.18343521654605865
step: 550, loss: 0.08971069008111954
step: 560, loss: 0.08368892967700958
step: 570, loss: 0.19574593007564545
step: 580, loss: 0.17911764979362488
step: 590, loss: 0.11633221805095673
step: 600, loss: 0.06542537361383438
step: 610, loss: 0.12736135721206665
step: 620, loss: 0.08620138466358185
step: 630, loss: 0.10608100891113281
step: 640, loss: 0.04774044454097748
step: 650, loss: 0.1355655938386917
step: 660, loss: 0.011519484221935272
step: 670, loss: 0.11327900737524033
step: 680, loss: 0.10078783333301544
step: 690, loss: 0.1333615779876709
step: 700, loss: 0.10619773715734482
step: 710, loss: 0.14841361343860626
step: 720, loss: 0.09966927021741867
step: 730, loss: 0.17483806610107422
step: 740, loss: 0.18445535004138947
step: 750, loss: 0.11280664056539536
step: 760, loss: 0.05875128507614136
step: 770, loss: 0.10184840857982635
step: 780, loss: 0.29412397742271423
step: 790, loss: 0.06863723695278168
step: 800, loss: 0.13918709754943848
step: 810, loss: 0.11770682036876678
step: 820, loss: 0.16862265765666962
step: 830, loss: 0.19769656658172607
step: 840, loss: 0.037220388650894165
step: 850, loss: 0.11342369765043259
step: 860, loss: 0.1433165818452835
step: 870, loss: 0.07584575563669205
step: 880, loss: 0.11012595146894455
step: 890, loss: 0.19625432789325714
step: 900, loss: 0.1684042364358902
step: 910, loss: 0.10781197994947433
step: 920, loss: 0.09705528616905212
step: 930, loss: 0.04360094666481018
step: 940, loss: 0.19700802862644196
step: 950, loss: 0.17447125911712646
step: 960, loss: 0.21599440276622772
step: 970, loss: 0.06168258190155029
step: 980, loss: 0.07822167128324509
step: 990, loss: 0.13638128340244293
step: 1000, loss: 0.16941796243190765
step: 1010, loss: 0.037708062678575516
step: 1020, loss: 0.06623663753271103
step: 1030, loss: 0.05934176966547966
step: 1040, loss: 0.024359501898288727
step: 1050, loss: 0.020481159910559654
step: 1060, loss: 0.07754752039909363
step: 1070, loss: 0.04898093640804291
epoch 1: dev_f1=0.9327808471454879, f1=0.933579335793358, best_f1=0.933579335793358
step: 0, loss: 0.1162661537528038
step: 10, loss: 0.14556609094142914
step: 20, loss: 0.21258963644504547
step: 30, loss: 0.09693805873394012
step: 40, loss: 0.06433258205652237
step: 50, loss: 0.1606513112783432
step: 60, loss: 0.0752653032541275
step: 70, loss: 0.0375334732234478
step: 80, loss: 0.07644331455230713
step: 90, loss: 0.12052930891513824
step: 100, loss: 0.06758292764425278
step: 110, loss: 0.1280423253774643
step: 120, loss: 0.11001675575971603
step: 130, loss: 0.12410122156143188
step: 140, loss: 0.16513843834400177
step: 150, loss: 0.04057717323303223
step: 160, loss: 0.1143164411187172
step: 170, loss: 0.08753210306167603
step: 180, loss: 0.2744317352771759
step: 190, loss: 0.09871317446231842
step: 200, loss: 0.04262230172753334
step: 210, loss: 0.0496845506131649
step: 220, loss: 0.09049496799707413
step: 230, loss: 0.05850622430443764
step: 240, loss: 0.1419466882944107
step: 250, loss: 0.14524471759796143
step: 260, loss: 0.04621683433651924
step: 270, loss: 0.023689908906817436
step: 280, loss: 0.2158026546239853
step: 290, loss: 0.033086132258176804
step: 300, loss: 0.09361954033374786
step: 310, loss: 0.254887193441391
step: 320, loss: 0.08122777938842773
step: 330, loss: 0.119319848716259
step: 340, loss: 0.07991297543048859
step: 350, loss: 0.027491599321365356
step: 360, loss: 0.11534258723258972
step: 370, loss: 0.0975695326924324
step: 380, loss: 0.07627293467521667
step: 390, loss: 0.0440557636320591
step: 400, loss: 0.09048035740852356
step: 410, loss: 0.1295793652534485
step: 420, loss: 0.06641184538602829
step: 430, loss: 0.06931869685649872
step: 440, loss: 0.13171975314617157
step: 450, loss: 0.019132865592837334
step: 460, loss: 0.08512922376394272
step: 470, loss: 0.08365511894226074
step: 480, loss: 0.06995482742786407
step: 490, loss: 0.07382459193468094
step: 500, loss: 0.018083559349179268
step: 510, loss: 0.2963968515396118
step: 520, loss: 0.06169949099421501
step: 530, loss: 0.05018353462219238
step: 540, loss: 0.10055777430534363
step: 550, loss: 0.022806406021118164
step: 560, loss: 0.08219867944717407
step: 570, loss: 0.10731099545955658
step: 580, loss: 0.10283099859952927
step: 590, loss: 0.14741624891757965
step: 600, loss: 0.015519853681325912
step: 610, loss: 0.0639820396900177
step: 620, loss: 0.12040506303310394
step: 630, loss: 0.1185840591788292
step: 640, loss: 0.042707379907369614
step: 650, loss: 0.14551757276058197
step: 660, loss: 0.04776570945978165
step: 670, loss: 0.21310149133205414
step: 680, loss: 0.07356678694486618
step: 690, loss: 0.02799944020807743
step: 700, loss: 0.09851112961769104
step: 710, loss: 0.07037221640348434
step: 720, loss: 0.09752268344163895
step: 730, loss: 0.0872577577829361
step: 740, loss: 0.07163827121257782
step: 750, loss: 0.11646812409162521
step: 760, loss: 0.03661339730024338
step: 770, loss: 0.12032926082611084
step: 780, loss: 0.11960907280445099
step: 790, loss: 0.04692002758383751
step: 800, loss: 0.048383597284555435
step: 810, loss: 0.03924388810992241
step: 820, loss: 0.04844710975885391
step: 830, loss: 0.12300606071949005
step: 840, loss: 0.05800047144293785
step: 850, loss: 0.05096300318837166
step: 860, loss: 0.063521608710289
step: 870, loss: 0.061703674495220184
step: 880, loss: 0.13483494520187378
step: 890, loss: 0.19829581677913666
step: 900, loss: 0.02306833676993847
step: 910, loss: 0.02430671826004982
step: 920, loss: 0.05417698994278908
step: 930, loss: 0.12366560101509094
step: 940, loss: 0.15151983499526978
step: 950, loss: 0.3156511187553406
step: 960, loss: 0.11590108275413513
step: 970, loss: 0.06895902007818222
step: 980, loss: 0.05215073004364967
step: 990, loss: 0.09861335903406143
step: 1000, loss: 0.08152753114700317
step: 1010, loss: 0.04146900027990341
step: 1020, loss: 0.08390838652849197
step: 1030, loss: 0.04782088100910187
step: 1040, loss: 0.1286913901567459
step: 1050, loss: 0.015158467926084995
step: 1060, loss: 0.11894164979457855
step: 1070, loss: 0.10478883236646652
epoch 2: dev_f1=0.9370693615066605, f1=0.9359742054352833, best_f1=0.9359742054352833
step: 0, loss: 0.053985845297575
step: 10, loss: 0.08369730412960052
step: 20, loss: 0.029295770451426506
step: 30, loss: 0.041657231748104095
step: 40, loss: 0.006804808508604765
step: 50, loss: 0.033183641731739044
step: 60, loss: 0.09894402325153351
step: 70, loss: 0.015520291402935982
step: 80, loss: 0.08764007687568665
step: 90, loss: 0.045283395797014236
step: 100, loss: 0.029312973842024803
step: 110, loss: 0.1189739853143692
step: 120, loss: 0.0904756486415863
step: 130, loss: 0.05262836068868637
step: 140, loss: 0.019580041989684105
step: 150, loss: 0.028049573302268982
step: 160, loss: 0.08050226420164108
step: 170, loss: 0.16930890083312988
step: 180, loss: 0.21160684525966644
step: 190, loss: 0.08143389970064163
step: 200, loss: 0.07321786880493164
step: 210, loss: 0.026589279994368553
step: 220, loss: 0.022752678021788597
step: 230, loss: 0.06080470606684685
step: 240, loss: 0.17782753705978394
step: 250, loss: 0.00561889773234725
step: 260, loss: 0.15405552089214325
step: 270, loss: 0.037246450781822205
step: 280, loss: 0.018414095044136047
step: 290, loss: 0.13075214624404907
step: 300, loss: 0.009876116178929806
step: 310, loss: 0.017604798078536987
step: 320, loss: 0.0572066567838192
step: 330, loss: 0.03475479409098625
step: 340, loss: 0.09688457101583481
step: 350, loss: 0.07731614261865616
step: 360, loss: 0.0003377731773070991
step: 370, loss: 0.003295936156064272
step: 380, loss: 0.15315961837768555
step: 390, loss: 0.09205411374568939
step: 400, loss: 0.12785406410694122
step: 410, loss: 0.07270655035972595
step: 420, loss: 0.04023372009396553
step: 430, loss: 0.059115346521139145
step: 440, loss: 0.04540444537997246
step: 450, loss: 0.04423925653100014
step: 460, loss: 0.08752443641424179
step: 470, loss: 0.13859915733337402
step: 480, loss: 0.04055830091238022
step: 490, loss: 0.027948033064603806
step: 500, loss: 0.034395843744277954
step: 510, loss: 0.022600233554840088
step: 520, loss: 0.17236942052841187
step: 530, loss: 0.009146654978394508
step: 540, loss: 0.07164139300584793
step: 550, loss: 0.08155450224876404
step: 560, loss: 0.12565936148166656
step: 570, loss: 0.16100525856018066
step: 580, loss: 0.1553196758031845
step: 590, loss: 0.12427371740341187
step: 600, loss: 0.03257124125957489
step: 610, loss: 0.06260579824447632
step: 620, loss: 0.10595116764307022
step: 630, loss: 0.3943500816822052
step: 640, loss: 0.029568200930953026
step: 650, loss: 0.07596497982740402
step: 660, loss: 0.15313968062400818
step: 670, loss: 0.07582338154315948
step: 680, loss: 0.007625881116837263
step: 690, loss: 0.10763515532016754
step: 700, loss: 0.025553926825523376
step: 710, loss: 0.01875489018857479
step: 720, loss: 0.060698941349983215
step: 730, loss: 0.07808306068181992
step: 740, loss: 0.056727949529886246
step: 750, loss: 0.0690745934844017
step: 760, loss: 0.1372619867324829
step: 770, loss: 0.12792328000068665
step: 780, loss: 0.05229354277253151
step: 790, loss: 0.02468465268611908
step: 800, loss: 0.04757792130112648
step: 810, loss: 0.08091035485267639
step: 820, loss: 0.0005008723237551749
step: 830, loss: 0.01963961496949196
step: 840, loss: 0.09456580132246017
step: 850, loss: 0.07617343217134476
step: 860, loss: 0.11178017407655716
step: 870, loss: 0.06726240366697311
step: 880, loss: 0.12379306554794312
step: 890, loss: 0.08068707585334778
step: 900, loss: 0.13575227558612823
step: 910, loss: 0.04839039221405983
step: 920, loss: 0.03854212909936905
step: 930, loss: 0.13602688908576965
step: 940, loss: 0.04424315690994263
step: 950, loss: 0.08530700206756592
step: 960, loss: 0.10800831764936447
step: 970, loss: 0.07988391816616058
step: 980, loss: 0.03340674191713333
step: 990, loss: 0.12697520852088928
step: 1000, loss: 0.08656363934278488
step: 1010, loss: 0.04784157872200012
step: 1020, loss: 0.15393057465553284
step: 1030, loss: 0.06748683750629425
step: 1040, loss: 0.052471261471509933
step: 1050, loss: 0.0897006094455719
step: 1060, loss: 0.12630631029605865
step: 1070, loss: 0.05593891441822052
epoch 3: dev_f1=0.9324699352451433, f1=0.9243619489559165, best_f1=0.9359742054352833
step: 0, loss: 0.031119074672460556
step: 10, loss: 0.0579322911798954
step: 20, loss: 0.045930784195661545
step: 30, loss: 0.06649493426084518
step: 40, loss: 0.12700492143630981
step: 50, loss: 0.07872427999973297
step: 60, loss: 0.09046243131160736
step: 70, loss: 0.03391285240650177
step: 80, loss: 0.1066572442650795
step: 90, loss: 0.08715475350618362
step: 100, loss: 0.01995239034295082
step: 110, loss: 0.026449939236044884
step: 120, loss: 0.02291056513786316
step: 130, loss: 0.016514908522367477
step: 140, loss: 0.015657145529985428
step: 150, loss: 0.07914728671312332
step: 160, loss: 0.0074983807280659676
step: 170, loss: 0.09860143810510635
step: 180, loss: 0.18094602227210999
step: 190, loss: 0.007283109240233898
step: 200, loss: 0.09854940325021744
step: 210, loss: 0.012994276359677315
step: 220, loss: 0.07599187642335892
step: 230, loss: 0.051614273339509964
step: 240, loss: 0.06032177060842514
step: 250, loss: 0.014668168500065804
step: 260, loss: 0.08264849334955215
step: 270, loss: 0.05722934752702713
step: 280, loss: 0.017268070951104164
step: 290, loss: 0.02747231535613537
step: 300, loss: 0.12716898322105408
step: 310, loss: 0.022176571190357208
step: 320, loss: 0.04730084910988808
step: 330, loss: 0.02115204557776451
step: 340, loss: 0.19429761171340942
step: 350, loss: 0.04442122206091881
step: 360, loss: 0.0418904609978199
step: 370, loss: 0.12915819883346558
step: 380, loss: 0.0326722227036953
step: 390, loss: 0.05812712013721466
step: 400, loss: 0.025561999529600143
step: 410, loss: 0.04763048514723778
step: 420, loss: 0.08791245520114899
step: 430, loss: 0.08272876590490341
step: 440, loss: 0.13893505930900574
step: 450, loss: 0.01944633014500141
step: 460, loss: 0.04455718398094177
step: 470, loss: 0.06989727169275284
step: 480, loss: 0.04120533540844917
step: 490, loss: 0.03865611553192139
step: 500, loss: 0.0344465933740139
step: 510, loss: 0.0654645785689354
step: 520, loss: 0.02520366944372654
step: 530, loss: 0.08297735452651978
step: 540, loss: 0.08648032695055008
step: 550, loss: 0.0833965539932251
step: 560, loss: 0.18750573694705963
step: 570, loss: 0.027705317363142967
step: 580, loss: 0.067130446434021
step: 590, loss: 0.0664476528763771
step: 600, loss: 0.1016530990600586
step: 610, loss: 0.08285769075155258
step: 620, loss: 0.019610486924648285
step: 630, loss: 0.0624593123793602
step: 640, loss: 0.010274983942508698
step: 650, loss: 0.10611873865127563
step: 660, loss: 0.015380846336483955
step: 670, loss: 0.123079814016819
step: 680, loss: 0.013259552419185638
step: 690, loss: 0.012346289120614529
step: 700, loss: 0.08387784659862518
step: 710, loss: 0.06731977313756943
step: 720, loss: 0.04719327390193939
step: 730, loss: 0.09355922788381577
step: 740, loss: 0.1128297671675682
step: 750, loss: 0.0763150230050087
step: 760, loss: 0.09952367842197418
step: 770, loss: 0.08877154439687729
step: 780, loss: 0.012643232010304928
step: 790, loss: 0.08117131888866425
step: 800, loss: 0.06669821590185165
step: 810, loss: 0.08838094025850296
step: 820, loss: 0.07300884276628494
step: 830, loss: 0.11375216394662857
step: 840, loss: 0.12486308813095093
step: 850, loss: 0.17412328720092773
step: 860, loss: 0.07535701990127563
step: 870, loss: 0.12720394134521484
step: 880, loss: 0.06122288852930069
step: 890, loss: 0.046211060136556625
step: 900, loss: 0.07210240513086319
step: 910, loss: 0.06782982498407364
step: 920, loss: 0.021190915256738663
step: 930, loss: 0.046773772686719894
step: 940, loss: 0.06532993167638779
step: 950, loss: 0.010219297371804714
step: 960, loss: 0.060284897685050964
step: 970, loss: 0.23562292754650116
step: 980, loss: 0.06287456303834915
step: 990, loss: 0.030979754403233528
step: 1000, loss: 0.021627558395266533
step: 1010, loss: 0.0207162257283926
step: 1020, loss: 0.015375702641904354
step: 1030, loss: 0.07849427312612534
step: 1040, loss: 0.1342836171388626
step: 1050, loss: 0.010593605227768421
step: 1060, loss: 0.05980156362056732
step: 1070, loss: 0.01968049257993698
epoch 4: dev_f1=0.9327846364883402, f1=0.9263351749539595, best_f1=0.9359742054352833
step: 0, loss: 0.10156150162220001
step: 10, loss: 0.05351937189698219
step: 20, loss: 0.004548924509435892
step: 30, loss: 0.006265902891755104
step: 40, loss: 0.23304395377635956
step: 50, loss: 0.01942478120326996
step: 60, loss: 0.22763888537883759
step: 70, loss: 0.0894952118396759
step: 80, loss: 0.029482394456863403
step: 90, loss: 0.03650836646556854
step: 100, loss: 0.07913445681333542
step: 110, loss: 0.10475727170705795
step: 120, loss: 0.041351549327373505
step: 130, loss: 0.06236972659826279
step: 140, loss: 0.06689894944429398
step: 150, loss: 0.10251858830451965
step: 160, loss: 0.09217103570699692
step: 170, loss: 0.0075849732384085655
step: 180, loss: 0.09432829171419144
step: 190, loss: 0.0442507341504097
step: 200, loss: 0.16887640953063965
step: 210, loss: 0.0645482987165451
step: 220, loss: 0.11233068257570267
step: 230, loss: 0.02694430761039257
step: 240, loss: 0.05816086381673813
step: 250, loss: 0.12569397687911987
step: 260, loss: 0.09835372865200043
step: 270, loss: 0.06511609256267548
step: 280, loss: 0.07701584696769714
step: 290, loss: 0.06665386259555817
step: 300, loss: 0.08772578835487366
step: 310, loss: 0.01866990141570568
step: 320, loss: 0.16882777214050293
step: 330, loss: 0.05726714804768562
step: 340, loss: 0.0867229625582695
step: 350, loss: 0.04254986345767975
step: 360, loss: 0.009588873013854027
step: 370, loss: 0.02630658447742462
step: 380, loss: 0.042665932327508926
step: 390, loss: 0.012697364203631878
step: 400, loss: 0.2369159311056137
step: 410, loss: 0.02133173495531082
step: 420, loss: 0.12250618636608124
step: 430, loss: 0.09053245186805725
step: 440, loss: 0.08483065664768219
step: 450, loss: 0.09784086048603058
step: 460, loss: 0.030934881418943405
step: 470, loss: 0.1163715124130249
step: 480, loss: 0.0667281225323677
step: 490, loss: 0.02113666757941246
step: 500, loss: 0.02043035253882408
step: 510, loss: 0.025533070787787437
step: 520, loss: 0.0740717202425003
step: 530, loss: 0.08479402959346771
step: 540, loss: 0.04916594550013542
step: 550, loss: 0.1248888373374939
step: 560, loss: 0.18842095136642456
step: 570, loss: 0.040337659418582916
step: 580, loss: 0.050074655562639236
step: 590, loss: 0.0971207544207573
step: 600, loss: 0.06715185940265656
step: 610, loss: 0.030257266014814377
step: 620, loss: 0.05008606240153313
step: 630, loss: 0.010059735737740993
step: 640, loss: 0.016522584483027458
step: 650, loss: 0.13099278509616852
step: 660, loss: 0.04532913491129875
step: 670, loss: 0.05672651156783104
step: 680, loss: 0.08096180111169815
step: 690, loss: 0.0323837473988533
step: 700, loss: 0.04109599441289902
step: 710, loss: 0.04280225932598114
step: 720, loss: 0.018726661801338196
step: 730, loss: 0.0487067811191082
step: 740, loss: 0.06906577199697495
step: 750, loss: 0.09401142597198486
step: 760, loss: 0.15922467410564423
step: 770, loss: 0.09775355458259583
step: 780, loss: 0.004843577276915312
step: 790, loss: 0.15202943980693817
step: 800, loss: 0.027737127617001534
step: 810, loss: 0.11095646023750305
step: 820, loss: 0.029425043612718582
step: 830, loss: 0.01826031506061554
step: 840, loss: 0.004067758563905954
step: 850, loss: 0.010021070018410683
step: 860, loss: 0.03657577559351921
step: 870, loss: 0.12449685484170914
step: 880, loss: 0.07632090896368027
step: 890, loss: 0.010570582933723927
step: 900, loss: 0.025912145152688026
step: 910, loss: 0.049612756818532944
step: 920, loss: 0.13483157753944397
step: 930, loss: 0.008808652870357037
step: 940, loss: 0.01910046674311161
step: 950, loss: 0.11842940002679825
step: 960, loss: 0.02155040204524994
step: 970, loss: 9.876284457277507e-05
step: 980, loss: 0.035447340458631516
step: 990, loss: 0.07503384351730347
step: 1000, loss: 0.030350223183631897
step: 1010, loss: 0.033360160887241364
step: 1020, loss: 0.09922817349433899
step: 1030, loss: 0.01366373896598816
step: 1040, loss: 0.10897315293550491
step: 1050, loss: 0.016064662486314774
step: 1060, loss: 0.07070831954479218
step: 1070, loss: 0.0846843421459198
epoch 5: dev_f1=0.9330210772833724, f1=0.9315838800374883, best_f1=0.9359742054352833
step: 0, loss: 0.053705908358097076
step: 10, loss: 0.10320517420768738
step: 20, loss: 0.06236228346824646
step: 30, loss: 0.10091421753168106
step: 40, loss: 0.3288090229034424
step: 50, loss: 0.11293987184762955
step: 60, loss: 0.00996720977127552
step: 70, loss: 0.021636370569467545
step: 80, loss: 0.011873220093548298
step: 90, loss: 0.017190124839544296
step: 100, loss: 0.09303505718708038
step: 110, loss: 0.020409993827342987
step: 120, loss: 0.1377042531967163
step: 130, loss: 0.01696695014834404
step: 140, loss: 0.03526078909635544
step: 150, loss: 0.0391041599214077
step: 160, loss: 0.12810486555099487
step: 170, loss: 0.00026151860947720706
step: 180, loss: 0.11309812217950821
step: 190, loss: 0.11104866117238998
step: 200, loss: 0.008905473165214062
step: 210, loss: 0.10684589296579361
step: 220, loss: 0.10669416934251785
step: 230, loss: 0.036575477570295334
step: 240, loss: 0.09029990434646606
step: 250, loss: 0.08527687937021255
step: 260, loss: 0.04628682881593704
step: 270, loss: 0.025148620828986168
step: 280, loss: 0.03290516510605812
step: 290, loss: 3.595878661144525e-05
step: 300, loss: 0.06447291374206543
step: 310, loss: 0.018718011677265167
step: 320, loss: 0.045300159603357315
step: 330, loss: 0.060047321021556854
step: 340, loss: 0.09616352617740631
step: 350, loss: 0.04391166940331459
step: 360, loss: 0.048320699483156204
step: 370, loss: 0.09015906602144241
step: 380, loss: 0.15558230876922607
step: 390, loss: 0.06042679026722908
step: 400, loss: 0.09854553639888763
step: 410, loss: 0.030703790485858917
step: 420, loss: 0.05755180865526199
step: 430, loss: 0.10021177679300308
step: 440, loss: 0.19523371756076813
step: 450, loss: 0.011916004121303558
step: 460, loss: 0.030763164162635803
step: 470, loss: 0.07264154404401779
step: 480, loss: 0.09665238112211227
step: 490, loss: 0.08605247735977173
step: 500, loss: 0.028383377939462662
step: 510, loss: 0.05817936360836029
step: 520, loss: 0.10223177075386047
step: 530, loss: 0.03657349571585655
step: 540, loss: 0.07306373864412308
step: 550, loss: 0.021554576233029366
step: 560, loss: 0.0586492195725441
step: 570, loss: 0.07847265899181366
step: 580, loss: 0.049678411334753036
step: 590, loss: 0.020559966564178467
step: 600, loss: 0.0745227038860321
step: 610, loss: 0.02131875604391098
step: 620, loss: 0.011581990867853165
step: 630, loss: 0.030494749546051025
step: 640, loss: 0.010302256792783737
step: 650, loss: 0.016350550577044487
step: 660, loss: 0.24538807570934296
step: 670, loss: 0.05993470549583435
step: 680, loss: 0.019044402986764908
step: 690, loss: 0.1308707594871521
step: 700, loss: 0.10991087555885315
step: 710, loss: 0.1449349969625473
step: 720, loss: 0.11502295732498169
step: 730, loss: 0.10142306238412857
step: 740, loss: 0.031103715300559998
step: 750, loss: 0.04037776589393616
step: 760, loss: 0.015047461725771427
step: 770, loss: 0.04177095741033554
step: 780, loss: 0.01037619635462761
step: 790, loss: 0.011472410522401333
step: 800, loss: 0.020669298246502876
step: 810, loss: 0.07722776383161545
step: 820, loss: 0.05034700036048889
step: 830, loss: 0.02012021280825138
step: 840, loss: 0.17214278876781464
step: 850, loss: 0.03199450671672821
step: 860, loss: 0.12328805774450302
step: 870, loss: 0.011086894199252129
step: 880, loss: 0.06680301576852798
step: 890, loss: 0.033703066408634186
step: 900, loss: 0.00472784461453557
step: 910, loss: 0.031203629449009895
step: 920, loss: 0.10857775062322617
step: 930, loss: 0.006270067300647497
step: 940, loss: 0.0683845728635788
step: 950, loss: 0.00615709600970149
step: 960, loss: 0.003706426825374365
step: 970, loss: 0.08459677547216415
step: 980, loss: 0.031762611120939255
step: 990, loss: 0.07590092718601227
step: 1000, loss: 0.01768171787261963
step: 1010, loss: 0.0751204565167427
step: 1020, loss: 0.1297922134399414
step: 1030, loss: 0.24773967266082764
step: 1040, loss: 0.042026109993457794
step: 1050, loss: 0.06072893366217613
step: 1060, loss: 0.07216472923755646
step: 1070, loss: 0.03816460818052292
epoch 6: dev_f1=0.9384191176470588, f1=0.9272811486799445, best_f1=0.9272811486799445
step: 0, loss: 0.04914112761616707
step: 10, loss: 0.07221250981092453
step: 20, loss: 0.11217000335454941
step: 30, loss: 0.0936727225780487
step: 40, loss: 0.06595945358276367
step: 50, loss: 0.07104803621768951
step: 60, loss: 0.06508146971464157
step: 70, loss: 0.029085572808980942
step: 80, loss: 0.008782871067523956
step: 90, loss: 0.05830586701631546
step: 100, loss: 0.09044694900512695
step: 110, loss: 0.05259091034531593
step: 120, loss: 0.0704125463962555
step: 130, loss: 0.013164760544896126
step: 140, loss: 0.07250826060771942
step: 150, loss: 0.10115174949169159
step: 160, loss: 0.05175122991204262
step: 170, loss: 0.02582145668566227
step: 180, loss: 0.07246968150138855
step: 190, loss: 0.005493032746016979
step: 200, loss: 0.012644474394619465
step: 210, loss: 0.050725311040878296
step: 220, loss: 0.009799597784876823
step: 230, loss: 0.13511110842227936
step: 240, loss: 0.09675903618335724
step: 250, loss: 0.021622080355882645
step: 260, loss: 0.03208662569522858
step: 270, loss: 0.4068773090839386
step: 280, loss: 0.04498220980167389
step: 290, loss: 0.02874116413295269
step: 300, loss: 0.10621175915002823
step: 310, loss: 0.12035005539655685
step: 320, loss: 0.10266568511724472
step: 330, loss: 0.005093319341540337
step: 340, loss: 0.07024381309747696
step: 350, loss: 0.03177376464009285
step: 360, loss: 0.002720280783250928
step: 370, loss: 0.023805920034646988
step: 380, loss: 0.1327844262123108
step: 390, loss: 0.06719918549060822
step: 400, loss: 0.06959882378578186
step: 410, loss: 0.032651565968990326
step: 420, loss: 0.03627810999751091
step: 430, loss: 0.006697052624076605
step: 440, loss: 0.02996867708861828
step: 450, loss: 0.019083553925156593
step: 460, loss: 0.0852811262011528
step: 470, loss: 0.013217630796134472
step: 480, loss: 0.07365499436855316
step: 490, loss: 0.13303259015083313
step: 500, loss: 0.020416416227817535
step: 510, loss: 0.018691517412662506
step: 520, loss: 0.0027643158100545406
step: 530, loss: 0.07863378524780273
step: 540, loss: 0.006451793015003204
step: 550, loss: 0.04291832819581032
step: 560, loss: 0.09048200398683548
step: 570, loss: 0.06215665861964226
step: 580, loss: 0.03258294612169266
step: 590, loss: 0.0016680044354870915
step: 600, loss: 0.016415094956755638
step: 610, loss: 0.03964622691273689
step: 620, loss: 0.04776690900325775
step: 630, loss: 0.034681789577007294
step: 640, loss: 0.02987733855843544
step: 650, loss: 0.02105002850294113
step: 660, loss: 0.011686837300658226
step: 670, loss: 0.014786545187234879
step: 680, loss: 0.049177005887031555
step: 690, loss: 0.10891160368919373
step: 700, loss: 0.02162262424826622
step: 710, loss: 0.05658050999045372
step: 720, loss: 0.0095203323289752
step: 730, loss: 0.21281880140304565
step: 740, loss: 0.05599914491176605
step: 750, loss: 0.021967554464936256
step: 760, loss: 0.0269284900277853
step: 770, loss: 0.002280554734170437
step: 780, loss: 0.1331879198551178
step: 790, loss: 0.015831995755434036
step: 800, loss: 0.07322751730680466
step: 810, loss: 0.11299759894609451
step: 820, loss: 0.06366778165102005
step: 830, loss: 0.05309532582759857
step: 840, loss: 0.1575722098350525
step: 850, loss: 0.10874369740486145
step: 860, loss: 0.02538316510617733
step: 870, loss: 0.02720489166676998
step: 880, loss: 0.005968178156763315
step: 890, loss: 0.029032401740550995
step: 900, loss: 0.09847190231084824
step: 910, loss: 0.030937841162085533
step: 920, loss: 0.01804705709218979
step: 930, loss: 0.014582020230591297
step: 940, loss: 0.11172066628932953
step: 950, loss: 0.06680172681808472
step: 960, loss: 0.07108931243419647
step: 970, loss: 0.0061827655881643295
step: 980, loss: 0.007712294347584248
step: 990, loss: 0.0246602650731802
step: 1000, loss: 0.03816083073616028
step: 1010, loss: 0.05427749827504158
step: 1020, loss: 0.039081327617168427
step: 1030, loss: 0.005563927348703146
step: 1040, loss: 0.007108104415237904
step: 1050, loss: 0.07787303626537323
step: 1060, loss: 0.01975873112678528
step: 1070, loss: 0.01989111118018627
epoch 7: dev_f1=0.9279197080291971, f1=0.9223034734917733, best_f1=0.9272811486799445
step: 0, loss: 0.025412283837795258
step: 10, loss: 0.03355702385306358
step: 20, loss: 0.05997812747955322
step: 30, loss: 0.09841451048851013
step: 40, loss: 0.06615980714559555
step: 50, loss: 0.0069754584692418575
step: 60, loss: 0.020280908793210983
step: 70, loss: 0.01391729898750782
step: 80, loss: 0.06312721967697144
step: 90, loss: 0.03725612908601761
step: 100, loss: 0.0697961375117302
step: 110, loss: 0.02417626604437828
step: 120, loss: 0.005565829109400511
step: 130, loss: 5.060552939539775e-05
step: 140, loss: 0.05858703702688217
step: 150, loss: 0.07650548964738846
step: 160, loss: 0.0802723839879036
step: 170, loss: 0.015156557783484459
step: 180, loss: 0.003817229298874736
step: 190, loss: 0.03420506417751312
step: 200, loss: 0.22707819938659668
step: 210, loss: 0.07360310107469559
step: 220, loss: 0.09455591440200806
step: 230, loss: 0.004659797064960003
step: 240, loss: 0.18757301568984985
step: 250, loss: 0.0703265592455864
step: 260, loss: 0.05254441872239113
step: 270, loss: 0.012446919456124306
step: 280, loss: 0.03915075212717056
step: 290, loss: 0.0035097752697765827
step: 300, loss: 0.01453250553458929
step: 310, loss: 0.09228266030550003
step: 320, loss: 0.010503104887902737
step: 330, loss: 0.009934179484844208
step: 340, loss: 0.009641817770898342
step: 350, loss: 0.10124246031045914
step: 360, loss: 0.01173360738903284
step: 370, loss: 0.05401120334863663
step: 380, loss: 0.03994626924395561
step: 390, loss: 0.12310612201690674
step: 400, loss: 0.020230015739798546
step: 410, loss: 0.27052444219589233
step: 420, loss: 0.08512552827596664
step: 430, loss: 0.019391637295484543
step: 440, loss: 0.12162692099809647
step: 450, loss: 0.0849619060754776
step: 460, loss: 0.0252591073513031
step: 470, loss: 0.011663412675261497
step: 480, loss: 0.014060958288609982
step: 490, loss: 0.0662970244884491
step: 500, loss: 0.04011908546090126
step: 510, loss: 0.04160749912261963
step: 520, loss: 0.1303330510854721
step: 530, loss: 0.01092640683054924
step: 540, loss: 0.05813591927289963
step: 550, loss: 0.021308816969394684
step: 560, loss: 0.06083692982792854
step: 570, loss: 0.02283111959695816
step: 580, loss: 0.005443028174340725
step: 590, loss: 0.004239944275468588
step: 600, loss: 0.09407759457826614
step: 610, loss: 0.04769500344991684
step: 620, loss: 0.053790442645549774
step: 630, loss: 0.03379616141319275
step: 640, loss: 0.015144862234592438
step: 650, loss: 0.012912086211144924
step: 660, loss: 0.0982954204082489
step: 670, loss: 0.02670162171125412
step: 680, loss: 0.006632793229073286
step: 690, loss: 0.15695714950561523
step: 700, loss: 0.08306785672903061
step: 710, loss: 0.05681196227669716
step: 720, loss: 0.07428161054849625
step: 730, loss: 0.12377877533435822
step: 740, loss: 0.09749685227870941
step: 750, loss: 0.03534899652004242
step: 760, loss: 0.014808401465415955
step: 770, loss: 0.02359602600336075
step: 780, loss: 0.07887036353349686
step: 790, loss: 0.07900185883045197
step: 800, loss: 0.005828212946653366
step: 810, loss: 0.09744953364133835
step: 820, loss: 0.037421535700559616
step: 830, loss: 0.17602811753749847
step: 840, loss: 0.03259426727890968
step: 850, loss: 0.018157918006181717
step: 860, loss: 0.02848876640200615
step: 870, loss: 0.006506685167551041
step: 880, loss: 0.010290885344147682
step: 890, loss: 0.08334409445524216
step: 900, loss: 0.098478302359581
step: 910, loss: 0.08446399867534637
step: 920, loss: 0.0986010953783989
step: 930, loss: 0.043565329164266586
step: 940, loss: 0.09200930595397949
step: 950, loss: 0.059437550604343414
step: 960, loss: 0.06766317784786224
step: 970, loss: 0.06718003004789352
step: 980, loss: 0.11726272851228714
step: 990, loss: 0.013538145460188389
step: 1000, loss: 0.06585228443145752
step: 1010, loss: 0.025203783065080643
step: 1020, loss: 0.004849160555750132
step: 1030, loss: 0.045188114047050476
step: 1040, loss: 0.03305932879447937
step: 1050, loss: 0.06525643914937973
step: 1060, loss: 0.09255810081958771
step: 1070, loss: 0.020398985594511032
epoch 8: dev_f1=0.9343955014058105, f1=0.9269427640763147, best_f1=0.9272811486799445
step: 0, loss: 0.06964240968227386
step: 10, loss: 0.04971541091799736
step: 20, loss: 0.04397064074873924
step: 30, loss: 0.03871926665306091
step: 40, loss: 0.03280213102698326
step: 50, loss: 0.05501328408718109
step: 60, loss: 0.004166378639638424
step: 70, loss: 0.02082310989499092
step: 80, loss: 0.0068375966511666775
step: 90, loss: 0.043045774102211
step: 100, loss: 0.08265428990125656
step: 110, loss: 0.027535710483789444
step: 120, loss: 0.027063539251685143
step: 130, loss: 0.012274210341274738
step: 140, loss: 0.029477795585989952
step: 150, loss: 0.06885578483343124
step: 160, loss: 0.21135862171649933
step: 170, loss: 0.04256201907992363
step: 180, loss: 0.03241684287786484
step: 190, loss: 0.029715342447161674
step: 200, loss: 0.011145837604999542
step: 210, loss: 0.07391420006752014
step: 220, loss: 0.09693525731563568
step: 230, loss: 0.06805077940225601
step: 240, loss: 0.05527787655591965
step: 250, loss: 0.0022629410959780216
step: 260, loss: 0.08887723088264465
step: 270, loss: 0.020270269364118576
step: 280, loss: 0.0335552804172039
step: 290, loss: 0.016127867624163628
step: 300, loss: 0.012294618412852287
step: 310, loss: 0.019808826968073845
step: 320, loss: 0.017540842294692993
step: 330, loss: 0.0438665896654129
step: 340, loss: 0.06355875730514526
step: 350, loss: 0.07747434824705124
step: 360, loss: 0.11322764307260513
step: 370, loss: 0.1339886486530304
step: 380, loss: 0.009276594035327435
step: 390, loss: 0.02426963485777378
step: 400, loss: 0.017621973529458046
step: 410, loss: 0.05724278837442398
step: 420, loss: 0.0036437150556594133
step: 430, loss: 0.002021931344643235
step: 440, loss: 0.16312959790229797
step: 450, loss: 0.03463933244347572
step: 460, loss: 0.0766991525888443
step: 470, loss: 0.020269310101866722
step: 480, loss: 0.0782727599143982
step: 490, loss: 0.045476511120796204
step: 500, loss: 0.046625230461359024
step: 510, loss: 0.05236239731311798
step: 520, loss: 0.013632165268063545
step: 530, loss: 0.03338899835944176
step: 540, loss: 0.022044243291020393
step: 550, loss: 0.1503349244594574
step: 560, loss: 0.09174251556396484
step: 570, loss: 0.02094268798828125
step: 580, loss: 0.15880602598190308
step: 590, loss: 0.06824426352977753
step: 600, loss: 0.07094842195510864
step: 610, loss: 0.1298116147518158
step: 620, loss: 0.05742529779672623
step: 630, loss: 0.019414357841014862
step: 640, loss: 0.12240326404571533
step: 650, loss: 0.04273330420255661
step: 660, loss: 0.06768396496772766
step: 670, loss: 0.08995971083641052
step: 680, loss: 0.018297240138053894
step: 690, loss: 0.05648253858089447
step: 700, loss: 0.07592356204986572
step: 710, loss: 3.171596472384408e-05
step: 720, loss: 0.030324093997478485
step: 730, loss: 0.0018539810553193092
step: 740, loss: 0.01481772493571043
step: 750, loss: 0.07164186239242554
step: 760, loss: 0.028877414762973785
step: 770, loss: 0.029334967955946922
step: 780, loss: 0.0634162500500679
step: 790, loss: 0.03410766273736954
step: 800, loss: 0.010619239881634712
step: 810, loss: 0.06167105585336685
step: 820, loss: 0.004231968894600868
step: 830, loss: 0.015424364246428013
step: 840, loss: 0.17253515124320984
step: 850, loss: 0.06709340959787369
step: 860, loss: 0.05921526625752449
step: 870, loss: 0.0169608686119318
step: 880, loss: 0.09521484375
step: 890, loss: 0.005824815481901169
step: 900, loss: 0.007276118267327547
step: 910, loss: 0.003395744599401951
step: 920, loss: 0.0016091851284727454
step: 930, loss: 0.017075417563319206
step: 940, loss: 0.0010074093006551266
step: 950, loss: 0.07999767363071442
step: 960, loss: 0.025575963780283928
step: 970, loss: 0.049876388162374496
step: 980, loss: 0.031739138066768646
step: 990, loss: 0.07769425213336945
step: 1000, loss: 0.02555898204445839
step: 1010, loss: 0.0023130890913307667
step: 1020, loss: 0.007237722165882587
step: 1030, loss: 0.10288498550653458
step: 1040, loss: 0.06163899973034859
step: 1050, loss: 0.010346285998821259
step: 1060, loss: 0.06474167108535767
step: 1070, loss: 0.0003129838441964239
epoch 9: dev_f1=0.9295134151887223, f1=0.9253187613843351, best_f1=0.9272811486799445
step: 0, loss: 0.10203520953655243
step: 10, loss: 0.0711425244808197
step: 20, loss: 0.04206492751836777
step: 30, loss: 0.03975946083664894
step: 40, loss: 0.019322482869029045
step: 50, loss: 0.03331713378429413
step: 60, loss: 0.009478596970438957
step: 70, loss: 0.13621164858341217
step: 80, loss: 0.029570570215582848
step: 90, loss: 0.058985885232686996
step: 100, loss: 0.06145515665411949
step: 110, loss: 0.1021895706653595
step: 120, loss: 0.004530306905508041
step: 130, loss: 0.001927547506056726
step: 140, loss: 0.0109100928530097
step: 150, loss: 0.0003653035091701895
step: 160, loss: 0.0061063505709171295
step: 170, loss: 0.02929924987256527
step: 180, loss: 0.04112736135721207
step: 190, loss: 0.08252450823783875
step: 200, loss: 0.02863907814025879
step: 210, loss: 0.07330121099948883
step: 220, loss: 0.04538045823574066
step: 230, loss: 0.07683081179857254
step: 240, loss: 0.0868980810046196
step: 250, loss: 0.044484302401542664
step: 260, loss: 0.030347691848874092
step: 270, loss: 4.5977605623193085e-05
step: 280, loss: 0.0060795885510742664
step: 290, loss: 0.09080370515584946
step: 300, loss: 9.38963275984861e-05
step: 310, loss: 0.06146811693906784
step: 320, loss: 0.011640268377959728
step: 330, loss: 0.06549552083015442
step: 340, loss: 0.006792159751057625
step: 350, loss: 0.03711963817477226
step: 360, loss: 0.09498627483844757
step: 370, loss: 0.021589986979961395
step: 380, loss: 0.041843168437480927
step: 390, loss: 0.04898206517100334
step: 400, loss: 0.03177092969417572
step: 410, loss: 0.058258846402168274
step: 420, loss: 0.047001615166664124
step: 430, loss: 0.001165142748504877
step: 440, loss: 0.02851288579404354
step: 450, loss: 0.056129831820726395
step: 460, loss: 0.10395520180463791
step: 470, loss: 0.02539093606173992
step: 480, loss: 0.06813666224479675
step: 490, loss: 0.03692902997136116
step: 500, loss: 0.05910448357462883
step: 510, loss: 0.0004363822808954865
step: 520, loss: 0.10473959892988205
step: 530, loss: 0.15344080328941345
step: 540, loss: 0.013376454822719097
step: 550, loss: 0.04358189180493355
step: 560, loss: 0.10714899748563766
step: 570, loss: 0.00032697737333364785
step: 580, loss: 0.006216199602931738
step: 590, loss: 0.013376464135944843
step: 600, loss: 0.023066382855176926
step: 610, loss: 0.10167496651411057
step: 620, loss: 0.04426412656903267
step: 630, loss: 0.0065069543197751045
step: 640, loss: 0.07281938940286636
step: 650, loss: 0.01703834719955921
step: 660, loss: 0.00527655053883791
step: 670, loss: 0.024752847850322723
step: 680, loss: 0.015711668878793716
step: 690, loss: 0.004475030582398176
step: 700, loss: 0.036096278578042984
step: 710, loss: 0.12108820676803589
step: 720, loss: 0.026691284030675888
step: 730, loss: 0.03571510687470436
step: 740, loss: 0.04963800311088562
step: 750, loss: 0.08353942632675171
step: 760, loss: 0.007464134134352207
step: 770, loss: 0.04467955604195595
step: 780, loss: 0.05349033325910568
step: 790, loss: 0.002482467796653509
step: 800, loss: 0.0193663090467453
step: 810, loss: 0.0011811824515461922
step: 820, loss: 0.1008043959736824
step: 830, loss: 0.03990564122796059
step: 840, loss: 0.007693867664784193
step: 850, loss: 0.012716115452349186
step: 860, loss: 0.07536695897579193
step: 870, loss: 0.022724805399775505
step: 880, loss: 0.0006189604173414409
step: 890, loss: 0.032439686357975006
step: 900, loss: 0.03071012906730175
step: 910, loss: 0.024834005162119865
step: 920, loss: 0.03919432312250137
step: 930, loss: 0.11402837932109833
step: 940, loss: 0.009313489310443401
step: 950, loss: 0.000465488585177809
step: 960, loss: 0.04027508571743965
step: 970, loss: 0.011679877527058125
step: 980, loss: 0.0719785988330841
step: 990, loss: 0.025435341522097588
step: 1000, loss: 0.02835826575756073
step: 1010, loss: 0.05133755877614021
step: 1020, loss: 0.000506742624565959
step: 1030, loss: 0.02362690307199955
step: 1040, loss: 0.14663366973400116
step: 1050, loss: 3.579922849894501e-05
step: 1060, loss: 0.011172208935022354
step: 1070, loss: 0.010970618575811386
epoch 10: dev_f1=0.9330232558139535, f1=0.933271547729379, best_f1=0.9272811486799445
step: 0, loss: 0.0380331352353096
step: 10, loss: 0.020365308970212936
step: 20, loss: 2.678693999769166e-05
step: 30, loss: 0.11417496204376221
step: 40, loss: 0.009324143640697002
step: 50, loss: 0.1322178840637207
step: 60, loss: 0.0662102997303009
step: 70, loss: 0.06951549649238586
step: 80, loss: 0.054603610187768936
step: 90, loss: 0.02160034328699112
step: 100, loss: 0.009924900718033314
step: 110, loss: 0.025377685204148293
step: 120, loss: 0.0449606329202652
step: 130, loss: 0.021066665649414062
step: 140, loss: 0.07736162096261978
step: 150, loss: 0.03541354089975357
step: 160, loss: 0.11158626526594162
step: 170, loss: 0.02720436453819275
step: 180, loss: 0.007555284071713686
step: 190, loss: 0.0009229389252141118
step: 200, loss: 0.009620600380003452
step: 210, loss: 0.01778358779847622
step: 220, loss: 0.002532216254621744
step: 230, loss: 0.03472810611128807
step: 240, loss: 0.01821569912135601
step: 250, loss: 0.06233786791563034
step: 260, loss: 0.0002047209709417075
step: 270, loss: 0.024154748767614365
step: 280, loss: 0.019110923632979393
step: 290, loss: 0.09966453909873962
step: 300, loss: 0.05761849507689476
step: 310, loss: 8.005810377653688e-05
step: 320, loss: 0.062425896525382996
step: 330, loss: 0.07810011506080627
step: 340, loss: 0.09065600484609604
step: 350, loss: 0.0011562110157683492
step: 360, loss: 0.0034606135450303555
step: 370, loss: 0.08237437903881073
step: 380, loss: 0.0074384440667927265
step: 390, loss: 0.039267398416996
step: 400, loss: 0.014798573218286037
step: 410, loss: 0.012249109335243702
step: 420, loss: 0.014329993166029453
step: 430, loss: 0.022826023399829865
step: 440, loss: 0.08398465067148209
step: 450, loss: 0.10400103032588959
step: 460, loss: 0.17023614048957825
step: 470, loss: 0.001790825161151588
step: 480, loss: 0.04094788804650307
step: 490, loss: 0.058741483837366104
step: 500, loss: 0.002372227841988206
step: 510, loss: 0.06777302920818329
step: 520, loss: 0.005011062137782574
step: 530, loss: 0.00031849442166276276
step: 540, loss: 0.11112643778324127
step: 550, loss: 0.011033718474209309
step: 560, loss: 0.0074297417886555195
step: 570, loss: 0.029947204515337944
step: 580, loss: 0.011583611369132996
step: 590, loss: 0.05738508328795433
step: 600, loss: 0.12972012162208557
step: 610, loss: 0.06548892706632614
step: 620, loss: 0.05424439162015915
step: 630, loss: 0.012521280907094479
step: 640, loss: 0.1329471319913864
step: 650, loss: 0.00010948747512884438
step: 660, loss: 0.05081188306212425
step: 670, loss: 0.08279663324356079
step: 680, loss: 0.027281904593110085
step: 690, loss: 0.015776077285408974
step: 700, loss: 0.05028354004025459
step: 710, loss: 0.023483065888285637
step: 720, loss: 0.036554381251335144
step: 730, loss: 0.026759600266814232
step: 740, loss: 0.044724930077791214
step: 750, loss: 0.0038189045153558254
step: 760, loss: 0.039402205497026443
step: 770, loss: 0.016434738412499428
step: 780, loss: 0.028811391443014145
step: 790, loss: 0.07774169743061066
step: 800, loss: 0.05946194753050804
step: 810, loss: 0.1005576103925705
step: 820, loss: 0.04365826025605202
step: 830, loss: 0.0601067990064621
step: 840, loss: 0.040750280022621155
step: 850, loss: 0.046257201582193375
step: 860, loss: 0.0017617791891098022
step: 870, loss: 0.025484811514616013
step: 880, loss: 0.0036119127180427313
step: 890, loss: 0.03094625100493431
step: 900, loss: 0.0037915350403636694
step: 910, loss: 0.07642350345849991
step: 920, loss: 0.0339927114546299
step: 930, loss: 0.07365523278713226
step: 940, loss: 0.024948742240667343
step: 950, loss: 0.06062958016991615
step: 960, loss: 0.008076905272901058
step: 970, loss: 0.010821927338838577
step: 980, loss: 0.029248343780636787
step: 990, loss: 0.010695443488657475
step: 1000, loss: 0.00010432740236865357
step: 1010, loss: 0.0002431096218060702
step: 1020, loss: 0.017154451459646225
step: 1030, loss: 0.061849307268857956
step: 1040, loss: 0.029743827879428864
step: 1050, loss: 0.02815493755042553
step: 1060, loss: 0.031969569623470306
step: 1070, loss: 0.020413799211382866
epoch 11: dev_f1=0.9319664492078286, f1=0.9302325581395349, best_f1=0.9272811486799445
step: 0, loss: 0.014469391666352749
step: 10, loss: 0.04677211493253708
step: 20, loss: 0.006658604368567467
step: 30, loss: 7.896039460320026e-05
step: 40, loss: 0.057956762611866
step: 50, loss: 0.008514666929841042
step: 60, loss: 0.058146823197603226
step: 70, loss: 0.011826935224235058
step: 80, loss: 0.0005468836170621216
step: 90, loss: 0.0006197614129632711
step: 100, loss: 0.008967926725745201
step: 110, loss: 0.010415899567306042
step: 120, loss: 0.0008986013708636165
step: 130, loss: 0.04147830978035927
step: 140, loss: 0.025234242901206017
step: 150, loss: 0.0601324662566185
step: 160, loss: 0.00022371897648554295
step: 170, loss: 0.0788707360625267
step: 180, loss: 0.0006701854290440679
step: 190, loss: 0.003169883508235216
step: 200, loss: 0.03187162056565285
step: 210, loss: 0.017867010086774826
step: 220, loss: 0.10126203298568726
step: 230, loss: 0.018956854939460754
step: 240, loss: 0.022492002695798874
step: 250, loss: 0.03254174441099167
step: 260, loss: 0.06145825982093811
step: 270, loss: 0.01176384836435318
step: 280, loss: 0.05817602574825287
step: 290, loss: 0.02399863675236702
step: 300, loss: 0.13227695226669312
step: 310, loss: 0.012606928125023842
step: 320, loss: 0.04221167042851448
step: 330, loss: 0.014918388798832893
step: 340, loss: 0.054700955748558044
step: 350, loss: 0.00018700610962696373
step: 360, loss: 0.005280235316604376
step: 370, loss: 0.0736522302031517
step: 380, loss: 0.01738627441227436
step: 390, loss: 0.045936595648527145
step: 400, loss: 0.012910708785057068
step: 410, loss: 0.046341679990291595
step: 420, loss: 0.07755908370018005
step: 430, loss: 0.04334397241473198
step: 440, loss: 0.08031217753887177
step: 450, loss: 0.025301333516836166
step: 460, loss: 0.029027950018644333
step: 470, loss: 0.00015235014143399894
step: 480, loss: 0.05728619918227196
step: 490, loss: 2.546496398281306e-05
step: 500, loss: 0.08056708425283432
step: 510, loss: 0.007355347741395235
step: 520, loss: 1.390633678965969e-05
step: 530, loss: 0.00014211356756277382
step: 540, loss: 0.0043786964379251
step: 550, loss: 0.03153069317340851
step: 560, loss: 0.0011361966608092189
step: 570, loss: 0.03346818685531616
step: 580, loss: 0.018705863505601883
step: 590, loss: 0.019334398210048676
step: 600, loss: 0.03242303803563118
step: 610, loss: 0.024131450802087784
step: 620, loss: 0.017615344375371933
step: 630, loss: 0.0668603703379631
step: 640, loss: 0.029682856053113937
step: 650, loss: 0.006939074490219355
step: 660, loss: 0.0725659728050232
step: 670, loss: 1.3589679838332813e-05
step: 680, loss: 0.04462253302335739
step: 690, loss: 0.06870224326848984
step: 700, loss: 0.0445932038128376
step: 710, loss: 0.029708383604884148
step: 720, loss: 0.09877193719148636
step: 730, loss: 0.04079648479819298
step: 740, loss: 0.07248873263597488
step: 750, loss: 0.006118675693869591
step: 760, loss: 0.0005056441295892
step: 770, loss: 0.05813019350171089
step: 780, loss: 0.029042666777968407
step: 790, loss: 0.11037952452898026
step: 800, loss: 0.0851190835237503
step: 810, loss: 0.04613722115755081
step: 820, loss: 0.00259873503819108
step: 830, loss: 0.017396865412592888
step: 840, loss: 0.00026254146359860897
step: 850, loss: 0.07355910539627075
step: 860, loss: 0.07462847977876663
step: 870, loss: 0.11074207723140717
step: 880, loss: 8.162923040799797e-05
step: 890, loss: 0.06265173852443695
step: 900, loss: 0.10543583333492279
step: 910, loss: 0.01570824719965458
step: 920, loss: 0.022284870967268944
step: 930, loss: 0.007654845714569092
step: 940, loss: 0.004132949281483889
step: 950, loss: 0.00046349759213626385
step: 960, loss: 0.048030078411102295
step: 970, loss: 0.016679875552654266
step: 980, loss: 0.00016794109251350164
step: 990, loss: 0.002062202198430896
step: 1000, loss: 0.03642053157091141
step: 1010, loss: 0.04357943311333656
step: 1020, loss: 0.03689340129494667
step: 1030, loss: 0.021499687805771828
step: 1040, loss: 0.02201402187347412
step: 1050, loss: 0.012608878314495087
step: 1060, loss: 0.04710116982460022
step: 1070, loss: 0.04025552049279213
epoch 12: dev_f1=0.9288040949278734, f1=0.9339491916859123, best_f1=0.9272811486799445
step: 0, loss: 0.0589531771838665
step: 10, loss: 0.01923057995736599
step: 20, loss: 0.052096400409936905
step: 30, loss: 0.02579999715089798
step: 40, loss: 0.053552594035863876
step: 50, loss: 0.02366359531879425
step: 60, loss: 0.07468865066766739
step: 70, loss: 0.03401317074894905
step: 80, loss: 0.0010130336740985513
step: 90, loss: 0.11419487744569778
step: 100, loss: 0.026797572150826454
step: 110, loss: 0.03724183514714241
step: 120, loss: 0.07095572352409363
step: 130, loss: 0.043059296905994415
step: 140, loss: 0.03962220996618271
step: 150, loss: 0.06372171640396118
step: 160, loss: 0.004377851728349924
step: 170, loss: 0.013687912374734879
step: 180, loss: 0.028027290478348732
step: 190, loss: 0.08208686113357544
step: 200, loss: 0.10044559836387634
step: 210, loss: 0.05084729567170143
step: 220, loss: 0.028903571888804436
step: 230, loss: 3.419347922317684e-05
step: 240, loss: 0.021823614835739136
step: 250, loss: 0.07437977194786072
step: 260, loss: 0.02324356511235237
step: 270, loss: 0.045276839286088943
step: 280, loss: 0.00035134065547026694
step: 290, loss: 0.01322790328413248
step: 300, loss: 0.030636927112936974
step: 310, loss: 0.04125967621803284
step: 320, loss: 0.05324491858482361
step: 330, loss: 0.03412923961877823
step: 340, loss: 0.10342380404472351
step: 350, loss: 0.03367026895284653
step: 360, loss: 0.0011068838648498058
step: 370, loss: 0.004540218506008387
step: 380, loss: 0.024706685915589333
step: 390, loss: 0.021565532311797142
step: 400, loss: 0.022053668275475502
step: 410, loss: 0.028136856853961945
step: 420, loss: 0.029284799471497536
step: 430, loss: 0.04155340418219566
step: 440, loss: 0.002130665583536029
step: 450, loss: 0.05079955235123634
step: 460, loss: 0.08512559533119202
step: 470, loss: 0.05680524557828903
step: 480, loss: 0.0003531098482199013
step: 490, loss: 0.05302362143993378
step: 500, loss: 0.02909216657280922
step: 510, loss: 9.460956789553165e-05
step: 520, loss: 0.06479378044605255
step: 530, loss: 0.013915328308939934
step: 540, loss: 0.02787645533680916
step: 550, loss: 0.022099941968917847
step: 560, loss: 9.96503331407439e-06
step: 570, loss: 0.0365372970700264
step: 580, loss: 0.00016083245282061398
step: 590, loss: 0.045652810484170914
step: 600, loss: 0.05342596396803856
step: 610, loss: 0.025026563555002213
step: 620, loss: 0.02827235497534275
step: 630, loss: 0.06185818836092949
step: 640, loss: 0.021282250061631203
step: 650, loss: 0.005093586631119251
step: 660, loss: 0.010944037698209286
step: 670, loss: 0.04728683829307556
step: 680, loss: 5.522778883459978e-05
step: 690, loss: 0.0018097232095897198
step: 700, loss: 0.00847013108432293
step: 710, loss: 0.02486015483736992
step: 720, loss: 0.03247574344277382
step: 730, loss: 1.4301051123766229e-05
step: 740, loss: 0.012776194140315056
step: 750, loss: 0.0262210201472044
step: 760, loss: 0.0345207080245018
step: 770, loss: 0.00012991907715331763
step: 780, loss: 0.1479429453611374
step: 790, loss: 0.0021648923866450787
step: 800, loss: 0.07827619463205338
step: 810, loss: 0.12752440571784973
step: 820, loss: 0.02045905590057373
step: 830, loss: 0.020855460315942764
step: 840, loss: 0.004978932905942202
step: 850, loss: 0.029166271910071373
step: 860, loss: 0.14598651230335236
step: 870, loss: 0.010816404595971107
step: 880, loss: 0.015187014825642109
step: 890, loss: 0.057604171335697174
step: 900, loss: 0.02515394613146782
step: 910, loss: 0.02959885261952877
step: 920, loss: 7.575985364383087e-05
step: 930, loss: 0.02301776595413685
step: 940, loss: 0.15475933253765106
step: 950, loss: 0.060755934566259384
step: 960, loss: 0.033858370035886765
step: 970, loss: 0.013491150923073292
step: 980, loss: 0.025059401988983154
step: 990, loss: 0.028279591351747513
step: 1000, loss: 0.03258013725280762
step: 1010, loss: 0.04957159236073494
step: 1020, loss: 0.07679266482591629
step: 1030, loss: 0.00042620315798558295
step: 1040, loss: 0.0002159934665542096
step: 1050, loss: 0.01265811175107956
step: 1060, loss: 4.289181742933579e-05
step: 1070, loss: 0.07409346848726273
epoch 13: dev_f1=0.9240324892498806, f1=0.9261363636363635, best_f1=0.9272811486799445
step: 0, loss: 0.026111016049981117
step: 10, loss: 0.01711837388575077
step: 20, loss: 0.03693860024213791
step: 30, loss: 1.5764318959554657e-05
step: 40, loss: 0.040486931800842285
step: 50, loss: 0.016082141548395157
step: 60, loss: 0.0008073046919889748
step: 70, loss: 0.04443209618330002
step: 80, loss: 1.5783651178935543e-05
step: 90, loss: 0.035263542085886
step: 100, loss: 0.04728589951992035
step: 110, loss: 0.05705160275101662
step: 120, loss: 0.023156464099884033
step: 130, loss: 0.00159962079487741
step: 140, loss: 0.07042846083641052
step: 150, loss: 0.02730989083647728
step: 160, loss: 0.01643560267984867
step: 170, loss: 0.07888322323560715
step: 180, loss: 0.0589301772415638
step: 190, loss: 0.03007861226797104
step: 200, loss: 0.010965550318360329
step: 210, loss: 0.02411111816763878
step: 220, loss: 0.058507952839136124
step: 230, loss: 0.03742319345474243
step: 240, loss: 0.09172561019659042
step: 250, loss: 0.005302350036799908
step: 260, loss: 0.03964332863688469
step: 270, loss: 0.013532234355807304
step: 280, loss: 0.00039506639586761594
step: 290, loss: 0.0002667296212166548
step: 300, loss: 0.04247378557920456
step: 310, loss: 0.021257519721984863
step: 320, loss: 0.044477496296167374
step: 330, loss: 0.035958435386419296
step: 340, loss: 0.040818728506565094
step: 350, loss: 0.011134850792586803
step: 360, loss: 0.00019295778474770486
step: 370, loss: 0.016448188573122025
step: 380, loss: 0.05593680962920189
step: 390, loss: 0.007395355962216854
step: 400, loss: 0.03380836546421051
step: 410, loss: 0.013336067087948322
step: 420, loss: 0.04148321971297264
step: 430, loss: 0.0008043581037782133
step: 440, loss: 0.01911109872162342
step: 450, loss: 0.01424994133412838
step: 460, loss: 0.009405972436070442
step: 470, loss: 0.08373650908470154
step: 480, loss: 0.07642161101102829
step: 490, loss: 0.029711415991187096
step: 500, loss: 0.001677025225944817
step: 510, loss: 0.008736596442759037
step: 520, loss: 0.01565675251185894
step: 530, loss: 0.04569239914417267
step: 540, loss: 0.018597818911075592
step: 550, loss: 9.856997166934889e-06
step: 560, loss: 0.017054840922355652
step: 570, loss: 0.015209201723337173
step: 580, loss: 0.00018820662808138877
step: 590, loss: 0.020560501143336296
step: 600, loss: 0.02842542715370655
step: 610, loss: 0.012277141213417053
step: 620, loss: 0.0056882635690271854
step: 630, loss: 0.028923090547323227
step: 640, loss: 0.028163544833660126
step: 650, loss: 0.004363064654171467
step: 660, loss: 0.04125434532761574
step: 670, loss: 0.0016618022928014398
step: 680, loss: 0.05202251672744751
step: 690, loss: 0.03595208749175072
step: 700, loss: 2.2107275071903132e-05
step: 710, loss: 0.05142185091972351
step: 720, loss: 0.06862892210483551
step: 730, loss: 0.0007306291372515261
step: 740, loss: 0.027536261826753616
step: 750, loss: 0.0022558937780559063
step: 760, loss: 0.06317535787820816
step: 770, loss: 0.020433107390999794
step: 780, loss: 1.7671518435236067e-05
step: 790, loss: 0.05086958035826683
step: 800, loss: 0.002146465703845024
step: 810, loss: 0.10626047849655151
step: 820, loss: 0.01786891371011734
step: 830, loss: 0.001521273865364492
step: 840, loss: 3.31851260853e-05
step: 850, loss: 0.017871761694550514
step: 860, loss: 0.06153532490134239
step: 870, loss: 0.023339131847023964
step: 880, loss: 0.11025455594062805
step: 890, loss: 0.06213078647851944
step: 900, loss: 0.17787133157253265
step: 910, loss: 0.004162067547440529
step: 920, loss: 0.005995381623506546
step: 930, loss: 0.09023334830999374
step: 940, loss: 0.0020426190458238125
step: 950, loss: 0.003016670700162649
step: 960, loss: 0.03722348064184189
step: 970, loss: 0.00026035108021460474
step: 980, loss: 0.0008436264470219612
step: 990, loss: 0.0026208157651126385
step: 1000, loss: 0.029874267056584358
step: 1010, loss: 0.05404762551188469
step: 1020, loss: 0.029345398768782616
step: 1030, loss: 0.020910004153847694
step: 1040, loss: 0.04737066477537155
step: 1050, loss: 0.047093480825424194
step: 1060, loss: 0.00048675667494535446
step: 1070, loss: 0.022667255252599716
epoch 14: dev_f1=0.9286376274328081, f1=0.9273229070837167, best_f1=0.9272811486799445
step: 0, loss: 0.005677567794919014
step: 10, loss: 0.020802192389965057
step: 20, loss: 0.0339830219745636
step: 30, loss: 0.010136237367987633
step: 40, loss: 0.034516897052526474
step: 50, loss: 0.01548656914383173
step: 60, loss: 4.3280400859657675e-05
step: 70, loss: 0.04587269946932793
step: 80, loss: 0.02110131084918976
step: 90, loss: 0.03358554467558861
step: 100, loss: 0.021996621042490005
step: 110, loss: 0.007706122472882271
step: 120, loss: 0.02756918966770172
step: 130, loss: 0.040497198700904846
step: 140, loss: 0.010951277799904346
step: 150, loss: 0.01850833185017109
step: 160, loss: 0.05261645466089249
step: 170, loss: 0.00012949622760061175
step: 180, loss: 0.01644725352525711
step: 190, loss: 0.03077298402786255
step: 200, loss: 4.1867733671097085e-05
step: 210, loss: 0.061883050948381424
step: 220, loss: 0.0539095513522625
step: 230, loss: 4.185489524388686e-05
step: 240, loss: 0.00017070148896891624
step: 250, loss: 0.003276584902778268
step: 260, loss: 0.05968017876148224
step: 270, loss: 0.060484688729047775
step: 280, loss: 0.07848392426967621
step: 290, loss: 0.035548873245716095
step: 300, loss: 0.04663936421275139
step: 310, loss: 0.08608755469322205
step: 320, loss: 0.11811067163944244
step: 330, loss: 0.021724648773670197
step: 340, loss: 0.0011327676475048065
step: 350, loss: 1.4979053958086297e-05
step: 360, loss: 0.066170334815979
step: 370, loss: 0.017091285437345505
step: 380, loss: 0.02163311094045639
step: 390, loss: 0.04449671879410744
step: 400, loss: 0.02916903793811798
step: 410, loss: 0.05363816022872925
step: 420, loss: 2.9247241400298662e-05
step: 430, loss: 1.5794563296367414e-05
step: 440, loss: 0.06066896766424179
step: 450, loss: 0.002205914817750454
step: 460, loss: 0.0007328231004066765
step: 470, loss: 0.03706315904855728
step: 480, loss: 6.193169974721968e-05
step: 490, loss: 0.0005113496445119381
step: 500, loss: 0.021042607724666595
step: 510, loss: 0.0047220150008797646
step: 520, loss: 0.016667069867253304
step: 530, loss: 7.003795326454565e-05
step: 540, loss: 0.06800353527069092
step: 550, loss: 0.019471099600195885
step: 560, loss: 0.02698615752160549
step: 570, loss: 0.024551184847950935
step: 580, loss: 0.02218514122068882
step: 590, loss: 0.009210034273564816
step: 600, loss: 0.05590614303946495
step: 610, loss: 0.21111659705638885
step: 620, loss: 0.00037570082349702716
step: 630, loss: 0.009790889918804169
step: 640, loss: 0.02132513001561165
step: 650, loss: 0.015495328232645988
step: 660, loss: 0.0726209431886673
step: 670, loss: 0.020276302471756935
step: 680, loss: 0.03365441411733627
step: 690, loss: 0.0424569696187973
step: 700, loss: 0.01602870784699917
step: 710, loss: 0.11229380965232849
step: 720, loss: 0.07551667094230652
step: 730, loss: 0.0209319107234478
step: 740, loss: 0.00035698612919077277
step: 750, loss: 0.02863178588449955
step: 760, loss: 0.04642217606306076
step: 770, loss: 0.051594000309705734
step: 780, loss: 0.05597369745373726
step: 790, loss: 0.03270971029996872
step: 800, loss: 0.05731009319424629
step: 810, loss: 0.08105644583702087
step: 820, loss: 0.026789184659719467
step: 830, loss: 0.06280948221683502
step: 840, loss: 0.03839173913002014
step: 850, loss: 0.014585030265152454
step: 860, loss: 0.01875893399119377
step: 870, loss: 0.040532588958740234
step: 880, loss: 0.02708193100988865
step: 890, loss: 0.06769402325153351
step: 900, loss: 0.020738588646054268
step: 910, loss: 0.04958505183458328
step: 920, loss: 0.017704371362924576
step: 930, loss: 0.006727053318172693
step: 940, loss: 1.7593947632121854e-05
step: 950, loss: 0.0003056971763726324
step: 960, loss: 0.013403935357928276
step: 970, loss: 0.02541915699839592
step: 980, loss: 0.03436215594410896
step: 990, loss: 0.03207436949014664
step: 1000, loss: 0.03233537822961807
step: 1010, loss: 0.0268050916492939
step: 1020, loss: 0.11690123379230499
step: 1030, loss: 0.04889432340860367
step: 1040, loss: 0.036293890327215195
step: 1050, loss: 0.023419929668307304
step: 1060, loss: 0.03876824676990509
step: 1070, loss: 0.0120254997164011
epoch 15: dev_f1=0.9323515876668201, f1=0.9246231155778893, best_f1=0.9272811486799445
step: 0, loss: 0.013170301914215088
step: 10, loss: 0.02565895766019821
step: 20, loss: 0.04055127501487732
step: 30, loss: 0.029117345809936523
step: 40, loss: 0.015907369554042816
step: 50, loss: 0.03408082202076912
step: 60, loss: 0.0003734255151357502
step: 70, loss: 0.03118607960641384
step: 80, loss: 0.0821407362818718
step: 90, loss: 0.024693211540579796
step: 100, loss: 0.000517230131663382
step: 110, loss: 0.00010601806570775807
step: 120, loss: 0.023641172796487808
step: 130, loss: 0.049981337040662766
step: 140, loss: 0.002897266298532486
step: 150, loss: 0.02051987498998642
step: 160, loss: 0.045803796499967575
step: 170, loss: 0.010663919150829315
step: 180, loss: 2.7312391466693953e-05
step: 190, loss: 0.002932826057076454
step: 200, loss: 0.05687623843550682
step: 210, loss: 0.031160689890384674
step: 220, loss: 0.02052677981555462
step: 230, loss: 0.019733455032110214
step: 240, loss: 0.030488844960927963
step: 250, loss: 0.030213957652449608
step: 260, loss: 0.014570310711860657
step: 270, loss: 0.029483944177627563
step: 280, loss: 2.651810609677341e-05
step: 290, loss: 0.02189771458506584
step: 300, loss: 0.048717521131038666
step: 310, loss: 0.022274315357208252
step: 320, loss: 0.00025538538466207683
step: 330, loss: 0.021854186430573463
step: 340, loss: 0.004264893941581249
step: 350, loss: 0.008483338169753551
step: 360, loss: 0.018110103905200958
step: 370, loss: 0.025575457140803337
step: 380, loss: 0.004422443453222513
step: 390, loss: 0.02770022302865982
step: 400, loss: 0.07988400757312775
step: 410, loss: 0.08542069792747498
step: 420, loss: 0.06062775105237961
step: 430, loss: 0.004836439620703459
step: 440, loss: 0.02174554206430912
step: 450, loss: 0.00030803147819824517
step: 460, loss: 0.055352725088596344
step: 470, loss: 0.04725423455238342
step: 480, loss: 0.040985189378261566
step: 490, loss: 0.02368876524269581
step: 500, loss: 0.00018330241437070072
step: 510, loss: 0.02664860710501671
step: 520, loss: 7.066024409141392e-05
step: 530, loss: 0.0920286774635315
step: 540, loss: 0.04286880046129227
step: 550, loss: 0.026001283898949623
step: 560, loss: 0.03577696904540062
step: 570, loss: 0.05481541156768799
step: 580, loss: 8.329690899699926e-06
step: 590, loss: 0.04591023921966553
step: 600, loss: 3.649622522061691e-05
step: 610, loss: 0.030798913910984993
step: 620, loss: 0.000144010700751096
step: 630, loss: 0.06125318259000778
step: 640, loss: 0.0005649375962093472
step: 650, loss: 0.25883233547210693
step: 660, loss: 0.06199479103088379
step: 670, loss: 0.013738888315856457
step: 680, loss: 0.061986956745386124
step: 690, loss: 0.03810575231909752
step: 700, loss: 0.0001213502764585428
step: 710, loss: 0.04702240601181984
step: 720, loss: 0.04920356720685959
step: 730, loss: 0.0007410675752907991
step: 740, loss: 0.0815533921122551
step: 750, loss: 0.119486503303051
step: 760, loss: 0.06351267546415329
step: 770, loss: 0.0003012825327459723
step: 780, loss: 0.028819918632507324
step: 790, loss: 0.010610205121338367
step: 800, loss: 0.04208986833691597
step: 810, loss: 2.5643133994890377e-05
step: 820, loss: 0.11836909502744675
step: 830, loss: 0.0997554212808609
step: 840, loss: 0.021597377955913544
step: 850, loss: 3.644101525424048e-05
step: 860, loss: 0.09186694771051407
step: 870, loss: 0.005192701239138842
step: 880, loss: 3.389521225471981e-05
step: 890, loss: 0.08399613201618195
step: 900, loss: 0.039336372166872025
step: 910, loss: 0.037708546966314316
step: 920, loss: 0.004006466828286648
step: 930, loss: 0.021506059914827347
step: 940, loss: 0.046437494456768036
step: 950, loss: 0.003442628774791956
step: 960, loss: 0.0365101583302021
step: 970, loss: 0.00047002790961414576
step: 980, loss: 0.021311400458216667
step: 990, loss: 0.05194215476512909
step: 1000, loss: 0.024143565446138382
step: 1010, loss: 0.04616999998688698
step: 1020, loss: 0.043114177882671356
step: 1030, loss: 0.00314871734008193
step: 1040, loss: 0.07680235058069229
step: 1050, loss: 0.11325468122959137
step: 1060, loss: 0.00020924942509736866
step: 1070, loss: 0.0630059465765953
epoch 16: dev_f1=0.9319568277803848, f1=0.9230769230769231, best_f1=0.9272811486799445
step: 0, loss: 0.04126962274312973
step: 10, loss: 0.017590586096048355
step: 20, loss: 0.04912329092621803
step: 30, loss: 3.341812043800019e-05
step: 40, loss: 0.04254591464996338
step: 50, loss: 0.04338892176747322
step: 60, loss: 0.0016542550874873996
step: 70, loss: 2.426719402137678e-05
step: 80, loss: 0.033631037920713425
step: 90, loss: 0.012329818680882454
step: 100, loss: 0.022779598832130432
step: 110, loss: 0.04186386987566948
step: 120, loss: 0.05406343564391136
step: 130, loss: 0.00045976255205459893
step: 140, loss: 0.03894205763936043
step: 150, loss: 0.0008599732536822557
step: 160, loss: 0.025519179180264473
step: 170, loss: 0.04755157232284546
step: 180, loss: 0.0032971478067338467
step: 190, loss: 0.026355654001235962
step: 200, loss: 0.02801308035850525
step: 210, loss: 9.097091606236063e-06
step: 220, loss: 0.07419101148843765
step: 230, loss: 0.007505552377551794
step: 240, loss: 4.893520235782489e-05
step: 250, loss: 0.0332048274576664
step: 260, loss: 0.023357084020972252
step: 270, loss: 0.05574876070022583
step: 280, loss: 0.03664737939834595
step: 290, loss: 0.0003797388926614076
step: 300, loss: 3.6634275602409616e-05
step: 310, loss: 0.022480811923742294
step: 320, loss: 0.028428664430975914
step: 330, loss: 0.01694481447339058
step: 340, loss: 0.036904070526361465
step: 350, loss: 0.004647021181881428
step: 360, loss: 0.00014314828149508685
step: 370, loss: 0.17472299933433533
step: 380, loss: 5.325392339727841e-05
step: 390, loss: 0.044016171246767044
step: 400, loss: 0.0001583847333677113
step: 410, loss: 0.038213908672332764
step: 420, loss: 0.043631065636873245
step: 430, loss: 0.01925729028880596
step: 440, loss: 0.03343808650970459
step: 450, loss: 0.16444818675518036
step: 460, loss: 0.027289194986224174
step: 470, loss: 0.02929053083062172
step: 480, loss: 0.0226456206291914
step: 490, loss: 0.05897867679595947
step: 500, loss: 0.05406481400132179
step: 510, loss: 3.8636830140603706e-05
step: 520, loss: 0.032981861382722855
step: 530, loss: 0.05047041177749634
step: 540, loss: 0.020376956090331078
step: 550, loss: 0.03892140090465546
step: 560, loss: 0.013229813426733017
step: 570, loss: 0.00013486780517268926
step: 580, loss: 0.035024069249629974
step: 590, loss: 0.09330976754426956
step: 600, loss: 0.06852836906909943
step: 610, loss: 0.023317988961935043
step: 620, loss: 0.004829029552638531
step: 630, loss: 0.024043936282396317
step: 640, loss: 0.05139755457639694
step: 650, loss: 0.035132575780153275
step: 660, loss: 0.08104925602674484
step: 670, loss: 0.01237404439598322
step: 680, loss: 0.016718877479434013
step: 690, loss: 0.015304763801395893
step: 700, loss: 0.11945536732673645
step: 710, loss: 0.024366658180952072
step: 720, loss: 0.03189409151673317
step: 730, loss: 0.022829320281744003
step: 740, loss: 0.03402040898799896
step: 750, loss: 1.066908680513734e-05
step: 760, loss: 0.028054365888237953
step: 770, loss: 0.11174966394901276
step: 780, loss: 0.0421927310526371
step: 790, loss: 0.01914786733686924
step: 800, loss: 0.004289731848984957
step: 810, loss: 0.0003171479038428515
step: 820, loss: 0.023981623351573944
step: 830, loss: 0.05749449133872986
step: 840, loss: 0.059841543436050415
step: 850, loss: 0.021569745615124702
step: 860, loss: 0.00021586113143712282
step: 870, loss: 0.05093719810247421
step: 880, loss: 0.08867736160755157
step: 890, loss: 0.01830196939408779
step: 900, loss: 0.026545515283942223
step: 910, loss: 0.013267923146486282
step: 920, loss: 0.0676804631948471
step: 930, loss: 0.00012575228174682707
step: 940, loss: 0.00121674919500947
step: 950, loss: 0.026103006675839424
step: 960, loss: 0.00045526475878432393
step: 970, loss: 0.011642911471426487
step: 980, loss: 0.057477135211229324
step: 990, loss: 0.0003102047194261104
step: 1000, loss: 0.0868564173579216
step: 1010, loss: 0.02925935946404934
step: 1020, loss: 0.05007342994213104
step: 1030, loss: 0.02776472643017769
step: 1040, loss: 0.00012472167145460844
step: 1050, loss: 0.058293744921684265
step: 1060, loss: 0.04724856838583946
step: 1070, loss: 0.021162444725632668
epoch 17: dev_f1=0.9311475409836065, f1=0.9307942405945193, best_f1=0.9272811486799445
step: 0, loss: 0.01636088639497757
step: 10, loss: 0.02265884168446064
step: 20, loss: 0.04262501373887062
step: 30, loss: 0.020343760028481483
step: 40, loss: 0.00041941480594687164
step: 50, loss: 0.03863167762756348
step: 60, loss: 0.013257903978228569
step: 70, loss: 0.020601339638233185
step: 80, loss: 0.023845229297876358
step: 90, loss: 0.03908548131585121
step: 100, loss: 1.2866697034041863e-05
step: 110, loss: 0.0032201739959418774
step: 120, loss: 0.027138633653521538
step: 130, loss: 0.04421744495630264
step: 140, loss: 0.04028993099927902
step: 150, loss: 0.02644416317343712
step: 160, loss: 0.013072220608592033
step: 170, loss: 0.0009250131552107632
step: 180, loss: 0.08171867579221725
step: 190, loss: 0.006517055444419384
step: 200, loss: 0.042236652225255966
step: 210, loss: 0.018228579312562943
step: 220, loss: 0.0238778255879879
step: 230, loss: 0.03836273029446602
step: 240, loss: 0.03752823919057846
step: 250, loss: 0.021930214017629623
step: 260, loss: 0.04749830812215805
step: 270, loss: 4.818982051801868e-05
step: 280, loss: 0.023484481498599052
step: 290, loss: 0.030637606978416443
step: 300, loss: 0.02977718785405159
step: 310, loss: 9.942715223587584e-06
step: 320, loss: 0.02696942165493965
step: 330, loss: 2.6797197278938256e-05
step: 340, loss: 0.06340394914150238
step: 350, loss: 0.04887025058269501
step: 360, loss: 1.63947024702793e-05
step: 370, loss: 0.10635956376791
step: 380, loss: 0.013430960476398468
step: 390, loss: 0.06114117056131363
step: 400, loss: 0.02028379589319229
step: 410, loss: 0.04176180064678192
step: 420, loss: 0.03320550173521042
step: 430, loss: 0.002381661906838417
step: 440, loss: 0.03920497000217438
step: 450, loss: 0.03752114251255989
step: 460, loss: 0.0016320940339937806
step: 470, loss: 0.018894098699092865
step: 480, loss: 0.018929535523056984
step: 490, loss: 0.02630176953971386
step: 500, loss: 0.05335460230708122
step: 510, loss: 0.02195531502366066
step: 520, loss: 1.5831770724616945e-05
step: 530, loss: 2.7364400011720136e-05
step: 540, loss: 0.002450177213177085
step: 550, loss: 0.052351679652929306
step: 560, loss: 0.03498634323477745
step: 570, loss: 0.041874878108501434
step: 580, loss: 0.001993893412873149
step: 590, loss: 5.835066258441657e-05
step: 600, loss: 9.1003836132586e-05
step: 610, loss: 0.08809036016464233
step: 620, loss: 0.00015270574658643454
step: 630, loss: 0.12457893043756485
step: 640, loss: 0.05455837398767471
step: 650, loss: 0.015195130370557308
step: 660, loss: 0.04765656590461731
step: 670, loss: 0.14108681678771973
step: 680, loss: 0.035289883613586426
step: 690, loss: 0.0003549300308804959
step: 700, loss: 0.0009329827153123915
step: 710, loss: 0.03559451550245285
step: 720, loss: 1.186866302305134e-05
step: 730, loss: 0.019300276413559914
step: 740, loss: 0.06471705436706543
step: 750, loss: 0.018189379945397377
step: 760, loss: 0.022744303569197655
step: 770, loss: 6.986447988310829e-05
step: 780, loss: 0.025737598538398743
step: 790, loss: 0.04945481941103935
step: 800, loss: 0.051884181797504425
step: 810, loss: 0.00038022760418243706
step: 820, loss: 3.679775181808509e-05
step: 830, loss: 0.027308054268360138
step: 840, loss: 0.049044523388147354
step: 850, loss: 0.020890019834041595
step: 860, loss: 0.0491524413228035
step: 870, loss: 0.038832999765872955
step: 880, loss: 2.4202036001952365e-05
step: 890, loss: 0.02715243399143219
step: 900, loss: 0.014404095709323883
step: 910, loss: 0.05228660628199577
step: 920, loss: 0.02547803893685341
step: 930, loss: 0.02996823377907276
step: 940, loss: 0.042928021401166916
step: 950, loss: 0.000189436788787134
step: 960, loss: 2.0547899111988954e-05
step: 970, loss: 0.006412683054804802
step: 980, loss: 0.0001743754546623677
step: 990, loss: 0.0003700166125781834
step: 1000, loss: 0.01902417652308941
step: 1010, loss: 8.864385017659515e-05
step: 1020, loss: 0.04780152812600136
step: 1030, loss: 0.019939536228775978
step: 1040, loss: 0.0353354848921299
step: 1050, loss: 0.04078226163983345
step: 1060, loss: 2.5407511202502064e-05
step: 1070, loss: 4.3744308641180396e-05
epoch 18: dev_f1=0.9317004239284032, f1=0.9223573433115062, best_f1=0.9272811486799445
step: 0, loss: 0.0214122012257576
step: 10, loss: 0.07165640592575073
step: 20, loss: 0.000107754094642587
step: 30, loss: 0.0575295016169548
step: 40, loss: 0.00737793929874897
step: 50, loss: 0.024052530527114868
step: 60, loss: 0.07086752355098724
step: 70, loss: 0.0002310241834493354
step: 80, loss: 0.07976923137903214
step: 90, loss: 0.07729531824588776
step: 100, loss: 0.022497102618217468
step: 110, loss: 0.024251043796539307
step: 120, loss: 0.013667895458638668
step: 130, loss: 0.027132585644721985
step: 140, loss: 0.03321034833788872
step: 150, loss: 1.3358508113014977e-05
step: 160, loss: 0.023239625617861748
step: 170, loss: 0.04178492724895477
step: 180, loss: 0.06617984920740128
step: 190, loss: 0.045796073973178864
step: 200, loss: 0.1037253886461258
step: 210, loss: 0.07578295469284058
step: 220, loss: 0.046917419880628586
step: 230, loss: 4.624961729859933e-05
step: 240, loss: 0.03301316872239113
step: 250, loss: 0.0642404556274414
step: 260, loss: 0.058312952518463135
step: 270, loss: 0.00039842812111601233
step: 280, loss: 0.0003862260200548917
step: 290, loss: 0.05535664036870003
step: 300, loss: 0.04352026432752609
step: 310, loss: 0.0010467547690495849
step: 320, loss: 0.029070042073726654
step: 330, loss: 0.037484459578990936
step: 340, loss: 9.658325143391266e-05
step: 350, loss: 0.04556189477443695
step: 360, loss: 1.708743911876809e-05
step: 370, loss: 0.015090766362845898
step: 380, loss: 0.016332106664776802
step: 390, loss: 0.032166529446840286
step: 400, loss: 0.05117523670196533
step: 410, loss: 0.00016293783846776932
step: 420, loss: 0.006236399058252573
step: 430, loss: 0.05690982937812805
step: 440, loss: 3.205087341484614e-05
step: 450, loss: 0.01914580911397934
step: 460, loss: 0.022503435611724854
step: 470, loss: 0.036769282072782516
step: 480, loss: 0.024175502359867096
step: 490, loss: 0.07295431941747665
step: 500, loss: 0.06793786585330963
step: 510, loss: 0.05013217404484749
step: 520, loss: 0.02735472470521927
step: 530, loss: 0.013969196937978268
step: 540, loss: 0.024388859048485756
step: 550, loss: 0.0018764517735689878
step: 560, loss: 0.02077430859208107
step: 570, loss: 5.1824252295773476e-05
step: 580, loss: 0.00015139553579501808
step: 590, loss: 6.037143975845538e-05
step: 600, loss: 0.02415018528699875
step: 610, loss: 0.09788460284471512
step: 620, loss: 0.0006489664083346725
step: 630, loss: 0.09613996744155884
step: 640, loss: 4.593325866153464e-05
step: 650, loss: 0.024729182943701744
step: 660, loss: 0.022577490657567978
step: 670, loss: 0.04286748170852661
step: 680, loss: 0.040791917592287064
step: 690, loss: 2.285245318489615e-05
step: 700, loss: 0.025350341573357582
step: 710, loss: 0.08319833129644394
step: 720, loss: 0.05537104606628418
step: 730, loss: 3.226437183911912e-05
step: 740, loss: 3.801650746027008e-05
step: 750, loss: 0.024317631497979164
step: 760, loss: 0.0002486112935002893
step: 770, loss: 0.07731861621141434
step: 780, loss: 0.0023143321741372347
step: 790, loss: 0.010671922005712986
step: 800, loss: 0.028942454606294632
step: 810, loss: 0.0010791767854243517
step: 820, loss: 0.006709273438900709
step: 830, loss: 1.6040567061281763e-05
step: 840, loss: 0.03969705104827881
step: 850, loss: 0.020460601896047592
step: 860, loss: 0.018904758617281914
step: 870, loss: 0.01990656554698944
step: 880, loss: 0.020365849137306213
step: 890, loss: 0.04147464036941528
step: 900, loss: 0.0010266423923894763
step: 910, loss: 0.019614938646554947
step: 920, loss: 0.02212386764585972
step: 930, loss: 0.019033566117286682
step: 940, loss: 0.06037379801273346
step: 950, loss: 0.05183499678969383
step: 960, loss: 0.0404147207736969
step: 970, loss: 0.002912992611527443
step: 980, loss: 0.022803889587521553
step: 990, loss: 0.06920437514781952
step: 1000, loss: 1.6748088455642574e-05
step: 1010, loss: 1.2129250535508618e-05
step: 1020, loss: 0.01905110478401184
step: 1030, loss: 0.06223607063293457
step: 1040, loss: 0.007938569411635399
step: 1050, loss: 2.4008382752072066e-05
step: 1060, loss: 0.03188472241163254
step: 1070, loss: 0.03923729807138443
epoch 19: dev_f1=0.9308885754583921, f1=0.922071861875875, best_f1=0.9272811486799445
step: 0, loss: 0.044363539665937424
step: 10, loss: 1.6156174751813523e-05
step: 20, loss: 0.011741128750145435
step: 30, loss: 0.0008721557096578181
step: 40, loss: 0.031202862039208412
step: 50, loss: 0.06252337247133255
step: 60, loss: 0.018429195508360863
step: 70, loss: 0.07044042646884918
step: 80, loss: 0.0018860966665670276
step: 90, loss: 0.032650936394929886
step: 100, loss: 0.0017263905610889196
step: 110, loss: 0.022981997579336166
step: 120, loss: 0.0008570015197619796
step: 130, loss: 0.011404171586036682
step: 140, loss: 0.027598902583122253
step: 150, loss: 0.011511625722050667
step: 160, loss: 0.024335581809282303
step: 170, loss: 0.021315205842256546
step: 180, loss: 1.6394396880059503e-05
step: 190, loss: 3.481908424873836e-05
step: 200, loss: 5.444904672913253e-05
step: 210, loss: 0.039108581840991974
step: 220, loss: 0.059960559010505676
step: 230, loss: 0.04896172881126404
step: 240, loss: 0.040315400809049606
step: 250, loss: 0.002909383736550808
step: 260, loss: 1.0639296306180768e-05
step: 270, loss: 0.04684875160455704
step: 280, loss: 0.07510165125131607
step: 290, loss: 0.0028744207229465246
step: 300, loss: 0.04481736570596695
step: 310, loss: 1.838365278672427e-05
step: 320, loss: 0.0434778667986393
step: 330, loss: 0.0010560370283201337
step: 340, loss: 0.012425955384969711
step: 350, loss: 0.019960172474384308
step: 360, loss: 0.05134968459606171
step: 370, loss: 0.00014442972315009683
step: 380, loss: 0.001378913875669241
step: 390, loss: 0.024661285802721977
step: 400, loss: 1.5019640159152914e-05
step: 410, loss: 4.889193587587215e-05
step: 420, loss: 7.733665370324161e-06
step: 430, loss: 1.272151894227136e-05
step: 440, loss: 7.107821602403419e-06
step: 450, loss: 7.850214751670137e-05
step: 460, loss: 0.025181850418448448
step: 470, loss: 0.0003252393798902631
step: 480, loss: 1.3414438399195205e-05
step: 490, loss: 0.022109651938080788
step: 500, loss: 0.05253558233380318
step: 510, loss: 2.970362766063772e-05
step: 520, loss: 0.025010505691170692
step: 530, loss: 0.06564315408468246
step: 540, loss: 2.8116504836361855e-05
step: 550, loss: 2.2127005649963394e-05
step: 560, loss: 0.022450769320130348
step: 570, loss: 0.0032558548264205456
step: 580, loss: 0.0020313323475420475
step: 590, loss: 0.032679662108421326
step: 600, loss: 0.02251695655286312
step: 610, loss: 0.018165118992328644
step: 620, loss: 0.01992514170706272
step: 630, loss: 0.06125420704483986
step: 640, loss: 0.03343449532985687
step: 650, loss: 0.08091655373573303
step: 660, loss: 0.058462075889110565
step: 670, loss: 0.01589926704764366
step: 680, loss: 0.02421550638973713
step: 690, loss: 0.00014787778491154313
step: 700, loss: 0.015611774288117886
step: 710, loss: 2.3143145881476812e-05
step: 720, loss: 0.000855808611959219
step: 730, loss: 0.03477083519101143
step: 740, loss: 0.00017565304005984217
step: 750, loss: 0.01914682798087597
step: 760, loss: 1.4237737559597008e-05
step: 770, loss: 0.018737563863396645
step: 780, loss: 5.9902395150857046e-05
step: 790, loss: 0.0005824561812914908
step: 800, loss: 0.01081002876162529
step: 810, loss: 0.03843110799789429
step: 820, loss: 0.0004377343284431845
step: 830, loss: 0.0016455084551125765
step: 840, loss: 0.00016583722026553005
step: 850, loss: 0.021726250648498535
step: 860, loss: 8.135857206070796e-05
step: 870, loss: 0.01999562792479992
step: 880, loss: 0.016526751220226288
step: 890, loss: 0.042659129947423935
step: 900, loss: 0.029417162761092186
step: 910, loss: 0.057083725929260254
step: 920, loss: 0.014521393924951553
step: 930, loss: 0.022940905764698982
step: 940, loss: 0.00940457172691822
step: 950, loss: 0.07236455380916595
step: 960, loss: 6.462879537139088e-05
step: 970, loss: 1.0937250408460386e-05
step: 980, loss: 0.030766967684030533
step: 990, loss: 8.358863851753995e-05
step: 1000, loss: 0.024781251326203346
step: 1010, loss: 0.04139311611652374
step: 1020, loss: 0.0239501241594553
step: 1030, loss: 0.019632218405604362
step: 1040, loss: 0.030078314244747162
step: 1050, loss: 0.0009774627396836877
step: 1060, loss: 0.018482880666851997
step: 1070, loss: 4.934721073368564e-05
epoch 20: dev_f1=0.9285042333019755, f1=0.9244402985074627, best_f1=0.9272811486799445
