cuda
Device: cuda
step: 0, loss: 0.6045888662338257
step: 10, loss: 0.4282764792442322
step: 20, loss: 0.3666874170303345
step: 30, loss: 0.3498566150665283
step: 40, loss: 0.40759754180908203
step: 50, loss: 0.38162893056869507
step: 60, loss: 0.2722490131855011
step: 70, loss: 0.24166887998580933
step: 80, loss: 0.30483075976371765
step: 90, loss: 0.3325597047805786
step: 100, loss: 0.17641383409500122
step: 110, loss: 0.08506873995065689
step: 120, loss: 0.1546725630760193
step: 130, loss: 0.11656234413385391
step: 140, loss: 0.15559135377407074
step: 150, loss: 0.175559863448143
step: 160, loss: 0.0821039229631424
step: 170, loss: 0.2573738992214203
step: 180, loss: 0.1331927478313446
step: 190, loss: 0.138794407248497
step: 200, loss: 0.474004328250885
step: 210, loss: 0.12182408571243286
step: 220, loss: 0.20349179208278656
step: 230, loss: 0.21647299826145172
step: 240, loss: 0.13988514244556427
step: 250, loss: 0.05611705780029297
step: 260, loss: 0.11979366093873978
step: 270, loss: 0.13036467134952545
step: 280, loss: 0.14703866839408875
step: 290, loss: 0.04614138975739479
step: 300, loss: 0.09830610454082489
step: 310, loss: 0.1572035551071167
step: 320, loss: 0.11123024672269821
step: 330, loss: 0.10335179418325424
step: 340, loss: 0.09011639654636383
step: 350, loss: 0.10959027707576752
step: 360, loss: 0.15528801083564758
step: 370, loss: 0.39682459831237793
step: 380, loss: 0.10538330674171448
step: 390, loss: 0.041587863117456436
step: 400, loss: 0.05085928365588188
step: 410, loss: 0.1806156188249588
step: 420, loss: 0.07391919940710068
step: 430, loss: 0.07896824181079865
step: 440, loss: 0.07312767207622528
step: 450, loss: 0.06694729626178741
step: 460, loss: 0.06835003197193146
step: 470, loss: 0.11213720589876175
step: 480, loss: 0.08894453942775726
step: 490, loss: 0.1449601948261261
step: 500, loss: 0.07202374935150146
step: 510, loss: 0.18106356263160706
step: 520, loss: 0.16772377490997314
step: 530, loss: 0.1487267017364502
step: 540, loss: 0.0539340116083622
step: 550, loss: 0.2485504448413849
step: 560, loss: 0.08302940428256989
step: 570, loss: 0.09151169657707214
step: 580, loss: 0.028187019750475883
step: 590, loss: 0.07015131413936615
step: 600, loss: 0.044863682240247726
step: 610, loss: 0.11886429786682129
step: 620, loss: 0.14880269765853882
step: 630, loss: 0.025952011346817017
step: 640, loss: 0.060270823538303375
step: 650, loss: 0.10694707930088043
step: 660, loss: 0.12085800617933273
step: 670, loss: 0.21517932415008545
step: 680, loss: 0.19596824049949646
step: 690, loss: 0.10356935858726501
step: 700, loss: 0.16695420444011688
step: 710, loss: 0.2749016284942627
step: 720, loss: 0.042158592492341995
step: 730, loss: 0.026544462889432907
step: 740, loss: 0.11793743818998337
step: 750, loss: 0.07564222812652588
step: 760, loss: 0.15068449079990387
step: 770, loss: 0.13558606803417206
step: 780, loss: 0.07410963624715805
step: 790, loss: 0.10620413720607758
step: 800, loss: 0.20590949058532715
step: 810, loss: 0.05892965570092201
step: 820, loss: 0.14164768159389496
step: 830, loss: 0.18093489110469818
step: 840, loss: 0.1705458164215088
step: 850, loss: 0.04111383855342865
step: 860, loss: 0.04145679995417595
step: 870, loss: 0.20991463959217072
step: 880, loss: 0.04341882839798927
step: 890, loss: 0.11115583777427673
step: 900, loss: 0.07692296802997589
step: 910, loss: 0.09652100503444672
step: 920, loss: 0.142349511384964
step: 930, loss: 0.07629665732383728
step: 940, loss: 0.06551805138587952
step: 950, loss: 0.08751790970563889
step: 960, loss: 0.20700791478157043
step: 970, loss: 0.12314989417791367
step: 980, loss: 0.1855802834033966
step: 990, loss: 0.05709868296980858
step: 1000, loss: 0.1149456799030304
step: 1010, loss: 0.16318219900131226
step: 1020, loss: 0.09784739464521408
step: 1030, loss: 0.10134285688400269
step: 1040, loss: 0.16770483553409576
step: 1050, loss: 0.06015502288937569
step: 1060, loss: 0.08711366355419159
step: 1070, loss: 0.0681830421090126
epoch 1: dev_f1=0.9291914116034719, f1=0.9231464737793852, best_f1=0.9231464737793852
step: 0, loss: 0.07090124487876892
step: 10, loss: 0.08404603600502014
step: 20, loss: 0.06675469130277634
step: 30, loss: 0.20167285203933716
step: 40, loss: 0.040489278733730316
step: 50, loss: 0.06779283285140991
step: 60, loss: 0.028534024953842163
step: 70, loss: 0.11650490760803223
step: 80, loss: 0.19730345904827118
step: 90, loss: 0.08163335174322128
step: 100, loss: 0.035712264478206635
step: 110, loss: 0.1297571212053299
step: 120, loss: 0.12331445515155792
step: 130, loss: 0.049801722168922424
step: 140, loss: 0.11646851897239685
step: 150, loss: 0.07527075707912445
step: 160, loss: 0.03417032212018967
step: 170, loss: 0.07282347977161407
step: 180, loss: 0.12191563844680786
step: 190, loss: 0.11006215214729309
step: 200, loss: 0.09694932401180267
step: 210, loss: 0.15083396434783936
step: 220, loss: 0.17134883999824524
step: 230, loss: 0.13772642612457275
step: 240, loss: 0.10060865432024002
step: 250, loss: 0.01867736503481865
step: 260, loss: 0.11651304364204407
step: 270, loss: 0.09478157758712769
step: 280, loss: 0.11598558723926544
step: 290, loss: 0.03060140460729599
step: 300, loss: 0.04392051696777344
step: 310, loss: 0.08540838956832886
step: 320, loss: 0.0463339239358902
step: 330, loss: 0.05731438472867012
step: 340, loss: 0.13345159590244293
step: 350, loss: 0.04496055841445923
step: 360, loss: 0.056765247136354446
step: 370, loss: 0.03571806848049164
step: 380, loss: 0.07845765352249146
step: 390, loss: 0.0199313685297966
step: 400, loss: 0.14265626668930054
step: 410, loss: 0.030895857140421867
step: 420, loss: 0.053105343133211136
step: 430, loss: 0.09224764257669449
step: 440, loss: 0.09283379465341568
step: 450, loss: 0.1368519514799118
step: 460, loss: 0.03530602529644966
step: 470, loss: 0.12561260163784027
step: 480, loss: 0.0796632319688797
step: 490, loss: 0.1326492577791214
step: 500, loss: 0.12806785106658936
step: 510, loss: 0.11617090553045273
step: 520, loss: 0.14998243749141693
step: 530, loss: 0.013294178992509842
step: 540, loss: 0.025105981156229973
step: 550, loss: 0.09982158243656158
step: 560, loss: 0.02123037539422512
step: 570, loss: 0.11359512805938721
step: 580, loss: 0.05963948741555214
step: 590, loss: 0.052423227578401566
step: 600, loss: 0.08476632833480835
step: 610, loss: 0.1472659558057785
step: 620, loss: 0.05548863857984543
step: 630, loss: 0.043806254863739014
step: 640, loss: 0.04958881810307503
step: 650, loss: 0.06412578374147415
step: 660, loss: 0.21260419487953186
step: 670, loss: 0.09909393638372421
step: 680, loss: 0.07473236322402954
step: 690, loss: 0.10388139635324478
step: 700, loss: 0.1441507786512375
step: 710, loss: 0.13459940254688263
step: 720, loss: 0.03886130079627037
step: 730, loss: 0.094398133456707
step: 740, loss: 0.07198043912649155
step: 750, loss: 0.05702789127826691
step: 760, loss: 0.20084896683692932
step: 770, loss: 0.08112949132919312
step: 780, loss: 0.09943899512290955
step: 790, loss: 0.016914915293455124
step: 800, loss: 0.04754866287112236
step: 810, loss: 0.1478273719549179
step: 820, loss: 0.05089125409722328
step: 830, loss: 0.08826655894517899
step: 840, loss: 0.12605540454387665
step: 850, loss: 0.11764097958803177
step: 860, loss: 0.12716339528560638
step: 870, loss: 0.027308417484164238
step: 880, loss: 0.08428512513637543
step: 890, loss: 0.16701529920101166
step: 900, loss: 0.07774552702903748
step: 910, loss: 0.07682868838310242
step: 920, loss: 0.046617161482572556
step: 930, loss: 0.11465145647525787
step: 940, loss: 0.07812709361314774
step: 950, loss: 0.02133825235068798
step: 960, loss: 0.056952040642499924
step: 970, loss: 0.07175426185131073
step: 980, loss: 0.25867927074432373
step: 990, loss: 0.11855228245258331
step: 1000, loss: 0.08719118684530258
step: 1010, loss: 0.07070977240800858
step: 1020, loss: 0.10978416353464127
step: 1030, loss: 0.0927967056632042
step: 1040, loss: 0.12347425520420074
step: 1050, loss: 0.09863447397947311
step: 1060, loss: 0.08231952786445618
step: 1070, loss: 0.11507075279951096
epoch 2: dev_f1=0.9217230199166282, f1=0.923076923076923, best_f1=0.9231464737793852
step: 0, loss: 0.03202129527926445
step: 10, loss: 0.02296612225472927
step: 20, loss: 0.09523069113492966
step: 30, loss: 0.09142611920833588
step: 40, loss: 0.03799150511622429
step: 50, loss: 0.024560702964663506
step: 60, loss: 0.017855936661362648
step: 70, loss: 0.10518153011798859
step: 80, loss: 0.05970113351941109
step: 90, loss: 0.029514532536268234
step: 100, loss: 0.03748982027173042
step: 110, loss: 0.07362379878759384
step: 120, loss: 0.009627184830605984
step: 130, loss: 0.010275286622345448
step: 140, loss: 0.03095637448132038
step: 150, loss: 0.0989505872130394
step: 160, loss: 0.025981971994042397
step: 170, loss: 0.023381900042295456
step: 180, loss: 0.07633573561906815
step: 190, loss: 0.12151210010051727
step: 200, loss: 0.051836173981428146
step: 210, loss: 0.056003376841545105
step: 220, loss: 0.09220448136329651
step: 230, loss: 0.08065909892320633
step: 240, loss: 0.08615340292453766
step: 250, loss: 0.05857894942164421
step: 260, loss: 0.0934276208281517
step: 270, loss: 0.05378588289022446
step: 280, loss: 0.04189633950591087
step: 290, loss: 0.16334232687950134
step: 300, loss: 0.06936590373516083
step: 310, loss: 0.008399870246648788
step: 320, loss: 0.10796132683753967
step: 330, loss: 0.07365560531616211
step: 340, loss: 0.11286314576864243
step: 350, loss: 0.04021745175123215
step: 360, loss: 0.0639595240354538
step: 370, loss: 0.1548856943845749
step: 380, loss: 0.17206695675849915
step: 390, loss: 0.059546276926994324
step: 400, loss: 0.19871793687343597
step: 410, loss: 0.059844423085451126
step: 420, loss: 0.07286374270915985
step: 430, loss: 0.07467890530824661
step: 440, loss: 0.06811456382274628
step: 450, loss: 0.014417392201721668
step: 460, loss: 0.08289088308811188
step: 470, loss: 0.07381302863359451
step: 480, loss: 0.1005977913737297
step: 490, loss: 0.0536411851644516
step: 500, loss: 0.04355550929903984
step: 510, loss: 0.1384885460138321
step: 520, loss: 0.08868154138326645
step: 530, loss: 0.08586522191762924
step: 540, loss: 0.041279423981904984
step: 550, loss: 0.08329398185014725
step: 560, loss: 0.02731923758983612
step: 570, loss: 0.009084440767765045
step: 580, loss: 0.03407876193523407
step: 590, loss: 0.10627759248018265
step: 600, loss: 0.070463627576828
step: 610, loss: 0.07808468490839005
step: 620, loss: 0.12332714349031448
step: 630, loss: 0.011574254371225834
step: 640, loss: 0.0322512723505497
step: 650, loss: 0.048582881689071655
step: 660, loss: 0.03949545696377754
step: 670, loss: 0.039630427956581116
step: 680, loss: 0.06484832614660263
step: 690, loss: 0.07055933773517609
step: 700, loss: 0.04816750809550285
step: 710, loss: 0.14926768839359283
step: 720, loss: 0.13668188452720642
step: 730, loss: 0.03920017182826996
step: 740, loss: 0.08915844559669495
step: 750, loss: 0.12701614201068878
step: 760, loss: 0.02831769734621048
step: 770, loss: 0.03155791386961937
step: 780, loss: 0.12511217594146729
step: 790, loss: 0.03741035610437393
step: 800, loss: 0.024886833503842354
step: 810, loss: 0.019054481759667397
step: 820, loss: 0.09939594566822052
step: 830, loss: 0.2111579328775406
step: 840, loss: 0.12064148485660553
step: 850, loss: 0.029097920283675194
step: 860, loss: 0.0811966210603714
step: 870, loss: 0.036485593765974045
step: 880, loss: 0.19595929980278015
step: 890, loss: 0.007041383534669876
step: 900, loss: 0.11766890436410904
step: 910, loss: 0.08402847498655319
step: 920, loss: 0.006331237498670816
step: 930, loss: 0.12858404219150543
step: 940, loss: 0.09231646358966827
step: 950, loss: 0.16971415281295776
step: 960, loss: 0.01747826859354973
step: 970, loss: 0.06495289504528046
step: 980, loss: 0.16050933301448822
step: 990, loss: 0.042648691684007645
step: 1000, loss: 0.13314683735370636
step: 1010, loss: 0.1091243103146553
step: 1020, loss: 0.03566696494817734
step: 1030, loss: 0.014909428544342518
step: 1040, loss: 0.07016820460557938
step: 1050, loss: 0.08974666148424149
step: 1060, loss: 0.09025050699710846
step: 1070, loss: 0.027313154190778732
epoch 3: dev_f1=0.9348519362186788, f1=0.9337597076290544, best_f1=0.9337597076290544
step: 0, loss: 0.014200759120285511
step: 10, loss: 0.018659275025129318
step: 20, loss: 0.08663854002952576
step: 30, loss: 0.12719520926475525
step: 40, loss: 0.12923391163349152
step: 50, loss: 0.06248059496283531
step: 60, loss: 0.08919915556907654
step: 70, loss: 0.12918782234191895
step: 80, loss: 0.023603025823831558
step: 90, loss: 0.11074909567832947
step: 100, loss: 0.010892451740801334
step: 110, loss: 0.03774154931306839
step: 120, loss: 0.12128013372421265
step: 130, loss: 0.07527240365743637
step: 140, loss: 0.08727669715881348
step: 150, loss: 0.008006580173969269
step: 160, loss: 0.05634737387299538
step: 170, loss: 0.04065053537487984
step: 180, loss: 0.019078556448221207
step: 190, loss: 0.007634460460394621
step: 200, loss: 0.28271564841270447
step: 210, loss: 0.014600254595279694
step: 220, loss: 0.1578129380941391
step: 230, loss: 0.03080299310386181
step: 240, loss: 0.05266891047358513
step: 250, loss: 0.022859305143356323
step: 260, loss: 0.13316555321216583
step: 270, loss: 0.027382418513298035
step: 280, loss: 0.001780054997652769
step: 290, loss: 0.12440584599971771
step: 300, loss: 0.05176367610692978
step: 310, loss: 0.06175876408815384
step: 320, loss: 0.13614632189273834
step: 330, loss: 0.15401718020439148
step: 340, loss: 0.03816739842295647
step: 350, loss: 0.02374601550400257
step: 360, loss: 0.015370077453553677
step: 370, loss: 0.03852175921201706
step: 380, loss: 0.05000139772891998
step: 390, loss: 0.0719676986336708
step: 400, loss: 0.1107342392206192
step: 410, loss: 0.08109453320503235
step: 420, loss: 0.3360307514667511
step: 430, loss: 0.11052697896957397
step: 440, loss: 0.04146507754921913
step: 450, loss: 0.07927229255437851
step: 460, loss: 0.04314848408102989
step: 470, loss: 0.09784533828496933
step: 480, loss: 0.07770851254463196
step: 490, loss: 0.11890141665935516
step: 500, loss: 0.05089685693383217
step: 510, loss: 0.0312437042593956
step: 520, loss: 0.08769350498914719
step: 530, loss: 0.1511291265487671
step: 540, loss: 0.10892997682094574
step: 550, loss: 0.07798066735267639
step: 560, loss: 0.12793678045272827
step: 570, loss: 0.057470325380563736
step: 580, loss: 0.06296566873788834
step: 590, loss: 0.09596624225378036
step: 600, loss: 0.00024597960873506963
step: 610, loss: 0.01697617769241333
step: 620, loss: 0.19898423552513123
step: 630, loss: 0.03391018882393837
step: 640, loss: 0.0673673152923584
step: 650, loss: 0.04630611836910248
step: 660, loss: 0.06359779089689255
step: 670, loss: 0.053508564829826355
step: 680, loss: 0.04593420401215553
step: 690, loss: 0.03144654631614685
step: 700, loss: 0.02099575847387314
step: 710, loss: 0.09500052034854889
step: 720, loss: 0.06766247749328613
step: 730, loss: 0.06236502155661583
step: 740, loss: 0.12162581086158752
step: 750, loss: 0.014523638412356377
step: 760, loss: 0.0074814786203205585
step: 770, loss: 0.02619357965886593
step: 780, loss: 0.08175104111433029
step: 790, loss: 0.14874419569969177
step: 800, loss: 0.07183307409286499
step: 810, loss: 0.018660245463252068
step: 820, loss: 0.12004062533378601
step: 830, loss: 0.07843899726867676
step: 840, loss: 0.10667137056589127
step: 850, loss: 0.08355813473463058
step: 860, loss: 0.014767156913876534
step: 870, loss: 0.05205879360437393
step: 880, loss: 0.2935309112071991
step: 890, loss: 0.16929887235164642
step: 900, loss: 0.05349944904446602
step: 910, loss: 0.013262455351650715
step: 920, loss: 0.023725366219878197
step: 930, loss: 0.03033183142542839
step: 940, loss: 0.012482094578444958
step: 950, loss: 0.03355434909462929
step: 960, loss: 0.0952877551317215
step: 970, loss: 0.10805241763591766
step: 980, loss: 0.03718706592917442
step: 990, loss: 0.08465667068958282
step: 1000, loss: 0.02959590032696724
step: 1010, loss: 0.12103680521249771
step: 1020, loss: 0.08854561299085617
step: 1030, loss: 0.029051044955849648
step: 1040, loss: 0.09586268663406372
step: 1050, loss: 0.19316215813159943
step: 1060, loss: 0.10210271924734116
step: 1070, loss: 0.03637088090181351
epoch 4: dev_f1=0.934640522875817, f1=0.93666204345816, best_f1=0.9337597076290544
step: 0, loss: 0.2089533805847168
step: 10, loss: 0.03883062303066254
step: 20, loss: 0.05113665387034416
step: 30, loss: 0.0527416355907917
step: 40, loss: 0.003847336396574974
step: 50, loss: 0.0720309466123581
step: 60, loss: 0.01838880032300949
step: 70, loss: 0.03065386228263378
step: 80, loss: 0.03692031279206276
step: 90, loss: 0.18325258791446686
step: 100, loss: 0.27657684683799744
step: 110, loss: 0.08765596896409988
step: 120, loss: 0.1105395257472992
step: 130, loss: 0.08453796803951263
step: 140, loss: 0.01164600346237421
step: 150, loss: 0.014096708968281746
step: 160, loss: 0.008049441501498222
step: 170, loss: 0.09854387491941452
step: 180, loss: 0.07519040256738663
step: 190, loss: 0.06619082391262054
step: 200, loss: 0.027362780645489693
step: 210, loss: 0.19258195161819458
step: 220, loss: 0.010090518742799759
step: 230, loss: 0.1359846442937851
step: 240, loss: 0.04478282853960991
step: 250, loss: 0.008105852641165257
step: 260, loss: 0.04349827766418457
step: 270, loss: 0.08895352482795715
step: 280, loss: 0.13417106866836548
step: 290, loss: 0.02291760966181755
step: 300, loss: 0.10020875185728073
step: 310, loss: 0.03159457445144653
step: 320, loss: 0.08412504196166992
step: 330, loss: 0.07974448800086975
step: 340, loss: 0.007756145671010017
step: 350, loss: 0.0822630450129509
step: 360, loss: 0.07814837247133255
step: 370, loss: 0.04275108501315117
step: 380, loss: 0.0807667076587677
step: 390, loss: 0.03721221163868904
step: 400, loss: 0.11623039841651917
step: 410, loss: 0.03859182447195053
step: 420, loss: 0.0776398554444313
step: 430, loss: 0.06671464443206787
step: 440, loss: 0.027246184647083282
step: 450, loss: 0.07112622261047363
step: 460, loss: 0.11210949718952179
step: 470, loss: 0.013622716069221497
step: 480, loss: 0.061633024364709854
step: 490, loss: 0.12253506481647491
step: 500, loss: 0.015812674537301064
step: 510, loss: 0.1402411013841629
step: 520, loss: 0.006486330181360245
step: 530, loss: 0.13643822073936462
step: 540, loss: 0.029821084812283516
step: 550, loss: 0.12340989708900452
step: 560, loss: 0.08741747587919235
step: 570, loss: 0.04408789053559303
step: 580, loss: 0.012543566524982452
step: 590, loss: 0.13801491260528564
step: 600, loss: 0.029711462557315826
step: 610, loss: 0.07106423377990723
step: 620, loss: 0.16924706101417542
step: 630, loss: 0.08308577537536621
step: 640, loss: 0.037954796105623245
step: 650, loss: 0.09499437361955643
step: 660, loss: 0.06562841683626175
step: 670, loss: 0.1343744546175003
step: 680, loss: 0.13502566516399384
step: 690, loss: 0.07827561348676682
step: 700, loss: 0.07795765995979309
step: 710, loss: 0.11780291050672531
step: 720, loss: 0.009953787550330162
step: 730, loss: 0.13128577172756195
step: 740, loss: 0.011821421794593334
step: 750, loss: 0.0748441144824028
step: 760, loss: 0.03894978016614914
step: 770, loss: 0.043369513005018234
step: 780, loss: 0.1545245349407196
step: 790, loss: 0.013127833604812622
step: 800, loss: 0.10140833258628845
step: 810, loss: 0.11748629808425903
step: 820, loss: 0.0727052316069603
step: 830, loss: 0.10174132138490677
step: 840, loss: 0.09568685293197632
step: 850, loss: 0.022997664287686348
step: 860, loss: 0.02164246141910553
step: 870, loss: 0.19290010631084442
step: 880, loss: 0.025864798575639725
step: 890, loss: 0.09256305545568466
step: 900, loss: 0.03548299893736839
step: 910, loss: 0.0707000270485878
step: 920, loss: 0.043006476014852524
step: 930, loss: 0.02652597799897194
step: 940, loss: 0.14443008601665497
step: 950, loss: 0.00996467750519514
step: 960, loss: 0.009675588458776474
step: 970, loss: 0.15907539427280426
step: 980, loss: 0.094309963285923
step: 990, loss: 0.016490906476974487
step: 1000, loss: 0.031070373952388763
step: 1010, loss: 0.05204583704471588
step: 1020, loss: 0.006857356522232294
step: 1030, loss: 0.13694706559181213
step: 1040, loss: 0.13429655134677887
step: 1050, loss: 0.07847181707620621
step: 1060, loss: 0.09349092841148376
step: 1070, loss: 0.0902804285287857
epoch 5: dev_f1=0.9342043863742416, f1=0.9360709286047598, best_f1=0.9337597076290544
step: 0, loss: 0.14676016569137573
step: 10, loss: 0.018141109496355057
step: 20, loss: 0.08121607452630997
step: 30, loss: 0.04084087163209915
step: 40, loss: 0.05886932834982872
step: 50, loss: 0.0758555606007576
step: 60, loss: 0.20527558028697968
step: 70, loss: 0.14140921831130981
step: 80, loss: 0.029742997139692307
step: 90, loss: 0.03572433814406395
step: 100, loss: 0.06851303577423096
step: 110, loss: 0.03803996741771698
step: 120, loss: 0.023282615467905998
step: 130, loss: 0.12457520514726639
step: 140, loss: 0.06726828962564468
step: 150, loss: 0.019473282620310783
step: 160, loss: 0.06958092004060745
step: 170, loss: 0.04704611003398895
step: 180, loss: 0.0646977350115776
step: 190, loss: 0.03930073603987694
step: 200, loss: 0.030879974365234375
step: 210, loss: 0.01443827711045742
step: 220, loss: 0.019510779529809952
step: 230, loss: 0.10138849914073944
step: 240, loss: 0.03405869007110596
step: 250, loss: 0.004798030946403742
step: 260, loss: 0.0629919171333313
step: 270, loss: 0.09291663020849228
step: 280, loss: 0.011992755346000195
step: 290, loss: 0.03402703255414963
step: 300, loss: 0.07615261524915695
step: 310, loss: 0.0872390866279602
step: 320, loss: 0.022746102884411812
step: 330, loss: 0.008273555897176266
step: 340, loss: 0.11429890990257263
step: 350, loss: 0.011224196292459965
step: 360, loss: 0.06690093129873276
step: 370, loss: 0.07066444307565689
step: 380, loss: 0.07037863880395889
step: 390, loss: 0.029611967504024506
step: 400, loss: 0.06992243975400925
step: 410, loss: 0.03363921120762825
step: 420, loss: 0.0682055652141571
step: 430, loss: 0.0010101995430886745
step: 440, loss: 0.019905351102352142
step: 450, loss: 0.05072760581970215
step: 460, loss: 0.1500333845615387
step: 470, loss: 0.02146085351705551
step: 480, loss: 0.21187496185302734
step: 490, loss: 0.13420478999614716
step: 500, loss: 0.04303479567170143
step: 510, loss: 0.01885257288813591
step: 520, loss: 0.05770408734679222
step: 530, loss: 0.07678306102752686
step: 540, loss: 0.1252310872077942
step: 550, loss: 0.018003761768341064
step: 560, loss: 0.038368359208106995
step: 570, loss: 0.10313236713409424
step: 580, loss: 0.0015378398820757866
step: 590, loss: 0.0688210129737854
step: 600, loss: 0.11079991608858109
step: 610, loss: 0.09758099913597107
step: 620, loss: 0.08781726658344269
step: 630, loss: 0.10838078707456589
step: 640, loss: 0.024077147245407104
step: 650, loss: 0.03669537976384163
step: 660, loss: 0.01639694720506668
step: 670, loss: 0.0029966405127197504
step: 680, loss: 0.06185368075966835
step: 690, loss: 0.05436965823173523
step: 700, loss: 0.07502733170986176
step: 710, loss: 0.01353517360985279
step: 720, loss: 0.02007308602333069
step: 730, loss: 0.03461773693561554
step: 740, loss: 0.017152031883597374
step: 750, loss: 0.03816690295934677
step: 760, loss: 0.0169169120490551
step: 770, loss: 0.07671833038330078
step: 780, loss: 0.0609368197619915
step: 790, loss: 0.05926966667175293
step: 800, loss: 0.11665349453687668
step: 810, loss: 0.014064510352909565
step: 820, loss: 0.1723819226026535
step: 830, loss: 0.09068649262189865
step: 840, loss: 0.0644611269235611
step: 850, loss: 0.07985209673643112
step: 860, loss: 0.1748671531677246
step: 870, loss: 0.03865895792841911
step: 880, loss: 0.14161115884780884
step: 890, loss: 0.01576901040971279
step: 900, loss: 0.18788200616836548
step: 910, loss: 0.008768437430262566
step: 920, loss: 0.005970072466880083
step: 930, loss: 0.041459161788225174
step: 940, loss: 0.11372776329517365
step: 950, loss: 0.01633073203265667
step: 960, loss: 0.010808073915541172
step: 970, loss: 0.029737289994955063
step: 980, loss: 0.050078120082616806
step: 990, loss: 0.26118823885917664
step: 1000, loss: 0.09357792884111404
step: 1010, loss: 0.08848016709089279
step: 1020, loss: 0.07669609785079956
step: 1030, loss: 0.05505628138780594
step: 1040, loss: 0.0252063125371933
step: 1050, loss: 0.009079826064407825
step: 1060, loss: 0.2963329553604126
step: 1070, loss: 0.0691438689827919
epoch 6: dev_f1=0.9293023255813954, f1=0.9217230199166282, best_f1=0.9337597076290544
step: 0, loss: 0.16682863235473633
step: 10, loss: 0.09249275177717209
step: 20, loss: 0.030804689973592758
step: 30, loss: 0.03242100775241852
step: 40, loss: 0.12119372189044952
step: 50, loss: 0.031023606657981873
step: 60, loss: 0.05140793323516846
step: 70, loss: 0.18961206078529358
step: 80, loss: 0.014990976080298424
step: 90, loss: 0.02822989411652088
step: 100, loss: 0.09504104405641556
step: 110, loss: 0.0016624409472569823
step: 120, loss: 0.09404093027114868
step: 130, loss: 0.05778312683105469
step: 140, loss: 0.011692640371620655
step: 150, loss: 0.02375861257314682
step: 160, loss: 0.05327066779136658
step: 170, loss: 0.10950516909360886
step: 180, loss: 0.029832616448402405
step: 190, loss: 0.05585842579603195
step: 200, loss: 0.01550423726439476
step: 210, loss: 0.1794394999742508
step: 220, loss: 0.008812148123979568
step: 230, loss: 0.02845396287739277
step: 240, loss: 0.00954712275415659
step: 250, loss: 0.018606984987854958
step: 260, loss: 0.0599837526679039
step: 270, loss: 0.1218293160200119
step: 280, loss: 0.04679667577147484
step: 290, loss: 0.015367605723440647
step: 300, loss: 0.08148979395627975
step: 310, loss: 0.20945726335048676
step: 320, loss: 0.08531267940998077
step: 330, loss: 0.05789840966463089
step: 340, loss: 0.012138147838413715
step: 350, loss: 0.02633780427277088
step: 360, loss: 0.09701115638017654
step: 370, loss: 0.0651545450091362
step: 380, loss: 0.01747712306678295
step: 390, loss: 0.02666342258453369
step: 400, loss: 0.011112545616924763
step: 410, loss: 0.09400008618831635
step: 420, loss: 0.005159520078450441
step: 430, loss: 0.14101985096931458
step: 440, loss: 0.01848764531314373
step: 450, loss: 0.0683189257979393
step: 460, loss: 0.1105605885386467
step: 470, loss: 0.033536024391651154
step: 480, loss: 0.025603001937270164
step: 490, loss: 0.009637061506509781
step: 500, loss: 0.02144176885485649
step: 510, loss: 0.04658118635416031
step: 520, loss: 0.04684699699282646
step: 530, loss: 0.10903163254261017
step: 540, loss: 0.11158236116170883
step: 550, loss: 0.014262903481721878
step: 560, loss: 0.036828432232141495
step: 570, loss: 0.06877187639474869
step: 580, loss: 0.0148994829505682
step: 590, loss: 0.13094714283943176
step: 600, loss: 0.060889359563589096
step: 610, loss: 0.030708495527505875
step: 620, loss: 0.019342975690960884
step: 630, loss: 0.020537851378321648
step: 640, loss: 0.012945344671607018
step: 650, loss: 0.0036480810958892107
step: 660, loss: 0.001258507021702826
step: 670, loss: 0.06843770295381546
step: 680, loss: 0.1353578418493271
step: 690, loss: 0.05707773193717003
step: 700, loss: 0.01621279865503311
step: 710, loss: 0.015761686488986015
step: 720, loss: 0.013609763234853745
step: 730, loss: 0.041116863489151
step: 740, loss: 0.09586449712514877
step: 750, loss: 0.0856148898601532
step: 760, loss: 0.005395171698182821
step: 770, loss: 0.02303297072649002
step: 780, loss: 0.08722090721130371
step: 790, loss: 0.07042347639799118
step: 800, loss: 0.1023242175579071
step: 810, loss: 0.07016947865486145
step: 820, loss: 0.15032172203063965
step: 830, loss: 0.16315461695194244
step: 840, loss: 0.11074446886777878
step: 850, loss: 0.12534022331237793
step: 860, loss: 0.06703170388936996
step: 870, loss: 0.06421151757240295
step: 880, loss: 0.03945641964673996
step: 890, loss: 0.043112825602293015
step: 900, loss: 0.05582726001739502
step: 910, loss: 0.020765479654073715
step: 920, loss: 0.012422474101185799
step: 930, loss: 0.10037876665592194
step: 940, loss: 0.10393272340297699
step: 950, loss: 0.05883188545703888
step: 960, loss: 0.020641280338168144
step: 970, loss: 0.016565358266234398
step: 980, loss: 0.018563274294137955
step: 990, loss: 0.042086098343133926
step: 1000, loss: 0.04220585897564888
step: 1010, loss: 0.04816248640418053
step: 1020, loss: 0.06038835644721985
step: 1030, loss: 0.08022195845842361
step: 1040, loss: 0.01920490339398384
step: 1050, loss: 0.015281198546290398
step: 1060, loss: 0.06877452880144119
step: 1070, loss: 0.10641266405582428
epoch 7: dev_f1=0.9444189251263206, f1=0.937442502299908, best_f1=0.937442502299908
step: 0, loss: 0.05362045392394066
step: 10, loss: 0.13272231817245483
step: 20, loss: 0.10804831236600876
step: 30, loss: 0.01453168224543333
step: 40, loss: 0.02095126360654831
step: 50, loss: 0.009123092517256737
step: 60, loss: 0.07636575400829315
step: 70, loss: 0.029466278851032257
step: 80, loss: 0.07158104330301285
step: 90, loss: 0.011920756660401821
step: 100, loss: 0.03136642277240753
step: 110, loss: 0.12888741493225098
step: 120, loss: 0.13663044571876526
step: 130, loss: 0.03440801054239273
step: 140, loss: 0.05901278927922249
step: 150, loss: 0.003154572332277894
step: 160, loss: 0.1703004688024521
step: 170, loss: 0.04995007440447807
step: 180, loss: 0.03304725140333176
step: 190, loss: 0.04824259877204895
step: 200, loss: 0.0725497230887413
step: 210, loss: 0.018508829176425934
step: 220, loss: 0.011871001683175564
step: 230, loss: 0.06858858466148376
step: 240, loss: 0.050296515226364136
step: 250, loss: 0.018546611070632935
step: 260, loss: 0.12920524179935455
step: 270, loss: 0.011267870664596558
step: 280, loss: 0.11218005418777466
step: 290, loss: 0.04082880914211273
step: 300, loss: 0.03893767669796944
step: 310, loss: 0.021630441769957542
step: 320, loss: 0.04597939923405647
step: 330, loss: 0.02963591367006302
step: 340, loss: 0.0423436276614666
step: 350, loss: 0.01928442157804966
step: 360, loss: 0.04060664772987366
step: 370, loss: 0.08493798971176147
step: 380, loss: 0.06995750218629837
step: 390, loss: 0.07539454102516174
step: 400, loss: 0.07066025584936142
step: 410, loss: 0.0206892192363739
step: 420, loss: 0.009045104496181011
step: 430, loss: 0.019574591889977455
step: 440, loss: 0.02637600339949131
step: 450, loss: 0.09637700766324997
step: 460, loss: 0.07691290229558945
step: 470, loss: 0.037613395601511
step: 480, loss: 0.0517902709543705
step: 490, loss: 0.02393479458987713
step: 500, loss: 0.00393518153578043
step: 510, loss: 0.12548747658729553
step: 520, loss: 0.0744083821773529
step: 530, loss: 0.01569436676800251
step: 540, loss: 0.12469501793384552
step: 550, loss: 0.0076324595138430595
step: 560, loss: 0.07269607484340668
step: 570, loss: 0.015841398388147354
step: 580, loss: 0.02320084162056446
step: 590, loss: 0.005592343397438526
step: 600, loss: 0.006723347119987011
step: 610, loss: 0.01792857237160206
step: 620, loss: 0.13739879429340363
step: 630, loss: 0.06757961958646774
step: 640, loss: 0.023319989442825317
step: 650, loss: 0.05486368015408516
step: 660, loss: 0.037927210330963135
step: 670, loss: 0.07085947692394257
step: 680, loss: 0.05324448645114899
step: 690, loss: 0.006094526499509811
step: 700, loss: 0.08654768019914627
step: 710, loss: 0.008956903591752052
step: 720, loss: 0.011766355484724045
step: 730, loss: 0.020414389669895172
step: 740, loss: 0.08920504152774811
step: 750, loss: 0.07132227718830109
step: 760, loss: 0.014584379270672798
step: 770, loss: 0.111058309674263
step: 780, loss: 0.03926333039999008
step: 790, loss: 0.014536536298692226
step: 800, loss: 0.10192041099071503
step: 810, loss: 0.12118379771709442
step: 820, loss: 0.11772719025611877
step: 830, loss: 0.013473204337060452
step: 840, loss: 0.02760935015976429
step: 850, loss: 0.09847118705511093
step: 860, loss: 0.06953345984220505
step: 870, loss: 0.07999782264232635
step: 880, loss: 0.04147365689277649
step: 890, loss: 0.0685446709394455
step: 900, loss: 0.0038451929576694965
step: 910, loss: 0.004730370361357927
step: 920, loss: 0.02005353756248951
step: 930, loss: 0.061134032905101776
step: 940, loss: 0.0513107106089592
step: 950, loss: 0.1754334270954132
step: 960, loss: 0.1312970370054245
step: 970, loss: 0.047203242778778076
step: 980, loss: 0.05263163149356842
step: 990, loss: 0.1640809029340744
step: 1000, loss: 0.04144243523478508
step: 1010, loss: 0.0962040051817894
step: 1020, loss: 0.0376417338848114
step: 1030, loss: 0.022109735757112503
step: 1040, loss: 0.1278732866048813
step: 1050, loss: 0.008495815098285675
step: 1060, loss: 0.009025590494275093
step: 1070, loss: 0.0871296301484108
epoch 8: dev_f1=0.9361305361305362, f1=0.9391705069124424, best_f1=0.937442502299908
step: 0, loss: 0.008883650414645672
step: 10, loss: 0.03844781592488289
step: 20, loss: 0.07604825496673584
step: 30, loss: 0.026633987203240395
step: 40, loss: 0.017352722585201263
step: 50, loss: 0.12171168625354767
step: 60, loss: 0.05943448096513748
step: 70, loss: 0.08217602968215942
step: 80, loss: 0.06985776871442795
step: 90, loss: 0.062495939433574677
step: 100, loss: 0.04225458949804306
step: 110, loss: 0.08343693614006042
step: 120, loss: 0.020657528191804886
step: 130, loss: 0.06596280634403229
step: 140, loss: 0.0027792013715952635
step: 150, loss: 0.00475347600877285
step: 160, loss: 0.018742207437753677
step: 170, loss: 0.2138076275587082
step: 180, loss: 0.23342712223529816
step: 190, loss: 0.0008598980493843555
step: 200, loss: 0.1058783009648323
step: 210, loss: 0.0165556613355875
step: 220, loss: 0.03367149084806442
step: 230, loss: 0.04018671438097954
step: 240, loss: 0.03231107443571091
step: 250, loss: 0.05377813056111336
step: 260, loss: 0.014833700843155384
step: 270, loss: 0.023458877578377724
step: 280, loss: 0.14411252737045288
step: 290, loss: 0.16225087642669678
step: 300, loss: 0.059066206216812134
step: 310, loss: 0.07491852343082428
step: 320, loss: 0.024158013984560966
step: 330, loss: 0.013178461231291294
step: 340, loss: 0.0006265750853344798
step: 350, loss: 0.13390995562076569
step: 360, loss: 0.07361550629138947
step: 370, loss: 0.059411101043224335
step: 380, loss: 0.02236495539546013
step: 390, loss: 0.03250919282436371
step: 400, loss: 0.11822839081287384
step: 410, loss: 0.002745238831266761
step: 420, loss: 0.00306572113186121
step: 430, loss: 0.08519817143678665
step: 440, loss: 0.08784297853708267
step: 450, loss: 0.01917714625597
step: 460, loss: 0.20555128157138824
step: 470, loss: 0.025870997458696365
step: 480, loss: 0.026390699669718742
step: 490, loss: 0.023562481626868248
step: 500, loss: 0.09669317305088043
step: 510, loss: 0.037959158420562744
step: 520, loss: 0.04584984853863716
step: 530, loss: 0.0652136355638504
step: 540, loss: 0.019240856170654297
step: 550, loss: 0.11363930255174637
step: 560, loss: 0.06001538038253784
step: 570, loss: 0.057930342853069305
step: 580, loss: 0.08120901137590408
step: 590, loss: 0.13209517300128937
step: 600, loss: 0.017289798706769943
step: 610, loss: 0.024476993829011917
step: 620, loss: 0.13814783096313477
step: 630, loss: 0.10313601791858673
step: 640, loss: 0.06598140299320221
step: 650, loss: 0.06903158128261566
step: 660, loss: 0.026264343410730362
step: 670, loss: 0.07362816482782364
step: 680, loss: 0.0543544627726078
step: 690, loss: 0.12447133660316467
step: 700, loss: 0.06514637172222137
step: 710, loss: 0.0014807480620220304
step: 720, loss: 0.04654749855399132
step: 730, loss: 0.015820486471056938
step: 740, loss: 0.0162248145788908
step: 750, loss: 0.04895044490695
step: 760, loss: 0.004232348874211311
step: 770, loss: 0.07222539186477661
step: 780, loss: 0.025960490107536316
step: 790, loss: 0.005963093601167202
step: 800, loss: 0.002333033597096801
step: 810, loss: 0.15668097138404846
step: 820, loss: 0.007498925551772118
step: 830, loss: 0.06979484856128693
step: 840, loss: 0.03215166926383972
step: 850, loss: 0.013004475273191929
step: 860, loss: 0.00222209095954895
step: 870, loss: 0.015692275017499924
step: 880, loss: 3.4075983421644196e-05
step: 890, loss: 0.08445479720830917
step: 900, loss: 0.033506959676742554
step: 910, loss: 0.0741271898150444
step: 920, loss: 0.025185896083712578
step: 930, loss: 0.020241353660821915
step: 940, loss: 0.07234258949756622
step: 950, loss: 0.0439610630273819
step: 960, loss: 0.06549707800149918
step: 970, loss: 0.01007450744509697
step: 980, loss: 0.11444482952356339
step: 990, loss: 0.029276102781295776
step: 1000, loss: 0.01070263423025608
step: 1010, loss: 0.0752030685544014
step: 1020, loss: 0.2312544584274292
step: 1030, loss: 0.1343669444322586
step: 1040, loss: 0.10453370958566666
step: 1050, loss: 0.03729309141635895
step: 1060, loss: 0.027358457446098328
step: 1070, loss: 0.18585404753684998
epoch 9: dev_f1=0.9395910780669144, f1=0.937095282146161, best_f1=0.937442502299908
step: 0, loss: 0.014592449180781841
step: 10, loss: 0.003020168049260974
step: 20, loss: 0.03733306750655174
step: 30, loss: 0.09684810042381287
step: 40, loss: 0.014725623652338982
step: 50, loss: 0.04181678965687752
step: 60, loss: 0.04189377278089523
step: 70, loss: 0.07425342500209808
step: 80, loss: 2.578151543275453e-05
step: 90, loss: 0.08841464668512344
step: 100, loss: 0.011259607970714569
step: 110, loss: 0.015466012991964817
step: 120, loss: 0.03859163820743561
step: 130, loss: 0.009883727878332138
step: 140, loss: 0.020904693752527237
step: 150, loss: 0.15079370141029358
step: 160, loss: 0.057360682636499405
step: 170, loss: 0.04313397407531738
step: 180, loss: 0.10155390948057175
step: 190, loss: 0.034820009022951126
step: 200, loss: 0.07307777553796768
step: 210, loss: 0.022334225475788116
step: 220, loss: 0.08530682325363159
step: 230, loss: 0.018615955486893654
step: 240, loss: 0.014974072575569153
step: 250, loss: 0.010517534799873829
step: 260, loss: 0.12318037450313568
step: 270, loss: 0.08692452311515808
step: 280, loss: 0.07669506222009659
step: 290, loss: 0.0001630706392461434
step: 300, loss: 0.09854777902364731
step: 310, loss: 0.09725114703178406
step: 320, loss: 0.05850914120674133
step: 330, loss: 0.038070183247327805
step: 340, loss: 0.030412767082452774
step: 350, loss: 0.00039484247099608183
step: 360, loss: 0.002457117661833763
step: 370, loss: 0.0010698868427425623
step: 380, loss: 0.021476028487086296
step: 390, loss: 0.053183700889348984
step: 400, loss: 0.04777514934539795
step: 410, loss: 0.000592031457927078
step: 420, loss: 0.06613827496767044
step: 430, loss: 0.002225241856649518
step: 440, loss: 0.019980641081929207
step: 450, loss: 0.004091464914381504
step: 460, loss: 0.08196769654750824
step: 470, loss: 0.06699113547801971
step: 480, loss: 0.030123451724648476
step: 490, loss: 0.014605379663407803
step: 500, loss: 0.0027017102111130953
step: 510, loss: 0.15360428392887115
step: 520, loss: 0.025655852630734444
step: 530, loss: 0.018965963274240494
step: 540, loss: 0.06213041767477989
step: 550, loss: 0.02131544053554535
step: 560, loss: 0.12310098111629486
step: 570, loss: 0.03295687586069107
step: 580, loss: 0.037578970193862915
step: 590, loss: 0.012421395629644394
step: 600, loss: 0.027603808790445328
step: 610, loss: 0.009761950001120567
step: 620, loss: 0.05698138102889061
step: 630, loss: 0.06519123911857605
step: 640, loss: 0.07540757954120636
step: 650, loss: 0.033583756536245346
step: 660, loss: 0.06818424165248871
step: 670, loss: 0.018801148980855942
step: 680, loss: 0.12229819595813751
step: 690, loss: 0.13363465666770935
step: 700, loss: 0.10161753743886948
step: 710, loss: 0.031853195279836655
step: 720, loss: 0.009915218688547611
step: 730, loss: 0.06178971752524376
step: 740, loss: 0.04351181909441948
step: 750, loss: 0.14181116223335266
step: 760, loss: 0.008143404498696327
step: 770, loss: 0.023115329444408417
step: 780, loss: 0.005399555899202824
step: 790, loss: 0.0008480094838887453
step: 800, loss: 0.1159425675868988
step: 810, loss: 0.12380345165729523
step: 820, loss: 0.005900965072214603
step: 830, loss: 0.043169304728507996
step: 840, loss: 0.036710500717163086
step: 850, loss: 0.07436779886484146
step: 860, loss: 0.0641263946890831
step: 870, loss: 0.039017580449581146
step: 880, loss: 0.011150362901389599
step: 890, loss: 0.050985947251319885
step: 900, loss: 0.012760652229189873
step: 910, loss: 0.017473923042416573
step: 920, loss: 0.038095902651548386
step: 930, loss: 0.06988365948200226
step: 940, loss: 0.079801544547081
step: 950, loss: 0.028264818713068962
step: 960, loss: 0.03744007274508476
step: 970, loss: 0.030456535518169403
step: 980, loss: 0.03405076265335083
step: 990, loss: 0.04318646341562271
step: 1000, loss: 0.1152145117521286
step: 1010, loss: 0.0390680767595768
step: 1020, loss: 0.030678855255246162
step: 1030, loss: 0.019005054607987404
step: 1040, loss: 0.045618072152137756
step: 1050, loss: 0.04153366759419441
step: 1060, loss: 0.08229580521583557
step: 1070, loss: 0.06947700679302216
epoch 10: dev_f1=0.9371800837598881, f1=0.932963476652797, best_f1=0.937442502299908
step: 0, loss: 0.11585623770952225
step: 10, loss: 0.05511326342821121
step: 20, loss: 8.191863889805973e-05
step: 30, loss: 0.022670550271868706
step: 40, loss: 0.02192128822207451
step: 50, loss: 0.04610211029648781
step: 60, loss: 0.044995058327913284
step: 70, loss: 0.11297518014907837
step: 80, loss: 0.13731420040130615
step: 90, loss: 0.0654740035533905
step: 100, loss: 0.06229503080248833
step: 110, loss: 0.024879200384020805
step: 120, loss: 0.05470479279756546
step: 130, loss: 0.04081196337938309
step: 140, loss: 0.037340469658374786
step: 150, loss: 0.07091900706291199
step: 160, loss: 0.06426301598548889
step: 170, loss: 0.03380681574344635
step: 180, loss: 0.009974404238164425
step: 190, loss: 3.1033720006234944e-05
step: 200, loss: 0.07773140072822571
step: 210, loss: 0.03481433540582657
step: 220, loss: 0.07388530671596527
step: 230, loss: 0.0041299606673419476
step: 240, loss: 0.059908054769039154
step: 250, loss: 0.05773380026221275
step: 260, loss: 0.01880573108792305
step: 270, loss: 0.0013542653759941459
step: 280, loss: 0.046974752098321915
step: 290, loss: 0.06237725913524628
step: 300, loss: 4.458380499272607e-05
step: 310, loss: 0.07579731941223145
step: 320, loss: 3.505284621496685e-05
step: 330, loss: 0.09544240683317184
step: 340, loss: 0.020099185407161713
step: 350, loss: 0.0489126592874527
step: 360, loss: 0.0031618394423276186
step: 370, loss: 0.044852688908576965
step: 380, loss: 0.0007482520304620266
step: 390, loss: 0.04042214900255203
step: 400, loss: 0.027951935306191444
step: 410, loss: 0.003143759910017252
step: 420, loss: 0.028376063331961632
step: 430, loss: 0.025247696787118912
step: 440, loss: 0.1286180168390274
step: 450, loss: 0.03919123113155365
step: 460, loss: 0.007223668973892927
step: 470, loss: 0.0013398448936641216
step: 480, loss: 0.006813558284193277
step: 490, loss: 0.08844311535358429
step: 500, loss: 0.015834281221032143
step: 510, loss: 0.033327363431453705
step: 520, loss: 0.0034314272925257683
step: 530, loss: 0.12916792929172516
step: 540, loss: 0.10408817231655121
step: 550, loss: 0.027291055768728256
step: 560, loss: 0.07229278236627579
step: 570, loss: 0.020429659634828568
step: 580, loss: 0.04170123115181923
step: 590, loss: 0.09299823641777039
step: 600, loss: 0.04819970577955246
step: 610, loss: 0.058677788823843
step: 620, loss: 0.07022479176521301
step: 630, loss: 0.0008565182215534151
step: 640, loss: 0.003919236361980438
step: 650, loss: 0.005610817112028599
step: 660, loss: 1.1566915418370627e-05
step: 670, loss: 0.03570431098341942
step: 680, loss: 0.015286663547158241
step: 690, loss: 0.03336094319820404
step: 700, loss: 0.007871266454458237
step: 710, loss: 0.024575449526309967
step: 720, loss: 0.11005564779043198
step: 730, loss: 0.07323607802391052
step: 740, loss: 0.06324618309736252
step: 750, loss: 0.08175304532051086
step: 760, loss: 0.014998910017311573
step: 770, loss: 0.019333401694893837
step: 780, loss: 0.014391705393791199
step: 790, loss: 0.010655506514012814
step: 800, loss: 0.07839731127023697
step: 810, loss: 0.09995409101247787
step: 820, loss: 0.039319224655628204
step: 830, loss: 0.07043363153934479
step: 840, loss: 0.07995226979255676
step: 850, loss: 0.024346034973859787
step: 860, loss: 0.01939130201935768
step: 870, loss: 0.02025466039776802
step: 880, loss: 0.09599968045949936
step: 890, loss: 0.03544135019183159
step: 900, loss: 0.06816744059324265
step: 910, loss: 0.11144011467695236
step: 920, loss: 0.02962612919509411
step: 930, loss: 0.07511930912733078
step: 940, loss: 0.0716315433382988
step: 950, loss: 0.0008363960077986121
step: 960, loss: 0.024616003036499023
step: 970, loss: 0.043358348309993744
step: 980, loss: 0.0027752190362662077
step: 990, loss: 0.03634319081902504
step: 1000, loss: 0.041838839650154114
step: 1010, loss: 0.03087650053203106
step: 1020, loss: 0.04051796346902847
step: 1030, loss: 0.1049804836511612
step: 1040, loss: 0.0011037380900233984
step: 1050, loss: 0.1405406892299652
step: 1060, loss: 0.02479674480855465
step: 1070, loss: 0.06827893853187561
epoch 11: dev_f1=0.9384544192503471, f1=0.9316081330868762, best_f1=0.937442502299908
step: 0, loss: 0.06621406972408295
step: 10, loss: 0.009965059347450733
step: 20, loss: 0.0454082228243351
step: 30, loss: 0.04132142663002014
step: 40, loss: 0.005934104789048433
step: 50, loss: 0.005950090475380421
step: 60, loss: 0.018446210771799088
step: 70, loss: 0.025408348068594933
step: 80, loss: 0.02428915910422802
step: 90, loss: 0.009565090760588646
step: 100, loss: 0.0011625824263319373
step: 110, loss: 0.06469308584928513
step: 120, loss: 0.07127278298139572
step: 130, loss: 0.1855798214673996
step: 140, loss: 0.039727456867694855
step: 150, loss: 0.022501278668642044
step: 160, loss: 0.14603711664676666
step: 170, loss: 0.03764643892645836
step: 180, loss: 0.026282833889126778
step: 190, loss: 0.003838687902316451
step: 200, loss: 0.0960945263504982
step: 210, loss: 0.0016158047365024686
step: 220, loss: 0.025153299793601036
step: 230, loss: 0.03095341846346855
step: 240, loss: 0.007830802351236343
step: 250, loss: 0.025127029046416283
step: 260, loss: 0.024441733956336975
step: 270, loss: 0.03526824340224266
step: 280, loss: 0.019706357270479202
step: 290, loss: 0.07195374369621277
step: 300, loss: 0.04123563691973686
step: 310, loss: 0.004190732724964619
step: 320, loss: 0.06164756417274475
step: 330, loss: 0.012651312164962292
step: 340, loss: 0.029150396585464478
step: 350, loss: 0.11067475378513336
step: 360, loss: 0.0023013539612293243
step: 370, loss: 0.010127957910299301
step: 380, loss: 0.007061552722007036
step: 390, loss: 0.04669288918375969
step: 400, loss: 0.0528658963739872
step: 410, loss: 0.03758217394351959
step: 420, loss: 0.07879716157913208
step: 430, loss: 0.023451687768101692
step: 440, loss: 0.028531745076179504
step: 450, loss: 0.043873295187950134
step: 460, loss: 0.04532915726304054
step: 470, loss: 0.022916793823242188
step: 480, loss: 0.009601700119674206
step: 490, loss: 0.035492151975631714
step: 500, loss: 0.006260123569518328
step: 510, loss: 0.013025290332734585
step: 520, loss: 0.07617688924074173
step: 530, loss: 0.01036788523197174
step: 540, loss: 0.01603567600250244
step: 550, loss: 0.10099407285451889
step: 560, loss: 0.000649340683594346
step: 570, loss: 0.01916295662522316
step: 580, loss: 0.036620642989873886
step: 590, loss: 0.0026433065067976713
step: 600, loss: 0.013571285642683506
step: 610, loss: 0.0006645744433626533
step: 620, loss: 0.005553661845624447
step: 630, loss: 0.11537756770849228
step: 640, loss: 0.05923927575349808
step: 650, loss: 0.06671807914972305
step: 660, loss: 0.021788883954286575
step: 670, loss: 0.08257517218589783
step: 680, loss: 0.04732713848352432
step: 690, loss: 0.03465649113059044
step: 700, loss: 0.022494029253721237
step: 710, loss: 0.08131884038448334
step: 720, loss: 0.0015941632445901632
step: 730, loss: 0.012485728599131107
step: 740, loss: 0.03472958877682686
step: 750, loss: 0.15693141520023346
step: 760, loss: 0.01713193766772747
step: 770, loss: 0.042186275124549866
step: 780, loss: 0.01272631622850895
step: 790, loss: 0.017127200961112976
step: 800, loss: 0.00198302767239511
step: 810, loss: 0.10844945162534714
step: 820, loss: 0.026492033153772354
step: 830, loss: 0.01939036138355732
step: 840, loss: 0.003872724249958992
step: 850, loss: 0.049879562109708786
step: 860, loss: 0.07357098907232285
step: 870, loss: 0.036012306809425354
step: 880, loss: 0.052124377340078354
step: 890, loss: 0.03550005331635475
step: 900, loss: 0.12171623855829239
step: 910, loss: 0.02803167514503002
step: 920, loss: 0.10689123719930649
step: 930, loss: 0.047428831458091736
step: 940, loss: 0.016941474750638008
step: 950, loss: 0.004396018106490374
step: 960, loss: 0.022257328033447266
step: 970, loss: 0.032823991030454636
step: 980, loss: 0.034986693412065506
step: 990, loss: 0.024825112894177437
step: 1000, loss: 0.011575780808925629
step: 1010, loss: 0.00025206891587004066
step: 1020, loss: 0.03723035007715225
step: 1030, loss: 0.0010752268135547638
step: 1040, loss: 0.0009617827017791569
step: 1050, loss: 0.11782395839691162
step: 1060, loss: 0.04376780614256859
step: 1070, loss: 0.038784585893154144
epoch 12: dev_f1=0.9402644778841769, f1=0.928377153218495, best_f1=0.937442502299908
step: 0, loss: 0.046195559203624725
step: 10, loss: 0.028292255476117134
step: 20, loss: 0.005303761921823025
step: 30, loss: 0.01868552342057228
step: 40, loss: 0.06652390956878662
step: 50, loss: 0.027273647487163544
step: 60, loss: 0.02607905864715576
step: 70, loss: 0.056250542402267456
step: 80, loss: 0.03874407708644867
step: 90, loss: 0.09005805850028992
step: 100, loss: 0.0012725726701319218
step: 110, loss: 0.001035891706123948
step: 120, loss: 0.04845047742128372
step: 130, loss: 0.034416988492012024
step: 140, loss: 0.07952860742807388
step: 150, loss: 0.03834577649831772
step: 160, loss: 0.032124005258083344
step: 170, loss: 0.03850984200835228
step: 180, loss: 0.0006615674938075244
step: 190, loss: 0.019600914791226387
step: 200, loss: 0.06509803980588913
step: 210, loss: 0.07994863390922546
step: 220, loss: 0.0010953819146379828
step: 230, loss: 0.02114708349108696
step: 240, loss: 0.0003458714345470071
step: 250, loss: 0.06734973937273026
step: 260, loss: 0.04153049364686012
step: 270, loss: 3.642099181888625e-05
step: 280, loss: 0.07465814799070358
step: 290, loss: 0.04767928272485733
step: 300, loss: 0.004571538884192705
step: 310, loss: 0.05678641423583031
step: 320, loss: 0.004929880611598492
step: 330, loss: 0.11207535117864609
step: 340, loss: 0.0433422215282917
step: 350, loss: 0.031135687604546547
step: 360, loss: 0.0019753864035010338
step: 370, loss: 0.05272690951824188
step: 380, loss: 0.03892084211111069
step: 390, loss: 0.02805759757757187
step: 400, loss: 0.022634055465459824
step: 410, loss: 0.01670161448419094
step: 420, loss: 0.014318101108074188
step: 430, loss: 0.025815267115831375
step: 440, loss: 0.06541000306606293
step: 450, loss: 0.0004549079167190939
step: 460, loss: 0.05196236073970795
step: 470, loss: 0.10228928178548813
step: 480, loss: 0.04709934443235397
step: 490, loss: 0.08263631910085678
step: 500, loss: 0.0024750877637416124
step: 510, loss: 0.04290548712015152
step: 520, loss: 0.0016793898539617658
step: 530, loss: 0.001635245280340314
step: 540, loss: 0.09003876149654388
step: 550, loss: 0.04260893166065216
step: 560, loss: 0.06722130626440048
step: 570, loss: 0.05975542590022087
step: 580, loss: 0.0386807881295681
step: 590, loss: 0.037343110889196396
step: 600, loss: 0.03649454936385155
step: 610, loss: 0.023898854851722717
step: 620, loss: 0.03650958091020584
step: 630, loss: 0.037963882088661194
step: 640, loss: 0.04345231503248215
step: 650, loss: 0.0009875644464045763
step: 660, loss: 0.04907984286546707
step: 670, loss: 0.022305108606815338
step: 680, loss: 0.014353806152939796
step: 690, loss: 0.02583836205303669
step: 700, loss: 0.02024843730032444
step: 710, loss: 0.00018067170458380133
step: 720, loss: 0.01859104633331299
step: 730, loss: 0.026224913075566292
step: 740, loss: 0.004055207595229149
step: 750, loss: 0.03717423975467682
step: 760, loss: 0.024036258459091187
step: 770, loss: 0.2676072418689728
step: 780, loss: 0.003371954895555973
step: 790, loss: 0.01932559534907341
step: 800, loss: 0.0361313559114933
step: 810, loss: 0.027831589803099632
step: 820, loss: 0.045992955565452576
step: 830, loss: 0.0031111445277929306
step: 840, loss: 0.05565125122666359
step: 850, loss: 0.03904469683766365
step: 860, loss: 0.052839647978544235
step: 870, loss: 0.021596118807792664
step: 880, loss: 0.03179829195141792
step: 890, loss: 0.03414604067802429
step: 900, loss: 0.021303808316588402
step: 910, loss: 0.0354672372341156
step: 920, loss: 0.044634826481342316
step: 930, loss: 0.023176683112978935
step: 940, loss: 0.022437069565057755
step: 950, loss: 0.00013214684440754354
step: 960, loss: 0.07542193681001663
step: 970, loss: 0.027710238471627235
step: 980, loss: 0.006047683767974377
step: 990, loss: 0.0037879114970564842
step: 1000, loss: 0.024409202858805656
step: 1010, loss: 0.04330815374851227
step: 1020, loss: 0.04601096734404564
step: 1030, loss: 0.03760836273431778
step: 1040, loss: 0.0006512402324005961
step: 1050, loss: 0.010720986872911453
step: 1060, loss: 0.014544973149895668
step: 1070, loss: 0.019024791195988655
epoch 13: dev_f1=0.9385884509624199, f1=0.927956502038967, best_f1=0.937442502299908
step: 0, loss: 0.00014591720537282526
step: 10, loss: 0.02733936533331871
step: 20, loss: 0.029073970392346382
step: 30, loss: 0.015582704916596413
step: 40, loss: 6.497321010101587e-05
step: 50, loss: 0.026003699749708176
step: 60, loss: 0.012659651227295399
step: 70, loss: 0.04248175024986267
step: 80, loss: 0.00044866371899843216
step: 90, loss: 0.0006825372693128884
step: 100, loss: 0.0780191570520401
step: 110, loss: 0.04094398021697998
step: 120, loss: 0.0005614076508209109
step: 130, loss: 0.06563208252191544
step: 140, loss: 0.027409860864281654
step: 150, loss: 0.03597398102283478
step: 160, loss: 6.872111407574266e-05
step: 170, loss: 0.0011970392661169171
step: 180, loss: 6.624088564421982e-05
step: 190, loss: 0.04923296347260475
step: 200, loss: 0.020252887159585953
step: 210, loss: 0.05255601927638054
step: 220, loss: 0.0028508086688816547
step: 230, loss: 0.0002723739598877728
step: 240, loss: 0.00010651693446561694
step: 250, loss: 6.676765042357147e-05
step: 260, loss: 0.0002899449900723994
step: 270, loss: 0.08979728817939758
step: 280, loss: 0.04729358106851578
step: 290, loss: 0.030759038403630257
step: 300, loss: 1.561980570841115e-05
step: 310, loss: 0.07223572582006454
step: 320, loss: 0.002636504592373967
step: 330, loss: 0.07063207775354385
step: 340, loss: 0.018633514642715454
step: 350, loss: 0.0403861328959465
step: 360, loss: 0.0024460048880428076
step: 370, loss: 0.023453831672668457
step: 380, loss: 0.03191208839416504
step: 390, loss: 0.0009682615054771304
step: 400, loss: 0.023048441857099533
step: 410, loss: 0.09078943729400635
step: 420, loss: 0.029697300866246223
step: 430, loss: 0.018189499154686928
step: 440, loss: 0.0030033544171601534
step: 450, loss: 0.0009967121295630932
step: 460, loss: 0.02664492465555668
step: 470, loss: 0.00012886742479167879
step: 480, loss: 0.01929682306945324
step: 490, loss: 0.025602633133530617
step: 500, loss: 0.0006219744682312012
step: 510, loss: 0.0032610115595161915
step: 520, loss: 0.0257195346057415
step: 530, loss: 0.03972911834716797
step: 540, loss: 0.09385745972394943
step: 550, loss: 0.04801715910434723
step: 560, loss: 0.004838092718273401
step: 570, loss: 0.05107984319329262
step: 580, loss: 0.09424768388271332
step: 590, loss: 0.06643150746822357
step: 600, loss: 0.0714588612318039
step: 610, loss: 0.022168532013893127
step: 620, loss: 0.008555283769965172
step: 630, loss: 0.03790384158492088
step: 640, loss: 0.0021811979822814465
step: 650, loss: 0.003622123971581459
step: 660, loss: 0.012188958004117012
step: 670, loss: 0.027976635843515396
step: 680, loss: 0.0482337586581707
step: 690, loss: 0.0022553158923983574
step: 700, loss: 0.0578063540160656
step: 710, loss: 0.00821575615555048
step: 720, loss: 0.008109035901725292
step: 730, loss: 0.026284245774149895
step: 740, loss: 0.0013390814419835806
step: 750, loss: 0.03021232783794403
step: 760, loss: 0.07179141789674759
step: 770, loss: 2.9907256248407066e-05
step: 780, loss: 0.03139987587928772
step: 790, loss: 1.9013212295249104e-05
step: 800, loss: 0.00849334616214037
step: 810, loss: 0.04635497182607651
step: 820, loss: 8.011172758415341e-05
step: 830, loss: 0.0008451293688267469
step: 840, loss: 0.03229639679193497
step: 850, loss: 0.018490858376026154
step: 860, loss: 0.08071094751358032
step: 870, loss: 0.014847425743937492
step: 880, loss: 0.02486717514693737
step: 890, loss: 2.601894630060997e-05
step: 900, loss: 0.04214514046907425
step: 910, loss: 0.07019447535276413
step: 920, loss: 0.002010771306231618
step: 930, loss: 0.0120741818100214
step: 940, loss: 0.0330413393676281
step: 950, loss: 0.01148734800517559
step: 960, loss: 0.025354115292429924
step: 970, loss: 0.06773558259010315
step: 980, loss: 0.0002327134570805356
step: 990, loss: 0.007833163253962994
step: 1000, loss: 0.021125653758645058
step: 1010, loss: 0.026848098263144493
step: 1020, loss: 0.03679041936993599
step: 1030, loss: 0.022284653037786484
step: 1040, loss: 0.07520107179880142
step: 1050, loss: 0.04499337822198868
step: 1060, loss: 0.016078902408480644
step: 1070, loss: 0.0008310019038617611
epoch 14: dev_f1=0.9374714742126883, f1=0.932249322493225, best_f1=0.937442502299908
step: 0, loss: 0.00018112627731170505
step: 10, loss: 0.1136750653386116
step: 20, loss: 0.027067868039011955
step: 30, loss: 0.09528794139623642
step: 40, loss: 0.009404820390045643
step: 50, loss: 0.03179989755153656
step: 60, loss: 0.020836884155869484
step: 70, loss: 0.0013037999160587788
step: 80, loss: 0.11785697191953659
step: 90, loss: 0.05465705692768097
step: 100, loss: 0.008061179891228676
step: 110, loss: 0.07848513871431351
step: 120, loss: 0.06470507383346558
step: 130, loss: 0.011074488051235676
step: 140, loss: 0.004002072848379612
step: 150, loss: 0.00576922157779336
step: 160, loss: 0.029921118170022964
step: 170, loss: 0.05370166897773743
step: 180, loss: 2.479969771229662e-05
step: 190, loss: 0.010545815341174603
step: 200, loss: 0.00534861208871007
step: 210, loss: 2.640432649059221e-05
step: 220, loss: 0.00248948996886611
step: 230, loss: 0.04406164586544037
step: 240, loss: 0.0628773495554924
step: 250, loss: 0.05446028709411621
step: 260, loss: 0.000561732507776469
step: 270, loss: 0.06593123078346252
step: 280, loss: 0.034918978810310364
step: 290, loss: 0.02281002514064312
step: 300, loss: 0.05066980421543121
step: 310, loss: 0.047408442944288254
step: 320, loss: 0.026687510311603546
step: 330, loss: 0.08371447771787643
step: 340, loss: 0.010587389580905437
step: 350, loss: 0.0007977375644259155
step: 360, loss: 0.20395544171333313
step: 370, loss: 2.4409888283116743e-05
step: 380, loss: 0.030109774321317673
step: 390, loss: 0.1889977604150772
step: 400, loss: 0.0781218558549881
step: 410, loss: 0.10199983417987823
step: 420, loss: 0.030050138011574745
step: 430, loss: 0.022018160670995712
step: 440, loss: 0.020251767709851265
step: 450, loss: 0.027053512632846832
step: 460, loss: 0.056826669722795486
step: 470, loss: 9.543461783323437e-05
step: 480, loss: 0.012661687098443508
step: 490, loss: 7.104356336640194e-05
step: 500, loss: 0.03991188481450081
step: 510, loss: 0.08580572158098221
step: 520, loss: 0.03560285642743111
step: 530, loss: 0.02053394354879856
step: 540, loss: 0.06467269361019135
step: 550, loss: 0.0026409183628857136
step: 560, loss: 0.02286529913544655
step: 570, loss: 5.045844955020584e-05
step: 580, loss: 0.07020942121744156
step: 590, loss: 0.0508638434112072
step: 600, loss: 0.0029822022188454866
step: 610, loss: 0.02103382721543312
step: 620, loss: 0.03554176911711693
step: 630, loss: 0.022146446630358696
step: 640, loss: 0.03631838038563728
step: 650, loss: 0.07009314000606537
step: 660, loss: 0.032976631075143814
step: 670, loss: 0.00044558546505868435
step: 680, loss: 0.0303703173995018
step: 690, loss: 0.07141333818435669
step: 700, loss: 0.05422738939523697
step: 710, loss: 0.04645398259162903
step: 720, loss: 0.0023146048188209534
step: 730, loss: 0.06216449290513992
step: 740, loss: 0.08108147978782654
step: 750, loss: 3.752511111088097e-05
step: 760, loss: 0.026329629123210907
step: 770, loss: 0.029129352420568466
step: 780, loss: 0.0558035671710968
step: 790, loss: 0.03410298749804497
step: 800, loss: 0.019698243588209152
step: 810, loss: 0.09028375148773193
step: 820, loss: 0.0012548668310046196
step: 830, loss: 1.795183925423771e-05
step: 840, loss: 0.03011314757168293
step: 850, loss: 0.000157349873916246
step: 860, loss: 0.0030797715298831463
step: 870, loss: 0.02171233482658863
step: 880, loss: 0.011908994987607002
step: 890, loss: 0.018437858670949936
step: 900, loss: 0.05098099634051323
step: 910, loss: 3.446243499638513e-05
step: 920, loss: 0.03888164460659027
step: 930, loss: 0.02077529765665531
step: 940, loss: 0.01732165738940239
step: 950, loss: 0.024840304628014565
step: 960, loss: 0.045046743005514145
step: 970, loss: 0.01226599607616663
step: 980, loss: 0.053429484367370605
step: 990, loss: 0.003991647157818079
step: 1000, loss: 0.01703137531876564
step: 1010, loss: 0.09122997522354126
step: 1020, loss: 0.00015718606300652027
step: 1030, loss: 0.0694253221154213
step: 1040, loss: 0.05997961014509201
step: 1050, loss: 0.03706808015704155
step: 1060, loss: 0.021397069096565247
step: 1070, loss: 0.09218490123748779
epoch 15: dev_f1=0.9374130737134909, f1=0.9282739472466451, best_f1=0.937442502299908
step: 0, loss: 0.017992012202739716
step: 10, loss: 0.0009546121000312269
step: 20, loss: 0.04073056951165199
step: 30, loss: 0.05991974472999573
step: 40, loss: 0.015509221702814102
step: 50, loss: 0.024020211771130562
step: 60, loss: 0.024047303944826126
step: 70, loss: 0.024688275530934334
step: 80, loss: 0.042342785745859146
step: 90, loss: 0.02328099124133587
step: 100, loss: 0.00024918862618505955
step: 110, loss: 0.032879069447517395
step: 120, loss: 0.0340525321662426
step: 130, loss: 0.024568699300289154
step: 140, loss: 0.04604354873299599
step: 150, loss: 3.287879371782765e-05
step: 160, loss: 0.01338490005582571
step: 170, loss: 0.00012229077401570976
step: 180, loss: 0.08748192340135574
step: 190, loss: 4.4782118493458256e-05
step: 200, loss: 0.036194853484630585
step: 210, loss: 0.18942564725875854
step: 220, loss: 0.0804070383310318
step: 230, loss: 0.08088705688714981
step: 240, loss: 0.051094383001327515
step: 250, loss: 9.034189861267805e-05
step: 260, loss: 0.03577655181288719
step: 270, loss: 7.071818254189566e-05
step: 280, loss: 0.015000816434621811
step: 290, loss: 0.00010564427066128701
step: 300, loss: 0.0032619743142277002
step: 310, loss: 0.0003854437964037061
step: 320, loss: 2.7767006031353958e-05
step: 330, loss: 0.10905437171459198
step: 340, loss: 0.039873845875263214
step: 350, loss: 0.13061222434043884
step: 360, loss: 3.641576040536165e-05
step: 370, loss: 0.005647304467856884
step: 380, loss: 0.045235615223646164
step: 390, loss: 4.858477404923178e-05
step: 400, loss: 0.00017642042075749487
step: 410, loss: 7.961730443639681e-05
step: 420, loss: 0.08897852152585983
step: 430, loss: 0.04805310443043709
step: 440, loss: 0.013363647274672985
step: 450, loss: 0.023225929588079453
step: 460, loss: 0.17779143154621124
step: 470, loss: 0.02122272178530693
step: 480, loss: 0.025261899456381798
step: 490, loss: 0.03303329274058342
step: 500, loss: 0.03431165963411331
step: 510, loss: 0.037739500403404236
step: 520, loss: 0.08649296313524246
step: 530, loss: 0.03876832127571106
step: 540, loss: 0.026278182864189148
step: 550, loss: 0.00012330792378634214
step: 560, loss: 0.029779735952615738
step: 570, loss: 0.031619057059288025
step: 580, loss: 3.385011950740591e-05
step: 590, loss: 0.056338392198085785
step: 600, loss: 8.203770994441584e-05
step: 610, loss: 0.015358077362179756
step: 620, loss: 0.0348447822034359
step: 630, loss: 0.029181884601712227
step: 640, loss: 0.0036797288339585066
step: 650, loss: 6.0904956626472995e-05
step: 660, loss: 2.0931365725118667e-05
step: 670, loss: 0.021103180944919586
step: 680, loss: 0.058233339339494705
step: 690, loss: 0.08132530748844147
step: 700, loss: 4.445975719136186e-05
step: 710, loss: 0.06439715623855591
step: 720, loss: 0.0020343931391835213
step: 730, loss: 0.04788144305348396
step: 740, loss: 0.03511706739664078
step: 750, loss: 0.052194658666849136
step: 760, loss: 0.0226331427693367
step: 770, loss: 0.0007525228429585695
step: 780, loss: 0.018127495422959328
step: 790, loss: 0.030346864834427834
step: 800, loss: 4.1033043089555576e-05
step: 810, loss: 0.003193299286067486
step: 820, loss: 0.00015937280841171741
step: 830, loss: 0.021872933954000473
step: 840, loss: 0.016293738037347794
step: 850, loss: 0.00015748775331303477
step: 860, loss: 0.045440781861543655
step: 870, loss: 0.04554131627082825
step: 880, loss: 0.07291453331708908
step: 890, loss: 0.04208644852042198
step: 900, loss: 0.014733763411641121
step: 910, loss: 0.029482197016477585
step: 920, loss: 0.009695830754935741
step: 930, loss: 0.07215481251478195
step: 940, loss: 0.047859497368335724
step: 950, loss: 0.0318576917052269
step: 960, loss: 0.0416572131216526
step: 970, loss: 0.017191961407661438
step: 980, loss: 0.0037293059285730124
step: 990, loss: 0.0027882340364158154
step: 1000, loss: 0.02103843167424202
step: 1010, loss: 5.8128094678977504e-05
step: 1020, loss: 0.0008699289173819125
step: 1030, loss: 0.01939617469906807
step: 1040, loss: 0.01984347775578499
step: 1050, loss: 0.001999652711674571
step: 1060, loss: 0.02270757593214512
step: 1070, loss: 0.03780105710029602
epoch 16: dev_f1=0.9333945796968306, f1=0.9293205654354765, best_f1=0.937442502299908
step: 0, loss: 0.00040274689672514796
step: 10, loss: 0.03614244610071182
step: 20, loss: 0.020165076479315758
step: 30, loss: 0.00018688515410758555
step: 40, loss: 4.8181093006860465e-05
step: 50, loss: 0.018501129001379013
step: 60, loss: 0.028206171467900276
step: 70, loss: 0.015132349915802479
step: 80, loss: 0.00011815426842076704
step: 90, loss: 0.0005297695170156658
step: 100, loss: 0.030969642102718353
step: 110, loss: 0.00011993404041277245
step: 120, loss: 0.04539690539240837
step: 130, loss: 0.00017349314293824136
step: 140, loss: 0.0016169011360034347
step: 150, loss: 0.032947901636362076
step: 160, loss: 0.04460825026035309
step: 170, loss: 0.0233716182410717
step: 180, loss: 0.02859731763601303
step: 190, loss: 0.004803612362593412
step: 200, loss: 7.442524656653404e-05
step: 210, loss: 0.0011267340742051601
step: 220, loss: 0.00013234476500656456
step: 230, loss: 0.023241491988301277
step: 240, loss: 0.021729161962866783
step: 250, loss: 0.12448014318943024
step: 260, loss: 0.0271215308457613
step: 270, loss: 0.0030828905291855335
step: 280, loss: 0.0626038908958435
step: 290, loss: 0.016000058501958847
step: 300, loss: 0.01832222007215023
step: 310, loss: 0.018340913578867912
step: 320, loss: 0.007322062272578478
step: 330, loss: 0.03573671728372574
step: 340, loss: 0.021244758740067482
step: 350, loss: 5.332226646714844e-05
step: 360, loss: 0.0020427838899195194
step: 370, loss: 0.0610799714922905
step: 380, loss: 0.0019184972625225782
step: 390, loss: 0.034436509013175964
step: 400, loss: 0.00010775269038276747
step: 410, loss: 3.8802074413979426e-05
step: 420, loss: 0.023411905393004417
step: 430, loss: 0.05343075096607208
step: 440, loss: 0.02203594334423542
step: 450, loss: 0.046737223863601685
step: 460, loss: 5.5385895393555984e-05
step: 470, loss: 0.03947710618376732
step: 480, loss: 0.03678940609097481
step: 490, loss: 0.015676522627472878
step: 500, loss: 0.051473937928676605
step: 510, loss: 0.004794557578861713
step: 520, loss: 0.03625737130641937
step: 530, loss: 0.035609278827905655
step: 540, loss: 0.02061242237687111
step: 550, loss: 0.04385325685143471
step: 560, loss: 0.03698018565773964
step: 570, loss: 0.030624747276306152
step: 580, loss: 0.04860730096697807
step: 590, loss: 0.00024405712611041963
step: 600, loss: 0.02324533462524414
step: 610, loss: 0.0013505617389455438
step: 620, loss: 0.02378268353641033
step: 630, loss: 0.0011932910420000553
step: 640, loss: 0.02386164292693138
step: 650, loss: 0.058813612908124924
step: 660, loss: 0.0025898104067891836
step: 670, loss: 0.05256136506795883
step: 680, loss: 0.019609985873103142
step: 690, loss: 0.06079455837607384
step: 700, loss: 0.001176104648038745
step: 710, loss: 0.08195146173238754
step: 720, loss: 8.631952368887141e-05
step: 730, loss: 0.02192530408501625
step: 740, loss: 0.0476936511695385
step: 750, loss: 0.13369344174861908
step: 760, loss: 0.06328767538070679
step: 770, loss: 0.00014552257198374718
step: 780, loss: 0.020612357184290886
step: 790, loss: 0.004656489007174969
step: 800, loss: 0.02453920803964138
step: 810, loss: 0.0484745167195797
step: 820, loss: 0.00030455144587904215
step: 830, loss: 0.08475188910961151
step: 840, loss: 0.027897724881768227
step: 850, loss: 1.167490700026974e-05
step: 860, loss: 0.020195743069052696
step: 870, loss: 0.0009951991960406303
step: 880, loss: 0.02254488505423069
step: 890, loss: 0.017863282933831215
step: 900, loss: 0.020565640181303024
step: 910, loss: 2.5255087166442536e-05
step: 920, loss: 0.04551750421524048
step: 930, loss: 0.042960088700056076
step: 940, loss: 0.024018950760364532
step: 950, loss: 0.008826573379337788
step: 960, loss: 0.038713499903678894
step: 970, loss: 0.03237837553024292
step: 980, loss: 0.03740745782852173
step: 990, loss: 0.05340098962187767
step: 1000, loss: 0.029163263738155365
step: 1010, loss: 0.010126570239663124
step: 1020, loss: 9.87093590083532e-05
step: 1030, loss: 3.1876363209448755e-05
step: 1040, loss: 0.16946353018283844
step: 1050, loss: 0.0441717728972435
step: 1060, loss: 0.0001032080253935419
step: 1070, loss: 0.0148641187697649
epoch 17: dev_f1=0.9314685314685315, f1=0.9308584686774942, best_f1=0.937442502299908
step: 0, loss: 0.05419240891933441
step: 10, loss: 0.01763894408941269
step: 20, loss: 0.0005685603246092796
step: 30, loss: 0.018582794815301895
step: 40, loss: 0.00041163680725730956
step: 50, loss: 1.3775909792457242e-05
step: 60, loss: 0.00012340252578724176
step: 70, loss: 0.02064508944749832
step: 80, loss: 0.00013909924018662423
step: 90, loss: 0.02724534645676613
step: 100, loss: 0.04306034743785858
step: 110, loss: 0.0166863352060318
step: 120, loss: 0.02877780981361866
step: 130, loss: 0.00010979087528539822
step: 140, loss: 0.00010802589531522244
step: 150, loss: 0.015205977484583855
step: 160, loss: 0.038530997931957245
step: 170, loss: 0.04794098064303398
step: 180, loss: 0.07175737619400024
step: 190, loss: 0.020645301789045334
step: 200, loss: 1.3850455616193358e-05
step: 210, loss: 0.021709291264414787
step: 220, loss: 0.00015319477824959904
step: 230, loss: 1.5667994375689887e-05
step: 240, loss: 2.9410542992991395e-05
step: 250, loss: 0.019939566031098366
step: 260, loss: 0.06042607128620148
step: 270, loss: 6.131809641374275e-05
step: 280, loss: 0.02547266334295273
step: 290, loss: 0.029808949679136276
step: 300, loss: 0.0002945031737908721
step: 310, loss: 0.01867526024580002
step: 320, loss: 0.03566661477088928
step: 330, loss: 4.254915620549582e-05
step: 340, loss: 0.02163241244852543
step: 350, loss: 4.883034125668928e-05
step: 360, loss: 0.05319897085428238
step: 370, loss: 0.05353022739291191
step: 380, loss: 0.0003434864629525691
step: 390, loss: 0.02304108999669552
step: 400, loss: 0.024711862206459045
step: 410, loss: 0.0608099140226841
step: 420, loss: 0.03050214983522892
step: 430, loss: 0.021442169323563576
step: 440, loss: 0.023426325991749763
step: 450, loss: 2.008875526371412e-05
step: 460, loss: 0.05780409276485443
step: 470, loss: 0.021027475595474243
step: 480, loss: 0.02932775393128395
step: 490, loss: 0.03114587813615799
step: 500, loss: 2.8734360967064276e-05
step: 510, loss: 0.0414615161716938
step: 520, loss: 0.032472264021635056
step: 530, loss: 0.004881289787590504
step: 540, loss: 0.0002862152468878776
step: 550, loss: 0.03334953263401985
step: 560, loss: 0.05281027778983116
step: 570, loss: 0.00038399334880523384
step: 580, loss: 0.022448919713497162
step: 590, loss: 5.0376609578961506e-05
step: 600, loss: 0.027816258370876312
step: 610, loss: 0.024549171328544617
step: 620, loss: 0.02353547140955925
step: 630, loss: 0.0379304401576519
step: 640, loss: 0.00012442590377759188
step: 650, loss: 0.021556567400693893
step: 660, loss: 0.003128780983388424
step: 670, loss: 0.03963270038366318
step: 680, loss: 0.014838232658803463
step: 690, loss: 0.00019723687728401273
step: 700, loss: 0.04615609720349312
step: 710, loss: 0.03215351700782776
step: 720, loss: 0.05395040288567543
step: 730, loss: 0.037230636924505234
step: 740, loss: 0.05652617663145065
step: 750, loss: 0.0298925768584013
step: 760, loss: 0.0011937826639041305
step: 770, loss: 0.016022156924009323
step: 780, loss: 0.023843249306082726
step: 790, loss: 0.02692832052707672
step: 800, loss: 0.038574691861867905
step: 810, loss: 0.051276691257953644
step: 820, loss: 3.225085310987197e-05
step: 830, loss: 0.019140848889946938
step: 840, loss: 0.00042029639007523656
step: 850, loss: 0.03127896413207054
step: 860, loss: 0.023170428350567818
step: 870, loss: 0.017456959933042526
step: 880, loss: 0.04448910802602768
step: 890, loss: 0.0057899062521755695
step: 900, loss: 1.951938793354202e-05
step: 910, loss: 0.000325717031955719
step: 920, loss: 0.03397345170378685
step: 930, loss: 0.007232407573610544
step: 940, loss: 0.0022326926700770855
step: 950, loss: 0.04114284738898277
step: 960, loss: 3.339148315717466e-05
step: 970, loss: 0.0019035607110708952
step: 980, loss: 0.05093824863433838
step: 990, loss: 0.04963591694831848
step: 1000, loss: 0.0007266722968779504
step: 1010, loss: 8.364859968423843e-05
step: 1020, loss: 0.00017710356041789055
step: 1030, loss: 0.1050785705447197
step: 1040, loss: 0.06376176327466965
step: 1050, loss: 0.06981956958770752
step: 1060, loss: 0.020372238010168076
step: 1070, loss: 0.046634603291749954
epoch 18: dev_f1=0.9322191272051997, f1=0.9310504396112911, best_f1=0.937442502299908
step: 0, loss: 0.01393810287117958
step: 10, loss: 0.05843305587768555
step: 20, loss: 0.06060659885406494
step: 30, loss: 0.022187020629644394
step: 40, loss: 0.07771273702383041
step: 50, loss: 0.0002305380185134709
step: 60, loss: 0.0002158426068490371
step: 70, loss: 0.04653213918209076
step: 80, loss: 0.010166068561375141
step: 90, loss: 0.001721586799249053
step: 100, loss: 0.00015856485697440803
step: 110, loss: 0.007951063103973866
step: 120, loss: 0.016575472429394722
step: 130, loss: 0.028560347855091095
step: 140, loss: 1.1581780199776404e-05
step: 150, loss: 0.06552240252494812
step: 160, loss: 0.020115163177251816
step: 170, loss: 0.04449298605322838
step: 180, loss: 0.023841334506869316
step: 190, loss: 0.06258121132850647
step: 200, loss: 3.6918045225320384e-05
step: 210, loss: 0.023479647934436798
step: 220, loss: 0.025722302496433258
step: 230, loss: 0.00010424594802316278
step: 240, loss: 0.044582318514585495
step: 250, loss: 1.2922710084239952e-05
step: 260, loss: 0.054993048310279846
step: 270, loss: 0.00010023253707913682
step: 280, loss: 0.00043170404387637973
step: 290, loss: 0.022583885118365288
step: 300, loss: 0.028427844867110252
step: 310, loss: 0.08458340167999268
step: 320, loss: 3.605069650802761e-05
step: 330, loss: 0.006643315777182579
step: 340, loss: 0.03079671412706375
step: 350, loss: 0.025159142911434174
step: 360, loss: 0.02715194597840309
step: 370, loss: 0.024416092783212662
step: 380, loss: 2.7278518246021122e-05
step: 390, loss: 0.0725320354104042
step: 400, loss: 0.02904873713850975
step: 410, loss: 0.04529070854187012
step: 420, loss: 0.00015378755051642656
step: 430, loss: 0.03123416379094124
step: 440, loss: 0.0027259155176579952
step: 450, loss: 0.03721103444695473
step: 460, loss: 0.013002702035009861
step: 470, loss: 0.04221063479781151
step: 480, loss: 4.2978921555913985e-05
step: 490, loss: 4.4710868678521365e-05
step: 500, loss: 0.02649211511015892
step: 510, loss: 0.02152979001402855
step: 520, loss: 0.016060957685112953
step: 530, loss: 0.00013028371904511005
step: 540, loss: 0.10901432484388351
step: 550, loss: 0.0316019244492054
step: 560, loss: 2.9281571187311783e-05
step: 570, loss: 0.040201764553785324
step: 580, loss: 0.02335406094789505
step: 590, loss: 0.007728885859251022
step: 600, loss: 0.021606022492051125
step: 610, loss: 0.045440755784511566
step: 620, loss: 0.025940222665667534
step: 630, loss: 0.010660440661013126
step: 640, loss: 0.00031001222669146955
step: 650, loss: 0.06278626620769501
step: 660, loss: 0.0004948859568685293
step: 670, loss: 1.9310253264848143e-05
step: 680, loss: 3.0163386327330954e-05
step: 690, loss: 0.04434298723936081
step: 700, loss: 0.03213155269622803
step: 710, loss: 6.016816769260913e-05
step: 720, loss: 0.015194653533399105
step: 730, loss: 0.014727834612131119
step: 740, loss: 0.02579524740576744
step: 750, loss: 0.0681663453578949
step: 760, loss: 0.0004169426974840462
step: 770, loss: 0.02181849628686905
step: 780, loss: 0.019969111308455467
step: 790, loss: 0.039265695959329605
step: 800, loss: 0.05899300053715706
step: 810, loss: 0.00026840867940336466
step: 820, loss: 0.01697545312345028
step: 830, loss: 0.041970569640398026
step: 840, loss: 0.00034224800765514374
step: 850, loss: 0.0006840478163212538
step: 860, loss: 0.03328009694814682
step: 870, loss: 0.021755682304501534
step: 880, loss: 2.667480475793127e-05
step: 890, loss: 0.04927664250135422
step: 900, loss: 0.022206097841262817
step: 910, loss: 0.0036560853477567434
step: 920, loss: 0.07396883517503738
step: 930, loss: 4.3807431211462244e-05
step: 940, loss: 0.06663390249013901
step: 950, loss: 0.07564815878868103
step: 960, loss: 0.004798992536962032
step: 970, loss: 0.013830936513841152
step: 980, loss: 0.023385556414723396
step: 990, loss: 0.02204652689397335
step: 1000, loss: 0.04368172958493233
step: 1010, loss: 0.03762101009488106
step: 1020, loss: 0.0213471706956625
step: 1030, loss: 0.022315725684165955
step: 1040, loss: 2.2439362510340288e-05
step: 1050, loss: 0.0001261132856598124
step: 1060, loss: 0.020990490913391113
step: 1070, loss: 0.017812035977840424
epoch 19: dev_f1=0.9282385834109972, f1=0.9271461716937355, best_f1=0.937442502299908
step: 0, loss: 0.026964927092194557
step: 10, loss: 0.02731439098715782
step: 20, loss: 0.03806556761264801
step: 30, loss: 0.04785850644111633
step: 40, loss: 0.04964987561106682
step: 50, loss: 1.229323424922768e-05
step: 60, loss: 0.0030396422371268272
step: 70, loss: 0.012372203171253204
step: 80, loss: 0.0006546361837536097
step: 90, loss: 0.0034792646765708923
step: 100, loss: 7.250743510667235e-05
step: 110, loss: 0.022018464282155037
step: 120, loss: 0.04624296352267265
step: 130, loss: 0.026345986872911453
step: 140, loss: 0.00010503388330107555
step: 150, loss: 0.0014055984793230891
step: 160, loss: 0.025247694924473763
step: 170, loss: 1.8182439816882834e-05
step: 180, loss: 4.899676059721969e-05
step: 190, loss: 0.012333288788795471
step: 200, loss: 1.738914943416603e-05
step: 210, loss: 0.02665966935455799
step: 220, loss: 1.3678720279131085e-05
step: 230, loss: 3.890858715749346e-05
step: 240, loss: 0.0007389495731331408
step: 250, loss: 0.021231144666671753
step: 260, loss: 2.3390122805722058e-05
step: 270, loss: 0.02296130731701851
step: 280, loss: 0.00013469508849084377
step: 290, loss: 0.05325490981340408
step: 300, loss: 8.981610335467849e-06
step: 310, loss: 0.0735883116722107
step: 320, loss: 0.056866757571697235
step: 330, loss: 2.2152626115712337e-05
step: 340, loss: 0.03188353404402733
step: 350, loss: 0.0372147336602211
step: 360, loss: 0.022833585739135742
step: 370, loss: 0.04106416553258896
step: 380, loss: 0.001464769011363387
step: 390, loss: 9.73898422671482e-05
step: 400, loss: 3.4103290090570226e-05
step: 410, loss: 0.04394087940454483
step: 420, loss: 0.00472278194501996
step: 430, loss: 0.023695126175880432
step: 440, loss: 0.040690455585718155
step: 450, loss: 2.7597647203947417e-05
step: 460, loss: 0.024591566994786263
step: 470, loss: 0.014203016646206379
step: 480, loss: 0.00025935782468877733
step: 490, loss: 0.023344529792666435
step: 500, loss: 5.1346498366910964e-05
step: 510, loss: 0.08222785592079163
step: 520, loss: 0.017384683713316917
step: 530, loss: 0.018167881295084953
step: 540, loss: 0.03125985711812973
step: 550, loss: 0.007913884706795216
step: 560, loss: 4.373486081021838e-05
step: 570, loss: 0.01935533806681633
step: 580, loss: 0.01605278067290783
step: 590, loss: 0.04113556072115898
step: 600, loss: 0.04335582256317139
step: 610, loss: 4.249586345395073e-05
step: 620, loss: 0.01149399857968092
step: 630, loss: 0.021593190729618073
step: 640, loss: 4.79014815937262e-05
step: 650, loss: 0.018747905269265175
step: 660, loss: 0.04685638099908829
step: 670, loss: 0.037239912897348404
step: 680, loss: 5.6239645346067846e-05
step: 690, loss: 0.03130590170621872
step: 700, loss: 1.624938340683002e-05
step: 710, loss: 4.369988164398819e-05
step: 720, loss: 6.108674278948456e-05
step: 730, loss: 1.9463690478005446e-05
step: 740, loss: 0.0167226605117321
step: 750, loss: 3.7209541915217414e-05
step: 760, loss: 0.00027351867174729705
step: 770, loss: 0.01849008910357952
step: 780, loss: 8.097443060250953e-05
step: 790, loss: 2.225018761237152e-05
step: 800, loss: 0.02309243381023407
step: 810, loss: 0.01925320364534855
step: 820, loss: 0.00023361993953585625
step: 830, loss: 0.01359754428267479
step: 840, loss: 5.351625077310018e-05
step: 850, loss: 0.008123955689370632
step: 860, loss: 0.052442990243434906
step: 870, loss: 0.11557316035032272
step: 880, loss: 0.0007013498689047992
step: 890, loss: 0.04269159957766533
step: 900, loss: 0.0007572384201921523
step: 910, loss: 3.54236617567949e-05
step: 920, loss: 0.04019131883978844
step: 930, loss: 0.010485619306564331
step: 940, loss: 0.01399106066673994
step: 950, loss: 8.53829988045618e-06
step: 960, loss: 0.044947125017642975
step: 970, loss: 0.04907718673348427
step: 980, loss: 0.01702653430402279
step: 990, loss: 0.02561856433749199
step: 1000, loss: 2.0583695004461333e-05
step: 1010, loss: 4.752547829411924e-05
step: 1020, loss: 0.042850349098443985
step: 1030, loss: 0.043779224157333374
step: 1040, loss: 0.056562576442956924
step: 1050, loss: 0.09286926686763763
step: 1060, loss: 4.143100159126334e-05
step: 1070, loss: 0.0001732891978463158
epoch 20: dev_f1=0.9301675977653632, f1=0.92814093648586, best_f1=0.937442502299908
