cuda
Device: cuda
step: 0, loss: 0.6125706434249878
step: 10, loss: 0.4254116415977478
step: 20, loss: 0.44940614700317383
step: 30, loss: 0.36811015009880066
step: 40, loss: 0.3964802920818329
step: 50, loss: 0.16269272565841675
step: 60, loss: 0.37565988302230835
step: 70, loss: 0.13214851915836334
step: 80, loss: 0.22479112446308136
step: 90, loss: 0.14092116057872772
step: 100, loss: 0.3619426488876343
step: 110, loss: 0.26299023628234863
step: 120, loss: 0.35204556584358215
step: 130, loss: 0.18631255626678467
step: 140, loss: 0.09711569547653198
step: 150, loss: 0.2326553910970688
step: 160, loss: 0.16204512119293213
step: 170, loss: 0.17494513094425201
step: 180, loss: 0.16009365022182465
step: 190, loss: 0.08606594800949097
step: 200, loss: 0.07242725044488907
step: 210, loss: 0.3273248076438904
step: 220, loss: 0.15769311785697937
step: 230, loss: 0.0628170445561409
step: 240, loss: 0.22843241691589355
step: 250, loss: 0.12960009276866913
step: 260, loss: 0.0642482340335846
step: 270, loss: 0.048461977392435074
step: 280, loss: 0.347858726978302
step: 290, loss: 0.15587714314460754
step: 300, loss: 0.18422773480415344
step: 310, loss: 0.22603943943977356
step: 320, loss: 0.08601074665784836
step: 330, loss: 0.15818177163600922
step: 340, loss: 0.05698279291391373
step: 350, loss: 0.09972464293241501
step: 360, loss: 0.49918073415756226
step: 370, loss: 0.10702943056821823
step: 380, loss: 0.09389029443264008
step: 390, loss: 0.28577056527137756
step: 400, loss: 0.17763665318489075
step: 410, loss: 0.1506074070930481
step: 420, loss: 0.045972853899002075
step: 430, loss: 0.24619650840759277
step: 440, loss: 0.045693907886743546
step: 450, loss: 0.0831039622426033
step: 460, loss: 0.0945851281285286
step: 470, loss: 0.05786345526576042
step: 480, loss: 0.0463782474398613
step: 490, loss: 0.10998870432376862
step: 500, loss: 0.14281019568443298
step: 510, loss: 0.10535311698913574
step: 520, loss: 0.17319145798683167
step: 530, loss: 0.0752950981259346
step: 540, loss: 0.05135311931371689
step: 550, loss: 0.05655898153781891
step: 560, loss: 0.2758677303791046
step: 570, loss: 0.2743668258190155
step: 580, loss: 0.03592154383659363
step: 590, loss: 0.0609714649617672
step: 600, loss: 0.06887117028236389
step: 610, loss: 0.15662704408168793
step: 620, loss: 0.04124385491013527
step: 630, loss: 0.018153134733438492
step: 640, loss: 0.12009849399328232
step: 650, loss: 0.06991683691740036
step: 660, loss: 0.07315997779369354
step: 670, loss: 0.06773468106985092
step: 680, loss: 0.07652756571769714
step: 690, loss: 0.2271258682012558
step: 700, loss: 0.15055538713932037
step: 710, loss: 0.15343058109283447
step: 720, loss: 0.07527443766593933
step: 730, loss: 0.03687877953052521
step: 740, loss: 0.021308263763785362
step: 750, loss: 0.14605197310447693
step: 760, loss: 0.19892291724681854
step: 770, loss: 0.11046300083398819
step: 780, loss: 0.060216985642910004
step: 790, loss: 0.03948843479156494
step: 800, loss: 0.15830321609973907
step: 810, loss: 0.07838962972164154
step: 820, loss: 0.047214142978191376
step: 830, loss: 0.12525472044944763
step: 840, loss: 0.05394267290830612
step: 850, loss: 0.21260546147823334
step: 860, loss: 0.0667230561375618
step: 870, loss: 0.11874982714653015
step: 880, loss: 0.14916087687015533
step: 890, loss: 0.11375957727432251
step: 900, loss: 0.08048427104949951
step: 910, loss: 0.14533567428588867
step: 920, loss: 0.1083562970161438
step: 930, loss: 0.06469336152076721
step: 940, loss: 0.06485011428594589
step: 950, loss: 0.07248043268918991
step: 960, loss: 0.05577808618545532
step: 970, loss: 0.08812130987644196
step: 980, loss: 0.08415203541517258
step: 990, loss: 0.25887757539749146
step: 1000, loss: 0.12982390820980072
step: 1010, loss: 0.061298660933971405
step: 1020, loss: 0.11348609626293182
step: 1030, loss: 0.11739806830883026
step: 1040, loss: 0.08442996442317963
step: 1050, loss: 0.02001972310245037
step: 1060, loss: 0.09982848912477493
step: 1070, loss: 0.12859971821308136
epoch 1: dev_f1=0.9251637043966324, f1=0.9242144177449169, best_f1=0.9242144177449169
step: 0, loss: 0.056479211896657944
step: 10, loss: 0.17272065579891205
step: 20, loss: 0.08899328857660294
step: 30, loss: 0.050144296139478683
step: 40, loss: 0.08221578598022461
step: 50, loss: 0.06144283711910248
step: 60, loss: 0.1604524850845337
step: 70, loss: 0.17391757667064667
step: 80, loss: 0.023375114426016808
step: 90, loss: 0.10444451123476028
step: 100, loss: 0.09604842215776443
step: 110, loss: 0.012900331057608128
step: 120, loss: 0.11759821325540543
step: 130, loss: 0.14013484120368958
step: 140, loss: 0.07320946455001831
step: 150, loss: 0.12814576923847198
step: 160, loss: 0.0532168373465538
step: 170, loss: 0.14425669610500336
step: 180, loss: 0.07932907342910767
step: 190, loss: 0.10548709332942963
step: 200, loss: 0.028813738375902176
step: 210, loss: 0.1287003606557846
step: 220, loss: 0.08543697744607925
step: 230, loss: 0.10945451259613037
step: 240, loss: 0.02592427097260952
step: 250, loss: 0.1164085865020752
step: 260, loss: 0.15461641550064087
step: 270, loss: 0.006874540355056524
step: 280, loss: 0.06479555368423462
step: 290, loss: 0.08109631389379501
step: 300, loss: 0.27458786964416504
step: 310, loss: 0.10026054084300995
step: 320, loss: 0.09972578287124634
step: 330, loss: 0.04761210083961487
step: 340, loss: 0.0978957936167717
step: 350, loss: 0.12578466534614563
step: 360, loss: 0.05449220538139343
step: 370, loss: 0.06399949640035629
step: 380, loss: 0.09588903933763504
step: 390, loss: 0.00020165802561677992
step: 400, loss: 0.1519751101732254
step: 410, loss: 0.05510858818888664
step: 420, loss: 0.07454836368560791
step: 430, loss: 0.10783685743808746
step: 440, loss: 0.032019272446632385
step: 450, loss: 0.018254077062010765
step: 460, loss: 0.03718465566635132
step: 470, loss: 0.09186702221632004
step: 480, loss: 0.23749032616615295
step: 490, loss: 0.07681101560592651
step: 500, loss: 0.033374667167663574
step: 510, loss: 0.15665222704410553
step: 520, loss: 0.2104853093624115
step: 530, loss: 0.04972633719444275
step: 540, loss: 0.1817040890455246
step: 550, loss: 0.07730787992477417
step: 560, loss: 0.03476494178175926
step: 570, loss: 0.039342161267995834
step: 580, loss: 0.07879187166690826
step: 590, loss: 0.07484336197376251
step: 600, loss: 0.193827286362648
step: 610, loss: 0.02759723737835884
step: 620, loss: 0.09648100286722183
step: 630, loss: 0.06356217712163925
step: 640, loss: 0.08239338546991348
step: 650, loss: 0.09758756309747696
step: 660, loss: 0.018673298880457878
step: 670, loss: 0.0741073489189148
step: 680, loss: 0.1308891624212265
step: 690, loss: 0.08012739568948746
step: 700, loss: 0.21090149879455566
step: 710, loss: 0.008970250375568867
step: 720, loss: 0.02328719198703766
step: 730, loss: 0.13808627426624298
step: 740, loss: 0.08198556303977966
step: 750, loss: 0.1079462394118309
step: 760, loss: 0.013946522027254105
step: 770, loss: 0.18239599466323853
step: 780, loss: 0.037165094166994095
step: 790, loss: 0.03755196928977966
step: 800, loss: 0.04187469556927681
step: 810, loss: 0.009206120856106281
step: 820, loss: 0.07393030822277069
step: 830, loss: 0.02452576532959938
step: 840, loss: 0.14855298399925232
step: 850, loss: 0.1909615695476532
step: 860, loss: 0.10204201191663742
step: 870, loss: 0.0619361437857151
step: 880, loss: 0.07398466765880585
step: 890, loss: 0.06957975029945374
step: 900, loss: 0.011925002560019493
step: 910, loss: 0.110023133456707
step: 920, loss: 0.056807778775691986
step: 930, loss: 0.0508844330906868
step: 940, loss: 0.1021353155374527
step: 950, loss: 0.023061435669660568
step: 960, loss: 0.2860947251319885
step: 970, loss: 0.02257106453180313
step: 980, loss: 0.14089049398899078
step: 990, loss: 0.1574619710445404
step: 1000, loss: 0.08766492456197739
step: 1010, loss: 0.26341187953948975
step: 1020, loss: 0.09186283499002457
step: 1030, loss: 0.06461545825004578
step: 1040, loss: 0.13451316952705383
step: 1050, loss: 0.03308962658047676
step: 1060, loss: 0.024479305371642113
step: 1070, loss: 0.05401522293686867
epoch 2: dev_f1=0.9380776340110906, f1=0.9378739070409572, best_f1=0.9378739070409572
step: 0, loss: 0.08494383096694946
step: 10, loss: 0.07635903358459473
step: 20, loss: 0.12187866121530533
step: 30, loss: 0.13461549580097198
step: 40, loss: 0.14390723407268524
step: 50, loss: 0.04970676451921463
step: 60, loss: 0.044283077120780945
step: 70, loss: 0.02038271725177765
step: 80, loss: 0.04219274967908859
step: 90, loss: 0.04869787022471428
step: 100, loss: 0.0801013931632042
step: 110, loss: 0.03599144518375397
step: 120, loss: 0.16698910295963287
step: 130, loss: 0.04306967183947563
step: 140, loss: 0.02156611904501915
step: 150, loss: 0.013220971450209618
step: 160, loss: 0.09962406754493713
step: 170, loss: 0.18719063699245453
step: 180, loss: 0.06087081879377365
step: 190, loss: 0.07605664432048798
step: 200, loss: 0.18484555184841156
step: 210, loss: 0.06928487122058868
step: 220, loss: 0.10220864415168762
step: 230, loss: 0.10751089453697205
step: 240, loss: 0.0283990316092968
step: 250, loss: 0.12230847775936127
step: 260, loss: 0.11416929215192795
step: 270, loss: 0.0643225684762001
step: 280, loss: 0.031837042421102524
step: 290, loss: 0.10456474870443344
step: 300, loss: 0.03304564952850342
step: 310, loss: 0.07448714971542358
step: 320, loss: 0.04419327154755592
step: 330, loss: 0.2110498696565628
step: 340, loss: 0.3202180862426758
step: 350, loss: 0.08966711908578873
step: 360, loss: 0.027855174615979195
step: 370, loss: 0.0402987115085125
step: 380, loss: 0.027605073526501656
step: 390, loss: 0.33693453669548035
step: 400, loss: 0.13756321370601654
step: 410, loss: 0.011494279839098454
step: 420, loss: 0.04192911833524704
step: 430, loss: 0.11600346863269806
step: 440, loss: 0.015596375800669193
step: 450, loss: 0.0560942217707634
step: 460, loss: 0.01646570861339569
step: 470, loss: 0.17521943151950836
step: 480, loss: 0.11719202995300293
step: 490, loss: 0.07690345495939255
step: 500, loss: 0.01619514636695385
step: 510, loss: 0.04365381971001625
step: 520, loss: 0.0923100933432579
step: 530, loss: 0.06667730957269669
step: 540, loss: 0.09798197448253632
step: 550, loss: 0.19591781497001648
step: 560, loss: 0.08299365639686584
step: 570, loss: 0.0336165577173233
step: 580, loss: 0.06101788952946663
step: 590, loss: 0.026977170258760452
step: 600, loss: 0.05388534069061279
step: 610, loss: 0.060189783573150635
step: 620, loss: 0.18976691365242004
step: 630, loss: 0.07766549289226532
step: 640, loss: 0.10919945687055588
step: 650, loss: 0.039485689252614975
step: 660, loss: 0.014973286539316177
step: 670, loss: 0.06892847269773483
step: 680, loss: 0.022845018655061722
step: 690, loss: 0.09845497459173203
step: 700, loss: 0.10480722039937973
step: 710, loss: 0.08540312200784683
step: 720, loss: 0.10814706981182098
step: 730, loss: 0.0041913739405572414
step: 740, loss: 0.11293960362672806
step: 750, loss: 0.09624544531106949
step: 760, loss: 0.07530508190393448
step: 770, loss: 0.0065710460767149925
step: 780, loss: 0.050183963030576706
step: 790, loss: 0.13080689311027527
step: 800, loss: 0.04426591098308563
step: 810, loss: 0.07501643151044846
step: 820, loss: 0.025983119383454323
step: 830, loss: 0.020853452384471893
step: 840, loss: 0.04752637445926666
step: 850, loss: 0.04565897211432457
step: 860, loss: 0.026733627542853355
step: 870, loss: 0.04304732754826546
step: 880, loss: 0.032189950346946716
step: 890, loss: 0.07142669707536697
step: 900, loss: 0.036894869059324265
step: 910, loss: 0.06123097613453865
step: 920, loss: 0.014256613329052925
step: 930, loss: 0.16683858633041382
step: 940, loss: 0.1790570616722107
step: 950, loss: 0.0634998306632042
step: 960, loss: 0.07148087024688721
step: 970, loss: 0.014516286551952362
step: 980, loss: 0.07087060064077377
step: 990, loss: 0.13051852583885193
step: 1000, loss: 0.120844766497612
step: 1010, loss: 0.05571102723479271
step: 1020, loss: 0.05474120005965233
step: 1030, loss: 0.06033335253596306
step: 1040, loss: 0.10864617675542831
step: 1050, loss: 0.02287471853196621
step: 1060, loss: 0.06645176559686661
step: 1070, loss: 0.01457003504037857
epoch 3: dev_f1=0.94200187090739, f1=0.9319568277803848, best_f1=0.9319568277803848
step: 0, loss: 0.11261286586523056
step: 10, loss: 0.09212468564510345
step: 20, loss: 0.027182115241885185
step: 30, loss: 0.08158032596111298
step: 40, loss: 0.08357512205839157
step: 50, loss: 0.10785271972417831
step: 60, loss: 0.07090461254119873
step: 70, loss: 0.02540828287601471
step: 80, loss: 0.059321969747543335
step: 90, loss: 0.011095704510807991
step: 100, loss: 0.12675677239894867
step: 110, loss: 0.07108444720506668
step: 120, loss: 0.16590070724487305
step: 130, loss: 0.031429171562194824
step: 140, loss: 0.06835229694843292
step: 150, loss: 0.019981876015663147
step: 160, loss: 0.03823041915893555
step: 170, loss: 0.08711280673742294
step: 180, loss: 0.14449216425418854
step: 190, loss: 0.19397585093975067
step: 200, loss: 0.11545456200838089
step: 210, loss: 0.00010698210826376453
step: 220, loss: 0.09498634934425354
step: 230, loss: 0.04165469855070114
step: 240, loss: 0.048684414476156235
step: 250, loss: 0.023554028943181038
step: 260, loss: 0.10230696201324463
step: 270, loss: 0.09650567173957825
step: 280, loss: 0.04844672977924347
step: 290, loss: 0.06828238070011139
step: 300, loss: 0.03132252022624016
step: 310, loss: 0.09872613102197647
step: 320, loss: 0.0788729190826416
step: 330, loss: 0.03536461293697357
step: 340, loss: 0.011668682098388672
step: 350, loss: 0.03125661611557007
step: 360, loss: 0.04113589972257614
step: 370, loss: 0.02822270803153515
step: 380, loss: 0.006792701780796051
step: 390, loss: 0.01111220009624958
step: 400, loss: 0.1123005747795105
step: 410, loss: 0.014349064789712429
step: 420, loss: 0.025721896439790726
step: 430, loss: 0.0489133857190609
step: 440, loss: 0.08970632404088974
step: 450, loss: 0.025601321831345558
step: 460, loss: 0.04441088065505028
step: 470, loss: 0.0616716630756855
step: 480, loss: 0.11814649403095245
step: 490, loss: 0.12067572772502899
step: 500, loss: 0.03971068933606148
step: 510, loss: 0.12290265411138535
step: 520, loss: 0.06937282532453537
step: 530, loss: 0.09165802597999573
step: 540, loss: 0.03955434262752533
step: 550, loss: 0.0949426144361496
step: 560, loss: 0.15605154633522034
step: 570, loss: 0.037358980625867844
step: 580, loss: 0.049356672912836075
step: 590, loss: 0.08855992555618286
step: 600, loss: 0.027325952425599098
step: 610, loss: 0.07646124064922333
step: 620, loss: 0.02963148057460785
step: 630, loss: 0.013855229131877422
step: 640, loss: 0.10374486446380615
step: 650, loss: 0.1130598932504654
step: 660, loss: 0.048576876521110535
step: 670, loss: 0.00972399115562439
step: 680, loss: 0.3088400661945343
step: 690, loss: 0.01230726670473814
step: 700, loss: 0.09388238191604614
step: 710, loss: 0.1123620867729187
step: 720, loss: 0.08829234540462494
step: 730, loss: 0.17443691194057465
step: 740, loss: 0.020310265943408012
step: 750, loss: 0.22802619636058807
step: 760, loss: 0.0671612024307251
step: 770, loss: 0.04419440031051636
step: 780, loss: 0.09590012580156326
step: 790, loss: 0.023165522143244743
step: 800, loss: 0.12683916091918945
step: 810, loss: 0.1111915111541748
step: 820, loss: 0.074703648686409
step: 830, loss: 0.012838917784392834
step: 840, loss: 0.032682716846466064
step: 850, loss: 0.03684784844517708
step: 860, loss: 0.02665809355676174
step: 870, loss: 0.12043814361095428
step: 880, loss: 0.106410913169384
step: 890, loss: 0.06281376630067825
step: 900, loss: 0.10888079553842545
step: 910, loss: 0.22751553356647491
step: 920, loss: 0.07541628181934357
step: 930, loss: 0.07492905855178833
step: 940, loss: 0.09735158830881119
step: 950, loss: 0.042387768626213074
step: 960, loss: 0.020129650831222534
step: 970, loss: 0.057657912373542786
step: 980, loss: 0.08717525750398636
step: 990, loss: 0.02236201986670494
step: 1000, loss: 0.02878345549106598
step: 1010, loss: 0.07154514640569687
step: 1020, loss: 0.09818536788225174
step: 1030, loss: 0.07449919730424881
step: 1040, loss: 0.028562886640429497
step: 1050, loss: 0.10768093168735504
step: 1060, loss: 0.07347618788480759
step: 1070, loss: 0.14207307994365692
epoch 4: dev_f1=0.9346642468239564, f1=0.9309718437783834, best_f1=0.9319568277803848
step: 0, loss: 0.04546036943793297
step: 10, loss: 0.055282723158597946
step: 20, loss: 0.12123437225818634
step: 30, loss: 0.014589492231607437
step: 40, loss: 0.011686369776725769
step: 50, loss: 0.012032351456582546
step: 60, loss: 0.0710168182849884
step: 70, loss: 0.058771632611751556
step: 80, loss: 0.009902702644467354
step: 90, loss: 0.18011832237243652
step: 100, loss: 0.01652374118566513
step: 110, loss: 0.03728736564517021
step: 120, loss: 0.15345382690429688
step: 130, loss: 0.005884814541786909
step: 140, loss: 0.08530013263225555
step: 150, loss: 0.013575364835560322
step: 160, loss: 0.060221727937459946
step: 170, loss: 0.2271255999803543
step: 180, loss: 0.03661687299609184
step: 190, loss: 0.0036463153082877398
step: 200, loss: 0.013120574876666069
step: 210, loss: 0.03623207286000252
step: 220, loss: 0.08089961856603622
step: 230, loss: 0.13413673639297485
step: 240, loss: 0.08543186634778976
step: 250, loss: 0.12213961780071259
step: 260, loss: 0.06613470613956451
step: 270, loss: 0.006800835952162743
step: 280, loss: 0.05674439296126366
step: 290, loss: 0.043443746864795685
step: 300, loss: 0.05327868461608887
step: 310, loss: 0.08794763684272766
step: 320, loss: 0.08131729066371918
step: 330, loss: 0.05610838532447815
step: 340, loss: 0.06173606589436531
step: 350, loss: 0.08319102972745895
step: 360, loss: 0.11556518077850342
step: 370, loss: 0.08187183737754822
step: 380, loss: 0.09823637455701828
step: 390, loss: 0.0588809996843338
step: 400, loss: 0.04802658036351204
step: 410, loss: 0.06435617059469223
step: 420, loss: 0.06745678186416626
step: 430, loss: 0.023315858095884323
step: 440, loss: 0.11121338605880737
step: 450, loss: 0.00013807728828396648
step: 460, loss: 0.03666305169463158
step: 470, loss: 0.20772254467010498
step: 480, loss: 0.017685426399111748
step: 490, loss: 0.10016129910945892
step: 500, loss: 0.02203286439180374
step: 510, loss: 0.03682803362607956
step: 520, loss: 0.15223321318626404
step: 530, loss: 0.032688699662685394
step: 540, loss: 0.022228986024856567
step: 550, loss: 0.09175989031791687
step: 560, loss: 0.17138539254665375
step: 570, loss: 0.08325690031051636
step: 580, loss: 0.032229743897914886
step: 590, loss: 0.019041797146201134
step: 600, loss: 0.11614087969064713
step: 610, loss: 0.07821048051118851
step: 620, loss: 0.0898185670375824
step: 630, loss: 0.0467173233628273
step: 640, loss: 0.025926658883690834
step: 650, loss: 0.020784344524145126
step: 660, loss: 0.011621983721852303
step: 670, loss: 0.08924616128206253
step: 680, loss: 0.018924342468380928
step: 690, loss: 0.09676696360111237
step: 700, loss: 0.01516928430646658
step: 710, loss: 0.0045430101454257965
step: 720, loss: 0.09471457451581955
step: 730, loss: 0.1337173581123352
step: 740, loss: 0.03160807862877846
step: 750, loss: 0.03836643695831299
step: 760, loss: 0.12310095131397247
step: 770, loss: 0.17152860760688782
step: 780, loss: 0.10522673279047012
step: 790, loss: 0.010462398640811443
step: 800, loss: 0.015356545336544514
step: 810, loss: 0.061689894646406174
step: 820, loss: 0.06094447895884514
step: 830, loss: 0.07886318862438202
step: 840, loss: 0.02615409716963768
step: 850, loss: 0.07598390430212021
step: 860, loss: 0.15879952907562256
step: 870, loss: 0.10958070307970047
step: 880, loss: 0.08959819376468658
step: 890, loss: 0.09982970356941223
step: 900, loss: 0.023156028240919113
step: 910, loss: 0.05550093948841095
step: 920, loss: 0.17361773550510406
step: 930, loss: 0.1599711775779724
step: 940, loss: 0.04312344267964363
step: 950, loss: 0.021316347643733025
step: 960, loss: 0.09514453262090683
step: 970, loss: 0.041916124522686005
step: 980, loss: 0.036480069160461426
step: 990, loss: 0.016211478039622307
step: 1000, loss: 0.048048235476017
step: 1010, loss: 0.0834324061870575
step: 1020, loss: 0.05612620711326599
step: 1030, loss: 0.06105915457010269
step: 1040, loss: 0.11299458891153336
step: 1050, loss: 0.03312830626964569
step: 1060, loss: 0.021792562678456306
step: 1070, loss: 0.06386010348796844
epoch 5: dev_f1=0.9428571428571428, f1=0.9324699352451433, best_f1=0.9324699352451433
step: 0, loss: 0.00020833649614360183
step: 10, loss: 0.04043387994170189
step: 20, loss: 0.028984442353248596
step: 30, loss: 0.09395375847816467
step: 40, loss: 0.015384810045361519
step: 50, loss: 0.19649197161197662
step: 60, loss: 0.25877684354782104
step: 70, loss: 0.0780707448720932
step: 80, loss: 0.14333012700080872
step: 90, loss: 0.06457207351922989
step: 100, loss: 0.055649567395448685
step: 110, loss: 0.028149738907814026
step: 120, loss: 0.011444478295743465
step: 130, loss: 0.010225568898022175
step: 140, loss: 0.005375605076551437
step: 150, loss: 0.0617816261947155
step: 160, loss: 0.09781552851200104
step: 170, loss: 0.16006390750408173
step: 180, loss: 0.0313381627202034
step: 190, loss: 0.0549243688583374
step: 200, loss: 0.08928249776363373
step: 210, loss: 0.07558271288871765
step: 220, loss: 0.021616172045469284
step: 230, loss: 0.05282771959900856
step: 240, loss: 0.04296175763010979
step: 250, loss: 0.007770051248371601
step: 260, loss: 0.023432962596416473
step: 270, loss: 0.0907624363899231
step: 280, loss: 0.06909651309251785
step: 290, loss: 0.04627251997590065
step: 300, loss: 0.007359783630818129
step: 310, loss: 0.07859880477190018
step: 320, loss: 0.045579589903354645
step: 330, loss: 0.09665121138095856
step: 340, loss: 0.010715470649302006
step: 350, loss: 0.13042840361595154
step: 360, loss: 0.017180990427732468
step: 370, loss: 0.041550230234861374
step: 380, loss: 0.023803137242794037
step: 390, loss: 0.01602942869067192
step: 400, loss: 0.023251213133335114
step: 410, loss: 0.05925294756889343
step: 420, loss: 0.1739809811115265
step: 430, loss: 0.14244189858436584
step: 440, loss: 0.05132752284407616
step: 450, loss: 0.034687310457229614
step: 460, loss: 0.11478182673454285
step: 470, loss: 0.024813340976834297
step: 480, loss: 0.1066679134964943
step: 490, loss: 0.08722098916769028
step: 500, loss: 0.18776768445968628
step: 510, loss: 0.05097818002104759
step: 520, loss: 0.07286843657493591
step: 530, loss: 0.0023683542385697365
step: 540, loss: 0.039354898035526276
step: 550, loss: 0.01344851590692997
step: 560, loss: 0.1244293749332428
step: 570, loss: 0.017276909202337265
step: 580, loss: 0.04445314407348633
step: 590, loss: 0.05036617070436478
step: 600, loss: 0.04627755284309387
step: 610, loss: 0.0553242526948452
step: 620, loss: 0.13464835286140442
step: 630, loss: 0.07309292256832123
step: 640, loss: 0.011072900146245956
step: 650, loss: 0.11609388887882233
step: 660, loss: 0.0986005961894989
step: 670, loss: 0.0086235161870718
step: 680, loss: 0.11176476627588272
step: 690, loss: 0.018075130879878998
step: 700, loss: 0.06117266044020653
step: 710, loss: 0.06054915115237236
step: 720, loss: 0.002599275205284357
step: 730, loss: 0.10494893789291382
step: 740, loss: 0.06948765367269516
step: 750, loss: 0.007346523925662041
step: 760, loss: 0.018249671906232834
step: 770, loss: 0.04919508472084999
step: 780, loss: 0.06424356997013092
step: 790, loss: 0.10797883570194244
step: 800, loss: 0.016832349821925163
step: 810, loss: 0.03049081191420555
step: 820, loss: 0.06735239923000336
step: 830, loss: 0.027692101895809174
step: 840, loss: 0.012079242616891861
step: 850, loss: 0.07542154937982559
step: 860, loss: 0.08189290761947632
step: 870, loss: 0.006865235045552254
step: 880, loss: 0.12094362825155258
step: 890, loss: 0.06034618988633156
step: 900, loss: 0.01966535672545433
step: 910, loss: 0.08942487090826035
step: 920, loss: 0.1517680138349533
step: 930, loss: 0.06590575724840164
step: 940, loss: 0.025961754843592644
step: 950, loss: 0.06717325747013092
step: 960, loss: 0.06376403570175171
step: 970, loss: 0.13140633702278137
step: 980, loss: 0.07944325357675552
step: 990, loss: 0.015980450436472893
step: 1000, loss: 0.062374282628297806
step: 1010, loss: 0.10154230147600174
step: 1020, loss: 0.027453390881419182
step: 1030, loss: 0.011952041648328304
step: 1040, loss: 0.083265021443367
step: 1050, loss: 0.126447856426239
step: 1060, loss: 0.004025043919682503
step: 1070, loss: 0.044082362204790115
epoch 6: dev_f1=0.9406896551724139, f1=0.9362092703074805, best_f1=0.9324699352451433
step: 0, loss: 0.008732282556593418
step: 10, loss: 0.06629692763090134
step: 20, loss: 0.05491212010383606
step: 30, loss: 0.06332245469093323
step: 40, loss: 0.014314282685518265
step: 50, loss: 0.03134460747241974
step: 60, loss: 0.08420711010694504
step: 70, loss: 0.010426691733300686
step: 80, loss: 0.0526377409696579
step: 90, loss: 0.061033811420202255
step: 100, loss: 0.015539612621068954
step: 110, loss: 0.15620501339435577
step: 120, loss: 0.016610033810138702
step: 130, loss: 0.06046618893742561
step: 140, loss: 0.015747016295790672
step: 150, loss: 0.04746664687991142
step: 160, loss: 0.07767979800701141
step: 170, loss: 0.08673718571662903
step: 180, loss: 0.07485363632440567
step: 190, loss: 0.05453405901789665
step: 200, loss: 0.02845827490091324
step: 210, loss: 0.02567695640027523
step: 220, loss: 0.011289461515843868
step: 230, loss: 0.04231298714876175
step: 240, loss: 0.0293855220079422
step: 250, loss: 0.028424307703971863
step: 260, loss: 0.09939277917146683
step: 270, loss: 0.09904345124959946
step: 280, loss: 0.30903831124305725
step: 290, loss: 0.05807851254940033
step: 300, loss: 0.029963605105876923
step: 310, loss: 0.07713305950164795
step: 320, loss: 0.033210936933755875
step: 330, loss: 0.07405491173267365
step: 340, loss: 0.12644876539707184
step: 350, loss: 0.015940513461828232
step: 360, loss: 0.024933934211730957
step: 370, loss: 0.011927585117518902
step: 380, loss: 0.04543403536081314
step: 390, loss: 0.08383587747812271
step: 400, loss: 0.03835326060652733
step: 410, loss: 0.004003001842647791
step: 420, loss: 0.004298665095120668
step: 430, loss: 0.0929981917142868
step: 440, loss: 0.007029906380921602
step: 450, loss: 0.18139399588108063
step: 460, loss: 0.029863378033041954
step: 470, loss: 0.07389897853136063
step: 480, loss: 0.011742588132619858
step: 490, loss: 0.007113233208656311
step: 500, loss: 0.00725702615454793
step: 510, loss: 0.02423097938299179
step: 520, loss: 0.053669705986976624
step: 530, loss: 0.046102192252874374
step: 540, loss: 0.03764908015727997
step: 550, loss: 0.07970187067985535
step: 560, loss: 0.022065555676817894
step: 570, loss: 0.02681572176516056
step: 580, loss: 0.16423626244068146
step: 590, loss: 0.22554327547550201
step: 600, loss: 0.06911931931972504
step: 610, loss: 0.07012933492660522
step: 620, loss: 0.022274857386946678
step: 630, loss: 0.1148439273238182
step: 640, loss: 0.044628892093896866
step: 650, loss: 0.004266868811100721
step: 660, loss: 0.007294788025319576
step: 670, loss: 0.07909379154443741
step: 680, loss: 0.042288631200790405
step: 690, loss: 0.036766838282346725
step: 700, loss: 0.022919392213225365
step: 710, loss: 0.04036334902048111
step: 720, loss: 0.03982171043753624
step: 730, loss: 0.01587759703397751
step: 740, loss: 0.10734212398529053
step: 750, loss: 0.004756588023155928
step: 760, loss: 0.10424588620662689
step: 770, loss: 0.025182554498314857
step: 780, loss: 0.01443973183631897
step: 790, loss: 0.0654282197356224
step: 800, loss: 0.09832122921943665
step: 810, loss: 0.08626552671194077
step: 820, loss: 0.10790887475013733
step: 830, loss: 0.13601268827915192
step: 840, loss: 0.06842201203107834
step: 850, loss: 0.08049514144659042
step: 860, loss: 0.037408072501420975
step: 870, loss: 0.03308609500527382
step: 880, loss: 0.11588574945926666
step: 890, loss: 0.1041073203086853
step: 900, loss: 0.004062539432197809
step: 910, loss: 0.021232228726148605
step: 920, loss: 0.08147650957107544
step: 930, loss: 0.00890106987208128
step: 940, loss: 0.08152785152196884
step: 950, loss: 0.0947934165596962
step: 960, loss: 0.013163402676582336
step: 970, loss: 0.09184426069259644
step: 980, loss: 0.06748513132333755
step: 990, loss: 0.03659561276435852
step: 1000, loss: 0.0007520397775806487
step: 1010, loss: 0.0021967836655676365
step: 1020, loss: 0.14994637668132782
step: 1030, loss: 0.17251119017601013
step: 1040, loss: 0.016419708728790283
step: 1050, loss: 0.00958116166293621
step: 1060, loss: 0.03636352717876434
step: 1070, loss: 0.06846597790718079
epoch 7: dev_f1=0.9417163836622304, f1=0.9362092703074805, best_f1=0.9324699352451433
step: 0, loss: 0.0719691812992096
step: 10, loss: 0.04484585300087929
step: 20, loss: 0.09368135780096054
step: 30, loss: 0.09889417886734009
step: 40, loss: 0.037579093128442764
step: 50, loss: 0.06595343351364136
step: 60, loss: 0.0072260634042322636
step: 70, loss: 0.03442888334393501
step: 80, loss: 0.03368719667196274
step: 90, loss: 0.016992608085274696
step: 100, loss: 0.006304425187408924
step: 110, loss: 0.040327075868844986
step: 120, loss: 0.012312248349189758
step: 130, loss: 0.011218861676752567
step: 140, loss: 0.028714191168546677
step: 150, loss: 0.0685858279466629
step: 160, loss: 0.00803188793361187
step: 170, loss: 0.06144948676228523
step: 180, loss: 0.039203763008117676
step: 190, loss: 0.0248477291315794
step: 200, loss: 0.019424274563789368
step: 210, loss: 0.10535627603530884
step: 220, loss: 0.036906152963638306
step: 230, loss: 0.04222652688622475
step: 240, loss: 0.060404784977436066
step: 250, loss: 0.13216426968574524
step: 260, loss: 0.0481533408164978
step: 270, loss: 0.04988802596926689
step: 280, loss: 0.08535054326057434
step: 290, loss: 0.09610973298549652
step: 300, loss: 0.06313863396644592
step: 310, loss: 0.00015308053116314113
step: 320, loss: 0.049519386142492294
step: 330, loss: 0.10100297629833221
step: 340, loss: 0.016121478751301765
step: 350, loss: 0.009905101731419563
step: 360, loss: 0.03723237290978432
step: 370, loss: 0.03366074711084366
step: 380, loss: 0.05018339306116104
step: 390, loss: 0.0680588111281395
step: 400, loss: 0.0035066900309175253
step: 410, loss: 0.19242997467517853
step: 420, loss: 0.07370919734239578
step: 430, loss: 0.03522271662950516
step: 440, loss: 0.03312017768621445
step: 450, loss: 8.58413040987216e-05
step: 460, loss: 0.1087670847773552
step: 470, loss: 0.0054505630396306515
step: 480, loss: 0.06327208131551743
step: 490, loss: 0.020016765221953392
step: 500, loss: 0.10581691563129425
step: 510, loss: 0.024733761325478554
step: 520, loss: 0.02664048969745636
step: 530, loss: 0.0715361014008522
step: 540, loss: 0.018630443140864372
step: 550, loss: 0.04456318914890289
step: 560, loss: 0.0679355338215828
step: 570, loss: 0.013271134346723557
step: 580, loss: 0.023814646527171135
step: 590, loss: 0.02327488362789154
step: 600, loss: 0.018675561994314194
step: 610, loss: 7.219726103357971e-05
step: 620, loss: 0.044170718640089035
step: 630, loss: 0.00674166064709425
step: 640, loss: 0.12967897951602936
step: 650, loss: 0.015162324532866478
step: 660, loss: 0.006255045533180237
step: 670, loss: 0.044368308037519455
step: 680, loss: 0.055046308785676956
step: 690, loss: 0.07659250497817993
step: 700, loss: 0.033774688839912415
step: 710, loss: 0.06698502600193024
step: 720, loss: 0.06090659648180008
step: 730, loss: 0.04396657645702362
step: 740, loss: 0.04365725815296173
step: 750, loss: 0.021413128823041916
step: 760, loss: 0.048168767243623734
step: 770, loss: 0.0776347815990448
step: 780, loss: 0.05140858143568039
step: 790, loss: 0.02161906659603119
step: 800, loss: 0.01317320205271244
step: 810, loss: 0.03809543326497078
step: 820, loss: 0.07186562567949295
step: 830, loss: 0.09880470484495163
step: 840, loss: 0.021614380180835724
step: 850, loss: 0.011115781962871552
step: 860, loss: 0.016250038519501686
step: 870, loss: 0.029155287891626358
step: 880, loss: 0.018212493509054184
step: 890, loss: 0.06478482484817505
step: 900, loss: 0.03098948858678341
step: 910, loss: 0.02180715650320053
step: 920, loss: 0.02418767847120762
step: 930, loss: 0.08298999071121216
step: 940, loss: 0.10147365182638168
step: 950, loss: 0.05810347944498062
step: 960, loss: 0.04431309178471565
step: 970, loss: 0.010284929536283016
step: 980, loss: 0.025612572208046913
step: 990, loss: 0.01645027846097946
step: 1000, loss: 0.02174336463212967
step: 1010, loss: 0.06771953403949738
step: 1020, loss: 0.034527089446783066
step: 1030, loss: 0.11894058436155319
step: 1040, loss: 0.012099787592887878
step: 1050, loss: 0.025785129517316818
step: 1060, loss: 0.049365848302841187
step: 1070, loss: 0.03925902768969536
epoch 8: dev_f1=0.9384965831435079, f1=0.9314442413162706, best_f1=0.9324699352451433
step: 0, loss: 0.041349854320287704
step: 10, loss: 0.0011947561288252473
step: 20, loss: 0.03394447639584541
step: 30, loss: 0.021889440715312958
step: 40, loss: 0.055212799459695816
step: 50, loss: 0.03810372203588486
step: 60, loss: 0.01664155349135399
step: 70, loss: 0.008711631409823895
step: 80, loss: 0.038089387118816376
step: 90, loss: 0.06010902300477028
step: 100, loss: 0.020637458190321922
step: 110, loss: 0.04892824962735176
step: 120, loss: 0.08215723186731339
step: 130, loss: 0.005268378648906946
step: 140, loss: 0.07607723027467728
step: 150, loss: 0.07144741714000702
step: 160, loss: 0.05019067972898483
step: 170, loss: 0.021837959066033363
step: 180, loss: 0.015915416181087494
step: 190, loss: 0.06503137201070786
step: 200, loss: 0.004259355366230011
step: 210, loss: 0.005658931098878384
step: 220, loss: 0.03808998689055443
step: 230, loss: 0.00963624194264412
step: 240, loss: 0.1356189250946045
step: 250, loss: 0.11840010434389114
step: 260, loss: 0.048205409198999405
step: 270, loss: 0.021060720086097717
step: 280, loss: 0.06391669064760208
step: 290, loss: 0.038771387189626694
step: 300, loss: 0.047523871064186096
step: 310, loss: 0.03257303684949875
step: 320, loss: 0.12830547988414764
step: 330, loss: 0.04194687679409981
step: 340, loss: 6.59002544125542e-05
step: 350, loss: 0.011634979397058487
step: 360, loss: 0.007332054898142815
step: 370, loss: 0.07086168229579926
step: 380, loss: 0.1320449709892273
step: 390, loss: 0.02808564528822899
step: 400, loss: 0.0014126576716080308
step: 410, loss: 0.02976948395371437
step: 420, loss: 0.015347585082054138
step: 430, loss: 0.008158671669661999
step: 440, loss: 0.05868849158287048
step: 450, loss: 0.02791210450232029
step: 460, loss: 0.1049887016415596
step: 470, loss: 0.02516743540763855
step: 480, loss: 0.06292343139648438
step: 490, loss: 0.03320147097110748
step: 500, loss: 0.04757346585392952
step: 510, loss: 0.21443983912467957
step: 520, loss: 0.08620565384626389
step: 530, loss: 0.012330975383520126
step: 540, loss: 0.008166532963514328
step: 550, loss: 0.023615362122654915
step: 560, loss: 0.009596706368029118
step: 570, loss: 0.07985333353281021
step: 580, loss: 0.03928292915225029
step: 590, loss: 0.1243857815861702
step: 600, loss: 0.06569473445415497
step: 610, loss: 0.044991385191679
step: 620, loss: 0.056657131761312485
step: 630, loss: 0.09909860044717789
step: 640, loss: 0.028416601940989494
step: 650, loss: 0.032664842903614044
step: 660, loss: 0.04015706852078438
step: 670, loss: 0.10778059810400009
step: 680, loss: 0.026312626898288727
step: 690, loss: 0.019279763102531433
step: 700, loss: 0.07844378054141998
step: 710, loss: 0.06695166975259781
step: 720, loss: 0.08548210561275482
step: 730, loss: 0.04519600048661232
step: 740, loss: 0.126237154006958
step: 750, loss: 0.005858381744474173
step: 760, loss: 0.016685957089066505
step: 770, loss: 0.07252592593431473
step: 780, loss: 0.038138389587402344
step: 790, loss: 0.007772180717438459
step: 800, loss: 0.007697803899645805
step: 810, loss: 0.090767040848732
step: 820, loss: 0.1048731580376625
step: 830, loss: 0.05120253935456276
step: 840, loss: 0.03407928720116615
step: 850, loss: 0.08687609434127808
step: 860, loss: 0.0726790577173233
step: 870, loss: 0.03705534711480141
step: 880, loss: 0.042923104017972946
step: 890, loss: 0.0039385342970490456
step: 900, loss: 0.018839256837964058
step: 910, loss: 0.023605169728398323
step: 920, loss: 0.010317273437976837
step: 930, loss: 0.04221838712692261
step: 940, loss: 0.03747369721531868
step: 950, loss: 0.045904744416475296
step: 960, loss: 0.08445605635643005
step: 970, loss: 0.057608362287282944
step: 980, loss: 0.08771693706512451
step: 990, loss: 0.15153047442436218
step: 1000, loss: 0.05745673179626465
step: 1010, loss: 0.09511247277259827
step: 1020, loss: 0.029646562412381172
step: 1030, loss: 0.06831160187721252
step: 1040, loss: 0.013424387201666832
step: 1050, loss: 0.023966185748577118
step: 1060, loss: 0.05504588037729263
step: 1070, loss: 0.05532410368323326
epoch 9: dev_f1=0.9413936317489617, f1=0.9280442804428044, best_f1=0.9324699352451433
step: 0, loss: 0.013684914447367191
step: 10, loss: 0.04702872782945633
step: 20, loss: 0.02134132944047451
step: 30, loss: 0.007348912768065929
step: 40, loss: 0.013484937138855457
step: 50, loss: 0.0795416533946991
step: 60, loss: 0.03948482498526573
step: 70, loss: 0.0070130061358213425
step: 80, loss: 0.029261361807584763
step: 90, loss: 0.012303429655730724
step: 100, loss: 0.06768746674060822
step: 110, loss: 0.06714625656604767
step: 120, loss: 0.031624600291252136
step: 130, loss: 0.05444362014532089
step: 140, loss: 0.04381103068590164
step: 150, loss: 0.0795147716999054
step: 160, loss: 0.042685240507125854
step: 170, loss: 0.011184976436197758
step: 180, loss: 0.020430924370884895
step: 190, loss: 0.006762977223843336
step: 200, loss: 0.09346546977758408
step: 210, loss: 0.017341740429401398
step: 220, loss: 0.04104204103350639
step: 230, loss: 0.2461322396993637
step: 240, loss: 0.06542258709669113
step: 250, loss: 0.08598928898572922
step: 260, loss: 0.04444349929690361
step: 270, loss: 0.002910017501562834
step: 280, loss: 0.05039193108677864
step: 290, loss: 7.69515972933732e-05
step: 300, loss: 0.006540268659591675
step: 310, loss: 5.273236456559971e-05
step: 320, loss: 0.025591852143406868
step: 330, loss: 0.008039615117013454
step: 340, loss: 0.0039432356134057045
step: 350, loss: 0.07264219224452972
step: 360, loss: 0.029712608084082603
step: 370, loss: 0.03467045724391937
step: 380, loss: 0.03482741117477417
step: 390, loss: 0.08999604731798172
step: 400, loss: 0.01770663633942604
step: 410, loss: 0.09409689903259277
step: 420, loss: 0.014470853842794895
step: 430, loss: 0.01465293113142252
step: 440, loss: 0.05244291573762894
step: 450, loss: 0.048800572752952576
step: 460, loss: 0.09355558454990387
step: 470, loss: 0.001501110615208745
step: 480, loss: 0.04117453470826149
step: 490, loss: 0.04020283371210098
step: 500, loss: 0.04875583201646805
step: 510, loss: 0.024113601073622704
step: 520, loss: 0.043547388166189194
step: 530, loss: 0.07391631603240967
step: 540, loss: 0.12269403040409088
step: 550, loss: 0.07234849780797958
step: 560, loss: 0.038793209940195084
step: 570, loss: 0.0858006700873375
step: 580, loss: 0.026361357420682907
step: 590, loss: 0.00655726995319128
step: 600, loss: 0.09157940000295639
step: 610, loss: 0.028523240238428116
step: 620, loss: 0.020443694666028023
step: 630, loss: 0.012052862904965878
step: 640, loss: 0.011497060768306255
step: 650, loss: 0.057482726871967316
step: 660, loss: 0.02603231742978096
step: 670, loss: 0.014563679695129395
step: 680, loss: 0.025876520201563835
step: 690, loss: 0.09488344192504883
step: 700, loss: 0.01898297667503357
step: 710, loss: 0.01899353228509426
step: 720, loss: 0.03578680008649826
step: 730, loss: 0.10430037975311279
step: 740, loss: 0.012446308508515358
step: 750, loss: 0.06395751237869263
step: 760, loss: 0.05018260329961777
step: 770, loss: 0.0003682958194985986
step: 780, loss: 0.02419407293200493
step: 790, loss: 0.0007577296928502619
step: 800, loss: 0.013167712837457657
step: 810, loss: 0.04295065626502037
step: 820, loss: 0.039730288088321686
step: 830, loss: 0.12266111373901367
step: 840, loss: 0.09888254851102829
step: 850, loss: 0.0009489627555012703
step: 860, loss: 0.01060611754655838
step: 870, loss: 0.021341517567634583
step: 880, loss: 0.1550847738981247
step: 890, loss: 0.029902543872594833
step: 900, loss: 0.006122516468167305
step: 910, loss: 0.0660298764705658
step: 920, loss: 0.03879721090197563
step: 930, loss: 0.01654895953834057
step: 940, loss: 0.022315561771392822
step: 950, loss: 0.06322797387838364
step: 960, loss: 0.03428203985095024
step: 970, loss: 0.026472294703125954
step: 980, loss: 0.008868384175002575
step: 990, loss: 0.03614784777164459
step: 1000, loss: 0.12677238881587982
step: 1010, loss: 0.03216928243637085
step: 1020, loss: 0.10151825100183487
step: 1030, loss: 0.08898534625768661
step: 1040, loss: 0.071109339594841
step: 1050, loss: 0.024142909795045853
step: 1060, loss: 0.10264710336923599
step: 1070, loss: 0.015825137495994568
epoch 10: dev_f1=0.9416160672582905, f1=0.9381107491856677, best_f1=0.9324699352451433
step: 0, loss: 0.03531048074364662
step: 10, loss: 0.03143812343478203
step: 20, loss: 0.039075080305337906
step: 30, loss: 0.006872686091810465
step: 40, loss: 0.002047755056992173
step: 50, loss: 0.005261538550257683
step: 60, loss: 0.05505157262086868
step: 70, loss: 0.07870093733072281
step: 80, loss: 0.018667612224817276
step: 90, loss: 0.005109791178256273
step: 100, loss: 0.003626831341534853
step: 110, loss: 0.013184634037315845
step: 120, loss: 0.01658630184829235
step: 130, loss: 0.08017179369926453
step: 140, loss: 0.07760913670063019
step: 150, loss: 0.0409989058971405
step: 160, loss: 0.018521180376410484
step: 170, loss: 0.08447039127349854
step: 180, loss: 0.05637593939900398
step: 190, loss: 0.046787459403276443
step: 200, loss: 0.00030957587296143174
step: 210, loss: 0.027105025947093964
step: 220, loss: 0.06744249910116196
step: 230, loss: 0.008083046413958073
step: 240, loss: 0.0746317207813263
step: 250, loss: 0.0034222672693431377
step: 260, loss: 0.00015565866488032043
step: 270, loss: 0.039560530334711075
step: 280, loss: 2.044017855951097e-05
step: 290, loss: 0.04406732693314552
step: 300, loss: 0.07121448218822479
step: 310, loss: 0.017493491992354393
step: 320, loss: 0.20226581394672394
step: 330, loss: 0.04151547700166702
step: 340, loss: 0.02656443603336811
step: 350, loss: 0.0038109307643026114
step: 360, loss: 0.013899730518460274
step: 370, loss: 0.057865794748067856
step: 380, loss: 2.9754595743725076e-05
step: 390, loss: 0.10213308781385422
step: 400, loss: 0.00942784734070301
step: 410, loss: 0.014414209872484207
step: 420, loss: 0.00829730462282896
step: 430, loss: 0.016303880140185356
step: 440, loss: 0.01365568209439516
step: 450, loss: 0.02864568680524826
step: 460, loss: 0.04951923340559006
step: 470, loss: 0.0684167891740799
step: 480, loss: 0.1921340823173523
step: 490, loss: 0.029049383476376534
step: 500, loss: 0.04736589640378952
step: 510, loss: 0.07905823737382889
step: 520, loss: 0.00581946037709713
step: 530, loss: 0.0013756618136540055
step: 540, loss: 0.0010835707653313875
step: 550, loss: 0.04014216363430023
step: 560, loss: 0.07736733555793762
step: 570, loss: 0.003081520553678274
step: 580, loss: 0.002400223631411791
step: 590, loss: 0.04401790723204613
step: 600, loss: 0.04335445538163185
step: 610, loss: 0.011874779127538204
step: 620, loss: 0.018822969868779182
step: 630, loss: 0.001698171254247427
step: 640, loss: 0.035851769149303436
step: 650, loss: 0.10646232217550278
step: 660, loss: 0.01217884011566639
step: 670, loss: 0.0051687234081327915
step: 680, loss: 0.08579132705926895
step: 690, loss: 0.024757960811257362
step: 700, loss: 0.004056261852383614
step: 710, loss: 0.11279220134019852
step: 720, loss: 0.04341178387403488
step: 730, loss: 0.08142952620983124
step: 740, loss: 0.04195191338658333
step: 750, loss: 0.0283365398645401
step: 760, loss: 0.05390129238367081
step: 770, loss: 0.026788638904690742
step: 780, loss: 0.0649292916059494
step: 790, loss: 0.10967369377613068
step: 800, loss: 0.030587943270802498
step: 810, loss: 0.032935887575149536
step: 820, loss: 0.022228823974728584
step: 830, loss: 0.049887433648109436
step: 840, loss: 0.07943237572908401
step: 850, loss: 0.010496906004846096
step: 860, loss: 0.02164146676659584
step: 870, loss: 0.019635695964097977
step: 880, loss: 0.0016855476424098015
step: 890, loss: 0.041519518941640854
step: 900, loss: 0.1489805281162262
step: 910, loss: 0.01655280403792858
step: 920, loss: 0.10018648207187653
step: 930, loss: 0.04897543787956238
step: 940, loss: 0.03204880654811859
step: 950, loss: 0.07570993155241013
step: 960, loss: 0.06874323636293411
step: 970, loss: 0.09131269156932831
step: 980, loss: 0.14772439002990723
step: 990, loss: 0.09259337186813354
step: 1000, loss: 0.04623428359627724
step: 1010, loss: 0.024910474196076393
step: 1020, loss: 0.06220575422048569
step: 1030, loss: 0.03301205858588219
step: 1040, loss: 0.06288672238588333
step: 1050, loss: 0.11345073580741882
step: 1060, loss: 0.011130875907838345
step: 1070, loss: 0.016855081543326378
epoch 11: dev_f1=0.9420884632922938, f1=0.9281164695177435, best_f1=0.9324699352451433
step: 0, loss: 0.036419667303562164
step: 10, loss: 0.00031216940260492265
step: 20, loss: 0.002235135529190302
step: 30, loss: 0.03781178593635559
step: 40, loss: 0.032495975494384766
step: 50, loss: 0.08056477457284927
step: 60, loss: 0.02454151026904583
step: 70, loss: 0.0020973251666873693
step: 80, loss: 0.004366014618426561
step: 90, loss: 0.04557347297668457
step: 100, loss: 0.008508638478815556
step: 110, loss: 0.0332125648856163
step: 120, loss: 0.055014751851558685
step: 130, loss: 0.03411342576146126
step: 140, loss: 0.030034217983484268
step: 150, loss: 0.002536618383601308
step: 160, loss: 0.000494474486913532
step: 170, loss: 0.025969654321670532
step: 180, loss: 0.015606758184731007
step: 190, loss: 0.06012424826622009
step: 200, loss: 0.021184319630265236
step: 210, loss: 0.048127952963113785
step: 220, loss: 0.037367697805166245
step: 230, loss: 0.16724862158298492
step: 240, loss: 0.08563781529664993
step: 250, loss: 0.02007000334560871
step: 260, loss: 0.01876412332057953
step: 270, loss: 0.06731443107128143
step: 280, loss: 0.06061074510216713
step: 290, loss: 0.00047486289986409247
step: 300, loss: 0.03252439945936203
step: 310, loss: 0.033543024212121964
step: 320, loss: 0.012841417454183102
step: 330, loss: 0.030907414853572845
step: 340, loss: 0.04048064351081848
step: 350, loss: 0.004967879503965378
step: 360, loss: 0.07801508158445358
step: 370, loss: 0.0653587356209755
step: 380, loss: 0.0759308785200119
step: 390, loss: 0.025260433554649353
step: 400, loss: 0.025222981348633766
step: 410, loss: 5.689592580893077e-05
step: 420, loss: 0.027754945680499077
step: 430, loss: 0.0878399983048439
step: 440, loss: 6.955493881832808e-05
step: 450, loss: 0.04283330589532852
step: 460, loss: 0.034700170159339905
step: 470, loss: 0.058027032762765884
step: 480, loss: 0.1335146427154541
step: 490, loss: 0.01271657831966877
step: 500, loss: 0.009451509453356266
step: 510, loss: 0.028093112632632256
step: 520, loss: 0.0688071995973587
step: 530, loss: 0.05823563039302826
step: 540, loss: 0.0846884697675705
step: 550, loss: 0.012205645442008972
step: 560, loss: 0.02892409823834896
step: 570, loss: 0.08297936618328094
step: 580, loss: 3.489663504296914e-05
step: 590, loss: 0.017276568338274956
step: 600, loss: 0.05011128634214401
step: 610, loss: 0.07877148687839508
step: 620, loss: 0.060923267155885696
step: 630, loss: 0.0805024579167366
step: 640, loss: 0.015391938388347626
step: 650, loss: 0.19083033502101898
step: 660, loss: 0.03926875814795494
step: 670, loss: 0.00045643484918400645
step: 680, loss: 0.08816011995077133
step: 690, loss: 0.026607122272253036
step: 700, loss: 0.0642407163977623
step: 710, loss: 0.021993832662701607
step: 720, loss: 0.03755148872733116
step: 730, loss: 0.03517330065369606
step: 740, loss: 0.0063663143664598465
step: 750, loss: 0.11878784000873566
step: 760, loss: 0.0647566020488739
step: 770, loss: 0.04605039209127426
step: 780, loss: 0.09917031973600388
step: 790, loss: 0.05743192508816719
step: 800, loss: 0.039289966225624084
step: 810, loss: 0.09265996515750885
step: 820, loss: 0.024909531697630882
step: 830, loss: 0.0016272690845653415
step: 840, loss: 0.11211512237787247
step: 850, loss: 0.017460409551858902
step: 860, loss: 0.0011123005533590913
step: 870, loss: 0.0025480359327048063
step: 880, loss: 0.002258248394355178
step: 890, loss: 0.004257857799530029
step: 900, loss: 0.0015276097692549229
step: 910, loss: 3.711782119353302e-05
step: 920, loss: 0.06856938451528549
step: 930, loss: 0.016794363036751747
step: 940, loss: 0.0013639871031045914
step: 950, loss: 0.003678928827866912
step: 960, loss: 0.02248743176460266
step: 970, loss: 4.2520354327280074e-05
step: 980, loss: 0.04032794013619423
step: 990, loss: 0.08751855045557022
step: 1000, loss: 0.03152332454919815
step: 1010, loss: 0.05466820299625397
step: 1020, loss: 0.0019357597921043634
step: 1030, loss: 0.0014525519218295813
step: 1040, loss: 0.07119650393724442
step: 1050, loss: 0.042872920632362366
step: 1060, loss: 0.018759721890091896
step: 1070, loss: 0.04905896261334419
epoch 12: dev_f1=0.9386446886446886, f1=0.9242700729927007, best_f1=0.9324699352451433
step: 0, loss: 0.00078500562813133
step: 10, loss: 0.0038863944355398417
step: 20, loss: 0.0003112116828560829
step: 30, loss: 0.058894623070955276
step: 40, loss: 0.05057337135076523
step: 50, loss: 0.006809634156525135
step: 60, loss: 0.07690123468637466
step: 70, loss: 0.12145739793777466
step: 80, loss: 0.013517070561647415
step: 90, loss: 0.024386275559663773
step: 100, loss: 0.03617212921380997
step: 110, loss: 0.060647524893283844
step: 120, loss: 0.0020919782109558582
step: 130, loss: 0.002829363103955984
step: 140, loss: 0.023425456136465073
step: 150, loss: 0.06859588623046875
step: 160, loss: 0.044543564319610596
step: 170, loss: 0.061536990106105804
step: 180, loss: 0.014068684540688992
step: 190, loss: 0.09895464777946472
step: 200, loss: 0.03402683883905411
step: 210, loss: 0.03141504526138306
step: 220, loss: 0.028426501899957657
step: 230, loss: 0.061510659754276276
step: 240, loss: 0.07990478724241257
step: 250, loss: 0.008885188028216362
step: 260, loss: 0.017100468277931213
step: 270, loss: 0.015435867942869663
step: 280, loss: 0.04983489587903023
step: 290, loss: 0.03375087305903435
step: 300, loss: 0.001364974887110293
step: 310, loss: 0.02693895436823368
step: 320, loss: 0.008126413449645042
step: 330, loss: 2.3975289877853356e-05
step: 340, loss: 0.01856587640941143
step: 350, loss: 0.026318911463022232
step: 360, loss: 0.10996027290821075
step: 370, loss: 0.07171007245779037
step: 380, loss: 0.05558966100215912
step: 390, loss: 0.059816595166921616
step: 400, loss: 0.004629660397768021
step: 410, loss: 0.00031921302434057
step: 420, loss: 0.010836690664291382
step: 430, loss: 0.05660069361329079
step: 440, loss: 0.022244974970817566
step: 450, loss: 0.07332383841276169
step: 460, loss: 0.0003846945764962584
step: 470, loss: 0.02952626906335354
step: 480, loss: 0.023082533851265907
step: 490, loss: 0.002937458688393235
step: 500, loss: 0.08382734656333923
step: 510, loss: 0.022016679868102074
step: 520, loss: 0.019880298525094986
step: 530, loss: 0.023647047579288483
step: 540, loss: 0.00052716612117365
step: 550, loss: 0.029436051845550537
step: 560, loss: 0.01594729907810688
step: 570, loss: 0.00402910215780139
step: 580, loss: 0.041829828172922134
step: 590, loss: 0.021079355850815773
step: 600, loss: 0.022883055731654167
step: 610, loss: 0.0015911576338112354
step: 620, loss: 0.029847292229533195
step: 630, loss: 0.0018497009295970201
step: 640, loss: 0.01962468773126602
step: 650, loss: 0.018318550661206245
step: 660, loss: 0.053346987813711166
step: 670, loss: 0.03916770592331886
step: 680, loss: 0.0359024815261364
step: 690, loss: 0.028651973232626915
step: 700, loss: 0.04480674862861633
step: 710, loss: 0.099186010658741
step: 720, loss: 0.0004280785797163844
step: 730, loss: 0.0002484042488504201
step: 740, loss: 0.009479212574660778
step: 750, loss: 9.364527795696631e-05
step: 760, loss: 0.021811675280332565
step: 770, loss: 0.0070061939768493176
step: 780, loss: 0.006803127471357584
step: 790, loss: 0.02163926139473915
step: 800, loss: 0.01517775934189558
step: 810, loss: 0.05363605171442032
step: 820, loss: 0.07918881624937057
step: 830, loss: 0.0716840997338295
step: 840, loss: 0.0045076292008161545
step: 850, loss: 0.00012453157978598028
step: 860, loss: 0.02239488810300827
step: 870, loss: 0.019641157239675522
step: 880, loss: 0.006096114404499531
step: 890, loss: 0.0409807488322258
step: 900, loss: 0.06579996645450592
step: 910, loss: 0.04662034288048744
step: 920, loss: 0.03275463357567787
step: 930, loss: 0.034135472029447556
step: 940, loss: 0.08767493069171906
step: 950, loss: 0.036645591259002686
step: 960, loss: 0.03512600064277649
step: 970, loss: 0.09394101798534393
step: 980, loss: 0.029505295678973198
step: 990, loss: 0.005069812759757042
step: 1000, loss: 0.03612491115927696
step: 1010, loss: 0.027689527720212936
step: 1020, loss: 0.11588846892118454
step: 1030, loss: 0.025259975343942642
step: 1040, loss: 0.10370955616235733
step: 1050, loss: 0.0018503895262256265
step: 1060, loss: 0.005858064163476229
step: 1070, loss: 1.1883569641213398e-05
epoch 13: dev_f1=0.9429622815087396, f1=0.9282428702851886, best_f1=0.9282428702851886
step: 0, loss: 0.026653075590729713
step: 10, loss: 0.0697542354464531
step: 20, loss: 0.10341459512710571
step: 30, loss: 0.023799816146492958
step: 40, loss: 0.0027373237535357475
step: 50, loss: 6.759219104424119e-05
step: 60, loss: 0.00015981553588062525
step: 70, loss: 0.01893361657857895
step: 80, loss: 0.029176943004131317
step: 90, loss: 0.0036252420395612717
step: 100, loss: 0.012878697365522385
step: 110, loss: 0.01688133180141449
step: 120, loss: 0.0009161813650280237
step: 130, loss: 0.09096626937389374
step: 140, loss: 0.06254178285598755
step: 150, loss: 0.020405029878020287
step: 160, loss: 0.030225686728954315
step: 170, loss: 0.011274220421910286
step: 180, loss: 0.004299904685467482
step: 190, loss: 0.000584773370064795
step: 200, loss: 0.019635170698165894
step: 210, loss: 0.018530121073126793
step: 220, loss: 0.11754989624023438
step: 230, loss: 0.01714126020669937
step: 240, loss: 0.05492479354143143
step: 250, loss: 0.06429098546504974
step: 260, loss: 0.09802460670471191
step: 270, loss: 4.103701576241292e-05
step: 280, loss: 0.000622158870100975
step: 290, loss: 0.0476565957069397
step: 300, loss: 0.0006846300675533712
step: 310, loss: 0.09373612701892853
step: 320, loss: 0.031437985599040985
step: 330, loss: 0.003987486939877272
step: 340, loss: 0.010530407540500164
step: 350, loss: 0.03280176594853401
step: 360, loss: 0.08138014376163483
step: 370, loss: 0.016715532168745995
step: 380, loss: 0.0024413964711129665
step: 390, loss: 0.02396513521671295
step: 400, loss: 0.11322175711393356
step: 410, loss: 0.06948460638523102
step: 420, loss: 0.04422786831855774
step: 430, loss: 0.03528217226266861
step: 440, loss: 0.0013158684596419334
step: 450, loss: 0.012795832008123398
step: 460, loss: 3.1679923267802224e-05
step: 470, loss: 0.001066958182491362
step: 480, loss: 0.038186512887477875
step: 490, loss: 0.0007821862236596644
step: 500, loss: 0.14858394861221313
step: 510, loss: 0.041650254279375076
step: 520, loss: 0.07065307348966599
step: 530, loss: 0.025960998609662056
step: 540, loss: 0.030912606045603752
step: 550, loss: 0.00021413451759144664
step: 560, loss: 0.06608350574970245
step: 570, loss: 0.0439082533121109
step: 580, loss: 0.05223151668906212
step: 590, loss: 0.02027648314833641
step: 600, loss: 0.04725923389196396
step: 610, loss: 0.03413350507616997
step: 620, loss: 0.047083016484975815
step: 630, loss: 0.00022620359959546477
step: 640, loss: 8.035312202991918e-05
step: 650, loss: 0.09747444838285446
step: 660, loss: 0.017016716301441193
step: 670, loss: 0.0013155564665794373
step: 680, loss: 1.5675796021241695e-05
step: 690, loss: 0.04012591019272804
step: 700, loss: 0.02340167760848999
step: 710, loss: 0.00562095083296299
step: 720, loss: 0.03688352555036545
step: 730, loss: 0.01768321916460991
step: 740, loss: 0.03164977207779884
step: 750, loss: 0.08320684731006622
step: 760, loss: 0.028485167771577835
step: 770, loss: 0.0037355602253228426
step: 780, loss: 0.11195047944784164
step: 790, loss: 0.003320442046970129
step: 800, loss: 0.03531932085752487
step: 810, loss: 0.04361812770366669
step: 820, loss: 0.028212107717990875
step: 830, loss: 0.04415817931294441
step: 840, loss: 0.01226758398115635
step: 850, loss: 0.03286254405975342
step: 860, loss: 0.03024626150727272
step: 870, loss: 0.02834172546863556
step: 880, loss: 0.04920729249715805
step: 890, loss: 0.002404283033683896
step: 900, loss: 0.08813662081956863
step: 910, loss: 0.018960993736982346
step: 920, loss: 0.01809333823621273
step: 930, loss: 0.0006189716514199972
step: 940, loss: 0.03325715288519859
step: 950, loss: 0.04762036353349686
step: 960, loss: 0.03920438140630722
step: 970, loss: 0.017373990267515182
step: 980, loss: 0.02447662502527237
step: 990, loss: 0.137499138712883
step: 1000, loss: 0.030086016282439232
step: 1010, loss: 0.042120832949876785
step: 1020, loss: 0.07010963559150696
step: 1030, loss: 0.12763845920562744
step: 1040, loss: 0.15632633864879608
step: 1050, loss: 0.023374848067760468
step: 1060, loss: 0.0656716451048851
step: 1070, loss: 0.06397051364183426
epoch 14: dev_f1=0.9411219286045434, f1=0.9351851851851852, best_f1=0.9282428702851886
step: 0, loss: 0.07245955616235733
step: 10, loss: 0.045955002307891846
step: 20, loss: 0.0015472787199541926
step: 30, loss: 0.027686791494488716
step: 40, loss: 0.0006114756106399
step: 50, loss: 5.244199564913288e-05
step: 60, loss: 0.011509296484291553
step: 70, loss: 0.042143315076828
step: 80, loss: 0.026042230427265167
step: 90, loss: 0.09116751700639725
step: 100, loss: 0.018415650352835655
step: 110, loss: 0.048595670610666275
step: 120, loss: 0.0074232760816812515
step: 130, loss: 2.1211017156019807e-05
step: 140, loss: 0.13892222940921783
step: 150, loss: 8.804154640529305e-05
step: 160, loss: 0.0008671781979501247
step: 170, loss: 0.029269209131598473
step: 180, loss: 0.04976062476634979
step: 190, loss: 0.03358648717403412
step: 200, loss: 0.015449726022779942
step: 210, loss: 0.0027688215486705303
step: 220, loss: 0.008985782042145729
step: 230, loss: 0.001862134551629424
step: 240, loss: 0.018170518800616264
step: 250, loss: 0.029129717499017715
step: 260, loss: 0.12044546008110046
step: 270, loss: 0.0001994740596273914
step: 280, loss: 0.004490712657570839
step: 290, loss: 0.025904636830091476
step: 300, loss: 0.058655399829149246
step: 310, loss: 0.1192173883318901
step: 320, loss: 0.004423166625201702
step: 330, loss: 0.0454898364841938
step: 340, loss: 0.09182661771774292
step: 350, loss: 0.044976722449064255
step: 360, loss: 2.134397072950378e-05
step: 370, loss: 0.008278975263237953
step: 380, loss: 0.0019819254521280527
step: 390, loss: 4.401176920509897e-05
step: 400, loss: 0.024582084268331528
step: 410, loss: 0.010636922903358936
step: 420, loss: 0.028994619846343994
step: 430, loss: 0.06334281712770462
step: 440, loss: 0.0020017847418785095
step: 450, loss: 0.0296477060765028
step: 460, loss: 0.03775325044989586
step: 470, loss: 0.05244030803442001
step: 480, loss: 0.028625428676605225
step: 490, loss: 0.07657859474420547
step: 500, loss: 0.08172077685594559
step: 510, loss: 0.08008155226707458
step: 520, loss: 0.00023571107885800302
step: 530, loss: 0.13763292133808136
step: 540, loss: 0.02249385230243206
step: 550, loss: 0.023938311263918877
step: 560, loss: 0.02161986567080021
step: 570, loss: 0.004217898473143578
step: 580, loss: 0.03574535995721817
step: 590, loss: 0.07755232602357864
step: 600, loss: 0.016668284311890602
step: 610, loss: 0.0184283796697855
step: 620, loss: 0.0018450528150424361
step: 630, loss: 0.08095111697912216
step: 640, loss: 0.046247269958257675
step: 650, loss: 0.04845258966088295
step: 660, loss: 0.06683479994535446
step: 670, loss: 0.016285251826047897
step: 680, loss: 0.027040116488933563
step: 690, loss: 0.03379863128066063
step: 700, loss: 0.026806730777025223
step: 710, loss: 1.9448818420642056e-05
step: 720, loss: 0.025419160723686218
step: 730, loss: 0.00459365313872695
step: 740, loss: 0.009274759329855442
step: 750, loss: 0.1400848627090454
step: 760, loss: 0.07210777699947357
step: 770, loss: 0.047602832317352295
step: 780, loss: 0.022768395021557808
step: 790, loss: 0.057318683713674545
step: 800, loss: 0.04365761578083038
step: 810, loss: 0.009545642882585526
step: 820, loss: 0.02748117409646511
step: 830, loss: 0.06640862673521042
step: 840, loss: 0.045817285776138306
step: 850, loss: 4.101133890799247e-05
step: 860, loss: 0.019305232912302017
step: 870, loss: 1.8901489966083318e-05
step: 880, loss: 0.00022570572036784142
step: 890, loss: 0.05905895307660103
step: 900, loss: 0.010645732283592224
step: 910, loss: 0.0785968229174614
step: 920, loss: 0.0032693310640752316
step: 930, loss: 0.10111112892627716
step: 940, loss: 0.04170824959874153
step: 950, loss: 1.512071230536094e-05
step: 960, loss: 3.3374715712852776e-05
step: 970, loss: 0.03168266639113426
step: 980, loss: 2.8280004698899575e-05
step: 990, loss: 0.002532273530960083
step: 1000, loss: 0.008767958730459213
step: 1010, loss: 0.04964906722307205
step: 1020, loss: 0.06361832469701767
step: 1030, loss: 0.049676451832056046
step: 1040, loss: 0.0619426891207695
step: 1050, loss: 0.05540654435753822
step: 1060, loss: 0.0294907558709383
step: 1070, loss: 0.014974161051213741
epoch 15: dev_f1=0.9399260628465804, f1=0.9285714285714285, best_f1=0.9282428702851886
step: 0, loss: 0.033641282469034195
step: 10, loss: 0.015363176353275776
step: 20, loss: 4.097595592611469e-05
step: 30, loss: 0.01883571222424507
step: 40, loss: 0.035205669701099396
step: 50, loss: 0.021966764703392982
step: 60, loss: 0.006226670928299427
step: 70, loss: 0.012763386592268944
step: 80, loss: 0.073724664747715
step: 90, loss: 0.01682412438094616
step: 100, loss: 3.936576467822306e-05
step: 110, loss: 0.0011471459874883294
step: 120, loss: 0.0038466036785393953
step: 130, loss: 0.01950649917125702
step: 140, loss: 6.115240103099495e-05
step: 150, loss: 0.021552767604589462
step: 160, loss: 0.0005879125092178583
step: 170, loss: 0.04847770184278488
step: 180, loss: 0.03287690132856369
step: 190, loss: 0.04557850956916809
step: 200, loss: 0.015309901908040047
step: 210, loss: 0.0001531734742457047
step: 220, loss: 0.06694885343313217
step: 230, loss: 0.021278828382492065
step: 240, loss: 0.0018941458547487855
step: 250, loss: 0.0003667942073661834
step: 260, loss: 0.021515225991606712
step: 270, loss: 0.0584133118391037
step: 280, loss: 0.0372387170791626
step: 290, loss: 0.003225045744329691
step: 300, loss: 0.0991930440068245
step: 310, loss: 0.03959127143025398
step: 320, loss: 0.08830046653747559
step: 330, loss: 0.03645319119095802
step: 340, loss: 0.0670381411910057
step: 350, loss: 0.02194478176534176
step: 360, loss: 0.02106541581451893
step: 370, loss: 0.007542753592133522
step: 380, loss: 0.05794887989759445
step: 390, loss: 0.02176995575428009
step: 400, loss: 0.017623815685510635
step: 410, loss: 0.06741112470626831
step: 420, loss: 0.0709245577454567
step: 430, loss: 0.062008216977119446
step: 440, loss: 0.00100441905669868
step: 450, loss: 0.09748721867799759
step: 460, loss: 0.023103978484869003
step: 470, loss: 0.024564405903220177
step: 480, loss: 0.0502142533659935
step: 490, loss: 0.00016084835806395859
step: 500, loss: 0.02703768014907837
step: 510, loss: 0.03797078877687454
step: 520, loss: 0.00027593120466917753
step: 530, loss: 0.04546164348721504
step: 540, loss: 0.03588653728365898
step: 550, loss: 0.008671990595757961
step: 560, loss: 0.05403944477438927
step: 570, loss: 0.035302095115184784
step: 580, loss: 0.022708425298333168
step: 590, loss: 0.05768832191824913
step: 600, loss: 0.00031028621015138924
step: 610, loss: 0.03148264065384865
step: 620, loss: 0.030729936435818672
step: 630, loss: 0.0796547457575798
step: 640, loss: 0.07052765041589737
step: 650, loss: 0.003408008022233844
step: 660, loss: 0.0767558142542839
step: 670, loss: 0.05234704911708832
step: 680, loss: 0.034059323370456696
step: 690, loss: 0.044875986874103546
step: 700, loss: 0.013162760064005852
step: 710, loss: 1.3287930414662696e-05
step: 720, loss: 0.10598698258399963
step: 730, loss: 0.0006200920906849205
step: 740, loss: 0.027618519961833954
step: 750, loss: 0.057738956063985825
step: 760, loss: 0.044898007065057755
step: 770, loss: 0.029349321499466896
step: 780, loss: 0.0073460666462779045
step: 790, loss: 0.020197473466396332
step: 800, loss: 0.0009369269828312099
step: 810, loss: 0.0009794490179046988
step: 820, loss: 0.010786980390548706
step: 830, loss: 0.023608339950442314
step: 840, loss: 0.04249972850084305
step: 850, loss: 0.0204341858625412
step: 860, loss: 0.004375450778752565
step: 870, loss: 0.0016306290635839105
step: 880, loss: 0.0005200788145884871
step: 890, loss: 0.06984781473875046
step: 900, loss: 0.03757817670702934
step: 910, loss: 0.05076779052615166
step: 920, loss: 0.06280053406953812
step: 930, loss: 0.02602604404091835
step: 940, loss: 0.026232808828353882
step: 950, loss: 0.053215522319078445
step: 960, loss: 0.01950540952384472
step: 970, loss: 0.09735139459371567
step: 980, loss: 0.036711208522319794
step: 990, loss: 0.025577683001756668
step: 1000, loss: 0.03588879108428955
step: 1010, loss: 0.024219844490289688
step: 1020, loss: 2.622678039188031e-05
step: 1030, loss: 0.039986271411180496
step: 1040, loss: 0.02559596672654152
step: 1050, loss: 0.02153896912932396
step: 1060, loss: 0.042818766087293625
step: 1070, loss: 0.01559899840503931
epoch 16: dev_f1=0.9386814200092208, f1=0.9263157894736843, best_f1=0.9282428702851886
step: 0, loss: 0.010833079926669598
step: 10, loss: 0.01945093832910061
step: 20, loss: 0.06992024928331375
step: 30, loss: 0.054654017090797424
step: 40, loss: 2.8258325983188115e-05
step: 50, loss: 8.826597331790254e-05
step: 60, loss: 0.011883141472935677
step: 70, loss: 0.03474699705839157
step: 80, loss: 0.0016252334462478757
step: 90, loss: 0.0353827029466629
step: 100, loss: 5.104938099975698e-05
step: 110, loss: 0.03882543370127678
step: 120, loss: 0.018116595223546028
step: 130, loss: 0.02165207639336586
step: 140, loss: 0.024939747527241707
step: 150, loss: 0.0009637724724598229
step: 160, loss: 0.04087486118078232
step: 170, loss: 0.017552288249135017
step: 180, loss: 0.02575097791850567
step: 190, loss: 1.763486761774402e-05
step: 200, loss: 0.003979198168963194
step: 210, loss: 0.04213627427816391
step: 220, loss: 0.021115807816386223
step: 230, loss: 0.0475182943046093
step: 240, loss: 4.5562668674392626e-05
step: 250, loss: 0.000403545331209898
step: 260, loss: 0.024508299306035042
step: 270, loss: 0.0017056360375136137
step: 280, loss: 0.03632132336497307
step: 290, loss: 0.02144366316497326
step: 300, loss: 0.00013522263907361776
step: 310, loss: 0.02161845751106739
step: 320, loss: 0.024881087243556976
step: 330, loss: 0.001383406575769186
step: 340, loss: 0.039020195603370667
step: 350, loss: 0.03895524516701698
step: 360, loss: 7.77786408434622e-05
step: 370, loss: 0.06355813145637512
step: 380, loss: 0.002931982045993209
step: 390, loss: 0.03521640971302986
step: 400, loss: 0.04490127041935921
step: 410, loss: 0.0013403280172497034
step: 420, loss: 0.0009161162888631225
step: 430, loss: 7.681683200644329e-05
step: 440, loss: 0.05595395341515541
step: 450, loss: 3.691014353535138e-05
step: 460, loss: 0.01975984312593937
step: 470, loss: 0.0006813686341047287
step: 480, loss: 0.02058253437280655
step: 490, loss: 0.059011783450841904
step: 500, loss: 0.062425557523965836
step: 510, loss: 0.022657247260212898
step: 520, loss: 0.029113009572029114
step: 530, loss: 0.033554598689079285
step: 540, loss: 0.030620494857430458
step: 550, loss: 0.03455580398440361
step: 560, loss: 0.013057980686426163
step: 570, loss: 0.038392581045627594
step: 580, loss: 0.03816169500350952
step: 590, loss: 0.03187406435608864
step: 600, loss: 0.022684648633003235
step: 610, loss: 0.0636436939239502
step: 620, loss: 0.010876460932195187
step: 630, loss: 5.1665214414242655e-05
step: 640, loss: 0.03643617406487465
step: 650, loss: 0.03003688156604767
step: 660, loss: 2.3877457351773046e-05
step: 670, loss: 3.420963912503794e-05
step: 680, loss: 0.000885225716046989
step: 690, loss: 0.022863244637846947
step: 700, loss: 4.022624852950685e-05
step: 710, loss: 0.09890468418598175
step: 720, loss: 0.05124368891119957
step: 730, loss: 0.055414095520973206
step: 740, loss: 0.020108474418520927
step: 750, loss: 0.05750006064772606
step: 760, loss: 0.02806156314909458
step: 770, loss: 0.052651453763246536
step: 780, loss: 0.03312249854207039
step: 790, loss: 0.060362182557582855
step: 800, loss: 0.004846654832363129
step: 810, loss: 0.006620520260185003
step: 820, loss: 0.06113504245877266
step: 830, loss: 0.01944991573691368
step: 840, loss: 0.0001969518489204347
step: 850, loss: 1.6342401067959145e-05
step: 860, loss: 0.007106586825102568
step: 870, loss: 0.04595757648348808
step: 880, loss: 0.04368354752659798
step: 890, loss: 0.0030084603931754827
step: 900, loss: 0.001457184087485075
step: 910, loss: 5.7507972087478265e-05
step: 920, loss: 0.0016372513491660357
step: 930, loss: 0.0339016430079937
step: 940, loss: 0.021000469103455544
step: 950, loss: 0.0654064193367958
step: 960, loss: 0.022472957149147987
step: 970, loss: 0.1314580887556076
step: 980, loss: 0.030587468296289444
step: 990, loss: 0.041756320744752884
step: 1000, loss: 0.030469125136733055
step: 1010, loss: 0.08352895081043243
step: 1020, loss: 0.03924735635519028
step: 1030, loss: 0.02129027433693409
step: 1040, loss: 0.02192148193717003
step: 1050, loss: 0.04466036334633827
step: 1060, loss: 0.029928850010037422
step: 1070, loss: 0.027694858610630035
epoch 17: dev_f1=0.9386792452830189, f1=0.9314553990610329, best_f1=0.9282428702851886
step: 0, loss: 0.01953495480120182
step: 10, loss: 0.0001992217148654163
step: 20, loss: 0.05167429894208908
step: 30, loss: 0.05885155498981476
step: 40, loss: 0.025862079113721848
step: 50, loss: 0.04200119525194168
step: 60, loss: 0.03611317276954651
step: 70, loss: 0.0025947573594748974
step: 80, loss: 0.0631965771317482
step: 90, loss: 0.020542996004223824
step: 100, loss: 0.0905604213476181
step: 110, loss: 0.013584382832050323
step: 120, loss: 0.029091479256749153
step: 130, loss: 0.07884824275970459
step: 140, loss: 0.006387598812580109
step: 150, loss: 0.03958030790090561
step: 160, loss: 0.052379000931978226
step: 170, loss: 0.034295711666345596
step: 180, loss: 0.04657605290412903
step: 190, loss: 0.02388354390859604
step: 200, loss: 0.026346934959292412
step: 210, loss: 0.03970828652381897
step: 220, loss: 3.5261236916994676e-05
step: 230, loss: 0.03398675471544266
step: 240, loss: 1.3649260836245958e-05
step: 250, loss: 0.000100354001915548
step: 260, loss: 0.004524277523159981
step: 270, loss: 0.042066790163517
step: 280, loss: 0.02189684472978115
step: 290, loss: 0.018401609733700752
step: 300, loss: 0.0522034615278244
step: 310, loss: 0.010787843726575375
step: 320, loss: 0.04075288772583008
step: 330, loss: 3.361448762007058e-05
step: 340, loss: 0.01893514394760132
step: 350, loss: 0.01735147088766098
step: 360, loss: 0.023359455168247223
step: 370, loss: 1.503124167356873e-05
step: 380, loss: 0.01873600110411644
step: 390, loss: 0.0003326324513182044
step: 400, loss: 0.04533054307103157
step: 410, loss: 9.740103996591642e-05
step: 420, loss: 0.04639560729265213
step: 430, loss: 2.375146868871525e-05
step: 440, loss: 0.00031027471413835883
step: 450, loss: 0.023697419092059135
step: 460, loss: 0.0005351740401238203
step: 470, loss: 0.014764077961444855
step: 480, loss: 0.0645446628332138
step: 490, loss: 0.0940089002251625
step: 500, loss: 0.0004451712593436241
step: 510, loss: 2.3274335035239346e-05
step: 520, loss: 0.00023411217262037098
step: 530, loss: 0.08197207748889923
step: 540, loss: 0.0760747417807579
step: 550, loss: 0.001881923177279532
step: 560, loss: 0.02077433653175831
step: 570, loss: 0.03397679328918457
step: 580, loss: 0.042461976408958435
step: 590, loss: 0.01445047464221716
step: 600, loss: 0.033629417419433594
step: 610, loss: 0.0027291360311210155
step: 620, loss: 0.008817395195364952
step: 630, loss: 0.03464240953326225
step: 640, loss: 0.0010647193994373083
step: 650, loss: 0.018529903143644333
step: 660, loss: 0.024310436099767685
step: 670, loss: 0.04275081679224968
step: 680, loss: 0.0371832437813282
step: 690, loss: 0.06299670785665512
step: 700, loss: 0.031120536848902702
step: 710, loss: 0.021412674337625504
step: 720, loss: 0.00035937942448072135
step: 730, loss: 0.1374209076166153
step: 740, loss: 0.04417043551802635
step: 750, loss: 0.023352384567260742
step: 760, loss: 1.5686680853832513e-05
step: 770, loss: 0.0005213821423240006
step: 780, loss: 0.002663287566974759
step: 790, loss: 0.000770377810113132
step: 800, loss: 0.08968732506036758
step: 810, loss: 0.008188053965568542
step: 820, loss: 0.012501765042543411
step: 830, loss: 0.047150157392024994
step: 840, loss: 0.002714993664994836
step: 850, loss: 0.017776327207684517
step: 860, loss: 0.04382363334298134
step: 870, loss: 0.05652347207069397
step: 880, loss: 0.020642496645450592
step: 890, loss: 0.0045399353839457035
step: 900, loss: 0.00030209741089493036
step: 910, loss: 0.017975755035877228
step: 920, loss: 0.07693611085414886
step: 930, loss: 0.008616755716502666
step: 940, loss: 0.011372468434274197
step: 950, loss: 0.05761890485882759
step: 960, loss: 0.00046660201041959226
step: 970, loss: 0.042532823979854584
step: 980, loss: 3.6587520298780873e-05
step: 990, loss: 0.055038414895534515
step: 1000, loss: 0.041385017335414886
step: 1010, loss: 0.04710041731595993
step: 1020, loss: 0.040176067501306534
step: 1030, loss: 0.0027900072745978832
step: 1040, loss: 0.012398101389408112
step: 1050, loss: 0.02292194962501526
step: 1060, loss: 0.02727746218442917
step: 1070, loss: 2.825178853527177e-05
epoch 18: dev_f1=0.9371752479924421, f1=0.9321394910461829, best_f1=0.9282428702851886
step: 0, loss: 0.0022455633152276278
step: 10, loss: 0.06951668113470078
step: 20, loss: 0.0657612755894661
step: 30, loss: 0.03061862103641033
step: 40, loss: 0.008173315785825253
step: 50, loss: 0.013661857694387436
step: 60, loss: 0.0696350634098053
step: 70, loss: 0.04359947144985199
step: 80, loss: 0.03384283557534218
step: 90, loss: 0.03112448751926422
step: 100, loss: 0.11589188128709793
step: 110, loss: 0.00014161760918796062
step: 120, loss: 0.01467082928866148
step: 130, loss: 0.02503184601664543
step: 140, loss: 0.02921479567885399
step: 150, loss: 0.018326809629797935
step: 160, loss: 2.591897464299109e-05
step: 170, loss: 0.024351714178919792
step: 180, loss: 0.007868924178183079
step: 190, loss: 0.02226758375763893
step: 200, loss: 7.205813017208129e-05
step: 210, loss: 0.022197799757122993
step: 220, loss: 0.014159716665744781
step: 230, loss: 0.03510161116719246
step: 240, loss: 2.215646964032203e-05
step: 250, loss: 5.7511850172886625e-05
step: 260, loss: 0.00010522027150727808
step: 270, loss: 0.05844137817621231
step: 280, loss: 0.026685427874326706
step: 290, loss: 0.021027375012636185
step: 300, loss: 0.013701638206839561
step: 310, loss: 0.009608062915503979
step: 320, loss: 1.430100564903114e-05
step: 330, loss: 0.054771460592746735
step: 340, loss: 0.014986129477620125
step: 350, loss: 0.004578948486596346
step: 360, loss: 2.679389035620261e-05
step: 370, loss: 0.022779209539294243
step: 380, loss: 0.04880910366773605
step: 390, loss: 0.0006167927640490234
step: 400, loss: 0.04524987190961838
step: 410, loss: 0.004880811553448439
step: 420, loss: 0.03399636223912239
step: 430, loss: 2.895104444178287e-05
step: 440, loss: 0.02575027383863926
step: 450, loss: 0.017991062253713608
step: 460, loss: 0.00022932425781618804
step: 470, loss: 0.01760973036289215
step: 480, loss: 4.870109842158854e-05
step: 490, loss: 0.020520253106951714
step: 500, loss: 0.02490968629717827
step: 510, loss: 2.049941940640565e-05
step: 520, loss: 0.06160411611199379
step: 530, loss: 0.0233998354524374
step: 540, loss: 0.02765362709760666
step: 550, loss: 0.0001160032261395827
step: 560, loss: 6.849143392173573e-05
step: 570, loss: 0.017433062195777893
step: 580, loss: 0.00013648932508658618
step: 590, loss: 0.03324659541249275
step: 600, loss: 0.02346823178231716
step: 610, loss: 0.026845235377550125
step: 620, loss: 0.0016519103664904833
step: 630, loss: 0.01905963383615017
step: 640, loss: 0.010005362331867218
step: 650, loss: 0.0013148129219189286
step: 660, loss: 1.9367238564882427e-05
step: 670, loss: 0.08907951414585114
step: 680, loss: 1.6248830434051342e-05
step: 690, loss: 5.1758419431280345e-05
step: 700, loss: 0.026347991079092026
step: 710, loss: 1.7500020476290956e-05
step: 720, loss: 0.0012253908207640052
step: 730, loss: 0.014013724401593208
step: 740, loss: 0.0020215350668877363
step: 750, loss: 9.038791904458776e-05
step: 760, loss: 0.0012289267033338547
step: 770, loss: 0.021967772394418716
step: 780, loss: 0.10617026686668396
step: 790, loss: 2.7002388378605247e-05
step: 800, loss: 3.1817802664591e-05
step: 810, loss: 1.96164855879033e-05
step: 820, loss: 0.05796809121966362
step: 830, loss: 0.0006629663403145969
step: 840, loss: 0.04658709466457367
step: 850, loss: 0.047726090997457504
step: 860, loss: 0.02395515702664852
step: 870, loss: 0.012116510421037674
step: 880, loss: 0.027689017355442047
step: 890, loss: 0.02016320824623108
step: 900, loss: 0.05128198489546776
step: 910, loss: 3.571424895199016e-05
step: 920, loss: 0.013214822858572006
step: 930, loss: 0.04122781381011009
step: 940, loss: 2.3181861251941882e-05
step: 950, loss: 0.16300639510154724
step: 960, loss: 0.000940440921112895
step: 970, loss: 0.033900968730449677
step: 980, loss: 0.055193942040205
step: 990, loss: 6.419149576686323e-05
step: 1000, loss: 0.0003435187099967152
step: 1010, loss: 2.265788680233527e-05
step: 1020, loss: 0.04225469380617142
step: 1030, loss: 0.002192353131249547
step: 1040, loss: 0.01594901643693447
step: 1050, loss: 1.2188979781058151e-05
step: 1060, loss: 0.040706612169742584
step: 1070, loss: 0.0001144899069913663
epoch 19: dev_f1=0.9383402874362541, f1=0.9308118081180812, best_f1=0.9282428702851886
step: 0, loss: 4.086799890501425e-05
step: 10, loss: 0.0004413818824104965
step: 20, loss: 0.023448575288057327
step: 30, loss: 0.07447602599859238
step: 40, loss: 0.00041882111690938473
step: 50, loss: 0.040583569556474686
step: 60, loss: 0.01867819018661976
step: 70, loss: 0.024347856640815735
step: 80, loss: 0.02652069553732872
step: 90, loss: 0.02252851240336895
step: 100, loss: 0.00043563920189626515
step: 110, loss: 0.023627422749996185
step: 120, loss: 0.020770840346813202
step: 130, loss: 0.031218241900205612
step: 140, loss: 0.0001084198011085391
step: 150, loss: 6.85698541929014e-05
step: 160, loss: 0.0042912717908620834
step: 170, loss: 0.0007483767112717032
step: 180, loss: 0.040653739124536514
step: 190, loss: 0.05616031214594841
step: 200, loss: 0.07397370785474777
step: 210, loss: 0.0002158319839509204
step: 220, loss: 0.031954698264598846
step: 230, loss: 0.0190195944160223
step: 240, loss: 0.02794715389609337
step: 250, loss: 0.0009419465204700828
step: 260, loss: 0.04502695053815842
step: 270, loss: 0.03673473373055458
step: 280, loss: 4.942633677273989e-05
step: 290, loss: 0.0734013095498085
step: 300, loss: 0.011166699230670929
step: 310, loss: 0.020205166190862656
step: 320, loss: 0.0514741875231266
step: 330, loss: 3.7795536627527326e-05
step: 340, loss: 0.05851292610168457
step: 350, loss: 0.009789093397557735
step: 360, loss: 0.00014592381194233894
step: 370, loss: 0.00014171040675137192
step: 380, loss: 0.0006196616450324655
step: 390, loss: 0.04437241330742836
step: 400, loss: 9.588890679879114e-05
step: 410, loss: 0.07403799891471863
step: 420, loss: 0.019485464319586754
step: 430, loss: 0.004432681016623974
step: 440, loss: 0.07388922572135925
step: 450, loss: 0.027542313560843468
step: 460, loss: 0.035455942153930664
step: 470, loss: 0.006226855795830488
step: 480, loss: 0.014241266995668411
step: 490, loss: 0.017429297789931297
step: 500, loss: 0.05945310369133949
step: 510, loss: 0.06000066548585892
step: 520, loss: 0.02078106999397278
step: 530, loss: 0.08672979474067688
step: 540, loss: 0.03298784792423248
step: 550, loss: 0.22939762473106384
step: 560, loss: 5.7419558288529515e-05
step: 570, loss: 0.037805601954460144
step: 580, loss: 0.02150443010032177
step: 590, loss: 0.012035038322210312
step: 600, loss: 0.006376023404300213
step: 610, loss: 1.3932378351455554e-05
step: 620, loss: 0.04566726088523865
step: 630, loss: 0.021467333659529686
step: 640, loss: 0.021923208609223366
step: 650, loss: 0.020488232374191284
step: 660, loss: 0.04554252699017525
step: 670, loss: 0.0006392160430550575
step: 680, loss: 0.025876447558403015
step: 690, loss: 2.5180785087286495e-05
step: 700, loss: 1.8994467609445564e-05
step: 710, loss: 3.1569943530485034e-05
step: 720, loss: 0.06135684624314308
step: 730, loss: 0.029731793329119682
step: 740, loss: 3.534784627845511e-05
step: 750, loss: 0.0001692289806669578
step: 760, loss: 0.02018793672323227
step: 770, loss: 2.1917794583714567e-05
step: 780, loss: 0.04994446411728859
step: 790, loss: 0.027162600308656693
step: 800, loss: 2.5764995370991528e-05
step: 810, loss: 0.03618067875504494
step: 820, loss: 0.10632841289043427
step: 830, loss: 0.009530308656394482
step: 840, loss: 1.1667439139273483e-05
step: 850, loss: 3.3405765861971304e-05
step: 860, loss: 0.07077792286872864
step: 870, loss: 0.05271124467253685
step: 880, loss: 0.014122596941888332
step: 890, loss: 0.0685276985168457
step: 900, loss: 0.000571407494135201
step: 910, loss: 0.01766226813197136
step: 920, loss: 0.021818913519382477
step: 930, loss: 0.0713263601064682
step: 940, loss: 0.029456354677677155
step: 950, loss: 0.04043056070804596
step: 960, loss: 0.06673948466777802
step: 970, loss: 0.0006376300589181483
step: 980, loss: 0.04362231120467186
step: 990, loss: 0.03400431573390961
step: 1000, loss: 0.019171662628650665
step: 1010, loss: 0.04203939437866211
step: 1020, loss: 0.04515136033296585
step: 1030, loss: 0.019578665494918823
step: 1040, loss: 0.05973653867840767
step: 1050, loss: 0.021055597811937332
step: 1060, loss: 0.05075298994779587
step: 1070, loss: 5.5578784667886794e-05
epoch 20: dev_f1=0.936470588235294, f1=0.9325842696629213, best_f1=0.9282428702851886
