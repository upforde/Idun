cuda
Device: cuda
step: 0, loss: 0.8976874351501465
step: 10, loss: 0.45171791315078735
step: 20, loss: 0.6102563738822937
step: 30, loss: 0.5784023404121399
step: 40, loss: 0.3552897274494171
step: 50, loss: 0.31113532185554504
step: 60, loss: 0.2157643884420395
step: 70, loss: 0.14389705657958984
step: 80, loss: 0.04347330704331398
step: 90, loss: 0.27942955493927
step: 100, loss: 0.15507757663726807
step: 110, loss: 0.21862821280956268
step: 120, loss: 0.23900087177753448
step: 130, loss: 0.22649721801280975
step: 140, loss: 0.05803180858492851
step: 150, loss: 0.11817304790019989
step: 160, loss: 0.19739565253257751
step: 170, loss: 0.22595864534378052
step: 180, loss: 0.03899114206433296
step: 190, loss: 0.08077386766672134
step: 200, loss: 0.08468874543905258
step: 210, loss: 0.13522747159004211
step: 220, loss: 0.14448799192905426
step: 230, loss: 0.06490463763475418
step: 240, loss: 0.13423770666122437
step: 250, loss: 0.09252718091011047
step: 260, loss: 0.1286018043756485
step: 270, loss: 0.03484557196497917
step: 280, loss: 0.05251803621649742
step: 290, loss: 0.14427770674228668
step: 300, loss: 0.1509445607662201
step: 310, loss: 0.06527141481637955
step: 320, loss: 0.25102856755256653
step: 330, loss: 0.12325508892536163
step: 340, loss: 0.2768721878528595
step: 350, loss: 0.12586158514022827
step: 360, loss: 0.13467197120189667
step: 370, loss: 0.3227290213108063
step: 380, loss: 0.21439458429813385
step: 390, loss: 0.22749467194080353
step: 400, loss: 0.10031091421842575
step: 410, loss: 0.12633851170539856
step: 420, loss: 0.20702025294303894
step: 430, loss: 0.15062931180000305
step: 440, loss: 0.10469835996627808
step: 450, loss: 0.12997055053710938
step: 460, loss: 0.3493952751159668
step: 470, loss: 0.12475862354040146
step: 480, loss: 0.08420509845018387
step: 490, loss: 0.07930845022201538
step: 500, loss: 0.056001510471105576
step: 510, loss: 0.052877962589263916
step: 520, loss: 0.029297245666384697
step: 530, loss: 0.028299905359745026
step: 540, loss: 0.2809847593307495
step: 550, loss: 0.09749735891819
step: 560, loss: 0.14350497722625732
step: 570, loss: 0.09619642049074173
step: 580, loss: 0.07037871330976486
step: 590, loss: 0.06860572844743729
step: 600, loss: 0.24223321676254272
step: 610, loss: 0.13289383053779602
step: 620, loss: 0.18161490559577942
step: 630, loss: 0.10012663900852203
step: 640, loss: 0.05865985155105591
step: 650, loss: 0.09166624397039413
step: 660, loss: 0.02002631314098835
step: 670, loss: 0.04571276530623436
step: 680, loss: 0.13896024227142334
step: 690, loss: 0.03497017174959183
step: 700, loss: 0.1322452872991562
step: 710, loss: 0.1804739385843277
step: 720, loss: 0.04569898173213005
step: 730, loss: 0.08950074762105942
step: 740, loss: 0.05351508408784866
step: 750, loss: 0.10519523918628693
step: 760, loss: 0.11609575897455215
step: 770, loss: 0.0653393343091011
step: 780, loss: 0.1523655652999878
step: 790, loss: 0.10131145268678665
step: 800, loss: 0.1564389318227768
step: 810, loss: 0.12119009345769882
step: 820, loss: 0.031080657616257668
step: 830, loss: 0.06876322627067566
step: 840, loss: 0.07093490660190582
step: 850, loss: 0.017912741750478745
step: 860, loss: 0.09749604761600494
step: 870, loss: 0.1773078441619873
step: 880, loss: 0.22822025418281555
step: 890, loss: 0.12711061537265778
step: 900, loss: 0.074334517121315
step: 910, loss: 0.21399301290512085
step: 920, loss: 0.10719981044530869
step: 930, loss: 0.08634477108716965
step: 940, loss: 0.03866102546453476
step: 950, loss: 0.013510878197848797
step: 960, loss: 0.07681386917829514
step: 970, loss: 0.12682639062404633
step: 980, loss: 0.07612261921167374
step: 990, loss: 0.041301365941762924
step: 1000, loss: 0.026447219774127007
step: 1010, loss: 0.22766269743442535
step: 1020, loss: 0.049488335847854614
step: 1030, loss: 0.3344324231147766
step: 1040, loss: 0.0862230509519577
step: 1050, loss: 0.050001103430986404
step: 1060, loss: 0.0911804810166359
step: 1070, loss: 0.16312997043132782
epoch 1: dev_f1=0.9293302540415704, f1=0.9304029304029303, best_f1=0.9304029304029303
step: 0, loss: 0.16910862922668457
step: 10, loss: 0.05015401542186737
step: 20, loss: 0.11070837080478668
step: 30, loss: 0.11376731842756271
step: 40, loss: 0.026669234037399292
step: 50, loss: 0.03904710337519646
step: 60, loss: 0.1119602844119072
step: 70, loss: 0.0730152502655983
step: 80, loss: 0.35389113426208496
step: 90, loss: 0.0739017203450203
step: 100, loss: 0.08058975636959076
step: 110, loss: 0.10966113954782486
step: 120, loss: 0.10100213438272476
step: 130, loss: 0.037926603108644485
step: 140, loss: 0.0812365785241127
step: 150, loss: 0.08920885622501373
step: 160, loss: 0.16535980999469757
step: 170, loss: 0.09313119947910309
step: 180, loss: 0.13578486442565918
step: 190, loss: 0.03889743238687515
step: 200, loss: 0.036486729979515076
step: 210, loss: 0.028025895357131958
step: 220, loss: 0.07449755817651749
step: 230, loss: 0.11772575229406357
step: 240, loss: 0.029362112283706665
step: 250, loss: 0.22548912465572357
step: 260, loss: 0.07538004964590073
step: 270, loss: 0.01959516853094101
step: 280, loss: 0.1901981085538864
step: 290, loss: 0.049724649637937546
step: 300, loss: 0.06779727339744568
step: 310, loss: 0.03270421177148819
step: 320, loss: 0.09543679654598236
step: 330, loss: 0.12857702374458313
step: 340, loss: 0.1243436262011528
step: 350, loss: 0.05898549035191536
step: 360, loss: 0.13693270087242126
step: 370, loss: 0.07166849821805954
step: 380, loss: 0.1105305626988411
step: 390, loss: 0.1427428126335144
step: 400, loss: 0.06322015821933746
step: 410, loss: 0.05551578849554062
step: 420, loss: 0.15643690526485443
step: 430, loss: 0.047201208770275116
step: 440, loss: 0.2929179072380066
step: 450, loss: 0.13903777301311493
step: 460, loss: 0.06126396358013153
step: 470, loss: 0.23306162655353546
step: 480, loss: 0.15406771004199982
step: 490, loss: 0.17945772409439087
step: 500, loss: 0.18199187517166138
step: 510, loss: 0.036620981991291046
step: 520, loss: 0.05640418455004692
step: 530, loss: 0.08034224063158035
step: 540, loss: 0.21271264553070068
step: 550, loss: 0.08208811283111572
step: 560, loss: 0.09257223457098007
step: 570, loss: 0.071413055062294
step: 580, loss: 0.1262485831975937
step: 590, loss: 0.05970216169953346
step: 600, loss: 0.14514882862567902
step: 610, loss: 0.242863729596138
step: 620, loss: 0.11969251185655594
step: 630, loss: 0.027621790766716003
step: 640, loss: 0.17824427783489227
step: 650, loss: 0.047882772982120514
step: 660, loss: 0.03135034441947937
step: 670, loss: 0.11764416098594666
step: 680, loss: 0.1199997216463089
step: 690, loss: 0.12533797323703766
step: 700, loss: 0.1552540510892868
step: 710, loss: 0.0910855084657669
step: 720, loss: 0.15953266620635986
step: 730, loss: 0.10498655587434769
step: 740, loss: 0.10297633707523346
step: 750, loss: 0.1236792728304863
step: 760, loss: 0.11542435735464096
step: 770, loss: 0.03164692223072052
step: 780, loss: 0.0438712015748024
step: 790, loss: 0.03942609950900078
step: 800, loss: 0.16560903191566467
step: 810, loss: 0.08776376396417618
step: 820, loss: 0.10175525397062302
step: 830, loss: 0.03453715890645981
step: 840, loss: 0.05336131155490875
step: 850, loss: 0.1157686784863472
step: 860, loss: 0.020613761618733406
step: 870, loss: 0.21249140799045563
step: 880, loss: 0.1359172910451889
step: 890, loss: 0.07351366430521011
step: 900, loss: 0.1357661485671997
step: 910, loss: 0.07203447818756104
step: 920, loss: 0.026436150074005127
step: 930, loss: 0.16132035851478577
step: 940, loss: 0.07630158215761185
step: 950, loss: 0.11736387014389038
step: 960, loss: 0.12663088738918304
step: 970, loss: 0.18678055703639984
step: 980, loss: 0.02024082839488983
step: 990, loss: 0.12195988744497299
step: 1000, loss: 0.17144520580768585
step: 1010, loss: 0.043212730437517166
step: 1020, loss: 0.08868244290351868
step: 1030, loss: 0.03656809777021408
step: 1040, loss: 0.15617144107818604
step: 1050, loss: 0.11829955130815506
step: 1060, loss: 0.0659601166844368
step: 1070, loss: 0.12287771701812744
epoch 2: dev_f1=0.9320297951582867, f1=0.9304467987102718, best_f1=0.9304467987102718
step: 0, loss: 0.11947730928659439
step: 10, loss: 0.06535951048135757
step: 20, loss: 0.0319189578294754
step: 30, loss: 0.215201273560524
step: 40, loss: 0.07063242048025131
step: 50, loss: 0.07790903747081757
step: 60, loss: 0.11433421820402145
step: 70, loss: 0.1078837588429451
step: 80, loss: 0.11066149175167084
step: 90, loss: 0.07258051633834839
step: 100, loss: 0.042913489043712616
step: 110, loss: 0.04329609125852585
step: 120, loss: 0.05119018629193306
step: 130, loss: 0.08725021779537201
step: 140, loss: 0.07411648333072662
step: 150, loss: 0.10120748728513718
step: 160, loss: 0.11023872345685959
step: 170, loss: 0.09412619471549988
step: 180, loss: 0.06971434503793716
step: 190, loss: 0.022643979638814926
step: 200, loss: 0.12275338917970657
step: 210, loss: 0.027747567743062973
step: 220, loss: 0.19030728936195374
step: 230, loss: 0.01607920415699482
step: 240, loss: 0.040347445756196976
step: 250, loss: 0.042723845690488815
step: 260, loss: 0.026569845154881477
step: 270, loss: 0.07069677114486694
step: 280, loss: 0.023450132459402084
step: 290, loss: 0.0037815463729202747
step: 300, loss: 0.020263968035578728
step: 310, loss: 0.08111875504255295
step: 320, loss: 0.010449416004121304
step: 330, loss: 0.08143747597932816
step: 340, loss: 0.04271212965250015
step: 350, loss: 0.14562372863292694
step: 360, loss: 0.04857223480939865
step: 370, loss: 0.10209987312555313
step: 380, loss: 0.12776026129722595
step: 390, loss: 0.08858069777488708
step: 400, loss: 0.03522563725709915
step: 410, loss: 0.06133173778653145
step: 420, loss: 0.0423862487077713
step: 430, loss: 0.02530207298696041
step: 440, loss: 0.06525014340877533
step: 450, loss: 0.009193236008286476
step: 460, loss: 0.0693933367729187
step: 470, loss: 0.04503519833087921
step: 480, loss: 0.029676320031285286
step: 490, loss: 0.0294652096927166
step: 500, loss: 0.02272706665098667
step: 510, loss: 0.046427395194768906
step: 520, loss: 0.11911197751760483
step: 530, loss: 0.13034968078136444
step: 540, loss: 0.0858929231762886
step: 550, loss: 0.19491833448410034
step: 560, loss: 0.02047007903456688
step: 570, loss: 0.15417325496673584
step: 580, loss: 0.05851674824953079
step: 590, loss: 0.0013375497655943036
step: 600, loss: 0.14374323189258575
step: 610, loss: 0.08735252171754837
step: 620, loss: 0.05887584388256073
step: 630, loss: 0.2216428816318512
step: 640, loss: 0.08143726736307144
step: 650, loss: 0.0530967190861702
step: 660, loss: 0.021328041329979897
step: 670, loss: 0.13267385959625244
step: 680, loss: 0.048897840082645416
step: 690, loss: 0.03268946707248688
step: 700, loss: 0.04191175848245621
step: 710, loss: 0.052645936608314514
step: 720, loss: 0.16080723702907562
step: 730, loss: 0.0623309463262558
step: 740, loss: 0.055658359080553055
step: 750, loss: 0.08600093424320221
step: 760, loss: 0.08513572067022324
step: 770, loss: 0.060577306896448135
step: 780, loss: 0.010364210233092308
step: 790, loss: 0.0036556089762598276
step: 800, loss: 0.13169270753860474
step: 810, loss: 0.01468795258551836
step: 820, loss: 0.048603449016809464
step: 830, loss: 0.03776242583990097
step: 840, loss: 0.07841774076223373
step: 850, loss: 0.19876103103160858
step: 860, loss: 0.22437021136283875
step: 870, loss: 0.14103540778160095
step: 880, loss: 0.08803823590278625
step: 890, loss: 0.06858573853969574
step: 900, loss: 0.012770961970090866
step: 910, loss: 0.07455507665872574
step: 920, loss: 0.06450548768043518
step: 930, loss: 0.11844822764396667
step: 940, loss: 0.08274423331022263
step: 950, loss: 0.06452346593141556
step: 960, loss: 0.2902003824710846
step: 970, loss: 0.01401742734014988
step: 980, loss: 0.10587544739246368
step: 990, loss: 0.14164064824581146
step: 1000, loss: 0.08320081233978271
step: 1010, loss: 0.22129929065704346
step: 1020, loss: 0.0865728035569191
step: 1030, loss: 0.09984052926301956
step: 1040, loss: 0.13012021780014038
step: 1050, loss: 0.02940056286752224
step: 1060, loss: 0.05598137155175209
step: 1070, loss: 0.030256222933530807
epoch 3: dev_f1=0.9440145653163405, f1=0.9319419237749547, best_f1=0.9319419237749547
step: 0, loss: 0.0878845751285553
step: 10, loss: 0.01274402067065239
step: 20, loss: 0.015618087723851204
step: 30, loss: 0.07305463403463364
step: 40, loss: 0.05956323817372322
step: 50, loss: 0.03075331263244152
step: 60, loss: 0.01586795039474964
step: 70, loss: 0.044495418667793274
step: 80, loss: 0.06977533549070358
step: 90, loss: 0.0932256206870079
step: 100, loss: 0.09983855485916138
step: 110, loss: 0.06282022595405579
step: 120, loss: 0.02845468930900097
step: 130, loss: 0.03456975519657135
step: 140, loss: 0.06794460862874985
step: 150, loss: 0.0774657353758812
step: 160, loss: 0.11261016130447388
step: 170, loss: 0.0645177960395813
step: 180, loss: 0.05121427774429321
step: 190, loss: 0.10257036238908768
step: 200, loss: 0.053355634212493896
step: 210, loss: 0.08921489864587784
step: 220, loss: 0.03206004947423935
step: 230, loss: 0.055912744253873825
step: 240, loss: 0.01714618317782879
step: 250, loss: 0.07847695797681808
step: 260, loss: 0.026069967076182365
step: 270, loss: 0.07001791149377823
step: 280, loss: 0.14037615060806274
step: 290, loss: 0.005991502199321985
step: 300, loss: 0.020655807107686996
step: 310, loss: 0.11524435877799988
step: 320, loss: 0.08353595435619354
step: 330, loss: 0.13554374873638153
step: 340, loss: 0.03708112984895706
step: 350, loss: 0.10155796259641647
step: 360, loss: 0.08570713549852371
step: 370, loss: 0.0547388419508934
step: 380, loss: 0.04775208234786987
step: 390, loss: 0.01952694170176983
step: 400, loss: 0.007570050191134214
step: 410, loss: 0.010463830083608627
step: 420, loss: 0.0028860862366855145
step: 430, loss: 0.014260771684348583
step: 440, loss: 0.04894667863845825
step: 450, loss: 0.1092149168252945
step: 460, loss: 0.015154426917433739
step: 470, loss: 0.1318766325712204
step: 480, loss: 0.026788340881466866
step: 490, loss: 0.1238793283700943
step: 500, loss: 0.0357900895178318
step: 510, loss: 0.16203932464122772
step: 520, loss: 0.05426986142992973
step: 530, loss: 0.08454018831253052
step: 540, loss: 0.04462571442127228
step: 550, loss: 0.11071883141994476
step: 560, loss: 0.13223320245742798
step: 570, loss: 0.07150977849960327
step: 580, loss: 0.0793273076415062
step: 590, loss: 0.20027950406074524
step: 600, loss: 0.019641416147351265
step: 610, loss: 0.04959454387426376
step: 620, loss: 0.028951197862625122
step: 630, loss: 0.05445188283920288
step: 640, loss: 0.04466331750154495
step: 650, loss: 0.010561401955783367
step: 660, loss: 0.13509708642959595
step: 670, loss: 0.1396971344947815
step: 680, loss: 0.07484189420938492
step: 690, loss: 0.13564451038837433
step: 700, loss: 0.0031136616598814726
step: 710, loss: 0.087000273168087
step: 720, loss: 0.060099177062511444
step: 730, loss: 0.02198784612119198
step: 740, loss: 0.014190064743161201
step: 750, loss: 0.025220632553100586
step: 760, loss: 0.05480955168604851
step: 770, loss: 0.029882123693823814
step: 780, loss: 0.02880825288593769
step: 790, loss: 0.3443859815597534
step: 800, loss: 0.14723636209964752
step: 810, loss: 0.1470327377319336
step: 820, loss: 0.135077103972435
step: 830, loss: 0.15191814303398132
step: 840, loss: 0.08665632456541061
step: 850, loss: 0.0563194565474987
step: 860, loss: 0.0242649894207716
step: 870, loss: 0.15947325527668
step: 880, loss: 0.017509741708636284
step: 890, loss: 0.0004887996474280953
step: 900, loss: 0.010347033850848675
step: 910, loss: 0.03079565055668354
step: 920, loss: 0.19101855158805847
step: 930, loss: 0.08310764282941818
step: 940, loss: 0.019707564264535904
step: 950, loss: 0.18564245104789734
step: 960, loss: 0.13980363309383392
step: 970, loss: 0.01594274304807186
step: 980, loss: 0.02871795929968357
step: 990, loss: 0.05824671685695648
step: 1000, loss: 0.14476744830608368
step: 1010, loss: 0.0021337915677577257
step: 1020, loss: 0.06268473714590073
step: 1030, loss: 0.008207817561924458
step: 1040, loss: 0.07338346540927887
step: 1050, loss: 0.17007319629192352
step: 1060, loss: 0.06782745569944382
step: 1070, loss: 0.029350033029913902
epoch 4: dev_f1=0.9393090569561158, f1=0.9270784951230839, best_f1=0.9319419237749547
step: 0, loss: 0.08215964585542679
step: 10, loss: 0.10020969808101654
step: 20, loss: 0.08752557635307312
step: 30, loss: 0.01357496902346611
step: 40, loss: 0.03327682614326477
step: 50, loss: 0.10933427512645721
step: 60, loss: 0.012953906320035458
step: 70, loss: 0.06563948094844818
step: 80, loss: 0.07757081836462021
step: 90, loss: 0.09231546521186829
step: 100, loss: 0.017305821180343628
step: 110, loss: 0.006836645305156708
step: 120, loss: 0.013808412477374077
step: 130, loss: 0.026621557772159576
step: 140, loss: 0.05981019139289856
step: 150, loss: 0.06042841821908951
step: 160, loss: 0.0310509093105793
step: 170, loss: 0.05272115021944046
step: 180, loss: 0.005141017027199268
step: 190, loss: 0.019452985376119614
step: 200, loss: 0.12092651426792145
step: 210, loss: 0.035922545939683914
step: 220, loss: 0.02307245135307312
step: 230, loss: 0.07004348933696747
step: 240, loss: 0.02728903479874134
step: 250, loss: 0.08271308243274689
step: 260, loss: 0.00860151182860136
step: 270, loss: 0.014221844263374805
step: 280, loss: 0.04040227457880974
step: 290, loss: 0.00905890204012394
step: 300, loss: 0.20725660026073456
step: 310, loss: 0.002894847420975566
step: 320, loss: 0.014223316684365273
step: 330, loss: 0.11102313548326492
step: 340, loss: 0.026146970689296722
step: 350, loss: 0.0023390904534608126
step: 360, loss: 0.16585278511047363
step: 370, loss: 0.030416924506425858
step: 380, loss: 0.04825267195701599
step: 390, loss: 0.1181148961186409
step: 400, loss: 0.04947330057621002
step: 410, loss: 0.11127698421478271
step: 420, loss: 0.06782513111829758
step: 430, loss: 0.022879021242260933
step: 440, loss: 0.11062490195035934
step: 450, loss: 0.10533753037452698
step: 460, loss: 0.07817996293306351
step: 470, loss: 0.003730139695107937
step: 480, loss: 0.06803335249423981
step: 490, loss: 0.16562148928642273
step: 500, loss: 0.14925415813922882
step: 510, loss: 0.11506924033164978
step: 520, loss: 0.04092353582382202
step: 530, loss: 0.09057565778493881
step: 540, loss: 0.07797661423683167
step: 550, loss: 0.10225974768400192
step: 560, loss: 0.040496569126844406
step: 570, loss: 0.010369106195867062
step: 580, loss: 0.011311383917927742
step: 590, loss: 0.05859209597110748
step: 600, loss: 0.05997135490179062
step: 610, loss: 0.07245364785194397
step: 620, loss: 0.019975459203124046
step: 630, loss: 0.05931686609983444
step: 640, loss: 0.2029068022966385
step: 650, loss: 0.018897492438554764
step: 660, loss: 0.0601416751742363
step: 670, loss: 0.07081674039363861
step: 680, loss: 0.083600252866745
step: 690, loss: 0.06924669444561005
step: 700, loss: 0.07813135534524918
step: 710, loss: 0.013159174472093582
step: 720, loss: 0.12958210706710815
step: 730, loss: 0.15297777950763702
step: 740, loss: 0.017776187509298325
step: 750, loss: 0.03870886191725731
step: 760, loss: 0.03122154250741005
step: 770, loss: 0.08644081652164459
step: 780, loss: 0.06937529891729355
step: 790, loss: 0.028565501794219017
step: 800, loss: 0.11746244877576828
step: 810, loss: 0.07773581147193909
step: 820, loss: 0.10269716382026672
step: 830, loss: 0.08164749294519424
step: 840, loss: 0.07643131166696548
step: 850, loss: 0.07574531435966492
step: 860, loss: 0.059352975338697433
step: 870, loss: 0.13089531660079956
step: 880, loss: 0.05393518507480621
step: 890, loss: 0.06782161444425583
step: 900, loss: 0.126854807138443
step: 910, loss: 0.12587107717990875
step: 920, loss: 0.06736598908901215
step: 930, loss: 0.13635492324829102
step: 940, loss: 0.05952683836221695
step: 950, loss: 0.0635995864868164
step: 960, loss: 0.03207775205373764
step: 970, loss: 0.17466136813163757
step: 980, loss: 0.16535033285617828
step: 990, loss: 0.011255593039095402
step: 1000, loss: 0.059236735105514526
step: 1010, loss: 0.13636159896850586
step: 1020, loss: 0.1477096974849701
step: 1030, loss: 0.05105873942375183
step: 1040, loss: 0.003388278651982546
step: 1050, loss: 0.016387978568673134
step: 1060, loss: 0.11885706335306168
step: 1070, loss: 0.17024844884872437
epoch 5: dev_f1=0.9437070938215102, f1=0.9338842975206612, best_f1=0.9319419237749547
step: 0, loss: 0.24886739253997803
step: 10, loss: 0.16339293122291565
step: 20, loss: 0.02656594291329384
step: 30, loss: 0.0234361719340086
step: 40, loss: 0.032531481236219406
step: 50, loss: 0.0556524395942688
step: 60, loss: 0.010175065137445927
step: 70, loss: 0.029763666912913322
step: 80, loss: 0.01323210634291172
step: 90, loss: 0.00662495382130146
step: 100, loss: 0.17763395607471466
step: 110, loss: 0.006460798904299736
step: 120, loss: 0.022931495681405067
step: 130, loss: 0.017089327797293663
step: 140, loss: 0.038205742835998535
step: 150, loss: 0.07105899602174759
step: 160, loss: 0.03459868207573891
step: 170, loss: 0.022075718268752098
step: 180, loss: 0.010339854285120964
step: 190, loss: 0.02169768325984478
step: 200, loss: 0.014599049463868141
step: 210, loss: 0.057792797684669495
step: 220, loss: 0.08763150125741959
step: 230, loss: 0.1322403997182846
step: 240, loss: 0.02521398849785328
step: 250, loss: 0.14942128956317902
step: 260, loss: 0.05909695848822594
step: 270, loss: 0.05010407045483589
step: 280, loss: 0.06025219336152077
step: 290, loss: 0.07433963567018509
step: 300, loss: 0.0015443675220012665
step: 310, loss: 0.010666387155652046
step: 320, loss: 0.03660116344690323
step: 330, loss: 0.10374566912651062
step: 340, loss: 0.09940272569656372
step: 350, loss: 0.008916099555790424
step: 360, loss: 0.09351710975170135
step: 370, loss: 0.014335904270410538
step: 380, loss: 0.0459514781832695
step: 390, loss: 0.09289082139730453
step: 400, loss: 0.08075287193059921
step: 410, loss: 0.05933024361729622
step: 420, loss: 0.010771015658974648
step: 430, loss: 0.031890708953142166
step: 440, loss: 0.2010265588760376
step: 450, loss: 0.029335662722587585
step: 460, loss: 0.0846845731139183
step: 470, loss: 0.1381426304578781
step: 480, loss: 0.1237129345536232
step: 490, loss: 0.015980754047632217
step: 500, loss: 0.029946856200695038
step: 510, loss: 0.11659013479948044
step: 520, loss: 0.025390446186065674
step: 530, loss: 0.08885656297206879
step: 540, loss: 0.016307635232806206
step: 550, loss: 0.05520365759730339
step: 560, loss: 0.08600248396396637
step: 570, loss: 0.13263025879859924
step: 580, loss: 0.032873619347810745
step: 590, loss: 0.012853126972913742
step: 600, loss: 0.07633868604898453
step: 610, loss: 0.011269462294876575
step: 620, loss: 0.018867217004299164
step: 630, loss: 0.1454954296350479
step: 640, loss: 0.14350689947605133
step: 650, loss: 0.09218710660934448
step: 660, loss: 0.07253667712211609
step: 670, loss: 0.031779177486896515
step: 680, loss: 0.05584384500980377
step: 690, loss: 0.07697683572769165
step: 700, loss: 0.07353340834379196
step: 710, loss: 0.06027420982718468
step: 720, loss: 0.014331375248730183
step: 730, loss: 0.087684266269207
step: 740, loss: 0.018020199611783028
step: 750, loss: 0.038734130561351776
step: 760, loss: 0.07287617772817612
step: 770, loss: 0.16865666210651398
step: 780, loss: 0.0025529428385198116
step: 790, loss: 0.015903441235423088
step: 800, loss: 0.02339833974838257
step: 810, loss: 0.03952744975686073
step: 820, loss: 0.059995897114276886
step: 830, loss: 0.04312539100646973
step: 840, loss: 0.061490148305892944
step: 850, loss: 0.13695767521858215
step: 860, loss: 0.03407915681600571
step: 870, loss: 0.03305599465966225
step: 880, loss: 0.0436013825237751
step: 890, loss: 0.0980038270354271
step: 900, loss: 0.22864840924739838
step: 910, loss: 0.012007146142423153
step: 920, loss: 0.06075626239180565
step: 930, loss: 0.05360320582985878
step: 940, loss: 0.11305955797433853
step: 950, loss: 0.02599315345287323
step: 960, loss: 0.016584379598498344
step: 970, loss: 0.15253998339176178
step: 980, loss: 0.06075538694858551
step: 990, loss: 0.07354703545570374
step: 1000, loss: 0.08106919378042221
step: 1010, loss: 0.031183451414108276
step: 1020, loss: 0.034195397049188614
step: 1030, loss: 0.0442996621131897
step: 1040, loss: 0.09010626375675201
step: 1050, loss: 0.09721887111663818
step: 1060, loss: 5.414331826614216e-05
step: 1070, loss: 0.030230384320020676
epoch 6: dev_f1=0.93646408839779, f1=0.9336405529953917, best_f1=0.9319419237749547
step: 0, loss: 0.058050382882356644
step: 10, loss: 0.09171130508184433
step: 20, loss: 0.06385637819766998
step: 30, loss: 0.0376235768198967
step: 40, loss: 0.05809752643108368
step: 50, loss: 0.01300574466586113
step: 60, loss: 0.043224964290857315
step: 70, loss: 0.09594884514808655
step: 80, loss: 0.10260003060102463
step: 90, loss: 0.010237997397780418
step: 100, loss: 0.18564751744270325
step: 110, loss: 0.10683645308017731
step: 120, loss: 0.004985784646123648
step: 130, loss: 0.03751622140407562
step: 140, loss: 0.06343571841716766
step: 150, loss: 0.06449554860591888
step: 160, loss: 0.06226132810115814
step: 170, loss: 0.08454553782939911
step: 180, loss: 0.13142360746860504
step: 190, loss: 0.028531339019536972
step: 200, loss: 0.0213718730956316
step: 210, loss: 0.06391320377588272
step: 220, loss: 0.06632908433675766
step: 230, loss: 0.014710938557982445
step: 240, loss: 0.011699389666318893
step: 250, loss: 0.011318850331008434
step: 260, loss: 0.05992598086595535
step: 270, loss: 0.05288059264421463
step: 280, loss: 0.0315539613366127
step: 290, loss: 0.042922306805849075
step: 300, loss: 0.03740701079368591
step: 310, loss: 0.04242919757962227
step: 320, loss: 0.01562432013452053
step: 330, loss: 0.04399922490119934
step: 340, loss: 0.01663215458393097
step: 350, loss: 0.06867597997188568
step: 360, loss: 0.02467995323240757
step: 370, loss: 0.14806227385997772
step: 380, loss: 0.056228961795568466
step: 390, loss: 0.05318908393383026
step: 400, loss: 0.15193358063697815
step: 410, loss: 0.10724955052137375
step: 420, loss: 0.024989601224660873
step: 430, loss: 0.11160538345575333
step: 440, loss: 0.051922351121902466
step: 450, loss: 0.060827434062957764
step: 460, loss: 0.06900391727685928
step: 470, loss: 0.0029975930228829384
step: 480, loss: 0.07381953299045563
step: 490, loss: 0.05039273947477341
step: 500, loss: 0.014243604615330696
step: 510, loss: 0.0735945999622345
step: 520, loss: 0.02305643819272518
step: 530, loss: 0.093034528195858
step: 540, loss: 0.0699678584933281
step: 550, loss: 0.05612225830554962
step: 560, loss: 0.11648577451705933
step: 570, loss: 0.10305242240428925
step: 580, loss: 0.08775270730257034
step: 590, loss: 0.0519220195710659
step: 600, loss: 0.021230123937129974
step: 610, loss: 0.0008357512997463346
step: 620, loss: 0.018150754272937775
step: 630, loss: 0.018572045490145683
step: 640, loss: 0.008060766384005547
step: 650, loss: 0.011263067834079266
step: 660, loss: 0.014254622161388397
step: 670, loss: 0.06872053444385529
step: 680, loss: 0.008680197410285473
step: 690, loss: 0.06720580905675888
step: 700, loss: 0.012027324177324772
step: 710, loss: 0.05125537887215614
step: 720, loss: 0.056331075727939606
step: 730, loss: 0.030648062005639076
step: 740, loss: 0.02135768160223961
step: 750, loss: 0.017385238781571388
step: 760, loss: 0.06332452595233917
step: 770, loss: 0.00021184966317377985
step: 780, loss: 0.00029099470702931285
step: 790, loss: 0.1287388801574707
step: 800, loss: 0.12984557449817657
step: 810, loss: 0.008124865591526031
step: 820, loss: 0.08083314448595047
step: 830, loss: 0.018045108765363693
step: 840, loss: 0.0897054374217987
step: 850, loss: 0.038999043405056
step: 860, loss: 0.023062610998749733
step: 870, loss: 0.03418495133519173
step: 880, loss: 0.03730345144867897
step: 890, loss: 0.09438088536262512
step: 900, loss: 0.11387599259614944
step: 910, loss: 0.0654001235961914
step: 920, loss: 0.009759564884006977
step: 930, loss: 0.092378169298172
step: 940, loss: 0.034985970705747604
step: 950, loss: 0.07752499729394913
step: 960, loss: 0.06710789352655411
step: 970, loss: 0.020898330956697464
step: 980, loss: 0.09835067391395569
step: 990, loss: 0.04724443331360817
step: 1000, loss: 0.04609128087759018
step: 1010, loss: 0.01516523864120245
step: 1020, loss: 0.014526905491948128
step: 1030, loss: 0.06213609501719475
step: 1040, loss: 0.022438444197177887
step: 1050, loss: 0.21095077693462372
step: 1060, loss: 0.0769326388835907
step: 1070, loss: 0.10937067866325378
epoch 7: dev_f1=0.944007403979639, f1=0.9327808471454879, best_f1=0.9319419237749547
step: 0, loss: 0.013866155408322811
step: 10, loss: 0.01657339558005333
step: 20, loss: 0.05708916485309601
step: 30, loss: 0.09861616790294647
step: 40, loss: 0.029710866510868073
step: 50, loss: 0.11719366163015366
step: 60, loss: 0.02204103395342827
step: 70, loss: 0.03070329874753952
step: 80, loss: 0.034065548330545425
step: 90, loss: 0.02013726718723774
step: 100, loss: 0.012758656404912472
step: 110, loss: 0.007274016737937927
step: 120, loss: 0.034026164561510086
step: 130, loss: 0.030087895691394806
step: 140, loss: 0.005671343766152859
step: 150, loss: 0.0012985310750082135
step: 160, loss: 0.0825970470905304
step: 170, loss: 0.09523709863424301
step: 180, loss: 0.019341813400387764
step: 190, loss: 0.0661294236779213
step: 200, loss: 0.012318000197410583
step: 210, loss: 0.018491216003894806
step: 220, loss: 0.04476592317223549
step: 230, loss: 0.005057353992015123
step: 240, loss: 0.06103161722421646
step: 250, loss: 0.003719243686646223
step: 260, loss: 0.017404235899448395
step: 270, loss: 0.016065102070569992
step: 280, loss: 0.01813020370900631
step: 290, loss: 0.17682768404483795
step: 300, loss: 0.003799730446189642
step: 310, loss: 0.06929150968790054
step: 320, loss: 0.051903948187828064
step: 330, loss: 0.07989208400249481
step: 340, loss: 0.09174922108650208
step: 350, loss: 0.07114505022764206
step: 360, loss: 0.044923778623342514
step: 370, loss: 0.031060433015227318
step: 380, loss: 0.04194827005267143
step: 390, loss: 0.009536027908325195
step: 400, loss: 0.008240513503551483
step: 410, loss: 0.009135834872722626
step: 420, loss: 0.11108654737472534
step: 430, loss: 0.12385962903499603
step: 440, loss: 0.013519072905182838
step: 450, loss: 0.061402756720781326
step: 460, loss: 0.012079738080501556
step: 470, loss: 0.005956856533885002
step: 480, loss: 0.1246829479932785
step: 490, loss: 0.005133890546858311
step: 500, loss: 0.053352151066064835
step: 510, loss: 0.04392780736088753
step: 520, loss: 0.01516105979681015
step: 530, loss: 0.058165933936834335
step: 540, loss: 0.06805139780044556
step: 550, loss: 0.07135683298110962
step: 560, loss: 0.022676169872283936
step: 570, loss: 0.008652153424918652
step: 580, loss: 0.05229886993765831
step: 590, loss: 0.03415033221244812
step: 600, loss: 0.08286111056804657
step: 610, loss: 0.04558921977877617
step: 620, loss: 0.07723768800497055
step: 630, loss: 0.013259402476251125
step: 640, loss: 0.011214193888008595
step: 650, loss: 0.010839691385626793
step: 660, loss: 0.04810317978262901
step: 670, loss: 0.12277506291866302
step: 680, loss: 0.017322584986686707
step: 690, loss: 0.181761234998703
step: 700, loss: 0.005848567467182875
step: 710, loss: 0.030079001560807228
step: 720, loss: 0.006591177545487881
step: 730, loss: 0.02520078606903553
step: 740, loss: 0.014120660722255707
step: 750, loss: 0.06806384027004242
step: 760, loss: 0.06601444631814957
step: 770, loss: 0.018678607419133186
step: 780, loss: 0.15530386567115784
step: 790, loss: 0.08535473793745041
step: 800, loss: 0.04439668357372284
step: 810, loss: 0.10360914468765259
step: 820, loss: 0.04243827611207962
step: 830, loss: 0.015734199434518814
step: 840, loss: 0.04360435530543327
step: 850, loss: 0.06483574956655502
step: 860, loss: 0.0353550910949707
step: 870, loss: 0.05223160609602928
step: 880, loss: 0.0027889113407582045
step: 890, loss: 0.03808624669909477
step: 900, loss: 0.10658150166273117
step: 910, loss: 0.017406374216079712
step: 920, loss: 0.017209619283676147
step: 930, loss: 0.027409564703702927
step: 940, loss: 0.006806753575801849
step: 950, loss: 0.004947078414261341
step: 960, loss: 0.0032585831359028816
step: 970, loss: 0.023663677275180817
step: 980, loss: 0.27985939383506775
step: 990, loss: 0.01866205595433712
step: 1000, loss: 0.1904933601617813
step: 1010, loss: 0.08329693973064423
step: 1020, loss: 0.02398030273616314
step: 1030, loss: 0.022559277713298798
step: 1040, loss: 0.03262085095047951
step: 1050, loss: 0.10242590308189392
step: 1060, loss: 0.009480191394686699
step: 1070, loss: 0.04759941250085831
epoch 8: dev_f1=0.9368616527390901, f1=0.9357374017568193, best_f1=0.9319419237749547
step: 0, loss: 0.06808215379714966
step: 10, loss: 0.07341672480106354
step: 20, loss: 0.013534472323954105
step: 30, loss: 0.027432620525360107
step: 40, loss: 0.12223769724369049
step: 50, loss: 0.14094489812850952
step: 60, loss: 0.011497629806399345
step: 70, loss: 0.00683195423334837
step: 80, loss: 0.018528982996940613
step: 90, loss: 0.061198145151138306
step: 100, loss: 0.0010727111948654056
step: 110, loss: 0.018603939563035965
step: 120, loss: 0.12985385954380035
step: 130, loss: 0.01643790677189827
step: 140, loss: 0.03526660427451134
step: 150, loss: 0.04930822551250458
step: 160, loss: 0.0670924112200737
step: 170, loss: 0.08666760474443436
step: 180, loss: 0.05081125348806381
step: 190, loss: 0.019844431430101395
step: 200, loss: 0.11158658564090729
step: 210, loss: 0.010257619433104992
step: 220, loss: 0.039724308997392654
step: 230, loss: 0.00907316617667675
step: 240, loss: 0.05910593271255493
step: 250, loss: 0.015710679814219475
step: 260, loss: 0.09189154207706451
step: 270, loss: 0.05515236034989357
step: 280, loss: 0.06891950964927673
step: 290, loss: 0.020132338628172874
step: 300, loss: 0.42717206478118896
step: 310, loss: 0.024854907765984535
step: 320, loss: 0.06643389165401459
step: 330, loss: 0.06165684014558792
step: 340, loss: 0.08713976293802261
step: 350, loss: 0.023260658606886864
step: 360, loss: 0.032485973089933395
step: 370, loss: 0.01964816264808178
step: 380, loss: 0.03038242645561695
step: 390, loss: 0.026485059410333633
step: 400, loss: 0.05417395383119583
step: 410, loss: 0.006614213809370995
step: 420, loss: 0.10365234315395355
step: 430, loss: 0.038518026471138
step: 440, loss: 0.10364583879709244
step: 450, loss: 0.012492355890572071
step: 460, loss: 0.06043776124715805
step: 470, loss: 0.009498406201601028
step: 480, loss: 0.05323581025004387
step: 490, loss: 0.02173316292464733
step: 500, loss: 0.010861425660550594
step: 510, loss: 0.009301227517426014
step: 520, loss: 0.06833016872406006
step: 530, loss: 0.061054304242134094
step: 540, loss: 0.09635338932275772
step: 550, loss: 0.06128419190645218
step: 560, loss: 0.07359214127063751
step: 570, loss: 0.034112777560949326
step: 580, loss: 0.04331137612462044
step: 590, loss: 0.06713081896305084
step: 600, loss: 0.1630052924156189
step: 610, loss: 0.17709167301654816
step: 620, loss: 0.04376750811934471
step: 630, loss: 0.01831940747797489
step: 640, loss: 0.06265541166067123
step: 650, loss: 0.08315214514732361
step: 660, loss: 0.028069332242012024
step: 670, loss: 0.03633682429790497
step: 680, loss: 0.09209121763706207
step: 690, loss: 0.032962165772914886
step: 700, loss: 0.005356551613658667
step: 710, loss: 0.08860103040933609
step: 720, loss: 0.0012493696995079517
step: 730, loss: 0.0062605226412415504
step: 740, loss: 0.06942284852266312
step: 750, loss: 0.0036056851968169212
step: 760, loss: 0.019719669595360756
step: 770, loss: 0.09676119685173035
step: 780, loss: 0.03593287989497185
step: 790, loss: 0.028623640537261963
step: 800, loss: 0.10031262040138245
step: 810, loss: 0.011049448512494564
step: 820, loss: 0.21670366823673248
step: 830, loss: 0.05199841037392616
step: 840, loss: 0.0318819060921669
step: 850, loss: 0.016409724950790405
step: 860, loss: 0.06755328178405762
step: 870, loss: 0.05755896493792534
step: 880, loss: 0.0011145664611831307
step: 890, loss: 0.07138501852750778
step: 900, loss: 0.11853951215744019
step: 910, loss: 0.014751630835235119
step: 920, loss: 0.020302604883909225
step: 930, loss: 0.02373167686164379
step: 940, loss: 0.0688076764345169
step: 950, loss: 0.04925613850355148
step: 960, loss: 0.008972150273621082
step: 970, loss: 0.013239119201898575
step: 980, loss: 0.09202936291694641
step: 990, loss: 0.039826974272727966
step: 1000, loss: 0.022012725472450256
step: 1010, loss: 0.08695909380912781
step: 1020, loss: 0.0004299694555811584
step: 1030, loss: 0.02439279668033123
step: 1040, loss: 0.028024202212691307
step: 1050, loss: 0.014384960755705833
step: 1060, loss: 0.07254312187433243
step: 1070, loss: 0.008450998924672604
epoch 9: dev_f1=0.9354243542435424, f1=0.9327846364883402, best_f1=0.9319419237749547
step: 0, loss: 0.006663470063358545
step: 10, loss: 0.01951746456325054
step: 20, loss: 0.018525738269090652
step: 30, loss: 0.010290473699569702
step: 40, loss: 0.2445279210805893
step: 50, loss: 0.05020132288336754
step: 60, loss: 0.13949039578437805
step: 70, loss: 0.030738668516278267
step: 80, loss: 0.08846744894981384
step: 90, loss: 0.07283107936382294
step: 100, loss: 0.054786473512649536
step: 110, loss: 0.09418198466300964
step: 120, loss: 0.006575919222086668
step: 130, loss: 0.02504662610590458
step: 140, loss: 0.08156891912221909
step: 150, loss: 0.09059073030948639
step: 160, loss: 0.023482805117964745
step: 170, loss: 0.011352155357599258
step: 180, loss: 0.005481398664414883
step: 190, loss: 0.017768237739801407
step: 200, loss: 0.008290570229291916
step: 210, loss: 0.07425881177186966
step: 220, loss: 0.021159488707780838
step: 230, loss: 0.03967277705669403
step: 240, loss: 0.007023409474641085
step: 250, loss: 0.02163279429078102
step: 260, loss: 0.022403119131922722
step: 270, loss: 0.024468258023262024
step: 280, loss: 0.031014837324619293
step: 290, loss: 0.08985976129770279
step: 300, loss: 0.08245978504419327
step: 310, loss: 0.134013369679451
step: 320, loss: 0.00011419612565077841
step: 330, loss: 0.06794194877147675
step: 340, loss: 0.033779967576265335
step: 350, loss: 0.05365423113107681
step: 360, loss: 0.05619531869888306
step: 370, loss: 0.01363855879753828
step: 380, loss: 0.018839942291378975
step: 390, loss: 0.0005880333483219147
step: 400, loss: 0.04066416248679161
step: 410, loss: 0.008501075208187103
step: 420, loss: 0.029991235584020615
step: 430, loss: 0.08452194184064865
step: 440, loss: 0.08954259008169174
step: 450, loss: 0.030979033559560776
step: 460, loss: 0.006567355711013079
step: 470, loss: 0.09558678418397903
step: 480, loss: 0.08422642201185226
step: 490, loss: 0.010273642838001251
step: 500, loss: 0.17540962994098663
step: 510, loss: 0.12107347697019577
step: 520, loss: 0.0807025209069252
step: 530, loss: 0.012749005109071732
step: 540, loss: 0.05926608294248581
step: 550, loss: 0.06363476812839508
step: 560, loss: 0.022440733388066292
step: 570, loss: 0.05497574433684349
step: 580, loss: 0.07717379182577133
step: 590, loss: 0.012961059808731079
step: 600, loss: 0.014967506751418114
step: 610, loss: 0.08288966119289398
step: 620, loss: 0.046137433499097824
step: 630, loss: 0.004992452450096607
step: 640, loss: 0.010617705062031746
step: 650, loss: 0.007287909276783466
step: 660, loss: 0.010099323466420174
step: 670, loss: 0.005520257633179426
step: 680, loss: 0.09007837623357773
step: 690, loss: 0.03673076629638672
step: 700, loss: 0.06939738988876343
step: 710, loss: 0.0020225578919053078
step: 720, loss: 0.004193861037492752
step: 730, loss: 0.04194777086377144
step: 740, loss: 0.051121730357408524
step: 750, loss: 0.022677849978208542
step: 760, loss: 0.04595803841948509
step: 770, loss: 0.03350328654050827
step: 780, loss: 0.027939636260271072
step: 790, loss: 0.04340740293264389
step: 800, loss: 0.009641522541642189
step: 810, loss: 0.02222944051027298
step: 820, loss: 0.1018989160656929
step: 830, loss: 0.030559323728084564
step: 840, loss: 0.0564875528216362
step: 850, loss: 0.002390774665400386
step: 860, loss: 3.804072184721008e-05
step: 870, loss: 0.07123847305774689
step: 880, loss: 0.11484713852405548
step: 890, loss: 0.004281874280422926
step: 900, loss: 0.07373040169477463
step: 910, loss: 0.26515060663223267
step: 920, loss: 0.10766886174678802
step: 930, loss: 0.07207535207271576
step: 940, loss: 0.03220658004283905
step: 950, loss: 0.06326167285442352
step: 960, loss: 3.784934233408421e-05
step: 970, loss: 0.003282058984041214
step: 980, loss: 0.030255461111664772
step: 990, loss: 0.060769904404878616
step: 1000, loss: 0.07922077924013138
step: 1010, loss: 0.07849672436714172
step: 1020, loss: 0.07379227131605148
step: 1030, loss: 0.06922878324985504
step: 1040, loss: 0.06644079089164734
step: 1050, loss: 0.050676342099905014
step: 1060, loss: 0.05776406079530716
step: 1070, loss: 0.09543482959270477
epoch 10: dev_f1=0.9437269372693727, f1=0.9348025711662074, best_f1=0.9319419237749547
step: 0, loss: 0.016797229647636414
step: 10, loss: 0.015895316377282143
step: 20, loss: 0.03172202408313751
step: 30, loss: 0.0357731431722641
step: 40, loss: 0.020273318514227867
step: 50, loss: 0.0004440861812327057
step: 60, loss: 0.027210507541894913
step: 70, loss: 0.01619279384613037
step: 80, loss: 0.006498000118881464
step: 90, loss: 0.02083001844584942
step: 100, loss: 0.16380001604557037
step: 110, loss: 0.03754062205553055
step: 120, loss: 0.04614397883415222
step: 130, loss: 0.0010018030880019069
step: 140, loss: 0.10149792581796646
step: 150, loss: 0.00842187087982893
step: 160, loss: 0.07214425504207611
step: 170, loss: 0.007020486984401941
step: 180, loss: 0.07484930008649826
step: 190, loss: 0.02078968845307827
step: 200, loss: 0.04082135856151581
step: 210, loss: 0.10010764747858047
step: 220, loss: 0.00012127615627832711
step: 230, loss: 0.07875330001115799
step: 240, loss: 0.052432894706726074
step: 250, loss: 0.024561133235692978
step: 260, loss: 0.05342802777886391
step: 270, loss: 0.007968058809638023
step: 280, loss: 0.05369411036372185
step: 290, loss: 4.920950595987961e-05
step: 300, loss: 0.011612013913691044
step: 310, loss: 0.04315050318837166
step: 320, loss: 0.07655593007802963
step: 330, loss: 0.02614215388894081
step: 340, loss: 0.005451503209769726
step: 350, loss: 0.014295440167188644
step: 360, loss: 0.012343397364020348
step: 370, loss: 0.008676795288920403
step: 380, loss: 0.03394131734967232
step: 390, loss: 0.01564602367579937
step: 400, loss: 0.09292052686214447
step: 410, loss: 0.011216742917895317
step: 420, loss: 0.08619482070207596
step: 430, loss: 0.13932137191295624
step: 440, loss: 0.03636155277490616
step: 450, loss: 0.03190242871642113
step: 460, loss: 0.06071370467543602
step: 470, loss: 0.04435832425951958
step: 480, loss: 0.010158102959394455
step: 490, loss: 0.1189146339893341
step: 500, loss: 0.005869291257113218
step: 510, loss: 0.018574684858322144
step: 520, loss: 0.020392917096614838
step: 530, loss: 0.05829359591007233
step: 540, loss: 0.033507466316223145
step: 550, loss: 0.04390532150864601
step: 560, loss: 0.1164579838514328
step: 570, loss: 0.037393130362033844
step: 580, loss: 0.08234691619873047
step: 590, loss: 0.09773494303226471
step: 600, loss: 0.05412498489022255
step: 610, loss: 0.011795022524893284
step: 620, loss: 0.03492741286754608
step: 630, loss: 0.0027298477943986654
step: 640, loss: 0.03759864345192909
step: 650, loss: 0.013563859276473522
step: 660, loss: 0.012928802520036697
step: 670, loss: 0.0854799672961235
step: 680, loss: 0.020803336054086685
step: 690, loss: 0.26292839646339417
step: 700, loss: 0.009741295129060745
step: 710, loss: 0.00757173914462328
step: 720, loss: 0.0424821674823761
step: 730, loss: 0.34607571363449097
step: 740, loss: 0.007313731592148542
step: 750, loss: 0.03994552791118622
step: 760, loss: 0.038743358105421066
step: 770, loss: 0.0159481018781662
step: 780, loss: 0.011622406542301178
step: 790, loss: 0.022553008049726486
step: 800, loss: 0.015958888456225395
step: 810, loss: 0.07641647011041641
step: 820, loss: 0.09743984043598175
step: 830, loss: 0.014493919909000397
step: 840, loss: 0.017762409523129463
step: 850, loss: 0.08326414227485657
step: 860, loss: 0.026747552677989006
step: 870, loss: 0.030449099838733673
step: 880, loss: 0.07634478807449341
step: 890, loss: 0.007398116402328014
step: 900, loss: 0.07682304829359055
step: 910, loss: 0.04911627247929573
step: 920, loss: 0.003645837539806962
step: 930, loss: 0.0002796837070491165
step: 940, loss: 0.00677091721445322
step: 950, loss: 0.018071455880999565
step: 960, loss: 0.042189162224531174
step: 970, loss: 0.007131633348762989
step: 980, loss: 7.331625238293782e-05
step: 990, loss: 0.015071355737745762
step: 1000, loss: 0.00014895344793330878
step: 1010, loss: 0.0011503000278025866
step: 1020, loss: 0.07293558865785599
step: 1030, loss: 0.0034279453102499247
step: 1040, loss: 0.025196349248290062
step: 1050, loss: 0.1278333216905594
step: 1060, loss: 0.004610845353454351
step: 1070, loss: 0.050191543996334076
epoch 11: dev_f1=0.9362880886426593, f1=0.9281464530892448, best_f1=0.9319419237749547
step: 0, loss: 0.015027370303869247
step: 10, loss: 0.05124439671635628
step: 20, loss: 0.04222286492586136
step: 30, loss: 0.04489121958613396
step: 40, loss: 0.0035487764980643988
step: 50, loss: 0.019370300695300102
step: 60, loss: 0.025403257459402084
step: 70, loss: 0.05776113271713257
step: 80, loss: 0.006392974406480789
step: 90, loss: 0.02090166136622429
step: 100, loss: 0.01687382534146309
step: 110, loss: 0.049684517085552216
step: 120, loss: 0.0013922518119215965
step: 130, loss: 0.0033522043377161026
step: 140, loss: 0.004743189550936222
step: 150, loss: 0.10437604039907455
step: 160, loss: 0.04950471967458725
step: 170, loss: 0.02489437162876129
step: 180, loss: 0.09100866317749023
step: 190, loss: 0.027785038575530052
step: 200, loss: 0.11431471258401871
step: 210, loss: 0.03869254142045975
step: 220, loss: 0.06004311889410019
step: 230, loss: 0.04642735794186592
step: 240, loss: 0.020328549668192863
step: 250, loss: 0.1091110110282898
step: 260, loss: 0.009088083170354366
step: 270, loss: 0.019605547189712524
step: 280, loss: 0.016964085400104523
step: 290, loss: 0.02589477226138115
step: 300, loss: 0.02795129269361496
step: 310, loss: 0.17202676832675934
step: 320, loss: 0.01900532841682434
step: 330, loss: 0.0978638157248497
step: 340, loss: 0.10282762348651886
step: 350, loss: 0.0060812318697571754
step: 360, loss: 0.03602861985564232
step: 370, loss: 0.00835496187210083
step: 380, loss: 0.09700557589530945
step: 390, loss: 0.01891416683793068
step: 400, loss: 0.09207373112440109
step: 410, loss: 0.020314140245318413
step: 420, loss: 0.03821117430925369
step: 430, loss: 0.027347467839717865
step: 440, loss: 0.021684138104319572
step: 450, loss: 0.014527544379234314
step: 460, loss: 0.056260861456394196
step: 470, loss: 0.03128088638186455
step: 480, loss: 0.012411985546350479
step: 490, loss: 0.004855291452258825
step: 500, loss: 0.037656910717487335
step: 510, loss: 0.15045380592346191
step: 520, loss: 0.013694954104721546
step: 530, loss: 0.08176326751708984
step: 540, loss: 0.010839559137821198
step: 550, loss: 0.007802202831953764
step: 560, loss: 0.0013646221486851573
step: 570, loss: 0.07549476623535156
step: 580, loss: 0.026683008298277855
step: 590, loss: 0.00012767328007612377
step: 600, loss: 0.20708011090755463
step: 610, loss: 0.0012871649814769626
step: 620, loss: 0.00909077562391758
step: 630, loss: 0.002279301406815648
step: 640, loss: 0.026368210092186928
step: 650, loss: 0.04183543100953102
step: 660, loss: 0.02815249003469944
step: 670, loss: 0.05410120263695717
step: 680, loss: 0.0018636789172887802
step: 690, loss: 0.08199499547481537
step: 700, loss: 0.049013957381248474
step: 710, loss: 0.03452929109334946
step: 720, loss: 0.011967148631811142
step: 730, loss: 0.12085128575563431
step: 740, loss: 0.00011546814494067803
step: 750, loss: 0.00032195006497204304
step: 760, loss: 0.059295788407325745
step: 770, loss: 0.16504904627799988
step: 780, loss: 0.07083950936794281
step: 790, loss: 0.07861165702342987
step: 800, loss: 0.03754449263215065
step: 810, loss: 0.012601298280060291
step: 820, loss: 0.05896774306893349
step: 830, loss: 0.054668184369802475
step: 840, loss: 0.0474407933652401
step: 850, loss: 0.0538971945643425
step: 860, loss: 0.06019733101129532
step: 870, loss: 0.029632728546857834
step: 880, loss: 0.06532412022352219
step: 890, loss: 0.04244692251086235
step: 900, loss: 0.03697928786277771
step: 910, loss: 0.03290446102619171
step: 920, loss: 0.05469147861003876
step: 930, loss: 0.014208815060555935
step: 940, loss: 0.0978592038154602
step: 950, loss: 0.042750284075737
step: 960, loss: 0.010654696263372898
step: 970, loss: 0.00844279583543539
step: 980, loss: 0.041182998567819595
step: 990, loss: 0.07739917188882828
step: 1000, loss: 0.040554482489824295
step: 1010, loss: 0.09296946972608566
step: 1020, loss: 0.10787434875965118
step: 1030, loss: 0.04515291377902031
step: 1040, loss: 0.03839350491762161
step: 1050, loss: 0.01861141063272953
step: 1060, loss: 0.0894983559846878
step: 1070, loss: 0.12030470371246338
epoch 12: dev_f1=0.935602575896964, f1=0.9323583180987203, best_f1=0.9319419237749547
step: 0, loss: 0.0037518609315156937
step: 10, loss: 0.015579568222165108
step: 20, loss: 0.04363437741994858
step: 30, loss: 0.014551990665495396
step: 40, loss: 0.06116946041584015
step: 50, loss: 0.0143531309440732
step: 60, loss: 0.014509114436805248
step: 70, loss: 0.004644866567105055
step: 80, loss: 0.030578818172216415
step: 90, loss: 0.09848933666944504
step: 100, loss: 0.031455572694540024
step: 110, loss: 0.09640324860811234
step: 120, loss: 0.0692179873585701
step: 130, loss: 0.008151478134095669
step: 140, loss: 0.013156497851014137
step: 150, loss: 0.027874603867530823
step: 160, loss: 0.04355349391698837
step: 170, loss: 0.008040090091526508
step: 180, loss: 0.00625547394156456
step: 190, loss: 0.00028998349444009364
step: 200, loss: 0.01179096382111311
step: 210, loss: 0.038958076387643814
step: 220, loss: 0.002899059560149908
step: 230, loss: 0.004665035288780928
step: 240, loss: 0.031086158007383347
step: 250, loss: 0.04683609679341316
step: 260, loss: 0.10544009506702423
step: 270, loss: 0.018508851528167725
step: 280, loss: 0.045629244297742844
step: 290, loss: 0.028781935572624207
step: 300, loss: 0.0572819821536541
step: 310, loss: 0.06788532435894012
step: 320, loss: 0.03576052188873291
step: 330, loss: 0.0034240803215652704
step: 340, loss: 0.023774754256010056
step: 350, loss: 0.07192791253328323
step: 360, loss: 0.02283301018178463
step: 370, loss: 0.07322792708873749
step: 380, loss: 0.002592905657365918
step: 390, loss: 0.0007275257376022637
step: 400, loss: 0.03810267895460129
step: 410, loss: 0.015106200240552425
step: 420, loss: 0.040372610092163086
step: 430, loss: 0.07338143140077591
step: 440, loss: 0.004082045517861843
step: 450, loss: 0.10434351861476898
step: 460, loss: 0.02398972027003765
step: 470, loss: 0.011509640142321587
step: 480, loss: 0.0033482839353382587
step: 490, loss: 0.006583069451153278
step: 500, loss: 0.04056892916560173
step: 510, loss: 0.0150008425116539
step: 520, loss: 0.01642206683754921
step: 530, loss: 0.12454105913639069
step: 540, loss: 0.03100910224020481
step: 550, loss: 0.013630794361233711
step: 560, loss: 0.022289682179689407
step: 570, loss: 0.028821701183915138
step: 580, loss: 0.0017329080728814006
step: 590, loss: 0.12320554256439209
step: 600, loss: 0.001092379679903388
step: 610, loss: 0.012558718211948872
step: 620, loss: 0.011553287506103516
step: 630, loss: 0.04276386275887489
step: 640, loss: 0.09994564950466156
step: 650, loss: 0.00777467479929328
step: 660, loss: 0.1093929186463356
step: 670, loss: 0.041745834052562714
step: 680, loss: 0.04550435394048691
step: 690, loss: 0.043810803443193436
step: 700, loss: 0.009921197779476643
step: 710, loss: 0.03567691147327423
step: 720, loss: 0.017181895673274994
step: 730, loss: 0.00027199130272492766
step: 740, loss: 0.04997803270816803
step: 750, loss: 0.021791592240333557
step: 760, loss: 0.013760201632976532
step: 770, loss: 0.09780971705913544
step: 780, loss: 0.040626510977745056
step: 790, loss: 0.0947265475988388
step: 800, loss: 0.07465659081935883
step: 810, loss: 0.02599327452480793
step: 820, loss: 0.039881132543087006
step: 830, loss: 0.08905797451734543
step: 840, loss: 0.08596812188625336
step: 850, loss: 0.039261240512132645
step: 860, loss: 0.10400820523500443
step: 870, loss: 0.09631846845149994
step: 880, loss: 0.023945381864905357
step: 890, loss: 0.027908748015761375
step: 900, loss: 0.0041971090249717236
step: 910, loss: 0.0008989021880552173
step: 920, loss: 0.009544087573885918
step: 930, loss: 0.07588162273168564
step: 940, loss: 0.04239097610116005
step: 950, loss: 0.006622691173106432
step: 960, loss: 0.07850316911935806
step: 970, loss: 0.029779421165585518
step: 980, loss: 0.10680855810642242
step: 990, loss: 1.8089800505549647e-05
step: 1000, loss: 0.015705527737736702
step: 1010, loss: 0.0558302141726017
step: 1020, loss: 0.06083807349205017
step: 1030, loss: 5.860978126293048e-05
step: 1040, loss: 0.02731255255639553
step: 1050, loss: 0.011451879516243935
step: 1060, loss: 0.03993029147386551
step: 1070, loss: 0.029148023575544357
epoch 13: dev_f1=0.932387706855792, f1=0.9342723004694835, best_f1=0.9319419237749547
step: 0, loss: 1.6350122677977197e-05
step: 10, loss: 1.5195314517768566e-05
step: 20, loss: 0.0621410496532917
step: 30, loss: 0.01545267179608345
step: 40, loss: 0.029611095786094666
step: 50, loss: 0.0008033147896640003
step: 60, loss: 0.08771201223134995
step: 70, loss: 0.0011705755023285747
step: 80, loss: 0.010271024890244007
step: 90, loss: 0.03986967355012894
step: 100, loss: 0.03535310924053192
step: 110, loss: 0.004114668350666761
step: 120, loss: 0.049909558147192
step: 130, loss: 0.046689536422491074
step: 140, loss: 0.025957753881812096
step: 150, loss: 0.007209851872175932
step: 160, loss: 0.04117821529507637
step: 170, loss: 0.04179516062140465
step: 180, loss: 0.01971096731722355
step: 190, loss: 0.020611748099327087
step: 200, loss: 0.1766711175441742
step: 210, loss: 0.004646404180675745
step: 220, loss: 0.04834478348493576
step: 230, loss: 0.14018438756465912
step: 240, loss: 0.024686021730303764
step: 250, loss: 0.02870587445795536
step: 260, loss: 0.0018523785984143615
step: 270, loss: 0.01587914302945137
step: 280, loss: 0.10329561680555344
step: 290, loss: 0.0025629715528339148
step: 300, loss: 0.007175455801188946
step: 310, loss: 0.028454231098294258
step: 320, loss: 0.01201849989593029
step: 330, loss: 0.08672058582305908
step: 340, loss: 0.06161171570420265
step: 350, loss: 0.005467250943183899
step: 360, loss: 0.03674976900219917
step: 370, loss: 0.0676911398768425
step: 380, loss: 0.00582018680870533
step: 390, loss: 0.0010301129659637809
step: 400, loss: 0.00028265302535146475
step: 410, loss: 0.02240961790084839
step: 420, loss: 0.018291080370545387
step: 430, loss: 0.022052286192774773
step: 440, loss: 0.10256680101156235
step: 450, loss: 0.00026870789588429034
step: 460, loss: 0.03888696804642677
step: 470, loss: 0.06129326671361923
step: 480, loss: 0.034852877259254456
step: 490, loss: 0.07558853179216385
step: 500, loss: 0.1232389584183693
step: 510, loss: 0.02125120721757412
step: 520, loss: 0.0007405610522255301
step: 530, loss: 0.07751616090536118
step: 540, loss: 0.003960933070629835
step: 550, loss: 0.025675129145383835
step: 560, loss: 0.02152726612985134
step: 570, loss: 0.02895009145140648
step: 580, loss: 0.00020318238239269704
step: 590, loss: 0.02891702763736248
step: 600, loss: 0.05637122690677643
step: 610, loss: 0.0032828410621732473
step: 620, loss: 0.07099518924951553
step: 630, loss: 0.08414500951766968
step: 640, loss: 0.010526543483138084
step: 650, loss: 0.002207699231803417
step: 660, loss: 0.221715047955513
step: 670, loss: 0.02222370356321335
step: 680, loss: 0.00011671693937387317
step: 690, loss: 0.008224262855947018
step: 700, loss: 0.054086729884147644
step: 710, loss: 0.04319252818822861
step: 720, loss: 0.03819969296455383
step: 730, loss: 0.012134330347180367
step: 740, loss: 1.56645637616748e-05
step: 750, loss: 0.015295742079615593
step: 760, loss: 0.02263122797012329
step: 770, loss: 0.0217401422560215
step: 780, loss: 0.07365717738866806
step: 790, loss: 0.018763180822134018
step: 800, loss: 0.047284215688705444
step: 810, loss: 0.0068436735309660435
step: 820, loss: 0.03577147796750069
step: 830, loss: 0.041137248277664185
step: 840, loss: 0.04123677313327789
step: 850, loss: 0.000652085174806416
step: 860, loss: 4.252945291227661e-05
step: 870, loss: 0.062367793172597885
step: 880, loss: 0.05476506054401398
step: 890, loss: 0.016919849440455437
step: 900, loss: 0.02001793310046196
step: 910, loss: 0.000286952534224838
step: 920, loss: 3.45035623467993e-05
step: 930, loss: 7.923796511022374e-05
step: 940, loss: 0.0030519224237650633
step: 950, loss: 0.060986340045928955
step: 960, loss: 0.04118601977825165
step: 970, loss: 0.003005519276484847
step: 980, loss: 0.02398749440908432
step: 990, loss: 0.028722040355205536
step: 1000, loss: 0.06097028777003288
step: 1010, loss: 0.044142719358205795
step: 1020, loss: 0.017809197306632996
step: 1030, loss: 0.021536607295274734
step: 1040, loss: 0.059071559458971024
step: 1050, loss: 0.022919097915291786
step: 1060, loss: 0.005825430620461702
step: 1070, loss: 0.0025267477612942457
epoch 14: dev_f1=0.9371534195933457, f1=0.9370437956204379, best_f1=0.9319419237749547
step: 0, loss: 0.08510623872280121
step: 10, loss: 0.005617504473775625
step: 20, loss: 0.012602525763213634
step: 30, loss: 0.043798621743917465
step: 40, loss: 0.00911311898380518
step: 50, loss: 0.00018679712957236916
step: 60, loss: 0.020514465868473053
step: 70, loss: 0.1049402579665184
step: 80, loss: 0.1507188230752945
step: 90, loss: 0.03821956366300583
step: 100, loss: 0.049699947237968445
step: 110, loss: 0.002575199818238616
step: 120, loss: 0.062017712742090225
step: 130, loss: 0.011200989596545696
step: 140, loss: 0.01566906087100506
step: 150, loss: 0.04525528475642204
step: 160, loss: 0.12146413326263428
step: 170, loss: 0.03555156663060188
step: 180, loss: 0.043630894273519516
step: 190, loss: 0.0005140923894941807
step: 200, loss: 0.02539924532175064
step: 210, loss: 0.012658265419304371
step: 220, loss: 0.00235741026699543
step: 230, loss: 0.02505975216627121
step: 240, loss: 0.047498419880867004
step: 250, loss: 0.024062572047114372
step: 260, loss: 0.04865371435880661
step: 270, loss: 0.0193000640720129
step: 280, loss: 0.004095590673387051
step: 290, loss: 0.04603086784482002
step: 300, loss: 0.09541881829500198
step: 310, loss: 0.030580123886466026
step: 320, loss: 0.032158784568309784
step: 330, loss: 0.007996522821485996
step: 340, loss: 0.07951431721448898
step: 350, loss: 0.07558949291706085
step: 360, loss: 0.001429806579835713
step: 370, loss: 0.0005175152327865362
step: 380, loss: 0.04977794736623764
step: 390, loss: 0.010395299643278122
step: 400, loss: 0.031597692519426346
step: 410, loss: 0.0015119175659492612
step: 420, loss: 0.05566522851586342
step: 430, loss: 0.026856379583477974
step: 440, loss: 0.07843460142612457
step: 450, loss: 0.08270706236362457
step: 460, loss: 0.024298084899783134
step: 470, loss: 4.8988662456395105e-05
step: 480, loss: 0.028320230543613434
step: 490, loss: 0.06394757330417633
step: 500, loss: 0.0009036801639012992
step: 510, loss: 0.060976721346378326
step: 520, loss: 6.864203896839172e-05
step: 530, loss: 0.022016139701008797
step: 540, loss: 0.06669256836175919
step: 550, loss: 0.048758573830127716
step: 560, loss: 0.004512646235525608
step: 570, loss: 0.0013512143632397056
step: 580, loss: 0.0014312309212982655
step: 590, loss: 0.020191652700304985
step: 600, loss: 0.05356711894273758
step: 610, loss: 0.05805409699678421
step: 620, loss: 0.06106502190232277
step: 630, loss: 0.04150800406932831
step: 640, loss: 0.07563630491495132
step: 650, loss: 0.017440039664506912
step: 660, loss: 0.0002884661662392318
step: 670, loss: 0.07683589309453964
step: 680, loss: 3.5593740904005244e-05
step: 690, loss: 0.025923721492290497
step: 700, loss: 0.003342194017022848
step: 710, loss: 0.021740548312664032
step: 720, loss: 0.054870735853910446
step: 730, loss: 0.022281819954514503
step: 740, loss: 0.00043915637070313096
step: 750, loss: 0.04500836506485939
step: 760, loss: 0.033030081540346146
step: 770, loss: 0.04243098571896553
step: 780, loss: 0.02031228318810463
step: 790, loss: 0.023301081731915474
step: 800, loss: 0.036994997411966324
step: 810, loss: 0.0007295495015569031
step: 820, loss: 0.025972185656428337
step: 830, loss: 0.009935164824128151
step: 840, loss: 0.0013686164747923613
step: 850, loss: 0.02479754202067852
step: 860, loss: 0.032311540096998215
step: 870, loss: 0.02234676480293274
step: 880, loss: 0.039759311825037
step: 890, loss: 0.026515832170844078
step: 900, loss: 2.1192196072661318e-05
step: 910, loss: 0.028448104858398438
step: 920, loss: 0.03316972032189369
step: 930, loss: 0.002306535607203841
step: 940, loss: 0.002807063050568104
step: 950, loss: 0.0003608976840041578
step: 960, loss: 0.0009102005860768259
step: 970, loss: 0.009802901186048985
step: 980, loss: 0.0001657292596064508
step: 990, loss: 0.03752340003848076
step: 1000, loss: 0.051762256771326065
step: 1010, loss: 0.02439681626856327
step: 1020, loss: 0.03312232345342636
step: 1030, loss: 0.037746675312519073
step: 1040, loss: 0.04279689863324165
step: 1050, loss: 1.7151027350337245e-05
step: 1060, loss: 0.0368817038834095
step: 1070, loss: 0.031134910881519318
epoch 15: dev_f1=0.9377358490566038, f1=0.932330827067669, best_f1=0.9319419237749547
step: 0, loss: 0.003244060790166259
step: 10, loss: 0.025585975497961044
step: 20, loss: 0.000156847047037445
step: 30, loss: 0.09893597662448883
step: 40, loss: 0.004309303127229214
step: 50, loss: 0.0008959718397818506
step: 60, loss: 0.03830474242568016
step: 70, loss: 0.00010066373215522617
step: 80, loss: 0.08846478909254074
step: 90, loss: 1.815677751437761e-05
step: 100, loss: 0.0014147257898002863
step: 110, loss: 0.00986191164702177
step: 120, loss: 0.0031136288307607174
step: 130, loss: 0.14111553132534027
step: 140, loss: 0.000706634484231472
step: 150, loss: 0.0386841855943203
step: 160, loss: 0.0017827352276071906
step: 170, loss: 0.026306714862585068
step: 180, loss: 0.0018310215091332793
step: 190, loss: 0.07109994441270828
step: 200, loss: 0.030129116028547287
step: 210, loss: 8.005173731362447e-05
step: 220, loss: 0.040438245981931686
step: 230, loss: 0.08595238626003265
step: 240, loss: 0.021053938195109367
step: 250, loss: 0.03492631018161774
step: 260, loss: 0.015314359217882156
step: 270, loss: 0.0003249058499932289
step: 280, loss: 0.03980186581611633
step: 290, loss: 0.08144071698188782
step: 300, loss: 0.04458516463637352
step: 310, loss: 0.005442140623927116
step: 320, loss: 0.0282214917242527
step: 330, loss: 0.06461352854967117
step: 340, loss: 0.004042474552989006
step: 350, loss: 3.06478250422515e-05
step: 360, loss: 0.07423479110002518
step: 370, loss: 0.0006477790884673595
step: 380, loss: 0.0012569576501846313
step: 390, loss: 0.0002608680515550077
step: 400, loss: 0.04053836315870285
step: 410, loss: 0.008646875619888306
step: 420, loss: 0.03468981385231018
step: 430, loss: 0.08712129294872284
step: 440, loss: 0.016529222950339317
step: 450, loss: 0.020060818642377853
step: 460, loss: 0.003277312498539686
step: 470, loss: 0.08474506437778473
step: 480, loss: 0.06618738174438477
step: 490, loss: 0.11819669604301453
step: 500, loss: 0.05605710297822952
step: 510, loss: 0.09185083210468292
step: 520, loss: 0.07395392656326294
step: 530, loss: 0.0024181136395782232
step: 540, loss: 0.03708222135901451
step: 550, loss: 0.10498135536909103
step: 560, loss: 0.010600205510854721
step: 570, loss: 0.0022141325753182173
step: 580, loss: 0.022901812568306923
step: 590, loss: 0.01279554795473814
step: 600, loss: 3.603832010412589e-05
step: 610, loss: 0.008800196461379528
step: 620, loss: 0.00011790405551437289
step: 630, loss: 0.03189394995570183
step: 640, loss: 0.0005603634053841233
step: 650, loss: 0.029517820104956627
step: 660, loss: 0.0001429457770427689
step: 670, loss: 1.24311873150873e-05
step: 680, loss: 0.015937533229589462
step: 690, loss: 0.002144010504707694
step: 700, loss: 0.026614990085363388
step: 710, loss: 0.0004414081631693989
step: 720, loss: 0.02089003100991249
step: 730, loss: 0.015050137415528297
step: 740, loss: 0.008637686260044575
step: 750, loss: 0.00900733470916748
step: 760, loss: 0.023770777508616447
step: 770, loss: 1.7962884157896042e-05
step: 780, loss: 0.022903569042682648
step: 790, loss: 0.0280186478048563
step: 800, loss: 0.11451809108257294
step: 810, loss: 0.035787466913461685
step: 820, loss: 0.010629018768668175
step: 830, loss: 0.031166383996605873
step: 840, loss: 0.019502386450767517
step: 850, loss: 0.08572959899902344
step: 860, loss: 9.324107668362558e-05
step: 870, loss: 0.03341533616185188
step: 880, loss: 0.0010966119589284062
step: 890, loss: 0.0707736685872078
step: 900, loss: 0.0030014917720109224
step: 910, loss: 0.0011844331165775657
step: 920, loss: 0.038246139883995056
step: 930, loss: 0.00034162699012085795
step: 940, loss: 0.020611898973584175
step: 950, loss: 0.017271848395466805
step: 960, loss: 0.024340154603123665
step: 970, loss: 0.10554635524749756
step: 980, loss: 0.044431813061237335
step: 990, loss: 0.015111487358808517
step: 1000, loss: 0.0248648039996624
step: 1010, loss: 0.028315642848610878
step: 1020, loss: 0.0004294998070690781
step: 1030, loss: 6.587844109162688e-05
step: 1040, loss: 0.036646768450737
step: 1050, loss: 0.030301809310913086
step: 1060, loss: 0.0006813651416450739
step: 1070, loss: 0.05378967896103859
epoch 16: dev_f1=0.9351503759398496, f1=0.9273743016759776, best_f1=0.9319419237749547
step: 0, loss: 0.004957024473696947
step: 10, loss: 0.030061954632401466
step: 20, loss: 0.01803528144955635
step: 30, loss: 1.9620601960923523e-05
step: 40, loss: 0.09122856706380844
step: 50, loss: 0.02209297940135002
step: 60, loss: 0.007707617711275816
step: 70, loss: 0.0166756771504879
step: 80, loss: 0.09457149356603622
step: 90, loss: 0.0732945129275322
step: 100, loss: 0.0004141728568356484
step: 110, loss: 0.025505177676677704
step: 120, loss: 6.218232738319784e-05
step: 130, loss: 1.9076762328040786e-05
step: 140, loss: 0.22444964945316315
step: 150, loss: 0.037176940590143204
step: 160, loss: 0.0030289744026958942
step: 170, loss: 0.029783621430397034
step: 180, loss: 1.2062389942002483e-05
step: 190, loss: 0.0009107454679906368
step: 200, loss: 0.044486887753009796
step: 210, loss: 0.02355579100549221
step: 220, loss: 0.05620220676064491
step: 230, loss: 0.007245205342769623
step: 240, loss: 0.006081230007112026
step: 250, loss: 0.002448303159326315
step: 260, loss: 0.02016201615333557
step: 270, loss: 0.038176171481609344
step: 280, loss: 0.04469415172934532
step: 290, loss: 0.00017370074056088924
step: 300, loss: 0.022413957864046097
step: 310, loss: 0.03140779212117195
step: 320, loss: 0.01840919815003872
step: 330, loss: 0.015596305020153522
step: 340, loss: 0.023539192974567413
step: 350, loss: 0.020276885479688644
step: 360, loss: 0.0008099233964458108
step: 370, loss: 0.021969303488731384
step: 380, loss: 0.010969631373882294
step: 390, loss: 0.0004330489900894463
step: 400, loss: 0.02048761397600174
step: 410, loss: 0.04521682858467102
step: 420, loss: 0.02888527326285839
step: 430, loss: 0.06443318724632263
step: 440, loss: 2.374743780819699e-05
step: 450, loss: 0.03157293424010277
step: 460, loss: 0.011863114312291145
step: 470, loss: 4.112773603992537e-05
step: 480, loss: 0.020842453464865685
step: 490, loss: 0.01864703744649887
step: 500, loss: 0.023224953562021255
step: 510, loss: 0.06008576229214668
step: 520, loss: 0.031079748645424843
step: 530, loss: 0.11229363828897476
step: 540, loss: 0.02471591904759407
step: 550, loss: 0.0025224254932254553
step: 560, loss: 0.021971173584461212
step: 570, loss: 0.05441564321517944
step: 580, loss: 0.05293832719326019
step: 590, loss: 0.017213961109519005
step: 600, loss: 0.008954391814768314
step: 610, loss: 1.3015975127927959e-05
step: 620, loss: 0.024430790916085243
step: 630, loss: 0.1604924201965332
step: 640, loss: 0.010404114611446857
step: 650, loss: 0.07404682785272598
step: 660, loss: 0.05923404544591904
step: 670, loss: 0.00010887832468142733
step: 680, loss: 0.04241279512643814
step: 690, loss: 0.0902332291007042
step: 700, loss: 0.04215928539633751
step: 710, loss: 0.00012706225970759988
step: 720, loss: 0.02682819776237011
step: 730, loss: 0.02294471301138401
step: 740, loss: 0.03096647746860981
step: 750, loss: 0.014770335517823696
step: 760, loss: 0.047186803072690964
step: 770, loss: 0.02589833363890648
step: 780, loss: 0.026166215538978577
step: 790, loss: 0.020326200872659683
step: 800, loss: 0.03776959702372551
step: 810, loss: 0.029815025627613068
step: 820, loss: 0.0687379390001297
step: 830, loss: 0.043079350143671036
step: 840, loss: 0.05843660235404968
step: 850, loss: 0.026741143316030502
step: 860, loss: 0.03894663602113724
step: 870, loss: 0.036692142486572266
step: 880, loss: 0.03754111006855965
step: 890, loss: 0.021112116053700447
step: 900, loss: 0.03553583472967148
step: 910, loss: 0.11720957607030869
step: 920, loss: 0.002028930466622114
step: 930, loss: 0.0023942249827086926
step: 940, loss: 0.037975285202264786
step: 950, loss: 0.026773350313305855
step: 960, loss: 8.387835987377912e-05
step: 970, loss: 0.07495258003473282
step: 980, loss: 0.013224500231444836
step: 990, loss: 0.03608419746160507
step: 1000, loss: 0.0001817458978621289
step: 1010, loss: 0.00888094399124384
step: 1020, loss: 0.0009860801510512829
step: 1030, loss: 0.02225121669471264
step: 1040, loss: 0.03181490674614906
step: 1050, loss: 0.024551818147301674
step: 1060, loss: 0.04054349288344383
step: 1070, loss: 0.002010595053434372
epoch 17: dev_f1=0.9358914365933552, f1=0.9306008383791335, best_f1=0.9319419237749547
step: 0, loss: 0.002275326056405902
step: 10, loss: 0.022403644397854805
step: 20, loss: 0.04764135554432869
step: 30, loss: 0.07240688055753708
step: 40, loss: 0.01128052081912756
step: 50, loss: 0.007017731666564941
step: 60, loss: 0.07362980395555496
step: 70, loss: 0.02165418118238449
step: 80, loss: 3.440643922658637e-05
step: 90, loss: 0.018071366474032402
step: 100, loss: 0.014766719192266464
step: 110, loss: 0.005637455265969038
step: 120, loss: 0.08127406239509583
step: 130, loss: 0.003402519738301635
step: 140, loss: 0.028560776263475418
step: 150, loss: 0.0929771214723587
step: 160, loss: 0.03900527209043503
step: 170, loss: 0.03967421501874924
step: 180, loss: 0.02985992841422558
step: 190, loss: 0.06555671989917755
step: 200, loss: 1.6256890376098454e-05
step: 210, loss: 0.025018850341439247
step: 220, loss: 0.012235822156071663
step: 230, loss: 1.1254028322582599e-05
step: 240, loss: 0.028471896424889565
step: 250, loss: 0.02456810139119625
step: 260, loss: 1.2535492714960128e-05
step: 270, loss: 0.031356312334537506
step: 280, loss: 0.03041878156363964
step: 290, loss: 0.014691922813653946
step: 300, loss: 2.1642354113282636e-05
step: 310, loss: 3.166911119478755e-05
step: 320, loss: 0.01499254908412695
step: 330, loss: 0.0002791982551570982
step: 340, loss: 0.0006233591120690107
step: 350, loss: 0.055833615362644196
step: 360, loss: 0.022659335285425186
step: 370, loss: 0.018537094816565514
step: 380, loss: 0.026265645399689674
step: 390, loss: 0.03697152063250542
step: 400, loss: 0.02090056799352169
step: 410, loss: 0.04551148787140846
step: 420, loss: 0.031347841024398804
step: 430, loss: 0.0033620952162891626
step: 440, loss: 0.04560433328151703
step: 450, loss: 0.0010288525372743607
step: 460, loss: 0.04136957600712776
step: 470, loss: 0.027636706829071045
step: 480, loss: 1.3496584870154038e-05
step: 490, loss: 0.018236154690384865
step: 500, loss: 0.02041708491742611
step: 510, loss: 0.056892141699790955
step: 520, loss: 0.02183179184794426
step: 530, loss: 0.01790720596909523
step: 540, loss: 0.04757748171687126
step: 550, loss: 0.055199433118104935
step: 560, loss: 1.9002176486537792e-05
step: 570, loss: 0.04411450773477554
step: 580, loss: 1.534410876047332e-05
step: 590, loss: 0.013916436582803726
step: 600, loss: 0.0009153182036243379
step: 610, loss: 1.889795203169342e-05
step: 620, loss: 0.00010608729644445702
step: 630, loss: 0.024576300755143166
step: 640, loss: 0.03741779178380966
step: 650, loss: 0.058988623321056366
step: 660, loss: 0.002260660519823432
step: 670, loss: 3.499030208331533e-05
step: 680, loss: 0.03689977899193764
step: 690, loss: 0.020016025751829147
step: 700, loss: 0.017767181620001793
step: 710, loss: 0.024178247898817062
step: 720, loss: 5.885231803404167e-05
step: 730, loss: 0.0002378079225309193
step: 740, loss: 0.07741546630859375
step: 750, loss: 0.054527927190065384
step: 760, loss: 0.06315327435731888
step: 770, loss: 0.0054245623759925365
step: 780, loss: 0.05428003892302513
step: 790, loss: 0.04774728789925575
step: 800, loss: 0.027078814804553986
step: 810, loss: 0.024913441389799118
step: 820, loss: 0.04160986468195915
step: 830, loss: 0.00353005388751626
step: 840, loss: 0.02455824427306652
step: 850, loss: 0.0025308772455900908
step: 860, loss: 4.813867053599097e-05
step: 870, loss: 0.00023396042524836957
step: 880, loss: 3.076305074500851e-05
step: 890, loss: 0.11997947841882706
step: 900, loss: 0.03920925408601761
step: 910, loss: 5.756922109867446e-05
step: 920, loss: 0.0006287720752879977
step: 930, loss: 0.04459206014871597
step: 940, loss: 0.024606820195913315
step: 950, loss: 0.017311781644821167
step: 960, loss: 0.018196409568190575
step: 970, loss: 1.894932211143896e-05
step: 980, loss: 2.579905412858352e-05
step: 990, loss: 0.0001724893372738734
step: 1000, loss: 0.03826841711997986
step: 1010, loss: 0.02471214346587658
step: 1020, loss: 1.5768560842843726e-05
step: 1030, loss: 0.007359253242611885
step: 1040, loss: 2.006363502005115e-05
step: 1050, loss: 0.018709445372223854
step: 1060, loss: 0.05157870426774025
step: 1070, loss: 0.005934372544288635
epoch 18: dev_f1=0.9390815370196813, f1=0.929840972871843, best_f1=0.9319419237749547
step: 0, loss: 0.02783551812171936
step: 10, loss: 0.041815854609012604
step: 20, loss: 0.022347645834088326
step: 30, loss: 6.459225551225245e-05
step: 40, loss: 0.028238071128726006
step: 50, loss: 0.024550925940275192
step: 60, loss: 0.015137599781155586
step: 70, loss: 0.0016054707812145352
step: 80, loss: 0.00017035598284564912
step: 90, loss: 0.030215220525860786
step: 100, loss: 0.025127654895186424
step: 110, loss: 1.4439067854254972e-05
step: 120, loss: 0.02393442578613758
step: 130, loss: 2.5325278329546563e-05
step: 140, loss: 0.033840958029031754
step: 150, loss: 1.2881940165243577e-05
step: 160, loss: 4.840356996282935e-05
step: 170, loss: 7.91213897173293e-05
step: 180, loss: 0.031345710158348083
step: 190, loss: 0.015627996996045113
step: 200, loss: 0.028442751616239548
step: 210, loss: 0.019054587930440903
step: 220, loss: 0.06991849839687347
step: 230, loss: 1.4580588867829647e-05
step: 240, loss: 0.0004813870182260871
step: 250, loss: 0.030480481684207916
step: 260, loss: 0.02610127627849579
step: 270, loss: 0.005751931108534336
step: 280, loss: 4.6319615648826584e-05
step: 290, loss: 0.054484423249959946
step: 300, loss: 0.02700348198413849
step: 310, loss: 0.056563593447208405
step: 320, loss: 0.004855156876146793
step: 330, loss: 0.023586543276906013
step: 340, loss: 0.04834439605474472
step: 350, loss: 0.019836323335766792
step: 360, loss: 0.05315551161766052
step: 370, loss: 0.024197038263082504
step: 380, loss: 3.241036392864771e-05
step: 390, loss: 2.304759073012974e-05
step: 400, loss: 0.018535684794187546
step: 410, loss: 0.005008703097701073
step: 420, loss: 2.7295185645925812e-05
step: 430, loss: 0.026546647772192955
step: 440, loss: 2.4451925128232688e-05
step: 450, loss: 0.027701575309038162
step: 460, loss: 0.0003833869122900069
step: 470, loss: 4.133620677748695e-05
step: 480, loss: 0.021235881373286247
step: 490, loss: 0.019048169255256653
step: 500, loss: 0.01892225071787834
step: 510, loss: 0.09336959570646286
step: 520, loss: 9.862809383776039e-05
step: 530, loss: 0.02210509032011032
step: 540, loss: 2.7461313948151655e-05
step: 550, loss: 0.028631895780563354
step: 560, loss: 0.045124851167201996
step: 570, loss: 0.016603218391537666
step: 580, loss: 0.039451513439416885
step: 590, loss: 0.06764242798089981
step: 600, loss: 2.3426367988577113e-05
step: 610, loss: 0.0018944703042507172
step: 620, loss: 0.00030442705610767007
step: 630, loss: 0.0016660882392898202
step: 640, loss: 7.629873289261013e-05
step: 650, loss: 0.11564455181360245
step: 660, loss: 0.06261072307825089
step: 670, loss: 4.289122807676904e-05
step: 680, loss: 0.0008604290196672082
step: 690, loss: 0.037967074662446976
step: 700, loss: 0.008030423894524574
step: 710, loss: 0.02260361984372139
step: 720, loss: 0.0254201702773571
step: 730, loss: 1.327300924458541e-05
step: 740, loss: 0.05907003954052925
step: 750, loss: 0.038095202296972275
step: 760, loss: 3.5295488487463444e-05
step: 770, loss: 0.036200862377882004
step: 780, loss: 0.0002289132244186476
step: 790, loss: 0.039311282336711884
step: 800, loss: 0.014781855046749115
step: 810, loss: 0.043000467121601105
step: 820, loss: 0.0004559574299491942
step: 830, loss: 0.03808979317545891
step: 840, loss: 0.0019156973576173186
step: 850, loss: 0.06260640919208527
step: 860, loss: 5.985370808048174e-05
step: 870, loss: 0.005048603750765324
step: 880, loss: 0.015289092436432838
step: 890, loss: 0.0001617080852156505
step: 900, loss: 0.00014984158042352647
step: 910, loss: 0.07728127390146255
step: 920, loss: 0.023168649524450302
step: 930, loss: 0.02500682696700096
step: 940, loss: 0.01738845556974411
step: 950, loss: 0.00035230806679464877
step: 960, loss: 0.011215060018002987
step: 970, loss: 0.05325537919998169
step: 980, loss: 0.060955241322517395
step: 990, loss: 0.03220982104539871
step: 1000, loss: 0.017941979691386223
step: 1010, loss: 0.01799803413450718
step: 1020, loss: 0.0509352944791317
step: 1030, loss: 0.01655491068959236
step: 1040, loss: 0.0477324053645134
step: 1050, loss: 0.046108178794384
step: 1060, loss: 0.01612727716565132
step: 1070, loss: 1.4502295016427524e-05
epoch 19: dev_f1=0.9385633270321362, f1=0.9295112781954888, best_f1=0.9319419237749547
step: 0, loss: 0.019248785451054573
step: 10, loss: 0.020863233134150505
step: 20, loss: 0.04956764355301857
step: 30, loss: 0.08602301776409149
step: 40, loss: 0.06724479049444199
step: 50, loss: 0.028090856969356537
step: 60, loss: 0.03864031657576561
step: 70, loss: 0.0797036811709404
step: 80, loss: 0.013632899150252342
step: 90, loss: 0.00044595656800083816
step: 100, loss: 0.026591183617711067
step: 110, loss: 2.292068711540196e-05
step: 120, loss: 0.07811533659696579
step: 130, loss: 1.2755222087434959e-05
step: 140, loss: 0.002771673956885934
step: 150, loss: 0.05393049493432045
step: 160, loss: 1.3615606803796254e-05
step: 170, loss: 0.01409032940864563
step: 180, loss: 0.01418267097324133
step: 190, loss: 0.00011292086855974048
step: 200, loss: 2.5822306270129047e-05
step: 210, loss: 0.011687074787914753
step: 220, loss: 1.1056595212721732e-05
step: 230, loss: 1.6744790627853945e-05
step: 240, loss: 0.0029964661225676537
step: 250, loss: 0.0718592032790184
step: 260, loss: 0.010832936502993107
step: 270, loss: 0.029706332832574844
step: 280, loss: 0.02235860377550125
step: 290, loss: 0.002268595155328512
step: 300, loss: 0.06855335086584091
step: 310, loss: 0.013643572106957436
step: 320, loss: 0.000285061018075794
step: 330, loss: 0.028818022459745407
step: 340, loss: 0.01960432343184948
step: 350, loss: 2.07263910851907e-05
step: 360, loss: 0.024229779839515686
step: 370, loss: 0.0005902001284994185
step: 380, loss: 0.01866520568728447
step: 390, loss: 1.6893705833354034e-05
step: 400, loss: 0.016317103058099747
step: 410, loss: 0.01712430827319622
step: 420, loss: 0.038239166140556335
step: 430, loss: 0.02489815466105938
step: 440, loss: 0.04030529409646988
step: 450, loss: 0.025976376608014107
step: 460, loss: 0.0169695895165205
step: 470, loss: 0.0003204939130228013
step: 480, loss: 0.06536023318767548
step: 490, loss: 0.043655749410390854
step: 500, loss: 0.05375320464372635
step: 510, loss: 0.02324996143579483
step: 520, loss: 0.021111367270350456
step: 530, loss: 5.4954809456830844e-05
step: 540, loss: 0.0038544051349163055
step: 550, loss: 0.044279344379901886
step: 560, loss: 1.2941518434672616e-05
step: 570, loss: 8.244698256021366e-05
step: 580, loss: 3.6074812669539824e-05
step: 590, loss: 2.215151471318677e-05
step: 600, loss: 0.04447009786963463
step: 610, loss: 0.04023953527212143
step: 620, loss: 0.1118965595960617
step: 630, loss: 0.047037214040756226
step: 640, loss: 0.02670174464583397
step: 650, loss: 0.031141161918640137
step: 660, loss: 0.02393149957060814
step: 670, loss: 0.0770447701215744
step: 680, loss: 1.837641502788756e-05
step: 690, loss: 0.060164306312799454
step: 700, loss: 0.02012430503964424
step: 710, loss: 0.0008559782290831208
step: 720, loss: 0.017862556502223015
step: 730, loss: 0.0592779666185379
step: 740, loss: 0.035954419523477554
step: 750, loss: 0.02607284113764763
step: 760, loss: 2.7862595743499696e-05
step: 770, loss: 0.01886596716940403
step: 780, loss: 0.023340266197919846
step: 790, loss: 0.032577551901340485
step: 800, loss: 0.011886591091752052
step: 810, loss: 0.00024187054077629
step: 820, loss: 0.007411325350403786
step: 830, loss: 0.0035039137583225965
step: 840, loss: 0.005262684542685747
step: 850, loss: 3.041173840756528e-05
step: 860, loss: 0.018348123878240585
step: 870, loss: 0.037146586924791336
step: 880, loss: 0.01951824314892292
step: 890, loss: 0.015048091299831867
step: 900, loss: 0.03650898486375809
step: 910, loss: 2.1873605874134228e-05
step: 920, loss: 0.00037778844125568867
step: 930, loss: 0.05868501588702202
step: 940, loss: 0.044710736721754074
step: 950, loss: 4.523729512584396e-05
step: 960, loss: 0.005278951022773981
step: 970, loss: 2.73818241112167e-05
step: 980, loss: 0.018453486263751984
step: 990, loss: 0.028582707047462463
step: 1000, loss: 0.06155592203140259
step: 1010, loss: 1.3217168998380657e-05
step: 1020, loss: 3.6738914786837995e-05
step: 1030, loss: 1.8000138879870065e-05
step: 1040, loss: 0.0018338353838771582
step: 1050, loss: 0.03597574681043625
step: 1060, loss: 0.024259287863969803
step: 1070, loss: 3.672889943118207e-05
epoch 20: dev_f1=0.9376181474480151, f1=0.9308885754583921, best_f1=0.9319419237749547
