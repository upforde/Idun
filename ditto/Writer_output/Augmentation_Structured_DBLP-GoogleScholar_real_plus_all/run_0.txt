cuda
Device: cuda
step: 0, loss: 0.7780042886734009
step: 10, loss: 0.49657756090164185
step: 20, loss: 0.6901740431785583
step: 30, loss: 0.44941553473472595
step: 40, loss: 0.3244715631008148
step: 50, loss: 0.22113707661628723
step: 60, loss: 0.29556676745414734
step: 70, loss: 0.2650569975376129
step: 80, loss: 0.21911105513572693
step: 90, loss: 0.140228733420372
step: 100, loss: 0.24974952638149261
step: 110, loss: 0.16031497716903687
step: 120, loss: 0.2799373269081116
step: 130, loss: 0.2234485000371933
step: 140, loss: 0.12738539278507233
step: 150, loss: 0.2435724437236786
step: 160, loss: 0.09345456212759018
step: 170, loss: 0.10613080114126205
step: 180, loss: 0.13144394755363464
step: 190, loss: 0.25475409626960754
step: 200, loss: 0.147172749042511
step: 210, loss: 0.16105888783931732
step: 220, loss: 0.2380002737045288
step: 230, loss: 0.12596958875656128
step: 240, loss: 0.2885568141937256
step: 250, loss: 0.10489597916603088
step: 260, loss: 0.22278359532356262
step: 270, loss: 0.10148858278989792
step: 280, loss: 0.27340251207351685
step: 290, loss: 0.12964461743831635
step: 300, loss: 0.2519931197166443
step: 310, loss: 0.1835038959980011
step: 320, loss: 0.1268453747034073
step: 330, loss: 0.05051200091838837
step: 340, loss: 0.13547693192958832
step: 350, loss: 0.1569654941558838
step: 360, loss: 0.11214424669742584
step: 370, loss: 0.23898819088935852
step: 380, loss: 0.16574105620384216
step: 390, loss: 0.18751081824302673
step: 400, loss: 0.10654627531766891
step: 410, loss: 0.19534577429294586
step: 420, loss: 0.08537402004003525
step: 430, loss: 0.20095142722129822
step: 440, loss: 0.07654033601284027
step: 450, loss: 0.08413878083229065
step: 460, loss: 0.08369838446378708
step: 470, loss: 0.05782276391983032
step: 480, loss: 0.08786827325820923
step: 490, loss: 0.14198973774909973
step: 500, loss: 0.1809430569410324
step: 510, loss: 0.11789770424365997
step: 520, loss: 0.04508640989661217
step: 530, loss: 0.13817675411701202
step: 540, loss: 0.0866929292678833
step: 550, loss: 0.06043434515595436
step: 560, loss: 0.06594984978437424
step: 570, loss: 0.058040354400873184
step: 580, loss: 0.13155798614025116
step: 590, loss: 0.22578491270542145
step: 600, loss: 0.15163888037204742
step: 610, loss: 0.1656581461429596
step: 620, loss: 0.14070184528827667
step: 630, loss: 0.2792085111141205
step: 640, loss: 0.08925322443246841
step: 650, loss: 0.06872820854187012
step: 660, loss: 0.1482580453157425
step: 670, loss: 0.08759063482284546
step: 680, loss: 0.04506165161728859
step: 690, loss: 0.03952538222074509
step: 700, loss: 0.0816386342048645
step: 710, loss: 0.27452927827835083
step: 720, loss: 0.06315245479345322
step: 730, loss: 0.0899009183049202
step: 740, loss: 0.03184283897280693
step: 750, loss: 0.07041696459054947
step: 760, loss: 0.1386856734752655
step: 770, loss: 0.10234233736991882
step: 780, loss: 0.16561205685138702
step: 790, loss: 0.06336051225662231
step: 800, loss: 0.1200554296374321
step: 810, loss: 0.31054848432540894
step: 820, loss: 0.029272641986608505
step: 830, loss: 0.177948459982872
step: 840, loss: 0.1345873326063156
step: 850, loss: 0.08729968965053558
step: 860, loss: 0.06526362150907516
step: 870, loss: 0.20083460211753845
step: 880, loss: 0.09924232214689255
step: 890, loss: 0.11485099047422409
step: 900, loss: 0.22023850679397583
step: 910, loss: 0.028761466965079308
step: 920, loss: 0.15026991069316864
step: 930, loss: 0.08500161021947861
step: 940, loss: 0.09878452122211456
step: 950, loss: 0.2698719799518585
step: 960, loss: 0.12434671819210052
step: 970, loss: 0.12271306663751602
step: 980, loss: 0.128658726811409
step: 990, loss: 0.0696103498339653
step: 1000, loss: 0.03428146615624428
step: 1010, loss: 0.06147003173828125
step: 1020, loss: 0.04563288018107414
step: 1030, loss: 0.11405611783266068
step: 1040, loss: 0.05642094835639
step: 1050, loss: 0.07877761870622635
step: 1060, loss: 0.19331210851669312
step: 1070, loss: 0.13759849965572357
epoch 1: dev_f1=0.9108910891089109, f1=0.9132379248658319, best_f1=0.9132379248658319
step: 0, loss: 0.06114377826452255
step: 10, loss: 0.11104314029216766
step: 20, loss: 0.09314668923616409
step: 30, loss: 0.1216939389705658
step: 40, loss: 0.08574327826499939
step: 50, loss: 0.17947889864444733
step: 60, loss: 0.05099267140030861
step: 70, loss: 0.10628288239240646
step: 80, loss: 0.08555324375629425
step: 90, loss: 0.14959603548049927
step: 100, loss: 0.09067980945110321
step: 110, loss: 0.06325285136699677
step: 120, loss: 0.06080890819430351
step: 130, loss: 0.113428495824337
step: 140, loss: 0.1801319420337677
step: 150, loss: 0.06579092144966125
step: 160, loss: 0.07711214572191238
step: 170, loss: 0.08241734653711319
step: 180, loss: 0.024876756593585014
step: 190, loss: 0.06412901729345322
step: 200, loss: 0.12556305527687073
step: 210, loss: 0.1352856606245041
step: 220, loss: 0.1589638739824295
step: 230, loss: 0.17203928530216217
step: 240, loss: 0.11850012838840485
step: 250, loss: 0.07439211010932922
step: 260, loss: 0.11909755319356918
step: 270, loss: 0.01967601850628853
step: 280, loss: 0.18689483404159546
step: 290, loss: 0.08876747637987137
step: 300, loss: 0.10371113568544388
step: 310, loss: 0.06726270914077759
step: 320, loss: 0.06121097877621651
step: 330, loss: 0.10208059847354889
step: 340, loss: 0.05216625705361366
step: 350, loss: 0.11808550357818604
step: 360, loss: 0.10766785591840744
step: 370, loss: 0.04389933496713638
step: 380, loss: 0.06936295330524445
step: 390, loss: 0.00905991904437542
step: 400, loss: 0.17705729603767395
step: 410, loss: 0.15439139306545258
step: 420, loss: 0.13335254788398743
step: 430, loss: 0.03685491904616356
step: 440, loss: 0.0909288078546524
step: 450, loss: 0.04281415045261383
step: 460, loss: 0.15904681384563446
step: 470, loss: 0.02388443984091282
step: 480, loss: 0.1466568112373352
step: 490, loss: 0.022871825844049454
step: 500, loss: 0.1530616730451584
step: 510, loss: 0.02065890282392502
step: 520, loss: 0.0044576553627848625
step: 530, loss: 0.11175493896007538
step: 540, loss: 0.022792208939790726
step: 550, loss: 0.08946478366851807
step: 560, loss: 0.12413125485181808
step: 570, loss: 0.11814083904027939
step: 580, loss: 0.11880847811698914
step: 590, loss: 0.09004393965005875
step: 600, loss: 0.04500913619995117
step: 610, loss: 0.026540333405137062
step: 620, loss: 0.06133345887064934
step: 630, loss: 0.20362266898155212
step: 640, loss: 0.07229475677013397
step: 650, loss: 0.26464325189590454
step: 660, loss: 0.08856996148824692
step: 670, loss: 0.06559009104967117
step: 680, loss: 0.08843401074409485
step: 690, loss: 0.07668764889240265
step: 700, loss: 0.12644924223423004
step: 710, loss: 0.09721754491329193
step: 720, loss: 0.011973186396062374
step: 730, loss: 0.05512431636452675
step: 740, loss: 0.08920551091432571
step: 750, loss: 0.14296729862689972
step: 760, loss: 0.050961051136255264
step: 770, loss: 0.03019389510154724
step: 780, loss: 0.011725158430635929
step: 790, loss: 0.3083341419696808
step: 800, loss: 0.10471400618553162
step: 810, loss: 0.08163685351610184
step: 820, loss: 0.13216860592365265
step: 830, loss: 0.0787225216627121
step: 840, loss: 0.1238880604505539
step: 850, loss: 0.09935765713453293
step: 860, loss: 0.017051437869668007
step: 870, loss: 0.07189422845840454
step: 880, loss: 0.03343752399086952
step: 890, loss: 0.12361609190702438
step: 900, loss: 0.08584807813167572
step: 910, loss: 0.012475713156163692
step: 920, loss: 0.05451471731066704
step: 930, loss: 0.034335941076278687
step: 940, loss: 0.10231664031744003
step: 950, loss: 0.08730115741491318
step: 960, loss: 0.1905365139245987
step: 970, loss: 0.08225592225790024
step: 980, loss: 0.11337273567914963
step: 990, loss: 0.09372836351394653
step: 1000, loss: 0.16833624243736267
step: 1010, loss: 0.06881158798933029
step: 1020, loss: 0.017012400552630424
step: 1030, loss: 0.033916763961315155
step: 1040, loss: 0.09239911288022995
step: 1050, loss: 0.03980483114719391
step: 1060, loss: 0.04269479215145111
step: 1070, loss: 0.04726577177643776
epoch 2: dev_f1=0.9317453046266607, f1=0.9338805289557685, best_f1=0.9338805289557685
step: 0, loss: 0.03804595768451691
step: 10, loss: 0.010717888362705708
step: 20, loss: 0.14103925228118896
step: 30, loss: 0.05491803213953972
step: 40, loss: 0.017534174025058746
step: 50, loss: 0.0615457147359848
step: 60, loss: 0.04708309471607208
step: 70, loss: 0.06271983683109283
step: 80, loss: 0.03046575002372265
step: 90, loss: 0.0546506904065609
step: 100, loss: 0.12415439635515213
step: 110, loss: 0.06406862288713455
step: 120, loss: 0.073830746114254
step: 130, loss: 0.02668798714876175
step: 140, loss: 0.031175266951322556
step: 150, loss: 0.14657998085021973
step: 160, loss: 0.09863552451133728
step: 170, loss: 0.043465130031108856
step: 180, loss: 0.00886642187833786
step: 190, loss: 0.041154228150844574
step: 200, loss: 0.06384316831827164
step: 210, loss: 0.20915409922599792
step: 220, loss: 0.013424621894955635
step: 230, loss: 0.14090079069137573
step: 240, loss: 0.09540484845638275
step: 250, loss: 0.3263549208641052
step: 260, loss: 0.03532939404249191
step: 270, loss: 0.11561992764472961
step: 280, loss: 0.09054255485534668
step: 290, loss: 0.08250211179256439
step: 300, loss: 0.14099472761154175
step: 310, loss: 0.01872233673930168
step: 320, loss: 0.22704558074474335
step: 330, loss: 0.11871825158596039
step: 340, loss: 0.043103840202093124
step: 350, loss: 0.06735537201166153
step: 360, loss: 0.025426669046282768
step: 370, loss: 0.10587461292743683
step: 380, loss: 0.09582971781492233
step: 390, loss: 0.1766340583562851
step: 400, loss: 0.020822761580348015
step: 410, loss: 0.02860526368021965
step: 420, loss: 0.019325435161590576
step: 430, loss: 0.06615280359983444
step: 440, loss: 0.0239785835146904
step: 450, loss: 0.20460473001003265
step: 460, loss: 0.08859096467494965
step: 470, loss: 0.030935538932681084
step: 480, loss: 0.025091489776968956
step: 490, loss: 0.02829834632575512
step: 500, loss: 0.05537081137299538
step: 510, loss: 0.060096241533756256
step: 520, loss: 0.10658898949623108
step: 530, loss: 0.15620732307434082
step: 540, loss: 0.15392819046974182
step: 550, loss: 0.08058425784111023
step: 560, loss: 0.019442494958639145
step: 570, loss: 0.12042555212974548
step: 580, loss: 0.10064838081598282
step: 590, loss: 7.234993245219812e-05
step: 600, loss: 0.03161292523145676
step: 610, loss: 0.016832150518894196
step: 620, loss: 0.014867358841001987
step: 630, loss: 0.09142588078975677
step: 640, loss: 0.1658937782049179
step: 650, loss: 0.13077621161937714
step: 660, loss: 0.06760752946138382
step: 670, loss: 0.09793909639120102
step: 680, loss: 0.07172071188688278
step: 690, loss: 0.04005534201860428
step: 700, loss: 0.2635338306427002
step: 710, loss: 0.05832469090819359
step: 720, loss: 0.02774803712964058
step: 730, loss: 0.09019749611616135
step: 740, loss: 0.09948685765266418
step: 750, loss: 0.07888826727867126
step: 760, loss: 0.1119212955236435
step: 770, loss: 0.19675306975841522
step: 780, loss: 0.031001456081867218
step: 790, loss: 0.10651037842035294
step: 800, loss: 0.37819939851760864
step: 810, loss: 0.10506334900856018
step: 820, loss: 0.027260277420282364
step: 830, loss: 0.023033397272229195
step: 840, loss: 0.015083357691764832
step: 850, loss: 0.06458504498004913
step: 860, loss: 0.11414507031440735
step: 870, loss: 0.04121755436062813
step: 880, loss: 0.09443069994449615
step: 890, loss: 0.07503383606672287
step: 900, loss: 0.12592458724975586
step: 910, loss: 0.08822010457515717
step: 920, loss: 0.014040161855518818
step: 930, loss: 0.0950278639793396
step: 940, loss: 0.13742230832576752
step: 950, loss: 0.06481573730707169
step: 960, loss: 0.010031094774603844
step: 970, loss: 0.10118270665407181
step: 980, loss: 0.0661025121808052
step: 990, loss: 0.11168379336595535
step: 1000, loss: 0.03495647385716438
step: 1010, loss: 0.16491733491420746
step: 1020, loss: 0.024182412773370743
step: 1030, loss: 0.015783607959747314
step: 1040, loss: 0.07791274040937424
step: 1050, loss: 0.0156659334897995
step: 1060, loss: 0.05785474553704262
step: 1070, loss: 0.06313393265008926
epoch 3: dev_f1=0.9360709286047598, f1=0.9425925925925925, best_f1=0.9425925925925925
step: 0, loss: 0.11876646429300308
step: 10, loss: 0.07422778755426407
step: 20, loss: 0.07029249519109726
step: 30, loss: 0.06693395227193832
step: 40, loss: 0.06314308941364288
step: 50, loss: 0.028930513188242912
step: 60, loss: 0.058896828442811966
step: 70, loss: 0.07394237071275711
step: 80, loss: 0.021244879812002182
step: 90, loss: 0.003720484208315611
step: 100, loss: 0.016778744757175446
step: 110, loss: 0.04990449175238609
step: 120, loss: 0.05748536065220833
step: 130, loss: 0.07703003287315369
step: 140, loss: 0.13971024751663208
step: 150, loss: 0.15253837406635284
step: 160, loss: 0.1485300362110138
step: 170, loss: 0.13179296255111694
step: 180, loss: 0.04152372479438782
step: 190, loss: 0.007454711478203535
step: 200, loss: 0.04880518466234207
step: 210, loss: 0.025229446589946747
step: 220, loss: 0.09415969997644424
step: 230, loss: 0.09539615362882614
step: 240, loss: 0.0895826444029808
step: 250, loss: 0.06105174496769905
step: 260, loss: 0.1446114033460617
step: 270, loss: 0.050532661378383636
step: 280, loss: 0.06098711118102074
step: 290, loss: 0.09452889859676361
step: 300, loss: 0.010713910683989525
step: 310, loss: 0.07052355259656906
step: 320, loss: 0.012703021988272667
step: 330, loss: 0.023319412022829056
step: 340, loss: 0.05317959561944008
step: 350, loss: 0.11293324828147888
step: 360, loss: 0.15521161258220673
step: 370, loss: 0.03642597049474716
step: 380, loss: 0.03470878303050995
step: 390, loss: 0.027614498510956764
step: 400, loss: 0.08005322515964508
step: 410, loss: 0.044605135917663574
step: 420, loss: 0.11969320476055145
step: 430, loss: 0.14654603600502014
step: 440, loss: 0.10416021198034286
step: 450, loss: 0.022877853363752365
step: 460, loss: 0.1615930199623108
step: 470, loss: 0.10081638395786285
step: 480, loss: 0.05185816437005997
step: 490, loss: 0.013682881370186806
step: 500, loss: 0.007875995710492134
step: 510, loss: 0.05691828206181526
step: 520, loss: 0.12434078752994537
step: 530, loss: 0.05793136730790138
step: 540, loss: 0.0650210827589035
step: 550, loss: 0.0898936539888382
step: 560, loss: 0.019695965573191643
step: 570, loss: 0.020887870341539383
step: 580, loss: 0.21088555455207825
step: 590, loss: 0.04688316211104393
step: 600, loss: 0.04581393301486969
step: 610, loss: 0.040189266204833984
step: 620, loss: 0.013618195429444313
step: 630, loss: 0.02533477544784546
step: 640, loss: 0.040104515850543976
step: 650, loss: 0.04759136587381363
step: 660, loss: 0.02700130082666874
step: 670, loss: 0.005319515708833933
step: 680, loss: 0.03875366225838661
step: 690, loss: 0.10386714339256287
step: 700, loss: 0.13935767114162445
step: 710, loss: 0.03280840069055557
step: 720, loss: 0.06349454820156097
step: 730, loss: 0.0830925852060318
step: 740, loss: 0.047688648104667664
step: 750, loss: 0.10660607367753983
step: 760, loss: 0.08749108761548996
step: 770, loss: 0.024831335991621017
step: 780, loss: 0.08254612237215042
step: 790, loss: 0.11067485809326172
step: 800, loss: 0.047733135521411896
step: 810, loss: 0.029360707849264145
step: 820, loss: 0.011355923488736153
step: 830, loss: 0.0896342322230339
step: 840, loss: 0.0732559859752655
step: 850, loss: 0.05006016045808792
step: 860, loss: 0.003770100651308894
step: 870, loss: 0.13973145186901093
step: 880, loss: 0.11191833764314651
step: 890, loss: 0.022957710549235344
step: 900, loss: 0.09995568543672562
step: 910, loss: 0.03235466033220291
step: 920, loss: 0.08424726873636246
step: 930, loss: 0.11563548445701599
step: 940, loss: 0.13738219439983368
step: 950, loss: 0.09688232839107513
step: 960, loss: 0.13519121706485748
step: 970, loss: 0.05128553882241249
step: 980, loss: 0.07842064648866653
step: 990, loss: 0.009672167710959911
step: 1000, loss: 0.10171867907047272
step: 1010, loss: 0.06545205414295197
step: 1020, loss: 0.04558699205517769
step: 1030, loss: 0.11858294904232025
step: 1040, loss: 0.036996662616729736
step: 1050, loss: 0.07119571417570114
step: 1060, loss: 0.021088894456624985
step: 1070, loss: 0.056166183203458786
epoch 4: dev_f1=0.9324875396465792, f1=0.9279279279279279, best_f1=0.9425925925925925
step: 0, loss: 0.02986105903983116
step: 10, loss: 0.109265998005867
step: 20, loss: 0.017479421570897102
step: 30, loss: 0.0393909215927124
step: 40, loss: 0.07667628675699234
step: 50, loss: 0.06342911720275879
step: 60, loss: 0.03716827929019928
step: 70, loss: 0.0697232261300087
step: 80, loss: 0.04692172631621361
step: 90, loss: 0.06336658447980881
step: 100, loss: 0.07281406968832016
step: 110, loss: 0.053377360105514526
step: 120, loss: 0.02520613744854927
step: 130, loss: 0.05367287993431091
step: 140, loss: 0.012263454496860504
step: 150, loss: 0.032928239554166794
step: 160, loss: 0.04341312125325203
step: 170, loss: 0.024141058325767517
step: 180, loss: 0.016212699934840202
step: 190, loss: 0.05654870718717575
step: 200, loss: 0.037976011633872986
step: 210, loss: 0.02972661703824997
step: 220, loss: 0.07443704456090927
step: 230, loss: 0.037461139261722565
step: 240, loss: 0.006750444415956736
step: 250, loss: 0.039027031511068344
step: 260, loss: 0.025302212685346603
step: 270, loss: 0.025276193395256996
step: 280, loss: 0.008827277459204197
step: 290, loss: 0.015444155782461166
step: 300, loss: 0.015407619997859001
step: 310, loss: 0.023107022047042847
step: 320, loss: 0.11528702825307846
step: 330, loss: 0.07319731265306473
step: 340, loss: 0.03380552679300308
step: 350, loss: 0.056445058435201645
step: 360, loss: 0.014910558238625526
step: 370, loss: 0.07476981729269028
step: 380, loss: 0.025911865755915642
step: 390, loss: 0.08089907467365265
step: 400, loss: 0.0050757285207509995
step: 410, loss: 0.0944485068321228
step: 420, loss: 0.22733962535858154
step: 430, loss: 0.021665822714567184
step: 440, loss: 0.06030479446053505
step: 450, loss: 0.061281781643629074
step: 460, loss: 0.056712523102760315
step: 470, loss: 0.03938763588666916
step: 480, loss: 0.025316765531897545
step: 490, loss: 0.1293991208076477
step: 500, loss: 0.055388182401657104
step: 510, loss: 0.04321873188018799
step: 520, loss: 0.08911589533090591
step: 530, loss: 0.007173772435635328
step: 540, loss: 0.02073892019689083
step: 550, loss: 0.02303503081202507
step: 560, loss: 0.06965607404708862
step: 570, loss: 0.001555953174829483
step: 580, loss: 0.05603106692433357
step: 590, loss: 0.02423502318561077
step: 600, loss: 0.1695426106452942
step: 610, loss: 0.09329885244369507
step: 620, loss: 0.02034013718366623
step: 630, loss: 0.08317968994379044
step: 640, loss: 0.09750304371118546
step: 650, loss: 0.009787765331566334
step: 660, loss: 0.033741146326065063
step: 670, loss: 0.005861980840563774
step: 680, loss: 0.010611481964588165
step: 690, loss: 0.12150093913078308
step: 700, loss: 0.031525492668151855
step: 710, loss: 0.07169238477945328
step: 720, loss: 0.0003178560873493552
step: 730, loss: 0.06927499175071716
step: 740, loss: 0.008723567239940166
step: 750, loss: 0.01977783441543579
step: 760, loss: 0.014911840669810772
step: 770, loss: 0.016008632257580757
step: 780, loss: 0.019859299063682556
step: 790, loss: 0.01211381983011961
step: 800, loss: 0.0159571785479784
step: 810, loss: 0.17837569117546082
step: 820, loss: 0.010150259360671043
step: 830, loss: 0.04073343053460121
step: 840, loss: 0.0830298513174057
step: 850, loss: 0.12145345658063889
step: 860, loss: 0.021594449877738953
step: 870, loss: 0.05030902847647667
step: 880, loss: 0.041357364505529404
step: 890, loss: 0.05963686853647232
step: 900, loss: 0.07905741035938263
step: 910, loss: 0.07682156562805176
step: 920, loss: 0.11649402230978012
step: 930, loss: 0.03178064525127411
step: 940, loss: 0.17362795770168304
step: 950, loss: 0.034313175827264786
step: 960, loss: 0.037273526191711426
step: 970, loss: 0.10996633768081665
step: 980, loss: 0.0076398164965212345
step: 990, loss: 0.08912887424230576
step: 1000, loss: 0.00032863387605175376
step: 1010, loss: 0.003182058921083808
step: 1020, loss: 0.007736880332231522
step: 1030, loss: 0.06611106544733047
step: 1040, loss: 0.057858679443597794
step: 1050, loss: 0.04314974322915077
step: 1060, loss: 0.03020797297358513
step: 1070, loss: 0.0763777643442154
epoch 5: dev_f1=0.9370114942528737, f1=0.9321723189734189, best_f1=0.9321723189734189
step: 0, loss: 0.016104422509670258
step: 10, loss: 0.15086497366428375
step: 20, loss: 0.01696929708123207
step: 30, loss: 0.00878811813890934
step: 40, loss: 0.029112471267580986
step: 50, loss: 0.14640025794506073
step: 60, loss: 0.0996364876627922
step: 70, loss: 0.049439914524555206
step: 80, loss: 0.013308823108673096
step: 90, loss: 0.031800564378499985
step: 100, loss: 0.01902960054576397
step: 110, loss: 0.017084965482354164
step: 120, loss: 0.01660163328051567
step: 130, loss: 0.01467597670853138
step: 140, loss: 0.023413842543959618
step: 150, loss: 0.002945061307400465
step: 160, loss: 0.005176038481295109
step: 170, loss: 0.0062612625770270824
step: 180, loss: 0.07030296325683594
step: 190, loss: 0.08242494612932205
step: 200, loss: 0.023179398849606514
step: 210, loss: 0.11046073585748672
step: 220, loss: 0.10674705356359482
step: 230, loss: 0.09479930251836777
step: 240, loss: 0.12460735440254211
step: 250, loss: 0.03547458350658417
step: 260, loss: 0.028870437294244766
step: 270, loss: 0.017484119161963463
step: 280, loss: 0.0109966229647398
step: 290, loss: 0.06703902035951614
step: 300, loss: 0.010975057259202003
step: 310, loss: 0.10236502438783646
step: 320, loss: 0.028637656942009926
step: 330, loss: 0.00911535881459713
step: 340, loss: 0.15693719685077667
step: 350, loss: 0.07846146821975708
step: 360, loss: 0.0019145298283547163
step: 370, loss: 0.034914080053567886
step: 380, loss: 0.05136970430612564
step: 390, loss: 0.08643212914466858
step: 400, loss: 0.1999676525592804
step: 410, loss: 0.039641350507736206
step: 420, loss: 0.0016049285186454654
step: 430, loss: 0.012913868762552738
step: 440, loss: 0.020981058478355408
step: 450, loss: 0.024844935163855553
step: 460, loss: 0.1746388077735901
step: 470, loss: 0.058811843395233154
step: 480, loss: 0.049910128116607666
step: 490, loss: 0.13884881138801575
step: 500, loss: 0.10901273787021637
step: 510, loss: 0.0685926154255867
step: 520, loss: 0.006097128614783287
step: 530, loss: 0.025083674117922783
step: 540, loss: 0.031353119760751724
step: 550, loss: 0.03644096478819847
step: 560, loss: 0.05140514671802521
step: 570, loss: 0.0368390753865242
step: 580, loss: 0.018072009086608887
step: 590, loss: 0.07200434058904648
step: 600, loss: 0.049284882843494415
step: 610, loss: 0.1069130226969719
step: 620, loss: 0.06415271013975143
step: 630, loss: 0.04572729766368866
step: 640, loss: 0.17901772260665894
step: 650, loss: 0.02381477877497673
step: 660, loss: 0.07726453244686127
step: 670, loss: 0.1614721566438675
step: 680, loss: 0.05883714556694031
step: 690, loss: 0.049998559057712555
step: 700, loss: 0.020048415288329124
step: 710, loss: 0.02747335098683834
step: 720, loss: 0.08033812791109085
step: 730, loss: 0.10355765372514725
step: 740, loss: 0.04563754424452782
step: 750, loss: 0.02268279157578945
step: 760, loss: 0.003187185851857066
step: 770, loss: 0.05596213415265083
step: 780, loss: 0.020081184804439545
step: 790, loss: 0.07726609706878662
step: 800, loss: 0.09278102219104767
step: 810, loss: 0.013931755907833576
step: 820, loss: 0.06311710923910141
step: 830, loss: 0.03837168961763382
step: 840, loss: 0.04264330863952637
step: 850, loss: 0.01637612283229828
step: 860, loss: 0.05661061033606529
step: 870, loss: 0.012802227400243282
step: 880, loss: 0.014339815825223923
step: 890, loss: 0.1551775336265564
step: 900, loss: 0.007786562666296959
step: 910, loss: 0.17068643867969513
step: 920, loss: 0.035425957292318344
step: 930, loss: 0.1115892082452774
step: 940, loss: 0.07589828222990036
step: 950, loss: 0.01732298918068409
step: 960, loss: 0.006863694172352552
step: 970, loss: 0.12131264805793762
step: 980, loss: 0.03833824396133423
step: 990, loss: 0.14720693230628967
step: 1000, loss: 0.05738673731684685
step: 1010, loss: 0.026407834142446518
step: 1020, loss: 0.06829314678907394
step: 1030, loss: 0.022889167070388794
step: 1040, loss: 0.05977480113506317
step: 1050, loss: 0.016303524374961853
step: 1060, loss: 0.09162773191928864
step: 1070, loss: 0.05174606665968895
epoch 6: dev_f1=0.9336426914153132, f1=0.9302973977695168, best_f1=0.9321723189734189
step: 0, loss: 0.05488697439432144
step: 10, loss: 0.07557861506938934
step: 20, loss: 0.041712671518325806
step: 30, loss: 0.08426497876644135
step: 40, loss: 0.014660741202533245
step: 50, loss: 0.0207110196352005
step: 60, loss: 0.04743688553571701
step: 70, loss: 0.019055889919400215
step: 80, loss: 0.15395882725715637
step: 90, loss: 0.016079794615507126
step: 100, loss: 0.005711977835744619
step: 110, loss: 0.07383269816637039
step: 120, loss: 0.08962992578744888
step: 130, loss: 0.015965504571795464
step: 140, loss: 0.004323361441493034
step: 150, loss: 0.007914187386631966
step: 160, loss: 0.05312109366059303
step: 170, loss: 0.015754561871290207
step: 180, loss: 0.0006889381911605597
step: 190, loss: 0.0395226888358593
step: 200, loss: 0.07285352796316147
step: 210, loss: 0.04672073572874069
step: 220, loss: 0.007405659183859825
step: 230, loss: 0.06369589269161224
step: 240, loss: 0.11602631956338882
step: 250, loss: 0.022536074742674828
step: 260, loss: 0.06144076958298683
step: 270, loss: 0.14496111869812012
step: 280, loss: 0.08831080794334412
step: 290, loss: 0.04966745898127556
step: 300, loss: 0.0758286640048027
step: 310, loss: 0.044065605849027634
step: 320, loss: 0.06583583354949951
step: 330, loss: 0.008296762593090534
step: 340, loss: 0.059304554015398026
step: 350, loss: 0.04915887862443924
step: 360, loss: 0.047266777604818344
step: 370, loss: 0.020305830985307693
step: 380, loss: 0.02266470342874527
step: 390, loss: 0.011521631851792336
step: 400, loss: 0.0020270152017474174
step: 410, loss: 0.00963925663381815
step: 420, loss: 0.08204206079244614
step: 430, loss: 0.033542606979608536
step: 440, loss: 0.024784667417407036
step: 450, loss: 0.03408484905958176
step: 460, loss: 0.08115999400615692
step: 470, loss: 0.02235068753361702
step: 480, loss: 0.05758814141154289
step: 490, loss: 0.10595457255840302
step: 500, loss: 0.010736850090324879
step: 510, loss: 0.12111556529998779
step: 520, loss: 0.05385935306549072
step: 530, loss: 0.003679942572489381
step: 540, loss: 0.06738672405481339
step: 550, loss: 0.017838463187217712
step: 560, loss: 0.060861822217702866
step: 570, loss: 0.07850279659032822
step: 580, loss: 0.032488640397787094
step: 590, loss: 0.0363164097070694
step: 600, loss: 0.022530805319547653
step: 610, loss: 0.03256324678659439
step: 620, loss: 0.014582113362848759
step: 630, loss: 0.07823894917964935
step: 640, loss: 0.019811999052762985
step: 650, loss: 0.010136781260371208
step: 660, loss: 0.07225634902715683
step: 670, loss: 0.09376167505979538
step: 680, loss: 0.1036335751414299
step: 690, loss: 0.06404075026512146
step: 700, loss: 0.09820528328418732
step: 710, loss: 0.045966118574142456
step: 720, loss: 0.0006261303788051009
step: 730, loss: 0.020862599834799767
step: 740, loss: 0.08772001415491104
step: 750, loss: 0.1124376729130745
step: 760, loss: 0.05187001824378967
step: 770, loss: 0.03608355671167374
step: 780, loss: 0.0342758446931839
step: 790, loss: 0.06591575592756271
step: 800, loss: 0.0323915034532547
step: 810, loss: 0.088900625705719
step: 820, loss: 0.24733786284923553
step: 830, loss: 0.0998910441994667
step: 840, loss: 0.00014066288713365793
step: 850, loss: 0.04253150522708893
step: 860, loss: 0.15541686117649078
step: 870, loss: 0.025092318654060364
step: 880, loss: 0.12808775901794434
step: 890, loss: 0.05660606548190117
step: 900, loss: 0.08182572573423386
step: 910, loss: 0.046228379011154175
step: 920, loss: 0.011936540715396404
step: 930, loss: 0.012733064591884613
step: 940, loss: 0.040227409452199936
step: 950, loss: 0.06252148747444153
step: 960, loss: 0.15895789861679077
step: 970, loss: 0.007884562015533447
step: 980, loss: 0.00624699704349041
step: 990, loss: 0.02831340581178665
step: 1000, loss: 0.11589740961790085
step: 1010, loss: 0.05070684850215912
step: 1020, loss: 0.062213096767663956
step: 1030, loss: 0.04718770086765289
step: 1040, loss: 0.017143141478300095
step: 1050, loss: 0.014340542256832123
step: 1060, loss: 0.048341553658246994
step: 1070, loss: 0.03756263479590416
epoch 7: dev_f1=0.9342857142857143, f1=0.924618320610687, best_f1=0.9321723189734189
step: 0, loss: 0.04903659224510193
step: 10, loss: 0.06491193175315857
step: 20, loss: 0.013034462928771973
step: 30, loss: 0.00218199216760695
step: 40, loss: 0.03744439408183098
step: 50, loss: 0.06909240782260895
step: 60, loss: 0.037185247987508774
step: 70, loss: 0.05975575000047684
step: 80, loss: 0.02811717614531517
step: 90, loss: 0.053470298647880554
step: 100, loss: 0.19049383699893951
step: 110, loss: 0.15307928621768951
step: 120, loss: 0.0171930231153965
step: 130, loss: 0.15199656784534454
step: 140, loss: 0.0017879223451018333
step: 150, loss: 0.03912118077278137
step: 160, loss: 0.1063227578997612
step: 170, loss: 0.14694415032863617
step: 180, loss: 0.030290478840470314
step: 190, loss: 0.06338782608509064
step: 200, loss: 0.12288471311330795
step: 210, loss: 0.00757124088704586
step: 220, loss: 0.0032542343251407146
step: 230, loss: 0.12440875172615051
step: 240, loss: 0.039267368614673615
step: 250, loss: 0.00830615684390068
step: 260, loss: 0.014659994281828403
step: 270, loss: 0.2369215339422226
step: 280, loss: 0.0047325193881988525
step: 290, loss: 0.05727731063961983
step: 300, loss: 0.07605638355016708
step: 310, loss: 0.09255719929933548
step: 320, loss: 0.05747862532734871
step: 330, loss: 0.009933865629136562
step: 340, loss: 0.0027138590812683105
step: 350, loss: 0.0717780739068985
step: 360, loss: 0.0595373660326004
step: 370, loss: 0.10871043801307678
step: 380, loss: 0.06272406131029129
step: 390, loss: 0.05155044049024582
step: 400, loss: 0.01345047913491726
step: 410, loss: 0.013799280859529972
step: 420, loss: 0.048744142055511475
step: 430, loss: 0.007007203996181488
step: 440, loss: 0.01298733800649643
step: 450, loss: 0.08095116913318634
step: 460, loss: 0.30545228719711304
step: 470, loss: 0.052800968289375305
step: 480, loss: 0.09024351835250854
step: 490, loss: 0.004469888284802437
step: 500, loss: 0.0045621879398822784
step: 510, loss: 0.01406758464872837
step: 520, loss: 0.14575302600860596
step: 530, loss: 0.008427475579082966
step: 540, loss: 0.012358730658888817
step: 550, loss: 0.02965199574828148
step: 560, loss: 0.08208529651165009
step: 570, loss: 0.05167587846517563
step: 580, loss: 0.017562944442033768
step: 590, loss: 0.08665239810943604
step: 600, loss: 0.12464918196201324
step: 610, loss: 0.018277648836374283
step: 620, loss: 0.09715958684682846
step: 630, loss: 0.018244247883558273
step: 640, loss: 0.012419842183589935
step: 650, loss: 0.1060488149523735
step: 660, loss: 0.026114588603377342
step: 670, loss: 0.012201901525259018
step: 680, loss: 0.025169704109430313
step: 690, loss: 0.008918936364352703
step: 700, loss: 0.015303244814276695
step: 710, loss: 0.0478692501783371
step: 720, loss: 0.002205747878178954
step: 730, loss: 0.07627135515213013
step: 740, loss: 0.06922716647386551
step: 750, loss: 0.04464093968272209
step: 760, loss: 0.06242340803146362
step: 770, loss: 0.04881567135453224
step: 780, loss: 0.15719330310821533
step: 790, loss: 0.0638217106461525
step: 800, loss: 0.04583996161818504
step: 810, loss: 0.01889769919216633
step: 820, loss: 0.06687144935131073
step: 830, loss: 0.0007358089205808938
step: 840, loss: 0.02864168770611286
step: 850, loss: 0.05278416723012924
step: 860, loss: 0.023626994341611862
step: 870, loss: 0.012135544791817665
step: 880, loss: 0.053169287741184235
step: 890, loss: 0.061069946736097336
step: 900, loss: 0.09969040751457214
step: 910, loss: 0.013774668797850609
step: 920, loss: 0.06655199080705643
step: 930, loss: 0.023945869877934456
step: 940, loss: 0.00024354115885216743
step: 950, loss: 0.09663204103708267
step: 960, loss: 0.08317098021507263
step: 970, loss: 0.022189175710082054
step: 980, loss: 0.018490979447960854
step: 990, loss: 0.017556950449943542
step: 1000, loss: 0.04159505292773247
step: 1010, loss: 0.04915129393339157
step: 1020, loss: 0.0064348746091127396
step: 1030, loss: 0.011861024424433708
step: 1040, loss: 0.0244732778519392
step: 1050, loss: 0.05280635878443718
step: 1060, loss: 0.030011380091309547
step: 1070, loss: 0.10134311020374298
epoch 8: dev_f1=0.9371215649743828, f1=0.9298245614035088, best_f1=0.9298245614035088
step: 0, loss: 0.016052190214395523
step: 10, loss: 0.07623842358589172
step: 20, loss: 0.12614552676677704
step: 30, loss: 0.060854315757751465
step: 40, loss: 0.05090368911623955
step: 50, loss: 0.012395755387842655
step: 60, loss: 0.041280824691057205
step: 70, loss: 0.005232653580605984
step: 80, loss: 0.025286642834544182
step: 90, loss: 0.003673835191875696
step: 100, loss: 0.006099849008023739
step: 110, loss: 0.01602558046579361
step: 120, loss: 0.07721807807683945
step: 130, loss: 0.00913380179554224
step: 140, loss: 0.05997708812355995
step: 150, loss: 0.0023108175955712795
step: 160, loss: 0.13860656321048737
step: 170, loss: 0.01231719646602869
step: 180, loss: 0.0791458711028099
step: 190, loss: 0.03220660239458084
step: 200, loss: 0.0937720239162445
step: 210, loss: 0.17866183817386627
step: 220, loss: 0.05100294575095177
step: 230, loss: 0.012358471751213074
step: 240, loss: 0.028552331030368805
step: 250, loss: 0.0007159436354413629
step: 260, loss: 0.07905832678079605
step: 270, loss: 0.013551331125199795
step: 280, loss: 0.05444483086466789
step: 290, loss: 0.179191455245018
step: 300, loss: 0.01195484772324562
step: 310, loss: 0.09021659195423126
step: 320, loss: 0.027198150753974915
step: 330, loss: 0.00624005775898695
step: 340, loss: 0.06771469116210938
step: 350, loss: 0.030168842524290085
step: 360, loss: 0.03628413379192352
step: 370, loss: 0.027991635724902153
step: 380, loss: 0.068931944668293
step: 390, loss: 0.02781219780445099
step: 400, loss: 0.07642486691474915
step: 410, loss: 0.04147152602672577
step: 420, loss: 0.0022801589220762253
step: 430, loss: 0.03520894795656204
step: 440, loss: 0.04249746352434158
step: 450, loss: 0.054104555398225784
step: 460, loss: 0.06563003361225128
step: 470, loss: 0.0077585321851074696
step: 480, loss: 0.04327565059065819
step: 490, loss: 0.07292690873146057
step: 500, loss: 0.0839366689324379
step: 510, loss: 0.03763223811984062
step: 520, loss: 0.004349964205175638
step: 530, loss: 0.0001348626974504441
step: 540, loss: 0.01988326385617256
step: 550, loss: 0.03217807784676552
step: 560, loss: 0.0505870096385479
step: 570, loss: 0.019485212862491608
step: 580, loss: 0.017478235065937042
step: 590, loss: 0.03651824966073036
step: 600, loss: 0.019281474873423576
step: 610, loss: 0.03162741661071777
step: 620, loss: 0.12223950773477554
step: 630, loss: 0.03485298529267311
step: 640, loss: 0.11749553680419922
step: 650, loss: 0.036220524460077286
step: 660, loss: 0.0361206941306591
step: 670, loss: 0.05232646316289902
step: 680, loss: 0.032166484743356705
step: 690, loss: 0.02518404647707939
step: 700, loss: 0.024892861023545265
step: 710, loss: 0.00500640831887722
step: 720, loss: 0.020409906283020973
step: 730, loss: 0.02772204391658306
step: 740, loss: 0.02825292944908142
step: 750, loss: 0.05844639986753464
step: 760, loss: 0.09986522793769836
step: 770, loss: 0.006230346858501434
step: 780, loss: 0.0010190021712332964
step: 790, loss: 4.1835908632492647e-05
step: 800, loss: 0.04765123873949051
step: 810, loss: 0.056186430156230927
step: 820, loss: 0.14649270474910736
step: 830, loss: 0.015451434999704361
step: 840, loss: 0.01227252371609211
step: 850, loss: 0.0017911894246935844
step: 860, loss: 0.048662230372428894
step: 870, loss: 0.008706128224730492
step: 880, loss: 0.22943489253520966
step: 890, loss: 0.054140593856573105
step: 900, loss: 0.030190419405698776
step: 910, loss: 0.037602487951517105
step: 920, loss: 0.0724821612238884
step: 930, loss: 0.021743105724453926
step: 940, loss: 0.07475923746824265
step: 950, loss: 0.032157979905605316
step: 960, loss: 0.014692745171487331
step: 970, loss: 0.11862336844205856
step: 980, loss: 0.07599049806594849
step: 990, loss: 0.0007419214234687388
step: 1000, loss: 0.01942574977874756
step: 1010, loss: 0.019100716337561607
step: 1020, loss: 0.006407216191291809
step: 1030, loss: 0.028252221643924713
step: 1040, loss: 0.05953380838036537
step: 1050, loss: 0.2042887955904007
step: 1060, loss: 0.0005678998422808945
step: 1070, loss: 0.0684422105550766
epoch 9: dev_f1=0.9330232558139535, f1=0.9268518518518517, best_f1=0.9298245614035088
step: 0, loss: 0.06248633190989494
step: 10, loss: 0.01182921789586544
step: 20, loss: 0.026682235300540924
step: 30, loss: 0.0019137045601382852
step: 40, loss: 0.01841101236641407
step: 50, loss: 0.05826269090175629
step: 60, loss: 0.03163088485598564
step: 70, loss: 0.004223594907671213
step: 80, loss: 0.01809115894138813
step: 90, loss: 0.016579508781433105
step: 100, loss: 0.033443354070186615
step: 110, loss: 0.03684691712260246
step: 120, loss: 0.04573784023523331
step: 130, loss: 0.032474588602781296
step: 140, loss: 0.002285036025568843
step: 150, loss: 0.01976628229022026
step: 160, loss: 0.00814488809555769
step: 170, loss: 0.03079039789736271
step: 180, loss: 0.002028695773333311
step: 190, loss: 0.002217178698629141
step: 200, loss: 0.042431555688381195
step: 210, loss: 0.09524457901716232
step: 220, loss: 0.08199174702167511
step: 230, loss: 0.006070714443922043
step: 240, loss: 0.010575160384178162
step: 250, loss: 0.07328443229198456
step: 260, loss: 0.03430090472102165
step: 270, loss: 0.00010049258708022535
step: 280, loss: 0.09316454827785492
step: 290, loss: 0.020743492990732193
step: 300, loss: 0.07107990980148315
step: 310, loss: 0.00018273179011885077
step: 320, loss: 0.049221236258745193
step: 330, loss: 0.10602886974811554
step: 340, loss: 0.04796876758337021
step: 350, loss: 0.10125424712896347
step: 360, loss: 0.05195622891187668
step: 370, loss: 0.10991745442152023
step: 380, loss: 0.057195570319890976
step: 390, loss: 0.024605222046375275
step: 400, loss: 0.09384160488843918
step: 410, loss: 0.08779796957969666
step: 420, loss: 0.061507053673267365
step: 430, loss: 0.10080631822347641
step: 440, loss: 0.04473905265331268
step: 450, loss: 0.021445920690894127
step: 460, loss: 0.020376520231366158
step: 470, loss: 0.026549847796559334
step: 480, loss: 0.02976182848215103
step: 490, loss: 0.02340245060622692
step: 500, loss: 0.017434483394026756
step: 510, loss: 0.03871319070458412
step: 520, loss: 0.02445506863296032
step: 530, loss: 0.07202274352312088
step: 540, loss: 0.15355175733566284
step: 550, loss: 0.0004942199448123574
step: 560, loss: 0.0024610571563243866
step: 570, loss: 0.14169195294380188
step: 580, loss: 0.03501454368233681
step: 590, loss: 0.16131232678890228
step: 600, loss: 0.10153178125619888
step: 610, loss: 0.02059628628194332
step: 620, loss: 0.03930531069636345
step: 630, loss: 6.231872248463333e-05
step: 640, loss: 0.09123188257217407
step: 650, loss: 0.03214584290981293
step: 660, loss: 0.01645161770284176
step: 670, loss: 0.0320870466530323
step: 680, loss: 0.0976840928196907
step: 690, loss: 2.9298398658283986e-05
step: 700, loss: 0.04842107743024826
step: 710, loss: 0.007755370810627937
step: 720, loss: 0.0951911211013794
step: 730, loss: 0.0058782403357326984
step: 740, loss: 0.002093652496114373
step: 750, loss: 0.05603186786174774
step: 760, loss: 0.02819143980741501
step: 770, loss: 0.02941574715077877
step: 780, loss: 0.0814981460571289
step: 790, loss: 0.05190197750926018
step: 800, loss: 0.028433166444301605
step: 810, loss: 0.050827838480472565
step: 820, loss: 0.0201493538916111
step: 830, loss: 0.014379228465259075
step: 840, loss: 0.02690708637237549
step: 850, loss: 0.007990487851202488
step: 860, loss: 0.02246343344449997
step: 870, loss: 0.06265401840209961
step: 880, loss: 0.04222641885280609
step: 890, loss: 0.04373127222061157
step: 900, loss: 0.05677083879709244
step: 910, loss: 0.00014329631812870502
step: 920, loss: 0.04615958780050278
step: 930, loss: 0.029282769188284874
step: 940, loss: 0.061459239572286606
step: 950, loss: 0.10469149053096771
step: 960, loss: 0.0002840916276909411
step: 970, loss: 0.014374179765582085
step: 980, loss: 0.039758238941431046
step: 990, loss: 0.011487304233014584
step: 1000, loss: 0.06419286131858826
step: 1010, loss: 0.07981622964143753
step: 1020, loss: 0.0858127623796463
step: 1030, loss: 0.035947516560554504
step: 1040, loss: 0.04766346886754036
step: 1050, loss: 0.03980925306677818
step: 1060, loss: 0.01973811723291874
step: 1070, loss: 0.07571721822023392
epoch 10: dev_f1=0.9367789570835257, f1=0.9254829806807728, best_f1=0.9298245614035088
step: 0, loss: 0.019579274579882622
step: 10, loss: 0.01986885443329811
step: 20, loss: 0.03687451407313347
step: 30, loss: 0.009178844280540943
step: 40, loss: 0.035764776170253754
step: 50, loss: 0.05026380345225334
step: 60, loss: 0.0016327190678566694
step: 70, loss: 0.09640850871801376
step: 80, loss: 0.01232916209846735
step: 90, loss: 0.059135548770427704
step: 100, loss: 0.03712084889411926
step: 110, loss: 0.015305154956877232
step: 120, loss: 0.03143124282360077
step: 130, loss: 0.05768072232604027
step: 140, loss: 6.533868872793391e-05
step: 150, loss: 0.035776421427726746
step: 160, loss: 0.00014355806342791766
step: 170, loss: 0.09228014200925827
step: 180, loss: 0.0718616247177124
step: 190, loss: 0.043356750160455704
step: 200, loss: 0.03400934487581253
step: 210, loss: 0.034281667321920395
step: 220, loss: 0.002088980982080102
step: 230, loss: 0.06094491854310036
step: 240, loss: 0.037683356553316116
step: 250, loss: 0.0681300088763237
step: 260, loss: 0.0343366414308548
step: 270, loss: 0.034140996634960175
step: 280, loss: 0.04482609033584595
step: 290, loss: 0.018147628754377365
step: 300, loss: 0.022700363770127296
step: 310, loss: 0.0007899754564277828
step: 320, loss: 0.010964298620820045
step: 330, loss: 0.028081823140382767
step: 340, loss: 0.06614986062049866
step: 350, loss: 0.006833766121417284
step: 360, loss: 0.015876656398177147
step: 370, loss: 0.025482337921857834
step: 380, loss: 0.07737690955400467
step: 390, loss: 0.07976467907428741
step: 400, loss: 0.031392961740493774
step: 410, loss: 0.01400086935609579
step: 420, loss: 0.023983146995306015
step: 430, loss: 0.016601474955677986
step: 440, loss: 0.013723429292440414
step: 450, loss: 0.07590727508068085
step: 460, loss: 0.04292714595794678
step: 470, loss: 0.001087173237465322
step: 480, loss: 0.016616206616163254
step: 490, loss: 0.04905404895544052
step: 500, loss: 0.01848146691918373
step: 510, loss: 0.027088550850749016
step: 520, loss: 3.517261575325392e-05
step: 530, loss: 0.011747288517653942
step: 540, loss: 0.013807912357151508
step: 550, loss: 0.027037134394049644
step: 560, loss: 0.00029393177828751504
step: 570, loss: 0.0781269297003746
step: 580, loss: 0.07543349266052246
step: 590, loss: 0.06546750664710999
step: 600, loss: 0.04591890424489975
step: 610, loss: 0.04844040051102638
step: 620, loss: 0.0607353150844574
step: 630, loss: 0.04917905479669571
step: 640, loss: 0.06831866502761841
step: 650, loss: 0.011480163782835007
step: 660, loss: 0.157828688621521
step: 670, loss: 0.04849819839000702
step: 680, loss: 0.04339030757546425
step: 690, loss: 0.0016159390797838569
step: 700, loss: 0.04287831485271454
step: 710, loss: 0.0069483621045947075
step: 720, loss: 0.024394648149609566
step: 730, loss: 0.01701481081545353
step: 740, loss: 0.0724480152130127
step: 750, loss: 0.013862177729606628
step: 760, loss: 0.045724280178546906
step: 770, loss: 0.0627063661813736
step: 780, loss: 0.0018860396230593324
step: 790, loss: 0.00011119229020550847
step: 800, loss: 0.00038307326030917466
step: 810, loss: 0.07761505246162415
step: 820, loss: 0.032835375517606735
step: 830, loss: 0.03810228407382965
step: 840, loss: 0.023738805204629898
step: 850, loss: 0.05041498690843582
step: 860, loss: 0.03749588504433632
step: 870, loss: 0.009741077199578285
step: 880, loss: 0.01358482614159584
step: 890, loss: 7.265087333507836e-05
step: 900, loss: 0.08251620829105377
step: 910, loss: 0.026970699429512024
step: 920, loss: 0.0014436765341088176
step: 930, loss: 0.03917495906352997
step: 940, loss: 0.024715658277273178
step: 950, loss: 0.01684810407459736
step: 960, loss: 0.058270592242479324
step: 970, loss: 0.009054525755345821
step: 980, loss: 0.06454446911811829
step: 990, loss: 0.008860429748892784
step: 1000, loss: 0.009575829841196537
step: 1010, loss: 0.002284773625433445
step: 1020, loss: 0.11342941224575043
step: 1030, loss: 0.02504078671336174
step: 1040, loss: 0.02666722796857357
step: 1050, loss: 0.02940518967807293
step: 1060, loss: 0.004531321581453085
step: 1070, loss: 0.014391914941370487
epoch 11: dev_f1=0.9342043863742416, f1=0.9305555555555556, best_f1=0.9298245614035088
step: 0, loss: 0.060096319764852524
step: 10, loss: 0.0311061292886734
step: 20, loss: 0.04227564483880997
step: 30, loss: 0.005559329874813557
step: 40, loss: 0.03688942641019821
step: 50, loss: 0.04868355020880699
step: 60, loss: 0.0684666708111763
step: 70, loss: 0.10136089473962784
step: 80, loss: 0.014251346699893475
step: 90, loss: 0.002376754768192768
step: 100, loss: 0.09109167754650116
step: 110, loss: 0.0006079204613342881
step: 120, loss: 0.00010151392052648589
step: 130, loss: 0.09338080137968063
step: 140, loss: 0.008023181930184364
step: 150, loss: 0.019770009443163872
step: 160, loss: 0.032400183379650116
step: 170, loss: 0.017031190916895866
step: 180, loss: 0.027539853006601334
step: 190, loss: 0.04448111727833748
step: 200, loss: 0.01716437004506588
step: 210, loss: 0.0346490740776062
step: 220, loss: 0.01687762700021267
step: 230, loss: 0.00019336478726472706
step: 240, loss: 0.06873524188995361
step: 250, loss: 0.09359210729598999
step: 260, loss: 0.041498422622680664
step: 270, loss: 0.011717704124748707
step: 280, loss: 0.028610654175281525
step: 290, loss: 0.00048297998728230596
step: 300, loss: 0.02478703297674656
step: 310, loss: 0.02256525680422783
step: 320, loss: 0.0023383868392556906
step: 330, loss: 0.013384433463215828
step: 340, loss: 0.02977214939892292
step: 350, loss: 0.0005161661538295448
step: 360, loss: 0.00010722370643634349
step: 370, loss: 0.02417021244764328
step: 380, loss: 0.005567546933889389
step: 390, loss: 0.028262605890631676
step: 400, loss: 0.018523911014199257
step: 410, loss: 0.025935549288988113
step: 420, loss: 0.020621804520487785
step: 430, loss: 0.05250610411167145
step: 440, loss: 0.0005340434145182371
step: 450, loss: 0.027964062988758087
step: 460, loss: 0.028704918920993805
step: 470, loss: 0.09164497256278992
step: 480, loss: 0.04230780899524689
step: 490, loss: 0.0044637396931648254
step: 500, loss: 0.0009440194698981941
step: 510, loss: 0.020037570968270302
step: 520, loss: 0.03565073758363724
step: 530, loss: 0.0031378385610878468
step: 540, loss: 0.024207722395658493
step: 550, loss: 0.01039024256169796
step: 560, loss: 0.01336217112839222
step: 570, loss: 0.014691255055367947
step: 580, loss: 0.033283594995737076
step: 590, loss: 0.05123614892363548
step: 600, loss: 0.0013954961905255914
step: 610, loss: 0.031111670657992363
step: 620, loss: 0.00017035803466569632
step: 630, loss: 0.06935126334428787
step: 640, loss: 0.023234764114022255
step: 650, loss: 0.015610958449542522
step: 660, loss: 0.039859987795352936
step: 670, loss: 4.760539741255343e-05
step: 680, loss: 0.013449572958052158
step: 690, loss: 0.00010697781544877216
step: 700, loss: 0.02981874719262123
step: 710, loss: 0.00021707400446757674
step: 720, loss: 0.03292776271700859
step: 730, loss: 0.0058054374530911446
step: 740, loss: 1.4189398825692479e-05
step: 750, loss: 0.049428410828113556
step: 760, loss: 0.05214499309659004
step: 770, loss: 0.018161587417125702
step: 780, loss: 0.02146902121603489
step: 790, loss: 1.0829327038663905e-05
step: 800, loss: 0.010811854153871536
step: 810, loss: 0.046491339802742004
step: 820, loss: 0.07181476801633835
step: 830, loss: 0.08579146862030029
step: 840, loss: 0.02024865709245205
step: 850, loss: 0.045338958501815796
step: 860, loss: 0.03446429222822189
step: 870, loss: 0.05328017845749855
step: 880, loss: 0.0008982246508821845
step: 890, loss: 0.028757425025105476
step: 900, loss: 0.06154424697160721
step: 910, loss: 0.07340548932552338
step: 920, loss: 0.012957165017724037
step: 930, loss: 0.05408981814980507
step: 940, loss: 0.016561787575483322
step: 950, loss: 0.23099777102470398
step: 960, loss: 0.03336429223418236
step: 970, loss: 0.055416613817214966
step: 980, loss: 0.031164443120360374
step: 990, loss: 0.04608564078807831
step: 1000, loss: 0.016785426065325737
step: 1010, loss: 0.06815662235021591
step: 1020, loss: 0.00027075907564722
step: 1030, loss: 0.029959416016936302
step: 1040, loss: 0.04403824731707573
step: 1050, loss: 0.004231091123074293
step: 1060, loss: 0.05560425668954849
step: 1070, loss: 0.05409185215830803
epoch 12: dev_f1=0.9330254041570438, f1=0.9281105990783408, best_f1=0.9298245614035088
step: 0, loss: 0.02828318253159523
step: 10, loss: 0.061870086938142776
step: 20, loss: 0.10506026446819305
step: 30, loss: 0.05537402629852295
step: 40, loss: 0.006558700930327177
step: 50, loss: 0.0029318726155906916
step: 60, loss: 0.11170326918363571
step: 70, loss: 0.07795532792806625
step: 80, loss: 0.06391142308712006
step: 90, loss: 0.00045986464829184115
step: 100, loss: 0.029871487990021706
step: 110, loss: 0.01927768997848034
step: 120, loss: 0.06456511467695236
step: 130, loss: 0.004238208755850792
step: 140, loss: 0.01663818582892418
step: 150, loss: 0.03268272429704666
step: 160, loss: 0.027328988537192345
step: 170, loss: 0.01396155171096325
step: 180, loss: 0.059692930430173874
step: 190, loss: 0.08508650213479996
step: 200, loss: 0.027833519503474236
step: 210, loss: 0.030869411304593086
step: 220, loss: 0.026615137234330177
step: 230, loss: 0.03575750067830086
step: 240, loss: 0.0022095260210335255
step: 250, loss: 0.004653474316000938
step: 260, loss: 0.0620114840567112
step: 270, loss: 0.026006925851106644
step: 280, loss: 0.029870957136154175
step: 290, loss: 0.04987097904086113
step: 300, loss: 0.023330384865403175
step: 310, loss: 7.564233237644657e-05
step: 320, loss: 0.02550141140818596
step: 330, loss: 0.020836077630519867
step: 340, loss: 0.046474944800138474
step: 350, loss: 0.00023285731731448323
step: 360, loss: 0.004347189329564571
step: 370, loss: 0.02566220983862877
step: 380, loss: 0.0005265456857159734
step: 390, loss: 4.5646916987607256e-05
step: 400, loss: 0.00134393316693604
step: 410, loss: 0.04974143207073212
step: 420, loss: 0.00046007506898604333
step: 430, loss: 0.044999077916145325
step: 440, loss: 0.06948556005954742
step: 450, loss: 0.002922195941209793
step: 460, loss: 0.013823684304952621
step: 470, loss: 0.00666138157248497
step: 480, loss: 0.03240690380334854
step: 490, loss: 0.0003519694146234542
step: 500, loss: 0.0018466317560523748
step: 510, loss: 0.0003011321241501719
step: 520, loss: 0.14072038233280182
step: 530, loss: 0.01434218231588602
step: 540, loss: 0.10341096669435501
step: 550, loss: 0.00014946171722840518
step: 560, loss: 9.029598004417494e-05
step: 570, loss: 0.012857248075306416
step: 580, loss: 0.10447515547275543
step: 590, loss: 0.04923956096172333
step: 600, loss: 3.258615470258519e-05
step: 610, loss: 0.03216702118515968
step: 620, loss: 0.00027013462386094034
step: 630, loss: 0.12949877977371216
step: 640, loss: 0.03601783514022827
step: 650, loss: 0.0464385487139225
step: 660, loss: 6.040593143552542e-05
step: 670, loss: 0.018855327740311623
step: 680, loss: 0.011926785111427307
step: 690, loss: 0.012712705880403519
step: 700, loss: 0.06524710357189178
step: 710, loss: 0.0005124893505126238
step: 720, loss: 0.0060787443071603775
step: 730, loss: 0.0472433939576149
step: 740, loss: 0.022682391107082367
step: 750, loss: 0.01779518835246563
step: 760, loss: 0.024645106866955757
step: 770, loss: 0.0666796937584877
step: 780, loss: 0.03489711135625839
step: 790, loss: 0.10165577381849289
step: 800, loss: 0.07956299930810928
step: 810, loss: 0.05136800929903984
step: 820, loss: 0.043714068830013275
step: 830, loss: 0.0008014461491256952
step: 840, loss: 0.007686220109462738
step: 850, loss: 0.02409025840461254
step: 860, loss: 0.0773983895778656
step: 870, loss: 0.05401235446333885
step: 880, loss: 0.0564180389046669
step: 890, loss: 0.0002823002287186682
step: 900, loss: 0.055376119911670685
step: 910, loss: 0.00021573131380137056
step: 920, loss: 0.02603348344564438
step: 930, loss: 0.03530454263091087
step: 940, loss: 0.0086767403408885
step: 950, loss: 0.042021531611680984
step: 960, loss: 0.00037164019886404276
step: 970, loss: 0.0007412172271870077
step: 980, loss: 0.030386507511138916
step: 990, loss: 0.0022680358961224556
step: 1000, loss: 0.028873031958937645
step: 1010, loss: 0.012274692766368389
step: 1020, loss: 0.02209312655031681
step: 1030, loss: 0.10061077773571014
step: 1040, loss: 9.61119349085493e-06
step: 1050, loss: 0.00038460202631540596
step: 1060, loss: 0.03408963605761528
step: 1070, loss: 0.025589974597096443
epoch 13: dev_f1=0.9352319706017456, f1=0.929784304726939, best_f1=0.9298245614035088
step: 0, loss: 0.02505413256585598
step: 10, loss: 0.011561614461243153
step: 20, loss: 0.00011617081327131018
step: 30, loss: 0.03773020580410957
step: 40, loss: 0.02469230629503727
step: 50, loss: 0.01742882840335369
step: 60, loss: 0.042202696204185486
step: 70, loss: 0.005904050078243017
step: 80, loss: 0.03440091386437416
step: 90, loss: 9.650994616094977e-05
step: 100, loss: 0.038211241364479065
step: 110, loss: 0.07795128971338272
step: 120, loss: 0.0313260443508625
step: 130, loss: 0.046357713639736176
step: 140, loss: 2.3620219508302398e-05
step: 150, loss: 0.00012359021638985723
step: 160, loss: 0.030286755412817
step: 170, loss: 0.026042448356747627
step: 180, loss: 0.06814202666282654
step: 190, loss: 0.008180007338523865
step: 200, loss: 0.01970115676522255
step: 210, loss: 0.2381904423236847
step: 220, loss: 0.0005215416895225644
step: 230, loss: 0.008426626212894917
step: 240, loss: 0.07916624844074249
step: 250, loss: 0.00046598308836109936
step: 260, loss: 0.03713751584291458
step: 270, loss: 0.015884479507803917
step: 280, loss: 0.01974322460591793
step: 290, loss: 0.023780593648552895
step: 300, loss: 1.944079667737242e-05
step: 310, loss: 0.042766328901052475
step: 320, loss: 0.03019772097468376
step: 330, loss: 0.07904305309057236
step: 340, loss: 0.029908262193202972
step: 350, loss: 0.03371996432542801
step: 360, loss: 0.00028644627309404314
step: 370, loss: 0.04605904594063759
step: 380, loss: 0.03264017775654793
step: 390, loss: 0.0008414756739512086
step: 400, loss: 0.09875030815601349
step: 410, loss: 0.01902427338063717
step: 420, loss: 0.04068098962306976
step: 430, loss: 0.01616319827735424
step: 440, loss: 0.0020539171528071165
step: 450, loss: 0.013230795040726662
step: 460, loss: 0.06554792076349258
step: 470, loss: 0.012408586218953133
step: 480, loss: 0.07938576489686966
step: 490, loss: 0.0008374775061383843
step: 500, loss: 0.12102071195840836
step: 510, loss: 0.04404057562351227
step: 520, loss: 0.04469003900885582
step: 530, loss: 0.01966533437371254
step: 540, loss: 0.0002748439146671444
step: 550, loss: 0.02528076246380806
step: 560, loss: 0.03606881946325302
step: 570, loss: 0.004049590323120356
step: 580, loss: 0.014486282132565975
step: 590, loss: 0.04326854273676872
step: 600, loss: 0.09476339817047119
step: 610, loss: 0.028902631253004074
step: 620, loss: 0.019249118864536285
step: 630, loss: 0.02651096135377884
step: 640, loss: 5.931509076617658e-05
step: 650, loss: 0.0516350157558918
step: 660, loss: 0.039398930966854095
step: 670, loss: 0.0013829797971993685
step: 680, loss: 1.1995321074209642e-05
step: 690, loss: 0.024101339280605316
step: 700, loss: 0.05715097114443779
step: 710, loss: 0.0002690282417461276
step: 720, loss: 0.02103559672832489
step: 730, loss: 0.029139701277017593
step: 740, loss: 0.021136078983545303
step: 750, loss: 0.06383415311574936
step: 760, loss: 0.0584825724363327
step: 770, loss: 0.03384626284241676
step: 780, loss: 0.02214845083653927
step: 790, loss: 0.017924737185239792
step: 800, loss: 0.0002641806495375931
step: 810, loss: 6.041447340976447e-05
step: 820, loss: 0.07437532395124435
step: 830, loss: 0.00047484933747909963
step: 840, loss: 0.0022371113300323486
step: 850, loss: 0.09888717532157898
step: 860, loss: 0.016586028039455414
step: 870, loss: 0.003751036012545228
step: 880, loss: 0.026545997709035873
step: 890, loss: 0.0886533185839653
step: 900, loss: 0.05142649635672569
step: 910, loss: 0.039548806846141815
step: 920, loss: 0.0037297545932233334
step: 930, loss: 0.03962171822786331
step: 940, loss: 0.07530803233385086
step: 950, loss: 0.02911902405321598
step: 960, loss: 0.11079712212085724
step: 970, loss: 0.04874660074710846
step: 980, loss: 0.0002066251472570002
step: 990, loss: 0.00019434778369031847
step: 1000, loss: 0.045173175632953644
step: 1010, loss: 0.0007510907016694546
step: 1020, loss: 0.0137522267177701
step: 1030, loss: 0.005505343433469534
step: 1040, loss: 0.048354074358940125
step: 1050, loss: 0.024756599217653275
step: 1060, loss: 0.01981980912387371
step: 1070, loss: 0.04281468316912651
epoch 14: dev_f1=0.9280806229958772, f1=0.9250574712643677, best_f1=0.9298245614035088
step: 0, loss: 0.04595474526286125
step: 10, loss: 0.00017115561058744788
step: 20, loss: 0.0019068740075454116
step: 30, loss: 0.04301575943827629
step: 40, loss: 0.001167088164947927
step: 50, loss: 0.08761825412511826
step: 60, loss: 0.011371217668056488
step: 70, loss: 0.07024736702442169
step: 80, loss: 0.024269185960292816
step: 90, loss: 0.045736268162727356
step: 100, loss: 0.05432949587702751
step: 110, loss: 0.031031237915158272
step: 120, loss: 0.07092839479446411
step: 130, loss: 0.03773096576333046
step: 140, loss: 0.0013331994414329529
step: 150, loss: 0.02947217971086502
step: 160, loss: 0.02004322223365307
step: 170, loss: 0.05407263711094856
step: 180, loss: 3.9501181163359433e-05
step: 190, loss: 1.5746325516374782e-05
step: 200, loss: 5.319790943758562e-05
step: 210, loss: 0.014572830870747566
step: 220, loss: 0.01644917204976082
step: 230, loss: 0.0464060939848423
step: 240, loss: 0.1168305054306984
step: 250, loss: 0.041802167892456055
step: 260, loss: 0.01273521687835455
step: 270, loss: 0.028562095016241074
step: 280, loss: 0.0011213241377845407
step: 290, loss: 0.03671356290578842
step: 300, loss: 0.020867599174380302
step: 310, loss: 0.015954697504639626
step: 320, loss: 0.016142919659614563
step: 330, loss: 0.00039104471215978265
step: 340, loss: 0.005934305023401976
step: 350, loss: 0.015122934244573116
step: 360, loss: 0.07185618579387665
step: 370, loss: 4.830830584978685e-05
step: 380, loss: 0.025056183338165283
step: 390, loss: 0.028215019032359123
step: 400, loss: 0.00016978118219412863
step: 410, loss: 0.021571222692728043
step: 420, loss: 0.02597973868250847
step: 430, loss: 0.01986010931432247
step: 440, loss: 0.003582640551030636
step: 450, loss: 0.038428522646427155
step: 460, loss: 0.04896135255694389
step: 470, loss: 0.023093780502676964
step: 480, loss: 0.00945831835269928
step: 490, loss: 0.04191432520747185
step: 500, loss: 0.03112618252635002
step: 510, loss: 0.027540849521756172
step: 520, loss: 0.05055234953761101
step: 530, loss: 0.027086835354566574
step: 540, loss: 0.03254977613687515
step: 550, loss: 0.014933525584638119
step: 560, loss: 0.03957577422261238
step: 570, loss: 0.00026987268938682973
step: 580, loss: 0.0009703482501208782
step: 590, loss: 0.01906193234026432
step: 600, loss: 0.01966569572687149
step: 610, loss: 0.010309886187314987
step: 620, loss: 0.06363287568092346
step: 630, loss: 0.041157398372888565
step: 640, loss: 0.04371573403477669
step: 650, loss: 0.027960577979683876
step: 660, loss: 0.00023917948419693857
step: 670, loss: 0.045858558267354965
step: 680, loss: 0.0721849873661995
step: 690, loss: 0.01181742548942566
step: 700, loss: 0.04309042915701866
step: 710, loss: 0.0002728897670749575
step: 720, loss: 0.003956031519919634
step: 730, loss: 0.016783133149147034
step: 740, loss: 0.0022141998633742332
step: 750, loss: 0.012153013609349728
step: 760, loss: 0.07324928790330887
step: 770, loss: 0.02224140428006649
step: 780, loss: 0.08162885159254074
step: 790, loss: 0.04721646383404732
step: 800, loss: 0.0019110010471194983
step: 810, loss: 2.1221823772066273e-05
step: 820, loss: 0.062498461455106735
step: 830, loss: 3.813860166701488e-05
step: 840, loss: 0.015778090804815292
step: 850, loss: 0.00012864645395893604
step: 860, loss: 0.08375000953674316
step: 870, loss: 0.0002478370734024793
step: 880, loss: 0.1245037391781807
step: 890, loss: 0.04233453422784805
step: 900, loss: 0.05415060743689537
step: 910, loss: 0.021328581497073174
step: 920, loss: 0.023380354046821594
step: 930, loss: 0.03286420926451683
step: 940, loss: 0.025027962401509285
step: 950, loss: 7.546843698946759e-05
step: 960, loss: 0.04233343154191971
step: 970, loss: 0.0001934994215844199
step: 980, loss: 0.0005640182644128799
step: 990, loss: 0.027608808130025864
step: 1000, loss: 0.09298522770404816
step: 1010, loss: 0.0204304251819849
step: 1020, loss: 3.631758227129467e-05
step: 1030, loss: 0.07942640036344528
step: 1040, loss: 0.015418056398630142
step: 1050, loss: 0.05557027459144592
step: 1060, loss: 0.02758350595831871
step: 1070, loss: 0.023371411487460136
epoch 15: dev_f1=0.9374130737134909, f1=0.9272388059701492, best_f1=0.9272388059701492
step: 0, loss: 0.020357770845294
step: 10, loss: 0.06989995390176773
step: 20, loss: 0.015876529738307
step: 30, loss: 0.05883633345365524
step: 40, loss: 0.022205809131264687
step: 50, loss: 0.020897800102829933
step: 60, loss: 0.013975497335195541
step: 70, loss: 0.018719935789704323
step: 80, loss: 0.04043538123369217
step: 90, loss: 0.012600111775100231
step: 100, loss: 0.00016027827223297209
step: 110, loss: 0.02620522491633892
step: 120, loss: 0.021951137110590935
step: 130, loss: 0.026261908933520317
step: 140, loss: 0.02181677706539631
step: 150, loss: 0.00018287490820512176
step: 160, loss: 6.122038030298427e-05
step: 170, loss: 1.6528652849956416e-05
step: 180, loss: 0.0009665774996392429
step: 190, loss: 0.025506699457764626
step: 200, loss: 0.025250796228647232
step: 210, loss: 0.0497424490749836
step: 220, loss: 0.01851142942905426
step: 230, loss: 0.039978452026844025
step: 240, loss: 0.033921364694833755
step: 250, loss: 0.09722404927015305
step: 260, loss: 0.0448310449719429
step: 270, loss: 0.07244886457920074
step: 280, loss: 0.04317387938499451
step: 290, loss: 7.16957074473612e-05
step: 300, loss: 0.04387074336409569
step: 310, loss: 1.0982044841512106e-05
step: 320, loss: 0.029986785724759102
step: 330, loss: 0.028381764888763428
step: 340, loss: 0.020975816994905472
step: 350, loss: 0.020688461139798164
step: 360, loss: 0.03171566128730774
step: 370, loss: 0.01972724311053753
step: 380, loss: 0.12141928821802139
step: 390, loss: 0.0706634595990181
step: 400, loss: 0.01593898795545101
step: 410, loss: 0.07140251249074936
step: 420, loss: 0.013294749893248081
step: 430, loss: 0.03441218286752701
step: 440, loss: 0.03710506483912468
step: 450, loss: 4.4022297515766695e-05
step: 460, loss: 0.042598068714141846
step: 470, loss: 0.022267235442996025
step: 480, loss: 0.0006106307846494019
step: 490, loss: 0.020363707095384598
step: 500, loss: 0.06929434835910797
step: 510, loss: 0.026793651282787323
step: 520, loss: 0.018628809601068497
step: 530, loss: 0.018679581582546234
step: 540, loss: 0.017813824117183685
step: 550, loss: 3.8350637623807415e-05
step: 560, loss: 0.03290029242634773
step: 570, loss: 0.0003146091185044497
step: 580, loss: 0.021552054211497307
step: 590, loss: 0.019039686769247055
step: 600, loss: 0.05286341905593872
step: 610, loss: 0.07097068428993225
step: 620, loss: 0.0054105184972286224
step: 630, loss: 0.017058253288269043
step: 640, loss: 0.0038828160613775253
step: 650, loss: 0.025320667773485184
step: 660, loss: 0.028584128245711327
step: 670, loss: 0.04481268301606178
step: 680, loss: 0.020043401047587395
step: 690, loss: 0.024966247379779816
step: 700, loss: 0.13494838774204254
step: 710, loss: 0.02032068930566311
step: 720, loss: 0.02250952273607254
step: 730, loss: 0.008885184302926064
step: 740, loss: 0.022195924073457718
step: 750, loss: 0.04518001154065132
step: 760, loss: 0.03302139788866043
step: 770, loss: 3.9253151044249535e-05
step: 780, loss: 0.00012022049486404285
step: 790, loss: 0.005417203530669212
step: 800, loss: 0.00010598599328659475
step: 810, loss: 0.017495254054665565
step: 820, loss: 0.04271708428859711
step: 830, loss: 0.008807225152850151
step: 840, loss: 3.0335631890920922e-05
step: 850, loss: 0.03753213211894035
step: 860, loss: 0.01715303584933281
step: 870, loss: 0.02339758165180683
step: 880, loss: 0.10149277746677399
step: 890, loss: 0.007549920119345188
step: 900, loss: 0.022265944629907608
step: 910, loss: 0.07744591683149338
step: 920, loss: 0.024694010615348816
step: 930, loss: 0.07747791707515717
step: 940, loss: 3.4010499803116545e-05
step: 950, loss: 0.00021554389968514442
step: 960, loss: 0.045098792761564255
step: 970, loss: 9.903871978167444e-05
step: 980, loss: 0.03144276887178421
step: 990, loss: 0.052528198808431625
step: 1000, loss: 0.030400658026337624
step: 1010, loss: 0.08239346742630005
step: 1020, loss: 1.1414206710469443e-05
step: 1030, loss: 0.02868439257144928
step: 1040, loss: 0.02551060914993286
step: 1050, loss: 0.06512226909399033
step: 1060, loss: 0.027513064444065094
step: 1070, loss: 0.019713526591658592
epoch 16: dev_f1=0.9364858599907279, f1=0.9242212924221292, best_f1=0.9272388059701492
step: 0, loss: 0.022783378139138222
step: 10, loss: 0.02070242166519165
step: 20, loss: 0.0007931513246148825
step: 30, loss: 0.04304571822285652
step: 40, loss: 0.024348706007003784
step: 50, loss: 1.5865611203480512e-05
step: 60, loss: 0.01822071522474289
step: 70, loss: 0.022956181317567825
step: 80, loss: 0.03606544807553291
step: 90, loss: 0.016821883618831635
step: 100, loss: 9.859300189418718e-05
step: 110, loss: 0.0020591295324265957
step: 120, loss: 9.903057070914656e-05
step: 130, loss: 0.013897833414375782
step: 140, loss: 0.024892030283808708
step: 150, loss: 2.6742178306449205e-05
step: 160, loss: 0.03779391944408417
step: 170, loss: 0.009198356419801712
step: 180, loss: 0.016735326498746872
step: 190, loss: 0.08774568885564804
step: 200, loss: 0.04367050528526306
step: 210, loss: 0.013486476615071297
step: 220, loss: 0.019943280145525932
step: 230, loss: 0.022989364340901375
step: 240, loss: 0.07637674361467361
step: 250, loss: 4.407983578857966e-05
step: 260, loss: 0.019439158961176872
step: 270, loss: 0.021268773823976517
step: 280, loss: 0.0007012313581071794
step: 290, loss: 5.960953785688616e-05
step: 300, loss: 0.02714853733778
step: 310, loss: 0.04372280091047287
step: 320, loss: 0.00019011297263205051
step: 330, loss: 0.02207261137664318
step: 340, loss: 0.02087261714041233
step: 350, loss: 0.058382172137498856
step: 360, loss: 0.05671988055109978
step: 370, loss: 0.01868126541376114
step: 380, loss: 0.042300473898649216
step: 390, loss: 0.09082730859518051
step: 400, loss: 0.02405027486383915
step: 410, loss: 3.211654620827176e-05
step: 420, loss: 0.020409246906638145
step: 430, loss: 0.04043355584144592
step: 440, loss: 0.04386375471949577
step: 450, loss: 7.943742093630135e-05
step: 460, loss: 0.05721307173371315
step: 470, loss: 0.04557543992996216
step: 480, loss: 0.019625412300229073
step: 490, loss: 0.023498844355344772
step: 500, loss: 0.0695636123418808
step: 510, loss: 3.8049194699851796e-05
step: 520, loss: 0.019022321328520775
step: 530, loss: 0.04207541421055794
step: 540, loss: 0.07462075352668762
step: 550, loss: 6.83606558595784e-05
step: 560, loss: 0.04602845758199692
step: 570, loss: 1.7142661818070337e-05
step: 580, loss: 0.0005904059507884085
step: 590, loss: 0.028003830462694168
step: 600, loss: 0.052305418998003006
step: 610, loss: 0.10516862571239471
step: 620, loss: 0.06470902264118195
step: 630, loss: 0.0014414627803489566
step: 640, loss: 1.3209709322836716e-05
step: 650, loss: 0.06944558024406433
step: 660, loss: 0.023860491812229156
step: 670, loss: 0.0038555129431188107
step: 680, loss: 0.008609401062130928
step: 690, loss: 0.018601451069116592
step: 700, loss: 0.03358815982937813
step: 710, loss: 0.04768688604235649
step: 720, loss: 0.017373794689774513
step: 730, loss: 0.05084528401494026
step: 740, loss: 0.00540587492287159
step: 750, loss: 0.0004931687726639211
step: 760, loss: 0.00012743991101160645
step: 770, loss: 0.05764710530638695
step: 780, loss: 0.0611766055226326
step: 790, loss: 9.930280793923885e-05
step: 800, loss: 3.7187299312790856e-05
step: 810, loss: 0.00145740678999573
step: 820, loss: 0.056748177856206894
step: 830, loss: 0.01562638208270073
step: 840, loss: 3.045472112717107e-05
step: 850, loss: 0.00035244025639258325
step: 860, loss: 0.015508563257753849
step: 870, loss: 5.2950890676584095e-05
step: 880, loss: 0.005446588154882193
step: 890, loss: 0.04220930114388466
step: 900, loss: 4.963695027981885e-05
step: 910, loss: 0.021381469443440437
step: 920, loss: 0.025130856782197952
step: 930, loss: 0.014878716319799423
step: 940, loss: 4.6089149691397324e-05
step: 950, loss: 0.017714032903313637
step: 960, loss: 0.023021278902888298
step: 970, loss: 0.03874422609806061
step: 980, loss: 0.040585894137620926
step: 990, loss: 8.976503158919513e-05
step: 1000, loss: 0.05466273054480553
step: 1010, loss: 0.00018983187328558415
step: 1020, loss: 0.018905814737081528
step: 1030, loss: 0.020033400505781174
step: 1040, loss: 0.04500233009457588
step: 1050, loss: 0.04276832193136215
step: 1060, loss: 0.12617994844913483
step: 1070, loss: 0.01669829525053501
epoch 17: dev_f1=0.9341544291804832, f1=0.9208905731880626, best_f1=0.9272388059701492
step: 0, loss: 0.0032632353249937296
step: 10, loss: 0.004344466142356396
step: 20, loss: 0.0515994094312191
step: 30, loss: 0.018488632515072823
step: 40, loss: 5.4090935009298846e-05
step: 50, loss: 0.025446204468607903
step: 60, loss: 0.00010826972720678896
step: 70, loss: 0.0002229404344689101
step: 80, loss: 0.026373106986284256
step: 90, loss: 0.022127913311123848
step: 100, loss: 0.001160607673227787
step: 110, loss: 0.039546526968479156
step: 120, loss: 0.056071627885103226
step: 130, loss: 0.0262722410261631
step: 140, loss: 0.019110659137368202
step: 150, loss: 0.0001748982904246077
step: 160, loss: 0.059872958809137344
step: 170, loss: 0.012015237472951412
step: 180, loss: 0.04360602796077728
step: 190, loss: 0.020939568057656288
step: 200, loss: 1.5269522918970324e-05
step: 210, loss: 0.06339696794748306
step: 220, loss: 0.01880219578742981
step: 230, loss: 0.01847829855978489
step: 240, loss: 0.020169002935290337
step: 250, loss: 0.04213687404990196
step: 260, loss: 0.00011383314995327964
step: 270, loss: 0.026109686121344566
step: 280, loss: 0.02200830541551113
step: 290, loss: 0.036694735288619995
step: 300, loss: 0.02173903025686741
step: 310, loss: 3.4900655009550974e-05
step: 320, loss: 2.4737957573961467e-05
step: 330, loss: 2.381036028964445e-05
step: 340, loss: 5.0561920943437144e-05
step: 350, loss: 0.0007743513560853899
step: 360, loss: 9.74459107965231e-05
step: 370, loss: 4.363425978226587e-05
step: 380, loss: 0.00013849898823536932
step: 390, loss: 0.031248684972524643
step: 400, loss: 0.00043767859460785985
step: 410, loss: 0.019118990749120712
step: 420, loss: 0.017474237829446793
step: 430, loss: 0.018901119008660316
step: 440, loss: 0.008225565776228905
step: 450, loss: 4.299245847505517e-05
step: 460, loss: 0.001563777681440115
step: 470, loss: 0.004617223050445318
step: 480, loss: 2.435072383377701e-05
step: 490, loss: 0.018694881349802017
step: 500, loss: 0.03719451650977135
step: 510, loss: 2.522543400118593e-05
step: 520, loss: 0.03237658366560936
step: 530, loss: 0.05004676431417465
step: 540, loss: 0.06709832698106766
step: 550, loss: 0.05177262797951698
step: 560, loss: 0.08301548659801483
step: 570, loss: 0.05763791874051094
step: 580, loss: 0.0651119127869606
step: 590, loss: 0.02384331449866295
step: 600, loss: 1.7072205082513392e-05
step: 610, loss: 0.0699700117111206
step: 620, loss: 0.0006118708406575024
step: 630, loss: 0.016595875844359398
step: 640, loss: 0.022138049826025963
step: 650, loss: 3.225224281777628e-05
step: 660, loss: 8.571852958993986e-06
step: 670, loss: 0.03959311172366142
step: 680, loss: 0.0005915388464927673
step: 690, loss: 0.00390635896474123
step: 700, loss: 0.0003203426313120872
step: 710, loss: 9.682475501904264e-05
step: 720, loss: 0.02643907628953457
step: 730, loss: 0.03256026655435562
step: 740, loss: 0.03198384493589401
step: 750, loss: 0.022388450801372528
step: 760, loss: 0.023550182580947876
step: 770, loss: 0.018224608153104782
step: 780, loss: 0.024209661409258842
step: 790, loss: 0.039619311690330505
step: 800, loss: 0.024012112990021706
step: 810, loss: 0.03190215677022934
step: 820, loss: 0.022226393222808838
step: 830, loss: 0.019568277522921562
step: 840, loss: 5.889093881705776e-05
step: 850, loss: 0.042100485414266586
step: 860, loss: 0.023571617901325226
step: 870, loss: 0.0011055786162614822
step: 880, loss: 0.021417060866951942
step: 890, loss: 0.037649668753147125
step: 900, loss: 0.026808539405465126
step: 910, loss: 6.263446994125843e-05
step: 920, loss: 3.7673886254196987e-05
step: 930, loss: 0.06297960877418518
step: 940, loss: 0.009982985444366932
step: 950, loss: 0.016779862344264984
step: 960, loss: 9.91309862001799e-05
step: 970, loss: 0.03093966655433178
step: 980, loss: 0.05096995830535889
step: 990, loss: 0.0412740483880043
step: 1000, loss: 0.04626089334487915
step: 1010, loss: 0.021853260695934296
step: 1020, loss: 0.020203733816742897
step: 1030, loss: 0.0463462769985199
step: 1040, loss: 0.018254682421684265
step: 1050, loss: 0.11703218519687653
step: 1060, loss: 0.025318438187241554
step: 1070, loss: 0.020327752456068993
epoch 18: dev_f1=0.937207122774133, f1=0.9243776420854861, best_f1=0.9272388059701492
step: 0, loss: 0.032129496335983276
step: 10, loss: 8.352563600055873e-05
step: 20, loss: 0.05516951531171799
step: 30, loss: 9.002027218230069e-05
step: 40, loss: 0.0066056689247488976
step: 50, loss: 3.610194107750431e-05
step: 60, loss: 0.024731900542974472
step: 70, loss: 0.030169442296028137
step: 80, loss: 0.00018042416195385158
step: 90, loss: 0.0019436931470409036
step: 100, loss: 0.013352684676647186
step: 110, loss: 0.0388275608420372
step: 120, loss: 0.00011621198063949123
step: 130, loss: 0.0005769944400526583
step: 140, loss: 0.04904794692993164
step: 150, loss: 3.4733806387521327e-05
step: 160, loss: 0.02466517873108387
step: 170, loss: 0.04728885740041733
step: 180, loss: 0.0001042727890308015
step: 190, loss: 0.018022865056991577
step: 200, loss: 5.072199564892799e-05
step: 210, loss: 2.3244047042680904e-05
step: 220, loss: 0.01688736118376255
step: 230, loss: 0.00011761952919187024
step: 240, loss: 3.777694655582309e-05
step: 250, loss: 0.01829543337225914
step: 260, loss: 0.00010817981092259288
step: 270, loss: 0.08138582110404968
step: 280, loss: 0.02549740858376026
step: 290, loss: 0.015528337098658085
step: 300, loss: 0.042096298187971115
step: 310, loss: 0.0009911610977724195
step: 320, loss: 0.02789520099759102
step: 330, loss: 0.023479601368308067
step: 340, loss: 0.031130146235227585
step: 350, loss: 0.0004639898252207786
step: 360, loss: 0.0676855593919754
step: 370, loss: 0.025135211646556854
step: 380, loss: 0.06670695543289185
step: 390, loss: 0.06643004715442657
step: 400, loss: 2.4148206648533233e-05
step: 410, loss: 0.02056960202753544
step: 420, loss: 0.06675930321216583
step: 430, loss: 9.329955355497077e-05
step: 440, loss: 0.024772655218839645
step: 450, loss: 0.04599325731396675
step: 460, loss: 0.02922045812010765
step: 470, loss: 8.112069917842746e-05
step: 480, loss: 0.00010677849058993161
step: 490, loss: 2.316531572432723e-05
step: 500, loss: 2.263274473079946e-05
step: 510, loss: 0.03564934432506561
step: 520, loss: 0.022272367030382156
step: 530, loss: 0.04000682756304741
step: 540, loss: 9.026120824273676e-05
step: 550, loss: 0.07140441238880157
step: 560, loss: 0.02301023341715336
step: 570, loss: 0.0026993288192898035
step: 580, loss: 0.01774325966835022
step: 590, loss: 1.4606352124246769e-05
step: 600, loss: 0.0001453675504308194
step: 610, loss: 3.830700006801635e-05
step: 620, loss: 3.587558967410587e-05
step: 630, loss: 0.055782437324523926
step: 640, loss: 0.019111933186650276
step: 650, loss: 0.060474034398794174
step: 660, loss: 2.56198054557899e-05
step: 670, loss: 3.1818133720662445e-05
step: 680, loss: 3.345971344970167e-05
step: 690, loss: 0.0002613375836517662
step: 700, loss: 0.00024042051518335938
step: 710, loss: 0.0449381060898304
step: 720, loss: 0.03476569056510925
step: 730, loss: 8.37813968246337e-06
step: 740, loss: 0.022931566461920738
step: 750, loss: 0.06546398997306824
step: 760, loss: 0.0005878085503354669
step: 770, loss: 0.024012932553887367
step: 780, loss: 0.00015373126370832324
step: 790, loss: 0.0009672378655523062
step: 800, loss: 6.086336725275032e-05
step: 810, loss: 2.8902411941089667e-05
step: 820, loss: 0.05337674170732498
step: 830, loss: 0.022211479023098946
step: 840, loss: 7.552747410954908e-05
step: 850, loss: 0.045134540647268295
step: 860, loss: 0.05416232720017433
step: 870, loss: 1.5191153579507954e-05
step: 880, loss: 0.049249447882175446
step: 890, loss: 0.00012617452011909336
step: 900, loss: 0.03865674510598183
step: 910, loss: 5.456136568682268e-05
step: 920, loss: 9.700605005491525e-06
step: 930, loss: 0.03916552662849426
step: 940, loss: 0.00012605440861079842
step: 950, loss: 0.019168395549058914
step: 960, loss: 0.017193853855133057
step: 970, loss: 0.043216485530138016
step: 980, loss: 1.0728739653131925e-05
step: 990, loss: 0.00027340161614120007
step: 1000, loss: 2.204856173193548e-05
step: 1010, loss: 0.023353341966867447
step: 1020, loss: 0.09841267019510269
step: 1030, loss: 2.3725327991996892e-05
step: 1040, loss: 0.0024758577346801758
step: 1050, loss: 0.022135650739073753
step: 1060, loss: 0.026251528412103653
step: 1070, loss: 0.027178969234228134
epoch 19: dev_f1=0.9340245051837888, f1=0.924092409240924, best_f1=0.9272388059701492
step: 0, loss: 0.020121412351727486
step: 10, loss: 0.00026350951520726085
step: 20, loss: 2.1329136870917864e-05
step: 30, loss: 0.05528971552848816
step: 40, loss: 2.644059350132011e-05
step: 50, loss: 0.025243226438760757
step: 60, loss: 0.027637630701065063
step: 70, loss: 0.010833780281245708
step: 80, loss: 0.0225637536495924
step: 90, loss: 0.02053348906338215
step: 100, loss: 5.368908023228869e-05
step: 110, loss: 0.04784345254302025
step: 120, loss: 0.037965722382068634
step: 130, loss: 0.00044743259786628187
step: 140, loss: 0.034302953630685806
step: 150, loss: 0.0013496900210157037
step: 160, loss: 0.02403942495584488
step: 170, loss: 0.0030762783717364073
step: 180, loss: 1.2256043191882782e-05
step: 190, loss: 0.02394157461822033
step: 200, loss: 6.489030056400225e-05
step: 210, loss: 0.009140150621533394
step: 220, loss: 0.10587369650602341
step: 230, loss: 8.31276411190629e-05
step: 240, loss: 0.000479246664326638
step: 250, loss: 0.020072679966688156
step: 260, loss: 0.018247973173856735
step: 270, loss: 0.07051195949316025
step: 280, loss: 0.02917638048529625
step: 290, loss: 0.08071138709783554
step: 300, loss: 0.029476795345544815
step: 310, loss: 2.0495559510891326e-05
step: 320, loss: 0.07851521670818329
step: 330, loss: 0.12311665713787079
step: 340, loss: 0.047153957188129425
step: 350, loss: 1.753020114847459e-05
step: 360, loss: 0.023771818727254868
step: 370, loss: 0.026577357202768326
step: 380, loss: 6.80712255416438e-05
step: 390, loss: 0.02339947782456875
step: 400, loss: 0.05186065286397934
step: 410, loss: 0.02088209055364132
step: 420, loss: 0.023165499791502953
step: 430, loss: 0.11722360551357269
step: 440, loss: 0.021557755768299103
step: 450, loss: 2.1348621885408647e-05
step: 460, loss: 0.01946238987147808
step: 470, loss: 0.026114443317055702
step: 480, loss: 8.948182949097827e-05
step: 490, loss: 4.6457262214971706e-05
step: 500, loss: 9.43165214266628e-05
step: 510, loss: 0.017235426232218742
step: 520, loss: 7.390167593257502e-05
step: 530, loss: 0.04864954203367233
step: 540, loss: 0.002139999531209469
step: 550, loss: 0.04244137555360794
step: 560, loss: 0.022007223218679428
step: 570, loss: 0.020834501832723618
step: 580, loss: 3.745668436749838e-05
step: 590, loss: 0.04115808382630348
step: 600, loss: 0.025353137403726578
step: 610, loss: 9.033782589540351e-06
step: 620, loss: 0.017591895535588264
step: 630, loss: 0.028437094762921333
step: 640, loss: 0.04300723597407341
step: 650, loss: 0.005437251180410385
step: 660, loss: 0.051086824387311935
step: 670, loss: 0.0005142427980899811
step: 680, loss: 8.534598237019964e-06
step: 690, loss: 0.04780397564172745
step: 700, loss: 0.027401559054851532
step: 710, loss: 0.05765000730752945
step: 720, loss: 0.0023647246416658163
step: 730, loss: 0.0363241471350193
step: 740, loss: 0.03030768595635891
step: 750, loss: 0.04233895242214203
step: 760, loss: 5.467795199365355e-05
step: 770, loss: 0.0002585032780189067
step: 780, loss: 0.02094300277531147
step: 790, loss: 0.039857883006334305
step: 800, loss: 3.0157052606227808e-05
step: 810, loss: 4.404826904647052e-05
step: 820, loss: 0.027300970628857613
step: 830, loss: 0.02079763263463974
step: 840, loss: 1.5586057998007163e-05
step: 850, loss: 7.160826498875394e-05
step: 860, loss: 0.04000220075249672
step: 870, loss: 0.023513080552220345
step: 880, loss: 0.06306137889623642
step: 890, loss: 0.022455157712101936
step: 900, loss: 0.02631549723446369
step: 910, loss: 0.04281960427761078
step: 920, loss: 0.04274781048297882
step: 930, loss: 0.030421733856201172
step: 940, loss: 0.006139751058071852
step: 950, loss: 0.07169947773218155
step: 960, loss: 2.092742761305999e-05
step: 970, loss: 2.8856960852863267e-05
step: 980, loss: 1.1924467798962723e-05
step: 990, loss: 3.8086858694441617e-05
step: 1000, loss: 0.029137825593352318
step: 1010, loss: 2.3650572984479368e-05
step: 1020, loss: 0.026933914050459862
step: 1030, loss: 6.999153265496716e-05
step: 1040, loss: 0.04308094456791878
step: 1050, loss: 0.027480464428663254
step: 1060, loss: 3.635511893662624e-05
step: 1070, loss: 0.02867591753602028
epoch 20: dev_f1=0.9329582747304266, f1=0.9246704331450095, best_f1=0.9272388059701492
