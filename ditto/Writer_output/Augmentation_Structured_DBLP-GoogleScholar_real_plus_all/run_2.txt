cuda
Device: cuda
step: 0, loss: 0.8226845264434814
step: 10, loss: 0.6422009468078613
step: 20, loss: 0.5247682929039001
step: 30, loss: 0.45043015480041504
step: 40, loss: 0.49090489745140076
step: 50, loss: 0.2766440510749817
step: 60, loss: 0.31764429807662964
step: 70, loss: 0.3512185215950012
step: 80, loss: 0.12566789984703064
step: 90, loss: 0.36767154932022095
step: 100, loss: 0.26046308875083923
step: 110, loss: 0.30962157249450684
step: 120, loss: 0.24914224445819855
step: 130, loss: 0.15113948285579681
step: 140, loss: 0.27935755252838135
step: 150, loss: 0.18996736407279968
step: 160, loss: 0.13347120583057404
step: 170, loss: 0.2896716892719269
step: 180, loss: 0.2539184093475342
step: 190, loss: 0.18525363504886627
step: 200, loss: 0.25151610374450684
step: 210, loss: 0.05826818570494652
step: 220, loss: 0.14504465460777283
step: 230, loss: 0.13778525590896606
step: 240, loss: 0.12125227600336075
step: 250, loss: 0.15367162227630615
step: 260, loss: 0.09392676502466202
step: 270, loss: 0.12513381242752075
step: 280, loss: 0.11772087961435318
step: 290, loss: 0.11207586526870728
step: 300, loss: 0.07612018287181854
step: 310, loss: 0.09163326025009155
step: 320, loss: 0.23121196031570435
step: 330, loss: 0.08284241706132889
step: 340, loss: 0.17968134582042694
step: 350, loss: 0.10235144197940826
step: 360, loss: 0.1953745037317276
step: 370, loss: 0.10513260215520859
step: 380, loss: 0.05168718472123146
step: 390, loss: 0.014008349739015102
step: 400, loss: 0.21341730654239655
step: 410, loss: 0.0753270611166954
step: 420, loss: 0.06204172596335411
step: 430, loss: 0.1395738273859024
step: 440, loss: 0.13671284914016724
step: 450, loss: 0.11624861508607864
step: 460, loss: 0.28969383239746094
step: 470, loss: 0.17280124127864838
step: 480, loss: 0.07021385431289673
step: 490, loss: 0.15358717739582062
step: 500, loss: 0.15184526145458221
step: 510, loss: 0.10854190587997437
step: 520, loss: 0.12333944439888
step: 530, loss: 0.06274780631065369
step: 540, loss: 0.16579996049404144
step: 550, loss: 0.09361626952886581
step: 560, loss: 0.06395334750413895
step: 570, loss: 0.11720217764377594
step: 580, loss: 0.042330656200647354
step: 590, loss: 0.29481106996536255
step: 600, loss: 0.07707196474075317
step: 610, loss: 0.07690572738647461
step: 620, loss: 0.24162107706069946
step: 630, loss: 0.14849616587162018
step: 640, loss: 0.1435251384973526
step: 650, loss: 0.021296925842761993
step: 660, loss: 0.06342058628797531
step: 670, loss: 0.18671005964279175
step: 680, loss: 0.06557828187942505
step: 690, loss: 0.08617378026247025
step: 700, loss: 0.1180327981710434
step: 710, loss: 0.2171216756105423
step: 720, loss: 0.0968170166015625
step: 730, loss: 0.24827343225479126
step: 740, loss: 0.03730514645576477
step: 750, loss: 0.08527670055627823
step: 760, loss: 0.07665237039327621
step: 770, loss: 0.10995224118232727
step: 780, loss: 0.0988256186246872
step: 790, loss: 0.27562958002090454
step: 800, loss: 0.08408718556165695
step: 810, loss: 0.11771943420171738
step: 820, loss: 0.08538949489593506
step: 830, loss: 0.22079117596149445
step: 840, loss: 0.37446328997612
step: 850, loss: 0.2067517638206482
step: 860, loss: 0.09970587491989136
step: 870, loss: 0.10742256045341492
step: 880, loss: 0.17999155819416046
step: 890, loss: 0.18033194541931152
step: 900, loss: 0.13834068179130554
step: 910, loss: 0.10202819108963013
step: 920, loss: 0.1414930373430252
step: 930, loss: 0.2018914669752121
step: 940, loss: 0.04479730501770973
step: 950, loss: 0.05364670231938362
step: 960, loss: 0.09073364734649658
step: 970, loss: 0.039554160088300705
step: 980, loss: 0.12017632275819778
step: 990, loss: 0.10326416045427322
step: 1000, loss: 0.01686384528875351
step: 1010, loss: 0.10078329592943192
step: 1020, loss: 0.04893498495221138
step: 1030, loss: 0.06655006110668182
step: 1040, loss: 0.11973433941602707
step: 1050, loss: 0.1522008776664734
step: 1060, loss: 0.07604382932186127
step: 1070, loss: 0.019726568832993507
epoch 1: dev_f1=0.9251764705882354, f1=0.9289363678588016, best_f1=0.9289363678588016
step: 0, loss: 0.11489542573690414
step: 10, loss: 0.04209177941083908
step: 20, loss: 0.16320645809173584
step: 30, loss: 0.1358572542667389
step: 40, loss: 0.08192124962806702
step: 50, loss: 0.03110605478286743
step: 60, loss: 0.08534417301416397
step: 70, loss: 0.18327359855175018
step: 80, loss: 0.09021736681461334
step: 90, loss: 0.12746559083461761
step: 100, loss: 0.03822595626115799
step: 110, loss: 0.1226888969540596
step: 120, loss: 0.08489736169576645
step: 130, loss: 0.15758833289146423
step: 140, loss: 0.19922636449337006
step: 150, loss: 0.10227073729038239
step: 160, loss: 0.16535283625125885
step: 170, loss: 0.10738363862037659
step: 180, loss: 0.03158097714185715
step: 190, loss: 0.07079769670963287
step: 200, loss: 0.044795528054237366
step: 210, loss: 0.12381124496459961
step: 220, loss: 0.05885467305779457
step: 230, loss: 0.04648497328162193
step: 240, loss: 0.10565093159675598
step: 250, loss: 0.22522667050361633
step: 260, loss: 0.08096141368150711
step: 270, loss: 0.12205291539430618
step: 280, loss: 0.07608374953269958
step: 290, loss: 0.1110866591334343
step: 300, loss: 0.11213193833827972
step: 310, loss: 0.04243800416588783
step: 320, loss: 0.04490884765982628
step: 330, loss: 0.0550839863717556
step: 340, loss: 0.10366948693990707
step: 350, loss: 0.0910816416144371
step: 360, loss: 0.06977648288011551
step: 370, loss: 0.0589192695915699
step: 380, loss: 0.12763004004955292
step: 390, loss: 0.0846104845404625
step: 400, loss: 0.05877699702978134
step: 410, loss: 0.06082689389586449
step: 420, loss: 0.030908014625310898
step: 430, loss: 0.04431992769241333
step: 440, loss: 0.08833062648773193
step: 450, loss: 0.019896220415830612
step: 460, loss: 0.07560524344444275
step: 470, loss: 0.08336637169122696
step: 480, loss: 0.057243090122938156
step: 490, loss: 0.02417660690844059
step: 500, loss: 0.07538063824176788
step: 510, loss: 0.038920171558856964
step: 520, loss: 0.11303208023309708
step: 530, loss: 0.01679554209113121
step: 540, loss: 0.27981069684028625
step: 550, loss: 0.1736694723367691
step: 560, loss: 0.04660778492689133
step: 570, loss: 0.09144684672355652
step: 580, loss: 0.04956347495317459
step: 590, loss: 0.1259552389383316
step: 600, loss: 0.07904189825057983
step: 610, loss: 0.06054956465959549
step: 620, loss: 0.016250580549240112
step: 630, loss: 0.06632386893033981
step: 640, loss: 0.1420268565416336
step: 650, loss: 0.028519582003355026
step: 660, loss: 0.10784310102462769
step: 670, loss: 0.13380776345729828
step: 680, loss: 0.001886248355731368
step: 690, loss: 0.060557834804058075
step: 700, loss: 0.045641545206308365
step: 710, loss: 0.06595349311828613
step: 720, loss: 0.03343156352639198
step: 730, loss: 0.09483454376459122
step: 740, loss: 0.07945510745048523
step: 750, loss: 0.13877250254154205
step: 760, loss: 0.06529371440410614
step: 770, loss: 0.031916458159685135
step: 780, loss: 0.09164648503065109
step: 790, loss: 0.07655631750822067
step: 800, loss: 0.0995977446436882
step: 810, loss: 0.1132921352982521
step: 820, loss: 0.10510130971670151
step: 830, loss: 0.08833076804876328
step: 840, loss: 0.059389207512140274
step: 850, loss: 0.11667007207870483
step: 860, loss: 0.016671650111675262
step: 870, loss: 0.06048068031668663
step: 880, loss: 0.05570655316114426
step: 890, loss: 0.06947378069162369
step: 900, loss: 0.07483243197202682
step: 910, loss: 0.027609756216406822
step: 920, loss: 0.17492102086544037
step: 930, loss: 0.16734230518341064
step: 940, loss: 0.11592329293489456
step: 950, loss: 0.057012032717466354
step: 960, loss: 0.12482845783233643
step: 970, loss: 0.08823587745428085
step: 980, loss: 0.0661267563700676
step: 990, loss: 0.11259131878614426
step: 1000, loss: 0.04349392652511597
step: 1010, loss: 0.10423017293214798
step: 1020, loss: 0.03821853920817375
step: 1030, loss: 0.015011660754680634
step: 1040, loss: 0.07151755690574646
step: 1050, loss: 0.024088174104690552
step: 1060, loss: 0.06716524064540863
step: 1070, loss: 0.1452471911907196
epoch 2: dev_f1=0.9352189781021898, f1=0.9317561419472248, best_f1=0.9317561419472248
step: 0, loss: 0.01893315650522709
step: 10, loss: 0.028432069346308708
step: 20, loss: 0.13030782341957092
step: 30, loss: 0.06796883791685104
step: 40, loss: 0.08316434174776077
step: 50, loss: 0.01988827995955944
step: 60, loss: 0.10285034030675888
step: 70, loss: 0.019330371171236038
step: 80, loss: 0.0953756645321846
step: 90, loss: 0.03800203278660774
step: 100, loss: 0.019505752250552177
step: 110, loss: 0.0510922446846962
step: 120, loss: 0.18218767642974854
step: 130, loss: 0.08640289306640625
step: 140, loss: 0.07773434370756149
step: 150, loss: 0.05747233331203461
step: 160, loss: 0.06609465181827545
step: 170, loss: 0.14726941287517548
step: 180, loss: 0.0729585587978363
step: 190, loss: 0.12163632363080978
step: 200, loss: 0.18621106445789337
step: 210, loss: 0.09977759420871735
step: 220, loss: 0.0651085376739502
step: 230, loss: 0.14449170231819153
step: 240, loss: 0.024656526744365692
step: 250, loss: 0.11760267615318298
step: 260, loss: 0.07843959331512451
step: 270, loss: 0.029421446844935417
step: 280, loss: 0.017992626875638962
step: 290, loss: 0.10649394989013672
step: 300, loss: 0.3273320496082306
step: 310, loss: 0.030131325125694275
step: 320, loss: 0.04836036264896393
step: 330, loss: 0.10260245203971863
step: 340, loss: 0.10856311768293381
step: 350, loss: 0.031432073563337326
step: 360, loss: 0.13285265862941742
step: 370, loss: 0.016751153394579887
step: 380, loss: 0.0578165203332901
step: 390, loss: 0.01690441183745861
step: 400, loss: 0.22272124886512756
step: 410, loss: 0.18221591413021088
step: 420, loss: 0.11594482511281967
step: 430, loss: 0.12563855946063995
step: 440, loss: 0.06708438694477081
step: 450, loss: 0.14592070877552032
step: 460, loss: 0.06587043404579163
step: 470, loss: 0.16519345343112946
step: 480, loss: 0.034888118505477905
step: 490, loss: 0.05719665065407753
step: 500, loss: 0.046473242342472076
step: 510, loss: 0.014042472466826439
step: 520, loss: 0.08329769223928452
step: 530, loss: 0.15833938121795654
step: 540, loss: 0.04863985255360603
step: 550, loss: 0.08458690345287323
step: 560, loss: 0.19831062853336334
step: 570, loss: 0.05307317525148392
step: 580, loss: 0.050444185733795166
step: 590, loss: 0.07857419550418854
step: 600, loss: 0.0646897479891777
step: 610, loss: 0.04035348445177078
step: 620, loss: 0.07479047775268555
step: 630, loss: 0.11982900649309158
step: 640, loss: 0.07735741883516312
step: 650, loss: 0.08745311200618744
step: 660, loss: 0.11810004711151123
step: 670, loss: 0.14931011199951172
step: 680, loss: 0.06625377386808395
step: 690, loss: 0.07269960641860962
step: 700, loss: 0.04813187196850777
step: 710, loss: 0.010277177207171917
step: 720, loss: 0.1526826024055481
step: 730, loss: 0.07776340842247009
step: 740, loss: 0.07002723962068558
step: 750, loss: 0.03370819613337517
step: 760, loss: 0.17865680158138275
step: 770, loss: 0.07251885533332825
step: 780, loss: 0.03724485635757446
step: 790, loss: 0.07510875165462494
step: 800, loss: 0.08997154235839844
step: 810, loss: 0.18014992773532867
step: 820, loss: 0.12300210446119308
step: 830, loss: 0.07295093685388565
step: 840, loss: 0.024869516491889954
step: 850, loss: 0.09332524240016937
step: 860, loss: 0.09041126817464828
step: 870, loss: 0.0889464020729065
step: 880, loss: 0.06284492462873459
step: 890, loss: 0.056903135031461716
step: 900, loss: 0.015013976953923702
step: 910, loss: 0.04551008716225624
step: 920, loss: 0.19813869893550873
step: 930, loss: 0.026172151789069176
step: 940, loss: 0.12208573520183563
step: 950, loss: 0.08233585953712463
step: 960, loss: 0.05462512746453285
step: 970, loss: 0.07328161597251892
step: 980, loss: 0.07434768229722977
step: 990, loss: 0.07772883027791977
step: 1000, loss: 0.1055610179901123
step: 1010, loss: 0.14866016805171967
step: 1020, loss: 0.0528569221496582
step: 1030, loss: 0.21727323532104492
step: 1040, loss: 0.007986919023096561
step: 1050, loss: 0.09934230148792267
step: 1060, loss: 0.07520762085914612
step: 1070, loss: 0.23416198790073395
epoch 3: dev_f1=0.9384544192503471, f1=0.9352319706017456, best_f1=0.9352319706017456
step: 0, loss: 0.12113302201032639
step: 10, loss: 0.16481201350688934
step: 20, loss: 0.01600714772939682
step: 30, loss: 0.0365266352891922
step: 40, loss: 0.03602396324276924
step: 50, loss: 0.049517083913087845
step: 60, loss: 0.06469064950942993
step: 70, loss: 0.09770713001489639
step: 80, loss: 0.12941749393939972
step: 90, loss: 0.0574239157140255
step: 100, loss: 0.11499261111021042
step: 110, loss: 0.20291173458099365
step: 120, loss: 0.059383414685726166
step: 130, loss: 0.024672459810972214
step: 140, loss: 0.04095730930566788
step: 150, loss: 0.08512483537197113
step: 160, loss: 0.07953091710805893
step: 170, loss: 0.05484485253691673
step: 180, loss: 0.012197819538414478
step: 190, loss: 0.027593526989221573
step: 200, loss: 0.005559994839131832
step: 210, loss: 0.03787153214216232
step: 220, loss: 0.11371684074401855
step: 230, loss: 0.04469534009695053
step: 240, loss: 0.08362454921007156
step: 250, loss: 0.03821677342057228
step: 260, loss: 0.12551771104335785
step: 270, loss: 0.08305539935827255
step: 280, loss: 0.09715629369020462
step: 290, loss: 0.07603457570075989
step: 300, loss: 0.05066213756799698
step: 310, loss: 0.06266852468252182
step: 320, loss: 0.07038497179746628
step: 330, loss: 0.0733179971575737
step: 340, loss: 0.004119669087231159
step: 350, loss: 0.10068116337060928
step: 360, loss: 0.11101426929235458
step: 370, loss: 0.04005764424800873
step: 380, loss: 0.031248442828655243
step: 390, loss: 0.15303252637386322
step: 400, loss: 0.018718605861067772
step: 410, loss: 0.07308612763881683
step: 420, loss: 0.10157328099012375
step: 430, loss: 0.05941065028309822
step: 440, loss: 0.07706628739833832
step: 450, loss: 0.025067104026675224
step: 460, loss: 0.06625312566757202
step: 470, loss: 0.1424972414970398
step: 480, loss: 0.23400476574897766
step: 490, loss: 0.021114256232976913
step: 500, loss: 0.0631789118051529
step: 510, loss: 0.007371256127953529
step: 520, loss: 0.023502208292484283
step: 530, loss: 0.04574676603078842
step: 540, loss: 0.06502857059240341
step: 550, loss: 0.038799937814474106
step: 560, loss: 0.07034576684236526
step: 570, loss: 0.11711544543504715
step: 580, loss: 0.13229113817214966
step: 590, loss: 0.019832609221339226
step: 600, loss: 0.009607434272766113
step: 610, loss: 0.3045344948768616
step: 620, loss: 0.031289126724004745
step: 630, loss: 0.0770125687122345
step: 640, loss: 0.04747623950242996
step: 650, loss: 0.03687499463558197
step: 660, loss: 0.08082084357738495
step: 670, loss: 0.03532031551003456
step: 680, loss: 0.01993805170059204
step: 690, loss: 0.0051041459664702415
step: 700, loss: 0.07488317787647247
step: 710, loss: 0.025511182844638824
step: 720, loss: 0.015792831778526306
step: 730, loss: 0.050087764859199524
step: 740, loss: 0.005548459477722645
step: 750, loss: 0.06883340328931808
step: 760, loss: 0.0453912653028965
step: 770, loss: 0.07273678481578827
step: 780, loss: 0.015894414857029915
step: 790, loss: 0.027542898431420326
step: 800, loss: 0.07163526862859726
step: 810, loss: 0.17756013572216034
step: 820, loss: 0.1781594157218933
step: 830, loss: 0.02835681289434433
step: 840, loss: 0.05340629816055298
step: 850, loss: 0.07269512861967087
step: 860, loss: 0.16340625286102295
step: 870, loss: 0.10787269473075867
step: 880, loss: 0.05200778320431709
step: 890, loss: 0.09655546396970749
step: 900, loss: 0.02299024723470211
step: 910, loss: 0.07617242634296417
step: 920, loss: 0.03200385347008705
step: 930, loss: 0.04456685483455658
step: 940, loss: 0.08395097404718399
step: 950, loss: 0.09694160521030426
step: 960, loss: 0.05520497262477875
step: 970, loss: 0.05293745920062065
step: 980, loss: 0.029577985405921936
step: 990, loss: 0.046858906745910645
step: 1000, loss: 0.029896140098571777
step: 1010, loss: 0.04642924293875694
step: 1020, loss: 0.061414264142513275
step: 1030, loss: 0.09783707559108734
step: 1040, loss: 0.09516747295856476
step: 1050, loss: 0.1520892083644867
step: 1060, loss: 0.10511098802089691
step: 1070, loss: 0.04370768740773201
epoch 4: dev_f1=0.9418874941887495, f1=0.9341372912801483, best_f1=0.9341372912801483
step: 0, loss: 0.04634244367480278
step: 10, loss: 0.15121877193450928
step: 20, loss: 0.20008690655231476
step: 30, loss: 0.04962742701172829
step: 40, loss: 0.03569658845663071
step: 50, loss: 0.02587810344994068
step: 60, loss: 0.07306700199842453
step: 70, loss: 0.0156694483011961
step: 80, loss: 0.02567942999303341
step: 90, loss: 0.10439232736825943
step: 100, loss: 0.019308539107441902
step: 110, loss: 0.02939603105187416
step: 120, loss: 0.0643041729927063
step: 130, loss: 0.1545524150133133
step: 140, loss: 0.12451793253421783
step: 150, loss: 0.07236511260271072
step: 160, loss: 0.0173790380358696
step: 170, loss: 0.032571032643318176
step: 180, loss: 0.08405789732933044
step: 190, loss: 0.11911223828792572
step: 200, loss: 0.0221544299274683
step: 210, loss: 0.015554090961813927
step: 220, loss: 0.017472023144364357
step: 230, loss: 0.06621173024177551
step: 240, loss: 0.04954501986503601
step: 250, loss: 0.05698337405920029
step: 260, loss: 0.05016346275806427
step: 270, loss: 0.017182180657982826
step: 280, loss: 0.03563448041677475
step: 290, loss: 0.14848686754703522
step: 300, loss: 0.07102570682764053
step: 310, loss: 0.1214168593287468
step: 320, loss: 0.10346145182847977
step: 330, loss: 0.04917418211698532
step: 340, loss: 0.04785798117518425
step: 350, loss: 0.06057899072766304
step: 360, loss: 0.09012845903635025
step: 370, loss: 0.09143934398889542
step: 380, loss: 0.06800348311662674
step: 390, loss: 0.09871291369199753
step: 400, loss: 0.03874969482421875
step: 410, loss: 0.09861760586500168
step: 420, loss: 0.049124810844659805
step: 430, loss: 0.05063492804765701
step: 440, loss: 0.05280948802828789
step: 450, loss: 0.037618063390254974
step: 460, loss: 0.04536966606974602
step: 470, loss: 0.0072949957102537155
step: 480, loss: 0.09907496720552444
step: 490, loss: 0.016420219093561172
step: 500, loss: 0.009012864902615547
step: 510, loss: 0.04162402078509331
step: 520, loss: 0.00645431550219655
step: 530, loss: 0.10507804900407791
step: 540, loss: 0.07215079665184021
step: 550, loss: 0.009584922343492508
step: 560, loss: 0.010130117647349834
step: 570, loss: 0.012013347819447517
step: 580, loss: 0.09757016599178314
step: 590, loss: 0.2191191464662552
step: 600, loss: 0.0572967454791069
step: 610, loss: 0.04723421856760979
step: 620, loss: 0.11511019617319107
step: 630, loss: 0.1148497685790062
step: 640, loss: 0.04068931192159653
step: 650, loss: 0.23044012486934662
step: 660, loss: 0.03567171469330788
step: 670, loss: 0.055401511490345
step: 680, loss: 0.1411624699831009
step: 690, loss: 0.16479508578777313
step: 700, loss: 0.048630379140377045
step: 710, loss: 0.05033660680055618
step: 720, loss: 0.0717734768986702
step: 730, loss: 0.06818564981222153
step: 740, loss: 0.11949361115694046
step: 750, loss: 0.19509966671466827
step: 760, loss: 0.03707488253712654
step: 770, loss: 0.01175824273377657
step: 780, loss: 0.027003683149814606
step: 790, loss: 0.14677974581718445
step: 800, loss: 0.0749974399805069
step: 810, loss: 0.04046546667814255
step: 820, loss: 0.020734798163175583
step: 830, loss: 0.04252990707755089
step: 840, loss: 0.14399851858615875
step: 850, loss: 0.016933424398303032
step: 860, loss: 0.027373511344194412
step: 870, loss: 0.013667971827089787
step: 880, loss: 0.07046528905630112
step: 890, loss: 0.04108560457825661
step: 900, loss: 0.06063329800963402
step: 910, loss: 0.08477141708135605
step: 920, loss: 0.03852621093392372
step: 930, loss: 0.10050569474697113
step: 940, loss: 0.07083380222320557
step: 950, loss: 0.07809463143348694
step: 960, loss: 0.05698471516370773
step: 970, loss: 0.045130085200071335
step: 980, loss: 0.052311889827251434
step: 990, loss: 0.11488749086856842
step: 1000, loss: 0.19015038013458252
step: 1010, loss: 0.009730183519423008
step: 1020, loss: 0.08466958999633789
step: 1030, loss: 0.05791451036930084
step: 1040, loss: 0.06677110493183136
step: 1050, loss: 0.04156915470957756
step: 1060, loss: 0.01947174221277237
step: 1070, loss: 0.10626031458377838
epoch 5: dev_f1=0.9371428571428572, f1=0.9344648750589346, best_f1=0.9341372912801483
step: 0, loss: 0.07703794538974762
step: 10, loss: 0.0476178415119648
step: 20, loss: 0.02509733848273754
step: 30, loss: 0.03545393794775009
step: 40, loss: 0.08285561949014664
step: 50, loss: 0.029941191896796227
step: 60, loss: 0.09114736318588257
step: 70, loss: 0.02339080721139908
step: 80, loss: 0.018964042887091637
step: 90, loss: 0.027898862957954407
step: 100, loss: 0.09119875729084015
step: 110, loss: 0.06353843957185745
step: 120, loss: 0.06631236523389816
step: 130, loss: 0.020040014758706093
step: 140, loss: 0.025948503986001015
step: 150, loss: 0.026324810460209846
step: 160, loss: 0.1473667174577713
step: 170, loss: 0.09210546314716339
step: 180, loss: 0.02261507511138916
step: 190, loss: 0.09202336519956589
step: 200, loss: 0.08629078418016434
step: 210, loss: 0.0391041599214077
step: 220, loss: 0.044393036514520645
step: 230, loss: 0.1033574789762497
step: 240, loss: 0.008032075129449368
step: 250, loss: 0.04972262308001518
step: 260, loss: 0.0030943204183131456
step: 270, loss: 0.09451482445001602
step: 280, loss: 0.07217960059642792
step: 290, loss: 0.030662044882774353
step: 300, loss: 0.04631379619240761
step: 310, loss: 0.022753380239009857
step: 320, loss: 0.0002912005875259638
step: 330, loss: 0.056367386132478714
step: 340, loss: 0.039664238691329956
step: 350, loss: 0.023458637297153473
step: 360, loss: 0.05045130476355553
step: 370, loss: 0.016721084713935852
step: 380, loss: 0.06550996750593185
step: 390, loss: 0.03033388964831829
step: 400, loss: 0.025615472346544266
step: 410, loss: 0.06719948351383209
step: 420, loss: 0.040493302047252655
step: 430, loss: 0.03102290630340576
step: 440, loss: 0.029079003259539604
step: 450, loss: 0.02243567444384098
step: 460, loss: 0.03549738600850105
step: 470, loss: 0.05719014257192612
step: 480, loss: 0.06814603507518768
step: 490, loss: 0.09733903408050537
step: 500, loss: 0.04552258923649788
step: 510, loss: 0.03970348462462425
step: 520, loss: 0.003285342361778021
step: 530, loss: 0.06575453281402588
step: 540, loss: 0.035721052438020706
step: 550, loss: 0.015276717022061348
step: 560, loss: 0.0041640703566372395
step: 570, loss: 0.07880702614784241
step: 580, loss: 0.047432295978069305
step: 590, loss: 0.06559807807207108
step: 600, loss: 0.023188769817352295
step: 610, loss: 0.0807638019323349
step: 620, loss: 0.08543934673070908
step: 630, loss: 0.07057255506515503
step: 640, loss: 0.10686599463224411
step: 650, loss: 0.07237208634614944
step: 660, loss: 0.07066948711872101
step: 670, loss: 0.0774059072136879
step: 680, loss: 0.04774476960301399
step: 690, loss: 0.13853789865970612
step: 700, loss: 0.022641392424702644
step: 710, loss: 0.042240262031555176
step: 720, loss: 0.07626406848430634
step: 730, loss: 0.02647213265299797
step: 740, loss: 0.03735528141260147
step: 750, loss: 0.02906930260360241
step: 760, loss: 0.029086243361234665
step: 770, loss: 0.043797045946121216
step: 780, loss: 0.004599898587912321
step: 790, loss: 0.014930522069334984
step: 800, loss: 0.08056879788637161
step: 810, loss: 0.003432667115703225
step: 820, loss: 0.054145850241184235
step: 830, loss: 0.01066513266414404
step: 840, loss: 0.06830612570047379
step: 850, loss: 0.10921023786067963
step: 860, loss: 0.18270590901374817
step: 870, loss: 0.08907823264598846
step: 880, loss: 0.02714928239583969
step: 890, loss: 0.02344539947807789
step: 900, loss: 0.021525638177990913
step: 910, loss: 0.017423680052161217
step: 920, loss: 0.0738825723528862
step: 930, loss: 0.1481720209121704
step: 940, loss: 0.07083196192979813
step: 950, loss: 0.011742040514945984
step: 960, loss: 0.0654926523566246
step: 970, loss: 0.05989179387688637
step: 980, loss: 0.08138388395309448
step: 990, loss: 0.06335869431495667
step: 1000, loss: 0.07332347333431244
step: 1010, loss: 0.11909046024084091
step: 1020, loss: 0.021298490464687347
step: 1030, loss: 0.14034388959407806
step: 1040, loss: 0.15091806650161743
step: 1050, loss: 0.027699187397956848
step: 1060, loss: 0.008733640424907207
step: 1070, loss: 0.015249621123075485
epoch 6: dev_f1=0.9360709286047598, f1=0.9330232558139535, best_f1=0.9341372912801483
step: 0, loss: 0.008276613429188728
step: 10, loss: 0.008060364983975887
step: 20, loss: 0.02706790901720524
step: 30, loss: 0.015456484630703926
step: 40, loss: 8.153813541866839e-05
step: 50, loss: 0.05366029217839241
step: 60, loss: 0.020770203322172165
step: 70, loss: 0.0596366710960865
step: 80, loss: 0.13167794048786163
step: 90, loss: 0.03814411908388138
step: 100, loss: 0.0019101587822660804
step: 110, loss: 0.23973944783210754
step: 120, loss: 0.02446935325860977
step: 130, loss: 0.03606973588466644
step: 140, loss: 0.08581665903329849
step: 150, loss: 0.06021372228860855
step: 160, loss: 0.06218058615922928
step: 170, loss: 0.028268706053495407
step: 180, loss: 0.0653727725148201
step: 190, loss: 0.02288644015789032
step: 200, loss: 0.0364563949406147
step: 210, loss: 0.014214764349162579
step: 220, loss: 0.030205223709344864
step: 230, loss: 0.01596170663833618
step: 240, loss: 0.014171364717185497
step: 250, loss: 0.012521586380898952
step: 260, loss: 0.037693314254283905
step: 270, loss: 0.0396246463060379
step: 280, loss: 0.008297426626086235
step: 290, loss: 0.05279453471302986
step: 300, loss: 0.026702798902988434
step: 310, loss: 0.030945800244808197
step: 320, loss: 0.0768398642539978
step: 330, loss: 0.008475454524159431
step: 340, loss: 0.051414504647254944
step: 350, loss: 0.031872011721134186
step: 360, loss: 0.13122662901878357
step: 370, loss: 0.08554214239120483
step: 380, loss: 0.039116159081459045
step: 390, loss: 0.02830531634390354
step: 400, loss: 0.08776090294122696
step: 410, loss: 0.009984264150261879
step: 420, loss: 0.026566321030259132
step: 430, loss: 0.12707360088825226
step: 440, loss: 0.03804970905184746
step: 450, loss: 0.016110926866531372
step: 460, loss: 0.00020405508985277265
step: 470, loss: 4.524454561760649e-05
step: 480, loss: 0.04800969362258911
step: 490, loss: 0.07400545477867126
step: 500, loss: 0.010091312229633331
step: 510, loss: 0.11370588839054108
step: 520, loss: 0.07417214661836624
step: 530, loss: 0.09153156727552414
step: 540, loss: 0.21545085310935974
step: 550, loss: 0.05758187174797058
step: 560, loss: 0.018932625651359558
step: 570, loss: 0.08822045475244522
step: 580, loss: 0.173863023519516
step: 590, loss: 0.07799240201711655
step: 600, loss: 0.05671475827693939
step: 610, loss: 1.9017348677152768e-05
step: 620, loss: 0.059082046151161194
step: 630, loss: 0.019677747040987015
step: 640, loss: 0.0781661719083786
step: 650, loss: 0.05040750652551651
step: 660, loss: 0.06880802661180496
step: 670, loss: 0.14475634694099426
step: 680, loss: 0.08591576665639877
step: 690, loss: 0.035405248403549194
step: 700, loss: 0.17450818419456482
step: 710, loss: 0.044662803411483765
step: 720, loss: 0.021968889981508255
step: 730, loss: 0.10984861850738525
step: 740, loss: 0.08447472006082535
step: 750, loss: 0.04324101284146309
step: 760, loss: 0.01983383670449257
step: 770, loss: 0.006336707156151533
step: 780, loss: 0.009925971738994122
step: 790, loss: 0.07365593314170837
step: 800, loss: 0.08830540627241135
step: 810, loss: 0.007349157705903053
step: 820, loss: 0.011032930575311184
step: 830, loss: 0.09110024571418762
step: 840, loss: 0.021388016641139984
step: 850, loss: 0.08777188509702682
step: 860, loss: 0.010229258798062801
step: 870, loss: 0.07250263541936874
step: 880, loss: 0.03414226323366165
step: 890, loss: 0.01570184715092182
step: 900, loss: 0.13133135437965393
step: 910, loss: 0.04985853284597397
step: 920, loss: 0.00015861471183598042
step: 930, loss: 0.10487185418605804
step: 940, loss: 0.029310787096619606
step: 950, loss: 0.0238006841391325
step: 960, loss: 0.14709067344665527
step: 970, loss: 0.06019311398267746
step: 980, loss: 0.057863377034664154
step: 990, loss: 0.01183578372001648
step: 1000, loss: 0.0251314640045166
step: 1010, loss: 0.010756870731711388
step: 1020, loss: 0.03535747528076172
step: 1030, loss: 0.017629487439990044
step: 1040, loss: 0.05391016975045204
step: 1050, loss: 0.11029603332281113
step: 1060, loss: 0.0903201624751091
step: 1070, loss: 0.005236825905740261
epoch 7: dev_f1=0.9328493647912885, f1=0.9301270417422868, best_f1=0.9341372912801483
step: 0, loss: 0.00021277382620610297
step: 10, loss: 0.11220943182706833
step: 20, loss: 0.07840889692306519
step: 30, loss: 0.03948540240526199
step: 40, loss: 0.013413508422672749
step: 50, loss: 0.011394733563065529
step: 60, loss: 0.07956510782241821
step: 70, loss: 0.08652535080909729
step: 80, loss: 0.10129276663064957
step: 90, loss: 0.05409874767065048
step: 100, loss: 0.014198960736393929
step: 110, loss: 0.011209593154489994
step: 120, loss: 0.08477714657783508
step: 130, loss: 0.0827605202794075
step: 140, loss: 0.1436130255460739
step: 150, loss: 0.008056568913161755
step: 160, loss: 0.02455516904592514
step: 170, loss: 0.08549880981445312
step: 180, loss: 0.03550441935658455
step: 190, loss: 0.007317219395190477
step: 200, loss: 0.08946447819471359
step: 210, loss: 0.02072468400001526
step: 220, loss: 0.1051892414689064
step: 230, loss: 0.006517380475997925
step: 240, loss: 0.02312290668487549
step: 250, loss: 0.062455128878355026
step: 260, loss: 0.0265080276876688
step: 270, loss: 0.08476162701845169
step: 280, loss: 0.06779833883047104
step: 290, loss: 0.07609689235687256
step: 300, loss: 0.09576678276062012
step: 310, loss: 0.04255251958966255
step: 320, loss: 0.03810699284076691
step: 330, loss: 0.18155133724212646
step: 340, loss: 0.014354906976222992
step: 350, loss: 0.02640700154006481
step: 360, loss: 0.03716244176030159
step: 370, loss: 0.04831936955451965
step: 380, loss: 0.10647494345903397
step: 390, loss: 0.07509484887123108
step: 400, loss: 0.017400875687599182
step: 410, loss: 0.09824550151824951
step: 420, loss: 0.008492065593600273
step: 430, loss: 0.04706057161092758
step: 440, loss: 0.09314986318349838
step: 450, loss: 0.014338908717036247
step: 460, loss: 0.03455548733472824
step: 470, loss: 0.07274913787841797
step: 480, loss: 0.06135179474949837
step: 490, loss: 0.00492433924227953
step: 500, loss: 0.05205832049250603
step: 510, loss: 0.03999004885554314
step: 520, loss: 0.07185113430023193
step: 530, loss: 0.005926637444645166
step: 540, loss: 0.00308179366402328
step: 550, loss: 0.023525258526206017
step: 560, loss: 0.13253828883171082
step: 570, loss: 0.13451912999153137
step: 580, loss: 0.07563117891550064
step: 590, loss: 0.024008046835660934
step: 600, loss: 0.06137958914041519
step: 610, loss: 0.05424797534942627
step: 620, loss: 0.0627051293849945
step: 630, loss: 0.029327992349863052
step: 640, loss: 0.017785482108592987
step: 650, loss: 0.10276851058006287
step: 660, loss: 0.02345104143023491
step: 670, loss: 0.06608928740024567
step: 680, loss: 0.07806111872196198
step: 690, loss: 0.059886544942855835
step: 700, loss: 0.06665270030498505
step: 710, loss: 0.030980346724390984
step: 720, loss: 0.1303917020559311
step: 730, loss: 0.12090783566236496
step: 740, loss: 0.13007500767707825
step: 750, loss: 0.06982921808958054
step: 760, loss: 0.06494477391242981
step: 770, loss: 0.030548760667443275
step: 780, loss: 0.005104564595967531
step: 790, loss: 0.05393174663186073
step: 800, loss: 0.04187552630901337
step: 810, loss: 0.01586158201098442
step: 820, loss: 0.048023998737335205
step: 830, loss: 0.002128063701093197
step: 840, loss: 0.013366647064685822
step: 850, loss: 0.08435765653848648
step: 860, loss: 0.1570054441690445
step: 870, loss: 0.17518582940101624
step: 880, loss: 0.011119483038783073
step: 890, loss: 0.020237520337104797
step: 900, loss: 0.012733451090753078
step: 910, loss: 0.1656915694475174
step: 920, loss: 0.004086644388735294
step: 930, loss: 0.05940212309360504
step: 940, loss: 0.059307344257831573
step: 950, loss: 0.08417139947414398
step: 960, loss: 0.052478041499853134
step: 970, loss: 0.02671882137656212
step: 980, loss: 0.08850251883268356
step: 990, loss: 0.08433517813682556
step: 1000, loss: 0.005426212679594755
step: 1010, loss: 0.04489253833889961
step: 1020, loss: 0.07686194032430649
step: 1030, loss: 0.08635978400707245
step: 1040, loss: 0.008841046132147312
step: 1050, loss: 0.07175131142139435
step: 1060, loss: 0.09262138605117798
step: 1070, loss: 0.10012227296829224
epoch 8: dev_f1=0.9405306495882891, f1=0.9317051108095885, best_f1=0.9341372912801483
step: 0, loss: 0.03139500692486763
step: 10, loss: 0.06777889281511307
step: 20, loss: 0.020046576857566833
step: 30, loss: 0.011399766430258751
step: 40, loss: 0.08712668716907501
step: 50, loss: 0.1775113046169281
step: 60, loss: 0.007863285019993782
step: 70, loss: 0.018100900575518608
step: 80, loss: 0.056365497410297394
step: 90, loss: 0.0119804497808218
step: 100, loss: 0.04020242765545845
step: 110, loss: 0.03408065065741539
step: 120, loss: 0.003443974070250988
step: 130, loss: 0.022820504382252693
step: 140, loss: 0.0411534421145916
step: 150, loss: 0.03737925365567207
step: 160, loss: 0.07283282279968262
step: 170, loss: 0.13829052448272705
step: 180, loss: 0.014775711111724377
step: 190, loss: 0.09460198879241943
step: 200, loss: 0.0532173253595829
step: 210, loss: 0.01993795670568943
step: 220, loss: 0.004264137241989374
step: 230, loss: 0.02456546202301979
step: 240, loss: 0.009878914803266525
step: 250, loss: 0.09783923625946045
step: 260, loss: 0.027134506031870842
step: 270, loss: 0.01175831537693739
step: 280, loss: 0.0024287591222673655
step: 290, loss: 0.06915248185396194
step: 300, loss: 0.0027698874473571777
step: 310, loss: 0.05256783962249756
step: 320, loss: 0.0357726588845253
step: 330, loss: 0.020905552431941032
step: 340, loss: 0.02949029766023159
step: 350, loss: 0.052087586373090744
step: 360, loss: 0.01913478970527649
step: 370, loss: 0.095384880900383
step: 380, loss: 0.032118722796440125
step: 390, loss: 0.019672872498631477
step: 400, loss: 0.031889040023088455
step: 410, loss: 0.016838179901242256
step: 420, loss: 0.009707864373922348
step: 430, loss: 0.016479961574077606
step: 440, loss: 0.077903151512146
step: 450, loss: 0.06799036264419556
step: 460, loss: 0.03245511278510094
step: 470, loss: 0.010097678750753403
step: 480, loss: 0.0377846360206604
step: 490, loss: 0.01696390099823475
step: 500, loss: 6.0769245465053245e-05
step: 510, loss: 0.07821819186210632
step: 520, loss: 0.02038794383406639
step: 530, loss: 0.08708392828702927
step: 540, loss: 0.02724716067314148
step: 550, loss: 0.1331462264060974
step: 560, loss: 0.008337113074958324
step: 570, loss: 1.9452312699286267e-05
step: 580, loss: 0.021983342245221138
step: 590, loss: 0.03338408097624779
step: 600, loss: 0.10718381404876709
step: 610, loss: 0.0996473878622055
step: 620, loss: 0.0051176659762859344
step: 630, loss: 0.015178455971181393
step: 640, loss: 0.02881406992673874
step: 650, loss: 0.013959941454231739
step: 660, loss: 0.009528975933790207
step: 670, loss: 0.039835937321186066
step: 680, loss: 0.0001345312484772876
step: 690, loss: 0.07215911149978638
step: 700, loss: 0.02383001334965229
step: 710, loss: 0.1458737701177597
step: 720, loss: 0.037917137145996094
step: 730, loss: 0.1591261476278305
step: 740, loss: 0.030149860307574272
step: 750, loss: 0.004149796906858683
step: 760, loss: 0.025076262652873993
step: 770, loss: 0.037010595202445984
step: 780, loss: 0.043990910053253174
step: 790, loss: 0.0015803888672962785
step: 800, loss: 0.09868913143873215
step: 810, loss: 0.08893478661775589
step: 820, loss: 0.11759694665670395
step: 830, loss: 0.024566512554883957
step: 840, loss: 0.02527892403304577
step: 850, loss: 0.02133755572140217
step: 860, loss: 0.08055223524570465
step: 870, loss: 0.13510861992835999
step: 880, loss: 0.11955921351909637
step: 890, loss: 0.013693396002054214
step: 900, loss: 0.0672091394662857
step: 910, loss: 0.043592419475317
step: 920, loss: 0.0869656428694725
step: 930, loss: 0.009307000786066055
step: 940, loss: 0.035860154777765274
step: 950, loss: 0.20882678031921387
step: 960, loss: 0.020463692024350166
step: 970, loss: 0.04689950495958328
step: 980, loss: 0.025738626718521118
step: 990, loss: 0.023124681785702705
step: 1000, loss: 0.054768577218055725
step: 1010, loss: 0.010591572150588036
step: 1020, loss: 0.053206343203783035
step: 1030, loss: 0.02271881327033043
step: 1040, loss: 0.0778685137629509
step: 1050, loss: 0.0052133165299892426
step: 1060, loss: 0.06099163740873337
step: 1070, loss: 0.006787294056266546
epoch 9: dev_f1=0.9354691075514875, f1=0.9338168631006345, best_f1=0.9341372912801483
step: 0, loss: 0.04359887167811394
step: 10, loss: 0.11973696202039719
step: 20, loss: 0.00822214875370264
step: 30, loss: 0.008030847646296024
step: 40, loss: 0.012992056086659431
step: 50, loss: 0.04799993708729744
step: 60, loss: 0.0816311165690422
step: 70, loss: 0.044180773198604584
step: 80, loss: 0.08377626538276672
step: 90, loss: 0.0044530238956213
step: 100, loss: 0.06674820929765701
step: 110, loss: 0.008305363357067108
step: 120, loss: 0.0808006301522255
step: 130, loss: 0.07130541652441025
step: 140, loss: 0.05534796789288521
step: 150, loss: 0.0946931391954422
step: 160, loss: 0.03070814535021782
step: 170, loss: 0.15056902170181274
step: 180, loss: 0.007231825962662697
step: 190, loss: 0.11673992872238159
step: 200, loss: 0.01477990671992302
step: 210, loss: 0.052177757024765015
step: 220, loss: 0.0464010126888752
step: 230, loss: 0.001786528737284243
step: 240, loss: 0.0668429359793663
step: 250, loss: 0.047377925366163254
step: 260, loss: 0.0973605066537857
step: 270, loss: 0.06787358224391937
step: 280, loss: 0.027081172913312912
step: 290, loss: 0.03638920933008194
step: 300, loss: 0.011892542243003845
step: 310, loss: 0.048744652420282364
step: 320, loss: 0.013719601556658745
step: 330, loss: 0.00346523174084723
step: 340, loss: 0.017828065901994705
step: 350, loss: 0.1600029021501541
step: 360, loss: 0.01038641668856144
step: 370, loss: 0.014843657612800598
step: 380, loss: 0.0877932757139206
step: 390, loss: 0.022662492468953133
step: 400, loss: 0.09455080330371857
step: 410, loss: 0.17338880896568298
step: 420, loss: 0.11374672502279282
step: 430, loss: 0.00987992249429226
step: 440, loss: 0.014549186453223228
step: 450, loss: 0.14920444786548615
step: 460, loss: 0.025250853970646858
step: 470, loss: 0.044795118272304535
step: 480, loss: 0.007858656346797943
step: 490, loss: 0.003136980114504695
step: 500, loss: 0.04861396178603172
step: 510, loss: 0.10824070125818253
step: 520, loss: 0.058616138994693756
step: 530, loss: 0.0005088361795060337
step: 540, loss: 0.06504996865987778
step: 550, loss: 0.12874998152256012
step: 560, loss: 0.04299312084913254
step: 570, loss: 0.0109605947509408
step: 580, loss: 0.007416377775371075
step: 590, loss: 0.0062030283734202385
step: 600, loss: 0.08238022774457932
step: 610, loss: 0.018205340951681137
step: 620, loss: 0.03824281692504883
step: 630, loss: 0.08850182592868805
step: 640, loss: 0.016163295134902
step: 650, loss: 0.09008350223302841
step: 660, loss: 0.06293225288391113
step: 670, loss: 0.07883106917142868
step: 680, loss: 0.010271531529724598
step: 690, loss: 0.034511931240558624
step: 700, loss: 0.04132016748189926
step: 710, loss: 0.06988167017698288
step: 720, loss: 0.058609042316675186
step: 730, loss: 0.07334589958190918
step: 740, loss: 0.03406732901930809
step: 750, loss: 0.032564301043748856
step: 760, loss: 0.06690606474876404
step: 770, loss: 0.07263174653053284
step: 780, loss: 0.11372435092926025
step: 790, loss: 0.018404794856905937
step: 800, loss: 0.017697107046842575
step: 810, loss: 0.05814934894442558
step: 820, loss: 0.014980633743107319
step: 830, loss: 0.020965445786714554
step: 840, loss: 0.01756850630044937
step: 850, loss: 0.135421022772789
step: 860, loss: 0.014638256281614304
step: 870, loss: 0.1158352792263031
step: 880, loss: 0.09613605588674545
step: 890, loss: 0.030683955177664757
step: 900, loss: 0.0461944080889225
step: 910, loss: 0.020327193662524223
step: 920, loss: 0.05024750903248787
step: 930, loss: 0.03775842860341072
step: 940, loss: 0.03921661898493767
step: 950, loss: 0.017284076660871506
step: 960, loss: 0.07473087310791016
step: 970, loss: 0.035209111869335175
step: 980, loss: 0.04738538712263107
step: 990, loss: 0.03445376455783844
step: 1000, loss: 0.05543959140777588
step: 1010, loss: 0.04755061864852905
step: 1020, loss: 0.06535568833351135
step: 1030, loss: 0.053350578993558884
step: 1040, loss: 0.017165351659059525
step: 1050, loss: 0.026737887412309647
step: 1060, loss: 0.01378548238426447
step: 1070, loss: 0.0038460404612123966
epoch 10: dev_f1=0.9335205992509362, f1=0.9302973977695168, best_f1=0.9341372912801483
step: 0, loss: 0.04785484820604324
step: 10, loss: 0.011744800955057144
step: 20, loss: 0.11669258773326874
step: 30, loss: 0.035192325711250305
step: 40, loss: 0.10805671662092209
step: 50, loss: 0.005299871321767569
step: 60, loss: 0.03277447074651718
step: 70, loss: 0.03852826729416847
step: 80, loss: 0.09305580705404282
step: 90, loss: 0.03687617927789688
step: 100, loss: 0.038613323122262955
step: 110, loss: 0.01881515420973301
step: 120, loss: 0.04705481231212616
step: 130, loss: 0.023116767406463623
step: 140, loss: 0.005660018417984247
step: 150, loss: 0.010555005632340908
step: 160, loss: 0.0483856163918972
step: 170, loss: 1.7370763089274988e-05
step: 180, loss: 0.04090619459748268
step: 190, loss: 0.04131979122757912
step: 200, loss: 0.03863929584622383
step: 210, loss: 0.0922570750117302
step: 220, loss: 0.01001165434718132
step: 230, loss: 0.03830365836620331
step: 240, loss: 0.02726597897708416
step: 250, loss: 0.02617468684911728
step: 260, loss: 0.0023366869427263737
step: 270, loss: 0.006003114394843578
step: 280, loss: 0.009359666146337986
step: 290, loss: 0.03403828293085098
step: 300, loss: 0.012307314202189445
step: 310, loss: 0.050723154097795486
step: 320, loss: 0.022822311148047447
step: 330, loss: 0.011606755666434765
step: 340, loss: 0.03572412207722664
step: 350, loss: 0.11200426518917084
step: 360, loss: 0.006678151432424784
step: 370, loss: 0.0697403997182846
step: 380, loss: 0.08725567907094955
step: 390, loss: 0.017065895721316338
step: 400, loss: 0.12447043508291245
step: 410, loss: 0.06362001597881317
step: 420, loss: 0.022584380581974983
step: 430, loss: 0.06662756949663162
step: 440, loss: 0.05835112929344177
step: 450, loss: 0.0013298102421686053
step: 460, loss: 0.022681990638375282
step: 470, loss: 0.06939682364463806
step: 480, loss: 0.013271704316139221
step: 490, loss: 0.06242389231920242
step: 500, loss: 0.04198792949318886
step: 510, loss: 0.029864169657230377
step: 520, loss: 0.008477629162371159
step: 530, loss: 0.016840018332004547
step: 540, loss: 0.023328734561800957
step: 550, loss: 0.0042805843986570835
step: 560, loss: 0.06792772561311722
step: 570, loss: 0.010760384611785412
step: 580, loss: 0.010816015303134918
step: 590, loss: 0.002816168125718832
step: 600, loss: 0.012737476266920567
step: 610, loss: 0.01732609234750271
step: 620, loss: 0.011464124545454979
step: 630, loss: 0.059389837086200714
step: 640, loss: 0.05932289734482765
step: 650, loss: 0.05735313892364502
step: 660, loss: 0.10981060564517975
step: 670, loss: 0.0512605682015419
step: 680, loss: 0.04023095592856407
step: 690, loss: 0.011723310686647892
step: 700, loss: 0.04446316137909889
step: 710, loss: 0.061632897704839706
step: 720, loss: 0.11371175199747086
step: 730, loss: 0.10013049840927124
step: 740, loss: 0.018515951931476593
step: 750, loss: 0.060305386781692505
step: 760, loss: 0.08705276250839233
step: 770, loss: 0.0023913958575576544
step: 780, loss: 0.08925630897283554
step: 790, loss: 0.041945770382881165
step: 800, loss: 0.12703344225883484
step: 810, loss: 0.06550323218107224
step: 820, loss: 0.009613309986889362
step: 830, loss: 0.010906604118645191
step: 840, loss: 0.0657363086938858
step: 850, loss: 0.02507696859538555
step: 860, loss: 0.015215860679745674
step: 870, loss: 0.10521139204502106
step: 880, loss: 0.01685013435781002
step: 890, loss: 0.01555861160159111
step: 900, loss: 0.06535753607749939
step: 910, loss: 0.0024350115563720465
step: 920, loss: 0.0332757867872715
step: 930, loss: 0.011442773975431919
step: 940, loss: 0.013531303033232689
step: 950, loss: 0.009477616287767887
step: 960, loss: 0.02916518971323967
step: 970, loss: 0.24029763042926788
step: 980, loss: 0.017850715667009354
step: 990, loss: 0.010886394418776035
step: 1000, loss: 0.01770479418337345
step: 1010, loss: 0.02052435092628002
step: 1020, loss: 0.03060823678970337
step: 1030, loss: 0.04447105526924133
step: 1040, loss: 0.07109326124191284
step: 1050, loss: 0.0032576248049736023
step: 1060, loss: 0.04806132987141609
step: 1070, loss: 0.014173147268593311
epoch 11: dev_f1=0.9368863955119214, f1=0.9403606102635228, best_f1=0.9341372912801483
step: 0, loss: 0.08688165247440338
step: 10, loss: 0.06720636785030365
step: 20, loss: 0.07539861649274826
step: 30, loss: 0.08069247752428055
step: 40, loss: 0.00857490487396717
step: 50, loss: 0.12299777567386627
step: 60, loss: 0.001334338216111064
step: 70, loss: 0.001359115238301456
step: 80, loss: 0.0002825949341058731
step: 90, loss: 0.038049496710300446
step: 100, loss: 0.00399712985381484
step: 110, loss: 0.00790400616824627
step: 120, loss: 0.058329589664936066
step: 130, loss: 0.009560908190906048
step: 140, loss: 0.04969661682844162
step: 150, loss: 0.006518402602523565
step: 160, loss: 0.05447143316268921
step: 170, loss: 0.04890018329024315
step: 180, loss: 0.040709566324949265
step: 190, loss: 0.005340036004781723
step: 200, loss: 0.045967333018779755
step: 210, loss: 0.01873145066201687
step: 220, loss: 0.007728219032287598
step: 230, loss: 0.11118829250335693
step: 240, loss: 0.050056032836437225
step: 250, loss: 0.01611228846013546
step: 260, loss: 0.023694759234786034
step: 270, loss: 0.01214580051600933
step: 280, loss: 0.02018178068101406
step: 290, loss: 0.014559775590896606
step: 300, loss: 0.01081127393990755
step: 310, loss: 0.0032681359443813562
step: 320, loss: 0.016839710995554924
step: 330, loss: 0.07830031216144562
step: 340, loss: 0.020867984741926193
step: 350, loss: 0.02424907311797142
step: 360, loss: 0.03729372099041939
step: 370, loss: 0.07864850014448166
step: 380, loss: 0.08576411008834839
step: 390, loss: 0.04878360033035278
step: 400, loss: 0.03147585317492485
step: 410, loss: 0.0695662871003151
step: 420, loss: 0.046544015407562256
step: 430, loss: 0.06377118825912476
step: 440, loss: 0.13312794268131256
step: 450, loss: 0.027388282120227814
step: 460, loss: 0.018609225749969482
step: 470, loss: 0.020320570096373558
step: 480, loss: 0.007460438180714846
step: 490, loss: 0.016522061079740524
step: 500, loss: 0.016235819086432457
step: 510, loss: 0.0376371368765831
step: 520, loss: 0.00012755634088534862
step: 530, loss: 0.11582882702350616
step: 540, loss: 0.1052117869257927
step: 550, loss: 0.00010025542724179104
step: 560, loss: 0.033676426857709885
step: 570, loss: 0.06481495499610901
step: 580, loss: 0.03858427703380585
step: 590, loss: 0.0320691280066967
step: 600, loss: 0.030539654195308685
step: 610, loss: 0.0001224918814841658
step: 620, loss: 0.00951251108199358
step: 630, loss: 1.8722243112279102e-05
step: 640, loss: 0.14811287820339203
step: 650, loss: 0.044197335839271545
step: 660, loss: 0.0919712707400322
step: 670, loss: 0.04666031152009964
step: 680, loss: 0.06638916581869125
step: 690, loss: 0.08551809191703796
step: 700, loss: 0.10838311910629272
step: 710, loss: 0.02419048547744751
step: 720, loss: 0.014177481643855572
step: 730, loss: 0.009593911468982697
step: 740, loss: 0.006148602347820997
step: 750, loss: 0.02574564330279827
step: 760, loss: 0.030294764786958694
step: 770, loss: 0.020202115178108215
step: 780, loss: 0.015167992562055588
step: 790, loss: 0.05271036922931671
step: 800, loss: 0.0007067784899845719
step: 810, loss: 0.000930827809497714
step: 820, loss: 0.031280264258384705
step: 830, loss: 0.03082560934126377
step: 840, loss: 0.015627093613147736
step: 850, loss: 0.01701739802956581
step: 860, loss: 0.0001384074566885829
step: 870, loss: 0.005503695458173752
step: 880, loss: 0.009953629225492477
step: 890, loss: 0.011359596624970436
step: 900, loss: 0.1587792932987213
step: 910, loss: 0.0008329867268912494
step: 920, loss: 0.0032239079009741545
step: 930, loss: 0.011537829414010048
step: 940, loss: 0.002136344788596034
step: 950, loss: 0.044360335916280746
step: 960, loss: 0.048002541065216064
step: 970, loss: 0.019674930721521378
step: 980, loss: 0.01936247944831848
step: 990, loss: 0.043629635125398636
step: 1000, loss: 0.039824701845645905
step: 1010, loss: 0.03639642521739006
step: 1020, loss: 0.014542740769684315
step: 1030, loss: 0.02490268647670746
step: 1040, loss: 0.08123251795768738
step: 1050, loss: 0.05157802253961563
step: 1060, loss: 0.03584454581141472
step: 1070, loss: 0.06561833620071411
epoch 12: dev_f1=0.9391796322489392, f1=0.9340196537201684, best_f1=0.9341372912801483
step: 0, loss: 0.04453689232468605
step: 10, loss: 0.040453702211380005
step: 20, loss: 0.042665887624025345
step: 30, loss: 0.06090163439512253
step: 40, loss: 0.04637235775589943
step: 50, loss: 0.05179889127612114
step: 60, loss: 0.031366411596536636
step: 70, loss: 0.012427585199475288
step: 80, loss: 0.007080224342644215
step: 90, loss: 0.001002939068712294
step: 100, loss: 0.04636526480317116
step: 110, loss: 0.0068123131059110165
step: 120, loss: 0.0680074691772461
step: 130, loss: 0.0698319673538208
step: 140, loss: 0.00043596592149697244
step: 150, loss: 0.003447800874710083
step: 160, loss: 0.1603088676929474
step: 170, loss: 0.00012595663429237902
step: 180, loss: 0.05365784466266632
step: 190, loss: 0.012917257845401764
step: 200, loss: 0.03629748895764351
step: 210, loss: 0.0012978396844118834
step: 220, loss: 0.04073074832558632
step: 230, loss: 0.07730651646852493
step: 240, loss: 0.014682946726679802
step: 250, loss: 0.03593631461262703
step: 260, loss: 0.002889157272875309
step: 270, loss: 0.03272132948040962
step: 280, loss: 0.005190066993236542
step: 290, loss: 0.023903198540210724
step: 300, loss: 0.05050622671842575
step: 310, loss: 0.028073720633983612
step: 320, loss: 0.00027279392816126347
step: 330, loss: 0.04740654677152634
step: 340, loss: 0.029232801869511604
step: 350, loss: 0.001110314391553402
step: 360, loss: 0.0003131308185402304
step: 370, loss: 0.011987443082034588
step: 380, loss: 0.03266909345984459
step: 390, loss: 0.0773841068148613
step: 400, loss: 0.28099507093429565
step: 410, loss: 0.059536539018154144
step: 420, loss: 0.024792829528450966
step: 430, loss: 0.039694465696811676
step: 440, loss: 0.0506877638399601
step: 450, loss: 0.011986187659204006
step: 460, loss: 0.10188797861337662
step: 470, loss: 0.05904416739940643
step: 480, loss: 0.030157485976815224
step: 490, loss: 0.0793709009885788
step: 500, loss: 0.04593760147690773
step: 510, loss: 0.06132269650697708
step: 520, loss: 0.00039082911098375916
step: 530, loss: 0.02654922381043434
step: 540, loss: 0.026486659422516823
step: 550, loss: 0.03974045440554619
step: 560, loss: 0.02331819012761116
step: 570, loss: 0.06007011979818344
step: 580, loss: 0.0003198778722435236
step: 590, loss: 0.11275614798069
step: 600, loss: 0.041745468974113464
step: 610, loss: 0.0822487622499466
step: 620, loss: 0.03141198679804802
step: 630, loss: 0.022285383194684982
step: 640, loss: 0.0006325379363261163
step: 650, loss: 0.01817132532596588
step: 660, loss: 0.03621847555041313
step: 670, loss: 0.054402854293584824
step: 680, loss: 0.1594894379377365
step: 690, loss: 0.04719608277082443
step: 700, loss: 0.010717302560806274
step: 710, loss: 0.0014261151663959026
step: 720, loss: 0.008455983363091946
step: 730, loss: 0.0550176165997982
step: 740, loss: 0.012586720287799835
step: 750, loss: 0.03396869823336601
step: 760, loss: 0.0366692952811718
step: 770, loss: 0.005201881751418114
step: 780, loss: 0.05241084471344948
step: 790, loss: 0.000846164533868432
step: 800, loss: 0.00028882661717943847
step: 810, loss: 0.03589523583650589
step: 820, loss: 0.03351125866174698
step: 830, loss: 0.0027522763703018427
step: 840, loss: 0.03332460671663284
step: 850, loss: 0.001436402089893818
step: 860, loss: 0.00869282241910696
step: 870, loss: 0.06502712517976761
step: 880, loss: 0.003173575969412923
step: 890, loss: 0.0007792518008500338
step: 900, loss: 0.055338677018880844
step: 910, loss: 0.026984810829162598
step: 920, loss: 0.02116277441382408
step: 930, loss: 0.0016352958045899868
step: 940, loss: 0.006995050236582756
step: 950, loss: 0.00016971881268545985
step: 960, loss: 0.039037786424160004
step: 970, loss: 0.027803361415863037
step: 980, loss: 0.052750036120414734
step: 990, loss: 0.03216789662837982
step: 1000, loss: 0.0021701857913285494
step: 1010, loss: 0.0009615624439902604
step: 1020, loss: 0.00031122335349209607
step: 1030, loss: 0.06043385714292526
step: 1040, loss: 0.006678879726678133
step: 1050, loss: 0.00039520833524875343
step: 1060, loss: 0.036581672728061676
step: 1070, loss: 0.00493251159787178
epoch 13: dev_f1=0.9397363465160076, f1=0.9283372365339578, best_f1=0.9341372912801483
step: 0, loss: 0.004956830758601427
step: 10, loss: 0.0012549343518912792
step: 20, loss: 0.10036567598581314
step: 30, loss: 0.03536994382739067
step: 40, loss: 0.0006141850026324391
step: 50, loss: 0.09117494523525238
step: 60, loss: 0.0005410854355432093
step: 70, loss: 0.03458579629659653
step: 80, loss: 0.03040945902466774
step: 90, loss: 0.05739317089319229
step: 100, loss: 0.006650416646152735
step: 110, loss: 0.027243904769420624
step: 120, loss: 0.04454319179058075
step: 130, loss: 0.04806487262248993
step: 140, loss: 0.005425682291388512
step: 150, loss: 0.09230800718069077
step: 160, loss: 0.018856924027204514
step: 170, loss: 0.00135965330991894
step: 180, loss: 0.00011577914119698107
step: 190, loss: 0.034776072949171066
step: 200, loss: 0.036048147827386856
step: 210, loss: 0.044125963002443314
step: 220, loss: 0.06075289100408554
step: 230, loss: 0.011496491730213165
step: 240, loss: 0.0035912347957491875
step: 250, loss: 0.036123309284448624
step: 260, loss: 0.018611524254083633
step: 270, loss: 0.02422541379928589
step: 280, loss: 0.0411091074347496
step: 290, loss: 0.001527881482616067
step: 300, loss: 0.037707969546318054
step: 310, loss: 0.05454055964946747
step: 320, loss: 0.006018516607582569
step: 330, loss: 0.0038566570729017258
step: 340, loss: 0.03192830830812454
step: 350, loss: 0.02313697151839733
step: 360, loss: 0.0004787757352460176
step: 370, loss: 0.01774759404361248
step: 380, loss: 0.09101957082748413
step: 390, loss: 0.039772771298885345
step: 400, loss: 0.03269191458821297
step: 410, loss: 0.027237536385655403
step: 420, loss: 0.01519081648439169
step: 430, loss: 0.02006026729941368
step: 440, loss: 0.04447714984416962
step: 450, loss: 0.05198316648602486
step: 460, loss: 0.07134396582841873
step: 470, loss: 0.08147318661212921
step: 480, loss: 0.029322059825062752
step: 490, loss: 0.039910122752189636
step: 500, loss: 0.07696926593780518
step: 510, loss: 0.12504921853542328
step: 520, loss: 0.043739136308431625
step: 530, loss: 0.03579666092991829
step: 540, loss: 0.07412775605916977
step: 550, loss: 4.347864160081372e-05
step: 560, loss: 0.06014244630932808
step: 570, loss: 0.011935384012758732
step: 580, loss: 0.01278254110366106
step: 590, loss: 0.0541437566280365
step: 600, loss: 0.08361496776342392
step: 610, loss: 0.05869916081428528
step: 620, loss: 0.0005889079184271395
step: 630, loss: 0.1378631293773651
step: 640, loss: 0.04325122758746147
step: 650, loss: 0.015476778149604797
step: 660, loss: 0.0007807567599229515
step: 670, loss: 0.0003183019580319524
step: 680, loss: 0.00011790564894909039
step: 690, loss: 0.041273634880781174
step: 700, loss: 2.44814800680615e-05
step: 710, loss: 0.046426769345998764
step: 720, loss: 0.044737111777067184
step: 730, loss: 0.0009318234515376389
step: 740, loss: 0.014208455570042133
step: 750, loss: 0.06159579008817673
step: 760, loss: 0.06263554841279984
step: 770, loss: 0.033314406871795654
step: 780, loss: 0.06846126168966293
step: 790, loss: 0.030072718858718872
step: 800, loss: 0.10907454788684845
step: 810, loss: 0.05681117624044418
step: 820, loss: 0.08330908417701721
step: 830, loss: 0.00014765583910048008
step: 840, loss: 0.03265318647027016
step: 850, loss: 0.07562057673931122
step: 860, loss: 0.015339490957558155
step: 870, loss: 0.043855685740709305
step: 880, loss: 0.022238600999116898
step: 890, loss: 0.02771720662713051
step: 900, loss: 0.11695125699043274
step: 910, loss: 0.00126547587569803
step: 920, loss: 0.017637915909290314
step: 930, loss: 0.0888100191950798
step: 940, loss: 0.0061524915508925915
step: 950, loss: 0.012713667005300522
step: 960, loss: 0.005630835425108671
step: 970, loss: 0.011152662336826324
step: 980, loss: 0.02706274203956127
step: 990, loss: 0.03273477032780647
step: 1000, loss: 0.05909125506877899
step: 1010, loss: 0.10309766232967377
step: 1020, loss: 0.04310033842921257
step: 1030, loss: 0.08414026349782944
step: 1040, loss: 0.01980658434331417
step: 1050, loss: 0.009622863493859768
step: 1060, loss: 0.021931719034910202
step: 1070, loss: 0.008730345405638218
epoch 14: dev_f1=0.9317865429234339, f1=0.9281767955801105, best_f1=0.9341372912801483
step: 0, loss: 0.05424286052584648
step: 10, loss: 0.09103568643331528
step: 20, loss: 0.08872063457965851
step: 30, loss: 0.001251728506758809
step: 40, loss: 0.04396941512823105
step: 50, loss: 0.041501641273498535
step: 60, loss: 0.0006156305898912251
step: 70, loss: 0.028157778084278107
step: 80, loss: 0.022948378697037697
step: 90, loss: 0.050631918013095856
step: 100, loss: 0.00018900724535342306
step: 110, loss: 0.005831616465002298
step: 120, loss: 0.034263234585523605
step: 130, loss: 0.00011205944610992447
step: 140, loss: 0.03961033746600151
step: 150, loss: 0.037270303815603256
step: 160, loss: 0.01691557466983795
step: 170, loss: 0.02757614105939865
step: 180, loss: 0.00582353537902236
step: 190, loss: 0.00010346942872274667
step: 200, loss: 0.0034940270707011223
step: 210, loss: 0.0004161850083619356
step: 220, loss: 0.06896042823791504
step: 230, loss: 0.05536273494362831
step: 240, loss: 0.023835226893424988
step: 250, loss: 0.015492528676986694
step: 260, loss: 3.668795034172945e-05
step: 270, loss: 0.019944338127970695
step: 280, loss: 0.04193933680653572
step: 290, loss: 0.010092262178659439
step: 300, loss: 0.0024240310303866863
step: 310, loss: 0.03384079784154892
step: 320, loss: 0.01701325736939907
step: 330, loss: 0.012089354917407036
step: 340, loss: 0.023679617792367935
step: 350, loss: 0.020262200385332108
step: 360, loss: 0.02604632079601288
step: 370, loss: 0.06169403716921806
step: 380, loss: 0.01891247369349003
step: 390, loss: 0.003118201857432723
step: 400, loss: 0.0004592348705045879
step: 410, loss: 0.06373722851276398
step: 420, loss: 0.021783271804451942
step: 430, loss: 0.012221520766615868
step: 440, loss: 0.01653570681810379
step: 450, loss: 0.01741991937160492
step: 460, loss: 0.012485286220908165
step: 470, loss: 0.017157845199108124
step: 480, loss: 0.008306157775223255
step: 490, loss: 0.02584056183695793
step: 500, loss: 0.030576465651392937
step: 510, loss: 0.03565933182835579
step: 520, loss: 0.014536445960402489
step: 530, loss: 0.0003853139642160386
step: 540, loss: 0.001861770055256784
step: 550, loss: 0.006393048446625471
step: 560, loss: 0.18328478932380676
step: 570, loss: 0.05623089522123337
step: 580, loss: 0.017660601064562798
step: 590, loss: 0.09272412210702896
step: 600, loss: 5.443885311251506e-05
step: 610, loss: 0.08391197770833969
step: 620, loss: 0.0035060555674135685
step: 630, loss: 0.050136204808950424
step: 640, loss: 0.03588363155722618
step: 650, loss: 0.06263483315706253
step: 660, loss: 8.180169970728457e-05
step: 670, loss: 0.024353792890906334
step: 680, loss: 0.10560201108455658
step: 690, loss: 0.015425010584294796
step: 700, loss: 0.041975196450948715
step: 710, loss: 0.00047355974675156176
step: 720, loss: 9.566658263793215e-05
step: 730, loss: 0.002026525093242526
step: 740, loss: 1.9522782167769037e-05
step: 750, loss: 0.038215674459934235
step: 760, loss: 4.949733556713909e-05
step: 770, loss: 0.0324997678399086
step: 780, loss: 0.00015332984912674874
step: 790, loss: 0.029045455157756805
step: 800, loss: 0.026337401941418648
step: 810, loss: 0.023517562076449394
step: 820, loss: 0.009029923938214779
step: 830, loss: 0.01869112439453602
step: 840, loss: 0.0334332250058651
step: 850, loss: 0.01601632498204708
step: 860, loss: 0.00858907401561737
step: 870, loss: 0.0006055906997062266
step: 880, loss: 0.026595711708068848
step: 890, loss: 0.00015282470849342644
step: 900, loss: 0.03692565858364105
step: 910, loss: 0.004380113910883665
step: 920, loss: 0.002264708513393998
step: 930, loss: 0.0011450119782239199
step: 940, loss: 0.04752207547426224
step: 950, loss: 0.03005240298807621
step: 960, loss: 0.0550294928252697
step: 970, loss: 0.03072027862071991
step: 980, loss: 0.03998101130127907
step: 990, loss: 0.03232474997639656
step: 1000, loss: 0.03839874640107155
step: 1010, loss: 0.02306627668440342
step: 1020, loss: 0.07562148571014404
step: 1030, loss: 1.6554444300709292e-05
step: 1040, loss: 0.008265557698905468
step: 1050, loss: 0.06277992576360703
step: 1060, loss: 0.02459169737994671
step: 1070, loss: 0.04949665814638138
epoch 15: dev_f1=0.9346497414198403, f1=0.9318394024276377, best_f1=0.9341372912801483
step: 0, loss: 0.03480225428938866
step: 10, loss: 0.023425331339240074
step: 20, loss: 0.08220461010932922
step: 30, loss: 0.013472199440002441
step: 40, loss: 0.04270819202065468
step: 50, loss: 0.0026067420840263367
step: 60, loss: 0.00015244432142935693
step: 70, loss: 0.039638083428144455
step: 80, loss: 0.007450142875313759
step: 90, loss: 0.020358948037028313
step: 100, loss: 1.924438947753515e-05
step: 110, loss: 0.05109173431992531
step: 120, loss: 0.06150364875793457
step: 130, loss: 0.01671646721661091
step: 140, loss: 0.04669181630015373
step: 150, loss: 0.013669992797076702
step: 160, loss: 0.05073070898652077
step: 170, loss: 0.01583884283900261
step: 180, loss: 0.0015322555555030704
step: 190, loss: 0.024254323914647102
step: 200, loss: 0.039193425327539444
step: 210, loss: 4.29975516453851e-05
step: 220, loss: 0.03691083565354347
step: 230, loss: 0.020980913192033768
step: 240, loss: 0.025450177490711212
step: 250, loss: 0.03362268581986427
step: 260, loss: 0.05741685628890991
step: 270, loss: 2.8295344236539677e-05
step: 280, loss: 6.29127025604248e-05
step: 290, loss: 0.05244695022702217
step: 300, loss: 0.011164779774844646
step: 310, loss: 6.449873035307974e-05
step: 320, loss: 0.0009733024635352194
step: 330, loss: 0.0017018528888002038
step: 340, loss: 0.007912339642643929
step: 350, loss: 0.016804775223135948
step: 360, loss: 0.03644602373242378
step: 370, loss: 1.3217079867899884e-05
step: 380, loss: 0.02053717151284218
step: 390, loss: 0.049884870648384094
step: 400, loss: 0.035071052610874176
step: 410, loss: 0.022696761414408684
step: 420, loss: 0.033781103789806366
step: 430, loss: 0.01582481898367405
step: 440, loss: 0.003089272417128086
step: 450, loss: 0.021390797570347786
step: 460, loss: 0.030145034193992615
step: 470, loss: 0.05947066843509674
step: 480, loss: 0.00015725793491583318
step: 490, loss: 0.010507349856197834
step: 500, loss: 0.06212804466485977
step: 510, loss: 0.00014752583228982985
step: 520, loss: 0.01576613448560238
step: 530, loss: 0.025849467143416405
step: 540, loss: 6.132620910648257e-05
step: 550, loss: 0.015200546942651272
step: 560, loss: 0.06355931609869003
step: 570, loss: 0.017241910099983215
step: 580, loss: 0.008864891715347767
step: 590, loss: 0.0001375094725517556
step: 600, loss: 1.3261776985018514e-05
step: 610, loss: 0.01685933768749237
step: 620, loss: 0.028353936970233917
step: 630, loss: 0.017195818945765495
step: 640, loss: 0.01679318957030773
step: 650, loss: 0.06526003032922745
step: 660, loss: 0.0005743603105656803
step: 670, loss: 0.024682655930519104
step: 680, loss: 0.0366201214492321
step: 690, loss: 0.04342243820428848
step: 700, loss: 0.0034098697360605
step: 710, loss: 0.025484764948487282
step: 720, loss: 0.037459950894117355
step: 730, loss: 0.08567214012145996
step: 740, loss: 0.022704586386680603
step: 750, loss: 0.004733696114271879
step: 760, loss: 0.03500838577747345
step: 770, loss: 0.08730142563581467
step: 780, loss: 0.04583822935819626
step: 790, loss: 0.0007655899389646947
step: 800, loss: 0.2392130345106125
step: 810, loss: 0.00043538142926990986
step: 820, loss: 0.004123620223253965
step: 830, loss: 0.018519669771194458
step: 840, loss: 0.048500146716833115
step: 850, loss: 0.05359986796975136
step: 860, loss: 0.029794326052069664
step: 870, loss: 0.02143891341984272
step: 880, loss: 0.046477608382701874
step: 890, loss: 0.01812857948243618
step: 900, loss: 0.0009182250360026956
step: 910, loss: 0.02462136745452881
step: 920, loss: 0.0196081455796957
step: 930, loss: 8.758099284023046e-06
step: 940, loss: 0.056032244116067886
step: 950, loss: 8.611808880232275e-05
step: 960, loss: 3.537736483849585e-05
step: 970, loss: 0.10888239741325378
step: 980, loss: 0.07664105296134949
step: 990, loss: 0.04359341040253639
step: 1000, loss: 0.09572268277406693
step: 1010, loss: 0.00022413434635382146
step: 1020, loss: 0.013840917497873306
step: 1030, loss: 0.002685527317225933
step: 1040, loss: 0.020549075677990913
step: 1050, loss: 0.02627330832183361
step: 1060, loss: 0.06622999906539917
step: 1070, loss: 0.031825777143239975
epoch 16: dev_f1=0.9327146171693736, f1=0.9278445883441258, best_f1=0.9341372912801483
step: 0, loss: 0.047090087085962296
step: 10, loss: 0.0038690557703375816
step: 20, loss: 0.027408743277192116
step: 30, loss: 0.014791418798267841
step: 40, loss: 0.0001202939311042428
step: 50, loss: 0.014473127201199532
step: 60, loss: 0.02087348885834217
step: 70, loss: 9.599571058060974e-05
step: 80, loss: 0.017662858590483665
step: 90, loss: 0.04077163338661194
step: 100, loss: 0.03390016034245491
step: 110, loss: 0.0005519064143300056
step: 120, loss: 0.0028035591822117567
step: 130, loss: 0.010660313069820404
step: 140, loss: 0.020936068147420883
step: 150, loss: 0.015268197283148766
step: 160, loss: 0.013330349698662758
step: 170, loss: 0.018773090094327927
step: 180, loss: 0.03502592816948891
step: 190, loss: 0.031184552237391472
step: 200, loss: 0.0048836166970431805
step: 210, loss: 1.9072371287620626e-05
step: 220, loss: 4.1858264012262225e-05
step: 230, loss: 0.0394364669919014
step: 240, loss: 0.0031925279181450605
step: 250, loss: 0.0723729357123375
step: 260, loss: 0.015526073053479195
step: 270, loss: 0.020582951605319977
step: 280, loss: 0.017617182806134224
step: 290, loss: 2.3884465917944908e-05
step: 300, loss: 0.06121499463915825
step: 310, loss: 0.09167033433914185
step: 320, loss: 0.060162756592035294
step: 330, loss: 0.04676413908600807
step: 340, loss: 0.004067974165081978
step: 350, loss: 0.023421095684170723
step: 360, loss: 0.037505198270082474
step: 370, loss: 0.05223705247044563
step: 380, loss: 0.05759015679359436
step: 390, loss: 0.06158410385251045
step: 400, loss: 9.075145499082282e-05
step: 410, loss: 0.034602049738168716
step: 420, loss: 0.02435540035367012
step: 430, loss: 0.04676178842782974
step: 440, loss: 0.024042414501309395
step: 450, loss: 0.05056113004684448
step: 460, loss: 0.03264959901571274
step: 470, loss: 0.09587747603654861
step: 480, loss: 0.00022514956071972847
step: 490, loss: 0.06024114042520523
step: 500, loss: 0.003601147560402751
step: 510, loss: 0.0334918238222599
step: 520, loss: 0.02497771568596363
step: 530, loss: 0.05007500573992729
step: 540, loss: 0.0007599469972774386
step: 550, loss: 0.056114666163921356
step: 560, loss: 0.00021944627224002033
step: 570, loss: 0.020571419969201088
step: 580, loss: 0.01638980023562908
step: 590, loss: 0.03883778303861618
step: 600, loss: 0.018918193876743317
step: 610, loss: 0.022854849696159363
step: 620, loss: 0.0016948452685028315
step: 630, loss: 0.02507719025015831
step: 640, loss: 0.042705241590738297
step: 650, loss: 0.06046140938997269
step: 660, loss: 0.05046309158205986
step: 670, loss: 0.025955429300665855
step: 680, loss: 0.03476375341415405
step: 690, loss: 0.03864951431751251
step: 700, loss: 2.7949141440331005e-05
step: 710, loss: 0.024503929540514946
step: 720, loss: 0.05572839453816414
step: 730, loss: 1.4245079000829719e-05
step: 740, loss: 0.00010114013275597245
step: 750, loss: 0.059064608067274094
step: 760, loss: 0.054943062365055084
step: 770, loss: 1.3566833331424277e-05
step: 780, loss: 0.02199432998895645
step: 790, loss: 2.7371495889383368e-05
step: 800, loss: 0.08911765366792679
step: 810, loss: 0.018874946981668472
step: 820, loss: 0.025793015956878662
step: 830, loss: 4.834241190110333e-05
step: 840, loss: 0.005400391295552254
step: 850, loss: 0.020813841372728348
step: 860, loss: 0.009529638104140759
step: 870, loss: 0.06385744363069534
step: 880, loss: 0.06681398302316666
step: 890, loss: 0.0176031943410635
step: 900, loss: 0.022326838225126266
step: 910, loss: 0.0026978706009685993
step: 920, loss: 0.006415091920644045
step: 930, loss: 0.02706243097782135
step: 940, loss: 0.025494934991002083
step: 950, loss: 0.032354678958654404
step: 960, loss: 2.1445159291033633e-05
step: 970, loss: 0.06099038943648338
step: 980, loss: 0.0008075438090600073
step: 990, loss: 0.017063908278942108
step: 1000, loss: 0.019708678126335144
step: 1010, loss: 0.064152792096138
step: 1020, loss: 0.015245922841131687
step: 1030, loss: 0.0007445503724738955
step: 1040, loss: 0.03882204368710518
step: 1050, loss: 0.01773870922625065
step: 1060, loss: 0.002090752124786377
step: 1070, loss: 0.049766991287469864
epoch 17: dev_f1=0.9373831775700935, f1=0.932093023255814, best_f1=0.9341372912801483
step: 0, loss: 0.02279171720147133
step: 10, loss: 0.0521974042057991
step: 20, loss: 0.04019507020711899
step: 30, loss: 0.07643651962280273
step: 40, loss: 0.05233633145689964
step: 50, loss: 4.146961509832181e-05
step: 60, loss: 0.06382708251476288
step: 70, loss: 2.1031817595940083e-05
step: 80, loss: 5.978944318485446e-05
step: 90, loss: 0.04020780324935913
step: 100, loss: 0.00011548584734555334
step: 110, loss: 0.023230239748954773
step: 120, loss: 0.04957864060997963
step: 130, loss: 0.00017291971016675234
step: 140, loss: 0.05920499563217163
step: 150, loss: 0.025518886744976044
step: 160, loss: 0.06158118322491646
step: 170, loss: 2.2376812921720557e-05
step: 180, loss: 0.03136490657925606
step: 190, loss: 0.022043662145733833
step: 200, loss: 0.024004386737942696
step: 210, loss: 2.4578128432040103e-05
step: 220, loss: 0.08127452433109283
step: 230, loss: 0.0018028017366304994
step: 240, loss: 5.607010825769976e-05
step: 250, loss: 0.06973409652709961
step: 260, loss: 0.04955470934510231
step: 270, loss: 0.003549717366695404
step: 280, loss: 0.0007649651379324496
step: 290, loss: 0.039604030549526215
step: 300, loss: 0.050006188452243805
step: 310, loss: 0.03897341340780258
step: 320, loss: 0.012263916432857513
step: 330, loss: 0.02142924815416336
step: 340, loss: 0.03253813832998276
step: 350, loss: 0.0740170031785965
step: 360, loss: 0.04994795098900795
step: 370, loss: 0.00837030727416277
step: 380, loss: 4.3370291678002104e-05
step: 390, loss: 1.0799490155477542e-05
step: 400, loss: 0.0003684053081087768
step: 410, loss: 0.0001339838927378878
step: 420, loss: 0.032463438808918
step: 430, loss: 0.043630197644233704
step: 440, loss: 0.057236768305301666
step: 450, loss: 0.02244161069393158
step: 460, loss: 0.05582130700349808
step: 470, loss: 8.813962267595343e-06
step: 480, loss: 2.4287566702696495e-05
step: 490, loss: 0.025338271632790565
step: 500, loss: 0.00011288936366327107
step: 510, loss: 0.06756633520126343
step: 520, loss: 0.024905001744627953
step: 530, loss: 0.043440982699394226
step: 540, loss: 7.000568439252675e-05
step: 550, loss: 0.053551796823740005
step: 560, loss: 0.016976214945316315
step: 570, loss: 0.02683407999575138
step: 580, loss: 0.026018189266324043
step: 590, loss: 0.08153209090232849
step: 600, loss: 0.02661799266934395
step: 610, loss: 0.0001437206956325099
step: 620, loss: 1.8026084944722243e-05
step: 630, loss: 0.03404887393116951
step: 640, loss: 0.037425026297569275
step: 650, loss: 0.022463394328951836
step: 660, loss: 0.019072694703936577
step: 670, loss: 0.0067069074138998985
step: 680, loss: 4.505354809225537e-05
step: 690, loss: 0.02358921989798546
step: 700, loss: 1.1782633919210639e-05
step: 710, loss: 1.832740417739842e-05
step: 720, loss: 0.030812328681349754
step: 730, loss: 0.027472762390971184
step: 740, loss: 0.023033684119582176
step: 750, loss: 0.09339280426502228
step: 760, loss: 0.02265928126871586
step: 770, loss: 0.019924674183130264
step: 780, loss: 0.08380114287137985
step: 790, loss: 0.04453166946768761
step: 800, loss: 0.024699512869119644
step: 810, loss: 0.022199969738721848
step: 820, loss: 0.055958863347768784
step: 830, loss: 0.02106311544775963
step: 840, loss: 0.019968397915363312
step: 850, loss: 0.03321943059563637
step: 860, loss: 9.179280459647998e-05
step: 870, loss: 0.0007843875209800899
step: 880, loss: 0.00021645180822815746
step: 890, loss: 0.007985101081430912
step: 900, loss: 0.025238171219825745
step: 910, loss: 1.5261828593793325e-05
step: 920, loss: 3.0349407097673975e-05
step: 930, loss: 0.09081080555915833
step: 940, loss: 0.09371580928564072
step: 950, loss: 0.019532736390829086
step: 960, loss: 0.007938805036246777
step: 970, loss: 0.01643175445497036
step: 980, loss: 0.07005128264427185
step: 990, loss: 0.014425072818994522
step: 1000, loss: 1.4263404409575742e-05
step: 1010, loss: 7.309002830879763e-05
step: 1020, loss: 0.029246514663100243
step: 1030, loss: 6.260005466174334e-05
step: 1040, loss: 0.00043471064418554306
step: 1050, loss: 0.017707115039229393
step: 1060, loss: 0.0562606081366539
step: 1070, loss: 0.03007957711815834
epoch 18: dev_f1=0.9359698681732581, f1=0.9267382174521699, best_f1=0.9341372912801483
step: 0, loss: 0.022441498935222626
step: 10, loss: 0.07453396916389465
step: 20, loss: 0.051765888929367065
step: 30, loss: 0.027774065732955933
step: 40, loss: 0.016455816105008125
step: 50, loss: 0.0775822177529335
step: 60, loss: 0.049102988094091415
step: 70, loss: 0.02618350088596344
step: 80, loss: 0.07961935549974442
step: 90, loss: 0.036192040890455246
step: 100, loss: 0.08991803228855133
step: 110, loss: 0.021009201183915138
step: 120, loss: 2.9762732083327137e-05
step: 130, loss: 0.013696127571165562
step: 140, loss: 0.06465012580156326
step: 150, loss: 0.021759994328022003
step: 160, loss: 2.6138615794479847e-05
step: 170, loss: 0.00026411021826788783
step: 180, loss: 0.02188701555132866
step: 190, loss: 0.007568635046482086
step: 200, loss: 0.0008125155000016093
step: 210, loss: 0.018778301775455475
step: 220, loss: 0.030087854713201523
step: 230, loss: 2.8254726203158498e-05
step: 240, loss: 2.349683018110227e-05
step: 250, loss: 0.03958360478281975
step: 260, loss: 5.862028046976775e-05
step: 270, loss: 0.10018857568502426
step: 280, loss: 0.017674366012215614
step: 290, loss: 4.4406086090020835e-05
step: 300, loss: 2.0915009372401983e-05
step: 310, loss: 0.00010866252705454826
step: 320, loss: 0.05727299302816391
step: 330, loss: 0.02787829376757145
step: 340, loss: 0.10582175850868225
step: 350, loss: 4.002997593488544e-05
step: 360, loss: 0.0950549989938736
step: 370, loss: 0.0001297973794862628
step: 380, loss: 0.046448543667793274
step: 390, loss: 0.04202459380030632
step: 400, loss: 8.054575300775468e-05
step: 410, loss: 0.020165488123893738
step: 420, loss: 0.05617423728108406
step: 430, loss: 4.031516073155217e-05
step: 440, loss: 0.02709030546247959
step: 450, loss: 0.05312373861670494
step: 460, loss: 0.026538601145148277
step: 470, loss: 0.026243137195706367
step: 480, loss: 0.00019934450392611325
step: 490, loss: 0.02845144458115101
step: 500, loss: 0.06296755373477936
step: 510, loss: 0.046937860548496246
step: 520, loss: 0.038896337151527405
step: 530, loss: 0.061452433466911316
step: 540, loss: 0.0526181235909462
step: 550, loss: 0.0481959693133831
step: 560, loss: 0.02381928265094757
step: 570, loss: 0.022269513458013535
step: 580, loss: 0.00010617497173370793
step: 590, loss: 0.013660858385264874
step: 600, loss: 0.0357101634144783
step: 610, loss: 0.026371410116553307
step: 620, loss: 0.00021255906904116273
step: 630, loss: 0.01640927419066429
step: 640, loss: 0.020160548388957977
step: 650, loss: 0.018643155694007874
step: 660, loss: 1.7739128452376463e-05
step: 670, loss: 0.07370749861001968
step: 680, loss: 0.008056039921939373
step: 690, loss: 0.038616713136434555
step: 700, loss: 0.05048656836152077
step: 710, loss: 0.02072601020336151
step: 720, loss: 0.0422532893717289
step: 730, loss: 0.00030832618358545005
step: 740, loss: 0.0006769626634195447
step: 750, loss: 3.078239751630463e-05
step: 760, loss: 0.01181357353925705
step: 770, loss: 0.021858640015125275
step: 780, loss: 5.050840263720602e-05
step: 790, loss: 0.04731538146734238
step: 800, loss: 0.024518242105841637
step: 810, loss: 0.054228562861680984
step: 820, loss: 4.099387660971843e-05
step: 830, loss: 6.088492227718234e-05
step: 840, loss: 0.08051031827926636
step: 850, loss: 0.0445781946182251
step: 860, loss: 2.740826857916545e-05
step: 870, loss: 0.03186905384063721
step: 880, loss: 0.01701698824763298
step: 890, loss: 0.03239496052265167
step: 900, loss: 0.018545344471931458
step: 910, loss: 0.009640778414905071
step: 920, loss: 0.002807511016726494
step: 930, loss: 0.04348432272672653
step: 940, loss: 0.000679573102388531
step: 950, loss: 0.07726022601127625
step: 960, loss: 0.0667002946138382
step: 970, loss: 0.06921172887086868
step: 980, loss: 0.025082815438508987
step: 990, loss: 0.024594221264123917
step: 1000, loss: 0.06324522942304611
step: 1010, loss: 0.02194877900183201
step: 1020, loss: 0.0031119852792471647
step: 1030, loss: 0.00023746307124383748
step: 1040, loss: 0.023887109011411667
step: 1050, loss: 1.5220218301692512e-05
step: 1060, loss: 1.502749728388153e-05
step: 1070, loss: 0.021751614287495613
epoch 19: dev_f1=0.9342789598108747, f1=0.9291412482402628, best_f1=0.9341372912801483
step: 0, loss: 1.1276224540779367e-05
step: 10, loss: 2.4833690986270085e-05
step: 20, loss: 0.10554389655590057
step: 30, loss: 0.04829825833439827
step: 40, loss: 0.0020018485374748707
step: 50, loss: 0.020222892984747887
step: 60, loss: 0.04849587753415108
step: 70, loss: 6.0209491493878886e-05
step: 80, loss: 0.019411200657486916
step: 90, loss: 0.00014062035188544542
step: 100, loss: 0.10792431235313416
step: 110, loss: 0.019074957817792892
step: 120, loss: 0.01859389804303646
step: 130, loss: 0.04533596336841583
step: 140, loss: 2.48496526182862e-05
step: 150, loss: 0.043715059757232666
step: 160, loss: 0.044901520013809204
step: 170, loss: 0.00011517375241965055
step: 180, loss: 0.04573850333690643
step: 190, loss: 0.004424910992383957
step: 200, loss: 0.027134008705615997
step: 210, loss: 0.011946800164878368
step: 220, loss: 0.004963314160704613
step: 230, loss: 0.01799137145280838
step: 240, loss: 0.01411143783479929
step: 250, loss: 0.04268265888094902
step: 260, loss: 0.022171298041939735
step: 270, loss: 0.050141312181949615
step: 280, loss: 2.0156841856078245e-05
step: 290, loss: 0.018775690346956253
step: 300, loss: 0.00010921745706582442
step: 310, loss: 0.04744439572095871
step: 320, loss: 0.047302357852458954
step: 330, loss: 0.0004622058477252722
step: 340, loss: 0.001552340341731906
step: 350, loss: 3.143872527289204e-05
step: 360, loss: 0.07482662051916122
step: 370, loss: 0.00024186508380807936
step: 380, loss: 0.01960371807217598
step: 390, loss: 0.060529161244630814
step: 400, loss: 0.00022662286937702447
step: 410, loss: 2.6437015549163334e-05
step: 420, loss: 0.05626540631055832
step: 430, loss: 0.021234942600131035
step: 440, loss: 1.4062404261494521e-05
step: 450, loss: 0.020683925598859787
step: 460, loss: 0.006588040851056576
step: 470, loss: 8.936900485423394e-06
step: 480, loss: 0.007230987772345543
step: 490, loss: 0.025381367653608322
step: 500, loss: 0.05948774516582489
step: 510, loss: 7.282873866643058e-06
step: 520, loss: 0.047742512077093124
step: 530, loss: 9.879304343485273e-06
step: 540, loss: 0.021604744717478752
step: 550, loss: 0.035204097628593445
step: 560, loss: 0.017089035362005234
step: 570, loss: 0.025204112753272057
step: 580, loss: 0.040027424693107605
step: 590, loss: 0.05243290215730667
step: 600, loss: 0.022037304937839508
step: 610, loss: 0.00015814001380931586
step: 620, loss: 0.025969378650188446
step: 630, loss: 3.236201882828027e-05
step: 640, loss: 0.020981265231966972
step: 650, loss: 0.019004058092832565
step: 660, loss: 0.0009283337276428938
step: 670, loss: 0.018463026732206345
step: 680, loss: 0.0229705348610878
step: 690, loss: 0.0923708900809288
step: 700, loss: 0.052504055202007294
step: 710, loss: 0.028042152523994446
step: 720, loss: 1.0464174010849092e-05
step: 730, loss: 0.022589663043618202
step: 740, loss: 0.07227244228124619
step: 750, loss: 0.09717413783073425
step: 760, loss: 3.104226925643161e-05
step: 770, loss: 0.08935286849737167
step: 780, loss: 0.021054331213235855
step: 790, loss: 0.028525251895189285
step: 800, loss: 0.025267072021961212
step: 810, loss: 8.430275556747802e-06
step: 820, loss: 4.169292515143752e-05
step: 830, loss: 0.012173297815024853
step: 840, loss: 0.00012877378321718425
step: 850, loss: 0.002859153551980853
step: 860, loss: 0.02090304344892502
step: 870, loss: 0.019451353698968887
step: 880, loss: 0.0728394016623497
step: 890, loss: 1.977641659323126e-05
step: 900, loss: 0.020090635865926743
step: 910, loss: 0.06347476691007614
step: 920, loss: 0.016695531085133553
step: 930, loss: 0.06464994698762894
step: 940, loss: 0.02156697027385235
step: 950, loss: 7.172786718001589e-05
step: 960, loss: 0.06493037194013596
step: 970, loss: 0.003774370299652219
step: 980, loss: 0.019729532301425934
step: 990, loss: 0.0001183947388199158
step: 1000, loss: 0.001172629650682211
step: 1010, loss: 0.010695808567106724
step: 1020, loss: 0.06920207291841507
step: 1030, loss: 0.10393480211496353
step: 1040, loss: 0.05210427939891815
step: 1050, loss: 9.897978998196777e-06
step: 1060, loss: 1.5087115571077447e-05
step: 1070, loss: 0.018934179097414017
epoch 20: dev_f1=0.9328323156411461, f1=0.9290023201856149, best_f1=0.9341372912801483
