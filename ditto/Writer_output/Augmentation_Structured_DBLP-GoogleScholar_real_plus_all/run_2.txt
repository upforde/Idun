cuda
Device: cuda
step: 0, loss: 0.6431025862693787
step: 10, loss: 0.5470074415206909
step: 20, loss: 0.35538360476493835
step: 30, loss: 0.4375160336494446
step: 40, loss: 0.32559144496917725
step: 50, loss: 0.21790193021297455
step: 60, loss: 0.07702572643756866
step: 70, loss: 0.2117961198091507
step: 80, loss: 0.2610016167163849
step: 90, loss: 0.22431689500808716
step: 100, loss: 0.18932515382766724
step: 110, loss: 0.09090825915336609
step: 120, loss: 0.2828935384750366
step: 130, loss: 0.05876399949193001
step: 140, loss: 0.1140432134270668
step: 150, loss: 0.16125549376010895
step: 160, loss: 0.21425579488277435
step: 170, loss: 0.1320492923259735
step: 180, loss: 0.1886938512325287
step: 190, loss: 0.18575790524482727
step: 200, loss: 0.1455095112323761
step: 210, loss: 0.15356895327568054
step: 220, loss: 0.11571261286735535
step: 230, loss: 0.2966596186161041
step: 240, loss: 0.17163097858428955
step: 250, loss: 0.06664121896028519
step: 260, loss: 0.09260191768407822
step: 270, loss: 0.14769911766052246
step: 280, loss: 0.07759251445531845
step: 290, loss: 0.09791150689125061
step: 300, loss: 0.12006504833698273
step: 310, loss: 0.11789862811565399
step: 320, loss: 0.11492154747247696
step: 330, loss: 0.16223931312561035
step: 340, loss: 0.07240919768810272
step: 350, loss: 0.190359964966774
step: 360, loss: 0.14492915570735931
step: 370, loss: 0.21697033941745758
step: 380, loss: 0.08472121506929398
step: 390, loss: 0.42402225732803345
step: 400, loss: 0.024363312870264053
step: 410, loss: 0.12730731070041656
step: 420, loss: 0.1711592972278595
step: 430, loss: 0.18956099450588226
step: 440, loss: 0.19066207110881805
step: 450, loss: 0.06076015159487724
step: 460, loss: 0.3006916046142578
step: 470, loss: 0.11319278180599213
step: 480, loss: 0.15452790260314941
step: 490, loss: 0.21801896393299103
step: 500, loss: 0.10903134196996689
step: 510, loss: 0.07948974519968033
step: 520, loss: 0.09804049879312515
step: 530, loss: 0.06335578113794327
step: 540, loss: 0.10916192829608917
step: 550, loss: 0.44165298342704773
step: 560, loss: 0.1069670170545578
step: 570, loss: 0.13043151795864105
step: 580, loss: 0.1335950791835785
step: 590, loss: 0.10709954053163528
step: 600, loss: 0.11061722040176392
step: 610, loss: 0.1419104039669037
step: 620, loss: 0.0907081738114357
step: 630, loss: 0.13223986327648163
step: 640, loss: 0.08667503297328949
step: 650, loss: 0.1379716992378235
step: 660, loss: 0.1365593671798706
step: 670, loss: 0.12625040113925934
step: 680, loss: 0.26741525530815125
step: 690, loss: 0.026618488132953644
step: 700, loss: 0.07851608842611313
step: 710, loss: 0.04588039219379425
step: 720, loss: 0.06048059090971947
step: 730, loss: 0.1391400694847107
step: 740, loss: 0.09471749514341354
step: 750, loss: 0.3204275071620941
step: 760, loss: 0.20636558532714844
step: 770, loss: 0.04879682883620262
step: 780, loss: 0.017536615952849388
step: 790, loss: 0.12387167662382126
step: 800, loss: 0.043831441551446915
step: 810, loss: 0.1085156723856926
step: 820, loss: 0.09808841347694397
step: 830, loss: 0.12438197433948517
step: 840, loss: 0.15863990783691406
step: 850, loss: 0.09321905672550201
step: 860, loss: 0.06268622726202011
step: 870, loss: 0.08759912103414536
step: 880, loss: 0.1314317137002945
step: 890, loss: 0.14143520593643188
step: 900, loss: 0.08961156755685806
step: 910, loss: 0.14036455750465393
step: 920, loss: 0.16898347437381744
step: 930, loss: 0.12538889050483704
step: 940, loss: 0.09829399734735489
step: 950, loss: 0.08195489645004272
step: 960, loss: 0.0587129145860672
step: 970, loss: 0.04935845732688904
step: 980, loss: 0.1721440851688385
step: 990, loss: 0.12782424688339233
step: 1000, loss: 0.21127763390541077
step: 1010, loss: 0.10512593388557434
step: 1020, loss: 0.0005984891904518008
step: 1030, loss: 0.07440300285816193
step: 1040, loss: 0.031547773629426956
step: 1050, loss: 0.1701096147298813
step: 1060, loss: 0.041837144643068314
step: 1070, loss: 0.050351716578006744
epoch 1: dev_f1=0.9211267605633803, f1=0.9180327868852459, best_f1=0.9180327868852459
step: 0, loss: 0.06732433289289474
step: 10, loss: 0.11422950029373169
step: 20, loss: 0.09665555506944656
step: 30, loss: 0.02429744228720665
step: 40, loss: 0.09275268018245697
step: 50, loss: 0.1756567806005478
step: 60, loss: 0.060466740280389786
step: 70, loss: 0.029010385274887085
step: 80, loss: 0.28084641695022583
step: 90, loss: 0.052567802369594574
step: 100, loss: 0.08922930061817169
step: 110, loss: 0.06538009643554688
step: 120, loss: 0.0446736104786396
step: 130, loss: 0.158975750207901
step: 140, loss: 0.044643037021160126
step: 150, loss: 0.06363870948553085
step: 160, loss: 0.14610597491264343
step: 170, loss: 0.0769507884979248
step: 180, loss: 0.07516634464263916
step: 190, loss: 0.22828103601932526
step: 200, loss: 0.11221754550933838
step: 210, loss: 0.11549650877714157
step: 220, loss: 0.15446586906909943
step: 230, loss: 0.1577373743057251
step: 240, loss: 0.002012989018112421
step: 250, loss: 0.1290893256664276
step: 260, loss: 0.09480196237564087
step: 270, loss: 0.0749608725309372
step: 280, loss: 0.0730624794960022
step: 290, loss: 0.06212901324033737
step: 300, loss: 0.06809401512145996
step: 310, loss: 0.05781291797757149
step: 320, loss: 0.17924529314041138
step: 330, loss: 0.13428868353366852
step: 340, loss: 0.10138613730669022
step: 350, loss: 0.19444474577903748
step: 360, loss: 0.036499857902526855
step: 370, loss: 0.04007435590028763
step: 380, loss: 0.07378309965133667
step: 390, loss: 0.05474582687020302
step: 400, loss: 0.10060140490531921
step: 410, loss: 0.15580515563488007
step: 420, loss: 0.1077052429318428
step: 430, loss: 0.024043001234531403
step: 440, loss: 0.028536967933177948
step: 450, loss: 0.038693420588970184
step: 460, loss: 0.03691919147968292
step: 470, loss: 0.14099226891994476
step: 480, loss: 0.11937732994556427
step: 490, loss: 0.09093717485666275
step: 500, loss: 0.17700983583927155
step: 510, loss: 0.15505847334861755
step: 520, loss: 0.1043047308921814
step: 530, loss: 0.10731833428144455
step: 540, loss: 0.12520648539066315
step: 550, loss: 0.03768887370824814
step: 560, loss: 0.09513115882873535
step: 570, loss: 0.03882792964577675
step: 580, loss: 0.0921882912516594
step: 590, loss: 0.16732576489448547
step: 600, loss: 0.09599026292562485
step: 610, loss: 0.10208021104335785
step: 620, loss: 0.13404180109500885
step: 630, loss: 0.10110995173454285
step: 640, loss: 0.04192432016134262
step: 650, loss: 0.01118921022862196
step: 660, loss: 0.25270259380340576
step: 670, loss: 0.03172106668353081
step: 680, loss: 0.047657083719968796
step: 690, loss: 0.06426549702882767
step: 700, loss: 0.14708635210990906
step: 710, loss: 0.15433591604232788
step: 720, loss: 0.019570747390389442
step: 730, loss: 0.07119857519865036
step: 740, loss: 0.028017757460474968
step: 750, loss: 0.017971327528357506
step: 760, loss: 0.14904485642910004
step: 770, loss: 0.1846085786819458
step: 780, loss: 0.03735273331403732
step: 790, loss: 0.1820971518754959
step: 800, loss: 0.04165365546941757
step: 810, loss: 0.08157648891210556
step: 820, loss: 0.05579685792326927
step: 830, loss: 0.19211825728416443
step: 840, loss: 0.08683103322982788
step: 850, loss: 0.023761160671710968
step: 860, loss: 0.060060933232307434
step: 870, loss: 0.09384223073720932
step: 880, loss: 0.010099958628416061
step: 890, loss: 0.10138743370771408
step: 900, loss: 0.061405181884765625
step: 910, loss: 0.045667413622140884
step: 920, loss: 0.05624609440565109
step: 930, loss: 0.011475355364382267
step: 940, loss: 0.052232131361961365
step: 950, loss: 0.12948985397815704
step: 960, loss: 0.026493839919567108
step: 970, loss: 0.08289704471826553
step: 980, loss: 0.0029734252020716667
step: 990, loss: 0.04471255838871002
step: 1000, loss: 0.07761328667402267
step: 1010, loss: 0.051733314990997314
step: 1020, loss: 0.011384978890419006
step: 1030, loss: 0.12962473928928375
step: 1040, loss: 0.10468171536922455
step: 1050, loss: 0.15327244997024536
step: 1060, loss: 0.04651983827352524
step: 1070, loss: 0.0872875228524208
epoch 2: dev_f1=0.9332711152589829, f1=0.9337068160597572, best_f1=0.9337068160597572
step: 0, loss: 0.029747331514954567
step: 10, loss: 0.021509336307644844
step: 20, loss: 0.009358181618154049
step: 30, loss: 0.07675980776548386
step: 40, loss: 0.04397381842136383
step: 50, loss: 0.03017624095082283
step: 60, loss: 0.11060674488544464
step: 70, loss: 0.07682883739471436
step: 80, loss: 0.02178087644279003
step: 90, loss: 0.15440316498279572
step: 100, loss: 0.06484794616699219
step: 110, loss: 0.05580897256731987
step: 120, loss: 0.1284738928079605
step: 130, loss: 0.14696265757083893
step: 140, loss: 0.04664541780948639
step: 150, loss: 0.010732256807386875
step: 160, loss: 0.05927545949816704
step: 170, loss: 0.06337013095617294
step: 180, loss: 0.06073169782757759
step: 190, loss: 0.13531534373760223
step: 200, loss: 0.10687193274497986
step: 210, loss: 0.10897205024957657
step: 220, loss: 0.040704336017370224
step: 230, loss: 0.0207713283598423
step: 240, loss: 0.028935980051755905
step: 250, loss: 0.0808725580573082
step: 260, loss: 0.03424711897969246
step: 270, loss: 0.10817629098892212
step: 280, loss: 0.05352095514535904
step: 290, loss: 0.007179409731179476
step: 300, loss: 0.1875622570514679
step: 310, loss: 0.09163471311330795
step: 320, loss: 0.04419437795877457
step: 330, loss: 0.36555179953575134
step: 340, loss: 0.0640047937631607
step: 350, loss: 0.09709689766168594
step: 360, loss: 0.014528709463775158
step: 370, loss: 0.012848478741943836
step: 380, loss: 0.012314779683947563
step: 390, loss: 0.05805463343858719
step: 400, loss: 0.15021680295467377
step: 410, loss: 0.031125886365771294
step: 420, loss: 0.02970188669860363
step: 430, loss: 0.10785991698503494
step: 440, loss: 0.07880201935768127
step: 450, loss: 0.11499029397964478
step: 460, loss: 0.05731441453099251
step: 470, loss: 0.11074119061231613
step: 480, loss: 0.07860991358757019
step: 490, loss: 0.0163833387196064
step: 500, loss: 0.033994197845458984
step: 510, loss: 0.028688538819551468
step: 520, loss: 0.04878436401486397
step: 530, loss: 0.044069670140743256
step: 540, loss: 0.021210797131061554
step: 550, loss: 0.10819600522518158
step: 560, loss: 0.05138716101646423
step: 570, loss: 0.008912747725844383
step: 580, loss: 0.09651635587215424
step: 590, loss: 0.047470297664403915
step: 600, loss: 0.031836919486522675
step: 610, loss: 0.10715284943580627
step: 620, loss: 0.027162188664078712
step: 630, loss: 0.2258397936820984
step: 640, loss: 0.02694915235042572
step: 650, loss: 0.0990624874830246
step: 660, loss: 0.07213512808084488
step: 670, loss: 0.053631946444511414
step: 680, loss: 0.05414770543575287
step: 690, loss: 0.04698818176984787
step: 700, loss: 0.0843261182308197
step: 710, loss: 0.14981594681739807
step: 720, loss: 0.13867761194705963
step: 730, loss: 0.016582155600190163
step: 740, loss: 0.016606923192739487
step: 750, loss: 0.1381232887506485
step: 760, loss: 0.03531425818800926
step: 770, loss: 0.10078207403421402
step: 780, loss: 0.016106294468045235
step: 790, loss: 0.027569033205509186
step: 800, loss: 0.050392985343933105
step: 810, loss: 0.030705993995070457
step: 820, loss: 0.11936678737401962
step: 830, loss: 0.01103863213211298
step: 840, loss: 0.15574930608272552
step: 850, loss: 0.047556355595588684
step: 860, loss: 0.044462256133556366
step: 870, loss: 0.12817497551441193
step: 880, loss: 0.15584416687488556
step: 890, loss: 0.0010146638378500938
step: 900, loss: 0.014240853488445282
step: 910, loss: 0.191727414727211
step: 920, loss: 0.058226387947797775
step: 930, loss: 0.049468688666820526
step: 940, loss: 0.05510300397872925
step: 950, loss: 0.05479087308049202
step: 960, loss: 0.14806027710437775
step: 970, loss: 0.14784300327301025
step: 980, loss: 0.10320518910884857
step: 990, loss: 0.037870291620492935
step: 1000, loss: 0.11960963904857635
step: 1010, loss: 0.017300058156251907
step: 1020, loss: 0.1691247820854187
step: 1030, loss: 0.13376815617084503
step: 1040, loss: 0.01813609153032303
step: 1050, loss: 0.048037733882665634
step: 1060, loss: 0.08999824523925781
step: 1070, loss: 0.0742979422211647
epoch 3: dev_f1=0.9359963685882887, f1=0.9316432775011317, best_f1=0.9316432775011317
step: 0, loss: 0.02280394546687603
step: 10, loss: 0.09338118880987167
step: 20, loss: 0.028935685753822327
step: 30, loss: 0.21545585989952087
step: 40, loss: 0.12766264379024506
step: 50, loss: 0.024161415174603462
step: 60, loss: 0.01960153505206108
step: 70, loss: 0.02392369508743286
step: 80, loss: 0.08483384549617767
step: 90, loss: 0.14742890000343323
step: 100, loss: 0.14060445129871368
step: 110, loss: 0.043635934591293335
step: 120, loss: 0.022194748744368553
step: 130, loss: 0.060824405401945114
step: 140, loss: 0.2305869311094284
step: 150, loss: 0.12657082080841064
step: 160, loss: 0.027125809341669083
step: 170, loss: 0.12327977269887924
step: 180, loss: 0.053467631340026855
step: 190, loss: 0.07715359330177307
step: 200, loss: 0.043050505220890045
step: 210, loss: 0.05546509847044945
step: 220, loss: 0.06523679196834564
step: 230, loss: 0.030587827786803246
step: 240, loss: 0.0068356613628566265
step: 250, loss: 0.015967534855008125
step: 260, loss: 0.057773612439632416
step: 270, loss: 0.07131015509366989
step: 280, loss: 0.06440170109272003
step: 290, loss: 0.1422077864408493
step: 300, loss: 0.023109085857868195
step: 310, loss: 0.025695282965898514
step: 320, loss: 0.07253447920084
step: 330, loss: 0.01216509472578764
step: 340, loss: 0.026065340265631676
step: 350, loss: 0.04384390637278557
step: 360, loss: 0.16454368829727173
step: 370, loss: 0.041879910975694656
step: 380, loss: 0.13394366204738617
step: 390, loss: 0.08765029162168503
step: 400, loss: 0.02672651596367359
step: 410, loss: 0.000948053493630141
step: 420, loss: 0.14459086954593658
step: 430, loss: 0.08257409930229187
step: 440, loss: 0.10165753215551376
step: 450, loss: 0.06454359740018845
step: 460, loss: 0.0729590505361557
step: 470, loss: 0.04304955154657364
step: 480, loss: 0.014816022478044033
step: 490, loss: 0.0874750018119812
step: 500, loss: 0.07153751701116562
step: 510, loss: 0.08472096920013428
step: 520, loss: 0.11338059604167938
step: 530, loss: 0.09714440256357193
step: 540, loss: 0.05056384578347206
step: 550, loss: 0.052523646503686905
step: 560, loss: 0.06861750036478043
step: 570, loss: 0.11571948230266571
step: 580, loss: 0.04435455799102783
step: 590, loss: 0.03865320608019829
step: 600, loss: 0.053135018795728683
step: 610, loss: 0.34630507230758667
step: 620, loss: 0.08418670296669006
step: 630, loss: 0.09678430110216141
step: 640, loss: 0.06872653216123581
step: 650, loss: 0.06478776782751083
step: 660, loss: 0.18854299187660217
step: 670, loss: 0.1961243897676468
step: 680, loss: 0.036635734140872955
step: 690, loss: 0.05648432672023773
step: 700, loss: 0.05488937348127365
step: 710, loss: 0.11550123989582062
step: 720, loss: 0.05828714370727539
step: 730, loss: 0.16874602437019348
step: 740, loss: 0.025817112997174263
step: 750, loss: 0.0879431888461113
step: 760, loss: 0.09582450240850449
step: 770, loss: 0.04738996922969818
step: 780, loss: 0.014040018431842327
step: 790, loss: 0.014545194804668427
step: 800, loss: 0.0658758357167244
step: 810, loss: 0.11377719789743423
step: 820, loss: 0.018095165491104126
step: 830, loss: 0.10473129153251648
step: 840, loss: 0.0015646194806322455
step: 850, loss: 0.029575515538454056
step: 860, loss: 0.0814903974533081
step: 870, loss: 0.03888467699289322
step: 880, loss: 0.07973843812942505
step: 890, loss: 0.041068919003009796
step: 900, loss: 0.06874120980501175
step: 910, loss: 0.13336095213890076
step: 920, loss: 0.0637911707162857
step: 930, loss: 0.016263047233223915
step: 940, loss: 0.034299302846193314
step: 950, loss: 0.086162269115448
step: 960, loss: 0.02587815932929516
step: 970, loss: 0.0063244071789085865
step: 980, loss: 0.08539797365665436
step: 990, loss: 0.12507621943950653
step: 1000, loss: 0.03751054033637047
step: 1010, loss: 0.032420504838228226
step: 1020, loss: 0.15372304618358612
step: 1030, loss: 0.06143473461270332
step: 1040, loss: 0.02283758856356144
step: 1050, loss: 0.10654611140489578
step: 1060, loss: 0.12780345976352692
step: 1070, loss: 0.013483814895153046
epoch 4: dev_f1=0.9343200740055504, f1=0.9371847776249428, best_f1=0.9316432775011317
step: 0, loss: 0.01562141440808773
step: 10, loss: 0.029665391892194748
step: 20, loss: 0.044286832213401794
step: 30, loss: 0.091603122651577
step: 40, loss: 0.027981825172901154
step: 50, loss: 0.13221174478530884
step: 60, loss: 0.0816071629524231
step: 70, loss: 0.0997447818517685
step: 80, loss: 0.03260181471705437
step: 90, loss: 0.18866582214832306
step: 100, loss: 0.019107650965452194
step: 110, loss: 0.021221686154603958
step: 120, loss: 0.10462786257266998
step: 130, loss: 0.06308526545763016
step: 140, loss: 0.019627727568149567
step: 150, loss: 0.3392661511898041
step: 160, loss: 0.08992299437522888
step: 170, loss: 0.06396526843309402
step: 180, loss: 0.027295684441924095
step: 190, loss: 0.02306022122502327
step: 200, loss: 0.11472507566213608
step: 210, loss: 0.0907677486538887
step: 220, loss: 0.13573557138442993
step: 230, loss: 0.015239104628562927
step: 240, loss: 0.1734420210123062
step: 250, loss: 0.09174095094203949
step: 260, loss: 0.04971976950764656
step: 270, loss: 0.0011678485898301005
step: 280, loss: 0.05295536667108536
step: 290, loss: 0.006770232692360878
step: 300, loss: 0.01899402216076851
step: 310, loss: 0.005868737120181322
step: 320, loss: 0.044356804341077805
step: 330, loss: 0.12409624457359314
step: 340, loss: 0.11312876641750336
step: 350, loss: 0.10520951449871063
step: 360, loss: 0.029055075719952583
step: 370, loss: 0.1298508495092392
step: 380, loss: 0.14373481273651123
step: 390, loss: 0.01896149106323719
step: 400, loss: 0.007010241970419884
step: 410, loss: 0.03813137859106064
step: 420, loss: 0.0065576317720115185
step: 430, loss: 0.0485173724591732
step: 440, loss: 0.10387293249368668
step: 450, loss: 0.013915035873651505
step: 460, loss: 0.08601687103509903
step: 470, loss: 0.03785822540521622
step: 480, loss: 0.04824918136000633
step: 490, loss: 0.10032007098197937
step: 500, loss: 0.07172112911939621
step: 510, loss: 0.08862484991550446
step: 520, loss: 0.09991764277219772
step: 530, loss: 0.12600524723529816
step: 540, loss: 0.03141258656978607
step: 550, loss: 0.019185028970241547
step: 560, loss: 0.012205285020172596
step: 570, loss: 0.04986405745148659
step: 580, loss: 0.022324439138174057
step: 590, loss: 0.011779166758060455
step: 600, loss: 0.06639264523983002
step: 610, loss: 0.002698345109820366
step: 620, loss: 0.013003842905163765
step: 630, loss: 0.0665837973356247
step: 640, loss: 0.02371646836400032
step: 650, loss: 0.048165567219257355
step: 660, loss: 0.07633593678474426
step: 670, loss: 0.03376893326640129
step: 680, loss: 0.060618720948696136
step: 690, loss: 0.10308279097080231
step: 700, loss: 0.035507332533597946
step: 710, loss: 0.13999009132385254
step: 720, loss: 0.05656059458851814
step: 730, loss: 0.028470542281866074
step: 740, loss: 0.0024273530580103397
step: 750, loss: 0.05383211001753807
step: 760, loss: 0.06220272555947304
step: 770, loss: 0.015985960140824318
step: 780, loss: 0.017101548612117767
step: 790, loss: 0.028606180101633072
step: 800, loss: 0.002783572766929865
step: 810, loss: 0.19432593882083893
step: 820, loss: 0.028555119410157204
step: 830, loss: 0.06356415152549744
step: 840, loss: 0.16280867159366608
step: 850, loss: 0.13088487088680267
step: 860, loss: 0.013235104270279408
step: 870, loss: 0.07884920388460159
step: 880, loss: 0.07437010854482651
step: 890, loss: 0.11247986555099487
step: 900, loss: 0.05631975829601288
step: 910, loss: 0.017969762906432152
step: 920, loss: 0.10238853842020035
step: 930, loss: 0.09772917628288269
step: 940, loss: 0.053929269313812256
step: 950, loss: 0.061013851314783096
step: 960, loss: 0.04499952495098114
step: 970, loss: 0.01957300491631031
step: 980, loss: 0.07733654975891113
step: 990, loss: 0.03851088136434555
step: 1000, loss: 0.024536898359656334
step: 1010, loss: 0.0439242422580719
step: 1020, loss: 0.08800175040960312
step: 1030, loss: 0.26772943139076233
step: 1040, loss: 0.018767887726426125
step: 1050, loss: 0.009120333939790726
step: 1060, loss: 0.09842509776353836
step: 1070, loss: 0.11281518638134003
epoch 5: dev_f1=0.9422098936662043, f1=0.936150666054203, best_f1=0.936150666054203
step: 0, loss: 0.218861386179924
step: 10, loss: 0.0914171114563942
step: 20, loss: 0.09646216034889221
step: 30, loss: 0.057608768343925476
step: 40, loss: 0.1282181292772293
step: 50, loss: 0.015811089426279068
step: 60, loss: 0.2626713216304779
step: 70, loss: 0.01929689757525921
step: 80, loss: 0.017768211662769318
step: 90, loss: 0.009469014592468739
step: 100, loss: 0.023504553362727165
step: 110, loss: 0.055508311837911606
step: 120, loss: 0.02233850583434105
step: 130, loss: 0.07166716456413269
step: 140, loss: 0.04641413316130638
step: 150, loss: 0.09061193466186523
step: 160, loss: 0.12671281397342682
step: 170, loss: 0.007339604198932648
step: 180, loss: 0.06655421108007431
step: 190, loss: 0.0685187503695488
step: 200, loss: 0.07205138355493546
step: 210, loss: 0.08715221285820007
step: 220, loss: 0.19364739954471588
step: 230, loss: 0.04886322841048241
step: 240, loss: 0.09349820017814636
step: 250, loss: 0.004202726297080517
step: 260, loss: 0.04780779778957367
step: 270, loss: 0.05714349076151848
step: 280, loss: 0.028629081323742867
step: 290, loss: 0.021689727902412415
step: 300, loss: 0.03305365517735481
step: 310, loss: 0.13368113338947296
step: 320, loss: 0.018054641783237457
step: 330, loss: 0.04892907291650772
step: 340, loss: 0.03737254813313484
step: 350, loss: 0.036192845553159714
step: 360, loss: 0.039009612053632736
step: 370, loss: 0.13121898472309113
step: 380, loss: 0.09358329325914383
step: 390, loss: 0.0073022195138037205
step: 400, loss: 0.22617343068122864
step: 410, loss: 0.08160436153411865
step: 420, loss: 0.03923232853412628
step: 430, loss: 0.08644495904445648
step: 440, loss: 0.07483561336994171
step: 450, loss: 0.01268191821873188
step: 460, loss: 0.032088641077280045
step: 470, loss: 0.03222037851810455
step: 480, loss: 0.10137490928173065
step: 490, loss: 0.07660096138715744
step: 500, loss: 0.1353975534439087
step: 510, loss: 0.2610218822956085
step: 520, loss: 0.04049065709114075
step: 530, loss: 0.13957667350769043
step: 540, loss: 0.12175652384757996
step: 550, loss: 0.08044730126857758
step: 560, loss: 0.017746154218912125
step: 570, loss: 0.0757312998175621
step: 580, loss: 0.07192212343215942
step: 590, loss: 0.019125238060951233
step: 600, loss: 0.20336498320102692
step: 610, loss: 0.022263191640377045
step: 620, loss: 0.049271345138549805
step: 630, loss: 0.03796220198273659
step: 640, loss: 0.043743692338466644
step: 650, loss: 0.02068813145160675
step: 660, loss: 0.09739196300506592
step: 670, loss: 0.04187232255935669
step: 680, loss: 0.034900542348623276
step: 690, loss: 0.051990095525979996
step: 700, loss: 0.08155730366706848
step: 710, loss: 0.13041453063488007
step: 720, loss: 0.08587713539600372
step: 730, loss: 0.0574054941534996
step: 740, loss: 0.014183510094881058
step: 750, loss: 0.024294685572385788
step: 760, loss: 0.10947249084711075
step: 770, loss: 0.007820009253919125
step: 780, loss: 0.014616414904594421
step: 790, loss: 0.04499144107103348
step: 800, loss: 0.023455040529370308
step: 810, loss: 0.12536215782165527
step: 820, loss: 0.022011414170265198
step: 830, loss: 0.016109630465507507
step: 840, loss: 0.4637809991836548
step: 850, loss: 0.07949018478393555
step: 860, loss: 0.057841673493385315
step: 870, loss: 0.05450496822595596
step: 880, loss: 0.030613034963607788
step: 890, loss: 0.005546374712139368
step: 900, loss: 0.017623325809836388
step: 910, loss: 0.1064455583691597
step: 920, loss: 0.15337790548801422
step: 930, loss: 0.0060275555588305
step: 940, loss: 0.07771459221839905
step: 950, loss: 0.043536119163036346
step: 960, loss: 0.019208213314414024
step: 970, loss: 0.010987390764057636
step: 980, loss: 0.06713945418596268
step: 990, loss: 0.04914071783423424
step: 1000, loss: 0.03702489286661148
step: 1010, loss: 0.030876705422997475
step: 1020, loss: 0.007760557346045971
step: 1030, loss: 0.08505173027515411
step: 1040, loss: 0.08638665825128555
step: 1050, loss: 0.05968621000647545
step: 1060, loss: 0.1726328283548355
step: 1070, loss: 0.02158437669277191
epoch 6: dev_f1=0.9341372912801483, f1=0.9259088817303267, best_f1=0.936150666054203
step: 0, loss: 0.10957324504852295
step: 10, loss: 0.05969374626874924
step: 20, loss: 0.13492703437805176
step: 30, loss: 0.0824810191988945
step: 40, loss: 0.13242429494857788
step: 50, loss: 0.024446716532111168
step: 60, loss: 0.029441239312291145
step: 70, loss: 0.025103606283664703
step: 80, loss: 0.04101411998271942
step: 90, loss: 0.014562932774424553
step: 100, loss: 0.10425947606563568
step: 110, loss: 0.0778546929359436
step: 120, loss: 0.014090651646256447
step: 130, loss: 0.08016648888587952
step: 140, loss: 0.005376729648560286
step: 150, loss: 0.025358201935887337
step: 160, loss: 0.0845378190279007
step: 170, loss: 0.07710181176662445
step: 180, loss: 0.06277737766504288
step: 190, loss: 0.04625288024544716
step: 200, loss: 0.11495757848024368
step: 210, loss: 0.007981577888131142
step: 220, loss: 0.00532434182241559
step: 230, loss: 0.02574056014418602
step: 240, loss: 0.08393976837396622
step: 250, loss: 0.013034805655479431
step: 260, loss: 0.0875164195895195
step: 270, loss: 0.05523648113012314
step: 280, loss: 0.023404747247695923
step: 290, loss: 0.035728394985198975
step: 300, loss: 0.014274099841713905
step: 310, loss: 9.386236342834309e-05
step: 320, loss: 0.023213675245642662
step: 330, loss: 0.009048255160450935
step: 340, loss: 0.019013982266187668
step: 350, loss: 0.1323067843914032
step: 360, loss: 0.0724383220076561
step: 370, loss: 0.0017127743922173977
step: 380, loss: 0.021786516532301903
step: 390, loss: 0.01699005998671055
step: 400, loss: 0.0038622368592768908
step: 410, loss: 0.019492818042635918
step: 420, loss: 0.02517363801598549
step: 430, loss: 0.11706055700778961
step: 440, loss: 0.02235296182334423
step: 450, loss: 0.06614906340837479
step: 460, loss: 0.02589777484536171
step: 470, loss: 0.048001114279031754
step: 480, loss: 0.06636251509189606
step: 490, loss: 0.10627898573875427
step: 500, loss: 0.011717084795236588
step: 510, loss: 0.005772831849753857
step: 520, loss: 0.029264379292726517
step: 530, loss: 0.06942753493785858
step: 540, loss: 0.02400464192032814
step: 550, loss: 0.011253643780946732
step: 560, loss: 0.016974905505776405
step: 570, loss: 0.05090836063027382
step: 580, loss: 0.12499810755252838
step: 590, loss: 0.048504553735256195
step: 600, loss: 0.05394874885678291
step: 610, loss: 0.1121835708618164
step: 620, loss: 0.10027781128883362
step: 630, loss: 0.0751195177435875
step: 640, loss: 0.008295249193906784
step: 650, loss: 0.0854690670967102
step: 660, loss: 0.07526513934135437
step: 670, loss: 0.10767237842082977
step: 680, loss: 0.008108988404273987
step: 690, loss: 0.011513232253491879
step: 700, loss: 0.023912880569696426
step: 710, loss: 0.005887978710234165
step: 720, loss: 0.09410742670297623
step: 730, loss: 0.059287432581186295
step: 740, loss: 0.08697454631328583
step: 750, loss: 0.05386100709438324
step: 760, loss: 0.005846431478857994
step: 770, loss: 0.06767198443412781
step: 780, loss: 0.006838272791355848
step: 790, loss: 0.016407987102866173
step: 800, loss: 0.028658373281359673
step: 810, loss: 0.08311113715171814
step: 820, loss: 0.08839501440525055
step: 830, loss: 0.06556035578250885
step: 840, loss: 0.016955306753516197
step: 850, loss: 0.0076586781069636345
step: 860, loss: 0.0314808264374733
step: 870, loss: 0.16485944390296936
step: 880, loss: 0.033602263778448105
step: 890, loss: 0.133710578083992
step: 900, loss: 0.00769377825781703
step: 910, loss: 0.07440967857837677
step: 920, loss: 0.025202469900250435
step: 930, loss: 0.012889450415968895
step: 940, loss: 0.024518784135580063
step: 950, loss: 0.09156627207994461
step: 960, loss: 0.047473639249801636
step: 970, loss: 0.021486038342118263
step: 980, loss: 0.05985235422849655
step: 990, loss: 0.11937461048364639
step: 1000, loss: 0.17215879261493683
step: 1010, loss: 0.012036149390041828
step: 1020, loss: 0.06001051142811775
step: 1030, loss: 0.04224134609103203
step: 1040, loss: 0.044001344591379166
step: 1050, loss: 0.15950410068035126
step: 1060, loss: 0.023291176185011864
step: 1070, loss: 0.00641295313835144
epoch 7: dev_f1=0.9410672853828307, f1=0.9386814200092208, best_f1=0.936150666054203
step: 0, loss: 0.016996681690216064
step: 10, loss: 0.006666575558483601
step: 20, loss: 0.01606440357863903
step: 30, loss: 0.02454978972673416
step: 40, loss: 0.10249640792608261
step: 50, loss: 0.09455262869596481
step: 60, loss: 0.06709187477827072
step: 70, loss: 0.005863965023308992
step: 80, loss: 0.1173086017370224
step: 90, loss: 0.11223367601633072
step: 100, loss: 0.018805822357535362
step: 110, loss: 0.010029210709035397
step: 120, loss: 0.06784242391586304
step: 130, loss: 0.016026072204113007
step: 140, loss: 0.06558555364608765
step: 150, loss: 0.10614755749702454
step: 160, loss: 0.013772944919764996
step: 170, loss: 0.001977943815290928
step: 180, loss: 0.0725918635725975
step: 190, loss: 0.02761782892048359
step: 200, loss: 0.03924144059419632
step: 210, loss: 0.01127857156097889
step: 220, loss: 0.005146650597453117
step: 230, loss: 0.0013293302617967129
step: 240, loss: 0.04361910745501518
step: 250, loss: 0.01639106124639511
step: 260, loss: 0.1187807247042656
step: 270, loss: 0.03697403147816658
step: 280, loss: 0.0039278436452150345
step: 290, loss: 0.008617774583399296
step: 300, loss: 0.10676497220993042
step: 310, loss: 0.007980821654200554
step: 320, loss: 0.04585719853639603
step: 330, loss: 0.013821398839354515
step: 340, loss: 0.05699699744582176
step: 350, loss: 0.06531376391649246
step: 360, loss: 0.03736528381705284
step: 370, loss: 0.010142330080270767
step: 380, loss: 0.054885633289813995
step: 390, loss: 0.0037072228733450174
step: 400, loss: 0.04439369961619377
step: 410, loss: 0.20394787192344666
step: 420, loss: 0.03759826719760895
step: 430, loss: 0.033872853964567184
step: 440, loss: 0.0029764596838504076
step: 450, loss: 0.06829183548688889
step: 460, loss: 0.02134094201028347
step: 470, loss: 0.05755459889769554
step: 480, loss: 0.008778784424066544
step: 490, loss: 0.018182897940278053
step: 500, loss: 0.04499603807926178
step: 510, loss: 0.18881554901599884
step: 520, loss: 0.06897291541099548
step: 530, loss: 0.03383634611964226
step: 540, loss: 0.07041723281145096
step: 550, loss: 0.0052596330642700195
step: 560, loss: 0.07224402576684952
step: 570, loss: 0.024883121252059937
step: 580, loss: 0.1632920801639557
step: 590, loss: 0.01793207973241806
step: 600, loss: 0.07651910930871964
step: 610, loss: 0.054920800030231476
step: 620, loss: 0.009360907599329948
step: 630, loss: 0.05851630121469498
step: 640, loss: 0.07821577787399292
step: 650, loss: 0.006560307461768389
step: 660, loss: 0.058119747787714005
step: 670, loss: 0.09883035719394684
step: 680, loss: 0.08428096771240234
step: 690, loss: 0.0014732088893651962
step: 700, loss: 0.08119846880435944
step: 710, loss: 0.0739809200167656
step: 720, loss: 0.03338096663355827
step: 730, loss: 0.04940422251820564
step: 740, loss: 0.04087288677692413
step: 750, loss: 0.007640362251549959
step: 760, loss: 0.007800258230417967
step: 770, loss: 0.010390087030827999
step: 780, loss: 0.03525242209434509
step: 790, loss: 0.12214864790439606
step: 800, loss: 0.07097210735082626
step: 810, loss: 0.07058423012495041
step: 820, loss: 0.03820759803056717
step: 830, loss: 0.0836416706442833
step: 840, loss: 0.08195829391479492
step: 850, loss: 0.04132675752043724
step: 860, loss: 0.0022558849304914474
step: 870, loss: 0.07861386239528656
step: 880, loss: 0.04004361480474472
step: 890, loss: 0.018457740545272827
step: 900, loss: 0.0038605935405939817
step: 910, loss: 0.016060154885053635
step: 920, loss: 0.2597730755805969
step: 930, loss: 0.05268999561667442
step: 940, loss: 0.03207651525735855
step: 950, loss: 0.09294741600751877
step: 960, loss: 0.08537857979536057
step: 970, loss: 0.08066993206739426
step: 980, loss: 0.008452944457530975
step: 990, loss: 0.00942901149392128
step: 1000, loss: 0.025569789111614227
step: 1010, loss: 0.06871815770864487
step: 1020, loss: 0.043536681681871414
step: 1030, loss: 0.0796733871102333
step: 1040, loss: 0.0855933129787445
step: 1050, loss: 0.029109729453921318
step: 1060, loss: 0.040318429470062256
step: 1070, loss: 0.1114567220211029
epoch 8: dev_f1=0.9328392774432608, f1=0.9348729792147806, best_f1=0.936150666054203
step: 0, loss: 0.06854753941297531
step: 10, loss: 0.05789455026388168
step: 20, loss: 0.037622228264808655
step: 30, loss: 0.059493567794561386
step: 40, loss: 0.03763425722718239
step: 50, loss: 0.03612631559371948
step: 60, loss: 0.034878239035606384
step: 70, loss: 0.011979415081441402
step: 80, loss: 0.01203041523694992
step: 90, loss: 0.004079895094037056
step: 100, loss: 0.018074309453368187
step: 110, loss: 0.09082826226949692
step: 120, loss: 0.02040141075849533
step: 130, loss: 0.04950491338968277
step: 140, loss: 0.02391207590699196
step: 150, loss: 0.030533352866768837
step: 160, loss: 0.025674467906355858
step: 170, loss: 0.06882050633430481
step: 180, loss: 0.03436403349041939
step: 190, loss: 0.09021029621362686
step: 200, loss: 0.05808993801474571
step: 210, loss: 0.097115159034729
step: 220, loss: 0.010717482306063175
step: 230, loss: 0.08284147083759308
step: 240, loss: 0.030338674783706665
step: 250, loss: 0.04473361745476723
step: 260, loss: 0.02012225054204464
step: 270, loss: 0.03838648647069931
step: 280, loss: 0.024221215397119522
step: 290, loss: 0.04260263219475746
step: 300, loss: 0.011577614583075047
step: 310, loss: 0.09660499542951584
step: 320, loss: 0.020646926015615463
step: 330, loss: 0.0805123820900917
step: 340, loss: 0.0017498030792921782
step: 350, loss: 0.010452436283230782
step: 360, loss: 0.004127182066440582
step: 370, loss: 0.002364978427067399
step: 380, loss: 0.10321899503469467
step: 390, loss: 0.07062338292598724
step: 400, loss: 0.01345023699104786
step: 410, loss: 0.10066583752632141
step: 420, loss: 0.02560894377529621
step: 430, loss: 0.04545827582478523
step: 440, loss: 0.03886446729302406
step: 450, loss: 0.01506674475967884
step: 460, loss: 0.0022483726497739553
step: 470, loss: 0.059774331748485565
step: 480, loss: 0.05021077021956444
step: 490, loss: 0.03381142392754555
step: 500, loss: 0.05887940898537636
step: 510, loss: 0.09165142476558685
step: 520, loss: 0.19642417132854462
step: 530, loss: 0.017135389149188995
step: 540, loss: 0.0912572592496872
step: 550, loss: 0.16003601253032684
step: 560, loss: 0.01197533868253231
step: 570, loss: 0.0008000880479812622
step: 580, loss: 0.008696929551661015
step: 590, loss: 0.0013073120499029756
step: 600, loss: 0.009942695498466492
step: 610, loss: 0.021924277767539024
step: 620, loss: 0.093103788793087
step: 630, loss: 0.0333077646791935
step: 640, loss: 0.13794614374637604
step: 650, loss: 0.031379688531160355
step: 660, loss: 0.029343729838728905
step: 670, loss: 0.1255595088005066
step: 680, loss: 0.03808191791176796
step: 690, loss: 0.008463920094072819
step: 700, loss: 0.1251145452260971
step: 710, loss: 0.1709684580564499
step: 720, loss: 0.012241124175488949
step: 730, loss: 0.006297471933066845
step: 740, loss: 0.03645113855600357
step: 750, loss: 0.0502745620906353
step: 760, loss: 0.0222502201795578
step: 770, loss: 0.03645826131105423
step: 780, loss: 0.024710480123758316
step: 790, loss: 0.01791873574256897
step: 800, loss: 0.17375293374061584
step: 810, loss: 0.02305992692708969
step: 820, loss: 0.06119612604379654
step: 830, loss: 0.0250600166618824
step: 840, loss: 0.12572132050991058
step: 850, loss: 0.10179425030946732
step: 860, loss: 0.03306262195110321
step: 870, loss: 0.05017336085438728
step: 880, loss: 0.06253492832183838
step: 890, loss: 0.11743852496147156
step: 900, loss: 0.0009391566272825003
step: 910, loss: 0.07502438127994537
step: 920, loss: 0.02346987836062908
step: 930, loss: 0.05247555673122406
step: 940, loss: 0.1652413308620453
step: 950, loss: 0.08601973950862885
step: 960, loss: 0.041153524070978165
step: 970, loss: 0.08647383749485016
step: 980, loss: 0.024972667917609215
step: 990, loss: 0.013901441358029842
step: 1000, loss: 0.0065611582249403
step: 1010, loss: 0.012615138664841652
step: 1020, loss: 0.07323946803808212
step: 1030, loss: 0.055933624505996704
step: 1040, loss: 0.0032045410480350256
step: 1050, loss: 0.01500250119715929
step: 1060, loss: 0.03779880329966545
step: 1070, loss: 0.1258053034543991
epoch 9: dev_f1=0.93989588263133, f1=0.9342723004694835, best_f1=0.936150666054203
step: 0, loss: 0.10204481333494186
step: 10, loss: 0.058625925332307816
step: 20, loss: 0.0003434194659348577
step: 30, loss: 0.008218483999371529
step: 40, loss: 0.00040266095311380923
step: 50, loss: 0.1136787086725235
step: 60, loss: 0.022077258676290512
step: 70, loss: 0.007179528474807739
step: 80, loss: 0.06466079503297806
step: 90, loss: 0.005863912403583527
step: 100, loss: 0.01758599653840065
step: 110, loss: 0.02789893187582493
step: 120, loss: 0.003519476158544421
step: 130, loss: 0.016074232757091522
step: 140, loss: 0.011773141101002693
step: 150, loss: 0.030858075246214867
step: 160, loss: 0.010136780329048634
step: 170, loss: 0.04878385365009308
step: 180, loss: 0.0053193941712379456
step: 190, loss: 0.08865093439817429
step: 200, loss: 0.028635844588279724
step: 210, loss: 0.013863244093954563
step: 220, loss: 0.03569761663675308
step: 230, loss: 0.030777230858802795
step: 240, loss: 0.006836704444140196
step: 250, loss: 0.012364204972982407
step: 260, loss: 0.005577319301664829
step: 270, loss: 0.02076847106218338
step: 280, loss: 0.05408585071563721
step: 290, loss: 0.0891481265425682
step: 300, loss: 0.0006384582375176251
step: 310, loss: 0.04476848989725113
step: 320, loss: 0.05783456936478615
step: 330, loss: 0.06514216959476471
step: 340, loss: 0.0657215490937233
step: 350, loss: 0.0005494420183822513
step: 360, loss: 0.024140289053320885
step: 370, loss: 0.17213575541973114
step: 380, loss: 0.028024794533848763
step: 390, loss: 0.07580863684415817
step: 400, loss: 0.022989345714449883
step: 410, loss: 0.05759444832801819
step: 420, loss: 0.0039359526708722115
step: 430, loss: 0.15105906128883362
step: 440, loss: 0.06562630832195282
step: 450, loss: 0.09188565611839294
step: 460, loss: 0.010850431397557259
step: 470, loss: 0.026521258056163788
step: 480, loss: 0.061705298721790314
step: 490, loss: 0.06357861310243607
step: 500, loss: 0.06655953079462051
step: 510, loss: 0.05826522782444954
step: 520, loss: 0.007154726888984442
step: 530, loss: 0.15296469628810883
step: 540, loss: 0.08796630799770355
step: 550, loss: 0.15166489779949188
step: 560, loss: 0.03545384481549263
step: 570, loss: 0.05405470356345177
step: 580, loss: 0.016690926626324654
step: 590, loss: 0.12495233118534088
step: 600, loss: 0.03884086757898331
step: 610, loss: 0.04769357293844223
step: 620, loss: 0.032367996871471405
step: 630, loss: 0.052492521703243256
step: 640, loss: 0.07619333267211914
step: 650, loss: 0.0776953399181366
step: 660, loss: 0.02066957950592041
step: 670, loss: 0.00846413429826498
step: 680, loss: 0.07148712873458862
step: 690, loss: 0.011619413271546364
step: 700, loss: 0.05996275320649147
step: 710, loss: 0.058141645044088364
step: 720, loss: 0.004101556725800037
step: 730, loss: 0.30699676275253296
step: 740, loss: 0.033955637365579605
step: 750, loss: 0.03546188771724701
step: 760, loss: 0.08141735941171646
step: 770, loss: 0.12014031410217285
step: 780, loss: 0.0007450716802850366
step: 790, loss: 0.07541648298501968
step: 800, loss: 0.006339971907436848
step: 810, loss: 0.020938009023666382
step: 820, loss: 0.04382349178195
step: 830, loss: 0.012835869565606117
step: 840, loss: 0.007709518074989319
step: 850, loss: 0.055527202785015106
step: 860, loss: 0.0845562294125557
step: 870, loss: 0.04194559156894684
step: 880, loss: 0.017851706594228745
step: 890, loss: 0.012583952397108078
step: 900, loss: 0.05733417719602585
step: 910, loss: 0.034025888890028
step: 920, loss: 0.05217979848384857
step: 930, loss: 0.00024087008205242455
step: 940, loss: 0.23397864401340485
step: 950, loss: 0.05080414190888405
step: 960, loss: 0.029120517894625664
step: 970, loss: 0.02679811604321003
step: 980, loss: 0.004739061463624239
step: 990, loss: 0.04349938780069351
step: 1000, loss: 0.11384368687868118
step: 1010, loss: 0.05467670038342476
step: 1020, loss: 0.010849183425307274
step: 1030, loss: 0.11657701432704926
step: 1040, loss: 0.04994600638747215
step: 1050, loss: 0.004426154773682356
step: 1060, loss: 0.01990392617881298
step: 1070, loss: 0.0064428821206092834
epoch 10: dev_f1=0.9377901578458682, f1=0.934752429430819, best_f1=0.936150666054203
step: 0, loss: 0.027315540239214897
step: 10, loss: 0.14532910287380219
step: 20, loss: 0.005912255961447954
step: 30, loss: 0.027678143233060837
step: 40, loss: 0.07246137410402298
step: 50, loss: 0.26901882886886597
step: 60, loss: 0.036987870931625366
step: 70, loss: 0.00035779940662905574
step: 80, loss: 0.0007661813287995756
step: 90, loss: 0.08763359487056732
step: 100, loss: 0.07772422581911087
step: 110, loss: 0.03956279158592224
step: 120, loss: 0.10064235329627991
step: 130, loss: 0.05333300679922104
step: 140, loss: 0.018660979345440865
step: 150, loss: 0.09415996819734573
step: 160, loss: 0.027437705546617508
step: 170, loss: 0.03100571408867836
step: 180, loss: 0.05574522167444229
step: 190, loss: 0.0637049749493599
step: 200, loss: 0.09636931866407394
step: 210, loss: 0.014123822562396526
step: 220, loss: 0.052527569234371185
step: 230, loss: 0.03606768324971199
step: 240, loss: 0.04519326612353325
step: 250, loss: 0.03572554886341095
step: 260, loss: 0.008677233010530472
step: 270, loss: 0.04530229791998863
step: 280, loss: 0.031288452446460724
step: 290, loss: 0.04974019154906273
step: 300, loss: 0.05757155641913414
step: 310, loss: 0.07377105951309204
step: 320, loss: 0.00648417929187417
step: 330, loss: 0.10812447220087051
step: 340, loss: 0.00975707732141018
step: 350, loss: 0.04435106739401817
step: 360, loss: 0.009693462401628494
step: 370, loss: 0.04020075500011444
step: 380, loss: 0.04152597859501839
step: 390, loss: 0.006527803838253021
step: 400, loss: 0.05055782198905945
step: 410, loss: 0.02755812555551529
step: 420, loss: 0.0766344964504242
step: 430, loss: 0.012821177020668983
step: 440, loss: 0.055912453681230545
step: 450, loss: 0.03955681994557381
step: 460, loss: 0.005986267700791359
step: 470, loss: 0.045387446880340576
step: 480, loss: 0.001676157582551241
step: 490, loss: 0.0030470285564661026
step: 500, loss: 0.0614827498793602
step: 510, loss: 0.034696247428655624
step: 520, loss: 0.039670687168836594
step: 530, loss: 0.0004998106160201132
step: 540, loss: 0.03803621977567673
step: 550, loss: 0.041621435433626175
step: 560, loss: 0.03174765035510063
step: 570, loss: 0.010152659378945827
step: 580, loss: 0.05012122541666031
step: 590, loss: 0.00010994196782121435
step: 600, loss: 0.09192308783531189
step: 610, loss: 0.07666488736867905
step: 620, loss: 0.02147229202091694
step: 630, loss: 0.03277142345905304
step: 640, loss: 0.04097067192196846
step: 650, loss: 0.0057378970086574554
step: 660, loss: 0.00011627487401710823
step: 670, loss: 0.05662199854850769
step: 680, loss: 0.03311143442988396
step: 690, loss: 0.03387261554598808
step: 700, loss: 0.0006265487754717469
step: 710, loss: 0.00927732978016138
step: 720, loss: 0.008167063817381859
step: 730, loss: 0.005258780438452959
step: 740, loss: 0.060545701533555984
step: 750, loss: 0.002635026816278696
step: 760, loss: 0.07175183296203613
step: 770, loss: 0.12197257578372955
step: 780, loss: 0.06733500212430954
step: 790, loss: 0.027259649708867073
step: 800, loss: 0.04880904406309128
step: 810, loss: 0.00021088948415126652
step: 820, loss: 0.05293668434023857
step: 830, loss: 0.030162867158651352
step: 840, loss: 0.044645581394433975
step: 850, loss: 0.10156504064798355
step: 860, loss: 0.06317976862192154
step: 870, loss: 0.01320569310337305
step: 880, loss: 0.02993890643119812
step: 890, loss: 0.08331117033958435
step: 900, loss: 0.08128628134727478
step: 910, loss: 0.07738274335861206
step: 920, loss: 0.00022165197879076004
step: 930, loss: 0.039345335215330124
step: 940, loss: 0.04675900563597679
step: 950, loss: 0.026803335174918175
step: 960, loss: 0.020523877814412117
step: 970, loss: 0.02809765748679638
step: 980, loss: 0.014879601076245308
step: 990, loss: 0.038001302629709244
step: 1000, loss: 0.023656658828258514
step: 1010, loss: 0.0625140368938446
step: 1020, loss: 0.0010618522064760327
step: 1030, loss: 0.0008475666400045156
step: 1040, loss: 0.0508572980761528
step: 1050, loss: 0.04640406742691994
step: 1060, loss: 0.04216691479086876
step: 1070, loss: 0.044550828635692596
epoch 11: dev_f1=0.9319568277803848, f1=0.9264432029795159, best_f1=0.936150666054203
step: 0, loss: 0.08613031357526779
step: 10, loss: 0.04408864304423332
step: 20, loss: 0.012392967939376831
step: 30, loss: 0.06010204553604126
step: 40, loss: 0.0022297834511846304
step: 50, loss: 0.06904319673776627
step: 60, loss: 0.0034412075765430927
step: 70, loss: 0.037211161106824875
step: 80, loss: 0.0029959590174257755
step: 90, loss: 0.05902664735913277
step: 100, loss: 0.030063331127166748
step: 110, loss: 9.068836516235024e-05
step: 120, loss: 0.0035377261228859425
step: 130, loss: 0.003749112831428647
step: 140, loss: 0.013221781700849533
step: 150, loss: 0.058508727699518204
step: 160, loss: 0.00131011672783643
step: 170, loss: 1.405538114340743e-05
step: 180, loss: 0.11198362708091736
step: 190, loss: 0.05052636191248894
step: 200, loss: 0.0001208093308378011
step: 210, loss: 0.005269904620945454
step: 220, loss: 0.1195625513792038
step: 230, loss: 0.027156613767147064
step: 240, loss: 0.006267709657549858
step: 250, loss: 0.14944639801979065
step: 260, loss: 0.09226348996162415
step: 270, loss: 0.04779379814863205
step: 280, loss: 0.017972229048609734
step: 290, loss: 0.06837357580661774
step: 300, loss: 0.055328916758298874
step: 310, loss: 0.00011104236909886822
step: 320, loss: 0.043370768427848816
step: 330, loss: 0.04565602168440819
step: 340, loss: 0.002561068395152688
step: 350, loss: 0.010680553503334522
step: 360, loss: 0.030581559985876083
step: 370, loss: 0.02803659252822399
step: 380, loss: 0.08560013771057129
step: 390, loss: 0.05376238375902176
step: 400, loss: 0.0076736402697861195
step: 410, loss: 0.060011379420757294
step: 420, loss: 0.0006767113809473813
step: 430, loss: 0.0003360314585734159
step: 440, loss: 0.019024403765797615
step: 450, loss: 0.025246120989322662
step: 460, loss: 0.012212744913995266
step: 470, loss: 0.044350117444992065
step: 480, loss: 0.02476051077246666
step: 490, loss: 0.01862010732293129
step: 500, loss: 0.022759493440389633
step: 510, loss: 0.00020869185391347855
step: 520, loss: 0.05025740712881088
step: 530, loss: 0.09704393148422241
step: 540, loss: 0.022073283791542053
step: 550, loss: 0.06024310737848282
step: 560, loss: 0.03494535759091377
step: 570, loss: 0.051963113248348236
step: 580, loss: 0.019956085830926895
step: 590, loss: 0.017947280779480934
step: 600, loss: 0.00348525308072567
step: 610, loss: 0.058774683624506
step: 620, loss: 0.03878406062722206
step: 630, loss: 0.02966153249144554
step: 640, loss: 0.08493510633707047
step: 650, loss: 0.038334716111421585
step: 660, loss: 0.14202173054218292
step: 670, loss: 0.023545026779174805
step: 680, loss: 0.041917815804481506
step: 690, loss: 0.01961241103708744
step: 700, loss: 0.00198991852812469
step: 710, loss: 0.07580142468214035
step: 720, loss: 0.04023654758930206
step: 730, loss: 0.06675063818693161
step: 740, loss: 0.03141691908240318
step: 750, loss: 0.07675328850746155
step: 760, loss: 0.004438161849975586
step: 770, loss: 0.1817978471517563
step: 780, loss: 0.08586723357439041
step: 790, loss: 0.004633767064660788
step: 800, loss: 0.08446136862039566
step: 810, loss: 0.16415321826934814
step: 820, loss: 0.10677427053451538
step: 830, loss: 0.1455252468585968
step: 840, loss: 0.06018934026360512
step: 850, loss: 0.00700202165171504
step: 860, loss: 0.05595897510647774
step: 870, loss: 0.06543222069740295
step: 880, loss: 0.023337770253419876
step: 890, loss: 0.008462857455015182
step: 900, loss: 0.04888591542840004
step: 910, loss: 0.1709083467721939
step: 920, loss: 8.081645501079038e-05
step: 930, loss: 0.06212546303868294
step: 940, loss: 0.03141162544488907
step: 950, loss: 0.0646190494298935
step: 960, loss: 0.05377614125609398
step: 970, loss: 0.059212666004896164
step: 980, loss: 0.017117725685238838
step: 990, loss: 0.00041585092549212277
step: 1000, loss: 0.03572101518511772
step: 1010, loss: 0.09380623698234558
step: 1020, loss: 0.06383240222930908
step: 1030, loss: 0.042162925004959106
step: 1040, loss: 0.00012478011194616556
step: 1050, loss: 0.002499643247574568
step: 1060, loss: 0.029528748244047165
step: 1070, loss: 0.04539503902196884
epoch 12: dev_f1=0.9367441860465117, f1=0.9337656322371468, best_f1=0.936150666054203
step: 0, loss: 0.07504715770483017
step: 10, loss: 0.02578211948275566
step: 20, loss: 0.04885454475879669
step: 30, loss: 0.08967936784029007
step: 40, loss: 0.03520524129271507
step: 50, loss: 0.0663263276219368
step: 60, loss: 9.359047544421628e-05
step: 70, loss: 0.009121347218751907
step: 80, loss: 0.0005957719986326993
step: 90, loss: 0.05627300217747688
step: 100, loss: 0.041406843811273575
step: 110, loss: 0.04684832692146301
step: 120, loss: 0.0634155198931694
step: 130, loss: 0.07928348332643509
step: 140, loss: 0.02056955359876156
step: 150, loss: 0.018467001616954803
step: 160, loss: 0.043942999094724655
step: 170, loss: 0.0209742933511734
step: 180, loss: 0.045611392706632614
step: 190, loss: 0.006067038979381323
step: 200, loss: 0.04681439697742462
step: 210, loss: 0.002243152353912592
step: 220, loss: 0.12014701962471008
step: 230, loss: 0.04947416111826897
step: 240, loss: 0.03517968952655792
step: 250, loss: 0.0041298274882137775
step: 260, loss: 0.04515573009848595
step: 270, loss: 0.00599463377147913
step: 280, loss: 0.011749650351703167
step: 290, loss: 0.019720736891031265
step: 300, loss: 0.06697071343660355
step: 310, loss: 0.1329934149980545
step: 320, loss: 0.026336267590522766
step: 330, loss: 0.003009167732670903
step: 340, loss: 0.046344492584466934
step: 350, loss: 0.15561233460903168
step: 360, loss: 0.00029911648016422987
step: 370, loss: 0.04663585126399994
step: 380, loss: 0.09142071008682251
step: 390, loss: 0.025968924164772034
step: 400, loss: 0.005583534948527813
step: 410, loss: 0.038514167070388794
step: 420, loss: 0.003121905028820038
step: 430, loss: 0.01640794798731804
step: 440, loss: 0.0012439544079825282
step: 450, loss: 0.004644816741347313
step: 460, loss: 0.06277530640363693
step: 470, loss: 0.05725853145122528
step: 480, loss: 0.0022775372490286827
step: 490, loss: 0.10092291235923767
step: 500, loss: 0.04488040879368782
step: 510, loss: 0.0005709351389668882
step: 520, loss: 9.85833175946027e-05
step: 530, loss: 0.0003460365696810186
step: 540, loss: 0.022807933390140533
step: 550, loss: 0.0402165949344635
step: 560, loss: 0.03268631547689438
step: 570, loss: 0.08791718631982803
step: 580, loss: 7.974692562129349e-05
step: 590, loss: 0.04183404520153999
step: 600, loss: 0.004702432546764612
step: 610, loss: 0.029305286705493927
step: 620, loss: 6.035720798536204e-05
step: 630, loss: 0.07542300969362259
step: 640, loss: 0.011954355984926224
step: 650, loss: 0.04339923337101936
step: 660, loss: 0.013668936677277088
step: 670, loss: 0.0042788442224264145
step: 680, loss: 0.010402482934296131
step: 690, loss: 0.02967396192252636
step: 700, loss: 0.10770200192928314
step: 710, loss: 0.0036731662694364786
step: 720, loss: 0.04976677894592285
step: 730, loss: 0.036051083356142044
step: 740, loss: 0.015115348622202873
step: 750, loss: 0.03946405649185181
step: 760, loss: 0.0016138522187247872
step: 770, loss: 0.04222361743450165
step: 780, loss: 0.022551605477929115
step: 790, loss: 0.02411629818379879
step: 800, loss: 0.02166607975959778
step: 810, loss: 0.026573199778795242
step: 820, loss: 0.000442912190919742
step: 830, loss: 0.002577589126303792
step: 840, loss: 0.0003393523511476815
step: 850, loss: 0.021353719756007195
step: 860, loss: 0.07045243680477142
step: 870, loss: 0.015585345216095448
step: 880, loss: 0.08032096177339554
step: 890, loss: 0.08452603220939636
step: 900, loss: 0.06185542792081833
step: 910, loss: 0.023767441511154175
step: 920, loss: 0.04878166317939758
step: 930, loss: 0.027586212381720543
step: 940, loss: 0.06819139420986176
step: 950, loss: 1.3276768186187837e-05
step: 960, loss: 0.0016078276094049215
step: 970, loss: 0.03252601996064186
step: 980, loss: 0.02320653386414051
step: 990, loss: 0.006094477139413357
step: 1000, loss: 0.04407290369272232
step: 1010, loss: 0.015402809716761112
step: 1020, loss: 0.022786037996411324
step: 1030, loss: 0.10376397520303726
step: 1040, loss: 0.10626532137393951
step: 1050, loss: 0.00019344718020875007
step: 1060, loss: 0.005722354631870985
step: 1070, loss: 0.028735211119055748
epoch 13: dev_f1=0.9404651162790698, f1=0.9340710004610421, best_f1=0.936150666054203
step: 0, loss: 0.014454682357609272
step: 10, loss: 0.05001585930585861
step: 20, loss: 0.00011653685942292213
step: 30, loss: 0.033298514783382416
step: 40, loss: 0.0008629567455500364
step: 50, loss: 0.0002339116035727784
step: 60, loss: 0.015649067237973213
step: 70, loss: 0.025635816156864166
step: 80, loss: 0.02202047035098076
step: 90, loss: 0.003187395865097642
step: 100, loss: 2.3446125851478428e-05
step: 110, loss: 5.332022192305885e-05
step: 120, loss: 0.004465440753847361
step: 130, loss: 0.00023425744439009577
step: 140, loss: 0.030279651284217834
step: 150, loss: 0.026944475248456
step: 160, loss: 0.06630877405405045
step: 170, loss: 0.028229014948010445
step: 180, loss: 0.01914721168577671
step: 190, loss: 0.00039187032962217927
step: 200, loss: 2.718576433835551e-05
step: 210, loss: 0.014159240759909153
step: 220, loss: 0.02266245149075985
step: 230, loss: 0.030463745817542076
step: 240, loss: 0.06900762766599655
step: 250, loss: 0.0006222345400601625
step: 260, loss: 0.03768805414438248
step: 270, loss: 0.0183242317289114
step: 280, loss: 0.03215378150343895
step: 290, loss: 0.015333451330661774
step: 300, loss: 0.0006166131934151053
step: 310, loss: 0.00311990175396204
step: 320, loss: 0.04659697413444519
step: 330, loss: 0.0001742122258292511
step: 340, loss: 0.12887948751449585
step: 350, loss: 0.03190905973315239
step: 360, loss: 0.02762555703520775
step: 370, loss: 0.03484417498111725
step: 380, loss: 0.0037814911920577288
step: 390, loss: 0.06043719872832298
step: 400, loss: 0.0011433321051299572
step: 410, loss: 0.009817267768085003
step: 420, loss: 0.05566834285855293
step: 430, loss: 5.66023045394104e-05
step: 440, loss: 0.10229049623012543
step: 450, loss: 0.08916886895895004
step: 460, loss: 0.0334075428545475
step: 470, loss: 0.006122644525021315
step: 480, loss: 0.022648977115750313
step: 490, loss: 0.021916726604104042
step: 500, loss: 0.07333242148160934
step: 510, loss: 0.00043055310379713774
step: 520, loss: 0.04850633069872856
step: 530, loss: 0.02681484818458557
step: 540, loss: 0.04781438410282135
step: 550, loss: 0.04112584516406059
step: 560, loss: 0.026778630912303925
step: 570, loss: 0.04779724404215813
step: 580, loss: 0.04946814104914665
step: 590, loss: 0.00022271732450462878
step: 600, loss: 0.016998395323753357
step: 610, loss: 0.06193426251411438
step: 620, loss: 0.41544538736343384
step: 630, loss: 0.012731272727251053
step: 640, loss: 0.02070692926645279
step: 650, loss: 0.04338080435991287
step: 660, loss: 0.03036290965974331
step: 670, loss: 0.0016180365346372128
step: 680, loss: 0.1261339783668518
step: 690, loss: 0.016121378168463707
step: 700, loss: 0.007556757889688015
step: 710, loss: 0.0008699088357388973
step: 720, loss: 0.04334786534309387
step: 730, loss: 0.08190733194351196
step: 740, loss: 0.0008691330440342426
step: 750, loss: 0.03135108947753906
step: 760, loss: 0.01151780690997839
step: 770, loss: 0.019090259447693825
step: 780, loss: 0.013333197683095932
step: 790, loss: 0.0005659240996465087
step: 800, loss: 0.018225915729999542
step: 810, loss: 0.00025381697923876345
step: 820, loss: 0.020258400589227676
step: 830, loss: 0.02106870897114277
step: 840, loss: 0.05987390875816345
step: 850, loss: 0.0013313281815499067
step: 860, loss: 0.002610101830214262
step: 870, loss: 0.028674134984612465
step: 880, loss: 0.001835293835029006
step: 890, loss: 0.053241606801748276
step: 900, loss: 0.00018320404342375696
step: 910, loss: 0.06288744509220123
step: 920, loss: 0.03655363991856575
step: 930, loss: 0.002280040644109249
step: 940, loss: 0.036583468317985535
step: 950, loss: 0.062466152012348175
step: 960, loss: 0.04022429883480072
step: 970, loss: 0.04742543026804924
step: 980, loss: 0.000968779728282243
step: 990, loss: 0.003240306628867984
step: 1000, loss: 0.05783650651574135
step: 1010, loss: 0.004611592274159193
step: 1020, loss: 0.07141723483800888
step: 1030, loss: 0.012532312422990799
step: 1040, loss: 0.014475896954536438
step: 1050, loss: 0.031416118144989014
step: 1060, loss: 0.07982676476240158
step: 1070, loss: 0.05099005252122879
epoch 14: dev_f1=0.9387186629526463, f1=0.9330275229357798, best_f1=0.936150666054203
step: 0, loss: 2.595296609797515e-05
step: 10, loss: 0.04446757584810257
step: 20, loss: 0.09270023554563522
step: 30, loss: 0.016735365614295006
step: 40, loss: 0.034193702042102814
step: 50, loss: 0.0008925743750296533
step: 60, loss: 0.020858075469732285
step: 70, loss: 0.0009871264919638634
step: 80, loss: 0.005711240693926811
step: 90, loss: 0.020330170169472694
step: 100, loss: 0.07471099495887756
step: 110, loss: 0.03679734095931053
step: 120, loss: 0.040145520120859146
step: 130, loss: 0.0008464536513201892
step: 140, loss: 0.0010940395295619965
step: 150, loss: 0.02830742672085762
step: 160, loss: 0.00020770906121470034
step: 170, loss: 4.7821107727941126e-05
step: 180, loss: 0.0010981835657730699
step: 190, loss: 0.020018594339489937
step: 200, loss: 0.006798159796744585
step: 210, loss: 0.0006143711507320404
step: 220, loss: 0.018055444583296776
step: 230, loss: 0.0033581028692424297
step: 240, loss: 0.03645366430282593
step: 250, loss: 0.00350265228189528
step: 260, loss: 9.000083082355559e-05
step: 270, loss: 0.04777899384498596
step: 280, loss: 0.014794846065342426
step: 290, loss: 0.011981784366071224
step: 300, loss: 0.013490656390786171
step: 310, loss: 0.06576655805110931
step: 320, loss: 0.018534282222390175
step: 330, loss: 0.07502534985542297
step: 340, loss: 0.0021272110752761364
step: 350, loss: 0.10122547298669815
step: 360, loss: 0.09865115582942963
step: 370, loss: 0.018381139263510704
step: 380, loss: 0.016331955790519714
step: 390, loss: 0.029912346974015236
step: 400, loss: 0.05597732216119766
step: 410, loss: 0.00820445828139782
step: 420, loss: 0.048742957413196564
step: 430, loss: 7.90278718341142e-05
step: 440, loss: 0.022664779797196388
step: 450, loss: 0.04602828621864319
step: 460, loss: 0.064456045627594
step: 470, loss: 0.013664470054209232
step: 480, loss: 0.01958659291267395
step: 490, loss: 0.004959580488502979
step: 500, loss: 0.01332144346088171
step: 510, loss: 0.023338064551353455
step: 520, loss: 0.0009367768070660532
step: 530, loss: 0.03421573340892792
step: 540, loss: 0.0007740894216112792
step: 550, loss: 0.024110902100801468
step: 560, loss: 0.023177247494459152
step: 570, loss: 0.03142012283205986
step: 580, loss: 0.0014239066513255239
step: 590, loss: 0.0354030467569828
step: 600, loss: 0.03299066051840782
step: 610, loss: 0.05479969456791878
step: 620, loss: 0.058016981929540634
step: 630, loss: 0.03112751431763172
step: 640, loss: 0.028959674760699272
step: 650, loss: 0.0727253407239914
step: 660, loss: 0.00039877326344139874
step: 670, loss: 0.04302908107638359
step: 680, loss: 0.029980333521962166
step: 690, loss: 0.006589099299162626
step: 700, loss: 0.021801309660077095
step: 710, loss: 0.0004650548507925123
step: 720, loss: 0.19608330726623535
step: 730, loss: 0.06152573972940445
step: 740, loss: 0.07028508186340332
step: 750, loss: 0.00045784900430589914
step: 760, loss: 0.045205578207969666
step: 770, loss: 0.00021469505736604333
step: 780, loss: 0.07237105816602707
step: 790, loss: 0.022945910692214966
step: 800, loss: 0.030285067856311798
step: 810, loss: 0.04282326623797417
step: 820, loss: 0.05826718360185623
step: 830, loss: 0.02687695436179638
step: 840, loss: 0.02749895118176937
step: 850, loss: 0.02713835798203945
step: 860, loss: 0.000210672224056907
step: 870, loss: 0.056209053844213486
step: 880, loss: 0.03583419322967529
step: 890, loss: 0.0194237120449543
step: 900, loss: 0.009466241113841534
step: 910, loss: 5.671580947819166e-05
step: 920, loss: 0.02549591474235058
step: 930, loss: 0.015318794175982475
step: 940, loss: 0.03822564706206322
step: 950, loss: 0.02348988875746727
step: 960, loss: 0.0004400412435643375
step: 970, loss: 0.10845977067947388
step: 980, loss: 0.00890390109270811
step: 990, loss: 0.026711082085967064
step: 1000, loss: 0.05599091202020645
step: 1010, loss: 0.018906133249402046
step: 1020, loss: 0.017969045788049698
step: 1030, loss: 0.026102503761649132
step: 1040, loss: 0.00414550956338644
step: 1050, loss: 0.04134835675358772
step: 1060, loss: 0.02240375056862831
step: 1070, loss: 0.00010326196206733584
epoch 15: dev_f1=0.9371158392434988, f1=0.9276315789473684, best_f1=0.936150666054203
step: 0, loss: 0.02607215940952301
step: 10, loss: 0.05573202669620514
step: 20, loss: 0.008895143866539001
step: 30, loss: 0.003927713260054588
step: 40, loss: 0.021963849663734436
step: 50, loss: 0.03266603872179985
step: 60, loss: 0.09419965744018555
step: 70, loss: 0.00021124762133695185
step: 80, loss: 0.021683089435100555
step: 90, loss: 0.048903755843639374
step: 100, loss: 0.04142414778470993
step: 110, loss: 2.6358657123637386e-05
step: 120, loss: 0.02398974634706974
step: 130, loss: 3.841162833850831e-05
step: 140, loss: 0.017751174047589302
step: 150, loss: 0.05250932276248932
step: 160, loss: 0.0031681759282946587
step: 170, loss: 0.01968972198665142
step: 180, loss: 9.784426947589964e-05
step: 190, loss: 0.042961861938238144
step: 200, loss: 0.036540351808071136
step: 210, loss: 0.0332554429769516
step: 220, loss: 0.019866444170475006
step: 230, loss: 0.041884712874889374
step: 240, loss: 0.030178992077708244
step: 250, loss: 0.06338614970445633
step: 260, loss: 0.021689336746931076
step: 270, loss: 0.027963196858763695
step: 280, loss: 0.012514336965978146
step: 290, loss: 0.00019585288828238845
step: 300, loss: 0.030353639274835587
step: 310, loss: 0.05034153535962105
step: 320, loss: 0.03587745130062103
step: 330, loss: 0.022978398948907852
step: 340, loss: 0.019889365881681442
step: 350, loss: 0.01645715720951557
step: 360, loss: 0.032122496515512466
step: 370, loss: 0.013533554039895535
step: 380, loss: 0.023549210280179977
step: 390, loss: 0.017466403543949127
step: 400, loss: 0.025928348302841187
step: 410, loss: 0.04060717299580574
step: 420, loss: 0.027988310903310776
step: 430, loss: 0.048243094235658646
step: 440, loss: 7.912307773949578e-05
step: 450, loss: 0.010899608954787254
step: 460, loss: 0.038670480251312256
step: 470, loss: 0.022530891001224518
step: 480, loss: 9.982852498069406e-05
step: 490, loss: 0.019877547398209572
step: 500, loss: 0.00011452358739916235
step: 510, loss: 0.019436826929450035
step: 520, loss: 0.00016460927145089954
step: 530, loss: 0.00485938461497426
step: 540, loss: 0.07636009156703949
step: 550, loss: 0.08588533103466034
step: 560, loss: 0.0021697976626455784
step: 570, loss: 0.085823193192482
step: 580, loss: 0.03636414557695389
step: 590, loss: 0.09716972708702087
step: 600, loss: 0.021822385489940643
step: 610, loss: 0.0016457714373245835
step: 620, loss: 0.001957228407263756
step: 630, loss: 0.00796052161604166
step: 640, loss: 0.006852305959910154
step: 650, loss: 0.03726283460855484
step: 660, loss: 0.0357612781226635
step: 670, loss: 0.03804199770092964
step: 680, loss: 0.0032222256995737553
step: 690, loss: 0.022578900679945946
step: 700, loss: 0.0016379989683628082
step: 710, loss: 0.0020588792394846678
step: 720, loss: 0.06270967423915863
step: 730, loss: 0.0005179993459023535
step: 740, loss: 0.053767018020153046
step: 750, loss: 0.042498376220464706
step: 760, loss: 0.027896488085389137
step: 770, loss: 0.09864131361246109
step: 780, loss: 0.09863327443599701
step: 790, loss: 0.00013960804790258408
step: 800, loss: 0.02465212531387806
step: 810, loss: 0.021572280675172806
step: 820, loss: 0.004759248346090317
step: 830, loss: 0.0001246215106220916
step: 840, loss: 0.005679744761437178
step: 850, loss: 0.012520840391516685
step: 860, loss: 0.04303780943155289
step: 870, loss: 0.02235635183751583
step: 880, loss: 6.478745490312576e-05
step: 890, loss: 0.003812090726569295
step: 900, loss: 0.03587630018591881
step: 910, loss: 4.168035593465902e-05
step: 920, loss: 0.04993954300880432
step: 930, loss: 0.035961467772722244
step: 940, loss: 0.036115989089012146
step: 950, loss: 0.001637124689295888
step: 960, loss: 0.015207451768219471
step: 970, loss: 0.08155500143766403
step: 980, loss: 0.06027549132704735
step: 990, loss: 0.040869276970624924
step: 1000, loss: 0.07897629588842392
step: 1010, loss: 0.06837190687656403
step: 1020, loss: 0.0007525659166276455
step: 1030, loss: 0.027229182422161102
step: 1040, loss: 0.04244612529873848
step: 1050, loss: 0.0005761840147897601
step: 1060, loss: 0.04163796454668045
step: 1070, loss: 6.368188769556582e-05
epoch 16: dev_f1=0.9367924528301887, f1=0.9314045730284647, best_f1=0.936150666054203
step: 0, loss: 0.04712287709116936
step: 10, loss: 0.04435962066054344
step: 20, loss: 0.03692524880170822
step: 30, loss: 0.004295578226447105
step: 40, loss: 0.022174807265400887
step: 50, loss: 0.0015783837297931314
step: 60, loss: 0.02297207899391651
step: 70, loss: 0.036795467138290405
step: 80, loss: 0.017125774174928665
step: 90, loss: 0.06257563084363937
step: 100, loss: 0.0008678737794980407
step: 110, loss: 1.7922020560945384e-05
step: 120, loss: 0.019499218091368675
step: 130, loss: 0.03273998573422432
step: 140, loss: 0.0003229720750823617
step: 150, loss: 6.911694799782708e-05
step: 160, loss: 0.051354940980672836
step: 170, loss: 0.03572551906108856
step: 180, loss: 0.01913674734532833
step: 190, loss: 6.136592128314078e-05
step: 200, loss: 0.00011698079470079392
step: 210, loss: 0.023388581350445747
step: 220, loss: 0.010831023566424847
step: 230, loss: 0.017155231907963753
step: 240, loss: 0.04819844290614128
step: 250, loss: 0.03794431313872337
step: 260, loss: 0.038483764976263046
step: 270, loss: 0.04463186115026474
step: 280, loss: 0.023667089641094208
step: 290, loss: 0.027150729671120644
step: 300, loss: 0.07891469448804855
step: 310, loss: 0.060947347432374954
step: 320, loss: 0.026085268706083298
step: 330, loss: 0.027060616761446
step: 340, loss: 1.9911125491489656e-05
step: 350, loss: 0.06167024374008179
step: 360, loss: 6.185934762470424e-05
step: 370, loss: 0.04220234975218773
step: 380, loss: 0.00014587129408027977
step: 390, loss: 0.02392786182463169
step: 400, loss: 0.06647539883852005
step: 410, loss: 0.019149623811244965
step: 420, loss: 0.012370886281132698
step: 430, loss: 7.407787052216008e-05
step: 440, loss: 0.06743869185447693
step: 450, loss: 0.001125263050198555
step: 460, loss: 0.048262517899274826
step: 470, loss: 0.02475445158779621
step: 480, loss: 0.0475398451089859
step: 490, loss: 0.015751808881759644
step: 500, loss: 0.0006445301114581525
step: 510, loss: 0.045532286167144775
step: 520, loss: 0.049904096871614456
step: 530, loss: 0.023682964965701103
step: 540, loss: 0.03230002522468567
step: 550, loss: 0.0027109908405691385
step: 560, loss: 0.03789674863219261
step: 570, loss: 0.059974730014801025
step: 580, loss: 0.007252671755850315
step: 590, loss: 0.0491204634308815
step: 600, loss: 0.04646693170070648
step: 610, loss: 0.01881713606417179
step: 620, loss: 0.01387985609471798
step: 630, loss: 0.015502563677728176
step: 640, loss: 0.038053903728723526
step: 650, loss: 2.0507157387328334e-05
step: 660, loss: 0.0022670673206448555
step: 670, loss: 0.023083029314875603
step: 680, loss: 0.020844271406531334
step: 690, loss: 0.0001924109528772533
step: 700, loss: 7.005822408245876e-05
step: 710, loss: 0.007220827508717775
step: 720, loss: 0.07109794020652771
step: 730, loss: 0.019057391211390495
step: 740, loss: 7.739577267784625e-05
step: 750, loss: 0.05711039528250694
step: 760, loss: 0.015475161373615265
step: 770, loss: 0.039554063230752945
step: 780, loss: 0.0017831753939390182
step: 790, loss: 0.060118094086647034
step: 800, loss: 0.00048175686970353127
step: 810, loss: 2.277575185871683e-05
step: 820, loss: 0.00013278507685754448
step: 830, loss: 0.03437976911664009
step: 840, loss: 0.022020483389496803
step: 850, loss: 4.234195876051672e-05
step: 860, loss: 0.004024645313620567
step: 870, loss: 3.881063821609132e-05
step: 880, loss: 0.011480764485895634
step: 890, loss: 7.539259968325496e-05
step: 900, loss: 0.051789287477731705
step: 910, loss: 2.897259037126787e-05
step: 920, loss: 0.01971912570297718
step: 930, loss: 0.028272641822695732
step: 940, loss: 0.058481890708208084
step: 950, loss: 0.00013178463268559426
step: 960, loss: 0.02003440260887146
step: 970, loss: 0.06981842964887619
step: 980, loss: 0.045759521424770355
step: 990, loss: 0.04443219304084778
step: 1000, loss: 0.017483394593000412
step: 1010, loss: 0.0931195467710495
step: 1020, loss: 0.0001219647892867215
step: 1030, loss: 0.014367320574820042
step: 1040, loss: 0.01973802037537098
step: 1050, loss: 0.04083272069692612
step: 1060, loss: 0.03789885342121124
step: 1070, loss: 0.0010887847747653723
epoch 17: dev_f1=0.9369786839666358, f1=0.9305747126436781, best_f1=0.936150666054203
step: 0, loss: 0.0038889579009264708
step: 10, loss: 0.06952708959579468
step: 20, loss: 0.007327157072722912
step: 30, loss: 0.018892941996455193
step: 40, loss: 0.013304801657795906
step: 50, loss: 0.07162132859230042
step: 60, loss: 0.012064040638506413
step: 70, loss: 0.040533483028411865
step: 80, loss: 0.019475821405649185
step: 90, loss: 0.026327993720769882
step: 100, loss: 0.049868643283843994
step: 110, loss: 0.021352270618081093
step: 120, loss: 4.836642983718775e-05
step: 130, loss: 0.03784669563174248
step: 140, loss: 0.02706262841820717
step: 150, loss: 0.0005316334427334368
step: 160, loss: 5.385441909311339e-05
step: 170, loss: 0.08040446043014526
step: 180, loss: 1.198784048028756e-05
step: 190, loss: 0.029489921405911446
step: 200, loss: 0.0650930106639862
step: 210, loss: 0.02149960584938526
step: 220, loss: 2.2570682631339878e-05
step: 230, loss: 0.03411036357283592
step: 240, loss: 0.03091464564204216
step: 250, loss: 0.0013225156581029296
step: 260, loss: 3.398568514967337e-05
step: 270, loss: 0.01667354628443718
step: 280, loss: 0.024121712893247604
step: 290, loss: 0.06430862098932266
step: 300, loss: 0.001522389124147594
step: 310, loss: 0.022528305649757385
step: 320, loss: 0.04841264709830284
step: 330, loss: 2.339338061574381e-05
step: 340, loss: 0.0474480576813221
step: 350, loss: 0.00018629201804287732
step: 360, loss: 0.00032297693542204797
step: 370, loss: 0.017115535214543343
step: 380, loss: 0.029210573062300682
step: 390, loss: 0.024898355826735497
step: 400, loss: 0.05286962538957596
step: 410, loss: 0.01433379203081131
step: 420, loss: 0.04035279154777527
step: 430, loss: 0.04089932143688202
step: 440, loss: 1.8562477634986863e-05
step: 450, loss: 0.019443631172180176
step: 460, loss: 0.020653055980801582
step: 470, loss: 0.016546230763196945
step: 480, loss: 5.763549415860325e-05
step: 490, loss: 0.06436245143413544
step: 500, loss: 0.04025478661060333
step: 510, loss: 0.04707498848438263
step: 520, loss: 0.060849059373140335
step: 530, loss: 0.06506729125976562
step: 540, loss: 0.017714576795697212
step: 550, loss: 0.03314603492617607
step: 560, loss: 0.053743116557598114
step: 570, loss: 0.0029932630714029074
step: 580, loss: 0.02252996154129505
step: 590, loss: 0.009267782792448997
step: 600, loss: 0.029461275786161423
step: 610, loss: 0.00913009699434042
step: 620, loss: 0.019191155210137367
step: 630, loss: 0.01670803129673004
step: 640, loss: 0.02805049903690815
step: 650, loss: 0.044586218893527985
step: 660, loss: 0.027308322489261627
step: 670, loss: 4.328892464400269e-05
step: 680, loss: 6.997612945269793e-05
step: 690, loss: 0.018863067030906677
step: 700, loss: 0.06126838177442551
step: 710, loss: 0.02265341579914093
step: 720, loss: 0.022364363074302673
step: 730, loss: 0.04948285222053528
step: 740, loss: 0.018822479993104935
step: 750, loss: 0.025372732430696487
step: 760, loss: 0.000692445901222527
step: 770, loss: 0.024009257555007935
step: 780, loss: 0.0012776667717844248
step: 790, loss: 0.020063864067196846
step: 800, loss: 0.021018357947468758
step: 810, loss: 0.062334783375263214
step: 820, loss: 4.656312012230046e-05
step: 830, loss: 0.00026432579034008086
step: 840, loss: 0.009584990330040455
step: 850, loss: 0.026752715930342674
step: 860, loss: 0.06312071532011032
step: 870, loss: 0.02296316809952259
step: 880, loss: 3.98858537664637e-05
step: 890, loss: 0.00016389253141824156
step: 900, loss: 0.009280495345592499
step: 910, loss: 0.014944893307983875
step: 920, loss: 0.03215041384100914
step: 930, loss: 0.0357181541621685
step: 940, loss: 0.0005860166274942458
step: 950, loss: 0.02330288477241993
step: 960, loss: 0.026442380622029305
step: 970, loss: 0.023250864818692207
step: 980, loss: 0.04550343006849289
step: 990, loss: 0.01595343090593815
step: 1000, loss: 0.047164224088191986
step: 1010, loss: 0.01337166503071785
step: 1020, loss: 0.0004630016628652811
step: 1030, loss: 0.03231522813439369
step: 1040, loss: 0.030524540692567825
step: 1050, loss: 0.08733750134706497
step: 1060, loss: 0.04492506384849548
step: 1070, loss: 0.02349545620381832
epoch 18: dev_f1=0.9370300751879698, f1=0.9293023255813954, best_f1=0.936150666054203
step: 0, loss: 0.011091485619544983
step: 10, loss: 0.05095091089606285
step: 20, loss: 0.0006037844577804208
step: 30, loss: 0.0379924476146698
step: 40, loss: 0.061056409031152725
step: 50, loss: 0.01164224836975336
step: 60, loss: 0.022625960409641266
step: 70, loss: 0.04484148696064949
step: 80, loss: 0.014684862457215786
step: 90, loss: 3.69246699847281e-05
step: 100, loss: 0.058369994163513184
step: 110, loss: 0.036767564713954926
step: 120, loss: 2.98407394438982e-05
step: 130, loss: 0.01923574134707451
step: 140, loss: 0.01490292139351368
step: 150, loss: 0.04311716556549072
step: 160, loss: 0.0002505835145711899
step: 170, loss: 0.0005319352494552732
step: 180, loss: 0.00530252605676651
step: 190, loss: 0.03710390254855156
step: 200, loss: 0.00046161303180269897
step: 210, loss: 0.023340703919529915
step: 220, loss: 0.00037965504452586174
step: 230, loss: 0.0476449579000473
step: 240, loss: 0.000977997900918126
step: 250, loss: 0.034842945635318756
step: 260, loss: 0.0200046319514513
step: 270, loss: 0.03865237906575203
step: 280, loss: 0.06070012226700783
step: 290, loss: 0.09755049645900726
step: 300, loss: 3.161399581586011e-05
step: 310, loss: 0.018216129392385483
step: 320, loss: 0.027269717305898666
step: 330, loss: 0.014910350553691387
step: 340, loss: 0.01954490691423416
step: 350, loss: 0.026582257822155952
step: 360, loss: 0.01753174513578415
step: 370, loss: 0.04629187285900116
step: 380, loss: 0.0002690556866582483
step: 390, loss: 1.871879430836998e-05
step: 400, loss: 5.361976218409836e-05
step: 410, loss: 0.0036526615731418133
step: 420, loss: 0.035893384367227554
step: 430, loss: 1.3593415133072995e-05
step: 440, loss: 0.02748447097837925
step: 450, loss: 0.007395975291728973
step: 460, loss: 0.055094484239816666
step: 470, loss: 7.683565490879118e-05
step: 480, loss: 0.05053205415606499
step: 490, loss: 0.00550821190699935
step: 500, loss: 0.0006294246995821595
step: 510, loss: 0.02753015235066414
step: 520, loss: 2.5166422346956097e-05
step: 530, loss: 0.0188060961663723
step: 540, loss: 0.04389166459441185
step: 550, loss: 0.026613423600792885
step: 560, loss: 0.020273353904485703
step: 570, loss: 0.03008558414876461
step: 580, loss: 0.02243305929005146
step: 590, loss: 0.020857607945799828
step: 600, loss: 0.01634536311030388
step: 610, loss: 0.055432334542274475
step: 620, loss: 7.349008228629827e-05
step: 630, loss: 0.024681301787495613
step: 640, loss: 0.03927227109670639
step: 650, loss: 0.03066621534526348
step: 660, loss: 0.00027212683926336467
step: 670, loss: 0.05650719627737999
step: 680, loss: 0.0006903655594214797
step: 690, loss: 0.05044056847691536
step: 700, loss: 0.0003940488095395267
step: 710, loss: 0.02466403692960739
step: 720, loss: 0.055460840463638306
step: 730, loss: 0.02464013174176216
step: 740, loss: 0.027331169694662094
step: 750, loss: 0.11704602837562561
step: 760, loss: 0.019931897521018982
step: 770, loss: 0.09691334515810013
step: 780, loss: 0.00018965560593642294
step: 790, loss: 0.023440144956111908
step: 800, loss: 0.0015475436812266707
step: 810, loss: 0.013476716354489326
step: 820, loss: 0.003528912551701069
step: 830, loss: 0.02929138019680977
step: 840, loss: 1.7381602447130717e-05
step: 850, loss: 0.07579829543828964
step: 860, loss: 0.03533027321100235
step: 870, loss: 6.592988938791677e-05
step: 880, loss: 0.000351999478880316
step: 890, loss: 0.06202199310064316
step: 900, loss: 0.017299557104706764
step: 910, loss: 2.226494689239189e-05
step: 920, loss: 0.08623962849378586
step: 930, loss: 0.019913898780941963
step: 940, loss: 0.024908216670155525
step: 950, loss: 0.0006811055354773998
step: 960, loss: 3.31598348566331e-05
step: 970, loss: 0.02422940731048584
step: 980, loss: 0.00010269818449160084
step: 990, loss: 0.015176844783127308
step: 1000, loss: 0.014920477755367756
step: 1010, loss: 0.00010129363363375887
step: 1020, loss: 5.6386928918072954e-05
step: 1030, loss: 0.02103656344115734
step: 1040, loss: 0.04778972640633583
step: 1050, loss: 8.830660954117775e-05
step: 1060, loss: 0.02700606919825077
step: 1070, loss: 1.266583421966061e-05
epoch 19: dev_f1=0.9342723004694835, f1=0.9291994447015272, best_f1=0.936150666054203
step: 0, loss: 0.019467676058411598
step: 10, loss: 0.0017735277069732547
step: 20, loss: 0.02151716873049736
step: 30, loss: 0.06561874598264694
step: 40, loss: 8.646984497318044e-05
step: 50, loss: 0.04366561770439148
step: 60, loss: 1.1231639291509055e-05
step: 70, loss: 0.05702757090330124
step: 80, loss: 1.7467296856921166e-05
step: 90, loss: 0.020286371931433678
step: 100, loss: 4.2197447328362614e-05
step: 110, loss: 0.025361789390444756
step: 120, loss: 0.04237335920333862
step: 130, loss: 0.03590726479887962
step: 140, loss: 1.229706595040625e-05
step: 150, loss: 0.01998217962682247
step: 160, loss: 0.0003539323515724391
step: 170, loss: 0.0769127756357193
step: 180, loss: 0.045789603143930435
step: 190, loss: 0.034470848739147186
step: 200, loss: 0.03849828615784645
step: 210, loss: 0.0385441817343235
step: 220, loss: 0.00012795644579455256
step: 230, loss: 0.06213311105966568
step: 240, loss: 0.03883819654583931
step: 250, loss: 0.0002465730649419129
step: 260, loss: 0.001469373470172286
step: 270, loss: 0.014382965862751007
step: 280, loss: 0.013047137297689915
step: 290, loss: 0.04337909072637558
step: 300, loss: 0.0028385594487190247
step: 310, loss: 0.00017325104272458702
step: 320, loss: 0.03684109449386597
step: 330, loss: 0.0447111539542675
step: 340, loss: 0.050637416541576385
step: 350, loss: 0.048235196620225906
step: 360, loss: 2.4216331439674832e-05
step: 370, loss: 3.290000313427299e-05
step: 380, loss: 0.03807729482650757
step: 390, loss: 5.398752909968607e-05
step: 400, loss: 0.001621549716219306
step: 410, loss: 0.0604398250579834
step: 420, loss: 2.114040034939535e-05
step: 430, loss: 5.6672670325497165e-05
step: 440, loss: 0.05464189872145653
step: 450, loss: 0.03985864669084549
step: 460, loss: 0.01866120658814907
step: 470, loss: 0.0045372191816568375
step: 480, loss: 0.14241455495357513
step: 490, loss: 0.019147703424096107
step: 500, loss: 4.6736764488741755e-05
step: 510, loss: 0.00016378037980757654
step: 520, loss: 0.019336534664034843
step: 530, loss: 0.026888085529208183
step: 540, loss: 0.05169934779405594
step: 550, loss: 0.026320789009332657
step: 560, loss: 0.030583254992961884
step: 570, loss: 0.017651425674557686
step: 580, loss: 0.00015412452921736985
step: 590, loss: 0.03428258001804352
step: 600, loss: 3.6679834011010826e-05
step: 610, loss: 0.0002241272886749357
step: 620, loss: 0.021745536476373672
step: 630, loss: 0.025998005643486977
step: 640, loss: 6.536384898936376e-05
step: 650, loss: 0.03623732551932335
step: 660, loss: 0.07977982610464096
step: 670, loss: 0.01317591778934002
step: 680, loss: 0.0515676811337471
step: 690, loss: 0.04426945000886917
step: 700, loss: 0.0009230219293385744
step: 710, loss: 1.8741331587079912e-05
step: 720, loss: 8.02367358119227e-05
step: 730, loss: 0.025434404611587524
step: 740, loss: 0.04525475576519966
step: 750, loss: 2.3742361008771695e-05
step: 760, loss: 0.0001240362471435219
step: 770, loss: 2.574368227215018e-05
step: 780, loss: 0.0189365204423666
step: 790, loss: 0.04222491383552551
step: 800, loss: 0.04843418672680855
step: 810, loss: 0.03747148439288139
step: 820, loss: 0.026071669533848763
step: 830, loss: 0.025400346145033836
step: 840, loss: 0.09016790241003036
step: 850, loss: 2.0305682483012788e-05
step: 860, loss: 0.0002732544671744108
step: 870, loss: 2.1255189494695514e-05
step: 880, loss: 4.45531950390432e-05
step: 890, loss: 0.0065713259391486645
step: 900, loss: 0.03218052536249161
step: 910, loss: 0.02217235043644905
step: 920, loss: 1.782863910193555e-05
step: 930, loss: 0.041669659316539764
step: 940, loss: 0.06181417405605316
step: 950, loss: 0.019591962918639183
step: 960, loss: 0.037872131913900375
step: 970, loss: 0.0004831722762901336
step: 980, loss: 0.016421707347035408
step: 990, loss: 0.021528426557779312
step: 1000, loss: 6.499198207166046e-05
step: 1010, loss: 0.00012238819908816367
step: 1020, loss: 0.024084076285362244
step: 1030, loss: 0.08095166832208633
step: 1040, loss: 0.021902503445744514
step: 1050, loss: 0.036791764199733734
step: 1060, loss: 0.03811296448111534
step: 1070, loss: 0.02129027247428894
epoch 20: dev_f1=0.9332706766917293, f1=0.9317865429234339, best_f1=0.936150666054203
