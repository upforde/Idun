cuda
Device: cuda
step: 0, loss: 0.5994255542755127
step: 10, loss: 0.39829716086387634
step: 20, loss: 0.37017565965652466
step: 30, loss: 0.38532912731170654
step: 40, loss: 0.1765175312757492
step: 50, loss: 0.4902999997138977
step: 60, loss: 0.20624932646751404
step: 70, loss: 0.2515835762023926
step: 80, loss: 0.1072438657283783
step: 90, loss: 0.21848633885383606
step: 100, loss: 0.2730652987957001
step: 110, loss: 0.14571568369865417
step: 120, loss: 0.3688170313835144
step: 130, loss: 0.2708188593387604
step: 140, loss: 0.3543207347393036
step: 150, loss: 0.1218273937702179
step: 160, loss: 0.22247262299060822
step: 170, loss: 0.19784338772296906
step: 180, loss: 0.09736748784780502
step: 190, loss: 0.2578127086162567
step: 200, loss: 0.13331209123134613
step: 210, loss: 0.07926654815673828
step: 220, loss: 0.06403084844350815
step: 230, loss: 0.13228008151054382
step: 240, loss: 0.2651170492172241
step: 250, loss: 0.2893432378768921
step: 260, loss: 0.48847413063049316
step: 270, loss: 0.22303858399391174
step: 280, loss: 0.19475337862968445
step: 290, loss: 0.1483195722103119
step: 300, loss: 0.14308124780654907
step: 310, loss: 0.07608190178871155
step: 320, loss: 0.4134957790374756
step: 330, loss: 0.09133186936378479
step: 340, loss: 0.1544918566942215
step: 350, loss: 0.2275354266166687
step: 360, loss: 0.10840471088886261
step: 370, loss: 0.19389906525611877
step: 380, loss: 0.10505333542823792
step: 390, loss: 0.22509481012821198
step: 400, loss: 0.08444003015756607
step: 410, loss: 0.16729611158370972
step: 420, loss: 0.08646850287914276
step: 430, loss: 0.3190116286277771
step: 440, loss: 0.053098712116479874
step: 450, loss: 0.21918466687202454
step: 460, loss: 0.1663953959941864
step: 470, loss: 0.11187758296728134
step: 480, loss: 0.10167106240987778
step: 490, loss: 0.05566749721765518
step: 500, loss: 0.14581339061260223
step: 510, loss: 0.05182616040110588
step: 520, loss: 0.018604926764965057
step: 530, loss: 0.1087152287364006
step: 540, loss: 0.22006598114967346
step: 550, loss: 0.18231427669525146
step: 560, loss: 0.2733229100704193
step: 570, loss: 0.08825983852148056
step: 580, loss: 0.11410301178693771
step: 590, loss: 0.05798175558447838
step: 600, loss: 0.10140006989240646
step: 610, loss: 0.15257865190505981
step: 620, loss: 0.14528140425682068
step: 630, loss: 0.019694635644555092
step: 640, loss: 0.10165119916200638
step: 650, loss: 0.18656674027442932
step: 660, loss: 0.15009300410747528
step: 670, loss: 0.1508151888847351
step: 680, loss: 0.05865338444709778
step: 690, loss: 0.23109352588653564
step: 700, loss: 0.1205466091632843
step: 710, loss: 0.14919161796569824
step: 720, loss: 0.10332684218883514
step: 730, loss: 0.12284006178379059
step: 740, loss: 0.19152918457984924
step: 750, loss: 0.0700497105717659
step: 760, loss: 0.1381135731935501
step: 770, loss: 0.21432149410247803
step: 780, loss: 0.23393988609313965
step: 790, loss: 0.13653072714805603
step: 800, loss: 0.20800410211086273
step: 810, loss: 0.18920095264911652
step: 820, loss: 0.3167550563812256
step: 830, loss: 0.17415611445903778
step: 840, loss: 0.09525955468416214
step: 850, loss: 0.15543779730796814
step: 860, loss: 0.058110032230615616
step: 870, loss: 0.09654464572668076
step: 880, loss: 0.09139818698167801
step: 890, loss: 0.17057748138904572
step: 900, loss: 0.21005167067050934
step: 910, loss: 0.11337162554264069
step: 920, loss: 0.12909172475337982
step: 930, loss: 0.09540950506925583
step: 940, loss: 0.2077912837266922
step: 950, loss: 0.03136644884943962
step: 960, loss: 0.14929011464118958
step: 970, loss: 0.07314474880695343
step: 980, loss: 0.04488760605454445
step: 990, loss: 0.11944898962974548
step: 1000, loss: 0.16367657482624054
step: 1010, loss: 0.07949855178594589
step: 1020, loss: 0.014142480678856373
step: 1030, loss: 0.1035294458270073
step: 1040, loss: 0.06529920548200607
step: 1050, loss: 0.11554694920778275
step: 1060, loss: 0.22569309175014496
step: 1070, loss: 0.1242920309305191
epoch 1: dev_f1=0.9246704331450095, f1=0.9141248240262787, best_f1=0.9141248240262787
step: 0, loss: 0.059011273086071014
step: 10, loss: 0.0701681599020958
step: 20, loss: 0.10183440148830414
step: 30, loss: 0.06171629950404167
step: 40, loss: 0.008668070659041405
step: 50, loss: 0.12469307333230972
step: 60, loss: 0.21724186837673187
step: 70, loss: 0.17424622178077698
step: 80, loss: 0.06382861733436584
step: 90, loss: 0.10532169789075851
step: 100, loss: 0.08058004826307297
step: 110, loss: 0.025566110387444496
step: 120, loss: 0.11039295047521591
step: 130, loss: 0.1273917406797409
step: 140, loss: 0.026356184855103493
step: 150, loss: 0.17751054465770721
step: 160, loss: 0.08547507971525192
step: 170, loss: 0.06744413822889328
step: 180, loss: 0.1723950207233429
step: 190, loss: 0.04419097676873207
step: 200, loss: 0.13911256194114685
step: 210, loss: 0.3052207827568054
step: 220, loss: 0.045263975858688354
step: 230, loss: 0.124275803565979
step: 240, loss: 0.1957821547985077
step: 250, loss: 0.14253084361553192
step: 260, loss: 0.11986922472715378
step: 270, loss: 0.037593964487314224
step: 280, loss: 0.07738470286130905
step: 290, loss: 0.10435523837804794
step: 300, loss: 0.029424402862787247
step: 310, loss: 0.14240789413452148
step: 320, loss: 0.06342018395662308
step: 330, loss: 0.07591434568166733
step: 340, loss: 0.1005917638540268
step: 350, loss: 0.0343954972922802
step: 360, loss: 0.12202514708042145
step: 370, loss: 0.10887628048658371
step: 380, loss: 0.09774565696716309
step: 390, loss: 0.13139283657073975
step: 400, loss: 0.1538325697183609
step: 410, loss: 0.15660995244979858
step: 420, loss: 0.07207153737545013
step: 430, loss: 0.08478216826915741
step: 440, loss: 0.18653979897499084
step: 450, loss: 0.03967754542827606
step: 460, loss: 0.129115030169487
step: 470, loss: 0.03847996145486832
step: 480, loss: 0.0436529815196991
step: 490, loss: 0.04204750433564186
step: 500, loss: 0.025383690372109413
step: 510, loss: 0.2139763981103897
step: 520, loss: 0.03044634498655796
step: 530, loss: 0.10297342389822006
step: 540, loss: 0.1710367500782013
step: 550, loss: 0.1474250704050064
step: 560, loss: 0.20317693054676056
step: 570, loss: 0.08186758309602737
step: 580, loss: 0.05989408493041992
step: 590, loss: 0.043997637927532196
step: 600, loss: 0.06524144858121872
step: 610, loss: 0.13307666778564453
step: 620, loss: 0.02058427967131138
step: 630, loss: 0.2542303800582886
step: 640, loss: 0.10063621401786804
step: 650, loss: 0.1401878446340561
step: 660, loss: 0.09356015175580978
step: 670, loss: 0.12616190314292908
step: 680, loss: 0.14084823429584503
step: 690, loss: 0.06975723803043365
step: 700, loss: 0.12515029311180115
step: 710, loss: 0.15169528126716614
step: 720, loss: 0.12662765383720398
step: 730, loss: 0.03769589960575104
step: 740, loss: 0.14644962549209595
step: 750, loss: 0.03173786774277687
step: 760, loss: 0.12552118301391602
step: 770, loss: 0.06017984077334404
step: 780, loss: 0.18979518115520477
step: 790, loss: 0.0593365915119648
step: 800, loss: 0.1538737267255783
step: 810, loss: 0.08158540725708008
step: 820, loss: 0.1827242374420166
step: 830, loss: 0.013732509687542915
step: 840, loss: 0.09575723856687546
step: 850, loss: 0.19076623022556305
step: 860, loss: 0.09573174268007278
step: 870, loss: 0.020838551223278046
step: 880, loss: 0.038852229714393616
step: 890, loss: 0.010536443442106247
step: 900, loss: 0.20735692977905273
step: 910, loss: 0.18490217626094818
step: 920, loss: 0.08601155132055283
step: 930, loss: 0.021955208852887154
step: 940, loss: 0.10987623035907745
step: 950, loss: 0.008280313573777676
step: 960, loss: 0.05757223814725876
step: 970, loss: 0.03897806629538536
step: 980, loss: 0.09737805277109146
step: 990, loss: 0.16172990202903748
step: 1000, loss: 0.029981140047311783
step: 1010, loss: 0.02433668076992035
step: 1020, loss: 0.05786238983273506
step: 1030, loss: 0.12339401245117188
step: 1040, loss: 0.09981942921876907
step: 1050, loss: 0.07324711978435516
step: 1060, loss: 0.1088557094335556
step: 1070, loss: 0.15132810175418854
epoch 2: dev_f1=0.9203619909502263, f1=0.905829596412556, best_f1=0.9141248240262787
step: 0, loss: 0.06068113073706627
step: 10, loss: 0.07640544325113297
step: 20, loss: 0.08499391376972198
step: 30, loss: 0.12424544990062714
step: 40, loss: 0.1596926748752594
step: 50, loss: 0.03717723488807678
step: 60, loss: 0.040135107934474945
step: 70, loss: 0.14180885255336761
step: 80, loss: 0.017199750989675522
step: 90, loss: 0.026472032070159912
step: 100, loss: 0.032831620424985886
step: 110, loss: 0.05395929887890816
step: 120, loss: 0.013756828382611275
step: 130, loss: 0.006828583776950836
step: 140, loss: 0.006070428993552923
step: 150, loss: 0.07244323939085007
step: 160, loss: 0.08192948251962662
step: 170, loss: 0.025382356718182564
step: 180, loss: 0.0853046253323555
step: 190, loss: 0.049434177577495575
step: 200, loss: 0.04297521337866783
step: 210, loss: 0.08707184344530106
step: 220, loss: 0.042428646236658096
step: 230, loss: 0.09609349817037582
step: 240, loss: 0.06451836228370667
step: 250, loss: 0.13707445561885834
step: 260, loss: 0.0322021022439003
step: 270, loss: 0.16860191524028778
step: 280, loss: 0.041462644934654236
step: 290, loss: 0.17501802742481232
step: 300, loss: 0.11479280889034271
step: 310, loss: 0.0332733578979969
step: 320, loss: 0.09520553052425385
step: 330, loss: 0.0914451852440834
step: 340, loss: 0.1502722054719925
step: 350, loss: 0.08186638355255127
step: 360, loss: 0.03950432687997818
step: 370, loss: 0.05436386913061142
step: 380, loss: 0.02996884472668171
step: 390, loss: 0.05953958258032799
step: 400, loss: 0.03382414951920509
step: 410, loss: 0.04939686506986618
step: 420, loss: 0.14352171123027802
step: 430, loss: 0.025891315191984177
step: 440, loss: 0.11437374353408813
step: 450, loss: 0.1650819331407547
step: 460, loss: 0.01013517938554287
step: 470, loss: 0.06765472888946533
step: 480, loss: 0.06735032051801682
step: 490, loss: 0.1607772409915924
step: 500, loss: 0.1506037563085556
step: 510, loss: 0.10099474340677261
step: 520, loss: 0.11467905342578888
step: 530, loss: 0.07089433073997498
step: 540, loss: 0.12568242847919464
step: 550, loss: 0.04339245706796646
step: 560, loss: 0.032911304384469986
step: 570, loss: 0.06329348683357239
step: 580, loss: 0.048129741102457047
step: 590, loss: 0.02642747014760971
step: 600, loss: 0.057106249034404755
step: 610, loss: 0.07705577462911606
step: 620, loss: 0.04225646331906319
step: 630, loss: 0.08524802327156067
step: 640, loss: 0.15380209684371948
step: 650, loss: 0.17430920898914337
step: 660, loss: 0.050294987857341766
step: 670, loss: 0.08480258285999298
step: 680, loss: 0.10886155068874359
step: 690, loss: 0.10427261143922806
step: 700, loss: 0.10857504606246948
step: 710, loss: 0.1415177881717682
step: 720, loss: 0.06535888463258743
step: 730, loss: 0.033061642199754715
step: 740, loss: 0.053336407989263535
step: 750, loss: 0.025939960032701492
step: 760, loss: 0.0803767591714859
step: 770, loss: 0.1622246503829956
step: 780, loss: 0.18143559992313385
step: 790, loss: 0.0726015493273735
step: 800, loss: 0.03253000229597092
step: 810, loss: 0.31764042377471924
step: 820, loss: 0.07173755019903183
step: 830, loss: 0.24458305537700653
step: 840, loss: 0.06801485270261765
step: 850, loss: 0.14011111855506897
step: 860, loss: 0.04468218982219696
step: 870, loss: 0.05189196392893791
step: 880, loss: 0.01199150737375021
step: 890, loss: 0.043536476790905
step: 900, loss: 0.05632796138525009
step: 910, loss: 0.08744959533214569
step: 920, loss: 0.17902392148971558
step: 930, loss: 0.09880504012107849
step: 940, loss: 0.15692219138145447
step: 950, loss: 0.07696494460105896
step: 960, loss: 0.07383549213409424
step: 970, loss: 0.09622108936309814
step: 980, loss: 0.09456032514572144
step: 990, loss: 0.0935516282916069
step: 1000, loss: 0.13871893286705017
step: 1010, loss: 0.09382344037294388
step: 1020, loss: 0.1259976029396057
step: 1030, loss: 0.08916396647691727
step: 1040, loss: 0.032598044723272324
step: 1050, loss: 0.21425530314445496
step: 1060, loss: 0.07890064269304276
step: 1070, loss: 0.03754264861345291
epoch 3: dev_f1=0.9372967951695309, f1=0.9304713019132057, best_f1=0.9304713019132057
step: 0, loss: 0.03907574340701103
step: 10, loss: 0.30934086441993713
step: 20, loss: 0.022129813209176064
step: 30, loss: 0.004016908351331949
step: 40, loss: 0.1495392620563507
step: 50, loss: 0.0488412082195282
step: 60, loss: 0.06709569692611694
step: 70, loss: 0.022681033238768578
step: 80, loss: 0.02249923348426819
step: 90, loss: 0.09831555932760239
step: 100, loss: 0.040491968393325806
step: 110, loss: 0.08365373313426971
step: 120, loss: 0.012458667159080505
step: 130, loss: 0.04783041402697563
step: 140, loss: 0.027165278792381287
step: 150, loss: 0.06695547699928284
step: 160, loss: 0.14497825503349304
step: 170, loss: 0.014181430451571941
step: 180, loss: 0.14563220739364624
step: 190, loss: 0.046149153262376785
step: 200, loss: 0.08567547053098679
step: 210, loss: 0.065547414124012
step: 220, loss: 0.06431430578231812
step: 230, loss: 0.11351396888494492
step: 240, loss: 0.014872340485453606
step: 250, loss: 0.04618817940354347
step: 260, loss: 0.0887036994099617
step: 270, loss: 0.12452384829521179
step: 280, loss: 0.06196350231766701
step: 290, loss: 0.06484048813581467
step: 300, loss: 0.03635265678167343
step: 310, loss: 0.047887008637189865
step: 320, loss: 0.05564527586102486
step: 330, loss: 0.0938110202550888
step: 340, loss: 0.10211677849292755
step: 350, loss: 0.06681308150291443
step: 360, loss: 0.023835154250264168
step: 370, loss: 0.08207271248102188
step: 380, loss: 0.10314761847257614
step: 390, loss: 0.13151776790618896
step: 400, loss: 0.13797999918460846
step: 410, loss: 0.01034154836088419
step: 420, loss: 0.01883109286427498
step: 430, loss: 0.15539699792861938
step: 440, loss: 0.04697728902101517
step: 450, loss: 0.05942361801862717
step: 460, loss: 0.15086813271045685
step: 470, loss: 0.052302271127700806
step: 480, loss: 0.04389187693595886
step: 490, loss: 0.10094698518514633
step: 500, loss: 0.3083053529262543
step: 510, loss: 0.08983896672725677
step: 520, loss: 0.056598350405693054
step: 530, loss: 0.02145879715681076
step: 540, loss: 0.03219287097454071
step: 550, loss: 0.24632319808006287
step: 560, loss: 0.028607452288269997
step: 570, loss: 0.08378088474273682
step: 580, loss: 0.042680080980062485
step: 590, loss: 0.07286141812801361
step: 600, loss: 0.032472796738147736
step: 610, loss: 0.01611281745135784
step: 620, loss: 0.05365603044629097
step: 630, loss: 0.007819540798664093
step: 640, loss: 0.0789017453789711
step: 650, loss: 0.11846426129341125
step: 660, loss: 0.1081632748246193
step: 670, loss: 0.11413531005382538
step: 680, loss: 0.010611309669911861
step: 690, loss: 0.2012307494878769
step: 700, loss: 0.01473661232739687
step: 710, loss: 0.01460866630077362
step: 720, loss: 0.13163559138774872
step: 730, loss: 0.02171383611857891
step: 740, loss: 0.05748193338513374
step: 750, loss: 0.006214328110218048
step: 760, loss: 0.020535098388791084
step: 770, loss: 0.06383989751338959
step: 780, loss: 0.04658493027091026
step: 790, loss: 0.012344147078692913
step: 800, loss: 0.14464563131332397
step: 810, loss: 0.12157982587814331
step: 820, loss: 0.14606599509716034
step: 830, loss: 0.06938453763723373
step: 840, loss: 0.04770316183567047
step: 850, loss: 0.17305684089660645
step: 860, loss: 0.008633109740912914
step: 870, loss: 0.05493520572781563
step: 880, loss: 0.049227386713027954
step: 890, loss: 0.1071026474237442
step: 900, loss: 0.016604458913207054
step: 910, loss: 0.18426668643951416
step: 920, loss: 0.07668942958116531
step: 930, loss: 0.04228262975811958
step: 940, loss: 0.08359462767839432
step: 950, loss: 0.07364483177661896
step: 960, loss: 0.09429866820573807
step: 970, loss: 0.08098182082176208
step: 980, loss: 0.14352329075336456
step: 990, loss: 0.007102849427610636
step: 1000, loss: 0.04900381341576576
step: 1010, loss: 0.19277438521385193
step: 1020, loss: 0.3102312386035919
step: 1030, loss: 0.08103980123996735
step: 1040, loss: 0.06359142810106277
step: 1050, loss: 0.10644741356372833
step: 1060, loss: 0.07001423090696335
step: 1070, loss: 0.11081978678703308
epoch 4: dev_f1=0.9353788935378894, f1=0.9297347603536529, best_f1=0.9304713019132057
step: 0, loss: 0.015275418758392334
step: 10, loss: 0.05020878091454506
step: 20, loss: 0.20426735281944275
step: 30, loss: 0.069546639919281
step: 40, loss: 0.03339996561408043
step: 50, loss: 0.05247565731406212
step: 60, loss: 0.05804690718650818
step: 70, loss: 0.0381510965526104
step: 80, loss: 0.060479845851659775
step: 90, loss: 0.023319678381085396
step: 100, loss: 0.1958635151386261
step: 110, loss: 0.11069735884666443
step: 120, loss: 0.0059416634030640125
step: 130, loss: 0.05835124850273132
step: 140, loss: 0.10155082494020462
step: 150, loss: 0.07730083167552948
step: 160, loss: 0.08477310836315155
step: 170, loss: 0.06173045560717583
step: 180, loss: 0.01442177314311266
step: 190, loss: 0.014813434332609177
step: 200, loss: 0.017268240451812744
step: 210, loss: 0.04274517297744751
step: 220, loss: 0.027603646740317345
step: 230, loss: 0.13795118033885956
step: 240, loss: 0.01867665909230709
step: 250, loss: 0.012497778981924057
step: 260, loss: 0.0502503365278244
step: 270, loss: 0.0007105569820851088
step: 280, loss: 0.08052065223455429
step: 290, loss: 0.0032553605269640684
step: 300, loss: 0.10592769831418991
step: 310, loss: 0.14040662348270416
step: 320, loss: 0.13910241425037384
step: 330, loss: 0.04810734838247299
step: 340, loss: 0.03663703054189682
step: 350, loss: 0.07541403919458389
step: 360, loss: 0.03822512552142143
step: 370, loss: 0.10318993031978607
step: 380, loss: 0.14054161310195923
step: 390, loss: 0.05361947417259216
step: 400, loss: 0.010297573171555996
step: 410, loss: 0.016938576474785805
step: 420, loss: 0.06811069697141647
step: 430, loss: 0.012209603562951088
step: 440, loss: 0.03981336951255798
step: 450, loss: 0.034428272396326065
step: 460, loss: 0.026249462738633156
step: 470, loss: 0.007965548895299435
step: 480, loss: 0.11050322651863098
step: 490, loss: 0.0585307776927948
step: 500, loss: 0.037199750542640686
step: 510, loss: 0.00558753265067935
step: 520, loss: 0.012482987716794014
step: 530, loss: 0.041008830070495605
step: 540, loss: 0.021379664540290833
step: 550, loss: 0.012080492451786995
step: 560, loss: 0.010222123004496098
step: 570, loss: 0.03835543617606163
step: 580, loss: 0.017253899946808815
step: 590, loss: 0.09506098181009293
step: 600, loss: 0.006542944349348545
step: 610, loss: 0.07617193460464478
step: 620, loss: 0.07259082794189453
step: 630, loss: 0.12830716371536255
step: 640, loss: 0.05722113326191902
step: 650, loss: 0.15702693164348602
step: 660, loss: 0.03609074279665947
step: 670, loss: 0.026506632566452026
step: 680, loss: 0.07349664717912674
step: 690, loss: 0.11219089478254318
step: 700, loss: 0.07500414550304413
step: 710, loss: 0.127470463514328
step: 720, loss: 0.0763990730047226
step: 730, loss: 0.043541405349969864
step: 740, loss: 0.06365299969911575
step: 750, loss: 0.21374869346618652
step: 760, loss: 0.07874226570129395
step: 770, loss: 0.16334426403045654
step: 780, loss: 0.0497538186609745
step: 790, loss: 0.07358337938785553
step: 800, loss: 0.28320154547691345
step: 810, loss: 0.06569195538759232
step: 820, loss: 0.035435374826192856
step: 830, loss: 0.026859108358621597
step: 840, loss: 0.07536299526691437
step: 850, loss: 0.11647865921258926
step: 860, loss: 0.11522860080003738
step: 870, loss: 0.027367228642106056
step: 880, loss: 0.04933878406882286
step: 890, loss: 0.033846016973257065
step: 900, loss: 0.07028459012508392
step: 910, loss: 0.018790971487760544
step: 920, loss: 0.2135007530450821
step: 930, loss: 0.012733311392366886
step: 940, loss: 0.03737190365791321
step: 950, loss: 0.03220386803150177
step: 960, loss: 0.022355783730745316
step: 970, loss: 0.035834796726703644
step: 980, loss: 0.05051908269524574
step: 990, loss: 0.12557187676429749
step: 1000, loss: 0.02265371009707451
step: 1010, loss: 0.056039560586214066
step: 1020, loss: 0.034369077533483505
step: 1030, loss: 0.026630926877260208
step: 1040, loss: 0.025102481245994568
step: 1050, loss: 0.09024740755558014
step: 1060, loss: 0.053885914385318756
step: 1070, loss: 0.06658255308866501
epoch 5: dev_f1=0.9330889092575618, f1=0.9334557136301056, best_f1=0.9304713019132057
step: 0, loss: 0.09669841080904007
step: 10, loss: 0.09748299419879913
step: 20, loss: 0.07263598591089249
step: 30, loss: 0.030057014897465706
step: 40, loss: 0.02826199308037758
step: 50, loss: 0.11931788921356201
step: 60, loss: 0.02793189510703087
step: 70, loss: 0.056019801646471024
step: 80, loss: 0.0694786012172699
step: 90, loss: 0.10807385295629501
step: 100, loss: 0.02097667194902897
step: 110, loss: 0.01643979921936989
step: 120, loss: 0.05170099809765816
step: 130, loss: 0.028964752331376076
step: 140, loss: 0.0215488001704216
step: 150, loss: 0.011727816425263882
step: 160, loss: 0.10320605337619781
step: 170, loss: 0.08074026554822922
step: 180, loss: 0.11274125427007675
step: 190, loss: 0.06816834956407547
step: 200, loss: 0.21276968717575073
step: 210, loss: 0.05381806939840317
step: 220, loss: 0.006412688177078962
step: 230, loss: 0.024421455338597298
step: 240, loss: 0.05371707305312157
step: 250, loss: 0.002817720640450716
step: 260, loss: 0.011992573738098145
step: 270, loss: 0.176813542842865
step: 280, loss: 0.06709276139736176
step: 290, loss: 0.11469601839780807
step: 300, loss: 0.051180485635995865
step: 310, loss: 0.011891314759850502
step: 320, loss: 0.09226629137992859
step: 330, loss: 0.04873206466436386
step: 340, loss: 0.05498432368040085
step: 350, loss: 0.09137967228889465
step: 360, loss: 0.047578323632478714
step: 370, loss: 0.12676864862442017
step: 380, loss: 0.02131391316652298
step: 390, loss: 0.10006948560476303
step: 400, loss: 0.04434102028608322
step: 410, loss: 0.04042750969529152
step: 420, loss: 0.08890284597873688
step: 430, loss: 0.09288041293621063
step: 440, loss: 0.005156961735337973
step: 450, loss: 0.014949165284633636
step: 460, loss: 0.008604857139289379
step: 470, loss: 0.198222815990448
step: 480, loss: 0.058985985815525055
step: 490, loss: 0.08795659244060516
step: 500, loss: 0.11419826745986938
step: 510, loss: 0.04011588171124458
step: 520, loss: 0.04900212213397026
step: 530, loss: 0.003304094076156616
step: 540, loss: 0.0660863071680069
step: 550, loss: 0.10695966333150864
step: 560, loss: 0.007426152005791664
step: 570, loss: 0.0710529088973999
step: 580, loss: 0.06256455928087234
step: 590, loss: 0.01575709879398346
step: 600, loss: 0.011944867670536041
step: 610, loss: 0.15245980024337769
step: 620, loss: 0.023361843079328537
step: 630, loss: 0.07254967838525772
step: 640, loss: 0.09209583699703217
step: 650, loss: 0.020132480189204216
step: 660, loss: 0.05175192654132843
step: 670, loss: 0.07892974466085434
step: 680, loss: 0.031088586896657944
step: 690, loss: 0.020681949332356453
step: 700, loss: 0.036641791462898254
step: 710, loss: 0.050421204417943954
step: 720, loss: 0.17690621316432953
step: 730, loss: 0.014224646613001823
step: 740, loss: 0.042116209864616394
step: 750, loss: 0.11833325028419495
step: 760, loss: 0.0049499040469527245
step: 770, loss: 0.15840928256511688
step: 780, loss: 0.1107686385512352
step: 790, loss: 0.1153956949710846
step: 800, loss: 0.08763168007135391
step: 810, loss: 0.12316390872001648
step: 820, loss: 0.0368909016251564
step: 830, loss: 0.1302344650030136
step: 840, loss: 0.01517584826797247
step: 850, loss: 0.02481289952993393
step: 860, loss: 0.13334041833877563
step: 870, loss: 0.024110082536935806
step: 880, loss: 0.050703659653663635
step: 890, loss: 0.008451875299215317
step: 900, loss: 0.02744688093662262
step: 910, loss: 0.008158106356859207
step: 920, loss: 0.008695540018379688
step: 930, loss: 0.0834662914276123
step: 940, loss: 0.2276545912027359
step: 950, loss: 0.02777429297566414
step: 960, loss: 0.0013236672384664416
step: 970, loss: 0.01662522368133068
step: 980, loss: 0.03815050050616264
step: 990, loss: 0.04391099512577057
step: 1000, loss: 0.03058721125125885
step: 1010, loss: 0.06100759655237198
step: 1020, loss: 0.034967049956321716
step: 1030, loss: 0.364437460899353
step: 1040, loss: 0.2052462249994278
step: 1050, loss: 0.1538255512714386
step: 1060, loss: 0.16106322407722473
step: 1070, loss: 0.01687016710639
epoch 6: dev_f1=0.9353187529083293, f1=0.9390980939098094, best_f1=0.9304713019132057
step: 0, loss: 0.06512200832366943
step: 10, loss: 0.06823362410068512
step: 20, loss: 0.09714237600564957
step: 30, loss: 0.10985512286424637
step: 40, loss: 0.027928560972213745
step: 50, loss: 0.019224287942051888
step: 60, loss: 0.01396543625742197
step: 70, loss: 0.00940579641610384
step: 80, loss: 0.009752949699759483
step: 90, loss: 0.01864374428987503
step: 100, loss: 0.0850881040096283
step: 110, loss: 0.0332142673432827
step: 120, loss: 0.061349838972091675
step: 130, loss: 0.041532427072525024
step: 140, loss: 0.050418686121702194
step: 150, loss: 0.1597452461719513
step: 160, loss: 0.12900185585021973
step: 170, loss: 0.06408123672008514
step: 180, loss: 0.13879993557929993
step: 190, loss: 0.10322724282741547
step: 200, loss: 0.02824067696928978
step: 210, loss: 0.049764979630708694
step: 220, loss: 0.04699750244617462
step: 230, loss: 0.0075163752771914005
step: 240, loss: 0.010557870380580425
step: 250, loss: 0.037211377173662186
step: 260, loss: 0.09958509355783463
step: 270, loss: 0.09403719007968903
step: 280, loss: 0.040144313126802444
step: 290, loss: 0.05414314195513725
step: 300, loss: 0.019072096794843674
step: 310, loss: 0.013247784227132797
step: 320, loss: 0.05077521502971649
step: 330, loss: 0.04827401787042618
step: 340, loss: 0.006104073952883482
step: 350, loss: 0.05502662807703018
step: 360, loss: 0.012878959998488426
step: 370, loss: 0.0563892163336277
step: 380, loss: 0.08294276148080826
step: 390, loss: 0.1414676308631897
step: 400, loss: 0.05557277053594589
step: 410, loss: 0.042971521615982056
step: 420, loss: 0.027932394295930862
step: 430, loss: 0.01750645972788334
step: 440, loss: 0.019681217148900032
step: 450, loss: 0.028164131566882133
step: 460, loss: 0.04542829841375351
step: 470, loss: 0.0015286222333088517
step: 480, loss: 0.1024114340543747
step: 490, loss: 0.012645358219742775
step: 500, loss: 0.03052455373108387
step: 510, loss: 0.026225320994853973
step: 520, loss: 0.1425500214099884
step: 530, loss: 0.07039612531661987
step: 540, loss: 0.025891438126564026
step: 550, loss: 0.08990409225225449
step: 560, loss: 0.09555868804454803
step: 570, loss: 0.019177723675966263
step: 580, loss: 0.05352243781089783
step: 590, loss: 0.018307430669665337
step: 600, loss: 0.10268334299325943
step: 610, loss: 0.047569941729307175
step: 620, loss: 0.008318222127854824
step: 630, loss: 0.11188222467899323
step: 640, loss: 0.08261915296316147
step: 650, loss: 0.11402104794979095
step: 660, loss: 0.009361372329294682
step: 670, loss: 0.1688067466020584
step: 680, loss: 0.08291445672512054
step: 690, loss: 0.01639460027217865
step: 700, loss: 0.03227580338716507
step: 710, loss: 0.041085440665483475
step: 720, loss: 0.03645500913262367
step: 730, loss: 0.15962260961532593
step: 740, loss: 0.042148906737565994
step: 750, loss: 0.05040382221341133
step: 760, loss: 0.09145934879779816
step: 770, loss: 0.03389879688620567
step: 780, loss: 0.029713237658143044
step: 790, loss: 0.007993987761437893
step: 800, loss: 0.0037550705019384623
step: 810, loss: 0.061512481421232224
step: 820, loss: 0.0938742458820343
step: 830, loss: 0.05772089585661888
step: 840, loss: 0.028399279341101646
step: 850, loss: 0.020680047571659088
step: 860, loss: 0.03289012238383293
step: 870, loss: 0.22269701957702637
step: 880, loss: 0.08291763067245483
step: 890, loss: 0.01195534598082304
step: 900, loss: 0.045003652572631836
step: 910, loss: 0.06633608043193817
step: 920, loss: 0.028614455834031105
step: 930, loss: 0.02181919850409031
step: 940, loss: 0.08179309964179993
step: 950, loss: 0.049347974359989166
step: 960, loss: 0.12250501662492752
step: 970, loss: 0.12260358035564423
step: 980, loss: 0.04733078181743622
step: 990, loss: 0.028711263090372086
step: 1000, loss: 0.007528368849307299
step: 1010, loss: 0.0366692878305912
step: 1020, loss: 0.019384369254112244
step: 1030, loss: 0.11787308752536774
step: 1040, loss: 0.02039244771003723
step: 1050, loss: 0.05116458237171173
step: 1060, loss: 0.029644932597875595
step: 1070, loss: 0.14242464303970337
epoch 7: dev_f1=0.9298653042266605, f1=0.923646459972235, best_f1=0.9304713019132057
step: 0, loss: 0.07484051585197449
step: 10, loss: 0.03248990699648857
step: 20, loss: 0.015904048457741737
step: 30, loss: 0.02270122617483139
step: 40, loss: 0.06613064557313919
step: 50, loss: 0.013099062256515026
step: 60, loss: 0.017857227474451065
step: 70, loss: 0.08536360412836075
step: 80, loss: 0.011621838435530663
step: 90, loss: 0.08387243747711182
step: 100, loss: 0.12115742266178131
step: 110, loss: 0.09495777636766434
step: 120, loss: 0.05783368647098541
step: 130, loss: 0.024379465728998184
step: 140, loss: 0.036292120814323425
step: 150, loss: 0.0038021777290850878
step: 160, loss: 0.03743426501750946
step: 170, loss: 0.06486672163009644
step: 180, loss: 0.03629075735807419
step: 190, loss: 0.0383596234023571
step: 200, loss: 0.11977153271436691
step: 210, loss: 0.07751575112342834
step: 220, loss: 0.017562925815582275
step: 230, loss: 0.04004785791039467
step: 240, loss: 0.1280299872159958
step: 250, loss: 0.09778937697410583
step: 260, loss: 0.031050805002450943
step: 270, loss: 0.045160967856645584
step: 280, loss: 0.20967985689640045
step: 290, loss: 0.07144111394882202
step: 300, loss: 0.0061495122499763966
step: 310, loss: 0.04587934538722038
step: 320, loss: 0.05905812606215477
step: 330, loss: 0.007471201941370964
step: 340, loss: 0.12302834540605545
step: 350, loss: 0.0027635833248496056
step: 360, loss: 0.0059141358360648155
step: 370, loss: 0.06051051616668701
step: 380, loss: 0.009691181592643261
step: 390, loss: 0.0808955505490303
step: 400, loss: 0.04593523591756821
step: 410, loss: 0.038930296897888184
step: 420, loss: 0.025565868243575096
step: 430, loss: 0.02729473076760769
step: 440, loss: 0.090422123670578
step: 450, loss: 0.13443535566329956
step: 460, loss: 0.05487201735377312
step: 470, loss: 3.1357503758044913e-05
step: 480, loss: 0.018514307215809822
step: 490, loss: 0.08219064772129059
step: 500, loss: 0.035560738295316696
step: 510, loss: 0.007503680419176817
step: 520, loss: 0.14794419705867767
step: 530, loss: 0.006346782669425011
step: 540, loss: 0.013556879945099354
step: 550, loss: 0.2158873826265335
step: 560, loss: 0.016154449433088303
step: 570, loss: 0.053510479629039764
step: 580, loss: 0.2312418669462204
step: 590, loss: 0.023874720558524132
step: 600, loss: 0.07213868945837021
step: 610, loss: 0.06568822264671326
step: 620, loss: 0.11703628301620483
step: 630, loss: 0.05547264963388443
step: 640, loss: 0.07339130342006683
step: 650, loss: 0.05639224871993065
step: 660, loss: 0.07144699990749359
step: 670, loss: 0.038222044706344604
step: 680, loss: 0.02738972194492817
step: 690, loss: 0.11893429607152939
step: 700, loss: 0.015256829559803009
step: 710, loss: 0.013683521188795567
step: 720, loss: 0.06234997138381004
step: 730, loss: 0.019426241517066956
step: 740, loss: 0.10869918763637543
step: 750, loss: 0.020760226994752884
step: 760, loss: 0.023898039013147354
step: 770, loss: 0.0029123984277248383
step: 780, loss: 0.059727076441049576
step: 790, loss: 0.03131009638309479
step: 800, loss: 0.01528982538729906
step: 810, loss: 0.02744762971997261
step: 820, loss: 0.022818220779299736
step: 830, loss: 0.0359434112906456
step: 840, loss: 0.03866736218333244
step: 850, loss: 0.11491747945547104
step: 860, loss: 0.09130657464265823
step: 870, loss: 0.15598943829536438
step: 880, loss: 0.03345589339733124
step: 890, loss: 0.14396938681602478
step: 900, loss: 0.05729958787560463
step: 910, loss: 0.02218068763613701
step: 920, loss: 0.013562529347836971
step: 930, loss: 0.03147406876087189
step: 940, loss: 0.04596375301480293
step: 950, loss: 0.08342152833938599
step: 960, loss: 0.08870670944452286
step: 970, loss: 0.03776263818144798
step: 980, loss: 0.0556366890668869
step: 990, loss: 0.078612320125103
step: 1000, loss: 0.007862589322030544
step: 1010, loss: 0.09000910818576813
step: 1020, loss: 0.020525407046079636
step: 1030, loss: 0.07182585448026657
step: 1040, loss: 0.052376508712768555
step: 1050, loss: 0.013834560289978981
step: 1060, loss: 0.06446637213230133
step: 1070, loss: 0.11828247457742691
epoch 8: dev_f1=0.931985294117647, f1=0.9305936073059361, best_f1=0.9304713019132057
step: 0, loss: 0.1145283430814743
step: 10, loss: 0.0136460792273283
step: 20, loss: 0.02511647529900074
step: 30, loss: 0.019981635734438896
step: 40, loss: 0.0949670746922493
step: 50, loss: 0.06796704232692719
step: 60, loss: 0.010329614393413067
step: 70, loss: 0.031892888247966766
step: 80, loss: 0.01577802002429962
step: 90, loss: 0.03605902940034866
step: 100, loss: 0.09421020746231079
step: 110, loss: 0.05051296576857567
step: 120, loss: 0.0047621773555874825
step: 130, loss: 0.012593149207532406
step: 140, loss: 0.09194990247488022
step: 150, loss: 0.01577824354171753
step: 160, loss: 0.07824263721704483
step: 170, loss: 0.04249396175146103
step: 180, loss: 0.005097624845802784
step: 190, loss: 0.04670219123363495
step: 200, loss: 0.06845509260892868
step: 210, loss: 0.022592725232243538
step: 220, loss: 0.0726570338010788
step: 230, loss: 0.10820721834897995
step: 240, loss: 0.004349231254309416
step: 250, loss: 0.01049896702170372
step: 260, loss: 0.08058430999517441
step: 270, loss: 0.05374089628458023
step: 280, loss: 0.019910935312509537
step: 290, loss: 0.049922339618206024
step: 300, loss: 0.10316351801156998
step: 310, loss: 0.04668336361646652
step: 320, loss: 0.039732325822114944
step: 330, loss: 0.030748683959245682
step: 340, loss: 0.09880494326353073
step: 350, loss: 0.03228266164660454
step: 360, loss: 0.0199887715280056
step: 370, loss: 0.016731418669223785
step: 380, loss: 0.08709562569856644
step: 390, loss: 0.043628428131341934
step: 400, loss: 0.0031829169020056725
step: 410, loss: 0.009536132216453552
step: 420, loss: 0.003161806147545576
step: 430, loss: 0.04223831370472908
step: 440, loss: 0.04096262902021408
step: 450, loss: 0.062000811100006104
step: 460, loss: 0.06842197477817535
step: 470, loss: 0.027133610099554062
step: 480, loss: 0.13801690936088562
step: 490, loss: 0.026973385363817215
step: 500, loss: 0.02760501764714718
step: 510, loss: 0.01223795861005783
step: 520, loss: 0.014112680219113827
step: 530, loss: 0.09420900791883469
step: 540, loss: 0.0027704257518053055
step: 550, loss: 0.05635794252157211
step: 560, loss: 0.054044440388679504
step: 570, loss: 0.09545084834098816
step: 580, loss: 0.07102203369140625
step: 590, loss: 0.011196820065379143
step: 600, loss: 0.006146065425127745
step: 610, loss: 0.04539095610380173
step: 620, loss: 0.0018922168528661132
step: 630, loss: 0.014331013895571232
step: 640, loss: 0.0068924385122954845
step: 650, loss: 0.008307038806378841
step: 660, loss: 0.042105063796043396
step: 670, loss: 0.13349956274032593
step: 680, loss: 0.08180074393749237
step: 690, loss: 0.00044396394514478743
step: 700, loss: 0.11061076074838638
step: 710, loss: 0.07055705785751343
step: 720, loss: 0.1846250742673874
step: 730, loss: 0.11325868964195251
step: 740, loss: 0.00011469778110040352
step: 750, loss: 0.06564512103796005
step: 760, loss: 0.012517363764345646
step: 770, loss: 0.017909487709403038
step: 780, loss: 0.0019616263452917337
step: 790, loss: 0.06642995774745941
step: 800, loss: 0.004326960537582636
step: 810, loss: 0.04190980643033981
step: 820, loss: 0.14731799066066742
step: 830, loss: 0.04724432900547981
step: 840, loss: 0.06279829889535904
step: 850, loss: 0.031071718782186508
step: 860, loss: 0.005611793138086796
step: 870, loss: 0.009900457225739956
step: 880, loss: 0.1021575853228569
step: 890, loss: 0.022792469710111618
step: 900, loss: 0.0488496758043766
step: 910, loss: 0.00857369415462017
step: 920, loss: 0.06062621995806694
step: 930, loss: 0.1625208556652069
step: 940, loss: 0.01242498867213726
step: 950, loss: 0.022698411718010902
step: 960, loss: 0.09116512537002563
step: 970, loss: 0.03656141832470894
step: 980, loss: 0.03424803167581558
step: 990, loss: 0.06728100031614304
step: 1000, loss: 0.09747760742902756
step: 1010, loss: 0.008551590144634247
step: 1020, loss: 0.08182556927204132
step: 1030, loss: 0.057217419147491455
step: 1040, loss: 0.018940770998597145
step: 1050, loss: 0.024913569912314415
step: 1060, loss: 0.019415488466620445
step: 1070, loss: 0.06832738220691681
epoch 9: dev_f1=0.9386248269497001, f1=0.9292649098474343, best_f1=0.9292649098474343
step: 0, loss: 0.03254444897174835
step: 10, loss: 0.15808619558811188
step: 20, loss: 0.043491147458553314
step: 30, loss: 0.006954668089747429
step: 40, loss: 0.04827556386590004
step: 50, loss: 0.12559323012828827
step: 60, loss: 0.048579003661870956
step: 70, loss: 0.06327766925096512
step: 80, loss: 0.014024498872458935
step: 90, loss: 0.1603078544139862
step: 100, loss: 0.021284282207489014
step: 110, loss: 0.1136622205376625
step: 120, loss: 0.05565638467669487
step: 130, loss: 0.021861687302589417
step: 140, loss: 0.01331138052046299
step: 150, loss: 0.007516072131693363
step: 160, loss: 0.023447828367352486
step: 170, loss: 0.0037569880951195955
step: 180, loss: 0.032036010175943375
step: 190, loss: 0.03084084950387478
step: 200, loss: 0.05852697417140007
step: 210, loss: 0.09377972781658173
step: 220, loss: 0.04830343276262283
step: 230, loss: 0.006391903851181269
step: 240, loss: 0.009019449353218079
step: 250, loss: 0.15145651996135712
step: 260, loss: 0.0647454783320427
step: 270, loss: 0.04328100383281708
step: 280, loss: 0.04622690752148628
step: 290, loss: 0.012709388509392738
step: 300, loss: 0.022852417081594467
step: 310, loss: 0.0036389175802469254
step: 320, loss: 0.10961287468671799
step: 330, loss: 0.016736486926674843
step: 340, loss: 0.026296887546777725
step: 350, loss: 0.0022752126678824425
step: 360, loss: 0.028411034494638443
step: 370, loss: 0.027416225522756577
step: 380, loss: 0.027285100892186165
step: 390, loss: 0.07409736514091492
step: 400, loss: 0.03916548192501068
step: 410, loss: 0.030584122985601425
step: 420, loss: 6.470972584793344e-05
step: 430, loss: 0.06020951643586159
step: 440, loss: 0.03999164327979088
step: 450, loss: 0.07158041000366211
step: 460, loss: 0.0026813349686563015
step: 470, loss: 0.08738543838262558
step: 480, loss: 0.07431250065565109
step: 490, loss: 0.07638253271579742
step: 500, loss: 0.07109366357326508
step: 510, loss: 0.021308502182364464
step: 520, loss: 0.1295849233865738
step: 530, loss: 0.049476321786642075
step: 540, loss: 0.10939603298902512
step: 550, loss: 0.02310860902070999
step: 560, loss: 0.005723318085074425
step: 570, loss: 0.14674827456474304
step: 580, loss: 0.013391630724072456
step: 590, loss: 0.05408065766096115
step: 600, loss: 0.06042914465069771
step: 610, loss: 0.10260690748691559
step: 620, loss: 0.012553486041724682
step: 630, loss: 0.012698527425527573
step: 640, loss: 0.05815625190734863
step: 650, loss: 0.024289384484291077
step: 660, loss: 0.012522795237600803
step: 670, loss: 0.05808626487851143
step: 680, loss: 0.034811533987522125
step: 690, loss: 0.0007139104418456554
step: 700, loss: 0.08909918367862701
step: 710, loss: 0.034489456564188004
step: 720, loss: 0.02376258745789528
step: 730, loss: 0.045446064323186874
step: 740, loss: 0.06042018532752991
step: 750, loss: 0.06648536026477814
step: 760, loss: 0.010412916541099548
step: 770, loss: 0.038744885474443436
step: 780, loss: 0.044553037732839584
step: 790, loss: 0.0642169788479805
step: 800, loss: 0.07428022474050522
step: 810, loss: 0.06901378929615021
step: 820, loss: 0.029572058469057083
step: 830, loss: 0.07614190876483917
step: 840, loss: 0.005610060412436724
step: 850, loss: 0.007452906109392643
step: 860, loss: 0.013920937664806843
step: 870, loss: 0.023139525204896927
step: 880, loss: 0.03459051623940468
step: 890, loss: 0.09361673146486282
step: 900, loss: 0.01467155385762453
step: 910, loss: 0.09302745014429092
step: 920, loss: 0.003714086255058646
step: 930, loss: 0.03457968682050705
step: 940, loss: 0.047295793890953064
step: 950, loss: 0.013234967365860939
step: 960, loss: 2.6329355023335665e-05
step: 970, loss: 0.04150351136922836
step: 980, loss: 0.07753882557153702
step: 990, loss: 0.03671397268772125
step: 1000, loss: 0.05281407758593559
step: 1010, loss: 0.04351156949996948
step: 1020, loss: 0.02451084926724434
step: 1030, loss: 0.03113103285431862
step: 1040, loss: 0.01896778680384159
step: 1050, loss: 0.0026257471181452274
step: 1060, loss: 0.03427575156092644
step: 1070, loss: 0.027224482968449593
epoch 10: dev_f1=0.9405255878284925, f1=0.9303184125519152, best_f1=0.9303184125519152
step: 0, loss: 0.019523663446307182
step: 10, loss: 0.012596962042152882
step: 20, loss: 0.047177840024232864
step: 30, loss: 0.028509000316262245
step: 40, loss: 0.0005607327329926193
step: 50, loss: 0.06476815044879913
step: 60, loss: 0.041539326310157776
step: 70, loss: 0.00688011571764946
step: 80, loss: 0.07320620119571686
step: 90, loss: 0.0029260076116770506
step: 100, loss: 0.022867301478981972
step: 110, loss: 0.06442228704690933
step: 120, loss: 0.028940342366695404
step: 130, loss: 0.06151971593499184
step: 140, loss: 0.05634104087948799
step: 150, loss: 0.15551216900348663
step: 160, loss: 0.012103118002414703
step: 170, loss: 0.03459532558917999
step: 180, loss: 0.05148616060614586
step: 190, loss: 0.027793535962700844
step: 200, loss: 0.08217229694128036
step: 210, loss: 0.08739646524190903
step: 220, loss: 4.338115832069889e-05
step: 230, loss: 0.08908773958683014
step: 240, loss: 0.025900159031152725
step: 250, loss: 0.0020418830681592226
step: 260, loss: 0.032270774245262146
step: 270, loss: 0.04045959562063217
step: 280, loss: 0.039003804326057434
step: 290, loss: 0.04198769852519035
step: 300, loss: 0.0016611693426966667
step: 310, loss: 0.1232215017080307
step: 320, loss: 0.0801403746008873
step: 330, loss: 0.012407525442540646
step: 340, loss: 0.031119076535105705
step: 350, loss: 0.10911526530981064
step: 360, loss: 0.03024100698530674
step: 370, loss: 0.3027871549129486
step: 380, loss: 0.027910593897104263
step: 390, loss: 0.00619601272046566
step: 400, loss: 0.037902045994997025
step: 410, loss: 0.01790604554116726
step: 420, loss: 0.11029308289289474
step: 430, loss: 0.10108066350221634
step: 440, loss: 0.019980929791927338
step: 450, loss: 0.009850619360804558
step: 460, loss: 0.014147073961794376
step: 470, loss: 0.04184664040803909
step: 480, loss: 0.03061418980360031
step: 490, loss: 0.03238692507147789
step: 500, loss: 0.06964833289384842
step: 510, loss: 0.05505451187491417
step: 520, loss: 0.04491729661822319
step: 530, loss: 0.0212041474878788
step: 540, loss: 0.026449479162693024
step: 550, loss: 0.016570651903748512
step: 560, loss: 0.06186598166823387
step: 570, loss: 0.0015121962642297149
step: 580, loss: 0.23248529434204102
step: 590, loss: 0.10405401140451431
step: 600, loss: 0.07390046864748001
step: 610, loss: 0.1676616668701172
step: 620, loss: 0.05377741530537605
step: 630, loss: 0.008947404101490974
step: 640, loss: 0.01747041381895542
step: 650, loss: 0.018476683646440506
step: 660, loss: 0.12390738725662231
step: 670, loss: 0.05608540400862694
step: 680, loss: 0.05951421707868576
step: 690, loss: 0.046016767621040344
step: 700, loss: 0.03432627022266388
step: 710, loss: 0.07331111282110214
step: 720, loss: 0.12509290874004364
step: 730, loss: 0.10106600075960159
step: 740, loss: 0.10934591293334961
step: 750, loss: 0.03688208758831024
step: 760, loss: 0.005538451485335827
step: 770, loss: 0.009350358508527279
step: 780, loss: 0.005086117424070835
step: 790, loss: 0.0843375101685524
step: 800, loss: 0.012691457755863667
step: 810, loss: 0.0019139753421768546
step: 820, loss: 0.09136909246444702
step: 830, loss: 0.021293003112077713
step: 840, loss: 0.039016906172037125
step: 850, loss: 0.11068971455097198
step: 860, loss: 0.022792957723140717
step: 870, loss: 0.014721464365720749
step: 880, loss: 0.020539922639727592
step: 890, loss: 0.14874109625816345
step: 900, loss: 0.04749372974038124
step: 910, loss: 0.03804408386349678
step: 920, loss: 0.11841525882482529
step: 930, loss: 0.12025319039821625
step: 940, loss: 0.04376782849431038
step: 950, loss: 0.07019510120153427
step: 960, loss: 0.0004816098080482334
step: 970, loss: 0.08436848968267441
step: 980, loss: 0.07218886911869049
step: 990, loss: 0.04866153746843338
step: 1000, loss: 0.012853752821683884
step: 1010, loss: 0.1621672660112381
step: 1020, loss: 0.04292517155408859
step: 1030, loss: 0.006608318537473679
step: 1040, loss: 0.007786238566040993
step: 1050, loss: 6.760891119483858e-05
step: 1060, loss: 0.0156664177775383
step: 1070, loss: 0.05434541404247284
epoch 11: dev_f1=0.9310035842293907, f1=0.9241071428571428, best_f1=0.9303184125519152
step: 0, loss: 0.07503485679626465
step: 10, loss: 0.006428101100027561
step: 20, loss: 0.032690830528736115
step: 30, loss: 0.08130839467048645
step: 40, loss: 0.08283107727766037
step: 50, loss: 0.0032140298280864954
step: 60, loss: 0.0002982025616802275
step: 70, loss: 0.028350941836833954
step: 80, loss: 0.00028462926275096834
step: 90, loss: 0.002009932417422533
step: 100, loss: 0.04173172265291214
step: 110, loss: 0.04387688636779785
step: 120, loss: 0.060041215270757675
step: 130, loss: 0.033842816948890686
step: 140, loss: 0.013543558306992054
step: 150, loss: 0.08352293074131012
step: 160, loss: 0.005484422668814659
step: 170, loss: 0.09740661829710007
step: 180, loss: 0.004926105961203575
step: 190, loss: 0.11225837469100952
step: 200, loss: 0.05013057217001915
step: 210, loss: 0.033991508185863495
step: 220, loss: 0.027159638702869415
step: 230, loss: 0.020048758015036583
step: 240, loss: 0.20740807056427002
step: 250, loss: 0.041991498321294785
step: 260, loss: 0.05999802052974701
step: 270, loss: 0.042491938918828964
step: 280, loss: 0.03202882409095764
step: 290, loss: 0.01749257743358612
step: 300, loss: 0.04289628192782402
step: 310, loss: 0.006471604574471712
step: 320, loss: 0.13142795860767365
step: 330, loss: 0.09159502387046814
step: 340, loss: 0.006164600141346455
step: 350, loss: 0.007301135919988155
step: 360, loss: 0.018399907276034355
step: 370, loss: 0.03471418097615242
step: 380, loss: 0.03698714077472687
step: 390, loss: 0.04408800229430199
step: 400, loss: 0.05253760144114494
step: 410, loss: 0.02374144457280636
step: 420, loss: 0.06848889589309692
step: 430, loss: 0.06274174898862839
step: 440, loss: 0.03477237746119499
step: 450, loss: 0.002245376817882061
step: 460, loss: 0.03946216404438019
step: 470, loss: 0.09378758817911148
step: 480, loss: 0.053112711757421494
step: 490, loss: 0.03459760919213295
step: 500, loss: 0.1331801563501358
step: 510, loss: 0.06002125144004822
step: 520, loss: 0.025563839823007584
step: 530, loss: 0.07533785700798035
step: 540, loss: 0.018466463312506676
step: 550, loss: 0.0008158511482179165
step: 560, loss: 0.060263849794864655
step: 570, loss: 0.041138991713523865
step: 580, loss: 0.00388774904422462
step: 590, loss: 0.03206495940685272
step: 600, loss: 0.04827863350510597
step: 610, loss: 0.05377913638949394
step: 620, loss: 0.02232450433075428
step: 630, loss: 3.054927583434619e-05
step: 640, loss: 0.0031791571527719498
step: 650, loss: 0.08856578171253204
step: 660, loss: 0.03473307192325592
step: 670, loss: 0.05424227938055992
step: 680, loss: 0.021857423707842827
step: 690, loss: 0.221157044172287
step: 700, loss: 0.11852257698774338
step: 710, loss: 0.01925624907016754
step: 720, loss: 0.02285612002015114
step: 730, loss: 0.0757823958992958
step: 740, loss: 0.01930374652147293
step: 750, loss: 0.011888396926224232
step: 760, loss: 0.001461196574382484
step: 770, loss: 0.0005126143805682659
step: 780, loss: 0.06030639633536339
step: 790, loss: 0.1341235488653183
step: 800, loss: 0.02842900902032852
step: 810, loss: 0.0073718903586268425
step: 820, loss: 0.09776241332292557
step: 830, loss: 0.012945135124027729
step: 840, loss: 0.08346916735172272
step: 850, loss: 0.03185814619064331
step: 860, loss: 0.048612408339977264
step: 870, loss: 0.0016581084346398711
step: 880, loss: 0.009524350054562092
step: 890, loss: 0.006452949717640877
step: 900, loss: 0.033958181738853455
step: 910, loss: 0.061597466468811035
step: 920, loss: 0.017964011058211327
step: 930, loss: 0.014965001493692398
step: 940, loss: 0.027468711137771606
step: 950, loss: 0.01685722917318344
step: 960, loss: 0.027274250984191895
step: 970, loss: 0.022753456607460976
step: 980, loss: 0.028628941625356674
step: 990, loss: 0.014960555359721184
step: 1000, loss: 0.03155720233917236
step: 1010, loss: 0.044753849506378174
step: 1020, loss: 0.014961148612201214
step: 1030, loss: 0.05115591362118721
step: 1040, loss: 0.01971551589667797
step: 1050, loss: 0.02253660373389721
step: 1060, loss: 0.001709455857053399
step: 1070, loss: 0.10254031419754028
epoch 12: dev_f1=0.9322820037105751, f1=0.9357374017568193, best_f1=0.9303184125519152
step: 0, loss: 0.023840565234422684
step: 10, loss: 0.02130873315036297
step: 20, loss: 0.0039961556904017925
step: 30, loss: 0.031084585934877396
step: 40, loss: 0.05009821802377701
step: 50, loss: 0.06486765295267105
step: 60, loss: 0.05816153436899185
step: 70, loss: 0.03370823711156845
step: 80, loss: 0.08892886340618134
step: 90, loss: 2.7443516955827363e-05
step: 100, loss: 0.022861959412693977
step: 110, loss: 0.039734672755002975
step: 120, loss: 0.05284634977579117
step: 130, loss: 0.057339709252119064
step: 140, loss: 0.07177989929914474
step: 150, loss: 0.022194908931851387
step: 160, loss: 0.09534504264593124
step: 170, loss: 0.022812889888882637
step: 180, loss: 0.053950924426317215
step: 190, loss: 0.00023277761647477746
step: 200, loss: 0.04388970881700516
step: 210, loss: 0.019155550748109818
step: 220, loss: 0.001338296104222536
step: 230, loss: 0.04589473083615303
step: 240, loss: 0.15664994716644287
step: 250, loss: 0.05878980830311775
step: 260, loss: 0.016047516837716103
step: 270, loss: 0.017615672200918198
step: 280, loss: 0.035053323954343796
step: 290, loss: 0.04021216928958893
step: 300, loss: 0.0009439447894692421
step: 310, loss: 0.0006392999202944338
step: 320, loss: 0.02199522592127323
step: 330, loss: 0.016093311831355095
step: 340, loss: 0.009757368825376034
step: 350, loss: 0.014576665125787258
step: 360, loss: 0.024815119802951813
step: 370, loss: 0.009175091050565243
step: 380, loss: 3.061233655898832e-05
step: 390, loss: 0.06010611727833748
step: 400, loss: 0.005492554046213627
step: 410, loss: 0.054396212100982666
step: 420, loss: 0.07429227232933044
step: 430, loss: 0.010056667029857635
step: 440, loss: 0.056162137538194656
step: 450, loss: 0.03577495366334915
step: 460, loss: 6.309030868578702e-05
step: 470, loss: 0.020720193162560463
step: 480, loss: 0.00020002257952000946
step: 490, loss: 0.003436862025409937
step: 500, loss: 0.004331963136792183
step: 510, loss: 0.08457959443330765
step: 520, loss: 0.14581257104873657
step: 530, loss: 0.0687950924038887
step: 540, loss: 0.07625013589859009
step: 550, loss: 0.04146156087517738
step: 560, loss: 0.04734758660197258
step: 570, loss: 0.07997814565896988
step: 580, loss: 0.0017447759164497256
step: 590, loss: 0.11585387587547302
step: 600, loss: 0.022749202325940132
step: 610, loss: 0.05318683758378029
step: 620, loss: 0.03584016487002373
step: 630, loss: 0.001210738206282258
step: 640, loss: 0.004973223898559809
step: 650, loss: 0.00015427330799866468
step: 660, loss: 0.02641991525888443
step: 670, loss: 0.001630806247703731
step: 680, loss: 0.0032215819228440523
step: 690, loss: 0.04570429027080536
step: 700, loss: 0.017347797751426697
step: 710, loss: 0.03969930112361908
step: 720, loss: 0.0038510304875671864
step: 730, loss: 0.04232493042945862
step: 740, loss: 0.0003114888386335224
step: 750, loss: 0.00011695508874254301
step: 760, loss: 0.023066196590662003
step: 770, loss: 0.04514181986451149
step: 780, loss: 0.008051592856645584
step: 790, loss: 0.05641103535890579
step: 800, loss: 0.020492438226938248
step: 810, loss: 0.03348692134022713
step: 820, loss: 0.035567473620176315
step: 830, loss: 4.079045538674109e-05
step: 840, loss: 0.13925881683826447
step: 850, loss: 0.041828811168670654
step: 860, loss: 0.03956061601638794
step: 870, loss: 0.09571374207735062
step: 880, loss: 0.00095743453130126
step: 890, loss: 0.003880805801600218
step: 900, loss: 0.08230482786893845
step: 910, loss: 0.0005034712376073003
step: 920, loss: 0.026767123490571976
step: 930, loss: 4.165328937233426e-05
step: 940, loss: 0.0022268916945904493
step: 950, loss: 0.0006119957542978227
step: 960, loss: 0.03569816052913666
step: 970, loss: 0.040698591619729996
step: 980, loss: 0.000406089355237782
step: 990, loss: 0.00013559090439230204
step: 1000, loss: 0.037393856793642044
step: 1010, loss: 0.128418430685997
step: 1020, loss: 0.05573228746652603
step: 1030, loss: 0.009084729477763176
step: 1040, loss: 0.025719307363033295
step: 1050, loss: 0.022817227989435196
step: 1060, loss: 0.04922826588153839
step: 1070, loss: 0.01609901338815689
epoch 13: dev_f1=0.9348729792147806, f1=0.9301470588235294, best_f1=0.9303184125519152
step: 0, loss: 0.08991564065217972
step: 10, loss: 0.06863231956958771
step: 20, loss: 0.010909468866884708
step: 30, loss: 0.02620258368551731
step: 40, loss: 0.03789912909269333
step: 50, loss: 0.009853051975369453
step: 60, loss: 0.010966014117002487
step: 70, loss: 0.09027077257633209
step: 80, loss: 0.004657037556171417
step: 90, loss: 0.05418897420167923
step: 100, loss: 0.06276401877403259
step: 110, loss: 0.00013884225336369127
step: 120, loss: 0.041401613503694534
step: 130, loss: 0.028884457424283028
step: 140, loss: 0.00041150383185595274
step: 150, loss: 0.00025269718025811017
step: 160, loss: 0.045325879007577896
step: 170, loss: 0.028836624696850777
step: 180, loss: 0.042361896485090256
step: 190, loss: 2.7811807740363292e-05
step: 200, loss: 0.05759627744555473
step: 210, loss: 0.004009126219898462
step: 220, loss: 7.71040067775175e-05
step: 230, loss: 0.01071702316403389
step: 240, loss: 0.02111653797328472
step: 250, loss: 0.029749872162938118
step: 260, loss: 0.004385991487652063
step: 270, loss: 0.07224886864423752
step: 280, loss: 7.343362085521221e-05
step: 290, loss: 0.06705198436975479
step: 300, loss: 0.013852379284799099
step: 310, loss: 2.636905264807865e-05
step: 320, loss: 0.0221079271286726
step: 330, loss: 0.049325618892908096
step: 340, loss: 0.0636843889951706
step: 350, loss: 0.007096735294908285
step: 360, loss: 0.0667218342423439
step: 370, loss: 0.07332894951105118
step: 380, loss: 0.0006816359236836433
step: 390, loss: 0.041557423770427704
step: 400, loss: 0.0017480967799201608
step: 410, loss: 0.047776393592357635
step: 420, loss: 0.05470864474773407
step: 430, loss: 0.03748396411538124
step: 440, loss: 0.03821706771850586
step: 450, loss: 0.05158451944589615
step: 460, loss: 0.18917132914066315
step: 470, loss: 0.033954769372940063
step: 480, loss: 0.04594172164797783
step: 490, loss: 0.08313745260238647
step: 500, loss: 0.026949899271130562
step: 510, loss: 0.0955890417098999
step: 520, loss: 0.07349830865859985
step: 530, loss: 0.08744926005601883
step: 540, loss: 0.08495155721902847
step: 550, loss: 0.023093776777386665
step: 560, loss: 0.02339271828532219
step: 570, loss: 0.0046761613339185715
step: 580, loss: 0.04092300683259964
step: 590, loss: 0.029773171991109848
step: 600, loss: 0.07085705548524857
step: 610, loss: 0.006868711207062006
step: 620, loss: 0.06339436769485474
step: 630, loss: 0.0003818593977484852
step: 640, loss: 7.452803401974961e-05
step: 650, loss: 0.04701927304267883
step: 660, loss: 0.009270685724914074
step: 670, loss: 0.09082694351673126
step: 680, loss: 0.0006792386993765831
step: 690, loss: 0.059053607285022736
step: 700, loss: 0.014316877350211143
step: 710, loss: 0.09752814471721649
step: 720, loss: 0.019731977954506874
step: 730, loss: 0.0001985615526791662
step: 740, loss: 0.026325684040784836
step: 750, loss: 0.016605086624622345
step: 760, loss: 0.011622505262494087
step: 770, loss: 0.03732150420546532
step: 780, loss: 0.07468278706073761
step: 790, loss: 0.0005767599795944989
step: 800, loss: 0.04401245340704918
step: 810, loss: 0.016873300075531006
step: 820, loss: 0.004235077649354935
step: 830, loss: 0.026995845139026642
step: 840, loss: 0.0767773687839508
step: 850, loss: 0.000707241881173104
step: 860, loss: 0.025966422632336617
step: 870, loss: 0.04523337632417679
step: 880, loss: 0.003291897941380739
step: 890, loss: 0.0230840053409338
step: 900, loss: 0.041352614760398865
step: 910, loss: 0.000585560395848006
step: 920, loss: 3.729373202077113e-05
step: 930, loss: 5.9282501752022654e-05
step: 940, loss: 0.03495705872774124
step: 950, loss: 2.0067798686795868e-05
step: 960, loss: 0.030138568952679634
step: 970, loss: 0.022380370646715164
step: 980, loss: 0.02555696666240692
step: 990, loss: 0.12383582442998886
step: 1000, loss: 0.038058165460824966
step: 1010, loss: 0.03880416229367256
step: 1020, loss: 0.017069516703486443
step: 1030, loss: 0.059066448360681534
step: 1040, loss: 0.07830679416656494
step: 1050, loss: 0.091497503221035
step: 1060, loss: 0.026658061891794205
step: 1070, loss: 0.015647264197468758
epoch 14: dev_f1=0.9365225390984362, f1=0.9280806229958772, best_f1=0.9303184125519152
step: 0, loss: 0.050793036818504333
step: 10, loss: 0.028654836118221283
step: 20, loss: 1.9344723114045337e-05
step: 30, loss: 0.00016304364544339478
step: 40, loss: 0.023782093077898026
step: 50, loss: 0.014075390063226223
step: 60, loss: 9.93804496829398e-05
step: 70, loss: 0.00023494442575611174
step: 80, loss: 0.0812680721282959
step: 90, loss: 2.368056811974384e-05
step: 100, loss: 0.036866091191768646
step: 110, loss: 0.22341348230838776
step: 120, loss: 0.0046492633409798145
step: 130, loss: 0.03327789902687073
step: 140, loss: 0.009914887137711048
step: 150, loss: 8.678701124154031e-05
step: 160, loss: 0.13945423066616058
step: 170, loss: 0.01910034567117691
step: 180, loss: 0.0502457320690155
step: 190, loss: 0.021615851670503616
step: 200, loss: 0.019006652757525444
step: 210, loss: 6.72965616104193e-05
step: 220, loss: 0.0025329438503831625
step: 230, loss: 0.06266021728515625
step: 240, loss: 0.00044331944081932306
step: 250, loss: 0.009270244278013706
step: 260, loss: 0.0225644763559103
step: 270, loss: 3.157283936161548e-05
step: 280, loss: 0.01783241517841816
step: 290, loss: 0.0057943654246628284
step: 300, loss: 0.008670233190059662
step: 310, loss: 0.02046775259077549
step: 320, loss: 0.013095345348119736
step: 330, loss: 0.014721807092428207
step: 340, loss: 0.046991463750600815
step: 350, loss: 0.01948380284011364
step: 360, loss: 0.004923528991639614
step: 370, loss: 0.03023350052535534
step: 380, loss: 0.02758963033556938
step: 390, loss: 5.573325324803591e-05
step: 400, loss: 0.04603516682982445
step: 410, loss: 0.020246997475624084
step: 420, loss: 3.4395863622194156e-05
step: 430, loss: 0.01600625179708004
step: 440, loss: 0.0073260897770524025
step: 450, loss: 0.015650611370801926
step: 460, loss: 0.04595425724983215
step: 470, loss: 0.03751743584871292
step: 480, loss: 0.0003482788451947272
step: 490, loss: 0.06543667614459991
step: 500, loss: 0.05133715644478798
step: 510, loss: 0.055586762726306915
step: 520, loss: 0.007736916188150644
step: 530, loss: 2.8194313927087933e-05
step: 540, loss: 2.100955680361949e-05
step: 550, loss: 0.03378041088581085
step: 560, loss: 0.022651629522442818
step: 570, loss: 0.020714055746793747
step: 580, loss: 0.033730264753103256
step: 590, loss: 0.0009717329521663487
step: 600, loss: 0.062324896454811096
step: 610, loss: 0.0010188507148995996
step: 620, loss: 0.07835832983255386
step: 630, loss: 0.0307956263422966
step: 640, loss: 0.03705504909157753
step: 650, loss: 2.993810994667001e-05
step: 660, loss: 0.01828043721616268
step: 670, loss: 0.02746134251356125
step: 680, loss: 0.04627703130245209
step: 690, loss: 0.02025749161839485
step: 700, loss: 0.05533543974161148
step: 710, loss: 3.340046532684937e-05
step: 720, loss: 0.012250353582203388
step: 730, loss: 0.07469150424003601
step: 740, loss: 0.00473109632730484
step: 750, loss: 0.0403251126408577
step: 760, loss: 0.008152380585670471
step: 770, loss: 0.10459129512310028
step: 780, loss: 0.03303851559758186
step: 790, loss: 0.016059212386608124
step: 800, loss: 0.046642787754535675
step: 810, loss: 0.029699435457587242
step: 820, loss: 0.0021681166253983974
step: 830, loss: 0.09916824102401733
step: 840, loss: 1.3098000636091456e-05
step: 850, loss: 0.029367787763476372
step: 860, loss: 0.0001012725115288049
step: 870, loss: 0.03109978884458542
step: 880, loss: 0.03883805125951767
step: 890, loss: 4.71267121611163e-05
step: 900, loss: 0.024938981980085373
step: 910, loss: 0.01760263182222843
step: 920, loss: 0.020315222442150116
step: 930, loss: 7.089326390996575e-05
step: 940, loss: 0.0667906180024147
step: 950, loss: 0.02711513079702854
step: 960, loss: 0.04682095721364021
step: 970, loss: 0.02896076999604702
step: 980, loss: 0.0007137273205444217
step: 990, loss: 0.0360267236828804
step: 1000, loss: 0.029119282960891724
step: 1010, loss: 0.003943056333810091
step: 1020, loss: 0.030666125938296318
step: 1030, loss: 0.04667286202311516
step: 1040, loss: 0.02482524700462818
step: 1050, loss: 0.14390824735164642
step: 1060, loss: 0.01560214627534151
step: 1070, loss: 0.08939450234174728
epoch 15: dev_f1=0.9338235294117647, f1=0.9278538812785389, best_f1=0.9303184125519152
step: 0, loss: 0.038368403911590576
step: 10, loss: 0.010599304921925068
step: 20, loss: 0.06710851937532425
step: 30, loss: 0.03588234260678291
step: 40, loss: 0.01447962038218975
step: 50, loss: 0.0319245308637619
step: 60, loss: 0.03917890787124634
step: 70, loss: 0.11172952502965927
step: 80, loss: 0.05590420588850975
step: 90, loss: 0.1259274184703827
step: 100, loss: 2.3218710339278914e-05
step: 110, loss: 0.02318335324525833
step: 120, loss: 0.01153755746781826
step: 130, loss: 0.05103365704417229
step: 140, loss: 0.014439176768064499
step: 150, loss: 0.03486868366599083
step: 160, loss: 0.031204484403133392
step: 170, loss: 0.021537283435463905
step: 180, loss: 0.06935756653547287
step: 190, loss: 0.06124800816178322
step: 200, loss: 0.13502132892608643
step: 210, loss: 0.01199976447969675
step: 220, loss: 0.021693894639611244
step: 230, loss: 0.06084079295396805
step: 240, loss: 5.001286626793444e-05
step: 250, loss: 7.431613630615175e-05
step: 260, loss: 0.03163113072514534
step: 270, loss: 0.007838216610252857
step: 280, loss: 0.05765923485159874
step: 290, loss: 0.043088480830192566
step: 300, loss: 0.058740582317113876
step: 310, loss: 0.07579488307237625
step: 320, loss: 0.045001305639743805
step: 330, loss: 0.024192189797759056
step: 340, loss: 0.037098489701747894
step: 350, loss: 0.02274765446782112
step: 360, loss: 6.984669744269922e-05
step: 370, loss: 1.642813549551647e-05
step: 380, loss: 0.02286973036825657
step: 390, loss: 0.03512030467391014
step: 400, loss: 3.362957068020478e-05
step: 410, loss: 0.09964413195848465
step: 420, loss: 0.06907127797603607
step: 430, loss: 0.016820760443806648
step: 440, loss: 0.02133902534842491
step: 450, loss: 0.03759199380874634
step: 460, loss: 0.06692253798246384
step: 470, loss: 0.12409531325101852
step: 480, loss: 0.02288845181465149
step: 490, loss: 0.00017429317813366652
step: 500, loss: 0.01753194071352482
step: 510, loss: 0.018084291368722916
step: 520, loss: 0.07064750045537949
step: 530, loss: 0.03650324419140816
step: 540, loss: 0.08517534285783768
step: 550, loss: 0.01701757125556469
step: 560, loss: 0.005651910789310932
step: 570, loss: 0.024297118186950684
step: 580, loss: 0.16598699986934662
step: 590, loss: 0.00014416636258829385
step: 600, loss: 0.040356408804655075
step: 610, loss: 0.023244639858603477
step: 620, loss: 0.016738340258598328
step: 630, loss: 0.031530849635601044
step: 640, loss: 0.04832901433110237
step: 650, loss: 0.037235431373119354
step: 660, loss: 0.020019182935357094
step: 670, loss: 0.018388602882623672
step: 680, loss: 0.04502836987376213
step: 690, loss: 0.06801657378673553
step: 700, loss: 0.010944626294076443
step: 710, loss: 0.06487293541431427
step: 720, loss: 0.06529784947633743
step: 730, loss: 0.002101724036037922
step: 740, loss: 0.019727513194084167
step: 750, loss: 0.001187248039059341
step: 760, loss: 0.0033297305926680565
step: 770, loss: 0.10060364007949829
step: 780, loss: 0.04414210468530655
step: 790, loss: 0.04035898298025131
step: 800, loss: 0.0525662861764431
step: 810, loss: 0.04872184246778488
step: 820, loss: 0.0596950426697731
step: 830, loss: 0.03910896182060242
step: 840, loss: 0.0021533966064453125
step: 850, loss: 0.07595623284578323
step: 860, loss: 0.028103411197662354
step: 870, loss: 0.07565588504076004
step: 880, loss: 0.00025606804410927
step: 890, loss: 0.000186686243978329
step: 900, loss: 0.022225869819521904
step: 910, loss: 3.513358751661144e-05
step: 920, loss: 0.0019511606078594923
step: 930, loss: 0.03569716587662697
step: 940, loss: 0.015277779661118984
step: 950, loss: 0.02498256042599678
step: 960, loss: 0.021741850301623344
step: 970, loss: 0.049496572464704514
step: 980, loss: 0.0798419862985611
step: 990, loss: 0.022348247468471527
step: 1000, loss: 0.003511581104248762
step: 1010, loss: 0.022095929831266403
step: 1020, loss: 0.035928256809711456
step: 1030, loss: 0.0924237072467804
step: 1040, loss: 0.0075005642138421535
step: 1050, loss: 0.08930062502622604
step: 1060, loss: 0.07757657021284103
step: 1070, loss: 0.006326616276055574
epoch 16: dev_f1=0.9328460484239378, f1=0.9219600725952812, best_f1=0.9303184125519152
step: 0, loss: 0.009987669065594673
step: 10, loss: 0.010851535946130753
step: 20, loss: 0.0001335615961579606
step: 30, loss: 0.0412200465798378
step: 40, loss: 0.05623317137360573
step: 50, loss: 1.8003887817030773e-05
step: 60, loss: 0.12179212272167206
step: 70, loss: 0.019925614818930626
step: 80, loss: 0.007649037521332502
step: 90, loss: 0.038654815405607224
step: 100, loss: 0.0001026870304485783
step: 110, loss: 0.04381744936108589
step: 120, loss: 0.04866637662053108
step: 130, loss: 0.0003600843483582139
step: 140, loss: 0.09484840929508209
step: 150, loss: 0.0013625919818878174
step: 160, loss: 3.764116991078481e-05
step: 170, loss: 0.11869398504495621
step: 180, loss: 0.018769606947898865
step: 190, loss: 0.03079909086227417
step: 200, loss: 0.0019280543783679605
step: 210, loss: 0.07275746762752533
step: 220, loss: 0.05693204328417778
step: 230, loss: 0.00018892883963417262
step: 240, loss: 0.04275434836745262
step: 250, loss: 2.8492602723417804e-05
step: 260, loss: 0.06022252142429352
step: 270, loss: 0.04354686662554741
step: 280, loss: 0.023807674646377563
step: 290, loss: 0.03988669812679291
step: 300, loss: 0.03906601667404175
step: 310, loss: 0.021146010607481003
step: 320, loss: 0.03948557749390602
step: 330, loss: 0.022357380017638206
step: 340, loss: 0.012721585109829903
step: 350, loss: 0.052083633840084076
step: 360, loss: 9.313486225437373e-05
step: 370, loss: 0.010531803593039513
step: 380, loss: 0.09391404688358307
step: 390, loss: 0.0030945290345698595
step: 400, loss: 0.015972502529621124
step: 410, loss: 0.05749887228012085
step: 420, loss: 0.02001640573143959
step: 430, loss: 0.05329350009560585
step: 440, loss: 0.006096114404499531
step: 450, loss: 0.001074811676517129
step: 460, loss: 2.2748285118723288e-05
step: 470, loss: 0.0437285341322422
step: 480, loss: 0.0035197229590266943
step: 490, loss: 0.019242921844124794
step: 500, loss: 0.03404257446527481
step: 510, loss: 0.07091204822063446
step: 520, loss: 7.87175667937845e-05
step: 530, loss: 0.05102069303393364
step: 540, loss: 0.07353896647691727
step: 550, loss: 0.040114663541316986
step: 560, loss: 0.059175312519073486
step: 570, loss: 0.0067912195809185505
step: 580, loss: 0.034452442079782486
step: 590, loss: 0.007310028187930584
step: 600, loss: 0.0068077812902629375
step: 610, loss: 0.001735488185659051
step: 620, loss: 0.08040907979011536
step: 630, loss: 0.03273541480302811
step: 640, loss: 1.7620141079532914e-05
step: 650, loss: 0.04792772978544235
step: 660, loss: 0.06926540285348892
step: 670, loss: 0.07301168143749237
step: 680, loss: 0.06362800300121307
step: 690, loss: 0.00012662772496696562
step: 700, loss: 2.371396476519294e-05
step: 710, loss: 0.015706047415733337
step: 720, loss: 0.00016481545753777027
step: 730, loss: 3.4062300983350724e-05
step: 740, loss: 0.0020038941875100136
step: 750, loss: 0.0760081484913826
step: 760, loss: 1.7571745047462173e-05
step: 770, loss: 0.027723737061023712
step: 780, loss: 0.041739027947187424
step: 790, loss: 0.04443616420030594
step: 800, loss: 0.021832238882780075
step: 810, loss: 0.02955300360918045
step: 820, loss: 0.03605473041534424
step: 830, loss: 8.114620868582278e-05
step: 840, loss: 0.025343293324112892
step: 850, loss: 0.018714888021349907
step: 860, loss: 0.03712337464094162
step: 870, loss: 0.04822227731347084
step: 880, loss: 0.002105646301060915
step: 890, loss: 0.00037569654523395
step: 900, loss: 0.02921489253640175
step: 910, loss: 0.01652904786169529
step: 920, loss: 0.0002554546808823943
step: 930, loss: 0.015393003821372986
step: 940, loss: 1.6025944205466658e-05
step: 950, loss: 0.000765852106269449
step: 960, loss: 0.020748088136315346
step: 970, loss: 0.01886683888733387
step: 980, loss: 0.06503164768218994
step: 990, loss: 0.02373027242720127
step: 1000, loss: 0.04906619340181351
step: 1010, loss: 0.04384739324450493
step: 1020, loss: 6.947015936020762e-05
step: 1030, loss: 0.020504429936408997
step: 1040, loss: 0.02645704336464405
step: 1050, loss: 0.027289582416415215
step: 1060, loss: 0.023796193301677704
step: 1070, loss: 0.1364777684211731
epoch 17: dev_f1=0.9326614750343564, f1=0.9224489795918368, best_f1=0.9303184125519152
step: 0, loss: 0.022885624319314957
step: 10, loss: 0.0011698363814502954
step: 20, loss: 0.056356560438871384
step: 30, loss: 0.0628909096121788
step: 40, loss: 5.7691693655215204e-05
step: 50, loss: 0.00467944098636508
step: 60, loss: 0.0416254885494709
step: 70, loss: 0.050336435437202454
step: 80, loss: 0.04489470273256302
step: 90, loss: 0.04691864177584648
step: 100, loss: 0.0827501192688942
step: 110, loss: 0.008853686973452568
step: 120, loss: 0.06529016047716141
step: 130, loss: 0.010782724246382713
step: 140, loss: 0.025029491633176804
step: 150, loss: 2.298783147125505e-05
step: 160, loss: 0.04944337159395218
step: 170, loss: 0.044651832431554794
step: 180, loss: 0.014013751409947872
step: 190, loss: 0.02009001560509205
step: 200, loss: 0.032678164541721344
step: 210, loss: 2.712192690523807e-05
step: 220, loss: 0.038111910223960876
step: 230, loss: 0.043885041028261185
step: 240, loss: 0.027930228039622307
step: 250, loss: 0.023344403132796288
step: 260, loss: 0.046487029641866684
step: 270, loss: 1.5902953236945905e-05
step: 280, loss: 0.03764284774661064
step: 290, loss: 0.09805921465158463
step: 300, loss: 0.00016579967632424086
step: 310, loss: 0.01620970107614994
step: 320, loss: 0.0005102161085233092
step: 330, loss: 0.03700985014438629
step: 340, loss: 0.022633176296949387
step: 350, loss: 0.043987490236759186
step: 360, loss: 2.9986393201397732e-05
step: 370, loss: 0.005688513163477182
step: 380, loss: 0.052215881645679474
step: 390, loss: 0.03446558490395546
step: 400, loss: 0.018025562167167664
step: 410, loss: 1.6618183508398943e-05
step: 420, loss: 0.000142602133564651
step: 430, loss: 7.805885979905725e-05
step: 440, loss: 0.041798993945121765
step: 450, loss: 7.607830775668845e-05
step: 460, loss: 0.010375682264566422
step: 470, loss: 2.6660709409043193e-05
step: 480, loss: 0.013582016341388226
step: 490, loss: 0.05210866779088974
step: 500, loss: 0.060472846031188965
step: 510, loss: 0.03894688934087753
step: 520, loss: 0.016511013731360435
step: 530, loss: 0.010911417193710804
step: 540, loss: 0.021123673766851425
step: 550, loss: 0.03233306109905243
step: 560, loss: 0.013658436015248299
step: 570, loss: 0.0029292081017047167
step: 580, loss: 0.008608049713075161
step: 590, loss: 0.021516205742955208
step: 600, loss: 0.03159497678279877
step: 610, loss: 0.020777516067028046
step: 620, loss: 0.04558229446411133
step: 630, loss: 0.021932395175099373
step: 640, loss: 0.047343287616968155
step: 650, loss: 0.003449744079262018
step: 660, loss: 0.00017922781989909708
step: 670, loss: 0.015197444707155228
step: 680, loss: 0.0003090167883783579
step: 690, loss: 0.006741911172866821
step: 700, loss: 0.07633616775274277
step: 710, loss: 0.06434714794158936
step: 720, loss: 0.019486078992486
step: 730, loss: 2.5792714950512163e-05
step: 740, loss: 0.031052937731146812
step: 750, loss: 0.0053294384852051735
step: 760, loss: 0.044615816324949265
step: 770, loss: 0.00024596028379164636
step: 780, loss: 0.1091369017958641
step: 790, loss: 0.02791845053434372
step: 800, loss: 0.00028130077407695353
step: 810, loss: 0.030094221234321594
step: 820, loss: 0.024712303653359413
step: 830, loss: 0.04270879179239273
step: 840, loss: 0.02480945736169815
step: 850, loss: 0.05562592297792435
step: 860, loss: 0.04482457786798477
step: 870, loss: 0.043290309607982635
step: 880, loss: 0.024119606241583824
step: 890, loss: 0.030379919335246086
step: 900, loss: 1.9400937162572518e-05
step: 910, loss: 0.020019562914967537
step: 920, loss: 0.0031201690435409546
step: 930, loss: 0.024885190650820732
step: 940, loss: 7.7483055065386e-05
step: 950, loss: 0.021187638863921165
step: 960, loss: 0.0568997897207737
step: 970, loss: 0.08554720133543015
step: 980, loss: 0.04172876477241516
step: 990, loss: 0.029355930164456367
step: 1000, loss: 0.0006771207554265857
step: 1010, loss: 0.060237713158130646
step: 1020, loss: 0.02651796117424965
step: 1030, loss: 0.032355405390262604
step: 1040, loss: 0.06971108168363571
step: 1050, loss: 0.000686952262185514
step: 1060, loss: 9.653342567617074e-05
step: 1070, loss: 0.021544504910707474
epoch 18: dev_f1=0.9328392774432608, f1=0.923076923076923, best_f1=0.9303184125519152
step: 0, loss: 0.015194945968687534
step: 10, loss: 0.0009428044431842864
step: 20, loss: 0.029248304665088654
step: 30, loss: 0.04889773577451706
step: 40, loss: 0.04110973700881004
step: 50, loss: 0.00046183160156942904
step: 60, loss: 0.0429878793656826
step: 70, loss: 0.07481798529624939
step: 80, loss: 0.01845398359000683
step: 90, loss: 0.020281536504626274
step: 100, loss: 0.0003353288338985294
step: 110, loss: 0.028388410806655884
step: 120, loss: 0.015534872189164162
step: 130, loss: 0.08695519715547562
step: 140, loss: 0.00939272716641426
step: 150, loss: 0.021280407905578613
step: 160, loss: 0.04709218814969063
step: 170, loss: 1.682685069681611e-05
step: 180, loss: 0.03825684264302254
step: 190, loss: 0.10569068789482117
step: 200, loss: 6.36883924016729e-05
step: 210, loss: 0.02728095091879368
step: 220, loss: 0.01904660277068615
step: 230, loss: 2.321869760635309e-05
step: 240, loss: 0.0008315201266668737
step: 250, loss: 4.140557939535938e-05
step: 260, loss: 0.07607437670230865
step: 270, loss: 0.017925387248396873
step: 280, loss: 0.0002249675162602216
step: 290, loss: 0.013904678635299206
step: 300, loss: 0.0001621673727640882
step: 310, loss: 0.03449680656194687
step: 320, loss: 0.024356326088309288
step: 330, loss: 0.01894809864461422
step: 340, loss: 0.02492751181125641
step: 350, loss: 0.06417424231767654
step: 360, loss: 1.8852790162782185e-05
step: 370, loss: 0.059354547411203384
step: 380, loss: 0.0015415900852531195
step: 390, loss: 7.792691758368164e-05
step: 400, loss: 0.040768515318632126
step: 410, loss: 0.06576504558324814
step: 420, loss: 0.00018210358393844217
step: 430, loss: 0.02459223009645939
step: 440, loss: 0.07346662878990173
step: 450, loss: 0.06008144095540047
step: 460, loss: 2.8385131372488104e-05
step: 470, loss: 0.04344647377729416
step: 480, loss: 0.09091097116470337
step: 490, loss: 0.06208641454577446
step: 500, loss: 0.03685465082526207
step: 510, loss: 0.07946722954511642
step: 520, loss: 4.927034751744941e-05
step: 530, loss: 4.347061621956527e-05
step: 540, loss: 0.01747754029929638
step: 550, loss: 0.039713867008686066
step: 560, loss: 0.0283653661608696
step: 570, loss: 0.04821174591779709
step: 580, loss: 0.0011678137816488743
step: 590, loss: 9.579421748640016e-05
step: 600, loss: 1.2338047781668138e-05
step: 610, loss: 0.038980841636657715
step: 620, loss: 0.0008852124447003007
step: 630, loss: 0.024526096880435944
step: 640, loss: 0.02591310814023018
step: 650, loss: 0.0001111006858991459
step: 660, loss: 0.021479561924934387
step: 670, loss: 2.9025404728599824e-05
step: 680, loss: 3.608688712120056e-05
step: 690, loss: 5.409559526015073e-05
step: 700, loss: 0.03190884366631508
step: 710, loss: 0.00011625976912910119
step: 720, loss: 0.05201801657676697
step: 730, loss: 0.0018296317430213094
step: 740, loss: 2.003781628445722e-05
step: 750, loss: 0.016493458300828934
step: 760, loss: 0.015758920460939407
step: 770, loss: 0.013215561397373676
step: 780, loss: 0.021709058433771133
step: 790, loss: 0.010583207942545414
step: 800, loss: 1.3373543879424687e-05
step: 810, loss: 0.10287202894687653
step: 820, loss: 0.05636540427803993
step: 830, loss: 0.02214757166802883
step: 840, loss: 0.0776931419968605
step: 850, loss: 0.014214984141290188
step: 860, loss: 0.03484547883272171
step: 870, loss: 0.06369706988334656
step: 880, loss: 0.004767272155731916
step: 890, loss: 0.001341851195320487
step: 900, loss: 0.021618321537971497
step: 910, loss: 0.08419829607009888
step: 920, loss: 0.021823303773999214
step: 930, loss: 0.04196004942059517
step: 940, loss: 0.01870727352797985
step: 950, loss: 0.059175025671720505
step: 960, loss: 0.10473649203777313
step: 970, loss: 0.00025156940682791173
step: 980, loss: 0.030029762536287308
step: 990, loss: 3.4783508453983814e-05
step: 1000, loss: 0.003140742192044854
step: 1010, loss: 0.01934361830353737
step: 1020, loss: 0.020604224875569344
step: 1030, loss: 3.72715039702598e-05
step: 1040, loss: 0.022148581221699715
step: 1050, loss: 1.3477971151587553e-05
step: 1060, loss: 0.0200954619795084
step: 1070, loss: 0.060468778014183044
epoch 19: dev_f1=0.9327102803738317, f1=0.9262371615312792, best_f1=0.9303184125519152
step: 0, loss: 0.0003179439518135041
step: 10, loss: 0.04141923412680626
step: 20, loss: 0.006947492249310017
step: 30, loss: 0.019642647355794907
step: 40, loss: 0.03299255669116974
step: 50, loss: 0.0804443359375
step: 60, loss: 0.022892288863658905
step: 70, loss: 0.04292858764529228
step: 80, loss: 0.1035182848572731
step: 90, loss: 0.003854571608826518
step: 100, loss: 3.425955947022885e-05
step: 110, loss: 0.07319975644350052
step: 120, loss: 2.995816794282291e-05
step: 130, loss: 0.018554337322711945
step: 140, loss: 0.00022138454369269311
step: 150, loss: 0.04784337803721428
step: 160, loss: 0.0010494792368263006
step: 170, loss: 0.022022519260644913
step: 180, loss: 0.023336010053753853
step: 190, loss: 0.05486604571342468
step: 200, loss: 0.0011406209086999297
step: 210, loss: 0.03989261016249657
step: 220, loss: 0.0014950867043808103
step: 230, loss: 0.06571519374847412
step: 240, loss: 0.04420609399676323
step: 250, loss: 0.04378513991832733
step: 260, loss: 0.025089360773563385
step: 270, loss: 0.0009727003052830696
step: 280, loss: 3.280578675912693e-05
step: 290, loss: 0.046793583780527115
step: 300, loss: 0.03633242845535278
step: 310, loss: 0.0002371063019381836
step: 320, loss: 0.001409970922395587
step: 330, loss: 0.03914118930697441
step: 340, loss: 1.4040399946679827e-05
step: 350, loss: 0.026592543348670006
step: 360, loss: 0.0419301763176918
step: 370, loss: 5.191175660002045e-05
step: 380, loss: 0.052853070199489594
step: 390, loss: 0.025797836482524872
step: 400, loss: 0.017793139442801476
step: 410, loss: 2.0928013327647932e-05
step: 420, loss: 0.00010093083255924284
step: 430, loss: 2.346094152017031e-05
step: 440, loss: 0.018309563398361206
step: 450, loss: 1.3854167264071293e-05
step: 460, loss: 0.017057744786143303
step: 470, loss: 0.044740211218595505
step: 480, loss: 0.03179672732949257
step: 490, loss: 0.035880591720342636
step: 500, loss: 0.021572906523942947
step: 510, loss: 0.020353930070996284
step: 520, loss: 0.02803826332092285
step: 530, loss: 0.02031433768570423
step: 540, loss: 0.028891708701848984
step: 550, loss: 0.020370179787278175
step: 560, loss: 0.010592148639261723
step: 570, loss: 0.023450398817658424
step: 580, loss: 0.059998996555805206
step: 590, loss: 1.9370427253306843e-05
step: 600, loss: 0.022070422768592834
step: 610, loss: 0.00620631780475378
step: 620, loss: 0.02705357037484646
step: 630, loss: 0.002067658817395568
step: 640, loss: 0.04762596637010574
step: 650, loss: 0.07148124277591705
step: 660, loss: 0.026221051812171936
step: 670, loss: 0.018722837790846825
step: 680, loss: 0.04746837913990021
step: 690, loss: 0.0008730180561542511
step: 700, loss: 0.019338741898536682
step: 710, loss: 0.022285273298621178
step: 720, loss: 0.0001569218875374645
step: 730, loss: 0.0034874258562922478
step: 740, loss: 0.05441772937774658
step: 750, loss: 0.0006587416282854974
step: 760, loss: 0.02554275095462799
step: 770, loss: 0.07071594148874283
step: 780, loss: 0.06723307073116302
step: 790, loss: 0.0015572577249258757
step: 800, loss: 0.04441337287425995
step: 810, loss: 0.029658755287528038
step: 820, loss: 0.00015482913295272738
step: 830, loss: 0.05018303915858269
step: 840, loss: 0.02857177145779133
step: 850, loss: 0.04585842043161392
step: 860, loss: 2.5374778488185257e-05
step: 870, loss: 0.012399165891110897
step: 880, loss: 0.016230138018727303
step: 890, loss: 0.044645629823207855
step: 900, loss: 0.03586040809750557
step: 910, loss: 5.929705730522983e-05
step: 920, loss: 0.06527616828680038
step: 930, loss: 0.07216934114694595
step: 940, loss: 0.02736840397119522
step: 950, loss: 0.04705369845032692
step: 960, loss: 0.04837043210864067
step: 970, loss: 0.01306060142815113
step: 980, loss: 0.00041956669883802533
step: 990, loss: 2.807705277518835e-05
step: 1000, loss: 0.026669088751077652
step: 1010, loss: 0.0001431534910807386
step: 1020, loss: 0.01605980098247528
step: 1030, loss: 0.08565628528594971
step: 1040, loss: 4.971149974153377e-05
step: 1050, loss: 0.005672052502632141
step: 1060, loss: 0.0003240907972212881
step: 1070, loss: 0.02535891905426979
epoch 20: dev_f1=0.9328984156570364, f1=0.9271461716937355, best_f1=0.9303184125519152
