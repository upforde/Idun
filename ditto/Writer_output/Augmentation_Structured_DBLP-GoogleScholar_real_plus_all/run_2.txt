cuda
Device: cuda
step: 0, loss: 0.6047321557998657
step: 10, loss: 0.4220230281352997
step: 20, loss: 0.40958431363105774
step: 30, loss: 0.4400685131549835
step: 40, loss: 0.2677919268608093
step: 50, loss: 0.35504457354545593
step: 60, loss: 0.3101513385772705
step: 70, loss: 0.30966708064079285
step: 80, loss: 0.1218206062912941
step: 90, loss: 0.18825410306453705
step: 100, loss: 0.3326634466648102
step: 110, loss: 0.1791602224111557
step: 120, loss: 0.336936354637146
step: 130, loss: 0.18406721949577332
step: 140, loss: 0.24753277003765106
step: 150, loss: 0.18108287453651428
step: 160, loss: 0.22841858863830566
step: 170, loss: 0.21388788521289825
step: 180, loss: 0.08152812719345093
step: 190, loss: 0.21593372523784637
step: 200, loss: 0.15265542268753052
step: 210, loss: 0.1033242866396904
step: 220, loss: 0.04161129146814346
step: 230, loss: 0.13045047223567963
step: 240, loss: 0.31973567605018616
step: 250, loss: 0.2139393538236618
step: 260, loss: 0.3520095646381378
step: 270, loss: 0.16882477700710297
step: 280, loss: 0.24586118757724762
step: 290, loss: 0.11856953054666519
step: 300, loss: 0.1747318059206009
step: 310, loss: 0.02492351457476616
step: 320, loss: 0.26261618733406067
step: 330, loss: 0.10961727052927017
step: 340, loss: 0.11141324043273926
step: 350, loss: 0.22366049885749817
step: 360, loss: 0.06192930042743683
step: 370, loss: 0.14762014150619507
step: 380, loss: 0.1496438831090927
step: 390, loss: 0.16892895102500916
step: 400, loss: 0.08909715712070465
step: 410, loss: 0.23672924935817719
step: 420, loss: 0.08227674663066864
step: 430, loss: 0.2714444398880005
step: 440, loss: 0.07246662676334381
step: 450, loss: 0.210993230342865
step: 460, loss: 0.26421234011650085
step: 470, loss: 0.08309144526720047
step: 480, loss: 0.0917980819940567
step: 490, loss: 0.05646691098809242
step: 500, loss: 0.13745397329330444
step: 510, loss: 0.047590117901563644
step: 520, loss: 0.018490232527256012
step: 530, loss: 0.06324342638254166
step: 540, loss: 0.26269441843032837
step: 550, loss: 0.1308661550283432
step: 560, loss: 0.19868245720863342
step: 570, loss: 0.09567185491323471
step: 580, loss: 0.095703125
step: 590, loss: 0.0677412673830986
step: 600, loss: 0.05181067809462547
step: 610, loss: 0.11555779725313187
step: 620, loss: 0.23122167587280273
step: 630, loss: 0.013600464910268784
step: 640, loss: 0.06792784482240677
step: 650, loss: 0.11285271495580673
step: 660, loss: 0.14297328889369965
step: 670, loss: 0.1647288203239441
step: 680, loss: 0.044254399836063385
step: 690, loss: 0.2462955266237259
step: 700, loss: 0.1356937289237976
step: 710, loss: 0.20585522055625916
step: 720, loss: 0.08013187348842621
step: 730, loss: 0.13118931651115417
step: 740, loss: 0.1593451052904129
step: 750, loss: 0.04407888650894165
step: 760, loss: 0.10290266573429108
step: 770, loss: 0.2043362706899643
step: 780, loss: 0.1267305314540863
step: 790, loss: 0.1198737770318985
step: 800, loss: 0.20636563003063202
step: 810, loss: 0.13300752639770508
step: 820, loss: 0.26681458950042725
step: 830, loss: 0.12430670112371445
step: 840, loss: 0.140784353017807
step: 850, loss: 0.11061447858810425
step: 860, loss: 0.0598861388862133
step: 870, loss: 0.09907015413045883
step: 880, loss: 0.11855550855398178
step: 890, loss: 0.13850170373916626
step: 900, loss: 0.2860739231109619
step: 910, loss: 0.12599624693393707
step: 920, loss: 0.1416020393371582
step: 930, loss: 0.09355674684047699
step: 940, loss: 0.16060414910316467
step: 950, loss: 0.031003013253211975
step: 960, loss: 0.24881677329540253
step: 970, loss: 0.12201537936925888
step: 980, loss: 0.03829484060406685
step: 990, loss: 0.11789029836654663
step: 1000, loss: 0.1322880983352661
step: 1010, loss: 0.05869705602526665
step: 1020, loss: 0.012154195457696915
step: 1030, loss: 0.09368610382080078
step: 1040, loss: 0.05480734258890152
step: 1050, loss: 0.15686263144016266
step: 1060, loss: 0.24144870042800903
step: 1070, loss: 0.1555836945772171
epoch 1: dev_f1=0.9155756207674943, f1=0.9179440937781785, best_f1=0.9179440937781785
step: 0, loss: 0.05749238282442093
step: 10, loss: 0.08516301214694977
step: 20, loss: 0.10964158177375793
step: 30, loss: 0.06625797599554062
step: 40, loss: 0.01976296864449978
step: 50, loss: 0.06502439826726913
step: 60, loss: 0.14713139832019806
step: 70, loss: 0.14305441081523895
step: 80, loss: 0.03549486771225929
step: 90, loss: 0.20182788372039795
step: 100, loss: 0.06315193325281143
step: 110, loss: 0.09163665771484375
step: 120, loss: 0.09558234363794327
step: 130, loss: 0.05834048241376877
step: 140, loss: 0.027342507615685463
step: 150, loss: 0.1329030990600586
step: 160, loss: 0.07256627082824707
step: 170, loss: 0.09641431272029877
step: 180, loss: 0.18121127784252167
step: 190, loss: 0.04890778288245201
step: 200, loss: 0.1239495575428009
step: 210, loss: 0.20251764357089996
step: 220, loss: 0.03158409520983696
step: 230, loss: 0.07955548167228699
step: 240, loss: 0.16403865814208984
step: 250, loss: 0.14574535191059113
step: 260, loss: 0.11731795966625214
step: 270, loss: 0.026953378692269325
step: 280, loss: 0.08177737891674042
step: 290, loss: 0.15200495719909668
step: 300, loss: 0.010133928619325161
step: 310, loss: 0.09125421941280365
step: 320, loss: 0.06431373208761215
step: 330, loss: 0.07802169024944305
step: 340, loss: 0.0746011883020401
step: 350, loss: 0.02156003750860691
step: 360, loss: 0.19899146258831024
step: 370, loss: 0.25423896312713623
step: 380, loss: 0.1337735801935196
step: 390, loss: 0.1028519719839096
step: 400, loss: 0.11676598340272903
step: 410, loss: 0.16077640652656555
step: 420, loss: 0.07319232076406479
step: 430, loss: 0.08255218714475632
step: 440, loss: 0.3250274062156677
step: 450, loss: 0.05287458747625351
step: 460, loss: 0.1298770010471344
step: 470, loss: 0.028449302539229393
step: 480, loss: 0.03929699957370758
step: 490, loss: 0.07358323782682419
step: 500, loss: 0.02992657572031021
step: 510, loss: 0.21663981676101685
step: 520, loss: 0.03196640685200691
step: 530, loss: 0.10375603288412094
step: 540, loss: 0.2208588719367981
step: 550, loss: 0.10037536919116974
step: 560, loss: 0.2048400491476059
step: 570, loss: 0.09168949723243713
step: 580, loss: 0.027887027710676193
step: 590, loss: 0.034288935363292694
step: 600, loss: 0.04840477555990219
step: 610, loss: 0.15676440298557281
step: 620, loss: 0.03328952193260193
step: 630, loss: 0.16759440302848816
step: 640, loss: 0.12554298341274261
step: 650, loss: 0.08616043627262115
step: 660, loss: 0.1756821572780609
step: 670, loss: 0.07744654268026352
step: 680, loss: 0.14833709597587585
step: 690, loss: 0.08876166492700577
step: 700, loss: 0.07329437136650085
step: 710, loss: 0.08163426071405411
step: 720, loss: 0.10288234055042267
step: 730, loss: 0.05991162359714508
step: 740, loss: 0.15057945251464844
step: 750, loss: 0.032066263258457184
step: 760, loss: 0.10810742527246475
step: 770, loss: 0.07265646010637283
step: 780, loss: 0.18645332753658295
step: 790, loss: 0.0627540796995163
step: 800, loss: 0.15276283025741577
step: 810, loss: 0.09214271605014801
step: 820, loss: 0.1487250179052353
step: 830, loss: 0.018473604694008827
step: 840, loss: 0.08416827023029327
step: 850, loss: 0.20466449856758118
step: 860, loss: 0.10055872797966003
step: 870, loss: 0.03654850646853447
step: 880, loss: 0.02493828348815441
step: 890, loss: 0.008305483497679234
step: 900, loss: 0.23867982625961304
step: 910, loss: 0.14974725246429443
step: 920, loss: 0.09087643772363663
step: 930, loss: 0.022565050050616264
step: 940, loss: 0.11070196330547333
step: 950, loss: 0.008368893526494503
step: 960, loss: 0.0327763557434082
step: 970, loss: 0.04415430501103401
step: 980, loss: 0.09056858718395233
step: 990, loss: 0.12421224266290665
step: 1000, loss: 0.08525512367486954
step: 1010, loss: 0.0651160478591919
step: 1020, loss: 0.06944602727890015
step: 1030, loss: 0.15793971717357635
step: 1040, loss: 0.0870293527841568
step: 1050, loss: 0.06157926097512245
step: 1060, loss: 0.14072029292583466
step: 1070, loss: 0.06713739037513733
epoch 2: dev_f1=0.918572735590119, f1=0.923216719672876, best_f1=0.923216719672876
step: 0, loss: 0.114019475877285
step: 10, loss: 0.05738081783056259
step: 20, loss: 0.13482357561588287
step: 30, loss: 0.14755180478096008
step: 40, loss: 0.13065429031848907
step: 50, loss: 0.025641951709985733
step: 60, loss: 0.04631455987691879
step: 70, loss: 0.12847399711608887
step: 80, loss: 0.0008750183042138815
step: 90, loss: 0.011208631098270416
step: 100, loss: 0.017285387963056564
step: 110, loss: 0.0328260101377964
step: 120, loss: 0.024154189974069595
step: 130, loss: 0.022215746343135834
step: 140, loss: 0.018994944170117378
step: 150, loss: 0.10022013634443283
step: 160, loss: 0.0962749645113945
step: 170, loss: 0.039659127593040466
step: 180, loss: 0.07491639256477356
step: 190, loss: 0.07325316965579987
step: 200, loss: 0.048265837132930756
step: 210, loss: 0.043901097029447556
step: 220, loss: 0.03697558119893074
step: 230, loss: 0.08740333467721939
step: 240, loss: 0.05746294558048248
step: 250, loss: 0.0789446234703064
step: 260, loss: 0.02688615396618843
step: 270, loss: 0.12492061406373978
step: 280, loss: 0.06260155886411667
step: 290, loss: 0.19540327787399292
step: 300, loss: 0.1332743763923645
step: 310, loss: 0.03443508222699165
step: 320, loss: 0.09004921466112137
step: 330, loss: 0.08701341599225998
step: 340, loss: 0.15964893996715546
step: 350, loss: 0.033188968896865845
step: 360, loss: 0.06032823771238327
step: 370, loss: 0.04582832381129265
step: 380, loss: 0.03312062472105026
step: 390, loss: 0.08088671416044235
step: 400, loss: 0.031891994178295135
step: 410, loss: 0.043736401945352554
step: 420, loss: 0.06524231284856796
step: 430, loss: 0.047150131314992905
step: 440, loss: 0.1180734857916832
step: 450, loss: 0.14361582696437836
step: 460, loss: 0.007218017242848873
step: 470, loss: 0.026300208643078804
step: 480, loss: 0.09008986502885818
step: 490, loss: 0.17597146332263947
step: 500, loss: 0.1838926076889038
step: 510, loss: 0.1311492770910263
step: 520, loss: 0.1362496316432953
step: 530, loss: 0.0777706652879715
step: 540, loss: 0.06593412160873413
step: 550, loss: 0.05450214445590973
step: 560, loss: 0.023815995082259178
step: 570, loss: 0.038820717483758926
step: 580, loss: 0.06219959259033203
step: 590, loss: 0.009642988443374634
step: 600, loss: 0.06491384655237198
step: 610, loss: 0.0703471377491951
step: 620, loss: 0.03841261565685272
step: 630, loss: 0.1069522425532341
step: 640, loss: 0.18979540467262268
step: 650, loss: 0.1049347072839737
step: 660, loss: 0.05197571590542793
step: 670, loss: 0.0480906143784523
step: 680, loss: 0.06624485552310944
step: 690, loss: 0.09506837278604507
step: 700, loss: 0.11278380453586578
step: 710, loss: 0.09571292996406555
step: 720, loss: 0.03288719803094864
step: 730, loss: 0.01603657193481922
step: 740, loss: 0.05170297622680664
step: 750, loss: 0.03958139941096306
step: 760, loss: 0.0521865114569664
step: 770, loss: 0.18309316039085388
step: 780, loss: 0.12736812233924866
step: 790, loss: 0.07684071362018585
step: 800, loss: 0.03154495358467102
step: 810, loss: 0.3390909731388092
step: 820, loss: 0.04935155808925629
step: 830, loss: 0.21895818412303925
step: 840, loss: 0.04738392308354378
step: 850, loss: 0.10127708315849304
step: 860, loss: 0.024295371025800705
step: 870, loss: 0.042387522757053375
step: 880, loss: 0.02449292689561844
step: 890, loss: 0.03259970620274544
step: 900, loss: 0.14658211171627045
step: 910, loss: 0.09780462831258774
step: 920, loss: 0.10040418803691864
step: 930, loss: 0.10333313792943954
step: 940, loss: 0.1747894287109375
step: 950, loss: 0.12025136500597
step: 960, loss: 0.10931504517793655
step: 970, loss: 0.07390356808900833
step: 980, loss: 0.10267157852649689
step: 990, loss: 0.10149292647838593
step: 1000, loss: 0.14141377806663513
step: 1010, loss: 0.10057757049798965
step: 1020, loss: 0.11276402324438095
step: 1030, loss: 0.11520104855298996
step: 1040, loss: 0.044403575360774994
step: 1050, loss: 0.19108541309833527
step: 1060, loss: 0.07913826406002045
step: 1070, loss: 0.053729552775621414
epoch 3: dev_f1=0.9335154826958107, f1=0.9301903898458749, best_f1=0.9301903898458749
step: 0, loss: 0.04340539872646332
step: 10, loss: 0.3317210078239441
step: 20, loss: 0.023056739941239357
step: 30, loss: 0.004962407983839512
step: 40, loss: 0.13849817216396332
step: 50, loss: 0.025824788957834244
step: 60, loss: 0.029890943318605423
step: 70, loss: 0.01606711372733116
step: 80, loss: 0.03773904964327812
step: 90, loss: 0.08404570072889328
step: 100, loss: 0.09273561835289001
step: 110, loss: 0.08969426155090332
step: 120, loss: 0.003755769692361355
step: 130, loss: 0.04080171883106232
step: 140, loss: 0.04357461631298065
step: 150, loss: 0.05956368148326874
step: 160, loss: 0.12571805715560913
step: 170, loss: 0.0587729886174202
step: 180, loss: 0.09786481410264969
step: 190, loss: 0.026611629873514175
step: 200, loss: 0.07864825427532196
step: 210, loss: 0.03664366155862808
step: 220, loss: 0.15504547953605652
step: 230, loss: 0.08602597564458847
step: 240, loss: 0.006577866617590189
step: 250, loss: 0.061165787279605865
step: 260, loss: 0.1002415269613266
step: 270, loss: 0.10241908580064774
step: 280, loss: 0.06292621791362762
step: 290, loss: 0.05885868892073631
step: 300, loss: 0.053257741034030914
step: 310, loss: 0.08150318264961243
step: 320, loss: 0.06040282920002937
step: 330, loss: 0.06888091564178467
step: 340, loss: 0.10378023982048035
step: 350, loss: 0.04189935326576233
step: 360, loss: 0.017419669777154922
step: 370, loss: 0.09274256974458694
step: 380, loss: 0.10000468790531158
step: 390, loss: 0.13171835243701935
step: 400, loss: 0.11042381078004837
step: 410, loss: 0.010246127843856812
step: 420, loss: 0.0174331646412611
step: 430, loss: 0.20814578235149384
step: 440, loss: 0.03157461807131767
step: 450, loss: 0.05189066380262375
step: 460, loss: 0.1803668886423111
step: 470, loss: 0.013451382517814636
step: 480, loss: 0.0626802071928978
step: 490, loss: 0.011873302981257439
step: 500, loss: 0.35054120421409607
step: 510, loss: 0.08890172094106674
step: 520, loss: 0.07855280488729477
step: 530, loss: 0.00995292142033577
step: 540, loss: 0.06001599505543709
step: 550, loss: 0.13865819573402405
step: 560, loss: 0.10518437623977661
step: 570, loss: 0.0461893230676651
step: 580, loss: 0.060669802129268646
step: 590, loss: 0.11126921325922012
step: 600, loss: 0.08721359074115753
step: 610, loss: 0.009152425453066826
step: 620, loss: 0.06643307954072952
step: 630, loss: 0.019424084573984146
step: 640, loss: 0.035679418593645096
step: 650, loss: 0.07692413777112961
step: 660, loss: 0.08732142299413681
step: 670, loss: 0.11143093556165695
step: 680, loss: 0.0010927439434453845
step: 690, loss: 0.18307431042194366
step: 700, loss: 0.0061494107358157635
step: 710, loss: 0.0225965678691864
step: 720, loss: 0.1023259088397026
step: 730, loss: 0.017396505922079086
step: 740, loss: 0.09029651433229446
step: 750, loss: 0.013751920312643051
step: 760, loss: 0.051626622676849365
step: 770, loss: 0.06481892615556717
step: 780, loss: 0.05925396829843521
step: 790, loss: 0.010410834103822708
step: 800, loss: 0.09673407673835754
step: 810, loss: 0.0649043396115303
step: 820, loss: 0.1528417021036148
step: 830, loss: 0.048258520662784576
step: 840, loss: 0.02092866599559784
step: 850, loss: 0.0904407873749733
step: 860, loss: 0.009008918888866901
step: 870, loss: 0.04643625766038895
step: 880, loss: 0.039331451058387756
step: 890, loss: 0.06870236992835999
step: 900, loss: 0.022581767290830612
step: 910, loss: 0.10221582651138306
step: 920, loss: 0.030389631167054176
step: 930, loss: 0.04162220656871796
step: 940, loss: 0.06339583545923233
step: 950, loss: 0.10853640735149384
step: 960, loss: 0.08667066693305969
step: 970, loss: 0.1252506524324417
step: 980, loss: 0.15397103130817413
step: 990, loss: 0.006436364725232124
step: 1000, loss: 0.028778068721294403
step: 1010, loss: 0.16489583253860474
step: 1020, loss: 0.22814425826072693
step: 1030, loss: 0.09866856038570404
step: 1040, loss: 0.07176384329795837
step: 1050, loss: 0.09298738092184067
step: 1060, loss: 0.11298355460166931
step: 1070, loss: 0.16854719817638397
epoch 4: dev_f1=0.9330905780609924, f1=0.9337568058076225, best_f1=0.9301903898458749
step: 0, loss: 0.013697287067770958
step: 10, loss: 0.04224890470504761
step: 20, loss: 0.1627003401517868
step: 30, loss: 0.0700632631778717
step: 40, loss: 0.014589311555027962
step: 50, loss: 0.03967564180493355
step: 60, loss: 0.04349702224135399
step: 70, loss: 0.03504963964223862
step: 80, loss: 0.0492163710296154
step: 90, loss: 0.02244589291512966
step: 100, loss: 0.11081929504871368
step: 110, loss: 0.16939881443977356
step: 120, loss: 0.03507322445511818
step: 130, loss: 0.051578719168901443
step: 140, loss: 0.07468556612730026
step: 150, loss: 0.07283668965101242
step: 160, loss: 0.045586030930280685
step: 170, loss: 0.0826985165476799
step: 180, loss: 0.011613922193646431
step: 190, loss: 0.011059483513236046
step: 200, loss: 0.05901578813791275
step: 210, loss: 0.03825237229466438
step: 220, loss: 0.10641361027956009
step: 230, loss: 0.14294491708278656
step: 240, loss: 0.01944098062813282
step: 250, loss: 0.02986888773739338
step: 260, loss: 0.013620160520076752
step: 270, loss: 0.0049830274656414986
step: 280, loss: 0.11621477454900742
step: 290, loss: 0.0023681691382080317
step: 300, loss: 0.029312362894415855
step: 310, loss: 0.09748787432909012
step: 320, loss: 0.08695018291473389
step: 330, loss: 0.060620736330747604
step: 340, loss: 0.02996818907558918
step: 350, loss: 0.08548367023468018
step: 360, loss: 0.06830821931362152
step: 370, loss: 0.058570630848407745
step: 380, loss: 0.0931917205452919
step: 390, loss: 0.03941667824983597
step: 400, loss: 0.00752668734639883
step: 410, loss: 0.01173738669604063
step: 420, loss: 0.06752805411815643
step: 430, loss: 0.014624363742768764
step: 440, loss: 0.01672901026904583
step: 450, loss: 0.016472505405545235
step: 460, loss: 0.08265529572963715
step: 470, loss: 0.013754433952271938
step: 480, loss: 0.1177491545677185
step: 490, loss: 0.05618143454194069
step: 500, loss: 0.040415070950984955
step: 510, loss: 0.006758613046258688
step: 520, loss: 0.011978784576058388
step: 530, loss: 0.04915187880396843
step: 540, loss: 0.046746864914894104
step: 550, loss: 0.01622149348258972
step: 560, loss: 0.01601123809814453
step: 570, loss: 0.05008884519338608
step: 580, loss: 0.014831793494522572
step: 590, loss: 0.08825384825468063
step: 600, loss: 0.01242736354470253
step: 610, loss: 0.06483559310436249
step: 620, loss: 0.04991239309310913
step: 630, loss: 0.12099172919988632
step: 640, loss: 0.023111335933208466
step: 650, loss: 0.12202571332454681
step: 660, loss: 0.06249883025884628
step: 670, loss: 0.02831512689590454
step: 680, loss: 0.06089121103286743
step: 690, loss: 0.049765244126319885
step: 700, loss: 0.11357804387807846
step: 710, loss: 0.13378240168094635
step: 720, loss: 0.07583977282047272
step: 730, loss: 0.07921750098466873
step: 740, loss: 0.05620085075497627
step: 750, loss: 0.1416652649641037
step: 760, loss: 0.07346825301647186
step: 770, loss: 0.0778486430644989
step: 780, loss: 0.06545581668615341
step: 790, loss: 0.09310203045606613
step: 800, loss: 0.07288675755262375
step: 810, loss: 0.045825328677892685
step: 820, loss: 0.04032387211918831
step: 830, loss: 0.019570333883166313
step: 840, loss: 0.053085993975400925
step: 850, loss: 0.037189699709415436
step: 860, loss: 0.05306422710418701
step: 870, loss: 0.02513793297111988
step: 880, loss: 0.0361127145588398
step: 890, loss: 0.02301918715238571
step: 900, loss: 0.048260647803545
step: 910, loss: 0.024148236960172653
step: 920, loss: 0.16638915240764618
step: 930, loss: 0.011778522282838821
step: 940, loss: 0.027734071016311646
step: 950, loss: 0.01974417269229889
step: 960, loss: 0.04345228523015976
step: 970, loss: 0.006881961598992348
step: 980, loss: 0.06965913623571396
step: 990, loss: 0.13869965076446533
step: 1000, loss: 0.091270312666893
step: 1010, loss: 0.030520666390657425
step: 1020, loss: 0.044161610305309296
step: 1030, loss: 0.06321050971746445
step: 1040, loss: 0.004990185610949993
step: 1050, loss: 0.11483806371688843
step: 1060, loss: 0.08773539960384369
step: 1070, loss: 0.038355372846126556
epoch 5: dev_f1=0.9344490934449092, f1=0.9271889400921659, best_f1=0.9271889400921659
step: 0, loss: 0.10076431930065155
step: 10, loss: 0.08901765197515488
step: 20, loss: 0.07254084199666977
step: 30, loss: 0.02851800248026848
step: 40, loss: 0.02347017079591751
step: 50, loss: 0.11402256041765213
step: 60, loss: 0.026647035032510757
step: 70, loss: 0.05555468797683716
step: 80, loss: 0.0835195779800415
step: 90, loss: 0.08457139879465103
step: 100, loss: 0.017569102346897125
step: 110, loss: 0.024286948144435883
step: 120, loss: 0.02780451439321041
step: 130, loss: 0.06367882341146469
step: 140, loss: 0.07804117351770401
step: 150, loss: 0.011841890402138233
step: 160, loss: 0.0528985895216465
step: 170, loss: 0.07196537405252457
step: 180, loss: 0.0779559388756752
step: 190, loss: 0.06656607240438461
step: 200, loss: 0.15126484632492065
step: 210, loss: 0.08521272987127304
step: 220, loss: 0.009383942931890488
step: 230, loss: 0.023914309218525887
step: 240, loss: 0.11202527582645416
step: 250, loss: 0.019787486642599106
step: 260, loss: 0.006575112231075764
step: 270, loss: 0.1307181417942047
step: 280, loss: 0.026383547112345695
step: 290, loss: 0.09857987612485886
step: 300, loss: 0.021022703498601913
step: 310, loss: 0.022327782586216927
step: 320, loss: 0.09042917937040329
step: 330, loss: 0.06745488941669464
step: 340, loss: 0.07673841714859009
step: 350, loss: 0.08788175880908966
step: 360, loss: 0.013232797384262085
step: 370, loss: 0.0881553664803505
step: 380, loss: 0.015970071777701378
step: 390, loss: 0.06469165533781052
step: 400, loss: 0.08158910274505615
step: 410, loss: 0.05204567313194275
step: 420, loss: 0.08331845700740814
step: 430, loss: 0.1125558391213417
step: 440, loss: 0.006597973871976137
step: 450, loss: 0.01684711128473282
step: 460, loss: 0.01900242269039154
step: 470, loss: 0.060748837888240814
step: 480, loss: 0.07817303389310837
step: 490, loss: 0.16147533059120178
step: 500, loss: 0.04001331701874733
step: 510, loss: 0.10136868804693222
step: 520, loss: 0.13307100534439087
step: 530, loss: 0.004781521391123533
step: 540, loss: 0.10259899497032166
step: 550, loss: 0.04824584349989891
step: 560, loss: 0.006743361242115498
step: 570, loss: 0.06516868621110916
step: 580, loss: 0.05875731632113457
step: 590, loss: 0.011166906915605068
step: 600, loss: 0.010996413417160511
step: 610, loss: 0.12692764401435852
step: 620, loss: 0.01674705557525158
step: 630, loss: 0.03105420432984829
step: 640, loss: 0.08784046769142151
step: 650, loss: 0.04785066097974777
step: 660, loss: 0.05950360745191574
step: 670, loss: 0.06922872364521027
step: 680, loss: 0.03277689218521118
step: 690, loss: 0.007371677551418543
step: 700, loss: 0.02192709408700466
step: 710, loss: 0.024931591004133224
step: 720, loss: 0.19174392521381378
step: 730, loss: 0.022998034954071045
step: 740, loss: 0.004497109446674585
step: 750, loss: 0.032852787524461746
step: 760, loss: 0.0024262990336865187
step: 770, loss: 0.14230510592460632
step: 780, loss: 0.1280844658613205
step: 790, loss: 0.13365335762500763
step: 800, loss: 0.09724073112010956
step: 810, loss: 0.12191419303417206
step: 820, loss: 0.010354205965995789
step: 830, loss: 0.12932634353637695
step: 840, loss: 0.025327168405056
step: 850, loss: 0.031024815514683723
step: 860, loss: 0.04347579553723335
step: 870, loss: 0.02574741095304489
step: 880, loss: 0.09561160951852798
step: 890, loss: 0.004820949397981167
step: 900, loss: 0.026403555646538734
step: 910, loss: 0.01610168069601059
step: 920, loss: 0.00013180525274947286
step: 930, loss: 0.11770414561033249
step: 940, loss: 0.2242424190044403
step: 950, loss: 0.037183769047260284
step: 960, loss: 0.013849684968590736
step: 970, loss: 0.02336883544921875
step: 980, loss: 0.015169871971011162
step: 990, loss: 0.03148440271615982
step: 1000, loss: 0.05120474472641945
step: 1010, loss: 0.06476780772209167
step: 1020, loss: 0.013838967308402061
step: 1030, loss: 0.04224494472146034
step: 1040, loss: 0.11956953257322311
step: 1050, loss: 0.1665920466184616
step: 1060, loss: 0.07391872256994247
step: 1070, loss: 0.014474730007350445
epoch 6: dev_f1=0.9325323475046211, f1=0.9310027598896043, best_f1=0.9271889400921659
step: 0, loss: 0.06807292252779007
step: 10, loss: 0.07927916944026947
step: 20, loss: 0.08192247897386551
step: 30, loss: 0.08708769083023071
step: 40, loss: 0.015922479331493378
step: 50, loss: 0.04574200510978699
step: 60, loss: 0.01433496829122305
step: 70, loss: 0.009466501884162426
step: 80, loss: 0.014868068508803844
step: 90, loss: 0.020326385274529457
step: 100, loss: 0.08914189040660858
step: 110, loss: 0.06238120049238205
step: 120, loss: 0.06991253048181534
step: 130, loss: 0.05127662792801857
step: 140, loss: 0.04975326359272003
step: 150, loss: 0.12291441857814789
step: 160, loss: 0.04676111787557602
step: 170, loss: 0.08203673362731934
step: 180, loss: 0.15537625551223755
step: 190, loss: 0.08190708607435226
step: 200, loss: 0.028728557750582695
step: 210, loss: 0.03542238101363182
step: 220, loss: 0.08919176459312439
step: 230, loss: 0.004906706046313047
step: 240, loss: 0.035477541387081146
step: 250, loss: 0.026423783972859383
step: 260, loss: 0.2769962549209595
step: 270, loss: 0.10947193950414658
step: 280, loss: 0.04933922737836838
step: 290, loss: 0.046570926904678345
step: 300, loss: 0.018033279106020927
step: 310, loss: 0.01100942026823759
step: 320, loss: 0.03680895268917084
step: 330, loss: 0.005641565192490816
step: 340, loss: 0.009602958336472511
step: 350, loss: 0.11998570710420609
step: 360, loss: 0.024685200303792953
step: 370, loss: 0.017498496919870377
step: 380, loss: 0.03733760118484497
step: 390, loss: 0.20414778590202332
step: 400, loss: 0.04145828261971474
step: 410, loss: 0.15269440412521362
step: 420, loss: 0.038240574300289154
step: 430, loss: 0.014849470928311348
step: 440, loss: 0.011671386659145355
step: 450, loss: 0.032345231622457504
step: 460, loss: 0.02702217735350132
step: 470, loss: 0.00020580254204105586
step: 480, loss: 0.0888642892241478
step: 490, loss: 0.009102998301386833
step: 500, loss: 0.019279930740594864
step: 510, loss: 0.023524122312664986
step: 520, loss: 0.0831216499209404
step: 530, loss: 0.07958587259054184
step: 540, loss: 0.011328224092721939
step: 550, loss: 0.13600513339042664
step: 560, loss: 0.07443726807832718
step: 570, loss: 0.013410926796495914
step: 580, loss: 0.04409436881542206
step: 590, loss: 0.02691962569952011
step: 600, loss: 0.062340859323740005
step: 610, loss: 0.05206798017024994
step: 620, loss: 0.04611530154943466
step: 630, loss: 0.193649023771286
step: 640, loss: 0.07276102900505066
step: 650, loss: 0.07646629214286804
step: 660, loss: 0.005472111981362104
step: 670, loss: 0.20362290740013123
step: 680, loss: 0.07378413528203964
step: 690, loss: 0.017454830929636955
step: 700, loss: 0.027491454035043716
step: 710, loss: 0.0245459396392107
step: 720, loss: 0.06415842473506927
step: 730, loss: 0.3513745665550232
step: 740, loss: 0.005597535986453295
step: 750, loss: 0.1476127952337265
step: 760, loss: 0.12076692283153534
step: 770, loss: 0.05403779819607735
step: 780, loss: 0.03565758839249611
step: 790, loss: 0.008594473823904991
step: 800, loss: 0.002596414415165782
step: 810, loss: 0.10172032564878464
step: 820, loss: 0.07526960223913193
step: 830, loss: 0.0525517500936985
step: 840, loss: 0.04275209829211235
step: 850, loss: 0.022979548200964928
step: 860, loss: 0.042240966111421585
step: 870, loss: 0.18190287053585052
step: 880, loss: 0.05441209673881531
step: 890, loss: 0.014036791399121284
step: 900, loss: 0.02079252526164055
step: 910, loss: 0.043849218636751175
step: 920, loss: 0.03339947760105133
step: 930, loss: 0.010729579254984856
step: 940, loss: 0.04773132503032684
step: 950, loss: 0.06589145958423615
step: 960, loss: 0.11820156127214432
step: 970, loss: 0.13281118869781494
step: 980, loss: 0.057114724069833755
step: 990, loss: 0.0490981750190258
step: 1000, loss: 0.005392263177782297
step: 1010, loss: 0.0070053404197096825
step: 1020, loss: 0.022651808336377144
step: 1030, loss: 0.13812404870986938
step: 1040, loss: 0.019743388518691063
step: 1050, loss: 0.04494015499949455
step: 1060, loss: 0.012136304751038551
step: 1070, loss: 0.1355447620153427
epoch 7: dev_f1=0.9297197978870005, f1=0.9312557286892759, best_f1=0.9271889400921659
step: 0, loss: 0.06452631205320358
step: 10, loss: 0.03485328331589699
step: 20, loss: 0.01626288704574108
step: 30, loss: 0.021316027268767357
step: 40, loss: 0.0705837607383728
step: 50, loss: 0.022106517106294632
step: 60, loss: 0.04641855135560036
step: 70, loss: 0.04984034597873688
step: 80, loss: 0.019097616896033287
step: 90, loss: 0.1312461644411087
step: 100, loss: 0.0749121680855751
step: 110, loss: 0.06612527370452881
step: 120, loss: 0.026560479775071144
step: 130, loss: 0.036427974700927734
step: 140, loss: 0.042169272899627686
step: 150, loss: 0.006339374464005232
step: 160, loss: 0.09951328486204147
step: 170, loss: 0.06223678961396217
step: 180, loss: 0.04155384376645088
step: 190, loss: 0.015866409987211227
step: 200, loss: 0.08944389969110489
step: 210, loss: 0.0720464363694191
step: 220, loss: 0.01820102147758007
step: 230, loss: 0.037907883524894714
step: 240, loss: 0.22304119169712067
step: 250, loss: 0.08454116433858871
step: 260, loss: 0.03267654776573181
step: 270, loss: 0.04582242667675018
step: 280, loss: 0.19763688743114471
step: 290, loss: 0.09051145613193512
step: 300, loss: 0.004693531896919012
step: 310, loss: 0.06339758634567261
step: 320, loss: 0.07032144069671631
step: 330, loss: 6.435243267333135e-05
step: 340, loss: 0.036311324685811996
step: 350, loss: 0.011091615073382854
step: 360, loss: 0.00520463939756155
step: 370, loss: 0.03727380558848381
step: 380, loss: 0.0007882486679591238
step: 390, loss: 0.066788449883461
step: 400, loss: 0.07252971082925797
step: 410, loss: 0.012398689985275269
step: 420, loss: 0.09500530362129211
step: 430, loss: 0.050570763647556305
step: 440, loss: 0.08076533675193787
step: 450, loss: 0.09974966198205948
step: 460, loss: 0.028089258819818497
step: 470, loss: 5.713621430913918e-05
step: 480, loss: 0.010804673656821251
step: 490, loss: 0.19560480117797852
step: 500, loss: 0.015376518480479717
step: 510, loss: 0.026063023135066032
step: 520, loss: 0.14039349555969238
step: 530, loss: 0.004899432882666588
step: 540, loss: 0.016101015731692314
step: 550, loss: 0.20882278680801392
step: 560, loss: 0.02201182208955288
step: 570, loss: 0.047518279403448105
step: 580, loss: 0.1207318902015686
step: 590, loss: 0.06379643827676773
step: 600, loss: 0.06798641383647919
step: 610, loss: 0.06882298737764359
step: 620, loss: 0.10832405835390091
step: 630, loss: 0.0662442222237587
step: 640, loss: 0.007714060600847006
step: 650, loss: 0.12025278806686401
step: 660, loss: 0.07200431823730469
step: 670, loss: 0.021824553608894348
step: 680, loss: 0.02248934656381607
step: 690, loss: 0.08349472284317017
step: 700, loss: 0.007536290679126978
step: 710, loss: 0.006454897578805685
step: 720, loss: 0.018679378554224968
step: 730, loss: 0.006484744139015675
step: 740, loss: 0.09648825973272324
step: 750, loss: 0.019107846543192863
step: 760, loss: 0.00494084507226944
step: 770, loss: 0.0037075267173349857
step: 780, loss: 0.05321474000811577
step: 790, loss: 0.03581438586115837
step: 800, loss: 0.009609587490558624
step: 810, loss: 0.010956824757158756
step: 820, loss: 0.01318275649100542
step: 830, loss: 0.0204025749117136
step: 840, loss: 0.01938115991652012
step: 850, loss: 0.1260133534669876
step: 860, loss: 0.07827551662921906
step: 870, loss: 0.03385147824883461
step: 880, loss: 0.02524125948548317
step: 890, loss: 0.13117603957653046
step: 900, loss: 0.05910344049334526
step: 910, loss: 0.08440086990594864
step: 920, loss: 0.027067411690950394
step: 930, loss: 0.034799687564373016
step: 940, loss: 0.06278961896896362
step: 950, loss: 0.09714815020561218
step: 960, loss: 0.1453000009059906
step: 970, loss: 0.055088985711336136
step: 980, loss: 0.04986266419291496
step: 990, loss: 0.07551521062850952
step: 1000, loss: 0.009466079995036125
step: 1010, loss: 0.07452581822872162
step: 1020, loss: 0.017834968864917755
step: 1030, loss: 0.026934891939163208
step: 1040, loss: 0.05759274959564209
step: 1050, loss: 0.00904151052236557
step: 1060, loss: 0.09076260030269623
step: 1070, loss: 0.11888578534126282
epoch 8: dev_f1=0.9323515876668201, f1=0.9313815187557181, best_f1=0.9271889400921659
step: 0, loss: 0.12023045122623444
step: 10, loss: 0.018108470365405083
step: 20, loss: 0.045450642704963684
step: 30, loss: 0.02976345084607601
step: 40, loss: 0.09982973337173462
step: 50, loss: 0.055455006659030914
step: 60, loss: 0.004214824177324772
step: 70, loss: 0.04196054860949516
step: 80, loss: 0.006406827829778194
step: 90, loss: 0.032900433987379074
step: 100, loss: 0.10210303217172623
step: 110, loss: 0.0473543182015419
step: 120, loss: 0.006593666039407253
step: 130, loss: 0.004557653330266476
step: 140, loss: 0.14709362387657166
step: 150, loss: 0.03374806419014931
step: 160, loss: 0.04951801523566246
step: 170, loss: 0.036796435713768005
step: 180, loss: 0.015993891283869743
step: 190, loss: 0.025086479261517525
step: 200, loss: 0.05960450321435928
step: 210, loss: 0.006013659294694662
step: 220, loss: 0.0562782883644104
step: 230, loss: 0.09635508805513382
step: 240, loss: 0.008971777744591236
step: 250, loss: 0.012651238590478897
step: 260, loss: 0.03653888404369354
step: 270, loss: 0.05002746358513832
step: 280, loss: 0.02005705237388611
step: 290, loss: 0.05792484059929848
step: 300, loss: 0.08766043931245804
step: 310, loss: 0.07127759605646133
step: 320, loss: 0.03608759492635727
step: 330, loss: 0.03468036651611328
step: 340, loss: 0.12029648572206497
step: 350, loss: 0.022625477984547615
step: 360, loss: 0.0426550954580307
step: 370, loss: 0.012002600356936455
step: 380, loss: 0.09807868301868439
step: 390, loss: 0.06262095272541046
step: 400, loss: 0.025864779949188232
step: 410, loss: 0.01310690212994814
step: 420, loss: 0.00014987081522122025
step: 430, loss: 0.02953382581472397
step: 440, loss: 0.0455564521253109
step: 450, loss: 0.08544134348630905
step: 460, loss: 0.038537170737981796
step: 470, loss: 0.02459064871072769
step: 480, loss: 0.1473858803510666
step: 490, loss: 0.026479946449398994
step: 500, loss: 0.03824862465262413
step: 510, loss: 0.015649832785129547
step: 520, loss: 0.020640864968299866
step: 530, loss: 0.0898386687040329
step: 540, loss: 0.013459084555506706
step: 550, loss: 0.08209137618541718
step: 560, loss: 0.17497345805168152
step: 570, loss: 0.10283026844263077
step: 580, loss: 0.05584561079740524
step: 590, loss: 0.01957721821963787
step: 600, loss: 0.010887615382671356
step: 610, loss: 0.030044415965676308
step: 620, loss: 0.0009409360936842859
step: 630, loss: 0.013965828344225883
step: 640, loss: 0.00839011836796999
step: 650, loss: 0.020572278648614883
step: 660, loss: 0.1444447934627533
step: 670, loss: 0.009934375993907452
step: 680, loss: 0.08224986493587494
step: 690, loss: 4.384315252536908e-05
step: 700, loss: 0.1484079658985138
step: 710, loss: 0.0141939427703619
step: 720, loss: 0.17463470995426178
step: 730, loss: 0.08313506096601486
step: 740, loss: 5.165008406038396e-05
step: 750, loss: 0.05556957423686981
step: 760, loss: 0.006708144210278988
step: 770, loss: 0.05034865811467171
step: 780, loss: 0.00913562998175621
step: 790, loss: 0.0592973418533802
step: 800, loss: 0.017894437536597252
step: 810, loss: 0.04707925766706467
step: 820, loss: 0.16575618088245392
step: 830, loss: 0.0718829482793808
step: 840, loss: 0.08994738757610321
step: 850, loss: 0.027900194749236107
step: 860, loss: 0.006113941315561533
step: 870, loss: 0.00975200068205595
step: 880, loss: 0.0994444414973259
step: 890, loss: 0.021255753934383392
step: 900, loss: 0.041763246059417725
step: 910, loss: 0.007293323054909706
step: 920, loss: 0.04099695757031441
step: 930, loss: 0.20641392469406128
step: 940, loss: 0.022368289530277252
step: 950, loss: 0.025609591975808144
step: 960, loss: 0.06930094957351685
step: 970, loss: 0.060140516608953476
step: 980, loss: 0.019506683573126793
step: 990, loss: 0.04937547445297241
step: 1000, loss: 0.08393103629350662
step: 1010, loss: 0.017354970797896385
step: 1020, loss: 0.05122428387403488
step: 1030, loss: 0.03547840565443039
step: 1040, loss: 0.014059853740036488
step: 1050, loss: 0.02355937846004963
step: 1060, loss: 0.020084703341126442
step: 1070, loss: 0.06946224719285965
epoch 9: dev_f1=0.9270976616231087, f1=0.9280806229958772, best_f1=0.9271889400921659
step: 0, loss: 0.0646662712097168
step: 10, loss: 0.09591156989336014
step: 20, loss: 0.049021631479263306
step: 30, loss: 0.0068862829357385635
step: 40, loss: 0.009639276191592216
step: 50, loss: 0.09772887825965881
step: 60, loss: 0.045639537274837494
step: 70, loss: 0.009180346503853798
step: 80, loss: 0.02513953484594822
step: 90, loss: 0.18555963039398193
step: 100, loss: 0.030856909230351448
step: 110, loss: 0.07687053084373474
step: 120, loss: 0.031614601612091064
step: 130, loss: 0.01602800004184246
step: 140, loss: 0.008432270027697086
step: 150, loss: 0.0015175509033724666
step: 160, loss: 0.004950726870447397
step: 170, loss: 0.0031360522843897343
step: 180, loss: 0.03217766433954239
step: 190, loss: 0.031497083604335785
step: 200, loss: 0.08928083628416061
step: 210, loss: 0.08495058864355087
step: 220, loss: 0.07076091319322586
step: 230, loss: 0.0042771040461957455
step: 240, loss: 0.015810342505574226
step: 250, loss: 0.07775729894638062
step: 260, loss: 0.051784347742795944
step: 270, loss: 0.10513725876808167
step: 280, loss: 0.08658453822135925
step: 290, loss: 0.0031009323429316282
step: 300, loss: 0.020612912252545357
step: 310, loss: 0.007663748227059841
step: 320, loss: 0.11108958721160889
step: 330, loss: 0.006514889188110828
step: 340, loss: 0.02398764342069626
step: 350, loss: 0.008671150542795658
step: 360, loss: 0.030935926362872124
step: 370, loss: 0.021656479686498642
step: 380, loss: 0.004919982515275478
step: 390, loss: 0.091739222407341
step: 400, loss: 0.029347456991672516
step: 410, loss: 0.05620483309030533
step: 420, loss: 0.00040250224992632866
step: 430, loss: 0.036759328097105026
step: 440, loss: 0.07967490702867508
step: 450, loss: 0.0702875629067421
step: 460, loss: 0.001622367068193853
step: 470, loss: 0.08392348885536194
step: 480, loss: 0.02699568122625351
step: 490, loss: 0.05332152545452118
step: 500, loss: 0.07417638599872589
step: 510, loss: 0.05877909064292908
step: 520, loss: 0.06878890842199326
step: 530, loss: 0.03648914024233818
step: 540, loss: 0.10966385900974274
step: 550, loss: 0.029572442173957825
step: 560, loss: 0.00944740790873766
step: 570, loss: 0.09951483458280563
step: 580, loss: 0.019197138026356697
step: 590, loss: 0.05247720330953598
step: 600, loss: 0.05365373566746712
step: 610, loss: 0.08039512485265732
step: 620, loss: 0.030359668657183647
step: 630, loss: 0.017416223883628845
step: 640, loss: 0.03128083795309067
step: 650, loss: 0.020124057307839394
step: 660, loss: 0.03230397775769234
step: 670, loss: 0.0469585619866848
step: 680, loss: 0.011917054653167725
step: 690, loss: 0.023633327335119247
step: 700, loss: 0.05789044126868248
step: 710, loss: 0.050711143761873245
step: 720, loss: 0.013718845322728157
step: 730, loss: 0.04190954938530922
step: 740, loss: 0.04523627087473869
step: 750, loss: 0.10994300246238708
step: 760, loss: 0.012710431590676308
step: 770, loss: 0.03047299012541771
step: 780, loss: 0.03488662838935852
step: 790, loss: 0.05835545435547829
step: 800, loss: 0.043213628232479095
step: 810, loss: 0.06432894617319107
step: 820, loss: 0.026967279613018036
step: 830, loss: 0.0923609584569931
step: 840, loss: 0.008889841847121716
step: 850, loss: 0.01516419742256403
step: 860, loss: 0.004508492536842823
step: 870, loss: 0.026342790573835373
step: 880, loss: 0.04369112476706505
step: 890, loss: 0.0704457089304924
step: 900, loss: 0.006611334625631571
step: 910, loss: 0.1495533138513565
step: 920, loss: 0.09790890663862228
step: 930, loss: 0.10775178670883179
step: 940, loss: 0.057596102356910706
step: 950, loss: 0.01986214518547058
step: 960, loss: 0.000162617870955728
step: 970, loss: 0.04098603129386902
step: 980, loss: 0.0341532900929451
step: 990, loss: 0.06979726254940033
step: 1000, loss: 0.04694095253944397
step: 1010, loss: 0.0683179721236229
step: 1020, loss: 0.02788536250591278
step: 1030, loss: 0.027975032106041908
step: 1040, loss: 0.027153637260198593
step: 1050, loss: 0.009989000856876373
step: 1060, loss: 0.2984507977962494
step: 1070, loss: 0.06341186910867691
epoch 10: dev_f1=0.9290681502086231, f1=0.9287037037037037, best_f1=0.9271889400921659
step: 0, loss: 0.01317566353827715
step: 10, loss: 0.01314907893538475
step: 20, loss: 0.03910345956683159
step: 30, loss: 0.00793302059173584
step: 40, loss: 0.0004087038978468627
step: 50, loss: 0.08059349656105042
step: 60, loss: 0.04008019343018532
step: 70, loss: 0.002539779292419553
step: 80, loss: 0.08135396242141724
step: 90, loss: 0.013729114085435867
step: 100, loss: 0.02256017178297043
step: 110, loss: 0.059981491416692734
step: 120, loss: 0.021382661536335945
step: 130, loss: 0.05189632996916771
step: 140, loss: 0.03241859748959541
step: 150, loss: 0.10543791949748993
step: 160, loss: 0.01933095045387745
step: 170, loss: 0.025285692885518074
step: 180, loss: 0.03764176368713379
step: 190, loss: 0.09104877710342407
step: 200, loss: 0.0535854697227478
step: 210, loss: 0.08603979647159576
step: 220, loss: 7.44224525988102e-05
step: 230, loss: 0.25711914896965027
step: 240, loss: 0.036051228642463684
step: 250, loss: 0.008483035489916801
step: 260, loss: 0.030124731361865997
step: 270, loss: 0.04605045169591904
step: 280, loss: 0.015449753031134605
step: 290, loss: 0.008713356219232082
step: 300, loss: 0.0005841030506417155
step: 310, loss: 0.10007591545581818
step: 320, loss: 0.05508473888039589
step: 330, loss: 0.011837867088615894
step: 340, loss: 0.05344223603606224
step: 350, loss: 0.08575374633073807
step: 360, loss: 0.050586529076099396
step: 370, loss: 0.2841884195804596
step: 380, loss: 0.023219726979732513
step: 390, loss: 0.006974842399358749
step: 400, loss: 0.03671897575259209
step: 410, loss: 0.011287813074886799
step: 420, loss: 0.07023061811923981
step: 430, loss: 0.16623017191886902
step: 440, loss: 0.025606868788599968
step: 450, loss: 0.005935077555477619
step: 460, loss: 0.03265557810664177
step: 470, loss: 0.049201156944036484
step: 480, loss: 0.015464764088392258
step: 490, loss: 0.032049428671598434
step: 500, loss: 0.050612375140190125
step: 510, loss: 0.06789156794548035
step: 520, loss: 0.02619159035384655
step: 530, loss: 0.03745435178279877
step: 540, loss: 0.02211541309952736
step: 550, loss: 0.008492536842823029
step: 560, loss: 0.03287290036678314
step: 570, loss: 0.0009215332102030516
step: 580, loss: 0.1710243970155716
step: 590, loss: 0.06123924255371094
step: 600, loss: 0.0462520532310009
step: 610, loss: 0.08407951146364212
step: 620, loss: 0.0607481524348259
step: 630, loss: 0.009900529868900776
step: 640, loss: 0.0006586623494513333
step: 650, loss: 0.020418329164385796
step: 660, loss: 0.17255531251430511
step: 670, loss: 0.042273327708244324
step: 680, loss: 0.07301649451255798
step: 690, loss: 0.06068116053938866
step: 700, loss: 0.03530562296509743
step: 710, loss: 0.10057505965232849
step: 720, loss: 0.09141640365123749
step: 730, loss: 0.0911766067147255
step: 740, loss: 0.0735638216137886
step: 750, loss: 0.03123791702091694
step: 760, loss: 0.008295713923871517
step: 770, loss: 0.005668602883815765
step: 780, loss: 0.0007699740235693753
step: 790, loss: 0.0442737452685833
step: 800, loss: 0.01477975957095623
step: 810, loss: 0.009063114412128925
step: 820, loss: 0.09362885355949402
step: 830, loss: 0.00353819178417325
step: 840, loss: 0.038138870149850845
step: 850, loss: 0.05832374840974808
step: 860, loss: 0.0014448952861130238
step: 870, loss: 0.008226252160966396
step: 880, loss: 0.02043757773935795
step: 890, loss: 0.09203492105007172
step: 900, loss: 0.05232999101281166
step: 910, loss: 0.04176647216081619
step: 920, loss: 0.10778965801000595
step: 930, loss: 0.08887352049350739
step: 940, loss: 0.039877425879240036
step: 950, loss: 0.07600194215774536
step: 960, loss: 0.0002567407500464469
step: 970, loss: 0.06242924928665161
step: 980, loss: 0.06568349897861481
step: 990, loss: 0.05894311144948006
step: 1000, loss: 0.013873531483113766
step: 1010, loss: 0.13480083644390106
step: 1020, loss: 0.03463806211948395
step: 1030, loss: 0.007535409182310104
step: 1040, loss: 0.02388388104736805
step: 1050, loss: 0.00025641240063123405
step: 1060, loss: 0.012509078718721867
step: 1070, loss: 0.04610547795891762
epoch 11: dev_f1=0.9341923607915326, f1=0.9306384933394579, best_f1=0.9271889400921659
step: 0, loss: 0.07253856956958771
step: 10, loss: 0.006465759593993425
step: 20, loss: 0.02904559299349785
step: 30, loss: 0.05410673841834068
step: 40, loss: 0.01965601183474064
step: 50, loss: 0.009393860585987568
step: 60, loss: 0.017138617113232613
step: 70, loss: 0.04136102274060249
step: 80, loss: 0.002600814215838909
step: 90, loss: 0.001083970069885254
step: 100, loss: 0.04996468499302864
step: 110, loss: 0.04525158926844597
step: 120, loss: 0.026085542514920235
step: 130, loss: 0.03776004910469055
step: 140, loss: 0.01022932305932045
step: 150, loss: 0.07738955318927765
step: 160, loss: 0.007203904911875725
step: 170, loss: 0.10852768272161484
step: 180, loss: 0.001738844090141356
step: 190, loss: 0.06809787452220917
step: 200, loss: 0.046507835388183594
step: 210, loss: 0.02288147434592247
step: 220, loss: 0.006313064601272345
step: 230, loss: 0.017765847966074944
step: 240, loss: 0.038409359753131866
step: 250, loss: 0.047221772372722626
step: 260, loss: 0.07655417919158936
step: 270, loss: 0.04674554616212845
step: 280, loss: 0.04104745388031006
step: 290, loss: 0.030626650899648666
step: 300, loss: 0.03661687672138214
step: 310, loss: 0.0032699971925467253
step: 320, loss: 0.048787470906972885
step: 330, loss: 0.07460863888263702
step: 340, loss: 0.007815941236913204
step: 350, loss: 0.004089872818440199
step: 360, loss: 0.016663582995533943
step: 370, loss: 0.022935625165700912
step: 380, loss: 0.034128788858652115
step: 390, loss: 0.03837161883711815
step: 400, loss: 0.12870362401008606
step: 410, loss: 0.032452721148729324
step: 420, loss: 0.037181753665208817
step: 430, loss: 0.015702521428465843
step: 440, loss: 0.05683966353535652
step: 450, loss: 0.0002540762070566416
step: 460, loss: 0.03391993045806885
step: 470, loss: 0.08720307052135468
step: 480, loss: 0.07081058621406555
step: 490, loss: 0.018229378387331963
step: 500, loss: 0.09343783557415009
step: 510, loss: 0.02385587990283966
step: 520, loss: 0.033100150525569916
step: 530, loss: 0.07430771738290787
step: 540, loss: 0.01679246313869953
step: 550, loss: 0.00045402569230645895
step: 560, loss: 0.05186961591243744
step: 570, loss: 0.026329971849918365
step: 580, loss: 0.00022244235151447356
step: 590, loss: 0.015156389214098454
step: 600, loss: 0.052127301692962646
step: 610, loss: 0.04533671587705612
step: 620, loss: 0.048640940338373184
step: 630, loss: 4.573493788484484e-05
step: 640, loss: 0.01826491206884384
step: 650, loss: 0.06761139631271362
step: 660, loss: 0.02579600177705288
step: 670, loss: 0.053468264639377594
step: 680, loss: 0.019610760733485222
step: 690, loss: 0.22281309962272644
step: 700, loss: 0.0795028880238533
step: 710, loss: 0.003945457749068737
step: 720, loss: 0.026987997815012932
step: 730, loss: 0.06839705258607864
step: 740, loss: 0.021953679621219635
step: 750, loss: 0.013049112632870674
step: 760, loss: 0.000402286765165627
step: 770, loss: 0.0013657897943630815
step: 780, loss: 0.038941994309425354
step: 790, loss: 0.080810546875
step: 800, loss: 0.007802757900208235
step: 810, loss: 0.004460979253053665
step: 820, loss: 0.10131372511386871
step: 830, loss: 0.0031839509028941393
step: 840, loss: 0.09887395054101944
step: 850, loss: 0.029759369790554047
step: 860, loss: 0.03531092032790184
step: 870, loss: 0.0022683171555399895
step: 880, loss: 0.00026734493440017104
step: 890, loss: 0.001298300689086318
step: 900, loss: 0.04478752240538597
step: 910, loss: 0.05857417359948158
step: 920, loss: 0.03945817053318024
step: 930, loss: 0.002797586377710104
step: 940, loss: 0.15326617658138275
step: 950, loss: 0.007040779106318951
step: 960, loss: 0.022471005097031593
step: 970, loss: 0.026857474818825722
step: 980, loss: 0.03715438023209572
step: 990, loss: 0.03735483065247536
step: 1000, loss: 0.08449007570743561
step: 1010, loss: 0.03891851380467415
step: 1020, loss: 0.010311105288565159
step: 1030, loss: 0.0773196741938591
step: 1040, loss: 0.016805145889520645
step: 1050, loss: 0.01998814195394516
step: 1060, loss: 0.005563842132687569
step: 1070, loss: 0.090705506503582
epoch 12: dev_f1=0.9318826868495743, f1=0.9328922495274102, best_f1=0.9271889400921659
step: 0, loss: 0.021456396207213402
step: 10, loss: 0.022112954407930374
step: 20, loss: 0.002198615577071905
step: 30, loss: 0.027658237144351006
step: 40, loss: 0.09498341381549835
step: 50, loss: 0.051153965294361115
step: 60, loss: 0.053397029638290405
step: 70, loss: 0.04007326066493988
step: 80, loss: 0.024923594668507576
step: 90, loss: 0.00014251191169023514
step: 100, loss: 0.005241619423031807
step: 110, loss: 0.0292181596159935
step: 120, loss: 0.04265821725130081
step: 130, loss: 0.05799221247434616
step: 140, loss: 0.04841117933392525
step: 150, loss: 0.031622517853975296
step: 160, loss: 0.08047759532928467
step: 170, loss: 0.0045942384749650955
step: 180, loss: 0.04963940009474754
step: 190, loss: 0.01298737432807684
step: 200, loss: 0.038246627897024155
step: 210, loss: 0.015745528042316437
step: 220, loss: 0.0016657995292916894
step: 230, loss: 0.040277451276779175
step: 240, loss: 0.025606391951441765
step: 250, loss: 0.04652532562613487
step: 260, loss: 0.0030687320977449417
step: 270, loss: 0.018299641087651253
step: 280, loss: 0.028882617130875587
step: 290, loss: 0.032678794115781784
step: 300, loss: 0.0012097280705347657
step: 310, loss: 0.00010665984882507473
step: 320, loss: 0.01628853753209114
step: 330, loss: 0.005605617072433233
step: 340, loss: 0.0002354638127144426
step: 350, loss: 0.022949548438191414
step: 360, loss: 0.023358313366770744
step: 370, loss: 0.01713927462697029
step: 380, loss: 0.00016392288671340793
step: 390, loss: 0.04703008756041527
step: 400, loss: 0.0009781758999451995
step: 410, loss: 0.06027565896511078
step: 420, loss: 0.02408815175294876
step: 430, loss: 0.04486411437392235
step: 440, loss: 0.07941978424787521
step: 450, loss: 0.020243480801582336
step: 460, loss: 0.011235722340643406
step: 470, loss: 0.016494059935212135
step: 480, loss: 0.013363577425479889
step: 490, loss: 0.0038333304692059755
step: 500, loss: 0.015397337265312672
step: 510, loss: 0.03786204010248184
step: 520, loss: 0.12094701826572418
step: 530, loss: 0.07449787110090256
step: 540, loss: 0.06751208007335663
step: 550, loss: 0.04569995775818825
step: 560, loss: 0.0518064871430397
step: 570, loss: 0.058656465262174606
step: 580, loss: 0.005312021356076002
step: 590, loss: 0.1552877277135849
step: 600, loss: 0.029836280271410942
step: 610, loss: 0.04382850602269173
step: 620, loss: 0.052863094955682755
step: 630, loss: 0.014957227744162083
step: 640, loss: 0.000546358001884073
step: 650, loss: 0.008839479647576809
step: 660, loss: 0.05713287368416786
step: 670, loss: 8.049296593526378e-05
step: 680, loss: 0.0002692840644158423
step: 690, loss: 0.13462844491004944
step: 700, loss: 0.024439962580800056
step: 710, loss: 0.0387105830013752
step: 720, loss: 0.007826598361134529
step: 730, loss: 0.03364196792244911
step: 740, loss: 0.003805159591138363
step: 750, loss: 3.3945765608223155e-05
step: 760, loss: 0.015314656309783459
step: 770, loss: 0.08968500792980194
step: 780, loss: 0.0020697556901723146
step: 790, loss: 0.033135902136564255
step: 800, loss: 0.02070804126560688
step: 810, loss: 0.03014586865901947
step: 820, loss: 0.062202733010053635
step: 830, loss: 4.6186505642253906e-05
step: 840, loss: 0.029226545244455338
step: 850, loss: 0.036552898585796356
step: 860, loss: 0.06656286120414734
step: 870, loss: 0.02997630462050438
step: 880, loss: 0.006873674225062132
step: 890, loss: 0.011454652063548565
step: 900, loss: 0.049972984939813614
step: 910, loss: 0.0002510035992600024
step: 920, loss: 0.026303930208086967
step: 930, loss: 0.0013386714272201061
step: 940, loss: 0.007265795487910509
step: 950, loss: 0.0037649492733180523
step: 960, loss: 0.04841640219092369
step: 970, loss: 0.03711286187171936
step: 980, loss: 0.0022508595138788223
step: 990, loss: 0.00538556557148695
step: 1000, loss: 0.02122798189520836
step: 1010, loss: 0.05708107352256775
step: 1020, loss: 0.05299703776836395
step: 1030, loss: 0.0005065960576757789
step: 1040, loss: 0.023007860407233238
step: 1050, loss: 0.028274906799197197
step: 1060, loss: 0.06815140694379807
step: 1070, loss: 0.012595243752002716
epoch 13: dev_f1=0.9291784702549575, f1=0.9304511278195489, best_f1=0.9271889400921659
step: 0, loss: 0.09133077412843704
step: 10, loss: 0.07121230661869049
step: 20, loss: 0.0025090021081268787
step: 30, loss: 0.0438554547727108
step: 40, loss: 0.08955147117376328
step: 50, loss: 0.006600438617169857
step: 60, loss: 0.02739356830716133
step: 70, loss: 0.024112369865179062
step: 80, loss: 0.0015375979710370302
step: 90, loss: 0.025802375748753548
step: 100, loss: 0.05358877778053284
step: 110, loss: 0.015803128480911255
step: 120, loss: 0.034995440393686295
step: 130, loss: 0.038149718195199966
step: 140, loss: 0.001309703104197979
step: 150, loss: 0.00022976302716415375
step: 160, loss: 0.03001038171350956
step: 170, loss: 0.03912175074219704
step: 180, loss: 0.034035876393318176
step: 190, loss: 3.386352909728885e-05
step: 200, loss: 0.06434161961078644
step: 210, loss: 0.01745898276567459
step: 220, loss: 0.0002611446543596685
step: 230, loss: 0.03137820214033127
step: 240, loss: 0.0016096814069896936
step: 250, loss: 0.0225809495896101
step: 260, loss: 0.0027933516539633274
step: 270, loss: 0.08413714915513992
step: 280, loss: 0.0002356806508032605
step: 290, loss: 0.032136183232069016
step: 300, loss: 0.0008784922538325191
step: 310, loss: 0.00013936590403318405
step: 320, loss: 0.006729447282850742
step: 330, loss: 0.07660383731126785
step: 340, loss: 0.030911313369870186
step: 350, loss: 0.014127327129244804
step: 360, loss: 0.08446826785802841
step: 370, loss: 0.04802492633461952
step: 380, loss: 0.011754324659705162
step: 390, loss: 0.061556555330753326
step: 400, loss: 0.00955742597579956
step: 410, loss: 0.03652874380350113
step: 420, loss: 0.08777903765439987
step: 430, loss: 0.04799804836511612
step: 440, loss: 0.0231715627014637
step: 450, loss: 0.04823983833193779
step: 460, loss: 0.0875810757279396
step: 470, loss: 0.012896809726953506
step: 480, loss: 0.023122064769268036
step: 490, loss: 0.04457336291670799
step: 500, loss: 0.02155608870089054
step: 510, loss: 0.021625172346830368
step: 520, loss: 0.058299217373132706
step: 530, loss: 0.05465349182486534
step: 540, loss: 0.095490463078022
step: 550, loss: 0.03029475547373295
step: 560, loss: 0.023078832775354385
step: 570, loss: 0.00033683396759442985
step: 580, loss: 0.057643093168735504
step: 590, loss: 0.03843672573566437
step: 600, loss: 0.11231771111488342
step: 610, loss: 0.013860320672392845
step: 620, loss: 0.0629611611366272
step: 630, loss: 0.004948291927576065
step: 640, loss: 2.1199657567194663e-05
step: 650, loss: 0.027686579152941704
step: 660, loss: 0.005411693826317787
step: 670, loss: 0.08703002333641052
step: 680, loss: 0.0003211525618098676
step: 690, loss: 0.055038683116436005
step: 700, loss: 0.006875155493617058
step: 710, loss: 0.0689644142985344
step: 720, loss: 0.02584793232381344
step: 730, loss: 0.0032028178684413433
step: 740, loss: 0.0448584146797657
step: 750, loss: 0.014896903187036514
step: 760, loss: 0.03756577894091606
step: 770, loss: 0.04119062051177025
step: 780, loss: 0.06504977494478226
step: 790, loss: 0.00020197004778310657
step: 800, loss: 0.0224424097687006
step: 810, loss: 0.0004724184691440314
step: 820, loss: 0.0012611341662704945
step: 830, loss: 0.020302806049585342
step: 840, loss: 0.05488637834787369
step: 850, loss: 0.001106445793993771
step: 860, loss: 0.025062760338187218
step: 870, loss: 0.04206487163901329
step: 880, loss: 0.005641760770231485
step: 890, loss: 0.03324428200721741
step: 900, loss: 0.05053446441888809
step: 910, loss: 0.0005397859495133162
step: 920, loss: 2.108454646077007e-05
step: 930, loss: 0.0002312445139978081
step: 940, loss: 0.016414282843470573
step: 950, loss: 1.9728300685528666e-05
step: 960, loss: 0.024653498083353043
step: 970, loss: 0.04909538850188255
step: 980, loss: 0.01881389692425728
step: 990, loss: 0.1291402131319046
step: 1000, loss: 0.009682051837444305
step: 1010, loss: 0.044083788990974426
step: 1020, loss: 0.0002812583406921476
step: 1030, loss: 0.16186484694480896
step: 1040, loss: 0.094702810049057
step: 1050, loss: 0.10669365525245667
step: 1060, loss: 0.02465505339205265
step: 1070, loss: 0.03349676728248596
epoch 14: dev_f1=0.9290023201856149, f1=0.9256351039260969, best_f1=0.9271889400921659
step: 0, loss: 0.029593847692012787
step: 10, loss: 0.02739449217915535
step: 20, loss: 2.409388980595395e-05
step: 30, loss: 0.030901392921805382
step: 40, loss: 0.03200988098978996
step: 50, loss: 0.007524026557803154
step: 60, loss: 0.006423115264624357
step: 70, loss: 0.015147801488637924
step: 80, loss: 0.10660967230796814
step: 90, loss: 2.4272982045658864e-05
step: 100, loss: 0.03316445276141167
step: 110, loss: 0.06045151501893997
step: 120, loss: 0.00307118846103549
step: 130, loss: 0.01287462655454874
step: 140, loss: 0.023450907319784164
step: 150, loss: 2.239185596408788e-05
step: 160, loss: 0.0853075236082077
step: 170, loss: 0.006684713065624237
step: 180, loss: 0.05214133858680725
step: 190, loss: 0.020354535430669785
step: 200, loss: 0.011288831010460854
step: 210, loss: 5.932203566771932e-05
step: 220, loss: 0.0025410319212824106
step: 230, loss: 0.063991017639637
step: 240, loss: 5.652727122651413e-05
step: 250, loss: 0.005448898766189814
step: 260, loss: 0.021023789420723915
step: 270, loss: 0.0018202499486505985
step: 280, loss: 0.057200122624635696
step: 290, loss: 0.0009483850444667041
step: 300, loss: 0.00017706127255223691
step: 310, loss: 0.026461614295840263
step: 320, loss: 0.017722677439451218
step: 330, loss: 0.00012043736933264881
step: 340, loss: 0.04902748018503189
step: 350, loss: 0.02349325641989708
step: 360, loss: 0.002180439652875066
step: 370, loss: 0.02279558964073658
step: 380, loss: 0.019915934652090073
step: 390, loss: 0.00018951969104819
step: 400, loss: 0.04500572383403778
step: 410, loss: 0.019156362861394882
step: 420, loss: 0.007945690304040909
step: 430, loss: 0.04293142631649971
step: 440, loss: 0.044463783502578735
step: 450, loss: 0.020115694031119347
step: 460, loss: 0.0367269404232502
step: 470, loss: 0.047857578843832016
step: 480, loss: 0.0001806622458389029
step: 490, loss: 0.12416321039199829
step: 500, loss: 0.05249834433197975
step: 510, loss: 0.03876751288771629
step: 520, loss: 0.0053076958283782005
step: 530, loss: 0.0002032571064773947
step: 540, loss: 5.984368181088939e-05
step: 550, loss: 0.047504376620054245
step: 560, loss: 0.01668998971581459
step: 570, loss: 0.022914936766028404
step: 580, loss: 0.04247841611504555
step: 590, loss: 0.00884301494807005
step: 600, loss: 0.14834897220134735
step: 610, loss: 0.0020714253187179565
step: 620, loss: 0.06936386227607727
step: 630, loss: 0.023596348240971565
step: 640, loss: 0.05013687536120415
step: 650, loss: 2.9763326892862096e-05
step: 660, loss: 0.030236920341849327
step: 670, loss: 0.04249699413776398
step: 680, loss: 0.051905062049627304
step: 690, loss: 0.0018377917585894465
step: 700, loss: 0.04412032663822174
step: 710, loss: 4.800075839739293e-05
step: 720, loss: 0.018138034269213676
step: 730, loss: 0.09011616557836533
step: 740, loss: 0.002980551915243268
step: 750, loss: 0.02590198814868927
step: 760, loss: 0.016738172620534897
step: 770, loss: 0.05779867246747017
step: 780, loss: 0.0678611621260643
step: 790, loss: 0.029968302696943283
step: 800, loss: 0.07824866473674774
step: 810, loss: 0.020641762763261795
step: 820, loss: 0.0020684651099145412
step: 830, loss: 0.19884301722049713
step: 840, loss: 7.889220432844013e-05
step: 850, loss: 0.04939141124486923
step: 860, loss: 0.018679587170481682
step: 870, loss: 0.023668965324759483
step: 880, loss: 0.01734301634132862
step: 890, loss: 0.003311789594590664
step: 900, loss: 0.012006193399429321
step: 910, loss: 0.01711985096335411
step: 920, loss: 0.030042197555303574
step: 930, loss: 0.002212848514318466
step: 940, loss: 0.11007963120937347
step: 950, loss: 0.03130516782402992
step: 960, loss: 0.049944717437028885
step: 970, loss: 0.016470421105623245
step: 980, loss: 5.1408744184300303e-05
step: 990, loss: 0.04147520288825035
step: 1000, loss: 0.033248111605644226
step: 1010, loss: 0.037667132914066315
step: 1020, loss: 0.02019643597304821
step: 1030, loss: 0.04811325669288635
step: 1040, loss: 0.0252312533557415
step: 1050, loss: 0.12784110009670258
step: 1060, loss: 0.00045732164289802313
step: 1070, loss: 0.0659293457865715
epoch 15: dev_f1=0.9306839186691312, f1=0.926605504587156, best_f1=0.9271889400921659
step: 0, loss: 0.025305982679128647
step: 10, loss: 0.012665728107094765
step: 20, loss: 0.06476464867591858
step: 30, loss: 0.02396732196211815
step: 40, loss: 0.03471283242106438
step: 50, loss: 0.06638524681329727
step: 60, loss: 0.02103321999311447
step: 70, loss: 0.06541185081005096
step: 80, loss: 0.04597897082567215
step: 90, loss: 0.048608455806970596
step: 100, loss: 4.998229996999726e-05
step: 110, loss: 0.022599751129746437
step: 120, loss: 0.02357601933181286
step: 130, loss: 0.0815637856721878
step: 140, loss: 0.0265298243612051
step: 150, loss: 0.018929559737443924
step: 160, loss: 0.041361331939697266
step: 170, loss: 0.041258443146944046
step: 180, loss: 0.07349333167076111
step: 190, loss: 0.038712840527296066
step: 200, loss: 0.10103842616081238
step: 210, loss: 0.020482806488871574
step: 220, loss: 0.0013260975247249007
step: 230, loss: 0.026105664670467377
step: 240, loss: 5.6869888794608414e-05
step: 250, loss: 2.787733501463663e-05
step: 260, loss: 0.003706385614350438
step: 270, loss: 0.009885549545288086
step: 280, loss: 0.018088290467858315
step: 290, loss: 0.05193908512592316
step: 300, loss: 0.054198428988456726
step: 310, loss: 0.047357846051454544
step: 320, loss: 0.054753806442022324
step: 330, loss: 0.0261929202824831
step: 340, loss: 0.044977735728025436
step: 350, loss: 0.026280688121914864
step: 360, loss: 3.907819336745888e-05
step: 370, loss: 2.5337174520245753e-05
step: 380, loss: 0.05476105958223343
step: 390, loss: 0.030312396585941315
step: 400, loss: 1.9158243958372623e-05
step: 410, loss: 0.08517584204673767
step: 420, loss: 0.07138359546661377
step: 430, loss: 0.027356738224625587
step: 440, loss: 0.02158333919942379
step: 450, loss: 0.03805137053132057
step: 460, loss: 0.06316972523927689
step: 470, loss: 0.1544089913368225
step: 480, loss: 0.021272046491503716
step: 490, loss: 9.21326718525961e-05
step: 500, loss: 0.02454264461994171
step: 510, loss: 0.021242870017886162
step: 520, loss: 0.029264556244015694
step: 530, loss: 0.05566249042749405
step: 540, loss: 0.07246671617031097
step: 550, loss: 0.017552891746163368
step: 560, loss: 0.004619567189365625
step: 570, loss: 0.026072341948747635
step: 580, loss: 0.025165753439068794
step: 590, loss: 0.00022227583394851536
step: 600, loss: 0.03621857985854149
step: 610, loss: 0.01586327515542507
step: 620, loss: 0.005176502279937267
step: 630, loss: 0.04190300777554512
step: 640, loss: 0.03682548925280571
step: 650, loss: 0.04503687471151352
step: 660, loss: 0.025145500898361206
step: 670, loss: 0.00026841287035495043
step: 680, loss: 0.04572358354926109
step: 690, loss: 0.06331662088632584
step: 700, loss: 0.004851410631090403
step: 710, loss: 0.07738380134105682
step: 720, loss: 0.022241706028580666
step: 730, loss: 0.005620087031275034
step: 740, loss: 0.018478309735655785
step: 750, loss: 0.0008518259273841977
step: 760, loss: 0.001579234842211008
step: 770, loss: 0.09632544964551926
step: 780, loss: 0.021464966237545013
step: 790, loss: 0.025297323241829872
step: 800, loss: 0.04744156822562218
step: 810, loss: 0.042797431349754333
step: 820, loss: 0.0460369735956192
step: 830, loss: 0.05967045575380325
step: 840, loss: 0.0021467050537467003
step: 850, loss: 0.0777127593755722
step: 860, loss: 0.024182185530662537
step: 870, loss: 0.10241154581308365
step: 880, loss: 0.00020498127560131252
step: 890, loss: 2.643532570800744e-05
step: 900, loss: 0.026779627427458763
step: 910, loss: 0.00012579669419210404
step: 920, loss: 0.02192540653049946
step: 930, loss: 0.03244223818182945
step: 940, loss: 0.007726001553237438
step: 950, loss: 0.030653009191155434
step: 960, loss: 0.020833633840084076
step: 970, loss: 0.06591319292783737
step: 980, loss: 0.0927656814455986
step: 990, loss: 0.04369430989027023
step: 1000, loss: 0.008509041741490364
step: 1010, loss: 0.04965147748589516
step: 1020, loss: 0.039831336587667465
step: 1030, loss: 0.05746714025735855
step: 1040, loss: 3.1837033020565286e-05
step: 1050, loss: 0.09086774289608002
step: 1060, loss: 0.029286811128258705
step: 1070, loss: 8.158643322531134e-05
epoch 16: dev_f1=0.9328392774432608, f1=0.9266943291839558, best_f1=0.9271889400921659
step: 0, loss: 0.0028764999005943537
step: 10, loss: 0.0003585337835829705
step: 20, loss: 0.04431235045194626
step: 30, loss: 0.03892739862203598
step: 40, loss: 0.03898438811302185
step: 50, loss: 0.0006274651968851686
step: 60, loss: 0.06931111961603165
step: 70, loss: 0.024808848276734352
step: 80, loss: 2.12816521525383e-05
step: 90, loss: 0.043479256331920624
step: 100, loss: 7.721529982518405e-05
step: 110, loss: 0.04414893314242363
step: 120, loss: 0.04688500612974167
step: 130, loss: 0.007360425777733326
step: 140, loss: 0.0685701072216034
step: 150, loss: 0.00010919247870333493
step: 160, loss: 0.0016621443210169673
step: 170, loss: 0.16114294528961182
step: 180, loss: 0.022024646401405334
step: 190, loss: 0.023983383551239967
step: 200, loss: 0.01747395657002926
step: 210, loss: 0.0443565733730793
step: 220, loss: 0.05837482213973999
step: 230, loss: 0.0002728161634877324
step: 240, loss: 0.04540083557367325
step: 250, loss: 0.00011957423703279346
step: 260, loss: 0.042752668261528015
step: 270, loss: 0.060032449662685394
step: 280, loss: 0.025497108697891235
step: 290, loss: 0.030450059100985527
step: 300, loss: 0.038387563079595566
step: 310, loss: 0.022720681503415108
step: 320, loss: 0.07782141119241714
step: 330, loss: 0.02424570918083191
step: 340, loss: 0.032455503940582275
step: 350, loss: 0.05135839432477951
step: 360, loss: 0.002216941677033901
step: 370, loss: 0.020984385162591934
step: 380, loss: 0.048277515918016434
step: 390, loss: 4.201173214823939e-05
step: 400, loss: 0.010546314530074596
step: 410, loss: 0.11106376349925995
step: 420, loss: 0.025621872395277023
step: 430, loss: 0.04328485578298569
step: 440, loss: 0.0007537389174103737
step: 450, loss: 0.008200143463909626
step: 460, loss: 0.0012022071750834584
step: 470, loss: 0.02578858844935894
step: 480, loss: 0.006878384854644537
step: 490, loss: 0.022083889693021774
step: 500, loss: 0.05005437135696411
step: 510, loss: 0.09077780693769455
step: 520, loss: 0.0018918446730822325
step: 530, loss: 0.05117131769657135
step: 540, loss: 0.07000613212585449
step: 550, loss: 0.02577907405793667
step: 560, loss: 0.11995834857225418
step: 570, loss: 0.0009085957426577806
step: 580, loss: 0.02104504033923149
step: 590, loss: 0.005094179417937994
step: 600, loss: 0.0089569091796875
step: 610, loss: 0.0006990981637500226
step: 620, loss: 0.07320424914360046
step: 630, loss: 0.04211072623729706
step: 640, loss: 6.972663686610758e-05
step: 650, loss: 0.049128513783216476
step: 660, loss: 0.0789579451084137
step: 670, loss: 0.021786944940686226
step: 680, loss: 0.19568605720996857
step: 690, loss: 0.0004984582774341106
step: 700, loss: 3.775947698159143e-05
step: 710, loss: 0.0185328908264637
step: 720, loss: 0.00013042068167123944
step: 730, loss: 1.653568870096933e-05
step: 740, loss: 0.03386836126446724
step: 750, loss: 0.061988893896341324
step: 760, loss: 0.0001372892438666895
step: 770, loss: 0.030862828716635704
step: 780, loss: 0.045516032725572586
step: 790, loss: 0.11383461207151413
step: 800, loss: 0.01785825565457344
step: 810, loss: 0.029755350202322006
step: 820, loss: 0.024360332638025284
step: 830, loss: 0.001906084711663425
step: 840, loss: 0.02177496999502182
step: 850, loss: 0.040728989988565445
step: 860, loss: 0.024825550615787506
step: 870, loss: 0.06203106790781021
step: 880, loss: 0.028426609933376312
step: 890, loss: 0.022685548290610313
step: 900, loss: 0.047198645770549774
step: 910, loss: 0.02060122601687908
step: 920, loss: 7.233663200167939e-05
step: 930, loss: 0.0222136490046978
step: 940, loss: 1.280362812394742e-05
step: 950, loss: 2.2641295799985528e-05
step: 960, loss: 0.024054942652583122
step: 970, loss: 0.00435738917440176
step: 980, loss: 0.09505745768547058
step: 990, loss: 0.020026247948408127
step: 1000, loss: 0.039501264691352844
step: 1010, loss: 0.0459870882332325
step: 1020, loss: 0.0006270084413699806
step: 1030, loss: 0.022460469976067543
step: 1040, loss: 0.020166704431176186
step: 1050, loss: 0.04104187712073326
step: 1060, loss: 0.02759607508778572
step: 1070, loss: 0.15539219975471497
epoch 17: dev_f1=0.9356943150046597, f1=0.9268518518518517, best_f1=0.9268518518518517
step: 0, loss: 0.02016563154757023
step: 10, loss: 0.00021646666573360562
step: 20, loss: 0.060582444071769714
step: 30, loss: 0.05841105803847313
step: 40, loss: 0.00041931626037694514
step: 50, loss: 9.443222370464355e-05
step: 60, loss: 0.04297662898898125
step: 70, loss: 0.03665453568100929
step: 80, loss: 0.04195304587483406
step: 90, loss: 0.04257693886756897
step: 100, loss: 0.06430629640817642
step: 110, loss: 0.023213541135191917
step: 120, loss: 0.04529385268688202
step: 130, loss: 0.01784955896437168
step: 140, loss: 0.03549506515264511
step: 150, loss: 0.000702112854924053
step: 160, loss: 0.047295942902565
step: 170, loss: 0.04407860338687897
step: 180, loss: 0.021224286407232285
step: 190, loss: 0.03790413588285446
step: 200, loss: 0.045449111610651016
step: 210, loss: 0.00139120954554528
step: 220, loss: 0.0511787123978138
step: 230, loss: 0.048089995980262756
step: 240, loss: 0.05320487916469574
step: 250, loss: 0.01432286947965622
step: 260, loss: 0.03057091496884823
step: 270, loss: 1.4014154658070765e-05
step: 280, loss: 0.061624202877283096
step: 290, loss: 0.08189578354358673
step: 300, loss: 4.1822651837719604e-05
step: 310, loss: 0.030463000759482384
step: 320, loss: 0.0027979824226349592
step: 330, loss: 0.017916681244969368
step: 340, loss: 0.01675291359424591
step: 350, loss: 0.042413972318172455
step: 360, loss: 8.704158972250298e-05
step: 370, loss: 0.009730340912938118
step: 380, loss: 0.07239079475402832
step: 390, loss: 0.01647976227104664
step: 400, loss: 0.019826900213956833
step: 410, loss: 4.7144407290033996e-05
step: 420, loss: 0.01790822483599186
step: 430, loss: 2.8280932383495383e-05
step: 440, loss: 0.0371997244656086
step: 450, loss: 5.738746767747216e-05
step: 460, loss: 0.06646235287189484
step: 470, loss: 0.0009671179577708244
step: 480, loss: 0.019959745928645134
step: 490, loss: 0.02985919453203678
step: 500, loss: 0.07035680115222931
step: 510, loss: 0.03118540346622467
step: 520, loss: 0.01983833685517311
step: 530, loss: 0.02388749085366726
step: 540, loss: 0.009200246073305607
step: 550, loss: 0.03418269380927086
step: 560, loss: 0.022295163944363594
step: 570, loss: 0.02038145810365677
step: 580, loss: 0.03114086575806141
step: 590, loss: 0.020431695505976677
step: 600, loss: 0.0671314224600792
step: 610, loss: 0.01933831349015236
step: 620, loss: 0.04972352087497711
step: 630, loss: 0.01633063703775406
step: 640, loss: 0.02702578343451023
step: 650, loss: 0.017168041318655014
step: 660, loss: 0.0039916858077049255
step: 670, loss: 0.015703869983553886
step: 680, loss: 6.871265213703737e-05
step: 690, loss: 0.000877846556250006
step: 700, loss: 0.07657019793987274
step: 710, loss: 0.05878834426403046
step: 720, loss: 0.02246134541928768
step: 730, loss: 3.469809234957211e-05
step: 740, loss: 0.013992433436214924
step: 750, loss: 0.01102948747575283
step: 760, loss: 0.04572926089167595
step: 770, loss: 0.00032915675546973944
step: 780, loss: 0.09199298918247223
step: 790, loss: 0.026476413011550903
step: 800, loss: 0.0014319192850962281
step: 810, loss: 0.024323368445038795
step: 820, loss: 0.0327686108648777
step: 830, loss: 0.05800534039735794
step: 840, loss: 0.024139322340488434
step: 850, loss: 0.055279530584812164
step: 860, loss: 0.04651211202144623
step: 870, loss: 0.03540443629026413
step: 880, loss: 0.02437707781791687
step: 890, loss: 0.05614742636680603
step: 900, loss: 0.0009279975784011185
step: 910, loss: 0.02533167041838169
step: 920, loss: 0.014007531106472015
step: 930, loss: 0.022772904485464096
step: 940, loss: 2.512407081667334e-05
step: 950, loss: 0.012615189887583256
step: 960, loss: 0.04620545729994774
step: 970, loss: 0.05250796303153038
step: 980, loss: 7.835122960386798e-05
step: 990, loss: 0.05468377470970154
step: 1000, loss: 8.57623090269044e-05
step: 1010, loss: 0.0645819902420044
step: 1020, loss: 0.016360120847821236
step: 1030, loss: 0.029141517356038094
step: 1040, loss: 0.06285572797060013
step: 1050, loss: 7.160662789829075e-05
step: 1060, loss: 8.617115236120299e-05
step: 1070, loss: 0.02453606389462948
epoch 18: dev_f1=0.9293401965372016, f1=0.9245020842982862, best_f1=0.9268518518518517
step: 0, loss: 0.020717544481158257
step: 10, loss: 0.019754856824874878
step: 20, loss: 0.021678689867258072
step: 30, loss: 0.04211195185780525
step: 40, loss: 0.0431952103972435
step: 50, loss: 0.0001810266257962212
step: 60, loss: 0.022822275757789612
step: 70, loss: 0.06856801360845566
step: 80, loss: 0.01911872997879982
step: 90, loss: 0.021545594558119774
step: 100, loss: 0.0005037991213612258
step: 110, loss: 0.05423341691493988
step: 120, loss: 0.0010069897398352623
step: 130, loss: 0.09708026051521301
step: 140, loss: 0.025510668754577637
step: 150, loss: 0.027943091467022896
step: 160, loss: 0.04780720919370651
step: 170, loss: 3.532985283527523e-05
step: 180, loss: 0.0448760986328125
step: 190, loss: 0.0739421471953392
step: 200, loss: 0.003127770498394966
step: 210, loss: 0.024301284924149513
step: 220, loss: 0.022136833518743515
step: 230, loss: 2.2275882656686008e-05
step: 240, loss: 3.240377191104926e-05
step: 250, loss: 3.121150439255871e-05
step: 260, loss: 0.10831523686647415
step: 270, loss: 0.018860559910535812
step: 280, loss: 0.011989514343440533
step: 290, loss: 0.0008960752747952938
step: 300, loss: 0.0003872525994665921
step: 310, loss: 0.023715153336524963
step: 320, loss: 0.03678932040929794
step: 330, loss: 0.025487618520855904
step: 340, loss: 0.03873259946703911
step: 350, loss: 0.07301709800958633
step: 360, loss: 4.4690030335914344e-05
step: 370, loss: 0.1019127294421196
step: 380, loss: 8.081026317086071e-05
step: 390, loss: 5.450376193039119e-05
step: 400, loss: 0.048711929470300674
step: 410, loss: 0.031198779121041298
step: 420, loss: 0.0008128248155117035
step: 430, loss: 0.015318957157433033
step: 440, loss: 0.04847487062215805
step: 450, loss: 0.07063258439302444
step: 460, loss: 4.072617957717739e-05
step: 470, loss: 0.04967673867940903
step: 480, loss: 0.02520402893424034
step: 490, loss: 0.055231619626283646
step: 500, loss: 0.018916962668299675
step: 510, loss: 0.06957606226205826
step: 520, loss: 2.5600558728910983e-05
step: 530, loss: 6.711036257911474e-05
step: 540, loss: 0.02136051282286644
step: 550, loss: 0.0185074619948864
step: 560, loss: 0.01996791921555996
step: 570, loss: 0.04272640869021416
step: 580, loss: 0.002007531002163887
step: 590, loss: 0.0006091592949815094
step: 600, loss: 1.385780797136249e-05
step: 610, loss: 0.04062788933515549
step: 620, loss: 0.0012300842208787799
step: 630, loss: 0.023332413285970688
step: 640, loss: 0.028364140540361404
step: 650, loss: 0.0021083003375679255
step: 660, loss: 0.018291044980287552
step: 670, loss: 2.8031165129505098e-05
step: 680, loss: 3.526349610183388e-05
step: 690, loss: 2.773643245745916e-05
step: 700, loss: 0.023130148649215698
step: 710, loss: 5.0468162953620777e-05
step: 720, loss: 0.047111548483371735
step: 730, loss: 0.016671251505613327
step: 740, loss: 5.5246844567591324e-05
step: 750, loss: 0.021896617487072945
step: 760, loss: 0.002846194664016366
step: 770, loss: 0.01879957504570484
step: 780, loss: 0.018718598410487175
step: 790, loss: 0.023445257917046547
step: 800, loss: 4.840733527089469e-05
step: 810, loss: 0.05459466576576233
step: 820, loss: 0.03770598769187927
step: 830, loss: 0.02443452924489975
step: 840, loss: 0.06967895478010178
step: 850, loss: 0.02211994118988514
step: 860, loss: 0.03213350474834442
step: 870, loss: 0.13541275262832642
step: 880, loss: 0.0022884164936840534
step: 890, loss: 0.001047286787070334
step: 900, loss: 0.00020904955454170704
step: 910, loss: 0.09855029731988907
step: 920, loss: 0.02735591121017933
step: 930, loss: 0.045060232281684875
step: 940, loss: 0.017520740628242493
step: 950, loss: 0.059320930391550064
step: 960, loss: 0.18523992598056793
step: 970, loss: 0.0001656135282246396
step: 980, loss: 0.03445182368159294
step: 990, loss: 0.001259279204532504
step: 1000, loss: 0.00016183040861506015
step: 1010, loss: 0.024852406233549118
step: 1020, loss: 0.01600983738899231
step: 1030, loss: 1.7165719327749684e-05
step: 1040, loss: 0.025440601631999016
step: 1050, loss: 1.0695216587919276e-05
step: 1060, loss: 0.03001755103468895
step: 1070, loss: 0.04648297652602196
epoch 19: dev_f1=0.9296037296037295, f1=0.9247113163972287, best_f1=0.9268518518518517
step: 0, loss: 0.011614704504609108
step: 10, loss: 0.056370001286268234
step: 20, loss: 0.028757596388459206
step: 30, loss: 0.04242392256855965
step: 40, loss: 0.023096194490790367
step: 50, loss: 0.08877909928560257
step: 60, loss: 0.026226382702589035
step: 70, loss: 0.041997894644737244
step: 80, loss: 0.0865442082285881
step: 90, loss: 2.8030737666995265e-05
step: 100, loss: 2.0566274542943574e-05
step: 110, loss: 0.061719898134469986
step: 120, loss: 0.0005358443595468998
step: 130, loss: 0.026989806443452835
step: 140, loss: 0.0001513284514658153
step: 150, loss: 0.042372774332761765
step: 160, loss: 5.788984344690107e-05
step: 170, loss: 0.01849525235593319
step: 180, loss: 0.0200719702988863
step: 190, loss: 0.044891174882650375
step: 200, loss: 0.020823007449507713
step: 210, loss: 0.020744943991303444
step: 220, loss: 7.668082980671898e-05
step: 230, loss: 0.028877103701233864
step: 240, loss: 0.018520081415772438
step: 250, loss: 0.026356074959039688
step: 260, loss: 0.016181305050849915
step: 270, loss: 0.00010340464359614998
step: 280, loss: 4.1366685763932765e-05
step: 290, loss: 0.04101146385073662
step: 300, loss: 0.019156290218234062
step: 310, loss: 0.0573510080575943
step: 320, loss: 0.0010912127327173948
step: 330, loss: 0.04868880659341812
step: 340, loss: 1.8915565306087956e-05
step: 350, loss: 0.02245093323290348
step: 360, loss: 0.02802247926592827
step: 370, loss: 2.2671179976896383e-05
step: 380, loss: 0.0702304020524025
step: 390, loss: 0.04928382486104965
step: 400, loss: 0.01797933503985405
step: 410, loss: 3.452653618296608e-05
step: 420, loss: 0.00013608933659270406
step: 430, loss: 2.6704954507295042e-05
step: 440, loss: 0.022949310019612312
step: 450, loss: 8.221033203881234e-05
step: 460, loss: 0.020904242992401123
step: 470, loss: 0.05174075812101364
step: 480, loss: 0.03569016605615616
step: 490, loss: 0.0436355322599411
step: 500, loss: 0.029423853382468224
step: 510, loss: 0.02329956740140915
step: 520, loss: 0.05103931576013565
step: 530, loss: 0.023600932210683823
step: 540, loss: 0.04479571431875229
step: 550, loss: 0.022338110953569412
step: 560, loss: 0.020398208871483803
step: 570, loss: 0.023219475522637367
step: 580, loss: 0.060596764087677
step: 590, loss: 5.038161179982126e-05
step: 600, loss: 0.04839571192860603
step: 610, loss: 0.008576106280088425
step: 620, loss: 0.02485886961221695
step: 630, loss: 0.00169627636205405
step: 640, loss: 0.037069521844387054
step: 650, loss: 0.04469582065939903
step: 660, loss: 0.027879253029823303
step: 670, loss: 0.016969850286841393
step: 680, loss: 0.038096390664577484
step: 690, loss: 1.418198644387303e-05
step: 700, loss: 0.012750505469739437
step: 710, loss: 0.0331198088824749
step: 720, loss: 3.082900002482347e-05
step: 730, loss: 0.0027488956693559885
step: 740, loss: 0.04654787480831146
step: 750, loss: 0.00023692805552855134
step: 760, loss: 0.023726392537355423
step: 770, loss: 0.05666932836174965
step: 780, loss: 0.06055616959929466
step: 790, loss: 0.0014024191768839955
step: 800, loss: 0.04130399599671364
step: 810, loss: 0.02458353340625763
step: 820, loss: 0.0008123019943013787
step: 830, loss: 0.03772376477718353
step: 840, loss: 0.02821306139230728
step: 850, loss: 0.04837077856063843
step: 860, loss: 1.8379860193817876e-05
step: 870, loss: 0.015674082562327385
step: 880, loss: 0.04385646432638168
step: 890, loss: 0.03598964959383011
step: 900, loss: 0.04313213750720024
step: 910, loss: 2.5598585125408135e-05
step: 920, loss: 0.05956016108393669
step: 930, loss: 0.04878063499927521
step: 940, loss: 0.02494019828736782
step: 950, loss: 0.0385124534368515
step: 960, loss: 0.04940200224518776
step: 970, loss: 0.016442211344838142
step: 980, loss: 6.504874909296632e-05
step: 990, loss: 4.496550536714494e-05
step: 1000, loss: 0.02359391376376152
step: 1010, loss: 0.00041159545071423054
step: 1020, loss: 0.018931329250335693
step: 1030, loss: 0.10826098173856735
step: 1040, loss: 2.8366324841044843e-05
step: 1050, loss: 0.0006422451115213335
step: 1060, loss: 0.0006596201565116644
step: 1070, loss: 0.02574816159904003
epoch 20: dev_f1=0.9285380663241476, f1=0.9252206223873664, best_f1=0.9268518518518517
