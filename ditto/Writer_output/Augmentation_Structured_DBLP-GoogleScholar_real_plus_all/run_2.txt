cuda
Device: cuda
step: 0, loss: 0.5595793724060059
step: 10, loss: 0.42404279112815857
step: 20, loss: 0.5130778551101685
step: 30, loss: 0.41160663962364197
step: 40, loss: 0.3178630769252777
step: 50, loss: 0.3478449583053589
step: 60, loss: 0.4043290913105011
step: 70, loss: 0.2297922819852829
step: 80, loss: 0.28281229734420776
step: 90, loss: 0.23884521424770355
step: 100, loss: 0.3740882873535156
step: 110, loss: 0.24030905961990356
step: 120, loss: 0.27453863620758057
step: 130, loss: 0.22130419313907623
step: 140, loss: 0.06488799303770065
step: 150, loss: 0.04081949591636658
step: 160, loss: 0.18191085755825043
step: 170, loss: 0.267193466424942
step: 180, loss: 0.10571309179067612
step: 190, loss: 0.139145165681839
step: 200, loss: 0.1759801208972931
step: 210, loss: 0.13775873184204102
step: 220, loss: 0.1787794679403305
step: 230, loss: 0.14114533364772797
step: 240, loss: 0.14343294501304626
step: 250, loss: 0.16163460910320282
step: 260, loss: 0.12951256334781647
step: 270, loss: 0.05402707681059837
step: 280, loss: 0.08332779258489609
step: 290, loss: 0.2205350697040558
step: 300, loss: 0.09520254284143448
step: 310, loss: 0.11383166164159775
step: 320, loss: 0.04908512905240059
step: 330, loss: 0.1188608929514885
step: 340, loss: 0.018401481211185455
step: 350, loss: 0.1295756846666336
step: 360, loss: 0.14373211562633514
step: 370, loss: 0.11933718621730804
step: 380, loss: 0.10363194346427917
step: 390, loss: 0.16811665892601013
step: 400, loss: 0.05387163534760475
step: 410, loss: 0.06723447144031525
step: 420, loss: 0.07398071140050888
step: 430, loss: 0.1759643405675888
step: 440, loss: 0.1275826245546341
step: 450, loss: 0.024661652743816376
step: 460, loss: 0.18633732199668884
step: 470, loss: 0.0766751766204834
step: 480, loss: 0.01763923652470112
step: 490, loss: 0.09424826502799988
step: 500, loss: 0.21093997359275818
step: 510, loss: 0.2235550582408905
step: 520, loss: 0.07529331743717194
step: 530, loss: 0.06855028867721558
step: 540, loss: 0.04991406947374344
step: 550, loss: 0.2624530792236328
step: 560, loss: 0.0912921130657196
step: 570, loss: 0.3050759434700012
step: 580, loss: 0.14499808847904205
step: 590, loss: 0.10868048667907715
step: 600, loss: 0.17851568758487701
step: 610, loss: 0.18263398110866547
step: 620, loss: 0.05235441029071808
step: 630, loss: 0.02663862518966198
step: 640, loss: 0.09727704524993896
step: 650, loss: 0.15568721294403076
step: 660, loss: 0.17958885431289673
step: 670, loss: 0.7457972168922424
step: 680, loss: 0.1617204248905182
step: 690, loss: 0.09611819684505463
step: 700, loss: 0.07846163213253021
step: 710, loss: 0.03723461180925369
step: 720, loss: 0.040838032960891724
step: 730, loss: 0.04215208441019058
step: 740, loss: 0.048911966383457184
step: 750, loss: 0.01716325432062149
step: 760, loss: 0.10117591917514801
step: 770, loss: 0.009626814164221287
step: 780, loss: 0.06607800722122192
step: 790, loss: 0.10433409363031387
step: 800, loss: 0.10513855516910553
step: 810, loss: 0.12806996703147888
step: 820, loss: 0.16935589909553528
step: 830, loss: 0.10501494258642197
step: 840, loss: 0.12446486949920654
step: 850, loss: 0.17753636837005615
step: 860, loss: 0.056023236364126205
step: 870, loss: 0.15126830339431763
step: 880, loss: 0.1550828367471695
step: 890, loss: 0.35372400283813477
step: 900, loss: 0.2677280902862549
step: 910, loss: 0.042313992977142334
step: 920, loss: 0.02287008799612522
step: 930, loss: 0.10090786218643188
step: 940, loss: 0.029601246118545532
step: 950, loss: 0.07165336608886719
step: 960, loss: 0.033353306353092194
step: 970, loss: 0.07184717059135437
step: 980, loss: 0.09694355726242065
step: 990, loss: 0.09805209934711456
step: 1000, loss: 0.09046884626150131
step: 1010, loss: 0.19146546721458435
step: 1020, loss: 0.257004052400589
step: 1030, loss: 0.06357540190219879
step: 1040, loss: 0.17788690328598022
step: 1050, loss: 0.2683735489845276
step: 1060, loss: 0.0780215859413147
step: 1070, loss: 0.1221264973282814
epoch 1: dev_f1=0.9307942405945193, f1=0.9242916860195076, best_f1=0.9242916860195076
step: 0, loss: 0.12521708011627197
step: 10, loss: 0.08527413755655289
step: 20, loss: 0.07333293557167053
step: 30, loss: 0.07426824420690536
step: 40, loss: 0.06091392785310745
step: 50, loss: 0.1693740338087082
step: 60, loss: 0.0442400798201561
step: 70, loss: 0.007533778436481953
step: 80, loss: 0.04171557351946831
step: 90, loss: 0.20454320311546326
step: 100, loss: 0.14933548867702484
step: 110, loss: 0.07711765915155411
step: 120, loss: 0.04971737042069435
step: 130, loss: 0.2523082494735718
step: 140, loss: 0.17178170382976532
step: 150, loss: 0.0996486097574234
step: 160, loss: 0.05761327967047691
step: 170, loss: 0.044926803559064865
step: 180, loss: 0.1369284987449646
step: 190, loss: 0.10594726353883743
step: 200, loss: 0.08246750384569168
step: 210, loss: 0.09216049313545227
step: 220, loss: 0.12422467023134232
step: 230, loss: 0.018093034625053406
step: 240, loss: 0.07933858782052994
step: 250, loss: 0.07544758170843124
step: 260, loss: 0.057083550840616226
step: 270, loss: 0.13134635984897614
step: 280, loss: 0.01300989743322134
step: 290, loss: 0.1996549814939499
step: 300, loss: 0.015057737939059734
step: 310, loss: 0.0732765942811966
step: 320, loss: 0.036823976784944534
step: 330, loss: 0.10346707701683044
step: 340, loss: 0.025543754920363426
step: 350, loss: 0.07934045046567917
step: 360, loss: 0.06152156740427017
step: 370, loss: 0.024334268644452095
step: 380, loss: 0.019668729975819588
step: 390, loss: 0.10276423394680023
step: 400, loss: 0.12201148271560669
step: 410, loss: 0.1004648506641388
step: 420, loss: 0.17969229817390442
step: 430, loss: 0.044979654252529144
step: 440, loss: 0.07941789925098419
step: 450, loss: 0.08769460767507553
step: 460, loss: 0.2525855302810669
step: 470, loss: 0.10468917340040207
step: 480, loss: 0.014645536430180073
step: 490, loss: 0.023915475234389305
step: 500, loss: 0.08628875762224197
step: 510, loss: 0.18651893734931946
step: 520, loss: 0.10010457038879395
step: 530, loss: 0.026811152696609497
step: 540, loss: 0.05098608136177063
step: 550, loss: 0.12359242141246796
step: 560, loss: 0.03644289821386337
step: 570, loss: 0.08781023323535919
step: 580, loss: 0.01960405334830284
step: 590, loss: 0.047816768288612366
step: 600, loss: 0.012931660749018192
step: 610, loss: 0.09656822681427002
step: 620, loss: 0.06803660839796066
step: 630, loss: 0.10731366276741028
step: 640, loss: 0.04794194921851158
step: 650, loss: 0.0639280378818512
step: 660, loss: 0.16364626586437225
step: 670, loss: 0.05825032293796539
step: 680, loss: 0.04382402449846268
step: 690, loss: 0.14263182878494263
step: 700, loss: 0.033258721232414246
step: 710, loss: 0.12318697571754456
step: 720, loss: 0.03809386491775513
step: 730, loss: 0.09104537963867188
step: 740, loss: 0.05175842344760895
step: 750, loss: 0.02246181294322014
step: 760, loss: 0.10249479860067368
step: 770, loss: 0.19991518557071686
step: 780, loss: 0.09913317114114761
step: 790, loss: 0.08854001015424728
step: 800, loss: 0.13280300796031952
step: 810, loss: 0.14637391269207
step: 820, loss: 0.04761659726500511
step: 830, loss: 0.1265743523836136
step: 840, loss: 0.06639435142278671
step: 850, loss: 0.10905072093009949
step: 860, loss: 0.017259841784834862
step: 870, loss: 0.020916126668453217
step: 880, loss: 0.052915338426828384
step: 890, loss: 0.03524240106344223
step: 900, loss: 0.14463989436626434
step: 910, loss: 0.3282512426376343
step: 920, loss: 0.1103840172290802
step: 930, loss: 0.08195129781961441
step: 940, loss: 0.051550645381212234
step: 950, loss: 0.012334282509982586
step: 960, loss: 0.09130386263132095
step: 970, loss: 0.008927094750106335
step: 980, loss: 0.07312971353530884
step: 990, loss: 0.0752173438668251
step: 1000, loss: 0.03545815125107765
step: 1010, loss: 0.026390325278043747
step: 1020, loss: 0.052714020013809204
step: 1030, loss: 0.1706577092409134
step: 1040, loss: 0.07535870373249054
step: 1050, loss: 0.11427675187587738
step: 1060, loss: 0.1348065286874771
step: 1070, loss: 0.035482537001371384
epoch 2: dev_f1=0.9341317365269461, f1=0.9356617647058824, best_f1=0.9356617647058824
step: 0, loss: 0.13045534491539001
step: 10, loss: 0.091730035841465
step: 20, loss: 0.054663386195898056
step: 30, loss: 0.013723992742598057
step: 40, loss: 0.1255502700805664
step: 50, loss: 0.05709370970726013
step: 60, loss: 0.04659011960029602
step: 70, loss: 0.1050698459148407
step: 80, loss: 0.03332127258181572
step: 90, loss: 0.12716428935527802
step: 100, loss: 0.018543049693107605
step: 110, loss: 0.12183284759521484
step: 120, loss: 0.09479983896017075
step: 130, loss: 0.019512344151735306
step: 140, loss: 0.10795413702726364
step: 150, loss: 0.08937899023294449
step: 160, loss: 0.022254256531596184
step: 170, loss: 0.012281849980354309
step: 180, loss: 0.02644544281065464
step: 190, loss: 0.12783662974834442
step: 200, loss: 0.0924275740981102
step: 210, loss: 0.115175262093544
step: 220, loss: 0.02897672727704048
step: 230, loss: 0.23924703896045685
step: 240, loss: 0.11314898729324341
step: 250, loss: 0.07511083036661148
step: 260, loss: 0.09754571318626404
step: 270, loss: 0.09171588718891144
step: 280, loss: 0.013073140755295753
step: 290, loss: 0.08226306736469269
step: 300, loss: 0.01718354970216751
step: 310, loss: 0.017258401960134506
step: 320, loss: 0.03340287134051323
step: 330, loss: 0.0007460466003976762
step: 340, loss: 0.04648182913661003
step: 350, loss: 0.1260044276714325
step: 360, loss: 0.1098921149969101
step: 370, loss: 0.08647020161151886
step: 380, loss: 0.06967172771692276
step: 390, loss: 0.022998977452516556
step: 400, loss: 0.018506111577153206
step: 410, loss: 0.05254870653152466
step: 420, loss: 0.050926219671964645
step: 430, loss: 0.07009410113096237
step: 440, loss: 0.07476368546485901
step: 450, loss: 0.07042579352855682
step: 460, loss: 0.10295943915843964
step: 470, loss: 0.06171069294214249
step: 480, loss: 0.06674826145172119
step: 490, loss: 0.026394866406917572
step: 500, loss: 0.06570424139499664
step: 510, loss: 0.07297216355800629
step: 520, loss: 0.02562570758163929
step: 530, loss: 0.0759732723236084
step: 540, loss: 0.02882874570786953
step: 550, loss: 0.06730644404888153
step: 560, loss: 0.08282916992902756
step: 570, loss: 0.017880145460367203
step: 580, loss: 0.19372479617595673
step: 590, loss: 0.19172857701778412
step: 600, loss: 0.06171160563826561
step: 610, loss: 0.09523757547140121
step: 620, loss: 0.16696439683437347
step: 630, loss: 0.018574004992842674
step: 640, loss: 0.04811404272913933
step: 650, loss: 0.06650561839342117
step: 660, loss: 0.06019647419452667
step: 670, loss: 0.09069177508354187
step: 680, loss: 0.020513510331511497
step: 690, loss: 0.06297656893730164
step: 700, loss: 0.19737933576107025
step: 710, loss: 0.045014988631010056
step: 720, loss: 0.02690952457487583
step: 730, loss: 0.0849275067448616
step: 740, loss: 0.08163970708847046
step: 750, loss: 0.1028631329536438
step: 760, loss: 0.3946211040019989
step: 770, loss: 0.033002451062202454
step: 780, loss: 0.1929633915424347
step: 790, loss: 0.15297654271125793
step: 800, loss: 0.028182590380311012
step: 810, loss: 0.07393624633550644
step: 820, loss: 0.028641654178500175
step: 830, loss: 0.01784960739314556
step: 840, loss: 0.09445764124393463
step: 850, loss: 0.09233713150024414
step: 860, loss: 0.03309296816587448
step: 870, loss: 0.011733585968613625
step: 880, loss: 0.0763283371925354
step: 890, loss: 0.08409246057271957
step: 900, loss: 0.04388822987675667
step: 910, loss: 0.035921890288591385
step: 920, loss: 0.09198499470949173
step: 930, loss: 0.020383188501000404
step: 940, loss: 0.1057906374335289
step: 950, loss: 0.00019500908092595637
step: 960, loss: 0.07335381954908371
step: 970, loss: 0.10644669085741043
step: 980, loss: 0.05212382599711418
step: 990, loss: 0.006756490096449852
step: 1000, loss: 0.052202899008989334
step: 1010, loss: 0.060788314789533615
step: 1020, loss: 0.043416578322649
step: 1030, loss: 0.07171915471553802
step: 1040, loss: 0.06286095082759857
step: 1050, loss: 0.13717734813690186
step: 1060, loss: 0.07970696687698364
step: 1070, loss: 0.15313658118247986
epoch 3: dev_f1=0.9385113268608415, f1=0.9340761374187557, best_f1=0.9340761374187557
step: 0, loss: 0.006699846591800451
step: 10, loss: 0.11494376510381699
step: 20, loss: 0.027620874345302582
step: 30, loss: 0.11410225927829742
step: 40, loss: 0.07011637836694717
step: 50, loss: 0.10959865897893906
step: 60, loss: 0.06941567361354828
step: 70, loss: 0.024859920144081116
step: 80, loss: 0.14854514598846436
step: 90, loss: 0.10114169865846634
step: 100, loss: 0.015010768547654152
step: 110, loss: 0.01593879610300064
step: 120, loss: 0.06994757056236267
step: 130, loss: 0.12498093396425247
step: 140, loss: 0.2013208121061325
step: 150, loss: 0.01286363136023283
step: 160, loss: 0.03908221051096916
step: 170, loss: 0.16925585269927979
step: 180, loss: 0.22286076843738556
step: 190, loss: 0.019374746829271317
step: 200, loss: 0.025064822286367416
step: 210, loss: 0.07317003607749939
step: 220, loss: 0.051214441657066345
step: 230, loss: 0.1474144160747528
step: 240, loss: 0.07227911055088043
step: 250, loss: 0.07582439482212067
step: 260, loss: 0.11653141677379608
step: 270, loss: 0.037487778812646866
step: 280, loss: 0.10888578742742538
step: 290, loss: 0.055101893842220306
step: 300, loss: 0.1085711121559143
step: 310, loss: 0.0849810391664505
step: 320, loss: 0.029379963874816895
step: 330, loss: 0.08579262346029282
step: 340, loss: 0.17625093460083008
step: 350, loss: 0.020238757133483887
step: 360, loss: 0.10477321594953537
step: 370, loss: 0.0911129042506218
step: 380, loss: 0.02401517517864704
step: 390, loss: 0.009365048259496689
step: 400, loss: 0.08393684029579163
step: 410, loss: 0.06733203679323196
step: 420, loss: 0.11898550391197205
step: 430, loss: 0.06703467667102814
step: 440, loss: 0.12642022967338562
step: 450, loss: 0.02217084728181362
step: 460, loss: 0.09579703211784363
step: 470, loss: 0.07504228502511978
step: 480, loss: 0.02118944562971592
step: 490, loss: 0.07279019802808762
step: 500, loss: 0.013520389795303345
step: 510, loss: 0.11354111135005951
step: 520, loss: 0.029713936150074005
step: 530, loss: 0.07930723577737808
step: 540, loss: 0.0210860725492239
step: 550, loss: 0.03941091522574425
step: 560, loss: 0.0756736546754837
step: 570, loss: 0.019973160699009895
step: 580, loss: 0.05260583758354187
step: 590, loss: 0.054268836975097656
step: 600, loss: 0.042563460767269135
step: 610, loss: 0.025514371693134308
step: 620, loss: 0.08262504637241364
step: 630, loss: 0.07929295301437378
step: 640, loss: 0.05855252593755722
step: 650, loss: 0.12461365014314651
step: 660, loss: 0.04085070639848709
step: 670, loss: 0.10610494017601013
step: 680, loss: 0.11752767860889435
step: 690, loss: 0.08089862763881683
step: 700, loss: 0.02446785941720009
step: 710, loss: 0.022334091365337372
step: 720, loss: 0.18168926239013672
step: 730, loss: 0.09950876981019974
step: 740, loss: 0.04837660491466522
step: 750, loss: 0.10046741366386414
step: 760, loss: 0.09807294607162476
step: 770, loss: 0.04328957572579384
step: 780, loss: 0.02987213060259819
step: 790, loss: 0.03404427692294121
step: 800, loss: 0.0725906640291214
step: 810, loss: 0.08883561193943024
step: 820, loss: 0.07124462723731995
step: 830, loss: 0.14480867981910706
step: 840, loss: 0.06364524364471436
step: 850, loss: 0.015411797910928726
step: 860, loss: 0.028135551139712334
step: 870, loss: 0.11618675291538239
step: 880, loss: 0.033787939697504044
step: 890, loss: 0.0335502028465271
step: 900, loss: 0.06983528286218643
step: 910, loss: 0.052244897931814194
step: 920, loss: 0.04542364180088043
step: 930, loss: 0.010501500219106674
step: 940, loss: 0.0676705613732338
step: 950, loss: 0.05477119982242584
step: 960, loss: 0.0743110254406929
step: 970, loss: 0.0577387772500515
step: 980, loss: 0.05249721184372902
step: 990, loss: 0.10331936180591583
step: 1000, loss: 0.08404449373483658
step: 1010, loss: 0.06441792845726013
step: 1020, loss: 0.10253727436065674
step: 1030, loss: 0.056957874447107315
step: 1040, loss: 0.00724068796262145
step: 1050, loss: 0.03419751301407814
step: 1060, loss: 0.04631144180893898
step: 1070, loss: 0.01517355628311634
epoch 4: dev_f1=0.9307298930729893, f1=0.9321642824180896, best_f1=0.9340761374187557
step: 0, loss: 0.027872804552316666
step: 10, loss: 0.17252549529075623
step: 20, loss: 0.06353021413087845
step: 30, loss: 0.03994663059711456
step: 40, loss: 0.05305851250886917
step: 50, loss: 0.05490285903215408
step: 60, loss: 0.012867772951722145
step: 70, loss: 0.1086760014295578
step: 80, loss: 0.05127487704157829
step: 90, loss: 0.01901085674762726
step: 100, loss: 0.019512129947543144
step: 110, loss: 0.014267281629145145
step: 120, loss: 0.07850610464811325
step: 130, loss: 0.06138310208916664
step: 140, loss: 0.08090080320835114
step: 150, loss: 5.829657311551273e-05
step: 160, loss: 0.012864230200648308
step: 170, loss: 0.01755499467253685
step: 180, loss: 0.07683523744344711
step: 190, loss: 0.07185948640108109
step: 200, loss: 0.010378921404480934
step: 210, loss: 0.019922800362110138
step: 220, loss: 0.0544615276157856
step: 230, loss: 0.046974360942840576
step: 240, loss: 0.06658294796943665
step: 250, loss: 0.06664780527353287
step: 260, loss: 0.02582845836877823
step: 270, loss: 0.020487546920776367
step: 280, loss: 0.14039771258831024
step: 290, loss: 0.1277237981557846
step: 300, loss: 0.22356855869293213
step: 310, loss: 0.014294658787548542
step: 320, loss: 0.07840213179588318
step: 330, loss: 0.08569329231977463
step: 340, loss: 0.055233098566532135
step: 350, loss: 0.09001077711582184
step: 360, loss: 0.07082259654998779
step: 370, loss: 0.014537603594362736
step: 380, loss: 0.04197564721107483
step: 390, loss: 0.012927733361721039
step: 400, loss: 0.01066421065479517
step: 410, loss: 0.07212947309017181
step: 420, loss: 0.11425840854644775
step: 430, loss: 0.14588864147663116
step: 440, loss: 0.08761940151453018
step: 450, loss: 0.05323836952447891
step: 460, loss: 0.005325664300471544
step: 470, loss: 0.0019289731280878186
step: 480, loss: 0.12806782126426697
step: 490, loss: 0.2253113090991974
step: 500, loss: 0.043684057891368866
step: 510, loss: 0.04877983406186104
step: 520, loss: 0.060402266681194305
step: 530, loss: 0.02369878441095352
step: 540, loss: 0.07980135828256607
step: 550, loss: 0.048042140901088715
step: 560, loss: 0.005654428619891405
step: 570, loss: 0.018668513745069504
step: 580, loss: 0.18858876824378967
step: 590, loss: 0.14595390856266022
step: 600, loss: 0.058629654347896576
step: 610, loss: 0.031199699267745018
step: 620, loss: 0.03361649438738823
step: 630, loss: 0.06765634566545486
step: 640, loss: 0.05389276146888733
step: 650, loss: 0.07468147575855255
step: 660, loss: 0.08197848498821259
step: 670, loss: 0.02437521517276764
step: 680, loss: 0.02412417158484459
step: 690, loss: 0.08587262779474258
step: 700, loss: 0.026321304962038994
step: 710, loss: 0.05917114019393921
step: 720, loss: 0.08491943031549454
step: 730, loss: 0.0784982368350029
step: 740, loss: 0.06893348693847656
step: 750, loss: 0.05886673182249069
step: 760, loss: 0.02168050967156887
step: 770, loss: 0.074824258685112
step: 780, loss: 0.034348368644714355
step: 790, loss: 0.029536904767155647
step: 800, loss: 0.06367388367652893
step: 810, loss: 0.04152103140950203
step: 820, loss: 0.07393840700387955
step: 830, loss: 0.0710204541683197
step: 840, loss: 0.0037791195791214705
step: 850, loss: 0.11434880644083023
step: 860, loss: 0.0005933998618274927
step: 870, loss: 0.06839179247617722
step: 880, loss: 0.03983442485332489
step: 890, loss: 0.09074076265096664
step: 900, loss: 0.15228311717510223
step: 910, loss: 0.019254149869084358
step: 920, loss: 0.07646571099758148
step: 930, loss: 0.026781445369124413
step: 940, loss: 0.052980389446020126
step: 950, loss: 0.017433948814868927
step: 960, loss: 0.01502328459173441
step: 970, loss: 0.03334233537316322
step: 980, loss: 0.07326990365982056
step: 990, loss: 0.021376488730311394
step: 1000, loss: 0.027559073641896248
step: 1010, loss: 0.0001142914843512699
step: 1020, loss: 0.0697721317410469
step: 1030, loss: 0.18951734900474548
step: 1040, loss: 0.061620455235242844
step: 1050, loss: 0.000964723585639149
step: 1060, loss: 0.11815305054187775
step: 1070, loss: 0.032113660126924515
epoch 5: dev_f1=0.9277496548550391, f1=0.9276714885674288, best_f1=0.9340761374187557
step: 0, loss: 0.008411996066570282
step: 10, loss: 0.02087700366973877
step: 20, loss: 0.019492529332637787
step: 30, loss: 0.0676269456744194
step: 40, loss: 0.005053017754107714
step: 50, loss: 0.08675119280815125
step: 60, loss: 0.002016698941588402
step: 70, loss: 0.0163949616253376
step: 80, loss: 0.018546737730503082
step: 90, loss: 0.1793290078639984
step: 100, loss: 0.09422421455383301
step: 110, loss: 0.01821635104715824
step: 120, loss: 0.05760832130908966
step: 130, loss: 0.055333953350782394
step: 140, loss: 0.05469006299972534
step: 150, loss: 0.04432988911867142
step: 160, loss: 0.03214893490076065
step: 170, loss: 0.006460078060626984
step: 180, loss: 0.09866794943809509
step: 190, loss: 0.012032922357320786
step: 200, loss: 0.017144422978162766
step: 210, loss: 0.1951315999031067
step: 220, loss: 0.023494794964790344
step: 230, loss: 0.012425909750163555
step: 240, loss: 0.03493885323405266
step: 250, loss: 0.0060339635238051414
step: 260, loss: 0.05901633948087692
step: 270, loss: 0.010580020025372505
step: 280, loss: 0.03886930271983147
step: 290, loss: 0.010904214344918728
step: 300, loss: 0.08969850838184357
step: 310, loss: 0.020427480340003967
step: 320, loss: 0.026442332193255424
step: 330, loss: 0.05411764979362488
step: 340, loss: 0.016518080607056618
step: 350, loss: 0.057994965463876724
step: 360, loss: 0.06895896792411804
step: 370, loss: 0.027033187448978424
step: 380, loss: 0.031491685658693314
step: 390, loss: 0.09806298464536667
step: 400, loss: 0.05713147297501564
step: 410, loss: 0.05252059921622276
step: 420, loss: 0.12550097703933716
step: 430, loss: 0.023281119763851166
step: 440, loss: 0.068307064473629
step: 450, loss: 0.02325914055109024
step: 460, loss: 0.020596608519554138
step: 470, loss: 0.015365652740001678
step: 480, loss: 0.08409778773784637
step: 490, loss: 0.08519431948661804
step: 500, loss: 0.022295229136943817
step: 510, loss: 0.06524991989135742
step: 520, loss: 0.02732844091951847
step: 530, loss: 0.01764557510614395
step: 540, loss: 0.10362857580184937
step: 550, loss: 0.035250160843133926
step: 560, loss: 0.10618684440851212
step: 570, loss: 0.04892046004533768
step: 580, loss: 0.010811574757099152
step: 590, loss: 0.0892847329378128
step: 600, loss: 0.0350685641169548
step: 610, loss: 0.04251467436552048
step: 620, loss: 0.010709729045629501
step: 630, loss: 0.22696669399738312
step: 640, loss: 0.07132470607757568
step: 650, loss: 0.11976273357868195
step: 660, loss: 0.023433847352862358
step: 670, loss: 0.08785949647426605
step: 680, loss: 0.011509668081998825
step: 690, loss: 0.037042807787656784
step: 700, loss: 0.037483684718608856
step: 710, loss: 0.006942081730812788
step: 720, loss: 0.008886480703949928
step: 730, loss: 0.14697480201721191
step: 740, loss: 0.07984453439712524
step: 750, loss: 0.11637081950902939
step: 760, loss: 0.07623721659183502
step: 770, loss: 0.04740345850586891
step: 780, loss: 0.013385487720370293
step: 790, loss: 0.0345517061650753
step: 800, loss: 0.027503719553351402
step: 810, loss: 0.010529791004955769
step: 820, loss: 0.05994923785328865
step: 830, loss: 0.09202752262353897
step: 840, loss: 0.06335500627756119
step: 850, loss: 0.10072240978479385
step: 860, loss: 0.107478566467762
step: 870, loss: 0.020768018439412117
step: 880, loss: 0.06496822088956833
step: 890, loss: 0.02336079254746437
step: 900, loss: 0.07538198679685593
step: 910, loss: 0.08431961387395859
step: 920, loss: 0.06756791472434998
step: 930, loss: 0.06649918854236603
step: 940, loss: 0.008947096765041351
step: 950, loss: 0.12553070485591888
step: 960, loss: 0.0001562793622724712
step: 970, loss: 0.11784576624631882
step: 980, loss: 0.026530802249908447
step: 990, loss: 0.0423942431807518
step: 1000, loss: 0.1324518620967865
step: 1010, loss: 0.014589618891477585
step: 1020, loss: 0.4324844479560852
step: 1030, loss: 0.015648450702428818
step: 1040, loss: 0.01074211485683918
step: 1050, loss: 0.0362614281475544
step: 1060, loss: 0.07213285565376282
step: 1070, loss: 0.01253863237798214
epoch 6: dev_f1=0.9358560221504384, f1=0.9322820037105751, best_f1=0.9340761374187557
step: 0, loss: 0.1827278733253479
step: 10, loss: 0.021897954866290092
step: 20, loss: 0.09236843883991241
step: 30, loss: 0.03890332952141762
step: 40, loss: 0.008633802644908428
step: 50, loss: 0.02122662402689457
step: 60, loss: 0.10517537593841553
step: 70, loss: 0.05446021258831024
step: 80, loss: 0.0493050180375576
step: 90, loss: 0.0653599426150322
step: 100, loss: 0.14374637603759766
step: 110, loss: 0.004212577827274799
step: 120, loss: 0.013792959041893482
step: 130, loss: 0.11075425148010254
step: 140, loss: 0.03408561646938324
step: 150, loss: 0.07956176996231079
step: 160, loss: 0.05295756086707115
step: 170, loss: 0.025784911587834358
step: 180, loss: 0.00707046315073967
step: 190, loss: 0.05849944427609444
step: 200, loss: 0.10268498957157135
step: 210, loss: 0.06797856837511063
step: 220, loss: 0.036420147866010666
step: 230, loss: 0.07543962448835373
step: 240, loss: 0.009442905895411968
step: 250, loss: 0.10602432489395142
step: 260, loss: 0.10474179685115814
step: 270, loss: 0.006967546418309212
step: 280, loss: 0.0381062775850296
step: 290, loss: 0.07276728004217148
step: 300, loss: 0.01131510827690363
step: 310, loss: 0.08569817245006561
step: 320, loss: 0.0017128188628703356
step: 330, loss: 0.12989823520183563
step: 340, loss: 0.06469161808490753
step: 350, loss: 0.00020677979046013206
step: 360, loss: 0.028296729549765587
step: 370, loss: 0.1255042850971222
step: 380, loss: 0.21088162064552307
step: 390, loss: 0.09093598276376724
step: 400, loss: 0.053634729236364365
step: 410, loss: 0.11917883902788162
step: 420, loss: 0.09121384471654892
step: 430, loss: 0.006985449697822332
step: 440, loss: 0.03855964541435242
step: 450, loss: 0.07709775865077972
step: 460, loss: 0.05337758734822273
step: 470, loss: 0.1363823413848877
step: 480, loss: 0.01678393967449665
step: 490, loss: 0.055943191051483154
step: 500, loss: 0.08275304734706879
step: 510, loss: 0.011740123853087425
step: 520, loss: 0.06071247160434723
step: 530, loss: 0.046529918909072876
step: 540, loss: 0.056408144533634186
step: 550, loss: 0.05818578600883484
step: 560, loss: 0.06732605397701263
step: 570, loss: 0.12604035437107086
step: 580, loss: 0.023291191086173058
step: 590, loss: 0.03130318224430084
step: 600, loss: 0.006750949192792177
step: 610, loss: 0.015005105175077915
step: 620, loss: 0.10306347906589508
step: 630, loss: 0.09226943552494049
step: 640, loss: 0.10146240144968033
step: 650, loss: 0.010939349420368671
step: 660, loss: 0.02349044568836689
step: 670, loss: 0.039050254970788956
step: 680, loss: 0.09129559248685837
step: 690, loss: 0.018633052706718445
step: 700, loss: 0.029688760638237
step: 710, loss: 0.06893634796142578
step: 720, loss: 0.07671842724084854
step: 730, loss: 0.016076959669589996
step: 740, loss: 0.10516277700662613
step: 750, loss: 0.008231169544160366
step: 760, loss: 0.017868192866444588
step: 770, loss: 0.02318301610648632
step: 780, loss: 0.06383080780506134
step: 790, loss: 0.014473599381744862
step: 800, loss: 0.008770344778895378
step: 810, loss: 0.0002675559080671519
step: 820, loss: 0.009772094897925854
step: 830, loss: 0.006891130469739437
step: 840, loss: 0.006390562746673822
step: 850, loss: 0.013758109882473946
step: 860, loss: 0.02247684635221958
step: 870, loss: 0.004995689261704683
step: 880, loss: 0.032950807362794876
step: 890, loss: 0.016829190775752068
step: 900, loss: 0.12248650938272476
step: 910, loss: 0.021392667666077614
step: 920, loss: 0.21531298756599426
step: 930, loss: 0.0899304673075676
step: 940, loss: 0.07200631499290466
step: 950, loss: 0.006050048395991325
step: 960, loss: 0.020089197903871536
step: 970, loss: 0.0036822459660470486
step: 980, loss: 0.053818851709365845
step: 990, loss: 0.0064100236631929874
step: 1000, loss: 0.02311638928949833
step: 1010, loss: 0.07928674668073654
step: 1020, loss: 0.006409193854779005
step: 1030, loss: 0.12094622105360031
step: 1040, loss: 0.019155506044626236
step: 1050, loss: 0.013266248628497124
step: 1060, loss: 0.008384348824620247
step: 1070, loss: 0.0979740172624588
epoch 7: dev_f1=0.9291044776119404, f1=0.9217877094972067, best_f1=0.9340761374187557
step: 0, loss: 0.033324699848890305
step: 10, loss: 0.054720327258110046
step: 20, loss: 0.021748779341578484
step: 30, loss: 0.040564414113759995
step: 40, loss: 0.07201094180345535
step: 50, loss: 0.1148490235209465
step: 60, loss: 0.0732000544667244
step: 70, loss: 0.07447140663862228
step: 80, loss: 0.05595209822058678
step: 90, loss: 0.11985006928443909
step: 100, loss: 0.04929644614458084
step: 110, loss: 0.00028700815164484084
step: 120, loss: 0.11669580638408661
step: 130, loss: 0.036584507673978806
step: 140, loss: 0.0031945419032126665
step: 150, loss: 0.015135079622268677
step: 160, loss: 0.0584079772233963
step: 170, loss: 0.023978151381015778
step: 180, loss: 0.01701490953564644
step: 190, loss: 0.0860438346862793
step: 200, loss: 0.1174163743853569
step: 210, loss: 9.525860514258966e-05
step: 220, loss: 0.009219009429216385
step: 230, loss: 0.03005794622004032
step: 240, loss: 0.006437021307647228
step: 250, loss: 0.05852709338068962
step: 260, loss: 0.021311746910214424
step: 270, loss: 0.010994126088917255
step: 280, loss: 0.03757936879992485
step: 290, loss: 0.05333636701107025
step: 300, loss: 0.019525472074747086
step: 310, loss: 0.0644768550992012
step: 320, loss: 0.058823566883802414
step: 330, loss: 0.019360149279236794
step: 340, loss: 0.032266173511743546
step: 350, loss: 0.0745352953672409
step: 360, loss: 0.11452026665210724
step: 370, loss: 0.02693333476781845
step: 380, loss: 0.09877848625183105
step: 390, loss: 0.004758454859256744
step: 400, loss: 0.012128490954637527
step: 410, loss: 0.03739282116293907
step: 420, loss: 0.0955488458275795
step: 430, loss: 0.11082682013511658
step: 440, loss: 0.061723727732896805
step: 450, loss: 0.01761009357869625
step: 460, loss: 0.015186530537903309
step: 470, loss: 0.023138055577874184
step: 480, loss: 0.08583798259496689
step: 490, loss: 0.011590925045311451
step: 500, loss: 0.025642842054367065
step: 510, loss: 0.12225013226270676
step: 520, loss: 0.15133816003799438
step: 530, loss: 0.04201684519648552
step: 540, loss: 0.1495841145515442
step: 550, loss: 0.10549504309892654
step: 560, loss: 0.0758805125951767
step: 570, loss: 0.015449661761522293
step: 580, loss: 0.06263748556375504
step: 590, loss: 0.05906863510608673
step: 600, loss: 0.01368317473679781
step: 610, loss: 0.005190965253859758
step: 620, loss: 0.008611622266471386
step: 630, loss: 0.00922418013215065
step: 640, loss: 0.004348963964730501
step: 650, loss: 0.028805183246731758
step: 660, loss: 0.065645232796669
step: 670, loss: 0.06974393874406815
step: 680, loss: 0.10205469280481339
step: 690, loss: 0.01892077922821045
step: 700, loss: 0.10327596962451935
step: 710, loss: 0.13399861752986908
step: 720, loss: 0.1270962953567505
step: 730, loss: 0.028913365676999092
step: 740, loss: 0.16145475208759308
step: 750, loss: 0.06758298724889755
step: 760, loss: 0.07658779621124268
step: 770, loss: 0.07978940010070801
step: 780, loss: 0.03530809283256531
step: 790, loss: 0.05693275108933449
step: 800, loss: 0.023646553978323936
step: 810, loss: 0.1925087869167328
step: 820, loss: 0.03479455038905144
step: 830, loss: 0.01588609255850315
step: 840, loss: 0.1324736475944519
step: 850, loss: 0.060281749814748764
step: 860, loss: 0.05491608753800392
step: 870, loss: 0.048251744359731674
step: 880, loss: 0.1195903792977333
step: 890, loss: 0.022339902818202972
step: 900, loss: 0.005594935733824968
step: 910, loss: 0.008645548485219479
step: 920, loss: 0.0996861457824707
step: 930, loss: 0.025840334594249725
step: 940, loss: 0.05992602929472923
step: 950, loss: 0.07746266573667526
step: 960, loss: 0.005697429180145264
step: 970, loss: 0.08720766752958298
step: 980, loss: 0.043785806745290756
step: 990, loss: 0.03892220929265022
step: 1000, loss: 0.05974680930376053
step: 1010, loss: 0.1077616959810257
step: 1020, loss: 0.03363514319062233
step: 1030, loss: 0.06740467250347137
step: 1040, loss: 0.061128173023462296
step: 1050, loss: 0.016166582703590393
step: 1060, loss: 0.03515257686376572
step: 1070, loss: 0.07801800966262817
epoch 8: dev_f1=0.9312413474850022, f1=0.928735632183908, best_f1=0.9340761374187557
step: 0, loss: 0.12002239376306534
step: 10, loss: 0.048503413796424866
step: 20, loss: 0.04051601141691208
step: 30, loss: 0.00038735015550628304
step: 40, loss: 0.05890925973653793
step: 50, loss: 0.12161318957805634
step: 60, loss: 0.02392488531768322
step: 70, loss: 0.017879365012049675
step: 80, loss: 0.01237561833113432
step: 90, loss: 0.03673633933067322
step: 100, loss: 0.046481721103191376
step: 110, loss: 0.007172623183578253
step: 120, loss: 0.048010583966970444
step: 130, loss: 0.10436892509460449
step: 140, loss: 0.019260982051491737
step: 150, loss: 0.03656652569770813
step: 160, loss: 0.026557933539152145
step: 170, loss: 0.035172268748283386
step: 180, loss: 0.056325607001781464
step: 190, loss: 0.025726737454533577
step: 200, loss: 0.002438575029373169
step: 210, loss: 0.18407008051872253
step: 220, loss: 0.02517641894519329
step: 230, loss: 0.01607213355600834
step: 240, loss: 0.018182553350925446
step: 250, loss: 0.051391541957855225
step: 260, loss: 0.028776952996850014
step: 270, loss: 0.006433607079088688
step: 280, loss: 0.009470333345234394
step: 290, loss: 0.05978337675333023
step: 300, loss: 0.003931483253836632
step: 310, loss: 0.037225570529699326
step: 320, loss: 0.012794531881809235
step: 330, loss: 0.017495665699243546
step: 340, loss: 0.03814680129289627
step: 350, loss: 0.000680741504766047
step: 360, loss: 0.031029243022203445
step: 370, loss: 0.08863741904497147
step: 380, loss: 0.056692324578762054
step: 390, loss: 0.08685401827096939
step: 400, loss: 0.12306657433509827
step: 410, loss: 0.014551335945725441
step: 420, loss: 0.05782452970743179
step: 430, loss: 0.0658031702041626
step: 440, loss: 0.04269738122820854
step: 450, loss: 0.19307518005371094
step: 460, loss: 0.0032506322022527456
step: 470, loss: 0.05371907353401184
step: 480, loss: 0.017580261453986168
step: 490, loss: 0.007837431505322456
step: 500, loss: 0.13922178745269775
step: 510, loss: 0.03962358087301254
step: 520, loss: 0.04010605812072754
step: 530, loss: 0.0007953447639010847
step: 540, loss: 0.008408887311816216
step: 550, loss: 0.06860709190368652
step: 560, loss: 0.018442539498209953
step: 570, loss: 0.07465427368879318
step: 580, loss: 0.008699891157448292
step: 590, loss: 0.011019008234143257
step: 600, loss: 0.060736872255802155
step: 610, loss: 0.04798201844096184
step: 620, loss: 0.009611749090254307
step: 630, loss: 0.007095306180417538
step: 640, loss: 0.005193451419472694
step: 650, loss: 0.1791345179080963
step: 660, loss: 0.0415983721613884
step: 670, loss: 0.12579436600208282
step: 680, loss: 0.06686542928218842
step: 690, loss: 0.10642116516828537
step: 700, loss: 0.04422150179743767
step: 710, loss: 0.10058858245611191
step: 720, loss: 0.044536467641592026
step: 730, loss: 0.010223175399005413
step: 740, loss: 0.008816130459308624
step: 750, loss: 0.06721179932355881
step: 760, loss: 0.032494548708200455
step: 770, loss: 0.0655657947063446
step: 780, loss: 0.025669243186712265
step: 790, loss: 0.024371309205889702
step: 800, loss: 0.020522378385066986
step: 810, loss: 0.016401221975684166
step: 820, loss: 0.005388173740357161
step: 830, loss: 0.054139528423547745
step: 840, loss: 0.06438732147216797
step: 850, loss: 0.05263866111636162
step: 860, loss: 0.05458291620016098
step: 870, loss: 0.1441136598587036
step: 880, loss: 0.010323387570679188
step: 890, loss: 0.015565093606710434
step: 900, loss: 0.011982554569840431
step: 910, loss: 0.09211739152669907
step: 920, loss: 0.0052101933397352695
step: 930, loss: 0.017960581928491592
step: 940, loss: 0.20870238542556763
step: 950, loss: 0.011879803612828255
step: 960, loss: 0.02893914096057415
step: 970, loss: 0.07994749397039413
step: 980, loss: 0.0025278038810938597
step: 990, loss: 0.03525283932685852
step: 1000, loss: 0.06228684261441231
step: 1010, loss: 0.1180487796664238
step: 1020, loss: 0.13144780695438385
step: 1030, loss: 0.004269903060048819
step: 1040, loss: 0.11484508961439133
step: 1050, loss: 0.013493971899151802
step: 1060, loss: 0.06273391097784042
step: 1070, loss: 0.029217885807156563
epoch 9: dev_f1=0.9333954354913834, f1=0.9291044776119404, best_f1=0.9340761374187557
step: 0, loss: 0.03362303599715233
step: 10, loss: 0.017583319917321205
step: 20, loss: 0.061614591628313065
step: 30, loss: 0.002217737026512623
step: 40, loss: 0.003895336529240012
step: 50, loss: 0.10886657238006592
step: 60, loss: 0.09308798611164093
step: 70, loss: 0.03067800961434841
step: 80, loss: 0.048727262765169144
step: 90, loss: 0.007400808855891228
step: 100, loss: 0.0813959538936615
step: 110, loss: 0.06858933717012405
step: 120, loss: 0.0130410585552454
step: 130, loss: 0.007120953872799873
step: 140, loss: 0.046769045293331146
step: 150, loss: 0.0002232011902378872
step: 160, loss: 0.015032737515866756
step: 170, loss: 0.04766668379306793
step: 180, loss: 0.011354799382388592
step: 190, loss: 0.06678726524114609
step: 200, loss: 0.14028400182724
step: 210, loss: 0.0352921336889267
step: 220, loss: 0.04337193816900253
step: 230, loss: 0.023746272549033165
step: 240, loss: 0.004498157650232315
step: 250, loss: 0.014925377443432808
step: 260, loss: 0.03469957783818245
step: 270, loss: 0.12564364075660706
step: 280, loss: 0.0956101045012474
step: 290, loss: 0.042024459689855576
step: 300, loss: 0.14345374703407288
step: 310, loss: 0.008050916716456413
step: 320, loss: 0.008996110409498215
step: 330, loss: 0.030353248119354248
step: 340, loss: 0.05392066016793251
step: 350, loss: 0.03998071327805519
step: 360, loss: 0.05688151344656944
step: 370, loss: 0.008576661348342896
step: 380, loss: 0.12953785061836243
step: 390, loss: 0.05262036249041557
step: 400, loss: 0.12082123756408691
step: 410, loss: 0.036748725920915604
step: 420, loss: 0.017004210501909256
step: 430, loss: 0.012726938351988792
step: 440, loss: 0.0210573747754097
step: 450, loss: 0.0021084873005747795
step: 460, loss: 0.019088787958025932
step: 470, loss: 0.07329193502664566
step: 480, loss: 0.021787986159324646
step: 490, loss: 0.020994883030653
step: 500, loss: 0.009827143512666225
step: 510, loss: 0.012188175693154335
step: 520, loss: 0.0330381840467453
step: 530, loss: 0.007286308333277702
step: 540, loss: 0.019161583855748177
step: 550, loss: 0.01747715100646019
step: 560, loss: 0.029028067365288734
step: 570, loss: 0.020810913294553757
step: 580, loss: 0.1360701024532318
step: 590, loss: 0.008879889734089375
step: 600, loss: 0.04270591959357262
step: 610, loss: 0.05385661870241165
step: 620, loss: 0.03798159584403038
step: 630, loss: 0.014671583659946918
step: 640, loss: 0.14371462166309357
step: 650, loss: 0.018598215654492378
step: 660, loss: 0.018801730126142502
step: 670, loss: 0.004449651576578617
step: 680, loss: 0.007113543804734945
step: 690, loss: 0.0006747320294380188
step: 700, loss: 0.10839223861694336
step: 710, loss: 0.06888624280691147
step: 720, loss: 0.03594548627734184
step: 730, loss: 0.022480109706521034
step: 740, loss: 0.013243320398032665
step: 750, loss: 0.017601322382688522
step: 760, loss: 0.16089123487472534
step: 770, loss: 0.017169836908578873
step: 780, loss: 0.003129956079646945
step: 790, loss: 0.047671012580394745
step: 800, loss: 0.015903202816843987
step: 810, loss: 0.1012914627790451
step: 820, loss: 0.04206232354044914
step: 830, loss: 0.010762753896415234
step: 840, loss: 0.12205807864665985
step: 850, loss: 0.04022660478949547
step: 860, loss: 0.04543376341462135
step: 870, loss: 0.062150925397872925
step: 880, loss: 0.028489025309681892
step: 890, loss: 0.06589251011610031
step: 900, loss: 0.13195055723190308
step: 910, loss: 0.022758303210139275
step: 920, loss: 0.050580888986587524
step: 930, loss: 0.07191219180822372
step: 940, loss: 0.02207896113395691
step: 950, loss: 0.047084741294384
step: 960, loss: 0.017216920852661133
step: 970, loss: 0.01940537430346012
step: 980, loss: 0.0153466472402215
step: 990, loss: 0.015938488766551018
step: 1000, loss: 0.0027382776606827974
step: 1010, loss: 0.013159498572349548
step: 1020, loss: 0.04800739139318466
step: 1030, loss: 0.06932426989078522
step: 1040, loss: 0.03835747018456459
step: 1050, loss: 0.16175396740436554
step: 1060, loss: 0.13826559484004974
step: 1070, loss: 0.008127330802381039
epoch 10: dev_f1=0.9304063521718824, f1=0.9289055191768008, best_f1=0.9340761374187557
step: 0, loss: 0.09615571796894073
step: 10, loss: 0.0028482056222856045
step: 20, loss: 0.0068641528487205505
step: 30, loss: 0.006057785823941231
step: 40, loss: 0.041667692363262177
step: 50, loss: 0.025643952190876007
step: 60, loss: 0.06952782720327377
step: 70, loss: 0.0030296696349978447
step: 80, loss: 0.02745440974831581
step: 90, loss: 0.011823834851384163
step: 100, loss: 0.0009252720046788454
step: 110, loss: 0.054406628012657166
step: 120, loss: 0.0004058776830788702
step: 130, loss: 0.01666598953306675
step: 140, loss: 0.011804376728832722
step: 150, loss: 0.08497727662324905
step: 160, loss: 0.024260753765702248
step: 170, loss: 0.04696051776409149
step: 180, loss: 0.0650472566485405
step: 190, loss: 0.056298043578863144
step: 200, loss: 0.11610803753137589
step: 210, loss: 0.04083238169550896
step: 220, loss: 0.04607977718114853
step: 230, loss: 0.03800991550087929
step: 240, loss: 0.13864468038082123
step: 250, loss: 0.00017869952716864645
step: 260, loss: 0.18066361546516418
step: 270, loss: 0.012608639895915985
step: 280, loss: 0.05447003245353699
step: 290, loss: 0.012821818701922894
step: 300, loss: 0.07051194459199905
step: 310, loss: 0.02670496515929699
step: 320, loss: 0.0290227010846138
step: 330, loss: 0.035078201442956924
step: 340, loss: 0.017948182299733162
step: 350, loss: 0.0216293353587389
step: 360, loss: 0.05867790803313255
step: 370, loss: 0.012166175059974194
step: 380, loss: 0.010509875603020191
step: 390, loss: 0.03409584239125252
step: 400, loss: 0.016851674765348434
step: 410, loss: 0.020463746041059494
step: 420, loss: 0.051427409052848816
step: 430, loss: 0.002273001242429018
step: 440, loss: 0.0059389593079686165
step: 450, loss: 0.06356868147850037
step: 460, loss: 0.017806077376008034
step: 470, loss: 0.011386191472411156
step: 480, loss: 0.012629224918782711
step: 490, loss: 0.06274231523275375
step: 500, loss: 0.031512752175331116
step: 510, loss: 0.05633140727877617
step: 520, loss: 0.0035719829611480236
step: 530, loss: 0.0035609386395663023
step: 540, loss: 0.09970656037330627
step: 550, loss: 0.023685434833168983
step: 560, loss: 0.008535035885870457
step: 570, loss: 0.028406452387571335
step: 580, loss: 0.07923772186040878
step: 590, loss: 0.0004413128481246531
step: 600, loss: 0.15695689618587494
step: 610, loss: 0.06282070279121399
step: 620, loss: 0.07247702032327652
step: 630, loss: 0.05686919018626213
step: 640, loss: 0.003024606965482235
step: 650, loss: 0.03335339576005936
step: 660, loss: 0.14034348726272583
step: 670, loss: 0.05703531578183174
step: 680, loss: 0.1018606498837471
step: 690, loss: 0.05617481842637062
step: 700, loss: 0.022047605365514755
step: 710, loss: 0.0026797764003276825
step: 720, loss: 0.006797031033784151
step: 730, loss: 0.0007587362779304385
step: 740, loss: 0.00589638901874423
step: 750, loss: 0.03470524400472641
step: 760, loss: 0.21805541217327118
step: 770, loss: 0.0009043127647601068
step: 780, loss: 0.07191290706396103
step: 790, loss: 0.03712795302271843
step: 800, loss: 0.07020437717437744
step: 810, loss: 0.25471383333206177
step: 820, loss: 0.07209465652704239
step: 830, loss: 0.05560314655303955
step: 840, loss: 0.00535984430462122
step: 850, loss: 0.0027635947335511446
step: 860, loss: 0.05728970840573311
step: 870, loss: 0.0974888801574707
step: 880, loss: 0.046448174864053726
step: 890, loss: 0.05336583033204079
step: 900, loss: 0.017860060557723045
step: 910, loss: 0.006640808191150427
step: 920, loss: 0.05154486745595932
step: 930, loss: 0.015089116990566254
step: 940, loss: 0.02611926756799221
step: 950, loss: 0.006333394441753626
step: 960, loss: 0.042692817747592926
step: 970, loss: 0.011068320833146572
step: 980, loss: 0.03605815768241882
step: 990, loss: 0.06270278245210648
step: 1000, loss: 0.05800770968198776
step: 1010, loss: 0.07076232880353928
step: 1020, loss: 0.06387683004140854
step: 1030, loss: 0.005011031404137611
step: 1040, loss: 0.06633014976978302
step: 1050, loss: 0.013643107376992702
step: 1060, loss: 0.10690716654062271
step: 1070, loss: 0.03411354497075081
epoch 11: dev_f1=0.9348025711662074, f1=0.9302752293577982, best_f1=0.9340761374187557
step: 0, loss: 0.03750067949295044
step: 10, loss: 0.002429200801998377
step: 20, loss: 0.0627511739730835
step: 30, loss: 0.018549473956227303
step: 40, loss: 0.005539709236472845
step: 50, loss: 0.09649891406297684
step: 60, loss: 0.0019529347773641348
step: 70, loss: 0.042177993804216385
step: 80, loss: 0.08728915452957153
step: 90, loss: 0.027193399146199226
step: 100, loss: 0.04547008499503136
step: 110, loss: 0.0001795502903405577
step: 120, loss: 0.04025248810648918
step: 130, loss: 0.0474308505654335
step: 140, loss: 0.02275227941572666
step: 150, loss: 0.002590673742815852
step: 160, loss: 0.14898213744163513
step: 170, loss: 0.028435006737709045
step: 180, loss: 0.003031036350876093
step: 190, loss: 0.031183447688817978
step: 200, loss: 0.06912798434495926
step: 210, loss: 0.06896553933620453
step: 220, loss: 0.005547253414988518
step: 230, loss: 0.10387503355741501
step: 240, loss: 0.05199752002954483
step: 250, loss: 0.03510378673672676
step: 260, loss: 0.0032638898119330406
step: 270, loss: 0.1155213862657547
step: 280, loss: 0.0019962822552770376
step: 290, loss: 0.04077249765396118
step: 300, loss: 0.0416734553873539
step: 310, loss: 0.01030406728386879
step: 320, loss: 0.014031367376446724
step: 330, loss: 0.021541330963373184
step: 340, loss: 0.02751135267317295
step: 350, loss: 0.017497356981039047
step: 360, loss: 0.011941961944103241
step: 370, loss: 0.01207699254155159
step: 380, loss: 0.00015261360385920852
step: 390, loss: 0.006547234486788511
step: 400, loss: 0.03290707245469093
step: 410, loss: 0.04326241835951805
step: 420, loss: 0.06494037806987762
step: 430, loss: 0.06878691911697388
step: 440, loss: 0.07554838061332703
step: 450, loss: 0.006535628344863653
step: 460, loss: 0.002158518647775054
step: 470, loss: 0.055682044476270676
step: 480, loss: 0.06485933065414429
step: 490, loss: 0.06049278378486633
step: 500, loss: 0.1087121069431305
step: 510, loss: 0.06963980197906494
step: 520, loss: 0.0002968041808344424
step: 530, loss: 0.00011117531539639458
step: 540, loss: 0.010336773470044136
step: 550, loss: 0.03992028161883354
step: 560, loss: 0.016231993213295937
step: 570, loss: 0.018698429688811302
step: 580, loss: 0.021987775340676308
step: 590, loss: 0.005912161432206631
step: 600, loss: 0.03960247337818146
step: 610, loss: 0.0003379473346285522
step: 620, loss: 0.03434783220291138
step: 630, loss: 0.012529879808425903
step: 640, loss: 0.027609899640083313
step: 650, loss: 0.20125605165958405
step: 660, loss: 0.07846929132938385
step: 670, loss: 8.923416316974908e-05
step: 680, loss: 0.008702857419848442
step: 690, loss: 0.017220383509993553
step: 700, loss: 0.025698881596326828
step: 710, loss: 0.022669490426778793
step: 720, loss: 0.05817306041717529
step: 730, loss: 0.09652853012084961
step: 740, loss: 0.006324938032776117
step: 750, loss: 0.048174671828746796
step: 760, loss: 0.0056385924108326435
step: 770, loss: 0.022992433980107307
step: 780, loss: 0.03724486380815506
step: 790, loss: 0.0017743437783792615
step: 800, loss: 0.03302282467484474
step: 810, loss: 0.030098088085651398
step: 820, loss: 0.04869318753480911
step: 830, loss: 0.027169086039066315
step: 840, loss: 0.05334637314081192
step: 850, loss: 0.015772411599755287
step: 860, loss: 0.07760726660490036
step: 870, loss: 0.056323714554309845
step: 880, loss: 0.0213677529245615
step: 890, loss: 0.032026052474975586
step: 900, loss: 0.07322437316179276
step: 910, loss: 0.03455566242337227
step: 920, loss: 0.027026690542697906
step: 930, loss: 0.018590644001960754
step: 940, loss: 0.020750682801008224
step: 950, loss: 0.030034128576517105
step: 960, loss: 0.04249727725982666
step: 970, loss: 0.0027659705374389887
step: 980, loss: 0.03921493887901306
step: 990, loss: 0.00019541870278771967
step: 1000, loss: 0.13605496287345886
step: 1010, loss: 0.09578506648540497
step: 1020, loss: 0.03842220827937126
step: 1030, loss: 0.04769410565495491
step: 1040, loss: 0.028715118765830994
step: 1050, loss: 0.18547353148460388
step: 1060, loss: 0.024952862411737442
step: 1070, loss: 0.06162969768047333
epoch 12: dev_f1=0.9284403669724771, f1=0.9295255642561031, best_f1=0.9340761374187557
step: 0, loss: 0.047767914831638336
step: 10, loss: 0.030998462811112404
step: 20, loss: 0.05971449986100197
step: 30, loss: 0.002110254019498825
step: 40, loss: 0.030335772782564163
step: 50, loss: 0.0027526153717190027
step: 60, loss: 0.00231049838475883
step: 70, loss: 0.022077230736613274
step: 80, loss: 0.09499895572662354
step: 90, loss: 4.4140982936369255e-05
step: 100, loss: 0.03637504205107689
step: 110, loss: 0.08825565874576569
step: 120, loss: 0.004970608279109001
step: 130, loss: 0.0198755394667387
step: 140, loss: 0.05924300104379654
step: 150, loss: 0.0041800010949373245
step: 160, loss: 0.05794501677155495
step: 170, loss: 0.022830821573734283
step: 180, loss: 0.0017127562314271927
step: 190, loss: 0.05600496008992195
step: 200, loss: 0.00025939266197383404
step: 210, loss: 0.00042824706179089844
step: 220, loss: 0.020682690665125847
step: 230, loss: 0.003113898914307356
step: 240, loss: 0.03746255859732628
step: 250, loss: 0.04512818157672882
step: 260, loss: 0.08596498519182205
step: 270, loss: 0.1078416034579277
step: 280, loss: 0.07741605490446091
step: 290, loss: 2.743741606536787e-05
step: 300, loss: 0.00976471696048975
step: 310, loss: 0.047083184123039246
step: 320, loss: 0.00043264206033200026
step: 330, loss: 0.023906895890831947
step: 340, loss: 0.07381193339824677
step: 350, loss: 0.13861343264579773
step: 360, loss: 0.05699358880519867
step: 370, loss: 0.01330295205116272
step: 380, loss: 0.07921076565980911
step: 390, loss: 0.03216332197189331
step: 400, loss: 0.01756436750292778
step: 410, loss: 0.04028850421309471
step: 420, loss: 0.0009331876062788069
step: 430, loss: 0.0014677291037514806
step: 440, loss: 0.013808179646730423
step: 450, loss: 0.000718740455340594
step: 460, loss: 0.031886711716651917
step: 470, loss: 0.0293542742729187
step: 480, loss: 0.019513366743922234
step: 490, loss: 0.029879577457904816
step: 500, loss: 0.06988044828176498
step: 510, loss: 0.026546670123934746
step: 520, loss: 0.042413290590047836
step: 530, loss: 0.02151903323829174
step: 540, loss: 0.008850440382957458
step: 550, loss: 0.03626222163438797
step: 560, loss: 0.03071078471839428
step: 570, loss: 0.11252767592668533
step: 580, loss: 0.02908957190811634
step: 590, loss: 0.036053482443094254
step: 600, loss: 0.06001295894384384
step: 610, loss: 0.014009729959070683
step: 620, loss: 0.0018367341253906488
step: 630, loss: 0.0031956529710441828
step: 640, loss: 0.0008670235401950777
step: 650, loss: 0.0290488563477993
step: 660, loss: 0.041851479560136795
step: 670, loss: 0.06755996495485306
step: 680, loss: 0.01961272396147251
step: 690, loss: 0.00015683186938986182
step: 700, loss: 0.004316726699471474
step: 710, loss: 0.01795528270304203
step: 720, loss: 0.07324644923210144
step: 730, loss: 0.015889016911387444
step: 740, loss: 0.07469470798969269
step: 750, loss: 0.00577164301648736
step: 760, loss: 0.00813751108944416
step: 770, loss: 0.0015709336148574948
step: 780, loss: 0.026657555252313614
step: 790, loss: 0.008486496284604073
step: 800, loss: 0.019453493878245354
step: 810, loss: 0.03903615474700928
step: 820, loss: 0.10977818071842194
step: 830, loss: 0.047471243888139725
step: 840, loss: 0.049511153250932693
step: 850, loss: 0.0023084497079253197
step: 860, loss: 0.02807481773197651
step: 870, loss: 0.056036219000816345
step: 880, loss: 0.021688703447580338
step: 890, loss: 0.009903083555400372
step: 900, loss: 0.013293536379933357
step: 910, loss: 0.016654325649142265
step: 920, loss: 0.014521569944918156
step: 930, loss: 0.03875534236431122
step: 940, loss: 0.04217659309506416
step: 950, loss: 4.0075428842101246e-05
step: 960, loss: 0.023721711710095406
step: 970, loss: 0.02414858527481556
step: 980, loss: 0.030800148844718933
step: 990, loss: 0.03001101315021515
step: 1000, loss: 0.0017022574320435524
step: 1010, loss: 0.0004901908687315881
step: 1020, loss: 0.038114458322525024
step: 1030, loss: 0.057088568806648254
step: 1040, loss: 0.06521323323249817
step: 1050, loss: 0.0010272355284541845
step: 1060, loss: 0.018803633749485016
step: 1070, loss: 0.042415913194417953
epoch 13: dev_f1=0.9326568265682658, f1=0.9225776541492814, best_f1=0.9340761374187557
step: 0, loss: 0.005933947395533323
step: 10, loss: 0.0012873500818386674
step: 20, loss: 0.00088927720207721
step: 30, loss: 5.074021828477271e-05
step: 40, loss: 0.011869617737829685
step: 50, loss: 0.0001224641891894862
step: 60, loss: 0.050241075456142426
step: 70, loss: 0.028194529935717583
step: 80, loss: 0.01593865640461445
step: 90, loss: 0.056230079382658005
step: 100, loss: 0.0018060478614643216
step: 110, loss: 0.026964247226715088
step: 120, loss: 0.0012701102532446384
step: 130, loss: 0.10442958772182465
step: 140, loss: 0.029405999928712845
step: 150, loss: 1.5228833035507705e-05
step: 160, loss: 0.05534179136157036
step: 170, loss: 2.5766195903997868e-05
step: 180, loss: 0.020077908411622047
step: 190, loss: 0.0755903422832489
step: 200, loss: 0.08125749230384827
step: 210, loss: 0.025433124974370003
step: 220, loss: 0.061277277767658234
step: 230, loss: 0.06659705191850662
step: 240, loss: 0.022199219092726707
step: 250, loss: 0.08092547953128815
step: 260, loss: 0.00040788977639749646
step: 270, loss: 0.018012486398220062
step: 280, loss: 0.05295005813241005
step: 290, loss: 0.017443586140871048
step: 300, loss: 0.056781549006700516
step: 310, loss: 0.00018701104272622615
step: 320, loss: 7.633624773006886e-05
step: 330, loss: 0.018488753587007523
step: 340, loss: 0.037799056619405746
step: 350, loss: 0.014606735669076443
step: 360, loss: 0.06263343244791031
step: 370, loss: 0.06897248327732086
step: 380, loss: 0.01868223026394844
step: 390, loss: 0.0015199673362076283
step: 400, loss: 0.02751084230840206
step: 410, loss: 0.0033472366631031036
step: 420, loss: 0.01634884811937809
step: 430, loss: 0.04698409140110016
step: 440, loss: 0.0003198188205715269
step: 450, loss: 0.019889377057552338
step: 460, loss: 0.05684255436062813
step: 470, loss: 0.004922586027532816
step: 480, loss: 0.002760570961982012
step: 490, loss: 0.035660166293382645
step: 500, loss: 0.13747528195381165
step: 510, loss: 0.017734142020344734
step: 520, loss: 0.06828097999095917
step: 530, loss: 0.024170204997062683
step: 540, loss: 0.052953872829675674
step: 550, loss: 0.009455953724682331
step: 560, loss: 0.0004886568058282137
step: 570, loss: 0.03488035500049591
step: 580, loss: 0.04815920069813728
step: 590, loss: 0.0649954080581665
step: 600, loss: 0.04835063964128494
step: 610, loss: 0.02123272977769375
step: 620, loss: 0.0250905342400074
step: 630, loss: 0.015564548783004284
step: 640, loss: 0.11603778600692749
step: 650, loss: 0.06494024395942688
step: 660, loss: 0.08985935151576996
step: 670, loss: 4.3230804294580594e-05
step: 680, loss: 0.0054858229123055935
step: 690, loss: 0.05046144127845764
step: 700, loss: 0.03784269466996193
step: 710, loss: 0.020028311759233475
step: 720, loss: 0.04225769639015198
step: 730, loss: 0.029352925717830658
step: 740, loss: 0.02163253352046013
step: 750, loss: 0.02479988895356655
step: 760, loss: 0.01959424652159214
step: 770, loss: 0.03489087149500847
step: 780, loss: 0.0016658687964081764
step: 790, loss: 0.01968679018318653
step: 800, loss: 0.037981901317834854
step: 810, loss: 0.054212816059589386
step: 820, loss: 0.07858537882566452
step: 830, loss: 0.00832238420844078
step: 840, loss: 0.025050705298781395
step: 850, loss: 2.09504651138559e-05
step: 860, loss: 0.0015107269864529371
step: 870, loss: 0.026935959234833717
step: 880, loss: 0.029190663248300552
step: 890, loss: 0.04234075918793678
step: 900, loss: 0.04681282863020897
step: 910, loss: 2.2082649593357928e-05
step: 920, loss: 0.034480560570955276
step: 930, loss: 0.004657167010009289
step: 940, loss: 0.08031828701496124
step: 950, loss: 0.04852203652262688
step: 960, loss: 0.032934993505477905
step: 970, loss: 0.0004602657863870263
step: 980, loss: 0.04503106698393822
step: 990, loss: 0.0131986690685153
step: 1000, loss: 0.014104495756328106
step: 1010, loss: 0.026121150702238083
step: 1020, loss: 0.02443348616361618
step: 1030, loss: 0.007798794656991959
step: 1040, loss: 0.018727852031588554
step: 1050, loss: 0.01904226467013359
step: 1060, loss: 0.0382973775267601
step: 1070, loss: 0.030472494661808014
epoch 14: dev_f1=0.9339491916859123, f1=0.9245020842982862, best_f1=0.9340761374187557
step: 0, loss: 0.0238118264824152
step: 10, loss: 0.01674783229827881
step: 20, loss: 0.007050918880850077
step: 30, loss: 0.05045970529317856
step: 40, loss: 0.02568991854786873
step: 50, loss: 0.06548962742090225
step: 60, loss: 0.004664172418415546
step: 70, loss: 0.032158300280570984
step: 80, loss: 0.011420076712965965
step: 90, loss: 0.016116807237267494
step: 100, loss: 0.02313600294291973
step: 110, loss: 0.004044403787702322
step: 120, loss: 0.00029145143344067037
step: 130, loss: 0.010311045683920383
step: 140, loss: 0.041838496923446655
step: 150, loss: 0.0320289172232151
step: 160, loss: 0.00020643768948502839
step: 170, loss: 0.021031128242611885
step: 180, loss: 0.025738608092069626
step: 190, loss: 0.08197401463985443
step: 200, loss: 0.03768698871135712
step: 210, loss: 0.04781552776694298
step: 220, loss: 0.01093467976897955
step: 230, loss: 0.038419704884290695
step: 240, loss: 2.4678793124621734e-05
step: 250, loss: 0.06912340223789215
step: 260, loss: 0.02228635922074318
step: 270, loss: 0.022023875266313553
step: 280, loss: 0.02775679901242256
step: 290, loss: 0.0006761770928278565
step: 300, loss: 0.0332481786608696
step: 310, loss: 0.06306378543376923
step: 320, loss: 0.08990828692913055
step: 330, loss: 0.039513107389211655
step: 340, loss: 0.006875815335661173
step: 350, loss: 0.024382183328270912
step: 360, loss: 0.02740761637687683
step: 370, loss: 5.3847285016672686e-05
step: 380, loss: 0.03165140375494957
step: 390, loss: 0.046518441289663315
step: 400, loss: 0.000668652297463268
step: 410, loss: 0.06433866918087006
step: 420, loss: 0.0003606912214308977
step: 430, loss: 0.0806109607219696
step: 440, loss: 0.001559344120323658
step: 450, loss: 0.048848167061805725
step: 460, loss: 0.008712316863238811
step: 470, loss: 0.02112877182662487
step: 480, loss: 0.050358861684799194
step: 490, loss: 0.0015279831131920218
step: 500, loss: 0.05363757535815239
step: 510, loss: 0.0067633031867444515
step: 520, loss: 0.06596570461988449
step: 530, loss: 0.0625547468662262
step: 540, loss: 0.023179911077022552
step: 550, loss: 0.020335925742983818
step: 560, loss: 0.09832727909088135
step: 570, loss: 0.001759891165420413
step: 580, loss: 0.0104744927957654
step: 590, loss: 6.164277874631807e-05
step: 600, loss: 0.007536076940596104
step: 610, loss: 0.07808885723352432
step: 620, loss: 0.011040575802326202
step: 630, loss: 0.04144882410764694
step: 640, loss: 0.028798239305615425
step: 650, loss: 0.018681788817048073
step: 660, loss: 0.08971163630485535
step: 670, loss: 0.03849698603153229
step: 680, loss: 0.020225202664732933
step: 690, loss: 0.07722797989845276
step: 700, loss: 0.023502018302679062
step: 710, loss: 7.376090798061341e-05
step: 720, loss: 0.3383637070655823
step: 730, loss: 0.005535160657018423
step: 740, loss: 0.02074677310883999
step: 750, loss: 0.04648284986615181
step: 760, loss: 0.009388894774019718
step: 770, loss: 6.326701259240508e-05
step: 780, loss: 0.0929916650056839
step: 790, loss: 9.193879668600857e-05
step: 800, loss: 0.014555428177118301
step: 810, loss: 0.14812692999839783
step: 820, loss: 0.006130670662969351
step: 830, loss: 0.0381213016808033
step: 840, loss: 0.047571778297424316
step: 850, loss: 0.04878440871834755
step: 860, loss: 0.0001149817617260851
step: 870, loss: 0.0006880573346279562
step: 880, loss: 0.01845371723175049
step: 890, loss: 0.04302464798092842
step: 900, loss: 0.08638393878936768
step: 910, loss: 0.05764776095747948
step: 920, loss: 0.029277140274643898
step: 930, loss: 0.0017349565168842673
step: 940, loss: 0.0005273486603982747
step: 950, loss: 0.0012723812833428383
step: 960, loss: 0.019888654351234436
step: 970, loss: 0.01271251030266285
step: 980, loss: 0.05889023095369339
step: 990, loss: 0.09197011590003967
step: 1000, loss: 0.021644793450832367
step: 1010, loss: 0.05197827145457268
step: 1020, loss: 0.003833585884422064
step: 1030, loss: 0.0446087010204792
step: 1040, loss: 0.030645515769720078
step: 1050, loss: 0.015226621180772781
step: 1060, loss: 0.0012530165258795023
step: 1070, loss: 0.11384887993335724
epoch 15: dev_f1=0.9258215962441314, f1=0.923221855864343, best_f1=0.9340761374187557
step: 0, loss: 0.023034190759062767
step: 10, loss: 0.021141260862350464
step: 20, loss: 0.0010022659553214908
step: 30, loss: 0.005528478883206844
step: 40, loss: 0.04383097216486931
step: 50, loss: 0.03621906042098999
step: 60, loss: 0.009388350881636143
step: 70, loss: 0.00037112427526153624
step: 80, loss: 0.02465912140905857
step: 90, loss: 0.020791154354810715
step: 100, loss: 0.007450869772583246
step: 110, loss: 0.05792318284511566
step: 120, loss: 1.7545897208037786e-05
step: 130, loss: 0.11628654599189758
step: 140, loss: 0.0032709715887904167
step: 150, loss: 0.03292573615908623
step: 160, loss: 0.02371908538043499
step: 170, loss: 0.05349356681108475
step: 180, loss: 0.01740800216794014
step: 190, loss: 0.003199979430064559
step: 200, loss: 0.0042456965893507
step: 210, loss: 0.02080445922911167
step: 220, loss: 0.002651564311236143
step: 230, loss: 0.19224749505519867
step: 240, loss: 0.0017953546484932303
step: 250, loss: 2.748036422417499e-05
step: 260, loss: 0.009675875306129456
step: 270, loss: 0.016938574612140656
step: 280, loss: 0.0010056841420009732
step: 290, loss: 0.05702876299619675
step: 300, loss: 0.00010901662608375773
step: 310, loss: 0.07401661574840546
step: 320, loss: 0.002990090288221836
step: 330, loss: 0.020409174263477325
step: 340, loss: 0.039149362593889236
step: 350, loss: 0.03232452645897865
step: 360, loss: 7.373899279627949e-05
step: 370, loss: 0.00862849410623312
step: 380, loss: 0.04372080788016319
step: 390, loss: 0.05528080835938454
step: 400, loss: 0.044171325862407684
step: 410, loss: 2.0115890947636217e-05
step: 420, loss: 1.7940685211215168e-05
step: 430, loss: 0.030350307002663612
step: 440, loss: 7.046184327919036e-05
step: 450, loss: 0.027168655768036842
step: 460, loss: 0.02551880292594433
step: 470, loss: 0.05073319748044014
step: 480, loss: 0.0002699559845495969
step: 490, loss: 0.003276023082435131
step: 500, loss: 0.06969767063856125
step: 510, loss: 0.024361584335565567
step: 520, loss: 0.04741480574011803
step: 530, loss: 0.008642512373626232
step: 540, loss: 0.028243163600564003
step: 550, loss: 0.09195592999458313
step: 560, loss: 3.555745934136212e-05
step: 570, loss: 0.006049679592251778
step: 580, loss: 8.368978888029233e-05
step: 590, loss: 0.02571861259639263
step: 600, loss: 0.05754224210977554
step: 610, loss: 0.02517600916326046
step: 620, loss: 0.068296879529953
step: 630, loss: 0.0014232936082407832
step: 640, loss: 0.018638910725712776
step: 650, loss: 0.0002637711295392364
step: 660, loss: 0.012844794429838657
step: 670, loss: 0.026575475931167603
step: 680, loss: 4.921624713460915e-05
step: 690, loss: 0.04910733923316002
step: 700, loss: 0.0075941248796880245
step: 710, loss: 0.000858532264828682
step: 720, loss: 0.011808652430772781
step: 730, loss: 0.022558022290468216
step: 740, loss: 0.021492915228009224
step: 750, loss: 0.007104664575308561
step: 760, loss: 0.0008141770376823843
step: 770, loss: 0.01895071007311344
step: 780, loss: 0.01945951022207737
step: 790, loss: 0.039744410663843155
step: 800, loss: 0.00038122371188364923
step: 810, loss: 2.1770123566966504e-05
step: 820, loss: 0.07308303564786911
step: 830, loss: 0.03425150364637375
step: 840, loss: 0.007981296628713608
step: 850, loss: 0.01732412539422512
step: 860, loss: 0.08429225534200668
step: 870, loss: 0.040073104202747345
step: 880, loss: 0.021628525108098984
step: 890, loss: 0.010739121586084366
step: 900, loss: 0.010835929773747921
step: 910, loss: 0.025685302913188934
step: 920, loss: 0.0007125979755073786
step: 930, loss: 5.15889551024884e-05
step: 940, loss: 0.03149019181728363
step: 950, loss: 0.02959836646914482
step: 960, loss: 0.010716180317103863
step: 970, loss: 0.03131580352783203
step: 980, loss: 0.02610529586672783
step: 990, loss: 0.0991000384092331
step: 1000, loss: 0.04245821386575699
step: 1010, loss: 0.05065705254673958
step: 1020, loss: 0.049891434609889984
step: 1030, loss: 0.03133794292807579
step: 1040, loss: 0.023900233209133148
step: 1050, loss: 0.025395536795258522
step: 1060, loss: 0.027096737176179886
step: 1070, loss: 0.0017168022459372878
epoch 16: dev_f1=0.9332105020727776, f1=0.925497454881999, best_f1=0.9340761374187557
step: 0, loss: 0.04969321936368942
step: 10, loss: 0.0012800543336197734
step: 20, loss: 1.3548759852710646e-05
step: 30, loss: 0.029973812401294708
step: 40, loss: 0.024854108691215515
step: 50, loss: 0.025182733312249184
step: 60, loss: 0.03504465892910957
step: 70, loss: 0.023082854226231575
step: 80, loss: 0.00032673677196726203
step: 90, loss: 0.03748081251978874
step: 100, loss: 2.5270917831221595e-05
step: 110, loss: 0.001625041477382183
step: 120, loss: 0.015178457833826542
step: 130, loss: 0.016747143119573593
step: 140, loss: 0.00022145883121993393
step: 150, loss: 3.810829730355181e-05
step: 160, loss: 0.01910620927810669
step: 170, loss: 0.045433640480041504
step: 180, loss: 0.02346411906182766
step: 190, loss: 0.033751457929611206
step: 200, loss: 0.0017499615205451846
step: 210, loss: 0.022466816008090973
step: 220, loss: 0.009951413609087467
step: 230, loss: 0.000161151954671368
step: 240, loss: 0.02083897963166237
step: 250, loss: 0.050303973257541656
step: 260, loss: 1.7329726688330993e-05
step: 270, loss: 0.0003169580886606127
step: 280, loss: 0.03248516842722893
step: 290, loss: 0.030226051807403564
step: 300, loss: 0.02754547819495201
step: 310, loss: 0.020893562585115433
step: 320, loss: 0.028829552233219147
step: 330, loss: 0.011369573883712292
step: 340, loss: 6.265547563089058e-05
step: 350, loss: 0.028534432873129845
step: 360, loss: 0.042730893939733505
step: 370, loss: 0.0007037750328890979
step: 380, loss: 0.07642295956611633
step: 390, loss: 0.0004523226816672832
step: 400, loss: 0.027732044458389282
step: 410, loss: 0.022413307800889015
step: 420, loss: 0.06103375181555748
step: 430, loss: 0.018526190891861916
step: 440, loss: 0.015543056651949883
step: 450, loss: 0.0399443618953228
step: 460, loss: 0.00259591406211257
step: 470, loss: 0.06051435321569443
step: 480, loss: 0.03637734055519104
step: 490, loss: 0.03743506968021393
step: 500, loss: 0.01621113531291485
step: 510, loss: 0.01871485635638237
step: 520, loss: 0.06697772443294525
step: 530, loss: 2.56992152571911e-05
step: 540, loss: 0.03165634348988533
step: 550, loss: 0.035138484090566635
step: 560, loss: 0.02100175805389881
step: 570, loss: 0.00013907918764743954
step: 580, loss: 0.059379711747169495
step: 590, loss: 0.02951045334339142
step: 600, loss: 0.00299584842287004
step: 610, loss: 3.757023296202533e-05
step: 620, loss: 6.609618867514655e-05
step: 630, loss: 0.00013783271424472332
step: 640, loss: 0.17440667748451233
step: 650, loss: 0.004772369749844074
step: 660, loss: 0.002589293522760272
step: 670, loss: 7.878805627115071e-05
step: 680, loss: 0.06230683624744415
step: 690, loss: 0.033611197024583817
step: 700, loss: 0.058889854699373245
step: 710, loss: 0.02036709524691105
step: 720, loss: 0.0744004100561142
step: 730, loss: 0.060447290539741516
step: 740, loss: 0.00023970087931957096
step: 750, loss: 0.0027805352583527565
step: 760, loss: 0.037013325840234756
step: 770, loss: 0.024767648428678513
step: 780, loss: 0.031120043247938156
step: 790, loss: 0.04252235218882561
step: 800, loss: 0.002838919637724757
step: 810, loss: 0.0021847581956535578
step: 820, loss: 0.03560711443424225
step: 830, loss: 0.050646569579839706
step: 840, loss: 0.001749472925439477
step: 850, loss: 0.024232706055045128
step: 860, loss: 1.5098311450856272e-05
step: 870, loss: 0.00023147297906689346
step: 880, loss: 0.00013146104174666107
step: 890, loss: 0.022015627473592758
step: 900, loss: 0.00041885863174684346
step: 910, loss: 0.017010493203997612
step: 920, loss: 9.075330308405682e-05
step: 930, loss: 0.022090893238782883
step: 940, loss: 0.03738364577293396
step: 950, loss: 0.02991403266787529
step: 960, loss: 5.222817344474606e-05
step: 970, loss: 0.03941302001476288
step: 980, loss: 0.02225368656218052
step: 990, loss: 0.08550342172384262
step: 1000, loss: 0.001017543370835483
step: 1010, loss: 6.358521204674616e-05
step: 1020, loss: 0.07017187029123306
step: 1030, loss: 0.06070820987224579
step: 1040, loss: 0.015015173703432083
step: 1050, loss: 0.013543477281928062
step: 1060, loss: 0.011487799696624279
step: 1070, loss: 0.02858920767903328
epoch 17: dev_f1=0.9310344827586207, f1=0.9266697804764129, best_f1=0.9340761374187557
step: 0, loss: 0.028627855703234673
step: 10, loss: 0.0003109340905211866
step: 20, loss: 0.0671376883983612
step: 30, loss: 0.06984268873929977
step: 40, loss: 0.08730868250131607
step: 50, loss: 0.06492608040571213
step: 60, loss: 0.00757307605817914
step: 70, loss: 0.06372010707855225
step: 80, loss: 0.011229103431105614
step: 90, loss: 3.065526834689081e-05
step: 100, loss: 0.04255088418722153
step: 110, loss: 0.024124057963490486
step: 120, loss: 0.026314405724406242
step: 130, loss: 0.034480128437280655
step: 140, loss: 0.0195225328207016
step: 150, loss: 0.030663518235087395
step: 160, loss: 0.16220706701278687
step: 170, loss: 3.2420306524727494e-05
step: 180, loss: 0.028869222849607468
step: 190, loss: 0.00046421060687862337
step: 200, loss: 0.021884430199861526
step: 210, loss: 0.023725496605038643
step: 220, loss: 2.1098625438753515e-05
step: 230, loss: 0.033811721950769424
step: 240, loss: 0.04735754802823067
step: 250, loss: 1.959835753950756e-05
step: 260, loss: 0.034551117569208145
step: 270, loss: 0.028607450425624847
step: 280, loss: 0.09931811690330505
step: 290, loss: 0.04037807881832123
step: 300, loss: 0.017473699524998665
step: 310, loss: 0.02551628090441227
step: 320, loss: 0.015330242924392223
step: 330, loss: 0.01690586470067501
step: 340, loss: 3.796442979364656e-05
step: 350, loss: 0.024711336940526962
step: 360, loss: 0.012996519915759563
step: 370, loss: 0.04279076308012009
step: 380, loss: 0.042754776775836945
step: 390, loss: 0.05603251978754997
step: 400, loss: 0.0497283861041069
step: 410, loss: 0.014470449648797512
step: 420, loss: 0.020868264138698578
step: 430, loss: 0.00025669854949228466
step: 440, loss: 0.016111191362142563
step: 450, loss: 7.368249498540536e-05
step: 460, loss: 0.00014020793605595827
step: 470, loss: 0.016469350084662437
step: 480, loss: 0.033091720193624496
step: 490, loss: 0.05093654990196228
step: 500, loss: 0.09519802033901215
step: 510, loss: 8.908051677281037e-05
step: 520, loss: 0.023639926686882973
step: 530, loss: 0.04713977128267288
step: 540, loss: 0.03136982023715973
step: 550, loss: 0.018535226583480835
step: 560, loss: 0.05151723697781563
step: 570, loss: 0.004812265280634165
step: 580, loss: 0.02841709367930889
step: 590, loss: 0.0005403487011790276
step: 600, loss: 0.0016439331229776144
step: 610, loss: 0.00018151373660657555
step: 620, loss: 0.023027611896395683
step: 630, loss: 0.017225882038474083
step: 640, loss: 0.02558598853647709
step: 650, loss: 0.04356956481933594
step: 660, loss: 7.231349445646629e-05
step: 670, loss: 0.0710892453789711
step: 680, loss: 0.06315461546182632
step: 690, loss: 0.04450346902012825
step: 700, loss: 0.02132256142795086
step: 710, loss: 0.020206261426210403
step: 720, loss: 0.10866936296224594
step: 730, loss: 0.0008224398479796946
step: 740, loss: 0.0703917145729065
step: 750, loss: 0.04491642862558365
step: 760, loss: 0.0025572990998625755
step: 770, loss: 0.023305770009756088
step: 780, loss: 0.08155202120542526
step: 790, loss: 0.02033785916864872
step: 800, loss: 0.00031480120378546417
step: 810, loss: 9.137248707702383e-05
step: 820, loss: 0.020739519968628883
step: 830, loss: 1.7415335605619475e-05
step: 840, loss: 0.017487872391939163
step: 850, loss: 0.047708649188280106
step: 860, loss: 3.2884825486689806e-05
step: 870, loss: 0.0018629137193784118
step: 880, loss: 0.018688317388296127
step: 890, loss: 0.050489313900470734
step: 900, loss: 0.0240609310567379
step: 910, loss: 0.039505764842033386
step: 920, loss: 0.018397608771920204
step: 930, loss: 0.025242267176508904
step: 940, loss: 0.021795805543661118
step: 950, loss: 0.022854620590806007
step: 960, loss: 0.018257804214954376
step: 970, loss: 0.0006292578764259815
step: 980, loss: 0.025930970907211304
step: 990, loss: 8.838433132041246e-05
step: 1000, loss: 0.0005375139298848808
step: 1010, loss: 0.07062798738479614
step: 1020, loss: 0.023042485117912292
step: 1030, loss: 0.054763272404670715
step: 1040, loss: 2.161697375413496e-05
step: 1050, loss: 2.7244142984272912e-05
step: 1060, loss: 0.017162110656499863
step: 1070, loss: 2.2443802663474344e-05
epoch 18: dev_f1=0.9328323156411461, f1=0.9229314420803783, best_f1=0.9340761374187557
step: 0, loss: 0.023687103763222694
step: 10, loss: 0.06417136639356613
step: 20, loss: 0.04138421639800072
step: 30, loss: 7.320463191717863e-05
step: 40, loss: 0.024220893159508705
step: 50, loss: 0.014810842461884022
step: 60, loss: 0.02266533672809601
step: 70, loss: 1.7560343621880747e-05
step: 80, loss: 0.028857972472906113
step: 90, loss: 1.489354508521501e-05
step: 100, loss: 2.752418913587462e-05
step: 110, loss: 0.02196519449353218
step: 120, loss: 1.381320362270344e-05
step: 130, loss: 6.380727427313104e-05
step: 140, loss: 0.060851577669382095
step: 150, loss: 0.03341245278716087
step: 160, loss: 0.020194945856928825
step: 170, loss: 8.430489833699539e-05
step: 180, loss: 0.030566509813070297
step: 190, loss: 0.07076197117567062
step: 200, loss: 0.041152939200401306
step: 210, loss: 0.022701647132635117
step: 220, loss: 0.11367060244083405
step: 230, loss: 0.017932526767253876
step: 240, loss: 0.0006019711145199835
step: 250, loss: 8.558877743780613e-05
step: 260, loss: 0.061120614409446716
step: 270, loss: 0.00027508914354257286
step: 280, loss: 0.043185826390981674
step: 290, loss: 9.3297720013652e-05
step: 300, loss: 0.0352536141872406
step: 310, loss: 0.019722364842891693
step: 320, loss: 0.031843338161706924
step: 330, loss: 7.21007672837004e-05
step: 340, loss: 0.04769778624176979
step: 350, loss: 0.0536455474793911
step: 360, loss: 3.1435345590580255e-05
step: 370, loss: 0.1165049821138382
step: 380, loss: 0.005383026786148548
step: 390, loss: 0.07735812664031982
step: 400, loss: 0.042591650038957596
step: 410, loss: 0.032182272523641586
step: 420, loss: 0.01794753596186638
step: 430, loss: 0.0017780226189643145
step: 440, loss: 0.0005105244927108288
step: 450, loss: 3.460655716480687e-05
step: 460, loss: 0.02288450486958027
step: 470, loss: 0.004123098682612181
step: 480, loss: 0.14366044104099274
step: 490, loss: 2.6860272555495612e-05
step: 500, loss: 1.3936180039308965e-05
step: 510, loss: 0.0018028928898274899
step: 520, loss: 0.01481892541050911
step: 530, loss: 0.00010310638026567176
step: 540, loss: 0.03694124147295952
step: 550, loss: 0.0009983459021896124
step: 560, loss: 0.09835490584373474
step: 570, loss: 0.014338514767587185
step: 580, loss: 6.192737055243924e-05
step: 590, loss: 0.02437625639140606
step: 600, loss: 0.019492659717798233
step: 610, loss: 0.01877458766102791
step: 620, loss: 0.025825319811701775
step: 630, loss: 2.181336094508879e-05
step: 640, loss: 0.04401031509041786
step: 650, loss: 0.03513041138648987
step: 660, loss: 0.00668242946267128
step: 670, loss: 0.01772250235080719
step: 680, loss: 0.02118542790412903
step: 690, loss: 2.2447184164775535e-05
step: 700, loss: 0.02863508090376854
step: 710, loss: 0.039945557713508606
step: 720, loss: 0.002890689065679908
step: 730, loss: 0.05655008181929588
step: 740, loss: 0.040956515818834305
step: 750, loss: 0.018429292365908623
step: 760, loss: 2.2283202270045877e-05
step: 770, loss: 0.04133285954594612
step: 780, loss: 0.038672782480716705
step: 790, loss: 0.029671145603060722
step: 800, loss: 0.0004096474149264395
step: 810, loss: 0.025565115734934807
step: 820, loss: 0.028902500867843628
step: 830, loss: 0.01997988298535347
step: 840, loss: 6.895969272591174e-05
step: 850, loss: 0.04429606348276138
step: 860, loss: 0.0011857885401695967
step: 870, loss: 5.009746746509336e-05
step: 880, loss: 0.02777976356446743
step: 890, loss: 0.0019264962757006288
step: 900, loss: 3.571159686543979e-05
step: 910, loss: 0.03518613055348396
step: 920, loss: 5.506566594704054e-05
step: 930, loss: 0.021917350590229034
step: 940, loss: 1.2569032151077408e-05
step: 950, loss: 0.06590274721384048
step: 960, loss: 0.027192486450076103
step: 970, loss: 0.03323748707771301
step: 980, loss: 0.0204558577388525
step: 990, loss: 0.0031933544669300318
step: 1000, loss: 0.022885717451572418
step: 1010, loss: 0.03501572459936142
step: 1020, loss: 2.459210008964874e-05
step: 1030, loss: 0.0251818485558033
step: 1040, loss: 0.01782219670712948
step: 1050, loss: 0.013836881145834923
step: 1060, loss: 0.01860848441720009
step: 1070, loss: 0.02380651980638504
epoch 19: dev_f1=0.9318394024276377, f1=0.9211267605633803, best_f1=0.9340761374187557
step: 0, loss: 0.019656231626868248
step: 10, loss: 0.046217601746320724
step: 20, loss: 0.02432294934988022
step: 30, loss: 0.02824658341705799
step: 40, loss: 0.0361461266875267
step: 50, loss: 0.0010377714643254876
step: 60, loss: 0.016644420102238655
step: 70, loss: 0.013785086572170258
step: 80, loss: 0.04336080700159073
step: 90, loss: 0.00023883089306764305
step: 100, loss: 5.86579080845695e-05
step: 110, loss: 3.9025962905725464e-05
step: 120, loss: 0.02031918242573738
step: 130, loss: 0.07865563780069351
step: 140, loss: 2.3437038180418313e-05
step: 150, loss: 0.01690910942852497
step: 160, loss: 0.021980471909046173
step: 170, loss: 0.02733837254345417
step: 180, loss: 0.03411778435111046
step: 190, loss: 0.0007610531756654382
step: 200, loss: 0.010588295757770538
step: 210, loss: 0.040059950202703476
step: 220, loss: 0.05305838584899902
step: 230, loss: 0.02910100296139717
step: 240, loss: 0.03752077743411064
step: 250, loss: 0.0062838345766067505
step: 260, loss: 2.434370617265813e-05
step: 270, loss: 0.04533931612968445
step: 280, loss: 0.01647815853357315
step: 290, loss: 0.04659026116132736
step: 300, loss: 0.003585927654057741
step: 310, loss: 0.00025037958403117955
step: 320, loss: 0.00886139553040266
step: 330, loss: 0.017718534916639328
step: 340, loss: 4.0567196265328676e-05
step: 350, loss: 0.044987089931964874
step: 360, loss: 0.001461430685594678
step: 370, loss: 0.07588144391775131
step: 380, loss: 0.021255463361740112
step: 390, loss: 0.08286246657371521
step: 400, loss: 0.01648293249309063
step: 410, loss: 0.0343269407749176
step: 420, loss: 0.0002884613932110369
step: 430, loss: 0.008704711683094501
step: 440, loss: 0.02336604706943035
step: 450, loss: 0.059817083179950714
step: 460, loss: 0.0341201052069664
step: 470, loss: 0.000109062013507355
step: 480, loss: 0.046001143753528595
step: 490, loss: 0.04511350765824318
step: 500, loss: 1.1514783182065003e-05
step: 510, loss: 5.970459824311547e-05
step: 520, loss: 0.09279262274503708
step: 530, loss: 0.029775556176900864
step: 540, loss: 0.01491528656333685
step: 550, loss: 0.015857279300689697
step: 560, loss: 0.001499864854849875
step: 570, loss: 0.020234595984220505
step: 580, loss: 0.021942634135484695
step: 590, loss: 2.6838411940843798e-05
step: 600, loss: 0.08638797700405121
step: 610, loss: 0.01773691177368164
step: 620, loss: 0.04266681894659996
step: 630, loss: 0.016965672373771667
step: 640, loss: 0.11571459472179413
step: 650, loss: 3.917661524610594e-05
step: 660, loss: 0.0441691130399704
step: 670, loss: 0.01942320168018341
step: 680, loss: 4.501617877394892e-05
step: 690, loss: 0.04254859313368797
step: 700, loss: 0.06075837463140488
step: 710, loss: 0.01236390694975853
step: 720, loss: 2.1575509890681133e-05
step: 730, loss: 0.031708333641290665
step: 740, loss: 6.20670325588435e-05
step: 750, loss: 0.056848544627428055
step: 760, loss: 0.03101586550474167
step: 770, loss: 0.028995729982852936
step: 780, loss: 0.014909092336893082
step: 790, loss: 6.472790846601129e-05
step: 800, loss: 0.019599292427301407
step: 810, loss: 0.03641840070486069
step: 820, loss: 0.06370565295219421
step: 830, loss: 0.026935020461678505
step: 840, loss: 0.045645054429769516
step: 850, loss: 0.03791419789195061
step: 860, loss: 0.04724908620119095
step: 870, loss: 0.02947930619120598
step: 880, loss: 0.061343591660261154
step: 890, loss: 0.026350785046815872
step: 900, loss: 0.03865429759025574
step: 910, loss: 0.025425978004932404
step: 920, loss: 0.028290964663028717
step: 930, loss: 0.00017200002912431955
step: 940, loss: 0.0001705210015643388
step: 950, loss: 0.057690877467393875
step: 960, loss: 0.025947505608201027
step: 970, loss: 0.07402726262807846
step: 980, loss: 0.06401054561138153
step: 990, loss: 0.056168172508478165
step: 1000, loss: 0.01580914482474327
step: 1010, loss: 0.019639229401946068
step: 1020, loss: 0.0464479885995388
step: 1030, loss: 0.0076794931665062904
step: 1040, loss: 0.022235527634620667
step: 1050, loss: 0.02063799276947975
step: 1060, loss: 0.13907207548618317
step: 1070, loss: 0.0008703131461516023
epoch 20: dev_f1=0.9300373134328358, f1=0.9232209737827715, best_f1=0.9340761374187557
