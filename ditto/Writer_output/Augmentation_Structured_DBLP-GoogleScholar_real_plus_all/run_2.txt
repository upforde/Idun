cuda
Device: cuda
step: 0, loss: 0.7416917681694031
step: 10, loss: 0.38378286361694336
step: 20, loss: 0.5039069652557373
step: 30, loss: 0.6201646327972412
step: 40, loss: 0.5149983763694763
step: 50, loss: 0.33911123871803284
step: 60, loss: 0.4664420783519745
step: 70, loss: 0.3778550624847412
step: 80, loss: 0.26394566893577576
step: 90, loss: 0.15240657329559326
step: 100, loss: 0.16746699810028076
step: 110, loss: 0.16852021217346191
step: 120, loss: 0.3763159513473511
step: 130, loss: 0.20471104979515076
step: 140, loss: 0.14789481461048126
step: 150, loss: 0.19715175032615662
step: 160, loss: 0.15556269884109497
step: 170, loss: 0.2615642547607422
step: 180, loss: 0.08497310429811478
step: 190, loss: 0.1859963834285736
step: 200, loss: 0.3262898325920105
step: 210, loss: 0.2507878839969635
step: 220, loss: 0.07587019354104996
step: 230, loss: 0.19479671120643616
step: 240, loss: 0.3772346079349518
step: 250, loss: 0.1869855672121048
step: 260, loss: 0.11236406862735748
step: 270, loss: 0.2583434283733368
step: 280, loss: 0.1937289983034134
step: 290, loss: 0.1418333500623703
step: 300, loss: 0.2411334365606308
step: 310, loss: 0.2741917371749878
step: 320, loss: 0.11233697086572647
step: 330, loss: 0.11553386598825455
step: 340, loss: 0.08613348007202148
step: 350, loss: 0.16881880164146423
step: 360, loss: 0.10327056050300598
step: 370, loss: 0.263031542301178
step: 380, loss: 0.09918837249279022
step: 390, loss: 0.07106559723615646
step: 400, loss: 0.07071519643068314
step: 410, loss: 0.09516627341508865
step: 420, loss: 0.11763089895248413
step: 430, loss: 0.3391278386116028
step: 440, loss: 0.11735683679580688
step: 450, loss: 0.12845511734485626
step: 460, loss: 0.12175162136554718
step: 470, loss: 0.0814497098326683
step: 480, loss: 0.04056856781244278
step: 490, loss: 0.14376521110534668
step: 500, loss: 0.0545574352145195
step: 510, loss: 0.14466004073619843
step: 520, loss: 0.03703651577234268
step: 530, loss: 0.06927599012851715
step: 540, loss: 0.1496041715145111
step: 550, loss: 0.1787804216146469
step: 560, loss: 0.06343427300453186
step: 570, loss: 0.1548316329717636
step: 580, loss: 0.03760991245508194
step: 590, loss: 0.13185863196849823
step: 600, loss: 0.08784335106611252
step: 610, loss: 0.05817142128944397
step: 620, loss: 0.20092807710170746
step: 630, loss: 0.13168495893478394
step: 640, loss: 0.08108191192150116
step: 650, loss: 0.21097081899642944
step: 660, loss: 0.034795667976140976
step: 670, loss: 0.18005388975143433
step: 680, loss: 0.11419520527124405
step: 690, loss: 0.23277994990348816
step: 700, loss: 0.09903377294540405
step: 710, loss: 0.09684644639492035
step: 720, loss: 0.025479866191744804
step: 730, loss: 0.10565751045942307
step: 740, loss: 0.28105103969573975
step: 750, loss: 0.1405949741601944
step: 760, loss: 0.1473371535539627
step: 770, loss: 0.11652888357639313
step: 780, loss: 0.02729851007461548
step: 790, loss: 0.05491652339696884
step: 800, loss: 0.02301204763352871
step: 810, loss: 0.1673896759748459
step: 820, loss: 0.08201707154512405
step: 830, loss: 0.13113917410373688
step: 840, loss: 0.04664953798055649
step: 850, loss: 0.2474534660577774
step: 860, loss: 0.07442771643400192
step: 870, loss: 0.11568942666053772
step: 880, loss: 0.09057971835136414
step: 890, loss: 0.08131271600723267
step: 900, loss: 0.11281690001487732
step: 910, loss: 0.10117273032665253
step: 920, loss: 0.032398853451013565
step: 930, loss: 0.1935148537158966
step: 940, loss: 0.06956447660923004
step: 950, loss: 0.06223440170288086
step: 960, loss: 0.08763384819030762
step: 970, loss: 0.035916849970817566
step: 980, loss: 0.1760246753692627
step: 990, loss: 0.1406891793012619
step: 1000, loss: 0.07161752879619598
step: 1010, loss: 0.12531830370426178
step: 1020, loss: 0.09086398780345917
step: 1030, loss: 0.022172898054122925
step: 1040, loss: 0.08669202029705048
step: 1050, loss: 0.08744190633296967
step: 1060, loss: 0.05231408774852753
step: 1070, loss: 0.018581248819828033
epoch 1: dev_f1=0.9269195189639223, f1=0.9304029304029303, best_f1=0.9304029304029303
step: 0, loss: 0.19222158193588257
step: 10, loss: 0.08155423402786255
step: 20, loss: 0.06007898598909378
step: 30, loss: 0.0891013890504837
step: 40, loss: 0.04010229930281639
step: 50, loss: 0.07677970826625824
step: 60, loss: 0.042164526879787445
step: 70, loss: 0.03371190279722214
step: 80, loss: 0.146728977560997
step: 90, loss: 0.05509946867823601
step: 100, loss: 0.07314356416463852
step: 110, loss: 0.1391311138868332
step: 120, loss: 0.052817583084106445
step: 130, loss: 0.07428012788295746
step: 140, loss: 0.16740846633911133
step: 150, loss: 0.01656516268849373
step: 160, loss: 0.12629155814647675
step: 170, loss: 0.2517373859882355
step: 180, loss: 0.08042782545089722
step: 190, loss: 0.2027331441640854
step: 200, loss: 0.044018276035785675
step: 210, loss: 0.12633006274700165
step: 220, loss: 0.09123039990663528
step: 230, loss: 0.21917906403541565
step: 240, loss: 0.05137326195836067
step: 250, loss: 0.015363205224275589
step: 260, loss: 0.014064750634133816
step: 270, loss: 0.139252170920372
step: 280, loss: 0.14090865850448608
step: 290, loss: 0.13982810080051422
step: 300, loss: 0.17552046477794647
step: 310, loss: 0.028195396065711975
step: 320, loss: 0.16724893450737
step: 330, loss: 0.14296980202198029
step: 340, loss: 0.13577276468276978
step: 350, loss: 0.028828023001551628
step: 360, loss: 0.10683102160692215
step: 370, loss: 0.08346137404441833
step: 380, loss: 0.03297678008675575
step: 390, loss: 0.11914704740047455
step: 400, loss: 0.04669688269495964
step: 410, loss: 0.07030800729990005
step: 420, loss: 0.09018465131521225
step: 430, loss: 0.16204610466957092
step: 440, loss: 0.12293299287557602
step: 450, loss: 0.04201984405517578
step: 460, loss: 0.08434167504310608
step: 470, loss: 0.14337122440338135
step: 480, loss: 0.07536650449037552
step: 490, loss: 0.0836150273680687
step: 500, loss: 0.13377058506011963
step: 510, loss: 0.16078390181064606
step: 520, loss: 0.12421251088380814
step: 530, loss: 0.0920700654387474
step: 540, loss: 0.04553806781768799
step: 550, loss: 0.13545596599578857
step: 560, loss: 0.08222444355487823
step: 570, loss: 0.14121507108211517
step: 580, loss: 0.0483693964779377
step: 590, loss: 0.24498307704925537
step: 600, loss: 0.006048194132745266
step: 610, loss: 0.13383172452449799
step: 620, loss: 0.08244670182466507
step: 630, loss: 0.0474022775888443
step: 640, loss: 0.01929117925465107
step: 650, loss: 0.03765805438160896
step: 660, loss: 0.11619964241981506
step: 670, loss: 0.047762542963027954
step: 680, loss: 0.2171514332294464
step: 690, loss: 0.030317358672618866
step: 700, loss: 0.04552615433931351
step: 710, loss: 0.06785373389720917
step: 720, loss: 0.1086941510438919
step: 730, loss: 0.09914028644561768
step: 740, loss: 0.06954238563776016
step: 750, loss: 0.12868352234363556
step: 760, loss: 0.13108670711517334
step: 770, loss: 0.0732603445649147
step: 780, loss: 0.08055751025676727
step: 790, loss: 0.007415562402456999
step: 800, loss: 0.018679248169064522
step: 810, loss: 0.01680426113307476
step: 820, loss: 0.12356100976467133
step: 830, loss: 0.05765678733587265
step: 840, loss: 0.04432707279920578
step: 850, loss: 0.08861420303583145
step: 860, loss: 0.0951569452881813
step: 870, loss: 0.1363145411014557
step: 880, loss: 0.1549822986125946
step: 890, loss: 0.10675664991140366
step: 900, loss: 0.056310903280973434
step: 910, loss: 0.051495932042598724
step: 920, loss: 0.0880199745297432
step: 930, loss: 0.13107284903526306
step: 940, loss: 0.15193413197994232
step: 950, loss: 0.19002674520015717
step: 960, loss: 0.1176828071475029
step: 970, loss: 0.05595573037862778
step: 980, loss: 0.03360968828201294
step: 990, loss: 0.08889447152614594
step: 1000, loss: 0.025852052494883537
step: 1010, loss: 0.16326384246349335
step: 1020, loss: 0.06584154814481735
step: 1030, loss: 0.08824922889471054
step: 1040, loss: 0.11630658060312271
step: 1050, loss: 0.09658431261777878
step: 1060, loss: 0.05237773060798645
step: 1070, loss: 0.2130785584449768
epoch 2: dev_f1=0.9216981132075471, f1=0.9183864915572232, best_f1=0.9304029304029303
step: 0, loss: 0.05070151016116142
step: 10, loss: 0.10893817245960236
step: 20, loss: 0.08184758573770523
step: 30, loss: 0.09289698302745819
step: 40, loss: 0.12663544714450836
step: 50, loss: 0.08741787075996399
step: 60, loss: 0.011092581786215305
step: 70, loss: 0.05215737596154213
step: 80, loss: 0.07389365881681442
step: 90, loss: 0.12271419167518616
step: 100, loss: 0.013287102803587914
step: 110, loss: 0.0010708869667723775
step: 120, loss: 0.06377793103456497
step: 130, loss: 0.0830349251627922
step: 140, loss: 0.05467565730214119
step: 150, loss: 0.02781302109360695
step: 160, loss: 0.11092787235975266
step: 170, loss: 0.02870260737836361
step: 180, loss: 0.11383174359798431
step: 190, loss: 0.20000799000263214
step: 200, loss: 0.27928444743156433
step: 210, loss: 0.06193632259964943
step: 220, loss: 0.06358062475919724
step: 230, loss: 0.0411604642868042
step: 240, loss: 0.037115491926670074
step: 250, loss: 0.0035117215011268854
step: 260, loss: 0.05655551701784134
step: 270, loss: 0.11764495819807053
step: 280, loss: 0.16330863535404205
step: 290, loss: 0.11191211640834808
step: 300, loss: 0.20878392457962036
step: 310, loss: 0.12999694049358368
step: 320, loss: 0.19900766015052795
step: 330, loss: 0.030858114361763
step: 340, loss: 0.02040361985564232
step: 350, loss: 0.04379705339670181
step: 360, loss: 0.02133900299668312
step: 370, loss: 0.11519289761781693
step: 380, loss: 0.09905272722244263
step: 390, loss: 0.13706475496292114
step: 400, loss: 0.019493455067276955
step: 410, loss: 0.03327379375696182
step: 420, loss: 0.08420209586620331
step: 430, loss: 0.045014455914497375
step: 440, loss: 0.11619464308023453
step: 450, loss: 0.10911455750465393
step: 460, loss: 0.07175219058990479
step: 470, loss: 0.050850752741098404
step: 480, loss: 0.09799358248710632
step: 490, loss: 0.010223226621747017
step: 500, loss: 0.15228880941867828
step: 510, loss: 0.12993931770324707
step: 520, loss: 0.07297029346227646
step: 530, loss: 0.195387065410614
step: 540, loss: 0.13368171453475952
step: 550, loss: 0.057968463748693466
step: 560, loss: 0.06993105262517929
step: 570, loss: 0.07831558585166931
step: 580, loss: 0.1583133041858673
step: 590, loss: 0.039703693240880966
step: 600, loss: 0.025208571925759315
step: 610, loss: 0.0819784626364708
step: 620, loss: 0.014220701530575752
step: 630, loss: 0.12341097742319107
step: 640, loss: 0.04063434898853302
step: 650, loss: 0.07991283386945724
step: 660, loss: 0.14830756187438965
step: 670, loss: 0.11082892119884491
step: 680, loss: 0.0353667289018631
step: 690, loss: 0.13989825546741486
step: 700, loss: 0.06761495769023895
step: 710, loss: 0.014374318532645702
step: 720, loss: 0.16042177379131317
step: 730, loss: 0.09675461798906326
step: 740, loss: 0.15105964243412018
step: 750, loss: 0.14192461967468262
step: 760, loss: 0.022355737164616585
step: 770, loss: 0.051845669746398926
step: 780, loss: 0.07520018517971039
step: 790, loss: 0.05357281118631363
step: 800, loss: 0.08608408272266388
step: 810, loss: 0.15331217646598816
step: 820, loss: 0.08115287125110626
step: 830, loss: 0.011743768118321896
step: 840, loss: 0.10058164596557617
step: 850, loss: 0.10854045301675797
step: 860, loss: 0.1594904661178589
step: 870, loss: 0.0276397205889225
step: 880, loss: 0.050580400973558426
step: 890, loss: 0.0644102543592453
step: 900, loss: 0.17348554730415344
step: 910, loss: 0.016064012423157692
step: 920, loss: 0.02003864012658596
step: 930, loss: 0.0430125929415226
step: 940, loss: 0.12968464195728302
step: 950, loss: 0.10126450657844543
step: 960, loss: 0.07467415928840637
step: 970, loss: 0.02980085276067257
step: 980, loss: 0.050568658858537674
step: 990, loss: 0.03757938742637634
step: 1000, loss: 0.09436079114675522
step: 1010, loss: 0.08070838451385498
step: 1020, loss: 0.13626185059547424
step: 1030, loss: 0.03670018911361694
step: 1040, loss: 0.08415800333023071
step: 1050, loss: 0.11637493968009949
step: 1060, loss: 0.02801663987338543
step: 1070, loss: 0.009977991692721844
epoch 3: dev_f1=0.9281767955801105, f1=0.9277777777777779, best_f1=0.9277777777777779
step: 0, loss: 0.09731603413820267
step: 10, loss: 0.040553342550992966
step: 20, loss: 0.05607040598988533
step: 30, loss: 0.010495645925402641
step: 40, loss: 0.23749154806137085
step: 50, loss: 0.0809202715754509
step: 60, loss: 0.02198280766606331
step: 70, loss: 0.0994182899594307
step: 80, loss: 0.05473436415195465
step: 90, loss: 0.09320803731679916
step: 100, loss: 0.013156444765627384
step: 110, loss: 0.03457271680235863
step: 120, loss: 0.08175894618034363
step: 130, loss: 0.02024015225470066
step: 140, loss: 0.058033883571624756
step: 150, loss: 0.041275154799222946
step: 160, loss: 0.03926556184887886
step: 170, loss: 0.07455413043498993
step: 180, loss: 0.024485191330313683
step: 190, loss: 0.006203805096447468
step: 200, loss: 0.07548681646585464
step: 210, loss: 0.21012386679649353
step: 220, loss: 0.1106521338224411
step: 230, loss: 0.04037012532353401
step: 240, loss: 0.06813494861125946
step: 250, loss: 0.11497373133897781
step: 260, loss: 0.09654715657234192
step: 270, loss: 0.005848593544214964
step: 280, loss: 0.05267490819096565
step: 290, loss: 0.02635653130710125
step: 300, loss: 0.029520684853196144
step: 310, loss: 0.10905152559280396
step: 320, loss: 0.02156568132340908
step: 330, loss: 0.028471503406763077
step: 340, loss: 0.15205906331539154
step: 350, loss: 0.03843483701348305
step: 360, loss: 0.02709929458796978
step: 370, loss: 0.030613474547863007
step: 380, loss: 0.015738291665911674
step: 390, loss: 0.023566672578454018
step: 400, loss: 0.008330564945936203
step: 410, loss: 0.005836006719619036
step: 420, loss: 0.06972835212945938
step: 430, loss: 0.048555195331573486
step: 440, loss: 0.007039959076792002
step: 450, loss: 0.08244366198778152
step: 460, loss: 0.031765371561050415
step: 470, loss: 0.14074647426605225
step: 480, loss: 0.06921037286520004
step: 490, loss: 0.022456655278801918
step: 500, loss: 0.1544387936592102
step: 510, loss: 0.02701531909406185
step: 520, loss: 0.08041553944349289
step: 530, loss: 0.12798187136650085
step: 540, loss: 0.13995051383972168
step: 550, loss: 0.05374186486005783
step: 560, loss: 0.09758510440587997
step: 570, loss: 0.07245215773582458
step: 580, loss: 0.052846189588308334
step: 590, loss: 0.1829882264137268
step: 600, loss: 0.08387760072946548
step: 610, loss: 0.1652102768421173
step: 620, loss: 0.03351324424147606
step: 630, loss: 0.06384260207414627
step: 640, loss: 0.010077456012368202
step: 650, loss: 0.04973195493221283
step: 660, loss: 0.03827473148703575
step: 670, loss: 0.16729871928691864
step: 680, loss: 0.15730342268943787
step: 690, loss: 0.2533556818962097
step: 700, loss: 0.006440168712288141
step: 710, loss: 0.014365806244313717
step: 720, loss: 0.09863745421171188
step: 730, loss: 0.0873531624674797
step: 740, loss: 0.0718344897031784
step: 750, loss: 0.014079784974455833
step: 760, loss: 0.02931966818869114
step: 770, loss: 0.15345962345600128
step: 780, loss: 0.05300237238407135
step: 790, loss: 0.13948005437850952
step: 800, loss: 0.072695292532444
step: 810, loss: 0.03035803698003292
step: 820, loss: 0.013124581426382065
step: 830, loss: 0.17011910676956177
step: 840, loss: 0.030415687710046768
step: 850, loss: 0.28127390146255493
step: 860, loss: 0.13921348750591278
step: 870, loss: 0.07342147827148438
step: 880, loss: 0.10763682425022125
step: 890, loss: 0.09619884938001633
step: 900, loss: 0.036315515637397766
step: 910, loss: 0.012087762355804443
step: 920, loss: 0.040890198200941086
step: 930, loss: 0.10689616203308105
step: 940, loss: 0.027138615027070045
step: 950, loss: 0.06630174815654755
step: 960, loss: 0.0598081573843956
step: 970, loss: 0.08375432342290878
step: 980, loss: 0.04874840006232262
step: 990, loss: 0.061565324664115906
step: 1000, loss: 0.24157965183258057
step: 1010, loss: 0.11048559099435806
step: 1020, loss: 0.06410171836614609
step: 1030, loss: 0.05438941717147827
step: 1040, loss: 0.06516364216804504
step: 1050, loss: 0.0024356527719646692
step: 1060, loss: 0.08914041519165039
step: 1070, loss: 0.03156565874814987
epoch 4: dev_f1=0.9341486359360301, f1=0.9295112781954888, best_f1=0.9295112781954888
step: 0, loss: 0.11041112244129181
step: 10, loss: 0.009297340176999569
step: 20, loss: 0.05282587185502052
step: 30, loss: 0.015097021125257015
step: 40, loss: 0.03542337194085121
step: 50, loss: 0.0830378532409668
step: 60, loss: 0.1027817353606224
step: 70, loss: 0.09703577309846878
step: 80, loss: 0.08470401912927628
step: 90, loss: 0.041832681745290756
step: 100, loss: 0.03649183362722397
step: 110, loss: 0.012006158009171486
step: 120, loss: 0.0005132370279170573
step: 130, loss: 0.025026066228747368
step: 140, loss: 0.12893374264240265
step: 150, loss: 0.0822993740439415
step: 160, loss: 0.04195339232683182
step: 170, loss: 0.08896053582429886
step: 180, loss: 0.06458670645952225
step: 190, loss: 0.047239333391189575
step: 200, loss: 0.23457472026348114
step: 210, loss: 0.0598762184381485
step: 220, loss: 0.14453686773777008
step: 230, loss: 0.07796991616487503
step: 240, loss: 0.05100737512111664
step: 250, loss: 0.07244914770126343
step: 260, loss: 0.02944773994386196
step: 270, loss: 0.10821066796779633
step: 280, loss: 0.06363032013177872
step: 290, loss: 0.083071768283844
step: 300, loss: 0.01688995398581028
step: 310, loss: 0.15186280012130737
step: 320, loss: 0.08250561356544495
step: 330, loss: 0.015650244429707527
step: 340, loss: 0.14347423613071442
step: 350, loss: 0.06731114536523819
step: 360, loss: 0.03963370621204376
step: 370, loss: 0.10928846150636673
step: 380, loss: 0.027625029906630516
step: 390, loss: 0.04768781736493111
step: 400, loss: 0.11220965534448624
step: 410, loss: 0.040617238730192184
step: 420, loss: 0.037711575627326965
step: 430, loss: 0.09234619140625
step: 440, loss: 0.09129835665225983
step: 450, loss: 0.13954824209213257
step: 460, loss: 0.03891069442033768
step: 470, loss: 0.026885434985160828
step: 480, loss: 0.01244937814772129
step: 490, loss: 0.0749976858496666
step: 500, loss: 0.0043477159924805164
step: 510, loss: 0.011445391923189163
step: 520, loss: 0.014445782639086246
step: 530, loss: 0.007386940065771341
step: 540, loss: 0.057884447276592255
step: 550, loss: 0.03163124620914459
step: 560, loss: 0.15073499083518982
step: 570, loss: 0.07396728545427322
step: 580, loss: 0.06997998803853989
step: 590, loss: 0.008654597215354443
step: 600, loss: 0.0754094198346138
step: 610, loss: 0.0772830992937088
step: 620, loss: 0.034473638981580734
step: 630, loss: 0.007247684523463249
step: 640, loss: 0.07708005607128143
step: 650, loss: 0.08649791032075882
step: 660, loss: 0.15590927004814148
step: 670, loss: 0.03965792432427406
step: 680, loss: 0.024599311873316765
step: 690, loss: 0.1357129067182541
step: 700, loss: 0.08311496675014496
step: 710, loss: 0.02774731256067753
step: 720, loss: 0.016253739595413208
step: 730, loss: 0.10498236864805222
step: 740, loss: 0.08408548682928085
step: 750, loss: 0.018596479669213295
step: 760, loss: 0.03563205525279045
step: 770, loss: 0.07871946692466736
step: 780, loss: 0.06396829336881638
step: 790, loss: 0.09273622930049896
step: 800, loss: 0.14161431789398193
step: 810, loss: 0.03401923552155495
step: 820, loss: 0.057350240647792816
step: 830, loss: 0.0935949981212616
step: 840, loss: 0.09256605803966522
step: 850, loss: 0.04885796457529068
step: 860, loss: 0.11060814559459686
step: 870, loss: 0.017965683713555336
step: 880, loss: 0.025220010429620743
step: 890, loss: 0.02018832415342331
step: 900, loss: 0.06777530163526535
step: 910, loss: 0.0696517825126648
step: 920, loss: 0.07917167246341705
step: 930, loss: 0.0080291498452425
step: 940, loss: 0.10173623263835907
step: 950, loss: 0.07854268699884415
step: 960, loss: 0.009406059980392456
step: 970, loss: 0.009150652214884758
step: 980, loss: 0.021095948293805122
step: 990, loss: 0.01670028828084469
step: 1000, loss: 0.11176305264234543
step: 1010, loss: 0.1293816864490509
step: 1020, loss: 0.08315612375736237
step: 1030, loss: 0.041144248098134995
step: 1040, loss: 0.024623548611998558
step: 1050, loss: 0.02273045852780342
step: 1060, loss: 0.07721550762653351
step: 1070, loss: 0.03725074604153633
epoch 5: dev_f1=0.9340710004610421, f1=0.921451538814883, best_f1=0.9295112781954888
step: 0, loss: 0.08721552789211273
step: 10, loss: 0.03752933070063591
step: 20, loss: 0.11943166702985764
step: 30, loss: 0.058453261852264404
step: 40, loss: 0.15478456020355225
step: 50, loss: 0.1268199384212494
step: 60, loss: 0.031068308278918266
step: 70, loss: 0.1040617972612381
step: 80, loss: 0.051397714763879776
step: 90, loss: 0.04762755706906319
step: 100, loss: 0.08993812650442123
step: 110, loss: 0.005139038432389498
step: 120, loss: 0.10390587896108627
step: 130, loss: 0.07951103150844574
step: 140, loss: 0.09402072429656982
step: 150, loss: 0.00010101150837726891
step: 160, loss: 0.048817217350006104
step: 170, loss: 0.0772065743803978
step: 180, loss: 0.09136854112148285
step: 190, loss: 0.035252321511507034
step: 200, loss: 0.0664689838886261
step: 210, loss: 0.07282551378011703
step: 220, loss: 0.28764447569847107
step: 230, loss: 0.18674005568027496
step: 240, loss: 0.02860763482749462
step: 250, loss: 0.017749572172760963
step: 260, loss: 0.03752783685922623
step: 270, loss: 0.056962575763463974
step: 280, loss: 0.17154979705810547
step: 290, loss: 0.06570867449045181
step: 300, loss: 0.21289750933647156
step: 310, loss: 0.02919907495379448
step: 320, loss: 0.07713183760643005
step: 330, loss: 0.03859056159853935
step: 340, loss: 0.10083954781293869
step: 350, loss: 0.08960483223199844
step: 360, loss: 0.2986755967140198
step: 370, loss: 0.11739227175712585
step: 380, loss: 0.02933983877301216
step: 390, loss: 0.0931563600897789
step: 400, loss: 0.0003962569171562791
step: 410, loss: 0.07631020247936249
step: 420, loss: 0.04306179657578468
step: 430, loss: 0.11996704339981079
step: 440, loss: 0.06644338369369507
step: 450, loss: 0.06276725977659225
step: 460, loss: 0.05094622075557709
step: 470, loss: 0.008430235087871552
step: 480, loss: 0.018829138949513435
step: 490, loss: 0.07268431037664413
step: 500, loss: 0.046322595328092575
step: 510, loss: 0.007232837378978729
step: 520, loss: 0.02764350362122059
step: 530, loss: 0.022640636190772057
step: 540, loss: 0.019667914137244225
step: 550, loss: 0.03757762908935547
step: 560, loss: 0.0197012759745121
step: 570, loss: 0.007943118922412395
step: 580, loss: 0.06331221014261246
step: 590, loss: 0.014219515956938267
step: 600, loss: 0.11332131177186966
step: 610, loss: 0.05964326858520508
step: 620, loss: 0.0494995042681694
step: 630, loss: 0.11093620955944061
step: 640, loss: 0.07629267871379852
step: 650, loss: 0.06755483150482178
step: 660, loss: 0.04505094513297081
step: 670, loss: 0.07573435455560684
step: 680, loss: 0.03411241993308067
step: 690, loss: 0.045244742184877396
step: 700, loss: 0.01351235806941986
step: 710, loss: 0.023212607949972153
step: 720, loss: 0.09546306729316711
step: 730, loss: 0.014583911746740341
step: 740, loss: 0.007221205160021782
step: 750, loss: 0.046628568321466446
step: 760, loss: 0.13190606236457825
step: 770, loss: 0.025405731052160263
step: 780, loss: 0.19570854306221008
step: 790, loss: 0.01624532788991928
step: 800, loss: 0.007813744246959686
step: 810, loss: 0.05463402718305588
step: 820, loss: 0.10545877367258072
step: 830, loss: 0.04319572076201439
step: 840, loss: 0.00015247259580064565
step: 850, loss: 0.06713113933801651
step: 860, loss: 0.10156360268592834
step: 870, loss: 0.07319822907447815
step: 880, loss: 0.09348174929618835
step: 890, loss: 0.03617478907108307
step: 900, loss: 0.03265770897269249
step: 910, loss: 0.024246690794825554
step: 920, loss: 0.03977371007204056
step: 930, loss: 0.07649233937263489
step: 940, loss: 0.00923097226768732
step: 950, loss: 0.009999161586165428
step: 960, loss: 0.2387097179889679
step: 970, loss: 0.036281999200582504
step: 980, loss: 0.042638689279556274
step: 990, loss: 0.0011612566886469722
step: 1000, loss: 0.030964836478233337
step: 1010, loss: 0.027518369257450104
step: 1020, loss: 0.07371477037668228
step: 1030, loss: 0.039356667548418045
step: 1040, loss: 0.09025657922029495
step: 1050, loss: 0.10664395987987518
step: 1060, loss: 0.048603255301713943
step: 1070, loss: 0.003930802922695875
epoch 6: dev_f1=0.9337042188224385, f1=0.9309225776541493, best_f1=0.9295112781954888
step: 0, loss: 0.06668498367071152
step: 10, loss: 0.09459549933671951
step: 20, loss: 0.0728534609079361
step: 30, loss: 0.018882188946008682
step: 40, loss: 0.025632714852690697
step: 50, loss: 0.06588107347488403
step: 60, loss: 0.005484662018716335
step: 70, loss: 0.10151232033967972
step: 80, loss: 0.0197895560413599
step: 90, loss: 0.09906784445047379
step: 100, loss: 0.12310612201690674
step: 110, loss: 0.0004169775638729334
step: 120, loss: 0.03353595361113548
step: 130, loss: 0.017006056383252144
step: 140, loss: 0.07893765717744827
step: 150, loss: 0.01634332910180092
step: 160, loss: 0.0841689482331276
step: 170, loss: 0.021819323301315308
step: 180, loss: 0.11125251650810242
step: 190, loss: 0.06336939334869385
step: 200, loss: 0.014822181314229965
step: 210, loss: 0.1042046919465065
step: 220, loss: 0.02342965640127659
step: 230, loss: 0.0019498553592711687
step: 240, loss: 0.0737379789352417
step: 250, loss: 0.01298050582408905
step: 260, loss: 0.02707793191075325
step: 270, loss: 0.018996138125658035
step: 280, loss: 0.0024502540472894907
step: 290, loss: 0.057251956313848495
step: 300, loss: 0.010705128312110901
step: 310, loss: 0.06739427894353867
step: 320, loss: 0.11173391342163086
step: 330, loss: 0.008925078436732292
step: 340, loss: 0.1170220673084259
step: 350, loss: 0.09768281877040863
step: 360, loss: 0.025953292846679688
step: 370, loss: 0.01692473143339157
step: 380, loss: 0.00177641527261585
step: 390, loss: 0.030931448563933372
step: 400, loss: 0.004243371542543173
step: 410, loss: 0.25574761629104614
step: 420, loss: 0.02541431039571762
step: 430, loss: 0.017506787553429604
step: 440, loss: 0.0099254809319973
step: 450, loss: 0.003914474975317717
step: 460, loss: 0.08639518916606903
step: 470, loss: 0.0204008761793375
step: 480, loss: 0.013885047286748886
step: 490, loss: 0.055328987538814545
step: 500, loss: 0.02889174036681652
step: 510, loss: 0.045914068818092346
step: 520, loss: 0.08079885691404343
step: 530, loss: 0.14093048870563507
step: 540, loss: 0.16871404647827148
step: 550, loss: 0.024044658988714218
step: 560, loss: 0.052731044590473175
step: 570, loss: 0.16657529771327972
step: 580, loss: 0.03168768435716629
step: 590, loss: 0.020198682323098183
step: 600, loss: 0.04773345962166786
step: 610, loss: 0.12647494673728943
step: 620, loss: 0.02285689115524292
step: 630, loss: 0.11961908638477325
step: 640, loss: 0.12081466615200043
step: 650, loss: 0.16901814937591553
step: 660, loss: 0.017748801037669182
step: 670, loss: 0.17435073852539062
step: 680, loss: 0.042856231331825256
step: 690, loss: 0.020206090062856674
step: 700, loss: 0.1359170824289322
step: 710, loss: 0.04546711966395378
step: 720, loss: 0.057915836572647095
step: 730, loss: 0.02541300468146801
step: 740, loss: 0.05505766719579697
step: 750, loss: 0.04692315682768822
step: 760, loss: 0.00014001832460053265
step: 770, loss: 0.02045731246471405
step: 780, loss: 0.05301327630877495
step: 790, loss: 0.039004068821668625
step: 800, loss: 0.1253608912229538
step: 810, loss: 0.0010331007651984692
step: 820, loss: 0.15294554829597473
step: 830, loss: 0.05878803879022598
step: 840, loss: 0.008469032123684883
step: 850, loss: 0.004769188351929188
step: 860, loss: 0.03989243134856224
step: 870, loss: 0.03268779441714287
step: 880, loss: 0.0721905380487442
step: 890, loss: 0.0803871676325798
step: 900, loss: 0.010477949865162373
step: 910, loss: 0.02108597941696644
step: 920, loss: 0.1764032244682312
step: 930, loss: 0.017971737310290337
step: 940, loss: 0.038279660046100616
step: 950, loss: 0.06893713772296906
step: 960, loss: 0.15253472328186035
step: 970, loss: 0.07320044934749603
step: 980, loss: 0.1230950653553009
step: 990, loss: 0.11106498539447784
step: 1000, loss: 0.04359189420938492
step: 1010, loss: 0.005469170399010181
step: 1020, loss: 0.024322664365172386
step: 1030, loss: 0.05938496068120003
step: 1040, loss: 0.09843474626541138
step: 1050, loss: 0.004376884084194899
step: 1060, loss: 0.0038973032496869564
step: 1070, loss: 0.027319252490997314
epoch 7: dev_f1=0.9405756731662025, f1=0.9347014925373135, best_f1=0.9347014925373135
step: 0, loss: 0.042312297970056534
step: 10, loss: 0.11200842261314392
step: 20, loss: 0.01699984446167946
step: 30, loss: 0.03780010715126991
step: 40, loss: 0.01611293852329254
step: 50, loss: 0.018994472920894623
step: 60, loss: 0.010654950514435768
step: 70, loss: 0.06902749836444855
step: 80, loss: 0.05210650712251663
step: 90, loss: 0.005068300291895866
step: 100, loss: 0.0829879567027092
step: 110, loss: 0.007323354482650757
step: 120, loss: 0.037194088101387024
step: 130, loss: 0.021935831755399704
step: 140, loss: 0.19662335515022278
step: 150, loss: 0.036033228039741516
step: 160, loss: 0.09099169075489044
step: 170, loss: 0.0684104785323143
step: 180, loss: 0.08042830973863602
step: 190, loss: 0.059998176991939545
step: 200, loss: 0.03001883253455162
step: 210, loss: 0.058447375893592834
step: 220, loss: 0.02534944750368595
step: 230, loss: 0.022587424144148827
step: 240, loss: 0.1790105402469635
step: 250, loss: 0.05676718428730965
step: 260, loss: 0.06407874822616577
step: 270, loss: 0.05590370297431946
step: 280, loss: 0.014338175766170025
step: 290, loss: 0.03176095709204674
step: 300, loss: 0.04076778143644333
step: 310, loss: 0.08251757174730301
step: 320, loss: 0.10813593119382858
step: 330, loss: 0.027081293985247612
step: 340, loss: 0.019539376720786095
step: 350, loss: 0.034074220806360245
step: 360, loss: 0.03143788501620293
step: 370, loss: 0.004268576856702566
step: 380, loss: 0.03067803382873535
step: 390, loss: 0.1204419732093811
step: 400, loss: 0.0924396738409996
step: 410, loss: 0.060976237058639526
step: 420, loss: 0.043292924761772156
step: 430, loss: 0.11820761114358902
step: 440, loss: 0.02546686679124832
step: 450, loss: 0.1317569613456726
step: 460, loss: 0.09341767430305481
step: 470, loss: 0.017886700108647346
step: 480, loss: 0.0322321318089962
step: 490, loss: 0.07346183061599731
step: 500, loss: 0.10389469563961029
step: 510, loss: 0.020726699382066727
step: 520, loss: 0.005939284805208445
step: 530, loss: 0.019312849268317223
step: 540, loss: 0.09403407573699951
step: 550, loss: 0.041885823011398315
step: 560, loss: 0.2846621870994568
step: 570, loss: 0.02099650725722313
step: 580, loss: 0.10174588859081268
step: 590, loss: 0.0613112635910511
step: 600, loss: 0.004334002733230591
step: 610, loss: 0.07169820368289948
step: 620, loss: 0.006996498443186283
step: 630, loss: 0.07957388460636139
step: 640, loss: 0.018281197175383568
step: 650, loss: 0.07564452290534973
step: 660, loss: 0.03359312191605568
step: 670, loss: 0.011969675309956074
step: 680, loss: 0.00932006910443306
step: 690, loss: 0.1721295416355133
step: 700, loss: 0.05724812299013138
step: 710, loss: 0.07370234280824661
step: 720, loss: 0.03569779172539711
step: 730, loss: 0.08244362473487854
step: 740, loss: 0.0437091700732708
step: 750, loss: 0.11066547781229019
step: 760, loss: 0.03659069538116455
step: 770, loss: 0.11121905595064163
step: 780, loss: 0.028811438009142876
step: 790, loss: 0.031348392367362976
step: 800, loss: 0.02874213270843029
step: 810, loss: 0.049154430627822876
step: 820, loss: 0.007086280267685652
step: 830, loss: 0.04492528364062309
step: 840, loss: 0.10754891484975815
step: 850, loss: 0.032389454543590546
step: 860, loss: 0.012756478041410446
step: 870, loss: 0.11173473298549652
step: 880, loss: 0.05644143745303154
step: 890, loss: 0.02706863358616829
step: 900, loss: 0.04335061460733414
step: 910, loss: 0.011772380210459232
step: 920, loss: 0.0758020207285881
step: 930, loss: 0.007782684173434973
step: 940, loss: 0.022767286747694016
step: 950, loss: 0.016143234446644783
step: 960, loss: 0.03709825873374939
step: 970, loss: 0.24590493738651276
step: 980, loss: 0.01895863190293312
step: 990, loss: 0.016007551923394203
step: 1000, loss: 0.14075802266597748
step: 1010, loss: 0.005066509358584881
step: 1020, loss: 0.05204062536358833
step: 1030, loss: 0.03303977847099304
step: 1040, loss: 0.15346136689186096
step: 1050, loss: 0.05269208922982216
step: 1060, loss: 0.10835925489664078
step: 1070, loss: 0.1207873597741127
epoch 8: dev_f1=0.9382830626450116, f1=0.9357967667436491, best_f1=0.9347014925373135
step: 0, loss: 0.014524108730256557
step: 10, loss: 0.032114721834659576
step: 20, loss: 0.0929512083530426
step: 30, loss: 0.09569910168647766
step: 40, loss: 0.026605846360325813
step: 50, loss: 0.041548050940036774
step: 60, loss: 0.050293147563934326
step: 70, loss: 0.06868426501750946
step: 80, loss: 0.07145003229379654
step: 90, loss: 0.106002576649189
step: 100, loss: 0.0031403491739183664
step: 110, loss: 0.1388448178768158
step: 120, loss: 0.031109526753425598
step: 130, loss: 0.004307225346565247
step: 140, loss: 0.026079876348376274
step: 150, loss: 0.05292650684714317
step: 160, loss: 0.04524112492799759
step: 170, loss: 0.08447793871164322
step: 180, loss: 0.0696343183517456
step: 190, loss: 0.013306668028235435
step: 200, loss: 0.017053652554750443
step: 210, loss: 0.09147509932518005
step: 220, loss: 0.08184158802032471
step: 230, loss: 0.016991334035992622
step: 240, loss: 0.01721809059381485
step: 250, loss: 0.10224442929029465
step: 260, loss: 0.12609396874904633
step: 270, loss: 0.030855916440486908
step: 280, loss: 0.11678345501422882
step: 290, loss: 0.003371348138898611
step: 300, loss: 0.019816908985376358
step: 310, loss: 0.009513149969279766
step: 320, loss: 0.10963443666696548
step: 330, loss: 0.015863293781876564
step: 340, loss: 0.005928992293775082
step: 350, loss: 0.16070109605789185
step: 360, loss: 0.07997366040945053
step: 370, loss: 0.0277611892670393
step: 380, loss: 0.06482600420713425
step: 390, loss: 0.01192496344447136
step: 400, loss: 0.04387463256716728
step: 410, loss: 0.030148964375257492
step: 420, loss: 0.022720521315932274
step: 430, loss: 0.05000322684645653
step: 440, loss: 0.04473862051963806
step: 450, loss: 0.020082928240299225
step: 460, loss: 0.04974796995520592
step: 470, loss: 0.007422558031976223
step: 480, loss: 0.014170282520353794
step: 490, loss: 0.038592588156461716
step: 500, loss: 0.07367885857820511
step: 510, loss: 0.19041748344898224
step: 520, loss: 0.02778884395956993
step: 530, loss: 0.03522656112909317
step: 540, loss: 0.004140602890402079
step: 550, loss: 0.03031465783715248
step: 560, loss: 0.005167278926819563
step: 570, loss: 0.13172097504138947
step: 580, loss: 0.0008589967619627714
step: 590, loss: 0.0006949721719138324
step: 600, loss: 0.009002340957522392
step: 610, loss: 0.09154652059078217
step: 620, loss: 0.06727346032857895
step: 630, loss: 0.0713203176856041
step: 640, loss: 0.015150235965847969
step: 650, loss: 0.1004263162612915
step: 660, loss: 0.1207876056432724
step: 670, loss: 0.11207836866378784
step: 680, loss: 0.023663654923439026
step: 690, loss: 0.13470111787319183
step: 700, loss: 0.044930897653102875
step: 710, loss: 0.0044515603221952915
step: 720, loss: 0.013554994016885757
step: 730, loss: 0.021763674914836884
step: 740, loss: 0.05243798717856407
step: 750, loss: 0.015346149913966656
step: 760, loss: 0.05834629759192467
step: 770, loss: 0.012198613956570625
step: 780, loss: 0.00627308851107955
step: 790, loss: 0.0697844997048378
step: 800, loss: 0.05101810023188591
step: 810, loss: 0.08211354911327362
step: 820, loss: 0.013572217896580696
step: 830, loss: 0.09465835243463516
step: 840, loss: 0.05435281991958618
step: 850, loss: 0.03412054851651192
step: 860, loss: 0.05438374727964401
step: 870, loss: 0.14868254959583282
step: 880, loss: 0.0640043094754219
step: 890, loss: 0.17177680134773254
step: 900, loss: 0.06634539365768433
step: 910, loss: 0.017741765826940536
step: 920, loss: 0.024174252524971962
step: 930, loss: 0.007767331320792437
step: 940, loss: 0.06232748553156853
step: 950, loss: 0.024467969313263893
step: 960, loss: 0.04657129943370819
step: 970, loss: 0.02276626229286194
step: 980, loss: 0.028088247403502464
step: 990, loss: 0.1295783966779709
step: 1000, loss: 0.020363902673125267
step: 1010, loss: 0.04317544028162956
step: 1020, loss: 0.02555236779153347
step: 1030, loss: 0.01623440533876419
step: 1040, loss: 0.027821769937872887
step: 1050, loss: 0.09721916168928146
step: 1060, loss: 0.03784894943237305
step: 1070, loss: 0.14399509131908417
epoch 9: dev_f1=0.9383057090239412, f1=0.9386814200092208, best_f1=0.9347014925373135
step: 0, loss: 0.09178866446018219
step: 10, loss: 0.020936541259288788
step: 20, loss: 0.030621428042650223
step: 30, loss: 0.027764176949858665
step: 40, loss: 0.018508298322558403
step: 50, loss: 0.0370686911046505
step: 60, loss: 0.010614913888275623
step: 70, loss: 0.01997622661292553
step: 80, loss: 0.02998519316315651
step: 90, loss: 0.08210256695747375
step: 100, loss: 0.06754196435213089
step: 110, loss: 0.060043446719646454
step: 120, loss: 0.0035452074371278286
step: 130, loss: 0.056910451501607895
step: 140, loss: 0.002896721940487623
step: 150, loss: 0.0060710785910487175
step: 160, loss: 0.034139327704906464
step: 170, loss: 0.07368677854537964
step: 180, loss: 0.009214445948600769
step: 190, loss: 0.012437253259122372
step: 200, loss: 0.01688767597079277
step: 210, loss: 0.0964081734418869
step: 220, loss: 0.018812697380781174
step: 230, loss: 0.07514427602291107
step: 240, loss: 0.017467927187681198
step: 250, loss: 0.018551206216216087
step: 260, loss: 0.0004981464589945972
step: 270, loss: 0.012387213297188282
step: 280, loss: 0.09735719859600067
step: 290, loss: 0.010056041181087494
step: 300, loss: 0.01897025853395462
step: 310, loss: 0.051042452454566956
step: 320, loss: 0.14382752776145935
step: 330, loss: 0.08896804600954056
step: 340, loss: 0.050413548946380615
step: 350, loss: 0.045464444905519485
step: 360, loss: 0.029349351301789284
step: 370, loss: 0.03881639614701271
step: 380, loss: 0.07494369894266129
step: 390, loss: 0.06499864161014557
step: 400, loss: 0.05829547718167305
step: 410, loss: 0.022242171689867973
step: 420, loss: 0.009008819237351418
step: 430, loss: 0.12162304669618607
step: 440, loss: 0.030856292694807053
step: 450, loss: 0.0014777424512431026
step: 460, loss: 0.009579673409461975
step: 470, loss: 0.0493137463927269
step: 480, loss: 0.0388505645096302
step: 490, loss: 0.03245911747217178
step: 500, loss: 0.04250222072005272
step: 510, loss: 0.0842117890715599
step: 520, loss: 0.06544963270425797
step: 530, loss: 0.2863209545612335
step: 540, loss: 0.03666473925113678
step: 550, loss: 0.07312903553247452
step: 560, loss: 0.07980217784643173
step: 570, loss: 0.0012013086816295981
step: 580, loss: 0.04541338235139847
step: 590, loss: 0.0864141434431076
step: 600, loss: 0.005623868200927973
step: 610, loss: 0.04902484267950058
step: 620, loss: 0.05690661072731018
step: 630, loss: 0.0005940782139077783
step: 640, loss: 0.16064144670963287
step: 650, loss: 0.00394838210195303
step: 660, loss: 0.06795234978199005
step: 670, loss: 0.08350659161806107
step: 680, loss: 0.03442767262458801
step: 690, loss: 0.002332949312403798
step: 700, loss: 0.09465815871953964
step: 710, loss: 0.02049298584461212
step: 720, loss: 0.05323851853609085
step: 730, loss: 0.06038166210055351
step: 740, loss: 0.025036107748746872
step: 750, loss: 0.03759291395545006
step: 760, loss: 0.00537885632365942
step: 770, loss: 0.0007466939277946949
step: 780, loss: 0.11945593357086182
step: 790, loss: 0.009681068360805511
step: 800, loss: 0.1612989902496338
step: 810, loss: 0.023088285699486732
step: 820, loss: 0.02186441235244274
step: 830, loss: 0.018513422459363937
step: 840, loss: 0.1800018548965454
step: 850, loss: 0.025640819221735
step: 860, loss: 0.03448692336678505
step: 870, loss: 0.04928285628557205
step: 880, loss: 0.07289842516183853
step: 890, loss: 0.017187025398015976
step: 900, loss: 0.013276235200464725
step: 910, loss: 0.07900775223970413
step: 920, loss: 0.003997278865426779
step: 930, loss: 0.01250175479799509
step: 940, loss: 0.04963676631450653
step: 950, loss: 0.06028221175074577
step: 960, loss: 0.01025407761335373
step: 970, loss: 0.013426238670945168
step: 980, loss: 0.09096194803714752
step: 990, loss: 0.1163480281829834
step: 1000, loss: 0.052638690918684006
step: 1010, loss: 0.03473597764968872
step: 1020, loss: 0.0491538867354393
step: 1030, loss: 0.024666612967848778
step: 1040, loss: 0.10739324986934662
step: 1050, loss: 0.039050254970788956
step: 1060, loss: 0.052380576729774475
step: 1070, loss: 0.055384982377290726
epoch 10: dev_f1=0.9212562585343651, f1=0.9226569608735214, best_f1=0.9347014925373135
step: 0, loss: 0.08895998448133469
step: 10, loss: 0.0008238236769102514
step: 20, loss: 0.05208473652601242
step: 30, loss: 0.021784810349345207
step: 40, loss: 0.08239244669675827
step: 50, loss: 0.0434001088142395
step: 60, loss: 0.06729959696531296
step: 70, loss: 0.044745948165655136
step: 80, loss: 0.028828507289290428
step: 90, loss: 0.0010603585978969932
step: 100, loss: 0.004724966362118721
step: 110, loss: 0.002128789434209466
step: 120, loss: 0.1003379225730896
step: 130, loss: 0.0643884688615799
step: 140, loss: 0.03794633969664574
step: 150, loss: 0.04568978771567345
step: 160, loss: 0.08970475941896439
step: 170, loss: 0.04375040531158447
step: 180, loss: 0.040882330387830734
step: 190, loss: 0.027558961883187294
step: 200, loss: 0.14456307888031006
step: 210, loss: 0.03289685398340225
step: 220, loss: 0.09565110504627228
step: 230, loss: 0.04053609073162079
step: 240, loss: 0.007936390116810799
step: 250, loss: 0.020885121077299118
step: 260, loss: 0.000495394691824913
step: 270, loss: 0.004898866638541222
step: 280, loss: 0.006037137471139431
step: 290, loss: 0.008181334473192692
step: 300, loss: 0.012794223614037037
step: 310, loss: 0.008285457268357277
step: 320, loss: 0.018059540539979935
step: 330, loss: 0.07343132793903351
step: 340, loss: 0.0656043291091919
step: 350, loss: 0.05893562361598015
step: 360, loss: 0.03681696951389313
step: 370, loss: 0.018380893394351006
step: 380, loss: 0.0376296304166317
step: 390, loss: 0.0006987051456235349
step: 400, loss: 0.034647662192583084
step: 410, loss: 0.02575969509780407
step: 420, loss: 0.04349767044186592
step: 430, loss: 0.03955862671136856
step: 440, loss: 0.10542979091405869
step: 450, loss: 0.006554453633725643
step: 460, loss: 0.053512923419475555
step: 470, loss: 0.03434978052973747
step: 480, loss: 4.923234155285172e-05
step: 490, loss: 0.01770753785967827
step: 500, loss: 0.022500647231936455
step: 510, loss: 0.027253862470388412
step: 520, loss: 0.05709128826856613
step: 530, loss: 0.038210999220609665
step: 540, loss: 0.0848507285118103
step: 550, loss: 0.0961470678448677
step: 560, loss: 0.1273021250963211
step: 570, loss: 0.04598996788263321
step: 580, loss: 0.0032528024166822433
step: 590, loss: 0.06020331755280495
step: 600, loss: 0.1111515611410141
step: 610, loss: 0.03973298519849777
step: 620, loss: 0.02450571209192276
step: 630, loss: 0.059249646961688995
step: 640, loss: 0.031812336295843124
step: 650, loss: 0.02557413838803768
step: 660, loss: 0.037240978330373764
step: 670, loss: 0.005741068162024021
step: 680, loss: 0.010330183431506157
step: 690, loss: 4.836156949750148e-05
step: 700, loss: 0.02567996084690094
step: 710, loss: 0.028197593986988068
step: 720, loss: 0.0365532785654068
step: 730, loss: 0.03369466960430145
step: 740, loss: 0.01634400524199009
step: 750, loss: 0.08750093728303909
step: 760, loss: 0.07496971637010574
step: 770, loss: 0.04491633549332619
step: 780, loss: 0.05229857936501503
step: 790, loss: 0.023879582062363625
step: 800, loss: 0.008823208510875702
step: 810, loss: 0.026733819395303726
step: 820, loss: 0.009834442287683487
step: 830, loss: 0.10128521174192429
step: 840, loss: 0.041489120572805405
step: 850, loss: 0.03739030286669731
step: 860, loss: 0.013484764844179153
step: 870, loss: 0.03864995762705803
step: 880, loss: 0.00029893152532167733
step: 890, loss: 0.09799415618181229
step: 900, loss: 0.1245189979672432
step: 910, loss: 0.03245043754577637
step: 920, loss: 0.0740935429930687
step: 930, loss: 0.03134872764348984
step: 940, loss: 0.05692339688539505
step: 950, loss: 0.010457419790327549
step: 960, loss: 0.06269238889217377
step: 970, loss: 0.05054130032658577
step: 980, loss: 0.07913435250520706
step: 990, loss: 0.04764298349618912
step: 1000, loss: 0.061114754527807236
step: 1010, loss: 0.002394505776464939
step: 1020, loss: 0.0189434252679348
step: 1030, loss: 0.12315424531698227
step: 1040, loss: 0.08185675740242004
step: 1050, loss: 0.02856922708451748
step: 1060, loss: 0.04356686398386955
step: 1070, loss: 0.10084373503923416
epoch 11: dev_f1=0.9346826126954921, f1=0.931985294117647, best_f1=0.9347014925373135
step: 0, loss: 0.018254639580845833
step: 10, loss: 0.011838902719318867
step: 20, loss: 0.00012701720697805285
step: 30, loss: 0.010154335759580135
step: 40, loss: 0.054411597549915314
step: 50, loss: 0.0007175161154009402
step: 60, loss: 0.04381261765956879
step: 70, loss: 0.0011625621700659394
step: 80, loss: 0.04769967496395111
step: 90, loss: 0.0010004445211961865
step: 100, loss: 0.003621998941525817
step: 110, loss: 0.002850905293598771
step: 120, loss: 0.10662151873111725
step: 130, loss: 0.10678830742835999
step: 140, loss: 0.04592287540435791
step: 150, loss: 0.03252415359020233
step: 160, loss: 0.03142601624131203
step: 170, loss: 0.00028852533432655036
step: 180, loss: 0.0642918199300766
step: 190, loss: 0.019858811050653458
step: 200, loss: 0.024169938638806343
step: 210, loss: 0.006390207912772894
step: 220, loss: 0.00903309229761362
step: 230, loss: 0.003114336868748069
step: 240, loss: 0.0017554988153278828
step: 250, loss: 0.0337279811501503
step: 260, loss: 0.0340697318315506
step: 270, loss: 0.008863965980708599
step: 280, loss: 0.00013139890506863594
step: 290, loss: 0.022202160209417343
step: 300, loss: 0.032262060791254044
step: 310, loss: 0.07952438294887543
step: 320, loss: 0.07577905803918839
step: 330, loss: 0.04320308193564415
step: 340, loss: 0.08049512654542923
step: 350, loss: 0.011219064705073833
step: 360, loss: 0.0766923651099205
step: 370, loss: 0.001380591420456767
step: 380, loss: 0.020204948261380196
step: 390, loss: 0.03836923465132713
step: 400, loss: 0.042691685259342194
step: 410, loss: 0.054974570870399475
step: 420, loss: 0.0005025186692364514
step: 430, loss: 0.0790148600935936
step: 440, loss: 0.04963674023747444
step: 450, loss: 0.09851030260324478
step: 460, loss: 0.06991130858659744
step: 470, loss: 0.05184945464134216
step: 480, loss: 0.041531987488269806
step: 490, loss: 0.14833186566829681
step: 500, loss: 0.025745825842022896
step: 510, loss: 0.0476478673517704
step: 520, loss: 0.024340493604540825
step: 530, loss: 0.004372445400804281
step: 540, loss: 0.07947296649217606
step: 550, loss: 0.04532542824745178
step: 560, loss: 0.010761350393295288
step: 570, loss: 0.05535312369465828
step: 580, loss: 0.0027681749779731035
step: 590, loss: 0.02490251511335373
step: 600, loss: 0.05244240537285805
step: 610, loss: 0.10377874970436096
step: 620, loss: 0.05079140514135361
step: 630, loss: 0.006835995241999626
step: 640, loss: 0.07123157382011414
step: 650, loss: 0.03683869540691376
step: 660, loss: 0.0002646119683049619
step: 670, loss: 0.18387871980667114
step: 680, loss: 0.042163215577602386
step: 690, loss: 0.05483188107609749
step: 700, loss: 0.05016617849469185
step: 710, loss: 0.061747193336486816
step: 720, loss: 0.03918378800153732
step: 730, loss: 0.03194565698504448
step: 740, loss: 0.06656806170940399
step: 750, loss: 0.07911207526922226
step: 760, loss: 0.08042734861373901
step: 770, loss: 0.05861308425664902
step: 780, loss: 0.005736534483730793
step: 790, loss: 0.04428233951330185
step: 800, loss: 0.002028906252235174
step: 810, loss: 0.03496889770030975
step: 820, loss: 0.03318339213728905
step: 830, loss: 0.05810406059026718
step: 840, loss: 0.05231492221355438
step: 850, loss: 0.024989837780594826
step: 860, loss: 0.0401013009250164
step: 870, loss: 0.03362063691020012
step: 880, loss: 0.06879746913909912
step: 890, loss: 0.004430537112057209
step: 900, loss: 0.038372818380594254
step: 910, loss: 0.05787878483533859
step: 920, loss: 0.052301663905382156
step: 930, loss: 0.018557095900177956
step: 940, loss: 0.053261421620845795
step: 950, loss: 0.08102233707904816
step: 960, loss: 0.06293666362762451
step: 970, loss: 0.00022963399533182383
step: 980, loss: 0.0018725121626630425
step: 990, loss: 0.03317561373114586
step: 1000, loss: 0.012708665803074837
step: 1010, loss: 0.04231105372309685
step: 1020, loss: 0.01156020537018776
step: 1030, loss: 0.02759452536702156
step: 1040, loss: 0.009050287306308746
step: 1050, loss: 0.00013742131704930216
step: 1060, loss: 0.11694151908159256
step: 1070, loss: 0.005119006615132093
epoch 12: dev_f1=0.9270544783010157, f1=0.9274156264447527, best_f1=0.9347014925373135
step: 0, loss: 0.016524704173207283
step: 10, loss: 0.04560040682554245
step: 20, loss: 0.0033131209202110767
step: 30, loss: 0.07002060115337372
step: 40, loss: 0.043337225914001465
step: 50, loss: 0.0014274601126089692
step: 60, loss: 0.022515708580613136
step: 70, loss: 0.08624833822250366
step: 80, loss: 0.0003448580682743341
step: 90, loss: 0.012033936567604542
step: 100, loss: 0.04267927631735802
step: 110, loss: 0.038333941251039505
step: 120, loss: 0.0012016062391921878
step: 130, loss: 0.004729852546006441
step: 140, loss: 0.0004507428966462612
step: 150, loss: 0.011059822514653206
step: 160, loss: 0.0012825060402974486
step: 170, loss: 0.04004942625761032
step: 180, loss: 0.021734142675995827
step: 190, loss: 0.04536856338381767
step: 200, loss: 0.1922275424003601
step: 210, loss: 0.06180089712142944
step: 220, loss: 0.008014531806111336
step: 230, loss: 0.018608471378684044
step: 240, loss: 0.02813153713941574
step: 250, loss: 0.03754046559333801
step: 260, loss: 0.0610746294260025
step: 270, loss: 0.006988597568124533
step: 280, loss: 0.016876403242349625
step: 290, loss: 0.000634772062767297
step: 300, loss: 0.07545702904462814
step: 310, loss: 0.09630756080150604
step: 320, loss: 8.871823956724256e-05
step: 330, loss: 0.06521045416593552
step: 340, loss: 0.027067674323916435
step: 350, loss: 0.002873260760679841
step: 360, loss: 0.0931120291352272
step: 370, loss: 0.007688269484788179
step: 380, loss: 0.054546553641557693
step: 390, loss: 0.025480931624770164
step: 400, loss: 0.022046001628041267
step: 410, loss: 0.01783650368452072
step: 420, loss: 0.021174777299165726
step: 430, loss: 0.025379003956913948
step: 440, loss: 0.04690564051270485
step: 450, loss: 0.0530325211584568
step: 460, loss: 0.04435064643621445
step: 470, loss: 8.901350520318374e-05
step: 480, loss: 0.1156325414776802
step: 490, loss: 0.05493921414017677
step: 500, loss: 0.02775213122367859
step: 510, loss: 0.02259228192269802
step: 520, loss: 0.03635062649846077
step: 530, loss: 0.011356549337506294
step: 540, loss: 0.07894127815961838
step: 550, loss: 0.03917218744754791
step: 560, loss: 0.016071882098913193
step: 570, loss: 0.013106872327625751
step: 580, loss: 4.726188853965141e-05
step: 590, loss: 0.03247581422328949
step: 600, loss: 0.014178968966007233
step: 610, loss: 0.0017327936366200447
step: 620, loss: 0.15845884382724762
step: 630, loss: 0.03167682886123657
step: 640, loss: 0.052110135555267334
step: 650, loss: 0.0020865718834102154
step: 660, loss: 0.06506961584091187
step: 670, loss: 0.00684285257011652
step: 680, loss: 0.05027356371283531
step: 690, loss: 0.13238933682441711
step: 700, loss: 0.02506685070693493
step: 710, loss: 0.033084530383348465
step: 720, loss: 0.05901777744293213
step: 730, loss: 0.1248103454709053
step: 740, loss: 0.013505297712981701
step: 750, loss: 6.0569178458536044e-05
step: 760, loss: 0.054275333881378174
step: 770, loss: 0.05766621604561806
step: 780, loss: 0.009772027842700481
step: 790, loss: 0.04387674108147621
step: 800, loss: 0.12795153260231018
step: 810, loss: 0.1398819386959076
step: 820, loss: 0.01664535515010357
step: 830, loss: 3.921400275430642e-05
step: 840, loss: 0.00011983862350462005
step: 850, loss: 0.1175965741276741
step: 860, loss: 0.13156262040138245
step: 870, loss: 0.12955419719219208
step: 880, loss: 0.04440334811806679
step: 890, loss: 0.09345532953739166
step: 900, loss: 0.028398899361491203
step: 910, loss: 0.0007898131152614951
step: 920, loss: 0.06227971613407135
step: 930, loss: 0.0017863126704469323
step: 940, loss: 0.03586047142744064
step: 950, loss: 0.030678564682602882
step: 960, loss: 0.004174674395471811
step: 970, loss: 0.003576982067897916
step: 980, loss: 0.018671268597245216
step: 990, loss: 0.027562212198972702
step: 1000, loss: 0.03458786383271217
step: 1010, loss: 0.038228437304496765
step: 1020, loss: 0.00028643387486226857
step: 1030, loss: 0.08147372305393219
step: 1040, loss: 0.026764005422592163
step: 1050, loss: 0.0010215133661404252
step: 1060, loss: 0.04857490211725235
step: 1070, loss: 0.051030270755290985
epoch 13: dev_f1=0.9261363636363635, f1=0.9268060836501901, best_f1=0.9347014925373135
step: 0, loss: 1.794076342775952e-05
step: 10, loss: 0.0008174232207238674
step: 20, loss: 0.0625341609120369
step: 30, loss: 0.028740394860506058
step: 40, loss: 0.01477760262787342
step: 50, loss: 0.01612713560461998
step: 60, loss: 5.1819239160977304e-05
step: 70, loss: 0.17862007021903992
step: 80, loss: 0.021420616656541824
step: 90, loss: 0.06153982877731323
step: 100, loss: 0.05610598623752594
step: 110, loss: 0.057706981897354126
step: 120, loss: 0.046121206134557724
step: 130, loss: 0.06647653877735138
step: 140, loss: 0.1043442115187645
step: 150, loss: 0.014642215333878994
step: 160, loss: 0.027499493211507797
step: 170, loss: 0.0017393783200532198
step: 180, loss: 0.009312255308032036
step: 190, loss: 0.05272695794701576
step: 200, loss: 0.04588859900832176
step: 210, loss: 0.014015796594321728
step: 220, loss: 0.04529305174946785
step: 230, loss: 0.04324407875537872
step: 240, loss: 0.06807656586170197
step: 250, loss: 0.001140260137617588
step: 260, loss: 0.09059275686740875
step: 270, loss: 0.012333172373473644
step: 280, loss: 2.3259810404852033e-05
step: 290, loss: 0.026036912575364113
step: 300, loss: 0.0001002347853500396
step: 310, loss: 0.009749626740813255
step: 320, loss: 0.04381726682186127
step: 330, loss: 0.03767722472548485
step: 340, loss: 0.00454245088621974
step: 350, loss: 0.021022407338023186
step: 360, loss: 0.05165598914027214
step: 370, loss: 0.0006494502886198461
step: 380, loss: 0.008480962365865707
step: 390, loss: 0.00920573715120554
step: 400, loss: 0.022564103826880455
step: 410, loss: 3.30817601934541e-05
step: 420, loss: 0.0349620021879673
step: 430, loss: 0.05777018144726753
step: 440, loss: 0.000688341271597892
step: 450, loss: 0.008551049046218395
step: 460, loss: 0.009504440240561962
step: 470, loss: 0.09604696929454803
step: 480, loss: 0.007179163862019777
step: 490, loss: 0.04083937779068947
step: 500, loss: 0.0021836424712091684
step: 510, loss: 0.002799485344439745
step: 520, loss: 0.038428910076618195
step: 530, loss: 0.028613761067390442
step: 540, loss: 0.0005053486092947423
step: 550, loss: 0.07419290393590927
step: 560, loss: 0.047798577696084976
step: 570, loss: 0.021159620955586433
step: 580, loss: 0.06529316306114197
step: 590, loss: 0.04113156348466873
step: 600, loss: 0.007505549117922783
step: 610, loss: 0.030913159251213074
step: 620, loss: 0.004830030724406242
step: 630, loss: 0.0610925629734993
step: 640, loss: 0.0473581999540329
step: 650, loss: 0.0020519127137959003
step: 660, loss: 0.04093918576836586
step: 670, loss: 0.008279189467430115
step: 680, loss: 0.00016620074165984988
step: 690, loss: 0.016892511397600174
step: 700, loss: 0.01842385157942772
step: 710, loss: 0.03310847282409668
step: 720, loss: 0.0004564306582324207
step: 730, loss: 0.03893434628844261
step: 740, loss: 0.05642811581492424
step: 750, loss: 0.027188852429389954
step: 760, loss: 0.0034138686023652554
step: 770, loss: 0.004187626764178276
step: 780, loss: 0.04235254228115082
step: 790, loss: 0.02050226926803589
step: 800, loss: 0.07977984845638275
step: 810, loss: 0.034799229353666306
step: 820, loss: 0.06433690339326859
step: 830, loss: 0.02196309342980385
step: 840, loss: 0.08403300493955612
step: 850, loss: 1.4446549357671756e-05
step: 860, loss: 0.04281776770949364
step: 870, loss: 0.05044851079583168
step: 880, loss: 0.0035241772420704365
step: 890, loss: 2.0827505068155006e-05
step: 900, loss: 0.047337524592876434
step: 910, loss: 4.5092056097928435e-05
step: 920, loss: 0.02265520580112934
step: 930, loss: 0.047547806054353714
step: 940, loss: 0.03435838222503662
step: 950, loss: 0.019735565409064293
step: 960, loss: 0.041747234761714935
step: 970, loss: 0.040832310914993286
step: 980, loss: 0.030134305357933044
step: 990, loss: 0.035603806376457214
step: 1000, loss: 0.03546014055609703
step: 1010, loss: 0.03715970367193222
step: 1020, loss: 0.07260798662900925
step: 1030, loss: 0.045970771461725235
step: 1040, loss: 0.13499514758586884
step: 1050, loss: 0.05192452296614647
step: 1060, loss: 0.05757955089211464
step: 1070, loss: 0.049603160470724106
epoch 14: dev_f1=0.9349930843706776, f1=0.9311778290993071, best_f1=0.9347014925373135
step: 0, loss: 0.08246662467718124
step: 10, loss: 0.07924854755401611
step: 20, loss: 0.0007195547223091125
step: 30, loss: 0.0009795663645491004
step: 40, loss: 0.011044910177588463
step: 50, loss: 0.04542858153581619
step: 60, loss: 0.01757822185754776
step: 70, loss: 0.00020178490376565605
step: 80, loss: 0.10089776664972305
step: 90, loss: 0.030033210292458534
step: 100, loss: 0.0015373274218291044
step: 110, loss: 0.044167812913656235
step: 120, loss: 0.045213744044303894
step: 130, loss: 0.004413238726556301
step: 140, loss: 0.017797963693737984
step: 150, loss: 0.00018520100275054574
step: 160, loss: 0.0001386860094498843
step: 170, loss: 2.522939939808566e-05
step: 180, loss: 0.00011877757060574368
step: 190, loss: 0.00992928072810173
step: 200, loss: 0.02906651608645916
step: 210, loss: 0.02725267969071865
step: 220, loss: 0.048693880438804626
step: 230, loss: 0.04728826880455017
step: 240, loss: 0.015270390547811985
step: 250, loss: 0.0315680205821991
step: 260, loss: 0.012644925154745579
step: 270, loss: 0.039615970104932785
step: 280, loss: 0.06719191372394562
step: 290, loss: 0.03711031749844551
step: 300, loss: 0.0006122636841610074
step: 310, loss: 0.018665604293346405
step: 320, loss: 0.04021391272544861
step: 330, loss: 0.048373881727457047
step: 340, loss: 0.04032617434859276
step: 350, loss: 0.07379747182130814
step: 360, loss: 0.04335002228617668
step: 370, loss: 4.56846428278368e-05
step: 380, loss: 8.319626067532226e-05
step: 390, loss: 0.11233332008123398
step: 400, loss: 0.017508329823613167
step: 410, loss: 0.022909363731741905
step: 420, loss: 0.04774786904454231
step: 430, loss: 0.0251899566501379
step: 440, loss: 0.008654728531837463
step: 450, loss: 0.0146991778165102
step: 460, loss: 0.0003802850842475891
step: 470, loss: 0.07224922627210617
step: 480, loss: 0.07357572764158249
step: 490, loss: 0.02788066491484642
step: 500, loss: 0.026683751493692398
step: 510, loss: 0.02044391818344593
step: 520, loss: 0.021124986931681633
step: 530, loss: 0.004391395952552557
step: 540, loss: 0.045834556221961975
step: 550, loss: 0.05154283717274666
step: 560, loss: 0.04856766015291214
step: 570, loss: 0.025371424853801727
step: 580, loss: 0.1347081959247589
step: 590, loss: 0.019320759922266006
step: 600, loss: 0.023091884329915047
step: 610, loss: 0.001162251690402627
step: 620, loss: 0.023037295788526535
step: 630, loss: 0.03335068002343178
step: 640, loss: 0.023113224655389786
step: 650, loss: 0.05637964606285095
step: 660, loss: 0.0004985157283954322
step: 670, loss: 0.0016489489935338497
step: 680, loss: 0.007474242709577084
step: 690, loss: 0.021844547241926193
step: 700, loss: 0.014265909790992737
step: 710, loss: 0.00020459783263504505
step: 720, loss: 1.6979627616819926e-05
step: 730, loss: 0.05811610072851181
step: 740, loss: 0.021562974900007248
step: 750, loss: 0.028416061773896217
step: 760, loss: 0.0638701394200325
step: 770, loss: 0.029735757037997246
step: 780, loss: 0.04608675092458725
step: 790, loss: 3.0578128644265234e-05
step: 800, loss: 0.058109983801841736
step: 810, loss: 0.045376427471637726
step: 820, loss: 0.10949219763278961
step: 830, loss: 0.023004841059446335
step: 840, loss: 0.0585494339466095
step: 850, loss: 0.009411800652742386
step: 860, loss: 0.022622665390372276
step: 870, loss: 0.06483608484268188
step: 880, loss: 0.08608049899339676
step: 890, loss: 0.12087021768093109
step: 900, loss: 0.044518813490867615
step: 910, loss: 0.00011229504889342934
step: 920, loss: 0.0018995312275364995
step: 930, loss: 0.05881854146718979
step: 940, loss: 0.06331478804349899
step: 950, loss: 0.04517044872045517
step: 960, loss: 0.05795901268720627
step: 970, loss: 0.00024088204372674227
step: 980, loss: 0.05513990670442581
step: 990, loss: 0.003112836740911007
step: 1000, loss: 0.05082913488149643
step: 1010, loss: 0.00721136387437582
step: 1020, loss: 0.05551893636584282
step: 1030, loss: 0.055354125797748566
step: 1040, loss: 0.07314178347587585
step: 1050, loss: 0.035359952598810196
step: 1060, loss: 0.06526100635528564
step: 1070, loss: 0.0013889389811083674
epoch 15: dev_f1=0.9261363636363635, f1=0.9220595181861123, best_f1=0.9347014925373135
step: 0, loss: 0.01455256063491106
step: 10, loss: 5.652334220940247e-05
step: 20, loss: 0.04883277043700218
step: 30, loss: 0.018099233508110046
step: 40, loss: 0.03361022099852562
step: 50, loss: 0.019897518679499626
step: 60, loss: 0.012586787343025208
step: 70, loss: 0.027459722012281418
step: 80, loss: 0.02129562571644783
step: 90, loss: 0.03719868138432503
step: 100, loss: 0.07055988907814026
step: 110, loss: 0.008919204585254192
step: 120, loss: 0.016461245715618134
step: 130, loss: 3.403977825655602e-05
step: 140, loss: 0.015444206073880196
step: 150, loss: 0.00026392354629933834
step: 160, loss: 0.10331638902425766
step: 170, loss: 0.027666617184877396
step: 180, loss: 0.01841454952955246
step: 190, loss: 0.04941657930612564
step: 200, loss: 0.00043770368210971355
step: 210, loss: 4.088340938324109e-05
step: 220, loss: 0.02662215195596218
step: 230, loss: 0.025533510372042656
step: 240, loss: 0.03168907016515732
step: 250, loss: 0.2028653919696808
step: 260, loss: 0.04115615785121918
step: 270, loss: 0.05798280984163284
step: 280, loss: 0.020851530134677887
step: 290, loss: 0.08533357828855515
step: 300, loss: 0.05172417685389519
step: 310, loss: 0.03406636416912079
step: 320, loss: 0.00018777596415020525
step: 330, loss: 0.017336759716272354
step: 340, loss: 0.069401316344738
step: 350, loss: 0.052605342119932175
step: 360, loss: 0.00010042724170489237
step: 370, loss: 0.029765630140900612
step: 380, loss: 0.0322454459965229
step: 390, loss: 0.04846850037574768
step: 400, loss: 0.02183411829173565
step: 410, loss: 0.02703382819890976
step: 420, loss: 0.0063200476579368114
step: 430, loss: 0.07287253439426422
step: 440, loss: 0.0026186525356024504
step: 450, loss: 0.018048720434308052
step: 460, loss: 0.006775037385523319
step: 470, loss: 0.0021708677522838116
step: 480, loss: 0.0783793106675148
step: 490, loss: 0.002789611928164959
step: 500, loss: 0.032928116619586945
step: 510, loss: 0.0008440176607109606
step: 520, loss: 0.0637134313583374
step: 530, loss: 0.0003690567973535508
step: 540, loss: 0.0076967221684753895
step: 550, loss: 0.02159634418785572
step: 560, loss: 0.03781360387802124
step: 570, loss: 0.00020723759371321648
step: 580, loss: 0.03115699253976345
step: 590, loss: 0.04357362166047096
step: 600, loss: 0.0010317345149815083
step: 610, loss: 0.011436225846409798
step: 620, loss: 0.039378874003887177
step: 630, loss: 0.02212531678378582
step: 640, loss: 0.06163739413022995
step: 650, loss: 0.01863611862063408
step: 660, loss: 0.020284412428736687
step: 670, loss: 0.016059627756476402
step: 680, loss: 0.09118924289941788
step: 690, loss: 0.061272986233234406
step: 700, loss: 0.024291852489113808
step: 710, loss: 0.01827952079474926
step: 720, loss: 0.057433079928159714
step: 730, loss: 0.0002985757018905133
step: 740, loss: 0.05502447485923767
step: 750, loss: 0.02226107381284237
step: 760, loss: 0.003214465454220772
step: 770, loss: 0.030999265611171722
step: 780, loss: 0.0306260846555233
step: 790, loss: 0.026162458583712578
step: 800, loss: 0.04077809303998947
step: 810, loss: 0.05073381960391998
step: 820, loss: 0.0005649583763442934
step: 830, loss: 0.016934823244810104
step: 840, loss: 0.020256415009498596
step: 850, loss: 0.040737640112638474
step: 860, loss: 0.029368087649345398
step: 870, loss: 0.043015554547309875
step: 880, loss: 0.030550247058272362
step: 890, loss: 0.027275249361991882
step: 900, loss: 0.04656250402331352
step: 910, loss: 0.0018479747232049704
step: 920, loss: 0.00015392753994092345
step: 930, loss: 7.883293437771499e-05
step: 940, loss: 0.024738140404224396
step: 950, loss: 0.00611895089969039
step: 960, loss: 0.0676724910736084
step: 970, loss: 0.07561717927455902
step: 980, loss: 0.01882648468017578
step: 990, loss: 0.01809215173125267
step: 1000, loss: 0.004251077305525541
step: 1010, loss: 0.005243287421762943
step: 1020, loss: 0.01910974271595478
step: 1030, loss: 0.016811667010188103
step: 1040, loss: 1.8730066585703753e-05
step: 1050, loss: 0.021398209035396576
step: 1060, loss: 0.014711463823914528
step: 1070, loss: 0.00035483582178130746
epoch 16: dev_f1=0.9283372365339578, f1=0.9275766016713091, best_f1=0.9347014925373135
step: 0, loss: 0.055809009820222855
step: 10, loss: 7.054851448629051e-05
step: 20, loss: 0.029908180236816406
step: 30, loss: 0.046616122126579285
step: 40, loss: 0.00011100299161626026
step: 50, loss: 0.00015211680147331208
step: 60, loss: 0.026335619390010834
step: 70, loss: 0.00019554259779397398
step: 80, loss: 8.202783646993339e-05
step: 90, loss: 0.019312769174575806
step: 100, loss: 0.0076224422082304955
step: 110, loss: 0.02415604516863823
step: 120, loss: 0.06398578733205795
step: 130, loss: 0.008069684728980064
step: 140, loss: 4.80519411212299e-05
step: 150, loss: 0.00013334646064322442
step: 160, loss: 0.07533769309520721
step: 170, loss: 0.003174966899678111
step: 180, loss: 0.0293692909181118
step: 190, loss: 0.03968977555632591
step: 200, loss: 0.016612861305475235
step: 210, loss: 0.00010623674461385235
step: 220, loss: 0.12572279572486877
step: 230, loss: 0.00011331650603096932
step: 240, loss: 0.028769709169864655
step: 250, loss: 0.0385449081659317
step: 260, loss: 0.057438258081674576
step: 270, loss: 0.021237647160887718
step: 280, loss: 9.114896965911612e-05
step: 290, loss: 0.02108384110033512
step: 300, loss: 0.0005400195368565619
step: 310, loss: 0.00010666450543794781
step: 320, loss: 0.0007579872035421431
step: 330, loss: 2.5073390133911744e-05
step: 340, loss: 0.0021895889658480883
step: 350, loss: 0.018404880538582802
step: 360, loss: 0.03383953869342804
step: 370, loss: 0.022320447489619255
step: 380, loss: 0.03203720971941948
step: 390, loss: 0.07026638835668564
step: 400, loss: 0.03204205632209778
step: 410, loss: 0.03259866312146187
step: 420, loss: 0.04495682567358017
step: 430, loss: 1.506863918621093e-05
step: 440, loss: 0.001778812613338232
step: 450, loss: 0.04574507474899292
step: 460, loss: 0.00017503161507193
step: 470, loss: 0.03783522918820381
step: 480, loss: 4.6175086026778445e-05
step: 490, loss: 0.0001474083255743608
step: 500, loss: 0.019503721967339516
step: 510, loss: 0.00013820345338899642
step: 520, loss: 0.045437924563884735
step: 530, loss: 0.04705802723765373
step: 540, loss: 0.023681914433836937
step: 550, loss: 0.025253282859921455
step: 560, loss: 0.032097168266773224
step: 570, loss: 0.041030317544937134
step: 580, loss: 0.002776461187750101
step: 590, loss: 0.0013030582340434194
step: 600, loss: 0.06581640988588333
step: 610, loss: 2.3989885448827408e-05
step: 620, loss: 0.0007446570671163499
step: 630, loss: 0.03690788149833679
step: 640, loss: 0.01869095303118229
step: 650, loss: 0.0008151349029503763
step: 660, loss: 0.03677291423082352
step: 670, loss: 0.02610962465405464
step: 680, loss: 0.06273572891950607
step: 690, loss: 0.01100450474768877
step: 700, loss: 0.02283603325486183
step: 710, loss: 0.07704149186611176
step: 720, loss: 0.0012055299011990428
step: 730, loss: 0.03869028016924858
step: 740, loss: 0.05961620435118675
step: 750, loss: 0.019181475043296814
step: 760, loss: 0.041561275720596313
step: 770, loss: 0.013697606511414051
step: 780, loss: 0.04186594486236572
step: 790, loss: 2.255942308693193e-05
step: 800, loss: 0.018164999783039093
step: 810, loss: 0.026904847472906113
step: 820, loss: 0.02960052900016308
step: 830, loss: 0.04536300152540207
step: 840, loss: 2.0473686163313687e-05
step: 850, loss: 0.039068929851055145
step: 860, loss: 2.1713382011512294e-05
step: 870, loss: 0.05280448868870735
step: 880, loss: 0.00018561935576144606
step: 890, loss: 0.018971305340528488
step: 900, loss: 0.01937338337302208
step: 910, loss: 0.029194237664341927
step: 920, loss: 0.0011246977373957634
step: 930, loss: 0.06095145642757416
step: 940, loss: 0.00033309636637568474
step: 950, loss: 0.027093470096588135
step: 960, loss: 0.01793103851377964
step: 970, loss: 0.0887027382850647
step: 980, loss: 0.018591398373246193
step: 990, loss: 0.033856309950351715
step: 1000, loss: 0.056623462587594986
step: 1010, loss: 0.004460223019123077
step: 1020, loss: 0.029313737526535988
step: 1030, loss: 0.07300744950771332
step: 1040, loss: 0.01983479969203472
step: 1050, loss: 0.04913688823580742
step: 1060, loss: 0.0001971258025150746
step: 1070, loss: 0.017489148303866386
epoch 17: dev_f1=0.9296435272045028, f1=0.9278350515463917, best_f1=0.9347014925373135
step: 0, loss: 0.019951272755861282
step: 10, loss: 0.013439718633890152
step: 20, loss: 0.022434722632169724
step: 30, loss: 0.023482516407966614
step: 40, loss: 0.027488205581903458
step: 50, loss: 1.1134826308989432e-05
step: 60, loss: 0.03533553332090378
step: 70, loss: 0.03873340040445328
step: 80, loss: 5.27656520716846e-05
step: 90, loss: 0.0577722042798996
step: 100, loss: 0.07398676872253418
step: 110, loss: 0.03435079753398895
step: 120, loss: 0.053741730749607086
step: 130, loss: 0.012787208892405033
step: 140, loss: 0.023773789405822754
step: 150, loss: 0.04000788554549217
step: 160, loss: 0.02192244492471218
step: 170, loss: 0.0485977977514267
step: 180, loss: 0.0376831479370594
step: 190, loss: 2.0019233488710597e-05
step: 200, loss: 0.00024351805041078478
step: 210, loss: 0.00018285390979144722
step: 220, loss: 0.021747441962361336
step: 230, loss: 0.06767188012599945
step: 240, loss: 0.025794735178351402
step: 250, loss: 0.025042105466127396
step: 260, loss: 0.047113701701164246
step: 270, loss: 0.027655385434627533
step: 280, loss: 0.048869285732507706
step: 290, loss: 0.01847786456346512
step: 300, loss: 0.000216516520595178
step: 310, loss: 1.2218843039590865e-05
step: 320, loss: 0.0462942011654377
step: 330, loss: 0.0005477046361193061
step: 340, loss: 0.021243033930659294
step: 350, loss: 6.156291055958718e-05
step: 360, loss: 0.025956422090530396
step: 370, loss: 0.043647751212120056
step: 380, loss: 0.021238647401332855
step: 390, loss: 0.07011588662862778
step: 400, loss: 0.05407777056097984
step: 410, loss: 0.02345360442996025
step: 420, loss: 0.041228458285331726
step: 430, loss: 0.06901315599679947
step: 440, loss: 2.609013972687535e-05
step: 450, loss: 0.04124770313501358
step: 460, loss: 0.04079248756170273
step: 470, loss: 0.020743360742926598
step: 480, loss: 4.6838176785968244e-05
step: 490, loss: 0.02141610160470009
step: 500, loss: 0.0432170070707798
step: 510, loss: 0.07004900276660919
step: 520, loss: 0.01671418361365795
step: 530, loss: 0.003226505359634757
step: 540, loss: 6.23271189397201e-05
step: 550, loss: 0.03322848305106163
step: 560, loss: 3.33608259097673e-05
step: 570, loss: 0.02253754623234272
step: 580, loss: 0.0375758521258831
step: 590, loss: 5.336034155334346e-05
step: 600, loss: 1.7948023014469072e-05
step: 610, loss: 0.00010789385851239786
step: 620, loss: 0.022958917543292046
step: 630, loss: 1.6193669580388814e-05
step: 640, loss: 0.019947007298469543
step: 650, loss: 0.06180182099342346
step: 660, loss: 0.00019589858129620552
step: 670, loss: 0.06466478109359741
step: 680, loss: 0.020253058522939682
step: 690, loss: 0.039372049272060394
step: 700, loss: 0.025404736399650574
step: 710, loss: 0.02046986296772957
step: 720, loss: 0.08917050808668137
step: 730, loss: 0.07998917251825333
step: 740, loss: 0.0011324954684823751
step: 750, loss: 0.06401994824409485
step: 760, loss: 0.03899751603603363
step: 770, loss: 0.023830922320485115
step: 780, loss: 0.06322722882032394
step: 790, loss: 0.0398666076362133
step: 800, loss: 0.04517802596092224
step: 810, loss: 0.016962606459856033
step: 820, loss: 0.00010048323019873351
step: 830, loss: 0.03914723917841911
step: 840, loss: 3.1834584660828114e-05
step: 850, loss: 0.010706931352615356
step: 860, loss: 0.05097828060388565
step: 870, loss: 0.0231629628688097
step: 880, loss: 0.009628755040466785
step: 890, loss: 0.0010869769612327218
step: 900, loss: 7.546430424554273e-05
step: 910, loss: 0.05761472508311272
step: 920, loss: 0.04001909866929054
step: 930, loss: 0.024280861020088196
step: 940, loss: 0.01793792098760605
step: 950, loss: 0.05862724408507347
step: 960, loss: 0.0769551694393158
step: 970, loss: 4.952939707436599e-05
step: 980, loss: 0.024620849639177322
step: 990, loss: 3.4700435207923874e-05
step: 1000, loss: 0.007266594097018242
step: 1010, loss: 0.07265147566795349
step: 1020, loss: 0.035971879959106445
step: 1030, loss: 0.03143836185336113
step: 1040, loss: 0.030535638332366943
step: 1050, loss: 0.06268221884965897
step: 1060, loss: 6.313939957180992e-05
step: 1070, loss: 0.04251395910978317
epoch 18: dev_f1=0.9297752808988764, f1=0.9231490159325211, best_f1=0.9347014925373135
step: 0, loss: 0.08698220551013947
step: 10, loss: 0.02260129526257515
step: 20, loss: 0.028048135340213776
step: 30, loss: 5.758165934821591e-05
step: 40, loss: 0.04671531915664673
step: 50, loss: 0.04678564518690109
step: 60, loss: 0.015034736134111881
step: 70, loss: 0.008694949559867382
step: 80, loss: 4.648456888389774e-05
step: 90, loss: 0.02961324341595173
step: 100, loss: 0.013939416036009789
step: 110, loss: 0.013950682245194912
step: 120, loss: 0.030925145372748375
step: 130, loss: 0.05529342219233513
step: 140, loss: 0.034246329218149185
step: 150, loss: 7.6609430834651e-05
step: 160, loss: 2.274086364195682e-05
step: 170, loss: 0.027506856247782707
step: 180, loss: 0.04271791875362396
step: 190, loss: 3.974870196543634e-05
step: 200, loss: 5.73262877878733e-05
step: 210, loss: 0.028182540088891983
step: 220, loss: 8.518106187693775e-05
step: 230, loss: 0.065084308385849
step: 240, loss: 0.023679044097661972
step: 250, loss: 0.05085297301411629
step: 260, loss: 0.018149452283978462
step: 270, loss: 0.031012699007987976
step: 280, loss: 0.058574095368385315
step: 290, loss: 4.066274414071813e-05
step: 300, loss: 0.0627884492278099
step: 310, loss: 0.02063455805182457
step: 320, loss: 0.0003995231818407774
step: 330, loss: 0.04645225405693054
step: 340, loss: 1.8204695152235217e-05
step: 350, loss: 0.021365592256188393
step: 360, loss: 0.024311773478984833
step: 370, loss: 0.0032457620836794376
step: 380, loss: 0.04941670224070549
step: 390, loss: 0.14486204087734222
step: 400, loss: 0.04570992663502693
step: 410, loss: 0.06997034698724747
step: 420, loss: 0.040681127458810806
step: 430, loss: 0.04942702129483223
step: 440, loss: 1.3924949598731473e-05
step: 450, loss: 0.08009172230958939
step: 460, loss: 0.0761309564113617
step: 470, loss: 1.8744693079497665e-05
step: 480, loss: 0.06975311785936356
step: 490, loss: 0.04217696562409401
step: 500, loss: 0.0002885016147047281
step: 510, loss: 0.054628171026706696
step: 520, loss: 0.032206084579229355
step: 530, loss: 0.022293871268630028
step: 540, loss: 0.01385202445089817
step: 550, loss: 0.024393025785684586
step: 560, loss: 0.0202481709420681
step: 570, loss: 0.021958820521831512
step: 580, loss: 0.022656839340925217
step: 590, loss: 0.019078336656093597
step: 600, loss: 0.035321611911058426
step: 610, loss: 0.02664991095662117
step: 620, loss: 0.024396134540438652
step: 630, loss: 0.058964625000953674
step: 640, loss: 0.04320767521858215
step: 650, loss: 0.051061972975730896
step: 660, loss: 0.06130095571279526
step: 670, loss: 0.010961109772324562
step: 680, loss: 0.02013247087597847
step: 690, loss: 0.002703521167859435
step: 700, loss: 0.03469117358326912
step: 710, loss: 0.0009462777525186539
step: 720, loss: 0.05274352431297302
step: 730, loss: 0.019307199865579605
step: 740, loss: 0.01776067726314068
step: 750, loss: 0.00023325937218032777
step: 760, loss: 0.02047950029373169
step: 770, loss: 0.04034852981567383
step: 780, loss: 0.04347937926650047
step: 790, loss: 8.377554331673309e-05
step: 800, loss: 5.797528865514323e-05
step: 810, loss: 0.06684765219688416
step: 820, loss: 0.019372813403606415
step: 830, loss: 0.0001684316957835108
step: 840, loss: 0.04748113825917244
step: 850, loss: 0.04235972464084625
step: 860, loss: 0.038984257727861404
step: 870, loss: 0.0001107930947910063
step: 880, loss: 0.014646023511886597
step: 890, loss: 0.06828183680772781
step: 900, loss: 0.02247454784810543
step: 910, loss: 0.04659790173172951
step: 920, loss: 0.07677215337753296
step: 930, loss: 0.010287359356880188
step: 940, loss: 0.18979081511497498
step: 950, loss: 2.7568816221901216e-05
step: 960, loss: 1.6920017515076324e-05
step: 970, loss: 0.021470380946993828
step: 980, loss: 4.029133924632333e-05
step: 990, loss: 0.0423453226685524
step: 1000, loss: 0.07387317717075348
step: 1010, loss: 0.02961471863090992
step: 1020, loss: 0.013418936170637608
step: 1030, loss: 0.00023158697877079248
step: 1040, loss: 0.04167785868048668
step: 1050, loss: 0.021794937551021576
step: 1060, loss: 0.03731226176023483
step: 1070, loss: 0.027102256193757057
epoch 19: dev_f1=0.9294062646096307, f1=0.9257356375525455, best_f1=0.9347014925373135
step: 0, loss: 0.03340050205588341
step: 10, loss: 0.057926446199417114
step: 20, loss: 3.54784497176297e-05
step: 30, loss: 0.026957741007208824
step: 40, loss: 0.02468097023665905
step: 50, loss: 0.015347953885793686
step: 60, loss: 0.050466831773519516
step: 70, loss: 3.6286524846218526e-05
step: 80, loss: 0.05251157656311989
step: 90, loss: 2.765479075605981e-05
step: 100, loss: 0.024345550686120987
step: 110, loss: 0.00015204261580947787
step: 120, loss: 2.2338441340252757e-05
step: 130, loss: 0.019031913951039314
step: 140, loss: 0.001009048311971128
step: 150, loss: 0.020098451524972916
step: 160, loss: 0.017095258459448814
step: 170, loss: 0.008242066018283367
step: 180, loss: 0.07699861377477646
step: 190, loss: 3.286857463535853e-05
step: 200, loss: 6.77059797453694e-05
step: 210, loss: 0.014479770325124264
step: 220, loss: 0.026934027671813965
step: 230, loss: 0.008913543075323105
step: 240, loss: 0.02501372992992401
step: 250, loss: 0.01870877854526043
step: 260, loss: 0.022838223725557327
step: 270, loss: 0.02285902388393879
step: 280, loss: 1.889008126454428e-05
step: 290, loss: 0.02019796334207058
step: 300, loss: 0.018369095399975777
step: 310, loss: 0.035849880427122116
step: 320, loss: 6.520900933537632e-05
step: 330, loss: 0.10396964102983475
step: 340, loss: 0.032309334725141525
step: 350, loss: 0.014864838682115078
step: 360, loss: 1.2725482520181686e-05
step: 370, loss: 0.01451926026493311
step: 380, loss: 0.06816475838422775
step: 390, loss: 0.04880746826529503
step: 400, loss: 2.7080275685875677e-05
step: 410, loss: 5.2736650104634464e-05
step: 420, loss: 0.013788755983114243
step: 430, loss: 0.023507125675678253
step: 440, loss: 4.1606457671150565e-05
step: 450, loss: 0.016477592289447784
step: 460, loss: 0.025996575132012367
step: 470, loss: 0.011042604222893715
step: 480, loss: 0.03438860550522804
step: 490, loss: 2.9561912015196867e-05
step: 500, loss: 0.05815562233328819
step: 510, loss: 0.04304298013448715
step: 520, loss: 0.04880702868103981
step: 530, loss: 0.011345569044351578
step: 540, loss: 1.1980439921899233e-05
step: 550, loss: 0.033839158713817596
step: 560, loss: 0.007982848212122917
step: 570, loss: 0.01642245054244995
step: 580, loss: 0.021920377388596535
step: 590, loss: 0.0011045790743082762
step: 600, loss: 0.06076306477189064
step: 610, loss: 0.04058052971959114
step: 620, loss: 0.0742311179637909
step: 630, loss: 0.0014614019310101867
step: 640, loss: 0.033920492976903915
step: 650, loss: 0.00922231562435627
step: 660, loss: 0.03762936592102051
step: 670, loss: 0.020096110180020332
step: 680, loss: 0.0002246373624075204
step: 690, loss: 0.02277340367436409
step: 700, loss: 0.07269246131181717
step: 710, loss: 0.04508839547634125
step: 720, loss: 0.033668920397758484
step: 730, loss: 0.020241446793079376
step: 740, loss: 1.5347872249549255e-05
step: 750, loss: 3.5830998967867345e-05
step: 760, loss: 1.3556131307268515e-05
step: 770, loss: 0.022974122315645218
step: 780, loss: 0.023091595619916916
step: 790, loss: 0.013307347893714905
step: 800, loss: 0.05994655564427376
step: 810, loss: 0.00011395847832318395
step: 820, loss: 2.1970847228658386e-05
step: 830, loss: 7.786789501551539e-05
step: 840, loss: 0.011010914109647274
step: 850, loss: 4.5523742301156744e-05
step: 860, loss: 0.041875727474689484
step: 870, loss: 0.020914800465106964
step: 880, loss: 0.05036628991365433
step: 890, loss: 0.04697827622294426
step: 900, loss: 0.0389140248298645
step: 910, loss: 0.0578291192650795
step: 920, loss: 0.0006991728441789746
step: 930, loss: 0.08449095487594604
step: 940, loss: 0.022780325263738632
step: 950, loss: 0.025500955060124397
step: 960, loss: 0.018162421882152557
step: 970, loss: 2.9639839340234175e-05
step: 980, loss: 0.04364354908466339
step: 990, loss: 0.041448067873716354
step: 1000, loss: 0.049910977482795715
step: 1010, loss: 1.4841351912764367e-05
step: 1020, loss: 0.04458532854914665
step: 1030, loss: 1.891251486085821e-05
step: 1040, loss: 0.031923096626996994
step: 1050, loss: 0.08484766632318497
step: 1060, loss: 0.022827502340078354
step: 1070, loss: 0.04121348634362221
epoch 20: dev_f1=0.9295380307979467, f1=0.9258049463369109, best_f1=0.9347014925373135
