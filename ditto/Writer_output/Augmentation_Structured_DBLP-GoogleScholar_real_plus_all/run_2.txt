cuda
Device: cuda
step: 0, loss: 0.7100862264633179
step: 10, loss: 0.459763765335083
step: 20, loss: 0.38960379362106323
step: 30, loss: 0.8367922306060791
step: 40, loss: 0.3359488248825073
step: 50, loss: 0.3773880898952484
step: 60, loss: 0.10127343982458115
step: 70, loss: 0.2928568720817566
step: 80, loss: 0.24381069839000702
step: 90, loss: 0.24327974021434784
step: 100, loss: 0.26907476782798767
step: 110, loss: 0.1336025893688202
step: 120, loss: 0.11386329680681229
step: 130, loss: 0.19780036807060242
step: 140, loss: 0.16068905591964722
step: 150, loss: 0.0714149922132492
step: 160, loss: 0.3121725916862488
step: 170, loss: 0.06322348117828369
step: 180, loss: 0.056672871112823486
step: 190, loss: 0.3867008686065674
step: 200, loss: 0.12593397498130798
step: 210, loss: 0.07278794795274734
step: 220, loss: 0.23125045001506805
step: 230, loss: 0.08068326115608215
step: 240, loss: 0.037647537887096405
step: 250, loss: 0.04336216673254967
step: 260, loss: 0.24819043278694153
step: 270, loss: 0.08067843317985535
step: 280, loss: 0.12654994428157806
step: 290, loss: 0.16772188246250153
step: 300, loss: 0.09184379875659943
step: 310, loss: 0.13459353148937225
step: 320, loss: 0.08309883624315262
step: 330, loss: 0.08316127955913544
step: 340, loss: 0.14661787450313568
step: 350, loss: 0.258353054523468
step: 360, loss: 0.12031521648168564
step: 370, loss: 0.1157149225473404
step: 380, loss: 0.10972870886325836
step: 390, loss: 0.07546189427375793
step: 400, loss: 0.14072543382644653
step: 410, loss: 0.07689782977104187
step: 420, loss: 0.08408813178539276
step: 430, loss: 0.10461940616369247
step: 440, loss: 0.0734570249915123
step: 450, loss: 0.12955501675605774
step: 460, loss: 0.09563347697257996
step: 470, loss: 0.12484832853078842
step: 480, loss: 0.3179713487625122
step: 490, loss: 0.12266276031732559
step: 500, loss: 0.1815102994441986
step: 510, loss: 0.16771069169044495
step: 520, loss: 0.13291220366954803
step: 530, loss: 0.14134405553340912
step: 540, loss: 0.1727277636528015
step: 550, loss: 0.028980450704693794
step: 560, loss: 0.20024403929710388
step: 570, loss: 0.019313087686896324
step: 580, loss: 0.10380353778600693
step: 590, loss: 0.13846607506275177
step: 600, loss: 0.1670278012752533
step: 610, loss: 0.02067234180867672
step: 620, loss: 0.02336745709180832
step: 630, loss: 0.18082275986671448
step: 640, loss: 0.11622779816389084
step: 650, loss: 0.11216350644826889
step: 660, loss: 0.07762923091650009
step: 670, loss: 0.034991584718227386
step: 680, loss: 0.12468183040618896
step: 690, loss: 0.08734993636608124
step: 700, loss: 0.014714159071445465
step: 710, loss: 0.02002786286175251
step: 720, loss: 0.06186098977923393
step: 730, loss: 0.10583502054214478
step: 740, loss: 0.06531619280576706
step: 750, loss: 0.2247609794139862
step: 760, loss: 0.09665548801422119
step: 770, loss: 0.05042474716901779
step: 780, loss: 0.1821839064359665
step: 790, loss: 0.07268793135881424
step: 800, loss: 0.030196096748113632
step: 810, loss: 0.06367695331573486
step: 820, loss: 0.048403751105070114
step: 830, loss: 0.11078154295682907
step: 840, loss: 0.18917344510555267
step: 850, loss: 0.13876280188560486
step: 860, loss: 0.09083550423383713
step: 870, loss: 0.08285326510667801
step: 880, loss: 0.18820372223854065
step: 890, loss: 0.0165691077709198
step: 900, loss: 0.073977530002594
step: 910, loss: 0.09461507201194763
step: 920, loss: 0.08485493808984756
step: 930, loss: 0.10218021273612976
step: 940, loss: 0.16256053745746613
step: 950, loss: 0.1938014179468155
step: 960, loss: 0.03252023831009865
step: 970, loss: 0.09497187286615372
step: 980, loss: 0.13301187753677368
step: 990, loss: 0.022949276491999626
step: 1000, loss: 0.05708618462085724
step: 1010, loss: 0.11258365213871002
step: 1020, loss: 0.018466444686055183
step: 1030, loss: 0.011535543017089367
step: 1040, loss: 0.20318524539470673
step: 1050, loss: 0.00759671488776803
step: 1060, loss: 0.09606871753931046
step: 1070, loss: 0.06876566261053085
epoch 1: dev_f1=0.9202797202797203, f1=0.917516218721038, best_f1=0.917516218721038
step: 0, loss: 0.07651383429765701
step: 10, loss: 0.05366570129990578
step: 20, loss: 0.1288808435201645
step: 30, loss: 0.028142021968960762
step: 40, loss: 0.1984606385231018
step: 50, loss: 0.04091033712029457
step: 60, loss: 0.09559407830238342
step: 70, loss: 0.052442766726017
step: 80, loss: 0.03880719840526581
step: 90, loss: 0.09861939400434494
step: 100, loss: 0.20877766609191895
step: 110, loss: 0.11721160262823105
step: 120, loss: 0.04022563621401787
step: 130, loss: 0.0702897384762764
step: 140, loss: 0.07400788366794586
step: 150, loss: 0.009196236729621887
step: 160, loss: 0.07404583692550659
step: 170, loss: 0.08805786818265915
step: 180, loss: 0.020011678338050842
step: 190, loss: 0.0968628004193306
step: 200, loss: 0.15146417915821075
step: 210, loss: 0.035561490803956985
step: 220, loss: 0.10794811695814133
step: 230, loss: 0.060214798897504807
step: 240, loss: 0.10477858781814575
step: 250, loss: 0.14666326344013214
step: 260, loss: 0.1000952273607254
step: 270, loss: 0.0842956155538559
step: 280, loss: 0.05872999131679535
step: 290, loss: 0.12602455914020538
step: 300, loss: 0.02318352274596691
step: 310, loss: 0.10656391084194183
step: 320, loss: 0.01905575767159462
step: 330, loss: 0.0224030539393425
step: 340, loss: 0.015710676088929176
step: 350, loss: 0.06477531045675278
step: 360, loss: 0.06718293577432632
step: 370, loss: 0.10374804586172104
step: 380, loss: 0.09420475363731384
step: 390, loss: 0.1612333357334137
step: 400, loss: 0.08698318898677826
step: 410, loss: 0.11095385998487473
step: 420, loss: 0.06754700839519501
step: 430, loss: 0.1284877210855484
step: 440, loss: 0.11090347915887833
step: 450, loss: 0.16159600019454956
step: 460, loss: 0.05253637954592705
step: 470, loss: 0.05167018994688988
step: 480, loss: 0.07167595624923706
step: 490, loss: 0.13813573122024536
step: 500, loss: 0.058156732469797134
step: 510, loss: 0.07412789762020111
step: 520, loss: 0.07355869561433792
step: 530, loss: 0.06188017874956131
step: 540, loss: 0.06485576182603836
step: 550, loss: 0.21639028191566467
step: 560, loss: 0.028978543356060982
step: 570, loss: 0.04613923653960228
step: 580, loss: 0.08065598458051682
step: 590, loss: 0.14993774890899658
step: 600, loss: 0.1417277306318283
step: 610, loss: 0.13310971856117249
step: 620, loss: 0.07535601407289505
step: 630, loss: 0.075043685734272
step: 640, loss: 0.07913534343242645
step: 650, loss: 0.10673999786376953
step: 660, loss: 0.08500338345766068
step: 670, loss: 0.09138621389865875
step: 680, loss: 0.04702538251876831
step: 690, loss: 0.1732722818851471
step: 700, loss: 0.0318327322602272
step: 710, loss: 0.06969544291496277
step: 720, loss: 0.16920001804828644
step: 730, loss: 0.07825211435556412
step: 740, loss: 0.07005017250776291
step: 750, loss: 0.06071189045906067
step: 760, loss: 0.029693052172660828
step: 770, loss: 0.2036670595407486
step: 780, loss: 0.03934074565768242
step: 790, loss: 0.04002172872424126
step: 800, loss: 0.035551927983760834
step: 810, loss: 0.024172095581889153
step: 820, loss: 0.15926297008991241
step: 830, loss: 0.021291058510541916
step: 840, loss: 0.08792544901371002
step: 850, loss: 0.09882603585720062
step: 860, loss: 0.05852184072136879
step: 870, loss: 0.22142641246318817
step: 880, loss: 0.03559425473213196
step: 890, loss: 0.10496382415294647
step: 900, loss: 0.0746249258518219
step: 910, loss: 0.09251215308904648
step: 920, loss: 0.15668673813343048
step: 930, loss: 0.14711683988571167
step: 940, loss: 0.07207062840461731
step: 950, loss: 0.05819522216916084
step: 960, loss: 0.06546677649021149
step: 970, loss: 0.060217518359422684
step: 980, loss: 0.20470109581947327
step: 990, loss: 0.05539281666278839
step: 1000, loss: 0.101514533162117
step: 1010, loss: 0.021904753521084785
step: 1020, loss: 0.03138270229101181
step: 1030, loss: 0.03252538666129112
step: 1040, loss: 0.07641464471817017
step: 1050, loss: 0.10898763686418533
step: 1060, loss: 0.02665683627128601
step: 1070, loss: 0.11899968981742859
epoch 2: dev_f1=0.9191919191919192, f1=0.929551692589204, best_f1=0.917516218721038
step: 0, loss: 0.03591716289520264
step: 10, loss: 0.03948114067316055
step: 20, loss: 0.05956508219242096
step: 30, loss: 0.07053001970052719
step: 40, loss: 0.026426823809742928
step: 50, loss: 0.16538123786449432
step: 60, loss: 0.15553656220436096
step: 70, loss: 0.0024158505257219076
step: 80, loss: 0.09167349338531494
step: 90, loss: 0.1666359156370163
step: 100, loss: 0.08806180208921432
step: 110, loss: 0.08736112713813782
step: 120, loss: 0.11364346742630005
step: 130, loss: 0.1122540831565857
step: 140, loss: 0.011554720811545849
step: 150, loss: 0.15984641015529633
step: 160, loss: 0.11818751692771912
step: 170, loss: 0.12411423027515411
step: 180, loss: 0.026970550417900085
step: 190, loss: 0.11229240894317627
step: 200, loss: 0.014791147783398628
step: 210, loss: 0.028286002576351166
step: 220, loss: 0.12667670845985413
step: 230, loss: 0.10885210335254669
step: 240, loss: 0.033386193215847015
step: 250, loss: 0.04369150847196579
step: 260, loss: 0.02751295454800129
step: 270, loss: 0.03284067660570145
step: 280, loss: 0.06935520470142365
step: 290, loss: 0.04561832919716835
step: 300, loss: 0.01718219183385372
step: 310, loss: 0.15207752585411072
step: 320, loss: 0.054885782301425934
step: 330, loss: 0.04209442436695099
step: 340, loss: 0.16282908618450165
step: 350, loss: 0.10527922213077545
step: 360, loss: 0.07678966224193573
step: 370, loss: 0.002584097208455205
step: 380, loss: 0.041122596710920334
step: 390, loss: 0.10816612839698792
step: 400, loss: 0.03194494545459747
step: 410, loss: 0.06187187135219574
step: 420, loss: 0.06447448581457138
step: 430, loss: 0.018842454999685287
step: 440, loss: 0.10409141331911087
step: 450, loss: 0.13106398284435272
step: 460, loss: 0.1431197077035904
step: 470, loss: 0.02167700044810772
step: 480, loss: 0.07457145303487778
step: 490, loss: 0.02179683744907379
step: 500, loss: 0.014633938670158386
step: 510, loss: 0.11906380951404572
step: 520, loss: 0.03766569495201111
step: 530, loss: 0.12335073202848434
step: 540, loss: 0.12049029767513275
step: 550, loss: 0.09750440716743469
step: 560, loss: 0.09481606632471085
step: 570, loss: 0.028575370088219643
step: 580, loss: 0.13434746861457825
step: 590, loss: 0.03909703344106674
step: 600, loss: 0.07677561789751053
step: 610, loss: 0.06578205525875092
step: 620, loss: 0.029567351564764977
step: 630, loss: 0.021872946992516518
step: 640, loss: 0.08067180961370468
step: 650, loss: 0.015027815476059914
step: 660, loss: 0.09998579323291779
step: 670, loss: 0.09303010255098343
step: 680, loss: 0.21825046837329865
step: 690, loss: 0.025155380368232727
step: 700, loss: 0.018400631844997406
step: 710, loss: 0.009613936766982079
step: 720, loss: 0.013046789914369583
step: 730, loss: 0.05579213425517082
step: 740, loss: 0.05714169889688492
step: 750, loss: 0.08162461221218109
step: 760, loss: 0.07762353867292404
step: 770, loss: 0.13878697156906128
step: 780, loss: 0.08240838348865509
step: 790, loss: 0.005804253276437521
step: 800, loss: 0.07609380036592484
step: 810, loss: 0.01842300035059452
step: 820, loss: 0.03365395590662956
step: 830, loss: 0.042713988572359085
step: 840, loss: 0.02791019342839718
step: 850, loss: 0.020959584042429924
step: 860, loss: 0.09414303302764893
step: 870, loss: 0.1415298879146576
step: 880, loss: 0.11897031962871552
step: 890, loss: 0.050146300345659256
step: 900, loss: 0.033330243080854416
step: 910, loss: 0.061625584959983826
step: 920, loss: 0.08266029506921768
step: 930, loss: 0.01724248006939888
step: 940, loss: 0.08952229470014572
step: 950, loss: 0.011407923884689808
step: 960, loss: 0.09223999083042145
step: 970, loss: 0.023340977728366852
step: 980, loss: 0.04109258949756622
step: 990, loss: 0.04072406888008118
step: 1000, loss: 0.10193435847759247
step: 1010, loss: 0.06263738870620728
step: 1020, loss: 0.10506156086921692
step: 1030, loss: 0.05015065521001816
step: 1040, loss: 0.012486331164836884
step: 1050, loss: 0.08572325855493546
step: 1060, loss: 0.06490004062652588
step: 1070, loss: 0.04142310097813606
epoch 3: dev_f1=0.9278824069820856, f1=0.9267161410018553, best_f1=0.9267161410018553
step: 0, loss: 0.04748227819800377
step: 10, loss: 0.08597861230373383
step: 20, loss: 0.02494923584163189
step: 30, loss: 0.10827463865280151
step: 40, loss: 0.021091870963573456
step: 50, loss: 0.06336820870637894
step: 60, loss: 0.01807199977338314
step: 70, loss: 0.10849951952695847
step: 80, loss: 0.05966975912451744
step: 90, loss: 0.06105036288499832
step: 100, loss: 0.013096717186272144
step: 110, loss: 0.042733389884233475
step: 120, loss: 0.0517481192946434
step: 130, loss: 0.07392830401659012
step: 140, loss: 0.031056180596351624
step: 150, loss: 0.08852566033601761
step: 160, loss: 0.017075955867767334
step: 170, loss: 0.009931630454957485
step: 180, loss: 0.011137241497635841
step: 190, loss: 0.04077363759279251
step: 200, loss: 0.02114022895693779
step: 210, loss: 0.03146016597747803
step: 220, loss: 0.0292605422437191
step: 230, loss: 0.006578553467988968
step: 240, loss: 0.09448465704917908
step: 250, loss: 0.1518629491329193
step: 260, loss: 0.09302754700183868
step: 270, loss: 0.07300561666488647
step: 280, loss: 0.1546151041984558
step: 290, loss: 0.030687889084219933
step: 300, loss: 0.013192674145102501
step: 310, loss: 0.06108127534389496
step: 320, loss: 0.03044002503156662
step: 330, loss: 0.09984950721263885
step: 340, loss: 0.030028486624360085
step: 350, loss: 0.06812760978937149
step: 360, loss: 0.12224701046943665
step: 370, loss: 0.00666649779304862
step: 380, loss: 0.0507291816174984
step: 390, loss: 0.1966080516576767
step: 400, loss: 0.0984119325876236
step: 410, loss: 0.05490865558385849
step: 420, loss: 0.05768300220370293
step: 430, loss: 0.06615574657917023
step: 440, loss: 0.054676372557878494
step: 450, loss: 0.17570087313652039
step: 460, loss: 0.03146908059716225
step: 470, loss: 0.10655231773853302
step: 480, loss: 0.019839558750391006
step: 490, loss: 0.00649510882794857
step: 500, loss: 0.10593318939208984
step: 510, loss: 0.05587545037269592
step: 520, loss: 0.030711812898516655
step: 530, loss: 0.01622869074344635
step: 540, loss: 0.053466323763132095
step: 550, loss: 0.01890391856431961
step: 560, loss: 0.03623713180422783
step: 570, loss: 0.057762354612350464
step: 580, loss: 0.10941024869680405
step: 590, loss: 0.0576743558049202
step: 600, loss: 0.03236302360892296
step: 610, loss: 0.06489305943250656
step: 620, loss: 0.000435360474511981
step: 630, loss: 0.14621898531913757
step: 640, loss: 0.008468491025269032
step: 650, loss: 0.06761389225721359
step: 660, loss: 0.04020659998059273
step: 670, loss: 0.09623280167579651
step: 680, loss: 0.07697119563817978
step: 690, loss: 0.05517644062638283
step: 700, loss: 0.12880048155784607
step: 710, loss: 0.025974215939641
step: 720, loss: 0.022031715139746666
step: 730, loss: 0.012780895456671715
step: 740, loss: 0.16999836266040802
step: 750, loss: 0.14087170362472534
step: 760, loss: 0.06948139518499374
step: 770, loss: 0.00014895832282491028
step: 780, loss: 0.07289005815982819
step: 790, loss: 0.06689619272947311
step: 800, loss: 0.035334669053554535
step: 810, loss: 0.02126716449856758
step: 820, loss: 0.07637549936771393
step: 830, loss: 0.06756500899791718
step: 840, loss: 0.042532119899988174
step: 850, loss: 0.10350073873996735
step: 860, loss: 0.00016421441978309304
step: 870, loss: 0.06855408847332001
step: 880, loss: 0.14396825432777405
step: 890, loss: 0.013944143429398537
step: 900, loss: 0.04367028549313545
step: 910, loss: 0.11201169341802597
step: 920, loss: 0.05218905583024025
step: 930, loss: 0.12507249414920807
step: 940, loss: 0.09073617309331894
step: 950, loss: 0.03118695318698883
step: 960, loss: 0.2253650426864624
step: 970, loss: 0.04070525988936424
step: 980, loss: 0.0635552704334259
step: 990, loss: 0.13051661849021912
step: 1000, loss: 0.07845578342676163
step: 1010, loss: 0.0629831850528717
step: 1020, loss: 0.061483900994062424
step: 1030, loss: 0.08753622323274612
step: 1040, loss: 0.10243412852287292
step: 1050, loss: 0.0763411670923233
step: 1060, loss: 0.00012242613593116403
step: 1070, loss: 0.07253020256757736
epoch 4: dev_f1=0.93666204345816, f1=0.9340148698884759, best_f1=0.9340148698884759
step: 0, loss: 0.031803105026483536
step: 10, loss: 0.08149803429841995
step: 20, loss: 0.008198725990951061
step: 30, loss: 0.01393868774175644
step: 40, loss: 0.08045852184295654
step: 50, loss: 0.07853739708662033
step: 60, loss: 0.04279851168394089
step: 70, loss: 0.03499498590826988
step: 80, loss: 0.04088257625699043
step: 90, loss: 0.06176736578345299
step: 100, loss: 0.06739138066768646
step: 110, loss: 0.0434536449611187
step: 120, loss: 0.027805471792817116
step: 130, loss: 0.11427342891693115
step: 140, loss: 0.013866443186998367
step: 150, loss: 0.07726669311523438
step: 160, loss: 0.030722208321094513
step: 170, loss: 0.16707909107208252
step: 180, loss: 0.012725614942610264
step: 190, loss: 0.073041170835495
step: 200, loss: 0.16928333044052124
step: 210, loss: 0.009821189567446709
step: 220, loss: 0.017981763929128647
step: 230, loss: 0.026880789548158646
step: 240, loss: 0.02060815691947937
step: 250, loss: 0.019243812188506126
step: 260, loss: 0.0728880912065506
step: 270, loss: 0.09076103568077087
step: 280, loss: 0.0907929390668869
step: 290, loss: 0.012604626826941967
step: 300, loss: 0.06884218752384186
step: 310, loss: 0.03843630105257034
step: 320, loss: 0.047861248254776
step: 330, loss: 0.13993923366069794
step: 340, loss: 0.022436736151576042
step: 350, loss: 0.03374850004911423
step: 360, loss: 0.020936882123351097
step: 370, loss: 0.11323228478431702
step: 380, loss: 0.05131720006465912
step: 390, loss: 0.08180863410234451
step: 400, loss: 0.045258987694978714
step: 410, loss: 0.01778671145439148
step: 420, loss: 0.009468790143728256
step: 430, loss: 0.04932662844657898
step: 440, loss: 0.014025131240487099
step: 450, loss: 0.061470046639442444
step: 460, loss: 0.030850205570459366
step: 470, loss: 0.037067219614982605
step: 480, loss: 0.02879258804023266
step: 490, loss: 0.1677502691745758
step: 500, loss: 0.07329785823822021
step: 510, loss: 0.035946205258369446
step: 520, loss: 0.06905025988817215
step: 530, loss: 0.09224078059196472
step: 540, loss: 0.000580742722377181
step: 550, loss: 0.07713224738836288
step: 560, loss: 0.018360743299126625
step: 570, loss: 0.13546650111675262
step: 580, loss: 0.09493929892778397
step: 590, loss: 0.13189952075481415
step: 600, loss: 0.026418115943670273
step: 610, loss: 0.01324913464486599
step: 620, loss: 0.058519963175058365
step: 630, loss: 0.09200217574834824
step: 640, loss: 0.03382712975144386
step: 650, loss: 0.07013803720474243
step: 660, loss: 0.015234911814332008
step: 670, loss: 0.031163794919848442
step: 680, loss: 0.10315067321062088
step: 690, loss: 0.06583360582590103
step: 700, loss: 0.005528132896870375
step: 710, loss: 0.06780446320772171
step: 720, loss: 0.057195477187633514
step: 730, loss: 0.016847919672727585
step: 740, loss: 0.15087881684303284
step: 750, loss: 0.05260567367076874
step: 760, loss: 0.10306768864393234
step: 770, loss: 0.09481236338615417
step: 780, loss: 0.014629380777478218
step: 790, loss: 0.08088617771863937
step: 800, loss: 0.02022136189043522
step: 810, loss: 0.0785660520195961
step: 820, loss: 0.06942325830459595
step: 830, loss: 0.02112789824604988
step: 840, loss: 0.07830506563186646
step: 850, loss: 0.017992177978157997
step: 860, loss: 0.06075691059231758
step: 870, loss: 0.09960975497961044
step: 880, loss: 0.10318830609321594
step: 890, loss: 0.17117922008037567
step: 900, loss: 0.12599991261959076
step: 910, loss: 0.030505117028951645
step: 920, loss: 0.014678234234452248
step: 930, loss: 0.0743790715932846
step: 940, loss: 0.020209209993481636
step: 950, loss: 0.06850045919418335
step: 960, loss: 0.08964111655950546
step: 970, loss: 0.07635107636451721
step: 980, loss: 0.07144738733768463
step: 990, loss: 0.05958609655499458
step: 1000, loss: 0.07475845515727997
step: 1010, loss: 0.00951375812292099
step: 1020, loss: 0.10239802300930023
step: 1030, loss: 0.03745056316256523
step: 1040, loss: 0.04110870882868767
step: 1050, loss: 0.020808877423405647
step: 1060, loss: 0.05243949964642525
step: 1070, loss: 0.0985843688249588
epoch 5: dev_f1=0.9407441433164906, f1=0.9356458238247376, best_f1=0.9356458238247376
step: 0, loss: 0.022256676107645035
step: 10, loss: 0.015519840642809868
step: 20, loss: 0.0287619698792696
step: 30, loss: 0.010467955842614174
step: 40, loss: 0.03633802384138107
step: 50, loss: 0.05038754642009735
step: 60, loss: 0.013537471182644367
step: 70, loss: 0.17785587906837463
step: 80, loss: 0.0450458824634552
step: 90, loss: 0.021254098042845726
step: 100, loss: 0.0074890232644975185
step: 110, loss: 0.057689204812049866
step: 120, loss: 0.15423643589019775
step: 130, loss: 0.04681020230054855
step: 140, loss: 0.03664037212729454
step: 150, loss: 0.10411755740642548
step: 160, loss: 0.0031850282102823257
step: 170, loss: 0.008558421395719051
step: 180, loss: 0.013826475478708744
step: 190, loss: 0.022375404834747314
step: 200, loss: 0.055951934307813644
step: 210, loss: 0.012316807173192501
step: 220, loss: 0.0199209526181221
step: 230, loss: 0.05523769184947014
step: 240, loss: 0.007384192198514938
step: 250, loss: 0.0005413906183093786
step: 260, loss: 0.09618174284696579
step: 270, loss: 0.03465552255511284
step: 280, loss: 0.012912562116980553
step: 290, loss: 0.041971318423748016
step: 300, loss: 0.05632743984460831
step: 310, loss: 0.014702728018164635
step: 320, loss: 0.0636836588382721
step: 330, loss: 0.08311907947063446
step: 340, loss: 0.01780547760426998
step: 350, loss: 0.030280206352472305
step: 360, loss: 0.07095097005367279
step: 370, loss: 0.008611844852566719
step: 380, loss: 0.007165519054979086
step: 390, loss: 0.004791188053786755
step: 400, loss: 0.08120610564947128
step: 410, loss: 0.031867340207099915
step: 420, loss: 0.001043563592247665
step: 430, loss: 0.01641647145152092
step: 440, loss: 0.10835150629281998
step: 450, loss: 0.07148130238056183
step: 460, loss: 0.03044363483786583
step: 470, loss: 0.0516132228076458
step: 480, loss: 0.00027328956639394164
step: 490, loss: 0.03756531700491905
step: 500, loss: 0.11865770071744919
step: 510, loss: 0.09090093523263931
step: 520, loss: 0.009075203910470009
step: 530, loss: 0.005953993182629347
step: 540, loss: 0.010426189750432968
step: 550, loss: 0.035803791135549545
step: 560, loss: 0.016141671687364578
step: 570, loss: 0.06231636181473732
step: 580, loss: 0.00012854048691224307
step: 590, loss: 0.07489822804927826
step: 600, loss: 0.033743489533662796
step: 610, loss: 0.020397070795297623
step: 620, loss: 0.10005125403404236
step: 630, loss: 0.02478218637406826
step: 640, loss: 0.11705230176448822
step: 650, loss: 0.033715393394231796
step: 660, loss: 0.08355182409286499
step: 670, loss: 0.003258045995607972
step: 680, loss: 0.0044029694981873035
step: 690, loss: 0.02671593800187111
step: 700, loss: 0.2161530703306198
step: 710, loss: 0.16016511619091034
step: 720, loss: 0.07541675865650177
step: 730, loss: 0.0875110924243927
step: 740, loss: 0.07301024347543716
step: 750, loss: 0.030593054369091988
step: 760, loss: 0.042211901396512985
step: 770, loss: 0.03973052278161049
step: 780, loss: 0.024070002138614655
step: 790, loss: 0.17753343284130096
step: 800, loss: 0.04980660602450371
step: 810, loss: 0.0770292803645134
step: 820, loss: 0.07862826436758041
step: 830, loss: 0.0178189929574728
step: 840, loss: 0.05442230775952339
step: 850, loss: 0.05036959797143936
step: 860, loss: 0.006252143066376448
step: 870, loss: 0.07012678682804108
step: 880, loss: 0.07303544878959656
step: 890, loss: 0.04400855675339699
step: 900, loss: 0.11532235890626907
step: 910, loss: 0.013702264986932278
step: 920, loss: 0.013077548705041409
step: 930, loss: 0.011593293398618698
step: 940, loss: 0.052014369517564774
step: 950, loss: 0.047047462314367294
step: 960, loss: 0.0051291873678565025
step: 970, loss: 0.12135834246873856
step: 980, loss: 0.07735689729452133
step: 990, loss: 0.04290543124079704
step: 1000, loss: 0.02008247561752796
step: 1010, loss: 0.08035604655742645
step: 1020, loss: 0.009711082093417645
step: 1030, loss: 0.08297266811132431
step: 1040, loss: 0.0268904659897089
step: 1050, loss: 0.016550276428461075
step: 1060, loss: 0.03763371706008911
step: 1070, loss: 0.08388318866491318
epoch 6: dev_f1=0.9368520263901979, f1=0.9272641952135147, best_f1=0.9356458238247376
step: 0, loss: 0.027649130672216415
step: 10, loss: 0.01337648555636406
step: 20, loss: 0.011659887619316578
step: 30, loss: 0.00661155441775918
step: 40, loss: 0.015017911791801453
step: 50, loss: 0.03258388862013817
step: 60, loss: 0.032438725233078
step: 70, loss: 0.07150433957576752
step: 80, loss: 8.318440814036876e-05
step: 90, loss: 0.10936499387025833
step: 100, loss: 0.051240213215351105
step: 110, loss: 0.04810481518507004
step: 120, loss: 0.06113770604133606
step: 130, loss: 0.09124279022216797
step: 140, loss: 0.05193101987242699
step: 150, loss: 0.050783392041921616
step: 160, loss: 0.044008780270814896
step: 170, loss: 0.01931392028927803
step: 180, loss: 0.011111583560705185
step: 190, loss: 0.05939607694745064
step: 200, loss: 0.02008623257279396
step: 210, loss: 0.029870502650737762
step: 220, loss: 0.0038908033166080713
step: 230, loss: 0.004901053849607706
step: 240, loss: 0.08087712526321411
step: 250, loss: 0.04931977763772011
step: 260, loss: 0.09859432280063629
step: 270, loss: 0.03047736920416355
step: 280, loss: 0.025784922763705254
step: 290, loss: 0.018699096515774727
step: 300, loss: 0.03510412946343422
step: 310, loss: 0.13175362348556519
step: 320, loss: 0.0971323624253273
step: 330, loss: 0.01335685234516859
step: 340, loss: 0.07188058644533157
step: 350, loss: 0.04923201724886894
step: 360, loss: 0.03935489431023598
step: 370, loss: 0.02810581959784031
step: 380, loss: 0.04083253815770149
step: 390, loss: 0.03031538799405098
step: 400, loss: 0.012895514257252216
step: 410, loss: 0.025050276890397072
step: 420, loss: 0.07398205250501633
step: 430, loss: 0.029886651784181595
step: 440, loss: 0.02803722210228443
step: 450, loss: 0.04881424084305763
step: 460, loss: 0.0057624327018857
step: 470, loss: 0.04774655029177666
step: 480, loss: 0.000318051635986194
step: 490, loss: 0.131609708070755
step: 500, loss: 0.22053198516368866
step: 510, loss: 0.09729607403278351
step: 520, loss: 0.07184018194675446
step: 530, loss: 0.0005237643490545452
step: 540, loss: 0.07258681207895279
step: 550, loss: 0.021338628605008125
step: 560, loss: 0.09152605384588242
step: 570, loss: 0.07632691413164139
step: 580, loss: 0.06551513820886612
step: 590, loss: 0.07606033980846405
step: 600, loss: 0.08736228197813034
step: 610, loss: 0.07903902977705002
step: 620, loss: 0.2207004427909851
step: 630, loss: 0.15671013295650482
step: 640, loss: 0.05260405316948891
step: 650, loss: 0.006531486287713051
step: 660, loss: 0.15730717778205872
step: 670, loss: 0.007915324531495571
step: 680, loss: 0.009525977075099945
step: 690, loss: 0.04913542792201042
step: 700, loss: 0.11756119132041931
step: 710, loss: 0.0652271956205368
step: 720, loss: 0.043373893946409225
step: 730, loss: 0.0016829522792249918
step: 740, loss: 0.029215380549430847
step: 750, loss: 0.030497737228870392
step: 760, loss: 0.010637994855642319
step: 770, loss: 0.01100439578294754
step: 780, loss: 0.13339634239673615
step: 790, loss: 0.06151267886161804
step: 800, loss: 0.02300453931093216
step: 810, loss: 0.0148263955488801
step: 820, loss: 0.012528222985565662
step: 830, loss: 0.020273592323064804
step: 840, loss: 0.00963332038372755
step: 850, loss: 0.03510626405477524
step: 860, loss: 0.059950437396764755
step: 870, loss: 0.05865300074219704
step: 880, loss: 0.05812939628958702
step: 890, loss: 0.14126430451869965
step: 900, loss: 0.07058414071798325
step: 910, loss: 0.06582394987344742
step: 920, loss: 0.015248706564307213
step: 930, loss: 0.12976090610027313
step: 940, loss: 0.019364099949598312
step: 950, loss: 0.13727973401546478
step: 960, loss: 0.05075550451874733
step: 970, loss: 0.05708940327167511
step: 980, loss: 0.10647539049386978
step: 990, loss: 0.027679620310664177
step: 1000, loss: 0.010721990838646889
step: 1010, loss: 0.03270870819687843
step: 1020, loss: 0.10528861731290817
step: 1030, loss: 0.06593705713748932
step: 1040, loss: 0.0737684890627861
step: 1050, loss: 0.03915868699550629
step: 1060, loss: 0.054399602115154266
step: 1070, loss: 0.10039906948804855
epoch 7: dev_f1=0.9409048938134812, f1=0.9375, best_f1=0.9375
step: 0, loss: 0.12930803000926971
step: 10, loss: 0.08338557183742523
step: 20, loss: 0.03525195270776749
step: 30, loss: 0.03536805137991905
step: 40, loss: 0.015464751981198788
step: 50, loss: 0.016537822782993317
step: 60, loss: 0.0599854439496994
step: 70, loss: 0.008847278542816639
step: 80, loss: 0.006132493261247873
step: 90, loss: 0.12204262614250183
step: 100, loss: 0.015278869308531284
step: 110, loss: 0.010102549567818642
step: 120, loss: 0.006931759417057037
step: 130, loss: 0.05981742590665817
step: 140, loss: 0.06792458146810532
step: 150, loss: 0.013332841917872429
step: 160, loss: 0.06797730922698975
step: 170, loss: 0.018419083207845688
step: 180, loss: 0.0038091898895800114
step: 190, loss: 0.027999147772789
step: 200, loss: 0.09617530554533005
step: 210, loss: 0.014315430074930191
step: 220, loss: 0.05088035389780998
step: 230, loss: 0.06436888873577118
step: 240, loss: 0.035009559243917465
step: 250, loss: 0.03934984654188156
step: 260, loss: 0.017405511811375618
step: 270, loss: 0.009775065816938877
step: 280, loss: 0.011237753555178642
step: 290, loss: 0.022304154932498932
step: 300, loss: 0.08818387240171432
step: 310, loss: 0.04862222820520401
step: 320, loss: 0.05770410597324371
step: 330, loss: 0.08058136701583862
step: 340, loss: 0.02923700585961342
step: 350, loss: 0.07816173136234283
step: 360, loss: 0.12139824777841568
step: 370, loss: 0.05140666663646698
step: 380, loss: 0.08196025341749191
step: 390, loss: 0.062393348664045334
step: 400, loss: 0.010687255300581455
step: 410, loss: 0.014499993063509464
step: 420, loss: 0.14789491891860962
step: 430, loss: 0.071147620677948
step: 440, loss: 0.00431669969111681
step: 450, loss: 0.05803988501429558
step: 460, loss: 0.18521316349506378
step: 470, loss: 0.006157298572361469
step: 480, loss: 0.05100121721625328
step: 490, loss: 0.001835295115597546
step: 500, loss: 0.08035875856876373
step: 510, loss: 0.07688489556312561
step: 520, loss: 0.07819437235593796
step: 530, loss: 0.000183331489097327
step: 540, loss: 0.04053625464439392
step: 550, loss: 0.030777182430028915
step: 560, loss: 0.01886594109237194
step: 570, loss: 0.12555228173732758
step: 580, loss: 0.012981420382857323
step: 590, loss: 0.053783029317855835
step: 600, loss: 0.02591678500175476
step: 610, loss: 0.11877135187387466
step: 620, loss: 0.05345301702618599
step: 630, loss: 0.035596806555986404
step: 640, loss: 0.028227495029568672
step: 650, loss: 0.05785538628697395
step: 660, loss: 0.042543161660432816
step: 670, loss: 0.03480538725852966
step: 680, loss: 0.014322636649012566
step: 690, loss: 0.014943292364478111
step: 700, loss: 0.07351066917181015
step: 710, loss: 0.015588781796395779
step: 720, loss: 0.0483374185860157
step: 730, loss: 0.08398883789777756
step: 740, loss: 0.0959186851978302
step: 750, loss: 0.018011868000030518
step: 760, loss: 0.07047264277935028
step: 770, loss: 0.06665591895580292
step: 780, loss: 0.057033225893974304
step: 790, loss: 0.04008818045258522
step: 800, loss: 0.015053384006023407
step: 810, loss: 0.03816208988428116
step: 820, loss: 0.04987471178174019
step: 830, loss: 0.048264604061841965
step: 840, loss: 0.06511474400758743
step: 850, loss: 0.07409598678350449
step: 860, loss: 0.23495768010616302
step: 870, loss: 0.06792652606964111
step: 880, loss: 0.008153071627020836
step: 890, loss: 0.12087312340736389
step: 900, loss: 0.027037302032113075
step: 910, loss: 0.012900988571345806
step: 920, loss: 0.0830242857336998
step: 930, loss: 0.03778088092803955
step: 940, loss: 0.023918336257338524
step: 950, loss: 0.06401779502630234
step: 960, loss: 0.03762408718466759
step: 970, loss: 0.034588057547807693
step: 980, loss: 0.08026600629091263
step: 990, loss: 0.1246120035648346
step: 1000, loss: 0.021504515781998634
step: 1010, loss: 0.006455146707594395
step: 1020, loss: 0.04558328911662102
step: 1030, loss: 0.032454732805490494
step: 1040, loss: 0.12564487755298615
step: 1050, loss: 0.047669485211372375
step: 1060, loss: 0.02904878742992878
step: 1070, loss: 0.010862791910767555
epoch 8: dev_f1=0.9298085688240657, f1=0.9329685362517101, best_f1=0.9375
step: 0, loss: 0.06257274746894836
step: 10, loss: 0.10736013203859329
step: 20, loss: 0.05016779154539108
step: 30, loss: 0.015460263937711716
step: 40, loss: 0.0909196063876152
step: 50, loss: 0.05274844542145729
step: 60, loss: 0.03624359145760536
step: 70, loss: 0.04302506148815155
step: 80, loss: 0.022058557718992233
step: 90, loss: 0.03512680530548096
step: 100, loss: 0.052999526262283325
step: 110, loss: 0.006040072068572044
step: 120, loss: 0.07949873805046082
step: 130, loss: 0.013587906956672668
step: 140, loss: 0.0753573477268219
step: 150, loss: 0.018926365301012993
step: 160, loss: 0.0007549482979811728
step: 170, loss: 0.11703366786241531
step: 180, loss: 0.06433072686195374
step: 190, loss: 0.015288332477211952
step: 200, loss: 0.09688350558280945
step: 210, loss: 0.09821078181266785
step: 220, loss: 0.005357698537409306
step: 230, loss: 0.09728214889764786
step: 240, loss: 0.03881492838263512
step: 250, loss: 0.06903340667486191
step: 260, loss: 0.02269560657441616
step: 270, loss: 0.0018360657850280404
step: 280, loss: 0.14925223588943481
step: 290, loss: 0.008024051785469055
step: 300, loss: 0.07268407195806503
step: 310, loss: 0.008831573650240898
step: 320, loss: 0.012294182553887367
step: 330, loss: 0.005418348591774702
step: 340, loss: 0.1610695868730545
step: 350, loss: 0.027394495904445648
step: 360, loss: 0.062105659395456314
step: 370, loss: 0.008796365931630135
step: 380, loss: 0.07540127635002136
step: 390, loss: 0.07730478793382645
step: 400, loss: 0.014617758803069592
step: 410, loss: 0.039109669625759125
step: 420, loss: 0.0008556087268516421
step: 430, loss: 0.06888703256845474
step: 440, loss: 0.037922490388154984
step: 450, loss: 0.04808879271149635
step: 460, loss: 0.010226448066532612
step: 470, loss: 0.06944379210472107
step: 480, loss: 0.1777399331331253
step: 490, loss: 0.056446000933647156
step: 500, loss: 0.00661130016669631
step: 510, loss: 0.057179443538188934
step: 520, loss: 9.096831490751356e-05
step: 530, loss: 0.01666932739317417
step: 540, loss: 0.0031221816316246986
step: 550, loss: 0.06889937818050385
step: 560, loss: 0.056986238807439804
step: 570, loss: 0.00755145400762558
step: 580, loss: 0.052295662462711334
step: 590, loss: 0.07799699157476425
step: 600, loss: 0.009936653077602386
step: 610, loss: 0.005495109129697084
step: 620, loss: 0.011367369443178177
step: 630, loss: 0.011149324476718903
step: 640, loss: 0.07645323872566223
step: 650, loss: 0.12665899097919464
step: 660, loss: 0.0030482495203614235
step: 670, loss: 0.06596694141626358
step: 680, loss: 0.07052379846572876
step: 690, loss: 0.0006955093122087419
step: 700, loss: 0.09298510104417801
step: 710, loss: 0.10137414932250977
step: 720, loss: 0.010598033666610718
step: 730, loss: 0.06331459432840347
step: 740, loss: 0.008556575514376163
step: 750, loss: 0.052841104567050934
step: 760, loss: 0.10627960413694382
step: 770, loss: 0.053360942751169205
step: 780, loss: 0.016967084258794785
step: 790, loss: 0.01989678479731083
step: 800, loss: 0.0026169512420892715
step: 810, loss: 0.09550262987613678
step: 820, loss: 0.05841522291302681
step: 830, loss: 0.020610002800822258
step: 840, loss: 0.08189094066619873
step: 850, loss: 0.08347471058368683
step: 860, loss: 0.06822744756937027
step: 870, loss: 0.03540068492293358
step: 880, loss: 0.015114609152078629
step: 890, loss: 0.049904175102710724
step: 900, loss: 0.10125415027141571
step: 910, loss: 0.052133843302726746
step: 920, loss: 0.15865914523601532
step: 930, loss: 0.025404339656233788
step: 940, loss: 0.15791842341423035
step: 950, loss: 0.07027191668748856
step: 960, loss: 0.02151624858379364
step: 970, loss: 0.07105811685323715
step: 980, loss: 0.07361334562301636
step: 990, loss: 0.0010830408427864313
step: 1000, loss: 0.006305769085884094
step: 1010, loss: 0.04820995405316353
step: 1020, loss: 0.05369521304965019
step: 1030, loss: 0.034813571721315384
step: 1040, loss: 0.05697351694107056
step: 1050, loss: 0.02908919006586075
step: 1060, loss: 0.03231219947338104
step: 1070, loss: 0.02466113492846489
epoch 9: dev_f1=0.9377901578458682, f1=0.9341317365269461, best_f1=0.9375
step: 0, loss: 0.05005313828587532
step: 10, loss: 0.020607108250260353
step: 20, loss: 0.00933025125414133
step: 30, loss: 0.02066408097743988
step: 40, loss: 0.04580162838101387
step: 50, loss: 0.06457432359457016
step: 60, loss: 0.07810834795236588
step: 70, loss: 0.0032165127340704203
step: 80, loss: 0.003871015040203929
step: 90, loss: 0.00664273789152503
step: 100, loss: 0.010058523155748844
step: 110, loss: 0.046596232801675797
step: 120, loss: 0.0069725667126476765
step: 130, loss: 4.638251994038001e-05
step: 140, loss: 0.007050483953207731
step: 150, loss: 0.03555251285433769
step: 160, loss: 0.03761930763721466
step: 170, loss: 0.05272671580314636
step: 180, loss: 0.018590491265058517
step: 190, loss: 0.04800915718078613
step: 200, loss: 0.05736837908625603
step: 210, loss: 0.05097050219774246
step: 220, loss: 0.020876659080386162
step: 230, loss: 0.000719204603228718
step: 240, loss: 0.012901945039629936
step: 250, loss: 0.06023965775966644
step: 260, loss: 0.045208919793367386
step: 270, loss: 0.008960336446762085
step: 280, loss: 0.028197968378663063
step: 290, loss: 0.02852194383740425
step: 300, loss: 0.022745590656995773
step: 310, loss: 0.0019935518503189087
step: 320, loss: 0.014743241481482983
step: 330, loss: 0.004186902195215225
step: 340, loss: 0.0006638109916821122
step: 350, loss: 0.021759387105703354
step: 360, loss: 0.009053971618413925
step: 370, loss: 0.05111607909202576
step: 380, loss: 0.0061446381732821465
step: 390, loss: 0.12527017295360565
step: 400, loss: 0.044500138610601425
step: 410, loss: 0.01874379627406597
step: 420, loss: 0.007610596250742674
step: 430, loss: 0.0036324087996035814
step: 440, loss: 0.12336620688438416
step: 450, loss: 0.02961277961730957
step: 460, loss: 0.0010223048739135265
step: 470, loss: 0.001130431774072349
step: 480, loss: 0.01178185734897852
step: 490, loss: 0.015304132364690304
step: 500, loss: 0.02165822871029377
step: 510, loss: 0.02491159364581108
step: 520, loss: 0.0004457088652998209
step: 530, loss: 0.01824764907360077
step: 540, loss: 0.039648089557886124
step: 550, loss: 0.07113563269376755
step: 560, loss: 0.018633512780070305
step: 570, loss: 0.039673130959272385
step: 580, loss: 0.030122844502329826
step: 590, loss: 0.032321635633707047
step: 600, loss: 0.109815813601017
step: 610, loss: 0.07166510075330734
step: 620, loss: 0.0022580816876143217
step: 630, loss: 0.03314416855573654
step: 640, loss: 0.010422701947391033
step: 650, loss: 0.0010154797928407788
step: 660, loss: 0.0437404029071331
step: 670, loss: 0.08553984016180038
step: 680, loss: 0.057398393750190735
step: 690, loss: 0.00957336276769638
step: 700, loss: 0.014135991223156452
step: 710, loss: 0.019005639478564262
step: 720, loss: 0.031379058957099915
step: 730, loss: 0.018777213990688324
step: 740, loss: 0.018238460645079613
step: 750, loss: 0.012450091540813446
step: 760, loss: 0.01984117180109024
step: 770, loss: 0.06263729929924011
step: 780, loss: 0.08426487445831299
step: 790, loss: 0.02615765854716301
step: 800, loss: 0.01723616197705269
step: 810, loss: 0.0036509630735963583
step: 820, loss: 0.015552794560790062
step: 830, loss: 0.06327912956476212
step: 840, loss: 0.07251360267400742
step: 850, loss: 0.006251028273254633
step: 860, loss: 0.012595386244356632
step: 870, loss: 0.08687623590230942
step: 880, loss: 0.02615855261683464
step: 890, loss: 0.0022683104034513235
step: 900, loss: 3.4561282518552616e-05
step: 910, loss: 0.010325504466891289
step: 920, loss: 0.03063228726387024
step: 930, loss: 0.10810635983943939
step: 940, loss: 0.05162131041288376
step: 950, loss: 0.06281640380620956
step: 960, loss: 0.016818566247820854
step: 970, loss: 0.03704189136624336
step: 980, loss: 0.014041395857930183
step: 990, loss: 0.11235300451517105
step: 1000, loss: 0.04451480135321617
step: 1010, loss: 0.015027164481580257
step: 1020, loss: 0.03752576559782028
step: 1030, loss: 0.02913065254688263
step: 1040, loss: 0.10630720853805542
step: 1050, loss: 0.022467784583568573
step: 1060, loss: 0.04247167333960533
step: 1070, loss: 0.027712270617485046
epoch 10: dev_f1=0.9344938158497481, f1=0.9335154826958107, best_f1=0.9375
step: 0, loss: 0.0257976483553648
step: 10, loss: 0.02572677843272686
step: 20, loss: 0.03108549490571022
step: 30, loss: 0.035255011171102524
step: 40, loss: 0.06543304026126862
step: 50, loss: 0.0890585407614708
step: 60, loss: 0.0793621614575386
step: 70, loss: 0.008888602256774902
step: 80, loss: 0.02803211472928524
step: 90, loss: 0.0010530357249081135
step: 100, loss: 0.08937124162912369
step: 110, loss: 0.04697088897228241
step: 120, loss: 0.02920224517583847
step: 130, loss: 0.04730244725942612
step: 140, loss: 0.09553183615207672
step: 150, loss: 0.002699019154533744
step: 160, loss: 0.06911955773830414
step: 170, loss: 3.18127749778796e-05
step: 180, loss: 0.002015464473515749
step: 190, loss: 0.1406029462814331
step: 200, loss: 0.0009923449251800776
step: 210, loss: 0.021050894632935524
step: 220, loss: 0.013128558173775673
step: 230, loss: 0.0006588090909644961
step: 240, loss: 0.07674477994441986
step: 250, loss: 0.0004690061614383012
step: 260, loss: 0.01229644101113081
step: 270, loss: 0.023003648966550827
step: 280, loss: 0.010247411206364632
step: 290, loss: 0.007708747871220112
step: 300, loss: 0.09501650184392929
step: 310, loss: 0.03965618833899498
step: 320, loss: 0.03611717373132706
step: 330, loss: 0.034983016550540924
step: 340, loss: 0.030033785849809647
step: 350, loss: 0.028879426419734955
step: 360, loss: 0.004890791140496731
step: 370, loss: 0.00257825362496078
step: 380, loss: 0.009533711709082127
step: 390, loss: 0.001546047511510551
step: 400, loss: 0.0995960608124733
step: 410, loss: 0.03566015884280205
step: 420, loss: 0.0018922585295513272
step: 430, loss: 0.04809868335723877
step: 440, loss: 0.01729966327548027
step: 450, loss: 0.05144636705517769
step: 460, loss: 0.03861233592033386
step: 470, loss: 0.07520513981580734
step: 480, loss: 0.0013049283297732472
step: 490, loss: 0.06579001992940903
step: 500, loss: 0.06578616797924042
step: 510, loss: 0.024455541744828224
step: 520, loss: 0.15336620807647705
step: 530, loss: 0.005318319424986839
step: 540, loss: 0.037503913044929504
step: 550, loss: 0.05115192383527756
step: 560, loss: 0.06271670758724213
step: 570, loss: 0.016897020861506462
step: 580, loss: 0.0015523149631917477
step: 590, loss: 0.03138944134116173
step: 600, loss: 8.772438013693318e-05
step: 610, loss: 0.03889158368110657
step: 620, loss: 0.06177201494574547
step: 630, loss: 0.014201036654412746
step: 640, loss: 0.041405513882637024
step: 650, loss: 0.028073804453015327
step: 660, loss: 0.0249245073646307
step: 670, loss: 0.0073815593495965
step: 680, loss: 0.006565875373780727
step: 690, loss: 0.0013694344088435173
step: 700, loss: 0.013786877505481243
step: 710, loss: 0.022943539544939995
step: 720, loss: 0.015495659783482552
step: 730, loss: 0.034841567277908325
step: 740, loss: 0.00019214815984014422
step: 750, loss: 0.02967234142124653
step: 760, loss: 0.03086928278207779
step: 770, loss: 0.0011593515519052744
step: 780, loss: 0.059027742594480515
step: 790, loss: 0.03924106806516647
step: 800, loss: 0.01781717874109745
step: 810, loss: 0.08983849734067917
step: 820, loss: 0.03218541294336319
step: 830, loss: 2.5554812964401208e-05
step: 840, loss: 0.005438001360744238
step: 850, loss: 0.04142140597105026
step: 860, loss: 0.053315721452236176
step: 870, loss: 0.008497246541082859
step: 880, loss: 0.024689210578799248
step: 890, loss: 0.032284434884786606
step: 900, loss: 0.014503249898552895
step: 910, loss: 0.03317589685320854
step: 920, loss: 7.630878826603293e-05
step: 930, loss: 0.00022734251979272813
step: 940, loss: 0.04278106242418289
step: 950, loss: 0.10393167287111282
step: 960, loss: 0.008632177487015724
step: 970, loss: 0.0005220775492489338
step: 980, loss: 0.2686222791671753
step: 990, loss: 0.005717545747756958
step: 1000, loss: 0.03699193149805069
step: 1010, loss: 0.015229860320687294
step: 1020, loss: 0.025431735441088676
step: 1030, loss: 0.025359230116009712
step: 1040, loss: 0.0940156877040863
step: 1050, loss: 0.018926946446299553
step: 1060, loss: 0.11265786737203598
step: 1070, loss: 0.04304158315062523
epoch 11: dev_f1=0.9341317365269461, f1=0.9315571887919155, best_f1=0.9375
step: 0, loss: 0.009313526563346386
step: 10, loss: 0.01417144387960434
step: 20, loss: 0.03503081202507019
step: 30, loss: 0.04798857495188713
step: 40, loss: 0.005599438212811947
step: 50, loss: 0.06668981909751892
step: 60, loss: 0.0004361188330221921
step: 70, loss: 0.01260458491742611
step: 80, loss: 0.05239346995949745
step: 90, loss: 0.017478609457612038
step: 100, loss: 0.004349155351519585
step: 110, loss: 0.08515805751085281
step: 120, loss: 0.09338293224573135
step: 130, loss: 0.03890550881624222
step: 140, loss: 0.05822312459349632
step: 150, loss: 0.04213834926486015
step: 160, loss: 0.07243797183036804
step: 170, loss: 0.03938007354736328
step: 180, loss: 0.03948386386036873
step: 190, loss: 0.025439519435167313
step: 200, loss: 0.02467193268239498
step: 210, loss: 0.00940709374845028
step: 220, loss: 0.004960205405950546
step: 230, loss: 0.0028981552459299564
step: 240, loss: 0.0002973036898765713
step: 250, loss: 0.024806823581457138
step: 260, loss: 0.05769064649939537
step: 270, loss: 0.01066249143332243
step: 280, loss: 0.013552924618124962
step: 290, loss: 0.021949119865894318
step: 300, loss: 0.006441437639296055
step: 310, loss: 0.046378351747989655
step: 320, loss: 0.0007390697137452662
step: 330, loss: 0.015673089772462845
step: 340, loss: 0.003483439330011606
step: 350, loss: 0.071382075548172
step: 360, loss: 0.050744958221912384
step: 370, loss: 0.03414677828550339
step: 380, loss: 0.045281387865543365
step: 390, loss: 0.046595074236392975
step: 400, loss: 0.013054286129772663
step: 410, loss: 0.012943674810230732
step: 420, loss: 0.019465848803520203
step: 430, loss: 0.04678085818886757
step: 440, loss: 0.020681656897068024
step: 450, loss: 0.0010470844572409987
step: 460, loss: 0.08847300708293915
step: 470, loss: 0.00012675620382651687
step: 480, loss: 0.010223434306681156
step: 490, loss: 0.03259919583797455
step: 500, loss: 0.08444607257843018
step: 510, loss: 0.09221336245536804
step: 520, loss: 0.03696036711335182
step: 530, loss: 0.010282297618687153
step: 540, loss: 0.09017831832170486
step: 550, loss: 0.029289163649082184
step: 560, loss: 0.03862900659441948
step: 570, loss: 0.01748492568731308
step: 580, loss: 0.07650978118181229
step: 590, loss: 0.05529217794537544
step: 600, loss: 0.023997396230697632
step: 610, loss: 0.01777733862400055
step: 620, loss: 0.003803429426625371
step: 630, loss: 0.0025196773931384087
step: 640, loss: 0.02155337855219841
step: 650, loss: 0.026478838175535202
step: 660, loss: 0.0027749063447117805
step: 670, loss: 0.04268082603812218
step: 680, loss: 0.01469171792268753
step: 690, loss: 0.0015760506503283978
step: 700, loss: 0.027525130659341812
step: 710, loss: 0.03020256757736206
step: 720, loss: 0.05359210446476936
step: 730, loss: 0.01561015285551548
step: 740, loss: 0.09826608002185822
step: 750, loss: 0.07324342429637909
step: 760, loss: 0.006865429691970348
step: 770, loss: 0.030319493263959885
step: 780, loss: 0.026244914159178734
step: 790, loss: 0.06644182652235031
step: 800, loss: 0.01856308802962303
step: 810, loss: 0.04371681064367294
step: 820, loss: 0.01276266761124134
step: 830, loss: 0.006275078281760216
step: 840, loss: 0.0533299520611763
step: 850, loss: 0.00029484054539352655
step: 860, loss: 0.049123138189315796
step: 870, loss: 0.022575346753001213
step: 880, loss: 0.03338344767689705
step: 890, loss: 0.01310187578201294
step: 900, loss: 0.050481513142585754
step: 910, loss: 0.014657187275588512
step: 920, loss: 0.010447992943227291
step: 930, loss: 0.03374216705560684
step: 940, loss: 0.008071279153227806
step: 950, loss: 0.07709237188100815
step: 960, loss: 0.017841730266809464
step: 970, loss: 0.06982564181089401
step: 980, loss: 0.089406318962574
step: 990, loss: 0.06908752024173737
step: 1000, loss: 0.07589388638734818
step: 1010, loss: 0.01573665253818035
step: 1020, loss: 0.00407912814989686
step: 1030, loss: 0.030137768015265465
step: 1040, loss: 0.03715549409389496
step: 1050, loss: 0.07200951874256134
step: 1060, loss: 0.04029260203242302
step: 1070, loss: 0.03132948279380798
epoch 12: dev_f1=0.9349555451567618, f1=0.9328984156570364, best_f1=0.9375
step: 0, loss: 0.04655076935887337
step: 10, loss: 0.12565173208713531
step: 20, loss: 0.03062903881072998
step: 30, loss: 0.015463016927242279
step: 40, loss: 0.0012982700718566775
step: 50, loss: 0.0649154782295227
step: 60, loss: 0.02792736329138279
step: 70, loss: 0.013426628895103931
step: 80, loss: 0.0675596296787262
step: 90, loss: 0.0006781082483939826
step: 100, loss: 4.123095641261898e-05
step: 110, loss: 0.018409283831715584
step: 120, loss: 0.00442809471860528
step: 130, loss: 0.027510812506079674
step: 140, loss: 0.021131938323378563
step: 150, loss: 0.015520919114351273
step: 160, loss: 0.006516000255942345
step: 170, loss: 0.08239990472793579
step: 180, loss: 0.0513366162776947
step: 190, loss: 0.0011296190787106752
step: 200, loss: 0.04502676799893379
step: 210, loss: 0.00523986853659153
step: 220, loss: 0.003168004099279642
step: 230, loss: 0.04979250580072403
step: 240, loss: 0.056936491280794144
step: 250, loss: 0.0004978966899216175
step: 260, loss: 0.06470043957233429
step: 270, loss: 0.025433070957660675
step: 280, loss: 0.03065308928489685
step: 290, loss: 0.041022080928087234
step: 300, loss: 0.022879183292388916
step: 310, loss: 0.056415196508169174
step: 320, loss: 0.10229074209928513
step: 330, loss: 0.027552256360650063
step: 340, loss: 0.0300401970744133
step: 350, loss: 0.07812076061964035
step: 360, loss: 0.06886199116706848
step: 370, loss: 0.012114928103983402
step: 380, loss: 0.056674931198358536
step: 390, loss: 0.0011907769367098808
step: 400, loss: 0.0037079222965985537
step: 410, loss: 0.0007336836424656212
step: 420, loss: 0.08010120689868927
step: 430, loss: 0.0006560588371939957
step: 440, loss: 0.013346279971301556
step: 450, loss: 0.04313036426901817
step: 460, loss: 0.13607771694660187
step: 470, loss: 0.027669863775372505
step: 480, loss: 0.07206027209758759
step: 490, loss: 0.02794063277542591
step: 500, loss: 0.0023412012960761786
step: 510, loss: 0.00795114878565073
step: 520, loss: 0.019395766779780388
step: 530, loss: 0.03670132905244827
step: 540, loss: 0.015152866952121258
step: 550, loss: 0.00025818755966611207
step: 560, loss: 0.050333745777606964
step: 570, loss: 0.028293346986174583
step: 580, loss: 4.629076283890754e-05
step: 590, loss: 0.016553737223148346
step: 600, loss: 0.09589450061321259
step: 610, loss: 0.007281215395778418
step: 620, loss: 0.013351229950785637
step: 630, loss: 0.05725383758544922
step: 640, loss: 0.04864266514778137
step: 650, loss: 0.03795967251062393
step: 660, loss: 0.00024366217257920653
step: 670, loss: 0.00035462272353470325
step: 680, loss: 0.03234878182411194
step: 690, loss: 0.05092131718993187
step: 700, loss: 0.04408927634358406
step: 710, loss: 1.9285344023955986e-05
step: 720, loss: 0.08422095328569412
step: 730, loss: 0.017820151522755623
step: 740, loss: 0.0104126101359725
step: 750, loss: 0.018282758072018623
step: 760, loss: 1.2032582162646577e-05
step: 770, loss: 0.04288720712065697
step: 780, loss: 0.03446536883711815
step: 790, loss: 1.6398356819991022e-05
step: 800, loss: 0.0001220411213580519
step: 810, loss: 0.015584323555231094
step: 820, loss: 0.03146893158555031
step: 830, loss: 0.0025038376916199923
step: 840, loss: 0.06394681334495544
step: 850, loss: 0.06092066317796707
step: 860, loss: 0.009146449156105518
step: 870, loss: 0.027220571413636208
step: 880, loss: 0.023064449429512024
step: 890, loss: 0.03901587426662445
step: 900, loss: 0.024390583857893944
step: 910, loss: 0.07506558299064636
step: 920, loss: 0.012489345856010914
step: 930, loss: 0.03249884024262428
step: 940, loss: 0.0959237739443779
step: 950, loss: 0.022536570206284523
step: 960, loss: 0.011014727875590324
step: 970, loss: 0.04156547784805298
step: 980, loss: 0.047445811331272125
step: 990, loss: 0.021414589136838913
step: 1000, loss: 0.20652121305465698
step: 1010, loss: 0.016494739800691605
step: 1020, loss: 0.11298253387212753
step: 1030, loss: 0.0075963265262544155
step: 1040, loss: 0.028023073449730873
step: 1050, loss: 0.03411533683538437
step: 1060, loss: 0.0557829923927784
step: 1070, loss: 0.0374206081032753
epoch 13: dev_f1=0.9311627906976745, f1=0.932963476652797, best_f1=0.9375
step: 0, loss: 0.018248237669467926
step: 10, loss: 0.00708688423037529
step: 20, loss: 0.06581087410449982
step: 30, loss: 0.0036416819784790277
step: 40, loss: 0.02448093704879284
step: 50, loss: 0.041833169758319855
step: 60, loss: 0.062394045293331146
step: 70, loss: 0.024661310017108917
step: 80, loss: 0.0018182797357439995
step: 90, loss: 0.028394006192684174
step: 100, loss: 0.0494285449385643
step: 110, loss: 7.047164399409667e-05
step: 120, loss: 0.013746554963290691
step: 130, loss: 2.6090474420925602e-05
step: 140, loss: 0.01731928065419197
step: 150, loss: 0.07092748582363129
step: 160, loss: 0.0035183769650757313
step: 170, loss: 0.03999986872076988
step: 180, loss: 0.06876059621572495
step: 190, loss: 0.025435302406549454
step: 200, loss: 0.04186481609940529
step: 210, loss: 0.04420628771185875
step: 220, loss: 0.02767978608608246
step: 230, loss: 0.014337003231048584
step: 240, loss: 0.0333341583609581
step: 250, loss: 0.06082916632294655
step: 260, loss: 0.0004087967681698501
step: 270, loss: 0.017079727724194527
step: 280, loss: 0.0001210570553666912
step: 290, loss: 0.04782669246196747
step: 300, loss: 0.03635358065366745
step: 310, loss: 0.02148812636733055
step: 320, loss: 0.004423970356583595
step: 330, loss: 5.9722631704062223e-05
step: 340, loss: 0.018469076603651047
step: 350, loss: 1.430495558452094e-05
step: 360, loss: 0.00018244516104459763
step: 370, loss: 0.016263602301478386
step: 380, loss: 0.021459488198161125
step: 390, loss: 0.050188276916742325
step: 400, loss: 0.0229972992092371
step: 410, loss: 0.023188088089227676
step: 420, loss: 0.07177318632602692
step: 430, loss: 0.0009936651913449168
step: 440, loss: 0.05929379537701607
step: 450, loss: 0.004340677056461573
step: 460, loss: 0.026694707572460175
step: 470, loss: 0.015983382239937782
step: 480, loss: 0.019894879311323166
step: 490, loss: 0.010388709604740143
step: 500, loss: 0.0037161624059081078
step: 510, loss: 0.0007305669714696705
step: 520, loss: 0.0229664109647274
step: 530, loss: 0.044695328921079636
step: 540, loss: 0.003619741415604949
step: 550, loss: 0.04075419157743454
step: 560, loss: 0.026073317974805832
step: 570, loss: 0.03178097680211067
step: 580, loss: 8.078174869297072e-05
step: 590, loss: 0.08543741703033447
step: 600, loss: 0.0027898168191313744
step: 610, loss: 0.0018023402662947774
step: 620, loss: 0.0001080232032109052
step: 630, loss: 0.06184926629066467
step: 640, loss: 0.05443920940160751
step: 650, loss: 0.01384244579821825
step: 660, loss: 0.05253415182232857
step: 670, loss: 0.11070018261671066
step: 680, loss: 0.041022732853889465
step: 690, loss: 0.002448671031743288
step: 700, loss: 0.04889171943068504
step: 710, loss: 0.001880001393146813
step: 720, loss: 0.0076627712696790695
step: 730, loss: 0.01906157284975052
step: 740, loss: 0.02347937598824501
step: 750, loss: 0.0027683652006089687
step: 760, loss: 0.02360774204134941
step: 770, loss: 0.020076066255569458
step: 780, loss: 0.030435362830758095
step: 790, loss: 0.004005751572549343
step: 800, loss: 0.02244662307202816
step: 810, loss: 0.06715956330299377
step: 820, loss: 0.026885736733675003
step: 830, loss: 0.004486143589019775
step: 840, loss: 0.015534071251749992
step: 850, loss: 0.0022132399026304483
step: 860, loss: 0.027675770223140717
step: 870, loss: 0.011973777785897255
step: 880, loss: 0.08383594453334808
step: 890, loss: 0.04023471847176552
step: 900, loss: 0.01640678010880947
step: 910, loss: 0.0016304932069033384
step: 920, loss: 0.07027450948953629
step: 930, loss: 0.008784739300608635
step: 940, loss: 0.04614822566509247
step: 950, loss: 0.048599328845739365
step: 960, loss: 0.05748704820871353
step: 970, loss: 1.5076025192684028e-05
step: 980, loss: 0.029713977128267288
step: 990, loss: 0.030784592032432556
step: 1000, loss: 0.043623458594083786
step: 1010, loss: 4.135088965995237e-05
step: 1020, loss: 0.03514040634036064
step: 1030, loss: 0.003572063520550728
step: 1040, loss: 3.2877433113753796e-05
step: 1050, loss: 5.147114643477835e-05
step: 1060, loss: 0.0026528502348810434
step: 1070, loss: 0.1359734833240509
epoch 14: dev_f1=0.9302752293577982, f1=0.934065934065934, best_f1=0.9375
step: 0, loss: 0.039315689355134964
step: 10, loss: 1.702426561678294e-05
step: 20, loss: 6.941123137949035e-05
step: 30, loss: 0.05984015017747879
step: 40, loss: 0.05354117974638939
step: 50, loss: 0.022131210193037987
step: 60, loss: 0.029179580509662628
step: 70, loss: 0.010735118761658669
step: 80, loss: 0.014587175101041794
step: 90, loss: 0.03317169100046158
step: 100, loss: 0.029570478945970535
step: 110, loss: 0.026915820315480232
step: 120, loss: 0.006924283690750599
step: 130, loss: 0.0030567622743546963
step: 140, loss: 0.05097568407654762
step: 150, loss: 0.025556588545441628
step: 160, loss: 0.007571591529995203
step: 170, loss: 0.010662449523806572
step: 180, loss: 0.018071027472615242
step: 190, loss: 0.017166776582598686
step: 200, loss: 0.053071871399879456
step: 210, loss: 1.282606172026135e-05
step: 220, loss: 0.23831792175769806
step: 230, loss: 8.483080455334857e-05
step: 240, loss: 0.09793354570865631
step: 250, loss: 0.05116666853427887
step: 260, loss: 0.0063920230604708195
step: 270, loss: 0.030768612399697304
step: 280, loss: 4.0398273995378986e-05
step: 290, loss: 0.022441759705543518
step: 300, loss: 0.00044583651470020413
step: 310, loss: 0.046524591743946075
step: 320, loss: 0.036955371499061584
step: 330, loss: 0.003479556879028678
step: 340, loss: 0.0027623530477285385
step: 350, loss: 0.0724995881319046
step: 360, loss: 0.07572543621063232
step: 370, loss: 0.01774841547012329
step: 380, loss: 0.04347958788275719
step: 390, loss: 0.007540525868535042
step: 400, loss: 0.004804963245987892
step: 410, loss: 0.01431911438703537
step: 420, loss: 0.02928236871957779
step: 430, loss: 0.00024060277792159468
step: 440, loss: 0.09258024394512177
step: 450, loss: 0.03389991819858551
step: 460, loss: 0.07892844080924988
step: 470, loss: 0.004639993421733379
step: 480, loss: 0.1305384337902069
step: 490, loss: 0.002584443660452962
step: 500, loss: 4.608955714502372e-05
step: 510, loss: 0.05365127697587013
step: 520, loss: 7.404250209219754e-05
step: 530, loss: 0.00018955994164571166
step: 540, loss: 0.020489847287535667
step: 550, loss: 0.012717329896986485
step: 560, loss: 5.398170469561592e-05
step: 570, loss: 0.006370618473738432
step: 580, loss: 5.211484312894754e-05
step: 590, loss: 1.34220790641848e-05
step: 600, loss: 0.048410166054964066
step: 610, loss: 0.07339856028556824
step: 620, loss: 0.021553393453359604
step: 630, loss: 0.020733388140797615
step: 640, loss: 0.05645305663347244
step: 650, loss: 2.8790374926757067e-05
step: 660, loss: 0.045733798295259476
step: 670, loss: 0.021798966452479362
step: 680, loss: 0.0222392026335001
step: 690, loss: 0.05924016982316971
step: 700, loss: 0.00011283215280855075
step: 710, loss: 0.07774300873279572
step: 720, loss: 0.013644805178046227
step: 730, loss: 0.012139666825532913
step: 740, loss: 0.029006190598011017
step: 750, loss: 0.036084093153476715
step: 760, loss: 0.04468589648604393
step: 770, loss: 0.04932790994644165
step: 780, loss: 0.06277698278427124
step: 790, loss: 0.0754939466714859
step: 800, loss: 0.09531313180923462
step: 810, loss: 0.0030204306822270155
step: 820, loss: 0.02392151579260826
step: 830, loss: 0.02410426363348961
step: 840, loss: 0.011262069456279278
step: 850, loss: 0.02569575048983097
step: 860, loss: 0.00010383089102106169
step: 870, loss: 0.061286985874176025
step: 880, loss: 0.036411553621292114
step: 890, loss: 0.035366132855415344
step: 900, loss: 0.06650031358003616
step: 910, loss: 0.09016736596822739
step: 920, loss: 0.0039031491614878178
step: 930, loss: 0.04329966753721237
step: 940, loss: 1.935626642080024e-05
step: 950, loss: 0.006743222009390593
step: 960, loss: 0.07652462273836136
step: 970, loss: 0.00017355146701447666
step: 980, loss: 0.06624666601419449
step: 990, loss: 0.023266730830073357
step: 1000, loss: 5.492867057910189e-05
step: 1010, loss: 0.007645795121788979
step: 1020, loss: 0.03632359951734543
step: 1030, loss: 0.05389973521232605
step: 1040, loss: 0.00017163113807328045
step: 1050, loss: 0.09689720720052719
step: 1060, loss: 0.05081496760249138
step: 1070, loss: 0.06716664880514145
epoch 15: dev_f1=0.9376989540700319, f1=0.9347234814143245, best_f1=0.9375
step: 0, loss: 0.00921444408595562
step: 10, loss: 0.05496734380722046
step: 20, loss: 0.021330615505576134
step: 30, loss: 0.016093270853161812
step: 40, loss: 0.022743668407201767
step: 50, loss: 1.244608483830234e-05
step: 60, loss: 0.044641926884651184
step: 70, loss: 0.03154675289988518
step: 80, loss: 0.025227464735507965
step: 90, loss: 0.0001818614109652117
step: 100, loss: 0.0001641781273065135
step: 110, loss: 0.00026067349244840443
step: 120, loss: 0.06368320435285568
step: 130, loss: 0.02143600769340992
step: 140, loss: 0.02119627594947815
step: 150, loss: 0.0007871382404118776
step: 160, loss: 0.028515882790088654
step: 170, loss: 2.0108591343159787e-05
step: 180, loss: 2.0976194718969055e-05
step: 190, loss: 0.04524718225002289
step: 200, loss: 0.11860199272632599
step: 210, loss: 0.04174632579088211
step: 220, loss: 0.04776778444647789
step: 230, loss: 0.04589318111538887
step: 240, loss: 0.02030804380774498
step: 250, loss: 0.047283172607421875
step: 260, loss: 0.040373653173446655
step: 270, loss: 0.04024215787649155
step: 280, loss: 0.04524056240916252
step: 290, loss: 0.0028225011192262173
step: 300, loss: 0.033268239349126816
step: 310, loss: 0.014540712349116802
step: 320, loss: 0.04752631112933159
step: 330, loss: 0.04349894821643829
step: 340, loss: 0.05391527712345123
step: 350, loss: 0.08252709358930588
step: 360, loss: 0.02248222753405571
step: 370, loss: 0.02502315677702427
step: 380, loss: 0.01377965323626995
step: 390, loss: 0.02464967593550682
step: 400, loss: 0.0431646890938282
step: 410, loss: 0.0028020148165524006
step: 420, loss: 0.004660171922296286
step: 430, loss: 0.088422492146492
step: 440, loss: 0.006394427269697189
step: 450, loss: 0.021255385130643845
step: 460, loss: 0.00110957445576787
step: 470, loss: 0.054232366383075714
step: 480, loss: 0.014191698282957077
step: 490, loss: 0.06506303697824478
step: 500, loss: 0.03670690208673477
step: 510, loss: 0.016551939770579338
step: 520, loss: 0.006402133032679558
step: 530, loss: 0.03643534332513809
step: 540, loss: 0.00024084467440843582
step: 550, loss: 0.0789569690823555
step: 560, loss: 0.023835228756070137
step: 570, loss: 0.03242676705121994
step: 580, loss: 0.011595828458666801
step: 590, loss: 0.04422733932733536
step: 600, loss: 0.030665665864944458
step: 610, loss: 0.0694367066025734
step: 620, loss: 0.003686649492010474
step: 630, loss: 0.017959842458367348
step: 640, loss: 0.02400515042245388
step: 650, loss: 0.03955827280879021
step: 660, loss: 0.10204821825027466
step: 670, loss: 0.00050538923824206
step: 680, loss: 0.028489338234066963
step: 690, loss: 0.06572485715150833
step: 700, loss: 0.045458536595106125
step: 710, loss: 0.018504630774259567
step: 720, loss: 0.024905528873205185
step: 730, loss: 0.03416772931814194
step: 740, loss: 0.02396717108786106
step: 750, loss: 0.030212832614779472
step: 760, loss: 0.019068488851189613
step: 770, loss: 0.01232489850372076
step: 780, loss: 0.013967900536954403
step: 790, loss: 0.024060864001512527
step: 800, loss: 0.06258700042963028
step: 810, loss: 0.09146332740783691
step: 820, loss: 0.02876916341483593
step: 830, loss: 1.9531136786099523e-05
step: 840, loss: 0.04493296891450882
step: 850, loss: 0.03871949389576912
step: 860, loss: 0.02715017832815647
step: 870, loss: 0.05255753546953201
step: 880, loss: 0.002175046131014824
step: 890, loss: 0.03092334419488907
step: 900, loss: 3.808151086559519e-05
step: 910, loss: 0.04391072317957878
step: 920, loss: 0.04070940241217613
step: 930, loss: 0.06208943948149681
step: 940, loss: 0.09933048486709595
step: 950, loss: 8.831209561321884e-05
step: 960, loss: 0.026770444586873055
step: 970, loss: 0.03599327430129051
step: 980, loss: 0.017478756606578827
step: 990, loss: 0.04141489788889885
step: 1000, loss: 0.0010445285588502884
step: 1010, loss: 0.01831417717039585
step: 1020, loss: 0.0012048209318891168
step: 1030, loss: 0.08706607669591904
step: 1040, loss: 0.001200688537210226
step: 1050, loss: 0.021123839542269707
step: 1060, loss: 0.0609697587788105
step: 1070, loss: 0.0015055765397846699
epoch 16: dev_f1=0.9288040949278734, f1=0.9266480965645311, best_f1=0.9375
step: 0, loss: 0.022944927215576172
step: 10, loss: 0.06187497824430466
step: 20, loss: 0.039902687072753906
step: 30, loss: 0.010554277338087559
step: 40, loss: 4.083920066477731e-05
step: 50, loss: 0.019328312948346138
step: 60, loss: 0.02078627049922943
step: 70, loss: 0.07093186676502228
step: 80, loss: 0.056534599512815475
step: 90, loss: 0.041977304965257645
step: 100, loss: 0.031153466552495956
step: 110, loss: 0.019779495894908905
step: 120, loss: 0.023328300565481186
step: 130, loss: 0.024085527285933495
step: 140, loss: 0.00021770450985059142
step: 150, loss: 1.6457623132737353e-05
step: 160, loss: 0.002267066854983568
step: 170, loss: 4.1064929973799735e-05
step: 180, loss: 0.027347074821591377
step: 190, loss: 2.2622847609454766e-05
step: 200, loss: 0.07891815155744553
step: 210, loss: 0.007284119259566069
step: 220, loss: 1.602224620000925e-05
step: 230, loss: 1.2207653526274953e-05
step: 240, loss: 0.016456371173262596
step: 250, loss: 0.022482145577669144
step: 260, loss: 0.0068656872026622295
step: 270, loss: 0.0031346098985522985
step: 280, loss: 0.0015300678787752986
step: 290, loss: 1.1306180567771662e-05
step: 300, loss: 1.7288697563344613e-05
step: 310, loss: 0.026140328496694565
step: 320, loss: 0.017161063849925995
step: 330, loss: 0.002901748288422823
step: 340, loss: 5.14131534146145e-05
step: 350, loss: 0.0005722881178371608
step: 360, loss: 0.02779380790889263
step: 370, loss: 0.027673203498125076
step: 380, loss: 0.0008039454114623368
step: 390, loss: 7.178407395258546e-05
step: 400, loss: 0.026102634146809578
step: 410, loss: 0.06465829163789749
step: 420, loss: 0.014810696244239807
step: 430, loss: 0.034064944833517075
step: 440, loss: 0.002484728815034032
step: 450, loss: 0.04494180157780647
step: 460, loss: 0.017807919532060623
step: 470, loss: 0.01705729402601719
step: 480, loss: 0.031185179948806763
step: 490, loss: 0.030942879617214203
step: 500, loss: 6.728181324433535e-05
step: 510, loss: 0.00011978069960605353
step: 520, loss: 0.04521343484520912
step: 530, loss: 0.004064704291522503
step: 540, loss: 1.1138532499899156e-05
step: 550, loss: 1.6301530195050873e-05
step: 560, loss: 0.023673752322793007
step: 570, loss: 0.0005822679377160966
step: 580, loss: 0.02391968108713627
step: 590, loss: 0.022246913984417915
step: 600, loss: 0.04925485700368881
step: 610, loss: 0.039979711174964905
step: 620, loss: 0.023099098354578018
step: 630, loss: 0.03220225125551224
step: 640, loss: 0.07705088704824448
step: 650, loss: 0.06168153136968613
step: 660, loss: 0.023476246744394302
step: 670, loss: 0.13247030973434448
step: 680, loss: 0.02141084522008896
step: 690, loss: 6.559603207278997e-05
step: 700, loss: 0.006444558501243591
step: 710, loss: 0.03197511285543442
step: 720, loss: 0.06308600306510925
step: 730, loss: 4.46332705905661e-05
step: 740, loss: 1.033761327562388e-05
step: 750, loss: 2.6902247554971837e-05
step: 760, loss: 0.005927145015448332
step: 770, loss: 0.04210621491074562
step: 780, loss: 0.0933205708861351
step: 790, loss: 8.905151480576023e-05
step: 800, loss: 0.052769776433706284
step: 810, loss: 0.02186117134988308
step: 820, loss: 7.842521881684661e-05
step: 830, loss: 0.020674915984272957
step: 840, loss: 0.00230600219219923
step: 850, loss: 0.05624047666788101
step: 860, loss: 0.00502508319914341
step: 870, loss: 0.017239214852452278
step: 880, loss: 0.06256084889173508
step: 890, loss: 0.024781949818134308
step: 900, loss: 7.337820716202259e-05
step: 910, loss: 2.0845796825597063e-05
step: 920, loss: 0.000823044974822551
step: 930, loss: 0.10057226568460464
step: 940, loss: 0.02282417006790638
step: 950, loss: 0.010343980975449085
step: 960, loss: 0.06822311878204346
step: 970, loss: 0.039581943303346634
step: 980, loss: 0.03827308863401413
step: 990, loss: 0.002699183067306876
step: 1000, loss: 0.0470355823636055
step: 1010, loss: 0.037256356328725815
step: 1020, loss: 0.024511242285370827
step: 1030, loss: 0.05836911126971245
step: 1040, loss: 8.971786155598238e-05
step: 1050, loss: 0.0797237753868103
step: 1060, loss: 0.05362680181860924
step: 1070, loss: 1.3604552805190906e-05
epoch 17: dev_f1=0.931711880261927, f1=0.9302325581395349, best_f1=0.9375
step: 0, loss: 0.0414508581161499
step: 10, loss: 0.0007123266113922
step: 20, loss: 0.026678593829274178
step: 30, loss: 0.00026995569351129234
step: 40, loss: 0.03697768598794937
step: 50, loss: 0.011442477814853191
step: 60, loss: 0.012848133221268654
step: 70, loss: 0.02316177822649479
step: 80, loss: 0.08166548609733582
step: 90, loss: 0.05209621787071228
step: 100, loss: 0.005838116630911827
step: 110, loss: 0.0002858659718185663
step: 120, loss: 0.02518087439239025
step: 130, loss: 0.006308155599981546
step: 140, loss: 0.09412018954753876
step: 150, loss: 0.04512945935130119
step: 160, loss: 0.0005237131263129413
step: 170, loss: 0.025781575590372086
step: 180, loss: 0.1350575089454651
step: 190, loss: 0.06698533147573471
step: 200, loss: 0.011114466935396194
step: 210, loss: 0.020421573892235756
step: 220, loss: 4.0035938582150266e-05
step: 230, loss: 4.5817167119821534e-05
step: 240, loss: 0.040616974234580994
step: 250, loss: 0.11331023275852203
step: 260, loss: 0.01496787928044796
step: 270, loss: 0.07386931777000427
step: 280, loss: 0.0226361732929945
step: 290, loss: 9.081630560103804e-05
step: 300, loss: 4.3717991502489895e-05
step: 310, loss: 0.008491912856698036
step: 320, loss: 0.04672970250248909
step: 330, loss: 2.2175623598741367e-05
step: 340, loss: 3.328463208163157e-05
step: 350, loss: 0.019681362435221672
step: 360, loss: 0.03363954648375511
step: 370, loss: 0.13458335399627686
step: 380, loss: 1.9657143639051355e-05
step: 390, loss: 0.009847737848758698
step: 400, loss: 2.0499692254816182e-05
step: 410, loss: 0.03945767134428024
step: 420, loss: 0.024808472022414207
step: 430, loss: 5.115985550219193e-05
step: 440, loss: 0.03595708683133125
step: 450, loss: 0.024965353310108185
step: 460, loss: 0.27212151885032654
step: 470, loss: 8.40750290080905e-05
step: 480, loss: 0.06371819972991943
step: 490, loss: 0.02389797382056713
step: 500, loss: 0.00017005117842927575
step: 510, loss: 7.66189768910408e-05
step: 520, loss: 0.03828012943267822
step: 530, loss: 0.03015635907649994
step: 540, loss: 0.001003278186544776
step: 550, loss: 4.168141822447069e-05
step: 560, loss: 0.046131432056427
step: 570, loss: 0.011274462565779686
step: 580, loss: 0.00017156015383079648
step: 590, loss: 0.02577788196504116
step: 600, loss: 0.002650950802490115
step: 610, loss: 9.209389827447012e-05
step: 620, loss: 0.06551486253738403
step: 630, loss: 3.9715319871902466e-05
step: 640, loss: 0.05455193668603897
step: 650, loss: 0.045324284583330154
step: 660, loss: 0.022119620814919472
step: 670, loss: 0.0170113667845726
step: 680, loss: 0.018820244818925858
step: 690, loss: 0.048287149518728256
step: 700, loss: 0.05326351523399353
step: 710, loss: 0.0716547891497612
step: 720, loss: 0.017463866621255875
step: 730, loss: 1.225235428137239e-05
step: 740, loss: 0.05308684706687927
step: 750, loss: 0.018553627654910088
step: 760, loss: 1.398082258674549e-05
step: 770, loss: 8.648943185107782e-05
step: 780, loss: 0.03679601103067398
step: 790, loss: 3.107911834376864e-05
step: 800, loss: 0.045648910105228424
step: 810, loss: 0.0002445720019750297
step: 820, loss: 0.0020986096933484077
step: 830, loss: 0.02856750413775444
step: 840, loss: 0.07774977385997772
step: 850, loss: 3.147724419250153e-05
step: 860, loss: 1.3712599866266828e-05
step: 870, loss: 0.03545290231704712
step: 880, loss: 6.079598097130656e-05
step: 890, loss: 0.007793889846652746
step: 900, loss: 0.02993939071893692
step: 910, loss: 0.01569593884050846
step: 920, loss: 0.0007464110967703164
step: 930, loss: 0.01789499819278717
step: 940, loss: 2.486392440914642e-05
step: 950, loss: 0.026667505502700806
step: 960, loss: 0.13895480334758759
step: 970, loss: 0.0267312191426754
step: 980, loss: 0.09424295276403427
step: 990, loss: 0.03547172248363495
step: 1000, loss: 0.040741488337516785
step: 1010, loss: 0.02152823656797409
step: 1020, loss: 0.024027248844504356
step: 1030, loss: 0.024931633844971657
step: 1040, loss: 0.01492859236896038
step: 1050, loss: 0.04361638054251671
step: 1060, loss: 1.994456943066325e-05
step: 1070, loss: 0.0951266661286354
epoch 18: dev_f1=0.9312267657992565, f1=0.9321016166281756, best_f1=0.9375
step: 0, loss: 0.024257320910692215
step: 10, loss: 2.398598735453561e-05
step: 20, loss: 0.017479967325925827
step: 30, loss: 0.04322656989097595
step: 40, loss: 0.008279846981167793
step: 50, loss: 0.09113527089357376
step: 60, loss: 0.08027137070894241
step: 70, loss: 0.07011968642473221
step: 80, loss: 0.03462835028767586
step: 90, loss: 0.05431465432047844
step: 100, loss: 0.048293158411979675
step: 110, loss: 0.0005395989865064621
step: 120, loss: 0.0001931410952238366
step: 130, loss: 0.023534907028079033
step: 140, loss: 0.05981629714369774
step: 150, loss: 0.00010389114322606474
step: 160, loss: 0.0630321279168129
step: 170, loss: 0.019491463899612427
step: 180, loss: 0.03088652715086937
step: 190, loss: 0.017048459500074387
step: 200, loss: 0.027320683002471924
step: 210, loss: 6.027067138347775e-05
step: 220, loss: 0.023667121306061745
step: 230, loss: 0.020077886059880257
step: 240, loss: 0.043573521077632904
step: 250, loss: 0.05797648802399635
step: 260, loss: 0.0028764756862074137
step: 270, loss: 0.10203999280929565
step: 280, loss: 0.014548749662935734
step: 290, loss: 0.0210721492767334
step: 300, loss: 0.018079586327075958
step: 310, loss: 0.046186864376068115
step: 320, loss: 1.1499878382892348e-05
step: 330, loss: 0.03198658302426338
step: 340, loss: 0.07627984881401062
step: 350, loss: 0.06942539662122726
step: 360, loss: 0.0090523362159729
step: 370, loss: 0.023268433287739754
step: 380, loss: 2.401961864961777e-05
step: 390, loss: 0.01769411936402321
step: 400, loss: 1.0646809641912114e-05
step: 410, loss: 0.03729541227221489
step: 420, loss: 0.019888514652848244
step: 430, loss: 0.05644834041595459
step: 440, loss: 2.921004306699615e-05
step: 450, loss: 0.000656330434139818
step: 460, loss: 0.02049212157726288
step: 470, loss: 0.02879708632826805
step: 480, loss: 0.023750633001327515
step: 490, loss: 1.5560044630547054e-05
step: 500, loss: 0.00013287992624100298
step: 510, loss: 0.0625600516796112
step: 520, loss: 0.024161547422409058
step: 530, loss: 0.011514225043356419
step: 540, loss: 0.02386205457150936
step: 550, loss: 0.0228053480386734
step: 560, loss: 1.9926172171835788e-05
step: 570, loss: 1.9512583094183356e-05
step: 580, loss: 0.023310264572501183
step: 590, loss: 0.09449080377817154
step: 600, loss: 0.00023311331460718066
step: 610, loss: 0.0009882677113637328
step: 620, loss: 2.3207763661048375e-05
step: 630, loss: 0.06679859012365341
step: 640, loss: 0.07645966112613678
step: 650, loss: 0.06785067915916443
step: 660, loss: 0.05226989462971687
step: 670, loss: 2.7248939659330063e-05
step: 680, loss: 2.4454802769469097e-05
step: 690, loss: 0.031024929136037827
step: 700, loss: 0.028128420934081078
step: 710, loss: 1.3090545508021023e-05
step: 720, loss: 0.04810735583305359
step: 730, loss: 0.040855035185813904
step: 740, loss: 0.018644971773028374
step: 750, loss: 0.04024886712431908
step: 760, loss: 0.0378088541328907
step: 770, loss: 0.03733455762267113
step: 780, loss: 2.1792337065562606e-05
step: 790, loss: 0.053193073719739914
step: 800, loss: 0.00016511158901266754
step: 810, loss: 0.0005477105733007193
step: 820, loss: 0.031647372990846634
step: 830, loss: 0.011178589425981045
step: 840, loss: 0.04511483758687973
step: 850, loss: 0.030280563980340958
step: 860, loss: 0.055973704904317856
step: 870, loss: 0.00013324531028047204
step: 880, loss: 0.028059091418981552
step: 890, loss: 3.7942107155686244e-05
step: 900, loss: 1.9419449017732404e-05
step: 910, loss: 0.00020457284699659795
step: 920, loss: 0.0003889781655743718
step: 930, loss: 3.587612809496932e-05
step: 940, loss: 0.03656480461359024
step: 950, loss: 8.51783188409172e-05
step: 960, loss: 0.031324777752161026
step: 970, loss: 0.07655195891857147
step: 980, loss: 0.026317700743675232
step: 990, loss: 2.920080987678375e-05
step: 1000, loss: 0.005061951465904713
step: 1010, loss: 0.09776083379983902
step: 1020, loss: 0.00035462260711938143
step: 1030, loss: 0.023820219561457634
step: 1040, loss: 0.026910386979579926
step: 1050, loss: 0.01425160001963377
step: 1060, loss: 0.012990192510187626
step: 1070, loss: 2.667065018613357e-05
epoch 19: dev_f1=0.9293023255813954, f1=0.9278445883441258, best_f1=0.9375
step: 0, loss: 0.02110004797577858
step: 10, loss: 0.00018896214896813035
step: 20, loss: 0.0007922226213850081
step: 30, loss: 0.05960211530327797
step: 40, loss: 3.333126369398087e-05
step: 50, loss: 0.02168124169111252
step: 60, loss: 0.07762350887060165
step: 70, loss: 0.0006990545080043375
step: 80, loss: 1.6465466615045443e-05
step: 90, loss: 1.5552828699583188e-05
step: 100, loss: 3.5743909393204376e-05
step: 110, loss: 0.029912132769823074
step: 120, loss: 0.06526689976453781
step: 130, loss: 5.5072880059015006e-05
step: 140, loss: 7.035702583380044e-05
step: 150, loss: 8.952547796070576e-05
step: 160, loss: 0.023600086569786072
step: 170, loss: 0.018918147310614586
step: 180, loss: 5.639465234708041e-05
step: 190, loss: 0.0024257635232061148
step: 200, loss: 0.03315194696187973
step: 210, loss: 1.8272085071657784e-05
step: 220, loss: 0.02110244706273079
step: 230, loss: 0.050693415105342865
step: 240, loss: 0.025883208960294724
step: 250, loss: 0.018830429762601852
step: 260, loss: 0.015431193634867668
step: 270, loss: 0.015507590025663376
step: 280, loss: 0.0004936852492392063
step: 290, loss: 5.237111690803431e-05
step: 300, loss: 0.017073972150683403
step: 310, loss: 0.0007748770294710994
step: 320, loss: 0.00822582095861435
step: 330, loss: 0.0009289267472922802
step: 340, loss: 0.012321221642196178
step: 350, loss: 0.04837508499622345
step: 360, loss: 0.042226891964673996
step: 370, loss: 0.03537196293473244
step: 380, loss: 0.00031629198929294944
step: 390, loss: 0.016045335680246353
step: 400, loss: 0.0195575300604105
step: 410, loss: 0.03967119753360748
step: 420, loss: 0.01699920743703842
step: 430, loss: 0.02415098063647747
step: 440, loss: 2.2481042833533138e-05
step: 450, loss: 0.0015803329879418015
step: 460, loss: 0.08691748976707458
step: 470, loss: 0.021905051544308662
step: 480, loss: 0.03751711547374725
step: 490, loss: 0.045724935829639435
step: 500, loss: 0.022016525268554688
step: 510, loss: 0.00013572859461419284
step: 520, loss: 0.02424701675772667
step: 530, loss: 0.04780444875359535
step: 540, loss: 0.00014351932622957975
step: 550, loss: 0.022430449724197388
step: 560, loss: 4.965124753653072e-05
step: 570, loss: 7.994116458576173e-05
step: 580, loss: 3.0474955565296113e-05
step: 590, loss: 0.0013371928362175822
step: 600, loss: 0.00013796478742733598
step: 610, loss: 0.03761369362473488
step: 620, loss: 0.0900527611374855
step: 630, loss: 0.08108609914779663
step: 640, loss: 0.0023039199877530336
step: 650, loss: 1.9758321286644787e-05
step: 660, loss: 0.01402100920677185
step: 670, loss: 0.01719636470079422
step: 680, loss: 0.057679615914821625
step: 690, loss: 0.021252335980534554
step: 700, loss: 0.04228254035115242
step: 710, loss: 0.040427058935165405
step: 720, loss: 0.03948787599802017
step: 730, loss: 0.0353425107896328
step: 740, loss: 0.023428548127412796
step: 750, loss: 4.0042083128355443e-05
step: 760, loss: 1.579126728756819e-05
step: 770, loss: 0.02262558601796627
step: 780, loss: 0.016956474632024765
step: 790, loss: 0.021243739873170853
step: 800, loss: 0.03923667594790459
step: 810, loss: 1.8096801795763895e-05
step: 820, loss: 5.9685939049813896e-05
step: 830, loss: 0.0962333232164383
step: 840, loss: 0.0002070496411761269
step: 850, loss: 0.060324907302856445
step: 860, loss: 0.01723126508295536
step: 870, loss: 0.044260505586862564
step: 880, loss: 0.001996828941628337
step: 890, loss: 2.7274354579276405e-05
step: 900, loss: 0.10607144236564636
step: 910, loss: 0.000955953961238265
step: 920, loss: 0.0393843837082386
step: 930, loss: 0.047581881284713745
step: 940, loss: 0.05406767129898071
step: 950, loss: 0.04227408766746521
step: 960, loss: 1.613026688573882e-05
step: 970, loss: 1.895386776595842e-05
step: 980, loss: 0.03004453517496586
step: 990, loss: 0.0002252811100333929
step: 1000, loss: 0.0250046718865633
step: 1010, loss: 0.030832596123218536
step: 1020, loss: 0.02558865398168564
step: 1030, loss: 0.0017389958957210183
step: 1040, loss: 0.05210252106189728
step: 1050, loss: 0.014553372748196125
step: 1060, loss: 0.020264090970158577
step: 1070, loss: 0.09038865566253662
epoch 20: dev_f1=0.929472209248015, f1=0.9272137227630968, best_f1=0.9375
