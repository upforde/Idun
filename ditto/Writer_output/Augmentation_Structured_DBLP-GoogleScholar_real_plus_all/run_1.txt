cuda
Device: cuda
step: 0, loss: 0.6607308387756348
step: 10, loss: 0.49289634823799133
step: 20, loss: 0.6303661465644836
step: 30, loss: 0.4830513596534729
step: 40, loss: 0.43678590655326843
step: 50, loss: 0.49974459409713745
step: 60, loss: 0.2319359928369522
step: 70, loss: 0.22205878794193268
step: 80, loss: 0.3584393560886383
step: 90, loss: 0.3572298586368561
step: 100, loss: 0.30538561940193176
step: 110, loss: 0.1944265067577362
step: 120, loss: 0.09451203793287277
step: 130, loss: 0.31008341908454895
step: 140, loss: 0.1920224130153656
step: 150, loss: 0.08736005425453186
step: 160, loss: 0.15598241984844208
step: 170, loss: 0.21021609008312225
step: 180, loss: 0.18950779736042023
step: 190, loss: 0.13555876910686493
step: 200, loss: 0.1795416921377182
step: 210, loss: 0.19016072154045105
step: 220, loss: 0.11415503174066544
step: 230, loss: 0.3004703223705292
step: 240, loss: 0.10012627393007278
step: 250, loss: 0.1334439069032669
step: 260, loss: 0.22782333195209503
step: 270, loss: 0.2579135298728943
step: 280, loss: 0.1423613727092743
step: 290, loss: 0.19576597213745117
step: 300, loss: 0.04122335463762283
step: 310, loss: 0.2512093782424927
step: 320, loss: 0.09270065277814865
step: 330, loss: 0.4106103479862213
step: 340, loss: 0.3017815947532654
step: 350, loss: 0.11371785402297974
step: 360, loss: 0.11335878074169159
step: 370, loss: 0.16244107484817505
step: 380, loss: 0.23335066437721252
step: 390, loss: 0.04388204216957092
step: 400, loss: 0.12779095768928528
step: 410, loss: 0.15348386764526367
step: 420, loss: 0.05198035016655922
step: 430, loss: 0.20017214119434357
step: 440, loss: 0.09394313395023346
step: 450, loss: 0.45885786414146423
step: 460, loss: 0.1594766527414322
step: 470, loss: 0.015095940791070461
step: 480, loss: 0.1748410165309906
step: 490, loss: 0.30699101090431213
step: 500, loss: 0.1462254524230957
step: 510, loss: 0.1651662141084671
step: 520, loss: 0.21525421738624573
step: 530, loss: 0.18008799850940704
step: 540, loss: 0.21738936007022858
step: 550, loss: 0.0849638432264328
step: 560, loss: 0.03074456751346588
step: 570, loss: 0.06410345435142517
step: 580, loss: 0.13863319158554077
step: 590, loss: 0.08452728390693665
step: 600, loss: 0.21160967648029327
step: 610, loss: 0.04891987144947052
step: 620, loss: 0.01993318274617195
step: 630, loss: 0.06145038083195686
step: 640, loss: 0.198327898979187
step: 650, loss: 0.06351657956838608
step: 660, loss: 0.15685486793518066
step: 670, loss: 0.17784874141216278
step: 680, loss: 0.05829520523548126
step: 690, loss: 0.18564382195472717
step: 700, loss: 0.1036381796002388
step: 710, loss: 0.24431343376636505
step: 720, loss: 0.08866593986749649
step: 730, loss: 0.029398543760180473
step: 740, loss: 0.09061471372842789
step: 750, loss: 0.05440719425678253
step: 760, loss: 0.19883301854133606
step: 770, loss: 0.062395691871643066
step: 780, loss: 0.1569512039422989
step: 790, loss: 0.04865254461765289
step: 800, loss: 0.12300103157758713
step: 810, loss: 0.016184497624635696
step: 820, loss: 0.03791366145014763
step: 830, loss: 0.11325565725564957
step: 840, loss: 0.09520713984966278
step: 850, loss: 0.061255551874637604
step: 860, loss: 0.11637880653142929
step: 870, loss: 0.03320905193686485
step: 880, loss: 0.0953364446759224
step: 890, loss: 0.07916844636201859
step: 900, loss: 0.03814283013343811
step: 910, loss: 0.1450667828321457
step: 920, loss: 0.028831467032432556
step: 930, loss: 0.0701901912689209
step: 940, loss: 0.10269640386104584
step: 950, loss: 0.07354756444692612
step: 960, loss: 0.08468855917453766
step: 970, loss: 0.12323761731386185
step: 980, loss: 0.19718359410762787
step: 990, loss: 0.08266684412956238
step: 1000, loss: 0.06110076233744621
step: 1010, loss: 0.055454980581998825
step: 1020, loss: 0.15736353397369385
step: 1030, loss: 0.08313549309968948
step: 1040, loss: 0.006990934256464243
step: 1050, loss: 0.018489506095647812
step: 1060, loss: 0.007450100500136614
step: 1070, loss: 0.1738450825214386
epoch 1: dev_f1=0.9273640931932389, f1=0.9302961275626425, best_f1=0.9302961275626425
step: 0, loss: 0.11356280744075775
step: 10, loss: 0.05330177769064903
step: 20, loss: 0.10280869156122208
step: 30, loss: 0.07133034616708755
step: 40, loss: 0.05737325921654701
step: 50, loss: 0.06818239390850067
step: 60, loss: 0.06871794909238815
step: 70, loss: 0.1501854509115219
step: 80, loss: 0.02583393268287182
step: 90, loss: 0.02865341119468212
step: 100, loss: 0.013158543966710567
step: 110, loss: 0.016644325107336044
step: 120, loss: 0.03225709870457649
step: 130, loss: 0.14103978872299194
step: 140, loss: 0.2262204885482788
step: 150, loss: 0.09214423596858978
step: 160, loss: 0.030456632375717163
step: 170, loss: 0.1598406881093979
step: 180, loss: 0.12721110880374908
step: 190, loss: 0.03695167973637581
step: 200, loss: 0.09067026525735855
step: 210, loss: 0.010537134483456612
step: 220, loss: 0.12223020195960999
step: 230, loss: 0.11701470613479614
step: 240, loss: 0.09988387674093246
step: 250, loss: 0.051785774528980255
step: 260, loss: 0.14722999930381775
step: 270, loss: 0.0573575496673584
step: 280, loss: 0.0558227002620697
step: 290, loss: 0.006987832952290773
step: 300, loss: 0.017944931983947754
step: 310, loss: 0.1401122808456421
step: 320, loss: 0.13183166086673737
step: 330, loss: 0.07081177085638046
step: 340, loss: 0.18818062543869019
step: 350, loss: 0.0953419953584671
step: 360, loss: 0.012299243360757828
step: 370, loss: 0.048061393201351166
step: 380, loss: 0.1257120817899704
step: 390, loss: 0.11819320172071457
step: 400, loss: 0.07955837994813919
step: 410, loss: 0.0930473580956459
step: 420, loss: 0.07468877732753754
step: 430, loss: 0.11598819494247437
step: 440, loss: 0.1828140914440155
step: 450, loss: 0.07494042068719864
step: 460, loss: 0.04146668687462807
step: 470, loss: 0.07632595300674438
step: 480, loss: 0.041468821465969086
step: 490, loss: 0.21414320170879364
step: 500, loss: 0.2480878233909607
step: 510, loss: 0.18241913616657257
step: 520, loss: 0.03406138718128204
step: 530, loss: 0.15060055255889893
step: 540, loss: 0.020424094051122665
step: 550, loss: 0.07587114721536636
step: 560, loss: 0.20828504860401154
step: 570, loss: 0.07508662343025208
step: 580, loss: 0.10566962510347366
step: 590, loss: 0.03142827749252319
step: 600, loss: 0.025816291570663452
step: 610, loss: 0.017440473660826683
step: 620, loss: 0.06511785835027695
step: 630, loss: 0.22116252779960632
step: 640, loss: 0.0659673660993576
step: 650, loss: 0.04991680383682251
step: 660, loss: 0.09368336200714111
step: 670, loss: 0.10158608853816986
step: 680, loss: 0.025486452504992485
step: 690, loss: 0.06768454611301422
step: 700, loss: 0.09399273246526718
step: 710, loss: 0.07701414078474045
step: 720, loss: 0.1579800248146057
step: 730, loss: 0.0661245584487915
step: 740, loss: 0.04204430803656578
step: 750, loss: 0.0574553981423378
step: 760, loss: 0.06604310125112534
step: 770, loss: 0.02389741875231266
step: 780, loss: 0.03121917136013508
step: 790, loss: 0.16501779854297638
step: 800, loss: 0.23515290021896362
step: 810, loss: 0.10235767066478729
step: 820, loss: 0.12911473214626312
step: 830, loss: 0.03824082389473915
step: 840, loss: 0.020664596930146217
step: 850, loss: 0.016990002244710922
step: 860, loss: 0.12093807011842728
step: 870, loss: 0.09856672585010529
step: 880, loss: 0.08355668932199478
step: 890, loss: 0.1729435920715332
step: 900, loss: 0.05916620045900345
step: 910, loss: 0.08812417089939117
step: 920, loss: 0.17243632674217224
step: 930, loss: 0.05661937594413757
step: 940, loss: 0.01212853193283081
step: 950, loss: 0.11775895208120346
step: 960, loss: 0.08205051720142365
step: 970, loss: 0.07927937060594559
step: 980, loss: 0.0833364799618721
step: 990, loss: 0.3977926969528198
step: 1000, loss: 0.07899079471826553
step: 1010, loss: 0.07179852575063705
step: 1020, loss: 0.02746548317372799
step: 1030, loss: 0.06085004284977913
step: 1040, loss: 0.045001428574323654
step: 1050, loss: 0.01253215316683054
step: 1060, loss: 0.014228549785912037
step: 1070, loss: 0.022845372557640076
epoch 2: dev_f1=0.9309255079006772, f1=0.931345980126468, best_f1=0.931345980126468
step: 0, loss: 0.03942392021417618
step: 10, loss: 0.16056248545646667
step: 20, loss: 0.033091895282268524
step: 30, loss: 0.07168307900428772
step: 40, loss: 0.017421413213014603
step: 50, loss: 0.032256826758384705
step: 60, loss: 0.07478772848844528
step: 70, loss: 0.04234478250145912
step: 80, loss: 0.25091731548309326
step: 90, loss: 0.031201444566249847
step: 100, loss: 0.03976888954639435
step: 110, loss: 0.04357488080859184
step: 120, loss: 0.009086902253329754
step: 130, loss: 0.057426124811172485
step: 140, loss: 0.010344250127673149
step: 150, loss: 0.19161345064640045
step: 160, loss: 0.20265239477157593
step: 170, loss: 0.23633211851119995
step: 180, loss: 0.07795929908752441
step: 190, loss: 0.012882102280855179
step: 200, loss: 0.08034010976552963
step: 210, loss: 0.10460501909255981
step: 220, loss: 0.13654567301273346
step: 230, loss: 0.02912907674908638
step: 240, loss: 0.14264816045761108
step: 250, loss: 0.0847233235836029
step: 260, loss: 0.005171545781195164
step: 270, loss: 0.15917141735553741
step: 280, loss: 0.16302190721035004
step: 290, loss: 0.07643802464008331
step: 300, loss: 0.010087688453495502
step: 310, loss: 0.0913076102733612
step: 320, loss: 0.08622635900974274
step: 330, loss: 0.08536109328269958
step: 340, loss: 0.15641674399375916
step: 350, loss: 0.02191472053527832
step: 360, loss: 0.01114192046225071
step: 370, loss: 0.04783080145716667
step: 380, loss: 0.10744927078485489
step: 390, loss: 0.0014533300418406725
step: 400, loss: 0.04577769339084625
step: 410, loss: 0.13111722469329834
step: 420, loss: 0.1098097711801529
step: 430, loss: 0.06627120077610016
step: 440, loss: 0.09236898273229599
step: 450, loss: 0.0564044713973999
step: 460, loss: 0.06827990710735321
step: 470, loss: 0.06949585676193237
step: 480, loss: 0.21197228133678436
step: 490, loss: 0.03489391505718231
step: 500, loss: 0.07262560725212097
step: 510, loss: 0.02531065233051777
step: 520, loss: 0.031364135444164276
step: 530, loss: 0.05761466920375824
step: 540, loss: 0.009908587671816349
step: 550, loss: 0.15164373815059662
step: 560, loss: 0.14169493317604065
step: 570, loss: 0.06369636952877045
step: 580, loss: 0.10958297550678253
step: 590, loss: 0.11463706940412521
step: 600, loss: 0.047869015485048294
step: 610, loss: 0.09660845994949341
step: 620, loss: 0.07539834082126617
step: 630, loss: 0.024863503873348236
step: 640, loss: 0.07730969041585922
step: 650, loss: 0.015512620098888874
step: 660, loss: 0.04797370731830597
step: 670, loss: 0.05062622204422951
step: 680, loss: 0.04626079648733139
step: 690, loss: 0.03662621229887009
step: 700, loss: 0.01757183112204075
step: 710, loss: 0.14659383893013
step: 720, loss: 0.16597381234169006
step: 730, loss: 0.08760932832956314
step: 740, loss: 0.020904013887047768
step: 750, loss: 0.049983710050582886
step: 760, loss: 0.033250581473112106
step: 770, loss: 0.03777962177991867
step: 780, loss: 0.07061216235160828
step: 790, loss: 0.1658123880624771
step: 800, loss: 0.05317468196153641
step: 810, loss: 0.287258505821228
step: 820, loss: 0.04562222212553024
step: 830, loss: 0.037959564477205276
step: 840, loss: 0.11853624880313873
step: 850, loss: 0.07810784131288528
step: 860, loss: 0.17017166316509247
step: 870, loss: 0.10019845515489578
step: 880, loss: 0.0248121228069067
step: 890, loss: 0.1283419281244278
step: 900, loss: 0.07697600871324539
step: 910, loss: 0.02805633470416069
step: 920, loss: 0.1246635764837265
step: 930, loss: 0.09084808826446533
step: 940, loss: 0.09230852872133255
step: 950, loss: 0.2509525418281555
step: 960, loss: 0.1925661563873291
step: 970, loss: 0.022180797532200813
step: 980, loss: 0.06051712483167648
step: 990, loss: 0.0492207407951355
step: 1000, loss: 0.04012821242213249
step: 1010, loss: 0.11538087576627731
step: 1020, loss: 0.09019464254379272
step: 1030, loss: 0.038436297327280045
step: 1040, loss: 0.012061281129717827
step: 1050, loss: 0.03273017331957817
step: 1060, loss: 0.05868897959589958
step: 1070, loss: 0.04155619814991951
epoch 3: dev_f1=0.9398148148148149, f1=0.9461077844311377, best_f1=0.9461077844311377
step: 0, loss: 0.11862227320671082
step: 10, loss: 0.0984782949090004
step: 20, loss: 0.07950374484062195
step: 30, loss: 0.10790057480335236
step: 40, loss: 0.036056432873010635
step: 50, loss: 0.13221345841884613
step: 60, loss: 0.0718076154589653
step: 70, loss: 0.11225588619709015
step: 80, loss: 0.02032356709241867
step: 90, loss: 0.008958752267062664
step: 100, loss: 0.065688356757164
step: 110, loss: 0.017751915380358696
step: 120, loss: 0.004895931575447321
step: 130, loss: 0.014339419081807137
step: 140, loss: 0.017329823225736618
step: 150, loss: 0.015022635459899902
step: 160, loss: 0.016775695607066154
step: 170, loss: 0.09019283950328827
step: 180, loss: 0.08741675317287445
step: 190, loss: 0.07373789697885513
step: 200, loss: 0.17297692596912384
step: 210, loss: 0.09848883002996445
step: 220, loss: 0.053070634603500366
step: 230, loss: 0.0169795211404562
step: 240, loss: 0.10355009138584137
step: 250, loss: 0.02279830165207386
step: 260, loss: 0.00165630376432091
step: 270, loss: 0.18687166273593903
step: 280, loss: 0.0807790756225586
step: 290, loss: 0.04210358113050461
step: 300, loss: 0.07465435564517975
step: 310, loss: 0.01982928439974785
step: 320, loss: 0.042535655200481415
step: 330, loss: 0.1402512490749359
step: 340, loss: 0.03483439236879349
step: 350, loss: 0.04793680086731911
step: 360, loss: 0.12185609340667725
step: 370, loss: 0.1423138976097107
step: 380, loss: 0.05467028543353081
step: 390, loss: 0.007896977476775646
step: 400, loss: 0.03354092687368393
step: 410, loss: 0.03433125466108322
step: 420, loss: 0.047883547842502594
step: 430, loss: 0.06500265002250671
step: 440, loss: 0.10614215582609177
step: 450, loss: 0.12105938792228699
step: 460, loss: 0.10408049821853638
step: 470, loss: 0.030926063656806946
step: 480, loss: 0.01045153010636568
step: 490, loss: 0.03903106227517128
step: 500, loss: 0.004897044971585274
step: 510, loss: 0.036637838929891586
step: 520, loss: 0.04419119283556938
step: 530, loss: 0.16980284452438354
step: 540, loss: 0.06385890394449234
step: 550, loss: 0.026370376348495483
step: 560, loss: 0.025013210251927376
step: 570, loss: 6.0985039453953505e-05
step: 580, loss: 0.028281720355153084
step: 590, loss: 0.11794760078191757
step: 600, loss: 0.05539568141102791
step: 610, loss: 0.03832000494003296
step: 620, loss: 0.08050932735204697
step: 630, loss: 0.006718514021486044
step: 640, loss: 0.06838005036115646
step: 650, loss: 0.03427939862012863
step: 660, loss: 0.024658793583512306
step: 670, loss: 0.15293145179748535
step: 680, loss: 0.0690939649939537
step: 690, loss: 0.08113042265176773
step: 700, loss: 0.020275570452213287
step: 710, loss: 0.15981978178024292
step: 720, loss: 0.04069625213742256
step: 730, loss: 0.06402371823787689
step: 740, loss: 0.004823349881917238
step: 750, loss: 0.10365492850542068
step: 760, loss: 0.10788611322641373
step: 770, loss: 0.03159135952591896
step: 780, loss: 0.07706228643655777
step: 790, loss: 0.07507061958312988
step: 800, loss: 0.047440122812986374
step: 810, loss: 0.011609744280576706
step: 820, loss: 0.08293316513299942
step: 830, loss: 0.06029177084565163
step: 840, loss: 0.0410572774708271
step: 850, loss: 0.027459729462862015
step: 860, loss: 0.09264425188302994
step: 870, loss: 0.021145304664969444
step: 880, loss: 0.1919579654932022
step: 890, loss: 0.08779110014438629
step: 900, loss: 0.085025854408741
step: 910, loss: 0.07017719745635986
step: 920, loss: 0.02646877057850361
step: 930, loss: 0.07914884388446808
step: 940, loss: 0.011375747621059418
step: 950, loss: 0.20705553889274597
step: 960, loss: 0.0487535297870636
step: 970, loss: 0.014818603172898293
step: 980, loss: 0.16951829195022583
step: 990, loss: 0.18221545219421387
step: 1000, loss: 0.0323348194360733
step: 1010, loss: 0.07085186243057251
step: 1020, loss: 0.04370416700839996
step: 1030, loss: 0.09170226752758026
step: 1040, loss: 0.1845942586660385
step: 1050, loss: 0.06721652299165726
step: 1060, loss: 0.2242426723241806
step: 1070, loss: 0.05222821980714798
epoch 4: dev_f1=0.9380863039399624, f1=0.9430970149253732, best_f1=0.9461077844311377
step: 0, loss: 0.0029356328304857016
step: 10, loss: 0.001115518854930997
step: 20, loss: 0.07996392995119095
step: 30, loss: 0.09545344859361649
step: 40, loss: 0.045523129403591156
step: 50, loss: 0.09468331187963486
step: 60, loss: 0.13955695927143097
step: 70, loss: 0.06705261021852493
step: 80, loss: 0.01338682696223259
step: 90, loss: 0.010814572684466839
step: 100, loss: 0.01950632967054844
step: 110, loss: 0.11844832450151443
step: 120, loss: 0.05766221508383751
step: 130, loss: 0.09343556314706802
step: 140, loss: 0.06320812553167343
step: 150, loss: 0.06504760682582855
step: 160, loss: 0.12304366379976273
step: 170, loss: 0.07699103653430939
step: 180, loss: 0.08397459983825684
step: 190, loss: 0.05783998593688011
step: 200, loss: 0.029179010540246964
step: 210, loss: 0.10333229601383209
step: 220, loss: 0.045950423926115036
step: 230, loss: 0.04604243114590645
step: 240, loss: 0.06732376664876938
step: 250, loss: 0.008889717981219292
step: 260, loss: 0.014768645167350769
step: 270, loss: 0.005143593531101942
step: 280, loss: 0.03586278110742569
step: 290, loss: 0.023137545213103294
step: 300, loss: 0.004481778014451265
step: 310, loss: 0.09386305510997772
step: 320, loss: 0.06445414572954178
step: 330, loss: 0.24773190915584564
step: 340, loss: 0.05321170389652252
step: 350, loss: 0.10819549113512039
step: 360, loss: 0.002299655694514513
step: 370, loss: 0.0369906909763813
step: 380, loss: 0.06749159097671509
step: 390, loss: 0.05489589646458626
step: 400, loss: 0.023669825866818428
step: 410, loss: 0.011355978436768055
step: 420, loss: 0.04604851081967354
step: 430, loss: 0.04362298175692558
step: 440, loss: 0.018925003707408905
step: 450, loss: 0.06742244958877563
step: 460, loss: 0.03838427737355232
step: 470, loss: 0.08203420788049698
step: 480, loss: 0.021880533546209335
step: 490, loss: 0.1245356872677803
step: 500, loss: 0.040689483284950256
step: 510, loss: 0.021915802732110023
step: 520, loss: 0.02093491517007351
step: 530, loss: 0.06692187488079071
step: 540, loss: 0.05227741599082947
step: 550, loss: 0.06268499046564102
step: 560, loss: 0.007550231646746397
step: 570, loss: 0.006779914256185293
step: 580, loss: 0.0355786494910717
step: 590, loss: 0.01850111410021782
step: 600, loss: 0.03791958466172218
step: 610, loss: 0.015246866270899773
step: 620, loss: 0.01017598807811737
step: 630, loss: 0.013802986592054367
step: 640, loss: 0.010195708833634853
step: 650, loss: 0.002127918181940913
step: 660, loss: 0.034893762320280075
step: 670, loss: 0.0692305788397789
step: 680, loss: 0.03608529642224312
step: 690, loss: 0.09081988036632538
step: 700, loss: 0.012988065369427204
step: 710, loss: 0.007979125715792179
step: 720, loss: 0.03307100012898445
step: 730, loss: 0.013317947275936604
step: 740, loss: 0.02924520894885063
step: 750, loss: 0.018712583929300308
step: 760, loss: 0.08934303373098373
step: 770, loss: 0.0375312976539135
step: 780, loss: 0.08301054686307907
step: 790, loss: 0.015319986268877983
step: 800, loss: 0.004355044104158878
step: 810, loss: 0.02109743468463421
step: 820, loss: 0.0773090273141861
step: 830, loss: 0.10939390957355499
step: 840, loss: 0.023747554048895836
step: 850, loss: 0.0038280622102320194
step: 860, loss: 0.06607092171907425
step: 870, loss: 0.07701089233160019
step: 880, loss: 0.029122119769454002
step: 890, loss: 0.00943328719586134
step: 900, loss: 0.023301072418689728
step: 910, loss: 0.09932199865579605
step: 920, loss: 0.03536374494433403
step: 930, loss: 0.07480055838823318
step: 940, loss: 0.03411905840039253
step: 950, loss: 0.0899302288889885
step: 960, loss: 0.15893816947937012
step: 970, loss: 0.06371840834617615
step: 980, loss: 0.13305173814296722
step: 990, loss: 0.034717850387096405
step: 1000, loss: 0.09638094902038574
step: 1010, loss: 0.14621952176094055
step: 1020, loss: 0.13711120188236237
step: 1030, loss: 0.0767815113067627
step: 1040, loss: 0.07464137673377991
step: 1050, loss: 0.023239579051733017
step: 1060, loss: 0.11777020990848541
step: 1070, loss: 0.12483765184879303
epoch 5: dev_f1=0.9409070087036188, f1=0.9418764302059497, best_f1=0.9418764302059497
step: 0, loss: 0.14734189212322235
step: 10, loss: 0.0569903664290905
step: 20, loss: 0.0773719772696495
step: 30, loss: 0.024206141009926796
step: 40, loss: 0.03566061332821846
step: 50, loss: 0.025131454691290855
step: 60, loss: 0.01834537647664547
step: 70, loss: 0.049569498747587204
step: 80, loss: 0.06284432113170624
step: 90, loss: 0.15910935401916504
step: 100, loss: 0.039043720811605453
step: 110, loss: 0.11303959786891937
step: 120, loss: 0.05654613673686981
step: 130, loss: 0.09264988452196121
step: 140, loss: 0.14477644860744476
step: 150, loss: 0.06963863968849182
step: 160, loss: 0.06289970874786377
step: 170, loss: 0.11204575002193451
step: 180, loss: 0.06459061056375504
step: 190, loss: 0.044523656368255615
step: 200, loss: 0.11026313155889511
step: 210, loss: 0.008098945021629333
step: 220, loss: 0.23773492872714996
step: 230, loss: 0.040621139109134674
step: 240, loss: 0.023122137412428856
step: 250, loss: 0.053165581077337265
step: 260, loss: 0.0050057764165103436
step: 270, loss: 0.018791763111948967
step: 280, loss: 0.08453871309757233
step: 290, loss: 0.008497531525790691
step: 300, loss: 0.11830903589725494
step: 310, loss: 0.02395143173635006
step: 320, loss: 0.014412997290492058
step: 330, loss: 0.008418316021561623
step: 340, loss: 0.11651885509490967
step: 350, loss: 0.0871368795633316
step: 360, loss: 0.07359857112169266
step: 370, loss: 0.028212780132889748
step: 380, loss: 0.08468050509691238
step: 390, loss: 0.10366686433553696
step: 400, loss: 0.11739208549261093
step: 410, loss: 0.24462217092514038
step: 420, loss: 0.018040252849459648
step: 430, loss: 0.11794911324977875
step: 440, loss: 0.08815616369247437
step: 450, loss: 0.07245063036680222
step: 460, loss: 0.04688654839992523
step: 470, loss: 0.06822716444730759
step: 480, loss: 0.05589889734983444
step: 490, loss: 0.011364239268004894
step: 500, loss: 0.042184989899396896
step: 510, loss: 0.05642293766140938
step: 520, loss: 0.017170008271932602
step: 530, loss: 0.01760348305106163
step: 540, loss: 0.0740755945444107
step: 550, loss: 0.0015815745573490858
step: 560, loss: 0.01679382286965847
step: 570, loss: 0.08607944846153259
step: 580, loss: 0.16851021349430084
step: 590, loss: 0.08895596861839294
step: 600, loss: 0.0012774606002494693
step: 610, loss: 0.20872561633586884
step: 620, loss: 0.10170570015907288
step: 630, loss: 0.060086436569690704
step: 640, loss: 0.06914348900318146
step: 650, loss: 0.010003202594816685
step: 660, loss: 0.045140061527490616
step: 670, loss: 0.007960447110235691
step: 680, loss: 0.05914384126663208
step: 690, loss: 0.054600946605205536
step: 700, loss: 0.0638432502746582
step: 710, loss: 0.024238022044301033
step: 720, loss: 0.09333475679159164
step: 730, loss: 0.010689841583371162
step: 740, loss: 0.06875458359718323
step: 750, loss: 0.07661251723766327
step: 760, loss: 0.013165079057216644
step: 770, loss: 0.18157389760017395
step: 780, loss: 0.04100553318858147
step: 790, loss: 0.08367414772510529
step: 800, loss: 0.11078626662492752
step: 810, loss: 0.03403936326503754
step: 820, loss: 0.030439047142863274
step: 830, loss: 0.05729634687304497
step: 840, loss: 0.11791379004716873
step: 850, loss: 0.0359475202858448
step: 860, loss: 0.046465348452329636
step: 870, loss: 0.031306035816669464
step: 880, loss: 0.030194342136383057
step: 890, loss: 0.18580065667629242
step: 900, loss: 0.13712124526500702
step: 910, loss: 0.05998413264751434
step: 920, loss: 0.10443031042814255
step: 930, loss: 0.03931193798780441
step: 940, loss: 0.08125156909227371
step: 950, loss: 0.0328855998814106
step: 960, loss: 0.06695330888032913
step: 970, loss: 0.03977806121110916
step: 980, loss: 0.08143284916877747
step: 990, loss: 0.13010065257549286
step: 1000, loss: 0.05135833099484444
step: 1010, loss: 0.023203043267130852
step: 1020, loss: 0.01386529952287674
step: 1030, loss: 0.03987859934568405
step: 1040, loss: 0.034247469156980515
step: 1050, loss: 0.06997877359390259
step: 1060, loss: 0.06872382014989853
step: 1070, loss: 0.014079206623136997
epoch 6: dev_f1=0.9390018484288354, f1=0.9357045143638849, best_f1=0.9418764302059497
step: 0, loss: 0.04223673418164253
step: 10, loss: 0.021867720410227776
step: 20, loss: 0.010020414367318153
step: 30, loss: 0.029286647215485573
step: 40, loss: 0.051341354846954346
step: 50, loss: 0.04836009442806244
step: 60, loss: 0.015274753794074059
step: 70, loss: 0.02963348478078842
step: 80, loss: 0.025115730240941048
step: 90, loss: 0.1106906458735466
step: 100, loss: 0.057130783796310425
step: 110, loss: 7.240546983666718e-05
step: 120, loss: 0.024591311812400818
step: 130, loss: 0.062710240483284
step: 140, loss: 0.13928452134132385
step: 150, loss: 0.00375229399651289
step: 160, loss: 0.01850581169128418
step: 170, loss: 0.02367343381047249
step: 180, loss: 0.06047094613313675
step: 190, loss: 0.044192537665367126
step: 200, loss: 0.01356787420809269
step: 210, loss: 0.07858584076166153
step: 220, loss: 0.03625482693314552
step: 230, loss: 0.09682272374629974
step: 240, loss: 0.002852393314242363
step: 250, loss: 0.0002848355798050761
step: 260, loss: 0.10986179113388062
step: 270, loss: 0.09304496645927429
step: 280, loss: 0.026623070240020752
step: 290, loss: 0.011817717924714088
step: 300, loss: 0.013750632293522358
step: 310, loss: 0.05932626128196716
step: 320, loss: 0.104936383664608
step: 330, loss: 0.0024530061054974794
step: 340, loss: 0.03223191946744919
step: 350, loss: 0.04224710166454315
step: 360, loss: 0.005147901363670826
step: 370, loss: 0.12627221643924713
step: 380, loss: 0.021967507898807526
step: 390, loss: 0.14406833052635193
step: 400, loss: 0.1209610104560852
step: 410, loss: 0.0076026008464396
step: 420, loss: 0.022925037890672684
step: 430, loss: 0.055880285799503326
step: 440, loss: 0.18052472174167633
step: 450, loss: 0.11283566057682037
step: 460, loss: 0.1099378690123558
step: 470, loss: 0.012269372120499611
step: 480, loss: 0.025631971657276154
step: 490, loss: 0.07083142548799515
step: 500, loss: 0.02366512082517147
step: 510, loss: 0.11585135757923126
step: 520, loss: 0.12109008431434631
step: 530, loss: 0.02021493948996067
step: 540, loss: 0.13293254375457764
step: 550, loss: 0.09332823753356934
step: 560, loss: 0.0161454901099205
step: 570, loss: 0.020486906170845032
step: 580, loss: 0.13684462010860443
step: 590, loss: 0.06140945851802826
step: 600, loss: 0.03812821954488754
step: 610, loss: 0.02417146787047386
step: 620, loss: 0.07938548922538757
step: 630, loss: 0.08960220962762833
step: 640, loss: 0.00877927616238594
step: 650, loss: 0.07052458822727203
step: 660, loss: 0.06586552411317825
step: 670, loss: 0.10346407443284988
step: 680, loss: 0.08411397784948349
step: 690, loss: 0.04016806557774544
step: 700, loss: 0.030406367033720016
step: 710, loss: 0.04372302442789078
step: 720, loss: 0.04337626323103905
step: 730, loss: 0.08626797050237656
step: 740, loss: 0.021304748952388763
step: 750, loss: 0.09530569612979889
step: 760, loss: 0.020123302936553955
step: 770, loss: 0.0008942857384681702
step: 780, loss: 0.010524454526603222
step: 790, loss: 0.04665767028927803
step: 800, loss: 0.049617279320955276
step: 810, loss: 0.0025274883955717087
step: 820, loss: 0.008117851801216602
step: 830, loss: 0.015063888393342495
step: 840, loss: 0.013200176879763603
step: 850, loss: 0.06482403725385666
step: 860, loss: 0.029013819992542267
step: 870, loss: 0.023304548114538193
step: 880, loss: 0.013341682963073254
step: 890, loss: 0.015696143731474876
step: 900, loss: 0.006420006509870291
step: 910, loss: 0.11330617219209671
step: 920, loss: 0.095512755215168
step: 930, loss: 0.09845732897520065
step: 940, loss: 0.013108136132359505
step: 950, loss: 0.015490341000258923
step: 960, loss: 0.05913931131362915
step: 970, loss: 0.14812907576560974
step: 980, loss: 0.03789781033992767
step: 990, loss: 0.10228581726551056
step: 1000, loss: 0.10960494726896286
step: 1010, loss: 0.1115729883313179
step: 1020, loss: 0.1528407335281372
step: 1030, loss: 0.040544863790273666
step: 1040, loss: 0.09807047247886658
step: 1050, loss: 0.027649978175759315
step: 1060, loss: 0.021745452657341957
step: 1070, loss: 0.009233761578798294
epoch 7: dev_f1=0.9400836042731072, f1=0.9332105020727776, best_f1=0.9418764302059497
step: 0, loss: 0.029947124421596527
step: 10, loss: 0.05121951550245285
step: 20, loss: 0.0917573943734169
step: 30, loss: 0.0264518354088068
step: 40, loss: 0.0360204242169857
step: 50, loss: 0.014258028008043766
step: 60, loss: 0.02464308589696884
step: 70, loss: 0.0853651836514473
step: 80, loss: 0.06190834194421768
step: 90, loss: 0.0021083748433738947
step: 100, loss: 0.07732625305652618
step: 110, loss: 0.01113559864461422
step: 120, loss: 0.04648410528898239
step: 130, loss: 0.10116887837648392
step: 140, loss: 0.07498043030500412
step: 150, loss: 0.010688923299312592
step: 160, loss: 0.023395083844661713
step: 170, loss: 0.06729494035243988
step: 180, loss: 0.013116742484271526
step: 190, loss: 0.04304005578160286
step: 200, loss: 0.09504459798336029
step: 210, loss: 0.0026865515392273664
step: 220, loss: 0.02548949047923088
step: 230, loss: 0.07446689903736115
step: 240, loss: 0.048850174993276596
step: 250, loss: 0.010848600417375565
step: 260, loss: 0.04951290041208267
step: 270, loss: 0.01601460576057434
step: 280, loss: 0.06249812990427017
step: 290, loss: 0.006805634591728449
step: 300, loss: 0.11882258206605911
step: 310, loss: 0.053874701261520386
step: 320, loss: 0.004496223293244839
step: 330, loss: 0.03423839062452316
step: 340, loss: 0.203762948513031
step: 350, loss: 0.04173097014427185
step: 360, loss: 0.13762697577476501
step: 370, loss: 0.013665623031556606
step: 380, loss: 0.10295797884464264
step: 390, loss: 0.023925358429551125
step: 400, loss: 0.15781153738498688
step: 410, loss: 0.019887423142790794
step: 420, loss: 0.04196596145629883
step: 430, loss: 0.04542657360434532
step: 440, loss: 0.029711997136473656
step: 450, loss: 0.1670915186405182
step: 460, loss: 0.0416511632502079
step: 470, loss: 0.07296013087034225
step: 480, loss: 0.01880769617855549
step: 490, loss: 0.031355198472738266
step: 500, loss: 0.0285525843501091
step: 510, loss: 0.012498878873884678
step: 520, loss: 0.01438656635582447
step: 530, loss: 0.008554872125387192
step: 540, loss: 0.05436088889837265
step: 550, loss: 0.054653093218803406
step: 560, loss: 0.18525196611881256
step: 570, loss: 0.07006663829088211
step: 580, loss: 0.044208332896232605
step: 590, loss: 0.06531158089637756
step: 600, loss: 0.006871505174785852
step: 610, loss: 0.020138144493103027
step: 620, loss: 0.10603880882263184
step: 630, loss: 0.007602732628583908
step: 640, loss: 0.19807936251163483
step: 650, loss: 0.07661909610033035
step: 660, loss: 0.018181035295128822
step: 670, loss: 0.058371346443891525
step: 680, loss: 0.07942882180213928
step: 690, loss: 0.013497071340680122
step: 700, loss: 0.09040652960538864
step: 710, loss: 0.048413895070552826
step: 720, loss: 0.011162251234054565
step: 730, loss: 0.010407142341136932
step: 740, loss: 0.08081924170255661
step: 750, loss: 0.060578908771276474
step: 760, loss: 0.016203077509999275
step: 770, loss: 0.0866246446967125
step: 780, loss: 0.013362240046262741
step: 790, loss: 0.0511605367064476
step: 800, loss: 0.013246528804302216
step: 810, loss: 0.009385495446622372
step: 820, loss: 0.038752682507038116
step: 830, loss: 0.059033822268247604
step: 840, loss: 0.006344190798699856
step: 850, loss: 0.08949441462755203
step: 860, loss: 0.08429871499538422
step: 870, loss: 0.17937220633029938
step: 880, loss: 0.002983844606205821
step: 890, loss: 0.13195563852787018
step: 900, loss: 0.058328527957201004
step: 910, loss: 0.0017515049548819661
step: 920, loss: 0.0958670899271965
step: 930, loss: 0.047835543751716614
step: 940, loss: 0.0257802065461874
step: 950, loss: 0.02379123494029045
step: 960, loss: 0.014489633962512016
step: 970, loss: 0.03418121114373207
step: 980, loss: 0.029076682403683662
step: 990, loss: 0.012205880135297775
step: 1000, loss: 0.013656824827194214
step: 1010, loss: 0.08228784799575806
step: 1020, loss: 0.05691689997911453
step: 1030, loss: 0.0028948180843144655
step: 1040, loss: 0.0002613926772028208
step: 1050, loss: 0.08614243566989899
step: 1060, loss: 0.0014907460426911712
step: 1070, loss: 0.19746972620487213
epoch 8: dev_f1=0.9217391304347826, f1=0.9194876486733761, best_f1=0.9418764302059497
step: 0, loss: 0.062367428094148636
step: 10, loss: 0.10313338786363602
step: 20, loss: 0.013297056779265404
step: 30, loss: 0.13299492001533508
step: 40, loss: 0.04508460313081741
step: 50, loss: 5.640372182824649e-05
step: 60, loss: 0.05141349136829376
step: 70, loss: 0.009994583204388618
step: 80, loss: 0.0042701116763055325
step: 90, loss: 0.033617351204156876
step: 100, loss: 0.11922359466552734
step: 110, loss: 0.05327494069933891
step: 120, loss: 0.046419404447078705
step: 130, loss: 0.06602489203214645
step: 140, loss: 2.8936086891917512e-05
step: 150, loss: 0.0918186828494072
step: 160, loss: 0.010072406381368637
step: 170, loss: 0.13347242772579193
step: 180, loss: 0.0802527368068695
step: 190, loss: 0.03039254993200302
step: 200, loss: 0.08645439147949219
step: 210, loss: 0.058728478848934174
step: 220, loss: 0.058588020503520966
step: 230, loss: 0.07409827411174774
step: 240, loss: 0.04419884458184242
step: 250, loss: 0.006592577788978815
step: 260, loss: 0.02241487242281437
step: 270, loss: 0.06986699253320694
step: 280, loss: 0.11561067402362823
step: 290, loss: 0.005122516304254532
step: 300, loss: 0.03895414620637894
step: 310, loss: 0.014387207105755806
step: 320, loss: 0.01110150571912527
step: 330, loss: 0.013688824139535427
step: 340, loss: 0.08448393642902374
step: 350, loss: 0.06480065733194351
step: 360, loss: 0.0032239470165222883
step: 370, loss: 0.011024137027561665
step: 380, loss: 0.050116196274757385
step: 390, loss: 0.006998824886977673
step: 400, loss: 0.03806474432349205
step: 410, loss: 0.015442715026438236
step: 420, loss: 0.08720647543668747
step: 430, loss: 0.016091108322143555
step: 440, loss: 0.02935059182345867
step: 450, loss: 0.01295875757932663
step: 460, loss: 0.03474578633904457
step: 470, loss: 0.01787855476140976
step: 480, loss: 0.14984291791915894
step: 490, loss: 0.055091742426157
step: 500, loss: 0.04695699363946915
step: 510, loss: 0.025293076410889626
step: 520, loss: 0.061139065772295
step: 530, loss: 0.04959962144494057
step: 540, loss: 0.015549041330814362
step: 550, loss: 0.02433350495994091
step: 560, loss: 0.0024707531556487083
step: 570, loss: 0.004781563300639391
step: 580, loss: 0.05422820895910263
step: 590, loss: 0.008997136726975441
step: 600, loss: 0.1264192759990692
step: 610, loss: 0.06662116944789886
step: 620, loss: 0.06628373265266418
step: 630, loss: 0.16071432828903198
step: 640, loss: 0.0030622847843915224
step: 650, loss: 0.021315477788448334
step: 660, loss: 0.0131402388215065
step: 670, loss: 0.024650946259498596
step: 680, loss: 0.005250158719718456
step: 690, loss: 0.014094572514295578
step: 700, loss: 0.08127924799919128
step: 710, loss: 0.11148851364850998
step: 720, loss: 0.07559524476528168
step: 730, loss: 0.09573342651128769
step: 740, loss: 0.05419236049056053
step: 750, loss: 0.048874761909246445
step: 760, loss: 0.009013975970447063
step: 770, loss: 0.07555056363344193
step: 780, loss: 0.08116165548563004
step: 790, loss: 0.04642484709620476
step: 800, loss: 0.016519391909241676
step: 810, loss: 0.11474190652370453
step: 820, loss: 0.001386961666867137
step: 830, loss: 0.0184914693236351
step: 840, loss: 0.023470256477594376
step: 850, loss: 0.021863309666514397
step: 860, loss: 0.03914989158511162
step: 870, loss: 0.006687570363283157
step: 880, loss: 0.01807945780456066
step: 890, loss: 0.014472048729658127
step: 900, loss: 0.07929763197898865
step: 910, loss: 0.03800024464726448
step: 920, loss: 0.01416871603578329
step: 930, loss: 0.0893683210015297
step: 940, loss: 0.07973524183034897
step: 950, loss: 0.060374610126018524
step: 960, loss: 0.005749578587710857
step: 970, loss: 0.10603401064872742
step: 980, loss: 0.016846518963575363
step: 990, loss: 0.13169345259666443
step: 1000, loss: 0.01143735833466053
step: 1010, loss: 0.026109836995601654
step: 1020, loss: 0.014922653324902058
step: 1030, loss: 0.029593821614980698
step: 1040, loss: 0.08177691698074341
step: 1050, loss: 0.12401735782623291
step: 1060, loss: 0.06049836054444313
step: 1070, loss: 0.02875661849975586
epoch 9: dev_f1=0.9328984156570364, f1=0.9284064665127021, best_f1=0.9418764302059497
step: 0, loss: 0.0640772208571434
step: 10, loss: 0.017059003934264183
step: 20, loss: 0.024983307346701622
step: 30, loss: 0.00229953252710402
step: 40, loss: 0.0476343147456646
step: 50, loss: 0.0003347917809151113
step: 60, loss: 0.09947331249713898
step: 70, loss: 0.03741680085659027
step: 80, loss: 0.002777017652988434
step: 90, loss: 0.06151935085654259
step: 100, loss: 0.013354758732020855
step: 110, loss: 0.030910497531294823
step: 120, loss: 0.035795919597148895
step: 130, loss: 0.031151965260505676
step: 140, loss: 0.032013487070798874
step: 150, loss: 0.08651016652584076
step: 160, loss: 0.1290302276611328
step: 170, loss: 0.08311393111944199
step: 180, loss: 0.0012867243494838476
step: 190, loss: 0.03538381680846214
step: 200, loss: 0.04127395898103714
step: 210, loss: 0.011294061318039894
step: 220, loss: 0.0439516082406044
step: 230, loss: 0.002107189502567053
step: 240, loss: 0.0594363696873188
step: 250, loss: 0.017224784940481186
step: 260, loss: 0.10818661749362946
step: 270, loss: 0.019419223070144653
step: 280, loss: 0.13884086906909943
step: 290, loss: 0.004460739903151989
step: 300, loss: 0.01839570514857769
step: 310, loss: 0.00972797442227602
step: 320, loss: 0.017123762518167496
step: 330, loss: 0.133415088057518
step: 340, loss: 0.013774730265140533
step: 350, loss: 0.014711986295878887
step: 360, loss: 0.06705678999423981
step: 370, loss: 0.004381838720291853
step: 380, loss: 0.05032595992088318
step: 390, loss: 0.0836920216679573
step: 400, loss: 0.02412191592156887
step: 410, loss: 0.029682796448469162
step: 420, loss: 0.02306644804775715
step: 430, loss: 0.06871584057807922
step: 440, loss: 0.009948399849236012
step: 450, loss: 0.07113456726074219
step: 460, loss: 0.00014110586198512465
step: 470, loss: 0.21875929832458496
step: 480, loss: 0.008930174633860588
step: 490, loss: 0.02632923237979412
step: 500, loss: 0.06879784911870956
step: 510, loss: 0.053111109882593155
step: 520, loss: 0.03744478151202202
step: 530, loss: 0.011576305143535137
step: 540, loss: 0.0316348597407341
step: 550, loss: 0.01507713831961155
step: 560, loss: 0.00978478230535984
step: 570, loss: 0.010427148081362247
step: 580, loss: 0.008671106770634651
step: 590, loss: 0.026090500876307487
step: 600, loss: 0.003320523304864764
step: 610, loss: 0.10004512220621109
step: 620, loss: 0.0720004290342331
step: 630, loss: 0.07742126286029816
step: 640, loss: 0.057573091238737106
step: 650, loss: 0.04850413277745247
step: 660, loss: 0.2364310771226883
step: 670, loss: 0.01818896271288395
step: 680, loss: 0.020849213004112244
step: 690, loss: 0.02597864903509617
step: 700, loss: 0.0848366841673851
step: 710, loss: 0.06324101984500885
step: 720, loss: 0.06006757542490959
step: 730, loss: 0.031481098383665085
step: 740, loss: 0.029676437377929688
step: 750, loss: 0.037274789065122604
step: 760, loss: 0.09712442755699158
step: 770, loss: 0.000260863802395761
step: 780, loss: 0.009937062859535217
step: 790, loss: 0.0032497139181941748
step: 800, loss: 0.06229163706302643
step: 810, loss: 0.053467851132154465
step: 820, loss: 0.10073942691087723
step: 830, loss: 0.027957875281572342
step: 840, loss: 0.08531993627548218
step: 850, loss: 0.14567261934280396
step: 860, loss: 0.018119806423783302
step: 870, loss: 0.04661979898810387
step: 880, loss: 0.019453279674053192
step: 890, loss: 0.0006603261572308838
step: 900, loss: 0.006758054718375206
step: 910, loss: 0.06932435184717178
step: 920, loss: 0.007182107772678137
step: 930, loss: 0.041932009160518646
step: 940, loss: 0.03390742838382721
step: 950, loss: 0.09869901835918427
step: 960, loss: 0.024286963045597076
step: 970, loss: 0.08021230250597
step: 980, loss: 0.08224466443061829
step: 990, loss: 0.09281343221664429
step: 1000, loss: 0.005733216647058725
step: 1010, loss: 0.061834871768951416
step: 1020, loss: 0.06276332587003708
step: 1030, loss: 0.016131486743688583
step: 1040, loss: 0.07308080047369003
step: 1050, loss: 0.009725695475935936
step: 1060, loss: 0.010585041716694832
step: 1070, loss: 0.04503130912780762
epoch 10: dev_f1=0.9396350023397285, f1=0.934752429430819, best_f1=0.9418764302059497
step: 0, loss: 0.00770168099552393
step: 10, loss: 0.03437760844826698
step: 20, loss: 0.006186899729073048
step: 30, loss: 0.045768819749355316
step: 40, loss: 0.016658201813697815
step: 50, loss: 0.04402395337820053
step: 60, loss: 0.0669933408498764
step: 70, loss: 0.038580797612667084
step: 80, loss: 0.056226737797260284
step: 90, loss: 0.004269939847290516
step: 100, loss: 0.004340889863669872
step: 110, loss: 0.021057648584246635
step: 120, loss: 0.03287912532687187
step: 130, loss: 0.02726835198700428
step: 140, loss: 0.01447711605578661
step: 150, loss: 0.04379957169294357
step: 160, loss: 0.0012507936917245388
step: 170, loss: 0.0025521242059767246
step: 180, loss: 0.013937889598309994
step: 190, loss: 0.007804259192198515
step: 200, loss: 0.06915454566478729
step: 210, loss: 0.05551735684275627
step: 220, loss: 0.03526017442345619
step: 230, loss: 0.009012878872454166
step: 240, loss: 0.0067591494880616665
step: 250, loss: 0.021195070818066597
step: 260, loss: 0.06580565124750137
step: 270, loss: 0.013682329095900059
step: 280, loss: 0.06670840829610825
step: 290, loss: 0.047995392233133316
step: 300, loss: 0.0631679818034172
step: 310, loss: 0.011147270910441875
step: 320, loss: 0.01688336208462715
step: 330, loss: 7.766854832880199e-05
step: 340, loss: 0.29312461614608765
step: 350, loss: 0.01207114476710558
step: 360, loss: 0.02059047296643257
step: 370, loss: 0.05764162167906761
step: 380, loss: 0.03901645913720131
step: 390, loss: 0.021238772198557854
step: 400, loss: 0.013775539584457874
step: 410, loss: 0.0707520991563797
step: 420, loss: 0.046262528747320175
step: 430, loss: 0.00010735796968219802
step: 440, loss: 0.04226616770029068
step: 450, loss: 0.060494646430015564
step: 460, loss: 0.002386562991887331
step: 470, loss: 0.002488592639565468
step: 480, loss: 0.004386827349662781
step: 490, loss: 0.010024449788033962
step: 500, loss: 0.0198451429605484
step: 510, loss: 0.16111284494400024
step: 520, loss: 0.042525023221969604
step: 530, loss: 0.09389539808034897
step: 540, loss: 0.016770221292972565
step: 550, loss: 0.14079169929027557
step: 560, loss: 0.006566163618117571
step: 570, loss: 0.020008614286780357
step: 580, loss: 0.11044702678918839
step: 590, loss: 0.0023688222281634808
step: 600, loss: 0.045450203120708466
step: 610, loss: 0.0002805978001561016
step: 620, loss: 0.003957467153668404
step: 630, loss: 0.048979174345731735
step: 640, loss: 0.055780474096536636
step: 650, loss: 0.06152571365237236
step: 660, loss: 0.002725529484450817
step: 670, loss: 0.10617850720882416
step: 680, loss: 0.028870802372694016
step: 690, loss: 0.0016207549488171935
step: 700, loss: 0.0008935087826102972
step: 710, loss: 0.0801808163523674
step: 720, loss: 0.08990346640348434
step: 730, loss: 0.03384210914373398
step: 740, loss: 0.04961862042546272
step: 750, loss: 0.07728535681962967
step: 760, loss: 0.024754149839282036
step: 770, loss: 0.0031431736424565315
step: 780, loss: 0.054009586572647095
step: 790, loss: 0.1122041642665863
step: 800, loss: 0.026731044054031372
step: 810, loss: 0.05879901349544525
step: 820, loss: 0.05381755530834198
step: 830, loss: 0.03856322541832924
step: 840, loss: 0.11058084666728973
step: 850, loss: 0.010237113572657108
step: 860, loss: 0.02675379440188408
step: 870, loss: 0.0529586486518383
step: 880, loss: 0.01637466438114643
step: 890, loss: 0.009644889272749424
step: 900, loss: 0.056794460862874985
step: 910, loss: 0.018049346283078194
step: 920, loss: 0.0003780561382882297
step: 930, loss: 0.0727054700255394
step: 940, loss: 0.0021957261487841606
step: 950, loss: 0.01977030746638775
step: 960, loss: 0.017786182463169098
step: 970, loss: 0.12431208789348602
step: 980, loss: 0.08382449299097061
step: 990, loss: 0.08370959758758545
step: 1000, loss: 0.05310843512415886
step: 1010, loss: 0.01881467178463936
step: 1020, loss: 0.1340581476688385
step: 1030, loss: 0.028278058394789696
step: 1040, loss: 0.010644660331308842
step: 1050, loss: 0.10523252934217453
step: 1060, loss: 0.026139885187149048
step: 1070, loss: 0.003619259921833873
epoch 11: dev_f1=0.9393511988716502, f1=0.9402985074626865, best_f1=0.9418764302059497
step: 0, loss: 0.031034214422106743
step: 10, loss: 0.08642994612455368
step: 20, loss: 0.04204597324132919
step: 30, loss: 0.025258654728531837
step: 40, loss: 0.02394692413508892
step: 50, loss: 0.034003205597400665
step: 60, loss: 2.4910563297453336e-05
step: 70, loss: 0.00019139601499773562
step: 80, loss: 0.023901792243123055
step: 90, loss: 0.04378091171383858
step: 100, loss: 0.028449395671486855
step: 110, loss: 0.002889154711738229
step: 120, loss: 0.06215129420161247
step: 130, loss: 0.10706771910190582
step: 140, loss: 0.0076455180533230305
step: 150, loss: 0.04098961874842644
step: 160, loss: 0.00569883082062006
step: 170, loss: 0.033961474895477295
step: 180, loss: 0.02403245121240616
step: 190, loss: 0.00092394242528826
step: 200, loss: 0.00428021652624011
step: 210, loss: 0.010156296193599701
step: 220, loss: 0.027742628008127213
step: 230, loss: 0.009690096601843834
step: 240, loss: 0.05124291405081749
step: 250, loss: 0.02690608613193035
step: 260, loss: 3.167400063830428e-05
step: 270, loss: 0.05170346796512604
step: 280, loss: 0.08747569471597672
step: 290, loss: 0.027331477031111717
step: 300, loss: 0.03337092325091362
step: 310, loss: 0.03683226928114891
step: 320, loss: 0.023621154949069023
step: 330, loss: 0.028438253328204155
step: 340, loss: 0.0368257611989975
step: 350, loss: 0.0014631884405389428
step: 360, loss: 3.8766749639762565e-05
step: 370, loss: 0.0015431410865858197
step: 380, loss: 0.051328904926776886
step: 390, loss: 0.1263613998889923
step: 400, loss: 0.002246956806629896
step: 410, loss: 0.053274087607860565
step: 420, loss: 0.029427334666252136
step: 430, loss: 0.06383279711008072
step: 440, loss: 0.00849188957363367
step: 450, loss: 0.023679351434111595
step: 460, loss: 0.024242280051112175
step: 470, loss: 0.07104061543941498
step: 480, loss: 0.03289271146059036
step: 490, loss: 0.07909274846315384
step: 500, loss: 0.006354569457471371
step: 510, loss: 0.08181019872426987
step: 520, loss: 0.025149518623948097
step: 530, loss: 0.02332294173538685
step: 540, loss: 0.027430221438407898
step: 550, loss: 0.03063107281923294
step: 560, loss: 0.10454025119543076
step: 570, loss: 0.0025501037016510963
step: 580, loss: 0.02478037029504776
step: 590, loss: 0.03800474479794502
step: 600, loss: 0.1497127264738083
step: 610, loss: 0.0004636243393179029
step: 620, loss: 0.0129061508923769
step: 630, loss: 0.1319204568862915
step: 640, loss: 0.018465887755155563
step: 650, loss: 0.00010488084808457643
step: 660, loss: 0.02033412456512451
step: 670, loss: 0.030160075053572655
step: 680, loss: 0.010498467832803726
step: 690, loss: 0.09993341565132141
step: 700, loss: 0.00019715676899068058
step: 710, loss: 0.050893425941467285
step: 720, loss: 0.06084152311086655
step: 730, loss: 0.0037828560452908278
step: 740, loss: 0.029861673712730408
step: 750, loss: 0.002143610268831253
step: 760, loss: 0.009336903691291809
step: 770, loss: 0.012145472690463066
step: 780, loss: 0.04874902963638306
step: 790, loss: 0.05088651552796364
step: 800, loss: 0.10161661356687546
step: 810, loss: 0.02809605747461319
step: 820, loss: 0.009301784448325634
step: 830, loss: 0.007017828989773989
step: 840, loss: 0.00762959523126483
step: 850, loss: 0.04016387090086937
step: 860, loss: 0.114829882979393
step: 870, loss: 0.02271405979990959
step: 880, loss: 0.014612816274166107
step: 890, loss: 0.015257068909704685
step: 900, loss: 0.01863175444304943
step: 910, loss: 0.058775365352630615
step: 920, loss: 0.0007084384560585022
step: 930, loss: 1.690142016741447e-05
step: 940, loss: 0.002344149863347411
step: 950, loss: 0.10523994266986847
step: 960, loss: 0.020129265263676643
step: 970, loss: 0.033706143498420715
step: 980, loss: 0.04523992910981178
step: 990, loss: 0.03667376562952995
step: 1000, loss: 0.0545114204287529
step: 1010, loss: 0.0031550780404359102
step: 1020, loss: 0.07175569981336594
step: 1030, loss: 0.033911339938640594
step: 1040, loss: 0.00979106780141592
step: 1050, loss: 0.05238412320613861
step: 1060, loss: 0.05092155933380127
step: 1070, loss: 0.06479036062955856
epoch 12: dev_f1=0.9372967951695309, f1=0.9366742596810934, best_f1=0.9418764302059497
step: 0, loss: 0.13636454939842224
step: 10, loss: 0.057970110327005386
step: 20, loss: 0.0115974685177207
step: 30, loss: 0.014896111562848091
step: 40, loss: 0.035355303436517715
step: 50, loss: 0.012621286325156689
step: 60, loss: 0.04998627305030823
step: 70, loss: 0.003143532667309046
step: 80, loss: 0.0052600461058318615
step: 90, loss: 0.0005499703693203628
step: 100, loss: 0.057219430804252625
step: 110, loss: 0.03301408886909485
step: 120, loss: 0.037506524473428726
step: 130, loss: 0.02339620143175125
step: 140, loss: 0.019674748182296753
step: 150, loss: 0.008028670214116573
step: 160, loss: 0.01613348349928856
step: 170, loss: 0.028395064175128937
step: 180, loss: 0.03110078163444996
step: 190, loss: 0.3308306932449341
step: 200, loss: 0.05011425539851189
step: 210, loss: 0.011244945228099823
step: 220, loss: 0.033828254789114
step: 230, loss: 0.0003401021531317383
step: 240, loss: 0.031318556517362595
step: 250, loss: 0.0037891040556132793
step: 260, loss: 0.018285969272255898
step: 270, loss: 0.018470264971256256
step: 280, loss: 0.032849300652742386
step: 290, loss: 0.07626435905694962
step: 300, loss: 0.0621073879301548
step: 310, loss: 0.0258757546544075
step: 320, loss: 0.034427013248205185
step: 330, loss: 0.051414694637060165
step: 340, loss: 2.5037077648448758e-05
step: 350, loss: 0.008835043758153915
step: 360, loss: 0.08007263392210007
step: 370, loss: 0.003232897724956274
step: 380, loss: 9.234942262992263e-05
step: 390, loss: 0.12339181452989578
step: 400, loss: 0.03204459324479103
step: 410, loss: 0.03953012079000473
step: 420, loss: 0.016106942668557167
step: 430, loss: 0.004489945247769356
step: 440, loss: 0.026901420205831528
step: 450, loss: 2.2526055545313284e-05
step: 460, loss: 0.03229155391454697
step: 470, loss: 0.0010482189245522022
step: 480, loss: 0.033731359988451004
step: 490, loss: 0.036809973418712616
step: 500, loss: 0.1419404000043869
step: 510, loss: 0.0309572983533144
step: 520, loss: 0.021346794441342354
step: 530, loss: 0.06895887106657028
step: 540, loss: 0.04042917117476463
step: 550, loss: 0.14531266689300537
step: 560, loss: 0.012285778298974037
step: 570, loss: 0.0513157844543457
step: 580, loss: 0.0001829427492339164
step: 590, loss: 0.07945467531681061
step: 600, loss: 0.008268394507467747
step: 610, loss: 0.09692782908678055
step: 620, loss: 0.08410712331533432
step: 630, loss: 0.042552899569272995
step: 640, loss: 0.0035774309653788805
step: 650, loss: 0.03278651461005211
step: 660, loss: 0.03554737940430641
step: 670, loss: 0.00691651226952672
step: 680, loss: 0.016584979370236397
step: 690, loss: 0.05954834446310997
step: 700, loss: 0.049589451402425766
step: 710, loss: 0.04651065170764923
step: 720, loss: 0.06886806339025497
step: 730, loss: 0.026450496166944504
step: 740, loss: 0.004102111794054508
step: 750, loss: 0.044783227145671844
step: 760, loss: 0.1650151014328003
step: 770, loss: 0.048671796917915344
step: 780, loss: 0.004714996553957462
step: 790, loss: 0.05291696637868881
step: 800, loss: 0.029240526258945465
step: 810, loss: 0.00039377008215524256
step: 820, loss: 0.03317695111036301
step: 830, loss: 0.046505000442266464
step: 840, loss: 4.148114021518268e-05
step: 850, loss: 0.0026257731951773167
step: 860, loss: 0.0004684908199124038
step: 870, loss: 0.08416985720396042
step: 880, loss: 0.029866227880120277
step: 890, loss: 0.02136145904660225
step: 900, loss: 0.0007395287393592298
step: 910, loss: 0.07635252922773361
step: 920, loss: 0.0009675798355601728
step: 930, loss: 0.2335943728685379
step: 940, loss: 0.04926656186580658
step: 950, loss: 0.0027918454725295305
step: 960, loss: 0.04643905907869339
step: 970, loss: 4.076478217029944e-05
step: 980, loss: 0.026017431169748306
step: 990, loss: 0.00902995653450489
step: 1000, loss: 0.05077553167939186
step: 1010, loss: 0.002167397178709507
step: 1020, loss: 0.027653612196445465
step: 1030, loss: 0.03140394017100334
step: 1040, loss: 0.0013837121659889817
step: 1050, loss: 0.001086977543309331
step: 1060, loss: 0.06754782050848007
step: 1070, loss: 0.000815392064396292
epoch 13: dev_f1=0.936768149882904, f1=0.9406350667280258, best_f1=0.9418764302059497
step: 0, loss: 0.03160272166132927
step: 10, loss: 0.04604295268654823
step: 20, loss: 0.002909344155341387
step: 30, loss: 0.07702261954545975
step: 40, loss: 0.01557825319468975
step: 50, loss: 0.017163988202810287
step: 60, loss: 0.031501274555921555
step: 70, loss: 0.0020895684137940407
step: 80, loss: 0.016703564673662186
step: 90, loss: 8.758667536312714e-05
step: 100, loss: 0.09019984304904938
step: 110, loss: 0.023071356117725372
step: 120, loss: 0.0682448148727417
step: 130, loss: 0.05703699216246605
step: 140, loss: 0.03445855528116226
step: 150, loss: 0.03793622925877571
step: 160, loss: 0.02884621173143387
step: 170, loss: 0.00040826608892530203
step: 180, loss: 0.03366117179393768
step: 190, loss: 0.002915031276643276
step: 200, loss: 0.022198274731636047
step: 210, loss: 0.03225293755531311
step: 220, loss: 0.039871543645858765
step: 230, loss: 0.000200200141989626
step: 240, loss: 0.03723379224538803
step: 250, loss: 0.01874205470085144
step: 260, loss: 0.008826547302305698
step: 270, loss: 0.0003431664372328669
step: 280, loss: 0.00048139155842363834
step: 290, loss: 0.007425537332892418
step: 300, loss: 0.10242630541324615
step: 310, loss: 3.598037437768653e-05
step: 320, loss: 0.12306402623653412
step: 330, loss: 0.04444639012217522
step: 340, loss: 0.00024774015764705837
step: 350, loss: 0.0024483297020196915
step: 360, loss: 0.02279302291572094
step: 370, loss: 0.0014670748496428132
step: 380, loss: 0.1129985824227333
step: 390, loss: 0.0301730427891016
step: 400, loss: 0.014199329540133476
step: 410, loss: 0.03831939399242401
step: 420, loss: 0.026613516733050346
step: 430, loss: 0.04567872732877731
step: 440, loss: 0.00016542711819056422
step: 450, loss: 0.03834591433405876
step: 460, loss: 0.007650479674339294
step: 470, loss: 0.021626010537147522
step: 480, loss: 0.0013778057182207704
step: 490, loss: 0.025893419981002808
step: 500, loss: 0.042814951390028
step: 510, loss: 0.0005703222122974694
step: 520, loss: 0.029040388762950897
step: 530, loss: 0.0006518082227557898
step: 540, loss: 0.05256321653723717
step: 550, loss: 0.02664290927350521
step: 560, loss: 0.02734292857348919
step: 570, loss: 0.029826659709215164
step: 580, loss: 0.002767495810985565
step: 590, loss: 0.05431680008769035
step: 600, loss: 0.0062440126203000546
step: 610, loss: 0.00019365799380466342
step: 620, loss: 0.01705356501042843
step: 630, loss: 2.920135375461541e-05
step: 640, loss: 0.06851118057966232
step: 650, loss: 0.030117465183138847
step: 660, loss: 0.06802407652139664
step: 670, loss: 0.16437110304832458
step: 680, loss: 0.010830785147845745
step: 690, loss: 0.0005942210555076599
step: 700, loss: 0.02446669153869152
step: 710, loss: 0.03001822531223297
step: 720, loss: 0.0010400862665846944
step: 730, loss: 0.0027829166501760483
step: 740, loss: 0.30792203545570374
step: 750, loss: 0.0041788844391703606
step: 760, loss: 0.005189793184399605
step: 770, loss: 0.06096063554286957
step: 780, loss: 0.0019072600407525897
step: 790, loss: 0.047528382390737534
step: 800, loss: 0.041069064289331436
step: 810, loss: 0.08397131413221359
step: 820, loss: 0.039945777505636215
step: 830, loss: 0.053356971591711044
step: 840, loss: 0.0002784205134958029
step: 850, loss: 0.042173370718955994
step: 860, loss: 0.045086007565259933
step: 870, loss: 0.15857316553592682
step: 880, loss: 0.0482933484017849
step: 890, loss: 0.10158664733171463
step: 900, loss: 0.0028245127759873867
step: 910, loss: 0.03858085349202156
step: 920, loss: 0.018995914608240128
step: 930, loss: 0.035708263516426086
step: 940, loss: 0.000208046127227135
step: 950, loss: 0.0012432241346687078
step: 960, loss: 0.006117886397987604
step: 970, loss: 0.043475955724716187
step: 980, loss: 0.008773727342486382
step: 990, loss: 0.016653185710310936
step: 1000, loss: 0.0540081225335598
step: 1010, loss: 0.037127383053302765
step: 1020, loss: 0.07169687002897263
step: 1030, loss: 0.08035872131586075
step: 1040, loss: 0.026393163949251175
step: 1050, loss: 0.03856524080038071
step: 1060, loss: 0.0881710797548294
step: 1070, loss: 0.04007915034890175
epoch 14: dev_f1=0.9355742296918768, f1=0.9393382352941178, best_f1=0.9418764302059497
step: 0, loss: 0.026106372475624084
step: 10, loss: 0.00370000465773046
step: 20, loss: 0.07171111553907394
step: 30, loss: 0.08895896375179291
step: 40, loss: 0.04221009090542793
step: 50, loss: 0.0019239407265558839
step: 60, loss: 0.020396705716848373
step: 70, loss: 0.003971743397414684
step: 80, loss: 0.04331297054886818
step: 90, loss: 0.030658509582281113
step: 100, loss: 0.04993654415011406
step: 110, loss: 0.02077479101717472
step: 120, loss: 0.03852737322449684
step: 130, loss: 0.03890302777290344
step: 140, loss: 0.056995924562215805
step: 150, loss: 0.022180600091814995
step: 160, loss: 0.04172253608703613
step: 170, loss: 0.003400836605578661
step: 180, loss: 0.046233367174863815
step: 190, loss: 0.0438510999083519
step: 200, loss: 0.04812082275748253
step: 210, loss: 0.03050989657640457
step: 220, loss: 0.03293152153491974
step: 230, loss: 0.010581114329397678
step: 240, loss: 0.04100852832198143
step: 250, loss: 0.029629744589328766
step: 260, loss: 0.01788332872092724
step: 270, loss: 0.018149370327591896
step: 280, loss: 0.00027154575218446553
step: 290, loss: 0.07453326880931854
step: 300, loss: 0.002611900679767132
step: 310, loss: 0.011134222149848938
step: 320, loss: 0.018408289179205894
step: 330, loss: 0.03287120908498764
step: 340, loss: 0.034182358533144
step: 350, loss: 0.03734762966632843
step: 360, loss: 0.08840937167406082
step: 370, loss: 0.01308597531169653
step: 380, loss: 0.0237723495811224
step: 390, loss: 0.016118116676807404
step: 400, loss: 9.327055886387825e-05
step: 410, loss: 0.04163286089897156
step: 420, loss: 0.0882154256105423
step: 430, loss: 0.0220062006264925
step: 440, loss: 0.014309772290289402
step: 450, loss: 0.058306142687797546
step: 460, loss: 0.04135412350296974
step: 470, loss: 0.03102538362145424
step: 480, loss: 0.018431277945637703
step: 490, loss: 0.04739370197057724
step: 500, loss: 0.042359091341495514
step: 510, loss: 0.04895918443799019
step: 520, loss: 0.01892141066491604
step: 530, loss: 0.002909497357904911
step: 540, loss: 0.022226227447390556
step: 550, loss: 0.014112014323472977
step: 560, loss: 0.004330378957092762
step: 570, loss: 0.0387711375951767
step: 580, loss: 0.02134101837873459
step: 590, loss: 0.0038539529778063297
step: 600, loss: 0.09859345108270645
step: 610, loss: 0.05884886533021927
step: 620, loss: 0.005736859515309334
step: 630, loss: 0.07440625131130219
step: 640, loss: 0.015530957840383053
step: 650, loss: 0.08452644944190979
step: 660, loss: 0.020317137241363525
step: 670, loss: 0.030670180916786194
step: 680, loss: 0.005276680923998356
step: 690, loss: 0.0004423957143444568
step: 700, loss: 0.003132774494588375
step: 710, loss: 0.012063732370734215
step: 720, loss: 0.0004076674522366375
step: 730, loss: 0.008725801482796669
step: 740, loss: 0.11152572184801102
step: 750, loss: 0.02414787746965885
step: 760, loss: 0.0002496237284503877
step: 770, loss: 0.004925933666527271
step: 780, loss: 0.02382512390613556
step: 790, loss: 0.024360276758670807
step: 800, loss: 0.01968812569975853
step: 810, loss: 0.035472188144922256
step: 820, loss: 3.3208958484465256e-05
step: 830, loss: 0.00209985813125968
step: 840, loss: 0.0668674036860466
step: 850, loss: 4.630794865079224e-05
step: 860, loss: 0.07580568641424179
step: 870, loss: 0.022335566580295563
step: 880, loss: 0.000291533418931067
step: 890, loss: 0.02719300612807274
step: 900, loss: 0.04764062166213989
step: 910, loss: 0.03947312384843826
step: 920, loss: 0.054369185119867325
step: 930, loss: 0.07081253081560135
step: 940, loss: 0.04754670336842537
step: 950, loss: 0.0076638516038656235
step: 960, loss: 0.0038888847921043634
step: 970, loss: 0.04329206421971321
step: 980, loss: 0.06501796096563339
step: 990, loss: 3.0091379812802188e-05
step: 1000, loss: 0.019870080053806305
step: 1010, loss: 9.85569495242089e-05
step: 1020, loss: 0.008029750548303127
step: 1030, loss: 0.04792653024196625
step: 1040, loss: 0.028983892872929573
step: 1050, loss: 0.04407048970460892
step: 1060, loss: 0.04297664016485214
step: 1070, loss: 0.03445271775126457
epoch 15: dev_f1=0.9332079021636878, f1=0.9363678588016722, best_f1=0.9418764302059497
step: 0, loss: 0.06625637412071228
step: 10, loss: 0.0397510901093483
step: 20, loss: 0.011959911324083805
step: 30, loss: 0.040011826902627945
step: 40, loss: 0.015251567587256432
step: 50, loss: 0.022814685478806496
step: 60, loss: 1.320604860666208e-05
step: 70, loss: 0.024380221962928772
step: 80, loss: 0.00023925225832499564
step: 90, loss: 0.044699400663375854
step: 100, loss: 0.0027305379044264555
step: 110, loss: 0.0565047487616539
step: 120, loss: 7.849027315387502e-05
step: 130, loss: 0.08623829483985901
step: 140, loss: 0.01799938827753067
step: 150, loss: 0.0005153987440280616
step: 160, loss: 0.06867827475070953
step: 170, loss: 0.03048449195921421
step: 180, loss: 0.17956605553627014
step: 190, loss: 0.025443371385335922
step: 200, loss: 0.008972709067165852
step: 210, loss: 0.028913134709000587
step: 220, loss: 0.028518790379166603
step: 230, loss: 0.03629031032323837
step: 240, loss: 0.022038720548152924
step: 250, loss: 9.421305730938911e-05
step: 260, loss: 0.011517475359141827
step: 270, loss: 0.06936714053153992
step: 280, loss: 0.0461718812584877
step: 290, loss: 3.047146492463071e-05
step: 300, loss: 0.04172433912754059
step: 310, loss: 0.011345777660608292
step: 320, loss: 0.026752334088087082
step: 330, loss: 0.019551821053028107
step: 340, loss: 0.03018730692565441
step: 350, loss: 0.0934441015124321
step: 360, loss: 0.04877094551920891
step: 370, loss: 0.03487859666347504
step: 380, loss: 0.00031656408100388944
step: 390, loss: 0.014843474142253399
step: 400, loss: 0.016500964760780334
step: 410, loss: 0.00033708286355249584
step: 420, loss: 0.042179618030786514
step: 430, loss: 0.026786379516124725
step: 440, loss: 0.02211606688797474
step: 450, loss: 0.024288054555654526
step: 460, loss: 0.05701865628361702
step: 470, loss: 2.234323983429931e-05
step: 480, loss: 0.019159192219376564
step: 490, loss: 0.0011260486207902431
step: 500, loss: 4.2413550545461476e-05
step: 510, loss: 0.001591587788425386
step: 520, loss: 0.0007038253825157881
step: 530, loss: 0.05134611949324608
step: 540, loss: 0.00017235256382264197
step: 550, loss: 0.03733516111969948
step: 560, loss: 0.002560199936851859
step: 570, loss: 0.04208803549408913
step: 580, loss: 0.021724602207541466
step: 590, loss: 0.0009210117277689278
step: 600, loss: 0.048850540071725845
step: 610, loss: 5.730495831812732e-05
step: 620, loss: 0.04469309374690056
step: 630, loss: 0.005078969988971949
step: 640, loss: 0.009953886270523071
step: 650, loss: 0.12858277559280396
step: 660, loss: 0.025714296847581863
step: 670, loss: 0.0013223706046119332
step: 680, loss: 0.01657908223569393
step: 690, loss: 0.02632955275475979
step: 700, loss: 0.13684074580669403
step: 710, loss: 0.04601123556494713
step: 720, loss: 0.0650089681148529
step: 730, loss: 0.04737837240099907
step: 740, loss: 0.0599978007376194
step: 750, loss: 0.037397351115942
step: 760, loss: 0.003111951518803835
step: 770, loss: 0.004359696060419083
step: 780, loss: 0.0026610041968524456
step: 790, loss: 0.047298502177000046
step: 800, loss: 6.469520303653553e-05
step: 810, loss: 0.010854018852114677
step: 820, loss: 0.07369530946016312
step: 830, loss: 0.010972533375024796
step: 840, loss: 0.020391227677464485
step: 850, loss: 0.027751075103878975
step: 860, loss: 0.01376823615282774
step: 870, loss: 2.3486962163588032e-05
step: 880, loss: 3.041170748474542e-05
step: 890, loss: 0.05821731686592102
step: 900, loss: 0.04235808923840523
step: 910, loss: 0.01086448598653078
step: 920, loss: 0.00025332404766231775
step: 930, loss: 0.0027316531632095575
step: 940, loss: 0.050863880664110184
step: 950, loss: 0.00013897483586333692
step: 960, loss: 0.011255595833063126
step: 970, loss: 0.03365140035748482
step: 980, loss: 0.018802043050527573
step: 990, loss: 0.047282420098781586
step: 1000, loss: 7.894444570410997e-05
step: 1010, loss: 0.05617783963680267
step: 1020, loss: 0.0032239549327641726
step: 1030, loss: 0.018446164205670357
step: 1040, loss: 0.01904183067381382
step: 1050, loss: 4.976013588020578e-05
step: 1060, loss: 0.07957560569047928
step: 1070, loss: 0.00011631625238806009
epoch 16: dev_f1=0.9357277882797731, f1=0.9434137291280148, best_f1=0.9418764302059497
step: 0, loss: 0.0004977694479748607
step: 10, loss: 0.02897321991622448
step: 20, loss: 6.35111064184457e-05
step: 30, loss: 0.08821773529052734
step: 40, loss: 0.10583089292049408
step: 50, loss: 0.05064535140991211
step: 60, loss: 0.0002189085353165865
step: 70, loss: 0.0484931506216526
step: 80, loss: 0.00040957090095616877
step: 90, loss: 0.0005045199650339782
step: 100, loss: 7.584670674987137e-05
step: 110, loss: 0.05394422635436058
step: 120, loss: 0.01676326058804989
step: 130, loss: 0.018102483823895454
step: 140, loss: 0.020299451425671577
step: 150, loss: 1.9512686776579358e-05
step: 160, loss: 0.020061198621988297
step: 170, loss: 0.022505180910229683
step: 180, loss: 0.02878449112176895
step: 190, loss: 0.01736023835837841
step: 200, loss: 0.00022225535940378904
step: 210, loss: 0.07798077166080475
step: 220, loss: 0.0013107487466186285
step: 230, loss: 0.0304900910705328
step: 240, loss: 0.0012675838079303503
step: 250, loss: 0.002808137098327279
step: 260, loss: 0.12105122953653336
step: 270, loss: 0.012227804400026798
step: 280, loss: 0.023464631289243698
step: 290, loss: 0.0025091972202062607
step: 300, loss: 2.1374909920268692e-05
step: 310, loss: 0.022429203614592552
step: 320, loss: 0.0016261717537418008
step: 330, loss: 0.0041351765394210815
step: 340, loss: 4.417596210259944e-05
step: 350, loss: 0.04818516969680786
step: 360, loss: 2.791479892039206e-05
step: 370, loss: 0.14895397424697876
step: 380, loss: 0.003548751585185528
step: 390, loss: 0.03142901882529259
step: 400, loss: 0.03747368976473808
step: 410, loss: 0.026122812181711197
step: 420, loss: 0.04823148623108864
step: 430, loss: 0.008595607243478298
step: 440, loss: 6.600697815883905e-05
step: 450, loss: 0.02579154632985592
step: 460, loss: 0.024078670889139175
step: 470, loss: 0.00797029584646225
step: 480, loss: 2.01571274374146e-05
step: 490, loss: 0.031378764659166336
step: 500, loss: 0.013995593413710594
step: 510, loss: 0.03058747760951519
step: 520, loss: 0.000671284506097436
step: 530, loss: 0.07329507917165756
step: 540, loss: 1.2490767403505743e-05
step: 550, loss: 0.026290271431207657
step: 560, loss: 0.0031914478167891502
step: 570, loss: 0.005537315737456083
step: 580, loss: 4.469740088097751e-05
step: 590, loss: 0.04900561645627022
step: 600, loss: 0.0002495020453352481
step: 610, loss: 6.320305692497641e-05
step: 620, loss: 0.046876221895217896
step: 630, loss: 0.02474815957248211
step: 640, loss: 0.01285844761878252
step: 650, loss: 0.027504412457346916
step: 660, loss: 0.04653209075331688
step: 670, loss: 0.0028152037411928177
step: 680, loss: 2.638443220348563e-05
step: 690, loss: 0.004102413076907396
step: 700, loss: 0.027583664283156395
step: 710, loss: 2.8994743843213655e-05
step: 720, loss: 1.148496721725678e-05
step: 730, loss: 0.10844053328037262
step: 740, loss: 0.004695571027696133
step: 750, loss: 0.04506322741508484
step: 760, loss: 0.04671719670295715
step: 770, loss: 0.03783535212278366
step: 780, loss: 0.0008533838554285467
step: 790, loss: 0.0003171962744090706
step: 800, loss: 0.0007813524571247399
step: 810, loss: 0.012306584976613522
step: 820, loss: 0.044539548456668854
step: 830, loss: 0.026750436052680016
step: 840, loss: 0.0001550629094708711
step: 850, loss: 0.00045827621943317354
step: 860, loss: 0.1150052398443222
step: 870, loss: 0.03816353157162666
step: 880, loss: 0.03644021600484848
step: 890, loss: 0.04229637607932091
step: 900, loss: 5.53359896002803e-05
step: 910, loss: 0.03222082182765007
step: 920, loss: 0.03738432005047798
step: 930, loss: 0.0030832220800220966
step: 940, loss: 0.022534795105457306
step: 950, loss: 0.019023001194000244
step: 960, loss: 0.009632222354412079
step: 970, loss: 0.028585927560925484
step: 980, loss: 0.003959608729928732
step: 990, loss: 0.04083309322595596
step: 1000, loss: 1.7191958249895833e-05
step: 1010, loss: 0.019367024302482605
step: 1020, loss: 0.07550795376300812
step: 1030, loss: 3.384441515663639e-05
step: 1040, loss: 0.0031599323265254498
step: 1050, loss: 0.0009300510282628238
step: 1060, loss: 0.007222856394946575
step: 1070, loss: 0.00037513821735046804
epoch 17: dev_f1=0.9339667458432305, f1=0.9409559512652297, best_f1=0.9418764302059497
step: 0, loss: 0.04000493511557579
step: 10, loss: 0.011186905205249786
step: 20, loss: 0.07749531418085098
step: 30, loss: 1.7165684766951017e-05
step: 40, loss: 0.024881450459361076
step: 50, loss: 3.314473360660486e-05
step: 60, loss: 0.010391547344624996
step: 70, loss: 0.049977853894233704
step: 80, loss: 0.008248213678598404
step: 90, loss: 0.04274638742208481
step: 100, loss: 0.1174231544137001
step: 110, loss: 0.03986281901597977
step: 120, loss: 9.203224180964753e-05
step: 130, loss: 1.3254343684820924e-05
step: 140, loss: 0.040827564895153046
step: 150, loss: 0.003158086445182562
step: 160, loss: 0.016782943159341812
step: 170, loss: 0.06008314713835716
step: 180, loss: 0.026078278198838234
step: 190, loss: 0.011159433051943779
step: 200, loss: 0.026658091694116592
step: 210, loss: 0.010335138067603111
step: 220, loss: 0.0027567034121602774
step: 230, loss: 0.06456004828214645
step: 240, loss: 0.08917158097028732
step: 250, loss: 0.059895820915699005
step: 260, loss: 0.04050491750240326
step: 270, loss: 5.228647205512971e-05
step: 280, loss: 0.052873652428388596
step: 290, loss: 0.09871095418930054
step: 300, loss: 2.083840809063986e-05
step: 310, loss: 0.10796095430850983
step: 320, loss: 0.0005831964081153274
step: 330, loss: 0.00016289799532387406
step: 340, loss: 0.07515133172273636
step: 350, loss: 0.040448032319545746
step: 360, loss: 0.021059934049844742
step: 370, loss: 0.041466984897851944
step: 380, loss: 0.012133007869124413
step: 390, loss: 0.06402729451656342
step: 400, loss: 0.0816340446472168
step: 410, loss: 0.03659746050834656
step: 420, loss: 1.869695734058041e-05
step: 430, loss: 0.025823354721069336
step: 440, loss: 0.02670259028673172
step: 450, loss: 6.640764331677929e-05
step: 460, loss: 0.0036319128703325987
step: 470, loss: 0.040886785835027695
step: 480, loss: 1.977691863430664e-05
step: 490, loss: 0.024623490869998932
step: 500, loss: 0.03652053698897362
step: 510, loss: 0.03206288814544678
step: 520, loss: 2.5688092136988416e-05
step: 530, loss: 0.02372416853904724
step: 540, loss: 0.03698977455496788
step: 550, loss: 0.027022207155823708
step: 560, loss: 0.05770605057477951
step: 570, loss: 0.01860976032912731
step: 580, loss: 0.05159112066030502
step: 590, loss: 0.019538672640919685
step: 600, loss: 0.020984983071684837
step: 610, loss: 0.03399408981204033
step: 620, loss: 0.04023272544145584
step: 630, loss: 3.956194996135309e-05
step: 640, loss: 0.032172419130802155
step: 650, loss: 0.04240401089191437
step: 660, loss: 0.02298375964164734
step: 670, loss: 0.03081880323588848
step: 680, loss: 0.00011999048729194328
step: 690, loss: 1.7314639990217984e-05
step: 700, loss: 0.03114970773458481
step: 710, loss: 0.000653275172226131
step: 720, loss: 0.014713226817548275
step: 730, loss: 0.06189775466918945
step: 740, loss: 0.01402876153588295
step: 750, loss: 0.03886939212679863
step: 760, loss: 0.03857988491654396
step: 770, loss: 0.037977296859025955
step: 780, loss: 0.06638836115598679
step: 790, loss: 0.03438485413789749
step: 800, loss: 0.0342077910900116
step: 810, loss: 0.01751370169222355
step: 820, loss: 0.059351544827222824
step: 830, loss: 0.023827431723475456
step: 840, loss: 0.03943570703268051
step: 850, loss: 0.013459693640470505
step: 860, loss: 3.1441275496035814e-05
step: 870, loss: 0.026590358465909958
step: 880, loss: 0.05034942924976349
step: 890, loss: 0.008723114617168903
step: 900, loss: 0.03216845169663429
step: 910, loss: 0.04718887805938721
step: 920, loss: 0.043161895126104355
step: 930, loss: 0.02025287039577961
step: 940, loss: 0.05290491133928299
step: 950, loss: 3.5221659345552325e-05
step: 960, loss: 0.093478724360466
step: 970, loss: 0.02215324342250824
step: 980, loss: 0.04728999733924866
step: 990, loss: 6.037384446244687e-05
step: 1000, loss: 0.056196428835392
step: 1010, loss: 0.019873252138495445
step: 1020, loss: 1.827930100262165e-05
step: 1030, loss: 0.08346172422170639
step: 1040, loss: 0.08676543831825256
step: 1050, loss: 0.018289780244231224
step: 1060, loss: 0.09239701181650162
step: 1070, loss: 0.04251232370734215
epoch 18: dev_f1=0.9366729678638942, f1=0.9428704133766836, best_f1=0.9418764302059497
step: 0, loss: 0.02441011182963848
step: 10, loss: 0.026972122490406036
step: 20, loss: 0.0003218259662389755
step: 30, loss: 0.011300326324999332
step: 40, loss: 0.0515894740819931
step: 50, loss: 0.025736752897500992
step: 60, loss: 0.07603086531162262
step: 70, loss: 0.05693218857049942
step: 80, loss: 0.0001645703159738332
step: 90, loss: 0.029480040073394775
step: 100, loss: 0.028879966586828232
step: 110, loss: 0.02176513336598873
step: 120, loss: 1.7355627278448083e-05
step: 130, loss: 0.01625188998878002
step: 140, loss: 0.0001740134321153164
step: 150, loss: 0.0424785241484642
step: 160, loss: 0.02585477940738201
step: 170, loss: 0.021927360445261
step: 180, loss: 0.09107931703329086
step: 190, loss: 0.04158298671245575
step: 200, loss: 0.06153339520096779
step: 210, loss: 0.031155956909060478
step: 220, loss: 0.02024710364639759
step: 230, loss: 0.02625860460102558
step: 240, loss: 1.781032005965244e-05
step: 250, loss: 0.022416984662413597
step: 260, loss: 0.04820103198289871
step: 270, loss: 0.024138977751135826
step: 280, loss: 0.03359386324882507
step: 290, loss: 0.036518096923828125
step: 300, loss: 0.04138723760843277
step: 310, loss: 0.02477840706706047
step: 320, loss: 0.0004545655392576009
step: 330, loss: 0.05053127557039261
step: 340, loss: 0.022006571292877197
step: 350, loss: 0.026920685544610023
step: 360, loss: 0.049882788211107254
step: 370, loss: 0.012662289664149284
step: 380, loss: 0.035887882113456726
step: 390, loss: 0.02802475355565548
step: 400, loss: 0.003294155467301607
step: 410, loss: 0.0005201470921747386
step: 420, loss: 0.02858108840882778
step: 430, loss: 0.06829604506492615
step: 440, loss: 0.006541998591274023
step: 450, loss: 0.0011904910206794739
step: 460, loss: 0.021914955228567123
step: 470, loss: 5.083791256765835e-05
step: 480, loss: 0.03308584913611412
step: 490, loss: 0.055489957332611084
step: 500, loss: 0.03511180728673935
step: 510, loss: 0.01832067035138607
step: 520, loss: 0.0048989648930728436
step: 530, loss: 0.04997888579964638
step: 540, loss: 0.021479789167642593
step: 550, loss: 0.017214052379131317
step: 560, loss: 2.6723808332462795e-05
step: 570, loss: 0.030008938163518906
step: 580, loss: 0.03755955398082733
step: 590, loss: 0.04106157273054123
step: 600, loss: 0.07047189772129059
step: 610, loss: 0.00017040515376720577
step: 620, loss: 0.026114946231245995
step: 630, loss: 1.2129429705964867e-05
step: 640, loss: 0.000624565000180155
step: 650, loss: 0.014879807829856873
step: 660, loss: 0.02079247683286667
step: 670, loss: 0.04695020616054535
step: 680, loss: 0.023589318618178368
step: 690, loss: 0.06231842190027237
step: 700, loss: 0.04186764359474182
step: 710, loss: 0.139686718583107
step: 720, loss: 0.08406639099121094
step: 730, loss: 0.001500892685726285
step: 740, loss: 0.05018232762813568
step: 750, loss: 0.016502514481544495
step: 760, loss: 0.022970721125602722
step: 770, loss: 0.08640121668577194
step: 780, loss: 0.03559204563498497
step: 790, loss: 0.01697482541203499
step: 800, loss: 3.645095057436265e-05
step: 810, loss: 0.06893547624349594
step: 820, loss: 0.031896352767944336
step: 830, loss: 0.028269348666071892
step: 840, loss: 0.02002222090959549
step: 850, loss: 0.06484165042638779
step: 860, loss: 0.02838202379643917
step: 870, loss: 0.023823736235499382
step: 880, loss: 0.07217609882354736
step: 890, loss: 0.01537392195314169
step: 900, loss: 0.00861704908311367
step: 910, loss: 0.048185478895902634
step: 920, loss: 0.0736057460308075
step: 930, loss: 0.015620114281773567
step: 940, loss: 0.022467762231826782
step: 950, loss: 4.138823351240717e-05
step: 960, loss: 0.01293640211224556
step: 970, loss: 1.3831833712174557e-05
step: 980, loss: 2.9998260288266465e-05
step: 990, loss: 2.2464932044385932e-05
step: 1000, loss: 0.01751532591879368
step: 1010, loss: 0.0193000640720129
step: 1020, loss: 0.026064133271574974
step: 1030, loss: 0.003509227419272065
step: 1040, loss: 1.5001506653788965e-05
step: 1050, loss: 0.07018709182739258
step: 1060, loss: 1.9151308151776902e-05
step: 1070, loss: 2.084255902445875e-05
epoch 19: dev_f1=0.9348335677449601, f1=0.9351724137931035, best_f1=0.9418764302059497
step: 0, loss: 0.007002345286309719
step: 10, loss: 0.003140437649562955
step: 20, loss: 0.04220891743898392
step: 30, loss: 0.04012949764728546
step: 40, loss: 0.01641565002501011
step: 50, loss: 0.059408657252788544
step: 60, loss: 1.2751506801578216e-05
step: 70, loss: 0.022967854514718056
step: 80, loss: 2.9231874577817507e-05
step: 90, loss: 2.7144060368300416e-05
step: 100, loss: 3.1575509638059884e-05
step: 110, loss: 0.003261702135205269
step: 120, loss: 0.05254093185067177
step: 130, loss: 0.03746103122830391
step: 140, loss: 0.04027050733566284
step: 150, loss: 0.00027057697298005223
step: 160, loss: 0.0015916263218969107
step: 170, loss: 0.02272622101008892
step: 180, loss: 0.039928462356328964
step: 190, loss: 0.05129755288362503
step: 200, loss: 0.054710350930690765
step: 210, loss: 0.026239046826958656
step: 220, loss: 0.031992193311452866
step: 230, loss: 0.02520066499710083
step: 240, loss: 0.01866861991584301
step: 250, loss: 2.786041295621544e-05
step: 260, loss: 4.66583514935337e-05
step: 270, loss: 1.8491889932192862e-05
step: 280, loss: 0.07525275647640228
step: 290, loss: 0.04519512876868248
step: 300, loss: 0.029070856049656868
step: 310, loss: 0.007418079301714897
step: 320, loss: 0.025082388892769814
step: 330, loss: 0.0364554189145565
step: 340, loss: 3.0768165743211284e-05
step: 350, loss: 1.3194807252148166e-05
step: 360, loss: 5.749587216996588e-05
step: 370, loss: 0.011068145744502544
step: 380, loss: 0.004057019948959351
step: 390, loss: 2.547634176153224e-05
step: 400, loss: 0.020508496090769768
step: 410, loss: 7.613461639266461e-05
step: 420, loss: 0.10264043509960175
step: 430, loss: 1.6595773558947258e-05
step: 440, loss: 0.013550232164561749
step: 450, loss: 2.548737575125415e-05
step: 460, loss: 0.021669404581189156
step: 470, loss: 0.0005598015850409865
step: 480, loss: 0.07200058549642563
step: 490, loss: 0.0557776540517807
step: 500, loss: 3.6038596590515226e-05
step: 510, loss: 0.00022104984964244068
step: 520, loss: 0.024655790999531746
step: 530, loss: 0.020946338772773743
step: 540, loss: 0.0002497882233001292
step: 550, loss: 0.00028345853206701577
step: 560, loss: 1.791825889085885e-05
step: 570, loss: 0.030324943363666534
step: 580, loss: 0.001139447558671236
step: 590, loss: 3.916456989827566e-05
step: 600, loss: 0.005642628762871027
step: 610, loss: 0.027816029265522957
step: 620, loss: 0.06601053476333618
step: 630, loss: 0.02478013187646866
step: 640, loss: 3.5900924558518454e-05
step: 650, loss: 0.00014127443137113005
step: 660, loss: 0.013928234577178955
step: 670, loss: 0.002730879932641983
step: 680, loss: 0.031236834824085236
step: 690, loss: 0.012560339644551277
step: 700, loss: 0.0019075889140367508
step: 710, loss: 0.03917689248919487
step: 720, loss: 2.063693682430312e-05
step: 730, loss: 0.02581162191927433
step: 740, loss: 0.022558098658919334
step: 750, loss: 1.2475881703721825e-05
step: 760, loss: 7.693238876527175e-05
step: 770, loss: 0.01578780636191368
step: 780, loss: 0.00011407561396481469
step: 790, loss: 0.010472423397004604
step: 800, loss: 0.06343702226877213
step: 810, loss: 0.043056320399045944
step: 820, loss: 0.02314179576933384
step: 830, loss: 0.012311004102230072
step: 840, loss: 1.7124915757449344e-05
step: 850, loss: 0.010134311392903328
step: 860, loss: 0.016734512522816658
step: 870, loss: 0.026028059422969818
step: 880, loss: 0.00019064501975663006
step: 890, loss: 2.3761973352520727e-05
step: 900, loss: 0.02806095965206623
step: 910, loss: 0.020359758287668228
step: 920, loss: 0.05626456439495087
step: 930, loss: 0.0018207047833129764
step: 940, loss: 0.012449314817786217
step: 950, loss: 0.051964689046144485
step: 960, loss: 2.482577838236466e-05
step: 970, loss: 0.07211356610059738
step: 980, loss: 0.05376938730478287
step: 990, loss: 2.774770291580353e-05
step: 1000, loss: 1.3585989108833019e-05
step: 1010, loss: 0.0029367890674620867
step: 1020, loss: 0.022678129374980927
step: 1030, loss: 0.036262281239032745
step: 1040, loss: 0.0009991247206926346
step: 1050, loss: 0.042762890458106995
step: 1060, loss: 1.2587594937940594e-05
step: 1070, loss: 0.06487157940864563
epoch 20: dev_f1=0.935040303461356, f1=0.9374416433239963, best_f1=0.9418764302059497
