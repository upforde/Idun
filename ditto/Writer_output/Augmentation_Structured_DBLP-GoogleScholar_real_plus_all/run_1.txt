cuda
Device: cuda
step: 0, loss: 0.590615451335907
step: 10, loss: 0.418487548828125
step: 20, loss: 0.38706761598587036
step: 30, loss: 0.30586615204811096
step: 40, loss: 0.4163615107536316
step: 50, loss: 0.20430302619934082
step: 60, loss: 0.5124996900558472
step: 70, loss: 0.233367919921875
step: 80, loss: 0.30883392691612244
step: 90, loss: 0.30980363488197327
step: 100, loss: 0.09087026119232178
step: 110, loss: 0.12726551294326782
step: 120, loss: 0.20376770198345184
step: 130, loss: 0.2727352976799011
step: 140, loss: 0.17506946623325348
step: 150, loss: 0.25323769450187683
step: 160, loss: 0.14445215463638306
step: 170, loss: 0.14461749792099
step: 180, loss: 0.24902935326099396
step: 190, loss: 0.050966985523700714
step: 200, loss: 0.11033299565315247
step: 210, loss: 0.1297363042831421
step: 220, loss: 0.17465904355049133
step: 230, loss: 0.05948588624596596
step: 240, loss: 0.12805601954460144
step: 250, loss: 0.13162292540073395
step: 260, loss: 0.10696253925561905
step: 270, loss: 0.0481363944709301
step: 280, loss: 0.24407021701335907
step: 290, loss: 0.1866069734096527
step: 300, loss: 0.12738974392414093
step: 310, loss: 0.07387209683656693
step: 320, loss: 0.13986116647720337
step: 330, loss: 0.22539672255516052
step: 340, loss: 0.20159728825092316
step: 350, loss: 0.0772823691368103
step: 360, loss: 0.2585800886154175
step: 370, loss: 0.0842326208949089
step: 380, loss: 0.2382781058549881
step: 390, loss: 0.13794536888599396
step: 400, loss: 0.2636350691318512
step: 410, loss: 0.08577118068933487
step: 420, loss: 0.2902245819568634
step: 430, loss: 0.11660953611135483
step: 440, loss: 0.2254691869020462
step: 450, loss: 0.14135313034057617
step: 460, loss: 0.10139086097478867
step: 470, loss: 0.05316256731748581
step: 480, loss: 0.18475030362606049
step: 490, loss: 0.11053046584129333
step: 500, loss: 0.10850879549980164
step: 510, loss: 0.09528804570436478
step: 520, loss: 0.09915381669998169
step: 530, loss: 0.09563004970550537
step: 540, loss: 0.05059928447008133
step: 550, loss: 0.14276427030563354
step: 560, loss: 0.26516562700271606
step: 570, loss: 0.10527690500020981
step: 580, loss: 0.18118207156658173
step: 590, loss: 0.21595418453216553
step: 600, loss: 0.09047165513038635
step: 610, loss: 0.11271265149116516
step: 620, loss: 0.08585592359304428
step: 630, loss: 0.2442110776901245
step: 640, loss: 0.12960681319236755
step: 650, loss: 0.12741099298000336
step: 660, loss: 0.11611809581518173
step: 670, loss: 0.11079642921686172
step: 680, loss: 0.19629976153373718
step: 690, loss: 0.1033962219953537
step: 700, loss: 0.12304088473320007
step: 710, loss: 0.004737185314297676
step: 720, loss: 0.0990704745054245
step: 730, loss: 0.02610107697546482
step: 740, loss: 0.026596520096063614
step: 750, loss: 0.10488656908273697
step: 760, loss: 0.09755633771419525
step: 770, loss: 0.11019984632730484
step: 780, loss: 0.13753414154052734
step: 790, loss: 0.23988287150859833
step: 800, loss: 0.14390790462493896
step: 810, loss: 0.1420222371816635
step: 820, loss: 0.10638691484928131
step: 830, loss: 0.11726422607898712
step: 840, loss: 0.058851901441812515
step: 850, loss: 0.08434495329856873
step: 860, loss: 0.1037108302116394
step: 870, loss: 0.13179104030132294
step: 880, loss: 0.053096186369657516
step: 890, loss: 0.10178368538618088
step: 900, loss: 0.1608768105506897
step: 910, loss: 0.10745415836572647
step: 920, loss: 0.030132438987493515
step: 930, loss: 0.08934035897254944
step: 940, loss: 0.21210229396820068
step: 950, loss: 0.21319794654846191
step: 960, loss: 0.048461783677339554
step: 970, loss: 0.48574504256248474
step: 980, loss: 0.31488630175590515
step: 990, loss: 0.05699663609266281
step: 1000, loss: 0.13603177666664124
step: 1010, loss: 0.2452918440103531
step: 1020, loss: 0.10804391652345657
step: 1030, loss: 0.1668548732995987
step: 1040, loss: 0.1139330267906189
step: 1050, loss: 0.08202696591615677
step: 1060, loss: 0.3139578700065613
step: 1070, loss: 0.2569560706615448
epoch 1: dev_f1=0.927470534904805, f1=0.9315315315315316, best_f1=0.9315315315315316
step: 0, loss: 0.033003732562065125
step: 10, loss: 0.18996955454349518
step: 20, loss: 0.05901836231350899
step: 30, loss: 0.047848667949438095
step: 40, loss: 0.2679935395717621
step: 50, loss: 0.07978489249944687
step: 60, loss: 0.04439647123217583
step: 70, loss: 0.12025637924671173
step: 80, loss: 0.08695871382951736
step: 90, loss: 0.1439894437789917
step: 100, loss: 0.0837993323802948
step: 110, loss: 0.051895152777433395
step: 120, loss: 0.027776559814810753
step: 130, loss: 0.07229697704315186
step: 140, loss: 0.13440638780593872
step: 150, loss: 0.08548525720834732
step: 160, loss: 0.1530618667602539
step: 170, loss: 0.1181824654340744
step: 180, loss: 0.2774863839149475
step: 190, loss: 0.09258533269166946
step: 200, loss: 0.10264885425567627
step: 210, loss: 0.05647611245512962
step: 220, loss: 0.04677709564566612
step: 230, loss: 0.017373312264680862
step: 240, loss: 0.11891798675060272
step: 250, loss: 0.057603515684604645
step: 260, loss: 0.22206734120845795
step: 270, loss: 0.02920435555279255
step: 280, loss: 0.03665643185377121
step: 290, loss: 0.15611933171749115
step: 300, loss: 0.0799737423658371
step: 310, loss: 0.0969868153333664
step: 320, loss: 0.18306797742843628
step: 330, loss: 0.10935209691524506
step: 340, loss: 0.03307662159204483
step: 350, loss: 0.12654297053813934
step: 360, loss: 0.11715012043714523
step: 370, loss: 0.19800275564193726
step: 380, loss: 0.049745824187994
step: 390, loss: 0.07320433855056763
step: 400, loss: 0.1272822618484497
step: 410, loss: 0.053530581295490265
step: 420, loss: 0.14970779418945312
step: 430, loss: 0.08921831101179123
step: 440, loss: 0.11781742423772812
step: 450, loss: 0.044398676604032516
step: 460, loss: 0.06778950244188309
step: 470, loss: 0.043582022190093994
step: 480, loss: 0.13794611394405365
step: 490, loss: 0.18945440649986267
step: 500, loss: 0.0697108656167984
step: 510, loss: 0.08152300119400024
step: 520, loss: 0.10429122298955917
step: 530, loss: 0.045677971094846725
step: 540, loss: 0.09692111611366272
step: 550, loss: 0.032562512904405594
step: 560, loss: 0.12598824501037598
step: 570, loss: 0.0997805967926979
step: 580, loss: 0.070632204413414
step: 590, loss: 0.12647736072540283
step: 600, loss: 0.04227374121546745
step: 610, loss: 0.10473636537790298
step: 620, loss: 0.14279672503471375
step: 630, loss: 0.05874161049723625
step: 640, loss: 0.0666409283876419
step: 650, loss: 0.15605399012565613
step: 660, loss: 0.042154863476753235
step: 670, loss: 0.07415458559989929
step: 680, loss: 0.04056820273399353
step: 690, loss: 0.221566304564476
step: 700, loss: 0.11640029400587082
step: 710, loss: 0.05475051701068878
step: 720, loss: 0.12316736578941345
step: 730, loss: 0.2487698197364807
step: 740, loss: 0.0745721161365509
step: 750, loss: 0.06874936819076538
step: 760, loss: 0.11704658716917038
step: 770, loss: 0.10717310011386871
step: 780, loss: 0.0713845044374466
step: 790, loss: 0.04520142450928688
step: 800, loss: 0.16195856034755707
step: 810, loss: 0.05795716494321823
step: 820, loss: 0.08049152791500092
step: 830, loss: 0.08323705196380615
step: 840, loss: 0.15458498895168304
step: 850, loss: 0.005533245857805014
step: 860, loss: 0.035301703959703445
step: 870, loss: 0.07866855710744858
step: 880, loss: 0.05533992871642113
step: 890, loss: 0.09510289877653122
step: 900, loss: 0.04052891582250595
step: 910, loss: 0.013618246652185917
step: 920, loss: 0.23175565898418427
step: 930, loss: 0.08537865430116653
step: 940, loss: 0.03896543011069298
step: 950, loss: 0.02278977818787098
step: 960, loss: 0.24857306480407715
step: 970, loss: 0.08037803322076797
step: 980, loss: 0.08057283610105515
step: 990, loss: 0.08647489547729492
step: 1000, loss: 0.07651886343955994
step: 1010, loss: 0.22999417781829834
step: 1020, loss: 0.09593432396650314
step: 1030, loss: 0.14669165015220642
step: 1040, loss: 0.15869690477848053
step: 1050, loss: 0.17203392088413239
step: 1060, loss: 0.1802891343832016
step: 1070, loss: 0.015663832426071167
epoch 2: dev_f1=0.9364214350590373, f1=0.9330316742081448, best_f1=0.9330316742081448
step: 0, loss: 0.030853034928441048
step: 10, loss: 0.057106152176856995
step: 20, loss: 0.051970332860946655
step: 30, loss: 0.13853691518306732
step: 40, loss: 0.12128409743309021
step: 50, loss: 0.04930461198091507
step: 60, loss: 0.05970621854066849
step: 70, loss: 0.06970098614692688
step: 80, loss: 0.004627106245607138
step: 90, loss: 0.06492452323436737
step: 100, loss: 0.08006250858306885
step: 110, loss: 0.017981912940740585
step: 120, loss: 0.14654771983623505
step: 130, loss: 0.023285912349820137
step: 140, loss: 0.08679113537073135
step: 150, loss: 0.1041160374879837
step: 160, loss: 0.09188134223222733
step: 170, loss: 0.08813083171844482
step: 180, loss: 0.025649715214967728
step: 190, loss: 0.02532520890235901
step: 200, loss: 0.22144778072834015
step: 210, loss: 0.06635399162769318
step: 220, loss: 0.02751348912715912
step: 230, loss: 0.11290506273508072
step: 240, loss: 0.1011003702878952
step: 250, loss: 0.10817717760801315
step: 260, loss: 0.17581698298454285
step: 270, loss: 0.10587384551763535
step: 280, loss: 0.010474488139152527
step: 290, loss: 0.08172021061182022
step: 300, loss: 0.09730037301778793
step: 310, loss: 0.04929325357079506
step: 320, loss: 0.06545083969831467
step: 330, loss: 0.05554157868027687
step: 340, loss: 0.07626696676015854
step: 350, loss: 0.134120374917984
step: 360, loss: 0.07952322065830231
step: 370, loss: 0.05078709125518799
step: 380, loss: 0.04648013040423393
step: 390, loss: 0.0017797366017475724
step: 400, loss: 0.20200929045677185
step: 410, loss: 0.060498230159282684
step: 420, loss: 0.07951109111309052
step: 430, loss: 0.28129491209983826
step: 440, loss: 0.11781148612499237
step: 450, loss: 0.06153963506221771
step: 460, loss: 0.16382545232772827
step: 470, loss: 0.111658476293087
step: 480, loss: 0.06055108830332756
step: 490, loss: 0.062268033623695374
step: 500, loss: 0.13916395604610443
step: 510, loss: 0.04430582374334335
step: 520, loss: 0.03043666109442711
step: 530, loss: 0.28032058477401733
step: 540, loss: 0.013696009293198586
step: 550, loss: 0.1640302985906601
step: 560, loss: 0.0762770026922226
step: 570, loss: 0.0939064472913742
step: 580, loss: 0.07980924099683762
step: 590, loss: 0.12995992600917816
step: 600, loss: 0.07559560984373093
step: 610, loss: 0.13990245759487152
step: 620, loss: 0.00777420774102211
step: 630, loss: 0.06600676476955414
step: 640, loss: 0.05643869563937187
step: 650, loss: 0.019466236233711243
step: 660, loss: 0.0745592713356018
step: 670, loss: 0.06354491412639618
step: 680, loss: 0.037769172340631485
step: 690, loss: 0.13599605858325958
step: 700, loss: 0.0668475404381752
step: 710, loss: 0.006434454116970301
step: 720, loss: 0.09225384145975113
step: 730, loss: 0.06710147112607956
step: 740, loss: 0.02920127473771572
step: 750, loss: 0.05156310647726059
step: 760, loss: 0.08814510703086853
step: 770, loss: 0.015373487025499344
step: 780, loss: 0.15057675540447235
step: 790, loss: 0.020577313378453255
step: 800, loss: 0.07580472528934479
step: 810, loss: 0.16163429617881775
step: 820, loss: 0.029239583760499954
step: 830, loss: 0.09300920367240906
step: 840, loss: 0.0707644447684288
step: 850, loss: 0.012722032144665718
step: 860, loss: 0.04092467948794365
step: 870, loss: 0.10074584931135178
step: 880, loss: 0.15144561231136322
step: 890, loss: 0.02458425797522068
step: 900, loss: 0.02262229658663273
step: 910, loss: 0.12222731113433838
step: 920, loss: 0.016787990927696228
step: 930, loss: 0.02755250595510006
step: 940, loss: 0.13290748000144958
step: 950, loss: 0.1442716419696808
step: 960, loss: 0.06987109035253525
step: 970, loss: 0.11270452290773392
step: 980, loss: 0.08452071994543076
step: 990, loss: 0.08229833096265793
step: 1000, loss: 0.06222030520439148
step: 1010, loss: 0.08400294184684753
step: 1020, loss: 0.042140938341617584
step: 1030, loss: 0.13734157383441925
step: 1040, loss: 0.05615482106804848
step: 1050, loss: 0.09015557169914246
step: 1060, loss: 0.030936967581510544
step: 1070, loss: 0.03333394229412079
epoch 3: dev_f1=0.9279404927940492, f1=0.9275893675527039, best_f1=0.9330316742081448
step: 0, loss: 0.04200422391295433
step: 10, loss: 0.007718248292803764
step: 20, loss: 0.12575162947177887
step: 30, loss: 0.13029137253761292
step: 40, loss: 0.08365951478481293
step: 50, loss: 0.10321782529354095
step: 60, loss: 0.11655537784099579
step: 70, loss: 0.027579518035054207
step: 80, loss: 0.07515918463468552
step: 90, loss: 0.12089010328054428
step: 100, loss: 0.032060571014881134
step: 110, loss: 0.13292352855205536
step: 120, loss: 0.09683477133512497
step: 130, loss: 0.0072797490283846855
step: 140, loss: 0.034688737243413925
step: 150, loss: 0.10014727711677551
step: 160, loss: 0.10456614941358566
step: 170, loss: 0.07206341624259949
step: 180, loss: 0.028340477496385574
step: 190, loss: 0.02345089055597782
step: 200, loss: 0.15162627398967743
step: 210, loss: 0.09455406665802002
step: 220, loss: 0.060667045414447784
step: 230, loss: 0.02548385038971901
step: 240, loss: 0.019383778795599937
step: 250, loss: 0.01220244076102972
step: 260, loss: 0.05152442678809166
step: 270, loss: 0.029370367527008057
step: 280, loss: 0.09278563410043716
step: 290, loss: 0.16313618421554565
step: 300, loss: 0.06578458100557327
step: 310, loss: 0.024351250380277634
step: 320, loss: 0.01738305762410164
step: 330, loss: 0.13803884387016296
step: 340, loss: 0.08452316373586655
step: 350, loss: 0.1612224578857422
step: 360, loss: 0.06763501465320587
step: 370, loss: 0.08578374981880188
step: 380, loss: 0.119378462433815
step: 390, loss: 0.025096707046031952
step: 400, loss: 0.002570383483543992
step: 410, loss: 0.06881984323263168
step: 420, loss: 0.020093850791454315
step: 430, loss: 0.09480241686105728
step: 440, loss: 0.07117598503828049
step: 450, loss: 0.036349181085824966
step: 460, loss: 0.04028838500380516
step: 470, loss: 0.08364289253950119
step: 480, loss: 0.016453761607408524
step: 490, loss: 0.010895260609686375
step: 500, loss: 0.1012062206864357
step: 510, loss: 0.16107645630836487
step: 520, loss: 0.09627415984869003
step: 530, loss: 0.035865418612957
step: 540, loss: 0.08055425435304642
step: 550, loss: 0.00882590189576149
step: 560, loss: 0.08941417187452316
step: 570, loss: 0.1237928494811058
step: 580, loss: 0.019695602357387543
step: 590, loss: 0.005228756926953793
step: 600, loss: 0.06560838967561722
step: 610, loss: 0.014989194460213184
step: 620, loss: 0.12355556339025497
step: 630, loss: 0.028592796996235847
step: 640, loss: 0.053156789392232895
step: 650, loss: 0.04359741881489754
step: 660, loss: 0.09193458408117294
step: 670, loss: 0.04405742138624191
step: 680, loss: 0.10134857892990112
step: 690, loss: 0.04403897747397423
step: 700, loss: 0.2726728916168213
step: 710, loss: 0.009201977401971817
step: 720, loss: 0.08638249337673187
step: 730, loss: 0.016637571156024933
step: 740, loss: 0.0515761524438858
step: 750, loss: 0.041755884885787964
step: 760, loss: 0.0709657371044159
step: 770, loss: 0.06319206953048706
step: 780, loss: 0.016440540552139282
step: 790, loss: 0.1304822564125061
step: 800, loss: 0.07076595723628998
step: 810, loss: 0.11204777657985687
step: 820, loss: 0.0995292142033577
step: 830, loss: 0.002208232181146741
step: 840, loss: 0.07750204205513
step: 850, loss: 0.04726649075746536
step: 860, loss: 0.051855314522981644
step: 870, loss: 0.2523905336856842
step: 880, loss: 0.029650051146745682
step: 890, loss: 0.050566017627716064
step: 900, loss: 0.002964533632621169
step: 910, loss: 0.016941221430897713
step: 920, loss: 0.15104687213897705
step: 930, loss: 0.0861809179186821
step: 940, loss: 0.13055849075317383
step: 950, loss: 0.02675764262676239
step: 960, loss: 0.162281796336174
step: 970, loss: 0.02999143674969673
step: 980, loss: 0.013548603281378746
step: 990, loss: 0.0180666446685791
step: 1000, loss: 0.25472381711006165
step: 1010, loss: 0.0009417397668585181
step: 1020, loss: 0.10863243043422699
step: 1030, loss: 0.03355737403035164
step: 1040, loss: 0.015644753351807594
step: 1050, loss: 0.2011668086051941
step: 1060, loss: 0.24674244225025177
step: 1070, loss: 0.02969243749976158
epoch 4: dev_f1=0.9330889092575618, f1=0.9373571101966164, best_f1=0.9330316742081448
step: 0, loss: 0.08530322462320328
step: 10, loss: 0.1556914746761322
step: 20, loss: 0.07584753632545471
step: 30, loss: 0.0672139823436737
step: 40, loss: 0.0186495091766119
step: 50, loss: 0.084577277302742
step: 60, loss: 0.02180955931544304
step: 70, loss: 0.020171746611595154
step: 80, loss: 0.08943036943674088
step: 90, loss: 0.2908000946044922
step: 100, loss: 0.11462687700986862
step: 110, loss: 0.07218705862760544
step: 120, loss: 0.08703099191188812
step: 130, loss: 0.0979015976190567
step: 140, loss: 0.2011479139328003
step: 150, loss: 0.01932847872376442
step: 160, loss: 0.22272002696990967
step: 170, loss: 0.1340554803609848
step: 180, loss: 0.09712481498718262
step: 190, loss: 0.019161082804203033
step: 200, loss: 0.014432437717914581
step: 210, loss: 0.06022046133875847
step: 220, loss: 0.02680996060371399
step: 230, loss: 0.04953911155462265
step: 240, loss: 0.11613427102565765
step: 250, loss: 0.07105352729558945
step: 260, loss: 0.015824446454644203
step: 270, loss: 0.10437154769897461
step: 280, loss: 0.1766137182712555
step: 290, loss: 0.0737433135509491
step: 300, loss: 0.05127360299229622
step: 310, loss: 0.08264070004224777
step: 320, loss: 0.017125939950346947
step: 330, loss: 0.004005716647952795
step: 340, loss: 0.11837445199489594
step: 350, loss: 0.021645106375217438
step: 360, loss: 0.02210407517850399
step: 370, loss: 0.06358610838651657
step: 380, loss: 0.19826632738113403
step: 390, loss: 0.07026652991771698
step: 400, loss: 0.05551239848136902
step: 410, loss: 0.08762440085411072
step: 420, loss: 0.09426813572645187
step: 430, loss: 0.02608627825975418
step: 440, loss: 0.052011553198099136
step: 450, loss: 0.012576584704220295
step: 460, loss: 0.014364728704094887
step: 470, loss: 0.02337556891143322
step: 480, loss: 0.005570718087255955
step: 490, loss: 0.00011906863801414147
step: 500, loss: 0.07968594133853912
step: 510, loss: 0.12530966103076935
step: 520, loss: 0.016863977536559105
step: 530, loss: 0.01656613126397133
step: 540, loss: 0.017725570127367973
step: 550, loss: 0.040648575872182846
step: 560, loss: 0.030169179663062096
step: 570, loss: 0.07303351163864136
step: 580, loss: 0.01400960423052311
step: 590, loss: 0.006008357275277376
step: 600, loss: 0.050768252462148666
step: 610, loss: 0.12385895848274231
step: 620, loss: 0.03062748722732067
step: 630, loss: 0.01699466072022915
step: 640, loss: 0.0046271770261228085
step: 650, loss: 0.013518070802092552
step: 660, loss: 0.1094672754406929
step: 670, loss: 0.1327587366104126
step: 680, loss: 0.11320867389440536
step: 690, loss: 0.051542747765779495
step: 700, loss: 0.05876721814274788
step: 710, loss: 0.0777633786201477
step: 720, loss: 0.026647601276636124
step: 730, loss: 0.03426816686987877
step: 740, loss: 0.017726996913552284
step: 750, loss: 0.15702494978904724
step: 760, loss: 0.08829618990421295
step: 770, loss: 0.13355889916419983
step: 780, loss: 0.05675631761550903
step: 790, loss: 0.05978462100028992
step: 800, loss: 0.03857242316007614
step: 810, loss: 0.079020194709301
step: 820, loss: 0.01215544156730175
step: 830, loss: 0.05230112746357918
step: 840, loss: 0.05316450074315071
step: 850, loss: 0.09077522158622742
step: 860, loss: 0.020366529002785683
step: 870, loss: 0.03319239243865013
step: 880, loss: 0.005460529122501612
step: 890, loss: 0.04398702457547188
step: 900, loss: 0.019944582134485245
step: 910, loss: 0.06348764151334763
step: 920, loss: 0.04204529523849487
step: 930, loss: 0.03695639222860336
step: 940, loss: 0.05204363167285919
step: 950, loss: 0.05341474339365959
step: 960, loss: 0.05606827512383461
step: 970, loss: 0.036530617624521255
step: 980, loss: 0.059012603014707565
step: 990, loss: 0.0037339557893574238
step: 1000, loss: 0.03681115806102753
step: 1010, loss: 0.07806647568941116
step: 1020, loss: 0.0036385587882250547
step: 1030, loss: 0.05218590050935745
step: 1040, loss: 0.0278894305229187
step: 1050, loss: 0.08056996017694473
step: 1060, loss: 0.06700492650270462
step: 1070, loss: 0.13238415122032166
epoch 5: dev_f1=0.9226594301221166, f1=0.9234254644313548, best_f1=0.9330316742081448
step: 0, loss: 0.009775889106094837
step: 10, loss: 0.017223071306943893
step: 20, loss: 0.003059815615415573
step: 30, loss: 0.015965456143021584
step: 40, loss: 0.0341804064810276
step: 50, loss: 0.00433091027662158
step: 60, loss: 0.0030481675639748573
step: 70, loss: 0.09846663475036621
step: 80, loss: 0.12615366280078888
step: 90, loss: 0.0201556533575058
step: 100, loss: 0.0077938358299434185
step: 110, loss: 0.02011719159781933
step: 120, loss: 0.054749373346567154
step: 130, loss: 0.018638096749782562
step: 140, loss: 0.08755800127983093
step: 150, loss: 0.014068969525396824
step: 160, loss: 0.034448109567165375
step: 170, loss: 0.08288294821977615
step: 180, loss: 0.007291349582374096
step: 190, loss: 0.025789178907871246
step: 200, loss: 0.0104591753333807
step: 210, loss: 0.09494805335998535
step: 220, loss: 0.060008928179740906
step: 230, loss: 0.025294944643974304
step: 240, loss: 0.008568061515688896
step: 250, loss: 0.03125036880373955
step: 260, loss: 0.02365719899535179
step: 270, loss: 0.0631093680858612
step: 280, loss: 0.01929609291255474
step: 290, loss: 0.03642301633954048
step: 300, loss: 0.036504801362752914
step: 310, loss: 0.1028585210442543
step: 320, loss: 0.053536564111709595
step: 330, loss: 0.04041192680597305
step: 340, loss: 0.06334635615348816
step: 350, loss: 0.17135433852672577
step: 360, loss: 0.023660048842430115
step: 370, loss: 0.006153524853289127
step: 380, loss: 0.011316420510411263
step: 390, loss: 0.044233255088329315
step: 400, loss: 0.08777462691068649
step: 410, loss: 0.05960298702120781
step: 420, loss: 0.05933254212141037
step: 430, loss: 0.05119412764906883
step: 440, loss: 0.03391746059060097
step: 450, loss: 0.09323535114526749
step: 460, loss: 0.07184440642595291
step: 470, loss: 0.020814403891563416
step: 480, loss: 0.048072267323732376
step: 490, loss: 0.03317123278975487
step: 500, loss: 0.017893118783831596
step: 510, loss: 0.06908273696899414
step: 520, loss: 0.023783089593052864
step: 530, loss: 0.07912507653236389
step: 540, loss: 0.07442227751016617
step: 550, loss: 0.2809278964996338
step: 560, loss: 0.021442275494337082
step: 570, loss: 0.1488998532295227
step: 580, loss: 0.03365417569875717
step: 590, loss: 0.04905811697244644
step: 600, loss: 0.02815580554306507
step: 610, loss: 0.08597634732723236
step: 620, loss: 0.1352897733449936
step: 630, loss: 0.10241369903087616
step: 640, loss: 0.015393568202853203
step: 650, loss: 0.08400433510541916
step: 660, loss: 0.08973555266857147
step: 670, loss: 0.0147516168653965
step: 680, loss: 0.07983788847923279
step: 690, loss: 0.00172595982439816
step: 700, loss: 0.03588699549436569
step: 710, loss: 0.09894566237926483
step: 720, loss: 0.0585794635117054
step: 730, loss: 0.05814634636044502
step: 740, loss: 0.11966761201620102
step: 750, loss: 0.006217687390744686
step: 760, loss: 0.07488790154457092
step: 770, loss: 0.07259594649076462
step: 780, loss: 0.12812113761901855
step: 790, loss: 0.09192623943090439
step: 800, loss: 0.022321835160255432
step: 810, loss: 0.0498473197221756
step: 820, loss: 0.04877254739403725
step: 830, loss: 0.051140185445547104
step: 840, loss: 0.02289159782230854
step: 850, loss: 0.06512165814638138
step: 860, loss: 0.09915930777788162
step: 870, loss: 0.1001327857375145
step: 880, loss: 0.017269311472773552
step: 890, loss: 0.012761021964251995
step: 900, loss: 0.11069062352180481
step: 910, loss: 0.005015750881284475
step: 920, loss: 0.02053852751851082
step: 930, loss: 0.014695210382342339
step: 940, loss: 0.07590501755475998
step: 950, loss: 0.10708925873041153
step: 960, loss: 0.021607961505651474
step: 970, loss: 0.017796384170651436
step: 980, loss: 0.07117074728012085
step: 990, loss: 0.026177505031228065
step: 1000, loss: 0.006013205274939537
step: 1010, loss: 0.0035264575853943825
step: 1020, loss: 0.15077315270900726
step: 1030, loss: 0.12988123297691345
step: 1040, loss: 0.08300657570362091
step: 1050, loss: 0.08956842869520187
step: 1060, loss: 0.05158737301826477
step: 1070, loss: 0.17402680218219757
epoch 6: dev_f1=0.9356343283582089, f1=0.937847866419295, best_f1=0.9330316742081448
step: 0, loss: 0.02112218551337719
step: 10, loss: 0.02453004941344261
step: 20, loss: 0.020007556304335594
step: 30, loss: 0.06934984028339386
step: 40, loss: 0.12638042867183685
step: 50, loss: 0.08207233995199203
step: 60, loss: 0.05345261096954346
step: 70, loss: 0.048031896352767944
step: 80, loss: 0.1135069727897644
step: 90, loss: 0.05431899428367615
step: 100, loss: 0.07361068576574326
step: 110, loss: 0.0751626119017601
step: 120, loss: 0.013467240147292614
step: 130, loss: 0.058884717524051666
step: 140, loss: 0.02746877633035183
step: 150, loss: 0.045932587236166
step: 160, loss: 0.10360954701900482
step: 170, loss: 0.019789088517427444
step: 180, loss: 0.224573016166687
step: 190, loss: 0.054489411413669586
step: 200, loss: 0.07892809808254242
step: 210, loss: 0.019074054434895515
step: 220, loss: 0.047849852591753006
step: 230, loss: 0.055755555629730225
step: 240, loss: 0.03197108954191208
step: 250, loss: 0.01452782191336155
step: 260, loss: 0.008801070973277092
step: 270, loss: 0.034147776663303375
step: 280, loss: 0.06451596319675446
step: 290, loss: 0.014363549649715424
step: 300, loss: 0.0199106577783823
step: 310, loss: 0.00601913221180439
step: 320, loss: 0.08033713698387146
step: 330, loss: 0.07229438424110413
step: 340, loss: 0.054896965622901917
step: 350, loss: 0.007823373191058636
step: 360, loss: 0.08974414318799973
step: 370, loss: 0.010298910550773144
step: 380, loss: 0.024067064747214317
step: 390, loss: 0.018522799015045166
step: 400, loss: 0.047638632357120514
step: 410, loss: 0.1292399764060974
step: 420, loss: 0.0232565738260746
step: 430, loss: 0.04406348243355751
step: 440, loss: 0.07997090369462967
step: 450, loss: 0.09408004581928253
step: 460, loss: 0.11150643974542618
step: 470, loss: 0.18570001423358917
step: 480, loss: 0.013268989510834217
step: 490, loss: 0.0799059122800827
step: 500, loss: 0.060769546777009964
step: 510, loss: 0.0161697119474411
step: 520, loss: 0.006885337643325329
step: 530, loss: 0.015983449295163155
step: 540, loss: 0.10587450861930847
step: 550, loss: 0.019714554771780968
step: 560, loss: 0.006816421635448933
step: 570, loss: 0.015549929812550545
step: 580, loss: 0.06173912435770035
step: 590, loss: 0.13601499795913696
step: 600, loss: 0.006841893307864666
step: 610, loss: 0.016831140965223312
step: 620, loss: 0.00947339553385973
step: 630, loss: 0.04088817909359932
step: 640, loss: 0.031149616464972496
step: 650, loss: 0.004305893089622259
step: 660, loss: 0.06507274508476257
step: 670, loss: 0.049806147813797
step: 680, loss: 0.004822243936359882
step: 690, loss: 0.07730508595705032
step: 700, loss: 0.057960860431194305
step: 710, loss: 0.017631547525525093
step: 720, loss: 0.1398693174123764
step: 730, loss: 0.07973635196685791
step: 740, loss: 0.153663769364357
step: 750, loss: 0.11578652262687683
step: 760, loss: 0.12642261385917664
step: 770, loss: 0.004623903427273035
step: 780, loss: 0.07831386476755142
step: 790, loss: 0.014897067099809647
step: 800, loss: 0.012606815434992313
step: 810, loss: 0.10230716317892075
step: 820, loss: 0.11284995824098587
step: 830, loss: 0.025662623345851898
step: 840, loss: 0.046496495604515076
step: 850, loss: 0.06854797899723053
step: 860, loss: 0.08762365579605103
step: 870, loss: 0.09688551723957062
step: 880, loss: 0.02364509180188179
step: 890, loss: 0.05669508874416351
step: 900, loss: 0.000218868677620776
step: 910, loss: 0.0041227987967431545
step: 920, loss: 0.015035226941108704
step: 930, loss: 0.0614209808409214
step: 940, loss: 0.05368831381201744
step: 950, loss: 0.02527114376425743
step: 960, loss: 0.08831850439310074
step: 970, loss: 0.050005510449409485
step: 980, loss: 0.0742795392870903
step: 990, loss: 0.03693350404500961
step: 1000, loss: 0.16913467645645142
step: 1010, loss: 0.05232660472393036
step: 1020, loss: 0.13860520720481873
step: 1030, loss: 0.057026054710149765
step: 1040, loss: 0.05759517475962639
step: 1050, loss: 0.08699751645326614
step: 1060, loss: 0.06555447727441788
step: 1070, loss: 0.0937202125787735
epoch 7: dev_f1=0.936768149882904, f1=0.9341983317886932, best_f1=0.9341983317886932
step: 0, loss: 0.047719914466142654
step: 10, loss: 0.021665912121534348
step: 20, loss: 0.003056565299630165
step: 30, loss: 0.08340618759393692
step: 40, loss: 0.05729033425450325
step: 50, loss: 0.05674310773611069
step: 60, loss: 0.018064476549625397
step: 70, loss: 0.014921539463102818
step: 80, loss: 0.0007022375357337296
step: 90, loss: 0.09035539627075195
step: 100, loss: 0.008811907842755318
step: 110, loss: 0.07872039824724197
step: 120, loss: 0.042516350746154785
step: 130, loss: 0.027862530201673508
step: 140, loss: 0.07703910768032074
step: 150, loss: 0.014997106045484543
step: 160, loss: 0.019021864980459213
step: 170, loss: 0.010605095885694027
step: 180, loss: 0.08923576772212982
step: 190, loss: 0.024373775348067284
step: 200, loss: 0.03472204878926277
step: 210, loss: 0.00894902367144823
step: 220, loss: 0.0880419909954071
step: 230, loss: 0.04646048694849014
step: 240, loss: 0.04059600457549095
step: 250, loss: 0.07524048537015915
step: 260, loss: 0.07485407590866089
step: 270, loss: 0.056989166885614395
step: 280, loss: 0.04421842098236084
step: 290, loss: 0.031890347599983215
step: 300, loss: 0.012551075778901577
step: 310, loss: 0.09596109390258789
step: 320, loss: 0.030290167778730392
step: 330, loss: 0.014165684580802917
step: 340, loss: 0.09772702306509018
step: 350, loss: 0.0773250088095665
step: 360, loss: 0.04541519284248352
step: 370, loss: 0.03113039769232273
step: 380, loss: 0.08051226288080215
step: 390, loss: 0.004851857200264931
step: 400, loss: 0.06947202980518341
step: 410, loss: 0.015969784930348396
step: 420, loss: 0.10673752427101135
step: 430, loss: 0.06160152330994606
step: 440, loss: 0.04496493935585022
step: 450, loss: 0.1662595421075821
step: 460, loss: 0.0693269893527031
step: 470, loss: 0.032490074634552
step: 480, loss: 0.005747667513787746
step: 490, loss: 0.018452176824212074
step: 500, loss: 0.04037274792790413
step: 510, loss: 0.0763455405831337
step: 520, loss: 0.003261555451899767
step: 530, loss: 0.1943851262331009
step: 540, loss: 0.03822573274374008
step: 550, loss: 0.13740688562393188
step: 560, loss: 0.07787436991930008
step: 570, loss: 0.06642948091030121
step: 580, loss: 0.05208165943622589
step: 590, loss: 0.0249690730124712
step: 600, loss: 0.021800726652145386
step: 610, loss: 0.15476509928703308
step: 620, loss: 0.036960452795028687
step: 630, loss: 0.07543009519577026
step: 640, loss: 0.07933730632066727
step: 650, loss: 0.011971806176006794
step: 660, loss: 0.06293705850839615
step: 670, loss: 0.06902609765529633
step: 680, loss: 0.010851463302969933
step: 690, loss: 0.012910563498735428
step: 700, loss: 0.10013682395219803
step: 710, loss: 0.02818397805094719
step: 720, loss: 0.05923819914460182
step: 730, loss: 6.046603084541857e-05
step: 740, loss: 0.10226753354072571
step: 750, loss: 0.01286129467189312
step: 760, loss: 0.0063055832870304585
step: 770, loss: 0.09691212326288223
step: 780, loss: 8.577033440815285e-05
step: 790, loss: 0.02666504494845867
step: 800, loss: 0.02254728600382805
step: 810, loss: 0.27497580647468567
step: 820, loss: 0.034423086792230606
step: 830, loss: 0.09790369868278503
step: 840, loss: 0.12145324051380157
step: 850, loss: 0.1273130178451538
step: 860, loss: 0.012891452759504318
step: 870, loss: 0.029902195557951927
step: 880, loss: 0.09422406554222107
step: 890, loss: 0.06874644011259079
step: 900, loss: 0.06212693452835083
step: 910, loss: 0.08171914517879486
step: 920, loss: 0.0955105721950531
step: 930, loss: 0.0936049073934555
step: 940, loss: 0.01780114695429802
step: 950, loss: 0.02574780397117138
step: 960, loss: 0.09262026846408844
step: 970, loss: 0.04191289842128754
step: 980, loss: 0.045194558799266815
step: 990, loss: 0.007561240810900927
step: 1000, loss: 0.057485803961753845
step: 1010, loss: 0.050998713821172714
step: 1020, loss: 0.07052138447761536
step: 1030, loss: 0.09267133474349976
step: 1040, loss: 0.03536919504404068
step: 1050, loss: 0.02727651782333851
step: 1060, loss: 0.07748096436262131
step: 1070, loss: 0.04820612445473671
epoch 8: dev_f1=0.9330872173511767, f1=0.9340054995417048, best_f1=0.9341983317886932
step: 0, loss: 0.043880049139261246
step: 10, loss: 0.02420411817729473
step: 20, loss: 0.06070832163095474
step: 30, loss: 0.11131780594587326
step: 40, loss: 0.05671772360801697
step: 50, loss: 0.12430766969919205
step: 60, loss: 0.07062102109193802
step: 70, loss: 0.16823488473892212
step: 80, loss: 0.06986479461193085
step: 90, loss: 0.015453671105206013
step: 100, loss: 0.009191435761749744
step: 110, loss: 0.014441490173339844
step: 120, loss: 0.004363709595054388
step: 130, loss: 2.897437479987275e-05
step: 140, loss: 0.01428962778300047
step: 150, loss: 0.13985571265220642
step: 160, loss: 0.004804140422493219
step: 170, loss: 0.013116943649947643
step: 180, loss: 0.01634245179593563
step: 190, loss: 0.008591701276600361
step: 200, loss: 0.03633736073970795
step: 210, loss: 0.01341787539422512
step: 220, loss: 0.006847884971648455
step: 230, loss: 0.053802382200956345
step: 240, loss: 0.13130898773670197
step: 250, loss: 0.03000328317284584
step: 260, loss: 0.0007945368997752666
step: 270, loss: 7.434047438437119e-05
step: 280, loss: 0.01548831071704626
step: 290, loss: 0.006477195769548416
step: 300, loss: 0.14211398363113403
step: 310, loss: 0.12420687824487686
step: 320, loss: 0.028902115300297737
step: 330, loss: 0.008384729735553265
step: 340, loss: 0.06133570522069931
step: 350, loss: 0.004031062126159668
step: 360, loss: 0.01680821366608143
step: 370, loss: 0.05329626798629761
step: 380, loss: 0.010046208277344704
step: 390, loss: 0.005850318353623152
step: 400, loss: 0.08240056782960892
step: 410, loss: 0.22222039103507996
step: 420, loss: 0.021647358313202858
step: 430, loss: 0.11379749327898026
step: 440, loss: 0.12236077338457108
step: 450, loss: 0.02434331737458706
step: 460, loss: 0.011070648208260536
step: 470, loss: 0.06528132408857346
step: 480, loss: 0.011752791702747345
step: 490, loss: 0.04584519937634468
step: 500, loss: 0.03138403594493866
step: 510, loss: 0.05790732428431511
step: 520, loss: 0.04357677325606346
step: 530, loss: 0.008472209796309471
step: 540, loss: 0.057881128042936325
step: 550, loss: 0.005838869139552116
step: 560, loss: 0.009233265183866024
step: 570, loss: 0.05684860795736313
step: 580, loss: 0.08231763541698456
step: 590, loss: 0.16809938848018646
step: 600, loss: 0.04093308746814728
step: 610, loss: 0.003971749916672707
step: 620, loss: 0.011760764755308628
step: 630, loss: 0.009232694283127785
step: 640, loss: 0.044597078114748
step: 650, loss: 0.023421961814165115
step: 660, loss: 0.0706200897693634
step: 670, loss: 0.030297134071588516
step: 680, loss: 0.010116470977663994
step: 690, loss: 0.09878496080636978
step: 700, loss: 0.03909910097718239
step: 710, loss: 0.08623698353767395
step: 720, loss: 0.08133013546466827
step: 730, loss: 0.0082863699644804
step: 740, loss: 0.07414697110652924
step: 750, loss: 0.06387562304735184
step: 760, loss: 0.015362069942057133
step: 770, loss: 0.14871326088905334
step: 780, loss: 0.04140223190188408
step: 790, loss: 0.03175567090511322
step: 800, loss: 0.053587209433317184
step: 810, loss: 0.08224377781152725
step: 820, loss: 0.04099364951252937
step: 830, loss: 0.05356329679489136
step: 840, loss: 0.004051622934639454
step: 850, loss: 0.02031131647527218
step: 860, loss: 0.05640171840786934
step: 870, loss: 0.04447613283991814
step: 880, loss: 0.007282380945980549
step: 890, loss: 0.0340663343667984
step: 900, loss: 0.009440166875720024
step: 910, loss: 0.037700966000556946
step: 920, loss: 0.04383495822548866
step: 930, loss: 0.07937996089458466
step: 940, loss: 0.11377429217100143
step: 950, loss: 0.02319907397031784
step: 960, loss: 0.012732625007629395
step: 970, loss: 0.05046580359339714
step: 980, loss: 0.014359747059643269
step: 990, loss: 0.01784655824303627
step: 1000, loss: 0.025724906474351883
step: 1010, loss: 0.1250317245721817
step: 1020, loss: 0.052232351154088974
step: 1030, loss: 0.041032664477825165
step: 1040, loss: 0.09684451669454575
step: 1050, loss: 0.017906304448843002
step: 1060, loss: 0.00295779830776155
step: 1070, loss: 0.06680191308259964
epoch 9: dev_f1=0.9354243542435424, f1=0.9353647276084949, best_f1=0.9341983317886932
step: 0, loss: 0.018489647656679153
step: 10, loss: 0.08288171887397766
step: 20, loss: 0.0064490726217627525
step: 30, loss: 0.002088977722451091
step: 40, loss: 0.038684435188770294
step: 50, loss: 0.0049211629666388035
step: 60, loss: 0.010936924256384373
step: 70, loss: 0.043178409337997437
step: 80, loss: 0.0697404146194458
step: 90, loss: 0.005780462641268969
step: 100, loss: 0.0575152151286602
step: 110, loss: 0.04089130833745003
step: 120, loss: 0.020248526707291603
step: 130, loss: 0.06696895509958267
step: 140, loss: 0.0025821728631854057
step: 150, loss: 0.07322951406240463
step: 160, loss: 0.057890601456165314
step: 170, loss: 0.0003005730686709285
step: 180, loss: 0.014863507822155952
step: 190, loss: 0.07558301091194153
step: 200, loss: 0.048988617956638336
step: 210, loss: 0.04416050389409065
step: 220, loss: 0.015071650967001915
step: 230, loss: 0.004271855112165213
step: 240, loss: 0.045938022434711456
step: 250, loss: 0.0006141357007436454
step: 260, loss: 0.019980380311608315
step: 270, loss: 0.005521462764590979
step: 280, loss: 0.0009331586770713329
step: 290, loss: 0.053687404841184616
step: 300, loss: 0.09821678698062897
step: 310, loss: 0.022936856374144554
step: 320, loss: 0.05575266107916832
step: 330, loss: 0.04056926071643829
step: 340, loss: 0.09661970287561417
step: 350, loss: 0.06257010996341705
step: 360, loss: 0.024749211966991425
step: 370, loss: 0.04220861941576004
step: 380, loss: 0.054478298872709274
step: 390, loss: 0.09063098579645157
step: 400, loss: 0.021478712558746338
step: 410, loss: 0.006784874014556408
step: 420, loss: 0.015008746646344662
step: 430, loss: 0.05262422189116478
step: 440, loss: 0.043846581131219864
step: 450, loss: 0.011887554079294205
step: 460, loss: 0.01525706797838211
step: 470, loss: 0.016147110611200333
step: 480, loss: 0.05402679741382599
step: 490, loss: 0.09050652384757996
step: 500, loss: 0.0012671684380620718
step: 510, loss: 0.01579318381845951
step: 520, loss: 0.004690463654696941
step: 530, loss: 0.07983987033367157
step: 540, loss: 0.0066637215204536915
step: 550, loss: 0.020956197753548622
step: 560, loss: 0.01880536787211895
step: 570, loss: 0.02671051397919655
step: 580, loss: 0.001779867452569306
step: 590, loss: 0.06125200539827347
step: 600, loss: 0.08506017178297043
step: 610, loss: 0.0025074491277337074
step: 620, loss: 0.0799625813961029
step: 630, loss: 0.02369271032512188
step: 640, loss: 0.04702582210302353
step: 650, loss: 0.055202849209308624
step: 660, loss: 0.042695797979831696
step: 670, loss: 0.0012740822276100516
step: 680, loss: 0.002324274741113186
step: 690, loss: 0.01765391230583191
step: 700, loss: 0.05304042249917984
step: 710, loss: 0.0018965390045195818
step: 720, loss: 0.06581909954547882
step: 730, loss: 0.01978999190032482
step: 740, loss: 0.054018404334783554
step: 750, loss: 0.01825617253780365
step: 760, loss: 0.10594697296619415
step: 770, loss: 0.0276469886302948
step: 780, loss: 0.0018989701056852937
step: 790, loss: 0.19569846987724304
step: 800, loss: 0.016554417088627815
step: 810, loss: 0.01886529102921486
step: 820, loss: 0.28220316767692566
step: 830, loss: 0.05184853449463844
step: 840, loss: 0.0723305344581604
step: 850, loss: 0.04065234959125519
step: 860, loss: 0.025129294022917747
step: 870, loss: 0.04887915030121803
step: 880, loss: 0.00219744723290205
step: 890, loss: 0.030940577387809753
step: 900, loss: 0.08775671571493149
step: 910, loss: 0.11290857940912247
step: 920, loss: 0.07660630345344543
step: 930, loss: 0.08798607438802719
step: 940, loss: 0.018140800297260284
step: 950, loss: 0.05108106881380081
step: 960, loss: 0.036020729690790176
step: 970, loss: 0.043188340961933136
step: 980, loss: 0.03322840481996536
step: 990, loss: 0.03920667618513107
step: 1000, loss: 0.08101243525743484
step: 1010, loss: 0.027255190536379814
step: 1020, loss: 0.029723655432462692
step: 1030, loss: 0.036065444350242615
step: 1040, loss: 0.25375446677207947
step: 1050, loss: 0.020235178992152214
step: 1060, loss: 0.1728234589099884
step: 1070, loss: 0.050034407526254654
epoch 10: dev_f1=0.9271889400921659, f1=0.9308755760368663, best_f1=0.9341983317886932
step: 0, loss: 0.05883575230836868
step: 10, loss: 0.061720024794340134
step: 20, loss: 0.05382312089204788
step: 30, loss: 0.050623293966054916
step: 40, loss: 0.00818594265729189
step: 50, loss: 0.04216080158948898
step: 60, loss: 0.04762546718120575
step: 70, loss: 0.15735505521297455
step: 80, loss: 0.03176237270236015
step: 90, loss: 0.025149116292595863
step: 100, loss: 0.0370272621512413
step: 110, loss: 0.010481316596269608
step: 120, loss: 0.007443130016326904
step: 130, loss: 0.09646404534578323
step: 140, loss: 0.009283075109124184
step: 150, loss: 0.09092028439044952
step: 160, loss: 0.08121981471776962
step: 170, loss: 0.032499272376298904
step: 180, loss: 0.05475519970059395
step: 190, loss: 0.16344431042671204
step: 200, loss: 0.032013341784477234
step: 210, loss: 0.015146687626838684
step: 220, loss: 0.031501807272434235
step: 230, loss: 0.007702914997935295
step: 240, loss: 0.04476408287882805
step: 250, loss: 0.028958970680832863
step: 260, loss: 0.02939431369304657
step: 270, loss: 0.005523828789591789
step: 280, loss: 0.008120529353618622
step: 290, loss: 0.16279445588588715
step: 300, loss: 0.030916068702936172
step: 310, loss: 0.07219914346933365
step: 320, loss: 0.0003901028831023723
step: 330, loss: 0.042707864195108414
step: 340, loss: 0.008869582787156105
step: 350, loss: 0.1302010864019394
step: 360, loss: 0.03365052118897438
step: 370, loss: 0.044618766754865646
step: 380, loss: 0.046314626932144165
step: 390, loss: 0.03307751193642616
step: 400, loss: 0.011166914366185665
step: 410, loss: 0.01158585399389267
step: 420, loss: 0.007802862208336592
step: 430, loss: 0.027841225266456604
step: 440, loss: 0.028118861839175224
step: 450, loss: 0.023633353412151337
step: 460, loss: 0.048917632550001144
step: 470, loss: 0.009511400945484638
step: 480, loss: 0.03633798286318779
step: 490, loss: 0.002951581496745348
step: 500, loss: 0.02029384672641754
step: 510, loss: 0.03448905795812607
step: 520, loss: 0.05439275503158569
step: 530, loss: 0.04493720084428787
step: 540, loss: 0.05511556193232536
step: 550, loss: 0.021398257464170456
step: 560, loss: 0.08597761392593384
step: 570, loss: 0.04370083287358284
step: 580, loss: 0.020097624510526657
step: 590, loss: 0.010145509615540504
step: 600, loss: 0.0023388550616800785
step: 610, loss: 0.07685213536024094
step: 620, loss: 0.0007628885214217007
step: 630, loss: 0.03488842397928238
step: 640, loss: 0.05450023338198662
step: 650, loss: 0.00035333383129909635
step: 660, loss: 0.023420177400112152
step: 670, loss: 0.01720103994011879
step: 680, loss: 0.06594803929328918
step: 690, loss: 0.06137458235025406
step: 700, loss: 0.03670673072338104
step: 710, loss: 0.0026538081001490355
step: 720, loss: 0.0019247611053287983
step: 730, loss: 0.03648088872432709
step: 740, loss: 0.007543996442109346
step: 750, loss: 0.0013118148781359196
step: 760, loss: 0.009084904566407204
step: 770, loss: 0.033730488270521164
step: 780, loss: 0.07443206012248993
step: 790, loss: 0.05418422818183899
step: 800, loss: 0.047449029982089996
step: 810, loss: 0.0035222829319536686
step: 820, loss: 0.04750550538301468
step: 830, loss: 0.01649351418018341
step: 840, loss: 0.07569292187690735
step: 850, loss: 0.1134357675909996
step: 860, loss: 0.02097422443330288
step: 870, loss: 0.012895655818283558
step: 880, loss: 0.05918920785188675
step: 890, loss: 0.09375728666782379
step: 900, loss: 0.015217780135571957
step: 910, loss: 0.02809269167482853
step: 920, loss: 0.04132463037967682
step: 930, loss: 0.06381452083587646
step: 940, loss: 0.004952809773385525
step: 950, loss: 0.02645125798881054
step: 960, loss: 0.06549996137619019
step: 970, loss: 0.01019061915576458
step: 980, loss: 0.16401156783103943
step: 990, loss: 0.028592705726623535
step: 1000, loss: 0.0002310170530108735
step: 1010, loss: 0.07451576739549637
step: 1020, loss: 0.09583999961614609
step: 1030, loss: 0.04331360384821892
step: 1040, loss: 0.012194017879664898
step: 1050, loss: 0.06391299515962601
step: 1060, loss: 0.00753974262624979
step: 1070, loss: 0.06476403027772903
epoch 11: dev_f1=0.929840972871843, f1=0.9248014946286782, best_f1=0.9341983317886932
step: 0, loss: 0.02878664806485176
step: 10, loss: 0.060209885239601135
step: 20, loss: 0.027234341949224472
step: 30, loss: 0.045536842197179794
step: 40, loss: 0.05816016346216202
step: 50, loss: 0.04995862394571304
step: 60, loss: 0.0014203243190422654
step: 70, loss: 0.05757294222712517
step: 80, loss: 0.01612641103565693
step: 90, loss: 0.10271403193473816
step: 100, loss: 0.038724660873413086
step: 110, loss: 0.12106399238109589
step: 120, loss: 0.004250007681548595
step: 130, loss: 0.0010970967123284936
step: 140, loss: 0.005385364405810833
step: 150, loss: 0.07352397590875626
step: 160, loss: 0.029231980443000793
step: 170, loss: 0.019553707912564278
step: 180, loss: 0.0003526046348270029
step: 190, loss: 0.03912106156349182
step: 200, loss: 0.13215351104736328
step: 210, loss: 0.06524811685085297
step: 220, loss: 0.03945488855242729
step: 230, loss: 0.06631825119256973
step: 240, loss: 0.09209710359573364
step: 250, loss: 0.0016080213245004416
step: 260, loss: 0.04437253624200821
step: 270, loss: 0.04251949116587639
step: 280, loss: 0.08177979290485382
step: 290, loss: 0.022133424878120422
step: 300, loss: 0.017956100404262543
step: 310, loss: 0.0002980544522870332
step: 320, loss: 0.020912060514092445
step: 330, loss: 0.11589138209819794
step: 340, loss: 0.07818519324064255
step: 350, loss: 0.03136540576815605
step: 360, loss: 0.03826505318284035
step: 370, loss: 0.07621585577726364
step: 380, loss: 0.040175214409828186
step: 390, loss: 0.04283545911312103
step: 400, loss: 0.04193084314465523
step: 410, loss: 0.051041994243860245
step: 420, loss: 0.011874010786414146
step: 430, loss: 0.05623480677604675
step: 440, loss: 0.016524778679013252
step: 450, loss: 0.07434645295143127
step: 460, loss: 0.04563099890947342
step: 470, loss: 0.056516263633966446
step: 480, loss: 0.025787247344851494
step: 490, loss: 0.0017378145130351186
step: 500, loss: 0.01916247047483921
step: 510, loss: 0.0018912553787231445
step: 520, loss: 0.09165606647729874
step: 530, loss: 3.7566336686722934e-05
step: 540, loss: 0.021226728335022926
step: 550, loss: 4.2094034142792225e-05
step: 560, loss: 0.005867432802915573
step: 570, loss: 0.03514127433300018
step: 580, loss: 0.00011509090109029785
step: 590, loss: 0.00021547536016441882
step: 600, loss: 0.03834518790245056
step: 610, loss: 0.11020588129758835
step: 620, loss: 0.03610905259847641
step: 630, loss: 0.022166358307003975
step: 640, loss: 0.0022447635419666767
step: 650, loss: 0.02482413686811924
step: 660, loss: 0.016793489456176758
step: 670, loss: 0.08099855482578278
step: 680, loss: 6.503718032035977e-05
step: 690, loss: 0.02890576235949993
step: 700, loss: 0.04426905885338783
step: 710, loss: 0.09191536903381348
step: 720, loss: 0.13922572135925293
step: 730, loss: 0.005351459141820669
step: 740, loss: 0.006044498644769192
step: 750, loss: 0.032450009137392044
step: 760, loss: 0.09203184396028519
step: 770, loss: 0.1103375107049942
step: 780, loss: 0.12374848872423172
step: 790, loss: 0.0006506301579065621
step: 800, loss: 0.01715717650949955
step: 810, loss: 0.022886447608470917
step: 820, loss: 0.05500566586852074
step: 830, loss: 0.06813372671604156
step: 840, loss: 0.0011022284161299467
step: 850, loss: 0.047628793865442276
step: 860, loss: 0.05937502905726433
step: 870, loss: 0.0032024134416133165
step: 880, loss: 0.05263778567314148
step: 890, loss: 4.8702579078963026e-05
step: 900, loss: 0.0006086210487410426
step: 910, loss: 2.7618156309472397e-05
step: 920, loss: 0.024320848286151886
step: 930, loss: 0.11797855794429779
step: 940, loss: 0.016194026917219162
step: 950, loss: 0.02468051388859749
step: 960, loss: 0.02841995283961296
step: 970, loss: 0.05474736541509628
step: 980, loss: 0.06831029057502747
step: 990, loss: 0.07913129031658173
step: 1000, loss: 0.013347236439585686
step: 1010, loss: 4.131949754082598e-05
step: 1020, loss: 0.036208417266607285
step: 1030, loss: 0.019044360145926476
step: 1040, loss: 0.03512381762266159
step: 1050, loss: 0.03966666758060455
step: 1060, loss: 0.014204655773937702
step: 1070, loss: 0.11976099014282227
epoch 12: dev_f1=0.9360331339162449, f1=0.9258406264394289, best_f1=0.9341983317886932
step: 0, loss: 0.03923392295837402
step: 10, loss: 0.03782377019524574
step: 20, loss: 0.026880521327257156
step: 30, loss: 0.04207579791545868
step: 40, loss: 0.00019539189815986902
step: 50, loss: 0.0009376090602017939
step: 60, loss: 0.09221874922513962
step: 70, loss: 0.037939704954624176
step: 80, loss: 0.03881554678082466
step: 90, loss: 0.11377408355474472
step: 100, loss: 0.041405025869607925
step: 110, loss: 0.12168027460575104
step: 120, loss: 0.0018838595133274794
step: 130, loss: 0.0314880795776844
step: 140, loss: 0.07859870046377182
step: 150, loss: 0.05095003917813301
step: 160, loss: 0.008993818424642086
step: 170, loss: 0.005349704995751381
step: 180, loss: 0.006370831746608019
step: 190, loss: 4.904135494143702e-05
step: 200, loss: 0.0003539663157425821
step: 210, loss: 0.03338392823934555
step: 220, loss: 0.05128607898950577
step: 230, loss: 0.028386013582348824
step: 240, loss: 0.01442051399499178
step: 250, loss: 0.049507975578308105
step: 260, loss: 0.043556731194257736
step: 270, loss: 0.03763425722718239
step: 280, loss: 0.028709255158901215
step: 290, loss: 0.0006589069962501526
step: 300, loss: 0.07857178151607513
step: 310, loss: 0.0021643340587615967
step: 320, loss: 0.03935649245977402
step: 330, loss: 0.02669389918446541
step: 340, loss: 0.0001569983724039048
step: 350, loss: 0.07847537845373154
step: 360, loss: 0.14236249029636383
step: 370, loss: 0.06677021086215973
step: 380, loss: 0.09221779555082321
step: 390, loss: 0.026852160692214966
step: 400, loss: 0.02464885078370571
step: 410, loss: 0.05615292862057686
step: 420, loss: 0.03921633958816528
step: 430, loss: 0.0004190646286588162
step: 440, loss: 2.3095843062037602e-05
step: 450, loss: 3.4027987567242235e-05
step: 460, loss: 0.026015715673565865
step: 470, loss: 0.0754147544503212
step: 480, loss: 0.024408798664808273
step: 490, loss: 0.05591288581490517
step: 500, loss: 8.132411312544718e-05
step: 510, loss: 0.08996471762657166
step: 520, loss: 0.026204856112599373
step: 530, loss: 0.05786848068237305
step: 540, loss: 0.0017332915449514985
step: 550, loss: 0.009530076757073402
step: 560, loss: 0.023914866149425507
step: 570, loss: 0.012084169313311577
step: 580, loss: 0.11776521801948547
step: 590, loss: 0.04602361470460892
step: 600, loss: 0.15104523301124573
step: 610, loss: 0.03613346070051193
step: 620, loss: 0.06236125901341438
step: 630, loss: 0.017520608380436897
step: 640, loss: 0.044077448546886444
step: 650, loss: 0.07371363788843155
step: 660, loss: 0.04505491629242897
step: 670, loss: 0.005390232894569635
step: 680, loss: 0.043751273304224014
step: 690, loss: 0.014360355213284492
step: 700, loss: 0.020294565707445145
step: 710, loss: 0.06116888299584389
step: 720, loss: 0.036720920354127884
step: 730, loss: 0.04591158404946327
step: 740, loss: 0.06230579689145088
step: 750, loss: 0.0021559663582593203
step: 760, loss: 0.08827760070562363
step: 770, loss: 0.0257915910333395
step: 780, loss: 0.0005518491379916668
step: 790, loss: 0.03105437383055687
step: 800, loss: 0.071736179292202
step: 810, loss: 0.079350546002388
step: 820, loss: 0.006159297656267881
step: 830, loss: 0.07912232726812363
step: 840, loss: 0.03205614909529686
step: 850, loss: 0.0002683945931494236
step: 860, loss: 0.0012198849581182003
step: 870, loss: 0.05282382294535637
step: 880, loss: 0.06975217163562775
step: 890, loss: 1.8439781342749484e-05
step: 900, loss: 0.03352341428399086
step: 910, loss: 0.051995981484651566
step: 920, loss: 0.02386937290430069
step: 930, loss: 0.018919801339507103
step: 940, loss: 0.029921548441052437
step: 950, loss: 0.0703430026769638
step: 960, loss: 0.026441054418683052
step: 970, loss: 0.03063480369746685
step: 980, loss: 0.025345901027321815
step: 990, loss: 0.017719995230436325
step: 1000, loss: 0.0018205353990197182
step: 1010, loss: 0.030927643179893494
step: 1020, loss: 0.021602004766464233
step: 1030, loss: 0.03082256391644478
step: 1040, loss: 0.04791657626628876
step: 1050, loss: 0.039165060967206955
step: 1060, loss: 0.04682418331503868
step: 1070, loss: 0.0773894339799881
epoch 13: dev_f1=0.9253034547152195, f1=0.9271958666040395, best_f1=0.9341983317886932
step: 0, loss: 0.0003453593235462904
step: 10, loss: 0.009834221564233303
step: 20, loss: 0.06174416095018387
step: 30, loss: 0.051401928067207336
step: 40, loss: 0.04391346871852875
step: 50, loss: 0.11109121143817902
step: 60, loss: 0.019728325307369232
step: 70, loss: 0.09648458659648895
step: 80, loss: 0.025421328842639923
step: 90, loss: 0.030865922570228577
step: 100, loss: 0.014687548391520977
step: 110, loss: 0.0062983776442706585
step: 120, loss: 0.04036452993750572
step: 130, loss: 0.026359036564826965
step: 140, loss: 0.02429654262959957
step: 150, loss: 0.0001290176878683269
step: 160, loss: 0.027726605534553528
step: 170, loss: 0.037275850772857666
step: 180, loss: 0.023241356015205383
step: 190, loss: 0.04260362312197685
step: 200, loss: 0.011014862917363644
step: 210, loss: 0.001711921184323728
step: 220, loss: 0.0010077481856569648
step: 230, loss: 1.7515983927296475e-05
step: 240, loss: 0.01753484271466732
step: 250, loss: 0.049409858882427216
step: 260, loss: 0.05044817179441452
step: 270, loss: 0.008360754698514938
step: 280, loss: 0.02864149957895279
step: 290, loss: 0.015375933609902859
step: 300, loss: 0.04007825627923012
step: 310, loss: 0.008788836188614368
step: 320, loss: 0.041267670691013336
step: 330, loss: 0.0822668969631195
step: 340, loss: 0.021321600303053856
step: 350, loss: 0.0665803998708725
step: 360, loss: 0.008885331451892853
step: 370, loss: 0.03767670318484306
step: 380, loss: 0.049543216824531555
step: 390, loss: 0.04715297371149063
step: 400, loss: 0.06135472282767296
step: 410, loss: 0.03888619691133499
step: 420, loss: 1.8491626178729348e-05
step: 430, loss: 0.011349689215421677
step: 440, loss: 0.022587478160858154
step: 450, loss: 0.009630149230360985
step: 460, loss: 0.06861083954572678
step: 470, loss: 0.01228975411504507
step: 480, loss: 0.020586416125297546
step: 490, loss: 0.025887291878461838
step: 500, loss: 0.046937502920627594
step: 510, loss: 0.01834966614842415
step: 520, loss: 0.01781475357711315
step: 530, loss: 0.023152846843004227
step: 540, loss: 0.027123311534523964
step: 550, loss: 0.027736371383070946
step: 560, loss: 0.0774034932255745
step: 570, loss: 0.07604093104600906
step: 580, loss: 0.04668278247117996
step: 590, loss: 0.02051922120153904
step: 600, loss: 0.0597122386097908
step: 610, loss: 0.030114924535155296
step: 620, loss: 0.04041297733783722
step: 630, loss: 0.04520191252231598
step: 640, loss: 0.00011354176967870444
step: 650, loss: 0.00020908976148348302
step: 660, loss: 0.03761061653494835
step: 670, loss: 0.000614581978879869
step: 680, loss: 0.05605754256248474
step: 690, loss: 0.022668613120913506
step: 700, loss: 0.07022556662559509
step: 710, loss: 0.06367437541484833
step: 720, loss: 0.07587233930826187
step: 730, loss: 0.053264763206243515
step: 740, loss: 0.04934721812605858
step: 750, loss: 0.0358903594315052
step: 760, loss: 0.0006704931729473174
step: 770, loss: 0.001122244051657617
step: 780, loss: 0.0002918060345109552
step: 790, loss: 0.03709813952445984
step: 800, loss: 0.044857751578092575
step: 810, loss: 0.06568458676338196
step: 820, loss: 0.004179149400442839
step: 830, loss: 0.047351326793432236
step: 840, loss: 0.06564555317163467
step: 850, loss: 0.014814969152212143
step: 860, loss: 0.04317976534366608
step: 870, loss: 0.030421756207942963
step: 880, loss: 0.033457934856414795
step: 890, loss: 0.0802346020936966
step: 900, loss: 0.0006019302527420223
step: 910, loss: 0.01657114177942276
step: 920, loss: 0.05833784490823746
step: 930, loss: 0.018024280667304993
step: 940, loss: 0.04290050268173218
step: 950, loss: 0.0012119181919842958
step: 960, loss: 0.07474512606859207
step: 970, loss: 0.05261008441448212
step: 980, loss: 0.036260928958654404
step: 990, loss: 0.15049666166305542
step: 1000, loss: 0.0511779859662056
step: 1010, loss: 0.0006701130187138915
step: 1020, loss: 3.527498847688548e-05
step: 1030, loss: 7.094762986525893e-05
step: 1040, loss: 0.12011027336120605
step: 1050, loss: 0.07823116332292557
step: 1060, loss: 0.03095174953341484
step: 1070, loss: 0.022820942103862762
epoch 14: dev_f1=0.924953095684803, f1=0.924092409240924, best_f1=0.9341983317886932
step: 0, loss: 0.000498805136885494
step: 10, loss: 0.03151196986436844
step: 20, loss: 0.021212011575698853
step: 30, loss: 0.0004771181847900152
step: 40, loss: 0.005953597370535135
step: 50, loss: 0.006547668483108282
step: 60, loss: 0.06490644067525864
step: 70, loss: 0.00010722000297391787
step: 80, loss: 0.03983702138066292
step: 90, loss: 0.014080718159675598
step: 100, loss: 0.02955438941717148
step: 110, loss: 2.258490894746501e-05
step: 120, loss: 0.018372712656855583
step: 130, loss: 1.70016737683909e-05
step: 140, loss: 0.05868733674287796
step: 150, loss: 0.05070338398218155
step: 160, loss: 0.08193744719028473
step: 170, loss: 0.01170154195278883
step: 180, loss: 0.019594380632042885
step: 190, loss: 0.0557250902056694
step: 200, loss: 0.061804916709661484
step: 210, loss: 0.07806404680013657
step: 220, loss: 0.023394005373120308
step: 230, loss: 0.019355954602360725
step: 240, loss: 0.044061947613954544
step: 250, loss: 0.02155519649386406
step: 260, loss: 0.021325478330254555
step: 270, loss: 0.03481467068195343
step: 280, loss: 0.023497307673096657
step: 290, loss: 0.0399453230202198
step: 300, loss: 0.030447734519839287
step: 310, loss: 0.023348888382315636
step: 320, loss: 0.021495457738637924
step: 330, loss: 0.03156714513897896
step: 340, loss: 0.014058282598853111
step: 350, loss: 0.014960835687816143
step: 360, loss: 0.0003430171054787934
step: 370, loss: 0.047993794083595276
step: 380, loss: 2.741040225373581e-05
step: 390, loss: 0.0010657404782250524
step: 400, loss: 1.8618149624671787e-05
step: 410, loss: 0.05280033126473427
step: 420, loss: 0.03382781147956848
step: 430, loss: 0.024593647569417953
step: 440, loss: 0.043492019176483154
step: 450, loss: 0.09459692984819412
step: 460, loss: 0.07305163890123367
step: 470, loss: 0.027384450659155846
step: 480, loss: 0.08505945652723312
step: 490, loss: 0.00010159324301639572
step: 500, loss: 0.011374842375516891
step: 510, loss: 0.019003743305802345
step: 520, loss: 5.037598020862788e-05
step: 530, loss: 0.08296673744916916
step: 540, loss: 0.04158848151564598
step: 550, loss: 0.03832681104540825
step: 560, loss: 0.03957482799887657
step: 570, loss: 0.040318045765161514
step: 580, loss: 0.013888482004404068
step: 590, loss: 0.050258755683898926
step: 600, loss: 0.006010571960359812
step: 610, loss: 0.024181529879570007
step: 620, loss: 0.07306595891714096
step: 630, loss: 0.028166478499770164
step: 640, loss: 0.01942818984389305
step: 650, loss: 0.0753585621714592
step: 660, loss: 0.0015461569419130683
step: 670, loss: 0.00661112554371357
step: 680, loss: 0.036781296133995056
step: 690, loss: 0.025317100808024406
step: 700, loss: 0.03755871579051018
step: 710, loss: 3.280712553532794e-05
step: 720, loss: 0.02820744551718235
step: 730, loss: 0.02211509272456169
step: 740, loss: 0.0020562615245580673
step: 750, loss: 0.041383981704711914
step: 760, loss: 0.00016076430620159954
step: 770, loss: 0.04752189666032791
step: 780, loss: 0.00014166589244268835
step: 790, loss: 0.03351680189371109
step: 800, loss: 0.00013970736472401768
step: 810, loss: 0.0020423976238816977
step: 820, loss: 0.05746898427605629
step: 830, loss: 0.020999079570174217
step: 840, loss: 0.00016240193508565426
step: 850, loss: 0.08693210780620575
step: 860, loss: 0.03198758512735367
step: 870, loss: 0.04597173258662224
step: 880, loss: 0.11771660298109055
step: 890, loss: 0.02774391882121563
step: 900, loss: 0.03599254786968231
step: 910, loss: 0.0507190078496933
step: 920, loss: 0.042102351784706116
step: 930, loss: 0.02213730849325657
step: 940, loss: 0.07310623675584793
step: 950, loss: 0.08970977365970612
step: 960, loss: 0.0888742059469223
step: 970, loss: 0.030764374881982803
step: 980, loss: 0.12014760822057724
step: 990, loss: 0.06456170231103897
step: 1000, loss: 0.08639533817768097
step: 1010, loss: 0.03835184872150421
step: 1020, loss: 0.01957090012729168
step: 1030, loss: 0.07443380355834961
step: 1040, loss: 0.04207649081945419
step: 1050, loss: 0.005449051037430763
step: 1060, loss: 0.010968713089823723
step: 1070, loss: 1.025564233714249e-05
epoch 15: dev_f1=0.9291115311909263, f1=0.920514040932889, best_f1=0.9341983317886932
step: 0, loss: 0.04439549148082733
step: 10, loss: 0.041130632162094116
step: 20, loss: 0.03635931387543678
step: 30, loss: 1.2270981642359402e-05
step: 40, loss: 4.452737994142808e-05
step: 50, loss: 0.09026215225458145
step: 60, loss: 0.05322612076997757
step: 70, loss: 3.3858377719298005e-05
step: 80, loss: 4.5131444494472817e-05
step: 90, loss: 0.02637554332613945
step: 100, loss: 0.014287753961980343
step: 110, loss: 0.02360699512064457
step: 120, loss: 0.020953884348273277
step: 130, loss: 0.06265445798635483
step: 140, loss: 0.000438815972302109
step: 150, loss: 0.0004889739211648703
step: 160, loss: 0.023156629875302315
step: 170, loss: 0.024186141788959503
step: 180, loss: 0.026475956663489342
step: 190, loss: 0.02679937332868576
step: 200, loss: 0.03397313505411148
step: 210, loss: 0.015533676370978355
step: 220, loss: 0.02555174194276333
step: 230, loss: 0.02107664756476879
step: 240, loss: 4.596102735376917e-05
step: 250, loss: 0.006928918417543173
step: 260, loss: 0.038526277989149094
step: 270, loss: 7.32619155314751e-05
step: 280, loss: 0.026109706610441208
step: 290, loss: 0.003114276099950075
step: 300, loss: 0.022724013775587082
step: 310, loss: 0.0001884981757029891
step: 320, loss: 1.4096278391662054e-05
step: 330, loss: 0.03336610645055771
step: 340, loss: 0.0027415496297180653
step: 350, loss: 0.16112583875656128
step: 360, loss: 3.909636870957911e-05
step: 370, loss: 0.005854406394064426
step: 380, loss: 0.028476988896727562
step: 390, loss: 0.019372904673218727
step: 400, loss: 0.0210544653236866
step: 410, loss: 0.051620855927467346
step: 420, loss: 0.12516705691814423
step: 430, loss: 0.02492697723209858
step: 440, loss: 0.04533878341317177
step: 450, loss: 0.0009937224676832557
step: 460, loss: 0.05000733584165573
step: 470, loss: 0.05693734064698219
step: 480, loss: 0.020417682826519012
step: 490, loss: 0.020064007490873337
step: 500, loss: 0.020959245041012764
step: 510, loss: 0.07625201344490051
step: 520, loss: 0.05178690329194069
step: 530, loss: 0.022172121331095695
step: 540, loss: 0.060707032680511475
step: 550, loss: 4.323431130615063e-05
step: 560, loss: 0.025448160246014595
step: 570, loss: 0.026097014546394348
step: 580, loss: 0.0834682360291481
step: 590, loss: 0.06257778406143188
step: 600, loss: 0.02735745720565319
step: 610, loss: 0.01930161938071251
step: 620, loss: 0.018834233283996582
step: 630, loss: 0.0004540602385532111
step: 640, loss: 0.0573410764336586
step: 650, loss: 0.0388360396027565
step: 660, loss: 0.028660131618380547
step: 670, loss: 0.054029595106840134
step: 680, loss: 1.878203147498425e-05
step: 690, loss: 0.044168323278427124
step: 700, loss: 0.004039168357849121
step: 710, loss: 0.09765192121267319
step: 720, loss: 0.026014436036348343
step: 730, loss: 0.02208596281707287
step: 740, loss: 0.025106577202677727
step: 750, loss: 2.994705027958844e-05
step: 760, loss: 0.0032848024275153875
step: 770, loss: 0.0131081473082304
step: 780, loss: 0.045962173491716385
step: 790, loss: 0.022246159613132477
step: 800, loss: 0.0002839570806827396
step: 810, loss: 0.03196518123149872
step: 820, loss: 0.02591586299240589
step: 830, loss: 5.7721226767171174e-05
step: 840, loss: 0.023526055738329887
step: 850, loss: 0.011142711155116558
step: 860, loss: 0.0027596221771091223
step: 870, loss: 0.01644415594637394
step: 880, loss: 9.700422378955409e-05
step: 890, loss: 0.024712542071938515
step: 900, loss: 0.03964732214808464
step: 910, loss: 0.1053597554564476
step: 920, loss: 0.00011252765398239717
step: 930, loss: 0.0210479237139225
step: 940, loss: 0.015870211645960808
step: 950, loss: 1.79438302438939e-05
step: 960, loss: 0.02696613222360611
step: 970, loss: 0.025853397324681282
step: 980, loss: 6.931110692676157e-05
step: 990, loss: 0.07059419900178909
step: 1000, loss: 0.0466301366686821
step: 1010, loss: 0.06202378123998642
step: 1020, loss: 0.04580315947532654
step: 1030, loss: 0.001115614315494895
step: 1040, loss: 0.09456200897693634
step: 1050, loss: 0.019093291833996773
step: 1060, loss: 0.020976414903998375
step: 1070, loss: 0.022529583424329758
epoch 16: dev_f1=0.9332711152589829, f1=0.9276315789473684, best_f1=0.9341983317886932
step: 0, loss: 0.07633937895298004
step: 10, loss: 0.026451729238033295
step: 20, loss: 0.0229988694190979
step: 30, loss: 0.04119844362139702
step: 40, loss: 0.002220149850472808
step: 50, loss: 0.0033784457482397556
step: 60, loss: 0.015325648710131645
step: 70, loss: 0.0006710129091516137
step: 80, loss: 0.05941329151391983
step: 90, loss: 0.007122850976884365
step: 100, loss: 0.026100696995854378
step: 110, loss: 0.002491797786206007
step: 120, loss: 0.04373076930642128
step: 130, loss: 0.03055368736386299
step: 140, loss: 0.044883545488119125
step: 150, loss: 0.025919023901224136
step: 160, loss: 0.02524462528526783
step: 170, loss: 0.047024261206388474
step: 180, loss: 0.04404563829302788
step: 190, loss: 0.024186747148633003
step: 200, loss: 0.00011354057642165571
step: 210, loss: 0.032209545373916626
step: 220, loss: 0.020343251526355743
step: 230, loss: 0.0009584188228473067
step: 240, loss: 0.00028105141245760024
step: 250, loss: 0.0775938481092453
step: 260, loss: 0.021525869145989418
step: 270, loss: 2.099049015669152e-05
step: 280, loss: 7.361199823208153e-05
step: 290, loss: 0.02544553205370903
step: 300, loss: 0.0479438416659832
step: 310, loss: 0.00015813906793482602
step: 320, loss: 0.035573918372392654
step: 330, loss: 0.0038412995636463165
step: 340, loss: 0.027750371024012566
step: 350, loss: 0.065061554312706
step: 360, loss: 2.4651009880471975e-05
step: 370, loss: 0.013317304663360119
step: 380, loss: 0.1178363710641861
step: 390, loss: 0.00043794093653559685
step: 400, loss: 0.05565493553876877
step: 410, loss: 0.029540695250034332
step: 420, loss: 6.442048470489681e-05
step: 430, loss: 0.046113863587379456
step: 440, loss: 0.00010210269829258323
step: 450, loss: 0.021465584635734558
step: 460, loss: 0.10262873023748398
step: 470, loss: 2.3992459318833426e-05
step: 480, loss: 0.022308707237243652
step: 490, loss: 0.03088231198489666
step: 500, loss: 0.021899381652474403
step: 510, loss: 9.201982902595773e-05
step: 520, loss: 0.00011490545148262754
step: 530, loss: 0.03159068897366524
step: 540, loss: 0.024169985204935074
step: 550, loss: 8.513439388480037e-05
step: 560, loss: 0.022446518763899803
step: 570, loss: 0.003936290740966797
step: 580, loss: 0.0005691968835890293
step: 590, loss: 0.042611826211214066
step: 600, loss: 3.989028846262954e-05
step: 610, loss: 0.0001182540217996575
step: 620, loss: 0.057450275868177414
step: 630, loss: 0.038974370807409286
step: 640, loss: 0.0162897240370512
step: 650, loss: 0.029787296429276466
step: 660, loss: 0.0002149446081602946
step: 670, loss: 0.05431707948446274
step: 680, loss: 4.231762795825489e-05
step: 690, loss: 0.060584958642721176
step: 700, loss: 0.0205922182649374
step: 710, loss: 0.02012196183204651
step: 720, loss: 0.036164816468954086
step: 730, loss: 0.0014851405285298824
step: 740, loss: 0.00024312442110385746
step: 750, loss: 4.286548573873006e-05
step: 760, loss: 0.02680242247879505
step: 770, loss: 0.011804915964603424
step: 780, loss: 0.00019482833158690482
step: 790, loss: 0.03315124288201332
step: 800, loss: 2.7133204639540054e-05
step: 810, loss: 0.04166991263628006
step: 820, loss: 0.011886581778526306
step: 830, loss: 0.019834205508232117
step: 840, loss: 0.0394938588142395
step: 850, loss: 0.03119451180100441
step: 860, loss: 0.00046036645653657615
step: 870, loss: 0.04154961183667183
step: 880, loss: 0.0002587934141047299
step: 890, loss: 0.02545796148478985
step: 900, loss: 0.028422115370631218
step: 910, loss: 0.0004457422473933548
step: 920, loss: 0.051665566861629486
step: 930, loss: 0.01653175801038742
step: 940, loss: 3.928814840037376e-05
step: 950, loss: 4.287268529878929e-05
step: 960, loss: 0.020454883575439453
step: 970, loss: 0.04321257025003433
step: 980, loss: 0.021861504763364792
step: 990, loss: 0.02109162136912346
step: 1000, loss: 0.048168763518333435
step: 1010, loss: 0.030104845762252808
step: 1020, loss: 0.020617978647351265
step: 1030, loss: 4.074525350006297e-05
step: 1040, loss: 8.635187259642407e-05
step: 1050, loss: 0.019432811066508293
step: 1060, loss: 0.0053605493158102036
step: 1070, loss: 0.002446508966386318
epoch 17: dev_f1=0.9328984156570364, f1=0.9262564584311883, best_f1=0.9341983317886932
step: 0, loss: 0.16154147684574127
step: 10, loss: 0.0023612927179783583
step: 20, loss: 0.04064970090985298
step: 30, loss: 0.0491432249546051
step: 40, loss: 0.014263499528169632
step: 50, loss: 0.015609752386808395
step: 60, loss: 0.03064294531941414
step: 70, loss: 6.534989370265976e-05
step: 80, loss: 0.06643430143594742
step: 90, loss: 0.008363398723304272
step: 100, loss: 0.039763353765010834
step: 110, loss: 0.0001179381797555834
step: 120, loss: 0.05100593715906143
step: 130, loss: 0.004332990385591984
step: 140, loss: 0.03829945623874664
step: 150, loss: 0.03023878112435341
step: 160, loss: 0.03511663153767586
step: 170, loss: 0.04470716416835785
step: 180, loss: 0.022839326411485672
step: 190, loss: 0.0943412110209465
step: 200, loss: 9.663600940257311e-05
step: 210, loss: 0.016607386991381645
step: 220, loss: 0.03884334862232208
step: 230, loss: 0.021216994151473045
step: 240, loss: 0.027875293046236038
step: 250, loss: 0.027179595082998276
step: 260, loss: 0.0006343545392155647
step: 270, loss: 0.025592606514692307
step: 280, loss: 3.815561649389565e-05
step: 290, loss: 0.06593025475740433
step: 300, loss: 1.777207216946408e-05
step: 310, loss: 0.0060433573089540005
step: 320, loss: 0.02382436953485012
step: 330, loss: 0.08632868528366089
step: 340, loss: 1.2956336831848603e-05
step: 350, loss: 0.006265091244131327
step: 360, loss: 5.657054134644568e-05
step: 370, loss: 2.0417308405740187e-05
step: 380, loss: 0.022718673571944237
step: 390, loss: 2.950451562355738e-05
step: 400, loss: 4.5224063796922565e-05
step: 410, loss: 0.0016566906124353409
step: 420, loss: 0.07952382415533066
step: 430, loss: 0.050653427839279175
step: 440, loss: 0.0008869830635376275
step: 450, loss: 2.8111779101891443e-05
step: 460, loss: 0.029285430908203125
step: 470, loss: 0.0012958053266629577
step: 480, loss: 0.015213650651276112
step: 490, loss: 0.04723701998591423
step: 500, loss: 0.0077958907932043076
step: 510, loss: 0.03305840119719505
step: 520, loss: 0.05945267900824547
step: 530, loss: 0.030892513692378998
step: 540, loss: 0.019140157848596573
step: 550, loss: 0.00042760669020935893
step: 560, loss: 0.06071227788925171
step: 570, loss: 0.026296889409422874
step: 580, loss: 0.10070916265249252
step: 590, loss: 4.5879824028816074e-05
step: 600, loss: 0.00016613813932053745
step: 610, loss: 0.04027177020907402
step: 620, loss: 0.0421321876347065
step: 630, loss: 0.0001369595411233604
step: 640, loss: 0.039045482873916626
step: 650, loss: 0.03140083700418472
step: 660, loss: 0.06267117708921432
step: 670, loss: 0.05045720189809799
step: 680, loss: 0.10627315938472748
step: 690, loss: 0.023140965029597282
step: 700, loss: 0.021740930154919624
step: 710, loss: 0.025878621265292168
step: 720, loss: 7.705916505074129e-05
step: 730, loss: 0.02574765682220459
step: 740, loss: 0.09109952300786972
step: 750, loss: 0.00037895122659392655
step: 760, loss: 0.04606486111879349
step: 770, loss: 0.02938987873494625
step: 780, loss: 0.10137880593538284
step: 790, loss: 0.051749471575021744
step: 800, loss: 0.02429681271314621
step: 810, loss: 0.02643793635070324
step: 820, loss: 0.05685875192284584
step: 830, loss: 0.017363062128424644
step: 840, loss: 6.009101343806833e-05
step: 850, loss: 0.04328010231256485
step: 860, loss: 0.034222375601530075
step: 870, loss: 3.676955384435132e-05
step: 880, loss: 0.052246760576963425
step: 890, loss: 0.022836990654468536
step: 900, loss: 0.02280992642045021
step: 910, loss: 0.08491803705692291
step: 920, loss: 0.01905938796699047
step: 930, loss: 0.00026175857055932283
step: 940, loss: 1.691947727522347e-05
step: 950, loss: 0.044316451996564865
step: 960, loss: 0.027167435735464096
step: 970, loss: 0.01379381399601698
step: 980, loss: 0.06426145136356354
step: 990, loss: 0.047336675226688385
step: 1000, loss: 0.04333004727959633
step: 1010, loss: 0.039936065673828125
step: 1020, loss: 2.1746582206105813e-05
step: 1030, loss: 8.84593537193723e-05
step: 1040, loss: 0.0002309426199644804
step: 1050, loss: 0.04092884436249733
step: 1060, loss: 1.4826391634414904e-05
step: 1070, loss: 0.01503866445273161
epoch 18: dev_f1=0.9301025163094129, f1=0.9266012155212716, best_f1=0.9341983317886932
step: 0, loss: 0.014403068460524082
step: 10, loss: 0.05283331871032715
step: 20, loss: 0.0478338822722435
step: 30, loss: 0.02205674722790718
step: 40, loss: 1.938142850121949e-05
step: 50, loss: 0.03295416012406349
step: 60, loss: 0.04352526739239693
step: 70, loss: 0.02770475298166275
step: 80, loss: 0.026204776018857956
step: 90, loss: 0.07451179623603821
step: 100, loss: 0.00010197550000157207
step: 110, loss: 0.03874475508928299
step: 120, loss: 0.02375703863799572
step: 130, loss: 0.0012441769940778613
step: 140, loss: 8.326892566401511e-05
step: 150, loss: 0.08878283202648163
step: 160, loss: 0.02000146545469761
step: 170, loss: 0.045072782784700394
step: 180, loss: 0.0005370925064198673
step: 190, loss: 6.681665399810299e-05
step: 200, loss: 0.04350791499018669
step: 210, loss: 0.023168910294771194
step: 220, loss: 0.0390874482691288
step: 230, loss: 0.042501259595155716
step: 240, loss: 0.01954130455851555
step: 250, loss: 0.10229777544736862
step: 260, loss: 3.05837020277977e-05
step: 270, loss: 0.04976111650466919
step: 280, loss: 0.020772479474544525
step: 290, loss: 0.02251620590686798
step: 300, loss: 0.00018682159134186804
step: 310, loss: 0.005540914833545685
step: 320, loss: 0.00019106699619442225
step: 330, loss: 0.0014327836688607931
step: 340, loss: 0.025475306436419487
step: 350, loss: 0.0023469896987080574
step: 360, loss: 0.03727647289633751
step: 370, loss: 0.04606923088431358
step: 380, loss: 0.06332383304834366
step: 390, loss: 5.849457738804631e-05
step: 400, loss: 0.01633252203464508
step: 410, loss: 0.00012435636017471552
step: 420, loss: 0.039626412093639374
step: 430, loss: 0.03472231701016426
step: 440, loss: 0.025630123913288116
step: 450, loss: 0.0258872602134943
step: 460, loss: 0.034732427448034286
step: 470, loss: 0.001587477046996355
step: 480, loss: 0.07857440412044525
step: 490, loss: 0.013283444568514824
step: 500, loss: 0.022621773183345795
step: 510, loss: 0.04795249551534653
step: 520, loss: 0.03077574633061886
step: 530, loss: 0.02235117182135582
step: 540, loss: 0.01653534732758999
step: 550, loss: 0.027228131890296936
step: 560, loss: 0.02212456613779068
step: 570, loss: 1.0013506653194781e-05
step: 580, loss: 0.02140972577035427
step: 590, loss: 0.0006001318688504398
step: 600, loss: 0.02130395546555519
step: 610, loss: 6.79619115544483e-05
step: 620, loss: 0.03068707324564457
step: 630, loss: 0.03465546295046806
step: 640, loss: 0.02667507342994213
step: 650, loss: 0.019208170473575592
step: 660, loss: 0.09722326695919037
step: 670, loss: 0.023132268339395523
step: 680, loss: 0.0002895314828492701
step: 690, loss: 8.787907972873654e-06
step: 700, loss: 0.029290571808815002
step: 710, loss: 0.03428390249609947
step: 720, loss: 0.03409967198967934
step: 730, loss: 1.441280710423598e-05
step: 740, loss: 0.00017600043793208897
step: 750, loss: 0.017904000356793404
step: 760, loss: 0.04352708160877228
step: 770, loss: 0.045597005635499954
step: 780, loss: 0.05215005949139595
step: 790, loss: 0.08524016290903091
step: 800, loss: 0.18037837743759155
step: 810, loss: 0.0027397554367780685
step: 820, loss: 0.017383433878421783
step: 830, loss: 0.04221652075648308
step: 840, loss: 0.0019394549308344722
step: 850, loss: 0.0001589039748068899
step: 860, loss: 0.04777221754193306
step: 870, loss: 5.562160367844626e-05
step: 880, loss: 0.062815360724926
step: 890, loss: 7.773650577291846e-05
step: 900, loss: 0.024791428819298744
step: 910, loss: 0.023843448609113693
step: 920, loss: 0.028400395065546036
step: 930, loss: 0.017354365438222885
step: 940, loss: 0.035698335617780685
step: 950, loss: 0.0029308805242180824
step: 960, loss: 0.0659424290060997
step: 970, loss: 0.037990592420101166
step: 980, loss: 0.0010360494488850236
step: 990, loss: 2.949953886854928e-05
step: 1000, loss: 0.00048216228606179357
step: 1010, loss: 0.019091082736849785
step: 1020, loss: 1.941880509548355e-05
step: 1030, loss: 0.012816033326089382
step: 1040, loss: 0.00036215217551216483
step: 1050, loss: 0.0011547819012776017
step: 1060, loss: 0.04074542969465256
step: 1070, loss: 0.04488090053200722
epoch 19: dev_f1=0.9314045730284647, f1=0.9265325222274216, best_f1=0.9341983317886932
step: 0, loss: 6.109862442826852e-05
step: 10, loss: 0.024944128468632698
step: 20, loss: 0.03931277617812157
step: 30, loss: 6.741646939190105e-05
step: 40, loss: 0.02530635893344879
step: 50, loss: 0.04091094806790352
step: 60, loss: 0.01865558885037899
step: 70, loss: 0.04585712030529976
step: 80, loss: 0.0018454156816005707
step: 90, loss: 6.80029988870956e-05
step: 100, loss: 0.0007569817826151848
step: 110, loss: 0.018589697778224945
step: 120, loss: 0.0469185970723629
step: 130, loss: 0.021038347855210304
step: 140, loss: 2.6972038540407084e-05
step: 150, loss: 0.021338967606425285
step: 160, loss: 3.696852218126878e-05
step: 170, loss: 0.066581130027771
step: 180, loss: 0.019046833738684654
step: 190, loss: 0.0003036014677491039
step: 200, loss: 4.3180614738957956e-05
step: 210, loss: 0.07676415890455246
step: 220, loss: 0.0013852041447535157
step: 230, loss: 0.00021646961977239698
step: 240, loss: 2.517494431231171e-05
step: 250, loss: 0.004500046372413635
step: 260, loss: 0.04380016773939133
step: 270, loss: 0.00014745375665370375
step: 280, loss: 0.10671427845954895
step: 290, loss: 0.00954312551766634
step: 300, loss: 0.02343507669866085
step: 310, loss: 0.0017241748282685876
step: 320, loss: 0.018287036567926407
step: 330, loss: 0.04307176172733307
step: 340, loss: 8.361967047676444e-05
step: 350, loss: 0.02329321950674057
step: 360, loss: 0.020966779440641403
step: 370, loss: 0.07835381478071213
step: 380, loss: 0.061059098690748215
step: 390, loss: 0.000320593302603811
step: 400, loss: 5.706569936592132e-05
step: 410, loss: 0.11663170903921127
step: 420, loss: 1.924731259350665e-05
step: 430, loss: 0.011302808299660683
step: 440, loss: 3.8685291656292975e-05
step: 450, loss: 0.0017875336343422532
step: 460, loss: 0.04426092654466629
step: 470, loss: 3.682755050249398e-05
step: 480, loss: 0.006015831604599953
step: 490, loss: 0.06316410005092621
step: 500, loss: 0.025275804102420807
step: 510, loss: 0.04662562906742096
step: 520, loss: 0.02351636439561844
step: 530, loss: 0.020947786048054695
step: 540, loss: 0.06698434054851532
step: 550, loss: 0.00011250190436840057
step: 560, loss: 2.3743843485135585e-05
step: 570, loss: 3.4366581530775875e-05
step: 580, loss: 4.533782339422032e-05
step: 590, loss: 0.021166430786252022
step: 600, loss: 0.00010856072185561061
step: 610, loss: 0.03451079502701759
step: 620, loss: 0.053183335810899734
step: 630, loss: 0.04698719456791878
step: 640, loss: 0.06216629967093468
step: 650, loss: 0.0006897067069076002
step: 660, loss: 0.05563334375619888
step: 670, loss: 0.03590286523103714
step: 680, loss: 0.023009568452835083
step: 690, loss: 0.001271378598175943
step: 700, loss: 0.043082136660814285
step: 710, loss: 0.017386559396982193
step: 720, loss: 0.04363848641514778
step: 730, loss: 0.00018688870477490127
step: 740, loss: 0.027160223573446274
step: 750, loss: 0.023494314402341843
step: 760, loss: 0.041055090725421906
step: 770, loss: 0.06285552680492401
step: 780, loss: 0.028287675231695175
step: 790, loss: 0.021181868389248848
step: 800, loss: 0.0003409205819480121
step: 810, loss: 0.02373996004462242
step: 820, loss: 0.014213452115654945
step: 830, loss: 0.02068180963397026
step: 840, loss: 0.015969200059771538
step: 850, loss: 0.07347454130649567
step: 860, loss: 4.267687108949758e-05
step: 870, loss: 0.0406021773815155
step: 880, loss: 0.0623062402009964
step: 890, loss: 0.04820822551846504
step: 900, loss: 0.052624527364969254
step: 910, loss: 0.05647280812263489
step: 920, loss: 0.00010914279846474528
step: 930, loss: 0.06368829309940338
step: 940, loss: 0.04992925748229027
step: 950, loss: 0.06094883754849434
step: 960, loss: 0.009699782356619835
step: 970, loss: 0.04755275323987007
step: 980, loss: 0.0005875948118045926
step: 990, loss: 0.00022589261061511934
step: 1000, loss: 0.037381093949079514
step: 1010, loss: 0.06321606785058975
step: 1020, loss: 0.048660989850759506
step: 1030, loss: 0.021522440016269684
step: 1040, loss: 0.0005209848750382662
step: 1050, loss: 0.01773851178586483
step: 1060, loss: 0.013241572305560112
step: 1070, loss: 0.00017271733668167144
epoch 20: dev_f1=0.932274638019617, f1=0.9259606373008434, best_f1=0.9341983317886932
