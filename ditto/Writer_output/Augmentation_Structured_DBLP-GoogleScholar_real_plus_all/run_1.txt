cuda
Device: cuda
step: 0, loss: 0.6489090323448181
step: 10, loss: 0.5777864456176758
step: 20, loss: 0.3781803548336029
step: 30, loss: 0.43499958515167236
step: 40, loss: 0.3564353883266449
step: 50, loss: 0.31000417470932007
step: 60, loss: 0.1924259215593338
step: 70, loss: 0.20735611021518707
step: 80, loss: 0.23942233622074127
step: 90, loss: 0.12764889001846313
step: 100, loss: 0.1477271318435669
step: 110, loss: 0.3358176350593567
step: 120, loss: 0.19150681793689728
step: 130, loss: 0.25467315316200256
step: 140, loss: 0.15269885957241058
step: 150, loss: 0.24154134094715118
step: 160, loss: 0.19143031537532806
step: 170, loss: 0.11433373391628265
step: 180, loss: 0.10430140793323517
step: 190, loss: 0.13247551023960114
step: 200, loss: 0.13410064578056335
step: 210, loss: 0.17664985358715057
step: 220, loss: 0.21462002396583557
step: 230, loss: 0.16509012877941132
step: 240, loss: 0.10855868458747864
step: 250, loss: 0.0756649374961853
step: 260, loss: 0.15483219921588898
step: 270, loss: 0.06474602222442627
step: 280, loss: 0.09159871190786362
step: 290, loss: 0.11460869014263153
step: 300, loss: 0.1340084969997406
step: 310, loss: 0.22021760046482086
step: 320, loss: 0.20629815757274628
step: 330, loss: 0.2633531391620636
step: 340, loss: 0.12299370765686035
step: 350, loss: 0.03229004144668579
step: 360, loss: 0.28917548060417175
step: 370, loss: 0.11679123342037201
step: 380, loss: 0.3313937783241272
step: 390, loss: 0.17164961993694305
step: 400, loss: 0.2320069521665573
step: 410, loss: 0.10426005721092224
step: 420, loss: 0.14415238797664642
step: 430, loss: 0.15299637615680695
step: 440, loss: 0.1404792219400406
step: 450, loss: 0.059005800634622574
step: 460, loss: 0.30474379658699036
step: 470, loss: 0.06819643080234528
step: 480, loss: 0.0705619603395462
step: 490, loss: 0.15036040544509888
step: 500, loss: 0.11957794427871704
step: 510, loss: 0.08552518486976624
step: 520, loss: 0.19583655893802643
step: 530, loss: 0.07153743505477905
step: 540, loss: 0.08162254095077515
step: 550, loss: 0.08496538549661636
step: 560, loss: 0.16163362562656403
step: 570, loss: 0.25143158435821533
step: 580, loss: 0.07061080634593964
step: 590, loss: 0.08496399223804474
step: 600, loss: 0.20186151564121246
step: 610, loss: 0.08977244049310684
step: 620, loss: 0.08718705177307129
step: 630, loss: 0.09093775600194931
step: 640, loss: 0.05254416540265083
step: 650, loss: 0.0435682088136673
step: 660, loss: 0.06347233057022095
step: 670, loss: 0.05434493348002434
step: 680, loss: 0.12489568442106247
step: 690, loss: 0.08533360064029694
step: 700, loss: 0.09731193631887436
step: 710, loss: 0.09061829745769501
step: 720, loss: 0.12803497910499573
step: 730, loss: 0.16387644410133362
step: 740, loss: 0.151646226644516
step: 750, loss: 0.0722862035036087
step: 760, loss: 0.14111104607582092
step: 770, loss: 0.022707641124725342
step: 780, loss: 0.07975824922323227
step: 790, loss: 0.08615005016326904
step: 800, loss: 0.15729817748069763
step: 810, loss: 0.07245130836963654
step: 820, loss: 0.16672180593013763
step: 830, loss: 0.024776389822363853
step: 840, loss: 0.12163367122411728
step: 850, loss: 0.05715944245457649
step: 860, loss: 0.13169147074222565
step: 870, loss: 0.1456984579563141
step: 880, loss: 0.0691593810915947
step: 890, loss: 0.09636443853378296
step: 900, loss: 0.06735172867774963
step: 910, loss: 0.129247784614563
step: 920, loss: 0.02942550554871559
step: 930, loss: 0.05431763082742691
step: 940, loss: 0.08336662501096725
step: 950, loss: 0.07605170458555222
step: 960, loss: 0.004429592750966549
step: 970, loss: 0.11715468019247055
step: 980, loss: 0.040365491062402725
step: 990, loss: 0.08475405722856522
step: 1000, loss: 0.12481212615966797
step: 1010, loss: 0.06357121467590332
step: 1020, loss: 0.049965593963861465
step: 1030, loss: 0.01858489401638508
step: 1040, loss: 0.10582999140024185
step: 1050, loss: 0.10183040052652359
step: 1060, loss: 0.0692271888256073
step: 1070, loss: 0.05716270953416824
epoch 1: dev_f1=0.9273743016759776, f1=0.9286043298019346, best_f1=0.9286043298019346
step: 0, loss: 0.035160671919584274
step: 10, loss: 0.11523597687482834
step: 20, loss: 0.03938264027237892
step: 30, loss: 0.1087508574128151
step: 40, loss: 0.11942104250192642
step: 50, loss: 0.051848363131284714
step: 60, loss: 0.10030792653560638
step: 70, loss: 0.09603800624608994
step: 80, loss: 0.20397597551345825
step: 90, loss: 0.02917119860649109
step: 100, loss: 0.07732265442609787
step: 110, loss: 0.23320288956165314
step: 120, loss: 0.10033655911684036
step: 130, loss: 0.21937264502048492
step: 140, loss: 0.039528872817754745
step: 150, loss: 0.049276817589998245
step: 160, loss: 0.12032859027385712
step: 170, loss: 0.30421024560928345
step: 180, loss: 0.08684088289737701
step: 190, loss: 0.054036810994148254
step: 200, loss: 0.14738409221172333
step: 210, loss: 0.07919327169656754
step: 220, loss: 0.07821454107761383
step: 230, loss: 0.20946082472801208
step: 240, loss: 0.085426926612854
step: 250, loss: 0.03860918805003166
step: 260, loss: 0.1437450349330902
step: 270, loss: 0.07354506850242615
step: 280, loss: 0.03672751411795616
step: 290, loss: 0.05756887421011925
step: 300, loss: 0.08422013372182846
step: 310, loss: 0.10491257905960083
step: 320, loss: 0.11987949907779694
step: 330, loss: 0.024636108428239822
step: 340, loss: 0.20297150313854218
step: 350, loss: 0.13361646234989166
step: 360, loss: 0.05959421768784523
step: 370, loss: 0.10572097450494766
step: 380, loss: 0.0775584951043129
step: 390, loss: 0.13129523396492004
step: 400, loss: 0.11742401123046875
step: 410, loss: 0.07543802261352539
step: 420, loss: 0.2248339056968689
step: 430, loss: 0.1586807370185852
step: 440, loss: 0.061779893934726715
step: 450, loss: 0.08805038034915924
step: 460, loss: 0.015153612941503525
step: 470, loss: 0.11746411770582199
step: 480, loss: 0.08568312227725983
step: 490, loss: 0.05500058829784393
step: 500, loss: 0.02789047732949257
step: 510, loss: 0.028573382645845413
step: 520, loss: 0.07035930454730988
step: 530, loss: 0.22523781657218933
step: 540, loss: 0.1869596242904663
step: 550, loss: 0.0002821942907758057
step: 560, loss: 0.11727090924978256
step: 570, loss: 0.022635342553257942
step: 580, loss: 0.10576780885457993
step: 590, loss: 0.08731956779956818
step: 600, loss: 0.13324154913425446
step: 610, loss: 0.08072429150342941
step: 620, loss: 0.1912841945886612
step: 630, loss: 0.10540598630905151
step: 640, loss: 0.14148564636707306
step: 650, loss: 0.17982378602027893
step: 660, loss: 0.08510307222604752
step: 670, loss: 0.17499041557312012
step: 680, loss: 0.05120430141687393
step: 690, loss: 0.17871426045894623
step: 700, loss: 0.21159368753433228
step: 710, loss: 0.028543176129460335
step: 720, loss: 0.01294697541743517
step: 730, loss: 0.0634743943810463
step: 740, loss: 0.060492247343063354
step: 750, loss: 0.17635194957256317
step: 760, loss: 0.02094125747680664
step: 770, loss: 0.12014675885438919
step: 780, loss: 0.13447414338588715
step: 790, loss: 0.009382232092320919
step: 800, loss: 0.05599348619580269
step: 810, loss: 0.11782528460025787
step: 820, loss: 0.07804332673549652
step: 830, loss: 0.07444743812084198
step: 840, loss: 0.09877538681030273
step: 850, loss: 0.12045764178037643
step: 860, loss: 0.004535496700555086
step: 870, loss: 0.12657716870307922
step: 880, loss: 0.13491256535053253
step: 890, loss: 0.03292528912425041
step: 900, loss: 0.04256676137447357
step: 910, loss: 0.19280517101287842
step: 920, loss: 0.07473073899745941
step: 930, loss: 0.16929490864276886
step: 940, loss: 0.1436598151922226
step: 950, loss: 0.07567566633224487
step: 960, loss: 0.07817724347114563
step: 970, loss: 0.18656571209430695
step: 980, loss: 0.015113580971956253
step: 990, loss: 0.14926078915596008
step: 1000, loss: 0.08899203687906265
step: 1010, loss: 0.08779514580965042
step: 1020, loss: 0.09224803000688553
step: 1030, loss: 0.08407942205667496
step: 1040, loss: 0.21044544875621796
step: 1050, loss: 0.08335324376821518
step: 1060, loss: 0.1383536010980606
step: 1070, loss: 0.0628616139292717
epoch 2: dev_f1=0.9338303821062441, f1=0.9325894932589495, best_f1=0.9325894932589495
step: 0, loss: 0.009466459043323994
step: 10, loss: 0.034331392496824265
step: 20, loss: 0.021294675767421722
step: 30, loss: 0.07232343405485153
step: 40, loss: 0.0695127323269844
step: 50, loss: 0.18769602477550507
step: 60, loss: 0.1012292355298996
step: 70, loss: 0.016405882313847542
step: 80, loss: 0.0334201380610466
step: 90, loss: 0.06148449704051018
step: 100, loss: 0.08304933458566666
step: 110, loss: 0.08054447174072266
step: 120, loss: 0.18176108598709106
step: 130, loss: 0.09122422337532043
step: 140, loss: 0.02235320582985878
step: 150, loss: 0.07190895080566406
step: 160, loss: 0.0008031603647395968
step: 170, loss: 0.22282232344150543
step: 180, loss: 0.11292493343353271
step: 190, loss: 0.01690915785729885
step: 200, loss: 0.08208882808685303
step: 210, loss: 0.029574673622846603
step: 220, loss: 0.10673302412033081
step: 230, loss: 0.022134538739919662
step: 240, loss: 0.09239216893911362
step: 250, loss: 0.23237597942352295
step: 260, loss: 0.2708262503147125
step: 270, loss: 0.06869950890541077
step: 280, loss: 0.03327883407473564
step: 290, loss: 0.13087010383605957
step: 300, loss: 0.19288823008537292
step: 310, loss: 0.19684351980686188
step: 320, loss: 0.031398456543684006
step: 330, loss: 0.1366451531648636
step: 340, loss: 0.08333007991313934
step: 350, loss: 0.12128099054098129
step: 360, loss: 0.11229752749204636
step: 370, loss: 0.05601831153035164
step: 380, loss: 0.10214264690876007
step: 390, loss: 0.05549154058098793
step: 400, loss: 0.020824847742915154
step: 410, loss: 0.019416553899645805
step: 420, loss: 0.03139196336269379
step: 430, loss: 0.008963493630290031
step: 440, loss: 0.08214423805475235
step: 450, loss: 0.10731732100248337
step: 460, loss: 0.07027099281549454
step: 470, loss: 0.1897454857826233
step: 480, loss: 0.09000291675329208
step: 490, loss: 0.03374994173645973
step: 500, loss: 0.09518025815486908
step: 510, loss: 0.1271752119064331
step: 520, loss: 0.08705843985080719
step: 530, loss: 0.02785361185669899
step: 540, loss: 0.11026030033826828
step: 550, loss: 0.1423669457435608
step: 560, loss: 0.042593102902173996
step: 570, loss: 0.02330404706299305
step: 580, loss: 0.2688751816749573
step: 590, loss: 0.1286790668964386
step: 600, loss: 0.04196271300315857
step: 610, loss: 0.020896246656775475
step: 620, loss: 0.013951089233160019
step: 630, loss: 0.06467204540967941
step: 640, loss: 0.07951133698225021
step: 650, loss: 0.029129832983016968
step: 660, loss: 0.009078658185899258
step: 670, loss: 0.006260501686483622
step: 680, loss: 0.08965042978525162
step: 690, loss: 0.0058838301338255405
step: 700, loss: 0.14794208109378815
step: 710, loss: 0.15062463283538818
step: 720, loss: 0.04457295686006546
step: 730, loss: 0.0671277716755867
step: 740, loss: 0.07906956970691681
step: 750, loss: 0.20566825568675995
step: 760, loss: 0.1253076046705246
step: 770, loss: 0.028260305523872375
step: 780, loss: 0.08538435399532318
step: 790, loss: 0.18675662577152252
step: 800, loss: 0.027421709150075912
step: 810, loss: 0.044207505881786346
step: 820, loss: 0.12758304178714752
step: 830, loss: 0.029978236183524132
step: 840, loss: 0.03863482177257538
step: 850, loss: 0.012910638004541397
step: 860, loss: 0.06431042402982712
step: 870, loss: 0.02981894090771675
step: 880, loss: 0.06898993998765945
step: 890, loss: 0.08081764727830887
step: 900, loss: 0.026004668325185776
step: 910, loss: 0.027953848242759705
step: 920, loss: 0.08414668589830399
step: 930, loss: 0.015831107273697853
step: 940, loss: 0.07643711566925049
step: 950, loss: 0.1667749583721161
step: 960, loss: 0.1551882028579712
step: 970, loss: 0.01899091526865959
step: 980, loss: 0.05035682022571564
step: 990, loss: 0.11452897638082504
step: 1000, loss: 0.1776500791311264
step: 1010, loss: 0.07090940326452255
step: 1020, loss: 0.0912686213850975
step: 1030, loss: 0.010073859244585037
step: 1040, loss: 0.046382468193769455
step: 1050, loss: 0.15187835693359375
step: 1060, loss: 0.08320600539445877
step: 1070, loss: 0.0359584204852581
epoch 3: dev_f1=0.9322033898305084, f1=0.9285051067780873, best_f1=0.9325894932589495
step: 0, loss: 0.07185349613428116
step: 10, loss: 0.06711427867412567
step: 20, loss: 0.04880005121231079
step: 30, loss: 0.017052285373210907
step: 40, loss: 0.07746890187263489
step: 50, loss: 0.04096581041812897
step: 60, loss: 0.025714542716741562
step: 70, loss: 0.07143551111221313
step: 80, loss: 0.07819457352161407
step: 90, loss: 0.03863389045000076
step: 100, loss: 0.029760997742414474
step: 110, loss: 0.02850360795855522
step: 120, loss: 0.13080279529094696
step: 130, loss: 0.011361608281731606
step: 140, loss: 0.09170781821012497
step: 150, loss: 0.14815688133239746
step: 160, loss: 0.1119479164481163
step: 170, loss: 0.14987246692180634
step: 180, loss: 0.03949793800711632
step: 190, loss: 0.02283259481191635
step: 200, loss: 0.029280247166752815
step: 210, loss: 0.03206239268183708
step: 220, loss: 0.08730348199605942
step: 230, loss: 0.12313763797283173
step: 240, loss: 0.052135780453681946
step: 250, loss: 0.03986654803156853
step: 260, loss: 0.08660729974508286
step: 270, loss: 0.052961427718400955
step: 280, loss: 0.022167271003127098
step: 290, loss: 0.1302081048488617
step: 300, loss: 0.05528104305267334
step: 310, loss: 0.041100505739450455
step: 320, loss: 0.09474978595972061
step: 330, loss: 0.013512558303773403
step: 340, loss: 0.02355491742491722
step: 350, loss: 0.007928142324090004
step: 360, loss: 0.10256464779376984
step: 370, loss: 0.05323134735226631
step: 380, loss: 0.2378561794757843
step: 390, loss: 0.1436341553926468
step: 400, loss: 0.024840645492076874
step: 410, loss: 0.045319437980651855
step: 420, loss: 0.034523844718933105
step: 430, loss: 0.13887955248355865
step: 440, loss: 0.012320851907134056
step: 450, loss: 0.018481314182281494
step: 460, loss: 0.04707643762230873
step: 470, loss: 0.08124393224716187
step: 480, loss: 0.16451936960220337
step: 490, loss: 0.016845108941197395
step: 500, loss: 0.03192245960235596
step: 510, loss: 0.025844087824225426
step: 520, loss: 0.05045218765735626
step: 530, loss: 0.022106055170297623
step: 540, loss: 0.20740075409412384
step: 550, loss: 0.08103738725185394
step: 560, loss: 0.07580399513244629
step: 570, loss: 0.08287063986063004
step: 580, loss: 0.15339457988739014
step: 590, loss: 0.013626706786453724
step: 600, loss: 0.09484422951936722
step: 610, loss: 0.1410609930753708
step: 620, loss: 0.06385617703199387
step: 630, loss: 0.016360942274332047
step: 640, loss: 0.0741267055273056
step: 650, loss: 0.2479441612958908
step: 660, loss: 0.05600580945611
step: 670, loss: 0.036205653101205826
step: 680, loss: 0.08561008423566818
step: 690, loss: 0.017084533348679543
step: 700, loss: 0.019221510738134384
step: 710, loss: 0.0658777505159378
step: 720, loss: 0.020735958591103554
step: 730, loss: 0.04219307750463486
step: 740, loss: 0.06761478632688522
step: 750, loss: 0.1284853219985962
step: 760, loss: 0.21017128229141235
step: 770, loss: 0.09417131543159485
step: 780, loss: 0.10500390082597733
step: 790, loss: 0.048020921647548676
step: 800, loss: 0.12458044290542603
step: 810, loss: 0.04648001492023468
step: 820, loss: 0.04299141839146614
step: 830, loss: 0.08444340527057648
step: 840, loss: 0.10215520113706589
step: 850, loss: 0.04686633124947548
step: 860, loss: 0.00038861966459080577
step: 870, loss: 0.0774756669998169
step: 880, loss: 0.06256507337093353
step: 890, loss: 0.07010973989963531
step: 900, loss: 0.07988850772380829
step: 910, loss: 0.024505693465471268
step: 920, loss: 0.04840794578194618
step: 930, loss: 0.038852911442518234
step: 940, loss: 0.11199124157428741
step: 950, loss: 0.0809156522154808
step: 960, loss: 0.12122873961925507
step: 970, loss: 0.16802172362804413
step: 980, loss: 0.141402930021286
step: 990, loss: 0.0681229755282402
step: 1000, loss: 0.11144841462373734
step: 1010, loss: 0.1281946748495102
step: 1020, loss: 0.1559968888759613
step: 1030, loss: 0.06365878134965897
step: 1040, loss: 0.03369743376970291
step: 1050, loss: 0.04188137501478195
step: 1060, loss: 0.015794934704899788
step: 1070, loss: 0.15907609462738037
epoch 4: dev_f1=0.9344490934449092, f1=0.9269195189639223, best_f1=0.9269195189639223
step: 0, loss: 0.013549826107919216
step: 10, loss: 0.0687800943851471
step: 20, loss: 0.06438208371400833
step: 30, loss: 0.07968424260616302
step: 40, loss: 0.1549742966890335
step: 50, loss: 0.022358356043696404
step: 60, loss: 0.006865187082439661
step: 70, loss: 0.019304662942886353
step: 80, loss: 0.06662895530462265
step: 90, loss: 0.1034642830491066
step: 100, loss: 0.026630336418747902
step: 110, loss: 0.060158759355545044
step: 120, loss: 0.07288368046283722
step: 130, loss: 0.06730508804321289
step: 140, loss: 0.06227507442235947
step: 150, loss: 0.08333900570869446
step: 160, loss: 0.2671094238758087
step: 170, loss: 0.08174178004264832
step: 180, loss: 0.00339656719006598
step: 190, loss: 0.03327857330441475
step: 200, loss: 0.07153421640396118
step: 210, loss: 0.06944362819194794
step: 220, loss: 0.06494873017072678
step: 230, loss: 0.07974620163440704
step: 240, loss: 0.028673503547906876
step: 250, loss: 0.006081285420805216
step: 260, loss: 0.4155750572681427
step: 270, loss: 0.1844022572040558
step: 280, loss: 0.06688955426216125
step: 290, loss: 0.012514717876911163
step: 300, loss: 0.10963816940784454
step: 310, loss: 0.026657378301024437
step: 320, loss: 0.00762192765250802
step: 330, loss: 0.02100428193807602
step: 340, loss: 0.001110278652049601
step: 350, loss: 0.0028707729652523994
step: 360, loss: 0.0351107120513916
step: 370, loss: 0.08704093098640442
step: 380, loss: 0.06569094955921173
step: 390, loss: 0.05500994622707367
step: 400, loss: 0.00024084150209091604
step: 410, loss: 0.10516060888767242
step: 420, loss: 0.05172896385192871
step: 430, loss: 0.04023953527212143
step: 440, loss: 0.07754319161176682
step: 450, loss: 0.05953294038772583
step: 460, loss: 0.1605951189994812
step: 470, loss: 0.010801553726196289
step: 480, loss: 0.04690153896808624
step: 490, loss: 0.02939341962337494
step: 500, loss: 0.09536240994930267
step: 510, loss: 0.08855877071619034
step: 520, loss: 0.01581227406859398
step: 530, loss: 0.00775937782600522
step: 540, loss: 0.0372793972492218
step: 550, loss: 0.20171980559825897
step: 560, loss: 0.07261524349451065
step: 570, loss: 0.04127742350101471
step: 580, loss: 0.048093006014823914
step: 590, loss: 0.01889152266085148
step: 600, loss: 0.14790023863315582
step: 610, loss: 0.08075699210166931
step: 620, loss: 0.028331520035862923
step: 630, loss: 0.1460823267698288
step: 640, loss: 0.13834860920906067
step: 650, loss: 0.03202167525887489
step: 660, loss: 0.0368451364338398
step: 670, loss: 0.026815373450517654
step: 680, loss: 0.05176601558923721
step: 690, loss: 0.022694293409585953
step: 700, loss: 0.10219132900238037
step: 710, loss: 0.10775326192378998
step: 720, loss: 0.1700969785451889
step: 730, loss: 0.01117908488959074
step: 740, loss: 0.09065134823322296
step: 750, loss: 0.024152524769306183
step: 760, loss: 0.003911539446562529
step: 770, loss: 0.08778559416532516
step: 780, loss: 0.04480268433690071
step: 790, loss: 0.05200299620628357
step: 800, loss: 0.05355055630207062
step: 810, loss: 0.05087088420987129
step: 820, loss: 0.05704670771956444
step: 830, loss: 0.21978291869163513
step: 840, loss: 0.06691206246614456
step: 850, loss: 0.02784506045281887
step: 860, loss: 0.02991815283894539
step: 870, loss: 0.085507333278656
step: 880, loss: 0.15516942739486694
step: 890, loss: 0.031029995530843735
step: 900, loss: 0.14551956951618195
step: 910, loss: 0.1541343629360199
step: 920, loss: 0.08007510751485825
step: 930, loss: 0.03352665901184082
step: 940, loss: 0.008281268179416656
step: 950, loss: 0.03818266838788986
step: 960, loss: 0.10110548883676529
step: 970, loss: 0.06237656623125076
step: 980, loss: 0.008098693564534187
step: 990, loss: 0.0491904690861702
step: 1000, loss: 0.09833395481109619
step: 1010, loss: 0.07073687016963959
step: 1020, loss: 0.11614403128623962
step: 1030, loss: 0.11138927936553955
step: 1040, loss: 0.12532587349414825
step: 1050, loss: 0.040083177387714386
step: 1060, loss: 0.07131122052669525
step: 1070, loss: 0.18062658607959747
epoch 5: dev_f1=0.9400749063670412, f1=0.935831381733021, best_f1=0.935831381733021
step: 0, loss: 0.016511229798197746
step: 10, loss: 0.05017760396003723
step: 20, loss: 0.04498448595404625
step: 30, loss: 0.00648106774315238
step: 40, loss: 0.005620998330414295
step: 50, loss: 0.007252193987369537
step: 60, loss: 0.01277807354927063
step: 70, loss: 0.009547807276248932
step: 80, loss: 0.10791178792715073
step: 90, loss: 0.1541406512260437
step: 100, loss: 0.029017388820648193
step: 110, loss: 0.09634178876876831
step: 120, loss: 0.009439763613045216
step: 130, loss: 0.03541235998272896
step: 140, loss: 0.04022793099284172
step: 150, loss: 0.08045656979084015
step: 160, loss: 0.11033672839403152
step: 170, loss: 0.031555064022541046
step: 180, loss: 0.015339625999331474
step: 190, loss: 0.020859021693468094
step: 200, loss: 0.02283932827413082
step: 210, loss: 0.23574240505695343
step: 220, loss: 0.05728183314204216
step: 230, loss: 0.04263721778988838
step: 240, loss: 0.07955751568078995
step: 250, loss: 0.0844888910651207
step: 260, loss: 0.06052665412425995
step: 270, loss: 0.15926608443260193
step: 280, loss: 0.046197619289159775
step: 290, loss: 0.0630064457654953
step: 300, loss: 0.05750548094511032
step: 310, loss: 0.06988723576068878
step: 320, loss: 0.0427643321454525
step: 330, loss: 0.050093069672584534
step: 340, loss: 0.07026790827512741
step: 350, loss: 0.09536752849817276
step: 360, loss: 0.09878043085336685
step: 370, loss: 0.020390845835208893
step: 380, loss: 0.0655345544219017
step: 390, loss: 0.059836067259311676
step: 400, loss: 0.11951158940792084
step: 410, loss: 0.11839495599269867
step: 420, loss: 0.010615834034979343
step: 430, loss: 0.008242698386311531
step: 440, loss: 0.061268385499715805
step: 450, loss: 0.04227016493678093
step: 460, loss: 0.023008497431874275
step: 470, loss: 0.006325765512883663
step: 480, loss: 0.036245062947273254
step: 490, loss: 0.08022688329219818
step: 500, loss: 0.10593560338020325
step: 510, loss: 0.08238158375024796
step: 520, loss: 0.08517483621835709
step: 530, loss: 0.08050082623958588
step: 540, loss: 0.12644489109516144
step: 550, loss: 0.010325731709599495
step: 560, loss: 0.0227500069886446
step: 570, loss: 0.018442004919052124
step: 580, loss: 0.012154091149568558
step: 590, loss: 0.02172880619764328
step: 600, loss: 0.06522806733846664
step: 610, loss: 0.05505847930908203
step: 620, loss: 0.006453538313508034
step: 630, loss: 0.061466313898563385
step: 640, loss: 0.0303193386644125
step: 650, loss: 0.04129858687520027
step: 660, loss: 0.008925288915634155
step: 670, loss: 0.13125306367874146
step: 680, loss: 0.07023560255765915
step: 690, loss: 0.07768265157938004
step: 700, loss: 0.04356735944747925
step: 710, loss: 0.020076192915439606
step: 720, loss: 0.006772296968847513
step: 730, loss: 0.057610832154750824
step: 740, loss: 0.24721534550189972
step: 750, loss: 0.04764549434185028
step: 760, loss: 0.019130203872919083
step: 770, loss: 0.037994254380464554
step: 780, loss: 0.000537262880243361
step: 790, loss: 0.06831004470586777
step: 800, loss: 0.04988114535808563
step: 810, loss: 0.02813524752855301
step: 820, loss: 0.05178536847233772
step: 830, loss: 0.010431598871946335
step: 840, loss: 0.02453976310789585
step: 850, loss: 0.06046949699521065
step: 860, loss: 0.200415700674057
step: 870, loss: 0.014682571403682232
step: 880, loss: 0.00633942149579525
step: 890, loss: 0.04800209775567055
step: 900, loss: 0.009022575803101063
step: 910, loss: 0.002387954853475094
step: 920, loss: 0.06892901659011841
step: 930, loss: 0.13066180050373077
step: 940, loss: 0.19353167712688446
step: 950, loss: 0.026469986885786057
step: 960, loss: 0.03335067629814148
step: 970, loss: 0.03693818673491478
step: 980, loss: 0.022151261568069458
step: 990, loss: 0.09319225698709488
step: 1000, loss: 0.09647715091705322
step: 1010, loss: 0.10911431163549423
step: 1020, loss: 0.040079645812511444
step: 1030, loss: 0.06377249956130981
step: 1040, loss: 0.030446698889136314
step: 1050, loss: 0.054887112230062485
step: 1060, loss: 0.09043096750974655
step: 1070, loss: 0.08815653622150421
epoch 6: dev_f1=0.9425502101821578, f1=0.9411764705882353, best_f1=0.9411764705882353
step: 0, loss: 0.0007213205681182444
step: 10, loss: 0.1386437863111496
step: 20, loss: 0.2986695468425751
step: 30, loss: 0.06230871379375458
step: 40, loss: 0.015728825703263283
step: 50, loss: 0.006063020322471857
step: 60, loss: 0.11047697067260742
step: 70, loss: 0.0380278155207634
step: 80, loss: 0.07365820556879044
step: 90, loss: 0.07811330258846283
step: 100, loss: 0.0001479679485782981
step: 110, loss: 0.07756559550762177
step: 120, loss: 0.09919849783182144
step: 130, loss: 0.046042025089263916
step: 140, loss: 0.003477575955912471
step: 150, loss: 0.0026387504767626524
step: 160, loss: 0.059389859437942505
step: 170, loss: 0.012139259837567806
step: 180, loss: 0.12199056148529053
step: 190, loss: 0.09484028816223145
step: 200, loss: 0.08096874505281448
step: 210, loss: 0.04571259766817093
step: 220, loss: 0.0537596121430397
step: 230, loss: 0.024031197652220726
step: 240, loss: 0.0027626939117908478
step: 250, loss: 0.0006328515592031181
step: 260, loss: 0.08449031412601471
step: 270, loss: 0.04002793878316879
step: 280, loss: 0.1175888255238533
step: 290, loss: 0.04889069125056267
step: 300, loss: 0.023968640714883804
step: 310, loss: 0.01845473051071167
step: 320, loss: 0.04037022963166237
step: 330, loss: 0.0270854402333498
step: 340, loss: 0.009022099897265434
step: 350, loss: 0.0480714812874794
step: 360, loss: 0.025821173563599586
step: 370, loss: 0.01040766853839159
step: 380, loss: 0.11766130477190018
step: 390, loss: 0.030948247760534286
step: 400, loss: 0.03605955094099045
step: 410, loss: 0.0008170893997885287
step: 420, loss: 0.0001690547651378438
step: 430, loss: 0.031599756330251694
step: 440, loss: 0.05454963818192482
step: 450, loss: 0.07003294676542282
step: 460, loss: 0.021577084437012672
step: 470, loss: 0.10189878940582275
step: 480, loss: 0.02887994609773159
step: 490, loss: 0.038161374628543854
step: 500, loss: 0.033146459609270096
step: 510, loss: 0.02387547492980957
step: 520, loss: 0.05552000552415848
step: 530, loss: 0.24579982459545135
step: 540, loss: 0.026855196803808212
step: 550, loss: 0.023637570440769196
step: 560, loss: 0.03188686817884445
step: 570, loss: 0.01795586571097374
step: 580, loss: 0.08361432701349258
step: 590, loss: 0.07228869199752808
step: 600, loss: 0.062392640858888626
step: 610, loss: 0.04789959639310837
step: 620, loss: 0.06190088763833046
step: 630, loss: 0.07778050750494003
step: 640, loss: 0.006915797479450703
step: 650, loss: 0.04813471436500549
step: 660, loss: 0.005247755907475948
step: 670, loss: 0.08906519412994385
step: 680, loss: 0.06962411850690842
step: 690, loss: 0.08297384530305862
step: 700, loss: 0.1887878179550171
step: 710, loss: 0.04424234852194786
step: 720, loss: 0.14903894066810608
step: 730, loss: 0.01612420566380024
step: 740, loss: 0.08171519637107849
step: 750, loss: 0.08065123111009598
step: 760, loss: 0.0004086791886948049
step: 770, loss: 0.1360471397638321
step: 780, loss: 0.0022628502920269966
step: 790, loss: 0.029529647901654243
step: 800, loss: 0.020062202587723732
step: 810, loss: 0.07874156534671783
step: 820, loss: 0.07949062436819077
step: 830, loss: 0.06641444563865662
step: 840, loss: 0.03740689158439636
step: 850, loss: 0.009209809824824333
step: 860, loss: 0.016453932970762253
step: 870, loss: 0.01814456656575203
step: 880, loss: 0.20560114085674286
step: 890, loss: 0.097226582467556
step: 900, loss: 0.014692381024360657
step: 910, loss: 0.044119738042354584
step: 920, loss: 0.0064492421224713326
step: 930, loss: 0.0011801260989159346
step: 940, loss: 0.06333138793706894
step: 950, loss: 0.04012562334537506
step: 960, loss: 0.012002535164356232
step: 970, loss: 0.15258659422397614
step: 980, loss: 0.09026981145143509
step: 990, loss: 0.012346562929451466
step: 1000, loss: 0.07094756513834
step: 1010, loss: 0.028019431978464127
step: 1020, loss: 0.09974890202283859
step: 1030, loss: 0.1990281045436859
step: 1040, loss: 0.09342227876186371
step: 1050, loss: 0.12172861397266388
step: 1060, loss: 0.07922722399234772
step: 1070, loss: 0.10413553565740585
epoch 7: dev_f1=0.9351127473538886, f1=0.9333945796968306, best_f1=0.9411764705882353
step: 0, loss: 0.06803818047046661
step: 10, loss: 0.017130836844444275
step: 20, loss: 0.10465916991233826
step: 30, loss: 0.05436386540532112
step: 40, loss: 0.06304251402616501
step: 50, loss: 0.0424758642911911
step: 60, loss: 0.1390582025051117
step: 70, loss: 0.048589933663606644
step: 80, loss: 0.05223080515861511
step: 90, loss: 0.06749152392148972
step: 100, loss: 0.04672323539853096
step: 110, loss: 0.014709684997797012
step: 120, loss: 0.05243804678320885
step: 130, loss: 0.0008236455032601953
step: 140, loss: 0.09768353402614594
step: 150, loss: 0.01987149938941002
step: 160, loss: 0.02538985386490822
step: 170, loss: 0.006523411720991135
step: 180, loss: 0.006986798718571663
step: 190, loss: 0.014291806146502495
step: 200, loss: 0.006333912722766399
step: 210, loss: 0.05961454287171364
step: 220, loss: 0.041152697056531906
step: 230, loss: 0.039971306920051575
step: 240, loss: 0.0207015722990036
step: 250, loss: 0.013374760746955872
step: 260, loss: 0.09408466517925262
step: 270, loss: 0.0628315880894661
step: 280, loss: 0.0020560589618980885
step: 290, loss: 0.05034208670258522
step: 300, loss: 0.00796560663729906
step: 310, loss: 0.06876829266548157
step: 320, loss: 0.01217779889702797
step: 330, loss: 0.030438639223575592
step: 340, loss: 0.060454972088336945
step: 350, loss: 0.03772222623229027
step: 360, loss: 0.0027411223854869604
step: 370, loss: 0.09983890503644943
step: 380, loss: 0.03138751909136772
step: 390, loss: 0.003411762183532119
step: 400, loss: 0.012160980142652988
step: 410, loss: 0.07852880656719208
step: 420, loss: 0.013666678220033646
step: 430, loss: 0.13961535692214966
step: 440, loss: 0.09488482773303986
step: 450, loss: 0.030353523790836334
step: 460, loss: 0.04187987744808197
step: 470, loss: 0.02291424199938774
step: 480, loss: 0.011343618854880333
step: 490, loss: 0.07900682091712952
step: 500, loss: 0.0641244426369667
step: 510, loss: 0.009007250890135765
step: 520, loss: 0.05353334918618202
step: 530, loss: 0.008059368468821049
step: 540, loss: 0.09699827432632446
step: 550, loss: 0.013708680868148804
step: 560, loss: 0.009516939520835876
step: 570, loss: 0.04726357012987137
step: 580, loss: 0.005899591371417046
step: 590, loss: 0.020229918882250786
step: 600, loss: 0.09278854727745056
step: 610, loss: 0.06404630094766617
step: 620, loss: 0.06596796959638596
step: 630, loss: 0.06371743232011795
step: 640, loss: 0.014158437959849834
step: 650, loss: 0.043062545359134674
step: 660, loss: 0.06264354288578033
step: 670, loss: 0.029180124402046204
step: 680, loss: 0.004600659944117069
step: 690, loss: 0.07085952162742615
step: 700, loss: 0.008326523937284946
step: 710, loss: 0.0827643945813179
step: 720, loss: 0.019265029579401016
step: 730, loss: 0.045519791543483734
step: 740, loss: 0.02276545763015747
step: 750, loss: 0.028511757031083107
step: 760, loss: 0.002390009816735983
step: 770, loss: 0.005429867189377546
step: 780, loss: 0.055760763585567474
step: 790, loss: 0.029994653537869453
step: 800, loss: 0.004423006437718868
step: 810, loss: 0.04951264336705208
step: 820, loss: 0.10195519775152206
step: 830, loss: 0.09262978285551071
step: 840, loss: 0.017099928110837936
step: 850, loss: 0.09151038527488708
step: 860, loss: 0.10438473522663116
step: 870, loss: 0.018504710868000984
step: 880, loss: 0.012371157296001911
step: 890, loss: 0.09132514894008636
step: 900, loss: 0.023167438805103302
step: 910, loss: 0.03711952269077301
step: 920, loss: 0.06975485384464264
step: 930, loss: 0.024399083107709885
step: 940, loss: 0.09280849993228912
step: 950, loss: 0.03144945204257965
step: 960, loss: 0.04086390510201454
step: 970, loss: 0.08173508942127228
step: 980, loss: 0.05197719484567642
step: 990, loss: 0.03039238601922989
step: 1000, loss: 0.08682787418365479
step: 1010, loss: 0.004019722808152437
step: 1020, loss: 0.012153438292443752
step: 1030, loss: 0.04923880100250244
step: 1040, loss: 0.005499077029526234
step: 1050, loss: 0.035328928381204605
step: 1060, loss: 0.03984773904085159
step: 1070, loss: 0.06780266761779785
epoch 8: dev_f1=0.932274638019617, f1=0.9326521133302369, best_f1=0.9411764705882353
step: 0, loss: 0.034875594079494476
step: 10, loss: 0.03729460760951042
step: 20, loss: 0.08270761370658875
step: 30, loss: 0.10067255049943924
step: 40, loss: 0.017306920140981674
step: 50, loss: 0.029923291876912117
step: 60, loss: 0.024218643084168434
step: 70, loss: 0.06402681022882462
step: 80, loss: 0.07568608224391937
step: 90, loss: 0.04260767996311188
step: 100, loss: 0.04435435310006142
step: 110, loss: 0.004365095868706703
step: 120, loss: 0.007568450644612312
step: 130, loss: 0.0033051050268113613
step: 140, loss: 0.0031282175332307816
step: 150, loss: 0.023598328232765198
step: 160, loss: 0.0666411966085434
step: 170, loss: 0.0392904058098793
step: 180, loss: 0.15884988009929657
step: 190, loss: 0.05197092145681381
step: 200, loss: 0.016202934086322784
step: 210, loss: 0.05723913758993149
step: 220, loss: 0.09320848435163498
step: 230, loss: 0.04149774834513664
step: 240, loss: 0.06306556612253189
step: 250, loss: 0.002532088663429022
step: 260, loss: 0.009701164439320564
step: 270, loss: 0.002595358295366168
step: 280, loss: 0.0914013609290123
step: 290, loss: 0.019610660150647163
step: 300, loss: 0.04970439895987511
step: 310, loss: 0.020688481628894806
step: 320, loss: 0.11504542827606201
step: 330, loss: 0.11138381063938141
step: 340, loss: 0.12624198198318481
step: 350, loss: 0.06621161848306656
step: 360, loss: 0.0014428268186748028
step: 370, loss: 0.002805030904710293
step: 380, loss: 0.020435411483049393
step: 390, loss: 0.08289776742458344
step: 400, loss: 0.05950145795941353
step: 410, loss: 0.03625478222966194
step: 420, loss: 0.1134951040148735
step: 430, loss: 0.03769121691584587
step: 440, loss: 0.1506265550851822
step: 450, loss: 0.009396030567586422
step: 460, loss: 0.03845570236444473
step: 470, loss: 0.03951169550418854
step: 480, loss: 0.06374259293079376
step: 490, loss: 0.009608794935047626
step: 500, loss: 0.03862489387392998
step: 510, loss: 0.041205067187547684
step: 520, loss: 0.04756684973835945
step: 530, loss: 0.05679599195718765
step: 540, loss: 0.10329977422952652
step: 550, loss: 0.011955168098211288
step: 560, loss: 0.04297816380858421
step: 570, loss: 0.06592156738042831
step: 580, loss: 0.01929629221558571
step: 590, loss: 0.010568511672317982
step: 600, loss: 0.027962207794189453
step: 610, loss: 0.0008853939361870289
step: 620, loss: 0.05043329671025276
step: 630, loss: 0.03952891752123833
step: 640, loss: 0.0008506919257342815
step: 650, loss: 0.0414004810154438
step: 660, loss: 0.11916499584913254
step: 670, loss: 0.019336774945259094
step: 680, loss: 0.07113692164421082
step: 690, loss: 0.10123304277658463
step: 700, loss: 0.013019570149481297
step: 710, loss: 0.011427238583564758
step: 720, loss: 0.05357690155506134
step: 730, loss: 0.042386725544929504
step: 740, loss: 0.05180280655622482
step: 750, loss: 0.07096797972917557
step: 760, loss: 0.0726127177476883
step: 770, loss: 0.06915067881345749
step: 780, loss: 0.07359091937541962
step: 790, loss: 0.10906659066677094
step: 800, loss: 0.0665755569934845
step: 810, loss: 0.08520041406154633
step: 820, loss: 0.047804612666368484
step: 830, loss: 0.08368383347988129
step: 840, loss: 0.008929344825446606
step: 850, loss: 0.07533173263072968
step: 860, loss: 0.11242576688528061
step: 870, loss: 0.018135791644454002
step: 880, loss: 0.03973890095949173
step: 890, loss: 0.0017247007926926017
step: 900, loss: 0.07883154600858688
step: 910, loss: 0.030369434505701065
step: 920, loss: 0.12036611139774323
step: 930, loss: 0.000785333220846951
step: 940, loss: 0.04373091831803322
step: 950, loss: 0.008605200797319412
step: 960, loss: 0.00926954299211502
step: 970, loss: 0.011066818609833717
step: 980, loss: 0.027502059936523438
step: 990, loss: 0.050800688564777374
step: 1000, loss: 0.10226426273584366
step: 1010, loss: 0.05643835663795471
step: 1020, loss: 0.026492144912481308
step: 1030, loss: 0.0434703528881073
step: 1040, loss: 0.0266338549554348
step: 1050, loss: 0.11590125411748886
step: 1060, loss: 0.04998350888490677
step: 1070, loss: 0.026330655440688133
epoch 9: dev_f1=0.9394221808014911, f1=0.9350046425255338, best_f1=0.9411764705882353
step: 0, loss: 0.00530266622081399
step: 10, loss: 0.04646105691790581
step: 20, loss: 0.12067851424217224
step: 30, loss: 0.0010210321051999927
step: 40, loss: 0.0033514322713017464
step: 50, loss: 0.06434153765439987
step: 60, loss: 0.030162129551172256
step: 70, loss: 0.0003354827349539846
step: 80, loss: 0.01206060778349638
step: 90, loss: 0.09803028404712677
step: 100, loss: 0.016647711396217346
step: 110, loss: 0.15744629502296448
step: 120, loss: 0.013035504147410393
step: 130, loss: 0.052521996200084686
step: 140, loss: 0.02586367540061474
step: 150, loss: 0.08327746391296387
step: 160, loss: 0.02586580254137516
step: 170, loss: 0.02837241068482399
step: 180, loss: 0.15390239655971527
step: 190, loss: 0.07701292634010315
step: 200, loss: 0.0730191022157669
step: 210, loss: 0.04464595392346382
step: 220, loss: 0.064628466963768
step: 230, loss: 0.03631317615509033
step: 240, loss: 0.020759548991918564
step: 250, loss: 0.04049757495522499
step: 260, loss: 0.04098358377814293
step: 270, loss: 0.0730907991528511
step: 280, loss: 0.015134807676076889
step: 290, loss: 0.07315260171890259
step: 300, loss: 0.0005105205345898867
step: 310, loss: 0.08732135593891144
step: 320, loss: 0.04561716318130493
step: 330, loss: 0.036311835050582886
step: 340, loss: 0.08591457456350327
step: 350, loss: 0.022345103323459625
step: 360, loss: 0.11005877703428268
step: 370, loss: 0.0063447062857449055
step: 380, loss: 0.02432757243514061
step: 390, loss: 0.009698674082756042
step: 400, loss: 0.007870377972722054
step: 410, loss: 0.007088279351592064
step: 420, loss: 0.14592896401882172
step: 430, loss: 0.050168536603450775
step: 440, loss: 0.04161553084850311
step: 450, loss: 0.01656375825405121
step: 460, loss: 0.0766477882862091
step: 470, loss: 0.01742783933877945
step: 480, loss: 0.07931545376777649
step: 490, loss: 0.09639342129230499
step: 500, loss: 0.050710756331682205
step: 510, loss: 0.0033535445109009743
step: 520, loss: 0.05629861727356911
step: 530, loss: 0.00012317935761529952
step: 540, loss: 0.003788270289078355
step: 550, loss: 0.03731253743171692
step: 560, loss: 0.04579678922891617
step: 570, loss: 0.11512438207864761
step: 580, loss: 0.062492597848176956
step: 590, loss: 0.14334723353385925
step: 600, loss: 0.08451954275369644
step: 610, loss: 0.07147454470396042
step: 620, loss: 0.01430140808224678
step: 630, loss: 0.0021796002984046936
step: 640, loss: 0.06795720010995865
step: 650, loss: 0.03814644739031792
step: 660, loss: 0.11871081590652466
step: 670, loss: 0.047091152518987656
step: 680, loss: 0.03840996325016022
step: 690, loss: 0.161670982837677
step: 700, loss: 0.008211218751966953
step: 710, loss: 0.03021404705941677
step: 720, loss: 0.004780590068548918
step: 730, loss: 0.10362908989191055
step: 740, loss: 0.04867729917168617
step: 750, loss: 0.04781872034072876
step: 760, loss: 0.06944084912538528
step: 770, loss: 0.03391695395112038
step: 780, loss: 0.0897110104560852
step: 790, loss: 0.13487805426120758
step: 800, loss: 0.17137499153614044
step: 810, loss: 0.02905970998108387
step: 820, loss: 0.03764678165316582
step: 830, loss: 0.032976336777210236
step: 840, loss: 0.048250023275613785
step: 850, loss: 0.0026378671173006296
step: 860, loss: 0.06998244673013687
step: 870, loss: 0.01921529322862625
step: 880, loss: 0.0982295572757721
step: 890, loss: 0.030468225479125977
step: 900, loss: 0.07672715932130814
step: 910, loss: 0.04914676770567894
step: 920, loss: 0.07641994208097458
step: 930, loss: 0.03093658946454525
step: 940, loss: 0.13354921340942383
step: 950, loss: 0.019944824278354645
step: 960, loss: 0.008007586002349854
step: 970, loss: 0.0142495883628726
step: 980, loss: 0.054727062582969666
step: 990, loss: 0.048978909850120544
step: 1000, loss: 0.019199850037693977
step: 1010, loss: 0.007490299642086029
step: 1020, loss: 0.05473927780985832
step: 1030, loss: 0.021727045997977257
step: 1040, loss: 0.17467230558395386
step: 1050, loss: 0.00039889290928840637
step: 1060, loss: 0.01639043353497982
step: 1070, loss: 0.06230657547712326
epoch 10: dev_f1=0.9383624655013799, f1=0.9354099862574439, best_f1=0.9411764705882353
step: 0, loss: 0.00900106318295002
step: 10, loss: 0.017725927755236626
step: 20, loss: 0.015976838767528534
step: 30, loss: 0.03490384668111801
step: 40, loss: 0.014055786654353142
step: 50, loss: 0.030080437660217285
step: 60, loss: 0.03684030845761299
step: 70, loss: 0.0025900760665535927
step: 80, loss: 0.0925540030002594
step: 90, loss: 0.06182311847805977
step: 100, loss: 0.0008625569753348827
step: 110, loss: 0.016763737425208092
step: 120, loss: 0.14023268222808838
step: 130, loss: 0.011422095820307732
step: 140, loss: 0.08955524861812592
step: 150, loss: 0.05890022963285446
step: 160, loss: 0.03977184370160103
step: 170, loss: 0.005411098711192608
step: 180, loss: 0.004350793547928333
step: 190, loss: 0.01895381696522236
step: 200, loss: 0.004585285671055317
step: 210, loss: 0.0022564721293747425
step: 220, loss: 0.0009429965284653008
step: 230, loss: 0.038844894617795944
step: 240, loss: 0.04194347560405731
step: 250, loss: 0.04058064520359039
step: 260, loss: 0.06796886026859283
step: 270, loss: 0.08925111591815948
step: 280, loss: 0.027003105729818344
step: 290, loss: 0.028621403500437737
step: 300, loss: 0.04503065347671509
step: 310, loss: 0.004760741721838713
step: 320, loss: 0.08113270998001099
step: 330, loss: 0.018415605649352074
step: 340, loss: 0.10461780428886414
step: 350, loss: 0.03801789879798889
step: 360, loss: 0.05273420363664627
step: 370, loss: 0.04972220957279205
step: 380, loss: 4.9885831685969606e-05
step: 390, loss: 0.04278566688299179
step: 400, loss: 0.10425635427236557
step: 410, loss: 0.0053320773877203465
step: 420, loss: 0.0013413667911663651
step: 430, loss: 0.08772195130586624
step: 440, loss: 0.005207219626754522
step: 450, loss: 0.0012564891949295998
step: 460, loss: 0.0066526224836707115
step: 470, loss: 0.06796929240226746
step: 480, loss: 0.0028268140740692616
step: 490, loss: 0.1866067349910736
step: 500, loss: 0.04080648720264435
step: 510, loss: 0.023548517376184464
step: 520, loss: 0.019912172108888626
step: 530, loss: 0.0011176549596711993
step: 540, loss: 0.022639617323875427
step: 550, loss: 0.11524911969900131
step: 560, loss: 0.018376192077994347
step: 570, loss: 0.05074966698884964
step: 580, loss: 0.018572211265563965
step: 590, loss: 0.0870070829987526
step: 600, loss: 9.960384340956807e-05
step: 610, loss: 0.0002241289766971022
step: 620, loss: 0.048998840153217316
step: 630, loss: 0.005175883416086435
step: 640, loss: 0.04362126439809799
step: 650, loss: 0.13384726643562317
step: 660, loss: 0.0033670691773295403
step: 670, loss: 0.048123836517333984
step: 680, loss: 0.06564417481422424
step: 690, loss: 0.1112736389040947
step: 700, loss: 0.00820802990347147
step: 710, loss: 0.028534207493066788
step: 720, loss: 0.19339443743228912
step: 730, loss: 0.004649066366255283
step: 740, loss: 0.047897856682538986
step: 750, loss: 0.04939420148730278
step: 760, loss: 0.005484416149556637
step: 770, loss: 0.027464136481285095
step: 780, loss: 0.08874484896659851
step: 790, loss: 2.0801058781216852e-05
step: 800, loss: 0.06801536679267883
step: 810, loss: 0.05025104433298111
step: 820, loss: 0.024407029151916504
step: 830, loss: 0.0013396310387179255
step: 840, loss: 0.028895024210214615
step: 850, loss: 0.04333069548010826
step: 860, loss: 0.07874426245689392
step: 870, loss: 0.0919790118932724
step: 880, loss: 0.005198338069021702
step: 890, loss: 0.1651563048362732
step: 900, loss: 0.05254258215427399
step: 910, loss: 0.055571261793375015
step: 920, loss: 0.0015542415203526616
step: 930, loss: 0.04018978402018547
step: 940, loss: 0.06655637919902802
step: 950, loss: 0.05396454036235809
step: 960, loss: 0.0456157885491848
step: 970, loss: 0.09055416285991669
step: 980, loss: 0.10780266672372818
step: 990, loss: 0.001405340968631208
step: 1000, loss: 0.11849484592676163
step: 1010, loss: 0.07390224188566208
step: 1020, loss: 0.011979658156633377
step: 1030, loss: 0.025347940623760223
step: 1040, loss: 0.05212140455842018
step: 1050, loss: 0.09837410598993301
step: 1060, loss: 0.03973463922739029
step: 1070, loss: 0.11036841571331024
epoch 11: dev_f1=0.9377901578458682, f1=0.9334557136301056, best_f1=0.9411764705882353
step: 0, loss: 0.11673819273710251
step: 10, loss: 0.000386766652809456
step: 20, loss: 0.032407909631729126
step: 30, loss: 0.04017404466867447
step: 40, loss: 0.015611431561410427
step: 50, loss: 0.005614343099296093
step: 60, loss: 0.028214741498231888
step: 70, loss: 0.02655336819589138
step: 80, loss: 0.07827936112880707
step: 90, loss: 0.0066367220133543015
step: 100, loss: 0.015034778043627739
step: 110, loss: 0.030233923345804214
step: 120, loss: 0.05145698040723801
step: 130, loss: 0.03099934570491314
step: 140, loss: 0.05343373119831085
step: 150, loss: 0.03986746817827225
step: 160, loss: 0.030472755432128906
step: 170, loss: 0.0077173784375190735
step: 180, loss: 0.026559680700302124
step: 190, loss: 0.002039441140368581
step: 200, loss: 0.08013243973255157
step: 210, loss: 0.0345514751970768
step: 220, loss: 0.051086124032735825
step: 230, loss: 0.08462629467248917
step: 240, loss: 0.03115001507103443
step: 250, loss: 0.03942782059311867
step: 260, loss: 0.014045952819287777
step: 270, loss: 0.11423229426145554
step: 280, loss: 0.09016638249158859
step: 290, loss: 0.04700397327542305
step: 300, loss: 0.0016366814961656928
step: 310, loss: 0.10645445436239243
step: 320, loss: 0.028121434152126312
step: 330, loss: 0.02495826780796051
step: 340, loss: 0.03461017087101936
step: 350, loss: 0.02326062321662903
step: 360, loss: 0.02252405881881714
step: 370, loss: 0.00271690939553082
step: 380, loss: 0.1477750688791275
step: 390, loss: 0.0968705266714096
step: 400, loss: 0.040741171687841415
step: 410, loss: 0.035564593970775604
step: 420, loss: 0.020479639992117882
step: 430, loss: 0.0592292919754982
step: 440, loss: 0.02063269540667534
step: 450, loss: 0.011105930432677269
step: 460, loss: 0.07094564288854599
step: 470, loss: 0.012365353293716908
step: 480, loss: 0.12240579724311829
step: 490, loss: 0.027877572923898697
step: 500, loss: 0.012143413536250591
step: 510, loss: 0.005258073564618826
step: 520, loss: 0.00410812720656395
step: 530, loss: 0.003470473689958453
step: 540, loss: 0.026076428592205048
step: 550, loss: 0.022340673953294754
step: 560, loss: 0.04756804555654526
step: 570, loss: 0.014371342957019806
step: 580, loss: 0.016187408939003944
step: 590, loss: 0.06411025673151016
step: 600, loss: 0.015274511650204659
step: 610, loss: 0.02879682369530201
step: 620, loss: 0.008079972118139267
step: 630, loss: 0.17769038677215576
step: 640, loss: 0.019413890317082405
step: 650, loss: 0.05561616271734238
step: 660, loss: 0.010126041248440742
step: 670, loss: 0.005911421962082386
step: 680, loss: 0.010633624158799648
step: 690, loss: 0.05311112478375435
step: 700, loss: 7.2673057729844e-05
step: 710, loss: 0.020316189154982567
step: 720, loss: 0.0018610866973176599
step: 730, loss: 0.00010062487126560882
step: 740, loss: 0.00891127809882164
step: 750, loss: 0.1354818493127823
step: 760, loss: 0.026168355718255043
step: 770, loss: 0.03506162390112877
step: 780, loss: 0.08314287662506104
step: 790, loss: 0.0004004717629868537
step: 800, loss: 0.03339358791708946
step: 810, loss: 0.0009892391972243786
step: 820, loss: 0.029980473220348358
step: 830, loss: 0.0022778671700507402
step: 840, loss: 0.08882130682468414
step: 850, loss: 0.023838678374886513
step: 860, loss: 0.008255120366811752
step: 870, loss: 0.00816415622830391
step: 880, loss: 0.002079700818285346
step: 890, loss: 0.007513793185353279
step: 900, loss: 0.034956738352775574
step: 910, loss: 0.14081299304962158
step: 920, loss: 0.00014800381904933602
step: 930, loss: 0.061654508113861084
step: 940, loss: 0.025533918291330338
step: 950, loss: 0.016200261190533638
step: 960, loss: 0.07145047187805176
step: 970, loss: 0.0010981374653056264
step: 980, loss: 0.0020072627812623978
step: 990, loss: 0.011685245670378208
step: 1000, loss: 0.04936455562710762
step: 1010, loss: 0.010983049869537354
step: 1020, loss: 0.2373819500207901
step: 1030, loss: 0.031341783702373505
step: 1040, loss: 0.07096943259239197
step: 1050, loss: 0.0019280973356217146
step: 1060, loss: 0.06485344469547272
step: 1070, loss: 0.01167934201657772
epoch 12: dev_f1=0.9337626494940202, f1=0.9225894069714802, best_f1=0.9411764705882353
step: 0, loss: 0.037340711802244186
step: 10, loss: 0.0030491796787828207
step: 20, loss: 0.038634832948446274
step: 30, loss: 0.00579878780990839
step: 40, loss: 0.04533553868532181
step: 50, loss: 0.013362389989197254
step: 60, loss: 0.020809898152947426
step: 70, loss: 0.005863849073648453
step: 80, loss: 0.10525383800268173
step: 90, loss: 0.07317423075437546
step: 100, loss: 0.01281301025301218
step: 110, loss: 0.00040706034633331
step: 120, loss: 0.000348154513631016
step: 130, loss: 0.03790934383869171
step: 140, loss: 0.038824841380119324
step: 150, loss: 0.036988597363233566
step: 160, loss: 0.0004887758987024426
step: 170, loss: 0.20444008708000183
step: 180, loss: 0.05011206865310669
step: 190, loss: 0.0725136548280716
step: 200, loss: 0.07085254788398743
step: 210, loss: 0.0008443390252068639
step: 220, loss: 0.0004596085345838219
step: 230, loss: 5.639364826492965e-05
step: 240, loss: 0.001793605275452137
step: 250, loss: 0.001139686442911625
step: 260, loss: 0.05082903057336807
step: 270, loss: 0.02465665712952614
step: 280, loss: 0.06973021477460861
step: 290, loss: 0.032104697078466415
step: 300, loss: 0.024323824793100357
step: 310, loss: 0.07046934962272644
step: 320, loss: 0.02107979916036129
step: 330, loss: 0.01968495547771454
step: 340, loss: 0.028159640729427338
step: 350, loss: 0.04091262444853783
step: 360, loss: 0.08848059177398682
step: 370, loss: 0.003960487898439169
step: 380, loss: 0.022257249802350998
step: 390, loss: 0.0086286049336195
step: 400, loss: 0.04009325057268143
step: 410, loss: 0.04825185239315033
step: 420, loss: 0.03497253730893135
step: 430, loss: 0.02726440131664276
step: 440, loss: 0.06060697138309479
step: 450, loss: 0.019618375226855278
step: 460, loss: 0.11350776255130768
step: 470, loss: 0.05361764132976532
step: 480, loss: 0.0015328656882047653
step: 490, loss: 0.10295476764440536
step: 500, loss: 0.04145730286836624
step: 510, loss: 0.07700318098068237
step: 520, loss: 0.0061599756591022015
step: 530, loss: 0.03851841390132904
step: 540, loss: 0.06477905809879303
step: 550, loss: 0.04226791486144066
step: 560, loss: 0.0010389706585556269
step: 570, loss: 0.00042588042560964823
step: 580, loss: 0.042343251407146454
step: 590, loss: 0.028168149292469025
step: 600, loss: 0.035779595375061035
step: 610, loss: 0.08901295065879822
step: 620, loss: 0.005614445544779301
step: 630, loss: 0.04606947675347328
step: 640, loss: 0.05953435227274895
step: 650, loss: 0.0009224779787473381
step: 660, loss: 0.01613716594874859
step: 670, loss: 0.011440631002187729
step: 680, loss: 0.0009923159377649426
step: 690, loss: 0.00010174108319915831
step: 700, loss: 0.013270012103021145
step: 710, loss: 0.03467843681573868
step: 720, loss: 0.03330050781369209
step: 730, loss: 0.0008715943549759686
step: 740, loss: 0.016405349597334862
step: 750, loss: 0.030010569840669632
step: 760, loss: 0.015302096493542194
step: 770, loss: 0.015237859450280666
step: 780, loss: 0.09253983199596405
step: 790, loss: 0.057596974074840546
step: 800, loss: 0.023208387196063995
step: 810, loss: 0.0706159919500351
step: 820, loss: 0.0001802529295673594
step: 830, loss: 0.07279537618160248
step: 840, loss: 0.05486362800002098
step: 850, loss: 0.024230750277638435
step: 860, loss: 0.03881023824214935
step: 870, loss: 0.023099644109606743
step: 880, loss: 0.005418462213128805
step: 890, loss: 0.09820037335157394
step: 900, loss: 0.16847778856754303
step: 910, loss: 0.027081705629825592
step: 920, loss: 1.2747693290293682e-05
step: 930, loss: 0.09418189525604248
step: 940, loss: 0.00016806824714876711
step: 950, loss: 0.0374046266078949
step: 960, loss: 0.00020609365310519934
step: 970, loss: 0.024053243920207024
step: 980, loss: 3.7500874896068126e-05
step: 990, loss: 0.0002937624230980873
step: 1000, loss: 0.034582145512104034
step: 1010, loss: 0.0005097083630971611
step: 1020, loss: 0.10770156234502792
step: 1030, loss: 0.00010035984450951219
step: 1040, loss: 0.06657570600509644
step: 1050, loss: 0.037333063781261444
step: 1060, loss: 0.02555762603878975
step: 1070, loss: 0.04144613444805145
epoch 13: dev_f1=0.9342403628117913, f1=0.923626619026351, best_f1=0.9411764705882353
step: 0, loss: 0.013654645532369614
step: 10, loss: 0.03883881866931915
step: 20, loss: 0.015569583512842655
step: 30, loss: 0.016383282840251923
step: 40, loss: 0.0029306148644536734
step: 50, loss: 0.04811408370733261
step: 60, loss: 0.10624881088733673
step: 70, loss: 0.05949201434850693
step: 80, loss: 0.05361368507146835
step: 90, loss: 0.0032513770274817944
step: 100, loss: 0.03955176845192909
step: 110, loss: 0.00011742464266717434
step: 120, loss: 0.014569311402738094
step: 130, loss: 0.012812608852982521
step: 140, loss: 0.00014558041584677994
step: 150, loss: 0.00011017965152859688
step: 160, loss: 0.03497924655675888
step: 170, loss: 0.025206100195646286
step: 180, loss: 0.027487315237522125
step: 190, loss: 0.03793301805853844
step: 200, loss: 0.022840188816189766
step: 210, loss: 0.07169273495674133
step: 220, loss: 0.07718223333358765
step: 230, loss: 0.014037547633051872
step: 240, loss: 0.028612999245524406
step: 250, loss: 0.0011321878992021084
step: 260, loss: 0.013083500787615776
step: 270, loss: 0.0021303482353687286
step: 280, loss: 0.0012249067658558488
step: 290, loss: 0.018834896385669708
step: 300, loss: 0.07344149798154831
step: 310, loss: 0.0001409022370353341
step: 320, loss: 0.01599719561636448
step: 330, loss: 0.01905202306807041
step: 340, loss: 0.027583526447415352
step: 350, loss: 0.016104543581604958
step: 360, loss: 0.028289003297686577
step: 370, loss: 0.14411242306232452
step: 380, loss: 0.00025028048548847437
step: 390, loss: 0.07869739830493927
step: 400, loss: 0.07522446662187576
step: 410, loss: 0.05734611675143242
step: 420, loss: 0.03885561600327492
step: 430, loss: 0.06370934098958969
step: 440, loss: 0.0014790792483836412
step: 450, loss: 0.0035437471233308315
step: 460, loss: 0.07439196854829788
step: 470, loss: 0.0013329737121239305
step: 480, loss: 0.0013431283878162503
step: 490, loss: 0.00016172484902199358
step: 500, loss: 0.0006262995302677155
step: 510, loss: 0.062072161585092545
step: 520, loss: 0.02669498510658741
step: 530, loss: 0.04366057366132736
step: 540, loss: 0.040428824722766876
step: 550, loss: 0.023180784657597542
step: 560, loss: 0.06488586962223053
step: 570, loss: 0.028321310877799988
step: 580, loss: 0.00419424194842577
step: 590, loss: 4.045453533763066e-05
step: 600, loss: 0.05553427338600159
step: 610, loss: 0.01834039017558098
step: 620, loss: 0.003969949670135975
step: 630, loss: 0.04508126154541969
step: 640, loss: 0.04382353276014328
step: 650, loss: 0.0005557987024076283
step: 660, loss: 0.046042997390031815
step: 670, loss: 0.018849613144993782
step: 680, loss: 0.014733938500285149
step: 690, loss: 0.052636001259088516
step: 700, loss: 0.02621428109705448
step: 710, loss: 0.026707328855991364
step: 720, loss: 0.030928516760468483
step: 730, loss: 0.0013373231049627066
step: 740, loss: 0.051470257341861725
step: 750, loss: 0.016931219026446342
step: 760, loss: 0.07083198428153992
step: 770, loss: 0.018427863717079163
step: 780, loss: 0.022876441478729248
step: 790, loss: 0.03597545996308327
step: 800, loss: 0.009169178083539009
step: 810, loss: 0.03587383031845093
step: 820, loss: 0.030723756179213524
step: 830, loss: 0.00015917757991701365
step: 840, loss: 0.011584575287997723
step: 850, loss: 0.05784992873668671
step: 860, loss: 0.026674993336200714
step: 870, loss: 0.016508866101503372
step: 880, loss: 0.060213398188352585
step: 890, loss: 0.014306466095149517
step: 900, loss: 0.011441144160926342
step: 910, loss: 0.07236438989639282
step: 920, loss: 0.0013171113096177578
step: 930, loss: 0.06065487116575241
step: 940, loss: 0.15179698169231415
step: 950, loss: 0.003381304908543825
step: 960, loss: 0.011670549400150776
step: 970, loss: 0.0650544986128807
step: 980, loss: 0.059874050319194794
step: 990, loss: 0.01884870044887066
step: 1000, loss: 0.044467318803071976
step: 1010, loss: 0.05886712297797203
step: 1020, loss: 0.03555655851960182
step: 1030, loss: 0.07031086087226868
step: 1040, loss: 0.020093567669391632
step: 1050, loss: 0.031030649319291115
step: 1060, loss: 0.03989309072494507
step: 1070, loss: 0.0313410647213459
epoch 14: dev_f1=0.9318394024276377, f1=0.9235048678720444, best_f1=0.9411764705882353
step: 0, loss: 0.018620776012539864
step: 10, loss: 0.02010185271501541
step: 20, loss: 0.007863568142056465
step: 30, loss: 0.06125890836119652
step: 40, loss: 0.04787237197160721
step: 50, loss: 8.996489668788854e-06
step: 60, loss: 0.034493040293455124
step: 70, loss: 0.03415636345744133
step: 80, loss: 0.0015652693109586835
step: 90, loss: 0.04492444172501564
step: 100, loss: 0.08392538875341415
step: 110, loss: 0.06907088309526443
step: 120, loss: 0.0985354408621788
step: 130, loss: 0.029651740565896034
step: 140, loss: 0.02445278875529766
step: 150, loss: 0.0001128863514168188
step: 160, loss: 0.0001448054244974628
step: 170, loss: 0.0017159765120595694
step: 180, loss: 0.0017819696804508567
step: 190, loss: 0.016083747148513794
step: 200, loss: 0.06313975155353546
step: 210, loss: 0.013275601901113987
step: 220, loss: 0.01790117658674717
step: 230, loss: 0.06412550806999207
step: 240, loss: 0.015509282238781452
step: 250, loss: 0.0216493159532547
step: 260, loss: 0.09196260571479797
step: 270, loss: 0.05536960810422897
step: 280, loss: 0.02463858760893345
step: 290, loss: 0.034516479820013046
step: 300, loss: 0.03584454208612442
step: 310, loss: 0.018513616174459457
step: 320, loss: 6.997854507062584e-05
step: 330, loss: 0.014790009707212448
step: 340, loss: 0.026709888130426407
step: 350, loss: 0.03064068779349327
step: 360, loss: 0.07108806818723679
step: 370, loss: 0.032647404819726944
step: 380, loss: 0.01642773300409317
step: 390, loss: 0.0317976288497448
step: 400, loss: 0.024698764085769653
step: 410, loss: 0.028722118586301804
step: 420, loss: 0.00010820381430676207
step: 430, loss: 0.04733799770474434
step: 440, loss: 0.05935034900903702
step: 450, loss: 0.054450973868370056
step: 460, loss: 0.1320773810148239
step: 470, loss: 0.0010940078645944595
step: 480, loss: 0.023452941328287125
step: 490, loss: 0.00029302501934580505
step: 500, loss: 0.024872848764061928
step: 510, loss: 0.06111036241054535
step: 520, loss: 0.0472981333732605
step: 530, loss: 0.03258099779486656
step: 540, loss: 0.0539606511592865
step: 550, loss: 0.025142062455415726
step: 560, loss: 0.023024704307317734
step: 570, loss: 1.5817226085346192e-05
step: 580, loss: 0.0001451554271625355
step: 590, loss: 0.060374949127435684
step: 600, loss: 0.02392442338168621
step: 610, loss: 0.07293825596570969
step: 620, loss: 0.0008658035658299923
step: 630, loss: 4.579048982122913e-05
step: 640, loss: 0.026867739856243134
step: 650, loss: 0.01699456200003624
step: 660, loss: 0.052069805562496185
step: 670, loss: 0.04016919434070587
step: 680, loss: 0.018664123490452766
step: 690, loss: 0.026124414056539536
step: 700, loss: 6.303696136455983e-05
step: 710, loss: 0.02826761081814766
step: 720, loss: 0.03084428235888481
step: 730, loss: 0.2187366485595703
step: 740, loss: 0.04941238462924957
step: 750, loss: 0.04521811753511429
step: 760, loss: 0.0627240240573883
step: 770, loss: 0.009014536626636982
step: 780, loss: 0.0037782597355544567
step: 790, loss: 0.019766217097640038
step: 800, loss: 0.0151244280859828
step: 810, loss: 0.29309090971946716
step: 820, loss: 0.04399663209915161
step: 830, loss: 0.05375007539987564
step: 840, loss: 0.05262856185436249
step: 850, loss: 0.014716975390911102
step: 860, loss: 0.021740801632404327
step: 870, loss: 0.013148188591003418
step: 880, loss: 0.07294117659330368
step: 890, loss: 0.000173294116393663
step: 900, loss: 0.037187203764915466
step: 910, loss: 0.17708761990070343
step: 920, loss: 0.04803687334060669
step: 930, loss: 0.0035752698313444853
step: 940, loss: 7.440552144544199e-05
step: 950, loss: 0.08702170848846436
step: 960, loss: 8.862411050358787e-06
step: 970, loss: 6.218205817276612e-05
step: 980, loss: 0.030622804537415504
step: 990, loss: 0.06715548038482666
step: 1000, loss: 0.0004768791259266436
step: 1010, loss: 0.029875190928578377
step: 1020, loss: 0.11974840611219406
step: 1030, loss: 0.05465244501829147
step: 1040, loss: 0.02545834518969059
step: 1050, loss: 0.06533326208591461
step: 1060, loss: 4.663566141971387e-05
step: 1070, loss: 0.03665083646774292
epoch 15: dev_f1=0.930562116202173, f1=0.9269662921348314, best_f1=0.9411764705882353
step: 0, loss: 0.020143672823905945
step: 10, loss: 0.020711060613393784
step: 20, loss: 0.0005103214643895626
step: 30, loss: 0.02872571349143982
step: 40, loss: 4.295780308893882e-05
step: 50, loss: 0.021277671679854393
step: 60, loss: 0.07374054193496704
step: 70, loss: 0.041786812245845795
step: 80, loss: 0.02780064195394516
step: 90, loss: 0.04233933612704277
step: 100, loss: 0.0010309884091839194
step: 110, loss: 0.028980154544115067
step: 120, loss: 0.04228714108467102
step: 130, loss: 8.592847007093951e-05
step: 140, loss: 0.0960412472486496
step: 150, loss: 0.007274272385984659
step: 160, loss: 0.019394004717469215
step: 170, loss: 0.06396938860416412
step: 180, loss: 0.05693832412362099
step: 190, loss: 0.013665608130395412
step: 200, loss: 0.08811219781637192
step: 210, loss: 0.01282405387610197
step: 220, loss: 0.03266007453203201
step: 230, loss: 0.028333444148302078
step: 240, loss: 0.10655992478132248
step: 250, loss: 8.756072202231735e-05
step: 260, loss: 0.05034741386771202
step: 270, loss: 0.03992209583520889
step: 280, loss: 0.0002830183948390186
step: 290, loss: 0.03330758586525917
step: 300, loss: 0.02391204424202442
step: 310, loss: 4.488974082050845e-05
step: 320, loss: 1.0292867955286056e-05
step: 330, loss: 1.8182101484853774e-05
step: 340, loss: 0.04504111409187317
step: 350, loss: 5.755194797529839e-05
step: 360, loss: 0.05704803392291069
step: 370, loss: 0.020648211240768433
step: 380, loss: 0.03898933529853821
step: 390, loss: 0.04664471000432968
step: 400, loss: 0.08133598417043686
step: 410, loss: 0.022790316492319107
step: 420, loss: 0.01634051837027073
step: 430, loss: 0.016339657828211784
step: 440, loss: 0.024947740137577057
step: 450, loss: 0.05776287615299225
step: 460, loss: 0.012147748842835426
step: 470, loss: 0.018118370324373245
step: 480, loss: 2.603382381494157e-05
step: 490, loss: 0.049881190061569214
step: 500, loss: 0.02807018905878067
step: 510, loss: 0.023427395150065422
step: 520, loss: 5.714576400350779e-05
step: 530, loss: 0.02051057294011116
step: 540, loss: 0.07087056338787079
step: 550, loss: 0.037449512630701065
step: 560, loss: 2.6815670935320668e-05
step: 570, loss: 0.020593542605638504
step: 580, loss: 0.05358518287539482
step: 590, loss: 3.115874278591946e-05
step: 600, loss: 0.021192466840147972
step: 610, loss: 0.02812480926513672
step: 620, loss: 0.025129297748208046
step: 630, loss: 0.03707398846745491
step: 640, loss: 0.026043802499771118
step: 650, loss: 0.010929960757493973
step: 660, loss: 0.03298875316977501
step: 670, loss: 3.055669367313385e-05
step: 680, loss: 3.2101699616760015e-05
step: 690, loss: 0.018153689801692963
step: 700, loss: 8.30234494060278e-05
step: 710, loss: 0.029510781168937683
step: 720, loss: 0.05563521012663841
step: 730, loss: 7.278675911948085e-05
step: 740, loss: 3.468634531600401e-05
step: 750, loss: 0.0018698932835832238
step: 760, loss: 9.201403372571804e-06
step: 770, loss: 0.02705000340938568
step: 780, loss: 0.04973560571670532
step: 790, loss: 0.07036352157592773
step: 800, loss: 0.07464916259050369
step: 810, loss: 0.04874423146247864
step: 820, loss: 0.04395410045981407
step: 830, loss: 0.06970501691102982
step: 840, loss: 0.030096430331468582
step: 850, loss: 0.08636850863695145
step: 860, loss: 0.032545529305934906
step: 870, loss: 0.027894819155335426
step: 880, loss: 0.03884940966963768
step: 890, loss: 0.02488316036760807
step: 900, loss: 0.06584149599075317
step: 910, loss: 0.022660212591290474
step: 920, loss: 0.03624522686004639
step: 930, loss: 0.03916552662849426
step: 940, loss: 0.019822537899017334
step: 950, loss: 0.03716666251420975
step: 960, loss: 0.016958674415946007
step: 970, loss: 6.7352975747780874e-06
step: 980, loss: 0.029875610023736954
step: 990, loss: 0.02568044140934944
step: 1000, loss: 0.025424886494874954
step: 1010, loss: 0.03741757199168205
step: 1020, loss: 0.001981512177735567
step: 1030, loss: 0.020856494084000587
step: 1040, loss: 0.022135775536298752
step: 1050, loss: 0.01644721068441868
step: 1060, loss: 0.08229153603315353
step: 1070, loss: 0.06206049770116806
epoch 16: dev_f1=0.9305816135084428, f1=0.9256505576208177, best_f1=0.9411764705882353
step: 0, loss: 0.08439704030752182
step: 10, loss: 0.02834317646920681
step: 20, loss: 0.006118654273450375
step: 30, loss: 0.0004966304986737669
step: 40, loss: 0.022912897169589996
step: 50, loss: 0.016111532226204872
step: 60, loss: 0.07047972828149796
step: 70, loss: 0.014083576388657093
step: 80, loss: 0.06701239198446274
step: 90, loss: 0.029059600085020065
step: 100, loss: 0.02887563593685627
step: 110, loss: 0.03773446008563042
step: 120, loss: 0.04366225749254227
step: 130, loss: 0.03536764159798622
step: 140, loss: 0.0774177610874176
step: 150, loss: 0.04102887213230133
step: 160, loss: 0.031570304185152054
step: 170, loss: 0.06455401331186295
step: 180, loss: 0.00020262924954295158
step: 190, loss: 0.014211161062121391
step: 200, loss: 0.051476702094078064
step: 210, loss: 0.020137492567300797
step: 220, loss: 0.03230796381831169
step: 230, loss: 0.021393563598394394
step: 240, loss: 0.04242493957281113
step: 250, loss: 0.04270230978727341
step: 260, loss: 0.0010843846248462796
step: 270, loss: 0.03626347333192825
step: 280, loss: 0.02713223733007908
step: 290, loss: 0.07515284419059753
step: 300, loss: 0.001385209965519607
step: 310, loss: 5.684741699951701e-05
step: 320, loss: 0.07020194828510284
step: 330, loss: 6.136404408607632e-05
step: 340, loss: 8.229113518609665e-06
step: 350, loss: 0.041605234146118164
step: 360, loss: 0.05194967985153198
step: 370, loss: 5.5387357861036435e-05
step: 380, loss: 0.04237857088446617
step: 390, loss: 0.0001323878823313862
step: 400, loss: 1.738474929879885e-05
step: 410, loss: 0.0701100081205368
step: 420, loss: 0.005913080647587776
step: 430, loss: 0.005609638057649136
step: 440, loss: 0.012257678434252739
step: 450, loss: 0.04590717703104019
step: 460, loss: 0.05316701903939247
step: 470, loss: 0.013353473506867886
step: 480, loss: 0.02224116027355194
step: 490, loss: 0.01191841159015894
step: 500, loss: 0.017163874581456184
step: 510, loss: 7.80071786721237e-06
step: 520, loss: 0.06190304830670357
step: 530, loss: 0.04185894876718521
step: 540, loss: 0.02360197901725769
step: 550, loss: 0.07063852250576019
step: 560, loss: 0.025920303538441658
step: 570, loss: 1.7328875401290134e-05
step: 580, loss: 0.047165267169475555
step: 590, loss: 0.020818935707211494
step: 600, loss: 0.11060091108083725
step: 610, loss: 0.0725458636879921
step: 620, loss: 0.04007825627923012
step: 630, loss: 3.001986988238059e-05
step: 640, loss: 0.013688062317669392
step: 650, loss: 0.0211395975202322
step: 660, loss: 0.07638712227344513
step: 670, loss: 0.030089279636740685
step: 680, loss: 0.025597598403692245
step: 690, loss: 0.045303329825401306
step: 700, loss: 2.0421053704922087e-05
step: 710, loss: 0.04802533984184265
step: 720, loss: 0.010880811139941216
step: 730, loss: 0.04084380716085434
step: 740, loss: 0.006454050075262785
step: 750, loss: 0.0008411890594288707
step: 760, loss: 4.2390547605464235e-05
step: 770, loss: 0.03832285478711128
step: 780, loss: 1.1045390237995889e-05
step: 790, loss: 0.050464265048503876
step: 800, loss: 0.028301220387220383
step: 810, loss: 0.0031725356820970774
step: 820, loss: 0.043542586266994476
step: 830, loss: 0.06229217350482941
step: 840, loss: 0.023420199751853943
step: 850, loss: 0.029104387387633324
step: 860, loss: 0.012619871646165848
step: 870, loss: 2.6123103452846408e-05
step: 880, loss: 0.0315847285091877
step: 890, loss: 0.0389489084482193
step: 900, loss: 0.030658898875117302
step: 910, loss: 1.0114079486811534e-05
step: 920, loss: 0.027703631669282913
step: 930, loss: 0.042885538190603256
step: 940, loss: 9.126890290644951e-06
step: 950, loss: 0.001046866993419826
step: 960, loss: 0.06187373772263527
step: 970, loss: 0.06710659712553024
step: 980, loss: 0.02350839413702488
step: 990, loss: 0.0028023296035826206
step: 1000, loss: 0.0638328418135643
step: 1010, loss: 0.042579956352710724
step: 1020, loss: 0.02551519125699997
step: 1030, loss: 2.1655609089066274e-05
step: 1040, loss: 0.022212285548448563
step: 1050, loss: 4.347948924987577e-05
step: 1060, loss: 0.017544103786349297
step: 1070, loss: 0.01756022870540619
epoch 17: dev_f1=0.9322113136979896, f1=0.925290023201856, best_f1=0.9411764705882353
step: 0, loss: 0.027591897174715996
step: 10, loss: 0.07322510331869125
step: 20, loss: 0.017658159136772156
step: 30, loss: 0.02362874709069729
step: 40, loss: 5.0803671911126e-05
step: 50, loss: 0.0032177853863686323
step: 60, loss: 0.007674700114876032
step: 70, loss: 0.0302071962505579
step: 80, loss: 0.019052553921937943
step: 90, loss: 0.019528765231370926
step: 100, loss: 0.1483066827058792
step: 110, loss: 0.00115658575668931
step: 120, loss: 0.024238208308815956
step: 130, loss: 0.024832574650645256
step: 140, loss: 0.002182859694585204
step: 150, loss: 0.021134719252586365
step: 160, loss: 2.461822259647306e-05
step: 170, loss: 0.029620962217450142
step: 180, loss: 0.022867893800139427
step: 190, loss: 0.013879062607884407
step: 200, loss: 1.396951665810775e-05
step: 210, loss: 0.01313098892569542
step: 220, loss: 0.00025079259648919106
step: 230, loss: 0.00040129863191396
step: 240, loss: 0.07574384659528732
step: 250, loss: 0.026074782013893127
step: 260, loss: 0.01225972454994917
step: 270, loss: 7.476624887203798e-06
step: 280, loss: 0.03111523762345314
step: 290, loss: 0.0648227334022522
step: 300, loss: 0.030118094757199287
step: 310, loss: 0.05592271313071251
step: 320, loss: 1.447558679501526e-05
step: 330, loss: 0.00024432491045445204
step: 340, loss: 0.022332770749926567
step: 350, loss: 0.02121211402118206
step: 360, loss: 5.571726069319993e-05
step: 370, loss: 0.09925751388072968
step: 380, loss: 0.0388350784778595
step: 390, loss: 0.021523606032133102
step: 400, loss: 0.00023751769913360476
step: 410, loss: 0.00015752231411170214
step: 420, loss: 0.0366518460214138
step: 430, loss: 3.801463026320562e-05
step: 440, loss: 0.04131101444363594
step: 450, loss: 0.012669811956584454
step: 460, loss: 0.09952057898044586
step: 470, loss: 1.3135093468008563e-05
step: 480, loss: 0.008559261448681355
step: 490, loss: 0.00171056785620749
step: 500, loss: 0.04569688439369202
step: 510, loss: 0.020049264654517174
step: 520, loss: 0.04554618522524834
step: 530, loss: 1.20620397865423e-05
step: 540, loss: 0.0001509199501015246
step: 550, loss: 7.31838881620206e-05
step: 560, loss: 0.06258413940668106
step: 570, loss: 0.03578861430287361
step: 580, loss: 0.08594243228435516
step: 590, loss: 5.271922054816969e-05
step: 600, loss: 7.812192052369937e-05
step: 610, loss: 0.07108961045742035
step: 620, loss: 3.907972131855786e-05
step: 630, loss: 3.647063203970902e-05
step: 640, loss: 0.02150353044271469
step: 650, loss: 0.04619111493229866
step: 660, loss: 0.016746142879128456
step: 670, loss: 0.050922684371471405
step: 680, loss: 0.02555019222199917
step: 690, loss: 3.3914904634002596e-05
step: 700, loss: 0.03569287061691284
step: 710, loss: 0.06454263627529144
step: 720, loss: 0.02558358944952488
step: 730, loss: 0.019080711528658867
step: 740, loss: 0.00012696566409431398
step: 750, loss: 0.07834330201148987
step: 760, loss: 0.017586341127753258
step: 770, loss: 0.021967167034745216
step: 780, loss: 1.777258876245469e-05
step: 790, loss: 0.03156265988945961
step: 800, loss: 0.045707959681749344
step: 810, loss: 0.015294083394110203
step: 820, loss: 0.0464315190911293
step: 830, loss: 0.046654440462589264
step: 840, loss: 0.020072022452950478
step: 850, loss: 0.1099541112780571
step: 860, loss: 3.782934072660282e-05
step: 870, loss: 0.06840027123689651
step: 880, loss: 0.026199903339147568
step: 890, loss: 0.05448278784751892
step: 900, loss: 0.00013561631203629076
step: 910, loss: 0.041893742978572845
step: 920, loss: 0.04448863863945007
step: 930, loss: 0.024541037157177925
step: 940, loss: 0.01944538950920105
step: 950, loss: 0.015650196000933647
step: 960, loss: 0.042272765189409256
step: 970, loss: 0.0585031732916832
step: 980, loss: 0.0180195402354002
step: 990, loss: 0.022094158455729485
step: 1000, loss: 0.063591867685318
step: 1010, loss: 2.249909084639512e-05
step: 1020, loss: 0.0215583685785532
step: 1030, loss: 0.04379510506987572
step: 1040, loss: 2.5379440558026545e-05
step: 1050, loss: 0.04569452255964279
step: 1060, loss: 0.0199433583766222
step: 1070, loss: 0.0001565290876897052
epoch 18: dev_f1=0.9322113136979896, f1=0.9288354898336414, best_f1=0.9411764705882353
step: 0, loss: 0.023797115311026573
step: 10, loss: 2.7655758458422497e-05
step: 20, loss: 0.02038082852959633
step: 30, loss: 0.0017136519309133291
step: 40, loss: 0.10926026105880737
step: 50, loss: 0.022602418437600136
step: 60, loss: 0.020007504150271416
step: 70, loss: 0.015955574810504913
step: 80, loss: 0.020989054813981056
step: 90, loss: 0.06208072230219841
step: 100, loss: 0.022302210330963135
step: 110, loss: 0.023360958322882652
step: 120, loss: 0.021441543474793434
step: 130, loss: 0.024557456374168396
step: 140, loss: 0.02461223676800728
step: 150, loss: 0.00034144986420869827
step: 160, loss: 1.7713085981085896e-05
step: 170, loss: 0.07458816468715668
step: 180, loss: 0.026323234662413597
step: 190, loss: 0.020552005618810654
step: 200, loss: 0.030395500361919403
step: 210, loss: 0.07036006450653076
step: 220, loss: 0.08842429518699646
step: 230, loss: 3.326078876852989e-05
step: 240, loss: 0.0003021796001121402
step: 250, loss: 0.05050697922706604
step: 260, loss: 0.07606504112482071
step: 270, loss: 1.8227092368761078e-05
step: 280, loss: 0.019731953740119934
step: 290, loss: 0.06028100848197937
step: 300, loss: 3.7614307075273246e-05
step: 310, loss: 0.039406973868608475
step: 320, loss: 0.02292909473180771
step: 330, loss: 0.03876304626464844
step: 340, loss: 0.00014385630493052304
step: 350, loss: 0.00012632603466045111
step: 360, loss: 1.7388925698469393e-05
step: 370, loss: 2.3039534426061437e-05
step: 380, loss: 0.026347611099481583
step: 390, loss: 0.021443644538521767
step: 400, loss: 1.691598299657926e-05
step: 410, loss: 8.70967505761655e-06
step: 420, loss: 0.006809649523347616
step: 430, loss: 0.016818270087242126
step: 440, loss: 0.016790810972452164
step: 450, loss: 0.025990458205342293
step: 460, loss: 0.0025692065246403217
step: 470, loss: 0.04364418610930443
step: 480, loss: 0.0844201073050499
step: 490, loss: 0.04751620069146156
step: 500, loss: 0.0035375403240323067
step: 510, loss: 0.022273216396570206
step: 520, loss: 2.61776822298998e-05
step: 530, loss: 0.036131564527750015
step: 540, loss: 0.03935280442237854
step: 550, loss: 0.03571421280503273
step: 560, loss: 0.014925818890333176
step: 570, loss: 0.00020677231077570468
step: 580, loss: 1.6170522940228693e-05
step: 590, loss: 0.02428947389125824
step: 600, loss: 0.023438211530447006
step: 610, loss: 0.020690033212304115
step: 620, loss: 0.019209686666727066
step: 630, loss: 0.06816829741001129
step: 640, loss: 0.01954655721783638
step: 650, loss: 0.058570072054862976
step: 660, loss: 0.01299355085939169
step: 670, loss: 0.0430716797709465
step: 680, loss: 3.0547216738341376e-05
step: 690, loss: 0.022452330216765404
step: 700, loss: 0.018763380125164986
step: 710, loss: 0.014774790965020657
step: 720, loss: 0.00015458269626833498
step: 730, loss: 0.02227930910885334
step: 740, loss: 0.00013689749175682664
step: 750, loss: 2.8919364922330715e-05
step: 760, loss: 0.0781744122505188
step: 770, loss: 0.00037925239303149283
step: 780, loss: 2.1415107767097652e-05
step: 790, loss: 0.2987005114555359
step: 800, loss: 0.020951993763446808
step: 810, loss: 0.02523522824048996
step: 820, loss: 0.015604570508003235
step: 830, loss: 0.021268416196107864
step: 840, loss: 1.3924715858593117e-05
step: 850, loss: 1.982798130484298e-05
step: 860, loss: 0.019469620659947395
step: 870, loss: 0.001109554199501872
step: 880, loss: 0.061314016580581665
step: 890, loss: 0.14798696339130402
step: 900, loss: 0.018384408205747604
step: 910, loss: 0.05010538548231125
step: 920, loss: 0.03664754703640938
step: 930, loss: 0.036763567477464676
step: 940, loss: 0.07939453423023224
step: 950, loss: 0.09473620355129242
step: 960, loss: 0.02385321632027626
step: 970, loss: 0.016078829765319824
step: 980, loss: 0.00017270758689846843
step: 990, loss: 2.4501639927621e-05
step: 1000, loss: 0.002306010341271758
step: 1010, loss: 0.0812031477689743
step: 1020, loss: 1.582437107572332e-05
step: 1030, loss: 0.09237916767597198
step: 1040, loss: 0.029107287526130676
step: 1050, loss: 0.003135986626148224
step: 1060, loss: 2.0841776859015226e-05
step: 1070, loss: 0.005578957498073578
epoch 19: dev_f1=0.930276087973795, f1=0.9271461716937355, best_f1=0.9411764705882353
step: 0, loss: 0.05670185759663582
step: 10, loss: 0.0003891194355674088
step: 20, loss: 0.031237728893756866
step: 30, loss: 0.010505392216145992
step: 40, loss: 4.8699967010179535e-05
step: 50, loss: 0.004200566094368696
step: 60, loss: 0.025277860462665558
step: 70, loss: 0.021389294415712357
step: 80, loss: 0.05281723290681839
step: 90, loss: 0.05783272907137871
step: 100, loss: 0.028188267722725868
step: 110, loss: 0.0014114589430391788
step: 120, loss: 2.9229904612293467e-05
step: 130, loss: 0.02507156692445278
step: 140, loss: 0.03876594826579094
step: 150, loss: 0.06347741186618805
step: 160, loss: 0.000263569614617154
step: 170, loss: 0.005495526362210512
step: 180, loss: 0.01623363047838211
step: 190, loss: 0.014831176027655602
step: 200, loss: 0.017541348934173584
step: 210, loss: 0.023033130913972855
step: 220, loss: 0.021490545943379402
step: 230, loss: 0.021515248343348503
step: 240, loss: 0.046530913561582565
step: 250, loss: 0.0011662004981189966
step: 260, loss: 0.04138604551553726
step: 270, loss: 0.050747282803058624
step: 280, loss: 0.009005478583276272
step: 290, loss: 0.04338984191417694
step: 300, loss: 0.040777672082185745
step: 310, loss: 0.0651710033416748
step: 320, loss: 0.0652734711766243
step: 330, loss: 0.04837500676512718
step: 340, loss: 9.409990525455214e-06
step: 350, loss: 0.02524600364267826
step: 360, loss: 0.00018344970885664225
step: 370, loss: 0.020702997222542763
step: 380, loss: 0.018344378098845482
step: 390, loss: 1.3202177797211334e-05
step: 400, loss: 0.04089132696390152
step: 410, loss: 0.022137867286801338
step: 420, loss: 0.03425905108451843
step: 430, loss: 1.095586412702687e-05
step: 440, loss: 0.016282346099615097
step: 450, loss: 0.014184309169650078
step: 460, loss: 0.027183199301362038
step: 470, loss: 0.041876185685396194
step: 480, loss: 1.1395364708732814e-05
step: 490, loss: 0.09424412995576859
step: 500, loss: 0.03116416558623314
step: 510, loss: 8.697900193510577e-05
step: 520, loss: 0.019465234130620956
step: 530, loss: 0.07629061490297318
step: 540, loss: 7.614453352289274e-06
step: 550, loss: 2.100568963214755e-05
step: 560, loss: 1.0639155334501993e-05
step: 570, loss: 0.007994367741048336
step: 580, loss: 0.06769075989723206
step: 590, loss: 0.02776702120900154
step: 600, loss: 0.044222645461559296
step: 610, loss: 0.0290552768856287
step: 620, loss: 0.04396091774106026
step: 630, loss: 0.017895448952913284
step: 640, loss: 0.021947184577584267
step: 650, loss: 0.0672231987118721
step: 660, loss: 0.028484448790550232
step: 670, loss: 0.01271826308220625
step: 680, loss: 0.02430570311844349
step: 690, loss: 0.017293304204940796
step: 700, loss: 5.631767999147996e-05
step: 710, loss: 0.05233125388622284
step: 720, loss: 0.03754843398928642
step: 730, loss: 0.06599400192499161
step: 740, loss: 0.00010097355698235333
step: 750, loss: 0.008599297143518925
step: 760, loss: 0.0016420282190665603
step: 770, loss: 0.020398149266839027
step: 780, loss: 0.012188372202217579
step: 790, loss: 0.024105753749608994
step: 800, loss: 0.020466353744268417
step: 810, loss: 6.96912466082722e-05
step: 820, loss: 0.025597894564270973
step: 830, loss: 0.024405183270573616
step: 840, loss: 0.023331545293331146
step: 850, loss: 0.022247672080993652
step: 860, loss: 0.0001064566895365715
step: 870, loss: 9.182735084323213e-06
step: 880, loss: 2.0576851966325194e-05
step: 890, loss: 0.018768860027194023
step: 900, loss: 0.06760510057210922
step: 910, loss: 0.015656402334570885
step: 920, loss: 1.5488800272578374e-05
step: 930, loss: 5.5222903029061854e-05
step: 940, loss: 0.028865817934274673
step: 950, loss: 0.06385459750890732
step: 960, loss: 4.067548434250057e-05
step: 970, loss: 0.02009921334683895
step: 980, loss: 0.053682565689086914
step: 990, loss: 0.006182069890201092
step: 1000, loss: 0.025522664189338684
step: 1010, loss: 0.0041658151894807816
step: 1020, loss: 1.7627164197620004e-05
step: 1030, loss: 0.001162216067314148
step: 1040, loss: 0.02308005467057228
step: 1050, loss: 0.061701711267232895
step: 1060, loss: 0.03474355489015579
step: 1070, loss: 0.020109863951802254
epoch 20: dev_f1=0.9312762973352035, f1=0.9267161410018553, best_f1=0.9411764705882353
