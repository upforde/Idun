cuda
Device: cuda
step: 0, loss: 0.8353202939033508
step: 10, loss: 0.3761530816555023
step: 20, loss: 0.4387151896953583
step: 30, loss: 0.4945433735847473
step: 40, loss: 0.43846794962882996
step: 50, loss: 0.28929629921913147
step: 60, loss: 0.30252984166145325
step: 70, loss: 0.1687958538532257
step: 80, loss: 0.49423718452453613
step: 90, loss: 0.25240206718444824
step: 100, loss: 0.11372892558574677
step: 110, loss: 0.23185235261917114
step: 120, loss: 0.043982598930597305
step: 130, loss: 0.2797785699367523
step: 140, loss: 0.1828167885541916
step: 150, loss: 0.3419985771179199
step: 160, loss: 0.10559310019016266
step: 170, loss: 0.13661636412143707
step: 180, loss: 0.13066016137599945
step: 190, loss: 0.16262975335121155
step: 200, loss: 0.17907533049583435
step: 210, loss: 0.15838587284088135
step: 220, loss: 0.11266399174928665
step: 230, loss: 0.12904703617095947
step: 240, loss: 0.12389017641544342
step: 250, loss: 0.17013289034366608
step: 260, loss: 0.16541427373886108
step: 270, loss: 0.08531302958726883
step: 280, loss: 0.1277833878993988
step: 290, loss: 0.31462910771369934
step: 300, loss: 0.11393025517463684
step: 310, loss: 0.13288435339927673
step: 320, loss: 0.22634711861610413
step: 330, loss: 0.11944212019443512
step: 340, loss: 0.06582479178905487
step: 350, loss: 0.1620827466249466
step: 360, loss: 0.1981392204761505
step: 370, loss: 0.11960503458976746
step: 380, loss: 0.07715415954589844
step: 390, loss: 0.14731815457344055
step: 400, loss: 0.09332702308893204
step: 410, loss: 0.15278081595897675
step: 420, loss: 0.15691258013248444
step: 430, loss: 0.21512389183044434
step: 440, loss: 0.08957021683454514
step: 450, loss: 0.19248414039611816
step: 460, loss: 0.16971229016780853
step: 470, loss: 0.24172520637512207
step: 480, loss: 0.05317666009068489
step: 490, loss: 0.14266186952590942
step: 500, loss: 0.08765901625156403
step: 510, loss: 0.12975303828716278
step: 520, loss: 0.1454368233680725
step: 530, loss: 0.10019572824239731
step: 540, loss: 0.20994630455970764
step: 550, loss: 0.19011566042900085
step: 560, loss: 0.1218336895108223
step: 570, loss: 0.17177586257457733
step: 580, loss: 0.04478088393807411
step: 590, loss: 0.06752113997936249
step: 600, loss: 0.1016998440027237
step: 610, loss: 0.04413847625255585
step: 620, loss: 0.04968535900115967
step: 630, loss: 0.09542369842529297
step: 640, loss: 0.16484956443309784
step: 650, loss: 0.1165083721280098
step: 660, loss: 0.06807376444339752
step: 670, loss: 0.0920247882604599
step: 680, loss: 0.1792633831501007
step: 690, loss: 0.08047868311405182
step: 700, loss: 0.04257741570472717
step: 710, loss: 0.057700105011463165
step: 720, loss: 0.05927491560578346
step: 730, loss: 0.0775127187371254
step: 740, loss: 0.0830935463309288
step: 750, loss: 0.16524048149585724
step: 760, loss: 0.047135502099990845
step: 770, loss: 0.1575768142938614
step: 780, loss: 0.14091840386390686
step: 790, loss: 0.13970156013965607
step: 800, loss: 0.10679445415735245
step: 810, loss: 0.08127881586551666
step: 820, loss: 0.03892579302191734
step: 830, loss: 0.3348054587841034
step: 840, loss: 0.31477969884872437
step: 850, loss: 0.06930109858512878
step: 860, loss: 0.07309795171022415
step: 870, loss: 0.1335894763469696
step: 880, loss: 0.06276760250329971
step: 890, loss: 0.08592896908521652
step: 900, loss: 0.24604807794094086
step: 910, loss: 0.10200577974319458
step: 920, loss: 0.018979400396347046
step: 930, loss: 0.19089645147323608
step: 940, loss: 0.09820196032524109
step: 950, loss: 0.08104244619607925
step: 960, loss: 0.07998918741941452
step: 970, loss: 0.09876832365989685
step: 980, loss: 0.049381617456674576
step: 990, loss: 0.09718920290470123
step: 1000, loss: 0.19592759013175964
step: 1010, loss: 0.4304552376270294
step: 1020, loss: 0.05816102772951126
step: 1030, loss: 0.03262483328580856
step: 1040, loss: 0.08595401793718338
step: 1050, loss: 0.12920475006103516
step: 1060, loss: 0.03671586886048317
step: 1070, loss: 0.08598724007606506
epoch 1: dev_f1=0.9279279279279279, f1=0.9245960502692998, best_f1=0.9245960502692998
step: 0, loss: 0.02495754510164261
step: 10, loss: 0.059070389717817307
step: 20, loss: 0.01545474398881197
step: 30, loss: 0.022478971630334854
step: 40, loss: 0.04252695292234421
step: 50, loss: 0.0780937671661377
step: 60, loss: 0.1646273136138916
step: 70, loss: 0.11593730747699738
step: 80, loss: 0.16945160925388336
step: 90, loss: 0.08466868847608566
step: 100, loss: 0.022540519014000893
step: 110, loss: 0.007090757135301828
step: 120, loss: 0.03218264877796173
step: 130, loss: 0.08095947653055191
step: 140, loss: 0.053496070206165314
step: 150, loss: 0.10584921389818192
step: 160, loss: 0.058971770107746124
step: 170, loss: 0.09966360032558441
step: 180, loss: 0.12920106947422028
step: 190, loss: 0.06685043126344681
step: 200, loss: 0.10847418755292892
step: 210, loss: 0.024832475930452347
step: 220, loss: 0.096481092274189
step: 230, loss: 0.09326941519975662
step: 240, loss: 0.10475753992795944
step: 250, loss: 0.07692845910787582
step: 260, loss: 0.09342201799154282
step: 270, loss: 0.10927000641822815
step: 280, loss: 0.12657587230205536
step: 290, loss: 0.08095220476388931
step: 300, loss: 0.11259883642196655
step: 310, loss: 0.04953445494174957
step: 320, loss: 0.06489650905132294
step: 330, loss: 0.06868838518857956
step: 340, loss: 0.0867895856499672
step: 350, loss: 0.2223334014415741
step: 360, loss: 0.09979059547185898
step: 370, loss: 0.12281742691993713
step: 380, loss: 0.1074005514383316
step: 390, loss: 0.24313713610172272
step: 400, loss: 0.0694122165441513
step: 410, loss: 0.02919033169746399
step: 420, loss: 0.15495282411575317
step: 430, loss: 0.011824813671410084
step: 440, loss: 0.06948647648096085
step: 450, loss: 0.17131657898426056
step: 460, loss: 0.09839730709791183
step: 470, loss: 0.08899061381816864
step: 480, loss: 0.057975705713033676
step: 490, loss: 0.058075182139873505
step: 500, loss: 0.2026764452457428
step: 510, loss: 0.011131555773317814
step: 520, loss: 0.17413519322872162
step: 530, loss: 0.09004262089729309
step: 540, loss: 0.08087021112442017
step: 550, loss: 0.11415725946426392
step: 560, loss: 0.12101491540670395
step: 570, loss: 0.05181664600968361
step: 580, loss: 0.18856196105480194
step: 590, loss: 0.03868917375802994
step: 600, loss: 0.2101532220840454
step: 610, loss: 0.031768493354320526
step: 620, loss: 0.021743301302194595
step: 630, loss: 0.10690570622682571
step: 640, loss: 0.10537178814411163
step: 650, loss: 0.07649426907300949
step: 660, loss: 0.0509524904191494
step: 670, loss: 0.11793149262666702
step: 680, loss: 0.08410143852233887
step: 690, loss: 0.0336204431951046
step: 700, loss: 0.033378295600414276
step: 710, loss: 0.09186428785324097
step: 720, loss: 0.011659376323223114
step: 730, loss: 0.018388275057077408
step: 740, loss: 0.10763926804065704
step: 750, loss: 0.06329002231359482
step: 760, loss: 0.10645041614770889
step: 770, loss: 0.14383304119110107
step: 780, loss: 0.07851787656545639
step: 790, loss: 0.08869615197181702
step: 800, loss: 0.24193912744522095
step: 810, loss: 0.021694576367735863
step: 820, loss: 0.11791318655014038
step: 830, loss: 0.11210841685533524
step: 840, loss: 0.06276658922433853
step: 850, loss: 0.041192907840013504
step: 860, loss: 0.019797084853053093
step: 870, loss: 0.0004443202633410692
step: 880, loss: 0.01417835708707571
step: 890, loss: 0.14094872772693634
step: 900, loss: 0.07471755892038345
step: 910, loss: 0.0702129453420639
step: 920, loss: 0.07301725447177887
step: 930, loss: 0.09465290606021881
step: 940, loss: 0.06882606446743011
step: 950, loss: 0.11478686332702637
step: 960, loss: 0.08382007479667664
step: 970, loss: 0.21886445581912994
step: 980, loss: 0.1469753086566925
step: 990, loss: 0.08476575464010239
step: 1000, loss: 0.04317395016551018
step: 1010, loss: 0.0019730632193386555
step: 1020, loss: 0.03069572150707245
step: 1030, loss: 0.07263120263814926
step: 1040, loss: 0.0700782909989357
step: 1050, loss: 0.14450058341026306
step: 1060, loss: 0.1098514124751091
step: 1070, loss: 0.0723278820514679
epoch 2: dev_f1=0.9304267161410019, f1=0.9301249421564091, best_f1=0.9301249421564091
step: 0, loss: 0.03298421576619148
step: 10, loss: 0.034017473459243774
step: 20, loss: 0.01938972808420658
step: 30, loss: 0.23610727488994598
step: 40, loss: 0.04422023147344589
step: 50, loss: 0.023119600489735603
step: 60, loss: 0.09561370313167572
step: 70, loss: 0.09013258665800095
step: 80, loss: 0.09000779688358307
step: 90, loss: 0.1372436285018921
step: 100, loss: 0.057473473250865936
step: 110, loss: 0.04965057596564293
step: 120, loss: 0.06594919413328171
step: 130, loss: 0.0392504557967186
step: 140, loss: 0.07235854864120483
step: 150, loss: 0.0269883144646883
step: 160, loss: 0.03209089860320091
step: 170, loss: 0.05942685529589653
step: 180, loss: 0.02315671741962433
step: 190, loss: 0.05858892574906349
step: 200, loss: 0.05720336735248566
step: 210, loss: 0.09965331852436066
step: 220, loss: 0.014537695795297623
step: 230, loss: 0.01810545288026333
step: 240, loss: 0.1109248697757721
step: 250, loss: 0.05157947540283203
step: 260, loss: 0.01816299930214882
step: 270, loss: 0.03508759289979935
step: 280, loss: 0.1553994119167328
step: 290, loss: 0.02160647138953209
step: 300, loss: 0.07017083466053009
step: 310, loss: 0.16941112279891968
step: 320, loss: 0.11320560425519943
step: 330, loss: 0.07721077650785446
step: 340, loss: 0.10864126682281494
step: 350, loss: 0.07920057326555252
step: 360, loss: 0.1100533977150917
step: 370, loss: 0.06977979838848114
step: 380, loss: 0.08274175226688385
step: 390, loss: 0.12183989584445953
step: 400, loss: 0.04460171237587929
step: 410, loss: 0.11853650212287903
step: 420, loss: 0.10049664974212646
step: 430, loss: 0.10534785687923431
step: 440, loss: 0.09183157980442047
step: 450, loss: 0.08640825748443604
step: 460, loss: 0.15295922756195068
step: 470, loss: 0.026877934113144875
step: 480, loss: 0.11214489489793777
step: 490, loss: 0.08468509465456009
step: 500, loss: 0.05768702179193497
step: 510, loss: 0.0641501247882843
step: 520, loss: 0.09607413411140442
step: 530, loss: 0.14996281266212463
step: 540, loss: 0.033556412905454636
step: 550, loss: 0.017661236226558685
step: 560, loss: 0.060791097581386566
step: 570, loss: 0.1323019564151764
step: 580, loss: 0.05936934053897858
step: 590, loss: 0.04080887511372566
step: 600, loss: 0.13769473135471344
step: 610, loss: 0.1493760049343109
step: 620, loss: 0.09393777698278427
step: 630, loss: 0.09558657556772232
step: 640, loss: 0.1666809320449829
step: 650, loss: 0.0854898989200592
step: 660, loss: 0.07307986915111542
step: 670, loss: 0.033077552914619446
step: 680, loss: 0.16358216106891632
step: 690, loss: 0.05440504848957062
step: 700, loss: 0.038719262927770615
step: 710, loss: 0.016425305977463722
step: 720, loss: 0.11193322390317917
step: 730, loss: 0.08186399936676025
step: 740, loss: 0.010550901293754578
step: 750, loss: 0.12363743036985397
step: 760, loss: 0.04285307601094246
step: 770, loss: 0.06855364143848419
step: 780, loss: 0.09072700142860413
step: 790, loss: 0.03204800933599472
step: 800, loss: 0.02927517518401146
step: 810, loss: 0.003144456772133708
step: 820, loss: 0.09109345078468323
step: 830, loss: 0.15315061807632446
step: 840, loss: 0.16212113201618195
step: 850, loss: 0.0646689385175705
step: 860, loss: 0.040158726274967194
step: 870, loss: 0.14782050251960754
step: 880, loss: 0.024470822885632515
step: 890, loss: 0.05437423661351204
step: 900, loss: 0.043054550886154175
step: 910, loss: 0.018029095605015755
step: 920, loss: 0.06199130415916443
step: 930, loss: 0.008737459778785706
step: 940, loss: 0.07950926572084427
step: 950, loss: 0.08600986003875732
step: 960, loss: 0.05513426661491394
step: 970, loss: 0.0014544696314260364
step: 980, loss: 0.03932001441717148
step: 990, loss: 0.15488238632678986
step: 1000, loss: 0.08941636234521866
step: 1010, loss: 0.09760802239179611
step: 1020, loss: 0.10312874615192413
step: 1030, loss: 0.005776740610599518
step: 1040, loss: 0.03248201310634613
step: 1050, loss: 0.07429024577140808
step: 1060, loss: 0.027881480753421783
step: 1070, loss: 0.19400069117546082
epoch 3: dev_f1=0.9371584699453551, f1=0.9359963685882887, best_f1=0.9359963685882887
step: 0, loss: 0.01319173350930214
step: 10, loss: 0.06074818968772888
step: 20, loss: 0.08713647723197937
step: 30, loss: 0.031415075063705444
step: 40, loss: 0.17189277708530426
step: 50, loss: 0.15359672904014587
step: 60, loss: 0.004696954973042011
step: 70, loss: 0.02520378679037094
step: 80, loss: 0.047734953463077545
step: 90, loss: 0.07667471468448639
step: 100, loss: 0.0493432991206646
step: 110, loss: 0.02940233051776886
step: 120, loss: 0.0724598616361618
step: 130, loss: 0.01453850232064724
step: 140, loss: 0.02173459716141224
step: 150, loss: 0.15087094902992249
step: 160, loss: 0.008068655617535114
step: 170, loss: 0.2383580505847931
step: 180, loss: 0.01985550858080387
step: 190, loss: 0.07045198231935501
step: 200, loss: 0.061682552099227905
step: 210, loss: 0.09496970474720001
step: 220, loss: 0.06044190376996994
step: 230, loss: 0.14642301201820374
step: 240, loss: 0.03514391556382179
step: 250, loss: 0.0726873129606247
step: 260, loss: 0.045210592448711395
step: 270, loss: 0.011418483220040798
step: 280, loss: 0.02567409910261631
step: 290, loss: 0.02320820651948452
step: 300, loss: 0.0176897831261158
step: 310, loss: 0.07748503983020782
step: 320, loss: 0.0722765251994133
step: 330, loss: 0.06467731297016144
step: 340, loss: 0.10447164624929428
step: 350, loss: 0.11608559638261795
step: 360, loss: 0.023105304688215256
step: 370, loss: 0.08433470875024796
step: 380, loss: 0.05008602887392044
step: 390, loss: 0.006747214123606682
step: 400, loss: 0.15175531804561615
step: 410, loss: 0.0062135616317391396
step: 420, loss: 0.02974626049399376
step: 430, loss: 0.07373099029064178
step: 440, loss: 0.1879543960094452
step: 450, loss: 0.06597544997930527
step: 460, loss: 0.05112416669726372
step: 470, loss: 0.07015050947666168
step: 480, loss: 0.06965576857328415
step: 490, loss: 0.13702204823493958
step: 500, loss: 0.07872980833053589
step: 510, loss: 0.05716698244214058
step: 520, loss: 0.0244708564132452
step: 530, loss: 0.05257387459278107
step: 540, loss: 0.12298499047756195
step: 550, loss: 0.02156924270093441
step: 560, loss: 0.07607480138540268
step: 570, loss: 0.022457420825958252
step: 580, loss: 0.0872497707605362
step: 590, loss: 0.019288241863250732
step: 600, loss: 0.015756770968437195
step: 610, loss: 0.08079684525728226
step: 620, loss: 0.06898429989814758
step: 630, loss: 0.08143440634012222
step: 640, loss: 0.19911549985408783
step: 650, loss: 0.21386554837226868
step: 660, loss: 0.08973381668329239
step: 670, loss: 0.1102127954363823
step: 680, loss: 0.05275123938918114
step: 690, loss: 0.03163911774754524
step: 700, loss: 0.09635234624147415
step: 710, loss: 0.18431448936462402
step: 720, loss: 0.06743907183408737
step: 730, loss: 0.035517845302820206
step: 740, loss: 0.032486747950315475
step: 750, loss: 0.007644373457878828
step: 760, loss: 0.13260717689990997
step: 770, loss: 0.15696799755096436
step: 780, loss: 0.06619417667388916
step: 790, loss: 0.0577402263879776
step: 800, loss: 0.10828421264886856
step: 810, loss: 0.0812920406460762
step: 820, loss: 0.08225160837173462
step: 830, loss: 0.06569214165210724
step: 840, loss: 0.0212022066116333
step: 850, loss: 0.20229820907115936
step: 860, loss: 0.07520889490842819
step: 870, loss: 0.08155696839094162
step: 880, loss: 0.05992613360285759
step: 890, loss: 0.00012164888175902888
step: 900, loss: 0.05370036140084267
step: 910, loss: 0.025611162185668945
step: 920, loss: 0.05954129621386528
step: 930, loss: 0.052441567182540894
step: 940, loss: 0.07158723473548889
step: 950, loss: 0.04494420066475868
step: 960, loss: 0.027721736580133438
step: 970, loss: 0.031496137380599976
step: 980, loss: 0.01927848346531391
step: 990, loss: 0.09479357302188873
step: 1000, loss: 0.052281130105257034
step: 1010, loss: 0.04847570136189461
step: 1020, loss: 0.017964821308851242
step: 1030, loss: 0.08036427944898605
step: 1040, loss: 0.08804142475128174
step: 1050, loss: 0.08926375955343246
step: 1060, loss: 0.06210539862513542
step: 1070, loss: 0.062071990221738815
epoch 4: dev_f1=0.9295112781954888, f1=0.9228624535315985, best_f1=0.9359963685882887
step: 0, loss: 0.12526825070381165
step: 10, loss: 0.07784993946552277
step: 20, loss: 0.003462372813373804
step: 30, loss: 0.08363917469978333
step: 40, loss: 0.014555616304278374
step: 50, loss: 0.1375086009502411
step: 60, loss: 0.019573861733078957
step: 70, loss: 0.02507832646369934
step: 80, loss: 0.009079483337700367
step: 90, loss: 0.04776126518845558
step: 100, loss: 0.10364741832017899
step: 110, loss: 0.006961663719266653
step: 120, loss: 0.08429297804832458
step: 130, loss: 0.03793290629982948
step: 140, loss: 0.00888508465141058
step: 150, loss: 0.017545733600854874
step: 160, loss: 0.015558912418782711
step: 170, loss: 0.14814868569374084
step: 180, loss: 0.09892990440130234
step: 190, loss: 0.05130605772137642
step: 200, loss: 0.03914833813905716
step: 210, loss: 0.05559469014406204
step: 220, loss: 0.04923863336443901
step: 230, loss: 0.0061357468366622925
step: 240, loss: 0.01165201235562563
step: 250, loss: 0.044859495013952255
step: 260, loss: 0.06308350712060928
step: 270, loss: 0.06356781721115112
step: 280, loss: 0.011208891868591309
step: 290, loss: 0.02169605903327465
step: 300, loss: 0.012019488960504532
step: 310, loss: 0.07529152929782867
step: 320, loss: 0.057015784084796906
step: 330, loss: 0.1404460221529007
step: 340, loss: 0.09771213680505753
step: 350, loss: 0.02044380083680153
step: 360, loss: 0.10541259497404099
step: 370, loss: 0.020688496530056
step: 380, loss: 0.09046637266874313
step: 390, loss: 0.1380368024110794
step: 400, loss: 0.0802869200706482
step: 410, loss: 0.07858707755804062
step: 420, loss: 0.1115555465221405
step: 430, loss: 0.07462935149669647
step: 440, loss: 0.00023545685689896345
step: 450, loss: 0.05782350152730942
step: 460, loss: 0.06631258875131607
step: 470, loss: 0.10944477468729019
step: 480, loss: 0.03325759619474411
step: 490, loss: 0.005135889630764723
step: 500, loss: 0.11404751986265182
step: 510, loss: 0.04949995130300522
step: 520, loss: 0.036432597786188126
step: 530, loss: 0.02335161529481411
step: 540, loss: 0.11549574136734009
step: 550, loss: 0.12360291182994843
step: 560, loss: 0.06463102996349335
step: 570, loss: 0.03857284411787987
step: 580, loss: 0.0068237618543207645
step: 590, loss: 0.12301439046859741
step: 600, loss: 0.08133682608604431
step: 610, loss: 0.10161074995994568
step: 620, loss: 0.03291928395628929
step: 630, loss: 0.09381823986768723
step: 640, loss: 0.1311996579170227
step: 650, loss: 0.0175738874822855
step: 660, loss: 0.01597118005156517
step: 670, loss: 0.19191908836364746
step: 680, loss: 0.05207419395446777
step: 690, loss: 0.04545758292078972
step: 700, loss: 0.06781809777021408
step: 710, loss: 0.014217223040759563
step: 720, loss: 0.05037447810173035
step: 730, loss: 0.12269444763660431
step: 740, loss: 0.02036428265273571
step: 750, loss: 0.01881229691207409
step: 760, loss: 0.10060843080282211
step: 770, loss: 0.07683566957712173
step: 780, loss: 0.018249671906232834
step: 790, loss: 0.012895098887383938
step: 800, loss: 0.1533111035823822
step: 810, loss: 0.039021085947752
step: 820, loss: 0.005095573142170906
step: 830, loss: 0.04931192845106125
step: 840, loss: 0.026379290968179703
step: 850, loss: 0.024815253913402557
step: 860, loss: 0.0564461387693882
step: 870, loss: 0.011107889004051685
step: 880, loss: 0.02076364867389202
step: 890, loss: 0.048309676349163055
step: 900, loss: 0.027820970863103867
step: 910, loss: 0.032665397971868515
step: 920, loss: 0.2345970720052719
step: 930, loss: 0.015063398517668247
step: 940, loss: 0.173638254404068
step: 950, loss: 0.12470071762800217
step: 960, loss: 0.009758919477462769
step: 970, loss: 0.01149709802120924
step: 980, loss: 0.012771881185472012
step: 990, loss: 0.010101529769599438
step: 1000, loss: 0.06777627021074295
step: 1010, loss: 0.06279663741588593
step: 1020, loss: 0.038534607738256454
step: 1030, loss: 0.042126599699258804
step: 1040, loss: 0.11126143485307693
step: 1050, loss: 0.0777929499745369
step: 1060, loss: 0.04210413992404938
step: 1070, loss: 0.01003818679600954
epoch 5: dev_f1=0.9374155785682124, f1=0.9320737741790374, best_f1=0.9320737741790374
step: 0, loss: 0.05846727639436722
step: 10, loss: 0.05653022229671478
step: 20, loss: 0.027048742398619652
step: 30, loss: 0.024219848215579987
step: 40, loss: 0.10217021405696869
step: 50, loss: 0.08493375778198242
step: 60, loss: 0.10927683860063553
step: 70, loss: 0.18638421595096588
step: 80, loss: 0.022991176694631577
step: 90, loss: 0.08119025826454163
step: 100, loss: 0.07047279179096222
step: 110, loss: 0.018043117597699165
step: 120, loss: 0.07723021507263184
step: 130, loss: 0.05153539031744003
step: 140, loss: 0.016304105520248413
step: 150, loss: 0.00515054352581501
step: 160, loss: 0.04095494747161865
step: 170, loss: 0.014609637670218945
step: 180, loss: 0.010432819835841656
step: 190, loss: 0.07430515438318253
step: 200, loss: 0.07263598591089249
step: 210, loss: 0.025458186864852905
step: 220, loss: 0.021038586273789406
step: 230, loss: 0.05504091829061508
step: 240, loss: 0.046825431287288666
step: 250, loss: 0.02088990993797779
step: 260, loss: 0.026469433680176735
step: 270, loss: 0.10851088166236877
step: 280, loss: 0.022096041589975357
step: 290, loss: 0.09657183289527893
step: 300, loss: 0.03504617139697075
step: 310, loss: 0.024248579517006874
step: 320, loss: 0.017731113359332085
step: 330, loss: 0.007858267985284328
step: 340, loss: 0.05486422777175903
step: 350, loss: 0.07884860783815384
step: 360, loss: 0.07696723937988281
step: 370, loss: 0.10376515984535217
step: 380, loss: 0.08665639162063599
step: 390, loss: 0.04636862501502037
step: 400, loss: 0.010450773872435093
step: 410, loss: 0.03228199854493141
step: 420, loss: 0.1113235354423523
step: 430, loss: 0.04907749220728874
step: 440, loss: 0.005380849353969097
step: 450, loss: 0.06533164530992508
step: 460, loss: 0.04726005718111992
step: 470, loss: 0.02437257394194603
step: 480, loss: 0.12092838436365128
step: 490, loss: 0.024610044434666634
step: 500, loss: 0.014695031568408012
step: 510, loss: 0.065946064889431
step: 520, loss: 0.012332049198448658
step: 530, loss: 0.06478382647037506
step: 540, loss: 0.05745618790388107
step: 550, loss: 0.011645177379250526
step: 560, loss: 0.017050841823220253
step: 570, loss: 0.006928597576916218
step: 580, loss: 0.06368628144264221
step: 590, loss: 0.08738982677459717
step: 600, loss: 0.1390647143125534
step: 610, loss: 0.036221008747816086
step: 620, loss: 0.022765150293707848
step: 630, loss: 0.06635285913944244
step: 640, loss: 0.0026345504447817802
step: 650, loss: 0.07966481894254684
step: 660, loss: 0.06531429290771484
step: 670, loss: 0.07110199332237244
step: 680, loss: 0.08220823854207993
step: 690, loss: 0.03276234492659569
step: 700, loss: 0.04438158497214317
step: 710, loss: 0.09881221503019333
step: 720, loss: 0.085017129778862
step: 730, loss: 0.100526824593544
step: 740, loss: 0.08928702026605606
step: 750, loss: 0.013545115478336811
step: 760, loss: 0.005595040507614613
step: 770, loss: 0.02910124883055687
step: 780, loss: 0.039030492305755615
step: 790, loss: 0.010597449727356434
step: 800, loss: 0.02520589344203472
step: 810, loss: 0.0507022999227047
step: 820, loss: 0.08453833311796188
step: 830, loss: 0.11005594581365585
step: 840, loss: 0.08948961645364761
step: 850, loss: 0.10974393784999847
step: 860, loss: 0.27493786811828613
step: 870, loss: 0.020430054515600204
step: 880, loss: 0.07178430259227753
step: 890, loss: 0.04749136045575142
step: 900, loss: 0.1265963315963745
step: 910, loss: 0.0834842100739479
step: 920, loss: 0.030446097254753113
step: 930, loss: 0.10966645926237106
step: 940, loss: 0.06131058931350708
step: 950, loss: 0.01561227161437273
step: 960, loss: 0.04230787232518196
step: 970, loss: 0.04264801740646362
step: 980, loss: 0.1493692398071289
step: 990, loss: 0.037325840443372726
step: 1000, loss: 0.019719157367944717
step: 1010, loss: 0.011609936133027077
step: 1020, loss: 0.062496963888406754
step: 1030, loss: 0.014176899567246437
step: 1040, loss: 0.15854515135288239
step: 1050, loss: 0.05025690421462059
step: 1060, loss: 0.28730231523513794
step: 1070, loss: 0.11734892427921295
epoch 6: dev_f1=0.9393382352941178, f1=0.936697247706422, best_f1=0.936697247706422
step: 0, loss: 0.03030318394303322
step: 10, loss: 0.009810316376388073
step: 20, loss: 0.03798036649823189
step: 30, loss: 0.06749813258647919
step: 40, loss: 0.08228220790624619
step: 50, loss: 0.1572052240371704
step: 60, loss: 0.019553713500499725
step: 70, loss: 0.134070485830307
step: 80, loss: 0.059001803398132324
step: 90, loss: 0.04455026984214783
step: 100, loss: 0.01704620011150837
step: 110, loss: 0.041238199919462204
step: 120, loss: 0.09459735453128815
step: 130, loss: 0.048176322132349014
step: 140, loss: 0.009992782026529312
step: 150, loss: 0.08633086085319519
step: 160, loss: 0.011221794411540031
step: 170, loss: 0.018885193392634392
step: 180, loss: 0.01306260097771883
step: 190, loss: 0.04922342672944069
step: 200, loss: 0.031427279114723206
step: 210, loss: 0.10742909461259842
step: 220, loss: 0.0730496272444725
step: 230, loss: 0.04045514017343521
step: 240, loss: 0.09788895398378372
step: 250, loss: 0.008012179285287857
step: 260, loss: 0.03645846247673035
step: 270, loss: 0.03273921459913254
step: 280, loss: 0.024205125868320465
step: 290, loss: 0.04934981092810631
step: 300, loss: 0.012953367084264755
step: 310, loss: 0.022832462564110756
step: 320, loss: 0.06278302520513535
step: 330, loss: 0.14857055246829987
step: 340, loss: 0.03211713954806328
step: 350, loss: 0.03505133092403412
step: 360, loss: 0.014047122560441494
step: 370, loss: 0.14406408369541168
step: 380, loss: 0.011197750456631184
step: 390, loss: 0.024229273200035095
step: 400, loss: 0.0138078723102808
step: 410, loss: 0.011987305246293545
step: 420, loss: 0.11720146983861923
step: 430, loss: 0.07097609341144562
step: 440, loss: 0.023856794461607933
step: 450, loss: 0.015456153079867363
step: 460, loss: 0.04126472771167755
step: 470, loss: 0.10099435597658157
step: 480, loss: 0.09964611381292343
step: 490, loss: 0.004415328614413738
step: 500, loss: 0.3233143091201782
step: 510, loss: 0.03318841755390167
step: 520, loss: 0.008010143414139748
step: 530, loss: 0.029391571879386902
step: 540, loss: 0.028223615139722824
step: 550, loss: 0.07578926533460617
step: 560, loss: 0.07132875174283981
step: 570, loss: 0.05475059524178505
step: 580, loss: 0.017633013427257538
step: 590, loss: 0.05212419480085373
step: 600, loss: 0.07286197692155838
step: 610, loss: 0.003190651535987854
step: 620, loss: 0.08013606071472168
step: 630, loss: 0.09524724632501602
step: 640, loss: 0.07939416170120239
step: 650, loss: 0.041885629296302795
step: 660, loss: 0.13464440405368805
step: 670, loss: 0.05234215781092644
step: 680, loss: 0.04708156734704971
step: 690, loss: 0.14917533099651337
step: 700, loss: 0.07435230910778046
step: 710, loss: 0.04936075210571289
step: 720, loss: 0.04669966921210289
step: 730, loss: 0.007131690625101328
step: 740, loss: 0.01005743257701397
step: 750, loss: 0.021863356232643127
step: 760, loss: 0.018486373126506805
step: 770, loss: 0.0030641816556453705
step: 780, loss: 0.006877476815134287
step: 790, loss: 0.020029455423355103
step: 800, loss: 0.053847987204790115
step: 810, loss: 0.040268976241350174
step: 820, loss: 0.10361972451210022
step: 830, loss: 0.2178504765033722
step: 840, loss: 0.0060645462945103645
step: 850, loss: 0.06509437412023544
step: 860, loss: 0.022299356758594513
step: 870, loss: 0.16896972060203552
step: 880, loss: 0.07880288362503052
step: 890, loss: 0.006438977085053921
step: 900, loss: 0.01167283020913601
step: 910, loss: 0.05388972535729408
step: 920, loss: 0.03745197504758835
step: 930, loss: 0.013313893228769302
step: 940, loss: 0.009614245966076851
step: 950, loss: 0.0024279223289340734
step: 960, loss: 0.010822197422385216
step: 970, loss: 0.07775294780731201
step: 980, loss: 0.041088297963142395
step: 990, loss: 0.05434480682015419
step: 1000, loss: 0.07053383439779282
step: 1010, loss: 0.08858177065849304
step: 1020, loss: 0.040181830525398254
step: 1030, loss: 0.15035225450992584
step: 1040, loss: 0.15903158485889435
step: 1050, loss: 0.13413815200328827
step: 1060, loss: 0.0369873009622097
step: 1070, loss: 0.025654198601841927
epoch 7: dev_f1=0.9433611884865365, f1=0.933271547729379, best_f1=0.933271547729379
step: 0, loss: 0.01873033307492733
step: 10, loss: 0.020246630534529686
step: 20, loss: 0.0009784132707864046
step: 30, loss: 0.019132783636450768
step: 40, loss: 0.015502160415053368
step: 50, loss: 0.17163924872875214
step: 60, loss: 0.03487631678581238
step: 70, loss: 0.0018811747431755066
step: 80, loss: 0.008069140836596489
step: 90, loss: 0.07692725211381912
step: 100, loss: 0.056008946150541306
step: 110, loss: 0.028914082795381546
step: 120, loss: 0.12831899523735046
step: 130, loss: 0.08037297427654266
step: 140, loss: 0.03694349527359009
step: 150, loss: 0.10761915892362595
step: 160, loss: 0.048212334513664246
step: 170, loss: 0.11316724121570587
step: 180, loss: 0.10057021677494049
step: 190, loss: 0.044486191123723984
step: 200, loss: 0.0070862784050405025
step: 210, loss: 0.1125994622707367
step: 220, loss: 0.04991600289940834
step: 230, loss: 0.0706985741853714
step: 240, loss: 0.027620771899819374
step: 250, loss: 0.05523272603750229
step: 260, loss: 0.0017554396763443947
step: 270, loss: 0.023752737790346146
step: 280, loss: 0.020538918673992157
step: 290, loss: 0.013478612527251244
step: 300, loss: 0.08994856476783752
step: 310, loss: 0.017537761479616165
step: 320, loss: 0.04560035094618797
step: 330, loss: 0.09936416149139404
step: 340, loss: 0.011260505765676498
step: 350, loss: 0.08075461536645889
step: 360, loss: 0.023884862661361694
step: 370, loss: 0.08941493183374405
step: 380, loss: 0.023506591096520424
step: 390, loss: 0.03799659013748169
step: 400, loss: 0.12991701066493988
step: 410, loss: 0.05156945064663887
step: 420, loss: 0.021961407735943794
step: 430, loss: 0.045964375138282776
step: 440, loss: 0.12805335223674774
step: 450, loss: 0.016023866832256317
step: 460, loss: 0.03395465016365051
step: 470, loss: 0.09869206696748734
step: 480, loss: 0.06441373378038406
step: 490, loss: 0.0036187213845551014
step: 500, loss: 0.042846571654081345
step: 510, loss: 0.09552352875471115
step: 520, loss: 0.13921992480754852
step: 530, loss: 0.03631412237882614
step: 540, loss: 0.009734459221363068
step: 550, loss: 0.07410214841365814
step: 560, loss: 0.062073588371276855
step: 570, loss: 0.00011176021507708356
step: 580, loss: 0.004063036292791367
step: 590, loss: 0.05832779407501221
step: 600, loss: 0.0006978908204473555
step: 610, loss: 0.0009305517305620015
step: 620, loss: 0.23181912302970886
step: 630, loss: 0.04819384217262268
step: 640, loss: 0.1342059075832367
step: 650, loss: 0.04833366349339485
step: 660, loss: 0.061434902250766754
step: 670, loss: 0.027548164129257202
step: 680, loss: 0.19951920211315155
step: 690, loss: 0.031812336295843124
step: 700, loss: 0.02703026682138443
step: 710, loss: 0.06297314912080765
step: 720, loss: 0.033802203834056854
step: 730, loss: 0.012017842382192612
step: 740, loss: 0.08253222703933716
step: 750, loss: 0.025007791817188263
step: 760, loss: 0.007979769259691238
step: 770, loss: 0.006677227094769478
step: 780, loss: 0.021822212263941765
step: 790, loss: 0.022541819140315056
step: 800, loss: 0.004033226985484362
step: 810, loss: 0.055770669132471085
step: 820, loss: 0.08962470293045044
step: 830, loss: 0.034455690532922745
step: 840, loss: 0.03612406924366951
step: 850, loss: 0.0017183463787660003
step: 860, loss: 0.025976337492465973
step: 870, loss: 0.030367286875844002
step: 880, loss: 0.022647416219115257
step: 890, loss: 0.26718616485595703
step: 900, loss: 0.025578461587429047
step: 910, loss: 0.045429032295942307
step: 920, loss: 0.017531506717205048
step: 930, loss: 0.04470343142747879
step: 940, loss: 0.026690423488616943
step: 950, loss: 0.1182020977139473
step: 960, loss: 0.10319584608078003
step: 970, loss: 0.04688790440559387
step: 980, loss: 0.14766010642051697
step: 990, loss: 0.03909787908196449
step: 1000, loss: 0.07701154053211212
step: 1010, loss: 0.03000754863023758
step: 1020, loss: 0.022933781147003174
step: 1030, loss: 0.09041939675807953
step: 1040, loss: 0.011942323297262192
step: 1050, loss: 0.048443812876939774
step: 1060, loss: 0.016348455101251602
step: 1070, loss: 0.06313400715589523
epoch 8: dev_f1=0.9310344827586207, f1=0.9269195189639223, best_f1=0.933271547729379
step: 0, loss: 0.08110898733139038
step: 10, loss: 0.1343606859445572
step: 20, loss: 0.02156580053269863
step: 30, loss: 0.03224540501832962
step: 40, loss: 0.009372971951961517
step: 50, loss: 0.035128071904182434
step: 60, loss: 0.08657049387693405
step: 70, loss: 0.048137713223695755
step: 80, loss: 0.04888511076569557
step: 90, loss: 0.09601393342018127
step: 100, loss: 0.013608803041279316
step: 110, loss: 0.006384754087775946
step: 120, loss: 0.1605486422777176
step: 130, loss: 0.04746311530470848
step: 140, loss: 0.05215013399720192
step: 150, loss: 0.27728933095932007
step: 160, loss: 0.09844530373811722
step: 170, loss: 0.0708388164639473
step: 180, loss: 0.12144714593887329
step: 190, loss: 0.038625024259090424
step: 200, loss: 0.05274367704987526
step: 210, loss: 0.05672973021864891
step: 220, loss: 0.007284508086740971
step: 230, loss: 0.01943889446556568
step: 240, loss: 0.06541457772254944
step: 250, loss: 0.06794680655002594
step: 260, loss: 0.06782230734825134
step: 270, loss: 0.00326025509275496
step: 280, loss: 0.08266714215278625
step: 290, loss: 0.051819153130054474
step: 300, loss: 0.01136783231049776
step: 310, loss: 0.03447699546813965
step: 320, loss: 0.024890772998332977
step: 330, loss: 0.0169528741389513
step: 340, loss: 0.02833816409111023
step: 350, loss: 0.0007754520629532635
step: 360, loss: 0.03410791978240013
step: 370, loss: 0.032111071050167084
step: 380, loss: 0.03747640177607536
step: 390, loss: 0.055258363485336304
step: 400, loss: 0.016966858878731728
step: 410, loss: 0.051208287477493286
step: 420, loss: 0.06380262970924377
step: 430, loss: 0.03512202203273773
step: 440, loss: 0.07729044556617737
step: 450, loss: 0.06278374791145325
step: 460, loss: 0.009919896721839905
step: 470, loss: 0.05665227770805359
step: 480, loss: 0.11900482326745987
step: 490, loss: 0.07020322978496552
step: 500, loss: 0.13004881143569946
step: 510, loss: 0.10817287117242813
step: 520, loss: 0.027538442984223366
step: 530, loss: 0.04134008288383484
step: 540, loss: 0.004859967157244682
step: 550, loss: 0.06657053530216217
step: 560, loss: 0.0427425280213356
step: 570, loss: 0.014485837891697884
step: 580, loss: 0.050004515796899796
step: 590, loss: 0.05473671108484268
step: 600, loss: 0.011124544776976109
step: 610, loss: 0.013061068952083588
step: 620, loss: 0.036591511219739914
step: 630, loss: 0.019180921837687492
step: 640, loss: 0.15903085470199585
step: 650, loss: 0.0061945985071361065
step: 660, loss: 0.1075579896569252
step: 670, loss: 0.11493299901485443
step: 680, loss: 0.016728337854146957
step: 690, loss: 0.001870779786258936
step: 700, loss: 0.031854212284088135
step: 710, loss: 0.04055347293615341
step: 720, loss: 0.089693583548069
step: 730, loss: 0.013075844384729862
step: 740, loss: 0.06087435781955719
step: 750, loss: 0.01080685667693615
step: 760, loss: 0.13481992483139038
step: 770, loss: 0.03737039491534233
step: 780, loss: 0.011625105515122414
step: 790, loss: 0.08071628957986832
step: 800, loss: 0.04454585164785385
step: 810, loss: 0.006510298233479261
step: 820, loss: 0.015900811180472374
step: 830, loss: 0.012817046605050564
step: 840, loss: 0.11319828033447266
step: 850, loss: 0.04038887470960617
step: 860, loss: 0.11500611901283264
step: 870, loss: 0.05948631092905998
step: 880, loss: 0.017518609762191772
step: 890, loss: 5.096830500406213e-05
step: 900, loss: 0.016021262854337692
step: 910, loss: 0.0005906230653636158
step: 920, loss: 0.0024427147582173347
step: 930, loss: 2.899307946790941e-05
step: 940, loss: 0.024978237226605415
step: 950, loss: 0.015514074824750423
step: 960, loss: 0.27077731490135193
step: 970, loss: 0.059059519320726395
step: 980, loss: 0.04756699129939079
step: 990, loss: 0.04947187751531601
step: 1000, loss: 0.001853280351497233
step: 1010, loss: 0.21074052155017853
step: 1020, loss: 0.033464811742305756
step: 1030, loss: 0.011523398570716381
step: 1040, loss: 0.06731727719306946
step: 1050, loss: 0.008180289529263973
step: 1060, loss: 0.0015953860711306334
step: 1070, loss: 0.015725335106253624
epoch 9: dev_f1=0.9374416433239963, f1=0.9353187529083293, best_f1=0.933271547729379
step: 0, loss: 0.03640821576118469
step: 10, loss: 0.11840209364891052
step: 20, loss: 0.040449850261211395
step: 30, loss: 0.003954493906348944
step: 40, loss: 0.0927283763885498
step: 50, loss: 0.0332673154771328
step: 60, loss: 0.038824502378702164
step: 70, loss: 0.027864644303917885
step: 80, loss: 0.002430700697004795
step: 90, loss: 0.06780510395765305
step: 100, loss: 0.07186015695333481
step: 110, loss: 0.09769183397293091
step: 120, loss: 0.030457738786935806
step: 130, loss: 0.041729021817445755
step: 140, loss: 0.002411406021565199
step: 150, loss: 0.008767673745751381
step: 160, loss: 0.023870298638939857
step: 170, loss: 0.030703246593475342
step: 180, loss: 0.01880553923547268
step: 190, loss: 0.05218810588121414
step: 200, loss: 0.04347306862473488
step: 210, loss: 0.001092748250812292
step: 220, loss: 0.010570739395916462
step: 230, loss: 0.03879423439502716
step: 240, loss: 0.046282388269901276
step: 250, loss: 0.04750850424170494
step: 260, loss: 0.004303258843719959
step: 270, loss: 0.00802129041403532
step: 280, loss: 0.02240883745253086
step: 290, loss: 0.004501506220549345
step: 300, loss: 0.04066236689686775
step: 310, loss: 0.021383080631494522
step: 320, loss: 0.008242161013185978
step: 330, loss: 0.16456125676631927
step: 340, loss: 0.00564913684502244
step: 350, loss: 0.007297471631318331
step: 360, loss: 0.008685051463544369
step: 370, loss: 0.04870889335870743
step: 380, loss: 0.09570977091789246
step: 390, loss: 0.000261891313130036
step: 400, loss: 0.04031267762184143
step: 410, loss: 0.046140242367982864
step: 420, loss: 0.03834189474582672
step: 430, loss: 0.012581472285091877
step: 440, loss: 0.00811772421002388
step: 450, loss: 0.10654465854167938
step: 460, loss: 0.055934663861989975
step: 470, loss: 0.05915309116244316
step: 480, loss: 0.03296105936169624
step: 490, loss: 0.027876917272806168
step: 500, loss: 0.00775807024911046
step: 510, loss: 0.048413291573524475
step: 520, loss: 0.06536052376031876
step: 530, loss: 0.0357077457010746
step: 540, loss: 0.00924225989729166
step: 550, loss: 0.029373852536082268
step: 560, loss: 0.05594414100050926
step: 570, loss: 0.08516891300678253
step: 580, loss: 0.08065884560346603
step: 590, loss: 0.0617225356400013
step: 600, loss: 0.02631499618291855
step: 610, loss: 0.058443475514650345
step: 620, loss: 0.000350528716808185
step: 630, loss: 0.00827210396528244
step: 640, loss: 0.06625833362340927
step: 650, loss: 0.004713681526482105
step: 660, loss: 0.016786161810159683
step: 670, loss: 0.06859681755304337
step: 680, loss: 0.05683350935578346
step: 690, loss: 0.08332553505897522
step: 700, loss: 0.025768931955099106
step: 710, loss: 0.013930544257164001
step: 720, loss: 0.0003522583865560591
step: 730, loss: 0.09064563363790512
step: 740, loss: 0.0001228122564498335
step: 750, loss: 0.015006400644779205
step: 760, loss: 0.014396892860531807
step: 770, loss: 0.11933583766222
step: 780, loss: 0.027718769386410713
step: 790, loss: 0.03283204883337021
step: 800, loss: 0.06282375752925873
step: 810, loss: 0.00758650666102767
step: 820, loss: 0.08731836080551147
step: 830, loss: 0.06307389587163925
step: 840, loss: 0.04552387818694115
step: 850, loss: 0.057429734617471695
step: 860, loss: 0.11933253705501556
step: 870, loss: 0.06870013475418091
step: 880, loss: 0.08598261326551437
step: 890, loss: 0.023594317957758904
step: 900, loss: 0.048320699483156204
step: 910, loss: 0.05720692127943039
step: 920, loss: 0.00041129806777462363
step: 930, loss: 0.05473540723323822
step: 940, loss: 0.02166025899350643
step: 950, loss: 0.0018161870539188385
step: 960, loss: 0.017325712367892265
step: 970, loss: 0.11130103468894958
step: 980, loss: 0.16237668693065643
step: 990, loss: 0.03870745003223419
step: 1000, loss: 0.01691998541355133
step: 1010, loss: 0.018334288150072098
step: 1020, loss: 0.046201933175325394
step: 1030, loss: 0.18899837136268616
step: 1040, loss: 0.11799986660480499
step: 1050, loss: 0.03218324854969978
step: 1060, loss: 0.013539592735469341
step: 1070, loss: 0.04688088595867157
epoch 10: dev_f1=0.9412304866850323, f1=0.9375284997720018, best_f1=0.933271547729379
step: 0, loss: 0.04846613109111786
step: 10, loss: 0.024608833715319633
step: 20, loss: 0.05279330536723137
step: 30, loss: 0.009080102667212486
step: 40, loss: 0.007522901054471731
step: 50, loss: 0.013750266283750534
step: 60, loss: 0.012351789511740208
step: 70, loss: 0.007188672199845314
step: 80, loss: 0.06935877352952957
step: 90, loss: 0.011345542035996914
step: 100, loss: 0.14806121587753296
step: 110, loss: 0.04684438928961754
step: 120, loss: 0.12083563953638077
step: 130, loss: 0.0108867222443223
step: 140, loss: 0.03666181489825249
step: 150, loss: 0.059770915657281876
step: 160, loss: 0.05659591034054756
step: 170, loss: 6.243459938559681e-05
step: 180, loss: 0.0008279049070551991
step: 190, loss: 0.00860591046512127
step: 200, loss: 0.09778297692537308
step: 210, loss: 0.07958460599184036
step: 220, loss: 0.015016757883131504
step: 230, loss: 0.029014557600021362
step: 240, loss: 0.09450090676546097
step: 250, loss: 0.0579790323972702
step: 260, loss: 0.07040244340896606
step: 270, loss: 0.08360892534255981
step: 280, loss: 0.038802992552518845
step: 290, loss: 0.07293257117271423
step: 300, loss: 0.0021112626418471336
step: 310, loss: 0.07050098478794098
step: 320, loss: 0.014744296669960022
step: 330, loss: 0.03609323501586914
step: 340, loss: 0.10875317454338074
step: 350, loss: 0.021356789395213127
step: 360, loss: 0.033849336206912994
step: 370, loss: 0.010406033135950565
step: 380, loss: 0.03489860147237778
step: 390, loss: 0.03716622665524483
step: 400, loss: 0.03149512782692909
step: 410, loss: 0.08510614186525345
step: 420, loss: 6.14007658441551e-05
step: 430, loss: 0.028632406145334244
step: 440, loss: 0.01997489668428898
step: 450, loss: 0.0007143718539737165
step: 460, loss: 0.008072725497186184
step: 470, loss: 0.025926407426595688
step: 480, loss: 0.03961263969540596
step: 490, loss: 0.05049579590559006
step: 500, loss: 0.11048935353755951
step: 510, loss: 0.01878928579390049
step: 520, loss: 0.09728505462408066
step: 530, loss: 0.01154819130897522
step: 540, loss: 0.01379724033176899
step: 550, loss: 0.05187085643410683
step: 560, loss: 0.015712687745690346
step: 570, loss: 0.05370098352432251
step: 580, loss: 0.044327519834041595
step: 590, loss: 0.003484573680907488
step: 600, loss: 0.008366863243281841
step: 610, loss: 0.12360337376594543
step: 620, loss: 0.12125765532255173
step: 630, loss: 0.02691345289349556
step: 640, loss: 0.038644615560770035
step: 650, loss: 0.2561739683151245
step: 660, loss: 0.011849815957248211
step: 670, loss: 0.07905851304531097
step: 680, loss: 0.008383061736822128
step: 690, loss: 0.06828082352876663
step: 700, loss: 0.012141035869717598
step: 710, loss: 0.007579440716654062
step: 720, loss: 0.03551977500319481
step: 730, loss: 0.018974151462316513
step: 740, loss: 0.0013617522781714797
step: 750, loss: 0.03532223775982857
step: 760, loss: 0.08176345378160477
step: 770, loss: 0.010352835059165955
step: 780, loss: 0.07267593592405319
step: 790, loss: 0.06089163199067116
step: 800, loss: 0.09807091951370239
step: 810, loss: 0.05676285922527313
step: 820, loss: 0.03682929277420044
step: 830, loss: 0.09744074195623398
step: 840, loss: 0.029953155666589737
step: 850, loss: 0.019611267372965813
step: 860, loss: 0.03667484596371651
step: 870, loss: 0.10658670961856842
step: 880, loss: 0.004010919481515884
step: 890, loss: 0.012223952449858189
step: 900, loss: 0.023998891934752464
step: 910, loss: 0.027073757722973824
step: 920, loss: 0.037313420325517654
step: 930, loss: 0.005193475633859634
step: 940, loss: 0.031050559133291245
step: 950, loss: 0.017698535695672035
step: 960, loss: 0.03786834701895714
step: 970, loss: 0.04969220235943794
step: 980, loss: 0.09681157767772675
step: 990, loss: 0.02801356464624405
step: 1000, loss: 0.025858959183096886
step: 1010, loss: 0.03423484042286873
step: 1020, loss: 0.03294091299176216
step: 1030, loss: 0.0019031553529202938
step: 1040, loss: 0.026056071743369102
step: 1050, loss: 0.01825167052447796
step: 1060, loss: 0.06265586614608765
step: 1070, loss: 0.009024829603731632
epoch 11: dev_f1=0.937471051412691, f1=0.9314179796107508, best_f1=0.933271547729379
step: 0, loss: 0.09150874614715576
step: 10, loss: 0.04202562943100929
step: 20, loss: 0.057840682566165924
step: 30, loss: 0.03827352821826935
step: 40, loss: 0.056248731911182404
step: 50, loss: 0.015979068353772163
step: 60, loss: 0.05975343659520149
step: 70, loss: 0.02366958186030388
step: 80, loss: 0.046528615057468414
step: 90, loss: 0.08860465884208679
step: 100, loss: 0.01806841790676117
step: 110, loss: 0.006779711227864027
step: 120, loss: 0.04497525095939636
step: 130, loss: 0.0186185110360384
step: 140, loss: 0.04590624198317528
step: 150, loss: 0.0004730968503281474
step: 160, loss: 0.05945716053247452
step: 170, loss: 0.011454969644546509
step: 180, loss: 0.1465023010969162
step: 190, loss: 0.04925250634551048
step: 200, loss: 0.041320230811834335
step: 210, loss: 0.07442540675401688
step: 220, loss: 0.06329052150249481
step: 230, loss: 0.03074672445654869
step: 240, loss: 0.008250963874161243
step: 250, loss: 0.0640120878815651
step: 260, loss: 0.0005108577897772193
step: 270, loss: 0.08119018375873566
step: 280, loss: 0.003501374740153551
step: 290, loss: 0.035930000245571136
step: 300, loss: 0.029326729476451874
step: 310, loss: 0.05640726163983345
step: 320, loss: 0.02483365312218666
step: 330, loss: 0.026278439909219742
step: 340, loss: 0.07360965758562088
step: 350, loss: 0.01982594095170498
step: 360, loss: 0.03557756915688515
step: 370, loss: 0.05334409326314926
step: 380, loss: 0.048029690980911255
step: 390, loss: 0.0033837133087217808
step: 400, loss: 0.010531903244554996
step: 410, loss: 0.04058203473687172
step: 420, loss: 0.0018973187543451786
step: 430, loss: 0.17221884429454803
step: 440, loss: 0.10841746628284454
step: 450, loss: 0.03977978229522705
step: 460, loss: 0.07750771939754486
step: 470, loss: 0.026334861293435097
step: 480, loss: 0.022644909098744392
step: 490, loss: 0.02572985179722309
step: 500, loss: 0.08911671489477158
step: 510, loss: 0.017489371821284294
step: 520, loss: 0.00917962659150362
step: 530, loss: 0.01829509623348713
step: 540, loss: 0.018608637154102325
step: 550, loss: 0.0009559619356878102
step: 560, loss: 0.0029644127935171127
step: 570, loss: 0.04751099646091461
step: 580, loss: 0.005250662099570036
step: 590, loss: 0.02119474671781063
step: 600, loss: 0.03312023729085922
step: 610, loss: 0.053408607840538025
step: 620, loss: 0.001969026168808341
step: 630, loss: 0.13674548268318176
step: 640, loss: 0.0034699924290180206
step: 650, loss: 0.011762578040361404
step: 660, loss: 0.05516032502055168
step: 670, loss: 0.0010117143392562866
step: 680, loss: 0.06555669009685516
step: 690, loss: 0.03446301445364952
step: 700, loss: 0.02692563086748123
step: 710, loss: 0.008346487767994404
step: 720, loss: 0.014269030652940273
step: 730, loss: 0.012882925570011139
step: 740, loss: 0.027857450768351555
step: 750, loss: 0.019393373280763626
step: 760, loss: 0.011529682204127312
step: 770, loss: 0.0020753040444105864
step: 780, loss: 0.055102210491895676
step: 790, loss: 0.024549949914216995
step: 800, loss: 0.033811528235673904
step: 810, loss: 0.025399282574653625
step: 820, loss: 0.044117823243141174
step: 830, loss: 0.00012455403339117765
step: 840, loss: 0.00033412480843253434
step: 850, loss: 0.023336930200457573
step: 860, loss: 0.001464794622734189
step: 870, loss: 0.1567377746105194
step: 880, loss: 0.0014827142003923655
step: 890, loss: 0.08533066511154175
step: 900, loss: 0.028950905427336693
step: 910, loss: 0.02421071007847786
step: 920, loss: 0.047536905854940414
step: 930, loss: 0.035751860588788986
step: 940, loss: 0.03268097713589668
step: 950, loss: 0.0003094710409641266
step: 960, loss: 0.03355783969163895
step: 970, loss: 4.2786381527548656e-05
step: 980, loss: 0.042670249938964844
step: 990, loss: 0.1294376701116562
step: 1000, loss: 0.04104573652148247
step: 1010, loss: 0.019277730956673622
step: 1020, loss: 0.026247218251228333
step: 1030, loss: 0.0452614426612854
step: 1040, loss: 0.011525612324476242
step: 1050, loss: 0.10126351565122604
step: 1060, loss: 0.10076886415481567
step: 1070, loss: 0.006555031519383192
epoch 12: dev_f1=0.9352319706017456, f1=0.9363261566651397, best_f1=0.933271547729379
step: 0, loss: 0.03198816254734993
step: 10, loss: 0.07213883101940155
step: 20, loss: 0.0018613339634612203
step: 30, loss: 0.030641449615359306
step: 40, loss: 0.057852257043123245
step: 50, loss: 0.05588306859135628
step: 60, loss: 0.0003563019563443959
step: 70, loss: 0.0002820554072968662
step: 80, loss: 0.021073199808597565
step: 90, loss: 0.031234892085194588
step: 100, loss: 0.029522351920604706
step: 110, loss: 0.04148806259036064
step: 120, loss: 0.07702406495809555
step: 130, loss: 0.03290252760052681
step: 140, loss: 0.01596204563975334
step: 150, loss: 0.0004950376460328698
step: 160, loss: 0.029748622328042984
step: 170, loss: 0.042094986885786057
step: 180, loss: 0.15642708539962769
step: 190, loss: 0.026730507612228394
step: 200, loss: 0.03664415702223778
step: 210, loss: 0.03330112248659134
step: 220, loss: 0.034906789660453796
step: 230, loss: 0.035422082990407944
step: 240, loss: 0.013890059664845467
step: 250, loss: 0.04659893363714218
step: 260, loss: 0.07352502644062042
step: 270, loss: 0.038513097912073135
step: 280, loss: 0.03725866973400116
step: 290, loss: 0.05929733067750931
step: 300, loss: 0.04417511820793152
step: 310, loss: 0.043714676052331924
step: 320, loss: 0.0017529611941426992
step: 330, loss: 0.0036452519707381725
step: 340, loss: 0.07885799556970596
step: 350, loss: 0.00041687191696837544
step: 360, loss: 0.05114283785223961
step: 370, loss: 0.04727187752723694
step: 380, loss: 0.06073061004281044
step: 390, loss: 0.056388162076473236
step: 400, loss: 0.020879670977592468
step: 410, loss: 0.06888487190008163
step: 420, loss: 0.041153497993946075
step: 430, loss: 0.052389297634363174
step: 440, loss: 0.020486148074269295
step: 450, loss: 0.0001965742849279195
step: 460, loss: 0.011863108724355698
step: 470, loss: 0.0009144296636804938
step: 480, loss: 0.08890519291162491
step: 490, loss: 0.006749704480171204
step: 500, loss: 0.04161671921610832
step: 510, loss: 0.030060766264796257
step: 520, loss: 0.11569897085428238
step: 530, loss: 0.013050842098891735
step: 540, loss: 0.05241013318300247
step: 550, loss: 0.03521139174699783
step: 560, loss: 0.005333294626325369
step: 570, loss: 0.00022185090347193182
step: 580, loss: 0.037162959575653076
step: 590, loss: 0.09562519937753677
step: 600, loss: 0.02905403822660446
step: 610, loss: 0.0012287301942706108
step: 620, loss: 0.05475703999400139
step: 630, loss: 4.4630585762206465e-05
step: 640, loss: 0.022754285484552383
step: 650, loss: 0.00038150622276589274
step: 660, loss: 0.06800538301467896
step: 670, loss: 0.049053870141506195
step: 680, loss: 0.027652563527226448
step: 690, loss: 0.04104846343398094
step: 700, loss: 0.016324859112501144
step: 710, loss: 0.15301920473575592
step: 720, loss: 7.188293966464698e-05
step: 730, loss: 0.011449395678937435
step: 740, loss: 0.0016914353473111987
step: 750, loss: 0.029666151851415634
step: 760, loss: 0.021996479481458664
step: 770, loss: 0.01891796849668026
step: 780, loss: 9.92095738183707e-05
step: 790, loss: 0.00609581358730793
step: 800, loss: 0.019442448392510414
step: 810, loss: 0.005816658493131399
step: 820, loss: 0.08151399344205856
step: 830, loss: 0.007082586642354727
step: 840, loss: 0.0014102287823334336
step: 850, loss: 0.038706161081790924
step: 860, loss: 0.07071216404438019
step: 870, loss: 0.022646721452474594
step: 880, loss: 6.027631388860755e-05
step: 890, loss: 0.036940138787031174
step: 900, loss: 0.0561043843626976
step: 910, loss: 0.04596938192844391
step: 920, loss: 0.09313955903053284
step: 930, loss: 0.032370392233133316
step: 940, loss: 0.0011547753820195794
step: 950, loss: 0.042269427329301834
step: 960, loss: 0.05894381180405617
step: 970, loss: 0.06799888610839844
step: 980, loss: 0.08395861834287643
step: 990, loss: 0.04556155204772949
step: 1000, loss: 0.06134188920259476
step: 1010, loss: 0.0001961154630407691
step: 1020, loss: 0.00038942531682550907
step: 1030, loss: 8.895806240616366e-05
step: 1040, loss: 0.013632671907544136
step: 1050, loss: 0.0032199302222579718
step: 1060, loss: 0.03562132641673088
step: 1070, loss: 0.013559523969888687
epoch 13: dev_f1=0.9384191176470588, f1=0.9357798165137614, best_f1=0.933271547729379
step: 0, loss: 0.02134598046541214
step: 10, loss: 0.06407777965068817
step: 20, loss: 0.022082757204771042
step: 30, loss: 0.19673341512680054
step: 40, loss: 0.00041287936619482934
step: 50, loss: 0.009773551486432552
step: 60, loss: 0.10024292767047882
step: 70, loss: 0.0049135684967041016
step: 80, loss: 0.03841136768460274
step: 90, loss: 0.03595472127199173
step: 100, loss: 0.041214097291231155
step: 110, loss: 0.002037322148680687
step: 120, loss: 0.03486279770731926
step: 130, loss: 0.0004971352173015475
step: 140, loss: 0.022006846964359283
step: 150, loss: 0.025770779699087143
step: 160, loss: 0.005730629898607731
step: 170, loss: 0.027553308755159378
step: 180, loss: 0.04294825717806816
step: 190, loss: 0.040438540279865265
step: 200, loss: 0.00045490445336326957
step: 210, loss: 0.03681069239974022
step: 220, loss: 1.2092207725800108e-05
step: 230, loss: 0.0016473210416734219
step: 240, loss: 7.281216676346958e-05
step: 250, loss: 0.056382063776254654
step: 260, loss: 0.0006867056363262236
step: 270, loss: 0.04823782294988632
step: 280, loss: 0.036135606467723846
step: 290, loss: 2.8903030397486873e-05
step: 300, loss: 0.0040428596548736095
step: 310, loss: 0.04970820993185043
step: 320, loss: 0.017800234258174896
step: 330, loss: 0.0002288640826009214
step: 340, loss: 0.03594532981514931
step: 350, loss: 0.015087072737514973
step: 360, loss: 0.005838390905410051
step: 370, loss: 0.01734512485563755
step: 380, loss: 0.10162751376628876
step: 390, loss: 0.06591454148292542
step: 400, loss: 0.03457751125097275
step: 410, loss: 0.08088717609643936
step: 420, loss: 0.058496102690696716
step: 430, loss: 0.0023926778230816126
step: 440, loss: 0.00022000778699293733
step: 450, loss: 0.004247330594807863
step: 460, loss: 0.0002916485827881843
step: 470, loss: 0.02218763902783394
step: 480, loss: 0.03424116596579552
step: 490, loss: 0.04055215045809746
step: 500, loss: 0.06743906438350677
step: 510, loss: 0.02153785526752472
step: 520, loss: 0.0014254178386181593
step: 530, loss: 0.00040966394590213895
step: 540, loss: 0.03721073269844055
step: 550, loss: 0.07351796329021454
step: 560, loss: 0.029715245589613914
step: 570, loss: 0.05891293287277222
step: 580, loss: 0.07123735547065735
step: 590, loss: 0.036224640905857086
step: 600, loss: 0.0829315185546875
step: 610, loss: 0.027852095663547516
step: 620, loss: 0.0007228833856061101
step: 630, loss: 0.038385059684515
step: 640, loss: 0.018774934113025665
step: 650, loss: 0.06492451578378677
step: 660, loss: 0.07825753092765808
step: 670, loss: 0.08254925906658173
step: 680, loss: 0.001399650820530951
step: 690, loss: 0.04258519038558006
step: 700, loss: 0.03726847842335701
step: 710, loss: 0.00429138820618391
step: 720, loss: 0.03020613081753254
step: 730, loss: 0.06995341181755066
step: 740, loss: 0.020964961498975754
step: 750, loss: 0.03431390970945358
step: 760, loss: 0.02075641043484211
step: 770, loss: 0.15837711095809937
step: 780, loss: 0.07830837368965149
step: 790, loss: 0.011912498623132706
step: 800, loss: 0.06650259345769882
step: 810, loss: 0.039929673075675964
step: 820, loss: 0.048683203756809235
step: 830, loss: 0.03867713734507561
step: 840, loss: 0.019957585260272026
step: 850, loss: 0.06630222499370575
step: 860, loss: 0.05839903652667999
step: 870, loss: 3.168080365867354e-05
step: 880, loss: 0.01482133287936449
step: 890, loss: 0.012916043400764465
step: 900, loss: 8.472926856484264e-05
step: 910, loss: 0.14528048038482666
step: 920, loss: 0.03732403740286827
step: 930, loss: 0.05758370831608772
step: 940, loss: 0.042045965790748596
step: 950, loss: 0.0001806407526601106
step: 960, loss: 0.020959017798304558
step: 970, loss: 0.04210849478840828
step: 980, loss: 0.012155700474977493
step: 990, loss: 0.03789030760526657
step: 1000, loss: 1.3731226317759138e-05
step: 1010, loss: 0.0800408199429512
step: 1020, loss: 0.03057028539478779
step: 1030, loss: 0.026942577213048935
step: 1040, loss: 0.07345732301473618
step: 1050, loss: 0.02889665775001049
step: 1060, loss: 0.0004443168290890753
step: 1070, loss: 0.08972949534654617
epoch 14: dev_f1=0.9352451433857539, f1=0.9333950046253469, best_f1=0.933271547729379
step: 0, loss: 0.0005270810797810555
step: 10, loss: 0.00010399834718555212
step: 20, loss: 0.035865284502506256
step: 30, loss: 0.008548727259039879
step: 40, loss: 0.06130119413137436
step: 50, loss: 0.05753599479794502
step: 60, loss: 0.08824839442968369
step: 70, loss: 0.005525702144950628
step: 80, loss: 0.00020738116290885955
step: 90, loss: 2.0022849639644846e-05
step: 100, loss: 0.024352652952075005
step: 110, loss: 0.054482653737068176
step: 120, loss: 0.025808630511164665
step: 130, loss: 0.11785425990819931
step: 140, loss: 0.021416278555989265
step: 150, loss: 0.004381840117275715
step: 160, loss: 0.00017861476226244122
step: 170, loss: 0.028773343190550804
step: 180, loss: 0.0003313149500172585
step: 190, loss: 0.018693728372454643
step: 200, loss: 0.027086224406957626
step: 210, loss: 0.054304338991642
step: 220, loss: 0.04503076151013374
step: 230, loss: 0.03977922350168228
step: 240, loss: 0.02380828559398651
step: 250, loss: 0.02987864427268505
step: 260, loss: 0.0004372629337012768
step: 270, loss: 0.022100867703557014
step: 280, loss: 0.06493161618709564
step: 290, loss: 2.0432491510291584e-05
step: 300, loss: 0.01596616767346859
step: 310, loss: 0.030006293207406998
step: 320, loss: 0.02317076176404953
step: 330, loss: 0.006359393242746592
step: 340, loss: 0.05112993344664574
step: 350, loss: 0.04539928585290909
step: 360, loss: 0.021464752033352852
step: 370, loss: 2.0671037418651395e-05
step: 380, loss: 0.021814996376633644
step: 390, loss: 3.1563649827148765e-05
step: 400, loss: 0.00016185369167942554
step: 410, loss: 0.051117878407239914
step: 420, loss: 0.00040277495281770825
step: 430, loss: 0.004022074863314629
step: 440, loss: 0.0005680222529917955
step: 450, loss: 0.07483863085508347
step: 460, loss: 0.03851154446601868
step: 470, loss: 2.497276000212878e-05
step: 480, loss: 0.023107245564460754
step: 490, loss: 0.042627401649951935
step: 500, loss: 0.02103273756802082
step: 510, loss: 0.04666046425700188
step: 520, loss: 0.02218894474208355
step: 530, loss: 0.02636152319610119
step: 540, loss: 0.05884471908211708
step: 550, loss: 0.03039594553411007
step: 560, loss: 0.00013823897461406887
step: 570, loss: 0.026406697928905487
step: 580, loss: 0.024280201643705368
step: 590, loss: 0.020055469125509262
step: 600, loss: 0.029140716418623924
step: 610, loss: 0.06193822994828224
step: 620, loss: 3.1549003324471414e-05
step: 630, loss: 0.03545932471752167
step: 640, loss: 0.03550422936677933
step: 650, loss: 0.08359304070472717
step: 660, loss: 0.04531826451420784
step: 670, loss: 0.009326847270131111
step: 680, loss: 0.011461409740149975
step: 690, loss: 0.16914069652557373
step: 700, loss: 0.045825693756341934
step: 710, loss: 0.03142932057380676
step: 720, loss: 0.06947362422943115
step: 730, loss: 0.07257146388292313
step: 740, loss: 0.0810537114739418
step: 750, loss: 0.03782226890325546
step: 760, loss: 0.0003635449684225023
step: 770, loss: 0.027286536991596222
step: 780, loss: 0.1078270822763443
step: 790, loss: 0.002359426114708185
step: 800, loss: 0.022107677534222603
step: 810, loss: 0.07420836389064789
step: 820, loss: 0.01866839826107025
step: 830, loss: 4.098420322407037e-05
step: 840, loss: 0.04192516580224037
step: 850, loss: 0.03247474133968353
step: 860, loss: 0.048370566219091415
step: 870, loss: 0.0006440369761548936
step: 880, loss: 0.014847006648778915
step: 890, loss: 0.06835871934890747
step: 900, loss: 0.04306494817137718
step: 910, loss: 0.06900538504123688
step: 920, loss: 0.024370217695832253
step: 930, loss: 4.524291216512211e-05
step: 940, loss: 2.0826781110372394e-05
step: 950, loss: 0.0735921561717987
step: 960, loss: 0.10612326115369797
step: 970, loss: 0.07347988337278366
step: 980, loss: 0.027699101716279984
step: 990, loss: 0.012508846819400787
step: 1000, loss: 0.0696696937084198
step: 1010, loss: 1.8465763787389733e-05
step: 1020, loss: 0.028322095051407814
step: 1030, loss: 0.04723634570837021
step: 1040, loss: 0.049232762306928635
step: 1050, loss: 0.044773638248443604
step: 1060, loss: 0.023868542164564133
step: 1070, loss: 0.00016104413953144103
epoch 15: dev_f1=0.9341983317886932, f1=0.9327188940092166, best_f1=0.933271547729379
step: 0, loss: 0.04845667630434036
step: 10, loss: 0.023132145404815674
step: 20, loss: 0.045387834310531616
step: 30, loss: 0.03270857408642769
step: 40, loss: 0.027790024876594543
step: 50, loss: 0.0574583001434803
step: 60, loss: 0.04254354164004326
step: 70, loss: 0.021888401359319687
step: 80, loss: 0.043579068034887314
step: 90, loss: 0.017608826979994774
step: 100, loss: 0.002683469792827964
step: 110, loss: 0.00026088321465067565
step: 120, loss: 0.024961048737168312
step: 130, loss: 0.07063908874988556
step: 140, loss: 0.04134852811694145
step: 150, loss: 0.0006574784056283534
step: 160, loss: 0.01650046557188034
step: 170, loss: 0.04404633864760399
step: 180, loss: 4.2718973418232054e-05
step: 190, loss: 0.025247029960155487
step: 200, loss: 0.09489897638559341
step: 210, loss: 0.04759418964385986
step: 220, loss: 0.030295977368950844
step: 230, loss: 0.009615079499781132
step: 240, loss: 0.0012727525318041444
step: 250, loss: 0.05322130024433136
step: 260, loss: 0.024692770093679428
step: 270, loss: 0.0697346180677414
step: 280, loss: 0.03602135553956032
step: 290, loss: 0.09648430347442627
step: 300, loss: 0.02613680623471737
step: 310, loss: 0.018040498718619347
step: 320, loss: 0.0008474468486383557
step: 330, loss: 5.497012170962989e-05
step: 340, loss: 2.1966960048303008e-05
step: 350, loss: 0.006074825301766396
step: 360, loss: 0.003975169267505407
step: 370, loss: 0.05853203311562538
step: 380, loss: 0.009095900692045689
step: 390, loss: 0.04609645903110504
step: 400, loss: 5.979657726129517e-05
step: 410, loss: 0.040491994470357895
step: 420, loss: 0.011153755709528923
step: 430, loss: 0.00015114335110411048
step: 440, loss: 0.018534783273935318
step: 450, loss: 0.0001275985559914261
step: 460, loss: 0.016159964725375175
step: 470, loss: 0.019900819286704063
step: 480, loss: 0.0916115939617157
step: 490, loss: 0.039421871304512024
step: 500, loss: 0.060985177755355835
step: 510, loss: 0.058798763900995255
step: 520, loss: 0.0013424069620668888
step: 530, loss: 0.08951971679925919
step: 540, loss: 0.039261169731616974
step: 550, loss: 0.2732919752597809
step: 560, loss: 7.975433982210234e-05
step: 570, loss: 0.01394130103290081
step: 580, loss: 0.06152956187725067
step: 590, loss: 0.018875397741794586
step: 600, loss: 7.787373760947958e-05
step: 610, loss: 0.028033189475536346
step: 620, loss: 0.04011959582567215
step: 630, loss: 0.0009660404175519943
step: 640, loss: 5.9725945902755484e-05
step: 650, loss: 1.4532158274960238e-05
step: 660, loss: 0.0921541228890419
step: 670, loss: 0.03221481665968895
step: 680, loss: 0.05412396043539047
step: 690, loss: 0.019959045574069023
step: 700, loss: 0.03406406193971634
step: 710, loss: 0.010519455187022686
step: 720, loss: 0.07319875806570053
step: 730, loss: 0.005108300130814314
step: 740, loss: 0.05719147250056267
step: 750, loss: 0.04062771052122116
step: 760, loss: 0.11050110310316086
step: 770, loss: 0.047881003469228745
step: 780, loss: 0.023589270189404488
step: 790, loss: 0.020262286067008972
step: 800, loss: 0.0022487568203359842
step: 810, loss: 0.04066343605518341
step: 820, loss: 0.06299669295549393
step: 830, loss: 0.044400814920663834
step: 840, loss: 0.036417730152606964
step: 850, loss: 0.02407505363225937
step: 860, loss: 2.1024668967584148e-05
step: 870, loss: 0.03382048010826111
step: 880, loss: 0.017756491899490356
step: 890, loss: 2.88023948087357e-05
step: 900, loss: 0.0006602680077776313
step: 910, loss: 0.030519943684339523
step: 920, loss: 0.0972789078950882
step: 930, loss: 0.029934674501419067
step: 940, loss: 0.04342151805758476
step: 950, loss: 3.6016117519466206e-05
step: 960, loss: 3.36846751451958e-05
step: 970, loss: 0.01277050282806158
step: 980, loss: 0.05823686346411705
step: 990, loss: 6.183146615512669e-05
step: 1000, loss: 0.02724413387477398
step: 1010, loss: 0.04028184711933136
step: 1020, loss: 0.01976102963089943
step: 1030, loss: 0.01937399059534073
step: 1040, loss: 0.042932502925395966
step: 1050, loss: 0.019129678606987
step: 1060, loss: 0.050478745251894
step: 1070, loss: 0.06945789605379105
epoch 16: dev_f1=0.9395348837209302, f1=0.9290023201856149, best_f1=0.933271547729379
step: 0, loss: 0.010701190680265427
step: 10, loss: 3.895551344612613e-05
step: 20, loss: 0.03737321496009827
step: 30, loss: 0.01703505404293537
step: 40, loss: 0.022753005847334862
step: 50, loss: 0.020247843116521835
step: 60, loss: 0.02080424129962921
step: 70, loss: 0.0501989871263504
step: 80, loss: 0.00029646456823684275
step: 90, loss: 0.02331574261188507
step: 100, loss: 3.787711466429755e-05
step: 110, loss: 0.07369652390480042
step: 120, loss: 0.03243720531463623
step: 130, loss: 5.183642861084081e-05
step: 140, loss: 0.024657227098941803
step: 150, loss: 0.05690164491534233
step: 160, loss: 7.472348079318181e-05
step: 170, loss: 0.019185425713658333
step: 180, loss: 0.018649443984031677
step: 190, loss: 0.022638162598013878
step: 200, loss: 0.054039642214775085
step: 210, loss: 0.03200215846300125
step: 220, loss: 0.04660915583372116
step: 230, loss: 7.766749331494793e-05
step: 240, loss: 0.06331350654363632
step: 250, loss: 0.03163521736860275
step: 260, loss: 5.1465183787513524e-05
step: 270, loss: 0.05583930388092995
step: 280, loss: 0.05564197152853012
step: 290, loss: 0.029377704486250877
step: 300, loss: 0.044834282249212265
step: 310, loss: 0.011009767651557922
step: 320, loss: 0.0431373305618763
step: 330, loss: 0.09508220851421356
step: 340, loss: 1.8011462088907138e-05
step: 350, loss: 0.03089803457260132
step: 360, loss: 8.641382737550884e-05
step: 370, loss: 0.02583455853164196
step: 380, loss: 0.0006540367030538619
step: 390, loss: 0.056623127311468124
step: 400, loss: 0.07588423043489456
step: 410, loss: 0.0002497053937986493
step: 420, loss: 0.0075143990106880665
step: 430, loss: 0.029621072113513947
step: 440, loss: 0.033644985407590866
step: 450, loss: 3.178935367031954e-05
step: 460, loss: 0.005711048375815153
step: 470, loss: 0.025201980024576187
step: 480, loss: 0.054556261748075485
step: 490, loss: 0.024360474199056625
step: 500, loss: 0.0004972507595084608
step: 510, loss: 0.04697004705667496
step: 520, loss: 0.05695800483226776
step: 530, loss: 0.05224212631583214
step: 540, loss: 0.0004070066788699478
step: 550, loss: 0.04145584627985954
step: 560, loss: 0.004944374319165945
step: 570, loss: 0.07964301109313965
step: 580, loss: 0.022650951519608498
step: 590, loss: 0.05930546298623085
step: 600, loss: 0.0009280979284085333
step: 610, loss: 5.102301656734198e-05
step: 620, loss: 0.04027257114648819
step: 630, loss: 0.0170914214104414
step: 640, loss: 0.03142780810594559
step: 650, loss: 0.00028041386394761503
step: 660, loss: 0.04647810012102127
step: 670, loss: 0.08684639632701874
step: 680, loss: 0.000738667557016015
step: 690, loss: 0.024800293147563934
step: 700, loss: 0.00020791086717508733
step: 710, loss: 1.7527130694361404e-05
step: 720, loss: 0.09969422966241837
step: 730, loss: 0.04738770052790642
step: 740, loss: 1.559378142701462e-05
step: 750, loss: 0.04935845360159874
step: 760, loss: 0.01836923137307167
step: 770, loss: 0.03454802557826042
step: 780, loss: 0.03870708867907524
step: 790, loss: 0.05985299497842789
step: 800, loss: 0.02583901397883892
step: 810, loss: 0.007456678431481123
step: 820, loss: 0.056703854352235794
step: 830, loss: 0.06958217173814774
step: 840, loss: 0.000760256196372211
step: 850, loss: 0.025824422016739845
step: 860, loss: 3.123351780232042e-05
step: 870, loss: 0.017038928344845772
step: 880, loss: 0.0527106374502182
step: 890, loss: 0.000192242645425722
step: 900, loss: 0.07080315053462982
step: 910, loss: 0.046076562255620956
step: 920, loss: 0.07063870877027512
step: 930, loss: 0.037221070379018784
step: 940, loss: 0.04080558568239212
step: 950, loss: 0.04039881378412247
step: 960, loss: 0.04050108790397644
step: 970, loss: 0.02702436037361622
step: 980, loss: 0.06305746734142303
step: 990, loss: 0.01273097563534975
step: 1000, loss: 0.03545880690217018
step: 1010, loss: 0.07386013120412827
step: 1020, loss: 1.7463782569393516e-05
step: 1030, loss: 0.046863749623298645
step: 1040, loss: 0.021760012954473495
step: 1050, loss: 0.01497757900506258
step: 1060, loss: 0.026498926803469658
step: 1070, loss: 0.03991900756955147
epoch 17: dev_f1=0.9299539170506912, f1=0.9281105990783408, best_f1=0.933271547729379
step: 0, loss: 0.08466976881027222
step: 10, loss: 0.0029284837655723095
step: 20, loss: 0.00014050657046027482
step: 30, loss: 0.022364048287272453
step: 40, loss: 2.0104096620343626e-05
step: 50, loss: 0.02574181742966175
step: 60, loss: 0.01618560031056404
step: 70, loss: 0.0001747598871588707
step: 80, loss: 9.541766485199332e-05
step: 90, loss: 0.05944808945059776
step: 100, loss: 0.01883222535252571
step: 110, loss: 0.0367511622607708
step: 120, loss: 0.0015739673981443048
step: 130, loss: 0.02661760337650776
step: 140, loss: 0.036381904035806656
step: 150, loss: 0.053797606378793716
step: 160, loss: 1.5753945262986235e-05
step: 170, loss: 0.04067608341574669
step: 180, loss: 0.01703624613583088
step: 190, loss: 7.563605322502553e-05
step: 200, loss: 0.032611262053251266
step: 210, loss: 0.04385476931929588
step: 220, loss: 0.041118036955595016
step: 230, loss: 0.018607527017593384
step: 240, loss: 3.514389754855074e-05
step: 250, loss: 0.0149970268830657
step: 260, loss: 0.015777450054883957
step: 270, loss: 0.029658731073141098
step: 280, loss: 0.0014583569718524814
step: 290, loss: 0.0240999236702919
step: 300, loss: 5.3733067034045234e-05
step: 310, loss: 0.015240534208714962
step: 320, loss: 0.03721783682703972
step: 330, loss: 0.023282790556550026
step: 340, loss: 0.00013782255700789392
step: 350, loss: 0.041662681847810745
step: 360, loss: 0.021492987871170044
step: 370, loss: 0.023572972044348717
step: 380, loss: 0.010657121427357197
step: 390, loss: 1.5828421965125017e-05
step: 400, loss: 0.014710037969052792
step: 410, loss: 0.022683141753077507
step: 420, loss: 0.04776105284690857
step: 430, loss: 0.00010521701187826693
step: 440, loss: 1.8566202925285324e-05
step: 450, loss: 1.8152783013647422e-05
step: 460, loss: 0.07164264470338821
step: 470, loss: 0.025216465815901756
step: 480, loss: 0.024890266358852386
step: 490, loss: 0.025948766618967056
step: 500, loss: 0.00013735990796703845
step: 510, loss: 4.573164915200323e-05
step: 520, loss: 2.2384498151950538e-05
step: 530, loss: 0.05321205407381058
step: 540, loss: 0.00014492959599010646
step: 550, loss: 0.022434338927268982
step: 560, loss: 0.07664503157138824
step: 570, loss: 0.05550544336438179
step: 580, loss: 0.00020880614465568215
step: 590, loss: 0.04486338794231415
step: 600, loss: 0.023255757987499237
step: 610, loss: 0.03477095440030098
step: 620, loss: 0.037581443786621094
step: 630, loss: 0.041814692318439484
step: 640, loss: 0.0436476394534111
step: 650, loss: 0.05690482258796692
step: 660, loss: 0.059836361557245255
step: 670, loss: 0.017688406631350517
step: 680, loss: 0.00038420644705183804
step: 690, loss: 0.04144742339849472
step: 700, loss: 0.03692704439163208
step: 710, loss: 0.0870322734117508
step: 720, loss: 0.09186916798353195
step: 730, loss: 0.042314399033784866
step: 740, loss: 6.456239498220384e-05
step: 750, loss: 0.0016492047579959035
step: 760, loss: 0.020845714956521988
step: 770, loss: 0.02006070502102375
step: 780, loss: 0.036812759935855865
step: 790, loss: 1.7642132661421783e-05
step: 800, loss: 0.06339424848556519
step: 810, loss: 0.07166338711977005
step: 820, loss: 0.018537741154432297
step: 830, loss: 4.5187662180978805e-05
step: 840, loss: 0.06297910213470459
step: 850, loss: 0.005819047335535288
step: 860, loss: 0.09153389185667038
step: 870, loss: 0.023017633706331253
step: 880, loss: 0.07793805003166199
step: 890, loss: 0.018778424710035324
step: 900, loss: 0.03933973237872124
step: 910, loss: 2.51669371209573e-05
step: 920, loss: 0.022514494135975838
step: 930, loss: 0.0013160816160961986
step: 940, loss: 0.019132444635033607
step: 950, loss: 0.029496416449546814
step: 960, loss: 0.017151331529021263
step: 970, loss: 0.004842047579586506
step: 980, loss: 3.4101365599781275e-05
step: 990, loss: 0.02410406433045864
step: 1000, loss: 8.810699364403263e-05
step: 1010, loss: 5.0134887715103105e-05
step: 1020, loss: 0.04274022951722145
step: 1030, loss: 0.0215578805655241
step: 1040, loss: 0.02200373075902462
step: 1050, loss: 0.016640815883874893
step: 1060, loss: 0.05429584160447121
step: 1070, loss: 0.09816400706768036
epoch 18: dev_f1=0.9306930693069307, f1=0.9219924812030075, best_f1=0.933271547729379
step: 0, loss: 9.92788263829425e-05
step: 10, loss: 0.02006048709154129
step: 20, loss: 0.04608381167054176
step: 30, loss: 0.02497495524585247
step: 40, loss: 1.2799982869182713e-05
step: 50, loss: 0.00046605971874669194
step: 60, loss: 0.02116321213543415
step: 70, loss: 0.04089168831706047
step: 80, loss: 0.00014261032629292458
step: 90, loss: 0.03357245773077011
step: 100, loss: 1.7314134311163798e-05
step: 110, loss: 2.8805228794226423e-05
step: 120, loss: 5.543768565985374e-05
step: 130, loss: 1.994376361835748e-05
step: 140, loss: 0.12260451912879944
step: 150, loss: 0.009556303732097149
step: 160, loss: 0.07321051508188248
step: 170, loss: 0.00021351248142309487
step: 180, loss: 1.628297832212411e-05
step: 190, loss: 0.05591506138443947
step: 200, loss: 8.995965617941692e-05
step: 210, loss: 2.175113149860408e-05
step: 220, loss: 0.04191717877984047
step: 230, loss: 0.03565799817442894
step: 240, loss: 4.6120319893816486e-05
step: 250, loss: 0.0007618108065798879
step: 260, loss: 0.0126116294413805
step: 270, loss: 0.01095305010676384
step: 280, loss: 0.060260869562625885
step: 290, loss: 1.9437633454799652e-05
step: 300, loss: 0.040009625256061554
step: 310, loss: 0.050052180886268616
step: 320, loss: 0.02430475875735283
step: 330, loss: 0.06724539399147034
step: 340, loss: 1.5161554983933456e-05
step: 350, loss: 0.05880126357078552
step: 360, loss: 0.08723156899213791
step: 370, loss: 0.02187691628932953
step: 380, loss: 0.01322587113827467
step: 390, loss: 0.04537471383810043
step: 400, loss: 9.361604497826193e-06
step: 410, loss: 0.02388920821249485
step: 420, loss: 0.04281352460384369
step: 430, loss: 0.024966947734355927
step: 440, loss: 0.017031077295541763
step: 450, loss: 0.01679852418601513
step: 460, loss: 0.04351246729493141
step: 470, loss: 5.29244753124658e-05
step: 480, loss: 0.02270396612584591
step: 490, loss: 0.0007307530613616109
step: 500, loss: 0.018242690712213516
step: 510, loss: 0.032651904970407486
step: 520, loss: 0.00011644051846815273
step: 530, loss: 0.03935080021619797
step: 540, loss: 0.02274145744740963
step: 550, loss: 0.06942758709192276
step: 560, loss: 2.7765343475039117e-05
step: 570, loss: 0.018623586744070053
step: 580, loss: 9.927039354806766e-05
step: 590, loss: 0.045545920729637146
step: 600, loss: 0.002877376973628998
step: 610, loss: 4.1585404687793925e-05
step: 620, loss: 0.028874268755316734
step: 630, loss: 0.0025530527345836163
step: 640, loss: 0.0019702957943081856
step: 650, loss: 1.7906537323142402e-05
step: 660, loss: 7.331257074838504e-05
step: 670, loss: 0.049367617815732956
step: 680, loss: 0.0301444660872221
step: 690, loss: 0.00014652637764811516
step: 700, loss: 1.0549957551120315e-05
step: 710, loss: 0.03145448490977287
step: 720, loss: 0.08375505357980728
step: 730, loss: 0.014642554335296154
step: 740, loss: 0.004002018366008997
step: 750, loss: 0.02180894836783409
step: 760, loss: 0.026137497276067734
step: 770, loss: 4.3892941903322935e-05
step: 780, loss: 0.04145866259932518
step: 790, loss: 1.769476875779219e-05
step: 800, loss: 0.0018603828502818942
step: 810, loss: 0.022698739543557167
step: 820, loss: 0.04271902143955231
step: 830, loss: 0.02497369609773159
step: 840, loss: 0.0010417030425742269
step: 850, loss: 0.04630408063530922
step: 860, loss: 0.03580383211374283
step: 870, loss: 0.0353814959526062
step: 880, loss: 0.05571654066443443
step: 890, loss: 0.024520738050341606
step: 900, loss: 0.020131489261984825
step: 910, loss: 0.05558432638645172
step: 920, loss: 0.0002689922694116831
step: 930, loss: 1.436410366295604e-05
step: 940, loss: 2.472662708896678e-05
step: 950, loss: 0.042035061866045
step: 960, loss: 0.028206322342157364
step: 970, loss: 0.030072782188653946
step: 980, loss: 0.03879740834236145
step: 990, loss: 0.05478125810623169
step: 1000, loss: 0.05642332881689072
step: 1010, loss: 0.016910040751099586
step: 1020, loss: 0.0174652561545372
step: 1030, loss: 0.0011425556149333715
step: 1040, loss: 0.03522796556353569
step: 1050, loss: 0.001798943616449833
step: 1060, loss: 0.09809336066246033
step: 1070, loss: 0.02445371262729168
epoch 19: dev_f1=0.9351981351981352, f1=0.92814093648586, best_f1=0.933271547729379
step: 0, loss: 4.847000309382565e-05
step: 10, loss: 0.018197719007730484
step: 20, loss: 0.04376154765486717
step: 30, loss: 0.07003203779459
step: 40, loss: 0.044467613101005554
step: 50, loss: 0.018441835418343544
step: 60, loss: 0.029181579127907753
step: 70, loss: 0.013794466853141785
step: 80, loss: 3.224673491786234e-05
step: 90, loss: 0.0394897498190403
step: 100, loss: 0.01961473934352398
step: 110, loss: 0.030329151079058647
step: 120, loss: 2.294249316037167e-05
step: 130, loss: 1.142164819611935e-05
step: 140, loss: 0.058717992156744
step: 150, loss: 0.012568263337016106
step: 160, loss: 0.19629739224910736
step: 170, loss: 0.002105249557644129
step: 180, loss: 0.01964033581316471
step: 190, loss: 0.03584659472107887
step: 200, loss: 0.03808020055294037
step: 210, loss: 0.037379190325737
step: 220, loss: 0.03573649004101753
step: 230, loss: 0.025187242776155472
step: 240, loss: 0.017429502680897713
step: 250, loss: 0.10976913571357727
step: 260, loss: 0.03797575458884239
step: 270, loss: 0.02551605924963951
step: 280, loss: 0.02461082860827446
step: 290, loss: 0.09202148765325546
step: 300, loss: 0.021991701796650887
step: 310, loss: 0.007978840731084347
step: 320, loss: 0.017845097929239273
step: 330, loss: 0.04803560674190521
step: 340, loss: 0.003576308023184538
step: 350, loss: 0.028444072231650352
step: 360, loss: 0.04645398259162903
step: 370, loss: 0.012950889766216278
step: 380, loss: 0.04043435677886009
step: 390, loss: 4.817044464289211e-05
step: 400, loss: 0.018917351961135864
step: 410, loss: 0.00010873239807551727
step: 420, loss: 7.201336120488122e-05
step: 430, loss: 0.02457278035581112
step: 440, loss: 0.00031193162431009114
step: 450, loss: 0.04013299196958542
step: 460, loss: 0.023829471319913864
step: 470, loss: 0.0025118645280599594
step: 480, loss: 0.025411495938897133
step: 490, loss: 6.535071588587016e-05
step: 500, loss: 0.019432341679930687
step: 510, loss: 0.0015998240560293198
step: 520, loss: 0.016653304919600487
step: 530, loss: 0.020548967644572258
step: 540, loss: 0.021348996087908745
step: 550, loss: 0.061586905270814896
step: 560, loss: 2.449244675517548e-05
step: 570, loss: 1.533665636088699e-05
step: 580, loss: 0.027963092550635338
step: 590, loss: 0.018165724352002144
step: 600, loss: 0.022528640925884247
step: 610, loss: 0.00019605304987635463
step: 620, loss: 0.002430829219520092
step: 630, loss: 0.0005900868563912809
step: 640, loss: 0.02082332968711853
step: 650, loss: 0.0001456274330848828
step: 660, loss: 0.045737262815237045
step: 670, loss: 0.015100335702300072
step: 680, loss: 0.022942006587982178
step: 690, loss: 2.819457949954085e-05
step: 700, loss: 0.04299535974860191
step: 710, loss: 0.0584290474653244
step: 720, loss: 0.02775195986032486
step: 730, loss: 0.06602392345666885
step: 740, loss: 0.047061990946531296
step: 750, loss: 3.932409526896663e-05
step: 760, loss: 0.004084600601345301
step: 770, loss: 0.020115656778216362
step: 780, loss: 0.022741232067346573
step: 790, loss: 0.02023547701537609
step: 800, loss: 0.021354470402002335
step: 810, loss: 0.17664597928524017
step: 820, loss: 0.02611958235502243
step: 830, loss: 0.031109416857361794
step: 840, loss: 2.6350699044996873e-05
step: 850, loss: 0.024183494970202446
step: 860, loss: 0.019708823412656784
step: 870, loss: 0.0248419176787138
step: 880, loss: 0.00018853886285796762
step: 890, loss: 2.1508694771910086e-05
step: 900, loss: 0.043436262756586075
step: 910, loss: 0.03814077004790306
step: 920, loss: 0.14208035171031952
step: 930, loss: 1.7590389688848518e-05
step: 940, loss: 0.04099012166261673
step: 950, loss: 0.023843765258789062
step: 960, loss: 0.02243245206773281
step: 970, loss: 0.02611926756799221
step: 980, loss: 0.02303559146821499
step: 990, loss: 0.047768186777830124
step: 1000, loss: 0.023697245866060257
step: 1010, loss: 3.0507551855407655e-05
step: 1020, loss: 0.016966765746474266
step: 1030, loss: 0.014338376000523567
step: 1040, loss: 0.0002002587862079963
step: 1050, loss: 4.277834523236379e-05
step: 1060, loss: 0.02251896634697914
step: 1070, loss: 0.045784756541252136
epoch 20: dev_f1=0.9344030202925908, f1=0.9278642149929278, best_f1=0.933271547729379
