cuda
Device: cuda
step: 0, loss: 0.5498653650283813
step: 10, loss: 0.36283907294273376
step: 20, loss: 0.2579975128173828
step: 30, loss: 0.34276875853538513
step: 40, loss: 0.3304186165332794
step: 50, loss: 0.07152210175991058
step: 60, loss: 0.23179712891578674
step: 70, loss: 0.4634181261062622
step: 80, loss: 0.39072200655937195
step: 90, loss: 0.239746555685997
step: 100, loss: 0.21958580613136292
step: 110, loss: 0.36176201701164246
step: 120, loss: 0.1924280822277069
step: 130, loss: 0.2015514224767685
step: 140, loss: 0.12188049405813217
step: 150, loss: 0.1944410353899002
step: 160, loss: 0.28929001092910767
step: 170, loss: 0.1861373484134674
step: 180, loss: 0.06088300794363022
step: 190, loss: 0.24913984537124634
step: 200, loss: 0.10250147432088852
step: 210, loss: 0.257802277803421
step: 220, loss: 0.34018629789352417
step: 230, loss: 0.2467627227306366
step: 240, loss: 0.17912326753139496
step: 250, loss: 0.13193973898887634
step: 260, loss: 0.04166710376739502
step: 270, loss: 0.03802822530269623
step: 280, loss: 0.043502967804670334
step: 290, loss: 0.09628677368164062
step: 300, loss: 0.0750611424446106
step: 310, loss: 0.12547630071640015
step: 320, loss: 0.14957420527935028
step: 330, loss: 0.06206696853041649
step: 340, loss: 0.11054347455501556
step: 350, loss: 0.09888903051614761
step: 360, loss: 0.1575288474559784
step: 370, loss: 0.1465449184179306
step: 380, loss: 0.1265893131494522
step: 390, loss: 0.05505923554301262
step: 400, loss: 0.09070660918951035
step: 410, loss: 0.25985535979270935
step: 420, loss: 0.09705373644828796
step: 430, loss: 0.11827182024717331
step: 440, loss: 0.08318881690502167
step: 450, loss: 0.199848473072052
step: 460, loss: 0.217790424823761
step: 470, loss: 0.22761984169483185
step: 480, loss: 0.12737634778022766
step: 490, loss: 0.1719256043434143
step: 500, loss: 0.10429072380065918
step: 510, loss: 0.04961022362112999
step: 520, loss: 0.20113839209079742
step: 530, loss: 0.04576146602630615
step: 540, loss: 0.16164816915988922
step: 550, loss: 0.036001965403556824
step: 560, loss: 0.04634818434715271
step: 570, loss: 0.1296035200357437
step: 580, loss: 0.05667636916041374
step: 590, loss: 0.03811744600534439
step: 600, loss: 0.07687440514564514
step: 610, loss: 0.1537533700466156
step: 620, loss: 0.06349676102399826
step: 630, loss: 0.07961885631084442
step: 640, loss: 0.05248061940073967
step: 650, loss: 0.1366184949874878
step: 660, loss: 0.09693802893161774
step: 670, loss: 0.07962056994438171
step: 680, loss: 0.15581467747688293
step: 690, loss: 0.16759049892425537
step: 700, loss: 0.07880882918834686
step: 710, loss: 0.08499172329902649
step: 720, loss: 0.2030358761548996
step: 730, loss: 0.09113166481256485
step: 740, loss: 0.20378941297531128
step: 750, loss: 0.2154308259487152
step: 760, loss: 0.04958310350775719
step: 770, loss: 0.17497532069683075
step: 780, loss: 0.05475056916475296
step: 790, loss: 0.11270704120397568
step: 800, loss: 0.03196437284350395
step: 810, loss: 0.10249744355678558
step: 820, loss: 0.053906865417957306
step: 830, loss: 0.06714919954538345
step: 840, loss: 0.06046578660607338
step: 850, loss: 0.16135215759277344
step: 860, loss: 0.09058474749326706
step: 870, loss: 0.1285334825515747
step: 880, loss: 0.17492972314357758
step: 890, loss: 0.10909263044595718
step: 900, loss: 0.09723477065563202
step: 910, loss: 0.059388186782598495
step: 920, loss: 0.09331076592206955
step: 930, loss: 0.07114889472723007
step: 940, loss: 0.0053805941715836525
step: 950, loss: 0.164014533162117
step: 960, loss: 0.09606438875198364
step: 970, loss: 0.10878324508666992
step: 980, loss: 0.046867549419403076
step: 990, loss: 0.018249139189720154
step: 1000, loss: 0.14695735275745392
step: 1010, loss: 0.24078230559825897
step: 1020, loss: 0.09025806933641434
step: 1030, loss: 0.18573950231075287
step: 1040, loss: 0.14448724687099457
step: 1050, loss: 0.10391779243946075
step: 1060, loss: 0.06204674392938614
step: 1070, loss: 0.1269024908542633
epoch 1: dev_f1=0.9336343115124154, f1=0.9300448430493273, best_f1=0.9300448430493273
step: 0, loss: 0.11883606016635895
step: 10, loss: 0.06229893118143082
step: 20, loss: 0.06450891494750977
step: 30, loss: 0.08273894339799881
step: 40, loss: 0.2462974190711975
step: 50, loss: 0.0496305450797081
step: 60, loss: 0.16367653012275696
step: 70, loss: 0.2243158370256424
step: 80, loss: 0.08894012868404388
step: 90, loss: 0.11993828415870667
step: 100, loss: 0.19228756427764893
step: 110, loss: 0.050532907247543335
step: 120, loss: 0.10530511289834976
step: 130, loss: 0.018092265352606773
step: 140, loss: 0.0824841633439064
step: 150, loss: 0.1995902955532074
step: 160, loss: 0.15938261151313782
step: 170, loss: 0.09190645068883896
step: 180, loss: 0.024565784260630608
step: 190, loss: 0.015682391822338104
step: 200, loss: 0.021650388836860657
step: 210, loss: 0.14901424944400787
step: 220, loss: 0.15628790855407715
step: 230, loss: 0.08644925057888031
step: 240, loss: 0.015557201579213142
step: 250, loss: 0.05807443708181381
step: 260, loss: 0.05931111052632332
step: 270, loss: 0.09820631891489029
step: 280, loss: 0.02327154576778412
step: 290, loss: 0.264597088098526
step: 300, loss: 0.15694285929203033
step: 310, loss: 0.226849764585495
step: 320, loss: 0.018329253420233727
step: 330, loss: 0.2086196094751358
step: 340, loss: 0.07231747359037399
step: 350, loss: 0.080463707447052
step: 360, loss: 0.03331567719578743
step: 370, loss: 0.29412591457366943
step: 380, loss: 0.12054698169231415
step: 390, loss: 0.02118360809981823
step: 400, loss: 0.342231810092926
step: 410, loss: 0.020501181483268738
step: 420, loss: 0.08443139493465424
step: 430, loss: 0.08043405413627625
step: 440, loss: 0.1797526478767395
step: 450, loss: 0.06795516610145569
step: 460, loss: 0.14430570602416992
step: 470, loss: 0.1021694466471672
step: 480, loss: 0.08944162726402283
step: 490, loss: 0.07136113196611404
step: 500, loss: 0.0923892930150032
step: 510, loss: 0.14900878071784973
step: 520, loss: 0.07116634398698807
step: 530, loss: 0.05578748136758804
step: 540, loss: 0.1668514907360077
step: 550, loss: 0.04384461045265198
step: 560, loss: 0.14477048814296722
step: 570, loss: 0.06094575673341751
step: 580, loss: 0.0704892948269844
step: 590, loss: 0.07449548691511154
step: 600, loss: 0.14778552949428558
step: 610, loss: 0.12497615814208984
step: 620, loss: 0.1870618462562561
step: 630, loss: 0.1926390379667282
step: 640, loss: 0.06731168925762177
step: 650, loss: 0.035522203892469406
step: 660, loss: 0.12248800694942474
step: 670, loss: 0.1332341730594635
step: 680, loss: 0.05882115289568901
step: 690, loss: 0.08352196216583252
step: 700, loss: 0.09363973140716553
step: 710, loss: 0.02874593809247017
step: 720, loss: 0.01655699871480465
step: 730, loss: 0.10841205716133118
step: 740, loss: 0.16598691046237946
step: 750, loss: 0.03182884305715561
step: 760, loss: 0.05845840275287628
step: 770, loss: 0.04555768147110939
step: 780, loss: 0.03609321266412735
step: 790, loss: 0.04449894279241562
step: 800, loss: 0.08690132945775986
step: 810, loss: 0.06977042555809021
step: 820, loss: 0.08393298834562302
step: 830, loss: 0.06359326839447021
step: 840, loss: 0.11919479072093964
step: 850, loss: 0.05837107449769974
step: 860, loss: 0.07282336801290512
step: 870, loss: 0.04998888447880745
step: 880, loss: 0.054611120373010635
step: 890, loss: 0.07801603525876999
step: 900, loss: 0.07833290100097656
step: 910, loss: 0.16113099455833435
step: 920, loss: 0.09306824207305908
step: 930, loss: 0.06678389012813568
step: 940, loss: 0.09432576596736908
step: 950, loss: 0.11606435477733612
step: 960, loss: 0.19593669474124908
step: 970, loss: 0.008549511432647705
step: 980, loss: 0.12479328364133835
step: 990, loss: 0.016584107652306557
step: 1000, loss: 0.12812526524066925
step: 1010, loss: 0.03198850527405739
step: 1020, loss: 0.0411624051630497
step: 1030, loss: 0.1829686313867569
step: 1040, loss: 0.034004293382167816
step: 1050, loss: 0.10715755075216293
step: 1060, loss: 0.1704818308353424
step: 1070, loss: 0.02835167944431305
epoch 2: dev_f1=0.9347111319868483, f1=0.9389277389277391, best_f1=0.9389277389277391
step: 0, loss: 0.06326409429311752
step: 10, loss: 0.13956831395626068
step: 20, loss: 0.028652489185333252
step: 30, loss: 0.10585067421197891
step: 40, loss: 0.03539513796567917
step: 50, loss: 0.014223570004105568
step: 60, loss: 0.03176742419600487
step: 70, loss: 0.010598180815577507
step: 80, loss: 0.007490868680179119
step: 90, loss: 0.03391217067837715
step: 100, loss: 0.06566266715526581
step: 110, loss: 0.014315741136670113
step: 120, loss: 0.10370282083749771
step: 130, loss: 0.024332275614142418
step: 140, loss: 0.057438191026449203
step: 150, loss: 0.18717168271541595
step: 160, loss: 0.19401010870933533
step: 170, loss: 0.02130597084760666
step: 180, loss: 0.12943623960018158
step: 190, loss: 0.023886002600193024
step: 200, loss: 0.10735592991113663
step: 210, loss: 0.0732545554637909
step: 220, loss: 0.14636215567588806
step: 230, loss: 0.2502928078174591
step: 240, loss: 0.07907411456108093
step: 250, loss: 0.08223459124565125
step: 260, loss: 0.04766523092985153
step: 270, loss: 0.07339121401309967
step: 280, loss: 0.017992673441767693
step: 290, loss: 0.05438963323831558
step: 300, loss: 0.008117642253637314
step: 310, loss: 0.0613594651222229
step: 320, loss: 0.011285677552223206
step: 330, loss: 0.07596084475517273
step: 340, loss: 0.03166254609823227
step: 350, loss: 0.03429163247346878
step: 360, loss: 0.08564972132444382
step: 370, loss: 0.10148252546787262
step: 380, loss: 0.11047738790512085
step: 390, loss: 0.09380102157592773
step: 400, loss: 0.11296264082193375
step: 410, loss: 0.012264421209692955
step: 420, loss: 0.037739407271146774
step: 430, loss: 0.36598730087280273
step: 440, loss: 0.20155532658100128
step: 450, loss: 0.09663889557123184
step: 460, loss: 0.028011605143547058
step: 470, loss: 0.02319183014333248
step: 480, loss: 0.010598625987768173
step: 490, loss: 0.030763566493988037
step: 500, loss: 0.06564702838659286
step: 510, loss: 0.016301793977618217
step: 520, loss: 0.1573173552751541
step: 530, loss: 0.059251025319099426
step: 540, loss: 0.07719120383262634
step: 550, loss: 0.11674138158559799
step: 560, loss: 0.020467747002840042
step: 570, loss: 0.017083432525396347
step: 580, loss: 0.034308820962905884
step: 590, loss: 0.05358009412884712
step: 600, loss: 0.048367612063884735
step: 610, loss: 0.031243734061717987
step: 620, loss: 0.06977584213018417
step: 630, loss: 0.16378124058246613
step: 640, loss: 0.048978500068187714
step: 650, loss: 0.11217993497848511
step: 660, loss: 0.029105860739946365
step: 670, loss: 0.11246734857559204
step: 680, loss: 0.22931236028671265
step: 690, loss: 0.04680341109633446
step: 700, loss: 0.06689384579658508
step: 710, loss: 0.03706298768520355
step: 720, loss: 0.1090380847454071
step: 730, loss: 0.02755109593272209
step: 740, loss: 0.1083223894238472
step: 750, loss: 0.08113157004117966
step: 760, loss: 0.10871052742004395
step: 770, loss: 0.06566330045461655
step: 780, loss: 0.029654307290911674
step: 790, loss: 0.0859147161245346
step: 800, loss: 0.06417959928512573
step: 810, loss: 0.0020913474727422
step: 820, loss: 0.01805788092315197
step: 830, loss: 0.06215259060263634
step: 840, loss: 0.09498706459999084
step: 850, loss: 0.03464490920305252
step: 860, loss: 0.04678146168589592
step: 870, loss: 0.17379871010780334
step: 880, loss: 0.05564595013856888
step: 890, loss: 0.08303382992744446
step: 900, loss: 0.1380336731672287
step: 910, loss: 0.0714707002043724
step: 920, loss: 0.029775748029351234
step: 930, loss: 0.19328860938549042
step: 940, loss: 0.02118217572569847
step: 950, loss: 0.10414773970842361
step: 960, loss: 0.13089004158973694
step: 970, loss: 0.010679937899112701
step: 980, loss: 0.09038052707910538
step: 990, loss: 0.033449687063694
step: 1000, loss: 0.009198999032378197
step: 1010, loss: 0.08327442407608032
step: 1020, loss: 0.12584514915943146
step: 1030, loss: 0.11938706040382385
step: 1040, loss: 0.05215059220790863
step: 1050, loss: 0.033544834703207016
step: 1060, loss: 0.17638257145881653
step: 1070, loss: 0.012880570255219936
epoch 3: dev_f1=0.928735632183908, f1=0.930909090909091, best_f1=0.9389277389277391
step: 0, loss: 0.1339035928249359
step: 10, loss: 0.01619902439415455
step: 20, loss: 0.026058193296194077
step: 30, loss: 0.06741004437208176
step: 40, loss: 0.102876216173172
step: 50, loss: 0.2018362581729889
step: 60, loss: 0.23410049080848694
step: 70, loss: 0.0735163688659668
step: 80, loss: 0.1270100325345993
step: 90, loss: 0.07696839421987534
step: 100, loss: 0.09326808899641037
step: 110, loss: 0.0162542462348938
step: 120, loss: 0.07225549221038818
step: 130, loss: 0.026077520102262497
step: 140, loss: 0.0761130079627037
step: 150, loss: 0.03265296295285225
step: 160, loss: 0.2137872278690338
step: 170, loss: 0.16581033170223236
step: 180, loss: 0.07514731585979462
step: 190, loss: 0.031679145991802216
step: 200, loss: 0.08898704499006271
step: 210, loss: 0.018607817590236664
step: 220, loss: 0.03237234801054001
step: 230, loss: 0.007030113600194454
step: 240, loss: 0.001926386496052146
step: 250, loss: 0.026722310110926628
step: 260, loss: 0.031049663200974464
step: 270, loss: 0.016333425417542458
step: 280, loss: 0.049505043774843216
step: 290, loss: 0.014118778519332409
step: 300, loss: 0.08170904219150543
step: 310, loss: 0.004977055825293064
step: 320, loss: 0.08285542577505112
step: 330, loss: 0.07580769062042236
step: 340, loss: 0.06067831069231033
step: 350, loss: 0.12849776446819305
step: 360, loss: 0.06120549142360687
step: 370, loss: 0.15782135725021362
step: 380, loss: 0.08737459033727646
step: 390, loss: 0.043534696102142334
step: 400, loss: 0.11026263236999512
step: 410, loss: 0.08588087558746338
step: 420, loss: 0.0619114525616169
step: 430, loss: 0.0684618353843689
step: 440, loss: 0.025200767442584038
step: 450, loss: 0.031027428805828094
step: 460, loss: 0.06654474139213562
step: 470, loss: 0.051719196140766144
step: 480, loss: 0.26720356941223145
step: 490, loss: 0.13490696251392365
step: 500, loss: 0.08445923775434494
step: 510, loss: 0.022640813142061234
step: 520, loss: 0.03242222219705582
step: 530, loss: 0.018485724925994873
step: 540, loss: 0.03616637364029884
step: 550, loss: 0.04638684168457985
step: 560, loss: 0.00915729533880949
step: 570, loss: 0.016198134049773216
step: 580, loss: 0.040609244257211685
step: 590, loss: 0.09923724830150604
step: 600, loss: 0.06557660549879074
step: 610, loss: 0.11931989341974258
step: 620, loss: 0.06078152731060982
step: 630, loss: 0.012470810674130917
step: 640, loss: 0.05899291858077049
step: 650, loss: 0.1426364779472351
step: 660, loss: 0.01829781010746956
step: 670, loss: 0.027757955715060234
step: 680, loss: 0.052484337240457535
step: 690, loss: 0.028301360085606575
step: 700, loss: 0.11555077135562897
step: 710, loss: 0.06667769700288773
step: 720, loss: 0.09035494923591614
step: 730, loss: 0.23862408101558685
step: 740, loss: 0.024049459025263786
step: 750, loss: 0.014110149815678596
step: 760, loss: 0.012597829103469849
step: 770, loss: 0.03213409334421158
step: 780, loss: 0.10854793339967728
step: 790, loss: 0.04652346670627594
step: 800, loss: 0.16464978456497192
step: 810, loss: 0.027245759963989258
step: 820, loss: 0.05902808532118797
step: 830, loss: 0.07405292242765427
step: 840, loss: 0.02804330363869667
step: 850, loss: 0.15030212700366974
step: 860, loss: 0.013377891853451729
step: 870, loss: 0.019517043605446815
step: 880, loss: 0.021904274821281433
step: 890, loss: 0.034048087894916534
step: 900, loss: 0.08315511792898178
step: 910, loss: 0.13324405252933502
step: 920, loss: 0.13123226165771484
step: 930, loss: 0.08588553965091705
step: 940, loss: 0.061079636216163635
step: 950, loss: 0.029721103608608246
step: 960, loss: 0.07885134965181351
step: 970, loss: 0.04574902728199959
step: 980, loss: 0.039456311613321304
step: 990, loss: 0.11858896911144257
step: 1000, loss: 0.11817971616983414
step: 1010, loss: 0.12112460285425186
step: 1020, loss: 0.09107651561498642
step: 1030, loss: 0.03770576789975166
step: 1040, loss: 0.026428554207086563
step: 1050, loss: 0.008275562897324562
step: 1060, loss: 0.022887829691171646
step: 1070, loss: 0.06153819337487221
epoch 4: dev_f1=0.93666204345816, f1=0.9314312011044639, best_f1=0.9314312011044639
step: 0, loss: 0.009734567254781723
step: 10, loss: 0.052722010761499405
step: 20, loss: 0.023295827209949493
step: 30, loss: 0.10319933295249939
step: 40, loss: 0.08794041723012924
step: 50, loss: 0.009193315170705318
step: 60, loss: 0.059030234813690186
step: 70, loss: 0.22384749352931976
step: 80, loss: 0.031195668503642082
step: 90, loss: 0.05063603073358536
step: 100, loss: 0.019086124375462532
step: 110, loss: 8.363732922589406e-05
step: 120, loss: 0.2604978382587433
step: 130, loss: 0.061635445803403854
step: 140, loss: 0.008724771440029144
step: 150, loss: 0.013343269005417824
step: 160, loss: 0.06258918344974518
step: 170, loss: 0.0076905060559511185
step: 180, loss: 0.009335394017398357
step: 190, loss: 0.05099168047308922
step: 200, loss: 0.09331080317497253
step: 210, loss: 0.04847845435142517
step: 220, loss: 0.023571426048874855
step: 230, loss: 0.013976728543639183
step: 240, loss: 0.06856252253055573
step: 250, loss: 0.016644679009914398
step: 260, loss: 0.04630763456225395
step: 270, loss: 0.031960345804691315
step: 280, loss: 0.08927500247955322
step: 290, loss: 0.036354806274175644
step: 300, loss: 0.10547880083322525
step: 310, loss: 0.08276278525590897
step: 320, loss: 0.02579481154680252
step: 330, loss: 0.04983473941683769
step: 340, loss: 0.0343010351061821
step: 350, loss: 0.09165499359369278
step: 360, loss: 0.034271396696567535
step: 370, loss: 0.0568353645503521
step: 380, loss: 0.05439165234565735
step: 390, loss: 0.04636996611952782
step: 400, loss: 0.07804462313652039
step: 410, loss: 0.008215836249291897
step: 420, loss: 0.02589353546500206
step: 430, loss: 0.08204425871372223
step: 440, loss: 0.061228521168231964
step: 450, loss: 0.10043102502822876
step: 460, loss: 0.034815236926078796
step: 470, loss: 0.00733516039326787
step: 480, loss: 0.0001821281184675172
step: 490, loss: 0.07949163019657135
step: 500, loss: 0.07011722773313522
step: 510, loss: 0.06754955649375916
step: 520, loss: 0.08343543112277985
step: 530, loss: 0.06448762118816376
step: 540, loss: 0.023275095969438553
step: 550, loss: 0.1644294559955597
step: 560, loss: 0.04030108451843262
step: 570, loss: 0.02003033272922039
step: 580, loss: 0.00279240682721138
step: 590, loss: 0.008235582150518894
step: 600, loss: 0.03205485641956329
step: 610, loss: 0.01590495929121971
step: 620, loss: 0.05609988421201706
step: 630, loss: 0.008786814287304878
step: 640, loss: 0.06785311549901962
step: 650, loss: 0.11208296567201614
step: 660, loss: 0.061312876641750336
step: 670, loss: 0.001967350021004677
step: 680, loss: 0.05903734639286995
step: 690, loss: 0.06684526056051254
step: 700, loss: 0.1267835795879364
step: 710, loss: 0.02835797145962715
step: 720, loss: 0.005951726343482733
step: 730, loss: 0.0034283578861504793
step: 740, loss: 0.07198356091976166
step: 750, loss: 0.12623518705368042
step: 760, loss: 0.03827056661248207
step: 770, loss: 0.11249809712171555
step: 780, loss: 0.024239839985966682
step: 790, loss: 0.14311663806438446
step: 800, loss: 0.09350251406431198
step: 810, loss: 0.04827117919921875
step: 820, loss: 0.008104593493044376
step: 830, loss: 0.10560355335474014
step: 840, loss: 0.0963292270898819
step: 850, loss: 0.044905006885528564
step: 860, loss: 0.10786033421754837
step: 870, loss: 0.04537339136004448
step: 880, loss: 0.09084609895944595
step: 890, loss: 0.0871080681681633
step: 900, loss: 0.11875822395086288
step: 910, loss: 0.04177294671535492
step: 920, loss: 0.0014403475215658545
step: 930, loss: 0.03553875535726547
step: 940, loss: 0.17968527972698212
step: 950, loss: 0.040086232125759125
step: 960, loss: 0.07302138209342957
step: 970, loss: 0.12430763244628906
step: 980, loss: 0.10480771213769913
step: 990, loss: 0.06504766643047333
step: 1000, loss: 0.04891229793429375
step: 1010, loss: 0.0689149796962738
step: 1020, loss: 0.0580398291349411
step: 1030, loss: 0.018343303352594376
step: 1040, loss: 0.07926828414201736
step: 1050, loss: 0.03684607148170471
step: 1060, loss: 0.00740404799580574
step: 1070, loss: 0.11927495896816254
epoch 5: dev_f1=0.9382022471910113, f1=0.9290023201856149, best_f1=0.9290023201856149
step: 0, loss: 0.05891678109765053
step: 10, loss: 0.037908799946308136
step: 20, loss: 0.03487171232700348
step: 30, loss: 0.017591778188943863
step: 40, loss: 0.00828107912093401
step: 50, loss: 0.012673929333686829
step: 60, loss: 0.020106283947825432
step: 70, loss: 0.04916276037693024
step: 80, loss: 0.0841626226902008
step: 90, loss: 0.011521088890731335
step: 100, loss: 0.031906407326459885
step: 110, loss: 0.015438660979270935
step: 120, loss: 0.0941201001405716
step: 130, loss: 0.0168406143784523
step: 140, loss: 0.01322463620454073
step: 150, loss: 0.09469452500343323
step: 160, loss: 0.007550056558102369
step: 170, loss: 0.08235345035791397
step: 180, loss: 0.08583594113588333
step: 190, loss: 0.0146391112357378
step: 200, loss: 0.041335828602313995
step: 210, loss: 0.015850991010665894
step: 220, loss: 0.07579691708087921
step: 230, loss: 0.03054577298462391
step: 240, loss: 0.059678815305233
step: 250, loss: 0.0768687054514885
step: 260, loss: 0.06414495408535004
step: 270, loss: 0.02588041126728058
step: 280, loss: 0.05982011556625366
step: 290, loss: 0.10385167598724365
step: 300, loss: 0.07879875600337982
step: 310, loss: 0.006824943702667952
step: 320, loss: 0.008151703514158726
step: 330, loss: 0.027301687747240067
step: 340, loss: 0.08526928722858429
step: 350, loss: 0.12353905290365219
step: 360, loss: 0.033000923693180084
step: 370, loss: 0.02673252485692501
step: 380, loss: 5.009982123738155e-05
step: 390, loss: 0.09532082080841064
step: 400, loss: 0.07956203818321228
step: 410, loss: 0.0811978280544281
step: 420, loss: 0.1030404344201088
step: 430, loss: 0.19146598875522614
step: 440, loss: 0.03290493041276932
step: 450, loss: 0.06946226954460144
step: 460, loss: 0.09120924770832062
step: 470, loss: 0.029339583590626717
step: 480, loss: 0.02252112701535225
step: 490, loss: 0.007573882583528757
step: 500, loss: 0.112066850066185
step: 510, loss: 0.075986847281456
step: 520, loss: 0.11013959348201752
step: 530, loss: 0.09625314921140671
step: 540, loss: 0.020833471789956093
step: 550, loss: 0.06026697903871536
step: 560, loss: 0.05682305246591568
step: 570, loss: 0.07515084743499756
step: 580, loss: 0.02797849103808403
step: 590, loss: 0.13612550497055054
step: 600, loss: 0.037793274968862534
step: 610, loss: 0.04870173707604408
step: 620, loss: 0.029176563024520874
step: 630, loss: 0.008113715797662735
step: 640, loss: 0.1106470599770546
step: 650, loss: 0.11985328048467636
step: 660, loss: 0.018886882811784744
step: 670, loss: 0.06503145396709442
step: 680, loss: 0.10628598928451538
step: 690, loss: 0.20356552302837372
step: 700, loss: 0.06191437691450119
step: 710, loss: 0.18432512879371643
step: 720, loss: 0.010443388484418392
step: 730, loss: 0.0702458918094635
step: 740, loss: 0.1170002743601799
step: 750, loss: 0.039867617189884186
step: 760, loss: 0.017065811902284622
step: 770, loss: 0.08268457651138306
step: 780, loss: 0.03628434240818024
step: 790, loss: 0.08618959039449692
step: 800, loss: 0.06755045801401138
step: 810, loss: 0.11093967407941818
step: 820, loss: 0.06104529649019241
step: 830, loss: 0.02644963748753071
step: 840, loss: 0.09084586054086685
step: 850, loss: 0.09041690081357956
step: 860, loss: 0.05765530839562416
step: 870, loss: 0.05678755044937134
step: 880, loss: 0.05967589467763901
step: 890, loss: 0.0657971054315567
step: 900, loss: 0.12731292843818665
step: 910, loss: 0.10064665973186493
step: 920, loss: 0.05876469239592552
step: 930, loss: 0.28037697076797485
step: 940, loss: 0.09648071229457855
step: 950, loss: 0.051602739840745926
step: 960, loss: 0.017677119001746178
step: 970, loss: 0.042203668504953384
step: 980, loss: 0.050390541553497314
step: 990, loss: 0.02103997953236103
step: 1000, loss: 0.1140938252210617
step: 1010, loss: 0.047910891473293304
step: 1020, loss: 0.14124633371829987
step: 1030, loss: 0.038946881890296936
step: 1040, loss: 0.09690630435943604
step: 1050, loss: 0.02034332975745201
step: 1060, loss: 0.021354354918003082
step: 1070, loss: 0.09315791726112366
epoch 6: dev_f1=0.933826931975937, f1=0.924791086350975, best_f1=0.9290023201856149
step: 0, loss: 0.14588870108127594
step: 10, loss: 0.07688681781291962
step: 20, loss: 0.057448580861091614
step: 30, loss: 0.1094193235039711
step: 40, loss: 0.04267356917262077
step: 50, loss: 0.11023622751235962
step: 60, loss: 0.023333529010415077
step: 70, loss: 0.0011524928268045187
step: 80, loss: 0.030960451811552048
step: 90, loss: 0.02349250391125679
step: 100, loss: 0.14243319630622864
step: 110, loss: 0.0286286361515522
step: 120, loss: 0.03553953021764755
step: 130, loss: 0.07808137685060501
step: 140, loss: 3.517231743899174e-05
step: 150, loss: 0.017480088397860527
step: 160, loss: 0.14634518325328827
step: 170, loss: 0.0018639337504282594
step: 180, loss: 0.004724383354187012
step: 190, loss: 0.02477448806166649
step: 200, loss: 0.1035308763384819
step: 210, loss: 0.008094078861176968
step: 220, loss: 0.09370027482509613
step: 230, loss: 0.07079499959945679
step: 240, loss: 0.07586357742547989
step: 250, loss: 0.06108193099498749
step: 260, loss: 0.027972109615802765
step: 270, loss: 0.028834255412220955
step: 280, loss: 0.05974181741476059
step: 290, loss: 0.03513038530945778
step: 300, loss: 0.01063226256519556
step: 310, loss: 0.09601213037967682
step: 320, loss: 0.04265197739005089
step: 330, loss: 0.013876298442482948
step: 340, loss: 0.08476322889328003
step: 350, loss: 0.058588217943906784
step: 360, loss: 0.19995583593845367
step: 370, loss: 0.025071145966649055
step: 380, loss: 0.0056287506595253944
step: 390, loss: 0.005540212616324425
step: 400, loss: 0.021796906366944313
step: 410, loss: 0.008987386710941792
step: 420, loss: 0.05858919396996498
step: 430, loss: 0.09044049680233002
step: 440, loss: 0.036096248775720596
step: 450, loss: 0.08858756721019745
step: 460, loss: 0.0769723579287529
step: 470, loss: 0.0179080069065094
step: 480, loss: 0.03732621297240257
step: 490, loss: 0.0008543177391402423
step: 500, loss: 0.02029665932059288
step: 510, loss: 0.03780168667435646
step: 520, loss: 0.12464086711406708
step: 530, loss: 0.04695972055196762
step: 540, loss: 0.11266596615314484
step: 550, loss: 0.06425878405570984
step: 560, loss: 0.03713477775454521
step: 570, loss: 0.03231728821992874
step: 580, loss: 0.0039008590392768383
step: 590, loss: 0.001738554798066616
step: 600, loss: 0.030238157138228416
step: 610, loss: 0.017710868269205093
step: 620, loss: 0.024598877876996994
step: 630, loss: 0.14305192232131958
step: 640, loss: 0.08041039854288101
step: 650, loss: 0.01398911327123642
step: 660, loss: 0.02063542976975441
step: 670, loss: 0.09595001488924026
step: 680, loss: 0.1570148915052414
step: 690, loss: 0.007712953258305788
step: 700, loss: 0.13807770609855652
step: 710, loss: 0.021307168528437614
step: 720, loss: 0.06018265336751938
step: 730, loss: 0.08037526905536652
step: 740, loss: 0.1258959323167801
step: 750, loss: 0.08397265523672104
step: 760, loss: 0.06793142855167389
step: 770, loss: 0.01611463725566864
step: 780, loss: 0.023270582780241966
step: 790, loss: 0.18477146327495575
step: 800, loss: 0.02307637594640255
step: 810, loss: 0.03965777903795242
step: 820, loss: 0.0390772670507431
step: 830, loss: 0.12408294528722763
step: 840, loss: 0.09844309836626053
step: 850, loss: 0.06945408880710602
step: 860, loss: 0.01009206473827362
step: 870, loss: 0.11646649986505508
step: 880, loss: 0.009297024458646774
step: 890, loss: 0.003012831090018153
step: 900, loss: 0.09023120999336243
step: 910, loss: 0.08159972727298737
step: 920, loss: 0.09008590877056122
step: 930, loss: 0.018708787858486176
step: 940, loss: 0.09706343710422516
step: 950, loss: 0.16773775219917297
step: 960, loss: 0.12135966122150421
step: 970, loss: 0.0926690474152565
step: 980, loss: 0.06923140585422516
step: 990, loss: 0.024831756949424744
step: 1000, loss: 0.007242201827466488
step: 1010, loss: 0.033185187727212906
step: 1020, loss: 0.013227866031229496
step: 1030, loss: 0.025719035416841507
step: 1040, loss: 0.054777611047029495
step: 1050, loss: 0.0159454382956028
step: 1060, loss: 0.03453913703560829
step: 1070, loss: 0.003994177561253309
epoch 7: dev_f1=0.9325323475046211, f1=0.9301470588235294, best_f1=0.9290023201856149
step: 0, loss: 0.03887605294585228
step: 10, loss: 0.06534360349178314
step: 20, loss: 0.0032695464324206114
step: 30, loss: 0.009997793473303318
step: 40, loss: 0.022815868258476257
step: 50, loss: 0.025152593851089478
step: 60, loss: 0.024732012301683426
step: 70, loss: 0.031070245429873466
step: 80, loss: 0.013420559465885162
step: 90, loss: 0.1065792366862297
step: 100, loss: 0.018852131441235542
step: 110, loss: 0.030490171164274216
step: 120, loss: 0.009835857897996902
step: 130, loss: 0.06836137175559998
step: 140, loss: 0.00901240948587656
step: 150, loss: 0.007917140610516071
step: 160, loss: 0.03964846581220627
step: 170, loss: 0.01849769800901413
step: 180, loss: 0.055364761501550674
step: 190, loss: 3.3872012863866985e-05
step: 200, loss: 0.1274527907371521
step: 210, loss: 0.023435618728399277
step: 220, loss: 0.010495414026081562
step: 230, loss: 0.0035046434495598078
step: 240, loss: 0.06779646128416061
step: 250, loss: 0.01980467326939106
step: 260, loss: 0.088239885866642
step: 270, loss: 0.10659277439117432
step: 280, loss: 0.10783734917640686
step: 290, loss: 0.07290541380643845
step: 300, loss: 0.08627787232398987
step: 310, loss: 0.02923104166984558
step: 320, loss: 0.05304067209362984
step: 330, loss: 0.004907664377242327
step: 340, loss: 0.05229300260543823
step: 350, loss: 0.015346778556704521
step: 360, loss: 0.008041931316256523
step: 370, loss: 0.07428339868783951
step: 380, loss: 0.13490162789821625
step: 390, loss: 0.025494279339909554
step: 400, loss: 0.07347041368484497
step: 410, loss: 0.08256124705076218
step: 420, loss: 0.0361754335463047
step: 430, loss: 0.01601310819387436
step: 440, loss: 0.027140723541378975
step: 450, loss: 0.02163233608007431
step: 460, loss: 0.03318391367793083
step: 470, loss: 0.06059933826327324
step: 480, loss: 0.04840109497308731
step: 490, loss: 0.01680786721408367
step: 500, loss: 0.06811907887458801
step: 510, loss: 0.06205814704298973
step: 520, loss: 0.030491609126329422
step: 530, loss: 0.05374084413051605
step: 540, loss: 0.007857080549001694
step: 550, loss: 0.009141918271780014
step: 560, loss: 0.0008376092300750315
step: 570, loss: 0.04857435077428818
step: 580, loss: 0.061241183429956436
step: 590, loss: 0.1364130675792694
step: 600, loss: 5.502102430909872e-05
step: 610, loss: 0.05307158827781677
step: 620, loss: 0.10346393287181854
step: 630, loss: 0.07035133242607117
step: 640, loss: 0.03494434431195259
step: 650, loss: 0.000899934209883213
step: 660, loss: 0.03558873012661934
step: 670, loss: 0.0008938807877711952
step: 680, loss: 0.024427758529782295
step: 690, loss: 0.025673883035779
step: 700, loss: 0.06632446497678757
step: 710, loss: 0.08968593180179596
step: 720, loss: 0.033044107258319855
step: 730, loss: 0.0481208898127079
step: 740, loss: 0.06423810869455338
step: 750, loss: 0.0005529558402486145
step: 760, loss: 0.004840249195694923
step: 770, loss: 0.03481563925743103
step: 780, loss: 0.015419784002006054
step: 790, loss: 0.0626843273639679
step: 800, loss: 0.059233736246824265
step: 810, loss: 0.051609206944704056
step: 820, loss: 0.010530442930758
step: 830, loss: 0.02488454431295395
step: 840, loss: 0.027462350204586983
step: 850, loss: 0.05257463455200195
step: 860, loss: 0.024675654247403145
step: 870, loss: 0.060046758502721786
step: 880, loss: 0.027450712397694588
step: 890, loss: 0.008989322930574417
step: 900, loss: 0.012512095272541046
step: 910, loss: 0.12426833063364029
step: 920, loss: 0.037304241210222244
step: 930, loss: 0.022643085569143295
step: 940, loss: 0.06349456310272217
step: 950, loss: 0.08303505182266235
step: 960, loss: 0.013329130597412586
step: 970, loss: 0.09434624761343002
step: 980, loss: 0.08449964225292206
step: 990, loss: 0.10491475462913513
step: 1000, loss: 0.015360740013420582
step: 1010, loss: 0.09372593462467194
step: 1020, loss: 0.0495186522603035
step: 1030, loss: 0.04103373363614082
step: 1040, loss: 0.008846452459692955
step: 1050, loss: 0.06405821442604065
step: 1060, loss: 0.04674464836716652
step: 1070, loss: 0.0012004446471109986
epoch 8: dev_f1=0.9332719742291763, f1=0.9348025711662074, best_f1=0.9290023201856149
step: 0, loss: 0.05657455325126648
step: 10, loss: 0.01661013625562191
step: 20, loss: 0.05622415244579315
step: 30, loss: 0.003137232270091772
step: 40, loss: 0.05300791561603546
step: 50, loss: 0.0025122370570898056
step: 60, loss: 0.07621694356203079
step: 70, loss: 0.16726870834827423
step: 80, loss: 0.05717821419239044
step: 90, loss: 0.039716627448797226
step: 100, loss: 0.03740512579679489
step: 110, loss: 0.025833051651716232
step: 120, loss: 0.003932801075279713
step: 130, loss: 0.039120715111494064
step: 140, loss: 0.10794496536254883
step: 150, loss: 0.006956685334444046
step: 160, loss: 0.1123717874288559
step: 170, loss: 0.00865652784705162
step: 180, loss: 0.03681584447622299
step: 190, loss: 0.09189356118440628
step: 200, loss: 0.09905768185853958
step: 210, loss: 0.14575417339801788
step: 220, loss: 0.08156337589025497
step: 230, loss: 0.12931875884532928
step: 240, loss: 0.013900809921324253
step: 250, loss: 0.06285875290632248
step: 260, loss: 0.025980768725275993
step: 270, loss: 0.04301304370164871
step: 280, loss: 0.06163058802485466
step: 290, loss: 0.095781110227108
step: 300, loss: 0.002303648740053177
step: 310, loss: 0.020352331921458244
step: 320, loss: 0.07575249671936035
step: 330, loss: 0.09079701453447342
step: 340, loss: 0.0031266375444829464
step: 350, loss: 0.01112655270844698
step: 360, loss: 0.005992998834699392
step: 370, loss: 0.11398057639598846
step: 380, loss: 0.009416849352419376
step: 390, loss: 0.04591304436326027
step: 400, loss: 0.0514223612844944
step: 410, loss: 0.0038129861932247877
step: 420, loss: 0.04307585954666138
step: 430, loss: 0.009305563755333424
step: 440, loss: 0.022747095674276352
step: 450, loss: 0.08247911185026169
step: 460, loss: 0.0644945353269577
step: 470, loss: 0.042750563472509384
step: 480, loss: 0.039070092141628265
step: 490, loss: 0.035975582897663116
step: 500, loss: 0.059895407408475876
step: 510, loss: 0.027627354487776756
step: 520, loss: 0.012192712165415287
step: 530, loss: 0.045620691031217575
step: 540, loss: 0.008005506359040737
step: 550, loss: 0.008276923559606075
step: 560, loss: 0.04507698491215706
step: 570, loss: 0.01674973964691162
step: 580, loss: 0.0503794327378273
step: 590, loss: 0.07101932913064957
step: 600, loss: 0.03274551406502724
step: 610, loss: 0.03444314002990723
step: 620, loss: 0.03754205256700516
step: 630, loss: 0.02183370850980282
step: 640, loss: 0.01640320010483265
step: 650, loss: 0.07550123333930969
step: 660, loss: 0.2634711265563965
step: 670, loss: 0.022825265303254128
step: 680, loss: 0.06701087951660156
step: 690, loss: 0.08638130873441696
step: 700, loss: 0.0129209840670228
step: 710, loss: 0.12481360882520676
step: 720, loss: 0.07012153416872025
step: 730, loss: 0.08870192617177963
step: 740, loss: 0.02034899778664112
step: 750, loss: 0.019291263073682785
step: 760, loss: 0.0430576466023922
step: 770, loss: 0.0013733429368585348
step: 780, loss: 0.01691490039229393
step: 790, loss: 0.0019719027914106846
step: 800, loss: 0.03983733057975769
step: 810, loss: 0.0658349096775055
step: 820, loss: 0.04060106351971626
step: 830, loss: 0.0007979499059729278
step: 840, loss: 0.056023839861154556
step: 850, loss: 0.12358415126800537
step: 860, loss: 0.12486845999956131
step: 870, loss: 0.061799753457307816
step: 880, loss: 0.05666389316320419
step: 890, loss: 0.012238046154379845
step: 900, loss: 0.10388366878032684
step: 910, loss: 0.0031735459342598915
step: 920, loss: 0.0768328309059143
step: 930, loss: 0.20773601531982422
step: 940, loss: 0.0045462194830179214
step: 950, loss: 0.01461245771497488
step: 960, loss: 0.0439910888671875
step: 970, loss: 0.0723935067653656
step: 980, loss: 0.1188754066824913
step: 990, loss: 0.06653323769569397
step: 1000, loss: 0.01216812152415514
step: 1010, loss: 0.029911743476986885
step: 1020, loss: 0.03344022482633591
step: 1030, loss: 0.02396300993859768
step: 1040, loss: 0.029854828491806984
step: 1050, loss: 0.05151548236608505
step: 1060, loss: 0.12283486872911453
step: 1070, loss: 0.07142750918865204
epoch 9: dev_f1=0.9387568555758683, f1=0.9339407744874716, best_f1=0.9339407744874716
step: 0, loss: 0.030420590192079544
step: 10, loss: 0.021180246025323868
step: 20, loss: 0.14425988495349884
step: 30, loss: 0.020820725709199905
step: 40, loss: 0.009903907775878906
step: 50, loss: 0.043630458414554596
step: 60, loss: 0.07478281110525131
step: 70, loss: 0.06184033304452896
step: 80, loss: 0.01727563515305519
step: 90, loss: 0.07001610100269318
step: 100, loss: 0.001996665494516492
step: 110, loss: 0.06381630152463913
step: 120, loss: 0.0233440101146698
step: 130, loss: 0.024901563301682472
step: 140, loss: 0.04310695827007294
step: 150, loss: 0.011424960568547249
step: 160, loss: 0.005707479547709227
step: 170, loss: 0.05641230195760727
step: 180, loss: 0.03839416056871414
step: 190, loss: 0.009210119023919106
step: 200, loss: 0.09905818849802017
step: 210, loss: 0.09471272677183151
step: 220, loss: 0.021349551156163216
step: 230, loss: 0.03677617758512497
step: 240, loss: 0.016927426680922508
step: 250, loss: 0.0011954514775425196
step: 260, loss: 0.3289145231246948
step: 270, loss: 0.09895812720060349
step: 280, loss: 0.02647012285888195
step: 290, loss: 0.025316543877124786
step: 300, loss: 0.030091334134340286
step: 310, loss: 0.06431450694799423
step: 320, loss: 0.00702043017372489
step: 330, loss: 0.005862083286046982
step: 340, loss: 0.06715928018093109
step: 350, loss: 0.11241880059242249
step: 360, loss: 0.026330551132559776
step: 370, loss: 0.11107691377401352
step: 380, loss: 0.011201177723705769
step: 390, loss: 0.10389251261949539
step: 400, loss: 0.03393927961587906
step: 410, loss: 0.007790653966367245
step: 420, loss: 0.061988335102796555
step: 430, loss: 0.13501107692718506
step: 440, loss: 0.029066085815429688
step: 450, loss: 0.005024355370551348
step: 460, loss: 0.004608656279742718
step: 470, loss: 0.021997883915901184
step: 480, loss: 0.021063659340143204
step: 490, loss: 0.15784531831741333
step: 500, loss: 0.1271451860666275
step: 510, loss: 0.029311738908290863
step: 520, loss: 0.029869727790355682
step: 530, loss: 0.0022454550489783287
step: 540, loss: 0.0296616330742836
step: 550, loss: 0.06086999922990799
step: 560, loss: 0.09409084916114807
step: 570, loss: 0.055906955152750015
step: 580, loss: 0.0731300488114357
step: 590, loss: 0.0007494860328733921
step: 600, loss: 0.050167959183454514
step: 610, loss: 0.04783087968826294
step: 620, loss: 0.02971518784761429
step: 630, loss: 0.03520897775888443
step: 640, loss: 0.04817990958690643
step: 650, loss: 0.04794918745756149
step: 660, loss: 0.04607619717717171
step: 670, loss: 0.019884321838617325
step: 680, loss: 0.07093444466590881
step: 690, loss: 0.07626135647296906
step: 700, loss: 0.04414348304271698
step: 710, loss: 0.013343973085284233
step: 720, loss: 0.022961849346756935
step: 730, loss: 0.13618649542331696
step: 740, loss: 0.0007817287696525455
step: 750, loss: 0.04315023124217987
step: 760, loss: 0.009829220362007618
step: 770, loss: 0.038119126111269
step: 780, loss: 0.014871018007397652
step: 790, loss: 0.0035288906656205654
step: 800, loss: 0.036809228360652924
step: 810, loss: 0.054913222789764404
step: 820, loss: 0.06124819070100784
step: 830, loss: 0.056737691164016724
step: 840, loss: 2.4646109523018822e-05
step: 850, loss: 0.0007831687107682228
step: 860, loss: 0.004816989414393902
step: 870, loss: 0.010479954071342945
step: 880, loss: 0.0485781654715538
step: 890, loss: 0.051946431398391724
step: 900, loss: 0.07586964964866638
step: 910, loss: 0.08083518594503403
step: 920, loss: 0.058435022830963135
step: 930, loss: 0.03243713080883026
step: 940, loss: 0.031297504901885986
step: 950, loss: 0.06407323479652405
step: 960, loss: 0.10543109476566315
step: 970, loss: 0.02696123719215393
step: 980, loss: 0.03141943737864494
step: 990, loss: 0.018563132733106613
step: 1000, loss: 0.0057283733040094376
step: 1010, loss: 0.0011917240917682648
step: 1020, loss: 0.03387356549501419
step: 1030, loss: 0.039171457290649414
step: 1040, loss: 0.03588460013270378
step: 1050, loss: 0.11158517003059387
step: 1060, loss: 0.1168147623538971
step: 1070, loss: 0.08251279592514038
epoch 10: dev_f1=0.9272976680384087, f1=0.9249658935879944, best_f1=0.9339407744874716
step: 0, loss: 0.08587737381458282
step: 10, loss: 0.015951989218592644
step: 20, loss: 0.03452913463115692
step: 30, loss: 0.17379635572433472
step: 40, loss: 0.0027582496404647827
step: 50, loss: 0.060125682502985
step: 60, loss: 0.035587962716817856
step: 70, loss: 0.0005144084570929408
step: 80, loss: 0.00020504456188064069
step: 90, loss: 0.005600174888968468
step: 100, loss: 0.0036240762565284967
step: 110, loss: 0.14006155729293823
step: 120, loss: 0.023997100070118904
step: 130, loss: 0.04276875779032707
step: 140, loss: 0.049440816044807434
step: 150, loss: 0.0009641696233302355
step: 160, loss: 0.02684091217815876
step: 170, loss: 0.019268415868282318
step: 180, loss: 0.0027711563743650913
step: 190, loss: 0.012983063235878944
step: 200, loss: 0.01926420070230961
step: 210, loss: 0.023884553462266922
step: 220, loss: 0.05123744532465935
step: 230, loss: 0.1325533241033554
step: 240, loss: 0.0017924188869073987
step: 250, loss: 0.002305832225829363
step: 260, loss: 0.051348455250263214
step: 270, loss: 0.0028599202632904053
step: 280, loss: 0.031686924397945404
step: 290, loss: 0.015580866485834122
step: 300, loss: 0.0811079889535904
step: 310, loss: 9.170483099296689e-05
step: 320, loss: 0.004573458805680275
step: 330, loss: 0.05246477946639061
step: 340, loss: 0.002104954794049263
step: 350, loss: 0.051142722368240356
step: 360, loss: 0.07503516227006912
step: 370, loss: 0.0009636479080654681
step: 380, loss: 0.10393114387989044
step: 390, loss: 0.08073890954256058
step: 400, loss: 0.051205966621637344
step: 410, loss: 0.03452962636947632
step: 420, loss: 0.036244891583919525
step: 430, loss: 0.006733062211424112
step: 440, loss: 0.003012938890606165
step: 450, loss: 0.0008102561696432531
step: 460, loss: 0.09301230311393738
step: 470, loss: 0.13667507469654083
step: 480, loss: 0.0326109305024147
step: 490, loss: 0.04873035103082657
step: 500, loss: 0.05301576852798462
step: 510, loss: 0.045699600130319595
step: 520, loss: 0.05402510240674019
step: 530, loss: 0.030828358605504036
step: 540, loss: 0.02699929103255272
step: 550, loss: 0.05417688563466072
step: 560, loss: 0.09715259820222855
step: 570, loss: 0.06533276289701462
step: 580, loss: 0.04772676154971123
step: 590, loss: 0.0010465860832482576
step: 600, loss: 0.016723914071917534
step: 610, loss: 0.01858619600534439
step: 620, loss: 0.012988789938390255
step: 630, loss: 0.03285824880003929
step: 640, loss: 0.13064098358154297
step: 650, loss: 0.026831094175577164
step: 660, loss: 0.008567048236727715
step: 670, loss: 0.1601864993572235
step: 680, loss: 0.015352830290794373
step: 690, loss: 0.035725753754377365
step: 700, loss: 0.013832363300025463
step: 710, loss: 0.0053204698488116264
step: 720, loss: 0.13896353542804718
step: 730, loss: 0.0020272540859878063
step: 740, loss: 0.02810179814696312
step: 750, loss: 0.014232665300369263
step: 760, loss: 0.04379035905003548
step: 770, loss: 0.005533324088901281
step: 780, loss: 0.02914172038435936
step: 790, loss: 0.007114562205970287
step: 800, loss: 0.0004793312109541148
step: 810, loss: 0.019290747120976448
step: 820, loss: 0.031427450478076935
step: 830, loss: 0.05699814110994339
step: 840, loss: 0.053288377821445465
step: 850, loss: 0.012740427628159523
step: 860, loss: 0.04589894413948059
step: 870, loss: 0.029506441205739975
step: 880, loss: 0.03723360225558281
step: 890, loss: 0.05200621113181114
step: 900, loss: 0.06357534229755402
step: 910, loss: 0.06897743791341782
step: 920, loss: 0.12347911298274994
step: 930, loss: 0.03430092707276344
step: 940, loss: 0.06756201386451721
step: 950, loss: 0.03680168837308884
step: 960, loss: 0.06314366310834885
step: 970, loss: 0.02473009005188942
step: 980, loss: 0.06312612444162369
step: 990, loss: 0.006651189643889666
step: 1000, loss: 0.01371442899107933
step: 1010, loss: 5.132362639415078e-05
step: 1020, loss: 0.014689934439957142
step: 1030, loss: 0.1903836876153946
step: 1040, loss: 0.04380647838115692
step: 1050, loss: 0.03626754879951477
step: 1060, loss: 0.0636005699634552
step: 1070, loss: 0.00501511013135314
epoch 11: dev_f1=0.9299129638112689, f1=0.9261440869959222, best_f1=0.9339407744874716
step: 0, loss: 0.019315354526042938
step: 10, loss: 0.033174335956573486
step: 20, loss: 0.05119306221604347
step: 30, loss: 0.051773056387901306
step: 40, loss: 0.04960329085588455
step: 50, loss: 0.08245132118463516
step: 60, loss: 0.04344259202480316
step: 70, loss: 0.031222335994243622
step: 80, loss: 0.04803945869207382
step: 90, loss: 0.03979484364390373
step: 100, loss: 0.0015137132722884417
step: 110, loss: 0.03018796071410179
step: 120, loss: 0.022370746359229088
step: 130, loss: 0.03042571246623993
step: 140, loss: 0.060899101197719574
step: 150, loss: 0.08189805597066879
step: 160, loss: 0.033981457352638245
step: 170, loss: 0.09039278328418732
step: 180, loss: 0.030070016160607338
step: 190, loss: 0.0251392163336277
step: 200, loss: 0.02184428460896015
step: 210, loss: 0.00011289065150776878
step: 220, loss: 0.0008097915560938418
step: 230, loss: 0.05256025493144989
step: 240, loss: 0.024080170318484306
step: 250, loss: 0.05694036930799484
step: 260, loss: 0.02188732475042343
step: 270, loss: 0.0002746554964687675
step: 280, loss: 0.021641697734594345
step: 290, loss: 0.07308518141508102
step: 300, loss: 0.03545573353767395
step: 310, loss: 0.07064291834831238
step: 320, loss: 0.011122277937829494
step: 330, loss: 0.007106367032974958
step: 340, loss: 0.04580247774720192
step: 350, loss: 0.0803644061088562
step: 360, loss: 0.031076593324542046
step: 370, loss: 0.0004583121044561267
step: 380, loss: 0.0033373639453202486
step: 390, loss: 0.11603894829750061
step: 400, loss: 0.0008865628624334931
step: 410, loss: 0.016306443139910698
step: 420, loss: 0.0448266938328743
step: 430, loss: 0.03441770002245903
step: 440, loss: 0.03147542104125023
step: 450, loss: 0.026754869148135185
step: 460, loss: 0.018754560500383377
step: 470, loss: 0.04900394007563591
step: 480, loss: 0.050702501088380814
step: 490, loss: 0.03986405208706856
step: 500, loss: 0.12674292922019958
step: 510, loss: 0.1799471378326416
step: 520, loss: 0.043156594038009644
step: 530, loss: 0.04747459292411804
step: 540, loss: 0.03485095873475075
step: 550, loss: 0.00654058950021863
step: 560, loss: 0.05581061169505119
step: 570, loss: 0.05608557164669037
step: 580, loss: 0.06744059175252914
step: 590, loss: 0.0003552582929842174
step: 600, loss: 0.011419582180678844
step: 610, loss: 0.034319039434194565
step: 620, loss: 0.0688520222902298
step: 630, loss: 0.04914432391524315
step: 640, loss: 0.007749846670776606
step: 650, loss: 0.0014065916184335947
step: 660, loss: 0.001001134980469942
step: 670, loss: 0.03200320899486542
step: 680, loss: 0.0011582158040255308
step: 690, loss: 0.07852061092853546
step: 700, loss: 0.004126190673559904
step: 710, loss: 0.051499392837285995
step: 720, loss: 0.07893537729978561
step: 730, loss: 0.009262586943805218
step: 740, loss: 0.008946212939918041
step: 750, loss: 0.08646801859140396
step: 760, loss: 0.08899664878845215
step: 770, loss: 0.058544982224702835
step: 780, loss: 0.05151927098631859
step: 790, loss: 0.02975740097463131
step: 800, loss: 0.006854449864476919
step: 810, loss: 0.1336238980293274
step: 820, loss: 0.016608089208602905
step: 830, loss: 0.021352095529437065
step: 840, loss: 0.02629723772406578
step: 850, loss: 0.0006360879051499069
step: 860, loss: 0.023574266582727432
step: 870, loss: 1.6823145415401086e-05
step: 880, loss: 0.051298242062330246
step: 890, loss: 0.04557964578270912
step: 900, loss: 0.024520268663764
step: 910, loss: 0.019270529970526695
step: 920, loss: 0.013157656416296959
step: 930, loss: 0.053206395357847214
step: 940, loss: 0.002189473481848836
step: 950, loss: 0.0022145055700093508
step: 960, loss: 0.010531877167522907
step: 970, loss: 0.05506908521056175
step: 980, loss: 0.021843472495675087
step: 990, loss: 0.009591751731932163
step: 1000, loss: 0.023522743955254555
step: 1010, loss: 0.01651259884238243
step: 1020, loss: 0.042484063655138016
step: 1030, loss: 0.11062397807836533
step: 1040, loss: 0.03328713774681091
step: 1050, loss: 0.002183958888053894
step: 1060, loss: 0.027221307158470154
step: 1070, loss: 0.04978010430932045
epoch 12: dev_f1=0.9321016166281756, f1=0.928801102434543, best_f1=0.9339407744874716
step: 0, loss: 0.0278844702988863
step: 10, loss: 0.005556553136557341
step: 20, loss: 0.06464488059282303
step: 30, loss: 0.030238430947065353
step: 40, loss: 9.659430361352861e-05
step: 50, loss: 0.03769629821181297
step: 60, loss: 0.03530685603618622
step: 70, loss: 0.05283878371119499
step: 80, loss: 0.00587758282199502
step: 90, loss: 0.020023992285132408
step: 100, loss: 0.002136626048013568
step: 110, loss: 0.03304208442568779
step: 120, loss: 0.0023291995748877525
step: 130, loss: 0.1303962916135788
step: 140, loss: 0.007880850695073605
step: 150, loss: 0.018220221623778343
step: 160, loss: 0.03175082057714462
step: 170, loss: 0.03561657667160034
step: 180, loss: 0.05401318520307541
step: 190, loss: 0.0767989307641983
step: 200, loss: 0.1624533236026764
step: 210, loss: 0.007467926479876041
step: 220, loss: 0.042395006865262985
step: 230, loss: 0.018536774441599846
step: 240, loss: 0.007773079443722963
step: 250, loss: 0.040767621248960495
step: 260, loss: 0.10357627272605896
step: 270, loss: 0.008872140198946
step: 280, loss: 0.0008401136146858335
step: 290, loss: 0.034493520855903625
step: 300, loss: 0.000682610145304352
step: 310, loss: 0.0008931180345825851
step: 320, loss: 0.0354713574051857
step: 330, loss: 2.761714131338522e-05
step: 340, loss: 0.00016857880109455436
step: 350, loss: 0.021650174632668495
step: 360, loss: 0.05619324371218681
step: 370, loss: 0.05838386341929436
step: 380, loss: 0.048557184636592865
step: 390, loss: 0.026144353672862053
step: 400, loss: 0.04088372364640236
step: 410, loss: 0.06936243921518326
step: 420, loss: 0.05617022141814232
step: 430, loss: 0.04632836952805519
step: 440, loss: 0.00032388727413490415
step: 450, loss: 0.0024588059168308973
step: 460, loss: 0.00043697969522327185
step: 470, loss: 0.07418758422136307
step: 480, loss: 0.038639020174741745
step: 490, loss: 0.04688916355371475
step: 500, loss: 0.0015769116580486298
step: 510, loss: 0.016303066164255142
step: 520, loss: 0.11795550584793091
step: 530, loss: 0.06189766526222229
step: 540, loss: 0.014801878482103348
step: 550, loss: 0.054791681468486786
step: 560, loss: 0.0006954885320737958
step: 570, loss: 0.0002727002138271928
step: 580, loss: 0.12756726145744324
step: 590, loss: 0.02080913633108139
step: 600, loss: 0.03693166375160217
step: 610, loss: 0.0016133124008774757
step: 620, loss: 0.0008415724150836468
step: 630, loss: 0.02631969191133976
step: 640, loss: 0.06668505817651749
step: 650, loss: 0.0016313763335347176
step: 660, loss: 0.11703817546367645
step: 670, loss: 0.08569261431694031
step: 680, loss: 0.08272630721330643
step: 690, loss: 0.06740989536046982
step: 700, loss: 0.10107304900884628
step: 710, loss: 0.04703560844063759
step: 720, loss: 0.03184518218040466
step: 730, loss: 0.018695341423153877
step: 740, loss: 0.050198569893836975
step: 750, loss: 0.06749926507472992
step: 760, loss: 0.04912521690130234
step: 770, loss: 0.04015259072184563
step: 780, loss: 0.05375393107533455
step: 790, loss: 0.03959820047020912
step: 800, loss: 0.01868218183517456
step: 810, loss: 0.004919008817523718
step: 820, loss: 0.0003774359356611967
step: 830, loss: 0.02093607187271118
step: 840, loss: 0.08515268564224243
step: 850, loss: 0.09883399307727814
step: 860, loss: 5.373569001676515e-05
step: 870, loss: 0.02414308302104473
step: 880, loss: 0.027971280738711357
step: 890, loss: 0.04790053516626358
step: 900, loss: 0.0017774896696209908
step: 910, loss: 0.0009455610415898263
step: 920, loss: 0.04387066513299942
step: 930, loss: 0.046339306980371475
step: 940, loss: 0.0006963061168789864
step: 950, loss: 0.07030021399259567
step: 960, loss: 0.0416916124522686
step: 970, loss: 0.00015269263531081378
step: 980, loss: 0.015648864209651947
step: 990, loss: 0.018842607736587524
step: 1000, loss: 0.015552946366369724
step: 1010, loss: 0.08279023319482803
step: 1020, loss: 0.05756711587309837
step: 1030, loss: 0.03204645216464996
step: 1040, loss: 0.006199630443006754
step: 1050, loss: 0.009027012623846531
step: 1060, loss: 0.05565514415502548
step: 1070, loss: 0.0588282085955143
epoch 13: dev_f1=0.9327272727272726, f1=0.9315192743764172, best_f1=0.9339407744874716
step: 0, loss: 0.05197153240442276
step: 10, loss: 0.04982752352952957
step: 20, loss: 0.025470687076449394
step: 30, loss: 0.012163981795310974
step: 40, loss: 0.04049230366945267
step: 50, loss: 6.398451660061255e-05
step: 60, loss: 0.0002767787373159081
step: 70, loss: 0.007425141055136919
step: 80, loss: 0.08161874115467072
step: 90, loss: 0.03354416415095329
step: 100, loss: 0.06886132061481476
step: 110, loss: 0.03467649966478348
step: 120, loss: 4.659191472455859e-05
step: 130, loss: 0.0012701299274340272
step: 140, loss: 0.0434948205947876
step: 150, loss: 0.006335836369544268
step: 160, loss: 0.1055578663945198
step: 170, loss: 0.013575068674981594
step: 180, loss: 0.02182067185640335
step: 190, loss: 0.053918857127428055
step: 200, loss: 0.06338634341955185
step: 210, loss: 0.027671685442328453
step: 220, loss: 0.013060146011412144
step: 230, loss: 0.02782398648560047
step: 240, loss: 0.022253919392824173
step: 250, loss: 0.011201836168766022
step: 260, loss: 0.016132498160004616
step: 270, loss: 0.005601578392088413
step: 280, loss: 0.004222690127789974
step: 290, loss: 0.012702595442533493
step: 300, loss: 0.020123692229390144
step: 310, loss: 0.04013962671160698
step: 320, loss: 7.640496187377721e-05
step: 330, loss: 2.8857215511379763e-05
step: 340, loss: 0.013774988241493702
step: 350, loss: 0.018987683579325676
step: 360, loss: 0.0696672797203064
step: 370, loss: 0.015907825902104378
step: 380, loss: 0.0006129939574748278
step: 390, loss: 0.014005070552229881
step: 400, loss: 0.0004306563059799373
step: 410, loss: 0.05913551151752472
step: 420, loss: 0.01600257121026516
step: 430, loss: 0.10502295196056366
step: 440, loss: 0.051678068935871124
step: 450, loss: 0.008720035664737225
step: 460, loss: 0.016683131456375122
step: 470, loss: 0.003764544613659382
step: 480, loss: 0.02381305769085884
step: 490, loss: 0.04694392532110214
step: 500, loss: 0.024601425975561142
step: 510, loss: 0.11666330695152283
step: 520, loss: 0.025070015341043472
step: 530, loss: 0.04915018752217293
step: 540, loss: 0.014968418516218662
step: 550, loss: 0.04701065644621849
step: 560, loss: 0.005835981573909521
step: 570, loss: 0.05843905359506607
step: 580, loss: 2.8716394808725454e-05
step: 590, loss: 0.020638717338442802
step: 600, loss: 0.03374134749174118
step: 610, loss: 0.07395860552787781
step: 620, loss: 8.060906839091331e-05
step: 630, loss: 0.10439523309469223
step: 640, loss: 0.01906094141304493
step: 650, loss: 0.018832871690392494
step: 660, loss: 0.022976865991950035
step: 670, loss: 0.018971823155879974
step: 680, loss: 0.035084549337625504
step: 690, loss: 0.09395629167556763
step: 700, loss: 0.03859521076083183
step: 710, loss: 0.00023580621927976608
step: 720, loss: 0.03955427557229996
step: 730, loss: 0.04153115302324295
step: 740, loss: 1.528461871203035e-05
step: 750, loss: 0.023541655391454697
step: 760, loss: 0.039863221347332
step: 770, loss: 0.0001666162715991959
step: 780, loss: 0.0013426797231659293
step: 790, loss: 0.06699071079492569
step: 800, loss: 0.030159808695316315
step: 810, loss: 0.000378106371499598
step: 820, loss: 0.06811337172985077
step: 830, loss: 0.06989401578903198
step: 840, loss: 0.06247517466545105
step: 850, loss: 0.004349450580775738
step: 860, loss: 0.027666840702295303
step: 870, loss: 0.044019460678100586
step: 880, loss: 0.03551797196269035
step: 890, loss: 0.052115548402071
step: 900, loss: 0.0007490625139325857
step: 910, loss: 0.04661212116479874
step: 920, loss: 0.02944466844201088
step: 930, loss: 1.7881036910694093e-05
step: 940, loss: 0.0488823726773262
step: 950, loss: 0.029469812288880348
step: 960, loss: 0.00016120831423904747
step: 970, loss: 0.005319533403962851
step: 980, loss: 0.0646987184882164
step: 990, loss: 0.0013174705673009157
step: 1000, loss: 0.05029415339231491
step: 1010, loss: 0.00319535075686872
step: 1020, loss: 0.005505261942744255
step: 1030, loss: 0.02066897787153721
step: 1040, loss: 0.11867969483137131
step: 1050, loss: 0.02414904534816742
step: 1060, loss: 0.0455024391412735
step: 1070, loss: 0.07630015909671783
epoch 14: dev_f1=0.9336426914153132, f1=0.9313047487321346, best_f1=0.9339407744874716
step: 0, loss: 0.022881412878632545
step: 10, loss: 0.024853281676769257
step: 20, loss: 0.09374655783176422
step: 30, loss: 0.0041402531787753105
step: 40, loss: 0.029989594593644142
step: 50, loss: 0.01706627756357193
step: 60, loss: 0.022264549508690834
step: 70, loss: 0.04419877007603645
step: 80, loss: 0.0364944227039814
step: 90, loss: 0.03760285675525665
step: 100, loss: 0.02129877731204033
step: 110, loss: 0.0958310142159462
step: 120, loss: 0.06645434349775314
step: 130, loss: 0.000324210268445313
step: 140, loss: 0.03347260504961014
step: 150, loss: 0.00010182830010307953
step: 160, loss: 0.05177490785717964
step: 170, loss: 0.0022448778618127108
step: 180, loss: 0.03885680437088013
step: 190, loss: 0.022844048216938972
step: 200, loss: 0.0003057956346310675
step: 210, loss: 0.04823457822203636
step: 220, loss: 4.6640081563964486e-05
step: 230, loss: 0.014998827129602432
step: 240, loss: 0.020770864561200142
step: 250, loss: 0.02978373132646084
step: 260, loss: 0.01868452876806259
step: 270, loss: 0.06225457787513733
step: 280, loss: 0.021980714052915573
step: 290, loss: 0.0001288905623368919
step: 300, loss: 0.06443122029304504
step: 310, loss: 0.03669898211956024
step: 320, loss: 1.182022606371902e-05
step: 330, loss: 0.009455950930714607
step: 340, loss: 0.0005451706820167601
step: 350, loss: 0.008104212582111359
step: 360, loss: 0.02898569405078888
step: 370, loss: 0.05143045634031296
step: 380, loss: 0.0218132883310318
step: 390, loss: 0.007199687883257866
step: 400, loss: 0.05163305625319481
step: 410, loss: 6.766837032046169e-05
step: 420, loss: 0.022855328395962715
step: 430, loss: 0.007694288622587919
step: 440, loss: 0.0007709742640145123
step: 450, loss: 0.019339337944984436
step: 460, loss: 0.0001341940078418702
step: 470, loss: 0.00792658980935812
step: 480, loss: 3.271905006840825e-05
step: 490, loss: 0.03161337226629257
step: 500, loss: 0.017476674169301987
step: 510, loss: 0.022023843601346016
step: 520, loss: 0.02253161184489727
step: 530, loss: 0.0880398377776146
step: 540, loss: 0.05036633834242821
step: 550, loss: 0.024755455553531647
step: 560, loss: 0.00714012049138546
step: 570, loss: 0.046555325388908386
step: 580, loss: 0.019885901361703873
step: 590, loss: 0.14361846446990967
step: 600, loss: 0.017384223639965057
step: 610, loss: 0.011055693961679935
step: 620, loss: 0.0003560986078809947
step: 630, loss: 0.0432884506881237
step: 640, loss: 0.06168200448155403
step: 650, loss: 0.019330615177750587
step: 660, loss: 0.05107968673110008
step: 670, loss: 0.03346904367208481
step: 680, loss: 0.025803351774811745
step: 690, loss: 0.030205773189663887
step: 700, loss: 0.022173944860696793
step: 710, loss: 0.04839039966464043
step: 720, loss: 0.05610815808176994
step: 730, loss: 0.0466940738260746
step: 740, loss: 0.007501592393964529
step: 750, loss: 0.06262651830911636
step: 760, loss: 0.020104868337512016
step: 770, loss: 0.00012926316412631422
step: 780, loss: 0.0025256453081965446
step: 790, loss: 0.07056357711553574
step: 800, loss: 8.950624032877386e-05
step: 810, loss: 2.937061981356237e-05
step: 820, loss: 0.02179361693561077
step: 830, loss: 4.99522102472838e-05
step: 840, loss: 0.05316433683037758
step: 850, loss: 0.07710864394903183
step: 860, loss: 0.004190737847238779
step: 870, loss: 9.231857256963849e-05
step: 880, loss: 0.021049531176686287
step: 890, loss: 0.02059325948357582
step: 900, loss: 0.0517791286110878
step: 910, loss: 0.02154863439500332
step: 920, loss: 0.1095045879483223
step: 930, loss: 0.022014833986759186
step: 940, loss: 0.049574755132198334
step: 950, loss: 0.0029991772025823593
step: 960, loss: 0.041017286479473114
step: 970, loss: 0.046709951013326645
step: 980, loss: 0.055562082678079605
step: 990, loss: 0.018305277451872826
step: 1000, loss: 0.018653197214007378
step: 1010, loss: 0.026401562616229057
step: 1020, loss: 0.05108003318309784
step: 1030, loss: 0.05526044964790344
step: 1040, loss: 0.019097385928034782
step: 1050, loss: 0.06314925104379654
step: 1060, loss: 0.0003059955488424748
step: 1070, loss: 0.032527439296245575
epoch 15: dev_f1=0.926829268292683, f1=0.9213377296278851, best_f1=0.9339407744874716
step: 0, loss: 0.0004117858479730785
step: 10, loss: 0.035927996039390564
step: 20, loss: 0.00261461129412055
step: 30, loss: 0.04919241741299629
step: 40, loss: 0.0981387197971344
step: 50, loss: 0.017400454729795456
step: 60, loss: 0.02532968856394291
step: 70, loss: 0.1373172402381897
step: 80, loss: 0.03417635336518288
step: 90, loss: 0.1010514423251152
step: 100, loss: 0.06035357713699341
step: 110, loss: 0.036742884665727615
step: 120, loss: 0.08102162927389145
step: 130, loss: 0.000155098459799774
step: 140, loss: 0.04592111334204674
step: 150, loss: 0.03569016978144646
step: 160, loss: 0.04398435354232788
step: 170, loss: 0.05118145793676376
step: 180, loss: 0.014971560798585415
step: 190, loss: 0.022262055426836014
step: 200, loss: 0.020516611635684967
step: 210, loss: 3.521368853398599e-05
step: 220, loss: 0.03778558969497681
step: 230, loss: 0.1381397843360901
step: 240, loss: 0.0005208885413594544
step: 250, loss: 4.074268872500397e-05
step: 260, loss: 0.07165126502513885
step: 270, loss: 0.02569654956459999
step: 280, loss: 0.01467921957373619
step: 290, loss: 0.04476609826087952
step: 300, loss: 0.05494256317615509
step: 310, loss: 1.4405310139409266e-05
step: 320, loss: 0.06311867386102676
step: 330, loss: 6.699824007228017e-05
step: 340, loss: 0.0005223123589530587
step: 350, loss: 0.01562955603003502
step: 360, loss: 0.0624317042529583
step: 370, loss: 0.030596613883972168
step: 380, loss: 0.09403737634420395
step: 390, loss: 0.024198150262236595
step: 400, loss: 0.023117611184716225
step: 410, loss: 0.05858132988214493
step: 420, loss: 0.0006133086862973869
step: 430, loss: 0.03090432472527027
step: 440, loss: 0.04193320870399475
step: 450, loss: 0.007444694638252258
step: 460, loss: 9.29259549593553e-05
step: 470, loss: 0.03745442256331444
step: 480, loss: 7.485441165044904e-05
step: 490, loss: 0.000401868048356846
step: 500, loss: 0.05555625632405281
step: 510, loss: 0.06203552335500717
step: 520, loss: 0.03943633660674095
step: 530, loss: 0.009261964820325375
step: 540, loss: 4.5062985009280965e-05
step: 550, loss: 0.0007769994554109871
step: 560, loss: 0.029174061492085457
step: 570, loss: 0.026041749864816666
step: 580, loss: 0.025753984227776527
step: 590, loss: 0.014030100777745247
step: 600, loss: 0.00015708636783529073
step: 610, loss: 0.00011207678471691906
step: 620, loss: 0.05154234915971756
step: 630, loss: 0.03833863511681557
step: 640, loss: 1.691964098426979e-05
step: 650, loss: 0.0007909900741651654
step: 660, loss: 0.01912742108106613
step: 670, loss: 0.02430935576558113
step: 680, loss: 0.0009953293483704329
step: 690, loss: 0.00032456990447826684
step: 700, loss: 0.027591515332460403
step: 710, loss: 0.02315935492515564
step: 720, loss: 0.00020701769972220063
step: 730, loss: 0.019439175724983215
step: 740, loss: 0.047864291816949844
step: 750, loss: 0.013600382022559643
step: 760, loss: 0.00020602098084054887
step: 770, loss: 0.020778939127922058
step: 780, loss: 0.005359304137527943
step: 790, loss: 0.0761832520365715
step: 800, loss: 0.023231791332364082
step: 810, loss: 0.0262837503105402
step: 820, loss: 0.029777714982628822
step: 830, loss: 1.5038688616186846e-05
step: 840, loss: 3.362816642038524e-05
step: 850, loss: 0.02063428796827793
step: 860, loss: 0.0005957583780400455
step: 870, loss: 0.020022831857204437
step: 880, loss: 0.022373847663402557
step: 890, loss: 0.04608534649014473
step: 900, loss: 0.023055534809827805
step: 910, loss: 0.035127297043800354
step: 920, loss: 7.593438203912228e-05
step: 930, loss: 0.001385298790410161
step: 940, loss: 0.00011461770191090181
step: 950, loss: 0.024239087477326393
step: 960, loss: 0.04333615303039551
step: 970, loss: 0.00022798952704761177
step: 980, loss: 0.02429640293121338
step: 990, loss: 0.01964600756764412
step: 1000, loss: 0.03679438680410385
step: 1010, loss: 4.209397593513131e-05
step: 1020, loss: 0.03149786219000816
step: 1030, loss: 0.035918060690164566
step: 1040, loss: 0.044082265347242355
step: 1050, loss: 7.251107308547944e-05
step: 1060, loss: 0.02746211737394333
step: 1070, loss: 0.01612958312034607
epoch 16: dev_f1=0.9314814814814815, f1=0.9300602130616026, best_f1=0.9339407744874716
step: 0, loss: 0.06384435296058655
step: 10, loss: 0.008655432611703873
step: 20, loss: 0.03390710428357124
step: 30, loss: 0.03544292598962784
step: 40, loss: 0.03984828665852547
step: 50, loss: 0.02462952770292759
step: 60, loss: 0.03239129111170769
step: 70, loss: 4.7308803914347664e-05
step: 80, loss: 0.03018200956285
step: 90, loss: 0.0002808158751577139
step: 100, loss: 0.04931933060288429
step: 110, loss: 0.020760009065270424
step: 120, loss: 0.04744621738791466
step: 130, loss: 7.198207458714023e-05
step: 140, loss: 0.00018189658294431865
step: 150, loss: 0.018759513273835182
step: 160, loss: 0.05765317752957344
step: 170, loss: 0.009349904023110867
step: 180, loss: 0.01410167571157217
step: 190, loss: 0.022226333618164062
step: 200, loss: 0.00047072835150174797
step: 210, loss: 0.0012968190712854266
step: 220, loss: 0.01558371726423502
step: 230, loss: 0.02592926286160946
step: 240, loss: 0.015327653847634792
step: 250, loss: 0.04555550590157509
step: 260, loss: 0.0033648626413196325
step: 270, loss: 0.004885764792561531
step: 280, loss: 0.012146925553679466
step: 290, loss: 0.07463046908378601
step: 300, loss: 0.0011518466053530574
step: 310, loss: 7.584349805256352e-05
step: 320, loss: 0.032476529479026794
step: 330, loss: 1.8912593077402562e-05
step: 340, loss: 3.727682997123338e-05
step: 350, loss: 6.275270425248891e-05
step: 360, loss: 0.0243738554418087
step: 370, loss: 0.024137265980243683
step: 380, loss: 0.026369094848632812
step: 390, loss: 0.0384000763297081
step: 400, loss: 0.10906120389699936
step: 410, loss: 0.0001267802290385589
step: 420, loss: 0.024221668019890785
step: 430, loss: 0.08411487191915512
step: 440, loss: 0.04618404433131218
step: 450, loss: 0.025166748091578484
step: 460, loss: 0.02054796926677227
step: 470, loss: 0.05042574927210808
step: 480, loss: 0.000249693141086027
step: 490, loss: 0.018068930134177208
step: 500, loss: 0.009206763468682766
step: 510, loss: 0.0001550319284433499
step: 520, loss: 0.00114408356603235
step: 530, loss: 0.001344296964816749
step: 540, loss: 0.026099316775798798
step: 550, loss: 0.01981152407824993
step: 560, loss: 0.027658753097057343
step: 570, loss: 0.047115955501794815
step: 580, loss: 3.552290945663117e-05
step: 590, loss: 0.039359718561172485
step: 600, loss: 0.007315930910408497
step: 610, loss: 0.07278144359588623
step: 620, loss: 0.0008039148524403572
step: 630, loss: 0.02515106089413166
step: 640, loss: 0.0007476984756067395
step: 650, loss: 0.04944887384772301
step: 660, loss: 0.024301262572407722
step: 670, loss: 0.00019998327479697764
step: 680, loss: 0.10684764385223389
step: 690, loss: 5.9600315580610186e-05
step: 700, loss: 0.00046676467172801495
step: 710, loss: 0.0067898272536695
step: 720, loss: 0.02691410668194294
step: 730, loss: 0.034268539398908615
step: 740, loss: 0.023553863167762756
step: 750, loss: 0.019282277673482895
step: 760, loss: 0.026189502328634262
step: 770, loss: 0.023234622552990913
step: 780, loss: 0.026396475732326508
step: 790, loss: 0.04480636864900589
step: 800, loss: 0.04813414812088013
step: 810, loss: 0.0016420551110059023
step: 820, loss: 0.06341889500617981
step: 830, loss: 0.0018163863569498062
step: 840, loss: 0.015167100355029106
step: 850, loss: 0.055626463145017624
step: 860, loss: 0.04541271924972534
step: 870, loss: 0.03149039298295975
step: 880, loss: 3.495846613077447e-05
step: 890, loss: 0.01849251426756382
step: 900, loss: 3.082006151089445e-05
step: 910, loss: 0.0008789576822891831
step: 920, loss: 0.017047151923179626
step: 930, loss: 7.596013165311888e-05
step: 940, loss: 0.019262129440903664
step: 950, loss: 0.03090011142194271
step: 960, loss: 0.05522198602557182
step: 970, loss: 0.018902255222201347
step: 980, loss: 5.850936577189714e-05
step: 990, loss: 0.011900490149855614
step: 1000, loss: 0.014158778823912144
step: 1010, loss: 0.04241970553994179
step: 1020, loss: 0.00015035927935969085
step: 1030, loss: 0.03901369869709015
step: 1040, loss: 0.006301766261458397
step: 1050, loss: 0.06383378803730011
step: 1060, loss: 0.00044208666076883674
step: 1070, loss: 0.04533638805150986
epoch 17: dev_f1=0.9317231769623782, f1=0.9241443108233117, best_f1=0.9339407744874716
step: 0, loss: 0.023668929934501648
step: 10, loss: 0.02124197781085968
step: 20, loss: 0.021367406472563744
step: 30, loss: 0.00024323983234353364
step: 40, loss: 0.07683151215314865
step: 50, loss: 0.0013996505877003074
step: 60, loss: 4.617890590452589e-05
step: 70, loss: 0.00016490809503011405
step: 80, loss: 0.01974007859826088
step: 90, loss: 0.043453674763441086
step: 100, loss: 7.3455368692521e-05
step: 110, loss: 0.00023208888887893409
step: 120, loss: 0.15922826528549194
step: 130, loss: 0.07147850841283798
step: 140, loss: 0.025062942877411842
step: 150, loss: 0.03128008171916008
step: 160, loss: 0.0016758890124037862
step: 170, loss: 0.041563890874385834
step: 180, loss: 0.00013023066276218742
step: 190, loss: 0.03769543394446373
step: 200, loss: 0.04225529730319977
step: 210, loss: 0.014379051513969898
step: 220, loss: 0.0499151274561882
step: 230, loss: 0.020110536366701126
step: 240, loss: 0.051049791276454926
step: 250, loss: 0.00217809178866446
step: 260, loss: 0.00020614310051314533
step: 270, loss: 0.07307235896587372
step: 280, loss: 0.0009351205080747604
step: 290, loss: 0.08585809916257858
step: 300, loss: 0.02494780719280243
step: 310, loss: 0.04633568599820137
step: 320, loss: 0.14119160175323486
step: 330, loss: 7.505516259698197e-05
step: 340, loss: 0.041928160935640335
step: 350, loss: 0.006965831387788057
step: 360, loss: 0.02482178620994091
step: 370, loss: 0.0018754031043499708
step: 380, loss: 2.76550417765975e-05
step: 390, loss: 2.4828452296787873e-05
step: 400, loss: 0.07045391947031021
step: 410, loss: 0.0025585712864995003
step: 420, loss: 0.0005701946211047471
step: 430, loss: 8.970443559519481e-06
step: 440, loss: 0.00036557469866238534
step: 450, loss: 0.00010084856330649927
step: 460, loss: 0.0006960862083360553
step: 470, loss: 0.02436795085668564
step: 480, loss: 0.052090372890233994
step: 490, loss: 0.019784776493906975
step: 500, loss: 0.03662655130028725
step: 510, loss: 0.04810509458184242
step: 520, loss: 0.019562311470508575
step: 530, loss: 0.024824580177664757
step: 540, loss: 3.7898862501606345e-05
step: 550, loss: 0.001115020364522934
step: 560, loss: 0.06287205964326859
step: 570, loss: 0.0960393026471138
step: 580, loss: 0.043819356709718704
step: 590, loss: 0.025453073903918266
step: 600, loss: 0.04720031097531319
step: 610, loss: 0.016385691240429878
step: 620, loss: 0.06018031761050224
step: 630, loss: 0.023582441732287407
step: 640, loss: 6.992305134190246e-05
step: 650, loss: 0.0027821995317935944
step: 660, loss: 0.018532689660787582
step: 670, loss: 3.148540417896584e-05
step: 680, loss: 0.05064641311764717
step: 690, loss: 0.027012456208467484
step: 700, loss: 0.002946606371551752
step: 710, loss: 0.01731148362159729
step: 720, loss: 0.0253862664103508
step: 730, loss: 0.03168201446533203
step: 740, loss: 0.047577567398548126
step: 750, loss: 2.838372893165797e-05
step: 760, loss: 8.215819980250672e-05
step: 770, loss: 0.01970861479640007
step: 780, loss: 0.0548301599919796
step: 790, loss: 0.04666908457875252
step: 800, loss: 0.04537276178598404
step: 810, loss: 0.020925505086779594
step: 820, loss: 0.016991853713989258
step: 830, loss: 0.034691210836172104
step: 840, loss: 0.05227749049663544
step: 850, loss: 0.029807517305016518
step: 860, loss: 0.009333777241408825
step: 870, loss: 0.025193996727466583
step: 880, loss: 0.09501811116933823
step: 890, loss: 0.06820665299892426
step: 900, loss: 0.03092782571911812
step: 910, loss: 5.287108069751412e-05
step: 920, loss: 5.7604491303209215e-05
step: 930, loss: 0.033518433570861816
step: 940, loss: 0.023877166211605072
step: 950, loss: 0.04492640867829323
step: 960, loss: 0.10251253843307495
step: 970, loss: 0.14719918370246887
step: 980, loss: 0.01733390800654888
step: 990, loss: 0.03606212139129639
step: 1000, loss: 0.01957932859659195
step: 1010, loss: 0.00012732986942864954
step: 1020, loss: 2.980639874294866e-05
step: 1030, loss: 0.0466444306075573
step: 1040, loss: 0.021883822977542877
step: 1050, loss: 0.04043639078736305
step: 1060, loss: 0.0551454983651638
step: 1070, loss: 0.02030685544013977
epoch 18: dev_f1=0.9288040949278734, f1=0.9230055658627088, best_f1=0.9339407744874716
step: 0, loss: 0.02191121317446232
step: 10, loss: 0.0029420554637908936
step: 20, loss: 0.011046494357287884
step: 30, loss: 0.05302110314369202
step: 40, loss: 0.026411008089780807
step: 50, loss: 0.021874239668250084
step: 60, loss: 0.0438857339322567
step: 70, loss: 0.013617596589028835
step: 80, loss: 0.0422336682677269
step: 90, loss: 0.022605467587709427
step: 100, loss: 8.28500105853891e-06
step: 110, loss: 0.0016176693607121706
step: 120, loss: 0.02107243426144123
step: 130, loss: 0.041309792548418045
step: 140, loss: 0.07117944955825806
step: 150, loss: 0.04460606351494789
step: 160, loss: 0.00016784979379735887
step: 170, loss: 0.019500212743878365
step: 180, loss: 0.024567166343331337
step: 190, loss: 0.06445270776748657
step: 200, loss: 0.07553527504205704
step: 210, loss: 0.013279233127832413
step: 220, loss: 0.02668732963502407
step: 230, loss: 0.0651969462633133
step: 240, loss: 0.025994306430220604
step: 250, loss: 0.09960474073886871
step: 260, loss: 0.022250542417168617
step: 270, loss: 0.01711687445640564
step: 280, loss: 0.022150885313749313
step: 290, loss: 0.05533164367079735
step: 300, loss: 0.04433208703994751
step: 310, loss: 0.029656918719410896
step: 320, loss: 0.017474984750151634
step: 330, loss: 0.024950645864009857
step: 340, loss: 0.023628298193216324
step: 350, loss: 0.07920393347740173
step: 360, loss: 0.020325254648923874
step: 370, loss: 0.02216767519712448
step: 380, loss: 0.02574019879102707
step: 390, loss: 0.02171095460653305
step: 400, loss: 0.00037062430055812
step: 410, loss: 0.0016179507365450263
step: 420, loss: 0.044340021908283234
step: 430, loss: 2.9905015253461897e-05
step: 440, loss: 0.016679994761943817
step: 450, loss: 0.023269524797797203
step: 460, loss: 0.015748782083392143
step: 470, loss: 0.039217330515384674
step: 480, loss: 0.025000017136335373
step: 490, loss: 0.0004752226232085377
step: 500, loss: 4.509602877078578e-05
step: 510, loss: 0.036951322108507156
step: 520, loss: 0.02232075296342373
step: 530, loss: 7.090496364980936e-05
step: 540, loss: 0.04763106256723404
step: 550, loss: 0.09460974484682083
step: 560, loss: 0.0006128008826635778
step: 570, loss: 0.012410923838615417
step: 580, loss: 0.021334173157811165
step: 590, loss: 0.07325470447540283
step: 600, loss: 0.011755739338696003
step: 610, loss: 0.08682484179735184
step: 620, loss: 0.0683310478925705
step: 630, loss: 0.06178107485175133
step: 640, loss: 0.02574969455599785
step: 650, loss: 0.06450434774160385
step: 660, loss: 0.04316866770386696
step: 670, loss: 0.0001684177404968068
step: 680, loss: 0.041703492403030396
step: 690, loss: 0.0020294932182878256
step: 700, loss: 0.04500434547662735
step: 710, loss: 0.061154596507549286
step: 720, loss: 1.2047302334394772e-05
step: 730, loss: 0.046635702252388
step: 740, loss: 0.020236684009432793
step: 750, loss: 0.05344512686133385
step: 760, loss: 0.02186952903866768
step: 770, loss: 9.852567745838314e-05
step: 780, loss: 0.05106862634420395
step: 790, loss: 0.06159090995788574
step: 800, loss: 0.0008097239187918603
step: 810, loss: 0.0013452692655846477
step: 820, loss: 0.00594962015748024
step: 830, loss: 0.0006801965064369142
step: 840, loss: 0.019340652972459793
step: 850, loss: 0.00084872409934178
step: 860, loss: 0.0001773349940776825
step: 870, loss: 0.018648933619260788
step: 880, loss: 0.07156616449356079
step: 890, loss: 0.01568208821117878
step: 900, loss: 0.004918012768030167
step: 910, loss: 1.9668455934152007e-05
step: 920, loss: 0.025800904259085655
step: 930, loss: 0.006820709444582462
step: 940, loss: 0.000284764013485983
step: 950, loss: 0.0017727386439219117
step: 960, loss: 0.04177156090736389
step: 970, loss: 0.020218539983034134
step: 980, loss: 0.014035174623131752
step: 990, loss: 0.011633283458650112
step: 1000, loss: 0.022645501419901848
step: 1010, loss: 0.001003630692139268
step: 1020, loss: 0.035653386265039444
step: 1030, loss: 0.017271224409341812
step: 1040, loss: 0.0725271925330162
step: 1050, loss: 0.03737790137529373
step: 1060, loss: 0.00012592386337928474
step: 1070, loss: 0.0008573636878281832
epoch 19: dev_f1=0.9272898961284232, f1=0.9220595181861123, best_f1=0.9339407744874716
step: 0, loss: 9.731348109198734e-05
step: 10, loss: 0.02448088303208351
step: 20, loss: 0.0180943813174963
step: 30, loss: 0.041425153613090515
step: 40, loss: 0.04404052346944809
step: 50, loss: 0.0013975703623145819
step: 60, loss: 0.021639332175254822
step: 70, loss: 0.02290223352611065
step: 80, loss: 0.027155639603734016
step: 90, loss: 3.500909951981157e-05
step: 100, loss: 0.0554976686835289
step: 110, loss: 0.03595181182026863
step: 120, loss: 4.9246998969465494e-05
step: 130, loss: 1.8394403014099225e-05
step: 140, loss: 0.04358292371034622
step: 150, loss: 0.02068348228931427
step: 160, loss: 2.522818249417469e-05
step: 170, loss: 8.67241669766372e-06
step: 180, loss: 0.018419435247778893
step: 190, loss: 0.00031498854514211416
step: 200, loss: 0.0017135230591520667
step: 210, loss: 0.014572910964488983
step: 220, loss: 0.004994482267647982
step: 230, loss: 0.0018271938897669315
step: 240, loss: 8.695570431882516e-05
step: 250, loss: 0.047464895993471146
step: 260, loss: 9.978825983125716e-05
step: 270, loss: 5.906679143663496e-05
step: 280, loss: 0.036130890250205994
step: 290, loss: 0.03866910561919212
step: 300, loss: 0.08394273370504379
step: 310, loss: 0.024528633803129196
step: 320, loss: 0.022758562117815018
step: 330, loss: 0.06883389502763748
step: 340, loss: 0.02077818103134632
step: 350, loss: 0.018465010449290276
step: 360, loss: 0.00014790744171477854
step: 370, loss: 0.05022088438272476
step: 380, loss: 0.04107258841395378
step: 390, loss: 0.0001438218168914318
step: 400, loss: 0.00752467243000865
step: 410, loss: 0.03771441802382469
step: 420, loss: 0.027504045516252518
step: 430, loss: 0.03098468668758869
step: 440, loss: 0.035266805440187454
step: 450, loss: 0.00012647903349716216
step: 460, loss: 0.04054047167301178
step: 470, loss: 0.0778694674372673
step: 480, loss: 0.03153727576136589
step: 490, loss: 0.04173573851585388
step: 500, loss: 0.021642440930008888
step: 510, loss: 0.00023002435045782477
step: 520, loss: 0.0011350340209901333
step: 530, loss: 0.00015261088265106082
step: 540, loss: 2.1195564841036685e-05
step: 550, loss: 0.02775423973798752
step: 560, loss: 0.09932007640600204
step: 570, loss: 0.04882321134209633
step: 580, loss: 0.0015554649289697409
step: 590, loss: 0.003667894285172224
step: 600, loss: 2.6976445951731876e-05
step: 610, loss: 0.022904714569449425
step: 620, loss: 0.020219597965478897
step: 630, loss: 0.07267078757286072
step: 640, loss: 0.01976955123245716
step: 650, loss: 0.02045086957514286
step: 660, loss: 0.030066831037402153
step: 670, loss: 0.021587828174233437
step: 680, loss: 0.02222752757370472
step: 690, loss: 0.0012391818454489112
step: 700, loss: 0.016712738201022148
step: 710, loss: 0.019678641110658646
step: 720, loss: 0.051155246794223785
step: 730, loss: 0.057308003306388855
step: 740, loss: 0.06340949982404709
step: 750, loss: 0.06061789020895958
step: 760, loss: 0.04551389068365097
step: 770, loss: 0.09573964774608612
step: 780, loss: 7.659044058527797e-05
step: 790, loss: 0.08539803326129913
step: 800, loss: 0.0436788909137249
step: 810, loss: 0.06023949384689331
step: 820, loss: 0.04313235357403755
step: 830, loss: 0.00019317830447107553
step: 840, loss: 0.014283791184425354
step: 850, loss: 0.0011894963681697845
step: 860, loss: 0.023381728678941727
step: 870, loss: 0.017086392268538475
step: 880, loss: 6.632303848164156e-05
step: 890, loss: 0.017804989591240883
step: 900, loss: 0.0004114270268473774
step: 910, loss: 0.019209804013371468
step: 920, loss: 0.018838079646229744
step: 930, loss: 2.873218727472704e-05
step: 940, loss: 0.01846940442919731
step: 950, loss: 0.05297856405377388
step: 960, loss: 0.02005668357014656
step: 970, loss: 2.3813259758753702e-05
step: 980, loss: 0.005366029217839241
step: 990, loss: 0.01618223264813423
step: 1000, loss: 0.00025643204571679235
step: 1010, loss: 0.00028045594808645546
step: 1020, loss: 0.027684321627020836
step: 1030, loss: 1.736287958920002e-05
step: 1040, loss: 0.02189294621348381
step: 1050, loss: 2.5830673621385358e-05
step: 1060, loss: 0.00783652625977993
step: 1070, loss: 0.02108813263475895
epoch 20: dev_f1=0.927796130250118, f1=0.9227144203581528, best_f1=0.9339407744874716
