cuda
Device: cuda
step: 0, loss: 0.8596568703651428
step: 10, loss: 0.5193014740943909
step: 20, loss: 0.6247073411941528
step: 30, loss: 0.7019904255867004
step: 40, loss: 0.40239495038986206
step: 50, loss: 0.5370994806289673
step: 60, loss: 0.2949090003967285
step: 70, loss: 0.2940298318862915
step: 80, loss: 0.26752012968063354
step: 90, loss: 0.3495510220527649
step: 100, loss: 0.3172541856765747
step: 110, loss: 0.1839865744113922
step: 120, loss: 0.2306254357099533
step: 130, loss: 0.27326908707618713
step: 140, loss: 0.319149911403656
step: 150, loss: 0.23330006003379822
step: 160, loss: 0.12217305600643158
step: 170, loss: 0.16549411416053772
step: 180, loss: 0.1861695498228073
step: 190, loss: 0.2380499243736267
step: 200, loss: 0.15639233589172363
step: 210, loss: 0.13579630851745605
step: 220, loss: 0.13985027372837067
step: 230, loss: 0.20147526264190674
step: 240, loss: 0.13784851133823395
step: 250, loss: 0.15621566772460938
step: 260, loss: 0.11644696444272995
step: 270, loss: 0.33898407220840454
step: 280, loss: 0.13144004344940186
step: 290, loss: 0.18036815524101257
step: 300, loss: 0.21261341869831085
step: 310, loss: 0.030889693647623062
step: 320, loss: 0.11601237952709198
step: 330, loss: 0.046896543353796005
step: 340, loss: 0.17848001420497894
step: 350, loss: 0.06732018291950226
step: 360, loss: 0.030393412336707115
step: 370, loss: 0.18940582871437073
step: 380, loss: 0.17546625435352325
step: 390, loss: 0.0850256159901619
step: 400, loss: 0.24432440102100372
step: 410, loss: 0.2622562050819397
step: 420, loss: 0.16318072378635406
step: 430, loss: 0.007777748163789511
step: 440, loss: 0.17270344495773315
step: 450, loss: 0.05408632755279541
step: 460, loss: 0.06102718785405159
step: 470, loss: 0.06842631101608276
step: 480, loss: 0.1155194416642189
step: 490, loss: 0.16281011700630188
step: 500, loss: 0.09036917239427567
step: 510, loss: 0.05255476012825966
step: 520, loss: 0.23101525008678436
step: 530, loss: 0.1110987439751625
step: 540, loss: 0.20913483202457428
step: 550, loss: 0.1512121856212616
step: 560, loss: 0.243497833609581
step: 570, loss: 0.0782453790307045
step: 580, loss: 0.1452699899673462
step: 590, loss: 0.005051234737038612
step: 600, loss: 0.12377851456403732
step: 610, loss: 0.1208440363407135
step: 620, loss: 0.13363423943519592
step: 630, loss: 0.12433336675167084
step: 640, loss: 0.0768243670463562
step: 650, loss: 0.15230710804462433
step: 660, loss: 0.09207724779844284
step: 670, loss: 0.09622353315353394
step: 680, loss: 0.06394362449645996
step: 690, loss: 0.08171577751636505
step: 700, loss: 0.12864509224891663
step: 710, loss: 0.013327216729521751
step: 720, loss: 0.07489097118377686
step: 730, loss: 0.07096860557794571
step: 740, loss: 0.13535962998867035
step: 750, loss: 0.03902055695652962
step: 760, loss: 0.11746833473443985
step: 770, loss: 0.070086769759655
step: 780, loss: 0.06881042569875717
step: 790, loss: 0.11047304421663284
step: 800, loss: 0.03196754306554794
step: 810, loss: 0.314336895942688
step: 820, loss: 0.12340604513883591
step: 830, loss: 0.024805650115013123
step: 840, loss: 0.08259078860282898
step: 850, loss: 0.029078150168061256
step: 860, loss: 0.05685005336999893
step: 870, loss: 0.052758894860744476
step: 880, loss: 0.03149677440524101
step: 890, loss: 0.16518931090831757
step: 900, loss: 0.08214980363845825
step: 910, loss: 0.05347122251987457
step: 920, loss: 0.22222900390625
step: 930, loss: 0.06613655388355255
step: 940, loss: 0.2040604054927826
step: 950, loss: 0.038851525634527206
step: 960, loss: 0.15188068151474
step: 970, loss: 0.07208520919084549
step: 980, loss: 0.07126674056053162
step: 990, loss: 0.04158327728509903
step: 1000, loss: 0.01114723365753889
step: 1010, loss: 0.02033250965178013
step: 1020, loss: 0.022668948397040367
step: 1030, loss: 0.0196540430188179
step: 1040, loss: 0.2596249282360077
step: 1050, loss: 0.04644706845283508
step: 1060, loss: 0.07844346016645432
step: 1070, loss: 0.09153753519058228
epoch 1: dev_f1=0.9163602941176471, f1=0.9207068418667875, best_f1=0.9207068418667875
step: 0, loss: 0.09741726517677307
step: 10, loss: 0.07250966876745224
step: 20, loss: 0.04559078812599182
step: 30, loss: 0.04939667135477066
step: 40, loss: 0.0921764075756073
step: 50, loss: 0.06697055697441101
step: 60, loss: 0.05378969386219978
step: 70, loss: 0.1764189898967743
step: 80, loss: 0.0383317731320858
step: 90, loss: 0.18849408626556396
step: 100, loss: 0.20809659361839294
step: 110, loss: 0.035571254789829254
step: 120, loss: 0.14637722074985504
step: 130, loss: 0.10192081332206726
step: 140, loss: 0.1312418282032013
step: 150, loss: 0.07816055417060852
step: 160, loss: 0.17451141774654388
step: 170, loss: 0.08072683215141296
step: 180, loss: 0.18541309237480164
step: 190, loss: 0.07869938015937805
step: 200, loss: 0.05294448509812355
step: 210, loss: 0.16697825491428375
step: 220, loss: 0.2105524092912674
step: 230, loss: 0.16683998703956604
step: 240, loss: 0.1320790797472
step: 250, loss: 0.07187191396951675
step: 260, loss: 0.09660471975803375
step: 270, loss: 0.2667592465877533
step: 280, loss: 0.07573073357343674
step: 290, loss: 0.046816691756248474
step: 300, loss: 0.06997945159673691
step: 310, loss: 0.06943534314632416
step: 320, loss: 0.15192660689353943
step: 330, loss: 0.030131669715046883
step: 340, loss: 0.02963916026055813
step: 350, loss: 0.21404606103897095
step: 360, loss: 0.015497580170631409
step: 370, loss: 0.13781479001045227
step: 380, loss: 0.04051331803202629
step: 390, loss: 0.08825511485338211
step: 400, loss: 0.05720415338873863
step: 410, loss: 0.011110330000519753
step: 420, loss: 0.05689303204417229
step: 430, loss: 0.1408132016658783
step: 440, loss: 0.09019943326711655
step: 450, loss: 0.10695905238389969
step: 460, loss: 0.18911269307136536
step: 470, loss: 0.014073960483074188
step: 480, loss: 0.07919196039438248
step: 490, loss: 0.07206513732671738
step: 500, loss: 0.04268043115735054
step: 510, loss: 0.12931521236896515
step: 520, loss: 0.09549557417631149
step: 530, loss: 0.175619438290596
step: 540, loss: 0.07825206965208054
step: 550, loss: 0.11017576605081558
step: 560, loss: 0.02163902297616005
step: 570, loss: 0.0690990760922432
step: 580, loss: 0.04495161026716232
step: 590, loss: 0.07300281524658203
step: 600, loss: 0.09877310693264008
step: 610, loss: 0.12679332494735718
step: 620, loss: 0.03891338035464287
step: 630, loss: 0.07545606046915054
step: 640, loss: 0.18194055557250977
step: 650, loss: 0.04544697701931
step: 660, loss: 0.11508598178625107
step: 670, loss: 0.15843240916728973
step: 680, loss: 0.10641318559646606
step: 690, loss: 0.10176479816436768
step: 700, loss: 0.025786997750401497
step: 710, loss: 0.1178947240114212
step: 720, loss: 0.06129870191216469
step: 730, loss: 0.10793936997652054
step: 740, loss: 0.10555823147296906
step: 750, loss: 0.009943037293851376
step: 760, loss: 0.028227096423506737
step: 770, loss: 0.04925363510847092
step: 780, loss: 0.11700477451086044
step: 790, loss: 0.06376495957374573
step: 800, loss: 0.02785087563097477
step: 810, loss: 0.34147438406944275
step: 820, loss: 0.06841814517974854
step: 830, loss: 0.10527729243040085
step: 840, loss: 0.10898498445749283
step: 850, loss: 0.03655056282877922
step: 860, loss: 0.0798313170671463
step: 870, loss: 0.057128533720970154
step: 880, loss: 0.09373001754283905
step: 890, loss: 0.031128697097301483
step: 900, loss: 0.07335756719112396
step: 910, loss: 0.0688367486000061
step: 920, loss: 0.1280556321144104
step: 930, loss: 0.060763005167245865
step: 940, loss: 0.12624095380306244
step: 950, loss: 0.05823088809847832
step: 960, loss: 0.0345071442425251
step: 970, loss: 0.1399853229522705
step: 980, loss: 0.1361602544784546
step: 990, loss: 0.14564836025238037
step: 1000, loss: 0.07226715236902237
step: 1010, loss: 0.0699433907866478
step: 1020, loss: 0.03374562785029411
step: 1030, loss: 0.15054629743099213
step: 1040, loss: 0.13102541863918304
step: 1050, loss: 0.12874652445316315
step: 1060, loss: 0.03262761980295181
step: 1070, loss: 0.0010173702612519264
epoch 2: dev_f1=0.9418657052726453, f1=0.9420224719101123, best_f1=0.9420224719101123
step: 0, loss: 0.13193541765213013
step: 10, loss: 0.04314803332090378
step: 20, loss: 0.030826115980744362
step: 30, loss: 0.014366750605404377
step: 40, loss: 0.11840254813432693
step: 50, loss: 0.11885175108909607
step: 60, loss: 0.15089139342308044
step: 70, loss: 0.04118199273943901
step: 80, loss: 0.02843283861875534
step: 90, loss: 0.03125377744436264
step: 100, loss: 0.05673659220337868
step: 110, loss: 0.11223044991493225
step: 120, loss: 0.0009622902143746614
step: 130, loss: 0.13421347737312317
step: 140, loss: 0.0939621552824974
step: 150, loss: 0.046701766550540924
step: 160, loss: 0.057549361139535904
step: 170, loss: 0.03101026825606823
step: 180, loss: 0.40696996450424194
step: 190, loss: 0.08581207692623138
step: 200, loss: 0.06409236788749695
step: 210, loss: 0.06875550001859665
step: 220, loss: 0.026665786281228065
step: 230, loss: 0.08066431432962418
step: 240, loss: 0.023114537820219994
step: 250, loss: 0.06580918282270432
step: 260, loss: 0.10232464224100113
step: 270, loss: 0.08354312926530838
step: 280, loss: 0.16616888344287872
step: 290, loss: 0.07985924184322357
step: 300, loss: 0.06442538648843765
step: 310, loss: 0.06029784306883812
step: 320, loss: 0.10042709857225418
step: 330, loss: 0.015003722161054611
step: 340, loss: 0.05786741152405739
step: 350, loss: 0.12486827373504639
step: 360, loss: 0.07959321141242981
step: 370, loss: 0.13228297233581543
step: 380, loss: 0.09451036155223846
step: 390, loss: 0.011104928329586983
step: 400, loss: 0.04720107838511467
step: 410, loss: 0.020781733095645905
step: 420, loss: 0.008997887372970581
step: 430, loss: 0.06708798557519913
step: 440, loss: 0.007241117302328348
step: 450, loss: 0.08659203350543976
step: 460, loss: 0.048444390296936035
step: 470, loss: 0.09410577267408371
step: 480, loss: 0.04122664034366608
step: 490, loss: 0.03967971354722977
step: 500, loss: 0.009340187534689903
step: 510, loss: 0.027144955471158028
step: 520, loss: 0.051873549818992615
step: 530, loss: 0.08729711174964905
step: 540, loss: 0.0860648825764656
step: 550, loss: 0.12959378957748413
step: 560, loss: 0.019148612394928932
step: 570, loss: 0.0413554385304451
step: 580, loss: 0.07759937644004822
step: 590, loss: 0.060184236615896225
step: 600, loss: 0.058042190968990326
step: 610, loss: 0.031202297657728195
step: 620, loss: 0.07628469914197922
step: 630, loss: 0.040493689477443695
step: 640, loss: 0.026786863803863525
step: 650, loss: 0.05269233509898186
step: 660, loss: 0.01670207269489765
step: 670, loss: 0.12394319474697113
step: 680, loss: 0.1783348023891449
step: 690, loss: 0.14736895263195038
step: 700, loss: 0.12844794988632202
step: 710, loss: 0.05925900489091873
step: 720, loss: 0.12566210329532623
step: 730, loss: 0.07785332947969437
step: 740, loss: 0.06508388370275497
step: 750, loss: 0.0917210578918457
step: 760, loss: 0.049900397658348083
step: 770, loss: 0.053116243332624435
step: 780, loss: 0.09680822491645813
step: 790, loss: 0.016931939870119095
step: 800, loss: 0.03375057876110077
step: 810, loss: 0.04444122686982155
step: 820, loss: 0.11313541233539581
step: 830, loss: 0.06061071902513504
step: 840, loss: 0.044274792075157166
step: 850, loss: 0.032948799431324005
step: 860, loss: 0.1217697486281395
step: 870, loss: 0.038709040731191635
step: 880, loss: 0.07232192158699036
step: 890, loss: 0.02259810082614422
step: 900, loss: 0.04739999398589134
step: 910, loss: 0.07311547547578812
step: 920, loss: 0.13756659626960754
step: 930, loss: 0.09906946867704391
step: 940, loss: 0.05877982825040817
step: 950, loss: 0.07949136197566986
step: 960, loss: 0.027173493057489395
step: 970, loss: 0.14369331300258636
step: 980, loss: 0.11406725645065308
step: 990, loss: 0.06194956228137016
step: 1000, loss: 0.10947567969560623
step: 1010, loss: 0.026378197595477104
step: 1020, loss: 0.16750875115394592
step: 1030, loss: 0.06219843775033951
step: 1040, loss: 0.09790749847888947
step: 1050, loss: 0.07269716262817383
step: 1060, loss: 0.15990625321865082
step: 1070, loss: 0.026248972862958908
epoch 3: dev_f1=0.9330889092575618, f1=0.9343065693430658, best_f1=0.9420224719101123
step: 0, loss: 0.017714953050017357
step: 10, loss: 0.13223092257976532
step: 20, loss: 0.03158042952418327
step: 30, loss: 0.07441301643848419
step: 40, loss: 0.007320128846913576
step: 50, loss: 0.19093476235866547
step: 60, loss: 0.06812433153390884
step: 70, loss: 0.013542650267481804
step: 80, loss: 0.1254003942012787
step: 90, loss: 0.08039341866970062
step: 100, loss: 0.02346610464155674
step: 110, loss: 0.03922161087393761
step: 120, loss: 0.05243394523859024
step: 130, loss: 0.00023132689238991588
step: 140, loss: 0.014484185725450516
step: 150, loss: 0.06686680763959885
step: 160, loss: 0.03342696279287338
step: 170, loss: 0.0645635724067688
step: 180, loss: 0.10517023503780365
step: 190, loss: 0.05721120163798332
step: 200, loss: 0.3673695921897888
step: 210, loss: 0.15539531409740448
step: 220, loss: 0.1799003779888153
step: 230, loss: 0.07854314893484116
step: 240, loss: 0.039965398609638214
step: 250, loss: 0.0007201666012406349
step: 260, loss: 0.08368201553821564
step: 270, loss: 0.18973463773727417
step: 280, loss: 0.019148798659443855
step: 290, loss: 0.07272956520318985
step: 300, loss: 0.03517623990774155
step: 310, loss: 0.0436808317899704
step: 320, loss: 0.06179845333099365
step: 330, loss: 0.2108975499868393
step: 340, loss: 0.06694656610488892
step: 350, loss: 0.016453556716442108
step: 360, loss: 0.07275831699371338
step: 370, loss: 0.01686028577387333
step: 380, loss: 0.10264902561903
step: 390, loss: 0.08819332718849182
step: 400, loss: 0.014427931047976017
step: 410, loss: 0.0962432399392128
step: 420, loss: 0.06600303947925568
step: 430, loss: 0.04170205071568489
step: 440, loss: 0.012106566689908504
step: 450, loss: 0.03552014380693436
step: 460, loss: 0.02967947907745838
step: 470, loss: 0.07723352313041687
step: 480, loss: 0.02350669354200363
step: 490, loss: 0.08100997656583786
step: 500, loss: 0.08891255408525467
step: 510, loss: 0.03371015936136246
step: 520, loss: 0.07247882336378098
step: 530, loss: 0.10975442826747894
step: 540, loss: 0.030165545642375946
step: 550, loss: 0.06180909276008606
step: 560, loss: 0.07072994112968445
step: 570, loss: 0.06538175791501999
step: 580, loss: 0.017219936475157738
step: 590, loss: 0.05718490108847618
step: 600, loss: 0.12160193920135498
step: 610, loss: 0.0486767403781414
step: 620, loss: 0.14162978529930115
step: 630, loss: 0.05193250998854637
step: 640, loss: 0.01860504224896431
step: 650, loss: 0.11470885574817657
step: 660, loss: 0.024512777104973793
step: 670, loss: 0.10243327170610428
step: 680, loss: 0.043232884258031845
step: 690, loss: 0.08036059886217117
step: 700, loss: 0.015493585728108883
step: 710, loss: 0.00981079414486885
step: 720, loss: 0.035297464579343796
step: 730, loss: 0.11115571856498718
step: 740, loss: 0.096348837018013
step: 750, loss: 0.1090446189045906
step: 760, loss: 0.03989230841398239
step: 770, loss: 0.06384383887052536
step: 780, loss: 0.018380697816610336
step: 790, loss: 0.10951539129018784
step: 800, loss: 0.1369631588459015
step: 810, loss: 0.044862523674964905
step: 820, loss: 0.02156565897166729
step: 830, loss: 0.033067379146814346
step: 840, loss: 0.01433491986244917
step: 850, loss: 0.08967199921607971
step: 860, loss: 0.08649473637342453
step: 870, loss: 0.03916125372052193
step: 880, loss: 0.04333864524960518
step: 890, loss: 0.09731481224298477
step: 900, loss: 0.12997694313526154
step: 910, loss: 0.10116209834814072
step: 920, loss: 0.03412254527211189
step: 930, loss: 0.02819901704788208
step: 940, loss: 0.12426735460758209
step: 950, loss: 0.07627042382955551
step: 960, loss: 0.11486832052469254
step: 970, loss: 0.07552450150251389
step: 980, loss: 0.020478148013353348
step: 990, loss: 0.09911863505840302
step: 1000, loss: 0.025347862392663956
step: 1010, loss: 0.011287886649370193
step: 1020, loss: 0.21633277833461761
step: 1030, loss: 0.027223875746130943
step: 1040, loss: 0.1386280655860901
step: 1050, loss: 0.037295304238796234
step: 1060, loss: 0.06993789970874786
step: 1070, loss: 0.075042724609375
epoch 4: dev_f1=0.9377289377289378, f1=0.9313815187557181, best_f1=0.9420224719101123
step: 0, loss: 0.040955428034067154
step: 10, loss: 0.028550732880830765
step: 20, loss: 0.016665752977132797
step: 30, loss: 0.027595093473792076
step: 40, loss: 0.00660411873832345
step: 50, loss: 0.02349006198346615
step: 60, loss: 0.027610454708337784
step: 70, loss: 0.09113436192274094
step: 80, loss: 0.13815930485725403
step: 90, loss: 0.07393477857112885
step: 100, loss: 0.017559411004185677
step: 110, loss: 0.07596499472856522
step: 120, loss: 0.05675923451781273
step: 130, loss: 0.08456586301326752
step: 140, loss: 0.0904039740562439
step: 150, loss: 0.032054055482149124
step: 160, loss: 0.05470392853021622
step: 170, loss: 0.07273027300834656
step: 180, loss: 0.06248628348112106
step: 190, loss: 0.024722479283809662
step: 200, loss: 0.01784243993461132
step: 210, loss: 0.050763797014951706
step: 220, loss: 0.0381954088807106
step: 230, loss: 0.015184421092271805
step: 240, loss: 0.004620024003088474
step: 250, loss: 0.05713219568133354
step: 260, loss: 0.11430995911359787
step: 270, loss: 0.03298515826463699
step: 280, loss: 0.08226583898067474
step: 290, loss: 0.0912754237651825
step: 300, loss: 0.00023871012672316283
step: 310, loss: 0.08967196196317673
step: 320, loss: 0.07013339549303055
step: 330, loss: 0.10621995478868484
step: 340, loss: 0.017654508352279663
step: 350, loss: 0.04078616574406624
step: 360, loss: 0.013193853199481964
step: 370, loss: 0.012890754267573357
step: 380, loss: 0.0161743201315403
step: 390, loss: 0.11120432615280151
step: 400, loss: 0.029847608879208565
step: 410, loss: 0.06746714562177658
step: 420, loss: 0.08647410571575165
step: 430, loss: 0.15372319519519806
step: 440, loss: 0.031413137912750244
step: 450, loss: 0.03932490572333336
step: 460, loss: 0.20337940752506256
step: 470, loss: 0.019551943987607956
step: 480, loss: 0.03459876775741577
step: 490, loss: 0.10552296042442322
step: 500, loss: 0.07760091125965118
step: 510, loss: 0.1684408187866211
step: 520, loss: 0.09219591319561005
step: 530, loss: 0.06827694922685623
step: 540, loss: 0.13560731709003448
step: 550, loss: 0.06647319346666336
step: 560, loss: 0.04944375529885292
step: 570, loss: 0.07867440581321716
step: 580, loss: 0.08527399599552155
step: 590, loss: 0.05718272551894188
step: 600, loss: 0.06392911821603775
step: 610, loss: 0.032492391765117645
step: 620, loss: 0.06844298541545868
step: 630, loss: 0.061606865376234055
step: 640, loss: 0.05176491290330887
step: 650, loss: 0.043108049780130386
step: 660, loss: 0.045682501047849655
step: 670, loss: 0.05703309550881386
step: 680, loss: 0.007830791175365448
step: 690, loss: 0.1799602061510086
step: 700, loss: 0.1705482304096222
step: 710, loss: 0.07304026931524277
step: 720, loss: 0.07470166683197021
step: 730, loss: 0.05613965541124344
step: 740, loss: 0.013368867337703705
step: 750, loss: 0.017344556748867035
step: 760, loss: 0.044345904141664505
step: 770, loss: 0.015028180554509163
step: 780, loss: 0.0818464383482933
step: 790, loss: 0.0746283233165741
step: 800, loss: 0.06713192164897919
step: 810, loss: 0.010495290160179138
step: 820, loss: 0.0964682474732399
step: 830, loss: 0.15638518333435059
step: 840, loss: 0.05379004776477814
step: 850, loss: 0.054175250232219696
step: 860, loss: 0.02013969235122204
step: 870, loss: 0.04449985921382904
step: 880, loss: 0.08114200830459595
step: 890, loss: 0.046415042132139206
step: 900, loss: 0.08712677657604218
step: 910, loss: 0.1110181137919426
step: 920, loss: 0.03598468378186226
step: 930, loss: 0.03432701155543327
step: 940, loss: 0.02626274898648262
step: 950, loss: 0.0070222471840679646
step: 960, loss: 0.006808634381741285
step: 970, loss: 0.02159476839005947
step: 980, loss: 0.006025911774486303
step: 990, loss: 0.03308143839240074
step: 1000, loss: 0.15017367899417877
step: 1010, loss: 0.017378009855747223
step: 1020, loss: 0.02276679128408432
step: 1030, loss: 0.10169794410467148
step: 1040, loss: 0.0087820990011096
step: 1050, loss: 0.030045202001929283
step: 1060, loss: 0.11537392437458038
step: 1070, loss: 0.056291233748197556
epoch 5: dev_f1=0.9330889092575618, f1=0.9262295081967213, best_f1=0.9420224719101123
step: 0, loss: 0.052436187863349915
step: 10, loss: 0.06951306760311127
step: 20, loss: 0.035474833101034164
step: 30, loss: 0.014543909579515457
step: 40, loss: 0.0285356342792511
step: 50, loss: 0.06641583889722824
step: 60, loss: 0.008218532428145409
step: 70, loss: 0.07437673211097717
step: 80, loss: 0.015281002968549728
step: 90, loss: 0.020345110446214676
step: 100, loss: 0.015819262713193893
step: 110, loss: 0.13903462886810303
step: 120, loss: 0.0178440622985363
step: 130, loss: 0.056257639080286026
step: 140, loss: 0.024242589250206947
step: 150, loss: 0.03341054171323776
step: 160, loss: 0.2103857845067978
step: 170, loss: 0.008387464098632336
step: 180, loss: 0.06727191805839539
step: 190, loss: 0.11037493497133255
step: 200, loss: 0.09279249608516693
step: 210, loss: 0.010403573513031006
step: 220, loss: 0.009269224479794502
step: 230, loss: 0.026341643184423447
step: 240, loss: 0.007887415587902069
step: 250, loss: 0.056314971297979355
step: 260, loss: 0.004253986291587353
step: 270, loss: 0.026496069505810738
step: 280, loss: 0.01153039000928402
step: 290, loss: 0.08804541826248169
step: 300, loss: 0.11688739061355591
step: 310, loss: 0.028904564678668976
step: 320, loss: 0.022055191919207573
step: 330, loss: 0.0722951889038086
step: 340, loss: 0.02700519748032093
step: 350, loss: 0.02054121345281601
step: 360, loss: 0.0053846221417188644
step: 370, loss: 0.07707764208316803
step: 380, loss: 0.062036167830228806
step: 390, loss: 0.04929602891206741
step: 400, loss: 0.026200050488114357
step: 410, loss: 0.009277859702706337
step: 420, loss: 0.015284658409655094
step: 430, loss: 0.017375722527503967
step: 440, loss: 0.1323160082101822
step: 450, loss: 0.07548802345991135
step: 460, loss: 0.13315273821353912
step: 470, loss: 0.030952736735343933
step: 480, loss: 0.05988423153758049
step: 490, loss: 0.04953975975513458
step: 500, loss: 0.07132310420274734
step: 510, loss: 0.057195961475372314
step: 520, loss: 0.01515576895326376
step: 530, loss: 0.054860178381204605
step: 540, loss: 0.03426758572459221
step: 550, loss: 0.007472257129848003
step: 560, loss: 0.15972422063350677
step: 570, loss: 0.024327652528882027
step: 580, loss: 0.008127082139253616
step: 590, loss: 0.126948282122612
step: 600, loss: 0.00395831186324358
step: 610, loss: 0.023701244965195656
step: 620, loss: 0.0162905715405941
step: 630, loss: 0.032464731484651566
step: 640, loss: 0.07596312463283539
step: 650, loss: 0.052028462290763855
step: 660, loss: 0.026025015860795975
step: 670, loss: 0.17039361596107483
step: 680, loss: 0.047841884195804596
step: 690, loss: 0.07624612748622894
step: 700, loss: 0.01226380281150341
step: 710, loss: 0.014048377983272076
step: 720, loss: 0.047559622675180435
step: 730, loss: 0.025638772174715996
step: 740, loss: 0.06438275426626205
step: 750, loss: 0.05852463096380234
step: 760, loss: 0.013146501034498215
step: 770, loss: 0.14122231304645538
step: 780, loss: 0.08468515425920486
step: 790, loss: 0.12200606614351273
step: 800, loss: 0.04000142961740494
step: 810, loss: 0.11104140430688858
step: 820, loss: 0.0877237468957901
step: 830, loss: 0.06583207845687866
step: 840, loss: 0.0014110379852354527
step: 850, loss: 0.02438420243561268
step: 860, loss: 0.06141519546508789
step: 870, loss: 0.016533570364117622
step: 880, loss: 0.07947305589914322
step: 890, loss: 0.08481066673994064
step: 900, loss: 0.006859165150672197
step: 910, loss: 0.05703318491578102
step: 920, loss: 0.08640348166227341
step: 930, loss: 0.05602295324206352
step: 940, loss: 0.03830019757151604
step: 950, loss: 0.03541483357548714
step: 960, loss: 0.03702571243047714
step: 970, loss: 0.10834210366010666
step: 980, loss: 0.01987675204873085
step: 990, loss: 0.03165289759635925
step: 1000, loss: 0.009435988962650299
step: 1010, loss: 0.17669245600700378
step: 1020, loss: 0.11148156225681305
step: 1030, loss: 0.07708384096622467
step: 1040, loss: 0.029312975704669952
step: 1050, loss: 0.07220682501792908
step: 1060, loss: 0.009863737970590591
step: 1070, loss: 0.08795634657144547
epoch 6: dev_f1=0.9406264609630668, f1=0.9338303821062441, best_f1=0.9420224719101123
step: 0, loss: 0.08100657910108566
step: 10, loss: 0.07151589542627335
step: 20, loss: 0.1571989506483078
step: 30, loss: 0.10936511307954788
step: 40, loss: 0.062067072838544846
step: 50, loss: 0.015327800065279007
step: 60, loss: 0.09712659567594528
step: 70, loss: 0.05109301954507828
step: 80, loss: 0.049381937831640244
step: 90, loss: 0.015152910724282265
step: 100, loss: 0.006705916952341795
step: 110, loss: 0.12168290466070175
step: 120, loss: 0.023890815675258636
step: 130, loss: 0.03503424674272537
step: 140, loss: 0.09243106096982956
step: 150, loss: 0.044548094272613525
step: 160, loss: 0.020599592477083206
step: 170, loss: 0.02720697596669197
step: 180, loss: 0.08377521485090256
step: 190, loss: 0.08098477870225906
step: 200, loss: 0.005341263487935066
step: 210, loss: 0.026836052536964417
step: 220, loss: 0.11774774640798569
step: 230, loss: 0.005292726214975119
step: 240, loss: 0.016176145523786545
step: 250, loss: 0.05196775868535042
step: 260, loss: 0.12835605442523956
step: 270, loss: 0.09733472764492035
step: 280, loss: 0.08258318156003952
step: 290, loss: 0.04229043424129486
step: 300, loss: 0.028220757842063904
step: 310, loss: 0.1367623656988144
step: 320, loss: 0.0738246887922287
step: 330, loss: 0.054018519818782806
step: 340, loss: 0.03176896274089813
step: 350, loss: 0.10634414851665497
step: 360, loss: 0.055268675088882446
step: 370, loss: 0.15328559279441833
step: 380, loss: 0.116673044860363
step: 390, loss: 0.006835381966084242
step: 400, loss: 0.03858475387096405
step: 410, loss: 0.02795547805726528
step: 420, loss: 0.014509269036352634
step: 430, loss: 0.08877290785312653
step: 440, loss: 0.08007373660802841
step: 450, loss: 0.07756192982196808
step: 460, loss: 0.09131445735692978
step: 470, loss: 0.05770253762602806
step: 480, loss: 0.008895272389054298
step: 490, loss: 0.08365444839000702
step: 500, loss: 0.013034310191869736
step: 510, loss: 0.15098848938941956
step: 520, loss: 0.08222658932209015
step: 530, loss: 0.04126107320189476
step: 540, loss: 0.08941146731376648
step: 550, loss: 0.020106380805373192
step: 560, loss: 0.06952497363090515
step: 570, loss: 0.028796367347240448
step: 580, loss: 0.06254029273986816
step: 590, loss: 0.018822478130459785
step: 600, loss: 0.05185956880450249
step: 610, loss: 0.1325920969247818
step: 620, loss: 0.009325788356363773
step: 630, loss: 0.035370636731386185
step: 640, loss: 0.026373252272605896
step: 650, loss: 0.07837517559528351
step: 660, loss: 0.07317610085010529
step: 670, loss: 0.06339605152606964
step: 680, loss: 0.06623724102973938
step: 690, loss: 0.02904610149562359
step: 700, loss: 0.11290643364191055
step: 710, loss: 0.005987427197396755
step: 720, loss: 0.07654626667499542
step: 730, loss: 0.04751097410917282
step: 740, loss: 0.019616171717643738
step: 750, loss: 0.0555562786757946
step: 760, loss: 0.030924201011657715
step: 770, loss: 0.15322546660900116
step: 780, loss: 0.022322166711091995
step: 790, loss: 0.04570924863219261
step: 800, loss: 0.005680114030838013
step: 810, loss: 0.03673630207777023
step: 820, loss: 0.007645579520612955
step: 830, loss: 0.037518639117479324
step: 840, loss: 0.04805855453014374
step: 850, loss: 0.02414855919778347
step: 860, loss: 0.030916376039385796
step: 870, loss: 0.035947371274232864
step: 880, loss: 0.014408649876713753
step: 890, loss: 0.18775884807109833
step: 900, loss: 0.015272138640284538
step: 910, loss: 0.039808373898267746
step: 920, loss: 0.038500525057315826
step: 930, loss: 0.14943434298038483
step: 940, loss: 0.02391558326780796
step: 950, loss: 0.010881884023547173
step: 960, loss: 0.034545011818408966
step: 970, loss: 0.005955379921942949
step: 980, loss: 0.05018385499715805
step: 990, loss: 0.04093029722571373
step: 1000, loss: 0.07095237076282501
step: 1010, loss: 0.01091432198882103
step: 1020, loss: 0.10346480458974838
step: 1030, loss: 0.012549610808491707
step: 1040, loss: 0.04847393184900284
step: 1050, loss: 0.015040554106235504
step: 1060, loss: 0.060718294233083725
step: 1070, loss: 0.027138713747262955
epoch 7: dev_f1=0.939297124600639, f1=0.9329102447869446, best_f1=0.9420224719101123
step: 0, loss: 0.018002949655056
step: 10, loss: 0.02904866635799408
step: 20, loss: 0.08846232295036316
step: 30, loss: 0.034714434295892715
step: 40, loss: 0.016585590317845345
step: 50, loss: 0.008244221098721027
step: 60, loss: 0.007117176428437233
step: 70, loss: 0.08904362469911575
step: 80, loss: 0.020587239414453506
step: 90, loss: 0.06806937605142593
step: 100, loss: 0.10736339539289474
step: 110, loss: 0.016016200184822083
step: 120, loss: 0.000797100190538913
step: 130, loss: 0.05772675573825836
step: 140, loss: 0.07518342137336731
step: 150, loss: 0.015999337658286095
step: 160, loss: 0.05836571753025055
step: 170, loss: 0.015211413614451885
step: 180, loss: 0.061045706272125244
step: 190, loss: 0.008676796220242977
step: 200, loss: 0.14456428587436676
step: 210, loss: 0.022470947355031967
step: 220, loss: 0.11512483656406403
step: 230, loss: 0.02333257533609867
step: 240, loss: 0.011788755655288696
step: 250, loss: 0.009449183940887451
step: 260, loss: 0.10848291963338852
step: 270, loss: 0.13848359882831573
step: 280, loss: 0.050862397998571396
step: 290, loss: 0.017533181235194206
step: 300, loss: 0.11587821692228317
step: 310, loss: 0.012536248192191124
step: 320, loss: 0.0421886071562767
step: 330, loss: 0.0952848270535469
step: 340, loss: 0.04000893607735634
step: 350, loss: 0.00012656237231567502
step: 360, loss: 0.05386914312839508
step: 370, loss: 0.04882471263408661
step: 380, loss: 0.03187276050448418
step: 390, loss: 0.02973031811416149
step: 400, loss: 0.03787613287568092
step: 410, loss: 0.02257055975496769
step: 420, loss: 0.05378611013293266
step: 430, loss: 0.0001581162796355784
step: 440, loss: 0.011580954305827618
step: 450, loss: 0.010954998433589935
step: 460, loss: 0.05979118123650551
step: 470, loss: 0.14275330305099487
step: 480, loss: 0.014500769786536694
step: 490, loss: 0.0014374488964676857
step: 500, loss: 0.09005855768918991
step: 510, loss: 0.06712131202220917
step: 520, loss: 0.04833747074007988
step: 530, loss: 0.10210049152374268
step: 540, loss: 0.03397325798869133
step: 550, loss: 0.004669682122766972
step: 560, loss: 0.0072204782627522945
step: 570, loss: 0.009867100045084953
step: 580, loss: 0.07118920236825943
step: 590, loss: 0.01800752431154251
step: 600, loss: 0.013431434519588947
step: 610, loss: 0.020170241594314575
step: 620, loss: 0.04358735680580139
step: 630, loss: 0.05156758800148964
step: 640, loss: 0.024545995518565178
step: 650, loss: 0.02117777243256569
step: 660, loss: 0.06472378224134445
step: 670, loss: 0.017187051475048065
step: 680, loss: 0.07528644055128098
step: 690, loss: 0.0530489981174469
step: 700, loss: 0.05316861346364021
step: 710, loss: 0.004545233678072691
step: 720, loss: 0.07221432775259018
step: 730, loss: 0.011749702505767345
step: 740, loss: 0.06749553978443146
step: 750, loss: 0.00867372564971447
step: 760, loss: 0.1215219795703888
step: 770, loss: 0.0415974035859108
step: 780, loss: 0.025140302255749702
step: 790, loss: 0.02754133567214012
step: 800, loss: 0.10096331685781479
step: 810, loss: 0.07505843788385391
step: 820, loss: 0.07654449343681335
step: 830, loss: 0.069459468126297
step: 840, loss: 0.012455765157938004
step: 850, loss: 0.01213978510349989
step: 860, loss: 0.007607022766023874
step: 870, loss: 0.005051803775131702
step: 880, loss: 0.027757108211517334
step: 890, loss: 0.014394517987966537
step: 900, loss: 0.003364503849297762
step: 910, loss: 0.14111565053462982
step: 920, loss: 0.08937172591686249
step: 930, loss: 0.07184800505638123
step: 940, loss: 0.02865907922387123
step: 950, loss: 0.00334301614202559
step: 960, loss: 0.061843737959861755
step: 970, loss: 0.08862107992172241
step: 980, loss: 0.07838989049196243
step: 990, loss: 0.14230597019195557
step: 1000, loss: 0.16520683467388153
step: 1010, loss: 0.08923676609992981
step: 1020, loss: 0.010654211975634098
step: 1030, loss: 0.04541261866688728
step: 1040, loss: 0.0882948637008667
step: 1050, loss: 0.019048959016799927
step: 1060, loss: 0.0071968697011470795
step: 1070, loss: 0.012122229672968388
epoch 8: dev_f1=0.9376718606782769, f1=0.9354691075514875, best_f1=0.9420224719101123
step: 0, loss: 0.06218942627310753
step: 10, loss: 0.04769255593419075
step: 20, loss: 0.01450640894472599
step: 30, loss: 0.03480665013194084
step: 40, loss: 0.20441190898418427
step: 50, loss: 0.09971301257610321
step: 60, loss: 0.09729106724262238
step: 70, loss: 0.0173871498554945
step: 80, loss: 0.11102544516324997
step: 90, loss: 0.006501374300569296
step: 100, loss: 0.007699520792812109
step: 110, loss: 0.08416875451803207
step: 120, loss: 0.040019743144512177
step: 130, loss: 0.008298811502754688
step: 140, loss: 0.04117972403764725
step: 150, loss: 0.02304384857416153
step: 160, loss: 0.11606506258249283
step: 170, loss: 0.006152709014713764
step: 180, loss: 0.05214482545852661
step: 190, loss: 0.05919792503118515
step: 200, loss: 0.07066977769136429
step: 210, loss: 0.10893867164850235
step: 220, loss: 0.010928108356893063
step: 230, loss: 0.046671368181705475
step: 240, loss: 0.07492269575595856
step: 250, loss: 0.03540860861539841
step: 260, loss: 0.0066823214292526245
step: 270, loss: 0.01603703200817108
step: 280, loss: 0.008210932835936546
step: 290, loss: 0.02346041053533554
step: 300, loss: 0.09929291903972626
step: 310, loss: 0.011776686646044254
step: 320, loss: 0.07494630664587021
step: 330, loss: 0.011714900843799114
step: 340, loss: 0.03135661408305168
step: 350, loss: 0.015584828332066536
step: 360, loss: 0.0030346906278282404
step: 370, loss: 0.01094996090978384
step: 380, loss: 0.012611191719770432
step: 390, loss: 6.737574585713446e-05
step: 400, loss: 0.012622015550732613
step: 410, loss: 0.14633356034755707
step: 420, loss: 0.012352602556347847
step: 430, loss: 0.04000358656048775
step: 440, loss: 0.019047988578677177
step: 450, loss: 0.055180229246616364
step: 460, loss: 0.013052213005721569
step: 470, loss: 0.0041076866909861565
step: 480, loss: 0.09354954957962036
step: 490, loss: 0.06419102847576141
step: 500, loss: 0.039240311831235886
step: 510, loss: 0.11416836082935333
step: 520, loss: 0.06139221414923668
step: 530, loss: 0.0645587295293808
step: 540, loss: 0.005306615494191647
step: 550, loss: 0.0016473842551931739
step: 560, loss: 0.02067825198173523
step: 570, loss: 0.024172253906726837
step: 580, loss: 0.02460820972919464
step: 590, loss: 0.003050244878977537
step: 600, loss: 0.07295417785644531
step: 610, loss: 0.04624802619218826
step: 620, loss: 0.04353617504239082
step: 630, loss: 0.07121576368808746
step: 640, loss: 0.016704102978110313
step: 650, loss: 0.05454608052968979
step: 660, loss: 0.19913679361343384
step: 670, loss: 0.06385287642478943
step: 680, loss: 0.03388867899775505
step: 690, loss: 0.020684288814663887
step: 700, loss: 0.07933827489614487
step: 710, loss: 0.08610858768224716
step: 720, loss: 0.030647164210677147
step: 730, loss: 0.0753052607178688
step: 740, loss: 0.02266344241797924
step: 750, loss: 0.11728813499212265
step: 760, loss: 0.03881341591477394
step: 770, loss: 0.004810945130884647
step: 780, loss: 0.0035334264393895864
step: 790, loss: 0.09249544143676758
step: 800, loss: 0.001986230257898569
step: 810, loss: 0.06451567262411118
step: 820, loss: 0.00926603376865387
step: 830, loss: 0.11283774673938751
step: 840, loss: 0.11085672676563263
step: 850, loss: 0.010926846414804459
step: 860, loss: 0.04328778758645058
step: 870, loss: 0.009837918914854527
step: 880, loss: 0.07193126529455185
step: 890, loss: 0.01643345132470131
step: 900, loss: 0.015687992796301842
step: 910, loss: 0.046779125928878784
step: 920, loss: 0.0023711565881967545
step: 930, loss: 0.11480807512998581
step: 940, loss: 0.07595698535442352
step: 950, loss: 0.012991434894502163
step: 960, loss: 0.006534702144563198
step: 970, loss: 0.00858290120959282
step: 980, loss: 0.020790250971913338
step: 990, loss: 0.003525218227878213
step: 1000, loss: 0.04953153431415558
step: 1010, loss: 0.038712721318006516
step: 1020, loss: 0.060029931366443634
step: 1030, loss: 0.06890411674976349
step: 1040, loss: 0.10233045369386673
step: 1050, loss: 0.07133017480373383
step: 1060, loss: 0.07339548319578171
step: 1070, loss: 0.1430656611919403
epoch 9: dev_f1=0.9436947417403444, f1=0.9388322520852641, best_f1=0.9388322520852641
step: 0, loss: 0.03665519505739212
step: 10, loss: 0.018269574269652367
step: 20, loss: 0.01309146173298359
step: 30, loss: 0.008061885833740234
step: 40, loss: 0.06075384467840195
step: 50, loss: 0.04953900724649429
step: 60, loss: 3.239169382140972e-05
step: 70, loss: 0.07578974217176437
step: 80, loss: 0.009274549782276154
step: 90, loss: 0.10098772495985031
step: 100, loss: 0.048213809728622437
step: 110, loss: 0.019430415704846382
step: 120, loss: 0.015836451202630997
step: 130, loss: 0.020817764103412628
step: 140, loss: 0.1177859827876091
step: 150, loss: 0.027196010574698448
step: 160, loss: 0.019948309287428856
step: 170, loss: 0.046609919518232346
step: 180, loss: 0.04945271089673042
step: 190, loss: 0.07029317319393158
step: 200, loss: 0.02978673204779625
step: 210, loss: 0.059891924262046814
step: 220, loss: 0.07899129390716553
step: 230, loss: 0.02019587717950344
step: 240, loss: 0.02626609429717064
step: 250, loss: 0.07136798650026321
step: 260, loss: 0.03355387598276138
step: 270, loss: 0.11133603006601334
step: 280, loss: 0.00031972816213965416
step: 290, loss: 0.007710985839366913
step: 300, loss: 0.07762335240840912
step: 310, loss: 0.0430716872215271
step: 320, loss: 0.06374096125364304
step: 330, loss: 0.04740656539797783
step: 340, loss: 0.16642431914806366
step: 350, loss: 0.04287468641996384
step: 360, loss: 0.01685747131705284
step: 370, loss: 0.010511035099625587
step: 380, loss: 0.18331187963485718
step: 390, loss: 0.1060464084148407
step: 400, loss: 0.013130497187376022
step: 410, loss: 0.010314593091607094
step: 420, loss: 0.06493204087018967
step: 430, loss: 0.02309202216565609
step: 440, loss: 0.0573628805577755
step: 450, loss: 0.02419138327240944
step: 460, loss: 0.041373111307621
step: 470, loss: 0.006743111182004213
step: 480, loss: 0.08063776046037674
step: 490, loss: 0.00569229107350111
step: 500, loss: 0.011087587103247643
step: 510, loss: 0.03338368237018585
step: 520, loss: 0.0209371205419302
step: 530, loss: 0.0001360227179247886
step: 540, loss: 0.0019511418649926782
step: 550, loss: 0.012734867632389069
step: 560, loss: 0.05448692664504051
step: 570, loss: 0.002763880416750908
step: 580, loss: 8.213250839617103e-05
step: 590, loss: 0.047047778964042664
step: 600, loss: 0.045458219945430756
step: 610, loss: 0.09300152212381363
step: 620, loss: 0.052493948489427567
step: 630, loss: 0.048048216849565506
step: 640, loss: 0.07121364772319794
step: 650, loss: 0.07520079612731934
step: 660, loss: 0.018813254311680794
step: 670, loss: 0.0017178884008899331
step: 680, loss: 0.04920195788145065
step: 690, loss: 0.025199051946401596
step: 700, loss: 0.014542733319103718
step: 710, loss: 0.21068976819515228
step: 720, loss: 0.10247161239385605
step: 730, loss: 0.03311442211270332
step: 740, loss: 0.017240937799215317
step: 750, loss: 3.384165756870061e-05
step: 760, loss: 0.021160466596484184
step: 770, loss: 0.08237248659133911
step: 780, loss: 0.042252495884895325
step: 790, loss: 0.0032493537291884422
step: 800, loss: 0.013366905972361565
step: 810, loss: 0.05020086467266083
step: 820, loss: 0.05366615206003189
step: 830, loss: 0.017757561057806015
step: 840, loss: 0.05465547367930412
step: 850, loss: 0.048562828451395035
step: 860, loss: 0.014826680533587933
step: 870, loss: 0.031205065548419952
step: 880, loss: 0.04115404933691025
step: 890, loss: 0.08029818534851074
step: 900, loss: 0.06050967052578926
step: 910, loss: 0.08769296109676361
step: 920, loss: 0.016697658225893974
step: 930, loss: 0.15522199869155884
step: 940, loss: 0.02330857142806053
step: 950, loss: 0.056984540075063705
step: 960, loss: 0.020276717841625214
step: 970, loss: 0.009214799851179123
step: 980, loss: 0.011361970566213131
step: 990, loss: 0.023669635877013206
step: 1000, loss: 0.021643152460455894
step: 1010, loss: 0.004212168976664543
step: 1020, loss: 0.10363356024026871
step: 1030, loss: 0.01618029735982418
step: 1040, loss: 0.054151199758052826
step: 1050, loss: 0.06547743827104568
step: 1060, loss: 0.053540050983428955
step: 1070, loss: 0.002008371986448765
epoch 10: dev_f1=0.9329710144927535, f1=0.9291196388261851, best_f1=0.9388322520852641
step: 0, loss: 0.02944379672408104
step: 10, loss: 0.003005651291459799
step: 20, loss: 0.16174030303955078
step: 30, loss: 0.020565159618854523
step: 40, loss: 0.05274573713541031
step: 50, loss: 0.08175201714038849
step: 60, loss: 0.0054491194896399975
step: 70, loss: 0.00658757146447897
step: 80, loss: 0.03682887181639671
step: 90, loss: 0.06981845200061798
step: 100, loss: 3.726980139617808e-05
step: 110, loss: 0.04390149191021919
step: 120, loss: 0.0070891124196350574
step: 130, loss: 0.00011739213368855417
step: 140, loss: 0.04688339680433273
step: 150, loss: 0.05729418620467186
step: 160, loss: 0.06216070055961609
step: 170, loss: 0.018226556479930878
step: 180, loss: 0.12129031121730804
step: 190, loss: 0.042417410761117935
step: 200, loss: 0.032909613102674484
step: 210, loss: 0.02503552846610546
step: 220, loss: 0.046954091638326645
step: 230, loss: 0.003142023691907525
step: 240, loss: 0.08667086064815521
step: 250, loss: 0.013578325510025024
step: 260, loss: 0.06410138309001923
step: 270, loss: 0.019577352330088615
step: 280, loss: 0.02304810658097267
step: 290, loss: 0.03611148148775101
step: 300, loss: 0.03441024199128151
step: 310, loss: 0.056997429579496384
step: 320, loss: 0.010742157697677612
step: 330, loss: 0.0010968822753056884
step: 340, loss: 0.026580406352877617
step: 350, loss: 0.01734944060444832
step: 360, loss: 0.08183899521827698
step: 370, loss: 0.0005619560834020376
step: 380, loss: 0.08836834132671356
step: 390, loss: 0.022036723792552948
step: 400, loss: 0.025505395606160164
step: 410, loss: 0.026668649166822433
step: 420, loss: 0.04065196216106415
step: 430, loss: 0.0008603291935287416
step: 440, loss: 0.09207186102867126
step: 450, loss: 0.050284579396247864
step: 460, loss: 0.011013406328856945
step: 470, loss: 0.06488754600286484
step: 480, loss: 0.10324914008378983
step: 490, loss: 0.13674484193325043
step: 500, loss: 0.006509288679808378
step: 510, loss: 0.011816129088401794
step: 520, loss: 0.009059232659637928
step: 530, loss: 0.005310484208166599
step: 540, loss: 0.05377189815044403
step: 550, loss: 0.08571149408817291
step: 560, loss: 0.05812672898173332
step: 570, loss: 0.0008615950937382877
step: 580, loss: 0.05173306539654732
step: 590, loss: 0.004090904723852873
step: 600, loss: 0.013903125189244747
step: 610, loss: 0.09182552993297577
step: 620, loss: 0.0892954170703888
step: 630, loss: 0.064467653632164
step: 640, loss: 0.03841206431388855
step: 650, loss: 0.02024945616722107
step: 660, loss: 0.05547590181231499
step: 670, loss: 0.09099310636520386
step: 680, loss: 0.021800987422466278
step: 690, loss: 0.012517226859927177
step: 700, loss: 0.007120934315025806
step: 710, loss: 0.0253558661788702
step: 720, loss: 0.04190342128276825
step: 730, loss: 0.02690146490931511
step: 740, loss: 0.003338542766869068
step: 750, loss: 0.0990888848900795
step: 760, loss: 0.02224847674369812
step: 770, loss: 0.006204682867974043
step: 780, loss: 0.056823961436748505
step: 790, loss: 0.01549868006259203
step: 800, loss: 0.034370314329862595
step: 810, loss: 0.034998536109924316
step: 820, loss: 0.05652754381299019
step: 830, loss: 0.009944469667971134
step: 840, loss: 0.0020542850252240896
step: 850, loss: 0.02291136607527733
step: 860, loss: 0.05747450515627861
step: 870, loss: 0.0657939612865448
step: 880, loss: 0.029725193977355957
step: 890, loss: 0.02336006425321102
step: 900, loss: 0.023073066025972366
step: 910, loss: 0.08405259996652603
step: 920, loss: 0.0022713495418429375
step: 930, loss: 0.0609251968562603
step: 940, loss: 0.08166096359491348
step: 950, loss: 0.03894280269742012
step: 960, loss: 0.0025483251083642244
step: 970, loss: 0.011355502530932426
step: 980, loss: 0.01900855451822281
step: 990, loss: 0.013759469613432884
step: 1000, loss: 0.02925599366426468
step: 1010, loss: 0.08457262814044952
step: 1020, loss: 0.05952897295355797
step: 1030, loss: 0.004782327450811863
step: 1040, loss: 0.0011002486571669579
step: 1050, loss: 0.07350955903530121
step: 1060, loss: 0.039572782814502716
step: 1070, loss: 0.016807101666927338
epoch 11: dev_f1=0.9366852886405959, f1=0.9337042188224385, best_f1=0.9388322520852641
step: 0, loss: 0.019247518852353096
step: 10, loss: 0.005821953061968088
step: 20, loss: 0.08519676327705383
step: 30, loss: 0.14750763773918152
step: 40, loss: 0.003645647084340453
step: 50, loss: 0.05222046747803688
step: 60, loss: 0.09559628367424011
step: 70, loss: 0.05765409395098686
step: 80, loss: 0.012495376169681549
step: 90, loss: 0.022266194224357605
step: 100, loss: 0.056112512946128845
step: 110, loss: 0.02621176280081272
step: 120, loss: 0.04501761123538017
step: 130, loss: 0.004812543746083975
step: 140, loss: 0.046733591705560684
step: 150, loss: 0.019541045650839806
step: 160, loss: 0.0004645866865757853
step: 170, loss: 0.004988737404346466
step: 180, loss: 0.012626003473997116
step: 190, loss: 0.018616808578372
step: 200, loss: 0.00812937319278717
step: 210, loss: 0.01959172450006008
step: 220, loss: 0.14202120900154114
step: 230, loss: 0.06678438931703568
step: 240, loss: 0.0032922911923378706
step: 250, loss: 0.002061130478978157
step: 260, loss: 0.05660269036889076
step: 270, loss: 0.00035381619818508625
step: 280, loss: 0.0352376252412796
step: 290, loss: 0.002398594282567501
step: 300, loss: 0.022542638704180717
step: 310, loss: 0.052762221544981
step: 320, loss: 0.02684522420167923
step: 330, loss: 0.0022912700660526752
step: 340, loss: 0.0022129102144390345
step: 350, loss: 0.03741256892681122
step: 360, loss: 0.004522814881056547
step: 370, loss: 0.041683800518512726
step: 380, loss: 0.019300414249300957
step: 390, loss: 0.0008829933940432966
step: 400, loss: 0.028462974354624748
step: 410, loss: 0.05432463437318802
step: 420, loss: 0.0029449257999658585
step: 430, loss: 0.04784317687153816
step: 440, loss: 0.030975613743066788
step: 450, loss: 0.023819491267204285
step: 460, loss: 0.014970401301980019
step: 470, loss: 0.0007171896868385375
step: 480, loss: 0.05292649194598198
step: 490, loss: 0.020667776465415955
step: 500, loss: 0.02135516330599785
step: 510, loss: 0.057564664632081985
step: 520, loss: 0.061608195304870605
step: 530, loss: 0.00048482613055966794
step: 540, loss: 0.03347849100828171
step: 550, loss: 0.13432635366916656
step: 560, loss: 0.025491518899798393
step: 570, loss: 0.06789421290159225
step: 580, loss: 0.012822281569242477
step: 590, loss: 0.0021135015413165092
step: 600, loss: 0.026461781933903694
step: 610, loss: 0.04290979355573654
step: 620, loss: 4.54147084383294e-05
step: 630, loss: 0.04222290217876434
step: 640, loss: 0.03396831452846527
step: 650, loss: 0.053945332765579224
step: 660, loss: 0.00012517253344412893
step: 670, loss: 0.014825958758592606
step: 680, loss: 0.1312062293291092
step: 690, loss: 0.05354486033320427
step: 700, loss: 0.015189631842076778
step: 710, loss: 0.09176256507635117
step: 720, loss: 0.04384202882647514
step: 730, loss: 0.0013618250377476215
step: 740, loss: 0.010478499345481396
step: 750, loss: 0.004951958544552326
step: 760, loss: 0.004668514709919691
step: 770, loss: 0.04561665654182434
step: 780, loss: 0.006994781084358692
step: 790, loss: 0.08194369822740555
step: 800, loss: 0.057417578995227814
step: 810, loss: 0.05054416507482529
step: 820, loss: 0.1334540992975235
step: 830, loss: 0.01885681040585041
step: 840, loss: 0.061534907668828964
step: 850, loss: 0.06982770562171936
step: 860, loss: 0.04098055884242058
step: 870, loss: 0.09567749500274658
step: 880, loss: 0.027255715802311897
step: 890, loss: 0.02442399226129055
step: 900, loss: 0.0009962781332433224
step: 910, loss: 0.07722368091344833
step: 920, loss: 0.06277381628751755
step: 930, loss: 0.08864205330610275
step: 940, loss: 0.044024862349033356
step: 950, loss: 0.0050911009311676025
step: 960, loss: 0.002185928402468562
step: 970, loss: 0.0037848632782697678
step: 980, loss: 0.047596126794815063
step: 990, loss: 0.001102557172998786
step: 1000, loss: 0.041012682020664215
step: 1010, loss: 0.00324425520375371
step: 1020, loss: 0.014099393971264362
step: 1030, loss: 0.1346331238746643
step: 1040, loss: 0.006711109541356564
step: 1050, loss: 0.10660149902105331
step: 1060, loss: 0.04260454699397087
step: 1070, loss: 0.01992128975689411
epoch 12: dev_f1=0.9328984156570364, f1=0.9307479224376731, best_f1=0.9388322520852641
step: 0, loss: 0.0009268260910175741
step: 10, loss: 0.00586867006495595
step: 20, loss: 0.011756797321140766
step: 30, loss: 0.028172079473733902
step: 40, loss: 0.003315432695671916
step: 50, loss: 0.06326917558908463
step: 60, loss: 0.0016800439916551113
step: 70, loss: 0.024486767128109932
step: 80, loss: 0.05660435929894447
step: 90, loss: 0.0662570521235466
step: 100, loss: 0.012355050072073936
step: 110, loss: 0.07399159669876099
step: 120, loss: 0.07976517081260681
step: 130, loss: 0.029633257538080215
step: 140, loss: 0.026872560381889343
step: 150, loss: 0.0021270227152854204
step: 160, loss: 0.025515586137771606
step: 170, loss: 0.0004189723404124379
step: 180, loss: 0.012149539776146412
step: 190, loss: 0.06073932722210884
step: 200, loss: 0.1215580627322197
step: 210, loss: 0.00018167229427490383
step: 220, loss: 0.023776154965162277
step: 230, loss: 0.02507448010146618
step: 240, loss: 0.00011667826765915379
step: 250, loss: 0.02303532138466835
step: 260, loss: 0.030868176370859146
step: 270, loss: 0.05899462103843689
step: 280, loss: 7.231855124700814e-05
step: 290, loss: 0.0717441588640213
step: 300, loss: 0.016432102769613266
step: 310, loss: 0.0014948698226362467
step: 320, loss: 0.010092881508171558
step: 330, loss: 0.14880838990211487
step: 340, loss: 0.02269149385392666
step: 350, loss: 0.03811727091670036
step: 360, loss: 0.002854664344340563
step: 370, loss: 0.03510930389165878
step: 380, loss: 0.016399385407567024
step: 390, loss: 0.009207726456224918
step: 400, loss: 0.005295657552778721
step: 410, loss: 0.0027357996441423893
step: 420, loss: 0.05639491602778435
step: 430, loss: 0.03987855836749077
step: 440, loss: 0.024312153458595276
step: 450, loss: 0.02497727796435356
step: 460, loss: 0.031248843297362328
step: 470, loss: 0.031113162636756897
step: 480, loss: 3.9364054828183725e-05
step: 490, loss: 0.012742588296532631
step: 500, loss: 0.024211376905441284
step: 510, loss: 0.0361773818731308
step: 520, loss: 1.0181161997024901e-05
step: 530, loss: 0.02884616330265999
step: 540, loss: 0.060207486152648926
step: 550, loss: 0.010770960710942745
step: 560, loss: 0.01504422351717949
step: 570, loss: 0.03466705232858658
step: 580, loss: 0.09521400183439255
step: 590, loss: 0.007998957298696041
step: 600, loss: 0.05062106251716614
step: 610, loss: 0.0012574407737702131
step: 620, loss: 0.0013719077687710524
step: 630, loss: 3.1046740332385525e-05
step: 640, loss: 0.04391683638095856
step: 650, loss: 0.02169341780245304
step: 660, loss: 0.039160147309303284
step: 670, loss: 0.11555667221546173
step: 680, loss: 0.019913282245397568
step: 690, loss: 0.15689435601234436
step: 700, loss: 0.025545472279191017
step: 710, loss: 0.030420837923884392
step: 720, loss: 0.0763939842581749
step: 730, loss: 0.01869025081396103
step: 740, loss: 0.09014689922332764
step: 750, loss: 0.009305866435170174
step: 760, loss: 0.09076274931430817
step: 770, loss: 0.039982929825782776
step: 780, loss: 0.04654278978705406
step: 790, loss: 0.02296607755124569
step: 800, loss: 0.018843693658709526
step: 810, loss: 0.01881948485970497
step: 820, loss: 0.021468786522746086
step: 830, loss: 0.04005105420947075
step: 840, loss: 0.08716883510351181
step: 850, loss: 0.04415420815348625
step: 860, loss: 0.02159486897289753
step: 870, loss: 0.05781405419111252
step: 880, loss: 0.06559079140424728
step: 890, loss: 0.0007271565846167505
step: 900, loss: 0.0011634485563263297
step: 910, loss: 0.054370131343603134
step: 920, loss: 0.0002820719382725656
step: 930, loss: 0.011636843904852867
step: 940, loss: 1.4796595678490121e-05
step: 950, loss: 0.04593415930867195
step: 960, loss: 0.07095896452665329
step: 970, loss: 0.02757657691836357
step: 980, loss: 0.0013670834014192224
step: 990, loss: 0.018925484269857407
step: 1000, loss: 8.506578160449862e-05
step: 1010, loss: 0.00619625486433506
step: 1020, loss: 0.016436604782938957
step: 1030, loss: 0.1790814995765686
step: 1040, loss: 0.03545879200100899
step: 1050, loss: 0.0615694522857666
step: 1060, loss: 0.0007400237373076379
step: 1070, loss: 0.06427980959415436
epoch 13: dev_f1=0.9350529709811147, f1=0.9307201458523247, best_f1=0.9388322520852641
step: 0, loss: 0.007135376799851656
step: 10, loss: 0.10942645370960236
step: 20, loss: 0.02701006457209587
step: 30, loss: 0.022693829610943794
step: 40, loss: 0.047772057354450226
step: 50, loss: 0.030754422768950462
step: 60, loss: 0.057393383234739304
step: 70, loss: 0.0003071481769438833
step: 80, loss: 0.0002352054143557325
step: 90, loss: 0.12577849626541138
step: 100, loss: 0.00026919724768958986
step: 110, loss: 0.05039753392338753
step: 120, loss: 0.0001235958916367963
step: 130, loss: 0.006024272181093693
step: 140, loss: 0.019040623679757118
step: 150, loss: 0.0013921363279223442
step: 160, loss: 0.001063456991687417
step: 170, loss: 0.03942553699016571
step: 180, loss: 0.0642724335193634
step: 190, loss: 0.022288870066404343
step: 200, loss: 0.00040893928962759674
step: 210, loss: 0.037429798394441605
step: 220, loss: 0.016450241208076477
step: 230, loss: 0.00010090846626553684
step: 240, loss: 0.03304164484143257
step: 250, loss: 0.01624375209212303
step: 260, loss: 0.0013309718342497945
step: 270, loss: 0.004577857907861471
step: 280, loss: 0.022040823474526405
step: 290, loss: 0.01930587738752365
step: 300, loss: 0.06973311305046082
step: 310, loss: 0.053612563759088516
step: 320, loss: 0.02248355560004711
step: 330, loss: 0.0007948673446662724
step: 340, loss: 0.06244564801454544
step: 350, loss: 0.046703752130270004
step: 360, loss: 0.023973213508725166
step: 370, loss: 0.03291473537683487
step: 380, loss: 0.06719215959310532
step: 390, loss: 0.02524443157017231
step: 400, loss: 0.030271830037236214
step: 410, loss: 0.01569097302854061
step: 420, loss: 0.08850865811109543
step: 430, loss: 0.03512455150485039
step: 440, loss: 0.012690110132098198
step: 450, loss: 0.04669266566634178
step: 460, loss: 0.03886471316218376
step: 470, loss: 0.005382172763347626
step: 480, loss: 0.06019693613052368
step: 490, loss: 0.0359848327934742
step: 500, loss: 0.017088403925299644
step: 510, loss: 0.0038448963314294815
step: 520, loss: 0.0054192980751395226
step: 530, loss: 0.00038963332190178335
step: 540, loss: 0.017834054306149483
step: 550, loss: 0.001721594133414328
step: 560, loss: 0.04314260557293892
step: 570, loss: 6.446107727242634e-05
step: 580, loss: 0.03930218890309334
step: 590, loss: 0.030286844819784164
step: 600, loss: 0.019795220345258713
step: 610, loss: 0.0005422254907898605
step: 620, loss: 7.505522080464289e-05
step: 630, loss: 0.006458562798798084
step: 640, loss: 0.06979621201753616
step: 650, loss: 0.03588150814175606
step: 660, loss: 7.320143049582839e-05
step: 670, loss: 0.028703009709715843
step: 680, loss: 0.005181383807212114
step: 690, loss: 0.03460560366511345
step: 700, loss: 0.039660900831222534
step: 710, loss: 0.01853490248322487
step: 720, loss: 0.007401586044579744
step: 730, loss: 0.0816909521818161
step: 740, loss: 0.054966043680906296
step: 750, loss: 0.04743243008852005
step: 760, loss: 0.04373724386096001
step: 770, loss: 0.0011344687081873417
step: 780, loss: 0.01582634635269642
step: 790, loss: 0.040699224919080734
step: 800, loss: 0.05869768187403679
step: 810, loss: 0.046854835003614426
step: 820, loss: 0.01972985453903675
step: 830, loss: 0.057183120399713516
step: 840, loss: 0.1445804387331009
step: 850, loss: 0.004834057297557592
step: 860, loss: 0.03954417258501053
step: 870, loss: 0.03258487582206726
step: 880, loss: 0.03136478736996651
step: 890, loss: 0.033389121294021606
step: 900, loss: 0.0006120629841461778
step: 910, loss: 0.025694245472550392
step: 920, loss: 0.02638387493789196
step: 930, loss: 0.03038322553038597
step: 940, loss: 0.0001041294599417597
step: 950, loss: 0.033705469220876694
step: 960, loss: 0.030778344720602036
step: 970, loss: 0.10257402062416077
step: 980, loss: 0.0001895719615276903
step: 990, loss: 0.022609209641814232
step: 1000, loss: 0.07500030845403671
step: 1010, loss: 0.0216181892901659
step: 1020, loss: 0.007168212439864874
step: 1030, loss: 0.036752622574567795
step: 1040, loss: 0.010783257894217968
step: 1050, loss: 0.02168072760105133
step: 1060, loss: 0.11648177355527878
step: 1070, loss: 0.002073464449495077
epoch 14: dev_f1=0.9342043863742416, f1=0.935813953488372, best_f1=0.9388322520852641
step: 0, loss: 0.04745177924633026
step: 10, loss: 0.024981824681162834
step: 20, loss: 0.06649714708328247
step: 30, loss: 7.319408905459568e-05
step: 40, loss: 0.02053068019449711
step: 50, loss: 0.03960097208619118
step: 60, loss: 0.04669244587421417
step: 70, loss: 0.04774755612015724
step: 80, loss: 0.00038069344009272754
step: 90, loss: 0.001706545241177082
step: 100, loss: 0.02259494736790657
step: 110, loss: 2.8453845516196452e-05
step: 120, loss: 0.022606391459703445
step: 130, loss: 0.023569529876112938
step: 140, loss: 0.11942659318447113
step: 150, loss: 0.01704038307070732
step: 160, loss: 0.036058973520994186
step: 170, loss: 0.028039846569299698
step: 180, loss: 0.010346245020627975
step: 190, loss: 0.11477280408143997
step: 200, loss: 0.024084316566586494
step: 210, loss: 0.005574587732553482
step: 220, loss: 0.000128193772980012
step: 230, loss: 0.0008275324362330139
step: 240, loss: 4.2070405470440164e-05
step: 250, loss: 0.017760176211595535
step: 260, loss: 0.048854708671569824
step: 270, loss: 0.06429295241832733
step: 280, loss: 0.03748584911227226
step: 290, loss: 0.027428612112998962
step: 300, loss: 0.037638548761606216
step: 310, loss: 0.017715347930788994
step: 320, loss: 0.045720767229795456
step: 330, loss: 0.04341525211930275
step: 340, loss: 0.00029335712315514684
step: 350, loss: 0.05234015733003616
step: 360, loss: 0.023242317140102386
step: 370, loss: 0.03436357155442238
step: 380, loss: 0.026393579319119453
step: 390, loss: 0.013804740272462368
step: 400, loss: 0.042794421315193176
step: 410, loss: 0.002606539521366358
step: 420, loss: 0.0074510881677269936
step: 430, loss: 0.03922359645366669
step: 440, loss: 0.009019346907734871
step: 450, loss: 0.05026199296116829
step: 460, loss: 0.044166937470436096
step: 470, loss: 0.13546067476272583
step: 480, loss: 0.015173511579632759
step: 490, loss: 0.018683888018131256
step: 500, loss: 0.07831326872110367
step: 510, loss: 0.0014014255721122026
step: 520, loss: 0.020401353016495705
step: 530, loss: 0.0009130684775300324
step: 540, loss: 0.0113601665943861
step: 550, loss: 0.10643436014652252
step: 560, loss: 0.0410166010260582
step: 570, loss: 0.0321282297372818
step: 580, loss: 0.057524099946022034
step: 590, loss: 7.540541264461353e-05
step: 600, loss: 0.12379276007413864
step: 610, loss: 0.048104606568813324
step: 620, loss: 0.003670419566333294
step: 630, loss: 0.032914940267801285
step: 640, loss: 0.07240866869688034
step: 650, loss: 0.01799006573855877
step: 660, loss: 0.0012189645785838366
step: 670, loss: 0.005307562183588743
step: 680, loss: 0.1060544103384018
step: 690, loss: 0.021389348432421684
step: 700, loss: 0.043496619910001755
step: 710, loss: 0.03061126358807087
step: 720, loss: 0.042882148176431656
step: 730, loss: 0.13818389177322388
step: 740, loss: 0.07543033361434937
step: 750, loss: 0.02133435569703579
step: 760, loss: 0.0033649972174316645
step: 770, loss: 0.035493236035108566
step: 780, loss: 0.0005951040075160563
step: 790, loss: 0.005512506701052189
step: 800, loss: 0.015859585255384445
step: 810, loss: 7.306798943318427e-05
step: 820, loss: 0.07782922685146332
step: 830, loss: 0.03983178734779358
step: 840, loss: 4.2387218854855746e-05
step: 850, loss: 0.027934137731790543
step: 860, loss: 0.05113508552312851
step: 870, loss: 0.0035565325524657965
step: 880, loss: 0.036987531930208206
step: 890, loss: 0.015532547608017921
step: 900, loss: 0.011453581973910332
step: 910, loss: 0.09559094905853271
step: 920, loss: 0.02724618650972843
step: 930, loss: 0.01663709618151188
step: 940, loss: 0.013276532292366028
step: 950, loss: 6.61076046526432e-05
step: 960, loss: 0.03740359842777252
step: 970, loss: 0.007311997935175896
step: 980, loss: 0.0003210016875527799
step: 990, loss: 0.018201125785708427
step: 1000, loss: 0.0048639229498803616
step: 1010, loss: 0.0033117816783487797
step: 1020, loss: 0.03398006781935692
step: 1030, loss: 0.11050227284431458
step: 1040, loss: 0.03755698725581169
step: 1050, loss: 0.00047318663564510643
step: 1060, loss: 0.002057046629488468
step: 1070, loss: 0.01048079039901495
epoch 15: dev_f1=0.9322268326417704, f1=0.9335167354424576, best_f1=0.9388322520852641
step: 0, loss: 0.015991611406207085
step: 10, loss: 0.03022940270602703
step: 20, loss: 0.00047545068082399666
step: 30, loss: 0.0026895918417721987
step: 40, loss: 0.0004310003714635968
step: 50, loss: 0.04005909338593483
step: 60, loss: 0.0001209283946081996
step: 70, loss: 0.005888323299586773
step: 80, loss: 0.020516281947493553
step: 90, loss: 0.11150183528661728
step: 100, loss: 0.015100185759365559
step: 110, loss: 0.0821811705827713
step: 120, loss: 0.018086964264512062
step: 130, loss: 0.0006283528637140989
step: 140, loss: 0.06091130152344704
step: 150, loss: 0.00021612191630993038
step: 160, loss: 0.00014915689826011658
step: 170, loss: 0.0501529835164547
step: 180, loss: 0.02459968812763691
step: 190, loss: 0.08354862779378891
step: 200, loss: 0.04477907344698906
step: 210, loss: 0.04739265516400337
step: 220, loss: 0.01770956441760063
step: 230, loss: 0.016678135842084885
step: 240, loss: 0.039622221142053604
step: 250, loss: 0.028130773454904556
step: 260, loss: 0.06572940945625305
step: 270, loss: 0.02599850855767727
step: 280, loss: 0.014012313447892666
step: 290, loss: 0.06303991377353668
step: 300, loss: 0.07995083183050156
step: 310, loss: 0.0008615551050752401
step: 320, loss: 0.055455971509218216
step: 330, loss: 0.02146952599287033
step: 340, loss: 0.06355676800012589
step: 350, loss: 0.022492358461022377
step: 360, loss: 0.02875254675745964
step: 370, loss: 0.05874646082520485
step: 380, loss: 0.04599855840206146
step: 390, loss: 0.055184416472911835
step: 400, loss: 0.07925231009721756
step: 410, loss: 0.019389526918530464
step: 420, loss: 0.013485957868397236
step: 430, loss: 0.027491169050335884
step: 440, loss: 0.028981784358620644
step: 450, loss: 2.7218633476877585e-05
step: 460, loss: 0.04147612303495407
step: 470, loss: 0.03696439415216446
step: 480, loss: 0.00048416093341074884
step: 490, loss: 0.044232048094272614
step: 500, loss: 0.07680482417345047
step: 510, loss: 0.0008150268695317209
step: 520, loss: 0.00014504566206596792
step: 530, loss: 0.03268299624323845
step: 540, loss: 0.02518058568239212
step: 550, loss: 0.006900986190885305
step: 560, loss: 0.07151351869106293
step: 570, loss: 0.07211333513259888
step: 580, loss: 0.0342908650636673
step: 590, loss: 0.0005309307016432285
step: 600, loss: 0.023349110037088394
step: 610, loss: 0.05706721916794777
step: 620, loss: 0.0061957561410963535
step: 630, loss: 0.00035123692941851914
step: 640, loss: 0.002759038470685482
step: 650, loss: 0.07454570382833481
step: 660, loss: 0.006579192355275154
step: 670, loss: 0.019527489319443703
step: 680, loss: 0.027500074356794357
step: 690, loss: 0.04814908653497696
step: 700, loss: 0.021802807226777077
step: 710, loss: 0.03363795951008797
step: 720, loss: 0.027015628293156624
step: 730, loss: 0.018489206209778786
step: 740, loss: 0.1268259584903717
step: 750, loss: 0.053669434040784836
step: 760, loss: 0.028049765154719353
step: 770, loss: 0.04064428433775902
step: 780, loss: 0.09003348648548126
step: 790, loss: 0.10763856023550034
step: 800, loss: 0.00196477142162621
step: 810, loss: 0.08731794357299805
step: 820, loss: 0.0573098361492157
step: 830, loss: 0.06631987541913986
step: 840, loss: 0.057746533304452896
step: 850, loss: 9.475764818489552e-05
step: 860, loss: 0.050795335322618484
step: 870, loss: 0.0007875992450863123
step: 880, loss: 0.05104721337556839
step: 890, loss: 0.017074810341000557
step: 900, loss: 0.023840362206101418
step: 910, loss: 0.020160267129540443
step: 920, loss: 0.02373003587126732
step: 930, loss: 0.02295055240392685
step: 940, loss: 0.015233614481985569
step: 950, loss: 0.0009117829031310976
step: 960, loss: 0.022918827831745148
step: 970, loss: 0.03308853134512901
step: 980, loss: 0.00033769075525924563
step: 990, loss: 0.05341767892241478
step: 1000, loss: 0.034352440387010574
step: 1010, loss: 0.01131994929164648
step: 1020, loss: 0.012470008805394173
step: 1030, loss: 0.039858583360910416
step: 1040, loss: 0.016481423750519753
step: 1050, loss: 0.01256532222032547
step: 1060, loss: 0.05762983858585358
step: 1070, loss: 0.004386101383715868
epoch 16: dev_f1=0.9309056956115779, f1=0.9331476323119777, best_f1=0.9388322520852641
step: 0, loss: 0.020020365715026855
step: 10, loss: 0.0560147725045681
step: 20, loss: 0.022732624784111977
step: 30, loss: 0.04083241522312164
step: 40, loss: 0.002403351478278637
step: 50, loss: 5.790067370980978e-05
step: 60, loss: 0.03405226022005081
step: 70, loss: 0.025164788588881493
step: 80, loss: 0.023528821766376495
step: 90, loss: 0.02434871345758438
step: 100, loss: 0.018722033128142357
step: 110, loss: 0.012178969569504261
step: 120, loss: 0.036076221615076065
step: 130, loss: 0.0005178435239940882
step: 140, loss: 0.0008872526232153177
step: 150, loss: 0.04389999061822891
step: 160, loss: 0.07134080678224564
step: 170, loss: 0.06674427539110184
step: 180, loss: 0.022710535675287247
step: 190, loss: 0.00024476920953020453
step: 200, loss: 0.056472860276699066
step: 210, loss: 0.020039435476064682
step: 220, loss: 0.002004052512347698
step: 230, loss: 0.020662080496549606
step: 240, loss: 0.0005453169578686357
step: 250, loss: 0.021131198853254318
step: 260, loss: 0.03261643648147583
step: 270, loss: 0.09947750717401505
step: 280, loss: 0.00903189368546009
step: 290, loss: 0.010059056803584099
step: 300, loss: 0.019129641354084015
step: 310, loss: 0.00029909206205047667
step: 320, loss: 0.033730268478393555
step: 330, loss: 0.021060187369585037
step: 340, loss: 0.0035806403029710054
step: 350, loss: 0.032009195536375046
step: 360, loss: 0.028001023456454277
step: 370, loss: 0.05749259144067764
step: 380, loss: 0.029516737908124924
step: 390, loss: 0.00816238485276699
step: 400, loss: 3.377307439222932e-05
step: 410, loss: 0.026940004900097847
step: 420, loss: 0.045558396726846695
step: 430, loss: 0.042219869792461395
step: 440, loss: 0.00010112192831002176
step: 450, loss: 0.06445009261369705
step: 460, loss: 0.0009228076669387519
step: 470, loss: 0.00010382499021943659
step: 480, loss: 0.05025305971503258
step: 490, loss: 0.038377419114112854
step: 500, loss: 0.024619750678539276
step: 510, loss: 0.06738750636577606
step: 520, loss: 0.054186780005693436
step: 530, loss: 0.04372590035200119
step: 540, loss: 2.3341643100138754e-05
step: 550, loss: 9.485062037128955e-05
step: 560, loss: 0.00021158828167244792
step: 570, loss: 0.03329072520136833
step: 580, loss: 0.00016444234643131495
step: 590, loss: 0.02260059118270874
step: 600, loss: 0.02389853075146675
step: 610, loss: 0.04193598031997681
step: 620, loss: 0.02527509815990925
step: 630, loss: 0.05427563190460205
step: 640, loss: 6.166855746414512e-05
step: 650, loss: 0.06072155758738518
step: 660, loss: 0.022039610892534256
step: 670, loss: 0.01955663226544857
step: 680, loss: 0.06225870922207832
step: 690, loss: 0.020139608532190323
step: 700, loss: 0.03870664909482002
step: 710, loss: 0.02256472036242485
step: 720, loss: 0.02054574526846409
step: 730, loss: 0.044453151524066925
step: 740, loss: 0.025541558861732483
step: 750, loss: 0.031168727204203606
step: 760, loss: 0.024907590821385384
step: 770, loss: 0.09053389728069305
step: 780, loss: 0.0009803327266126871
step: 790, loss: 0.05837811157107353
step: 800, loss: 0.03493104502558708
step: 810, loss: 0.06532185524702072
step: 820, loss: 3.333140557515435e-05
step: 830, loss: 0.021316824480891228
step: 840, loss: 0.008653907105326653
step: 850, loss: 5.265347135718912e-05
step: 860, loss: 0.02104783244431019
step: 870, loss: 0.016078248620033264
step: 880, loss: 2.13710154639557e-05
step: 890, loss: 0.027997158467769623
step: 900, loss: 2.048090027528815e-05
step: 910, loss: 0.014212985523045063
step: 920, loss: 0.056471969932317734
step: 930, loss: 0.021547457203269005
step: 940, loss: 0.060505520552396774
step: 950, loss: 0.021684620529413223
step: 960, loss: 0.0009842799045145512
step: 970, loss: 0.06247154250741005
step: 980, loss: 0.014961428008973598
step: 990, loss: 0.026259804144501686
step: 1000, loss: 0.08652132004499435
step: 1010, loss: 0.02167210914194584
step: 1020, loss: 0.00042002659756690264
step: 1030, loss: 0.009560937993228436
step: 1040, loss: 0.002035495126619935
step: 1050, loss: 0.015149181708693504
step: 1060, loss: 0.06673716008663177
step: 1070, loss: 0.0039405361749231815
epoch 17: dev_f1=0.9314685314685315, f1=0.9284043051006083, best_f1=0.9388322520852641
step: 0, loss: 0.004599367268383503
step: 10, loss: 0.0003444902249611914
step: 20, loss: 0.05055243894457817
step: 30, loss: 0.049220141023397446
step: 40, loss: 0.023161383345723152
step: 50, loss: 0.01654665172100067
step: 60, loss: 0.0015805072616785765
step: 70, loss: 0.001023392309434712
step: 80, loss: 0.029884185642004013
step: 90, loss: 0.013053776696324348
step: 100, loss: 0.0021491372026503086
step: 110, loss: 0.02820473164319992
step: 120, loss: 0.025408634915947914
step: 130, loss: 0.03668782114982605
step: 140, loss: 7.134550105547532e-05
step: 150, loss: 0.03741667792201042
step: 160, loss: 6.195744936121628e-05
step: 170, loss: 0.05067870393395424
step: 180, loss: 0.024551985785365105
step: 190, loss: 0.01981816440820694
step: 200, loss: 0.013855420053005219
step: 210, loss: 0.022235194221138954
step: 220, loss: 0.02078702114522457
step: 230, loss: 0.01768576353788376
step: 240, loss: 0.02668505348265171
step: 250, loss: 0.04402897506952286
step: 260, loss: 0.04653926193714142
step: 270, loss: 0.02306310646235943
step: 280, loss: 0.021158801391720772
step: 290, loss: 0.0007937837508507073
step: 300, loss: 0.07034505158662796
step: 310, loss: 0.028465116396546364
step: 320, loss: 0.02017614245414734
step: 330, loss: 0.022583086043596268
step: 340, loss: 0.019389722496271133
step: 350, loss: 7.2542650741525e-05
step: 360, loss: 0.00013095021131448448
step: 370, loss: 0.0205402672290802
step: 380, loss: 0.01702907495200634
step: 390, loss: 0.022571895271539688
step: 400, loss: 3.011951775988564e-05
step: 410, loss: 0.0029683364555239677
step: 420, loss: 0.01307103130966425
step: 430, loss: 1.468846676289104e-05
step: 440, loss: 0.0013966780388727784
step: 450, loss: 0.0001894898305181414
step: 460, loss: 0.015358406119048595
step: 470, loss: 0.04964330792427063
step: 480, loss: 2.157797098334413e-05
step: 490, loss: 0.018422286957502365
step: 500, loss: 1.5124219316930976e-05
step: 510, loss: 0.016651883721351624
step: 520, loss: 0.02743462473154068
step: 530, loss: 0.03731200844049454
step: 540, loss: 0.02886834181845188
step: 550, loss: 1.47146092785988e-05
step: 560, loss: 0.0005551431677304208
step: 570, loss: 0.00011558265396161005
step: 580, loss: 0.08790380507707596
step: 590, loss: 0.030922748148441315
step: 600, loss: 1.1227919458178803e-05
step: 610, loss: 0.0517507903277874
step: 620, loss: 0.0020020720548927784
step: 630, loss: 2.4515749828424305e-05
step: 640, loss: 0.023850155994296074
step: 650, loss: 0.05018075928092003
step: 660, loss: 0.002789580961689353
step: 670, loss: 0.017523104324936867
step: 680, loss: 0.015641774982213974
step: 690, loss: 0.00016989803407341242
step: 700, loss: 0.03840694576501846
step: 710, loss: 0.022739438340067863
step: 720, loss: 0.01719580963253975
step: 730, loss: 0.029255174100399017
step: 740, loss: 0.021650200709700584
step: 750, loss: 0.016650555655360222
step: 760, loss: 0.02456752210855484
step: 770, loss: 0.07489132881164551
step: 780, loss: 0.01929367333650589
step: 790, loss: 0.02462279424071312
step: 800, loss: 7.260058919200674e-05
step: 810, loss: 0.028972843661904335
step: 820, loss: 0.09137922525405884
step: 830, loss: 0.021687692031264305
step: 840, loss: 0.09734223783016205
step: 850, loss: 0.032329391688108444
step: 860, loss: 0.02388487011194229
step: 870, loss: 0.015566140413284302
step: 880, loss: 0.018933679908514023
step: 890, loss: 0.013749155215919018
step: 900, loss: 0.02683776617050171
step: 910, loss: 0.005984867457300425
step: 920, loss: 0.04804100841283798
step: 930, loss: 0.01882103458046913
step: 940, loss: 0.02030658721923828
step: 950, loss: 0.04162266477942467
step: 960, loss: 0.02234860695898533
step: 970, loss: 0.021043021231889725
step: 980, loss: 0.03385990113019943
step: 990, loss: 2.2283651560428552e-05
step: 1000, loss: 2.611837044241838e-05
step: 1010, loss: 0.009423471987247467
step: 1020, loss: 0.02398928999900818
step: 1030, loss: 0.048296622931957245
step: 1040, loss: 0.0003704540431499481
step: 1050, loss: 0.0013568418798968196
step: 1060, loss: 0.05650205910205841
step: 1070, loss: 0.051602765917778015
epoch 18: dev_f1=0.9315448658649398, f1=0.9305108145421077, best_f1=0.9388322520852641
step: 0, loss: 0.05274367704987526
step: 10, loss: 0.11721973866224289
step: 20, loss: 0.0001309425279032439
step: 30, loss: 0.04245806485414505
step: 40, loss: 0.07943334430456161
step: 50, loss: 0.0043047089129686356
step: 60, loss: 0.01932632364332676
step: 70, loss: 5.7364144595339894e-05
step: 80, loss: 0.019667087122797966
step: 90, loss: 0.00017846794798970222
step: 100, loss: 0.0001971674500964582
step: 110, loss: 0.02549108862876892
step: 120, loss: 0.026092130690813065
step: 130, loss: 0.05162855237722397
step: 140, loss: 0.0038567990995943546
step: 150, loss: 0.035692598670721054
step: 160, loss: 0.05942488834261894
step: 170, loss: 2.3600283384439535e-05
step: 180, loss: 0.03689293935894966
step: 190, loss: 0.05792279541492462
step: 200, loss: 0.02448268048465252
step: 210, loss: 0.0001063651725417003
step: 220, loss: 2.4937568014138378e-05
step: 230, loss: 0.02124939113855362
step: 240, loss: 0.0001619483227841556
step: 250, loss: 0.06430648267269135
step: 260, loss: 0.020076153799891472
step: 270, loss: 0.009369857609272003
step: 280, loss: 0.021830789744853973
step: 290, loss: 0.05900441110134125
step: 300, loss: 2.8488426323747262e-05
step: 310, loss: 0.027723029255867004
step: 320, loss: 0.02295180968940258
step: 330, loss: 0.00044794101268053055
step: 340, loss: 0.09002653509378433
step: 350, loss: 0.0021452405489981174
step: 360, loss: 0.022408096119761467
step: 370, loss: 0.03976083919405937
step: 380, loss: 0.0021774889901280403
step: 390, loss: 0.0004925166140310466
step: 400, loss: 0.04627234861254692
step: 410, loss: 3.1747382308822125e-05
step: 420, loss: 0.019465655088424683
step: 430, loss: 0.00019919671467505395
step: 440, loss: 0.026646949350833893
step: 450, loss: 0.13949370384216309
step: 460, loss: 0.07099056243896484
step: 470, loss: 0.0517493411898613
step: 480, loss: 1.2516650713223498e-05
step: 490, loss: 0.04864678159356117
step: 500, loss: 0.018422797322273254
step: 510, loss: 0.021380988880991936
step: 520, loss: 0.04991723969578743
step: 530, loss: 0.043131303042173386
step: 540, loss: 0.00140983029268682
step: 550, loss: 0.01045108214020729
step: 560, loss: 0.025783803313970566
step: 570, loss: 0.021669486537575722
step: 580, loss: 0.03330765664577484
step: 590, loss: 0.019818704575300217
step: 600, loss: 0.011403528042137623
step: 610, loss: 0.03423739969730377
step: 620, loss: 0.021916313096880913
step: 630, loss: 0.0025474890135228634
step: 640, loss: 0.0684167891740799
step: 650, loss: 0.020131852477788925
step: 660, loss: 0.055368389934301376
step: 670, loss: 0.03020470030605793
step: 680, loss: 1.5753463230794296e-05
step: 690, loss: 0.06342804431915283
step: 700, loss: 0.050000548362731934
step: 710, loss: 0.02144870162010193
step: 720, loss: 0.0010096774203702807
step: 730, loss: 0.013094970025122166
step: 740, loss: 0.020944256335496902
step: 750, loss: 0.0011947609018534422
step: 760, loss: 0.0005944125005044043
step: 770, loss: 1.8741122403298505e-05
step: 780, loss: 2.419058364466764e-05
step: 790, loss: 0.015451319515705109
step: 800, loss: 0.01819838024675846
step: 810, loss: 0.020241763442754745
step: 820, loss: 0.014296070672571659
step: 830, loss: 1.3768446478934493e-05
step: 840, loss: 0.0861251950263977
step: 850, loss: 0.03334617614746094
step: 860, loss: 0.050543177872896194
step: 870, loss: 0.08166433870792389
step: 880, loss: 0.0008472753106616437
step: 890, loss: 0.05069209635257721
step: 900, loss: 0.014218878000974655
step: 910, loss: 0.02544873021543026
step: 920, loss: 0.04845200106501579
step: 930, loss: 0.0006961731123737991
step: 940, loss: 0.0326782688498497
step: 950, loss: 3.201979416189715e-05
step: 960, loss: 0.0011792373843491077
step: 970, loss: 0.013404167257249355
step: 980, loss: 0.010247023776173592
step: 990, loss: 0.018230626359581947
step: 1000, loss: 6.0529135225806385e-05
step: 1010, loss: 2.193775071646087e-05
step: 1020, loss: 0.09746745973825455
step: 1030, loss: 0.013304628431797028
step: 1040, loss: 0.04586496949195862
step: 1050, loss: 0.014378099702298641
step: 1060, loss: 0.0005304765654727817
step: 1070, loss: 0.020031942054629326
epoch 19: dev_f1=0.9302325581395349, f1=0.9340148698884759, best_f1=0.9388322520852641
step: 0, loss: 0.024668985977768898
step: 10, loss: 4.2620438762241974e-05
step: 20, loss: 0.017003897577524185
step: 30, loss: 0.00029985306900925934
step: 40, loss: 8.236724534071982e-05
step: 50, loss: 1.5500641893595457e-05
step: 60, loss: 0.020627178251743317
step: 70, loss: 0.0001897383772302419
step: 80, loss: 0.04596313089132309
step: 90, loss: 0.0002654897980391979
step: 100, loss: 0.0595364049077034
step: 110, loss: 0.03822437673807144
step: 120, loss: 0.07279036939144135
step: 130, loss: 1.2758799130097032e-05
step: 140, loss: 0.008648843504488468
step: 150, loss: 0.02200670726597309
step: 160, loss: 1.2918785614601802e-05
step: 170, loss: 0.0007900844793766737
step: 180, loss: 0.04022756963968277
step: 190, loss: 0.019370896741747856
step: 200, loss: 0.02931193821132183
step: 210, loss: 0.010696901008486748
step: 220, loss: 0.05655577778816223
step: 230, loss: 0.00035083299735561013
step: 240, loss: 0.022959362715482712
step: 250, loss: 0.02390008233487606
step: 260, loss: 4.087933120899834e-05
step: 270, loss: 0.019496362656354904
step: 280, loss: 0.03920634090900421
step: 290, loss: 0.0016054881270974874
step: 300, loss: 0.021618204191327095
step: 310, loss: 0.06641768664121628
step: 320, loss: 0.05306236445903778
step: 330, loss: 0.0008047025185078382
step: 340, loss: 0.04867520183324814
step: 350, loss: 0.018625490367412567
step: 360, loss: 1.5053629795147572e-05
step: 370, loss: 0.05592254549264908
step: 380, loss: 0.038585372269153595
step: 390, loss: 2.4984043193398975e-05
step: 400, loss: 0.022755814716219902
step: 410, loss: 0.05196090787649155
step: 420, loss: 0.02291778475046158
step: 430, loss: 0.0225937869399786
step: 440, loss: 0.008124561980366707
step: 450, loss: 0.027181651443243027
step: 460, loss: 0.0005170072545297444
step: 470, loss: 0.032525066286325455
step: 480, loss: 9.939113806467503e-05
step: 490, loss: 0.01342221349477768
step: 500, loss: 0.01675584726035595
step: 510, loss: 0.04640055075287819
step: 520, loss: 3.330555045977235e-05
step: 530, loss: 0.05985172465443611
step: 540, loss: 0.06145927309989929
step: 550, loss: 0.03274857625365257
step: 560, loss: 4.189824539935216e-05
step: 570, loss: 0.06695093959569931
step: 580, loss: 0.0019641746766865253
step: 590, loss: 0.05962204560637474
step: 600, loss: 0.03742285817861557
step: 610, loss: 0.07086451351642609
step: 620, loss: 0.0021317179780453444
step: 630, loss: 0.06948050111532211
step: 640, loss: 0.0001410745462635532
step: 650, loss: 0.018480563536286354
step: 660, loss: 0.06331406533718109
step: 670, loss: 0.018380487337708473
step: 680, loss: 0.027838710695505142
step: 690, loss: 0.03478250652551651
step: 700, loss: 0.04221310839056969
step: 710, loss: 0.003391495905816555
step: 720, loss: 0.04395608231425285
step: 730, loss: 0.0002145199105143547
step: 740, loss: 0.0002563378948252648
step: 750, loss: 2.4993132683448493e-05
step: 760, loss: 0.02152508683502674
step: 770, loss: 0.06217683106660843
step: 780, loss: 1.1164546776853967e-05
step: 790, loss: 0.024727920070290565
step: 800, loss: 8.583016096963547e-06
step: 810, loss: 1.3689946172235068e-05
step: 820, loss: 0.06032189354300499
step: 830, loss: 0.024440914392471313
step: 840, loss: 2.3452048480976373e-05
step: 850, loss: 0.03760494664311409
step: 860, loss: 0.024410901591181755
step: 870, loss: 0.0001017163012875244
step: 880, loss: 8.457387593807653e-05
step: 890, loss: 0.05348668247461319
step: 900, loss: 5.5586398957530037e-05
step: 910, loss: 7.33632841729559e-05
step: 920, loss: 0.043181803077459335
step: 930, loss: 0.017056627199053764
step: 940, loss: 0.021237526088953018
step: 950, loss: 0.020759792998433113
step: 960, loss: 0.002137641189619899
step: 970, loss: 0.021996989846229553
step: 980, loss: 0.0007403100025840104
step: 990, loss: 3.641150033217855e-05
step: 1000, loss: 3.694583574542776e-05
step: 1010, loss: 0.02347290702164173
step: 1020, loss: 0.0025843570474535227
step: 1030, loss: 3.0994713597465307e-05
step: 1040, loss: 2.4216420570155606e-05
step: 1050, loss: 0.02656453289091587
step: 1060, loss: 0.02725685015320778
step: 1070, loss: 0.022251620888710022
epoch 20: dev_f1=0.9287037037037037, f1=0.9313047487321346, best_f1=0.9388322520852641
