cuda
Device: cuda
step: 0, loss: 0.7882494330406189
step: 10, loss: 0.5783082842826843
step: 20, loss: 0.6107949018478394
step: 30, loss: 0.5848789811134338
step: 40, loss: 0.5329645872116089
step: 50, loss: 0.3339683413505554
step: 60, loss: 0.5159583687782288
step: 70, loss: 0.4825277626514435
step: 80, loss: 0.3864191770553589
step: 90, loss: 0.32782623171806335
step: 100, loss: 0.17528168857097626
step: 110, loss: 0.1821531057357788
step: 120, loss: 0.10140898823738098
step: 130, loss: 0.1391526162624359
step: 140, loss: 0.10846015065908432
step: 150, loss: 0.4219130873680115
step: 160, loss: 0.1660775989294052
step: 170, loss: 0.20232464373111725
step: 180, loss: 0.10249491035938263
step: 190, loss: 0.12007975578308105
step: 200, loss: 0.03390420600771904
step: 210, loss: 0.04328155145049095
step: 220, loss: 0.04571111127734184
step: 230, loss: 0.08252979815006256
step: 240, loss: 0.04498890042304993
step: 250, loss: 0.10374187678098679
step: 260, loss: 0.005808047018945217
step: 270, loss: 0.057491470128297806
epoch 1: dev_f1=0.9680968096809681, f1=0.9765363128491621, best_f1=0.9765363128491621
step: 0, loss: 0.07055835425853729
step: 10, loss: 0.012334578670561314
step: 20, loss: 0.06337154656648636
step: 30, loss: 0.044792626053094864
step: 40, loss: 0.09350333362817764
step: 50, loss: 0.0456862635910511
step: 60, loss: 0.022241048514842987
step: 70, loss: 0.04245462268590927
step: 80, loss: 0.15360592305660248
step: 90, loss: 0.009374851360917091
step: 100, loss: 0.09710509330034256
step: 110, loss: 0.01823926717042923
step: 120, loss: 0.4174838364124298
step: 130, loss: 0.004954015836119652
step: 140, loss: 0.04011004790663719
step: 150, loss: 0.006480447016656399
step: 160, loss: 0.1022912859916687
step: 170, loss: 0.053616080433130264
step: 180, loss: 0.06387556344270706
step: 190, loss: 0.006659925449639559
step: 200, loss: 0.17754405736923218
step: 210, loss: 0.0042445966973900795
step: 220, loss: 0.1674688756465912
step: 230, loss: 0.030611345544457436
step: 240, loss: 0.03466731682419777
step: 250, loss: 0.037225428968667984
step: 260, loss: 0.11622495949268341
step: 270, loss: 0.017547592520713806
epoch 2: dev_f1=0.9788182831661093, f1=0.9797752808988766, best_f1=0.9797752808988766
step: 0, loss: 0.0072552780620753765
step: 10, loss: 0.12193597108125687
step: 20, loss: 0.033664628863334656
step: 30, loss: 0.007787865120917559
step: 40, loss: 0.0067877015098929405
step: 50, loss: 0.024166839197278023
step: 60, loss: 0.026553906500339508
step: 70, loss: 0.026445824652910233
step: 80, loss: 0.0773153007030487
step: 90, loss: 0.006616451311856508
step: 100, loss: 0.0804048404097557
step: 110, loss: 0.0018706296104937792
step: 120, loss: 0.0034577427431941032
step: 130, loss: 0.014695543795824051
step: 140, loss: 0.00557488389313221
step: 150, loss: 0.002810609294101596
step: 160, loss: 0.0006376111414283514
step: 170, loss: 0.008038962259888649
step: 180, loss: 0.002446308033540845
step: 190, loss: 0.003068903461098671
step: 200, loss: 0.03745448216795921
step: 210, loss: 0.0032123641576617956
step: 220, loss: 0.004446354694664478
step: 230, loss: 0.0018307561986148357
step: 240, loss: 0.0030140860471874475
step: 250, loss: 0.006308439187705517
step: 260, loss: 0.0008003425318747759
step: 270, loss: 0.0019325129687786102
epoch 3: dev_f1=0.9799107142857142, f1=0.9785310734463276, best_f1=0.9785310734463276
step: 0, loss: 0.16336531937122345
step: 10, loss: 0.026855511590838432
step: 20, loss: 0.2535456418991089
step: 30, loss: 0.01619216986000538
step: 40, loss: 0.04368293657898903
step: 50, loss: 0.005016434472054243
step: 60, loss: 0.08662243187427521
step: 70, loss: 0.0028557342011481524
step: 80, loss: 0.0010339233558624983
step: 90, loss: 0.0018274381291121244
step: 100, loss: 0.003717199433594942
step: 110, loss: 0.0014617755077779293
step: 120, loss: 0.0013124841498211026
step: 130, loss: 0.09843632578849792
step: 140, loss: 0.002333893673494458
step: 150, loss: 0.0009062968892976642
step: 160, loss: 0.0013431679690256715
step: 170, loss: 0.0053741056472063065
step: 180, loss: 0.0019304113229736686
step: 190, loss: 0.0022412806283682585
step: 200, loss: 0.00439935177564621
step: 210, loss: 0.0030622079502791166
step: 220, loss: 0.01576891355216503
step: 230, loss: 0.00422340352088213
step: 240, loss: 0.019321536645293236
step: 250, loss: 0.015525811351835728
step: 260, loss: 0.015380597673356533
step: 270, loss: 0.0016856408910825849
epoch 4: dev_f1=0.9842342342342343, f1=0.9807909604519773, best_f1=0.9807909604519773
step: 0, loss: 0.0050073591992259026
step: 10, loss: 0.004216480068862438
step: 20, loss: 0.00773579441010952
step: 30, loss: 0.0010206899605691433
step: 40, loss: 0.03825655207037926
step: 50, loss: 0.003210702445358038
step: 60, loss: 0.009580451995134354
step: 70, loss: 0.001487511326558888
step: 80, loss: 0.012088725343346596
step: 90, loss: 0.06629685312509537
step: 100, loss: 0.0012473375536501408
step: 110, loss: 0.007423238828778267
step: 120, loss: 0.001221093931235373
step: 130, loss: 0.03645537421107292
step: 140, loss: 0.03160328418016434
step: 150, loss: 0.002445090329274535
step: 160, loss: 0.0012287602294236422
step: 170, loss: 0.0020032136235386133
step: 180, loss: 0.003717967774719
step: 190, loss: 0.001674594939686358
step: 200, loss: 0.0286848247051239
step: 210, loss: 0.08424454182386398
step: 220, loss: 0.008013231679797173
step: 230, loss: 0.04747839272022247
step: 240, loss: 0.011827822774648666
step: 250, loss: 0.00953974761068821
step: 260, loss: 0.012550576590001583
step: 270, loss: 0.004043946973979473
epoch 5: dev_f1=0.987709497206704, f1=0.9832026875699889, best_f1=0.9832026875699889
step: 0, loss: 0.002556050894781947
step: 10, loss: 0.01578366942703724
step: 20, loss: 0.00241939933039248
step: 30, loss: 0.022126544266939163
step: 40, loss: 0.00782779324799776
step: 50, loss: 0.009655618108808994
step: 60, loss: 0.015950031578540802
step: 70, loss: 0.0015524260234087706
step: 80, loss: 0.0018903922755271196
step: 90, loss: 0.10744694620370865
step: 100, loss: 0.0029015312902629375
step: 110, loss: 0.002707181964069605
step: 120, loss: 0.001153025310486555
step: 130, loss: 0.008932631462812424
step: 140, loss: 0.004433879163116217
step: 150, loss: 0.0018755878554657102
step: 160, loss: 0.10651107877492905
step: 170, loss: 0.0024136025458574295
step: 180, loss: 0.0004883244982920587
step: 190, loss: 0.0008669626549817622
step: 200, loss: 0.0005195784033276141
step: 210, loss: 0.0018665211973711848
step: 220, loss: 0.005309947766363621
step: 230, loss: 0.003996310289949179
step: 240, loss: 0.009437796659767628
step: 250, loss: 0.0005820844089612365
step: 260, loss: 0.0017771837301552296
step: 270, loss: 0.0011328599648550153
epoch 6: dev_f1=0.9728506787330317, f1=0.976324689966178, best_f1=0.9832026875699889
step: 0, loss: 0.004622254520654678
step: 10, loss: 0.0008089834591373801
step: 20, loss: 0.0006333807250484824
step: 30, loss: 0.001213190727867186
step: 40, loss: 0.002104206243529916
step: 50, loss: 0.0018419221742078662
step: 60, loss: 0.0007982539245858788
step: 70, loss: 0.0007121445960365236
step: 80, loss: 0.0009960532188415527
step: 90, loss: 0.002464492106810212
step: 100, loss: 0.00047456054016947746
step: 110, loss: 0.00043853791430592537
step: 120, loss: 0.0013782415771856904
step: 130, loss: 0.004223758354783058
step: 140, loss: 0.0013022746425122023
step: 150, loss: 0.0006689547444693744
step: 160, loss: 0.0013102733064442873
step: 170, loss: 0.0004174102214165032
step: 180, loss: 0.00030869964393787086
step: 190, loss: 0.001589868450537324
step: 200, loss: 0.0008841452654451132
step: 210, loss: 0.17980554699897766
step: 220, loss: 0.003648576559498906
step: 230, loss: 0.0006958763115108013
step: 240, loss: 0.0011480000102892518
step: 250, loss: 0.00794160459190607
step: 260, loss: 0.0725095197558403
step: 270, loss: 0.015108318999409676
epoch 7: dev_f1=0.9732739420935412, f1=0.9744160177975528, best_f1=0.9832026875699889
step: 0, loss: 0.013907905668020248
step: 10, loss: 0.0017460890812799335
step: 20, loss: 0.0006561029586009681
step: 30, loss: 0.0035617088433355093
step: 40, loss: 0.006215777713805437
step: 50, loss: 0.004257807508111
step: 60, loss: 0.0027606976218521595
step: 70, loss: 0.003322397591546178
step: 80, loss: 0.0026536223012953997
step: 90, loss: 0.0006870192592032254
step: 100, loss: 0.0003986816154792905
step: 110, loss: 0.0007725860341452062
step: 120, loss: 0.0005156396655365825
step: 130, loss: 0.022756854072213173
step: 140, loss: 0.01836802251636982
step: 150, loss: 0.0006915702833794057
step: 160, loss: 0.009854013100266457
step: 170, loss: 0.001168753718957305
step: 180, loss: 0.005899912677705288
step: 190, loss: 0.0010735035175457597
step: 200, loss: 0.0008142972365021706
step: 210, loss: 0.001460381201468408
step: 220, loss: 0.0009516171412542462
step: 230, loss: 0.0009529005037620664
step: 240, loss: 0.0012561287730932236
step: 250, loss: 0.001345330965705216
step: 260, loss: 0.0016735971439629793
step: 270, loss: 0.000719367410056293
epoch 8: dev_f1=0.9865771812080537, f1=0.9876819708846584, best_f1=0.9832026875699889
step: 0, loss: 0.0008691327529959381
step: 10, loss: 0.0011662064353004098
step: 20, loss: 0.0002534932573325932
step: 30, loss: 0.000512747501488775
step: 40, loss: 0.12810324132442474
step: 50, loss: 0.0005348247941583395
step: 60, loss: 0.0064390976913273335
step: 70, loss: 0.11525560915470123
step: 80, loss: 0.014773078262805939
step: 90, loss: 0.002410145476460457
step: 100, loss: 0.0002467534504830837
step: 110, loss: 0.00020900333765894175
step: 120, loss: 0.00022220882237888873
step: 130, loss: 0.0004802189359907061
step: 140, loss: 0.011151808314025402
step: 150, loss: 0.001357478671707213
step: 160, loss: 0.00037983767106197774
step: 170, loss: 0.00017190341895911843
step: 180, loss: 0.00026867949054576457
step: 190, loss: 0.00045187256182543933
step: 200, loss: 0.00028753301012329757
step: 210, loss: 0.09985616058111191
step: 220, loss: 0.0015286272391676903
step: 230, loss: 0.00044179215910844505
step: 240, loss: 0.0006543761701323092
step: 250, loss: 0.0048171766102313995
step: 260, loss: 0.0010249112965539098
step: 270, loss: 0.0022443656343966722
epoch 9: dev_f1=0.9755011135857461, f1=0.9765886287625419, best_f1=0.9832026875699889
step: 0, loss: 0.0005045231082476676
step: 10, loss: 0.00181615783367306
step: 20, loss: 0.0013489284319803119
step: 30, loss: 0.0016280453419312835
step: 40, loss: 0.0009795192163437605
step: 50, loss: 0.0003711101890075952
step: 60, loss: 0.0003970770922023803
step: 70, loss: 0.0005507530877366662
step: 80, loss: 0.0006718583172187209
step: 90, loss: 0.0002059421531157568
step: 100, loss: 0.0003332757332827896
step: 110, loss: 0.001398246269673109
step: 120, loss: 0.0010694272350519896
step: 130, loss: 0.005010536871850491
step: 140, loss: 0.0007198757375590503
step: 150, loss: 0.00035410470445640385
step: 160, loss: 0.0018472338560968637
step: 170, loss: 0.0012643756344914436
step: 180, loss: 0.00012694673205260187
step: 190, loss: 0.0007198519306257367
step: 200, loss: 0.008026182651519775
step: 210, loss: 0.027689067646861076
step: 220, loss: 0.0004774929257109761
step: 230, loss: 0.0002151619119103998
step: 240, loss: 0.0001877611066447571
step: 250, loss: 0.00032923041726462543
step: 260, loss: 0.0003100098401773721
step: 270, loss: 0.005482037086039782
epoch 10: dev_f1=0.9819819819819819, f1=0.9842342342342343, best_f1=0.9832026875699889
step: 0, loss: 0.00017276052676606923
step: 10, loss: 0.013326448388397694
step: 20, loss: 0.00016200132085941732
step: 30, loss: 0.0007377908914349973
step: 40, loss: 0.00022915107547305524
step: 50, loss: 0.0004530917794909328
step: 60, loss: 0.012490939348936081
step: 70, loss: 0.0004565934941638261
step: 80, loss: 0.00018735699995886534
step: 90, loss: 0.00010754874529084191
step: 100, loss: 0.0012743417173624039
step: 110, loss: 0.00028057736926712096
step: 120, loss: 0.0005041008116677403
step: 130, loss: 0.00031051645055413246
step: 140, loss: 0.03056642971932888
step: 150, loss: 0.000130468572024256
step: 160, loss: 0.0004770214145537466
step: 170, loss: 0.00019522124784998596
step: 180, loss: 0.12912395596504211
step: 190, loss: 0.011074231937527657
step: 200, loss: 0.008894308470189571
step: 210, loss: 0.003549395827576518
step: 220, loss: 0.017554614692926407
step: 230, loss: 0.0001849797263275832
step: 240, loss: 0.0013980877120047808
step: 250, loss: 0.0003435923426877707
step: 260, loss: 0.00038613079232163727
step: 270, loss: 0.00047956520575098693
epoch 11: dev_f1=0.9843400447427293, f1=0.9821428571428571, best_f1=0.9832026875699889
step: 0, loss: 0.0003884125908371061
step: 10, loss: 0.003085632110014558
step: 20, loss: 0.00036298547638580203
step: 30, loss: 0.00020958871755283326
step: 40, loss: 0.0014542374992743134
step: 50, loss: 0.00028225971618667245
step: 60, loss: 0.024712560698390007
step: 70, loss: 0.0007134092156775296
step: 80, loss: 0.0008302805945277214
step: 90, loss: 0.00031005358323454857
step: 100, loss: 0.0011044348357245326
step: 110, loss: 0.00011989619088126346
step: 120, loss: 0.00023101786791812629
step: 130, loss: 0.013375911861658096
step: 140, loss: 0.0008641784661449492
step: 150, loss: 0.00022868621454108506
step: 160, loss: 0.00013356571434997022
step: 170, loss: 0.00012721461826004088
step: 180, loss: 9.832805517362431e-05
step: 190, loss: 0.0001344620977761224
step: 200, loss: 0.00012578319001477212
step: 210, loss: 9.247218258678913e-05
step: 220, loss: 0.03498000279068947
step: 230, loss: 0.0012992400443181396
step: 240, loss: 0.00013998718350194395
step: 250, loss: 0.00020571092318277806
step: 260, loss: 0.0015352084301412106
step: 270, loss: 0.00024899959680624306
epoch 12: dev_f1=0.9776785714285714, f1=0.983277591973244, best_f1=0.9832026875699889
step: 0, loss: 0.001561227603815496
step: 10, loss: 0.0005953327636234462
step: 20, loss: 0.0004005644586868584
step: 30, loss: 0.00010429133544676006
step: 40, loss: 9.690843580756336e-05
step: 50, loss: 0.0003692285972647369
step: 60, loss: 0.1192634329199791
step: 70, loss: 0.009553101845085621
step: 80, loss: 0.00011710999388014898
step: 90, loss: 0.0003733903868123889
step: 100, loss: 0.00173766422085464
step: 110, loss: 0.0004429282562341541
step: 120, loss: 0.0002751990396063775
step: 130, loss: 0.0001439916086383164
step: 140, loss: 0.000525430659763515
step: 150, loss: 0.00012412825890351087
step: 160, loss: 0.00016309402417391539
step: 170, loss: 0.00017472158651798964
step: 180, loss: 0.0005051996558904648
step: 190, loss: 0.00018274964531883597
step: 200, loss: 0.00016399957530666143
step: 210, loss: 0.0011224690824747086
step: 220, loss: 0.15533873438835144
step: 230, loss: 0.04784470051527023
step: 240, loss: 0.0008694123825989664
step: 250, loss: 0.033635787665843964
step: 260, loss: 0.004775737412273884
step: 270, loss: 0.00025885843206197023
epoch 13: dev_f1=0.9875706214689265, f1=0.9831271091113611, best_f1=0.9832026875699889
step: 0, loss: 0.003514661453664303
step: 10, loss: 0.0002748487750068307
step: 20, loss: 0.0016162225510925055
step: 30, loss: 0.0007441613706760108
step: 40, loss: 0.00046767506864853203
step: 50, loss: 0.006095005664974451
step: 60, loss: 0.00020673018298111856
step: 70, loss: 0.0013864003121852875
step: 80, loss: 0.00012835548841394484
step: 90, loss: 0.0003175876918248832
step: 100, loss: 0.00011445318523328751
step: 110, loss: 0.00459707947447896
step: 120, loss: 0.00020438095089048147
step: 130, loss: 0.00014706903311889619
step: 140, loss: 0.004392002709209919
step: 150, loss: 0.00016476375458296388
step: 160, loss: 0.0002137716655852273
step: 170, loss: 0.001277684117667377
step: 180, loss: 7.785052730469033e-05
step: 190, loss: 0.031027432531118393
step: 200, loss: 0.00015220891509670764
step: 210, loss: 0.0008548932964913547
step: 220, loss: 9.46933141676709e-05
step: 230, loss: 0.00016664991562720388
step: 240, loss: 0.0012591049307957292
step: 250, loss: 8.371805597562343e-05
step: 260, loss: 0.0021590187679976225
step: 270, loss: 0.00011712554260157049
epoch 14: dev_f1=0.9819413092550789, f1=0.9865168539325843, best_f1=0.9832026875699889
step: 0, loss: 0.00013970708823762834
step: 10, loss: 0.00012777309166267514
step: 20, loss: 8.455167699139565e-05
step: 30, loss: 8.83846078068018e-05
step: 40, loss: 0.001151243457570672
step: 50, loss: 0.0003490789677016437
step: 60, loss: 0.00503340782597661
step: 70, loss: 0.00030134967528283596
step: 80, loss: 0.0002463791170157492
step: 90, loss: 8.534196967957541e-05
step: 100, loss: 0.00010469539847690612
step: 110, loss: 0.00019433813577052206
step: 120, loss: 0.00020834528550039977
step: 130, loss: 0.0007370556122623384
step: 140, loss: 0.0007859127945266664
step: 150, loss: 0.00025912417913787067
step: 160, loss: 0.00024398982350248843
step: 170, loss: 0.00013480058987624943
step: 180, loss: 0.00038165898877196014
step: 190, loss: 0.0007296891999430954
step: 200, loss: 0.016481976956129074
step: 210, loss: 0.03824732080101967
step: 220, loss: 0.00021474792447406799
step: 230, loss: 0.00011665179772535339
step: 240, loss: 0.0007618705276399851
step: 250, loss: 0.00016233250789809972
step: 260, loss: 0.004328438546508551
step: 270, loss: 0.013704400509595871
epoch 15: dev_f1=0.9852440408626559, f1=0.9841628959276018, best_f1=0.9832026875699889
step: 0, loss: 6.868005584692582e-05
step: 10, loss: 0.005105448886752129
step: 20, loss: 0.00015580766194034368
step: 30, loss: 0.00010293741797795519
step: 40, loss: 0.0002926199813373387
step: 50, loss: 5.7131164794554934e-05
step: 60, loss: 9.941656026057899e-05
step: 70, loss: 0.0001440127962268889
step: 80, loss: 0.02969016134738922
step: 90, loss: 0.00010907043906627223
step: 100, loss: 0.00015124425408430398
step: 110, loss: 0.0071569038555026054
step: 120, loss: 0.0030511277727782726
step: 130, loss: 0.00043110590195283294
step: 140, loss: 0.00031962967477738857
step: 150, loss: 0.00014535142690874636
step: 160, loss: 0.0001099809305742383
step: 170, loss: 9.533437696518376e-05
step: 180, loss: 0.00039369845762848854
step: 190, loss: 4.197317684884183e-05
step: 200, loss: 0.00032045214902609587
step: 210, loss: 0.00015793055354151875
step: 220, loss: 7.563401595689356e-05
step: 230, loss: 0.00011907409498235211
step: 240, loss: 0.00010922540968749672
step: 250, loss: 0.00043829239439219236
step: 260, loss: 0.00011653158435365185
step: 270, loss: 5.193817560211755e-05
epoch 16: dev_f1=0.9854423292273236, f1=0.9767441860465117, best_f1=0.9832026875699889
step: 0, loss: 0.013040594756603241
step: 10, loss: 8.53108722367324e-05
step: 20, loss: 0.00012611565762199461
step: 30, loss: 0.01194905024021864
step: 40, loss: 7.303859456442297e-05
step: 50, loss: 4.000032276962884e-05
step: 60, loss: 0.004383993335068226
step: 70, loss: 5.8434590755496174e-05
step: 80, loss: 0.00015226632240228355
step: 90, loss: 0.00010579160880297422
step: 100, loss: 0.00013018261233810335
step: 110, loss: 6.469806976383552e-05
step: 120, loss: 5.144252645550296e-05
step: 130, loss: 6.110406684456393e-05
step: 140, loss: 8.365507528651506e-05
step: 150, loss: 6.774902431061491e-05
step: 160, loss: 5.2709467126987875e-05
step: 170, loss: 4.794237975147553e-05
step: 180, loss: 7.62681956985034e-05
step: 190, loss: 5.899934330955148e-05
step: 200, loss: 9.747348667588085e-05
step: 210, loss: 0.00041294153197668493
step: 220, loss: 7.05948332324624e-05
step: 230, loss: 0.0002498803660273552
step: 240, loss: 0.0018043830059468746
step: 250, loss: 7.106568227754906e-05
step: 260, loss: 5.9879992477362975e-05
step: 270, loss: 5.31974365003407e-05
epoch 17: dev_f1=0.9898989898989898, f1=0.9788182831661093, best_f1=0.9788182831661093
step: 0, loss: 0.017513630911707878
step: 10, loss: 9.126936492975801e-05
step: 20, loss: 0.00015225919196382165
step: 30, loss: 0.0003632329753600061
step: 40, loss: 0.0001455222227377817
step: 50, loss: 4.901434658677317e-05
step: 60, loss: 5.063534263172187e-05
step: 70, loss: 0.0001206521992571652
step: 80, loss: 0.0001528111897641793
step: 90, loss: 0.0028466018848121166
step: 100, loss: 0.00017214413674082607
step: 110, loss: 8.297878957819194e-05
step: 120, loss: 0.00011006571730831638
step: 130, loss: 9.752821642905474e-05
step: 140, loss: 0.00010860466136364266
step: 150, loss: 0.00017181364819407463
step: 160, loss: 0.02468741685152054
step: 170, loss: 4.048109985888004e-05
step: 180, loss: 0.0007931471336632967
step: 190, loss: 8.48628842504695e-05
step: 200, loss: 6.253465835470706e-05
step: 210, loss: 0.04953140765428543
step: 220, loss: 5.352209336706437e-05
step: 230, loss: 0.0008819290087558329
step: 240, loss: 4.9632864829618484e-05
step: 250, loss: 0.0005021565593779087
step: 260, loss: 9.54428396653384e-05
step: 270, loss: 0.00020392806618474424
epoch 18: dev_f1=0.9898534385569334, f1=0.9842696629213483, best_f1=0.9788182831661093
step: 0, loss: 6.15157769061625e-05
step: 10, loss: 4.88435362058226e-05
step: 20, loss: 4.700957651948556e-05
step: 30, loss: 4.170629472355358e-05
step: 40, loss: 4.724434984382242e-05
step: 50, loss: 5.183470420888625e-05
step: 60, loss: 5.64270158065483e-05
step: 70, loss: 3.948635276174173e-05
step: 80, loss: 0.00016142001550178975
step: 90, loss: 0.00011263912892900407
step: 100, loss: 2.7257357942289673e-05
step: 110, loss: 7.87757890066132e-05
step: 120, loss: 6.471455708378926e-05
step: 130, loss: 7.757165440125391e-05
step: 140, loss: 2.2932474166736938e-05
step: 150, loss: 4.09804233640898e-05
step: 160, loss: 0.010845915414392948
step: 170, loss: 0.0016543357633054256
step: 180, loss: 0.0002960195124614984
step: 190, loss: 0.0001795506541384384
step: 200, loss: 4.460048512555659e-05
step: 210, loss: 0.0006029055803082883
step: 220, loss: 0.00010579053196124732
step: 230, loss: 0.000355073920218274
step: 240, loss: 5.66769449505955e-05
step: 250, loss: 3.5247641790192574e-05
step: 260, loss: 5.815667464048602e-05
step: 270, loss: 4.0215407352661714e-05
epoch 19: dev_f1=0.9898534385569334, f1=0.9821029082774049, best_f1=0.9788182831661093
step: 0, loss: 0.0013994555920362473
step: 10, loss: 4.407571395859122e-05
step: 20, loss: 8.412938768742606e-05
step: 30, loss: 4.8120749852387235e-05
step: 40, loss: 0.00016470858827233315
step: 50, loss: 4.608840026776306e-05
step: 60, loss: 0.00026979375979863107
step: 70, loss: 4.743841782328673e-05
step: 80, loss: 3.852873487630859e-05
step: 90, loss: 0.00017132687207777053
step: 100, loss: 6.023274181643501e-05
step: 110, loss: 6.9443580287043e-05
step: 120, loss: 3.5585810110205784e-05
step: 130, loss: 0.00010202334669884294
step: 140, loss: 5.59310065000318e-05
step: 150, loss: 5.274619979900308e-05
step: 160, loss: 4.063381493324414e-05
step: 170, loss: 3.1604180549038574e-05
step: 180, loss: 8.877654909156263e-05
step: 190, loss: 3.773932621697895e-05
step: 200, loss: 3.3142736356239766e-05
step: 210, loss: 0.00010925699461949989
step: 220, loss: 5.8181369240628555e-05
step: 230, loss: 4.089046342414804e-05
step: 240, loss: 0.0016181429382413626
step: 250, loss: 0.01279562246054411
step: 260, loss: 4.076000186614692e-05
step: 270, loss: 4.553745384328067e-05
epoch 20: dev_f1=0.9887133182844244, f1=0.9831649831649831, best_f1=0.9788182831661093
