cuda
Device: cuda
step: 0, loss: 0.6474010348320007
step: 10, loss: 0.6134059429168701
step: 20, loss: 0.494907408952713
step: 30, loss: 0.41327136754989624
step: 40, loss: 0.529224693775177
step: 50, loss: 0.3624873161315918
step: 60, loss: 0.2143678516149521
step: 70, loss: 0.19320496916770935
step: 80, loss: 0.2208167463541031
step: 90, loss: 0.13941653072834015
step: 100, loss: 0.21148596704006195
step: 110, loss: 0.27892330288887024
step: 120, loss: 0.07683152705430984
step: 130, loss: 0.4431677460670471
step: 140, loss: 0.09976127743721008
step: 150, loss: 0.2804337739944458
step: 160, loss: 0.2069287896156311
step: 170, loss: 0.08542975038290024
step: 180, loss: 0.3406970798969269
step: 190, loss: 0.13779594004154205
step: 200, loss: 0.2317313253879547
step: 210, loss: 0.12767687439918518
step: 220, loss: 0.08020900189876556
step: 230, loss: 0.0746324434876442
step: 240, loss: 0.05975722894072533
step: 250, loss: 0.07323635369539261
step: 260, loss: 0.10643276572227478
step: 270, loss: 0.14599163830280304
epoch 1: dev_f1=0.9809203142536477, f1=0.9784824462061155, best_f1=0.9784824462061155
step: 0, loss: 0.08680562674999237
step: 10, loss: 0.05017310008406639
step: 20, loss: 0.02355566807091236
step: 30, loss: 0.02418898046016693
step: 40, loss: 0.005569242872297764
step: 50, loss: 0.06732949614524841
step: 60, loss: 0.009884171187877655
step: 70, loss: 0.12515655159950256
step: 80, loss: 0.14781059324741364
step: 90, loss: 0.027165833860635757
step: 100, loss: 0.27359896898269653
step: 110, loss: 0.005939375143498182
step: 120, loss: 0.01008978858590126
step: 130, loss: 0.005525646265596151
step: 140, loss: 0.11556923389434814
step: 150, loss: 0.1061713770031929
step: 160, loss: 0.08004552870988846
step: 170, loss: 0.015267147682607174
step: 180, loss: 0.09951037913560867
step: 190, loss: 0.006283868104219437
step: 200, loss: 0.08744709193706512
step: 210, loss: 0.010162084363400936
step: 220, loss: 0.01989228092133999
step: 230, loss: 0.026603922247886658
step: 240, loss: 0.1299525499343872
step: 250, loss: 0.029438205063343048
step: 260, loss: 0.09367624670267105
step: 270, loss: 0.10106463730335236
epoch 2: dev_f1=0.9822222222222222, f1=0.9788182831661093, best_f1=0.9788182831661093
step: 0, loss: 0.04395079240202904
step: 10, loss: 0.11864212155342102
step: 20, loss: 0.017761794850230217
step: 30, loss: 0.1868828535079956
step: 40, loss: 0.005290900822728872
step: 50, loss: 0.007606653030961752
step: 60, loss: 0.006489171646535397
step: 70, loss: 0.0029564322903752327
step: 80, loss: 0.36831867694854736
step: 90, loss: 0.03885859251022339
step: 100, loss: 0.08086894452571869
step: 110, loss: 0.05215835943818092
step: 120, loss: 0.007134946528822184
step: 130, loss: 0.003008020343258977
step: 140, loss: 0.000995488022454083
step: 150, loss: 0.04413147643208504
step: 160, loss: 0.035576093941926956
step: 170, loss: 0.18423020839691162
step: 180, loss: 0.04806168004870415
step: 190, loss: 0.05107489973306656
step: 200, loss: 0.01796102151274681
step: 210, loss: 0.0034746977034956217
step: 220, loss: 0.0014766217209398746
step: 230, loss: 0.016759799793362617
step: 240, loss: 0.006027217488735914
step: 250, loss: 0.04877060651779175
step: 260, loss: 0.05602730065584183
step: 270, loss: 0.0022779391147196293
epoch 3: dev_f1=0.9853438556933484, f1=0.9841986455981941, best_f1=0.9841986455981941
step: 0, loss: 0.020897679030895233
step: 10, loss: 0.010364996269345284
step: 20, loss: 0.01497596874833107
step: 30, loss: 0.0010693466756492853
step: 40, loss: 0.003305413294583559
step: 50, loss: 0.08181324601173401
step: 60, loss: 0.003197031794115901
step: 70, loss: 0.0036958283744752407
step: 80, loss: 0.0034844924230128527
step: 90, loss: 0.007070835214108229
step: 100, loss: 0.004006467293947935
step: 110, loss: 0.0024929794017225504
step: 120, loss: 0.09027627110481262
step: 130, loss: 0.002703743986785412
step: 140, loss: 0.0022385078482329845
step: 150, loss: 0.000960766919888556
step: 160, loss: 0.0007018899777904153
step: 170, loss: 0.003991628065705299
step: 180, loss: 0.010039659217000008
step: 190, loss: 0.0722307488322258
step: 200, loss: 0.18258145451545715
step: 210, loss: 0.011304862797260284
step: 220, loss: 0.004016142338514328
step: 230, loss: 0.002973403548821807
step: 240, loss: 0.012441925704479218
step: 250, loss: 0.03550073131918907
step: 260, loss: 0.007979340851306915
step: 270, loss: 0.0015022921143099666
epoch 4: dev_f1=0.9876543209876544, f1=0.9842696629213483, best_f1=0.9842696629213483
step: 0, loss: 0.0009632773580960929
step: 10, loss: 0.008867807686328888
step: 20, loss: 0.0005360116483643651
step: 30, loss: 0.005152715370059013
step: 40, loss: 0.0012044457253068686
step: 50, loss: 0.00038477484486065805
step: 60, loss: 0.052505973726511
step: 70, loss: 0.0010603441623970866
step: 80, loss: 0.0005749387200921774
step: 90, loss: 0.06710021942853928
step: 100, loss: 0.000472590938443318
step: 110, loss: 0.000811288773547858
step: 120, loss: 0.003144635818898678
step: 130, loss: 0.01313360407948494
step: 140, loss: 0.0025463025085628033
step: 150, loss: 0.17026387155056
step: 160, loss: 0.00676086125895381
step: 170, loss: 0.003379529109224677
step: 180, loss: 0.001985455397516489
step: 190, loss: 0.14430148899555206
step: 200, loss: 0.002826167969033122
step: 210, loss: 0.0017781162168830633
step: 220, loss: 0.021386737003922462
step: 230, loss: 0.0037206122651696205
step: 240, loss: 0.00827717874199152
step: 250, loss: 0.01244522724300623
step: 260, loss: 0.003519895952194929
step: 270, loss: 0.0022509244736284018
epoch 5: dev_f1=0.9764309764309763, f1=0.9786276715410572, best_f1=0.9842696629213483
step: 0, loss: 0.033681049942970276
step: 10, loss: 0.00029816298047080636
step: 20, loss: 0.0016910420963540673
step: 30, loss: 0.004024720750749111
step: 40, loss: 0.0010117340134456754
step: 50, loss: 0.0018208075780421495
step: 60, loss: 0.04217350482940674
step: 70, loss: 0.0014524351572617888
step: 80, loss: 0.002394784474745393
step: 90, loss: 0.19740410149097443
step: 100, loss: 0.0011761493515223265
step: 110, loss: 0.0021282900124788284
step: 120, loss: 0.003604194149374962
step: 130, loss: 0.0008282213238999248
step: 140, loss: 0.001174252713099122
step: 150, loss: 0.002872337820008397
step: 160, loss: 0.005520431790500879
step: 170, loss: 0.015395909547805786
step: 180, loss: 0.011822009459137917
step: 190, loss: 0.0011960570700466633
step: 200, loss: 0.0016464943764731288
step: 210, loss: 0.0007237709942273796
step: 220, loss: 0.005006174091249704
step: 230, loss: 0.0010342191671952605
step: 240, loss: 0.006695088930428028
step: 250, loss: 0.002403763122856617
step: 260, loss: 0.0010650013573467731
step: 270, loss: 0.000992669491097331
epoch 6: dev_f1=0.9854423292273236, f1=0.9865470852017937, best_f1=0.9842696629213483
step: 0, loss: 0.0010633969213813543
step: 10, loss: 0.0012194294249638915
step: 20, loss: 0.0005624698824249208
step: 30, loss: 0.00047194500803016126
step: 40, loss: 0.004016608465462923
step: 50, loss: 0.0012390208430588245
step: 60, loss: 0.0004399468016345054
step: 70, loss: 0.12223290652036667
step: 80, loss: 0.00997746642678976
step: 90, loss: 0.0013353152899071574
step: 100, loss: 0.001660832786001265
step: 110, loss: 0.0004985372070223093
step: 120, loss: 0.000226868549361825
step: 130, loss: 0.0017980774864554405
step: 140, loss: 0.001147363567724824
step: 150, loss: 0.02315068244934082
step: 160, loss: 0.014324386604130268
step: 170, loss: 0.010508393868803978
step: 180, loss: 0.00044365666690282524
step: 190, loss: 0.0006291509489528835
step: 200, loss: 0.0003417176194489002
step: 210, loss: 0.00046691225725226104
step: 220, loss: 0.00040172517765313387
step: 230, loss: 0.0004945319378748536
step: 240, loss: 0.0027640617918223143
step: 250, loss: 0.0034461943432688713
step: 260, loss: 0.00039008213207125664
step: 270, loss: 0.00972803495824337
epoch 7: dev_f1=0.9820224719101124, f1=0.9830890642615557, best_f1=0.9842696629213483
step: 0, loss: 0.0007792150136083364
step: 10, loss: 0.007734156679362059
step: 20, loss: 0.00031476758886128664
step: 30, loss: 0.0025494256988167763
step: 40, loss: 0.00044680864084511995
step: 50, loss: 0.0014464848209172487
step: 60, loss: 0.008676628582179546
step: 70, loss: 0.00017974627553485334
step: 80, loss: 0.205001100897789
step: 90, loss: 0.002604462206363678
step: 100, loss: 0.0007999399676918983
step: 110, loss: 0.0015290210722014308
step: 120, loss: 0.001948998891748488
step: 130, loss: 0.006824789103120565
step: 140, loss: 0.0010112940799444914
step: 150, loss: 0.001856726361438632
step: 160, loss: 0.00031277452944777906
step: 170, loss: 0.0006044683395884931
step: 180, loss: 0.00025310422643087804
step: 190, loss: 0.0004761649470310658
step: 200, loss: 0.0010379960294812918
step: 210, loss: 0.0004147160507272929
step: 220, loss: 0.00036352325696498156
step: 230, loss: 0.0024670299608260393
step: 240, loss: 0.0005825107800774276
step: 250, loss: 0.01266448013484478
step: 260, loss: 0.0005638726870529354
step: 270, loss: 0.0003310927131678909
epoch 8: dev_f1=0.9797752808988766, f1=0.984304932735426, best_f1=0.9842696629213483
step: 0, loss: 0.0008902116678655148
step: 10, loss: 0.0006723045953549445
step: 20, loss: 0.00046861180453561246
step: 30, loss: 0.00038275832775980234
step: 40, loss: 0.00029960961546748877
step: 50, loss: 0.00026899276417680085
step: 60, loss: 0.00019898863683920354
step: 70, loss: 0.05339066684246063
step: 80, loss: 0.0002928248723037541
step: 90, loss: 0.0004570753953885287
step: 100, loss: 0.0004550686862785369
step: 110, loss: 0.0006877340492792428
step: 120, loss: 0.03179415687918663
step: 130, loss: 0.0004109041765332222
step: 140, loss: 0.001431983895599842
step: 150, loss: 0.0005286856321617961
step: 160, loss: 0.004421341232955456
step: 170, loss: 0.08026610314846039
step: 180, loss: 0.0003848799387924373
step: 190, loss: 0.0010439256438985467
step: 200, loss: 0.0058994353748857975
step: 210, loss: 0.0005657912697643042
step: 220, loss: 0.005403687711805105
step: 230, loss: 0.0008209104998968542
step: 240, loss: 0.0004003965586889535
step: 250, loss: 0.00021481509611476213
step: 260, loss: 0.00017277852748520672
step: 270, loss: 0.00039511118666268885
epoch 9: dev_f1=0.9876265466816648, f1=0.9887640449438202, best_f1=0.9842696629213483
step: 0, loss: 0.00028176771593280137
step: 10, loss: 0.0001264390884898603
step: 20, loss: 0.0005144964088685811
step: 30, loss: 0.00030136635177768767
step: 40, loss: 0.0004003428330179304
step: 50, loss: 0.0002592565433587879
step: 60, loss: 0.00014986046880949289
step: 70, loss: 0.0012064932379871607
step: 80, loss: 0.00017579278210178018
step: 90, loss: 0.0003646409313660115
step: 100, loss: 0.008048616349697113
step: 110, loss: 0.04156798869371414
step: 120, loss: 0.00014804016973357648
step: 130, loss: 0.0002135430258931592
step: 140, loss: 6.451265653595328e-05
step: 150, loss: 0.0003810341586358845
step: 160, loss: 0.0019515391904860735
step: 170, loss: 0.00035116373328492045
step: 180, loss: 0.00018416113744024187
step: 190, loss: 0.010801749303936958
step: 200, loss: 0.00024220350314863026
step: 210, loss: 0.07953820377588272
step: 220, loss: 0.00048380353837274015
step: 230, loss: 0.2206314653158188
step: 240, loss: 0.0011188058415427804
step: 250, loss: 0.003104293951764703
step: 260, loss: 0.00026558266836218536
step: 270, loss: 0.0008427565335296094
epoch 10: dev_f1=0.9876265466816648, f1=0.978675645342312, best_f1=0.9842696629213483
step: 0, loss: 0.07492072880268097
step: 10, loss: 0.004244563635438681
step: 20, loss: 0.00039889244362711906
step: 30, loss: 0.00154194759670645
step: 40, loss: 0.00015212103608064353
step: 50, loss: 0.002673017093911767
step: 60, loss: 0.0003424064489081502
step: 70, loss: 0.0009087605867534876
step: 80, loss: 0.0033181265462189913
step: 90, loss: 0.005304566118866205
step: 100, loss: 0.002674480201676488
step: 110, loss: 0.0006480252486653626
step: 120, loss: 0.00020826027321163565
step: 130, loss: 0.0038747000508010387
step: 140, loss: 0.0053143007680773735
step: 150, loss: 0.0005077506066299975
step: 160, loss: 0.0004228411999065429
step: 170, loss: 0.0002973159425891936
step: 180, loss: 0.00045471909106709063
step: 190, loss: 0.0002706875966396183
step: 200, loss: 0.0005220015300437808
step: 210, loss: 0.0004961984232068062
step: 220, loss: 0.020897921174764633
step: 230, loss: 0.0002290706179337576
step: 240, loss: 0.0002624811604619026
step: 250, loss: 0.0020706586074084044
step: 260, loss: 0.0029740668833255768
step: 270, loss: 0.0007767241331748664
epoch 11: dev_f1=0.9887892376681614, f1=0.9820627802690582, best_f1=0.9820627802690582
step: 0, loss: 0.000715036119800061
step: 10, loss: 0.0008814811590127647
step: 20, loss: 0.0005118779372423887
step: 30, loss: 0.019023282453417778
step: 40, loss: 0.0047240289859473705
step: 50, loss: 0.000416224094806239
step: 60, loss: 0.0006007507909089327
step: 70, loss: 0.0002515311643946916
step: 80, loss: 0.00019572953169699758
step: 90, loss: 0.00021547025244217366
step: 100, loss: 0.0001233804359799251
step: 110, loss: 0.00016907705867197365
step: 120, loss: 0.0005341246142052114
step: 130, loss: 0.0027533890679478645
step: 140, loss: 0.0005111836362630129
step: 150, loss: 0.00015272006567101926
step: 160, loss: 0.00048161004087887704
step: 170, loss: 0.00018914963584393263
step: 180, loss: 0.003339710645377636
step: 190, loss: 0.00038237421540543437
step: 200, loss: 0.00037330560735426843
step: 210, loss: 0.00020810715795960277
step: 220, loss: 0.11998294293880463
step: 230, loss: 0.0003392864891793579
step: 240, loss: 0.015192528255283833
step: 250, loss: 0.00024813448544591665
step: 260, loss: 0.000687705643940717
step: 270, loss: 0.00029358279425650835
epoch 12: dev_f1=0.9910112359550561, f1=0.9853768278965129, best_f1=0.9853768278965129
step: 0, loss: 0.00023387755209114403
step: 10, loss: 0.00041470566065981984
step: 20, loss: 0.07047640532255173
step: 30, loss: 0.06548865139484406
step: 40, loss: 0.0016366493655368686
step: 50, loss: 0.0005641278112307191
step: 60, loss: 0.0004670569614972919
step: 70, loss: 0.0013386643258854747
step: 80, loss: 0.00022045159130357206
step: 90, loss: 0.00015033787349238992
step: 100, loss: 0.00015714921755716205
step: 110, loss: 0.00044569047167897224
step: 120, loss: 0.03173036500811577
step: 130, loss: 0.00019096753385383636
step: 140, loss: 0.0009570057736709714
step: 150, loss: 0.00031651509925723076
step: 160, loss: 0.1772012710571289
step: 170, loss: 0.010332400910556316
step: 180, loss: 0.0011009310837835073
step: 190, loss: 0.00019020888430532068
step: 200, loss: 0.00018872061627916992
step: 210, loss: 0.00016504013910889626
step: 220, loss: 0.0067601315677165985
step: 230, loss: 0.030102798715233803
step: 240, loss: 0.0009092878317460418
step: 250, loss: 0.0008932389318943024
step: 260, loss: 0.00036162493051961064
step: 270, loss: 0.00012406118912622333
epoch 13: dev_f1=0.9909706546275394, f1=0.9841986455981941, best_f1=0.9853768278965129
step: 0, loss: 0.001930193044245243
step: 10, loss: 9.423779556527734e-05
step: 20, loss: 0.00013599576777778566
step: 30, loss: 0.00023157848045229912
step: 40, loss: 0.00010179564560530707
step: 50, loss: 0.0007904352969489992
step: 60, loss: 0.00010776706039905548
step: 70, loss: 0.008779057301580906
step: 80, loss: 0.00041916119516827166
step: 90, loss: 0.00020048904116265476
step: 100, loss: 0.00020626034529414028
step: 110, loss: 0.00017349138215649873
step: 120, loss: 0.00015023810556158423
step: 130, loss: 0.0002041567931883037
step: 140, loss: 0.0005221134051680565
step: 150, loss: 0.00022577929485123605
step: 160, loss: 0.00023832780425436795
step: 170, loss: 0.04597849026322365
step: 180, loss: 0.00020078077795915306
step: 190, loss: 0.00031297068926505744
step: 200, loss: 0.0002056955563602969
step: 210, loss: 0.00022102017828729004
step: 220, loss: 0.0007336807320825756
step: 230, loss: 0.00012957323633600026
step: 240, loss: 0.0004113549366593361
step: 250, loss: 0.0001682931324467063
step: 260, loss: 0.00011534287477843463
step: 270, loss: 0.00024944471078924835
epoch 14: dev_f1=0.9888392857142857, f1=0.9799554565701558, best_f1=0.9853768278965129
step: 0, loss: 0.00031093796133063734
step: 10, loss: 0.0002314089797437191
step: 20, loss: 0.00029959515086375177
step: 30, loss: 0.00027678158949129283
step: 40, loss: 0.00032459813519380987
step: 50, loss: 0.00019288140174467117
step: 60, loss: 0.017275074496865273
step: 70, loss: 0.00019649173191282898
step: 80, loss: 0.0003275125927757472
step: 90, loss: 0.054569099098443985
step: 100, loss: 0.00027629564283415675
step: 110, loss: 0.030346427112817764
step: 120, loss: 0.0001247158506885171
step: 130, loss: 0.00026217143749818206
step: 140, loss: 0.0009630779968574643
step: 150, loss: 0.00016543144010938704
step: 160, loss: 0.0001342385949101299
step: 170, loss: 0.0011266553774476051
step: 180, loss: 0.027893846854567528
step: 190, loss: 7.442617788910866e-05
step: 200, loss: 0.00015756417997181416
step: 210, loss: 0.01605994813144207
step: 220, loss: 0.00010399744496680796
step: 230, loss: 0.00011860600352520123
step: 240, loss: 0.00015518306463491172
step: 250, loss: 9.220334322890267e-05
step: 260, loss: 0.00016164101543836296
step: 270, loss: 0.00010842396295629442
epoch 15: dev_f1=0.9887387387387387, f1=0.9831271091113611, best_f1=0.9853768278965129
step: 0, loss: 0.019952598959207535
step: 10, loss: 0.0002318173210369423
step: 20, loss: 0.001139886793680489
step: 30, loss: 0.0002417869691271335
step: 40, loss: 0.00026893726317211986
step: 50, loss: 0.0013521971413865685
step: 60, loss: 0.0001617781090317294
step: 70, loss: 0.00035407874383963645
step: 80, loss: 0.00027232689899392426
step: 90, loss: 0.000515206076670438
step: 100, loss: 7.69571415730752e-05
step: 110, loss: 8.196353155653924e-05
step: 120, loss: 9.413561201654375e-05
step: 130, loss: 0.0002980964782182127
step: 140, loss: 0.00036152548273094
step: 150, loss: 0.00021160385222174227
step: 160, loss: 0.0003492281830403954
step: 170, loss: 0.00019135400361847132
step: 180, loss: 0.00010972467862302437
step: 190, loss: 0.00019472491112537682
step: 200, loss: 0.00011004247789969668
step: 210, loss: 0.0009349034517072141
step: 220, loss: 0.0001259164564544335
step: 230, loss: 0.000128849787870422
step: 240, loss: 0.019705038517713547
step: 250, loss: 0.0007861559861339629
step: 260, loss: 0.0007526474073529243
step: 270, loss: 8.534723747288808e-05
epoch 16: dev_f1=0.984304932735426, f1=0.9832026875699889, best_f1=0.9853768278965129
step: 0, loss: 7.771883247187361e-05
step: 10, loss: 0.00040363395237363875
step: 20, loss: 0.00019212639017496258
step: 30, loss: 0.00019110788707621396
step: 40, loss: 0.00017081995611079037
step: 50, loss: 0.00012127659283578396
step: 60, loss: 0.01802162639796734
step: 70, loss: 0.00035032356390729547
step: 80, loss: 0.00016563310055062175
step: 90, loss: 0.00877569243311882
step: 100, loss: 0.03134400025010109
step: 110, loss: 0.00034382837475277483
step: 120, loss: 0.0001161684631370008
step: 130, loss: 0.0003402453730814159
step: 140, loss: 0.002001423155888915
step: 150, loss: 6.5183914557565e-05
step: 160, loss: 0.0011657173745334148
step: 170, loss: 0.0010271493811160326
step: 180, loss: 0.00012049776705680415
step: 190, loss: 0.00011774309678003192
step: 200, loss: 0.00013593102630693465
step: 210, loss: 0.00010845653741853312
step: 220, loss: 0.00010983848915202543
step: 230, loss: 7.857479795347899e-05
step: 240, loss: 0.00010266679601045325
step: 250, loss: 0.0013305852189660072
step: 260, loss: 7.745734183117747e-05
step: 270, loss: 0.00010035741433966905
epoch 17: dev_f1=0.9865168539325843, f1=0.9854096520763187, best_f1=0.9853768278965129
step: 0, loss: 7.994380575837567e-05
step: 10, loss: 0.008740894496440887
step: 20, loss: 0.00032970510073937476
step: 30, loss: 0.00014384370297193527
step: 40, loss: 9.266657434636727e-05
step: 50, loss: 8.268855162896216e-05
step: 60, loss: 0.006336817517876625
step: 70, loss: 6.919608858879656e-05
step: 80, loss: 0.00014074820501264185
step: 90, loss: 7.172908226493746e-05
step: 100, loss: 0.00014340256166178733
step: 110, loss: 6.834972009528428e-05
step: 120, loss: 8.796246402198449e-05
step: 130, loss: 8.349646668648347e-05
step: 140, loss: 0.00010240163101116195
step: 150, loss: 6.982501508900896e-05
step: 160, loss: 0.00012193590373499319
step: 170, loss: 0.027360139414668083
step: 180, loss: 0.011729502119123936
step: 190, loss: 0.00021850109624210745
step: 200, loss: 4.0740873373579234e-05
step: 210, loss: 0.00011926845036214218
step: 220, loss: 0.00047169323079288006
step: 230, loss: 9.4613540568389e-05
step: 240, loss: 4.997207724954933e-05
step: 250, loss: 0.015857242047786713
step: 260, loss: 9.535637218505144e-05
step: 270, loss: 0.00012050403165630996
epoch 18: dev_f1=0.9887387387387387, f1=0.9876265466816648, best_f1=0.9853768278965129
step: 0, loss: 0.00010702448344090953
step: 10, loss: 4.970601366949268e-05
step: 20, loss: 9.674656757852063e-05
step: 30, loss: 8.304226503241807e-05
step: 40, loss: 5.0157330406364053e-05
step: 50, loss: 0.0003279695229139179
step: 60, loss: 0.0002859740052372217
step: 70, loss: 5.579922435572371e-05
step: 80, loss: 0.00011439436639193445
step: 90, loss: 0.00016855128342285752
step: 100, loss: 0.00015598905156366527
step: 110, loss: 9.80402110144496e-05
step: 120, loss: 6.28240522928536e-05
step: 130, loss: 8.262763731181622e-05
step: 140, loss: 0.000161917952937074
step: 150, loss: 0.00013091717846691608
step: 160, loss: 9.483941539656371e-05
step: 170, loss: 6.603289511986077e-05
step: 180, loss: 5.548809713218361e-05
step: 190, loss: 0.0011910531902685761
step: 200, loss: 7.423770148307085e-05
step: 210, loss: 8.761433855397627e-05
step: 220, loss: 5.339161361916922e-05
step: 230, loss: 5.343236989574507e-05
step: 240, loss: 0.005017497576773167
step: 250, loss: 0.00011035463103326038
step: 260, loss: 6.651363946730271e-05
step: 270, loss: 5.939494076301344e-05
epoch 19: dev_f1=0.9887387387387387, f1=0.9865168539325843, best_f1=0.9853768278965129
step: 0, loss: 6.560792826348916e-05
step: 10, loss: 7.208788156276569e-05
step: 20, loss: 5.0616523367352784e-05
step: 30, loss: 0.00016297375259455293
step: 40, loss: 6.374340591719374e-05
step: 50, loss: 6.0988742916379124e-05
step: 60, loss: 0.0010981028899550438
step: 70, loss: 5.215672717895359e-05
step: 80, loss: 4.315221303841099e-05
step: 90, loss: 5.844836414325982e-05
step: 100, loss: 0.00017070410831365734
step: 110, loss: 0.00013009982649236917
step: 120, loss: 5.257985321804881e-05
step: 130, loss: 0.00113501341547817
step: 140, loss: 0.0007003861246630549
step: 150, loss: 0.0001560894015710801
step: 160, loss: 5.2385632443474606e-05
step: 170, loss: 0.00046309991739690304
step: 180, loss: 0.00010535743786022067
step: 190, loss: 0.00011271790572209284
step: 200, loss: 0.0001247823383891955
step: 210, loss: 0.0004445028898771852
step: 220, loss: 3.465873669483699e-05
step: 230, loss: 0.00018926819029729813
step: 240, loss: 4.5634456910192966e-05
step: 250, loss: 5.753371078753844e-05
step: 260, loss: 5.128604607307352e-05
step: 270, loss: 6.305774877546355e-05
epoch 20: dev_f1=0.9887387387387387, f1=0.9876265466816648, best_f1=0.9853768278965129
