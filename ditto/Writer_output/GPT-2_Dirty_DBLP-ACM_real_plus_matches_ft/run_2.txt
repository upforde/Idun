cuda
Device: cuda
step: 0, loss: 0.7938376665115356
step: 10, loss: 0.6131488084793091
step: 20, loss: 0.4065256416797638
step: 30, loss: 0.5370445847511292
step: 40, loss: 0.4264764189720154
step: 50, loss: 0.37519147992134094
step: 60, loss: 0.32324570417404175
step: 70, loss: 0.3726820945739746
step: 80, loss: 0.28356826305389404
step: 90, loss: 0.2386251538991928
step: 100, loss: 0.24420320987701416
step: 110, loss: 0.04780479893088341
step: 120, loss: 0.3458537459373474
step: 130, loss: 0.16988877952098846
step: 140, loss: 0.15440091490745544
step: 150, loss: 0.1503717303276062
step: 160, loss: 0.025943389162421227
step: 170, loss: 0.22444666922092438
step: 180, loss: 0.16957463324069977
step: 190, loss: 0.020610595121979713
step: 200, loss: 0.013731813989579678
step: 210, loss: 0.15318021178245544
step: 220, loss: 0.07190367579460144
step: 230, loss: 0.07359099388122559
step: 240, loss: 0.051788970828056335
step: 250, loss: 0.2440684586763382
step: 260, loss: 0.1565532684326172
step: 270, loss: 0.06884808093309402
epoch 1: dev_f1=0.9740112994350283, f1=0.9739524348810873, best_f1=0.9739524348810873
step: 0, loss: 0.024063721299171448
step: 10, loss: 0.017002122476696968
step: 20, loss: 0.12099979817867279
step: 30, loss: 0.01518124621361494
step: 40, loss: 0.07581919431686401
step: 50, loss: 0.009056045673787594
step: 60, loss: 0.005719258915632963
step: 70, loss: 0.04119405150413513
step: 80, loss: 0.01988770067691803
step: 90, loss: 0.050870250910520554
step: 100, loss: 0.03275179862976074
step: 110, loss: 0.10916023701429367
step: 120, loss: 0.12919498980045319
step: 130, loss: 0.06180607154965401
step: 140, loss: 0.04289819300174713
step: 150, loss: 0.10785673558712006
step: 160, loss: 0.052941929548978806
step: 170, loss: 0.019768010824918747
step: 180, loss: 0.0345955565571785
step: 190, loss: 0.10055296123027802
step: 200, loss: 0.15931925177574158
step: 210, loss: 0.026507627218961716
step: 220, loss: 0.02444475144147873
step: 230, loss: 0.011958901770412922
step: 240, loss: 0.007516892626881599
step: 250, loss: 0.005352689418941736
step: 260, loss: 0.003466057125478983
step: 270, loss: 0.002889922121539712
epoch 2: dev_f1=0.9766407119021134, f1=0.9720670391061451, best_f1=0.9720670391061451
step: 0, loss: 0.005031530279666185
step: 10, loss: 0.017390655353665352
step: 20, loss: 0.017041020095348358
step: 30, loss: 0.0025313864462077618
step: 40, loss: 0.0016826684586703777
step: 50, loss: 0.003767258021980524
step: 60, loss: 0.0014891821192577481
step: 70, loss: 0.007285550236701965
step: 80, loss: 0.0012132308911532164
step: 90, loss: 0.013153311796486378
step: 100, loss: 0.0064842612482607365
step: 110, loss: 0.0020789564587175846
step: 120, loss: 0.008829465135931969
step: 130, loss: 0.018865909427404404
step: 140, loss: 0.011167294345796108
step: 150, loss: 0.001737177837640047
step: 160, loss: 0.0006313738995231688
step: 170, loss: 0.08678147941827774
step: 180, loss: 0.033965371549129486
step: 190, loss: 0.053786683827638626
step: 200, loss: 0.008985579945147038
step: 210, loss: 0.013494469225406647
step: 220, loss: 0.004906614311039448
step: 230, loss: 0.10193784534931183
step: 240, loss: 0.002315857680514455
step: 250, loss: 0.039532601833343506
step: 260, loss: 0.0022277047391980886
step: 270, loss: 0.001025430392473936
epoch 3: dev_f1=0.9819819819819819, f1=0.9806157354618015, best_f1=0.9806157354618015
step: 0, loss: 0.008149074390530586
step: 10, loss: 0.14360608160495758
step: 20, loss: 0.0008609601645730436
step: 30, loss: 0.003283134428784251
step: 40, loss: 0.07773005217313766
step: 50, loss: 0.01456053089350462
step: 60, loss: 0.00530213164165616
step: 70, loss: 0.007380817551165819
step: 80, loss: 0.008408375084400177
step: 90, loss: 0.0004891903372481465
step: 100, loss: 0.00169504270888865
step: 110, loss: 0.0015782779082655907
step: 120, loss: 0.002210893202573061
step: 130, loss: 0.030668998137116432
step: 140, loss: 0.006432919763028622
step: 150, loss: 0.1565864533185959
step: 160, loss: 0.004399430006742477
step: 170, loss: 0.005163966678082943
step: 180, loss: 0.009267940185964108
step: 190, loss: 0.09002740681171417
step: 200, loss: 0.005300062242895365
step: 210, loss: 0.011714454740285873
step: 220, loss: 0.0018472536467015743
step: 230, loss: 0.001929663703776896
step: 240, loss: 0.11210569739341736
step: 250, loss: 0.016418568789958954
step: 260, loss: 0.0038294049445539713
step: 270, loss: 0.056391116231679916
epoch 4: dev_f1=0.9876543209876544, f1=0.9830890642615557, best_f1=0.9830890642615557
step: 0, loss: 0.02839321829378605
step: 10, loss: 0.052884940057992935
step: 20, loss: 0.00029546095174737275
step: 30, loss: 0.0008977216202765703
step: 40, loss: 0.0018716987688094378
step: 50, loss: 0.0020811238791793585
step: 60, loss: 0.004100559279322624
step: 70, loss: 0.00047722188173793256
step: 80, loss: 0.07055142521858215
step: 90, loss: 0.02715407870709896
step: 100, loss: 0.0005011115572415292
step: 110, loss: 0.003267707535997033
step: 120, loss: 0.0003864556783810258
step: 130, loss: 0.0023024759721010923
step: 140, loss: 0.001079887617379427
step: 150, loss: 0.0007144568953663111
step: 160, loss: 0.0006105061038397253
step: 170, loss: 0.0004398017772473395
step: 180, loss: 0.025360852479934692
step: 190, loss: 0.002431063447147608
step: 200, loss: 0.004016248043626547
step: 210, loss: 0.0005917735979892313
step: 220, loss: 0.00375223346054554
step: 230, loss: 0.037653710693120956
step: 240, loss: 0.002608586335554719
step: 250, loss: 0.30216068029403687
step: 260, loss: 0.009990835562348366
step: 270, loss: 0.0017551252385601401
epoch 5: dev_f1=0.9841628959276018, f1=0.9852440408626559, best_f1=0.9830890642615557
step: 0, loss: 0.0030500502325594425
step: 10, loss: 0.0040577673353254795
step: 20, loss: 0.006454162765294313
step: 30, loss: 0.002009960822761059
step: 40, loss: 0.0012931708479300141
step: 50, loss: 0.0006210824940353632
step: 60, loss: 0.0023907143622636795
step: 70, loss: 0.0004870678822044283
step: 80, loss: 0.0005934819346293807
step: 90, loss: 0.0008654368575662374
step: 100, loss: 0.0006865191971883178
step: 110, loss: 0.04115276411175728
step: 120, loss: 0.0059133730828762054
step: 130, loss: 0.0019282043213024735
step: 140, loss: 0.0005173071403987706
step: 150, loss: 0.0005760856438428164
step: 160, loss: 0.002219309564679861
step: 170, loss: 0.0007798777078278363
step: 180, loss: 0.0016160260420292616
step: 190, loss: 0.0005597780691459775
step: 200, loss: 0.005024017300456762
step: 210, loss: 0.020068610087037086
step: 220, loss: 0.013597177341580391
step: 230, loss: 0.0010314381215721369
step: 240, loss: 0.005829013418406248
step: 250, loss: 0.004086145665496588
step: 260, loss: 0.012644078582525253
step: 270, loss: 0.006168967112898827
epoch 6: dev_f1=0.9807909604519773, f1=0.9819004524886877, best_f1=0.9830890642615557
step: 0, loss: 0.0035049086436629295
step: 10, loss: 0.001575304544530809
step: 20, loss: 0.0005788310081698
step: 30, loss: 0.0005318135372363031
step: 40, loss: 0.001306359190493822
step: 50, loss: 0.0014216668205335736
step: 60, loss: 0.002702755620703101
step: 70, loss: 0.0010506706312298775
step: 80, loss: 0.01781015656888485
step: 90, loss: 0.0011154781095683575
step: 100, loss: 0.0009540437604300678
step: 110, loss: 0.0004524232354015112
step: 120, loss: 0.0017160169081762433
step: 130, loss: 0.0007222156273201108
step: 140, loss: 0.0006124849314801395
step: 150, loss: 0.02762705273926258
step: 160, loss: 0.0009558626334182918
step: 170, loss: 0.003452338045462966
step: 180, loss: 0.04095730558037758
step: 190, loss: 0.0017202204326167703
step: 200, loss: 0.0012408617185428739
step: 210, loss: 0.0014235784765332937
step: 220, loss: 0.0012773438356816769
step: 230, loss: 0.022079315036535263
step: 240, loss: 0.002738802693784237
step: 250, loss: 0.005478715058416128
step: 260, loss: 0.008101401850581169
step: 270, loss: 0.0012711207382380962
epoch 7: dev_f1=0.9808342728297633, f1=0.9864253393665158, best_f1=0.9830890642615557
step: 0, loss: 0.0006427444168366492
step: 10, loss: 0.00043627232662402093
step: 20, loss: 0.0014737488236278296
step: 30, loss: 0.05426599830389023
step: 40, loss: 0.0010584034025669098
step: 50, loss: 0.00046708789886906743
step: 60, loss: 0.0038022904191166162
step: 70, loss: 0.0006316956132650375
step: 80, loss: 0.0009421880240552127
step: 90, loss: 0.0006222223746590316
step: 100, loss: 0.0005499726394191384
step: 110, loss: 0.008131822571158409
step: 120, loss: 0.0002590653602965176
step: 130, loss: 0.000806117954198271
step: 140, loss: 0.0005846440326422453
step: 150, loss: 0.00018180487677454948
step: 160, loss: 0.0004733730456791818
step: 170, loss: 0.015370779670774937
step: 180, loss: 0.0030663837678730488
step: 190, loss: 0.00036848991294391453
step: 200, loss: 0.0015334967756643891
step: 210, loss: 0.0018676877953112125
step: 220, loss: 0.003515380434691906
step: 230, loss: 0.0050917561165988445
step: 240, loss: 0.005823330022394657
step: 250, loss: 0.0017819700296968222
step: 260, loss: 0.0006284170085564256
step: 270, loss: 0.026445407420396805
epoch 8: dev_f1=0.9853768278965129, f1=0.9887133182844244, best_f1=0.9830890642615557
step: 0, loss: 0.0009411021019332111
step: 10, loss: 0.002971767447888851
step: 20, loss: 0.010191446170210838
step: 30, loss: 0.0011007130378857255
step: 40, loss: 0.00042073981603607535
step: 50, loss: 0.0003636626061052084
step: 60, loss: 0.009648002684116364
step: 70, loss: 0.4634474813938141
step: 80, loss: 0.002784234704449773
step: 90, loss: 0.003870958462357521
step: 100, loss: 0.0017646033084020019
step: 110, loss: 0.0027599248569458723
step: 120, loss: 0.0007655035005882382
step: 130, loss: 0.0014219313161447644
step: 140, loss: 0.0017122322460636497
step: 150, loss: 0.001483568805269897
step: 160, loss: 0.00045054475776851177
step: 170, loss: 0.012843162752687931
step: 180, loss: 0.0006801620475016534
step: 190, loss: 0.00031836473499424756
step: 200, loss: 0.0013303293380886316
step: 210, loss: 0.022604040801525116
step: 220, loss: 0.0009107442456297576
step: 230, loss: 0.0025154254399240017
step: 240, loss: 0.023260613903403282
step: 250, loss: 0.000557247141841799
step: 260, loss: 0.0008809121791273355
step: 270, loss: 0.00563029944896698
epoch 9: dev_f1=0.980963045912654, f1=0.9842696629213483, best_f1=0.9830890642615557
step: 0, loss: 0.001191702438518405
step: 10, loss: 0.002420814009383321
step: 20, loss: 0.013738812878727913
step: 30, loss: 0.00025925514637492597
step: 40, loss: 0.0003059044829569757
step: 50, loss: 0.00015255744801834226
step: 60, loss: 0.0008155442192219198
step: 70, loss: 0.0010310134384781122
step: 80, loss: 0.1929170936346054
step: 90, loss: 0.002314035315066576
step: 100, loss: 0.008031570352613926
step: 110, loss: 0.14416247606277466
step: 120, loss: 0.013539284467697144
step: 130, loss: 0.004252737388014793
step: 140, loss: 0.0010491248685866594
step: 150, loss: 0.0007116867927834392
step: 160, loss: 0.0014420918887481093
step: 170, loss: 0.0007498530903831124
step: 180, loss: 0.0007761280285194516
step: 190, loss: 0.00015106280625332147
step: 200, loss: 0.004306780640035868
step: 210, loss: 0.009235819801688194
step: 220, loss: 0.00686611095443368
step: 230, loss: 0.0022376200649887323
step: 240, loss: 0.0006073123076930642
step: 250, loss: 0.0004804930358659476
step: 260, loss: 0.0011524318251758814
step: 270, loss: 0.0003078656445723027
epoch 10: dev_f1=0.9799107142857142, f1=0.9788182831661093, best_f1=0.9830890642615557
step: 0, loss: 0.0008109998889267445
step: 10, loss: 0.00029605638701468706
step: 20, loss: 0.0005538417026400566
step: 30, loss: 0.0005696393782272935
step: 40, loss: 0.00029074272606521845
step: 50, loss: 0.00015736318891867995
step: 60, loss: 0.0005475349025800824
step: 70, loss: 0.0001477366458857432
step: 80, loss: 0.000782100367359817
step: 90, loss: 0.00023653988318983465
step: 100, loss: 0.0001293016830459237
step: 110, loss: 0.00034345436142757535
step: 120, loss: 0.00018676121544558555
step: 130, loss: 0.0002573990495875478
step: 140, loss: 0.0009526999783702195
step: 150, loss: 0.000171142237377353
step: 160, loss: 0.0002555247046984732
step: 170, loss: 0.0002512122446205467
step: 180, loss: 0.00015002585132606328
step: 190, loss: 0.00028643955010920763
step: 200, loss: 0.00036443278077058494
step: 210, loss: 0.0014525540173053741
step: 220, loss: 0.020280444994568825
step: 230, loss: 0.0027296659536659718
step: 240, loss: 0.00015322992112487555
step: 250, loss: 0.00017564281006343663
step: 260, loss: 0.0002042211126536131
step: 270, loss: 0.0016843794146552682
epoch 11: dev_f1=0.983277591973244, f1=0.9810901001112348, best_f1=0.9830890642615557
step: 0, loss: 0.0011534270597621799
step: 10, loss: 0.0005069270846433938
step: 20, loss: 9.834115189732984e-05
step: 30, loss: 0.006976711563766003
step: 40, loss: 0.00024765048874542117
step: 50, loss: 0.0001159497769549489
step: 60, loss: 0.0001390899415127933
step: 70, loss: 7.878898759372532e-05
step: 80, loss: 0.08807689696550369
step: 90, loss: 0.00036125004407949746
step: 100, loss: 0.0003633962187450379
step: 110, loss: 0.000210486221476458
step: 120, loss: 0.00035573620698414743
step: 130, loss: 0.0003483419131953269
step: 140, loss: 0.0005058659589849412
step: 150, loss: 9.264893014915287e-05
step: 160, loss: 0.0001202878265758045
step: 170, loss: 0.00024843643768690526
step: 180, loss: 0.0017052681650966406
step: 190, loss: 0.0029021031223237514
step: 200, loss: 0.00042043669964186847
step: 210, loss: 0.0018479481805115938
step: 220, loss: 0.0014087047893553972
step: 230, loss: 0.00024289530119858682
step: 240, loss: 0.0014006787678226829
step: 250, loss: 0.04584686458110809
step: 260, loss: 7.799544982844964e-05
step: 270, loss: 0.000425362290116027
epoch 12: dev_f1=0.9785794813979707, f1=0.9864864864864865, best_f1=0.9830890642615557
step: 0, loss: 0.00012168857210781425
step: 10, loss: 0.000619666010607034
step: 20, loss: 0.00019677238014992326
step: 30, loss: 0.00011437066859798506
step: 40, loss: 0.0002408254222245887
step: 50, loss: 9.833714284468442e-05
step: 60, loss: 0.0013429353712126613
step: 70, loss: 0.000506382726598531
step: 80, loss: 0.052314553409814835
step: 90, loss: 0.08381371945142746
step: 100, loss: 0.0003653651801869273
step: 110, loss: 0.0020029402803629637
step: 120, loss: 0.0003623981901910156
step: 130, loss: 0.00021380477119237185
step: 140, loss: 0.0001134258636739105
step: 150, loss: 0.0011876547941938043
step: 160, loss: 0.0002261542686028406
step: 170, loss: 0.0001230216585099697
step: 180, loss: 0.0001826101215556264
step: 190, loss: 0.0002664861094672233
step: 200, loss: 0.00010041871428256854
step: 210, loss: 0.0002976193791255355
step: 220, loss: 0.003790627932175994
step: 230, loss: 0.00011746731615858153
step: 240, loss: 9.262828098144382e-05
step: 250, loss: 0.00013008160749450326
step: 260, loss: 0.00015691667795181274
step: 270, loss: 0.00022747748880647123
epoch 13: dev_f1=0.9787709497206705, f1=0.9820627802690582, best_f1=0.9830890642615557
step: 0, loss: 0.010871050879359245
step: 10, loss: 7.737884880043566e-05
step: 20, loss: 0.00012340181274339557
step: 30, loss: 7.160560926422477e-05
step: 40, loss: 8.629264630144462e-05
step: 50, loss: 0.00012454803800210357
step: 60, loss: 0.0004419501347001642
step: 70, loss: 0.00011933239875361323
step: 80, loss: 0.0002457548398524523
step: 90, loss: 0.00437021953985095
step: 100, loss: 5.886724466108717e-05
step: 110, loss: 6.855556421214715e-05
step: 120, loss: 0.00903032161295414
step: 130, loss: 0.00025587293202988803
step: 140, loss: 0.0002502471616026014
step: 150, loss: 9.768774907570332e-05
step: 160, loss: 9.042093006428331e-05
step: 170, loss: 7.700249261688441e-05
step: 180, loss: 5.848695946042426e-05
step: 190, loss: 0.00010975074110319838
step: 200, loss: 0.00010497596667846665
step: 210, loss: 0.009177486412227154
step: 220, loss: 0.00041009156848303974
step: 230, loss: 7.646040467079729e-05
step: 240, loss: 0.00019773621170315892
step: 250, loss: 0.06448552012443542
step: 260, loss: 0.0001386294752592221
step: 270, loss: 8.923724089981988e-05
epoch 14: dev_f1=0.9773755656108598, f1=0.9830124575311437, best_f1=0.9830890642615557
step: 0, loss: 8.987621549749747e-05
step: 10, loss: 7.286602340172976e-05
step: 20, loss: 8.291214908240363e-05
step: 30, loss: 0.0002466706500854343
step: 40, loss: 0.0008593386737629771
step: 50, loss: 9.457940905122086e-05
step: 60, loss: 9.966785000870004e-05
step: 70, loss: 6.802835559938103e-05
step: 80, loss: 0.00303913583047688
step: 90, loss: 0.0003115108993370086
step: 100, loss: 0.00010117108467966318
step: 110, loss: 0.00017403584206476808
step: 120, loss: 0.0002141902659786865
step: 130, loss: 9.881640289677307e-05
step: 140, loss: 0.007295788265764713
step: 150, loss: 0.00014660732995253056
step: 160, loss: 0.0004193692875560373
step: 170, loss: 0.004416783340275288
step: 180, loss: 0.000148239269037731
step: 190, loss: 0.0002575658727437258
step: 200, loss: 0.043299350887537
step: 210, loss: 0.1285121589899063
step: 220, loss: 0.0003117688756901771
step: 230, loss: 0.0006181684439070523
step: 240, loss: 0.00013979736831970513
step: 250, loss: 0.0001619636605028063
step: 260, loss: 0.00011407547572162002
step: 270, loss: 0.00021220963390078396
epoch 15: dev_f1=0.9820224719101124, f1=0.9831271091113611, best_f1=0.9830890642615557
step: 0, loss: 0.14078521728515625
step: 10, loss: 0.0038783284835517406
step: 20, loss: 0.00036343338433653116
step: 30, loss: 8.616108971182257e-05
step: 40, loss: 0.0003084687050431967
step: 50, loss: 0.00014250729873310775
step: 60, loss: 0.0010603019036352634
step: 70, loss: 0.01957729272544384
step: 80, loss: 0.00013197006774134934
step: 90, loss: 8.830652222968638e-05
step: 100, loss: 0.004323218017816544
step: 110, loss: 0.00020478400983847678
step: 120, loss: 0.0002145961334463209
step: 130, loss: 0.04935412481427193
step: 140, loss: 9.747522562975064e-05
step: 150, loss: 0.0001727224444039166
step: 160, loss: 0.0003009378560818732
step: 170, loss: 0.0005126399919390678
step: 180, loss: 0.0003959625319112092
step: 190, loss: 0.00018140519387088716
step: 200, loss: 0.01234313752502203
step: 210, loss: 0.0003427068004384637
step: 220, loss: 0.00012161865015514195
step: 230, loss: 0.021545283496379852
step: 240, loss: 0.01875804178416729
step: 250, loss: 0.04035394266247749
step: 260, loss: 9.54310962697491e-05
step: 270, loss: 0.0005568150663748384
epoch 16: dev_f1=0.9820224719101124, f1=0.9831271091113611, best_f1=0.9830890642615557
step: 0, loss: 0.00026178162079304457
step: 10, loss: 0.00010619594831950963
step: 20, loss: 5.7305100199300796e-05
step: 30, loss: 0.00916383508592844
step: 40, loss: 0.00018050335347652435
step: 50, loss: 0.00047605004510842264
step: 60, loss: 6.959852908039466e-05
step: 70, loss: 0.0020721929613500834
step: 80, loss: 0.00013097819464746863
step: 90, loss: 0.00013480476627591997
step: 100, loss: 0.007296312600374222
step: 110, loss: 6.045412737876177e-05
step: 120, loss: 0.00016053351282607764
step: 130, loss: 0.0065000723116099834
step: 140, loss: 0.0011757309548556805
step: 150, loss: 8.151809015544131e-05
step: 160, loss: 5.9918122133240104e-05
step: 170, loss: 0.00035481966915540397
step: 180, loss: 0.00015224370872601867
step: 190, loss: 0.0064543308690190315
step: 200, loss: 0.0006977125303819776
step: 210, loss: 0.00021323771215975285
step: 220, loss: 8.642320608487353e-05
step: 230, loss: 0.00027941606822423637
step: 240, loss: 0.00010766179184429348
step: 250, loss: 0.00010923204536084086
step: 260, loss: 0.00030860441620461643
step: 270, loss: 0.0002875053323805332
epoch 17: dev_f1=0.9830890642615557, f1=0.9819413092550789, best_f1=0.9830890642615557
step: 0, loss: 5.7895176723832265e-05
step: 10, loss: 7.620080577908084e-05
step: 20, loss: 0.00017748100799508393
step: 30, loss: 7.864255167078227e-05
step: 40, loss: 8.912588964449242e-05
step: 50, loss: 0.027645479887723923
step: 60, loss: 8.0978061305359e-05
step: 70, loss: 0.00017217418644577265
step: 80, loss: 0.0002716575108934194
step: 90, loss: 9.393965592607856e-05
step: 100, loss: 0.00791731383651495
step: 110, loss: 0.00016524808597750962
step: 120, loss: 7.906757673481479e-05
step: 130, loss: 0.0001952873426489532
step: 140, loss: 0.00010693686635931954
step: 150, loss: 0.00041934673208743334
step: 160, loss: 0.00015606182569172233
step: 170, loss: 7.970858132466674e-05
step: 180, loss: 0.00010130091686733067
step: 190, loss: 0.06541605293750763
step: 200, loss: 0.0001234933006344363
step: 210, loss: 0.014424233697354794
step: 220, loss: 0.00017331370327156037
step: 230, loss: 8.674821583554149e-05
step: 240, loss: 5.544102532439865e-05
step: 250, loss: 0.0001178341408376582
step: 260, loss: 9.4556700787507e-05
step: 270, loss: 7.045573875075206e-05
epoch 18: dev_f1=0.9830890642615557, f1=0.9819819819819819, best_f1=0.9830890642615557
step: 0, loss: 7.186210132203996e-05
step: 10, loss: 0.0038680522702634335
step: 20, loss: 0.00042018285603262484
step: 30, loss: 9.214092278853059e-05
step: 40, loss: 0.00010638653475325555
step: 50, loss: 5.357294139685109e-05
step: 60, loss: 0.0002809329307638109
step: 70, loss: 7.256152457557619e-05
step: 80, loss: 6.392107752617449e-05
step: 90, loss: 0.0002375767071498558
step: 100, loss: 8.455302304355428e-05
step: 110, loss: 7.276514952536672e-05
step: 120, loss: 0.008090171031653881
step: 130, loss: 6.811662024119869e-05
step: 140, loss: 0.09327992796897888
step: 150, loss: 5.489922114065848e-05
step: 160, loss: 9.664333629189059e-05
step: 170, loss: 0.00020495794888120145
step: 180, loss: 0.00019026071822736412
step: 190, loss: 0.00025581225054338574
step: 200, loss: 0.00016033863357733935
step: 210, loss: 7.901600474724546e-05
step: 220, loss: 8.4611980128102e-05
step: 230, loss: 6.304854468908161e-05
step: 240, loss: 0.00030217174207791686
step: 250, loss: 6.261570524657145e-05
step: 260, loss: 0.01086224615573883
step: 270, loss: 0.011216670274734497
epoch 19: dev_f1=0.9830890642615557, f1=0.9831271091113611, best_f1=0.9830890642615557
step: 0, loss: 0.0001671770733082667
step: 10, loss: 0.012119220569729805
step: 20, loss: 0.000864381727296859
step: 30, loss: 0.04024729132652283
step: 40, loss: 0.001472101197578013
step: 50, loss: 0.001414974802173674
step: 60, loss: 0.0001598874368937686
step: 70, loss: 0.00010400876635685563
step: 80, loss: 5.4516844102181494e-05
step: 90, loss: 0.003676817985251546
step: 100, loss: 0.00015209185949061066
step: 110, loss: 4.9115864385385066e-05
step: 120, loss: 6.00805833528284e-05
step: 130, loss: 0.0001309578656218946
step: 140, loss: 0.00020157324615865946
step: 150, loss: 0.039726607501506805
step: 160, loss: 0.00021011859644204378
step: 170, loss: 4.43814460595604e-05
step: 180, loss: 0.00010831373947439715
step: 190, loss: 0.0004187952436041087
step: 200, loss: 0.0016925984527915716
step: 210, loss: 5.028296072850935e-05
step: 220, loss: 0.0006830275524407625
step: 230, loss: 5.742562279920094e-05
step: 240, loss: 0.014384575188159943
step: 250, loss: 0.00019957195036113262
step: 260, loss: 0.00011225438356632367
step: 270, loss: 7.306644693017006e-05
epoch 20: dev_f1=0.9832026875699889, f1=0.9798206278026906, best_f1=0.9830890642615557
