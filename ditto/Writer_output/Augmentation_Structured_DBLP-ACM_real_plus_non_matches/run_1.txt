cuda
Device: cuda
step: 0, loss: 0.6419892311096191
step: 10, loss: 0.2686532735824585
step: 20, loss: 0.2280931919813156
step: 30, loss: 0.3762821555137634
step: 40, loss: 0.2534043788909912
step: 50, loss: 0.21173332631587982
step: 60, loss: 0.2739224433898926
step: 70, loss: 0.12778963148593903
step: 80, loss: 0.19908910989761353
step: 90, loss: 0.14690138399600983
step: 100, loss: 0.09396044909954071
step: 110, loss: 0.10668034106492996
step: 120, loss: 0.05839059129357338
step: 130, loss: 0.1382131278514862
step: 140, loss: 0.06830236315727234
step: 150, loss: 0.1822662502527237
step: 160, loss: 0.02943299524486065
step: 170, loss: 0.17317906022071838
step: 180, loss: 0.05238909274339676
step: 190, loss: 0.025541236624121666
step: 200, loss: 0.06098214536905289
step: 210, loss: 0.11150450259447098
step: 220, loss: 0.08868210762739182
step: 230, loss: 0.09282342344522476
step: 240, loss: 0.07921233773231506
step: 250, loss: 0.041526928544044495
step: 260, loss: 0.1268545687198639
step: 270, loss: 0.08377327769994736
step: 280, loss: 0.029685495421290398
step: 290, loss: 0.026489628478884697
step: 300, loss: 0.006085867993533611
step: 310, loss: 0.3369063138961792
step: 320, loss: 0.12521398067474365
step: 330, loss: 0.01172859501093626
step: 340, loss: 0.08757787942886353
step: 350, loss: 0.02150934375822544
step: 360, loss: 0.13199904561042786
step: 370, loss: 0.0765690878033638
step: 380, loss: 0.06844930350780487
step: 390, loss: 0.08277695626020432
step: 400, loss: 0.01751490868628025
step: 410, loss: 0.1801437884569168
step: 420, loss: 0.18791373074054718
epoch 1: dev_f1=0.987598647125141, f1=0.9796839729119639, best_f1=0.9796839729119639
step: 0, loss: 0.05998209863901138
step: 10, loss: 0.059020016342401505
step: 20, loss: 0.04434219375252724
step: 30, loss: 0.07414315640926361
step: 40, loss: 0.11199275404214859
step: 50, loss: 0.27071571350097656
step: 60, loss: 0.053750962018966675
step: 70, loss: 0.07315737754106522
step: 80, loss: 0.022578349336981773
step: 90, loss: 0.07421057671308517
step: 100, loss: 0.005318266339600086
step: 110, loss: 0.0049865832552313805
step: 120, loss: 0.10205753892660141
step: 130, loss: 0.02271764539182186
step: 140, loss: 0.07775075733661652
step: 150, loss: 0.09336071461439133
step: 160, loss: 0.033388424664735794
step: 170, loss: 0.04309377819299698
step: 180, loss: 0.10783278197050095
step: 190, loss: 0.06211937591433525
step: 200, loss: 0.028327126055955887
step: 210, loss: 0.03882891684770584
step: 220, loss: 0.09282737970352173
step: 230, loss: 0.17625273764133453
step: 240, loss: 0.02793535590171814
step: 250, loss: 0.07086742669343948
step: 260, loss: 0.030890539288520813
step: 270, loss: 0.003480774350464344
step: 280, loss: 0.04672783613204956
step: 290, loss: 0.0790930911898613
step: 300, loss: 0.05326635017991066
step: 310, loss: 0.04731258749961853
step: 320, loss: 0.07622220367193222
step: 330, loss: 0.06798701733350754
step: 340, loss: 0.08321835100650787
step: 350, loss: 0.12302873283624649
step: 360, loss: 0.08385967463254929
step: 370, loss: 0.0755523145198822
step: 380, loss: 0.029079554602503777
step: 390, loss: 0.03172111138701439
step: 400, loss: 0.05438157171010971
step: 410, loss: 0.04398130625486374
step: 420, loss: 0.07362253963947296
epoch 2: dev_f1=0.9865470852017937, f1=0.9843400447427293, best_f1=0.9796839729119639
step: 0, loss: 0.009312933310866356
step: 10, loss: 0.0679304376244545
step: 20, loss: 0.1362803876399994
step: 30, loss: 0.13739784061908722
step: 40, loss: 0.04953024536371231
step: 50, loss: 0.13204249739646912
step: 60, loss: 0.05713212117552757
step: 70, loss: 0.06484146416187286
step: 80, loss: 0.0069083864800632
step: 90, loss: 0.0791831836104393
step: 100, loss: 0.09077154844999313
step: 110, loss: 0.029234644025564194
step: 120, loss: 0.15785616636276245
step: 130, loss: 0.08472196757793427
step: 140, loss: 0.09427394717931747
step: 150, loss: 0.04839710891246796
step: 160, loss: 0.021231714636087418
step: 170, loss: 0.03209773078560829
step: 180, loss: 0.01238836906850338
step: 190, loss: 0.03474045917391777
step: 200, loss: 0.023260703310370445
step: 210, loss: 0.03163526579737663
step: 220, loss: 0.00010143476538360119
step: 230, loss: 0.13802200555801392
step: 240, loss: 0.009458109736442566
step: 250, loss: 0.01767173409461975
step: 260, loss: 0.051450904458761215
step: 270, loss: 0.06691935658454895
step: 280, loss: 0.02500767633318901
step: 290, loss: 0.1058911681175232
step: 300, loss: 0.18579944968223572
step: 310, loss: 0.04487672075629234
step: 320, loss: 0.10790945589542389
step: 330, loss: 0.02971416711807251
step: 340, loss: 0.0609571598470211
step: 350, loss: 0.06170792877674103
step: 360, loss: 0.0165393203496933
step: 370, loss: 0.062284450978040695
step: 380, loss: 0.11098546534776688
step: 390, loss: 0.17541241645812988
step: 400, loss: 0.013455549255013466
step: 410, loss: 0.022769423201680183
step: 420, loss: 0.10754893720149994
epoch 3: dev_f1=0.9854423292273236, f1=0.9785794813979707, best_f1=0.9796839729119639
step: 0, loss: 0.18239690363407135
step: 10, loss: 0.03854789957404137
step: 20, loss: 0.1228581890463829
step: 30, loss: 0.008605524897575378
step: 40, loss: 0.03601847216486931
step: 50, loss: 0.01991206593811512
step: 60, loss: 0.08743423968553543
step: 70, loss: 0.024264298379421234
step: 80, loss: 0.057292163372039795
step: 90, loss: 0.14004634320735931
step: 100, loss: 0.07835577428340912
step: 110, loss: 0.019313519820570946
step: 120, loss: 0.14174127578735352
step: 130, loss: 0.0645037293434143
step: 140, loss: 0.07203938066959381
step: 150, loss: 0.05749102309346199
step: 160, loss: 0.0666315108537674
step: 170, loss: 0.02398395724594593
step: 180, loss: 0.04284241050481796
step: 190, loss: 0.06023062765598297
step: 200, loss: 0.01258225180208683
step: 210, loss: 0.1888681799173355
step: 220, loss: 0.06716101616621017
step: 230, loss: 0.019628280773758888
step: 240, loss: 0.07496029883623123
step: 250, loss: 0.18009750545024872
step: 260, loss: 0.013691503554582596
step: 270, loss: 0.0713028833270073
step: 280, loss: 0.011012614704668522
step: 290, loss: 0.12655478715896606
step: 300, loss: 0.01318028662353754
step: 310, loss: 0.10580311715602875
step: 320, loss: 0.039989255368709564
step: 330, loss: 0.04124178737401962
step: 340, loss: 0.005406007170677185
step: 350, loss: 0.13764026761054993
step: 360, loss: 0.015539413318037987
step: 370, loss: 0.09193931519985199
step: 380, loss: 0.06280657649040222
step: 390, loss: 0.07668814063072205
step: 400, loss: 0.06974704563617706
step: 410, loss: 0.03063615784049034
step: 420, loss: 0.11305079609155655
epoch 4: dev_f1=0.9876819708846584, f1=0.9821029082774049, best_f1=0.9821029082774049
step: 0, loss: 0.007906017825007439
step: 10, loss: 0.03650839254260063
step: 20, loss: 0.0770426094532013
step: 30, loss: 0.026188679039478302
step: 40, loss: 0.07418540865182877
step: 50, loss: 0.0315532311797142
step: 60, loss: 0.013405777513980865
step: 70, loss: 0.016526848077774048
step: 80, loss: 0.12577058374881744
step: 90, loss: 0.03775222972035408
step: 100, loss: 0.09734750539064407
step: 110, loss: 0.02837234176695347
step: 120, loss: 0.12167835980653763
step: 130, loss: 0.03951035067439079
step: 140, loss: 0.06392867863178253
step: 150, loss: 0.019713230431079865
step: 160, loss: 0.10903806984424591
step: 170, loss: 0.016740217804908752
step: 180, loss: 0.06745977699756622
step: 190, loss: 0.09633413702249527
step: 200, loss: 0.08218294382095337
step: 210, loss: 0.05396648868918419
step: 220, loss: 0.03389526158571243
step: 230, loss: 0.14099419116973877
step: 240, loss: 0.010369537398219109
step: 250, loss: 0.1384541243314743
step: 260, loss: 0.08619921654462814
step: 270, loss: 0.07783518731594086
step: 280, loss: 0.12452633678913116
step: 290, loss: 0.037773750722408295
step: 300, loss: 0.01118685957044363
step: 310, loss: 0.025665584951639175
step: 320, loss: 0.025583574548363686
step: 330, loss: 0.07037521153688431
step: 340, loss: 0.07689601182937622
step: 350, loss: 0.08153223991394043
step: 360, loss: 0.02647390216588974
step: 370, loss: 0.05834795534610748
step: 380, loss: 0.1775958091020584
step: 390, loss: 0.03043179027736187
step: 400, loss: 0.1522706300020218
step: 410, loss: 0.11691650003194809
step: 420, loss: 0.08679821342229843
epoch 5: dev_f1=0.9909706546275394, f1=0.9841269841269841, best_f1=0.9841269841269841
step: 0, loss: 0.006978709250688553
step: 10, loss: 0.00935234036296606
step: 20, loss: 0.008925427682697773
step: 30, loss: 0.10209090262651443
step: 40, loss: 0.019949480891227722
step: 50, loss: 0.017022956162691116
step: 60, loss: 0.08592358976602554
step: 70, loss: 0.11327603459358215
step: 80, loss: 0.05171772465109825
step: 90, loss: 0.007914979942142963
step: 100, loss: 0.013837005943059921
step: 110, loss: 0.06946766376495361
step: 120, loss: 0.07516567409038544
step: 130, loss: 0.07353810966014862
step: 140, loss: 0.22534950077533722
step: 150, loss: 0.13287998735904694
step: 160, loss: 0.017017733305692673
step: 170, loss: 0.06608805060386658
step: 180, loss: 0.07608766108751297
step: 190, loss: 0.015392925590276718
step: 200, loss: 0.0227567907422781
step: 210, loss: 0.08297135680913925
step: 220, loss: 0.1459513008594513
step: 230, loss: 0.09830047190189362
step: 240, loss: 0.07106330245733261
step: 250, loss: 0.06688901036977768
step: 260, loss: 0.20091159641742706
step: 270, loss: 0.059743717312812805
step: 280, loss: 0.02262295037508011
step: 290, loss: 0.07462545484304428
step: 300, loss: 0.013539832085371017
step: 310, loss: 0.013428921811282635
step: 320, loss: 0.015018862672150135
step: 330, loss: 0.0683729350566864
step: 340, loss: 0.014901360496878624
step: 350, loss: 0.02801363728940487
step: 360, loss: 0.06190045177936554
step: 370, loss: 0.012807478196918964
step: 380, loss: 0.1374833583831787
step: 390, loss: 0.014810672029852867
step: 400, loss: 0.005087411496788263
step: 410, loss: 0.14742641150951385
step: 420, loss: 0.006045814137905836
epoch 6: dev_f1=0.992108229988726, f1=0.9808342728297633, best_f1=0.9808342728297633
step: 0, loss: 0.03877504542469978
step: 10, loss: 0.07131979614496231
step: 20, loss: 0.06851893663406372
step: 30, loss: 0.021022750064730644
step: 40, loss: 0.02498425543308258
step: 50, loss: 0.028453852981328964
step: 60, loss: 0.004638382699340582
step: 70, loss: 0.08571107685565948
step: 80, loss: 0.08085032552480698
step: 90, loss: 0.08663459867238998
step: 100, loss: 0.03407025709748268
step: 110, loss: 0.002822679467499256
step: 120, loss: 0.1236613541841507
step: 130, loss: 0.020616397261619568
step: 140, loss: 0.1336010843515396
step: 150, loss: 0.08809104561805725
step: 160, loss: 0.0829988345503807
step: 170, loss: 0.024459339678287506
step: 180, loss: 0.10180512815713882
step: 190, loss: 0.019932549446821213
step: 200, loss: 0.07190576195716858
step: 210, loss: 0.12310928106307983
step: 220, loss: 0.020418355241417885
step: 230, loss: 0.03501572459936142
step: 240, loss: 0.06426385045051575
step: 250, loss: 0.07324518263339996
step: 260, loss: 0.032173361629247665
step: 270, loss: 0.017776472494006157
step: 280, loss: 0.022374656051397324
step: 290, loss: 0.14290325343608856
step: 300, loss: 0.009656037203967571
step: 310, loss: 0.07486732304096222
step: 320, loss: 0.033798571676015854
step: 330, loss: 0.02908346615731716
step: 340, loss: 0.018799040466547012
step: 350, loss: 0.013631358742713928
step: 360, loss: 0.010287872515618801
step: 370, loss: 0.07089266926050186
step: 380, loss: 0.07814863324165344
step: 390, loss: 0.1780417263507843
step: 400, loss: 0.07931685447692871
step: 410, loss: 0.0584150031208992
step: 420, loss: 0.07278437912464142
epoch 7: dev_f1=0.9909502262443439, f1=0.9818181818181818, best_f1=0.9808342728297633
step: 0, loss: 0.05452808365225792
step: 10, loss: 0.05046871677041054
step: 20, loss: 0.06761042028665543
step: 30, loss: 0.07857166230678558
step: 40, loss: 0.07998275011777878
step: 50, loss: 0.02110467664897442
step: 60, loss: 0.0068509685806930065
step: 70, loss: 0.014918617904186249
step: 80, loss: 0.0253000445663929
step: 90, loss: 0.022425757721066475
step: 100, loss: 0.12813666462898254
step: 110, loss: 0.02456779032945633
step: 120, loss: 0.05049193650484085
step: 130, loss: 0.03260601684451103
step: 140, loss: 0.14504505693912506
step: 150, loss: 0.07008746266365051
step: 160, loss: 0.09012022614479065
step: 170, loss: 0.018723636865615845
step: 180, loss: 0.07021773606538773
step: 190, loss: 0.06086979806423187
step: 200, loss: 0.012244199402630329
step: 210, loss: 0.016982361674308777
step: 220, loss: 0.016690567135810852
step: 230, loss: 0.01697332225739956
step: 240, loss: 0.10260868817567825
step: 250, loss: 0.011980226263403893
step: 260, loss: 0.023680148646235466
step: 270, loss: 0.08419352024793625
step: 280, loss: 0.01235715951770544
step: 290, loss: 0.0717991441488266
step: 300, loss: 0.1308513581752777
step: 310, loss: 0.08529867231845856
step: 320, loss: 0.02871263585984707
step: 330, loss: 0.022021323442459106
step: 340, loss: 0.010366806760430336
step: 350, loss: 0.028717583045363426
step: 360, loss: 0.06382573395967484
step: 370, loss: 0.007851995527744293
step: 380, loss: 0.004974168725311756
step: 390, loss: 0.0687224417924881
step: 400, loss: 0.11350160092115402
step: 410, loss: 0.06557444483041763
step: 420, loss: 0.011463556438684464
epoch 8: dev_f1=0.9909706546275394, f1=0.9808342728297633, best_f1=0.9808342728297633
step: 0, loss: 0.018383916467428207
step: 10, loss: 0.007111642509698868
step: 20, loss: 0.13555388152599335
step: 30, loss: 0.10761487483978271
step: 40, loss: 0.0002889575844164938
step: 50, loss: 0.12190255522727966
step: 60, loss: 0.06177746132016182
step: 70, loss: 0.01567625254392624
step: 80, loss: 0.06148581951856613
step: 90, loss: 0.06642504036426544
step: 100, loss: 0.019852984696626663
step: 110, loss: 0.02176690474152565
step: 120, loss: 0.006566139403730631
step: 130, loss: 0.01938490755856037
step: 140, loss: 0.00585369486361742
step: 150, loss: 0.07800471037626266
step: 160, loss: 0.009874798357486725
step: 170, loss: 0.17245545983314514
step: 180, loss: 0.02577824704349041
step: 190, loss: 0.006671281531453133
step: 200, loss: 0.08730679005384445
step: 210, loss: 0.07256350666284561
step: 220, loss: 0.0037814672105014324
step: 230, loss: 0.020386531949043274
step: 240, loss: 0.0053245909512043
step: 250, loss: 0.07002043724060059
step: 260, loss: 0.12339390814304352
step: 270, loss: 0.06835786998271942
step: 280, loss: 0.019938645884394646
step: 290, loss: 0.02876300923526287
step: 300, loss: 0.01315203309059143
step: 310, loss: 0.017497876659035683
step: 320, loss: 0.03977591171860695
step: 330, loss: 0.07044544816017151
step: 340, loss: 0.007291062735021114
step: 350, loss: 0.08317852765321732
step: 360, loss: 0.022703947499394417
step: 370, loss: 0.11505383998155594
step: 380, loss: 0.02381853014230728
step: 390, loss: 0.001694507198408246
step: 400, loss: 0.017554963007569313
step: 410, loss: 0.009603215381503105
step: 420, loss: 0.15619231760501862
epoch 9: dev_f1=0.9898762654668166, f1=0.9819819819819819, best_f1=0.9808342728297633
step: 0, loss: 0.028816305100917816
step: 10, loss: 0.009365221485495567
step: 20, loss: 0.13601809740066528
step: 30, loss: 0.06208140030503273
step: 40, loss: 0.08285848051309586
step: 50, loss: 0.03424600511789322
step: 60, loss: 0.14277678728103638
step: 70, loss: 0.00010084921086672693
step: 80, loss: 0.04092878848314285
step: 90, loss: 0.011578606441617012
step: 100, loss: 0.003635244909673929
step: 110, loss: 0.14472992718219757
step: 120, loss: 0.0002917173260357231
step: 130, loss: 0.017438244074583054
step: 140, loss: 0.006925294641405344
step: 150, loss: 0.013079601339995861
step: 160, loss: 0.06912826746702194
step: 170, loss: 0.10861683636903763
step: 180, loss: 0.0719536766409874
step: 190, loss: 0.06423638761043549
step: 200, loss: 0.21242976188659668
step: 210, loss: 0.14148613810539246
step: 220, loss: 0.0196033027023077
step: 230, loss: 0.000159609189722687
step: 240, loss: 0.0574599914252758
step: 250, loss: 0.05082380771636963
step: 260, loss: 0.029060596600174904
step: 270, loss: 0.06051307171583176
step: 280, loss: 0.013634953647851944
step: 290, loss: 0.018583793193101883
step: 300, loss: 0.016545824706554413
step: 310, loss: 0.0924796462059021
step: 320, loss: 0.016141580417752266
step: 330, loss: 0.062329769134521484
step: 340, loss: 0.09466896206140518
step: 350, loss: 0.027339085936546326
step: 360, loss: 0.03749255836009979
step: 370, loss: 0.013737939298152924
step: 380, loss: 0.07814045995473862
step: 390, loss: 0.02884337492287159
step: 400, loss: 0.08422698080539703
step: 410, loss: 0.035881854593753815
step: 420, loss: 0.003436233615502715
epoch 10: dev_f1=0.9921612541993281, f1=0.9810055865921787, best_f1=0.9810055865921787
step: 0, loss: 0.010536924935877323
step: 10, loss: 0.015424658544361591
step: 20, loss: 0.039779406040906906
step: 30, loss: 0.022883623838424683
step: 40, loss: 0.05879935622215271
step: 50, loss: 0.08446033298969269
step: 60, loss: 0.019524501636624336
step: 70, loss: 0.04971417412161827
step: 80, loss: 0.026084495708346367
step: 90, loss: 0.06916731595993042
step: 100, loss: 0.15246301889419556
step: 110, loss: 0.03437197953462601
step: 120, loss: 0.03277680650353432
step: 130, loss: 0.010113721713423729
step: 140, loss: 0.006898044142872095
step: 150, loss: 0.018192382529377937
step: 160, loss: 0.0893876701593399
step: 170, loss: 0.052551716566085815
step: 180, loss: 0.06721041351556778
step: 190, loss: 0.002122347941622138
step: 200, loss: 0.0928993970155716
step: 210, loss: 0.06382767111063004
step: 220, loss: 0.02214909717440605
step: 230, loss: 0.048908781260252
step: 240, loss: 0.017907992005348206
step: 250, loss: 0.0032120842952281237
step: 260, loss: 0.06425366550683975
step: 270, loss: 0.0810314416885376
step: 280, loss: 0.004520503804087639
step: 290, loss: 0.11900985985994339
step: 300, loss: 0.014106236398220062
step: 310, loss: 0.0010342833120375872
step: 320, loss: 0.023413797840476036
step: 330, loss: 0.08445584774017334
step: 340, loss: 0.05324074998497963
step: 350, loss: 0.061436787247657776
step: 360, loss: 0.0462910421192646
step: 370, loss: 0.02408798225224018
step: 380, loss: 0.06643663346767426
step: 390, loss: 0.12958979606628418
step: 400, loss: 0.011264016851782799
step: 410, loss: 0.050727590918540955
step: 420, loss: 0.02437618561089039
epoch 11: dev_f1=0.9921259842519685, f1=0.9820224719101124, best_f1=0.9810055865921787
step: 0, loss: 0.041281428188085556
step: 10, loss: 0.0717383548617363
step: 20, loss: 0.07801173627376556
step: 30, loss: 0.004757662769407034
step: 40, loss: 0.019791023805737495
step: 50, loss: 0.12281975150108337
step: 60, loss: 0.003995166160166264
step: 70, loss: 0.06175320968031883
step: 80, loss: 0.021821890026330948
step: 90, loss: 0.02340095303952694
step: 100, loss: 0.011400118470191956
step: 110, loss: 0.05587896704673767
step: 120, loss: 0.08108509331941605
step: 130, loss: 0.00959774386137724
step: 140, loss: 0.0645609200000763
step: 150, loss: 0.030156835913658142
step: 160, loss: 0.023823194205760956
step: 170, loss: 0.0004478305345401168
step: 180, loss: 0.03530653193593025
step: 190, loss: 0.02389371767640114
step: 200, loss: 0.002058878540992737
step: 210, loss: 0.06197725608944893
step: 220, loss: 0.03756183013319969
step: 230, loss: 0.0157985370606184
step: 240, loss: 0.05945375934243202
step: 250, loss: 0.0671669989824295
step: 260, loss: 0.048940692096948624
step: 270, loss: 0.03830145299434662
step: 280, loss: 0.04732923209667206
step: 290, loss: 0.021281003952026367
step: 300, loss: 0.12200701981782913
step: 310, loss: 0.0094583285972476
step: 320, loss: 0.12050867825746536
step: 330, loss: 0.1492536962032318
step: 340, loss: 0.06860459595918655
step: 350, loss: 0.04706472530961037
step: 360, loss: 0.02452011965215206
step: 370, loss: 0.009446047246456146
step: 380, loss: 0.03261549025774002
step: 390, loss: 0.02981690689921379
step: 400, loss: 0.0006638036575168371
step: 410, loss: 0.0287961196154356
step: 420, loss: 0.05514264851808548
epoch 12: dev_f1=0.9921436588103255, f1=0.9832026875699889, best_f1=0.9810055865921787
step: 0, loss: 0.04253387823700905
step: 10, loss: 0.0784243568778038
step: 20, loss: 0.030754243955016136
step: 30, loss: 0.005745626054704189
step: 40, loss: 0.045549675822257996
step: 50, loss: 0.035018451511859894
step: 60, loss: 0.054835524410009384
step: 70, loss: 0.058771368116140366
step: 80, loss: 0.0003933086700271815
step: 90, loss: 0.02574540302157402
step: 100, loss: 0.004240843467414379
step: 110, loss: 0.04509790614247322
step: 120, loss: 0.036843836307525635
step: 130, loss: 0.04408373311161995
step: 140, loss: 0.021506378427147865
step: 150, loss: 0.04797031357884407
step: 160, loss: 0.024371234700083733
step: 170, loss: 0.04693715274333954
step: 180, loss: 0.11161807179450989
step: 190, loss: 0.024151071906089783
step: 200, loss: 0.04046594351530075
step: 210, loss: 0.03377867862582207
step: 220, loss: 0.06575371325016022
step: 230, loss: 0.002958944533020258
step: 240, loss: 0.05173094943165779
step: 250, loss: 0.049365345388650894
step: 260, loss: 0.0011379875941202044
step: 270, loss: 0.07430148869752884
step: 280, loss: 0.06062033399939537
step: 290, loss: 0.0027549094520509243
step: 300, loss: 0.004288352560251951
step: 310, loss: 0.061940789222717285
step: 320, loss: 0.04338136687874794
step: 330, loss: 0.04162953048944473
step: 340, loss: 0.005833031143993139
step: 350, loss: 0.16320879757404327
step: 360, loss: 0.005152305122464895
step: 370, loss: 0.012320233508944511
step: 380, loss: 0.06914646923542023
step: 390, loss: 0.08259333670139313
step: 400, loss: 0.02432328276336193
step: 410, loss: 0.13972556591033936
step: 420, loss: 0.04605947062373161
epoch 13: dev_f1=0.9910112359550561, f1=0.9842696629213483, best_f1=0.9810055865921787
step: 0, loss: 0.020990531891584396
step: 10, loss: 0.03963470831513405
step: 20, loss: 0.1011757031083107
step: 30, loss: 0.014854658395051956
step: 40, loss: 0.0008797693881206214
step: 50, loss: 0.04460320994257927
step: 60, loss: 0.008180299773812294
step: 70, loss: 0.07463563978672028
step: 80, loss: 0.046156007796525955
step: 90, loss: 0.00016167794819921255
step: 100, loss: 0.005112340673804283
step: 110, loss: 0.007754369173198938
step: 120, loss: 0.0025507810059934855
step: 130, loss: 0.006871333811432123
step: 140, loss: 0.03743089362978935
step: 150, loss: 0.0847867876291275
step: 160, loss: 0.022455263882875443
step: 170, loss: 2.0726618458866142e-05
step: 180, loss: 0.08771315962076187
step: 190, loss: 0.07847468554973602
step: 200, loss: 0.013247878290712833
step: 210, loss: 0.04789728298783302
step: 220, loss: 0.047174129635095596
step: 230, loss: 0.018763262778520584
step: 240, loss: 0.14270392060279846
step: 250, loss: 0.027631349861621857
step: 260, loss: 0.01834745705127716
step: 270, loss: 0.06798102706670761
step: 280, loss: 0.04842719808220863
step: 290, loss: 0.02969220280647278
step: 300, loss: 0.019066669046878815
step: 310, loss: 0.0007962785311974585
step: 320, loss: 0.10486716032028198
step: 330, loss: 0.08361629396677017
step: 340, loss: 0.05509769544005394
step: 350, loss: 0.003074104432016611
step: 360, loss: 0.028011249378323555
step: 370, loss: 0.036096103489398956
step: 380, loss: 2.753419175860472e-05
step: 390, loss: 0.0319126732647419
step: 400, loss: 0.05396469682455063
step: 410, loss: 0.06922438740730286
step: 420, loss: 0.01694231852889061
epoch 14: dev_f1=0.9910112359550561, f1=0.9821029082774049, best_f1=0.9810055865921787
step: 0, loss: 0.04418135806918144
step: 10, loss: 0.027354318648576736
step: 20, loss: 0.00035977648803964257
step: 30, loss: 0.0790802538394928
step: 40, loss: 0.001022963784635067
step: 50, loss: 0.04427078738808632
step: 60, loss: 0.04894529655575752
step: 70, loss: 0.03006976842880249
step: 80, loss: 0.04146718978881836
step: 90, loss: 0.044912368059158325
step: 100, loss: 0.0035993866622447968
step: 110, loss: 0.0841231495141983
step: 120, loss: 0.011425158940255642
step: 130, loss: 0.004932830110192299
step: 140, loss: 0.03524470329284668
step: 150, loss: 0.03541828691959381
step: 160, loss: 0.07492541521787643
step: 170, loss: 0.048937924206256866
step: 180, loss: 0.00015850874478928745
step: 190, loss: 0.06862816214561462
step: 200, loss: 0.023888250812888145
step: 210, loss: 0.00012801939737983048
step: 220, loss: 0.08523589372634888
step: 230, loss: 0.05147169902920723
step: 240, loss: 0.02318587154150009
step: 250, loss: 0.02098993770778179
step: 260, loss: 0.01425902545452118
step: 270, loss: 0.07122137397527695
step: 280, loss: 0.0265398770570755
step: 290, loss: 0.002100149868056178
step: 300, loss: 0.05628751218318939
step: 310, loss: 0.02202538028359413
step: 320, loss: 0.0003261363599449396
step: 330, loss: 0.05754475295543671
step: 340, loss: 0.015086539089679718
step: 350, loss: 0.03493526577949524
step: 360, loss: 0.06703218817710876
step: 370, loss: 0.01011819951236248
step: 380, loss: 0.03690536692738533
step: 390, loss: 0.0001283565943595022
step: 400, loss: 0.04363038390874863
step: 410, loss: 0.024180809035897255
step: 420, loss: 0.028253067284822464
epoch 15: dev_f1=0.9920903954802259, f1=0.9829738933030647, best_f1=0.9810055865921787
step: 0, loss: 0.030132904648780823
step: 10, loss: 0.02223234251141548
step: 20, loss: 0.01563160866498947
step: 30, loss: 0.1069597452878952
step: 40, loss: 0.02365989238023758
step: 50, loss: 0.06645514070987701
step: 60, loss: 0.02216167002916336
step: 70, loss: 0.02744334377348423
step: 80, loss: 0.027202941477298737
step: 90, loss: 0.016879664734005928
step: 100, loss: 0.01879780925810337
step: 110, loss: 0.002203512005507946
step: 120, loss: 0.02486884407699108
step: 130, loss: 0.03292449191212654
step: 140, loss: 0.03391869366168976
step: 150, loss: 0.004805821925401688
step: 160, loss: 0.05805147439241409
step: 170, loss: 0.046456556767225266
step: 180, loss: 0.04352442920207977
step: 190, loss: 0.0151151018217206
step: 200, loss: 0.0752912163734436
step: 210, loss: 0.07136643677949905
step: 220, loss: 0.05724434554576874
step: 230, loss: 0.00044490324216894805
step: 240, loss: 0.029966965317726135
step: 250, loss: 0.08020288497209549
step: 260, loss: 0.00013046480307821184
step: 270, loss: 0.0008453219779767096
step: 280, loss: 0.030415592715144157
step: 290, loss: 0.042295414954423904
step: 300, loss: 0.024351218715310097
step: 310, loss: 0.02429346926510334
step: 320, loss: 0.06613565236330032
step: 330, loss: 0.031051740050315857
step: 340, loss: 0.05615715682506561
step: 350, loss: 0.05146709084510803
step: 360, loss: 0.04857570677995682
step: 370, loss: 0.0003506594803184271
step: 380, loss: 0.06394103914499283
step: 390, loss: 0.06875553727149963
step: 400, loss: 0.025158066302537918
step: 410, loss: 0.02470860444009304
step: 420, loss: 0.01696206070482731
epoch 16: dev_f1=0.9921259842519685, f1=0.9831271091113611, best_f1=0.9810055865921787
step: 0, loss: 0.03875425085425377
step: 10, loss: 0.02174481749534607
step: 20, loss: 0.007248787209391594
step: 30, loss: 0.026550913229584694
step: 40, loss: 0.000588956056162715
step: 50, loss: 0.021549653261899948
step: 60, loss: 0.0001783923653420061
step: 70, loss: 0.0011504681315273046
step: 80, loss: 0.04516126960515976
step: 90, loss: 0.0017741108313202858
step: 100, loss: 0.00016962140216492116
step: 110, loss: 0.02029416337609291
step: 120, loss: 0.24908018112182617
step: 130, loss: 0.03814692795276642
step: 140, loss: 0.00018668366828933358
step: 150, loss: 0.02606743760406971
step: 160, loss: 0.022670118138194084
step: 170, loss: 0.0878201276063919
step: 180, loss: 0.02280118688941002
step: 190, loss: 0.06232183426618576
step: 200, loss: 0.04751698300242424
step: 210, loss: 0.02043752186000347
step: 220, loss: 0.00028642427059821784
step: 230, loss: 0.02290426939725876
step: 240, loss: 0.11117391288280487
step: 250, loss: 0.04581679403781891
step: 260, loss: 0.0315135233104229
step: 270, loss: 4.852627535001375e-05
step: 280, loss: 0.023056281730532646
step: 290, loss: 0.056125231087207794
step: 300, loss: 0.023691166192293167
step: 310, loss: 0.022198187187314034
step: 320, loss: 0.056538499891757965
step: 330, loss: 0.03231813386082649
step: 340, loss: 0.1011553406715393
step: 350, loss: 0.006136768497526646
step: 360, loss: 0.023818882182240486
step: 370, loss: 0.049564603716135025
step: 380, loss: 0.0002566661569289863
step: 390, loss: 0.04208926111459732
step: 400, loss: 0.015502979047596455
step: 410, loss: 0.039286378771066666
step: 420, loss: 0.0014571757055819035
epoch 17: dev_f1=0.9910112359550561, f1=0.984304932735426, best_f1=0.9810055865921787
step: 0, loss: 0.09261079877614975
step: 10, loss: 0.01997641660273075
step: 20, loss: 0.023687927052378654
step: 30, loss: 3.6128938518231735e-05
step: 40, loss: 0.00021626998204737902
step: 50, loss: 0.00023617871920578182
step: 60, loss: 0.034938693046569824
step: 70, loss: 0.08386999368667603
step: 80, loss: 0.029419369995594025
step: 90, loss: 0.00016301199502777308
step: 100, loss: 0.07279373705387115
step: 110, loss: 0.17983122169971466
step: 120, loss: 0.025567932054400444
step: 130, loss: 1.2058631000400055e-05
step: 140, loss: 0.02501020021736622
step: 150, loss: 0.021712854504585266
step: 160, loss: 9.18923833523877e-05
step: 170, loss: 0.06454857438802719
step: 180, loss: 0.04055517911911011
step: 190, loss: 0.04087093099951744
step: 200, loss: 0.1202046200633049
step: 210, loss: 0.04258036985993385
step: 220, loss: 0.00013496726751327515
step: 230, loss: 0.08699562400579453
step: 240, loss: 0.022977683693170547
step: 250, loss: 0.03124590776860714
step: 260, loss: 0.018749579787254333
step: 270, loss: 7.397950685117394e-05
step: 280, loss: 0.048212215304374695
step: 290, loss: 0.019302349537611008
step: 300, loss: 0.021751277148723602
step: 310, loss: 0.0002168621140299365
step: 320, loss: 0.02031758613884449
step: 330, loss: 0.052278585731983185
step: 340, loss: 0.02400125376880169
step: 350, loss: 0.026667263358831406
step: 360, loss: 0.01953088492155075
step: 370, loss: 0.03410188853740692
step: 380, loss: 0.00030995794804766774
step: 390, loss: 9.575051080901176e-05
step: 400, loss: 0.043611571192741394
step: 410, loss: 0.018473604694008827
step: 420, loss: 0.025039156898856163
epoch 18: dev_f1=0.9910112359550561, f1=0.9832026875699889, best_f1=0.9810055865921787
step: 0, loss: 0.09697714447975159
step: 10, loss: 0.019222315400838852
step: 20, loss: 0.04922863841056824
step: 30, loss: 0.02027740329504013
step: 40, loss: 0.0001733099779812619
step: 50, loss: 0.022060854360461235
step: 60, loss: 0.01639995351433754
step: 70, loss: 0.024534616619348526
step: 80, loss: 0.017930859699845314
step: 90, loss: 0.06820721924304962
step: 100, loss: 0.013045172207057476
step: 110, loss: 0.02130763791501522
step: 120, loss: 0.019417690113186836
step: 130, loss: 0.042859844863414764
step: 140, loss: 0.020314672961831093
step: 150, loss: 0.05351279675960541
step: 160, loss: 0.02699320577085018
step: 170, loss: 0.00014227168867364526
step: 180, loss: 0.0002611674426589161
step: 190, loss: 0.00010392018884886056
step: 200, loss: 0.00021870629279874265
step: 210, loss: 0.021339016035199165
step: 220, loss: 0.02788432687520981
step: 230, loss: 0.06245770677924156
step: 240, loss: 0.0017234757542610168
step: 250, loss: 0.00019209521997254342
step: 260, loss: 0.022588681429624557
step: 270, loss: 0.05874253809452057
step: 280, loss: 0.07420169562101364
step: 290, loss: 0.020090823993086815
step: 300, loss: 0.04441569745540619
step: 310, loss: 0.01997416466474533
step: 320, loss: 0.03872903436422348
step: 330, loss: 0.03595687076449394
step: 340, loss: 0.020236628130078316
step: 350, loss: 0.02350095845758915
step: 360, loss: 0.062118176370859146
step: 370, loss: 0.0001265826722374186
step: 380, loss: 0.00022947853722143918
step: 390, loss: 6.051296804798767e-05
step: 400, loss: 0.040965158492326736
step: 410, loss: 0.020808447152376175
step: 420, loss: 0.0213894322514534
epoch 19: dev_f1=0.9921436588103255, f1=0.9810055865921787, best_f1=0.9810055865921787
step: 0, loss: 2.953975672426168e-05
step: 10, loss: 0.00010601137182675302
step: 20, loss: 3.6915305827278644e-05
step: 30, loss: 0.019235484302043915
step: 40, loss: 0.023531559854745865
step: 50, loss: 0.02141180820763111
step: 60, loss: 5.07108197780326e-05
step: 70, loss: 0.03722011670470238
step: 80, loss: 3.1767707696417347e-05
step: 90, loss: 0.019059855490922928
step: 100, loss: 0.021028585731983185
step: 110, loss: 0.06245550140738487
step: 120, loss: 0.021091699600219727
step: 130, loss: 0.04838203638792038
step: 140, loss: 0.012619469314813614
step: 150, loss: 0.014317725785076618
step: 160, loss: 5.71300188312307e-05
step: 170, loss: 0.025033218786120415
step: 180, loss: 0.09527076035737991
step: 190, loss: 0.019564189016819
step: 200, loss: 0.00032501466921530664
step: 210, loss: 6.329068128252402e-05
step: 220, loss: 8.336298924405128e-05
step: 230, loss: 0.004022000357508659
step: 240, loss: 0.06324369460344315
step: 250, loss: 0.045207053422927856
step: 260, loss: 0.02421349287033081
step: 270, loss: 4.9885733460541815e-05
step: 280, loss: 0.021005170419812202
step: 290, loss: 2.798235072987154e-05
step: 300, loss: 9.652967128204182e-05
step: 310, loss: 0.00012215302558615804
step: 320, loss: 0.034829411655664444
step: 330, loss: 0.022326897829771042
step: 340, loss: 0.00011800504580605775
step: 350, loss: 0.024790911003947258
step: 360, loss: 0.00029957303195260465
step: 370, loss: 0.06837701797485352
step: 380, loss: 0.06674698740243912
step: 390, loss: 0.020734624937176704
step: 400, loss: 0.00019828557560686022
step: 410, loss: 0.04200170561671257
step: 420, loss: 0.04234358295798302
epoch 20: dev_f1=0.9921436588103255, f1=0.9810055865921787, best_f1=0.9810055865921787
