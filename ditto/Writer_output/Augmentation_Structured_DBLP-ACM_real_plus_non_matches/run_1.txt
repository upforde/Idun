cuda
Device: cuda
step: 0, loss: 0.6471387147903442
step: 10, loss: 0.14339783787727356
step: 20, loss: 0.2297496199607849
step: 30, loss: 0.2801749110221863
step: 40, loss: 0.23559418320655823
step: 50, loss: 0.2084425389766693
step: 60, loss: 0.24351631104946136
step: 70, loss: 0.34171900153160095
step: 80, loss: 0.12138587236404419
step: 90, loss: 0.12078510224819183
step: 100, loss: 0.0790492594242096
step: 110, loss: 0.013885731808841228
step: 120, loss: 0.012082964181900024
step: 130, loss: 0.06085365638136864
step: 140, loss: 0.04440780356526375
step: 150, loss: 0.0652039498090744
step: 160, loss: 0.04140102490782738
step: 170, loss: 0.04151895269751549
step: 180, loss: 0.11189109086990356
step: 190, loss: 0.0276584904640913
step: 200, loss: 0.05850789695978165
step: 210, loss: 0.1376139521598816
step: 220, loss: 0.0944916158914566
step: 230, loss: 0.01159534603357315
step: 240, loss: 0.09007930755615234
step: 250, loss: 0.28160521388053894
step: 260, loss: 0.05402746796607971
step: 270, loss: 0.0639822706580162
step: 280, loss: 0.17194697260856628
step: 290, loss: 0.012823033146560192
step: 300, loss: 0.2391214370727539
step: 310, loss: 0.011119911447167397
step: 320, loss: 0.04178399220108986
step: 330, loss: 0.057018812745809555
step: 340, loss: 0.038704097270965576
step: 350, loss: 0.09402603656053543
step: 360, loss: 0.08581811189651489
step: 370, loss: 0.013879645615816116
step: 380, loss: 0.03920372575521469
step: 390, loss: 0.3024634122848511
step: 400, loss: 0.035110849887132645
step: 410, loss: 0.08407115936279297
step: 420, loss: 0.08904971182346344
epoch 1: dev_f1=0.9910313901345291, f1=0.9821029082774049, best_f1=0.9821029082774049
step: 0, loss: 0.12957420945167542
step: 10, loss: 0.10769622772932053
step: 20, loss: 0.030299827456474304
step: 30, loss: 0.06658604741096497
step: 40, loss: 0.07308097928762436
step: 50, loss: 0.011644957587122917
step: 60, loss: 0.08174405246973038
step: 70, loss: 0.15502384305000305
step: 80, loss: 0.12742023169994354
step: 90, loss: 0.020604930818080902
step: 100, loss: 0.0926264151930809
step: 110, loss: 0.016344133764505386
step: 120, loss: 0.011269097216427326
step: 130, loss: 0.03527844324707985
step: 140, loss: 0.029353337362408638
step: 150, loss: 0.14795176684856415
step: 160, loss: 0.2002730369567871
step: 170, loss: 0.062062304466962814
step: 180, loss: 0.016515014693140984
step: 190, loss: 0.05650101229548454
step: 200, loss: 0.03889758139848709
step: 210, loss: 0.022319268435239792
step: 220, loss: 0.16649100184440613
step: 230, loss: 0.00947754830121994
step: 240, loss: 0.15298780798912048
step: 250, loss: 0.08392754197120667
step: 260, loss: 0.07564806938171387
step: 270, loss: 0.010215860791504383
step: 280, loss: 0.15391913056373596
step: 290, loss: 0.01736496575176716
step: 300, loss: 0.0712372288107872
step: 310, loss: 0.019117332994937897
step: 320, loss: 0.10848418623209
step: 330, loss: 0.046285659074783325
step: 340, loss: 0.018502799794077873
step: 350, loss: 0.15724720060825348
step: 360, loss: 0.1167706698179245
step: 370, loss: 0.03553110361099243
step: 380, loss: 0.1900928020477295
step: 390, loss: 0.07374413311481476
step: 400, loss: 0.08157239109277725
step: 410, loss: 0.07140286266803741
step: 420, loss: 0.08298259973526001
epoch 2: dev_f1=0.9887133182844244, f1=0.9819413092550789, best_f1=0.9821029082774049
step: 0, loss: 0.07399039715528488
step: 10, loss: 0.13090869784355164
step: 20, loss: 0.07164046168327332
step: 30, loss: 0.07747591286897659
step: 40, loss: 0.14836309850215912
step: 50, loss: 0.014353717677295208
step: 60, loss: 0.019663304090499878
step: 70, loss: 0.07310795783996582
step: 80, loss: 0.1452265828847885
step: 90, loss: 0.14342351257801056
step: 100, loss: 0.06055080145597458
step: 110, loss: 0.00669114151969552
step: 120, loss: 0.008666379377245903
step: 130, loss: 0.03387437388300896
step: 140, loss: 0.27644082903862
step: 150, loss: 0.02437923289835453
step: 160, loss: 0.0227963849902153
step: 170, loss: 0.10000789910554886
step: 180, loss: 0.060209959745407104
step: 190, loss: 0.09742531180381775
step: 200, loss: 0.03262151777744293
step: 210, loss: 0.17596693336963654
step: 220, loss: 0.012507982552051544
step: 230, loss: 0.006238417234271765
step: 240, loss: 0.01285518053919077
step: 250, loss: 0.06979578733444214
step: 260, loss: 0.022379379719495773
step: 270, loss: 0.01604454219341278
step: 280, loss: 0.07598726451396942
step: 290, loss: 0.014876516535878181
step: 300, loss: 0.11107704043388367
step: 310, loss: 0.0662543773651123
step: 320, loss: 0.14598935842514038
step: 330, loss: 0.0407949760556221
step: 340, loss: 0.01479316782206297
step: 350, loss: 0.027182798832654953
step: 360, loss: 0.10676942020654678
step: 370, loss: 0.007062384393066168
step: 380, loss: 0.06930719316005707
step: 390, loss: 0.1184234470129013
step: 400, loss: 0.16936922073364258
step: 410, loss: 0.016523119062185287
step: 420, loss: 0.12457669526338577
epoch 3: dev_f1=0.9921436588103255, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 0.08257294446229935
step: 10, loss: 0.006387338973581791
step: 20, loss: 0.06675774604082108
step: 30, loss: 0.13772274553775787
step: 40, loss: 0.1290082484483719
step: 50, loss: 0.05450090765953064
step: 60, loss: 0.02753479778766632
step: 70, loss: 0.06316942721605301
step: 80, loss: 0.011860494501888752
step: 90, loss: 0.10284721106290817
step: 100, loss: 0.06349744647741318
step: 110, loss: 0.11209461838006973
step: 120, loss: 0.004228164907544851
step: 130, loss: 0.16058196127414703
step: 140, loss: 0.020620377734303474
step: 150, loss: 0.018587078899145126
step: 160, loss: 0.023900043219327927
step: 170, loss: 0.07402239739894867
step: 180, loss: 0.008499132469296455
step: 190, loss: 0.15208549797534943
step: 200, loss: 0.06874474883079529
step: 210, loss: 0.018480580300092697
step: 220, loss: 0.03771935775876045
step: 230, loss: 0.050904154777526855
step: 240, loss: 0.014994576573371887
step: 250, loss: 0.017520012333989143
step: 260, loss: 0.00421740859746933
step: 270, loss: 0.02370709553360939
step: 280, loss: 0.1509132981300354
step: 290, loss: 0.019834283739328384
step: 300, loss: 0.015991028398275375
step: 310, loss: 0.0005625967751257122
step: 320, loss: 0.026476724073290825
step: 330, loss: 0.07054264843463898
step: 340, loss: 0.07332786172628403
step: 350, loss: 0.024360811337828636
step: 360, loss: 0.02536083199083805
step: 370, loss: 0.12030724436044693
step: 380, loss: 0.03019338846206665
step: 390, loss: 0.06774494796991348
step: 400, loss: 0.02012087032198906
step: 410, loss: 0.08666747063398361
step: 420, loss: 0.08132095634937286
epoch 4: dev_f1=0.9865771812080537, f1=0.9775784753363228, best_f1=0.984304932735426
step: 0, loss: 0.00942172296345234
step: 10, loss: 0.07493006438016891
step: 20, loss: 0.13226473331451416
step: 30, loss: 0.25412607192993164
step: 40, loss: 0.15128256380558014
step: 50, loss: 0.09213390946388245
step: 60, loss: 0.06868009269237518
step: 70, loss: 0.10344645380973816
step: 80, loss: 0.27152109146118164
step: 90, loss: 0.011514724232256413
step: 100, loss: 0.18547457456588745
step: 110, loss: 0.009755882434546947
step: 120, loss: 0.0674496442079544
step: 130, loss: 0.13677862286567688
step: 140, loss: 0.07646723836660385
step: 150, loss: 0.027115672826766968
step: 160, loss: 0.019655559211969376
step: 170, loss: 0.02619360387325287
step: 180, loss: 0.09754031151533127
step: 190, loss: 0.06489669531583786
step: 200, loss: 0.011518990620970726
step: 210, loss: 0.01912005804479122
step: 220, loss: 0.08944752812385559
step: 230, loss: 0.010136150754988194
step: 240, loss: 0.062028687447309494
step: 250, loss: 0.004136921837925911
step: 260, loss: 0.16283230483531952
step: 270, loss: 0.024789033457636833
step: 280, loss: 0.06286522001028061
step: 290, loss: 0.019253134727478027
step: 300, loss: 0.006098660174757242
step: 310, loss: 0.0075831664726138115
step: 320, loss: 0.05086997151374817
step: 330, loss: 0.010185156017541885
step: 340, loss: 0.020986482501029968
step: 350, loss: 0.023891057819128036
step: 360, loss: 0.08044112473726273
step: 370, loss: 0.018297243863344193
step: 380, loss: 0.04613631218671799
step: 390, loss: 0.045187972486019135
step: 400, loss: 0.0001784045743988827
step: 410, loss: 0.06361765414476395
step: 420, loss: 0.028853081166744232
epoch 5: dev_f1=0.9932885906040269, f1=0.9844444444444443, best_f1=0.9844444444444443
step: 0, loss: 0.09183163940906525
step: 10, loss: 0.1069972887635231
step: 20, loss: 0.010982982814311981
step: 30, loss: 0.04317765682935715
step: 40, loss: 0.05626551806926727
step: 50, loss: 0.07541405409574509
step: 60, loss: 0.1502700001001358
step: 70, loss: 0.012629765085875988
step: 80, loss: 0.07025090605020523
step: 90, loss: 0.06746157258749008
step: 100, loss: 0.16510066390037537
step: 110, loss: 0.06414936482906342
step: 120, loss: 0.04820067062973976
step: 130, loss: 0.09532339870929718
step: 140, loss: 0.06982182711362839
step: 150, loss: 0.016949042677879333
step: 160, loss: 0.09156093001365662
step: 170, loss: 0.10977116227149963
step: 180, loss: 0.016086550429463387
step: 190, loss: 0.036233678460121155
step: 200, loss: 0.01902155391871929
step: 210, loss: 0.1208774596452713
step: 220, loss: 0.00024086012854240835
step: 230, loss: 0.017618326470255852
step: 240, loss: 0.06458485126495361
step: 250, loss: 0.0805390253663063
step: 260, loss: 0.019147271290421486
step: 270, loss: 0.1169876828789711
step: 280, loss: 0.06751509755849838
step: 290, loss: 0.05004372075200081
step: 300, loss: 0.1610012948513031
step: 310, loss: 0.0064261192455887794
step: 320, loss: 0.03634338453412056
step: 330, loss: 0.08410738408565521
step: 340, loss: 0.15545804798603058
step: 350, loss: 0.024371083825826645
step: 360, loss: 0.027531100437045097
step: 370, loss: 0.015034996904432774
step: 380, loss: 0.017034875229001045
step: 390, loss: 0.05405120551586151
step: 400, loss: 0.00409665098413825
step: 410, loss: 0.21706873178482056
step: 420, loss: 0.0704454705119133
epoch 6: dev_f1=0.9887387387387387, f1=0.9865168539325843, best_f1=0.9844444444444443
step: 0, loss: 0.013136396184563637
step: 10, loss: 0.06647086888551712
step: 20, loss: 0.10049304366111755
step: 30, loss: 0.035603828728199005
step: 40, loss: 0.0707612931728363
step: 50, loss: 0.07480502128601074
step: 60, loss: 0.013061938807368279
step: 70, loss: 0.017597245052456856
step: 80, loss: 0.055422645062208176
step: 90, loss: 0.08276958018541336
step: 100, loss: 0.07998443394899368
step: 110, loss: 0.03615913167595863
step: 120, loss: 0.019865715876221657
step: 130, loss: 7.85046795499511e-05
step: 140, loss: 0.041952766478061676
step: 150, loss: 0.004569732118397951
step: 160, loss: 0.0215674489736557
step: 170, loss: 0.08541088551282883
step: 180, loss: 0.025173543021082878
step: 190, loss: 0.0711572989821434
step: 200, loss: 0.009187661111354828
step: 210, loss: 0.09398339688777924
step: 220, loss: 0.015683090314269066
step: 230, loss: 0.14762404561042786
step: 240, loss: 0.013223176822066307
step: 250, loss: 0.0080643892288208
step: 260, loss: 0.018766751512885094
step: 270, loss: 0.014740781858563423
step: 280, loss: 0.061550259590148926
step: 290, loss: 0.09652020037174225
step: 300, loss: 0.15958626568317413
step: 310, loss: 0.0659627765417099
step: 320, loss: 0.09839135408401489
step: 330, loss: 0.011621318757534027
step: 340, loss: 0.06117750331759453
step: 350, loss: 0.10529205203056335
step: 360, loss: 0.018552275374531746
step: 370, loss: 0.02343282289803028
step: 380, loss: 0.010376444086432457
step: 390, loss: 0.06703507900238037
step: 400, loss: 0.09087127447128296
step: 410, loss: 0.2150658369064331
step: 420, loss: 0.018872741609811783
epoch 7: dev_f1=0.9887387387387387, f1=0.9865168539325843, best_f1=0.9844444444444443
step: 0, loss: 0.08666641265153885
step: 10, loss: 0.038716476410627365
step: 20, loss: 0.019248299300670624
step: 30, loss: 0.04227199777960777
step: 40, loss: 0.03289846330881119
step: 50, loss: 0.0853903517127037
step: 60, loss: 0.04939667880535126
step: 70, loss: 0.013692658394575119
step: 80, loss: 0.06139509379863739
step: 90, loss: 0.009016871452331543
step: 100, loss: 0.07432521134614944
step: 110, loss: 0.019160520285367966
step: 120, loss: 0.19023050367832184
step: 130, loss: 0.048577021807432175
step: 140, loss: 0.15820828080177307
step: 150, loss: 0.0593818798661232
step: 160, loss: 0.08700312674045563
step: 170, loss: 0.016288748010993004
step: 180, loss: 0.05062130466103554
step: 190, loss: 0.02304384484887123
step: 200, loss: 0.037619929760694504
step: 210, loss: 0.07270541787147522
step: 220, loss: 0.1036822497844696
step: 230, loss: 0.011886903084814548
step: 240, loss: 0.02277473919093609
step: 250, loss: 0.0034440397284924984
step: 260, loss: 4.189740138826892e-05
step: 270, loss: 0.01366982702165842
step: 280, loss: 0.05955439433455467
step: 290, loss: 0.146681547164917
step: 300, loss: 0.021632511168718338
step: 310, loss: 0.017899062484502792
step: 320, loss: 0.1290636956691742
step: 330, loss: 0.09838846325874329
step: 340, loss: 0.07040411233901978
step: 350, loss: 0.03272493556141853
step: 360, loss: 0.03416118025779724
step: 370, loss: 0.20465879142284393
step: 380, loss: 0.038469210267066956
step: 390, loss: 0.06778921186923981
step: 400, loss: 0.08461728692054749
step: 410, loss: 0.015259716659784317
step: 420, loss: 0.0011454648338258266
epoch 8: dev_f1=0.9899216125419933, f1=0.9843749999999999, best_f1=0.9844444444444443
step: 0, loss: 0.09780465066432953
step: 10, loss: 0.05140046030282974
step: 20, loss: 0.02654918283224106
step: 30, loss: 0.11710197478532791
step: 40, loss: 0.033811599016189575
step: 50, loss: 0.05492723733186722
step: 60, loss: 0.007519930601119995
step: 70, loss: 0.006162984762340784
step: 80, loss: 0.09100065380334854
step: 90, loss: 0.025332942605018616
step: 100, loss: 0.10064942389726639
step: 110, loss: 0.13606885075569153
step: 120, loss: 0.09959950298070908
step: 130, loss: 0.0702185183763504
step: 140, loss: 0.018061190843582153
step: 150, loss: 0.016365837305784225
step: 160, loss: 0.09131098538637161
step: 170, loss: 0.004644464701414108
step: 180, loss: 0.1467037945985794
step: 190, loss: 0.14242962002754211
step: 200, loss: 0.07393249869346619
step: 210, loss: 0.05527251213788986
step: 220, loss: 0.010688635520637035
step: 230, loss: 0.05114768072962761
step: 240, loss: 0.009183683432638645
step: 250, loss: 0.005812793970108032
step: 260, loss: 0.03322892636060715
step: 270, loss: 0.00432190764695406
step: 280, loss: 0.007048452738672495
step: 290, loss: 0.08033914864063263
step: 300, loss: 0.12212687730789185
step: 310, loss: 0.020472489297389984
step: 320, loss: 0.01576811634004116
step: 330, loss: 0.01903144270181656
step: 340, loss: 0.008871620520949364
step: 350, loss: 0.013960497453808784
step: 360, loss: 0.027640262618660927
step: 370, loss: 0.013149100355803967
step: 380, loss: 0.07607066631317139
step: 390, loss: 0.05311715230345726
step: 400, loss: 0.07784410566091537
step: 410, loss: 0.07666493207216263
step: 420, loss: 0.00206380826421082
epoch 9: dev_f1=0.9910112359550561, f1=0.9887640449438202, best_f1=0.9844444444444443
step: 0, loss: 0.004822155926376581
step: 10, loss: 0.00017570013005752116
step: 20, loss: 0.03023373894393444
step: 30, loss: 0.01106194406747818
step: 40, loss: 0.14817458391189575
step: 50, loss: 0.09325011074542999
step: 60, loss: 0.005474706180393696
step: 70, loss: 0.026248179376125336
step: 80, loss: 0.05726293846964836
step: 90, loss: 0.07076124101877213
step: 100, loss: 0.010832546278834343
step: 110, loss: 0.032608307898044586
step: 120, loss: 2.9686229026992805e-05
step: 130, loss: 0.018345307558774948
step: 140, loss: 0.0017181576695293188
step: 150, loss: 0.008156216703355312
step: 160, loss: 0.006521345116198063
step: 170, loss: 0.0016608466394245625
step: 180, loss: 0.0017311880365014076
step: 190, loss: 0.02512526325881481
step: 200, loss: 0.004474518354982138
step: 210, loss: 0.0032688016071915627
step: 220, loss: 0.07575851678848267
step: 230, loss: 0.11444302648305893
step: 240, loss: 0.05164269357919693
step: 250, loss: 0.07741665095090866
step: 260, loss: 0.0690494254231453
step: 270, loss: 0.08607897162437439
step: 280, loss: 0.007996171712875366
step: 290, loss: 0.005854202434420586
step: 300, loss: 0.02947177365422249
step: 310, loss: 0.024049239233136177
step: 320, loss: 0.009275484830141068
step: 330, loss: 0.11363819986581802
step: 340, loss: 0.012827891856431961
step: 350, loss: 0.008662141859531403
step: 360, loss: 0.01567060872912407
step: 370, loss: 0.03398425504565239
step: 380, loss: 0.061310432851314545
step: 390, loss: 0.07429506629705429
step: 400, loss: 0.007869917899370193
step: 410, loss: 0.049078550189733505
step: 420, loss: 0.0406356118619442
epoch 10: dev_f1=0.9910313901345291, f1=0.9843400447427293, best_f1=0.9844444444444443
step: 0, loss: 0.01183145772665739
step: 10, loss: 0.0032109059393405914
step: 20, loss: 0.00024337384093087167
step: 30, loss: 0.04984886199235916
step: 40, loss: 0.06166047975420952
step: 50, loss: 0.003983251750469208
step: 60, loss: 0.04476555809378624
step: 70, loss: 0.003199605271220207
step: 80, loss: 0.022688671946525574
step: 90, loss: 0.0661088153719902
step: 100, loss: 0.06631232798099518
step: 110, loss: 0.0024397389497607946
step: 120, loss: 0.047086868435144424
step: 130, loss: 0.10360793769359589
step: 140, loss: 0.0319058857858181
step: 150, loss: 0.029124554246664047
step: 160, loss: 0.03969670087099075
step: 170, loss: 0.02642272226512432
step: 180, loss: 0.0024786097928881645
step: 190, loss: 0.04786515608429909
step: 200, loss: 0.09026322513818741
step: 210, loss: 0.126364603638649
step: 220, loss: 0.15387092530727386
step: 230, loss: 0.0305830929428339
step: 240, loss: 0.005719941109418869
step: 250, loss: 0.06996500492095947
step: 260, loss: 0.0372806042432785
step: 270, loss: 0.0790993720293045
step: 280, loss: 0.10353370010852814
step: 290, loss: 0.003145017195492983
step: 300, loss: 0.0015732867177575827
step: 310, loss: 3.485973138595e-05
step: 320, loss: 0.13607487082481384
step: 330, loss: 0.08490672707557678
step: 340, loss: 0.04538692533969879
step: 350, loss: 0.048154208809137344
step: 360, loss: 0.09086307138204575
step: 370, loss: 0.1906132996082306
step: 380, loss: 0.01863151416182518
step: 390, loss: 0.03855389356613159
step: 400, loss: 0.01891981065273285
step: 410, loss: 0.0013381910976022482
step: 420, loss: 0.031150024384260178
epoch 11: dev_f1=0.9761634506242906, f1=0.9667812142038945, best_f1=0.9844444444444443
step: 0, loss: 0.03631626069545746
step: 10, loss: 0.054616138339042664
step: 20, loss: 0.027448350563645363
step: 30, loss: 0.023635223507881165
step: 40, loss: 0.03585192188620567
step: 50, loss: 0.0017872503958642483
step: 60, loss: 0.009667996317148209
step: 70, loss: 0.030597323551774025
step: 80, loss: 0.04462483152747154
step: 90, loss: 0.03689412400126457
step: 100, loss: 0.02485833503305912
step: 110, loss: 0.009031145833432674
step: 120, loss: 0.0004546830605249852
step: 130, loss: 0.0034145722165703773
step: 140, loss: 0.08543349802494049
step: 150, loss: 2.2202460968401283e-05
step: 160, loss: 0.09722115099430084
step: 170, loss: 0.0029468766879290342
step: 180, loss: 0.02748773992061615
step: 190, loss: 0.07491444796323776
step: 200, loss: 0.01757701300084591
step: 210, loss: 0.0031283022835850716
step: 220, loss: 0.024937845766544342
step: 230, loss: 0.00010620006651151925
step: 240, loss: 0.02427522838115692
step: 250, loss: 0.06672793626785278
step: 260, loss: 0.0753355398774147
step: 270, loss: 0.0004320626030676067
step: 280, loss: 0.08682699501514435
step: 290, loss: 0.018387148156762123
step: 300, loss: 0.05548248440027237
step: 310, loss: 2.102899998135399e-05
step: 320, loss: 0.008704192005097866
step: 330, loss: 0.03898560628294945
step: 340, loss: 0.032395269721746445
step: 350, loss: 0.10065104067325592
step: 360, loss: 0.115237757563591
step: 370, loss: 0.028175245970487595
step: 380, loss: 0.0023206810001283884
step: 390, loss: 0.03992544487118721
step: 400, loss: 0.0005557521362788975
step: 410, loss: 0.0007983268587850034
step: 420, loss: 0.0005005834391340613
epoch 12: dev_f1=0.9910514541387023, f1=0.9842696629213483, best_f1=0.9844444444444443
step: 0, loss: 0.025833843275904655
step: 10, loss: 0.024774692952632904
step: 20, loss: 0.03386809676885605
step: 30, loss: 0.02875906229019165
step: 40, loss: 0.06812038272619247
step: 50, loss: 0.0036365617997944355
step: 60, loss: 0.0019426718354225159
step: 70, loss: 9.272179886465892e-05
step: 80, loss: 0.0331486314535141
step: 90, loss: 0.0005897036171518266
step: 100, loss: 0.11081195622682571
step: 110, loss: 0.005909512285143137
step: 120, loss: 0.02459621988236904
step: 130, loss: 0.05119635909795761
step: 140, loss: 0.06818048655986786
step: 150, loss: 0.015190553851425648
step: 160, loss: 0.06851769983768463
step: 170, loss: 0.012719115242362022
step: 180, loss: 0.010584425181150436
step: 190, loss: 0.028552185744047165
step: 200, loss: 0.1225133016705513
step: 210, loss: 0.01945653185248375
step: 220, loss: 0.03365718573331833
step: 230, loss: 0.03667744994163513
step: 240, loss: 0.000573068275116384
step: 250, loss: 0.03635210543870926
step: 260, loss: 0.04438989609479904
step: 270, loss: 0.0002713162684813142
step: 280, loss: 0.08583397418260574
step: 290, loss: 0.014495781622827053
step: 300, loss: 0.025393711403012276
step: 310, loss: 0.03439358249306679
step: 320, loss: 0.004172876011580229
step: 330, loss: 0.043770238757133484
step: 340, loss: 0.0005411638412624598
step: 350, loss: 0.018907003104686737
step: 360, loss: 0.026667065918445587
step: 370, loss: 0.05169656500220299
step: 380, loss: 0.05350775644183159
step: 390, loss: 0.00016098735795821995
step: 400, loss: 0.014854338951408863
step: 410, loss: 0.02909083664417267
step: 420, loss: 0.00019712383800651878
epoch 13: dev_f1=0.9932584269662922, f1=0.9820224719101124, best_f1=0.9844444444444443
step: 0, loss: 0.06258068978786469
step: 10, loss: 0.01851128414273262
step: 20, loss: 0.03987640514969826
step: 30, loss: 0.002356104087084532
step: 40, loss: 7.193718920461833e-05
step: 50, loss: 0.0040346975438296795
step: 60, loss: 0.020016631111502647
step: 70, loss: 0.00026125446311198175
step: 80, loss: 0.056617606431245804
step: 90, loss: 0.03722802549600601
step: 100, loss: 0.04037073254585266
step: 110, loss: 0.005848682019859552
step: 120, loss: 0.04822484776377678
step: 130, loss: 0.1188991516828537
step: 140, loss: 0.0004170603642705828
step: 150, loss: 0.11598936468362808
step: 160, loss: 0.016663286834955215
step: 170, loss: 0.0018506821943446994
step: 180, loss: 0.01735486462712288
step: 190, loss: 0.0024604531936347485
step: 200, loss: 0.0696946382522583
step: 210, loss: 0.0005560271092690527
step: 220, loss: 0.05485397204756737
step: 230, loss: 0.041627202183008194
step: 240, loss: 0.054849084466695786
step: 250, loss: 0.00013491735444404185
step: 260, loss: 0.07774261385202408
step: 270, loss: 0.03251471742987633
step: 280, loss: 0.00011290084512438625
step: 290, loss: 0.025892620906233788
step: 300, loss: 0.0001558545045554638
step: 310, loss: 0.000606690242420882
step: 320, loss: 0.023934906348586082
step: 330, loss: 0.022984258830547333
step: 340, loss: 0.00041588384192436934
step: 350, loss: 0.038241080939769745
step: 360, loss: 0.003303671255707741
step: 370, loss: 0.02200348675251007
step: 380, loss: 0.021662188693881035
step: 390, loss: 0.00022969165001995862
step: 400, loss: 0.05254784971475601
step: 410, loss: 0.23937185108661652
step: 420, loss: 0.0019634258933365345
epoch 14: dev_f1=0.9932735426008968, f1=0.9820627802690582, best_f1=0.9844444444444443
step: 0, loss: 0.03887127712368965
step: 10, loss: 0.02143097296357155
step: 20, loss: 0.07171128690242767
step: 30, loss: 0.019903700798749924
step: 40, loss: 0.03913656994700432
step: 50, loss: 0.061567384749650955
step: 60, loss: 0.0005851210444234312
step: 70, loss: 0.04214128851890564
step: 80, loss: 0.0001513599418103695
step: 90, loss: 0.02043868415057659
step: 100, loss: 0.08614834398031235
step: 110, loss: 0.03774377703666687
step: 120, loss: 0.002118444535881281
step: 130, loss: 0.039095327258110046
step: 140, loss: 0.057176049798727036
step: 150, loss: 0.015908095985651016
step: 160, loss: 0.08163459599018097
step: 170, loss: 0.018596382811665535
step: 180, loss: 0.00011318049655528739
step: 190, loss: 0.0005945723387412727
step: 200, loss: 0.00021366443252190948
step: 210, loss: 0.017267417162656784
step: 220, loss: 0.00023956544464454055
step: 230, loss: 0.03510790690779686
step: 240, loss: 0.0322161428630352
step: 250, loss: 0.017864616587758064
step: 260, loss: 0.002606807043775916
step: 270, loss: 0.02612033113837242
step: 280, loss: 0.12588651478290558
step: 290, loss: 0.07199134677648544
step: 300, loss: 0.022466717287898064
step: 310, loss: 0.03980385139584541
step: 320, loss: 0.02235720120370388
step: 330, loss: 0.03277891129255295
step: 340, loss: 0.01862516812980175
step: 350, loss: 0.07311131060123444
step: 360, loss: 0.019953828305006027
step: 370, loss: 0.013888892717659473
step: 380, loss: 0.08819777518510818
step: 390, loss: 0.019111666828393936
step: 400, loss: 0.0195179283618927
step: 410, loss: 0.02405322715640068
step: 420, loss: 0.015577811747789383
epoch 15: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9844444444444443
step: 0, loss: 0.05667998641729355
step: 10, loss: 0.020311322063207626
step: 20, loss: 0.02044081874191761
step: 30, loss: 0.04482308030128479
step: 40, loss: 0.04861123114824295
step: 50, loss: 0.01878402568399906
step: 60, loss: 0.015856347978115082
step: 70, loss: 0.023676130920648575
step: 80, loss: 0.00010618847591103986
step: 90, loss: 0.04932248592376709
step: 100, loss: 0.02329428680241108
step: 110, loss: 0.072230264544487
step: 120, loss: 0.0400436669588089
step: 130, loss: 0.029345743358135223
step: 140, loss: 0.014489605091512203
step: 150, loss: 8.048930612858385e-05
step: 160, loss: 0.04826103523373604
step: 170, loss: 0.00010937108163489029
step: 180, loss: 0.023228295147418976
step: 190, loss: 0.02226129360496998
step: 200, loss: 0.008020714856684208
step: 210, loss: 0.01588560827076435
step: 220, loss: 0.03959294781088829
step: 230, loss: 0.01615281216800213
step: 240, loss: 0.0719030424952507
step: 250, loss: 0.02243470959365368
step: 260, loss: 0.026144541800022125
step: 270, loss: 0.00011103560245828703
step: 280, loss: 0.08268077671527863
step: 290, loss: 0.024173254147171974
step: 300, loss: 0.030095452442765236
step: 310, loss: 0.03311740234494209
step: 320, loss: 1.6945841707638465e-05
step: 330, loss: 0.033690452575683594
step: 340, loss: 0.04550359025597572
step: 350, loss: 0.05822444707155228
step: 360, loss: 0.04348360747098923
step: 370, loss: 0.017871009185910225
step: 380, loss: 0.040420982986688614
step: 390, loss: 0.03690230846405029
step: 400, loss: 0.024057162925601006
step: 410, loss: 0.052767906337976456
step: 420, loss: 0.0006166668608784676
epoch 16: dev_f1=0.9932584269662922, f1=0.9831649831649831, best_f1=0.9844444444444443
step: 0, loss: 0.021611951291561127
step: 10, loss: 0.09868021309375763
step: 20, loss: 0.07712956517934799
step: 30, loss: 0.03556954115629196
step: 40, loss: 0.044673264026641846
step: 50, loss: 0.016809074208140373
step: 60, loss: 0.016065670177340508
step: 70, loss: 0.02085494063794613
step: 80, loss: 0.020623397082090378
step: 90, loss: 0.04424603283405304
step: 100, loss: 0.0003216155164409429
step: 110, loss: 0.045932263135910034
step: 120, loss: 0.024981362745165825
step: 130, loss: 0.04427133500576019
step: 140, loss: 0.021943556144833565
step: 150, loss: 0.025745976716279984
step: 160, loss: 0.04263124614953995
step: 170, loss: 0.039092861115932465
step: 180, loss: 0.02201925218105316
step: 190, loss: 0.06733950972557068
step: 200, loss: 0.029044002294540405
step: 210, loss: 0.018019087612628937
step: 220, loss: 0.022735267877578735
step: 230, loss: 0.024926682934165
step: 240, loss: 0.022523047402501106
step: 250, loss: 0.06337378174066544
step: 260, loss: 0.043121423572301865
step: 270, loss: 0.0001027775724651292
step: 280, loss: 0.0013891805429011583
step: 290, loss: 9.360354306409135e-05
step: 300, loss: 0.0003504992346279323
step: 310, loss: 0.0035287742502987385
step: 320, loss: 0.00028266810113564134
step: 330, loss: 0.020348431542515755
step: 340, loss: 0.07736083120107651
step: 350, loss: 0.040144484490156174
step: 360, loss: 0.028577592223882675
step: 370, loss: 0.017967931926250458
step: 380, loss: 0.025590214878320694
step: 390, loss: 0.04901067167520523
step: 400, loss: 0.046613968908786774
step: 410, loss: 0.10243044048547745
step: 420, loss: 0.015079224482178688
epoch 17: dev_f1=0.9932432432432432, f1=0.9808773903262092, best_f1=0.9844444444444443
step: 0, loss: 0.0237506665289402
step: 10, loss: 0.0820423811674118
step: 20, loss: 0.029574338346719742
step: 30, loss: 0.02571975253522396
step: 40, loss: 0.00023561097623314708
step: 50, loss: 0.05558283254504204
step: 60, loss: 0.022335516288876534
step: 70, loss: 0.031722381711006165
step: 80, loss: 0.05434221029281616
step: 90, loss: 3.142129207844846e-05
step: 100, loss: 0.054670482873916626
step: 110, loss: 0.03839787840843201
step: 120, loss: 0.07147584110498428
step: 130, loss: 0.07414260506629944
step: 140, loss: 0.027953313663601875
step: 150, loss: 0.04962610825896263
step: 160, loss: 6.452481466112658e-05
step: 170, loss: 0.00014572704094462097
step: 180, loss: 0.042852405458688736
step: 190, loss: 0.01346533838659525
step: 200, loss: 0.0002588893985375762
step: 210, loss: 0.01754572242498398
step: 220, loss: 0.07576178014278412
step: 230, loss: 0.0010013093706220388
step: 240, loss: 0.00028248224407434464
step: 250, loss: 0.00010036155435955152
step: 260, loss: 0.059185001999139786
step: 270, loss: 0.025520486757159233
step: 280, loss: 0.02727973274886608
step: 290, loss: 0.000381409510737285
step: 300, loss: 0.021362800151109695
step: 310, loss: 0.05884457752108574
step: 320, loss: 0.05965025722980499
step: 330, loss: 0.018906090408563614
step: 340, loss: 9.166942618321627e-05
step: 350, loss: 7.161832036217675e-05
step: 360, loss: 0.062258031219244
step: 370, loss: 0.025569017976522446
step: 380, loss: 0.00042924389708787203
step: 390, loss: 0.05114583298563957
step: 400, loss: 3.838310658466071e-05
step: 410, loss: 0.0416192002594471
step: 420, loss: 0.0001216231394209899
epoch 18: dev_f1=0.9943883277216611, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 6.582635978702456e-05
step: 10, loss: 0.019532382488250732
step: 20, loss: 0.021757058799266815
step: 30, loss: 0.08191222697496414
step: 40, loss: 0.037618137896060944
step: 50, loss: 0.03709183633327484
step: 60, loss: 2.7556627173908055e-05
step: 70, loss: 0.022404639050364494
step: 80, loss: 0.017241081222891808
step: 90, loss: 0.03953609988093376
step: 100, loss: 5.169530777493492e-05
step: 110, loss: 0.06698001176118851
step: 120, loss: 0.046747975051403046
step: 130, loss: 9.403820877196267e-05
step: 140, loss: 0.03957896679639816
step: 150, loss: 0.06865419447422028
step: 160, loss: 0.02340433932840824
step: 170, loss: 0.03470753878355026
step: 180, loss: 0.00039291236316785216
step: 190, loss: 0.08636324107646942
step: 200, loss: 0.02210908569395542
step: 210, loss: 0.021267713978886604
step: 220, loss: 0.02108522318303585
step: 230, loss: 0.05757111310958862
step: 240, loss: 0.029369592666625977
step: 250, loss: 0.00010948459384962916
step: 260, loss: 0.02677823230624199
step: 270, loss: 0.01635495387017727
step: 280, loss: 0.0022503265645354986
step: 290, loss: 6.516423309221864e-05
step: 300, loss: 6.658177153440192e-05
step: 310, loss: 0.03649451583623886
step: 320, loss: 0.01982630044221878
step: 330, loss: 0.028155069798231125
step: 340, loss: 0.03840154781937599
step: 350, loss: 0.009667259640991688
step: 360, loss: 0.025018729269504547
step: 370, loss: 0.02371721714735031
step: 380, loss: 0.0442657470703125
step: 390, loss: 0.022423487156629562
step: 400, loss: 0.026442350819706917
step: 410, loss: 0.045119743794202805
step: 420, loss: 0.021713824942708015
epoch 19: dev_f1=0.9943883277216611, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 0.04385984688997269
step: 10, loss: 0.0004857652820646763
step: 20, loss: 0.018731893971562386
step: 30, loss: 0.026772217825055122
step: 40, loss: 0.00029174212249927223
step: 50, loss: 9.387265890836716e-05
step: 60, loss: 0.04001466929912567
step: 70, loss: 0.06287813931703568
step: 80, loss: 0.10205868631601334
step: 90, loss: 0.033182960003614426
step: 100, loss: 5.4613527026958764e-05
step: 110, loss: 0.019445665180683136
step: 120, loss: 0.062246669083833694
step: 130, loss: 0.021147653460502625
step: 140, loss: 0.00017014243348967284
step: 150, loss: 0.00014301555347628891
step: 160, loss: 0.000190909588127397
step: 170, loss: 0.027248680591583252
step: 180, loss: 5.390611113398336e-05
step: 190, loss: 8.06098323664628e-05
step: 200, loss: 9.545826469548047e-05
step: 210, loss: 0.0628373995423317
step: 220, loss: 0.051978856325149536
step: 230, loss: 0.027194324880838394
step: 240, loss: 0.019298000261187553
step: 250, loss: 0.03544805943965912
step: 260, loss: 0.024974139407277107
step: 270, loss: 0.04112548381090164
step: 280, loss: 0.024905605241656303
step: 290, loss: 0.0248626209795475
step: 300, loss: 0.04416194185614586
step: 310, loss: 0.022650448605418205
step: 320, loss: 0.055409155786037445
step: 330, loss: 0.021720733493566513
step: 340, loss: 0.06128232553601265
step: 350, loss: 0.012444849126040936
step: 360, loss: 0.00012954477278981358
step: 370, loss: 0.02313460409641266
step: 380, loss: 0.041597675532102585
step: 390, loss: 0.0004598155792336911
step: 400, loss: 0.03957279771566391
step: 410, loss: 0.031446412205696106
step: 420, loss: 0.024636387825012207
epoch 20: dev_f1=0.9932735426008968, f1=0.984304932735426, best_f1=0.984304932735426
