cuda
Device: cuda
step: 0, loss: 0.511840283870697
step: 10, loss: 0.48579004406929016
step: 20, loss: 0.3581801652908325
step: 30, loss: 0.331590861082077
step: 40, loss: 0.24382640421390533
step: 50, loss: 0.15065963566303253
step: 60, loss: 0.21712151169776917
step: 70, loss: 0.1691100150346756
step: 80, loss: 0.07968717813491821
step: 90, loss: 0.12474334985017776
step: 100, loss: 0.23788782954216003
step: 110, loss: 0.15952426195144653
step: 120, loss: 0.051317617297172546
step: 130, loss: 0.14859361946582794
step: 140, loss: 0.161740243434906
step: 150, loss: 0.04305204004049301
step: 160, loss: 0.03155316784977913
step: 170, loss: 0.021714461967349052
step: 180, loss: 0.013050307519733906
step: 190, loss: 0.2008054107427597
step: 200, loss: 0.07308100908994675
step: 210, loss: 0.11808017641305923
step: 220, loss: 0.029320260509848595
step: 230, loss: 0.3173828721046448
step: 240, loss: 0.06874320656061172
step: 250, loss: 0.027828814461827278
step: 260, loss: 0.058804795145988464
step: 270, loss: 0.024921944364905357
step: 280, loss: 0.19226506352424622
step: 290, loss: 0.030966047197580338
step: 300, loss: 0.09085948020219803
step: 310, loss: 0.0481618270277977
step: 320, loss: 0.08147471398115158
step: 330, loss: 0.06430958211421967
step: 340, loss: 0.1864652931690216
step: 350, loss: 0.07061328738927841
step: 360, loss: 0.041909366846084595
step: 370, loss: 0.048555999994277954
step: 380, loss: 0.02422335185110569
step: 390, loss: 0.03145475313067436
step: 400, loss: 0.019103018566966057
step: 410, loss: 0.014914820902049541
step: 420, loss: 0.04678330197930336
epoch 1: dev_f1=0.9898305084745763, f1=0.9831271091113611, best_f1=0.9831271091113611
step: 0, loss: 0.19992920756340027
step: 10, loss: 0.101277194917202
step: 20, loss: 0.07087518274784088
step: 30, loss: 0.037677645683288574
step: 40, loss: 0.1445789486169815
step: 50, loss: 0.06705337017774582
step: 60, loss: 0.14146316051483154
step: 70, loss: 0.054918453097343445
step: 80, loss: 0.11841748654842377
step: 90, loss: 0.054453667253255844
step: 100, loss: 0.005349301733076572
step: 110, loss: 0.09292332828044891
step: 120, loss: 0.11937469989061356
step: 130, loss: 0.033740077167749405
step: 140, loss: 0.10535934567451477
step: 150, loss: 0.11294250935316086
step: 160, loss: 0.08031181246042252
step: 170, loss: 0.030514754354953766
step: 180, loss: 0.0030745675321668386
step: 190, loss: 0.09689978510141373
step: 200, loss: 0.08445568382740021
step: 210, loss: 0.03912849724292755
step: 220, loss: 0.04637087509036064
step: 230, loss: 0.015008507296442986
step: 240, loss: 0.0848037376999855
step: 250, loss: 0.1251058727502823
step: 260, loss: 0.026022199541330338
step: 270, loss: 0.018771100789308548
step: 280, loss: 0.014993920922279358
step: 290, loss: 0.10851690918207169
step: 300, loss: 0.09258241206407547
step: 310, loss: 0.066342294216156
step: 320, loss: 0.011387607082724571
step: 330, loss: 0.06970757991075516
step: 340, loss: 0.14174923300743103
step: 350, loss: 0.008776409551501274
step: 360, loss: 0.022088488563895226
step: 370, loss: 0.06902206689119339
step: 380, loss: 0.09835576266050339
step: 390, loss: 0.0428183414041996
step: 400, loss: 0.08951031416654587
step: 410, loss: 0.12792985141277313
step: 420, loss: 0.03280281275510788
epoch 2: dev_f1=0.977728285077951, f1=0.9699666295884317, best_f1=0.9831271091113611
step: 0, loss: 0.14327436685562134
step: 10, loss: 0.02933802641928196
step: 20, loss: 0.07528554648160934
step: 30, loss: 0.06892421841621399
step: 40, loss: 0.08370501548051834
step: 50, loss: 0.05095355212688446
step: 60, loss: 0.043145790696144104
step: 70, loss: 0.19957786798477173
step: 80, loss: 0.04160867631435394
step: 90, loss: 0.031142404302954674
step: 100, loss: 0.014205419458448887
step: 110, loss: 0.11601230502128601
step: 120, loss: 0.11432530730962753
step: 130, loss: 0.16466043889522552
step: 140, loss: 0.03797762095928192
step: 150, loss: 0.10322312265634537
step: 160, loss: 0.0014887077268213034
step: 170, loss: 0.01427970826625824
step: 180, loss: 0.08483186364173889
step: 190, loss: 0.1279437094926834
step: 200, loss: 0.17803777754306793
step: 210, loss: 0.12832821905612946
step: 220, loss: 0.018519097939133644
step: 230, loss: 0.017239585518836975
step: 240, loss: 0.054619599133729935
step: 250, loss: 0.08442699164152145
step: 260, loss: 0.005584201775491238
step: 270, loss: 0.14707887172698975
step: 280, loss: 0.07846540212631226
step: 290, loss: 0.07205667346715927
step: 300, loss: 0.010628439486026764
step: 310, loss: 0.12697580456733704
step: 320, loss: 0.013564699329435825
step: 330, loss: 0.1321144998073578
step: 340, loss: 0.1161913201212883
step: 350, loss: 0.08104429394006729
step: 360, loss: 0.08019997924566269
step: 370, loss: 0.023706229403614998
step: 380, loss: 0.019392311573028564
step: 390, loss: 0.0236662607640028
step: 400, loss: 0.09394873678684235
step: 410, loss: 0.05965461581945419
step: 420, loss: 0.12900108098983765
epoch 3: dev_f1=0.9887387387387387, f1=0.9853438556933484, best_f1=0.9831271091113611
step: 0, loss: 0.06036677956581116
step: 10, loss: 0.01946045644581318
step: 20, loss: 0.019272025674581528
step: 30, loss: 0.023982467129826546
step: 40, loss: 0.14461712539196014
step: 50, loss: 0.058895695954561234
step: 60, loss: 0.027568688616156578
step: 70, loss: 0.10196735709905624
step: 80, loss: 0.018384423106908798
step: 90, loss: 0.00915008969604969
step: 100, loss: 0.08889379352331161
step: 110, loss: 0.10022127628326416
step: 120, loss: 0.2340182214975357
step: 130, loss: 0.03179898113012314
step: 140, loss: 0.06975807994604111
step: 150, loss: 0.017924390733242035
step: 160, loss: 0.008026537485420704
step: 170, loss: 0.06957782804965973
step: 180, loss: 0.0649801641702652
step: 190, loss: 0.06169739365577698
step: 200, loss: 0.06455221027135849
step: 210, loss: 0.08725056052207947
step: 220, loss: 0.11368396878242493
step: 230, loss: 0.03911909833550453
step: 240, loss: 0.09347561746835709
step: 250, loss: 0.033005665987730026
step: 260, loss: 0.011141114868223667
step: 270, loss: 0.15496408939361572
step: 280, loss: 0.13041456043720245
step: 290, loss: 0.12438660115003586
step: 300, loss: 0.046361781656742096
step: 310, loss: 0.01613084226846695
step: 320, loss: 0.010663074441254139
step: 330, loss: 0.0318826399743557
step: 340, loss: 0.022402089089155197
step: 350, loss: 0.016038184985518456
step: 360, loss: 0.028122492134571075
step: 370, loss: 0.008258529007434845
step: 380, loss: 0.06962432712316513
step: 390, loss: 0.044500868767499924
step: 400, loss: 0.021543143317103386
step: 410, loss: 0.015028589405119419
step: 420, loss: 0.02328631281852722
epoch 4: dev_f1=0.985539488320356, f1=0.9800884955752212, best_f1=0.9831271091113611
step: 0, loss: 0.03181823715567589
step: 10, loss: 0.08004150539636612
step: 20, loss: 0.06961056590080261
step: 30, loss: 0.16383543610572815
step: 40, loss: 0.06423930823802948
step: 50, loss: 0.061024561524391174
step: 60, loss: 0.03218921646475792
step: 70, loss: 0.07269186526536942
step: 80, loss: 0.030189231038093567
step: 90, loss: 0.018224630504846573
step: 100, loss: 0.06591589003801346
step: 110, loss: 0.05779562145471573
step: 120, loss: 0.07163389772176743
step: 130, loss: 0.03165040165185928
step: 140, loss: 0.0798429399728775
step: 150, loss: 0.02448994852602482
step: 160, loss: 0.020328626036643982
step: 170, loss: 0.027683081105351448
step: 180, loss: 0.025372816249728203
step: 190, loss: 0.13036786019802094
step: 200, loss: 0.04366894066333771
step: 210, loss: 0.01132420264184475
step: 220, loss: 0.02043241076171398
step: 230, loss: 0.00885626208037138
step: 240, loss: 0.024616440758109093
step: 250, loss: 0.023090573027729988
step: 260, loss: 0.09903478622436523
step: 270, loss: 0.13335196673870087
step: 280, loss: 0.0750809907913208
step: 290, loss: 0.15134555101394653
step: 300, loss: 0.08201522380113602
step: 310, loss: 0.07989168167114258
step: 320, loss: 0.11380444467067719
step: 330, loss: 0.020981863141059875
step: 340, loss: 0.1709313988685608
step: 350, loss: 0.03263896331191063
step: 360, loss: 0.16824373602867126
step: 370, loss: 0.033132754266262054
step: 380, loss: 0.014562924392521381
step: 390, loss: 0.031191222369670868
step: 400, loss: 0.12303335964679718
step: 410, loss: 0.0073895263485610485
step: 420, loss: 0.006483356934040785
epoch 5: dev_f1=0.9887133182844244, f1=0.9798657718120806, best_f1=0.9831271091113611
step: 0, loss: 6.986562948441133e-05
step: 10, loss: 0.15879981219768524
step: 20, loss: 0.04614351689815521
step: 30, loss: 0.1197180449962616
step: 40, loss: 0.14281170070171356
step: 50, loss: 0.023793065920472145
step: 60, loss: 0.026688292622566223
step: 70, loss: 0.013352817855775356
step: 80, loss: 0.04084128886461258
step: 90, loss: 0.019146036356687546
step: 100, loss: 0.06401076167821884
step: 110, loss: 0.06298987567424774
step: 120, loss: 0.012715596705675125
step: 130, loss: 0.11839157342910767
step: 140, loss: 0.0400148369371891
step: 150, loss: 0.06293190270662308
step: 160, loss: 0.03367104381322861
step: 170, loss: 0.044732242822647095
step: 180, loss: 0.011353316716849804
step: 190, loss: 0.018918050453066826
step: 200, loss: 0.015613358467817307
step: 210, loss: 0.016869070008397102
step: 220, loss: 0.01035838108509779
step: 230, loss: 0.009043114259839058
step: 240, loss: 0.008759514428675175
step: 250, loss: 0.22354471683502197
step: 260, loss: 0.058270327746868134
step: 270, loss: 0.01723327301442623
step: 280, loss: 0.12215074896812439
step: 290, loss: 0.022735999897122383
step: 300, loss: 0.07069723308086395
step: 310, loss: 0.06202973797917366
step: 320, loss: 0.07390938699245453
step: 330, loss: 0.01422884687781334
step: 340, loss: 0.08158257603645325
step: 350, loss: 0.07862924039363861
step: 360, loss: 0.05118511617183685
step: 370, loss: 0.08777409046888351
step: 380, loss: 0.026365140452980995
step: 390, loss: 0.07552371174097061
step: 400, loss: 0.01936439238488674
step: 410, loss: 0.004809308331459761
step: 420, loss: 0.06448899954557419
epoch 6: dev_f1=0.9841269841269841, f1=0.9764837625979844, best_f1=0.9831271091113611
step: 0, loss: 0.025489721447229385
step: 10, loss: 0.13996244966983795
step: 20, loss: 0.07998873293399811
step: 30, loss: 0.03390064463019371
step: 40, loss: 0.07821334898471832
step: 50, loss: 0.08005888760089874
step: 60, loss: 0.013013982214033604
step: 70, loss: 0.013565892353653908
step: 80, loss: 0.02951432578265667
step: 90, loss: 0.005184287670999765
step: 100, loss: 0.052282195538282394
step: 110, loss: 0.06416371464729309
step: 120, loss: 0.09502804279327393
step: 130, loss: 0.05814802646636963
step: 140, loss: 0.08729875832796097
step: 150, loss: 0.01600571535527706
step: 160, loss: 0.0806926041841507
step: 170, loss: 0.05620003119111061
step: 180, loss: 0.06395472586154938
step: 190, loss: 0.052404653280973434
step: 200, loss: 0.041484057903289795
step: 210, loss: 0.030134735628962517
step: 220, loss: 0.025700287893414497
step: 230, loss: 0.06389041990041733
step: 240, loss: 0.012210825458168983
step: 250, loss: 0.09390611201524734
step: 260, loss: 0.012356937862932682
step: 270, loss: 0.005228119902312756
step: 280, loss: 0.07170137017965317
step: 290, loss: 0.17337682843208313
step: 300, loss: 0.13548997044563293
step: 310, loss: 0.11168280243873596
step: 320, loss: 0.06759283691644669
step: 330, loss: 0.03977920860052109
step: 340, loss: 0.007812993600964546
step: 350, loss: 0.03442578390240669
step: 360, loss: 0.03486580401659012
step: 370, loss: 0.08662950247526169
step: 380, loss: 0.061523787677288055
step: 390, loss: 0.22428883612155914
step: 400, loss: 0.12065918743610382
step: 410, loss: 0.018785009160637856
step: 420, loss: 0.029112929478287697
epoch 7: dev_f1=0.9875424688561721, f1=0.9786276715410572, best_f1=0.9831271091113611
step: 0, loss: 0.012178929522633553
step: 10, loss: 0.0020695982966572046
step: 20, loss: 0.13292114436626434
step: 30, loss: 0.018325595185160637
step: 40, loss: 0.03582334518432617
step: 50, loss: 0.08485976606607437
step: 60, loss: 0.0795913115143776
step: 70, loss: 0.07092353701591492
step: 80, loss: 0.004803917836397886
step: 90, loss: 0.07046683877706528
step: 100, loss: 0.08404485136270523
step: 110, loss: 0.02169005572795868
step: 120, loss: 0.017102308571338654
step: 130, loss: 0.06157388910651207
step: 140, loss: 0.007094677537679672
step: 150, loss: 0.25112196803092957
step: 160, loss: 0.046972762793302536
step: 170, loss: 0.08159637451171875
step: 180, loss: 0.056977465748786926
step: 190, loss: 0.06860561668872833
step: 200, loss: 0.04678579047322273
step: 210, loss: 0.0728948786854744
step: 220, loss: 0.11979173868894577
step: 230, loss: 0.06798486411571503
step: 240, loss: 0.02378869242966175
step: 250, loss: 0.017370615154504776
step: 260, loss: 0.08806268125772476
step: 270, loss: 0.048128049820661545
step: 280, loss: 0.04216210916638374
step: 290, loss: 0.12749381363391876
step: 300, loss: 0.18342962861061096
step: 310, loss: 0.08713670819997787
step: 320, loss: 0.06902828812599182
step: 330, loss: 0.00878359004855156
step: 340, loss: 0.14523938298225403
step: 350, loss: 0.08860176801681519
step: 360, loss: 0.08993533253669739
step: 370, loss: 0.006460119970142841
step: 380, loss: 0.06426698714494705
step: 390, loss: 0.034552205353975296
step: 400, loss: 0.07412704080343246
step: 410, loss: 0.01970427855849266
step: 420, loss: 0.007016933523118496
epoch 8: dev_f1=0.9910112359550561, f1=0.9799107142857142, best_f1=0.9799107142857142
step: 0, loss: 0.010983464308083057
step: 10, loss: 0.07261181622743607
step: 20, loss: 0.1608632653951645
step: 30, loss: 0.1964430809020996
step: 40, loss: 0.00901971198618412
step: 50, loss: 0.06983956694602966
step: 60, loss: 0.12788040935993195
step: 70, loss: 0.03718016669154167
step: 80, loss: 0.020675556734204292
step: 90, loss: 0.32759442925453186
step: 100, loss: 0.08627278357744217
step: 110, loss: 0.03759877011179924
step: 120, loss: 0.027652034536004066
step: 130, loss: 0.01749303564429283
step: 140, loss: 0.04292099550366402
step: 150, loss: 0.07838445901870728
step: 160, loss: 0.02044897899031639
step: 170, loss: 0.08826189488172531
step: 180, loss: 0.06721612066030502
step: 190, loss: 0.06641493737697601
step: 200, loss: 0.05551591143012047
step: 210, loss: 0.03995886445045471
step: 220, loss: 0.020630113780498505
step: 230, loss: 0.018812313675880432
step: 240, loss: 0.1551634520292282
step: 250, loss: 0.012986410409212112
step: 260, loss: 0.17275133728981018
step: 270, loss: 0.01285395398736
step: 280, loss: 0.09816835075616837
step: 290, loss: 0.017814479768276215
step: 300, loss: 0.08071941137313843
step: 310, loss: 0.13233280181884766
step: 320, loss: 0.08402173221111298
step: 330, loss: 0.07082634419202805
step: 340, loss: 0.07188642770051956
step: 350, loss: 0.014959996566176414
step: 360, loss: 0.05918971449136734
step: 370, loss: 0.029493747279047966
step: 380, loss: 0.0873236283659935
step: 390, loss: 0.005377214401960373
step: 400, loss: 0.015483223833143711
step: 410, loss: 0.002019179053604603
step: 420, loss: 0.1438942849636078
epoch 9: dev_f1=0.9864559819413092, f1=0.9797752808988766, best_f1=0.9799107142857142
step: 0, loss: 0.06802631169557571
step: 10, loss: 0.07321730256080627
step: 20, loss: 0.002413274021819234
step: 30, loss: 0.007498083170503378
step: 40, loss: 0.061249762773513794
step: 50, loss: 0.16965916752815247
step: 60, loss: 0.0535382479429245
step: 70, loss: 0.012658419087529182
step: 80, loss: 0.004275145940482616
step: 90, loss: 0.019783062860369682
step: 100, loss: 0.05685915797948837
step: 110, loss: 0.020229510962963104
step: 120, loss: 0.06590864062309265
step: 130, loss: 0.012028204277157784
step: 140, loss: 0.09345134347677231
step: 150, loss: 0.01947072148323059
step: 160, loss: 0.08178374171257019
step: 170, loss: 0.04358300566673279
step: 180, loss: 0.04843767359852791
step: 190, loss: 0.06549912691116333
step: 200, loss: 0.05340486019849777
step: 210, loss: 0.00828514900058508
step: 220, loss: 0.0751478374004364
step: 230, loss: 0.21458066999912262
step: 240, loss: 0.009059915319085121
step: 250, loss: 0.028086870908737183
step: 260, loss: 0.061730992048978806
step: 270, loss: 0.007305573206394911
step: 280, loss: 0.023259667679667473
step: 290, loss: 0.013402818702161312
step: 300, loss: 0.05738284811377525
step: 310, loss: 0.21633274853229523
step: 320, loss: 0.0818639025092125
step: 330, loss: 0.029865341261029243
step: 340, loss: 0.09506405144929886
step: 350, loss: 0.029868246987462044
step: 360, loss: 0.00821776408702135
step: 370, loss: 0.026783615350723267
step: 380, loss: 0.0056689027696847916
step: 390, loss: 0.09684921056032181
step: 400, loss: 0.021685775369405746
step: 410, loss: 0.019437219947576523
step: 420, loss: 0.073918417096138
epoch 10: dev_f1=0.9876819708846584, f1=0.9821428571428571, best_f1=0.9799107142857142
step: 0, loss: 0.017968717962503433
step: 10, loss: 0.06411123275756836
step: 20, loss: 0.015583607368171215
step: 30, loss: 0.009852040559053421
step: 40, loss: 0.01665899157524109
step: 50, loss: 0.05971955507993698
step: 60, loss: 0.027589481323957443
step: 70, loss: 0.08015347272157669
step: 80, loss: 0.017052657902240753
step: 90, loss: 0.07272402197122574
step: 100, loss: 0.01940406858921051
step: 110, loss: 0.042965855449438095
step: 120, loss: 0.06493532657623291
step: 130, loss: 0.03457499295473099
step: 140, loss: 0.02864285185933113
step: 150, loss: 0.015759872272610664
step: 160, loss: 0.07110870629549026
step: 170, loss: 0.11604226380586624
step: 180, loss: 0.010238135233521461
step: 190, loss: 0.01642417162656784
step: 200, loss: 0.006882325746119022
step: 210, loss: 0.004525426309555769
step: 220, loss: 0.026141375303268433
step: 230, loss: 0.016414480283856392
step: 240, loss: 0.05373570695519447
step: 250, loss: 0.02880181558430195
step: 260, loss: 0.012342444621026516
step: 270, loss: 0.06991341710090637
step: 280, loss: 0.019595157355070114
step: 290, loss: 0.09129627048969269
step: 300, loss: 0.08547580987215042
step: 310, loss: 0.12626942992210388
step: 320, loss: 0.02786978706717491
step: 330, loss: 0.04691123589873314
step: 340, loss: 0.04258088022470474
step: 350, loss: 3.762663254747167e-05
step: 360, loss: 0.09051686525344849
step: 370, loss: 0.08430682867765427
step: 380, loss: 0.02352939173579216
step: 390, loss: 0.07389606535434723
step: 400, loss: 0.13574673235416412
step: 410, loss: 0.01615719124674797
step: 420, loss: 0.013108339160680771
epoch 11: dev_f1=0.9887892376681614, f1=0.9797752808988766, best_f1=0.9799107142857142
step: 0, loss: 0.17676545679569244
step: 10, loss: 0.06490561366081238
step: 20, loss: 0.05823375657200813
step: 30, loss: 0.1264960616827011
step: 40, loss: 0.06632038205862045
step: 50, loss: 0.11361461877822876
step: 60, loss: 0.0036457646638154984
step: 70, loss: 0.006452844478189945
step: 80, loss: 0.030730435624718666
step: 90, loss: 0.07049062848091125
step: 100, loss: 0.016285093501210213
step: 110, loss: 0.1114296019077301
step: 120, loss: 0.004022190347313881
step: 130, loss: 0.12110892683267593
step: 140, loss: 0.0116665568202734
step: 150, loss: 0.008353568613529205
step: 160, loss: 0.09992857277393341
step: 170, loss: 0.04906129837036133
step: 180, loss: 0.22035002708435059
step: 190, loss: 0.0039203958585858345
step: 200, loss: 0.0543958842754364
step: 210, loss: 0.0675973892211914
step: 220, loss: 0.1964832842350006
step: 230, loss: 0.05328693240880966
step: 240, loss: 0.009415702894330025
step: 250, loss: 0.011932240799069405
step: 260, loss: 0.003911063075065613
step: 270, loss: 0.020142141729593277
step: 280, loss: 0.07380663603544235
step: 290, loss: 0.006114992778748274
step: 300, loss: 0.02123531885445118
step: 310, loss: 0.07895714789628983
step: 320, loss: 0.04452542960643768
step: 330, loss: 0.11403541266918182
step: 340, loss: 0.04571835324168205
step: 350, loss: 0.01738665997982025
step: 360, loss: 0.06709980964660645
step: 370, loss: 0.08303570002317429
step: 380, loss: 0.08325518667697906
step: 390, loss: 0.00013830926036462188
step: 400, loss: 0.0443464033305645
step: 410, loss: 0.007279714569449425
step: 420, loss: 0.02022719383239746
epoch 12: dev_f1=0.9910313901345291, f1=0.9821428571428571, best_f1=0.9821428571428571
step: 0, loss: 0.13270525634288788
step: 10, loss: 0.012814885005354881
step: 20, loss: 0.015597213059663773
step: 30, loss: 0.031001757830381393
step: 40, loss: 0.06653811037540436
step: 50, loss: 0.08170200139284134
step: 60, loss: 0.05461392179131508
step: 70, loss: 0.004099288955330849
step: 80, loss: 0.011540845036506653
step: 90, loss: 0.022441767156124115
step: 100, loss: 0.06072405353188515
step: 110, loss: 0.047584906220436096
step: 120, loss: 0.04421374574303627
step: 130, loss: 0.05291048437356949
step: 140, loss: 0.03008759766817093
step: 150, loss: 0.0041527170687913895
step: 160, loss: 0.12113739550113678
step: 170, loss: 0.07620295882225037
step: 180, loss: 0.044372592121362686
step: 190, loss: 0.007484488654881716
step: 200, loss: 0.003759379032999277
step: 210, loss: 0.01930815353989601
step: 220, loss: 0.015023582614958286
step: 230, loss: 0.11403690278530121
step: 240, loss: 0.02833547070622444
step: 250, loss: 0.06610435992479324
step: 260, loss: 0.07621725648641586
step: 270, loss: 0.03534935787320137
step: 280, loss: 0.014068603515625
step: 290, loss: 0.021545832976698875
step: 300, loss: 0.0031107114627957344
step: 310, loss: 0.08220656961202621
step: 320, loss: 0.024664655327796936
step: 330, loss: 0.005462928209453821
step: 340, loss: 0.0264356080442667
step: 350, loss: 0.017404500395059586
step: 360, loss: 1.967633761523757e-05
step: 370, loss: 0.029488638043403625
step: 380, loss: 2.34462659136625e-05
step: 390, loss: 0.17253020405769348
step: 400, loss: 0.007588354870676994
step: 410, loss: 0.007730487734079361
step: 420, loss: 0.060950908809900284
epoch 13: dev_f1=0.9898989898989898, f1=0.9821029082774049, best_f1=0.9821428571428571
step: 0, loss: 0.012955849058926105
step: 10, loss: 0.08472573012113571
step: 20, loss: 0.016337109729647636
step: 30, loss: 0.03716254606842995
step: 40, loss: 0.0667569562792778
step: 50, loss: 0.001086592674255371
step: 60, loss: 0.041570089757442474
step: 70, loss: 0.004425658844411373
step: 80, loss: 0.010769180953502655
step: 90, loss: 0.004632000811398029
step: 100, loss: 0.028841406106948853
step: 110, loss: 0.00856147613376379
step: 120, loss: 0.00990278646349907
step: 130, loss: 0.016519948840141296
step: 140, loss: 0.04382520914077759
step: 150, loss: 0.09774811565876007
step: 160, loss: 0.013643559068441391
step: 170, loss: 0.09236910939216614
step: 180, loss: 0.04681964963674545
step: 190, loss: 0.040006183087825775
step: 200, loss: 0.1251964569091797
step: 210, loss: 0.0034999139606952667
step: 220, loss: 0.021954694762825966
step: 230, loss: 0.1048676148056984
step: 240, loss: 0.014327244833111763
step: 250, loss: 0.0056976210325956345
step: 260, loss: 0.030208220705389977
step: 270, loss: 0.027570396661758423
step: 280, loss: 0.0877324789762497
step: 290, loss: 0.048448968678712845
step: 300, loss: 0.05100449174642563
step: 310, loss: 0.030047088861465454
step: 320, loss: 0.033645935356616974
step: 330, loss: 0.008425380103290081
step: 340, loss: 0.03532818704843521
step: 350, loss: 0.08866587281227112
step: 360, loss: 0.062188636511564255
step: 370, loss: 0.019266488030552864
step: 380, loss: 0.018743189051747322
step: 390, loss: 0.02391374669969082
step: 400, loss: 0.026087583974003792
step: 410, loss: 0.00023631889780517668
step: 420, loss: 7.416928565362468e-05
epoch 14: dev_f1=0.9932279909706545, f1=0.9809203142536477, best_f1=0.9809203142536477
step: 0, loss: 0.05810881778597832
step: 10, loss: 0.05071435123682022
step: 20, loss: 0.03963746502995491
step: 30, loss: 0.07274070382118225
step: 40, loss: 0.03515948727726936
step: 50, loss: 0.08171376585960388
step: 60, loss: 0.04913177713751793
step: 70, loss: 0.05607895180583
step: 80, loss: 0.07855966687202454
step: 90, loss: 0.03329872712492943
step: 100, loss: 0.043251920491456985
step: 110, loss: 0.15735819935798645
step: 120, loss: 0.006173786707222462
step: 130, loss: 0.007110420148819685
step: 140, loss: 0.08176416158676147
step: 150, loss: 0.02067016437649727
step: 160, loss: 0.06493786722421646
step: 170, loss: 0.02792789600789547
step: 180, loss: 0.0036930167116224766
step: 190, loss: 1.9300408894196153e-05
step: 200, loss: 0.1544005572795868
step: 210, loss: 0.03444055840373039
step: 220, loss: 0.013171043246984482
step: 230, loss: 0.0260221716016531
step: 240, loss: 0.0491597056388855
step: 250, loss: 0.06865760684013367
step: 260, loss: 0.03761788085103035
step: 270, loss: 0.12278351932764053
step: 280, loss: 0.061328914016485214
step: 290, loss: 0.03122001513838768
step: 300, loss: 0.02538265660405159
step: 310, loss: 0.02256532944738865
step: 320, loss: 0.021380767226219177
step: 330, loss: 0.028292236849665642
step: 340, loss: 0.029017383232712746
step: 350, loss: 0.05797187611460686
step: 360, loss: 0.14020715653896332
step: 370, loss: 0.263793021440506
step: 380, loss: 0.0025958800688385963
step: 390, loss: 0.04845081642270088
step: 400, loss: 0.06465752422809601
step: 410, loss: 0.06977330893278122
step: 420, loss: 0.02592511847615242
epoch 15: dev_f1=0.9898305084745763, f1=0.9798206278026906, best_f1=0.9809203142536477
step: 0, loss: 0.03295329213142395
step: 10, loss: 0.0007019519107416272
step: 20, loss: 0.029755784198641777
step: 30, loss: 0.04660046473145485
step: 40, loss: 0.0009678021306172013
step: 50, loss: 0.028676170855760574
step: 60, loss: 0.09256349503993988
step: 70, loss: 0.0763474851846695
step: 80, loss: 0.034530721604824066
step: 90, loss: 0.05796851962804794
step: 100, loss: 0.044106315821409225
step: 110, loss: 0.029527537524700165
step: 120, loss: 0.031222518533468246
step: 130, loss: 0.005228098016232252
step: 140, loss: 0.025615500286221504
step: 150, loss: 0.06217193603515625
step: 160, loss: 0.022475192323327065
step: 170, loss: 0.023195600137114525
step: 180, loss: 0.0012037594569846988
step: 190, loss: 0.06340048462152481
step: 200, loss: 0.032284047454595566
step: 210, loss: 0.06818000227212906
step: 220, loss: 0.0302718672901392
step: 230, loss: 0.06943248212337494
step: 240, loss: 0.08550994098186493
step: 250, loss: 0.05805240944027901
step: 260, loss: 0.023698510602116585
step: 270, loss: 0.027537954971194267
step: 280, loss: 0.0003691645397339016
step: 290, loss: 0.026782024651765823
step: 300, loss: 9.433740342501551e-05
step: 310, loss: 0.03185242414474487
step: 320, loss: 0.00013325773761607707
step: 330, loss: 0.0007313130190595984
step: 340, loss: 0.0682452842593193
step: 350, loss: 0.07793698459863663
step: 360, loss: 0.00027381235850043595
step: 370, loss: 0.00012491185043472797
step: 380, loss: 0.030543219298124313
step: 390, loss: 0.002858498366549611
step: 400, loss: 0.0006256108754314482
step: 410, loss: 4.215275475871749e-05
step: 420, loss: 0.056165825575590134
epoch 16: dev_f1=0.990990990990991, f1=0.9821428571428571, best_f1=0.9809203142536477
step: 0, loss: 0.06980932503938675
step: 10, loss: 0.021674873307347298
step: 20, loss: 0.06225499510765076
step: 30, loss: 0.14274077117443085
step: 40, loss: 0.031249094754457474
step: 50, loss: 0.05807024985551834
step: 60, loss: 0.0004279563727322966
step: 70, loss: 0.03870189189910889
step: 80, loss: 0.014676700346171856
step: 90, loss: 0.09032347798347473
step: 100, loss: 0.10646726191043854
step: 110, loss: 0.07816041260957718
step: 120, loss: 0.01045623142272234
step: 130, loss: 0.0004394681891426444
step: 140, loss: 0.07171660661697388
step: 150, loss: 0.043784406036138535
step: 160, loss: 0.052293743938207626
step: 170, loss: 6.218731141416356e-05
step: 180, loss: 0.05340230464935303
step: 190, loss: 1.5545436326647177e-05
step: 200, loss: 0.07268209755420685
step: 210, loss: 0.0366755910217762
step: 220, loss: 0.057841215282678604
step: 230, loss: 0.046783413738012314
step: 240, loss: 0.0002529298362787813
step: 250, loss: 0.018406465649604797
step: 260, loss: 0.08626846224069595
step: 270, loss: 0.0052846502512693405
step: 280, loss: 0.06244317442178726
step: 290, loss: 0.06151878088712692
step: 300, loss: 0.043873131275177
step: 310, loss: 0.0010676274541765451
step: 320, loss: 0.022491147741675377
step: 330, loss: 0.12773799896240234
step: 340, loss: 0.00015528983203694224
step: 350, loss: 0.009055602364242077
step: 360, loss: 0.06295302510261536
step: 370, loss: 0.009028347209095955
step: 380, loss: 0.025555303320288658
step: 390, loss: 0.05387584865093231
step: 400, loss: 1.8845885279006325e-05
step: 410, loss: 0.009954343549907207
step: 420, loss: 0.0004452634893823415
epoch 17: dev_f1=0.9921259842519685, f1=0.9833147942157954, best_f1=0.9809203142536477
step: 0, loss: 0.04503478482365608
step: 10, loss: 0.00015210341371130198
step: 20, loss: 0.0012215862516313791
step: 30, loss: 0.0003428511554375291
step: 40, loss: 0.0004722465528175235
step: 50, loss: 0.04651796817779541
step: 60, loss: 0.052728887647390366
step: 70, loss: 0.019201764836907387
step: 80, loss: 0.0020598869305104017
step: 90, loss: 0.09805703163146973
step: 100, loss: 0.0413566417992115
step: 110, loss: 0.00904457550495863
step: 120, loss: 0.024056337773799896
step: 130, loss: 0.02311592549085617
step: 140, loss: 0.04198843613266945
step: 150, loss: 0.04457838088274002
step: 160, loss: 0.01863766834139824
step: 170, loss: 0.041909992694854736
step: 180, loss: 0.036843955516815186
step: 190, loss: 0.040994565933942795
step: 200, loss: 0.0028859858866780996
step: 210, loss: 0.02548019029200077
step: 220, loss: 0.1119067594408989
step: 230, loss: 0.04243495315313339
step: 240, loss: 0.0012601242633536458
step: 250, loss: 0.0041280705481767654
step: 260, loss: 0.08540110290050507
step: 270, loss: 0.030935535207390785
step: 280, loss: 0.03778444975614548
step: 290, loss: 0.04435929283499718
step: 300, loss: 0.03276769816875458
step: 310, loss: 0.018417490646243095
step: 320, loss: 0.04143251106142998
step: 330, loss: 0.00048745490494184196
step: 340, loss: 0.0242631658911705
step: 350, loss: 0.015404950827360153
step: 360, loss: 0.05997698754072189
step: 370, loss: 0.016690701246261597
step: 380, loss: 0.10116015374660492
step: 390, loss: 0.00034835957922041416
step: 400, loss: 0.008179884403944016
step: 410, loss: 0.018021974712610245
step: 420, loss: 0.028347838670015335
epoch 18: dev_f1=0.9921259842519685, f1=0.9821826280623607, best_f1=0.9809203142536477
step: 0, loss: 0.05603667348623276
step: 10, loss: 0.011654832400381565
step: 20, loss: 0.03765294700860977
step: 30, loss: 0.07042199373245239
step: 40, loss: 0.060821931809186935
step: 50, loss: 0.026743484660983086
step: 60, loss: 0.0011362311197444797
step: 70, loss: 0.050706636160612106
step: 80, loss: 0.015088050626218319
step: 90, loss: 0.015375548973679543
step: 100, loss: 0.013966815546154976
step: 110, loss: 0.02351372130215168
step: 120, loss: 0.024463707581162453
step: 130, loss: 0.024017781019210815
step: 140, loss: 0.0009367922320961952
step: 150, loss: 0.014248871244490147
step: 160, loss: 0.010870730504393578
step: 170, loss: 0.059645235538482666
step: 180, loss: 0.03558369353413582
step: 190, loss: 0.02091842144727707
step: 200, loss: 0.014053217135369778
step: 210, loss: 0.019271349534392357
step: 220, loss: 0.00038814780418761075
step: 230, loss: 0.00015246422844938934
step: 240, loss: 0.036330580711364746
step: 250, loss: 0.059980783611536026
step: 260, loss: 0.043262679129838943
step: 270, loss: 0.00019284938753116876
step: 280, loss: 0.00014884756819810718
step: 290, loss: 0.037059348076581955
step: 300, loss: 0.001729293609969318
step: 310, loss: 0.0439772829413414
step: 320, loss: 0.012098858132958412
step: 330, loss: 0.07205043733119965
step: 340, loss: 0.0001493089075665921
step: 350, loss: 0.07058048248291016
step: 360, loss: 0.03000478632748127
step: 370, loss: 0.03767329454421997
step: 380, loss: 0.0802483782172203
step: 390, loss: 0.00023939994571264833
step: 400, loss: 0.03462842479348183
step: 410, loss: 0.00047188226017169654
step: 420, loss: 0.0640784353017807
epoch 19: dev_f1=0.9898534385569334, f1=0.9787709497206705, best_f1=0.9809203142536477
step: 0, loss: 0.02701319381594658
step: 10, loss: 5.9291494835633785e-05
step: 20, loss: 0.05219624191522598
step: 30, loss: 0.0027697605546563864
step: 40, loss: 0.00015652828733436763
step: 50, loss: 0.00018749390437733382
step: 60, loss: 0.022023281082510948
step: 70, loss: 0.026202095672488213
step: 80, loss: 0.013245162554085255
step: 90, loss: 0.01668548583984375
step: 100, loss: 0.03072940930724144
step: 110, loss: 0.0007848194218240678
step: 120, loss: 0.016467293724417686
step: 130, loss: 0.027014771476387978
step: 140, loss: 0.024417173117399216
step: 150, loss: 0.06129514425992966
step: 160, loss: 0.0003485007327981293
step: 170, loss: 0.021373428404331207
step: 180, loss: 0.05841904133558273
step: 190, loss: 0.07093537598848343
step: 200, loss: 0.07355405390262604
step: 210, loss: 0.01931588537991047
step: 220, loss: 0.03267794847488403
step: 230, loss: 0.07893035560846329
step: 240, loss: 8.821016672300175e-05
step: 250, loss: 0.04444167762994766
step: 260, loss: 0.0750281885266304
step: 270, loss: 0.01729995384812355
step: 280, loss: 0.038045547902584076
step: 290, loss: 0.030410846695303917
step: 300, loss: 0.05720503255724907
step: 310, loss: 0.013591226190328598
step: 320, loss: 0.042731981724500656
step: 330, loss: 0.05077622830867767
step: 340, loss: 0.000156439928105101
step: 350, loss: 0.1021362766623497
step: 360, loss: 0.0001262732985196635
step: 370, loss: 0.01953771337866783
step: 380, loss: 0.03525352478027344
step: 390, loss: 0.0012587509118020535
step: 400, loss: 0.01108940877020359
step: 410, loss: 7.962137897266075e-05
step: 420, loss: 0.022607384249567986
epoch 20: dev_f1=0.9898305084745763, f1=0.9776286353467561, best_f1=0.9809203142536477
