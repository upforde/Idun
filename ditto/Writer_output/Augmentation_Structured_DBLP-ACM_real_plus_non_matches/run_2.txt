cuda
Device: cuda
step: 0, loss: 0.7004976868629456
step: 10, loss: 0.094211146235466
step: 20, loss: 0.31723958253860474
step: 30, loss: 0.3693579137325287
step: 40, loss: 0.3422854244709015
step: 50, loss: 0.3039599061012268
step: 60, loss: 0.04555860906839371
step: 70, loss: 0.1253407597541809
step: 80, loss: 0.06483625620603561
step: 90, loss: 0.03670337796211243
step: 100, loss: 0.20810002088546753
step: 110, loss: 0.03173285722732544
step: 120, loss: 0.14561301469802856
step: 130, loss: 0.07865874469280243
step: 140, loss: 0.017655014991760254
step: 150, loss: 0.0047108447179198265
step: 160, loss: 0.08826861530542374
step: 170, loss: 0.11636736989021301
step: 180, loss: 0.041199591010808945
step: 190, loss: 0.0307316854596138
step: 200, loss: 0.12369085103273392
step: 210, loss: 0.13594315946102142
step: 220, loss: 0.0572407990694046
step: 230, loss: 0.06078893691301346
step: 240, loss: 0.018022269010543823
step: 250, loss: 0.2974262535572052
step: 260, loss: 0.12394076585769653
step: 270, loss: 0.07711722701787949
step: 280, loss: 0.05316752567887306
step: 290, loss: 0.09140125662088394
step: 300, loss: 0.10966473817825317
step: 310, loss: 0.1292443424463272
step: 320, loss: 0.09469220787286758
step: 330, loss: 0.17213329672813416
step: 340, loss: 0.04734605923295021
step: 350, loss: 0.0067568388767540455
step: 360, loss: 0.04916602745652199
step: 370, loss: 0.12126758694648743
step: 380, loss: 0.2145862877368927
step: 390, loss: 0.0911288931965828
step: 400, loss: 0.14265723526477814
step: 410, loss: 0.13163800537586212
step: 420, loss: 0.005920862779021263
epoch 1: dev_f1=0.9921259842519685, f1=0.9853768278965129, best_f1=0.9853768278965129
step: 0, loss: 0.0667942687869072
step: 10, loss: 0.005192705895751715
step: 20, loss: 0.10022513568401337
step: 30, loss: 0.015471043065190315
step: 40, loss: 0.15830190479755402
step: 50, loss: 0.250448077917099
step: 60, loss: 0.07072076946496964
step: 70, loss: 0.07261505722999573
step: 80, loss: 0.05873884633183479
step: 90, loss: 0.1638534963130951
step: 100, loss: 0.08053209632635117
step: 110, loss: 0.1498686969280243
step: 120, loss: 0.21168401837348938
step: 130, loss: 0.037276044487953186
step: 140, loss: 0.033165235072374344
step: 150, loss: 0.04557739943265915
step: 160, loss: 0.09285619109869003
step: 170, loss: 0.0739540159702301
step: 180, loss: 0.1618066430091858
step: 190, loss: 0.013950451277196407
step: 200, loss: 0.15118537843227386
step: 210, loss: 0.070615753531456
step: 220, loss: 0.019717028364539146
step: 230, loss: 0.014781314879655838
step: 240, loss: 0.03409386798739433
step: 250, loss: 0.09107890725135803
step: 260, loss: 0.019841494038701057
step: 270, loss: 0.018358128145337105
step: 280, loss: 0.07397007942199707
step: 290, loss: 0.05135510489344597
step: 300, loss: 0.023839404806494713
step: 310, loss: 0.01460953801870346
step: 320, loss: 0.09139610826969147
step: 330, loss: 0.1690584421157837
step: 340, loss: 0.07786159962415695
step: 350, loss: 0.2943050265312195
step: 360, loss: 0.0015836289385333657
step: 370, loss: 0.054163608700037
step: 380, loss: 0.03739014267921448
step: 390, loss: 0.03300891071557999
step: 400, loss: 0.06284408271312714
step: 410, loss: 0.02276795729994774
step: 420, loss: 0.005810139235109091
epoch 2: dev_f1=0.9909502262443439, f1=0.9875424688561721, best_f1=0.9853768278965129
step: 0, loss: 0.07842182368040085
step: 10, loss: 0.09705912321805954
step: 20, loss: 0.13181596994400024
step: 30, loss: 0.012692232616245747
step: 40, loss: 0.020490730181336403
step: 50, loss: 0.01354213710874319
step: 60, loss: 0.11589449644088745
step: 70, loss: 0.2037137895822525
step: 80, loss: 0.02974761091172695
step: 90, loss: 0.09252741187810898
step: 100, loss: 0.07123404741287231
step: 110, loss: 0.024633632972836494
step: 120, loss: 0.04240107536315918
step: 130, loss: 0.062484461814165115
step: 140, loss: 0.014433694072067738
step: 150, loss: 0.016645312309265137
step: 160, loss: 0.0056540872901678085
step: 170, loss: 0.03484536334872246
step: 180, loss: 0.012956764549016953
step: 190, loss: 0.07249633222818375
step: 200, loss: 0.016706684604287148
step: 210, loss: 0.042197149246931076
step: 220, loss: 0.06618589162826538
step: 230, loss: 0.010489795356988907
step: 240, loss: 0.1419319063425064
step: 250, loss: 0.06028285250067711
step: 260, loss: 0.07927726954221725
step: 270, loss: 0.1285441666841507
step: 280, loss: 0.08713489025831223
step: 290, loss: 0.04198926314711571
step: 300, loss: 0.0244094580411911
step: 310, loss: 0.13836288452148438
step: 320, loss: 0.05322672054171562
step: 330, loss: 0.010436814278364182
step: 340, loss: 0.04023301228880882
step: 350, loss: 0.16639262437820435
step: 360, loss: 0.09643945842981339
step: 370, loss: 0.08577312529087067
step: 380, loss: 0.10900391638278961
step: 390, loss: 0.059867601841688156
step: 400, loss: 0.08480720221996307
step: 410, loss: 0.016090676188468933
step: 420, loss: 0.036076854914426804
epoch 3: dev_f1=0.9920903954802259, f1=0.9920903954802259, best_f1=0.9853768278965129
step: 0, loss: 0.0703238993883133
step: 10, loss: 0.02816021628677845
step: 20, loss: 0.04004101827740669
step: 30, loss: 0.05090836063027382
step: 40, loss: 0.043382853269577026
step: 50, loss: 0.07313977181911469
step: 60, loss: 0.09259887784719467
step: 70, loss: 0.008939668536186218
step: 80, loss: 0.07184521108865738
step: 90, loss: 0.07145537436008453
step: 100, loss: 0.05342113599181175
step: 110, loss: 0.197354257106781
step: 120, loss: 0.1198076605796814
step: 130, loss: 0.006927541922777891
step: 140, loss: 0.06535971164703369
step: 150, loss: 0.06235819309949875
step: 160, loss: 0.012140611186623573
step: 170, loss: 0.0709112212061882
step: 180, loss: 0.07095403224229813
step: 190, loss: 0.015144315548241138
step: 200, loss: 0.07512553781270981
step: 210, loss: 0.03159297630190849
step: 220, loss: 0.012756835669279099
step: 230, loss: 0.12030787765979767
step: 240, loss: 0.07187838852405548
step: 250, loss: 0.07104068994522095
step: 260, loss: 0.06801799684762955
step: 270, loss: 0.01836533471941948
step: 280, loss: 0.05546796694397926
step: 290, loss: 0.08304225653409958
step: 300, loss: 0.08084841817617416
step: 310, loss: 0.036957889795303345
step: 320, loss: 0.05861276388168335
step: 330, loss: 0.08889172971248627
step: 340, loss: 0.08097510784864426
step: 350, loss: 0.10576637089252472
step: 360, loss: 0.020038587972521782
step: 370, loss: 0.11572094261646271
step: 380, loss: 0.01070823147892952
step: 390, loss: 0.02824333682656288
step: 400, loss: 0.0727291852235794
step: 410, loss: 0.08183424174785614
step: 420, loss: 0.12133531272411346
epoch 4: dev_f1=0.9932279909706545, f1=0.9853107344632768, best_f1=0.9853107344632768
step: 0, loss: 0.0840623676776886
step: 10, loss: 0.08846195787191391
step: 20, loss: 0.009089034982025623
step: 30, loss: 0.03437542915344238
step: 40, loss: 0.05833662673830986
step: 50, loss: 0.03267925605177879
step: 60, loss: 0.014965161681175232
step: 70, loss: 5.8217119658365846e-05
step: 80, loss: 0.07657823711633682
step: 90, loss: 0.08834762871265411
step: 100, loss: 0.07073105126619339
step: 110, loss: 0.036403559148311615
step: 120, loss: 0.035384759306907654
step: 130, loss: 0.006674266420304775
step: 140, loss: 0.018899934366345406
step: 150, loss: 0.1310451179742813
step: 160, loss: 0.0813293606042862
step: 170, loss: 0.02321869693696499
step: 180, loss: 0.12275271117687225
step: 190, loss: 0.03289874270558357
step: 200, loss: 0.0426153689622879
step: 210, loss: 0.036663077771663666
step: 220, loss: 0.07126200944185257
step: 230, loss: 0.08418102562427521
step: 240, loss: 0.06909235566854477
step: 250, loss: 0.04782169312238693
step: 260, loss: 0.010362043976783752
step: 270, loss: 0.11851584166288376
step: 280, loss: 0.05613178014755249
step: 290, loss: 0.03249559551477432
step: 300, loss: 0.061628472059965134
step: 310, loss: 0.14313513040542603
step: 320, loss: 0.0707046166062355
step: 330, loss: 0.0902084931731224
step: 340, loss: 0.07001206278800964
step: 350, loss: 0.013983679935336113
step: 360, loss: 0.1308949887752533
step: 370, loss: 0.01342929620295763
step: 380, loss: 0.019176285713911057
step: 390, loss: 0.0006689063156954944
step: 400, loss: 0.07668031007051468
step: 410, loss: 0.018618328496813774
step: 420, loss: 0.08551354706287384
epoch 5: dev_f1=0.9920724801812004, f1=0.9875424688561721, best_f1=0.9853107344632768
step: 0, loss: 0.009690599516034126
step: 10, loss: 0.022398870438337326
step: 20, loss: 0.08227771520614624
step: 30, loss: 0.06609604507684708
step: 40, loss: 0.13244718313217163
step: 50, loss: 0.0512278787791729
step: 60, loss: 0.058688342571258545
step: 70, loss: 0.0683228075504303
step: 80, loss: 0.0042087300680577755
step: 90, loss: 0.022757098078727722
step: 100, loss: 0.033837489783763885
step: 110, loss: 0.012584919109940529
step: 120, loss: 0.12920624017715454
step: 130, loss: 0.02426876686513424
step: 140, loss: 0.09968185424804688
step: 150, loss: 0.0690520852804184
step: 160, loss: 0.06064006686210632
step: 170, loss: 0.06946628540754318
step: 180, loss: 0.004091635812073946
step: 190, loss: 0.09533395618200302
step: 200, loss: 0.009045109152793884
step: 210, loss: 0.08181986212730408
step: 220, loss: 0.015756802633404732
step: 230, loss: 0.0709242895245552
step: 240, loss: 0.057649556547403336
step: 250, loss: 0.10556363314390182
step: 260, loss: 0.10297898948192596
step: 270, loss: 0.014333553612232208
step: 280, loss: 0.02654116228222847
step: 290, loss: 0.014729504473507404
step: 300, loss: 0.16756755113601685
step: 310, loss: 0.012112774886190891
step: 320, loss: 0.04468732327222824
step: 330, loss: 0.010214732028543949
step: 340, loss: 0.023566797375679016
step: 350, loss: 0.03033541329205036
step: 360, loss: 0.03547177091240883
step: 370, loss: 0.021030243486166
step: 380, loss: 0.008766496554017067
step: 390, loss: 0.038032542914152145
step: 400, loss: 0.00695255259051919
step: 410, loss: 0.08202958852052689
step: 420, loss: 0.07864777743816376
epoch 6: dev_f1=0.990990990990991, f1=0.9841986455981941, best_f1=0.9853107344632768
step: 0, loss: 0.25725382566452026
step: 10, loss: 0.018987633287906647
step: 20, loss: 0.041572317481040955
step: 30, loss: 0.02986777201294899
step: 40, loss: 0.08825831115245819
step: 50, loss: 0.05785021185874939
step: 60, loss: 0.011299777776002884
step: 70, loss: 0.0793633759021759
step: 80, loss: 0.07058465480804443
step: 90, loss: 0.12091362476348877
step: 100, loss: 0.11961764842271805
step: 110, loss: 0.04254579171538353
step: 120, loss: 0.01773499697446823
step: 130, loss: 0.08357568085193634
step: 140, loss: 0.019589269533753395
step: 150, loss: 0.030070601031184196
step: 160, loss: 0.00747271440923214
step: 170, loss: 0.0112103670835495
step: 180, loss: 0.016396919265389442
step: 190, loss: 0.019335675984621048
step: 200, loss: 0.009913090616464615
step: 210, loss: 0.017488554120063782
step: 220, loss: 0.0898142009973526
step: 230, loss: 0.014183088205754757
step: 240, loss: 0.01803583838045597
step: 250, loss: 0.03943098708987236
step: 260, loss: 0.11787919700145721
step: 270, loss: 0.08474686741828918
step: 280, loss: 0.15045249462127686
step: 290, loss: 0.016357669606804848
step: 300, loss: 0.00029246878693811595
step: 310, loss: 0.010504624806344509
step: 320, loss: 0.009281201288104057
step: 330, loss: 0.06198860704898834
step: 340, loss: 0.031955063343048096
step: 350, loss: 0.030190039426088333
step: 360, loss: 0.015738071873784065
step: 370, loss: 0.04300672560930252
step: 380, loss: 0.153493732213974
step: 390, loss: 0.25928622484207153
step: 400, loss: 0.1425766944885254
step: 410, loss: 0.07553856819868088
step: 420, loss: 0.06651736795902252
epoch 7: dev_f1=0.9887892376681614, f1=0.9787234042553192, best_f1=0.9853107344632768
step: 0, loss: 0.0847008153796196
step: 10, loss: 0.01672007516026497
step: 20, loss: 0.21167084574699402
step: 30, loss: 0.08379416167736053
step: 40, loss: 0.09813116490840912
step: 50, loss: 0.03500096872448921
step: 60, loss: 0.013957042247056961
step: 70, loss: 0.06940656900405884
step: 80, loss: 0.006191581021994352
step: 90, loss: 0.036906663328409195
step: 100, loss: 0.02410510927438736
step: 110, loss: 0.06749701499938965
step: 120, loss: 0.007097434252500534
step: 130, loss: 0.14189139008522034
step: 140, loss: 0.07084744423627853
step: 150, loss: 0.008164716884493828
step: 160, loss: 0.015892932191491127
step: 170, loss: 0.17145714163780212
step: 180, loss: 0.04350163787603378
step: 190, loss: 0.019847750663757324
step: 200, loss: 0.015129943378269672
step: 210, loss: 0.008919749408960342
step: 220, loss: 0.07069600373506546
step: 230, loss: 0.14333565533161163
step: 240, loss: 0.0006230031722225249
step: 250, loss: 0.02809830568730831
step: 260, loss: 0.07471653819084167
step: 270, loss: 0.04968415945768356
step: 280, loss: 0.02093677408993244
step: 290, loss: 0.007791583891957998
step: 300, loss: 0.01566973514854908
step: 310, loss: 0.010199658572673798
step: 320, loss: 0.0682954266667366
step: 330, loss: 0.17617754638195038
step: 340, loss: 0.08271589875221252
step: 350, loss: 0.03407563641667366
step: 360, loss: 0.023094341158866882
step: 370, loss: 0.026349470019340515
step: 380, loss: 0.08240313082933426
step: 390, loss: 0.07440249621868134
step: 400, loss: 0.08444736897945404
step: 410, loss: 0.008455743081867695
step: 420, loss: 0.06751992553472519
epoch 8: dev_f1=0.992108229988726, f1=0.9898074745186863, best_f1=0.9853107344632768
step: 0, loss: 0.07819945365190506
step: 10, loss: 0.00851638987660408
step: 20, loss: 0.07627128064632416
step: 30, loss: 0.1209046021103859
step: 40, loss: 0.04419976472854614
step: 50, loss: 0.0976538136601448
step: 60, loss: 0.07746966928243637
step: 70, loss: 0.1096542626619339
step: 80, loss: 0.04896201565861702
step: 90, loss: 0.05339811369776726
step: 100, loss: 0.13102388381958008
step: 110, loss: 0.07723512500524521
step: 120, loss: 0.07308363169431686
step: 130, loss: 0.01112968847155571
step: 140, loss: 0.005347392521798611
step: 150, loss: 0.11385457962751389
step: 160, loss: 0.11022345721721649
step: 170, loss: 0.1558249145746231
step: 180, loss: 0.04031063988804817
step: 190, loss: 0.00526244705542922
step: 200, loss: 0.009071431122720242
step: 210, loss: 0.08384758979082108
step: 220, loss: 0.041393086314201355
step: 230, loss: 7.882294448791072e-05
step: 240, loss: 0.08305492997169495
step: 250, loss: 0.037290796637535095
step: 260, loss: 0.15951424837112427
step: 270, loss: 0.005747325252741575
step: 280, loss: 0.007176169194281101
step: 290, loss: 0.015922190621495247
step: 300, loss: 0.0608036145567894
step: 310, loss: 0.06940093636512756
step: 320, loss: 0.03670281544327736
step: 330, loss: 0.006979337893426418
step: 340, loss: 0.002978329313918948
step: 350, loss: 0.08818511664867401
step: 360, loss: 0.0836266577243805
step: 370, loss: 0.0298325102776289
step: 380, loss: 0.019901925697922707
step: 390, loss: 0.02861092984676361
step: 400, loss: 0.11406917870044708
step: 410, loss: 0.07161739468574524
step: 420, loss: 0.15624429285526276
epoch 9: dev_f1=0.9932279909706545, f1=0.9830890642615557, best_f1=0.9853107344632768
step: 0, loss: 0.010105108842253685
step: 10, loss: 0.06500687450170517
step: 20, loss: 0.014700658619403839
step: 30, loss: 0.012820109724998474
step: 40, loss: 0.10024213790893555
step: 50, loss: 0.08826689422130585
step: 60, loss: 0.02992258034646511
step: 70, loss: 0.07508701831102371
step: 80, loss: 0.07116841524839401
step: 90, loss: 0.060842737555503845
step: 100, loss: 0.018548496067523956
step: 110, loss: 0.05737345665693283
step: 120, loss: 0.13841749727725983
step: 130, loss: 0.04164489731192589
step: 140, loss: 0.006875096820294857
step: 150, loss: 0.0526769794523716
step: 160, loss: 0.0031576738692820072
step: 170, loss: 0.06769994646310806
step: 180, loss: 0.0962894856929779
step: 190, loss: 0.04400860145688057
step: 200, loss: 0.07806821912527084
step: 210, loss: 0.012444281950592995
step: 220, loss: 0.2784292995929718
step: 230, loss: 0.03401730954647064
step: 240, loss: 0.03731735050678253
step: 250, loss: 0.030870795249938965
step: 260, loss: 0.04635641351342201
step: 270, loss: 0.04066909849643707
step: 280, loss: 0.10360530018806458
step: 290, loss: 0.010681592859327793
step: 300, loss: 0.002690455410629511
step: 310, loss: 0.06479982286691666
step: 320, loss: 0.019430391490459442
step: 330, loss: 0.11499203741550446
step: 340, loss: 0.1102227121591568
step: 350, loss: 0.04136297479271889
step: 360, loss: 0.10186813026666641
step: 370, loss: 0.13183331489562988
step: 380, loss: 0.04398682340979576
step: 390, loss: 0.08472704887390137
step: 400, loss: 0.027245281264185905
step: 410, loss: 0.13035979866981506
step: 420, loss: 0.10122751444578171
epoch 10: dev_f1=0.9921436588103255, f1=0.9832026875699889, best_f1=0.9853107344632768
step: 0, loss: 0.049541816115379333
step: 10, loss: 0.06426308304071426
step: 20, loss: 0.008005229756236076
step: 30, loss: 0.035772476345300674
step: 40, loss: 0.030595289543271065
step: 50, loss: 0.0379277803003788
step: 60, loss: 0.0185275636613369
step: 70, loss: 0.05816151946783066
step: 80, loss: 0.08659353107213974
step: 90, loss: 0.04437074065208435
step: 100, loss: 0.009300791658461094
step: 110, loss: 0.10703631490468979
step: 120, loss: 0.02246916852891445
step: 130, loss: 0.07055237889289856
step: 140, loss: 0.09265528619289398
step: 150, loss: 0.047010719776153564
step: 160, loss: 0.004961646627634764
step: 170, loss: 0.020177165046334267
step: 180, loss: 1.545609484310262e-05
step: 190, loss: 0.0005130150821059942
step: 200, loss: 0.07671476900577545
step: 210, loss: 0.05454568937420845
step: 220, loss: 0.10306014865636826
step: 230, loss: 0.011616956442594528
step: 240, loss: 0.04320184141397476
step: 250, loss: 0.0002941788698080927
step: 260, loss: 0.02668144181370735
step: 270, loss: 0.037168361246585846
step: 280, loss: 0.0387880839407444
step: 290, loss: 0.0438784696161747
step: 300, loss: 0.04656411334872246
step: 310, loss: 0.036141324788331985
step: 320, loss: 0.003924769349396229
step: 330, loss: 0.0004963111132383347
step: 340, loss: 0.023609202355146408
step: 350, loss: 0.032555267214775085
step: 360, loss: 0.043921127915382385
step: 370, loss: 0.09004346281290054
step: 380, loss: 0.01791694201529026
step: 390, loss: 0.02783246897161007
step: 400, loss: 0.0685756653547287
step: 410, loss: 0.035668905824422836
step: 420, loss: 0.04004146158695221
epoch 11: dev_f1=0.9921436588103255, f1=0.9832402234636871, best_f1=0.9853107344632768
step: 0, loss: 0.10328847914934158
step: 10, loss: 0.0474175401031971
step: 20, loss: 0.006959902588278055
step: 30, loss: 0.002446637023240328
step: 40, loss: 0.0395343042910099
step: 50, loss: 0.04928334057331085
step: 60, loss: 0.014960099011659622
step: 70, loss: 0.04919002950191498
step: 80, loss: 0.0032541495747864246
step: 90, loss: 0.011442573741078377
step: 100, loss: 0.041251275688409805
step: 110, loss: 0.03519759327173233
step: 120, loss: 0.04918401688337326
step: 130, loss: 0.021640608087182045
step: 140, loss: 0.03578605502843857
step: 150, loss: 0.020667901262640953
step: 160, loss: 0.017092609778046608
step: 170, loss: 0.0004800065071322024
step: 180, loss: 0.08164482563734055
step: 190, loss: 0.03337172046303749
step: 200, loss: 0.00792804453521967
step: 210, loss: 0.04062948003411293
step: 220, loss: 0.011719778180122375
step: 230, loss: 0.00017427910643164068
step: 240, loss: 0.012470326386392117
step: 250, loss: 0.03849388286471367
step: 260, loss: 0.010443421080708504
step: 270, loss: 0.029094193130731583
step: 280, loss: 0.023351436480879784
step: 290, loss: 0.0062859212048351765
step: 300, loss: 0.0017628498608246446
step: 310, loss: 0.03195144981145859
step: 320, loss: 0.016382534056901932
step: 330, loss: 0.002228229073807597
step: 340, loss: 0.016500990837812424
step: 350, loss: 0.020744312554597855
step: 360, loss: 0.004738334566354752
step: 370, loss: 0.031442996114492416
step: 380, loss: 0.03902149572968483
step: 390, loss: 0.042726319283246994
step: 400, loss: 0.0435396172106266
step: 410, loss: 0.05139357969164848
step: 420, loss: 0.016676614060997963
epoch 12: dev_f1=0.9943883277216611, f1=0.9831649831649831, best_f1=0.9831649831649831
step: 0, loss: 0.053855933248996735
step: 10, loss: 0.04906582459807396
step: 20, loss: 0.0001610871113371104
step: 30, loss: 0.011164561845362186
step: 40, loss: 0.033542562276124954
step: 50, loss: 0.02580307424068451
step: 60, loss: 5.102767318021506e-05
step: 70, loss: 0.0012194740120321512
step: 80, loss: 0.0002253133279737085
step: 90, loss: 0.0007530772127211094
step: 100, loss: 0.012405521236360073
step: 110, loss: 0.06654993444681168
step: 120, loss: 0.020682331174612045
step: 130, loss: 0.05811525881290436
step: 140, loss: 0.014278276823461056
step: 150, loss: 0.07118913531303406
step: 160, loss: 0.06283752620220184
step: 170, loss: 0.00572781078517437
step: 180, loss: 0.03449735417962074
step: 190, loss: 0.005633492488414049
step: 200, loss: 0.07976602017879486
step: 210, loss: 0.06893632560968399
step: 220, loss: 0.07650397717952728
step: 230, loss: 0.17006288468837738
step: 240, loss: 0.035003602504730225
step: 250, loss: 0.01816333644092083
step: 260, loss: 0.02193179354071617
step: 270, loss: 0.0003553342539817095
step: 280, loss: 0.02454942651093006
step: 290, loss: 0.05143478512763977
step: 300, loss: 2.0000847143819556e-05
step: 310, loss: 0.0027591767720878124
step: 320, loss: 0.02544877491891384
step: 330, loss: 0.0008995333919301629
step: 340, loss: 0.05427999421954155
step: 350, loss: 0.04059300571680069
step: 360, loss: 0.10871857404708862
step: 370, loss: 0.05086579918861389
step: 380, loss: 0.018846655264496803
step: 390, loss: 0.06302303820848465
step: 400, loss: 0.03462234511971474
step: 410, loss: 0.08243883401155472
step: 420, loss: 0.03059331141412258
epoch 13: dev_f1=0.990990990990991, f1=0.9842696629213483, best_f1=0.9831649831649831
step: 0, loss: 0.0015273537719622254
step: 10, loss: 0.029705967754125595
step: 20, loss: 0.08793474733829498
step: 30, loss: 0.020924050360918045
step: 40, loss: 0.03220066800713539
step: 50, loss: 0.029345931485295296
step: 60, loss: 0.0003506946668494493
step: 70, loss: 0.033274080604314804
step: 80, loss: 0.00022475849254988134
step: 90, loss: 2.0924551790812984e-05
step: 100, loss: 0.0074184914119541645
step: 110, loss: 0.0025393320247530937
step: 120, loss: 0.03998098894953728
step: 130, loss: 0.029181938618421555
step: 140, loss: 0.019246922805905342
step: 150, loss: 0.12750324606895447
step: 160, loss: 0.03125845268368721
step: 170, loss: 0.0006357067031785846
step: 180, loss: 0.00011102027201559395
step: 190, loss: 5.6262477301061153e-05
step: 200, loss: 0.02981993928551674
step: 210, loss: 0.000620395177975297
step: 220, loss: 0.10311257094144821
step: 230, loss: 0.015079393982887268
step: 240, loss: 0.03281798213720322
step: 250, loss: 0.025852955877780914
step: 260, loss: 0.05212372541427612
step: 270, loss: 0.034205637872219086
step: 280, loss: 0.06744662672281265
step: 290, loss: 6.841338472440839e-05
step: 300, loss: 0.02223539724946022
step: 310, loss: 0.017539912834763527
step: 320, loss: 0.0009703636169433594
step: 330, loss: 0.04463649541139603
step: 340, loss: 0.021048352122306824
step: 350, loss: 0.03279884159564972
step: 360, loss: 0.028901241719722748
step: 370, loss: 0.050567034631967545
step: 380, loss: 0.06426358968019485
step: 390, loss: 1.2546679499791935e-05
step: 400, loss: 0.10680138319730759
step: 410, loss: 0.050146378576755524
step: 420, loss: 0.025279751047492027
epoch 14: dev_f1=0.9921612541993281, f1=0.9833147942157954, best_f1=0.9831649831649831
step: 0, loss: 0.04132616147398949
step: 10, loss: 0.003847684944048524
step: 20, loss: 0.001630508922971785
step: 30, loss: 0.07171738147735596
step: 40, loss: 0.0005087749450467527
step: 50, loss: 0.05682562291622162
step: 60, loss: 0.003972353879362345
step: 70, loss: 0.04139436036348343
step: 80, loss: 1.4748231478733942e-05
step: 90, loss: 0.02959228679537773
step: 100, loss: 0.034680843353271484
step: 110, loss: 0.02394680865108967
step: 120, loss: 0.040271028876304626
step: 130, loss: 0.04232138767838478
step: 140, loss: 0.02299540489912033
step: 150, loss: 0.00114526879042387
step: 160, loss: 0.04715238884091377
step: 170, loss: 0.04804525524377823
step: 180, loss: 0.08323496580123901
step: 190, loss: 0.041599612683057785
step: 200, loss: 0.0002628812217153609
step: 210, loss: 1.2751554095302708e-05
step: 220, loss: 0.03520999848842621
step: 230, loss: 0.041687361896038055
step: 240, loss: 0.030131923034787178
step: 250, loss: 0.01156176719814539
step: 260, loss: 0.061374370008707047
step: 270, loss: 0.032260678708553314
step: 280, loss: 0.00024713072343729436
step: 290, loss: 0.021839473396539688
step: 300, loss: 0.02584880404174328
step: 310, loss: 0.0002090105408569798
step: 320, loss: 0.030261466279625893
step: 330, loss: 0.021016517654061317
step: 340, loss: 0.03131983429193497
step: 350, loss: 0.06613297015428543
step: 360, loss: 0.07500507682561874
step: 370, loss: 0.06041216850280762
step: 380, loss: 0.023034080862998962
step: 390, loss: 0.14440493285655975
step: 400, loss: 0.06581743061542511
step: 410, loss: 0.016968384385108948
step: 420, loss: 0.0005930262850597501
epoch 15: dev_f1=0.9921612541993281, f1=0.9843749999999999, best_f1=0.9831649831649831
step: 0, loss: 3.6735600588144735e-05
step: 10, loss: 0.07392214983701706
step: 20, loss: 0.04531428962945938
step: 30, loss: 0.0014564626617357135
step: 40, loss: 0.1363009661436081
step: 50, loss: 0.022217173129320145
step: 60, loss: 0.02599344402551651
step: 70, loss: 0.020146114751696587
step: 80, loss: 0.00010453409049659967
step: 90, loss: 0.019119681790471077
step: 100, loss: 0.025854943320155144
step: 110, loss: 0.01858750730752945
step: 120, loss: 0.029630742967128754
step: 130, loss: 0.0003424085152801126
step: 140, loss: 0.029133861884474754
step: 150, loss: 0.00015750009333714843
step: 160, loss: 0.04521853104233742
step: 170, loss: 0.0510132759809494
step: 180, loss: 0.037499092519283295
step: 190, loss: 0.00012894235260318965
step: 200, loss: 0.07813528925180435
step: 210, loss: 0.00013154424959793687
step: 220, loss: 0.020841149613261223
step: 230, loss: 0.03763372451066971
step: 240, loss: 0.022028720006346703
step: 250, loss: 0.06835392862558365
step: 260, loss: 0.09388448297977448
step: 270, loss: 0.05780583620071411
step: 280, loss: 0.05209444835782051
step: 290, loss: 0.01826125755906105
step: 300, loss: 0.020614055916666985
step: 310, loss: 0.016411656513810158
step: 320, loss: 0.024306589737534523
step: 330, loss: 0.05403919517993927
step: 340, loss: 0.0739855244755745
step: 350, loss: 0.03499671444296837
step: 360, loss: 0.00026099878596141934
step: 370, loss: 0.09103875607252121
step: 380, loss: 0.046617522835731506
step: 390, loss: 0.02136882394552231
step: 400, loss: 0.0002924864529632032
step: 410, loss: 0.03372819349169731
step: 420, loss: 0.011354262940585613
epoch 16: dev_f1=0.9921612541993281, f1=0.9844097995545658, best_f1=0.9831649831649831
step: 0, loss: 0.02958502806723118
step: 10, loss: 0.043795306235551834
step: 20, loss: 0.03452431783080101
step: 30, loss: 0.023720834404230118
step: 40, loss: 0.017185639590024948
step: 50, loss: 0.046345923095941544
step: 60, loss: 0.06968672573566437
step: 70, loss: 0.06016996502876282
step: 80, loss: 0.044226255267858505
step: 90, loss: 0.029428869485855103
step: 100, loss: 0.043363358825445175
step: 110, loss: 0.0010484564118087292
step: 120, loss: 0.0007874736911617219
step: 130, loss: 0.04254204407334328
step: 140, loss: 7.962194649735466e-05
step: 150, loss: 0.022590404376387596
step: 160, loss: 0.0240976233035326
step: 170, loss: 1.5362886188086122e-05
step: 180, loss: 0.01949763111770153
step: 190, loss: 0.0330498069524765
step: 200, loss: 0.023396283388137817
step: 210, loss: 0.017403773963451385
step: 220, loss: 0.06178953871130943
step: 230, loss: 0.00028132443549111485
step: 240, loss: 0.00046055184793658555
step: 250, loss: 0.06775151193141937
step: 260, loss: 0.0003394284285604954
step: 270, loss: 0.024251680821180344
step: 280, loss: 0.04030638188123703
step: 290, loss: 0.020885735750198364
step: 300, loss: 0.025634517893195152
step: 310, loss: 0.07920665293931961
step: 320, loss: 7.810497481841594e-05
step: 330, loss: 0.00015381482080556452
step: 340, loss: 0.03698493167757988
step: 350, loss: 0.02723458968102932
step: 360, loss: 0.02156713418662548
step: 370, loss: 0.0009661235380917788
step: 380, loss: 0.06659535318613052
step: 390, loss: 0.06499719619750977
step: 400, loss: 0.05893451347947121
step: 410, loss: 0.001293171662837267
step: 420, loss: 0.025868665426969528
epoch 17: dev_f1=0.9921612541993281, f1=0.9844097995545658, best_f1=0.9831649831649831
step: 0, loss: 9.566755034029484e-05
step: 10, loss: 0.020021237432956696
step: 20, loss: 0.024318963289260864
step: 30, loss: 0.006064921617507935
step: 40, loss: 9.018868695420679e-06
step: 50, loss: 5.929578037466854e-05
step: 60, loss: 0.0001702084846328944
step: 70, loss: 0.08304015547037125
step: 80, loss: 5.831219823448919e-05
step: 90, loss: 0.001995834056288004
step: 100, loss: 0.03772225230932236
step: 110, loss: 0.11459554731845856
step: 120, loss: 0.021757902577519417
step: 130, loss: 0.023409105837345123
step: 140, loss: 0.01795870251953602
step: 150, loss: 0.04535031318664551
step: 160, loss: 0.00040792327490635216
step: 170, loss: 6.84091355651617e-05
step: 180, loss: 0.022513164207339287
step: 190, loss: 0.03005916438996792
step: 200, loss: 0.01772945746779442
step: 210, loss: 0.024519182741642
step: 220, loss: 0.043797992169857025
step: 230, loss: 0.04387398436665535
step: 240, loss: 0.018720733001828194
step: 250, loss: 0.0684662014245987
step: 260, loss: 0.044949281960725784
step: 270, loss: 0.03866086155176163
step: 280, loss: 0.023104652762413025
step: 290, loss: 0.0434441976249218
step: 300, loss: 0.05345841497182846
step: 310, loss: 0.045318275690078735
step: 320, loss: 9.059686271939427e-05
step: 330, loss: 6.351490446832031e-05
step: 340, loss: 8.421007078140974e-05
step: 350, loss: 0.030857834964990616
step: 360, loss: 0.038972873240709305
step: 370, loss: 0.023121310397982597
step: 380, loss: 0.01948978379368782
step: 390, loss: 0.02121402509510517
step: 400, loss: 0.04343067854642868
step: 410, loss: 0.021072424948215485
step: 420, loss: 0.04356922581791878
epoch 18: dev_f1=0.9910313901345291, f1=0.9832402234636871, best_f1=0.9831649831649831
step: 0, loss: 0.029311519116163254
step: 10, loss: 5.46600749657955e-05
step: 20, loss: 0.046073976904153824
step: 30, loss: 6.738003139616922e-05
step: 40, loss: 0.00010135687625734136
step: 50, loss: 4.381733378977515e-05
step: 60, loss: 0.022310206666588783
step: 70, loss: 0.03285490348935127
step: 80, loss: 0.018142569810152054
step: 90, loss: 0.05308987572789192
step: 100, loss: 0.018260857090353966
step: 110, loss: 0.02215999737381935
step: 120, loss: 0.02334020659327507
step: 130, loss: 0.045306045562028885
step: 140, loss: 0.05806456878781319
step: 150, loss: 0.02750173583626747
step: 160, loss: 0.024494152516126633
step: 170, loss: 0.023249639198184013
step: 180, loss: 0.000985095975920558
step: 190, loss: 0.0019555215258151293
step: 200, loss: 0.053251929581165314
step: 210, loss: 0.018396392464637756
step: 220, loss: 0.06988176703453064
step: 230, loss: 0.0008149402565322816
step: 240, loss: 0.04411247745156288
step: 250, loss: 0.00016957908519543707
step: 260, loss: 0.00012223937665112317
step: 270, loss: 0.04906899854540825
step: 280, loss: 0.01943240873515606
step: 290, loss: 0.12763167917728424
step: 300, loss: 0.04954240843653679
step: 310, loss: 0.04763226583600044
step: 320, loss: 0.04487122595310211
step: 330, loss: 0.02198994904756546
step: 340, loss: 6.290620513027534e-05
step: 350, loss: 0.0007477668114006519
step: 360, loss: 0.04274458810687065
step: 370, loss: 0.04047539085149765
step: 380, loss: 0.0011992821237072349
step: 390, loss: 0.00022137259657029063
step: 400, loss: 0.06504613906145096
step: 410, loss: 0.0005409024888649583
step: 420, loss: 0.0001119382432079874
epoch 19: dev_f1=0.9921612541993281, f1=0.9821428571428571, best_f1=0.9831649831649831
step: 0, loss: 0.0062726642936468124
step: 10, loss: 0.056870248168706894
step: 20, loss: 0.03475247323513031
step: 30, loss: 4.894101220997982e-05
step: 40, loss: 0.04002764821052551
step: 50, loss: 0.021947726607322693
step: 60, loss: 0.025136858224868774
step: 70, loss: 0.00015378261741716415
step: 80, loss: 0.00046906183706596494
step: 90, loss: 0.025263851508498192
step: 100, loss: 0.018190043047070503
step: 110, loss: 2.8823415050283074e-05
step: 120, loss: 0.02062639221549034
step: 130, loss: 0.022323280572891235
step: 140, loss: 0.0001247124164365232
step: 150, loss: 0.045927781611680984
step: 160, loss: 0.0003159022890031338
step: 170, loss: 0.00019824897754006088
step: 180, loss: 0.024624066427350044
step: 190, loss: 0.040004853159189224
step: 200, loss: 0.022540170699357986
step: 210, loss: 0.03913302719593048
step: 220, loss: 3.8388578104786575e-05
step: 230, loss: 0.0384426973760128
step: 240, loss: 0.02369258552789688
step: 250, loss: 9.239221981260926e-05
step: 260, loss: 0.024140795692801476
step: 270, loss: 0.02000323124229908
step: 280, loss: 0.019227098673582077
step: 290, loss: 1.6308622434735298e-05
step: 300, loss: 0.022661302238702774
step: 310, loss: 0.025644196197390556
step: 320, loss: 0.05188237130641937
step: 330, loss: 0.03841211646795273
step: 340, loss: 0.04304727539420128
step: 350, loss: 0.04354578256607056
step: 360, loss: 0.05137135833501816
step: 370, loss: 0.045683618634939194
step: 380, loss: 0.00010416672012070194
step: 390, loss: 5.812981180497445e-05
step: 400, loss: 9.847414185060188e-05
step: 410, loss: 0.03945591673254967
step: 420, loss: 0.02011842094361782
epoch 20: dev_f1=0.9910313901345291, f1=0.9832402234636871, best_f1=0.9831649831649831
