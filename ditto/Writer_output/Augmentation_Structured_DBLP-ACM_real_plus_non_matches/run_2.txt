cuda
Device: cuda
step: 0, loss: 0.7897279858589172
step: 10, loss: 0.30928337574005127
step: 20, loss: 0.3990766108036041
step: 30, loss: 0.13194362819194794
step: 40, loss: 0.17560118436813354
step: 50, loss: 0.11708113551139832
step: 60, loss: 0.04487736523151398
step: 70, loss: 0.3066214919090271
step: 80, loss: 0.08007459342479706
step: 90, loss: 0.15771712362766266
step: 100, loss: 0.06815174967050552
step: 110, loss: 0.07682402431964874
step: 120, loss: 0.42560166120529175
step: 130, loss: 0.11379434913396835
step: 140, loss: 0.10256747156381607
step: 150, loss: 0.20331548154354095
step: 160, loss: 0.05433901399374008
step: 170, loss: 0.1496703028678894
step: 180, loss: 0.05987710878252983
step: 190, loss: 0.07973744720220566
step: 200, loss: 0.08592738211154938
step: 210, loss: 0.07730068266391754
step: 220, loss: 0.04004070907831192
step: 230, loss: 0.09591899067163467
step: 240, loss: 0.07651395350694656
step: 250, loss: 0.08998555690050125
step: 260, loss: 0.005166361108422279
step: 270, loss: 0.04109993949532509
step: 280, loss: 0.006353977136313915
step: 290, loss: 0.09646014869213104
step: 300, loss: 0.03577125445008278
step: 310, loss: 0.09065130352973938
step: 320, loss: 0.07639695703983307
step: 330, loss: 0.05685148015618324
step: 340, loss: 0.1036224216222763
step: 350, loss: 0.2061121016740799
step: 360, loss: 0.047621868550777435
step: 370, loss: 0.02382400445640087
step: 380, loss: 0.028698036447167397
step: 390, loss: 0.02100220136344433
step: 400, loss: 0.07376492768526077
step: 410, loss: 0.08851217478513718
step: 420, loss: 0.10595656931400299
epoch 1: dev_f1=0.977728285077951, f1=0.96875, best_f1=0.96875
step: 0, loss: 0.03714059293270111
step: 10, loss: 0.1707931011915207
step: 20, loss: 0.018101096153259277
step: 30, loss: 0.035660676658153534
step: 40, loss: 0.10839290916919708
step: 50, loss: 0.2093396782875061
step: 60, loss: 0.012948747724294662
step: 70, loss: 0.0895235538482666
step: 80, loss: 0.04980742558836937
step: 90, loss: 0.06343529373407364
step: 100, loss: 0.07043278962373734
step: 110, loss: 0.04183759540319443
step: 120, loss: 0.01355401985347271
step: 130, loss: 0.0046475473791360855
step: 140, loss: 0.11061125248670578
step: 150, loss: 0.07428409159183502
step: 160, loss: 0.027554292231798172
step: 170, loss: 0.01184419821947813
step: 180, loss: 0.015543715097010136
step: 190, loss: 0.03363864868879318
step: 200, loss: 0.027432136237621307
step: 210, loss: 0.010286079719662666
step: 220, loss: 0.013861213810741901
step: 230, loss: 0.026662679389119148
step: 240, loss: 0.08761312812566757
step: 250, loss: 0.07952457666397095
step: 260, loss: 0.009338632225990295
step: 270, loss: 0.32133832573890686
step: 280, loss: 0.029108207672834396
step: 290, loss: 0.013645458966493607
step: 300, loss: 0.0813380554318428
step: 310, loss: 0.1522226482629776
step: 320, loss: 0.06882891803979874
step: 330, loss: 0.0070631010457873344
step: 340, loss: 0.07962155342102051
step: 350, loss: 0.04264877736568451
step: 360, loss: 0.010839620605111122
step: 370, loss: 0.04630444943904877
step: 380, loss: 0.11003243178129196
step: 390, loss: 0.025361258536577225
step: 400, loss: 0.0007331729866564274
step: 410, loss: 0.011199094355106354
step: 420, loss: 0.03134417161345482
epoch 2: dev_f1=0.9853107344632768, f1=0.9775784753363228, best_f1=0.9775784753363228
step: 0, loss: 0.019248614087700844
step: 10, loss: 0.026695862412452698
step: 20, loss: 0.01744910329580307
step: 30, loss: 0.01218228880316019
step: 40, loss: 0.03269471973180771
step: 50, loss: 0.02413066104054451
step: 60, loss: 0.05961715430021286
step: 70, loss: 0.015604918822646141
step: 80, loss: 0.07192199677228928
step: 90, loss: 0.01299651712179184
step: 100, loss: 0.07364469766616821
step: 110, loss: 0.03255067765712738
step: 120, loss: 0.013913973234593868
step: 130, loss: 0.08403206616640091
step: 140, loss: 0.02074679359793663
step: 150, loss: 0.04606294259428978
step: 160, loss: 0.04522358626127243
step: 170, loss: 0.024935290217399597
step: 180, loss: 0.14551658928394318
step: 190, loss: 0.018928170204162598
step: 200, loss: 0.08106084913015366
step: 210, loss: 0.2535627782344818
step: 220, loss: 0.027662204578518867
step: 230, loss: 0.04489775747060776
step: 240, loss: 0.022258728742599487
step: 250, loss: 0.009370318613946438
step: 260, loss: 0.1393892914056778
step: 270, loss: 0.0821627527475357
step: 280, loss: 0.011686911806464195
step: 290, loss: 0.1422925889492035
step: 300, loss: 0.07348493486642838
step: 310, loss: 0.021890249103307724
step: 320, loss: 0.0761062502861023
step: 330, loss: 0.08775065094232559
step: 340, loss: 0.03539661690592766
step: 350, loss: 0.11382989585399628
step: 360, loss: 0.03832476958632469
step: 370, loss: 0.11690236628055573
step: 380, loss: 0.1433243453502655
step: 390, loss: 0.0845029354095459
step: 400, loss: 0.07966721802949905
step: 410, loss: 0.003959133289754391
step: 420, loss: 0.02999863587319851
epoch 3: dev_f1=0.9921259842519685, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 0.03323567658662796
step: 10, loss: 0.019416991621255875
step: 20, loss: 0.044365428388118744
step: 30, loss: 0.057950109243392944
step: 40, loss: 0.02781740576028824
step: 50, loss: 0.025254283100366592
step: 60, loss: 0.019137637689709663
step: 70, loss: 0.00015259561769198626
step: 80, loss: 0.07323967665433884
step: 90, loss: 0.014219327829778194
step: 100, loss: 0.06689520925283432
step: 110, loss: 0.014057045802474022
step: 120, loss: 0.1572386771440506
step: 130, loss: 0.0861266553401947
step: 140, loss: 0.07075998932123184
step: 150, loss: 0.07103408873081207
step: 160, loss: 0.053364355117082596
step: 170, loss: 0.03366101533174515
step: 180, loss: 0.009658877737820148
step: 190, loss: 0.005058463662862778
step: 200, loss: 0.17916440963745117
step: 210, loss: 0.06897889822721481
step: 220, loss: 0.06923512369394302
step: 230, loss: 0.057979434728622437
step: 240, loss: 0.03391168266534805
step: 250, loss: 0.02049848809838295
step: 260, loss: 0.14787131547927856
step: 270, loss: 0.010698836296796799
step: 280, loss: 0.01920553296804428
step: 290, loss: 0.08095692843198776
step: 300, loss: 0.012852255254983902
step: 310, loss: 0.0920337662100792
step: 320, loss: 0.07965059578418732
step: 330, loss: 0.07074402272701263
step: 340, loss: 0.1178443655371666
step: 350, loss: 0.09233620762825012
step: 360, loss: 0.07897299528121948
step: 370, loss: 0.08568065613508224
step: 380, loss: 0.10562393814325333
step: 390, loss: 0.06786848604679108
step: 400, loss: 0.11189384013414383
step: 410, loss: 0.033527880907058716
step: 420, loss: 0.06734605878591537
epoch 4: dev_f1=0.9899216125419933, f1=0.9831649831649831, best_f1=0.984304932735426
step: 0, loss: 0.025504153221845627
step: 10, loss: 0.04210609942674637
step: 20, loss: 0.07725603133440018
step: 30, loss: 0.010053703561425209
step: 40, loss: 0.05843101441860199
step: 50, loss: 0.15392711758613586
step: 60, loss: 0.032857004553079605
step: 70, loss: 0.017939018085598946
step: 80, loss: 0.024793602526187897
step: 90, loss: 0.016950013116002083
step: 100, loss: 0.12828129529953003
step: 110, loss: 0.0223025344312191
step: 120, loss: 0.020963530987501144
step: 130, loss: 0.09322141110897064
step: 140, loss: 0.09149689227342606
step: 150, loss: 0.028009697794914246
step: 160, loss: 0.02863837592303753
step: 170, loss: 0.07351980358362198
step: 180, loss: 0.07855412364006042
step: 190, loss: 0.07716647535562515
step: 200, loss: 0.11227169632911682
step: 210, loss: 0.00010507201659493148
step: 220, loss: 0.07356362044811249
step: 230, loss: 0.0813649371266365
step: 240, loss: 0.06953602284193039
step: 250, loss: 0.06532251089811325
step: 260, loss: 0.014342047274112701
step: 270, loss: 0.1197214424610138
step: 280, loss: 0.013134023174643517
step: 290, loss: 0.028401091694831848
step: 300, loss: 0.06937216222286224
step: 310, loss: 0.005358886905014515
step: 320, loss: 0.003002125769853592
step: 330, loss: 0.15326595306396484
step: 340, loss: 0.08192168921232224
step: 350, loss: 0.00452321395277977
step: 360, loss: 0.026672471314668655
step: 370, loss: 0.00010411092807771638
step: 380, loss: 0.05955728143453598
step: 390, loss: 0.0658380538225174
step: 400, loss: 0.014355645515024662
step: 410, loss: 0.007914923131465912
step: 420, loss: 0.035805027931928635
epoch 5: dev_f1=0.9898074745186863, f1=0.984090909090909, best_f1=0.984304932735426
step: 0, loss: 0.02617787942290306
step: 10, loss: 0.07808490842580795
step: 20, loss: 0.025484466925263405
step: 30, loss: 0.06557676941156387
step: 40, loss: 0.09704702347517014
step: 50, loss: 0.14081820845603943
step: 60, loss: 0.07215920835733414
step: 70, loss: 0.07967044413089752
step: 80, loss: 0.02389790117740631
step: 90, loss: 0.06881771236658096
step: 100, loss: 0.07202346622943878
step: 110, loss: 0.15759076178073883
step: 120, loss: 0.03561584651470184
step: 130, loss: 0.08832617104053497
step: 140, loss: 0.013739155605435371
step: 150, loss: 0.002273047575727105
step: 160, loss: 0.04740218073129654
step: 170, loss: 0.12778916954994202
step: 180, loss: 0.04870844632387161
step: 190, loss: 0.09327152371406555
step: 200, loss: 0.04197224974632263
step: 210, loss: 0.11153015494346619
step: 220, loss: 0.026714712381362915
step: 230, loss: 0.037485696375370026
step: 240, loss: 0.22575657069683075
step: 250, loss: 0.047979820519685745
step: 260, loss: 0.0069225262850522995
step: 270, loss: 0.06384767591953278
step: 280, loss: 0.018191810697317123
step: 290, loss: 0.0686454102396965
step: 300, loss: 0.11427286267280579
step: 310, loss: 7.841279148124158e-05
step: 320, loss: 0.05252096429467201
step: 330, loss: 0.08725294470787048
step: 340, loss: 0.05148862674832344
step: 350, loss: 0.132918119430542
step: 360, loss: 0.011085152626037598
step: 370, loss: 0.019535645842552185
step: 380, loss: 0.07822345197200775
step: 390, loss: 0.048072490841150284
step: 400, loss: 0.02392704039812088
step: 410, loss: 0.1562187522649765
step: 420, loss: 0.06756527721881866
epoch 6: dev_f1=0.9909706546275394, f1=0.9808773903262092, best_f1=0.984304932735426
step: 0, loss: 0.02971140667796135
step: 10, loss: 0.07457480579614639
step: 20, loss: 0.018880020827054977
step: 30, loss: 0.014926671981811523
step: 40, loss: 0.14359323680400848
step: 50, loss: 0.03963669016957283
step: 60, loss: 0.03034413605928421
step: 70, loss: 0.1546425223350525
step: 80, loss: 0.014506259933114052
step: 90, loss: 0.02012755535542965
step: 100, loss: 0.10772290080785751
step: 110, loss: 0.07604950666427612
step: 120, loss: 0.14999602735042572
step: 130, loss: 0.024199767038226128
step: 140, loss: 0.03428461402654648
step: 150, loss: 0.0807570144534111
step: 160, loss: 0.07427239418029785
step: 170, loss: 0.02987195923924446
step: 180, loss: 0.12085467576980591
step: 190, loss: 0.004441629163920879
step: 200, loss: 0.0371164046227932
step: 210, loss: 0.01766781136393547
step: 220, loss: 0.019490506500005722
step: 230, loss: 0.06419849395751953
step: 240, loss: 0.11671619117259979
step: 250, loss: 0.12914209067821503
step: 260, loss: 0.05759914591908455
step: 270, loss: 0.01351609081029892
step: 280, loss: 0.12152907997369766
step: 290, loss: 0.09573089331388474
step: 300, loss: 0.013282956555485725
step: 310, loss: 0.0032537588849663734
step: 320, loss: 0.08678143471479416
step: 330, loss: 0.0002402197424089536
step: 340, loss: 0.3058336079120636
step: 350, loss: 0.00011693873966578394
step: 360, loss: 0.044897161424160004
step: 370, loss: 0.1486731618642807
step: 380, loss: 0.07812865823507309
step: 390, loss: 0.2522122859954834
step: 400, loss: 0.016603203490376472
step: 410, loss: 0.05193402245640755
step: 420, loss: 0.09994189441204071
epoch 7: dev_f1=0.9932735426008968, f1=0.9809203142536477, best_f1=0.9809203142536477
step: 0, loss: 0.0066762990318238735
step: 10, loss: 0.058752257376909256
step: 20, loss: 0.022000107914209366
step: 30, loss: 0.1434158980846405
step: 40, loss: 0.08602533489465714
step: 50, loss: 0.02134867012500763
step: 60, loss: 0.014776311814785004
step: 70, loss: 0.05425665155053139
step: 80, loss: 0.10895226150751114
step: 90, loss: 0.02020121179521084
step: 100, loss: 0.08620568364858627
step: 110, loss: 0.02696293592453003
step: 120, loss: 0.08554890006780624
step: 130, loss: 0.005043098237365484
step: 140, loss: 0.08733218163251877
step: 150, loss: 0.08767508715391159
step: 160, loss: 0.024661622941493988
step: 170, loss: 0.01631942205131054
step: 180, loss: 0.11029289662837982
step: 190, loss: 0.059729788452386856
step: 200, loss: 0.021117838099598885
step: 210, loss: 0.019547734409570694
step: 220, loss: 0.013090204447507858
step: 230, loss: 0.0010291741928085685
step: 240, loss: 0.01257352251559496
step: 250, loss: 0.024172546342015266
step: 260, loss: 0.0645115077495575
step: 270, loss: 0.06011645495891571
step: 280, loss: 0.03810618817806244
step: 290, loss: 0.09039150923490524
step: 300, loss: 0.010509263724088669
step: 310, loss: 0.10759237408638
step: 320, loss: 0.012820601463317871
step: 330, loss: 0.082933209836483
step: 340, loss: 0.03552186116576195
step: 350, loss: 0.08770444989204407
step: 360, loss: 0.1447812020778656
step: 370, loss: 0.02042541094124317
step: 380, loss: 0.011045819148421288
step: 390, loss: 0.029866782948374748
step: 400, loss: 0.007449891418218613
step: 410, loss: 0.06875970959663391
step: 420, loss: 0.06881866604089737
epoch 8: dev_f1=0.9932584269662922, f1=0.9832402234636871, best_f1=0.9809203142536477
step: 0, loss: 0.0782407894730568
step: 10, loss: 0.0102144880220294
step: 20, loss: 0.04496675729751587
step: 30, loss: 0.021892782300710678
step: 40, loss: 0.012537281960248947
step: 50, loss: 0.003283133264631033
step: 60, loss: 0.11883559823036194
step: 70, loss: 0.060791295021772385
step: 80, loss: 0.030640028417110443
step: 90, loss: 0.05661400407552719
step: 100, loss: 0.08066195249557495
step: 110, loss: 0.10142725706100464
step: 120, loss: 0.06690775603055954
step: 130, loss: 0.023079123347997665
step: 140, loss: 0.02112133614718914
step: 150, loss: 0.01941753923892975
step: 160, loss: 0.08650790899991989
step: 170, loss: 0.04275471344590187
step: 180, loss: 0.03466145321726799
step: 190, loss: 0.18954141438007355
step: 200, loss: 0.004368994385004044
step: 210, loss: 0.08703457564115524
step: 220, loss: 0.04841373860836029
step: 230, loss: 0.027326306328177452
step: 240, loss: 0.07242472469806671
step: 250, loss: 0.047611210495233536
step: 260, loss: 0.09991385042667389
step: 270, loss: 0.07322303205728531
step: 280, loss: 0.026688329875469208
step: 290, loss: 0.21591134369373322
step: 300, loss: 0.013188895769417286
step: 310, loss: 0.027377385646104813
step: 320, loss: 0.03360944613814354
step: 330, loss: 0.009537561796605587
step: 340, loss: 0.03977254033088684
step: 350, loss: 0.019759073853492737
step: 360, loss: 0.02118472009897232
step: 370, loss: 0.08188256621360779
step: 380, loss: 0.01353106927126646
step: 390, loss: 0.08984781801700592
step: 400, loss: 0.020460691303014755
step: 410, loss: 0.14516976475715637
step: 420, loss: 0.09144435077905655
epoch 9: dev_f1=0.9921612541993281, f1=0.9723756906077348, best_f1=0.9809203142536477
step: 0, loss: 0.12481499463319778
step: 10, loss: 0.0399407222867012
step: 20, loss: 0.01751071773469448
step: 30, loss: 0.07912661135196686
step: 40, loss: 0.07941117137670517
step: 50, loss: 0.003918476868420839
step: 60, loss: 0.03233367204666138
step: 70, loss: 0.011805297806859016
step: 80, loss: 0.1318320482969284
step: 90, loss: 0.006218797527253628
step: 100, loss: 0.07279329746961594
step: 110, loss: 0.053133513778448105
step: 120, loss: 0.11204126477241516
step: 130, loss: 0.04091429337859154
step: 140, loss: 0.022956058382987976
step: 150, loss: 0.04104285314679146
step: 160, loss: 0.10175540298223495
step: 170, loss: 0.04764367640018463
step: 180, loss: 0.03968525305390358
step: 190, loss: 0.07673073559999466
step: 200, loss: 0.05546852946281433
step: 210, loss: 0.009899448603391647
step: 220, loss: 0.0068189469166100025
step: 230, loss: 0.004675226751714945
step: 240, loss: 0.005925256758928299
step: 250, loss: 0.017645420506596565
step: 260, loss: 0.11882764846086502
step: 270, loss: 0.010221554897725582
step: 280, loss: 0.04639773443341255
step: 290, loss: 0.01904447004199028
step: 300, loss: 0.010816988535225391
step: 310, loss: 0.005094446707516909
step: 320, loss: 0.011408239603042603
step: 330, loss: 0.007621283642947674
step: 340, loss: 0.16944557428359985
step: 350, loss: 0.0758223608136177
step: 360, loss: 0.03232768550515175
step: 370, loss: 0.04084498807787895
step: 380, loss: 0.18912629783153534
step: 390, loss: 0.07085425406694412
step: 400, loss: 0.07979767769575119
step: 410, loss: 0.0380125492811203
step: 420, loss: 0.012873819097876549
epoch 10: dev_f1=0.9910112359550561, f1=0.9787234042553192, best_f1=0.9809203142536477
step: 0, loss: 0.0276408102363348
step: 10, loss: 0.056555747985839844
step: 20, loss: 0.015976931899785995
step: 30, loss: 0.011758559383451939
step: 40, loss: 0.0020451778545975685
step: 50, loss: 0.002153753535822034
step: 60, loss: 0.03350367024540901
step: 70, loss: 0.04593760147690773
step: 80, loss: 0.10633380711078644
step: 90, loss: 0.009345412254333496
step: 100, loss: 0.17313836514949799
step: 110, loss: 0.0011878898367285728
step: 120, loss: 0.06498485803604126
step: 130, loss: 0.03319769352674484
step: 140, loss: 0.04570512846112251
step: 150, loss: 0.007405837997794151
step: 160, loss: 0.030104896053671837
step: 170, loss: 0.1604318916797638
step: 180, loss: 0.05550999194383621
step: 190, loss: 0.011030217632651329
step: 200, loss: 0.1560792624950409
step: 210, loss: 0.12573686242103577
step: 220, loss: 0.06549759954214096
step: 230, loss: 0.07790477573871613
step: 240, loss: 0.03420059382915497
step: 250, loss: 0.0491766557097435
step: 260, loss: 0.02984018810093403
step: 270, loss: 0.020272430032491684
step: 280, loss: 0.002727970015257597
step: 290, loss: 0.0010195458307862282
step: 300, loss: 0.04786381125450134
step: 310, loss: 0.02449752949178219
step: 320, loss: 0.03969168663024902
step: 330, loss: 0.0039035691879689693
step: 340, loss: 0.0747513622045517
step: 350, loss: 0.050017498433589935
step: 360, loss: 0.005658519454300404
step: 370, loss: 0.005788235925137997
step: 380, loss: 0.03800716996192932
step: 390, loss: 0.05829787254333496
step: 400, loss: 0.19266030192375183
step: 410, loss: 0.10220034420490265
step: 420, loss: 0.018266888335347176
epoch 11: dev_f1=0.9932126696832579, f1=0.9819004524886877, best_f1=0.9809203142536477
step: 0, loss: 0.06041468307375908
step: 10, loss: 0.03058451972901821
step: 20, loss: 0.02827349305152893
step: 30, loss: 0.050291724503040314
step: 40, loss: 0.10281360894441605
step: 50, loss: 0.061368655413389206
step: 60, loss: 0.12443126738071442
step: 70, loss: 0.008822191506624222
step: 80, loss: 0.05118092894554138
step: 90, loss: 0.042252156883478165
step: 100, loss: 0.0010560516966506839
step: 110, loss: 0.08114658296108246
step: 120, loss: 0.039179954677820206
step: 130, loss: 0.02642914466559887
step: 140, loss: 0.0402737632393837
step: 150, loss: 0.023477276787161827
step: 160, loss: 0.0451333150267601
step: 170, loss: 0.08147972822189331
step: 180, loss: 0.017615454271435738
step: 190, loss: 0.004381422884762287
step: 200, loss: 0.018133249133825302
step: 210, loss: 0.0004891589051112533
step: 220, loss: 0.07869281619787216
step: 230, loss: 0.03722772374749184
step: 240, loss: 0.07984837144613266
step: 250, loss: 0.027988756075501442
step: 260, loss: 0.028268765658140182
step: 270, loss: 0.00013303509331308305
step: 280, loss: 0.06470157951116562
step: 290, loss: 0.12890960276126862
step: 300, loss: 0.009887519292533398
step: 310, loss: 0.05134893208742142
step: 320, loss: 0.025241052731871605
step: 330, loss: 0.06109499931335449
step: 340, loss: 0.004399478435516357
step: 350, loss: 0.05651151016354561
step: 360, loss: 0.05404820665717125
step: 370, loss: 0.04479297995567322
step: 380, loss: 0.011634571477770805
step: 390, loss: 0.027374768629670143
step: 400, loss: 0.02537672221660614
step: 410, loss: 0.002614324912428856
step: 420, loss: 0.04706517234444618
epoch 12: dev_f1=0.9932584269662922, f1=0.9832026875699889, best_f1=0.9809203142536477
step: 0, loss: 0.0052003622986376286
step: 10, loss: 0.0734238401055336
step: 20, loss: 0.006386034656316042
step: 30, loss: 0.0049554649740457535
step: 40, loss: 0.036317385733127594
step: 50, loss: 0.014116589911282063
step: 60, loss: 0.024273592978715897
step: 70, loss: 0.055041708052158356
step: 80, loss: 0.0011472669430077076
step: 90, loss: 2.543514892749954e-05
step: 100, loss: 0.023750588297843933
step: 110, loss: 1.2513163710536901e-05
step: 120, loss: 0.008641000837087631
step: 130, loss: 0.020438561215996742
step: 140, loss: 0.09543427079916
step: 150, loss: 0.00010865328658837825
step: 160, loss: 0.03639309108257294
step: 170, loss: 0.1179567202925682
step: 180, loss: 0.04377172514796257
step: 190, loss: 0.034207534044981
step: 200, loss: 0.024001341313123703
step: 210, loss: 0.08391554653644562
step: 220, loss: 0.00018117952276952565
step: 230, loss: 0.06461922079324722
step: 240, loss: 0.04465702921152115
step: 250, loss: 0.018243327736854553
step: 260, loss: 0.003818294731900096
step: 270, loss: 0.011322912760078907
step: 280, loss: 0.03596753999590874
step: 290, loss: 0.0336821973323822
step: 300, loss: 0.04540790244936943
step: 310, loss: 0.0014864380937069654
step: 320, loss: 0.02825629711151123
step: 330, loss: 0.024626102298498154
step: 340, loss: 0.010935775004327297
step: 350, loss: 0.003395402105525136
step: 360, loss: 0.001781216124072671
step: 370, loss: 0.05115310102701187
step: 380, loss: 0.00040360804996453226
step: 390, loss: 0.035667382180690765
step: 400, loss: 0.06096481531858444
step: 410, loss: 0.05563092976808548
step: 420, loss: 0.00039222490158863366
epoch 13: dev_f1=0.9932432432432432, f1=0.9843400447427293, best_f1=0.9809203142536477
step: 0, loss: 0.011313899420201778
step: 10, loss: 0.02578018233180046
step: 20, loss: 0.0006623721565119922
step: 30, loss: 0.05776548385620117
step: 40, loss: 0.02293762005865574
step: 50, loss: 0.026121513918042183
step: 60, loss: 0.0655878484249115
step: 70, loss: 0.0320938304066658
step: 80, loss: 0.00015740792150609195
step: 90, loss: 0.018943069502711296
step: 100, loss: 0.021063365042209625
step: 110, loss: 0.023575013503432274
step: 120, loss: 0.045958686619997025
step: 130, loss: 4.4637905375566334e-05
step: 140, loss: 0.0002681550686247647
step: 150, loss: 0.15966084599494934
step: 160, loss: 0.061845120042562485
step: 170, loss: 0.0002983585582114756
step: 180, loss: 0.005058319307863712
step: 190, loss: 0.04836243391036987
step: 200, loss: 0.0011185952462255955
step: 210, loss: 0.04083462059497833
step: 220, loss: 0.08319470286369324
step: 230, loss: 0.05312960594892502
step: 240, loss: 0.01963214948773384
step: 250, loss: 0.007328722160309553
step: 260, loss: 0.026626234874129295
step: 270, loss: 0.0007579749217256904
step: 280, loss: 0.04337119311094284
step: 290, loss: 9.798206883715466e-05
step: 300, loss: 0.00021069329523015767
step: 310, loss: 0.025065364316105843
step: 320, loss: 0.0005336775211617351
step: 330, loss: 0.05734048783779144
step: 340, loss: 0.01919766329228878
step: 350, loss: 0.02122313529253006
step: 360, loss: 0.0326353944838047
step: 370, loss: 0.11080493777990341
step: 380, loss: 0.017202649265527725
step: 390, loss: 0.0045836446806788445
step: 400, loss: 0.012983732856810093
step: 410, loss: 0.000604224915150553
step: 420, loss: 0.05064873397350311
epoch 14: dev_f1=0.9932432432432432, f1=0.9832026875699889, best_f1=0.9809203142536477
step: 0, loss: 0.01766337640583515
step: 10, loss: 0.04296410083770752
step: 20, loss: 0.043868109583854675
step: 30, loss: 0.1058516800403595
step: 40, loss: 0.024422932416200638
step: 50, loss: 0.022754954174160957
step: 60, loss: 0.0029962488915771246
step: 70, loss: 0.015859557315707207
step: 80, loss: 0.06317466497421265
step: 90, loss: 0.017384033650159836
step: 100, loss: 8.241322211688384e-05
step: 110, loss: 0.09963115304708481
step: 120, loss: 0.04890004172921181
step: 130, loss: 9.303243859903887e-05
step: 140, loss: 0.022991741076111794
step: 150, loss: 0.015840359032154083
step: 160, loss: 0.01692298986017704
step: 170, loss: 0.008011114783585072
step: 180, loss: 3.894142355420627e-05
step: 190, loss: 0.04090110957622528
step: 200, loss: 0.04355109483003616
step: 210, loss: 0.04107782617211342
step: 220, loss: 0.017187045887112617
step: 230, loss: 0.053967226296663284
step: 240, loss: 0.0474553108215332
step: 250, loss: 0.011686903424561024
step: 260, loss: 0.04144672304391861
step: 270, loss: 0.00017291895346716046
step: 280, loss: 0.06840448081493378
step: 290, loss: 0.0007355454727075994
step: 300, loss: 0.021175043657422066
step: 310, loss: 0.006862466223537922
step: 320, loss: 0.05301647633314133
step: 330, loss: 0.02659309096634388
step: 340, loss: 0.06404011696577072
step: 350, loss: 0.02185356803238392
step: 360, loss: 0.02282898500561714
step: 370, loss: 2.448517807351891e-05
step: 380, loss: 0.03829097002744675
step: 390, loss: 0.02675158530473709
step: 400, loss: 0.03362075239419937
step: 410, loss: 0.029016640037298203
step: 420, loss: 0.01960979402065277
epoch 15: dev_f1=0.9932432432432432, f1=0.9854748603351955, best_f1=0.9809203142536477
step: 0, loss: 0.06501825153827667
step: 10, loss: 0.0027862198185175657
step: 20, loss: 0.022496717050671577
step: 30, loss: 0.01792421005666256
step: 40, loss: 0.020583778619766235
step: 50, loss: 0.03652616962790489
step: 60, loss: 8.464980783173814e-05
step: 70, loss: 0.00032260018633678555
step: 80, loss: 0.0040423511527478695
step: 90, loss: 0.09819522500038147
step: 100, loss: 0.04027587175369263
step: 110, loss: 0.020830055698752403
step: 120, loss: 0.11077140271663666
step: 130, loss: 0.04775472357869148
step: 140, loss: 0.04296218603849411
step: 150, loss: 0.027631085366010666
step: 160, loss: 0.02157270722091198
step: 170, loss: 5.869860979146324e-05
step: 180, loss: 9.511703683529049e-05
step: 190, loss: 0.06237207353115082
step: 200, loss: 0.02196970209479332
step: 210, loss: 0.027451153844594955
step: 220, loss: 0.0028828966896981
step: 230, loss: 0.06171707808971405
step: 240, loss: 5.7240442401962355e-05
step: 250, loss: 0.027174897491931915
step: 260, loss: 0.000687166815623641
step: 270, loss: 0.022173993289470673
step: 280, loss: 0.02557815983891487
step: 290, loss: 0.04360494017601013
step: 300, loss: 0.0001760160957928747
step: 310, loss: 7.970808655954897e-05
step: 320, loss: 0.07340241968631744
step: 330, loss: 0.021483855322003365
step: 340, loss: 0.0019263947615399957
step: 350, loss: 0.03784307837486267
step: 360, loss: 0.020049219951033592
step: 370, loss: 0.0005016057402826846
step: 380, loss: 0.0001419227191945538
step: 390, loss: 6.936853606021032e-05
step: 400, loss: 0.035346828401088715
step: 410, loss: 0.0001529187138658017
step: 420, loss: 0.11603185534477234
epoch 16: dev_f1=0.9932432432432432, f1=0.984304932735426, best_f1=0.9809203142536477
step: 0, loss: 0.021523332223296165
step: 10, loss: 0.04154244437813759
step: 20, loss: 6.166515231598169e-05
step: 30, loss: 0.020791534334421158
step: 40, loss: 0.021031789481639862
step: 50, loss: 0.019409477710723877
step: 60, loss: 0.03301982581615448
step: 70, loss: 0.016498662531375885
step: 80, loss: 0.06406431645154953
step: 90, loss: 0.0001249649067176506
step: 100, loss: 7.957675552461296e-05
step: 110, loss: 0.06082288920879364
step: 120, loss: 0.0001541922683827579
step: 130, loss: 0.025355203077197075
step: 140, loss: 0.15647315979003906
step: 150, loss: 0.007300529163330793
step: 160, loss: 0.032638419419527054
step: 170, loss: 0.020494956523180008
step: 180, loss: 0.0003578646283131093
step: 190, loss: 0.07154246419668198
step: 200, loss: 0.00087033148156479
step: 210, loss: 0.00014782743528485298
step: 220, loss: 0.0009978926973417401
step: 230, loss: 0.037547603249549866
step: 240, loss: 8.294299914268777e-05
step: 250, loss: 0.02364877425134182
step: 260, loss: 8.78666469361633e-05
step: 270, loss: 0.07769498974084854
step: 280, loss: 0.07249946892261505
step: 290, loss: 0.05022536218166351
step: 300, loss: 0.04737183824181557
step: 310, loss: 0.02620728686451912
step: 320, loss: 0.0617244578897953
step: 330, loss: 0.022273270413279533
step: 340, loss: 0.0422401987016201
step: 350, loss: 0.0001726366754155606
step: 360, loss: 0.04368578642606735
step: 370, loss: 0.05562371760606766
step: 380, loss: 0.00021563685731962323
step: 390, loss: 0.01870207116007805
step: 400, loss: 2.759777635219507e-05
step: 410, loss: 0.023578979074954987
step: 420, loss: 8.601683657616377e-05
epoch 17: dev_f1=0.9932432432432432, f1=0.9820224719101124, best_f1=0.9809203142536477
step: 0, loss: 0.060597680509090424
step: 10, loss: 0.02192733623087406
step: 20, loss: 0.0003146255621686578
step: 30, loss: 0.023623453453183174
step: 40, loss: 0.020172348245978355
step: 50, loss: 0.02459888532757759
step: 60, loss: 0.04034409672021866
step: 70, loss: 0.03112104721367359
step: 80, loss: 0.06698497384786606
step: 90, loss: 0.023145638406276703
step: 100, loss: 0.020885415375232697
step: 110, loss: 0.020174100995063782
step: 120, loss: 0.024419428780674934
step: 130, loss: 0.0003356429806444794
step: 140, loss: 0.08557280153036118
step: 150, loss: 0.020612061023712158
step: 160, loss: 0.016000131145119667
step: 170, loss: 0.020692924037575722
step: 180, loss: 0.03699016198515892
step: 190, loss: 0.03885342553257942
step: 200, loss: 0.001902510062791407
step: 210, loss: 0.02789315953850746
step: 220, loss: 0.02972770296037197
step: 230, loss: 0.021565845236182213
step: 240, loss: 0.020616501569747925
step: 250, loss: 0.02121083065867424
step: 260, loss: 0.00010759165161289275
step: 270, loss: 0.06350962817668915
step: 280, loss: 0.018813544884324074
step: 290, loss: 0.06492190808057785
step: 300, loss: 0.00019282000721432269
step: 310, loss: 0.04287207871675491
step: 320, loss: 9.30128589970991e-05
step: 330, loss: 0.02385946922004223
step: 340, loss: 0.0004276911204215139
step: 350, loss: 0.01792030781507492
step: 360, loss: 2.2248757886700332e-05
step: 370, loss: 7.702315633650869e-05
step: 380, loss: 0.041495710611343384
step: 390, loss: 0.04851611703634262
step: 400, loss: 0.02307673543691635
step: 410, loss: 0.006011974066495895
step: 420, loss: 0.02455996721982956
epoch 18: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9809203142536477
step: 0, loss: 3.91917274100706e-05
step: 10, loss: 0.1094445213675499
step: 20, loss: 0.07134941220283508
step: 30, loss: 0.023438483476638794
step: 40, loss: 0.04566950723528862
step: 50, loss: 0.050832029432058334
step: 60, loss: 0.00017971493070945144
step: 70, loss: 0.020409569144248962
step: 80, loss: 0.00014674756675958633
step: 90, loss: 0.021378297358751297
step: 100, loss: 4.49025901616551e-05
step: 110, loss: 8.127550972858444e-05
step: 120, loss: 0.04316871240735054
step: 130, loss: 0.023253509774804115
step: 140, loss: 0.040874090045690536
step: 150, loss: 2.709859109017998e-05
step: 160, loss: 0.003196622245013714
step: 170, loss: 0.10702995955944061
step: 180, loss: 0.04136722907423973
step: 190, loss: 0.019082218408584595
step: 200, loss: 0.02435624599456787
step: 210, loss: 0.06505648046731949
step: 220, loss: 0.04206160828471184
step: 230, loss: 0.02029622718691826
step: 240, loss: 0.029202796518802643
step: 250, loss: 0.0001148788069258444
step: 260, loss: 0.05507244914770126
step: 270, loss: 0.04380950704216957
step: 280, loss: 0.06257789582014084
step: 290, loss: 0.038817618042230606
step: 300, loss: 0.020820435136556625
step: 310, loss: 0.04839532449841499
step: 320, loss: 0.04362715035676956
step: 330, loss: 0.045381445437669754
step: 340, loss: 0.02319200336933136
step: 350, loss: 0.055028583854436874
step: 360, loss: 0.023387271910905838
step: 370, loss: 0.04433247819542885
step: 380, loss: 0.024421565234661102
step: 390, loss: 0.017147373408079147
step: 400, loss: 8.303343929583207e-05
step: 410, loss: 0.05736791715025902
step: 420, loss: 0.021359428763389587
epoch 19: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9809203142536477
step: 0, loss: 0.04744112491607666
step: 10, loss: 0.0019256464438512921
step: 20, loss: 0.02361428365111351
step: 30, loss: 0.02233550138771534
step: 40, loss: 0.0006208453560248017
step: 50, loss: 0.04043632373213768
step: 60, loss: 0.05326805263757706
step: 70, loss: 0.020490897819399834
step: 80, loss: 0.0001236552925547585
step: 90, loss: 0.022026777267456055
step: 100, loss: 0.01316164806485176
step: 110, loss: 5.309185871738009e-05
step: 120, loss: 0.06779144704341888
step: 130, loss: 0.05127745494246483
step: 140, loss: 0.022049207240343094
step: 150, loss: 0.02161385305225849
step: 160, loss: 0.04958511143922806
step: 170, loss: 0.04579813405871391
step: 180, loss: 0.015200687572360039
step: 190, loss: 0.02228539250791073
step: 200, loss: 0.00012166443048045039
step: 210, loss: 0.0743977501988411
step: 220, loss: 0.02134828455746174
step: 230, loss: 4.886992246611044e-05
step: 240, loss: 0.060994140803813934
step: 250, loss: 0.001019886345602572
step: 260, loss: 0.050761640071868896
step: 270, loss: 0.046009697020053864
step: 280, loss: 0.020901018753647804
step: 290, loss: 1.0762290003185626e-05
step: 300, loss: 0.04346264898777008
step: 310, loss: 0.043037839233875275
step: 320, loss: 0.025740347802639008
step: 330, loss: 0.025313451886177063
step: 340, loss: 0.016034556552767754
step: 350, loss: 0.011266796849668026
step: 360, loss: 0.027796123176813126
step: 370, loss: 9.18730947887525e-05
step: 380, loss: 0.04718576744198799
step: 390, loss: 5.44556460226886e-05
step: 400, loss: 0.10089345276355743
step: 410, loss: 0.04091959819197655
step: 420, loss: 0.021115167066454887
epoch 20: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9809203142536477
