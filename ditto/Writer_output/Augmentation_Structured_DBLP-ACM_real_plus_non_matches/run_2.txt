cuda
Device: cuda
step: 0, loss: 0.6824682950973511
step: 10, loss: 0.35499149560928345
step: 20, loss: 0.30755725502967834
step: 30, loss: 0.3626331686973572
step: 40, loss: 0.5937779545783997
step: 50, loss: 0.24182309210300446
step: 60, loss: 0.2069275975227356
step: 70, loss: 0.2017902284860611
step: 80, loss: 0.10771670192480087
step: 90, loss: 0.20530906319618225
step: 100, loss: 0.44570720195770264
step: 110, loss: 0.14887404441833496
step: 120, loss: 0.17379681766033173
step: 130, loss: 0.11394138634204865
step: 140, loss: 0.030532225966453552
step: 150, loss: 0.1293485313653946
step: 160, loss: 0.13678579032421112
step: 170, loss: 0.1660877764225006
step: 180, loss: 0.0141760827973485
step: 190, loss: 0.05486912652850151
step: 200, loss: 0.06819234788417816
step: 210, loss: 0.09574993699789047
step: 220, loss: 0.08102712035179138
step: 230, loss: 0.047826897352933884
step: 240, loss: 0.033210303634405136
step: 250, loss: 0.006588222924619913
step: 260, loss: 0.0989944264292717
step: 270, loss: 0.025510210543870926
step: 280, loss: 0.09586626291275024
step: 290, loss: 0.11206822097301483
step: 300, loss: 0.030487142503261566
step: 310, loss: 0.07837256789207458
step: 320, loss: 0.08418126404285431
step: 330, loss: 0.11111164093017578
step: 340, loss: 0.04099254310131073
step: 350, loss: 0.02386656403541565
step: 360, loss: 0.0004795583663508296
step: 370, loss: 0.03393682464957237
step: 380, loss: 0.061643555760383606
step: 390, loss: 0.019193215295672417
step: 400, loss: 0.105399489402771
step: 410, loss: 0.15704300999641418
step: 420, loss: 0.06528165191411972
epoch 1: dev_f1=0.9864559819413092, f1=0.9774774774774775, best_f1=0.9774774774774775
step: 0, loss: 0.12838192284107208
step: 10, loss: 0.03218190371990204
step: 20, loss: 0.12283503264188766
step: 30, loss: 0.07458646595478058
step: 40, loss: 0.11707132309675217
step: 50, loss: 0.026664933189749718
step: 60, loss: 0.032835427671670914
step: 70, loss: 0.005312013439834118
step: 80, loss: 0.05574110150337219
step: 90, loss: 0.06041661277413368
step: 100, loss: 0.017537251114845276
step: 110, loss: 0.014185110107064247
step: 120, loss: 0.13666848838329315
step: 130, loss: 0.02469620108604431
step: 140, loss: 0.07171732187271118
step: 150, loss: 0.04221954196691513
step: 160, loss: 0.011881234124302864
step: 170, loss: 0.05868331342935562
step: 180, loss: 0.02346772886812687
step: 190, loss: 0.08356776833534241
step: 200, loss: 0.14293700456619263
step: 210, loss: 0.03076331689953804
step: 220, loss: 0.19896425306797028
step: 230, loss: 0.1719558835029602
step: 240, loss: 0.0682407021522522
step: 250, loss: 0.16537323594093323
step: 260, loss: 0.005671724211424589
step: 270, loss: 0.00045305752428248525
step: 280, loss: 0.08897067606449127
step: 290, loss: 0.033992961049079895
step: 300, loss: 0.01028735376894474
step: 310, loss: 0.19207163155078888
step: 320, loss: 0.011607489548623562
step: 330, loss: 0.008933058008551598
step: 340, loss: 0.04695895314216614
step: 350, loss: 0.0765073299407959
step: 360, loss: 0.00989189650863409
step: 370, loss: 0.024842415004968643
step: 380, loss: 0.07974778115749359
step: 390, loss: 0.021288760006427765
step: 400, loss: 0.08402030169963837
step: 410, loss: 0.036845527589321136
step: 420, loss: 0.0943310409784317
epoch 2: dev_f1=0.990990990990991, f1=0.9785794813979707, best_f1=0.9785794813979707
step: 0, loss: 0.053762298077344894
step: 10, loss: 0.02108120359480381
step: 20, loss: 0.061987072229385376
step: 30, loss: 0.08843285590410233
step: 40, loss: 0.04218779131770134
step: 50, loss: 0.1472838968038559
step: 60, loss: 0.016880953684449196
step: 70, loss: 0.13135097920894623
step: 80, loss: 0.006575863808393478
step: 90, loss: 0.012033260427415371
step: 100, loss: 0.04463382810354233
step: 110, loss: 0.08559298515319824
step: 120, loss: 0.07850630581378937
step: 130, loss: 0.13534027338027954
step: 140, loss: 0.1402307003736496
step: 150, loss: 0.20030640065670013
step: 160, loss: 0.28647851943969727
step: 170, loss: 0.06775574386119843
step: 180, loss: 0.10628868639469147
step: 190, loss: 0.010214739479124546
step: 200, loss: 0.11373456567525864
step: 210, loss: 0.08090367168188095
step: 220, loss: 0.09746376425027847
step: 230, loss: 0.24028220772743225
step: 240, loss: 0.08843162655830383
step: 250, loss: 0.03711342066526413
step: 260, loss: 0.03745955228805542
step: 270, loss: 0.10232352465391159
step: 280, loss: 0.0939863845705986
step: 290, loss: 0.01281808316707611
step: 300, loss: 0.07620906084775925
step: 310, loss: 0.08855996280908585
step: 320, loss: 0.020929822698235512
step: 330, loss: 0.07371212542057037
step: 340, loss: 0.013646851293742657
step: 350, loss: 0.029055064544081688
step: 360, loss: 0.09207871556282043
step: 370, loss: 0.04546286538243294
step: 380, loss: 0.04924878850579262
step: 390, loss: 0.09916143864393234
step: 400, loss: 0.08683224767446518
step: 410, loss: 0.12519462406635284
step: 420, loss: 0.17758378386497498
epoch 3: dev_f1=0.9808773903262092, f1=0.9707865168539327, best_f1=0.9785794813979707
step: 0, loss: 0.22772245109081268
step: 10, loss: 0.19607125222682953
step: 20, loss: 0.1882971227169037
step: 30, loss: 0.1593136191368103
step: 40, loss: 0.07351965457201004
step: 50, loss: 0.05023908242583275
step: 60, loss: 0.16261480748653412
step: 70, loss: 0.028087586164474487
step: 80, loss: 0.038852863013744354
step: 90, loss: 0.09130369126796722
step: 100, loss: 0.00991279911249876
step: 110, loss: 0.020389266312122345
step: 120, loss: 0.0336877703666687
step: 130, loss: 0.10068883001804352
step: 140, loss: 0.2612641453742981
step: 150, loss: 0.07427046447992325
step: 160, loss: 0.0636272132396698
step: 170, loss: 0.01506376825273037
step: 180, loss: 0.010988010093569756
step: 190, loss: 0.011820144020020962
step: 200, loss: 0.016513846814632416
step: 210, loss: 0.014267714694142342
step: 220, loss: 0.06668894737958908
step: 230, loss: 0.07772590965032578
step: 240, loss: 0.006893109064549208
step: 250, loss: 0.061502594500780106
step: 260, loss: 0.0070214224979281425
step: 270, loss: 0.025496870279312134
step: 280, loss: 0.09556412696838379
step: 290, loss: 0.007832317613065243
step: 300, loss: 0.019368665292859077
step: 310, loss: 0.04992075264453888
step: 320, loss: 0.0069596609100699425
step: 330, loss: 0.08838848769664764
step: 340, loss: 0.11579049378633499
step: 350, loss: 0.016073960810899734
step: 360, loss: 0.08042296767234802
step: 370, loss: 0.07520066201686859
step: 380, loss: 0.07001835852861404
step: 390, loss: 0.06984306871891022
step: 400, loss: 0.12329265475273132
step: 410, loss: 0.08335788547992706
step: 420, loss: 0.07481609284877777
epoch 4: dev_f1=0.9921259842519685, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.08394168317317963
step: 10, loss: 0.04617965593934059
step: 20, loss: 0.08586925268173218
step: 30, loss: 0.007887858897447586
step: 40, loss: 0.01422875840216875
step: 50, loss: 0.029259687289595604
step: 60, loss: 0.01001039706170559
step: 70, loss: 0.02092951349914074
step: 80, loss: 0.07086563855409622
step: 90, loss: 0.11132391542196274
step: 100, loss: 0.05689019709825516
step: 110, loss: 0.07432762533426285
step: 120, loss: 0.16180746257305145
step: 130, loss: 0.1777728646993637
step: 140, loss: 0.13306216895580292
step: 150, loss: 0.06607877463102341
step: 160, loss: 0.08786148577928543
step: 170, loss: 0.008717777207493782
step: 180, loss: 0.023673273622989655
step: 190, loss: 0.07464837282896042
step: 200, loss: 0.0127702746540308
step: 210, loss: 0.04203119874000549
step: 220, loss: 0.08737815171480179
step: 230, loss: 0.05676561966538429
step: 240, loss: 0.03312669321894646
step: 250, loss: 0.08001270890235901
step: 260, loss: 0.07087154686450958
step: 270, loss: 0.057821691036224365
step: 280, loss: 0.033316176384687424
step: 290, loss: 0.034590624272823334
step: 300, loss: 0.058376163244247437
step: 310, loss: 0.017182601615786552
step: 320, loss: 0.0442364402115345
step: 330, loss: 0.013898301869630814
step: 340, loss: 0.05362381786108017
step: 350, loss: 0.04841332882642746
step: 360, loss: 0.016024846583604813
step: 370, loss: 0.06218038871884346
step: 380, loss: 0.017559055238962173
step: 390, loss: 0.022435717284679413
step: 400, loss: 0.13450665771961212
step: 410, loss: 0.08443185687065125
step: 420, loss: 0.08938916027545929
epoch 5: dev_f1=0.9910514541387023, f1=0.9833147942157954, best_f1=0.9854096520763187
step: 0, loss: 0.015612037852406502
step: 10, loss: 0.06954815983772278
step: 20, loss: 0.10021274536848068
step: 30, loss: 0.03642905876040459
step: 40, loss: 0.11515349894762039
step: 50, loss: 0.012513728812336922
step: 60, loss: 0.05091221258044243
step: 70, loss: 0.06546469032764435
step: 80, loss: 0.071874238550663
step: 90, loss: 0.10130203515291214
step: 100, loss: 0.025287311524152756
step: 110, loss: 0.029277335852384567
step: 120, loss: 0.03577449917793274
step: 130, loss: 0.016227081418037415
step: 140, loss: 0.06817327439785004
step: 150, loss: 0.07708851993083954
step: 160, loss: 0.16386358439922333
step: 170, loss: 0.09661917388439178
step: 180, loss: 0.06039416790008545
step: 190, loss: 0.08681762963533401
step: 200, loss: 0.10703208297491074
step: 210, loss: 0.09269491583108902
step: 220, loss: 0.01041125413030386
step: 230, loss: 0.01231609657406807
step: 240, loss: 0.09330812096595764
step: 250, loss: 0.015538962557911873
step: 260, loss: 0.018544869497418404
step: 270, loss: 0.054350946098566055
step: 280, loss: 0.010074805468320847
step: 290, loss: 0.02491014450788498
step: 300, loss: 0.07969974726438522
step: 310, loss: 0.025776419788599014
step: 320, loss: 0.030871983617544174
step: 330, loss: 0.06791403144598007
step: 340, loss: 0.01474781148135662
step: 350, loss: 0.05258558690547943
step: 360, loss: 0.010388977825641632
step: 370, loss: 0.019583705812692642
step: 380, loss: 0.13798010349273682
step: 390, loss: 0.017127148807048798
step: 400, loss: 0.1102939173579216
step: 410, loss: 0.06647096574306488
step: 420, loss: 0.00048530599451623857
epoch 6: dev_f1=0.9932432432432432, f1=0.9809203142536477, best_f1=0.9809203142536477
step: 0, loss: 0.12777559459209442
step: 10, loss: 0.033595893532037735
step: 20, loss: 0.05625281110405922
step: 30, loss: 0.00012161490303697065
step: 40, loss: 0.11336944997310638
step: 50, loss: 0.07239647954702377
step: 60, loss: 0.04257069155573845
step: 70, loss: 0.023764505982398987
step: 80, loss: 0.12188791483640671
step: 90, loss: 0.013223170302808285
step: 100, loss: 0.01346566528081894
step: 110, loss: 0.05385948717594147
step: 120, loss: 0.018018728122115135
step: 130, loss: 0.0639461800456047
step: 140, loss: 0.1444496065378189
step: 150, loss: 0.07459229230880737
step: 160, loss: 0.07154963165521622
step: 170, loss: 0.08932201564311981
step: 180, loss: 0.07185007631778717
step: 190, loss: 0.06963453441858292
step: 200, loss: 0.029544591903686523
step: 210, loss: 0.013501212000846863
step: 220, loss: 0.042908456176519394
step: 230, loss: 0.08556920289993286
step: 240, loss: 0.050976432859897614
step: 250, loss: 0.07216880470514297
step: 260, loss: 0.03683559224009514
step: 270, loss: 0.07369301468133926
step: 280, loss: 0.1912951022386551
step: 290, loss: 0.13166303932666779
step: 300, loss: 0.06153403967618942
step: 310, loss: 0.08948181569576263
step: 320, loss: 0.08177674561738968
step: 330, loss: 0.25225868821144104
step: 340, loss: 0.12040019780397415
step: 350, loss: 0.05681131035089493
step: 360, loss: 0.06709225475788116
step: 370, loss: 0.05942373722791672
step: 380, loss: 0.05901500582695007
step: 390, loss: 0.01513504795730114
step: 400, loss: 0.07716526836156845
step: 410, loss: 0.07657253742218018
step: 420, loss: 0.015562273561954498
epoch 7: dev_f1=0.9932735426008968, f1=0.9844097995545658, best_f1=0.9844097995545658
step: 0, loss: 0.02534966543316841
step: 10, loss: 0.022201750427484512
step: 20, loss: 0.027358021587133408
step: 30, loss: 0.11033452302217484
step: 40, loss: 0.06948788464069366
step: 50, loss: 0.005380658432841301
step: 60, loss: 0.02380017563700676
step: 70, loss: 0.10051584243774414
step: 80, loss: 0.09150516986846924
step: 90, loss: 0.022724837064743042
step: 100, loss: 0.02317645028233528
step: 110, loss: 0.08204755187034607
step: 120, loss: 0.1889297515153885
step: 130, loss: 0.00663971109315753
step: 140, loss: 0.07586164027452469
step: 150, loss: 0.052289728075265884
step: 160, loss: 0.01182276476174593
step: 170, loss: 0.09085740894079208
step: 180, loss: 0.17976027727127075
step: 190, loss: 0.07426685839891434
step: 200, loss: 0.02374117076396942
step: 210, loss: 0.031885746866464615
step: 220, loss: 0.24118073284626007
step: 230, loss: 0.02839445322751999
step: 240, loss: 0.035236358642578125
step: 250, loss: 0.008615553379058838
step: 260, loss: 0.04731570929288864
step: 270, loss: 0.1826653629541397
step: 280, loss: 0.035607561469078064
step: 290, loss: 0.03869181126356125
step: 300, loss: 0.017486572265625
step: 310, loss: 0.041126858443021774
step: 320, loss: 0.047711826860904694
step: 330, loss: 0.03418855369091034
step: 340, loss: 0.012096371501684189
step: 350, loss: 0.013852022588253021
step: 360, loss: 0.014776946976780891
step: 370, loss: 0.0426955409348011
step: 380, loss: 0.018516022711992264
step: 390, loss: 0.119151271879673
step: 400, loss: 0.06434605270624161
step: 410, loss: 0.06829062849283218
step: 420, loss: 0.055341463536024094
epoch 8: dev_f1=0.9899441340782122, f1=0.9833518312985573, best_f1=0.9844097995545658
step: 0, loss: 0.011012816801667213
step: 10, loss: 0.04170093312859535
step: 20, loss: 0.14301951229572296
step: 30, loss: 0.025410721078515053
step: 40, loss: 0.07419129461050034
step: 50, loss: 0.008329062722623348
step: 60, loss: 0.04813898727297783
step: 70, loss: 0.028664764016866684
step: 80, loss: 3.891340020345524e-05
step: 90, loss: 0.03827099874615669
step: 100, loss: 0.006542266812175512
step: 110, loss: 0.0820755809545517
step: 120, loss: 0.05844256281852722
step: 130, loss: 0.12633293867111206
step: 140, loss: 0.06740661710500717
step: 150, loss: 0.012261811643838882
step: 160, loss: 0.021856660023331642
step: 170, loss: 0.10850036144256592
step: 180, loss: 0.01033012941479683
step: 190, loss: 0.012106603011488914
step: 200, loss: 0.07241517305374146
step: 210, loss: 0.02746686339378357
step: 220, loss: 0.011146239005029202
step: 230, loss: 0.0176951102912426
step: 240, loss: 0.016830237582325935
step: 250, loss: 0.049413248896598816
step: 260, loss: 0.10817141830921173
step: 270, loss: 0.17458514869213104
step: 280, loss: 0.06530047208070755
step: 290, loss: 0.05606325715780258
step: 300, loss: 0.0665288120508194
step: 310, loss: 0.032818377017974854
step: 320, loss: 0.03863249346613884
step: 330, loss: 0.01231209747493267
step: 340, loss: 0.01729729399085045
step: 350, loss: 0.017249327152967453
step: 360, loss: 0.009099895134568214
step: 370, loss: 0.1296084076166153
step: 380, loss: 0.03751051798462868
step: 390, loss: 0.002905670553445816
step: 400, loss: 0.08165064454078674
step: 410, loss: 0.09124447405338287
step: 420, loss: 0.10165348649024963
epoch 9: dev_f1=0.9910112359550561, f1=0.9787709497206705, best_f1=0.9844097995545658
step: 0, loss: 0.006545380689203739
step: 10, loss: 0.05095670372247696
step: 20, loss: 0.07097917795181274
step: 30, loss: 0.02072164975106716
step: 40, loss: 0.018728964030742645
step: 50, loss: 0.025592150166630745
step: 60, loss: 0.051895804703235626
step: 70, loss: 0.07594962418079376
step: 80, loss: 0.05915489420294762
step: 90, loss: 0.03998691216111183
step: 100, loss: 0.08405805379152298
step: 110, loss: 0.042877987027168274
step: 120, loss: 0.1808561384677887
step: 130, loss: 0.009459775872528553
step: 140, loss: 0.189053013920784
step: 150, loss: 0.014338020235300064
step: 160, loss: 0.06893143057823181
step: 170, loss: 0.007512735202908516
step: 180, loss: 0.02955850213766098
step: 190, loss: 0.06940297782421112
step: 200, loss: 0.009635938331484795
step: 210, loss: 0.11363402754068375
step: 220, loss: 0.022421319037675858
step: 230, loss: 0.025748027488589287
step: 240, loss: 0.0585397370159626
step: 250, loss: 0.03803763911128044
step: 260, loss: 0.06938271224498749
step: 270, loss: 0.04172542318701744
step: 280, loss: 0.02636999450623989
step: 290, loss: 0.05046713724732399
step: 300, loss: 0.11783706396818161
step: 310, loss: 0.13172157108783722
step: 320, loss: 0.0572269968688488
step: 330, loss: 0.014118015766143799
step: 340, loss: 0.07445530593395233
step: 350, loss: 0.018386870622634888
step: 360, loss: 0.015464444644749165
step: 370, loss: 0.05138898268342018
step: 380, loss: 0.15345971286296844
step: 390, loss: 0.011436501517891884
step: 400, loss: 0.0713685154914856
step: 410, loss: 0.1331746131181717
step: 420, loss: 0.0021916814148426056
epoch 10: dev_f1=0.9921259842519685, f1=0.9821029082774049, best_f1=0.9844097995545658
step: 0, loss: 0.006605323404073715
step: 10, loss: 0.020594030618667603
step: 20, loss: 0.059341371059417725
step: 30, loss: 0.047181375324726105
step: 40, loss: 0.009617242962121964
step: 50, loss: 0.0016155297635123134
step: 60, loss: 0.06223520636558533
step: 70, loss: 0.12084130942821503
step: 80, loss: 0.053746726363897324
step: 90, loss: 0.023525068536400795
step: 100, loss: 0.01873386651277542
step: 110, loss: 0.046170249581336975
step: 120, loss: 0.017765812575817108
step: 130, loss: 0.1041903868317604
step: 140, loss: 0.015246637165546417
step: 150, loss: 0.013146968558430672
step: 160, loss: 0.0009901660960167646
step: 170, loss: 0.0036472133360803127
step: 180, loss: 0.08520863205194473
step: 190, loss: 0.12073824554681778
step: 200, loss: 0.01917404681444168
step: 210, loss: 2.837457213900052e-05
step: 220, loss: 0.16040034592151642
step: 230, loss: 0.1793491691350937
step: 240, loss: 0.13144829869270325
step: 250, loss: 0.04038364067673683
step: 260, loss: 0.020784957334399223
step: 270, loss: 0.059121452271938324
step: 280, loss: 0.02104206569492817
step: 290, loss: 0.012821887619793415
step: 300, loss: 0.11104554682970047
step: 310, loss: 0.06773009896278381
step: 320, loss: 0.058099862188100815
step: 330, loss: 0.005930209532380104
step: 340, loss: 0.036108050495386124
step: 350, loss: 0.009382815100252628
step: 360, loss: 0.07745050638914108
step: 370, loss: 0.05719925835728645
step: 380, loss: 5.403370232670568e-05
step: 390, loss: 0.09671560674905777
step: 400, loss: 0.015893079340457916
step: 410, loss: 0.03312326595187187
step: 420, loss: 0.07747525721788406
epoch 11: dev_f1=0.9921436588103255, f1=0.9843400447427293, best_f1=0.9844097995545658
step: 0, loss: 0.03984057903289795
step: 10, loss: 0.06551086157560349
step: 20, loss: 0.017351675778627396
step: 30, loss: 0.01572965271770954
step: 40, loss: 0.08730502426624298
step: 50, loss: 0.014561337418854237
step: 60, loss: 0.048603370785713196
step: 70, loss: 0.006443270947784185
step: 80, loss: 0.042528826743364334
step: 90, loss: 0.06232910975813866
step: 100, loss: 0.057532358914613724
step: 110, loss: 0.012409625574946404
step: 120, loss: 0.015889491885900497
step: 130, loss: 0.03794066980481148
step: 140, loss: 0.008403253741562366
step: 150, loss: 0.00306727085262537
step: 160, loss: 0.04725353792309761
step: 170, loss: 0.025668904185295105
step: 180, loss: 0.009529231116175652
step: 190, loss: 0.024682462215423584
step: 200, loss: 0.0114348279312253
step: 210, loss: 0.011664439924061298
step: 220, loss: 0.049849577248096466
step: 230, loss: 0.07495395839214325
step: 240, loss: 0.04519132897257805
step: 250, loss: 0.14326494932174683
step: 260, loss: 0.048199594020843506
step: 270, loss: 0.04631172865629196
step: 280, loss: 0.06451094150543213
step: 290, loss: 0.035778872668743134
step: 300, loss: 0.002603330882266164
step: 310, loss: 0.04295999929308891
step: 320, loss: 0.017783641815185547
step: 330, loss: 0.018824968487024307
step: 340, loss: 0.04563816636800766
step: 350, loss: 0.012298359535634518
step: 360, loss: 0.08260183781385422
step: 370, loss: 0.09493116289377213
step: 380, loss: 0.042123306542634964
step: 390, loss: 0.04006924480199814
step: 400, loss: 0.0638892874121666
step: 410, loss: 0.06654533743858337
step: 420, loss: 0.022484220564365387
epoch 12: dev_f1=0.992108229988726, f1=0.9831271091113611, best_f1=0.9844097995545658
step: 0, loss: 0.06087832525372505
step: 10, loss: 0.028733467683196068
step: 20, loss: 0.009782903827726841
step: 30, loss: 0.013253148645162582
step: 40, loss: 0.003969887737184763
step: 50, loss: 0.13512426614761353
step: 60, loss: 0.02514813281595707
step: 70, loss: 0.016610916703939438
step: 80, loss: 0.10171942412853241
step: 90, loss: 0.03922109678387642
step: 100, loss: 0.04311062768101692
step: 110, loss: 0.004486244637519121
step: 120, loss: 0.04953928291797638
step: 130, loss: 0.01771415024995804
step: 140, loss: 0.04919042810797691
step: 150, loss: 0.14138147234916687
step: 160, loss: 0.06868108361959457
step: 170, loss: 0.06118984892964363
step: 180, loss: 0.046788059175014496
step: 190, loss: 0.0010751173831522465
step: 200, loss: 0.07802877575159073
step: 210, loss: 0.009034451097249985
step: 220, loss: 0.018279703333973885
step: 230, loss: 0.10120049864053726
step: 240, loss: 0.056415703147649765
step: 250, loss: 0.012817378155887127
step: 260, loss: 0.12252809852361679
step: 270, loss: 0.044982194900512695
step: 280, loss: 0.14637313783168793
step: 290, loss: 0.012196449562907219
step: 300, loss: 0.012597678229212761
step: 310, loss: 0.15508762001991272
step: 320, loss: 0.00038296353886835277
step: 330, loss: 0.04123951122164726
step: 340, loss: 0.028325660154223442
step: 350, loss: 0.011780260130763054
step: 360, loss: 0.016655275598168373
step: 370, loss: 0.009576966054737568
step: 380, loss: 0.0005170490476302803
step: 390, loss: 0.012323358096182346
step: 400, loss: 0.016764089465141296
step: 410, loss: 0.015746217221021652
step: 420, loss: 0.09100059419870377
epoch 13: dev_f1=0.9910112359550561, f1=0.9843400447427293, best_f1=0.9844097995545658
step: 0, loss: 0.030155330896377563
step: 10, loss: 0.002740271855145693
step: 20, loss: 0.03234713897109032
step: 30, loss: 0.04635431990027428
step: 40, loss: 0.082033172249794
step: 50, loss: 0.048382896929979324
step: 60, loss: 0.02516666054725647
step: 70, loss: 0.07940109819173813
step: 80, loss: 0.0283330250531435
step: 90, loss: 0.002224193885922432
step: 100, loss: 0.06976158171892166
step: 110, loss: 0.08644688129425049
step: 120, loss: 0.02451392449438572
step: 130, loss: 0.007470988668501377
step: 140, loss: 0.06265253573656082
step: 150, loss: 0.033823080360889435
step: 160, loss: 0.137274831533432
step: 170, loss: 0.0003356837551109493
step: 180, loss: 0.0020182800944894552
step: 190, loss: 0.017807094380259514
step: 200, loss: 0.12835413217544556
step: 210, loss: 0.1275882124900818
step: 220, loss: 0.041568685322999954
step: 230, loss: 0.038786984980106354
step: 240, loss: 0.02992432750761509
step: 250, loss: 0.01981242187321186
step: 260, loss: 0.02456475794315338
step: 270, loss: 0.04470321908593178
step: 280, loss: 0.05885691195726395
step: 290, loss: 0.006969602312892675
step: 300, loss: 0.018842477351427078
step: 310, loss: 0.005043293349444866
step: 320, loss: 0.0009142669150605798
step: 330, loss: 0.0009386112214997411
step: 340, loss: 0.1571047008037567
step: 350, loss: 0.0003435956605244428
step: 360, loss: 0.041248925030231476
step: 370, loss: 0.11002849042415619
step: 380, loss: 0.09546078741550446
step: 390, loss: 0.039437197148799896
step: 400, loss: 0.011464598588645458
step: 410, loss: 0.005338430870324373
step: 420, loss: 0.00025162167730741203
epoch 14: dev_f1=0.9899216125419933, f1=0.9843749999999999, best_f1=0.9844097995545658
step: 0, loss: 0.03034903109073639
step: 10, loss: 0.0006648810231126845
step: 20, loss: 0.020008448511362076
step: 30, loss: 0.02280551940202713
step: 40, loss: 0.03772646561264992
step: 50, loss: 0.133980855345726
step: 60, loss: 0.023892082273960114
step: 70, loss: 0.001802331767976284
step: 80, loss: 0.047105226665735245
step: 90, loss: 0.022163506597280502
step: 100, loss: 0.0015158896567299962
step: 110, loss: 0.021285779774188995
step: 120, loss: 0.014721481129527092
step: 130, loss: 0.0050010294653475285
step: 140, loss: 0.05763927847146988
step: 150, loss: 0.021973296999931335
step: 160, loss: 0.04419231042265892
step: 170, loss: 0.03499249368906021
step: 180, loss: 0.01702827215194702
step: 190, loss: 0.00021838945394847542
step: 200, loss: 0.05547281727194786
step: 210, loss: 0.02174030989408493
step: 220, loss: 0.00026286483625881374
step: 230, loss: 0.005856791045516729
step: 240, loss: 0.0001257122348761186
step: 250, loss: 0.0005835708579979837
step: 260, loss: 0.007378635462373495
step: 270, loss: 0.035093460232019424
step: 280, loss: 0.03510480746626854
step: 290, loss: 0.024551864713430405
step: 300, loss: 0.03442370519042015
step: 310, loss: 0.02654501050710678
step: 320, loss: 0.015326844528317451
step: 330, loss: 0.0009580773185007274
step: 340, loss: 0.03273564204573631
step: 350, loss: 0.0006138720200397074
step: 360, loss: 0.0607624277472496
step: 370, loss: 0.00017051780014298856
step: 380, loss: 0.017367223277688026
step: 390, loss: 0.012497182004153728
step: 400, loss: 0.027835648506879807
step: 410, loss: 0.023173268884420395
step: 420, loss: 0.00656331330537796
epoch 15: dev_f1=0.9921259842519685, f1=0.980963045912654, best_f1=0.9844097995545658
step: 0, loss: 0.09325599670410156
step: 10, loss: 0.02122621424496174
step: 20, loss: 0.00014062458649277687
step: 30, loss: 0.02286277525126934
step: 40, loss: 0.10729875415563583
step: 50, loss: 0.0581437423825264
step: 60, loss: 0.02305051125586033
step: 70, loss: 0.018210310488939285
step: 80, loss: 0.021914903074502945
step: 90, loss: 0.0001922280789585784
step: 100, loss: 0.0010859775356948376
step: 110, loss: 0.01603775843977928
step: 120, loss: 0.04625384882092476
step: 130, loss: 0.06374391168355942
step: 140, loss: 0.00020266632782295346
step: 150, loss: 0.0004958861973136663
step: 160, loss: 0.03946571797132492
step: 170, loss: 0.02697683498263359
step: 180, loss: 0.03590921312570572
step: 190, loss: 0.04771418124437332
step: 200, loss: 0.05626748874783516
step: 210, loss: 0.00020555351511575282
step: 220, loss: 0.0590762235224247
step: 230, loss: 0.009295811876654625
step: 240, loss: 0.05272822827100754
step: 250, loss: 0.048117659986019135
step: 260, loss: 0.020724749192595482
step: 270, loss: 0.002285601571202278
step: 280, loss: 0.04251262918114662
step: 290, loss: 0.030883539468050003
step: 300, loss: 0.024939483031630516
step: 310, loss: 0.0683397427201271
step: 320, loss: 0.017747625708580017
step: 330, loss: 0.06083563342690468
step: 340, loss: 0.08913362771272659
step: 350, loss: 0.017889387905597687
step: 360, loss: 0.00013960371143184602
step: 370, loss: 0.0689002126455307
step: 380, loss: 0.020764602348208427
step: 390, loss: 0.03655223175883293
step: 400, loss: 0.06662242114543915
step: 410, loss: 0.011986485682427883
step: 420, loss: 0.08035609871149063
epoch 16: dev_f1=0.9920903954802259, f1=0.9798206278026906, best_f1=0.9844097995545658
step: 0, loss: 0.011315987445414066
step: 10, loss: 0.0005188555805943906
step: 20, loss: 0.017959007993340492
step: 30, loss: 0.021067198365926743
step: 40, loss: 0.04441218823194504
step: 50, loss: 0.0005840473459102213
step: 60, loss: 0.07286986708641052
step: 70, loss: 0.003807122353464365
step: 80, loss: 0.014542716555297375
step: 90, loss: 0.043974921107292175
step: 100, loss: 0.035556841641664505
step: 110, loss: 0.025790870189666748
step: 120, loss: 0.0005055122310295701
step: 130, loss: 0.057788919657468796
step: 140, loss: 0.03664785623550415
step: 150, loss: 0.02275995723903179
step: 160, loss: 0.09553033113479614
step: 170, loss: 0.0003453261742834002
step: 180, loss: 0.04066123813390732
step: 190, loss: 0.021712351590394974
step: 200, loss: 0.03167083486914635
step: 210, loss: 0.04483556002378464
step: 220, loss: 0.004205747973173857
step: 230, loss: 0.1225842759013176
step: 240, loss: 0.024154063314199448
step: 250, loss: 0.02435465157032013
step: 260, loss: 0.002358179073780775
step: 270, loss: 4.758505383506417e-05
step: 280, loss: 0.00018430592899676412
step: 290, loss: 0.06190953031182289
step: 300, loss: 0.0562000647187233
step: 310, loss: 0.05328485369682312
step: 320, loss: 0.0010517408372834325
step: 330, loss: 0.001108516938984394
step: 340, loss: 0.018821483477950096
step: 350, loss: 0.027029575780034065
step: 360, loss: 0.05170157551765442
step: 370, loss: 0.008079311810433865
step: 380, loss: 3.3793592592701316e-05
step: 390, loss: 2.6387810066808015e-05
step: 400, loss: 0.015497207641601562
step: 410, loss: 0.02690247818827629
step: 420, loss: 0.004181518219411373
epoch 17: dev_f1=0.992108229988726, f1=0.9820627802690582, best_f1=0.9844097995545658
step: 0, loss: 0.06467752158641815
step: 10, loss: 0.021411802619695663
step: 20, loss: 0.020133396610617638
step: 30, loss: 0.0005296724266372621
step: 40, loss: 0.04193062335252762
step: 50, loss: 0.00016434997087344527
step: 60, loss: 0.0024876336101442575
step: 70, loss: 0.026575909927487373
step: 80, loss: 0.031909797340631485
step: 90, loss: 0.0028717273380607367
step: 100, loss: 0.0008958584512583911
step: 110, loss: 9.20264283195138e-05
step: 120, loss: 0.09981223940849304
step: 130, loss: 0.0022196928039193153
step: 140, loss: 0.020487546920776367
step: 150, loss: 6.9910500315018e-05
step: 160, loss: 0.10133334249258041
step: 170, loss: 0.0799950510263443
step: 180, loss: 0.03104192577302456
step: 190, loss: 0.1080479696393013
step: 200, loss: 0.056940581649541855
step: 210, loss: 0.003280819859355688
step: 220, loss: 0.03999513387680054
step: 230, loss: 0.04139672964811325
step: 240, loss: 0.0457807295024395
step: 250, loss: 0.05629045143723488
step: 260, loss: 0.07613126188516617
step: 270, loss: 0.0002759305643849075
step: 280, loss: 0.000311222713207826
step: 290, loss: 0.02824663743376732
step: 300, loss: 0.04498264566063881
step: 310, loss: 0.0030903222505003214
step: 320, loss: 0.030504800379276276
step: 330, loss: 8.220034942496568e-05
step: 340, loss: 0.020942384377121925
step: 350, loss: 0.02385646104812622
step: 360, loss: 0.07326651364564896
step: 370, loss: 0.0406704843044281
step: 380, loss: 0.0004945127293467522
step: 390, loss: 0.019702566787600517
step: 400, loss: 0.053652677685022354
step: 410, loss: 0.02548229694366455
step: 420, loss: 1.68974329426419e-05
epoch 18: dev_f1=0.9921259842519685, f1=0.9820627802690582, best_f1=0.9844097995545658
step: 0, loss: 0.0380566380918026
step: 10, loss: 0.05636594444513321
step: 20, loss: 0.017357129603624344
step: 30, loss: 0.00010982437379425392
step: 40, loss: 0.048737529665231705
step: 50, loss: 0.00011510353215271607
step: 60, loss: 0.015018464997410774
step: 70, loss: 0.027115648612380028
step: 80, loss: 0.0304100401699543
step: 90, loss: 0.00010780571756185964
step: 100, loss: 0.00022817481658421457
step: 110, loss: 5.194782715989277e-05
step: 120, loss: 0.023968521505594254
step: 130, loss: 0.02095361426472664
step: 140, loss: 0.05993546172976494
step: 150, loss: 0.0002459535899106413
step: 160, loss: 0.04124985635280609
step: 170, loss: 0.00012161357153672725
step: 180, loss: 0.0007934055174700916
step: 190, loss: 0.0004189001047052443
step: 200, loss: 0.029804008081555367
step: 210, loss: 0.02324843220412731
step: 220, loss: 0.08309811353683472
step: 230, loss: 6.339567335089669e-05
step: 240, loss: 0.020898276939988136
step: 250, loss: 0.05265558511018753
step: 260, loss: 0.06312493234872818
step: 270, loss: 0.00028083083452656865
step: 280, loss: 0.014822814613580704
step: 290, loss: 0.043540921062231064
step: 300, loss: 0.10902999341487885
step: 310, loss: 0.020271219313144684
step: 320, loss: 0.08039595931768417
step: 330, loss: 0.0019749656785279512
step: 340, loss: 0.04041779786348343
step: 350, loss: 0.0008433006587438285
step: 360, loss: 7.096662011463195e-05
step: 370, loss: 0.09691426903009415
step: 380, loss: 0.04121866822242737
step: 390, loss: 0.04455968365073204
step: 400, loss: 0.05262079834938049
step: 410, loss: 0.04938008636236191
step: 420, loss: 0.03449561074376106
epoch 19: dev_f1=0.9921259842519685, f1=0.9820627802690582, best_f1=0.9844097995545658
step: 0, loss: 0.03984706103801727
step: 10, loss: 0.06970977783203125
step: 20, loss: 0.05238441377878189
step: 30, loss: 0.0002751399006228894
step: 40, loss: 0.07343493402004242
step: 50, loss: 0.02376840077340603
step: 60, loss: 0.05287153646349907
step: 70, loss: 0.04185657575726509
step: 80, loss: 0.022520698606967926
step: 90, loss: 0.043392613530159
step: 100, loss: 0.019187763333320618
step: 110, loss: 0.02470068819820881
step: 120, loss: 0.037326715886592865
step: 130, loss: 0.00012912497913930565
step: 140, loss: 0.02090803161263466
step: 150, loss: 0.00011107794125564396
step: 160, loss: 0.024639545008540154
step: 170, loss: 0.025364160537719727
step: 180, loss: 0.020840365439653397
step: 190, loss: 0.019204214215278625
step: 200, loss: 9.044560283655301e-05
step: 210, loss: 0.05647294968366623
step: 220, loss: 0.02257721871137619
step: 230, loss: 0.01931138150393963
step: 240, loss: 0.03325004503130913
step: 250, loss: 0.02003660798072815
step: 260, loss: 1.3898947145207785e-05
step: 270, loss: 0.01725468412041664
step: 280, loss: 0.03665706887841225
step: 290, loss: 0.013696130365133286
step: 300, loss: 5.6235894589917734e-05
step: 310, loss: 7.875517621869221e-05
step: 320, loss: 0.012490203604102135
step: 330, loss: 0.05610797554254532
step: 340, loss: 0.026078347116708755
step: 350, loss: 0.04504525288939476
step: 360, loss: 0.022189853712916374
step: 370, loss: 0.042132627218961716
step: 380, loss: 0.00015393841022159904
step: 390, loss: 0.02468855492770672
step: 400, loss: 0.05186041072010994
step: 410, loss: 0.026194659993052483
step: 420, loss: 0.020068064332008362
epoch 20: dev_f1=0.990990990990991, f1=0.9820627802690582, best_f1=0.9844097995545658
