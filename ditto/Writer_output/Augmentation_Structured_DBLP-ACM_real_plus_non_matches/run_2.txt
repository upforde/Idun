cuda
Device: cuda
step: 0, loss: 0.6641520857810974
step: 10, loss: 0.1271989494562149
step: 20, loss: 0.23709329962730408
step: 30, loss: 0.2145695835351944
step: 40, loss: 0.3062988817691803
step: 50, loss: 0.1480768918991089
step: 60, loss: 0.1408829391002655
step: 70, loss: 0.03933661803603172
step: 80, loss: 0.09909816831350327
step: 90, loss: 0.04721401259303093
step: 100, loss: 0.10945858806371689
step: 110, loss: 0.1217312291264534
step: 120, loss: 0.012998854741454124
step: 130, loss: 0.10862120240926743
step: 140, loss: 0.16531157493591309
step: 150, loss: 0.14953359961509705
step: 160, loss: 0.06526247411966324
step: 170, loss: 0.06210848689079285
step: 180, loss: 0.13949237763881683
step: 190, loss: 0.06707218289375305
step: 200, loss: 0.16286969184875488
step: 210, loss: 0.06556111574172974
step: 220, loss: 0.007103992626070976
step: 230, loss: 0.08939271420240402
step: 240, loss: 0.028609449043869972
step: 250, loss: 0.06087867170572281
step: 260, loss: 0.20917461812496185
step: 270, loss: 0.021234067156910896
step: 280, loss: 0.04365454241633415
step: 290, loss: 0.023878544569015503
step: 300, loss: 0.09405789524316788
step: 310, loss: 0.20874543488025665
step: 320, loss: 0.06226787343621254
step: 330, loss: 0.08942177146673203
step: 340, loss: 0.016268732026219368
step: 350, loss: 0.033763643354177475
step: 360, loss: 0.007685970980674028
step: 370, loss: 0.025783086195588112
step: 380, loss: 0.04122506082057953
step: 390, loss: 0.09176558256149292
step: 400, loss: 0.036846358329057693
step: 410, loss: 0.14134645462036133
step: 420, loss: 0.07430332154035568
epoch 1: dev_f1=0.9840546697038726, f1=0.9759999999999999, best_f1=0.9759999999999999
step: 0, loss: 0.07126642763614655
step: 10, loss: 0.07391683757305145
step: 20, loss: 0.01780121400952339
step: 30, loss: 0.018539542332291603
step: 40, loss: 0.08088001608848572
step: 50, loss: 0.08458861708641052
step: 60, loss: 0.06665374338626862
step: 70, loss: 0.11808183789253235
step: 80, loss: 0.03110639564692974
step: 90, loss: 0.1079467162489891
step: 100, loss: 0.10197780281305313
step: 110, loss: 0.03105819784104824
step: 120, loss: 0.06175632029771805
step: 130, loss: 0.12313561141490936
step: 140, loss: 0.09951093047857285
step: 150, loss: 0.036947112530469894
step: 160, loss: 0.13850970566272736
step: 170, loss: 0.142975851893425
step: 180, loss: 0.06637852638959885
step: 190, loss: 0.03218309208750725
step: 200, loss: 0.08552917838096619
step: 210, loss: 0.02296007052063942
step: 220, loss: 0.009484254755079746
step: 230, loss: 0.020992230623960495
step: 240, loss: 0.11417162418365479
step: 250, loss: 0.16142916679382324
step: 260, loss: 0.029453182592988014
step: 270, loss: 0.044075269252061844
step: 280, loss: 0.0008515529916621745
step: 290, loss: 0.07605275511741638
step: 300, loss: 0.054736994206905365
step: 310, loss: 0.03464476019144058
step: 320, loss: 0.05450837314128876
step: 330, loss: 0.044444888830184937
step: 340, loss: 0.06969442963600159
step: 350, loss: 0.033964019268751144
step: 360, loss: 0.04261457175016403
step: 370, loss: 0.03481671214103699
step: 380, loss: 0.10911320894956589
step: 390, loss: 0.10537223517894745
step: 400, loss: 0.1203838661313057
step: 410, loss: 0.0854560062289238
step: 420, loss: 0.05373445153236389
epoch 2: dev_f1=0.9795454545454545, f1=0.979591836734694, best_f1=0.9759999999999999
step: 0, loss: 0.1017930805683136
step: 10, loss: 0.013434057123959064
step: 20, loss: 0.11167792975902557
step: 30, loss: 0.0513167642056942
step: 40, loss: 0.08270169794559479
step: 50, loss: 0.010670262388885021
step: 60, loss: 0.11558634787797928
step: 70, loss: 0.0940650925040245
step: 80, loss: 0.14180713891983032
step: 90, loss: 0.02782253548502922
step: 100, loss: 0.07785608619451523
step: 110, loss: 0.1311655342578888
step: 120, loss: 0.031223725527524948
step: 130, loss: 0.2726704180240631
step: 140, loss: 0.03140483796596527
step: 150, loss: 0.1139402985572815
step: 160, loss: 0.028200581669807434
step: 170, loss: 0.02500484324991703
step: 180, loss: 0.05707002431154251
step: 190, loss: 0.059146031737327576
step: 200, loss: 0.016937829554080963
step: 210, loss: 0.12481365352869034
step: 220, loss: 0.011228572577238083
step: 230, loss: 0.016317790374159813
step: 240, loss: 0.1750268042087555
step: 250, loss: 0.00640553142875433
step: 260, loss: 0.06093435734510422
step: 270, loss: 0.04823458567261696
step: 280, loss: 0.06200488284230232
step: 290, loss: 0.018792809918522835
step: 300, loss: 0.26031938195228577
step: 310, loss: 0.03455942124128342
step: 320, loss: 0.14916981756687164
step: 330, loss: 0.14701518416404724
step: 340, loss: 0.07166622579097748
step: 350, loss: 0.017879553139209747
step: 360, loss: 0.1235140860080719
step: 370, loss: 0.00853900145739317
step: 380, loss: 0.01709814928472042
step: 390, loss: 0.051087476313114166
step: 400, loss: 0.011439123190939426
step: 410, loss: 0.05737684667110443
step: 420, loss: 0.11618780344724655
epoch 3: dev_f1=0.9819819819819819, f1=0.9797297297297298, best_f1=0.9759999999999999
step: 0, loss: 0.07619854062795639
step: 10, loss: 0.029344378039240837
step: 20, loss: 0.0017941630212590098
step: 30, loss: 0.06419140100479126
step: 40, loss: 0.02978775091469288
step: 50, loss: 0.00017608655616641045
step: 60, loss: 0.07885396480560303
step: 70, loss: 0.06438399851322174
step: 80, loss: 0.09500947594642639
step: 90, loss: 0.0247811172157526
step: 100, loss: 0.08582381159067154
step: 110, loss: 0.025095917284488678
step: 120, loss: 0.17156942188739777
step: 130, loss: 0.06766170263290405
step: 140, loss: 0.13874243199825287
step: 150, loss: 0.03964745253324509
step: 160, loss: 0.0482700951397419
step: 170, loss: 0.018181826919317245
step: 180, loss: 0.03511768579483032
step: 190, loss: 0.016780754551291466
step: 200, loss: 0.05472652614116669
step: 210, loss: 0.15062128007411957
step: 220, loss: 0.14436392486095428
step: 230, loss: 0.015005689114332199
step: 240, loss: 0.015547732822597027
step: 250, loss: 0.33386164903640747
step: 260, loss: 0.09348177164793015
step: 270, loss: 0.036753855645656586
step: 280, loss: 0.07646200805902481
step: 290, loss: 0.07452815026044846
step: 300, loss: 0.06768686324357986
step: 310, loss: 0.02801133319735527
step: 320, loss: 0.08995414525270462
step: 330, loss: 0.13099025189876556
step: 340, loss: 0.1625436544418335
step: 350, loss: 0.14023646712303162
step: 360, loss: 0.02898261696100235
step: 370, loss: 0.036550894379615784
step: 380, loss: 0.019896656274795532
step: 390, loss: 0.16139698028564453
step: 400, loss: 0.1617870330810547
step: 410, loss: 0.02759830839931965
step: 420, loss: 0.052766963839530945
epoch 4: dev_f1=0.9865771812080537, f1=0.9821428571428571, best_f1=0.9821428571428571
step: 0, loss: 0.08750232309103012
step: 10, loss: 0.07312941551208496
step: 20, loss: 0.09340459853410721
step: 30, loss: 0.06312954425811768
step: 40, loss: 0.08158444613218307
step: 50, loss: 0.11042513698339462
step: 60, loss: 0.019194133579730988
step: 70, loss: 3.912185275112279e-05
step: 80, loss: 0.07214824110269547
step: 90, loss: 0.09718459844589233
step: 100, loss: 0.07548436522483826
step: 110, loss: 0.028430365025997162
step: 120, loss: 0.04193737730383873
step: 130, loss: 0.07678842544555664
step: 140, loss: 0.0495772510766983
step: 150, loss: 0.05334285646677017
step: 160, loss: 0.11183200776576996
step: 170, loss: 0.023516617715358734
step: 180, loss: 0.02974500134587288
step: 190, loss: 0.07463294267654419
step: 200, loss: 0.014613816514611244
step: 210, loss: 0.07285880297422409
step: 220, loss: 0.009624406695365906
step: 230, loss: 0.17224006354808807
step: 240, loss: 0.09134911745786667
step: 250, loss: 0.023937737569212914
step: 260, loss: 0.00011023283877875656
step: 270, loss: 0.005441739223897457
step: 280, loss: 0.06016014143824577
step: 290, loss: 0.08630356937646866
step: 300, loss: 0.01764778420329094
step: 310, loss: 0.061607424169778824
step: 320, loss: 0.04973161220550537
step: 330, loss: 0.1293620765209198
step: 340, loss: 0.09420949220657349
step: 350, loss: 0.08574599772691727
step: 360, loss: 0.024100514128804207
step: 370, loss: 0.03408786281943321
step: 380, loss: 0.019805245101451874
step: 390, loss: 0.11393032968044281
step: 400, loss: 0.27186983823776245
step: 410, loss: 0.027114050462841988
step: 420, loss: 0.06552936136722565
epoch 5: dev_f1=0.9830124575311437, f1=0.9682539682539683, best_f1=0.9821428571428571
step: 0, loss: 0.12106315791606903
step: 10, loss: 0.027614064514636993
step: 20, loss: 0.0224916972219944
step: 30, loss: 0.07715396583080292
step: 40, loss: 0.1107468456029892
step: 50, loss: 0.09878122806549072
step: 60, loss: 0.1333235800266266
step: 70, loss: 0.08194868266582489
step: 80, loss: 0.06246153265237808
step: 90, loss: 0.05254600942134857
step: 100, loss: 0.02265969105064869
step: 110, loss: 0.01813933625817299
step: 120, loss: 0.01579735055565834
step: 130, loss: 0.012217288836836815
step: 140, loss: 0.01131870225071907
step: 150, loss: 0.07368546724319458
step: 160, loss: 0.08722938597202301
step: 170, loss: 0.019402720034122467
step: 180, loss: 0.009391388855874538
step: 190, loss: 0.10997051000595093
step: 200, loss: 0.07359173893928528
step: 210, loss: 0.03202188014984131
step: 220, loss: 0.011495724320411682
step: 230, loss: 0.014979477971792221
step: 240, loss: 0.028390642255544662
step: 250, loss: 0.01945175975561142
step: 260, loss: 0.0863642618060112
step: 270, loss: 0.043091174215078354
step: 280, loss: 0.04281504079699516
step: 290, loss: 0.23115932941436768
step: 300, loss: 0.04353463277220726
step: 310, loss: 0.026842115446925163
step: 320, loss: 0.0167706198990345
step: 330, loss: 0.07361762225627899
step: 340, loss: 0.02997448295354843
step: 350, loss: 0.14312824606895447
step: 360, loss: 0.019208289682865143
step: 370, loss: 0.011699754744768143
step: 380, loss: 0.07749839872121811
step: 390, loss: 0.1403370201587677
step: 400, loss: 0.10250157117843628
step: 410, loss: 0.10295794904232025
step: 420, loss: 0.02818315662443638
epoch 6: dev_f1=0.9943630214205187, f1=0.9876265466816648, best_f1=0.9876265466816648
step: 0, loss: 0.020959921181201935
step: 10, loss: 0.019395167008042336
step: 20, loss: 0.013345224782824516
step: 30, loss: 0.10322987288236618
step: 40, loss: 0.015796324238181114
step: 50, loss: 0.117629773914814
step: 60, loss: 0.009308523498475552
step: 70, loss: 0.00010344453039579093
step: 80, loss: 0.025867626070976257
step: 90, loss: 0.02700759656727314
step: 100, loss: 0.0224128607660532
step: 110, loss: 0.013034309260547161
step: 120, loss: 0.07591152936220169
step: 130, loss: 0.09739966690540314
step: 140, loss: 0.0548197403550148
step: 150, loss: 0.02495982125401497
step: 160, loss: 0.028939956799149513
step: 170, loss: 0.08224903047084808
step: 180, loss: 0.13854162395000458
step: 190, loss: 0.016491737216711044
step: 200, loss: 0.07789427787065506
step: 210, loss: 0.10750310868024826
step: 220, loss: 0.05944905802607536
step: 230, loss: 0.088002510368824
step: 240, loss: 0.0331430546939373
step: 250, loss: 0.014039725065231323
step: 260, loss: 0.013795692473649979
step: 270, loss: 0.06187734380364418
step: 280, loss: 0.023006360977888107
step: 290, loss: 0.09078094363212585
step: 300, loss: 0.09272345155477524
step: 310, loss: 0.011917948722839355
step: 320, loss: 0.021500129252672195
step: 330, loss: 0.002362468745559454
step: 340, loss: 0.06958620250225067
step: 350, loss: 0.034004636108875275
step: 360, loss: 0.12889650464057922
step: 370, loss: 0.03452134504914284
step: 380, loss: 0.06634197384119034
step: 390, loss: 0.1244141161441803
step: 400, loss: 0.0058028497733175755
step: 410, loss: 0.21770456433296204
step: 420, loss: 0.005782401189208031
epoch 7: dev_f1=0.9943883277216611, f1=0.9843749999999999, best_f1=0.9843749999999999
step: 0, loss: 0.1254071593284607
step: 10, loss: 0.026260320097208023
step: 20, loss: 0.10412297397851944
step: 30, loss: 0.0680764839053154
step: 40, loss: 0.07205657660961151
step: 50, loss: 0.060684237629175186
step: 60, loss: 0.18495093286037445
step: 70, loss: 0.04237629100680351
step: 80, loss: 0.05996387451887131
step: 90, loss: 0.012689203023910522
step: 100, loss: 0.008738088421523571
step: 110, loss: 0.0053405617363750935
step: 120, loss: 0.01862138696014881
step: 130, loss: 0.0073900674469769
step: 140, loss: 0.07295030355453491
step: 150, loss: 0.15676085650920868
step: 160, loss: 0.12277678400278091
step: 170, loss: 0.14978745579719543
step: 180, loss: 0.0196952223777771
step: 190, loss: 0.007313350215554237
step: 200, loss: 0.08716652542352676
step: 210, loss: 0.06169022619724274
step: 220, loss: 0.14796864986419678
step: 230, loss: 0.06753340363502502
step: 240, loss: 0.0074948761612176895
step: 250, loss: 0.04808853194117546
step: 260, loss: 0.02684810198843479
step: 270, loss: 0.07091201841831207
step: 280, loss: 0.0758713111281395
step: 290, loss: 0.28440749645233154
step: 300, loss: 0.010190137661993504
step: 310, loss: 0.010178831405937672
step: 320, loss: 0.010239819064736366
step: 330, loss: 0.020404458045959473
step: 340, loss: 0.01906099170446396
step: 350, loss: 0.010428906418383121
step: 360, loss: 0.006416400894522667
step: 370, loss: 0.028158701956272125
step: 380, loss: 0.013493737205862999
step: 390, loss: 0.013540105894207954
step: 400, loss: 0.0202949158847332
step: 410, loss: 0.019559472799301147
step: 420, loss: 0.14241328835487366
epoch 8: dev_f1=0.9932735426008968, f1=0.9844097995545658, best_f1=0.9843749999999999
step: 0, loss: 0.01918584667146206
step: 10, loss: 0.014871509745717049
step: 20, loss: 0.0875614657998085
step: 30, loss: 0.07014070451259613
step: 40, loss: 0.02850605733692646
step: 50, loss: 0.016342058777809143
step: 60, loss: 0.056231893599033356
step: 70, loss: 0.009935453534126282
step: 80, loss: 0.07464299350976944
step: 90, loss: 0.014643185772001743
step: 100, loss: 0.0357670895755291
step: 110, loss: 0.031096378341317177
step: 120, loss: 0.07213941961526871
step: 130, loss: 0.014156959019601345
step: 140, loss: 0.02035057358443737
step: 150, loss: 0.024318784475326538
step: 160, loss: 0.019636638462543488
step: 170, loss: 0.013912428170442581
step: 180, loss: 0.016112975776195526
step: 190, loss: 0.00852122437208891
step: 200, loss: 0.0616866871714592
step: 210, loss: 0.03158789500594139
step: 220, loss: 0.012211835943162441
step: 230, loss: 0.01351734809577465
step: 240, loss: 0.03624885901808739
step: 250, loss: 0.0728583112359047
step: 260, loss: 0.024348119273781776
step: 270, loss: 2.3822785806260072e-05
step: 280, loss: 0.02952343039214611
step: 290, loss: 0.0779213234782219
step: 300, loss: 0.02140693925321102
step: 310, loss: 0.2394946664571762
step: 320, loss: 0.056898631155490875
step: 330, loss: 0.05215102806687355
step: 340, loss: 0.10035444051027298
step: 350, loss: 0.08566870540380478
step: 360, loss: 0.022995389997959137
step: 370, loss: 0.0067707994021475315
step: 380, loss: 0.07305105030536652
step: 390, loss: 0.03976846858859062
step: 400, loss: 0.035614870488643646
step: 410, loss: 0.116416797041893
step: 420, loss: 0.18533504009246826
epoch 9: dev_f1=0.9932432432432432, f1=0.9864864864864865, best_f1=0.9843749999999999
step: 0, loss: 0.006400637328624725
step: 10, loss: 0.11648105829954147
step: 20, loss: 0.015364091843366623
step: 30, loss: 0.02176533453166485
step: 40, loss: 0.02169886790215969
step: 50, loss: 0.024360649287700653
step: 60, loss: 0.007749498356133699
step: 70, loss: 0.10444192588329315
step: 80, loss: 0.013883275911211967
step: 90, loss: 0.0071344091556966305
step: 100, loss: 0.07903268188238144
step: 110, loss: 0.013332308270037174
step: 120, loss: 0.01163256261497736
step: 130, loss: 0.12923027575016022
step: 140, loss: 0.00858977995812893
step: 150, loss: 0.00754114193841815
step: 160, loss: 0.0871458426117897
step: 170, loss: 0.058198340237140656
step: 180, loss: 0.02925429865717888
step: 190, loss: 0.05280958116054535
step: 200, loss: 0.010646076872944832
step: 210, loss: 0.06249461695551872
step: 220, loss: 0.11157571524381638
step: 230, loss: 0.020730042830109596
step: 240, loss: 0.042863354086875916
step: 250, loss: 0.05833767354488373
step: 260, loss: 0.06345377117395401
step: 270, loss: 0.12785838544368744
step: 280, loss: 0.06928219646215439
step: 290, loss: 0.026816528290510178
step: 300, loss: 0.15939666330814362
step: 310, loss: 0.006987940985709429
step: 320, loss: 0.09973650425672531
step: 330, loss: 0.08618131279945374
step: 340, loss: 0.12430538982152939
step: 350, loss: 0.08976904302835464
step: 360, loss: 0.01162202563136816
step: 370, loss: 0.025278039276599884
step: 380, loss: 0.0806347131729126
step: 390, loss: 0.0322507843375206
step: 400, loss: 0.023096462711691856
step: 410, loss: 0.017609789967536926
step: 420, loss: 0.012240460142493248
epoch 10: dev_f1=0.9943757030371203, f1=0.9797752808988766, best_f1=0.9843749999999999
step: 0, loss: 0.06919356435537338
step: 10, loss: 0.006052037701010704
step: 20, loss: 0.02269306406378746
step: 30, loss: 0.1090918630361557
step: 40, loss: 0.09256561845541
step: 50, loss: 0.04125339537858963
step: 60, loss: 6.560800829902291e-05
step: 70, loss: 0.03374045342206955
step: 80, loss: 0.11175056546926498
step: 90, loss: 0.14093756675720215
step: 100, loss: 0.07965725660324097
step: 110, loss: 0.013820338062942028
step: 120, loss: 0.0751173347234726
step: 130, loss: 0.007611027453094721
step: 140, loss: 0.11580987274646759
step: 150, loss: 0.021822448819875717
step: 160, loss: 0.029290959239006042
step: 170, loss: 0.07237331569194794
step: 180, loss: 0.06250126659870148
step: 190, loss: 0.008713682182133198
step: 200, loss: 0.17289355397224426
step: 210, loss: 0.02997901476919651
step: 220, loss: 0.06816130131483078
step: 230, loss: 0.06406016647815704
step: 240, loss: 0.06679724901914597
step: 250, loss: 0.03397396579384804
step: 260, loss: 0.06952360272407532
step: 270, loss: 0.14160460233688354
step: 280, loss: 0.12728513777256012
step: 290, loss: 0.0192642230540514
step: 300, loss: 0.010837662033736706
step: 310, loss: 0.06695351749658585
step: 320, loss: 0.019932391121983528
step: 330, loss: 0.16398945450782776
step: 340, loss: 0.013197191059589386
step: 350, loss: 0.051427148282527924
step: 360, loss: 0.12133613228797913
step: 370, loss: 0.03215174376964569
step: 380, loss: 0.013864411041140556
step: 390, loss: 0.09408418834209442
step: 400, loss: 0.11752431094646454
step: 410, loss: 0.000969218963291496
step: 420, loss: 0.07752899080514908
epoch 11: dev_f1=0.9943757030371203, f1=0.9821029082774049, best_f1=0.9843749999999999
step: 0, loss: 0.05239886790513992
step: 10, loss: 0.010250166989862919
step: 20, loss: 0.05274037644267082
step: 30, loss: 0.04903099685907364
step: 40, loss: 0.10861381143331528
step: 50, loss: 0.09535134583711624
step: 60, loss: 0.02308458462357521
step: 70, loss: 0.08005116134881973
step: 80, loss: 0.006679801270365715
step: 90, loss: 0.041593946516513824
step: 100, loss: 0.07607768476009369
step: 110, loss: 0.0025602427776902914
step: 120, loss: 0.006605342496186495
step: 130, loss: 0.01184562873095274
step: 140, loss: 0.06478890031576157
step: 150, loss: 0.050183579325675964
step: 160, loss: 0.01143437810242176
step: 170, loss: 0.06763938814401627
step: 180, loss: 0.19922633469104767
step: 190, loss: 0.019928278401494026
step: 200, loss: 0.052423685789108276
step: 210, loss: 0.013026667758822441
step: 220, loss: 0.01208428107202053
step: 230, loss: 0.011073330417275429
step: 240, loss: 0.05564481392502785
step: 250, loss: 0.10896953195333481
step: 260, loss: 0.008271745406091213
step: 270, loss: 0.09677328914403915
step: 280, loss: 0.004174640867859125
step: 290, loss: 0.027836374938488007
step: 300, loss: 0.084581159055233
step: 310, loss: 0.025504793971776962
step: 320, loss: 0.03086460568010807
step: 330, loss: 0.08471082895994186
step: 340, loss: 0.046073805540800095
step: 350, loss: 0.009895644150674343
step: 360, loss: 0.014034098014235497
step: 370, loss: 0.11720523983240128
step: 380, loss: 0.02336161769926548
step: 390, loss: 0.0001475037424825132
step: 400, loss: 0.07905272394418716
step: 410, loss: 0.05684458836913109
step: 420, loss: 0.06266975402832031
epoch 12: dev_f1=0.9943757030371203, f1=0.9832402234636871, best_f1=0.9843749999999999
step: 0, loss: 0.029956525191664696
step: 10, loss: 0.1563509702682495
step: 20, loss: 0.05524767190217972
step: 30, loss: 0.05960704758763313
step: 40, loss: 0.031295739114284515
step: 50, loss: 0.08398623764514923
step: 60, loss: 0.0029914118349552155
step: 70, loss: 0.10550948232412338
step: 80, loss: 0.08490942418575287
step: 90, loss: 0.05689580366015434
step: 100, loss: 0.04375919699668884
step: 110, loss: 0.037270687520504
step: 120, loss: 0.05199366807937622
step: 130, loss: 0.04653644561767578
step: 140, loss: 0.01777578517794609
step: 150, loss: 0.06267165392637253
step: 160, loss: 0.046480920165777206
step: 170, loss: 0.031731896102428436
step: 180, loss: 0.13355793058872223
step: 190, loss: 0.016733482480049133
step: 200, loss: 0.04200829938054085
step: 210, loss: 0.1031154915690422
step: 220, loss: 0.11461597681045532
step: 230, loss: 0.016108032315969467
step: 240, loss: 0.007318953983485699
step: 250, loss: 2.8691621992038563e-05
step: 260, loss: 0.12937353551387787
step: 270, loss: 0.1357734203338623
step: 280, loss: 0.051700759679079056
step: 290, loss: 0.017963634803891182
step: 300, loss: 0.0768825113773346
step: 310, loss: 0.10383705794811249
step: 320, loss: 0.06012517958879471
step: 330, loss: 0.061870723962783813
step: 340, loss: 0.0885397419333458
step: 350, loss: 0.07604404538869858
step: 360, loss: 0.0597359724342823
step: 370, loss: 0.005588989704847336
step: 380, loss: 0.10398653149604797
step: 390, loss: 0.039634820073843
step: 400, loss: 0.07852943241596222
step: 410, loss: 0.003025050275027752
step: 420, loss: 0.01904541440308094
epoch 13: dev_f1=0.9932584269662922, f1=0.983277591973244, best_f1=0.9843749999999999
step: 0, loss: 0.01808764785528183
step: 10, loss: 0.09894873201847076
step: 20, loss: 0.022243110463023186
step: 30, loss: 0.06609568744897842
step: 40, loss: 0.0568540096282959
step: 50, loss: 0.07024722546339035
step: 60, loss: 0.06723977625370026
step: 70, loss: 0.0158701129257679
step: 80, loss: 0.015535680577158928
step: 90, loss: 0.036039531230926514
step: 100, loss: 0.03951392322778702
step: 110, loss: 0.006129028275609016
step: 120, loss: 0.10773393511772156
step: 130, loss: 0.0030172273982316256
step: 140, loss: 0.007452943827956915
step: 150, loss: 0.07542320340871811
step: 160, loss: 0.009918482974171638
step: 170, loss: 0.0039021808188408613
step: 180, loss: 0.041533954441547394
step: 190, loss: 0.03306572884321213
step: 200, loss: 0.06924900412559509
step: 210, loss: 0.17548434436321259
step: 220, loss: 0.012352962046861649
step: 230, loss: 0.07677888125181198
step: 240, loss: 0.012685644440352917
step: 250, loss: 0.048455189913511276
step: 260, loss: 0.03834354877471924
step: 270, loss: 0.08272359520196915
step: 280, loss: 0.0510391928255558
step: 290, loss: 0.02962806634604931
step: 300, loss: 0.04700162261724472
step: 310, loss: 0.11389703303575516
step: 320, loss: 0.02017456479370594
step: 330, loss: 0.03379807993769646
step: 340, loss: 0.0644623264670372
step: 350, loss: 0.0061308955773711205
step: 360, loss: 0.11183727532625198
step: 370, loss: 0.01999477669596672
step: 380, loss: 0.015903625637292862
step: 390, loss: 0.04362664371728897
step: 400, loss: 0.11183740198612213
step: 410, loss: 0.018189407885074615
step: 420, loss: 0.0041577499359846115
epoch 14: dev_f1=0.9943757030371203, f1=0.9865771812080537, best_f1=0.9843749999999999
step: 0, loss: 0.0007415537256747484
step: 10, loss: 0.08981263637542725
step: 20, loss: 0.03148141875863075
step: 30, loss: 0.027911372482776642
step: 40, loss: 0.048105381429195404
step: 50, loss: 0.006053677294403315
step: 60, loss: 0.0042564719915390015
step: 70, loss: 0.048677485436201096
step: 80, loss: 0.02593868225812912
step: 90, loss: 0.021454785019159317
step: 100, loss: 0.06921007484197617
step: 110, loss: 0.02699241228401661
step: 120, loss: 0.04177413880825043
step: 130, loss: 0.028679918497800827
step: 140, loss: 0.01577058434486389
step: 150, loss: 0.012496010400354862
step: 160, loss: 0.0109951077029109
step: 170, loss: 0.01466836966574192
step: 180, loss: 0.001128478324972093
step: 190, loss: 0.004652205854654312
step: 200, loss: 0.02727678045630455
step: 210, loss: 0.02249888889491558
step: 220, loss: 0.025859279558062553
step: 230, loss: 0.0857372134923935
step: 240, loss: 0.0803886204957962
step: 250, loss: 0.08379301428794861
step: 260, loss: 0.03223828226327896
step: 270, loss: 0.05312205106019974
step: 280, loss: 0.01191647071391344
step: 290, loss: 0.10632996261119843
step: 300, loss: 0.09070724248886108
step: 310, loss: 2.132993540726602e-05
step: 320, loss: 0.012346703559160233
step: 330, loss: 0.031543828547000885
step: 340, loss: 0.06999942660331726
step: 350, loss: 0.0017593693919479847
step: 360, loss: 0.07828787714242935
step: 370, loss: 8.01622518338263e-05
step: 380, loss: 4.045601235702634e-05
step: 390, loss: 0.021007006987929344
step: 400, loss: 0.0009456762345507741
step: 410, loss: 0.003452127333730459
step: 420, loss: 0.11596422642469406
epoch 15: dev_f1=0.9943757030371203, f1=0.9832026875699889, best_f1=0.9843749999999999
step: 0, loss: 0.002828980563208461
step: 10, loss: 0.047563593834638596
step: 20, loss: 0.03417385742068291
step: 30, loss: 0.016630711033940315
step: 40, loss: 0.060686804354190826
step: 50, loss: 0.02606208063662052
step: 60, loss: 0.0005097963730804622
step: 70, loss: 0.0002093138318741694
step: 80, loss: 0.020197460427880287
step: 90, loss: 0.00010462911450304091
step: 100, loss: 0.021551692858338356
step: 110, loss: 0.03481360524892807
step: 120, loss: 0.014077417552471161
step: 130, loss: 0.050782088190317154
step: 140, loss: 0.00012961633910890669
step: 150, loss: 0.06024353951215744
step: 160, loss: 0.01784718967974186
step: 170, loss: 0.010412844829261303
step: 180, loss: 0.03728840500116348
step: 190, loss: 0.004135142080485821
step: 200, loss: 0.03718789666891098
step: 210, loss: 0.017224237322807312
step: 220, loss: 0.0027862784918397665
step: 230, loss: 0.0010395451681688428
step: 240, loss: 0.07919813692569733
step: 250, loss: 0.04238356649875641
step: 260, loss: 0.026206545531749725
step: 270, loss: 0.05097580701112747
step: 280, loss: 0.01890178583562374
step: 290, loss: 0.0029988810420036316
step: 300, loss: 0.07906656712293625
step: 310, loss: 0.0013126139529049397
step: 320, loss: 0.02189255878329277
step: 330, loss: 0.020699666813015938
step: 340, loss: 0.00026226029149256647
step: 350, loss: 9.496028360445052e-05
step: 360, loss: 0.0703522264957428
step: 370, loss: 0.136898010969162
step: 380, loss: 0.005328285042196512
step: 390, loss: 0.00025105869281105697
step: 400, loss: 0.04184192791581154
step: 410, loss: 0.019675081595778465
step: 420, loss: 0.021999740973114967
epoch 16: dev_f1=0.9943630214205187, f1=0.9887387387387387, best_f1=0.9843749999999999
step: 0, loss: 0.09930378943681717
step: 10, loss: 0.07314430177211761
step: 20, loss: 0.02748931385576725
step: 30, loss: 0.025891967117786407
step: 40, loss: 0.0001743252360029146
step: 50, loss: 0.05251234024763107
step: 60, loss: 0.07315228879451752
step: 70, loss: 7.907844701549038e-05
step: 80, loss: 0.008099718019366264
step: 90, loss: 0.07932430505752563
step: 100, loss: 0.07811719924211502
step: 110, loss: 0.06049027666449547
step: 120, loss: 0.03645661100745201
step: 130, loss: 0.03937584161758423
step: 140, loss: 0.11651530116796494
step: 150, loss: 0.03515774384140968
step: 160, loss: 0.00024218751059379429
step: 170, loss: 0.02595307119190693
step: 180, loss: 0.016004111617803574
step: 190, loss: 0.04507433623075485
step: 200, loss: 0.01233717706054449
step: 210, loss: 0.04080769792199135
step: 220, loss: 0.04165475070476532
step: 230, loss: 0.006881908979266882
step: 240, loss: 0.0646868571639061
step: 250, loss: 0.025920623913407326
step: 260, loss: 0.005471322685480118
step: 270, loss: 0.0793582871556282
step: 280, loss: 0.041745513677597046
step: 290, loss: 0.06379641592502594
step: 300, loss: 0.022297555580735207
step: 310, loss: 0.012080017477273941
step: 320, loss: 0.047193508595228195
step: 330, loss: 0.0035412516444921494
step: 340, loss: 0.07870295643806458
step: 350, loss: 0.0017885570414364338
step: 360, loss: 0.00016997304919641465
step: 370, loss: 0.036777857691049576
step: 380, loss: 0.045327506959438324
step: 390, loss: 0.00016329408390447497
step: 400, loss: 0.005317665170878172
step: 410, loss: 0.013167990371584892
step: 420, loss: 0.0030904614832252264
epoch 17: dev_f1=0.9954954954954955, f1=0.9854423292273236, best_f1=0.9854423292273236
step: 0, loss: 0.00010339325672248378
step: 10, loss: 0.07279609143733978
step: 20, loss: 0.031203489750623703
step: 30, loss: 0.05684174597263336
step: 40, loss: 0.05166281387209892
step: 50, loss: 0.021691780537366867
step: 60, loss: 0.028570499271154404
step: 70, loss: 0.0009654865716584027
step: 80, loss: 0.03471173718571663
step: 90, loss: 0.0010850332910194993
step: 100, loss: 0.0011808067793026567
step: 110, loss: 0.020252671092748642
step: 120, loss: 0.020930811762809753
step: 130, loss: 0.019978750497102737
step: 140, loss: 0.05976653844118118
step: 150, loss: 0.031658727675676346
step: 160, loss: 0.0026748625095933676
step: 170, loss: 0.02187180519104004
step: 180, loss: 0.035019610077142715
step: 190, loss: 0.12331598252058029
step: 200, loss: 0.009409517049789429
step: 210, loss: 0.022121360525488853
step: 220, loss: 0.02050289511680603
step: 230, loss: 0.02915758639574051
step: 240, loss: 0.034051313996315
step: 250, loss: 0.059866733849048615
step: 260, loss: 0.005564207676798105
step: 270, loss: 0.048386842012405396
step: 280, loss: 0.0755620002746582
step: 290, loss: 0.01786993443965912
step: 300, loss: 0.019702833145856857
step: 310, loss: 0.0007790098898112774
step: 320, loss: 0.03357914835214615
step: 330, loss: 0.00045032569323666394
step: 340, loss: 0.025902263820171356
step: 350, loss: 0.01538028847426176
step: 360, loss: 0.017765071243047714
step: 370, loss: 0.010429859161376953
step: 380, loss: 0.001000910415314138
step: 390, loss: 0.0782434269785881
step: 400, loss: 0.030145682394504547
step: 410, loss: 0.0006969168316572905
step: 420, loss: 0.0005667379009537399
epoch 18: dev_f1=0.9954954954954955, f1=0.9843400447427293, best_f1=0.9854423292273236
step: 0, loss: 0.002184337005019188
step: 10, loss: 0.042428985238075256
step: 20, loss: 0.024570275098085403
step: 30, loss: 0.0026479181833565235
step: 40, loss: 0.00013035796291660517
step: 50, loss: 0.026206061244010925
step: 60, loss: 0.024849511682987213
step: 70, loss: 0.0005523927393369377
step: 80, loss: 0.03298847749829292
step: 90, loss: 0.046519190073013306
step: 100, loss: 0.040628042072057724
step: 110, loss: 0.027324719354510307
step: 120, loss: 0.0025002555921673775
step: 130, loss: 0.00026086880825459957
step: 140, loss: 0.010555506683886051
step: 150, loss: 0.031752120703458786
step: 160, loss: 0.00025131230358965695
step: 170, loss: 0.0733075812458992
step: 180, loss: 0.05461195483803749
step: 190, loss: 0.006891608703881502
step: 200, loss: 0.00342149892821908
step: 210, loss: 5.4336862376658246e-05
step: 220, loss: 0.04192323237657547
step: 230, loss: 0.0003014591638930142
step: 240, loss: 0.018532229587435722
step: 250, loss: 0.023081842809915543
step: 260, loss: 0.03564330190420151
step: 270, loss: 0.06507603079080582
step: 280, loss: 0.05185409262776375
step: 290, loss: 4.072087904205546e-05
step: 300, loss: 0.04545852169394493
step: 310, loss: 0.02778303623199463
step: 320, loss: 0.0009365219157189131
step: 330, loss: 0.02602696232497692
step: 340, loss: 2.4113764084177092e-05
step: 350, loss: 0.00013146927813068032
step: 360, loss: 0.043336354196071625
step: 370, loss: 0.0920090302824974
step: 380, loss: 0.026796072721481323
step: 390, loss: 0.000241862129769288
step: 400, loss: 0.037750035524368286
step: 410, loss: 0.0004311336379032582
step: 420, loss: 0.025410564616322517
epoch 19: dev_f1=0.995505617977528, f1=0.9855072463768116, best_f1=0.9855072463768116
step: 0, loss: 7.94802326709032e-05
step: 10, loss: 0.0473722405731678
step: 20, loss: 0.04310273379087448
step: 30, loss: 1.0192320587520953e-05
step: 40, loss: 0.034714967012405396
step: 50, loss: 0.05123034864664078
step: 60, loss: 0.025051195174455643
step: 70, loss: 0.001346144243143499
step: 80, loss: 0.014973020181059837
step: 90, loss: 0.047765035182237625
step: 100, loss: 0.046466585248708725
step: 110, loss: 4.2896299419226125e-05
step: 120, loss: 0.0018893228843808174
step: 130, loss: 0.07314180582761765
step: 140, loss: 7.395330612780526e-05
step: 150, loss: 0.07537416368722916
step: 160, loss: 0.0004890480195172131
step: 170, loss: 0.0006105403299443424
step: 180, loss: 0.018592577427625656
step: 190, loss: 0.052298419177532196
step: 200, loss: 0.0009741421672515571
step: 210, loss: 0.053616516292095184
step: 220, loss: 0.017385853454470634
step: 230, loss: 0.04395371302962303
step: 240, loss: 6.898479477968067e-05
step: 250, loss: 0.00013225458678789437
step: 260, loss: 0.025041693821549416
step: 270, loss: 0.03531937301158905
step: 280, loss: 0.044061869382858276
step: 290, loss: 0.00011935306247323751
step: 300, loss: 0.016744405031204224
step: 310, loss: 0.027340207248926163
step: 320, loss: 9.301991667598486e-06
step: 330, loss: 0.0022511116694658995
step: 340, loss: 0.0001348613150184974
step: 350, loss: 0.04688512533903122
step: 360, loss: 0.021403755992650986
step: 370, loss: 0.07483873516321182
step: 380, loss: 0.04125456511974335
step: 390, loss: 0.00018341165559832007
step: 400, loss: 0.05203106999397278
step: 410, loss: 0.02191617526113987
step: 420, loss: 0.02361632138490677
epoch 20: dev_f1=0.9954954954954955, f1=0.9832026875699889, best_f1=0.9855072463768116
