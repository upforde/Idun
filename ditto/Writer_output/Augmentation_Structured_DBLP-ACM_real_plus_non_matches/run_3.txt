cuda
Device: cuda
step: 0, loss: 0.7727245092391968
step: 10, loss: 0.36290594935417175
step: 20, loss: 0.2565743327140808
step: 30, loss: 0.4691581428050995
step: 40, loss: 0.3792443871498108
step: 50, loss: 0.1200701966881752
step: 60, loss: 0.2017296403646469
step: 70, loss: 0.04927524924278259
step: 80, loss: 0.12259892374277115
step: 90, loss: 0.12488815188407898
step: 100, loss: 0.06416676938533783
step: 110, loss: 0.06721216440200806
step: 120, loss: 0.05421841889619827
step: 130, loss: 0.08419169485569
step: 140, loss: 0.07551244646310806
step: 150, loss: 0.017153287306427956
step: 160, loss: 0.04524817317724228
step: 170, loss: 0.14939144253730774
step: 180, loss: 0.2508130967617035
step: 190, loss: 0.13470128178596497
step: 200, loss: 0.12472673505544662
step: 210, loss: 0.03281880170106888
step: 220, loss: 0.07814290374517441
step: 230, loss: 0.036863215267658234
step: 240, loss: 0.13486890494823456
step: 250, loss: 0.1552189737558365
step: 260, loss: 0.04963254556059837
step: 270, loss: 0.053935691714286804
step: 280, loss: 0.0810917466878891
step: 290, loss: 0.08049601316452026
step: 300, loss: 0.08025582134723663
step: 310, loss: 0.06776854395866394
step: 320, loss: 0.028324158862233162
step: 330, loss: 0.021518876776099205
step: 340, loss: 0.055430129170417786
step: 350, loss: 0.013796081766486168
step: 360, loss: 0.05628396198153496
step: 370, loss: 0.031639404594898224
step: 380, loss: 0.036751434206962585
step: 390, loss: 0.04581758379936218
step: 400, loss: 0.00729250255972147
step: 410, loss: 0.010351433418691158
step: 420, loss: 0.07945633679628372
epoch 1: dev_f1=0.9909706546275394, f1=0.9786276715410572, best_f1=0.9786276715410572
step: 0, loss: 0.09294506907463074
step: 10, loss: 0.04792498052120209
step: 20, loss: 0.20668435096740723
step: 30, loss: 0.029540617018938065
step: 40, loss: 0.013984167948365211
step: 50, loss: 0.017964083701372147
step: 60, loss: 0.0635230541229248
step: 70, loss: 0.14548544585704803
step: 80, loss: 0.08080967515707016
step: 90, loss: 0.16251736879348755
step: 100, loss: 0.019757796078920364
step: 110, loss: 0.11465820670127869
step: 120, loss: 0.07306378334760666
step: 130, loss: 0.18906337022781372
step: 140, loss: 0.03289709985256195
step: 150, loss: 0.05933674797415733
step: 160, loss: 0.07758573442697525
step: 170, loss: 0.1663278192281723
step: 180, loss: 0.1194891408085823
step: 190, loss: 0.016928071156144142
step: 200, loss: 0.008479204028844833
step: 210, loss: 0.013319281861186028
step: 220, loss: 0.017483890056610107
step: 230, loss: 0.01982847787439823
step: 240, loss: 0.1024155467748642
step: 250, loss: 0.14070867002010345
step: 260, loss: 0.04289879649877548
step: 270, loss: 0.059222955256700516
step: 280, loss: 0.05262341722846031
step: 290, loss: 0.1390015184879303
step: 300, loss: 0.2656537890434265
step: 310, loss: 0.03720100596547127
step: 320, loss: 0.14007335901260376
step: 330, loss: 0.1186537966132164
step: 340, loss: 0.03289742395281792
step: 350, loss: 0.023242956027388573
step: 360, loss: 0.025028664618730545
step: 370, loss: 0.011202271096408367
step: 380, loss: 0.08101621270179749
step: 390, loss: 0.049719348549842834
step: 400, loss: 0.12439022213220596
step: 410, loss: 0.06363646686077118
step: 420, loss: 0.054598934948444366
epoch 2: dev_f1=0.9910112359550561, f1=0.978865406006674, best_f1=0.978865406006674
step: 0, loss: 0.11450760811567307
step: 10, loss: 0.07221365720033646
step: 20, loss: 0.07255503535270691
step: 30, loss: 0.07658360153436661
step: 40, loss: 0.030267979949712753
step: 50, loss: 0.0289390217512846
step: 60, loss: 0.02670551836490631
step: 70, loss: 0.1861804872751236
step: 80, loss: 0.07595356553792953
step: 90, loss: 0.0034571525175124407
step: 100, loss: 0.09144516289234161
step: 110, loss: 0.09022849798202515
step: 120, loss: 0.12188843637704849
step: 130, loss: 0.08842495828866959
step: 140, loss: 0.011154523119330406
step: 150, loss: 0.03445139899849892
step: 160, loss: 0.0021852198988199234
step: 170, loss: 0.026306701824069023
step: 180, loss: 0.05410473793745041
step: 190, loss: 0.04514976218342781
step: 200, loss: 0.046357907354831696
step: 210, loss: 0.025584034621715546
step: 220, loss: 0.007073582615703344
step: 230, loss: 0.05671181529760361
step: 240, loss: 0.06813265383243561
step: 250, loss: 0.03562850505113602
step: 260, loss: 0.05155406519770622
step: 270, loss: 0.0703999400138855
step: 280, loss: 0.07232504338026047
step: 290, loss: 0.03329581394791603
step: 300, loss: 0.03475514426827431
step: 310, loss: 0.018712783232331276
step: 320, loss: 0.03121780976653099
step: 330, loss: 0.10488172620534897
step: 340, loss: 0.08652366697788239
step: 350, loss: 0.12960781157016754
step: 360, loss: 0.08245141059160233
step: 370, loss: 0.04841768741607666
step: 380, loss: 0.06442957371473312
step: 390, loss: 0.01894252933561802
step: 400, loss: 0.006205282639712095
step: 410, loss: 0.09694404900074005
step: 420, loss: 0.1259898692369461
epoch 3: dev_f1=0.9910313901345291, f1=0.9820627802690582, best_f1=0.9820627802690582
step: 0, loss: 0.018453944474458694
step: 10, loss: 0.07815819978713989
step: 20, loss: 0.019368169829249382
step: 30, loss: 0.03044784441590309
step: 40, loss: 0.012044934555888176
step: 50, loss: 0.014662709087133408
step: 60, loss: 0.00821894034743309
step: 70, loss: 0.011771082878112793
step: 80, loss: 0.06838208436965942
step: 90, loss: 0.05941459536552429
step: 100, loss: 0.0022038063034415245
step: 110, loss: 0.07710824906826019
step: 120, loss: 0.02547847107052803
step: 130, loss: 0.05765653774142265
step: 140, loss: 0.13122040033340454
step: 150, loss: 0.08433401584625244
step: 160, loss: 0.06962978839874268
step: 170, loss: 0.08298937231302261
step: 180, loss: 0.10165659338235855
step: 190, loss: 0.021865572780370712
step: 200, loss: 0.09150080382823944
step: 210, loss: 0.03357527405023575
step: 220, loss: 0.03822241351008415
step: 230, loss: 0.04098941385746002
step: 240, loss: 0.006813336629420519
step: 250, loss: 0.08976589143276215
step: 260, loss: 0.11168595403432846
step: 270, loss: 0.0666847676038742
step: 280, loss: 0.07509636133909225
step: 290, loss: 0.041103046387434006
step: 300, loss: 0.13134466111660004
step: 310, loss: 0.014939380809664726
step: 320, loss: 0.02464165911078453
step: 330, loss: 0.06290917098522186
step: 340, loss: 0.09085600823163986
step: 350, loss: 0.04834141209721565
step: 360, loss: 0.011881937272846699
step: 370, loss: 0.010262350551784039
step: 380, loss: 0.10776133835315704
step: 390, loss: 0.007630500011146069
step: 400, loss: 0.018576936796307564
step: 410, loss: 0.07435160875320435
step: 420, loss: 0.21599793434143066
epoch 4: dev_f1=0.9863945578231292, f1=0.9794988610478361, best_f1=0.9820627802690582
step: 0, loss: 0.13284865021705627
step: 10, loss: 0.007865800522267818
step: 20, loss: 0.08237775415182114
step: 30, loss: 0.022825021296739578
step: 40, loss: 0.014242725446820259
step: 50, loss: 0.058164045214653015
step: 60, loss: 0.06556933373212814
step: 70, loss: 0.09022581577301025
step: 80, loss: 0.030720923095941544
step: 90, loss: 0.08652467280626297
step: 100, loss: 0.21575260162353516
step: 110, loss: 0.0065656122751533985
step: 120, loss: 0.12133320420980453
step: 130, loss: 0.1324380487203598
step: 140, loss: 0.027471639215946198
step: 150, loss: 0.05397210270166397
step: 160, loss: 0.07365072518587112
step: 170, loss: 0.06038431078195572
step: 180, loss: 0.11172472685575485
step: 190, loss: 0.03464719280600548
step: 200, loss: 0.0692576915025711
step: 210, loss: 0.026223046705126762
step: 220, loss: 0.00589750288054347
step: 230, loss: 0.013825864531099796
step: 240, loss: 0.03267303854227066
step: 250, loss: 0.08134731650352478
step: 260, loss: 0.1888928860425949
step: 270, loss: 0.10705200582742691
step: 280, loss: 0.01983949914574623
step: 290, loss: 0.09388060122728348
step: 300, loss: 0.08480632305145264
step: 310, loss: 0.03990120068192482
step: 320, loss: 0.02092372626066208
step: 330, loss: 0.08937038481235504
step: 340, loss: 0.013718444854021072
step: 350, loss: 0.08052516728639603
step: 360, loss: 0.13510675728321075
step: 370, loss: 0.006087314337491989
step: 380, loss: 0.13818790018558502
step: 390, loss: 0.006121728103607893
step: 400, loss: 0.06843504309654236
step: 410, loss: 0.13433170318603516
step: 420, loss: 0.017750240862369537
epoch 5: dev_f1=0.992108229988726, f1=0.9831271091113611, best_f1=0.9831271091113611
step: 0, loss: 0.021481039002537727
step: 10, loss: 0.122121661901474
step: 20, loss: 0.009920036420226097
step: 30, loss: 0.1385987102985382
step: 40, loss: 0.00984251219779253
step: 50, loss: 0.0052322885021567345
step: 60, loss: 0.0028627507854253054
step: 70, loss: 0.1371530145406723
step: 80, loss: 0.016559630632400513
step: 90, loss: 0.09641487151384354
step: 100, loss: 0.1246936172246933
step: 110, loss: 0.010672396048903465
step: 120, loss: 0.0800028145313263
step: 130, loss: 0.1248798742890358
step: 140, loss: 0.06110306456685066
step: 150, loss: 0.02668657712638378
step: 160, loss: 0.05794459208846092
step: 170, loss: 0.05928248167037964
step: 180, loss: 0.10047908872365952
step: 190, loss: 0.08897241950035095
step: 200, loss: 0.01963566243648529
step: 210, loss: 0.08349337428808212
step: 220, loss: 0.08590921014547348
step: 230, loss: 0.05790405720472336
step: 240, loss: 0.01803380623459816
step: 250, loss: 0.07945529371500015
step: 260, loss: 0.05605827271938324
step: 270, loss: 0.13190287351608276
step: 280, loss: 0.025004563853144646
step: 290, loss: 0.01662103831768036
step: 300, loss: 0.01245565339922905
step: 310, loss: 0.07545609772205353
step: 320, loss: 0.013412554748356342
step: 330, loss: 0.14622075855731964
step: 340, loss: 0.13763479888439178
step: 350, loss: 0.09168195724487305
step: 360, loss: 0.09228195250034332
step: 370, loss: 0.0778072401881218
step: 380, loss: 0.03700202330946922
step: 390, loss: 0.046992603689432144
step: 400, loss: 0.06978659331798553
step: 410, loss: 0.11382168531417847
step: 420, loss: 0.04524732753634453
epoch 6: dev_f1=0.9943883277216611, f1=0.9854423292273236, best_f1=0.9854423292273236
step: 0, loss: 0.01894620805978775
step: 10, loss: 0.1131853461265564
step: 20, loss: 0.03898121416568756
step: 30, loss: 0.03619462251663208
step: 40, loss: 0.0058149066753685474
step: 50, loss: 0.039480194449424744
step: 60, loss: 0.07526550441980362
step: 70, loss: 0.016577523201704025
step: 80, loss: 0.0632898136973381
step: 90, loss: 0.071110799908638
step: 100, loss: 0.06884432584047318
step: 110, loss: 0.022664619609713554
step: 120, loss: 0.020344160497188568
step: 130, loss: 0.00730754341930151
step: 140, loss: 0.014066632837057114
step: 150, loss: 0.005601728800684214
step: 160, loss: 0.07294443994760513
step: 170, loss: 0.01063179224729538
step: 180, loss: 0.006246306002140045
step: 190, loss: 0.019649026915431023
step: 200, loss: 0.006188811268657446
step: 210, loss: 0.0032100884709507227
step: 220, loss: 0.01718374900519848
step: 230, loss: 0.16224712133407593
step: 240, loss: 0.027087539434432983
step: 250, loss: 0.09181858599185944
step: 260, loss: 0.023400265723466873
step: 270, loss: 0.11056177318096161
step: 280, loss: 0.00010303288581781089
step: 290, loss: 0.04027320817112923
step: 300, loss: 0.016922680661082268
step: 310, loss: 0.010199273005127907
step: 320, loss: 0.009346028789877892
step: 330, loss: 0.14814993739128113
step: 340, loss: 0.010980273596942425
step: 350, loss: 0.0882667526602745
step: 360, loss: 0.06531299650669098
step: 370, loss: 0.00012108022929169238
step: 380, loss: 0.057872723788022995
step: 390, loss: 0.048708751797676086
step: 400, loss: 0.12028264254331589
step: 410, loss: 0.05845925211906433
step: 420, loss: 0.07620614022016525
epoch 7: dev_f1=0.9921612541993281, f1=0.9821029082774049, best_f1=0.9854423292273236
step: 0, loss: 0.0002940284030046314
step: 10, loss: 0.012400157749652863
step: 20, loss: 0.08211850374937057
step: 30, loss: 0.099111407995224
step: 40, loss: 0.05730268731713295
step: 50, loss: 0.025174455717206
step: 60, loss: 0.053827013820409775
step: 70, loss: 0.027257204055786133
step: 80, loss: 0.008995353244245052
step: 90, loss: 0.006179890129715204
step: 100, loss: 0.023052489385008812
step: 110, loss: 0.08096667379140854
step: 120, loss: 0.023421134799718857
step: 130, loss: 0.006702236831188202
step: 140, loss: 0.013126086443662643
step: 150, loss: 0.025241758674383163
step: 160, loss: 0.01899540424346924
step: 170, loss: 0.07746423780918121
step: 180, loss: 0.01330346055328846
step: 190, loss: 0.08229397982358932
step: 200, loss: 0.06978467106819153
step: 210, loss: 0.008226699195802212
step: 220, loss: 0.06358872354030609
step: 230, loss: 0.0675998330116272
step: 240, loss: 0.07162560522556305
step: 250, loss: 0.027613205835223198
step: 260, loss: 0.017424503341317177
step: 270, loss: 0.045664381235837936
step: 280, loss: 0.2057889699935913
step: 290, loss: 0.04832883179187775
step: 300, loss: 0.09000150114297867
step: 310, loss: 0.08559934794902802
step: 320, loss: 0.06831913441419601
step: 330, loss: 0.08879748731851578
step: 340, loss: 0.07695819437503815
step: 350, loss: 0.06545419245958328
step: 360, loss: 0.1428803950548172
step: 370, loss: 0.01010280754417181
step: 380, loss: 0.07747910916805267
step: 390, loss: 0.12541033327579498
step: 400, loss: 0.14643818140029907
step: 410, loss: 0.09158200025558472
step: 420, loss: 0.1345854252576828
epoch 8: dev_f1=0.987598647125141, f1=0.9808773903262092, best_f1=0.9854423292273236
step: 0, loss: 0.04372447356581688
step: 10, loss: 0.00044387203524820507
step: 20, loss: 0.03129519149661064
step: 30, loss: 0.04547977074980736
step: 40, loss: 0.13190962374210358
step: 50, loss: 0.031110331416130066
step: 60, loss: 0.022618485614657402
step: 70, loss: 0.0055205244570970535
step: 80, loss: 0.057956159114837646
step: 90, loss: 0.0722215324640274
step: 100, loss: 0.07209505885839462
step: 110, loss: 0.006533041130751371
step: 120, loss: 0.007679732050746679
step: 130, loss: 0.06830767542123795
step: 140, loss: 0.04736802354454994
step: 150, loss: 0.07193127274513245
step: 160, loss: 0.05908496305346489
step: 170, loss: 0.04968379810452461
step: 180, loss: 0.07466982305049896
step: 190, loss: 0.011220754124224186
step: 200, loss: 0.039028335362672806
step: 210, loss: 0.013555624522268772
step: 220, loss: 0.027744103223085403
step: 230, loss: 0.20270319283008575
step: 240, loss: 0.0031741445418447256
step: 250, loss: 0.04880911484360695
step: 260, loss: 0.0031144344247877598
step: 270, loss: 0.022754617035388947
step: 280, loss: 0.08759558200836182
step: 290, loss: 0.08959830552339554
step: 300, loss: 0.10721231997013092
step: 310, loss: 0.16448648273944855
step: 320, loss: 0.024016674607992172
step: 330, loss: 0.0730617493391037
step: 340, loss: 0.12358664721250534
step: 350, loss: 0.07688772678375244
step: 360, loss: 0.18794845044612885
step: 370, loss: 0.03504524379968643
step: 380, loss: 0.13245216012001038
step: 390, loss: 0.031848564743995667
step: 400, loss: 0.03718041256070137
step: 410, loss: 0.03422393649816513
step: 420, loss: 0.03579390048980713
epoch 9: dev_f1=0.9943757030371203, f1=0.9831271091113611, best_f1=0.9854423292273236
step: 0, loss: 0.0388670489192009
step: 10, loss: 0.011292577721178532
step: 20, loss: 0.004429635591804981
step: 30, loss: 0.10605286806821823
step: 40, loss: 0.022741375491023064
step: 50, loss: 2.0499372112681158e-05
step: 60, loss: 0.06134924292564392
step: 70, loss: 0.03696068003773689
step: 80, loss: 0.019439980387687683
step: 90, loss: 0.012135145254433155
step: 100, loss: 0.023993544280529022
step: 110, loss: 0.10684119164943695
step: 120, loss: 0.07045917958021164
step: 130, loss: 0.04069976881146431
step: 140, loss: 0.058122262358665466
step: 150, loss: 0.040346842259168625
step: 160, loss: 0.016498016193509102
step: 170, loss: 0.0017968948232010007
step: 180, loss: 0.03992278128862381
step: 190, loss: 0.04915707930922508
step: 200, loss: 0.01739809848368168
step: 210, loss: 0.003948314115405083
step: 220, loss: 0.012692490592598915
step: 230, loss: 0.10803934186697006
step: 240, loss: 0.10035575926303864
step: 250, loss: 0.019092781469225883
step: 260, loss: 0.0990140363574028
step: 270, loss: 0.02412870153784752
step: 280, loss: 0.0842718780040741
step: 290, loss: 0.04474550858139992
step: 300, loss: 0.027472099289298058
step: 310, loss: 0.01818411611020565
step: 320, loss: 0.007622730452567339
step: 330, loss: 0.01870676316320896
step: 340, loss: 0.019556470215320587
step: 350, loss: 0.05062882974743843
step: 360, loss: 0.007651063147932291
step: 370, loss: 0.005296243354678154
step: 380, loss: 0.013289686292409897
step: 390, loss: 0.00035088451113551855
step: 400, loss: 0.12611790001392365
step: 410, loss: 0.13285917043685913
step: 420, loss: 0.015988565981388092
epoch 10: dev_f1=0.9943883277216611, f1=0.9855072463768116, best_f1=0.9854423292273236
step: 0, loss: 0.0035989603493362665
step: 10, loss: 0.07480151951313019
step: 20, loss: 0.07914288341999054
step: 30, loss: 1.89725815289421e-05
step: 40, loss: 0.004591288976371288
step: 50, loss: 0.023348573595285416
step: 60, loss: 0.030476972460746765
step: 70, loss: 0.006316362880170345
step: 80, loss: 0.004329157527536154
step: 90, loss: 0.059420738369226456
step: 100, loss: 0.03969082236289978
step: 110, loss: 0.04195055738091469
step: 120, loss: 0.008467688225209713
step: 130, loss: 0.0019664294086396694
step: 140, loss: 0.12653231620788574
step: 150, loss: 0.020948501303792
step: 160, loss: 0.04372705519199371
step: 170, loss: 0.03300788626074791
step: 180, loss: 0.03321902081370354
step: 190, loss: 0.11987420916557312
step: 200, loss: 0.045730963349342346
step: 210, loss: 0.11968285590410233
step: 220, loss: 0.06324872374534607
step: 230, loss: 0.07858849316835403
step: 240, loss: 0.09002382308244705
step: 250, loss: 0.03540193289518356
step: 260, loss: 0.008030813187360764
step: 270, loss: 0.08451159298419952
step: 280, loss: 0.03593381494283676
step: 290, loss: 0.07578612864017487
step: 300, loss: 0.006823108531534672
step: 310, loss: 0.02847529575228691
step: 320, loss: 0.048971883952617645
step: 330, loss: 0.09277606755495071
step: 340, loss: 0.12635231018066406
step: 350, loss: 0.03358246013522148
step: 360, loss: 0.03879261389374733
step: 370, loss: 0.06615301221609116
step: 380, loss: 0.0730210542678833
step: 390, loss: 0.0628415048122406
step: 400, loss: 0.10281040519475937
step: 410, loss: 0.1526225060224533
step: 420, loss: 0.003451078664511442
epoch 11: dev_f1=0.9866071428571428, f1=0.9810901001112348, best_f1=0.9854423292273236
step: 0, loss: 0.02906137704849243
step: 10, loss: 0.012727816589176655
step: 20, loss: 0.029009055346250534
step: 30, loss: 0.03163822367787361
step: 40, loss: 0.021341340616345406
step: 50, loss: 0.002741903066635132
step: 60, loss: 0.05871093273162842
step: 70, loss: 1.4312304301711265e-05
step: 80, loss: 0.02712142840027809
step: 90, loss: 0.011925479397177696
step: 100, loss: 0.015874184668064117
step: 110, loss: 0.0176867563277483
step: 120, loss: 0.008333688601851463
step: 130, loss: 0.017123643308877945
step: 140, loss: 0.0035688593052327633
step: 150, loss: 0.009687047451734543
step: 160, loss: 0.04044386371970177
step: 170, loss: 0.05095052719116211
step: 180, loss: 0.01206953078508377
step: 190, loss: 0.04706528037786484
step: 200, loss: 0.009957858361303806
step: 210, loss: 0.03508135303854942
step: 220, loss: 0.03723498061299324
step: 230, loss: 0.0408494658768177
step: 240, loss: 0.021362289786338806
step: 250, loss: 0.000516734435223043
step: 260, loss: 0.009991518221795559
step: 270, loss: 0.04734472557902336
step: 280, loss: 0.07660005241632462
step: 290, loss: 0.06452888250350952
step: 300, loss: 0.035172250121831894
step: 310, loss: 0.025629788637161255
step: 320, loss: 0.10749317705631256
step: 330, loss: 0.11099312454462051
step: 340, loss: 0.08449534326791763
step: 350, loss: 0.015107673592865467
step: 360, loss: 0.02146226167678833
step: 370, loss: 0.0254325233399868
step: 380, loss: 0.07678047567605972
step: 390, loss: 0.01714986376464367
step: 400, loss: 0.03281527757644653
step: 410, loss: 0.0073788957670331
step: 420, loss: 0.0016086912946775556
epoch 12: dev_f1=0.9910112359550561, f1=0.9831649831649831, best_f1=0.9854423292273236
step: 0, loss: 0.079243965446949
step: 10, loss: 0.026002630591392517
step: 20, loss: 0.011274161748588085
step: 30, loss: 0.01707008108496666
step: 40, loss: 0.036010295152664185
step: 50, loss: 0.00659035611897707
step: 60, loss: 0.024649785831570625
step: 70, loss: 0.00363617530092597
step: 80, loss: 0.061247773468494415
step: 90, loss: 0.01000133901834488
step: 100, loss: 0.018083812668919563
step: 110, loss: 0.038996223360300064
step: 120, loss: 0.002392177004367113
step: 130, loss: 0.008113304153084755
step: 140, loss: 0.1148371770977974
step: 150, loss: 0.0007900362834334373
step: 160, loss: 0.13178406655788422
step: 170, loss: 0.02623319998383522
step: 180, loss: 0.09621044993400574
step: 190, loss: 0.08496389538049698
step: 200, loss: 0.05659317970275879
step: 210, loss: 0.002403679070994258
step: 220, loss: 0.0020954529754817486
step: 230, loss: 0.012577999383211136
step: 240, loss: 0.034921564161777496
step: 250, loss: 0.005737653002142906
step: 260, loss: 0.024911075830459595
step: 270, loss: 0.04608104005455971
step: 280, loss: 0.029698027297854424
step: 290, loss: 0.055322784930467606
step: 300, loss: 0.06612440943717957
step: 310, loss: 0.008033803664147854
step: 320, loss: 0.0547109954059124
step: 330, loss: 0.01932360976934433
step: 340, loss: 0.027639152482151985
step: 350, loss: 0.02636948600411415
step: 360, loss: 0.01110081933438778
step: 370, loss: 0.000933201692532748
step: 380, loss: 0.015461135655641556
step: 390, loss: 0.10476452857255936
step: 400, loss: 0.05319325253367424
step: 410, loss: 0.05439842492341995
step: 420, loss: 0.02484986186027527
epoch 13: dev_f1=0.9921436588103255, f1=0.983277591973244, best_f1=0.9854423292273236
step: 0, loss: 0.03622337058186531
step: 10, loss: 0.019955525174736977
step: 20, loss: 0.02390064112842083
step: 30, loss: 0.022992990911006927
step: 40, loss: 0.026439541950821877
step: 50, loss: 0.028386389836668968
step: 60, loss: 0.0005656566936522722
step: 70, loss: 0.05626263841986656
step: 80, loss: 0.02803349867463112
step: 90, loss: 0.13967181742191315
step: 100, loss: 0.04232780262827873
step: 110, loss: 0.0011746007949113846
step: 120, loss: 0.006981407292187214
step: 130, loss: 0.03522303327918053
step: 140, loss: 0.07620317488908768
step: 150, loss: 0.024449320510029793
step: 160, loss: 0.012475907802581787
step: 170, loss: 0.029358627274632454
step: 180, loss: 2.8239242965355515e-05
step: 190, loss: 0.02287975884974003
step: 200, loss: 0.03005971387028694
step: 210, loss: 0.016130683943629265
step: 220, loss: 0.0704784020781517
step: 230, loss: 0.14653195440769196
step: 240, loss: 0.0006243512616492808
step: 250, loss: 0.14548055827617645
step: 260, loss: 0.0025538902264088392
step: 270, loss: 0.021943122148513794
step: 280, loss: 0.05666172504425049
step: 290, loss: 0.0026387148536741734
step: 300, loss: 0.0017274899873882532
step: 310, loss: 0.09180539101362228
step: 320, loss: 0.05053027719259262
step: 330, loss: 0.036060068756341934
step: 340, loss: 0.008060101419687271
step: 350, loss: 1.2032580343657173e-05
step: 360, loss: 0.034047406166791916
step: 370, loss: 0.03575460612773895
step: 380, loss: 0.02710122801363468
step: 390, loss: 0.0587935671210289
step: 400, loss: 0.005506929010152817
step: 410, loss: 0.0742599219083786
step: 420, loss: 0.03964148834347725
epoch 14: dev_f1=0.990990990990991, f1=0.9798206278026906, best_f1=0.9854423292273236
step: 0, loss: 0.059368930757045746
step: 10, loss: 0.02743314951658249
step: 20, loss: 0.04905042424798012
step: 30, loss: 0.023210158571600914
step: 40, loss: 0.07149557024240494
step: 50, loss: 0.004217356909066439
step: 60, loss: 0.02131909690797329
step: 70, loss: 9.794317884370685e-05
step: 80, loss: 0.044029660522937775
step: 90, loss: 0.055699121206998825
step: 100, loss: 1.1138434274471365e-05
step: 110, loss: 0.022877221927046776
step: 120, loss: 0.056722912937402725
step: 130, loss: 0.15368157625198364
step: 140, loss: 0.063001349568367
step: 150, loss: 0.01727466471493244
step: 160, loss: 0.04603041335940361
step: 170, loss: 0.0477207787334919
step: 180, loss: 0.0004621917032636702
step: 190, loss: 0.001097964821383357
step: 200, loss: 0.0508795864880085
step: 210, loss: 0.0003574918082449585
step: 220, loss: 0.01180948968976736
step: 230, loss: 0.021740224212408066
step: 240, loss: 0.0017521929694339633
step: 250, loss: 0.06089162081480026
step: 260, loss: 0.11641567945480347
step: 270, loss: 0.06270690262317657
step: 280, loss: 0.001664300449192524
step: 290, loss: 0.0004697587282862514
step: 300, loss: 0.0010157584911212325
step: 310, loss: 0.0012291745515540242
step: 320, loss: 0.0336422435939312
step: 330, loss: 0.005338669754564762
step: 340, loss: 0.04204944521188736
step: 350, loss: 0.09488394111394882
step: 360, loss: 0.023576896637678146
step: 370, loss: 0.052696503698825836
step: 380, loss: 0.04978946968913078
step: 390, loss: 0.0003831098147202283
step: 400, loss: 0.03969847783446312
step: 410, loss: 0.04137841984629631
step: 420, loss: 0.004184111952781677
epoch 15: dev_f1=0.9932735426008968, f1=0.9844444444444443, best_f1=0.9854423292273236
step: 0, loss: 0.044046927243471146
step: 10, loss: 0.032971739768981934
step: 20, loss: 0.007670533377677202
step: 30, loss: 0.021948734298348427
step: 40, loss: 0.00011142029688926414
step: 50, loss: 0.07375560700893402
step: 60, loss: 0.015974171459674835
step: 70, loss: 0.01958838291466236
step: 80, loss: 0.0345458947122097
step: 90, loss: 0.0002775183238554746
step: 100, loss: 0.0035064618568867445
step: 110, loss: 0.040129806846380234
step: 120, loss: 0.0613410621881485
step: 130, loss: 0.013054680079221725
step: 140, loss: 0.03151609003543854
step: 150, loss: 0.03428762033581734
step: 160, loss: 0.05378518998622894
step: 170, loss: 0.0016637584194540977
step: 180, loss: 0.0694592297077179
step: 190, loss: 0.01504326518625021
step: 200, loss: 0.042863134294748306
step: 210, loss: 0.016026703640818596
step: 220, loss: 0.04573018476366997
step: 230, loss: 0.020455872640013695
step: 240, loss: 0.02489277720451355
step: 250, loss: 0.02167200669646263
step: 260, loss: 0.06472434103488922
step: 270, loss: 0.03645298629999161
step: 280, loss: 0.05672367662191391
step: 290, loss: 0.00024873128859326243
step: 300, loss: 0.0001859311742009595
step: 310, loss: 0.0010864691575989127
step: 320, loss: 0.03611643239855766
step: 330, loss: 0.005275164730846882
step: 340, loss: 0.024493487551808357
step: 350, loss: 0.028796663507819176
step: 360, loss: 0.029224395751953125
step: 370, loss: 0.0001698649430181831
step: 380, loss: 0.03136369585990906
step: 390, loss: 0.04395454004406929
step: 400, loss: 0.04353823512792587
step: 410, loss: 0.022355524823069572
step: 420, loss: 0.022920355200767517
epoch 16: dev_f1=0.9932432432432432, f1=0.9820224719101124, best_f1=0.9854423292273236
step: 0, loss: 0.0696498453617096
step: 10, loss: 0.028432240709662437
step: 20, loss: 0.02352849394083023
step: 30, loss: 0.03455590829253197
step: 40, loss: 0.022320805117487907
step: 50, loss: 0.0694819837808609
step: 60, loss: 0.014972023665904999
step: 70, loss: 0.01983211189508438
step: 80, loss: 0.050985101610422134
step: 90, loss: 0.021444203332066536
step: 100, loss: 0.0028085100930184126
step: 110, loss: 0.026743946596980095
step: 120, loss: 0.05988139286637306
step: 130, loss: 0.02623724192380905
step: 140, loss: 0.032307133078575134
step: 150, loss: 0.03083835355937481
step: 160, loss: 0.09798704087734222
step: 170, loss: 0.0023333546705543995
step: 180, loss: 0.03295336291193962
step: 190, loss: 0.04494711756706238
step: 200, loss: 0.0297835823148489
step: 210, loss: 0.005453847348690033
step: 220, loss: 0.00099513481836766
step: 230, loss: 0.0328596793115139
step: 240, loss: 0.00018050623475573957
step: 250, loss: 0.002332146745175123
step: 260, loss: 0.0002525603922549635
step: 270, loss: 0.00036009831819683313
step: 280, loss: 0.0845339223742485
step: 290, loss: 0.06890376657247543
step: 300, loss: 0.04361473396420479
step: 310, loss: 0.006758247967809439
step: 320, loss: 0.0010428376263007522
step: 330, loss: 0.05864131450653076
step: 340, loss: 0.012842356227338314
step: 350, loss: 0.04430107772350311
step: 360, loss: 0.0439286045730114
step: 370, loss: 0.04755166545510292
step: 380, loss: 0.0016282248543575406
step: 390, loss: 0.00010610146273393184
step: 400, loss: 0.030216429382562637
step: 410, loss: 0.025864427909255028
step: 420, loss: 0.10179772973060608
epoch 17: dev_f1=0.9932432432432432, f1=0.9820224719101124, best_f1=0.9854423292273236
step: 0, loss: 0.03536227345466614
step: 10, loss: 0.015922535210847855
step: 20, loss: 0.040262553840875626
step: 30, loss: 0.008869153447449207
step: 40, loss: 0.030834443867206573
step: 50, loss: 0.00019606099522206932
step: 60, loss: 0.08311803638935089
step: 70, loss: 0.021839769557118416
step: 80, loss: 0.000516687345225364
step: 90, loss: 0.021176937967538834
step: 100, loss: 0.02674155868589878
step: 110, loss: 0.038513194769620895
step: 120, loss: 0.00279399286955595
step: 130, loss: 0.034267354756593704
step: 140, loss: 0.03684183210134506
step: 150, loss: 0.02186460606753826
step: 160, loss: 0.026695359498262405
step: 170, loss: 3.355033550178632e-05
step: 180, loss: 0.020816205069422722
step: 190, loss: 0.00012780529505107552
step: 200, loss: 0.07936012744903564
step: 210, loss: 0.043858714401721954
step: 220, loss: 0.009639326483011246
step: 230, loss: 0.08169209957122803
step: 240, loss: 0.000717728107701987
step: 250, loss: 0.0210416279733181
step: 260, loss: 0.00011900408571818843
step: 270, loss: 0.04389387369155884
step: 280, loss: 0.04304710775613785
step: 290, loss: 0.015131820924580097
step: 300, loss: 0.02408864162862301
step: 310, loss: 0.03179053217172623
step: 320, loss: 0.00016740438877604902
step: 330, loss: 0.02085275575518608
step: 340, loss: 0.06797908991575241
step: 350, loss: 0.05620483309030533
step: 360, loss: 0.00041362360934726894
step: 370, loss: 0.028799083083868027
step: 380, loss: 0.018830308690667152
step: 390, loss: 0.011994301341474056
step: 400, loss: 0.027837557718157768
step: 410, loss: 0.032060977071523666
step: 420, loss: 0.0034439810551702976
epoch 18: dev_f1=0.9932432432432432, f1=0.9820224719101124, best_f1=0.9854423292273236
step: 0, loss: 0.0188154149800539
step: 10, loss: 0.034606654196977615
step: 20, loss: 0.02737363614141941
step: 30, loss: 0.051292773336172104
step: 40, loss: 6.349277828121558e-05
step: 50, loss: 1.3261890671856236e-05
step: 60, loss: 0.03258195519447327
step: 70, loss: 0.08808989077806473
step: 80, loss: 0.00014163064770400524
step: 90, loss: 0.09013819694519043
step: 100, loss: 0.035947833210229874
step: 110, loss: 0.0211596991866827
step: 120, loss: 0.04026632755994797
step: 130, loss: 0.01620793528854847
step: 140, loss: 0.0003639414790086448
step: 150, loss: 0.0001313387620029971
step: 160, loss: 0.11709611117839813
step: 170, loss: 0.0585927851498127
step: 180, loss: 0.0002055493969237432
step: 190, loss: 0.025963973253965378
step: 200, loss: 0.02067914605140686
step: 210, loss: 0.0010590368183329701
step: 220, loss: 0.04103983938694
step: 230, loss: 0.07072301208972931
step: 240, loss: 0.04161599278450012
step: 250, loss: 0.0012957240687683225
step: 260, loss: 0.0027499948628246784
step: 270, loss: 8.388451533392072e-05
step: 280, loss: 0.052639324218034744
step: 290, loss: 0.00016654719365760684
step: 300, loss: 0.02241949364542961
step: 310, loss: 0.04321853816509247
step: 320, loss: 0.012982632033526897
step: 330, loss: 0.02508329041302204
step: 340, loss: 0.03287610784173012
step: 350, loss: 6.488466169685125e-05
step: 360, loss: 0.04029609635472298
step: 370, loss: 0.0229441300034523
step: 380, loss: 0.041799284517765045
step: 390, loss: 0.00015218487533275038
step: 400, loss: 0.04062611237168312
step: 410, loss: 0.026651713997125626
step: 420, loss: 0.0245047714561224
epoch 19: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9854423292273236
step: 0, loss: 0.00017764560470823199
step: 10, loss: 0.027723385021090508
step: 20, loss: 0.07949576526880264
step: 30, loss: 0.018381601199507713
step: 40, loss: 0.06938021630048752
step: 50, loss: 0.02349086105823517
step: 60, loss: 0.0021913147065788507
step: 70, loss: 0.014019639231264591
step: 80, loss: 0.019616123288869858
step: 90, loss: 0.07377780973911285
step: 100, loss: 0.03291437402367592
step: 110, loss: 0.02441156841814518
step: 120, loss: 0.0001690741628408432
step: 130, loss: 0.00012159493053331971
step: 140, loss: 0.022359689697623253
step: 150, loss: 0.0001309381623286754
step: 160, loss: 0.016462627798318863
step: 170, loss: 0.025762978941202164
step: 180, loss: 0.0733182430267334
step: 190, loss: 0.03305939957499504
step: 200, loss: 0.03406498581171036
step: 210, loss: 0.05831592157483101
step: 220, loss: 0.06075357645750046
step: 230, loss: 0.021672770380973816
step: 240, loss: 0.03283974900841713
step: 250, loss: 0.021185310557484627
step: 260, loss: 0.023154810070991516
step: 270, loss: 0.00011971439380431548
step: 280, loss: 0.0005123374867253006
step: 290, loss: 0.043362658470869064
step: 300, loss: 0.029411112889647484
step: 310, loss: 0.00029344376525841653
step: 320, loss: 0.019041994586586952
step: 330, loss: 0.016694391146302223
step: 340, loss: 7.467482646461576e-05
step: 350, loss: 0.00012051159865222871
step: 360, loss: 0.04463864117860794
step: 370, loss: 0.012728418223559856
step: 380, loss: 0.022374046966433525
step: 390, loss: 0.02576964907348156
step: 400, loss: 0.00016916764434427023
step: 410, loss: 0.00015544620691798627
step: 420, loss: 0.028544533997774124
epoch 20: dev_f1=0.9932432432432432, f1=0.9820224719101124, best_f1=0.9854423292273236
