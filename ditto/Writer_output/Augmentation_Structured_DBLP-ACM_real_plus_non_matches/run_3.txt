cuda
Device: cuda
step: 0, loss: 0.9776890873908997
step: 10, loss: 0.30360937118530273
step: 20, loss: 0.3346250653266907
step: 30, loss: 0.4995644986629486
step: 40, loss: 0.2735329568386078
step: 50, loss: 0.15348359942436218
step: 60, loss: 0.11257931590080261
step: 70, loss: 0.22316433489322662
step: 80, loss: 0.07426808774471283
step: 90, loss: 0.06823210418224335
step: 100, loss: 0.05713168531656265
step: 110, loss: 0.10413249582052231
step: 120, loss: 0.13326559960842133
step: 130, loss: 0.08149120956659317
step: 140, loss: 0.056842900812625885
step: 150, loss: 0.0941523090004921
step: 160, loss: 0.07852461189031601
step: 170, loss: 0.13180992007255554
step: 180, loss: 0.25498613715171814
step: 190, loss: 0.06111319735646248
step: 200, loss: 0.09613074362277985
step: 210, loss: 0.12362541258335114
step: 220, loss: 0.19904360175132751
step: 230, loss: 0.16016285121440887
step: 240, loss: 0.17771795392036438
step: 250, loss: 0.008887702599167824
step: 260, loss: 0.08785353600978851
step: 270, loss: 0.23297740519046783
step: 280, loss: 0.07482670247554779
step: 290, loss: 0.054902393370866776
step: 300, loss: 0.11429951339960098
step: 310, loss: 0.05600900575518608
step: 320, loss: 0.15678223967552185
step: 330, loss: 0.0957268476486206
step: 340, loss: 0.03674828261137009
step: 350, loss: 0.00647170701995492
step: 360, loss: 0.0796705111861229
step: 370, loss: 0.12359139323234558
step: 380, loss: 0.06582967191934586
step: 390, loss: 0.01176594290882349
step: 400, loss: 0.07058963924646378
step: 410, loss: 0.08683523535728455
step: 420, loss: 0.028328537940979004
epoch 1: dev_f1=0.9865771812080537, f1=0.9786276715410572, best_f1=0.9786276715410572
step: 0, loss: 0.08869591355323792
step: 10, loss: 0.07790548354387283
step: 20, loss: 0.018249448388814926
step: 30, loss: 0.005558778531849384
step: 40, loss: 0.02591206505894661
step: 50, loss: 0.013752453960478306
step: 60, loss: 0.02740752324461937
step: 70, loss: 0.1105104312300682
step: 80, loss: 0.10903199017047882
step: 90, loss: 0.05666366592049599
step: 100, loss: 0.04305700957775116
step: 110, loss: 0.02391095459461212
step: 120, loss: 0.08863478153944016
step: 130, loss: 0.047344889491796494
step: 140, loss: 0.16270092129707336
step: 150, loss: 0.0987817794084549
step: 160, loss: 0.060703519731760025
step: 170, loss: 0.06154773011803627
step: 180, loss: 0.10645334422588348
step: 190, loss: 0.012296793051064014
step: 200, loss: 0.06999753415584564
step: 210, loss: 0.02404281497001648
step: 220, loss: 0.2503170073032379
step: 230, loss: 0.12989996373653412
step: 240, loss: 0.06007831543684006
step: 250, loss: 0.13293366134166718
step: 260, loss: 0.040498536080121994
step: 270, loss: 0.06846161186695099
step: 280, loss: 0.08690325915813446
step: 290, loss: 0.10610169917345047
step: 300, loss: 0.07841011881828308
step: 310, loss: 0.12772627174854279
step: 320, loss: 0.01273335237056017
step: 330, loss: 0.06829401105642319
step: 340, loss: 0.024634001776576042
step: 350, loss: 0.07820665091276169
step: 360, loss: 0.08809355646371841
step: 370, loss: 0.012556716799736023
step: 380, loss: 0.06724870949983597
step: 390, loss: 0.0854637548327446
step: 400, loss: 0.024487817659974098
step: 410, loss: 0.01079049613326788
step: 420, loss: 0.01148916408419609
epoch 2: dev_f1=0.992108229988726, f1=0.9819004524886877, best_f1=0.9819004524886877
step: 0, loss: 0.015718255192041397
step: 10, loss: 0.07827600091695786
step: 20, loss: 0.013849792070686817
step: 30, loss: 0.020880792289972305
step: 40, loss: 0.07356967031955719
step: 50, loss: 0.06698635965585709
step: 60, loss: 0.06405472010374069
step: 70, loss: 0.08472268283367157
step: 80, loss: 0.07910725474357605
step: 90, loss: 0.09488172829151154
step: 100, loss: 0.030198128893971443
step: 110, loss: 0.00013873619900550693
step: 120, loss: 0.19141854345798492
step: 130, loss: 0.006559679284691811
step: 140, loss: 0.005624122451990843
step: 150, loss: 0.044351860880851746
step: 160, loss: 0.015848422423005104
step: 170, loss: 0.06324957311153412
step: 180, loss: 0.028441358357667923
step: 190, loss: 0.021845638751983643
step: 200, loss: 0.009919347241520882
step: 210, loss: 0.09852351993322372
step: 220, loss: 0.0857824832201004
step: 230, loss: 0.023302674293518066
step: 240, loss: 0.06392019987106323
step: 250, loss: 0.009233578108251095
step: 260, loss: 0.02446594275534153
step: 270, loss: 0.06728263199329376
step: 280, loss: 0.022447960451245308
step: 290, loss: 0.004193305969238281
step: 300, loss: 0.017947053536772728
step: 310, loss: 0.1315222531557083
step: 320, loss: 0.042648281902074814
step: 330, loss: 0.036833085119724274
step: 340, loss: 0.12380809336900711
step: 350, loss: 0.17780600488185883
step: 360, loss: 0.03674638643860817
step: 370, loss: 0.07738152146339417
step: 380, loss: 0.011725897900760174
step: 390, loss: 0.0740412250161171
step: 400, loss: 0.04775193706154823
step: 410, loss: 0.13048961758613586
step: 420, loss: 0.033107396215200424
epoch 3: dev_f1=0.9921436588103255, f1=0.9821029082774049, best_f1=0.9821029082774049
step: 0, loss: 0.020815392956137657
step: 10, loss: 0.09729728102684021
step: 20, loss: 0.03617280349135399
step: 30, loss: 0.21178339421749115
step: 40, loss: 0.02610507793724537
step: 50, loss: 0.014073599129915237
step: 60, loss: 0.02376762218773365
step: 70, loss: 0.019994111731648445
step: 80, loss: 0.14134655892848969
step: 90, loss: 0.1161286011338234
step: 100, loss: 0.1378035992383957
step: 110, loss: 0.026284851133823395
step: 120, loss: 0.0438503734767437
step: 130, loss: 0.0702705979347229
step: 140, loss: 0.09992515295743942
step: 150, loss: 0.062046848237514496
step: 160, loss: 0.017119769006967545
step: 170, loss: 0.0048217810690402985
step: 180, loss: 0.011868705973029137
step: 190, loss: 0.010351304896175861
step: 200, loss: 0.03177650272846222
step: 210, loss: 0.042545221745967865
step: 220, loss: 0.009442364796996117
step: 230, loss: 0.009399369359016418
step: 240, loss: 0.01460221130400896
step: 250, loss: 0.05762311443686485
step: 260, loss: 0.07575617730617523
step: 270, loss: 0.01407292764633894
step: 280, loss: 0.04580806568264961
step: 290, loss: 0.06635261327028275
step: 300, loss: 0.17589503526687622
step: 310, loss: 0.021770989522337914
step: 320, loss: 0.09247660636901855
step: 330, loss: 0.029092198237776756
step: 340, loss: 0.024998802691698074
step: 350, loss: 4.336504207458347e-05
step: 360, loss: 0.020479567348957062
step: 370, loss: 0.07799841463565826
step: 380, loss: 0.06977389752864838
step: 390, loss: 0.020938223227858543
step: 400, loss: 0.012826487421989441
step: 410, loss: 0.11985998600721359
step: 420, loss: 0.06479285657405853
epoch 4: dev_f1=0.9899216125419933, f1=0.980963045912654, best_f1=0.9821029082774049
step: 0, loss: 0.05924949049949646
step: 10, loss: 0.07288660109043121
step: 20, loss: 0.060816679149866104
step: 30, loss: 0.011062201112508774
step: 40, loss: 0.011419756338000298
step: 50, loss: 0.02557968907058239
step: 60, loss: 0.05930313467979431
step: 70, loss: 0.03529972955584526
step: 80, loss: 0.12373334169387817
step: 90, loss: 0.06507224589586258
step: 100, loss: 0.11295877397060394
step: 110, loss: 0.10835765302181244
step: 120, loss: 0.0581817589700222
step: 130, loss: 0.08706523478031158
step: 140, loss: 0.09548946470022202
step: 150, loss: 0.07937128841876984
step: 160, loss: 0.0678558424115181
step: 170, loss: 0.14045517146587372
step: 180, loss: 2.1673471565009095e-05
step: 190, loss: 0.06991389393806458
step: 200, loss: 0.005968756042420864
step: 210, loss: 0.1390615552663803
step: 220, loss: 0.026758309453725815
step: 230, loss: 0.0727270245552063
step: 240, loss: 0.029214419424533844
step: 250, loss: 0.006776038091629744
step: 260, loss: 0.06807954609394073
step: 270, loss: 0.08928130567073822
step: 280, loss: 0.0153926657512784
step: 290, loss: 0.08973344415426254
step: 300, loss: 0.08011458069086075
step: 310, loss: 0.04215623438358307
step: 320, loss: 0.08200141787528992
step: 330, loss: 0.08486796170473099
step: 340, loss: 0.1194089725613594
step: 350, loss: 0.15024122595787048
step: 360, loss: 0.017291493713855743
step: 370, loss: 0.01893565058708191
step: 380, loss: 0.06436585634946823
step: 390, loss: 0.02006997913122177
step: 400, loss: 0.09229520708322525
step: 410, loss: 0.03565638139843941
step: 420, loss: 0.17990587651729584
epoch 5: dev_f1=0.9909706546275394, f1=0.9808342728297633, best_f1=0.9821029082774049
step: 0, loss: 0.07416848838329315
step: 10, loss: 0.013894226402044296
step: 20, loss: 0.10535669326782227
step: 30, loss: 0.0857636034488678
step: 40, loss: 0.00018982724577654153
step: 50, loss: 0.0630926862359047
step: 60, loss: 0.010198863223195076
step: 70, loss: 0.005137781146913767
step: 80, loss: 0.14596684277057648
step: 90, loss: 0.06063706427812576
step: 100, loss: 0.023777814581990242
step: 110, loss: 0.010366742499172688
step: 120, loss: 0.010647655464708805
step: 130, loss: 0.0072157178074121475
step: 140, loss: 0.13681010901927948
step: 150, loss: 0.01937737688422203
step: 160, loss: 0.06694846600294113
step: 170, loss: 0.020959703251719475
step: 180, loss: 0.08144190907478333
step: 190, loss: 0.18884488940238953
step: 200, loss: 0.024484921246767044
step: 210, loss: 0.03677419200539589
step: 220, loss: 0.08211474865674973
step: 230, loss: 0.11248424649238586
step: 240, loss: 0.02545417845249176
step: 250, loss: 0.07083270698785782
step: 260, loss: 0.07873301208019257
step: 270, loss: 0.022881032899022102
step: 280, loss: 0.06453143805265427
step: 290, loss: 0.008724255487322807
step: 300, loss: 0.07047345489263535
step: 310, loss: 0.027547303587198257
step: 320, loss: 0.020796814933419228
step: 330, loss: 0.08426841348409653
step: 340, loss: 0.021259868517518044
step: 350, loss: 0.04068847745656967
step: 360, loss: 0.05488019436597824
step: 370, loss: 0.06482856720685959
step: 380, loss: 0.07589877396821976
step: 390, loss: 0.0630747526884079
step: 400, loss: 0.17165334522724152
step: 410, loss: 0.011842681095004082
step: 420, loss: 0.02002660185098648
epoch 6: dev_f1=0.9921259842519685, f1=0.9832402234636871, best_f1=0.9821029082774049
step: 0, loss: 0.004935103934258223
step: 10, loss: 0.01237571518868208
step: 20, loss: 0.022617630660533905
step: 30, loss: 0.15294887125492096
step: 40, loss: 0.0914226695895195
step: 50, loss: 0.045167360454797745
step: 60, loss: 0.07649647444486618
step: 70, loss: 2.5279239707742818e-05
step: 80, loss: 0.056422505527734756
step: 90, loss: 0.0707181766629219
step: 100, loss: 0.08223669975996017
step: 110, loss: 0.01703924685716629
step: 120, loss: 0.004069179762154818
step: 130, loss: 0.027773283421993256
step: 140, loss: 0.033837009221315384
step: 150, loss: 0.037441741675138474
step: 160, loss: 0.0475410558283329
step: 170, loss: 0.012498337775468826
step: 180, loss: 0.1280364692211151
step: 190, loss: 0.06190318986773491
step: 200, loss: 0.07158146053552628
step: 210, loss: 0.013005631975829601
step: 220, loss: 0.08421368896961212
step: 230, loss: 0.06459377706050873
step: 240, loss: 0.01716393604874611
step: 250, loss: 0.06308826804161072
step: 260, loss: 0.06087479367852211
step: 270, loss: 0.03855687752366066
step: 280, loss: 2.4031529392232187e-05
step: 290, loss: 0.01559507753700018
step: 300, loss: 0.06117534264922142
step: 310, loss: 3.6759891372639686e-05
step: 320, loss: 0.007271818816661835
step: 330, loss: 0.01747295632958412
step: 340, loss: 0.03241139277815819
step: 350, loss: 0.08438492566347122
step: 360, loss: 0.1389259248971939
step: 370, loss: 0.16168028116226196
step: 380, loss: 0.05909543111920357
step: 390, loss: 0.02661832422018051
step: 400, loss: 0.05148639529943466
step: 410, loss: 0.0945182740688324
step: 420, loss: 0.12656337022781372
epoch 7: dev_f1=0.9898762654668166, f1=0.9854748603351955, best_f1=0.9821029082774049
step: 0, loss: 0.0011439028894528747
step: 10, loss: 0.012125981040298939
step: 20, loss: 0.0629880353808403
step: 30, loss: 0.04173165559768677
step: 40, loss: 0.012305358424782753
step: 50, loss: 0.0543738417327404
step: 60, loss: 0.06835657358169556
step: 70, loss: 0.06495732814073563
step: 80, loss: 0.11356276273727417
step: 90, loss: 0.05954335257411003
step: 100, loss: 2.337214391445741e-05
step: 110, loss: 0.10668259859085083
step: 120, loss: 0.059594862163066864
step: 130, loss: 0.011378191411495209
step: 140, loss: 0.014995960518717766
step: 150, loss: 0.04185134917497635
step: 160, loss: 4.131624154979363e-05
step: 170, loss: 0.087315633893013
step: 180, loss: 0.009647410362958908
step: 190, loss: 0.1307578980922699
step: 200, loss: 0.015648290514945984
step: 210, loss: 0.057119086384773254
step: 220, loss: 0.009152451530098915
step: 230, loss: 0.021101802587509155
step: 240, loss: 0.09791524708271027
step: 250, loss: 0.09399215877056122
step: 260, loss: 0.1617506891489029
step: 270, loss: 0.019689586013555527
step: 280, loss: 0.018231499940156937
step: 290, loss: 0.020462796092033386
step: 300, loss: 0.057389747351408005
step: 310, loss: 0.07620850950479507
step: 320, loss: 0.0715392455458641
step: 330, loss: 0.017379939556121826
step: 340, loss: 0.014469808898866177
step: 350, loss: 0.05982840806245804
step: 360, loss: 0.012583699077367783
step: 370, loss: 0.0495745949447155
step: 380, loss: 0.04040130600333214
step: 390, loss: 0.06452272087335587
step: 400, loss: 0.023708684369921684
step: 410, loss: 0.022559598088264465
step: 420, loss: 0.025930527597665787
epoch 8: dev_f1=0.990990990990991, f1=0.9832026875699889, best_f1=0.9821029082774049
step: 0, loss: 0.061388660222291946
step: 10, loss: 0.02379235252737999
step: 20, loss: 0.06875484436750412
step: 30, loss: 0.11811468750238419
step: 40, loss: 0.022015396505594254
step: 50, loss: 0.055053118616342545
step: 60, loss: 0.006774472538381815
step: 70, loss: 0.009053964167833328
step: 80, loss: 0.0161975659430027
step: 90, loss: 0.019634680822491646
step: 100, loss: 0.01413063332438469
step: 110, loss: 0.016523417085409164
step: 120, loss: 0.06557613611221313
step: 130, loss: 0.05402854084968567
step: 140, loss: 0.014885269105434418
step: 150, loss: 0.05244716256856918
step: 160, loss: 0.05708630383014679
step: 170, loss: 0.10764778405427933
step: 180, loss: 0.10567163676023483
step: 190, loss: 0.019847322255373
step: 200, loss: 0.06640277802944183
step: 210, loss: 0.07564490288496017
step: 220, loss: 0.004510314203798771
step: 230, loss: 0.10312646627426147
step: 240, loss: 0.05806086212396622
step: 250, loss: 0.032050665467977524
step: 260, loss: 0.0016435682773590088
step: 270, loss: 0.03853616490960121
step: 280, loss: 0.0018556485883891582
step: 290, loss: 0.005512317176908255
step: 300, loss: 0.028616193681955338
step: 310, loss: 0.06577610969543457
step: 320, loss: 0.07973062247037888
step: 330, loss: 0.004270479083061218
step: 340, loss: 0.0021910276263952255
step: 350, loss: 0.03788609430193901
step: 360, loss: 0.16325418651103973
step: 370, loss: 0.03365722671151161
step: 380, loss: 0.041043803095817566
step: 390, loss: 0.08611278980970383
step: 400, loss: 0.036888036876916885
step: 410, loss: 0.07230313867330551
step: 420, loss: 0.07780986279249191
epoch 9: dev_f1=0.9932735426008968, f1=0.983277591973244, best_f1=0.983277591973244
step: 0, loss: 0.05234518274664879
step: 10, loss: 0.010530907660722733
step: 20, loss: 0.0038740430027246475
step: 30, loss: 0.006063051056116819
step: 40, loss: 0.04940307140350342
step: 50, loss: 0.01386108435690403
step: 60, loss: 0.056397754698991776
step: 70, loss: 0.006159926764667034
step: 80, loss: 0.011086308397352695
step: 90, loss: 0.016245782375335693
step: 100, loss: 0.06171765178442001
step: 110, loss: 0.005052604712545872
step: 120, loss: 0.00761725939810276
step: 130, loss: 0.05196751281619072
step: 140, loss: 0.044919904321432114
step: 150, loss: 0.03543715178966522
step: 160, loss: 0.02978670597076416
step: 170, loss: 0.007534104399383068
step: 180, loss: 0.06771574169397354
step: 190, loss: 0.0941544845700264
step: 200, loss: 0.05368657037615776
step: 210, loss: 0.03443055972456932
step: 220, loss: 0.00897261779755354
step: 230, loss: 0.00650485884398222
step: 240, loss: 0.04754774272441864
step: 250, loss: 0.05955926701426506
step: 260, loss: 0.030201375484466553
step: 270, loss: 0.04139663651585579
step: 280, loss: 0.01381534244865179
step: 290, loss: 0.025378786027431488
step: 300, loss: 0.09370315074920654
step: 310, loss: 0.014986549504101276
step: 320, loss: 0.10459540039300919
step: 330, loss: 0.00438035698607564
step: 340, loss: 0.0010214097565039992
step: 350, loss: 0.0060335202142596245
step: 360, loss: 0.009833799675107002
step: 370, loss: 0.003911335486918688
step: 380, loss: 0.0612795315682888
step: 390, loss: 0.15920616686344147
step: 400, loss: 0.02024119161069393
step: 410, loss: 0.01796269416809082
step: 420, loss: 0.0007519085193052888
epoch 10: dev_f1=0.9909706546275394, f1=0.9854096520763187, best_f1=0.983277591973244
step: 0, loss: 0.002928239293396473
step: 10, loss: 0.008326110430061817
step: 20, loss: 0.014917008578777313
step: 30, loss: 0.047030262649059296
step: 40, loss: 1.6197220247704536e-05
step: 50, loss: 0.03466052934527397
step: 60, loss: 0.0024673715233802795
step: 70, loss: 0.0649304911494255
step: 80, loss: 0.054144371300935745
step: 90, loss: 0.033263228833675385
step: 100, loss: 0.06916101276874542
step: 110, loss: 0.04349398985505104
step: 120, loss: 0.021246924996376038
step: 130, loss: 0.00143431406468153
step: 140, loss: 0.09983270615339279
step: 150, loss: 0.06430472433567047
step: 160, loss: 0.04716700688004494
step: 170, loss: 0.003889098297804594
step: 180, loss: 0.03473924100399017
step: 190, loss: 0.006420306861400604
step: 200, loss: 0.017772214487195015
step: 210, loss: 0.001327958540059626
step: 220, loss: 0.0008009554003365338
step: 230, loss: 0.009411212056875229
step: 240, loss: 0.011708781123161316
step: 250, loss: 0.07690784335136414
step: 260, loss: 0.021051719784736633
step: 270, loss: 0.021973315626382828
step: 280, loss: 0.016749273985624313
step: 290, loss: 0.048493582755327225
step: 300, loss: 0.1525600701570511
step: 310, loss: 0.01694238744676113
step: 320, loss: 0.00786056462675333
step: 330, loss: 0.06659533083438873
step: 340, loss: 0.019965197890996933
step: 350, loss: 0.1137235090136528
step: 360, loss: 0.012240302748978138
step: 370, loss: 0.035141002386808395
step: 380, loss: 0.0175878144800663
step: 390, loss: 0.06934495270252228
step: 400, loss: 0.07497089356184006
step: 410, loss: 0.034104082733392715
step: 420, loss: 0.04582012817263603
epoch 11: dev_f1=0.9898534385569334, f1=0.9831271091113611, best_f1=0.983277591973244
step: 0, loss: 0.021997205913066864
step: 10, loss: 0.06863760203123093
step: 20, loss: 0.08359720557928085
step: 30, loss: 0.07840318977832794
step: 40, loss: 0.00019028462702408433
step: 50, loss: 0.026229169219732285
step: 60, loss: 0.18480101227760315
step: 70, loss: 0.039298150688409805
step: 80, loss: 0.08738818764686584
step: 90, loss: 0.024344485253095627
step: 100, loss: 0.061875827610492706
step: 110, loss: 0.0405321829020977
step: 120, loss: 0.006613242439925671
step: 130, loss: 0.012004880234599113
step: 140, loss: 0.028477292507886887
step: 150, loss: 0.14382261037826538
step: 160, loss: 0.04250263795256615
step: 170, loss: 0.04308084398508072
step: 180, loss: 0.03515009954571724
step: 190, loss: 0.031763385981321335
step: 200, loss: 0.052188850939273834
step: 210, loss: 0.12898707389831543
step: 220, loss: 0.033258628100156784
step: 230, loss: 0.00762986158952117
step: 240, loss: 0.04868895560503006
step: 250, loss: 0.0332503542304039
step: 260, loss: 0.12204461544752121
step: 270, loss: 0.0019037151942029595
step: 280, loss: 0.04905473068356514
step: 290, loss: 0.0724601075053215
step: 300, loss: 0.0160794910043478
step: 310, loss: 0.10784365236759186
step: 320, loss: 0.07221782207489014
step: 330, loss: 0.008999179117381573
step: 340, loss: 0.04030006006360054
step: 350, loss: 0.05145413428544998
step: 360, loss: 0.0716630294919014
step: 370, loss: 0.018507832661271095
step: 380, loss: 0.06003908812999725
step: 390, loss: 0.001627336023375392
step: 400, loss: 0.057760585099458694
step: 410, loss: 0.0035844831727445126
step: 420, loss: 0.07535809278488159
epoch 12: dev_f1=0.992108229988726, f1=0.984304932735426, best_f1=0.983277591973244
step: 0, loss: 0.007333765272051096
step: 10, loss: 0.08031801879405975
step: 20, loss: 0.18242855370044708
step: 30, loss: 0.0011450918391346931
step: 40, loss: 0.0004714449169114232
step: 50, loss: 0.014922873117029667
step: 60, loss: 0.04593143239617348
step: 70, loss: 0.003470060648396611
step: 80, loss: 0.06321338564157486
step: 90, loss: 0.09720290452241898
step: 100, loss: 0.004111072048544884
step: 110, loss: 0.04272603988647461
step: 120, loss: 0.1417771726846695
step: 130, loss: 0.01452092919498682
step: 140, loss: 0.04734480008482933
step: 150, loss: 0.03918635472655296
step: 160, loss: 0.018140779808163643
step: 170, loss: 0.0262176301330328
step: 180, loss: 0.057426147162914276
step: 190, loss: 0.04027137532830238
step: 200, loss: 0.15862825512886047
step: 210, loss: 0.00042258159373886883
step: 220, loss: 0.08363177627325058
step: 230, loss: 0.0037341176066547632
step: 240, loss: 3.3526226616231725e-05
step: 250, loss: 0.0007763861794956028
step: 260, loss: 0.000933644943870604
step: 270, loss: 0.07429656386375427
step: 280, loss: 0.07353983074426651
step: 290, loss: 0.005075544584542513
step: 300, loss: 0.07625315338373184
step: 310, loss: 0.020015355199575424
step: 320, loss: 0.00046195348841138184
step: 330, loss: 4.952296512783505e-05
step: 340, loss: 0.04620518162846565
step: 350, loss: 0.05492190644145012
step: 360, loss: 0.026042236015200615
step: 370, loss: 0.16366855800151825
step: 380, loss: 0.04153024032711983
step: 390, loss: 0.026379374787211418
step: 400, loss: 0.056537456810474396
step: 410, loss: 0.08587311208248138
step: 420, loss: 0.0009109650272876024
epoch 13: dev_f1=0.9921612541993281, f1=0.983277591973244, best_f1=0.983277591973244
step: 0, loss: 0.07862056791782379
step: 10, loss: 0.020257433876395226
step: 20, loss: 0.011724069714546204
step: 30, loss: 0.019100522622466087
step: 40, loss: 0.03474434092640877
step: 50, loss: 0.024280132725834846
step: 60, loss: 0.013120300136506557
step: 70, loss: 9.865793253993616e-05
step: 80, loss: 3.923003168893047e-05
step: 90, loss: 0.03987683728337288
step: 100, loss: 0.04946625232696533
step: 110, loss: 0.021241629496216774
step: 120, loss: 0.04388925060629845
step: 130, loss: 0.026879150420427322
step: 140, loss: 0.06077640503644943
step: 150, loss: 0.019837351515889168
step: 160, loss: 0.021872473880648613
step: 170, loss: 2.768803824437782e-05
step: 180, loss: 0.022758126258850098
step: 190, loss: 0.011024221777915955
step: 200, loss: 0.025332080200314522
step: 210, loss: 0.0004812557599507272
step: 220, loss: 0.0651625245809555
step: 230, loss: 0.019958527758717537
step: 240, loss: 0.0385427363216877
step: 250, loss: 0.051411546766757965
step: 260, loss: 0.021249616518616676
step: 270, loss: 0.030457522720098495
step: 280, loss: 0.0004907877300865948
step: 290, loss: 0.028506146743893623
step: 300, loss: 0.026061855256557465
step: 310, loss: 0.04842075705528259
step: 320, loss: 0.04366602748632431
step: 330, loss: 0.002295313635841012
step: 340, loss: 0.05649367347359657
step: 350, loss: 0.012755819596350193
step: 360, loss: 0.01575472764670849
step: 370, loss: 0.0007510586874559522
step: 380, loss: 0.015044009312987328
step: 390, loss: 0.023653844371438026
step: 400, loss: 0.03465171903371811
step: 410, loss: 0.07431676983833313
step: 420, loss: 0.0001630708429729566
epoch 14: dev_f1=0.9921259842519685, f1=0.9843749999999999, best_f1=0.983277591973244
step: 0, loss: 0.032650139182806015
step: 10, loss: 0.015456370078027248
step: 20, loss: 0.05501065030694008
step: 30, loss: 0.04300924390554428
step: 40, loss: 0.07168228179216385
step: 50, loss: 0.019935354590415955
step: 60, loss: 0.05923932045698166
step: 70, loss: 0.009175747632980347
step: 80, loss: 0.02381267212331295
step: 90, loss: 0.009939604438841343
step: 100, loss: 0.02494007907807827
step: 110, loss: 0.0003249909495934844
step: 120, loss: 0.003571072593331337
step: 130, loss: 0.020344877615571022
step: 140, loss: 0.02812207117676735
step: 150, loss: 0.046902358531951904
step: 160, loss: 0.06210474669933319
step: 170, loss: 0.019189611077308655
step: 180, loss: 0.035914093255996704
step: 190, loss: 0.020517125725746155
step: 200, loss: 0.024184292182326317
step: 210, loss: 2.5930372430593707e-05
step: 220, loss: 0.023212134838104248
step: 230, loss: 0.051215872168540955
step: 240, loss: 0.04949703440070152
step: 250, loss: 0.11688324064016342
step: 260, loss: 1.4543356883223169e-05
step: 270, loss: 0.09851614385843277
step: 280, loss: 0.03402653709053993
step: 290, loss: 0.017839981243014336
step: 300, loss: 0.0277826189994812
step: 310, loss: 0.016459252685308456
step: 320, loss: 0.0010099343489855528
step: 330, loss: 0.02609383501112461
step: 340, loss: 0.00030080994474701583
step: 350, loss: 0.066929891705513
step: 360, loss: 0.020443979650735855
step: 370, loss: 0.1434900164604187
step: 380, loss: 0.01786002703011036
step: 390, loss: 0.1462739259004593
step: 400, loss: 0.020935093984007835
step: 410, loss: 0.024198314175009727
step: 420, loss: 0.02368430607020855
epoch 15: dev_f1=0.992108229988726, f1=0.9843400447427293, best_f1=0.983277591973244
step: 0, loss: 0.00038195165689103305
step: 10, loss: 0.00621284544467926
step: 20, loss: 0.02228591963648796
step: 30, loss: 0.024627933278679848
step: 40, loss: 0.042370863258838654
step: 50, loss: 0.07467783987522125
step: 60, loss: 0.04821845516562462
step: 70, loss: 4.000888657174073e-05
step: 80, loss: 0.02397783473134041
step: 90, loss: 0.00012526981299743056
step: 100, loss: 0.02167823351919651
step: 110, loss: 0.02236778661608696
step: 120, loss: 0.07774736732244492
step: 130, loss: 0.02119889296591282
step: 140, loss: 0.025099582970142365
step: 150, loss: 0.00019742132280953228
step: 160, loss: 5.3726762416772544e-05
step: 170, loss: 0.00020069566380698234
step: 180, loss: 0.00010675313387764618
step: 190, loss: 0.00023526980658061802
step: 200, loss: 0.0003679835645016283
step: 210, loss: 0.00012362629058770835
step: 220, loss: 0.04321151599287987
step: 230, loss: 0.025282656773924828
step: 240, loss: 0.023680249229073524
step: 250, loss: 0.017035793513059616
step: 260, loss: 0.04464830085635185
step: 270, loss: 0.04317484423518181
step: 280, loss: 0.04300738126039505
step: 290, loss: 0.01889600232243538
step: 300, loss: 0.016897553578019142
step: 310, loss: 0.022647462785243988
step: 320, loss: 0.042934734374284744
step: 330, loss: 0.09199580550193787
step: 340, loss: 0.0004708751221187413
step: 350, loss: 0.0009306964348070323
step: 360, loss: 0.019392652437090874
step: 370, loss: 0.00046374654630199075
step: 380, loss: 0.01268836297094822
step: 390, loss: 0.04290330037474632
step: 400, loss: 0.04802129045128822
step: 410, loss: 0.00019792024977505207
step: 420, loss: 0.00491150701418519
epoch 16: dev_f1=0.990990990990991, f1=0.9843749999999999, best_f1=0.983277591973244
step: 0, loss: 0.05002201348543167
step: 10, loss: 0.07799186557531357
step: 20, loss: 0.02244884893298149
step: 30, loss: 0.03594513610005379
step: 40, loss: 0.014958671294152737
step: 50, loss: 9.947818762157112e-05
step: 60, loss: 0.018647141754627228
step: 70, loss: 0.003101963084191084
step: 80, loss: 0.01841713860630989
step: 90, loss: 0.025266584008932114
step: 100, loss: 0.024726107716560364
step: 110, loss: 0.001146627706475556
step: 120, loss: 0.005119328387081623
step: 130, loss: 0.00021772236505057663
step: 140, loss: 0.02436172217130661
step: 150, loss: 0.024173034355044365
step: 160, loss: 5.9990084992023185e-05
step: 170, loss: 0.037751272320747375
step: 180, loss: 0.0007068011327646673
step: 190, loss: 0.04130998253822327
step: 200, loss: 0.00042804155964404345
step: 210, loss: 0.00014500290853902698
step: 220, loss: 0.023506727069616318
step: 230, loss: 0.014421450905501842
step: 240, loss: 0.04706769436597824
step: 250, loss: 0.0001041898358380422
step: 260, loss: 0.01916196383535862
step: 270, loss: 0.03971317037940025
step: 280, loss: 0.10495451837778091
step: 290, loss: 0.0001325504999840632
step: 300, loss: 0.0004549056466203183
step: 310, loss: 0.036633022129535675
step: 320, loss: 0.0003369240730535239
step: 330, loss: 0.021719206124544144
step: 340, loss: 0.022166656330227852
step: 350, loss: 0.051987890154123306
step: 360, loss: 0.021165737882256508
step: 370, loss: 0.00017394806491211057
step: 380, loss: 0.01687687262892723
step: 390, loss: 0.04724426195025444
step: 400, loss: 0.06189454719424248
step: 410, loss: 0.022878626361489296
step: 420, loss: 0.07570051401853561
epoch 17: dev_f1=0.9910112359550561, f1=0.9832402234636871, best_f1=0.983277591973244
step: 0, loss: 0.023234479129314423
step: 10, loss: 0.020611995831131935
step: 20, loss: 0.0004165347490925342
step: 30, loss: 0.0001313117827521637
step: 40, loss: 4.188752063782886e-05
step: 50, loss: 0.07039591670036316
step: 60, loss: 0.08951893448829651
step: 70, loss: 0.022986019030213356
step: 80, loss: 0.04422350227832794
step: 90, loss: 0.06967957317829132
step: 100, loss: 0.00022260392142925411
step: 110, loss: 0.00017239857697859406
step: 120, loss: 0.00033401622204110026
step: 130, loss: 0.0016180142993107438
step: 140, loss: 0.00019033867283724248
step: 150, loss: 0.08694159239530563
step: 160, loss: 0.05342739820480347
step: 170, loss: 0.00042354469769634306
step: 180, loss: 1.602588963578455e-05
step: 190, loss: 0.01833355613052845
step: 200, loss: 0.08178672194480896
step: 210, loss: 0.046154942363500595
step: 220, loss: 0.03045996092259884
step: 230, loss: 0.02214372344315052
step: 240, loss: 0.046273019164800644
step: 250, loss: 0.06040225923061371
step: 260, loss: 0.018894946202635765
step: 270, loss: 0.017285121604800224
step: 280, loss: 0.05439005047082901
step: 290, loss: 0.007163992617279291
step: 300, loss: 0.0006165256490930915
step: 310, loss: 0.024728398770093918
step: 320, loss: 0.0033322437666356564
step: 330, loss: 0.07120751589536667
step: 340, loss: 0.0001778402947820723
step: 350, loss: 0.020293742418289185
step: 360, loss: 0.00012757467629853636
step: 370, loss: 0.0001566343562444672
step: 380, loss: 0.032826270908117294
step: 390, loss: 0.044568587094545364
step: 400, loss: 0.07157276570796967
step: 410, loss: 7.472772267647088e-05
step: 420, loss: 0.04359477385878563
epoch 18: dev_f1=0.990990990990991, f1=0.9854423292273236, best_f1=0.983277591973244
step: 0, loss: 0.0002643653133418411
step: 10, loss: 8.542149589629844e-05
step: 20, loss: 0.03785596415400505
step: 30, loss: 0.02817823737859726
step: 40, loss: 0.08812661468982697
step: 50, loss: 0.00017647664935793728
step: 60, loss: 0.004165869206190109
step: 70, loss: 6.557573942700401e-05
step: 80, loss: 0.018813777714967728
step: 90, loss: 0.0493454784154892
step: 100, loss: 0.025238338857889175
step: 110, loss: 0.024937478825449944
step: 120, loss: 0.048952795565128326
step: 130, loss: 0.00021237399778328836
step: 140, loss: 0.00034515594597905874
step: 150, loss: 0.042375750839710236
step: 160, loss: 5.338927803677507e-05
step: 170, loss: 0.024669554084539413
step: 180, loss: 0.02706283889710903
step: 190, loss: 0.035756297409534454
step: 200, loss: 0.023279571905732155
step: 210, loss: 0.02328389696776867
step: 220, loss: 0.022233806550502777
step: 230, loss: 0.021559275686740875
step: 240, loss: 0.043424636125564575
step: 250, loss: 1.403290207235841e-05
step: 260, loss: 0.0010016760788857937
step: 270, loss: 0.04396223649382591
step: 280, loss: 0.02333424612879753
step: 290, loss: 4.7847264795564115e-05
step: 300, loss: 0.020218871533870697
step: 310, loss: 0.05889450013637543
step: 320, loss: 0.026262180879712105
step: 330, loss: 0.02589954063296318
step: 340, loss: 0.04073252156376839
step: 350, loss: 0.026654111221432686
step: 360, loss: 0.04761858657002449
step: 370, loss: 0.02139216661453247
step: 380, loss: 0.021049626171588898
step: 390, loss: 0.0247112475335598
step: 400, loss: 0.020289408043026924
step: 410, loss: 0.06616900116205215
step: 420, loss: 0.04725281521677971
epoch 19: dev_f1=0.9909706546275394, f1=0.9843400447427293, best_f1=0.983277591973244
step: 0, loss: 0.04140046238899231
step: 10, loss: 0.04592520371079445
step: 20, loss: 0.020969411358237267
step: 30, loss: 0.05830179154872894
step: 40, loss: 0.01675078459084034
step: 50, loss: 0.022862015292048454
step: 60, loss: 0.014227213338017464
step: 70, loss: 0.02487572468817234
step: 80, loss: 0.048472240567207336
step: 90, loss: 0.049387410283088684
step: 100, loss: 0.02127424068748951
step: 110, loss: 0.01059267483651638
step: 120, loss: 0.02367827482521534
step: 130, loss: 0.021235378459095955
step: 140, loss: 0.00011754334991564974
step: 150, loss: 0.02494148537516594
step: 160, loss: 0.06680545955896378
step: 170, loss: 0.02093108557164669
step: 180, loss: 0.037458520382642746
step: 190, loss: 0.02337157167494297
step: 200, loss: 0.012359297834336758
step: 210, loss: 0.00010484284575795755
step: 220, loss: 0.06374676525592804
step: 230, loss: 0.051073282957077026
step: 240, loss: 0.0211202222853899
step: 250, loss: 0.00024800957180559635
step: 260, loss: 0.021755320951342583
step: 270, loss: 0.00025815190747380257
step: 280, loss: 0.0006491249660030007
step: 290, loss: 0.020415611565113068
step: 300, loss: 0.0663779079914093
step: 310, loss: 0.0001619894028408453
step: 320, loss: 0.07291345298290253
step: 330, loss: 0.06271355599164963
step: 340, loss: 0.00023153677466325462
step: 350, loss: 0.06324643641710281
step: 360, loss: 0.04460487887263298
step: 370, loss: 0.03172890469431877
step: 380, loss: 0.020636050030589104
step: 390, loss: 0.01740366965532303
step: 400, loss: 0.049807898700237274
step: 410, loss: 7.119285146472976e-05
step: 420, loss: 0.02138557843863964
epoch 20: dev_f1=0.990990990990991, f1=0.9854423292273236, best_f1=0.983277591973244
