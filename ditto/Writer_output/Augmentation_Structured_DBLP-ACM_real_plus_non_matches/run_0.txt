cuda
Device: cuda
step: 0, loss: 0.6092061996459961
step: 10, loss: 0.41397711634635925
step: 20, loss: 0.3010846674442291
step: 30, loss: 0.36744076013565063
step: 40, loss: 0.20145514607429504
step: 50, loss: 0.23035043478012085
step: 60, loss: 0.16541065275669098
step: 70, loss: 0.13471096754074097
step: 80, loss: 0.08408839255571365
step: 90, loss: 0.18314196169376373
step: 100, loss: 0.09727117419242859
step: 110, loss: 0.012998230755329132
step: 120, loss: 0.10566744953393936
step: 130, loss: 0.10020052641630173
step: 140, loss: 0.053964704275131226
step: 150, loss: 0.1332627832889557
step: 160, loss: 0.10575886815786362
step: 170, loss: 0.09679892659187317
step: 180, loss: 0.06451065838336945
step: 190, loss: 0.18554921448230743
step: 200, loss: 0.23409759998321533
step: 210, loss: 0.07478585839271545
step: 220, loss: 0.11120349913835526
step: 230, loss: 0.053676873445510864
step: 240, loss: 0.020046163350343704
step: 250, loss: 0.08814354240894318
step: 260, loss: 0.10617054253816605
step: 270, loss: 0.09700202941894531
step: 280, loss: 0.01851676218211651
step: 290, loss: 0.030917219817638397
step: 300, loss: 0.04876358434557915
step: 310, loss: 0.0223535168915987
step: 320, loss: 0.0010008416138589382
step: 330, loss: 0.020951170474290848
step: 340, loss: 0.014142611064016819
step: 350, loss: 0.14191654324531555
step: 360, loss: 0.08543311804533005
step: 370, loss: 0.020908456295728683
step: 380, loss: 0.021529817953705788
step: 390, loss: 0.3036283552646637
step: 400, loss: 0.07361382246017456
step: 410, loss: 0.09731560200452805
step: 420, loss: 0.036244288086891174
epoch 1: dev_f1=0.9876265466816648, f1=0.9808773903262092, best_f1=0.9808773903262092
step: 0, loss: 0.039654869586229324
step: 10, loss: 0.08461527526378632
step: 20, loss: 0.006036537233740091
step: 30, loss: 0.10553926229476929
step: 40, loss: 0.08482103049755096
step: 50, loss: 0.08400727063417435
step: 60, loss: 0.005735734943300486
step: 70, loss: 0.16890095174312592
step: 80, loss: 0.08889205008745193
step: 90, loss: 0.09866414964199066
step: 100, loss: 0.10000206530094147
step: 110, loss: 0.1489037126302719
step: 120, loss: 0.017424127086997032
step: 130, loss: 0.026627039536833763
step: 140, loss: 0.09077949821949005
step: 150, loss: 0.012532353401184082
step: 160, loss: 0.14114509522914886
step: 170, loss: 0.10619531571865082
step: 180, loss: 0.012785571627318859
step: 190, loss: 0.0300724096596241
step: 200, loss: 0.007702242583036423
step: 210, loss: 0.19047757983207703
step: 220, loss: 0.05650719255208969
step: 230, loss: 0.16889362037181854
step: 240, loss: 0.0350913368165493
step: 250, loss: 0.025919541716575623
step: 260, loss: 0.028260990977287292
step: 270, loss: 0.04548563435673714
step: 280, loss: 0.06672775000333786
step: 290, loss: 0.10024969279766083
step: 300, loss: 0.013178074732422829
step: 310, loss: 0.08457882702350616
step: 320, loss: 0.10757718235254288
step: 330, loss: 0.019273236393928528
step: 340, loss: 0.09346958994865417
step: 350, loss: 0.026599599048495293
step: 360, loss: 0.08999872207641602
step: 370, loss: 0.04885173216462135
step: 380, loss: 0.1426069587469101
step: 390, loss: 0.013781287707388401
step: 400, loss: 0.04490579664707184
step: 410, loss: 0.2024703472852707
step: 420, loss: 0.08342394977807999
epoch 2: dev_f1=0.9876819708846584, f1=0.9765886287625419, best_f1=0.9765886287625419
step: 0, loss: 0.0012257929192855954
step: 10, loss: 0.005942880176007748
step: 20, loss: 0.0635405108332634
step: 30, loss: 0.02077275887131691
step: 40, loss: 0.06569802016019821
step: 50, loss: 0.053727176040410995
step: 60, loss: 0.03319641202688217
step: 70, loss: 0.1011354997754097
step: 80, loss: 0.11724149435758591
step: 90, loss: 0.11601244658231735
step: 100, loss: 0.09373719990253448
step: 110, loss: 0.09279729425907135
step: 120, loss: 0.07698642462491989
step: 130, loss: 0.03225914016366005
step: 140, loss: 0.08714918047189713
step: 150, loss: 0.09331473708152771
step: 160, loss: 0.1106729581952095
step: 170, loss: 0.07066681236028671
step: 180, loss: 0.06431467831134796
step: 190, loss: 0.180090069770813
step: 200, loss: 0.15020889043807983
step: 210, loss: 0.0724167674779892
step: 220, loss: 0.02137976512312889
step: 230, loss: 0.02961449883878231
step: 240, loss: 0.05955938249826431
step: 250, loss: 0.019450653344392776
step: 260, loss: 0.029851451516151428
step: 270, loss: 0.10922262817621231
step: 280, loss: 0.007942112162709236
step: 290, loss: 0.13126958906650543
step: 300, loss: 0.02299116738140583
step: 310, loss: 0.02270406298339367
step: 320, loss: 0.11982432752847672
step: 330, loss: 0.015328771434724331
step: 340, loss: 0.011118355207145214
step: 350, loss: 0.021071095019578934
step: 360, loss: 0.006678474601358175
step: 370, loss: 0.08283142745494843
step: 380, loss: 0.07247477769851685
step: 390, loss: 0.0017015569610521197
step: 400, loss: 0.012590020895004272
step: 410, loss: 0.054490525275468826
step: 420, loss: 0.05479389801621437
epoch 3: dev_f1=0.9865168539325843, f1=0.9809203142536477, best_f1=0.9765886287625419
step: 0, loss: 0.03359084576368332
step: 10, loss: 0.024767940863966942
step: 20, loss: 0.018575631082057953
step: 30, loss: 0.1854131519794464
step: 40, loss: 0.01741260476410389
step: 50, loss: 0.01588347926735878
step: 60, loss: 0.14724966883659363
step: 70, loss: 0.08019976317882538
step: 80, loss: 0.03666997328400612
step: 90, loss: 0.02560991235077381
step: 100, loss: 0.014946384355425835
step: 110, loss: 0.15747246146202087
step: 120, loss: 0.012031576596200466
step: 130, loss: 0.09245546162128448
step: 140, loss: 0.028491739183664322
step: 150, loss: 0.15432576835155487
step: 160, loss: 0.059908993542194366
step: 170, loss: 0.04884331673383713
step: 180, loss: 0.027433231472969055
step: 190, loss: 0.021976221352815628
step: 200, loss: 0.030441997572779655
step: 210, loss: 0.07320529967546463
step: 220, loss: 0.030811414122581482
step: 230, loss: 0.027737965807318687
step: 240, loss: 0.13483159244060516
step: 250, loss: 0.018557975068688393
step: 260, loss: 0.021746914833784103
step: 270, loss: 0.05472595617175102
step: 280, loss: 0.044856537133455276
step: 290, loss: 0.01780903898179531
step: 300, loss: 0.011701812036335468
step: 310, loss: 0.021783972159028053
step: 320, loss: 0.01590208150446415
step: 330, loss: 0.09235154837369919
step: 340, loss: 0.23015782237052917
step: 350, loss: 0.07896705716848373
step: 360, loss: 9.975522698368877e-05
step: 370, loss: 0.05621487647294998
step: 380, loss: 0.03177062049508095
step: 390, loss: 0.02754336968064308
step: 400, loss: 0.02353178709745407
step: 410, loss: 0.06899051368236542
step: 420, loss: 0.020557750016450882
epoch 4: dev_f1=0.9899665551839464, f1=0.985539488320356, best_f1=0.985539488320356
step: 0, loss: 0.0537380687892437
step: 10, loss: 0.030497366562485695
step: 20, loss: 0.009561835788190365
step: 30, loss: 0.058154813945293427
step: 40, loss: 0.05845053493976593
step: 50, loss: 0.023322176188230515
step: 60, loss: 0.024543944746255875
step: 70, loss: 0.053842995315790176
step: 80, loss: 0.062109652906656265
step: 90, loss: 0.10725351423025131
step: 100, loss: 0.07578687369823456
step: 110, loss: 0.013935091905295849
step: 120, loss: 0.09128119796514511
step: 130, loss: 0.009584725834429264
step: 140, loss: 0.01757342368364334
step: 150, loss: 0.012014674954116344
step: 160, loss: 0.006872592959553003
step: 170, loss: 0.03097788617014885
step: 180, loss: 0.1507837176322937
step: 190, loss: 0.03364228084683418
step: 200, loss: 0.08332368731498718
step: 210, loss: 0.029445664957165718
step: 220, loss: 0.02338360995054245
step: 230, loss: 0.041635412722826004
step: 240, loss: 0.009464590810239315
step: 250, loss: 0.06906839460134506
step: 260, loss: 0.10892791301012039
step: 270, loss: 0.07848566770553589
step: 280, loss: 0.02981141023337841
step: 290, loss: 0.1457957923412323
step: 300, loss: 0.06340523064136505
step: 310, loss: 0.06965629756450653
step: 320, loss: 0.0949694961309433
step: 330, loss: 0.024340713396668434
step: 340, loss: 0.004921292886137962
step: 350, loss: 0.05387455224990845
step: 360, loss: 0.010875748470425606
step: 370, loss: 0.014191297814249992
step: 380, loss: 0.08542344719171524
step: 390, loss: 0.09603029489517212
step: 400, loss: 0.014918223023414612
step: 410, loss: 0.01693279668688774
step: 420, loss: 0.018800321966409683
epoch 5: dev_f1=0.9921787709497207, f1=0.9823008849557522, best_f1=0.9823008849557522
step: 0, loss: 0.08676142990589142
step: 10, loss: 0.013464376330375671
step: 20, loss: 0.00440386775881052
step: 30, loss: 0.011390105821192265
step: 40, loss: 0.06453417986631393
step: 50, loss: 0.007529472932219505
step: 60, loss: 0.06500536948442459
step: 70, loss: 0.01786043867468834
step: 80, loss: 0.0039349026046693325
step: 90, loss: 0.07701250910758972
step: 100, loss: 0.06749894469976425
step: 110, loss: 0.019983971491456032
step: 120, loss: 0.017981043085455894
step: 130, loss: 0.01505964808166027
step: 140, loss: 4.062703010276891e-05
step: 150, loss: 0.07430023699998856
step: 160, loss: 0.060136470943689346
step: 170, loss: 0.023717932403087616
step: 180, loss: 6.026073606335558e-05
step: 190, loss: 0.1834392547607422
step: 200, loss: 0.11480261385440826
step: 210, loss: 0.15017706155776978
step: 220, loss: 0.05888788774609566
step: 230, loss: 0.007049855310469866
step: 240, loss: 0.06399624794721603
step: 250, loss: 0.016511008143424988
step: 260, loss: 0.047169703990221024
step: 270, loss: 0.019287697970867157
step: 280, loss: 0.014587855897843838
step: 290, loss: 0.024484101682901382
step: 300, loss: 0.019013531506061554
step: 310, loss: 0.061597276479005814
step: 320, loss: 0.011243647895753384
step: 330, loss: 0.08385851979255676
step: 340, loss: 0.09962785243988037
step: 350, loss: 0.007397301495075226
step: 360, loss: 0.07223813980817795
step: 370, loss: 0.10693082958459854
step: 380, loss: 0.08478051424026489
step: 390, loss: 0.007608809974044561
step: 400, loss: 0.026395399123430252
step: 410, loss: 0.04102578014135361
step: 420, loss: 0.010400107130408287
epoch 6: dev_f1=0.9943630214205187, f1=0.9865470852017937, best_f1=0.9865470852017937
step: 0, loss: 0.031222017481923103
step: 10, loss: 0.014314613305032253
step: 20, loss: 0.06844667345285416
step: 30, loss: 0.0001504184037912637
step: 40, loss: 0.08896549791097641
step: 50, loss: 0.051839858293533325
step: 60, loss: 0.06501008570194244
step: 70, loss: 0.05162200704216957
step: 80, loss: 0.00753772584721446
step: 90, loss: 0.00775678688660264
step: 100, loss: 0.09474756568670273
step: 110, loss: 0.023024221882224083
step: 120, loss: 0.01670055091381073
step: 130, loss: 0.01615055277943611
step: 140, loss: 0.025710508227348328
step: 150, loss: 0.09013723582029343
step: 160, loss: 0.029083911329507828
step: 170, loss: 0.057604897767305374
step: 180, loss: 0.018653782084584236
step: 190, loss: 0.1424228549003601
step: 200, loss: 0.0027823399286717176
step: 210, loss: 0.009902587160468102
step: 220, loss: 0.06594359129667282
step: 230, loss: 0.1161484643816948
step: 240, loss: 0.014105343259871006
step: 250, loss: 0.07746948301792145
step: 260, loss: 0.005958461668342352
step: 270, loss: 0.15325480699539185
step: 280, loss: 0.07299207895994186
step: 290, loss: 0.01024574227631092
step: 300, loss: 0.02139272168278694
step: 310, loss: 0.014561438001692295
step: 320, loss: 0.061150405555963516
step: 330, loss: 0.01782476156949997
step: 340, loss: 0.0032284297049045563
step: 350, loss: 0.07643841952085495
step: 360, loss: 0.005918061826378107
step: 370, loss: 0.1720508635044098
step: 380, loss: 0.019611120223999023
step: 390, loss: 0.0718931034207344
step: 400, loss: 0.1319168210029602
step: 410, loss: 0.0967491939663887
step: 420, loss: 0.05020855367183685
epoch 7: dev_f1=0.9932279909706545, f1=0.9854423292273236, best_f1=0.9865470852017937
step: 0, loss: 0.08894888311624527
step: 10, loss: 0.07307377457618713
step: 20, loss: 0.0486331433057785
step: 30, loss: 0.3490334451198578
step: 40, loss: 0.0802106037735939
step: 50, loss: 0.07292793691158295
step: 60, loss: 0.005007300525903702
step: 70, loss: 0.030523374676704407
step: 80, loss: 0.0070349229499697685
step: 90, loss: 0.08687026053667068
step: 100, loss: 0.019848419353365898
step: 110, loss: 0.005888304673135281
step: 120, loss: 0.1256295144557953
step: 130, loss: 0.2151404172182083
step: 140, loss: 0.009720316156744957
step: 150, loss: 0.09029104560613632
step: 160, loss: 0.0623992457985878
step: 170, loss: 0.02280140295624733
step: 180, loss: 0.12884074449539185
step: 190, loss: 0.0198806282132864
step: 200, loss: 0.05347217619419098
step: 210, loss: 0.09584463387727737
step: 220, loss: 0.08489405363798141
step: 230, loss: 0.02134905569255352
step: 240, loss: 0.0059587908908724785
step: 250, loss: 0.0307750441133976
step: 260, loss: 0.08114120364189148
step: 270, loss: 0.004856579005718231
step: 280, loss: 0.07054245471954346
step: 290, loss: 0.012069592252373695
step: 300, loss: 0.010969828814268112
step: 310, loss: 0.015944432467222214
step: 320, loss: 0.040729500353336334
step: 330, loss: 0.00011263874330325052
step: 340, loss: 0.08825136721134186
step: 350, loss: 0.007503421977162361
step: 360, loss: 0.08352786302566528
step: 370, loss: 0.01922393962740898
step: 380, loss: 0.049785371869802475
step: 390, loss: 0.024483967572450638
step: 400, loss: 0.0050029754638671875
step: 410, loss: 0.021034441888332367
step: 420, loss: 0.05508799105882645
epoch 8: dev_f1=0.9943757030371203, f1=0.9854423292273236, best_f1=0.9854423292273236
step: 0, loss: 0.09019140899181366
step: 10, loss: 0.0822218582034111
step: 20, loss: 0.12248269468545914
step: 30, loss: 0.0690414160490036
step: 40, loss: 0.0077322376891970634
step: 50, loss: 0.019761184230446815
step: 60, loss: 0.06848134100437164
step: 70, loss: 0.136428564786911
step: 80, loss: 0.005512995179742575
step: 90, loss: 0.005149104632437229
step: 100, loss: 0.009656498208642006
step: 110, loss: 0.01645735278725624
step: 120, loss: 0.07118130475282669
step: 130, loss: 0.07949598133563995
step: 140, loss: 0.06962405890226364
step: 150, loss: 0.0253117885440588
step: 160, loss: 0.027052834630012512
step: 170, loss: 0.010128832422196865
step: 180, loss: 0.011049475520849228
step: 190, loss: 0.010678023099899292
step: 200, loss: 0.012582369148731232
step: 210, loss: 3.1213308830047026e-05
step: 220, loss: 0.15583904087543488
step: 230, loss: 0.06671308726072311
step: 240, loss: 0.030370056629180908
step: 250, loss: 0.013549834489822388
step: 260, loss: 0.060344114899635315
step: 270, loss: 0.06901472806930542
step: 280, loss: 0.013927105814218521
step: 290, loss: 0.01383940503001213
step: 300, loss: 0.15632833540439606
step: 310, loss: 0.08760292828083038
step: 320, loss: 0.08893273770809174
step: 330, loss: 0.03180075064301491
step: 340, loss: 0.13434062898159027
step: 350, loss: 0.045309048146009445
step: 360, loss: 0.001823071506805718
step: 370, loss: 0.012078437022864819
step: 380, loss: 0.0055940402671694756
step: 390, loss: 0.10355953872203827
step: 400, loss: 0.1354351043701172
step: 410, loss: 0.06741735339164734
step: 420, loss: 0.061467088758945465
epoch 9: dev_f1=0.9954954954954955, f1=0.9854423292273236, best_f1=0.9854423292273236
step: 0, loss: 0.08820317685604095
step: 10, loss: 0.03831535205245018
step: 20, loss: 0.032516028732061386
step: 30, loss: 0.010701227933168411
step: 40, loss: 0.0936664342880249
step: 50, loss: 0.13198472559452057
step: 60, loss: 0.021319279447197914
step: 70, loss: 0.035365719348192215
step: 80, loss: 0.009006738662719727
step: 90, loss: 0.0039143553003668785
step: 100, loss: 0.1516808271408081
step: 110, loss: 0.12240903824567795
step: 120, loss: 0.014578246511518955
step: 130, loss: 0.023269498720765114
step: 140, loss: 0.010375249199569225
step: 150, loss: 0.010876314714550972
step: 160, loss: 0.07247178256511688
step: 170, loss: 0.07575520128011703
step: 180, loss: 0.06266580522060394
step: 190, loss: 0.03396837040781975
step: 200, loss: 0.011947425082325935
step: 210, loss: 0.003688979195430875
step: 220, loss: 0.013871952891349792
step: 230, loss: 0.07928281277418137
step: 240, loss: 0.021193550899624825
step: 250, loss: 0.05781935155391693
step: 260, loss: 0.0174716766923666
step: 270, loss: 0.07937169820070267
step: 280, loss: 0.004462854471057653
step: 290, loss: 0.125608429312706
step: 300, loss: 0.043764375150203705
step: 310, loss: 0.010649719275534153
step: 320, loss: 0.03811813145875931
step: 330, loss: 0.018665192648768425
step: 340, loss: 0.07175862044095993
step: 350, loss: 0.04003799706697464
step: 360, loss: 0.0481901653110981
step: 370, loss: 0.03182200714945793
step: 380, loss: 0.045647602528333664
step: 390, loss: 0.029380662366747856
step: 400, loss: 0.10470043122768402
step: 410, loss: 0.032869379967451096
step: 420, loss: 0.011563228443264961
epoch 10: dev_f1=0.9921259842519685, f1=0.9865470852017937, best_f1=0.9854423292273236
step: 0, loss: 0.028546908870339394
step: 10, loss: 0.02379351668059826
step: 20, loss: 0.01803472824394703
step: 30, loss: 0.016526227816939354
step: 40, loss: 0.02451072633266449
step: 50, loss: 0.10478456318378448
step: 60, loss: 0.0675654485821724
step: 70, loss: 0.011132244020700455
step: 80, loss: 0.015309044159948826
step: 90, loss: 0.012296176515519619
step: 100, loss: 0.017033077776432037
step: 110, loss: 0.06968936324119568
step: 120, loss: 0.07432305067777634
step: 130, loss: 0.15224741399288177
step: 140, loss: 0.024573450908064842
step: 150, loss: 0.02590140327811241
step: 160, loss: 0.037691980600357056
step: 170, loss: 0.10158572345972061
step: 180, loss: 0.030578818172216415
step: 190, loss: 0.0003453724493738264
step: 200, loss: 0.12338351458311081
step: 210, loss: 0.09810362011194229
step: 220, loss: 0.13847601413726807
step: 230, loss: 0.155605286359787
step: 240, loss: 0.02063448540866375
step: 250, loss: 0.01867683418095112
step: 260, loss: 0.011258644051849842
step: 270, loss: 0.025152310729026794
step: 280, loss: 0.0131642185151577
step: 290, loss: 0.01312254462391138
step: 300, loss: 0.005515753757208586
step: 310, loss: 0.01209236215800047
step: 320, loss: 0.0005397348431870341
step: 330, loss: 0.058016128838062286
step: 340, loss: 0.04667983576655388
step: 350, loss: 0.00956408679485321
step: 360, loss: 0.025428863242268562
step: 370, loss: 0.024424929171800613
step: 380, loss: 0.11483592540025711
step: 390, loss: 0.026348497718572617
step: 400, loss: 0.014485584571957588
step: 410, loss: 0.0040821717120707035
step: 420, loss: 0.03994810953736305
epoch 11: dev_f1=0.9932584269662922, f1=0.9843400447427293, best_f1=0.9854423292273236
step: 0, loss: 0.03614526614546776
step: 10, loss: 0.005310114473104477
step: 20, loss: 0.02106812782585621
step: 30, loss: 0.008942799642682076
step: 40, loss: 0.07763361185789108
step: 50, loss: 0.0847647562623024
step: 60, loss: 0.08289384096860886
step: 70, loss: 0.024280838668346405
step: 80, loss: 0.021493181586265564
step: 90, loss: 0.0069581810384988785
step: 100, loss: 0.10867965221405029
step: 110, loss: 0.09166685491800308
step: 120, loss: 0.08984018117189407
step: 130, loss: 0.019318213686347008
step: 140, loss: 0.11260281503200531
step: 150, loss: 0.02395070716738701
step: 160, loss: 0.07439689338207245
step: 170, loss: 0.09276626259088516
step: 180, loss: 0.07304873317480087
step: 190, loss: 0.009696097113192081
step: 200, loss: 5.898372546653263e-05
step: 210, loss: 0.0229845829308033
step: 220, loss: 0.08966350555419922
step: 230, loss: 0.02024633064866066
step: 240, loss: 0.10259800404310226
step: 250, loss: 0.18820129334926605
step: 260, loss: 0.11938972771167755
step: 270, loss: 0.0297254528850317
step: 280, loss: 0.1185046061873436
step: 290, loss: 0.025615213438868523
step: 300, loss: 0.12721750140190125
step: 310, loss: 0.037586018443107605
step: 320, loss: 0.07553518563508987
step: 330, loss: 0.10408215969800949
step: 340, loss: 0.01892007701098919
step: 350, loss: 0.08024183660745621
step: 360, loss: 0.00850318931043148
step: 370, loss: 0.013822238892316818
step: 380, loss: 0.01678614504635334
step: 390, loss: 0.020707733929157257
step: 400, loss: 0.022679027169942856
step: 410, loss: 0.03282026946544647
step: 420, loss: 0.022293992340564728
epoch 12: dev_f1=0.9943757030371203, f1=0.987736900780379, best_f1=0.9854423292273236
step: 0, loss: 0.08879991620779037
step: 10, loss: 0.027620790526270866
step: 20, loss: 0.07396917790174484
step: 30, loss: 0.00855913944542408
step: 40, loss: 0.10210869461297989
step: 50, loss: 0.020815672352910042
step: 60, loss: 0.13227112591266632
step: 70, loss: 0.11315719783306122
step: 80, loss: 0.042380038648843765
step: 90, loss: 0.005023953504860401
step: 100, loss: 0.002859464380890131
step: 110, loss: 0.004290326498448849
step: 120, loss: 0.08837667852640152
step: 130, loss: 0.019785122945904732
step: 140, loss: 0.213392972946167
step: 150, loss: 0.009487428702414036
step: 160, loss: 0.03266710042953491
step: 170, loss: 0.016627632081508636
step: 180, loss: 0.09028612822294235
step: 190, loss: 0.01746108941733837
step: 200, loss: 0.026726162061095238
step: 210, loss: 0.0694895014166832
step: 220, loss: 0.05671655014157295
step: 230, loss: 0.055371638387441635
step: 240, loss: 0.07108644396066666
step: 250, loss: 0.30800947546958923
step: 260, loss: 0.016351742669939995
step: 270, loss: 0.039359092712402344
step: 280, loss: 0.013040881603956223
step: 290, loss: 0.12843568623065948
step: 300, loss: 0.050115276128053665
step: 310, loss: 0.10641061514616013
step: 320, loss: 0.02704845927655697
step: 330, loss: 0.024794910103082657
step: 340, loss: 0.0024985820055007935
step: 350, loss: 0.01055342797189951
step: 360, loss: 0.11045972257852554
step: 370, loss: 0.07529446482658386
step: 380, loss: 0.01597198285162449
step: 390, loss: 0.12168560922145844
step: 400, loss: 0.010652091354131699
step: 410, loss: 0.004987712949514389
step: 420, loss: 0.0062347035855054855
epoch 13: dev_f1=0.990990990990991, f1=0.9854096520763187, best_f1=0.9854423292273236
step: 0, loss: 0.03945928439497948
step: 10, loss: 0.004390515852719545
step: 20, loss: 0.07307892292737961
step: 30, loss: 0.029490388929843903
step: 40, loss: 0.06326369196176529
step: 50, loss: 0.006521016824990511
step: 60, loss: 0.02200457826256752
step: 70, loss: 0.019968722015619278
step: 80, loss: 0.00797803420573473
step: 90, loss: 0.008095393888652325
step: 100, loss: 0.09706300497055054
step: 110, loss: 0.018834717571735382
step: 120, loss: 0.10688450187444687
step: 130, loss: 0.15144813060760498
step: 140, loss: 0.00765017606317997
step: 150, loss: 0.06871993839740753
step: 160, loss: 0.005395658779889345
step: 170, loss: 0.013890080153942108
step: 180, loss: 0.22438783943653107
step: 190, loss: 0.007947840727865696
step: 200, loss: 0.005092217121273279
step: 210, loss: 0.004583360161632299
step: 220, loss: 0.02255544438958168
step: 230, loss: 0.07659546285867691
step: 240, loss: 0.05325646325945854
step: 250, loss: 0.008275551721453667
step: 260, loss: 0.02775510959327221
step: 270, loss: 0.13636068999767303
step: 280, loss: 0.04453802481293678
step: 290, loss: 0.02770599164068699
step: 300, loss: 0.010341702960431576
step: 310, loss: 0.3174881637096405
step: 320, loss: 0.047012656927108765
step: 330, loss: 0.016899636015295982
step: 340, loss: 0.0784216895699501
step: 350, loss: 0.08273282647132874
step: 360, loss: 0.06272634118795395
step: 370, loss: 0.027571339160203934
step: 380, loss: 0.06283450126647949
step: 390, loss: 0.014332814142107964
step: 400, loss: 0.024070454761385918
step: 410, loss: 0.04011331498622894
step: 420, loss: 0.045074671506881714
epoch 14: dev_f1=0.9943883277216611, f1=0.9866071428571428, best_f1=0.9854423292273236
step: 0, loss: 0.015033483505249023
step: 10, loss: 0.007342286873608828
step: 20, loss: 0.06539427489042282
step: 30, loss: 0.03481290116906166
step: 40, loss: 0.011851383373141289
step: 50, loss: 0.09263723343610764
step: 60, loss: 0.059647176414728165
step: 70, loss: 0.07028751820325851
step: 80, loss: 0.10462605208158493
step: 90, loss: 0.08125071227550507
step: 100, loss: 0.007102441042661667
step: 110, loss: 0.01956763118505478
step: 120, loss: 0.09039954841136932
step: 130, loss: 0.16816037893295288
step: 140, loss: 0.11650488525629044
step: 150, loss: 0.00924103707075119
step: 160, loss: 0.0465095117688179
step: 170, loss: 0.07200079411268234
step: 180, loss: 7.004863437032327e-05
step: 190, loss: 0.007288820575922728
step: 200, loss: 0.019052661955356598
step: 210, loss: 0.13169673085212708
step: 220, loss: 0.1037861555814743
step: 230, loss: 0.01329136174172163
step: 240, loss: 0.0027772868052124977
step: 250, loss: 0.08903216570615768
step: 260, loss: 0.045516278594732285
step: 270, loss: 0.006049053277820349
step: 280, loss: 0.005861290730535984
step: 290, loss: 0.08971547335386276
step: 300, loss: 0.002259686356410384
step: 310, loss: 0.015668757259845734
step: 320, loss: 0.12362997978925705
step: 330, loss: 0.039306916296482086
step: 340, loss: 0.020711209625005722
step: 350, loss: 0.0015226160176098347
step: 360, loss: 0.17162971198558807
step: 370, loss: 0.0033906942699104548
step: 380, loss: 4.7021021600812674e-05
step: 390, loss: 0.016756881028413773
step: 400, loss: 0.025802796706557274
step: 410, loss: 0.033612415194511414
step: 420, loss: 0.0897793397307396
epoch 15: dev_f1=0.9943757030371203, f1=0.9843749999999999, best_f1=0.9854423292273236
step: 0, loss: 0.07240962982177734
step: 10, loss: 0.003904802491888404
step: 20, loss: 0.14040596783161163
step: 30, loss: 0.09508970379829407
step: 40, loss: 0.04877454787492752
step: 50, loss: 0.04241173341870308
step: 60, loss: 0.2023751437664032
step: 70, loss: 0.023165274411439896
step: 80, loss: 0.029413733631372452
step: 90, loss: 0.021985258907079697
step: 100, loss: 0.007245209533721209
step: 110, loss: 0.04599690064787865
step: 120, loss: 0.0011032050242647529
step: 130, loss: 0.029749704524874687
step: 140, loss: 0.0432891920208931
step: 150, loss: 0.06441932171583176
step: 160, loss: 0.003924655728042126
step: 170, loss: 0.09006732702255249
step: 180, loss: 0.002800369169563055
step: 190, loss: 0.037469763308763504
step: 200, loss: 0.008118647150695324
step: 210, loss: 0.03528856113553047
step: 220, loss: 0.016985323280096054
step: 230, loss: 0.006010569632053375
step: 240, loss: 0.04412603750824928
step: 250, loss: 0.04066748172044754
step: 260, loss: 0.020750461146235466
step: 270, loss: 0.003042241558432579
step: 280, loss: 0.0845336765050888
step: 290, loss: 0.0274361502379179
step: 300, loss: 1.766887362464331e-05
step: 310, loss: 0.044959258288145065
step: 320, loss: 0.0640505850315094
step: 330, loss: 0.005157159175723791
step: 340, loss: 0.016395919024944305
step: 350, loss: 0.0940002053976059
step: 360, loss: 0.006392478942871094
step: 370, loss: 0.002338576130568981
step: 380, loss: 0.02945370227098465
step: 390, loss: 0.029076898470520973
step: 400, loss: 0.09817410260438919
step: 410, loss: 0.014743577688932419
step: 420, loss: 0.007657742593437433
epoch 16: dev_f1=0.9932735426008968, f1=0.9866071428571428, best_f1=0.9854423292273236
step: 0, loss: 0.049127403646707535
step: 10, loss: 0.002681075595319271
step: 20, loss: 0.01459914818406105
step: 30, loss: 0.055256437510252
step: 40, loss: 0.06408116966485977
step: 50, loss: 0.021049894392490387
step: 60, loss: 0.01631322130560875
step: 70, loss: 0.01592218317091465
step: 80, loss: 0.00614199647679925
step: 90, loss: 0.0948360338807106
step: 100, loss: 0.039404504001140594
step: 110, loss: 0.06283201277256012
step: 120, loss: 0.0175382811576128
step: 130, loss: 0.0011618382995948195
step: 140, loss: 0.01629033498466015
step: 150, loss: 0.016921784728765488
step: 160, loss: 0.035310570150613785
step: 170, loss: 0.019528323784470558
step: 180, loss: 0.08827140927314758
step: 190, loss: 0.08545788377523422
step: 200, loss: 0.002813364379107952
step: 210, loss: 0.003901404794305563
step: 220, loss: 0.20182524621486664
step: 230, loss: 0.051232125610113144
step: 240, loss: 0.02304038219153881
step: 250, loss: 0.005773291457444429
step: 260, loss: 0.0035788975656032562
step: 270, loss: 0.0015786675503477454
step: 280, loss: 0.008528490550816059
step: 290, loss: 0.08610965311527252
step: 300, loss: 0.0060511305928230286
step: 310, loss: 0.07472985237836838
step: 320, loss: 0.014258285984396935
step: 330, loss: 0.027581630274653435
step: 340, loss: 0.0056647625751793385
step: 350, loss: 0.02481912262737751
step: 360, loss: 0.004456261172890663
step: 370, loss: 0.06027781218290329
step: 380, loss: 0.051606178283691406
step: 390, loss: 0.08730410039424896
step: 400, loss: 0.006601101718842983
step: 410, loss: 0.017177607864141464
step: 420, loss: 0.011974897235631943
epoch 17: dev_f1=0.9943757030371203, f1=0.9842696629213483, best_f1=0.9854423292273236
step: 0, loss: 0.01576625369489193
step: 10, loss: 0.00048674287972971797
step: 20, loss: 0.028985409066081047
step: 30, loss: 0.00586153008043766
step: 40, loss: 0.030439579859375954
step: 50, loss: 0.05779358372092247
step: 60, loss: 0.07277961820363998
step: 70, loss: 0.022157179191708565
step: 80, loss: 0.05188489332795143
step: 90, loss: 0.04403524473309517
step: 100, loss: 0.02181660383939743
step: 110, loss: 0.12116575986146927
step: 120, loss: 0.0173809677362442
step: 130, loss: 0.000875260098837316
step: 140, loss: 0.11516689509153366
step: 150, loss: 0.049616314470767975
step: 160, loss: 0.09015637636184692
step: 170, loss: 0.03644397482275963
step: 180, loss: 0.06932469457387924
step: 190, loss: 0.07304562628269196
step: 200, loss: 0.04313524439930916
step: 210, loss: 0.03155836462974548
step: 220, loss: 0.01989372819662094
step: 230, loss: 0.00018979351443704218
step: 240, loss: 0.011895878240466118
step: 250, loss: 0.06326501071453094
step: 260, loss: 0.02260148897767067
step: 270, loss: 0.001170846284367144
step: 280, loss: 0.03778938576579094
step: 290, loss: 0.020934198051691055
step: 300, loss: 0.02221083641052246
step: 310, loss: 0.03651895746588707
step: 320, loss: 0.0061605386435985565
step: 330, loss: 0.08312486857175827
step: 340, loss: 0.004238898400217295
step: 350, loss: 0.07960257679224014
step: 360, loss: 0.04680873453617096
step: 370, loss: 0.09205968677997589
step: 380, loss: 0.04450073093175888
step: 390, loss: 0.09476295858621597
step: 400, loss: 0.053425513207912445
step: 410, loss: 0.04967639222741127
step: 420, loss: 0.033667340874671936
epoch 18: dev_f1=0.995505617977528, f1=0.9832402234636871, best_f1=0.9832402234636871
step: 0, loss: 0.022081496194005013
step: 10, loss: 0.05210672318935394
step: 20, loss: 0.0018139263847842813
step: 30, loss: 0.014531402848660946
step: 40, loss: 0.02152806892991066
step: 50, loss: 0.09681840240955353
step: 60, loss: 0.02526877075433731
step: 70, loss: 0.028590243309736252
step: 80, loss: 0.042331304401159286
step: 90, loss: 0.019814133644104004
step: 100, loss: 0.051790058612823486
step: 110, loss: 0.011474003084003925
step: 120, loss: 0.00100959581322968
step: 130, loss: 0.0010798948351293802
step: 140, loss: 0.06048686057329178
step: 150, loss: 0.014267569407820702
step: 160, loss: 0.000161955802468583
step: 170, loss: 2.1322995962691493e-05
step: 180, loss: 0.05978216603398323
step: 190, loss: 0.010562012903392315
step: 200, loss: 0.003936282824724913
step: 210, loss: 0.1188693642616272
step: 220, loss: 0.07402632385492325
step: 230, loss: 0.025477491319179535
step: 240, loss: 0.005877851974219084
step: 250, loss: 0.2528790533542633
step: 260, loss: 0.018318749964237213
step: 270, loss: 0.004325164016336203
step: 280, loss: 0.01731194742023945
step: 290, loss: 0.04110778123140335
step: 300, loss: 0.0001499875943409279
step: 310, loss: 0.03461316227912903
step: 320, loss: 0.030933069065213203
step: 330, loss: 0.027405647560954094
step: 340, loss: 0.096320740878582
step: 350, loss: 0.09815865755081177
step: 360, loss: 0.002509447280317545
step: 370, loss: 0.029359882697463036
step: 380, loss: 0.000997038441710174
step: 390, loss: 0.06866367161273956
step: 400, loss: 0.04630493000149727
step: 410, loss: 0.0005885983118787408
step: 420, loss: 0.0002172733802581206
epoch 19: dev_f1=0.995505617977528, f1=0.9854423292273236, best_f1=0.9832402234636871
step: 0, loss: 0.12945561110973358
step: 10, loss: 0.02355118654668331
step: 20, loss: 0.006746298633515835
step: 30, loss: 0.06077751889824867
step: 40, loss: 0.024636898189783096
step: 50, loss: 0.05026138946413994
step: 60, loss: 0.02932754158973694
step: 70, loss: 0.001961931586265564
step: 80, loss: 0.08406974375247955
step: 90, loss: 0.03171287849545479
step: 100, loss: 0.026263633742928505
step: 110, loss: 0.013450829312205315
step: 120, loss: 0.0016823542537167668
step: 130, loss: 0.0008633806719444692
step: 140, loss: 0.0049757519736886024
step: 150, loss: 0.011049062013626099
step: 160, loss: 0.0493779331445694
step: 170, loss: 0.05002543330192566
step: 180, loss: 0.02555912733078003
step: 190, loss: 0.00010535649926168844
step: 200, loss: 0.001183828106150031
step: 210, loss: 0.024684829637408257
step: 220, loss: 0.07153741270303726
step: 230, loss: 1.5269821233232506e-05
step: 240, loss: 0.06082172319293022
step: 250, loss: 0.003039455972611904
step: 260, loss: 0.07170075178146362
step: 270, loss: 0.0014716631267219782
step: 280, loss: 0.02662532590329647
step: 290, loss: 0.023805275559425354
step: 300, loss: 0.04121362790465355
step: 310, loss: 0.01534309983253479
step: 320, loss: 0.022377019748091698
step: 330, loss: 0.017359156161546707
step: 340, loss: 0.01242072507739067
step: 350, loss: 0.0976521298289299
step: 360, loss: 0.0007344350451603532
step: 370, loss: 0.04578250274062157
step: 380, loss: 0.047501709312200546
step: 390, loss: 0.05343853682279587
step: 400, loss: 0.04131018742918968
step: 410, loss: 0.010236183181405067
step: 420, loss: 0.01787560246884823
epoch 20: dev_f1=0.9954954954954955, f1=0.9831271091113611, best_f1=0.9832402234636871
