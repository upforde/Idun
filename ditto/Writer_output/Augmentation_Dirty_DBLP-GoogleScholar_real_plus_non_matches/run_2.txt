cuda
Device: cuda
step: 0, loss: 0.6777310967445374
step: 10, loss: 0.31559640169143677
step: 20, loss: 0.49811264872550964
step: 30, loss: 0.15448246896266937
step: 40, loss: 0.4253920912742615
step: 50, loss: 0.43503913283348083
step: 60, loss: 0.22639082372188568
step: 70, loss: 0.3559546172618866
step: 80, loss: 0.2465345710515976
step: 90, loss: 0.33014997839927673
step: 100, loss: 0.09540537744760513
step: 110, loss: 0.06204002723097801
step: 120, loss: 0.1387549638748169
step: 130, loss: 0.132901132106781
step: 140, loss: 0.17925101518630981
step: 150, loss: 0.12453999370336533
step: 160, loss: 0.41053280234336853
step: 170, loss: 0.1848948746919632
step: 180, loss: 0.09677698463201523
step: 190, loss: 0.10783767700195312
step: 200, loss: 0.23835472762584686
step: 210, loss: 0.2439979910850525
step: 220, loss: 0.1308598667383194
step: 230, loss: 0.1797994077205658
step: 240, loss: 0.3328384459018707
step: 250, loss: 0.2334108054637909
step: 260, loss: 0.10448341071605682
step: 270, loss: 0.21369598805904388
step: 280, loss: 0.14025574922561646
step: 290, loss: 0.05770362541079521
step: 300, loss: 0.19269202649593353
step: 310, loss: 0.12040329724550247
step: 320, loss: 0.12543852627277374
step: 330, loss: 0.2564586102962494
step: 340, loss: 0.10386396944522858
step: 350, loss: 0.3479847311973572
step: 360, loss: 0.2101208120584488
step: 370, loss: 0.18861006200313568
step: 380, loss: 0.08985870331525803
step: 390, loss: 0.16544422507286072
step: 400, loss: 0.1612326204776764
step: 410, loss: 0.15710066258907318
step: 420, loss: 0.21850544214248657
step: 430, loss: 0.08326584845781326
step: 440, loss: 0.13021430373191833
step: 450, loss: 0.13093356788158417
step: 460, loss: 0.08337430655956268
step: 470, loss: 0.22590062022209167
step: 480, loss: 0.14324058592319489
step: 490, loss: 0.11091933399438858
step: 500, loss: 0.16919897496700287
step: 510, loss: 0.13558557629585266
step: 520, loss: 0.11827915161848068
step: 530, loss: 0.18320997059345245
step: 540, loss: 0.2773659825325012
step: 550, loss: 0.08276347815990448
step: 560, loss: 0.2900356352329254
step: 570, loss: 0.11471091955900192
step: 580, loss: 0.11274650692939758
step: 590, loss: 0.28459087014198303
step: 600, loss: 0.08799424022436142
step: 610, loss: 0.32781296968460083
step: 620, loss: 0.10732464492321014
step: 630, loss: 0.19807100296020508
step: 640, loss: 0.13106554746627808
step: 650, loss: 0.2540501058101654
step: 660, loss: 0.11093174666166306
step: 670, loss: 0.11289051175117493
step: 680, loss: 0.10749248415231705
step: 690, loss: 0.20190578699111938
step: 700, loss: 0.044606711715459824
step: 710, loss: 0.04790163040161133
step: 720, loss: 0.05358482524752617
step: 730, loss: 0.19016169011592865
step: 740, loss: 0.24267588555812836
step: 750, loss: 0.05551975592970848
step: 760, loss: 0.08638356626033783
step: 770, loss: 0.11035368591547012
step: 780, loss: 0.1778239905834198
step: 790, loss: 0.08182904124259949
step: 800, loss: 0.0788073018193245
step: 810, loss: 0.16799312829971313
step: 820, loss: 0.08808692544698715
step: 830, loss: 0.15507611632347107
step: 840, loss: 0.19936318695545197
step: 850, loss: 0.09769982099533081
step: 860, loss: 0.23488907516002655
step: 870, loss: 0.12000003457069397
step: 880, loss: 0.1945471465587616
step: 890, loss: 0.22498002648353577
step: 900, loss: 0.21526804566383362
step: 910, loss: 0.14215192198753357
step: 920, loss: 0.06237165257334709
step: 930, loss: 0.14011771976947784
step: 940, loss: 0.20919378101825714
step: 950, loss: 0.20364484190940857
step: 960, loss: 0.14108839631080627
step: 970, loss: 0.22153858840465546
epoch 1: dev_f1=0.9111210361768646, f1=0.9120142920946851, best_f1=0.9120142920946851
step: 0, loss: 0.1529136300086975
step: 10, loss: 0.08124904334545135
step: 20, loss: 0.1192852035164833
step: 30, loss: 0.022705955430865288
step: 40, loss: 0.0846782699227333
step: 50, loss: 0.1485692262649536
step: 60, loss: 0.13816726207733154
step: 70, loss: 0.11312887817621231
step: 80, loss: 0.11432984471321106
step: 90, loss: 0.10476235300302505
step: 100, loss: 0.055509209632873535
step: 110, loss: 0.13000193238258362
step: 120, loss: 0.19513611495494843
step: 130, loss: 0.10663783550262451
step: 140, loss: 0.15555870532989502
step: 150, loss: 0.0519135482609272
step: 160, loss: 0.12893900275230408
step: 170, loss: 0.07914607226848602
step: 180, loss: 0.1388699859380722
step: 190, loss: 0.23383548855781555
step: 200, loss: 0.20883379876613617
step: 210, loss: 0.16879209876060486
step: 220, loss: 0.09871357679367065
step: 230, loss: 0.1346295028924942
step: 240, loss: 0.14323611557483673
step: 250, loss: 0.11127478629350662
step: 260, loss: 0.04687406122684479
step: 270, loss: 0.15733909606933594
step: 280, loss: 0.1297214925289154
step: 290, loss: 0.12092050909996033
step: 300, loss: 0.22777903079986572
step: 310, loss: 0.2029547095298767
step: 320, loss: 0.15997318923473358
step: 330, loss: 0.032073043286800385
step: 340, loss: 0.13474918901920319
step: 350, loss: 0.08394162356853485
step: 360, loss: 0.16853806376457214
step: 370, loss: 0.10878541320562363
step: 380, loss: 0.12584327161312103
step: 390, loss: 0.13372984528541565
step: 400, loss: 0.11360729485750198
step: 410, loss: 0.15222550928592682
step: 420, loss: 0.17593300342559814
step: 430, loss: 0.05774390324950218
step: 440, loss: 0.06644109636545181
step: 450, loss: 0.052812185138463974
step: 460, loss: 0.0973856970667839
step: 470, loss: 0.14205877482891083
step: 480, loss: 0.09686216711997986
step: 490, loss: 0.13818170130252838
step: 500, loss: 0.09864725172519684
step: 510, loss: 0.08415808528661728
step: 520, loss: 0.04804376885294914
step: 530, loss: 0.14873825013637543
step: 540, loss: 0.05859455093741417
step: 550, loss: 0.09475598484277725
step: 560, loss: 0.0829387977719307
step: 570, loss: 0.09593093395233154
step: 580, loss: 0.07458831369876862
step: 590, loss: 0.12264247238636017
step: 600, loss: 0.10410290956497192
step: 610, loss: 0.025015754625201225
step: 620, loss: 0.3589933514595032
step: 630, loss: 0.18452484905719757
step: 640, loss: 0.15465083718299866
step: 650, loss: 0.23454530537128448
step: 660, loss: 0.11294928938150406
step: 670, loss: 0.14045850932598114
step: 680, loss: 0.07508284598588943
step: 690, loss: 0.0997876450419426
step: 700, loss: 0.2525879144668579
step: 710, loss: 0.15958259999752045
step: 720, loss: 0.09939969331026077
step: 730, loss: 0.04368773475289345
step: 740, loss: 0.09891436249017715
step: 750, loss: 0.24602340161800385
step: 760, loss: 0.09758759289979935
step: 770, loss: 0.06225027143955231
step: 780, loss: 0.1311129778623581
step: 790, loss: 0.11433940380811691
step: 800, loss: 0.14398415386676788
step: 810, loss: 0.11084350943565369
step: 820, loss: 0.13626322150230408
step: 830, loss: 0.15938758850097656
step: 840, loss: 0.09606403112411499
step: 850, loss: 0.07212522625923157
step: 860, loss: 0.16243503987789154
step: 870, loss: 0.10973863303661346
step: 880, loss: 0.12245413661003113
step: 890, loss: 0.20667551457881927
step: 900, loss: 0.18131209909915924
step: 910, loss: 0.0911756306886673
step: 920, loss: 0.24387094378471375
step: 930, loss: 0.1091027557849884
step: 940, loss: 0.07571285218000412
step: 950, loss: 0.15099602937698364
step: 960, loss: 0.06388306617736816
step: 970, loss: 0.17012494802474976
epoch 2: dev_f1=0.9189189189189189, f1=0.9130044843049326, best_f1=0.9130044843049326
step: 0, loss: 0.06797891855239868
step: 10, loss: 0.07150217145681381
step: 20, loss: 0.15736450254917145
step: 30, loss: 0.010932272300124168
step: 40, loss: 0.14744897186756134
step: 50, loss: 0.0833546593785286
step: 60, loss: 0.05438251048326492
step: 70, loss: 0.0868997648358345
step: 80, loss: 0.06986856460571289
step: 90, loss: 0.13838611543178558
step: 100, loss: 0.07214963436126709
step: 110, loss: 0.06322316080331802
step: 120, loss: 0.062023088335990906
step: 130, loss: 0.1664213240146637
step: 140, loss: 0.1383083015680313
step: 150, loss: 0.15854384005069733
step: 160, loss: 0.08600306510925293
step: 170, loss: 0.28104519844055176
step: 180, loss: 0.18073467910289764
step: 190, loss: 0.08598420768976212
step: 200, loss: 0.1414884328842163
step: 210, loss: 0.2195483148097992
step: 220, loss: 0.1532384604215622
step: 230, loss: 0.09184719622135162
step: 240, loss: 0.04374317824840546
step: 250, loss: 0.030143259093165398
step: 260, loss: 0.05774479731917381
step: 270, loss: 0.1020183339715004
step: 280, loss: 0.15446393191814423
step: 290, loss: 0.17278800904750824
step: 300, loss: 0.08406835794448853
step: 310, loss: 0.2874332666397095
step: 320, loss: 0.053001679480075836
step: 330, loss: 0.03380361944437027
step: 340, loss: 0.1797768473625183
step: 350, loss: 0.10662996768951416
step: 360, loss: 0.15466585755348206
step: 370, loss: 0.07015875726938248
step: 380, loss: 0.08365843445062637
step: 390, loss: 0.09749121963977814
step: 400, loss: 0.15912863612174988
step: 410, loss: 0.10298411548137665
step: 420, loss: 0.09848055988550186
step: 430, loss: 0.1197480708360672
step: 440, loss: 0.06598925590515137
step: 450, loss: 0.1095912978053093
step: 460, loss: 0.08833570033311844
step: 470, loss: 0.09106606245040894
step: 480, loss: 0.05663323402404785
step: 490, loss: 0.04270029813051224
step: 500, loss: 0.175828218460083
step: 510, loss: 0.034801553934812546
step: 520, loss: 0.06764612346887589
step: 530, loss: 0.06460553407669067
step: 540, loss: 0.1502651572227478
step: 550, loss: 0.12537866830825806
step: 560, loss: 0.05417948588728905
step: 570, loss: 0.11687686294317245
step: 580, loss: 0.08243725448846817
step: 590, loss: 0.10519935190677643
step: 600, loss: 0.12295079976320267
step: 610, loss: 0.10040519386529922
step: 620, loss: 0.0894368439912796
step: 630, loss: 0.0739467665553093
step: 640, loss: 0.10963717848062515
step: 650, loss: 0.08244754374027252
step: 660, loss: 0.17005610466003418
step: 670, loss: 0.10761406272649765
step: 680, loss: 0.08772153407335281
step: 690, loss: 0.1157636046409607
step: 700, loss: 0.2096613645553589
step: 710, loss: 0.15118765830993652
step: 720, loss: 0.09491054713726044
step: 730, loss: 0.048968568444252014
step: 740, loss: 0.10532763600349426
step: 750, loss: 0.10803229361772537
step: 760, loss: 0.3155929148197174
step: 770, loss: 0.14832507073879242
step: 780, loss: 0.10676459968090057
step: 790, loss: 0.13119369745254517
step: 800, loss: 0.14667870104312897
step: 810, loss: 0.10625480115413666
step: 820, loss: 0.04378201812505722
step: 830, loss: 0.04955240339040756
step: 840, loss: 0.23363372683525085
step: 850, loss: 0.09795788675546646
step: 860, loss: 0.4081059694290161
step: 870, loss: 0.0790739357471466
step: 880, loss: 0.06729817390441895
step: 890, loss: 0.1474652886390686
step: 900, loss: 0.1609373390674591
step: 910, loss: 0.10210676491260529
step: 920, loss: 0.029161697253584862
step: 930, loss: 0.08975300937891006
step: 940, loss: 0.13542905449867249
step: 950, loss: 0.1752808541059494
step: 960, loss: 0.13471610844135284
step: 970, loss: 0.19832096993923187
epoch 3: dev_f1=0.9310816978548607, f1=0.9248291571753987, best_f1=0.9248291571753987
step: 0, loss: 0.0792316123843193
step: 10, loss: 0.025599565356969833
step: 20, loss: 0.18099142611026764
step: 30, loss: 0.13039131462574005
step: 40, loss: 0.06837515532970428
step: 50, loss: 0.087519571185112
step: 60, loss: 0.12786497175693512
step: 70, loss: 0.13798099756240845
step: 80, loss: 0.21623021364212036
step: 90, loss: 0.1831795871257782
step: 100, loss: 0.10586308687925339
step: 110, loss: 0.12551665306091309
step: 120, loss: 0.10362476110458374
step: 130, loss: 0.03568050265312195
step: 140, loss: 0.02601194754242897
step: 150, loss: 0.2782593369483948
step: 160, loss: 0.09893365204334259
step: 170, loss: 0.11323012411594391
step: 180, loss: 0.14369651675224304
step: 190, loss: 0.06274110823869705
step: 200, loss: 0.07757426798343658
step: 210, loss: 0.06319651752710342
step: 220, loss: 0.11023394018411636
step: 230, loss: 0.09920099377632141
step: 240, loss: 0.030126934871077538
step: 250, loss: 0.13904204964637756
step: 260, loss: 0.11884874105453491
step: 270, loss: 0.14510689675807953
step: 280, loss: 0.19491486251354218
step: 290, loss: 0.09350918233394623
step: 300, loss: 0.09687475115060806
step: 310, loss: 0.07403986901044846
step: 320, loss: 0.14431792497634888
step: 330, loss: 0.0921979770064354
step: 340, loss: 0.0445249117910862
step: 350, loss: 0.17028196156024933
step: 360, loss: 0.042304906994104385
step: 370, loss: 0.12179350852966309
step: 380, loss: 0.15574711561203003
step: 390, loss: 0.05230310186743736
step: 400, loss: 0.22931961715221405
step: 410, loss: 0.15888912975788116
step: 420, loss: 0.18472149968147278
step: 430, loss: 0.042199984192848206
step: 440, loss: 0.08184201270341873
step: 450, loss: 0.1840282678604126
step: 460, loss: 0.06875507533550262
step: 470, loss: 0.0630297139286995
step: 480, loss: 0.061534732580184937
step: 490, loss: 0.12344752252101898
step: 500, loss: 0.03118443489074707
step: 510, loss: 0.16033300757408142
step: 520, loss: 0.08725228905677795
step: 530, loss: 0.12404520064592361
step: 540, loss: 0.12385202944278717
step: 550, loss: 0.020286833867430687
step: 560, loss: 0.10400737822055817
step: 570, loss: 0.06694160401821136
step: 580, loss: 0.2222949117422104
step: 590, loss: 0.06762979179620743
step: 600, loss: 0.11539721488952637
step: 610, loss: 0.10408708453178406
step: 620, loss: 0.07866726070642471
step: 630, loss: 0.0800318717956543
step: 640, loss: 0.0752878189086914
step: 650, loss: 0.21320584416389465
step: 660, loss: 0.10838261991739273
step: 670, loss: 0.09904927015304565
step: 680, loss: 0.14674803614616394
step: 690, loss: 0.261172354221344
step: 700, loss: 0.2000674605369568
step: 710, loss: 0.21127960085868835
step: 720, loss: 0.12341924756765366
step: 730, loss: 0.12066414207220078
step: 740, loss: 0.23722770810127258
step: 750, loss: 0.06302431225776672
step: 760, loss: 0.05143898352980614
step: 770, loss: 0.09639453887939453
step: 780, loss: 0.10034888237714767
step: 790, loss: 0.07929334044456482
step: 800, loss: 0.09184397757053375
step: 810, loss: 0.07162326574325562
step: 820, loss: 0.05654270946979523
step: 830, loss: 0.03356342762708664
step: 840, loss: 0.060062892735004425
step: 850, loss: 0.08792199939489365
step: 860, loss: 0.09585805982351303
step: 870, loss: 0.16979506611824036
step: 880, loss: 0.08530174195766449
step: 890, loss: 0.028318705037236214
step: 900, loss: 0.10402847081422806
step: 910, loss: 0.07483355700969696
step: 920, loss: 0.05822686851024628
step: 930, loss: 0.11315921694040298
step: 940, loss: 0.22842074930667877
step: 950, loss: 0.07753700762987137
step: 960, loss: 0.19190847873687744
step: 970, loss: 0.17726735770702362
epoch 4: dev_f1=0.935813953488372, f1=0.929784304726939, best_f1=0.929784304726939
step: 0, loss: 0.14517591893672943
step: 10, loss: 0.12221942096948624
step: 20, loss: 0.1297045350074768
step: 30, loss: 0.10400339215993881
step: 40, loss: 0.13854743540287018
step: 50, loss: 0.03490753471851349
step: 60, loss: 0.05266116186976433
step: 70, loss: 0.03918438032269478
step: 80, loss: 0.016031840816140175
step: 90, loss: 0.14516232907772064
step: 100, loss: 0.09758120030164719
step: 110, loss: 0.16524870693683624
step: 120, loss: 0.19438624382019043
step: 130, loss: 0.09121955186128616
step: 140, loss: 0.19458630681037903
step: 150, loss: 0.03242763876914978
step: 160, loss: 0.04672543331980705
step: 170, loss: 0.0561060830950737
step: 180, loss: 0.04160841926932335
step: 190, loss: 0.06138883903622627
step: 200, loss: 0.08754254132509232
step: 210, loss: 0.1602659970521927
step: 220, loss: 0.10263565927743912
step: 230, loss: 0.057878367602825165
step: 240, loss: 0.10915010422468185
step: 250, loss: 0.05350269377231598
step: 260, loss: 0.049972373992204666
step: 270, loss: 0.20277570188045502
step: 280, loss: 0.07089327275753021
step: 290, loss: 0.09478405863046646
step: 300, loss: 0.020275427028536797
step: 310, loss: 0.15605874359607697
step: 320, loss: 0.027332160621881485
step: 330, loss: 0.204219251871109
step: 340, loss: 0.13100479543209076
step: 350, loss: 0.05935627967119217
step: 360, loss: 0.11905616521835327
step: 370, loss: 0.046314503997564316
step: 380, loss: 0.07333113253116608
step: 390, loss: 0.11041149497032166
step: 400, loss: 0.12308108806610107
step: 410, loss: 0.1765233874320984
step: 420, loss: 0.1443183720111847
step: 430, loss: 0.04561474919319153
step: 440, loss: 0.08144321292638779
step: 450, loss: 0.026276694610714912
step: 460, loss: 0.118281289935112
step: 470, loss: 0.17313127219676971
step: 480, loss: 0.08499287068843842
step: 490, loss: 0.14611496031284332
step: 500, loss: 0.046098656952381134
step: 510, loss: 0.12606029212474823
step: 520, loss: 0.15695612132549286
step: 530, loss: 0.04133365675806999
step: 540, loss: 0.21642382442951202
step: 550, loss: 0.17346662282943726
step: 560, loss: 0.06624842435121536
step: 570, loss: 0.07824543118476868
step: 580, loss: 0.31050658226013184
step: 590, loss: 0.1307629644870758
step: 600, loss: 0.07278516888618469
step: 610, loss: 0.040801018476486206
step: 620, loss: 0.10897937417030334
step: 630, loss: 0.12049076706171036
step: 640, loss: 0.026726726442575455
step: 650, loss: 0.022984877228736877
step: 660, loss: 0.08168525248765945
step: 670, loss: 0.2731873393058777
step: 680, loss: 0.1660500466823578
step: 690, loss: 0.12931974232196808
step: 700, loss: 0.18294775485992432
step: 710, loss: 0.06291668117046356
step: 720, loss: 0.13042593002319336
step: 730, loss: 0.11084870249032974
step: 740, loss: 0.07480683922767639
step: 750, loss: 0.18687844276428223
step: 760, loss: 0.08804573118686676
step: 770, loss: 0.2944567799568176
step: 780, loss: 0.04453490301966667
step: 790, loss: 0.10988558828830719
step: 800, loss: 0.21910375356674194
step: 810, loss: 0.002543873153626919
step: 820, loss: 0.09925287961959839
step: 830, loss: 0.0548529177904129
step: 840, loss: 0.06323374807834625
step: 850, loss: 0.05837476998567581
step: 860, loss: 0.080293670296669
step: 870, loss: 0.11723596602678299
step: 880, loss: 0.22242556512355804
step: 890, loss: 0.18123950064182281
step: 900, loss: 0.05169915780425072
step: 910, loss: 0.08737380057573318
step: 920, loss: 0.09838128834962845
step: 930, loss: 0.02011440135538578
step: 940, loss: 0.17906896770000458
step: 950, loss: 0.1271338015794754
step: 960, loss: 0.1331784874200821
step: 970, loss: 0.0844012200832367
epoch 5: dev_f1=0.9368616527390901, f1=0.9334574220567706, best_f1=0.9334574220567706
step: 0, loss: 0.09698515385389328
step: 10, loss: 0.09466448426246643
step: 20, loss: 0.09523259848356247
step: 30, loss: 0.054680127650499344
step: 40, loss: 0.03941238671541214
step: 50, loss: 0.15172143280506134
step: 60, loss: 0.08236575871706009
step: 70, loss: 0.008517256006598473
step: 80, loss: 0.033648695796728134
step: 90, loss: 0.2676553428173065
step: 100, loss: 0.1281045824289322
step: 110, loss: 0.027697613462805748
step: 120, loss: 0.12399537116289139
step: 130, loss: 0.007108007557690144
step: 140, loss: 0.025917287915945053
step: 150, loss: 0.08080460131168365
step: 160, loss: 0.17739591002464294
step: 170, loss: 0.1436377316713333
step: 180, loss: 0.08225718885660172
step: 190, loss: 0.06320346891880035
step: 200, loss: 0.19131167232990265
step: 210, loss: 0.057459309697151184
step: 220, loss: 0.05337953940033913
step: 230, loss: 0.12636084854602814
step: 240, loss: 0.1291114240884781
step: 250, loss: 0.06717224419116974
step: 260, loss: 0.10621900111436844
step: 270, loss: 0.05947500467300415
step: 280, loss: 0.06289085000753403
step: 290, loss: 0.09860700368881226
step: 300, loss: 0.16793453693389893
step: 310, loss: 0.12689071893692017
step: 320, loss: 0.14506955444812775
step: 330, loss: 0.008741063997149467
step: 340, loss: 0.116399846971035
step: 350, loss: 0.09024429321289062
step: 360, loss: 0.07593228667974472
step: 370, loss: 0.10317762941122055
step: 380, loss: 0.11543388664722443
step: 390, loss: 0.0944744125008583
step: 400, loss: 0.033628787845373154
step: 410, loss: 0.08971651643514633
step: 420, loss: 0.18123137950897217
step: 430, loss: 0.07843858003616333
step: 440, loss: 0.06946893781423569
step: 450, loss: 0.02689426764845848
step: 460, loss: 0.06182079389691353
step: 470, loss: 0.054668083786964417
step: 480, loss: 0.06467323005199432
step: 490, loss: 0.11116485297679901
step: 500, loss: 0.0888371542096138
step: 510, loss: 0.10457250475883484
step: 520, loss: 0.06392897665500641
step: 530, loss: 0.008236764930188656
step: 540, loss: 0.10235137492418289
step: 550, loss: 0.12226825207471848
step: 560, loss: 0.021596094593405724
step: 570, loss: 0.1903056502342224
step: 580, loss: 0.12210938334465027
step: 590, loss: 0.06346702575683594
step: 600, loss: 0.0659979060292244
step: 610, loss: 0.06758831441402435
step: 620, loss: 0.11285705864429474
step: 630, loss: 0.1306208223104477
step: 640, loss: 0.07425349205732346
step: 650, loss: 0.059525489807128906
step: 660, loss: 0.14989742636680603
step: 670, loss: 0.0568174310028553
step: 680, loss: 0.23840244114398956
step: 690, loss: 0.10755909234285355
step: 700, loss: 0.08982287347316742
step: 710, loss: 0.07132016122341156
step: 720, loss: 0.08885324001312256
step: 730, loss: 0.1404281109571457
step: 740, loss: 0.10713799297809601
step: 750, loss: 0.14505043625831604
step: 760, loss: 0.20364275574684143
step: 770, loss: 0.02656581439077854
step: 780, loss: 0.1619294285774231
step: 790, loss: 0.07779955118894577
step: 800, loss: 0.06816387921571732
step: 810, loss: 0.11214340478181839
step: 820, loss: 0.10309521108865738
step: 830, loss: 0.14726562798023224
step: 840, loss: 0.13773493468761444
step: 850, loss: 0.03923392295837402
step: 860, loss: 0.12722104787826538
step: 870, loss: 0.04698614776134491
step: 880, loss: 0.12014704197645187
step: 890, loss: 0.09649316221475601
step: 900, loss: 0.03575779125094414
step: 910, loss: 0.10249659419059753
step: 920, loss: 0.16684716939926147
step: 930, loss: 0.1809965968132019
step: 940, loss: 0.09136329591274261
step: 950, loss: 0.20391502976417542
step: 960, loss: 0.07047906517982483
step: 970, loss: 0.041342318058013916
epoch 6: dev_f1=0.9313680331644404, f1=0.9245020842982862, best_f1=0.9334574220567706
step: 0, loss: 0.1273501217365265
step: 10, loss: 0.07086123526096344
step: 20, loss: 0.1841835230588913
step: 30, loss: 0.3266543745994568
step: 40, loss: 0.09145241975784302
step: 50, loss: 0.05397215485572815
step: 60, loss: 0.029316311702132225
step: 70, loss: 0.07512007653713226
step: 80, loss: 0.11659091711044312
step: 90, loss: 0.10230161249637604
step: 100, loss: 0.0620148740708828
step: 110, loss: 0.1462915688753128
step: 120, loss: 0.07177266478538513
step: 130, loss: 0.12418577075004578
step: 140, loss: 0.14022859930992126
step: 150, loss: 0.1215553730726242
step: 160, loss: 0.08447601646184921
step: 170, loss: 0.1492432951927185
step: 180, loss: 0.02224188670516014
step: 190, loss: 0.06059081107378006
step: 200, loss: 0.062034402042627335
step: 210, loss: 0.13371841609477997
step: 220, loss: 0.1368444561958313
step: 230, loss: 0.07952280342578888
step: 240, loss: 0.11617158353328705
step: 250, loss: 0.05669105798006058
step: 260, loss: 0.038774456828832626
step: 270, loss: 0.13127560913562775
step: 280, loss: 0.03616364300251007
step: 290, loss: 0.09282007068395615
step: 300, loss: 0.06605134159326553
step: 310, loss: 0.019254738464951515
step: 320, loss: 0.057277604937553406
step: 330, loss: 0.07523328065872192
step: 340, loss: 0.13427001237869263
step: 350, loss: 0.15369366109371185
step: 360, loss: 0.015786554664373398
step: 370, loss: 0.13946378231048584
step: 380, loss: 0.0937129408121109
step: 390, loss: 0.15356780588626862
step: 400, loss: 0.07048430293798447
step: 410, loss: 0.010234157554805279
step: 420, loss: 0.027291318401694298
step: 430, loss: 0.0753004401922226
step: 440, loss: 0.20215962827205658
step: 450, loss: 0.07226744294166565
step: 460, loss: 0.12094221264123917
step: 470, loss: 0.08854398131370544
step: 480, loss: 0.09920462220907211
step: 490, loss: 0.11273606866598129
step: 500, loss: 0.06075539439916611
step: 510, loss: 0.08309590071439743
step: 520, loss: 0.04105706885457039
step: 530, loss: 0.10739005357027054
step: 540, loss: 0.08207283169031143
step: 550, loss: 0.10940691828727722
step: 560, loss: 0.03818880766630173
step: 570, loss: 0.13902896642684937
step: 580, loss: 0.07843257486820221
step: 590, loss: 0.17282092571258545
step: 600, loss: 0.12645654380321503
step: 610, loss: 0.18356937170028687
step: 620, loss: 0.058498565107584
step: 630, loss: 0.04721474274992943
step: 640, loss: 0.1824263483285904
step: 650, loss: 0.05694074556231499
step: 660, loss: 0.07770697772502899
step: 670, loss: 0.08625297993421555
step: 680, loss: 0.07301654666662216
step: 690, loss: 0.06062100827693939
step: 700, loss: 0.2153233289718628
step: 710, loss: 0.12749727070331573
step: 720, loss: 0.12885020673274994
step: 730, loss: 0.09882452338933945
step: 740, loss: 0.05409020557999611
step: 750, loss: 0.1118258386850357
step: 760, loss: 0.014881767332553864
step: 770, loss: 0.039395809173583984
step: 780, loss: 0.13139258325099945
step: 790, loss: 0.13451628386974335
step: 800, loss: 0.13863568007946014
step: 810, loss: 0.03710714355111122
step: 820, loss: 0.042043931782245636
step: 830, loss: 0.1254236251115799
step: 840, loss: 0.0573379211127758
step: 850, loss: 0.08392428606748581
step: 860, loss: 0.09283683449029922
step: 870, loss: 0.1280200481414795
step: 880, loss: 0.08063801378011703
step: 890, loss: 0.21935158967971802
step: 900, loss: 0.15334779024124146
step: 910, loss: 0.09773032367229462
step: 920, loss: 0.2376171499490738
step: 930, loss: 0.012018595822155476
step: 940, loss: 0.05794471874833107
step: 950, loss: 0.062344130128622055
step: 960, loss: 0.13279634714126587
step: 970, loss: 0.11787612736225128
epoch 7: dev_f1=0.9323583180987203, f1=0.9291628334866605, best_f1=0.9334574220567706
step: 0, loss: 0.1473519653081894
step: 10, loss: 0.06888467073440552
step: 20, loss: 0.06480162590742111
step: 30, loss: 0.07598423957824707
step: 40, loss: 0.0987204983830452
step: 50, loss: 0.0971645638346672
step: 60, loss: 0.060538213700056076
step: 70, loss: 0.17732420563697815
step: 80, loss: 0.11008806526660919
step: 90, loss: 0.04355146735906601
step: 100, loss: 0.11286218464374542
step: 110, loss: 0.1317894011735916
step: 120, loss: 0.051310859620571136
step: 130, loss: 0.09809940308332443
step: 140, loss: 0.0397435799241066
step: 150, loss: 0.07892918586730957
step: 160, loss: 0.058589667081832886
step: 170, loss: 0.08450808376073837
step: 180, loss: 0.07947400957345963
step: 190, loss: 0.054400186985731125
step: 200, loss: 0.08092747628688812
step: 210, loss: 0.08791625499725342
step: 220, loss: 0.11298476159572601
step: 230, loss: 0.0753006637096405
step: 240, loss: 0.091008260846138
step: 250, loss: 0.15846768021583557
step: 260, loss: 0.01925957389175892
step: 270, loss: 0.025508282706141472
step: 280, loss: 0.155659481883049
step: 290, loss: 0.0843619629740715
step: 300, loss: 0.04974275454878807
step: 310, loss: 0.09600221365690231
step: 320, loss: 0.07484816759824753
step: 330, loss: 0.023324040696024895
step: 340, loss: 0.050173502415418625
step: 350, loss: 0.05402210354804993
step: 360, loss: 0.11245730519294739
step: 370, loss: 0.1214217096567154
step: 380, loss: 0.12301119416952133
step: 390, loss: 0.029753077775239944
step: 400, loss: 0.03729156777262688
step: 410, loss: 0.19383719563484192
step: 420, loss: 0.13209395110607147
step: 430, loss: 0.16485832631587982
step: 440, loss: 0.06533777713775635
step: 450, loss: 0.11804773658514023
step: 460, loss: 0.13408920168876648
step: 470, loss: 0.026662694290280342
step: 480, loss: 0.11008960008621216
step: 490, loss: 0.04837878793478012
step: 500, loss: 0.09360761940479279
step: 510, loss: 0.040782440453767776
step: 520, loss: 0.011863225139677525
step: 530, loss: 0.0487581267952919
step: 540, loss: 0.037768468260765076
step: 550, loss: 0.01819659397006035
step: 560, loss: 0.1118772104382515
step: 570, loss: 0.048008039593696594
step: 580, loss: 0.13916073739528656
step: 590, loss: 0.04099607467651367
step: 600, loss: 0.06230801343917847
step: 610, loss: 0.06270897388458252
step: 620, loss: 0.14992080628871918
step: 630, loss: 0.13153748214244843
step: 640, loss: 0.06636300683021545
step: 650, loss: 0.12432404607534409
step: 660, loss: 0.11551264673471451
step: 670, loss: 0.08667038381099701
step: 680, loss: 0.08132141828536987
step: 690, loss: 0.12473121285438538
step: 700, loss: 0.053027667105197906
step: 710, loss: 0.1586831510066986
step: 720, loss: 0.07484573870897293
step: 730, loss: 0.07589735090732574
step: 740, loss: 0.10949807614088058
step: 750, loss: 0.11102481186389923
step: 760, loss: 0.117728590965271
step: 770, loss: 0.12634752690792084
step: 780, loss: 0.030746428295969963
step: 790, loss: 0.0942297875881195
step: 800, loss: 0.23238298296928406
step: 810, loss: 0.11301154643297195
step: 820, loss: 0.09935413300991058
step: 830, loss: 0.047155894339084625
step: 840, loss: 0.12291970103979111
step: 850, loss: 0.14363649487495422
step: 860, loss: 0.046118538826704025
step: 870, loss: 0.05724147707223892
step: 880, loss: 0.07114683836698532
step: 890, loss: 0.028815392404794693
step: 900, loss: 0.12390122562646866
step: 910, loss: 0.15459731221199036
step: 920, loss: 0.07427676767110825
step: 930, loss: 0.17443256080150604
step: 940, loss: 0.15650293231010437
step: 950, loss: 0.09045064449310303
step: 960, loss: 0.09505200386047363
step: 970, loss: 0.12378533184528351
epoch 8: dev_f1=0.9327731092436975, f1=0.9276714885674288, best_f1=0.9334574220567706
step: 0, loss: 0.07015028595924377
step: 10, loss: 0.056697946041822433
step: 20, loss: 0.031154636293649673
step: 30, loss: 0.07770928740501404
step: 40, loss: 0.12677901983261108
step: 50, loss: 0.02438949979841709
step: 60, loss: 0.05434601381421089
step: 70, loss: 0.10796988755464554
step: 80, loss: 0.05936889722943306
step: 90, loss: 0.2199242264032364
step: 100, loss: 0.15918844938278198
step: 110, loss: 0.08054827153682709
step: 120, loss: 0.05553731694817543
step: 130, loss: 0.12261674553155899
step: 140, loss: 0.08657209575176239
step: 150, loss: 0.22554847598075867
step: 160, loss: 0.043200232088565826
step: 170, loss: 0.10948915034532547
step: 180, loss: 0.05831031873822212
step: 190, loss: 0.06921648234128952
step: 200, loss: 0.27458834648132324
step: 210, loss: 0.09621661901473999
step: 220, loss: 0.15998268127441406
step: 230, loss: 0.054902542382478714
step: 240, loss: 0.06749974191188812
step: 250, loss: 0.06077142059803009
step: 260, loss: 0.10820405930280685
step: 270, loss: 0.08310531079769135
step: 280, loss: 0.12164724618196487
step: 290, loss: 0.05645092576742172
step: 300, loss: 0.1566961258649826
step: 310, loss: 0.04961276054382324
step: 320, loss: 0.08045253902673721
step: 330, loss: 0.010462809354066849
step: 340, loss: 0.10497263818979263
step: 350, loss: 0.0865863785147667
step: 360, loss: 0.13952012360095978
step: 370, loss: 0.12290376424789429
step: 380, loss: 0.03323463350534439
step: 390, loss: 0.06829122453927994
step: 400, loss: 0.16220024228096008
step: 410, loss: 0.018955156207084656
step: 420, loss: 0.07871228456497192
step: 430, loss: 0.030345115810632706
step: 440, loss: 0.07685824483633041
step: 450, loss: 0.09603815525770187
step: 460, loss: 0.10309909284114838
step: 470, loss: 0.08635169267654419
step: 480, loss: 0.06734049320220947
step: 490, loss: 0.07854586094617844
step: 500, loss: 0.13671119511127472
step: 510, loss: 0.14957906305789948
step: 520, loss: 0.058918870985507965
step: 530, loss: 0.14567671716213226
step: 540, loss: 0.11161118000745773
step: 550, loss: 0.06257705390453339
step: 560, loss: 0.09388544410467148
step: 570, loss: 0.059587083756923676
step: 580, loss: 0.07922616600990295
step: 590, loss: 0.048257045447826385
step: 600, loss: 0.07406764477491379
step: 610, loss: 0.09578849375247955
step: 620, loss: 0.04641074314713478
step: 630, loss: 0.059625010937452316
step: 640, loss: 0.032968614250421524
step: 650, loss: 0.12173432111740112
step: 660, loss: 0.03911915421485901
step: 670, loss: 0.05078887939453125
step: 680, loss: 0.07011208683252335
step: 690, loss: 0.11337306350469589
step: 700, loss: 0.02992885187268257
step: 710, loss: 0.1317807286977768
step: 720, loss: 0.11683886498212814
step: 730, loss: 0.08838091045618057
step: 740, loss: 0.16747547686100006
step: 750, loss: 0.034249577671289444
step: 760, loss: 0.13014912605285645
step: 770, loss: 0.14138761162757874
step: 780, loss: 0.02243291772902012
step: 790, loss: 0.10268427431583405
step: 800, loss: 0.1382216215133667
step: 810, loss: 0.13247111439704895
step: 820, loss: 0.06116177514195442
step: 830, loss: 0.1480402797460556
step: 840, loss: 0.08849728107452393
step: 850, loss: 0.0354275144636631
step: 860, loss: 0.1349310278892517
step: 870, loss: 0.16549275815486908
step: 880, loss: 0.10865306854248047
step: 890, loss: 0.02757626213133335
step: 900, loss: 0.057421907782554626
step: 910, loss: 0.0936242938041687
step: 920, loss: 0.08867041766643524
step: 930, loss: 0.10066945105791092
step: 940, loss: 0.1819353997707367
step: 950, loss: 0.15205161273479462
step: 960, loss: 0.04598031938076019
step: 970, loss: 0.08767573535442352
epoch 9: dev_f1=0.9240037071362373, f1=0.9222894369474175, best_f1=0.9334574220567706
step: 0, loss: 0.06732166558504105
step: 10, loss: 0.1316060721874237
step: 20, loss: 0.03970831632614136
step: 30, loss: 0.05254397168755531
step: 40, loss: 0.020764457061886787
step: 50, loss: 0.14667834341526031
step: 60, loss: 0.05328158289194107
step: 70, loss: 0.08098854869604111
step: 80, loss: 0.013274656608700752
step: 90, loss: 0.09162761270999908
step: 100, loss: 0.08990520983934402
step: 110, loss: 0.04920874536037445
step: 120, loss: 0.13126835227012634
step: 130, loss: 0.06362606585025787
step: 140, loss: 0.07124517858028412
step: 150, loss: 0.06045901030302048
step: 160, loss: 0.017654957249760628
step: 170, loss: 0.09481081366539001
step: 180, loss: 0.022134259343147278
step: 190, loss: 0.055500578135252
step: 200, loss: 0.13961413502693176
step: 210, loss: 0.04490017145872116
step: 220, loss: 0.04039561375975609
step: 230, loss: 0.04937722906470299
step: 240, loss: 0.016937803477048874
step: 250, loss: 0.12722377479076385
step: 260, loss: 0.23332096636295319
step: 270, loss: 0.019092589616775513
step: 280, loss: 0.04450689256191254
step: 290, loss: 0.06292186677455902
step: 300, loss: 0.08575963973999023
step: 310, loss: 0.07527321577072144
step: 320, loss: 0.03223974630236626
step: 330, loss: 0.1054142490029335
step: 340, loss: 0.19535882771015167
step: 350, loss: 0.058587852865457535
step: 360, loss: 0.11298279464244843
step: 370, loss: 0.07072557508945465
step: 380, loss: 0.0653216540813446
step: 390, loss: 0.08375220000743866
step: 400, loss: 0.02983708307147026
step: 410, loss: 0.03614380210638046
step: 420, loss: 0.03859924525022507
step: 430, loss: 0.026919428259134293
step: 440, loss: 0.0655980035662651
step: 450, loss: 0.07531166821718216
step: 460, loss: 0.06061717867851257
step: 470, loss: 0.02189875952899456
step: 480, loss: 0.03287894278764725
step: 490, loss: 0.05871470272541046
step: 500, loss: 0.055084213614463806
step: 510, loss: 0.22704018652439117
step: 520, loss: 0.010220031253993511
step: 530, loss: 0.06827569752931595
step: 540, loss: 0.07242856174707413
step: 550, loss: 0.05559082329273224
step: 560, loss: 0.08351517468690872
step: 570, loss: 0.07755783945322037
step: 580, loss: 0.1016157865524292
step: 590, loss: 0.03768493980169296
step: 600, loss: 0.21995042264461517
step: 610, loss: 0.09789598733186722
step: 620, loss: 0.06265585869550705
step: 630, loss: 0.09817148000001907
step: 640, loss: 0.1952614039182663
step: 650, loss: 0.05375390872359276
step: 660, loss: 0.10310157388448715
step: 670, loss: 0.044127076864242554
step: 680, loss: 0.0520002506673336
step: 690, loss: 0.04891581833362579
step: 700, loss: 0.18619811534881592
step: 710, loss: 0.017054541036486626
step: 720, loss: 0.06684021651744843
step: 730, loss: 0.041864845901727676
step: 740, loss: 0.17072807252407074
step: 750, loss: 0.045242682099342346
step: 760, loss: 0.002076605102047324
step: 770, loss: 0.15071028470993042
step: 780, loss: 0.07119843363761902
step: 790, loss: 0.03007115051150322
step: 800, loss: 0.028258973732590675
step: 810, loss: 0.018605362623929977
step: 820, loss: 0.15766526758670807
step: 830, loss: 0.08077505975961685
step: 840, loss: 0.03788543492555618
step: 850, loss: 0.15940025448799133
step: 860, loss: 0.12307731807231903
step: 870, loss: 0.09479054808616638
step: 880, loss: 0.10083458572626114
step: 890, loss: 0.07756893336772919
step: 900, loss: 0.0627390667796135
step: 910, loss: 0.16131827235221863
step: 920, loss: 0.03751691058278084
step: 930, loss: 0.19800646603107452
step: 940, loss: 0.07164795696735382
step: 950, loss: 0.10925145447254181
step: 960, loss: 0.06370995193719864
step: 970, loss: 0.01311548426747322
epoch 10: dev_f1=0.9326473339569691, f1=0.9299482839680301, best_f1=0.9334574220567706
step: 0, loss: 0.0777219608426094
step: 10, loss: 0.06865827739238739
step: 20, loss: 0.059532761573791504
step: 30, loss: 0.10415654629468918
step: 40, loss: 0.06953771412372589
step: 50, loss: 0.12008161097764969
step: 60, loss: 0.23343269526958466
step: 70, loss: 0.07040107995271683
step: 80, loss: 0.1961957961320877
step: 90, loss: 0.08933926373720169
step: 100, loss: 0.021811679005622864
step: 110, loss: 0.08891964703798294
step: 120, loss: 0.11090793460607529
step: 130, loss: 0.02681320533156395
step: 140, loss: 0.09701155871152878
step: 150, loss: 0.08569646626710892
step: 160, loss: 0.10890898108482361
step: 170, loss: 0.08544450998306274
step: 180, loss: 0.10320190340280533
step: 190, loss: 0.1227697879076004
step: 200, loss: 0.10246607661247253
step: 210, loss: 0.02859017625451088
step: 220, loss: 0.024766830727458
step: 230, loss: 0.06846214830875397
step: 240, loss: 0.021826058626174927
step: 250, loss: 0.10564150661230087
step: 260, loss: 0.10773146152496338
step: 270, loss: 0.10300737619400024
step: 280, loss: 0.10156409442424774
step: 290, loss: 0.05500734597444534
step: 300, loss: 0.018943404778838158
step: 310, loss: 0.1335771679878235
step: 320, loss: 0.10437878221273422
step: 330, loss: 0.08344239741563797
step: 340, loss: 0.08715410530567169
step: 350, loss: 0.09694939106702805
step: 360, loss: 1.1727103810699191e-05
step: 370, loss: 0.05182201787829399
step: 380, loss: 0.05674823746085167
step: 390, loss: 0.04665733128786087
step: 400, loss: 0.03754888102412224
step: 410, loss: 0.07805664092302322
step: 420, loss: 0.07338345050811768
step: 430, loss: 0.0258256196975708
step: 440, loss: 0.05210486426949501
step: 450, loss: 0.020586621016263962
step: 460, loss: 0.012585937976837158
step: 470, loss: 0.043172355741262436
step: 480, loss: 0.051387060433626175
step: 490, loss: 0.05826536566019058
step: 500, loss: 0.11465342342853546
step: 510, loss: 0.09813589602708817
step: 520, loss: 0.18626868724822998
step: 530, loss: 0.029014283791184425
step: 540, loss: 0.006811350584030151
step: 550, loss: 0.10149519890546799
step: 560, loss: 0.05347143113613129
step: 570, loss: 0.025372810661792755
step: 580, loss: 0.13134536147117615
step: 590, loss: 0.2012961357831955
step: 600, loss: 0.06886368244886398
step: 610, loss: 0.15455147624015808
step: 620, loss: 0.13337552547454834
step: 630, loss: 0.06752876192331314
step: 640, loss: 0.05736856535077095
step: 650, loss: 0.23431800305843353
step: 660, loss: 0.12017025053501129
step: 670, loss: 0.1031731441617012
step: 680, loss: 0.11918330192565918
step: 690, loss: 0.14325565099716187
step: 700, loss: 0.05597016215324402
step: 710, loss: 0.0773361548781395
step: 720, loss: 0.0673167034983635
step: 730, loss: 0.11048532277345657
step: 740, loss: 0.003034894587472081
step: 750, loss: 0.0496353842318058
step: 760, loss: 0.11395235359668732
step: 770, loss: 0.029458731412887573
step: 780, loss: 0.08487748354673386
step: 790, loss: 0.1732637882232666
step: 800, loss: 0.0756397396326065
step: 810, loss: 0.030659513548016548
step: 820, loss: 0.069834403693676
step: 830, loss: 0.047063324600458145
step: 840, loss: 0.1177537813782692
step: 850, loss: 0.15667694807052612
step: 860, loss: 0.11094501614570618
step: 870, loss: 0.03327157720923424
step: 880, loss: 0.09360950440168381
step: 890, loss: 0.1124243438243866
step: 900, loss: 0.21863515675067902
step: 910, loss: 0.07636367529630661
step: 920, loss: 0.06736308336257935
step: 930, loss: 0.03015788458287716
step: 940, loss: 0.08581791818141937
step: 950, loss: 0.13428834080696106
step: 960, loss: 0.10679700970649719
step: 970, loss: 0.11191806942224503
epoch 11: dev_f1=0.9248716752216519, f1=0.9182624941616068, best_f1=0.9334574220567706
step: 0, loss: 0.10826560854911804
step: 10, loss: 0.031933896243572235
step: 20, loss: 0.022789031267166138
step: 30, loss: 0.11757887154817581
step: 40, loss: 0.0661558136343956
step: 50, loss: 0.013616763055324554
step: 60, loss: 0.10205910354852676
step: 70, loss: 0.12393993139266968
step: 80, loss: 0.015411820262670517
step: 90, loss: 0.07997605204582214
step: 100, loss: 0.08133874833583832
step: 110, loss: 0.1150139644742012
step: 120, loss: 0.14384497702121735
step: 130, loss: 0.02952699176967144
step: 140, loss: 0.012591002508997917
step: 150, loss: 0.09583324193954468
step: 160, loss: 0.07602400332689285
step: 170, loss: 0.08840209990739822
step: 180, loss: 0.10079072415828705
step: 190, loss: 0.13192535936832428
step: 200, loss: 0.05100117623806
step: 210, loss: 0.08956216275691986
step: 220, loss: 0.05999518930912018
step: 230, loss: 0.106871098279953
step: 240, loss: 0.07590961456298828
step: 250, loss: 0.18431931734085083
step: 260, loss: 0.04892376810312271
step: 270, loss: 0.026992853730916977
step: 280, loss: 0.1260872483253479
step: 290, loss: 0.16232822835445404
step: 300, loss: 0.059655267745256424
step: 310, loss: 0.038975946605205536
step: 320, loss: 0.007846691645681858
step: 330, loss: 0.12720495462417603
step: 340, loss: 0.061495520174503326
step: 350, loss: 0.14508894085884094
step: 360, loss: 0.01928536593914032
step: 370, loss: 0.03686875104904175
step: 380, loss: 0.02445284277200699
step: 390, loss: 0.03541172295808792
step: 400, loss: 0.12404371798038483
step: 410, loss: 0.062463805079460144
step: 420, loss: 0.022115472704172134
step: 430, loss: 0.08845644444227219
step: 440, loss: 0.0571453794836998
step: 450, loss: 0.08080805838108063
step: 460, loss: 0.0798865482211113
step: 470, loss: 0.056636419147253036
step: 480, loss: 0.04468167945742607
step: 490, loss: 0.09201812744140625
step: 500, loss: 0.04919051751494408
step: 510, loss: 0.11870857328176498
step: 520, loss: 0.1014968529343605
step: 530, loss: 0.002796560525894165
step: 540, loss: 0.024714870378375053
step: 550, loss: 0.03435168042778969
step: 560, loss: 0.1560896337032318
step: 570, loss: 0.02909422665834427
step: 580, loss: 0.009212145581841469
step: 590, loss: 0.02549181878566742
step: 600, loss: 0.017714975401759148
step: 610, loss: 0.05140189453959465
step: 620, loss: 0.12312328070402145
step: 630, loss: 0.06398532539606094
step: 640, loss: 0.15429791808128357
step: 650, loss: 0.10513658821582794
step: 660, loss: 0.09050903469324112
step: 670, loss: 0.04622582718729973
step: 680, loss: 0.06455793976783752
step: 690, loss: 0.07677239924669266
step: 700, loss: 0.13416551053524017
step: 710, loss: 0.0597340390086174
step: 720, loss: 0.09312079101800919
step: 730, loss: 0.16567641496658325
step: 740, loss: 0.012246071361005306
step: 750, loss: 0.04119260236620903
step: 760, loss: 0.0336538664996624
step: 770, loss: 0.10200343281030655
step: 780, loss: 0.0915665477514267
step: 790, loss: 0.05818486213684082
step: 800, loss: 0.06006383150815964
step: 810, loss: 0.028764929622411728
step: 820, loss: 0.09471587091684341
step: 830, loss: 0.05803939327597618
step: 840, loss: 0.10746406763792038
step: 850, loss: 0.08746589720249176
step: 860, loss: 0.02516755275428295
step: 870, loss: 0.007335939910262823
step: 880, loss: 0.059889715164899826
step: 890, loss: 0.08626678586006165
step: 900, loss: 0.08011680841445923
step: 910, loss: 0.18118388950824738
step: 920, loss: 0.058458469808101654
step: 930, loss: 0.04291326180100441
step: 940, loss: 0.0776444599032402
step: 950, loss: 0.08751270920038223
step: 960, loss: 0.02933715470135212
step: 970, loss: 0.06365296989679337
epoch 12: dev_f1=0.9322268326417704, f1=0.9228624535315985, best_f1=0.9334574220567706
step: 0, loss: 0.11177530884742737
step: 10, loss: 0.052310310304164886
step: 20, loss: 0.09082544595003128
step: 30, loss: 0.07936705648899078
step: 40, loss: 0.035793665796518326
step: 50, loss: 0.05319637805223465
step: 60, loss: 0.033266786485910416
step: 70, loss: 0.019465453922748566
step: 80, loss: 0.0003704130940604955
step: 90, loss: 0.1564231961965561
step: 100, loss: 0.026588276028633118
step: 110, loss: 0.032538287341594696
step: 120, loss: 0.07168175280094147
step: 130, loss: 0.020525475963950157
step: 140, loss: 0.11656901240348816
step: 150, loss: 0.08795072883367538
step: 160, loss: 0.12543204426765442
step: 170, loss: 0.047674503177404404
step: 180, loss: 0.0002657601435203105
step: 190, loss: 0.05455171316862106
step: 200, loss: 0.053462330251932144
step: 210, loss: 0.09150058776140213
step: 220, loss: 0.11397140473127365
step: 230, loss: 0.06831438839435577
step: 240, loss: 0.026082241907715797
step: 250, loss: 0.012091681361198425
step: 260, loss: 0.040237873792648315
step: 270, loss: 0.03655732050538063
step: 280, loss: 0.03399842977523804
step: 290, loss: 0.07876855880022049
step: 300, loss: 0.01883031241595745
step: 310, loss: 0.0879550650715828
step: 320, loss: 0.10102622210979462
step: 330, loss: 0.10669880360364914
step: 340, loss: 0.11282490193843842
step: 350, loss: 0.16521775722503662
step: 360, loss: 0.05000288784503937
step: 370, loss: 0.09658072888851166
step: 380, loss: 0.07327158749103546
step: 390, loss: 0.16665881872177124
step: 400, loss: 0.10522568970918655
step: 410, loss: 0.05136366933584213
step: 420, loss: 0.050689663738012314
step: 430, loss: 0.053285498172044754
step: 440, loss: 0.042420756071805954
step: 450, loss: 0.05169917643070221
step: 460, loss: 0.038089435547590256
step: 470, loss: 0.21427740156650543
step: 480, loss: 0.06409530341625214
step: 490, loss: 0.08633052557706833
step: 500, loss: 0.08825872838497162
step: 510, loss: 0.06909729540348053
step: 520, loss: 0.0711788684129715
step: 530, loss: 0.09081563353538513
step: 540, loss: 0.07454142719507217
step: 550, loss: 0.03895704448223114
step: 560, loss: 0.003573736408725381
step: 570, loss: 0.10828506946563721
step: 580, loss: 0.057669371366500854
step: 590, loss: 0.11462447792291641
step: 600, loss: 0.028159108012914658
step: 610, loss: 0.09408524632453918
step: 620, loss: 0.04474369436502457
step: 630, loss: 0.02617562748491764
step: 640, loss: 0.10063616186380386
step: 650, loss: 0.03737526759505272
step: 660, loss: 0.12929002940654755
step: 670, loss: 0.019044114276766777
step: 680, loss: 0.02434304729104042
step: 690, loss: 0.07287492603063583
step: 700, loss: 0.05430877208709717
step: 710, loss: 0.0604315921664238
step: 720, loss: 0.09027929604053497
step: 730, loss: 0.023795560002326965
step: 740, loss: 0.18365344405174255
step: 750, loss: 0.10626785457134247
step: 760, loss: 0.06879786401987076
step: 770, loss: 0.051384489983320236
step: 780, loss: 0.0003282759280409664
step: 790, loss: 0.11529681086540222
step: 800, loss: 0.07420079410076141
step: 810, loss: 0.026001790538430214
step: 820, loss: 0.051520008593797684
step: 830, loss: 0.06402510404586792
step: 840, loss: 0.11164887994527817
step: 850, loss: 0.024923056364059448
step: 860, loss: 0.055324189364910126
step: 870, loss: 0.005262480117380619
step: 880, loss: 0.06263464689254761
step: 890, loss: 0.09245743602514267
step: 900, loss: 0.036369457840919495
step: 910, loss: 0.10196493566036224
step: 920, loss: 0.028254477307200432
step: 930, loss: 0.028889773413538933
step: 940, loss: 0.0541577972471714
step: 950, loss: 0.05868638679385185
step: 960, loss: 0.028961393982172012
step: 970, loss: 0.032135311514139175
epoch 13: dev_f1=0.923581809657759, f1=0.9250234301780694, best_f1=0.9334574220567706
step: 0, loss: 0.07143177837133408
step: 10, loss: 0.07168092578649521
step: 20, loss: 0.049105510115623474
step: 30, loss: 0.016826381906867027
step: 40, loss: 0.22569431364536285
step: 50, loss: 0.013687691651284695
step: 60, loss: 0.03271973505616188
step: 70, loss: 0.03586659952998161
step: 80, loss: 0.05773737281560898
step: 90, loss: 0.08056110143661499
step: 100, loss: 0.049830302596092224
step: 110, loss: 0.16547682881355286
step: 120, loss: 0.012584739364683628
step: 130, loss: 0.02511981874704361
step: 140, loss: 0.0005596629926003516
step: 150, loss: 0.00043599845957942307
step: 160, loss: 0.054519109427928925
step: 170, loss: 0.056377727538347244
step: 180, loss: 0.0369509682059288
step: 190, loss: 0.05143454298377037
step: 200, loss: 0.0701679214835167
step: 210, loss: 0.05965828895568848
step: 220, loss: 0.04380534961819649
step: 230, loss: 0.06309103965759277
step: 240, loss: 0.06261653453111649
step: 250, loss: 0.05172839015722275
step: 260, loss: 0.08308670669794083
step: 270, loss: 9.856372344074771e-05
step: 280, loss: 0.06511934101581573
step: 290, loss: 0.022530624642968178
step: 300, loss: 0.07250326126813889
step: 310, loss: 0.038099922239780426
step: 320, loss: 0.08210068941116333
step: 330, loss: 0.09995070844888687
step: 340, loss: 0.06478385627269745
step: 350, loss: 0.015559487976133823
step: 360, loss: 0.022435646504163742
step: 370, loss: 0.07033948600292206
step: 380, loss: 0.023604856804013252
step: 390, loss: 0.09234496206045151
step: 400, loss: 0.06550391018390656
step: 410, loss: 0.002388077089563012
step: 420, loss: 0.12943434715270996
step: 430, loss: 0.07582847774028778
step: 440, loss: 0.0577770471572876
step: 450, loss: 0.03288025036454201
step: 460, loss: 0.10039886087179184
step: 470, loss: 0.08164180815219879
step: 480, loss: 0.051103100180625916
step: 490, loss: 0.03440459072589874
step: 500, loss: 0.11723417788743973
step: 510, loss: 0.12643377482891083
step: 520, loss: 0.026249324902892113
step: 530, loss: 0.021954186260700226
step: 540, loss: 0.10769587010145187
step: 550, loss: 0.027724966406822205
step: 560, loss: 0.0809488296508789
step: 570, loss: 0.05195171758532524
step: 580, loss: 0.002022374887019396
step: 590, loss: 0.040286701172590256
step: 600, loss: 0.015440915711224079
step: 610, loss: 0.09897613525390625
step: 620, loss: 0.021559080109000206
step: 630, loss: 0.015824513509869576
step: 640, loss: 0.05741025507450104
step: 650, loss: 0.054677415639162064
step: 660, loss: 0.07558589428663254
step: 670, loss: 0.12323687225580215
step: 680, loss: 0.14869005978107452
step: 690, loss: 0.08597748726606369
step: 700, loss: 0.18693900108337402
step: 710, loss: 0.021124394610524178
step: 720, loss: 0.08214778453111649
step: 730, loss: 0.12663154304027557
step: 740, loss: 0.009009890258312225
step: 750, loss: 0.04030344635248184
step: 760, loss: 0.03817871958017349
step: 770, loss: 0.10490724444389343
step: 780, loss: 0.08113846927881241
step: 790, loss: 0.10386282950639725
step: 800, loss: 0.1014624685049057
step: 810, loss: 0.10082344710826874
step: 820, loss: 0.011054063215851784
step: 830, loss: 0.0999557375907898
step: 840, loss: 0.06883782893419266
step: 850, loss: 0.029256176203489304
step: 860, loss: 0.04669816419482231
step: 870, loss: 0.0031875709537416697
step: 880, loss: 0.10174549371004105
step: 890, loss: 0.14479203522205353
step: 900, loss: 0.08481335639953613
step: 910, loss: 0.07644762098789215
step: 920, loss: 0.11697328090667725
step: 930, loss: 0.04880744218826294
step: 940, loss: 0.07766922563314438
step: 950, loss: 0.023613622412085533
step: 960, loss: 0.07889197021722794
step: 970, loss: 0.028117207810282707
epoch 14: dev_f1=0.9309865678554886, f1=0.9262371615312792, best_f1=0.9334574220567706
step: 0, loss: 0.02365882694721222
step: 10, loss: 0.059125933796167374
step: 20, loss: 0.03406672924757004
step: 30, loss: 0.022744279354810715
step: 40, loss: 0.07932531833648682
step: 50, loss: 0.05853663384914398
step: 60, loss: 0.04803461208939552
step: 70, loss: 0.059832457453012466
step: 80, loss: 0.09215859323740005
step: 90, loss: 0.04465536028146744
step: 100, loss: 0.048201605677604675
step: 110, loss: 0.029996875673532486
step: 120, loss: 0.089472196996212
step: 130, loss: 0.047960035502910614
step: 140, loss: 0.0650119036436081
step: 150, loss: 0.07139846682548523
step: 160, loss: 0.023566650226712227
step: 170, loss: 0.07689882069826126
step: 180, loss: 0.09362933039665222
step: 190, loss: 0.0977087914943695
step: 200, loss: 0.054007504135370255
step: 210, loss: 0.007958924397826195
step: 220, loss: 0.0004212711355648935
step: 230, loss: 0.1055247038602829
step: 240, loss: 0.07370789349079132
step: 250, loss: 0.08492965996265411
step: 260, loss: 0.038228362798690796
step: 270, loss: 0.0459178164601326
step: 280, loss: 0.13851214945316315
step: 290, loss: 0.03715260326862335
step: 300, loss: 0.02091929130256176
step: 310, loss: 0.09023028612136841
step: 320, loss: 0.07452718168497086
step: 330, loss: 0.13780885934829712
step: 340, loss: 0.13327202200889587
step: 350, loss: 0.015252867713570595
step: 360, loss: 0.10402452945709229
step: 370, loss: 0.016117505729198456
step: 380, loss: 0.02591526322066784
step: 390, loss: 0.03456960245966911
step: 400, loss: 0.025103431195020676
step: 410, loss: 0.011292865499854088
step: 420, loss: 0.05032111331820488
step: 430, loss: 0.01944383792579174
step: 440, loss: 0.06484557688236237
step: 450, loss: 0.00014323490904644132
step: 460, loss: 0.04968459531664848
step: 470, loss: 0.07404268532991409
step: 480, loss: 0.21471823751926422
step: 490, loss: 0.056817177683115005
step: 500, loss: 0.1668766587972641
step: 510, loss: 0.0815584734082222
step: 520, loss: 0.04354545846581459
step: 530, loss: 0.05728315934538841
step: 540, loss: 0.09236657619476318
step: 550, loss: 0.10905914753675461
step: 560, loss: 0.02618984691798687
step: 570, loss: 0.03871513903141022
step: 580, loss: 0.07861939817667007
step: 590, loss: 0.03210820257663727
step: 600, loss: 0.07980787754058838
step: 610, loss: 0.05242450162768364
step: 620, loss: 0.10293757915496826
step: 630, loss: 0.08629105985164642
step: 640, loss: 0.04765954241156578
step: 650, loss: 0.09354935586452484
step: 660, loss: 0.06718873977661133
step: 670, loss: 0.08113507181406021
step: 680, loss: 0.04043586179614067
step: 690, loss: 0.019389307126402855
step: 700, loss: 0.19504061341285706
step: 710, loss: 0.07549262791872025
step: 720, loss: 0.043375395238399506
step: 730, loss: 0.08699753880500793
step: 740, loss: 0.07512258738279343
step: 750, loss: 0.08802342414855957
step: 760, loss: 0.08921898156404495
step: 770, loss: 0.07919608056545258
step: 780, loss: 0.041891682893037796
step: 790, loss: 0.11032111942768097
step: 800, loss: 0.1225474551320076
step: 810, loss: 0.12062492966651917
step: 820, loss: 0.023896975442767143
step: 830, loss: 0.045477692037820816
step: 840, loss: 0.05314921587705612
step: 850, loss: 0.06770022958517075
step: 860, loss: 0.10138332098722458
step: 870, loss: 0.03377009555697441
step: 880, loss: 0.09814706444740295
step: 890, loss: 0.09652584791183472
step: 900, loss: 0.007726168259978294
step: 910, loss: 0.0004319173167459667
step: 920, loss: 0.07282789796590805
step: 930, loss: 0.12406615167856216
step: 940, loss: 0.0627087727189064
step: 950, loss: 0.06021963804960251
step: 960, loss: 0.021873684599995613
step: 970, loss: 0.12267284840345383
epoch 15: dev_f1=0.93202062822316, f1=0.9318288669487541, best_f1=0.9334574220567706
step: 0, loss: 0.04439469799399376
step: 10, loss: 0.11918728798627853
step: 20, loss: 0.0372176393866539
step: 30, loss: 0.02018534578382969
step: 40, loss: 0.058187440037727356
step: 50, loss: 0.036972835659980774
step: 60, loss: 0.10965850204229355
step: 70, loss: 0.02575361356139183
step: 80, loss: 0.0670260414481163
step: 90, loss: 0.015650101006031036
step: 100, loss: 0.02233700081706047
step: 110, loss: 0.06633015722036362
step: 120, loss: 0.12028583884239197
step: 130, loss: 5.307943501975387e-05
step: 140, loss: 0.057311274111270905
step: 150, loss: 0.06526493281126022
step: 160, loss: 0.0543929859995842
step: 170, loss: 0.03022768348455429
step: 180, loss: 0.024565838277339935
step: 190, loss: 0.057514213025569916
step: 200, loss: 0.026618264615535736
step: 210, loss: 0.04315575584769249
step: 220, loss: 0.029313884675502777
step: 230, loss: 0.07333169877529144
step: 240, loss: 0.05299852415919304
step: 250, loss: 0.019517572596669197
step: 260, loss: 0.04310156777501106
step: 270, loss: 0.1426735520362854
step: 280, loss: 0.005158704239875078
step: 290, loss: 0.02940474823117256
step: 300, loss: 0.0454644039273262
step: 310, loss: 0.026577068492770195
step: 320, loss: 0.0717925876379013
step: 330, loss: 0.025730470195412636
step: 340, loss: 0.007428851444274187
step: 350, loss: 0.0391867496073246
step: 360, loss: 0.08503465354442596
step: 370, loss: 0.03056919574737549
step: 380, loss: 0.08150921761989594
step: 390, loss: 0.026642000302672386
step: 400, loss: 0.07853882759809494
step: 410, loss: 0.020939141511917114
step: 420, loss: 0.10106541961431503
step: 430, loss: 0.033695511519908905
step: 440, loss: 0.06452330201864243
step: 450, loss: 0.06927938014268875
step: 460, loss: 0.04326239228248596
step: 470, loss: 0.049755170941352844
step: 480, loss: 0.003272361820563674
step: 490, loss: 0.020609179511666298
step: 500, loss: 0.11248144507408142
step: 510, loss: 0.10323324054479599
step: 520, loss: 0.11896632611751556
step: 530, loss: 0.02336016669869423
step: 540, loss: 0.02114306204020977
step: 550, loss: 0.056901443749666214
step: 560, loss: 0.04406291991472244
step: 570, loss: 0.023015987128019333
step: 580, loss: 0.06356724351644516
step: 590, loss: 0.041780415922403336
step: 600, loss: 0.11644221842288971
step: 610, loss: 0.035213373601436615
step: 620, loss: 0.046618130058050156
step: 630, loss: 0.016863606870174408
step: 640, loss: 0.0019241257105022669
step: 650, loss: 0.02843751385807991
step: 660, loss: 0.024027753621339798
step: 670, loss: 0.042067721486091614
step: 680, loss: 0.06201260909438133
step: 690, loss: 0.09867938607931137
step: 700, loss: 0.060411542654037476
step: 710, loss: 0.0002474966167937964
step: 720, loss: 0.11929432302713394
step: 730, loss: 0.08807378262281418
step: 740, loss: 0.027653319761157036
step: 750, loss: 0.060354817658662796
step: 760, loss: 0.02238033525645733
step: 770, loss: 0.0996239110827446
step: 780, loss: 0.06930972635746002
step: 790, loss: 0.06722164154052734
step: 800, loss: 0.022267304360866547
step: 810, loss: 0.06022028625011444
step: 820, loss: 0.04795776307582855
step: 830, loss: 0.02501554973423481
step: 840, loss: 0.07085474580526352
step: 850, loss: 0.0500066839158535
step: 860, loss: 0.024532461538910866
step: 870, loss: 0.09559054672718048
step: 880, loss: 0.04517180100083351
step: 890, loss: 0.00044676067773252726
step: 900, loss: 0.05602927505970001
step: 910, loss: 0.057821329683065414
step: 920, loss: 0.06653418391942978
step: 930, loss: 0.07904795557260513
step: 940, loss: 0.0246523879468441
step: 950, loss: 0.11262083053588867
step: 960, loss: 0.04755553603172302
step: 970, loss: 0.06101005896925926
epoch 16: dev_f1=0.9333945796968306, f1=0.92814093648586, best_f1=0.9334574220567706
step: 0, loss: 0.02828545682132244
step: 10, loss: 0.05744889751076698
step: 20, loss: 0.04587377607822418
step: 30, loss: 0.023747900500893593
step: 40, loss: 0.029426001012325287
step: 50, loss: 0.04503989964723587
step: 60, loss: 0.05417622625827789
step: 70, loss: 0.05459515005350113
step: 80, loss: 0.03634755685925484
step: 90, loss: 0.053180962800979614
step: 100, loss: 0.02826332300901413
step: 110, loss: 0.020185384899377823
step: 120, loss: 0.08308252692222595
step: 130, loss: 0.0010593296028673649
step: 140, loss: 0.06285276263952255
step: 150, loss: 0.07967641204595566
step: 160, loss: 0.08146342635154724
step: 170, loss: 0.05720880255103111
step: 180, loss: 0.013729686848819256
step: 190, loss: 0.021778570488095284
step: 200, loss: 0.06972761452198029
step: 210, loss: 0.12617214024066925
step: 220, loss: 0.00033808642183430493
step: 230, loss: 0.04093117639422417
step: 240, loss: 0.01717216521501541
step: 250, loss: 0.11769217252731323
step: 260, loss: 0.10289633274078369
step: 270, loss: 0.05010227486491203
step: 280, loss: 0.02022908255457878
step: 290, loss: 0.11894576251506805
step: 300, loss: 0.036591462790966034
step: 310, loss: 0.022153548896312714
step: 320, loss: 0.09656978398561478
step: 330, loss: 0.01881772093474865
step: 340, loss: 0.014071083627641201
step: 350, loss: 0.021612465381622314
step: 360, loss: 0.016840849071741104
step: 370, loss: 0.04907115548849106
step: 380, loss: 0.043103016912937164
step: 390, loss: 0.10375125706195831
step: 400, loss: 0.1100531816482544
step: 410, loss: 0.11386598646640778
step: 420, loss: 0.03185684233903885
step: 430, loss: 0.12329578399658203
step: 440, loss: 0.13896434009075165
step: 450, loss: 0.10730130225419998
step: 460, loss: 0.04562188684940338
step: 470, loss: 0.023839619010686874
step: 480, loss: 0.006509828846901655
step: 490, loss: 0.006811782717704773
step: 500, loss: 0.10866281390190125
step: 510, loss: 0.21558164060115814
step: 520, loss: 0.11931566894054413
step: 530, loss: 0.06998565793037415
step: 540, loss: 0.08004402369260788
step: 550, loss: 0.07638190686702728
step: 560, loss: 0.03445998951792717
step: 570, loss: 0.05949018895626068
step: 580, loss: 0.03369782865047455
step: 590, loss: 0.028870726004242897
step: 600, loss: 0.05612637847661972
step: 610, loss: 0.00026931625325232744
step: 620, loss: 0.08762624114751816
step: 630, loss: 0.034531038254499435
step: 640, loss: 0.04153924435377121
step: 650, loss: 0.08259414881467819
step: 660, loss: 0.05991242825984955
step: 670, loss: 0.09014499187469482
step: 680, loss: 0.05989829823374748
step: 690, loss: 0.036020033061504364
step: 700, loss: 0.04774336516857147
step: 710, loss: 0.000176404690137133
step: 720, loss: 0.02741648629307747
step: 730, loss: 0.08605921268463135
step: 740, loss: 0.03476809337735176
step: 750, loss: 0.037760179489851
step: 760, loss: 0.08308783918619156
step: 770, loss: 0.05299133062362671
step: 780, loss: 0.0001321185554843396
step: 790, loss: 0.10538899153470993
step: 800, loss: 0.07929050922393799
step: 810, loss: 0.12091921269893646
step: 820, loss: 0.05020519718527794
step: 830, loss: 0.0002264861250296235
step: 840, loss: 0.0608031339943409
step: 850, loss: 0.0635976567864418
step: 860, loss: 0.042148977518081665
step: 870, loss: 0.0146931242197752
step: 880, loss: 0.01910577528178692
step: 890, loss: 4.251776772434823e-05
step: 900, loss: 0.08592377603054047
step: 910, loss: 5.7098975958069786e-05
step: 920, loss: 0.07068982720375061
step: 930, loss: 0.061119891703128815
step: 940, loss: 0.05221446231007576
step: 950, loss: 0.04745826870203018
step: 960, loss: 0.025146866217255592
step: 970, loss: 0.019341938197612762
epoch 17: dev_f1=0.9251059821008009, f1=0.9244570349386214, best_f1=0.9334574220567706
step: 0, loss: 0.027488254010677338
step: 10, loss: 0.006186910904943943
step: 20, loss: 0.08482275158166885
step: 30, loss: 0.01475975476205349
step: 40, loss: 0.10630281269550323
step: 50, loss: 0.03729327395558357
step: 60, loss: 0.11324968189001083
step: 70, loss: 0.14316971600055695
step: 80, loss: 0.028760487213730812
step: 90, loss: 0.06657491624355316
step: 100, loss: 0.02584354765713215
step: 110, loss: 0.004368164576590061
step: 120, loss: 0.023831576108932495
step: 130, loss: 0.06164077669382095
step: 140, loss: 4.5718392357230186e-05
step: 150, loss: 0.04870880767703056
step: 160, loss: 0.053501032292842865
step: 170, loss: 0.04074150696396828
step: 180, loss: 0.01878654584288597
step: 190, loss: 0.0302971750497818
step: 200, loss: 0.05506615713238716
step: 210, loss: 0.04715472832322121
step: 220, loss: 0.027746077626943588
step: 230, loss: 0.09121208637952805
step: 240, loss: 0.04903250187635422
step: 250, loss: 0.014986664056777954
step: 260, loss: 0.023924661800265312
step: 270, loss: 0.052646100521087646
step: 280, loss: 1.2982376574655063e-05
step: 290, loss: 0.10853838175535202
step: 300, loss: 0.026629161089658737
step: 310, loss: 0.012424759566783905
step: 320, loss: 0.1354823261499405
step: 330, loss: 0.0472632460296154
step: 340, loss: 0.12493916600942612
step: 350, loss: 0.04007748141884804
step: 360, loss: 0.06739328056573868
step: 370, loss: 0.04271761327981949
step: 380, loss: 0.0002220765018137172
step: 390, loss: 0.03588832914829254
step: 400, loss: 0.04558096453547478
step: 410, loss: 0.07612652331590652
step: 420, loss: 0.03375842049717903
step: 430, loss: 0.011357276700437069
step: 440, loss: 0.11132466793060303
step: 450, loss: 0.031871359795331955
step: 460, loss: 0.04802832379937172
step: 470, loss: 0.0002459322568029165
step: 480, loss: 0.07291111350059509
step: 490, loss: 0.0476360097527504
step: 500, loss: 0.014441480860114098
step: 510, loss: 0.0054930527694523335
step: 520, loss: 0.08256234973669052
step: 530, loss: 0.017274439334869385
step: 540, loss: 0.06612803786993027
step: 550, loss: 0.024375244975090027
step: 560, loss: 0.08240486681461334
step: 570, loss: 0.08021730184555054
step: 580, loss: 0.11344070732593536
step: 590, loss: 0.03179987519979477
step: 600, loss: 0.017353875562548637
step: 610, loss: 0.10524237155914307
step: 620, loss: 0.050801437348127365
step: 630, loss: 0.02237028442323208
step: 640, loss: 0.0013991043670102954
step: 650, loss: 0.041025929152965546
step: 660, loss: 0.018755169585347176
step: 670, loss: 0.021121172234416008
step: 680, loss: 0.08494551479816437
step: 690, loss: 0.018448712304234505
step: 700, loss: 0.03530037775635719
step: 710, loss: 0.1093805655837059
step: 720, loss: 0.10595668107271194
step: 730, loss: 6.812177161918953e-05
step: 740, loss: 0.03650502488017082
step: 750, loss: 0.0001741209125611931
step: 760, loss: 0.050499651581048965
step: 770, loss: 0.06597694754600525
step: 780, loss: 0.051441166549921036
step: 790, loss: 0.05654723569750786
step: 800, loss: 0.01460008043795824
step: 810, loss: 0.03946685791015625
step: 820, loss: 0.02620876580476761
step: 830, loss: 0.0255444198846817
step: 840, loss: 0.040193166583776474
step: 850, loss: 0.0010963411768898368
step: 860, loss: 0.014115235768258572
step: 870, loss: 0.035600174218416214
step: 880, loss: 0.049911100417375565
step: 890, loss: 0.07503755390644073
step: 900, loss: 0.038918204605579376
step: 910, loss: 0.05229716747999191
step: 920, loss: 0.019894566386938095
step: 930, loss: 0.11484541743993759
step: 940, loss: 0.15533819794654846
step: 950, loss: 0.030032509937882423
step: 960, loss: 0.03921627253293991
step: 970, loss: 0.09176389873027802
epoch 18: dev_f1=0.9298000929800094, f1=0.9271028037383178, best_f1=0.9334574220567706
step: 0, loss: 0.048331424593925476
step: 10, loss: 0.03644561767578125
step: 20, loss: 0.04470067098736763
step: 30, loss: 1.5101504686754197e-05
step: 40, loss: 0.000452922162367031
step: 50, loss: 0.002653147093951702
step: 60, loss: 4.7865614760667086e-05
step: 70, loss: 0.03428367152810097
step: 80, loss: 0.018327202647924423
step: 90, loss: 0.02667953073978424
step: 100, loss: 0.06228983402252197
step: 110, loss: 0.030251139774918556
step: 120, loss: 0.01805972121655941
step: 130, loss: 0.012798075564205647
step: 140, loss: 0.03685302659869194
step: 150, loss: 0.03146424517035484
step: 160, loss: 0.04440062865614891
step: 170, loss: 0.02882816269993782
step: 180, loss: 0.02729659155011177
step: 190, loss: 0.03082270361483097
step: 200, loss: 0.06634007394313812
step: 210, loss: 0.012236885726451874
step: 220, loss: 0.025653844699263573
step: 230, loss: 0.04037663713097572
step: 240, loss: 0.03894584998488426
step: 250, loss: 0.10859168320894241
step: 260, loss: 0.09782169759273529
step: 270, loss: 0.07392127811908722
step: 280, loss: 0.04002867266535759
step: 290, loss: 0.09671652317047119
step: 300, loss: 0.0886419415473938
step: 310, loss: 0.007513022981584072
step: 320, loss: 0.10924868285655975
step: 330, loss: 0.02397644706070423
step: 340, loss: 0.05145784094929695
step: 350, loss: 0.027870070189237595
step: 360, loss: 0.00014317358727566898
step: 370, loss: 0.05505926162004471
step: 380, loss: 0.021477770060300827
step: 390, loss: 0.042916059494018555
step: 400, loss: 0.05202513933181763
step: 410, loss: 0.0792878121137619
step: 420, loss: 0.12405604124069214
step: 430, loss: 0.08331358432769775
step: 440, loss: 0.00014745304360985756
step: 450, loss: 0.03083864226937294
step: 460, loss: 7.930121500976384e-05
step: 470, loss: 0.0664687529206276
step: 480, loss: 0.13180823624134064
step: 490, loss: 0.033337339758872986
step: 500, loss: 0.077422596514225
step: 510, loss: 0.037047360092401505
step: 520, loss: 0.1079222783446312
step: 530, loss: 0.003481874242424965
step: 540, loss: 0.06004009395837784
step: 550, loss: 1.8519804143579677e-05
step: 560, loss: 0.01567363552749157
step: 570, loss: 0.07477149367332458
step: 580, loss: 0.04482249543070793
step: 590, loss: 0.0814734399318695
step: 600, loss: 0.08675199002027512
step: 610, loss: 0.04164594039320946
step: 620, loss: 0.03240416198968887
step: 630, loss: 0.014626037329435349
step: 640, loss: 0.06217653304338455
step: 650, loss: 0.11734390258789062
step: 660, loss: 0.007728201802819967
step: 670, loss: 0.044462841004133224
step: 680, loss: 0.04261837527155876
step: 690, loss: 0.06463474780321121
step: 700, loss: 0.023172693327069283
step: 710, loss: 0.05903282389044762
step: 720, loss: 0.0584615021944046
step: 730, loss: 0.05119886249303818
step: 740, loss: 0.034117937088012695
step: 750, loss: 0.01930416375398636
step: 760, loss: 0.03472419083118439
step: 770, loss: 0.11387960612773895
step: 780, loss: 0.03797866031527519
step: 790, loss: 0.04019636660814285
step: 800, loss: 0.005935395136475563
step: 810, loss: 0.24862071871757507
step: 820, loss: 0.021347258239984512
step: 830, loss: 0.07540224492549896
step: 840, loss: 0.06780244410037994
step: 850, loss: 0.02734680473804474
step: 860, loss: 0.04458983987569809
step: 870, loss: 0.03577406704425812
step: 880, loss: 7.653830107301474e-05
step: 890, loss: 0.026457248255610466
step: 900, loss: 0.10098125785589218
step: 910, loss: 0.029557591304183006
step: 920, loss: 0.05286061763763428
step: 930, loss: 0.12286835163831711
step: 940, loss: 0.04484819993376732
step: 950, loss: 0.05652843415737152
step: 960, loss: 0.04357818141579628
step: 970, loss: 0.03016066364943981
epoch 19: dev_f1=0.9289363678588016, f1=0.9258741258741259, best_f1=0.9334574220567706
step: 0, loss: 0.10704509168863297
step: 10, loss: 0.05727514624595642
step: 20, loss: 0.06989286094903946
step: 30, loss: 0.09488032013177872
step: 40, loss: 0.009107482619583607
step: 50, loss: 0.01812402904033661
step: 60, loss: 0.06796324253082275
step: 70, loss: 0.1237536072731018
step: 80, loss: 0.02863912284374237
step: 90, loss: 0.020746923983097076
step: 100, loss: 0.03993591293692589
step: 110, loss: 0.08284306526184082
step: 120, loss: 0.04727490618824959
step: 130, loss: 0.06917385011911392
step: 140, loss: 0.044815562665462494
step: 150, loss: 0.08468188345432281
step: 160, loss: 0.03232155367732048
step: 170, loss: 0.04969692975282669
step: 180, loss: 0.016821445897221565
step: 190, loss: 0.000810437195468694
step: 200, loss: 0.028968896716833115
step: 210, loss: 0.0889696255326271
step: 220, loss: 0.00016419160238001496
step: 230, loss: 0.021165790036320686
step: 240, loss: 0.0807715505361557
step: 250, loss: 0.021173497661948204
step: 260, loss: 0.0010516821639612317
step: 270, loss: 0.03563371300697327
step: 280, loss: 0.03066142275929451
step: 290, loss: 0.010692376643419266
step: 300, loss: 0.022209532558918
step: 310, loss: 0.00011055795766878873
step: 320, loss: 0.007169410120695829
step: 330, loss: 0.01620972342789173
step: 340, loss: 0.00014707297668792307
step: 350, loss: 0.01908848248422146
step: 360, loss: 0.05351315811276436
step: 370, loss: 0.09293459355831146
step: 380, loss: 0.10876938700675964
step: 390, loss: 0.02944789081811905
step: 400, loss: 0.04111987352371216
step: 410, loss: 0.016128813847899437
step: 420, loss: 0.010129147209227085
step: 430, loss: 0.0008161982987076044
step: 440, loss: 0.10127384960651398
step: 450, loss: 0.06920018792152405
step: 460, loss: 0.08903999626636505
step: 470, loss: 0.06073003262281418
step: 480, loss: 0.0468648299574852
step: 490, loss: 0.0011398022761568427
step: 500, loss: 0.043949294835329056
step: 510, loss: 0.05103413760662079
step: 520, loss: 0.06069669872522354
step: 530, loss: 0.020388806238770485
step: 540, loss: 0.0484628900885582
step: 550, loss: 0.019235970452427864
step: 560, loss: 0.033826593309640884
step: 570, loss: 0.051990870386362076
step: 580, loss: 0.07122493535280228
step: 590, loss: 0.024516038596630096
step: 600, loss: 0.04599907994270325
step: 610, loss: 0.09457264840602875
step: 620, loss: 0.04708920791745186
step: 630, loss: 0.014601287432014942
step: 640, loss: 0.016868378967046738
step: 650, loss: 4.649987386073917e-05
step: 660, loss: 0.08206865936517715
step: 670, loss: 0.05933530628681183
step: 680, loss: 0.075543612241745
step: 690, loss: 0.059765204787254333
step: 700, loss: 0.04764876514673233
step: 710, loss: 0.12461470067501068
step: 720, loss: 0.07262399792671204
step: 730, loss: 0.018420005217194557
step: 740, loss: 0.014109193347394466
step: 750, loss: 0.08658276498317719
step: 760, loss: 4.372887633508071e-05
step: 770, loss: 0.04178343340754509
step: 780, loss: 0.13097813725471497
step: 790, loss: 0.08020590245723724
step: 800, loss: 0.07677225023508072
step: 810, loss: 0.00011987010657321662
step: 820, loss: 0.031970083713531494
step: 830, loss: 0.09042301028966904
step: 840, loss: 0.04165594279766083
step: 850, loss: 0.005641303025186062
step: 860, loss: 0.09034521877765656
step: 870, loss: 0.039305198937654495
step: 880, loss: 0.01817004196345806
step: 890, loss: 0.05183602124452591
step: 900, loss: 0.01607295498251915
step: 910, loss: 0.028363991528749466
step: 920, loss: 0.046783532947301865
step: 930, loss: 0.029333841055631638
step: 940, loss: 0.011699693277478218
step: 950, loss: 0.05125477537512779
step: 960, loss: 0.058089450001716614
step: 970, loss: 0.025184109807014465
epoch 20: dev_f1=0.9262564584311883, f1=0.9251764705882354, best_f1=0.9334574220567706
