cuda
Device: cuda
step: 0, loss: 0.6986859440803528
step: 10, loss: 0.45717471837997437
step: 20, loss: 0.25258350372314453
step: 30, loss: 0.5180245637893677
step: 40, loss: 0.43476220965385437
step: 50, loss: 0.4539802074432373
step: 60, loss: 0.28984013199806213
step: 70, loss: 0.0886474996805191
step: 80, loss: 0.2064850628376007
step: 90, loss: 0.23997777700424194
step: 100, loss: 0.2103019803762436
step: 110, loss: 0.2534923553466797
step: 120, loss: 0.2145213782787323
step: 130, loss: 0.12419606745243073
step: 140, loss: 0.13543689250946045
step: 150, loss: 0.116822749376297
step: 160, loss: 0.2254059910774231
step: 170, loss: 0.04302700608968735
step: 180, loss: 0.12834830582141876
step: 190, loss: 0.09633321315050125
step: 200, loss: 0.17763040959835052
step: 210, loss: 0.09494137763977051
step: 220, loss: 0.1430824249982834
step: 230, loss: 0.2708714008331299
step: 240, loss: 0.15740230679512024
step: 250, loss: 0.15222720801830292
step: 260, loss: 0.0967685878276825
step: 270, loss: 0.08429790288209915
step: 280, loss: 0.10909821093082428
step: 290, loss: 0.043609872460365295
step: 300, loss: 0.08925236016511917
step: 310, loss: 0.15420061349868774
step: 320, loss: 0.062422432005405426
step: 330, loss: 0.0610673613846302
step: 340, loss: 0.08231323212385178
step: 350, loss: 0.12866145372390747
step: 360, loss: 0.1550326645374298
step: 370, loss: 0.396206796169281
step: 380, loss: 0.18449518084526062
step: 390, loss: 0.12422719597816467
step: 400, loss: 0.2739622890949249
step: 410, loss: 0.1626257300376892
step: 420, loss: 0.11544917523860931
step: 430, loss: 0.2259385734796524
step: 440, loss: 0.27827009558677673
step: 450, loss: 0.1295352429151535
step: 460, loss: 0.036303989589214325
step: 470, loss: 0.223612979054451
step: 480, loss: 0.09950745105743408
step: 490, loss: 0.17668205499649048
step: 500, loss: 0.259150892496109
step: 510, loss: 0.07933750748634338
step: 520, loss: 0.1756047159433365
step: 530, loss: 0.09440655261278152
step: 540, loss: 0.04938064143061638
step: 550, loss: 0.06804728507995605
step: 560, loss: 0.2313445657491684
step: 570, loss: 0.04439656436443329
step: 580, loss: 0.06291463226079941
step: 590, loss: 0.14160019159317017
step: 600, loss: 0.22394990921020508
step: 610, loss: 0.155049130320549
step: 620, loss: 0.19371993839740753
step: 630, loss: 0.17539049685001373
step: 640, loss: 0.1544836163520813
step: 650, loss: 0.14170442521572113
step: 660, loss: 0.07307642698287964
step: 670, loss: 0.1424088478088379
step: 680, loss: 0.10387444496154785
step: 690, loss: 0.27022120356559753
step: 700, loss: 0.13781854510307312
step: 710, loss: 0.14834369719028473
step: 720, loss: 0.07185366004705429
step: 730, loss: 0.1373598873615265
step: 740, loss: 0.1744925081729889
step: 750, loss: 0.16730928421020508
step: 760, loss: 0.14093588292598724
step: 770, loss: 0.13393209874629974
step: 780, loss: 0.1541256606578827
step: 790, loss: 0.2013775110244751
step: 800, loss: 0.08623538911342621
step: 810, loss: 0.2328830510377884
step: 820, loss: 0.12042322009801865
step: 830, loss: 0.12193747609853745
step: 840, loss: 0.10525675117969513
step: 850, loss: 0.13267023861408234
step: 860, loss: 0.11045526713132858
step: 870, loss: 0.07712598890066147
step: 880, loss: 0.27228495478630066
step: 890, loss: 0.1404922604560852
step: 900, loss: 0.23379819095134735
step: 910, loss: 0.09072774648666382
step: 920, loss: 0.13457173109054565
step: 930, loss: 0.12110649049282074
step: 940, loss: 0.22258010506629944
step: 950, loss: 0.09342625737190247
step: 960, loss: 0.17001444101333618
step: 970, loss: 0.2433287352323532
epoch 1: dev_f1=0.9122486288848263, f1=0.916439600363306, best_f1=0.916439600363306
step: 0, loss: 0.1727992743253708
step: 10, loss: 0.22988003492355347
step: 20, loss: 0.1725442260503769
step: 30, loss: 0.11678391695022583
step: 40, loss: 0.17005592584609985
step: 50, loss: 0.0726313441991806
step: 60, loss: 0.059963058680295944
step: 70, loss: 0.07541454583406448
step: 80, loss: 0.13590820133686066
step: 90, loss: 0.09152328968048096
step: 100, loss: 0.001844686339609325
step: 110, loss: 0.12087327241897583
step: 120, loss: 0.14327417314052582
step: 130, loss: 0.17749740183353424
step: 140, loss: 0.21603593230247498
step: 150, loss: 0.14709582924842834
step: 160, loss: 0.20392829179763794
step: 170, loss: 0.11460822075605392
step: 180, loss: 0.1281549036502838
step: 190, loss: 0.23794162273406982
step: 200, loss: 0.2079041302204132
step: 210, loss: 0.10026344656944275
step: 220, loss: 0.06633977591991425
step: 230, loss: 0.11271025985479355
step: 240, loss: 0.18515662848949432
step: 250, loss: 0.11121268570423126
step: 260, loss: 0.035341519862413406
step: 270, loss: 0.08084791153669357
step: 280, loss: 0.11190346628427505
step: 290, loss: 0.1480977088212967
step: 300, loss: 0.23109284043312073
step: 310, loss: 0.11156554520130157
step: 320, loss: 0.08126091212034225
step: 330, loss: 0.11541897803544998
step: 340, loss: 0.1611357480287552
step: 350, loss: 0.073309987783432
step: 360, loss: 0.12831048667430878
step: 370, loss: 0.05366646125912666
step: 380, loss: 0.15408945083618164
step: 390, loss: 0.10701227188110352
step: 400, loss: 0.08171485364437103
step: 410, loss: 0.12114030867815018
step: 420, loss: 0.15470896661281586
step: 430, loss: 0.18744643032550812
step: 440, loss: 0.1720677614212036
step: 450, loss: 0.14452797174453735
step: 460, loss: 0.08398936688899994
step: 470, loss: 0.1920657604932785
step: 480, loss: 0.17425237596035004
step: 490, loss: 0.08461012691259384
step: 500, loss: 0.07524889707565308
step: 510, loss: 0.05677589774131775
step: 520, loss: 0.026367848739027977
step: 530, loss: 0.06612135469913483
step: 540, loss: 0.0932181179523468
step: 550, loss: 0.20751532912254333
step: 560, loss: 0.07237131893634796
step: 570, loss: 0.09299089014530182
step: 580, loss: 0.11586278676986694
step: 590, loss: 0.0815640538930893
step: 600, loss: 0.13038796186447144
step: 610, loss: 0.07638897746801376
step: 620, loss: 0.09731084108352661
step: 630, loss: 0.1717650294303894
step: 640, loss: 0.02580106630921364
step: 650, loss: 0.038555391132831573
step: 660, loss: 0.1631677895784378
step: 670, loss: 0.17300191521644592
step: 680, loss: 0.12544046342372894
step: 690, loss: 0.1379367709159851
step: 700, loss: 0.19525380432605743
step: 710, loss: 0.0792287141084671
step: 720, loss: 0.03695559874176979
step: 730, loss: 0.16303786635398865
step: 740, loss: 0.14965812861919403
step: 750, loss: 0.11011345684528351
step: 760, loss: 0.3255373239517212
step: 770, loss: 0.2787385880947113
step: 780, loss: 0.11871393024921417
step: 790, loss: 0.14678309857845306
step: 800, loss: 0.055976517498493195
step: 810, loss: 0.03937314823269844
step: 820, loss: 0.06790760904550552
step: 830, loss: 0.11213719844818115
step: 840, loss: 0.07831546664237976
step: 850, loss: 0.03702787309885025
step: 860, loss: 0.11414150148630142
step: 870, loss: 0.09354645013809204
step: 880, loss: 0.15800364315509796
step: 890, loss: 0.07640106976032257
step: 900, loss: 0.09099624305963516
step: 910, loss: 0.029363561421632767
step: 920, loss: 0.13773766160011292
step: 930, loss: 0.08830022066831589
step: 940, loss: 0.2371387779712677
step: 950, loss: 0.1393035352230072
step: 960, loss: 0.021016262471675873
step: 970, loss: 0.11050176620483398
epoch 2: dev_f1=0.9201451905626135, f1=0.917870036101083, best_f1=0.917870036101083
step: 0, loss: 0.0611569806933403
step: 10, loss: 0.11977674812078476
step: 20, loss: 0.05038613826036453
step: 30, loss: 0.09286781400442123
step: 40, loss: 0.22482404112815857
step: 50, loss: 0.055507127195596695
step: 60, loss: 0.07139912247657776
step: 70, loss: 0.17376160621643066
step: 80, loss: 0.24946923553943634
step: 90, loss: 0.09494850039482117
step: 100, loss: 0.09283063560724258
step: 110, loss: 0.10663946717977524
step: 120, loss: 0.2520997226238251
step: 130, loss: 0.18214638531208038
step: 140, loss: 0.14462287724018097
step: 150, loss: 0.15242469310760498
step: 160, loss: 0.3042142987251282
step: 170, loss: 0.09891118109226227
step: 180, loss: 0.09050128608942032
step: 190, loss: 0.1314251869916916
step: 200, loss: 0.04674021899700165
step: 210, loss: 0.04562600329518318
step: 220, loss: 0.1727311611175537
step: 230, loss: 0.04168166220188141
step: 240, loss: 0.08264517784118652
step: 250, loss: 0.1719425618648529
step: 260, loss: 0.15960711240768433
step: 270, loss: 0.17355605959892273
step: 280, loss: 0.2424776405096054
step: 290, loss: 0.029731914401054382
step: 300, loss: 0.15463240444660187
step: 310, loss: 0.20804694294929504
step: 320, loss: 0.11581455171108246
step: 330, loss: 0.15110014379024506
step: 340, loss: 0.2554778456687927
step: 350, loss: 0.07531178742647171
step: 360, loss: 0.1289932280778885
step: 370, loss: 0.052482813596725464
step: 380, loss: 0.062084365636110306
step: 390, loss: 0.09817517548799515
step: 400, loss: 0.05644254758954048
step: 410, loss: 0.11802469938993454
step: 420, loss: 0.0610676072537899
step: 430, loss: 0.10334394127130508
step: 440, loss: 0.057343967258930206
step: 450, loss: 0.05965806171298027
step: 460, loss: 0.09248510003089905
step: 470, loss: 0.08890829235315323
step: 480, loss: 0.10436079651117325
step: 490, loss: 0.0892050713300705
step: 500, loss: 0.15459758043289185
step: 510, loss: 0.1247614175081253
step: 520, loss: 0.0447746142745018
step: 530, loss: 0.35507211089134216
step: 540, loss: 0.208353191614151
step: 550, loss: 0.08028662949800491
step: 560, loss: 0.11920317262411118
step: 570, loss: 0.09678207337856293
step: 580, loss: 0.16501915454864502
step: 590, loss: 0.07455852627754211
step: 600, loss: 0.05412178486585617
step: 610, loss: 0.036656349897384644
step: 620, loss: 0.1081320270895958
step: 630, loss: 0.10180986672639847
step: 640, loss: 0.20576977729797363
step: 650, loss: 0.14255712926387787
step: 660, loss: 0.21945607662200928
step: 670, loss: 0.0399315170943737
step: 680, loss: 0.16675598919391632
step: 690, loss: 0.0987016037106514
step: 700, loss: 0.13912056386470795
step: 710, loss: 0.08078376948833466
step: 720, loss: 0.34378862380981445
step: 730, loss: 0.07352013140916824
step: 740, loss: 0.12542103230953217
step: 750, loss: 0.045175231993198395
step: 760, loss: 0.0668279305100441
step: 770, loss: 0.21515332162380219
step: 780, loss: 0.15057067573070526
step: 790, loss: 0.08228982239961624
step: 800, loss: 0.15205995738506317
step: 810, loss: 0.14397108554840088
step: 820, loss: 0.12547092139720917
step: 830, loss: 0.07182817906141281
step: 840, loss: 0.0752486139535904
step: 850, loss: 0.1960233598947525
step: 860, loss: 0.20449070632457733
step: 870, loss: 0.04452922195196152
step: 880, loss: 0.12596458196640015
step: 890, loss: 0.1265147477388382
step: 900, loss: 0.05628637969493866
step: 910, loss: 0.07022367417812347
step: 920, loss: 0.16151632368564606
step: 930, loss: 0.10206148773431778
step: 940, loss: 0.04841574653983116
step: 950, loss: 0.15161775052547455
step: 960, loss: 0.052203357219696045
step: 970, loss: 0.16460108757019043
epoch 3: dev_f1=0.925589836660617, f1=0.9240506329113923, best_f1=0.9240506329113923
step: 0, loss: 0.17295460402965546
step: 10, loss: 0.16871683299541473
step: 20, loss: 0.08041760325431824
step: 30, loss: 0.08496420830488205
step: 40, loss: 0.1099938377737999
step: 50, loss: 0.20800727605819702
step: 60, loss: 0.126539409160614
step: 70, loss: 0.03351619839668274
step: 80, loss: 0.05921672657132149
step: 90, loss: 0.17329372465610504
step: 100, loss: 0.0784529522061348
step: 110, loss: 0.12461235374212265
step: 120, loss: 0.19894079864025116
step: 130, loss: 0.03702352195978165
step: 140, loss: 0.11388886719942093
step: 150, loss: 0.15008144080638885
step: 160, loss: 0.21299073100090027
step: 170, loss: 0.1288665384054184
step: 180, loss: 0.2213258147239685
step: 190, loss: 0.0893884226679802
step: 200, loss: 0.15509386360645294
step: 210, loss: 0.025458496063947678
step: 220, loss: 0.10375800728797913
step: 230, loss: 0.07407070696353912
step: 240, loss: 0.012252485379576683
step: 250, loss: 0.03228877857327461
step: 260, loss: 0.14674903452396393
step: 270, loss: 0.12233924865722656
step: 280, loss: 0.09176572412252426
step: 290, loss: 0.10628371685743332
step: 300, loss: 0.10166400671005249
step: 310, loss: 0.1347712278366089
step: 320, loss: 0.0749162808060646
step: 330, loss: 0.1714843064546585
step: 340, loss: 0.03114454448223114
step: 350, loss: 0.09249121695756912
step: 360, loss: 0.14208483695983887
step: 370, loss: 0.23229087889194489
step: 380, loss: 0.16963474452495575
step: 390, loss: 0.1333518624305725
step: 400, loss: 0.08371556550264359
step: 410, loss: 0.1295643001794815
step: 420, loss: 0.16936437785625458
step: 430, loss: 0.1223897635936737
step: 440, loss: 0.05711390823125839
step: 450, loss: 0.11938449740409851
step: 460, loss: 0.23063628375530243
step: 470, loss: 0.07340259104967117
step: 480, loss: 0.06362654268741608
step: 490, loss: 0.07208248227834702
step: 500, loss: 0.07085809111595154
step: 510, loss: 0.207538440823555
step: 520, loss: 0.1214953288435936
step: 530, loss: 0.19074983894824982
step: 540, loss: 0.10425183922052383
step: 550, loss: 0.04869112744927406
step: 560, loss: 0.09102803468704224
step: 570, loss: 0.07816486060619354
step: 580, loss: 0.0669953003525734
step: 590, loss: 0.13819795846939087
step: 600, loss: 0.16322685778141022
step: 610, loss: 0.09803447127342224
step: 620, loss: 0.11847939342260361
step: 630, loss: 0.09713146835565567
step: 640, loss: 0.094572514295578
step: 650, loss: 0.08773628622293472
step: 660, loss: 0.07966748625040054
step: 670, loss: 0.13026311993598938
step: 680, loss: 0.06848771870136261
step: 690, loss: 0.12459949404001236
step: 700, loss: 0.09789285808801651
step: 710, loss: 0.034083399921655655
step: 720, loss: 0.1771261990070343
step: 730, loss: 0.09365051984786987
step: 740, loss: 0.1666104793548584
step: 750, loss: 0.08874143660068512
step: 760, loss: 0.07211446762084961
step: 770, loss: 0.18308521807193756
step: 780, loss: 0.027825454249978065
step: 790, loss: 0.034193139523267746
step: 800, loss: 0.21044543385505676
step: 810, loss: 0.08789220452308655
step: 820, loss: 0.11235112696886063
step: 830, loss: 0.08359042555093765
step: 840, loss: 0.11017927527427673
step: 850, loss: 0.11971576511859894
step: 860, loss: 0.06653982400894165
step: 870, loss: 0.13610193133354187
step: 880, loss: 0.22194190323352814
step: 890, loss: 0.1928217113018036
step: 900, loss: 0.07230202108621597
step: 910, loss: 0.08829118311405182
step: 920, loss: 0.18725109100341797
step: 930, loss: 0.1633874475955963
step: 940, loss: 0.08564543724060059
step: 950, loss: 0.06285618990659714
step: 960, loss: 0.10240810364484787
step: 970, loss: 0.056671176105737686
epoch 4: dev_f1=0.9335810496980957, f1=0.9308755760368663, best_f1=0.9308755760368663
step: 0, loss: 0.04539469629526138
step: 10, loss: 0.1276695728302002
step: 20, loss: 0.06728209555149078
step: 30, loss: 0.1226642057299614
step: 40, loss: 0.11843660473823547
step: 50, loss: 0.08228784799575806
step: 60, loss: 0.1168922409415245
step: 70, loss: 0.11561723053455353
step: 80, loss: 0.06550323218107224
step: 90, loss: 0.0725124254822731
step: 100, loss: 0.09755944460630417
step: 110, loss: 0.12658722698688507
step: 120, loss: 0.11924620717763901
step: 130, loss: 0.10565119981765747
step: 140, loss: 0.08926671743392944
step: 150, loss: 0.09347973763942719
step: 160, loss: 0.11011825501918793
step: 170, loss: 0.14547204971313477
step: 180, loss: 0.09708747267723083
step: 190, loss: 0.1883513629436493
step: 200, loss: 0.21261505782604218
step: 210, loss: 0.03840065747499466
step: 220, loss: 0.031822025775909424
step: 230, loss: 0.18450148403644562
step: 240, loss: 0.1172950342297554
step: 250, loss: 0.11088047921657562
step: 260, loss: 0.03067253902554512
step: 270, loss: 0.05139416456222534
step: 280, loss: 0.05024801194667816
step: 290, loss: 0.06149277091026306
step: 300, loss: 0.09508845210075378
step: 310, loss: 0.02640700712800026
step: 320, loss: 0.13178762793540955
step: 330, loss: 0.12254957109689713
step: 340, loss: 0.07036192715167999
step: 350, loss: 0.09876564890146255
step: 360, loss: 0.1573854386806488
step: 370, loss: 0.06543644517660141
step: 380, loss: 0.07628908008337021
step: 390, loss: 0.09185323119163513
step: 400, loss: 0.08705174177885056
step: 410, loss: 0.029568295925855637
step: 420, loss: 0.046006448566913605
step: 430, loss: 0.13686558604240417
step: 440, loss: 0.06949109584093094
step: 450, loss: 0.06477396935224533
step: 460, loss: 0.2127639204263687
step: 470, loss: 0.19360525906085968
step: 480, loss: 0.1492537409067154
step: 490, loss: 0.11108188331127167
step: 500, loss: 0.10099898278713226
step: 510, loss: 0.05983918905258179
step: 520, loss: 0.046600110828876495
step: 530, loss: 0.033338505774736404
step: 540, loss: 0.10219617933034897
step: 550, loss: 0.18443618714809418
step: 560, loss: 0.10207755118608475
step: 570, loss: 0.1448996365070343
step: 580, loss: 0.13029105961322784
step: 590, loss: 0.08979599922895432
step: 600, loss: 0.14545807242393494
step: 610, loss: 0.06967590749263763
step: 620, loss: 0.04392579197883606
step: 630, loss: 0.053501348942518234
step: 640, loss: 0.01689089834690094
step: 650, loss: 0.10555215924978256
step: 660, loss: 0.09597212821245193
step: 670, loss: 0.12007782608270645
step: 680, loss: 0.16749241948127747
step: 690, loss: 0.10686543583869934
step: 700, loss: 0.14250153303146362
step: 710, loss: 0.10130476951599121
step: 720, loss: 0.011510399170219898
step: 730, loss: 0.07080347836017609
step: 740, loss: 0.15269120037555695
step: 750, loss: 0.08113396167755127
step: 760, loss: 0.07231999188661575
step: 770, loss: 0.08562421053647995
step: 780, loss: 0.23572979867458344
step: 790, loss: 0.12508751451969147
step: 800, loss: 0.07813888043165207
step: 810, loss: 0.043693315237760544
step: 820, loss: 0.05501483008265495
step: 830, loss: 0.07825668901205063
step: 840, loss: 0.23017820715904236
step: 850, loss: 0.11278888583183289
step: 860, loss: 0.24055920541286469
step: 870, loss: 0.1452305167913437
step: 880, loss: 0.11635936796665192
step: 890, loss: 0.14916160702705383
step: 900, loss: 0.02878606505692005
step: 910, loss: 0.09819844365119934
step: 920, loss: 0.25159454345703125
step: 930, loss: 0.1331890970468521
step: 940, loss: 0.15720516443252563
step: 950, loss: 0.09306035190820694
step: 960, loss: 0.0875820517539978
step: 970, loss: 0.22718283534049988
epoch 5: dev_f1=0.9358386801099908, f1=0.9272065514103731, best_f1=0.9272065514103731
step: 0, loss: 0.04318225383758545
step: 10, loss: 0.08284197002649307
step: 20, loss: 0.060902662575244904
step: 30, loss: 0.08365395665168762
step: 40, loss: 0.10093750059604645
step: 50, loss: 0.2051762342453003
step: 60, loss: 0.2081037163734436
step: 70, loss: 0.035217657685279846
step: 80, loss: 0.18580177426338196
step: 90, loss: 0.13865123689174652
step: 100, loss: 0.05180497467517853
step: 110, loss: 0.05940144136548042
step: 120, loss: 0.11978654563426971
step: 130, loss: 0.12218133360147476
step: 140, loss: 0.08970725536346436
step: 150, loss: 0.10906733572483063
step: 160, loss: 0.041005268692970276
step: 170, loss: 0.04706441983580589
step: 180, loss: 0.012927704490721226
step: 190, loss: 0.07651615887880325
step: 200, loss: 0.12136945873498917
step: 210, loss: 0.14290682971477509
step: 220, loss: 0.038966014981269836
step: 230, loss: 0.048342302441596985
step: 240, loss: 0.023269720375537872
step: 250, loss: 0.06771782785654068
step: 260, loss: 0.06166977435350418
step: 270, loss: 0.06724955886602402
step: 280, loss: 0.05759084224700928
step: 290, loss: 0.05148725211620331
step: 300, loss: 0.01894516870379448
step: 310, loss: 0.14889369904994965
step: 320, loss: 0.05158590152859688
step: 330, loss: 0.06269194930791855
step: 340, loss: 0.029458576813340187
step: 350, loss: 0.018732890486717224
step: 360, loss: 0.03598868101835251
step: 370, loss: 0.12184692174196243
step: 380, loss: 0.008308653719723225
step: 390, loss: 0.15317469835281372
step: 400, loss: 0.2505546808242798
step: 410, loss: 0.06518258899450302
step: 420, loss: 0.15335290133953094
step: 430, loss: 0.06873487681150436
step: 440, loss: 0.07283740490674973
step: 450, loss: 0.17939655482769012
step: 460, loss: 0.02190946787595749
step: 470, loss: 0.06056535989046097
step: 480, loss: 0.09754320979118347
step: 490, loss: 0.10551390796899796
step: 500, loss: 0.101292684674263
step: 510, loss: 0.08615756779909134
step: 520, loss: 0.08972598612308502
step: 530, loss: 0.09876112639904022
step: 540, loss: 0.1654672771692276
step: 550, loss: 0.06369374692440033
step: 560, loss: 0.04922015219926834
step: 570, loss: 0.04707891866564751
step: 580, loss: 0.07040650397539139
step: 590, loss: 0.10458671301603317
step: 600, loss: 0.04995036497712135
step: 610, loss: 0.11915653944015503
step: 620, loss: 0.1240897923707962
step: 630, loss: 0.09034506231546402
step: 640, loss: 0.09460561722517014
step: 650, loss: 0.049468833953142166
step: 660, loss: 0.07486119866371155
step: 670, loss: 0.12475268542766571
step: 680, loss: 0.045024577528238297
step: 690, loss: 0.10650590062141418
step: 700, loss: 0.1130785420536995
step: 710, loss: 0.03942105919122696
step: 720, loss: 0.08784352242946625
step: 730, loss: 0.03271269425749779
step: 740, loss: 0.07735580205917358
step: 750, loss: 0.059969380497932434
step: 760, loss: 0.1583164781332016
step: 770, loss: 0.10857580602169037
step: 780, loss: 0.12500068545341492
step: 790, loss: 0.07482688874006271
step: 800, loss: 0.08102896064519882
step: 810, loss: 0.0704856812953949
step: 820, loss: 0.16329210996627808
step: 830, loss: 0.11886554956436157
step: 840, loss: 0.006604479625821114
step: 850, loss: 0.11170155555009842
step: 860, loss: 0.10730914026498795
step: 870, loss: 0.10930180549621582
step: 880, loss: 0.1412336379289627
step: 890, loss: 0.11229322850704193
step: 900, loss: 0.16019600629806519
step: 910, loss: 0.04112200811505318
step: 920, loss: 0.07530668377876282
step: 930, loss: 0.041529156267642975
step: 940, loss: 0.0966583639383316
step: 950, loss: 0.10997867584228516
step: 960, loss: 0.10077386349439621
step: 970, loss: 0.2551102936267853
epoch 6: dev_f1=0.9321642824180896, f1=0.9294871794871795, best_f1=0.9272065514103731
step: 0, loss: 0.15461358428001404
step: 10, loss: 0.10976136475801468
step: 20, loss: 0.142950177192688
step: 30, loss: 0.03932127729058266
step: 40, loss: 0.06399417668581009
step: 50, loss: 0.025475213304162025
step: 60, loss: 0.03877296671271324
step: 70, loss: 0.08411432802677155
step: 80, loss: 0.12810662388801575
step: 90, loss: 0.2243800312280655
step: 100, loss: 0.10403694212436676
step: 110, loss: 0.08137422055006027
step: 120, loss: 0.10977179557085037
step: 130, loss: 0.04040267691016197
step: 140, loss: 0.16540497541427612
step: 150, loss: 0.08300652354955673
step: 160, loss: 0.06444399058818817
step: 170, loss: 0.015805525705218315
step: 180, loss: 0.02643432654440403
step: 190, loss: 0.07981300354003906
step: 200, loss: 0.07555359601974487
step: 210, loss: 0.09150796383619308
step: 220, loss: 0.13264068961143494
step: 230, loss: 0.1663818359375
step: 240, loss: 0.23992033302783966
step: 250, loss: 0.02234473265707493
step: 260, loss: 0.01919272541999817
step: 270, loss: 0.050835687667131424
step: 280, loss: 0.14659123122692108
step: 290, loss: 0.08789992332458496
step: 300, loss: 0.12752936780452728
step: 310, loss: 0.1081329882144928
step: 320, loss: 0.039330240339040756
step: 330, loss: 0.06723185628652573
step: 340, loss: 0.03807621821761131
step: 350, loss: 0.014822127297520638
step: 360, loss: 0.01930542103946209
step: 370, loss: 0.1251353919506073
step: 380, loss: 0.05111218988895416
step: 390, loss: 0.12770910561084747
step: 400, loss: 0.09237481653690338
step: 410, loss: 0.009924947284162045
step: 420, loss: 0.04652608558535576
step: 430, loss: 0.19497933983802795
step: 440, loss: 0.10100933164358139
step: 450, loss: 0.19698388874530792
step: 460, loss: 0.1467597782611847
step: 470, loss: 0.06799609959125519
step: 480, loss: 0.06642088294029236
step: 490, loss: 0.0874963104724884
step: 500, loss: 0.08804723620414734
step: 510, loss: 0.13599444925785065
step: 520, loss: 0.17152686417102814
step: 530, loss: 0.09096170216798782
step: 540, loss: 0.016367042437195778
step: 550, loss: 0.12078069895505905
step: 560, loss: 0.0798640251159668
step: 570, loss: 0.06273993849754333
step: 580, loss: 0.10637008398771286
step: 590, loss: 0.005656680092215538
step: 600, loss: 0.06402385234832764
step: 610, loss: 0.0247793085873127
step: 620, loss: 0.09825608134269714
step: 630, loss: 0.008664815686643124
step: 640, loss: 0.1404951512813568
step: 650, loss: 0.23207776248455048
step: 660, loss: 0.1318701207637787
step: 670, loss: 0.08634229749441147
step: 680, loss: 0.17512758076190948
step: 690, loss: 0.03149356693029404
step: 700, loss: 0.07687952369451523
step: 710, loss: 0.03186219558119774
step: 720, loss: 0.17893467843532562
step: 730, loss: 0.0994386151432991
step: 740, loss: 0.020295869559049606
step: 750, loss: 0.058555830270051956
step: 760, loss: 0.05457500368356705
step: 770, loss: 0.05388525873422623
step: 780, loss: 0.09316182881593704
step: 790, loss: 0.1254943609237671
step: 800, loss: 0.04732731729745865
step: 810, loss: 0.0892985537648201
step: 820, loss: 0.11552998423576355
step: 830, loss: 0.062052417546510696
step: 840, loss: 0.07441164553165436
step: 850, loss: 0.028036680072546005
step: 860, loss: 0.08279405534267426
step: 870, loss: 0.1083616241812706
step: 880, loss: 0.0640847459435463
step: 890, loss: 0.08418234437704086
step: 900, loss: 0.05378057062625885
step: 910, loss: 0.09412914514541626
step: 920, loss: 0.10602860152721405
step: 930, loss: 0.10413548350334167
step: 940, loss: 0.1331600397825241
step: 950, loss: 0.042921099811792374
step: 960, loss: 0.049374714493751526
step: 970, loss: 0.1066388189792633
epoch 7: dev_f1=0.9272137227630968, f1=0.9163972286374134, best_f1=0.9272065514103731
step: 0, loss: 0.038203105330467224
step: 10, loss: 0.08261246234178543
step: 20, loss: 0.11485595256090164
step: 30, loss: 0.07879414409399033
step: 40, loss: 0.09895171225070953
step: 50, loss: 0.04760246351361275
step: 60, loss: 0.12469962239265442
step: 70, loss: 0.04561588168144226
step: 80, loss: 0.13751429319381714
step: 90, loss: 0.15226982533931732
step: 100, loss: 0.00918588601052761
step: 110, loss: 0.08244145661592484
step: 120, loss: 0.16450247168540955
step: 130, loss: 0.03542804718017578
step: 140, loss: 0.09832973778247833
step: 150, loss: 0.051523927599191666
step: 160, loss: 0.12492873519659042
step: 170, loss: 0.08947624266147614
step: 180, loss: 0.0642913430929184
step: 190, loss: 0.08644960075616837
step: 200, loss: 0.02769499272108078
step: 210, loss: 0.057646796107292175
step: 220, loss: 0.08260897547006607
step: 230, loss: 0.02972300723195076
step: 240, loss: 0.052898257970809937
step: 250, loss: 0.060212392359972
step: 260, loss: 0.05044287070631981
step: 270, loss: 0.03365031257271767
step: 280, loss: 0.09086217731237411
step: 290, loss: 0.04911018908023834
step: 300, loss: 0.10121625661849976
step: 310, loss: 0.012954335659742355
step: 320, loss: 0.09872917830944061
step: 330, loss: 0.15675950050354004
step: 340, loss: 0.15742361545562744
step: 350, loss: 0.07869848608970642
step: 360, loss: 0.1148863360285759
step: 370, loss: 0.1975233107805252
step: 380, loss: 0.19892007112503052
step: 390, loss: 0.07605087012052536
step: 400, loss: 0.04827616363763809
step: 410, loss: 0.11731162667274475
step: 420, loss: 0.049544207751750946
step: 430, loss: 0.12409166246652603
step: 440, loss: 0.10000311583280563
step: 450, loss: 0.03682078793644905
step: 460, loss: 0.10295535624027252
step: 470, loss: 0.13375526666641235
step: 480, loss: 0.09090615808963776
step: 490, loss: 0.22060538828372955
step: 500, loss: 0.029240474104881287
step: 510, loss: 0.1782684028148651
step: 520, loss: 0.12103735655546188
step: 530, loss: 0.11568832397460938
step: 540, loss: 0.08839400112628937
step: 550, loss: 0.1272442489862442
step: 560, loss: 0.08578968793153763
step: 570, loss: 0.061880920082330704
step: 580, loss: 0.09037864953279495
step: 590, loss: 0.07002559304237366
step: 600, loss: 0.049442753195762634
step: 610, loss: 0.08225474506616592
step: 620, loss: 0.11644195765256882
step: 630, loss: 0.06873155385255814
step: 640, loss: 0.03694893792271614
step: 650, loss: 0.08279833942651749
step: 660, loss: 0.10568755865097046
step: 670, loss: 0.03938008472323418
step: 680, loss: 0.2418598234653473
step: 690, loss: 0.09211710095405579
step: 700, loss: 0.04390798509120941
step: 710, loss: 0.05959901586174965
step: 720, loss: 0.0291320588439703
step: 730, loss: 0.20470581948757172
step: 740, loss: 0.07970044016838074
step: 750, loss: 0.04321081191301346
step: 760, loss: 0.06236347183585167
step: 770, loss: 0.17602264881134033
step: 780, loss: 0.08889084309339523
step: 790, loss: 0.12714232504367828
step: 800, loss: 0.12862908840179443
step: 810, loss: 0.02647067978978157
step: 820, loss: 0.09624431282281876
step: 830, loss: 0.04729801416397095
step: 840, loss: 0.0806453600525856
step: 850, loss: 0.027986273169517517
step: 860, loss: 0.1034635677933693
step: 870, loss: 0.09146924316883087
step: 880, loss: 0.09572523087263107
step: 890, loss: 0.06832834333181381
step: 900, loss: 0.09501184523105621
step: 910, loss: 0.05870247632265091
step: 920, loss: 0.019456814974546432
step: 930, loss: 0.12285351753234863
step: 940, loss: 0.07770966738462448
step: 950, loss: 0.1755046844482422
step: 960, loss: 0.14697812497615814
step: 970, loss: 0.049890246242284775
epoch 8: dev_f1=0.931098696461825, f1=0.9292364990689013, best_f1=0.9272065514103731
step: 0, loss: 0.10027674585580826
step: 10, loss: 0.10354474186897278
step: 20, loss: 0.03295132890343666
step: 30, loss: 0.08537302166223526
step: 40, loss: 0.1532202661037445
step: 50, loss: 0.0365087166428566
step: 60, loss: 0.11540628224611282
step: 70, loss: 0.08206414431333542
step: 80, loss: 0.03167983144521713
step: 90, loss: 0.055042292922735214
step: 100, loss: 0.05176413059234619
step: 110, loss: 0.2565903067588806
step: 120, loss: 0.03920526057481766
step: 130, loss: 0.11063919961452484
step: 140, loss: 0.062455613166093826
step: 150, loss: 0.040541257709264755
step: 160, loss: 0.05512821674346924
step: 170, loss: 0.16077305376529694
step: 180, loss: 0.13238340616226196
step: 190, loss: 0.05071375146508217
step: 200, loss: 0.19546087086200714
step: 210, loss: 0.026210565119981766
step: 220, loss: 0.07416515052318573
step: 230, loss: 0.05067382752895355
step: 240, loss: 0.1191629022359848
step: 250, loss: 0.06114988401532173
step: 260, loss: 0.09356247633695602
step: 270, loss: 0.11499141156673431
step: 280, loss: 0.058191098272800446
step: 290, loss: 0.14739756286144257
step: 300, loss: 0.022431308403611183
step: 310, loss: 0.04363979026675224
step: 320, loss: 0.11372095346450806
step: 330, loss: 0.11118316650390625
step: 340, loss: 0.13732746243476868
step: 350, loss: 0.07270542532205582
step: 360, loss: 0.031459495425224304
step: 370, loss: 0.025402072817087173
step: 380, loss: 0.04512057453393936
step: 390, loss: 0.06724701076745987
step: 400, loss: 0.04084938392043114
step: 410, loss: 0.0757899284362793
step: 420, loss: 0.05172944813966751
step: 430, loss: 0.15778949856758118
step: 440, loss: 0.10144241154193878
step: 450, loss: 0.0541108101606369
step: 460, loss: 0.08514286577701569
step: 470, loss: 0.07333923876285553
step: 480, loss: 0.05822083353996277
step: 490, loss: 0.15146154165267944
step: 500, loss: 0.22435277700424194
step: 510, loss: 0.07914856821298599
step: 520, loss: 0.09653269499540329
step: 530, loss: 0.09553048759698868
step: 540, loss: 0.20183822512626648
step: 550, loss: 0.07835692167282104
step: 560, loss: 0.04637918621301651
step: 570, loss: 0.10977218300104141
step: 580, loss: 0.08724728971719742
step: 590, loss: 0.10132648050785065
step: 600, loss: 0.15190428495407104
step: 610, loss: 0.06832880526781082
step: 620, loss: 0.08162512630224228
step: 630, loss: 0.08472228795289993
step: 640, loss: 0.0805850699543953
step: 650, loss: 0.023233700543642044
step: 660, loss: 0.018875809386372566
step: 670, loss: 0.10336979478597641
step: 680, loss: 0.09274137765169144
step: 690, loss: 0.09020198881626129
step: 700, loss: 0.1867915689945221
step: 710, loss: 0.012759801931679249
step: 720, loss: 0.05674545466899872
step: 730, loss: 0.12933602929115295
step: 740, loss: 0.03322532773017883
step: 750, loss: 0.17203785479068756
step: 760, loss: 0.09346935898065567
step: 770, loss: 0.046392105519771576
step: 780, loss: 0.059444598853588104
step: 790, loss: 0.07561293989419937
step: 800, loss: 0.06365936249494553
step: 810, loss: 0.0967181846499443
step: 820, loss: 0.06453157961368561
step: 830, loss: 0.13256177306175232
step: 840, loss: 0.08428563177585602
step: 850, loss: 0.01863682083785534
step: 860, loss: 0.06498756259679794
step: 870, loss: 0.08353657275438309
step: 880, loss: 0.021108750253915787
step: 890, loss: 0.05957533046603203
step: 900, loss: 0.15227961540222168
step: 910, loss: 0.0772266685962677
step: 920, loss: 0.13478954136371613
step: 930, loss: 0.08119967579841614
step: 940, loss: 0.18919484317302704
step: 950, loss: 0.11943197250366211
step: 960, loss: 0.11363343894481659
step: 970, loss: 0.15796993672847748
epoch 9: dev_f1=0.9358386801099908, f1=0.9310661764705882, best_f1=0.9272065514103731
step: 0, loss: 0.08580004423856735
step: 10, loss: 0.0807410478591919
step: 20, loss: 0.03940204903483391
step: 30, loss: 0.04025311395525932
step: 40, loss: 0.0683525875210762
step: 50, loss: 0.03182978555560112
step: 60, loss: 0.08719156682491302
step: 70, loss: 0.13479898869991302
step: 80, loss: 0.14183294773101807
step: 90, loss: 0.058362435549497604
step: 100, loss: 0.03994106501340866
step: 110, loss: 0.07898436486721039
step: 120, loss: 0.0674365684390068
step: 130, loss: 0.009934972040355206
step: 140, loss: 0.12806436419487
step: 150, loss: 0.08296876400709152
step: 160, loss: 0.06942104548215866
step: 170, loss: 0.08595471829175949
step: 180, loss: 0.14639198780059814
step: 190, loss: 0.028339339420199394
step: 200, loss: 0.13650038838386536
step: 210, loss: 0.05816022679209709
step: 220, loss: 0.2584491968154907
step: 230, loss: 0.08098745346069336
step: 240, loss: 0.0587172769010067
step: 250, loss: 0.07419312745332718
step: 260, loss: 0.07477588951587677
step: 270, loss: 0.037490639835596085
step: 280, loss: 0.10661531984806061
step: 290, loss: 0.03183342143893242
step: 300, loss: 0.1415519416332245
step: 310, loss: 0.03227050602436066
step: 320, loss: 0.06808913499116898
step: 330, loss: 0.04650839418172836
step: 340, loss: 0.0887993648648262
step: 350, loss: 0.1147226095199585
step: 360, loss: 0.06033336743712425
step: 370, loss: 0.052883654832839966
step: 380, loss: 0.09090589731931686
step: 390, loss: 0.05364876613020897
step: 400, loss: 0.1274377852678299
step: 410, loss: 0.021027561277151108
step: 420, loss: 0.00928548164665699
step: 430, loss: 0.055609315633773804
step: 440, loss: 0.1377570629119873
step: 450, loss: 0.036356862634420395
step: 460, loss: 0.05507068708539009
step: 470, loss: 0.20817485451698303
step: 480, loss: 0.07407070696353912
step: 490, loss: 2.443343873892445e-05
step: 500, loss: 0.06757083535194397
step: 510, loss: 0.0699230432510376
step: 520, loss: 0.12163127213716507
step: 530, loss: 0.07720467448234558
step: 540, loss: 0.0427829846739769
step: 550, loss: 0.055002402514219284
step: 560, loss: 0.05587030574679375
step: 570, loss: 0.11152800917625427
step: 580, loss: 0.0745057687163353
step: 590, loss: 0.11244848370552063
step: 600, loss: 0.06002848967909813
step: 610, loss: 0.08473283797502518
step: 620, loss: 0.015413811430335045
step: 630, loss: 0.07750946283340454
step: 640, loss: 0.0878690555691719
step: 650, loss: 0.07778757065534592
step: 660, loss: 0.06706830114126205
step: 670, loss: 0.03653053194284439
step: 680, loss: 0.07889607548713684
step: 690, loss: 0.07736042141914368
step: 700, loss: 0.09815844148397446
step: 710, loss: 0.05771857500076294
step: 720, loss: 0.0052167391404509544
step: 730, loss: 0.04976382479071617
step: 740, loss: 0.012056306004524231
step: 750, loss: 0.16161802411079407
step: 760, loss: 0.1443966031074524
step: 770, loss: 0.1460856795310974
step: 780, loss: 0.048652321100234985
step: 790, loss: 0.0936465933918953
step: 800, loss: 0.09156108647584915
step: 810, loss: 0.10919743031263351
step: 820, loss: 0.0722302496433258
step: 830, loss: 0.06503282487392426
step: 840, loss: 0.06133529171347618
step: 850, loss: 0.1710943728685379
step: 860, loss: 0.09955941885709763
step: 870, loss: 0.10652268677949905
step: 880, loss: 0.05810897424817085
step: 890, loss: 0.08158338814973831
step: 900, loss: 0.07378421723842621
step: 910, loss: 0.04872578755021095
step: 920, loss: 0.12816482782363892
step: 930, loss: 0.14381086826324463
step: 940, loss: 0.035807933658361435
step: 950, loss: 0.04442572593688965
step: 960, loss: 0.03219107910990715
step: 970, loss: 0.1630699336528778
epoch 10: dev_f1=0.9324699352451433, f1=0.9281105990783408, best_f1=0.9272065514103731
step: 0, loss: 0.028987780213356018
step: 10, loss: 0.15771484375
step: 20, loss: 0.2302742600440979
step: 30, loss: 0.0516352504491806
step: 40, loss: 0.12825894355773926
step: 50, loss: 0.030082792043685913
step: 60, loss: 0.09585156291723251
step: 70, loss: 0.03088594600558281
step: 80, loss: 0.021571997553110123
step: 90, loss: 0.01782495155930519
step: 100, loss: 0.08863673359155655
step: 110, loss: 0.06995965540409088
step: 120, loss: 0.06562327593564987
step: 130, loss: 0.061310842633247375
step: 140, loss: 0.10545866191387177
step: 150, loss: 0.11812227219343185
step: 160, loss: 0.01727992296218872
step: 170, loss: 0.0509771928191185
step: 180, loss: 0.10011362284421921
step: 190, loss: 0.009665641002357006
step: 200, loss: 0.1351846605539322
step: 210, loss: 0.023182407021522522
step: 220, loss: 0.28584057092666626
step: 230, loss: 0.06560512632131577
step: 240, loss: 0.19595685601234436
step: 250, loss: 0.027253076434135437
step: 260, loss: 0.02875560335814953
step: 270, loss: 0.004735555499792099
step: 280, loss: 0.12687064707279205
step: 290, loss: 0.08587498962879181
step: 300, loss: 0.03884264454245567
step: 310, loss: 0.1104908362030983
step: 320, loss: 0.12646661698818207
step: 330, loss: 0.14248809218406677
step: 340, loss: 0.05986648052930832
step: 350, loss: 0.15801459550857544
step: 360, loss: 0.04426277428865433
step: 370, loss: 0.06571093946695328
step: 380, loss: 0.1072787195444107
step: 390, loss: 0.05393017828464508
step: 400, loss: 0.16119492053985596
step: 410, loss: 0.032995451241731644
step: 420, loss: 0.038751233369112015
step: 430, loss: 0.07478600740432739
step: 440, loss: 0.05697166174650192
step: 450, loss: 0.06326720863580704
step: 460, loss: 0.04614415764808655
step: 470, loss: 0.09351462125778198
step: 480, loss: 0.03129076212644577
step: 490, loss: 0.05544455349445343
step: 500, loss: 0.03876136988401413
step: 510, loss: 0.06328791379928589
step: 520, loss: 0.022836312651634216
step: 530, loss: 0.061262909322977066
step: 540, loss: 0.10934169590473175
step: 550, loss: 0.04332658275961876
step: 560, loss: 0.13503596186637878
step: 570, loss: 0.07736952602863312
step: 580, loss: 0.0969272032380104
step: 590, loss: 0.05878531560301781
step: 600, loss: 0.15868817269802094
step: 610, loss: 0.1394713968038559
step: 620, loss: 0.062423817813396454
step: 630, loss: 0.07779517769813538
step: 640, loss: 0.04072354733943939
step: 650, loss: 0.07422298938035965
step: 660, loss: 0.05879756808280945
step: 670, loss: 0.01568371057510376
step: 680, loss: 0.06543852388858795
step: 690, loss: 0.029333271086215973
step: 700, loss: 0.022423533722758293
step: 710, loss: 0.061908699572086334
step: 720, loss: 0.05742265656590462
step: 730, loss: 0.08620406687259674
step: 740, loss: 0.13925811648368835
step: 750, loss: 0.11057519167661667
step: 760, loss: 0.059485647827386856
step: 770, loss: 0.06929140537977219
step: 780, loss: 0.1292828768491745
step: 790, loss: 0.04512510821223259
step: 800, loss: 0.05318532884120941
step: 810, loss: 0.115592822432518
step: 820, loss: 0.08834750950336456
step: 830, loss: 0.07610473036766052
step: 840, loss: 0.1186763197183609
step: 850, loss: 0.03890117257833481
step: 860, loss: 0.13023531436920166
step: 870, loss: 0.041127584874629974
step: 880, loss: 0.17678053677082062
step: 890, loss: 0.07448871433734894
step: 900, loss: 0.046518176794052124
step: 910, loss: 0.15604451298713684
step: 920, loss: 0.038350582122802734
step: 930, loss: 0.04178402200341225
step: 940, loss: 0.20421911776065826
step: 950, loss: 0.016829488798975945
step: 960, loss: 0.10161879658699036
step: 970, loss: 0.011461874470114708
epoch 11: dev_f1=0.9350163627863488, f1=0.9210770659238626, best_f1=0.9272065514103731
step: 0, loss: 0.035731345415115356
step: 10, loss: 0.11256223917007446
step: 20, loss: 0.012127889320254326
step: 30, loss: 0.10147976130247116
step: 40, loss: 0.052621494978666306
step: 50, loss: 0.06824982166290283
step: 60, loss: 0.02004614658653736
step: 70, loss: 0.1808578222990036
step: 80, loss: 0.026123424991965294
step: 90, loss: 0.03471067175269127
step: 100, loss: 0.12358919531106949
step: 110, loss: 0.019044874235987663
step: 120, loss: 0.09550995379686356
step: 130, loss: 0.03911842778325081
step: 140, loss: 0.09053448587656021
step: 150, loss: 0.1322300136089325
step: 160, loss: 0.053760070353746414
step: 170, loss: 0.07769724726676941
step: 180, loss: 0.005196097306907177
step: 190, loss: 0.0383642353117466
step: 200, loss: 0.04775219038128853
step: 210, loss: 0.09667445719242096
step: 220, loss: 0.004178155679255724
step: 230, loss: 0.06281682848930359
step: 240, loss: 0.02788175828754902
step: 250, loss: 0.08733181655406952
step: 260, loss: 0.04133012890815735
step: 270, loss: 0.04388336092233658
step: 280, loss: 0.07942204177379608
step: 290, loss: 0.04341277480125427
step: 300, loss: 0.04606032371520996
step: 310, loss: 0.16429606080055237
step: 320, loss: 0.024323733523488045
step: 330, loss: 0.07481084764003754
step: 340, loss: 0.005291122943162918
step: 350, loss: 0.05243898555636406
step: 360, loss: 0.03232472389936447
step: 370, loss: 0.1301853209733963
step: 380, loss: 0.05739149823784828
step: 390, loss: 0.11159905791282654
step: 400, loss: 0.026563765481114388
step: 410, loss: 0.09965049475431442
step: 420, loss: 0.03581228107213974
step: 430, loss: 0.08640700578689575
step: 440, loss: 0.09860862046480179
step: 450, loss: 0.07537276297807693
step: 460, loss: 0.13431470096111298
step: 470, loss: 0.108798548579216
step: 480, loss: 0.04329466447234154
step: 490, loss: 0.0024792971089482307
step: 500, loss: 0.03707672655582428
step: 510, loss: 0.006969840731471777
step: 520, loss: 0.002907346934080124
step: 530, loss: 0.06684998422861099
step: 540, loss: 0.04885806515812874
step: 550, loss: 0.07467108964920044
step: 560, loss: 0.0853227972984314
step: 570, loss: 0.18395771086215973
step: 580, loss: 0.06300123780965805
step: 590, loss: 0.08560896664857864
step: 600, loss: 0.10003487765789032
step: 610, loss: 0.08427776396274567
step: 620, loss: 0.14510154724121094
step: 630, loss: 0.07446590065956116
step: 640, loss: 0.17130471765995026
step: 650, loss: 0.06812043488025665
step: 660, loss: 0.07688684016466141
step: 670, loss: 0.07072358578443527
step: 680, loss: 0.05180864781141281
step: 690, loss: 0.06569786369800568
step: 700, loss: 0.10587988048791885
step: 710, loss: 0.09953512996435165
step: 720, loss: 0.10161487758159637
step: 730, loss: 0.17245128750801086
step: 740, loss: 0.05339302495121956
step: 750, loss: 0.05024142563343048
step: 760, loss: 0.03433486074209213
step: 770, loss: 0.01358581893146038
step: 780, loss: 0.061431411653757095
step: 790, loss: 0.10980532318353653
step: 800, loss: 0.03578890115022659
step: 810, loss: 0.06180998682975769
step: 820, loss: 0.05986865237355232
step: 830, loss: 0.00942808948457241
step: 840, loss: 0.052225157618522644
step: 850, loss: 0.05347079038619995
step: 860, loss: 0.03381377458572388
step: 870, loss: 0.030929647386074066
step: 880, loss: 0.027170471847057343
step: 890, loss: 0.1963454931974411
step: 900, loss: 0.13640721142292023
step: 910, loss: 0.09827440977096558
step: 920, loss: 0.007690939586609602
step: 930, loss: 0.10940804332494736
step: 940, loss: 0.04633171856403351
step: 950, loss: 0.14823979139328003
step: 960, loss: 0.06686750799417496
step: 970, loss: 0.0033806883729994297
epoch 12: dev_f1=0.9353647276084949, f1=0.926829268292683, best_f1=0.9272065514103731
step: 0, loss: 0.06658700853586197
step: 10, loss: 0.003716021543368697
step: 20, loss: 0.10538730770349503
step: 30, loss: 0.058607108891010284
step: 40, loss: 0.07290250062942505
step: 50, loss: 0.07719247043132782
step: 60, loss: 0.2094952017068863
step: 70, loss: 0.0346890389919281
step: 80, loss: 0.1373317539691925
step: 90, loss: 0.02448911964893341
step: 100, loss: 0.09328286349773407
step: 110, loss: 0.0021754291374236345
step: 120, loss: 0.04524392634630203
step: 130, loss: 0.06711775064468384
step: 140, loss: 0.06686960905790329
step: 150, loss: 0.02039366215467453
step: 160, loss: 0.03937292471528053
step: 170, loss: 0.0558936782181263
step: 180, loss: 0.03198538348078728
step: 190, loss: 0.04658174514770508
step: 200, loss: 0.04066041111946106
step: 210, loss: 0.050856515765190125
step: 220, loss: 0.04243011027574539
step: 230, loss: 0.06528276950120926
step: 240, loss: 0.031179651618003845
step: 250, loss: 0.060943495482206345
step: 260, loss: 0.06577245146036148
step: 270, loss: 0.033066824078559875
step: 280, loss: 0.02411828190088272
step: 290, loss: 0.050124578177928925
step: 300, loss: 0.06694904714822769
step: 310, loss: 0.04332318156957626
step: 320, loss: 0.060994915664196014
step: 330, loss: 0.03793548420071602
step: 340, loss: 0.04335761442780495
step: 350, loss: 0.02027730830013752
step: 360, loss: 0.09532361477613449
step: 370, loss: 0.07647573202848434
step: 380, loss: 0.0447511300444603
step: 390, loss: 0.06853508204221725
step: 400, loss: 0.1134052649140358
step: 410, loss: 0.016948463395237923
step: 420, loss: 0.0530531108379364
step: 430, loss: 0.04373687133193016
step: 440, loss: 0.01947063021361828
step: 450, loss: 0.028316814452409744
step: 460, loss: 0.06878042221069336
step: 470, loss: 0.08279789239168167
step: 480, loss: 0.06297507137060165
step: 490, loss: 0.025680510327219963
step: 500, loss: 0.11657398194074631
step: 510, loss: 0.10461387038230896
step: 520, loss: 0.1341923177242279
step: 530, loss: 0.05052664875984192
step: 540, loss: 0.08289282023906708
step: 550, loss: 0.07241441309452057
step: 560, loss: 0.09217049926519394
step: 570, loss: 0.0030678168404847383
step: 580, loss: 0.13300132751464844
step: 590, loss: 0.08731222152709961
step: 600, loss: 0.05153653025627136
step: 610, loss: 0.08940251171588898
step: 620, loss: 0.10793177038431168
step: 630, loss: 0.08671177923679352
step: 640, loss: 0.01667439378798008
step: 650, loss: 0.04148036241531372
step: 660, loss: 0.08030781894922256
step: 670, loss: 0.022733531892299652
step: 680, loss: 0.13404908776283264
step: 690, loss: 0.08446227014064789
step: 700, loss: 0.15588493645191193
step: 710, loss: 0.038065966218709946
step: 720, loss: 0.14729182422161102
step: 730, loss: 0.11601593345403671
step: 740, loss: 0.14047837257385254
step: 750, loss: 0.004258027765899897
step: 760, loss: 0.06785275787115097
step: 770, loss: 0.045962367206811905
step: 780, loss: 0.037110306322574615
step: 790, loss: 0.058727458119392395
step: 800, loss: 0.025561580434441566
step: 810, loss: 0.046801451593637466
step: 820, loss: 0.15118323266506195
step: 830, loss: 0.04149744287133217
step: 840, loss: 0.048555660992860794
step: 850, loss: 0.05960437282919884
step: 860, loss: 0.06921950727701187
step: 870, loss: 0.02837429568171501
step: 880, loss: 0.1084972620010376
step: 890, loss: 0.049189817160367966
step: 900, loss: 0.10327525436878204
step: 910, loss: 0.0003330083563923836
step: 920, loss: 0.03333475813269615
step: 930, loss: 0.10608713328838348
step: 940, loss: 0.06269323825836182
step: 950, loss: 0.05752260237932205
step: 960, loss: 0.10352025926113129
step: 970, loss: 0.09769200533628464
epoch 13: dev_f1=0.9318181818181819, f1=0.9251059821008009, best_f1=0.9272065514103731
step: 0, loss: 0.027699269354343414
step: 10, loss: 0.046573057770729065
step: 20, loss: 0.06583453714847565
step: 30, loss: 0.06239987537264824
step: 40, loss: 0.01191360130906105
step: 50, loss: 0.05128214508295059
step: 60, loss: 0.02754630707204342
step: 70, loss: 0.08664868026971817
step: 80, loss: 0.023084310814738274
step: 90, loss: 0.08814292401075363
step: 100, loss: 0.04773898050189018
step: 110, loss: 0.06327752023935318
step: 120, loss: 0.03085656277835369
step: 130, loss: 0.0943315178155899
step: 140, loss: 0.06763215363025665
step: 150, loss: 0.09260344505310059
step: 160, loss: 0.008849774487316608
step: 170, loss: 0.09158841520547867
step: 180, loss: 0.0683193951845169
step: 190, loss: 0.1144774779677391
step: 200, loss: 0.09199006110429764
step: 210, loss: 0.08306492120027542
step: 220, loss: 0.03749120607972145
step: 230, loss: 0.11013749986886978
step: 240, loss: 0.05589026212692261
step: 250, loss: 0.04143805801868439
step: 260, loss: 0.05668388307094574
step: 270, loss: 0.03579636290669441
step: 280, loss: 0.047435179352760315
step: 290, loss: 0.062171727418899536
step: 300, loss: 0.06762710958719254
step: 310, loss: 0.004053524695336819
step: 320, loss: 0.07825569063425064
step: 330, loss: 0.05749789625406265
step: 340, loss: 0.0595836266875267
step: 350, loss: 0.04376499727368355
step: 360, loss: 0.005676116328686476
step: 370, loss: 0.0010018619941547513
step: 380, loss: 0.01572769321501255
step: 390, loss: 0.07195054739713669
step: 400, loss: 0.0032377559691667557
step: 410, loss: 0.024920232594013214
step: 420, loss: 0.016919683665037155
step: 430, loss: 0.01270279660820961
step: 440, loss: 0.05175967514514923
step: 450, loss: 0.057971324771642685
step: 460, loss: 0.09859231859445572
step: 470, loss: 0.05196546018123627
step: 480, loss: 0.007048362400382757
step: 490, loss: 0.07483988255262375
step: 500, loss: 0.15402495861053467
step: 510, loss: 0.04727189987897873
step: 520, loss: 0.08843682706356049
step: 530, loss: 0.05044516921043396
step: 540, loss: 0.0400867685675621
step: 550, loss: 0.06334401667118073
step: 560, loss: 0.03634994104504585
step: 570, loss: 0.1397942453622818
step: 580, loss: 0.0797441303730011
step: 590, loss: 0.054143767803907394
step: 600, loss: 0.058834049850702286
step: 610, loss: 0.02884785272181034
step: 620, loss: 0.010859602130949497
step: 630, loss: 0.13588523864746094
step: 640, loss: 0.0480804517865181
step: 650, loss: 0.10447162389755249
step: 660, loss: 0.015357363037765026
step: 670, loss: 0.023310476914048195
step: 680, loss: 0.08836119621992111
step: 690, loss: 0.057622332125902176
step: 700, loss: 0.04177994653582573
step: 710, loss: 0.01972293294966221
step: 720, loss: 0.03556101396679878
step: 730, loss: 0.08627848327159882
step: 740, loss: 0.07382597029209137
step: 750, loss: 0.04818779602646828
step: 760, loss: 0.11162350326776505
step: 770, loss: 0.02137092873454094
step: 780, loss: 0.04585326835513115
step: 790, loss: 0.022735701873898506
step: 800, loss: 0.02054199017584324
step: 810, loss: 0.020320981740951538
step: 820, loss: 0.001060566515661776
step: 830, loss: 0.010494507849216461
step: 840, loss: 0.07180372625589371
step: 850, loss: 0.023586655035614967
step: 860, loss: 0.03612028434872627
step: 870, loss: 0.14586231112480164
step: 880, loss: 0.02655710093677044
step: 890, loss: 0.042230769991874695
step: 900, loss: 0.03972319886088371
step: 910, loss: 0.06609941273927689
step: 920, loss: 0.014386123046278954
step: 930, loss: 0.017932040616869926
step: 940, loss: 0.07816506177186966
step: 950, loss: 5.2310453611426055e-05
step: 960, loss: 0.025134699419140816
step: 970, loss: 0.02861904725432396
epoch 14: dev_f1=0.9323943661971831, f1=0.9237961664329126, best_f1=0.9272065514103731
step: 0, loss: 0.05999366194009781
step: 10, loss: 0.04411686211824417
step: 20, loss: 0.043916232883930206
step: 30, loss: 0.10031428188085556
step: 40, loss: 0.0519411563873291
step: 50, loss: 0.0002289983385708183
step: 60, loss: 0.08914608508348465
step: 70, loss: 0.07077105343341827
step: 80, loss: 0.03989890217781067
step: 90, loss: 0.06261599808931351
step: 100, loss: 0.031467415392398834
step: 110, loss: 0.08298392593860626
step: 120, loss: 0.023356908932328224
step: 130, loss: 0.08256937563419342
step: 140, loss: 0.05867915228009224
step: 150, loss: 0.07124847173690796
step: 160, loss: 0.012435665354132652
step: 170, loss: 0.06635075062513351
step: 180, loss: 0.038889240473508835
step: 190, loss: 0.16115207970142365
step: 200, loss: 0.08488038927316666
step: 210, loss: 0.048217952251434326
step: 220, loss: 0.04428483173251152
step: 230, loss: 0.024054210633039474
step: 240, loss: 0.07314862310886383
step: 250, loss: 0.00810038112103939
step: 260, loss: 0.032080747187137604
step: 270, loss: 0.0677952691912651
step: 280, loss: 0.01618405431509018
step: 290, loss: 0.0374920517206192
step: 300, loss: 0.03092077001929283
step: 310, loss: 0.0633273497223854
step: 320, loss: 0.07811485975980759
step: 330, loss: 0.061108943074941635
step: 340, loss: 0.09857811033725739
step: 350, loss: 0.09404455125331879
step: 360, loss: 0.025730961933732033
step: 370, loss: 0.06150878220796585
step: 380, loss: 0.10043718665838242
step: 390, loss: 0.041997622698545456
step: 400, loss: 0.048656970262527466
step: 410, loss: 0.025249982252717018
step: 420, loss: 0.00015167135279625654
step: 430, loss: 0.0362776555120945
step: 440, loss: 0.16954466700553894
step: 450, loss: 0.0007318513817153871
step: 460, loss: 0.09887106716632843
step: 470, loss: 0.01360904797911644
step: 480, loss: 0.022444045171141624
step: 490, loss: 0.027161823585629463
step: 500, loss: 0.05386662110686302
step: 510, loss: 0.07745864242315292
step: 520, loss: 0.04844767600297928
step: 530, loss: 0.04015873745083809
step: 540, loss: 0.07323036342859268
step: 550, loss: 0.07879245281219482
step: 560, loss: 0.034660518169403076
step: 570, loss: 0.1091826856136322
step: 580, loss: 0.03996991366147995
step: 590, loss: 0.06341619789600372
step: 600, loss: 0.025091636925935745
step: 610, loss: 0.04552158713340759
step: 620, loss: 0.10873238742351532
step: 630, loss: 0.035888779908418655
step: 640, loss: 0.22850099205970764
step: 650, loss: 0.023270804435014725
step: 660, loss: 0.05205072462558746
step: 670, loss: 0.02161118946969509
step: 680, loss: 0.08975870162248611
step: 690, loss: 0.09299261122941971
step: 700, loss: 0.029514288529753685
step: 710, loss: 0.06108879670500755
step: 720, loss: 0.07364373654127121
step: 730, loss: 0.000273211975581944
step: 740, loss: 0.08888187259435654
step: 750, loss: 0.030053716152906418
step: 760, loss: 0.0832115188241005
step: 770, loss: 0.06822265684604645
step: 780, loss: 0.0003602697397582233
step: 790, loss: 0.014725659973919392
step: 800, loss: 0.07309034466743469
step: 810, loss: 0.010160109959542751
step: 820, loss: 0.04833853244781494
step: 830, loss: 0.0006331899203360081
step: 840, loss: 0.036739643663167953
step: 850, loss: 0.07486825436353683
step: 860, loss: 0.10288134217262268
step: 870, loss: 0.030353263020515442
step: 880, loss: 0.0006698906072415411
step: 890, loss: 0.028473062440752983
step: 900, loss: 0.07743636518716812
step: 910, loss: 0.0023231476079672575
step: 920, loss: 0.05239174887537956
step: 930, loss: 0.05782764405012131
step: 940, loss: 0.036045245826244354
step: 950, loss: 0.044073011726140976
step: 960, loss: 0.03446401655673981
step: 970, loss: 0.0658130869269371
epoch 15: dev_f1=0.9354536950420954, f1=0.9295380307979467, best_f1=0.9272065514103731
step: 0, loss: 0.02352135255932808
step: 10, loss: 0.0618101991713047
step: 20, loss: 0.0928172841668129
step: 30, loss: 0.060733117163181305
step: 40, loss: 0.12010611593723297
step: 50, loss: 0.040728017687797546
step: 60, loss: 0.001422347268089652
step: 70, loss: 0.16389714181423187
step: 80, loss: 0.02493169717490673
step: 90, loss: 0.0040769861079752445
step: 100, loss: 0.021944550797343254
step: 110, loss: 0.09431097656488419
step: 120, loss: 0.03135029971599579
step: 130, loss: 0.09122204035520554
step: 140, loss: 0.003197664860635996
step: 150, loss: 0.09519114345312119
step: 160, loss: 0.09651893377304077
step: 170, loss: 0.059339024126529694
step: 180, loss: 0.04351309314370155
step: 190, loss: 0.043649859726428986
step: 200, loss: 0.025952346622943878
step: 210, loss: 0.12317916005849838
step: 220, loss: 0.13494829833507538
step: 230, loss: 0.08025325834751129
step: 240, loss: 0.08294934779405594
step: 250, loss: 0.015164205804467201
step: 260, loss: 0.01801982894539833
step: 270, loss: 0.12917232513427734
step: 280, loss: 0.04072525352239609
step: 290, loss: 0.0735880434513092
step: 300, loss: 0.04103776067495346
step: 310, loss: 0.07002227753400803
step: 320, loss: 0.07060274481773376
step: 330, loss: 0.07425045222043991
step: 340, loss: 0.00011091557826148346
step: 350, loss: 0.041269514709711075
step: 360, loss: 0.04633529484272003
step: 370, loss: 0.1013827696442604
step: 380, loss: 0.17018860578536987
step: 390, loss: 0.019054317846894264
step: 400, loss: 0.06884162127971649
step: 410, loss: 0.13306045532226562
step: 420, loss: 0.021684641018509865
step: 430, loss: 0.1068054810166359
step: 440, loss: 0.07055115699768066
step: 450, loss: 0.044751036912202835
step: 460, loss: 0.07223778963088989
step: 470, loss: 0.04640655964612961
step: 480, loss: 0.01750536821782589
step: 490, loss: 0.10175810754299164
step: 500, loss: 0.04238947480916977
step: 510, loss: 0.016633037477731705
step: 520, loss: 0.10945291817188263
step: 530, loss: 0.04483425244688988
step: 540, loss: 0.07330071181058884
step: 550, loss: 0.00020234493422321975
step: 560, loss: 0.060387022793293
step: 570, loss: 0.07527540624141693
step: 580, loss: 0.048007141798734665
step: 590, loss: 0.01798669993877411
step: 600, loss: 0.05383027344942093
step: 610, loss: 0.09434416145086288
step: 620, loss: 0.07232899963855743
step: 630, loss: 0.05741341784596443
step: 640, loss: 0.0414138063788414
step: 650, loss: 0.08317398279905319
step: 660, loss: 0.07906243950128555
step: 670, loss: 0.015235464088618755
step: 680, loss: 0.0729902982711792
step: 690, loss: 0.03162268176674843
step: 700, loss: 0.0606362409889698
step: 710, loss: 0.04159849137067795
step: 720, loss: 0.03509140387177467
step: 730, loss: 0.03090519644320011
step: 740, loss: 0.0541679784655571
step: 750, loss: 0.06792986392974854
step: 760, loss: 0.102091945707798
step: 770, loss: 0.08378297090530396
step: 780, loss: 0.09352336078882217
step: 790, loss: 0.14247792959213257
step: 800, loss: 0.08674504607915878
step: 810, loss: 0.05507567524909973
step: 820, loss: 0.1375691294670105
step: 830, loss: 0.03409167379140854
step: 840, loss: 0.029238028451800346
step: 850, loss: 0.029715364798903465
step: 860, loss: 0.06300065666437149
step: 870, loss: 0.056668832898139954
step: 880, loss: 0.09323957562446594
step: 890, loss: 0.0459018349647522
step: 900, loss: 0.011248651891946793
step: 910, loss: 0.04046770557761192
step: 920, loss: 0.11560574173927307
step: 930, loss: 0.06899634748697281
step: 940, loss: 0.0326971560716629
step: 950, loss: 0.0817887932062149
step: 960, loss: 0.10535499453544617
step: 970, loss: 0.08607053756713867
epoch 16: dev_f1=0.9315196998123827, f1=0.9191210846189808, best_f1=0.9272065514103731
step: 0, loss: 0.039294496178627014
step: 10, loss: 0.12636123597621918
step: 20, loss: 0.01976255141198635
step: 30, loss: 0.04118647053837776
step: 40, loss: 0.023694908246397972
step: 50, loss: 0.043641578406095505
step: 60, loss: 0.029228052124381065
step: 70, loss: 0.01847071200609207
step: 80, loss: 0.008816927671432495
step: 90, loss: 0.037099335342645645
step: 100, loss: 0.02869958057999611
step: 110, loss: 0.07978744059801102
step: 120, loss: 0.04489131271839142
step: 130, loss: 0.09909947216510773
step: 140, loss: 0.0055329762399196625
step: 150, loss: 0.03304837644100189
step: 160, loss: 0.08825366199016571
step: 170, loss: 0.025559859350323677
step: 180, loss: 0.07403639703989029
step: 190, loss: 0.025285959243774414
step: 200, loss: 0.08484223484992981
step: 210, loss: 0.059321269392967224
step: 220, loss: 0.05806582048535347
step: 230, loss: 0.02651839330792427
step: 240, loss: 0.03413910046219826
step: 250, loss: 0.003024870064109564
step: 260, loss: 0.11717312037944794
step: 270, loss: 0.0016181360697373748
step: 280, loss: 0.05210120603442192
step: 290, loss: 6.21985673205927e-05
step: 300, loss: 0.05910378322005272
step: 310, loss: 0.03520737588405609
step: 320, loss: 0.031975727528333664
step: 330, loss: 0.07109610736370087
step: 340, loss: 0.058657195419073105
step: 350, loss: 0.09151661396026611
step: 360, loss: 0.026085739955306053
step: 370, loss: 0.032606348395347595
step: 380, loss: 0.02221437357366085
step: 390, loss: 0.061015862971544266
step: 400, loss: 0.08601027727127075
step: 410, loss: 0.05537211894989014
step: 420, loss: 0.00022772682132199407
step: 430, loss: 0.07861652970314026
step: 440, loss: 0.03513159975409508
step: 450, loss: 0.03178779035806656
step: 460, loss: 0.025392716750502586
step: 470, loss: 0.07088807970285416
step: 480, loss: 0.01198180764913559
step: 490, loss: 0.012863507494330406
step: 500, loss: 0.013366865925490856
step: 510, loss: 0.011058247648179531
step: 520, loss: 0.0738309919834137
step: 530, loss: 0.17795953154563904
step: 540, loss: 0.021029314026236534
step: 550, loss: 0.07062220573425293
step: 560, loss: 0.06764757633209229
step: 570, loss: 0.007948001846671104
step: 580, loss: 0.03607846796512604
step: 590, loss: 0.019217217341065407
step: 600, loss: 0.0001440961641492322
step: 610, loss: 0.06146633252501488
step: 620, loss: 0.0270374808460474
step: 630, loss: 0.06640469282865524
step: 640, loss: 0.029199596494436264
step: 650, loss: 0.09398014098405838
step: 660, loss: 0.04054153338074684
step: 670, loss: 0.015716323629021645
step: 680, loss: 0.02118466980755329
step: 690, loss: 0.02859075739979744
step: 700, loss: 0.025396987795829773
step: 710, loss: 0.13324257731437683
step: 720, loss: 0.08050716668367386
step: 730, loss: 0.04635684937238693
step: 740, loss: 0.13876979053020477
step: 750, loss: 0.009633716195821762
step: 760, loss: 0.047954678535461426
step: 770, loss: 0.18079924583435059
step: 780, loss: 0.05548003315925598
step: 790, loss: 0.10958468168973923
step: 800, loss: 0.10501234233379364
step: 810, loss: 0.014533326961100101
step: 820, loss: 0.021845264360308647
step: 830, loss: 0.006182205863296986
step: 840, loss: 0.08419699966907501
step: 850, loss: 0.021728450432419777
step: 860, loss: 0.05208354815840721
step: 870, loss: 0.07078450918197632
step: 880, loss: 0.04099631309509277
step: 890, loss: 0.024854425340890884
step: 900, loss: 0.07206214964389801
step: 910, loss: 0.02510722540318966
step: 920, loss: 0.08965005725622177
step: 930, loss: 0.04559299722313881
step: 940, loss: 0.10259491950273514
step: 950, loss: 0.06984394043684006
step: 960, loss: 0.0013895996380597353
step: 970, loss: 0.08094091713428497
epoch 17: dev_f1=0.929683813119396, f1=0.9269901083372586, best_f1=0.9272065514103731
step: 0, loss: 0.10062060505151749
step: 10, loss: 2.3929565941216424e-05
step: 20, loss: 0.06120297685265541
step: 30, loss: 0.0757126435637474
step: 40, loss: 0.08165469020605087
step: 50, loss: 0.02750595472753048
step: 60, loss: 2.6989706384483725e-05
step: 70, loss: 0.027122117578983307
step: 80, loss: 0.08443515002727509
step: 90, loss: 0.05658534914255142
step: 100, loss: 0.08418209850788116
step: 110, loss: 0.009755420498549938
step: 120, loss: 0.021855253726243973
step: 130, loss: 0.005157762207090855
step: 140, loss: 0.027303503826260567
step: 150, loss: 0.058719225227832794
step: 160, loss: 0.04107912629842758
step: 170, loss: 1.6889551261556335e-05
step: 180, loss: 0.03649768978357315
step: 190, loss: 0.015198235400021076
step: 200, loss: 0.0592825822532177
step: 210, loss: 0.027543742209672928
step: 220, loss: 0.022786717861890793
step: 230, loss: 0.10905972868204117
step: 240, loss: 0.038104329258203506
step: 250, loss: 0.016492526978254318
step: 260, loss: 0.032901275902986526
step: 270, loss: 0.03885386511683464
step: 280, loss: 0.04546155408024788
step: 290, loss: 0.15647737681865692
step: 300, loss: 0.022371787577867508
step: 310, loss: 0.03675070032477379
step: 320, loss: 0.03489242494106293
step: 330, loss: 0.0859941691160202
step: 340, loss: 0.08997450023889542
step: 350, loss: 0.08251595497131348
step: 360, loss: 0.014049003832042217
step: 370, loss: 0.07888149470090866
step: 380, loss: 0.056355997920036316
step: 390, loss: 0.030068695545196533
step: 400, loss: 0.018410470336675644
step: 410, loss: 0.09855284541845322
step: 420, loss: 0.036616064608097076
step: 430, loss: 0.010235348716378212
step: 440, loss: 0.11428992450237274
step: 450, loss: 7.040747732389718e-05
step: 460, loss: 0.039651576429605484
step: 470, loss: 0.14222782850265503
step: 480, loss: 0.0013738240813836455
step: 490, loss: 0.0529470220208168
step: 500, loss: 0.03135493025183678
step: 510, loss: 0.025610975921154022
step: 520, loss: 0.0416550487279892
step: 530, loss: 0.07830341905355453
step: 540, loss: 0.049485716968774796
step: 550, loss: 0.04896559938788414
step: 560, loss: 0.02655571512877941
step: 570, loss: 0.045185159891843796
step: 580, loss: 0.033502012491226196
step: 590, loss: 0.019957832992076874
step: 600, loss: 0.05854979529976845
step: 610, loss: 0.0001383535418426618
step: 620, loss: 0.06747907400131226
step: 630, loss: 0.03958747908473015
step: 640, loss: 0.05842479690909386
step: 650, loss: 0.05665832385420799
step: 660, loss: 0.000508465280290693
step: 670, loss: 0.05923255905508995
step: 680, loss: 0.09041693806648254
step: 690, loss: 0.07351328432559967
step: 700, loss: 0.03084898740053177
step: 710, loss: 0.07652672380208969
step: 720, loss: 8.193909889087081e-05
step: 730, loss: 0.04228490963578224
step: 740, loss: 0.06617824733257294
step: 750, loss: 0.04321533441543579
step: 760, loss: 0.07465357333421707
step: 770, loss: 0.07346287369728088
step: 780, loss: 0.07088509202003479
step: 790, loss: 0.032068297266960144
step: 800, loss: 0.21932272613048553
step: 810, loss: 0.06529511511325836
step: 820, loss: 0.0667862817645073
step: 830, loss: 0.07438667118549347
step: 840, loss: 0.07236640155315399
step: 850, loss: 0.056183893233537674
step: 860, loss: 0.11706728488206863
step: 870, loss: 0.018584521487355232
step: 880, loss: 0.048320237547159195
step: 890, loss: 0.039968591183423996
step: 900, loss: 0.04139459505677223
step: 910, loss: 0.03686299920082092
step: 920, loss: 0.02706843614578247
step: 930, loss: 0.022039037197828293
step: 940, loss: 0.04693613201379776
step: 950, loss: 0.00032666116021573544
step: 960, loss: 0.015871131792664528
step: 970, loss: 0.05793570354580879
epoch 18: dev_f1=0.9326424870466321, f1=0.9276315789473684, best_f1=0.9272065514103731
step: 0, loss: 0.040657639503479004
step: 10, loss: 0.08070208132266998
step: 20, loss: 0.07279638946056366
step: 30, loss: 0.038932498544454575
step: 40, loss: 0.10524433106184006
step: 50, loss: 0.033304013311862946
step: 60, loss: 0.023972993716597557
step: 70, loss: 0.04506458342075348
step: 80, loss: 0.036681272089481354
step: 90, loss: 0.018730107694864273
step: 100, loss: 0.08902154862880707
step: 110, loss: 0.05886536464095116
step: 120, loss: 0.056188877671957016
step: 130, loss: 6.370089977281168e-05
step: 140, loss: 0.0031238256487995386
step: 150, loss: 0.0032226720359176397
step: 160, loss: 0.03485822677612305
step: 170, loss: 0.008699001744389534
step: 180, loss: 0.010460817255079746
step: 190, loss: 0.10386905074119568
step: 200, loss: 0.04940817877650261
step: 210, loss: 0.023718886077404022
step: 220, loss: 0.03865643963217735
step: 230, loss: 0.01979460008442402
step: 240, loss: 0.03521052002906799
step: 250, loss: 0.02910481207072735
step: 260, loss: 0.08760996907949448
step: 270, loss: 0.08656642585992813
step: 280, loss: 0.04223527014255524
step: 290, loss: 0.05947245657444
step: 300, loss: 0.0659635066986084
step: 310, loss: 0.04688629135489464
step: 320, loss: 0.023043911904096603
step: 330, loss: 4.681473001255654e-05
step: 340, loss: 0.08817417919635773
step: 350, loss: 0.07557374238967896
step: 360, loss: 5.4464468121295795e-05
step: 370, loss: 0.02441762201488018
step: 380, loss: 0.029944907873868942
step: 390, loss: 0.053259629756212234
step: 400, loss: 0.04852190986275673
step: 410, loss: 0.0001301792508456856
step: 420, loss: 0.026357678696513176
step: 430, loss: 0.02550720050930977
step: 440, loss: 0.053493306040763855
step: 450, loss: 0.05253142863512039
step: 460, loss: 0.027787119150161743
step: 470, loss: 0.027173053473234177
step: 480, loss: 0.04382438212633133
step: 490, loss: 7.192351040430367e-05
step: 500, loss: 0.026821095496416092
step: 510, loss: 0.0071411291137337685
step: 520, loss: 0.014281278476119041
step: 530, loss: 0.04246446117758751
step: 540, loss: 0.009966909885406494
step: 550, loss: 0.12367648631334305
step: 560, loss: 0.03877784311771393
step: 570, loss: 0.031010543927550316
step: 580, loss: 0.015512621030211449
step: 590, loss: 0.10293669998645782
step: 600, loss: 0.0002706779050640762
step: 610, loss: 0.22500455379486084
step: 620, loss: 0.036436375230550766
step: 630, loss: 0.06338096410036087
step: 640, loss: 0.022768931463360786
step: 650, loss: 0.07073057442903519
step: 660, loss: 0.03746896982192993
step: 670, loss: 0.030251264572143555
step: 680, loss: 0.048874735832214355
step: 690, loss: 0.07780532538890839
step: 700, loss: 0.014025525189936161
step: 710, loss: 0.05387735366821289
step: 720, loss: 0.025950489565730095
step: 730, loss: 0.033248305320739746
step: 740, loss: 0.06026627868413925
step: 750, loss: 0.04469098150730133
step: 760, loss: 0.050048407167196274
step: 770, loss: 0.016611747443675995
step: 780, loss: 0.03195049241185188
step: 790, loss: 5.1938110118499026e-05
step: 800, loss: 0.04640023410320282
step: 810, loss: 0.018324794247746468
step: 820, loss: 0.04017949104309082
step: 830, loss: 0.03904277831315994
step: 840, loss: 0.0919719785451889
step: 850, loss: 0.04488283768296242
step: 860, loss: 0.03917421028017998
step: 870, loss: 0.09862559288740158
step: 880, loss: 0.03651795536279678
step: 890, loss: 0.05163918435573578
step: 900, loss: 0.002002009656280279
step: 910, loss: 0.08465828001499176
step: 920, loss: 0.0462878942489624
step: 930, loss: 0.05358148738741875
step: 940, loss: 0.13675394654273987
step: 950, loss: 0.09423122555017471
step: 960, loss: 0.04312090575695038
step: 970, loss: 0.0010201161494478583
epoch 19: dev_f1=0.9348946135831382, f1=0.9258741258741259, best_f1=0.9272065514103731
step: 0, loss: 0.04143823683261871
step: 10, loss: 0.0036117113195359707
step: 20, loss: 0.06776029616594315
step: 30, loss: 0.009537352249026299
step: 40, loss: 0.043678320944309235
step: 50, loss: 0.08575956523418427
step: 60, loss: 0.0011002003448083997
step: 70, loss: 0.044584356248378754
step: 80, loss: 0.058625634759664536
step: 90, loss: 0.013717487454414368
step: 100, loss: 0.0017776702297851443
step: 110, loss: 0.01477423682808876
step: 120, loss: 0.015369325876235962
step: 130, loss: 0.054765667766332626
step: 140, loss: 0.0677710771560669
step: 150, loss: 0.024021657183766365
step: 160, loss: 0.026794448494911194
step: 170, loss: 0.016397599130868912
step: 180, loss: 0.06151188537478447
step: 190, loss: 0.10473527759313583
step: 200, loss: 0.056352194398641586
step: 210, loss: 0.02750501036643982
step: 220, loss: 0.04886815324425697
step: 230, loss: 0.07711558789014816
step: 240, loss: 0.025562487542629242
step: 250, loss: 0.06969855725765228
step: 260, loss: 0.0003218448255211115
step: 270, loss: 0.09811834990978241
step: 280, loss: 0.07876424491405487
step: 290, loss: 0.05724542215466499
step: 300, loss: 0.04783302918076515
step: 310, loss: 0.04529256001114845
step: 320, loss: 0.016103781759738922
step: 330, loss: 0.06960590928792953
step: 340, loss: 0.018147248774766922
step: 350, loss: 6.739389937138185e-05
step: 360, loss: 0.00015953826368786395
step: 370, loss: 0.05791812762618065
step: 380, loss: 0.06969302892684937
step: 390, loss: 0.06284463405609131
step: 400, loss: 0.05846782773733139
step: 410, loss: 0.01960730366408825
step: 420, loss: 0.1154593750834465
step: 430, loss: 0.054078809916973114
step: 440, loss: 0.0003572555724531412
step: 450, loss: 0.011699042282998562
step: 460, loss: 0.020499922335147858
step: 470, loss: 0.04851524904370308
step: 480, loss: 1.3626960935653187e-05
step: 490, loss: 0.014683207497000694
step: 500, loss: 0.0868137925863266
step: 510, loss: 0.01304898876696825
step: 520, loss: 0.012067117728292942
step: 530, loss: 0.10851474106311798
step: 540, loss: 0.04269606992602348
step: 550, loss: 0.028491631150245667
step: 560, loss: 0.0012038606218993664
step: 570, loss: 0.05976239964365959
step: 580, loss: 0.015508290380239487
step: 590, loss: 0.058988962322473526
step: 600, loss: 0.042886946350336075
step: 610, loss: 0.05937520042061806
step: 620, loss: 3.287502840976231e-05
step: 630, loss: 0.07127168774604797
step: 640, loss: 0.07534737139940262
step: 650, loss: 0.02868625521659851
step: 660, loss: 0.027784503996372223
step: 670, loss: 0.03826889023184776
step: 680, loss: 0.0359623022377491
step: 690, loss: 0.023696966469287872
step: 700, loss: 0.049637362360954285
step: 710, loss: 0.02705184370279312
step: 720, loss: 0.032788123935461044
step: 730, loss: 0.03723521903157234
step: 740, loss: 0.08689231425523758
step: 750, loss: 0.01337154395878315
step: 760, loss: 0.02862115576863289
step: 770, loss: 0.04627300798892975
step: 780, loss: 0.07426934689283371
step: 790, loss: 0.04787182807922363
step: 800, loss: 0.018267890438437462
step: 810, loss: 0.06954673677682877
step: 820, loss: 0.02422480843961239
step: 830, loss: 0.07408671081066132
step: 840, loss: 7.427716627717018e-05
step: 850, loss: 0.030647287145256996
step: 860, loss: 0.08483660221099854
step: 870, loss: 0.09676989912986755
step: 880, loss: 0.08714795112609863
step: 890, loss: 0.10865733027458191
step: 900, loss: 0.016458231955766678
step: 910, loss: 0.00035722707980312407
step: 920, loss: 0.05262323096394539
step: 930, loss: 0.08968967199325562
step: 940, loss: 0.04471362382173538
step: 950, loss: 0.008295299485325813
step: 960, loss: 0.05360671132802963
step: 970, loss: 0.0487014465034008
epoch 20: dev_f1=0.9340866290018832, f1=0.9255966307908282, best_f1=0.9272065514103731
