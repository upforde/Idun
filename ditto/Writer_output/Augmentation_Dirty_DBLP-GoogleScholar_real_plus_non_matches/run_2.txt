cuda
Device: cuda
step: 0, loss: 0.8426950573921204
step: 10, loss: 0.37516534328460693
step: 20, loss: 0.4224012494087219
step: 30, loss: 0.3707955777645111
step: 40, loss: 0.28547796607017517
step: 50, loss: 0.3428955078125
step: 60, loss: 0.19257797300815582
step: 70, loss: 0.3150534927845001
step: 80, loss: 0.14498956501483917
step: 90, loss: 0.12104593962430954
step: 100, loss: 0.2694413661956787
step: 110, loss: 0.16039319336414337
step: 120, loss: 0.27020686864852905
step: 130, loss: 0.14429154992103577
step: 140, loss: 0.09714175760746002
step: 150, loss: 0.19342520833015442
step: 160, loss: 0.2270810753107071
step: 170, loss: 0.15046143531799316
step: 180, loss: 0.14610089361667633
step: 190, loss: 0.21491490304470062
step: 200, loss: 0.26089397072792053
step: 210, loss: 0.30428287386894226
step: 220, loss: 0.07186318933963776
step: 230, loss: 0.22500161826610565
step: 240, loss: 0.18234287202358246
step: 250, loss: 0.07386589795351028
step: 260, loss: 0.11243307590484619
step: 270, loss: 0.09232917428016663
step: 280, loss: 0.14293240010738373
step: 290, loss: 0.10639964044094086
step: 300, loss: 0.21362558007240295
step: 310, loss: 0.0831967443227768
step: 320, loss: 0.1607116013765335
step: 330, loss: 0.25433626770973206
step: 340, loss: 0.2315531224012375
step: 350, loss: 0.26962655782699585
step: 360, loss: 0.19533021748065948
step: 370, loss: 0.31964048743247986
step: 380, loss: 0.09005796909332275
step: 390, loss: 0.2974195182323456
step: 400, loss: 0.13036811351776123
step: 410, loss: 0.131642684340477
step: 420, loss: 0.16550402343273163
step: 430, loss: 0.14163072407245636
step: 440, loss: 0.07277410477399826
step: 450, loss: 0.13108322024345398
step: 460, loss: 0.09236257523298264
step: 470, loss: 0.11266347020864487
step: 480, loss: 0.09333693981170654
step: 490, loss: 0.09818433225154877
step: 500, loss: 0.20796799659729004
step: 510, loss: 0.1139930933713913
step: 520, loss: 0.10991036891937256
step: 530, loss: 0.09294367581605911
step: 540, loss: 0.13254210352897644
step: 550, loss: 0.07965973764657974
step: 560, loss: 0.11638510227203369
step: 570, loss: 0.11465873569250107
step: 580, loss: 0.15798890590667725
step: 590, loss: 0.1621091216802597
step: 600, loss: 0.14865048229694366
step: 610, loss: 0.15326179563999176
step: 620, loss: 0.11280045658349991
step: 630, loss: 0.07684998959302902
step: 640, loss: 0.1670326292514801
step: 650, loss: 0.12036068737506866
step: 660, loss: 0.1753842979669571
step: 670, loss: 0.17130260169506073
step: 680, loss: 0.039733950048685074
step: 690, loss: 0.20006871223449707
step: 700, loss: 0.18620628118515015
step: 710, loss: 0.04643550142645836
step: 720, loss: 0.14080126583576202
step: 730, loss: 0.05966932326555252
step: 740, loss: 0.1757037192583084
step: 750, loss: 0.05617590993642807
step: 760, loss: 0.13450856506824493
step: 770, loss: 0.17690551280975342
step: 780, loss: 0.20230625569820404
step: 790, loss: 0.14368586242198944
step: 800, loss: 0.17674991488456726
step: 810, loss: 0.1269223392009735
step: 820, loss: 0.0718846321105957
step: 830, loss: 0.16015923023223877
step: 840, loss: 0.10471102595329285
step: 850, loss: 0.18149346113204956
step: 860, loss: 0.09059316664934158
step: 870, loss: 0.12003373354673386
step: 880, loss: 0.11369512975215912
step: 890, loss: 0.15378792583942413
step: 900, loss: 0.17324425280094147
step: 910, loss: 0.13202807307243347
step: 920, loss: 0.18575823307037354
step: 930, loss: 0.13965961337089539
step: 940, loss: 0.08709701895713806
step: 950, loss: 0.1247466653585434
step: 960, loss: 0.037846725434064865
step: 970, loss: 0.12389010190963745
epoch 1: dev_f1=0.9332087809434843, f1=0.9301675977653632, best_f1=0.9301675977653632
step: 0, loss: 0.06903492659330368
step: 10, loss: 0.2198493629693985
step: 20, loss: 0.13128601014614105
step: 30, loss: 0.09099125117063522
step: 40, loss: 0.11853962391614914
step: 50, loss: 0.17492972314357758
step: 60, loss: 0.20622144639492035
step: 70, loss: 0.26075130701065063
step: 80, loss: 0.10461500287055969
step: 90, loss: 0.09338665008544922
step: 100, loss: 0.11712457984685898
step: 110, loss: 0.18908865749835968
step: 120, loss: 0.2286166399717331
step: 130, loss: 0.3008323311805725
step: 140, loss: 0.06199195981025696
step: 150, loss: 0.3161565065383911
step: 160, loss: 0.1643846482038498
step: 170, loss: 0.1863260418176651
step: 180, loss: 0.03447999805212021
step: 190, loss: 0.2578944265842438
step: 200, loss: 0.23793116211891174
step: 210, loss: 0.14244917035102844
step: 220, loss: 0.21861541271209717
step: 230, loss: 0.11689312011003494
step: 240, loss: 0.15211515128612518
step: 250, loss: 0.1486266404390335
step: 260, loss: 0.15337389707565308
step: 270, loss: 0.14246833324432373
step: 280, loss: 0.0822853371500969
step: 290, loss: 0.060509659349918365
step: 300, loss: 0.25868067145347595
step: 310, loss: 0.14208905398845673
step: 320, loss: 0.05974379926919937
step: 330, loss: 0.057919420301914215
step: 340, loss: 0.15580768883228302
step: 350, loss: 0.10543869435787201
step: 360, loss: 0.14005890488624573
step: 370, loss: 0.1415153443813324
step: 380, loss: 0.14858098328113556
step: 390, loss: 0.15307645499706268
step: 400, loss: 0.13567477464675903
step: 410, loss: 0.18310311436653137
step: 420, loss: 0.29837557673454285
step: 430, loss: 0.08484324812889099
step: 440, loss: 0.14016669988632202
step: 450, loss: 0.08390312641859055
step: 460, loss: 0.12512952089309692
step: 470, loss: 0.13536900281906128
step: 480, loss: 0.08069505542516708
step: 490, loss: 0.16050687432289124
step: 500, loss: 0.28959891200065613
step: 510, loss: 0.16528907418251038
step: 520, loss: 0.13259294629096985
step: 530, loss: 0.0700496956706047
step: 540, loss: 0.04924249276518822
step: 550, loss: 0.09705428034067154
step: 560, loss: 0.12374848872423172
step: 570, loss: 0.14164292812347412
step: 580, loss: 0.10755383223295212
step: 590, loss: 0.09974370896816254
step: 600, loss: 0.12522704899311066
step: 610, loss: 0.1918020397424698
step: 620, loss: 0.20838278532028198
step: 630, loss: 0.15242595970630646
step: 640, loss: 0.124029740691185
step: 650, loss: 0.16656500101089478
step: 660, loss: 0.1885327696800232
step: 670, loss: 0.12903465330600739
step: 680, loss: 0.08133292198181152
step: 690, loss: 0.11271730065345764
step: 700, loss: 0.04780514910817146
step: 710, loss: 0.04693024978041649
step: 720, loss: 0.12413225322961807
step: 730, loss: 0.4014368951320648
step: 740, loss: 0.13368915021419525
step: 750, loss: 0.03629707172513008
step: 760, loss: 0.1766485720872879
step: 770, loss: 0.1407725214958191
step: 780, loss: 0.27294784784317017
step: 790, loss: 0.10603681951761246
step: 800, loss: 0.226657897233963
step: 810, loss: 0.09035822749137878
step: 820, loss: 0.13335435092449188
step: 830, loss: 0.1327316164970398
step: 840, loss: 0.06730350852012634
step: 850, loss: 0.07162270694971085
step: 860, loss: 0.10994184017181396
step: 870, loss: 0.19471555948257446
step: 880, loss: 0.23370841145515442
step: 890, loss: 0.12087368965148926
step: 900, loss: 0.12300244718790054
step: 910, loss: 0.1580374538898468
step: 920, loss: 0.11617375165224075
step: 930, loss: 0.017350981011986732
step: 940, loss: 0.18143707513809204
step: 950, loss: 0.285171777009964
step: 960, loss: 0.19613975286483765
step: 970, loss: 0.07756122946739197
epoch 2: dev_f1=0.9167050161067648, f1=0.9157175398633257, best_f1=0.9301675977653632
step: 0, loss: 0.17791813611984253
step: 10, loss: 0.04405707120895386
step: 20, loss: 0.15167897939682007
step: 30, loss: 0.10183876752853394
step: 40, loss: 0.09594245254993439
step: 50, loss: 0.12423860281705856
step: 60, loss: 0.06993625313043594
step: 70, loss: 0.1452893316745758
step: 80, loss: 0.05004388093948364
step: 90, loss: 0.13319650292396545
step: 100, loss: 0.09600572288036346
step: 110, loss: 0.04297114163637161
step: 120, loss: 0.3043239712715149
step: 130, loss: 0.17304110527038574
step: 140, loss: 0.08786693960428238
step: 150, loss: 0.05113993212580681
step: 160, loss: 0.15799424052238464
step: 170, loss: 0.1286444365978241
step: 180, loss: 0.08874634653329849
step: 190, loss: 0.15679019689559937
step: 200, loss: 0.15751640498638153
step: 210, loss: 0.0652613639831543
step: 220, loss: 0.14528000354766846
step: 230, loss: 0.14886978268623352
step: 240, loss: 0.07002095878124237
step: 250, loss: 0.09129364788532257
step: 260, loss: 0.07815409451723099
step: 270, loss: 0.13964709639549255
step: 280, loss: 0.16864818334579468
step: 290, loss: 0.15302981436252594
step: 300, loss: 0.04713015258312225
step: 310, loss: 0.08917137235403061
step: 320, loss: 0.15282945334911346
step: 330, loss: 0.031121231615543365
step: 340, loss: 0.019674932584166527
step: 350, loss: 0.12629583477973938
step: 360, loss: 0.16050267219543457
step: 370, loss: 0.1464637666940689
step: 380, loss: 0.06874119490385056
step: 390, loss: 0.07148056477308273
step: 400, loss: 0.14527693390846252
step: 410, loss: 0.09905020892620087
step: 420, loss: 0.15163536369800568
step: 430, loss: 0.16247974336147308
step: 440, loss: 0.12708351016044617
step: 450, loss: 0.11967746913433075
step: 460, loss: 0.1938447803258896
step: 470, loss: 0.15751829743385315
step: 480, loss: 0.14038081467151642
step: 490, loss: 0.21575765311717987
step: 500, loss: 0.15285484492778778
step: 510, loss: 0.12825460731983185
step: 520, loss: 0.1446945071220398
step: 530, loss: 0.1048043817281723
step: 540, loss: 0.05681738257408142
step: 550, loss: 0.1715567409992218
step: 560, loss: 0.08471497148275375
step: 570, loss: 0.07869438081979752
step: 580, loss: 0.1736547201871872
step: 590, loss: 0.1329811066389084
step: 600, loss: 0.13606160879135132
step: 610, loss: 0.17000453174114227
step: 620, loss: 0.05556102842092514
step: 630, loss: 0.09899879992008209
step: 640, loss: 0.21657441556453705
step: 650, loss: 0.06823481619358063
step: 660, loss: 0.12997247278690338
step: 670, loss: 0.050408780574798584
step: 680, loss: 0.18150073289871216
step: 690, loss: 0.13811299204826355
step: 700, loss: 0.08690909296274185
step: 710, loss: 0.0782756507396698
step: 720, loss: 0.19770245254039764
step: 730, loss: 0.060080092400312424
step: 740, loss: 0.1971462070941925
step: 750, loss: 0.08715427666902542
step: 760, loss: 0.2631963789463043
step: 770, loss: 0.12863260507583618
step: 780, loss: 0.14681467413902283
step: 790, loss: 0.05514843761920929
step: 800, loss: 0.3063351809978485
step: 810, loss: 0.10250841826200485
step: 820, loss: 0.23023450374603271
step: 830, loss: 0.12021952122449875
step: 840, loss: 0.09524470567703247
step: 850, loss: 0.22780419886112213
step: 860, loss: 0.18442073464393616
step: 870, loss: 0.05881057307124138
step: 880, loss: 0.07310828566551208
step: 890, loss: 0.1374073326587677
step: 900, loss: 0.08847783505916595
step: 910, loss: 0.09538205713033676
step: 920, loss: 0.08367917686700821
step: 930, loss: 0.14629919826984406
step: 940, loss: 0.11722740530967712
step: 950, loss: 0.20194680988788605
step: 960, loss: 0.06508056819438934
step: 970, loss: 0.2846162021160126
epoch 3: dev_f1=0.9162790697674419, f1=0.9114272602111061, best_f1=0.9301675977653632
step: 0, loss: 0.14460374414920807
step: 10, loss: 0.11649294942617416
step: 20, loss: 0.11598600447177887
step: 30, loss: 0.18953749537467957
step: 40, loss: 0.07060844451189041
step: 50, loss: 0.11696859449148178
step: 60, loss: 0.11034560203552246
step: 70, loss: 0.044359657913446426
step: 80, loss: 0.13106125593185425
step: 90, loss: 0.12143902480602264
step: 100, loss: 0.1688418686389923
step: 110, loss: 0.044621966779232025
step: 120, loss: 0.050519295036792755
step: 130, loss: 0.1109718605875969
step: 140, loss: 0.07710903137922287
step: 150, loss: 0.10433350503444672
step: 160, loss: 0.19019828736782074
step: 170, loss: 0.07916931807994843
step: 180, loss: 0.10763541609048843
step: 190, loss: 0.05591318756341934
step: 200, loss: 0.1211118996143341
step: 210, loss: 0.1564388871192932
step: 220, loss: 0.06656420230865479
step: 230, loss: 0.09721928834915161
step: 240, loss: 0.07948540896177292
step: 250, loss: 0.13028374314308167
step: 260, loss: 0.10049140453338623
step: 270, loss: 0.09963124990463257
step: 280, loss: 0.1873636096715927
step: 290, loss: 0.08669351786375046
step: 300, loss: 0.2436700016260147
step: 310, loss: 0.11219596862792969
step: 320, loss: 0.08844801783561707
step: 330, loss: 0.09781315922737122
step: 340, loss: 0.08216703683137894
step: 350, loss: 0.055496808141469955
step: 360, loss: 0.10364922881126404
step: 370, loss: 0.06842755526304245
step: 380, loss: 0.0622267983853817
step: 390, loss: 0.08916298300027847
step: 400, loss: 0.2298951894044876
step: 410, loss: 0.06609150767326355
step: 420, loss: 0.1402711570262909
step: 430, loss: 0.16719180345535278
step: 440, loss: 0.15114553272724152
step: 450, loss: 0.11068980395793915
step: 460, loss: 0.14241454005241394
step: 470, loss: 0.026916420087218285
step: 480, loss: 0.16006538271903992
step: 490, loss: 0.0790424793958664
step: 500, loss: 0.15296638011932373
step: 510, loss: 0.09043243527412415
step: 520, loss: 0.03141903877258301
step: 530, loss: 0.10735859721899033
step: 540, loss: 0.07441046833992004
step: 550, loss: 0.07365026324987411
step: 560, loss: 0.09242253750562668
step: 570, loss: 0.09689450263977051
step: 580, loss: 0.12380392104387283
step: 590, loss: 0.15772050619125366
step: 600, loss: 0.08848781138658524
step: 610, loss: 0.06042516976594925
step: 620, loss: 0.1584249585866928
step: 630, loss: 0.2566535472869873
step: 640, loss: 0.21425959467887878
step: 650, loss: 0.061420854181051254
step: 660, loss: 0.20718322694301605
step: 670, loss: 0.0630379468202591
step: 680, loss: 0.07819393277168274
step: 690, loss: 0.2822801172733307
step: 700, loss: 0.2426198124885559
step: 710, loss: 0.16485320031642914
step: 720, loss: 0.05514661222696304
step: 730, loss: 0.16951139271259308
step: 740, loss: 0.06039159372448921
step: 750, loss: 0.17688025534152985
step: 760, loss: 0.055231060832738876
step: 770, loss: 0.05804656818509102
step: 780, loss: 0.03379739448428154
step: 790, loss: 0.05338583141565323
step: 800, loss: 0.10580722987651825
step: 810, loss: 0.16015037894248962
step: 820, loss: 0.12613768875598907
step: 830, loss: 0.08113706856966019
step: 840, loss: 0.095871202647686
step: 850, loss: 0.06286409497261047
step: 860, loss: 0.18300504982471466
step: 870, loss: 0.05781593173742294
step: 880, loss: 0.08130114525556564
step: 890, loss: 0.10452013462781906
step: 900, loss: 0.09762051701545715
step: 910, loss: 0.10680349916219711
step: 920, loss: 0.1302867829799652
step: 930, loss: 0.044330354779958725
step: 940, loss: 0.20637771487236023
step: 950, loss: 0.1650165617465973
step: 960, loss: 0.033155590295791626
step: 970, loss: 0.060444265604019165
epoch 4: dev_f1=0.9272137227630968, f1=0.9243619489559165, best_f1=0.9301675977653632
step: 0, loss: 0.11188304424285889
step: 10, loss: 0.14300227165222168
step: 20, loss: 0.23342040181159973
step: 30, loss: 0.04539921507239342
step: 40, loss: 0.08686769753694534
step: 50, loss: 0.03761123865842819
step: 60, loss: 0.04578186944127083
step: 70, loss: 0.044041458517313004
step: 80, loss: 0.05527946352958679
step: 90, loss: 0.13282015919685364
step: 100, loss: 0.13538937270641327
step: 110, loss: 0.11522790044546127
step: 120, loss: 0.020425962284207344
step: 130, loss: 0.17488980293273926
step: 140, loss: 0.12719254195690155
step: 150, loss: 0.31289440393447876
step: 160, loss: 0.03631488233804703
step: 170, loss: 0.19356021285057068
step: 180, loss: 0.22606807947158813
step: 190, loss: 0.057500209659338
step: 200, loss: 0.11213622242212296
step: 210, loss: 0.1303398162126541
step: 220, loss: 0.0987527072429657
step: 230, loss: 0.03547651693224907
step: 240, loss: 0.16004694998264313
step: 250, loss: 0.07372797280550003
step: 260, loss: 0.06649194657802582
step: 270, loss: 0.019415048882365227
step: 280, loss: 0.1279766857624054
step: 290, loss: 0.15646661818027496
step: 300, loss: 0.1436167061328888
step: 310, loss: 0.01804710365831852
step: 320, loss: 0.06519479304552078
step: 330, loss: 0.020898204296827316
step: 340, loss: 0.0688052549958229
step: 350, loss: 0.23456983268260956
step: 360, loss: 0.06137745827436447
step: 370, loss: 0.15124517679214478
step: 380, loss: 0.12550663948059082
step: 390, loss: 0.07398062199354172
step: 400, loss: 0.10992610454559326
step: 410, loss: 0.09566235542297363
step: 420, loss: 0.11029242724180222
step: 430, loss: 0.07140618562698364
step: 440, loss: 0.09915296733379364
step: 450, loss: 0.17006143927574158
step: 460, loss: 0.09141825139522552
step: 470, loss: 0.09418687969446182
step: 480, loss: 0.06045381352305412
step: 490, loss: 0.051771823316812515
step: 500, loss: 0.2967683672904968
step: 510, loss: 0.04190285876393318
step: 520, loss: 0.10466602444648743
step: 530, loss: 0.03071734681725502
step: 540, loss: 0.2664719521999359
step: 550, loss: 0.10813764482736588
step: 560, loss: 0.11209256947040558
step: 570, loss: 0.12383012473583221
step: 580, loss: 0.07787159085273743
step: 590, loss: 0.03358210623264313
step: 600, loss: 0.12794248759746552
step: 610, loss: 0.059938911348581314
step: 620, loss: 0.12901253998279572
step: 630, loss: 0.010526098310947418
step: 640, loss: 0.03967555612325668
step: 650, loss: 0.017427535727620125
step: 660, loss: 0.07879151403903961
step: 670, loss: 0.28024351596832275
step: 680, loss: 0.1290569007396698
step: 690, loss: 0.06620756536722183
step: 700, loss: 0.11873950064182281
step: 710, loss: 0.0823824480175972
step: 720, loss: 0.1372191458940506
step: 730, loss: 0.10182680934667587
step: 740, loss: 0.06525880098342896
step: 750, loss: 0.19021287560462952
step: 760, loss: 0.0836460143327713
step: 770, loss: 0.07933476567268372
step: 780, loss: 0.05521435663104057
step: 790, loss: 0.040032561868429184
step: 800, loss: 0.06633467227220535
step: 810, loss: 0.273529052734375
step: 820, loss: 0.129910409450531
step: 830, loss: 0.11521740257740021
step: 840, loss: 0.099545419216156
step: 850, loss: 0.05981983244419098
step: 860, loss: 0.16161611676216125
step: 870, loss: 0.13794907927513123
step: 880, loss: 0.07512298226356506
step: 890, loss: 0.11219178885221481
step: 900, loss: 0.16273242235183716
step: 910, loss: 0.09680743515491486
step: 920, loss: 0.09953191876411438
step: 930, loss: 0.035799168050289154
step: 940, loss: 0.2216656655073166
step: 950, loss: 0.08327091485261917
step: 960, loss: 0.12122318148612976
step: 970, loss: 0.15600910782814026
epoch 5: dev_f1=0.934065934065934, f1=0.935528120713306, best_f1=0.935528120713306
step: 0, loss: 0.012867825105786324
step: 10, loss: 0.16619186103343964
step: 20, loss: 0.027147551998496056
step: 30, loss: 0.052480731159448624
step: 40, loss: 0.02547612227499485
step: 50, loss: 0.14671866595745087
step: 60, loss: 0.057452406734228134
step: 70, loss: 0.07469882071018219
step: 80, loss: 0.13455386459827423
step: 90, loss: 0.11051136255264282
step: 100, loss: 0.15451890230178833
step: 110, loss: 0.1630672663450241
step: 120, loss: 0.03871346265077591
step: 130, loss: 0.02426900714635849
step: 140, loss: 0.12600794434547424
step: 150, loss: 0.13230453431606293
step: 160, loss: 0.0651603564620018
step: 170, loss: 0.03469982370734215
step: 180, loss: 0.094452865421772
step: 190, loss: 0.041373059153556824
step: 200, loss: 0.09600351005792618
step: 210, loss: 0.12114983052015305
step: 220, loss: 0.04688596352934837
step: 230, loss: 0.034134987741708755
step: 240, loss: 0.10917892307043076
step: 250, loss: 0.13437104225158691
step: 260, loss: 0.015013039112091064
step: 270, loss: 0.0706716850399971
step: 280, loss: 0.07801887392997742
step: 290, loss: 0.12631158530712128
step: 300, loss: 0.0751214250922203
step: 310, loss: 0.0428156778216362
step: 320, loss: 0.08341757208108902
step: 330, loss: 0.06030027195811272
step: 340, loss: 0.09763611108064651
step: 350, loss: 0.12281478196382523
step: 360, loss: 0.11833763122558594
step: 370, loss: 0.15870723128318787
step: 380, loss: 0.06137842312455177
step: 390, loss: 0.29369571805000305
step: 400, loss: 0.10030927509069443
step: 410, loss: 0.026090363040566444
step: 420, loss: 0.0439017191529274
step: 430, loss: 0.01464940421283245
step: 440, loss: 0.26244300603866577
step: 450, loss: 0.1668160855770111
step: 460, loss: 0.08359673619270325
step: 470, loss: 0.08638619631528854
step: 480, loss: 0.1291409581899643
step: 490, loss: 0.2344742864370346
step: 500, loss: 0.052233751863241196
step: 510, loss: 0.20554035902023315
step: 520, loss: 0.09218423813581467
step: 530, loss: 0.0355113223195076
step: 540, loss: 0.1485765278339386
step: 550, loss: 0.15780961513519287
step: 560, loss: 0.15011784434318542
step: 570, loss: 0.1548823118209839
step: 580, loss: 0.12665441632270813
step: 590, loss: 0.0625162348151207
step: 600, loss: 0.08587996661663055
step: 610, loss: 0.11790905892848969
step: 620, loss: 0.041670411825180054
step: 630, loss: 0.08898188173770905
step: 640, loss: 0.22393931448459625
step: 650, loss: 0.19481736421585083
step: 660, loss: 0.14246401190757751
step: 670, loss: 0.1411593109369278
step: 680, loss: 0.10548452287912369
step: 690, loss: 0.06690237671136856
step: 700, loss: 0.18913932144641876
step: 710, loss: 0.2633236050605774
step: 720, loss: 0.11174339056015015
step: 730, loss: 0.20842936635017395
step: 740, loss: 0.029892757534980774
step: 750, loss: 0.08294559270143509
step: 760, loss: 0.09020601958036423
step: 770, loss: 0.05383887141942978
step: 780, loss: 0.19036784768104553
step: 790, loss: 0.08871612697839737
step: 800, loss: 0.05988778918981552
step: 810, loss: 0.14316868782043457
step: 820, loss: 0.15954644978046417
step: 830, loss: 0.12588481605052948
step: 840, loss: 0.11816040426492691
step: 850, loss: 0.04623514413833618
step: 860, loss: 0.13656452298164368
step: 870, loss: 0.019557321444153786
step: 880, loss: 0.0828625038266182
step: 890, loss: 0.026369664818048477
step: 900, loss: 0.07696915417909622
step: 910, loss: 0.02312278375029564
step: 920, loss: 0.1640036404132843
step: 930, loss: 0.04724382236599922
step: 940, loss: 0.07870618253946304
step: 950, loss: 0.1378011405467987
step: 960, loss: 0.06497129052877426
step: 970, loss: 0.09499702602624893
epoch 6: dev_f1=0.9289055191768008, f1=0.932093023255814, best_f1=0.935528120713306
step: 0, loss: 0.04878288134932518
step: 10, loss: 0.1916903853416443
step: 20, loss: 0.04170294478535652
step: 30, loss: 0.1473865658044815
step: 40, loss: 0.09522674232721329
step: 50, loss: 0.07608535140752792
step: 60, loss: 0.0923554003238678
step: 70, loss: 0.039166271686553955
step: 80, loss: 0.026544809341430664
step: 90, loss: 0.16805875301361084
step: 100, loss: 0.07715138047933578
step: 110, loss: 0.07141333818435669
step: 120, loss: 0.08825425803661346
step: 130, loss: 0.08396948128938675
step: 140, loss: 0.053257837891578674
step: 150, loss: 0.1479918509721756
step: 160, loss: 0.038782767951488495
step: 170, loss: 0.19681571424007416
step: 180, loss: 0.022801129147410393
step: 190, loss: 0.062133289873600006
step: 200, loss: 0.07171127945184708
step: 210, loss: 0.09229107946157455
step: 220, loss: 0.136560320854187
step: 230, loss: 0.12584884464740753
step: 240, loss: 0.05133792757987976
step: 250, loss: 0.06268921494483948
step: 260, loss: 0.021811485290527344
step: 270, loss: 0.10607077926397324
step: 280, loss: 0.0820014700293541
step: 290, loss: 0.016869522631168365
step: 300, loss: 0.16163203120231628
step: 310, loss: 0.048578981310129166
step: 320, loss: 0.033189188688993454
step: 330, loss: 0.051189061254262924
step: 340, loss: 0.09378154575824738
step: 350, loss: 0.03774581849575043
step: 360, loss: 0.1257050633430481
step: 370, loss: 0.04237964004278183
step: 380, loss: 0.09222235530614853
step: 390, loss: 0.13604696094989777
step: 400, loss: 0.058474138379096985
step: 410, loss: 0.1527554988861084
step: 420, loss: 0.09609215706586838
step: 430, loss: 0.05021174997091293
step: 440, loss: 0.07523179054260254
step: 450, loss: 0.06664194911718369
step: 460, loss: 0.0669148787856102
step: 470, loss: 0.08409541100263596
step: 480, loss: 0.033164169639348984
step: 490, loss: 0.06802286952733994
step: 500, loss: 0.08995960652828217
step: 510, loss: 0.0821986049413681
step: 520, loss: 0.08767301589250565
step: 530, loss: 0.12132063508033752
step: 540, loss: 0.028090501204133034
step: 550, loss: 0.11620531976222992
step: 560, loss: 0.13380751013755798
step: 570, loss: 0.119735486805439
step: 580, loss: 0.07619751989841461
step: 590, loss: 0.12814544141292572
step: 600, loss: 0.1075819581747055
step: 610, loss: 0.07561976462602615
step: 620, loss: 0.08605509996414185
step: 630, loss: 0.08739548921585083
step: 640, loss: 0.25132083892822266
step: 650, loss: 0.2090122401714325
step: 660, loss: 0.08506083488464355
step: 670, loss: 0.01928739622235298
step: 680, loss: 0.12851117551326752
step: 690, loss: 0.11347929388284683
step: 700, loss: 0.08942772448062897
step: 710, loss: 0.19296765327453613
step: 720, loss: 0.030923992395401
step: 730, loss: 0.1029023826122284
step: 740, loss: 0.08466729521751404
step: 750, loss: 0.13302412629127502
step: 760, loss: 0.02979019656777382
step: 770, loss: 0.13964496552944183
step: 780, loss: 0.24763327836990356
step: 790, loss: 0.06727201491594315
step: 800, loss: 0.030063223093748093
step: 810, loss: 0.10406789928674698
step: 820, loss: 0.02622637152671814
step: 830, loss: 0.10320597887039185
step: 840, loss: 0.18040406703948975
step: 850, loss: 0.031204212456941605
step: 860, loss: 0.12470725923776627
step: 870, loss: 0.142600879073143
step: 880, loss: 0.15286771953105927
step: 890, loss: 0.07991620898246765
step: 900, loss: 0.03845273330807686
step: 910, loss: 0.09764731675386429
step: 920, loss: 0.03164444863796234
step: 930, loss: 0.1496882289648056
step: 940, loss: 0.09169463068246841
step: 950, loss: 0.10762882977724075
step: 960, loss: 0.045694779604673386
step: 970, loss: 0.07069020718336105
epoch 7: dev_f1=0.9268965517241379, f1=0.9292929292929294, best_f1=0.935528120713306
step: 0, loss: 0.13119269907474518
step: 10, loss: 0.08896400779485703
step: 20, loss: 0.10593714565038681
step: 30, loss: 0.056772999465465546
step: 40, loss: 0.02401074580848217
step: 50, loss: 0.07496903091669083
step: 60, loss: 0.04085580259561539
step: 70, loss: 0.0668635368347168
step: 80, loss: 0.06842494755983353
step: 90, loss: 0.09190355241298676
step: 100, loss: 0.08582551032304764
step: 110, loss: 0.1632625311613083
step: 120, loss: 0.02403142675757408
step: 130, loss: 0.11808329820632935
step: 140, loss: 0.058862440288066864
step: 150, loss: 0.08810126036405563
step: 160, loss: 0.21129658818244934
step: 170, loss: 0.08898620307445526
step: 180, loss: 0.0882989838719368
step: 190, loss: 0.040275152772665024
step: 200, loss: 0.10881112515926361
step: 210, loss: 0.03428454324603081
step: 220, loss: 0.03589121252298355
step: 230, loss: 0.120895616710186
step: 240, loss: 0.07582175731658936
step: 250, loss: 0.13333609700202942
step: 260, loss: 0.08113037794828415
step: 270, loss: 0.09522801637649536
step: 280, loss: 0.20277194678783417
step: 290, loss: 0.14174282550811768
step: 300, loss: 0.008872320875525475
step: 310, loss: 0.09470155090093613
step: 320, loss: 0.15005460381507874
step: 330, loss: 0.02417261153459549
step: 340, loss: 0.11434445530176163
step: 350, loss: 0.035943686962127686
step: 360, loss: 0.05346236750483513
step: 370, loss: 0.06329747289419174
step: 380, loss: 0.0818321704864502
step: 390, loss: 0.09634256362915039
step: 400, loss: 0.028032921254634857
step: 410, loss: 0.04642090946435928
step: 420, loss: 0.11532741785049438
step: 430, loss: 0.057339441031217575
step: 440, loss: 0.10896164178848267
step: 450, loss: 0.06257471442222595
step: 460, loss: 0.08176242560148239
step: 470, loss: 0.09560088068246841
step: 480, loss: 0.06552623212337494
step: 490, loss: 0.08043532818555832
step: 500, loss: 0.16864459216594696
step: 510, loss: 0.043414391577243805
step: 520, loss: 0.059213217347860336
step: 530, loss: 0.1374172568321228
step: 540, loss: 0.09778311848640442
step: 550, loss: 0.04785848781466484
step: 560, loss: 0.030827442184090614
step: 570, loss: 0.13699845969676971
step: 580, loss: 0.1420855075120926
step: 590, loss: 0.04311826825141907
step: 600, loss: 0.06145201250910759
step: 610, loss: 0.10281240940093994
step: 620, loss: 0.14137712121009827
step: 630, loss: 0.11468569189310074
step: 640, loss: 0.022708700969815254
step: 650, loss: 0.12659072875976562
step: 660, loss: 0.0321924164891243
step: 670, loss: 0.09012092649936676
step: 680, loss: 0.10136047005653381
step: 690, loss: 0.1497546136379242
step: 700, loss: 0.044014137238264084
step: 710, loss: 0.09723640233278275
step: 720, loss: 0.12757833302021027
step: 730, loss: 0.0557299368083477
step: 740, loss: 0.18177899718284607
step: 750, loss: 0.05344207212328911
step: 760, loss: 0.05207328870892525
step: 770, loss: 0.03817623481154442
step: 780, loss: 0.16713887453079224
step: 790, loss: 0.0773521363735199
step: 800, loss: 0.12573671340942383
step: 810, loss: 0.06604105234146118
step: 820, loss: 0.020807277411222458
step: 830, loss: 0.10813979804515839
step: 840, loss: 0.11699452996253967
step: 850, loss: 0.08466877788305283
step: 860, loss: 0.06321448087692261
step: 870, loss: 0.16374771296977997
step: 880, loss: 0.09316638112068176
step: 890, loss: 0.12137263268232346
step: 900, loss: 0.04083985090255737
step: 910, loss: 0.09202748537063599
step: 920, loss: 0.21873217821121216
step: 930, loss: 0.13430070877075195
step: 940, loss: 0.11069963127374649
step: 950, loss: 0.09328886866569519
step: 960, loss: 0.17769752442836761
step: 970, loss: 0.054318394511938095
epoch 8: dev_f1=0.9274563820018366, f1=0.9254686785550983, best_f1=0.935528120713306
step: 0, loss: 0.12012192606925964
step: 10, loss: 0.08169278502464294
step: 20, loss: 0.07767090201377869
step: 30, loss: 0.026222649961709976
step: 40, loss: 0.12006910145282745
step: 50, loss: 0.030775124207139015
step: 60, loss: 0.051630403846502304
step: 70, loss: 0.05451691523194313
step: 80, loss: 0.04989832639694214
step: 90, loss: 0.15490932762622833
step: 100, loss: 0.13069985806941986
step: 110, loss: 0.0345216803252697
step: 120, loss: 0.12353110313415527
step: 130, loss: 0.06046294793486595
step: 140, loss: 0.0618753582239151
step: 150, loss: 0.04140866920351982
step: 160, loss: 0.06764023751020432
step: 170, loss: 0.00782831571996212
step: 180, loss: 0.13028161227703094
step: 190, loss: 0.00997763779014349
step: 200, loss: 0.03790407255291939
step: 210, loss: 0.06856999546289444
step: 220, loss: 0.1002134457230568
step: 230, loss: 0.10991348326206207
step: 240, loss: 0.1832653284072876
step: 250, loss: 0.09157376736402512
step: 260, loss: 0.11953336745500565
step: 270, loss: 0.07835736125707626
step: 280, loss: 0.055364131927490234
step: 290, loss: 0.06096189096570015
step: 300, loss: 0.13857626914978027
step: 310, loss: 0.08320948481559753
step: 320, loss: 0.0868193656206131
step: 330, loss: 0.16537319123744965
step: 340, loss: 0.20134679973125458
step: 350, loss: 0.14490382373332977
step: 360, loss: 0.13238170742988586
step: 370, loss: 7.715220272075385e-05
step: 380, loss: 0.09905441105365753
step: 390, loss: 0.055943503975868225
step: 400, loss: 0.05425756424665451
step: 410, loss: 0.08550698310136795
step: 420, loss: 0.12750346958637238
step: 430, loss: 0.09792549908161163
step: 440, loss: 0.049168284982442856
step: 450, loss: 0.14422766864299774
step: 460, loss: 0.06775572896003723
step: 470, loss: 0.15431204438209534
step: 480, loss: 0.11238690465688705
step: 490, loss: 0.04717547446489334
step: 500, loss: 0.17876189947128296
step: 510, loss: 0.012961756438016891
step: 520, loss: 0.09695859253406525
step: 530, loss: 0.003359174355864525
step: 540, loss: 0.12270162999629974
step: 550, loss: 0.07033202052116394
step: 560, loss: 0.07603772729635239
step: 570, loss: 0.05189721658825874
step: 580, loss: 0.15535561740398407
step: 590, loss: 0.06807077676057816
step: 600, loss: 0.15330690145492554
step: 610, loss: 0.14625030755996704
step: 620, loss: 0.15216697752475739
step: 630, loss: 0.09252587705850601
step: 640, loss: 0.13092972338199615
step: 650, loss: 0.10486017167568207
step: 660, loss: 0.09873832017183304
step: 670, loss: 0.050610847771167755
step: 680, loss: 0.04953833669424057
step: 690, loss: 0.2119702696800232
step: 700, loss: 0.0542403981089592
step: 710, loss: 0.07806789875030518
step: 720, loss: 0.20484672486782074
step: 730, loss: 0.1846448928117752
step: 740, loss: 0.05018230155110359
step: 750, loss: 0.01043536327779293
step: 760, loss: 0.15854138135910034
step: 770, loss: 0.12168456614017487
step: 780, loss: 0.0824643149971962
step: 790, loss: 0.15872684121131897
step: 800, loss: 0.09806372225284576
step: 810, loss: 0.05360517278313637
step: 820, loss: 0.11669277399778366
step: 830, loss: 0.16153790056705475
step: 840, loss: 0.07078808546066284
step: 850, loss: 0.020783042535185814
step: 860, loss: 0.05411439761519432
step: 870, loss: 0.08838538825511932
step: 880, loss: 0.14304612576961517
step: 890, loss: 0.10142269730567932
step: 900, loss: 0.04477309808135033
step: 910, loss: 0.06415357440710068
step: 920, loss: 0.07412788271903992
step: 930, loss: 0.05247258022427559
step: 940, loss: 0.07415223121643066
step: 950, loss: 0.12392770498991013
step: 960, loss: 0.11523203551769257
step: 970, loss: 0.05059414729475975
epoch 9: dev_f1=0.932904411764706, f1=0.9306384933394579, best_f1=0.935528120713306
step: 0, loss: 0.05646372586488724
step: 10, loss: 0.019273515790700912
step: 20, loss: 0.09120069444179535
step: 30, loss: 0.10829603672027588
step: 40, loss: 0.12162548303604126
step: 50, loss: 0.1282995194196701
step: 60, loss: 0.04593299329280853
step: 70, loss: 0.030797632411122322
step: 80, loss: 0.05330163612961769
step: 90, loss: 0.07837021350860596
step: 100, loss: 0.09971734136343002
step: 110, loss: 0.05462855473160744
step: 120, loss: 0.03263768181204796
step: 130, loss: 0.02673613466322422
step: 140, loss: 0.004222237505018711
step: 150, loss: 0.08768054097890854
step: 160, loss: 0.09882095456123352
step: 170, loss: 0.020518874749541283
step: 180, loss: 0.12264052033424377
step: 190, loss: 0.05852538347244263
step: 200, loss: 0.10517974197864532
step: 210, loss: 0.2204667627811432
step: 220, loss: 0.09808529913425446
step: 230, loss: 0.08183737844228745
step: 240, loss: 0.12555798888206482
step: 250, loss: 0.022241687402129173
step: 260, loss: 0.009070640429854393
step: 270, loss: 0.04844377562403679
step: 280, loss: 0.034781184047460556
step: 290, loss: 0.19933684170246124
step: 300, loss: 0.04839453101158142
step: 310, loss: 0.13578897714614868
step: 320, loss: 0.07849728316068649
step: 330, loss: 0.15086643397808075
step: 340, loss: 0.039647176861763
step: 350, loss: 0.10443875938653946
step: 360, loss: 0.02020164579153061
step: 370, loss: 0.10048534721136093
step: 380, loss: 0.0762687399983406
step: 390, loss: 0.0405232273042202
step: 400, loss: 0.1203930601477623
step: 410, loss: 0.0466499924659729
step: 420, loss: 0.0785728171467781
step: 430, loss: 0.10317891836166382
step: 440, loss: 0.06038965657353401
step: 450, loss: 0.050764333456754684
step: 460, loss: 0.04816154018044472
step: 470, loss: 0.051640551537275314
step: 480, loss: 0.05048857629299164
step: 490, loss: 0.030665377154946327
step: 500, loss: 0.08682047575712204
step: 510, loss: 0.0607607439160347
step: 520, loss: 0.07601440697908401
step: 530, loss: 0.10687704384326935
step: 540, loss: 0.059152692556381226
step: 550, loss: 0.04880861937999725
step: 560, loss: 0.1083989366889
step: 570, loss: 0.060962606221437454
step: 580, loss: 0.017596634104847908
step: 590, loss: 0.11883898824453354
step: 600, loss: 0.06854362040758133
step: 610, loss: 0.035166334360837936
step: 620, loss: 0.1509827822446823
step: 630, loss: 0.06137906387448311
step: 640, loss: 0.0872589498758316
step: 650, loss: 0.057710785418748856
step: 660, loss: 0.04716593027114868
step: 670, loss: 0.11664886772632599
step: 680, loss: 0.07028570771217346
step: 690, loss: 0.1169402152299881
step: 700, loss: 0.04755783826112747
step: 710, loss: 0.06620051711797714
step: 720, loss: 0.05617646127939224
step: 730, loss: 0.08941128104925156
step: 740, loss: 0.11481814086437225
step: 750, loss: 0.08417115360498428
step: 760, loss: 0.1423531025648117
step: 770, loss: 0.03626873344182968
step: 780, loss: 0.024295201525092125
step: 790, loss: 0.10935936868190765
step: 800, loss: 0.07494810223579407
step: 810, loss: 0.03631216287612915
step: 820, loss: 0.03645262122154236
step: 830, loss: 0.047462835907936096
step: 840, loss: 0.06269543617963791
step: 850, loss: 0.14085838198661804
step: 860, loss: 0.09653318673372269
step: 870, loss: 0.13150590658187866
step: 880, loss: 0.04619506374001503
step: 890, loss: 0.0686817541718483
step: 900, loss: 0.07671598345041275
step: 910, loss: 0.06530071794986725
step: 920, loss: 0.034799568355083466
step: 930, loss: 0.26890480518341064
step: 940, loss: 0.0453571081161499
step: 950, loss: 0.05059110373258591
step: 960, loss: 0.037565868347883224
step: 970, loss: 0.031294796615839005
epoch 10: dev_f1=0.9260299625468165, f1=0.9253731343283583, best_f1=0.935528120713306
step: 0, loss: 0.032992053776979446
step: 10, loss: 0.0641096979379654
step: 20, loss: 0.24348846077919006
step: 30, loss: 0.05566014349460602
step: 40, loss: 0.04912465065717697
step: 50, loss: 0.09476397931575775
step: 60, loss: 0.003832748159766197
step: 70, loss: 0.09789379686117172
step: 80, loss: 0.034307271242141724
step: 90, loss: 0.08206969499588013
step: 100, loss: 0.19390076398849487
step: 110, loss: 0.049612633883953094
step: 120, loss: 0.03852709382772446
step: 130, loss: 0.04242219030857086
step: 140, loss: 0.04952429607510567
step: 150, loss: 0.05704553797841072
step: 160, loss: 0.17704066634178162
step: 170, loss: 0.15090897679328918
step: 180, loss: 0.038839373737573624
step: 190, loss: 0.03646983951330185
step: 200, loss: 0.06088471785187721
step: 210, loss: 0.04441374912858009
step: 220, loss: 0.052410829812288284
step: 230, loss: 0.08882056176662445
step: 240, loss: 0.05030854791402817
step: 250, loss: 0.07897427678108215
step: 260, loss: 0.07290736585855484
step: 270, loss: 0.09299498051404953
step: 280, loss: 0.04387657344341278
step: 290, loss: 0.13747183978557587
step: 300, loss: 0.02384382113814354
step: 310, loss: 0.0743035301566124
step: 320, loss: 0.07022123038768768
step: 330, loss: 0.07718697935342789
step: 340, loss: 0.06900248676538467
step: 350, loss: 0.04342556744813919
step: 360, loss: 0.1542528122663498
step: 370, loss: 0.11642912775278091
step: 380, loss: 0.06852244585752487
step: 390, loss: 0.16510683298110962
step: 400, loss: 0.1102251261472702
step: 410, loss: 0.11513331532478333
step: 420, loss: 0.14007970690727234
step: 430, loss: 0.09657707810401917
step: 440, loss: 0.11429651826620102
step: 450, loss: 0.02507389709353447
step: 460, loss: 0.042736299335956573
step: 470, loss: 0.11441250890493393
step: 480, loss: 0.20063601434230804
step: 490, loss: 0.06639841943979263
step: 500, loss: 0.06198212131857872
step: 510, loss: 0.12526662647724152
step: 520, loss: 0.06885382533073425
step: 530, loss: 0.019952140748500824
step: 540, loss: 0.05892457813024521
step: 550, loss: 0.07418415695428848
step: 560, loss: 0.06757009029388428
step: 570, loss: 0.1565152406692505
step: 580, loss: 0.10665478557348251
step: 590, loss: 0.15526574850082397
step: 600, loss: 0.12014948576688766
step: 610, loss: 0.04259136691689491
step: 620, loss: 0.04960618540644646
step: 630, loss: 0.07674999535083771
step: 640, loss: 0.022731689736247063
step: 650, loss: 0.16573305428028107
step: 660, loss: 0.17682287096977234
step: 670, loss: 0.04406822472810745
step: 680, loss: 0.019530288875102997
step: 690, loss: 0.08533364534378052
step: 700, loss: 0.0664801150560379
step: 710, loss: 0.07591675966978073
step: 720, loss: 0.07581223547458649
step: 730, loss: 0.04789058491587639
step: 740, loss: 0.03061506897211075
step: 750, loss: 0.07105786353349686
step: 760, loss: 0.030772877857089043
step: 770, loss: 0.05987858772277832
step: 780, loss: 0.04074862226843834
step: 790, loss: 0.06431443244218826
step: 800, loss: 0.08840354532003403
step: 810, loss: 0.04821169003844261
step: 820, loss: 0.0005039779935032129
step: 830, loss: 0.05174059420824051
step: 840, loss: 0.04808271303772926
step: 850, loss: 0.06807181984186172
step: 860, loss: 0.03529296815395355
step: 870, loss: 0.08804070204496384
step: 880, loss: 0.07078589498996735
step: 890, loss: 0.058790840208530426
step: 900, loss: 0.046439800411462784
step: 910, loss: 0.06610183417797089
step: 920, loss: 0.22302015125751495
step: 930, loss: 0.03690379858016968
step: 940, loss: 0.06444590538740158
step: 950, loss: 0.11148722469806671
step: 960, loss: 0.05911214277148247
step: 970, loss: 0.19552084803581238
epoch 11: dev_f1=0.9268755935422602, f1=0.9318288669487541, best_f1=0.935528120713306
step: 0, loss: 0.02943974733352661
step: 10, loss: 0.02517981082201004
step: 20, loss: 0.024924512952566147
step: 30, loss: 0.00403157714754343
step: 40, loss: 0.07888183742761612
step: 50, loss: 0.05334232747554779
step: 60, loss: 0.046773865818977356
step: 70, loss: 0.06095307692885399
step: 80, loss: 0.14003576338291168
step: 90, loss: 0.053498901426792145
step: 100, loss: 0.003104486269876361
step: 110, loss: 0.10226749628782272
step: 120, loss: 0.06000586226582527
step: 130, loss: 0.03321485593914986
step: 140, loss: 0.19787101447582245
step: 150, loss: 0.04721277207136154
step: 160, loss: 0.07160484045743942
step: 170, loss: 0.02369595319032669
step: 180, loss: 0.0012210406130179763
step: 190, loss: 0.04759882017970085
step: 200, loss: 0.06474107503890991
step: 210, loss: 0.03158857673406601
step: 220, loss: 0.038037750869989395
step: 230, loss: 0.4404349625110626
step: 240, loss: 0.16809982061386108
step: 250, loss: 0.002392370719462633
step: 260, loss: 0.061849527060985565
step: 270, loss: 0.11479736119508743
step: 280, loss: 0.051946550607681274
step: 290, loss: 0.08745098114013672
step: 300, loss: 0.07178709656000137
step: 310, loss: 0.08424726128578186
step: 320, loss: 0.06513004750013351
step: 330, loss: 0.02567709982395172
step: 340, loss: 0.07621926069259644
step: 350, loss: 0.14227333664894104
step: 360, loss: 0.03788428753614426
step: 370, loss: 0.08560987561941147
step: 380, loss: 0.09660450369119644
step: 390, loss: 0.04156264662742615
step: 400, loss: 0.03218730911612511
step: 410, loss: 0.04461075738072395
step: 420, loss: 0.0870104730129242
step: 430, loss: 0.04594261199235916
step: 440, loss: 0.054567109793424606
step: 450, loss: 0.04140760749578476
step: 460, loss: 0.032280150800943375
step: 470, loss: 0.08047284185886383
step: 480, loss: 0.07654571533203125
step: 490, loss: 0.08211484551429749
step: 500, loss: 0.12580254673957825
step: 510, loss: 0.07783681154251099
step: 520, loss: 0.14336824417114258
step: 530, loss: 0.05462532863020897
step: 540, loss: 0.0970461443066597
step: 550, loss: 0.07233865559101105
step: 560, loss: 0.08450448513031006
step: 570, loss: 0.07731304317712784
step: 580, loss: 0.10017984360456467
step: 590, loss: 0.11283775418996811
step: 600, loss: 0.059141114354133606
step: 610, loss: 0.005247136112302542
step: 620, loss: 0.12878547608852386
step: 630, loss: 0.04930030554533005
step: 640, loss: 0.08825761824846268
step: 650, loss: 0.037726178765296936
step: 660, loss: 0.012023726478219032
step: 670, loss: 0.06567082554101944
step: 680, loss: 0.029905039817094803
step: 690, loss: 0.07868674397468567
step: 700, loss: 0.05695904418826103
step: 710, loss: 0.08542503416538239
step: 720, loss: 0.07362964749336243
step: 730, loss: 0.09510717540979385
step: 740, loss: 0.018239276483654976
step: 750, loss: 0.07205811142921448
step: 760, loss: 0.008736759424209595
step: 770, loss: 0.10128821432590485
step: 780, loss: 0.0693354606628418
step: 790, loss: 0.05807982012629509
step: 800, loss: 0.023188551887869835
step: 810, loss: 0.1519993394613266
step: 820, loss: 0.09498182684183121
step: 830, loss: 0.02874678000807762
step: 840, loss: 0.022333214059472084
step: 850, loss: 0.07995078712701797
step: 860, loss: 0.03134697675704956
step: 870, loss: 0.031889721751213074
step: 880, loss: 0.028048120439052582
step: 890, loss: 0.06215885654091835
step: 900, loss: 0.2469003051519394
step: 910, loss: 0.07711172848939896
step: 920, loss: 0.08801165223121643
step: 930, loss: 0.18614983558654785
step: 940, loss: 0.06523548066616058
step: 950, loss: 0.04893304780125618
step: 960, loss: 0.047353073954582214
step: 970, loss: 0.030388832092285156
epoch 12: dev_f1=0.9275092936802973, f1=0.9303826648224988, best_f1=0.935528120713306
step: 0, loss: 0.0755663514137268
step: 10, loss: 0.027384687215089798
step: 20, loss: 0.07849805802106857
step: 30, loss: 0.09423632174730301
step: 40, loss: 0.023379892110824585
step: 50, loss: 0.030231058597564697
step: 60, loss: 0.013138499110937119
step: 70, loss: 0.08280371874570847
step: 80, loss: 0.026414450258016586
step: 90, loss: 0.011343198828399181
step: 100, loss: 0.08059976994991302
step: 110, loss: 0.12348691374063492
step: 120, loss: 0.05746684968471527
step: 130, loss: 0.12561865150928497
step: 140, loss: 0.12802577018737793
step: 150, loss: 0.031218726187944412
step: 160, loss: 0.10824470967054367
step: 170, loss: 0.05963590368628502
step: 180, loss: 0.1299932897090912
step: 190, loss: 0.012041895650327206
step: 200, loss: 1.9605697161750868e-05
step: 210, loss: 0.040234554558992386
step: 220, loss: 0.030124075710773468
step: 230, loss: 0.055474795401096344
step: 240, loss: 0.12126456946134567
step: 250, loss: 0.07025362551212311
step: 260, loss: 0.05304807052016258
step: 270, loss: 0.06715010851621628
step: 280, loss: 0.037291206419467926
step: 290, loss: 0.053634822368621826
step: 300, loss: 0.06562972068786621
step: 310, loss: 0.09493833780288696
step: 320, loss: 0.08914755284786224
step: 330, loss: 0.049818944185972214
step: 340, loss: 0.08327656984329224
step: 350, loss: 0.07105986773967743
step: 360, loss: 0.07984628528356552
step: 370, loss: 0.029156239703297615
step: 380, loss: 0.19648857414722443
step: 390, loss: 0.010719550773501396
step: 400, loss: 0.04402325302362442
step: 410, loss: 0.043681856244802475
step: 420, loss: 0.06362178176641464
step: 430, loss: 0.054485321044921875
step: 440, loss: 0.12143418937921524
step: 450, loss: 0.026204677298665047
step: 460, loss: 0.04587053880095482
step: 470, loss: 0.10108921676874161
step: 480, loss: 0.05533801391720772
step: 490, loss: 0.05698154866695404
step: 500, loss: 0.0398196317255497
step: 510, loss: 0.035945672541856766
step: 520, loss: 0.057281751185655594
step: 530, loss: 0.0002818309876602143
step: 540, loss: 0.1376318335533142
step: 550, loss: 0.0016767820343375206
step: 560, loss: 0.04292713478207588
step: 570, loss: 0.010440932586789131
step: 580, loss: 0.0028449147939682007
step: 590, loss: 0.08668488264083862
step: 600, loss: 0.03574687987565994
step: 610, loss: 0.044992852956056595
step: 620, loss: 0.07270011305809021
step: 630, loss: 0.12719276547431946
step: 640, loss: 0.014932891353964806
step: 650, loss: 0.08763240277767181
step: 660, loss: 0.05993964150547981
step: 670, loss: 0.030779127031564713
step: 680, loss: 0.05088718235492706
step: 690, loss: 0.04085076227784157
step: 700, loss: 0.06737097352743149
step: 710, loss: 0.029333818703889847
step: 720, loss: 0.05043690279126167
step: 730, loss: 0.06074685603380203
step: 740, loss: 0.13045737147331238
step: 750, loss: 0.09137564897537231
step: 760, loss: 0.1125083640217781
step: 770, loss: 0.004273341037333012
step: 780, loss: 0.037005309015512466
step: 790, loss: 0.13983188569545746
step: 800, loss: 0.034347325563430786
step: 810, loss: 0.11485040187835693
step: 820, loss: 0.026128724217414856
step: 830, loss: 0.19942207634449005
step: 840, loss: 0.028914039954543114
step: 850, loss: 0.04865965619683266
step: 860, loss: 0.10083464533090591
step: 870, loss: 0.004621426574885845
step: 880, loss: 0.06870317459106445
step: 890, loss: 0.0005887268926016986
step: 900, loss: 0.017018670216202736
step: 910, loss: 0.025426143780350685
step: 920, loss: 0.03301132097840309
step: 930, loss: 0.047593455761671066
step: 940, loss: 0.1211293563246727
step: 950, loss: 0.11211179196834564
step: 960, loss: 0.023006513714790344
step: 970, loss: 0.12435724586248398
epoch 13: dev_f1=0.9247808029533918, f1=0.9249193919852603, best_f1=0.935528120713306
step: 0, loss: 0.13372914493083954
step: 10, loss: 0.0275285467505455
step: 20, loss: 0.07426846027374268
step: 30, loss: 0.10810177773237228
step: 40, loss: 0.03377996012568474
step: 50, loss: 0.1397782564163208
step: 60, loss: 0.029567375779151917
step: 70, loss: 0.03440355509519577
step: 80, loss: 0.01712854765355587
step: 90, loss: 0.07939215004444122
step: 100, loss: 0.0013176833745092154
step: 110, loss: 0.08172551542520523
step: 120, loss: 0.06528507173061371
step: 130, loss: 0.2792341411113739
step: 140, loss: 0.05137118697166443
step: 150, loss: 0.08947117626667023
step: 160, loss: 0.07856086641550064
step: 170, loss: 0.0018541226163506508
step: 180, loss: 0.09382190555334091
step: 190, loss: 0.032637208700180054
step: 200, loss: 0.040312882512807846
step: 210, loss: 0.06439357995986938
step: 220, loss: 0.19308796525001526
step: 230, loss: 0.06481713801622391
step: 240, loss: 0.062271829694509506
step: 250, loss: 0.04576355963945389
step: 260, loss: 0.05917209014296532
step: 270, loss: 0.1854887753725052
step: 280, loss: 0.04600422456860542
step: 290, loss: 0.026645375415682793
step: 300, loss: 0.09426780045032501
step: 310, loss: 0.00017617639969103038
step: 320, loss: 0.12510350346565247
step: 330, loss: 0.0745895728468895
step: 340, loss: 0.03589807450771332
step: 350, loss: 0.05437280982732773
step: 360, loss: 0.02281886711716652
step: 370, loss: 0.0689605325460434
step: 380, loss: 0.03276783600449562
step: 390, loss: 0.07188842445611954
step: 400, loss: 0.13248860836029053
step: 410, loss: 0.0007875168230384588
step: 420, loss: 0.055269595235586166
step: 430, loss: 0.11101025342941284
step: 440, loss: 0.013192371465265751
step: 450, loss: 0.006778385024517775
step: 460, loss: 0.09656131267547607
step: 470, loss: 0.13454201817512512
step: 480, loss: 0.0732148289680481
step: 490, loss: 0.1018221527338028
step: 500, loss: 0.06023911014199257
step: 510, loss: 0.10748963803052902
step: 520, loss: 0.1512814611196518
step: 530, loss: 0.0698421522974968
step: 540, loss: 0.0511874258518219
step: 550, loss: 0.09502258151769638
step: 560, loss: 0.09238751977682114
step: 570, loss: 0.058717530220746994
step: 580, loss: 0.07216580957174301
step: 590, loss: 0.03400914743542671
step: 600, loss: 0.04583047330379486
step: 610, loss: 0.1374243199825287
step: 620, loss: 0.05051387846469879
step: 630, loss: 0.158845454454422
step: 640, loss: 0.02768418751657009
step: 650, loss: 0.03086564876139164
step: 660, loss: 0.006756855174899101
step: 670, loss: 0.03494727984070778
step: 680, loss: 0.047516196966171265
step: 690, loss: 0.05758756399154663
step: 700, loss: 0.015061970800161362
step: 710, loss: 0.0847451314330101
step: 720, loss: 6.921141175553203e-05
step: 730, loss: 0.041435450315475464
step: 740, loss: 0.12218400090932846
step: 750, loss: 0.1253797560930252
step: 760, loss: 0.06095370650291443
step: 770, loss: 0.05083217844367027
step: 780, loss: 0.08829183876514435
step: 790, loss: 0.05312096327543259
step: 800, loss: 0.08736986666917801
step: 810, loss: 0.07397019863128662
step: 820, loss: 0.04975917190313339
step: 830, loss: 0.12075553089380264
step: 840, loss: 0.08379014581441879
step: 850, loss: 0.049981262534856796
step: 860, loss: 0.08483162522315979
step: 870, loss: 0.07080297917127609
step: 880, loss: 0.004575831349939108
step: 890, loss: 0.06299765408039093
step: 900, loss: 0.043635375797748566
step: 910, loss: 0.16412536799907684
step: 920, loss: 0.052861712872982025
step: 930, loss: 0.037648044526576996
step: 940, loss: 0.03937884047627449
step: 950, loss: 0.038475196808576584
step: 960, loss: 0.16799414157867432
step: 970, loss: 0.1623801738023758
epoch 14: dev_f1=0.9224178962398858, f1=0.9284369114877589, best_f1=0.935528120713306
step: 0, loss: 0.030516300350427628
step: 10, loss: 0.07395879924297333
step: 20, loss: 0.0004316613485570997
step: 30, loss: 0.06702667474746704
step: 40, loss: 0.20173707604408264
step: 50, loss: 0.06984568387269974
step: 60, loss: 0.05136227235198021
step: 70, loss: 0.00533856637775898
step: 80, loss: 0.058298882097005844
step: 90, loss: 0.00025642896071076393
step: 100, loss: 0.06313768774271011
step: 110, loss: 0.0967017337679863
step: 120, loss: 0.06805587559938431
step: 130, loss: 0.042662136256694794
step: 140, loss: 0.0910467654466629
step: 150, loss: 0.06281912326812744
step: 160, loss: 0.008677476085722446
step: 170, loss: 0.008673262782394886
step: 180, loss: 0.04006790369749069
step: 190, loss: 0.08343887329101562
step: 200, loss: 0.04819679632782936
step: 210, loss: 0.08892643451690674
step: 220, loss: 0.07663681358098984
step: 230, loss: 0.06996359676122665
step: 240, loss: 0.022321773692965508
step: 250, loss: 0.04842813313007355
step: 260, loss: 0.032911211252212524
step: 270, loss: 0.07073810696601868
step: 280, loss: 0.01857502944767475
step: 290, loss: 0.040097806602716446
step: 300, loss: 0.023384539410471916
step: 310, loss: 0.0257338285446167
step: 320, loss: 0.06596561521291733
step: 330, loss: 0.06945688277482986
step: 340, loss: 0.23189564049243927
step: 350, loss: 0.02545381337404251
step: 360, loss: 0.039435017853975296
step: 370, loss: 0.11239444464445114
step: 380, loss: 0.07864374667406082
step: 390, loss: 0.012313510291278362
step: 400, loss: 0.038842394948005676
step: 410, loss: 0.04611955210566521
step: 420, loss: 0.017710549756884575
step: 430, loss: 0.06872908771038055
step: 440, loss: 0.0877143070101738
step: 450, loss: 0.02056366577744484
step: 460, loss: 0.02837996557354927
step: 470, loss: 0.06500592082738876
step: 480, loss: 0.12868887186050415
step: 490, loss: 0.035677917301654816
step: 500, loss: 0.13160091638565063
step: 510, loss: 0.0002623037726152688
step: 520, loss: 0.052271027117967606
step: 530, loss: 0.036476120352745056
step: 540, loss: 0.019453128799796104
step: 550, loss: 0.015888601541519165
step: 560, loss: 0.0584721639752388
step: 570, loss: 0.07913290709257126
step: 580, loss: 0.06859804689884186
step: 590, loss: 0.005868775304406881
step: 600, loss: 0.06224304437637329
step: 610, loss: 0.023769561201334
step: 620, loss: 0.04019980877637863
step: 630, loss: 0.0007758653373457491
step: 640, loss: 0.11594905704259872
step: 650, loss: 0.011891278438270092
step: 660, loss: 0.022089987993240356
step: 670, loss: 0.01989513635635376
step: 680, loss: 0.00023810459242668003
step: 690, loss: 0.0239713154733181
step: 700, loss: 0.04327525570988655
step: 710, loss: 0.04640170559287071
step: 720, loss: 0.09104258567094803
step: 730, loss: 0.04468829929828644
step: 740, loss: 0.044477447867393494
step: 750, loss: 0.024338513612747192
step: 760, loss: 0.06444338709115982
step: 770, loss: 0.08855905383825302
step: 780, loss: 0.007376768626272678
step: 790, loss: 0.04946424439549446
step: 800, loss: 0.04383634403347969
step: 810, loss: 0.08977912366390228
step: 820, loss: 0.0430435910820961
step: 830, loss: 0.055691953748464584
step: 840, loss: 0.059966228902339935
step: 850, loss: 0.37529265880584717
step: 860, loss: 0.007816688157618046
step: 870, loss: 0.14803430438041687
step: 880, loss: 0.052641239017248154
step: 890, loss: 0.0441734716296196
step: 900, loss: 0.0004294466634746641
step: 910, loss: 0.115425243973732
step: 920, loss: 0.04159940034151077
step: 930, loss: 0.0014450368471443653
step: 940, loss: 0.04489888995885849
step: 950, loss: 0.05151602625846863
step: 960, loss: 0.18933428823947906
step: 970, loss: 0.011921711266040802
epoch 15: dev_f1=0.9241443108233117, f1=0.9271889400921659, best_f1=0.935528120713306
step: 0, loss: 0.12392818927764893
step: 10, loss: 0.016921836882829666
step: 20, loss: 0.062382593750953674
step: 30, loss: 0.13693633675575256
step: 40, loss: 0.0849553793668747
step: 50, loss: 0.08450844883918762
step: 60, loss: 0.00857577845454216
step: 70, loss: 0.06307560950517654
step: 80, loss: 0.03150211647152901
step: 90, loss: 0.04342227801680565
step: 100, loss: 0.0007518903585150838
step: 110, loss: 0.041757114231586456
step: 120, loss: 0.06139412894845009
step: 130, loss: 0.007054842077195644
step: 140, loss: 0.07269889861345291
step: 150, loss: 0.05127721279859543
step: 160, loss: 0.02172158658504486
step: 170, loss: 0.03658830374479294
step: 180, loss: 0.04447047784924507
step: 190, loss: 0.0605175755918026
step: 200, loss: 0.07602334022521973
step: 210, loss: 0.05292971059679985
step: 220, loss: 0.0751003846526146
step: 230, loss: 0.054156769067049026
step: 240, loss: 0.02968936786055565
step: 250, loss: 0.0450902096927166
step: 260, loss: 0.07745365053415298
step: 270, loss: 0.04057212173938751
step: 280, loss: 0.0655154287815094
step: 290, loss: 0.03695347160100937
step: 300, loss: 0.1049434095621109
step: 310, loss: 0.06572115421295166
step: 320, loss: 0.08487359434366226
step: 330, loss: 0.07879083603620529
step: 340, loss: 0.007913540117442608
step: 350, loss: 0.036623138934373856
step: 360, loss: 0.021083364263176918
step: 370, loss: 0.06354249268770218
step: 380, loss: 0.009822946973145008
step: 390, loss: 0.06732881814241409
step: 400, loss: 0.013903340324759483
step: 410, loss: 0.01973116584122181
step: 420, loss: 0.1521974503993988
step: 430, loss: 0.07421351969242096
step: 440, loss: 0.05972883850336075
step: 450, loss: 0.024570133537054062
step: 460, loss: 0.13134078681468964
step: 470, loss: 0.08674356341362
step: 480, loss: 0.04549454152584076
step: 490, loss: 0.0242958702147007
step: 500, loss: 0.021247511729598045
step: 510, loss: 0.00978544820100069
step: 520, loss: 0.07828329503536224
step: 530, loss: 0.08396381139755249
step: 540, loss: 0.017449378967285156
step: 550, loss: 0.05739471688866615
step: 560, loss: 0.04202916845679283
step: 570, loss: 0.0627613440155983
step: 580, loss: 0.012772421352565289
step: 590, loss: 0.08670488744974136
step: 600, loss: 0.06840145587921143
step: 610, loss: 0.08115904033184052
step: 620, loss: 0.05353478714823723
step: 630, loss: 0.034846231341362
step: 640, loss: 0.09275689721107483
step: 650, loss: 0.04190812259912491
step: 660, loss: 0.025577276945114136
step: 670, loss: 0.023693062365055084
step: 680, loss: 0.0062293135561048985
step: 690, loss: 0.024238208308815956
step: 700, loss: 0.054520852863788605
step: 710, loss: 0.022680683061480522
step: 720, loss: 0.015884699299931526
step: 730, loss: 0.09283813834190369
step: 740, loss: 0.07420249283313751
step: 750, loss: 0.07442270219326019
step: 760, loss: 0.07544300705194473
step: 770, loss: 0.0690808817744255
step: 780, loss: 0.05697757378220558
step: 790, loss: 0.016712268814444542
step: 800, loss: 0.03660808503627777
step: 810, loss: 0.04334652051329613
step: 820, loss: 0.10027202218770981
step: 830, loss: 0.11227243393659592
step: 840, loss: 0.0008064875728450716
step: 850, loss: 0.10827107727527618
step: 860, loss: 0.03958861902356148
step: 870, loss: 0.09904183447360992
step: 880, loss: 0.052858270704746246
step: 890, loss: 0.10889919102191925
step: 900, loss: 0.028335634618997574
step: 910, loss: 0.12590157985687256
step: 920, loss: 0.06153568625450134
step: 930, loss: 0.11345743387937546
step: 940, loss: 0.035520464181900024
step: 950, loss: 0.11595558375120163
step: 960, loss: 0.045898035168647766
step: 970, loss: 0.027342308312654495
epoch 16: dev_f1=0.925290023201856, f1=0.9284725426857406, best_f1=0.935528120713306
step: 0, loss: 0.09205096960067749
step: 10, loss: 0.05369003117084503
step: 20, loss: 0.08867016434669495
step: 30, loss: 0.023142078891396523
step: 40, loss: 0.05743144825100899
step: 50, loss: 0.04880455136299133
step: 60, loss: 0.012954743579030037
step: 70, loss: 0.08632443100214005
step: 80, loss: 0.06103338673710823
step: 90, loss: 0.05496557801961899
step: 100, loss: 0.019446924328804016
step: 110, loss: 0.08350572735071182
step: 120, loss: 0.115046426653862
step: 130, loss: 0.026906196027994156
step: 140, loss: 0.03279431164264679
step: 150, loss: 0.034744828939437866
step: 160, loss: 0.039575159549713135
step: 170, loss: 0.06608037650585175
step: 180, loss: 0.0658905878663063
step: 190, loss: 0.008659189566969872
step: 200, loss: 0.1490936279296875
step: 210, loss: 0.02607347071170807
step: 220, loss: 0.02444828487932682
step: 230, loss: 0.027643030509352684
step: 240, loss: 0.08047126978635788
step: 250, loss: 0.09633312374353409
step: 260, loss: 0.05002344027161598
step: 270, loss: 0.03748704493045807
step: 280, loss: 0.0003141650231555104
step: 290, loss: 0.020012563094496727
step: 300, loss: 0.02502438984811306
step: 310, loss: 0.09345504641532898
step: 320, loss: 0.0124006113037467
step: 330, loss: 0.03477450832724571
step: 340, loss: 0.007526576053351164
step: 350, loss: 0.034446895122528076
step: 360, loss: 0.05528566613793373
step: 370, loss: 0.06480976939201355
step: 380, loss: 0.014886198565363884
step: 390, loss: 0.028290772810578346
step: 400, loss: 7.30527171981521e-05
step: 410, loss: 5.385672557167709e-05
step: 420, loss: 0.06737413257360458
step: 430, loss: 0.09544794261455536
step: 440, loss: 0.05459347367286682
step: 450, loss: 0.041176214814186096
step: 460, loss: 0.05992523953318596
step: 470, loss: 0.05304405465722084
step: 480, loss: 0.04268242418766022
step: 490, loss: 2.772371590253897e-05
step: 500, loss: 0.014875595457851887
step: 510, loss: 0.01723792962729931
step: 520, loss: 0.02368082106113434
step: 530, loss: 0.0930769145488739
step: 540, loss: 0.02593386545777321
step: 550, loss: 0.11151738464832306
step: 560, loss: 0.060638267546892166
step: 570, loss: 0.023529117926955223
step: 580, loss: 0.09447462111711502
step: 590, loss: 0.1157056987285614
step: 600, loss: 2.220134592789691e-05
step: 610, loss: 0.06527548283338547
step: 620, loss: 0.07395870238542557
step: 630, loss: 0.027188533917069435
step: 640, loss: 0.03492221236228943
step: 650, loss: 0.006909091025590897
step: 660, loss: 0.07422086596488953
step: 670, loss: 0.07238693535327911
step: 680, loss: 0.0816434696316719
step: 690, loss: 1.6696383681846783e-05
step: 700, loss: 0.0794166848063469
step: 710, loss: 0.07885794341564178
step: 720, loss: 0.03592344745993614
step: 730, loss: 0.0010955547913908958
step: 740, loss: 0.07502598315477371
step: 750, loss: 0.04777975752949715
step: 760, loss: 0.06318674236536026
step: 770, loss: 0.07680609822273254
step: 780, loss: 0.009643803350627422
step: 790, loss: 0.11913279443979263
step: 800, loss: 0.03315610811114311
step: 810, loss: 0.047308530658483505
step: 820, loss: 0.043232571333646774
step: 830, loss: 0.0740523710846901
step: 840, loss: 0.13126042485237122
step: 850, loss: 0.0479409284889698
step: 860, loss: 0.18384160101413727
step: 870, loss: 0.026026783511042595
step: 880, loss: 0.016792234033346176
step: 890, loss: 0.05728462338447571
step: 900, loss: 0.0138971246778965
step: 910, loss: 0.008961237035691738
step: 920, loss: 0.06405216455459595
step: 930, loss: 0.0071107856929302216
step: 940, loss: 0.049215953797101974
step: 950, loss: 0.04291122034192085
step: 960, loss: 0.044344622641801834
step: 970, loss: 0.07745840400457382
epoch 17: dev_f1=0.925891181988743, f1=0.9283054003724395, best_f1=0.935528120713306
step: 0, loss: 0.031720563769340515
step: 10, loss: 0.07756371796131134
step: 20, loss: 0.023011742159724236
step: 30, loss: 0.06921768933534622
step: 40, loss: 0.03931527957320213
step: 50, loss: 0.12247823923826218
step: 60, loss: 0.07584778219461441
step: 70, loss: 0.031791508197784424
step: 80, loss: 0.05936386063694954
step: 90, loss: 1.4625371477450244e-05
step: 100, loss: 0.08685888350009918
step: 110, loss: 0.07883042097091675
step: 120, loss: 0.03158226236701012
step: 130, loss: 0.020728828385472298
step: 140, loss: 0.06429720669984818
step: 150, loss: 0.0019479813054203987
step: 160, loss: 0.025481298565864563
step: 170, loss: 0.031759828329086304
step: 180, loss: 0.04388810321688652
step: 190, loss: 0.016765104606747627
step: 200, loss: 0.022386396303772926
step: 210, loss: 0.06057385355234146
step: 220, loss: 0.034088317304849625
step: 230, loss: 0.0724613144993782
step: 240, loss: 0.07721207290887833
step: 250, loss: 0.006673290394246578
step: 260, loss: 0.0013413801789283752
step: 270, loss: 0.08895013481378555
step: 280, loss: 0.06466956436634064
step: 290, loss: 0.04575343430042267
step: 300, loss: 0.035639893263578415
step: 310, loss: 0.1274605393409729
step: 320, loss: 0.0136366942897439
step: 330, loss: 0.010762146674096584
step: 340, loss: 3.6145687772659585e-05
step: 350, loss: 0.0939217209815979
step: 360, loss: 0.06980277597904205
step: 370, loss: 0.02500338666141033
step: 380, loss: 0.013573112897574902
step: 390, loss: 0.0290345661342144
step: 400, loss: 0.0399676114320755
step: 410, loss: 0.04169492796063423
step: 420, loss: 0.05086630955338478
step: 430, loss: 0.06046297773718834
step: 440, loss: 0.045516084879636765
step: 450, loss: 0.10612953454256058
step: 460, loss: 0.07665423303842545
step: 470, loss: 8.995272946776822e-05
step: 480, loss: 0.03635108843445778
step: 490, loss: 0.13877680897712708
step: 500, loss: 0.021267719566822052
step: 510, loss: 0.055583566427230835
step: 520, loss: 0.07782968133687973
step: 530, loss: 0.07366719841957092
step: 540, loss: 0.04396369680762291
step: 550, loss: 0.021018682047724724
step: 560, loss: 0.03992487117648125
step: 570, loss: 0.06252111494541168
step: 580, loss: 0.035654790699481964
step: 590, loss: 0.06580431759357452
step: 600, loss: 0.08778199553489685
step: 610, loss: 0.023484917357563972
step: 620, loss: 0.0038722138851881027
step: 630, loss: 0.033710457384586334
step: 640, loss: 0.06525509059429169
step: 650, loss: 0.13173048198223114
step: 660, loss: 0.038124535232782364
step: 670, loss: 0.0737980380654335
step: 680, loss: 0.0541958212852478
step: 690, loss: 0.09158005565404892
step: 700, loss: 0.03145682066679001
step: 710, loss: 0.08086372911930084
step: 720, loss: 0.0558907613158226
step: 730, loss: 0.05488184839487076
step: 740, loss: 0.02864740788936615
step: 750, loss: 0.06565821915864944
step: 760, loss: 0.00207091704942286
step: 770, loss: 0.016503870487213135
step: 780, loss: 0.04211772233247757
step: 790, loss: 0.04473339021205902
step: 800, loss: 0.06383611261844635
step: 810, loss: 0.07418651878833771
step: 820, loss: 0.0556974858045578
step: 830, loss: 0.10364726930856705
step: 840, loss: 0.05515388026833534
step: 850, loss: 0.047422491014003754
step: 860, loss: 0.034788113087415695
step: 870, loss: 0.0635376125574112
step: 880, loss: 0.10933569818735123
step: 890, loss: 0.07531745731830597
step: 900, loss: 0.04987253621220589
step: 910, loss: 0.02758110500872135
step: 920, loss: 0.06013830751180649
step: 930, loss: 0.05511682853102684
step: 940, loss: 0.14893892407417297
step: 950, loss: 0.024904996156692505
step: 960, loss: 0.02066228725016117
step: 970, loss: 0.062224697321653366
epoch 18: dev_f1=0.9244570349386214, f1=0.9305361305361305, best_f1=0.935528120713306
step: 0, loss: 0.08278542011976242
step: 10, loss: 0.012788294814527035
step: 20, loss: 0.0778859406709671
step: 30, loss: 0.05083348602056503
step: 40, loss: 0.09009093791246414
step: 50, loss: 0.006138400174677372
step: 60, loss: 0.03889778256416321
step: 70, loss: 0.011456399224698544
step: 80, loss: 2.715484515647404e-05
step: 90, loss: 0.027406765148043633
step: 100, loss: 0.06327711045742035
step: 110, loss: 0.11179837584495544
step: 120, loss: 0.05881950259208679
step: 130, loss: 0.13772323727607727
step: 140, loss: 0.009925240650773048
step: 150, loss: 0.019426746293902397
step: 160, loss: 0.09804920852184296
step: 170, loss: 0.038954634219408035
step: 180, loss: 0.05667300522327423
step: 190, loss: 0.03331657126545906
step: 200, loss: 0.03310944139957428
step: 210, loss: 0.04034816473722458
step: 220, loss: 0.005313995759934187
step: 230, loss: 0.06884728372097015
step: 240, loss: 0.025805531069636345
step: 250, loss: 0.04140544310212135
step: 260, loss: 0.017172733321785927
step: 270, loss: 0.05880777910351753
step: 280, loss: 0.07207704335451126
step: 290, loss: 0.022393718361854553
step: 300, loss: 0.014648551121354103
step: 310, loss: 0.030745837837457657
step: 320, loss: 0.01666734740138054
step: 330, loss: 0.051923565566539764
step: 340, loss: 0.04316449910402298
step: 350, loss: 0.08521559834480286
step: 360, loss: 0.053077250719070435
step: 370, loss: 0.0035929305013269186
step: 380, loss: 0.041234489530324936
step: 390, loss: 0.025727979838848114
step: 400, loss: 0.04706385359168053
step: 410, loss: 0.0685645267367363
step: 420, loss: 0.046683624386787415
step: 430, loss: 0.018926147371530533
step: 440, loss: 0.0053311912342906
step: 450, loss: 0.00013134098844602704
step: 460, loss: 0.06047658249735832
step: 470, loss: 0.0670294463634491
step: 480, loss: 0.053175993263721466
step: 490, loss: 4.528258432401344e-05
step: 500, loss: 0.04658835753798485
step: 510, loss: 0.11580537259578705
step: 520, loss: 0.0425911471247673
step: 530, loss: 0.08038057386875153
step: 540, loss: 0.05589432269334793
step: 550, loss: 0.05846455693244934
step: 560, loss: 0.04003727436065674
step: 570, loss: 0.05704748257994652
step: 580, loss: 0.03482673317193985
step: 590, loss: 0.04199749231338501
step: 600, loss: 0.0586496964097023
step: 610, loss: 0.05127505213022232
step: 620, loss: 0.04119845852255821
step: 630, loss: 0.04454620182514191
step: 640, loss: 0.016865864396095276
step: 650, loss: 0.08045881241559982
step: 660, loss: 0.008928460069000721
step: 670, loss: 0.041319701820611954
step: 680, loss: 0.042315419763326645
step: 690, loss: 0.05929923057556152
step: 700, loss: 0.018425103276968002
step: 710, loss: 0.02688228152692318
step: 720, loss: 0.1905592828989029
step: 730, loss: 0.14658139646053314
step: 740, loss: 0.039207980036735535
step: 750, loss: 0.01950833387672901
step: 760, loss: 0.060873791575431824
step: 770, loss: 0.0032922220416367054
step: 780, loss: 0.015793221071362495
step: 790, loss: 0.015907876193523407
step: 800, loss: 0.06393248587846756
step: 810, loss: 0.046122174710035324
step: 820, loss: 0.0001977380452444777
step: 830, loss: 0.07941773533821106
step: 840, loss: 0.04491572082042694
step: 850, loss: 0.0590842105448246
step: 860, loss: 0.10307694971561432
step: 870, loss: 0.026043249294161797
step: 880, loss: 0.01609477773308754
step: 890, loss: 0.10738194733858109
step: 900, loss: 0.06297000497579575
step: 910, loss: 0.11761213093996048
step: 920, loss: 0.050461191684007645
step: 930, loss: 0.10196003317832947
step: 940, loss: 0.01914314180612564
step: 950, loss: 0.08206399530172348
step: 960, loss: 0.08501705527305603
step: 970, loss: 0.02674637734889984
epoch 19: dev_f1=0.9211026615969581, f1=0.9296435272045028, best_f1=0.935528120713306
step: 0, loss: 0.11561007052659988
step: 10, loss: 0.053608138114213943
step: 20, loss: 0.009422927163541317
step: 30, loss: 0.04821987822651863
step: 40, loss: 0.04641534760594368
step: 50, loss: 0.016116062179207802
step: 60, loss: 0.05494548752903938
step: 70, loss: 0.04558158665895462
step: 80, loss: 0.04000610485672951
step: 90, loss: 0.05211808532476425
step: 100, loss: 0.15363866090774536
step: 110, loss: 0.1267518699169159
step: 120, loss: 0.05332048609852791
step: 130, loss: 0.06362228840589523
step: 140, loss: 0.10985619574785233
step: 150, loss: 0.0648859441280365
step: 160, loss: 0.05907929688692093
step: 170, loss: 0.017806921154260635
step: 180, loss: 0.03362354263663292
step: 190, loss: 0.03962918743491173
step: 200, loss: 0.028236595913767815
step: 210, loss: 0.05159362778067589
step: 220, loss: 0.14862485229969025
step: 230, loss: 0.059542443603277206
step: 240, loss: 0.06130799651145935
step: 250, loss: 0.0032237786799669266
step: 260, loss: 0.07294981926679611
step: 270, loss: 0.022069521248340607
step: 280, loss: 0.007172924932092428
step: 290, loss: 0.027370616793632507
step: 300, loss: 1.9937293473049067e-05
step: 310, loss: 0.03638393431901932
step: 320, loss: 0.06670722365379333
step: 330, loss: 0.021756375208497047
step: 340, loss: 0.06018231809139252
step: 350, loss: 0.043039217591285706
step: 360, loss: 0.09102362394332886
step: 370, loss: 0.0558890700340271
step: 380, loss: 0.05393987149000168
step: 390, loss: 0.011530683375895023
step: 400, loss: 0.03557293862104416
step: 410, loss: 0.03370722010731697
step: 420, loss: 3.533815106493421e-05
step: 430, loss: 0.043468695133924484
step: 440, loss: 0.006298412568867207
step: 450, loss: 0.08756954222917557
step: 460, loss: 4.518071000347845e-05
step: 470, loss: 0.017613107338547707
step: 480, loss: 0.0649411752820015
step: 490, loss: 0.00011434731277404353
step: 500, loss: 0.01682554930448532
step: 510, loss: 0.024397799745202065
step: 520, loss: 0.04343077540397644
step: 530, loss: 0.03823647275567055
step: 540, loss: 0.044724419713020325
step: 550, loss: 0.00012391709606163204
step: 560, loss: 0.045650314539670944
step: 570, loss: 0.026308001950383186
step: 580, loss: 0.026178114116191864
step: 590, loss: 0.028321746736764908
step: 600, loss: 0.054752349853515625
step: 610, loss: 0.02888195775449276
step: 620, loss: 0.08248615264892578
step: 630, loss: 0.019967710599303246
step: 640, loss: 0.05011821910738945
step: 650, loss: 0.019248465076088905
step: 660, loss: 0.07440526783466339
step: 670, loss: 0.05748366937041283
step: 680, loss: 0.01891837827861309
step: 690, loss: 0.04601282626390457
step: 700, loss: 0.086393341422081
step: 710, loss: 0.07456699758768082
step: 720, loss: 0.07033424824476242
step: 730, loss: 0.06149890646338463
step: 740, loss: 0.0699157789349556
step: 750, loss: 0.0462355762720108
step: 760, loss: 0.08359625190496445
step: 770, loss: 0.049358218908309937
step: 780, loss: 0.13640356063842773
step: 790, loss: 0.054794710129499435
step: 800, loss: 0.06336816400289536
step: 810, loss: 0.04716715216636658
step: 820, loss: 0.0030297902412712574
step: 830, loss: 0.028442595154047012
step: 840, loss: 0.00017513937200419605
step: 850, loss: 0.012969380244612694
step: 860, loss: 0.02680596150457859
step: 870, loss: 0.042851246893405914
step: 880, loss: 0.04205029457807541
step: 890, loss: 0.008681802079081535
step: 900, loss: 0.045189760625362396
step: 910, loss: 0.05911640077829361
step: 920, loss: 0.018580427393317223
step: 930, loss: 0.037944454699754715
step: 940, loss: 0.0441473163664341
step: 950, loss: 0.02377857081592083
step: 960, loss: 0.02629224956035614
step: 970, loss: 0.05012942850589752
epoch 20: dev_f1=0.9216896060749881, f1=0.931390977443609, best_f1=0.935528120713306
