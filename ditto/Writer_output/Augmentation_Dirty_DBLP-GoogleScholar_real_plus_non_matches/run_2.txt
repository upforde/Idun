cuda
Device: cuda
step: 0, loss: 0.6208680272102356
step: 10, loss: 0.3216450810432434
step: 20, loss: 0.1562851369380951
step: 30, loss: 0.21560977399349213
step: 40, loss: 0.2931457757949829
step: 50, loss: 0.18482987582683563
step: 60, loss: 0.198220357298851
step: 70, loss: 0.28397083282470703
step: 80, loss: 0.32784169912338257
step: 90, loss: 0.14697326719760895
step: 100, loss: 0.1603260338306427
step: 110, loss: 0.1267363578081131
step: 120, loss: 0.22882524132728577
step: 130, loss: 0.17897571623325348
step: 140, loss: 0.11217539012432098
step: 150, loss: 0.2399556040763855
step: 160, loss: 0.0859469473361969
step: 170, loss: 0.28144967555999756
step: 180, loss: 0.2288803607225418
step: 190, loss: 0.2688782811164856
step: 200, loss: 0.18301059305667877
step: 210, loss: 0.23848935961723328
step: 220, loss: 0.21171467006206512
step: 230, loss: 0.2357465624809265
step: 240, loss: 0.2259359508752823
step: 250, loss: 0.1463746875524521
step: 260, loss: 0.19185781478881836
step: 270, loss: 0.11941728740930557
step: 280, loss: 0.11332812905311584
step: 290, loss: 0.06633730232715607
step: 300, loss: 0.11797606199979782
step: 310, loss: 0.14760640263557434
step: 320, loss: 0.14632810652256012
step: 330, loss: 0.20067967474460602
step: 340, loss: 0.10297384858131409
step: 350, loss: 0.11986418813467026
step: 360, loss: 0.06483466178178787
step: 370, loss: 0.2041480392217636
step: 380, loss: 0.1455385833978653
step: 390, loss: 0.17984095215797424
step: 400, loss: 0.0889185294508934
step: 410, loss: 0.2878197431564331
step: 420, loss: 0.051069408655166626
step: 430, loss: 0.14377450942993164
step: 440, loss: 0.13276851177215576
step: 450, loss: 0.16410861909389496
step: 460, loss: 0.11826883256435394
step: 470, loss: 0.08536673337221146
step: 480, loss: 0.15609540045261383
step: 490, loss: 0.14775630831718445
step: 500, loss: 0.24889570474624634
step: 510, loss: 0.1390811949968338
step: 520, loss: 0.15049467980861664
step: 530, loss: 0.1192726418375969
step: 540, loss: 0.19370140135288239
step: 550, loss: 0.2769924998283386
step: 560, loss: 0.10584156215190887
step: 570, loss: 0.19340306520462036
step: 580, loss: 0.09391853213310242
step: 590, loss: 0.13145969808101654
step: 600, loss: 0.13181179761886597
step: 610, loss: 0.2298310101032257
step: 620, loss: 0.06900037080049515
step: 630, loss: 0.2692202925682068
step: 640, loss: 0.1400827169418335
step: 650, loss: 0.16388437151908875
step: 660, loss: 0.14571332931518555
step: 670, loss: 0.15429839491844177
step: 680, loss: 0.13937388360500336
step: 690, loss: 0.1550697535276413
step: 700, loss: 0.15186116099357605
step: 710, loss: 0.08741147816181183
step: 720, loss: 0.1671408712863922
step: 730, loss: 0.13339629769325256
step: 740, loss: 0.15062202513217926
step: 750, loss: 0.0839107558131218
step: 760, loss: 0.046587541699409485
step: 770, loss: 0.12355014681816101
step: 780, loss: 0.15070806443691254
step: 790, loss: 0.17810982465744019
step: 800, loss: 0.15734286606311798
step: 810, loss: 0.08296553045511246
step: 820, loss: 0.06696430593729019
step: 830, loss: 0.1838952898979187
step: 840, loss: 0.1027851551771164
step: 850, loss: 0.27433347702026367
step: 860, loss: 0.1687372624874115
step: 870, loss: 0.23058857023715973
step: 880, loss: 0.1507619470357895
step: 890, loss: 0.1468046009540558
step: 900, loss: 0.16767680644989014
step: 910, loss: 0.0891546681523323
step: 920, loss: 0.21804659068584442
step: 930, loss: 0.20847654342651367
step: 940, loss: 0.1077098399400711
step: 950, loss: 0.11350329220294952
step: 960, loss: 0.12807777523994446
step: 970, loss: 0.1406877338886261
epoch 1: dev_f1=0.9197761194029851, f1=0.9155060352831941, best_f1=0.9155060352831941
step: 0, loss: 0.163407102227211
step: 10, loss: 0.28627917170524597
step: 20, loss: 0.19013626873493195
step: 30, loss: 0.07816127687692642
step: 40, loss: 0.1268187016248703
step: 50, loss: 0.14387516677379608
step: 60, loss: 0.17421716451644897
step: 70, loss: 0.10090385377407074
step: 80, loss: 0.14799155294895172
step: 90, loss: 0.06543301045894623
step: 100, loss: 0.35264891386032104
step: 110, loss: 0.11146969348192215
step: 120, loss: 0.13155914843082428
step: 130, loss: 0.05593935027718544
step: 140, loss: 0.1262877732515335
step: 150, loss: 0.13691522181034088
step: 160, loss: 0.2714255154132843
step: 170, loss: 0.07732035964727402
step: 180, loss: 0.07435201853513718
step: 190, loss: 0.13117893040180206
step: 200, loss: 0.1136121079325676
step: 210, loss: 0.15776051580905914
step: 220, loss: 0.09952745586633682
step: 230, loss: 0.22204455733299255
step: 240, loss: 0.025710508227348328
step: 250, loss: 0.15973462164402008
step: 260, loss: 0.2669990658760071
step: 270, loss: 0.042125582695007324
step: 280, loss: 0.0972197949886322
step: 290, loss: 0.10422158241271973
step: 300, loss: 0.07716193795204163
step: 310, loss: 0.1559794545173645
step: 320, loss: 0.14452660083770752
step: 330, loss: 0.10217826068401337
step: 340, loss: 0.2783035933971405
step: 350, loss: 0.18228363990783691
step: 360, loss: 0.13631132245063782
step: 370, loss: 0.08814927935600281
step: 380, loss: 0.10757924616336823
step: 390, loss: 0.129338800907135
step: 400, loss: 0.03774126619100571
step: 410, loss: 0.21340849995613098
step: 420, loss: 0.14317667484283447
step: 430, loss: 0.18495382368564606
step: 440, loss: 0.0981549471616745
step: 450, loss: 0.09153100848197937
step: 460, loss: 0.19370877742767334
step: 470, loss: 0.19515886902809143
step: 480, loss: 0.1317845731973648
step: 490, loss: 0.07804719358682632
step: 500, loss: 0.26277604699134827
step: 510, loss: 0.11448395252227783
step: 520, loss: 0.18823516368865967
step: 530, loss: 0.15421278774738312
step: 540, loss: 0.05759429559111595
step: 550, loss: 0.11560938507318497
step: 560, loss: 0.15689100325107574
step: 570, loss: 0.12152736634016037
step: 580, loss: 0.08485278487205505
step: 590, loss: 0.09406852722167969
step: 600, loss: 0.10551683604717255
step: 610, loss: 0.3185548484325409
step: 620, loss: 0.04880734160542488
step: 630, loss: 0.25349298119544983
step: 640, loss: 0.20328539609909058
step: 650, loss: 0.1255057007074356
step: 660, loss: 0.31952717900276184
step: 670, loss: 0.06548155099153519
step: 680, loss: 0.0955117866396904
step: 690, loss: 0.10334780067205429
step: 700, loss: 0.14667606353759766
step: 710, loss: 0.1228581890463829
step: 720, loss: 0.17176520824432373
step: 730, loss: 0.08879786729812622
step: 740, loss: 0.12526634335517883
step: 750, loss: 0.07224101573228836
step: 760, loss: 0.11119627207517624
step: 770, loss: 0.1908627152442932
step: 780, loss: 0.14287935197353363
step: 790, loss: 0.09107577055692673
step: 800, loss: 0.07484958320856094
step: 810, loss: 0.13347843289375305
step: 820, loss: 0.18019013106822968
step: 830, loss: 0.18065693974494934
step: 840, loss: 0.12206653505563736
step: 850, loss: 0.08296479284763336
step: 860, loss: 0.11448977142572403
step: 870, loss: 0.13049980998039246
step: 880, loss: 0.18092837929725647
step: 890, loss: 0.08834478259086609
step: 900, loss: 0.12206275761127472
step: 910, loss: 0.3005876839160919
step: 920, loss: 0.10315877944231033
step: 930, loss: 0.19233086705207825
step: 940, loss: 0.08137870579957962
step: 950, loss: 0.140581414103508
step: 960, loss: 0.2096593976020813
step: 970, loss: 0.15585830807685852
epoch 2: dev_f1=0.9124254928931682, f1=0.9080982711555959, best_f1=0.9155060352831941
step: 0, loss: 0.1607438176870346
step: 10, loss: 0.12107237428426743
step: 20, loss: 0.18250134587287903
step: 30, loss: 0.10426255315542221
step: 40, loss: 0.1632808893918991
step: 50, loss: 0.30866944789886475
step: 60, loss: 0.08191137760877609
step: 70, loss: 0.07119477540254593
step: 80, loss: 0.2064426988363266
step: 90, loss: 0.06130646914243698
step: 100, loss: 0.2308557629585266
step: 110, loss: 0.1250074952840805
step: 120, loss: 0.08710397779941559
step: 130, loss: 0.1713521033525467
step: 140, loss: 0.09832227230072021
step: 150, loss: 0.10911724716424942
step: 160, loss: 0.11313141882419586
step: 170, loss: 0.08373810350894928
step: 180, loss: 0.06850844621658325
step: 190, loss: 0.0788489580154419
step: 200, loss: 0.04710105061531067
step: 210, loss: 0.041145022958517075
step: 220, loss: 0.18698611855506897
step: 230, loss: 0.1889641135931015
step: 240, loss: 0.2737603187561035
step: 250, loss: 0.1544029414653778
step: 260, loss: 0.19247186183929443
step: 270, loss: 0.0683489590883255
step: 280, loss: 0.10663759708404541
step: 290, loss: 0.16223427653312683
step: 300, loss: 0.15095746517181396
step: 310, loss: 0.06900952011346817
step: 320, loss: 0.23193980753421783
step: 330, loss: 0.14081957936286926
step: 340, loss: 0.0015364300925284624
step: 350, loss: 0.045566316694021225
step: 360, loss: 0.11796323955059052
step: 370, loss: 0.09260735660791397
step: 380, loss: 0.09582836180925369
step: 390, loss: 0.14590252935886383
step: 400, loss: 0.03223282843828201
step: 410, loss: 0.12394460290670395
step: 420, loss: 0.09684792160987854
step: 430, loss: 0.12347207218408585
step: 440, loss: 0.16414578258991241
step: 450, loss: 0.21137984097003937
step: 460, loss: 0.15676598250865936
step: 470, loss: 0.22640275955200195
step: 480, loss: 0.08875896781682968
step: 490, loss: 0.13518542051315308
step: 500, loss: 0.04154755175113678
step: 510, loss: 0.12390728294849396
step: 520, loss: 0.09544745832681656
step: 530, loss: 0.10096324980258942
step: 540, loss: 0.10074952989816666
step: 550, loss: 0.0748877301812172
step: 560, loss: 0.1503562331199646
step: 570, loss: 0.11468984186649323
step: 580, loss: 0.11728490889072418
step: 590, loss: 0.11964604258537292
step: 600, loss: 0.11333846300840378
step: 610, loss: 0.10266848653554916
step: 620, loss: 0.06643908470869064
step: 630, loss: 0.17011284828186035
step: 640, loss: 0.033393267542123795
step: 650, loss: 0.10264020413160324
step: 660, loss: 0.021873056888580322
step: 670, loss: 0.2329520732164383
step: 680, loss: 0.07703536748886108
step: 690, loss: 0.0957251489162445
step: 700, loss: 0.13931210339069366
step: 710, loss: 0.15200012922286987
step: 720, loss: 0.16858969628810883
step: 730, loss: 0.09715139865875244
step: 740, loss: 0.04124811664223671
step: 750, loss: 0.1586841195821762
step: 760, loss: 0.15274973213672638
step: 770, loss: 0.0657748430967331
step: 780, loss: 0.1256132274866104
step: 790, loss: 0.17086806893348694
step: 800, loss: 0.05292640998959541
step: 810, loss: 0.14334431290626526
step: 820, loss: 0.033240195363759995
step: 830, loss: 0.15408487617969513
step: 840, loss: 0.18271517753601074
step: 850, loss: 0.4159674346446991
step: 860, loss: 0.12435884028673172
step: 870, loss: 0.14353418350219727
step: 880, loss: 0.24737083911895752
step: 890, loss: 0.09267652034759521
step: 900, loss: 0.06593555212020874
step: 910, loss: 0.1103881299495697
step: 920, loss: 0.11829835176467896
step: 930, loss: 0.10539989173412323
step: 940, loss: 0.06302684545516968
step: 950, loss: 0.19819103181362152
step: 960, loss: 0.1156255379319191
step: 970, loss: 0.0836978331208229
epoch 3: dev_f1=0.9184707508060802, f1=0.9050691244239631, best_f1=0.9155060352831941
step: 0, loss: 0.13084185123443604
step: 10, loss: 0.09006380289793015
step: 20, loss: 0.2669529914855957
step: 30, loss: 0.24892018735408783
step: 40, loss: 0.1184224933385849
step: 50, loss: 0.06631109118461609
step: 60, loss: 0.12121308594942093
step: 70, loss: 0.02824036404490471
step: 80, loss: 0.045337848365306854
step: 90, loss: 0.16267862915992737
step: 100, loss: 0.10939230024814606
step: 110, loss: 0.06341173499822617
step: 120, loss: 0.06073310598731041
step: 130, loss: 0.08776585757732391
step: 140, loss: 0.10683194547891617
step: 150, loss: 0.25754857063293457
step: 160, loss: 0.0782611295580864
step: 170, loss: 0.17689074575901031
step: 180, loss: 0.19121114909648895
step: 190, loss: 0.06405652314424515
step: 200, loss: 0.1624639332294464
step: 210, loss: 0.1291561722755432
step: 220, loss: 0.07274767756462097
step: 230, loss: 0.0023951525799930096
step: 240, loss: 0.05127741023898125
step: 250, loss: 0.14299727976322174
step: 260, loss: 0.2790767252445221
step: 270, loss: 0.05685095489025116
step: 280, loss: 0.09133073687553406
step: 290, loss: 0.023125099018216133
step: 300, loss: 0.1276010423898697
step: 310, loss: 0.1346152275800705
step: 320, loss: 0.11312656104564667
step: 330, loss: 0.28035709261894226
step: 340, loss: 0.03299843519926071
step: 350, loss: 0.20063301920890808
step: 360, loss: 0.11325733363628387
step: 370, loss: 0.11679281294345856
step: 380, loss: 0.06323760747909546
step: 390, loss: 0.044213052839040756
step: 400, loss: 0.1825299710035324
step: 410, loss: 0.3015819191932678
step: 420, loss: 0.06199635937809944
step: 430, loss: 0.08543511480093002
step: 440, loss: 0.03927694261074066
step: 450, loss: 0.15774579346179962
step: 460, loss: 0.17921656370162964
step: 470, loss: 0.1532326489686966
step: 480, loss: 0.1083025112748146
step: 490, loss: 0.124659463763237
step: 500, loss: 0.1393425613641739
step: 510, loss: 0.0855240523815155
step: 520, loss: 0.11811596155166626
step: 530, loss: 0.08852779865264893
step: 540, loss: 0.14780908823013306
step: 550, loss: 0.12221893668174744
step: 560, loss: 0.06738351285457611
step: 570, loss: 0.027270186692476273
step: 580, loss: 0.10467274487018585
step: 590, loss: 0.1687496304512024
step: 600, loss: 0.12869121134281158
step: 610, loss: 0.06747043132781982
step: 620, loss: 0.25713369250297546
step: 630, loss: 0.14968490600585938
step: 640, loss: 0.05722173675894737
step: 650, loss: 0.27332109212875366
step: 660, loss: 0.05148456618189812
step: 670, loss: 0.1428748369216919
step: 680, loss: 0.11452153325080872
step: 690, loss: 0.050952691584825516
step: 700, loss: 0.05145755782723427
step: 710, loss: 0.06759142875671387
step: 720, loss: 0.10479751229286194
step: 730, loss: 0.2206011861562729
step: 740, loss: 0.16199466586112976
step: 750, loss: 0.12194003164768219
step: 760, loss: 0.09995779395103455
step: 770, loss: 0.09461359679698944
step: 780, loss: 0.18228206038475037
step: 790, loss: 0.1516714096069336
step: 800, loss: 0.21763283014297485
step: 810, loss: 0.17774170637130737
step: 820, loss: 0.029852142557501793
step: 830, loss: 0.15717735886573792
step: 840, loss: 0.1540311872959137
step: 850, loss: 0.06597214192152023
step: 860, loss: 0.08938799053430557
step: 870, loss: 0.025989681482315063
step: 880, loss: 0.1714434027671814
step: 890, loss: 0.10385401546955109
step: 900, loss: 0.05690277740359306
step: 910, loss: 0.09788262844085693
step: 920, loss: 0.18007616698741913
step: 930, loss: 0.0966646820306778
step: 940, loss: 0.2561416029930115
step: 950, loss: 0.048334039747714996
step: 960, loss: 0.0671999603509903
step: 970, loss: 0.1240992397069931
epoch 4: dev_f1=0.9249417249417249, f1=0.9217230199166282, best_f1=0.9217230199166282
step: 0, loss: 0.1571321338415146
step: 10, loss: 0.12193021178245544
step: 20, loss: 0.0573277585208416
step: 30, loss: 0.13421283662319183
step: 40, loss: 0.0370132252573967
step: 50, loss: 0.09968935698270798
step: 60, loss: 0.06523782014846802
step: 70, loss: 0.4552399516105652
step: 80, loss: 0.13300226628780365
step: 90, loss: 0.13904455304145813
step: 100, loss: 0.05136307328939438
step: 110, loss: 0.10406598448753357
step: 120, loss: 0.05879749357700348
step: 130, loss: 0.1527061015367508
step: 140, loss: 0.16455963253974915
step: 150, loss: 0.04292677715420723
step: 160, loss: 0.0347147211432457
step: 170, loss: 0.041696734726428986
step: 180, loss: 0.1456153392791748
step: 190, loss: 0.11229728162288666
step: 200, loss: 0.07689466327428818
step: 210, loss: 0.11707108467817307
step: 220, loss: 0.079523004591465
step: 230, loss: 0.13814297318458557
step: 240, loss: 0.1292920559644699
step: 250, loss: 0.07256561517715454
step: 260, loss: 0.1803688406944275
step: 270, loss: 0.08638879656791687
step: 280, loss: 0.03487730771303177
step: 290, loss: 0.08626707643270493
step: 300, loss: 0.08373448997735977
step: 310, loss: 0.1551070660352707
step: 320, loss: 0.0857045128941536
step: 330, loss: 0.06406337767839432
step: 340, loss: 0.057402562350034714
step: 350, loss: 0.16274303197860718
step: 360, loss: 0.12648750841617584
step: 370, loss: 0.05303791165351868
step: 380, loss: 0.09652203321456909
step: 390, loss: 0.10396755486726761
step: 400, loss: 0.06074785441160202
step: 410, loss: 0.09342548996210098
step: 420, loss: 0.07239386439323425
step: 430, loss: 0.050847914069890976
step: 440, loss: 0.10869691520929337
step: 450, loss: 0.15800979733467102
step: 460, loss: 0.06229482591152191
step: 470, loss: 0.11861270666122437
step: 480, loss: 0.06813644617795944
step: 490, loss: 0.1467040628194809
step: 500, loss: 0.24748927354812622
step: 510, loss: 0.03179356828331947
step: 520, loss: 0.11813317984342575
step: 530, loss: 0.09445057064294815
step: 540, loss: 0.1514582633972168
step: 550, loss: 0.03853956237435341
step: 560, loss: 0.136825293302536
step: 570, loss: 0.06246790289878845
step: 580, loss: 0.10266096144914627
step: 590, loss: 0.03949454799294472
step: 600, loss: 0.1680028885602951
step: 610, loss: 0.042011480778455734
step: 620, loss: 0.10182619839906693
step: 630, loss: 0.0771981030702591
step: 640, loss: 0.115076445043087
step: 650, loss: 0.21117813885211945
step: 660, loss: 0.07519099116325378
step: 670, loss: 0.04842269793152809
step: 680, loss: 0.15528252720832825
step: 690, loss: 0.07967889308929443
step: 700, loss: 0.08315082639455795
step: 710, loss: 0.07638999819755554
step: 720, loss: 0.13306507468223572
step: 730, loss: 0.08047432452440262
step: 740, loss: 0.0825679749250412
step: 750, loss: 0.1387292742729187
step: 760, loss: 0.14654147624969482
step: 770, loss: 0.16117915511131287
step: 780, loss: 0.16618666052818298
step: 790, loss: 0.09370390325784683
step: 800, loss: 0.09043541550636292
step: 810, loss: 0.05920307710766792
step: 820, loss: 0.09603506326675415
step: 830, loss: 0.16259491443634033
step: 840, loss: 0.08733973652124405
step: 850, loss: 0.03407600522041321
step: 860, loss: 0.1353735327720642
step: 870, loss: 0.03273395821452141
step: 880, loss: 0.059287410229444504
step: 890, loss: 0.02898213267326355
step: 900, loss: 0.07949446886777878
step: 910, loss: 0.07701798528432846
step: 920, loss: 0.10466808825731277
step: 930, loss: 0.01673468016088009
step: 940, loss: 0.06874874979257584
step: 950, loss: 0.08028198778629303
step: 960, loss: 0.1360035091638565
step: 970, loss: 0.1564505249261856
epoch 5: dev_f1=0.9241379310344828, f1=0.919815668202765, best_f1=0.9217230199166282
step: 0, loss: 0.08168736100196838
step: 10, loss: 0.10472109168767929
step: 20, loss: 0.05761489272117615
step: 30, loss: 0.0683031976222992
step: 40, loss: 0.07207201421260834
step: 50, loss: 0.08661782741546631
step: 60, loss: 0.1492113620042801
step: 70, loss: 0.16284774243831635
step: 80, loss: 0.12154354155063629
step: 90, loss: 0.034963130950927734
step: 100, loss: 0.08281273394823074
step: 110, loss: 0.2655181288719177
step: 120, loss: 0.034316450357437134
step: 130, loss: 0.010811093263328075
step: 140, loss: 0.05212802439928055
step: 150, loss: 0.11194026470184326
step: 160, loss: 0.13229958713054657
step: 170, loss: 0.1558905690908432
step: 180, loss: 0.17437715828418732
step: 190, loss: 0.09527339041233063
step: 200, loss: 0.11056285351514816
step: 210, loss: 0.10940926522016525
step: 220, loss: 0.07768916338682175
step: 230, loss: 0.0196234118193388
step: 240, loss: 0.08807135373353958
step: 250, loss: 0.04644042253494263
step: 260, loss: 0.0571322925388813
step: 270, loss: 0.01588387042284012
step: 280, loss: 0.05309440195560455
step: 290, loss: 0.1367247849702835
step: 300, loss: 0.0663314089179039
step: 310, loss: 0.13729918003082275
step: 320, loss: 0.08586271852254868
step: 330, loss: 0.017261050641536713
step: 340, loss: 0.12186024338006973
step: 350, loss: 0.0527530312538147
step: 360, loss: 0.09075721353292465
step: 370, loss: 0.08646663278341293
step: 380, loss: 0.010010064579546452
step: 390, loss: 0.0756148099899292
step: 400, loss: 0.027460159733891487
step: 410, loss: 0.09550120681524277
step: 420, loss: 0.05500641092658043
step: 430, loss: 0.1040472686290741
step: 440, loss: 0.13462652266025543
step: 450, loss: 0.054916996508836746
step: 460, loss: 0.12101700901985168
step: 470, loss: 0.014846941456198692
step: 480, loss: 0.18203938007354736
step: 490, loss: 0.008224655874073505
step: 500, loss: 0.10149314999580383
step: 510, loss: 0.0723491683602333
step: 520, loss: 0.06519674509763718
step: 530, loss: 0.04399979114532471
step: 540, loss: 0.04656621068716049
step: 550, loss: 0.13649164140224457
step: 560, loss: 0.11647945642471313
step: 570, loss: 0.10093210637569427
step: 580, loss: 0.010332838632166386
step: 590, loss: 0.11530041694641113
step: 600, loss: 0.14611274003982544
step: 610, loss: 0.03584447503089905
step: 620, loss: 0.05801479145884514
step: 630, loss: 0.0010193346533924341
step: 640, loss: 0.17063282430171967
step: 650, loss: 0.09223396331071854
step: 660, loss: 0.00926966592669487
step: 670, loss: 0.08566834777593613
step: 680, loss: 0.05136002227663994
step: 690, loss: 0.05132384970784187
step: 700, loss: 0.07623378187417984
step: 710, loss: 0.03194072097539902
step: 720, loss: 0.09631066769361496
step: 730, loss: 0.10323923826217651
step: 740, loss: 0.05979162082076073
step: 750, loss: 0.21358565986156464
step: 760, loss: 0.1642284393310547
step: 770, loss: 0.20651087164878845
step: 780, loss: 0.15401430428028107
step: 790, loss: 0.060196634382009506
step: 800, loss: 0.02245802991092205
step: 810, loss: 0.02401316724717617
step: 820, loss: 0.027565594762563705
step: 830, loss: 0.08746721595525742
step: 840, loss: 0.07866188883781433
step: 850, loss: 0.2606135904788971
step: 860, loss: 0.017871495336294174
step: 870, loss: 0.12672601640224457
step: 880, loss: 0.07163127511739731
step: 890, loss: 0.08575920015573502
step: 900, loss: 0.04484314098954201
step: 910, loss: 0.04787500202655792
step: 920, loss: 0.12121624499559402
step: 930, loss: 0.15905916690826416
step: 940, loss: 0.12023822963237762
step: 950, loss: 0.06914161890745163
step: 960, loss: 0.1596193164587021
step: 970, loss: 0.09227883815765381
epoch 6: dev_f1=0.9297597042513862, f1=0.929368029739777, best_f1=0.929368029739777
step: 0, loss: 0.12809519469738007
step: 10, loss: 0.1609405130147934
step: 20, loss: 0.08112934976816177
step: 30, loss: 0.014216914772987366
step: 40, loss: 0.14014823734760284
step: 50, loss: 0.13404810428619385
step: 60, loss: 0.08543922752141953
step: 70, loss: 0.2390962392091751
step: 80, loss: 0.06553182750940323
step: 90, loss: 0.0855725035071373
step: 100, loss: 0.2330721914768219
step: 110, loss: 0.15005768835544586
step: 120, loss: 0.028600262477993965
step: 130, loss: 0.24237944185733795
step: 140, loss: 0.10674981772899628
step: 150, loss: 0.11742305755615234
step: 160, loss: 0.12457934021949768
step: 170, loss: 0.014515640214085579
step: 180, loss: 0.14444850385189056
step: 190, loss: 0.17039775848388672
step: 200, loss: 0.05109749734401703
step: 210, loss: 0.11246167123317719
step: 220, loss: 0.07484795898199081
step: 230, loss: 0.10947936028242111
step: 240, loss: 0.03224566951394081
step: 250, loss: 0.05115330219268799
step: 260, loss: 0.11510074883699417
step: 270, loss: 0.1299317479133606
step: 280, loss: 0.035632144659757614
step: 290, loss: 0.05689698085188866
step: 300, loss: 0.1279555708169937
step: 310, loss: 0.193367138504982
step: 320, loss: 0.20315943658351898
step: 330, loss: 0.05399082601070404
step: 340, loss: 0.07942898571491241
step: 350, loss: 0.08833315223455429
step: 360, loss: 0.0305632334202528
step: 370, loss: 0.02271200716495514
step: 380, loss: 0.033579811453819275
step: 390, loss: 0.07317272573709488
step: 400, loss: 0.10388312488794327
step: 410, loss: 0.12282434105873108
step: 420, loss: 0.130280002951622
step: 430, loss: 0.07779088616371155
step: 440, loss: 0.07914863526821136
step: 450, loss: 0.10445833951234818
step: 460, loss: 0.03717752546072006
step: 470, loss: 0.0711316391825676
step: 480, loss: 0.015145530924201012
step: 490, loss: 0.19564831256866455
step: 500, loss: 0.08219849318265915
step: 510, loss: 0.17364978790283203
step: 520, loss: 0.12823177874088287
step: 530, loss: 0.14507204294204712
step: 540, loss: 0.062490448355674744
step: 550, loss: 0.037827685475349426
step: 560, loss: 0.15336646139621735
step: 570, loss: 0.05220518633723259
step: 580, loss: 0.1415683627128601
step: 590, loss: 0.1344992220401764
step: 600, loss: 0.1065790057182312
step: 610, loss: 0.21100355684757233
step: 620, loss: 0.02458265796303749
step: 630, loss: 0.08424266427755356
step: 640, loss: 0.02682957425713539
step: 650, loss: 0.10389184206724167
step: 660, loss: 0.02046499028801918
step: 670, loss: 0.35661956667900085
step: 680, loss: 0.10721488296985626
step: 690, loss: 0.06214210018515587
step: 700, loss: 0.0513484813272953
step: 710, loss: 0.019564300775527954
step: 720, loss: 0.09998209774494171
step: 730, loss: 0.18685612082481384
step: 740, loss: 0.16768430173397064
step: 750, loss: 0.10888601094484329
step: 760, loss: 0.047784674912691116
step: 770, loss: 0.04949476942420006
step: 780, loss: 0.11870111525058746
step: 790, loss: 0.09566335380077362
step: 800, loss: 0.1634366363286972
step: 810, loss: 0.06951052695512772
step: 820, loss: 0.2259257733821869
step: 830, loss: 0.08994217962026596
step: 840, loss: 0.1704026311635971
step: 850, loss: 0.0874139741063118
step: 860, loss: 0.07762190699577332
step: 870, loss: 0.07707381993532181
step: 880, loss: 0.03749048337340355
step: 890, loss: 0.03395378962159157
step: 900, loss: 0.20557695627212524
step: 910, loss: 0.07617571949958801
step: 920, loss: 0.07219018787145615
step: 930, loss: 0.06620492786169052
step: 940, loss: 0.06156507134437561
step: 950, loss: 0.09455521404743195
step: 960, loss: 0.37465229630470276
step: 970, loss: 0.07437615841627121
epoch 7: dev_f1=0.931807780320366, f1=0.9289316827143513, best_f1=0.9289316827143513
step: 0, loss: 0.0605926588177681
step: 10, loss: 0.059627752751111984
step: 20, loss: 0.07674737274646759
step: 30, loss: 0.03545732796192169
step: 40, loss: 0.09739799797534943
step: 50, loss: 0.09588787704706192
step: 60, loss: 0.05295969173312187
step: 70, loss: 0.1335204690694809
step: 80, loss: 0.037630677223205566
step: 90, loss: 0.020489033311605453
step: 100, loss: 0.06757014244794846
step: 110, loss: 0.10743221640586853
step: 120, loss: 0.13602551817893982
step: 130, loss: 0.03247293457388878
step: 140, loss: 0.14042221009731293
step: 150, loss: 0.13271211087703705
step: 160, loss: 0.05286224186420441
step: 170, loss: 0.012547027319669724
step: 180, loss: 0.11994494497776031
step: 190, loss: 0.1277313083410263
step: 200, loss: 0.1127728521823883
step: 210, loss: 0.07337895035743713
step: 220, loss: 0.13128554821014404
step: 230, loss: 0.06981051713228226
step: 240, loss: 0.06481634825468063
step: 250, loss: 0.1265854388475418
step: 260, loss: 0.08112753927707672
step: 270, loss: 0.23941701650619507
step: 280, loss: 0.06766458600759506
step: 290, loss: 0.08511701971292496
step: 300, loss: 0.08062741160392761
step: 310, loss: 0.11001709848642349
step: 320, loss: 0.11226901412010193
step: 330, loss: 0.03948134928941727
step: 340, loss: 0.08275913447141647
step: 350, loss: 0.09098641574382782
step: 360, loss: 0.13095597922801971
step: 370, loss: 0.08444685488939285
step: 380, loss: 0.11937092989683151
step: 390, loss: 0.0285712331533432
step: 400, loss: 0.15958914160728455
step: 410, loss: 0.08443477749824524
step: 420, loss: 0.09723363816738129
step: 430, loss: 0.028240706771612167
step: 440, loss: 0.1806267946958542
step: 450, loss: 0.015939105302095413
step: 460, loss: 0.1484142690896988
step: 470, loss: 0.18714866042137146
step: 480, loss: 0.024565398693084717
step: 490, loss: 0.01019127294421196
step: 500, loss: 0.060405831784009933
step: 510, loss: 0.1292746514081955
step: 520, loss: 0.06478026509284973
step: 530, loss: 0.08655291795730591
step: 540, loss: 0.04832484945654869
step: 550, loss: 0.07282482087612152
step: 560, loss: 0.0584583543241024
step: 570, loss: 0.11629769951105118
step: 580, loss: 0.05751810967922211
step: 590, loss: 0.020737072452902794
step: 600, loss: 0.04742736741900444
step: 610, loss: 0.08699043095111847
step: 620, loss: 0.1512908786535263
step: 630, loss: 0.09735515713691711
step: 640, loss: 0.06767906993627548
step: 650, loss: 0.113671213388443
step: 660, loss: 0.03679057955741882
step: 670, loss: 0.041234131902456284
step: 680, loss: 0.11609020829200745
step: 690, loss: 0.04645968973636627
step: 700, loss: 0.13839398324489594
step: 710, loss: 0.1239696815609932
step: 720, loss: 0.026025203987956047
step: 730, loss: 0.11943544447422028
step: 740, loss: 0.017557859420776367
step: 750, loss: 0.13587546348571777
step: 760, loss: 0.03916671499609947
step: 770, loss: 0.05076754838228226
step: 780, loss: 0.09474347531795502
step: 790, loss: 0.039315495640039444
step: 800, loss: 0.12543371319770813
step: 810, loss: 0.11849453300237656
step: 820, loss: 0.11969057470560074
step: 830, loss: 0.07107049971818924
step: 840, loss: 0.028721846640110016
step: 850, loss: 0.16301558911800385
step: 860, loss: 0.12692052125930786
step: 870, loss: 0.1235843226313591
step: 880, loss: 0.07101914286613464
step: 890, loss: 0.15331770479679108
step: 900, loss: 0.1357201188802719
step: 910, loss: 0.09765422344207764
step: 920, loss: 0.18887706100940704
step: 930, loss: 0.11143749207258224
step: 940, loss: 0.04068378359079361
step: 950, loss: 0.047770362347364426
step: 960, loss: 0.12036219239234924
step: 970, loss: 0.07890626788139343
epoch 8: dev_f1=0.9327188940092166, f1=0.9288354898336414, best_f1=0.9288354898336414
step: 0, loss: 0.056307658553123474
step: 10, loss: 0.008972452953457832
step: 20, loss: 0.028271444141864777
step: 30, loss: 0.10278331488370895
step: 40, loss: 0.05688663199543953
step: 50, loss: 0.04518076777458191
step: 60, loss: 0.10924355685710907
step: 70, loss: 0.0707259401679039
step: 80, loss: 0.09196765720844269
step: 90, loss: 0.048833560198545456
step: 100, loss: 0.030019931495189667
step: 110, loss: 0.08198373019695282
step: 120, loss: 0.07637089490890503
step: 130, loss: 0.08491221070289612
step: 140, loss: 0.08647774904966354
step: 150, loss: 0.012684850953519344
step: 160, loss: 0.11301431059837341
step: 170, loss: 0.0513753779232502
step: 180, loss: 0.12477773427963257
step: 190, loss: 0.052224621176719666
step: 200, loss: 0.15345221757888794
step: 210, loss: 0.15803758800029755
step: 220, loss: 0.15734054148197174
step: 230, loss: 0.028469108045101166
step: 240, loss: 0.08898883312940598
step: 250, loss: 0.018320294097065926
step: 260, loss: 0.06320001184940338
step: 270, loss: 0.11340136080980301
step: 280, loss: 0.16303053498268127
step: 290, loss: 0.06535332649946213
step: 300, loss: 0.0737420991063118
step: 310, loss: 0.1327044814825058
step: 320, loss: 0.10048041492700577
step: 330, loss: 0.02400320954620838
step: 340, loss: 0.07494312524795532
step: 350, loss: 0.09694231301546097
step: 360, loss: 0.00702449306845665
step: 370, loss: 0.03486885130405426
step: 380, loss: 0.17274725437164307
step: 390, loss: 0.09214398264884949
step: 400, loss: 0.010852538980543613
step: 410, loss: 0.04342831298708916
step: 420, loss: 0.08893082290887833
step: 430, loss: 0.07099985331296921
step: 440, loss: 0.02655012160539627
step: 450, loss: 0.02715061791241169
step: 460, loss: 0.09400011599063873
step: 470, loss: 0.017982816323637962
step: 480, loss: 0.04637604579329491
step: 490, loss: 0.026281632483005524
step: 500, loss: 0.12182814627885818
step: 510, loss: 0.09501725435256958
step: 520, loss: 0.039719291031360626
step: 530, loss: 0.03871607035398483
step: 540, loss: 0.12031610310077667
step: 550, loss: 0.05666957423090935
step: 560, loss: 0.1663752645254135
step: 570, loss: 0.156330868601799
step: 580, loss: 0.07419110089540482
step: 590, loss: 0.033290985971689224
step: 600, loss: 0.014059255830943584
step: 610, loss: 0.10866952687501907
step: 620, loss: 0.008476977236568928
step: 630, loss: 0.18530982732772827
step: 640, loss: 0.07964448630809784
step: 650, loss: 0.0859122946858406
step: 660, loss: 0.1487267166376114
step: 670, loss: 0.02781181037425995
step: 680, loss: 0.1308424323797226
step: 690, loss: 0.039592087268829346
step: 700, loss: 0.04143159091472626
step: 710, loss: 0.08072468638420105
step: 720, loss: 0.06494369357824326
step: 730, loss: 0.24118684232234955
step: 740, loss: 0.015192707069218159
step: 750, loss: 0.07183857262134552
step: 760, loss: 0.07666654884815216
step: 770, loss: 0.1257857233285904
step: 780, loss: 0.11939845979213715
step: 790, loss: 0.0847235769033432
step: 800, loss: 0.06407168507575989
step: 810, loss: 0.018201246857643127
step: 820, loss: 0.029337182641029358
step: 830, loss: 0.21779067814350128
step: 840, loss: 0.13752098381519318
step: 850, loss: 0.11154800653457642
step: 860, loss: 0.08727923035621643
step: 870, loss: 0.06402219086885452
step: 880, loss: 0.044824130833148956
step: 890, loss: 0.03981061652302742
step: 900, loss: 0.03095819056034088
step: 910, loss: 0.05507010966539383
step: 920, loss: 0.1571984589099884
step: 930, loss: 0.03930039703845978
step: 940, loss: 0.07118619978427887
step: 950, loss: 0.1258758306503296
step: 960, loss: 0.1120099276304245
step: 970, loss: 0.02363724820315838
epoch 9: dev_f1=0.9357374017568193, f1=0.9312413474850022, best_f1=0.9312413474850022
step: 0, loss: 0.06619061529636383
step: 10, loss: 0.055003318935632706
step: 20, loss: 0.04807955399155617
step: 30, loss: 0.034558895975351334
step: 40, loss: 0.10669658333063126
step: 50, loss: 0.08492248505353928
step: 60, loss: 0.07708462327718735
step: 70, loss: 0.09000545740127563
step: 80, loss: 0.043459948152303696
step: 90, loss: 0.06564720720052719
step: 100, loss: 0.10592822730541229
step: 110, loss: 0.12324264645576477
step: 120, loss: 0.15122482180595398
step: 130, loss: 0.09697519242763519
step: 140, loss: 0.04550303518772125
step: 150, loss: 0.028060197830200195
step: 160, loss: 0.026239868253469467
step: 170, loss: 0.017707154154777527
step: 180, loss: 0.0788571834564209
step: 190, loss: 0.08101484179496765
step: 200, loss: 0.2664855122566223
step: 210, loss: 0.07809634506702423
step: 220, loss: 0.051622916013002396
step: 230, loss: 0.03997466713190079
step: 240, loss: 0.02347380854189396
step: 250, loss: 0.036254167556762695
step: 260, loss: 0.032799191772937775
step: 270, loss: 0.09237807989120483
step: 280, loss: 0.06034529209136963
step: 290, loss: 0.035649511963129044
step: 300, loss: 0.07091222703456879
step: 310, loss: 0.17424219846725464
step: 320, loss: 0.12155940383672714
step: 330, loss: 0.16239102184772491
step: 340, loss: 0.09302100539207458
step: 350, loss: 0.10784616321325302
step: 360, loss: 0.12369381636381149
step: 370, loss: 0.09542016685009003
step: 380, loss: 0.08379346132278442
step: 390, loss: 0.12939520180225372
step: 400, loss: 0.13358378410339355
step: 410, loss: 0.07603351771831512
step: 420, loss: 0.0913429707288742
step: 430, loss: 0.0574316680431366
step: 440, loss: 0.06725858151912689
step: 450, loss: 0.10224861651659012
step: 460, loss: 0.09783889353275299
step: 470, loss: 1.6901109120226465e-05
step: 480, loss: 0.05240868404507637
step: 490, loss: 0.20185647904872894
step: 500, loss: 0.1419624239206314
step: 510, loss: 0.0975097194314003
step: 520, loss: 0.09948629140853882
step: 530, loss: 0.14655350148677826
step: 540, loss: 0.028191303834319115
step: 550, loss: 0.05835617706179619
step: 560, loss: 0.05546993762254715
step: 570, loss: 0.08082323521375656
step: 580, loss: 0.07982774078845978
step: 590, loss: 0.07740357518196106
step: 600, loss: 0.024746473878622055
step: 610, loss: 0.0864163190126419
step: 620, loss: 0.05765403434634209
step: 630, loss: 0.04558885097503662
step: 640, loss: 0.08349231630563736
step: 650, loss: 0.08080919831991196
step: 660, loss: 0.03672729805111885
step: 670, loss: 0.04309842735528946
step: 680, loss: 0.03939136117696762
step: 690, loss: 0.05887091904878616
step: 700, loss: 0.08019321411848068
step: 710, loss: 0.163853257894516
step: 720, loss: 0.04869319871068001
step: 730, loss: 0.12519699335098267
step: 740, loss: 0.014894798398017883
step: 750, loss: 0.08198604732751846
step: 760, loss: 0.034311674535274506
step: 770, loss: 0.08873429149389267
step: 780, loss: 0.07648323476314545
step: 790, loss: 0.09941434860229492
step: 800, loss: 0.12369532138109207
step: 810, loss: 0.10580809414386749
step: 820, loss: 0.11655640602111816
step: 830, loss: 0.02722429484128952
step: 840, loss: 0.027649281546473503
step: 850, loss: 0.04649680480360985
step: 860, loss: 0.14698906242847443
step: 870, loss: 0.06376086175441742
step: 880, loss: 0.04952440783381462
step: 890, loss: 0.1289895623922348
step: 900, loss: 0.0697065219283104
step: 910, loss: 0.09250783920288086
step: 920, loss: 0.16468563675880432
step: 930, loss: 0.0729600042104721
step: 940, loss: 0.011356651782989502
step: 950, loss: 0.07961039990186691
step: 960, loss: 0.06659568101167679
step: 970, loss: 0.06698896735906601
epoch 10: dev_f1=0.9313815187557181, f1=0.9289617486338797, best_f1=0.9312413474850022
step: 0, loss: 0.048647038638591766
step: 10, loss: 0.11257249116897583
step: 20, loss: 0.0295538529753685
step: 30, loss: 0.008265583775937557
step: 40, loss: 0.013189829885959625
step: 50, loss: 0.11778998374938965
step: 60, loss: 0.05900900065898895
step: 70, loss: 0.07702641934156418
step: 80, loss: 0.025885894894599915
step: 90, loss: 0.038580331951379776
step: 100, loss: 0.051218267530202866
step: 110, loss: 0.008125921711325645
step: 120, loss: 0.08024007081985474
step: 130, loss: 0.03248079493641853
step: 140, loss: 0.04293789714574814
step: 150, loss: 0.14980028569698334
step: 160, loss: 0.0315740741789341
step: 170, loss: 0.05859818309545517
step: 180, loss: 0.05412751063704491
step: 190, loss: 0.19475945830345154
step: 200, loss: 0.061211712658405304
step: 210, loss: 0.031021399423480034
step: 220, loss: 0.0517902672290802
step: 230, loss: 0.12500427663326263
step: 240, loss: 0.1121174693107605
step: 250, loss: 0.06499668955802917
step: 260, loss: 0.022830674424767494
step: 270, loss: 0.006106254179030657
step: 280, loss: 0.14289815723896027
step: 290, loss: 0.048670656979084015
step: 300, loss: 0.12838250398635864
step: 310, loss: 0.06119478866457939
step: 320, loss: 0.07388012111186981
step: 330, loss: 0.1676943004131317
step: 340, loss: 0.08762505650520325
step: 350, loss: 0.1002647876739502
step: 360, loss: 0.05781027674674988
step: 370, loss: 0.13113372027873993
step: 380, loss: 0.06752632558345795
step: 390, loss: 0.029223626479506493
step: 400, loss: 0.041506554931402206
step: 410, loss: 0.17500217258930206
step: 420, loss: 0.046324726194143295
step: 430, loss: 0.08611023426055908
step: 440, loss: 0.15350258350372314
step: 450, loss: 0.06740570813417435
step: 460, loss: 0.07323008030653
step: 470, loss: 0.07274267077445984
step: 480, loss: 0.1321210265159607
step: 490, loss: 0.021456463262438774
step: 500, loss: 0.0447213277220726
step: 510, loss: 0.05033676326274872
step: 520, loss: 0.06038414686918259
step: 530, loss: 0.12772098183631897
step: 540, loss: 0.0884832814335823
step: 550, loss: 0.25465336441993713
step: 560, loss: 0.15325501561164856
step: 570, loss: 0.05020756274461746
step: 580, loss: 0.0394023060798645
step: 590, loss: 0.051363687962293625
step: 600, loss: 0.005720963701605797
step: 610, loss: 0.07215029746294022
step: 620, loss: 0.1506122499704361
step: 630, loss: 0.06934715807437897
step: 640, loss: 0.018340811133384705
step: 650, loss: 0.14719709753990173
step: 660, loss: 0.1318259835243225
step: 670, loss: 0.0605500228703022
step: 680, loss: 0.08133164793252945
step: 690, loss: 0.06139823794364929
step: 700, loss: 0.11368918418884277
step: 710, loss: 0.02656170353293419
step: 720, loss: 0.005224880762398243
step: 730, loss: 0.1229047030210495
step: 740, loss: 0.0543229915201664
step: 750, loss: 0.07195305824279785
step: 760, loss: 0.10364148020744324
step: 770, loss: 0.02521827071905136
step: 780, loss: 0.1587931513786316
step: 790, loss: 0.05598234012722969
step: 800, loss: 0.06888483464717865
step: 810, loss: 0.05110958218574524
step: 820, loss: 0.043933358043432236
step: 830, loss: 0.039169054478406906
step: 840, loss: 0.1226004809141159
step: 850, loss: 0.014613800682127476
step: 860, loss: 0.06932493299245834
step: 870, loss: 0.05010581016540527
step: 880, loss: 0.02401397004723549
step: 890, loss: 0.0819498747587204
step: 900, loss: 0.054987020790576935
step: 910, loss: 0.12717154622077942
step: 920, loss: 0.04909764230251312
step: 930, loss: 0.07558532804250717
step: 940, loss: 0.03650524467229843
step: 950, loss: 0.018931398168206215
step: 960, loss: 0.053982868790626526
step: 970, loss: 0.010763315483927727
epoch 11: dev_f1=0.9314045730284647, f1=0.9277389277389277, best_f1=0.9312413474850022
step: 0, loss: 0.03805796802043915
step: 10, loss: 0.022089606150984764
step: 20, loss: 0.041466835886240005
step: 30, loss: 0.08686667680740356
step: 40, loss: 0.08099199831485748
step: 50, loss: 0.0833587571978569
step: 60, loss: 0.024259570986032486
step: 70, loss: 0.17825782299041748
step: 80, loss: 0.011208043433725834
step: 90, loss: 0.04195597767829895
step: 100, loss: 0.08369728922843933
step: 110, loss: 0.14912323653697968
step: 120, loss: 0.0659746527671814
step: 130, loss: 0.024377575144171715
step: 140, loss: 0.036516450345516205
step: 150, loss: 0.031081994995474815
step: 160, loss: 0.05890415981411934
step: 170, loss: 0.050124816596508026
step: 180, loss: 0.06653155386447906
step: 190, loss: 0.08910584449768066
step: 200, loss: 0.041985780000686646
step: 210, loss: 0.002552987076342106
step: 220, loss: 0.0692666545510292
step: 230, loss: 0.08852757513523102
step: 240, loss: 0.14954230189323425
step: 250, loss: 0.08777140080928802
step: 260, loss: 0.04358819127082825
step: 270, loss: 0.05350971966981888
step: 280, loss: 0.045339569449424744
step: 290, loss: 0.012184086255729198
step: 300, loss: 0.07549000531435013
step: 310, loss: 0.055518586188554764
step: 320, loss: 0.042946748435497284
step: 330, loss: 0.11808115243911743
step: 340, loss: 0.043825700879096985
step: 350, loss: 0.18327008187770844
step: 360, loss: 0.038651369512081146
step: 370, loss: 0.06833981722593307
step: 380, loss: 0.11902225762605667
step: 390, loss: 0.11621103435754776
step: 400, loss: 0.09393119812011719
step: 410, loss: 0.04320014640688896
step: 420, loss: 0.03996240720152855
step: 430, loss: 0.002856770297512412
step: 440, loss: 0.0811537578701973
step: 450, loss: 0.06335998326539993
step: 460, loss: 0.1619006097316742
step: 470, loss: 0.0865846574306488
step: 480, loss: 0.1044081375002861
step: 490, loss: 0.047261226922273636
step: 500, loss: 0.17971909046173096
step: 510, loss: 0.16947901248931885
step: 520, loss: 0.05590006709098816
step: 530, loss: 0.05749013274908066
step: 540, loss: 0.10546434670686722
step: 550, loss: 0.01829651929438114
step: 560, loss: 0.03018932230770588
step: 570, loss: 0.08100075274705887
step: 580, loss: 0.06400071084499359
step: 590, loss: 0.1422530710697174
step: 600, loss: 0.043206728994846344
step: 610, loss: 0.09093697369098663
step: 620, loss: 0.001162012224085629
step: 630, loss: 0.1381286084651947
step: 640, loss: 0.03962903842329979
step: 650, loss: 0.03812083229422569
step: 660, loss: 0.020531650632619858
step: 670, loss: 0.027272555977106094
step: 680, loss: 0.005592589266598225
step: 690, loss: 0.06396987289190292
step: 700, loss: 0.10901331901550293
step: 710, loss: 0.10948945581912994
step: 720, loss: 0.09432128816843033
step: 730, loss: 0.13298721611499786
step: 740, loss: 0.09416225552558899
step: 750, loss: 0.11643622815608978
step: 760, loss: 0.1051032766699791
step: 770, loss: 0.05943244695663452
step: 780, loss: 0.10109035670757294
step: 790, loss: 0.03569471836090088
step: 800, loss: 0.0843474417924881
step: 810, loss: 0.10608880966901779
step: 820, loss: 0.0666850358247757
step: 830, loss: 0.04420571029186249
step: 840, loss: 0.047699760645627975
step: 850, loss: 0.06162681430578232
step: 860, loss: 0.09412261843681335
step: 870, loss: 0.03656243160367012
step: 880, loss: 0.0036264911759644747
step: 890, loss: 0.07076869159936905
step: 900, loss: 0.15252965688705444
step: 910, loss: 0.1515897810459137
step: 920, loss: 0.04089066758751869
step: 930, loss: 0.078549325466156
step: 940, loss: 0.08885513991117477
step: 950, loss: 0.07394355535507202
step: 960, loss: 0.021747397258877754
step: 970, loss: 0.07219009846448898
epoch 12: dev_f1=0.9368616527390901, f1=0.9320388349514563, best_f1=0.9320388349514563
step: 0, loss: 0.14135035872459412
step: 10, loss: 0.05226624384522438
step: 20, loss: 0.06229434907436371
step: 30, loss: 0.11093109101057053
step: 40, loss: 0.014003973454236984
step: 50, loss: 0.0006553136627189815
step: 60, loss: 0.06989173591136932
step: 70, loss: 0.1214982122182846
step: 80, loss: 0.16177959740161896
step: 90, loss: 0.03779107332229614
step: 100, loss: 0.04676508158445358
step: 110, loss: 0.06338319927453995
step: 120, loss: 0.024524230509996414
step: 130, loss: 0.030008642002940178
step: 140, loss: 0.08334628492593765
step: 150, loss: 0.012945370748639107
step: 160, loss: 0.04576808586716652
step: 170, loss: 0.030836163088679314
step: 180, loss: 0.046002477407455444
step: 190, loss: 0.024911226704716682
step: 200, loss: 0.07485984265804291
step: 210, loss: 0.03223944455385208
step: 220, loss: 0.036273449659347534
step: 230, loss: 0.061570726335048676
step: 240, loss: 0.013382814824581146
step: 250, loss: 0.027218926697969437
step: 260, loss: 0.062134526669979095
step: 270, loss: 0.042266495525836945
step: 280, loss: 0.17399540543556213
step: 290, loss: 0.06529679149389267
step: 300, loss: 0.09543827176094055
step: 310, loss: 0.03696485236287117
step: 320, loss: 0.06163528934121132
step: 330, loss: 0.060342937707901
step: 340, loss: 0.09227025508880615
step: 350, loss: 0.08330319821834564
step: 360, loss: 0.12943314015865326
step: 370, loss: 0.01449456624686718
step: 380, loss: 0.06003928557038307
step: 390, loss: 0.059993915259838104
step: 400, loss: 0.04318534582853317
step: 410, loss: 0.1491246372461319
step: 420, loss: 0.055749956518411636
step: 430, loss: 0.067528136074543
step: 440, loss: 0.05165541172027588
step: 450, loss: 0.08115850389003754
step: 460, loss: 0.02796507626771927
step: 470, loss: 0.07988180965185165
step: 480, loss: 0.036912284791469574
step: 490, loss: 0.042740460485219955
step: 500, loss: 0.08078975975513458
step: 510, loss: 0.020103415474295616
step: 520, loss: 0.021539539098739624
step: 530, loss: 0.12708283960819244
step: 540, loss: 0.0812339335680008
step: 550, loss: 0.07332677394151688
step: 560, loss: 0.05977364629507065
step: 570, loss: 0.14396002888679504
step: 580, loss: 0.03305559605360031
step: 590, loss: 0.06410783529281616
step: 600, loss: 0.03377094864845276
step: 610, loss: 0.023697128519415855
step: 620, loss: 0.06757228821516037
step: 630, loss: 0.0357922799885273
step: 640, loss: 0.0696762278676033
step: 650, loss: 0.03330578655004501
step: 660, loss: 0.07257869839668274
step: 670, loss: 0.04837146773934364
step: 680, loss: 0.1826554238796234
step: 690, loss: 0.048229094594717026
step: 700, loss: 0.02768081985414028
step: 710, loss: 0.051975689828395844
step: 720, loss: 0.09988612681627274
step: 730, loss: 0.10084324330091476
step: 740, loss: 0.047186121344566345
step: 750, loss: 0.0784682184457779
step: 760, loss: 0.0007303331512957811
step: 770, loss: 0.10414253175258636
step: 780, loss: 0.029802922159433365
step: 790, loss: 0.06175001338124275
step: 800, loss: 0.0301743783056736
step: 810, loss: 0.030963201075792313
step: 820, loss: 0.0012606754899024963
step: 830, loss: 0.0005284147337079048
step: 840, loss: 0.14373773336410522
step: 850, loss: 0.09151224792003632
step: 860, loss: 0.06619460135698318
step: 870, loss: 0.12265369296073914
step: 880, loss: 0.03890155255794525
step: 890, loss: 0.0426471047103405
step: 900, loss: 0.003207402303814888
step: 910, loss: 0.1451127827167511
step: 920, loss: 0.0034580423962324858
step: 930, loss: 0.0009286646381951869
step: 940, loss: 0.01996629498898983
step: 950, loss: 0.1298927664756775
step: 960, loss: 0.0820213332772255
step: 970, loss: 0.07994191348552704
epoch 13: dev_f1=0.9283054003724395, f1=0.927348449791763, best_f1=0.9320388349514563
step: 0, loss: 0.05279364809393883
step: 10, loss: 0.03630196675658226
step: 20, loss: 0.001817704876884818
step: 30, loss: 0.024442611262202263
step: 40, loss: 0.10379369556903839
step: 50, loss: 0.04377034679055214
step: 60, loss: 0.0007725053001195192
step: 70, loss: 0.08641017228364944
step: 80, loss: 0.08459010720252991
step: 90, loss: 0.0008462877012789249
step: 100, loss: 0.06948494166135788
step: 110, loss: 0.04682294651865959
step: 120, loss: 0.011807278729975224
step: 130, loss: 0.0402417816221714
step: 140, loss: 0.0715840756893158
step: 150, loss: 0.03001844324171543
step: 160, loss: 0.10139914602041245
step: 170, loss: 0.07208488136529922
step: 180, loss: 0.033729080110788345
step: 190, loss: 0.04479817673563957
step: 200, loss: 0.04070136323571205
step: 210, loss: 0.0016072315629571676
step: 220, loss: 0.024317100644111633
step: 230, loss: 0.022909941151738167
step: 240, loss: 0.06340102851390839
step: 250, loss: 0.03587772324681282
step: 260, loss: 0.003119818167760968
step: 270, loss: 0.0829322412610054
step: 280, loss: 0.05231897160410881
step: 290, loss: 0.038555119186639786
step: 300, loss: 0.0345221608877182
step: 310, loss: 0.1370973438024521
step: 320, loss: 0.09390498697757721
step: 330, loss: 0.04715836048126221
step: 340, loss: 0.11645542085170746
step: 350, loss: 0.03950772061944008
step: 360, loss: 0.015194782987236977
step: 370, loss: 0.06268565356731415
step: 380, loss: 0.09245746582746506
step: 390, loss: 0.07344038784503937
step: 400, loss: 0.028244130313396454
step: 410, loss: 0.018947618082165718
step: 420, loss: 0.09422464668750763
step: 430, loss: 0.10163311660289764
step: 440, loss: 0.07330355048179626
step: 450, loss: 0.1991516649723053
step: 460, loss: 0.08633756637573242
step: 470, loss: 0.041298672556877136
step: 480, loss: 0.05232588201761246
step: 490, loss: 0.061957672238349915
step: 500, loss: 0.06407534331083298
step: 510, loss: 0.07843436300754547
step: 520, loss: 0.0570426844060421
step: 530, loss: 0.04448797553777695
step: 540, loss: 0.047287315130233765
step: 550, loss: 0.010980453342199326
step: 560, loss: 0.05068963021039963
step: 570, loss: 0.035385895520448685
step: 580, loss: 0.16249758005142212
step: 590, loss: 0.01877039670944214
step: 600, loss: 0.0719204992055893
step: 610, loss: 0.09319189190864563
step: 620, loss: 0.00264941668137908
step: 630, loss: 0.06235827878117561
step: 640, loss: 0.03973442688584328
step: 650, loss: 0.03802929446101189
step: 660, loss: 0.1466274857521057
step: 670, loss: 0.06229672580957413
step: 680, loss: 0.06438630819320679
step: 690, loss: 0.04423779994249344
step: 700, loss: 0.03742529824376106
step: 710, loss: 0.16067388653755188
step: 720, loss: 0.10600578784942627
step: 730, loss: 0.02938419207930565
step: 740, loss: 0.014206715859472752
step: 750, loss: 0.015406223945319653
step: 760, loss: 0.1493234932422638
step: 770, loss: 0.026372667402029037
step: 780, loss: 0.035204026848077774
step: 790, loss: 0.22333793342113495
step: 800, loss: 0.003981941379606724
step: 810, loss: 0.08031339943408966
step: 820, loss: 0.13832469284534454
step: 830, loss: 0.06158069893717766
step: 840, loss: 0.11667994409799576
step: 850, loss: 0.08142770081758499
step: 860, loss: 0.1200818195939064
step: 870, loss: 0.05245108902454376
step: 880, loss: 0.021482843905687332
step: 890, loss: 0.00222373241558671
step: 900, loss: 0.08759485930204391
step: 910, loss: 0.07025974988937378
step: 920, loss: 0.09006865322589874
step: 930, loss: 0.033343780785799026
step: 940, loss: 0.01530239637941122
step: 950, loss: 0.0003839621786028147
step: 960, loss: 0.02436041459441185
step: 970, loss: 0.16700664162635803
epoch 14: dev_f1=0.922936616507068, f1=0.9224452554744527, best_f1=0.9320388349514563
step: 0, loss: 0.04694269225001335
step: 10, loss: 0.03401270881295204
step: 20, loss: 0.011900761164724827
step: 30, loss: 0.044342294335365295
step: 40, loss: 0.08275336027145386
step: 50, loss: 0.023881444707512856
step: 60, loss: 0.030346931889653206
step: 70, loss: 0.10926686227321625
step: 80, loss: 0.0037525962106883526
step: 90, loss: 0.05179518088698387
step: 100, loss: 0.07385966926813126
step: 110, loss: 0.21090468764305115
step: 120, loss: 0.008968056179583073
step: 130, loss: 0.03072504885494709
step: 140, loss: 0.14906355738639832
step: 150, loss: 0.07642574608325958
step: 160, loss: 0.12758174538612366
step: 170, loss: 0.03117450699210167
step: 180, loss: 0.04291943460702896
step: 190, loss: 0.10761453956365585
step: 200, loss: 0.07659222185611725
step: 210, loss: 0.06017441675066948
step: 220, loss: 0.00031533819856122136
step: 230, loss: 0.0732397511601448
step: 240, loss: 0.11899389326572418
step: 250, loss: 0.009206028655171394
step: 260, loss: 0.12120064347982407
step: 270, loss: 0.03749077394604683
step: 280, loss: 0.039876434952020645
step: 290, loss: 0.05403817817568779
step: 300, loss: 0.1150454431772232
step: 310, loss: 0.024190926924347878
step: 320, loss: 0.06494412571191788
step: 330, loss: 0.029551493003964424
step: 340, loss: 0.025946155190467834
step: 350, loss: 0.1322750300168991
step: 360, loss: 0.021444037556648254
step: 370, loss: 0.030697157606482506
step: 380, loss: 0.07124435156583786
step: 390, loss: 0.05531540513038635
step: 400, loss: 0.06400158256292343
step: 410, loss: 0.04353481903672218
step: 420, loss: 0.003297456307336688
step: 430, loss: 0.0395483560860157
step: 440, loss: 0.081562839448452
step: 450, loss: 0.08137195557355881
step: 460, loss: 0.08837612718343735
step: 470, loss: 0.00822348240762949
step: 480, loss: 0.03709114342927933
step: 490, loss: 0.009662075899541378
step: 500, loss: 0.010078062303364277
step: 510, loss: 0.07819352298974991
step: 520, loss: 0.017928827553987503
step: 530, loss: 0.045037370175123215
step: 540, loss: 0.04680870100855827
step: 550, loss: 0.012225578539073467
step: 560, loss: 0.0025625794660300016
step: 570, loss: 0.06535220891237259
step: 580, loss: 0.08228997886180878
step: 590, loss: 0.016326025128364563
step: 600, loss: 0.022389600053429604
step: 610, loss: 0.053266968578100204
step: 620, loss: 0.01387595571577549
step: 630, loss: 0.041810981929302216
step: 640, loss: 0.05261947587132454
step: 650, loss: 0.025744885206222534
step: 660, loss: 0.018395500257611275
step: 670, loss: 0.03864860162138939
step: 680, loss: 0.09343862533569336
step: 690, loss: 0.061469461768865585
step: 700, loss: 0.032426077872514725
step: 710, loss: 0.09246782958507538
step: 720, loss: 0.0911177322268486
step: 730, loss: 0.10954438149929047
step: 740, loss: 0.02480902336537838
step: 750, loss: 0.04664153605699539
step: 760, loss: 0.06971573829650879
step: 770, loss: 0.1011253148317337
step: 780, loss: 0.04099427908658981
step: 790, loss: 0.04468635097146034
step: 800, loss: 0.19723069667816162
step: 810, loss: 0.08174587041139603
step: 820, loss: 0.08030582964420319
step: 830, loss: 0.013351927511394024
step: 840, loss: 0.1773301064968109
step: 850, loss: 0.0669102817773819
step: 860, loss: 0.04369233176112175
step: 870, loss: 0.05917796865105629
step: 880, loss: 0.12024901062250137
step: 890, loss: 0.0630502924323082
step: 900, loss: 0.00674833869561553
step: 910, loss: 0.0660330280661583
step: 920, loss: 0.05776260793209076
step: 930, loss: 0.11487090587615967
step: 940, loss: 0.07237207889556885
step: 950, loss: 0.003985079936683178
step: 960, loss: 0.1262986958026886
step: 970, loss: 0.06691542267799377
epoch 15: dev_f1=0.9293119698397737, f1=0.9268978444236176, best_f1=0.9320388349514563
step: 0, loss: 0.07909466326236725
step: 10, loss: 0.04376869648694992
step: 20, loss: 0.054534394294023514
step: 30, loss: 0.08672703057527542
step: 40, loss: 0.013300676830112934
step: 50, loss: 0.02874625101685524
step: 60, loss: 0.055786069482564926
step: 70, loss: 0.037747982889413834
step: 80, loss: 0.05014628544449806
step: 90, loss: 0.03864118829369545
step: 100, loss: 0.10253360867500305
step: 110, loss: 0.04648197069764137
step: 120, loss: 0.0507645308971405
step: 130, loss: 0.04744657129049301
step: 140, loss: 0.06432489305734634
step: 150, loss: 0.09828159213066101
step: 160, loss: 0.04876285046339035
step: 170, loss: 0.12647733092308044
step: 180, loss: 0.07597249001264572
step: 190, loss: 0.08026101440191269
step: 200, loss: 0.08574216812849045
step: 210, loss: 0.051990993320941925
step: 220, loss: 0.07930916547775269
step: 230, loss: 0.0011144247837364674
step: 240, loss: 0.04644564166665077
step: 250, loss: 0.035015374422073364
step: 260, loss: 0.030715307220816612
step: 270, loss: 0.045544981956481934
step: 280, loss: 0.034384045749902725
step: 290, loss: 0.06987042725086212
step: 300, loss: 0.08547069132328033
step: 310, loss: 0.08846177905797958
step: 320, loss: 0.07366164773702621
step: 330, loss: 0.09313872456550598
step: 340, loss: 0.02084297686815262
step: 350, loss: 0.028177767992019653
step: 360, loss: 0.07938414812088013
step: 370, loss: 0.08184932917356491
step: 380, loss: 0.003461722983047366
step: 390, loss: 0.014957288280129433
step: 400, loss: 5.1919334509875625e-05
step: 410, loss: 0.12315360456705093
step: 420, loss: 0.10534730553627014
step: 430, loss: 0.10072454065084457
step: 440, loss: 0.045021895319223404
step: 450, loss: 0.008793702349066734
step: 460, loss: 0.056137342005968094
step: 470, loss: 0.0678245946764946
step: 480, loss: 0.03591963276267052
step: 490, loss: 0.05106830224394798
step: 500, loss: 0.09625832736492157
step: 510, loss: 0.03334205225110054
step: 520, loss: 0.0794965997338295
step: 530, loss: 0.07061227411031723
step: 540, loss: 0.03685879707336426
step: 550, loss: 0.03290633112192154
step: 560, loss: 0.031248247250914574
step: 570, loss: 0.0398411899805069
step: 580, loss: 0.01913902536034584
step: 590, loss: 0.04299849271774292
step: 600, loss: 0.009720038622617722
step: 610, loss: 0.06990335881710052
step: 620, loss: 0.11328304558992386
step: 630, loss: 0.0011494372738525271
step: 640, loss: 0.012477176263928413
step: 650, loss: 0.11726721376180649
step: 660, loss: 0.10123442113399506
step: 670, loss: 0.10188793390989304
step: 680, loss: 0.036410681903362274
step: 690, loss: 0.06334159523248672
step: 700, loss: 0.1530841886997223
step: 710, loss: 0.1275644451379776
step: 720, loss: 0.023940294981002808
step: 730, loss: 0.013234728015959263
step: 740, loss: 0.07989941537380219
step: 750, loss: 0.03608573228120804
step: 760, loss: 0.10578442364931107
step: 770, loss: 0.015381334349513054
step: 780, loss: 2.0844930986640975e-05
step: 790, loss: 0.0843220055103302
step: 800, loss: 0.034292180091142654
step: 810, loss: 0.04364686831831932
step: 820, loss: 3.6023437132826075e-05
step: 830, loss: 0.05800461396574974
step: 840, loss: 0.035969603806734085
step: 850, loss: 0.05121370777487755
step: 860, loss: 0.033912476152181625
step: 870, loss: 0.05011897534132004
step: 880, loss: 0.029784679412841797
step: 890, loss: 0.03971162810921669
step: 900, loss: 0.04229177162051201
step: 910, loss: 0.08300594240427017
step: 920, loss: 0.0017993811052292585
step: 930, loss: 0.05283232033252716
step: 940, loss: 0.044126179069280624
step: 950, loss: 8.534585504094139e-06
step: 960, loss: 0.07177507132291794
step: 970, loss: 0.06398618221282959
epoch 16: dev_f1=0.9273323956868261, f1=0.9248716752216519, best_f1=0.9320388349514563
step: 0, loss: 0.029945306479930878
step: 10, loss: 0.014657819643616676
step: 20, loss: 0.022678833454847336
step: 30, loss: 0.028862107545137405
step: 40, loss: 0.03243134543299675
step: 50, loss: 0.03761467710137367
step: 60, loss: 0.02024521864950657
step: 70, loss: 0.05057215318083763
step: 80, loss: 0.029783625155687332
step: 90, loss: 0.02520303800702095
step: 100, loss: 0.045762695372104645
step: 110, loss: 0.027928899973630905
step: 120, loss: 0.013399701565504074
step: 130, loss: 0.051071375608444214
step: 140, loss: 0.03436660021543503
step: 150, loss: 0.01050572469830513
step: 160, loss: 0.07862261682748795
step: 170, loss: 0.024746160954236984
step: 180, loss: 0.12192711234092712
step: 190, loss: 0.0064667812548577785
step: 200, loss: 0.0933985710144043
step: 210, loss: 0.03809577226638794
step: 220, loss: 0.015582866035401821
step: 230, loss: 0.018822137266397476
step: 240, loss: 0.08963572233915329
step: 250, loss: 0.07669616490602493
step: 260, loss: 0.030849669128656387
step: 270, loss: 0.08541271090507507
step: 280, loss: 0.02810787782073021
step: 290, loss: 0.028481584042310715
step: 300, loss: 0.02182767353951931
step: 310, loss: 0.010133981704711914
step: 320, loss: 0.027821026742458344
step: 330, loss: 0.043792784214019775
step: 340, loss: 0.031078819185495377
step: 350, loss: 0.03566247969865799
step: 360, loss: 0.07759326696395874
step: 370, loss: 0.015306763350963593
step: 380, loss: 0.06191220507025719
step: 390, loss: 0.047690343111753464
step: 400, loss: 0.018811002373695374
step: 410, loss: 0.026419270783662796
step: 420, loss: 0.020331770181655884
step: 430, loss: 0.032666973769664764
step: 440, loss: 0.01137498952448368
step: 450, loss: 0.03536510095000267
step: 460, loss: 0.07750124484300613
step: 470, loss: 0.0007144859409891069
step: 480, loss: 0.012595264241099358
step: 490, loss: 0.03150174766778946
step: 500, loss: 0.0229372326284647
step: 510, loss: 0.0163026824593544
step: 520, loss: 0.06845561414957047
step: 530, loss: 0.028996679931879044
step: 540, loss: 0.11727326363325119
step: 550, loss: 0.09307657927274704
step: 560, loss: 0.07763022929430008
step: 570, loss: 0.09708607941865921
step: 580, loss: 0.06109897419810295
step: 590, loss: 0.054817333817481995
step: 600, loss: 0.045426785945892334
step: 610, loss: 0.01741379126906395
step: 620, loss: 0.024278808385133743
step: 630, loss: 0.02755879983305931
step: 640, loss: 0.03864431381225586
step: 650, loss: 0.07128380984067917
step: 660, loss: 0.0721668154001236
step: 670, loss: 0.02110929600894451
step: 680, loss: 0.09578423202037811
step: 690, loss: 0.0531168095767498
step: 700, loss: 0.022459836676716805
step: 710, loss: 0.002447230974212289
step: 720, loss: 0.07798798382282257
step: 730, loss: 0.05630708113312721
step: 740, loss: 0.03047545626759529
step: 750, loss: 0.05449051409959793
step: 760, loss: 0.021466754376888275
step: 770, loss: 0.028629789128899574
step: 780, loss: 0.08991643041372299
step: 790, loss: 0.11392475664615631
step: 800, loss: 0.04839424043893814
step: 810, loss: 0.0763850286602974
step: 820, loss: 0.1268312633037567
step: 830, loss: 0.0704919695854187
step: 840, loss: 0.023809347301721573
step: 850, loss: 0.06000643968582153
step: 860, loss: 1.461682768422179e-05
step: 870, loss: 0.09200497716665268
step: 880, loss: 0.05130419135093689
step: 890, loss: 0.03749145194888115
step: 900, loss: 0.0893782302737236
step: 910, loss: 0.045163556933403015
step: 920, loss: 0.04399922490119934
step: 930, loss: 0.04261026158928871
step: 940, loss: 0.06613481789827347
step: 950, loss: 0.0845068171620369
step: 960, loss: 0.0341365672647953
step: 970, loss: 0.03068719618022442
epoch 17: dev_f1=0.9321642824180896, f1=0.9259770114942528, best_f1=0.9320388349514563
step: 0, loss: 0.10151815414428711
step: 10, loss: 0.08405861258506775
step: 20, loss: 0.015089498832821846
step: 30, loss: 0.0001356769644189626
step: 40, loss: 0.08058737218379974
step: 50, loss: 0.08242979645729065
step: 60, loss: 0.09021127223968506
step: 70, loss: 0.10614176839590073
step: 80, loss: 0.04119568318128586
step: 90, loss: 0.14043620228767395
step: 100, loss: 0.1008184403181076
step: 110, loss: 0.04475666582584381
step: 120, loss: 0.05390865355730057
step: 130, loss: 0.0762275829911232
step: 140, loss: 0.09427937865257263
step: 150, loss: 0.004769657272845507
step: 160, loss: 0.060947008430957794
step: 170, loss: 0.05215271934866905
step: 180, loss: 2.376660813752096e-05
step: 190, loss: 0.02897661179304123
step: 200, loss: 0.027029773220419884
step: 210, loss: 0.05920872092247009
step: 220, loss: 0.0022451526019722223
step: 230, loss: 0.038949526846408844
step: 240, loss: 0.03801281005144119
step: 250, loss: 0.01709624007344246
step: 260, loss: 0.08045271039009094
step: 270, loss: 0.029763879254460335
step: 280, loss: 0.05026865005493164
step: 290, loss: 0.056344013661146164
step: 300, loss: 0.10053987056016922
step: 310, loss: 0.037646908313035965
step: 320, loss: 0.028125088661909103
step: 330, loss: 0.016773806884884834
step: 340, loss: 0.013855349272489548
step: 350, loss: 8.75437672220869e-06
step: 360, loss: 0.0008088007452897727
step: 370, loss: 0.030961619690060616
step: 380, loss: 0.02811606600880623
step: 390, loss: 0.08042575418949127
step: 400, loss: 0.03070867992937565
step: 410, loss: 0.033598531037569046
step: 420, loss: 0.10921590775251389
step: 430, loss: 0.05831388384103775
step: 440, loss: 0.09786837548017502
step: 450, loss: 0.1387212872505188
step: 460, loss: 0.047950729727745056
step: 470, loss: 0.07080386579036713
step: 480, loss: 0.04441940039396286
step: 490, loss: 0.03649117052555084
step: 500, loss: 0.05742540955543518
step: 510, loss: 0.07269781827926636
step: 520, loss: 0.055052194744348526
step: 530, loss: 0.013232831843197346
step: 540, loss: 0.17678681015968323
step: 550, loss: 0.06879915297031403
step: 560, loss: 0.0758814662694931
step: 570, loss: 0.02061699517071247
step: 580, loss: 0.12264387309551239
step: 590, loss: 0.05505170673131943
step: 600, loss: 0.005056745372712612
step: 610, loss: 0.025027208030223846
step: 620, loss: 0.06494791805744171
step: 630, loss: 0.03156685084104538
step: 640, loss: 0.04292348399758339
step: 650, loss: 0.09275227785110474
step: 660, loss: 0.024176379665732384
step: 670, loss: 0.021695075556635857
step: 680, loss: 0.037702783942222595
step: 690, loss: 0.024213774129748344
step: 700, loss: 0.048495449125766754
step: 710, loss: 0.06652648746967316
step: 720, loss: 0.03626028820872307
step: 730, loss: 0.08342717587947845
step: 740, loss: 0.012513130903244019
step: 750, loss: 0.09381309151649475
step: 760, loss: 0.05740323290228844
step: 770, loss: 0.04171029478311539
step: 780, loss: 0.09456097334623337
step: 790, loss: 0.03630763664841652
step: 800, loss: 0.08864108473062515
step: 810, loss: 0.048375047743320465
step: 820, loss: 0.058542996644973755
step: 830, loss: 0.029148584231734276
step: 840, loss: 0.08267153799533844
step: 850, loss: 0.13440220057964325
step: 860, loss: 0.03192947804927826
step: 870, loss: 0.0411209836602211
step: 880, loss: 0.046560321003198624
step: 890, loss: 0.05324333906173706
step: 900, loss: 0.06691829115152359
step: 910, loss: 0.03911307081580162
step: 920, loss: 0.04520891606807709
step: 930, loss: 0.017037102952599525
step: 940, loss: 0.0443841852247715
step: 950, loss: 0.05551702529191971
step: 960, loss: 0.04429621994495392
step: 970, loss: 0.05873951315879822
epoch 18: dev_f1=0.9306008383791335, f1=0.9270106927010693, best_f1=0.9320388349514563
step: 0, loss: 0.04789159074425697
step: 10, loss: 2.9768203603453003e-05
step: 20, loss: 0.04512204974889755
step: 30, loss: 0.11072102189064026
step: 40, loss: 0.023121951147913933
step: 50, loss: 0.04729367047548294
step: 60, loss: 0.04056701436638832
step: 70, loss: 0.021541085094213486
step: 80, loss: 1.7052236216841266e-05
step: 90, loss: 0.02492016740143299
step: 100, loss: 0.012129643000662327
step: 110, loss: 0.004988419357687235
step: 120, loss: 0.05053558573126793
step: 130, loss: 9.008913912111893e-05
step: 140, loss: 0.06834866851568222
step: 150, loss: 0.06439286470413208
step: 160, loss: 0.02544224075973034
step: 170, loss: 0.029417267069220543
step: 180, loss: 0.07223492860794067
step: 190, loss: 0.12237679213285446
step: 200, loss: 0.10301624238491058
step: 210, loss: 0.026335496455430984
step: 220, loss: 0.09611663967370987
step: 230, loss: 0.009477466344833374
step: 240, loss: 0.0847979187965393
step: 250, loss: 0.11394531279802322
step: 260, loss: 0.02322862297296524
step: 270, loss: 0.02938452735543251
step: 280, loss: 0.13933806121349335
step: 290, loss: 0.01628817245364189
step: 300, loss: 0.02045528031885624
step: 310, loss: 0.1718801110982895
step: 320, loss: 0.09495005011558533
step: 330, loss: 0.04358081519603729
step: 340, loss: 0.03374805301427841
step: 350, loss: 0.060028642416000366
step: 360, loss: 0.0498494878411293
step: 370, loss: 0.025803053751587868
step: 380, loss: 0.08811507374048233
step: 390, loss: 0.04563461244106293
step: 400, loss: 0.016805708408355713
step: 410, loss: 0.16287335753440857
step: 420, loss: 0.04567980393767357
step: 430, loss: 0.010356110520660877
step: 440, loss: 0.010743732564151287
step: 450, loss: 0.012237630784511566
step: 460, loss: 0.07296425104141235
step: 470, loss: 0.07349655777215958
step: 480, loss: 0.053292691707611084
step: 490, loss: 0.014922489412128925
step: 500, loss: 0.0003686310665216297
step: 510, loss: 0.01781274378299713
step: 520, loss: 0.085415780544281
step: 530, loss: 0.03878229483962059
step: 540, loss: 6.515881250379607e-05
step: 550, loss: 0.04513168707489967
step: 560, loss: 0.10249603539705276
step: 570, loss: 0.028760898858308792
step: 580, loss: 1.1615178664214909e-05
step: 590, loss: 0.00718420185148716
step: 600, loss: 0.12611839175224304
step: 610, loss: 0.06770116835832596
step: 620, loss: 0.00035051623126491904
step: 630, loss: 5.7202501920983195e-05
step: 640, loss: 0.08267034590244293
step: 650, loss: 0.01648290455341339
step: 660, loss: 0.01431212667375803
step: 670, loss: 0.042872704565525055
step: 680, loss: 0.05053152143955231
step: 690, loss: 0.12508074939250946
step: 700, loss: 0.00033701470238156617
step: 710, loss: 0.04789137467741966
step: 720, loss: 0.022380834445357323
step: 730, loss: 0.09184034168720245
step: 740, loss: 0.00017371152353007346
step: 750, loss: 0.04355292022228241
step: 760, loss: 0.028978170827031136
step: 770, loss: 0.04192009195685387
step: 780, loss: 0.051669735461473465
step: 790, loss: 0.015069239772856236
step: 800, loss: 0.04765450209379196
step: 810, loss: 0.06488814204931259
step: 820, loss: 0.031727686524391174
step: 830, loss: 0.06797313690185547
step: 840, loss: 0.16126438975334167
step: 850, loss: 0.02618841454386711
step: 860, loss: 0.14805179834365845
step: 870, loss: 1.94951135199517e-05
step: 880, loss: 0.09279880672693253
step: 890, loss: 0.01744062267243862
step: 900, loss: 0.01074510533362627
step: 910, loss: 0.039784397929906845
step: 920, loss: 0.02251116745173931
step: 930, loss: 0.09057928621768951
step: 940, loss: 0.056319721043109894
step: 950, loss: 0.03602459281682968
step: 960, loss: 0.0023067581932991743
step: 970, loss: 0.013985433615744114
epoch 19: dev_f1=0.928772258669166, f1=0.9253034547152195, best_f1=0.9320388349514563
step: 0, loss: 0.04246394336223602
step: 10, loss: 0.026562560349702835
step: 20, loss: 0.023119281977415085
step: 30, loss: 0.052716754376888275
step: 40, loss: 0.007671266328543425
step: 50, loss: 0.050258226692676544
step: 60, loss: 0.08315887302160263
step: 70, loss: 0.05386051908135414
step: 80, loss: 0.037355825304985046
step: 90, loss: 0.060732677578926086
step: 100, loss: 0.029174258932471275
step: 110, loss: 0.030099235475063324
step: 120, loss: 0.13141998648643494
step: 130, loss: 0.04716494679450989
step: 140, loss: 0.02670130878686905
step: 150, loss: 0.0617784783244133
step: 160, loss: 0.103444904088974
step: 170, loss: 0.05603902414441109
step: 180, loss: 0.014920767396688461
step: 190, loss: 0.01923966407775879
step: 200, loss: 0.08442232012748718
step: 210, loss: 0.017715608701109886
step: 220, loss: 0.06131669133901596
step: 230, loss: 0.1346937119960785
step: 240, loss: 0.0181051604449749
step: 250, loss: 0.10574926435947418
step: 260, loss: 0.0012234715977683663
step: 270, loss: 0.05716196075081825
step: 280, loss: 0.05986442044377327
step: 290, loss: 0.041353773325681686
step: 300, loss: 0.019736772403120995
step: 310, loss: 0.027279037982225418
step: 320, loss: 0.02811296284198761
step: 330, loss: 0.029203342273831367
step: 340, loss: 0.03125515207648277
step: 350, loss: 0.02458835206925869
step: 360, loss: 0.11379587650299072
step: 370, loss: 0.030436597764492035
step: 380, loss: 0.023582464084029198
step: 390, loss: 0.007138201035559177
step: 400, loss: 0.019644806161522865
step: 410, loss: 0.04011910408735275
step: 420, loss: 0.0004552127211354673
step: 430, loss: 0.11182481050491333
step: 440, loss: 0.030968476086854935
step: 450, loss: 0.12246062606573105
step: 460, loss: 0.028929632157087326
step: 470, loss: 0.04403079301118851
step: 480, loss: 0.08541792631149292
step: 490, loss: 0.05963077396154404
step: 500, loss: 0.04954800754785538
step: 510, loss: 0.0931427925825119
step: 520, loss: 0.03874275088310242
step: 530, loss: 0.03532210364937782
step: 540, loss: 0.0255269855260849
step: 550, loss: 0.022366419434547424
step: 560, loss: 0.029380733147263527
step: 570, loss: 0.04236382618546486
step: 580, loss: 0.028749540448188782
step: 590, loss: 0.04123511537909508
step: 600, loss: 0.05981164053082466
step: 610, loss: 0.05691257119178772
step: 620, loss: 0.04381164535880089
step: 630, loss: 0.02335539646446705
step: 640, loss: 0.07460153847932816
step: 650, loss: 0.1037696897983551
step: 660, loss: 5.227035580901429e-05
step: 670, loss: 0.011489000171422958
step: 680, loss: 0.03977783024311066
step: 690, loss: 0.0006983939674682915
step: 700, loss: 0.029373899102211
step: 710, loss: 0.09245077520608902
step: 720, loss: 0.11896096915006638
step: 730, loss: 6.43613311694935e-05
step: 740, loss: 0.20975376665592194
step: 750, loss: 0.023164082318544388
step: 760, loss: 0.016333669424057007
step: 770, loss: 0.0496215894818306
step: 780, loss: 0.08530358970165253
step: 790, loss: 1.2292815881664865e-05
step: 800, loss: 0.05157719925045967
step: 810, loss: 0.019744083285331726
step: 820, loss: 0.05705016106367111
step: 830, loss: 0.02689443528652191
step: 840, loss: 0.029124591499567032
step: 850, loss: 0.010232989676296711
step: 860, loss: 0.10822519659996033
step: 870, loss: 0.035758357495069504
step: 880, loss: 0.1881965845823288
step: 890, loss: 0.01867830567061901
step: 900, loss: 0.03740019351243973
step: 910, loss: 0.050590209662914276
step: 920, loss: 0.03892749920487404
step: 930, loss: 0.020651796832680702
step: 940, loss: 0.06252860277891159
step: 950, loss: 0.04356107488274574
step: 960, loss: 0.0001555377384647727
step: 970, loss: 0.00033001689007505774
epoch 20: dev_f1=0.9285714285714286, f1=0.9247311827956989, best_f1=0.9320388349514563
