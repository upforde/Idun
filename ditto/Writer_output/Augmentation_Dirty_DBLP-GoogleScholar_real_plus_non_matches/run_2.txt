cuda
Device: cuda
step: 0, loss: 0.7321963310241699
step: 10, loss: 0.4853239059448242
step: 20, loss: 0.3751029670238495
step: 30, loss: 0.4324483573436737
step: 40, loss: 0.15025478601455688
step: 50, loss: 0.23638689517974854
step: 60, loss: 0.21150702238082886
step: 70, loss: 0.20311209559440613
step: 80, loss: 0.4829811155796051
step: 90, loss: 0.4363706409931183
step: 100, loss: 0.24760708212852478
step: 110, loss: 0.18677981197834015
step: 120, loss: 0.13668368756771088
step: 130, loss: 0.18523120880126953
step: 140, loss: 0.3046537935733795
step: 150, loss: 0.21425916254520416
step: 160, loss: 0.27154213190078735
step: 170, loss: 0.19041889905929565
step: 180, loss: 0.17914167046546936
step: 190, loss: 0.13446468114852905
step: 200, loss: 0.08152403682470322
step: 210, loss: 0.14322920143604279
step: 220, loss: 0.06965229660272598
step: 230, loss: 0.26832810044288635
step: 240, loss: 0.23894043266773224
step: 250, loss: 0.1319335699081421
step: 260, loss: 0.13578744232654572
step: 270, loss: 0.07679271697998047
step: 280, loss: 0.060236893594264984
step: 290, loss: 0.07579831033945084
step: 300, loss: 0.10407521575689316
step: 310, loss: 0.1051468551158905
step: 320, loss: 0.2511581778526306
step: 330, loss: 0.30740275979042053
step: 340, loss: 0.12108030915260315
step: 350, loss: 0.08656461536884308
step: 360, loss: 0.1523061990737915
step: 370, loss: 0.21815866231918335
step: 380, loss: 0.2142641842365265
step: 390, loss: 0.1655752807855606
step: 400, loss: 0.04057110846042633
step: 410, loss: 0.17292213439941406
step: 420, loss: 0.07092267274856567
step: 430, loss: 0.25589969754219055
step: 440, loss: 0.19763381779193878
step: 450, loss: 0.21032674610614777
step: 460, loss: 0.26393383741378784
step: 470, loss: 0.2599349021911621
step: 480, loss: 0.15694081783294678
step: 490, loss: 0.15814955532550812
step: 500, loss: 0.34146562218666077
step: 510, loss: 0.1239854097366333
step: 520, loss: 0.17118622362613678
step: 530, loss: 0.16701963543891907
step: 540, loss: 0.05717208608984947
step: 550, loss: 0.2204245626926422
step: 560, loss: 0.21105962991714478
step: 570, loss: 0.11889546364545822
step: 580, loss: 0.11617765575647354
step: 590, loss: 0.17070762813091278
step: 600, loss: 0.24958071112632751
step: 610, loss: 0.13621316850185394
step: 620, loss: 0.14772772789001465
step: 630, loss: 0.13876578211784363
step: 640, loss: 0.15309366583824158
step: 650, loss: 0.07189943641424179
step: 660, loss: 0.20383521914482117
step: 670, loss: 0.15668775141239166
step: 680, loss: 0.11539095640182495
step: 690, loss: 0.2709050476551056
step: 700, loss: 0.18296483159065247
step: 710, loss: 0.1405656933784485
step: 720, loss: 0.05890848487615585
step: 730, loss: 0.25971120595932007
step: 740, loss: 0.08512416481971741
step: 750, loss: 0.1650538146495819
step: 760, loss: 0.1762738972902298
step: 770, loss: 0.04148077592253685
step: 780, loss: 0.22223728895187378
step: 790, loss: 0.20293599367141724
step: 800, loss: 0.10756919533014297
step: 810, loss: 0.20276768505573273
step: 820, loss: 0.18192723393440247
step: 830, loss: 0.0562870092689991
step: 840, loss: 0.05080379545688629
step: 850, loss: 0.08893665671348572
step: 860, loss: 0.10812067240476608
step: 870, loss: 0.14490564167499542
step: 880, loss: 0.12357687205076218
step: 890, loss: 0.1996178925037384
step: 900, loss: 0.1509450078010559
step: 910, loss: 0.14108917117118835
step: 920, loss: 0.06782638281583786
step: 930, loss: 0.24281427264213562
step: 940, loss: 0.15824247896671295
step: 950, loss: 0.23049712181091309
step: 960, loss: 0.17945200204849243
step: 970, loss: 0.05966759845614433
epoch 1: dev_f1=0.9296173830892772, f1=0.9184060721062618, best_f1=0.9184060721062618
step: 0, loss: 0.11135818809270859
step: 10, loss: 0.09560421854257584
step: 20, loss: 0.07912509143352509
step: 30, loss: 0.11879272013902664
step: 40, loss: 0.11430465430021286
step: 50, loss: 0.08114200085401535
step: 60, loss: 0.13181547820568085
step: 70, loss: 0.4258127212524414
step: 80, loss: 0.19772012531757355
step: 90, loss: 0.2553439140319824
step: 100, loss: 0.15063798427581787
step: 110, loss: 0.08136820793151855
step: 120, loss: 0.12269892543554306
step: 130, loss: 0.1524764895439148
step: 140, loss: 0.2537120282649994
step: 150, loss: 0.09521500766277313
step: 160, loss: 0.03175666928291321
step: 170, loss: 0.0839555561542511
step: 180, loss: 0.12166701257228851
step: 190, loss: 0.0829489603638649
step: 200, loss: 0.18208622932434082
step: 210, loss: 0.09620168060064316
step: 220, loss: 0.1568240225315094
step: 230, loss: 0.19398485124111176
step: 240, loss: 0.20615744590759277
step: 250, loss: 0.09824539721012115
step: 260, loss: 0.15215104818344116
step: 270, loss: 0.1042269915342331
step: 280, loss: 0.17682836949825287
step: 290, loss: 0.1492885798215866
step: 300, loss: 0.15929719805717468
step: 310, loss: 0.12131153047084808
step: 320, loss: 0.1412224918603897
step: 330, loss: 0.16055575013160706
step: 340, loss: 0.041266266256570816
step: 350, loss: 0.22850339114665985
step: 360, loss: 0.05616580322384834
step: 370, loss: 0.20490917563438416
step: 380, loss: 0.08728023618459702
step: 390, loss: 0.1278112679719925
step: 400, loss: 0.0881630927324295
step: 410, loss: 0.17829318344593048
step: 420, loss: 0.22267358005046844
step: 430, loss: 0.11797505617141724
step: 440, loss: 0.23004436492919922
step: 450, loss: 0.13225090503692627
step: 460, loss: 0.1716758906841278
step: 470, loss: 0.12324364483356476
step: 480, loss: 0.0907728374004364
step: 490, loss: 0.17899663746356964
step: 500, loss: 0.1736101359128952
step: 510, loss: 0.09195423871278763
step: 520, loss: 0.1450018435716629
step: 530, loss: 0.07303688675165176
step: 540, loss: 0.05217273533344269
step: 550, loss: 0.08490210026502609
step: 560, loss: 0.12323714792728424
step: 570, loss: 0.13088655471801758
step: 580, loss: 0.19649890065193176
step: 590, loss: 0.1920674592256546
step: 600, loss: 0.2768907845020294
step: 610, loss: 0.1362372189760208
step: 620, loss: 0.17069150507450104
step: 630, loss: 0.054280493408441544
step: 640, loss: 0.08368939906358719
step: 650, loss: 0.19935999810695648
step: 660, loss: 0.10670490562915802
step: 670, loss: 0.06678854674100876
step: 680, loss: 0.41010454297065735
step: 690, loss: 0.09676104038953781
step: 700, loss: 0.08911662548780441
step: 710, loss: 0.0767986848950386
step: 720, loss: 0.27539026737213135
step: 730, loss: 0.15939635038375854
step: 740, loss: 0.17636319994926453
step: 750, loss: 0.18340545892715454
step: 760, loss: 0.17427368462085724
step: 770, loss: 0.1807280331850052
step: 780, loss: 0.08788589388132095
step: 790, loss: 0.03907884284853935
step: 800, loss: 0.1296999156475067
step: 810, loss: 0.15557929873466492
step: 820, loss: 0.16963210701942444
step: 830, loss: 0.11352105438709259
step: 840, loss: 0.0833287164568901
step: 850, loss: 0.291775643825531
step: 860, loss: 0.22397886216640472
step: 870, loss: 0.16755640506744385
step: 880, loss: 0.18213742971420288
step: 890, loss: 0.195987731218338
step: 900, loss: 0.07309797406196594
step: 910, loss: 0.2767767608165741
step: 920, loss: 0.2081754505634308
step: 930, loss: 0.08865398168563843
step: 940, loss: 0.15648095309734344
step: 950, loss: 0.14007121324539185
step: 960, loss: 0.07084968686103821
step: 970, loss: 0.13867023587226868
epoch 2: dev_f1=0.9325267566309912, f1=0.9339534883720929, best_f1=0.9339534883720929
step: 0, loss: 0.188120037317276
step: 10, loss: 0.13725049793720245
step: 20, loss: 0.17742528021335602
step: 30, loss: 0.09500608593225479
step: 40, loss: 0.07064373791217804
step: 50, loss: 0.2874177396297455
step: 60, loss: 0.0659332275390625
step: 70, loss: 0.18860070407390594
step: 80, loss: 0.19415752589702606
step: 90, loss: 0.08456236124038696
step: 100, loss: 0.060691893100738525
step: 110, loss: 0.02835158258676529
step: 120, loss: 0.2584691643714905
step: 130, loss: 0.19625799357891083
step: 140, loss: 0.018067652359604836
step: 150, loss: 0.15919359028339386
step: 160, loss: 0.25025475025177
step: 170, loss: 0.014618667773902416
step: 180, loss: 0.060953911393880844
step: 190, loss: 0.16369548439979553
step: 200, loss: 0.06986925005912781
step: 210, loss: 0.0945092961192131
step: 220, loss: 0.10941151529550552
step: 230, loss: 0.07724134624004364
step: 240, loss: 0.12204785645008087
step: 250, loss: 0.15103045105934143
step: 260, loss: 0.2401629388332367
step: 270, loss: 0.10484174638986588
step: 280, loss: 0.11838729679584503
step: 290, loss: 0.09538491815328598
step: 300, loss: 0.16708791255950928
step: 310, loss: 0.08159460872411728
step: 320, loss: 0.15103526413440704
step: 330, loss: 0.06351616233587265
step: 340, loss: 0.10082222521305084
step: 350, loss: 0.3332635760307312
step: 360, loss: 0.09248168021440506
step: 370, loss: 0.22295859456062317
step: 380, loss: 0.08008785545825958
step: 390, loss: 0.15987133979797363
step: 400, loss: 0.06586401164531708
step: 410, loss: 0.18777583539485931
step: 420, loss: 0.1679133176803589
step: 430, loss: 0.08266423642635345
step: 440, loss: 0.10164067894220352
step: 450, loss: 0.13791266083717346
step: 460, loss: 0.06651399284601212
step: 470, loss: 0.06935373693704605
step: 480, loss: 0.11326103657484055
step: 490, loss: 0.058309104293584824
step: 500, loss: 0.03463141992688179
step: 510, loss: 0.05404306948184967
step: 520, loss: 0.114768847823143
step: 530, loss: 0.1313747763633728
step: 540, loss: 0.09713640809059143
step: 550, loss: 0.344491183757782
step: 560, loss: 0.07695627212524414
step: 570, loss: 0.04396449774503708
step: 580, loss: 0.022666051983833313
step: 590, loss: 0.15000273287296295
step: 600, loss: 0.04472038522362709
step: 610, loss: 0.1366816908121109
step: 620, loss: 0.06157670170068741
step: 630, loss: 0.03162508085370064
step: 640, loss: 0.09143094718456268
step: 650, loss: 0.09780976176261902
step: 660, loss: 0.09932082891464233
step: 670, loss: 0.08601684123277664
step: 680, loss: 0.17195232212543488
step: 690, loss: 0.3256932497024536
step: 700, loss: 0.0807868018746376
step: 710, loss: 0.06289694458246231
step: 720, loss: 0.17271451652050018
step: 730, loss: 0.059155307710170746
step: 740, loss: 0.1449175775051117
step: 750, loss: 0.18063603341579437
step: 760, loss: 0.13720811903476715
step: 770, loss: 0.08272842317819595
step: 780, loss: 0.18813450634479523
step: 790, loss: 0.056353721767663956
step: 800, loss: 0.20029601454734802
step: 810, loss: 0.06304969638586044
step: 820, loss: 0.2724030315876007
step: 830, loss: 0.049900930374860764
step: 840, loss: 0.13630102574825287
step: 850, loss: 0.12099315226078033
step: 860, loss: 0.2038612961769104
step: 870, loss: 0.2353438138961792
step: 880, loss: 0.11796324700117111
step: 890, loss: 0.10954517871141434
step: 900, loss: 0.08138457685709
step: 910, loss: 0.12835022807121277
step: 920, loss: 0.09380237013101578
step: 930, loss: 0.047351375222206116
step: 940, loss: 0.3178408741950989
step: 950, loss: 0.13187983632087708
step: 960, loss: 0.17135046422481537
step: 970, loss: 0.09537345916032791
epoch 3: dev_f1=0.9252252252252252, f1=0.9240449438202246, best_f1=0.9339534883720929
step: 0, loss: 0.09533809870481491
step: 10, loss: 0.10901911556720734
step: 20, loss: 0.1913682222366333
step: 30, loss: 0.10404850542545319
step: 40, loss: 0.12108059972524643
step: 50, loss: 0.0831889808177948
step: 60, loss: 0.01646980457007885
step: 70, loss: 0.026392972096800804
step: 80, loss: 0.1413646638393402
step: 90, loss: 0.1019628643989563
step: 100, loss: 0.10547854751348495
step: 110, loss: 0.15696276724338531
step: 120, loss: 0.23482373356819153
step: 130, loss: 0.08273543417453766
step: 140, loss: 0.17241080105304718
step: 150, loss: 0.04860658198595047
step: 160, loss: 0.09629439562559128
step: 170, loss: 0.12181399762630463
step: 180, loss: 0.13837911188602448
step: 190, loss: 0.07241122424602509
step: 200, loss: 0.08280042558908463
step: 210, loss: 0.08182936161756516
step: 220, loss: 0.07413206994533539
step: 230, loss: 0.14390012621879578
step: 240, loss: 0.12174424529075623
step: 250, loss: 0.118196502327919
step: 260, loss: 0.15814195573329926
step: 270, loss: 0.09189044684171677
step: 280, loss: 0.07105307281017303
step: 290, loss: 0.049451347440481186
step: 300, loss: 0.12166216969490051
step: 310, loss: 0.09654102474451065
step: 320, loss: 0.02789252996444702
step: 330, loss: 0.15083284676074982
step: 340, loss: 0.11897727102041245
step: 350, loss: 0.10487082600593567
step: 360, loss: 0.1825353354215622
step: 370, loss: 0.196828231215477
step: 380, loss: 0.17479601502418518
step: 390, loss: 0.15204039216041565
step: 400, loss: 0.0386599563062191
step: 410, loss: 0.1398700773715973
step: 420, loss: 0.1507970094680786
step: 430, loss: 0.13510802388191223
step: 440, loss: 0.16562147438526154
step: 450, loss: 0.24411922693252563
step: 460, loss: 0.07368762791156769
step: 470, loss: 0.11226001381874084
step: 480, loss: 0.021349851042032242
step: 490, loss: 0.04094658046960831
step: 500, loss: 0.03220890089869499
step: 510, loss: 0.0825258269906044
step: 520, loss: 0.052531540393829346
step: 530, loss: 0.020966991782188416
step: 540, loss: 0.12121356278657913
step: 550, loss: 0.10795684158802032
step: 560, loss: 0.15931686758995056
step: 570, loss: 0.12318800389766693
step: 580, loss: 0.16719257831573486
step: 590, loss: 0.21682575345039368
step: 600, loss: 0.11817331612110138
step: 610, loss: 0.10055885463953018
step: 620, loss: 0.07010049372911453
step: 630, loss: 0.07672286778688431
step: 640, loss: 0.15321917831897736
step: 650, loss: 0.08671877533197403
step: 660, loss: 0.04242466017603874
step: 670, loss: 0.13255298137664795
step: 680, loss: 0.06561371684074402
step: 690, loss: 0.12620624899864197
step: 700, loss: 0.17360594868659973
step: 710, loss: 0.012897493317723274
step: 720, loss: 0.18676918745040894
step: 730, loss: 0.039867013692855835
step: 740, loss: 0.1886390596628189
step: 750, loss: 0.09349009394645691
step: 760, loss: 0.1395452618598938
step: 770, loss: 0.10638180375099182
step: 780, loss: 0.10279957950115204
step: 790, loss: 0.07334266602993011
step: 800, loss: 0.18137778341770172
step: 810, loss: 0.10326236486434937
step: 820, loss: 0.1780390441417694
step: 830, loss: 0.16625967621803284
step: 840, loss: 0.08536149561405182
step: 850, loss: 0.142714723944664
step: 860, loss: 0.1863546520471573
step: 870, loss: 0.243202805519104
step: 880, loss: 0.05327671021223068
step: 890, loss: 0.11175356805324554
step: 900, loss: 0.21615177392959595
step: 910, loss: 0.06841424107551575
step: 920, loss: 0.13240128755569458
step: 930, loss: 0.06872835755348206
step: 940, loss: 0.09850811213254929
step: 950, loss: 0.06620380282402039
step: 960, loss: 0.11254610121250153
step: 970, loss: 0.15394262969493866
epoch 4: dev_f1=0.9337626494940202, f1=0.9303826648224988, best_f1=0.9303826648224988
step: 0, loss: 0.1304377317428589
step: 10, loss: 0.06849663704633713
step: 20, loss: 0.14056740701198578
step: 30, loss: 0.05876447632908821
step: 40, loss: 0.09042254090309143
step: 50, loss: 0.14312611520290375
step: 60, loss: 0.069938063621521
step: 70, loss: 0.11175176501274109
step: 80, loss: 0.08183678984642029
step: 90, loss: 0.08847492188215256
step: 100, loss: 0.06375356018543243
step: 110, loss: 0.12558642029762268
step: 120, loss: 0.054558299481868744
step: 130, loss: 0.17628315091133118
step: 140, loss: 0.04550470784306526
step: 150, loss: 0.011518198065459728
step: 160, loss: 0.13417862355709076
step: 170, loss: 0.09159640222787857
step: 180, loss: 0.039267122745513916
step: 190, loss: 0.07772258669137955
step: 200, loss: 0.0794728547334671
step: 210, loss: 0.08805032819509506
step: 220, loss: 0.15140335261821747
step: 230, loss: 0.16256211698055267
step: 240, loss: 0.11280713230371475
step: 250, loss: 0.21092025935649872
step: 260, loss: 0.01829293556511402
step: 270, loss: 0.08221662044525146
step: 280, loss: 0.08867557346820831
step: 290, loss: 0.1448899507522583
step: 300, loss: 0.2070574015378952
step: 310, loss: 0.039559490978717804
step: 320, loss: 0.12540636956691742
step: 330, loss: 0.11980490386486053
step: 340, loss: 0.06097886338829994
step: 350, loss: 0.08673103898763657
step: 360, loss: 0.10877935588359833
step: 370, loss: 0.01156969740986824
step: 380, loss: 0.11403100937604904
step: 390, loss: 0.059388529509305954
step: 400, loss: 0.12438838183879852
step: 410, loss: 0.22568757832050323
step: 420, loss: 0.23733189702033997
step: 430, loss: 0.001708110561594367
step: 440, loss: 0.15329620242118835
step: 450, loss: 0.08349961787462234
step: 460, loss: 0.0019220283720642328
step: 470, loss: 0.05860546976327896
step: 480, loss: 0.2315177619457245
step: 490, loss: 0.08307460695505142
step: 500, loss: 0.16669481992721558
step: 510, loss: 0.06141804903745651
step: 520, loss: 0.1551654040813446
step: 530, loss: 0.07018101215362549
step: 540, loss: 0.15729419887065887
step: 550, loss: 0.07938999682664871
step: 560, loss: 0.10581603646278381
step: 570, loss: 0.05448346212506294
step: 580, loss: 0.017072489485144615
step: 590, loss: 0.13683710992336273
step: 600, loss: 0.19890132546424866
step: 610, loss: 0.025756606832146645
step: 620, loss: 0.08169130235910416
step: 630, loss: 0.0871201828122139
step: 640, loss: 0.1226995438337326
step: 650, loss: 0.07334547489881516
step: 660, loss: 0.04628507420420647
step: 670, loss: 0.15246139466762543
step: 680, loss: 0.08918965607881546
step: 690, loss: 0.10879581421613693
step: 700, loss: 0.10406651347875595
step: 710, loss: 0.09189407527446747
step: 720, loss: 0.12034166604280472
step: 730, loss: 0.2545441687107086
step: 740, loss: 0.11701565235853195
step: 750, loss: 0.287171334028244
step: 760, loss: 0.07519807666540146
step: 770, loss: 0.04761833697557449
step: 780, loss: 0.08050800859928131
step: 790, loss: 0.006168601103127003
step: 800, loss: 0.02761000767350197
step: 810, loss: 0.22929345071315765
step: 820, loss: 0.13561980426311493
step: 830, loss: 0.03802136704325676
step: 840, loss: 0.1451883763074875
step: 850, loss: 0.04525590315461159
step: 860, loss: 0.12534892559051514
step: 870, loss: 0.0391712486743927
step: 880, loss: 0.05354777351021767
step: 890, loss: 0.10284743458032608
step: 900, loss: 0.09148281067609787
step: 910, loss: 0.04136374220252037
step: 920, loss: 0.0811179131269455
step: 930, loss: 0.14893117547035217
step: 940, loss: 0.16745133697986603
step: 950, loss: 0.10854560136795044
step: 960, loss: 0.1093747690320015
step: 970, loss: 0.08891960978507996
epoch 5: dev_f1=0.9289967934035731, f1=0.9274563820018366, best_f1=0.9303826648224988
step: 0, loss: 0.1105409562587738
step: 10, loss: 0.08101686090230942
step: 20, loss: 0.12084643542766571
step: 30, loss: 0.12048128992319107
step: 40, loss: 0.09356658160686493
step: 50, loss: 0.05251419171690941
step: 60, loss: 0.048731040209531784
step: 70, loss: 0.06494882702827454
step: 80, loss: 0.1595582216978073
step: 90, loss: 0.10169792175292969
step: 100, loss: 0.16233129799365997
step: 110, loss: 0.0961792916059494
step: 120, loss: 0.15651452541351318
step: 130, loss: 0.016652902588248253
step: 140, loss: 0.06443969905376434
step: 150, loss: 0.10454507917165756
step: 160, loss: 0.049196772277355194
step: 170, loss: 0.04837360978126526
step: 180, loss: 0.13805139064788818
step: 190, loss: 0.12712393701076508
step: 200, loss: 0.0857800617814064
step: 210, loss: 0.12702924013137817
step: 220, loss: 0.10994052141904831
step: 230, loss: 0.04512829706072807
step: 240, loss: 0.16479609906673431
step: 250, loss: 0.09222374111413956
step: 260, loss: 0.0825059562921524
step: 270, loss: 0.15593798458576202
step: 280, loss: 0.06178434193134308
step: 290, loss: 0.028615249320864677
step: 300, loss: 0.1972755342721939
step: 310, loss: 0.0922943651676178
step: 320, loss: 0.015331743285059929
step: 330, loss: 0.03642379865050316
step: 340, loss: 0.14568930864334106
step: 350, loss: 0.08730166405439377
step: 360, loss: 0.04568178579211235
step: 370, loss: 0.10396307706832886
step: 380, loss: 0.09820964187383652
step: 390, loss: 0.1288098245859146
step: 400, loss: 0.022846797481179237
step: 410, loss: 0.06852582842111588
step: 420, loss: 0.08042341470718384
step: 430, loss: 0.057194918394088745
step: 440, loss: 0.10047465562820435
step: 450, loss: 0.09662555158138275
step: 460, loss: 0.03699050471186638
step: 470, loss: 0.06945125758647919
step: 480, loss: 0.06573090702295303
step: 490, loss: 0.017807159572839737
step: 500, loss: 0.031066764146089554
step: 510, loss: 0.1404258906841278
step: 520, loss: 0.15067686140537262
step: 530, loss: 0.1395188868045807
step: 540, loss: 0.10992926359176636
step: 550, loss: 0.1633441150188446
step: 560, loss: 0.053966064006090164
step: 570, loss: 0.11381275206804276
step: 580, loss: 0.0805361270904541
step: 590, loss: 0.10162883251905441
step: 600, loss: 0.022823359817266464
step: 610, loss: 0.08409987390041351
step: 620, loss: 0.031775012612342834
step: 630, loss: 0.24515309929847717
step: 640, loss: 0.054524652659893036
step: 650, loss: 0.08098400384187698
step: 660, loss: 0.032997503876686096
step: 670, loss: 0.04887549951672554
step: 680, loss: 0.18752653896808624
step: 690, loss: 0.09398330003023148
step: 700, loss: 0.05979745835065842
step: 710, loss: 0.10121488571166992
step: 720, loss: 0.13807551562786102
step: 730, loss: 0.08038449287414551
step: 740, loss: 0.11066795140504837
step: 750, loss: 0.03728106617927551
step: 760, loss: 0.023751234635710716
step: 770, loss: 0.04683844745159149
step: 780, loss: 0.09906119108200073
step: 790, loss: 0.060297079384326935
step: 800, loss: 0.0728440061211586
step: 810, loss: 0.1712784767150879
step: 820, loss: 0.07108398526906967
step: 830, loss: 0.10209303349256516
step: 840, loss: 0.09860809892416
step: 850, loss: 0.051212508231401443
step: 860, loss: 0.18161332607269287
step: 870, loss: 0.06921321898698807
step: 880, loss: 0.07388416677713394
step: 890, loss: 0.07295606285333633
step: 900, loss: 0.038843028247356415
step: 910, loss: 0.17918267846107483
step: 920, loss: 0.11541128903627396
step: 930, loss: 0.07694040238857269
step: 940, loss: 0.10212579369544983
step: 950, loss: 0.1036161258816719
step: 960, loss: 0.07601583749055862
step: 970, loss: 0.19693626463413239
epoch 6: dev_f1=0.9223616922361693, f1=0.9116149930587691, best_f1=0.9303826648224988
step: 0, loss: 0.1341337412595749
step: 10, loss: 0.06629569828510284
step: 20, loss: 0.017584003508090973
step: 30, loss: 0.18505820631980896
step: 40, loss: 0.0965675339102745
step: 50, loss: 0.08152251690626144
step: 60, loss: 0.037195637822151184
step: 70, loss: 0.10288892686367035
step: 80, loss: 0.07653889805078506
step: 90, loss: 0.062136560678482056
step: 100, loss: 0.02096387930214405
step: 110, loss: 0.1093757227063179
step: 120, loss: 0.043126679956912994
step: 130, loss: 0.06106111407279968
step: 140, loss: 0.07016502320766449
step: 150, loss: 0.11610545217990875
step: 160, loss: 0.03623265027999878
step: 170, loss: 0.05301835015416145
step: 180, loss: 0.07979359477758408
step: 190, loss: 0.14344044029712677
step: 200, loss: 0.19962480664253235
step: 210, loss: 0.13191916048526764
step: 220, loss: 0.04184665158390999
step: 230, loss: 0.06613121181726456
step: 240, loss: 0.05443911254405975
step: 250, loss: 0.024310916662216187
step: 260, loss: 0.07301651686429977
step: 270, loss: 0.07290421426296234
step: 280, loss: 0.08079878240823746
step: 290, loss: 0.08449530601501465
step: 300, loss: 0.035957012325525284
step: 310, loss: 0.015461322851479053
step: 320, loss: 0.04892021045088768
step: 330, loss: 0.024849995970726013
step: 340, loss: 0.026627589017152786
step: 350, loss: 0.07592868059873581
step: 360, loss: 0.0804615169763565
step: 370, loss: 0.12355086952447891
step: 380, loss: 0.12892594933509827
step: 390, loss: 0.016364339739084244
step: 400, loss: 0.0799974650144577
step: 410, loss: 0.11444101482629776
step: 420, loss: 0.05132167041301727
step: 430, loss: 0.0849718376994133
step: 440, loss: 0.22632676362991333
step: 450, loss: 0.14363892376422882
step: 460, loss: 0.11006614565849304
step: 470, loss: 0.07967815548181534
step: 480, loss: 0.15875324606895447
step: 490, loss: 0.048431139439344406
step: 500, loss: 0.07027897983789444
step: 510, loss: 0.08791156113147736
step: 520, loss: 0.09477023780345917
step: 530, loss: 0.11659165471792221
step: 540, loss: 0.07131258398294449
step: 550, loss: 0.11471569538116455
step: 560, loss: 0.13081061840057373
step: 570, loss: 0.049506038427352905
step: 580, loss: 0.10088350623846054
step: 590, loss: 0.053283754736185074
step: 600, loss: 0.028648104518651962
step: 610, loss: 0.017453715205192566
step: 620, loss: 0.1280088871717453
step: 630, loss: 0.10219115018844604
step: 640, loss: 0.07662995159626007
step: 650, loss: 0.15932074189186096
step: 660, loss: 0.11227819323539734
step: 670, loss: 0.08513717353343964
step: 680, loss: 0.15313658118247986
step: 690, loss: 0.26289892196655273
step: 700, loss: 0.05639156699180603
step: 710, loss: 0.14282011985778809
step: 720, loss: 0.10398362576961517
step: 730, loss: 0.09557206928730011
step: 740, loss: 0.06742345541715622
step: 750, loss: 0.06533105671405792
step: 760, loss: 0.09495165944099426
step: 770, loss: 0.06513837724924088
step: 780, loss: 0.11618514358997345
step: 790, loss: 0.03216592222452164
step: 800, loss: 0.12536804378032684
step: 810, loss: 0.19346928596496582
step: 820, loss: 0.047643933445215225
step: 830, loss: 0.03253158926963806
step: 840, loss: 0.08205346763134003
step: 850, loss: 0.12199099361896515
step: 860, loss: 0.02376348152756691
step: 870, loss: 0.16244712471961975
step: 880, loss: 0.119994156062603
step: 890, loss: 0.04556407034397125
step: 900, loss: 0.0780755952000618
step: 910, loss: 0.12111395597457886
step: 920, loss: 0.11520001292228699
step: 930, loss: 0.010015334002673626
step: 940, loss: 0.118550606071949
step: 950, loss: 0.12622934579849243
step: 960, loss: 0.1331697702407837
step: 970, loss: 0.0013399084564298391
epoch 7: dev_f1=0.9333333333333333, f1=0.9292649098474343, best_f1=0.9303826648224988
step: 0, loss: 0.05693826824426651
step: 10, loss: 0.13049617409706116
step: 20, loss: 0.02750163897871971
step: 30, loss: 0.13559889793395996
step: 40, loss: 0.04496335983276367
step: 50, loss: 0.1110076829791069
step: 60, loss: 0.11401276290416718
step: 70, loss: 0.14562757313251495
step: 80, loss: 0.054207656532526016
step: 90, loss: 0.13265319168567657
step: 100, loss: 0.0580611377954483
step: 110, loss: 0.05898505449295044
step: 120, loss: 0.11109914630651474
step: 130, loss: 0.05130372568964958
step: 140, loss: 0.10189329087734222
step: 150, loss: 0.09689604490995407
step: 160, loss: 0.06351377815008163
step: 170, loss: 0.008380926214158535
step: 180, loss: 0.08811265230178833
step: 190, loss: 0.06821677833795547
step: 200, loss: 0.15559637546539307
step: 210, loss: 0.1374385505914688
step: 220, loss: 0.028115279972553253
step: 230, loss: 0.1610989272594452
step: 240, loss: 0.04969247803092003
step: 250, loss: 0.016573503613471985
step: 260, loss: 0.1212119534611702
step: 270, loss: 0.010948339477181435
step: 280, loss: 0.08123014122247696
step: 290, loss: 0.044071123003959656
step: 300, loss: 0.05357874929904938
step: 310, loss: 0.05630047991871834
step: 320, loss: 0.06886947154998779
step: 330, loss: 0.068047896027565
step: 340, loss: 0.12999138236045837
step: 350, loss: 0.0879487693309784
step: 360, loss: 0.09870873391628265
step: 370, loss: 0.028279615566134453
step: 380, loss: 0.11984997242689133
step: 390, loss: 0.06994163990020752
step: 400, loss: 0.11808672547340393
step: 410, loss: 0.1256544291973114
step: 420, loss: 0.06985627114772797
step: 430, loss: 0.10049359500408173
step: 440, loss: 0.12047480791807175
step: 450, loss: 0.047848645597696304
step: 460, loss: 0.09168927371501923
step: 470, loss: 0.08812429010868073
step: 480, loss: 0.06220416724681854
step: 490, loss: 0.022664252668619156
step: 500, loss: 0.09099272638559341
step: 510, loss: 0.18649311363697052
step: 520, loss: 0.07704000920057297
step: 530, loss: 0.0709829181432724
step: 540, loss: 0.07979980111122131
step: 550, loss: 0.0924411416053772
step: 560, loss: 0.1732911318540573
step: 570, loss: 0.1906164139509201
step: 580, loss: 0.117570661008358
step: 590, loss: 0.09711818397045135
step: 600, loss: 0.16112101078033447
step: 610, loss: 0.12411179393529892
step: 620, loss: 0.09397169202566147
step: 630, loss: 0.09712033718824387
step: 640, loss: 0.0756428986787796
step: 650, loss: 0.06965669244527817
step: 660, loss: 0.050050750374794006
step: 670, loss: 0.026969393715262413
step: 680, loss: 0.04836839810013771
step: 690, loss: 0.16854825615882874
step: 700, loss: 0.13900767266750336
step: 710, loss: 0.020111558958888054
step: 720, loss: 0.05108313634991646
step: 730, loss: 0.12118269503116608
step: 740, loss: 0.0969705730676651
step: 750, loss: 0.09322336316108704
step: 760, loss: 0.019825775176286697
step: 770, loss: 0.1342969685792923
step: 780, loss: 0.059179890900850296
step: 790, loss: 0.09929075837135315
step: 800, loss: 0.11166658252477646
step: 810, loss: 0.09631605446338654
step: 820, loss: 0.07176285982131958
step: 830, loss: 0.0211192574352026
step: 840, loss: 0.0711437240242958
step: 850, loss: 0.14566485583782196
step: 860, loss: 0.03121580369770527
step: 870, loss: 0.08280212432146072
step: 880, loss: 0.05691342055797577
step: 890, loss: 0.08767586201429367
step: 900, loss: 0.13228878378868103
step: 910, loss: 0.23411905765533447
step: 920, loss: 0.12868119776248932
step: 930, loss: 0.13963583111763
step: 940, loss: 0.19621700048446655
step: 950, loss: 0.11345198005437851
step: 960, loss: 0.10455252230167389
step: 970, loss: 0.09303589165210724
epoch 8: dev_f1=0.9338842975206612, f1=0.9257722452743199, best_f1=0.9257722452743199
step: 0, loss: 0.10640088468790054
step: 10, loss: 0.11664262413978577
step: 20, loss: 0.04037896543741226
step: 30, loss: 0.1929650455713272
step: 40, loss: 0.2105797529220581
step: 50, loss: 0.09672676771879196
step: 60, loss: 0.07554351538419724
step: 70, loss: 0.0600980669260025
step: 80, loss: 0.14734482765197754
step: 90, loss: 0.036993518471717834
step: 100, loss: 0.09785811603069305
step: 110, loss: 0.02819913625717163
step: 120, loss: 0.09263186156749725
step: 130, loss: 0.12489262223243713
step: 140, loss: 0.04284530133008957
step: 150, loss: 0.07161083072423935
step: 160, loss: 0.18659918010234833
step: 170, loss: 0.10457048565149307
step: 180, loss: 0.056981321424245834
step: 190, loss: 0.04599379003047943
step: 200, loss: 0.06462891399860382
step: 210, loss: 0.03674311935901642
step: 220, loss: 0.05647365748882294
step: 230, loss: 0.05744657665491104
step: 240, loss: 0.1048484593629837
step: 250, loss: 0.11962059885263443
step: 260, loss: 0.06158733740448952
step: 270, loss: 0.011780941858887672
step: 280, loss: 0.0760052353143692
step: 290, loss: 0.061989203095436096
step: 300, loss: 0.09991033375263214
step: 310, loss: 0.12777873873710632
step: 320, loss: 0.1386246532201767
step: 330, loss: 0.030307799577713013
step: 340, loss: 0.054147444665431976
step: 350, loss: 0.11906005442142487
step: 360, loss: 0.08605653047561646
step: 370, loss: 0.11519323289394379
step: 380, loss: 0.06276382505893707
step: 390, loss: 0.08735720813274384
step: 400, loss: 0.09636564552783966
step: 410, loss: 0.04371853545308113
step: 420, loss: 0.03741256520152092
step: 430, loss: 0.06266234815120697
step: 440, loss: 0.05288530886173248
step: 450, loss: 0.05903761461377144
step: 460, loss: 0.10835088789463043
step: 470, loss: 0.009203835390508175
step: 480, loss: 0.06663645058870316
step: 490, loss: 0.1178334653377533
step: 500, loss: 0.10217168927192688
step: 510, loss: 0.09286067634820938
step: 520, loss: 0.21133902668952942
step: 530, loss: 0.12452472746372223
step: 540, loss: 0.15397468209266663
step: 550, loss: 0.053073104470968246
step: 560, loss: 0.33267760276794434
step: 570, loss: 0.14391975104808807
step: 580, loss: 0.06378093361854553
step: 590, loss: 0.022064268589019775
step: 600, loss: 0.16086989641189575
step: 610, loss: 0.1454733908176422
step: 620, loss: 0.15702825784683228
step: 630, loss: 0.1128334105014801
step: 640, loss: 0.10619102418422699
step: 650, loss: 0.006377280689775944
step: 660, loss: 0.07554054260253906
step: 670, loss: 0.12007708847522736
step: 680, loss: 0.17601224780082703
step: 690, loss: 0.028619974851608276
step: 700, loss: 0.044500838965177536
step: 710, loss: 0.22468781471252441
step: 720, loss: 0.04922230914235115
step: 730, loss: 0.03140697255730629
step: 740, loss: 0.08794823288917542
step: 750, loss: 0.04586179554462433
step: 760, loss: 0.12218575924634933
step: 770, loss: 0.05771208927035332
step: 780, loss: 0.06364389508962631
step: 790, loss: 0.0643949955701828
step: 800, loss: 0.109857939183712
step: 810, loss: 0.07322513312101364
step: 820, loss: 0.024074874818325043
step: 830, loss: 0.0949551984667778
step: 840, loss: 0.1019824668765068
step: 850, loss: 0.06950642913579941
step: 860, loss: 0.10861442983150482
step: 870, loss: 0.02755393646657467
step: 880, loss: 0.05083660036325455
step: 890, loss: 0.07451548427343369
step: 900, loss: 0.15293198823928833
step: 910, loss: 0.10571932047605515
step: 920, loss: 0.051610250025987625
step: 930, loss: 0.07876282185316086
step: 940, loss: 0.04880542680621147
step: 950, loss: 0.03945458307862282
step: 960, loss: 0.11443797498941422
step: 970, loss: 0.07079602777957916
epoch 9: dev_f1=0.9341864716636197, f1=0.9284403669724771, best_f1=0.9284403669724771
step: 0, loss: 0.09419424831867218
step: 10, loss: 0.06650473922491074
step: 20, loss: 0.05455039069056511
step: 30, loss: 0.09174252301454544
step: 40, loss: 0.04537982493638992
step: 50, loss: 0.03762129694223404
step: 60, loss: 0.10779356211423874
step: 70, loss: 0.025953905656933784
step: 80, loss: 0.07310110330581665
step: 90, loss: 0.08249757438898087
step: 100, loss: 0.09014828503131866
step: 110, loss: 0.031024836003780365
step: 120, loss: 0.02821270003914833
step: 130, loss: 0.06348592787981033
step: 140, loss: 0.07481056451797485
step: 150, loss: 0.06600062549114227
step: 160, loss: 0.11472044140100479
step: 170, loss: 0.018620774149894714
step: 180, loss: 0.03527063503861427
step: 190, loss: 0.12380504608154297
step: 200, loss: 0.03649182245135307
step: 210, loss: 0.038426246494054794
step: 220, loss: 0.0033548122737556696
step: 230, loss: 0.012387308292090893
step: 240, loss: 0.03956575691699982
step: 250, loss: 0.04330051690340042
step: 260, loss: 0.1769198477268219
step: 270, loss: 0.08633499592542648
step: 280, loss: 0.08092376589775085
step: 290, loss: 0.0611686035990715
step: 300, loss: 0.03990078344941139
step: 310, loss: 0.08605310320854187
step: 320, loss: 0.078962042927742
step: 330, loss: 0.056635934859514236
step: 340, loss: 0.053593337535858154
step: 350, loss: 0.01938018761575222
step: 360, loss: 0.061555229127407074
step: 370, loss: 0.09063011407852173
step: 380, loss: 0.0976683646440506
step: 390, loss: 0.2631179392337799
step: 400, loss: 0.0695197805762291
step: 410, loss: 0.04371940344572067
step: 420, loss: 0.044635724276304245
step: 430, loss: 0.16271798312664032
step: 440, loss: 0.0782180204987526
step: 450, loss: 0.054216645658016205
step: 460, loss: 0.03466631472110748
step: 470, loss: 0.06811778247356415
step: 480, loss: 0.0456756092607975
step: 490, loss: 0.19533562660217285
step: 500, loss: 0.022987717762589455
step: 510, loss: 0.0376337505877018
step: 520, loss: 0.04879036918282509
step: 530, loss: 0.06805898249149323
step: 540, loss: 0.17780327796936035
step: 550, loss: 0.11696796119213104
step: 560, loss: 0.03230022266507149
step: 570, loss: 0.03717542067170143
step: 580, loss: 0.11164729297161102
step: 590, loss: 0.059842467308044434
step: 600, loss: 0.058728840202093124
step: 610, loss: 0.04178671911358833
step: 620, loss: 0.05883670225739479
step: 630, loss: 0.11822566390037537
step: 640, loss: 0.15111370384693146
step: 650, loss: 0.05399572104215622
step: 660, loss: 0.09941434860229492
step: 670, loss: 0.09641115367412567
step: 680, loss: 0.1118331179022789
step: 690, loss: 0.0283442921936512
step: 700, loss: 0.09799544513225555
step: 710, loss: 0.15400032699108124
step: 720, loss: 0.08830375224351883
step: 730, loss: 0.09815225005149841
step: 740, loss: 0.06279165297746658
step: 750, loss: 0.14836567640304565
step: 760, loss: 0.12685655057430267
step: 770, loss: 0.10039085894823074
step: 780, loss: 0.06992470473051071
step: 790, loss: 0.06727252900600433
step: 800, loss: 0.11826664954423904
step: 810, loss: 0.07338150590658188
step: 820, loss: 0.09473297744989395
step: 830, loss: 0.11851158738136292
step: 840, loss: 0.13041526079177856
step: 850, loss: 0.09392352402210236
step: 860, loss: 0.21678291261196136
step: 870, loss: 0.03178642690181732
step: 880, loss: 0.2608621120452881
step: 890, loss: 0.10125894099473953
step: 900, loss: 0.021948039531707764
step: 910, loss: 0.11506600677967072
step: 920, loss: 0.031056271865963936
step: 930, loss: 0.01096924114972353
step: 940, loss: 0.04506656154990196
step: 950, loss: 0.02996499091386795
step: 960, loss: 0.17720022797584534
step: 970, loss: 0.02796626277267933
epoch 10: dev_f1=0.9367205542725173, f1=0.9262672811059909, best_f1=0.9262672811059909
step: 0, loss: 0.05627819523215294
step: 10, loss: 0.03648809716105461
step: 20, loss: 0.10067268460988998
step: 30, loss: 0.029488472267985344
step: 40, loss: 0.08952831476926804
step: 50, loss: 0.10815723985433578
step: 60, loss: 0.0412486232817173
step: 70, loss: 0.03327745944261551
step: 80, loss: 0.03144250437617302
step: 90, loss: 0.12840601801872253
step: 100, loss: 0.1401343196630478
step: 110, loss: 0.09049022942781448
step: 120, loss: 0.16286440193653107
step: 130, loss: 0.16967621445655823
step: 140, loss: 0.1688033640384674
step: 150, loss: 0.13262763619422913
step: 160, loss: 0.03775741159915924
step: 170, loss: 0.01937054470181465
step: 180, loss: 0.09520029276609421
step: 190, loss: 0.03721568360924721
step: 200, loss: 0.04956826940178871
step: 210, loss: 0.13475027680397034
step: 220, loss: 0.0686231404542923
step: 230, loss: 0.05902815982699394
step: 240, loss: 0.0640949234366417
step: 250, loss: 0.016093086451292038
step: 260, loss: 0.07960042357444763
step: 270, loss: 0.14892691373825073
step: 280, loss: 0.08706051856279373
step: 290, loss: 0.0332879014313221
step: 300, loss: 0.040114641189575195
step: 310, loss: 0.09380719810724258
step: 320, loss: 0.034231480211019516
step: 330, loss: 0.0066353194415569305
step: 340, loss: 0.032651614397764206
step: 350, loss: 0.05327596887946129
step: 360, loss: 0.12116264551877975
step: 370, loss: 0.13960573077201843
step: 380, loss: 0.08066032826900482
step: 390, loss: 0.04103032499551773
step: 400, loss: 0.1075918897986412
step: 410, loss: 0.09422177821397781
step: 420, loss: 0.054278597235679626
step: 430, loss: 0.0704687237739563
step: 440, loss: 0.06907495856285095
step: 450, loss: 0.054465118795633316
step: 460, loss: 0.047876179218292236
step: 470, loss: 0.07852550595998764
step: 480, loss: 0.1265696883201599
step: 490, loss: 0.09616751968860626
step: 500, loss: 0.07825017720460892
step: 510, loss: 0.13971294462680817
step: 520, loss: 0.05204718932509422
step: 530, loss: 0.1154305711388588
step: 540, loss: 0.06721481680870056
step: 550, loss: 0.07722239196300507
step: 560, loss: 0.07066380977630615
step: 570, loss: 0.08376620709896088
step: 580, loss: 0.01269801426678896
step: 590, loss: 0.06976527720689774
step: 600, loss: 0.031017914414405823
step: 610, loss: 0.07113219797611237
step: 620, loss: 0.049637578427791595
step: 630, loss: 0.07135389745235443
step: 640, loss: 0.049383167177438736
step: 650, loss: 0.029572773724794388
step: 660, loss: 7.370039384113625e-05
step: 670, loss: 0.10923289507627487
step: 680, loss: 0.0824965164065361
step: 690, loss: 0.07307412475347519
step: 700, loss: 0.11006322503089905
step: 710, loss: 0.031163562089204788
step: 720, loss: 0.06212411820888519
step: 730, loss: 0.08982420712709427
step: 740, loss: 0.1178986206650734
step: 750, loss: 0.05336637794971466
step: 760, loss: 0.07285135239362717
step: 770, loss: 0.059924013912677765
step: 780, loss: 0.095411516726017
step: 790, loss: 0.058113258332014084
step: 800, loss: 0.14785368740558624
step: 810, loss: 0.10619024932384491
step: 820, loss: 0.040777187794446945
step: 830, loss: 0.04574936255812645
step: 840, loss: 0.06337706744670868
step: 850, loss: 0.0659995749592781
step: 860, loss: 0.15508830547332764
step: 870, loss: 0.020648974925279617
step: 880, loss: 0.07385558634996414
step: 890, loss: 0.10888277739286423
step: 900, loss: 0.14862404763698578
step: 910, loss: 0.15113011002540588
step: 920, loss: 0.13601373136043549
step: 930, loss: 0.03772177919745445
step: 940, loss: 0.057874057441949844
step: 950, loss: 0.07586223632097244
step: 960, loss: 0.06305036693811417
step: 970, loss: 0.024627000093460083
epoch 11: dev_f1=0.9348335677449601, f1=0.9310183012670109, best_f1=0.9262672811059909
step: 0, loss: 0.0836682841181755
step: 10, loss: 0.09820390492677689
step: 20, loss: 0.03984386473894119
step: 30, loss: 0.025619398802518845
step: 40, loss: 0.12922194600105286
step: 50, loss: 0.08352993428707123
step: 60, loss: 0.07164988666772842
step: 70, loss: 0.14512953162193298
step: 80, loss: 0.03680143505334854
step: 90, loss: 0.09641007333993912
step: 100, loss: 0.0723089650273323
step: 110, loss: 0.03341379016637802
step: 120, loss: 0.10420991480350494
step: 130, loss: 0.034947048872709274
step: 140, loss: 0.08908203989267349
step: 150, loss: 0.12635114789009094
step: 160, loss: 0.0685204565525055
step: 170, loss: 3.6321362131275237e-05
step: 180, loss: 0.06003657728433609
step: 190, loss: 0.006788745056837797
step: 200, loss: 0.08818858861923218
step: 210, loss: 0.061189960688352585
step: 220, loss: 0.021783243864774704
step: 230, loss: 0.004905457142740488
step: 240, loss: 0.05487089976668358
step: 250, loss: 0.06903485953807831
step: 260, loss: 0.05059564858675003
step: 270, loss: 0.011651181615889072
step: 280, loss: 0.05491125211119652
step: 290, loss: 0.0814262256026268
step: 300, loss: 0.023862240836024284
step: 310, loss: 0.008674154058098793
step: 320, loss: 0.0527108833193779
step: 330, loss: 0.02671966515481472
step: 340, loss: 0.05743355304002762
step: 350, loss: 0.09112191200256348
step: 360, loss: 0.09964874386787415
step: 370, loss: 0.018391432240605354
step: 380, loss: 0.029697617515921593
step: 390, loss: 0.04302597418427467
step: 400, loss: 0.12200626730918884
step: 410, loss: 0.06173462048172951
step: 420, loss: 0.06100386753678322
step: 430, loss: 0.04763453081250191
step: 440, loss: 0.02001626044511795
step: 450, loss: 0.10594520717859268
step: 460, loss: 0.1740695834159851
step: 470, loss: 0.029575703665614128
step: 480, loss: 0.08498658239841461
step: 490, loss: 0.06997554749250412
step: 500, loss: 0.27736830711364746
step: 510, loss: 0.10209012031555176
step: 520, loss: 0.1183168962597847
step: 530, loss: 0.08145225048065186
step: 540, loss: 0.08389541506767273
step: 550, loss: 0.07379192858934402
step: 560, loss: 0.01738743670284748
step: 570, loss: 0.13366708159446716
step: 580, loss: 0.02477441355586052
step: 590, loss: 0.027458056807518005
step: 600, loss: 0.029207374900579453
step: 610, loss: 0.01702931337058544
step: 620, loss: 0.045942604541778564
step: 630, loss: 0.1650787591934204
step: 640, loss: 2.780048998829443e-05
step: 650, loss: 0.13262757658958435
step: 660, loss: 0.05512912571430206
step: 670, loss: 0.06793706864118576
step: 680, loss: 0.17115715146064758
step: 690, loss: 0.03489886224269867
step: 700, loss: 0.06558728218078613
step: 710, loss: 0.016320329159498215
step: 720, loss: 0.10539200156927109
step: 730, loss: 0.07301340997219086
step: 740, loss: 0.11602292954921722
step: 750, loss: 0.17994768917560577
step: 760, loss: 0.03184262663125992
step: 770, loss: 0.01719070039689541
step: 780, loss: 0.13526944816112518
step: 790, loss: 0.02919602394104004
step: 800, loss: 0.05071021243929863
step: 810, loss: 0.1078372672200203
step: 820, loss: 0.11863163858652115
step: 830, loss: 0.03459728881716728
step: 840, loss: 0.020247016102075577
step: 850, loss: 0.12160048633813858
step: 860, loss: 0.05292170122265816
step: 870, loss: 0.08207501471042633
step: 880, loss: 0.07513836771249771
step: 890, loss: 0.0833628848195076
step: 900, loss: 0.038299284875392914
step: 910, loss: 0.11694834381341934
step: 920, loss: 0.04266706109046936
step: 930, loss: 0.07154138386249542
step: 940, loss: 0.07035378366708755
step: 950, loss: 0.03155134618282318
step: 960, loss: 0.046406157314777374
step: 970, loss: 0.10383296012878418
epoch 12: dev_f1=0.9297197978870005, f1=0.9241379310344828, best_f1=0.9262672811059909
step: 0, loss: 0.11979416012763977
step: 10, loss: 0.07977046817541122
step: 20, loss: 0.05467768758535385
step: 30, loss: 0.0793558657169342
step: 40, loss: 0.09238626062870026
step: 50, loss: 0.07250062376260757
step: 60, loss: 0.02738751471042633
step: 70, loss: 0.1012330874800682
step: 80, loss: 0.03529995679855347
step: 90, loss: 0.15147246420383453
step: 100, loss: 0.05203605815768242
step: 110, loss: 0.07420264929533005
step: 120, loss: 0.0717356875538826
step: 130, loss: 0.07102512568235397
step: 140, loss: 0.14286907017230988
step: 150, loss: 0.03811571002006531
step: 160, loss: 0.15349175035953522
step: 170, loss: 0.07235818356275558
step: 180, loss: 0.09949544072151184
step: 190, loss: 0.1070847362279892
step: 200, loss: 0.03076840378344059
step: 210, loss: 0.05772723630070686
step: 220, loss: 0.1303730309009552
step: 230, loss: 0.015265228226780891
step: 240, loss: 0.0862044245004654
step: 250, loss: 0.06744256615638733
step: 260, loss: 0.037120990455150604
step: 270, loss: 0.10945809632539749
step: 280, loss: 0.03382030129432678
step: 290, loss: 0.033775679767131805
step: 300, loss: 0.08699166029691696
step: 310, loss: 0.06938505917787552
step: 320, loss: 0.08995113521814346
step: 330, loss: 0.09546675533056259
step: 340, loss: 0.10013929009437561
step: 350, loss: 0.10451743006706238
step: 360, loss: 0.00711309676989913
step: 370, loss: 0.04773448407649994
step: 380, loss: 0.058025062084198
step: 390, loss: 0.07678806036710739
step: 400, loss: 0.06637150794267654
step: 410, loss: 0.041634395718574524
step: 420, loss: 0.07468423247337341
step: 430, loss: 0.0791180208325386
step: 440, loss: 0.13479207456111908
step: 450, loss: 0.08480428904294968
step: 460, loss: 0.05401470139622688
step: 470, loss: 0.09442348778247833
step: 480, loss: 0.02523929253220558
step: 490, loss: 0.07354624569416046
step: 500, loss: 0.04093797504901886
step: 510, loss: 0.05460719019174576
step: 520, loss: 0.03908209875226021
step: 530, loss: 0.11284930258989334
step: 540, loss: 0.05557989701628685
step: 550, loss: 0.10526825487613678
step: 560, loss: 0.08319295197725296
step: 570, loss: 0.067637138068676
step: 580, loss: 0.058531664311885834
step: 590, loss: 0.06601458787918091
step: 600, loss: 0.02022196725010872
step: 610, loss: 0.10402606427669525
step: 620, loss: 0.039997510612010956
step: 630, loss: 0.07834446430206299
step: 640, loss: 0.033180978149175644
step: 650, loss: 0.05243147164583206
step: 660, loss: 0.055548448115587234
step: 670, loss: 0.07348494976758957
step: 680, loss: 0.14062383770942688
step: 690, loss: 0.06988713145256042
step: 700, loss: 0.020056139677762985
step: 710, loss: 0.03652606159448624
step: 720, loss: 0.08098593354225159
step: 730, loss: 0.16359704732894897
step: 740, loss: 0.12777668237686157
step: 750, loss: 0.05274375155568123
step: 760, loss: 0.12118366360664368
step: 770, loss: 0.06318162381649017
step: 780, loss: 0.03725142031908035
step: 790, loss: 0.07529712468385696
step: 800, loss: 0.0664556622505188
step: 810, loss: 0.09490685909986496
step: 820, loss: 0.05160529538989067
step: 830, loss: 0.06390730291604996
step: 840, loss: 0.08403341472148895
step: 850, loss: 0.02354264073073864
step: 860, loss: 0.0013248487375676632
step: 870, loss: 0.06180727854371071
step: 880, loss: 0.06481287628412247
step: 890, loss: 0.06323548406362534
step: 900, loss: 0.12160153687000275
step: 910, loss: 0.07677838206291199
step: 920, loss: 0.037252504378557205
step: 930, loss: 0.05172831937670708
step: 940, loss: 0.1304313689470291
step: 950, loss: 0.1318632960319519
step: 960, loss: 0.013227778486907482
step: 970, loss: 0.02726299688220024
epoch 13: dev_f1=0.9361305361305362, f1=0.9322191272051997, best_f1=0.9262672811059909
step: 0, loss: 0.06965194642543793
step: 10, loss: 0.14775219559669495
step: 20, loss: 0.014705176465213299
step: 30, loss: 0.10987596213817596
step: 40, loss: 0.03607787564396858
step: 50, loss: 0.06042791157960892
step: 60, loss: 0.03438923507928848
step: 70, loss: 0.07052803784608841
step: 80, loss: 0.023636704310774803
step: 90, loss: 0.0501229465007782
step: 100, loss: 0.04269589111208916
step: 110, loss: 0.004130803979933262
step: 120, loss: 0.09083689749240875
step: 130, loss: 0.05441506206989288
step: 140, loss: 0.11847904324531555
step: 150, loss: 0.042474035173654556
step: 160, loss: 0.11151095479726791
step: 170, loss: 0.04567693918943405
step: 180, loss: 0.093103788793087
step: 190, loss: 0.2604934871196747
step: 200, loss: 0.025083214044570923
step: 210, loss: 0.09743600338697433
step: 220, loss: 0.05521178990602493
step: 230, loss: 0.016403064131736755
step: 240, loss: 0.07084423303604126
step: 250, loss: 0.05042245611548424
step: 260, loss: 0.00017901515820994973
step: 270, loss: 0.07131940126419067
step: 280, loss: 0.08855635672807693
step: 290, loss: 0.08133911341428757
step: 300, loss: 0.13593816757202148
step: 310, loss: 0.19597360491752625
step: 320, loss: 0.13506951928138733
step: 330, loss: 0.043639037758111954
step: 340, loss: 0.01174165029078722
step: 350, loss: 0.13731375336647034
step: 360, loss: 0.06723563373088837
step: 370, loss: 0.07438516616821289
step: 380, loss: 0.04533163830637932
step: 390, loss: 0.0612325593829155
step: 400, loss: 0.03887341171503067
step: 410, loss: 0.04770926013588905
step: 420, loss: 0.04820011928677559
step: 430, loss: 0.0811849981546402
step: 440, loss: 0.03191685676574707
step: 450, loss: 0.043690744787454605
step: 460, loss: 0.02710622549057007
step: 470, loss: 0.059624023735523224
step: 480, loss: 0.026798957958817482
step: 490, loss: 0.021463971585035324
step: 500, loss: 0.06248965859413147
step: 510, loss: 0.021825052797794342
step: 520, loss: 0.035993270576000214
step: 530, loss: 0.106829933822155
step: 540, loss: 0.12467510998249054
step: 550, loss: 0.06718163192272186
step: 560, loss: 0.0814027190208435
step: 570, loss: 0.08278209716081619
step: 580, loss: 0.06312088668346405
step: 590, loss: 0.08575361967086792
step: 600, loss: 0.08437560498714447
step: 610, loss: 0.08113475143909454
step: 620, loss: 0.06793272495269775
step: 630, loss: 0.12331820279359818
step: 640, loss: 0.14359399676322937
step: 650, loss: 0.061663463711738586
step: 660, loss: 0.021828550845384598
step: 670, loss: 0.0715746358036995
step: 680, loss: 0.030235782265663147
step: 690, loss: 0.0782456174492836
step: 700, loss: 0.02901083044707775
step: 710, loss: 0.07909974455833435
step: 720, loss: 0.023918813094496727
step: 730, loss: 0.04970501363277435
step: 740, loss: 0.01767672412097454
step: 750, loss: 0.008971625007689
step: 760, loss: 0.032495129853487015
step: 770, loss: 0.08321201056241989
step: 780, loss: 0.06869248300790787
step: 790, loss: 0.030646372586488724
step: 800, loss: 0.18363067507743835
step: 810, loss: 0.028802596032619476
step: 820, loss: 0.0576433390378952
step: 830, loss: 0.049116961658000946
step: 840, loss: 0.02537374757230282
step: 850, loss: 0.03378927707672119
step: 860, loss: 0.164668008685112
step: 870, loss: 0.06743216514587402
step: 880, loss: 0.18063783645629883
step: 890, loss: 0.04387980327010155
step: 900, loss: 0.031225038692355156
step: 910, loss: 0.12115223705768585
step: 920, loss: 0.2760687470436096
step: 930, loss: 0.060816992074251175
step: 940, loss: 0.10956159979104996
step: 950, loss: 0.03831297531723976
step: 960, loss: 0.06951488554477692
step: 970, loss: 0.03574792295694351
epoch 14: dev_f1=0.9332113449222323, f1=0.9251824817518249, best_f1=0.9262672811059909
step: 0, loss: 0.036050423979759216
step: 10, loss: 0.04625922814011574
step: 20, loss: 0.09029684215784073
step: 30, loss: 0.03339376300573349
step: 40, loss: 0.03948173299431801
step: 50, loss: 0.05677548050880432
step: 60, loss: 0.10860919207334518
step: 70, loss: 0.09880592674016953
step: 80, loss: 0.02735036239027977
step: 90, loss: 0.008432275615632534
step: 100, loss: 0.09453343600034714
step: 110, loss: 0.06575871258974075
step: 120, loss: 0.023447629064321518
step: 130, loss: 0.0007741537992842495
step: 140, loss: 0.09281709790229797
step: 150, loss: 0.08544103056192398
step: 160, loss: 0.05019558221101761
step: 170, loss: 0.08771731704473495
step: 180, loss: 0.04291263967752457
step: 190, loss: 0.07801808416843414
step: 200, loss: 0.004757373593747616
step: 210, loss: 0.12636792659759521
step: 220, loss: 0.07800886780023575
step: 230, loss: 0.09911462664604187
step: 240, loss: 0.1008862778544426
step: 250, loss: 0.04728687182068825
step: 260, loss: 0.06440319120883942
step: 270, loss: 0.02124403975903988
step: 280, loss: 0.05766933038830757
step: 290, loss: 0.14473947882652283
step: 300, loss: 0.08408438414335251
step: 310, loss: 0.0585932657122612
step: 320, loss: 0.12443272769451141
step: 330, loss: 0.037439748644828796
step: 340, loss: 0.0637994110584259
step: 350, loss: 0.016455672681331635
step: 360, loss: 0.05917133390903473
step: 370, loss: 0.019368696957826614
step: 380, loss: 0.06327610462903976
step: 390, loss: 0.08958514034748077
step: 400, loss: 0.07326379418373108
step: 410, loss: 0.011107243597507477
step: 420, loss: 0.03687266632914543
step: 430, loss: 0.05834990367293358
step: 440, loss: 0.03681514039635658
step: 450, loss: 0.03967400640249252
step: 460, loss: 0.09615511447191238
step: 470, loss: 0.04990848898887634
step: 480, loss: 0.07370170950889587
step: 490, loss: 0.13185369968414307
step: 500, loss: 0.07465031743049622
step: 510, loss: 0.08257680386304855
step: 520, loss: 0.06781032681465149
step: 530, loss: 0.08507709205150604
step: 540, loss: 0.04406850412487984
step: 550, loss: 0.15004216134548187
step: 560, loss: 0.0002128263149643317
step: 570, loss: 0.0298282653093338
step: 580, loss: 0.09926799684762955
step: 590, loss: 0.005838735494762659
step: 600, loss: 0.024578101933002472
step: 610, loss: 0.08442822843790054
step: 620, loss: 0.013647018931806087
step: 630, loss: 0.024902408942580223
step: 640, loss: 0.05475069209933281
step: 650, loss: 0.05001893639564514
step: 660, loss: 0.06974724680185318
step: 670, loss: 0.015976401045918465
step: 680, loss: 0.0465233139693737
step: 690, loss: 0.09715048968791962
step: 700, loss: 0.021038271486759186
step: 710, loss: 0.05023271590471268
step: 720, loss: 0.18180236220359802
step: 730, loss: 0.017239423468708992
step: 740, loss: 0.029249681159853935
step: 750, loss: 0.04234210401773453
step: 760, loss: 0.036696530878543854
step: 770, loss: 0.237917959690094
step: 780, loss: 0.03988296911120415
step: 790, loss: 0.05886956304311752
step: 800, loss: 0.07466790825128555
step: 810, loss: 0.029592251405119896
step: 820, loss: 0.03627387434244156
step: 830, loss: 0.10779678076505661
step: 840, loss: 0.0429372563958168
step: 850, loss: 0.11640432476997375
step: 860, loss: 0.05647602304816246
step: 870, loss: 0.02500147745013237
step: 880, loss: 0.18029119074344635
step: 890, loss: 0.01743590086698532
step: 900, loss: 0.023550841957330704
step: 910, loss: 0.029356852173805237
step: 920, loss: 0.033762749284505844
step: 930, loss: 0.04011848568916321
step: 940, loss: 0.07983272522687912
step: 950, loss: 0.07382971793413162
step: 960, loss: 0.0623888298869133
step: 970, loss: 0.005868517793715
epoch 15: dev_f1=0.936111111111111, f1=0.9291994447015272, best_f1=0.9262672811059909
step: 0, loss: 0.07029924541711807
step: 10, loss: 0.04134853929281235
step: 20, loss: 0.05170843377709389
step: 30, loss: 0.03277963027358055
step: 40, loss: 0.040704499930143356
step: 50, loss: 0.028669876977801323
step: 60, loss: 0.042301617562770844
step: 70, loss: 0.021853791549801826
step: 80, loss: 0.07179924845695496
step: 90, loss: 0.0010917286854237318
step: 100, loss: 0.07712949067354202
step: 110, loss: 0.04158567264676094
step: 120, loss: 0.03289186209440231
step: 130, loss: 0.12583649158477783
step: 140, loss: 0.07696512341499329
step: 150, loss: 0.10555268824100494
step: 160, loss: 0.10600731521844864
step: 170, loss: 0.042208895087242126
step: 180, loss: 0.10577833652496338
step: 190, loss: 0.030219443142414093
step: 200, loss: 0.08847551792860031
step: 210, loss: 0.03145470470190048
step: 220, loss: 0.10979408770799637
step: 230, loss: 0.06242716684937477
step: 240, loss: 0.035011470317840576
step: 250, loss: 0.08556250482797623
step: 260, loss: 0.07381591200828552
step: 270, loss: 0.11848077923059464
step: 280, loss: 0.0448310561478138
step: 290, loss: 0.03743733838200569
step: 300, loss: 0.03139868751168251
step: 310, loss: 0.05450178682804108
step: 320, loss: 0.07216404378414154
step: 330, loss: 0.040798984467983246
step: 340, loss: 0.023419542238116264
step: 350, loss: 0.0395231768488884
step: 360, loss: 0.07116906344890594
step: 370, loss: 0.0256890207529068
step: 380, loss: 0.05467616766691208
step: 390, loss: 0.0001288215134991333
step: 400, loss: 0.030182654038071632
step: 410, loss: 0.017888441681861877
step: 420, loss: 0.06728028506040573
step: 430, loss: 0.1387312114238739
step: 440, loss: 0.09620651602745056
step: 450, loss: 0.024370593950152397
step: 460, loss: 0.0007384991040453315
step: 470, loss: 0.045425791293382645
step: 480, loss: 0.11390408128499985
step: 490, loss: 0.025501983240246773
step: 500, loss: 0.03994230926036835
step: 510, loss: 0.09296512603759766
step: 520, loss: 0.08217278867959976
step: 530, loss: 0.09673850983381271
step: 540, loss: 0.07142623513936996
step: 550, loss: 0.039415404200553894
step: 560, loss: 0.06625691801309586
step: 570, loss: 0.028567859902977943
step: 580, loss: 0.03340138494968414
step: 590, loss: 0.045455578714609146
step: 600, loss: 0.14422520995140076
step: 610, loss: 0.026996927335858345
step: 620, loss: 0.15632781386375427
step: 630, loss: 0.03497277945280075
step: 640, loss: 0.0911373570561409
step: 650, loss: 0.07523077726364136
step: 660, loss: 0.03889103978872299
step: 670, loss: 0.028796076774597168
step: 680, loss: 0.041533537209033966
step: 690, loss: 0.06252065300941467
step: 700, loss: 0.0026356226298958063
step: 710, loss: 0.021692119538784027
step: 720, loss: 0.17460748553276062
step: 730, loss: 0.10438818484544754
step: 740, loss: 0.04269946366548538
step: 750, loss: 0.004491577390581369
step: 760, loss: 0.010513201355934143
step: 770, loss: 0.03595571964979172
step: 780, loss: 0.021252194419503212
step: 790, loss: 0.0369001068174839
step: 800, loss: 0.033794503659009933
step: 810, loss: 0.08141154050827026
step: 820, loss: 0.07951322942972183
step: 830, loss: 0.09629439562559128
step: 840, loss: 0.0970519483089447
step: 850, loss: 0.0516679547727108
step: 860, loss: 0.03172478824853897
step: 870, loss: 0.0663372203707695
step: 880, loss: 0.056078698486089706
step: 890, loss: 0.09651146084070206
step: 900, loss: 0.06986861675977707
step: 910, loss: 0.054571595042943954
step: 920, loss: 0.023854058235883713
step: 930, loss: 0.018327662721276283
step: 940, loss: 0.02212626114487648
step: 950, loss: 0.0524093359708786
step: 960, loss: 0.03730368986725807
step: 970, loss: 0.06909336149692535
epoch 16: dev_f1=0.9356343283582089, f1=0.927710843373494, best_f1=0.9262672811059909
step: 0, loss: 0.015394419431686401
step: 10, loss: 0.041050828993320465
step: 20, loss: 0.038831956684589386
step: 30, loss: 0.044266581535339355
step: 40, loss: 0.000547059637028724
step: 50, loss: 0.057625386863946915
step: 60, loss: 0.055025238543748856
step: 70, loss: 0.06262949109077454
step: 80, loss: 0.09943690150976181
step: 90, loss: 0.06188878044486046
step: 100, loss: 0.013556663878262043
step: 110, loss: 0.15740422904491425
step: 120, loss: 0.06863964349031448
step: 130, loss: 0.05288542062044144
step: 140, loss: 0.020051103085279465
step: 150, loss: 0.04052453860640526
step: 160, loss: 0.04962911084294319
step: 170, loss: 0.006530112121254206
step: 180, loss: 0.1129189059138298
step: 190, loss: 0.1432085782289505
step: 200, loss: 0.013027705252170563
step: 210, loss: 0.041552092880010605
step: 220, loss: 0.09196294844150543
step: 230, loss: 0.13011059165000916
step: 240, loss: 0.12016145884990692
step: 250, loss: 0.03890639916062355
step: 260, loss: 0.03207053616642952
step: 270, loss: 0.004847490694373846
step: 280, loss: 0.016492798924446106
step: 290, loss: 0.17196160554885864
step: 300, loss: 0.012395268306136131
step: 310, loss: 0.04918942600488663
step: 320, loss: 0.0056809717789292336
step: 330, loss: 0.0351981595158577
step: 340, loss: 0.18718530237674713
step: 350, loss: 0.020284343510866165
step: 360, loss: 0.06759193539619446
step: 370, loss: 0.03632042929530144
step: 380, loss: 0.04930569604039192
step: 390, loss: 0.023631973192095757
step: 400, loss: 0.025920800864696503
step: 410, loss: 0.01593145728111267
step: 420, loss: 0.07340916991233826
step: 430, loss: 0.027609514072537422
step: 440, loss: 0.014442700892686844
step: 450, loss: 0.012021085247397423
step: 460, loss: 0.051239125430583954
step: 470, loss: 0.034140896052122116
step: 480, loss: 0.029348429292440414
step: 490, loss: 0.06567888706922531
step: 500, loss: 0.01815931312739849
step: 510, loss: 0.004521587397903204
step: 520, loss: 0.00038234039675444365
step: 530, loss: 0.01698322966694832
step: 540, loss: 0.052459608763456345
step: 550, loss: 0.06153123825788498
step: 560, loss: 0.06471724808216095
step: 570, loss: 0.018148742616176605
step: 580, loss: 0.05649939551949501
step: 590, loss: 0.05067434534430504
step: 600, loss: 0.061478011310100555
step: 610, loss: 0.06690286099910736
step: 620, loss: 0.010733593255281448
step: 630, loss: 0.0729837715625763
step: 640, loss: 0.025665588676929474
step: 650, loss: 0.038432247936725616
step: 660, loss: 0.0017899664817377925
step: 670, loss: 0.04039036110043526
step: 680, loss: 0.053497739136219025
step: 690, loss: 0.04512214660644531
step: 700, loss: 0.09693898260593414
step: 710, loss: 0.04136664792895317
step: 720, loss: 0.0180258397012949
step: 730, loss: 0.031180832535028458
step: 740, loss: 0.03541562706232071
step: 750, loss: 0.15234822034835815
step: 760, loss: 0.07223383337259293
step: 770, loss: 0.056681111454963684
step: 780, loss: 0.04283730313181877
step: 790, loss: 0.021998237818479538
step: 800, loss: 0.07257296144962311
step: 810, loss: 0.04858074337244034
step: 820, loss: 0.07545749098062515
step: 830, loss: 0.03466552123427391
step: 840, loss: 0.06516490876674652
step: 850, loss: 0.07452301681041718
step: 860, loss: 0.040447868406772614
step: 870, loss: 0.01311689056456089
step: 880, loss: 0.032308828085660934
step: 890, loss: 0.03473600372672081
step: 900, loss: 0.06002311781048775
step: 910, loss: 0.04778432473540306
step: 920, loss: 0.05124397203326225
step: 930, loss: 0.13915611803531647
step: 940, loss: 0.05904514715075493
step: 950, loss: 0.08034569770097733
step: 960, loss: 0.08516127616167068
step: 970, loss: 0.01001537125557661
epoch 17: dev_f1=0.9322113136979896, f1=0.9296693060083837, best_f1=0.9262672811059909
step: 0, loss: 0.016071557998657227
step: 10, loss: 0.04069679602980614
step: 20, loss: 0.05235139653086662
step: 30, loss: 0.1095925122499466
step: 40, loss: 0.020096158608794212
step: 50, loss: 0.032903317362070084
step: 60, loss: 0.11449974030256271
step: 70, loss: 0.06844226270914078
step: 80, loss: 0.005719860550016165
step: 90, loss: 0.04032706469297409
step: 100, loss: 0.08857809752225876
step: 110, loss: 0.08003454655408859
step: 120, loss: 0.14042727649211884
step: 130, loss: 0.08330913633108139
step: 140, loss: 0.039081599563360214
step: 150, loss: 0.03440513461828232
step: 160, loss: 0.03619056195020676
step: 170, loss: 0.044346705079078674
step: 180, loss: 0.06742502003908157
step: 190, loss: 0.0031370471697300673
step: 200, loss: 0.0002000111562665552
step: 210, loss: 0.044768255203962326
step: 220, loss: 0.0561843179166317
step: 230, loss: 0.0028844005428254604
step: 240, loss: 0.05880899354815483
step: 250, loss: 0.035811685025691986
step: 260, loss: 0.03914874047040939
step: 270, loss: 0.05646699294447899
step: 280, loss: 0.01770457811653614
step: 290, loss: 0.019181931391358376
step: 300, loss: 0.03430510312318802
step: 310, loss: 0.03160666301846504
step: 320, loss: 0.03772146254777908
step: 330, loss: 0.1122170016169548
step: 340, loss: 0.05118647217750549
step: 350, loss: 0.03852090984582901
step: 360, loss: 0.1245889738202095
step: 370, loss: 0.0816553458571434
step: 380, loss: 0.05574091151356697
step: 390, loss: 0.07271752506494522
step: 400, loss: 0.040539246052503586
step: 410, loss: 0.04498337581753731
step: 420, loss: 0.024341993033885956
step: 430, loss: 0.048922114074230194
step: 440, loss: 0.10372458398342133
step: 450, loss: 0.018014201894402504
step: 460, loss: 0.03987245261669159
step: 470, loss: 0.06126037612557411
step: 480, loss: 0.00033071605139411986
step: 490, loss: 0.11456000804901123
step: 500, loss: 0.04085707291960716
step: 510, loss: 0.056643515825271606
step: 520, loss: 0.04644346609711647
step: 530, loss: 1.4900659152772278e-05
step: 540, loss: 0.12702037394046783
step: 550, loss: 0.09048384428024292
step: 560, loss: 0.09853144735097885
step: 570, loss: 0.10428302735090256
step: 580, loss: 0.032667774707078934
step: 590, loss: 0.115672767162323
step: 600, loss: 0.018189063295722008
step: 610, loss: 0.0386095866560936
step: 620, loss: 0.039694756269454956
step: 630, loss: 0.019375137984752655
step: 640, loss: 0.03520422801375389
step: 650, loss: 0.04883336275815964
step: 660, loss: 0.030310699716210365
step: 670, loss: 0.03685992583632469
step: 680, loss: 0.027609379962086678
step: 690, loss: 0.0029815228190273046
step: 700, loss: 0.04526462033390999
step: 710, loss: 0.06494227796792984
step: 720, loss: 0.03191254287958145
step: 730, loss: 0.04113979637622833
step: 740, loss: 0.016440855339169502
step: 750, loss: 0.00034489683457650244
step: 760, loss: 0.08361195027828217
step: 770, loss: 0.0731525793671608
step: 780, loss: 0.2199506312608719
step: 790, loss: 0.10199062526226044
step: 800, loss: 0.06587250530719757
step: 810, loss: 0.016953840851783752
step: 820, loss: 0.05212447792291641
step: 830, loss: 0.006217264104634523
step: 840, loss: 0.015243473462760448
step: 850, loss: 0.0665346160531044
step: 860, loss: 0.10616403073072433
step: 870, loss: 0.009606346487998962
step: 880, loss: 0.058565039187669754
step: 890, loss: 0.038985468447208405
step: 900, loss: 0.045920535922050476
step: 910, loss: 0.007164711598306894
step: 920, loss: 0.13866543769836426
step: 930, loss: 0.01445651426911354
step: 940, loss: 0.0507962591946125
step: 950, loss: 0.08155368268489838
step: 960, loss: 0.07613304257392883
step: 970, loss: 0.045097969472408295
epoch 18: dev_f1=0.9277777777777779, f1=0.9255663430420712, best_f1=0.9262672811059909
step: 0, loss: 0.03204355761408806
step: 10, loss: 0.0002004007255891338
step: 20, loss: 0.06704181432723999
step: 30, loss: 0.0882950946688652
step: 40, loss: 0.0019273603102192283
step: 50, loss: 0.08070863783359528
step: 60, loss: 0.028779275715351105
step: 70, loss: 0.05519891902804375
step: 80, loss: 0.06704205274581909
step: 90, loss: 0.060846056789159775
step: 100, loss: 0.00023003721435088664
step: 110, loss: 0.12230273336172104
step: 120, loss: 0.00010406358342152089
step: 130, loss: 0.11188126355409622
step: 140, loss: 0.002161409007385373
step: 150, loss: 0.1614573448896408
step: 160, loss: 0.17087726294994354
step: 170, loss: 0.09430353343486786
step: 180, loss: 0.07061819732189178
step: 190, loss: 0.011844683438539505
step: 200, loss: 0.029226481914520264
step: 210, loss: 0.017460621893405914
step: 220, loss: 0.028607433661818504
step: 230, loss: 0.08505621552467346
step: 240, loss: 0.021920135244727135
step: 250, loss: 0.09033899754285812
step: 260, loss: 0.022708605974912643
step: 270, loss: 0.023368721827864647
step: 280, loss: 0.04249170795083046
step: 290, loss: 0.035295143723487854
step: 300, loss: 0.011552509851753712
step: 310, loss: 0.0702018290758133
step: 320, loss: 0.03456171229481697
step: 330, loss: 0.05213022604584694
step: 340, loss: 0.0341879278421402
step: 350, loss: 0.02582540176808834
step: 360, loss: 0.05731029808521271
step: 370, loss: 0.02694505825638771
step: 380, loss: 0.09649388492107391
step: 390, loss: 0.00031509148539043963
step: 400, loss: 0.056479379534721375
step: 410, loss: 0.11822264641523361
step: 420, loss: 0.05744948238134384
step: 430, loss: 0.018850071355700493
step: 440, loss: 0.03782549872994423
step: 450, loss: 0.04065941274166107
step: 460, loss: 0.09004044532775879
step: 470, loss: 0.01679546944797039
step: 480, loss: 0.007647126447409391
step: 490, loss: 0.04842764511704445
step: 500, loss: 0.03804953023791313
step: 510, loss: 0.08045627176761627
step: 520, loss: 0.04116496443748474
step: 530, loss: 0.05118535831570625
step: 540, loss: 0.04408848285675049
step: 550, loss: 0.04568052291870117
step: 560, loss: 0.025967471301555634
step: 570, loss: 0.06550677120685577
step: 580, loss: 0.05598631128668785
step: 590, loss: 8.570206409785897e-05
step: 600, loss: 0.01217273622751236
step: 610, loss: 0.042412519454956055
step: 620, loss: 0.05730130523443222
step: 630, loss: 0.05398902669548988
step: 640, loss: 0.040808603167533875
step: 650, loss: 0.030290715396404266
step: 660, loss: 0.11356917023658752
step: 670, loss: 0.017287718132138252
step: 680, loss: 0.09826990962028503
step: 690, loss: 0.03659307211637497
step: 700, loss: 0.060331836342811584
step: 710, loss: 0.07643703371286392
step: 720, loss: 0.07858893275260925
step: 730, loss: 0.050973694771528244
step: 740, loss: 0.0041567487642169
step: 750, loss: 0.07088170945644379
step: 760, loss: 0.0496143214404583
step: 770, loss: 0.04736340045928955
step: 780, loss: 0.0661487728357315
step: 790, loss: 0.043488044291734695
step: 800, loss: 8.014836203074083e-05
step: 810, loss: 0.06155185028910637
step: 820, loss: 0.0536549873650074
step: 830, loss: 0.1455966681241989
step: 840, loss: 0.047056056559085846
step: 850, loss: 0.04728461056947708
step: 860, loss: 0.05129649490118027
step: 870, loss: 0.03913501650094986
step: 880, loss: 0.09027264267206192
step: 890, loss: 0.14892537891864777
step: 900, loss: 0.05590490251779556
step: 910, loss: 0.05443330854177475
step: 920, loss: 0.0021483623422682285
step: 930, loss: 2.3898161089164205e-05
step: 940, loss: 0.008237953297793865
step: 950, loss: 0.02370775304734707
step: 960, loss: 0.07677213102579117
step: 970, loss: 0.014791540801525116
epoch 19: dev_f1=0.926944971537002, f1=0.9249646059462011, best_f1=0.9262672811059909
step: 0, loss: 0.03978660702705383
step: 10, loss: 0.025178495794534683
step: 20, loss: 0.06975394487380981
step: 30, loss: 0.028977109119296074
step: 40, loss: 0.07467176765203476
step: 50, loss: 0.046162448823451996
step: 60, loss: 0.05876142531633377
step: 70, loss: 0.03745173290371895
step: 80, loss: 0.024216216057538986
step: 90, loss: 0.00015397611423395574
step: 100, loss: 0.015399489551782608
step: 110, loss: 0.15301619470119476
step: 120, loss: 0.022463878616690636
step: 130, loss: 0.031717926263809204
step: 140, loss: 0.019113730639219284
step: 150, loss: 0.05746372044086456
step: 160, loss: 0.05502745509147644
step: 170, loss: 0.04052630439400673
step: 180, loss: 0.03384700044989586
step: 190, loss: 0.07968322932720184
step: 200, loss: 0.00781969167292118
step: 210, loss: 0.045152757316827774
step: 220, loss: 0.018119731917977333
step: 230, loss: 0.0366465300321579
step: 240, loss: 0.062474366277456284
step: 250, loss: 0.000350340036675334
step: 260, loss: 0.07386887818574905
step: 270, loss: 0.0001965345290955156
step: 280, loss: 0.16689158976078033
step: 290, loss: 0.014393690973520279
step: 300, loss: 0.06716728210449219
step: 310, loss: 0.014697566628456116
step: 320, loss: 0.0359090119600296
step: 330, loss: 0.04803948849439621
step: 340, loss: 0.045168474316596985
step: 350, loss: 0.024231210350990295
step: 360, loss: 0.2057175487279892
step: 370, loss: 0.03039560839533806
step: 380, loss: 0.016801517456769943
step: 390, loss: 0.022797247394919395
step: 400, loss: 0.08971250057220459
step: 410, loss: 0.06302426755428314
step: 420, loss: 0.064225934445858
step: 430, loss: 0.030126776546239853
step: 440, loss: 0.0782281681895256
step: 450, loss: 0.058659058064222336
step: 460, loss: 0.01758776232600212
step: 470, loss: 4.202403579256497e-05
step: 480, loss: 0.03335163742303848
step: 490, loss: 0.005635491106659174
step: 500, loss: 0.04171549156308174
step: 510, loss: 0.02811865508556366
step: 520, loss: 0.07568527013063431
step: 530, loss: 0.08746258914470673
step: 540, loss: 0.029983408749103546
step: 550, loss: 0.0610123947262764
step: 560, loss: 0.10401272028684616
step: 570, loss: 0.04099380224943161
step: 580, loss: 0.05766451358795166
step: 590, loss: 0.01762819103896618
step: 600, loss: 0.062244921922683716
step: 610, loss: 0.010653375647962093
step: 620, loss: 0.0579054020345211
step: 630, loss: 0.014318802393972874
step: 640, loss: 0.06185794249176979
step: 650, loss: 0.10415419936180115
step: 660, loss: 0.0028020450845360756
step: 670, loss: 0.06427233666181564
step: 680, loss: 0.02958495356142521
step: 690, loss: 0.04313300549983978
step: 700, loss: 0.007052537985146046
step: 710, loss: 0.04052755981683731
step: 720, loss: 0.07254479825496674
step: 730, loss: 0.0329507440328598
step: 740, loss: 0.018476568162441254
step: 750, loss: 0.021156853064894676
step: 760, loss: 0.00783926248550415
step: 770, loss: 0.06201476231217384
step: 780, loss: 0.03480911627411842
step: 790, loss: 0.10031448304653168
step: 800, loss: 0.03851833567023277
step: 810, loss: 0.1237465888261795
step: 820, loss: 0.013087810017168522
step: 830, loss: 0.0014861330855637789
step: 840, loss: 0.02031691186130047
step: 850, loss: 0.05457526072859764
step: 860, loss: 0.0267231073230505
step: 870, loss: 0.03660283610224724
step: 880, loss: 0.05066938325762749
step: 890, loss: 0.025944454595446587
step: 900, loss: 0.11650407314300537
step: 910, loss: 0.03140981122851372
step: 920, loss: 0.03978250175714493
step: 930, loss: 0.0992467850446701
step: 940, loss: 0.00018615915905684233
step: 950, loss: 0.08613695949316025
step: 960, loss: 0.06191350519657135
step: 970, loss: 0.008890336379408836
epoch 20: dev_f1=0.9269901083372586, f1=0.926463700234192, best_f1=0.9262672811059909
