cuda
Device: cuda
step: 0, loss: 0.6908623576164246
step: 10, loss: 0.29774701595306396
step: 20, loss: 0.2455040067434311
step: 30, loss: 0.27572622895240784
step: 40, loss: 0.174388587474823
step: 50, loss: 0.13042496144771576
step: 60, loss: 0.14786356687545776
step: 70, loss: 0.1425325572490692
step: 80, loss: 0.07425173372030258
step: 90, loss: 0.21312688291072845
step: 100, loss: 0.14517149329185486
step: 110, loss: 0.1238357350230217
step: 120, loss: 0.2390744686126709
step: 130, loss: 0.14720162749290466
step: 140, loss: 0.19137220084667206
step: 150, loss: 0.130705326795578
step: 160, loss: 0.29775702953338623
step: 170, loss: 0.2308884561061859
step: 180, loss: 0.16938841342926025
step: 190, loss: 0.07660622149705887
step: 200, loss: 0.20051653683185577
step: 210, loss: 0.16362795233726501
step: 220, loss: 0.21443776786327362
step: 230, loss: 0.08156833052635193
step: 240, loss: 0.2154874950647354
step: 250, loss: 0.21152709424495697
step: 260, loss: 0.15568490326404572
step: 270, loss: 0.19226202368736267
step: 280, loss: 0.3070034682750702
step: 290, loss: 0.1713956892490387
step: 300, loss: 0.07864704728126526
step: 310, loss: 0.12005980312824249
step: 320, loss: 0.13751095533370972
step: 330, loss: 0.13940508663654327
step: 340, loss: 0.24940930306911469
step: 350, loss: 0.29240772128105164
step: 360, loss: 0.1053670197725296
step: 370, loss: 0.07690538465976715
step: 380, loss: 0.1748390942811966
step: 390, loss: 0.0890451967716217
step: 400, loss: 0.06589999049901962
step: 410, loss: 0.15405882894992828
step: 420, loss: 0.14296749234199524
step: 430, loss: 0.11711738258600235
step: 440, loss: 0.32546067237854004
step: 450, loss: 0.12178916484117508
step: 460, loss: 0.13828125596046448
step: 470, loss: 0.10449159890413284
step: 480, loss: 0.12157684564590454
step: 490, loss: 0.09161598235368729
step: 500, loss: 0.13081738352775574
step: 510, loss: 0.14403267204761505
step: 520, loss: 0.2085820734500885
step: 530, loss: 0.2929065227508545
step: 540, loss: 0.14107133448123932
step: 550, loss: 0.18344752490520477
step: 560, loss: 0.06275784969329834
step: 570, loss: 0.22903726994991302
step: 580, loss: 0.14201542735099792
step: 590, loss: 0.16138051450252533
step: 600, loss: 0.10621649026870728
step: 610, loss: 0.24420855939388275
step: 620, loss: 0.18859334290027618
step: 630, loss: 0.10438895225524902
step: 640, loss: 0.2527652680873871
step: 650, loss: 0.055208466947078705
step: 660, loss: 0.20999786257743835
step: 670, loss: 0.14160671830177307
step: 680, loss: 0.20201866328716278
step: 690, loss: 0.08143465220928192
step: 700, loss: 0.04804378002882004
step: 710, loss: 0.11843960732221603
step: 720, loss: 0.1522108018398285
step: 730, loss: 0.13647069036960602
step: 740, loss: 0.2161179780960083
step: 750, loss: 0.08397296071052551
step: 760, loss: 0.15295806527137756
step: 770, loss: 0.17149224877357483
step: 780, loss: 0.13125605881214142
step: 790, loss: 0.06791108101606369
step: 800, loss: 0.3083754777908325
step: 810, loss: 0.0497150681912899
step: 820, loss: 0.1696317493915558
step: 830, loss: 0.11015763133764267
step: 840, loss: 0.20142781734466553
step: 850, loss: 0.14981216192245483
step: 860, loss: 0.304647833108902
step: 870, loss: 0.23466306924819946
step: 880, loss: 0.14013174176216125
step: 890, loss: 0.17458052933216095
step: 900, loss: 0.27292385697364807
step: 910, loss: 0.049744993448257446
step: 920, loss: 0.18660081923007965
step: 930, loss: 0.12136758863925934
step: 940, loss: 0.13458645343780518
step: 950, loss: 0.11256109923124313
step: 960, loss: 0.2354486733675003
step: 970, loss: 0.12266022711992264
epoch 1: dev_f1=0.9182736455463728, f1=0.9140767824497258, best_f1=0.9140767824497258
step: 0, loss: 0.11316413432359695
step: 10, loss: 0.08170910179615021
step: 20, loss: 0.16935157775878906
step: 30, loss: 0.08857107907533646
step: 40, loss: 0.18007537722587585
step: 50, loss: 0.10654131323099136
step: 60, loss: 0.23805692791938782
step: 70, loss: 0.16965597867965698
step: 80, loss: 0.230825275182724
step: 90, loss: 0.17469118535518646
step: 100, loss: 0.2867130637168884
step: 110, loss: 0.1260150969028473
step: 120, loss: 0.11015439033508301
step: 130, loss: 0.07059469819068909
step: 140, loss: 0.15757966041564941
step: 150, loss: 0.12073712795972824
step: 160, loss: 0.22559382021427155
step: 170, loss: 0.10376157611608505
step: 180, loss: 0.3933973014354706
step: 190, loss: 0.1400347501039505
step: 200, loss: 0.13783378899097443
step: 210, loss: 0.08277565240859985
step: 220, loss: 0.14365863800048828
step: 230, loss: 0.22727113962173462
step: 240, loss: 0.13069893419742584
step: 250, loss: 0.08094845712184906
step: 260, loss: 0.05022439733147621
step: 270, loss: 0.10008245706558228
step: 280, loss: 0.20390427112579346
step: 290, loss: 0.08492019027471542
step: 300, loss: 0.09146377444267273
step: 310, loss: 0.2763192057609558
step: 320, loss: 0.24112503230571747
step: 330, loss: 0.17056608200073242
step: 340, loss: 0.10756877809762955
step: 350, loss: 0.22355471551418304
step: 360, loss: 0.09315018355846405
step: 370, loss: 0.22237281501293182
step: 380, loss: 0.21669155359268188
step: 390, loss: 0.02885087952017784
step: 400, loss: 0.06788865476846695
step: 410, loss: 0.15946952998638153
step: 420, loss: 0.17352327704429626
step: 430, loss: 0.14754238724708557
step: 440, loss: 0.17094586789608002
step: 450, loss: 0.06736622750759125
step: 460, loss: 0.14065396785736084
step: 470, loss: 0.11714047193527222
step: 480, loss: 0.2893023192882538
step: 490, loss: 0.1434696763753891
step: 500, loss: 0.09270301461219788
step: 510, loss: 0.15936653316020966
step: 520, loss: 0.1189919263124466
step: 530, loss: 0.08192545920610428
step: 540, loss: 0.15498316287994385
step: 550, loss: 0.06063025817275047
step: 560, loss: 0.1621200442314148
step: 570, loss: 0.11561417579650879
step: 580, loss: 0.15327703952789307
step: 590, loss: 0.15422476828098297
step: 600, loss: 0.0828070193529129
step: 610, loss: 0.208631694316864
step: 620, loss: 0.21615070104599
step: 630, loss: 0.13119253516197205
step: 640, loss: 0.15772399306297302
step: 650, loss: 0.16213087737560272
step: 660, loss: 0.26447969675064087
step: 670, loss: 0.255238801240921
step: 680, loss: 0.06662094593048096
step: 690, loss: 0.16263075172901154
step: 700, loss: 0.08989576995372772
step: 710, loss: 0.15654444694519043
step: 720, loss: 0.10772696882486343
step: 730, loss: 0.13759973645210266
step: 740, loss: 0.13131330907344818
step: 750, loss: 0.0705486536026001
step: 760, loss: 0.22709639370441437
step: 770, loss: 0.09616638720035553
step: 780, loss: 0.15522444248199463
step: 790, loss: 0.09019884467124939
step: 800, loss: 0.14647053182125092
step: 810, loss: 0.060458745807409286
step: 820, loss: 0.266033798456192
step: 830, loss: 0.12764935195446014
step: 840, loss: 0.1587221771478653
step: 850, loss: 0.07160460948944092
step: 860, loss: 0.09931186586618423
step: 870, loss: 0.19918093085289001
step: 880, loss: 0.1316387951374054
step: 890, loss: 0.1226339116692543
step: 900, loss: 0.10765962302684784
step: 910, loss: 0.13039812445640564
step: 920, loss: 0.1471974104642868
step: 930, loss: 0.21567460894584656
step: 940, loss: 0.11630737036466599
step: 950, loss: 0.09832746535539627
step: 960, loss: 0.10287179797887802
step: 970, loss: 0.23424451053142548
epoch 2: dev_f1=0.9252767527675276, f1=0.923216719672876, best_f1=0.923216719672876
step: 0, loss: 0.1127682626247406
step: 10, loss: 0.09954369813203812
step: 20, loss: 0.2266755998134613
step: 30, loss: 0.14720416069030762
step: 40, loss: 0.12638188898563385
step: 50, loss: 0.035297542810440063
step: 60, loss: 0.08872183412313461
step: 70, loss: 0.15980276465415955
step: 80, loss: 0.09116433560848236
step: 90, loss: 0.18060341477394104
step: 100, loss: 0.12018068134784698
step: 110, loss: 0.07000742107629776
step: 120, loss: 0.13612835109233856
step: 130, loss: 0.14514291286468506
step: 140, loss: 0.04936516284942627
step: 150, loss: 0.03637957572937012
step: 160, loss: 0.12472750246524811
step: 170, loss: 0.05367731302976608
step: 180, loss: 0.05461056903004646
step: 190, loss: 0.08020498603582382
step: 200, loss: 0.05727561190724373
step: 210, loss: 0.13723254203796387
step: 220, loss: 0.0859299823641777
step: 230, loss: 0.17036062479019165
step: 240, loss: 0.20640817284584045
step: 250, loss: 0.07380465418100357
step: 260, loss: 0.1672821193933487
step: 270, loss: 0.05799418315291405
step: 280, loss: 0.1791391670703888
step: 290, loss: 0.10382449626922607
step: 300, loss: 0.15806379914283752
step: 310, loss: 0.08623525500297546
step: 320, loss: 0.08089742064476013
step: 330, loss: 0.08976864069700241
step: 340, loss: 0.06130049005150795
step: 350, loss: 0.16553622484207153
step: 360, loss: 0.09691520780324936
step: 370, loss: 0.10165011137723923
step: 380, loss: 0.0109260780736804
step: 390, loss: 0.2630564272403717
step: 400, loss: 0.1067100539803505
step: 410, loss: 0.0848793014883995
step: 420, loss: 0.1655391901731491
step: 430, loss: 0.1941417008638382
step: 440, loss: 0.053661081939935684
step: 450, loss: 0.04030624032020569
step: 460, loss: 0.07255871593952179
step: 470, loss: 0.08179721236228943
step: 480, loss: 0.17089667916297913
step: 490, loss: 0.14789357781410217
step: 500, loss: 0.05778774991631508
step: 510, loss: 0.10996746271848679
step: 520, loss: 0.06080366298556328
step: 530, loss: 0.09372689574956894
step: 540, loss: 0.061406493186950684
step: 550, loss: 0.13359270989894867
step: 560, loss: 0.15927809476852417
step: 570, loss: 0.11461536586284637
step: 580, loss: 0.11382249742746353
step: 590, loss: 0.21591243147850037
step: 600, loss: 0.11185529828071594
step: 610, loss: 0.11713158339262009
step: 620, loss: 0.047939199954271317
step: 630, loss: 0.07323569804430008
step: 640, loss: 0.11081287264823914
step: 650, loss: 0.12617254257202148
step: 660, loss: 0.06781409680843353
step: 670, loss: 0.10518528521060944
step: 680, loss: 0.1603945791721344
step: 690, loss: 0.11370878666639328
step: 700, loss: 0.132587730884552
step: 710, loss: 0.08969851583242416
step: 720, loss: 0.14786632359027863
step: 730, loss: 0.08828539401292801
step: 740, loss: 0.18854869902133942
step: 750, loss: 0.09906124323606491
step: 760, loss: 0.07329417765140533
step: 770, loss: 0.025321457535028458
step: 780, loss: 0.020971788093447685
step: 790, loss: 0.13124127686023712
step: 800, loss: 0.30631065368652344
step: 810, loss: 0.07922082394361496
step: 820, loss: 0.11600691825151443
step: 830, loss: 0.0502951480448246
step: 840, loss: 0.09936007857322693
step: 850, loss: 0.04655124247074127
step: 860, loss: 0.1750974953174591
step: 870, loss: 0.08310776948928833
step: 880, loss: 0.2244470864534378
step: 890, loss: 0.12258493900299072
step: 900, loss: 0.2294396162033081
step: 910, loss: 0.19595807790756226
step: 920, loss: 0.1474839746952057
step: 930, loss: 0.10910943895578384
step: 940, loss: 0.05319715291261673
step: 950, loss: 0.14119777083396912
step: 960, loss: 0.12122726440429688
step: 970, loss: 0.09360843896865845
epoch 3: dev_f1=0.932901434521055, f1=0.9225058004640372, best_f1=0.9225058004640372
step: 0, loss: 0.03519247844815254
step: 10, loss: 0.16516253352165222
step: 20, loss: 0.05475534871220589
step: 30, loss: 0.1532711684703827
step: 40, loss: 0.10542262345552444
step: 50, loss: 0.1290077269077301
step: 60, loss: 0.11409997940063477
step: 70, loss: 0.04642633721232414
step: 80, loss: 0.038682106882333755
step: 90, loss: 0.07492352277040482
step: 100, loss: 0.085811547935009
step: 110, loss: 0.09728614240884781
step: 120, loss: 0.07168219238519669
step: 130, loss: 0.11150481551885605
step: 140, loss: 0.06443851441144943
step: 150, loss: 0.029843799769878387
step: 160, loss: 0.0392901673913002
step: 170, loss: 0.21466238796710968
step: 180, loss: 0.11254315078258514
step: 190, loss: 0.03464064747095108
step: 200, loss: 0.06593093276023865
step: 210, loss: 0.14880533516407013
step: 220, loss: 0.1340298354625702
step: 230, loss: 0.12711060047149658
step: 240, loss: 0.11368612945079803
step: 250, loss: 0.12503626942634583
step: 260, loss: 0.05113958194851875
step: 270, loss: 0.13391105830669403
step: 280, loss: 0.11806521564722061
step: 290, loss: 0.153290793299675
step: 300, loss: 0.2237822264432907
step: 310, loss: 0.04146120697259903
step: 320, loss: 0.04307263717055321
step: 330, loss: 0.0666235014796257
step: 340, loss: 0.11797233670949936
step: 350, loss: 0.06912565976381302
step: 360, loss: 0.14038093388080597
step: 370, loss: 0.026028595864772797
step: 380, loss: 0.05562927946448326
step: 390, loss: 0.16703283786773682
step: 400, loss: 0.033107515424489975
step: 410, loss: 0.2673523724079132
step: 420, loss: 0.023763101547956467
step: 430, loss: 0.07290145754814148
step: 440, loss: 0.1142597571015358
step: 450, loss: 0.15366047620773315
step: 460, loss: 0.13066013157367706
step: 470, loss: 0.08163154870271683
step: 480, loss: 0.14941103756427765
step: 490, loss: 0.07421305775642395
step: 500, loss: 0.15614953637123108
step: 510, loss: 0.11060446500778198
step: 520, loss: 0.09198861569166183
step: 530, loss: 0.17833097279071808
step: 540, loss: 0.19053608179092407
step: 550, loss: 0.15533746778964996
step: 560, loss: 0.12685468792915344
step: 570, loss: 0.12508563697338104
step: 580, loss: 0.1371815949678421
step: 590, loss: 0.06205010041594505
step: 600, loss: 0.0956236869096756
step: 610, loss: 0.14829394221305847
step: 620, loss: 0.08616473525762558
step: 630, loss: 0.08656205981969833
step: 640, loss: 0.11316217482089996
step: 650, loss: 0.06509269028902054
step: 660, loss: 0.17060253024101257
step: 670, loss: 0.03992610424757004
step: 680, loss: 0.09032890200614929
step: 690, loss: 0.08798833191394806
step: 700, loss: 0.034131553024053574
step: 710, loss: 0.06260255724191666
step: 720, loss: 0.13213855028152466
step: 730, loss: 0.11940548568964005
step: 740, loss: 0.12174579501152039
step: 750, loss: 0.2787633240222931
step: 760, loss: 0.12378013134002686
step: 770, loss: 0.20141856372356415
step: 780, loss: 0.1974264532327652
step: 790, loss: 0.07001690566539764
step: 800, loss: 0.13649152219295502
step: 810, loss: 0.17543257772922516
step: 820, loss: 0.05330218747258186
step: 830, loss: 0.18393978476524353
step: 840, loss: 0.15594185888767242
step: 850, loss: 0.04485900327563286
step: 860, loss: 0.09985911101102829
step: 870, loss: 0.16651049256324768
step: 880, loss: 0.08788815885782242
step: 890, loss: 0.14765000343322754
step: 900, loss: 0.1550155133008957
step: 910, loss: 0.06544356048107147
step: 920, loss: 0.07246477901935577
step: 930, loss: 0.0962328314781189
step: 940, loss: 0.14349018037319183
step: 950, loss: 0.2287929207086563
step: 960, loss: 0.13583596050739288
step: 970, loss: 0.1402183175086975
epoch 4: dev_f1=0.9112040911204091, f1=0.9106067623899954, best_f1=0.9225058004640372
step: 0, loss: 0.08339862525463104
step: 10, loss: 0.02927103452384472
step: 20, loss: 0.05959376320242882
step: 30, loss: 0.14021262526512146
step: 40, loss: 0.06719972938299179
step: 50, loss: 0.08347930014133453
step: 60, loss: 0.04990417882800102
step: 70, loss: 0.05597205087542534
step: 80, loss: 0.10292578488588333
step: 90, loss: 0.08165622502565384
step: 100, loss: 0.028854267671704292
step: 110, loss: 0.0269180815666914
step: 120, loss: 0.0474475622177124
step: 130, loss: 0.030167579650878906
step: 140, loss: 0.08669418841600418
step: 150, loss: 0.045831553637981415
step: 160, loss: 0.22191272675991058
step: 170, loss: 0.20544931292533875
step: 180, loss: 0.024073123931884766
step: 190, loss: 0.07897186279296875
step: 200, loss: 0.07918165624141693
step: 210, loss: 0.10704714059829712
step: 220, loss: 0.09506822377443314
step: 230, loss: 0.12731286883354187
step: 240, loss: 0.08048462122678757
step: 250, loss: 0.06098487228155136
step: 260, loss: 0.14171607792377472
step: 270, loss: 0.33822643756866455
step: 280, loss: 0.1828654408454895
step: 290, loss: 0.11543124914169312
step: 300, loss: 0.08708053082227707
step: 310, loss: 0.041904717683792114
step: 320, loss: 0.11378894746303558
step: 330, loss: 0.1641864776611328
step: 340, loss: 0.06244460493326187
step: 350, loss: 0.1623251736164093
step: 360, loss: 0.09178149700164795
step: 370, loss: 0.08727545291185379
step: 380, loss: 0.05334480106830597
step: 390, loss: 0.11327988654375076
step: 400, loss: 0.13246050477027893
step: 410, loss: 0.18098364770412445
step: 420, loss: 0.05826039984822273
step: 430, loss: 0.19071990251541138
step: 440, loss: 0.1039717048406601
step: 450, loss: 0.07810676842927933
step: 460, loss: 0.11246379464864731
step: 470, loss: 0.07492464780807495
step: 480, loss: 0.06465999037027359
step: 490, loss: 0.023921649903059006
step: 500, loss: 0.12085703015327454
step: 510, loss: 0.023903528228402138
step: 520, loss: 0.07375500351190567
step: 530, loss: 0.10063154250383377
step: 540, loss: 0.2309279441833496
step: 550, loss: 0.20271046459674835
step: 560, loss: 0.07032724469900131
step: 570, loss: 0.030600668862462044
step: 580, loss: 0.07498008012771606
step: 590, loss: 0.1262044608592987
step: 600, loss: 0.13555091619491577
step: 610, loss: 0.09977263957262039
step: 620, loss: 0.2517735958099365
step: 630, loss: 0.06635860353708267
step: 640, loss: 0.13648827373981476
step: 650, loss: 0.02264876663684845
step: 660, loss: 0.16830649971961975
step: 670, loss: 0.05611481890082359
step: 680, loss: 0.16115622222423553
step: 690, loss: 0.14983107149600983
step: 700, loss: 0.13340963423252106
step: 710, loss: 0.2549675703048706
step: 720, loss: 0.08017157763242722
step: 730, loss: 0.08372971415519714
step: 740, loss: 0.04258350655436516
step: 750, loss: 0.15179851651191711
step: 760, loss: 0.2283809781074524
step: 770, loss: 0.11384683102369308
step: 780, loss: 0.11928422749042511
step: 790, loss: 0.027547385543584824
step: 800, loss: 0.15392550826072693
step: 810, loss: 0.1908072531223297
step: 820, loss: 0.10264865309000015
step: 830, loss: 0.09099119156599045
step: 840, loss: 0.15525507926940918
step: 850, loss: 0.09348148852586746
step: 860, loss: 0.159220889210701
step: 870, loss: 0.27503958344459534
step: 880, loss: 0.25065526366233826
step: 890, loss: 0.07150246202945709
step: 900, loss: 0.10424121469259262
step: 910, loss: 0.13885381817817688
step: 920, loss: 0.10418184846639633
step: 930, loss: 0.050571706146001816
step: 940, loss: 0.10843194276094437
step: 950, loss: 0.05652192234992981
step: 960, loss: 0.15741197764873505
step: 970, loss: 0.11476568132638931
epoch 5: dev_f1=0.9308056872037914, f1=0.9290444654683065, best_f1=0.9225058004640372
step: 0, loss: 0.10294666141271591
step: 10, loss: 0.02296425588428974
step: 20, loss: 0.17160123586654663
step: 30, loss: 0.04892146959900856
step: 40, loss: 0.10304331034421921
step: 50, loss: 0.17560605704784393
step: 60, loss: 0.008526475168764591
step: 70, loss: 0.07115389406681061
step: 80, loss: 0.040938373655080795
step: 90, loss: 0.041158176958560944
step: 100, loss: 0.023568928241729736
step: 110, loss: 0.10977347940206528
step: 120, loss: 0.04133256524801254
step: 130, loss: 0.11431555449962616
step: 140, loss: 0.03485951945185661
step: 150, loss: 0.15383048355579376
step: 160, loss: 0.1267329454421997
step: 170, loss: 0.11387638002634048
step: 180, loss: 0.06358075886964798
step: 190, loss: 0.12109322845935822
step: 200, loss: 0.13152186572551727
step: 210, loss: 0.21885719895362854
step: 220, loss: 0.041025228798389435
step: 230, loss: 0.09117688983678818
step: 240, loss: 0.12273260205984116
step: 250, loss: 0.06796984374523163
step: 260, loss: 0.08372055739164352
step: 270, loss: 0.07843904197216034
step: 280, loss: 0.16826483607292175
step: 290, loss: 0.04275808855891228
step: 300, loss: 0.07154203206300735
step: 310, loss: 0.09479590505361557
step: 320, loss: 0.11050640046596527
step: 330, loss: 0.09351781755685806
step: 340, loss: 0.11187104880809784
step: 350, loss: 0.15625235438346863
step: 360, loss: 0.046295277774333954
step: 370, loss: 0.2571656405925751
step: 380, loss: 0.09905029833316803
step: 390, loss: 0.035005420446395874
step: 400, loss: 0.04335353150963783
step: 410, loss: 0.06379646062850952
step: 420, loss: 0.19143395125865936
step: 430, loss: 0.19945229589939117
step: 440, loss: 0.07156979292631149
step: 450, loss: 0.052561867982149124
step: 460, loss: 0.18686087429523468
step: 470, loss: 0.029991041868925095
step: 480, loss: 0.09756290167570114
step: 490, loss: 0.148016557097435
step: 500, loss: 0.10017410665750504
step: 510, loss: 0.16592289507389069
step: 520, loss: 0.12478222697973251
step: 530, loss: 0.0566115640103817
step: 540, loss: 0.17552411556243896
step: 550, loss: 0.18599390983581543
step: 560, loss: 0.08064387738704681
step: 570, loss: 0.07375561445951462
step: 580, loss: 0.10033653676509857
step: 590, loss: 0.10692226141691208
step: 600, loss: 0.09344818443059921
step: 610, loss: 0.16411006450653076
step: 620, loss: 0.21182967722415924
step: 630, loss: 0.09890024363994598
step: 640, loss: 0.0827317163348198
step: 650, loss: 0.22956453263759613
step: 660, loss: 0.06773121654987335
step: 670, loss: 0.05841689929366112
step: 680, loss: 0.13034120202064514
step: 690, loss: 0.05240071937441826
step: 700, loss: 0.06542741507291794
step: 710, loss: 0.2849440574645996
step: 720, loss: 0.08014342188835144
step: 730, loss: 0.1261853575706482
step: 740, loss: 0.12994559109210968
step: 750, loss: 0.044863101094961166
step: 760, loss: 0.07461077719926834
step: 770, loss: 0.12230570614337921
step: 780, loss: 0.2188407927751541
step: 790, loss: 0.10481227934360504
step: 800, loss: 0.06455682218074799
step: 810, loss: 0.14845919609069824
step: 820, loss: 0.11466334760189056
step: 830, loss: 0.05485473573207855
step: 840, loss: 0.052005037665367126
step: 850, loss: 0.1532619744539261
step: 860, loss: 0.08626978099346161
step: 870, loss: 0.1560095101594925
step: 880, loss: 0.07501468062400818
step: 890, loss: 0.08664669096469879
step: 900, loss: 0.048790786415338516
step: 910, loss: 0.12443273514509201
step: 920, loss: 0.0853656455874443
step: 930, loss: 0.07034867256879807
step: 940, loss: 0.047742266207933426
step: 950, loss: 0.08345954865217209
step: 960, loss: 0.10460703819990158
step: 970, loss: 0.1347385048866272
epoch 6: dev_f1=0.925589836660617, f1=0.9253055681303757, best_f1=0.9225058004640372
step: 0, loss: 0.06153703108429909
step: 10, loss: 0.06220436468720436
step: 20, loss: 0.020461291074752808
step: 30, loss: 0.045081883668899536
step: 40, loss: 0.040089644491672516
step: 50, loss: 0.008672700263559818
step: 60, loss: 0.07223211228847504
step: 70, loss: 0.028978688642382622
step: 80, loss: 0.1414482295513153
step: 90, loss: 0.0059553165920078754
step: 100, loss: 0.14593565464019775
step: 110, loss: 0.11006265133619308
step: 120, loss: 0.04924323782324791
step: 130, loss: 0.09643302857875824
step: 140, loss: 0.09856574237346649
step: 150, loss: 0.04475807398557663
step: 160, loss: 0.10819938033819199
step: 170, loss: 0.05836603417992592
step: 180, loss: 0.05006115883588791
step: 190, loss: 0.20001348853111267
step: 200, loss: 0.0562206469476223
step: 210, loss: 0.023428119719028473
step: 220, loss: 0.1477414071559906
step: 230, loss: 0.0380825437605381
step: 240, loss: 0.07803541421890259
step: 250, loss: 0.08802583813667297
step: 260, loss: 0.008582943119108677
step: 270, loss: 0.16992433369159698
step: 280, loss: 0.08465755730867386
step: 290, loss: 0.08833527565002441
step: 300, loss: 0.03642047196626663
step: 310, loss: 0.1248633936047554
step: 320, loss: 0.10757999867200851
step: 330, loss: 0.005653514992445707
step: 340, loss: 0.07315132021903992
step: 350, loss: 0.24210934340953827
step: 360, loss: 0.036218978464603424
step: 370, loss: 0.07675915211439133
step: 380, loss: 0.0736694261431694
step: 390, loss: 0.12005140632390976
step: 400, loss: 0.0656958743929863
step: 410, loss: 0.0964607447385788
step: 420, loss: 0.10547928512096405
step: 430, loss: 0.054780568927526474
step: 440, loss: 0.05252492055296898
step: 450, loss: 0.057785145938396454
step: 460, loss: 0.14385508000850677
step: 470, loss: 0.15937653183937073
step: 480, loss: 0.09502563625574112
step: 490, loss: 0.17902526259422302
step: 500, loss: 0.050946999341249466
step: 510, loss: 0.07233162969350815
step: 520, loss: 0.040051527321338654
step: 530, loss: 0.06915082782506943
step: 540, loss: 0.046591151505708694
step: 550, loss: 0.0489250048995018
step: 560, loss: 0.08186905086040497
step: 570, loss: 0.07476189732551575
step: 580, loss: 0.0839419811964035
step: 590, loss: 0.09929271787405014
step: 600, loss: 0.17620821297168732
step: 610, loss: 0.09728004038333893
step: 620, loss: 0.08444003015756607
step: 630, loss: 0.09681909531354904
step: 640, loss: 0.11385145038366318
step: 650, loss: 0.10338936746120453
step: 660, loss: 0.08020708709955215
step: 670, loss: 0.08944647014141083
step: 680, loss: 0.1393982470035553
step: 690, loss: 0.1265784353017807
step: 700, loss: 0.18447808921337128
step: 710, loss: 0.06695574522018433
step: 720, loss: 0.17861458659172058
step: 730, loss: 0.23684002459049225
step: 740, loss: 0.12264310568571091
step: 750, loss: 0.06133906543254852
step: 760, loss: 0.13488534092903137
step: 770, loss: 0.047800369560718536
step: 780, loss: 0.23129454255104065
step: 790, loss: 0.17660215497016907
step: 800, loss: 0.1297939270734787
step: 810, loss: 0.07340957969427109
step: 820, loss: 0.1445736289024353
step: 830, loss: 0.09913486242294312
step: 840, loss: 0.0947732925415039
step: 850, loss: 0.1381097435951233
step: 860, loss: 0.05787619948387146
step: 870, loss: 0.03639489784836769
step: 880, loss: 0.127688467502594
step: 890, loss: 0.046998798847198486
step: 900, loss: 0.08844321966171265
step: 910, loss: 0.10714291036128998
step: 920, loss: 0.025074316188693047
step: 930, loss: 0.038779012858867645
step: 940, loss: 0.02104916051030159
step: 950, loss: 0.12919177114963531
step: 960, loss: 0.04747903719544411
step: 970, loss: 0.07149837166070938
epoch 7: dev_f1=0.9284386617100371, f1=0.925719591457753, best_f1=0.9225058004640372
step: 0, loss: 0.07139589637517929
step: 10, loss: 0.10367589443922043
step: 20, loss: 0.10722315311431885
step: 30, loss: 0.14775268733501434
step: 40, loss: 0.07592222094535828
step: 50, loss: 0.15718333423137665
step: 60, loss: 0.056564267724752426
step: 70, loss: 0.03389817848801613
step: 80, loss: 0.08117345720529556
step: 90, loss: 0.1298784464597702
step: 100, loss: 0.04081311076879501
step: 110, loss: 0.08951853215694427
step: 120, loss: 0.08770227432250977
step: 130, loss: 0.09590531140565872
step: 140, loss: 0.12284792959690094
step: 150, loss: 0.057662393897771835
step: 160, loss: 0.07038798183202744
step: 170, loss: 0.08008678257465363
step: 180, loss: 0.14850853383541107
step: 190, loss: 0.13446977734565735
step: 200, loss: 0.014852091670036316
step: 210, loss: 0.07943610101938248
step: 220, loss: 0.03325089067220688
step: 230, loss: 0.11306888610124588
step: 240, loss: 0.030413059517741203
step: 250, loss: 0.1536167711019516
step: 260, loss: 0.06387285888195038
step: 270, loss: 0.07528923451900482
step: 280, loss: 0.026569603011012077
step: 290, loss: 0.04206429794430733
step: 300, loss: 0.11557424813508987
step: 310, loss: 0.06607942283153534
step: 320, loss: 0.14026178419589996
step: 330, loss: 0.08443839848041534
step: 340, loss: 0.11454012989997864
step: 350, loss: 0.03526477515697479
step: 360, loss: 0.023045849055051804
step: 370, loss: 0.33567243814468384
step: 380, loss: 0.039793387055397034
step: 390, loss: 0.15882763266563416
step: 400, loss: 0.10735290497541428
step: 410, loss: 0.05832705274224281
step: 420, loss: 0.17924529314041138
step: 430, loss: 0.041614189743995667
step: 440, loss: 0.06559579074382782
step: 450, loss: 0.07205445319414139
step: 460, loss: 0.16274599730968475
step: 470, loss: 0.0930856391787529
step: 480, loss: 0.04976992309093475
step: 490, loss: 0.08672480285167694
step: 500, loss: 0.09432898461818695
step: 510, loss: 0.03957796096801758
step: 520, loss: 0.07857280969619751
step: 530, loss: 0.03708499297499657
step: 540, loss: 0.1679043173789978
step: 550, loss: 0.06887960433959961
step: 560, loss: 0.09290596842765808
step: 570, loss: 0.03536919504404068
step: 580, loss: 0.061313748359680176
step: 590, loss: 0.059722788631916046
step: 600, loss: 0.05340656265616417
step: 610, loss: 0.03998463973402977
step: 620, loss: 0.18145495653152466
step: 630, loss: 0.0567028746008873
step: 640, loss: 0.051969658583402634
step: 650, loss: 0.02955779805779457
step: 660, loss: 0.10949347913265228
step: 670, loss: 0.02126346528530121
step: 680, loss: 0.03481173515319824
step: 690, loss: 0.14597341418266296
step: 700, loss: 0.03300882875919342
step: 710, loss: 0.09132895618677139
step: 720, loss: 0.08075165748596191
step: 730, loss: 0.054830536246299744
step: 740, loss: 0.06232628971338272
step: 750, loss: 0.10077167302370071
step: 760, loss: 0.062027569860219955
step: 770, loss: 0.04055304825305939
step: 780, loss: 0.09558272361755371
step: 790, loss: 0.0478212796151638
step: 800, loss: 0.06572674959897995
step: 810, loss: 0.06671784818172455
step: 820, loss: 0.17515525221824646
step: 830, loss: 0.05956875532865524
step: 840, loss: 0.04570876806974411
step: 850, loss: 0.08092018961906433
step: 860, loss: 0.05617600679397583
step: 870, loss: 0.05912698060274124
step: 880, loss: 0.3199692368507385
step: 890, loss: 0.06401561200618744
step: 900, loss: 0.0405394583940506
step: 910, loss: 0.04059919714927673
step: 920, loss: 0.07157200574874878
step: 930, loss: 0.19945664703845978
step: 940, loss: 0.060787420719861984
step: 950, loss: 0.10705763101577759
step: 960, loss: 0.07974350452423096
step: 970, loss: 0.020984787493944168
epoch 8: dev_f1=0.9248014946286782, f1=0.9237961664329126, best_f1=0.9225058004640372
step: 0, loss: 0.029448555782437325
step: 10, loss: 0.027733884751796722
step: 20, loss: 0.011183660477399826
step: 30, loss: 0.07292572408914566
step: 40, loss: 0.00850003957748413
step: 50, loss: 0.05241567641496658
step: 60, loss: 0.04100799188017845
step: 70, loss: 0.06209385395050049
step: 80, loss: 0.03609856963157654
step: 90, loss: 0.03219253197312355
step: 100, loss: 0.13577061891555786
step: 110, loss: 0.05809985473752022
step: 120, loss: 0.04227646812796593
step: 130, loss: 0.08138838410377502
step: 140, loss: 0.12208450585603714
step: 150, loss: 0.05732621252536774
step: 160, loss: 0.0887058824300766
step: 170, loss: 0.06047437712550163
step: 180, loss: 0.086878202855587
step: 190, loss: 0.06674110889434814
step: 200, loss: 0.04484681785106659
step: 210, loss: 0.023162076249718666
step: 220, loss: 0.10109201818704605
step: 230, loss: 0.07783805578947067
step: 240, loss: 0.015135785564780235
step: 250, loss: 0.06673081964254379
step: 260, loss: 0.11313942074775696
step: 270, loss: 0.05644741281867027
step: 280, loss: 0.05227939411997795
step: 290, loss: 0.07334497570991516
step: 300, loss: 0.04308202862739563
step: 310, loss: 0.18207724392414093
step: 320, loss: 0.09366980195045471
step: 330, loss: 0.15797051787376404
step: 340, loss: 0.11735241860151291
step: 350, loss: 0.020026836544275284
step: 360, loss: 0.08921036869287491
step: 370, loss: 0.2375655174255371
step: 380, loss: 0.08641426265239716
step: 390, loss: 0.030430059880018234
step: 400, loss: 0.05561140179634094
step: 410, loss: 0.09052102267742157
step: 420, loss: 0.04140608385205269
step: 430, loss: 0.08501316606998444
step: 440, loss: 0.13389182090759277
step: 450, loss: 0.07354293763637543
step: 460, loss: 0.11918522417545319
step: 470, loss: 0.0608585923910141
step: 480, loss: 0.11443429440259933
step: 490, loss: 0.1911725252866745
step: 500, loss: 0.11883179843425751
step: 510, loss: 0.045015547424554825
step: 520, loss: 0.07072219997644424
step: 530, loss: 0.07467355579137802
step: 540, loss: 0.057727131992578506
step: 550, loss: 0.08924554288387299
step: 560, loss: 0.10106340050697327
step: 570, loss: 0.1303228735923767
step: 580, loss: 0.07355155050754547
step: 590, loss: 0.03250966966152191
step: 600, loss: 0.10441689193248749
step: 610, loss: 0.06568043678998947
step: 620, loss: 0.10732442140579224
step: 630, loss: 0.032251548022031784
step: 640, loss: 0.0833430364727974
step: 650, loss: 0.0849488228559494
step: 660, loss: 0.30005234479904175
step: 670, loss: 0.07053062319755554
step: 680, loss: 0.10139504075050354
step: 690, loss: 0.031899433583021164
step: 700, loss: 0.09928634762763977
step: 710, loss: 0.09138300269842148
step: 720, loss: 0.09438914060592651
step: 730, loss: 0.039176102727651596
step: 740, loss: 0.08584585040807724
step: 750, loss: 0.18795327842235565
step: 760, loss: 0.03834982216358185
step: 770, loss: 0.12859894335269928
step: 780, loss: 0.0750921368598938
step: 790, loss: 0.05692178010940552
step: 800, loss: 0.09728290140628815
step: 810, loss: 0.24353663623332977
step: 820, loss: 0.11376987397670746
step: 830, loss: 0.1759217381477356
step: 840, loss: 0.2563766837120056
step: 850, loss: 0.16363929212093353
step: 860, loss: 0.14304710924625397
step: 870, loss: 0.09757735580205917
step: 880, loss: 0.035528261214494705
step: 890, loss: 0.06607642769813538
step: 900, loss: 0.023807941004633904
step: 910, loss: 0.09227944910526276
step: 920, loss: 0.05038919299840927
step: 930, loss: 0.05324121564626694
step: 940, loss: 0.061765722930431366
step: 950, loss: 0.08431820571422577
step: 960, loss: 0.022633682936429977
step: 970, loss: 0.07544922828674316
epoch 9: dev_f1=0.9237132352941178, f1=0.9270307480495641, best_f1=0.9225058004640372
step: 0, loss: 0.001640229718759656
step: 10, loss: 0.07260052859783173
step: 20, loss: 0.020828694105148315
step: 30, loss: 0.1720961630344391
step: 40, loss: 0.1433795541524887
step: 50, loss: 0.04280850663781166
step: 60, loss: 0.03999455273151398
step: 70, loss: 0.06828488409519196
step: 80, loss: 0.028754759579896927
step: 90, loss: 0.12126568704843521
step: 100, loss: 0.07715658098459244
step: 110, loss: 0.060199640691280365
step: 120, loss: 0.1414242535829544
step: 130, loss: 0.10578876733779907
step: 140, loss: 0.016821760684251785
step: 150, loss: 0.06345078349113464
step: 160, loss: 0.009946795180439949
step: 170, loss: 0.11034004390239716
step: 180, loss: 0.12341052293777466
step: 190, loss: 0.00988624058663845
step: 200, loss: 0.07420893758535385
step: 210, loss: 0.04204726964235306
step: 220, loss: 0.033706583082675934
step: 230, loss: 0.04555187746882439
step: 240, loss: 0.1993287205696106
step: 250, loss: 0.006518318317830563
step: 260, loss: 0.0922541692852974
step: 270, loss: 0.05716501921415329
step: 280, loss: 0.07673586159944534
step: 290, loss: 0.01514249388128519
step: 300, loss: 0.014925562776625156
step: 310, loss: 0.13016359508037567
step: 320, loss: 0.08853914588689804
step: 330, loss: 0.080490343272686
step: 340, loss: 0.106017105281353
step: 350, loss: 0.02005785144865513
step: 360, loss: 0.16540682315826416
step: 370, loss: 0.042775146663188934
step: 380, loss: 0.13532567024230957
step: 390, loss: 0.12142045050859451
step: 400, loss: 0.0860849916934967
step: 410, loss: 0.033568307757377625
step: 420, loss: 0.00010938561899820343
step: 430, loss: 0.06503497809171677
step: 440, loss: 0.1012856662273407
step: 450, loss: 0.07169220596551895
step: 460, loss: 0.06133276969194412
step: 470, loss: 0.2229750007390976
step: 480, loss: 0.11395018547773361
step: 490, loss: 0.034720875322818756
step: 500, loss: 0.018194744363427162
step: 510, loss: 0.028304601088166237
step: 520, loss: 0.1967405080795288
step: 530, loss: 0.06237331032752991
step: 540, loss: 0.23820742964744568
step: 550, loss: 0.021228957921266556
step: 560, loss: 0.0762266144156456
step: 570, loss: 0.06791036576032639
step: 580, loss: 0.06998499482870102
step: 590, loss: 0.01915612444281578
step: 600, loss: 0.09034402668476105
step: 610, loss: 0.0809125155210495
step: 620, loss: 0.08578143268823624
step: 630, loss: 0.01882435567677021
step: 640, loss: 0.10255766659975052
step: 650, loss: 0.011093787848949432
step: 660, loss: 0.07044424116611481
step: 670, loss: 0.015389966778457165
step: 680, loss: 0.051921676844358444
step: 690, loss: 0.03520166128873825
step: 700, loss: 0.0906536728143692
step: 710, loss: 0.023148313164711
step: 720, loss: 0.06385167688131332
step: 730, loss: 0.11603382974863052
step: 740, loss: 0.14773881435394287
step: 750, loss: 0.0919957160949707
step: 760, loss: 0.16327333450317383
step: 770, loss: 0.03633599355816841
step: 780, loss: 0.1610354483127594
step: 790, loss: 0.08270212262868881
step: 800, loss: 0.09136427938938141
step: 810, loss: 0.09379900246858597
step: 820, loss: 0.024992166087031364
step: 830, loss: 0.12068873643875122
step: 840, loss: 0.054835155606269836
step: 850, loss: 0.06612055003643036
step: 860, loss: 0.28331050276756287
step: 870, loss: 0.06496797502040863
step: 880, loss: 0.03654899075627327
step: 890, loss: 0.10628648102283478
step: 900, loss: 0.016098037362098694
step: 910, loss: 0.05722276121377945
step: 920, loss: 0.05017871409654617
step: 930, loss: 0.04960789903998375
step: 940, loss: 0.10443037003278732
step: 950, loss: 0.04391971230506897
step: 960, loss: 0.016467684879899025
step: 970, loss: 0.08350948989391327
epoch 10: dev_f1=0.927348449791763, f1=0.9231477220432581, best_f1=0.9225058004640372
step: 0, loss: 0.10518305748701096
step: 10, loss: 0.10336249321699142
step: 20, loss: 0.13786444067955017
step: 30, loss: 0.052038390189409256
step: 40, loss: 0.06541034579277039
step: 50, loss: 0.03645803779363632
step: 60, loss: 0.029648443683981895
step: 70, loss: 0.05683596432209015
step: 80, loss: 0.08740074187517166
step: 90, loss: 0.04780612513422966
step: 100, loss: 0.01940866746008396
step: 110, loss: 0.011861560866236687
step: 120, loss: 0.24108870327472687
step: 130, loss: 0.11480185389518738
step: 140, loss: 0.08851329982280731
step: 150, loss: 0.04686856269836426
step: 160, loss: 0.05117777734994888
step: 170, loss: 0.06846190243959427
step: 180, loss: 0.11470066010951996
step: 190, loss: 0.026051348075270653
step: 200, loss: 0.03945421427488327
step: 210, loss: 0.07854175567626953
step: 220, loss: 0.14697697758674622
step: 230, loss: 0.0436328761279583
step: 240, loss: 0.13180923461914062
step: 250, loss: 0.03131582587957382
step: 260, loss: 0.02473589777946472
step: 270, loss: 0.11471012234687805
step: 280, loss: 0.16292396187782288
step: 290, loss: 0.06924646347761154
step: 300, loss: 0.03267568349838257
step: 310, loss: 0.0774478167295456
step: 320, loss: 0.11469395458698273
step: 330, loss: 0.11910906434059143
step: 340, loss: 0.010469741187989712
step: 350, loss: 0.038929153233766556
step: 360, loss: 0.04372089356184006
step: 370, loss: 0.028031310066580772
step: 380, loss: 0.13863423466682434
step: 390, loss: 0.017994046211242676
step: 400, loss: 0.06163407117128372
step: 410, loss: 0.08943898975849152
step: 420, loss: 0.13345512747764587
step: 430, loss: 0.0502563938498497
step: 440, loss: 0.028557945042848587
step: 450, loss: 0.04781545698642731
step: 460, loss: 0.06739289313554764
step: 470, loss: 0.04093318432569504
step: 480, loss: 0.019826801493763924
step: 490, loss: 0.019834397360682487
step: 500, loss: 0.03628204017877579
step: 510, loss: 0.07787515968084335
step: 520, loss: 0.1108725443482399
step: 530, loss: 0.06918837130069733
step: 540, loss: 0.05253215134143829
step: 550, loss: 0.04235004633665085
step: 560, loss: 0.2638402283191681
step: 570, loss: 0.028509527444839478
step: 580, loss: 0.0652690976858139
step: 590, loss: 0.09060859680175781
step: 600, loss: 0.08052045851945877
step: 610, loss: 0.07028605788946152
step: 620, loss: 0.023130878806114197
step: 630, loss: 0.08717786520719528
step: 640, loss: 0.030305638909339905
step: 650, loss: 0.05036553367972374
step: 660, loss: 0.032280754297971725
step: 670, loss: 0.017009295523166656
step: 680, loss: 0.09983482211828232
step: 690, loss: 0.10958243161439896
step: 700, loss: 0.10107412934303284
step: 710, loss: 0.003968630917370319
step: 720, loss: 1.2796188457286917e-05
step: 730, loss: 0.014915588311851025
step: 740, loss: 0.029937485232949257
step: 750, loss: 0.04918786883354187
step: 760, loss: 0.02963763102889061
step: 770, loss: 0.0857158750295639
step: 780, loss: 0.05101817846298218
step: 790, loss: 0.01389828696846962
step: 800, loss: 0.04267407953739166
step: 810, loss: 0.06277280300855637
step: 820, loss: 0.1090204045176506
step: 830, loss: 0.045254264026880264
step: 840, loss: 0.09907528758049011
step: 850, loss: 0.09252957254648209
step: 860, loss: 0.01783391274511814
step: 870, loss: 0.1137397512793541
step: 880, loss: 0.17410817742347717
step: 890, loss: 0.0426962673664093
step: 900, loss: 0.04921954125165939
step: 910, loss: 0.04279995709657669
step: 920, loss: 0.08743169903755188
step: 930, loss: 0.04433978348970413
step: 940, loss: 0.1733778864145279
step: 950, loss: 0.1236160472035408
step: 960, loss: 0.22273842990398407
step: 970, loss: 0.09375213086605072
epoch 11: dev_f1=0.9301025163094129, f1=0.927806241266884, best_f1=0.9225058004640372
step: 0, loss: 0.06282472610473633
step: 10, loss: 0.056163541972637177
step: 20, loss: 0.06124807149171829
step: 30, loss: 0.03969433531165123
step: 40, loss: 0.013301017694175243
step: 50, loss: 0.02607347071170807
step: 60, loss: 0.05421700328588486
step: 70, loss: 0.031114958226680756
step: 80, loss: 0.007678334601223469
step: 90, loss: 0.03897997364401817
step: 100, loss: 0.04488344490528107
step: 110, loss: 0.031352318823337555
step: 120, loss: 0.01646948792040348
step: 130, loss: 0.0855584517121315
step: 140, loss: 0.012800348922610283
step: 150, loss: 0.07053330540657043
step: 160, loss: 0.08454935252666473
step: 170, loss: 0.10678454488515854
step: 180, loss: 0.04244846850633621
step: 190, loss: 0.039567843079566956
step: 200, loss: 0.10061067342758179
step: 210, loss: 0.04186240956187248
step: 220, loss: 0.0868191346526146
step: 230, loss: 0.06597194820642471
step: 240, loss: 0.10816792398691177
step: 250, loss: 0.016336258500814438
step: 260, loss: 0.1316298395395279
step: 270, loss: 0.08741147816181183
step: 280, loss: 0.026232635602355003
step: 290, loss: 0.18446166813373566
step: 300, loss: 0.04776725918054581
step: 310, loss: 0.07935626059770584
step: 320, loss: 0.007296786643564701
step: 330, loss: 0.08716405928134918
step: 340, loss: 0.05181751027703285
step: 350, loss: 0.08309079706668854
step: 360, loss: 0.06109704077243805
step: 370, loss: 0.017390051856637
step: 380, loss: 0.0656471773982048
step: 390, loss: 0.042158618569374084
step: 400, loss: 0.07227862626314163
step: 410, loss: 0.0514688678085804
step: 420, loss: 0.0049238670617341995
step: 430, loss: 0.05222375690937042
step: 440, loss: 0.048380304127931595
step: 450, loss: 0.018435589969158173
step: 460, loss: 0.015706511214375496
step: 470, loss: 0.00954571645706892
step: 480, loss: 0.15861620008945465
step: 490, loss: 0.1317349374294281
step: 500, loss: 0.04365167021751404
step: 510, loss: 0.007144947070628405
step: 520, loss: 0.2249729037284851
step: 530, loss: 0.1331796497106552
step: 540, loss: 0.056422412395477295
step: 550, loss: 0.01194215752184391
step: 560, loss: 0.11111635714769363
step: 570, loss: 0.017068153247237206
step: 580, loss: 0.08985045552253723
step: 590, loss: 0.03825297951698303
step: 600, loss: 0.0362834632396698
step: 610, loss: 0.010536224581301212
step: 620, loss: 0.10756011307239532
step: 630, loss: 0.022226249799132347
step: 640, loss: 0.028981156647205353
step: 650, loss: 0.12753644585609436
step: 660, loss: 0.181925430893898
step: 670, loss: 0.07898838073015213
step: 680, loss: 0.13946260511875153
step: 690, loss: 0.014773848466575146
step: 700, loss: 0.07727997750043869
step: 710, loss: 0.13041551411151886
step: 720, loss: 0.12016888707876205
step: 730, loss: 0.06529416143894196
step: 740, loss: 0.1145356073975563
step: 750, loss: 0.004927570000290871
step: 760, loss: 0.09994831681251526
step: 770, loss: 0.05636800453066826
step: 780, loss: 0.02800372615456581
step: 790, loss: 0.06953023374080658
step: 800, loss: 0.07373683899641037
step: 810, loss: 0.0036593929398804903
step: 820, loss: 0.15636420249938965
step: 830, loss: 0.008850260637700558
step: 840, loss: 0.09894754737615585
step: 850, loss: 0.1678108125925064
step: 860, loss: 0.07042808830738068
step: 870, loss: 0.0871051549911499
step: 880, loss: 0.04834574833512306
step: 890, loss: 0.04472436010837555
step: 900, loss: 0.035525329411029816
step: 910, loss: 0.04234623908996582
step: 920, loss: 0.03051438368856907
step: 930, loss: 0.07784069329500198
step: 940, loss: 0.027864286676049232
step: 950, loss: 0.02461238205432892
step: 960, loss: 0.05097275227308273
step: 970, loss: 0.10153663903474808
epoch 12: dev_f1=0.9251764705882354, f1=0.926921263554927, best_f1=0.9225058004640372
step: 0, loss: 0.0690682902932167
step: 10, loss: 0.08002659678459167
step: 20, loss: 0.06894358992576599
step: 30, loss: 0.1262531876564026
step: 40, loss: 0.03466896340250969
step: 50, loss: 0.018796708434820175
step: 60, loss: 0.08152718096971512
step: 70, loss: 0.05702810361981392
step: 80, loss: 0.1001257672905922
step: 90, loss: 0.012744463048875332
step: 100, loss: 0.09131388366222382
step: 110, loss: 0.007060278207063675
step: 120, loss: 0.04747888818383217
step: 130, loss: 0.05123843252658844
step: 140, loss: 0.056275393813848495
step: 150, loss: 0.0734001100063324
step: 160, loss: 0.026707878336310387
step: 170, loss: 0.05782413110136986
step: 180, loss: 0.06161763519048691
step: 190, loss: 0.05834745615720749
step: 200, loss: 0.04466671496629715
step: 210, loss: 0.08738334476947784
step: 220, loss: 0.08345562219619751
step: 230, loss: 0.0066423360258340836
step: 240, loss: 0.13440445065498352
step: 250, loss: 0.1379203498363495
step: 260, loss: 0.0248415470123291
step: 270, loss: 0.11171331256628036
step: 280, loss: 0.07333970814943314
step: 290, loss: 0.1627495288848877
step: 300, loss: 0.061483532190322876
step: 310, loss: 0.05204896628856659
step: 320, loss: 0.11917685717344284
step: 330, loss: 0.010558068752288818
step: 340, loss: 0.04547399654984474
step: 350, loss: 0.04190157726407051
step: 360, loss: 0.08481676876544952
step: 370, loss: 0.012854798696935177
step: 380, loss: 0.03163256123661995
step: 390, loss: 0.008667761459946632
step: 400, loss: 0.1313941478729248
step: 410, loss: 0.03471246361732483
step: 420, loss: 0.07744695246219635
step: 430, loss: 0.03416847810149193
step: 440, loss: 0.07339027523994446
step: 450, loss: 0.037514057010412216
step: 460, loss: 0.07464905083179474
step: 470, loss: 0.04723053425550461
step: 480, loss: 0.05815153568983078
step: 490, loss: 0.054748013615608215
step: 500, loss: 0.03644084185361862
step: 510, loss: 0.024601571261882782
step: 520, loss: 0.1626357138156891
step: 530, loss: 0.03958741948008537
step: 540, loss: 0.058726731687784195
step: 550, loss: 0.02924061007797718
step: 560, loss: 0.10586478561162949
step: 570, loss: 0.07285694032907486
step: 580, loss: 0.05449090525507927
step: 590, loss: 0.10879548639059067
step: 600, loss: 0.038157276809215546
step: 610, loss: 0.05452541634440422
step: 620, loss: 0.049465056508779526
step: 630, loss: 0.02381124533712864
step: 640, loss: 0.0108686164021492
step: 650, loss: 0.04702340066432953
step: 660, loss: 0.04913492500782013
step: 670, loss: 0.13299791514873505
step: 680, loss: 0.03843607380986214
step: 690, loss: 0.1310534030199051
step: 700, loss: 0.08966943621635437
step: 710, loss: 0.012790938839316368
step: 720, loss: 0.07931531220674515
step: 730, loss: 0.03960580751299858
step: 740, loss: 0.00903137307614088
step: 750, loss: 0.06027379259467125
step: 760, loss: 0.056941960006952286
step: 770, loss: 0.08539117127656937
step: 780, loss: 0.09344521909952164
step: 790, loss: 0.13631030917167664
step: 800, loss: 0.06984500586986542
step: 810, loss: 0.07978915423154831
step: 820, loss: 0.006178455892950296
step: 830, loss: 0.0459577850997448
step: 840, loss: 0.08169876039028168
step: 850, loss: 0.032946351915597916
step: 860, loss: 0.04025925695896149
step: 870, loss: 0.026860464364290237
step: 880, loss: 0.05285846069455147
step: 890, loss: 0.058529872447252274
step: 900, loss: 0.06022844463586807
step: 910, loss: 0.04494185745716095
step: 920, loss: 0.053784988820552826
step: 930, loss: 0.06371600925922394
step: 940, loss: 0.10567942261695862
step: 950, loss: 0.04695843905210495
step: 960, loss: 0.06691325455904007
step: 970, loss: 0.03500324487686157
epoch 13: dev_f1=0.9258079198907602, f1=0.9238486092111263, best_f1=0.9225058004640372
step: 0, loss: 0.048503097146749496
step: 10, loss: 0.07298147678375244
step: 20, loss: 0.1049254760146141
step: 30, loss: 0.09247077256441116
step: 40, loss: 0.12732458114624023
step: 50, loss: 0.034572944045066833
step: 60, loss: 0.04234299808740616
step: 70, loss: 0.0630078911781311
step: 80, loss: 0.03585558384656906
step: 90, loss: 0.09793080389499664
step: 100, loss: 0.02051856927573681
step: 110, loss: 0.12818004190921783
step: 120, loss: 0.12465976178646088
step: 130, loss: 0.10288255661725998
step: 140, loss: 0.031225578859448433
step: 150, loss: 0.07519477605819702
step: 160, loss: 0.007213075645267963
step: 170, loss: 0.016623275354504585
step: 180, loss: 0.04796559363603592
step: 190, loss: 0.14160865545272827
step: 200, loss: 0.031957536935806274
step: 210, loss: 0.022704239934682846
step: 220, loss: 0.049651533365249634
step: 230, loss: 0.22499191761016846
step: 240, loss: 0.0670909509062767
step: 250, loss: 0.0030933739617466927
step: 260, loss: 0.015908224508166313
step: 270, loss: 0.11495593190193176
step: 280, loss: 0.130788192152977
step: 290, loss: 0.13275966048240662
step: 300, loss: 0.0003187042020726949
step: 310, loss: 0.04054052382707596
step: 320, loss: 0.108592689037323
step: 330, loss: 0.10337363928556442
step: 340, loss: 0.05139210447669029
step: 350, loss: 0.07547472417354584
step: 360, loss: 0.15932029485702515
step: 370, loss: 0.020296966657042503
step: 380, loss: 0.0410873107612133
step: 390, loss: 0.0013139802031219006
step: 400, loss: 0.0601692721247673
step: 410, loss: 0.202794149518013
step: 420, loss: 0.12321743369102478
step: 430, loss: 0.24145306646823883
step: 440, loss: 0.005098392255604267
step: 450, loss: 0.05065681040287018
step: 460, loss: 0.10387678444385529
step: 470, loss: 0.06398981064558029
step: 480, loss: 0.07223387062549591
step: 490, loss: 0.06171492487192154
step: 500, loss: 0.036319196224212646
step: 510, loss: 0.1489218920469284
step: 520, loss: 0.096507728099823
step: 530, loss: 0.12614178657531738
step: 540, loss: 0.06390368193387985
step: 550, loss: 0.025136861950159073
step: 560, loss: 0.05426885560154915
step: 570, loss: 0.07305819541215897
step: 580, loss: 0.01752142608165741
step: 590, loss: 0.0097532132640481
step: 600, loss: 0.08927437663078308
step: 610, loss: 0.1403200477361679
step: 620, loss: 0.033158183097839355
step: 630, loss: 0.021260017529129982
step: 640, loss: 0.06569284945726395
step: 650, loss: 0.06765778362751007
step: 660, loss: 0.04036331549286842
step: 670, loss: 0.032377228140830994
step: 680, loss: 0.03990389034152031
step: 690, loss: 0.05453610420227051
step: 700, loss: 0.03418007493019104
step: 710, loss: 0.02876192331314087
step: 720, loss: 0.10475357621908188
step: 730, loss: 0.032687850296497345
step: 740, loss: 0.15742439031600952
step: 750, loss: 0.012553565204143524
step: 760, loss: 0.06188468262553215
step: 770, loss: 0.05955991894006729
step: 780, loss: 0.10232950747013092
step: 790, loss: 0.08828519284725189
step: 800, loss: 0.04933123663067818
step: 810, loss: 0.08564267307519913
step: 820, loss: 0.07437106221914291
step: 830, loss: 0.034596145153045654
step: 840, loss: 0.09155347943305969
step: 850, loss: 0.1432584524154663
step: 860, loss: 0.011273880489170551
step: 870, loss: 0.006103867664933205
step: 880, loss: 0.016212956979870796
step: 890, loss: 0.08333368599414825
step: 900, loss: 0.08336678147315979
step: 910, loss: 0.00884179212152958
step: 920, loss: 0.17213480174541473
step: 930, loss: 0.07837893068790436
step: 940, loss: 0.004241312388330698
step: 950, loss: 0.009963955730199814
step: 960, loss: 0.023755241185426712
step: 970, loss: 0.17281298339366913
epoch 14: dev_f1=0.9266227657572906, f1=0.9304511278195489, best_f1=0.9225058004640372
step: 0, loss: 0.07065001875162125
step: 10, loss: 0.08837059140205383
step: 20, loss: 0.05313749238848686
step: 30, loss: 0.08179150521755219
step: 40, loss: 0.06429638713598251
step: 50, loss: 0.07560843229293823
step: 60, loss: 0.030673645436763763
step: 70, loss: 0.15291568636894226
step: 80, loss: 0.11121387779712677
step: 90, loss: 0.003908851183950901
step: 100, loss: 0.06559816747903824
step: 110, loss: 0.0019735605455935
step: 120, loss: 0.0837365910410881
step: 130, loss: 0.03195644170045853
step: 140, loss: 0.023821700364351273
step: 150, loss: 0.1958988457918167
step: 160, loss: 0.04976460337638855
step: 170, loss: 0.02212648093700409
step: 180, loss: 0.01907222904264927
step: 190, loss: 0.07188780605792999
step: 200, loss: 0.04263461008667946
step: 210, loss: 0.040206730365753174
step: 220, loss: 0.08351828157901764
step: 230, loss: 0.03430517017841339
step: 240, loss: 0.09053731709718704
step: 250, loss: 0.015356793068349361
step: 260, loss: 0.1975070685148239
step: 270, loss: 0.10777902603149414
step: 280, loss: 0.12881797552108765
step: 290, loss: 0.004713577218353748
step: 300, loss: 0.09989985078573227
step: 310, loss: 0.07342725992202759
step: 320, loss: 0.032326098531484604
step: 330, loss: 0.09779516607522964
step: 340, loss: 0.07693688571453094
step: 350, loss: 0.024273786693811417
step: 360, loss: 0.0503314733505249
step: 370, loss: 0.02579282410442829
step: 380, loss: 0.07516611367464066
step: 390, loss: 0.03985181078314781
step: 400, loss: 0.04234224557876587
step: 410, loss: 0.10597827285528183
step: 420, loss: 0.059848833829164505
step: 430, loss: 0.052475254982709885
step: 440, loss: 0.04057641327381134
step: 450, loss: 0.06645403057336807
step: 460, loss: 0.0010841175680980086
step: 470, loss: 0.00844753347337246
step: 480, loss: 0.04432209953665733
step: 490, loss: 0.07777784019708633
step: 500, loss: 1.7403448509867303e-05
step: 510, loss: 0.045327167958021164
step: 520, loss: 0.04510658606886864
step: 530, loss: 0.0034241322427988052
step: 540, loss: 0.11916683614253998
step: 550, loss: 0.04721875861287117
step: 560, loss: 0.05712317302823067
step: 570, loss: 0.09292135387659073
step: 580, loss: 0.09367513656616211
step: 590, loss: 0.0324966236948967
step: 600, loss: 0.10454680025577545
step: 610, loss: 0.06724507361650467
step: 620, loss: 0.04634406790137291
step: 630, loss: 0.00022007018560543656
step: 640, loss: 0.06763023883104324
step: 650, loss: 0.01027669943869114
step: 660, loss: 0.12572947144508362
step: 670, loss: 0.06111680716276169
step: 680, loss: 0.08379790931940079
step: 690, loss: 0.06705480068922043
step: 700, loss: 0.08063008636236191
step: 710, loss: 0.04019923135638237
step: 720, loss: 0.0025172464083880186
step: 730, loss: 0.013341978192329407
step: 740, loss: 0.02682250551879406
step: 750, loss: 0.02244567684829235
step: 760, loss: 0.18438021838665009
step: 770, loss: 0.08335382491350174
step: 780, loss: 0.05200374126434326
step: 790, loss: 0.037286341190338135
step: 800, loss: 0.10990452021360397
step: 810, loss: 0.07920781522989273
step: 820, loss: 0.06383915990591049
step: 830, loss: 0.001279156655073166
step: 840, loss: 0.2551177442073822
step: 850, loss: 0.000677010859362781
step: 860, loss: 0.11610639095306396
step: 870, loss: 0.07351228594779968
step: 880, loss: 0.06487984955310822
step: 890, loss: 0.11952288448810577
step: 900, loss: 0.042764559388160706
step: 910, loss: 0.041450418531894684
step: 920, loss: 0.01772395521402359
step: 930, loss: 0.07910983264446259
step: 940, loss: 0.08480028808116913
step: 950, loss: 0.05347486957907677
step: 960, loss: 0.0660836398601532
step: 970, loss: 0.034325551241636276
epoch 15: dev_f1=0.9225865209471767, f1=0.9198350893266148, best_f1=0.9225058004640372
step: 0, loss: 0.021052353084087372
step: 10, loss: 0.0473569817841053
step: 20, loss: 0.064747653901577
step: 30, loss: 0.027684064581990242
step: 40, loss: 0.09566092491149902
step: 50, loss: 0.029893692582845688
step: 60, loss: 0.03391056880354881
step: 70, loss: 0.024154432117938995
step: 80, loss: 0.0011221650056540966
step: 90, loss: 0.009466510266065598
step: 100, loss: 0.08478555083274841
step: 110, loss: 0.10690591484308243
step: 120, loss: 0.04634569585323334
step: 130, loss: 0.07212919741868973
step: 140, loss: 0.034308478236198425
step: 150, loss: 0.0683002844452858
step: 160, loss: 0.026863522827625275
step: 170, loss: 0.02016475424170494
step: 180, loss: 0.0010781523305922747
step: 190, loss: 0.1070239394903183
step: 200, loss: 0.07950733602046967
step: 210, loss: 0.002628602785989642
step: 220, loss: 0.03411760926246643
step: 230, loss: 0.026727095246315002
step: 240, loss: 0.009150966070592403
step: 250, loss: 0.04589354246854782
step: 260, loss: 0.012947017326951027
step: 270, loss: 0.02994445152580738
step: 280, loss: 0.032045118510723114
step: 290, loss: 0.015372203662991524
step: 300, loss: 0.05587627738714218
step: 310, loss: 0.02879951521754265
step: 320, loss: 0.1104300245642662
step: 330, loss: 0.15335743129253387
step: 340, loss: 0.06673487275838852
step: 350, loss: 0.08669117838144302
step: 360, loss: 0.0004950050497427583
step: 370, loss: 0.06231113523244858
step: 380, loss: 0.045790329575538635
step: 390, loss: 0.0297527052462101
step: 400, loss: 0.1197129413485527
step: 410, loss: 0.013791583478450775
step: 420, loss: 0.20850223302841187
step: 430, loss: 0.025858934968709946
step: 440, loss: 0.036296386271715164
step: 450, loss: 0.05307411774992943
step: 460, loss: 0.07093138992786407
step: 470, loss: 0.04578864574432373
step: 480, loss: 0.09549253433942795
step: 490, loss: 0.043067991733551025
step: 500, loss: 0.027793919667601585
step: 510, loss: 0.021875226870179176
step: 520, loss: 0.05290485918521881
step: 530, loss: 0.03649701178073883
step: 540, loss: 0.09551399946212769
step: 550, loss: 0.11234208941459656
step: 560, loss: 0.038764357566833496
step: 570, loss: 0.09928741306066513
step: 580, loss: 0.07118501514196396
step: 590, loss: 0.04623137041926384
step: 600, loss: 0.0702301487326622
step: 610, loss: 0.016599174588918686
step: 620, loss: 0.07056596130132675
step: 630, loss: 0.09907836467027664
step: 640, loss: 0.09923084825277328
step: 650, loss: 0.03184627369046211
step: 660, loss: 0.03696610778570175
step: 670, loss: 0.029801853001117706
step: 680, loss: 0.06493290513753891
step: 690, loss: 0.05627644434571266
step: 700, loss: 0.06645132601261139
step: 710, loss: 0.001863026642240584
step: 720, loss: 0.0053682937286794186
step: 730, loss: 0.1111682876944542
step: 740, loss: 0.011815589852631092
step: 750, loss: 0.11803300678730011
step: 760, loss: 0.03313165158033371
step: 770, loss: 0.08772576600313187
step: 780, loss: 0.05531592294573784
step: 790, loss: 0.050827473402023315
step: 800, loss: 0.002117381663993001
step: 810, loss: 0.04150120168924332
step: 820, loss: 0.007005521561950445
step: 830, loss: 0.003597972681745887
step: 840, loss: 0.05473211035132408
step: 850, loss: 0.046559471637010574
step: 860, loss: 0.013026323169469833
step: 870, loss: 0.0727091133594513
step: 880, loss: 0.045109741389751434
step: 890, loss: 0.01826108619570732
step: 900, loss: 0.09437283128499985
step: 910, loss: 0.08290695399045944
step: 920, loss: 0.024516252800822258
step: 930, loss: 0.05621771886944771
step: 940, loss: 0.0580110065639019
step: 950, loss: 0.06104820966720581
step: 960, loss: 0.05733079835772514
step: 970, loss: 0.0705251470208168
epoch 16: dev_f1=0.9243856332703214, f1=0.9216981132075471, best_f1=0.9225058004640372
step: 0, loss: 0.0842704251408577
step: 10, loss: 0.06093469262123108
step: 20, loss: 0.00014945463044568896
step: 30, loss: 0.08343549817800522
step: 40, loss: 0.03374794125556946
step: 50, loss: 0.007348169106990099
step: 60, loss: 0.048001665621995926
step: 70, loss: 0.025587860494852066
step: 80, loss: 0.0636458545923233
step: 90, loss: 0.017667926847934723
step: 100, loss: 0.13505083322525024
step: 110, loss: 0.022221706807613373
step: 120, loss: 0.0364779531955719
step: 130, loss: 0.012226040475070477
step: 140, loss: 0.02095041610300541
step: 150, loss: 0.026702508330345154
step: 160, loss: 0.06643039733171463
step: 170, loss: 0.018366361036896706
step: 180, loss: 0.1451757550239563
step: 190, loss: 0.02728418819606304
step: 200, loss: 0.1175030767917633
step: 210, loss: 8.687047375133261e-05
step: 220, loss: 0.07780919969081879
step: 230, loss: 0.06554225832223892
step: 240, loss: 9.912909263221081e-06
step: 250, loss: 0.1028490886092186
step: 260, loss: 0.04320758953690529
step: 270, loss: 0.025101693347096443
step: 280, loss: 0.11854743957519531
step: 290, loss: 0.10354294627904892
step: 300, loss: 0.002444340381771326
step: 310, loss: 0.03245516121387482
step: 320, loss: 0.04211801663041115
step: 330, loss: 0.07048462331295013
step: 340, loss: 0.09244710206985474
step: 350, loss: 0.02982080541551113
step: 360, loss: 0.056683145463466644
step: 370, loss: 0.024577157571911812
step: 380, loss: 0.09300433844327927
step: 390, loss: 0.02343800850212574
step: 400, loss: 0.01428395975381136
step: 410, loss: 0.02967933565378189
step: 420, loss: 0.0670950636267662
step: 430, loss: 0.04625391215085983
step: 440, loss: 0.05998215079307556
step: 450, loss: 0.11823388934135437
step: 460, loss: 0.05612775310873985
step: 470, loss: 0.042804744094610214
step: 480, loss: 0.08238571882247925
step: 490, loss: 0.07024732977151871
step: 500, loss: 0.0808267816901207
step: 510, loss: 0.04901573061943054
step: 520, loss: 0.014165503904223442
step: 530, loss: 0.04760133847594261
step: 540, loss: 0.10953737050294876
step: 550, loss: 0.016466787084937096
step: 560, loss: 0.05540443956851959
step: 570, loss: 0.018371669575572014
step: 580, loss: 0.1195584088563919
step: 590, loss: 0.047573335468769073
step: 600, loss: 0.053152188658714294
step: 610, loss: 0.035785872489213943
step: 620, loss: 0.14240097999572754
step: 630, loss: 0.07265008240938187
step: 640, loss: 0.03987374156713486
step: 650, loss: 0.05976572632789612
step: 660, loss: 0.04350375011563301
step: 670, loss: 0.011962305754423141
step: 680, loss: 0.025192873552441597
step: 690, loss: 0.2438313215970993
step: 700, loss: 0.03155061975121498
step: 710, loss: 0.02287381701171398
step: 720, loss: 0.030119845643639565
step: 730, loss: 0.16359373927116394
step: 740, loss: 0.07047200947999954
step: 750, loss: 0.13692469894886017
step: 760, loss: 0.06471135467290878
step: 770, loss: 0.07026925683021545
step: 780, loss: 0.03865431249141693
step: 790, loss: 0.1281059980392456
step: 800, loss: 0.01894315704703331
step: 810, loss: 0.14009931683540344
step: 820, loss: 0.05812312662601471
step: 830, loss: 0.11237671971321106
step: 840, loss: 0.046024758368730545
step: 850, loss: 0.0041235098615288734
step: 860, loss: 0.07915742695331573
step: 870, loss: 0.04054420068860054
step: 880, loss: 0.043879762291908264
step: 890, loss: 0.1123247742652893
step: 900, loss: 0.008131180889904499
step: 910, loss: 0.06888192147016525
step: 920, loss: 0.07051745802164078
step: 930, loss: 0.12770989537239075
step: 940, loss: 0.0899248793721199
step: 950, loss: 0.05702528357505798
step: 960, loss: 0.035398028790950775
step: 970, loss: 0.0017162900185212493
epoch 17: dev_f1=0.9243065350258581, f1=0.922859830667921, best_f1=0.9225058004640372
step: 0, loss: 0.05098354071378708
step: 10, loss: 1.968224205484148e-05
step: 20, loss: 0.03171999007463455
step: 30, loss: 0.053026776760816574
step: 40, loss: 0.03223305568099022
step: 50, loss: 0.08625074476003647
step: 60, loss: 0.03672608733177185
step: 70, loss: 0.04623701050877571
step: 80, loss: 0.002712319139391184
step: 90, loss: 0.01708504743874073
step: 100, loss: 0.11003337055444717
step: 110, loss: 0.06800272315740585
step: 120, loss: 0.014723062515258789
step: 130, loss: 0.02960730902850628
step: 140, loss: 0.055154379457235336
step: 150, loss: 0.03395948186516762
step: 160, loss: 0.10048732161521912
step: 170, loss: 0.03901228308677673
step: 180, loss: 0.016433976590633392
step: 190, loss: 0.0031122975051403046
step: 200, loss: 0.08238991349935532
step: 210, loss: 0.04235648736357689
step: 220, loss: 0.018482090905308723
step: 230, loss: 0.05172313377261162
step: 240, loss: 0.17263120412826538
step: 250, loss: 0.0301001388579607
step: 260, loss: 0.005856502801179886
step: 270, loss: 0.06259511411190033
step: 280, loss: 0.021300187334418297
step: 290, loss: 0.08244591951370239
step: 300, loss: 0.00620884308591485
step: 310, loss: 0.01893126405775547
step: 320, loss: 0.028594128787517548
step: 330, loss: 0.10857568681240082
step: 340, loss: 0.03540385141968727
step: 350, loss: 0.02412913739681244
step: 360, loss: 0.058622732758522034
step: 370, loss: 0.05601055920124054
step: 380, loss: 0.022184789180755615
step: 390, loss: 0.05387662723660469
step: 400, loss: 0.04777403548359871
step: 410, loss: 0.14356344938278198
step: 420, loss: 0.00028759866836480796
step: 430, loss: 0.0004147914005443454
step: 440, loss: 0.01694992370903492
step: 450, loss: 0.09264048933982849
step: 460, loss: 0.061326924711465836
step: 470, loss: 0.0896364226937294
step: 480, loss: 0.0011879107914865017
step: 490, loss: 0.09012602269649506
step: 500, loss: 0.07016811519861221
step: 510, loss: 0.10416844487190247
step: 520, loss: 0.016781266778707504
step: 530, loss: 0.132572203874588
step: 540, loss: 0.05038733035326004
step: 550, loss: 0.01811147667467594
step: 560, loss: 0.06830985099077225
step: 570, loss: 0.035952433943748474
step: 580, loss: 8.374395292776171e-06
step: 590, loss: 0.04396411031484604
step: 600, loss: 0.028565462678670883
step: 610, loss: 0.012137421406805515
step: 620, loss: 0.037384603172540665
step: 630, loss: 0.0917300432920456
step: 640, loss: 0.0631515234708786
step: 650, loss: 0.050199851393699646
step: 660, loss: 0.04039962589740753
step: 670, loss: 0.055208370089530945
step: 680, loss: 0.0044266036711633205
step: 690, loss: 0.02338087186217308
step: 700, loss: 0.09767939150333405
step: 710, loss: 0.06190797686576843
step: 720, loss: 0.03345774859189987
step: 730, loss: 0.08915184438228607
step: 740, loss: 0.09483092278242111
step: 750, loss: 0.05653868243098259
step: 760, loss: 0.04176933690905571
step: 770, loss: 0.07791675627231598
step: 780, loss: 0.07279331237077713
step: 790, loss: 0.0774657130241394
step: 800, loss: 0.05122905969619751
step: 810, loss: 0.07654473185539246
step: 820, loss: 0.07351265102624893
step: 830, loss: 0.022863047197461128
step: 840, loss: 0.01121984701603651
step: 850, loss: 0.009359888732433319
step: 860, loss: 0.008137176744639874
step: 870, loss: 0.07618190348148346
step: 880, loss: 0.02415619231760502
step: 890, loss: 0.06226397678256035
step: 900, loss: 0.03953452408313751
step: 910, loss: 0.07561377435922623
step: 920, loss: 0.002148592844605446
step: 930, loss: 0.06029695272445679
step: 940, loss: 0.043542105704545975
step: 950, loss: 0.03490256145596504
step: 960, loss: 0.012532670982182026
step: 970, loss: 0.05871014669537544
epoch 18: dev_f1=0.923076923076923, f1=0.9213691026827011, best_f1=0.9225058004640372
step: 0, loss: 0.05171222239732742
step: 10, loss: 0.04816516116261482
step: 20, loss: 0.027518553659319878
step: 30, loss: 0.02576853707432747
step: 40, loss: 0.01837395876646042
step: 50, loss: 0.06193585693836212
step: 60, loss: 0.024574844166636467
step: 70, loss: 0.019613170996308327
step: 80, loss: 0.09533408284187317
step: 90, loss: 0.020309392362833023
step: 100, loss: 0.0001718233834253624
step: 110, loss: 0.06872744858264923
step: 120, loss: 0.008108335547149181
step: 130, loss: 0.053078025579452515
step: 140, loss: 0.059294309467077255
step: 150, loss: 0.11289835721254349
step: 160, loss: 0.04129024222493172
step: 170, loss: 0.031392116099596024
step: 180, loss: 0.0731227919459343
step: 190, loss: 0.02746259607374668
step: 200, loss: 0.035526204854249954
step: 210, loss: 0.030554383993148804
step: 220, loss: 0.10064483433961868
step: 230, loss: 0.04130968451499939
step: 240, loss: 0.0014259942108765244
step: 250, loss: 0.07505480945110321
step: 260, loss: 0.026340428739786148
step: 270, loss: 0.044557251036167145
step: 280, loss: 0.04054161533713341
step: 290, loss: 0.13141657412052155
step: 300, loss: 0.021078059449791908
step: 310, loss: 0.05115864425897598
step: 320, loss: 0.010555134154856205
step: 330, loss: 0.046008434146642685
step: 340, loss: 0.1919148862361908
step: 350, loss: 0.05417792499065399
step: 360, loss: 0.05259478837251663
step: 370, loss: 0.05390220507979393
step: 380, loss: 0.0071578072383999825
step: 390, loss: 0.06417399644851685
step: 400, loss: 4.91527644044254e-05
step: 410, loss: 0.022712677717208862
step: 420, loss: 0.03327403962612152
step: 430, loss: 0.04805750399827957
step: 440, loss: 0.06959246844053268
step: 450, loss: 0.0009687494020909071
step: 460, loss: 0.019555458799004555
step: 470, loss: 0.07112880796194077
step: 480, loss: 0.09603936970233917
step: 490, loss: 0.046714767813682556
step: 500, loss: 0.054256096482276917
step: 510, loss: 0.01386471651494503
step: 520, loss: 0.04538340866565704
step: 530, loss: 0.11443445086479187
step: 540, loss: 0.028560170903801918
step: 550, loss: 0.07361382246017456
step: 560, loss: 0.058105990290641785
step: 570, loss: 0.013186091557145119
step: 580, loss: 0.05726907029747963
step: 590, loss: 0.02600112184882164
step: 600, loss: 0.010710172355175018
step: 610, loss: 0.02310214377939701
step: 620, loss: 0.007777663413435221
step: 630, loss: 0.17268194258213043
step: 640, loss: 0.08342543989419937
step: 650, loss: 0.08003401011228561
step: 660, loss: 0.020395968109369278
step: 670, loss: 0.021267643198370934
step: 680, loss: 0.010076898150146008
step: 690, loss: 0.032419461756944656
step: 700, loss: 0.03917032480239868
step: 710, loss: 0.06852369755506516
step: 720, loss: 0.051664769649505615
step: 730, loss: 0.01598447747528553
step: 740, loss: 0.10395800322294235
step: 750, loss: 0.045787010341882706
step: 760, loss: 0.001248672604560852
step: 770, loss: 0.035598915070295334
step: 780, loss: 0.07946322113275528
step: 790, loss: 0.006164677441120148
step: 800, loss: 8.643142064101994e-05
step: 810, loss: 0.05815736576914787
step: 820, loss: 0.09668681025505066
step: 830, loss: 0.0673370212316513
step: 840, loss: 0.029611729085445404
step: 850, loss: 4.25917751272209e-05
step: 860, loss: 0.07101364433765411
step: 870, loss: 0.09104031324386597
step: 880, loss: 0.039829984307289124
step: 890, loss: 0.07392602413892746
step: 900, loss: 0.00010152968752663583
step: 910, loss: 0.02336602658033371
step: 920, loss: 0.04276306554675102
step: 930, loss: 0.06713570654392242
step: 940, loss: 0.010249793529510498
step: 950, loss: 0.01708054170012474
step: 960, loss: 0.026608223095536232
step: 970, loss: 0.0002602346648927778
epoch 19: dev_f1=0.921999065857076, f1=0.9226441631504922, best_f1=0.9225058004640372
step: 0, loss: 0.022535739466547966
step: 10, loss: 0.005299401469528675
step: 20, loss: 0.020506346598267555
step: 30, loss: 0.042709045112133026
step: 40, loss: 0.04911220818758011
step: 50, loss: 0.037210166454315186
step: 60, loss: 0.08022935688495636
step: 70, loss: 0.06292949616909027
step: 80, loss: 0.06813706457614899
step: 90, loss: 0.12997496128082275
step: 100, loss: 0.013219098560512066
step: 110, loss: 0.1075584664940834
step: 120, loss: 0.03003593161702156
step: 130, loss: 0.04329963028430939
step: 140, loss: 0.04762260243296623
step: 150, loss: 0.05370280519127846
step: 160, loss: 0.1265355497598648
step: 170, loss: 0.043347276747226715
step: 180, loss: 0.13905198872089386
step: 190, loss: 0.06771942973136902
step: 200, loss: 0.07995153963565826
step: 210, loss: 0.010836252942681313
step: 220, loss: 0.07149305194616318
step: 230, loss: 0.03881581872701645
step: 240, loss: 0.1429072767496109
step: 250, loss: 0.034937262535095215
step: 260, loss: 0.053481630980968475
step: 270, loss: 0.051552124321460724
step: 280, loss: 0.019004791975021362
step: 290, loss: 0.04228591173887253
step: 300, loss: 0.07194990664720535
step: 310, loss: 0.06416723132133484
step: 320, loss: 0.043599896132946014
step: 330, loss: 0.04135150462388992
step: 340, loss: 8.699070895090699e-05
step: 350, loss: 0.10666268318891525
step: 360, loss: 0.05965423956513405
step: 370, loss: 0.016127754002809525
step: 380, loss: 0.04159299284219742
step: 390, loss: 0.09753256291151047
step: 400, loss: 0.03947846591472626
step: 410, loss: 0.016428135335445404
step: 420, loss: 0.052498094737529755
step: 430, loss: 0.03291518613696098
step: 440, loss: 0.08328478783369064
step: 450, loss: 0.016741320490837097
step: 460, loss: 0.03237609565258026
step: 470, loss: 0.014738594181835651
step: 480, loss: 0.0009975726716220379
step: 490, loss: 0.04104889929294586
step: 500, loss: 0.02133733220398426
step: 510, loss: 0.04692568629980087
step: 520, loss: 0.020789843052625656
step: 530, loss: 0.09701145440340042
step: 540, loss: 0.012494085356593132
step: 550, loss: 0.005170869175344706
step: 560, loss: 2.601186861284077e-05
step: 570, loss: 0.0211908221244812
step: 580, loss: 0.00011299148172838613
step: 590, loss: 0.016388026997447014
step: 600, loss: 0.026715166866779327
step: 610, loss: 0.05231258273124695
step: 620, loss: 0.00017204116738867015
step: 630, loss: 0.02240874618291855
step: 640, loss: 0.032309390604496
step: 650, loss: 0.21323668956756592
step: 660, loss: 0.039107706397771835
step: 670, loss: 0.010229108855128288
step: 680, loss: 0.04271096736192703
step: 690, loss: 0.02771572954952717
step: 700, loss: 0.03005853481590748
step: 710, loss: 0.002059630583971739
step: 720, loss: 0.03324154391884804
step: 730, loss: 0.017674917355179787
step: 740, loss: 0.0393703356385231
step: 750, loss: 0.08960553258657455
step: 760, loss: 0.00013278794358484447
step: 770, loss: 0.0868406742811203
step: 780, loss: 0.0542253702878952
step: 790, loss: 0.10499099642038345
step: 800, loss: 0.015465966425836086
step: 810, loss: 0.01764483004808426
step: 820, loss: 0.02255769446492195
step: 830, loss: 0.09167912602424622
step: 840, loss: 0.030394626781344414
step: 850, loss: 0.10470083355903625
step: 860, loss: 0.06282869726419449
step: 870, loss: 0.07674698531627655
step: 880, loss: 0.0003320295363664627
step: 890, loss: 0.08826515078544617
step: 900, loss: 0.05719314143061638
step: 910, loss: 0.008292519487440586
step: 920, loss: 0.01305285282433033
step: 930, loss: 0.01937309466302395
step: 940, loss: 0.0004691035719588399
step: 950, loss: 0.044621240347623825
step: 960, loss: 0.011607340537011623
step: 970, loss: 0.028189150616526604
epoch 20: dev_f1=0.923005132991134, f1=0.9231490159325211, best_f1=0.9225058004640372
