cuda
Device: cuda
step: 0, loss: 0.5557103157043457
step: 10, loss: 0.2586066424846649
step: 20, loss: 0.29775765538215637
step: 30, loss: 0.2974662780761719
step: 40, loss: 0.2726430892944336
step: 50, loss: 0.23867423832416534
step: 60, loss: 0.2863730192184448
step: 70, loss: 0.3094448149204254
step: 80, loss: 0.09035023301839828
step: 90, loss: 0.11754642426967621
step: 100, loss: 0.23153989017009735
step: 110, loss: 0.22962436079978943
step: 120, loss: 0.11198259890079498
step: 130, loss: 0.07690604031085968
step: 140, loss: 0.14767219126224518
step: 150, loss: 0.2610606253147125
step: 160, loss: 0.08194257318973541
step: 170, loss: 0.1929960399866104
step: 180, loss: 0.11379161477088928
step: 190, loss: 0.08559520542621613
step: 200, loss: 0.19900135695934296
step: 210, loss: 0.44169747829437256
step: 220, loss: 0.19935183227062225
step: 230, loss: 0.17154444754123688
step: 240, loss: 0.14688771963119507
step: 250, loss: 0.1486606001853943
step: 260, loss: 0.2180015742778778
step: 270, loss: 0.23269669711589813
step: 280, loss: 0.06990864127874374
step: 290, loss: 0.1574667990207672
step: 300, loss: 0.2520482540130615
step: 310, loss: 0.16214311122894287
step: 320, loss: 0.2289590686559677
step: 330, loss: 0.22355793416500092
step: 340, loss: 0.09561966359615326
step: 350, loss: 0.044228147715330124
step: 360, loss: 0.05875377729535103
step: 370, loss: 0.17915618419647217
step: 380, loss: 0.11264609545469284
step: 390, loss: 0.08654039353132248
step: 400, loss: 0.20251348614692688
step: 410, loss: 0.14087019860744476
step: 420, loss: 0.07189641892910004
step: 430, loss: 0.06522946804761887
step: 440, loss: 0.110086590051651
step: 450, loss: 0.16859523952007294
step: 460, loss: 0.10251089930534363
step: 470, loss: 0.07056564837694168
step: 480, loss: 0.10327167809009552
step: 490, loss: 0.18088789284229279
step: 500, loss: 0.13172277808189392
step: 510, loss: 0.1629496067762375
step: 520, loss: 0.21709507703781128
step: 530, loss: 0.2406398504972458
step: 540, loss: 0.13326463103294373
step: 550, loss: 0.04354889690876007
step: 560, loss: 0.17111918330192566
step: 570, loss: 0.09352150559425354
step: 580, loss: 0.08439064770936966
step: 590, loss: 0.1064719408750534
step: 600, loss: 0.15132096409797668
step: 610, loss: 0.16723674535751343
step: 620, loss: 0.11117240786552429
step: 630, loss: 0.1337652951478958
step: 640, loss: 0.10802121460437775
step: 650, loss: 0.1702922284603119
step: 660, loss: 0.22637072205543518
step: 670, loss: 0.19272011518478394
step: 680, loss: 0.12945236265659332
step: 690, loss: 0.12990371882915497
step: 700, loss: 0.08256197720766068
step: 710, loss: 0.16625666618347168
step: 720, loss: 0.28438588976860046
step: 730, loss: 0.09223400801420212
step: 740, loss: 0.13695074617862701
step: 750, loss: 0.22480258345603943
step: 760, loss: 0.10123296082019806
step: 770, loss: 0.09076561033725739
step: 780, loss: 0.08666219562292099
step: 790, loss: 0.18506769835948944
step: 800, loss: 0.08335383981466293
step: 810, loss: 0.13608191907405853
step: 820, loss: 0.10111577808856964
step: 830, loss: 0.06734204292297363
step: 840, loss: 0.16655626893043518
step: 850, loss: 0.11201241612434387
step: 860, loss: 0.12054294347763062
step: 870, loss: 0.20338064432144165
step: 880, loss: 0.2947482168674469
step: 890, loss: 0.12625695765018463
step: 900, loss: 0.07570190727710724
step: 910, loss: 0.23753444850444794
step: 920, loss: 0.16502197086811066
step: 930, loss: 0.19208812713623047
step: 940, loss: 0.1082526370882988
step: 950, loss: 0.06181728467345238
step: 960, loss: 0.0861797109246254
step: 970, loss: 0.15990126132965088
epoch 1: dev_f1=0.9150812064965197, f1=0.9168975069252078, best_f1=0.9168975069252078
step: 0, loss: 0.18397441506385803
step: 10, loss: 0.23213709890842438
step: 20, loss: 0.09264387935400009
step: 30, loss: 0.09527429938316345
step: 40, loss: 0.13339093327522278
step: 50, loss: 0.07073402404785156
step: 60, loss: 0.15538188815116882
step: 70, loss: 0.13032938539981842
step: 80, loss: 0.18834459781646729
step: 90, loss: 0.07244069129228592
step: 100, loss: 0.09307772666215897
step: 110, loss: 0.061022207140922546
step: 120, loss: 0.085883729159832
step: 130, loss: 0.08559932559728622
step: 140, loss: 0.052474189549684525
step: 150, loss: 0.2317904680967331
step: 160, loss: 0.18585558235645294
step: 170, loss: 0.14044053852558136
step: 180, loss: 0.11255674064159393
step: 190, loss: 0.0982808992266655
step: 200, loss: 0.23985444009304047
step: 210, loss: 0.17497383058071136
step: 220, loss: 0.10741803050041199
step: 230, loss: 0.18595580756664276
step: 240, loss: 0.17192675173282623
step: 250, loss: 0.04430690407752991
step: 260, loss: 0.08353625237941742
step: 270, loss: 0.12256690114736557
step: 280, loss: 0.14821180701255798
step: 290, loss: 0.17435580492019653
step: 300, loss: 0.08281259983778
step: 310, loss: 0.09808094054460526
step: 320, loss: 0.12334708124399185
step: 330, loss: 0.3320964276790619
step: 340, loss: 0.18626661598682404
step: 350, loss: 0.104696124792099
step: 360, loss: 0.2459283471107483
step: 370, loss: 0.2139354944229126
step: 380, loss: 0.07239081710577011
step: 390, loss: 0.09771884977817535
step: 400, loss: 0.18615533411502838
step: 410, loss: 0.1666019707918167
step: 420, loss: 0.15232834219932556
step: 430, loss: 0.19432863593101501
step: 440, loss: 0.0976262092590332
step: 450, loss: 0.11466240137815475
step: 460, loss: 0.11130747944116592
step: 470, loss: 0.11696746200323105
step: 480, loss: 0.1404562145471573
step: 490, loss: 0.24272368848323822
step: 500, loss: 0.11503814160823822
step: 510, loss: 0.1555570363998413
step: 520, loss: 0.098424032330513
step: 530, loss: 0.05589686334133148
step: 540, loss: 0.1127934679389
step: 550, loss: 0.10729296505451202
step: 560, loss: 0.09242803603410721
step: 570, loss: 0.16986115276813507
step: 580, loss: 0.18521328270435333
step: 590, loss: 0.3468710482120514
step: 600, loss: 0.15004049241542816
step: 610, loss: 0.08590727299451828
step: 620, loss: 0.06289110332727432
step: 630, loss: 0.14860296249389648
step: 640, loss: 0.12889091670513153
step: 650, loss: 0.09441322833299637
step: 660, loss: 0.10033982992172241
step: 670, loss: 0.16806039214134216
step: 680, loss: 0.2480492740869522
step: 690, loss: 0.21672692894935608
step: 700, loss: 0.1278260350227356
step: 710, loss: 0.08690766245126724
step: 720, loss: 0.1337171494960785
step: 730, loss: 0.07553562521934509
step: 740, loss: 0.12305451184511185
step: 750, loss: 0.243168905377388
step: 760, loss: 0.08679324388504028
step: 770, loss: 0.15119308233261108
step: 780, loss: 0.2583155632019043
step: 790, loss: 0.0006618701154366136
step: 800, loss: 0.16559158265590668
step: 810, loss: 0.08670023828744888
step: 820, loss: 0.12972737848758698
step: 830, loss: 0.08103597909212112
step: 840, loss: 0.1698637306690216
step: 850, loss: 0.15704375505447388
step: 860, loss: 0.07840494066476822
step: 870, loss: 0.3587166666984558
step: 880, loss: 0.06564303487539291
step: 890, loss: 0.06655384600162506
step: 900, loss: 0.1934708207845688
step: 910, loss: 0.15035146474838257
step: 920, loss: 0.05280502140522003
step: 930, loss: 0.09954915940761566
step: 940, loss: 0.1433873474597931
step: 950, loss: 0.09756292402744293
step: 960, loss: 0.10411052405834198
step: 970, loss: 0.11275578290224075
epoch 2: dev_f1=0.9205759405480723, f1=0.9259944495837188, best_f1=0.9259944495837188
step: 0, loss: 0.06820319592952728
step: 10, loss: 0.08317413181066513
step: 20, loss: 0.14045925438404083
step: 30, loss: 0.07345085591077805
step: 40, loss: 0.33263516426086426
step: 50, loss: 0.08294255286455154
step: 60, loss: 0.173906147480011
step: 70, loss: 0.11231323331594467
step: 80, loss: 0.10659108310937881
step: 90, loss: 0.2034544050693512
step: 100, loss: 0.0911278948187828
step: 110, loss: 0.11165352910757065
step: 120, loss: 0.07278334349393845
step: 130, loss: 0.09558802098035812
step: 140, loss: 0.15954674780368805
step: 150, loss: 0.17254002392292023
step: 160, loss: 0.058094900101423264
step: 170, loss: 0.008227717131376266
step: 180, loss: 0.11128996312618256
step: 190, loss: 0.25990957021713257
step: 200, loss: 0.10076025128364563
step: 210, loss: 0.25552740693092346
step: 220, loss: 0.17161108553409576
step: 230, loss: 0.10968644171953201
step: 240, loss: 0.17345969378948212
step: 250, loss: 0.11290954053401947
step: 260, loss: 0.0765053853392601
step: 270, loss: 0.04977702349424362
step: 280, loss: 0.10505983978509903
step: 290, loss: 0.1415012627840042
step: 300, loss: 0.04250870272517204
step: 310, loss: 0.09637639671564102
step: 320, loss: 0.16900838911533356
step: 330, loss: 0.07041339576244354
step: 340, loss: 0.2384604662656784
step: 350, loss: 0.1682967245578766
step: 360, loss: 0.0337446965277195
step: 370, loss: 0.10416721552610397
step: 380, loss: 0.04943416640162468
step: 390, loss: 0.022737517952919006
step: 400, loss: 0.12582281231880188
step: 410, loss: 0.0539969839155674
step: 420, loss: 0.0894969031214714
step: 430, loss: 0.045679204165935516
step: 440, loss: 0.2547113001346588
step: 450, loss: 0.089717335999012
step: 460, loss: 0.11012924462556839
step: 470, loss: 0.10218937695026398
step: 480, loss: 0.1582852154970169
step: 490, loss: 0.1827223300933838
step: 500, loss: 0.08924367278814316
step: 510, loss: 0.18167270720005035
step: 520, loss: 0.047602489590644836
step: 530, loss: 0.06646740436553955
step: 540, loss: 0.017663046717643738
step: 550, loss: 0.05743386596441269
step: 560, loss: 0.16667845845222473
step: 570, loss: 0.19681091606616974
step: 580, loss: 0.049215931445360184
step: 590, loss: 0.1762247383594513
step: 600, loss: 0.10139709711074829
step: 610, loss: 0.07438059896230698
step: 620, loss: 0.05557600408792496
step: 630, loss: 0.10667598247528076
step: 640, loss: 0.09734219312667847
step: 650, loss: 0.12037825584411621
step: 660, loss: 0.18743796646595
step: 670, loss: 0.18872293829917908
step: 680, loss: 0.13460509479045868
step: 690, loss: 0.11536882072687149
step: 700, loss: 0.12156232446432114
step: 710, loss: 0.07586947083473206
step: 720, loss: 0.09209460020065308
step: 730, loss: 0.05295368283987045
step: 740, loss: 0.2023024708032608
step: 750, loss: 0.1314392238855362
step: 760, loss: 0.1349100023508072
step: 770, loss: 0.10943659394979477
step: 780, loss: 0.04154393449425697
step: 790, loss: 0.11813466250896454
step: 800, loss: 0.028145894408226013
step: 810, loss: 0.08011540025472641
step: 820, loss: 0.19665125012397766
step: 830, loss: 0.062910296022892
step: 840, loss: 0.07025975733995438
step: 850, loss: 0.17067140340805054
step: 860, loss: 0.14969220757484436
step: 870, loss: 0.07708068937063217
step: 880, loss: 0.06576510518789291
step: 890, loss: 0.05867651849985123
step: 900, loss: 0.11020191013813019
step: 910, loss: 0.0813901349902153
step: 920, loss: 0.05620478093624115
step: 930, loss: 0.057522498071193695
step: 940, loss: 0.08478208631277084
step: 950, loss: 0.16612710058689117
step: 960, loss: 0.0472274012863636
step: 970, loss: 0.1424163430929184
epoch 3: dev_f1=0.9354389224338133, f1=0.9315960912052118, best_f1=0.9315960912052118
step: 0, loss: 0.08149416744709015
step: 10, loss: 0.1385354846715927
step: 20, loss: 0.151286780834198
step: 30, loss: 0.17608536779880524
step: 40, loss: 0.1014452874660492
step: 50, loss: 0.1708456426858902
step: 60, loss: 0.109505794942379
step: 70, loss: 0.1735215187072754
step: 80, loss: 0.12314049899578094
step: 90, loss: 0.07152675092220306
step: 100, loss: 0.1176799014210701
step: 110, loss: 0.08143536746501923
step: 120, loss: 0.09115875512361526
step: 130, loss: 0.17126181721687317
step: 140, loss: 0.09299883246421814
step: 150, loss: 0.0415186882019043
step: 160, loss: 0.12029935419559479
step: 170, loss: 0.26183727383613586
step: 180, loss: 0.22155314683914185
step: 190, loss: 0.17093686759471893
step: 200, loss: 0.11413773894309998
step: 210, loss: 0.030211279168725014
step: 220, loss: 0.09268512576818466
step: 230, loss: 0.08685053139925003
step: 240, loss: 0.055363330990076065
step: 250, loss: 0.10691127181053162
step: 260, loss: 0.15502232313156128
step: 270, loss: 0.13115745782852173
step: 280, loss: 0.21994319558143616
step: 290, loss: 0.10956167429685593
step: 300, loss: 0.059682536870241165
step: 310, loss: 0.07786830514669418
step: 320, loss: 0.10758265852928162
step: 330, loss: 0.14035660028457642
step: 340, loss: 0.15488854050636292
step: 350, loss: 0.03946586698293686
step: 360, loss: 0.14894741773605347
step: 370, loss: 0.12822701036930084
step: 380, loss: 0.08662651479244232
step: 390, loss: 0.15677529573440552
step: 400, loss: 0.22653232514858246
step: 410, loss: 0.11189017444849014
step: 420, loss: 0.03917202353477478
step: 430, loss: 0.07572130113840103
step: 440, loss: 0.025388486683368683
step: 450, loss: 0.16348321735858917
step: 460, loss: 0.08931763470172882
step: 470, loss: 0.17595414817333221
step: 480, loss: 0.1091475784778595
step: 490, loss: 0.034050967544317245
step: 500, loss: 0.09097108244895935
step: 510, loss: 0.0706179291009903
step: 520, loss: 0.08490250259637833
step: 530, loss: 0.09223942458629608
step: 540, loss: 0.13515667617321014
step: 550, loss: 0.1267266720533371
step: 560, loss: 0.10731901973485947
step: 570, loss: 0.11970022320747375
step: 580, loss: 0.04935898259282112
step: 590, loss: 0.24693043529987335
step: 600, loss: 0.13424699008464813
step: 610, loss: 0.0708567276597023
step: 620, loss: 0.11366281658411026
step: 630, loss: 0.16066677868366241
step: 640, loss: 0.0793723613023758
step: 650, loss: 0.11242708563804626
step: 660, loss: 0.18891692161560059
step: 670, loss: 0.13184504210948944
step: 680, loss: 0.23704810440540314
step: 690, loss: 0.09176444262266159
step: 700, loss: 0.1556454598903656
step: 710, loss: 0.09222280979156494
step: 720, loss: 0.04329811781644821
step: 730, loss: 0.07276812195777893
step: 740, loss: 0.18001994490623474
step: 750, loss: 0.08491043001413345
step: 760, loss: 0.11020975559949875
step: 770, loss: 0.12182211130857468
step: 780, loss: 0.129409521818161
step: 790, loss: 0.047759268432855606
step: 800, loss: 0.06325939297676086
step: 810, loss: 0.0903225690126419
step: 820, loss: 0.1844971626996994
step: 830, loss: 0.13403001427650452
step: 840, loss: 0.13155461847782135
step: 850, loss: 0.1789226084947586
step: 860, loss: 0.09880560636520386
step: 870, loss: 0.11061751842498779
step: 880, loss: 0.165835902094841
step: 890, loss: 0.10554799437522888
step: 900, loss: 0.06218227371573448
step: 910, loss: 0.03517134487628937
step: 920, loss: 0.09759294241666794
step: 930, loss: 0.09726221859455109
step: 940, loss: 0.03656623885035515
step: 950, loss: 0.16763918101787567
step: 960, loss: 0.10296934098005295
step: 970, loss: 0.11421126872301102
epoch 4: dev_f1=0.9311969839773798, f1=0.9255966307908282, best_f1=0.9315960912052118
step: 0, loss: 0.09401214122772217
step: 10, loss: 0.14313338696956635
step: 20, loss: 0.12348680198192596
step: 30, loss: 0.10852164030075073
step: 40, loss: 0.029014989733695984
step: 50, loss: 0.09746715426445007
step: 60, loss: 0.09081297367811203
step: 70, loss: 0.14965201914310455
step: 80, loss: 0.01976807974278927
step: 90, loss: 0.16486233472824097
step: 100, loss: 0.1740383803844452
step: 110, loss: 0.15872883796691895
step: 120, loss: 0.18151123821735382
step: 130, loss: 0.04189876839518547
step: 140, loss: 0.06260424852371216
step: 150, loss: 0.10052773356437683
step: 160, loss: 0.0986771509051323
step: 170, loss: 0.07020220905542374
step: 180, loss: 0.05277348682284355
step: 190, loss: 0.05647004768252373
step: 200, loss: 0.0861835852265358
step: 210, loss: 0.09011803567409515
step: 220, loss: 0.08689194917678833
step: 230, loss: 0.06340809166431427
step: 240, loss: 0.09149471670389175
step: 250, loss: 0.12275667488574982
step: 260, loss: 0.2066338211297989
step: 270, loss: 0.056110069155693054
step: 280, loss: 0.02178979106247425
step: 290, loss: 0.04012153670191765
step: 300, loss: 0.06712469458580017
step: 310, loss: 0.15597474575042725
step: 320, loss: 0.07588560879230499
step: 330, loss: 0.09909810870885849
step: 340, loss: 0.15734665095806122
step: 350, loss: 0.0495181679725647
step: 360, loss: 0.06261326372623444
step: 370, loss: 0.04335228353738785
step: 380, loss: 0.07402930408716202
step: 390, loss: 0.13349220156669617
step: 400, loss: 0.11740836501121521
step: 410, loss: 0.023114299401640892
step: 420, loss: 0.19267570972442627
step: 430, loss: 0.0975692868232727
step: 440, loss: 0.06986352801322937
step: 450, loss: 0.19556917250156403
step: 460, loss: 0.028439048677682877
step: 470, loss: 0.040552034974098206
step: 480, loss: 0.17577588558197021
step: 490, loss: 0.08320804685354233
step: 500, loss: 0.14578135311603546
step: 510, loss: 0.054921191185712814
step: 520, loss: 0.08721526712179184
step: 530, loss: 0.07862933725118637
step: 540, loss: 0.04980519786477089
step: 550, loss: 0.09829338639974594
step: 560, loss: 0.10186124593019485
step: 570, loss: 0.030395079404115677
step: 580, loss: 0.05700802430510521
step: 590, loss: 0.07569179683923721
step: 600, loss: 0.34160274267196655
step: 610, loss: 0.10997989773750305
step: 620, loss: 0.06662898510694504
step: 630, loss: 0.14232943952083588
step: 640, loss: 0.21038025617599487
step: 650, loss: 0.011170747689902782
step: 660, loss: 0.12072230875492096
step: 670, loss: 0.19759711623191833
step: 680, loss: 0.09631548076868057
step: 690, loss: 0.09668441116809845
step: 700, loss: 0.1603853553533554
step: 710, loss: 0.1285315454006195
step: 720, loss: 0.05662432312965393
step: 730, loss: 0.09713411331176758
step: 740, loss: 0.0410475991666317
step: 750, loss: 0.06738034635782242
step: 760, loss: 0.028245452791452408
step: 770, loss: 0.1389704942703247
step: 780, loss: 0.08099581301212311
step: 790, loss: 0.12325013428926468
step: 800, loss: 0.17103558778762817
step: 810, loss: 0.09667190164327621
step: 820, loss: 0.16242387890815735
step: 830, loss: 0.06298932433128357
step: 840, loss: 0.04826900735497475
step: 850, loss: 0.007623661309480667
step: 860, loss: 0.10983334481716156
step: 870, loss: 0.03338795527815819
step: 880, loss: 0.08027247339487076
step: 890, loss: 0.14227260649204254
step: 900, loss: 0.1594594120979309
step: 910, loss: 0.051187530159950256
step: 920, loss: 0.157586008310318
step: 930, loss: 0.12041712552309036
step: 940, loss: 0.06943080574274063
step: 950, loss: 0.087018221616745
step: 960, loss: 0.06699052453041077
step: 970, loss: 0.04894332215189934
epoch 5: dev_f1=0.9354545454545454, f1=0.929384965831435, best_f1=0.929384965831435
step: 0, loss: 0.06853823363780975
step: 10, loss: 0.014412811025977135
step: 20, loss: 0.11700254678726196
step: 30, loss: 0.14956188201904297
step: 40, loss: 0.1089184507727623
step: 50, loss: 0.0724102035164833
step: 60, loss: 0.18498237431049347
step: 70, loss: 0.08865254372358322
step: 80, loss: 0.19246676564216614
step: 90, loss: 0.09998154640197754
step: 100, loss: 0.1763300597667694
step: 110, loss: 0.07942699640989304
step: 120, loss: 0.08481114357709885
step: 130, loss: 0.059660110622644424
step: 140, loss: 0.033021602779626846
step: 150, loss: 0.041333772242069244
step: 160, loss: 0.0743335485458374
step: 170, loss: 0.017527461051940918
step: 180, loss: 0.08911120146512985
step: 190, loss: 0.10089068114757538
step: 200, loss: 0.08802556246519089
step: 210, loss: 0.06718652695417404
step: 220, loss: 0.06700554490089417
step: 230, loss: 0.0615934282541275
step: 240, loss: 0.08237036317586899
step: 250, loss: 0.05408548563718796
step: 260, loss: 0.06897509098052979
step: 270, loss: 0.07281523942947388
step: 280, loss: 0.02029384672641754
step: 290, loss: 0.11608234792947769
step: 300, loss: 0.16712656617164612
step: 310, loss: 0.080990269780159
step: 320, loss: 0.205560564994812
step: 330, loss: 0.06475960463285446
step: 340, loss: 0.09008093923330307
step: 350, loss: 0.09994594007730484
step: 360, loss: 0.0813218355178833
step: 370, loss: 0.018218830227851868
step: 380, loss: 0.04759221896529198
step: 390, loss: 0.10583309829235077
step: 400, loss: 0.17468389868736267
step: 410, loss: 0.011756726540625095
step: 420, loss: 0.03093530423939228
step: 430, loss: 0.033359888941049576
step: 440, loss: 0.07285735756158829
step: 450, loss: 0.3120644986629486
step: 460, loss: 0.13736386597156525
step: 470, loss: 0.07783062756061554
step: 480, loss: 0.023629482835531235
step: 490, loss: 0.08450622856616974
step: 500, loss: 0.032685454934835434
step: 510, loss: 0.09356605261564255
step: 520, loss: 0.17335954308509827
step: 530, loss: 0.028962697833776474
step: 540, loss: 0.09155116975307465
step: 550, loss: 0.18166892230510712
step: 560, loss: 0.08007145673036575
step: 570, loss: 0.048635292798280716
step: 580, loss: 0.09583340585231781
step: 590, loss: 0.13507601618766785
step: 600, loss: 0.11960647255182266
step: 610, loss: 0.07468131929636002
step: 620, loss: 0.038144394755363464
step: 630, loss: 0.14613758027553558
step: 640, loss: 0.06010478734970093
step: 650, loss: 0.11560451239347458
step: 660, loss: 0.02409295365214348
step: 670, loss: 0.09318960458040237
step: 680, loss: 0.09402599930763245
step: 690, loss: 0.16936054825782776
step: 700, loss: 0.07428015023469925
step: 710, loss: 0.14125803112983704
step: 720, loss: 0.13360464572906494
step: 730, loss: 0.012478675693273544
step: 740, loss: 0.09639133512973785
step: 750, loss: 0.09616625308990479
step: 760, loss: 0.1286022812128067
step: 770, loss: 0.29857590794563293
step: 780, loss: 0.08761134743690491
step: 790, loss: 0.03566157817840576
step: 800, loss: 0.19798006117343903
step: 810, loss: 0.08935920894145966
step: 820, loss: 0.037883590906858444
step: 830, loss: 0.22301749885082245
step: 840, loss: 0.11655305325984955
step: 850, loss: 0.12698715925216675
step: 860, loss: 0.08537256717681885
step: 870, loss: 0.13319075107574463
step: 880, loss: 0.09428638219833374
step: 890, loss: 0.15327535569667816
step: 900, loss: 0.12371239811182022
step: 910, loss: 0.1910049170255661
step: 920, loss: 0.0651412308216095
step: 930, loss: 0.02975698560476303
step: 940, loss: 0.13489805161952972
step: 950, loss: 0.13884200155735016
step: 960, loss: 0.09156360477209091
step: 970, loss: 0.17113660275936127
epoch 6: dev_f1=0.926851431167651, f1=0.9198732458125848, best_f1=0.929384965831435
step: 0, loss: 0.13054664433002472
step: 10, loss: 0.03534853085875511
step: 20, loss: 0.0995740294456482
step: 30, loss: 0.05894497409462929
step: 40, loss: 0.03764396905899048
step: 50, loss: 0.08001364767551422
step: 60, loss: 0.04560620337724686
step: 70, loss: 0.031515415757894516
step: 80, loss: 0.04936566576361656
step: 90, loss: 0.034580834209918976
step: 100, loss: 0.05993668735027313
step: 110, loss: 0.13536809384822845
step: 120, loss: 0.05611079931259155
step: 130, loss: 0.031636565923690796
step: 140, loss: 0.06619090586900711
step: 150, loss: 0.00020843058882746845
step: 160, loss: 0.1379561722278595
step: 170, loss: 0.07144735008478165
step: 180, loss: 0.12800240516662598
step: 190, loss: 0.08436736464500427
step: 200, loss: 0.1689649373292923
step: 210, loss: 0.09486167877912521
step: 220, loss: 0.09616164118051529
step: 230, loss: 0.04537401720881462
step: 240, loss: 0.08120937645435333
step: 250, loss: 0.09492351859807968
step: 260, loss: 0.13176827132701874
step: 270, loss: 0.07887610048055649
step: 280, loss: 0.040132757276296616
step: 290, loss: 0.07676686346530914
step: 300, loss: 0.15083211660385132
step: 310, loss: 0.16178908944129944
step: 320, loss: 0.11517415940761566
step: 330, loss: 0.10608543455600739
step: 340, loss: 0.0793905034661293
step: 350, loss: 0.0944283977150917
step: 360, loss: 0.21581758558750153
step: 370, loss: 0.09904967248439789
step: 380, loss: 0.16003848612308502
step: 390, loss: 0.11304058879613876
step: 400, loss: 0.1631922572851181
step: 410, loss: 0.0698554590344429
step: 420, loss: 0.1293366253376007
step: 430, loss: 0.1460142731666565
step: 440, loss: 0.020363207906484604
step: 450, loss: 0.041945137083530426
step: 460, loss: 0.22059929370880127
step: 470, loss: 0.12281831353902817
step: 480, loss: 0.13734295964241028
step: 490, loss: 0.07554139196872711
step: 500, loss: 0.10882323980331421
step: 510, loss: 0.02114294096827507
step: 520, loss: 0.07320961356163025
step: 530, loss: 0.11135733872652054
step: 540, loss: 0.08486244827508926
step: 550, loss: 0.032974667847156525
step: 560, loss: 0.08825366944074631
step: 570, loss: 0.130331888794899
step: 580, loss: 0.10117112100124359
step: 590, loss: 0.11255580931901932
step: 600, loss: 0.06955676525831223
step: 610, loss: 0.06447630375623703
step: 620, loss: 0.0985272079706192
step: 630, loss: 0.12053293734788895
step: 640, loss: 0.07547859102487564
step: 650, loss: 0.23859292268753052
step: 660, loss: 0.12320516258478165
step: 670, loss: 0.057118695229291916
step: 680, loss: 0.10930158197879791
step: 690, loss: 0.10247375071048737
step: 700, loss: 0.037016622722148895
step: 710, loss: 0.09991993755102158
step: 720, loss: 0.1443018615245819
step: 730, loss: 0.05394437909126282
step: 740, loss: 0.01725607179105282
step: 750, loss: 0.2779940068721771
step: 760, loss: 0.13097354769706726
step: 770, loss: 0.14606130123138428
step: 780, loss: 0.26272326707839966
step: 790, loss: 0.06363032758235931
step: 800, loss: 0.0777357816696167
step: 810, loss: 0.13024267554283142
step: 820, loss: 0.07691991329193115
step: 830, loss: 0.10496839135885239
step: 840, loss: 0.12011363357305527
step: 850, loss: 0.1823686957359314
step: 860, loss: 0.12445510178804398
step: 870, loss: 0.06881070137023926
step: 880, loss: 0.1146557405591011
step: 890, loss: 0.06578338146209717
step: 900, loss: 0.059860002249479294
step: 910, loss: 0.10056812316179276
step: 920, loss: 0.05922703817486763
step: 930, loss: 0.15502682328224182
step: 940, loss: 0.15911611914634705
step: 950, loss: 0.05315732955932617
step: 960, loss: 0.20742195844650269
step: 970, loss: 0.017236176878213882
epoch 7: dev_f1=0.937528921795465, f1=0.9310504396112911, best_f1=0.9310504396112911
step: 0, loss: 0.12492527067661285
step: 10, loss: 0.09429072588682175
step: 20, loss: 0.1557864397764206
step: 30, loss: 0.0604097880423069
step: 40, loss: 0.10119666904211044
step: 50, loss: 0.05337700992822647
step: 60, loss: 0.11620660871267319
step: 70, loss: 0.13294190168380737
step: 80, loss: 0.18972796201705933
step: 90, loss: 0.04795810952782631
step: 100, loss: 0.045389775186777115
step: 110, loss: 0.051678165793418884
step: 120, loss: 0.007687406614422798
step: 130, loss: 0.19278261065483093
step: 140, loss: 0.010917610488831997
step: 150, loss: 0.04795502498745918
step: 160, loss: 0.07876255363225937
step: 170, loss: 0.11574967205524445
step: 180, loss: 0.06252776831388474
step: 190, loss: 0.08393167704343796
step: 200, loss: 0.1625385731458664
step: 210, loss: 0.07702044397592545
step: 220, loss: 0.020532088354229927
step: 230, loss: 0.1135527715086937
step: 240, loss: 0.07492832839488983
step: 250, loss: 0.01924579218029976
step: 260, loss: 0.030741622671484947
step: 270, loss: 0.1341724693775177
step: 280, loss: 0.06043320521712303
step: 290, loss: 0.025727007538080215
step: 300, loss: 0.15044695138931274
step: 310, loss: 0.07293333113193512
step: 320, loss: 0.044489435851573944
step: 330, loss: 0.13946327567100525
step: 340, loss: 0.04780187830328941
step: 350, loss: 0.03423561155796051
step: 360, loss: 0.05678744614124298
step: 370, loss: 0.04615632817149162
step: 380, loss: 0.16923944652080536
step: 390, loss: 0.2567322552204132
step: 400, loss: 0.06728444248437881
step: 410, loss: 0.07067437469959259
step: 420, loss: 0.1372053623199463
step: 430, loss: 0.0466889925301075
step: 440, loss: 0.06758970022201538
step: 450, loss: 0.05253981053829193
step: 460, loss: 0.09165001660585403
step: 470, loss: 0.13127630949020386
step: 480, loss: 0.12147240340709686
step: 490, loss: 0.042433060705661774
step: 500, loss: 0.05929027870297432
step: 510, loss: 0.06988412886857986
step: 520, loss: 0.025408416986465454
step: 530, loss: 0.1454765498638153
step: 540, loss: 0.038258299231529236
step: 550, loss: 0.02096369117498398
step: 560, loss: 0.049196284264326096
step: 570, loss: 0.08080499619245529
step: 580, loss: 0.06407430022954941
step: 590, loss: 0.0607701875269413
step: 600, loss: 0.15964774787425995
step: 610, loss: 0.10149472951889038
step: 620, loss: 0.20006892085075378
step: 630, loss: 0.09545467048883438
step: 640, loss: 0.013476576656103134
step: 650, loss: 0.10677805542945862
step: 660, loss: 0.07927914708852768
step: 670, loss: 0.08128079026937485
step: 680, loss: 0.06972089409828186
step: 690, loss: 0.042321886867284775
step: 700, loss: 0.26004210114479065
step: 710, loss: 0.08836133778095245
step: 720, loss: 0.0966242253780365
step: 730, loss: 0.1240396574139595
step: 740, loss: 0.02813192829489708
step: 750, loss: 0.1267847716808319
step: 760, loss: 0.09796156734228134
step: 770, loss: 0.04931148514151573
step: 780, loss: 0.06534736603498459
step: 790, loss: 0.1065199077129364
step: 800, loss: 0.07436707615852356
step: 810, loss: 0.0990833267569542
step: 820, loss: 0.12770810723304749
step: 830, loss: 0.06633360683917999
step: 840, loss: 0.062175266444683075
step: 850, loss: 0.008000041358172894
step: 860, loss: 0.18984106183052063
step: 870, loss: 0.1376558244228363
step: 880, loss: 0.07991307228803635
step: 890, loss: 0.1482148915529251
step: 900, loss: 0.19153594970703125
step: 910, loss: 0.15364155173301697
step: 920, loss: 0.07142533361911774
step: 930, loss: 0.0964469164609909
step: 940, loss: 0.10862159729003906
step: 950, loss: 0.10655497759580612
step: 960, loss: 0.13738076388835907
step: 970, loss: 0.15629082918167114
epoch 8: dev_f1=0.9323447636700649, f1=0.9361702127659576, best_f1=0.9310504396112911
step: 0, loss: 0.08192700147628784
step: 10, loss: 0.06302864849567413
step: 20, loss: 0.11795774102210999
step: 30, loss: 0.048782829195261
step: 40, loss: 0.05275392904877663
step: 50, loss: 0.08278997242450714
step: 60, loss: 0.15674492716789246
step: 70, loss: 0.012201587669551373
step: 80, loss: 0.083834208548069
step: 90, loss: 0.10740333050489426
step: 100, loss: 0.045966751873493195
step: 110, loss: 0.01652492769062519
step: 120, loss: 0.044278375804424286
step: 130, loss: 0.05199394375085831
step: 140, loss: 0.08549130707979202
step: 150, loss: 0.042228177189826965
step: 160, loss: 0.064419686794281
step: 170, loss: 0.07318165898323059
step: 180, loss: 0.03738829120993614
step: 190, loss: 0.10952824354171753
step: 200, loss: 0.034114375710487366
step: 210, loss: 0.13370348513126373
step: 220, loss: 0.09153345227241516
step: 230, loss: 0.012376023456454277
step: 240, loss: 0.013081145472824574
step: 250, loss: 0.03295383229851723
step: 260, loss: 0.041040290147066116
step: 270, loss: 0.036166951060295105
step: 280, loss: 0.02120288647711277
step: 290, loss: 0.056475795805454254
step: 300, loss: 0.09137684106826782
step: 310, loss: 0.0588558055460453
step: 320, loss: 0.06007687747478485
step: 330, loss: 0.0903518870472908
step: 340, loss: 0.07307945936918259
step: 350, loss: 0.07978428900241852
step: 360, loss: 0.02946620061993599
step: 370, loss: 0.07530857622623444
step: 380, loss: 0.2111530900001526
step: 390, loss: 0.04134727269411087
step: 400, loss: 0.0503552071750164
step: 410, loss: 0.04156836122274399
step: 420, loss: 0.06078973785042763
step: 430, loss: 0.07519090175628662
step: 440, loss: 0.0038067596033215523
step: 450, loss: 0.06807874143123627
step: 460, loss: 0.0647561177611351
step: 470, loss: 0.10444113612174988
step: 480, loss: 0.035850122570991516
step: 490, loss: 0.08422114700078964
step: 500, loss: 0.09664298593997955
step: 510, loss: 0.08628212660551071
step: 520, loss: 0.11772328615188599
step: 530, loss: 0.014960082247853279
step: 540, loss: 0.044361405074596405
step: 550, loss: 0.019873125478625298
step: 560, loss: 0.077627032995224
step: 570, loss: 0.07018841058015823
step: 580, loss: 0.05006907135248184
step: 590, loss: 0.0395636223256588
step: 600, loss: 0.07704541087150574
step: 610, loss: 0.02674550749361515
step: 620, loss: 0.1116042211651802
step: 630, loss: 0.026341965422034264
step: 640, loss: 0.13447806239128113
step: 650, loss: 0.050627704709768295
step: 660, loss: 0.1959424912929535
step: 670, loss: 0.0904923677444458
step: 680, loss: 0.19771446287631989
step: 690, loss: 0.05761650577187538
step: 700, loss: 0.08570587635040283
step: 710, loss: 0.07466494292020798
step: 720, loss: 0.02314986288547516
step: 730, loss: 0.10014618933200836
step: 740, loss: 0.08829870820045471
step: 750, loss: 0.06640293449163437
step: 760, loss: 0.051399312913417816
step: 770, loss: 0.023318098857998848
step: 780, loss: 0.1138533428311348
step: 790, loss: 0.10505543649196625
step: 800, loss: 0.011982498690485954
step: 810, loss: 0.13749676942825317
step: 820, loss: 0.03766721859574318
step: 830, loss: 0.03977680578827858
step: 840, loss: 0.09626320749521255
step: 850, loss: 0.012098569422960281
step: 860, loss: 0.14380209147930145
step: 870, loss: 0.10843862593173981
step: 880, loss: 0.2629837393760681
step: 890, loss: 0.10881388932466507
step: 900, loss: 0.010741946287453175
step: 910, loss: 0.04743179306387901
step: 920, loss: 1.4185513464326505e-05
step: 930, loss: 0.04189547151327133
step: 940, loss: 0.021357852965593338
step: 950, loss: 0.035342685878276825
step: 960, loss: 0.08808798342943192
step: 970, loss: 0.05123338848352432
epoch 9: dev_f1=0.9351251158480075, f1=0.9278445883441258, best_f1=0.9310504396112911
step: 0, loss: 0.0562504306435585
step: 10, loss: 0.023813679814338684
step: 20, loss: 0.02597387135028839
step: 30, loss: 0.02249697782099247
step: 40, loss: 0.05685817450284958
step: 50, loss: 0.09760664403438568
step: 60, loss: 0.08995425701141357
step: 70, loss: 0.08831893652677536
step: 80, loss: 0.05238953232765198
step: 90, loss: 0.06910936534404755
step: 100, loss: 0.013094598427414894
step: 110, loss: 0.11150504648685455
step: 120, loss: 0.002388554625213146
step: 130, loss: 0.07612306624650955
step: 140, loss: 0.07913985103368759
step: 150, loss: 0.09072119742631912
step: 160, loss: 0.06466637551784515
step: 170, loss: 0.5054345726966858
step: 180, loss: 0.18864576518535614
step: 190, loss: 0.013281209394335747
step: 200, loss: 0.13318106532096863
step: 210, loss: 0.07956983894109726
step: 220, loss: 0.026780471205711365
step: 230, loss: 0.0003750091418623924
step: 240, loss: 0.10249372571706772
step: 250, loss: 0.06285349279642105
step: 260, loss: 0.10032559931278229
step: 270, loss: 0.10933792591094971
step: 280, loss: 0.01341066975146532
step: 290, loss: 0.049272943288087845
step: 300, loss: 0.13907615840435028
step: 310, loss: 0.13840250670909882
step: 320, loss: 0.08686134964227676
step: 330, loss: 0.18306821584701538
step: 340, loss: 0.030742758885025978
step: 350, loss: 0.020670827478170395
step: 360, loss: 0.01213973481208086
step: 370, loss: 0.06348701566457748
step: 380, loss: 0.11073604971170425
step: 390, loss: 0.06326332688331604
step: 400, loss: 0.06081268936395645
step: 410, loss: 0.06356735527515411
step: 420, loss: 0.029969103634357452
step: 430, loss: 0.04888206347823143
step: 440, loss: 0.06469427794218063
step: 450, loss: 0.025061044842004776
step: 460, loss: 0.07155324518680573
step: 470, loss: 0.053243983536958694
step: 480, loss: 0.022707277908921242
step: 490, loss: 0.20080022513866425
step: 500, loss: 0.031716156750917435
step: 510, loss: 0.022377323359251022
step: 520, loss: 0.07297268509864807
step: 530, loss: 0.015009741298854351
step: 540, loss: 0.06343284249305725
step: 550, loss: 0.08060642331838608
step: 560, loss: 0.05805441737174988
step: 570, loss: 0.15987251698970795
step: 580, loss: 0.12662094831466675
step: 590, loss: 0.12133549153804779
step: 600, loss: 0.04255213588476181
step: 610, loss: 0.07817769795656204
step: 620, loss: 0.14702869951725006
step: 630, loss: 0.041730716824531555
step: 640, loss: 0.0286538265645504
step: 650, loss: 0.11985952407121658
step: 660, loss: 0.23297986388206482
step: 670, loss: 0.07402250915765762
step: 680, loss: 0.039067696779966354
step: 690, loss: 0.15981462597846985
step: 700, loss: 0.277161568403244
step: 710, loss: 0.034288838505744934
step: 720, loss: 0.09163201600313187
step: 730, loss: 0.02952544018626213
step: 740, loss: 0.10926845669746399
step: 750, loss: 0.0294242762029171
step: 760, loss: 0.05960068106651306
step: 770, loss: 0.0269756056368351
step: 780, loss: 0.04988381266593933
step: 790, loss: 0.09470313787460327
step: 800, loss: 0.14798840880393982
step: 810, loss: 0.06652507185935974
step: 820, loss: 0.07293600589036942
step: 830, loss: 0.03444954380393028
step: 840, loss: 0.049102671444416046
step: 850, loss: 0.08312749862670898
step: 860, loss: 0.1750304251909256
step: 870, loss: 0.08241325616836548
step: 880, loss: 0.017340971156954765
step: 890, loss: 0.06285504251718521
step: 900, loss: 0.10178319364786148
step: 910, loss: 0.057211440056562424
step: 920, loss: 0.1544557511806488
step: 930, loss: 0.10522803664207458
step: 940, loss: 0.05990970507264137
step: 950, loss: 0.03474140912294388
step: 960, loss: 0.16289407014846802
step: 970, loss: 0.16935527324676514
epoch 10: dev_f1=0.9308411214953269, f1=0.929889298892989, best_f1=0.9310504396112911
step: 0, loss: 0.04118003696203232
step: 10, loss: 0.09896747022867203
step: 20, loss: 0.050381310284137726
step: 30, loss: 0.0754021406173706
step: 40, loss: 0.013360418379306793
step: 50, loss: 0.06360673159360886
step: 60, loss: 0.04684997349977493
step: 70, loss: 0.0876777395606041
step: 80, loss: 0.022144807502627373
step: 90, loss: 0.06404483318328857
step: 100, loss: 0.09082271158695221
step: 110, loss: 0.09012544900178909
step: 120, loss: 0.054265908896923065
step: 130, loss: 0.09530965238809586
step: 140, loss: 0.08461419492959976
step: 150, loss: 0.0878235474228859
step: 160, loss: 0.1150669977068901
step: 170, loss: 0.041631851345300674
step: 180, loss: 0.0016117262421175838
step: 190, loss: 0.10111810266971588
step: 200, loss: 0.05267007648944855
step: 210, loss: 0.13678613305091858
step: 220, loss: 0.08005654811859131
step: 230, loss: 0.044178612530231476
step: 240, loss: 0.064401775598526
step: 250, loss: 0.07149346172809601
step: 260, loss: 0.009219304658472538
step: 270, loss: 0.02667764574289322
step: 280, loss: 0.0706503763794899
step: 290, loss: 0.11513788253068924
step: 300, loss: 0.05467881262302399
step: 310, loss: 0.03765412047505379
step: 320, loss: 0.05801498144865036
step: 330, loss: 0.09079555422067642
step: 340, loss: 0.059569764882326126
step: 350, loss: 0.20637820661067963
step: 360, loss: 0.011866680346429348
step: 370, loss: 0.10365733504295349
step: 380, loss: 0.22594593465328217
step: 390, loss: 0.1720019429922104
step: 400, loss: 0.1408976912498474
step: 410, loss: 0.013022717088460922
step: 420, loss: 0.09200580418109894
step: 430, loss: 0.03350609168410301
step: 440, loss: 0.1612824946641922
step: 450, loss: 0.07110849767923355
step: 460, loss: 0.07585521042346954
step: 470, loss: 0.10086110234260559
step: 480, loss: 0.17412354052066803
step: 490, loss: 0.053583767265081406
step: 500, loss: 0.03450660780072212
step: 510, loss: 0.029825862497091293
step: 520, loss: 0.045143891125917435
step: 530, loss: 0.18920297920703888
step: 540, loss: 0.12870420515537262
step: 550, loss: 0.0022951492574065924
step: 560, loss: 0.025038214400410652
step: 570, loss: 0.03187207877635956
step: 580, loss: 0.038916800171136856
step: 590, loss: 0.06011287122964859
step: 600, loss: 0.05962030589580536
step: 610, loss: 0.0972590520977974
step: 620, loss: 0.023149829357862473
step: 630, loss: 0.09424860775470734
step: 640, loss: 0.19921651482582092
step: 650, loss: 0.042271923273801804
step: 660, loss: 0.04121699184179306
step: 670, loss: 0.07054453343153
step: 680, loss: 0.24787290394306183
step: 690, loss: 0.058508481830358505
step: 700, loss: 0.039386086165905
step: 710, loss: 0.04688860476016998
step: 720, loss: 0.09769344329833984
step: 730, loss: 0.0009514010744169354
step: 740, loss: 0.12127687782049179
step: 750, loss: 0.11990918964147568
step: 760, loss: 0.14868946373462677
step: 770, loss: 0.028735674917697906
step: 780, loss: 0.04094783216714859
step: 790, loss: 0.07774867862462997
step: 800, loss: 0.13630886375904083
step: 810, loss: 0.020215975120663643
step: 820, loss: 0.025897681713104248
step: 830, loss: 0.08481880277395248
step: 840, loss: 0.036228977143764496
step: 850, loss: 0.09001414477825165
step: 860, loss: 0.04637400060892105
step: 870, loss: 0.01876937225461006
step: 880, loss: 0.138368159532547
step: 890, loss: 0.14539417624473572
step: 900, loss: 1.5306864952435717e-05
step: 910, loss: 0.029013585299253464
step: 920, loss: 0.10958486795425415
step: 930, loss: 0.0555863231420517
step: 940, loss: 0.03469279780983925
step: 950, loss: 0.024029435589909554
step: 960, loss: 0.09194660186767578
step: 970, loss: 0.10682734847068787
epoch 11: dev_f1=0.9355586462679647, f1=0.9313680331644404, best_f1=0.9310504396112911
step: 0, loss: 0.10777737200260162
step: 10, loss: 0.0517343245446682
step: 20, loss: 0.003197738667950034
step: 30, loss: 0.16593801975250244
step: 40, loss: 0.10340900719165802
step: 50, loss: 0.11040489375591278
step: 60, loss: 0.03586559742689133
step: 70, loss: 0.01048936415463686
step: 80, loss: 0.05639326944947243
step: 90, loss: 0.053328778594732285
step: 100, loss: 0.038551609963178635
step: 110, loss: 0.08907759189605713
step: 120, loss: 0.014965170063078403
step: 130, loss: 0.001349691767245531
step: 140, loss: 0.059365496039390564
step: 150, loss: 0.19210411608219147
step: 160, loss: 0.06731788069009781
step: 170, loss: 0.17577342689037323
step: 180, loss: 0.017727401107549667
step: 190, loss: 0.04601196199655533
step: 200, loss: 0.015647513791918755
step: 210, loss: 0.09179709851741791
step: 220, loss: 0.04844459891319275
step: 230, loss: 0.08663291484117508
step: 240, loss: 0.04112589359283447
step: 250, loss: 0.07467399537563324
step: 260, loss: 0.0676422119140625
step: 270, loss: 0.0645071417093277
step: 280, loss: 0.06096004322171211
step: 290, loss: 0.036746762692928314
step: 300, loss: 0.14649556577205658
step: 310, loss: 0.04043751209974289
step: 320, loss: 0.04954347014427185
step: 330, loss: 0.029507948085665703
step: 340, loss: 0.10418351739645004
step: 350, loss: 0.04559016972780228
step: 360, loss: 0.021487094461917877
step: 370, loss: 0.09296872466802597
step: 380, loss: 0.014382160268723965
step: 390, loss: 0.05846176669001579
step: 400, loss: 0.013311302289366722
step: 410, loss: 0.01956847682595253
step: 420, loss: 0.07085457444190979
step: 430, loss: 0.01798178255558014
step: 440, loss: 0.020241955295205116
step: 450, loss: 0.05148649588227272
step: 460, loss: 0.11937685310840607
step: 470, loss: 0.05108663812279701
step: 480, loss: 0.042079858481884
step: 490, loss: 0.04302948713302612
step: 500, loss: 0.0873730257153511
step: 510, loss: 0.22666746377944946
step: 520, loss: 0.07424251735210419
step: 530, loss: 0.016468595713377
step: 540, loss: 0.006854604929685593
step: 550, loss: 0.018716931343078613
step: 560, loss: 0.10976625978946686
step: 570, loss: 0.13625679910182953
step: 580, loss: 0.09716903418302536
step: 590, loss: 0.09746652096509933
step: 600, loss: 0.08444161713123322
step: 610, loss: 0.0596054270863533
step: 620, loss: 0.07354256510734558
step: 630, loss: 0.03480056673288345
step: 640, loss: 0.13920269906520844
step: 650, loss: 0.09593459963798523
step: 660, loss: 0.027381662279367447
step: 670, loss: 0.0952148586511612
step: 680, loss: 0.0024200938642024994
step: 690, loss: 0.0417960062623024
step: 700, loss: 0.051168832927942276
step: 710, loss: 0.07059937715530396
step: 720, loss: 0.13712553679943085
step: 730, loss: 0.06498145312070847
step: 740, loss: 0.0708514153957367
step: 750, loss: 0.014058797620236874
step: 760, loss: 0.0776713490486145
step: 770, loss: 0.1820291131734848
step: 780, loss: 0.04874755069613457
step: 790, loss: 0.09316311031579971
step: 800, loss: 0.054431233555078506
step: 810, loss: 0.04931090772151947
step: 820, loss: 0.021875586360692978
step: 830, loss: 0.07753557711839676
step: 840, loss: 0.12138763815164566
step: 850, loss: 0.03081502579152584
step: 860, loss: 0.024633722379803658
step: 870, loss: 0.022193294018507004
step: 880, loss: 0.033686403185129166
step: 890, loss: 0.03793953359127045
step: 900, loss: 0.044906601309776306
step: 910, loss: 0.053394615650177
step: 920, loss: 0.028741871938109398
step: 930, loss: 0.028952602297067642
step: 940, loss: 0.05013898387551308
step: 950, loss: 0.18780605494976044
step: 960, loss: 0.08218482881784439
step: 970, loss: 0.15546931326389313
epoch 12: dev_f1=0.9359963685882887, f1=0.9311594202898551, best_f1=0.9310504396112911
step: 0, loss: 0.0630853995680809
step: 10, loss: 0.031484849750995636
step: 20, loss: 0.0007261947612278163
step: 30, loss: 0.11018994450569153
step: 40, loss: 0.08866346627473831
step: 50, loss: 0.18398241698741913
step: 60, loss: 0.08704658597707748
step: 70, loss: 0.07412700355052948
step: 80, loss: 0.016598554328083992
step: 90, loss: 0.08366774022579193
step: 100, loss: 0.06405539065599442
step: 110, loss: 0.046100638806819916
step: 120, loss: 0.01985841803252697
step: 130, loss: 0.040113192051649094
step: 140, loss: 0.05794020742177963
step: 150, loss: 0.07102516293525696
step: 160, loss: 0.056063320487737656
step: 170, loss: 0.1319611668586731
step: 180, loss: 0.061668846756219864
step: 190, loss: 0.05275127664208412
step: 200, loss: 0.06305641680955887
step: 210, loss: 0.06021599844098091
step: 220, loss: 0.10439229011535645
step: 230, loss: 0.017250092700123787
step: 240, loss: 0.09879642724990845
step: 250, loss: 0.025376152247190475
step: 260, loss: 0.026692993938922882
step: 270, loss: 0.002204893622547388
step: 280, loss: 0.052186306565999985
step: 290, loss: 0.09348571300506592
step: 300, loss: 0.0026025716215372086
step: 310, loss: 0.06797850131988525
step: 320, loss: 0.02303934469819069
step: 330, loss: 0.032044149935245514
step: 340, loss: 0.010224120691418648
step: 350, loss: 0.03781197965145111
step: 360, loss: 0.031449731439352036
step: 370, loss: 0.05207500234246254
step: 380, loss: 0.07497027516365051
step: 390, loss: 0.015095995739102364
step: 400, loss: 0.06563356518745422
step: 410, loss: 0.04197775945067406
step: 420, loss: 0.003637155517935753
step: 430, loss: 0.02155790477991104
step: 440, loss: 0.0716504231095314
step: 450, loss: 0.10710296779870987
step: 460, loss: 0.053436681628227234
step: 470, loss: 0.01419351901859045
step: 480, loss: 0.08319055289030075
step: 490, loss: 0.001006107428111136
step: 500, loss: 0.09406282007694244
step: 510, loss: 0.02883036434650421
step: 520, loss: 0.0015688184648752213
step: 530, loss: 0.031206537038087845
step: 540, loss: 0.08165047317743301
step: 550, loss: 0.04698888212442398
step: 560, loss: 0.08629228919744492
step: 570, loss: 0.13326041400432587
step: 580, loss: 0.0666036307811737
step: 590, loss: 0.0748562216758728
step: 600, loss: 0.12684139609336853
step: 610, loss: 0.19598528742790222
step: 620, loss: 0.08568023145198822
step: 630, loss: 0.07414676994085312
step: 640, loss: 0.038984984159469604
step: 650, loss: 0.056110382080078125
step: 660, loss: 0.016899220645427704
step: 670, loss: 0.021880513057112694
step: 680, loss: 0.09775779396295547
step: 690, loss: 0.06106141582131386
step: 700, loss: 0.06854724138975143
step: 710, loss: 0.041819121688604355
step: 720, loss: 0.09501784294843674
step: 730, loss: 0.10635298490524292
step: 740, loss: 0.038221146911382675
step: 750, loss: 0.06360353529453278
step: 760, loss: 0.05794538930058479
step: 770, loss: 0.1530310958623886
step: 780, loss: 0.09655219316482544
step: 790, loss: 0.06450043618679047
step: 800, loss: 0.1659737229347229
step: 810, loss: 0.036972157657146454
step: 820, loss: 0.09721815586090088
step: 830, loss: 0.05266169458627701
step: 840, loss: 0.022789720445871353
step: 850, loss: 0.020068908110260963
step: 860, loss: 0.0592380054295063
step: 870, loss: 0.047410331666469574
step: 880, loss: 0.07116899639368057
step: 890, loss: 0.06007201224565506
step: 900, loss: 0.07765352725982666
step: 910, loss: 0.060878075659275055
step: 920, loss: 0.13894034922122955
step: 930, loss: 0.07352229207754135
step: 940, loss: 0.042260851711034775
step: 950, loss: 0.02730434574186802
step: 960, loss: 0.026064487174153328
step: 970, loss: 0.11857383698225021
epoch 13: dev_f1=0.9311627906976745, f1=0.9261495587552253, best_f1=0.9310504396112911
step: 0, loss: 0.09766978025436401
step: 10, loss: 0.13006816804409027
step: 20, loss: 0.092816062271595
step: 30, loss: 0.07115984708070755
step: 40, loss: 0.05277004465460777
step: 50, loss: 0.030930565670132637
step: 60, loss: 0.06068005412817001
step: 70, loss: 0.0057435305789113045
step: 80, loss: 0.040528375655412674
step: 90, loss: 0.05269895866513252
step: 100, loss: 0.052829477936029434
step: 110, loss: 0.08488436043262482
step: 120, loss: 0.03671857342123985
step: 130, loss: 9.744177077664062e-05
step: 140, loss: 0.040819212794303894
step: 150, loss: 0.017436809837818146
step: 160, loss: 0.060290321707725525
step: 170, loss: 0.1490410417318344
step: 180, loss: 0.041941605508327484
step: 190, loss: 0.0547039620578289
step: 200, loss: 0.0058904001489281654
step: 210, loss: 0.0037303310818970203
step: 220, loss: 0.020229918882250786
step: 230, loss: 0.10431678593158722
step: 240, loss: 0.0872582495212555
step: 250, loss: 0.07494448125362396
step: 260, loss: 0.019734714180231094
step: 270, loss: 0.04445251077413559
step: 280, loss: 0.03790900856256485
step: 290, loss: 0.03213072940707207
step: 300, loss: 0.1429610401391983
step: 310, loss: 0.048782940953969955
step: 320, loss: 0.02923046238720417
step: 330, loss: 0.036440297961235046
step: 340, loss: 0.011867837980389595
step: 350, loss: 0.06242241710424423
step: 360, loss: 0.03674478828907013
step: 370, loss: 0.06163584068417549
step: 380, loss: 0.07091891020536423
step: 390, loss: 0.08618027716875076
step: 400, loss: 0.026536891236901283
step: 410, loss: 0.03186678886413574
step: 420, loss: 0.05305095762014389
step: 430, loss: 0.0011408335994929075
step: 440, loss: 0.0360436737537384
step: 450, loss: 0.043487388640642166
step: 460, loss: 0.04517117887735367
step: 470, loss: 0.029802463948726654
step: 480, loss: 0.04090125858783722
step: 490, loss: 0.039192963391542435
step: 500, loss: 0.05062135308980942
step: 510, loss: 0.03610895201563835
step: 520, loss: 0.1460881382226944
step: 530, loss: 0.009869408793747425
step: 540, loss: 0.0713621973991394
step: 550, loss: 0.042638566344976425
step: 560, loss: 0.01349297259002924
step: 570, loss: 0.06762624531984329
step: 580, loss: 0.04594123736023903
step: 590, loss: 0.09800270944833755
step: 600, loss: 0.005974472500383854
step: 610, loss: 0.022115476429462433
step: 620, loss: 0.07153167575597763
step: 630, loss: 0.023429231718182564
step: 640, loss: 0.050805188715457916
step: 650, loss: 0.1104230210185051
step: 660, loss: 0.06914126127958298
step: 670, loss: 0.03202062100172043
step: 680, loss: 0.08364053070545197
step: 690, loss: 0.020876482129096985
step: 700, loss: 0.041815243661403656
step: 710, loss: 0.04005733132362366
step: 720, loss: 0.05303522199392319
step: 730, loss: 0.057545263320207596
step: 740, loss: 0.13303807377815247
step: 750, loss: 0.01105006504803896
step: 760, loss: 0.1468663513660431
step: 770, loss: 0.12459466606378555
step: 780, loss: 0.09924675524234772
step: 790, loss: 0.09363548457622528
step: 800, loss: 0.05685628205537796
step: 810, loss: 0.03252403810620308
step: 820, loss: 0.09360689669847488
step: 830, loss: 0.056960053741931915
step: 840, loss: 0.0974683165550232
step: 850, loss: 0.019987670704722404
step: 860, loss: 0.0325622633099556
step: 870, loss: 0.06406467407941818
step: 880, loss: 0.09275151044130325
step: 890, loss: 0.043787501752376556
step: 900, loss: 0.09048966318368912
step: 910, loss: 0.0003370392369106412
step: 920, loss: 0.05481985583901405
step: 930, loss: 0.03719894960522652
step: 940, loss: 0.019992005079984665
step: 950, loss: 0.05414245277643204
step: 960, loss: 0.03814374655485153
step: 970, loss: 0.037971124053001404
epoch 14: dev_f1=0.9300567107750473, f1=0.9285714285714286, best_f1=0.9310504396112911
step: 0, loss: 0.05816153064370155
step: 10, loss: 0.07119064033031464
step: 20, loss: 0.02944760210812092
step: 30, loss: 0.07915355265140533
step: 40, loss: 0.024166706949472427
step: 50, loss: 0.04040023684501648
step: 60, loss: 0.04791845381259918
step: 70, loss: 0.02022993564605713
step: 80, loss: 0.053255509585142136
step: 90, loss: 0.010580940172076225
step: 100, loss: 0.04703165218234062
step: 110, loss: 0.026894964277744293
step: 120, loss: 0.05314996466040611
step: 130, loss: 0.014533749781548977
step: 140, loss: 0.06266465038061142
step: 150, loss: 0.021173005923628807
step: 160, loss: 0.08391562104225159
step: 170, loss: 0.06321302056312561
step: 180, loss: 0.03229910507798195
step: 190, loss: 0.05670224502682686
step: 200, loss: 0.05578472465276718
step: 210, loss: 0.09446292370557785
step: 220, loss: 0.021584339439868927
step: 230, loss: 0.05605139210820198
step: 240, loss: 0.11357437074184418
step: 250, loss: 0.01778198778629303
step: 260, loss: 0.011776335537433624
step: 270, loss: 0.12640497088432312
step: 280, loss: 0.014881467446684837
step: 290, loss: 0.010720682330429554
step: 300, loss: 0.09926169365644455
step: 310, loss: 0.024697203189134598
step: 320, loss: 0.0722198337316513
step: 330, loss: 0.01642117090523243
step: 340, loss: 0.050270017236471176
step: 350, loss: 0.05718746781349182
step: 360, loss: 0.05643204599618912
step: 370, loss: 0.08381514251232147
step: 380, loss: 0.09093669056892395
step: 390, loss: 0.02770945243537426
step: 400, loss: 0.059625789523124695
step: 410, loss: 0.08354638516902924
step: 420, loss: 0.024361347779631615
step: 430, loss: 0.032028742134571075
step: 440, loss: 0.007633969187736511
step: 450, loss: 0.14421965181827545
step: 460, loss: 0.03604889661073685
step: 470, loss: 0.05009549483656883
step: 480, loss: 0.10210448503494263
step: 490, loss: 0.023663638159632683
step: 500, loss: 0.16489967703819275
step: 510, loss: 0.03672510012984276
step: 520, loss: 0.06913576275110245
step: 530, loss: 0.00015532334509771317
step: 540, loss: 0.02283312939107418
step: 550, loss: 0.0875239223241806
step: 560, loss: 0.04547668620944023
step: 570, loss: 0.05459124222397804
step: 580, loss: 0.07262004166841507
step: 590, loss: 0.09164773672819138
step: 600, loss: 0.079100601375103
step: 610, loss: 0.11587892472743988
step: 620, loss: 0.001910092425532639
step: 630, loss: 0.09857974201440811
step: 640, loss: 0.0635913535952568
step: 650, loss: 0.0669880211353302
step: 660, loss: 0.03713343292474747
step: 670, loss: 0.10001827031373978
step: 680, loss: 0.048038214445114136
step: 690, loss: 0.16571463644504547
step: 700, loss: 0.00601165508851409
step: 710, loss: 0.05350453779101372
step: 720, loss: 0.08260281383991241
step: 730, loss: 0.022293975576758385
step: 740, loss: 0.034259356558322906
step: 750, loss: 0.03661685064435005
step: 760, loss: 0.014147092588245869
step: 770, loss: 0.031270090490579605
step: 780, loss: 0.05333082377910614
step: 790, loss: 0.03899532929062843
step: 800, loss: 0.07536059617996216
step: 810, loss: 0.1034904271364212
step: 820, loss: 0.01817871816456318
step: 830, loss: 0.019239187240600586
step: 840, loss: 0.03288592770695686
step: 850, loss: 0.05544210225343704
step: 860, loss: 0.05456098914146423
step: 870, loss: 0.0012162298662588
step: 880, loss: 0.036066435277462006
step: 890, loss: 0.0413835272192955
step: 900, loss: 0.08378692716360092
step: 910, loss: 0.033433277159929276
step: 920, loss: 0.1288994550704956
step: 930, loss: 0.021597161889076233
step: 940, loss: 0.06729412078857422
step: 950, loss: 0.08402550965547562
step: 960, loss: 0.02305009216070175
step: 970, loss: 0.03796103969216347
epoch 15: dev_f1=0.9319664492078286, f1=0.9289012003693443, best_f1=0.9310504396112911
step: 0, loss: 0.015061662532389164
step: 10, loss: 0.09695702791213989
step: 20, loss: 0.019268780946731567
step: 30, loss: 0.05398648977279663
step: 40, loss: 0.0860794335603714
step: 50, loss: 0.04997195303440094
step: 60, loss: 0.04799816012382507
step: 70, loss: 0.08761542290449142
step: 80, loss: 4.353606345830485e-05
step: 90, loss: 0.03716243430972099
step: 100, loss: 0.07266490906476974
step: 110, loss: 0.007596628740429878
step: 120, loss: 0.0718069076538086
step: 130, loss: 0.016774030402302742
step: 140, loss: 0.024555955082178116
step: 150, loss: 0.047273337841033936
step: 160, loss: 0.08903637528419495
step: 170, loss: 0.10056047141551971
step: 180, loss: 0.10048343241214752
step: 190, loss: 0.031856659799814224
step: 200, loss: 0.017472123727202415
step: 210, loss: 0.058801162987947464
step: 220, loss: 0.03207109123468399
step: 230, loss: 0.10457801073789597
step: 240, loss: 0.04122612252831459
step: 250, loss: 0.06716137379407883
step: 260, loss: 0.060241397470235825
step: 270, loss: 0.061398137360811234
step: 280, loss: 0.03792828693985939
step: 290, loss: 0.0414697602391243
step: 300, loss: 0.02739882469177246
step: 310, loss: 0.10750395059585571
step: 320, loss: 0.012415614910423756
step: 330, loss: 0.0698896124958992
step: 340, loss: 0.0006673174793832004
step: 350, loss: 0.0020295334979891777
step: 360, loss: 0.030457455664873123
step: 370, loss: 0.02540222927927971
step: 380, loss: 0.042671624571084976
step: 390, loss: 0.13362324237823486
step: 400, loss: 0.10505083203315735
step: 410, loss: 0.017819728702306747
step: 420, loss: 0.031075987964868546
step: 430, loss: 0.03832075372338295
step: 440, loss: 0.03295481577515602
step: 450, loss: 0.11556662619113922
step: 460, loss: 0.028566719964146614
step: 470, loss: 0.14285783469676971
step: 480, loss: 0.11766377091407776
step: 490, loss: 0.04346279427409172
step: 500, loss: 0.05294881761074066
step: 510, loss: 0.017068851739168167
step: 520, loss: 0.11637546122074127
step: 530, loss: 0.014415137469768524
step: 540, loss: 0.04992818459868431
step: 550, loss: 0.05969705060124397
step: 560, loss: 0.10366974025964737
step: 570, loss: 0.09747948497533798
step: 580, loss: 0.06329195946455002
step: 590, loss: 0.03088962845504284
step: 600, loss: 0.04529586061835289
step: 610, loss: 0.05534598231315613
step: 620, loss: 0.05321425199508667
step: 630, loss: 0.04742719978094101
step: 640, loss: 0.06463383138179779
step: 650, loss: 0.15027113258838654
step: 660, loss: 0.08952011913061142
step: 670, loss: 0.0011691635008901358
step: 680, loss: 0.08941837400197983
step: 690, loss: 0.07480308413505554
step: 700, loss: 0.010209592059254646
step: 710, loss: 0.05906552076339722
step: 720, loss: 0.03638063743710518
step: 730, loss: 0.0017774569569155574
step: 740, loss: 0.03621244430541992
step: 750, loss: 0.06443092972040176
step: 760, loss: 0.04530442878603935
step: 770, loss: 0.017625855281949043
step: 780, loss: 0.02202668972313404
step: 790, loss: 0.000505955598782748
step: 800, loss: 0.0777631476521492
step: 810, loss: 0.00014483215636573732
step: 820, loss: 0.03030448965728283
step: 830, loss: 0.08950549364089966
step: 840, loss: 0.19246232509613037
step: 850, loss: 0.019575858488678932
step: 860, loss: 0.12901891767978668
step: 870, loss: 0.01902123913168907
step: 880, loss: 0.04150373488664627
step: 890, loss: 0.010144311934709549
step: 900, loss: 0.012246411293745041
step: 910, loss: 0.0721488893032074
step: 920, loss: 0.11914510279893875
step: 930, loss: 0.09639490395784378
step: 940, loss: 0.07159905135631561
step: 950, loss: 0.055276960134506226
step: 960, loss: 0.018353598192334175
step: 970, loss: 0.0031623588874936104
epoch 16: dev_f1=0.930276087973795, f1=0.9253592953175707, best_f1=0.9310504396112911
step: 0, loss: 0.05760633945465088
step: 10, loss: 0.03874145820736885
step: 20, loss: 0.1505601555109024
step: 30, loss: 0.03633323684334755
step: 40, loss: 0.05476170405745506
step: 50, loss: 0.014243662357330322
step: 60, loss: 0.03923755884170532
step: 70, loss: 0.03529057279229164
step: 80, loss: 0.021776961162686348
step: 90, loss: 0.1095382496714592
step: 100, loss: 0.02185538411140442
step: 110, loss: 0.007932020351290703
step: 120, loss: 0.10544238239526749
step: 130, loss: 0.07360954582691193
step: 140, loss: 0.045431893318891525
step: 150, loss: 0.08859158307313919
step: 160, loss: 0.044498592615127563
step: 170, loss: 0.042913928627967834
step: 180, loss: 0.012752546928822994
step: 190, loss: 5.99533123022411e-05
step: 200, loss: 0.07219933718442917
step: 210, loss: 0.0282224602997303
step: 220, loss: 0.049252212047576904
step: 230, loss: 0.043536264449357986
step: 240, loss: 0.0001908430567709729
step: 250, loss: 0.03878111019730568
step: 260, loss: 0.042907968163490295
step: 270, loss: 0.11857075989246368
step: 280, loss: 0.01892435923218727
step: 290, loss: 0.06217590719461441
step: 300, loss: 0.04187294468283653
step: 310, loss: 0.05758295953273773
step: 320, loss: 0.08004756271839142
step: 330, loss: 0.1415841430425644
step: 340, loss: 0.07239460200071335
step: 350, loss: 0.030648188665509224
step: 360, loss: 0.03474753722548485
step: 370, loss: 0.09435438364744186
step: 380, loss: 0.08263378590345383
step: 390, loss: 0.128597691655159
step: 400, loss: 0.0854177176952362
step: 410, loss: 0.017692934721708298
step: 420, loss: 0.03517290949821472
step: 430, loss: 0.03168775141239166
step: 440, loss: 0.005526343826204538
step: 450, loss: 0.017765037715435028
step: 460, loss: 0.019551903009414673
step: 470, loss: 0.07380499690771103
step: 480, loss: 0.0698835477232933
step: 490, loss: 0.07172571122646332
step: 500, loss: 0.16235345602035522
step: 510, loss: 0.043074727058410645
step: 520, loss: 0.0714605376124382
step: 530, loss: 0.018885508179664612
step: 540, loss: 0.08295603096485138
step: 550, loss: 0.00869891420006752
step: 560, loss: 0.0036690637934952974
step: 570, loss: 0.1136871874332428
step: 580, loss: 0.04863809049129486
step: 590, loss: 0.03690260276198387
step: 600, loss: 0.0045288074761629105
step: 610, loss: 0.09948183596134186
step: 620, loss: 4.918047852697782e-05
step: 630, loss: 0.01044665277004242
step: 640, loss: 0.006003499962389469
step: 650, loss: 0.00023848831187933683
step: 660, loss: 0.01414018776267767
step: 670, loss: 0.06890150159597397
step: 680, loss: 0.0010352052049711347
step: 690, loss: 0.03518734127283096
step: 700, loss: 0.04211811721324921
step: 710, loss: 0.03234752640128136
step: 720, loss: 0.017379986122250557
step: 730, loss: 0.05160687118768692
step: 740, loss: 0.03816084936261177
step: 750, loss: 0.07626420259475708
step: 760, loss: 0.03121820092201233
step: 770, loss: 0.012787244282662868
step: 780, loss: 0.09559990465641022
step: 790, loss: 0.007792219985276461
step: 800, loss: 0.1021152138710022
step: 810, loss: 0.07467827200889587
step: 820, loss: 0.0642605721950531
step: 830, loss: 0.04062963277101517
step: 840, loss: 0.02879457175731659
step: 850, loss: 0.012834708206355572
step: 860, loss: 0.0034078180324286222
step: 870, loss: 0.047259408980607986
step: 880, loss: 0.021741997450590134
step: 890, loss: 0.037478379905223846
step: 900, loss: 0.03955978900194168
step: 910, loss: 0.023309845477342606
step: 920, loss: 0.043999720364809036
step: 930, loss: 0.04309873655438423
step: 940, loss: 0.060188960283994675
step: 950, loss: 0.020046686753630638
step: 960, loss: 0.031295474618673325
step: 970, loss: 0.050676051527261734
epoch 17: dev_f1=0.9285714285714286, f1=0.9266012155212716, best_f1=0.9310504396112911
step: 0, loss: 0.0008152564405463636
step: 10, loss: 0.03446970134973526
step: 20, loss: 0.000142769975354895
step: 30, loss: 0.09510544687509537
step: 40, loss: 0.04020505025982857
step: 50, loss: 0.04923932999372482
step: 60, loss: 0.09090234339237213
step: 70, loss: 0.07586460560560226
step: 80, loss: 0.012853678315877914
step: 90, loss: 0.03640668839216232
step: 100, loss: 0.029420074075460434
step: 110, loss: 0.07561728358268738
step: 120, loss: 0.11186447739601135
step: 130, loss: 0.07535125315189362
step: 140, loss: 0.0019294056110084057
step: 150, loss: 0.0757179856300354
step: 160, loss: 0.09408343583345413
step: 170, loss: 0.03796250745654106
step: 180, loss: 0.0638100728392601
step: 190, loss: 0.04305734485387802
step: 200, loss: 0.053525686264038086
step: 210, loss: 0.15061526000499725
step: 220, loss: 3.3138298022095114e-05
step: 230, loss: 0.12555494904518127
step: 240, loss: 0.005905230529606342
step: 250, loss: 0.021141737699508667
step: 260, loss: 5.513041833182797e-05
step: 270, loss: 0.04042469710111618
step: 280, loss: 0.0383012630045414
step: 290, loss: 0.10636436194181442
step: 300, loss: 0.02827233448624611
step: 310, loss: 0.04544810950756073
step: 320, loss: 0.04939774423837662
step: 330, loss: 0.022809907793998718
step: 340, loss: 0.0212717168033123
step: 350, loss: 0.036434534937143326
step: 360, loss: 0.013176931999623775
step: 370, loss: 0.028563134372234344
step: 380, loss: 0.033725712448358536
step: 390, loss: 0.04008523002266884
step: 400, loss: 0.06315947324037552
step: 410, loss: 0.04659980908036232
step: 420, loss: 0.06247790902853012
step: 430, loss: 0.038280025124549866
step: 440, loss: 0.04390856251120567
step: 450, loss: 0.029292110353708267
step: 460, loss: 0.05767883360385895
step: 470, loss: 0.028404004871845245
step: 480, loss: 0.056558817625045776
step: 490, loss: 0.0790800079703331
step: 500, loss: 0.03043052740395069
step: 510, loss: 0.1768288016319275
step: 520, loss: 0.007594054099172354
step: 530, loss: 0.07792053371667862
step: 540, loss: 0.05628647655248642
step: 550, loss: 0.0684935450553894
step: 560, loss: 0.02518046461045742
step: 570, loss: 0.06585566699504852
step: 580, loss: 0.021337440237402916
step: 590, loss: 0.03313451260328293
step: 600, loss: 0.06610202044248581
step: 610, loss: 0.02492886409163475
step: 620, loss: 0.030132083222270012
step: 630, loss: 0.0441436693072319
step: 640, loss: 0.016739780083298683
step: 650, loss: 0.03438267111778259
step: 660, loss: 0.07252177596092224
step: 670, loss: 0.027682747691869736
step: 680, loss: 0.04152731969952583
step: 690, loss: 0.04322179779410362
step: 700, loss: 0.02218462899327278
step: 710, loss: 0.026113180443644524
step: 720, loss: 0.02973543293774128
step: 730, loss: 0.06184498593211174
step: 740, loss: 0.06052333489060402
step: 750, loss: 0.05218230187892914
step: 760, loss: 0.05701661482453346
step: 770, loss: 0.07487465441226959
step: 780, loss: 0.020937537774443626
step: 790, loss: 0.06490961462259293
step: 800, loss: 0.020965153351426125
step: 810, loss: 0.03719276189804077
step: 820, loss: 0.06198255717754364
step: 830, loss: 0.00986871961504221
step: 840, loss: 0.023222705349326134
step: 850, loss: 0.007711227051913738
step: 860, loss: 8.724575309315696e-06
step: 870, loss: 0.000655167328659445
step: 880, loss: 0.024438252672553062
step: 890, loss: 3.117942105745897e-05
step: 900, loss: 0.05553751438856125
step: 910, loss: 0.04210398346185684
step: 920, loss: 0.06929247081279755
step: 930, loss: 0.06989043951034546
step: 940, loss: 0.06823314726352692
step: 950, loss: 0.04169735684990883
step: 960, loss: 0.0006595953018404543
step: 970, loss: 0.15290546417236328
epoch 18: dev_f1=0.9279026217228464, f1=0.9239384041063929, best_f1=0.9310504396112911
step: 0, loss: 9.88542742561549e-05
step: 10, loss: 0.04753155633807182
step: 20, loss: 0.03699488565325737
step: 30, loss: 7.141321111703292e-05
step: 40, loss: 0.0008556811371818185
step: 50, loss: 0.09806516021490097
step: 60, loss: 0.05261668935418129
step: 70, loss: 0.024296995252370834
step: 80, loss: 0.05000641196966171
step: 90, loss: 0.032559722661972046
step: 100, loss: 0.062209565192461014
step: 110, loss: 0.06331749260425568
step: 120, loss: 2.7706493710866198e-05
step: 130, loss: 0.04595213383436203
step: 140, loss: 0.05522816255688667
step: 150, loss: 0.05866043269634247
step: 160, loss: 0.10848113894462585
step: 170, loss: 0.04912600666284561
step: 180, loss: 0.01682138815522194
step: 190, loss: 0.032233934849500656
step: 200, loss: 0.05320337042212486
step: 210, loss: 0.018795104697346687
step: 220, loss: 0.06398581713438034
step: 230, loss: 0.059625159949064255
step: 240, loss: 0.019579868763685226
step: 250, loss: 0.011416401714086533
step: 260, loss: 0.08538215607404709
step: 270, loss: 0.014354878105223179
step: 280, loss: 0.01240275613963604
step: 290, loss: 0.09511207044124603
step: 300, loss: 0.026571040973067284
step: 310, loss: 0.058121003210544586
step: 320, loss: 0.06096678972244263
step: 330, loss: 0.03935723006725311
step: 340, loss: 0.02636549435555935
step: 350, loss: 0.01958109624683857
step: 360, loss: 0.004795534536242485
step: 370, loss: 0.013346144929528236
step: 380, loss: 0.026967227458953857
step: 390, loss: 0.04105883091688156
step: 400, loss: 0.07459662854671478
step: 410, loss: 0.022157015278935432
step: 420, loss: 0.03572141379117966
step: 430, loss: 0.07995389401912689
step: 440, loss: 0.05592300742864609
step: 450, loss: 0.05419839918613434
step: 460, loss: 0.005220855586230755
step: 470, loss: 0.08365394920110703
step: 480, loss: 0.02108316496014595
step: 490, loss: 0.05154354125261307
step: 500, loss: 0.06341425329446793
step: 510, loss: 0.004149203188717365
step: 520, loss: 0.0387965627014637
step: 530, loss: 0.03276209905743599
step: 540, loss: 0.029550204053521156
step: 550, loss: 0.10480938851833344
step: 560, loss: 0.005372469779103994
step: 570, loss: 0.04268629476428032
step: 580, loss: 0.014433808624744415
step: 590, loss: 0.031956616789102554
step: 600, loss: 0.043993812054395676
step: 610, loss: 0.03594432771205902
step: 620, loss: 0.010499176569283009
step: 630, loss: 0.040129438042640686
step: 640, loss: 0.023992162197828293
step: 650, loss: 0.053692057728767395
step: 660, loss: 0.033836860209703445
step: 670, loss: 0.06209349259734154
step: 680, loss: 0.12780256569385529
step: 690, loss: 0.06081599369645119
step: 700, loss: 0.07527261227369308
step: 710, loss: 0.0005875840433873236
step: 720, loss: 0.02630162239074707
step: 730, loss: 0.07551902532577515
step: 740, loss: 0.03868968039751053
step: 750, loss: 0.023479245603084564
step: 760, loss: 0.038627494126558304
step: 770, loss: 0.00653561158105731
step: 780, loss: 0.06659294664859772
step: 790, loss: 0.0874851644039154
step: 800, loss: 0.1062108650803566
step: 810, loss: 0.10398567467927933
step: 820, loss: 0.04138202220201492
step: 830, loss: 0.03441106528043747
step: 840, loss: 0.010212241671979427
step: 850, loss: 0.04858512803912163
step: 860, loss: 0.06396827101707458
step: 870, loss: 0.05843561515212059
step: 880, loss: 0.01709868013858795
step: 890, loss: 0.0733976662158966
step: 900, loss: 0.040668562054634094
step: 910, loss: 0.00018668590928427875
step: 920, loss: 0.06538049876689911
step: 930, loss: 0.049937088042497635
step: 940, loss: 0.07794281095266342
step: 950, loss: 0.04469263553619385
step: 960, loss: 0.04096970334649086
step: 970, loss: 0.027242517098784447
epoch 19: dev_f1=0.9292076887013595, f1=0.9265116279069768, best_f1=0.9310504396112911
step: 0, loss: 0.13496312499046326
step: 10, loss: 0.01924389787018299
step: 20, loss: 0.067117840051651
step: 30, loss: 0.03363616764545441
step: 40, loss: 0.02826053462922573
step: 50, loss: 0.04101865738630295
step: 60, loss: 0.043191906064748764
step: 70, loss: 0.022578010335564613
step: 80, loss: 0.015712877735495567
step: 90, loss: 0.01192278042435646
step: 100, loss: 0.00033645046642050147
step: 110, loss: 0.011609268374741077
step: 120, loss: 0.018384966999292374
step: 130, loss: 0.11416757106781006
step: 140, loss: 0.04188775271177292
step: 150, loss: 0.045244090259075165
step: 160, loss: 0.05635639652609825
step: 170, loss: 0.0592176578938961
step: 180, loss: 0.06490182876586914
step: 190, loss: 0.017108704894781113
step: 200, loss: 0.036390893161296844
step: 210, loss: 0.025785531848669052
step: 220, loss: 0.020920684561133385
step: 230, loss: 0.06524881720542908
step: 240, loss: 0.054453663527965546
step: 250, loss: 0.05147849768400192
step: 260, loss: 0.03430553153157234
step: 270, loss: 0.033798206597566605
step: 280, loss: 0.01951136440038681
step: 290, loss: 0.07396037131547928
step: 300, loss: 0.02879004180431366
step: 310, loss: 0.10451046377420425
step: 320, loss: 0.03846690058708191
step: 330, loss: 0.04763202741742134
step: 340, loss: 0.024799158796668053
step: 350, loss: 0.07709203660488129
step: 360, loss: 0.06707251071929932
step: 370, loss: 0.06646361202001572
step: 380, loss: 2.503874566173181e-05
step: 390, loss: 0.03785768151283264
step: 400, loss: 0.09930803626775742
step: 410, loss: 0.01865624450147152
step: 420, loss: 0.027823809534311295
step: 430, loss: 0.08982504904270172
step: 440, loss: 0.0715271383523941
step: 450, loss: 0.05726180598139763
step: 460, loss: 0.05731682851910591
step: 470, loss: 0.04089486971497536
step: 480, loss: 0.08359553664922714
step: 490, loss: 0.028517084196209908
step: 500, loss: 0.04178288206458092
step: 510, loss: 0.09460307657718658
step: 520, loss: 3.0760820663999766e-05
step: 530, loss: 0.03678453341126442
step: 540, loss: 0.12784989178180695
step: 550, loss: 0.003294628346338868
step: 560, loss: 0.06123703718185425
step: 570, loss: 0.0019375707488507032
step: 580, loss: 0.018718702718615532
step: 590, loss: 0.03081505186855793
step: 600, loss: 0.027447015047073364
step: 610, loss: 0.03877025470137596
step: 620, loss: 0.03755001351237297
step: 630, loss: 0.0827987864613533
step: 640, loss: 0.01135244406759739
step: 650, loss: 0.027487093582749367
step: 660, loss: 0.1253829300403595
step: 670, loss: 0.05546170100569725
step: 680, loss: 0.0819287821650505
step: 690, loss: 0.06868050992488861
step: 700, loss: 0.07990362495183945
step: 710, loss: 0.09848347306251526
step: 720, loss: 0.11355257034301758
step: 730, loss: 0.055634718388319016
step: 740, loss: 0.03308883681893349
step: 750, loss: 0.03685068339109421
step: 760, loss: 0.0386199951171875
step: 770, loss: 0.06103933975100517
step: 780, loss: 0.07736986875534058
step: 790, loss: 0.022266680374741554
step: 800, loss: 0.12883563339710236
step: 810, loss: 0.00013824687630403787
step: 820, loss: 0.03192605823278427
step: 830, loss: 0.04508403688669205
step: 840, loss: 0.02107088640332222
step: 850, loss: 0.04027915745973587
step: 860, loss: 0.017019012942910194
step: 870, loss: 0.010716858319938183
step: 880, loss: 0.09607551991939545
step: 890, loss: 0.005261430516839027
step: 900, loss: 0.044038258492946625
step: 910, loss: 0.02387111820280552
step: 920, loss: 0.05459332838654518
step: 930, loss: 0.032831739634275436
step: 940, loss: 0.04712057486176491
step: 950, loss: 0.021155642345547676
step: 960, loss: 0.03910624980926514
step: 970, loss: 0.10465270280838013
epoch 20: dev_f1=0.9263657957244655, f1=0.922425952045134, best_f1=0.9310504396112911
