cuda
Device: cuda
step: 0, loss: 0.6422543525695801
step: 10, loss: 0.30928725004196167
step: 20, loss: 0.4227861166000366
step: 30, loss: 0.27458322048187256
step: 40, loss: 0.37798088788986206
step: 50, loss: 0.16236479580402374
step: 60, loss: 0.26120996475219727
step: 70, loss: 0.19195283949375153
step: 80, loss: 0.46245303750038147
step: 90, loss: 0.16107439994812012
step: 100, loss: 0.30345404148101807
step: 110, loss: 0.2984621524810791
step: 120, loss: 0.2004183679819107
step: 130, loss: 0.06820771098136902
step: 140, loss: 0.2358904480934143
step: 150, loss: 0.15807001292705536
step: 160, loss: 0.21486692130565643
step: 170, loss: 0.0930982381105423
step: 180, loss: 0.052760932594537735
step: 190, loss: 0.18962042033672333
step: 200, loss: 0.18142257630825043
step: 210, loss: 0.08859045058488846
step: 220, loss: 0.0991455540060997
step: 230, loss: 0.10635973513126373
step: 240, loss: 0.06719572842121124
step: 250, loss: 0.17339196801185608
step: 260, loss: 0.1307237446308136
step: 270, loss: 0.21932771801948547
step: 280, loss: 0.07826657593250275
step: 290, loss: 0.17646442353725433
step: 300, loss: 0.28166210651397705
step: 310, loss: 0.30735212564468384
step: 320, loss: 0.0610765740275383
step: 330, loss: 0.17744484543800354
step: 340, loss: 0.24596402049064636
step: 350, loss: 0.05177154019474983
step: 360, loss: 0.15170416235923767
step: 370, loss: 0.10029636323451996
step: 380, loss: 0.18556132912635803
step: 390, loss: 0.17560826241970062
step: 400, loss: 0.047492437064647675
step: 410, loss: 0.08867565542459488
step: 420, loss: 0.31621506810188293
step: 430, loss: 0.2148570418357849
step: 440, loss: 0.10803645104169846
step: 450, loss: 0.1541719138622284
step: 460, loss: 0.09702391177415848
step: 470, loss: 0.159354105591774
step: 480, loss: 0.26184675097465515
step: 490, loss: 0.19841618835926056
step: 500, loss: 0.12177326530218124
step: 510, loss: 0.07628536224365234
step: 520, loss: 0.0884695053100586
step: 530, loss: 0.27300506830215454
step: 540, loss: 0.04094694182276726
step: 550, loss: 0.0842846930027008
step: 560, loss: 0.14394116401672363
step: 570, loss: 0.2835041284561157
step: 580, loss: 0.20821398496627808
step: 590, loss: 0.1300881803035736
step: 600, loss: 0.10587729513645172
step: 610, loss: 0.1280207484960556
step: 620, loss: 0.22319366037845612
step: 630, loss: 0.12020264565944672
step: 640, loss: 0.14421695470809937
step: 650, loss: 0.1462402194738388
step: 660, loss: 0.05479682236909866
step: 670, loss: 0.20139974355697632
step: 680, loss: 0.17923590540885925
step: 690, loss: 0.14838331937789917
step: 700, loss: 0.12998037040233612
step: 710, loss: 0.18065495789051056
step: 720, loss: 0.07978472858667374
step: 730, loss: 0.1290605068206787
step: 740, loss: 0.09770824015140533
step: 750, loss: 0.11496545374393463
step: 760, loss: 0.04564967006444931
step: 770, loss: 0.08701633661985397
step: 780, loss: 0.20230746269226074
step: 790, loss: 0.16584302484989166
step: 800, loss: 0.2504502236843109
step: 810, loss: 0.24580973386764526
step: 820, loss: 0.16566821932792664
step: 830, loss: 0.15655767917633057
step: 840, loss: 0.1652573198080063
step: 850, loss: 0.19941456615924835
step: 860, loss: 0.15756092965602875
step: 870, loss: 0.1036980152130127
step: 880, loss: 0.14822719991207123
step: 890, loss: 0.16362236440181732
step: 900, loss: 0.08323140442371368
step: 910, loss: 0.08218047022819519
step: 920, loss: 0.07188546657562256
step: 930, loss: 0.21910037100315094
step: 940, loss: 0.2507917881011963
step: 950, loss: 0.12251961976289749
step: 960, loss: 0.16200308501720428
step: 970, loss: 0.11845479160547256
epoch 1: dev_f1=0.9123734037868779, f1=0.9110819097678493, best_f1=0.9110819097678493
step: 0, loss: 0.1188538670539856
step: 10, loss: 0.09107226878404617
step: 20, loss: 0.16942310333251953
step: 30, loss: 0.11491110175848007
step: 40, loss: 0.1736760437488556
step: 50, loss: 0.07628129422664642
step: 60, loss: 0.0594680979847908
step: 70, loss: 0.11602258682250977
step: 80, loss: 0.07836559414863586
step: 90, loss: 0.11929145455360413
step: 100, loss: 0.06257051229476929
step: 110, loss: 0.17281381785869598
step: 120, loss: 0.05746876448392868
step: 130, loss: 0.08865461498498917
step: 140, loss: 0.13095615804195404
step: 150, loss: 0.1503155529499054
step: 160, loss: 0.12126900255680084
step: 170, loss: 0.08037446439266205
step: 180, loss: 0.18918731808662415
step: 190, loss: 0.2719806134700775
step: 200, loss: 0.20608851313591003
step: 210, loss: 0.13103418052196503
step: 220, loss: 0.15117426216602325
step: 230, loss: 0.13090083003044128
step: 240, loss: 0.1606462597846985
step: 250, loss: 0.14454783499240875
step: 260, loss: 0.0904880240559578
step: 270, loss: 0.045910488814115524
step: 280, loss: 0.18755584955215454
step: 290, loss: 0.1576090008020401
step: 300, loss: 0.17757295072078705
step: 310, loss: 0.12235184013843536
step: 320, loss: 0.2617756426334381
step: 330, loss: 0.10409602522850037
step: 340, loss: 0.03135945647954941
step: 350, loss: 0.15990103781223297
step: 360, loss: 0.14690957963466644
step: 370, loss: 0.17224407196044922
step: 380, loss: 0.1258610039949417
step: 390, loss: 0.15943951904773712
step: 400, loss: 0.17736130952835083
step: 410, loss: 0.12723027169704437
step: 420, loss: 0.1936953365802765
step: 430, loss: 0.1044863611459732
step: 440, loss: 0.15083767473697662
step: 450, loss: 0.08827941119670868
step: 460, loss: 0.24294695258140564
step: 470, loss: 0.18881545960903168
step: 480, loss: 0.12068922072649002
step: 490, loss: 0.14503946900367737
step: 500, loss: 0.09227966517210007
step: 510, loss: 0.07281959801912308
step: 520, loss: 0.1762101650238037
step: 530, loss: 0.0795154869556427
step: 540, loss: 0.28949400782585144
step: 550, loss: 0.1122346818447113
step: 560, loss: 0.06294570118188858
step: 570, loss: 0.12683473527431488
step: 580, loss: 0.05552247539162636
step: 590, loss: 0.24426484107971191
step: 600, loss: 0.17829905450344086
step: 610, loss: 0.2062138020992279
step: 620, loss: 0.11308907717466354
step: 630, loss: 0.16970698535442352
step: 640, loss: 0.158080592751503
step: 650, loss: 0.1457054764032364
step: 660, loss: 0.08105309307575226
step: 670, loss: 0.13402849435806274
step: 680, loss: 0.1259405016899109
step: 690, loss: 0.08345922082662582
step: 700, loss: 0.0453956238925457
step: 710, loss: 0.10187874734401703
step: 720, loss: 0.0892225056886673
step: 730, loss: 0.2296682447195053
step: 740, loss: 0.08208931237459183
step: 750, loss: 0.10748858749866486
step: 760, loss: 0.13678456842899323
step: 770, loss: 0.40861934423446655
step: 780, loss: 0.143656924366951
step: 790, loss: 0.14254561066627502
step: 800, loss: 0.15690836310386658
step: 810, loss: 0.14877545833587646
step: 820, loss: 0.13559895753860474
step: 830, loss: 0.15991348028182983
step: 840, loss: 0.12155536562204361
step: 850, loss: 0.14073508977890015
step: 860, loss: 0.0766158178448677
step: 870, loss: 0.09504026174545288
step: 880, loss: 0.18471045792102814
step: 890, loss: 0.13309726119041443
step: 900, loss: 0.08055407553911209
step: 910, loss: 0.49106359481811523
step: 920, loss: 0.07976612448692322
step: 930, loss: 0.15859834849834442
step: 940, loss: 0.027816738933324814
step: 950, loss: 0.19566699862480164
step: 960, loss: 0.057983994483947754
step: 970, loss: 0.06506585329771042
epoch 2: dev_f1=0.9151119402985075, f1=0.9104408352668214, best_f1=0.9104408352668214
step: 0, loss: 0.07976821810007095
step: 10, loss: 0.058903735131025314
step: 20, loss: 0.09629780799150467
step: 30, loss: 0.11260443925857544
step: 40, loss: 0.14755327999591827
step: 50, loss: 0.20450061559677124
step: 60, loss: 0.09056103229522705
step: 70, loss: 0.2737172842025757
step: 80, loss: 0.11179651319980621
step: 90, loss: 0.011106394231319427
step: 100, loss: 0.20046505331993103
step: 110, loss: 0.044344015419483185
step: 120, loss: 0.17862053215503693
step: 130, loss: 0.23076482117176056
step: 140, loss: 0.07884348183870316
step: 150, loss: 0.02330648899078369
step: 160, loss: 0.20398752391338348
step: 170, loss: 0.1039784699678421
step: 180, loss: 0.04710354283452034
step: 190, loss: 0.08828515559434891
step: 200, loss: 0.09984283894300461
step: 210, loss: 0.036016952246427536
step: 220, loss: 0.08451306074857712
step: 230, loss: 0.020873045548796654
step: 240, loss: 0.08435535430908203
step: 250, loss: 0.21296916902065277
step: 260, loss: 0.07916277647018433
step: 270, loss: 0.07584492862224579
step: 280, loss: 0.11195838451385498
step: 290, loss: 0.1707509160041809
step: 300, loss: 0.17059080302715302
step: 310, loss: 0.1569812297821045
step: 320, loss: 0.1417384147644043
step: 330, loss: 0.16312025487422943
step: 340, loss: 0.1019001230597496
step: 350, loss: 0.32040494680404663
step: 360, loss: 0.15020202100276947
step: 370, loss: 0.09354870021343231
step: 380, loss: 0.023038357496261597
step: 390, loss: 0.23307998478412628
step: 400, loss: 0.1707807183265686
step: 410, loss: 0.1621706187725067
step: 420, loss: 0.09013189375400543
step: 430, loss: 0.1659936010837555
step: 440, loss: 0.12413474917411804
step: 450, loss: 0.057298265397548676
step: 460, loss: 0.1533672958612442
step: 470, loss: 0.1685732752084732
step: 480, loss: 0.40340885519981384
step: 490, loss: 0.08118298649787903
step: 500, loss: 0.06678655743598938
step: 510, loss: 0.1393570452928543
step: 520, loss: 0.0839516818523407
step: 530, loss: 0.08361726254224777
step: 540, loss: 0.12554684281349182
step: 550, loss: 0.1207151710987091
step: 560, loss: 0.21819061040878296
step: 570, loss: 0.16534161567687988
step: 580, loss: 0.22525036334991455
step: 590, loss: 0.18898354470729828
step: 600, loss: 0.13075090944766998
step: 610, loss: 0.2441265881061554
step: 620, loss: 0.14512978494167328
step: 630, loss: 0.12857523560523987
step: 640, loss: 0.1584494709968567
step: 650, loss: 0.17963485419750214
step: 660, loss: 0.08268696814775467
step: 670, loss: 0.0658988207578659
step: 680, loss: 0.10705550760030746
step: 690, loss: 0.18132205307483673
step: 700, loss: 0.10617462545633316
step: 710, loss: 0.10561420023441315
step: 720, loss: 0.2931624948978424
step: 730, loss: 0.12083860486745834
step: 740, loss: 0.0957333892583847
step: 750, loss: 0.12005557864904404
step: 760, loss: 0.10141322761774063
step: 770, loss: 0.1306258738040924
step: 780, loss: 0.18799442052841187
step: 790, loss: 0.09028664231300354
step: 800, loss: 0.07706371694803238
step: 810, loss: 0.12116699665784836
step: 820, loss: 0.2127450853586197
step: 830, loss: 0.001874046865850687
step: 840, loss: 0.02063893899321556
step: 850, loss: 0.08567995578050613
step: 860, loss: 0.11027175933122635
step: 870, loss: 0.33426690101623535
step: 880, loss: 0.10629699379205704
step: 890, loss: 0.07094891369342804
step: 900, loss: 0.19210511445999146
step: 910, loss: 0.07719772309064865
step: 920, loss: 0.07343394309282303
step: 930, loss: 0.061127424240112305
step: 940, loss: 0.054580144584178925
step: 950, loss: 0.15367580950260162
step: 960, loss: 0.20721441507339478
step: 970, loss: 0.11958993971347809
epoch 3: dev_f1=0.9206785878037598, f1=0.9223785746709033, best_f1=0.9223785746709033
step: 0, loss: 0.29298824071884155
step: 10, loss: 0.13998819887638092
step: 20, loss: 0.13524176180362701
step: 30, loss: 0.10186354070901871
step: 40, loss: 0.12488851696252823
step: 50, loss: 0.21962870657444
step: 60, loss: 0.10061489045619965
step: 70, loss: 0.16628539562225342
step: 80, loss: 0.10427020490169525
step: 90, loss: 0.05797451734542847
step: 100, loss: 0.08889357000589371
step: 110, loss: 0.14198175072669983
step: 120, loss: 0.10267425328493118
step: 130, loss: 0.08381087332963943
step: 140, loss: 0.11210550367832184
step: 150, loss: 0.11391081660985947
step: 160, loss: 0.1166628822684288
step: 170, loss: 0.15838885307312012
step: 180, loss: 0.1363639384508133
step: 190, loss: 0.1110762283205986
step: 200, loss: 0.1109381839632988
step: 210, loss: 0.04356514662504196
step: 220, loss: 0.03607417270541191
step: 230, loss: 0.15372075140476227
step: 240, loss: 0.15936025977134705
step: 250, loss: 0.23914596438407898
step: 260, loss: 0.11287984251976013
step: 270, loss: 0.09820469468832016
step: 280, loss: 0.16445575654506683
step: 290, loss: 0.1154538244009018
step: 300, loss: 0.05598510056734085
step: 310, loss: 0.049423132091760635
step: 320, loss: 0.08848831802606583
step: 330, loss: 0.09691756963729858
step: 340, loss: 0.07079000025987625
step: 350, loss: 0.07777279615402222
step: 360, loss: 0.18911880254745483
step: 370, loss: 0.13696244359016418
step: 380, loss: 0.04196540266275406
step: 390, loss: 0.08576004207134247
step: 400, loss: 0.1031305119395256
step: 410, loss: 0.0967767983675003
step: 420, loss: 0.15381450951099396
step: 430, loss: 0.15111014246940613
step: 440, loss: 0.06892931461334229
step: 450, loss: 0.11147396266460419
step: 460, loss: 0.09603511542081833
step: 470, loss: 0.17259514331817627
step: 480, loss: 0.22080360352993011
step: 490, loss: 0.06602256000041962
step: 500, loss: 0.06348785012960434
step: 510, loss: 0.12892413139343262
step: 520, loss: 0.0933280661702156
step: 530, loss: 0.15862135589122772
step: 540, loss: 0.09499166905879974
step: 550, loss: 0.11207705736160278
step: 560, loss: 0.11814703792333603
step: 570, loss: 0.15051640570163727
step: 580, loss: 0.09684212505817413
step: 590, loss: 0.10511071979999542
step: 600, loss: 0.11010539531707764
step: 610, loss: 0.10132845491170883
step: 620, loss: 0.18958573043346405
step: 630, loss: 0.13765889406204224
step: 640, loss: 0.19622555375099182
step: 650, loss: 0.12504495680332184
step: 660, loss: 0.08776670694351196
step: 670, loss: 0.07504665851593018
step: 680, loss: 0.05070794001221657
step: 690, loss: 0.11672668904066086
step: 700, loss: 0.20007655024528503
step: 710, loss: 0.0900796577334404
step: 720, loss: 0.08060730993747711
step: 730, loss: 0.06697742640972137
step: 740, loss: 0.07542368024587631
step: 750, loss: 0.07572632282972336
step: 760, loss: 0.10561734437942505
step: 770, loss: 0.11854071915149689
step: 780, loss: 0.1517549753189087
step: 790, loss: 0.14654476940631866
step: 800, loss: 0.06821981817483902
step: 810, loss: 0.13410422205924988
step: 820, loss: 0.10371942073106766
step: 830, loss: 0.11578769981861115
step: 840, loss: 0.07046095281839371
step: 850, loss: 0.2170553058385849
step: 860, loss: 0.09779670089483261
step: 870, loss: 0.11616072803735733
step: 880, loss: 0.10951147973537445
step: 890, loss: 0.06309757381677628
step: 900, loss: 0.07650896161794662
step: 910, loss: 0.2274266481399536
step: 920, loss: 0.14193657040596008
step: 930, loss: 0.14013445377349854
step: 940, loss: 0.0776003748178482
step: 950, loss: 0.20859356224536896
step: 960, loss: 0.12441739439964294
step: 970, loss: 0.16541504859924316
epoch 4: dev_f1=0.910351201478743, f1=0.9170506912442397, best_f1=0.9223785746709033
step: 0, loss: 0.20301298797130585
step: 10, loss: 0.1301373839378357
step: 20, loss: 0.14622880518436432
step: 30, loss: 0.12286587059497833
step: 40, loss: 0.0767223909497261
step: 50, loss: 0.04705316573381424
step: 60, loss: 0.05947200953960419
step: 70, loss: 0.09020235389471054
step: 80, loss: 0.12243738770484924
step: 90, loss: 0.14478503167629242
step: 100, loss: 0.07328377664089203
step: 110, loss: 0.16739295423030853
step: 120, loss: 0.11843766272068024
step: 130, loss: 0.08904178440570831
step: 140, loss: 0.1641424000263214
step: 150, loss: 0.060612767934799194
step: 160, loss: 0.21840175986289978
step: 170, loss: 0.06714946031570435
step: 180, loss: 0.07759668678045273
step: 190, loss: 0.04075464978814125
step: 200, loss: 0.10001640766859055
step: 210, loss: 0.035525690764188766
step: 220, loss: 0.1881779581308365
step: 230, loss: 0.16985341906547546
step: 240, loss: 0.07271605730056763
step: 250, loss: 0.11975441128015518
step: 260, loss: 0.06954436004161835
step: 270, loss: 0.09668369591236115
step: 280, loss: 0.07608189433813095
step: 290, loss: 0.08282442390918732
step: 300, loss: 0.049137573689222336
step: 310, loss: 0.04552599415183067
step: 320, loss: 0.15246862173080444
step: 330, loss: 0.05670788884162903
step: 340, loss: 0.10592179000377655
step: 350, loss: 0.02805960923433304
step: 360, loss: 0.08147593587636948
step: 370, loss: 0.0928862914443016
step: 380, loss: 0.1005384624004364
step: 390, loss: 0.0190412737429142
step: 400, loss: 0.17205582559108734
step: 410, loss: 0.08647643029689789
step: 420, loss: 0.061699192970991135
step: 430, loss: 0.08688955008983612
step: 440, loss: 0.16251738369464874
step: 450, loss: 0.031532060354948044
step: 460, loss: 0.09279558807611465
step: 470, loss: 0.12097553163766861
step: 480, loss: 0.20246946811676025
step: 490, loss: 0.10704312473535538
step: 500, loss: 0.07003459334373474
step: 510, loss: 0.08065346628427505
step: 520, loss: 0.05698363110423088
step: 530, loss: 0.07495016604661942
step: 540, loss: 0.06270406395196915
step: 550, loss: 0.04505925253033638
step: 560, loss: 0.059413351118564606
step: 570, loss: 0.0868924930691719
step: 580, loss: 0.04556742310523987
step: 590, loss: 0.10908292233943939
step: 600, loss: 0.18225668370723724
step: 610, loss: 0.1284397691488266
step: 620, loss: 0.09869013726711273
step: 630, loss: 0.2552858293056488
step: 640, loss: 0.08675851672887802
step: 650, loss: 0.0785190686583519
step: 660, loss: 0.07925152033567429
step: 670, loss: 0.1159791573882103
step: 680, loss: 0.06961267441511154
step: 690, loss: 0.0795559361577034
step: 700, loss: 0.2698424458503723
step: 710, loss: 0.08220074325799942
step: 720, loss: 0.11347673088312149
step: 730, loss: 0.02170349657535553
step: 740, loss: 0.13768881559371948
step: 750, loss: 0.05554734915494919
step: 760, loss: 0.202289879322052
step: 770, loss: 0.1282716542482376
step: 780, loss: 0.1712885946035385
step: 790, loss: 0.23445123434066772
step: 800, loss: 0.1258424073457718
step: 810, loss: 0.141545370221138
step: 820, loss: 0.05787506699562073
step: 830, loss: 0.14556558430194855
step: 840, loss: 0.09402158111333847
step: 850, loss: 0.025696080178022385
step: 860, loss: 0.037171680480241776
step: 870, loss: 0.12099265307188034
step: 880, loss: 0.12650151550769806
step: 890, loss: 0.18254749476909637
step: 900, loss: 0.07061885297298431
step: 910, loss: 0.06624442338943481
step: 920, loss: 0.1658773273229599
step: 930, loss: 0.0912720337510109
step: 940, loss: 0.07168314605951309
step: 950, loss: 0.13171470165252686
step: 960, loss: 0.09506037831306458
step: 970, loss: 0.10640513896942139
epoch 5: dev_f1=0.9266480965645311, f1=0.9287696577243294, best_f1=0.9287696577243294
step: 0, loss: 0.1529761403799057
step: 10, loss: 0.06001380831003189
step: 20, loss: 0.035677749663591385
step: 30, loss: 0.016714580357074738
step: 40, loss: 0.16214479506015778
step: 50, loss: 0.06396902352571487
step: 60, loss: 0.16403251886367798
step: 70, loss: 0.10466166585683823
step: 80, loss: 0.11980739235877991
step: 90, loss: 0.12363310158252716
step: 100, loss: 0.11731036007404327
step: 110, loss: 0.11479593068361282
step: 120, loss: 0.16901206970214844
step: 130, loss: 0.08667860925197601
step: 140, loss: 0.13305935263633728
step: 150, loss: 0.10629047453403473
step: 160, loss: 0.10709092766046524
step: 170, loss: 0.0782303437590599
step: 180, loss: 0.028354482725262642
step: 190, loss: 0.05621528625488281
step: 200, loss: 0.12458588182926178
step: 210, loss: 0.09769977629184723
step: 220, loss: 0.011485039256513119
step: 230, loss: 0.18234363198280334
step: 240, loss: 0.046547748148441315
step: 250, loss: 0.13743875920772552
step: 260, loss: 0.19801002740859985
step: 270, loss: 0.19604861736297607
step: 280, loss: 0.09364420175552368
step: 290, loss: 0.1101926937699318
step: 300, loss: 0.09031590819358826
step: 310, loss: 0.2617896497249603
step: 320, loss: 0.08003626763820648
step: 330, loss: 0.09281875193119049
step: 340, loss: 0.20058685541152954
step: 350, loss: 0.10903297364711761
step: 360, loss: 0.14592309296131134
step: 370, loss: 0.0816095620393753
step: 380, loss: 0.11721684038639069
step: 390, loss: 0.10055381059646606
step: 400, loss: 0.06843698769807816
step: 410, loss: 0.11183846741914749
step: 420, loss: 0.08592265844345093
step: 430, loss: 0.07404176145792007
step: 440, loss: 0.027904439717531204
step: 450, loss: 0.06725050508975983
step: 460, loss: 0.13816623389720917
step: 470, loss: 0.13467882573604584
step: 480, loss: 0.10638266056776047
step: 490, loss: 0.12757645547389984
step: 500, loss: 0.11336196959018707
step: 510, loss: 0.062464237213134766
step: 520, loss: 0.09942413866519928
step: 530, loss: 0.15578052401542664
step: 540, loss: 0.13711583614349365
step: 550, loss: 0.09439057111740112
step: 560, loss: 0.1327822059392929
step: 570, loss: 0.11847939342260361
step: 580, loss: 0.16560065746307373
step: 590, loss: 0.052235569804906845
step: 600, loss: 0.04436052590608597
step: 610, loss: 0.07204639166593552
step: 620, loss: 0.11214163154363632
step: 630, loss: 0.04893952235579491
step: 640, loss: 0.10218494385480881
step: 650, loss: 0.06426884233951569
step: 660, loss: 0.05098208039999008
step: 670, loss: 0.08006765693426132
step: 680, loss: 0.039364807307720184
step: 690, loss: 0.13581368327140808
step: 700, loss: 0.08196323364973068
step: 710, loss: 0.08190842717885971
step: 720, loss: 0.09588857740163803
step: 730, loss: 0.13109473884105682
step: 740, loss: 0.08159025013446808
step: 750, loss: 0.01097036898136139
step: 760, loss: 0.06930866837501526
step: 770, loss: 0.14623905718326569
step: 780, loss: 0.15891019999980927
step: 790, loss: 0.10043323040008545
step: 800, loss: 0.06289932131767273
step: 810, loss: 0.09716183692216873
step: 820, loss: 0.08779370039701462
step: 830, loss: 0.0963008850812912
step: 840, loss: 0.1007935181260109
step: 850, loss: 0.16893456876277924
step: 860, loss: 0.20830802619457245
step: 870, loss: 0.08158266544342041
step: 880, loss: 0.07397477328777313
step: 890, loss: 0.07761366665363312
step: 900, loss: 0.06462431699037552
step: 910, loss: 0.035283174365758896
step: 920, loss: 0.05503697693347931
step: 930, loss: 0.044199395924806595
step: 940, loss: 0.18065088987350464
step: 950, loss: 0.08934120088815689
step: 960, loss: 0.0679403766989708
step: 970, loss: 0.08360261470079422
epoch 6: dev_f1=0.9263443289652057, f1=0.9301487156376748, best_f1=0.9287696577243294
step: 0, loss: 0.015786217525601387
step: 10, loss: 0.2620994746685028
step: 20, loss: 0.09207384288311005
step: 30, loss: 0.1226220428943634
step: 40, loss: 0.20856358110904694
step: 50, loss: 0.09715310484170914
step: 60, loss: 0.15448805689811707
step: 70, loss: 0.07962533831596375
step: 80, loss: 0.14117275178432465
step: 90, loss: 0.1008177176117897
step: 100, loss: 0.04633196443319321
step: 110, loss: 0.09510879218578339
step: 120, loss: 0.17144659161567688
step: 130, loss: 0.07234413176774979
step: 140, loss: 0.03743034973740578
step: 150, loss: 0.06232794001698494
step: 160, loss: 0.11083848029375076
step: 170, loss: 0.14047059416770935
step: 180, loss: 0.07557365298271179
step: 190, loss: 0.18050220608711243
step: 200, loss: 0.03673340007662773
step: 210, loss: 0.07196708023548126
step: 220, loss: 0.07004678249359131
step: 230, loss: 0.09663551300764084
step: 240, loss: 0.015143373981118202
step: 250, loss: 0.11607629060745239
step: 260, loss: 0.052570320665836334
step: 270, loss: 0.2210245579481125
step: 280, loss: 0.09335169941186905
step: 290, loss: 0.10550479590892792
step: 300, loss: 0.03184571862220764
step: 310, loss: 0.04319440573453903
step: 320, loss: 0.04535643011331558
step: 330, loss: 0.02430075779557228
step: 340, loss: 0.008545979857444763
step: 350, loss: 0.2379862517118454
step: 360, loss: 0.15180325508117676
step: 370, loss: 0.21026529371738434
step: 380, loss: 0.158970907330513
step: 390, loss: 0.07690487056970596
step: 400, loss: 0.0913592129945755
step: 410, loss: 0.2315567433834076
step: 420, loss: 0.07328680902719498
step: 430, loss: 0.1191808208823204
step: 440, loss: 0.1647135615348816
step: 450, loss: 0.07812536507844925
step: 460, loss: 0.1570468544960022
step: 470, loss: 0.17070640623569489
step: 480, loss: 0.03570494055747986
step: 490, loss: 0.044654730707407
step: 500, loss: 0.11052941530942917
step: 510, loss: 0.06768050789833069
step: 520, loss: 0.12665581703186035
step: 530, loss: 0.01322232000529766
step: 540, loss: 0.12957054376602173
step: 550, loss: 0.11511137336492538
step: 560, loss: 0.10368704795837402
step: 570, loss: 0.008487256243824959
step: 580, loss: 0.023775607347488403
step: 590, loss: 0.3051150143146515
step: 600, loss: 0.04148165509104729
step: 610, loss: 0.2634163200855255
step: 620, loss: 0.08782230317592621
step: 630, loss: 0.06490758061408997
step: 640, loss: 0.04137668013572693
step: 650, loss: 0.06773815304040909
step: 660, loss: 0.08675552159547806
step: 670, loss: 0.11611291766166687
step: 680, loss: 0.07974305748939514
step: 690, loss: 0.17959806323051453
step: 700, loss: 0.06661108881235123
step: 710, loss: 0.06555251777172089
step: 720, loss: 0.0835724025964737
step: 730, loss: 0.07054780423641205
step: 740, loss: 0.13342007994651794
step: 750, loss: 0.10959333181381226
step: 760, loss: 0.10093086212873459
step: 770, loss: 0.09617437422275543
step: 780, loss: 0.09398909658193588
step: 790, loss: 0.04338190332055092
step: 800, loss: 0.09161650389432907
step: 810, loss: 0.06652341037988663
step: 820, loss: 0.017532160505652428
step: 830, loss: 0.14552028477191925
step: 840, loss: 0.4502686560153961
step: 850, loss: 0.10542891174554825
step: 860, loss: 0.103439100086689
step: 870, loss: 0.0004965615808032453
step: 880, loss: 0.07159541547298431
step: 890, loss: 0.20555278658866882
step: 900, loss: 0.02818632312119007
step: 910, loss: 0.13056550920009613
step: 920, loss: 0.1202368512749672
step: 930, loss: 0.053935300558805466
step: 940, loss: 0.1318577229976654
step: 950, loss: 0.08230309188365936
step: 960, loss: 0.06523039191961288
step: 970, loss: 0.11363010853528976
epoch 7: dev_f1=0.9314045730284647, f1=0.9275766016713091, best_f1=0.9275766016713091
step: 0, loss: 0.05159229412674904
step: 10, loss: 0.09013678133487701
step: 20, loss: 0.0837552472949028
step: 30, loss: 0.1030246764421463
step: 40, loss: 0.09618357568979263
step: 50, loss: 0.06261634826660156
step: 60, loss: 0.1398419290781021
step: 70, loss: 0.1128135398030281
step: 80, loss: 0.12564176321029663
step: 90, loss: 0.13287395238876343
step: 100, loss: 0.051211968064308167
step: 110, loss: 0.0504436157643795
step: 120, loss: 0.040366675704717636
step: 130, loss: 0.04852669686079025
step: 140, loss: 0.15775777399539948
step: 150, loss: 0.020391659811139107
step: 160, loss: 0.06240429729223251
step: 170, loss: 0.009418339468538761
step: 180, loss: 0.1290200799703598
step: 190, loss: 0.07825519144535065
step: 200, loss: 0.04032455384731293
step: 210, loss: 0.0961470827460289
step: 220, loss: 0.020254679024219513
step: 230, loss: 0.04825172945857048
step: 240, loss: 0.02590976469218731
step: 250, loss: 0.08695224672555923
step: 260, loss: 0.06035231798887253
step: 270, loss: 0.05054602026939392
step: 280, loss: 0.0912395790219307
step: 290, loss: 0.021344056352972984
step: 300, loss: 0.016133196651935577
step: 310, loss: 0.06252653151750565
step: 320, loss: 0.09699507802724838
step: 330, loss: 0.12294856458902359
step: 340, loss: 0.04819676652550697
step: 350, loss: 0.09033280611038208
step: 360, loss: 0.05086877569556236
step: 370, loss: 0.1180942952632904
step: 380, loss: 0.07476287335157394
step: 390, loss: 0.10869305580854416
step: 400, loss: 0.08354654908180237
step: 410, loss: 0.0339377224445343
step: 420, loss: 0.11178508400917053
step: 430, loss: 0.16884221136569977
step: 440, loss: 0.07611138373613358
step: 450, loss: 0.15285779535770416
step: 460, loss: 0.07162924855947495
step: 470, loss: 0.057915039360523224
step: 480, loss: 0.08419609069824219
step: 490, loss: 0.14646312594413757
step: 500, loss: 0.08045641332864761
step: 510, loss: 0.03135951980948448
step: 520, loss: 0.15956251323223114
step: 530, loss: 0.04565943032503128
step: 540, loss: 0.08644561469554901
step: 550, loss: 0.09300755709409714
step: 560, loss: 0.16909471154212952
step: 570, loss: 0.07003763318061829
step: 580, loss: 0.08034007251262665
step: 590, loss: 0.014250204898416996
step: 600, loss: 0.08596665412187576
step: 610, loss: 0.03709325194358826
step: 620, loss: 0.15074580907821655
step: 630, loss: 0.12011177837848663
step: 640, loss: 0.17408527433872223
step: 650, loss: 0.13371238112449646
step: 660, loss: 0.11621303856372833
step: 670, loss: 0.06048811227083206
step: 680, loss: 0.11772391200065613
step: 690, loss: 0.08251872658729553
step: 700, loss: 0.011326665990054607
step: 710, loss: 0.05743113532662392
step: 720, loss: 0.12119418382644653
step: 730, loss: 0.04346685856580734
step: 740, loss: 0.12516066431999207
step: 750, loss: 0.13781049847602844
step: 760, loss: 0.28327298164367676
step: 770, loss: 0.050420064479112625
step: 780, loss: 0.024454956874251366
step: 790, loss: 0.19250144064426422
step: 800, loss: 0.10097687691450119
step: 810, loss: 0.12154301255941391
step: 820, loss: 0.17675895988941193
step: 830, loss: 0.04553702473640442
step: 840, loss: 0.04251599311828613
step: 850, loss: 0.2135055810213089
step: 860, loss: 0.03136413171887398
step: 870, loss: 0.06827837228775024
step: 880, loss: 0.14232496917247772
step: 890, loss: 0.2645096182823181
step: 900, loss: 0.1536126732826233
step: 910, loss: 0.10254737734794617
step: 920, loss: 0.008399357087910175
step: 930, loss: 0.10915853083133698
step: 940, loss: 0.20692327618598938
step: 950, loss: 0.04956047981977463
step: 960, loss: 0.09294987469911575
step: 970, loss: 0.11102338135242462
epoch 8: dev_f1=0.9343807763401109, f1=0.934752429430819, best_f1=0.934752429430819
step: 0, loss: 0.029857151210308075
step: 10, loss: 0.04057886451482773
step: 20, loss: 0.020576203241944313
step: 30, loss: 0.14258728921413422
step: 40, loss: 0.070513054728508
step: 50, loss: 0.09371434897184372
step: 60, loss: 0.0815076008439064
step: 70, loss: 0.1568470150232315
step: 80, loss: 0.11297667026519775
step: 90, loss: 0.07494623214006424
step: 100, loss: 0.0003924978955183178
step: 110, loss: 0.07370948791503906
step: 120, loss: 0.16275231540203094
step: 130, loss: 0.11464431136846542
step: 140, loss: 0.06523917615413666
step: 150, loss: 0.24370057880878448
step: 160, loss: 0.09097965061664581
step: 170, loss: 0.052907221019268036
step: 180, loss: 0.07150638103485107
step: 190, loss: 0.04907742142677307
step: 200, loss: 0.025301923975348473
step: 210, loss: 0.02986522577702999
step: 220, loss: 0.08381658047437668
step: 230, loss: 0.13952629268169403
step: 240, loss: 0.06594416499137878
step: 250, loss: 0.04145853593945503
step: 260, loss: 0.03273576870560646
step: 270, loss: 0.11136487126350403
step: 280, loss: 0.08019639551639557
step: 290, loss: 0.06005913391709328
step: 300, loss: 0.061443157494068146
step: 310, loss: 0.057759929448366165
step: 320, loss: 0.1052045226097107
step: 330, loss: 0.13558495044708252
step: 340, loss: 0.037916604429483414
step: 350, loss: 0.1828283965587616
step: 360, loss: 0.07693251967430115
step: 370, loss: 0.15068000555038452
step: 380, loss: 0.06287648528814316
step: 390, loss: 0.15009643137454987
step: 400, loss: 0.05081837996840477
step: 410, loss: 0.11334195733070374
step: 420, loss: 0.13941247761249542
step: 430, loss: 0.05990864709019661
step: 440, loss: 0.016962969675660133
step: 450, loss: 0.10045038163661957
step: 460, loss: 0.10356421768665314
step: 470, loss: 0.15183508396148682
step: 480, loss: 0.041886184364557266
step: 490, loss: 0.08984111249446869
step: 500, loss: 0.08178505301475525
step: 510, loss: 0.18599705398082733
step: 520, loss: 0.07794251292943954
step: 530, loss: 0.0318770557641983
step: 540, loss: 0.06302270293235779
step: 550, loss: 0.09636805951595306
step: 560, loss: 0.05368732288479805
step: 570, loss: 0.06968078017234802
step: 580, loss: 0.026189031079411507
step: 590, loss: 0.014487992972135544
step: 600, loss: 0.03468061611056328
step: 610, loss: 0.03292228654026985
step: 620, loss: 0.03704892471432686
step: 630, loss: 0.04529966413974762
step: 640, loss: 0.10009602457284927
step: 650, loss: 0.14679235219955444
step: 660, loss: 0.06296609342098236
step: 670, loss: 0.08417166769504547
step: 680, loss: 0.007431257050484419
step: 690, loss: 0.09175607562065125
step: 700, loss: 0.06048626825213432
step: 710, loss: 0.08622327446937561
step: 720, loss: 0.0555981881916523
step: 730, loss: 0.0749034509062767
step: 740, loss: 0.08556880801916122
step: 750, loss: 0.06872531771659851
step: 760, loss: 0.1325778216123581
step: 770, loss: 0.055527009069919586
step: 780, loss: 0.07918570190668106
step: 790, loss: 0.14590954780578613
step: 800, loss: 0.1311703771352768
step: 810, loss: 0.05090875178575516
step: 820, loss: 0.02360178343951702
step: 830, loss: 0.03790225461125374
step: 840, loss: 0.06951043754816055
step: 850, loss: 0.11894956231117249
step: 860, loss: 0.07973123341798782
step: 870, loss: 0.14446903765201569
step: 880, loss: 0.13290193676948547
step: 890, loss: 0.12139113992452621
step: 900, loss: 0.07687336951494217
step: 910, loss: 0.03555697202682495
step: 920, loss: 0.04421687498688698
step: 930, loss: 0.007355766370892525
step: 940, loss: 0.12271524965763092
step: 950, loss: 0.14927005767822266
step: 960, loss: 0.08800601214170456
step: 970, loss: 0.0835564136505127
epoch 9: dev_f1=0.928505957836847, f1=0.9333333333333333, best_f1=0.934752429430819
step: 0, loss: 0.009408337064087391
step: 10, loss: 0.1000739261507988
step: 20, loss: 0.1651468127965927
step: 30, loss: 0.12309661507606506
step: 40, loss: 0.12140792608261108
step: 50, loss: 0.1370200365781784
step: 60, loss: 0.04008908197283745
step: 70, loss: 0.07944197207689285
step: 80, loss: 0.09825115650892258
step: 90, loss: 0.03879929333925247
step: 100, loss: 0.08179875463247299
step: 110, loss: 0.07656235247850418
step: 120, loss: 0.06632699072360992
step: 130, loss: 0.0003100512840319425
step: 140, loss: 0.08401672542095184
step: 150, loss: 0.06342782825231552
step: 160, loss: 0.05313011258840561
step: 170, loss: 0.06292667239904404
step: 180, loss: 0.11959820240736008
step: 190, loss: 0.16261619329452515
step: 200, loss: 0.05097833648324013
step: 210, loss: 0.0822942703962326
step: 220, loss: 0.057115569710731506
step: 230, loss: 0.0687747374176979
step: 240, loss: 0.06272533535957336
step: 250, loss: 0.039495691657066345
step: 260, loss: 0.05073454976081848
step: 270, loss: 0.0719812661409378
step: 280, loss: 0.06492356210947037
step: 290, loss: 0.0634881854057312
step: 300, loss: 0.03847261518239975
step: 310, loss: 0.05546790733933449
step: 320, loss: 0.17233191430568695
step: 330, loss: 0.08126527070999146
step: 340, loss: 0.09425347298383713
step: 350, loss: 0.133121520280838
step: 360, loss: 0.14608751237392426
step: 370, loss: 0.04557294398546219
step: 380, loss: 0.06441148370504379
step: 390, loss: 0.06893290579319
step: 400, loss: 0.046803079545497894
step: 410, loss: 0.07640542834997177
step: 420, loss: 0.06825482845306396
step: 430, loss: 0.062396079301834106
step: 440, loss: 0.15305671095848083
step: 450, loss: 0.013643895275890827
step: 460, loss: 0.03986683860421181
step: 470, loss: 0.13191646337509155
step: 480, loss: 0.11592382937669754
step: 490, loss: 0.06652233749628067
step: 500, loss: 0.03643278405070305
step: 510, loss: 0.045060861855745316
step: 520, loss: 0.053002189844846725
step: 530, loss: 0.1355278044939041
step: 540, loss: 0.1394413411617279
step: 550, loss: 0.11174236983060837
step: 560, loss: 0.1020292341709137
step: 570, loss: 0.04314041882753372
step: 580, loss: 0.14212647080421448
step: 590, loss: 0.25425320863723755
step: 600, loss: 0.09186860173940659
step: 610, loss: 0.06956607103347778
step: 620, loss: 0.2971867322921753
step: 630, loss: 0.06891992688179016
step: 640, loss: 0.06713420897722244
step: 650, loss: 0.040914542973041534
step: 660, loss: 0.14701752364635468
step: 670, loss: 0.04442800208926201
step: 680, loss: 0.04386693611741066
step: 690, loss: 0.09120315313339233
step: 700, loss: 0.07199694216251373
step: 710, loss: 0.09152677655220032
step: 720, loss: 0.09796047955751419
step: 730, loss: 0.027228062972426414
step: 740, loss: 0.040907155722379684
step: 750, loss: 0.11601299047470093
step: 760, loss: 0.11368320137262344
step: 770, loss: 0.1356794834136963
step: 780, loss: 0.16360919177532196
step: 790, loss: 0.24030834436416626
step: 800, loss: 0.018959565088152885
step: 810, loss: 0.05687251314520836
step: 820, loss: 0.12169213593006134
step: 830, loss: 0.09626848250627518
step: 840, loss: 0.046574633568525314
step: 850, loss: 0.06556986272335052
step: 860, loss: 0.08935574442148209
step: 870, loss: 0.19038398563861847
step: 880, loss: 0.16936752200126648
step: 890, loss: 0.043708380311727524
step: 900, loss: 0.16260428726673126
step: 910, loss: 0.14403469860553741
step: 920, loss: 0.14792120456695557
step: 930, loss: 0.06744714081287384
step: 940, loss: 0.041316937655210495
step: 950, loss: 0.12573981285095215
step: 960, loss: 0.09410259127616882
step: 970, loss: 0.12814931571483612
epoch 10: dev_f1=0.9302544769085768, f1=0.9256820319849483, best_f1=0.934752429430819
step: 0, loss: 0.054491642862558365
step: 10, loss: 0.031317517161369324
step: 20, loss: 0.05715172737836838
step: 30, loss: 0.03689548745751381
step: 40, loss: 0.11350710690021515
step: 50, loss: 0.1218581274151802
step: 60, loss: 0.12684348225593567
step: 70, loss: 0.24913956224918365
step: 80, loss: 0.027451451867818832
step: 90, loss: 0.038454052060842514
step: 100, loss: 0.06769921630620956
step: 110, loss: 0.11828389018774033
step: 120, loss: 0.11329946666955948
step: 130, loss: 0.11674681305885315
step: 140, loss: 0.04418996721506119
step: 150, loss: 0.22109174728393555
step: 160, loss: 0.07013079524040222
step: 170, loss: 0.059871695935726166
step: 180, loss: 0.10130108892917633
step: 190, loss: 0.11439166963100433
step: 200, loss: 0.07807452231645584
step: 210, loss: 0.1825380027294159
step: 220, loss: 0.125497967004776
step: 230, loss: 0.09333375841379166
step: 240, loss: 0.0687517300248146
step: 250, loss: 0.09338048100471497
step: 260, loss: 0.03330991789698601
step: 270, loss: 0.047233521938323975
step: 280, loss: 0.023988697677850723
step: 290, loss: 0.06732527166604996
step: 300, loss: 0.029794398695230484
step: 310, loss: 0.10581023246049881
step: 320, loss: 0.050923895090818405
step: 330, loss: 0.011838126927614212
step: 340, loss: 0.08550965785980225
step: 350, loss: 0.030199449509382248
step: 360, loss: 0.014190563932061195
step: 370, loss: 0.13970106840133667
step: 380, loss: 0.11296175420284271
step: 390, loss: 0.04992300271987915
step: 400, loss: 0.15986156463623047
step: 410, loss: 0.07978486269712448
step: 420, loss: 0.13249802589416504
step: 430, loss: 0.08601450175046921
step: 440, loss: 0.03336687013506889
step: 450, loss: 0.00725365849211812
step: 460, loss: 0.09913502633571625
step: 470, loss: 0.1286848485469818
step: 480, loss: 0.10361992567777634
step: 490, loss: 0.02512168511748314
step: 500, loss: 0.03039199858903885
step: 510, loss: 0.037681419402360916
step: 520, loss: 0.03426320105791092
step: 530, loss: 0.10708282142877579
step: 540, loss: 0.04436691105365753
step: 550, loss: 0.11911141127347946
step: 560, loss: 0.13170486688613892
step: 570, loss: 0.13026688992977142
step: 580, loss: 0.014097349718213081
step: 590, loss: 0.06526125222444534
step: 600, loss: 0.10097595304250717
step: 610, loss: 0.15165922045707703
step: 620, loss: 0.25967293977737427
step: 630, loss: 0.13434331119060516
step: 640, loss: 0.03356766700744629
step: 650, loss: 0.026692816987633705
step: 660, loss: 0.1493757963180542
step: 670, loss: 0.0408029705286026
step: 680, loss: 0.16964469850063324
step: 690, loss: 0.016971878707408905
step: 700, loss: 0.03790204972028732
step: 710, loss: 0.08166083693504333
step: 720, loss: 0.012725397944450378
step: 730, loss: 0.059991173446178436
step: 740, loss: 0.04037752002477646
step: 750, loss: 0.07994772493839264
step: 760, loss: 0.09719984978437424
step: 770, loss: 0.1047123596072197
step: 780, loss: 0.2300470471382141
step: 790, loss: 0.12090778350830078
step: 800, loss: 0.18309827148914337
step: 810, loss: 0.0403328537940979
step: 820, loss: 0.22682896256446838
step: 830, loss: 0.2725866734981537
step: 840, loss: 0.06050249561667442
step: 850, loss: 0.09467999637126923
step: 860, loss: 0.08781804889440536
step: 870, loss: 0.09967736154794693
step: 880, loss: 0.06127399951219559
step: 890, loss: 0.12040064483880997
step: 900, loss: 0.05280656740069389
step: 910, loss: 0.2981771230697632
step: 920, loss: 0.07912655174732208
step: 930, loss: 0.04613080993294716
step: 940, loss: 0.1123129203915596
step: 950, loss: 0.07956745475530624
step: 960, loss: 0.0663841962814331
step: 970, loss: 0.16296198964118958
epoch 11: dev_f1=0.9203132197144173, f1=0.9216589861751152, best_f1=0.934752429430819
step: 0, loss: 0.0845576673746109
step: 10, loss: 0.10522570461034775
step: 20, loss: 0.06081151217222214
step: 30, loss: 0.02360517531633377
step: 40, loss: 0.018910428509116173
step: 50, loss: 0.012815392576158047
step: 60, loss: 0.04246102645993233
step: 70, loss: 0.12163488566875458
step: 80, loss: 0.11422788351774216
step: 90, loss: 0.11045818030834198
step: 100, loss: 0.10637693107128143
step: 110, loss: 0.10597941279411316
step: 120, loss: 0.06512158364057541
step: 130, loss: 0.1257544904947281
step: 140, loss: 0.07427426427602768
step: 150, loss: 0.06209954991936684
step: 160, loss: 0.1265696883201599
step: 170, loss: 0.0964580848813057
step: 180, loss: 0.10493134707212448
step: 190, loss: 0.06757901608943939
step: 200, loss: 0.05704522877931595
step: 210, loss: 0.01646333932876587
step: 220, loss: 0.05415602773427963
step: 230, loss: 0.10556737333536148
step: 240, loss: 0.02157744951546192
step: 250, loss: 0.05104455351829529
step: 260, loss: 0.015828829258680344
step: 270, loss: 0.049323517829179764
step: 280, loss: 0.055356282740831375
step: 290, loss: 0.060309845954179764
step: 300, loss: 0.07292402535676956
step: 310, loss: 0.11286226660013199
step: 320, loss: 0.04149005189538002
step: 330, loss: 0.04969385266304016
step: 340, loss: 0.04417090117931366
step: 350, loss: 0.0037846474442631006
step: 360, loss: 0.02447853423655033
step: 370, loss: 0.05607730150222778
step: 380, loss: 0.055355433374643326
step: 390, loss: 0.05570775270462036
step: 400, loss: 0.1130700409412384
step: 410, loss: 0.008383423089981079
step: 420, loss: 0.07233373820781708
step: 430, loss: 0.07340921461582184
step: 440, loss: 0.1013006940484047
step: 450, loss: 0.051219046115875244
step: 460, loss: 0.039696481078863144
step: 470, loss: 0.01757529377937317
step: 480, loss: 0.04575127363204956
step: 490, loss: 0.08703465014696121
step: 500, loss: 0.08030050247907639
step: 510, loss: 0.1644313484430313
step: 520, loss: 0.06377366930246353
step: 530, loss: 0.06342112272977829
step: 540, loss: 0.05155785009264946
step: 550, loss: 0.04137495905160904
step: 560, loss: 0.05067017674446106
step: 570, loss: 0.20451568067073822
step: 580, loss: 0.09754068404436111
step: 590, loss: 0.036300525069236755
step: 600, loss: 0.034985221922397614
step: 610, loss: 0.04900236427783966
step: 620, loss: 0.08214198052883148
step: 630, loss: 0.08214741945266724
step: 640, loss: 0.004106220323592424
step: 650, loss: 0.08054061233997345
step: 660, loss: 0.027986986562609673
step: 670, loss: 0.09331813454627991
step: 680, loss: 0.17465797066688538
step: 690, loss: 0.026205990463495255
step: 700, loss: 0.054575927555561066
step: 710, loss: 0.12872368097305298
step: 720, loss: 0.06309016048908234
step: 730, loss: 0.13603365421295166
step: 740, loss: 0.05080738663673401
step: 750, loss: 0.0669047012925148
step: 760, loss: 0.09723939001560211
step: 770, loss: 0.05635664612054825
step: 780, loss: 0.20333492755889893
step: 790, loss: 0.015718309208750725
step: 800, loss: 0.06201745942234993
step: 810, loss: 0.15841969847679138
step: 820, loss: 0.1411656141281128
step: 830, loss: 0.09600134938955307
step: 840, loss: 0.09894813597202301
step: 850, loss: 0.12946729362010956
step: 860, loss: 0.16812998056411743
step: 870, loss: 0.11199118942022324
step: 880, loss: 0.06603030860424042
step: 890, loss: 0.03887128084897995
step: 900, loss: 0.013279559090733528
step: 910, loss: 0.027395447716116905
step: 920, loss: 0.10456353425979614
step: 930, loss: 0.027837315574288368
step: 940, loss: 0.0556667260825634
step: 950, loss: 0.1290828138589859
step: 960, loss: 0.01105482131242752
step: 970, loss: 0.14560972154140472
epoch 12: dev_f1=0.9203132197144173, f1=0.9185938945420906, best_f1=0.934752429430819
step: 0, loss: 0.0691048800945282
step: 10, loss: 0.05366968363523483
step: 20, loss: 0.09630166739225388
step: 30, loss: 0.04677771031856537
step: 40, loss: 0.021536540240049362
step: 50, loss: 0.08628799766302109
step: 60, loss: 0.05558706447482109
step: 70, loss: 0.03277599811553955
step: 80, loss: 0.029859647154808044
step: 90, loss: 0.018849682062864304
step: 100, loss: 0.009086721576750278
step: 110, loss: 0.012614434584975243
step: 120, loss: 0.018166787922382355
step: 130, loss: 0.021142704412341118
step: 140, loss: 0.1416858583688736
step: 150, loss: 0.011131861247122288
step: 160, loss: 0.030196765437722206
step: 170, loss: 0.06062360852956772
step: 180, loss: 0.015940450131893158
step: 190, loss: 0.1047498807311058
step: 200, loss: 0.048724837601184845
step: 210, loss: 0.008388898335397243
step: 220, loss: 0.13043753802776337
step: 230, loss: 0.06445404887199402
step: 240, loss: 0.01863657683134079
step: 250, loss: 0.16775232553482056
step: 260, loss: 0.06668674200773239
step: 270, loss: 0.01660599745810032
step: 280, loss: 0.09705356508493423
step: 290, loss: 0.10526162385940552
step: 300, loss: 0.044683702290058136
step: 310, loss: 0.06607185304164886
step: 320, loss: 0.020244238898158073
step: 330, loss: 0.003974731545895338
step: 340, loss: 0.09503686428070068
step: 350, loss: 0.12360315024852753
step: 360, loss: 0.009898526594042778
step: 370, loss: 0.059668563306331635
step: 380, loss: 0.17345872521400452
step: 390, loss: 0.036596450954675674
step: 400, loss: 0.12178913503885269
step: 410, loss: 0.07829856127500534
step: 420, loss: 0.11914021521806717
step: 430, loss: 0.15334023535251617
step: 440, loss: 0.07586201280355453
step: 450, loss: 0.08022120594978333
step: 460, loss: 0.07558267563581467
step: 470, loss: 0.04668164998292923
step: 480, loss: 0.020462797954678535
step: 490, loss: 0.05344356596469879
step: 500, loss: 0.16308556497097015
step: 510, loss: 0.10070230811834335
step: 520, loss: 0.1158483698964119
step: 530, loss: 0.03504470735788345
step: 540, loss: 0.06384192407131195
step: 550, loss: 0.1414756327867508
step: 560, loss: 0.05169393867254257
step: 570, loss: 0.08264641463756561
step: 580, loss: 0.07279477268457413
step: 590, loss: 0.006835117470473051
step: 600, loss: 0.09875006973743439
step: 610, loss: 0.1245499849319458
step: 620, loss: 0.02217373251914978
step: 630, loss: 0.056842140853405
step: 640, loss: 0.047565001994371414
step: 650, loss: 0.03187946975231171
step: 660, loss: 0.16892486810684204
step: 670, loss: 0.04113677516579628
step: 680, loss: 0.03560980409383774
step: 690, loss: 0.010770246386528015
step: 700, loss: 0.0732855349779129
step: 710, loss: 0.08667942136526108
step: 720, loss: 0.16546359658241272
step: 730, loss: 0.051950473338365555
step: 740, loss: 0.10107672214508057
step: 750, loss: 0.03207629919052124
step: 760, loss: 0.10989005863666534
step: 770, loss: 0.06964199244976044
step: 780, loss: 0.0362134650349617
step: 790, loss: 0.049624357372522354
step: 800, loss: 0.19532760977745056
step: 810, loss: 0.03153609484434128
step: 820, loss: 0.1915922909975052
step: 830, loss: 0.0579710528254509
step: 840, loss: 0.07120686024427414
step: 850, loss: 0.2803032696247101
step: 860, loss: 0.07975517213344574
step: 870, loss: 0.0633690357208252
step: 880, loss: 0.0628223791718483
step: 890, loss: 0.09817485511302948
step: 900, loss: 0.06991368532180786
step: 910, loss: 0.0456954725086689
step: 920, loss: 0.19925636053085327
step: 930, loss: 0.027913756668567657
step: 940, loss: 0.08016631007194519
step: 950, loss: 0.18671566247940063
step: 960, loss: 0.07522723078727722
step: 970, loss: 0.02000989392399788
epoch 13: dev_f1=0.9268518518518517, f1=0.9297347603536529, best_f1=0.934752429430819
step: 0, loss: 0.06296324729919434
step: 10, loss: 0.06866727769374847
step: 20, loss: 0.01219729334115982
step: 30, loss: 0.07974767684936523
step: 40, loss: 0.01783420704305172
step: 50, loss: 0.10016973316669464
step: 60, loss: 0.0056428806856274605
step: 70, loss: 0.03422405570745468
step: 80, loss: 0.11625806987285614
step: 90, loss: 0.12500976026058197
step: 100, loss: 0.135358989238739
step: 110, loss: 0.1186240091919899
step: 120, loss: 0.00953770987689495
step: 130, loss: 0.06372735649347305
step: 140, loss: 0.10039234161376953
step: 150, loss: 0.07757804542779922
step: 160, loss: 0.11806628853082657
step: 170, loss: 0.08117152005434036
step: 180, loss: 0.12482868134975433
step: 190, loss: 0.05000297725200653
step: 200, loss: 0.051674071699380875
step: 210, loss: 0.04849547892808914
step: 220, loss: 0.048894453793764114
step: 230, loss: 0.05241749808192253
step: 240, loss: 0.08233977854251862
step: 250, loss: 0.06356216967105865
step: 260, loss: 0.050651755183935165
step: 270, loss: 0.05904463306069374
step: 280, loss: 0.07436230778694153
step: 290, loss: 0.038053300231695175
step: 300, loss: 0.09392097592353821
step: 310, loss: 0.06831467151641846
step: 320, loss: 0.055977847427129745
step: 330, loss: 0.07430753856897354
step: 340, loss: 0.040128737688064575
step: 350, loss: 0.036616042256355286
step: 360, loss: 0.03477371856570244
step: 370, loss: 0.15916728973388672
step: 380, loss: 0.028550663962960243
step: 390, loss: 0.0031555627938359976
step: 400, loss: 0.057669300585985184
step: 410, loss: 0.05110187456011772
step: 420, loss: 0.07524514943361282
step: 430, loss: 0.03769528493285179
step: 440, loss: 0.042201559990644455
step: 450, loss: 0.05281519517302513
step: 460, loss: 0.004273679107427597
step: 470, loss: 0.1830243617296219
step: 480, loss: 0.1445646435022354
step: 490, loss: 0.13857614994049072
step: 500, loss: 0.08852969855070114
step: 510, loss: 0.04163726046681404
step: 520, loss: 0.0006258953944779932
step: 530, loss: 0.32447218894958496
step: 540, loss: 0.07987001538276672
step: 550, loss: 0.00018842561985366046
step: 560, loss: 0.051935434341430664
step: 570, loss: 0.04930633679032326
step: 580, loss: 0.0809105783700943
step: 590, loss: 0.07138007879257202
step: 600, loss: 0.05907778441905975
step: 610, loss: 0.026048164814710617
step: 620, loss: 0.04825545474886894
step: 630, loss: 0.04343298450112343
step: 640, loss: 0.055959150195121765
step: 650, loss: 0.04943063110113144
step: 660, loss: 0.03142800182104111
step: 670, loss: 0.12336838245391846
step: 680, loss: 0.02965575084090233
step: 690, loss: 0.07973641902208328
step: 700, loss: 0.07987886667251587
step: 710, loss: 0.0711149126291275
step: 720, loss: 0.05104842036962509
step: 730, loss: 0.10848157107830048
step: 740, loss: 0.07334606349468231
step: 750, loss: 0.07664643228054047
step: 760, loss: 0.12439895421266556
step: 770, loss: 0.00838728528469801
step: 780, loss: 0.05455307289958
step: 790, loss: 0.039474356919527054
step: 800, loss: 0.06035235524177551
step: 810, loss: 0.03175094723701477
step: 820, loss: 0.03134854510426521
step: 830, loss: 0.040170345455408096
step: 840, loss: 0.04683517664670944
step: 850, loss: 0.03751693665981293
step: 860, loss: 0.10134247690439224
step: 870, loss: 0.029150355607271194
step: 880, loss: 0.02299615368247032
step: 890, loss: 0.016501804813742638
step: 900, loss: 0.05665663629770279
step: 910, loss: 0.07686945796012878
step: 920, loss: 0.10503929853439331
step: 930, loss: 0.11176098883152008
step: 940, loss: 0.03896584361791611
step: 950, loss: 0.0004449075786396861
step: 960, loss: 0.12580077350139618
step: 970, loss: 0.15635474026203156
epoch 14: dev_f1=0.9187442289935366, f1=0.9195189639222942, best_f1=0.934752429430819
step: 0, loss: 0.02644360065460205
step: 10, loss: 0.0460001677274704
step: 20, loss: 0.11649708449840546
step: 30, loss: 0.021800709888339043
step: 40, loss: 0.02546383999288082
step: 50, loss: 0.07469191402196884
step: 60, loss: 0.0792163833975792
step: 70, loss: 0.04886395484209061
step: 80, loss: 0.018552185967564583
step: 90, loss: 0.09700236469507217
step: 100, loss: 0.12894561886787415
step: 110, loss: 0.1346629112958908
step: 120, loss: 0.05504368618130684
step: 130, loss: 0.049325764179229736
step: 140, loss: 0.02380390092730522
step: 150, loss: 0.022598128765821457
step: 160, loss: 0.06815113872289658
step: 170, loss: 0.021315133199095726
step: 180, loss: 0.0724065750837326
step: 190, loss: 0.13548290729522705
step: 200, loss: 0.031153012067079544
step: 210, loss: 0.055287789553403854
step: 220, loss: 0.06406411528587341
step: 230, loss: 0.08245585858821869
step: 240, loss: 0.09252151101827621
step: 250, loss: 0.10917752981185913
step: 260, loss: 0.06610696017742157
step: 270, loss: 0.08330224454402924
step: 280, loss: 0.05939135327935219
step: 290, loss: 0.030301913619041443
step: 300, loss: 0.019610922783613205
step: 310, loss: 0.03542875126004219
step: 320, loss: 0.11858883500099182
step: 330, loss: 0.010474509559571743
step: 340, loss: 0.09700334817171097
step: 350, loss: 0.01980544626712799
step: 360, loss: 0.020845912396907806
step: 370, loss: 0.1034872755408287
step: 380, loss: 0.0756814107298851
step: 390, loss: 0.026005944237113
step: 400, loss: 0.04462636634707451
step: 410, loss: 0.04258588328957558
step: 420, loss: 0.03291138634085655
step: 430, loss: 0.003569924971088767
step: 440, loss: 0.030028700828552246
step: 450, loss: 0.03608784079551697
step: 460, loss: 0.05329137668013573
step: 470, loss: 0.04959537461400032
step: 480, loss: 0.14088883996009827
step: 490, loss: 0.052541445940732956
step: 500, loss: 0.10538904368877411
step: 510, loss: 0.05607512220740318
step: 520, loss: 0.0574592687189579
step: 530, loss: 0.03861113265156746
step: 540, loss: 0.06589099019765854
step: 550, loss: 0.07550080865621567
step: 560, loss: 0.053861286491155624
step: 570, loss: 0.08446986228227615
step: 580, loss: 0.03576267883181572
step: 590, loss: 0.09306556731462479
step: 600, loss: 0.02550717443227768
step: 610, loss: 0.02093365229666233
step: 620, loss: 0.08245241641998291
step: 630, loss: 0.029020262882113457
step: 640, loss: 0.036177005618810654
step: 650, loss: 0.030733078718185425
step: 660, loss: 0.046326544135808945
step: 670, loss: 0.009922715835273266
step: 680, loss: 0.07790522277355194
step: 690, loss: 0.028330406174063683
step: 700, loss: 0.012450909242033958
step: 710, loss: 0.056206945329904556
step: 720, loss: 0.11815942078828812
step: 730, loss: 0.061012156307697296
step: 740, loss: 0.10189319401979446
step: 750, loss: 0.0730087086558342
step: 760, loss: 0.09389864653348923
step: 770, loss: 0.08103576302528381
step: 780, loss: 0.09370359778404236
step: 790, loss: 0.0087662935256958
step: 800, loss: 0.00015245085523929447
step: 810, loss: 0.09103294461965561
step: 820, loss: 0.039055053144693375
step: 830, loss: 0.01854325830936432
step: 840, loss: 0.0002637772704474628
step: 850, loss: 0.07788075506687164
step: 860, loss: 0.1415598839521408
step: 870, loss: 0.04045901447534561
step: 880, loss: 0.050742924213409424
step: 890, loss: 0.0604645311832428
step: 900, loss: 0.043334055691957474
step: 910, loss: 0.055188823491334915
step: 920, loss: 0.10822345316410065
step: 930, loss: 0.12104532867670059
step: 940, loss: 0.052579332143068314
step: 950, loss: 0.0011314767180010676
step: 960, loss: 0.028846964240074158
step: 970, loss: 0.06697624176740646
epoch 15: dev_f1=0.923221855864343, f1=0.9235849056603773, best_f1=0.934752429430819
step: 0, loss: 0.028896763920783997
step: 10, loss: 0.054249051958322525
step: 20, loss: 0.0732853040099144
step: 30, loss: 0.000619176309555769
step: 40, loss: 0.060735322535037994
step: 50, loss: 0.023184698075056076
step: 60, loss: 0.07232741266489029
step: 70, loss: 0.18377317488193512
step: 80, loss: 0.18046727776527405
step: 90, loss: 0.06828140467405319
step: 100, loss: 0.05902460962533951
step: 110, loss: 0.09843838214874268
step: 120, loss: 0.018181564286351204
step: 130, loss: 0.05389874428510666
step: 140, loss: 0.06573193520307541
step: 150, loss: 0.010693814605474472
step: 160, loss: 0.07329339534044266
step: 170, loss: 0.009071065112948418
step: 180, loss: 0.056508973240852356
step: 190, loss: 0.06819730997085571
step: 200, loss: 0.093614861369133
step: 210, loss: 0.010952153243124485
step: 220, loss: 0.11744243651628494
step: 230, loss: 0.01584043726325035
step: 240, loss: 0.002665107138454914
step: 250, loss: 0.039288733154535294
step: 260, loss: 0.021594291552901268
step: 270, loss: 0.05389830470085144
step: 280, loss: 0.10194472968578339
step: 290, loss: 0.0005218642763793468
step: 300, loss: 0.08602199703454971
step: 310, loss: 0.03798038884997368
step: 320, loss: 0.11195749789476395
step: 330, loss: 0.034944601356983185
step: 340, loss: 0.09498561173677444
step: 350, loss: 0.049773626029491425
step: 360, loss: 0.050805214792490005
step: 370, loss: 0.03431829437613487
step: 380, loss: 0.03288331627845764
step: 390, loss: 0.03563479334115982
step: 400, loss: 0.024078596383333206
step: 410, loss: 0.05833996832370758
step: 420, loss: 0.0162621159106493
step: 430, loss: 0.01249254122376442
step: 440, loss: 0.03059876337647438
step: 450, loss: 0.05799758434295654
step: 460, loss: 0.02502240240573883
step: 470, loss: 0.05898580327630043
step: 480, loss: 0.05906735360622406
step: 490, loss: 0.04800485447049141
step: 500, loss: 0.014578580856323242
step: 510, loss: 0.0016289983177557588
step: 520, loss: 0.02465631067752838
step: 530, loss: 0.01603485271334648
step: 540, loss: 0.04000408947467804
step: 550, loss: 0.07253622263669968
step: 560, loss: 0.086494579911232
step: 570, loss: 0.06842831522226334
step: 580, loss: 0.04016083478927612
step: 590, loss: 0.008557026274502277
step: 600, loss: 0.081926129758358
step: 610, loss: 0.04905401170253754
step: 620, loss: 0.03260793164372444
step: 630, loss: 0.016003651544451714
step: 640, loss: 0.01864505745470524
step: 650, loss: 0.0577629990875721
step: 660, loss: 0.09180327504873276
step: 670, loss: 0.11481624096632004
step: 680, loss: 0.03375997766852379
step: 690, loss: 0.0635969415307045
step: 700, loss: 0.02529839612543583
step: 710, loss: 0.011466375552117825
step: 720, loss: 0.006588350981473923
step: 730, loss: 0.07500898838043213
step: 740, loss: 0.06250011175870895
step: 750, loss: 0.03196655586361885
step: 760, loss: 0.056650880724191666
step: 770, loss: 0.08686136454343796
step: 780, loss: 0.08042474836111069
step: 790, loss: 0.03642165660858154
step: 800, loss: 0.026058904826641083
step: 810, loss: 0.06962185353040695
step: 820, loss: 0.04707156866788864
step: 830, loss: 0.036060646176338196
step: 840, loss: 0.03382620960474014
step: 850, loss: 0.12273348867893219
step: 860, loss: 0.03791094198822975
step: 870, loss: 2.034988210652955e-05
step: 880, loss: 0.04327768832445145
step: 890, loss: 0.017642373219132423
step: 900, loss: 0.195684552192688
step: 910, loss: 0.055871739983558655
step: 920, loss: 0.036100853234529495
step: 930, loss: 0.09665840119123459
step: 940, loss: 0.03893516585230827
step: 950, loss: 0.11215479671955109
step: 960, loss: 0.04435760900378227
step: 970, loss: 0.03781920298933983
epoch 16: dev_f1=0.9248014946286782, f1=0.9225746268656716, best_f1=0.934752429430819
step: 0, loss: 0.045763686299324036
step: 10, loss: 0.047976087778806686
step: 20, loss: 0.01946808025240898
step: 30, loss: 0.06462032347917557
step: 40, loss: 0.034646037966012955
step: 50, loss: 0.058432113379240036
step: 60, loss: 0.013117019087076187
step: 70, loss: 0.05865107849240303
step: 80, loss: 0.09872463345527649
step: 90, loss: 0.03859814628958702
step: 100, loss: 0.058129578828811646
step: 110, loss: 0.06381243467330933
step: 120, loss: 0.007294057868421078
step: 130, loss: 0.10310479253530502
step: 140, loss: 0.09748322516679764
step: 150, loss: 0.037490084767341614
step: 160, loss: 0.019618196412920952
step: 170, loss: 0.05487990379333496
step: 180, loss: 0.09550012648105621
step: 190, loss: 0.08177109807729721
step: 200, loss: 0.16652251780033112
step: 210, loss: 0.08224962651729584
step: 220, loss: 0.027855731546878815
step: 230, loss: 0.10432976484298706
step: 240, loss: 0.00010178019147133455
step: 250, loss: 0.0795195996761322
step: 260, loss: 0.041854649782180786
step: 270, loss: 0.12342903763055801
step: 280, loss: 0.09692659974098206
step: 290, loss: 0.15252184867858887
step: 300, loss: 0.043294452130794525
step: 310, loss: 0.07829780131578445
step: 320, loss: 0.04718732833862305
step: 330, loss: 0.025799168273806572
step: 340, loss: 0.09929211437702179
step: 350, loss: 0.06376837193965912
step: 360, loss: 0.0017878311919048429
step: 370, loss: 0.050660327076911926
step: 380, loss: 0.13178957998752594
step: 390, loss: 0.018473532050848007
step: 400, loss: 0.09135822206735611
step: 410, loss: 0.08120202273130417
step: 420, loss: 0.0003971586702391505
step: 430, loss: 0.06852871179580688
step: 440, loss: 0.04912262409925461
step: 450, loss: 0.04863063246011734
step: 460, loss: 0.002051361370831728
step: 470, loss: 0.25656941533088684
step: 480, loss: 0.05618829280138016
step: 490, loss: 0.00871291197836399
step: 500, loss: 0.015068422071635723
step: 510, loss: 0.014109335839748383
step: 520, loss: 0.07202967256307602
step: 530, loss: 0.09902725368738174
step: 540, loss: 0.07623105496168137
step: 550, loss: 0.043366629630327225
step: 560, loss: 0.0747782438993454
step: 570, loss: 0.05922439321875572
step: 580, loss: 0.06623449921607971
step: 590, loss: 0.040736548602581024
step: 600, loss: 0.0008825109107419848
step: 610, loss: 0.05330357328057289
step: 620, loss: 0.06482908874750137
step: 630, loss: 0.055207982659339905
step: 640, loss: 0.017088109627366066
step: 650, loss: 0.005397386848926544
step: 660, loss: 0.04914211109280586
step: 670, loss: 0.017765000462532043
step: 680, loss: 0.0009928223444148898
step: 690, loss: 0.18053580820560455
step: 700, loss: 0.07019311189651489
step: 710, loss: 0.07897011935710907
step: 720, loss: 0.053716063499450684
step: 730, loss: 0.12650129199028015
step: 740, loss: 0.10563299804925919
step: 750, loss: 0.012706572189927101
step: 760, loss: 0.019763411954045296
step: 770, loss: 0.0011007200228050351
step: 780, loss: 0.00010049643606180325
step: 790, loss: 0.030585989356040955
step: 800, loss: 0.10069568455219269
step: 810, loss: 0.025908485054969788
step: 820, loss: 0.03089934214949608
step: 830, loss: 0.008966559544205666
step: 840, loss: 0.04017839580774307
step: 850, loss: 0.013061750680208206
step: 860, loss: 0.14152942597866058
step: 870, loss: 0.036516088992357254
step: 880, loss: 0.04929618909955025
step: 890, loss: 0.09559311717748642
step: 900, loss: 0.06715894490480423
step: 910, loss: 0.04928683489561081
step: 920, loss: 0.13398315012454987
step: 930, loss: 0.055750392377376556
step: 940, loss: 0.14954873919487
step: 950, loss: 0.032497815787792206
step: 960, loss: 0.11206039041280746
step: 970, loss: 0.02593253366649151
epoch 17: dev_f1=0.9248014946286782, f1=0.921999065857076, best_f1=0.934752429430819
step: 0, loss: 0.0011424190597608685
step: 10, loss: 0.07602343708276749
step: 20, loss: 0.0301866102963686
step: 30, loss: 0.005674953572452068
step: 40, loss: 0.1677652895450592
step: 50, loss: 0.04936615750193596
step: 60, loss: 0.04938706010580063
step: 70, loss: 0.023657266050577164
step: 80, loss: 0.05998517945408821
step: 90, loss: 0.01571311056613922
step: 100, loss: 0.06661147624254227
step: 110, loss: 0.08631227165460587
step: 120, loss: 0.010197837837040424
step: 130, loss: 0.04257868602871895
step: 140, loss: 0.10093137621879578
step: 150, loss: 0.06260640919208527
step: 160, loss: 0.021533191204071045
step: 170, loss: 0.10883849114179611
step: 180, loss: 0.02374079078435898
step: 190, loss: 0.05316580832004547
step: 200, loss: 0.0531020388007164
step: 210, loss: 0.05106685310602188
step: 220, loss: 0.1245427206158638
step: 230, loss: 0.016710996627807617
step: 240, loss: 0.07191698253154755
step: 250, loss: 0.07114772498607635
step: 260, loss: 0.04630400985479355
step: 270, loss: 0.031218428164720535
step: 280, loss: 0.01853485219180584
step: 290, loss: 0.03993615880608559
step: 300, loss: 0.025985222309827805
step: 310, loss: 0.0298860315233469
step: 320, loss: 0.05619743466377258
step: 330, loss: 9.687399142421782e-05
step: 340, loss: 0.07961821556091309
step: 350, loss: 0.03266588971018791
step: 360, loss: 0.05539727583527565
step: 370, loss: 0.09229106456041336
step: 380, loss: 0.011713581159710884
step: 390, loss: 0.06507288664579391
step: 400, loss: 0.038302429020404816
step: 410, loss: 0.030545448884367943
step: 420, loss: 0.03670870512723923
step: 430, loss: 0.037303175777196884
step: 440, loss: 0.1108771339058876
step: 450, loss: 0.06204254925251007
step: 460, loss: 0.026165813207626343
step: 470, loss: 0.018827583640813828
step: 480, loss: 0.04460888355970383
step: 490, loss: 0.0020169534254819155
step: 500, loss: 0.09114155173301697
step: 510, loss: 0.021248888224363327
step: 520, loss: 0.05997850000858307
step: 530, loss: 0.043311528861522675
step: 540, loss: 0.15616461634635925
step: 550, loss: 0.05820967257022858
step: 560, loss: 0.021894726902246475
step: 570, loss: 0.03749161958694458
step: 580, loss: 0.039892490953207016
step: 590, loss: 0.0836944505572319
step: 600, loss: 0.03744593262672424
step: 610, loss: 0.052467793226242065
step: 620, loss: 0.058522894978523254
step: 630, loss: 0.06175366789102554
step: 640, loss: 0.1275198757648468
step: 650, loss: 0.008081608451902866
step: 660, loss: 0.08056311309337616
step: 670, loss: 0.07919294387102127
step: 680, loss: 0.11647982895374298
step: 690, loss: 0.031983450055122375
step: 700, loss: 0.02643071487545967
step: 710, loss: 0.08068643510341644
step: 720, loss: 0.17720451951026917
step: 730, loss: 0.06366825848817825
step: 740, loss: 0.03375585377216339
step: 750, loss: 0.025262579321861267
step: 760, loss: 0.07583978772163391
step: 770, loss: 0.06256794184446335
step: 780, loss: 0.09391465038061142
step: 790, loss: 0.04964109882712364
step: 800, loss: 0.03263825923204422
step: 810, loss: 0.055872589349746704
step: 820, loss: 0.04645199328660965
step: 830, loss: 0.08269444108009338
step: 840, loss: 0.05717436969280243
step: 850, loss: 0.07875014841556549
step: 860, loss: 0.00018753699259832501
step: 870, loss: 0.07885321974754333
step: 880, loss: 0.10927055031061172
step: 890, loss: 0.031072963029146194
step: 900, loss: 0.14147786796092987
step: 910, loss: 0.09430012851953506
step: 920, loss: 0.0213631484657526
step: 930, loss: 0.06327960640192032
step: 940, loss: 0.10071684420108795
step: 950, loss: 0.00015041715232655406
step: 960, loss: 0.07354145497083664
step: 970, loss: 0.020408501848578453
epoch 18: dev_f1=0.9259783121169259, f1=0.9222065063649223, best_f1=0.934752429430819
step: 0, loss: 0.01943923905491829
step: 10, loss: 0.006500943563878536
step: 20, loss: 0.07428047060966492
step: 30, loss: 0.05881519615650177
step: 40, loss: 0.061260342597961426
step: 50, loss: 0.13104547560214996
step: 60, loss: 0.0003395502280909568
step: 70, loss: 0.08779963850975037
step: 80, loss: 0.04490232467651367
step: 90, loss: 0.030675340443849564
step: 100, loss: 0.017206743359565735
step: 110, loss: 0.03515872359275818
step: 120, loss: 0.023944837972521782
step: 130, loss: 0.11406295001506805
step: 140, loss: 0.0668264701962471
step: 150, loss: 0.006846371106803417
step: 160, loss: 0.07724720239639282
step: 170, loss: 0.05256488919258118
step: 180, loss: 0.1425723135471344
step: 190, loss: 0.029655413702130318
step: 200, loss: 0.03767668455839157
step: 210, loss: 0.06571974605321884
step: 220, loss: 0.028949424624443054
step: 230, loss: 0.06993671506643295
step: 240, loss: 0.0367608517408371
step: 250, loss: 0.07433392107486725
step: 260, loss: 0.01207469031214714
step: 270, loss: 0.021703340113162994
step: 280, loss: 0.017668023705482483
step: 290, loss: 0.010934211313724518
step: 300, loss: 0.044537756592035294
step: 310, loss: 0.12118086218833923
step: 320, loss: 0.0630272701382637
step: 330, loss: 0.019455328583717346
step: 340, loss: 0.013048798777163029
step: 350, loss: 0.009788853116333485
step: 360, loss: 0.03995352238416672
step: 370, loss: 0.09550290554761887
step: 380, loss: 7.596614887006581e-05
step: 390, loss: 0.1305677443742752
step: 400, loss: 0.011452170088887215
step: 410, loss: 0.0405225045979023
step: 420, loss: 0.06035159155726433
step: 430, loss: 0.001627900986932218
step: 440, loss: 0.11691699922084808
step: 450, loss: 0.0460900142788887
step: 460, loss: 0.07103966921567917
step: 470, loss: 0.030088983476161957
step: 480, loss: 0.052563898265361786
step: 490, loss: 0.024017294868826866
step: 500, loss: 0.08712616562843323
step: 510, loss: 0.05578035116195679
step: 520, loss: 0.013103287667036057
step: 530, loss: 0.021042702719569206
step: 540, loss: 0.057137928903102875
step: 550, loss: 0.10066980123519897
step: 560, loss: 0.057089634239673615
step: 570, loss: 0.03244602307677269
step: 580, loss: 0.0005901947733946145
step: 590, loss: 0.023325780406594276
step: 600, loss: 0.018819328397512436
step: 610, loss: 0.027960050851106644
step: 620, loss: 0.1734539270401001
step: 630, loss: 0.08994502574205399
step: 640, loss: 0.00017997644317802042
step: 650, loss: 0.0005691489204764366
step: 660, loss: 0.11998098343610764
step: 670, loss: 0.009496044367551804
step: 680, loss: 0.0931922048330307
step: 690, loss: 0.11496485769748688
step: 700, loss: 0.04178338870406151
step: 710, loss: 0.10188677906990051
step: 720, loss: 0.002218100940808654
step: 730, loss: 0.001176777295768261
step: 740, loss: 0.07196373492479324
step: 750, loss: 0.034867070615291595
step: 760, loss: 0.08104503899812698
step: 770, loss: 0.07585132867097855
step: 780, loss: 0.0006927979411557317
step: 790, loss: 0.00010016540181823075
step: 800, loss: 0.05841401219367981
step: 810, loss: 0.054129403084516525
step: 820, loss: 0.011399028822779655
step: 830, loss: 0.018568143248558044
step: 840, loss: 0.07980562001466751
step: 850, loss: 0.02107134647667408
step: 860, loss: 0.04169377684593201
step: 870, loss: 0.03145989403128624
step: 880, loss: 0.03041531890630722
step: 890, loss: 0.03786294534802437
step: 900, loss: 0.032372038811445236
step: 910, loss: 0.00037721105036325753
step: 920, loss: 0.09964429587125778
step: 930, loss: 0.030819721519947052
step: 940, loss: 0.01655382290482521
step: 950, loss: 0.013829026371240616
step: 960, loss: 0.024094389751553535
step: 970, loss: 0.025926273316144943
epoch 19: dev_f1=0.9240801117838845, f1=0.919422449930135, best_f1=0.934752429430819
step: 0, loss: 0.07766509056091309
step: 10, loss: 0.047970663756132126
step: 20, loss: 0.004060502164065838
step: 30, loss: 0.02444222941994667
step: 40, loss: 0.08166476339101791
step: 50, loss: 0.055268555879592896
step: 60, loss: 0.07351851463317871
step: 70, loss: 0.0006101103499531746
step: 80, loss: 0.09641939401626587
step: 90, loss: 0.022965330630540848
step: 100, loss: 0.054527655243873596
step: 110, loss: 0.09091052412986755
step: 120, loss: 0.030729470774531364
step: 130, loss: 0.015397479757666588
step: 140, loss: 0.05494894087314606
step: 150, loss: 0.011704952456057072
step: 160, loss: 0.0305771641433239
step: 170, loss: 0.007587570697069168
step: 180, loss: 0.00013460057380143553
step: 190, loss: 0.05683412775397301
step: 200, loss: 0.04008723050355911
step: 210, loss: 0.0474449060857296
step: 220, loss: 0.024561991915106773
step: 230, loss: 0.04116835072636604
step: 240, loss: 0.058320578187704086
step: 250, loss: 0.033763572573661804
step: 260, loss: 0.04290781915187836
step: 270, loss: 0.004631787538528442
step: 280, loss: 0.03121817857027054
step: 290, loss: 0.1094478890299797
step: 300, loss: 0.10557976365089417
step: 310, loss: 0.051094017922878265
step: 320, loss: 0.06078125536441803
step: 330, loss: 0.06341241300106049
step: 340, loss: 0.009746399708092213
step: 350, loss: 0.0704134926199913
step: 360, loss: 0.07051127403974533
step: 370, loss: 0.0349155031144619
step: 380, loss: 0.01024680770933628
step: 390, loss: 0.0939643457531929
step: 400, loss: 0.041540686041116714
step: 410, loss: 0.031063618138432503
step: 420, loss: 0.05559561774134636
step: 430, loss: 0.16087739169597626
step: 440, loss: 0.018702322617173195
step: 450, loss: 0.14186051487922668
step: 460, loss: 0.13449478149414062
step: 470, loss: 0.045913953334093094
step: 480, loss: 0.00033109026844613254
step: 490, loss: 0.06363416463136673
step: 500, loss: 0.09238095581531525
step: 510, loss: 0.017926951870322227
step: 520, loss: 0.0010658727260306478
step: 530, loss: 0.031100569292902946
step: 540, loss: 0.09330368041992188
step: 550, loss: 0.00627391180023551
step: 560, loss: 0.0015333130722865462
step: 570, loss: 0.027125993743538857
step: 580, loss: 0.1076953113079071
step: 590, loss: 0.05299746245145798
step: 600, loss: 0.08050847798585892
step: 610, loss: 0.043469902127981186
step: 620, loss: 0.06854820251464844
step: 630, loss: 0.11944682896137238
step: 640, loss: 0.03960390016436577
step: 650, loss: 0.0002051361952908337
step: 660, loss: 0.010850615799427032
step: 670, loss: 0.09304402768611908
step: 680, loss: 0.042144838720560074
step: 690, loss: 0.06394918262958527
step: 700, loss: 0.025793027132749557
step: 710, loss: 0.025650445371866226
step: 720, loss: 0.06596509367227554
step: 730, loss: 0.08821693807840347
step: 740, loss: 0.08279755711555481
step: 750, loss: 0.06447922438383102
step: 760, loss: 0.08692867308855057
step: 770, loss: 0.05116621404886246
step: 780, loss: 0.05888805910944939
step: 790, loss: 0.014092188328504562
step: 800, loss: 0.11901969462633133
step: 810, loss: 0.0002877192455343902
step: 820, loss: 0.00013644073624163866
step: 830, loss: 0.016542136669158936
step: 840, loss: 0.0001608226593816653
step: 850, loss: 0.0001113798571168445
step: 860, loss: 0.06548610329627991
step: 870, loss: 0.029253821820020676
step: 880, loss: 0.024660548195242882
step: 890, loss: 0.0955284833908081
step: 900, loss: 0.029573040083050728
step: 910, loss: 0.0002560315770097077
step: 920, loss: 0.04904761537909508
step: 930, loss: 0.0814153328537941
step: 940, loss: 0.051979340612888336
step: 950, loss: 0.059476058930158615
step: 960, loss: 0.03784186765551567
step: 970, loss: 0.05746413394808769
epoch 20: dev_f1=0.923221855864343, f1=0.9214117647058824, best_f1=0.934752429430819
