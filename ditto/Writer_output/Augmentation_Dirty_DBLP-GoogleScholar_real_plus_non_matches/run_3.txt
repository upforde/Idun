cuda
Device: cuda
step: 0, loss: 0.946168065071106
step: 10, loss: 0.26828086376190186
step: 20, loss: 0.24487847089767456
step: 30, loss: 0.25530388951301575
step: 40, loss: 0.25084829330444336
step: 50, loss: 0.1053447350859642
step: 60, loss: 0.14177975058555603
step: 70, loss: 0.2381967008113861
step: 80, loss: 0.22254900634288788
step: 90, loss: 0.30985355377197266
step: 100, loss: 0.10669445246458054
step: 110, loss: 0.2031858265399933
step: 120, loss: 0.10238631069660187
step: 130, loss: 0.06832591444253922
step: 140, loss: 0.30277758836746216
step: 150, loss: 0.1598474383354187
step: 160, loss: 0.3299615979194641
step: 170, loss: 0.1910284012556076
step: 180, loss: 0.1415511965751648
step: 190, loss: 0.13586093485355377
step: 200, loss: 0.2514743506908417
step: 210, loss: 0.19077059626579285
step: 220, loss: 0.20892061293125153
step: 230, loss: 0.22966597974300385
step: 240, loss: 0.07745830714702606
step: 250, loss: 0.13165123760700226
step: 260, loss: 0.20104800164699554
step: 270, loss: 0.17093588411808014
step: 280, loss: 0.17085018754005432
step: 290, loss: 0.1803368777036667
step: 300, loss: 0.05835208669304848
step: 310, loss: 0.13221882283687592
step: 320, loss: 0.1973043531179428
step: 330, loss: 0.08586423099040985
step: 340, loss: 0.18167856335639954
step: 350, loss: 0.16306743025779724
step: 360, loss: 0.1509343832731247
step: 370, loss: 0.19574356079101562
step: 380, loss: 0.14166942238807678
step: 390, loss: 0.14894326031208038
step: 400, loss: 0.2637685239315033
step: 410, loss: 0.10265649110078812
step: 420, loss: 0.09562554210424423
step: 430, loss: 0.38820329308509827
step: 440, loss: 0.15730170905590057
step: 450, loss: 0.038413506001234055
step: 460, loss: 0.13055367767810822
step: 470, loss: 0.13477659225463867
step: 480, loss: 0.3419775664806366
step: 490, loss: 0.045809097588062286
step: 500, loss: 0.1477619856595993
step: 510, loss: 0.05840412899851799
step: 520, loss: 0.13953444361686707
step: 530, loss: 0.10242559760808945
step: 540, loss: 0.15756715834140778
step: 550, loss: 0.14284838736057281
step: 560, loss: 0.20148785412311554
step: 570, loss: 0.24580423533916473
step: 580, loss: 0.2492445707321167
step: 590, loss: 0.1480516791343689
step: 600, loss: 0.11960799247026443
step: 610, loss: 0.12931618094444275
step: 620, loss: 0.13479693233966827
step: 630, loss: 0.19450818002223969
step: 640, loss: 0.16187089681625366
step: 650, loss: 0.17136013507843018
step: 660, loss: 0.1520444005727768
step: 670, loss: 0.17767253518104553
step: 680, loss: 0.26974228024482727
step: 690, loss: 0.09961523860692978
step: 700, loss: 0.12046141922473907
step: 710, loss: 0.1357286125421524
step: 720, loss: 0.05798090994358063
step: 730, loss: 0.1477900892496109
step: 740, loss: 0.11448872834444046
step: 750, loss: 0.15937818586826324
step: 760, loss: 0.2818099558353424
step: 770, loss: 0.2326718121767044
step: 780, loss: 0.1170412003993988
step: 790, loss: 0.2033291757106781
step: 800, loss: 0.22347578406333923
step: 810, loss: 0.12926319241523743
step: 820, loss: 0.19253690540790558
step: 830, loss: 0.12695610523223877
step: 840, loss: 0.0915725827217102
step: 850, loss: 0.170855313539505
step: 860, loss: 0.18927471339702606
step: 870, loss: 0.17240704596042633
step: 880, loss: 0.4147186875343323
step: 890, loss: 0.09881582111120224
step: 900, loss: 0.08877342194318771
step: 910, loss: 0.15169920027256012
step: 920, loss: 0.15396441519260406
step: 930, loss: 0.10147237032651901
step: 940, loss: 0.25490865111351013
step: 950, loss: 0.09183753281831741
step: 960, loss: 0.18065065145492554
step: 970, loss: 0.09192173182964325
epoch 1: dev_f1=0.9135355364418288, f1=0.9098250336473755, best_f1=0.9098250336473755
step: 0, loss: 0.1617160588502884
step: 10, loss: 0.2476465255022049
step: 20, loss: 0.1554131805896759
step: 30, loss: 0.08248267322778702
step: 40, loss: 0.09972941130399704
step: 50, loss: 0.1264011114835739
step: 60, loss: 0.15160506963729858
step: 70, loss: 0.11751481145620346
step: 80, loss: 0.12506203353405
step: 90, loss: 0.10311613976955414
step: 100, loss: 0.06770579516887665
step: 110, loss: 0.10003040730953217
step: 120, loss: 0.12267369776964188
step: 130, loss: 0.07585705816745758
step: 140, loss: 0.09448070079088211
step: 150, loss: 0.1251649111509323
step: 160, loss: 0.10468393564224243
step: 170, loss: 0.1669195294380188
step: 180, loss: 0.055889569222927094
step: 190, loss: 0.3047965168952942
step: 200, loss: 0.05843242630362511
step: 210, loss: 0.1248689740896225
step: 220, loss: 0.08001581579446793
step: 230, loss: 0.25285354256629944
step: 240, loss: 0.15668441355228424
step: 250, loss: 0.14443287253379822
step: 260, loss: 0.12450253218412399
step: 270, loss: 0.09485990554094315
step: 280, loss: 0.1883302479982376
step: 290, loss: 0.16227403283119202
step: 300, loss: 0.13136498630046844
step: 310, loss: 0.09067431092262268
step: 320, loss: 0.14899533987045288
step: 330, loss: 0.09202832728624344
step: 340, loss: 0.16406577825546265
step: 350, loss: 0.17768904566764832
step: 360, loss: 0.14233888685703278
step: 370, loss: 0.0956542044878006
step: 380, loss: 0.1068042442202568
step: 390, loss: 0.02630293183028698
step: 400, loss: 0.21499963104724884
step: 410, loss: 0.14028677344322205
step: 420, loss: 0.12299027293920517
step: 430, loss: 0.22521229088306427
step: 440, loss: 0.07159912586212158
step: 450, loss: 0.12842221558094025
step: 460, loss: 0.1192716583609581
step: 470, loss: 0.14514411985874176
step: 480, loss: 0.09122610837221146
step: 490, loss: 0.23959584534168243
step: 500, loss: 0.10040891170501709
step: 510, loss: 0.0919400230050087
step: 520, loss: 0.35399338603019714
step: 530, loss: 0.07856887578964233
step: 540, loss: 0.15309660136699677
step: 550, loss: 0.1884496957063675
step: 560, loss: 0.1123385950922966
step: 570, loss: 0.07192396372556686
step: 580, loss: 0.14736345410346985
step: 590, loss: 0.018844375386834145
step: 600, loss: 0.08796845376491547
step: 610, loss: 0.2355313003063202
step: 620, loss: 0.08614332973957062
step: 630, loss: 0.16881830990314484
step: 640, loss: 0.1405131071805954
step: 650, loss: 0.11037749797105789
step: 660, loss: 0.1328001171350479
step: 670, loss: 0.11646270751953125
step: 680, loss: 0.06647045910358429
step: 690, loss: 0.13358664512634277
step: 700, loss: 0.15324825048446655
step: 710, loss: 0.05900409445166588
step: 720, loss: 0.1699402928352356
step: 730, loss: 0.04403521865606308
step: 740, loss: 0.17762544751167297
step: 750, loss: 0.13862666487693787
step: 760, loss: 0.12761954963207245
step: 770, loss: 0.07660069316625595
step: 780, loss: 0.08856230229139328
step: 790, loss: 0.19603215157985687
step: 800, loss: 0.1415943056344986
step: 810, loss: 0.08541052788496017
step: 820, loss: 0.15833891928195953
step: 830, loss: 0.10382711887359619
step: 840, loss: 0.12608183920383453
step: 850, loss: 0.038397278636693954
step: 860, loss: 0.06538305431604385
step: 870, loss: 0.06921587884426117
step: 880, loss: 0.12171968817710876
step: 890, loss: 0.17943882942199707
step: 900, loss: 0.13674192130565643
step: 910, loss: 0.05423108860850334
step: 920, loss: 0.1179206594824791
step: 930, loss: 0.17918531596660614
step: 940, loss: 0.06377144157886505
step: 950, loss: 0.16749322414398193
step: 960, loss: 0.09036094695329666
step: 970, loss: 0.04179692268371582
epoch 2: dev_f1=0.9199255121042831, f1=0.9202965708989804, best_f1=0.9202965708989804
step: 0, loss: 0.055461008101701736
step: 10, loss: 0.08483030647039413
step: 20, loss: 0.0732768103480339
step: 30, loss: 0.15959493815898895
step: 40, loss: 0.09724847972393036
step: 50, loss: 0.014684741385281086
step: 60, loss: 0.10098087042570114
step: 70, loss: 0.03462716192007065
step: 80, loss: 0.13054242730140686
step: 90, loss: 0.05649281665682793
step: 100, loss: 0.0696110650897026
step: 110, loss: 0.017772244289517403
step: 120, loss: 0.08773475885391235
step: 130, loss: 0.01437104307115078
step: 140, loss: 0.10785752534866333
step: 150, loss: 0.07201816141605377
step: 160, loss: 0.1972874253988266
step: 170, loss: 0.16973038017749786
step: 180, loss: 0.23456017673015594
step: 190, loss: 0.11145395785570145
step: 200, loss: 0.18857230246067047
step: 210, loss: 0.07831784337759018
step: 220, loss: 0.19305400550365448
step: 230, loss: 0.1767425388097763
step: 240, loss: 0.05737002193927765
step: 250, loss: 0.10507480800151825
step: 260, loss: 0.0937098041176796
step: 270, loss: 0.09613382071256638
step: 280, loss: 0.0848398208618164
step: 290, loss: 0.2283964902162552
step: 300, loss: 0.12825313210487366
step: 310, loss: 0.05075609311461449
step: 320, loss: 0.12544362246990204
step: 330, loss: 0.13830837607383728
step: 340, loss: 0.190421000123024
step: 350, loss: 0.12968236207962036
step: 360, loss: 0.0481814406812191
step: 370, loss: 0.12535139918327332
step: 380, loss: 0.09590736031532288
step: 390, loss: 0.17414355278015137
step: 400, loss: 0.07705815136432648
step: 410, loss: 0.0456833615899086
step: 420, loss: 0.1844811588525772
step: 430, loss: 0.12301348894834518
step: 440, loss: 0.2350691258907318
step: 450, loss: 0.11168129742145538
step: 460, loss: 0.17473214864730835
step: 470, loss: 0.07294873893260956
step: 480, loss: 0.07623136043548584
step: 490, loss: 0.1241869404911995
step: 500, loss: 0.24821671843528748
step: 510, loss: 0.2141730785369873
step: 520, loss: 0.10715042799711227
step: 530, loss: 0.04612992703914642
step: 540, loss: 0.1794300079345703
step: 550, loss: 0.1732904613018036
step: 560, loss: 0.20704448223114014
step: 570, loss: 0.08898269385099411
step: 580, loss: 0.188328355550766
step: 590, loss: 0.12124552577733994
step: 600, loss: 0.07858797907829285
step: 610, loss: 0.14064966142177582
step: 620, loss: 0.18199704587459564
step: 630, loss: 0.13783757388591766
step: 640, loss: 0.18409869074821472
step: 650, loss: 0.12017414718866348
step: 660, loss: 0.15188704431056976
step: 670, loss: 0.11985079199075699
step: 680, loss: 0.09712602198123932
step: 690, loss: 0.11692091822624207
step: 700, loss: 0.14879459142684937
step: 710, loss: 0.07516279816627502
step: 720, loss: 0.13929472863674164
step: 730, loss: 0.07888045907020569
step: 740, loss: 0.138310506939888
step: 750, loss: 0.11642836779356003
step: 760, loss: 0.07888760417699814
step: 770, loss: 0.0714680477976799
step: 780, loss: 0.11716899275779724
step: 790, loss: 0.13123895227909088
step: 800, loss: 0.17869532108306885
step: 810, loss: 0.25218528509140015
step: 820, loss: 0.07525824010372162
step: 830, loss: 0.0712403729557991
step: 840, loss: 0.06732133030891418
step: 850, loss: 0.06870321929454803
step: 860, loss: 0.07721639424562454
step: 870, loss: 0.15673941373825073
step: 880, loss: 0.16559477150440216
step: 890, loss: 0.0987565666437149
step: 900, loss: 0.2014349102973938
step: 910, loss: 0.04760880768299103
step: 920, loss: 0.17622146010398865
step: 930, loss: 0.2230534702539444
step: 940, loss: 0.115876205265522
step: 950, loss: 0.08908949792385101
step: 960, loss: 0.058481838554143906
step: 970, loss: 0.1977941244840622
epoch 3: dev_f1=0.9220246238030095, f1=0.9172382258802013, best_f1=0.9172382258802013
step: 0, loss: 0.18992216885089874
step: 10, loss: 0.1585140824317932
step: 20, loss: 0.08696339279413223
step: 30, loss: 0.048838745802640915
step: 40, loss: 0.1035313606262207
step: 50, loss: 0.2720494270324707
step: 60, loss: 0.07753845304250717
step: 70, loss: 0.10066480189561844
step: 80, loss: 0.10099215060472488
step: 90, loss: 0.15123958885669708
step: 100, loss: 0.12146922200918198
step: 110, loss: 0.0242388304322958
step: 120, loss: 0.10121587663888931
step: 130, loss: 0.10240069776773453
step: 140, loss: 0.12670044600963593
step: 150, loss: 0.10139995813369751
step: 160, loss: 0.13034799695014954
step: 170, loss: 0.05282898619771004
step: 180, loss: 0.021793419495224953
step: 190, loss: 0.07778163254261017
step: 200, loss: 0.062470320612192154
step: 210, loss: 0.06451862305402756
step: 220, loss: 0.06576792895793915
step: 230, loss: 0.09083619713783264
step: 240, loss: 0.11950016021728516
step: 250, loss: 0.263084352016449
step: 260, loss: 0.10305465012788773
step: 270, loss: 0.08763943612575531
step: 280, loss: 0.11293354630470276
step: 290, loss: 0.1701471507549286
step: 300, loss: 0.14940734207630157
step: 310, loss: 0.029965151101350784
step: 320, loss: 0.14888720214366913
step: 330, loss: 0.0806846022605896
step: 340, loss: 0.19385989010334015
step: 350, loss: 0.14910076558589935
step: 360, loss: 0.0402849055826664
step: 370, loss: 0.18598471581935883
step: 380, loss: 0.07530418783426285
step: 390, loss: 0.12108272314071655
step: 400, loss: 0.05439934879541397
step: 410, loss: 0.09866812080144882
step: 420, loss: 0.009418603964149952
step: 430, loss: 0.09157164394855499
step: 440, loss: 0.09066951274871826
step: 450, loss: 0.08091487735509872
step: 460, loss: 0.19994795322418213
step: 470, loss: 0.058214448392391205
step: 480, loss: 0.06353875249624252
step: 490, loss: 0.11957672983407974
step: 500, loss: 0.0531424917280674
step: 510, loss: 0.07339118421077728
step: 520, loss: 0.05368689447641373
step: 530, loss: 0.18749390542507172
step: 540, loss: 0.13704341650009155
step: 550, loss: 0.06575778871774673
step: 560, loss: 0.308374285697937
step: 570, loss: 0.11398429423570633
step: 580, loss: 0.0924634262919426
step: 590, loss: 0.10065974295139313
step: 600, loss: 0.10624673962593079
step: 610, loss: 0.13303358852863312
step: 620, loss: 0.11766807734966278
step: 630, loss: 0.11968811601400375
step: 640, loss: 0.11510687321424484
step: 650, loss: 0.18841394782066345
step: 660, loss: 0.09431061893701553
step: 670, loss: 0.1164141520857811
step: 680, loss: 0.11137761175632477
step: 690, loss: 0.054000552743673325
step: 700, loss: 0.10690193623304367
step: 710, loss: 0.21874922513961792
step: 720, loss: 0.16554677486419678
step: 730, loss: 0.07412813603878021
step: 740, loss: 0.11709792912006378
step: 750, loss: 0.19828006625175476
step: 760, loss: 0.06253667175769806
step: 770, loss: 0.12335741519927979
step: 780, loss: 0.13145916163921356
step: 790, loss: 0.06892850995063782
step: 800, loss: 0.09258441627025604
step: 810, loss: 0.08606703579425812
step: 820, loss: 0.09999706596136093
step: 830, loss: 0.04102412611246109
step: 840, loss: 0.20185041427612305
step: 850, loss: 0.1471155881881714
step: 860, loss: 0.06515581160783768
step: 870, loss: 0.2079964429140091
step: 880, loss: 0.11647728085517883
step: 890, loss: 0.14758311212062836
step: 900, loss: 0.05493539944291115
step: 910, loss: 0.12233936786651611
step: 920, loss: 0.12943613529205322
step: 930, loss: 0.013129381462931633
step: 940, loss: 0.08223906904459
step: 950, loss: 0.10146962851285934
step: 960, loss: 0.12868483364582062
step: 970, loss: 0.10399753600358963
epoch 4: dev_f1=0.9262865090403337, f1=0.9288702928870293, best_f1=0.9288702928870293
step: 0, loss: 0.10962117463350296
step: 10, loss: 0.06825029850006104
step: 20, loss: 0.17531800270080566
step: 30, loss: 0.1260286420583725
step: 40, loss: 0.08242364227771759
step: 50, loss: 0.06319166719913483
step: 60, loss: 0.11204057186841965
step: 70, loss: 0.011049818247556686
step: 80, loss: 0.1696070432662964
step: 90, loss: 0.027744971215724945
step: 100, loss: 0.07840494811534882
step: 110, loss: 0.08054514974355698
step: 120, loss: 0.12103215605020523
step: 130, loss: 0.1058751791715622
step: 140, loss: 0.08686719834804535
step: 150, loss: 0.11064577102661133
step: 160, loss: 0.10386167466640472
step: 170, loss: 0.010442117229104042
step: 180, loss: 0.16062194108963013
step: 190, loss: 0.10875099152326584
step: 200, loss: 0.10375485569238663
step: 210, loss: 0.062015652656555176
step: 220, loss: 0.12559914588928223
step: 230, loss: 0.03751358762383461
step: 240, loss: 0.13491290807724
step: 250, loss: 0.11387957632541656
step: 260, loss: 0.03794781118631363
step: 270, loss: 0.06912249326705933
step: 280, loss: 0.10746096819639206
step: 290, loss: 0.1952083855867386
step: 300, loss: 0.1821473389863968
step: 310, loss: 0.03348861262202263
step: 320, loss: 0.06990913301706314
step: 330, loss: 0.051978956907987595
step: 340, loss: 0.05950230732560158
step: 350, loss: 0.08709731698036194
step: 360, loss: 0.03365436941385269
step: 370, loss: 0.054098084568977356
step: 380, loss: 0.09488561749458313
step: 390, loss: 0.06998668611049652
step: 400, loss: 0.14998233318328857
step: 410, loss: 0.13073109090328217
step: 420, loss: 0.12030801177024841
step: 430, loss: 0.14988267421722412
step: 440, loss: 0.10494212806224823
step: 450, loss: 0.010361908935010433
step: 460, loss: 0.06487756967544556
step: 470, loss: 0.06886844336986542
step: 480, loss: 0.16632840037345886
step: 490, loss: 0.030069628730416298
step: 500, loss: 0.06062691658735275
step: 510, loss: 0.12568382918834686
step: 520, loss: 0.054069049656391144
step: 530, loss: 0.026627637445926666
step: 540, loss: 0.10808724164962769
step: 550, loss: 0.14617758989334106
step: 560, loss: 0.0912892073392868
step: 570, loss: 0.08625178039073944
step: 580, loss: 0.0514758825302124
step: 590, loss: 0.15334771573543549
step: 600, loss: 0.1524946391582489
step: 610, loss: 0.1098882257938385
step: 620, loss: 0.1762087345123291
step: 630, loss: 0.03625684976577759
step: 640, loss: 0.16555185616016388
step: 650, loss: 0.1109146773815155
step: 660, loss: 0.03327736631035805
step: 670, loss: 0.16641879081726074
step: 680, loss: 0.09391029924154282
step: 690, loss: 0.17397823929786682
step: 700, loss: 0.03645947948098183
step: 710, loss: 0.09362953901290894
step: 720, loss: 0.1582498550415039
step: 730, loss: 0.10276679694652557
step: 740, loss: 0.1660667359828949
step: 750, loss: 0.07621224969625473
step: 760, loss: 0.08442573249340057
step: 770, loss: 0.13089331984519958
step: 780, loss: 0.11902233958244324
step: 790, loss: 0.0196291022002697
step: 800, loss: 0.11996269971132278
step: 810, loss: 0.10737549513578415
step: 820, loss: 0.18737247586250305
step: 830, loss: 0.030037790536880493
step: 840, loss: 0.10422538965940475
step: 850, loss: 0.10625933110713959
step: 860, loss: 0.15871843695640564
step: 870, loss: 0.07109592109918594
step: 880, loss: 0.21281881630420685
step: 890, loss: 0.08142119646072388
step: 900, loss: 0.061484064906835556
step: 910, loss: 0.14687149226665497
step: 920, loss: 0.13091208040714264
step: 930, loss: 0.047242581844329834
step: 940, loss: 0.09253165870904922
step: 950, loss: 0.06785310059785843
step: 960, loss: 0.1406301110982895
step: 970, loss: 0.06289985775947571
epoch 5: dev_f1=0.9353958143767062, f1=0.9347234814143245, best_f1=0.9347234814143245
step: 0, loss: 0.17520809173583984
step: 10, loss: 0.1763264387845993
step: 20, loss: 0.10798204690217972
step: 30, loss: 0.05206425115466118
step: 40, loss: 0.06761683523654938
step: 50, loss: 0.09544587135314941
step: 60, loss: 0.13226868212223053
step: 70, loss: 0.06987810134887695
step: 80, loss: 0.022138409316539764
step: 90, loss: 0.07698766887187958
step: 100, loss: 0.11158961802721024
step: 110, loss: 0.14089810848236084
step: 120, loss: 0.13696882128715515
step: 130, loss: 0.08087795227766037
step: 140, loss: 0.07478035241365433
step: 150, loss: 0.09167805314064026
step: 160, loss: 0.12695643305778503
step: 170, loss: 0.07538355886936188
step: 180, loss: 0.1017073467373848
step: 190, loss: 0.045639943331480026
step: 200, loss: 0.01251329854130745
step: 210, loss: 0.143596351146698
step: 220, loss: 0.12819284200668335
step: 230, loss: 0.14324747025966644
step: 240, loss: 0.05253247171640396
step: 250, loss: 0.1439749002456665
step: 260, loss: 0.14456090331077576
step: 270, loss: 0.03280755132436752
step: 280, loss: 0.09205872565507889
step: 290, loss: 0.03511137142777443
step: 300, loss: 0.051276348531246185
step: 310, loss: 0.10090933740139008
step: 320, loss: 0.051595594733953476
step: 330, loss: 0.1584402322769165
step: 340, loss: 0.06812172383069992
step: 350, loss: 0.08999326825141907
step: 360, loss: 0.09671337157487869
step: 370, loss: 0.08442405611276627
step: 380, loss: 0.03276479244232178
step: 390, loss: 0.07202418893575668
step: 400, loss: 0.06445086002349854
step: 410, loss: 0.10680907964706421
step: 420, loss: 0.08058109879493713
step: 430, loss: 0.035817090421915054
step: 440, loss: 0.08524087071418762
step: 450, loss: 0.008518197573721409
step: 460, loss: 0.16665396094322205
step: 470, loss: 0.0657198429107666
step: 480, loss: 0.08909891545772552
step: 490, loss: 0.12030670046806335
step: 500, loss: 0.13581331074237823
step: 510, loss: 0.016198260709643364
step: 520, loss: 0.1496463418006897
step: 530, loss: 0.02266526222229004
step: 540, loss: 0.05943041667342186
step: 550, loss: 0.04345767945051193
step: 560, loss: 0.019631866365671158
step: 570, loss: 0.0804651528596878
step: 580, loss: 0.1712770313024521
step: 590, loss: 0.19708438217639923
step: 600, loss: 0.10444924235343933
step: 610, loss: 0.012162232771515846
step: 620, loss: 0.18197867274284363
step: 630, loss: 0.2849028408527374
step: 640, loss: 0.05783573165535927
step: 650, loss: 0.0933585911989212
step: 660, loss: 0.08437558263540268
step: 670, loss: 0.07937127351760864
step: 680, loss: 0.15581566095352173
step: 690, loss: 0.13762110471725464
step: 700, loss: 0.10020764172077179
step: 710, loss: 0.08960101753473282
step: 720, loss: 0.037411876022815704
step: 730, loss: 0.1131070926785469
step: 740, loss: 0.01545898150652647
step: 750, loss: 0.13695253431797028
step: 760, loss: 0.10257988423109055
step: 770, loss: 0.09901505708694458
step: 780, loss: 0.13234123587608337
step: 790, loss: 0.08811461925506592
step: 800, loss: 0.12016989290714264
step: 810, loss: 0.11539778858423233
step: 820, loss: 0.17346511781215668
step: 830, loss: 0.14464832842350006
step: 840, loss: 0.10391552746295929
step: 850, loss: 0.15894243121147156
step: 860, loss: 0.13287384808063507
step: 870, loss: 0.14020098745822906
step: 880, loss: 0.08771438151597977
step: 890, loss: 0.04715345799922943
step: 900, loss: 0.21917390823364258
step: 910, loss: 0.06362693756818771
step: 920, loss: 0.27997997403144836
step: 930, loss: 0.0554678775370121
step: 940, loss: 0.3846956789493561
step: 950, loss: 0.10721985995769501
step: 960, loss: 0.08422248065471649
step: 970, loss: 0.04451867565512657
epoch 6: dev_f1=0.923076923076923, f1=0.9250693802035153, best_f1=0.9347234814143245
step: 0, loss: 0.047048620879650116
step: 10, loss: 0.05739567056298256
step: 20, loss: 0.16365157067775726
step: 30, loss: 0.011000017635524273
step: 40, loss: 0.11296416074037552
step: 50, loss: 0.026303742080926895
step: 60, loss: 0.11964166164398193
step: 70, loss: 0.09571447223424911
step: 80, loss: 0.09580536931753159
step: 90, loss: 0.2270895540714264
step: 100, loss: 0.01504791434854269
step: 110, loss: 0.07796413451433182
step: 120, loss: 0.10067864507436752
step: 130, loss: 0.036918215453624725
step: 140, loss: 0.10200486332178116
step: 150, loss: 0.11746210604906082
step: 160, loss: 0.06478951871395111
step: 170, loss: 0.05465451255440712
step: 180, loss: 0.11442568153142929
step: 190, loss: 0.1397498995065689
step: 200, loss: 0.10133256018161774
step: 210, loss: 0.09091735631227493
step: 220, loss: 0.047820091247558594
step: 230, loss: 0.14583760499954224
step: 240, loss: 0.14240115880966187
step: 250, loss: 0.09987958520650864
step: 260, loss: 0.07196157425642014
step: 270, loss: 0.17745842039585114
step: 280, loss: 0.06008249148726463
step: 290, loss: 0.12857353687286377
step: 300, loss: 0.036371465772390366
step: 310, loss: 0.10524500906467438
step: 320, loss: 0.06917798519134521
step: 330, loss: 0.06835553795099258
step: 340, loss: 0.04287126660346985
step: 350, loss: 0.07421717792749405
step: 360, loss: 0.25744837522506714
step: 370, loss: 0.04900776594877243
step: 380, loss: 0.16819149255752563
step: 390, loss: 0.08215497434139252
step: 400, loss: 0.23058640956878662
step: 410, loss: 0.04383267089724541
step: 420, loss: 0.10179378092288971
step: 430, loss: 0.037373241037130356
step: 440, loss: 0.0013658353127539158
step: 450, loss: 0.029811913147568703
step: 460, loss: 0.14009997248649597
step: 470, loss: 0.13013820350170135
step: 480, loss: 0.04801555722951889
step: 490, loss: 0.14996173977851868
step: 500, loss: 0.08218115568161011
step: 510, loss: 0.08868333697319031
step: 520, loss: 0.01110988948494196
step: 530, loss: 0.06533510237932205
step: 540, loss: 0.17642362415790558
step: 550, loss: 0.1756177395582199
step: 560, loss: 0.08047191798686981
step: 570, loss: 0.1982853263616562
step: 580, loss: 0.05442361533641815
step: 590, loss: 0.08059175312519073
step: 600, loss: 0.22605450451374054
step: 610, loss: 0.09830950200557709
step: 620, loss: 0.104499451816082
step: 630, loss: 0.10058664530515671
step: 640, loss: 0.02933414652943611
step: 650, loss: 0.0818130224943161
step: 660, loss: 0.0643765851855278
step: 670, loss: 0.09688018262386322
step: 680, loss: 0.05468033254146576
step: 690, loss: 0.0934407189488411
step: 700, loss: 0.09650199115276337
step: 710, loss: 0.05335533246397972
step: 720, loss: 0.13353212177753448
step: 730, loss: 0.0847737193107605
step: 740, loss: 0.03063172847032547
step: 750, loss: 0.15226301550865173
step: 760, loss: 0.10643725842237473
step: 770, loss: 0.1630403697490692
step: 780, loss: 0.10623987019062042
step: 790, loss: 0.06348609924316406
step: 800, loss: 0.13858236372470856
step: 810, loss: 0.22576993703842163
step: 820, loss: 0.14966681599617004
step: 830, loss: 0.030935943126678467
step: 840, loss: 0.10658065229654312
step: 850, loss: 0.08482706546783447
step: 860, loss: 0.06402906775474548
step: 870, loss: 0.10215535759925842
step: 880, loss: 0.1435626596212387
step: 890, loss: 0.12776495516300201
step: 900, loss: 0.14781151711940765
step: 910, loss: 0.06592459231615067
step: 920, loss: 0.3199995458126068
step: 930, loss: 0.17970821261405945
step: 940, loss: 0.10972446948289871
step: 950, loss: 0.11986324936151505
step: 960, loss: 0.09976956248283386
step: 970, loss: 0.09569856524467468
epoch 7: dev_f1=0.9256661991584852, f1=0.923005132991134, best_f1=0.9347234814143245
step: 0, loss: 0.02580297365784645
step: 10, loss: 0.11594335734844208
step: 20, loss: 0.12670260667800903
step: 30, loss: 0.05001765489578247
step: 40, loss: 0.033992890268564224
step: 50, loss: 0.19213633239269257
step: 60, loss: 0.06980182230472565
step: 70, loss: 0.1076028048992157
step: 80, loss: 0.15052756667137146
step: 90, loss: 0.06979788094758987
step: 100, loss: 0.04938684031367302
step: 110, loss: 0.16585583984851837
step: 120, loss: 0.11533812433481216
step: 130, loss: 0.12976275384426117
step: 140, loss: 0.021882589906454086
step: 150, loss: 0.0409696139395237
step: 160, loss: 0.044120024889707565
step: 170, loss: 0.04797593131661415
step: 180, loss: 0.08343145996332169
step: 190, loss: 0.08213309943675995
step: 200, loss: 0.19456835091114044
step: 210, loss: 0.08775205165147781
step: 220, loss: 0.10847389698028564
step: 230, loss: 0.14302851259708405
step: 240, loss: 0.08556441217660904
step: 250, loss: 0.11219742894172668
step: 260, loss: 0.008420062251389027
step: 270, loss: 0.0737839788198471
step: 280, loss: 0.12760400772094727
step: 290, loss: 0.19894906878471375
step: 300, loss: 0.06884831935167313
step: 310, loss: 0.14844602346420288
step: 320, loss: 0.17622479796409607
step: 330, loss: 0.15288609266281128
step: 340, loss: 0.11029098927974701
step: 350, loss: 0.08204754441976547
step: 360, loss: 0.1585976630449295
step: 370, loss: 0.08253288269042969
step: 380, loss: 0.06465858966112137
step: 390, loss: 0.07771103084087372
step: 400, loss: 0.028067948296666145
step: 410, loss: 0.028383061289787292
step: 420, loss: 0.13928797841072083
step: 430, loss: 0.057849302887916565
step: 440, loss: 0.03391604498028755
step: 450, loss: 0.16171786189079285
step: 460, loss: 0.11701542139053345
step: 470, loss: 0.17040608823299408
step: 480, loss: 0.11281540989875793
step: 490, loss: 0.09523840248584747
step: 500, loss: 0.06543855369091034
step: 510, loss: 0.14675436913967133
step: 520, loss: 0.04085986316204071
step: 530, loss: 0.10198899358510971
step: 540, loss: 0.14178794622421265
step: 550, loss: 0.17049965262413025
step: 560, loss: 0.14185775816440582
step: 570, loss: 0.013934226706624031
step: 580, loss: 0.030559347942471504
step: 590, loss: 0.034242451190948486
step: 600, loss: 0.06322726607322693
step: 610, loss: 0.1210857704281807
step: 620, loss: 0.16314385831356049
step: 630, loss: 0.015881070867180824
step: 640, loss: 0.023460576310753822
step: 650, loss: 0.24121877551078796
step: 660, loss: 0.12905538082122803
step: 670, loss: 0.02849729359149933
step: 680, loss: 0.14479559659957886
step: 690, loss: 0.12450461834669113
step: 700, loss: 0.12306962162256241
step: 710, loss: 0.1484939306974411
step: 720, loss: 0.11916079372167587
step: 730, loss: 0.08480197191238403
step: 740, loss: 0.10073097795248032
step: 750, loss: 0.15386037528514862
step: 760, loss: 0.1392214596271515
step: 770, loss: 0.09859288483858109
step: 780, loss: 0.06681334972381592
step: 790, loss: 0.08774341642856598
step: 800, loss: 0.07461357861757278
step: 810, loss: 0.0653700977563858
step: 820, loss: 0.12938833236694336
step: 830, loss: 0.040257733315229416
step: 840, loss: 0.08025041222572327
step: 850, loss: 0.1053781807422638
step: 860, loss: 0.16816702485084534
step: 870, loss: 0.1716260015964508
step: 880, loss: 0.04937262088060379
step: 890, loss: 0.055954575538635254
step: 900, loss: 0.06723902374505997
step: 910, loss: 0.0917619839310646
step: 920, loss: 0.11230126768350601
step: 930, loss: 0.09770803898572922
step: 940, loss: 0.13337858021259308
step: 950, loss: 0.05071732774376869
step: 960, loss: 0.1195090264081955
step: 970, loss: 0.05885296314954758
epoch 8: dev_f1=0.9316200091785223, f1=0.9316712834718375, best_f1=0.9347234814143245
step: 0, loss: 0.05590231716632843
step: 10, loss: 0.10127750784158707
step: 20, loss: 0.11871633678674698
step: 30, loss: 0.07651276141405106
step: 40, loss: 0.03978124260902405
step: 50, loss: 0.04120404273271561
step: 60, loss: 0.11258698999881744
step: 70, loss: 0.12447110563516617
step: 80, loss: 0.04547363519668579
step: 90, loss: 0.09795394539833069
step: 100, loss: 0.2159697264432907
step: 110, loss: 0.10575489699840546
step: 120, loss: 0.07220233976840973
step: 130, loss: 3.0448369216173887e-05
step: 140, loss: 0.0704490914940834
step: 150, loss: 0.16380323469638824
step: 160, loss: 0.14506232738494873
step: 170, loss: 0.05290512368083
step: 180, loss: 0.1453261375427246
step: 190, loss: 0.08743955194950104
step: 200, loss: 0.08167040348052979
step: 210, loss: 0.16195090115070343
step: 220, loss: 0.10325878858566284
step: 230, loss: 0.0431109257042408
step: 240, loss: 0.06394194811582565
step: 250, loss: 0.06758483499288559
step: 260, loss: 0.10354214161634445
step: 270, loss: 0.010425252839922905
step: 280, loss: 0.17852096259593964
step: 290, loss: 0.02772260084748268
step: 300, loss: 0.06401295214891434
step: 310, loss: 0.16517183184623718
step: 320, loss: 0.18053580820560455
step: 330, loss: 0.133919820189476
step: 340, loss: 0.06027650833129883
step: 350, loss: 0.009413039311766624
step: 360, loss: 0.11290740966796875
step: 370, loss: 0.06656289845705032
step: 380, loss: 0.09171101450920105
step: 390, loss: 0.04451737180352211
step: 400, loss: 0.22498100996017456
step: 410, loss: 0.08619094640016556
step: 420, loss: 0.07751550525426865
step: 430, loss: 0.11145712435245514
step: 440, loss: 0.12732097506523132
step: 450, loss: 0.05591922998428345
step: 460, loss: 0.13061857223510742
step: 470, loss: 0.09527744352817535
step: 480, loss: 0.08293745666742325
step: 490, loss: 0.03125523775815964
step: 500, loss: 0.06590621918439865
step: 510, loss: 0.10822034627199173
step: 520, loss: 0.20511603355407715
step: 530, loss: 0.0861315056681633
step: 540, loss: 0.20149527490139008
step: 550, loss: 0.05851927399635315
step: 560, loss: 0.1179918572306633
step: 570, loss: 0.21318134665489197
step: 580, loss: 0.12479227781295776
step: 590, loss: 0.16426189243793488
step: 600, loss: 0.05578005686402321
step: 610, loss: 0.09829692542552948
step: 620, loss: 0.03163078427314758
step: 630, loss: 0.0015523020410910249
step: 640, loss: 0.08073703199625015
step: 650, loss: 0.026667872443795204
step: 660, loss: 0.029374154284596443
step: 670, loss: 0.12419004738330841
step: 680, loss: 0.030751166865229607
step: 690, loss: 0.032869257032871246
step: 700, loss: 0.0901312530040741
step: 710, loss: 0.16792970895767212
step: 720, loss: 0.0633171871304512
step: 730, loss: 0.03794756159186363
step: 740, loss: 0.013929177075624466
step: 750, loss: 0.002836785977706313
step: 760, loss: 0.04546934366226196
step: 770, loss: 0.10994664579629898
step: 780, loss: 0.0960250273346901
step: 790, loss: 0.05945579335093498
step: 800, loss: 0.11341379582881927
step: 810, loss: 0.16402193903923035
step: 820, loss: 0.14742989838123322
step: 830, loss: 0.2170698195695877
step: 840, loss: 0.07117107510566711
step: 850, loss: 0.04030298814177513
step: 860, loss: 0.08989670127630234
step: 870, loss: 0.06662461906671524
step: 880, loss: 0.10641520470380783
step: 890, loss: 0.04477737471461296
step: 900, loss: 0.1443175971508026
step: 910, loss: 0.06727413833141327
step: 920, loss: 0.061116088181734085
step: 930, loss: 0.11996765434741974
step: 940, loss: 0.09534431993961334
step: 950, loss: 0.1807927042245865
step: 960, loss: 0.15561436116695404
step: 970, loss: 0.11419077962636948
epoch 9: dev_f1=0.9288040949278734, f1=0.9233627496516488, best_f1=0.9347234814143245
step: 0, loss: 0.12100060284137726
step: 10, loss: 0.06596233695745468
step: 20, loss: 0.09295931458473206
step: 30, loss: 0.017138954252004623
step: 40, loss: 0.12470421940088272
step: 50, loss: 0.018379375338554382
step: 60, loss: 0.1654595285654068
step: 70, loss: 0.04042741656303406
step: 80, loss: 0.05300720036029816
step: 90, loss: 0.13453803956508636
step: 100, loss: 0.08908446133136749
step: 110, loss: 0.07960300147533417
step: 120, loss: 0.13115163147449493
step: 130, loss: 0.0664200633764267
step: 140, loss: 0.03407807648181915
step: 150, loss: 0.14321237802505493
step: 160, loss: 0.014895432628691196
step: 170, loss: 0.08661030977964401
step: 180, loss: 0.08397763222455978
step: 190, loss: 0.01896647736430168
step: 200, loss: 0.06595861911773682
step: 210, loss: 0.19463463127613068
step: 220, loss: 0.13648991286754608
step: 230, loss: 0.06306594610214233
step: 240, loss: 0.09351075440645218
step: 250, loss: 0.06533466279506683
step: 260, loss: 0.1064804345369339
step: 270, loss: 0.13222482800483704
step: 280, loss: 0.2369164228439331
step: 290, loss: 0.004436553455889225
step: 300, loss: 0.10033440589904785
step: 310, loss: 0.12835612893104553
step: 320, loss: 0.1499694436788559
step: 330, loss: 0.02453281171619892
step: 340, loss: 0.07675919681787491
step: 350, loss: 0.08188991993665695
step: 360, loss: 0.16927212476730347
step: 370, loss: 0.14309988915920258
step: 380, loss: 0.14143402874469757
step: 390, loss: 0.022798266261816025
step: 400, loss: 0.1225542277097702
step: 410, loss: 0.05344946309924126
step: 420, loss: 0.08647526055574417
step: 430, loss: 0.07843051850795746
step: 440, loss: 0.09196588397026062
step: 450, loss: 0.015488635748624802
step: 460, loss: 0.010855020955204964
step: 470, loss: 0.049956291913986206
step: 480, loss: 0.056398071348667145
step: 490, loss: 0.1234499141573906
step: 500, loss: 0.12091641128063202
step: 510, loss: 0.12406488507986069
step: 520, loss: 0.00438274722546339
step: 530, loss: 0.0777825117111206
step: 540, loss: 0.08053293079137802
step: 550, loss: 0.16649115085601807
step: 560, loss: 0.07050471752882004
step: 570, loss: 0.15953774750232697
step: 580, loss: 0.06674258410930634
step: 590, loss: 0.1070881262421608
step: 600, loss: 0.056978240609169006
step: 610, loss: 0.007631322834640741
step: 620, loss: 0.04294668883085251
step: 630, loss: 0.05207148566842079
step: 640, loss: 0.12484688311815262
step: 650, loss: 0.13227179646492004
step: 660, loss: 0.059906311333179474
step: 670, loss: 0.03972909227013588
step: 680, loss: 0.09563387930393219
step: 690, loss: 0.024671148508787155
step: 700, loss: 0.07896260172128677
step: 710, loss: 0.08236873149871826
step: 720, loss: 0.18816101551055908
step: 730, loss: 0.1280512660741806
step: 740, loss: 0.07150587439537048
step: 750, loss: 0.06789084523916245
step: 760, loss: 0.08819881826639175
step: 770, loss: 0.08823318034410477
step: 780, loss: 0.027270834892988205
step: 790, loss: 0.02652638778090477
step: 800, loss: 0.10280266404151917
step: 810, loss: 0.16143716871738434
step: 820, loss: 0.04746054857969284
step: 830, loss: 0.11448736488819122
step: 840, loss: 0.08923380821943283
step: 850, loss: 0.17677125334739685
step: 860, loss: 0.09717266261577606
step: 870, loss: 0.11133655905723572
step: 880, loss: 0.04276207089424133
step: 890, loss: 0.020096689462661743
step: 900, loss: 0.04338448867201805
step: 910, loss: 0.08097989857196808
step: 920, loss: 0.07093052566051483
step: 930, loss: 0.12349126487970352
step: 940, loss: 0.14924447238445282
step: 950, loss: 0.051564618945121765
step: 960, loss: 0.029286818578839302
step: 970, loss: 0.01820533536374569
epoch 10: dev_f1=0.9282777523983554, f1=0.9213993639254885, best_f1=0.9347234814143245
step: 0, loss: 0.06799118220806122
step: 10, loss: 0.11632438749074936
step: 20, loss: 0.04152338579297066
step: 30, loss: 0.07742506265640259
step: 40, loss: 0.06447993963956833
step: 50, loss: 0.1343454122543335
step: 60, loss: 0.09884248673915863
step: 70, loss: 0.03045397251844406
step: 80, loss: 0.004167239647358656
step: 90, loss: 0.1306108683347702
step: 100, loss: 0.09061630815267563
step: 110, loss: 0.0644759088754654
step: 120, loss: 0.17671069502830505
step: 130, loss: 0.1023818850517273
step: 140, loss: 0.14635537564754486
step: 150, loss: 0.08651896566152573
step: 160, loss: 0.06713256239891052
step: 170, loss: 0.1961577832698822
step: 180, loss: 0.0782349482178688
step: 190, loss: 0.09515508264303207
step: 200, loss: 0.037725985050201416
step: 210, loss: 0.13428515195846558
step: 220, loss: 0.07873442769050598
step: 230, loss: 0.07142072170972824
step: 240, loss: 0.08568732440471649
step: 250, loss: 0.057516008615493774
step: 260, loss: 0.0411367267370224
step: 270, loss: 0.062193773686885834
step: 280, loss: 0.07059831917285919
step: 290, loss: 0.0802239403128624
step: 300, loss: 0.035192180424928665
step: 310, loss: 0.038301218301057816
step: 320, loss: 0.08156219869852066
step: 330, loss: 0.13526786863803864
step: 340, loss: 0.028515195474028587
step: 350, loss: 0.09902689605951309
step: 360, loss: 0.03884349390864372
step: 370, loss: 0.13750994205474854
step: 380, loss: 0.1925298273563385
step: 390, loss: 0.1561477780342102
step: 400, loss: 0.0740857794880867
step: 410, loss: 0.09336215257644653
step: 420, loss: 0.02036334201693535
step: 430, loss: 0.08921803534030914
step: 440, loss: 0.06413039565086365
step: 450, loss: 0.06820915639400482
step: 460, loss: 0.08587756752967834
step: 470, loss: 0.02099628560245037
step: 480, loss: 0.07897241413593292
step: 490, loss: 0.08292138576507568
step: 500, loss: 0.09948132932186127
step: 510, loss: 0.12034575641155243
step: 520, loss: 0.0847763791680336
step: 530, loss: 0.1077418178319931
step: 540, loss: 0.12870219349861145
step: 550, loss: 0.21256214380264282
step: 560, loss: 0.09962381422519684
step: 570, loss: 0.08306248486042023
step: 580, loss: 0.09833862632513046
step: 590, loss: 0.07525069266557693
step: 600, loss: 0.013621143996715546
step: 610, loss: 0.059336334466934204
step: 620, loss: 0.04716353118419647
step: 630, loss: 0.0832529366016388
step: 640, loss: 0.0803280845284462
step: 650, loss: 0.06480316072702408
step: 660, loss: 0.03234764188528061
step: 670, loss: 0.0572509691119194
step: 680, loss: 0.11236488819122314
step: 690, loss: 0.09947402030229568
step: 700, loss: 0.06140894070267677
step: 710, loss: 0.11552279442548752
step: 720, loss: 0.04542607441544533
step: 730, loss: 0.13860826194286346
step: 740, loss: 0.041042111814022064
step: 750, loss: 8.467383304378018e-05
step: 760, loss: 0.0667138397693634
step: 770, loss: 0.04383484646677971
step: 780, loss: 0.06739354878664017
step: 790, loss: 0.19890731573104858
step: 800, loss: 0.09065661579370499
step: 810, loss: 0.007600196171551943
step: 820, loss: 0.03340621292591095
step: 830, loss: 0.11408915370702744
step: 840, loss: 0.10102719813585281
step: 850, loss: 0.03930937498807907
step: 860, loss: 0.030063064768910408
step: 870, loss: 0.08154387772083282
step: 880, loss: 0.07004185765981674
step: 890, loss: 0.14925068616867065
step: 900, loss: 0.06683777272701263
step: 910, loss: 0.0762995257973671
step: 920, loss: 0.09103807806968689
step: 930, loss: 0.0897136703133583
step: 940, loss: 0.12492619454860687
step: 950, loss: 0.005489125847816467
step: 960, loss: 0.08703695237636566
step: 970, loss: 0.08729638904333115
epoch 11: dev_f1=0.9362880886426593, f1=0.9285051067780873, best_f1=0.9285051067780873
step: 0, loss: 0.06469301134347916
step: 10, loss: 0.06266064196825027
step: 20, loss: 0.10775569081306458
step: 30, loss: 9.540275641484186e-05
step: 40, loss: 0.11242686212062836
step: 50, loss: 0.021063484251499176
step: 60, loss: 0.03419365733861923
step: 70, loss: 0.09159412980079651
step: 80, loss: 0.044376272708177567
step: 90, loss: 0.09161762148141861
step: 100, loss: 0.05898843705654144
step: 110, loss: 0.05655064433813095
step: 120, loss: 0.10835902392864227
step: 130, loss: 0.08909858763217926
step: 140, loss: 0.012631876394152641
step: 150, loss: 0.06338968873023987
step: 160, loss: 0.08380692452192307
step: 170, loss: 0.03405837342143059
step: 180, loss: 0.017205704003572464
step: 190, loss: 0.07391920685768127
step: 200, loss: 0.15788641571998596
step: 210, loss: 0.0030651346314698458
step: 220, loss: 0.06294063478708267
step: 230, loss: 0.1116257905960083
step: 240, loss: 0.04884190112352371
step: 250, loss: 0.0769866555929184
step: 260, loss: 0.04846680164337158
step: 270, loss: 0.036449067294597626
step: 280, loss: 0.22846755385398865
step: 290, loss: 0.020457850769162178
step: 300, loss: 0.032920051366090775
step: 310, loss: 0.09965181350708008
step: 320, loss: 0.02145327627658844
step: 330, loss: 0.03925299271941185
step: 340, loss: 0.026560664176940918
step: 350, loss: 0.04370774328708649
step: 360, loss: 0.1159866601228714
step: 370, loss: 0.03940337151288986
step: 380, loss: 0.02626737579703331
step: 390, loss: 0.0522456057369709
step: 400, loss: 0.028902564197778702
step: 410, loss: 0.03050745464861393
step: 420, loss: 0.13509483635425568
step: 430, loss: 0.03465138375759125
step: 440, loss: 0.02547733671963215
step: 450, loss: 0.012740240432322025
step: 460, loss: 0.05731949210166931
step: 470, loss: 0.11344723403453827
step: 480, loss: 0.03826378285884857
step: 490, loss: 0.09486136585474014
step: 500, loss: 0.030921369791030884
step: 510, loss: 0.03674846887588501
step: 520, loss: 0.12500646710395813
step: 530, loss: 0.01757403090596199
step: 540, loss: 0.15391094982624054
step: 550, loss: 0.11745438724756241
step: 560, loss: 0.10017232596874237
step: 570, loss: 0.12870673835277557
step: 580, loss: 0.13854408264160156
step: 590, loss: 0.021741801872849464
step: 600, loss: 0.01371433213353157
step: 610, loss: 0.04275812953710556
step: 620, loss: 0.09835568070411682
step: 630, loss: 0.04376000165939331
step: 640, loss: 0.06270558387041092
step: 650, loss: 0.11038285493850708
step: 660, loss: 0.14235004782676697
step: 670, loss: 0.025052329525351524
step: 680, loss: 0.10821139067411423
step: 690, loss: 0.014929695054888725
step: 700, loss: 0.12595196068286896
step: 710, loss: 0.03573531657457352
step: 720, loss: 0.14741955697536469
step: 730, loss: 0.03683111071586609
step: 740, loss: 0.08427144587039948
step: 750, loss: 0.06469044834375381
step: 760, loss: 0.05989684537053108
step: 770, loss: 0.08045873045921326
step: 780, loss: 0.0668717548251152
step: 790, loss: 0.060429248958826065
step: 800, loss: 0.11588191986083984
step: 810, loss: 0.006168697029352188
step: 820, loss: 0.15627148747444153
step: 830, loss: 0.04540480673313141
step: 840, loss: 0.04785657301545143
step: 850, loss: 0.19856272637844086
step: 860, loss: 0.11266115307807922
step: 870, loss: 0.10522699356079102
step: 880, loss: 0.04000081121921539
step: 890, loss: 0.03766322880983353
step: 900, loss: 0.111305370926857
step: 910, loss: 0.12424283474683762
step: 920, loss: 0.10497962683439255
step: 930, loss: 0.028437310829758644
step: 940, loss: 0.04092312231659889
step: 950, loss: 0.08239986002445221
step: 960, loss: 0.04178205132484436
step: 970, loss: 0.011727068573236465
epoch 12: dev_f1=0.9333950046253469, f1=0.9235023041474655, best_f1=0.9285051067780873
step: 0, loss: 0.052151817828416824
step: 10, loss: 0.05966491624712944
step: 20, loss: 0.04154106602072716
step: 30, loss: 0.08007242530584335
step: 40, loss: 0.07820098847150803
step: 50, loss: 0.06793424487113953
step: 60, loss: 0.05719602108001709
step: 70, loss: 0.014886864461004734
step: 80, loss: 0.04226591810584068
step: 90, loss: 0.01637059822678566
step: 100, loss: 0.03803686425089836
step: 110, loss: 7.654844375792891e-05
step: 120, loss: 0.0890665054321289
step: 130, loss: 0.1646777242422104
step: 140, loss: 0.04977058246731758
step: 150, loss: 0.06296511739492416
step: 160, loss: 0.0450248159468174
step: 170, loss: 0.11739812791347504
step: 180, loss: 0.030667582526803017
step: 190, loss: 0.02401018515229225
step: 200, loss: 0.06766384840011597
step: 210, loss: 0.08208902925252914
step: 220, loss: 0.06441265344619751
step: 230, loss: 0.030248235911130905
step: 240, loss: 0.08071295917034149
step: 250, loss: 0.011613353155553341
step: 260, loss: 0.048811737447977066
step: 270, loss: 0.09808986634016037
step: 280, loss: 0.0687071904540062
step: 290, loss: 0.01289789192378521
step: 300, loss: 0.07956168055534363
step: 310, loss: 0.045629460364580154
step: 320, loss: 0.03959338739514351
step: 330, loss: 0.08324015885591507
step: 340, loss: 0.08052040636539459
step: 350, loss: 0.09295704960823059
step: 360, loss: 0.025728512555360794
step: 370, loss: 0.09143733978271484
step: 380, loss: 0.03625182434916496
step: 390, loss: 0.09423746913671494
step: 400, loss: 0.045933112502098083
step: 410, loss: 0.06780219078063965
step: 420, loss: 0.10856129974126816
step: 430, loss: 0.07516247779130936
step: 440, loss: 0.04998589679598808
step: 450, loss: 0.03366577625274658
step: 460, loss: 0.190360426902771
step: 470, loss: 0.07879805564880371
step: 480, loss: 0.03262004628777504
step: 490, loss: 0.054050806909799576
step: 500, loss: 0.09254487603902817
step: 510, loss: 0.009789928793907166
step: 520, loss: 0.07787510752677917
step: 530, loss: 0.08064470440149307
step: 540, loss: 0.12904520332813263
step: 550, loss: 0.10047551989555359
step: 560, loss: 0.06563164293766022
step: 570, loss: 0.0726538896560669
step: 580, loss: 0.057628121227025986
step: 590, loss: 0.04616633430123329
step: 600, loss: 0.18036632239818573
step: 610, loss: 0.14416177570819855
step: 620, loss: 0.02737458050251007
step: 630, loss: 0.03880327194929123
step: 640, loss: 0.0390438437461853
step: 650, loss: 0.06860886514186859
step: 660, loss: 0.08985207974910736
step: 670, loss: 0.06048328056931496
step: 680, loss: 0.04215478524565697
step: 690, loss: 0.0878915786743164
step: 700, loss: 0.15755610167980194
step: 710, loss: 0.0233172420412302
step: 720, loss: 0.1207365170121193
step: 730, loss: 0.07136867195367813
step: 740, loss: 0.07958008348941803
step: 750, loss: 0.11320267617702484
step: 760, loss: 0.06764589250087738
step: 770, loss: 0.06282585114240646
step: 780, loss: 0.07209552824497223
step: 790, loss: 0.03072529099881649
step: 800, loss: 0.05078965052962303
step: 810, loss: 0.10474413633346558
step: 820, loss: 0.11871735006570816
step: 830, loss: 0.05498933047056198
step: 840, loss: 0.12258848547935486
step: 850, loss: 0.12309882789850235
step: 860, loss: 0.05900510028004646
step: 870, loss: 0.16089783608913422
step: 880, loss: 0.07813633978366852
step: 890, loss: 0.08868182450532913
step: 900, loss: 0.03035644069314003
step: 910, loss: 0.06932060420513153
step: 920, loss: 0.04007703810930252
step: 930, loss: 0.043182842433452606
step: 940, loss: 0.13860653340816498
step: 950, loss: 0.12364277243614197
step: 960, loss: 0.06150059401988983
step: 970, loss: 0.09222230315208435
epoch 13: dev_f1=0.9314312011044639, f1=0.9310504396112911, best_f1=0.9285051067780873
step: 0, loss: 0.12349896878004074
step: 10, loss: 0.028866801410913467
step: 20, loss: 0.061109013855457306
step: 30, loss: 0.10497172921895981
step: 40, loss: 0.04762212932109833
step: 50, loss: 0.0004315437690820545
step: 60, loss: 0.05675415322184563
step: 70, loss: 0.041912391781806946
step: 80, loss: 0.02900298871099949
step: 90, loss: 0.04395298659801483
step: 100, loss: 0.11794187128543854
step: 110, loss: 0.07515067607164383
step: 120, loss: 0.13740356266498566
step: 130, loss: 0.06172297149896622
step: 140, loss: 0.13327592611312866
step: 150, loss: 0.1327027529478073
step: 160, loss: 0.03349241614341736
step: 170, loss: 0.07185587286949158
step: 180, loss: 0.04142756015062332
step: 190, loss: 0.05522168055176735
step: 200, loss: 0.05020308494567871
step: 210, loss: 0.019452279433608055
step: 220, loss: 0.10737968981266022
step: 230, loss: 0.04693266376852989
step: 240, loss: 0.0241247471421957
step: 250, loss: 0.22532381117343903
step: 260, loss: 0.1619328260421753
step: 270, loss: 0.0668514221906662
step: 280, loss: 0.09369438886642456
step: 290, loss: 0.051814883947372437
step: 300, loss: 0.06721094995737076
step: 310, loss: 0.06217391788959503
step: 320, loss: 0.13961826264858246
step: 330, loss: 0.021804261952638626
step: 340, loss: 0.09927571564912796
step: 350, loss: 0.060126893222332
step: 360, loss: 0.06411554664373398
step: 370, loss: 0.0689454898238182
step: 380, loss: 0.09379689395427704
step: 390, loss: 0.04320527985692024
step: 400, loss: 0.011646232567727566
step: 410, loss: 0.14527274668216705
step: 420, loss: 0.007278646342456341
step: 430, loss: 0.036564942449331284
step: 440, loss: 0.0730217695236206
step: 450, loss: 0.0681309700012207
step: 460, loss: 0.08371543884277344
step: 470, loss: 0.07497919350862503
step: 480, loss: 0.25641629099845886
step: 490, loss: 0.0006767655140720308
step: 500, loss: 0.011812101118266582
step: 510, loss: 0.08058956265449524
step: 520, loss: 0.07282133400440216
step: 530, loss: 0.007368678227066994
step: 540, loss: 0.04231513664126396
step: 550, loss: 0.07148779928684235
step: 560, loss: 0.054083894938230515
step: 570, loss: 0.06523861736059189
step: 580, loss: 0.16603168845176697
step: 590, loss: 0.06641322374343872
step: 600, loss: 0.14515112340450287
step: 610, loss: 0.0941009521484375
step: 620, loss: 0.08400728553533554
step: 630, loss: 0.0476653017103672
step: 640, loss: 0.1480950266122818
step: 650, loss: 0.007298214826732874
step: 660, loss: 0.01674959994852543
step: 670, loss: 0.06641463935375214
step: 680, loss: 0.08941449224948883
step: 690, loss: 0.008998215198516846
step: 700, loss: 0.03581264987587929
step: 710, loss: 0.06577292084693909
step: 720, loss: 0.2018669694662094
step: 730, loss: 0.15260934829711914
step: 740, loss: 0.029068678617477417
step: 750, loss: 0.10315757989883423
step: 760, loss: 0.09148992598056793
step: 770, loss: 0.22802051901817322
step: 780, loss: 0.03784932196140289
step: 790, loss: 0.024110844358801842
step: 800, loss: 0.046469610184431076
step: 810, loss: 0.07446753978729248
step: 820, loss: 0.039275117218494415
step: 830, loss: 0.10215245187282562
step: 840, loss: 0.01541594136506319
step: 850, loss: 0.08159525692462921
step: 860, loss: 0.022693194448947906
step: 870, loss: 0.044609807431697845
step: 880, loss: 0.06739159673452377
step: 890, loss: 0.03122553415596485
step: 900, loss: 0.02534058690071106
step: 910, loss: 0.03301270678639412
step: 920, loss: 0.038807936012744904
step: 930, loss: 0.044861968606710434
step: 940, loss: 0.056561119854450226
step: 950, loss: 0.06662467122077942
step: 960, loss: 0.06668560951948166
step: 970, loss: 0.09483493864536285
epoch 14: dev_f1=0.9300184162062616, f1=0.9317231769623782, best_f1=0.9285051067780873
step: 0, loss: 0.07655087113380432
step: 10, loss: 0.020156830549240112
step: 20, loss: 0.05773136019706726
step: 30, loss: 0.09607399255037308
step: 40, loss: 0.07478499412536621
step: 50, loss: 0.11562904715538025
step: 60, loss: 0.029828472062945366
step: 70, loss: 0.019141336902976036
step: 80, loss: 0.0005293675349093974
step: 90, loss: 0.027552690356969833
step: 100, loss: 0.0652482733130455
step: 110, loss: 0.0035545658320188522
step: 120, loss: 0.04131317138671875
step: 130, loss: 0.039313919842243195
step: 140, loss: 0.10000982135534286
step: 150, loss: 0.07063174992799759
step: 160, loss: 0.01904604211449623
step: 170, loss: 0.05642140284180641
step: 180, loss: 0.08360103517770767
step: 190, loss: 0.07101964205503464
step: 200, loss: 0.000628666952252388
step: 210, loss: 0.095931276679039
step: 220, loss: 0.1449979543685913
step: 230, loss: 0.019049257040023804
step: 240, loss: 0.0508168488740921
step: 250, loss: 0.04667487367987633
step: 260, loss: 0.0002489997714292258
step: 270, loss: 0.0406828448176384
step: 280, loss: 0.057745784521102905
step: 290, loss: 0.0010992262978106737
step: 300, loss: 0.06408359855413437
step: 310, loss: 3.0440050977631472e-05
step: 320, loss: 0.023028861731290817
step: 330, loss: 0.2221541404724121
step: 340, loss: 0.043907590210437775
step: 350, loss: 0.06376750767230988
step: 360, loss: 0.008578452281653881
step: 370, loss: 0.005139651708304882
step: 380, loss: 0.049441516399383545
step: 390, loss: 0.02941015549004078
step: 400, loss: 0.0007705594762228429
step: 410, loss: 0.05202096328139305
step: 420, loss: 0.12291251868009567
step: 430, loss: 0.021689709275960922
step: 440, loss: 0.0004739196156151593
step: 450, loss: 0.0008767954423092306
step: 460, loss: 0.1073680892586708
step: 470, loss: 0.07924563437700272
step: 480, loss: 0.022052302956581116
step: 490, loss: 0.01720084808766842
step: 500, loss: 0.0025546869728714228
step: 510, loss: 0.040682196617126465
step: 520, loss: 0.13555829226970673
step: 530, loss: 0.03822892904281616
step: 540, loss: 0.022473568096756935
step: 550, loss: 0.038548871874809265
step: 560, loss: 0.14050449430942535
step: 570, loss: 0.10474634915590286
step: 580, loss: 0.07716994732618332
step: 590, loss: 0.11142000555992126
step: 600, loss: 0.0637047067284584
step: 610, loss: 0.14120928943157196
step: 620, loss: 0.10021735727787018
step: 630, loss: 0.04831825941801071
step: 640, loss: 0.05449928343296051
step: 650, loss: 0.06293933838605881
step: 660, loss: 0.09301202744245529
step: 670, loss: 0.08597556501626968
step: 680, loss: 0.09230658411979675
step: 690, loss: 0.12845300137996674
step: 700, loss: 0.042731430381536484
step: 710, loss: 0.15800394117832184
step: 720, loss: 0.03321371600031853
step: 730, loss: 0.12568660080432892
step: 740, loss: 0.08396054059267044
step: 750, loss: 0.028607908636331558
step: 760, loss: 0.05386865511536598
step: 770, loss: 0.057589340955019
step: 780, loss: 0.042134545743465424
step: 790, loss: 0.05875029042363167
step: 800, loss: 0.0175178125500679
step: 810, loss: 0.07981221377849579
step: 820, loss: 0.032731253653764725
step: 830, loss: 0.042395710945129395
step: 840, loss: 0.08094923198223114
step: 850, loss: 0.04413687065243721
step: 860, loss: 0.06357257068157196
step: 870, loss: 0.0715809315443039
step: 880, loss: 0.052376724779605865
step: 890, loss: 0.07460252940654755
step: 900, loss: 0.02588234283030033
step: 910, loss: 0.01845480129122734
step: 920, loss: 0.04344415292143822
step: 930, loss: 0.030717328190803528
step: 940, loss: 0.01735898107290268
step: 950, loss: 0.039120979607105255
step: 960, loss: 0.06954936683177948
step: 970, loss: 0.0761716440320015
epoch 15: dev_f1=0.9272211720226843, f1=0.9202453987730062, best_f1=0.9285051067780873
step: 0, loss: 0.062077347189188004
step: 10, loss: 0.046241018921136856
step: 20, loss: 0.07387714087963104
step: 30, loss: 0.01749822311103344
step: 40, loss: 0.02718351222574711
step: 50, loss: 0.023062720894813538
step: 60, loss: 0.04436752200126648
step: 70, loss: 0.048766568303108215
step: 80, loss: 0.012851275503635406
step: 90, loss: 0.050933726131916046
step: 100, loss: 0.04158105328679085
step: 110, loss: 0.048468101769685745
step: 120, loss: 0.066218800842762
step: 130, loss: 0.04622691124677658
step: 140, loss: 0.0365443229675293
step: 150, loss: 0.05382467433810234
step: 160, loss: 0.011444315314292908
step: 170, loss: 0.043798692524433136
step: 180, loss: 0.05094509944319725
step: 190, loss: 0.08978009223937988
step: 200, loss: 0.07504023611545563
step: 210, loss: 0.05584067106246948
step: 220, loss: 0.07702767103910446
step: 230, loss: 0.07161068171262741
step: 240, loss: 0.01785854995250702
step: 250, loss: 0.0032751422841101885
step: 260, loss: 0.00030363653786480427
step: 270, loss: 0.18789120018482208
step: 280, loss: 0.04369751363992691
step: 290, loss: 0.024011464789509773
step: 300, loss: 0.0812898576259613
step: 310, loss: 0.024440182372927666
step: 320, loss: 0.05073832347989082
step: 330, loss: 0.17145459353923798
step: 340, loss: 0.03294554725289345
step: 350, loss: 0.06447696685791016
step: 360, loss: 0.08931013196706772
step: 370, loss: 0.07792729884386063
step: 380, loss: 0.05542788654565811
step: 390, loss: 0.0023844486568123102
step: 400, loss: 0.033646658062934875
step: 410, loss: 0.02519286423921585
step: 420, loss: 0.0539587065577507
step: 430, loss: 0.0656181201338768
step: 440, loss: 0.10300731658935547
step: 450, loss: 0.030162544921040535
step: 460, loss: 0.052168745547533035
step: 470, loss: 0.14347365498542786
step: 480, loss: 0.11775945127010345
step: 490, loss: 0.08116874098777771
step: 500, loss: 0.0566343255341053
step: 510, loss: 0.057921405881643295
step: 520, loss: 0.0858696699142456
step: 530, loss: 0.057805225253105164
step: 540, loss: 0.10174734145402908
step: 550, loss: 0.034247566014528275
step: 560, loss: 0.057369496673345566
step: 570, loss: 0.02014395222067833
step: 580, loss: 0.07708612084388733
step: 590, loss: 0.057936009019613266
step: 600, loss: 0.04897148162126541
step: 610, loss: 0.11065704375505447
step: 620, loss: 0.037102844566106796
step: 630, loss: 0.010610784403979778
step: 640, loss: 0.10021282732486725
step: 650, loss: 0.025677403435111046
step: 660, loss: 0.1752658635377884
step: 670, loss: 0.020300447940826416
step: 680, loss: 0.09883051365613937
step: 690, loss: 0.08490680158138275
step: 700, loss: 0.07021170854568481
step: 710, loss: 0.09650954604148865
step: 720, loss: 0.049090173095464706
step: 730, loss: 0.054819460958242416
step: 740, loss: 0.012146223336458206
step: 750, loss: 0.04693715274333954
step: 760, loss: 0.0477287694811821
step: 770, loss: 0.04751542583107948
step: 780, loss: 0.03011896274983883
step: 790, loss: 0.02354476787149906
step: 800, loss: 0.0658489540219307
step: 810, loss: 0.14083154499530792
step: 820, loss: 0.012881573289632797
step: 830, loss: 0.08215566724538803
step: 840, loss: 0.08744984120130539
step: 850, loss: 4.2041592678288e-05
step: 860, loss: 0.23353946208953857
step: 870, loss: 0.05078290030360222
step: 880, loss: 0.04323405772447586
step: 890, loss: 0.0864977017045021
step: 900, loss: 0.02417421154677868
step: 910, loss: 0.148023784160614
step: 920, loss: 0.00033455988159403205
step: 930, loss: 0.19254231452941895
step: 940, loss: 0.0649285838007927
step: 950, loss: 0.05981902778148651
step: 960, loss: 0.03359437361359596
step: 970, loss: 0.01404076162725687
epoch 16: dev_f1=0.9314442413162706, f1=0.9275229357798166, best_f1=0.9285051067780873
step: 0, loss: 0.10915567725896835
step: 10, loss: 0.0640755221247673
step: 20, loss: 0.011162771843373775
step: 30, loss: 0.10281708836555481
step: 40, loss: 0.03528222441673279
step: 50, loss: 0.07322283834218979
step: 60, loss: 0.07145419716835022
step: 70, loss: 0.018998239189386368
step: 80, loss: 0.017133213579654694
step: 90, loss: 0.03575921058654785
step: 100, loss: 0.14385733008384705
step: 110, loss: 0.07180489599704742
step: 120, loss: 0.09985451400279999
step: 130, loss: 0.09982366114854813
step: 140, loss: 0.036246348172426224
step: 150, loss: 0.06333424150943756
step: 160, loss: 0.005218048579990864
step: 170, loss: 0.03766155242919922
step: 180, loss: 0.07350167632102966
step: 190, loss: 0.04535738751292229
step: 200, loss: 0.0037379495333880186
step: 210, loss: 0.04302681237459183
step: 220, loss: 0.04505769908428192
step: 230, loss: 0.022579336538910866
step: 240, loss: 0.043618034571409225
step: 250, loss: 0.07315678149461746
step: 260, loss: 0.020573463290929794
step: 270, loss: 0.0030485307797789574
step: 280, loss: 0.07155534625053406
step: 290, loss: 0.020702138543128967
step: 300, loss: 0.05612977594137192
step: 310, loss: 0.0396471731364727
step: 320, loss: 0.0706321969628334
step: 330, loss: 0.10393883287906647
step: 340, loss: 0.10734377801418304
step: 350, loss: 0.05950857326388359
step: 360, loss: 0.040877487510442734
step: 370, loss: 0.06882038712501526
step: 380, loss: 0.006896342616528273
step: 390, loss: 0.1308259218931198
step: 400, loss: 0.0770408883690834
step: 410, loss: 0.0003672660677693784
step: 420, loss: 0.018363792449235916
step: 430, loss: 0.04344141483306885
step: 440, loss: 0.05496042221784592
step: 450, loss: 0.040030594915151596
step: 460, loss: 0.03657884523272514
step: 470, loss: 0.020712818950414658
step: 480, loss: 0.15937507152557373
step: 490, loss: 0.09878432005643845
step: 500, loss: 0.09550854563713074
step: 510, loss: 0.012075584381818771
step: 520, loss: 0.0384797602891922
step: 530, loss: 0.04619365185499191
step: 540, loss: 0.04403367638587952
step: 550, loss: 0.010830297134816647
step: 560, loss: 0.024047715589404106
step: 570, loss: 0.002369099762290716
step: 580, loss: 0.031261008232831955
step: 590, loss: 0.014706469140946865
step: 600, loss: 0.016252130270004272
step: 610, loss: 0.05926771089434624
step: 620, loss: 0.04825455695390701
step: 630, loss: 0.07589208334684372
step: 640, loss: 0.07810956984758377
step: 650, loss: 0.05769560858607292
step: 660, loss: 0.01801936887204647
step: 670, loss: 0.12220408767461777
step: 680, loss: 0.06759613752365112
step: 690, loss: 0.0755719318985939
step: 700, loss: 0.07014384120702744
step: 710, loss: 0.06289416551589966
step: 720, loss: 0.012818637304008007
step: 730, loss: 0.022937890142202377
step: 740, loss: 0.03506267070770264
step: 750, loss: 0.1750159114599228
step: 760, loss: 0.028225313872098923
step: 770, loss: 0.0321265310049057
step: 780, loss: 0.05668474733829498
step: 790, loss: 0.04751744493842125
step: 800, loss: 0.07517366856336594
step: 810, loss: 0.06468338519334793
step: 820, loss: 0.006950175389647484
step: 830, loss: 0.015690596774220467
step: 840, loss: 0.14805065095424652
step: 850, loss: 0.07021547853946686
step: 860, loss: 0.0987376943230629
step: 870, loss: 0.19473080337047577
step: 880, loss: 0.042553987354040146
step: 890, loss: 0.0014805571408942342
step: 900, loss: 0.05799581855535507
step: 910, loss: 0.014885954558849335
step: 920, loss: 0.0012717805802822113
step: 930, loss: 0.1058696061372757
step: 940, loss: 0.04256762936711311
step: 950, loss: 0.08349304646253586
step: 960, loss: 0.0952514111995697
step: 970, loss: 0.06653096526861191
epoch 17: dev_f1=0.929840972871843, f1=0.9247311827956989, best_f1=0.9285051067780873
step: 0, loss: 0.0763850063085556
step: 10, loss: 0.01709563657641411
step: 20, loss: 0.05647469311952591
step: 30, loss: 0.039026688784360886
step: 40, loss: 0.024186402559280396
step: 50, loss: 0.06246494874358177
step: 60, loss: 0.04102214425802231
step: 70, loss: 0.025098953396081924
step: 80, loss: 0.12337638437747955
step: 90, loss: 4.2061048588948324e-05
step: 100, loss: 0.09390980750322342
step: 110, loss: 0.0821148008108139
step: 120, loss: 0.018925223499536514
step: 130, loss: 0.2177402377128601
step: 140, loss: 0.10776960104703903
step: 150, loss: 0.014604493975639343
step: 160, loss: 0.02972058206796646
step: 170, loss: 0.10331953316926956
step: 180, loss: 0.016049198806285858
step: 190, loss: 0.01753312721848488
step: 200, loss: 0.07286523282527924
step: 210, loss: 0.045031797140836716
step: 220, loss: 0.06561066210269928
step: 230, loss: 0.05061844363808632
step: 240, loss: 0.022229257971048355
step: 250, loss: 0.08343012630939484
step: 260, loss: 0.07020829617977142
step: 270, loss: 0.036671385169029236
step: 280, loss: 0.03007611259818077
step: 290, loss: 0.08754917979240417
step: 300, loss: 0.015560050494968891
step: 310, loss: 0.03270135819911957
step: 320, loss: 0.09835144877433777
step: 330, loss: 0.07869059592485428
step: 340, loss: 0.0595487505197525
step: 350, loss: 0.013066630810499191
step: 360, loss: 0.05727259814739227
step: 370, loss: 0.06326044350862503
step: 380, loss: 0.07713523507118225
step: 390, loss: 0.08540648967027664
step: 400, loss: 0.01509033516049385
step: 410, loss: 0.043552786111831665
step: 420, loss: 0.03449762240052223
step: 430, loss: 0.09467878192663193
step: 440, loss: 0.023518865928053856
step: 450, loss: 0.01433330588042736
step: 460, loss: 0.06374151259660721
step: 470, loss: 0.16309046745300293
step: 480, loss: 0.0676518902182579
step: 490, loss: 0.0377056747674942
step: 500, loss: 0.015831874683499336
step: 510, loss: 0.02769801951944828
step: 520, loss: 0.018281172960996628
step: 530, loss: 0.1255333423614502
step: 540, loss: 0.007367737591266632
step: 550, loss: 0.017310544848442078
step: 560, loss: 0.020244957879185677
step: 570, loss: 0.0625787302851677
step: 580, loss: 0.028472693637013435
step: 590, loss: 0.047216448932886124
step: 600, loss: 0.20667561888694763
step: 610, loss: 0.010280693881213665
step: 620, loss: 0.10111585259437561
step: 630, loss: 0.09357693046331406
step: 640, loss: 0.04780806228518486
step: 650, loss: 0.027529673650860786
step: 660, loss: 0.018783360719680786
step: 670, loss: 0.04018550366163254
step: 680, loss: 0.031241612508893013
step: 690, loss: 1.4289952559920494e-05
step: 700, loss: 0.05684290826320648
step: 710, loss: 0.021181633695960045
step: 720, loss: 0.041890811175107956
step: 730, loss: 0.06600650399923325
step: 740, loss: 0.13940151035785675
step: 750, loss: 0.1027127206325531
step: 760, loss: 0.045075610280036926
step: 770, loss: 0.07193097472190857
step: 780, loss: 0.07644176483154297
step: 790, loss: 0.08328376710414886
step: 800, loss: 0.055872898548841476
step: 810, loss: 1.3403389857558068e-05
step: 820, loss: 0.04544083774089813
step: 830, loss: 0.025328781455755234
step: 840, loss: 0.06777463853359222
step: 850, loss: 0.10665136575698853
step: 860, loss: 0.033734120428562164
step: 870, loss: 0.0672888234257698
step: 880, loss: 0.03972425311803818
step: 890, loss: 0.07255204021930695
step: 900, loss: 0.009886018931865692
step: 910, loss: 0.005147275980561972
step: 920, loss: 0.027972836047410965
step: 930, loss: 0.006510850042104721
step: 940, loss: 0.07733790576457977
step: 950, loss: 0.030057642608880997
step: 960, loss: 0.05063449591398239
step: 970, loss: 0.07473902404308319
epoch 18: dev_f1=0.9296435272045028, f1=0.9242282507015902, best_f1=0.9285051067780873
step: 0, loss: 0.10497614741325378
step: 10, loss: 0.12378593534231186
step: 20, loss: 0.036872509866952896
step: 30, loss: 0.018766367807984352
step: 40, loss: 0.08540353178977966
step: 50, loss: 0.020592276006937027
step: 60, loss: 0.01947104185819626
step: 70, loss: 0.08565864711999893
step: 80, loss: 0.03604362905025482
step: 90, loss: 0.06584858149290085
step: 100, loss: 5.273429269436747e-05
step: 110, loss: 0.03049069456756115
step: 120, loss: 0.000821716443169862
step: 130, loss: 0.043057505041360855
step: 140, loss: 0.07274969667196274
step: 150, loss: 0.04121968895196915
step: 160, loss: 0.06831926107406616
step: 170, loss: 0.05633170157670975
step: 180, loss: 0.008971859700977802
step: 190, loss: 0.035801392048597336
step: 200, loss: 0.05983133614063263
step: 210, loss: 0.022838473320007324
step: 220, loss: 0.060357414186000824
step: 230, loss: 0.01528602372854948
step: 240, loss: 0.023596540093421936
step: 250, loss: 0.06990289688110352
step: 260, loss: 0.03900248184800148
step: 270, loss: 0.01746690645813942
step: 280, loss: 0.0003650918370112777
step: 290, loss: 0.039916761219501495
step: 300, loss: 0.00019526024698279798
step: 310, loss: 0.021481458097696304
step: 320, loss: 0.0180257186293602
step: 330, loss: 0.04883214086294174
step: 340, loss: 0.046732719987630844
step: 350, loss: 0.03791109099984169
step: 360, loss: 0.024443194270133972
step: 370, loss: 0.026633158326148987
step: 380, loss: 0.07406952977180481
step: 390, loss: 0.023227890953421593
step: 400, loss: 0.027750559151172638
step: 410, loss: 0.047756120562553406
step: 420, loss: 0.019777435809373856
step: 430, loss: 0.01839269883930683
step: 440, loss: 0.012824893929064274
step: 450, loss: 0.05154626816511154
step: 460, loss: 0.0624375194311142
step: 470, loss: 0.021101243793964386
step: 480, loss: 0.07085295766592026
step: 490, loss: 0.08393934369087219
step: 500, loss: 0.047908857464790344
step: 510, loss: 3.171795469825156e-05
step: 520, loss: 0.0002759828930720687
step: 530, loss: 0.06153033673763275
step: 540, loss: 0.00043784480658359826
step: 550, loss: 0.10812326520681381
step: 560, loss: 0.0592961385846138
step: 570, loss: 0.004664312116801739
step: 580, loss: 0.14330628514289856
step: 590, loss: 0.05459391698241234
step: 600, loss: 0.06035220995545387
step: 610, loss: 0.02276439778506756
step: 620, loss: 0.10052195191383362
step: 630, loss: 0.0775836706161499
step: 640, loss: 0.1004551500082016
step: 650, loss: 0.013253333978354931
step: 660, loss: 0.06300734728574753
step: 670, loss: 0.034916654229164124
step: 680, loss: 0.08216942846775055
step: 690, loss: 0.046814169734716415
step: 700, loss: 0.054748665541410446
step: 710, loss: 0.04553772136569023
step: 720, loss: 0.014512655325233936
step: 730, loss: 0.03210640698671341
step: 740, loss: 0.08734595775604248
step: 750, loss: 0.035800281912088394
step: 760, loss: 0.05852023884654045
step: 770, loss: 0.05645616352558136
step: 780, loss: 0.08148550242185593
step: 790, loss: 0.08035332709550858
step: 800, loss: 0.06092911213636398
step: 810, loss: 0.04696783795952797
step: 820, loss: 0.05985291302204132
step: 830, loss: 0.1053168848156929
step: 840, loss: 0.04473872855305672
step: 850, loss: 0.05020632594823837
step: 860, loss: 0.10381811112165451
step: 870, loss: 0.043039917945861816
step: 880, loss: 0.027640078216791153
step: 890, loss: 0.07353027164936066
step: 900, loss: 0.05429939553141594
step: 910, loss: 0.046195920556783676
step: 920, loss: 0.022451968863606453
step: 930, loss: 0.03499020263552666
step: 940, loss: 0.13817869126796722
step: 950, loss: 0.08711082488298416
step: 960, loss: 0.006264186464250088
step: 970, loss: 0.06028706207871437
epoch 19: dev_f1=0.9304063521718824, f1=0.9249417249417249, best_f1=0.9285051067780873
step: 0, loss: 0.001072680577635765
step: 10, loss: 0.0002318370679859072
step: 20, loss: 0.040759358555078506
step: 30, loss: 0.07445316761732101
step: 40, loss: 0.049200594425201416
step: 50, loss: 0.017578350380063057
step: 60, loss: 0.029928110539913177
step: 70, loss: 0.03452014923095703
step: 80, loss: 0.02486811950802803
step: 90, loss: 0.074803926050663
step: 100, loss: 0.08374878764152527
step: 110, loss: 0.0180194191634655
step: 120, loss: 0.09088312834501266
step: 130, loss: 0.03825794532895088
step: 140, loss: 0.05742458254098892
step: 150, loss: 0.01954851858317852
step: 160, loss: 0.04196484759449959
step: 170, loss: 0.00017803322407417
step: 180, loss: 0.03722045570611954
step: 190, loss: 0.0033512588124722242
step: 200, loss: 0.09261622279882431
step: 210, loss: 0.04665472358465195
step: 220, loss: 8.576105756219476e-05
step: 230, loss: 0.012318192981183529
step: 240, loss: 0.06719829887151718
step: 250, loss: 0.05689917132258415
step: 260, loss: 0.015195611864328384
step: 270, loss: 0.07215426117181778
step: 280, loss: 0.06990285962820053
step: 290, loss: 0.04328952357172966
step: 300, loss: 3.652427039924078e-05
step: 310, loss: 1.2554126442410052e-05
step: 320, loss: 8.693725249031559e-05
step: 330, loss: 0.04715937376022339
step: 340, loss: 0.03926510736346245
step: 350, loss: 0.06291204690933228
step: 360, loss: 0.058145683258771896
step: 370, loss: 0.04134665057063103
step: 380, loss: 0.06264065951108932
step: 390, loss: 0.10057761520147324
step: 400, loss: 0.14093822240829468
step: 410, loss: 0.04324543848633766
step: 420, loss: 0.03077978827059269
step: 430, loss: 0.0588390976190567
step: 440, loss: 0.023536985740065575
step: 450, loss: 0.04064740985631943
step: 460, loss: 0.07850979268550873
step: 470, loss: 0.01779097504913807
step: 480, loss: 0.027425915002822876
step: 490, loss: 0.06372787058353424
step: 500, loss: 0.08406015485525131
step: 510, loss: 0.05469897389411926
step: 520, loss: 0.0710379034280777
step: 530, loss: 0.02263624034821987
step: 540, loss: 0.022440744563937187
step: 550, loss: 0.04955952242016792
step: 560, loss: 0.04100591316819191
step: 570, loss: 0.060186952352523804
step: 580, loss: 0.08372590690851212
step: 590, loss: 0.06886015087366104
step: 600, loss: 0.006020855158567429
step: 610, loss: 0.018827104941010475
step: 620, loss: 0.03530556336045265
step: 630, loss: 0.06331182271242142
step: 640, loss: 0.1382281631231308
step: 650, loss: 5.1052047638222575e-05
step: 660, loss: 0.08549218624830246
step: 670, loss: 0.019583215937018394
step: 680, loss: 0.07127425074577332
step: 690, loss: 0.030453698709607124
step: 700, loss: 0.0457037054002285
step: 710, loss: 0.030879082158207893
step: 720, loss: 0.03402947261929512
step: 730, loss: 0.06533509492874146
step: 740, loss: 0.03856084123253822
step: 750, loss: 0.04236305505037308
step: 760, loss: 0.06421376764774323
step: 770, loss: 0.007442443631589413
step: 780, loss: 0.046870775520801544
step: 790, loss: 0.141310915350914
step: 800, loss: 0.022280585020780563
step: 810, loss: 0.08323098719120026
step: 820, loss: 0.07440946996212006
step: 830, loss: 0.03254770487546921
step: 840, loss: 0.01151441689580679
step: 850, loss: 0.03801606968045235
step: 860, loss: 0.023963112384080887
step: 870, loss: 0.041519567370414734
step: 880, loss: 0.029493968933820724
step: 890, loss: 0.04630065709352493
step: 900, loss: 0.00417990842834115
step: 910, loss: 0.12027154117822647
step: 920, loss: 0.043397072702646255
step: 930, loss: 0.027468355372548103
step: 940, loss: 0.028023023158311844
step: 950, loss: 0.053101781755685806
step: 960, loss: 0.06720881909132004
step: 970, loss: 0.03829120472073555
epoch 20: dev_f1=0.9312762973352035, f1=0.9243697478991597, best_f1=0.9285051067780873
