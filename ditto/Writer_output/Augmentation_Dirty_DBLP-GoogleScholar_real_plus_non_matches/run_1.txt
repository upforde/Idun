cuda
Device: cuda
step: 0, loss: 0.8012309670448303
step: 10, loss: 0.3210572600364685
step: 20, loss: 0.2602813243865967
step: 30, loss: 0.31128934025764465
step: 40, loss: 0.3112165033817291
step: 50, loss: 0.21783044934272766
step: 60, loss: 0.10643406957387924
step: 70, loss: 0.14307326078414917
step: 80, loss: 0.2315920889377594
step: 90, loss: 0.19969116151332855
step: 100, loss: 0.11385050415992737
step: 110, loss: 0.11513716727495193
step: 120, loss: 0.16593313217163086
step: 130, loss: 0.23172986507415771
step: 140, loss: 0.21424919366836548
step: 150, loss: 0.10350008308887482
step: 160, loss: 0.08405211567878723
step: 170, loss: 0.06378466635942459
step: 180, loss: 0.28638237714767456
step: 190, loss: 0.2116193026304245
step: 200, loss: 0.14950333535671234
step: 210, loss: 0.16178128123283386
step: 220, loss: 0.08636505901813507
step: 230, loss: 0.1351480334997177
step: 240, loss: 0.5101957321166992
step: 250, loss: 0.12484780699014664
step: 260, loss: 0.08523724973201752
step: 270, loss: 0.14640019834041595
step: 280, loss: 0.10386630147695541
step: 290, loss: 0.15118622779846191
step: 300, loss: 0.20192046463489532
step: 310, loss: 0.18580979108810425
step: 320, loss: 0.24322448670864105
step: 330, loss: 0.18987728655338287
step: 340, loss: 0.2532041668891907
step: 350, loss: 0.28819921612739563
step: 360, loss: 0.1669892966747284
step: 370, loss: 0.07313822209835052
step: 380, loss: 0.1309315413236618
step: 390, loss: 0.2019989788532257
step: 400, loss: 0.16204695403575897
step: 410, loss: 0.1523466557264328
step: 420, loss: 0.18977393209934235
step: 430, loss: 0.18776284158229828
step: 440, loss: 0.19695822894573212
step: 450, loss: 0.12405551224946976
step: 460, loss: 0.20733428001403809
step: 470, loss: 0.19574996829032898
step: 480, loss: 0.12669917941093445
step: 490, loss: 0.17917107045650482
step: 500, loss: 0.25790414214134216
step: 510, loss: 0.11601367592811584
step: 520, loss: 0.1431947946548462
step: 530, loss: 0.16598983108997345
step: 540, loss: 0.11654563248157501
step: 550, loss: 0.13559038937091827
step: 560, loss: 0.19154059886932373
step: 570, loss: 0.14362381398677826
step: 580, loss: 0.1588297039270401
step: 590, loss: 0.06305892020463943
step: 600, loss: 0.10581210255622864
step: 610, loss: 0.2898542284965515
step: 620, loss: 0.14032594859600067
step: 630, loss: 0.10691986978054047
step: 640, loss: 0.2881447970867157
step: 650, loss: 0.041772548109292984
step: 660, loss: 0.2115258276462555
step: 670, loss: 0.18337482213974
step: 680, loss: 0.11616460978984833
step: 690, loss: 0.10259220004081726
step: 700, loss: 0.26312077045440674
step: 710, loss: 0.17871886491775513
step: 720, loss: 0.0628112182021141
step: 730, loss: 0.22481977939605713
step: 740, loss: 0.11190400272607803
step: 750, loss: 0.17616641521453857
step: 760, loss: 0.11006428301334381
step: 770, loss: 0.14415708184242249
step: 780, loss: 0.11220686882734299
step: 790, loss: 0.17369434237480164
step: 800, loss: 0.09915213286876678
step: 810, loss: 0.35355108976364136
step: 820, loss: 0.09186084568500519
step: 830, loss: 0.1616908311843872
step: 840, loss: 0.15092991292476654
step: 850, loss: 0.08256757259368896
step: 860, loss: 0.08840961754322052
step: 870, loss: 0.0842156782746315
step: 880, loss: 0.20193643867969513
step: 890, loss: 0.11095631867647171
step: 900, loss: 0.19101151823997498
step: 910, loss: 0.10461794584989548
step: 920, loss: 0.053715240210294724
step: 930, loss: 0.1176738291978836
step: 940, loss: 0.15510988235473633
step: 950, loss: 0.14013931155204773
step: 960, loss: 0.13314084708690643
step: 970, loss: 0.1746666580438614
epoch 1: dev_f1=0.9260808926080892, f1=0.921003717472119, best_f1=0.921003717472119
step: 0, loss: 0.10379328578710556
step: 10, loss: 0.09848004579544067
step: 20, loss: 0.11259286850690842
step: 30, loss: 0.11055746674537659
step: 40, loss: 0.08525088429450989
step: 50, loss: 0.11152328550815582
step: 60, loss: 0.052504148334264755
step: 70, loss: 0.15483637154102325
step: 80, loss: 0.1492728441953659
step: 90, loss: 0.12398240715265274
step: 100, loss: 0.14937840402126312
step: 110, loss: 0.16981685161590576
step: 120, loss: 0.19413183629512787
step: 130, loss: 0.1333301067352295
step: 140, loss: 0.23070597648620605
step: 150, loss: 0.09079371392726898
step: 160, loss: 0.12006211280822754
step: 170, loss: 0.08439048379659653
step: 180, loss: 0.11695270985364914
step: 190, loss: 0.14767897129058838
step: 200, loss: 0.00824663694947958
step: 210, loss: 0.11941573023796082
step: 220, loss: 0.13021673262119293
step: 230, loss: 0.058022014796733856
step: 240, loss: 0.2375488132238388
step: 250, loss: 0.15077468752861023
step: 260, loss: 0.180586040019989
step: 270, loss: 0.26983678340911865
step: 280, loss: 0.15202750265598297
step: 290, loss: 0.15767085552215576
step: 300, loss: 0.07912861555814743
step: 310, loss: 0.10073956102132797
step: 320, loss: 0.07253426313400269
step: 330, loss: 0.3092014193534851
step: 340, loss: 0.13512858748435974
step: 350, loss: 0.15613171458244324
step: 360, loss: 0.09835588932037354
step: 370, loss: 0.15329594910144806
step: 380, loss: 0.18138617277145386
step: 390, loss: 0.09391985088586807
step: 400, loss: 0.08776497840881348
step: 410, loss: 0.15641598403453827
step: 420, loss: 0.16185256838798523
step: 430, loss: 0.058448247611522675
step: 440, loss: 0.13796387612819672
step: 450, loss: 0.15495644509792328
step: 460, loss: 0.02499254234135151
step: 470, loss: 0.0916619524359703
step: 480, loss: 0.07316898554563522
step: 490, loss: 0.1254744827747345
step: 500, loss: 0.0913008600473404
step: 510, loss: 0.06359010934829712
step: 520, loss: 0.14669939875602722
step: 530, loss: 0.15918990969657898
step: 540, loss: 0.09531012922525406
step: 550, loss: 0.22989091277122498
step: 560, loss: 0.1719544678926468
step: 570, loss: 0.1499769538640976
step: 580, loss: 0.08052986115217209
step: 590, loss: 0.08459680527448654
step: 600, loss: 0.1157408282160759
step: 610, loss: 0.06308554112911224
step: 620, loss: 0.07867971062660217
step: 630, loss: 0.16045856475830078
step: 640, loss: 0.09685041755437851
step: 650, loss: 0.20569197833538055
step: 660, loss: 0.14516860246658325
step: 670, loss: 0.05410784110426903
step: 680, loss: 0.20804919302463531
step: 690, loss: 0.1821228712797165
step: 700, loss: 0.10681463032960892
step: 710, loss: 0.1254820078611374
step: 720, loss: 0.12061073631048203
step: 730, loss: 0.156895250082016
step: 740, loss: 0.14271406829357147
step: 750, loss: 0.2943711280822754
step: 760, loss: 0.014619795605540276
step: 770, loss: 0.17975950241088867
step: 780, loss: 0.11416393518447876
step: 790, loss: 0.1561897099018097
step: 800, loss: 0.0514763705432415
step: 810, loss: 0.16899758577346802
step: 820, loss: 0.15079951286315918
step: 830, loss: 0.21922098100185394
step: 840, loss: 0.17784136533737183
step: 850, loss: 0.14991192519664764
step: 860, loss: 0.1520107239484787
step: 870, loss: 0.14562657475471497
step: 880, loss: 0.11695468425750732
step: 890, loss: 0.06143425405025482
step: 900, loss: 0.10648240149021149
step: 910, loss: 0.10854983329772949
step: 920, loss: 0.15678542852401733
step: 930, loss: 0.12508907914161682
step: 940, loss: 0.25742000341415405
step: 950, loss: 0.10843884944915771
step: 960, loss: 0.1793113499879837
step: 970, loss: 0.2537372410297394
epoch 2: dev_f1=0.9290555806597379, f1=0.9268292682926829, best_f1=0.9268292682926829
step: 0, loss: 0.11142788827419281
step: 10, loss: 0.05844665318727493
step: 20, loss: 0.13808676600456238
step: 30, loss: 0.09759436547756195
step: 40, loss: 0.06849770992994308
step: 50, loss: 0.1153433546423912
step: 60, loss: 0.07132554054260254
step: 70, loss: 0.06645432114601135
step: 80, loss: 0.1781052201986313
step: 90, loss: 0.2036391943693161
step: 100, loss: 0.19462496042251587
step: 110, loss: 0.08715452998876572
step: 120, loss: 0.10676928609609604
step: 130, loss: 0.06384344398975372
step: 140, loss: 0.044222861528396606
step: 150, loss: 0.08727012574672699
step: 160, loss: 0.14189143478870392
step: 170, loss: 0.06044018641114235
step: 180, loss: 0.15400944650173187
step: 190, loss: 0.14029836654663086
step: 200, loss: 0.1814095675945282
step: 210, loss: 0.3033196032047272
step: 220, loss: 0.1416902393102646
step: 230, loss: 0.26868653297424316
step: 240, loss: 0.10350698232650757
step: 250, loss: 0.09894783794879913
step: 260, loss: 0.11809058487415314
step: 270, loss: 0.1004268005490303
step: 280, loss: 0.0972808226943016
step: 290, loss: 0.141534224152565
step: 300, loss: 0.09514392167329788
step: 310, loss: 0.17303098738193512
step: 320, loss: 0.05561072751879692
step: 330, loss: 0.16103385388851166
step: 340, loss: 0.4302789866924286
step: 350, loss: 0.07095503807067871
step: 360, loss: 0.04513366520404816
step: 370, loss: 0.08495151251554489
step: 380, loss: 0.07407958060503006
step: 390, loss: 0.05773765593767166
step: 400, loss: 0.09794484078884125
step: 410, loss: 0.1156071126461029
step: 420, loss: 0.18100406229496002
step: 430, loss: 0.1886548548936844
step: 440, loss: 0.1872381567955017
step: 450, loss: 0.13223309814929962
step: 460, loss: 0.2586585581302643
step: 470, loss: 0.07976652681827545
step: 480, loss: 0.11621313542127609
step: 490, loss: 0.08016883581876755
step: 500, loss: 0.1538865864276886
step: 510, loss: 0.17263683676719666
step: 520, loss: 0.15946468710899353
step: 530, loss: 0.13075701892375946
step: 540, loss: 0.13353927433490753
step: 550, loss: 0.08668868243694305
step: 560, loss: 0.14643150568008423
step: 570, loss: 0.1043022945523262
step: 580, loss: 0.05621691793203354
step: 590, loss: 0.07227272540330887
step: 600, loss: 0.09674657136201859
step: 610, loss: 0.12223365902900696
step: 620, loss: 0.13934074342250824
step: 630, loss: 0.08359432220458984
step: 640, loss: 0.07922191172838211
step: 650, loss: 0.12044539302587509
step: 660, loss: 0.24541345238685608
step: 670, loss: 0.0824708417057991
step: 680, loss: 0.17823860049247742
step: 690, loss: 0.08445277810096741
step: 700, loss: 0.06776764988899231
step: 710, loss: 0.08720748126506805
step: 720, loss: 0.08548538386821747
step: 730, loss: 0.14526143670082092
step: 740, loss: 0.056227412074804306
step: 750, loss: 0.03327232599258423
step: 760, loss: 0.09555864334106445
step: 770, loss: 0.07200754433870316
step: 780, loss: 0.18409419059753418
step: 790, loss: 0.14530985057353973
step: 800, loss: 0.16365352272987366
step: 810, loss: 0.059507135301828384
step: 820, loss: 0.10137571394443512
step: 830, loss: 0.11557211726903915
step: 840, loss: 0.11383653432130814
step: 850, loss: 0.11196531355381012
step: 860, loss: 0.195937842130661
step: 870, loss: 0.0652969628572464
step: 880, loss: 0.10663953423500061
step: 890, loss: 0.11353224515914917
step: 900, loss: 0.18642349541187286
step: 910, loss: 0.1275492161512375
step: 920, loss: 0.08256175369024277
step: 930, loss: 0.1135893389582634
step: 940, loss: 0.1263858824968338
step: 950, loss: 0.05749544873833656
step: 960, loss: 0.04274478182196617
step: 970, loss: 0.09199230372905731
epoch 3: dev_f1=0.9276285844333181, f1=0.9275101305718145, best_f1=0.9268292682926829
step: 0, loss: 0.1368071436882019
step: 10, loss: 0.053415246307849884
step: 20, loss: 0.10791517794132233
step: 30, loss: 0.12219332158565521
step: 40, loss: 0.040885426104068756
step: 50, loss: 0.08821019530296326
step: 60, loss: 0.08565637469291687
step: 70, loss: 0.128038227558136
step: 80, loss: 0.11525893956422806
step: 90, loss: 0.025624440982937813
step: 100, loss: 0.06628929078578949
step: 110, loss: 0.09708668291568756
step: 120, loss: 0.09197966009378433
step: 130, loss: 0.058011140674352646
step: 140, loss: 0.12072993069887161
step: 150, loss: 0.05410393327474594
step: 160, loss: 0.07986780256032944
step: 170, loss: 0.1053476333618164
step: 180, loss: 0.10334128886461258
step: 190, loss: 0.04401205852627754
step: 200, loss: 0.15731970965862274
step: 210, loss: 0.12041717022657394
step: 220, loss: 0.29958003759384155
step: 230, loss: 0.15674364566802979
step: 240, loss: 0.06180420145392418
step: 250, loss: 0.1095743253827095
step: 260, loss: 0.08805223554372787
step: 270, loss: 0.08063679188489914
step: 280, loss: 0.011189057491719723
step: 290, loss: 0.09978366643190384
step: 300, loss: 0.13189391791820526
step: 310, loss: 0.11068630963563919
step: 320, loss: 0.09302523732185364
step: 330, loss: 0.09665688872337341
step: 340, loss: 0.11255282908678055
step: 350, loss: 0.15206719934940338
step: 360, loss: 0.1597035974264145
step: 370, loss: 0.08555101603269577
step: 380, loss: 0.13261662423610687
step: 390, loss: 0.2527424991130829
step: 400, loss: 0.08770173043012619
step: 410, loss: 0.17286230623722076
step: 420, loss: 0.0918952152132988
step: 430, loss: 0.07963641732931137
step: 440, loss: 0.061472393572330475
step: 450, loss: 0.11301887035369873
step: 460, loss: 0.046871453523635864
step: 470, loss: 0.24539725482463837
step: 480, loss: 0.24749629199504852
step: 490, loss: 0.17218543589115143
step: 500, loss: 0.09825257956981659
step: 510, loss: 0.05796956270933151
step: 520, loss: 0.10080160200595856
step: 530, loss: 0.1197432428598404
step: 540, loss: 0.10253684222698212
step: 550, loss: 0.10436715185642242
step: 560, loss: 0.0919530913233757
step: 570, loss: 0.07914211601018906
step: 580, loss: 0.09089013189077377
step: 590, loss: 0.012078167870640755
step: 600, loss: 0.09305199235677719
step: 610, loss: 0.10712624341249466
step: 620, loss: 0.11990413814783096
step: 630, loss: 0.09824757277965546
step: 640, loss: 0.14718441665172577
step: 650, loss: 0.013184504583477974
step: 660, loss: 0.06793583929538727
step: 670, loss: 0.036181554198265076
step: 680, loss: 0.1265145242214203
step: 690, loss: 0.07235334813594818
step: 700, loss: 0.12084877490997314
step: 710, loss: 0.027030251920223236
step: 720, loss: 0.017215369269251823
step: 730, loss: 0.14019912481307983
step: 740, loss: 0.09432309120893478
step: 750, loss: 0.12260346114635468
step: 760, loss: 0.051909469068050385
step: 770, loss: 0.16208185255527496
step: 780, loss: 0.19708646833896637
step: 790, loss: 0.05335625261068344
step: 800, loss: 0.2877408564090729
step: 810, loss: 0.09026718139648438
step: 820, loss: 0.06899332255125046
step: 830, loss: 0.1671050488948822
step: 840, loss: 0.07239017635583878
step: 850, loss: 0.11598573625087738
step: 860, loss: 0.18828420341014862
step: 870, loss: 0.17962045967578888
step: 880, loss: 0.11601701378822327
step: 890, loss: 0.0936100110411644
step: 900, loss: 0.1987025886774063
step: 910, loss: 0.033383842557668686
step: 920, loss: 0.13052193820476532
step: 930, loss: 0.15783417224884033
step: 940, loss: 0.09835807979106903
step: 950, loss: 0.02882068045437336
step: 960, loss: 0.12567554414272308
step: 970, loss: 0.17745503783226013
epoch 4: dev_f1=0.934844192634561, f1=0.9299905392620624, best_f1=0.9299905392620624
step: 0, loss: 0.08765672892332077
step: 10, loss: 0.10519832372665405
step: 20, loss: 0.0783470869064331
step: 30, loss: 0.07292333990335464
step: 40, loss: 0.05694461986422539
step: 50, loss: 0.14963942766189575
step: 60, loss: 0.10367514938116074
step: 70, loss: 0.05246836692094803
step: 80, loss: 0.07299305498600006
step: 90, loss: 0.08792891353368759
step: 100, loss: 0.15017032623291016
step: 110, loss: 0.1888066828250885
step: 120, loss: 0.04929126054048538
step: 130, loss: 0.06549832969903946
step: 140, loss: 0.08358626812696457
step: 150, loss: 0.04272417351603508
step: 160, loss: 0.07896187156438828
step: 170, loss: 0.06499424576759338
step: 180, loss: 0.15445251762866974
step: 190, loss: 0.12033538520336151
step: 200, loss: 0.055743508040905
step: 210, loss: 0.02398000843822956
step: 220, loss: 0.07118517905473709
step: 230, loss: 0.1419866979122162
step: 240, loss: 0.24095679819583893
step: 250, loss: 0.012093046680092812
step: 260, loss: 0.05929958075284958
step: 270, loss: 0.07516063749790192
step: 280, loss: 0.06619377434253693
step: 290, loss: 0.062018003314733505
step: 300, loss: 0.07199003547430038
step: 310, loss: 0.1254274994134903
step: 320, loss: 0.14176832139492035
step: 330, loss: 0.0987628772854805
step: 340, loss: 0.03994973376393318
step: 350, loss: 0.13400444388389587
step: 360, loss: 0.08373517543077469
step: 370, loss: 0.01630191132426262
step: 380, loss: 0.1059754267334938
step: 390, loss: 0.06309235841035843
step: 400, loss: 0.14393830299377441
step: 410, loss: 0.16825994849205017
step: 420, loss: 0.041168469935655594
step: 430, loss: 0.10776708275079727
step: 440, loss: 0.1429772526025772
step: 450, loss: 0.07817049324512482
step: 460, loss: 0.14220912754535675
step: 470, loss: 0.13948185741901398
step: 480, loss: 0.0791688933968544
step: 490, loss: 0.04116246849298477
step: 500, loss: 0.03553658723831177
step: 510, loss: 0.0749342292547226
step: 520, loss: 0.1105860024690628
step: 530, loss: 0.10790620744228363
step: 540, loss: 0.046497076749801636
step: 550, loss: 0.43862977623939514
step: 560, loss: 0.0784640908241272
step: 570, loss: 0.09805811196565628
step: 580, loss: 0.04685240983963013
step: 590, loss: 0.04379380866885185
step: 600, loss: 0.03393060714006424
step: 610, loss: 0.0642867386341095
step: 620, loss: 0.08289425075054169
step: 630, loss: 0.07013645768165588
step: 640, loss: 0.1106400415301323
step: 650, loss: 0.034982144832611084
step: 660, loss: 0.19916868209838867
step: 670, loss: 0.08619250357151031
step: 680, loss: 0.1278662532567978
step: 690, loss: 0.12314937263727188
step: 700, loss: 0.11635781824588776
step: 710, loss: 0.035064686089754105
step: 720, loss: 0.08921779692173004
step: 730, loss: 0.1272926777601242
step: 740, loss: 0.15069378912448883
step: 750, loss: 0.022310957312583923
step: 760, loss: 0.12628084421157837
step: 770, loss: 0.11012621223926544
step: 780, loss: 0.06309167295694351
step: 790, loss: 0.10232185572385788
step: 800, loss: 0.036838263273239136
step: 810, loss: 0.09813593327999115
step: 820, loss: 0.06910794228315353
step: 830, loss: 0.19954295456409454
step: 840, loss: 0.1379721611738205
step: 850, loss: 0.027240872383117676
step: 860, loss: 0.08871607482433319
step: 870, loss: 0.15154212713241577
step: 880, loss: 0.06444159895181656
step: 890, loss: 0.07278096675872803
step: 900, loss: 0.08558061718940735
step: 910, loss: 0.1329490691423416
step: 920, loss: 0.20785290002822876
step: 930, loss: 0.09168760478496552
step: 940, loss: 0.1163339912891388
step: 950, loss: 0.09846805781126022
step: 960, loss: 0.08300061523914337
step: 970, loss: 0.09729946404695511
epoch 5: dev_f1=0.9341923607915326, f1=0.9296296296296297, best_f1=0.9299905392620624
step: 0, loss: 0.10011544078588486
step: 10, loss: 0.15848396718502045
step: 20, loss: 0.06397877633571625
step: 30, loss: 0.14389432966709137
step: 40, loss: 0.0750729888677597
step: 50, loss: 0.020216377452015877
step: 60, loss: 0.05097268521785736
step: 70, loss: 0.12265732884407043
step: 80, loss: 0.0684814527630806
step: 90, loss: 0.12882369756698608
step: 100, loss: 0.1079542338848114
step: 110, loss: 0.17924129962921143
step: 120, loss: 0.10940971970558167
step: 130, loss: 0.038123685866594315
step: 140, loss: 0.17846055328845978
step: 150, loss: 0.0213551614433527
step: 160, loss: 0.0871104970574379
step: 170, loss: 0.05768255516886711
step: 180, loss: 0.19789716601371765
step: 190, loss: 0.08907179534435272
step: 200, loss: 0.3623615503311157
step: 210, loss: 0.1432666927576065
step: 220, loss: 0.06580871343612671
step: 230, loss: 0.03967816382646561
step: 240, loss: 0.143837571144104
step: 250, loss: 0.044040270149707794
step: 260, loss: 0.0726211816072464
step: 270, loss: 0.0013042404316365719
step: 280, loss: 0.05442929267883301
step: 290, loss: 0.021112989634275436
step: 300, loss: 0.1534171998500824
step: 310, loss: 0.017181189730763435
step: 320, loss: 0.11293850094079971
step: 330, loss: 0.25555184483528137
step: 340, loss: 0.372282475233078
step: 350, loss: 0.0658857524394989
step: 360, loss: 0.05400162190198898
step: 370, loss: 0.06946665048599243
step: 380, loss: 0.10957872867584229
step: 390, loss: 0.006684503052383661
step: 400, loss: 0.06791933625936508
step: 410, loss: 0.11842744052410126
step: 420, loss: 0.03578000143170357
step: 430, loss: 0.07048390060663223
step: 440, loss: 0.0776047557592392
step: 450, loss: 0.12888309359550476
step: 460, loss: 0.1606731116771698
step: 470, loss: 0.20956231653690338
step: 480, loss: 0.07886411249637604
step: 490, loss: 0.0605982206761837
step: 500, loss: 0.14391084015369415
step: 510, loss: 0.06791209429502487
step: 520, loss: 0.08236617594957352
step: 530, loss: 0.08407386392354965
step: 540, loss: 0.06235172972083092
step: 550, loss: 0.051774151623249054
step: 560, loss: 0.09150877594947815
step: 570, loss: 0.05607949569821358
step: 580, loss: 0.14562098681926727
step: 590, loss: 0.20796401798725128
step: 600, loss: 0.07707436382770538
step: 610, loss: 0.07746432721614838
step: 620, loss: 0.08677065372467041
step: 630, loss: 0.07484971731901169
step: 640, loss: 0.1525854915380478
step: 650, loss: 0.10699789226055145
step: 660, loss: 0.021640170365571976
step: 670, loss: 0.08406991511583328
step: 680, loss: 0.03512471541762352
step: 690, loss: 0.056220680475234985
step: 700, loss: 0.09818293154239655
step: 710, loss: 0.03738286718726158
step: 720, loss: 0.15612299740314484
step: 730, loss: 0.0343974307179451
step: 740, loss: 0.10003332793712616
step: 750, loss: 0.09746778011322021
step: 760, loss: 0.11136613041162491
step: 770, loss: 0.12889675796031952
step: 780, loss: 0.05336925759911537
step: 790, loss: 0.1437564492225647
step: 800, loss: 0.09661341458559036
step: 810, loss: 0.014296057634055614
step: 820, loss: 0.06655024737119675
step: 830, loss: 0.12000354379415512
step: 840, loss: 0.026732945814728737
step: 850, loss: 0.14223550260066986
step: 860, loss: 0.09663932770490646
step: 870, loss: 0.1680847406387329
step: 880, loss: 0.07538232207298279
step: 890, loss: 0.12367653101682663
step: 900, loss: 0.07446825504302979
step: 910, loss: 0.09833826869726181
step: 920, loss: 0.0567324236035347
step: 930, loss: 0.12949948012828827
step: 940, loss: 0.24203048646450043
step: 950, loss: 0.1525370329618454
step: 960, loss: 0.170416921377182
step: 970, loss: 0.1443815380334854
epoch 6: dev_f1=0.9285380663241476, f1=0.9270346117867166, best_f1=0.9299905392620624
step: 0, loss: 0.05125710740685463
step: 10, loss: 0.03602023422718048
step: 20, loss: 0.10159573704004288
step: 30, loss: 0.05776197090744972
step: 40, loss: 0.056867122650146484
step: 50, loss: 0.10655377060174942
step: 60, loss: 0.01884879544377327
step: 70, loss: 0.06713660806417465
step: 80, loss: 0.07002419978380203
step: 90, loss: 0.10818478465080261
step: 100, loss: 0.06908803433179855
step: 110, loss: 0.037576157599687576
step: 120, loss: 0.0574772022664547
step: 130, loss: 0.024808797985315323
step: 140, loss: 0.16581332683563232
step: 150, loss: 0.06579141318798065
step: 160, loss: 0.029574105516076088
step: 170, loss: 0.20908086001873016
step: 180, loss: 0.127914160490036
step: 190, loss: 0.07326782494783401
step: 200, loss: 0.052924592047929764
step: 210, loss: 0.055419620126485825
step: 220, loss: 0.048547595739364624
step: 230, loss: 0.11837127059698105
step: 240, loss: 0.14789332449436188
step: 250, loss: 0.04621673375368118
step: 260, loss: 0.08317425847053528
step: 270, loss: 0.08381547778844833
step: 280, loss: 0.10450504720211029
step: 290, loss: 0.17014263570308685
step: 300, loss: 0.11806704849004745
step: 310, loss: 0.06963853538036346
step: 320, loss: 0.08475371450185776
step: 330, loss: 0.03811268508434296
step: 340, loss: 0.13961340487003326
step: 350, loss: 0.030933180823922157
step: 360, loss: 0.0994366779923439
step: 370, loss: 0.06004660949110985
step: 380, loss: 0.0709206834435463
step: 390, loss: 0.08418475836515427
step: 400, loss: 0.06515903770923615
step: 410, loss: 0.16775038838386536
step: 420, loss: 0.11760484427213669
step: 430, loss: 0.08234430849552155
step: 440, loss: 0.08503610640764236
step: 450, loss: 0.12109475582838058
step: 460, loss: 0.19819943606853485
step: 470, loss: 0.0658823698759079
step: 480, loss: 0.07483142614364624
step: 490, loss: 0.07062510401010513
step: 500, loss: 0.1083253026008606
step: 510, loss: 0.037205249071121216
step: 520, loss: 0.13305602967739105
step: 530, loss: 0.026328768581151962
step: 540, loss: 0.06597357988357544
step: 550, loss: 0.08196704834699631
step: 560, loss: 0.07661927491426468
step: 570, loss: 0.055179402232170105
step: 580, loss: 0.05361879616975784
step: 590, loss: 0.16616715490818024
step: 600, loss: 0.06802808493375778
step: 610, loss: 0.12069150060415268
step: 620, loss: 0.1098998636007309
step: 630, loss: 0.06193797290325165
step: 640, loss: 0.06452209502458572
step: 650, loss: 0.07460895925760269
step: 660, loss: 0.032991308718919754
step: 670, loss: 0.033240947872400284
step: 680, loss: 0.20551036298274994
step: 690, loss: 0.04760710150003433
step: 700, loss: 0.06608612090349197
step: 710, loss: 0.06555905193090439
step: 720, loss: 0.1424466073513031
step: 730, loss: 0.1135822981595993
step: 740, loss: 0.03281392157077789
step: 750, loss: 0.08493047952651978
step: 760, loss: 0.1599576324224472
step: 770, loss: 0.09499652683734894
step: 780, loss: 0.05976176634430885
step: 790, loss: 0.04792208597064018
step: 800, loss: 0.13430652022361755
step: 810, loss: 0.14882971346378326
step: 820, loss: 0.10965467989444733
step: 830, loss: 0.1308131366968155
step: 840, loss: 0.07561534643173218
step: 850, loss: 0.14864760637283325
step: 860, loss: 0.06866461038589478
step: 870, loss: 0.10021749883890152
step: 880, loss: 0.12105008959770203
step: 890, loss: 0.08476898074150085
step: 900, loss: 0.07648888975381851
step: 910, loss: 0.15007160604000092
step: 920, loss: 0.046768028289079666
step: 930, loss: 0.3942255973815918
step: 940, loss: 0.08540500700473785
step: 950, loss: 0.12992431223392487
step: 960, loss: 0.17199376225471497
step: 970, loss: 0.10756814479827881
epoch 7: dev_f1=0.929368029739777, f1=0.9287377736376339, best_f1=0.9299905392620624
step: 0, loss: 0.07977999746799469
step: 10, loss: 0.09057442843914032
step: 20, loss: 0.12267791479825974
step: 30, loss: 0.028559597209095955
step: 40, loss: 0.07528766989707947
step: 50, loss: 0.16005946695804596
step: 60, loss: 0.057521238923072815
step: 70, loss: 0.10075083374977112
step: 80, loss: 0.07321946322917938
step: 90, loss: 0.05865680053830147
step: 100, loss: 0.10386469960212708
step: 110, loss: 0.04916507005691528
step: 120, loss: 0.16830436885356903
step: 130, loss: 0.0317598357796669
step: 140, loss: 0.07630741596221924
step: 150, loss: 0.09706765413284302
step: 160, loss: 0.09018342941999435
step: 170, loss: 0.1588713824748993
step: 180, loss: 0.12318968772888184
step: 190, loss: 0.11197243630886078
step: 200, loss: 0.15525488555431366
step: 210, loss: 0.1384880393743515
step: 220, loss: 0.1436462700366974
step: 230, loss: 0.1382647007703781
step: 240, loss: 0.0824933871626854
step: 250, loss: 0.05304299294948578
step: 260, loss: 0.12046536058187485
step: 270, loss: 0.03828725963830948
step: 280, loss: 0.14976464211940765
step: 290, loss: 0.07910984754562378
step: 300, loss: 0.13848328590393066
step: 310, loss: 0.04347117245197296
step: 320, loss: 0.08468654006719589
step: 330, loss: 0.10577815771102905
step: 340, loss: 0.17449913918972015
step: 350, loss: 0.06793586909770966
step: 360, loss: 0.057493098080158234
step: 370, loss: 0.07906094938516617
step: 380, loss: 0.09754692018032074
step: 390, loss: 0.03114970028400421
step: 400, loss: 0.13642728328704834
step: 410, loss: 0.058048732578754425
step: 420, loss: 0.07898503541946411
step: 430, loss: 0.11274577677249908
step: 440, loss: 0.10768736153841019
step: 450, loss: 0.09458157420158386
step: 460, loss: 0.07085548341274261
step: 470, loss: 0.08963321149349213
step: 480, loss: 0.07447320222854614
step: 490, loss: 0.04662155732512474
step: 500, loss: 0.16207139194011688
step: 510, loss: 0.04394809156656265
step: 520, loss: 0.044372476637363434
step: 530, loss: 0.1112593412399292
step: 540, loss: 0.020381085574626923
step: 550, loss: 0.048009827733039856
step: 560, loss: 0.11571819335222244
step: 570, loss: 0.044919468462467194
step: 580, loss: 0.14388833940029144
step: 590, loss: 0.08301027119159698
step: 600, loss: 0.02278466895222664
step: 610, loss: 0.059066615998744965
step: 620, loss: 0.12206124514341354
step: 630, loss: 0.05692817643284798
step: 640, loss: 0.042731091380119324
step: 650, loss: 0.07473087310791016
step: 660, loss: 0.17668065428733826
step: 670, loss: 0.13003022968769073
step: 680, loss: 0.130791574716568
step: 690, loss: 0.11797577142715454
step: 700, loss: 0.12213466316461563
step: 710, loss: 0.06293676048517227
step: 720, loss: 0.04566222429275513
step: 730, loss: 0.0559409037232399
step: 740, loss: 0.07534514367580414
step: 750, loss: 0.020040743052959442
step: 760, loss: 0.03466959670186043
step: 770, loss: 0.0651884526014328
step: 780, loss: 0.0994274839758873
step: 790, loss: 0.0659453496336937
step: 800, loss: 0.06097615882754326
step: 810, loss: 0.07657572627067566
step: 820, loss: 0.17773063480854034
step: 830, loss: 0.0785466730594635
step: 840, loss: 0.14715012907981873
step: 850, loss: 0.07989111542701721
step: 860, loss: 0.11688000708818436
step: 870, loss: 0.09346964210271835
step: 880, loss: 0.10014849156141281
step: 890, loss: 0.020860131829977036
step: 900, loss: 0.059321481734514236
step: 910, loss: 0.06217852234840393
step: 920, loss: 0.1992027908563614
step: 930, loss: 0.1471264660358429
step: 940, loss: 0.12329590320587158
step: 950, loss: 0.10169406980276108
step: 960, loss: 0.14485737681388855
step: 970, loss: 0.12164661288261414
epoch 8: dev_f1=0.9322344322344323, f1=0.9312557286892759, best_f1=0.9299905392620624
step: 0, loss: 0.07566630840301514
step: 10, loss: 0.2238841950893402
step: 20, loss: 0.08038412034511566
step: 30, loss: 0.10975496470928192
step: 40, loss: 0.07033306360244751
step: 50, loss: 0.10613277554512024
step: 60, loss: 0.044359851628541946
step: 70, loss: 0.08716623485088348
step: 80, loss: 0.039141759276390076
step: 90, loss: 0.08185611665248871
step: 100, loss: 0.017163466662168503
step: 110, loss: 0.1071586087346077
step: 120, loss: 0.13606391847133636
step: 130, loss: 0.046404529362916946
step: 140, loss: 0.04111552610993385
step: 150, loss: 0.008901786059141159
step: 160, loss: 0.1102517694234848
step: 170, loss: 0.1331086903810501
step: 180, loss: 0.03623021021485329
step: 190, loss: 0.05192694067955017
step: 200, loss: 0.04291055351495743
step: 210, loss: 0.008851980790495872
step: 220, loss: 0.10599762201309204
step: 230, loss: 0.1969163417816162
step: 240, loss: 0.09754815697669983
step: 250, loss: 0.0309430118650198
step: 260, loss: 0.04568560793995857
step: 270, loss: 0.07214893400669098
step: 280, loss: 0.01989760622382164
step: 290, loss: 0.013528011739253998
step: 300, loss: 0.03327743709087372
step: 310, loss: 0.01684446819126606
step: 320, loss: 0.07984994351863861
step: 330, loss: 0.07213515788316727
step: 340, loss: 0.1782819926738739
step: 350, loss: 0.05176619812846184
step: 360, loss: 0.14448992908000946
step: 370, loss: 0.05293502286076546
step: 380, loss: 0.06157226487994194
step: 390, loss: 0.06178644299507141
step: 400, loss: 0.2019689828157425
step: 410, loss: 0.16000604629516602
step: 420, loss: 0.06254400312900543
step: 430, loss: 0.06935904920101166
step: 440, loss: 0.09108248353004456
step: 450, loss: 0.13211584091186523
step: 460, loss: 0.05201570689678192
step: 470, loss: 0.09169033914804459
step: 480, loss: 0.19317035377025604
step: 490, loss: 0.11351484805345535
step: 500, loss: 0.13018040359020233
step: 510, loss: 0.22692865133285522
step: 520, loss: 0.04287419095635414
step: 530, loss: 0.08530852943658829
step: 540, loss: 0.07597938925027847
step: 550, loss: 0.13279575109481812
step: 560, loss: 0.07045324146747589
step: 570, loss: 0.16241489350795746
step: 580, loss: 0.057432565838098526
step: 590, loss: 0.14251992106437683
step: 600, loss: 0.02955658547580242
step: 610, loss: 0.17584215104579926
step: 620, loss: 0.05305711179971695
step: 630, loss: 0.08641809970140457
step: 640, loss: 0.039663515985012054
step: 650, loss: 0.09801186621189117
step: 660, loss: 0.12513327598571777
step: 670, loss: 0.08333853632211685
step: 680, loss: 0.08518433570861816
step: 690, loss: 0.13648410141468048
step: 700, loss: 0.09548662602901459
step: 710, loss: 0.09170281141996384
step: 720, loss: 0.04122093692421913
step: 730, loss: 0.2047891914844513
step: 740, loss: 0.11116500943899155
step: 750, loss: 0.06547406315803528
step: 760, loss: 0.0302189439535141
step: 770, loss: 0.14160221815109253
step: 780, loss: 0.14524804055690765
step: 790, loss: 0.10706552118062973
step: 800, loss: 0.09996344894170761
step: 810, loss: 0.1809818595647812
step: 820, loss: 0.015802456066012383
step: 830, loss: 0.0760471299290657
step: 840, loss: 0.05606153979897499
step: 850, loss: 0.08247552067041397
step: 860, loss: 0.11070714890956879
step: 870, loss: 0.07442449033260345
step: 880, loss: 0.08955405652523041
step: 890, loss: 0.07558538764715195
step: 900, loss: 0.07151380181312561
step: 910, loss: 0.19965419173240662
step: 920, loss: 0.054518215358257294
step: 930, loss: 0.22128982841968536
step: 940, loss: 0.03256861865520477
step: 950, loss: 0.04108937457203865
step: 960, loss: 0.03755855932831764
step: 970, loss: 0.061991263180971146
epoch 9: dev_f1=0.9306197964847363, f1=0.9292649098474343, best_f1=0.9299905392620624
step: 0, loss: 0.0804831013083458
step: 10, loss: 0.12755592167377472
step: 20, loss: 0.10366843640804291
step: 30, loss: 0.08245562762022018
step: 40, loss: 0.1146092489361763
step: 50, loss: 0.015529822558164597
step: 60, loss: 0.08057738840579987
step: 70, loss: 0.12011658400297165
step: 80, loss: 0.04735999181866646
step: 90, loss: 0.15875878930091858
step: 100, loss: 0.0690794587135315
step: 110, loss: 0.07171700149774551
step: 120, loss: 0.1028580442070961
step: 130, loss: 0.06218639016151428
step: 140, loss: 0.029656603932380676
step: 150, loss: 0.034700147807598114
step: 160, loss: 0.07193221151828766
step: 170, loss: 0.12107738107442856
step: 180, loss: 0.017071599140763283
step: 190, loss: 0.0718126967549324
step: 200, loss: 0.01974257081747055
step: 210, loss: 0.3205353617668152
step: 220, loss: 0.11214000731706619
step: 230, loss: 0.017100658267736435
step: 240, loss: 0.06626123934984207
step: 250, loss: 0.43717721104621887
step: 260, loss: 0.013424132019281387
step: 270, loss: 0.11081438511610031
step: 280, loss: 0.025791537016630173
step: 290, loss: 0.045795951038599014
step: 300, loss: 0.055243320763111115
step: 310, loss: 0.043558113276958466
step: 320, loss: 0.05244980752468109
step: 330, loss: 0.2575400173664093
step: 340, loss: 0.2183343768119812
step: 350, loss: 0.09625418484210968
step: 360, loss: 0.036751408129930496
step: 370, loss: 0.021669412031769753
step: 380, loss: 0.12563300132751465
step: 390, loss: 0.09900624305009842
step: 400, loss: 0.07890881597995758
step: 410, loss: 0.08095435798168182
step: 420, loss: 0.04593940079212189
step: 430, loss: 0.040086809545755386
step: 440, loss: 0.028575588017702103
step: 450, loss: 0.05859176069498062
step: 460, loss: 0.16725294291973114
step: 470, loss: 0.019975027069449425
step: 480, loss: 0.07814257591962814
step: 490, loss: 0.05278885364532471
step: 500, loss: 0.1753096878528595
step: 510, loss: 0.1341877579689026
step: 520, loss: 0.12481784075498581
step: 530, loss: 0.010946354828774929
step: 540, loss: 0.17945343255996704
step: 550, loss: 0.047243375331163406
step: 560, loss: 0.060977667570114136
step: 570, loss: 0.04855864867568016
step: 580, loss: 0.1868916153907776
step: 590, loss: 0.14320211112499237
step: 600, loss: 0.06278079748153687
step: 610, loss: 0.0019585881382226944
step: 620, loss: 0.11378105729818344
step: 630, loss: 0.06752068549394608
step: 640, loss: 0.15060490369796753
step: 650, loss: 0.08935745060443878
step: 660, loss: 0.060345347970724106
step: 670, loss: 0.09730307012796402
step: 680, loss: 0.03385074809193611
step: 690, loss: 0.13950753211975098
step: 700, loss: 0.06619170308113098
step: 710, loss: 0.1130710244178772
step: 720, loss: 0.059892792254686356
step: 730, loss: 0.06956464052200317
step: 740, loss: 0.08292887359857559
step: 750, loss: 0.08735388517379761
step: 760, loss: 0.1244949996471405
step: 770, loss: 0.021478066220879555
step: 780, loss: 0.17016316950321198
step: 790, loss: 0.031941261142492294
step: 800, loss: 0.07505998015403748
step: 810, loss: 0.047823138535022736
step: 820, loss: 0.11574243009090424
step: 830, loss: 0.07887738943099976
step: 840, loss: 0.13485625386238098
step: 850, loss: 0.02831752970814705
step: 860, loss: 0.02260660007596016
step: 870, loss: 0.07773951441049576
step: 880, loss: 0.054411206394433975
step: 890, loss: 0.10239892452955246
step: 900, loss: 0.03681992366909981
step: 910, loss: 0.052231743931770325
step: 920, loss: 0.1883375197649002
step: 930, loss: 0.008658596314489841
step: 940, loss: 0.06768035143613815
step: 950, loss: 0.06202460452914238
step: 960, loss: 0.1464267373085022
step: 970, loss: 0.15865658223628998
epoch 10: dev_f1=0.935278030993619, f1=0.9305936073059361, best_f1=0.9305936073059361
step: 0, loss: 0.10661740601062775
step: 10, loss: 0.17543473839759827
step: 20, loss: 0.03475740924477577
step: 30, loss: 0.08684675395488739
step: 40, loss: 0.11400395631790161
step: 50, loss: 0.06781405210494995
step: 60, loss: 0.01616612821817398
step: 70, loss: 0.0728202760219574
step: 80, loss: 0.11062116175889969
step: 90, loss: 0.020868340507149696
step: 100, loss: 0.04187052324414253
step: 110, loss: 0.024336902424693108
step: 120, loss: 0.05049673467874527
step: 130, loss: 0.018981965258717537
step: 140, loss: 0.05315655469894409
step: 150, loss: 0.14095796644687653
step: 160, loss: 0.04857159033417702
step: 170, loss: 0.032137155532836914
step: 180, loss: 0.11167562007904053
step: 190, loss: 0.04688530042767525
step: 200, loss: 0.058641217648983
step: 210, loss: 0.12548288702964783
step: 220, loss: 0.11286833137273788
step: 230, loss: 0.08114247769117355
step: 240, loss: 0.08731704950332642
step: 250, loss: 0.11968210339546204
step: 260, loss: 0.14335282146930695
step: 270, loss: 0.013932084664702415
step: 280, loss: 0.03625744953751564
step: 290, loss: 0.03806724026799202
step: 300, loss: 0.04444485902786255
step: 310, loss: 0.04957422986626625
step: 320, loss: 0.007494400721043348
step: 330, loss: 0.05080179497599602
step: 340, loss: 0.060156211256980896
step: 350, loss: 0.09919275343418121
step: 360, loss: 0.1049806997179985
step: 370, loss: 0.13959236443042755
step: 380, loss: 0.04243307188153267
step: 390, loss: 0.1485438346862793
step: 400, loss: 0.07508190721273422
step: 410, loss: 0.14456050097942352
step: 420, loss: 0.040743038058280945
step: 430, loss: 0.028322745114564896
step: 440, loss: 0.143495574593544
step: 450, loss: 0.05740614980459213
step: 460, loss: 0.030717473477125168
step: 470, loss: 0.006201832089573145
step: 480, loss: 0.09833972901105881
step: 490, loss: 0.04732629284262657
step: 500, loss: 0.08741535991430283
step: 510, loss: 0.09644019603729248
step: 520, loss: 0.09836079180240631
step: 530, loss: 0.016846835613250732
step: 540, loss: 0.0886082574725151
step: 550, loss: 0.1948208212852478
step: 560, loss: 0.06511867046356201
step: 570, loss: 0.06182629242539406
step: 580, loss: 0.10556011646986008
step: 590, loss: 0.20612025260925293
step: 600, loss: 0.09377562999725342
step: 610, loss: 0.04699840769171715
step: 620, loss: 0.16409972310066223
step: 630, loss: 0.19021791219711304
step: 640, loss: 0.08507344871759415
step: 650, loss: 0.044555891305208206
step: 660, loss: 0.056066978722810745
step: 670, loss: 0.07237671315670013
step: 680, loss: 0.028446052223443985
step: 690, loss: 0.0670718401670456
step: 700, loss: 0.06610342115163803
step: 710, loss: 0.0766313225030899
step: 720, loss: 0.04465891793370247
step: 730, loss: 0.12506090104579926
step: 740, loss: 0.054687172174453735
step: 750, loss: 0.11114383488893509
step: 760, loss: 0.07566016167402267
step: 770, loss: 0.025401877239346504
step: 780, loss: 0.03004404529929161
step: 790, loss: 0.09157054871320724
step: 800, loss: 0.11917994171380997
step: 810, loss: 0.09458271414041519
step: 820, loss: 0.09514971822500229
step: 830, loss: 0.07892142236232758
step: 840, loss: 0.04924728721380234
step: 850, loss: 0.0645492821931839
step: 860, loss: 0.09770575165748596
step: 870, loss: 0.03874737769365311
step: 880, loss: 0.13682150840759277
step: 890, loss: 0.12097185105085373
step: 900, loss: 0.1034998819231987
step: 910, loss: 0.046669136732816696
step: 920, loss: 0.018075844272971153
step: 930, loss: 0.03162543848156929
step: 940, loss: 0.07814113795757294
step: 950, loss: 0.07266610115766525
step: 960, loss: 0.10168023407459259
step: 970, loss: 0.06046347692608833
epoch 11: dev_f1=0.9255121042830541, f1=0.9267161410018553, best_f1=0.9305936073059361
step: 0, loss: 0.17287728190422058
step: 10, loss: 0.01908191293478012
step: 20, loss: 0.12565895915031433
step: 30, loss: 0.04338706657290459
step: 40, loss: 0.05101534351706505
step: 50, loss: 0.031163830310106277
step: 60, loss: 0.01843332126736641
step: 70, loss: 0.036493055522441864
step: 80, loss: 0.05268789455294609
step: 90, loss: 0.10061830282211304
step: 100, loss: 0.020601261407136917
step: 110, loss: 0.034909188747406006
step: 120, loss: 0.10750183463096619
step: 130, loss: 0.2882763147354126
step: 140, loss: 0.011992965824902058
step: 150, loss: 0.13571062684059143
step: 160, loss: 0.2050655633211136
step: 170, loss: 0.027445966377854347
step: 180, loss: 0.1263922154903412
step: 190, loss: 0.04906828701496124
step: 200, loss: 0.029061466455459595
step: 210, loss: 0.023702695965766907
step: 220, loss: 0.04589856415987015
step: 230, loss: 0.035358328372240067
step: 240, loss: 0.08646173775196075
step: 250, loss: 0.0058461762964725494
step: 260, loss: 0.0038556454237550497
step: 270, loss: 0.007371711544692516
step: 280, loss: 0.09868114441633224
step: 290, loss: 0.04262999817728996
step: 300, loss: 0.017105935141444206
step: 310, loss: 0.03257356584072113
step: 320, loss: 0.05136033520102501
step: 330, loss: 0.20354731380939484
step: 340, loss: 0.11783234030008316
step: 350, loss: 0.058018606156110764
step: 360, loss: 0.08144500106573105
step: 370, loss: 0.07034630328416824
step: 380, loss: 0.027223287150263786
step: 390, loss: 0.08204009383916855
step: 400, loss: 0.01694503426551819
step: 410, loss: 0.0884207934141159
step: 420, loss: 0.10362689197063446
step: 430, loss: 0.13590186834335327
step: 440, loss: 0.03998403996229172
step: 450, loss: 0.16420426964759827
step: 460, loss: 0.044222746044397354
step: 470, loss: 0.0864664614200592
step: 480, loss: 0.11524461954832077
step: 490, loss: 0.12512792646884918
step: 500, loss: 0.004963010549545288
step: 510, loss: 0.09067338705062866
step: 520, loss: 0.027528826147317886
step: 530, loss: 0.07232405245304108
step: 540, loss: 0.13080772757530212
step: 550, loss: 0.10517971217632294
step: 560, loss: 0.07929426431655884
step: 570, loss: 0.046842675656080246
step: 580, loss: 0.044175587594509125
step: 590, loss: 0.17913760244846344
step: 600, loss: 0.02187376096844673
step: 610, loss: 0.09644221514463425
step: 620, loss: 0.005772920325398445
step: 630, loss: 0.06967706233263016
step: 640, loss: 0.09014713019132614
step: 650, loss: 0.07920784503221512
step: 660, loss: 0.10805732756853104
step: 670, loss: 0.09815506637096405
step: 680, loss: 0.07755919545888901
step: 690, loss: 0.15289437770843506
step: 700, loss: 0.18625368177890778
step: 710, loss: 0.017922520637512207
step: 720, loss: 0.006498465780168772
step: 730, loss: 0.14793440699577332
step: 740, loss: 0.028389565646648407
step: 750, loss: 0.10989009588956833
step: 760, loss: 0.045046012848615646
step: 770, loss: 0.07825396955013275
step: 780, loss: 0.12059054523706436
step: 790, loss: 0.04891034960746765
step: 800, loss: 0.1279657483100891
step: 810, loss: 0.05435170233249664
step: 820, loss: 0.08545921742916107
step: 830, loss: 0.003946367651224136
step: 840, loss: 0.05813410505652428
step: 850, loss: 0.02641473338007927
step: 860, loss: 0.08170005679130554
step: 870, loss: 0.10992328822612762
step: 880, loss: 0.004354227799922228
step: 890, loss: 0.06537426263093948
step: 900, loss: 0.06211589276790619
step: 910, loss: 0.08319296687841415
step: 920, loss: 0.13055185973644257
step: 930, loss: 0.12325141578912735
step: 940, loss: 0.05958286672830582
step: 950, loss: 0.06120232865214348
step: 960, loss: 0.01990710385143757
step: 970, loss: 0.028276754543185234
epoch 12: dev_f1=0.9302325581395349, f1=0.9245107176141659, best_f1=0.9305936073059361
step: 0, loss: 0.04571980983018875
step: 10, loss: 0.018673349171876907
step: 20, loss: 0.11103405803442001
step: 30, loss: 0.057652223855257034
step: 40, loss: 0.04994567483663559
step: 50, loss: 0.09349996596574783
step: 60, loss: 0.059030383825302124
step: 70, loss: 0.03826215863227844
step: 80, loss: 0.042787205427885056
step: 90, loss: 0.0011073658242821693
step: 100, loss: 0.17690809071063995
step: 110, loss: 0.07700275629758835
step: 120, loss: 0.1070241779088974
step: 130, loss: 0.08732642233371735
step: 140, loss: 0.031220853328704834
step: 150, loss: 0.056625910103321075
step: 160, loss: 0.05954023823142052
step: 170, loss: 0.030264001339673996
step: 180, loss: 0.04613311588764191
step: 190, loss: 0.03973810374736786
step: 200, loss: 0.03075348027050495
step: 210, loss: 0.0239200871437788
step: 220, loss: 0.06502389907836914
step: 230, loss: 0.02999841421842575
step: 240, loss: 0.11430111527442932
step: 250, loss: 0.10959140956401825
step: 260, loss: 0.08503913134336472
step: 270, loss: 0.07685192674398422
step: 280, loss: 0.060883425176143646
step: 290, loss: 0.011851750314235687
step: 300, loss: 0.08546116948127747
step: 310, loss: 0.07597116380929947
step: 320, loss: 0.05313853546977043
step: 330, loss: 0.06668643653392792
step: 340, loss: 0.0971396416425705
step: 350, loss: 0.05158820003271103
step: 360, loss: 0.11283719539642334
step: 370, loss: 0.10106982290744781
step: 380, loss: 0.04982605203986168
step: 390, loss: 0.1335948407649994
step: 400, loss: 0.04587351903319359
step: 410, loss: 0.09552522748708725
step: 420, loss: 0.09012170881032944
step: 430, loss: 0.06594698131084442
step: 440, loss: 0.032778091728687286
step: 450, loss: 0.1180918738245964
step: 460, loss: 0.05398279428482056
step: 470, loss: 0.13978630304336548
step: 480, loss: 0.04938645660877228
step: 490, loss: 0.08580756932497025
step: 500, loss: 0.06366296857595444
step: 510, loss: 0.15757115185260773
step: 520, loss: 0.0334441177546978
step: 530, loss: 0.09222538024187088
step: 540, loss: 0.027934841811656952
step: 550, loss: 0.0682249441742897
step: 560, loss: 0.00590079789981246
step: 570, loss: 0.027298038825392723
step: 580, loss: 0.06711075454950333
step: 590, loss: 0.17220143973827362
step: 600, loss: 0.0863402932882309
step: 610, loss: 0.03694455325603485
step: 620, loss: 0.10845145583152771
step: 630, loss: 0.15150855481624603
step: 640, loss: 0.08919844031333923
step: 650, loss: 0.029873056337237358
step: 660, loss: 0.07603121548891068
step: 670, loss: 0.1287582963705063
step: 680, loss: 0.17693191766738892
step: 690, loss: 0.1837211400270462
step: 700, loss: 0.045371223241090775
step: 710, loss: 0.05881770700216293
step: 720, loss: 0.031128225848078728
step: 730, loss: 0.02140767313539982
step: 740, loss: 0.10913555324077606
step: 750, loss: 0.10389040410518646
step: 760, loss: 0.07823842018842697
step: 770, loss: 0.05534806102514267
step: 780, loss: 0.01981380209326744
step: 790, loss: 0.04482514411211014
step: 800, loss: 0.0586540624499321
step: 810, loss: 0.09181179851293564
step: 820, loss: 0.10989478975534439
step: 830, loss: 0.07992161810398102
step: 840, loss: 0.11712625622749329
step: 850, loss: 0.0010865629883483052
step: 860, loss: 0.15018337965011597
step: 870, loss: 0.12097137421369553
step: 880, loss: 0.08181808143854141
step: 890, loss: 0.1186710074543953
step: 900, loss: 0.04087477922439575
step: 910, loss: 0.07908874750137329
step: 920, loss: 0.1673039048910141
step: 930, loss: 0.1124374121427536
step: 940, loss: 0.07825562357902527
step: 950, loss: 0.08189072459936142
step: 960, loss: 0.12265076488256454
step: 970, loss: 0.03302231803536415
epoch 13: dev_f1=0.9305816135084428, f1=0.9282027217268888, best_f1=0.9305936073059361
step: 0, loss: 0.033094484359025955
step: 10, loss: 0.06621216237545013
step: 20, loss: 0.14018389582633972
step: 30, loss: 0.06619011610746384
step: 40, loss: 0.013071398250758648
step: 50, loss: 0.002195167588070035
step: 60, loss: 0.10835759341716766
step: 70, loss: 0.04754447191953659
step: 80, loss: 0.051252685487270355
step: 90, loss: 0.05771242827177048
step: 100, loss: 0.22623184323310852
step: 110, loss: 0.07356042414903641
step: 120, loss: 0.052999284118413925
step: 130, loss: 0.03582735359668732
step: 140, loss: 0.015035955235362053
step: 150, loss: 0.15821915864944458
step: 160, loss: 0.04246768727898598
step: 170, loss: 0.08033357560634613
step: 180, loss: 0.03094617836177349
step: 190, loss: 0.0220160111784935
step: 200, loss: 0.12285244464874268
step: 210, loss: 0.01707225851714611
step: 220, loss: 0.04804261028766632
step: 230, loss: 0.124432273209095
step: 240, loss: 0.0687767043709755
step: 250, loss: 0.14630578458309174
step: 260, loss: 0.025439957156777382
step: 270, loss: 0.03417569771409035
step: 280, loss: 0.08115404844284058
step: 290, loss: 0.05078747868537903
step: 300, loss: 0.06510557234287262
step: 310, loss: 0.020796632394194603
step: 320, loss: 0.020167555660009384
step: 330, loss: 0.03500862792134285
step: 340, loss: 0.09349188208580017
step: 350, loss: 0.024167228490114212
step: 360, loss: 0.0006288638105615973
step: 370, loss: 0.10041824728250504
step: 380, loss: 0.005209386348724365
step: 390, loss: 0.035266079008579254
step: 400, loss: 0.22735296189785004
step: 410, loss: 0.20634663105010986
step: 420, loss: 0.02985125221312046
step: 430, loss: 0.07341526448726654
step: 440, loss: 0.02578609064221382
step: 450, loss: 0.015281462110579014
step: 460, loss: 0.028144555166363716
step: 470, loss: 0.09390603750944138
step: 480, loss: 0.11080168932676315
step: 490, loss: 0.044037915766239166
step: 500, loss: 0.0799170508980751
step: 510, loss: 0.05867923051118851
step: 520, loss: 0.08044401556253433
step: 530, loss: 0.08203750103712082
step: 540, loss: 0.01913457177579403
step: 550, loss: 0.03176755830645561
step: 560, loss: 0.15058419108390808
step: 570, loss: 0.08894356340169907
step: 580, loss: 0.12813133001327515
step: 590, loss: 0.07625506818294525
step: 600, loss: 0.06738752126693726
step: 610, loss: 0.07714057713747025
step: 620, loss: 0.025113072246313095
step: 630, loss: 0.04504312947392464
step: 640, loss: 0.18815158307552338
step: 650, loss: 0.0815148651599884
step: 660, loss: 0.11454769223928452
step: 670, loss: 0.06634945422410965
step: 680, loss: 0.04323171079158783
step: 690, loss: 0.024072768166661263
step: 700, loss: 0.0216460470110178
step: 710, loss: 0.08749565482139587
step: 720, loss: 0.05749979987740517
step: 730, loss: 0.07784214615821838
step: 740, loss: 0.17602333426475525
step: 750, loss: 0.08945488929748535
step: 760, loss: 0.006280891597270966
step: 770, loss: 0.039309918880462646
step: 780, loss: 0.025406472384929657
step: 790, loss: 0.08884166181087494
step: 800, loss: 0.007067194674164057
step: 810, loss: 0.10430949181318283
step: 820, loss: 0.04415959119796753
step: 830, loss: 0.05263463407754898
step: 840, loss: 0.06847631186246872
step: 850, loss: 0.12040974199771881
step: 860, loss: 0.08011557161808014
step: 870, loss: 0.09702981263399124
step: 880, loss: 0.0638696551322937
step: 890, loss: 0.06575372815132141
step: 900, loss: 0.03925745189189911
step: 910, loss: 0.06481513381004333
step: 920, loss: 0.0553140826523304
step: 930, loss: 0.08987176418304443
step: 940, loss: 0.19948501884937286
step: 950, loss: 0.09938154369592667
step: 960, loss: 0.08337046205997467
step: 970, loss: 0.13683807849884033
epoch 14: dev_f1=0.9288040949278734, f1=0.929170549860205, best_f1=0.9305936073059361
step: 0, loss: 0.04541050270199776
step: 10, loss: 0.0981956496834755
step: 20, loss: 0.11500876396894455
step: 30, loss: 0.013530912809073925
step: 40, loss: 0.0217136163264513
step: 50, loss: 0.05769846588373184
step: 60, loss: 5.2076284191571176e-05
step: 70, loss: 0.11122624576091766
step: 80, loss: 0.04295874759554863
step: 90, loss: 0.12849918007850647
step: 100, loss: 0.08060868084430695
step: 110, loss: 0.06065315008163452
step: 120, loss: 0.06501779705286026
step: 130, loss: 0.06239864230155945
step: 140, loss: 0.0016906997188925743
step: 150, loss: 0.058087851852178574
step: 160, loss: 0.029463842511177063
step: 170, loss: 0.0002918782120104879
step: 180, loss: 0.0331278033554554
step: 190, loss: 0.039258673787117004
step: 200, loss: 0.029719818383455276
step: 210, loss: 0.005745267029851675
step: 220, loss: 0.049554742872714996
step: 230, loss: 0.021816737949848175
step: 240, loss: 0.058968860656023026
step: 250, loss: 0.08159752935171127
step: 260, loss: 0.08850853890180588
step: 270, loss: 0.0663510113954544
step: 280, loss: 0.1564621925354004
step: 290, loss: 0.05598895251750946
step: 300, loss: 0.08469368517398834
step: 310, loss: 0.08092350512742996
step: 320, loss: 0.0076171536929905415
step: 330, loss: 0.0638900175690651
step: 340, loss: 0.04247908666729927
step: 350, loss: 0.06979783624410629
step: 360, loss: 0.024611391127109528
step: 370, loss: 0.044769659638404846
step: 380, loss: 0.029109900817275047
step: 390, loss: 0.05861489474773407
step: 400, loss: 0.14653414487838745
step: 410, loss: 0.1730504184961319
step: 420, loss: 0.08404455333948135
step: 430, loss: 0.003251647809520364
step: 440, loss: 0.1322985738515854
step: 450, loss: 0.09725285321474075
step: 460, loss: 0.06695045530796051
step: 470, loss: 0.016606975346803665
step: 480, loss: 0.12384692579507828
step: 490, loss: 0.024451566860079765
step: 500, loss: 0.03863148391246796
step: 510, loss: 0.05600951611995697
step: 520, loss: 0.05414453148841858
step: 530, loss: 0.11954018473625183
step: 540, loss: 0.02467283047735691
step: 550, loss: 0.06724537163972855
step: 560, loss: 0.09494483470916748
step: 570, loss: 0.11754739284515381
step: 580, loss: 0.10081549733877182
step: 590, loss: 0.11425961554050446
step: 600, loss: 0.0459744893014431
step: 610, loss: 0.2334684133529663
step: 620, loss: 0.06773140281438828
step: 630, loss: 0.14459122717380524
step: 640, loss: 0.01798419840633869
step: 650, loss: 0.06091234087944031
step: 660, loss: 0.09759241342544556
step: 670, loss: 0.1532878577709198
step: 680, loss: 0.10415951162576675
step: 690, loss: 0.03941585496068001
step: 700, loss: 0.09607291221618652
step: 710, loss: 0.06263464689254761
step: 720, loss: 0.08124230802059174
step: 730, loss: 0.12061164528131485
step: 740, loss: 0.053009796887636185
step: 750, loss: 0.05209216848015785
step: 760, loss: 0.02186635695397854
step: 770, loss: 0.012809470295906067
step: 780, loss: 0.06983152031898499
step: 790, loss: 0.03183434531092644
step: 800, loss: 0.08069214224815369
step: 810, loss: 0.10284200310707092
step: 820, loss: 0.028765255585312843
step: 830, loss: 0.041151195764541626
step: 840, loss: 0.005568379536271095
step: 850, loss: 0.11131586879491806
step: 860, loss: 0.006120895501226187
step: 870, loss: 0.03322698548436165
step: 880, loss: 0.06935255229473114
step: 890, loss: 0.19347743690013885
step: 900, loss: 0.07182152569293976
step: 910, loss: 0.15064065158367157
step: 920, loss: 0.029084958136081696
step: 930, loss: 0.0670466274023056
step: 940, loss: 0.007911140099167824
step: 950, loss: 0.026709357276558876
step: 960, loss: 0.04483801871538162
step: 970, loss: 0.0038787368685007095
epoch 15: dev_f1=0.9299303944315545, f1=0.927348449791763, best_f1=0.9305936073059361
step: 0, loss: 0.08011805266141891
step: 10, loss: 0.11159516870975494
step: 20, loss: 0.07650399953126907
step: 30, loss: 0.005130382254719734
step: 40, loss: 0.11510992795228958
step: 50, loss: 0.0772956907749176
step: 60, loss: 0.1053462103009224
step: 70, loss: 0.02770320698618889
step: 80, loss: 0.002022969303652644
step: 90, loss: 0.056810054928064346
step: 100, loss: 0.12518082559108734
step: 110, loss: 0.05349040776491165
step: 120, loss: 0.04268693923950195
step: 130, loss: 0.025453202426433563
step: 140, loss: 0.016023457050323486
step: 150, loss: 0.039345115423202515
step: 160, loss: 1.5288069334928878e-05
step: 170, loss: 0.11007143557071686
step: 180, loss: 0.08157753944396973
step: 190, loss: 0.011459670960903168
step: 200, loss: 0.02447623386979103
step: 210, loss: 0.08022703975439072
step: 220, loss: 0.036658644676208496
step: 230, loss: 0.007255862466990948
step: 240, loss: 0.051854874938726425
step: 250, loss: 0.06927251070737839
step: 260, loss: 0.06465183198451996
step: 270, loss: 0.10577638447284698
step: 280, loss: 0.02714867889881134
step: 290, loss: 0.05735207721590996
step: 300, loss: 0.04251128062605858
step: 310, loss: 0.04858539626002312
step: 320, loss: 0.047588467597961426
step: 330, loss: 0.029340963810682297
step: 340, loss: 0.054073844105005264
step: 350, loss: 0.01674254983663559
step: 360, loss: 0.06317299604415894
step: 370, loss: 0.03785315155982971
step: 380, loss: 0.07492802292108536
step: 390, loss: 0.030873052775859833
step: 400, loss: 0.03117934986948967
step: 410, loss: 0.029205776751041412
step: 420, loss: 0.046824708580970764
step: 430, loss: 0.05605237931013107
step: 440, loss: 0.10379387438297272
step: 450, loss: 0.000143302560900338
step: 460, loss: 0.15216954052448273
step: 470, loss: 0.1060870960354805
step: 480, loss: 0.08459744602441788
step: 490, loss: 0.15951770544052124
step: 500, loss: 0.07261823862791061
step: 510, loss: 0.13996706902980804
step: 520, loss: 0.09124914556741714
step: 530, loss: 0.022661808878183365
step: 540, loss: 0.1232328787446022
step: 550, loss: 0.12603023648262024
step: 560, loss: 0.13500148057937622
step: 570, loss: 0.05354408547282219
step: 580, loss: 0.09827914088964462
step: 590, loss: 0.06722309440374374
step: 600, loss: 0.03578520566225052
step: 610, loss: 0.052625544369220734
step: 620, loss: 0.11261191964149475
step: 630, loss: 0.09746285527944565
step: 640, loss: 0.04054888337850571
step: 650, loss: 0.06184779852628708
step: 660, loss: 0.04360080510377884
step: 670, loss: 0.17272059619426727
step: 680, loss: 0.03018369898200035
step: 690, loss: 0.030071115121245384
step: 700, loss: 0.06980963051319122
step: 710, loss: 0.11979004740715027
step: 720, loss: 0.01802694797515869
step: 730, loss: 0.11680862307548523
step: 740, loss: 0.08474940806627274
step: 750, loss: 0.052678585052490234
step: 760, loss: 0.062404435127973557
step: 770, loss: 0.04029366746544838
step: 780, loss: 0.08729928731918335
step: 790, loss: 0.04953983798623085
step: 800, loss: 0.04401157796382904
step: 810, loss: 0.05127637833356857
step: 820, loss: 0.019100423902273178
step: 830, loss: 0.10588880628347397
step: 840, loss: 0.0430045910179615
step: 850, loss: 0.018302759155631065
step: 860, loss: 0.052973031997680664
step: 870, loss: 0.05905051529407501
step: 880, loss: 0.027802476659417152
step: 890, loss: 0.059951115399599075
step: 900, loss: 0.12368922680616379
step: 910, loss: 0.08345672488212585
step: 920, loss: 0.10107259452342987
step: 930, loss: 0.09391236305236816
step: 940, loss: 0.058799270540475845
step: 950, loss: 0.10782016068696976
step: 960, loss: 0.07106227427721024
step: 970, loss: 0.00833016075193882
epoch 16: dev_f1=0.9322191272051997, f1=0.9298653042266605, best_f1=0.9305936073059361
step: 0, loss: 0.00025416977587156
step: 10, loss: 0.0768251121044159
step: 20, loss: 0.0828142762184143
step: 30, loss: 0.008506129495799541
step: 40, loss: 0.0962822362780571
step: 50, loss: 0.01984628289937973
step: 60, loss: 5.0476483011152595e-05
step: 70, loss: 0.0315033458173275
step: 80, loss: 0.10248482972383499
step: 90, loss: 0.07608357071876526
step: 100, loss: 0.06532586365938187
step: 110, loss: 6.665354885626584e-05
step: 120, loss: 0.12544594705104828
step: 130, loss: 0.03461886942386627
step: 140, loss: 0.019199395552277565
step: 150, loss: 0.021655408665537834
step: 160, loss: 0.030818715691566467
step: 170, loss: 0.01724177971482277
step: 180, loss: 0.060485489666461945
step: 190, loss: 0.04344705119729042
step: 200, loss: 0.04084617272019386
step: 210, loss: 0.10620344430208206
step: 220, loss: 0.024893170222640038
step: 230, loss: 0.06210840120911598
step: 240, loss: 0.08342581242322922
step: 250, loss: 0.208225816488266
step: 260, loss: 0.01743803173303604
step: 270, loss: 0.08836282044649124
step: 280, loss: 0.09194955974817276
step: 290, loss: 0.0001754957775119692
step: 300, loss: 0.09550876915454865
step: 310, loss: 0.15523508191108704
step: 320, loss: 0.014187999069690704
step: 330, loss: 0.047557901591062546
step: 340, loss: 0.07264380156993866
step: 350, loss: 0.05782366916537285
step: 360, loss: 0.0016184982378035784
step: 370, loss: 0.01700722798705101
step: 380, loss: 0.06587114185094833
step: 390, loss: 0.054738059639930725
step: 400, loss: 0.00023537848028354347
step: 410, loss: 0.017744870856404305
step: 420, loss: 0.006677164230495691
step: 430, loss: 0.0276760533452034
step: 440, loss: 0.055806297808885574
step: 450, loss: 0.0649423599243164
step: 460, loss: 0.05926579609513283
step: 470, loss: 0.04660825431346893
step: 480, loss: 0.04566028714179993
step: 490, loss: 0.07031922042369843
step: 500, loss: 0.1740598976612091
step: 510, loss: 0.041135918349027634
step: 520, loss: 0.09289991855621338
step: 530, loss: 0.018063774332404137
step: 540, loss: 0.03515727445483208
step: 550, loss: 0.08913079649209976
step: 560, loss: 0.09485582262277603
step: 570, loss: 0.06534542888402939
step: 580, loss: 0.049508072435855865
step: 590, loss: 0.03450727090239525
step: 600, loss: 0.10054326057434082
step: 610, loss: 0.0017871238524094224
step: 620, loss: 0.04790273308753967
step: 630, loss: 0.00035063797258771956
step: 640, loss: 0.08994127810001373
step: 650, loss: 0.10710971057415009
step: 660, loss: 0.025772036984562874
step: 670, loss: 0.04713006317615509
step: 680, loss: 0.025495998561382294
step: 690, loss: 0.05373970791697502
step: 700, loss: 0.056632086634635925
step: 710, loss: 0.04845578223466873
step: 720, loss: 0.06723098456859589
step: 730, loss: 0.20079417526721954
step: 740, loss: 0.011320878751575947
step: 750, loss: 0.15092837810516357
step: 760, loss: 0.08603524416685104
step: 770, loss: 0.04416301101446152
step: 780, loss: 0.04336857050657272
step: 790, loss: 0.02476276457309723
step: 800, loss: 0.10488487035036087
step: 810, loss: 0.06251903623342514
step: 820, loss: 0.14805057644844055
step: 830, loss: 0.05336910858750343
step: 840, loss: 0.06570498645305634
step: 850, loss: 0.004396549426019192
step: 860, loss: 0.024640532210469246
step: 870, loss: 0.004372383933514357
step: 880, loss: 0.04604196175932884
step: 890, loss: 0.08667939156293869
step: 900, loss: 0.09092383086681366
step: 910, loss: 0.11185208708047867
step: 920, loss: 0.04211020469665527
step: 930, loss: 0.0634317696094513
step: 940, loss: 0.00010626636503729969
step: 950, loss: 0.01842658594250679
step: 960, loss: 0.05746849253773689
step: 970, loss: 0.05801190063357353
epoch 17: dev_f1=0.9302325581395349, f1=0.9282385834109972, best_f1=0.9305936073059361
step: 0, loss: 0.05037202686071396
step: 10, loss: 0.11476050317287445
step: 20, loss: 0.07429566979408264
step: 30, loss: 0.04728660732507706
step: 40, loss: 0.02103568986058235
step: 50, loss: 0.06706631928682327
step: 60, loss: 0.07087387144565582
step: 70, loss: 0.020383724942803383
step: 80, loss: 0.0002744028461165726
step: 90, loss: 0.02054441347718239
step: 100, loss: 0.034318625926971436
step: 110, loss: 0.07680066674947739
step: 120, loss: 0.0009854873642325401
step: 130, loss: 0.016478370875120163
step: 140, loss: 0.09248729795217514
step: 150, loss: 0.01407263707369566
step: 160, loss: 0.08092707395553589
step: 170, loss: 0.024070797488093376
step: 180, loss: 0.06681499630212784
step: 190, loss: 0.03480523079633713
step: 200, loss: 0.016123060137033463
step: 210, loss: 0.021638495847582817
step: 220, loss: 0.03603701665997505
step: 230, loss: 0.05575269088149071
step: 240, loss: 0.06827432662248611
step: 250, loss: 0.06752689927816391
step: 260, loss: 0.0670529156923294
step: 270, loss: 0.036014046519994736
step: 280, loss: 0.03931376338005066
step: 290, loss: 0.061868857592344284
step: 300, loss: 0.05037327855825424
step: 310, loss: 0.005210853647440672
step: 320, loss: 0.09514708817005157
step: 330, loss: 0.0661289319396019
step: 340, loss: 0.02746044099330902
step: 350, loss: 0.07142919301986694
step: 360, loss: 0.05283545330166817
step: 370, loss: 0.051273591816425323
step: 380, loss: 0.016033129766583443
step: 390, loss: 0.10640688240528107
step: 400, loss: 0.07612644881010056
step: 410, loss: 0.07067820429801941
step: 420, loss: 0.02398475632071495
step: 430, loss: 0.04574151337146759
step: 440, loss: 0.013109724968671799
step: 450, loss: 0.05176692456007004
step: 460, loss: 0.010441025719046593
step: 470, loss: 0.00022920622723177075
step: 480, loss: 0.10877295583486557
step: 490, loss: 0.09781204909086227
step: 500, loss: 0.09577807784080505
step: 510, loss: 0.04776406288146973
step: 520, loss: 0.05693582072854042
step: 530, loss: 0.03247464820742607
step: 540, loss: 0.009478402324020863
step: 550, loss: 0.061620451509952545
step: 560, loss: 0.07908971607685089
step: 570, loss: 0.023532239720225334
step: 580, loss: 0.013649225234985352
step: 590, loss: 0.12646199762821198
step: 600, loss: 0.10968931019306183
step: 610, loss: 0.06790751963853836
step: 620, loss: 0.015285870991647243
step: 630, loss: 0.040226709097623825
step: 640, loss: 0.0022038458846509457
step: 650, loss: 0.12362155318260193
step: 660, loss: 0.1358957588672638
step: 670, loss: 0.03499637171626091
step: 680, loss: 0.03634478896856308
step: 690, loss: 0.07075010985136032
step: 700, loss: 0.018965907394886017
step: 710, loss: 0.06565364450216293
step: 720, loss: 0.031263887882232666
step: 730, loss: 0.0037709095049649477
step: 740, loss: 0.1100919246673584
step: 750, loss: 0.07744494080543518
step: 760, loss: 0.14706620573997498
step: 770, loss: 0.09160462021827698
step: 780, loss: 0.07273600250482559
step: 790, loss: 0.06407132744789124
step: 800, loss: 0.05768066272139549
step: 810, loss: 3.9923197618918493e-05
step: 820, loss: 0.046916693449020386
step: 830, loss: 0.032680779695510864
step: 840, loss: 0.03763929754495621
step: 850, loss: 0.04854534566402435
step: 860, loss: 0.04573903977870941
step: 870, loss: 0.019907115027308464
step: 880, loss: 0.0583372637629509
step: 890, loss: 0.021299486979842186
step: 900, loss: 0.11736827343702316
step: 910, loss: 0.02032722719013691
step: 920, loss: 0.08058074116706848
step: 930, loss: 0.047368742525577545
step: 940, loss: 0.017125960439443588
step: 950, loss: 0.028363030403852463
step: 960, loss: 0.057541925460100174
step: 970, loss: 0.025000888854265213
epoch 18: dev_f1=0.9329608938547487, f1=0.9301025163094129, best_f1=0.9305936073059361
step: 0, loss: 0.0002246571093564853
step: 10, loss: 0.05458094924688339
step: 20, loss: 0.0889308750629425
step: 30, loss: 0.024469200521707535
step: 40, loss: 0.06517291069030762
step: 50, loss: 0.057335760444402695
step: 60, loss: 0.0665401965379715
step: 70, loss: 0.06762274354696274
step: 80, loss: 0.04688454791903496
step: 90, loss: 0.05037922412157059
step: 100, loss: 0.027373559772968292
step: 110, loss: 0.05145904794335365
step: 120, loss: 0.06383869796991348
step: 130, loss: 0.1130823865532875
step: 140, loss: 0.04578292742371559
step: 150, loss: 0.10203170776367188
step: 160, loss: 0.015478982590138912
step: 170, loss: 0.08359841257333755
step: 180, loss: 0.0407135896384716
step: 190, loss: 0.024959096685051918
step: 200, loss: 0.04415152221918106
step: 210, loss: 0.08715777099132538
step: 220, loss: 0.0014427006244659424
step: 230, loss: 0.05378803610801697
step: 240, loss: 0.06332891434431076
step: 250, loss: 0.05708816647529602
step: 260, loss: 0.08691470324993134
step: 270, loss: 0.013868849724531174
step: 280, loss: 0.06936214864253998
step: 290, loss: 0.00012009556667180732
step: 300, loss: 0.051875218749046326
step: 310, loss: 0.06899799406528473
step: 320, loss: 0.043965894728899
step: 330, loss: 0.06348450481891632
step: 340, loss: 0.0673270970582962
step: 350, loss: 0.08868579566478729
step: 360, loss: 0.02580910548567772
step: 370, loss: 0.0229246336966753
step: 380, loss: 0.08177696913480759
step: 390, loss: 0.06395263969898224
step: 400, loss: 0.04263477027416229
step: 410, loss: 0.033875223249197006
step: 420, loss: 0.03842141106724739
step: 430, loss: 0.012954805046319962
step: 440, loss: 0.017849942669272423
step: 450, loss: 0.04254791885614395
step: 460, loss: 0.06581412255764008
step: 470, loss: 0.08668806403875351
step: 480, loss: 0.030568107962608337
step: 490, loss: 0.021213741973042488
step: 500, loss: 0.011152785271406174
step: 510, loss: 0.0003992239071521908
step: 520, loss: 0.000871025666128844
step: 530, loss: 0.06949439644813538
step: 540, loss: 0.05336928740143776
step: 550, loss: 0.0100912069901824
step: 560, loss: 0.014754921197891235
step: 570, loss: 0.05536691099405289
step: 580, loss: 0.16261667013168335
step: 590, loss: 0.06882007420063019
step: 600, loss: 0.04662371799349785
step: 610, loss: 0.1381799727678299
step: 620, loss: 0.014574335888028145
step: 630, loss: 0.04590817168354988
step: 640, loss: 0.08048442751169205
step: 650, loss: 0.03731049969792366
step: 660, loss: 0.09615249186754227
step: 670, loss: 0.05493698641657829
step: 680, loss: 0.09120495617389679
step: 690, loss: 0.02561219222843647
step: 700, loss: 0.0006055216654203832
step: 710, loss: 0.056198544800281525
step: 720, loss: 0.083312027156353
step: 730, loss: 0.0333450548350811
step: 740, loss: 0.04844653606414795
step: 750, loss: 0.01867939531803131
step: 760, loss: 0.06536637991666794
step: 770, loss: 0.08233045041561127
step: 780, loss: 0.00026118423556908965
step: 790, loss: 0.08025810867547989
step: 800, loss: 0.12652142345905304
step: 810, loss: 0.03662010282278061
step: 820, loss: 0.0002725020167417824
step: 830, loss: 0.06778424233198166
step: 840, loss: 0.047403834760189056
step: 850, loss: 0.037828996777534485
step: 860, loss: 0.029325898736715317
step: 870, loss: 0.05651819705963135
step: 880, loss: 0.12589561939239502
step: 890, loss: 0.07591938227415085
step: 900, loss: 0.014746902510523796
step: 910, loss: 0.03171548247337341
step: 920, loss: 0.03317031264305115
step: 930, loss: 0.019150227308273315
step: 940, loss: 0.04353795200586319
step: 950, loss: 0.11565331369638443
step: 960, loss: 0.05281224474310875
step: 970, loss: 0.04298572987318039
epoch 19: dev_f1=0.930276087973795, f1=0.9263947491795592, best_f1=0.9305936073059361
step: 0, loss: 0.0004894664161838591
step: 10, loss: 0.02749200351536274
step: 20, loss: 0.03402341157197952
step: 30, loss: 0.06594628095626831
step: 40, loss: 0.054496701806783676
step: 50, loss: 0.0014023801777511835
step: 60, loss: 0.00019385202904231846
step: 70, loss: 0.03315182030200958
step: 80, loss: 0.05521479249000549
step: 90, loss: 0.004257955122739077
step: 100, loss: 0.2928715646266937
step: 110, loss: 0.06019051373004913
step: 120, loss: 0.08152297139167786
step: 130, loss: 0.047859255224466324
step: 140, loss: 0.05508773773908615
step: 150, loss: 0.05772128701210022
step: 160, loss: 0.079376220703125
step: 170, loss: 0.07336103916168213
step: 180, loss: 0.02593381144106388
step: 190, loss: 0.06754079461097717
step: 200, loss: 0.031696394085884094
step: 210, loss: 0.035274021327495575
step: 220, loss: 0.029075313359498978
step: 230, loss: 0.0587259903550148
step: 240, loss: 0.062165189534425735
step: 250, loss: 0.0722898319363594
step: 260, loss: 0.014446962624788284
step: 270, loss: 0.03552599996328354
step: 280, loss: 0.03525473549962044
step: 290, loss: 0.056071937084198
step: 300, loss: 0.012501261197030544
step: 310, loss: 0.020079514011740685
step: 320, loss: 0.03894730657339096
step: 330, loss: 0.10233912616968155
step: 340, loss: 0.02327936701476574
step: 350, loss: 0.016810985282063484
step: 360, loss: 0.0717252865433693
step: 370, loss: 0.050333667546510696
step: 380, loss: 0.026531126350164413
step: 390, loss: 0.08706484735012054
step: 400, loss: 0.09573084115982056
step: 410, loss: 0.01134591456502676
step: 420, loss: 0.10248761624097824
step: 430, loss: 0.031202182173728943
step: 440, loss: 0.09665122628211975
step: 450, loss: 0.010628234595060349
step: 460, loss: 0.03487202152609825
step: 470, loss: 0.08224936574697495
step: 480, loss: 0.027170455083251
step: 490, loss: 0.04172849282622337
step: 500, loss: 0.01431993953883648
step: 510, loss: 0.035967860370874405
step: 520, loss: 0.07338780164718628
step: 530, loss: 0.11617930233478546
step: 540, loss: 0.054740071296691895
step: 550, loss: 0.05090034380555153
step: 560, loss: 0.13591670989990234
step: 570, loss: 0.038530927151441574
step: 580, loss: 0.14618796110153198
step: 590, loss: 0.08826980739831924
step: 600, loss: 0.0962182804942131
step: 610, loss: 0.03252613916993141
step: 620, loss: 0.0037136380560696125
step: 630, loss: 0.07295900583267212
step: 640, loss: 0.057637717574834824
step: 650, loss: 0.04681597277522087
step: 660, loss: 0.022890731692314148
step: 670, loss: 0.03275833651423454
step: 680, loss: 0.08320735394954681
step: 690, loss: 9.792973287403584e-05
step: 700, loss: 0.07986173033714294
step: 710, loss: 0.0023928373120725155
step: 720, loss: 0.01873437687754631
step: 730, loss: 0.08592357486486435
step: 740, loss: 0.04514458775520325
step: 750, loss: 0.15804411470890045
step: 760, loss: 0.11133304238319397
step: 770, loss: 0.024507923051714897
step: 780, loss: 0.04511697217822075
step: 790, loss: 0.014124575071036816
step: 800, loss: 0.10639457404613495
step: 810, loss: 0.06545089930295944
step: 820, loss: 0.019668763503432274
step: 830, loss: 0.046834930777549744
step: 840, loss: 0.049364060163497925
step: 850, loss: 0.10830113291740417
step: 860, loss: 0.03761633485555649
step: 870, loss: 0.03312401473522186
step: 880, loss: 0.1534048318862915
step: 890, loss: 0.04423735290765762
step: 900, loss: 0.08827697485685349
step: 910, loss: 0.01604880765080452
step: 920, loss: 0.07094129174947739
step: 930, loss: 0.05568971484899521
step: 940, loss: 0.025692572817206383
step: 950, loss: 0.08923248201608658
step: 960, loss: 3.4569879062473774e-05
step: 970, loss: 0.07782027125358582
epoch 20: dev_f1=0.9275225011842728, f1=0.9241706161137442, best_f1=0.9305936073059361
