cuda
Device: cuda
step: 0, loss: 0.609594464302063
step: 10, loss: 0.270235151052475
step: 20, loss: 0.28272563219070435
step: 30, loss: 0.39982283115386963
step: 40, loss: 0.36885058879852295
step: 50, loss: 0.14057643711566925
step: 60, loss: 0.18298806250095367
step: 70, loss: 0.1646435260772705
step: 80, loss: 0.2434992492198944
step: 90, loss: 0.24091462790966034
step: 100, loss: 0.21315708756446838
step: 110, loss: 0.16975285112857819
step: 120, loss: 0.23187677562236786
step: 130, loss: 0.19483789801597595
step: 140, loss: 0.12009230256080627
step: 150, loss: 0.23592808842658997
step: 160, loss: 0.16127578914165497
step: 170, loss: 0.25332918763160706
step: 180, loss: 0.17243364453315735
step: 190, loss: 0.12877421081066132
step: 200, loss: 0.12282831966876984
step: 210, loss: 0.12275788933038712
step: 220, loss: 0.12477247416973114
step: 230, loss: 0.01976034604012966
step: 240, loss: 0.18841266632080078
step: 250, loss: 0.27600687742233276
step: 260, loss: 0.15966123342514038
step: 270, loss: 0.08086324483156204
step: 280, loss: 0.24421989917755127
step: 290, loss: 0.1233188658952713
step: 300, loss: 0.1147056370973587
step: 310, loss: 0.12593036890029907
step: 320, loss: 0.10012516379356384
step: 330, loss: 0.15859349071979523
step: 340, loss: 0.28971928358078003
step: 350, loss: 0.18050825595855713
step: 360, loss: 0.12846803665161133
step: 370, loss: 0.13938550651073456
step: 380, loss: 0.10305269807577133
step: 390, loss: 0.11557052284479141
step: 400, loss: 0.2528311312198639
step: 410, loss: 0.10914284735918045
step: 420, loss: 0.2502436637878418
step: 430, loss: 0.2902284860610962
step: 440, loss: 0.2425999492406845
step: 450, loss: 0.2118031233549118
step: 460, loss: 0.05402853339910507
step: 470, loss: 0.16913412511348724
step: 480, loss: 0.10239452868700027
step: 490, loss: 0.2865377366542816
step: 500, loss: 0.2573986351490021
step: 510, loss: 0.21512307226657867
step: 520, loss: 0.14515866339206696
step: 530, loss: 0.15567298233509064
step: 540, loss: 0.33683261275291443
step: 550, loss: 0.2435636818408966
step: 560, loss: 0.11174886673688889
step: 570, loss: 0.12145216763019562
step: 580, loss: 0.14135706424713135
step: 590, loss: 0.09193618595600128
step: 600, loss: 0.20997904241085052
step: 610, loss: 0.12145799398422241
step: 620, loss: 0.0906866118311882
step: 630, loss: 0.11137771606445312
step: 640, loss: 0.08093910664319992
step: 650, loss: 0.14115796983242035
step: 660, loss: 0.2173783928155899
step: 670, loss: 0.20851309597492218
step: 680, loss: 0.3123270273208618
step: 690, loss: 0.15355011820793152
step: 700, loss: 0.15642297267913818
step: 710, loss: 0.21826712787151337
step: 720, loss: 0.13360224664211273
step: 730, loss: 0.05176038295030594
step: 740, loss: 0.08819602429866791
step: 750, loss: 0.22095341980457306
step: 760, loss: 0.10549823194742203
step: 770, loss: 0.26528194546699524
step: 780, loss: 0.1510653793811798
step: 790, loss: 0.09764561057090759
step: 800, loss: 0.1640496850013733
step: 810, loss: 0.12096171081066132
step: 820, loss: 0.16492204368114471
step: 830, loss: 0.018190545961260796
step: 840, loss: 0.12925104796886444
step: 850, loss: 0.27295705676078796
step: 860, loss: 0.08851563930511475
step: 870, loss: 0.09326454252004623
step: 880, loss: 0.15827885270118713
step: 890, loss: 0.1762976348400116
step: 900, loss: 0.08418639749288559
step: 910, loss: 0.1844330132007599
step: 920, loss: 0.18829700350761414
step: 930, loss: 0.1218654066324234
step: 940, loss: 0.08741552382707596
step: 950, loss: 0.031771834939718246
step: 960, loss: 0.242150217294693
step: 970, loss: 0.1482200026512146
epoch 1: dev_f1=0.8616262482168331, f1=0.8589073634204275, best_f1=0.8589073634204275
step: 0, loss: 0.08665131777524948
step: 10, loss: 0.12590175867080688
step: 20, loss: 0.09793981909751892
step: 30, loss: 0.060142092406749725
step: 40, loss: 0.21473988890647888
step: 50, loss: 0.21619346737861633
step: 60, loss: 0.18861126899719238
step: 70, loss: 0.12950697541236877
step: 80, loss: 0.14988164603710175
step: 90, loss: 0.08019006252288818
step: 100, loss: 0.10340290516614914
step: 110, loss: 0.08903906494379044
step: 120, loss: 0.16721725463867188
step: 130, loss: 0.14840562641620636
step: 140, loss: 0.08951988071203232
step: 150, loss: 0.18044143915176392
step: 160, loss: 0.13238972425460815
step: 170, loss: 0.17240530252456665
step: 180, loss: 0.10553523153066635
step: 190, loss: 0.1386851668357849
step: 200, loss: 0.11633877456188202
step: 210, loss: 0.06962543725967407
step: 220, loss: 0.13173134624958038
step: 230, loss: 0.04765937849879265
step: 240, loss: 0.057437047362327576
step: 250, loss: 0.0869181826710701
step: 260, loss: 0.07090229541063309
step: 270, loss: 0.10258651524782181
step: 280, loss: 0.0639001801609993
step: 290, loss: 0.20947186648845673
step: 300, loss: 0.1802102029323578
step: 310, loss: 0.08908778429031372
step: 320, loss: 0.18389812111854553
step: 330, loss: 0.04031694680452347
step: 340, loss: 0.11536771804094315
step: 350, loss: 0.13205735385417938
step: 360, loss: 0.12608963251113892
step: 370, loss: 0.08817033469676971
step: 380, loss: 0.18585258722305298
step: 390, loss: 0.1487809717655182
step: 400, loss: 0.11960913240909576
step: 410, loss: 0.17530591785907745
step: 420, loss: 0.13473132252693176
step: 430, loss: 0.1638033092021942
step: 440, loss: 0.11174748837947845
step: 450, loss: 0.1299050897359848
step: 460, loss: 0.11303861439228058
step: 470, loss: 0.06627558171749115
step: 480, loss: 0.1671774685382843
step: 490, loss: 0.0861184298992157
step: 500, loss: 0.051246076822280884
step: 510, loss: 0.2977263033390045
step: 520, loss: 0.15056228637695312
step: 530, loss: 0.2175188809633255
step: 540, loss: 0.17051875591278076
step: 550, loss: 0.07291192561388016
step: 560, loss: 0.03773125633597374
step: 570, loss: 0.22839292883872986
step: 580, loss: 0.1417219638824463
step: 590, loss: 0.11158038675785065
step: 600, loss: 0.2334243506193161
step: 610, loss: 0.2560955882072449
step: 620, loss: 0.26096612215042114
step: 630, loss: 0.17294950783252716
step: 640, loss: 0.22715182602405548
step: 650, loss: 0.08220874518156052
step: 660, loss: 0.23433060944080353
step: 670, loss: 0.06623769551515579
step: 680, loss: 0.10616573691368103
step: 690, loss: 0.08012174069881439
step: 700, loss: 0.07067155092954636
step: 710, loss: 0.11460503190755844
step: 720, loss: 0.12437372654676437
step: 730, loss: 0.231394425034523
step: 740, loss: 0.05611098185181618
step: 750, loss: 0.16905024647712708
step: 760, loss: 0.09559434652328491
step: 770, loss: 0.1224561557173729
step: 780, loss: 0.15879769623279572
step: 790, loss: 0.10051591694355011
step: 800, loss: 0.06549511849880219
step: 810, loss: 0.10004765540361404
step: 820, loss: 0.23573331534862518
step: 830, loss: 0.14056053757667542
step: 840, loss: 0.12910465896129608
step: 850, loss: 0.07925158739089966
step: 860, loss: 0.054343368858098984
step: 870, loss: 0.22583065927028656
step: 880, loss: 0.13137753307819366
step: 890, loss: 0.20651136338710785
step: 900, loss: 0.05619676038622856
step: 910, loss: 0.06793875992298126
step: 920, loss: 0.04714982211589813
step: 930, loss: 0.24440322816371918
step: 940, loss: 0.22282274067401886
step: 950, loss: 0.13362060487270355
step: 960, loss: 0.03974425792694092
step: 970, loss: 0.19435203075408936
epoch 2: dev_f1=0.912745545911375, f1=0.9095865515674694, best_f1=0.9095865515674694
step: 0, loss: 0.16846482455730438
step: 10, loss: 0.08031103014945984
step: 20, loss: 0.09216076135635376
step: 30, loss: 0.07081224024295807
step: 40, loss: 0.1239185631275177
step: 50, loss: 0.05183224380016327
step: 60, loss: 0.05823041498661041
step: 70, loss: 0.05272376909852028
step: 80, loss: 0.13084611296653748
step: 90, loss: 0.06858702003955841
step: 100, loss: 0.03393203765153885
step: 110, loss: 0.10353527963161469
step: 120, loss: 0.1742105484008789
step: 130, loss: 0.08605571836233139
step: 140, loss: 0.1408175230026245
step: 150, loss: 0.21774956583976746
step: 160, loss: 0.12923260033130646
step: 170, loss: 0.07472690939903259
step: 180, loss: 0.08293595165014267
step: 190, loss: 0.07152900099754333
step: 200, loss: 0.08553088456392288
step: 210, loss: 0.12116238474845886
step: 220, loss: 0.04646676033735275
step: 230, loss: 0.153997540473938
step: 240, loss: 0.052515462040901184
step: 250, loss: 0.07642097771167755
step: 260, loss: 0.039366018027067184
step: 270, loss: 0.10637611150741577
step: 280, loss: 0.14213332533836365
step: 290, loss: 0.11696448922157288
step: 300, loss: 0.13006919622421265
step: 310, loss: 0.1563393473625183
step: 320, loss: 0.14413194358348846
step: 330, loss: 0.12620793282985687
step: 340, loss: 0.11842593550682068
step: 350, loss: 0.22903941571712494
step: 360, loss: 0.1530860811471939
step: 370, loss: 0.11591695994138718
step: 380, loss: 0.15647391974925995
step: 390, loss: 0.19774270057678223
step: 400, loss: 0.29876208305358887
step: 410, loss: 0.10539986938238144
step: 420, loss: 0.09099940210580826
step: 430, loss: 0.11908066272735596
step: 440, loss: 0.19674807786941528
step: 450, loss: 0.09473222494125366
step: 460, loss: 0.23221895098686218
step: 470, loss: 0.08709319680929184
step: 480, loss: 0.15243682265281677
step: 490, loss: 0.09841702878475189
step: 500, loss: 0.06806282699108124
step: 510, loss: 0.05954321473836899
step: 520, loss: 0.17426882684230804
step: 530, loss: 0.1020369902253151
step: 540, loss: 0.15306439995765686
step: 550, loss: 0.07045894116163254
step: 560, loss: 0.13598372042179108
step: 570, loss: 0.11081910878419876
step: 580, loss: 0.08067858219146729
step: 590, loss: 0.0698687881231308
step: 600, loss: 0.17771990597248077
step: 610, loss: 0.07661803066730499
step: 620, loss: 0.16843491792678833
step: 630, loss: 0.039786145091056824
step: 640, loss: 0.12906648218631744
step: 650, loss: 0.05911238491535187
step: 660, loss: 0.029082242399454117
step: 670, loss: 0.1647176444530487
step: 680, loss: 0.12400674819946289
step: 690, loss: 0.03228241205215454
step: 700, loss: 0.09217776358127594
step: 710, loss: 0.05608617141842842
step: 720, loss: 0.09576183557510376
step: 730, loss: 0.04428131505846977
step: 740, loss: 0.13245633244514465
step: 750, loss: 0.16921280324459076
step: 760, loss: 0.22244226932525635
step: 770, loss: 0.13574329018592834
step: 780, loss: 0.056236859411001205
step: 790, loss: 0.05721970647573471
step: 800, loss: 0.07822000235319138
step: 810, loss: 0.028809888288378716
step: 820, loss: 0.08279109001159668
step: 830, loss: 0.15534985065460205
step: 840, loss: 0.06435272097587585
step: 850, loss: 0.08059624582529068
step: 860, loss: 0.03352499008178711
step: 870, loss: 0.0799788385629654
step: 880, loss: 0.14446845650672913
step: 890, loss: 0.18863928318023682
step: 900, loss: 0.0417630635201931
step: 910, loss: 0.0613166019320488
step: 920, loss: 0.0954497680068016
step: 930, loss: 0.16609901189804077
step: 940, loss: 0.0002810478035826236
step: 950, loss: 0.2926540970802307
step: 960, loss: 0.08202456682920456
step: 970, loss: 0.0854058563709259
epoch 3: dev_f1=0.9345454545454546, f1=0.9266968325791854, best_f1=0.9266968325791854
step: 0, loss: 0.09232792258262634
step: 10, loss: 0.08743369579315186
step: 20, loss: 0.1081746444106102
step: 30, loss: 0.059001874178647995
step: 40, loss: 0.04866170138120651
step: 50, loss: 0.030049001798033714
step: 60, loss: 0.05634051188826561
step: 70, loss: 0.22145146131515503
step: 80, loss: 0.22960300743579865
step: 90, loss: 0.12835246324539185
step: 100, loss: 0.026726873591542244
step: 110, loss: 0.09491035342216492
step: 120, loss: 0.03991353511810303
step: 130, loss: 0.03704937919974327
step: 140, loss: 0.07921011745929718
step: 150, loss: 0.1224028617143631
step: 160, loss: 0.07055915892124176
step: 170, loss: 0.12657620012760162
step: 180, loss: 0.164891317486763
step: 190, loss: 0.09114684164524078
step: 200, loss: 0.09162833541631699
step: 210, loss: 0.10826658457517624
step: 220, loss: 0.18639437854290009
step: 230, loss: 0.08571279793977737
step: 240, loss: 0.03594813123345375
step: 250, loss: 0.09078165143728256
step: 260, loss: 0.07705891877412796
step: 270, loss: 0.07793668657541275
step: 280, loss: 0.18467867374420166
step: 290, loss: 0.13497768342494965
step: 300, loss: 0.11536681652069092
step: 310, loss: 0.04159395396709442
step: 320, loss: 0.2663610875606537
step: 330, loss: 0.08560339361429214
step: 340, loss: 0.0553513802587986
step: 350, loss: 0.10992629081010818
step: 360, loss: 0.08367578685283661
step: 370, loss: 0.15427884459495544
step: 380, loss: 0.15746726095676422
step: 390, loss: 0.062228474766016006
step: 400, loss: 0.16594462096691132
step: 410, loss: 0.07914027571678162
step: 420, loss: 0.08328571170568466
step: 430, loss: 0.12866468727588654
step: 440, loss: 0.1294088065624237
step: 450, loss: 0.08617761731147766
step: 460, loss: 0.1835620105266571
step: 470, loss: 0.09362786263227463
step: 480, loss: 0.14865580201148987
step: 490, loss: 0.07797063142061234
step: 500, loss: 0.15588821470737457
step: 510, loss: 0.26374295353889465
step: 520, loss: 0.11201433092355728
step: 530, loss: 0.08500925451517105
step: 540, loss: 0.05739585682749748
step: 550, loss: 0.07642465829849243
step: 560, loss: 0.12106533348560333
step: 570, loss: 0.13194695115089417
step: 580, loss: 0.06172652542591095
step: 590, loss: 0.030290404334664345
step: 600, loss: 0.06273750960826874
step: 610, loss: 0.09437969326972961
step: 620, loss: 0.14567990601062775
step: 630, loss: 0.17528972029685974
step: 640, loss: 0.231355682015419
step: 650, loss: 0.14045129716396332
step: 660, loss: 0.030243901535868645
step: 670, loss: 0.1259320229291916
step: 680, loss: 0.05260388180613518
step: 690, loss: 0.070686474442482
step: 700, loss: 0.13905444741249084
step: 710, loss: 0.06347884982824326
step: 720, loss: 0.26346004009246826
step: 730, loss: 0.18462474644184113
step: 740, loss: 0.07906007021665573
step: 750, loss: 0.13449139893054962
step: 760, loss: 0.17620816826820374
step: 770, loss: 0.03429041802883148
step: 780, loss: 0.08941171318292618
step: 790, loss: 0.13749513030052185
step: 800, loss: 0.07934606075286865
step: 810, loss: 0.17023806273937225
step: 820, loss: 0.07617136090993881
step: 830, loss: 0.24077898263931274
step: 840, loss: 0.1652936190366745
step: 850, loss: 0.10110998898744583
step: 860, loss: 0.12474296987056732
step: 870, loss: 0.11209835112094879
step: 880, loss: 0.058058492839336395
step: 890, loss: 0.03534771502017975
step: 900, loss: 0.16803070902824402
step: 910, loss: 0.08786563575267792
step: 920, loss: 0.01746990531682968
step: 930, loss: 0.11046238243579865
step: 940, loss: 0.148391991853714
step: 950, loss: 0.04855524003505707
step: 960, loss: 0.10036489367485046
step: 970, loss: 0.16313020884990692
epoch 4: dev_f1=0.9264029438822446, f1=0.928212162780064, best_f1=0.9266968325791854
step: 0, loss: 0.060076095163822174
step: 10, loss: 0.04905106872320175
step: 20, loss: 0.08904147148132324
step: 30, loss: 0.1516617387533188
step: 40, loss: 0.09253698587417603
step: 50, loss: 0.06119851768016815
step: 60, loss: 0.05250188335776329
step: 70, loss: 0.12998199462890625
step: 80, loss: 0.07144306600093842
step: 90, loss: 0.03338252007961273
step: 100, loss: 0.06725458800792694
step: 110, loss: 0.10365547239780426
step: 120, loss: 0.07869578152894974
step: 130, loss: 0.11112266778945923
step: 140, loss: 0.16066685318946838
step: 150, loss: 0.09115564078092575
step: 160, loss: 0.0744173601269722
step: 170, loss: 0.11375103890895844
step: 180, loss: 0.16860587894916534
step: 190, loss: 0.07126695662736893
step: 200, loss: 0.0462266243994236
step: 210, loss: 0.17925319075584412
step: 220, loss: 0.1553749293088913
step: 230, loss: 0.06348733603954315
step: 240, loss: 0.15068618953227997
step: 250, loss: 0.19339868426322937
step: 260, loss: 0.3159645199775696
step: 270, loss: 0.04486728832125664
step: 280, loss: 0.06732633709907532
step: 290, loss: 0.08822797238826752
step: 300, loss: 0.05099686607718468
step: 310, loss: 0.05321872979402542
step: 320, loss: 0.06903582066297531
step: 330, loss: 0.12091264128684998
step: 340, loss: 0.058068811893463135
step: 350, loss: 0.03232942894101143
step: 360, loss: 0.04453735053539276
step: 370, loss: 0.12669986486434937
step: 380, loss: 0.05828031525015831
step: 390, loss: 0.07802846282720566
step: 400, loss: 0.12145695835351944
step: 410, loss: 0.045465901494026184
step: 420, loss: 0.13212448358535767
step: 430, loss: 0.0759938582777977
step: 440, loss: 0.10673218220472336
step: 450, loss: 0.0333087332546711
step: 460, loss: 0.13532844185829163
step: 470, loss: 0.08053953945636749
step: 480, loss: 0.08331404626369476
step: 490, loss: 0.07029279321432114
step: 500, loss: 0.05907157063484192
step: 510, loss: 0.05030260980129242
step: 520, loss: 0.10519221425056458
step: 530, loss: 0.01603211835026741
step: 540, loss: 0.021285753697156906
step: 550, loss: 0.08339092880487442
step: 560, loss: 0.14912472665309906
step: 570, loss: 0.1720125377178192
step: 580, loss: 0.192869171500206
step: 590, loss: 0.1545741707086563
step: 600, loss: 0.11595652252435684
step: 610, loss: 0.08560894429683685
step: 620, loss: 0.04208928719162941
step: 630, loss: 0.07320445775985718
step: 640, loss: 0.09643952548503876
step: 650, loss: 0.12636390328407288
step: 660, loss: 0.010665425099432468
step: 670, loss: 0.13732774555683136
step: 680, loss: 0.08971408009529114
step: 690, loss: 0.1213805302977562
step: 700, loss: 0.02970830537378788
step: 710, loss: 0.06453025341033936
step: 720, loss: 0.12105221301317215
step: 730, loss: 0.040864601731300354
step: 740, loss: 0.1094396710395813
step: 750, loss: 0.05507487431168556
step: 760, loss: 0.07168429344892502
step: 770, loss: 0.09163369238376617
step: 780, loss: 0.03901391103863716
step: 790, loss: 0.12514813244342804
step: 800, loss: 0.01747068576514721
step: 810, loss: 0.15227524936199188
step: 820, loss: 0.08397050201892853
step: 830, loss: 0.13639502227306366
step: 840, loss: 0.14453405141830444
step: 850, loss: 0.07791020721197128
step: 860, loss: 0.13815736770629883
step: 870, loss: 0.22260327637195587
step: 880, loss: 0.06214869022369385
step: 890, loss: 0.04025910794734955
step: 900, loss: 0.16617761552333832
step: 910, loss: 0.08145637810230255
step: 920, loss: 0.2427804172039032
step: 930, loss: 0.257524698972702
step: 940, loss: 0.09058347344398499
step: 950, loss: 0.07359681278467178
step: 960, loss: 0.03623371198773384
step: 970, loss: 0.09948184341192245
epoch 5: dev_f1=0.9312072892938498, f1=0.9257403189066059, best_f1=0.9266968325791854
step: 0, loss: 0.02913706563413143
step: 10, loss: 0.0827183946967125
step: 20, loss: 0.08788415789604187
step: 30, loss: 0.10672744363546371
step: 40, loss: 0.1400875747203827
step: 50, loss: 0.03386331722140312
step: 60, loss: 0.11908180266618729
step: 70, loss: 0.1345898061990738
step: 80, loss: 0.015679387375712395
step: 90, loss: 0.12090183794498444
step: 100, loss: 0.045933373272418976
step: 110, loss: 0.13529753684997559
step: 120, loss: 0.135391965508461
step: 130, loss: 0.10851563513278961
step: 140, loss: 0.18884970247745514
step: 150, loss: 0.21908830106258392
step: 160, loss: 0.09768015146255493
step: 170, loss: 0.16070501506328583
step: 180, loss: 0.067925363779068
step: 190, loss: 0.1423095315694809
step: 200, loss: 0.07620033621788025
step: 210, loss: 0.10242950171232224
step: 220, loss: 0.07271046191453934
step: 230, loss: 0.09407704323530197
step: 240, loss: 0.09793400764465332
step: 250, loss: 0.12463872134685516
step: 260, loss: 0.11680127680301666
step: 270, loss: 0.05449069291353226
step: 280, loss: 0.07977434247732162
step: 290, loss: 0.07994433492422104
step: 300, loss: 0.04821557179093361
step: 310, loss: 0.06392700970172882
step: 320, loss: 0.014464511536061764
step: 330, loss: 0.07687985897064209
step: 340, loss: 0.076751209795475
step: 350, loss: 0.053303103893995285
step: 360, loss: 0.02089599147439003
step: 370, loss: 0.14033789932727814
step: 380, loss: 0.11782989650964737
step: 390, loss: 0.11109919100999832
step: 400, loss: 0.06295368820428848
step: 410, loss: 0.1134599819779396
step: 420, loss: 0.0789821594953537
step: 430, loss: 0.04130563139915466
step: 440, loss: 0.20590999722480774
step: 450, loss: 0.06150422245264053
step: 460, loss: 0.167666494846344
step: 470, loss: 0.02288452908396721
step: 480, loss: 0.08495480567216873
step: 490, loss: 0.058464907109737396
step: 500, loss: 0.09905976802110672
step: 510, loss: 0.05597134679555893
step: 520, loss: 0.11316806823015213
step: 530, loss: 0.07024741917848587
step: 540, loss: 0.12081680446863174
step: 550, loss: 0.06498762220144272
step: 560, loss: 0.14283865690231323
step: 570, loss: 0.12179744243621826
step: 580, loss: 0.11548999696969986
step: 590, loss: 0.11628113687038422
step: 600, loss: 0.13603472709655762
step: 610, loss: 0.015304920263588428
step: 620, loss: 0.08682017773389816
step: 630, loss: 0.0753243938088417
step: 640, loss: 0.10754141956567764
step: 650, loss: 0.060109373182058334
step: 660, loss: 0.16150012612342834
step: 670, loss: 0.07407940179109573
step: 680, loss: 0.006411254871636629
step: 690, loss: 0.11557786911725998
step: 700, loss: 0.12083151936531067
step: 710, loss: 0.09479810297489166
step: 720, loss: 0.11318957805633545
step: 730, loss: 0.07267557084560394
step: 740, loss: 0.16000229120254517
step: 750, loss: 0.11299140751361847
step: 760, loss: 0.18937475979328156
step: 770, loss: 0.04553043469786644
step: 780, loss: 0.08340945839881897
step: 790, loss: 0.06679313629865646
step: 800, loss: 0.16777922213077545
step: 810, loss: 0.09375262260437012
step: 820, loss: 0.052745312452316284
step: 830, loss: 0.11178436875343323
step: 840, loss: 0.09743822365999222
step: 850, loss: 0.12282561510801315
step: 860, loss: 0.1027122288942337
step: 870, loss: 0.02623867802321911
step: 880, loss: 0.15770001709461212
step: 890, loss: 0.10505446046590805
step: 900, loss: 0.04258943721652031
step: 910, loss: 0.14309780299663544
step: 920, loss: 0.161047101020813
step: 930, loss: 0.14437812566757202
step: 940, loss: 0.08484133332967758
step: 950, loss: 0.11507710069417953
step: 960, loss: 0.140039324760437
step: 970, loss: 0.1438537985086441
epoch 6: dev_f1=0.9335167354424576, f1=0.9266943291839558, best_f1=0.9266968325791854
step: 0, loss: 0.11456220597028732
step: 10, loss: 0.09041924774646759
step: 20, loss: 0.043921757489442825
step: 30, loss: 0.04108801111578941
step: 40, loss: 0.14929577708244324
step: 50, loss: 0.08312379568815231
step: 60, loss: 0.14516235888004303
step: 70, loss: 0.055410973727703094
step: 80, loss: 0.06949639320373535
step: 90, loss: 0.18302419781684875
step: 100, loss: 0.12694776058197021
step: 110, loss: 0.19810940325260162
step: 120, loss: 0.038580331951379776
step: 130, loss: 0.05864854156970978
step: 140, loss: 0.170323446393013
step: 150, loss: 0.12789803743362427
step: 160, loss: 0.21352006494998932
step: 170, loss: 0.13786250352859497
step: 180, loss: 0.15406766533851624
step: 190, loss: 0.09669764339923859
step: 200, loss: 0.06035812571644783
step: 210, loss: 0.1856352686882019
step: 220, loss: 0.03185420110821724
step: 230, loss: 0.08051050454378128
step: 240, loss: 0.12287318706512451
step: 250, loss: 0.024430232122540474
step: 260, loss: 0.10882110148668289
step: 270, loss: 0.07091768085956573
step: 280, loss: 0.05060454085469246
step: 290, loss: 0.23038427531719208
step: 300, loss: 0.09937393665313721
step: 310, loss: 0.11728901416063309
step: 320, loss: 0.10489756613969803
step: 330, loss: 0.024200983345508575
step: 340, loss: 0.030210409313440323
step: 350, loss: 0.03361278399825096
step: 360, loss: 0.16958360373973846
step: 370, loss: 0.2134297639131546
step: 380, loss: 0.06590131670236588
step: 390, loss: 0.10255927592515945
step: 400, loss: 0.05880959331989288
step: 410, loss: 0.05805528908967972
step: 420, loss: 0.19152817130088806
step: 430, loss: 0.0181562602519989
step: 440, loss: 0.06250275671482086
step: 450, loss: 0.07704572379589081
step: 460, loss: 0.020942047238349915
step: 470, loss: 0.08513886481523514
step: 480, loss: 0.09780101478099823
step: 490, loss: 0.1984255462884903
step: 500, loss: 0.04441322758793831
step: 510, loss: 0.2719266414642334
step: 520, loss: 0.11230402439832687
step: 530, loss: 0.09489817917346954
step: 540, loss: 0.02104787528514862
step: 550, loss: 0.03114348091185093
step: 560, loss: 0.15123297274112701
step: 570, loss: 0.1270289272069931
step: 580, loss: 0.07887387275695801
step: 590, loss: 0.07443876564502716
step: 600, loss: 0.00739237992092967
step: 610, loss: 0.06956962496042252
step: 620, loss: 0.11917939782142639
step: 630, loss: 0.07491033524274826
step: 640, loss: 0.05651361867785454
step: 650, loss: 0.13886970281600952
step: 660, loss: 0.07180383801460266
step: 670, loss: 0.009797444567084312
step: 680, loss: 0.17749473452568054
step: 690, loss: 0.08088400214910507
step: 700, loss: 0.03905697539448738
step: 710, loss: 0.05779463052749634
step: 720, loss: 0.035354454070329666
step: 730, loss: 0.059702493250370026
step: 740, loss: 0.09952841699123383
step: 750, loss: 0.1863526552915573
step: 760, loss: 0.07315097004175186
step: 770, loss: 0.016002578660845757
step: 780, loss: 0.1272844821214676
step: 790, loss: 0.05379326641559601
step: 800, loss: 0.049687694758176804
step: 810, loss: 0.10631930083036423
step: 820, loss: 0.1404951512813568
step: 830, loss: 0.09928757697343826
step: 840, loss: 0.01170636061578989
step: 850, loss: 0.03735560551285744
step: 860, loss: 0.05304061248898506
step: 870, loss: 0.07304732501506805
step: 880, loss: 0.08078634738922119
step: 890, loss: 0.04221649840474129
step: 900, loss: 0.10652434825897217
step: 910, loss: 0.061594344675540924
step: 920, loss: 0.045491285622119904
step: 930, loss: 0.08756858855485916
step: 940, loss: 0.1609899252653122
step: 950, loss: 0.09646269679069519
step: 960, loss: 0.11670400202274323
step: 970, loss: 0.08156299591064453
epoch 7: dev_f1=0.9275766016713091, f1=0.9237875288683602, best_f1=0.9266968325791854
step: 0, loss: 0.07400250434875488
step: 10, loss: 0.07013659924268723
step: 20, loss: 0.028193816542625427
step: 30, loss: 0.12589813768863678
step: 40, loss: 0.08071162551641464
step: 50, loss: 0.05666480213403702
step: 60, loss: 0.014941426925361156
step: 70, loss: 0.06804896146059036
step: 80, loss: 0.070644311606884
step: 90, loss: 0.10701781511306763
step: 100, loss: 0.0949929729104042
step: 110, loss: 0.027267929166555405
step: 120, loss: 0.1435498297214508
step: 130, loss: 0.03993282839655876
step: 140, loss: 0.10583801567554474
step: 150, loss: 0.12835831940174103
step: 160, loss: 0.060713060200214386
step: 170, loss: 0.10890427231788635
step: 180, loss: 0.07441283762454987
step: 190, loss: 0.07634381949901581
step: 200, loss: 0.05415134131908417
step: 210, loss: 0.02423136681318283
step: 220, loss: 0.10802881419658661
step: 230, loss: 0.07408791780471802
step: 240, loss: 0.0646028146147728
step: 250, loss: 0.09977903962135315
step: 260, loss: 0.05192045867443085
step: 270, loss: 0.03097846731543541
step: 280, loss: 0.11435960233211517
step: 290, loss: 0.04490337148308754
step: 300, loss: 0.11998464912176132
step: 310, loss: 0.11167522519826889
step: 320, loss: 0.0623927041888237
step: 330, loss: 0.05979446321725845
step: 340, loss: 0.08960438519716263
step: 350, loss: 0.14810606837272644
step: 360, loss: 0.0461561493575573
step: 370, loss: 0.05365132912993431
step: 380, loss: 0.02321520261466503
step: 390, loss: 0.10866723954677582
step: 400, loss: 0.07779194414615631
step: 410, loss: 0.03615143150091171
step: 420, loss: 0.10106492042541504
step: 430, loss: 0.08736706525087357
step: 440, loss: 0.13148212432861328
step: 450, loss: 0.033848464488983154
step: 460, loss: 0.17623960971832275
step: 470, loss: 0.058163028210401535
step: 480, loss: 0.1337362676858902
step: 490, loss: 0.018212903290987015
step: 500, loss: 0.09383995831012726
step: 510, loss: 0.1486622393131256
step: 520, loss: 0.03561881184577942
step: 530, loss: 0.05333341658115387
step: 540, loss: 0.02371451072394848
step: 550, loss: 0.11228062212467194
step: 560, loss: 0.06641193479299545
step: 570, loss: 0.10350742936134338
step: 580, loss: 0.05755605548620224
step: 590, loss: 0.026032838970422745
step: 600, loss: 0.15693099796772003
step: 610, loss: 0.03297227621078491
step: 620, loss: 0.09970305114984512
step: 630, loss: 0.02800615131855011
step: 640, loss: 0.20614635944366455
step: 650, loss: 0.12867704033851624
step: 660, loss: 0.08977915346622467
step: 670, loss: 0.0498732328414917
step: 680, loss: 0.0875215008854866
step: 690, loss: 0.08480256795883179
step: 700, loss: 0.16341456770896912
step: 710, loss: 0.07608625292778015
step: 720, loss: 0.05085664987564087
step: 730, loss: 0.051671456545591354
step: 740, loss: 0.20507292449474335
step: 750, loss: 0.09505683183670044
step: 760, loss: 0.16536544263362885
step: 770, loss: 0.08208581060171127
step: 780, loss: 0.07508932799100876
step: 790, loss: 0.1324326992034912
step: 800, loss: 0.03396930173039436
step: 810, loss: 0.04264724999666214
step: 820, loss: 0.10342809557914734
step: 830, loss: 0.08897806704044342
step: 840, loss: 0.1598682552576065
step: 850, loss: 0.195364311337471
step: 860, loss: 0.18466933071613312
step: 870, loss: 0.18433794379234314
step: 880, loss: 0.06418248265981674
step: 890, loss: 0.11875986307859421
step: 900, loss: 0.16493794322013855
step: 910, loss: 0.10087406635284424
step: 920, loss: 0.11795373260974884
step: 930, loss: 0.2384854108095169
step: 940, loss: 0.08484148234128952
step: 950, loss: 0.10115566849708557
step: 960, loss: 0.05324282869696617
step: 970, loss: 0.25557246804237366
epoch 8: dev_f1=0.9283372365339578, f1=0.9217065166432256, best_f1=0.9266968325791854
step: 0, loss: 0.08171065896749496
step: 10, loss: 0.10386515408754349
step: 20, loss: 0.10886533558368683
step: 30, loss: 0.09101135283708572
step: 40, loss: 0.10642391443252563
step: 50, loss: 0.1265634298324585
step: 60, loss: 0.08735504746437073
step: 70, loss: 0.06485547125339508
step: 80, loss: 0.07027622312307358
step: 90, loss: 0.13825541734695435
step: 100, loss: 0.04940412566065788
step: 110, loss: 0.00744364270940423
step: 120, loss: 0.04817162826657295
step: 130, loss: 0.08807315677404404
step: 140, loss: 0.10225124657154083
step: 150, loss: 0.04964716359972954
step: 160, loss: 0.04743899777531624
step: 170, loss: 0.12246853858232498
step: 180, loss: 0.07072153687477112
step: 190, loss: 0.13383686542510986
step: 200, loss: 0.09720968455076218
step: 210, loss: 0.09819047152996063
step: 220, loss: 0.2546873986721039
step: 230, loss: 0.040116045624017715
step: 240, loss: 0.007015427108854055
step: 250, loss: 0.13817746937274933
step: 260, loss: 0.08424309641122818
step: 270, loss: 0.08791646361351013
step: 280, loss: 0.11510171741247177
step: 290, loss: 0.06095351278781891
step: 300, loss: 0.005508155096322298
step: 310, loss: 0.020707683637738228
step: 320, loss: 0.03001256473362446
step: 330, loss: 0.1422557830810547
step: 340, loss: 0.10859204083681107
step: 350, loss: 0.1483273208141327
step: 360, loss: 0.13020120561122894
step: 370, loss: 0.015301832929253578
step: 380, loss: 0.022517483681440353
step: 390, loss: 0.09690624475479126
step: 400, loss: 0.04184793680906296
step: 410, loss: 0.19366544485092163
step: 420, loss: 0.060016192495822906
step: 430, loss: 0.0959789901971817
step: 440, loss: 0.10626659542322159
step: 450, loss: 0.06481262296438217
step: 460, loss: 0.1012769490480423
step: 470, loss: 0.09926575422286987
step: 480, loss: 0.1617155820131302
step: 490, loss: 0.06357686221599579
step: 500, loss: 0.1483599841594696
step: 510, loss: 0.1096453070640564
step: 520, loss: 0.10184083878993988
step: 530, loss: 0.1178821325302124
step: 540, loss: 0.18697142601013184
step: 550, loss: 0.057138167321681976
step: 560, loss: 0.14791077375411987
step: 570, loss: 0.08226476609706879
step: 580, loss: 0.046385444700717926
step: 590, loss: 0.10776279866695404
step: 600, loss: 0.05122646689414978
step: 610, loss: 0.17193488776683807
step: 620, loss: 0.06516649574041367
step: 630, loss: 0.1398073136806488
step: 640, loss: 0.12132172286510468
step: 650, loss: 0.11568117886781693
step: 660, loss: 0.11338706314563751
step: 670, loss: 0.06303729861974716
step: 680, loss: 0.277849018573761
step: 690, loss: 0.28033149242401123
step: 700, loss: 0.05012506619095802
step: 710, loss: 0.16310079395771027
step: 720, loss: 0.07985098659992218
step: 730, loss: 0.11349192261695862
step: 740, loss: 0.10133301466703415
step: 750, loss: 0.1089189425110817
step: 760, loss: 0.11342021822929382
step: 770, loss: 0.07021773606538773
step: 780, loss: 0.09331351518630981
step: 790, loss: 0.10621292889118195
step: 800, loss: 0.09175058454275131
step: 810, loss: 0.12209790199995041
step: 820, loss: 0.02944282814860344
step: 830, loss: 0.07421955466270447
step: 840, loss: 0.06530250608921051
step: 850, loss: 0.06112925708293915
step: 860, loss: 0.062246039509773254
step: 870, loss: 0.12101241946220398
step: 880, loss: 0.06426384299993515
step: 890, loss: 0.08301880210638046
step: 900, loss: 0.05383237823843956
step: 910, loss: 0.0548439621925354
step: 920, loss: 0.051822368055582047
step: 930, loss: 0.011945387348532677
step: 940, loss: 0.09997239708900452
step: 950, loss: 0.17988784611225128
step: 960, loss: 0.05327531322836876
step: 970, loss: 0.08324979245662689
epoch 9: dev_f1=0.9318701417466849, f1=0.9281164695177435, best_f1=0.9266968325791854
step: 0, loss: 0.06017033010721207
step: 10, loss: 0.020081430673599243
step: 20, loss: 0.06311678141355515
step: 30, loss: 0.0969243198633194
step: 40, loss: 0.06020854786038399
step: 50, loss: 0.0671219453215599
step: 60, loss: 0.025999823585152626
step: 70, loss: 0.03267073258757591
step: 80, loss: 0.030999623239040375
step: 90, loss: 0.04158928245306015
step: 100, loss: 0.04126361012458801
step: 110, loss: 0.0302073173224926
step: 120, loss: 0.09786009043455124
step: 130, loss: 0.07693009078502655
step: 140, loss: 0.02137288637459278
step: 150, loss: 0.03951616212725639
step: 160, loss: 0.08178094029426575
step: 170, loss: 0.025683922693133354
step: 180, loss: 0.14058445394039154
step: 190, loss: 0.08689028769731522
step: 200, loss: 0.12064959108829498
step: 210, loss: 0.039919495582580566
step: 220, loss: 0.06191268190741539
step: 230, loss: 0.014144284650683403
step: 240, loss: 0.014056408777832985
step: 250, loss: 0.040057726204395294
step: 260, loss: 0.10673962533473969
step: 270, loss: 0.044124212116003036
step: 280, loss: 0.087504543364048
step: 290, loss: 0.04507877677679062
step: 300, loss: 0.017719408497214317
step: 310, loss: 0.09643751382827759
step: 320, loss: 0.14700688421726227
step: 330, loss: 0.11003300547599792
step: 340, loss: 0.03550935536623001
step: 350, loss: 0.03285737708210945
step: 360, loss: 0.0238708034157753
step: 370, loss: 0.03487464040517807
step: 380, loss: 0.11296512931585312
step: 390, loss: 0.06492472440004349
step: 400, loss: 0.07311008125543594
step: 410, loss: 0.010398650541901588
step: 420, loss: 0.08078229427337646
step: 430, loss: 0.13188552856445312
step: 440, loss: 0.0746368020772934
step: 450, loss: 0.15603236854076385
step: 460, loss: 0.06474747508764267
step: 470, loss: 0.08851560205221176
step: 480, loss: 0.18436965346336365
step: 490, loss: 0.03989923745393753
step: 500, loss: 0.20817811787128448
step: 510, loss: 0.17433519661426544
step: 520, loss: 0.0924839898943901
step: 530, loss: 0.11078157275915146
step: 540, loss: 0.029262203723192215
step: 550, loss: 0.056446418166160583
step: 560, loss: 0.05779138207435608
step: 570, loss: 0.09743792563676834
step: 580, loss: 0.10230144113302231
step: 590, loss: 0.10829903930425644
step: 600, loss: 0.058879874646663666
step: 610, loss: 0.2045670747756958
step: 620, loss: 0.2070569097995758
step: 630, loss: 0.08439745008945465
step: 640, loss: 0.074800506234169
step: 650, loss: 0.19293206930160522
step: 660, loss: 0.055389657616615295
step: 670, loss: 0.07812543213367462
step: 680, loss: 0.07569269090890884
step: 690, loss: 0.13315093517303467
step: 700, loss: 0.13638374209403992
step: 710, loss: 0.04073810949921608
step: 720, loss: 0.029578980058431625
step: 730, loss: 0.0007071891450323164
step: 740, loss: 0.04678541049361229
step: 750, loss: 0.09451675415039062
step: 760, loss: 0.1595841348171234
step: 770, loss: 0.05077877268195152
step: 780, loss: 0.06187693774700165
step: 790, loss: 0.03567568585276604
step: 800, loss: 0.15272842347621918
step: 810, loss: 0.15455575287342072
step: 820, loss: 0.1607457548379898
step: 830, loss: 0.14154642820358276
step: 840, loss: 0.1452319175004959
step: 850, loss: 0.05189098045229912
step: 860, loss: 0.014045335352420807
step: 870, loss: 0.24544654786586761
step: 880, loss: 0.1185666173696518
step: 890, loss: 0.08015171438455582
step: 900, loss: 0.1291760951280594
step: 910, loss: 0.10474777966737747
step: 920, loss: 0.04933192953467369
step: 930, loss: 0.08914584666490555
step: 940, loss: 0.08443332463502884
step: 950, loss: 0.23490695655345917
step: 960, loss: 0.014580662362277508
step: 970, loss: 0.018981147557497025
epoch 10: dev_f1=0.9321802457897133, f1=0.9281818181818182, best_f1=0.9266968325791854
step: 0, loss: 0.04139024019241333
step: 10, loss: 0.0069270059466362
step: 20, loss: 0.040899742394685745
step: 30, loss: 0.021187424659729004
step: 40, loss: 0.0309893935918808
step: 50, loss: 0.0231101606041193
step: 60, loss: 0.08580584824085236
step: 70, loss: 0.028007499873638153
step: 80, loss: 0.14713075757026672
step: 90, loss: 0.08118821680545807
step: 100, loss: 0.08396666496992111
step: 110, loss: 0.09752563387155533
step: 120, loss: 0.039567869156599045
step: 130, loss: 0.12849746644496918
step: 140, loss: 0.1155063733458519
step: 150, loss: 0.043951429426670074
step: 160, loss: 0.021705009043216705
step: 170, loss: 0.13637632131576538
step: 180, loss: 0.04202356934547424
step: 190, loss: 0.06094806268811226
step: 200, loss: 0.0330999530851841
step: 210, loss: 0.09718864411115646
step: 220, loss: 0.09744832664728165
step: 230, loss: 0.08050154894590378
step: 240, loss: 0.026485787704586983
step: 250, loss: 0.044812172651290894
step: 260, loss: 0.1831360012292862
step: 270, loss: 0.07270626723766327
step: 280, loss: 0.09361328184604645
step: 290, loss: 0.058148957788944244
step: 300, loss: 0.09281134605407715
step: 310, loss: 0.03352190926671028
step: 320, loss: 0.06022324040532112
step: 330, loss: 0.06830030679702759
step: 340, loss: 0.002838131971657276
step: 350, loss: 0.05919270217418671
step: 360, loss: 0.04345950484275818
step: 370, loss: 0.1221572607755661
step: 380, loss: 0.035557739436626434
step: 390, loss: 0.16841064393520355
step: 400, loss: 0.06362646073102951
step: 410, loss: 0.12099472433328629
step: 420, loss: 0.04113870486617088
step: 430, loss: 0.054389458149671555
step: 440, loss: 0.01158115267753601
step: 450, loss: 0.06995928287506104
step: 460, loss: 0.08674842119216919
step: 470, loss: 0.004289077594876289
step: 480, loss: 0.06378675252199173
step: 490, loss: 0.05706338956952095
step: 500, loss: 0.015879139304161072
step: 510, loss: 0.07058800011873245
step: 520, loss: 0.07795682549476624
step: 530, loss: 0.05189293250441551
step: 540, loss: 0.11710066348314285
step: 550, loss: 0.04660544544458389
step: 560, loss: 0.03122115507721901
step: 570, loss: 0.10054147243499756
step: 580, loss: 0.10750683397054672
step: 590, loss: 0.05787065997719765
step: 600, loss: 0.04945475608110428
step: 610, loss: 0.13189785182476044
step: 620, loss: 0.15903401374816895
step: 630, loss: 0.13023318350315094
step: 640, loss: 0.09312017261981964
step: 650, loss: 0.0824768990278244
step: 660, loss: 0.05601353943347931
step: 670, loss: 0.06152171641588211
step: 680, loss: 0.0483364500105381
step: 690, loss: 0.01090393215417862
step: 700, loss: 0.10933536291122437
step: 710, loss: 0.02940037101507187
step: 720, loss: 0.12270846962928772
step: 730, loss: 0.04122329130768776
step: 740, loss: 0.07653290033340454
step: 750, loss: 0.08761177211999893
step: 760, loss: 0.06081598997116089
step: 770, loss: 0.02002626657485962
step: 780, loss: 0.06621204316616058
step: 790, loss: 0.03782328963279724
step: 800, loss: 0.13830441236495972
step: 810, loss: 0.029801655560731888
step: 820, loss: 0.028903072699904442
step: 830, loss: 0.1711428463459015
step: 840, loss: 0.10337046533823013
step: 850, loss: 0.1237846314907074
step: 860, loss: 0.09081421047449112
step: 870, loss: 0.15838442742824554
step: 880, loss: 0.02411709725856781
step: 890, loss: 0.03428054228425026
step: 900, loss: 0.05256626754999161
step: 910, loss: 0.18135090172290802
step: 920, loss: 0.14907558262348175
step: 930, loss: 0.10729972273111343
step: 940, loss: 0.0349414199590683
step: 950, loss: 0.036649737507104874
step: 960, loss: 0.13052432239055634
step: 970, loss: 0.19933874905109406
epoch 11: dev_f1=0.9327846364883402, f1=0.9322344322344323, best_f1=0.9266968325791854
step: 0, loss: 0.05708744749426842
step: 10, loss: 0.012571717612445354
step: 20, loss: 0.05737430602312088
step: 30, loss: 0.05099543184041977
step: 40, loss: 0.08492539077997208
step: 50, loss: 0.18785689771175385
step: 60, loss: 0.0001678531407378614
step: 70, loss: 0.05325740575790405
step: 80, loss: 0.10364468395709991
step: 90, loss: 0.04047095403075218
step: 100, loss: 0.030759479850530624
step: 110, loss: 0.03416774421930313
step: 120, loss: 0.049753859639167786
step: 130, loss: 0.12547211349010468
step: 140, loss: 0.06875838339328766
step: 150, loss: 0.038543425500392914
step: 160, loss: 0.10620469599962234
step: 170, loss: 0.16823981702327728
step: 180, loss: 0.037861645221710205
step: 190, loss: 0.03068084642291069
step: 200, loss: 0.013319624587893486
step: 210, loss: 0.06169280782341957
step: 220, loss: 0.09136080741882324
step: 230, loss: 0.11842591315507889
step: 240, loss: 0.014106654562056065
step: 250, loss: 0.04202426224946976
step: 260, loss: 0.00798475556075573
step: 270, loss: 0.07944095134735107
step: 280, loss: 0.1858503818511963
step: 290, loss: 0.07631511241197586
step: 300, loss: 0.03905211389064789
step: 310, loss: 2.877988481486682e-05
step: 320, loss: 0.09935612976551056
step: 330, loss: 0.01716610975563526
step: 340, loss: 0.14163358509540558
step: 350, loss: 0.12517967820167542
step: 360, loss: 0.06322931498289108
step: 370, loss: 0.06620293110609055
step: 380, loss: 0.04955840855836868
step: 390, loss: 0.08375570178031921
step: 400, loss: 0.08645255863666534
step: 410, loss: 0.049837928265333176
step: 420, loss: 0.05306173115968704
step: 430, loss: 0.04816930741071701
step: 440, loss: 0.10457568615674973
step: 450, loss: 0.07554516941308975
step: 460, loss: 0.05605681240558624
step: 470, loss: 0.041840266436338425
step: 480, loss: 0.022425508126616478
step: 490, loss: 0.005175672471523285
step: 500, loss: 0.19102348387241364
step: 510, loss: 0.07593747973442078
step: 520, loss: 0.12452825903892517
step: 530, loss: 0.03870249167084694
step: 540, loss: 0.04585939645767212
step: 550, loss: 0.07003896683454514
step: 560, loss: 0.04459572583436966
step: 570, loss: 0.09350716322660446
step: 580, loss: 0.04389272257685661
step: 590, loss: 0.0553315207362175
step: 600, loss: 0.06730671972036362
step: 610, loss: 0.03517810255289078
step: 620, loss: 0.045779407024383545
step: 630, loss: 0.07293302565813065
step: 640, loss: 0.02576850727200508
step: 650, loss: 0.02744099497795105
step: 660, loss: 0.09181976318359375
step: 670, loss: 0.09083261340856552
step: 680, loss: 0.06067284941673279
step: 690, loss: 0.16284239292144775
step: 700, loss: 0.1050519198179245
step: 710, loss: 0.08099067956209183
step: 720, loss: 0.04478989169001579
step: 730, loss: 0.09723172336816788
step: 740, loss: 0.07576169818639755
step: 750, loss: 0.1267472505569458
step: 760, loss: 0.16170790791511536
step: 770, loss: 0.0623793788254261
step: 780, loss: 0.036176715046167374
step: 790, loss: 0.050175122916698456
step: 800, loss: 0.10141070932149887
step: 810, loss: 0.10462099313735962
step: 820, loss: 0.053133923560380936
step: 830, loss: 0.10502862930297852
step: 840, loss: 0.0834469422698021
step: 850, loss: 0.004884663503617048
step: 860, loss: 0.049456026405096054
step: 870, loss: 0.06147695332765579
step: 880, loss: 0.09213573485612869
step: 890, loss: 0.11704455316066742
step: 900, loss: 0.018013253808021545
step: 910, loss: 0.08100105077028275
step: 920, loss: 0.03911083564162254
step: 930, loss: 0.07018222659826279
step: 940, loss: 0.16539958119392395
step: 950, loss: 0.0488785095512867
step: 960, loss: 0.1377410739660263
step: 970, loss: 0.013266336172819138
epoch 12: dev_f1=0.9341317365269461, f1=0.9269870609981515, best_f1=0.9266968325791854
step: 0, loss: 0.05146648362278938
step: 10, loss: 0.07958423346281052
step: 20, loss: 0.08177206665277481
step: 30, loss: 0.0859808474779129
step: 40, loss: 0.01353132538497448
step: 50, loss: 0.10848351567983627
step: 60, loss: 0.09471360594034195
step: 70, loss: 0.08523493260145187
step: 80, loss: 0.0744921863079071
step: 90, loss: 0.05066027119755745
step: 100, loss: 0.05868218094110489
step: 110, loss: 0.11997565627098083
step: 120, loss: 0.03650527074933052
step: 130, loss: 0.04304734990000725
step: 140, loss: 0.054773781448602676
step: 150, loss: 0.06857682764530182
step: 160, loss: 0.07971201837062836
step: 170, loss: 0.08010057359933853
step: 180, loss: 0.01673138327896595
step: 190, loss: 0.028092773631215096
step: 200, loss: 0.054438285529613495
step: 210, loss: 0.004846342373639345
step: 220, loss: 0.04680832102894783
step: 230, loss: 0.02551666647195816
step: 240, loss: 0.05186896771192551
step: 250, loss: 0.07844177633523941
step: 260, loss: 0.0826040729880333
step: 270, loss: 0.08854303508996964
step: 280, loss: 0.014725865796208382
step: 290, loss: 0.028667043894529343
step: 300, loss: 0.026703739538788795
step: 310, loss: 0.02571549080312252
step: 320, loss: 0.07252103090286255
step: 330, loss: 0.03924119845032692
step: 340, loss: 0.06361890584230423
step: 350, loss: 0.08128740638494492
step: 360, loss: 0.057979606091976166
step: 370, loss: 0.09808336943387985
step: 380, loss: 0.037526749074459076
step: 390, loss: 1.5139299648581073e-05
step: 400, loss: 0.08883760124444962
step: 410, loss: 0.09262806177139282
step: 420, loss: 0.06651351600885391
step: 430, loss: 0.01834501139819622
step: 440, loss: 0.17106623947620392
step: 450, loss: 0.03034086525440216
step: 460, loss: 0.004987610038369894
step: 470, loss: 0.08640404790639877
step: 480, loss: 0.03638885170221329
step: 490, loss: 0.07979617267847061
step: 500, loss: 0.0377352312207222
step: 510, loss: 0.06492224335670471
step: 520, loss: 0.10346736758947372
step: 530, loss: 0.08106943964958191
step: 540, loss: 0.09124419093132019
step: 550, loss: 0.05722619220614433
step: 560, loss: 0.1537189781665802
step: 570, loss: 0.03520806133747101
step: 580, loss: 0.11319088935852051
step: 590, loss: 0.0686393678188324
step: 600, loss: 0.057171616703271866
step: 610, loss: 3.8372152630472556e-05
step: 620, loss: 0.05694299563765526
step: 630, loss: 0.029511529952287674
step: 640, loss: 0.060925669968128204
step: 650, loss: 0.09167569875717163
step: 660, loss: 0.10926935821771622
step: 670, loss: 0.0009911258239299059
step: 680, loss: 0.02580711618065834
step: 690, loss: 0.04282933846116066
step: 700, loss: 0.1299050748348236
step: 710, loss: 0.13952690362930298
step: 720, loss: 0.04594874382019043
step: 730, loss: 0.08591889590024948
step: 740, loss: 0.05969909206032753
step: 750, loss: 0.15391787886619568
step: 760, loss: 0.06134631112217903
step: 770, loss: 0.12126363813877106
step: 780, loss: 0.09409864246845245
step: 790, loss: 0.1525145024061203
step: 800, loss: 0.07826808094978333
step: 810, loss: 0.06813959777355194
step: 820, loss: 0.10456550121307373
step: 830, loss: 0.03951959311962128
step: 840, loss: 0.11289426684379578
step: 850, loss: 0.13344727456569672
step: 860, loss: 0.09807457029819489
step: 870, loss: 0.06161757558584213
step: 880, loss: 0.0803777426481247
step: 890, loss: 0.12488876283168793
step: 900, loss: 0.14743998646736145
step: 910, loss: 0.04978920891880989
step: 920, loss: 0.0346662774682045
step: 930, loss: 0.08718001842498779
step: 940, loss: 0.20365436375141144
step: 950, loss: 0.05999518558382988
step: 960, loss: 0.06526175141334534
step: 970, loss: 0.2548842430114746
epoch 13: dev_f1=0.927694406548431, f1=0.9214707217430775, best_f1=0.9266968325791854
step: 0, loss: 0.062344472855329514
step: 10, loss: 0.037964921444654465
step: 20, loss: 0.04644478112459183
step: 30, loss: 0.06619612872600555
step: 40, loss: 0.062044572085142136
step: 50, loss: 0.05115429684519768
step: 60, loss: 0.0037905804347246885
step: 70, loss: 0.0242573581635952
step: 80, loss: 0.08113117516040802
step: 90, loss: 0.04082469269633293
step: 100, loss: 0.049783118069171906
step: 110, loss: 0.07449420541524887
step: 120, loss: 0.06335030496120453
step: 130, loss: 0.12325537204742432
step: 140, loss: 0.015831230208277702
step: 150, loss: 0.10163980722427368
step: 160, loss: 0.0318223237991333
step: 170, loss: 0.05859855189919472
step: 180, loss: 0.02960333228111267
step: 190, loss: 0.10939143598079681
step: 200, loss: 0.07900048792362213
step: 210, loss: 0.03201555833220482
step: 220, loss: 0.025598211213946342
step: 230, loss: 0.05404151603579521
step: 240, loss: 0.06486976146697998
step: 250, loss: 0.09687582403421402
step: 260, loss: 0.021641839295625687
step: 270, loss: 0.07226138561964035
step: 280, loss: 0.07345227152109146
step: 290, loss: 0.07604354619979858
step: 300, loss: 0.16870644688606262
step: 310, loss: 0.03924291953444481
step: 320, loss: 0.054605767130851746
step: 330, loss: 0.07175140827894211
step: 340, loss: 0.007489692885428667
step: 350, loss: 0.03244861215353012
step: 360, loss: 0.0727597177028656
step: 370, loss: 0.028126755729317665
step: 380, loss: 0.09734735637903214
step: 390, loss: 0.04341256245970726
step: 400, loss: 0.03270765766501427
step: 410, loss: 0.11163613200187683
step: 420, loss: 0.0915989950299263
step: 430, loss: 0.10537487268447876
step: 440, loss: 0.015067596919834614
step: 450, loss: 0.10073800384998322
step: 460, loss: 0.029758915305137634
step: 470, loss: 0.15211716294288635
step: 480, loss: 0.07628405094146729
step: 490, loss: 0.082175113260746
step: 500, loss: 0.1179458349943161
step: 510, loss: 0.02248142473399639
step: 520, loss: 0.029649129137396812
step: 530, loss: 0.03623826056718826
step: 540, loss: 0.02729436755180359
step: 550, loss: 0.056980494409799576
step: 560, loss: 0.06999974697828293
step: 570, loss: 0.023024719208478928
step: 580, loss: 0.08521232008934021
step: 590, loss: 0.12461315840482712
step: 600, loss: 0.0844997689127922
step: 610, loss: 0.041045546531677246
step: 620, loss: 0.07172555476427078
step: 630, loss: 0.028044871985912323
step: 640, loss: 0.05408567562699318
step: 650, loss: 0.05333718657493591
step: 660, loss: 0.10644448548555374
step: 670, loss: 0.021484406664967537
step: 680, loss: 0.054146986454725266
step: 690, loss: 0.05801411345601082
step: 700, loss: 0.031571388244628906
step: 710, loss: 0.11994762718677521
step: 720, loss: 0.04565496742725372
step: 730, loss: 0.06704679876565933
step: 740, loss: 0.08786311745643616
step: 750, loss: 0.06733295321464539
step: 760, loss: 0.09182601422071457
step: 770, loss: 0.11000404506921768
step: 780, loss: 0.07504280656576157
step: 790, loss: 0.01290823519229889
step: 800, loss: 0.12447656691074371
step: 810, loss: 0.012986012734472752
step: 820, loss: 0.041385360062122345
step: 830, loss: 0.03351505845785141
step: 840, loss: 0.151524156332016
step: 850, loss: 0.044265542179346085
step: 860, loss: 0.05337176099419594
step: 870, loss: 0.0007488445844501257
step: 880, loss: 0.06471113115549088
step: 890, loss: 0.008268479257822037
step: 900, loss: 0.0008018738590180874
step: 910, loss: 0.01308720838278532
step: 920, loss: 0.04283194988965988
step: 930, loss: 0.08342095464468002
step: 940, loss: 0.07085014879703522
step: 950, loss: 0.03188958764076233
step: 960, loss: 0.09650571644306183
step: 970, loss: 0.1106204017996788
epoch 14: dev_f1=0.935064935064935, f1=0.9321561338289963, best_f1=0.9321561338289963
step: 0, loss: 0.03686210885643959
step: 10, loss: 0.05561153590679169
step: 20, loss: 0.10341669619083405
step: 30, loss: 0.07331860065460205
step: 40, loss: 0.015647703781723976
step: 50, loss: 0.10435226559638977
step: 60, loss: 0.04223142936825752
step: 70, loss: 0.03887917846441269
step: 80, loss: 0.06357673555612564
step: 90, loss: 0.00874150637537241
step: 100, loss: 0.009499355219304562
step: 110, loss: 0.007150684483349323
step: 120, loss: 0.0698167085647583
step: 130, loss: 0.048054128885269165
step: 140, loss: 0.055576395243406296
step: 150, loss: 0.0654296725988388
step: 160, loss: 0.0016194519121199846
step: 170, loss: 0.0004350488306954503
step: 180, loss: 0.025421680882573128
step: 190, loss: 0.09732717275619507
step: 200, loss: 0.0768967717885971
step: 210, loss: 0.10606853663921356
step: 220, loss: 0.11608706414699554
step: 230, loss: 0.09129796177148819
step: 240, loss: 0.09791054576635361
step: 250, loss: 0.03536178544163704
step: 260, loss: 0.10163181275129318
step: 270, loss: 0.04473908618092537
step: 280, loss: 0.06948616355657578
step: 290, loss: 0.02702188491821289
step: 300, loss: 0.021757347509264946
step: 310, loss: 0.03330602869391441
step: 320, loss: 0.02704433538019657
step: 330, loss: 0.05389857292175293
step: 340, loss: 0.058138079941272736
step: 350, loss: 0.024269232526421547
step: 360, loss: 0.05670619755983353
step: 370, loss: 0.08436750620603561
step: 380, loss: 0.06600525975227356
step: 390, loss: 0.04634685069322586
step: 400, loss: 0.0003169491537846625
step: 410, loss: 0.02985747531056404
step: 420, loss: 0.015990687534213066
step: 430, loss: 0.044192999601364136
step: 440, loss: 0.030065052211284637
step: 450, loss: 0.050955478101968765
step: 460, loss: 0.03953327238559723
step: 470, loss: 0.10191170871257782
step: 480, loss: 0.025733454152941704
step: 490, loss: 0.059405844658613205
step: 500, loss: 0.05076410248875618
step: 510, loss: 0.029662922024726868
step: 520, loss: 0.06029645726084709
step: 530, loss: 0.03827587142586708
step: 540, loss: 0.020351948216557503
step: 550, loss: 0.08563342690467834
step: 560, loss: 0.024583077058196068
step: 570, loss: 0.0877801850438118
step: 580, loss: 0.07968074083328247
step: 590, loss: 0.01586725190281868
step: 600, loss: 0.03464675322175026
step: 610, loss: 0.15589144825935364
step: 620, loss: 0.08602601289749146
step: 630, loss: 0.0689167007803917
step: 640, loss: 1.2874459571321495e-05
step: 650, loss: 0.048767633736133575
step: 660, loss: 0.005217336118221283
step: 670, loss: 0.07699260860681534
step: 680, loss: 0.02570982091128826
step: 690, loss: 0.09669313579797745
step: 700, loss: 0.02040237747132778
step: 710, loss: 0.050079066306352615
step: 720, loss: 0.03630252927541733
step: 730, loss: 0.10971463471651077
step: 740, loss: 0.07123558223247528
step: 750, loss: 0.06459949165582657
step: 760, loss: 0.0849127247929573
step: 770, loss: 0.1715293973684311
step: 780, loss: 0.07255064696073532
step: 790, loss: 0.15397417545318604
step: 800, loss: 0.02401086688041687
step: 810, loss: 0.0333835743367672
step: 820, loss: 0.0902455672621727
step: 830, loss: 0.050733741372823715
step: 840, loss: 0.05084541440010071
step: 850, loss: 0.02206460013985634
step: 860, loss: 0.057323817163705826
step: 870, loss: 0.07475658506155014
step: 880, loss: 0.06996093690395355
step: 890, loss: 4.341959720477462e-05
step: 900, loss: 0.08419568091630936
step: 910, loss: 0.1496938318014145
step: 920, loss: 0.046037983149290085
step: 930, loss: 0.06261146068572998
step: 940, loss: 0.08109530806541443
step: 950, loss: 0.07311270385980606
step: 960, loss: 0.02925776317715645
step: 970, loss: 0.0549427792429924
epoch 15: dev_f1=0.9316081330868762, f1=0.9260450160771704, best_f1=0.9321561338289963
step: 0, loss: 0.03343461826443672
step: 10, loss: 0.11454653739929199
step: 20, loss: 0.07443973422050476
step: 30, loss: 0.07285980135202408
step: 40, loss: 0.07275988161563873
step: 50, loss: 0.11860063672065735
step: 60, loss: 0.0011618859134614468
step: 70, loss: 0.03992028534412384
step: 80, loss: 0.05993863195180893
step: 90, loss: 0.0714605376124382
step: 100, loss: 0.10857241600751877
step: 110, loss: 0.05589580908417702
step: 120, loss: 0.08641395717859268
step: 130, loss: 0.09799286723136902
step: 140, loss: 0.0977800264954567
step: 150, loss: 0.025925394147634506
step: 160, loss: 0.1104302704334259
step: 170, loss: 0.10617680847644806
step: 180, loss: 0.04848240315914154
step: 190, loss: 0.04833237826824188
step: 200, loss: 0.016986873000860214
step: 210, loss: 0.03708605468273163
step: 220, loss: 0.0613996684551239
step: 230, loss: 0.010032355785369873
step: 240, loss: 0.02095242217183113
step: 250, loss: 0.037364810705184937
step: 260, loss: 0.045007266104221344
step: 270, loss: 0.061726439744234085
step: 280, loss: 0.14130209386348724
step: 290, loss: 0.006518566980957985
step: 300, loss: 0.052186619490385056
step: 310, loss: 0.10123060643672943
step: 320, loss: 0.05045130476355553
step: 330, loss: 0.08244474232196808
step: 340, loss: 0.14459927380084991
step: 350, loss: 0.02392398752272129
step: 360, loss: 0.14039228856563568
step: 370, loss: 0.08043286204338074
step: 380, loss: 0.15306900441646576
step: 390, loss: 0.0766761377453804
step: 400, loss: 0.16963347792625427
step: 410, loss: 0.02626393362879753
step: 420, loss: 0.01948011852800846
step: 430, loss: 0.07123375684022903
step: 440, loss: 0.12749864161014557
step: 450, loss: 0.06154509261250496
step: 460, loss: 0.011631293222308159
step: 470, loss: 0.10251057147979736
step: 480, loss: 0.02238873951137066
step: 490, loss: 0.0001530059234937653
step: 500, loss: 0.03632144257426262
step: 510, loss: 0.008051764219999313
step: 520, loss: 0.02050352655351162
step: 530, loss: 0.06165165826678276
step: 540, loss: 0.06685523688793182
step: 550, loss: 0.08153335005044937
step: 560, loss: 0.06940598040819168
step: 570, loss: 0.12574344873428345
step: 580, loss: 0.03564666584134102
step: 590, loss: 0.026187194511294365
step: 600, loss: 0.06685586273670197
step: 610, loss: 0.03744411841034889
step: 620, loss: 0.02032792568206787
step: 630, loss: 0.08340518176555634
step: 640, loss: 0.01723802648484707
step: 650, loss: 0.1793900728225708
step: 660, loss: 0.015223221853375435
step: 670, loss: 0.11808296293020248
step: 680, loss: 0.026543330401182175
step: 690, loss: 0.050271254032850266
step: 700, loss: 0.08362535387277603
step: 710, loss: 0.07089442014694214
step: 720, loss: 0.09548057615756989
step: 730, loss: 0.032468073070049286
step: 740, loss: 0.05000782385468483
step: 750, loss: 0.031897906213998795
step: 760, loss: 0.013071032240986824
step: 770, loss: 0.09801924228668213
step: 780, loss: 0.14085254073143005
step: 790, loss: 0.043797146528959274
step: 800, loss: 0.05632052198052406
step: 810, loss: 0.013737387023866177
step: 820, loss: 0.04564940556883812
step: 830, loss: 0.09888723492622375
step: 840, loss: 2.6641724616638385e-05
step: 850, loss: 0.0764976367354393
step: 860, loss: 0.04036484286189079
step: 870, loss: 0.02438708022236824
step: 880, loss: 0.0350453183054924
step: 890, loss: 0.07118285447359085
step: 900, loss: 0.10807761549949646
step: 910, loss: 0.016268711537122726
step: 920, loss: 0.11263459920883179
step: 930, loss: 0.013414014130830765
step: 940, loss: 0.004281068220734596
step: 950, loss: 0.014858095906674862
step: 960, loss: 0.06447016447782516
step: 970, loss: 0.10091929137706757
epoch 16: dev_f1=0.929889298892989, f1=0.928505957836847, best_f1=0.9321561338289963
step: 0, loss: 0.0411137230694294
step: 10, loss: 0.056526217609643936
step: 20, loss: 0.03351982682943344
step: 30, loss: 0.10193029791116714
step: 40, loss: 0.03312097489833832
step: 50, loss: 0.0007994325715117157
step: 60, loss: 0.007689901161938906
step: 70, loss: 0.13456574082374573
step: 80, loss: 0.000560289598070085
step: 90, loss: 0.025315940380096436
step: 100, loss: 0.07662759721279144
step: 110, loss: 0.017789606004953384
step: 120, loss: 9.316945215687156e-05
step: 130, loss: 0.03374373912811279
step: 140, loss: 0.043136339634656906
step: 150, loss: 0.07869744300842285
step: 160, loss: 0.08268284797668457
step: 170, loss: 0.04454675316810608
step: 180, loss: 6.832479266449809e-05
step: 190, loss: 0.04194270074367523
step: 200, loss: 0.0847238302230835
step: 210, loss: 0.031342461705207825
step: 220, loss: 0.09477706253528595
step: 230, loss: 0.0008928413153626025
step: 240, loss: 0.13395513594150543
step: 250, loss: 0.03877304866909981
step: 260, loss: 0.003059990704059601
step: 270, loss: 0.02976754866540432
step: 280, loss: 0.050979018211364746
step: 290, loss: 0.0966978371143341
step: 300, loss: 0.00428397860378027
step: 310, loss: 0.03933354839682579
step: 320, loss: 0.09422259777784348
step: 330, loss: 0.03407789394259453
step: 340, loss: 0.0001370369573123753
step: 350, loss: 0.05373295024037361
step: 360, loss: 0.000665648840367794
step: 370, loss: 0.0714137926697731
step: 380, loss: 0.1349838227033615
step: 390, loss: 0.10448970645666122
step: 400, loss: 0.07928410917520523
step: 410, loss: 0.01929425075650215
step: 420, loss: 0.06333757936954498
step: 430, loss: 0.06691595911979675
step: 440, loss: 0.029681747779250145
step: 450, loss: 0.0549006424844265
step: 460, loss: 0.034792762249708176
step: 470, loss: 0.017343083396553993
step: 480, loss: 0.045928485691547394
step: 490, loss: 0.15604381263256073
step: 500, loss: 0.019519459456205368
step: 510, loss: 0.04146893694996834
step: 520, loss: 0.012907493859529495
step: 530, loss: 0.00990230217576027
step: 540, loss: 0.0253123976290226
step: 550, loss: 0.07203038036823273
step: 560, loss: 0.09024454653263092
step: 570, loss: 0.051423534750938416
step: 580, loss: 0.05086793005466461
step: 590, loss: 0.03544851392507553
step: 600, loss: 0.024566028267145157
step: 610, loss: 0.06474079936742783
step: 620, loss: 0.11024810373783112
step: 630, loss: 0.12597617506980896
step: 640, loss: 0.001960498047992587
step: 650, loss: 0.12285485118627548
step: 660, loss: 0.01494740042835474
step: 670, loss: 0.08410283923149109
step: 680, loss: 0.0178481824696064
step: 690, loss: 0.08139724284410477
step: 700, loss: 0.000806399795692414
step: 710, loss: 0.05341064929962158
step: 720, loss: 0.05921987444162369
step: 730, loss: 0.002396184951066971
step: 740, loss: 0.08025103062391281
step: 750, loss: 0.03393855690956116
step: 760, loss: 0.05475901439785957
step: 770, loss: 0.018704911693930626
step: 780, loss: 0.04305657371878624
step: 790, loss: 0.030349677428603172
step: 800, loss: 0.06430678814649582
step: 810, loss: 0.11222603917121887
step: 820, loss: 0.029263772070407867
step: 830, loss: 0.0034083330538123846
step: 840, loss: 0.057263538241386414
step: 850, loss: 0.08076801151037216
step: 860, loss: 0.025049690157175064
step: 870, loss: 0.08827927708625793
step: 880, loss: 0.0598771795630455
step: 890, loss: 0.0507066547870636
step: 900, loss: 0.01632092520594597
step: 910, loss: 0.0639919564127922
step: 920, loss: 0.09597102552652359
step: 930, loss: 0.020685523748397827
step: 940, loss: 0.14234277606010437
step: 950, loss: 0.06858453899621964
step: 960, loss: 0.05240461230278015
step: 970, loss: 0.025604359805583954
epoch 17: dev_f1=0.9215777262180975, f1=0.9305108145421077, best_f1=0.9321561338289963
step: 0, loss: 0.02998627908527851
step: 10, loss: 0.03703625127673149
step: 20, loss: 0.01692746765911579
step: 30, loss: 0.12677687406539917
step: 40, loss: 0.0001316565612796694
step: 50, loss: 0.03608410432934761
step: 60, loss: 0.07221423089504242
step: 70, loss: 0.02931373566389084
step: 80, loss: 0.009754038415849209
step: 90, loss: 0.07373636960983276
step: 100, loss: 0.010715899057686329
step: 110, loss: 0.06477915495634079
step: 120, loss: 0.0015579011524096131
step: 130, loss: 0.05363157391548157
step: 140, loss: 0.0014271539403125644
step: 150, loss: 0.0007726477342657745
step: 160, loss: 0.030784856528043747
step: 170, loss: 0.05518601834774017
step: 180, loss: 0.045738790184259415
step: 190, loss: 0.12458456307649612
step: 200, loss: 0.027856100350618362
step: 210, loss: 0.07193075120449066
step: 220, loss: 0.05197206512093544
step: 230, loss: 0.044681914150714874
step: 240, loss: 0.03842230886220932
step: 250, loss: 0.031358752399683
step: 260, loss: 0.06402812898159027
step: 270, loss: 0.04936631768941879
step: 280, loss: 0.040712375193834305
step: 290, loss: 0.07056973874568939
step: 300, loss: 0.03139524906873703
step: 310, loss: 0.020094959065318108
step: 320, loss: 0.03719763830304146
step: 330, loss: 0.047685522586107254
step: 340, loss: 0.06438881903886795
step: 350, loss: 0.08243676275014877
step: 360, loss: 0.05538833141326904
step: 370, loss: 0.013124627992510796
step: 380, loss: 0.12509770691394806
step: 390, loss: 0.03589386120438576
step: 400, loss: 0.05089602991938591
step: 410, loss: 0.05632321536540985
step: 420, loss: 0.11166632175445557
step: 430, loss: 0.011520088650286198
step: 440, loss: 0.029447542503476143
step: 450, loss: 0.06286602467298508
step: 460, loss: 0.056125249713659286
step: 470, loss: 0.05423031002283096
step: 480, loss: 0.05782047286629677
step: 490, loss: 0.06070141866803169
step: 500, loss: 0.13942043483257294
step: 510, loss: 0.08752564340829849
step: 520, loss: 0.0006368749891407788
step: 530, loss: 0.05667297914624214
step: 540, loss: 0.08713312447071075
step: 550, loss: 0.048101358115673065
step: 560, loss: 0.03851121664047241
step: 570, loss: 0.09112946689128876
step: 580, loss: 0.046765994280576706
step: 590, loss: 0.0877314954996109
step: 600, loss: 0.04447997733950615
step: 610, loss: 0.08780207484960556
step: 620, loss: 0.04055008292198181
step: 630, loss: 0.17512071132659912
step: 640, loss: 0.2003396451473236
step: 650, loss: 0.00014472044131252915
step: 660, loss: 0.038663800805807114
step: 670, loss: 0.04872230812907219
step: 680, loss: 0.056689247488975525
step: 690, loss: 0.0011576978722587228
step: 700, loss: 0.14698158204555511
step: 710, loss: 0.0037070477847009897
step: 720, loss: 0.055326059460639954
step: 730, loss: 0.03892067074775696
step: 740, loss: 0.07849595695734024
step: 750, loss: 0.0013956488110125065
step: 760, loss: 0.0444381944835186
step: 770, loss: 0.0044268034398555756
step: 780, loss: 0.023920267820358276
step: 790, loss: 0.047090981155633926
step: 800, loss: 0.03300374001264572
step: 810, loss: 0.05876122787594795
step: 820, loss: 0.0922330766916275
step: 830, loss: 0.01810961402952671
step: 840, loss: 0.05666359141469002
step: 850, loss: 0.03103252686560154
step: 860, loss: 0.03012808971107006
step: 870, loss: 0.04166558012366295
step: 880, loss: 0.05324460566043854
step: 890, loss: 0.04363502934575081
step: 900, loss: 0.02227235957980156
step: 910, loss: 0.01783529669046402
step: 920, loss: 0.06664888560771942
step: 930, loss: 0.0010197240626439452
step: 940, loss: 0.058376532047986984
step: 950, loss: 0.10206684470176697
step: 960, loss: 0.04181809350848198
step: 970, loss: 0.025296727195382118
epoch 18: dev_f1=0.924791086350975, f1=0.9281767955801105, best_f1=0.9321561338289963
step: 0, loss: 1.8215083400718868e-05
step: 10, loss: 0.017035486176609993
step: 20, loss: 0.01845654845237732
step: 30, loss: 0.06555593013763428
step: 40, loss: 0.07656930387020111
step: 50, loss: 0.0001566064020153135
step: 60, loss: 0.12039631605148315
step: 70, loss: 0.019298771396279335
step: 80, loss: 0.08610661327838898
step: 90, loss: 0.033146802335977554
step: 100, loss: 0.012188701890408993
step: 110, loss: 0.0391216017305851
step: 120, loss: 0.0527351088821888
step: 130, loss: 0.062239598482847214
step: 140, loss: 0.02002587355673313
step: 150, loss: 0.007411406375467777
step: 160, loss: 0.04300430044531822
step: 170, loss: 0.08049919456243515
step: 180, loss: 0.002368172165006399
step: 190, loss: 2.7967700589215383e-05
step: 200, loss: 0.0675770491361618
step: 210, loss: 0.028518063947558403
step: 220, loss: 0.07195138931274414
step: 230, loss: 0.07352294027805328
step: 240, loss: 0.044401057064533234
step: 250, loss: 0.05958658084273338
step: 260, loss: 0.04172138869762421
step: 270, loss: 0.058074358850717545
step: 280, loss: 0.03935556858778
step: 290, loss: 0.04217606782913208
step: 300, loss: 0.08364077657461166
step: 310, loss: 0.08926162123680115
step: 320, loss: 0.026711558923125267
step: 330, loss: 0.03860500454902649
step: 340, loss: 0.0001248960179509595
step: 350, loss: 2.4767903596512042e-05
step: 360, loss: 0.07517679035663605
step: 370, loss: 0.08020991832017899
step: 380, loss: 0.01054568774998188
step: 390, loss: 0.030533814802765846
step: 400, loss: 0.024905644357204437
step: 410, loss: 0.01057189330458641
step: 420, loss: 0.00038451660657301545
step: 430, loss: 0.07426853477954865
step: 440, loss: 0.022197794169187546
step: 450, loss: 0.021417826414108276
step: 460, loss: 0.07297953218221664
step: 470, loss: 0.04374800994992256
step: 480, loss: 0.06881552189588547
step: 490, loss: 0.04077153652906418
step: 500, loss: 0.034214623272418976
step: 510, loss: 0.0906219333410263
step: 520, loss: 0.016584189608693123
step: 530, loss: 0.06440754234790802
step: 540, loss: 0.07908949255943298
step: 550, loss: 0.05353763699531555
step: 560, loss: 0.0409725084900856
step: 570, loss: 0.10990975052118301
step: 580, loss: 0.030791128054261208
step: 590, loss: 0.036059942096471786
step: 600, loss: 0.07936002314090729
step: 610, loss: 0.17978624999523163
step: 620, loss: 0.0230718981474638
step: 630, loss: 0.12139246612787247
step: 640, loss: 0.04264707863330841
step: 650, loss: 0.02113804593682289
step: 660, loss: 0.00013701328134629875
step: 670, loss: 0.027701854705810547
step: 680, loss: 0.05178403854370117
step: 690, loss: 0.11704447865486145
step: 700, loss: 0.02857283130288124
step: 710, loss: 0.03976697474718094
step: 720, loss: 0.04251466318964958
step: 730, loss: 0.06279679387807846
step: 740, loss: 0.0695897564291954
step: 750, loss: 0.0375627800822258
step: 760, loss: 0.04918050765991211
step: 770, loss: 0.021762080490589142
step: 780, loss: 0.036649998277425766
step: 790, loss: 0.0683123990893364
step: 800, loss: 0.03457079827785492
step: 810, loss: 0.009515621699392796
step: 820, loss: 0.06513696908950806
step: 830, loss: 0.09696302562952042
step: 840, loss: 0.021219642832875252
step: 850, loss: 0.06319686770439148
step: 860, loss: 0.025049081072211266
step: 870, loss: 0.0006890445365570486
step: 880, loss: 0.03797122463583946
step: 890, loss: 0.09235449135303497
step: 900, loss: 0.032861702144145966
step: 910, loss: 0.0014278192538768053
step: 920, loss: 0.11232013255357742
step: 930, loss: 0.05968654900789261
step: 940, loss: 0.03671741485595703
step: 950, loss: 0.009539157152175903
step: 960, loss: 0.050112999975681305
step: 970, loss: 0.03448605164885521
epoch 19: dev_f1=0.923581809657759, f1=0.9266480965645311, best_f1=0.9321561338289963
step: 0, loss: 0.042745672166347504
step: 10, loss: 0.02686833031475544
step: 20, loss: 0.051736414432525635
step: 30, loss: 0.07029940187931061
step: 40, loss: 0.03668581321835518
step: 50, loss: 0.07330986857414246
step: 60, loss: 0.024578433483839035
step: 70, loss: 0.07209917902946472
step: 80, loss: 0.05121214687824249
step: 90, loss: 0.045589372515678406
step: 100, loss: 0.07053938508033752
step: 110, loss: 0.028872553259134293
step: 120, loss: 0.0013989015715196729
step: 130, loss: 0.15259909629821777
step: 140, loss: 0.10302302986383438
step: 150, loss: 0.0706799328327179
step: 160, loss: 0.044170282781124115
step: 170, loss: 0.015425565652549267
step: 180, loss: 0.055479761213064194
step: 190, loss: 0.09813162684440613
step: 200, loss: 0.07362483441829681
step: 210, loss: 0.05846267566084862
step: 220, loss: 0.021580848842859268
step: 230, loss: 0.08150198310613632
step: 240, loss: 0.06508634239435196
step: 250, loss: 0.02580123394727707
step: 260, loss: 0.052359987050294876
step: 270, loss: 0.01889803260564804
step: 280, loss: 0.0330812931060791
step: 290, loss: 0.05332367494702339
step: 300, loss: 0.017975276336073875
step: 310, loss: 0.038112737238407135
step: 320, loss: 0.08159621804952621
step: 330, loss: 0.082127645611763
step: 340, loss: 0.029202571138739586
step: 350, loss: 0.08536060899496078
step: 360, loss: 0.10824596881866455
step: 370, loss: 0.05583491548895836
step: 380, loss: 0.01161038689315319
step: 390, loss: 0.0840529352426529
step: 400, loss: 0.022858869284391403
step: 410, loss: 0.006674745120108128
step: 420, loss: 0.028240403160452843
step: 430, loss: 0.053770121186971664
step: 440, loss: 0.10829268395900726
step: 450, loss: 0.0005044061690568924
step: 460, loss: 0.21644087135791779
step: 470, loss: 0.03455225005745888
step: 480, loss: 0.01592174731194973
step: 490, loss: 0.10817856341600418
step: 500, loss: 0.07916388660669327
step: 510, loss: 0.06022796034812927
step: 520, loss: 0.03859233111143112
step: 530, loss: 0.09248058497905731
step: 540, loss: 0.04387490078806877
step: 550, loss: 0.022746769711375237
step: 560, loss: 0.05260755121707916
step: 570, loss: 0.02821635827422142
step: 580, loss: 0.030239330604672432
step: 590, loss: 0.0014783669030293822
step: 600, loss: 0.02438778057694435
step: 610, loss: 0.03597928211092949
step: 620, loss: 0.029533497989177704
step: 630, loss: 0.03326797857880592
step: 640, loss: 0.00013900766498409212
step: 650, loss: 0.023077359423041344
step: 660, loss: 0.09751959890127182
step: 670, loss: 0.040873270481824875
step: 680, loss: 0.0659279152750969
step: 690, loss: 0.040775004774332047
step: 700, loss: 0.1151338741183281
step: 710, loss: 0.05584549158811569
step: 720, loss: 0.09179443120956421
step: 730, loss: 0.05204501375555992
step: 740, loss: 0.08045937120914459
step: 750, loss: 0.012437663972377777
step: 760, loss: 0.02187434956431389
step: 770, loss: 0.0005645053461194038
step: 780, loss: 0.019565926864743233
step: 790, loss: 0.05662795528769493
step: 800, loss: 0.0005481763510033488
step: 810, loss: 0.04885444790124893
step: 820, loss: 0.038091886788606644
step: 830, loss: 0.06271028518676758
step: 840, loss: 0.07209933549165726
step: 850, loss: 0.025534823536872864
step: 860, loss: 0.061934906989336014
step: 870, loss: 0.004049435257911682
step: 880, loss: 0.02370407059788704
step: 890, loss: 0.010308538563549519
step: 900, loss: 0.0336134172976017
step: 910, loss: 0.11539068818092346
step: 920, loss: 0.07728707045316696
step: 930, loss: 0.03485468775033951
step: 940, loss: 0.048458486795425415
step: 950, loss: 0.012186847627162933
step: 960, loss: 0.07023512572050095
step: 970, loss: 0.08638421446084976
epoch 20: dev_f1=0.923943661971831, f1=0.9275766016713091, best_f1=0.9321561338289963
