cuda
Device: cuda
step: 0, loss: 0.6889650821685791
step: 10, loss: 0.3323589861392975
step: 20, loss: 0.3683290183544159
step: 30, loss: 0.39800673723220825
step: 40, loss: 0.34116417169570923
step: 50, loss: 0.15655000507831573
step: 60, loss: 0.13976937532424927
step: 70, loss: 0.13892249763011932
step: 80, loss: 0.17599442601203918
step: 90, loss: 0.13718892633914948
step: 100, loss: 0.17685732245445251
step: 110, loss: 0.22453953325748444
step: 120, loss: 0.3088737428188324
step: 130, loss: 0.06210856884717941
step: 140, loss: 0.1985028088092804
step: 150, loss: 0.13887618482112885
step: 160, loss: 0.15572191774845123
step: 170, loss: 0.14947572350502014
step: 180, loss: 0.1353788524866104
step: 190, loss: 0.14521826803684235
step: 200, loss: 0.1184181198477745
step: 210, loss: 0.1214737743139267
step: 220, loss: 0.08770404756069183
step: 230, loss: 0.13816691935062408
step: 240, loss: 0.11530619859695435
step: 250, loss: 0.11266753822565079
step: 260, loss: 0.10464232414960861
step: 270, loss: 0.1055823266506195
step: 280, loss: 0.19489030539989471
step: 290, loss: 0.11586899310350418
step: 300, loss: 0.35297891497612
step: 310, loss: 0.12090737372636795
step: 320, loss: 0.18264828622341156
step: 330, loss: 0.11386854946613312
step: 340, loss: 0.18380139768123627
step: 350, loss: 0.20102788507938385
step: 360, loss: 0.1907481998205185
step: 370, loss: 0.08830934762954712
step: 380, loss: 0.1878293752670288
step: 390, loss: 0.15642940998077393
step: 400, loss: 0.20868080854415894
step: 410, loss: 0.17142540216445923
step: 420, loss: 0.12448246777057648
step: 430, loss: 0.22029082477092743
step: 440, loss: 0.24005618691444397
step: 450, loss: 0.061850398778915405
step: 460, loss: 0.09159751981496811
step: 470, loss: 0.1530739665031433
step: 480, loss: 0.07974643260240555
step: 490, loss: 0.08354222029447556
step: 500, loss: 0.2075420469045639
step: 510, loss: 0.1920415312051773
step: 520, loss: 0.17573082447052002
step: 530, loss: 0.10742244124412537
step: 540, loss: 0.24616198241710663
step: 550, loss: 0.08839936554431915
step: 560, loss: 0.12627477943897247
step: 570, loss: 0.21934689581394196
step: 580, loss: 0.05348718911409378
step: 590, loss: 0.08376000821590424
step: 600, loss: 0.20363400876522064
step: 610, loss: 0.30231204628944397
step: 620, loss: 0.09863407164812088
step: 630, loss: 0.188321053981781
step: 640, loss: 0.18043699860572815
step: 650, loss: 0.23736628890037537
step: 660, loss: 0.22866752743721008
step: 670, loss: 0.23099404573440552
step: 680, loss: 0.06429953873157501
step: 690, loss: 0.08737339824438095
step: 700, loss: 0.18641260266304016
step: 710, loss: 0.30381497740745544
step: 720, loss: 0.20320501923561096
step: 730, loss: 0.15961624681949615
step: 740, loss: 0.1711072325706482
step: 750, loss: 0.23124480247497559
step: 760, loss: 0.22110724449157715
step: 770, loss: 0.1672014743089676
step: 780, loss: 0.10652092844247818
step: 790, loss: 0.1959749311208725
step: 800, loss: 0.2959749400615692
step: 810, loss: 0.07641645520925522
step: 820, loss: 0.1444079875946045
step: 830, loss: 0.2399255931377411
step: 840, loss: 0.12320823967456818
step: 850, loss: 0.21903932094573975
step: 860, loss: 0.19739893078804016
step: 870, loss: 0.21103908121585846
step: 880, loss: 0.26320943236351013
step: 890, loss: 0.15001213550567627
step: 900, loss: 0.11430864781141281
step: 910, loss: 0.19050465524196625
step: 920, loss: 0.11845646053552628
step: 930, loss: 0.1382608860731125
step: 940, loss: 0.05618111416697502
step: 950, loss: 0.13900037109851837
step: 960, loss: 0.14171463251113892
step: 970, loss: 0.18202492594718933
epoch 1: dev_f1=0.9087540528022233, f1=0.9005524861878452, best_f1=0.9005524861878452
step: 0, loss: 0.09527727961540222
step: 10, loss: 0.029564520344138145
step: 20, loss: 0.07589496672153473
step: 30, loss: 0.1067669466137886
step: 40, loss: 0.12484847754240036
step: 50, loss: 0.052599161863327026
step: 60, loss: 0.06747061014175415
step: 70, loss: 0.1403428018093109
step: 80, loss: 0.11694902181625366
step: 90, loss: 0.498544305562973
step: 100, loss: 0.09932804107666016
step: 110, loss: 0.112027108669281
step: 120, loss: 0.3445293605327606
step: 130, loss: 0.10970412939786911
step: 140, loss: 0.11965421587228775
step: 150, loss: 0.025995198637247086
step: 160, loss: 0.1938670128583908
step: 170, loss: 0.12776584923267365
step: 180, loss: 0.07402484118938446
step: 190, loss: 0.16807813942432404
step: 200, loss: 0.1418887972831726
step: 210, loss: 0.24268779158592224
step: 220, loss: 0.10873203724622726
step: 230, loss: 0.14636310935020447
step: 240, loss: 0.2370363473892212
step: 250, loss: 0.10766353458166122
step: 260, loss: 0.06697840988636017
step: 270, loss: 0.11213673651218414
step: 280, loss: 0.12349364906549454
step: 290, loss: 0.15940554440021515
step: 300, loss: 0.039003871381282806
step: 310, loss: 0.054876409471035004
step: 320, loss: 0.21559515595436096
step: 330, loss: 0.12106379866600037
step: 340, loss: 0.29516881704330444
step: 350, loss: 0.10624442249536514
step: 360, loss: 0.12934739887714386
step: 370, loss: 0.12487395107746124
step: 380, loss: 0.14745180308818817
step: 390, loss: 0.09315163642168045
step: 400, loss: 0.07759909331798553
step: 410, loss: 0.16198314726352692
step: 420, loss: 0.1051170751452446
step: 430, loss: 0.2060362845659256
step: 440, loss: 0.13658088445663452
step: 450, loss: 0.11865786463022232
step: 460, loss: 0.14605922996997833
step: 470, loss: 0.048165373504161835
step: 480, loss: 0.13713227212429047
step: 490, loss: 0.05981718376278877
step: 500, loss: 0.030046336352825165
step: 510, loss: 0.1230727955698967
step: 520, loss: 0.17776155471801758
step: 530, loss: 0.133331298828125
step: 540, loss: 0.10321159660816193
step: 550, loss: 0.14594629406929016
step: 560, loss: 0.17945419251918793
step: 570, loss: 0.11921437084674835
step: 580, loss: 0.17331786453723907
step: 590, loss: 0.1867292821407318
step: 600, loss: 0.1005323976278305
step: 610, loss: 0.11616762727499008
step: 620, loss: 0.15138982236385345
step: 630, loss: 0.13497623801231384
step: 640, loss: 0.15603256225585938
step: 650, loss: 0.1447720229625702
step: 660, loss: 0.22946728765964508
step: 670, loss: 0.2516961693763733
step: 680, loss: 0.1553012728691101
step: 690, loss: 0.1555008739233017
step: 700, loss: 0.14953559637069702
step: 710, loss: 0.1975574791431427
step: 720, loss: 0.05177786201238632
step: 730, loss: 0.11091019213199615
step: 740, loss: 0.42266643047332764
step: 750, loss: 0.13041435182094574
step: 760, loss: 0.20064301788806915
step: 770, loss: 0.21296155452728271
step: 780, loss: 0.19301635026931763
step: 790, loss: 0.13940295577049255
step: 800, loss: 0.11106498539447784
step: 810, loss: 0.003920599818229675
step: 820, loss: 0.0766163021326065
step: 830, loss: 0.13044971227645874
step: 840, loss: 0.1339905709028244
step: 850, loss: 0.13398845493793488
step: 860, loss: 0.1672482192516327
step: 870, loss: 0.08845916390419006
step: 880, loss: 0.14791499078273773
step: 890, loss: 0.10620810091495514
step: 900, loss: 0.07885010540485382
step: 910, loss: 0.09534872323274612
step: 920, loss: 0.10329072922468185
step: 930, loss: 0.12701591849327087
step: 940, loss: 0.030487651005387306
step: 950, loss: 0.11824533343315125
step: 960, loss: 0.17271612584590912
step: 970, loss: 0.12362081557512283
epoch 2: dev_f1=0.9166666666666667, f1=0.9180778032036614, best_f1=0.9180778032036614
step: 0, loss: 0.09569595009088516
step: 10, loss: 0.07422186434268951
step: 20, loss: 0.07946718484163284
step: 30, loss: 0.12833771109580994
step: 40, loss: 0.0526554137468338
step: 50, loss: 0.16817788779735565
step: 60, loss: 0.10103040188550949
step: 70, loss: 0.04922068864107132
step: 80, loss: 0.0656711682677269
step: 90, loss: 0.039316412061452866
step: 100, loss: 0.11609428375959396
step: 110, loss: 0.094175785779953
step: 120, loss: 0.1250910758972168
step: 130, loss: 0.11711335927248001
step: 140, loss: 0.11818157881498337
step: 150, loss: 0.2924896776676178
step: 160, loss: 0.19226956367492676
step: 170, loss: 0.13604307174682617
step: 180, loss: 0.13321952521800995
step: 190, loss: 0.02199782058596611
step: 200, loss: 0.11295933276414871
step: 210, loss: 0.08015172928571701
step: 220, loss: 0.13517186045646667
step: 230, loss: 0.12657809257507324
step: 240, loss: 0.045664817094802856
step: 250, loss: 0.20047351717948914
step: 260, loss: 0.11808562278747559
step: 270, loss: 0.17607758939266205
step: 280, loss: 0.07975095510482788
step: 290, loss: 0.15826201438903809
step: 300, loss: 0.11596966534852982
step: 310, loss: 0.0531729981303215
step: 320, loss: 0.03890804946422577
step: 330, loss: 0.035859622061252594
step: 340, loss: 0.05595492944121361
step: 350, loss: 0.11956965178251266
step: 360, loss: 0.09739693254232407
step: 370, loss: 0.08194643259048462
step: 380, loss: 0.07987825572490692
step: 390, loss: 0.114523746073246
step: 400, loss: 0.04404570534825325
step: 410, loss: 0.09687069058418274
step: 420, loss: 0.10313062369823456
step: 430, loss: 0.2066602110862732
step: 440, loss: 0.2533612549304962
step: 450, loss: 0.19934596121311188
step: 460, loss: 0.11038357019424438
step: 470, loss: 0.1079743355512619
step: 480, loss: 0.055714577436447144
step: 490, loss: 0.19484128057956696
step: 500, loss: 0.15291407704353333
step: 510, loss: 0.08779047429561615
step: 520, loss: 0.07819142192602158
step: 530, loss: 0.06692583113908768
step: 540, loss: 0.09893627464771271
step: 550, loss: 0.09717631340026855
step: 560, loss: 0.046678319573402405
step: 570, loss: 0.0862794890999794
step: 580, loss: 0.08986858278512955
step: 590, loss: 0.09805437177419662
step: 600, loss: 0.07600455731153488
step: 610, loss: 0.12689237296581268
step: 620, loss: 0.038447845727205276
step: 630, loss: 0.12315740436315536
step: 640, loss: 0.11158810555934906
step: 650, loss: 0.06394370645284653
step: 660, loss: 0.030521197244524956
step: 670, loss: 0.1618415117263794
step: 680, loss: 0.10788644105195999
step: 690, loss: 0.11051187664270401
step: 700, loss: 0.14082691073417664
step: 710, loss: 0.051826220005750656
step: 720, loss: 0.0592702180147171
step: 730, loss: 0.0731324553489685
step: 740, loss: 0.07990606874227524
step: 750, loss: 0.0948539450764656
step: 760, loss: 0.11399836093187332
step: 770, loss: 0.12132924795150757
step: 780, loss: 0.14753954112529755
step: 790, loss: 0.08308158069849014
step: 800, loss: 0.06455964595079422
step: 810, loss: 0.0831250324845314
step: 820, loss: 0.05933079496026039
step: 830, loss: 0.03355511277914047
step: 840, loss: 0.12843072414398193
step: 850, loss: 0.1124444305896759
step: 860, loss: 0.09696079045534134
step: 870, loss: 0.0956360474228859
step: 880, loss: 0.10186178982257843
step: 890, loss: 0.13266123831272125
step: 900, loss: 0.06847158074378967
step: 910, loss: 0.10625778883695602
step: 920, loss: 0.09068048745393753
step: 930, loss: 0.06836085021495819
step: 940, loss: 0.15685567259788513
step: 950, loss: 0.1439194530248642
step: 960, loss: 0.08121274411678314
step: 970, loss: 0.1943357139825821
epoch 3: dev_f1=0.9195402298850575, f1=0.9168975069252078, best_f1=0.9168975069252078
step: 0, loss: 0.15427511930465698
step: 10, loss: 0.11570920050144196
step: 20, loss: 0.11477750539779663
step: 30, loss: 0.2747802734375
step: 40, loss: 0.03991441801190376
step: 50, loss: 0.06628646701574326
step: 60, loss: 0.05567160248756409
step: 70, loss: 0.20764537155628204
step: 80, loss: 0.02389654330909252
step: 90, loss: 0.10475629568099976
step: 100, loss: 0.10637479275465012
step: 110, loss: 0.06576314568519592
step: 120, loss: 0.0708417147397995
step: 130, loss: 0.11909487843513489
step: 140, loss: 0.02867179363965988
step: 150, loss: 0.05861479043960571
step: 160, loss: 0.02672409825026989
step: 170, loss: 0.10418087989091873
step: 180, loss: 0.05585802346467972
step: 190, loss: 0.10708703845739365
step: 200, loss: 0.09839130938053131
step: 210, loss: 0.19398358464241028
step: 220, loss: 0.10966377705335617
step: 230, loss: 0.19508004188537598
step: 240, loss: 0.0793195366859436
step: 250, loss: 0.11635671555995941
step: 260, loss: 0.103522390127182
step: 270, loss: 0.09105810523033142
step: 280, loss: 0.06384766101837158
step: 290, loss: 0.24519146978855133
step: 300, loss: 0.10851391404867172
step: 310, loss: 0.17019401490688324
step: 320, loss: 0.1270275115966797
step: 330, loss: 0.11258353292942047
step: 340, loss: 0.020900247618556023
step: 350, loss: 0.07904648035764694
step: 360, loss: 0.13536225259304047
step: 370, loss: 0.05305454134941101
step: 380, loss: 0.08575208485126495
step: 390, loss: 0.12061455845832825
step: 400, loss: 0.15351256728172302
step: 410, loss: 0.15518362820148468
step: 420, loss: 0.1532239019870758
step: 430, loss: 0.17672955989837646
step: 440, loss: 0.06021367013454437
step: 450, loss: 0.03327871859073639
step: 460, loss: 0.07083163410425186
step: 470, loss: 0.1542138308286667
step: 480, loss: 0.06615762412548065
step: 490, loss: 0.1160162165760994
step: 500, loss: 0.10858339816331863
step: 510, loss: 0.08870865404605865
step: 520, loss: 0.2684078812599182
step: 530, loss: 0.013820663094520569
step: 540, loss: 0.04009826481342316
step: 550, loss: 0.11180149018764496
step: 560, loss: 0.09188345074653625
step: 570, loss: 0.004744630306959152
step: 580, loss: 0.17144963145256042
step: 590, loss: 0.06806892901659012
step: 600, loss: 0.08522461354732513
step: 610, loss: 0.16687168180942535
step: 620, loss: 0.11774704605340958
step: 630, loss: 0.062452834099531174
step: 640, loss: 0.2478111833333969
step: 650, loss: 0.04591139405965805
step: 660, loss: 0.16205410659313202
step: 670, loss: 0.06755809485912323
step: 680, loss: 0.036162618547677994
step: 690, loss: 0.14465853571891785
step: 700, loss: 0.14663469791412354
step: 710, loss: 0.02425273507833481
step: 720, loss: 0.10470912605524063
step: 730, loss: 0.13053128123283386
step: 740, loss: 0.10979414731264114
step: 750, loss: 0.11470163613557816
step: 760, loss: 0.1593896448612213
step: 770, loss: 0.2418096959590912
step: 780, loss: 0.0902845710515976
step: 790, loss: 0.02568819932639599
step: 800, loss: 0.11575319617986679
step: 810, loss: 0.14935584366321564
step: 820, loss: 0.035590481013059616
step: 830, loss: 0.08485710620880127
step: 840, loss: 0.03601030632853508
step: 850, loss: 0.13237875699996948
step: 860, loss: 0.0741652101278305
step: 870, loss: 0.14504018425941467
step: 880, loss: 0.1530805230140686
step: 890, loss: 0.07472342252731323
step: 900, loss: 0.07487665116786957
step: 910, loss: 0.048072122037410736
step: 920, loss: 0.14714187383651733
step: 930, loss: 0.13711723685264587
step: 940, loss: 0.15912696719169617
step: 950, loss: 0.07142417877912521
step: 960, loss: 0.07185260206460953
step: 970, loss: 0.07460382580757141
epoch 4: dev_f1=0.937962962962963, f1=0.9406350667280258, best_f1=0.9406350667280258
step: 0, loss: 0.06929747015237808
step: 10, loss: 0.15443994104862213
step: 20, loss: 0.060934703797101974
step: 30, loss: 0.10942932218313217
step: 40, loss: 0.04824010282754898
step: 50, loss: 0.10846053063869476
step: 60, loss: 0.017658589407801628
step: 70, loss: 0.1272520273923874
step: 80, loss: 0.09020406752824783
step: 90, loss: 0.20928987860679626
step: 100, loss: 0.14653761684894562
step: 110, loss: 0.08771272003650665
step: 120, loss: 0.015946384519338608
step: 130, loss: 0.06729230284690857
step: 140, loss: 0.20124441385269165
step: 150, loss: 0.08406735956668854
step: 160, loss: 0.31857791543006897
step: 170, loss: 0.08678882569074631
step: 180, loss: 0.11360186338424683
step: 190, loss: 0.09875714033842087
step: 200, loss: 0.030411334708333015
step: 210, loss: 0.01500608678907156
step: 220, loss: 0.08970677852630615
step: 230, loss: 0.1591159850358963
step: 240, loss: 0.07854553312063217
step: 250, loss: 0.09771563112735748
step: 260, loss: 0.11895319819450378
step: 270, loss: 0.20335903763771057
step: 280, loss: 0.02419063076376915
step: 290, loss: 0.10082296282052994
step: 300, loss: 0.13774701952934265
step: 310, loss: 0.14575213193893433
step: 320, loss: 0.037196800112724304
step: 330, loss: 0.05990501493215561
step: 340, loss: 0.10260259360074997
step: 350, loss: 0.040656883269548416
step: 360, loss: 0.07895070314407349
step: 370, loss: 0.05592035502195358
step: 380, loss: 0.07088208943605423
step: 390, loss: 0.11292137950658798
step: 400, loss: 0.04318647459149361
step: 410, loss: 0.33401787281036377
step: 420, loss: 0.030694952234625816
step: 430, loss: 0.0945647582411766
step: 440, loss: 0.10363025963306427
step: 450, loss: 0.055889226496219635
step: 460, loss: 0.09553277492523193
step: 470, loss: 0.16562972962856293
step: 480, loss: 0.07790526002645493
step: 490, loss: 0.06915412098169327
step: 500, loss: 0.16596440970897675
step: 510, loss: 0.20092029869556427
step: 520, loss: 0.25947558879852295
step: 530, loss: 0.17357321083545685
step: 540, loss: 0.07498040795326233
step: 550, loss: 0.03992736339569092
step: 560, loss: 0.03684860095381737
step: 570, loss: 0.1469128578901291
step: 580, loss: 0.12598636746406555
step: 590, loss: 0.15082648396492004
step: 600, loss: 0.10122884809970856
step: 610, loss: 0.14827179908752441
step: 620, loss: 0.13261300325393677
step: 630, loss: 0.1042686253786087
step: 640, loss: 0.05967170000076294
step: 650, loss: 0.12494084239006042
step: 660, loss: 0.21186596155166626
step: 670, loss: 0.04125607758760452
step: 680, loss: 0.15527468919754028
step: 690, loss: 0.07794038206338882
step: 700, loss: 0.021409589797258377
step: 710, loss: 0.01305032055824995
step: 720, loss: 0.10336436331272125
step: 730, loss: 0.15916700661182404
step: 740, loss: 0.046107251197099686
step: 750, loss: 0.13969208300113678
step: 760, loss: 0.08710155636072159
step: 770, loss: 0.0796111449599266
step: 780, loss: 0.21241691708564758
step: 790, loss: 0.10727407038211823
step: 800, loss: 0.059483565390110016
step: 810, loss: 0.11422870308160782
step: 820, loss: 0.035957466810941696
step: 830, loss: 0.06499297171831131
step: 840, loss: 0.12083867937326431
step: 850, loss: 0.12969958782196045
step: 860, loss: 0.17996162176132202
step: 870, loss: 0.10550987720489502
step: 880, loss: 0.14453984797000885
step: 890, loss: 0.03283252194523811
step: 900, loss: 0.09285546839237213
step: 910, loss: 0.023201601579785347
step: 920, loss: 0.09951771050691605
step: 930, loss: 0.07886538654565811
step: 940, loss: 0.14810216426849365
step: 950, loss: 0.10642849653959274
step: 960, loss: 0.17353755235671997
step: 970, loss: 0.12823696434497833
epoch 5: dev_f1=0.9281716417910447, f1=0.9287377736376339, best_f1=0.9406350667280258
step: 0, loss: 0.05587716028094292
step: 10, loss: 0.08542368561029434
step: 20, loss: 0.0372864231467247
step: 30, loss: 0.09801989793777466
step: 40, loss: 0.11290471255779266
step: 50, loss: 0.032427240163087845
step: 60, loss: 0.034621354192495346
step: 70, loss: 0.23977941274642944
step: 80, loss: 0.05496726185083389
step: 90, loss: 0.16871757805347443
step: 100, loss: 0.14425694942474365
step: 110, loss: 0.07042515277862549
step: 120, loss: 0.0856899693608284
step: 130, loss: 0.0648888647556305
step: 140, loss: 0.09583015739917755
step: 150, loss: 0.09487742930650711
step: 160, loss: 0.13481007516384125
step: 170, loss: 0.21129538118839264
step: 180, loss: 0.07266637682914734
step: 190, loss: 0.016020428389310837
step: 200, loss: 0.10129797458648682
step: 210, loss: 0.08157049864530563
step: 220, loss: 0.1992367058992386
step: 230, loss: 0.0950433611869812
step: 240, loss: 0.14032912254333496
step: 250, loss: 0.0903564840555191
step: 260, loss: 0.16447538137435913
step: 270, loss: 0.052747681736946106
step: 280, loss: 0.06349720805883408
step: 290, loss: 0.24645531177520752
step: 300, loss: 0.03640308976173401
step: 310, loss: 0.22017067670822144
step: 320, loss: 0.04953139275312424
step: 330, loss: 0.09148463606834412
step: 340, loss: 0.14406323432922363
step: 350, loss: 0.06387966871261597
step: 360, loss: 0.05133500322699547
step: 370, loss: 0.18546319007873535
step: 380, loss: 0.11731131374835968
step: 390, loss: 0.19226443767547607
step: 400, loss: 0.037008512765169144
step: 410, loss: 0.30527037382125854
step: 420, loss: 0.12089250981807709
step: 430, loss: 0.014756742864847183
step: 440, loss: 0.09250892698764801
step: 450, loss: 0.014224863611161709
step: 460, loss: 0.03957882896065712
step: 470, loss: 0.03050948679447174
step: 480, loss: 0.10496465861797333
step: 490, loss: 0.030228400602936745
step: 500, loss: 0.0632968619465828
step: 510, loss: 0.024021698161959648
step: 520, loss: 0.03898425027728081
step: 530, loss: 0.11707799136638641
step: 540, loss: 0.11547839641571045
step: 550, loss: 0.078256756067276
step: 560, loss: 0.07552868127822876
step: 570, loss: 0.16532808542251587
step: 580, loss: 0.20721817016601562
step: 590, loss: 0.04927591234445572
step: 600, loss: 0.10597243905067444
step: 610, loss: 0.19521835446357727
step: 620, loss: 0.16555750370025635
step: 630, loss: 0.06695796549320221
step: 640, loss: 0.10379239171743393
step: 650, loss: 0.08770346641540527
step: 660, loss: 0.19675220549106598
step: 670, loss: 0.05950614809989929
step: 680, loss: 0.11604197323322296
step: 690, loss: 0.017224086448550224
step: 700, loss: 0.059556666761636734
step: 710, loss: 0.06951086223125458
step: 720, loss: 0.048771899193525314
step: 730, loss: 0.06187637522816658
step: 740, loss: 0.07426346093416214
step: 750, loss: 0.09150652587413788
step: 760, loss: 0.15805266797542572
step: 770, loss: 0.057150423526763916
step: 780, loss: 0.006019033025950193
step: 790, loss: 0.08366592228412628
step: 800, loss: 0.14450481534004211
step: 810, loss: 0.07993202656507492
step: 820, loss: 0.2406892478466034
step: 830, loss: 0.03370578587055206
step: 840, loss: 0.08173613250255585
step: 850, loss: 0.12748977541923523
step: 860, loss: 0.29736101627349854
step: 870, loss: 0.2873840928077698
step: 880, loss: 0.10168472677469254
step: 890, loss: 0.1599923074245453
step: 900, loss: 0.05847124755382538
step: 910, loss: 0.11888281255960464
step: 920, loss: 0.14310322701931
step: 930, loss: 0.10519565641880035
step: 940, loss: 0.08033836632966995
step: 950, loss: 0.12253915518522263
step: 960, loss: 0.0671391487121582
step: 970, loss: 0.016084173694252968
epoch 6: dev_f1=0.9327188940092166, f1=0.9313815187557181, best_f1=0.9406350667280258
step: 0, loss: 0.021942907944321632
step: 10, loss: 0.1567036658525467
step: 20, loss: 0.029232267290353775
step: 30, loss: 0.10249201208353043
step: 40, loss: 0.0905989482998848
step: 50, loss: 0.02755993790924549
step: 60, loss: 0.19225475192070007
step: 70, loss: 0.09374772757291794
step: 80, loss: 0.04902636259794235
step: 90, loss: 0.1289413869380951
step: 100, loss: 0.13171425461769104
step: 110, loss: 0.12027101963758469
step: 120, loss: 0.17568261921405792
step: 130, loss: 0.10556530207395554
step: 140, loss: 0.08050747215747833
step: 150, loss: 0.1591413915157318
step: 160, loss: 0.08778182417154312
step: 170, loss: 0.11554025858640671
step: 180, loss: 0.08310824632644653
step: 190, loss: 0.1795271784067154
step: 200, loss: 0.0647372305393219
step: 210, loss: 0.00018520356388762593
step: 220, loss: 0.058207836002111435
step: 230, loss: 0.10704527795314789
step: 240, loss: 0.05650825798511505
step: 250, loss: 0.03706255555152893
step: 260, loss: 0.04297211393713951
step: 270, loss: 0.08173762261867523
step: 280, loss: 0.12653619050979614
step: 290, loss: 0.1053418442606926
step: 300, loss: 0.09016925096511841
step: 310, loss: 0.031482961028814316
step: 320, loss: 0.16145551204681396
step: 330, loss: 0.08680767565965652
step: 340, loss: 0.13157320022583008
step: 350, loss: 0.04163695499300957
step: 360, loss: 0.063329316675663
step: 370, loss: 0.1811208873987198
step: 380, loss: 0.1376008242368698
step: 390, loss: 0.12470901012420654
step: 400, loss: 0.14380677044391632
step: 410, loss: 0.11931619793176651
step: 420, loss: 0.04129994288086891
step: 430, loss: 0.04084346070885658
step: 440, loss: 0.09945553541183472
step: 450, loss: 0.12961441278457642
step: 460, loss: 0.03744080662727356
step: 470, loss: 0.11516055464744568
step: 480, loss: 0.047226887196302414
step: 490, loss: 0.11499173194169998
step: 500, loss: 0.3591417670249939
step: 510, loss: 0.07805447280406952
step: 520, loss: 0.07024993747472763
step: 530, loss: 0.12352591753005981
step: 540, loss: 0.10413721948862076
step: 550, loss: 0.1305321604013443
step: 560, loss: 0.13491037487983704
step: 570, loss: 0.19557394087314606
step: 580, loss: 0.11792543530464172
step: 590, loss: 0.07839153707027435
step: 600, loss: 0.1017351746559143
step: 610, loss: 0.023055266588926315
step: 620, loss: 0.05704537406563759
step: 630, loss: 0.0589580163359642
step: 640, loss: 0.09004724025726318
step: 650, loss: 0.05903216078877449
step: 660, loss: 0.08453046530485153
step: 670, loss: 0.06873580813407898
step: 680, loss: 0.12424425780773163
step: 690, loss: 0.17979192733764648
step: 700, loss: 0.1029358059167862
step: 710, loss: 0.06073963642120361
step: 720, loss: 0.08139801770448685
step: 730, loss: 0.1174437552690506
step: 740, loss: 0.02731824479997158
step: 750, loss: 0.09800700098276138
step: 760, loss: 0.14957430958747864
step: 770, loss: 0.036520399153232574
step: 780, loss: 0.037565864622592926
step: 790, loss: 0.07021016627550125
step: 800, loss: 0.14975769817829132
step: 810, loss: 0.0460713654756546
step: 820, loss: 0.08293767273426056
step: 830, loss: 0.10541294515132904
step: 840, loss: 0.14313432574272156
step: 850, loss: 0.1963956356048584
step: 860, loss: 0.06292334198951721
step: 870, loss: 0.06195760890841484
step: 880, loss: 0.058292705565690994
step: 890, loss: 0.11933735013008118
step: 900, loss: 0.0781722441315651
step: 910, loss: 0.0753665566444397
step: 920, loss: 0.2303510159254074
step: 930, loss: 0.18902505934238434
step: 940, loss: 0.0712558776140213
step: 950, loss: 0.016639363020658493
step: 960, loss: 0.07210215926170349
step: 970, loss: 0.23634082078933716
epoch 7: dev_f1=0.936030103480715, f1=0.9223573433115062, best_f1=0.9406350667280258
step: 0, loss: 0.09273993968963623
step: 10, loss: 0.09572473168373108
step: 20, loss: 0.04183143749833107
step: 30, loss: 0.061581939458847046
step: 40, loss: 0.038136910647153854
step: 50, loss: 0.08649802953004837
step: 60, loss: 0.013819651678204536
step: 70, loss: 0.1351076364517212
step: 80, loss: 0.050333332270383835
step: 90, loss: 0.020638786256313324
step: 100, loss: 0.06699873507022858
step: 110, loss: 0.0565166100859642
step: 120, loss: 0.14896529912948608
step: 130, loss: 0.06520651280879974
step: 140, loss: 0.11668562889099121
step: 150, loss: 0.033743392676115036
step: 160, loss: 0.044807080179452896
step: 170, loss: 0.05878513678908348
step: 180, loss: 0.03448077291250229
step: 190, loss: 0.12959592044353485
step: 200, loss: 0.07900793105363846
step: 210, loss: 0.05892590060830116
step: 220, loss: 0.032319460064172745
step: 230, loss: 0.08623532950878143
step: 240, loss: 0.03923507407307625
step: 250, loss: 0.06860970705747604
step: 260, loss: 0.09813669323921204
step: 270, loss: 0.105094313621521
step: 280, loss: 0.04660454019904137
step: 290, loss: 0.04784110188484192
step: 300, loss: 0.15872029960155487
step: 310, loss: 0.0345592126250267
step: 320, loss: 0.17052972316741943
step: 330, loss: 0.1827053725719452
step: 340, loss: 0.03682851418852806
step: 350, loss: 0.10907478630542755
step: 360, loss: 0.0855642631649971
step: 370, loss: 0.08954580873250961
step: 380, loss: 0.08743081986904144
step: 390, loss: 0.04892951622605324
step: 400, loss: 0.015572542324662209
step: 410, loss: 0.055358488112688065
step: 420, loss: 0.13309499621391296
step: 430, loss: 0.0793074443936348
step: 440, loss: 0.03543134406208992
step: 450, loss: 0.10034666210412979
step: 460, loss: 0.22679847478866577
step: 470, loss: 0.05839824303984642
step: 480, loss: 0.061933841556310654
step: 490, loss: 0.06891382485628128
step: 500, loss: 0.10479667782783508
step: 510, loss: 0.14640198647975922
step: 520, loss: 0.021054279059171677
step: 530, loss: 0.10231913626194
step: 540, loss: 0.04760393127799034
step: 550, loss: 0.03593602776527405
step: 560, loss: 0.10180960595607758
step: 570, loss: 0.04286067932844162
step: 580, loss: 0.0508941113948822
step: 590, loss: 0.035248126834630966
step: 600, loss: 0.027033524587750435
step: 610, loss: 0.07525456696748734
step: 620, loss: 0.14548447728157043
step: 630, loss: 0.12370532006025314
step: 640, loss: 0.07389291375875473
step: 650, loss: 0.02376610040664673
step: 660, loss: 0.07852382212877274
step: 670, loss: 0.06656159460544586
step: 680, loss: 0.0626642256975174
step: 690, loss: 0.05615076795220375
step: 700, loss: 0.17167602479457855
step: 710, loss: 0.05307949706912041
step: 720, loss: 0.02201615273952484
step: 730, loss: 0.09146083891391754
step: 740, loss: 0.087553471326828
step: 750, loss: 0.17022332549095154
step: 760, loss: 0.058923669159412384
step: 770, loss: 0.059135448187589645
step: 780, loss: 0.07792631536722183
step: 790, loss: 0.03170979022979736
step: 800, loss: 0.08415527641773224
step: 810, loss: 0.06211923807859421
step: 820, loss: 0.025942906737327576
step: 830, loss: 0.007029854692518711
step: 840, loss: 0.11451884359121323
step: 850, loss: 0.2808455526828766
step: 860, loss: 0.02809547819197178
step: 870, loss: 0.025773655623197556
step: 880, loss: 0.12938249111175537
step: 890, loss: 0.010068980045616627
step: 900, loss: 0.1197076067328453
step: 910, loss: 0.06148383393883705
step: 920, loss: 0.013745661824941635
step: 930, loss: 0.1223030686378479
step: 940, loss: 0.12457745522260666
step: 950, loss: 0.10118564963340759
step: 960, loss: 0.2427242547273636
step: 970, loss: 0.17274975776672363
epoch 8: dev_f1=0.9323943661971831, f1=0.9269662921348314, best_f1=0.9406350667280258
step: 0, loss: 0.034212712198495865
step: 10, loss: 0.1024395301938057
step: 20, loss: 0.0528966560959816
step: 30, loss: 0.051280178129673004
step: 40, loss: 0.11566968262195587
step: 50, loss: 0.09602459520101547
step: 60, loss: 0.12035614997148514
step: 70, loss: 0.0634603425860405
step: 80, loss: 0.014089913107454777
step: 90, loss: 0.04733268916606903
step: 100, loss: 0.04356490075588226
step: 110, loss: 0.048233263194561005
step: 120, loss: 0.07128816843032837
step: 130, loss: 0.09110505878925323
step: 140, loss: 0.014833991415798664
step: 150, loss: 0.0817323550581932
step: 160, loss: 0.03410264477133751
step: 170, loss: 0.13936053216457367
step: 180, loss: 0.0796133354306221
step: 190, loss: 0.08963528275489807
step: 200, loss: 0.19111454486846924
step: 210, loss: 0.07760894298553467
step: 220, loss: 0.025494910776615143
step: 230, loss: 0.147699773311615
step: 240, loss: 0.09453324973583221
step: 250, loss: 0.03896474838256836
step: 260, loss: 0.1285257190465927
step: 270, loss: 0.1124458834528923
step: 280, loss: 0.1324017345905304
step: 290, loss: 0.03156904876232147
step: 300, loss: 0.09072845429182053
step: 310, loss: 0.1823025792837143
step: 320, loss: 0.11949845403432846
step: 330, loss: 0.014335251413285732
step: 340, loss: 0.049356859177351
step: 350, loss: 0.1350141167640686
step: 360, loss: 0.23953452706336975
step: 370, loss: 0.11505645513534546
step: 380, loss: 0.004357142373919487
step: 390, loss: 0.10546639561653137
step: 400, loss: 0.05068621411919594
step: 410, loss: 0.06078566610813141
step: 420, loss: 0.05529320240020752
step: 430, loss: 0.11794949322938919
step: 440, loss: 0.06064419075846672
step: 450, loss: 0.09105350822210312
step: 460, loss: 0.09081700444221497
step: 470, loss: 0.11703495681285858
step: 480, loss: 0.07955377548933029
step: 490, loss: 0.025487124919891357
step: 500, loss: 0.08056975901126862
step: 510, loss: 0.07169248908758163
step: 520, loss: 0.13081233203411102
step: 530, loss: 0.06307584047317505
step: 540, loss: 0.09289249032735825
step: 550, loss: 0.0855991318821907
step: 560, loss: 0.11431688070297241
step: 570, loss: 0.06501835584640503
step: 580, loss: 0.08283872157335281
step: 590, loss: 0.1328134387731552
step: 600, loss: 0.059485193341970444
step: 610, loss: 0.04289894551038742
step: 620, loss: 0.02670893631875515
step: 630, loss: 0.17218855023384094
step: 640, loss: 0.02352936752140522
step: 650, loss: 0.0931301936507225
step: 660, loss: 0.10126879066228867
step: 670, loss: 0.09241726994514465
step: 680, loss: 0.14838755130767822
step: 690, loss: 0.20945145189762115
step: 700, loss: 0.04353849217295647
step: 710, loss: 0.14158134162425995
step: 720, loss: 0.18445102870464325
step: 730, loss: 0.12398207187652588
step: 740, loss: 0.07389377802610397
step: 750, loss: 0.02554948627948761
step: 760, loss: 0.25170496106147766
step: 770, loss: 0.04018990322947502
step: 780, loss: 0.1165933832526207
step: 790, loss: 0.027144916355609894
step: 800, loss: 0.14328701794147491
step: 810, loss: 0.07819075882434845
step: 820, loss: 0.0730757787823677
step: 830, loss: 0.10771163552999496
step: 840, loss: 0.19468896090984344
step: 850, loss: 0.05318491533398628
step: 860, loss: 0.0688379630446434
step: 870, loss: 0.1108502522110939
step: 880, loss: 0.10048563033342361
step: 890, loss: 0.0654798224568367
step: 900, loss: 0.09847188740968704
step: 910, loss: 0.12902028858661652
step: 920, loss: 0.0698397234082222
step: 930, loss: 0.048381708562374115
step: 940, loss: 0.035698335617780685
step: 950, loss: 0.07880417257547379
step: 960, loss: 0.12405774742364883
step: 970, loss: 0.18800854682922363
epoch 9: dev_f1=0.9355870260392875, f1=0.9308291342189647, best_f1=0.9406350667280258
step: 0, loss: 0.1361994594335556
step: 10, loss: 0.03406091779470444
step: 20, loss: 0.04249433055520058
step: 30, loss: 0.05744992569088936
step: 40, loss: 0.0879138931632042
step: 50, loss: 0.02791718579828739
step: 60, loss: 0.04096735268831253
step: 70, loss: 0.006860443390905857
step: 80, loss: 0.14573624730110168
step: 90, loss: 0.04901735857129097
step: 100, loss: 0.031224116683006287
step: 110, loss: 0.12790414690971375
step: 120, loss: 0.03919559717178345
step: 130, loss: 0.11112862825393677
step: 140, loss: 0.02470479905605316
step: 150, loss: 0.2510923147201538
step: 160, loss: 0.0861319974064827
step: 170, loss: 0.07932683825492859
step: 180, loss: 0.06277558952569962
step: 190, loss: 0.02785586379468441
step: 200, loss: 0.0099467309191823
step: 210, loss: 0.07417329400777817
step: 220, loss: 0.045015133917331696
step: 230, loss: 0.061633702367544174
step: 240, loss: 0.03409314155578613
step: 250, loss: 0.08847976475954056
step: 260, loss: 0.08109492063522339
step: 270, loss: 0.07107265293598175
step: 280, loss: 0.13696250319480896
step: 290, loss: 0.0935550257563591
step: 300, loss: 0.08072885125875473
step: 310, loss: 0.1507338136434555
step: 320, loss: 0.13043442368507385
step: 330, loss: 0.05837399512529373
step: 340, loss: 0.0681757926940918
step: 350, loss: 0.046788137406110764
step: 360, loss: 0.056833721697330475
step: 370, loss: 0.0410834476351738
step: 380, loss: 0.052399370819330215
step: 390, loss: 0.06682489812374115
step: 400, loss: 0.02963506057858467
step: 410, loss: 0.07731740176677704
step: 420, loss: 0.049166012555360794
step: 430, loss: 0.022407349199056625
step: 440, loss: 0.12702405452728271
step: 450, loss: 0.09914476424455643
step: 460, loss: 0.027048898860812187
step: 470, loss: 0.18278712034225464
step: 480, loss: 0.14148658514022827
step: 490, loss: 0.09679756313562393
step: 500, loss: 0.06520964950323105
step: 510, loss: 0.16063760221004486
step: 520, loss: 0.09994885325431824
step: 530, loss: 0.10090901702642441
step: 540, loss: 0.09332886338233948
step: 550, loss: 0.060264457017183304
step: 560, loss: 0.0745372548699379
step: 570, loss: 0.0953834131360054
step: 580, loss: 0.023353051394224167
step: 590, loss: 0.07699155062437057
step: 600, loss: 0.027163993567228317
step: 610, loss: 0.015257187187671661
step: 620, loss: 0.0774960145354271
step: 630, loss: 0.012896713800728321
step: 640, loss: 0.16849474608898163
step: 650, loss: 0.03647762909531593
step: 660, loss: 0.05966613441705704
step: 670, loss: 0.1602562665939331
step: 680, loss: 0.13929161429405212
step: 690, loss: 0.026741310954093933
step: 700, loss: 0.12215691804885864
step: 710, loss: 0.1630026251077652
step: 720, loss: 0.06471038609743118
step: 730, loss: 0.25405633449554443
step: 740, loss: 0.11041846126317978
step: 750, loss: 0.16102705895900726
step: 760, loss: 0.12498695403337479
step: 770, loss: 0.07951025664806366
step: 780, loss: 0.14935144782066345
step: 790, loss: 0.11653776466846466
step: 800, loss: 0.054673753678798676
step: 810, loss: 0.15195472538471222
step: 820, loss: 0.1888551563024521
step: 830, loss: 0.06825007498264313
step: 840, loss: 0.02885078825056553
step: 850, loss: 0.14454659819602966
step: 860, loss: 0.05698307603597641
step: 870, loss: 0.054051220417022705
step: 880, loss: 0.030286569148302078
step: 890, loss: 0.01990068145096302
step: 900, loss: 0.08845146000385284
step: 910, loss: 0.2485097497701645
step: 920, loss: 0.026898575946688652
step: 930, loss: 0.0705028846859932
step: 940, loss: 0.2243562936782837
step: 950, loss: 0.08799923956394196
step: 960, loss: 0.05316012352705002
step: 970, loss: 0.04780608415603638
epoch 10: dev_f1=0.9330855018587362, f1=0.9301895515487749, best_f1=0.9406350667280258
step: 0, loss: 0.055060625076293945
step: 10, loss: 0.07636180520057678
step: 20, loss: 0.17079952359199524
step: 30, loss: 0.01936239004135132
step: 40, loss: 0.08602266013622284
step: 50, loss: 0.018268447369337082
step: 60, loss: 0.07334796339273453
step: 70, loss: 0.03232510760426521
step: 80, loss: 0.10519544780254364
step: 90, loss: 0.05306334048509598
step: 100, loss: 0.1060357615351677
step: 110, loss: 0.09377309679985046
step: 120, loss: 0.04865002632141113
step: 130, loss: 0.02242739498615265
step: 140, loss: 0.10617353022098541
step: 150, loss: 0.06976348906755447
step: 160, loss: 8.414124749833718e-05
step: 170, loss: 0.11283344775438309
step: 180, loss: 0.07450389862060547
step: 190, loss: 0.0477067306637764
step: 200, loss: 0.2291770577430725
step: 210, loss: 0.1678352802991867
step: 220, loss: 0.0841262936592102
step: 230, loss: 0.05122196674346924
step: 240, loss: 0.08414171636104584
step: 250, loss: 0.06133082136511803
step: 260, loss: 0.05132342502474785
step: 270, loss: 0.13451769948005676
step: 280, loss: 0.051062460988759995
step: 290, loss: 0.048465896397829056
step: 300, loss: 0.1400747299194336
step: 310, loss: 0.05581067129969597
step: 320, loss: 0.10521107912063599
step: 330, loss: 0.06603802740573883
step: 340, loss: 0.0536639466881752
step: 350, loss: 0.06879590451717377
step: 360, loss: 0.015196966007351875
step: 370, loss: 0.07335477322340012
step: 380, loss: 0.030756421387195587
step: 390, loss: 0.019984737038612366
step: 400, loss: 0.15766549110412598
step: 410, loss: 0.04979637265205383
step: 420, loss: 0.1997530460357666
step: 430, loss: 0.0519087016582489
step: 440, loss: 0.048521988093853
step: 450, loss: 0.04886080324649811
step: 460, loss: 0.01986466720700264
step: 470, loss: 0.1958240121603012
step: 480, loss: 0.12366266548633575
step: 490, loss: 0.11870478093624115
step: 500, loss: 0.042845673859119415
step: 510, loss: 0.06352216005325317
step: 520, loss: 0.21642941236495972
step: 530, loss: 0.10287812352180481
step: 540, loss: 0.056069254875183105
step: 550, loss: 0.03578895702958107
step: 560, loss: 0.03924101963639259
step: 570, loss: 0.0514926053583622
step: 580, loss: 0.04004834219813347
step: 590, loss: 0.3052290081977844
step: 600, loss: 0.03139536455273628
step: 610, loss: 0.04066496342420578
step: 620, loss: 0.07645978033542633
step: 630, loss: 0.0819888785481453
step: 640, loss: 0.08703477680683136
step: 650, loss: 0.09696163237094879
step: 660, loss: 0.14887717366218567
step: 670, loss: 0.04514424502849579
step: 680, loss: 0.0630735382437706
step: 690, loss: 0.06838399171829224
step: 700, loss: 0.08610754460096359
step: 710, loss: 0.0385664701461792
step: 720, loss: 0.07905018329620361
step: 730, loss: 0.10134264081716537
step: 740, loss: 0.006483606994152069
step: 750, loss: 0.008791609667241573
step: 760, loss: 0.036513008177280426
step: 770, loss: 0.11767684668302536
step: 780, loss: 0.044599730521440506
step: 790, loss: 0.005920829251408577
step: 800, loss: 0.07626465708017349
step: 810, loss: 0.048101965337991714
step: 820, loss: 0.04941236972808838
step: 830, loss: 0.028262928128242493
step: 840, loss: 0.07751789689064026
step: 850, loss: 0.08482135087251663
step: 860, loss: 0.11865871399641037
step: 870, loss: 0.08831166476011276
step: 880, loss: 0.1090758666396141
step: 890, loss: 0.10316450893878937
step: 900, loss: 0.059034790843725204
step: 910, loss: 0.03705764561891556
step: 920, loss: 0.07328677177429199
step: 930, loss: 0.06451485306024551
step: 940, loss: 0.25276893377304077
step: 950, loss: 0.02183729223906994
step: 960, loss: 0.0907936841249466
step: 970, loss: 0.15580181777477264
epoch 11: dev_f1=0.9330855018587362, f1=0.9338235294117647, best_f1=0.9406350667280258
step: 0, loss: 0.13493657112121582
step: 10, loss: 0.07528131455183029
step: 20, loss: 0.04634641855955124
step: 30, loss: 0.09262213110923767
step: 40, loss: 0.024992555379867554
step: 50, loss: 0.06983055174350739
step: 60, loss: 0.04460616409778595
step: 70, loss: 0.21106624603271484
step: 80, loss: 0.01931237243115902
step: 90, loss: 0.1253058910369873
step: 100, loss: 0.0903414711356163
step: 110, loss: 0.1011284738779068
step: 120, loss: 0.02136610448360443
step: 130, loss: 0.057126954197883606
step: 140, loss: 0.11102525144815445
step: 150, loss: 0.13930237293243408
step: 160, loss: 0.042120784521102905
step: 170, loss: 0.004715106450021267
step: 180, loss: 0.08698394894599915
step: 190, loss: 0.053011681884527206
step: 200, loss: 0.01992599107325077
step: 210, loss: 0.15318046510219574
step: 220, loss: 0.05558628588914871
step: 230, loss: 0.021427493542432785
step: 240, loss: 0.08475533127784729
step: 250, loss: 0.22956624627113342
step: 260, loss: 0.06508880108594894
step: 270, loss: 0.047218963503837585
step: 280, loss: 0.030692320317029953
step: 290, loss: 0.0851406380534172
step: 300, loss: 0.028568482026457787
step: 310, loss: 0.13179737329483032
step: 320, loss: 0.022162171080708504
step: 330, loss: 0.06955570727586746
step: 340, loss: 0.05255395174026489
step: 350, loss: 0.04482385143637657
step: 360, loss: 0.07213552296161652
step: 370, loss: 0.08433641493320465
step: 380, loss: 0.031168600544333458
step: 390, loss: 0.0317889079451561
step: 400, loss: 0.14406171441078186
step: 410, loss: 0.1044374629855156
step: 420, loss: 0.049091413617134094
step: 430, loss: 0.09116702526807785
step: 440, loss: 0.03660183027386665
step: 450, loss: 0.053337495774030685
step: 460, loss: 0.09079698473215103
step: 470, loss: 0.029333874583244324
step: 480, loss: 0.0008636791608296335
step: 490, loss: 0.0555107481777668
step: 500, loss: 0.0211563128978014
step: 510, loss: 0.19096721708774567
step: 520, loss: 0.04141419753432274
step: 530, loss: 0.11801020056009293
step: 540, loss: 0.05825402960181236
step: 550, loss: 0.0762856975197792
step: 560, loss: 0.07721542567014694
step: 570, loss: 0.0860997661948204
step: 580, loss: 0.09024834632873535
step: 590, loss: 0.08210758864879608
step: 600, loss: 0.028854841366410255
step: 610, loss: 0.015044927597045898
step: 620, loss: 0.04688223451375961
step: 630, loss: 0.07111212611198425
step: 640, loss: 0.07885094732046127
step: 650, loss: 0.07946155965328217
step: 660, loss: 0.06200643256306648
step: 670, loss: 0.08398786187171936
step: 680, loss: 0.050018999725580215
step: 690, loss: 0.04977201297879219
step: 700, loss: 0.0965224951505661
step: 710, loss: 0.06171685829758644
step: 720, loss: 0.08148851245641708
step: 730, loss: 0.08319772779941559
step: 740, loss: 0.036589402705430984
step: 750, loss: 0.03477312996983528
step: 760, loss: 0.08392506837844849
step: 770, loss: 0.04679087549448013
step: 780, loss: 0.0475129671394825
step: 790, loss: 0.041211310774087906
step: 800, loss: 0.048183538019657135
step: 810, loss: 0.013620753772556782
step: 820, loss: 0.08573396503925323
step: 830, loss: 0.1296561360359192
step: 840, loss: 0.009332690387964249
step: 850, loss: 0.030298415571451187
step: 860, loss: 0.08827778697013855
step: 870, loss: 0.02042030543088913
step: 880, loss: 0.06954406946897507
step: 890, loss: 0.02968604862689972
step: 900, loss: 0.1376948058605194
step: 910, loss: 0.24291405081748962
step: 920, loss: 0.10379334539175034
step: 930, loss: 0.061447180807590485
step: 940, loss: 0.14791835844516754
step: 950, loss: 0.05911143496632576
step: 960, loss: 0.06548461318016052
step: 970, loss: 0.09935082495212555
epoch 12: dev_f1=0.9322033898305084, f1=0.9293023255813954, best_f1=0.9406350667280258
step: 0, loss: 0.057302944362163544
step: 10, loss: 0.02361351251602173
step: 20, loss: 0.08351831138134003
step: 30, loss: 0.04830005019903183
step: 40, loss: 0.03356387838721275
step: 50, loss: 0.048872288316488266
step: 60, loss: 0.13789962232112885
step: 70, loss: 0.08666925877332687
step: 80, loss: 0.023700358346104622
step: 90, loss: 0.08056563138961792
step: 100, loss: 0.04575580731034279
step: 110, loss: 0.0629425123333931
step: 120, loss: 0.05659949779510498
step: 130, loss: 0.02120230533182621
step: 140, loss: 0.08043123036623001
step: 150, loss: 0.08497325330972672
step: 160, loss: 0.03592230752110481
step: 170, loss: 0.06343118846416473
step: 180, loss: 0.15157990157604218
step: 190, loss: 0.11777037382125854
step: 200, loss: 0.03020710125565529
step: 210, loss: 0.008878168649971485
step: 220, loss: 0.00972733087837696
step: 230, loss: 0.039416443556547165
step: 240, loss: 0.06664160639047623
step: 250, loss: 0.046324722468853
step: 260, loss: 0.04952364042401314
step: 270, loss: 0.05280840024352074
step: 280, loss: 0.030458927154541016
step: 290, loss: 0.08067409694194794
step: 300, loss: 0.04738367348909378
step: 310, loss: 0.017264042049646378
step: 320, loss: 0.10282907634973526
step: 330, loss: 0.16002927720546722
step: 340, loss: 0.11005161702632904
step: 350, loss: 0.03349088877439499
step: 360, loss: 0.009996771812438965
step: 370, loss: 0.011831948533654213
step: 380, loss: 0.10945694148540497
step: 390, loss: 0.0839357003569603
step: 400, loss: 0.07820092141628265
step: 410, loss: 0.10885995626449585
step: 420, loss: 0.04989038407802582
step: 430, loss: 0.11130905896425247
step: 440, loss: 0.0911605954170227
step: 450, loss: 0.04644685238599777
step: 460, loss: 0.098170205950737
step: 470, loss: 0.060029465705156326
step: 480, loss: 0.066946841776371
step: 490, loss: 0.051174793392419815
step: 500, loss: 0.07970297336578369
step: 510, loss: 0.07905061542987823
step: 520, loss: 0.06262416392564774
step: 530, loss: 0.03372461348772049
step: 540, loss: 0.10718203336000443
step: 550, loss: 0.08553130179643631
step: 560, loss: 0.053275272250175476
step: 570, loss: 0.027992481365799904
step: 580, loss: 0.07711485028266907
step: 590, loss: 0.15203344821929932
step: 600, loss: 0.019862927496433258
step: 610, loss: 0.11902773380279541
step: 620, loss: 0.05475896596908569
step: 630, loss: 0.10343841463327408
step: 640, loss: 0.0440174862742424
step: 650, loss: 0.06347023695707321
step: 660, loss: 0.0411999337375164
step: 670, loss: 0.05816938728094101
step: 680, loss: 0.06791804730892181
step: 690, loss: 0.11121051013469696
step: 700, loss: 0.07891469448804855
step: 710, loss: 0.14361946284770966
step: 720, loss: 0.09409359842538834
step: 730, loss: 0.03075999766588211
step: 740, loss: 0.06766404211521149
step: 750, loss: 0.10233871638774872
step: 760, loss: 0.1515958607196808
step: 770, loss: 0.08139773458242416
step: 780, loss: 0.023497242480516434
step: 790, loss: 0.10001413524150848
step: 800, loss: 0.0067801037803292274
step: 810, loss: 0.023554522544145584
step: 820, loss: 0.0586528554558754
step: 830, loss: 0.028098177164793015
step: 840, loss: 0.17060551047325134
step: 850, loss: 0.04658442735671997
step: 860, loss: 0.08313938230276108
step: 870, loss: 0.0736037865281105
step: 880, loss: 0.05764494836330414
step: 890, loss: 0.09116438031196594
step: 900, loss: 0.05551474168896675
step: 910, loss: 0.08787902444601059
step: 920, loss: 0.05389082804322243
step: 930, loss: 0.10845115035772324
step: 940, loss: 0.06137150898575783
step: 950, loss: 0.08343766629695892
step: 960, loss: 0.059944458305835724
step: 970, loss: 0.05175952985882759
epoch 13: dev_f1=0.9285380663241476, f1=0.9328392774432608, best_f1=0.9406350667280258
step: 0, loss: 0.052425675094127655
step: 10, loss: 0.07697507739067078
step: 20, loss: 0.03891390562057495
step: 30, loss: 0.024966128170490265
step: 40, loss: 0.1064557284116745
step: 50, loss: 0.0602913424372673
step: 60, loss: 0.016517670825123787
step: 70, loss: 0.024860188364982605
step: 80, loss: 0.047109030187129974
step: 90, loss: 0.09859893471002579
step: 100, loss: 0.12151476740837097
step: 110, loss: 0.12850303947925568
step: 120, loss: 0.0005374700995162129
step: 130, loss: 0.002555866725742817
step: 140, loss: 0.020888235419988632
step: 150, loss: 0.158969447016716
step: 160, loss: 0.06900467723608017
step: 170, loss: 0.050527919083833694
step: 180, loss: 0.027149271219968796
step: 190, loss: 0.022428438067436218
step: 200, loss: 0.027797508984804153
step: 210, loss: 0.003564321668818593
step: 220, loss: 0.14995437860488892
step: 230, loss: 0.1141168475151062
step: 240, loss: 0.11339324712753296
step: 250, loss: 0.06783886253833771
step: 260, loss: 0.0037514264695346355
step: 270, loss: 0.11863104999065399
step: 280, loss: 0.10393219441175461
step: 290, loss: 0.0820818617939949
step: 300, loss: 0.022580331191420555
step: 310, loss: 0.12515725195407867
step: 320, loss: 0.054096706211566925
step: 330, loss: 0.07984261214733124
step: 340, loss: 0.11549829691648483
step: 350, loss: 0.12557224929332733
step: 360, loss: 0.07805859297513962
step: 370, loss: 0.0045768884010612965
step: 380, loss: 0.02187412418425083
step: 390, loss: 0.14109574258327484
step: 400, loss: 0.07432299852371216
step: 410, loss: 0.1256716251373291
step: 420, loss: 0.13045300543308258
step: 430, loss: 0.059975504875183105
step: 440, loss: 0.0023118555545806885
step: 450, loss: 0.10420594364404678
step: 460, loss: 0.03474165499210358
step: 470, loss: 0.01925850473344326
step: 480, loss: 0.05902010574936867
step: 490, loss: 0.019103771075606346
step: 500, loss: 0.05217147246003151
step: 510, loss: 0.05076651647686958
step: 520, loss: 0.019147856160998344
step: 530, loss: 0.047983210533857346
step: 540, loss: 0.028216343373060226
step: 550, loss: 0.14283855259418488
step: 560, loss: 0.0657842680811882
step: 570, loss: 0.06944656372070312
step: 580, loss: 0.12671644985675812
step: 590, loss: 0.07300182431936264
step: 600, loss: 0.024867847561836243
step: 610, loss: 0.12257684767246246
step: 620, loss: 0.019726421684026718
step: 630, loss: 0.10241583734750748
step: 640, loss: 0.023162098601460457
step: 650, loss: 0.059919215738773346
step: 660, loss: 0.034854043275117874
step: 670, loss: 0.04692758619785309
step: 680, loss: 0.046784356236457825
step: 690, loss: 0.0019792881794273853
step: 700, loss: 0.09204620867967606
step: 710, loss: 0.037796519696712494
step: 720, loss: 0.04778742045164108
step: 730, loss: 0.0966464951634407
step: 740, loss: 0.04005517438054085
step: 750, loss: 0.10969561338424683
step: 760, loss: 2.4603385099908337e-05
step: 770, loss: 0.037806738168001175
step: 780, loss: 0.10524870455265045
step: 790, loss: 0.03934828191995621
step: 800, loss: 0.01960059441626072
step: 810, loss: 0.03924160823225975
step: 820, loss: 0.030075673013925552
step: 830, loss: 0.0008132701041176915
step: 840, loss: 0.0904092937707901
step: 850, loss: 0.0665106475353241
step: 860, loss: 0.09804511815309525
step: 870, loss: 0.14185266196727753
step: 880, loss: 0.02655971236526966
step: 890, loss: 0.03779027983546257
step: 900, loss: 0.14074251055717468
step: 910, loss: 0.05507245659828186
step: 920, loss: 0.11485782265663147
step: 930, loss: 0.048309240490198135
step: 940, loss: 0.010409225709736347
step: 950, loss: 0.1039716899394989
step: 960, loss: 0.027675984427332878
step: 970, loss: 0.043672144412994385
epoch 14: dev_f1=0.929840972871843, f1=0.9317865429234339, best_f1=0.9406350667280258
step: 0, loss: 0.006023856811225414
step: 10, loss: 0.050353698432445526
step: 20, loss: 0.04240382835268974
step: 30, loss: 0.057463258504867554
step: 40, loss: 0.0692719966173172
step: 50, loss: 0.06208408251404762
step: 60, loss: 0.07433716952800751
step: 70, loss: 0.0838860347867012
step: 80, loss: 0.017015747725963593
step: 90, loss: 0.03420695289969444
step: 100, loss: 0.054438307881355286
step: 110, loss: 0.14747220277786255
step: 120, loss: 0.07381406426429749
step: 130, loss: 0.0402216799557209
step: 140, loss: 0.0381837859749794
step: 150, loss: 0.0031127212569117546
step: 160, loss: 0.021882783621549606
step: 170, loss: 0.04040992632508278
step: 180, loss: 0.048131585121154785
step: 190, loss: 0.1230613961815834
step: 200, loss: 0.046818070113658905
step: 210, loss: 0.03684203326702118
step: 220, loss: 0.06369461864233017
step: 230, loss: 0.02470429427921772
step: 240, loss: 0.08470427989959717
step: 250, loss: 0.0816931426525116
step: 260, loss: 0.0019186405697837472
step: 270, loss: 0.2601942718029022
step: 280, loss: 0.0585329569876194
step: 290, loss: 0.03742125630378723
step: 300, loss: 0.04217556118965149
step: 310, loss: 0.0525401309132576
step: 320, loss: 0.024902544915676117
step: 330, loss: 0.04033703729510307
step: 340, loss: 0.11412493139505386
step: 350, loss: 0.04680034518241882
step: 360, loss: 0.11627230793237686
step: 370, loss: 0.061197638511657715
step: 380, loss: 0.030849434435367584
step: 390, loss: 0.08602489531040192
step: 400, loss: 0.01631755195558071
step: 410, loss: 0.12425517290830612
step: 420, loss: 0.04752012714743614
step: 430, loss: 0.09210009127855301
step: 440, loss: 0.07243278622627258
step: 450, loss: 0.08616679906845093
step: 460, loss: 0.07879015058279037
step: 470, loss: 0.03135322406888008
step: 480, loss: 0.10862426459789276
step: 490, loss: 0.05640048161149025
step: 500, loss: 0.10841139405965805
step: 510, loss: 0.07302485406398773
step: 520, loss: 0.10283910483121872
step: 530, loss: 0.03385845944285393
step: 540, loss: 0.09707179665565491
step: 550, loss: 0.029968854039907455
step: 560, loss: 0.07342842221260071
step: 570, loss: 0.056729793548583984
step: 580, loss: 0.031215781345963478
step: 590, loss: 0.08506793528795242
step: 600, loss: 0.16573835909366608
step: 610, loss: 0.03437570855021477
step: 620, loss: 0.08691508322954178
step: 630, loss: 0.08428353071212769
step: 640, loss: 0.03903315216302872
step: 650, loss: 0.03788154199719429
step: 660, loss: 0.0010147416032850742
step: 670, loss: 0.065023273229599
step: 680, loss: 0.09260773658752441
step: 690, loss: 0.07754456251859665
step: 700, loss: 0.03121514618396759
step: 710, loss: 0.04096422344446182
step: 720, loss: 0.0012044061440974474
step: 730, loss: 0.0827755481004715
step: 740, loss: 0.10451647639274597
step: 750, loss: 0.02980749122798443
step: 760, loss: 0.0684431791305542
step: 770, loss: 0.07708459347486496
step: 780, loss: 0.028662504628300667
step: 790, loss: 0.15899387001991272
step: 800, loss: 0.026912866160273552
step: 810, loss: 0.038393791764974594
step: 820, loss: 0.05505654588341713
step: 830, loss: 0.0024887819308787584
step: 840, loss: 0.038983240723609924
step: 850, loss: 0.04247409477829933
step: 860, loss: 0.06570704281330109
step: 870, loss: 0.1476094126701355
step: 880, loss: 0.01135297492146492
step: 890, loss: 0.009458089247345924
step: 900, loss: 0.08980076014995575
step: 910, loss: 0.18151447176933289
step: 920, loss: 0.032376863062381744
step: 930, loss: 0.017099523916840553
step: 940, loss: 0.08035872131586075
step: 950, loss: 0.1422838717699051
step: 960, loss: 0.04267967864871025
step: 970, loss: 0.10218081623315811
epoch 15: dev_f1=0.9306197964847363, f1=0.9333333333333335, best_f1=0.9406350667280258
step: 0, loss: 0.06310376524925232
step: 10, loss: 0.12180118262767792
step: 20, loss: 0.022138435393571854
step: 30, loss: 0.05762298405170441
step: 40, loss: 0.06645374000072479
step: 50, loss: 0.03472527116537094
step: 60, loss: 0.043361369520425797
step: 70, loss: 0.07144651561975479
step: 80, loss: 0.06138824671506882
step: 90, loss: 0.09111558645963669
step: 100, loss: 0.059030164033174515
step: 110, loss: 0.023655079305171967
step: 120, loss: 0.07364907115697861
step: 130, loss: 0.00023066716676112264
step: 140, loss: 0.029613202437758446
step: 150, loss: 0.06982681155204773
step: 160, loss: 0.0828920528292656
step: 170, loss: 0.11344631016254425
step: 180, loss: 0.16169139742851257
step: 190, loss: 0.016071131452918053
step: 200, loss: 0.001519461628049612
step: 210, loss: 0.00030503657762892544
step: 220, loss: 0.006433621048927307
step: 230, loss: 0.07749646157026291
step: 240, loss: 0.04431258141994476
step: 250, loss: 0.09585084021091461
step: 260, loss: 0.0375601164996624
step: 270, loss: 0.05980631336569786
step: 280, loss: 0.002937440760433674
step: 290, loss: 0.0716061145067215
step: 300, loss: 0.13510482013225555
step: 310, loss: 0.017128314822912216
step: 320, loss: 0.05602525174617767
step: 330, loss: 0.025264117866754532
step: 340, loss: 0.0743613913655281
step: 350, loss: 0.0802166759967804
step: 360, loss: 0.003001968376338482
step: 370, loss: 0.17898860573768616
step: 380, loss: 0.08479459583759308
step: 390, loss: 0.05726752430200577
step: 400, loss: 0.03224130719900131
step: 410, loss: 0.04281579703092575
step: 420, loss: 0.007896711118519306
step: 430, loss: 0.11718620359897614
step: 440, loss: 0.059714607894420624
step: 450, loss: 0.020036835223436356
step: 460, loss: 0.061258647590875626
step: 470, loss: 0.1584981381893158
step: 480, loss: 0.08267205208539963
step: 490, loss: 0.05711689591407776
step: 500, loss: 0.03722046688199043
step: 510, loss: 0.02437911182641983
step: 520, loss: 0.05579470098018646
step: 530, loss: 0.043961383402347565
step: 540, loss: 0.06190970912575722
step: 550, loss: 0.03238191828131676
step: 560, loss: 0.07054193317890167
step: 570, loss: 0.058549631386995316
step: 580, loss: 0.1265409290790558
step: 590, loss: 0.012972130440175533
step: 600, loss: 0.06248830258846283
step: 610, loss: 0.04991209879517555
step: 620, loss: 0.06140550225973129
step: 630, loss: 0.0843881145119667
step: 640, loss: 0.1384989321231842
step: 650, loss: 0.024310272186994553
step: 660, loss: 0.07221044600009918
step: 670, loss: 0.02128617651760578
step: 680, loss: 0.16096067428588867
step: 690, loss: 0.041985221207141876
step: 700, loss: 0.04017632082104683
step: 710, loss: 0.06585659831762314
step: 720, loss: 0.07102227210998535
step: 730, loss: 0.032274797558784485
step: 740, loss: 0.03339753299951553
step: 750, loss: 0.03278561308979988
step: 760, loss: 0.025537459179759026
step: 770, loss: 0.08246010541915894
step: 780, loss: 0.029735811054706573
step: 790, loss: 0.11088605970144272
step: 800, loss: 0.12695980072021484
step: 810, loss: 0.005815370939671993
step: 820, loss: 0.08542242646217346
step: 830, loss: 0.02677948959171772
step: 840, loss: 0.12273727357387543
step: 850, loss: 0.07462572306394577
step: 860, loss: 0.09767432510852814
step: 870, loss: 0.11946123093366623
step: 880, loss: 0.11491341888904572
step: 890, loss: 0.0970875471830368
step: 900, loss: 0.1035366952419281
step: 910, loss: 0.062447916716337204
step: 920, loss: 0.12466903030872345
step: 930, loss: 0.02125021256506443
step: 940, loss: 0.0352872796356678
step: 950, loss: 0.05646568164229393
step: 960, loss: 0.11270655691623688
step: 970, loss: 0.15010088682174683
epoch 16: dev_f1=0.9328323156411461, f1=0.931711880261927, best_f1=0.9406350667280258
step: 0, loss: 0.07036323100328445
step: 10, loss: 0.027882425114512444
step: 20, loss: 0.05668315291404724
step: 30, loss: 0.027367670089006424
step: 40, loss: 0.07310935854911804
step: 50, loss: 0.03947538137435913
step: 60, loss: 0.04105434939265251
step: 70, loss: 0.029007917270064354
step: 80, loss: 0.01821715757250786
step: 90, loss: 0.06776069104671478
step: 100, loss: 0.0390809141099453
step: 110, loss: 0.07081916928291321
step: 120, loss: 0.11050168424844742
step: 130, loss: 0.015812842175364494
step: 140, loss: 0.0028539279010146856
step: 150, loss: 0.01293537300080061
step: 160, loss: 0.03293424844741821
step: 170, loss: 0.07938451319932938
step: 180, loss: 0.009091035462915897
step: 190, loss: 0.014578892849385738
step: 200, loss: 0.0511440709233284
step: 210, loss: 0.05929519608616829
step: 220, loss: 0.04858323186635971
step: 230, loss: 0.04846755415201187
step: 240, loss: 0.02785617485642433
step: 250, loss: 0.03128983452916145
step: 260, loss: 0.049402203410863876
step: 270, loss: 0.025117218494415283
step: 280, loss: 0.04791533946990967
step: 290, loss: 0.011343702673912048
step: 300, loss: 0.07286802679300308
step: 310, loss: 0.06936381012201309
step: 320, loss: 0.07832448929548264
step: 330, loss: 0.11926861852407455
step: 340, loss: 0.10785536468029022
step: 350, loss: 0.04567212611436844
step: 360, loss: 0.022839490324258804
step: 370, loss: 0.06317788362503052
step: 380, loss: 0.03439411148428917
step: 390, loss: 0.00319311604835093
step: 400, loss: 0.09417091310024261
step: 410, loss: 0.0021194792352616787
step: 420, loss: 0.077448271214962
step: 430, loss: 0.0009911541128531098
step: 440, loss: 0.048100795596838
step: 450, loss: 0.09351477026939392
step: 460, loss: 0.04753950238227844
step: 470, loss: 0.012649482116103172
step: 480, loss: 0.02657330594956875
step: 490, loss: 0.03407510742545128
step: 500, loss: 0.04724249243736267
step: 510, loss: 0.07903532683849335
step: 520, loss: 0.10756593197584152
step: 530, loss: 0.1383746713399887
step: 540, loss: 0.035951316356658936
step: 550, loss: 0.059658098965883255
step: 560, loss: 0.10835158824920654
step: 570, loss: 0.06103016808629036
step: 580, loss: 0.019559653475880623
step: 590, loss: 0.018955474719405174
step: 600, loss: 0.08064331114292145
step: 610, loss: 0.027702579274773598
step: 620, loss: 0.05069858208298683
step: 630, loss: 0.022536911070346832
step: 640, loss: 0.2074519246816635
step: 650, loss: 0.1714082509279251
step: 660, loss: 0.11253518611192703
step: 670, loss: 0.05445262789726257
step: 680, loss: 0.053540587425231934
step: 690, loss: 0.06967293471097946
step: 700, loss: 0.04014206677675247
step: 710, loss: 0.04011648893356323
step: 720, loss: 0.025404030457139015
step: 730, loss: 0.0765651986002922
step: 740, loss: 0.04014031961560249
step: 750, loss: 0.05080719292163849
step: 760, loss: 0.08715175092220306
step: 770, loss: 0.018175940960645676
step: 780, loss: 0.06224615126848221
step: 790, loss: 0.06515281647443771
step: 800, loss: 0.011354058049619198
step: 810, loss: 0.14548011124134064
step: 820, loss: 0.03876805678009987
step: 830, loss: 0.27995565533638
step: 840, loss: 0.049310989677906036
step: 850, loss: 0.017464082688093185
step: 860, loss: 0.031280517578125
step: 870, loss: 1.013639302982483e-05
step: 880, loss: 0.017939947545528412
step: 890, loss: 0.08967165648937225
step: 900, loss: 0.009372420608997345
step: 910, loss: 0.17997446656227112
step: 920, loss: 0.12018246948719025
step: 930, loss: 0.08541202545166016
step: 940, loss: 0.18457357585430145
step: 950, loss: 0.15546612441539764
step: 960, loss: 0.026228904724121094
step: 970, loss: 0.00038197808316908777
epoch 17: dev_f1=0.93202062822316, f1=0.9328984156570364, best_f1=0.9406350667280258
step: 0, loss: 0.0670449510216713
step: 10, loss: 0.08095960319042206
step: 20, loss: 0.0625048503279686
step: 30, loss: 0.06790591776371002
step: 40, loss: 0.09396179020404816
step: 50, loss: 0.046645719558000565
step: 60, loss: 0.018830623477697372
step: 70, loss: 0.042601123452186584
step: 80, loss: 0.09201403707265854
step: 90, loss: 0.013943804427981377
step: 100, loss: 0.08823012560606003
step: 110, loss: 0.02863161638379097
step: 120, loss: 0.028497805818915367
step: 130, loss: 0.09136094152927399
step: 140, loss: 0.01728617213666439
step: 150, loss: 0.07345505803823471
step: 160, loss: 0.04046778753399849
step: 170, loss: 0.042285460978746414
step: 180, loss: 0.009297850541770458
step: 190, loss: 0.03853609412908554
step: 200, loss: 0.045841265469789505
step: 210, loss: 0.034144069999456406
step: 220, loss: 0.039683301001787186
step: 230, loss: 0.1722794473171234
step: 240, loss: 0.13101504743099213
step: 250, loss: 0.0636797696352005
step: 260, loss: 0.05067278444766998
step: 270, loss: 0.04354546591639519
step: 280, loss: 0.17261618375778198
step: 290, loss: 0.09726358950138092
step: 300, loss: 0.0032787462696433067
step: 310, loss: 0.01646542176604271
step: 320, loss: 0.000831369892694056
step: 330, loss: 0.004563517868518829
step: 340, loss: 0.053423382341861725
step: 350, loss: 0.061768513172864914
step: 360, loss: 0.02340388298034668
step: 370, loss: 0.06096557155251503
step: 380, loss: 0.06431383639574051
step: 390, loss: 0.02537248656153679
step: 400, loss: 0.04892599210143089
step: 410, loss: 0.009206396527588367
step: 420, loss: 0.0008547127363272011
step: 430, loss: 0.11693096905946732
step: 440, loss: 0.00012660399079322815
step: 450, loss: 0.08706481009721756
step: 460, loss: 0.0002648972440510988
step: 470, loss: 3.919006121577695e-05
step: 480, loss: 0.0727182924747467
step: 490, loss: 0.06643828004598618
step: 500, loss: 0.11845418065786362
step: 510, loss: 0.010508980602025986
step: 520, loss: 0.042323239147663116
step: 530, loss: 0.06413687765598297
step: 540, loss: 0.007668917998671532
step: 550, loss: 0.06582842767238617
step: 560, loss: 0.025437956675887108
step: 570, loss: 0.06015788018703461
step: 580, loss: 0.07427123188972473
step: 590, loss: 0.04392627254128456
step: 600, loss: 0.03991417959332466
step: 610, loss: 0.02126300521194935
step: 620, loss: 0.01667274907231331
step: 630, loss: 0.07068062573671341
step: 640, loss: 0.018278444185853004
step: 650, loss: 0.18014121055603027
step: 660, loss: 0.11591648310422897
step: 670, loss: 0.05660674721002579
step: 680, loss: 0.0837579071521759
step: 690, loss: 0.03726443648338318
step: 700, loss: 0.12575441598892212
step: 710, loss: 0.0473463237285614
step: 720, loss: 0.002937882672995329
step: 730, loss: 0.20719656348228455
step: 740, loss: 0.0445270836353302
step: 750, loss: 0.03316574916243553
step: 760, loss: 0.027305833995342255
step: 770, loss: 0.07695110142230988
step: 780, loss: 0.045887503772974014
step: 790, loss: 0.020572807639837265
step: 800, loss: 0.029994240030646324
step: 810, loss: 0.049155980348587036
step: 820, loss: 0.08803839236497879
step: 830, loss: 0.024851860478520393
step: 840, loss: 0.07040373235940933
step: 850, loss: 7.409938552882522e-05
step: 860, loss: 0.09698698669672012
step: 870, loss: 0.023905199021100998
step: 880, loss: 0.06200534850358963
step: 890, loss: 0.06215545907616615
step: 900, loss: 0.12035173177719116
step: 910, loss: 0.010531578212976456
step: 920, loss: 0.07832897454500198
step: 930, loss: 0.008889703080058098
step: 940, loss: 0.06831729412078857
step: 950, loss: 0.000950347981415689
step: 960, loss: 0.02109471894800663
step: 970, loss: 0.059078384190797806
epoch 18: dev_f1=0.9317535545023696, f1=0.9293119698397737, best_f1=0.9406350667280258
step: 0, loss: 0.05649951472878456
step: 10, loss: 0.06483954191207886
step: 20, loss: 0.034012798219919205
step: 30, loss: 0.08444102108478546
step: 40, loss: 0.06573127955198288
step: 50, loss: 0.08050525188446045
step: 60, loss: 0.04300820454955101
step: 70, loss: 0.11040852218866348
step: 80, loss: 0.07971504330635071
step: 90, loss: 0.028676748275756836
step: 100, loss: 0.029274607077240944
step: 110, loss: 0.04516773298382759
step: 120, loss: 0.03914109617471695
step: 130, loss: 0.031194211915135384
step: 140, loss: 0.06334470957517624
step: 150, loss: 0.062906913459301
step: 160, loss: 0.021431703120470047
step: 170, loss: 0.04202201962471008
step: 180, loss: 0.09160063415765762
step: 190, loss: 0.0756421610713005
step: 200, loss: 0.03963540494441986
step: 210, loss: 0.0668492317199707
step: 220, loss: 0.09309758245944977
step: 230, loss: 0.045719340443611145
step: 240, loss: 0.004111103247851133
step: 250, loss: 0.008361722342669964
step: 260, loss: 0.07966136932373047
step: 270, loss: 0.03398698940873146
step: 280, loss: 0.05491803586483002
step: 290, loss: 0.05453850328922272
step: 300, loss: 0.0006048514042049646
step: 310, loss: 0.0406453013420105
step: 320, loss: 0.08918488770723343
step: 330, loss: 0.051557932049036026
step: 340, loss: 0.016457071527838707
step: 350, loss: 0.01264728419482708
step: 360, loss: 0.05242568999528885
step: 370, loss: 0.0743187814950943
step: 380, loss: 0.03023245371878147
step: 390, loss: 0.14792045950889587
step: 400, loss: 0.022538263350725174
step: 410, loss: 0.10607246309518814
step: 420, loss: 0.020248141139745712
step: 430, loss: 0.07814320921897888
step: 440, loss: 0.02277264930307865
step: 450, loss: 0.004859221167862415
step: 460, loss: 0.0687788873910904
step: 470, loss: 0.03748360648751259
step: 480, loss: 0.08576410263776779
step: 490, loss: 0.04078329727053642
step: 500, loss: 0.11401285976171494
step: 510, loss: 0.023693284019827843
step: 520, loss: 0.06123146042227745
step: 530, loss: 0.04656711965799332
step: 540, loss: 0.02121288701891899
step: 550, loss: 0.0687306597828865
step: 560, loss: 0.05068189650774002
step: 570, loss: 0.013285970315337181
step: 580, loss: 0.15766461193561554
step: 590, loss: 0.06474455446004868
step: 600, loss: 0.014605609700083733
step: 610, loss: 0.0015398635296151042
step: 620, loss: 3.909620500053279e-05
step: 630, loss: 0.019808614626526833
step: 640, loss: 0.017441406846046448
step: 650, loss: 0.061169594526290894
step: 660, loss: 0.007094343192875385
step: 670, loss: 0.101361483335495
step: 680, loss: 0.06796365976333618
step: 690, loss: 0.15064264833927155
step: 700, loss: 0.07033859938383102
step: 710, loss: 0.051110535860061646
step: 720, loss: 0.07293199002742767
step: 730, loss: 0.1200954020023346
step: 740, loss: 0.04340137168765068
step: 750, loss: 0.04128136485815048
step: 760, loss: 0.019069937989115715
step: 770, loss: 0.035058122128248215
step: 780, loss: 0.05892800912261009
step: 790, loss: 0.047284092754125595
step: 800, loss: 0.022445349022746086
step: 810, loss: 0.000654177856631577
step: 820, loss: 0.0862077921628952
step: 830, loss: 0.0016390379751101136
step: 840, loss: 0.052798960357904434
step: 850, loss: 0.00018245368846692145
step: 860, loss: 0.01769242435693741
step: 870, loss: 0.04748396575450897
step: 880, loss: 0.062433816492557526
step: 890, loss: 0.025843342766165733
step: 900, loss: 0.01443527266383171
step: 910, loss: 0.11791923642158508
step: 920, loss: 0.0594555102288723
step: 930, loss: 0.14084826409816742
step: 940, loss: 0.09356251358985901
step: 950, loss: 0.07713903486728668
step: 960, loss: 0.10893649607896805
step: 970, loss: 0.0788244754076004
epoch 19: dev_f1=0.9325842696629213, f1=0.9324009324009325, best_f1=0.9406350667280258
step: 0, loss: 0.0041683511808514595
step: 10, loss: 0.023512868210673332
step: 20, loss: 0.05286165699362755
step: 30, loss: 0.10218498110771179
step: 40, loss: 0.022304926067590714
step: 50, loss: 0.07745834439992905
step: 60, loss: 0.015002220869064331
step: 70, loss: 0.049358561635017395
step: 80, loss: 0.06879034638404846
step: 90, loss: 0.024656277149915695
step: 100, loss: 0.06567029654979706
step: 110, loss: 0.09088660031557083
step: 120, loss: 0.08791691809892654
step: 130, loss: 0.037008605897426605
step: 140, loss: 0.04183080419898033
step: 150, loss: 0.039935335516929626
step: 160, loss: 0.05544992908835411
step: 170, loss: 0.04172345995903015
step: 180, loss: 0.019117742776870728
step: 190, loss: 0.07605665922164917
step: 200, loss: 0.02526259608566761
step: 210, loss: 0.013614698313176632
step: 220, loss: 0.012258521281182766
step: 230, loss: 0.12786230444908142
step: 240, loss: 0.01646413654088974
step: 250, loss: 0.07614459097385406
step: 260, loss: 0.013713977299630642
step: 270, loss: 0.09295649826526642
step: 280, loss: 0.0494808666408062
step: 290, loss: 0.09029004722833633
step: 300, loss: 0.06428676098585129
step: 310, loss: 0.04276642948389053
step: 320, loss: 0.03589801490306854
step: 330, loss: 0.000445160228991881
step: 340, loss: 0.07032541930675507
step: 350, loss: 0.03720170259475708
step: 360, loss: 0.07207977771759033
step: 370, loss: 0.053598951548337936
step: 380, loss: 0.04246499389410019
step: 390, loss: 0.1459500640630722
step: 400, loss: 0.03539007902145386
step: 410, loss: 0.11457076668739319
step: 420, loss: 6.388852398231393e-06
step: 430, loss: 0.037484049797058105
step: 440, loss: 0.0141358757391572
step: 450, loss: 0.00014474573254119605
step: 460, loss: 0.17455212771892548
step: 470, loss: 0.03475676476955414
step: 480, loss: 0.032021790742874146
step: 490, loss: 0.08276044577360153
step: 500, loss: 0.05171995609998703
step: 510, loss: 0.08741940557956696
step: 520, loss: 0.05002317577600479
step: 530, loss: 0.017825458198785782
step: 540, loss: 0.0407148152589798
step: 550, loss: 0.05522562190890312
step: 560, loss: 0.0003538795281201601
step: 570, loss: 0.042845238000154495
step: 580, loss: 0.0820082426071167
step: 590, loss: 0.0025773278903216124
step: 600, loss: 0.02616523765027523
step: 610, loss: 0.11843830347061157
step: 620, loss: 0.026425188407301903
step: 630, loss: 0.052060723304748535
step: 640, loss: 0.06096135079860687
step: 650, loss: 0.031207246705889702
step: 660, loss: 0.04189181700348854
step: 670, loss: 0.06584525108337402
step: 680, loss: 0.10747863352298737
step: 690, loss: 0.03659743070602417
step: 700, loss: 0.0022568826097995043
step: 710, loss: 0.04855867102742195
step: 720, loss: 0.02357194945216179
step: 730, loss: 0.015125570818781853
step: 740, loss: 0.019209692254662514
step: 750, loss: 0.00735680153593421
step: 760, loss: 0.08031187206506729
step: 770, loss: 0.08984319865703583
step: 780, loss: 0.0021499875001609325
step: 790, loss: 0.02943602204322815
step: 800, loss: 0.10416977852582932
step: 810, loss: 0.0031188251450657845
step: 820, loss: 0.02448396384716034
step: 830, loss: 0.06685898452997208
step: 840, loss: 0.04030556604266167
step: 850, loss: 0.11682090908288956
step: 860, loss: 0.06052110716700554
step: 870, loss: 0.024459507316350937
step: 880, loss: 0.01741468906402588
step: 890, loss: 0.023704705759882927
step: 900, loss: 0.14982903003692627
step: 910, loss: 0.08537007868289948
step: 920, loss: 0.09637267887592316
step: 930, loss: 0.05639513581991196
step: 940, loss: 0.034536298364400864
step: 950, loss: 0.069281205534935
step: 960, loss: 0.015238547697663307
step: 970, loss: 0.01688639260828495
epoch 20: dev_f1=0.9318288669487541, f1=0.9325210871602625, best_f1=0.9406350667280258
