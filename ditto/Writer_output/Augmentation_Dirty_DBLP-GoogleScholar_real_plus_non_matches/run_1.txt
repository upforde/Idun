cuda
Device: cuda
step: 0, loss: 0.6941498517990112
step: 10, loss: 0.3051246702671051
step: 20, loss: 0.37631550431251526
step: 30, loss: 0.2736249566078186
step: 40, loss: 0.47152942419052124
step: 50, loss: 0.27429649233818054
step: 60, loss: 0.23293271660804749
step: 70, loss: 0.1269906759262085
step: 80, loss: 0.1900106966495514
step: 90, loss: 0.15167278051376343
step: 100, loss: 0.14052599668502808
step: 110, loss: 0.14136818051338196
step: 120, loss: 0.1125997006893158
step: 130, loss: 0.11656847596168518
step: 140, loss: 0.14519469439983368
step: 150, loss: 0.17040276527404785
step: 160, loss: 0.11038114130496979
step: 170, loss: 0.15841367840766907
step: 180, loss: 0.11128357797861099
step: 190, loss: 0.19130578637123108
step: 200, loss: 0.17479074001312256
step: 210, loss: 0.22531640529632568
step: 220, loss: 0.12498670071363449
step: 230, loss: 0.0986119881272316
step: 240, loss: 0.20327313244342804
step: 250, loss: 0.2075602412223816
step: 260, loss: 0.19595959782600403
step: 270, loss: 0.0848473310470581
step: 280, loss: 0.13787832856178284
step: 290, loss: 0.12163590639829636
step: 300, loss: 0.1481867879629135
step: 310, loss: 0.10856758803129196
step: 320, loss: 0.05932217836380005
step: 330, loss: 0.1025981605052948
step: 340, loss: 0.07645558565855026
step: 350, loss: 0.27327075600624084
step: 360, loss: 0.11043815314769745
step: 370, loss: 0.14642801880836487
step: 380, loss: 0.14300276339054108
step: 390, loss: 0.14418381452560425
step: 400, loss: 0.1311248391866684
step: 410, loss: 0.09845670312643051
step: 420, loss: 0.15320350229740143
step: 430, loss: 0.2007036805152893
step: 440, loss: 0.15687017142772675
step: 450, loss: 0.11481958627700806
step: 460, loss: 0.13672378659248352
step: 470, loss: 0.11105987429618835
step: 480, loss: 0.0557897686958313
step: 490, loss: 0.10948583483695984
step: 500, loss: 0.25801223516464233
step: 510, loss: 0.1595069020986557
step: 520, loss: 0.041457079350948334
step: 530, loss: 0.16198958456516266
step: 540, loss: 0.18631917238235474
step: 550, loss: 0.15787625312805176
step: 560, loss: 0.2584647238254547
step: 570, loss: 0.1805884838104248
step: 580, loss: 0.14549142122268677
step: 590, loss: 0.17904406785964966
step: 600, loss: 0.22073052823543549
step: 610, loss: 0.0846116840839386
step: 620, loss: 0.0666901022195816
step: 630, loss: 0.255393922328949
step: 640, loss: 0.0773327425122261
step: 650, loss: 0.07939925044775009
step: 660, loss: 0.19074758887290955
step: 670, loss: 0.08651111274957657
step: 680, loss: 0.05710737779736519
step: 690, loss: 0.15507963299751282
step: 700, loss: 0.17330417037010193
step: 710, loss: 0.188444122672081
step: 720, loss: 0.21540510654449463
step: 730, loss: 0.1244923397898674
step: 740, loss: 0.15897776186466217
step: 750, loss: 0.2687755227088928
step: 760, loss: 0.08079839497804642
step: 770, loss: 0.2203594446182251
step: 780, loss: 0.2095463126897812
step: 790, loss: 0.15123584866523743
step: 800, loss: 0.15640918910503387
step: 810, loss: 0.11862370371818542
step: 820, loss: 0.13857918977737427
step: 830, loss: 0.14013627171516418
step: 840, loss: 0.167451873421669
step: 850, loss: 0.1419702172279358
step: 860, loss: 0.10271298885345459
step: 870, loss: 0.21142244338989258
step: 880, loss: 0.08266341686248779
step: 890, loss: 0.19852589070796967
step: 900, loss: 0.14616093039512634
step: 910, loss: 0.3385794460773468
step: 920, loss: 0.08597449213266373
step: 930, loss: 0.0754447653889656
step: 940, loss: 0.13973574340343475
step: 950, loss: 0.0689367949962616
step: 960, loss: 0.1425851285457611
step: 970, loss: 0.1261993795633316
epoch 1: dev_f1=0.9175398633257403, f1=0.9139492753623188, best_f1=0.9139492753623188
step: 0, loss: 0.09820009022951126
step: 10, loss: 0.1129041463136673
step: 20, loss: 0.1034492626786232
step: 30, loss: 0.08464230597019196
step: 40, loss: 0.09747893363237381
step: 50, loss: 0.04344953969120979
step: 60, loss: 0.12129687517881393
step: 70, loss: 0.16183435916900635
step: 80, loss: 0.11305329948663712
step: 90, loss: 0.14432355761528015
step: 100, loss: 0.14979475736618042
step: 110, loss: 0.28567710518836975
step: 120, loss: 0.08451058715581894
step: 130, loss: 0.14438743889331818
step: 140, loss: 0.21938443183898926
step: 150, loss: 0.19035954773426056
step: 160, loss: 0.14737536013126373
step: 170, loss: 0.03169682249426842
step: 180, loss: 0.17383763194084167
step: 190, loss: 0.14235042035579681
step: 200, loss: 0.2883293330669403
step: 210, loss: 0.12237466126680374
step: 220, loss: 0.16543278098106384
step: 230, loss: 0.19764725863933563
step: 240, loss: 0.06363826245069504
step: 250, loss: 0.07009801268577576
step: 260, loss: 0.07788072526454926
step: 270, loss: 0.08833290636539459
step: 280, loss: 0.13189615309238434
step: 290, loss: 0.154179185628891
step: 300, loss: 0.06725507974624634
step: 310, loss: 0.0746438056230545
step: 320, loss: 0.10195568948984146
step: 330, loss: 0.30721336603164673
step: 340, loss: 0.09660278260707855
step: 350, loss: 0.11494419723749161
step: 360, loss: 0.1684267669916153
step: 370, loss: 0.05886616185307503
step: 380, loss: 0.14743587374687195
step: 390, loss: 0.18306685984134674
step: 400, loss: 0.06208105757832527
step: 410, loss: 0.051920030266046524
step: 420, loss: 0.20010237395763397
step: 430, loss: 0.22147411108016968
step: 440, loss: 0.11317653954029083
step: 450, loss: 0.24342948198318481
step: 460, loss: 0.2039015144109726
step: 470, loss: 0.04599134251475334
step: 480, loss: 0.0898272842168808
step: 490, loss: 0.13865961134433746
step: 500, loss: 0.11514294892549515
step: 510, loss: 0.12563498318195343
step: 520, loss: 0.09543132036924362
step: 530, loss: 0.08385869860649109
step: 540, loss: 0.05971734970808029
step: 550, loss: 0.09274934977293015
step: 560, loss: 0.11317451298236847
step: 570, loss: 0.20725210011005402
step: 580, loss: 0.13182495534420013
step: 590, loss: 0.13837023079395294
step: 600, loss: 0.09816251695156097
step: 610, loss: 0.10682352632284164
step: 620, loss: 0.12823279201984406
step: 630, loss: 0.08292260766029358
step: 640, loss: 0.11769893765449524
step: 650, loss: 0.08744831383228302
step: 660, loss: 0.1659260243177414
step: 670, loss: 0.11585626006126404
step: 680, loss: 0.12227395921945572
step: 690, loss: 0.18058869242668152
step: 700, loss: 0.05118386447429657
step: 710, loss: 0.11747430264949799
step: 720, loss: 0.09752587974071503
step: 730, loss: 0.10777057707309723
step: 740, loss: 0.20269189774990082
step: 750, loss: 0.07646340876817703
step: 760, loss: 0.12482241541147232
step: 770, loss: 0.1455082893371582
step: 780, loss: 0.053263306617736816
step: 790, loss: 0.09318424016237259
step: 800, loss: 0.35513198375701904
step: 810, loss: 0.08442731946706772
step: 820, loss: 0.09355281293392181
step: 830, loss: 0.07573109120130539
step: 840, loss: 0.07107039541006088
step: 850, loss: 0.18305304646492004
step: 860, loss: 0.18772068619728088
step: 870, loss: 0.10367590934038162
step: 880, loss: 0.1253645271062851
step: 890, loss: 0.23666022717952728
step: 900, loss: 0.1503797322511673
step: 910, loss: 0.12688210606575012
step: 920, loss: 0.18004034459590912
step: 930, loss: 0.19119711220264435
step: 940, loss: 0.04478927329182625
step: 950, loss: 0.07438571751117706
step: 960, loss: 0.04412592574954033
step: 970, loss: 0.29316070675849915
epoch 2: dev_f1=0.9213587715216379, f1=0.9194661757938334, best_f1=0.9194661757938334
step: 0, loss: 0.0903007760643959
step: 10, loss: 0.06756109744310379
step: 20, loss: 0.15377631783485413
step: 30, loss: 0.08655529469251633
step: 40, loss: 0.20300544798374176
step: 50, loss: 0.14781169593334198
step: 60, loss: 0.16709575057029724
step: 70, loss: 0.07432490587234497
step: 80, loss: 0.131581112742424
step: 90, loss: 0.12148255854845047
step: 100, loss: 0.187895268201828
step: 110, loss: 0.21108531951904297
step: 120, loss: 0.08562707155942917
step: 130, loss: 0.1463157832622528
step: 140, loss: 0.19360552728176117
step: 150, loss: 0.11211768537759781
step: 160, loss: 0.025517992675304413
step: 170, loss: 0.06513658165931702
step: 180, loss: 0.11483978480100632
step: 190, loss: 0.07132714241743088
step: 200, loss: 0.1391087770462036
step: 210, loss: 0.2255021184682846
step: 220, loss: 0.091205894947052
step: 230, loss: 0.13669607043266296
step: 240, loss: 0.1622234731912613
step: 250, loss: 0.08327680826187134
step: 260, loss: 0.08397559076547623
step: 270, loss: 0.04186001792550087
step: 280, loss: 0.05808849260210991
step: 290, loss: 0.029721466824412346
step: 300, loss: 0.41336601972579956
step: 310, loss: 0.11556564271450043
step: 320, loss: 0.06819098442792892
step: 330, loss: 0.08093027025461197
step: 340, loss: 0.1199805736541748
step: 350, loss: 0.22472670674324036
step: 360, loss: 0.07205498218536377
step: 370, loss: 0.21690581738948822
step: 380, loss: 0.024092160165309906
step: 390, loss: 0.13078995048999786
step: 400, loss: 0.13549870252609253
step: 410, loss: 0.11374714970588684
step: 420, loss: 0.09426049888134003
step: 430, loss: 0.1121969074010849
step: 440, loss: 0.1818443238735199
step: 450, loss: 0.0851106271147728
step: 460, loss: 0.10076602548360825
step: 470, loss: 0.26638099551200867
step: 480, loss: 0.11558593809604645
step: 490, loss: 0.07142198085784912
step: 500, loss: 0.09836110472679138
step: 510, loss: 0.1279420703649521
step: 520, loss: 0.07119900733232498
step: 530, loss: 0.1390993595123291
step: 540, loss: 0.09479332715272903
step: 550, loss: 0.14145992696285248
step: 560, loss: 0.16094356775283813
step: 570, loss: 0.06817558407783508
step: 580, loss: 0.13419175148010254
step: 590, loss: 0.10644078254699707
step: 600, loss: 0.15956886112689972
step: 610, loss: 0.044907622039318085
step: 620, loss: 0.1329413652420044
step: 630, loss: 0.21920327842235565
step: 640, loss: 0.08921466022729874
step: 650, loss: 0.3167492151260376
step: 660, loss: 0.1577470302581787
step: 670, loss: 0.14495447278022766
step: 680, loss: 0.18704506754875183
step: 690, loss: 0.03541599586606026
step: 700, loss: 0.19698576629161835
step: 710, loss: 0.15687067806720734
step: 720, loss: 0.07860665023326874
step: 730, loss: 0.04408232122659683
step: 740, loss: 0.057393088936805725
step: 750, loss: 0.04936880245804787
step: 760, loss: 0.0639117881655693
step: 770, loss: 0.07104166597127914
step: 780, loss: 0.14609083533287048
step: 790, loss: 0.21272388100624084
step: 800, loss: 0.031570855528116226
step: 810, loss: 0.09525861591100693
step: 820, loss: 0.25156068801879883
step: 830, loss: 0.055336542427539825
step: 840, loss: 0.056835491210222244
step: 850, loss: 0.07518289983272552
step: 860, loss: 0.10097134113311768
step: 870, loss: 0.11632485687732697
step: 880, loss: 0.09693765640258789
step: 890, loss: 0.11287608742713928
step: 900, loss: 0.08386453241109848
step: 910, loss: 0.0920497253537178
step: 920, loss: 0.08917376399040222
step: 930, loss: 0.11509018391370773
step: 940, loss: 0.15635989606380463
step: 950, loss: 0.08359101414680481
step: 960, loss: 0.1147448718547821
step: 970, loss: 0.0904836505651474
epoch 3: dev_f1=0.9202626641651033, f1=0.9167828916782892, best_f1=0.9194661757938334
step: 0, loss: 0.0577390156686306
step: 10, loss: 0.07467728853225708
step: 20, loss: 0.12498735636472702
step: 30, loss: 0.11080185323953629
step: 40, loss: 0.10047220438718796
step: 50, loss: 0.04633180424571037
step: 60, loss: 0.08775509148836136
step: 70, loss: 0.09017350524663925
step: 80, loss: 0.05686096101999283
step: 90, loss: 0.09015224128961563
step: 100, loss: 0.07753637433052063
step: 110, loss: 0.16384707391262054
step: 120, loss: 0.03587999567389488
step: 130, loss: 0.17960870265960693
step: 140, loss: 0.11925097554922104
step: 150, loss: 0.13288643956184387
step: 160, loss: 0.1371166855096817
step: 170, loss: 0.2944910228252411
step: 180, loss: 0.09791069477796555
step: 190, loss: 0.07815368473529816
step: 200, loss: 0.06216131150722504
step: 210, loss: 0.16017763316631317
step: 220, loss: 0.11084918677806854
step: 230, loss: 0.012030732817947865
step: 240, loss: 0.12910431623458862
step: 250, loss: 0.11951758712530136
step: 260, loss: 0.1082935780286789
step: 270, loss: 0.07395882159471512
step: 280, loss: 0.09518339484930038
step: 290, loss: 0.08034973591566086
step: 300, loss: 0.11178846657276154
step: 310, loss: 0.1562609076499939
step: 320, loss: 0.15498052537441254
step: 330, loss: 0.1616625040769577
step: 340, loss: 0.1657727062702179
step: 350, loss: 0.053121745586395264
step: 360, loss: 0.0609017089009285
step: 370, loss: 0.1528017818927765
step: 380, loss: 0.020543627440929413
step: 390, loss: 0.1435995250940323
step: 400, loss: 0.0717172622680664
step: 410, loss: 0.24002669751644135
step: 420, loss: 0.07744532078504562
step: 430, loss: 0.18258929252624512
step: 440, loss: 0.177493155002594
step: 450, loss: 0.0954824760556221
step: 460, loss: 0.08925361186265945
step: 470, loss: 0.11285751312971115
step: 480, loss: 0.044443804770708084
step: 490, loss: 0.13407471776008606
step: 500, loss: 0.2034463733434677
step: 510, loss: 0.07469594478607178
step: 520, loss: 0.1342211812734604
step: 530, loss: 0.15557776391506195
step: 540, loss: 0.1027623862028122
step: 550, loss: 0.11834222078323364
step: 560, loss: 0.06231626123189926
step: 570, loss: 0.14343613386154175
step: 580, loss: 0.13278834521770477
step: 590, loss: 0.3288326859474182
step: 600, loss: 0.11173046380281448
step: 610, loss: 0.05794897675514221
step: 620, loss: 0.04974804446101189
step: 630, loss: 0.0729050412774086
step: 640, loss: 0.038330722600221634
step: 650, loss: 0.20696766674518585
step: 660, loss: 0.09560403972864151
step: 670, loss: 0.21795375645160675
step: 680, loss: 0.12840165197849274
step: 690, loss: 0.09041363000869751
step: 700, loss: 0.09243134409189224
step: 710, loss: 0.14495456218719482
step: 720, loss: 0.13864390552043915
step: 730, loss: 0.16563013195991516
step: 740, loss: 0.061315517872571945
step: 750, loss: 0.13723048567771912
step: 760, loss: 0.10532599687576294
step: 770, loss: 0.22416138648986816
step: 780, loss: 0.048888903111219406
step: 790, loss: 0.20467382669448853
step: 800, loss: 0.1791079044342041
step: 810, loss: 0.08212431520223618
step: 820, loss: 0.1467779576778412
step: 830, loss: 0.05498139187693596
step: 840, loss: 0.142470583319664
step: 850, loss: 0.16121695935726166
step: 860, loss: 0.1048486977815628
step: 870, loss: 0.08831623941659927
step: 880, loss: 0.031814850866794586
step: 890, loss: 0.10447738319635391
step: 900, loss: 0.10104262083768845
step: 910, loss: 0.22388096153736115
step: 920, loss: 0.14440585672855377
step: 930, loss: 0.029397916048765182
step: 940, loss: 0.10214056074619293
step: 950, loss: 0.172800675034523
step: 960, loss: 0.08043639361858368
step: 970, loss: 0.11356008797883987
epoch 4: dev_f1=0.9312839059674503, f1=0.9253731343283582, best_f1=0.9253731343283582
step: 0, loss: 0.022152801975607872
step: 10, loss: 0.06887052208185196
step: 20, loss: 0.06954531371593475
step: 30, loss: 0.09539596736431122
step: 40, loss: 0.0703233927488327
step: 50, loss: 0.1002952978014946
step: 60, loss: 0.09813592582941055
step: 70, loss: 0.054563116282224655
step: 80, loss: 0.16187256574630737
step: 90, loss: 0.12139996141195297
step: 100, loss: 0.07930535823106766
step: 110, loss: 0.03321469575166702
step: 120, loss: 0.14596520364284515
step: 130, loss: 0.12015646696090698
step: 140, loss: 0.13599704205989838
step: 150, loss: 0.13055145740509033
step: 160, loss: 0.14385880529880524
step: 170, loss: 0.15994282066822052
step: 180, loss: 0.11205682903528214
step: 190, loss: 0.06065799668431282
step: 200, loss: 0.12422928214073181
step: 210, loss: 0.08797512203454971
step: 220, loss: 0.022859672084450722
step: 230, loss: 0.12279971688985825
step: 240, loss: 0.06337618082761765
step: 250, loss: 0.09874614328145981
step: 260, loss: 0.04573194682598114
step: 270, loss: 0.14609935879707336
step: 280, loss: 0.04422414302825928
step: 290, loss: 0.012793965637683868
step: 300, loss: 0.10633984953165054
step: 310, loss: 0.17243698239326477
step: 320, loss: 0.06695616990327835
step: 330, loss: 0.1131945252418518
step: 340, loss: 0.10757594555616379
step: 350, loss: 0.10694778710603714
step: 360, loss: 0.13736607134342194
step: 370, loss: 0.13347017765045166
step: 380, loss: 0.006417717318981886
step: 390, loss: 0.06370153278112411
step: 400, loss: 0.027057813480496407
step: 410, loss: 0.12875522673130035
step: 420, loss: 0.07080423831939697
step: 430, loss: 0.050288837403059006
step: 440, loss: 0.0544716976583004
step: 450, loss: 0.008141053840517998
step: 460, loss: 0.07742037624120712
step: 470, loss: 0.11667957156896591
step: 480, loss: 0.09711234271526337
step: 490, loss: 0.12574870884418488
step: 500, loss: 0.18238747119903564
step: 510, loss: 0.18016599118709564
step: 520, loss: 0.08832105994224548
step: 530, loss: 0.10970889031887054
step: 540, loss: 0.12535373866558075
step: 550, loss: 0.07398821413516998
step: 560, loss: 0.1351347267627716
step: 570, loss: 0.10353554040193558
step: 580, loss: 0.08509556204080582
step: 590, loss: 0.08083106577396393
step: 600, loss: 0.16856253147125244
step: 610, loss: 0.05749831348657608
step: 620, loss: 0.06611444056034088
step: 630, loss: 0.10355011373758316
step: 640, loss: 0.12497302889823914
step: 650, loss: 0.09733777493238449
step: 660, loss: 0.1348566710948944
step: 670, loss: 0.11497471481561661
step: 680, loss: 0.09624266624450684
step: 690, loss: 0.1474626362323761
step: 700, loss: 0.13060501217842102
step: 710, loss: 0.19534187018871307
step: 720, loss: 0.19691520929336548
step: 730, loss: 0.15926556289196014
step: 740, loss: 0.11546141654253006
step: 750, loss: 0.11330768465995789
step: 760, loss: 0.012930383905768394
step: 770, loss: 0.08040408045053482
step: 780, loss: 0.1648028939962387
step: 790, loss: 0.18427065014839172
step: 800, loss: 0.10759720951318741
step: 810, loss: 0.14786271750926971
step: 820, loss: 0.08376065641641617
step: 830, loss: 0.11948604136705399
step: 840, loss: 0.10659641027450562
step: 850, loss: 0.2709905207157135
step: 860, loss: 0.03648808225989342
step: 870, loss: 0.11949431151151657
step: 880, loss: 0.07802224904298782
step: 890, loss: 0.1211182102560997
step: 900, loss: 0.05056611821055412
step: 910, loss: 0.0738997682929039
step: 920, loss: 0.09389664232730865
step: 930, loss: 0.35337814688682556
step: 940, loss: 0.11290097236633301
step: 950, loss: 0.03669939562678337
step: 960, loss: 0.28107842803001404
step: 970, loss: 0.09357722848653793
epoch 5: dev_f1=0.9222323879231473, f1=0.9177646524307133, best_f1=0.9253731343283582
step: 0, loss: 0.12886075675487518
step: 10, loss: 0.04699642211198807
step: 20, loss: 0.14174900949001312
step: 30, loss: 0.07473450899124146
step: 40, loss: 0.08295168727636337
step: 50, loss: 0.05480130389332771
step: 60, loss: 0.10761356353759766
step: 70, loss: 0.17005807161331177
step: 80, loss: 0.07747448980808258
step: 90, loss: 0.10038468986749649
step: 100, loss: 0.05820899456739426
step: 110, loss: 0.07659222930669785
step: 120, loss: 0.09236378222703934
step: 130, loss: 0.12299083173274994
step: 140, loss: 0.16660141944885254
step: 150, loss: 0.17025244235992432
step: 160, loss: 0.06857284903526306
step: 170, loss: 0.03507155925035477
step: 180, loss: 0.1966308206319809
step: 190, loss: 0.25432223081588745
step: 200, loss: 0.021578475832939148
step: 210, loss: 0.057498786598443985
step: 220, loss: 0.062450770288705826
step: 230, loss: 0.12700872123241425
step: 240, loss: 0.11865437030792236
step: 250, loss: 0.011906256899237633
step: 260, loss: 0.09059015661478043
step: 270, loss: 0.07731657475233078
step: 280, loss: 0.06026792898774147
step: 290, loss: 0.06233185529708862
step: 300, loss: 0.15971893072128296
step: 310, loss: 0.13799241185188293
step: 320, loss: 0.12045951932668686
step: 330, loss: 0.1387956440448761
step: 340, loss: 0.04409507289528847
step: 350, loss: 0.025921478867530823
step: 360, loss: 0.22937072813510895
step: 370, loss: 0.03179087117314339
step: 380, loss: 0.13601583242416382
step: 390, loss: 0.13430875539779663
step: 400, loss: 0.2803440988063812
step: 410, loss: 0.09850603342056274
step: 420, loss: 0.10040134936571121
step: 430, loss: 0.061522822827100754
step: 440, loss: 0.03206445649266243
step: 450, loss: 0.15902173519134521
step: 460, loss: 0.10174836218357086
step: 470, loss: 0.09372621029615402
step: 480, loss: 0.17693139612674713
step: 490, loss: 0.06898263096809387
step: 500, loss: 0.060155317187309265
step: 510, loss: 0.01049133576452732
step: 520, loss: 0.21399928629398346
step: 530, loss: 0.030542945489287376
step: 540, loss: 0.10966672003269196
step: 550, loss: 0.09882520884275436
step: 560, loss: 0.15722115337848663
step: 570, loss: 0.005829134956002235
step: 580, loss: 0.05605972185730934
step: 590, loss: 0.12680286169052124
step: 600, loss: 0.13178737461566925
step: 610, loss: 0.03641248121857643
step: 620, loss: 0.05140125751495361
step: 630, loss: 0.09444943070411682
step: 640, loss: 0.05932905152440071
step: 650, loss: 0.09737880527973175
step: 660, loss: 0.13472767174243927
step: 670, loss: 0.1917462795972824
step: 680, loss: 0.05206351727247238
step: 690, loss: 0.04801618307828903
step: 700, loss: 0.10442151129245758
step: 710, loss: 0.1653577983379364
step: 720, loss: 0.063933365046978
step: 730, loss: 0.11383793503046036
step: 740, loss: 0.2711547911167145
step: 750, loss: 0.2516845166683197
step: 760, loss: 0.2608712911605835
step: 770, loss: 0.1383589804172516
step: 780, loss: 0.07065615057945251
step: 790, loss: 0.06517919152975082
step: 800, loss: 0.09150689095258713
step: 810, loss: 0.07492109388113022
step: 820, loss: 0.11952318251132965
step: 830, loss: 0.1460474729537964
step: 840, loss: 0.1465090662240982
step: 850, loss: 0.08426756411790848
step: 860, loss: 0.08243373036384583
step: 870, loss: 0.09473428875207901
step: 880, loss: 0.06255803257226944
step: 890, loss: 0.03973658010363579
step: 900, loss: 0.059607382863759995
step: 910, loss: 0.04231375455856323
step: 920, loss: 0.11718838661909103
step: 930, loss: 0.14893613755702972
step: 940, loss: 0.06483489274978638
step: 950, loss: 0.08614486455917358
step: 960, loss: 0.05037188529968262
step: 970, loss: 0.13179440796375275
epoch 6: dev_f1=0.9233644859813084, f1=0.9247211895910781, best_f1=0.9253731343283582
step: 0, loss: 0.07800590991973877
step: 10, loss: 0.10692193359136581
step: 20, loss: 0.1129106879234314
step: 30, loss: 0.03121328167617321
step: 40, loss: 0.10374806821346283
step: 50, loss: 0.10360938310623169
step: 60, loss: 0.06841979175806046
step: 70, loss: 0.1046542301774025
step: 80, loss: 0.20221251249313354
step: 90, loss: 0.07208222150802612
step: 100, loss: 0.1511804461479187
step: 110, loss: 0.06389003992080688
step: 120, loss: 0.21158035099506378
step: 130, loss: 0.03447406366467476
step: 140, loss: 0.009463949128985405
step: 150, loss: 0.028117384761571884
step: 160, loss: 0.07476009428501129
step: 170, loss: 0.1411721557378769
step: 180, loss: 0.026161285117268562
step: 190, loss: 0.06620141863822937
step: 200, loss: 0.07100196182727814
step: 210, loss: 0.07464168220758438
step: 220, loss: 0.03395075723528862
step: 230, loss: 0.0488424226641655
step: 240, loss: 0.21348434686660767
step: 250, loss: 0.11649320274591446
step: 260, loss: 0.03762052580714226
step: 270, loss: 0.07114903628826141
step: 280, loss: 0.04268750548362732
step: 290, loss: 0.009762022644281387
step: 300, loss: 0.07774748653173447
step: 310, loss: 0.0753343477845192
step: 320, loss: 0.1412811130285263
step: 330, loss: 0.0418262779712677
step: 340, loss: 0.0745314359664917
step: 350, loss: 0.018350400030612946
step: 360, loss: 0.006342211738228798
step: 370, loss: 0.06410246342420578
step: 380, loss: 0.16846336424350739
step: 390, loss: 0.02920948900282383
step: 400, loss: 0.08416793495416641
step: 410, loss: 0.04840242862701416
step: 420, loss: 0.06088770180940628
step: 430, loss: 0.1163095235824585
step: 440, loss: 0.19928652048110962
step: 450, loss: 0.12453889846801758
step: 460, loss: 0.03193690627813339
step: 470, loss: 0.11016783118247986
step: 480, loss: 0.08211925625801086
step: 490, loss: 0.012724223546683788
step: 500, loss: 0.01457057986408472
step: 510, loss: 0.061987392604351044
step: 520, loss: 0.04375389963388443
step: 530, loss: 0.1227424219250679
step: 540, loss: 0.05816185101866722
step: 550, loss: 0.1320217400789261
step: 560, loss: 0.11914614588022232
step: 570, loss: 0.10148534178733826
step: 580, loss: 0.10804261267185211
step: 590, loss: 0.07038290053606033
step: 600, loss: 0.08036328852176666
step: 610, loss: 0.05738828331232071
step: 620, loss: 0.03126034140586853
step: 630, loss: 0.1631172150373459
step: 640, loss: 0.09305494278669357
step: 650, loss: 0.10645566135644913
step: 660, loss: 0.12087632715702057
step: 670, loss: 0.10416269302368164
step: 680, loss: 0.13464109599590302
step: 690, loss: 0.19404590129852295
step: 700, loss: 0.07333363592624664
step: 710, loss: 0.10702020674943924
step: 720, loss: 0.22858940064907074
step: 730, loss: 0.09866854548454285
step: 740, loss: 0.05802830308675766
step: 750, loss: 0.06200818717479706
step: 760, loss: 0.08320310711860657
step: 770, loss: 0.13668648898601532
step: 780, loss: 0.05572698637843132
step: 790, loss: 0.04874679446220398
step: 800, loss: 0.18978002667427063
step: 810, loss: 0.1392546147108078
step: 820, loss: 0.15231284499168396
step: 830, loss: 0.0795794352889061
step: 840, loss: 0.037294719368219376
step: 850, loss: 0.04896098002791405
step: 860, loss: 0.09947703778743744
step: 870, loss: 0.05275348201394081
step: 880, loss: 0.031231895089149475
step: 890, loss: 0.2017107456922531
step: 900, loss: 0.19188250601291656
step: 910, loss: 0.17365895211696625
step: 920, loss: 0.05302070826292038
step: 930, loss: 0.0972980335354805
step: 940, loss: 0.109178826212883
step: 950, loss: 0.12386393547058105
step: 960, loss: 0.016635851934552193
step: 970, loss: 0.0966838151216507
epoch 7: dev_f1=0.9293954776188279, f1=0.9313047487321346, best_f1=0.9253731343283582
step: 0, loss: 0.18166576325893402
step: 10, loss: 0.09478531032800674
step: 20, loss: 0.03250475227832794
step: 30, loss: 0.03462696075439453
step: 40, loss: 0.08933097124099731
step: 50, loss: 0.07511227577924728
step: 60, loss: 0.062212325632572174
step: 70, loss: 0.08378178626298904
step: 80, loss: 0.032951705157756805
step: 90, loss: 0.03693430498242378
step: 100, loss: 0.05878983438014984
step: 110, loss: 0.018099820241332054
step: 120, loss: 0.18843364715576172
step: 130, loss: 0.044323671609163284
step: 140, loss: 0.031182631850242615
step: 150, loss: 0.10422922670841217
step: 160, loss: 0.13046236336231232
step: 170, loss: 0.06786094605922699
step: 180, loss: 0.036771442741155624
step: 190, loss: 0.06941522657871246
step: 200, loss: 0.034844834357500076
step: 210, loss: 0.09281133115291595
step: 220, loss: 0.02967999130487442
step: 230, loss: 0.13029807806015015
step: 240, loss: 0.08297273516654968
step: 250, loss: 0.08974874764680862
step: 260, loss: 0.17887409031391144
step: 270, loss: 0.14438782632350922
step: 280, loss: 0.07437968254089355
step: 290, loss: 0.07467259466648102
step: 300, loss: 0.04077352583408356
step: 310, loss: 0.07823073863983154
step: 320, loss: 0.08256853371858597
step: 330, loss: 0.09945009648799896
step: 340, loss: 0.07095111906528473
step: 350, loss: 0.12766118347644806
step: 360, loss: 0.08702660351991653
step: 370, loss: 0.11577951908111572
step: 380, loss: 0.07222466170787811
step: 390, loss: 0.006383456289768219
step: 400, loss: 0.08896921575069427
step: 410, loss: 0.09324543178081512
step: 420, loss: 0.004408156964927912
step: 430, loss: 0.01986251398921013
step: 440, loss: 0.172684445977211
step: 450, loss: 0.025994354858994484
step: 460, loss: 0.08693443238735199
step: 470, loss: 0.21070826053619385
step: 480, loss: 0.05035706236958504
step: 490, loss: 0.056860391050577164
step: 500, loss: 0.09896507114171982
step: 510, loss: 0.10495657473802567
step: 520, loss: 0.04317130148410797
step: 530, loss: 0.012284791097044945
step: 540, loss: 0.11746645718812943
step: 550, loss: 0.08479191362857819
step: 560, loss: 0.03924160823225975
step: 570, loss: 0.1894260048866272
step: 580, loss: 0.04552873969078064
step: 590, loss: 0.02075231820344925
step: 600, loss: 0.14092867076396942
step: 610, loss: 0.05983664467930794
step: 620, loss: 0.047994233667850494
step: 630, loss: 0.3726824223995209
step: 640, loss: 0.06786003708839417
step: 650, loss: 0.09186550974845886
step: 660, loss: 0.009735268540680408
step: 670, loss: 0.13491564989089966
step: 680, loss: 0.049474380910396576
step: 690, loss: 0.08306509256362915
step: 700, loss: 0.07644140720367432
step: 710, loss: 0.17932328581809998
step: 720, loss: 0.14286570250988007
step: 730, loss: 0.005066620651632547
step: 740, loss: 0.09068965911865234
step: 750, loss: 0.08016494661569595
step: 760, loss: 0.0006061895401217043
step: 770, loss: 0.02990994043648243
step: 780, loss: 0.06248481571674347
step: 790, loss: 0.07150091230869293
step: 800, loss: 0.0554969497025013
step: 810, loss: 0.14713776111602783
step: 820, loss: 0.0066101741977036
step: 830, loss: 0.11575379222631454
step: 840, loss: 0.042056456208229065
step: 850, loss: 0.11814400553703308
step: 860, loss: 0.16316787898540497
step: 870, loss: 0.04824461042881012
step: 880, loss: 0.25591549277305603
step: 890, loss: 0.04202497750520706
step: 900, loss: 0.10371142625808716
step: 910, loss: 0.041269805282354355
step: 920, loss: 0.11956319957971573
step: 930, loss: 0.08998638391494751
step: 940, loss: 0.05510503053665161
step: 950, loss: 0.08942142128944397
step: 960, loss: 0.11958532780408859
step: 970, loss: 0.12160153687000275
epoch 8: dev_f1=0.9341923607915326, f1=0.9256880733944954, best_f1=0.9256880733944954
step: 0, loss: 0.0696474239230156
step: 10, loss: 0.13163001835346222
step: 20, loss: 0.11056048423051834
step: 30, loss: 0.07259990274906158
step: 40, loss: 0.049356505274772644
step: 50, loss: 0.09810813516378403
step: 60, loss: 0.08894357830286026
step: 70, loss: 0.02196701057255268
step: 80, loss: 0.02667735144495964
step: 90, loss: 0.10037384182214737
step: 100, loss: 0.10816550999879837
step: 110, loss: 0.12069503217935562
step: 120, loss: 0.12018293887376785
step: 130, loss: 0.02358776144683361
step: 140, loss: 0.0657554343342781
step: 150, loss: 0.0216023251414299
step: 160, loss: 0.040500860661268234
step: 170, loss: 0.08595330268144608
step: 180, loss: 0.09366291016340256
step: 190, loss: 0.0826653316617012
step: 200, loss: 0.04161928966641426
step: 210, loss: 0.12467573583126068
step: 220, loss: 0.13787797093391418
step: 230, loss: 0.06264370679855347
step: 240, loss: 0.1209031343460083
step: 250, loss: 0.0035436360631138086
step: 260, loss: 0.059672724455595016
step: 270, loss: 0.07969830185174942
step: 280, loss: 0.09028558433055878
step: 290, loss: 0.06388691067695618
step: 300, loss: 0.06460364907979965
step: 310, loss: 0.05154424160718918
step: 320, loss: 0.09666069597005844
step: 330, loss: 0.036523159593343735
step: 340, loss: 0.22907038033008575
step: 350, loss: 0.10025181621313095
step: 360, loss: 0.07544321566820145
step: 370, loss: 0.05548467859625816
step: 380, loss: 0.06499287486076355
step: 390, loss: 0.10642923414707184
step: 400, loss: 0.10686026513576508
step: 410, loss: 0.04257985204458237
step: 420, loss: 0.07064750045537949
step: 430, loss: 0.08840106427669525
step: 440, loss: 0.02380247414112091
step: 450, loss: 0.029243916273117065
step: 460, loss: 0.22096134722232819
step: 470, loss: 0.11903636157512665
step: 480, loss: 0.08922692388296127
step: 490, loss: 0.09906088560819626
step: 500, loss: 0.18945007026195526
step: 510, loss: 0.10836854577064514
step: 520, loss: 0.03716374933719635
step: 530, loss: 0.04776182770729065
step: 540, loss: 0.09849100559949875
step: 550, loss: 0.0729404017329216
step: 560, loss: 0.06361140310764313
step: 570, loss: 0.054538652300834656
step: 580, loss: 0.07541320472955704
step: 590, loss: 0.04438239708542824
step: 600, loss: 0.05885893851518631
step: 610, loss: 0.07789468765258789
step: 620, loss: 0.14756256341934204
step: 630, loss: 0.1834731251001358
step: 640, loss: 0.07353506237268448
step: 650, loss: 0.0696106031537056
step: 660, loss: 0.08578259497880936
step: 670, loss: 0.09139841794967651
step: 680, loss: 0.042553044855594635
step: 690, loss: 0.08314331620931625
step: 700, loss: 0.14112746715545654
step: 710, loss: 0.040958233177661896
step: 720, loss: 0.05901128426194191
step: 730, loss: 0.12819021940231323
step: 740, loss: 0.10795494168996811
step: 750, loss: 0.057455651462078094
step: 760, loss: 0.10261928290128708
step: 770, loss: 0.09251698851585388
step: 780, loss: 0.16311366856098175
step: 790, loss: 0.046633001416921616
step: 800, loss: 0.1592222899198532
step: 810, loss: 0.165410116314888
step: 820, loss: 0.07092787325382233
step: 830, loss: 0.09247470647096634
step: 840, loss: 0.10976523160934448
step: 850, loss: 0.01387525163590908
step: 860, loss: 0.0013412048574537039
step: 870, loss: 0.017649993300437927
step: 880, loss: 0.005620979703962803
step: 890, loss: 0.28693777322769165
step: 900, loss: 0.0569196417927742
step: 910, loss: 0.07535847276449203
step: 920, loss: 0.05128082260489464
step: 930, loss: 0.10042598098516464
step: 940, loss: 0.06645570695400238
step: 950, loss: 0.10429476201534271
step: 960, loss: 0.037734828889369965
step: 970, loss: 0.04278874397277832
epoch 9: dev_f1=0.9245810055865922, f1=0.9237170596393898, best_f1=0.9256880733944954
step: 0, loss: 0.08881647139787674
step: 10, loss: 0.04991792142391205
step: 20, loss: 0.026810213923454285
step: 30, loss: 0.21245041489601135
step: 40, loss: 0.06210417300462723
step: 50, loss: 0.0827215164899826
step: 60, loss: 0.04365726560354233
step: 70, loss: 0.126485213637352
step: 80, loss: 0.13290664553642273
step: 90, loss: 0.007598701864480972
step: 100, loss: 0.09534095227718353
step: 110, loss: 0.044187791645526886
step: 120, loss: 0.0815592110157013
step: 130, loss: 1.4830264262855053e-05
step: 140, loss: 0.10994452238082886
step: 150, loss: 0.010399319231510162
step: 160, loss: 0.07040844857692719
step: 170, loss: 0.08852728456258774
step: 180, loss: 0.12684276700019836
step: 190, loss: 0.08174090087413788
step: 200, loss: 0.12847690284252167
step: 210, loss: 0.02489347942173481
step: 220, loss: 0.0362015962600708
step: 230, loss: 0.07462696731090546
step: 240, loss: 0.04688723012804985
step: 250, loss: 0.018835071474313736
step: 260, loss: 0.043577421456575394
step: 270, loss: 0.06038080155849457
step: 280, loss: 0.09414194524288177
step: 290, loss: 0.12346664816141129
step: 300, loss: 0.06485483795404434
step: 310, loss: 0.06458571553230286
step: 320, loss: 0.17008252441883087
step: 330, loss: 0.12747325003147125
step: 340, loss: 0.0524677149951458
step: 350, loss: 0.11218629032373428
step: 360, loss: 0.11445856094360352
step: 370, loss: 0.1000983864068985
step: 380, loss: 0.07607800513505936
step: 390, loss: 0.03152148425579071
step: 400, loss: 0.03516994044184685
step: 410, loss: 0.07219619303941727
step: 420, loss: 0.1768563687801361
step: 430, loss: 0.12985245883464813
step: 440, loss: 0.11663062125444412
step: 450, loss: 0.2423277348279953
step: 460, loss: 0.08405767381191254
step: 470, loss: 0.027836881577968597
step: 480, loss: 0.06262548267841339
step: 490, loss: 0.027051806449890137
step: 500, loss: 0.20874488353729248
step: 510, loss: 0.008091204799711704
step: 520, loss: 0.14920476078987122
step: 530, loss: 0.14121802151203156
step: 540, loss: 0.08123666793107986
step: 550, loss: 0.0748475044965744
step: 560, loss: 0.05199171602725983
step: 570, loss: 0.141421377658844
step: 580, loss: 0.04172021523118019
step: 590, loss: 0.018361886963248253
step: 600, loss: 0.0030559725128114223
step: 610, loss: 0.08789296448230743
step: 620, loss: 0.02776075154542923
step: 630, loss: 0.050681959837675095
step: 640, loss: 0.031622208654880524
step: 650, loss: 0.04248276352882385
step: 660, loss: 0.07976353168487549
step: 670, loss: 0.11436931788921356
step: 680, loss: 0.07930430769920349
step: 690, loss: 0.2023618221282959
step: 700, loss: 0.08279784768819809
step: 710, loss: 0.03817189112305641
step: 720, loss: 0.04508352652192116
step: 730, loss: 0.16607892513275146
step: 740, loss: 0.08569014817476273
step: 750, loss: 0.04394951090216637
step: 760, loss: 0.11710876226425171
step: 770, loss: 0.08858557045459747
step: 780, loss: 0.042452577501535416
step: 790, loss: 0.06681466102600098
step: 800, loss: 0.031329650431871414
step: 810, loss: 0.02422890067100525
step: 820, loss: 0.12031394243240356
step: 830, loss: 0.051678404211997986
step: 840, loss: 0.13851553201675415
step: 850, loss: 0.06704872846603394
step: 860, loss: 0.12246518582105637
step: 870, loss: 0.09610702097415924
step: 880, loss: 0.14427578449249268
step: 890, loss: 0.22819063067436218
step: 900, loss: 0.06688432395458221
step: 910, loss: 0.14565607905387878
step: 920, loss: 0.08627909421920776
step: 930, loss: 0.12140613794326782
step: 940, loss: 0.0667186826467514
step: 950, loss: 0.055681318044662476
step: 960, loss: 0.012654358521103859
step: 970, loss: 0.13591469824314117
epoch 10: dev_f1=0.9305816135084428, f1=0.9245194561650257, best_f1=0.9256880733944954
step: 0, loss: 0.010429113171994686
step: 10, loss: 0.16525898873806
step: 20, loss: 0.021123334765434265
step: 30, loss: 0.10587794333696365
step: 40, loss: 0.06267154961824417
step: 50, loss: 0.006173946429044008
step: 60, loss: 0.004269552882760763
step: 70, loss: 0.03665042296051979
step: 80, loss: 0.056987106800079346
step: 90, loss: 0.013013255782425404
step: 100, loss: 0.08963315188884735
step: 110, loss: 0.04010291397571564
step: 120, loss: 0.00918127316981554
step: 130, loss: 0.14635470509529114
step: 140, loss: 0.03503499552607536
step: 150, loss: 0.0436704196035862
step: 160, loss: 0.06499836593866348
step: 170, loss: 0.11958178877830505
step: 180, loss: 0.012177828699350357
step: 190, loss: 0.04787926375865936
step: 200, loss: 0.03891311585903168
step: 210, loss: 0.12837722897529602
step: 220, loss: 0.052187979221343994
step: 230, loss: 0.07367449998855591
step: 240, loss: 0.03563464432954788
step: 250, loss: 0.10277024656534195
step: 260, loss: 0.06659716367721558
step: 270, loss: 0.02653311751782894
step: 280, loss: 0.03587685152888298
step: 290, loss: 0.11233741790056229
step: 300, loss: 0.11599216610193253
step: 310, loss: 0.06263236701488495
step: 320, loss: 0.016929082572460175
step: 330, loss: 0.08436836302280426
step: 340, loss: 0.11114713549613953
step: 350, loss: 0.07093282043933868
step: 360, loss: 0.06375610828399658
step: 370, loss: 0.0662299320101738
step: 380, loss: 0.029985226690769196
step: 390, loss: 0.06327728927135468
step: 400, loss: 0.1372634470462799
step: 410, loss: 0.05091196671128273
step: 420, loss: 0.00205294881016016
step: 430, loss: 0.14912180602550507
step: 440, loss: 0.08286648243665695
step: 450, loss: 0.01997007429599762
step: 460, loss: 0.14004379510879517
step: 470, loss: 0.08694149553775787
step: 480, loss: 0.06477772444486618
step: 490, loss: 0.0149620296433568
step: 500, loss: 0.12388473749160767
step: 510, loss: 0.03936762362718582
step: 520, loss: 0.01922471635043621
step: 530, loss: 0.03383459523320198
step: 540, loss: 0.01656145043671131
step: 550, loss: 0.03397756442427635
step: 560, loss: 0.12357078492641449
step: 570, loss: 0.08706187456846237
step: 580, loss: 0.0502106249332428
step: 590, loss: 0.1651591956615448
step: 600, loss: 0.06019488349556923
step: 610, loss: 0.08188463747501373
step: 620, loss: 0.09351902455091476
step: 630, loss: 0.02740168757736683
step: 640, loss: 0.06953877210617065
step: 650, loss: 0.046717897057533264
step: 660, loss: 0.14137104153633118
step: 670, loss: 0.0871928259730339
step: 680, loss: 0.08226907253265381
step: 690, loss: 0.06324192881584167
step: 700, loss: 0.0554116927087307
step: 710, loss: 0.02092953398823738
step: 720, loss: 0.15149495005607605
step: 730, loss: 0.05217374116182327
step: 740, loss: 0.066667839884758
step: 750, loss: 0.019769463688135147
step: 760, loss: 0.006542798597365618
step: 770, loss: 0.06440688669681549
step: 780, loss: 0.11777769774198532
step: 790, loss: 0.04156230762600899
step: 800, loss: 0.1533171832561493
step: 810, loss: 0.08405386656522751
step: 820, loss: 0.10933901369571686
step: 830, loss: 0.08059358596801758
step: 840, loss: 0.1560601145029068
step: 850, loss: 0.04770291969180107
step: 860, loss: 0.07594966888427734
step: 870, loss: 0.16984611749649048
step: 880, loss: 0.09168867766857147
step: 890, loss: 0.1723850816488266
step: 900, loss: 0.027992311865091324
step: 910, loss: 0.12295897305011749
step: 920, loss: 0.07780145853757858
step: 930, loss: 0.06133619323372841
step: 940, loss: 0.08670715987682343
step: 950, loss: 0.06536518782377243
step: 960, loss: 0.16773197054862976
step: 970, loss: 0.07491815835237503
epoch 11: dev_f1=0.9280074314909429, f1=0.9222941720629046, best_f1=0.9256880733944954
step: 0, loss: 0.0639113336801529
step: 10, loss: 0.005361650139093399
step: 20, loss: 0.04343544319272041
step: 30, loss: 0.028807343915104866
step: 40, loss: 0.031064637005329132
step: 50, loss: 0.07216048985719681
step: 60, loss: 0.02700180374085903
step: 70, loss: 0.07898615300655365
step: 80, loss: 0.13046039640903473
step: 90, loss: 0.034515369683504105
step: 100, loss: 0.0003507802030071616
step: 110, loss: 0.025357017293572426
step: 120, loss: 0.011343966238200665
step: 130, loss: 0.07435445487499237
step: 140, loss: 0.0847758948802948
step: 150, loss: 0.003249922301620245
step: 160, loss: 0.07077330350875854
step: 170, loss: 0.03729494661092758
step: 180, loss: 0.06890889257192612
step: 190, loss: 0.06753037124872208
step: 200, loss: 0.11015807837247849
step: 210, loss: 0.09366785734891891
step: 220, loss: 0.048622556030750275
step: 230, loss: 0.09298068284988403
step: 240, loss: 0.003312074113637209
step: 250, loss: 0.020568083971738815
step: 260, loss: 0.08217665553092957
step: 270, loss: 0.08721837401390076
step: 280, loss: 0.021992061287164688
step: 290, loss: 0.04294545203447342
step: 300, loss: 0.02580040693283081
step: 310, loss: 0.03882791846990585
step: 320, loss: 0.04082653671503067
step: 330, loss: 0.23026642203330994
step: 340, loss: 0.02197634056210518
step: 350, loss: 0.10789287090301514
step: 360, loss: 0.022969333454966545
step: 370, loss: 0.06192956864833832
step: 380, loss: 0.0321720726788044
step: 390, loss: 0.09864682704210281
step: 400, loss: 0.10078750550746918
step: 410, loss: 0.09384316205978394
step: 420, loss: 0.1506609320640564
step: 430, loss: 0.08333106338977814
step: 440, loss: 0.05092040076851845
step: 450, loss: 0.05854563042521477
step: 460, loss: 0.09338585287332535
step: 470, loss: 0.16918398439884186
step: 480, loss: 0.030843989923596382
step: 490, loss: 0.05003286898136139
step: 500, loss: 0.01631682738661766
step: 510, loss: 0.0692611113190651
step: 520, loss: 0.03181014955043793
step: 530, loss: 0.08960141241550446
step: 540, loss: 0.09123999625444412
step: 550, loss: 0.03283427283167839
step: 560, loss: 0.12129627168178558
step: 570, loss: 0.056280821561813354
step: 580, loss: 0.007670922204852104
step: 590, loss: 0.0619884729385376
step: 600, loss: 0.05230380967259407
step: 610, loss: 0.03762028366327286
step: 620, loss: 0.012585442513227463
step: 630, loss: 0.14839470386505127
step: 640, loss: 0.07887879759073257
step: 650, loss: 0.2426498383283615
step: 660, loss: 0.12121802568435669
step: 670, loss: 0.0668027400970459
step: 680, loss: 0.15629877150058746
step: 690, loss: 0.07632352411746979
step: 700, loss: 0.03306638449430466
step: 710, loss: 0.07279683649539948
step: 720, loss: 0.06257768720388412
step: 730, loss: 0.12118112295866013
step: 740, loss: 0.030637230724096298
step: 750, loss: 0.035323165357112885
step: 760, loss: 0.17528758943080902
step: 770, loss: 0.03891577199101448
step: 780, loss: 0.0907425656914711
step: 790, loss: 0.015806324779987335
step: 800, loss: 0.1830156296491623
step: 810, loss: 0.08428559452295303
step: 820, loss: 0.04545046016573906
step: 830, loss: 0.08055467903614044
step: 840, loss: 0.020589597523212433
step: 850, loss: 0.23029395937919617
step: 860, loss: 0.13948795199394226
step: 870, loss: 0.04387214779853821
step: 880, loss: 0.12692053616046906
step: 890, loss: 0.021367933601140976
step: 900, loss: 0.026663977652788162
step: 910, loss: 0.028364378958940506
step: 920, loss: 0.11884332448244095
step: 930, loss: 0.0002359206700930372
step: 940, loss: 0.007901196368038654
step: 950, loss: 0.08337344229221344
step: 960, loss: 0.10041170567274094
step: 970, loss: 0.060832101851701736
epoch 12: dev_f1=0.9226388229710489, f1=0.9166666666666666, best_f1=0.9256880733944954
step: 0, loss: 0.10078316926956177
step: 10, loss: 0.03715815395116806
step: 20, loss: 0.17048272490501404
step: 30, loss: 0.0905989408493042
step: 40, loss: 0.060663312673568726
step: 50, loss: 0.09376290440559387
step: 60, loss: 0.14645898342132568
step: 70, loss: 0.07051192969083786
step: 80, loss: 0.06683492660522461
step: 90, loss: 0.06072462350130081
step: 100, loss: 0.04826470464468002
step: 110, loss: 0.043616682291030884
step: 120, loss: 0.04122667759656906
step: 130, loss: 0.10491916537284851
step: 140, loss: 0.07138479501008987
step: 150, loss: 0.05880510061979294
step: 160, loss: 0.015180614776909351
step: 170, loss: 0.0016483450308442116
step: 180, loss: 0.1271587759256363
step: 190, loss: 0.01800411380827427
step: 200, loss: 0.14949190616607666
step: 210, loss: 0.0512462742626667
step: 220, loss: 0.048324670642614365
step: 230, loss: 0.04873264953494072
step: 240, loss: 0.060855913907289505
step: 250, loss: 0.022878967225551605
step: 260, loss: 0.012746384367346764
step: 270, loss: 0.05941283702850342
step: 280, loss: 0.1334953010082245
step: 290, loss: 0.08405247330665588
step: 300, loss: 0.02715332806110382
step: 310, loss: 0.04654845595359802
step: 320, loss: 0.10393526405096054
step: 330, loss: 0.20957869291305542
step: 340, loss: 0.010914837941527367
step: 350, loss: 0.05815913528203964
step: 360, loss: 0.026641033589839935
step: 370, loss: 0.10072031617164612
step: 380, loss: 0.01901964098215103
step: 390, loss: 0.08970481902360916
step: 400, loss: 0.08377805352210999
step: 410, loss: 0.013254362158477306
step: 420, loss: 0.053980156779289246
step: 430, loss: 0.05942618101835251
step: 440, loss: 0.06077620014548302
step: 450, loss: 0.06879236549139023
step: 460, loss: 0.19780702888965607
step: 470, loss: 0.0524614080786705
step: 480, loss: 0.01453973539173603
step: 490, loss: 0.03557221591472626
step: 500, loss: 0.1123855859041214
step: 510, loss: 0.07153142988681793
step: 520, loss: 0.05329085513949394
step: 530, loss: 0.04934259131550789
step: 540, loss: 0.04318388178944588
step: 550, loss: 0.023216869682073593
step: 560, loss: 0.06334754824638367
step: 570, loss: 0.24295224249362946
step: 580, loss: 0.03064509481191635
step: 590, loss: 0.04325287789106369
step: 600, loss: 0.0803830698132515
step: 610, loss: 0.15039482712745667
step: 620, loss: 0.07130574434995651
step: 630, loss: 0.009454007260501385
step: 640, loss: 0.021736446768045425
step: 650, loss: 0.07076546549797058
step: 660, loss: 0.043698750436306
step: 670, loss: 0.027201397344470024
step: 680, loss: 0.030511880293488503
step: 690, loss: 0.055918239057064056
step: 700, loss: 0.0738910585641861
step: 710, loss: 0.03881605342030525
step: 720, loss: 0.0630524680018425
step: 730, loss: 0.0330369658768177
step: 740, loss: 0.07974480092525482
step: 750, loss: 0.011953326873481274
step: 760, loss: 0.012445473112165928
step: 770, loss: 0.05853929743170738
step: 780, loss: 0.07965365052223206
step: 790, loss: 0.06170595437288284
step: 800, loss: 0.11037339270114899
step: 810, loss: 0.023177320137619972
step: 820, loss: 0.12609748542308807
step: 830, loss: 0.09569946676492691
step: 840, loss: 0.10524605959653854
step: 850, loss: 0.023064760491251945
step: 860, loss: 0.07850463688373566
step: 870, loss: 0.10048425197601318
step: 880, loss: 0.11976824700832367
step: 890, loss: 0.12462504953145981
step: 900, loss: 0.11228356510400772
step: 910, loss: 0.09064701199531555
step: 920, loss: 0.06429357081651688
step: 930, loss: 0.09858418256044388
step: 940, loss: 0.027930259704589844
step: 950, loss: 0.03132437914609909
step: 960, loss: 0.1070159301161766
step: 970, loss: 0.018362903967499733
epoch 13: dev_f1=0.9259962049335864, f1=0.9261176470588235, best_f1=0.9256880733944954
step: 0, loss: 0.060663431882858276
step: 10, loss: 0.13154934346675873
step: 20, loss: 0.06139041483402252
step: 30, loss: 0.030402906239032745
step: 40, loss: 0.0004959214711561799
step: 50, loss: 0.032960839569568634
step: 60, loss: 0.04526666924357414
step: 70, loss: 0.15935392677783966
step: 80, loss: 0.06732761114835739
step: 90, loss: 0.046151865273714066
step: 100, loss: 0.040827471762895584
step: 110, loss: 0.005548929329961538
step: 120, loss: 0.07610363513231277
step: 130, loss: 0.14004471898078918
step: 140, loss: 0.004877009429037571
step: 150, loss: 0.124935083091259
step: 160, loss: 0.015208294615149498
step: 170, loss: 0.07987994700670242
step: 180, loss: 0.09851372241973877
step: 190, loss: 0.045196179300546646
step: 200, loss: 0.03622869402170181
step: 210, loss: 0.14752666652202606
step: 220, loss: 0.12324976176023483
step: 230, loss: 0.13854952156543732
step: 240, loss: 0.06981369107961655
step: 250, loss: 0.07634907215833664
step: 260, loss: 0.033805906772613525
step: 270, loss: 0.06405261158943176
step: 280, loss: 0.03532874584197998
step: 290, loss: 0.05104202777147293
step: 300, loss: 8.16480751382187e-05
step: 310, loss: 0.06859889626502991
step: 320, loss: 0.05961664393544197
step: 330, loss: 0.02995171770453453
step: 340, loss: 0.038495223969221115
step: 350, loss: 0.10325045883655548
step: 360, loss: 0.08749242126941681
step: 370, loss: 0.06156535819172859
step: 380, loss: 0.041029199957847595
step: 390, loss: 0.016104182228446007
step: 400, loss: 0.04337044060230255
step: 410, loss: 0.0629403293132782
step: 420, loss: 0.08845580369234085
step: 430, loss: 0.08655548840761185
step: 440, loss: 0.047259073704481125
step: 450, loss: 0.03856351971626282
step: 460, loss: 0.0372253842651844
step: 470, loss: 0.0681118369102478
step: 480, loss: 0.07408779114484787
step: 490, loss: 0.03504392132163048
step: 500, loss: 0.057560209184885025
step: 510, loss: 0.08097797632217407
step: 520, loss: 0.08939406275749207
step: 530, loss: 0.0013654495123773813
step: 540, loss: 0.10139765590429306
step: 550, loss: 0.028757579624652863
step: 560, loss: 0.0360327810049057
step: 570, loss: 0.08837556093931198
step: 580, loss: 0.02352914586663246
step: 590, loss: 0.013049290515482426
step: 600, loss: 0.04354504495859146
step: 610, loss: 0.03202170506119728
step: 620, loss: 0.06486906856298447
step: 630, loss: 0.06611399352550507
step: 640, loss: 0.2515777349472046
step: 650, loss: 0.06005917116999626
step: 660, loss: 0.11588087677955627
step: 670, loss: 0.04684777557849884
step: 680, loss: 0.07551396638154984
step: 690, loss: 0.07566939294338226
step: 700, loss: 0.02948773093521595
step: 710, loss: 0.06966798007488251
step: 720, loss: 0.049819014966487885
step: 730, loss: 0.02254258655011654
step: 740, loss: 0.016224492341279984
step: 750, loss: 0.0678570494055748
step: 760, loss: 0.03908201679587364
step: 770, loss: 0.035033877938985825
step: 780, loss: 0.027054503560066223
step: 790, loss: 0.04088869318366051
step: 800, loss: 0.07898104190826416
step: 810, loss: 0.032626379281282425
step: 820, loss: 0.08292245119810104
step: 830, loss: 0.010138608515262604
step: 840, loss: 0.04597374051809311
step: 850, loss: 0.04958556219935417
step: 860, loss: 0.07408475130796432
step: 870, loss: 0.04933957755565643
step: 880, loss: 0.03730538859963417
step: 890, loss: 0.04436391219496727
step: 900, loss: 0.042463213205337524
step: 910, loss: 0.045876532793045044
step: 920, loss: 0.04051537811756134
step: 930, loss: 0.06477052718400955
step: 940, loss: 0.03432130441069603
step: 950, loss: 0.04145052656531334
step: 960, loss: 0.06745243817567825
step: 970, loss: 0.032777756452560425
epoch 14: dev_f1=0.9278445883441258, f1=0.9242843951985227, best_f1=0.9256880733944954
step: 0, loss: 0.03831419721245766
step: 10, loss: 0.029746482148766518
step: 20, loss: 0.12026593834161758
step: 30, loss: 0.03726290166378021
step: 40, loss: 0.07017043232917786
step: 50, loss: 0.027562923729419708
step: 60, loss: 0.018614407628774643
step: 70, loss: 0.02776571549475193
step: 80, loss: 0.016998616978526115
step: 90, loss: 0.012509657070040703
step: 100, loss: 0.0769905224442482
step: 110, loss: 0.014627794735133648
step: 120, loss: 0.05820181593298912
step: 130, loss: 0.00033298731432296336
step: 140, loss: 0.05172248184680939
step: 150, loss: 0.04954231530427933
step: 160, loss: 0.03269222378730774
step: 170, loss: 0.0637870579957962
step: 180, loss: 0.05585920438170433
step: 190, loss: 0.1315566599369049
step: 200, loss: 0.04626359045505524
step: 210, loss: 0.0075392345897853374
step: 220, loss: 0.011745661497116089
step: 230, loss: 0.04544937238097191
step: 240, loss: 0.06996745616197586
step: 250, loss: 0.07370399683713913
step: 260, loss: 0.03711690008640289
step: 270, loss: 0.10102558135986328
step: 280, loss: 0.015178793109953403
step: 290, loss: 0.02215658873319626
step: 300, loss: 0.07577033340930939
step: 310, loss: 0.05874020606279373
step: 320, loss: 0.07650097459554672
step: 330, loss: 0.07385613024234772
step: 340, loss: 0.03951526805758476
step: 350, loss: 0.035953588783741
step: 360, loss: 0.053817979991436005
step: 370, loss: 0.06064485013484955
step: 380, loss: 0.02553841471672058
step: 390, loss: 0.06292159855365753
step: 400, loss: 0.25734657049179077
step: 410, loss: 0.03422641381621361
step: 420, loss: 0.019074738025665283
step: 430, loss: 0.031724732369184494
step: 440, loss: 0.10483278334140778
step: 450, loss: 0.06584780663251877
step: 460, loss: 0.16995464265346527
step: 470, loss: 0.02931899204850197
step: 480, loss: 0.06873784959316254
step: 490, loss: 0.02424691431224346
step: 500, loss: 0.09314057976007462
step: 510, loss: 0.10952410846948624
step: 520, loss: 0.12621496617794037
step: 530, loss: 0.11831731349229813
step: 540, loss: 8.746021921979263e-05
step: 550, loss: 0.13653306663036346
step: 560, loss: 0.03969741612672806
step: 570, loss: 0.02924271672964096
step: 580, loss: 0.027054371312260628
step: 590, loss: 0.07337117940187454
step: 600, loss: 0.08058002591133118
step: 610, loss: 0.04806838929653168
step: 620, loss: 0.04606214165687561
step: 630, loss: 0.06321217119693756
step: 640, loss: 0.056207962334156036
step: 650, loss: 0.06837023794651031
step: 660, loss: 0.053500913083553314
step: 670, loss: 0.04748774692416191
step: 680, loss: 0.0883379876613617
step: 690, loss: 0.06731114536523819
step: 700, loss: 0.020281309261918068
step: 710, loss: 0.028935818001627922
step: 720, loss: 0.06580200791358948
step: 730, loss: 0.0014491239562630653
step: 740, loss: 0.0508098229765892
step: 750, loss: 0.08407022058963776
step: 760, loss: 0.07043319195508957
step: 770, loss: 0.04891658574342728
step: 780, loss: 0.036945875734090805
step: 790, loss: 0.004229543264955282
step: 800, loss: 0.033187028020620346
step: 810, loss: 0.009546426124870777
step: 820, loss: 0.011883760802447796
step: 830, loss: 0.10810849815607071
step: 840, loss: 0.050348419696092606
step: 850, loss: 0.012022498995065689
step: 860, loss: 0.09940645098686218
step: 870, loss: 0.12454579025506973
step: 880, loss: 0.014420989900827408
step: 890, loss: 0.00800748635083437
step: 900, loss: 0.007125149480998516
step: 910, loss: 0.038947924971580505
step: 920, loss: 0.08410686999559402
step: 930, loss: 0.14143133163452148
step: 940, loss: 0.1334775984287262
step: 950, loss: 0.11465409398078918
step: 960, loss: 0.05503805726766586
step: 970, loss: 0.025301102548837662
epoch 15: dev_f1=0.9256351039260969, f1=0.9209431345353675, best_f1=0.9256880733944954
step: 0, loss: 0.04380426183342934
step: 10, loss: 0.04171903803944588
step: 20, loss: 0.09255962073802948
step: 30, loss: 0.036452095955610275
step: 40, loss: 0.04695024713873863
step: 50, loss: 0.09333088248968124
step: 60, loss: 0.03352964669466019
step: 70, loss: 0.10251174867153168
step: 80, loss: 0.017507215961813927
step: 90, loss: 0.1714673936367035
step: 100, loss: 0.03596825525164604
step: 110, loss: 0.052294664084911346
step: 120, loss: 0.051096975803375244
step: 130, loss: 0.04907673969864845
step: 140, loss: 0.0004938238416798413
step: 150, loss: 0.051045771688222885
step: 160, loss: 0.07885643094778061
step: 170, loss: 0.089078888297081
step: 180, loss: 0.02663865126669407
step: 190, loss: 0.03961780667304993
step: 200, loss: 0.005753219593316317
step: 210, loss: 0.02159523405134678
step: 220, loss: 0.04631631076335907
step: 230, loss: 0.0007334756664931774
step: 240, loss: 0.06685620546340942
step: 250, loss: 0.02409881353378296
step: 260, loss: 0.07950929552316666
step: 270, loss: 0.006722111254930496
step: 280, loss: 0.0027136639691889286
step: 290, loss: 0.01418363582342863
step: 300, loss: 5.691999103873968e-05
step: 310, loss: 0.007132441271096468
step: 320, loss: 0.09224532544612885
step: 330, loss: 0.06355690956115723
step: 340, loss: 0.04348743334412575
step: 350, loss: 0.02875789813697338
step: 360, loss: 0.0396798737347126
step: 370, loss: 0.0661105364561081
step: 380, loss: 0.13444587588310242
step: 390, loss: 0.01194718386977911
step: 400, loss: 0.07364451140165329
step: 410, loss: 0.024112846702337265
step: 420, loss: 0.015505414456129074
step: 430, loss: 0.09779370576143265
step: 440, loss: 0.029536306858062744
step: 450, loss: 0.021483926102519035
step: 460, loss: 0.054643671959638596
step: 470, loss: 0.051576606929302216
step: 480, loss: 0.07433156669139862
step: 490, loss: 0.04479675740003586
step: 500, loss: 0.06925405561923981
step: 510, loss: 0.1284632384777069
step: 520, loss: 0.08429323136806488
step: 530, loss: 0.08582115918397903
step: 540, loss: 0.05845538526773453
step: 550, loss: 0.047487303614616394
step: 560, loss: 0.046338267624378204
step: 570, loss: 0.024545038118958473
step: 580, loss: 0.029821988195180893
step: 590, loss: 0.005791023373603821
step: 600, loss: 0.06965898722410202
step: 610, loss: 3.5360848414711654e-05
step: 620, loss: 0.10176366567611694
step: 630, loss: 0.06552010029554367
step: 640, loss: 0.029549986124038696
step: 650, loss: 0.04715553671121597
step: 660, loss: 0.041355568915605545
step: 670, loss: 0.09161599725484848
step: 680, loss: 0.050070181488990784
step: 690, loss: 0.03246845677495003
step: 700, loss: 0.04126373305916786
step: 710, loss: 0.012223532423377037
step: 720, loss: 0.04238788038492203
step: 730, loss: 9.24611413211096e-06
step: 740, loss: 0.0987544134259224
step: 750, loss: 0.027767393738031387
step: 760, loss: 0.014490040950477123
step: 770, loss: 0.08579552173614502
step: 780, loss: 0.070262111723423
step: 790, loss: 0.013889983296394348
step: 800, loss: 8.376558980671689e-05
step: 810, loss: 0.050861138850450516
step: 820, loss: 0.05197102949023247
step: 830, loss: 0.059276074171066284
step: 840, loss: 0.09510999172925949
step: 850, loss: 0.12692853808403015
step: 860, loss: 0.01626506820321083
step: 870, loss: 0.10648278146982193
step: 880, loss: 0.0013383671175688505
step: 890, loss: 0.10437633097171783
step: 900, loss: 0.038827378302812576
step: 910, loss: 0.026335371658205986
step: 920, loss: 0.1299670934677124
step: 930, loss: 0.012799017131328583
step: 940, loss: 0.005721248220652342
step: 950, loss: 0.061832863837480545
step: 960, loss: 0.12210419028997421
step: 970, loss: 0.018156178295612335
epoch 16: dev_f1=0.9230059935454127, f1=0.9206642066420663, best_f1=0.9256880733944954
step: 0, loss: 0.024280952289700508
step: 10, loss: 0.016525546088814735
step: 20, loss: 0.023674599826335907
step: 30, loss: 0.0004994176561012864
step: 40, loss: 0.017784012481570244
step: 50, loss: 0.08657927066087723
step: 60, loss: 0.07168415188789368
step: 70, loss: 0.036416880786418915
step: 80, loss: 0.05927213653922081
step: 90, loss: 0.033069949597120285
step: 100, loss: 0.0005283703794702888
step: 110, loss: 0.04021405056118965
step: 120, loss: 0.049132589250802994
step: 130, loss: 0.09598369151353836
step: 140, loss: 0.034949611872434616
step: 150, loss: 0.05266517773270607
step: 160, loss: 0.001536949654109776
step: 170, loss: 0.0005844914121553302
step: 180, loss: 0.04195511341094971
step: 190, loss: 0.09883585572242737
step: 200, loss: 0.13174475729465485
step: 210, loss: 0.07495541870594025
step: 220, loss: 0.012765335850417614
step: 230, loss: 0.00030738991335965693
step: 240, loss: 0.05339019000530243
step: 250, loss: 0.00860175583511591
step: 260, loss: 0.028606951236724854
step: 270, loss: 0.0418403223156929
step: 280, loss: 0.060668617486953735
step: 290, loss: 0.173349067568779
step: 300, loss: 0.03951580077409744
step: 310, loss: 0.14746394753456116
step: 320, loss: 0.061517950147390366
step: 330, loss: 0.02236275002360344
step: 340, loss: 0.012111064046621323
step: 350, loss: 0.041511066257953644
step: 360, loss: 0.03738094121217728
step: 370, loss: 0.02585461549460888
step: 380, loss: 0.09740318357944489
step: 390, loss: 0.05862373486161232
step: 400, loss: 0.10153986513614655
step: 410, loss: 0.0001311344822170213
step: 420, loss: 0.05711105838418007
step: 430, loss: 0.01551392674446106
step: 440, loss: 0.0010636266088113189
step: 450, loss: 0.049912430346012115
step: 460, loss: 0.011815400794148445
step: 470, loss: 0.09368781000375748
step: 480, loss: 0.039734434336423874
step: 490, loss: 0.08388695120811462
step: 500, loss: 0.028333980590105057
step: 510, loss: 0.010378660634160042
step: 520, loss: 0.04846017435193062
step: 530, loss: 0.04339625686407089
step: 540, loss: 0.012225945480167866
step: 550, loss: 0.09069907665252686
step: 560, loss: 0.033879354596138
step: 570, loss: 0.06627246737480164
step: 580, loss: 0.000464118696982041
step: 590, loss: 0.05515597388148308
step: 600, loss: 0.05897847190499306
step: 610, loss: 0.021236250177025795
step: 620, loss: 0.03497403860092163
step: 630, loss: 0.020121542736887932
step: 640, loss: 0.0280873142182827
step: 650, loss: 0.03067087009549141
step: 660, loss: 0.0007932611042633653
step: 670, loss: 0.08389545232057571
step: 680, loss: 0.020668381825089455
step: 690, loss: 0.15690730512142181
step: 700, loss: 0.12325171381235123
step: 710, loss: 0.0470709390938282
step: 720, loss: 0.028553731739521027
step: 730, loss: 0.06176071986556053
step: 740, loss: 0.05046076327562332
step: 750, loss: 0.035824038088321686
step: 760, loss: 0.03287883847951889
step: 770, loss: 0.08351395279169083
step: 780, loss: 0.06482574343681335
step: 790, loss: 0.04814323037862778
step: 800, loss: 0.03435918688774109
step: 810, loss: 0.05389523506164551
step: 820, loss: 0.024904731661081314
step: 830, loss: 0.007109793368726969
step: 840, loss: 0.07715918123722076
step: 850, loss: 0.05098728463053703
step: 860, loss: 0.11907082796096802
step: 870, loss: 0.05385945737361908
step: 880, loss: 0.12333019822835922
step: 890, loss: 0.05726724490523338
step: 900, loss: 0.10402453690767288
step: 910, loss: 0.1102803647518158
step: 920, loss: 0.03512144461274147
step: 930, loss: 0.027952291071414948
step: 940, loss: 0.0016806145431473851
step: 950, loss: 0.03648756071925163
step: 960, loss: 0.0715559720993042
step: 970, loss: 0.05515215918421745
epoch 17: dev_f1=0.9221330816422841, f1=0.9213483146067416, best_f1=0.9256880733944954
step: 0, loss: 0.06121839955449104
step: 10, loss: 0.00026818510377779603
step: 20, loss: 0.00854405015707016
step: 30, loss: 0.13892440497875214
step: 40, loss: 0.0031857064459472895
step: 50, loss: 0.0615551695227623
step: 60, loss: 0.08157524466514587
step: 70, loss: 6.674775795545429e-05
step: 80, loss: 0.04380946606397629
step: 90, loss: 0.12043468654155731
step: 100, loss: 0.06230412423610687
step: 110, loss: 0.028787605464458466
step: 120, loss: 0.06976605951786041
step: 130, loss: 0.016548288986086845
step: 140, loss: 0.029435740783810616
step: 150, loss: 0.06638311594724655
step: 160, loss: 0.00824069231748581
step: 170, loss: 0.0022388023789972067
step: 180, loss: 0.0777473971247673
step: 190, loss: 0.012218410149216652
step: 200, loss: 0.04182272031903267
step: 210, loss: 0.044286563992500305
step: 220, loss: 0.05244775861501694
step: 230, loss: 0.0652364045381546
step: 240, loss: 0.026795245707035065
step: 250, loss: 0.06619133800268173
step: 260, loss: 0.07634834200143814
step: 270, loss: 0.00989365391433239
step: 280, loss: 0.01266368106007576
step: 290, loss: 0.06466361880302429
step: 300, loss: 0.058644529432058334
step: 310, loss: 0.025947704911231995
step: 320, loss: 0.01412831898778677
step: 330, loss: 0.000963446858804673
step: 340, loss: 0.027241788804531097
step: 350, loss: 0.08325552195310593
step: 360, loss: 0.07547678798437119
step: 370, loss: 0.051091596484184265
step: 380, loss: 0.03919490799307823
step: 390, loss: 0.05654003843665123
step: 400, loss: 0.09862318634986877
step: 410, loss: 0.06381379812955856
step: 420, loss: 0.09048347920179367
step: 430, loss: 0.04675698280334473
step: 440, loss: 0.08174563944339752
step: 450, loss: 0.013617883436381817
step: 460, loss: 0.0001981797395274043
step: 470, loss: 0.07297192513942719
step: 480, loss: 0.046663619577884674
step: 490, loss: 0.1383773386478424
step: 500, loss: 0.00036076578544452786
step: 510, loss: 0.01695997081696987
step: 520, loss: 0.07855141907930374
step: 530, loss: 0.04873724281787872
step: 540, loss: 0.08333830535411835
step: 550, loss: 0.040087029337882996
step: 560, loss: 0.09256425499916077
step: 570, loss: 0.01515456847846508
step: 580, loss: 0.054665759205818176
step: 590, loss: 0.06298182904720306
step: 600, loss: 0.0321490615606308
step: 610, loss: 0.0006455891998484731
step: 620, loss: 0.06713266670703888
step: 630, loss: 0.0498843751847744
step: 640, loss: 0.033309146761894226
step: 650, loss: 0.020247993990778923
step: 660, loss: 0.012179134413599968
step: 670, loss: 0.05865390598773956
step: 680, loss: 0.03729095682501793
step: 690, loss: 0.029550950974225998
step: 700, loss: 0.02182302065193653
step: 710, loss: 0.06404396146535873
step: 720, loss: 0.05891764163970947
step: 730, loss: 0.023222357034683228
step: 740, loss: 0.011928226798772812
step: 750, loss: 0.06700118631124496
step: 760, loss: 0.04342331737279892
step: 770, loss: 0.056368157267570496
step: 780, loss: 0.08774714916944504
step: 790, loss: 0.020377740263938904
step: 800, loss: 0.030030082911252975
step: 810, loss: 0.06488466262817383
step: 820, loss: 0.05973144993185997
step: 830, loss: 0.008862421847879887
step: 840, loss: 0.03016003593802452
step: 850, loss: 0.05402640625834465
step: 860, loss: 0.09225042909383774
step: 870, loss: 0.13621023297309875
step: 880, loss: 0.013323132880032063
step: 890, loss: 0.044697266072034836
step: 900, loss: 0.041691191494464874
step: 910, loss: 7.919135532574728e-05
step: 920, loss: 0.10233236104249954
step: 930, loss: 0.10569748282432556
step: 940, loss: 0.07555439323186874
step: 950, loss: 0.028405556455254555
step: 960, loss: 0.1117045059800148
step: 970, loss: 0.08605678379535675
epoch 18: dev_f1=0.9221445221445221, f1=0.922077922077922, best_f1=0.9256880733944954
step: 0, loss: 0.023552291095256805
step: 10, loss: 0.06749223917722702
step: 20, loss: 8.708062523510307e-05
step: 30, loss: 0.04916782304644585
step: 40, loss: 0.021213170140981674
step: 50, loss: 0.06440378725528717
step: 60, loss: 0.05684877932071686
step: 70, loss: 0.004008409567177296
step: 80, loss: 0.034544698894023895
step: 90, loss: 0.045437976717948914
step: 100, loss: 0.05608658120036125
step: 110, loss: 0.0026122822891920805
step: 120, loss: 0.017246048897504807
step: 130, loss: 0.058002080768346786
step: 140, loss: 0.00012372262426652014
step: 150, loss: 0.057399455457925797
step: 160, loss: 0.01272429060190916
step: 170, loss: 0.015303713269531727
step: 180, loss: 0.12291471660137177
step: 190, loss: 0.09626226872205734
step: 200, loss: 0.06960959732532501
step: 210, loss: 0.10838547348976135
step: 220, loss: 0.03682544082403183
step: 230, loss: 7.757659477647394e-05
step: 240, loss: 0.04106348007917404
step: 250, loss: 0.13424177467823029
step: 260, loss: 0.001516964053735137
step: 270, loss: 0.013396471738815308
step: 280, loss: 0.026415906846523285
step: 290, loss: 0.10598193854093552
step: 300, loss: 0.023422980681061745
step: 310, loss: 0.0009139356552623212
step: 320, loss: 7.33091656002216e-05
step: 330, loss: 0.04280337691307068
step: 340, loss: 0.06385907530784607
step: 350, loss: 0.08524972200393677
step: 360, loss: 0.030656013637781143
step: 370, loss: 0.04742889851331711
step: 380, loss: 0.08267234265804291
step: 390, loss: 0.033307187259197235
step: 400, loss: 0.032984036952257156
step: 410, loss: 0.09076552093029022
step: 420, loss: 0.0208891648799181
step: 430, loss: 0.04261031374335289
step: 440, loss: 0.0791422575712204
step: 450, loss: 0.00026580601115711033
step: 460, loss: 0.0686313807964325
step: 470, loss: 0.023335512727499008
step: 480, loss: 0.05614691972732544
step: 490, loss: 0.0439680814743042
step: 500, loss: 0.051288578659296036
step: 510, loss: 0.010517856106162071
step: 520, loss: 0.04106495901942253
step: 530, loss: 0.04577074944972992
step: 540, loss: 0.05538245663046837
step: 550, loss: 0.05821273475885391
step: 560, loss: 0.04349370300769806
step: 570, loss: 0.051819730550050735
step: 580, loss: 0.07332558184862137
step: 590, loss: 0.04826229438185692
step: 600, loss: 0.00010753452079370618
step: 610, loss: 0.027338555082678795
step: 620, loss: 0.017861496657133102
step: 630, loss: 0.09467975050210953
step: 640, loss: 0.009761113673448563
step: 650, loss: 0.04188945144414902
step: 660, loss: 0.08587055653333664
step: 670, loss: 0.0007138167857192457
step: 680, loss: 0.17813432216644287
step: 690, loss: 0.06277481466531754
step: 700, loss: 0.029315756633877754
step: 710, loss: 0.03879259526729584
step: 720, loss: 0.06766363978385925
step: 730, loss: 0.03387584909796715
step: 740, loss: 0.022370506078004837
step: 750, loss: 0.04414329677820206
step: 760, loss: 0.011706807650625706
step: 770, loss: 0.10445453226566315
step: 780, loss: 0.015018214471638203
step: 790, loss: 2.841822788468562e-05
step: 800, loss: 0.07102535665035248
step: 810, loss: 0.0022539920173585415
step: 820, loss: 0.06401194632053375
step: 830, loss: 0.0651123896241188
step: 840, loss: 0.033309925347566605
step: 850, loss: 0.09188155084848404
step: 860, loss: 0.07319772243499756
step: 870, loss: 0.00027541740564629436
step: 880, loss: 0.030259529128670692
step: 890, loss: 0.03643594682216644
step: 900, loss: 0.08580915629863739
step: 910, loss: 0.08009118586778641
step: 920, loss: 0.04830772802233696
step: 930, loss: 0.05619276687502861
step: 940, loss: 0.0204144399613142
step: 950, loss: 0.011274971067905426
step: 960, loss: 0.06671617925167084
step: 970, loss: 0.018437610939145088
epoch 19: dev_f1=0.9203206034889202, f1=0.920486435921422, best_f1=0.9256880733944954
step: 0, loss: 0.08918353915214539
step: 10, loss: 0.04738013073801994
step: 20, loss: 0.016899894922971725
step: 30, loss: 0.028846709057688713
step: 40, loss: 0.025266198441386223
step: 50, loss: 0.06177626550197601
step: 60, loss: 0.04816485941410065
step: 70, loss: 0.09923964738845825
step: 80, loss: 0.03049738146364689
step: 90, loss: 0.038483571261167526
step: 100, loss: 0.02246132120490074
step: 110, loss: 0.04162217304110527
step: 120, loss: 0.08878756314516068
step: 130, loss: 0.06044820323586464
step: 140, loss: 0.025810273364186287
step: 150, loss: 0.031417105346918106
step: 160, loss: 0.08768857270479202
step: 170, loss: 0.042628463357686996
step: 180, loss: 0.06270952522754669
step: 190, loss: 0.025130819529294968
step: 200, loss: 0.0664660632610321
step: 210, loss: 0.04975130036473274
step: 220, loss: 0.057009000331163406
step: 230, loss: 0.011677778325974941
step: 240, loss: 0.04096720367670059
step: 250, loss: 0.04145897179841995
step: 260, loss: 0.05513213947415352
step: 270, loss: 0.04280376806855202
step: 280, loss: 0.00020661177404690534
step: 290, loss: 0.07091856002807617
step: 300, loss: 0.020444372668862343
step: 310, loss: 0.03899166360497475
step: 320, loss: 0.0211750827729702
step: 330, loss: 0.01954246312379837
step: 340, loss: 0.025809165090322495
step: 350, loss: 0.0641467422246933
step: 360, loss: 0.057744767516851425
step: 370, loss: 0.030169731006026268
step: 380, loss: 0.06975598633289337
step: 390, loss: 0.07230586558580399
step: 400, loss: 0.01544060930609703
step: 410, loss: 0.00018426527094561607
step: 420, loss: 0.12228213995695114
step: 430, loss: 0.10466692596673965
step: 440, loss: 0.03749183937907219
step: 450, loss: 0.05906461924314499
step: 460, loss: 0.030934667214751244
step: 470, loss: 0.0670250877737999
step: 480, loss: 0.06959651410579681
step: 490, loss: 0.018302857875823975
step: 500, loss: 0.03157385066151619
step: 510, loss: 0.06801708787679672
step: 520, loss: 0.055852487683296204
step: 530, loss: 0.0001978247455554083
step: 540, loss: 0.011307761073112488
step: 550, loss: 0.08762498944997787
step: 560, loss: 0.12703418731689453
step: 570, loss: 0.03646006062626839
step: 580, loss: 0.06760823726654053
step: 590, loss: 0.07370451092720032
step: 600, loss: 0.010720254853367805
step: 610, loss: 0.0989382341504097
step: 620, loss: 0.011834884993731976
step: 630, loss: 0.03496095910668373
step: 640, loss: 0.06344089657068253
step: 650, loss: 0.037181392312049866
step: 660, loss: 0.06933727115392685
step: 670, loss: 0.015087812207639217
step: 680, loss: 0.023101795464754105
step: 690, loss: 0.01632123813033104
step: 700, loss: 0.04254760965704918
step: 710, loss: 0.10337518900632858
step: 720, loss: 0.027949513867497444
step: 730, loss: 0.03520108386874199
step: 740, loss: 0.04216068610548973
step: 750, loss: 0.01609579287469387
step: 760, loss: 0.01344649400562048
step: 770, loss: 0.07190036028623581
step: 780, loss: 0.0006078542210161686
step: 790, loss: 0.06254374235868454
step: 800, loss: 0.06137805059552193
step: 810, loss: 0.016947761178016663
step: 820, loss: 0.03410905599594116
step: 830, loss: 1.1049044587707613e-05
step: 840, loss: 0.01523443590849638
step: 850, loss: 0.033049654215574265
step: 860, loss: 0.02449014037847519
step: 870, loss: 0.03213747963309288
step: 880, loss: 0.05538144335150719
step: 890, loss: 0.08975779265165329
step: 900, loss: 0.10311300307512283
step: 910, loss: 0.00019807346689049155
step: 920, loss: 0.07852385938167572
step: 930, loss: 0.020622698590159416
step: 940, loss: 0.049099527299404144
step: 950, loss: 0.06566411256790161
step: 960, loss: 0.011881371960043907
step: 970, loss: 0.06054395064711571
epoch 20: dev_f1=0.922425952045134, f1=0.920486435921422, best_f1=0.9256880733944954
