cuda
Device: cuda
step: 0, loss: 0.7700825333595276
step: 10, loss: 0.2370108962059021
step: 20, loss: 0.33960720896720886
step: 30, loss: 0.32275983691215515
step: 40, loss: 0.34149405360221863
step: 50, loss: 0.13726937770843506
step: 60, loss: 0.25473421812057495
step: 70, loss: 0.18883904814720154
step: 80, loss: 0.3325851857662201
step: 90, loss: 0.2888544201850891
step: 100, loss: 0.18293507397174835
step: 110, loss: 0.06361667066812515
step: 120, loss: 0.20582309365272522
step: 130, loss: 0.25576844811439514
step: 140, loss: 0.13232211768627167
step: 150, loss: 0.11718442291021347
step: 160, loss: 0.3425484597682953
step: 170, loss: 0.2718558609485626
step: 180, loss: 0.386691153049469
step: 190, loss: 0.23400413990020752
step: 200, loss: 0.17913362383842468
step: 210, loss: 0.16168271005153656
step: 220, loss: 0.1551361382007599
step: 230, loss: 0.15776559710502625
step: 240, loss: 0.17388321459293365
step: 250, loss: 0.24341891705989838
step: 260, loss: 0.15478861331939697
step: 270, loss: 0.20363584160804749
step: 280, loss: 0.047051481902599335
step: 290, loss: 0.1264176070690155
step: 300, loss: 0.29783910512924194
step: 310, loss: 0.262660950422287
step: 320, loss: 0.10700179636478424
step: 330, loss: 0.23680588603019714
step: 340, loss: 0.18809683620929718
step: 350, loss: 0.0901574119925499
step: 360, loss: 0.18314798176288605
step: 370, loss: 0.23468609154224396
step: 380, loss: 0.10635026544332504
step: 390, loss: 0.1036282405257225
step: 400, loss: 0.17565111815929413
step: 410, loss: 0.12914887070655823
step: 420, loss: 0.30263057351112366
step: 430, loss: 0.09683473408222198
step: 440, loss: 0.12517383694648743
step: 450, loss: 0.08999498188495636
step: 460, loss: 0.13366220891475677
step: 470, loss: 0.12965327501296997
step: 480, loss: 0.15077747404575348
step: 490, loss: 0.09756142646074295
step: 500, loss: 0.0817614421248436
step: 510, loss: 0.08301451057195663
step: 520, loss: 0.17872044444084167
step: 530, loss: 0.010982141830027103
step: 540, loss: 0.26310715079307556
step: 550, loss: 0.13373792171478271
step: 560, loss: 0.3009517192840576
step: 570, loss: 0.15985144674777985
step: 580, loss: 0.14933186769485474
step: 590, loss: 0.1556674838066101
step: 600, loss: 0.10391710698604584
step: 610, loss: 0.12380919605493546
step: 620, loss: 0.26379406452178955
step: 630, loss: 0.04057862609624863
step: 640, loss: 0.2611885368824005
step: 650, loss: 0.26706254482269287
step: 660, loss: 0.044725026935338974
step: 670, loss: 0.11714901775121689
step: 680, loss: 0.23634928464889526
step: 690, loss: 0.2806142568588257
step: 700, loss: 0.11996383219957352
step: 710, loss: 0.2699473202228546
step: 720, loss: 0.14070941507816315
step: 730, loss: 0.18490077555179596
step: 740, loss: 0.22034603357315063
step: 750, loss: 0.22648809850215912
step: 760, loss: 0.2623346447944641
step: 770, loss: 0.06621947139501572
step: 780, loss: 0.10459218919277191
step: 790, loss: 0.32815083861351013
step: 800, loss: 0.1777079999446869
step: 810, loss: 0.09152393043041229
step: 820, loss: 0.20471590757369995
step: 830, loss: 0.14847593009471893
step: 840, loss: 0.14397720992565155
step: 850, loss: 0.1098552867770195
step: 860, loss: 0.1656385213136673
step: 870, loss: 0.05183790996670723
step: 880, loss: 0.1914246529340744
step: 890, loss: 0.06195150688290596
step: 900, loss: 0.11327676475048065
step: 910, loss: 0.07374131679534912
step: 920, loss: 0.20999743044376373
step: 930, loss: 0.3215859532356262
step: 940, loss: 0.13676953315734863
step: 950, loss: 0.18351773917675018
step: 960, loss: 0.072400763630867
step: 970, loss: 0.2896265685558319
epoch 1: dev_f1=0.9255813953488372, f1=0.9349930843706776, best_f1=0.9349930843706776
step: 0, loss: 0.06976674497127533
step: 10, loss: 0.17098797857761383
step: 20, loss: 0.2095172256231308
step: 30, loss: 0.3101728856563568
step: 40, loss: 0.13128624856472015
step: 50, loss: 0.14135047793388367
step: 60, loss: 0.15512174367904663
step: 70, loss: 0.03505774214863777
step: 80, loss: 0.1727479100227356
step: 90, loss: 0.13236315548419952
step: 100, loss: 0.17248456180095673
step: 110, loss: 0.11878654360771179
step: 120, loss: 0.12352103739976883
step: 130, loss: 0.10566151142120361
step: 140, loss: 0.06828971952199936
step: 150, loss: 0.11384893208742142
step: 160, loss: 0.24070608615875244
step: 170, loss: 0.22540023922920227
step: 180, loss: 0.11680955439805984
step: 190, loss: 0.10427679866552353
step: 200, loss: 0.12265810370445251
step: 210, loss: 0.18143871426582336
step: 220, loss: 0.09087762236595154
step: 230, loss: 0.07301656901836395
step: 240, loss: 0.08821400254964828
step: 250, loss: 0.11657318472862244
step: 260, loss: 0.10420359671115875
step: 270, loss: 0.2033848613500595
step: 280, loss: 0.16343937814235687
step: 290, loss: 0.09303373843431473
step: 300, loss: 0.20107562839984894
step: 310, loss: 0.08937449008226395
step: 320, loss: 0.19423240423202515
step: 330, loss: 0.2073020040988922
step: 340, loss: 0.0622628889977932
step: 350, loss: 0.24552486836910248
step: 360, loss: 0.0999135822057724
step: 370, loss: 0.2308528870344162
step: 380, loss: 0.13465464115142822
step: 390, loss: 0.10135351866483688
step: 400, loss: 0.10921012610197067
step: 410, loss: 0.109103262424469
step: 420, loss: 0.2226184755563736
step: 430, loss: 0.2119179219007492
step: 440, loss: 0.09172490239143372
step: 450, loss: 0.09166182577610016
step: 460, loss: 0.2917555570602417
step: 470, loss: 0.14636510610580444
step: 480, loss: 0.11459609121084213
step: 490, loss: 0.2324157953262329
step: 500, loss: 0.2604483366012573
step: 510, loss: 0.09997126460075378
step: 520, loss: 0.1556454449892044
step: 530, loss: 0.12256984412670135
step: 540, loss: 0.23983998596668243
step: 550, loss: 0.10692964494228363
step: 560, loss: 0.3470940589904785
step: 570, loss: 0.2547013759613037
step: 580, loss: 0.008613483980298042
step: 590, loss: 0.16502270102500916
step: 600, loss: 0.16300277411937714
step: 610, loss: 0.03510597348213196
step: 620, loss: 0.12317947298288345
step: 630, loss: 0.2625662684440613
step: 640, loss: 0.18096722662448883
step: 650, loss: 0.1282169669866562
step: 660, loss: 0.06565427035093307
step: 670, loss: 0.21142442524433136
step: 680, loss: 0.11445049196481705
step: 690, loss: 0.29594331979751587
step: 700, loss: 0.09508045762777328
step: 710, loss: 0.14960072934627533
step: 720, loss: 0.1766262799501419
step: 730, loss: 0.2686135470867157
step: 740, loss: 0.05015387758612633
step: 750, loss: 0.10405533760786057
step: 760, loss: 0.10211756080389023
step: 770, loss: 0.09486494213342667
step: 780, loss: 0.16561627388000488
step: 790, loss: 0.14322611689567566
step: 800, loss: 0.2343575656414032
step: 810, loss: 0.12830261886119843
step: 820, loss: 0.11657124757766724
step: 830, loss: 0.14932753145694733
step: 840, loss: 0.08304028958082199
step: 850, loss: 0.10222835093736649
step: 860, loss: 0.2471216768026352
step: 870, loss: 0.15456514060497284
step: 880, loss: 0.14084304869174957
step: 890, loss: 0.10029403865337372
step: 900, loss: 0.23585861921310425
step: 910, loss: 0.35497477650642395
step: 920, loss: 0.09758669137954712
step: 930, loss: 0.1007692813873291
step: 940, loss: 0.08632852137088776
step: 950, loss: 0.28111669421195984
step: 960, loss: 0.09366030246019363
step: 970, loss: 0.04152749851346016
epoch 2: dev_f1=0.9161230195712954, f1=0.9164345403899723, best_f1=0.9349930843706776
step: 0, loss: 0.1655975878238678
step: 10, loss: 0.07542815059423447
step: 20, loss: 0.0865224227309227
step: 30, loss: 0.16856266558170319
step: 40, loss: 0.15557894110679626
step: 50, loss: 0.09725130349397659
step: 60, loss: 0.12947311997413635
step: 70, loss: 0.5280643701553345
step: 80, loss: 0.11763258278369904
step: 90, loss: 0.15936070680618286
step: 100, loss: 0.0707109346985817
step: 110, loss: 0.11906146258115768
step: 120, loss: 0.16988424956798553
step: 130, loss: 0.10516049712896347
step: 140, loss: 0.11566905677318573
step: 150, loss: 0.43171432614326477
step: 160, loss: 0.15220625698566437
step: 170, loss: 0.14135125279426575
step: 180, loss: 0.13699990510940552
step: 190, loss: 0.11801525950431824
step: 200, loss: 0.0915127769112587
step: 210, loss: 0.11447317153215408
step: 220, loss: 0.23996563255786896
step: 230, loss: 0.0905795693397522
step: 240, loss: 0.07290428131818771
step: 250, loss: 0.10403990745544434
step: 260, loss: 0.03775004670023918
step: 270, loss: 0.10513094812631607
step: 280, loss: 0.14862041175365448
step: 290, loss: 0.3268108367919922
step: 300, loss: 0.10527703166007996
step: 310, loss: 0.14301468431949615
step: 320, loss: 0.09093455225229263
step: 330, loss: 0.13435637950897217
step: 340, loss: 0.1077878549695015
step: 350, loss: 0.16153497993946075
step: 360, loss: 0.1439879834651947
step: 370, loss: 0.09261515736579895
step: 380, loss: 0.11348394304513931
step: 390, loss: 0.18604901432991028
step: 400, loss: 0.12867122888565063
step: 410, loss: 0.10076471418142319
step: 420, loss: 0.07255949079990387
step: 430, loss: 0.05553332716226578
step: 440, loss: 0.12341681122779846
step: 450, loss: 0.21567915380001068
step: 460, loss: 0.0804421454668045
step: 470, loss: 0.10812725126743317
step: 480, loss: 0.2706140875816345
step: 490, loss: 0.12069337069988251
step: 500, loss: 0.21264885365962982
step: 510, loss: 0.11518826335668564
step: 520, loss: 0.21063970029354095
step: 530, loss: 0.04266597703099251
step: 540, loss: 0.12993226945400238
step: 550, loss: 0.08910501003265381
step: 560, loss: 0.06430003046989441
step: 570, loss: 0.07365339994430542
step: 580, loss: 0.135647714138031
step: 590, loss: 0.17546936869621277
step: 600, loss: 0.16362668573856354
step: 610, loss: 0.1294146180152893
step: 620, loss: 0.28328725695610046
step: 630, loss: 0.08211977779865265
step: 640, loss: 0.19816957414150238
step: 650, loss: 0.0549360029399395
step: 660, loss: 0.15132154524326324
step: 670, loss: 0.1355283111333847
step: 680, loss: 0.14105242490768433
step: 690, loss: 0.11957713216543198
step: 700, loss: 0.10044778138399124
step: 710, loss: 0.15250200033187866
step: 720, loss: 0.2008294016122818
step: 730, loss: 0.026516038924455643
step: 740, loss: 0.05524267256259918
step: 750, loss: 0.2102404087781906
step: 760, loss: 0.20962488651275635
step: 770, loss: 0.11257301270961761
step: 780, loss: 0.13035444915294647
step: 790, loss: 0.1720784604549408
step: 800, loss: 0.11767739802598953
step: 810, loss: 0.22644871473312378
step: 820, loss: 0.19296197593212128
step: 830, loss: 0.18745402991771698
step: 840, loss: 0.08170274645090103
step: 850, loss: 0.09204832464456558
step: 860, loss: 0.12752719223499298
step: 870, loss: 0.13926903903484344
step: 880, loss: 0.13356800377368927
step: 890, loss: 0.09276377409696579
step: 900, loss: 0.10172858089208603
step: 910, loss: 0.2568344473838806
step: 920, loss: 0.1169719323515892
step: 930, loss: 0.1699782907962799
step: 940, loss: 0.18111996352672577
step: 950, loss: 0.06731902807950974
step: 960, loss: 0.07435698062181473
step: 970, loss: 0.08374539762735367
epoch 3: dev_f1=0.9206785878037598, f1=0.9201834862385322, best_f1=0.9349930843706776
step: 0, loss: 0.05902465432882309
step: 10, loss: 0.12276627868413925
step: 20, loss: 0.08249988406896591
step: 30, loss: 0.09101755917072296
step: 40, loss: 0.1116688996553421
step: 50, loss: 0.19941560924053192
step: 60, loss: 0.20311042666435242
step: 70, loss: 0.06483757495880127
step: 80, loss: 0.0846300721168518
step: 90, loss: 0.05003504082560539
step: 100, loss: 0.04517696052789688
step: 110, loss: 0.11024651676416397
step: 120, loss: 0.047382667660713196
step: 130, loss: 0.10186276584863663
step: 140, loss: 0.07429030537605286
step: 150, loss: 0.07205632328987122
step: 160, loss: 0.10812677443027496
step: 170, loss: 0.20201799273490906
step: 180, loss: 0.0890372022986412
step: 190, loss: 0.1709137260913849
step: 200, loss: 0.08848557621240616
step: 210, loss: 0.14309002459049225
step: 220, loss: 0.13130643963813782
step: 230, loss: 0.11799617856740952
step: 240, loss: 0.05310794711112976
step: 250, loss: 0.08554071933031082
step: 260, loss: 0.1287280172109604
step: 270, loss: 0.11951388418674469
step: 280, loss: 0.1643117368221283
step: 290, loss: 0.09361797571182251
step: 300, loss: 0.13943642377853394
step: 310, loss: 0.059614505618810654
step: 320, loss: 0.08131610602140427
step: 330, loss: 0.10369393974542618
step: 340, loss: 0.04159940779209137
step: 350, loss: 0.16741889715194702
step: 360, loss: 0.2846958637237549
step: 370, loss: 0.18082021176815033
step: 380, loss: 0.16617579758167267
step: 390, loss: 0.27746060490608215
step: 400, loss: 0.2116171419620514
step: 410, loss: 0.17792637646198273
step: 420, loss: 0.028911005705595016
step: 430, loss: 0.11895374953746796
step: 440, loss: 0.003982578404247761
step: 450, loss: 0.17354781925678253
step: 460, loss: 0.05004825443029404
step: 470, loss: 0.1350686103105545
step: 480, loss: 0.08039748668670654
step: 490, loss: 0.04790002480149269
step: 500, loss: 0.050375524908304214
step: 510, loss: 0.12151751667261124
step: 520, loss: 0.06309100985527039
step: 530, loss: 0.10803712904453278
step: 540, loss: 0.022549262270331383
step: 550, loss: 0.01872747763991356
step: 560, loss: 0.08125441521406174
step: 570, loss: 0.19324077665805817
step: 580, loss: 0.11615238338708878
step: 590, loss: 0.12102532386779785
step: 600, loss: 0.1164233386516571
step: 610, loss: 0.010392536409199238
step: 620, loss: 0.1208166778087616
step: 630, loss: 0.1207161471247673
step: 640, loss: 0.10719623416662216
step: 650, loss: 0.06082740053534508
step: 660, loss: 0.0778837576508522
step: 670, loss: 0.09088454395532608
step: 680, loss: 0.14355546236038208
step: 690, loss: 0.014822953380644321
step: 700, loss: 0.06414210796356201
step: 710, loss: 0.08788977563381195
step: 720, loss: 0.21818365156650543
step: 730, loss: 0.2362184375524521
step: 740, loss: 0.20666304230690002
step: 750, loss: 0.10303367674350739
step: 760, loss: 0.1676076501607895
step: 770, loss: 0.13795363903045654
step: 780, loss: 0.08191617578268051
step: 790, loss: 0.19722463190555573
step: 800, loss: 0.11642303317785263
step: 810, loss: 0.095074363052845
step: 820, loss: 0.049388255923986435
step: 830, loss: 0.085762158036232
step: 840, loss: 0.05126965045928955
step: 850, loss: 0.10473362356424332
step: 860, loss: 0.10263119637966156
step: 870, loss: 0.06430349498987198
step: 880, loss: 0.030966609716415405
step: 890, loss: 0.15724731981754303
step: 900, loss: 0.09066444635391235
step: 910, loss: 0.2934589087963104
step: 920, loss: 0.16386555135250092
step: 930, loss: 0.10879554599523544
step: 940, loss: 0.08613813668489456
step: 950, loss: 0.07939299941062927
step: 960, loss: 0.09235534071922302
step: 970, loss: 0.07072953879833221
epoch 4: dev_f1=0.9322964318389753, f1=0.927404718693285, best_f1=0.927404718693285
step: 0, loss: 0.1435205191373825
step: 10, loss: 0.020130548626184464
step: 20, loss: 0.10864262282848358
step: 30, loss: 0.09019675850868225
step: 40, loss: 0.01080414094030857
step: 50, loss: 0.11175987869501114
step: 60, loss: 0.13899055123329163
step: 70, loss: 0.0822942852973938
step: 80, loss: 0.14275850355625153
step: 90, loss: 0.04835880920290947
step: 100, loss: 0.2198820412158966
step: 110, loss: 0.08823494613170624
step: 120, loss: 0.06866320222616196
step: 130, loss: 0.18491530418395996
step: 140, loss: 0.09378519654273987
step: 150, loss: 0.04962627589702606
step: 160, loss: 0.06220261752605438
step: 170, loss: 0.17275117337703705
step: 180, loss: 0.07119408249855042
step: 190, loss: 0.0996723398566246
step: 200, loss: 0.1347092241048813
step: 210, loss: 0.019397638738155365
step: 220, loss: 0.0527331717312336
step: 230, loss: 0.13517268002033234
step: 240, loss: 0.08600932359695435
step: 250, loss: 0.015118935145437717
step: 260, loss: 0.25112149119377136
step: 270, loss: 0.0816405713558197
step: 280, loss: 0.11099313199520111
step: 290, loss: 0.07690582424402237
step: 300, loss: 0.08181482553482056
step: 310, loss: 0.07152900844812393
step: 320, loss: 0.3322669565677643
step: 330, loss: 0.05095415189862251
step: 340, loss: 0.12520112097263336
step: 350, loss: 0.09344729781150818
step: 360, loss: 0.1148429811000824
step: 370, loss: 0.0845925435423851
step: 380, loss: 0.06400398164987564
step: 390, loss: 0.04885706305503845
step: 400, loss: 0.08149527758359909
step: 410, loss: 0.007044860161840916
step: 420, loss: 0.0764477327466011
step: 430, loss: 0.08696122467517853
step: 440, loss: 0.11102399975061417
step: 450, loss: 0.08784014731645584
step: 460, loss: 0.13125938177108765
step: 470, loss: 0.16441617906093597
step: 480, loss: 0.046486515551805496
step: 490, loss: 0.11137428879737854
step: 500, loss: 0.12614473700523376
step: 510, loss: 0.1756065934896469
step: 520, loss: 0.08445367962121964
step: 530, loss: 0.11574801802635193
step: 540, loss: 0.11179973930120468
step: 550, loss: 0.130761057138443
step: 560, loss: 0.06432482600212097
step: 570, loss: 0.12808021903038025
step: 580, loss: 0.19975855946540833
step: 590, loss: 0.2209247201681137
step: 600, loss: 0.10599347949028015
step: 610, loss: 0.10894829034805298
step: 620, loss: 0.15071603655815125
step: 630, loss: 0.12859883904457092
step: 640, loss: 0.0624227412045002
step: 650, loss: 0.2468671351671219
step: 660, loss: 0.04637667164206505
step: 670, loss: 0.03763530030846596
step: 680, loss: 0.20361493527889252
step: 690, loss: 0.07790985703468323
step: 700, loss: 0.09488243609666824
step: 710, loss: 0.0807582437992096
step: 720, loss: 0.07433341443538666
step: 730, loss: 0.07948970049619675
step: 740, loss: 0.09178466349840164
step: 750, loss: 0.07573460787534714
step: 760, loss: 0.10466038435697556
step: 770, loss: 0.13251140713691711
step: 780, loss: 0.12213373184204102
step: 790, loss: 0.08108707517385483
step: 800, loss: 0.11961773037910461
step: 810, loss: 0.1442873179912567
step: 820, loss: 0.23087479174137115
step: 830, loss: 0.07610765844583511
step: 840, loss: 0.02181585691869259
step: 850, loss: 0.09438285231590271
step: 860, loss: 0.01996758207678795
step: 870, loss: 0.13837288320064545
step: 880, loss: 0.11832523345947266
step: 890, loss: 0.11097921431064606
step: 900, loss: 0.09045325964689255
step: 910, loss: 0.09652987867593765
step: 920, loss: 0.07657536119222641
step: 930, loss: 0.10055092722177505
step: 940, loss: 0.054718464612960815
step: 950, loss: 0.0808795690536499
step: 960, loss: 0.16401387751102448
step: 970, loss: 0.030392784625291824
epoch 5: dev_f1=0.9232914923291492, f1=0.9237918215613383, best_f1=0.927404718693285
step: 0, loss: 0.052888114005327225
step: 10, loss: 0.17187991738319397
step: 20, loss: 0.11099224537611008
step: 30, loss: 0.15473031997680664
step: 40, loss: 0.09785456210374832
step: 50, loss: 0.12086454778909683
step: 60, loss: 0.07361004501581192
step: 70, loss: 0.09928415715694427
step: 80, loss: 0.13577184081077576
step: 90, loss: 0.0981728807091713
step: 100, loss: 0.13460972905158997
step: 110, loss: 0.02139870636165142
step: 120, loss: 0.044755250215530396
step: 130, loss: 0.1113005131483078
step: 140, loss: 0.05406901240348816
step: 150, loss: 0.15159961581230164
step: 160, loss: 0.07853297144174576
step: 170, loss: 0.037179697304964066
step: 180, loss: 0.14346925914287567
step: 190, loss: 0.1025034487247467
step: 200, loss: 0.07738872617483139
step: 210, loss: 0.12080273032188416
step: 220, loss: 0.11344210803508759
step: 230, loss: 0.11303611099720001
step: 240, loss: 0.1608581840991974
step: 250, loss: 0.07549066841602325
step: 260, loss: 0.08824987709522247
step: 270, loss: 0.11881347000598907
step: 280, loss: 0.05121057108044624
step: 290, loss: 0.09665080159902573
step: 300, loss: 0.1007901281118393
step: 310, loss: 0.069020576775074
step: 320, loss: 0.06263259053230286
step: 330, loss: 0.12150107324123383
step: 340, loss: 0.08456412702798843
step: 350, loss: 0.10132359713315964
step: 360, loss: 0.08605159819126129
step: 370, loss: 0.11333265155553818
step: 380, loss: 0.053976595401763916
step: 390, loss: 0.06018855795264244
step: 400, loss: 0.06956765055656433
step: 410, loss: 0.07095393538475037
step: 420, loss: 0.02326391078531742
step: 430, loss: 0.28034648299217224
step: 440, loss: 0.11381474137306213
step: 450, loss: 0.07578668743371964
step: 460, loss: 0.15095111727714539
step: 470, loss: 0.19198447465896606
step: 480, loss: 0.09389597177505493
step: 490, loss: 0.11873970180749893
step: 500, loss: 0.15064750611782074
step: 510, loss: 0.03817257285118103
step: 520, loss: 0.12635435163974762
step: 530, loss: 0.10024504363536835
step: 540, loss: 0.08090002834796906
step: 550, loss: 0.05630528926849365
step: 560, loss: 0.06667011231184006
step: 570, loss: 0.11006980389356613
step: 580, loss: 0.045296818017959595
step: 590, loss: 0.12850627303123474
step: 600, loss: 0.07200326025485992
step: 610, loss: 0.11102981120347977
step: 620, loss: 0.09419183433055878
step: 630, loss: 0.1441851109266281
step: 640, loss: 0.07790271937847137
step: 650, loss: 0.15234126150608063
step: 660, loss: 0.06105946749448776
step: 670, loss: 0.07733788341283798
step: 680, loss: 0.11810670047998428
step: 690, loss: 0.03707554191350937
step: 700, loss: 0.13975153863430023
step: 710, loss: 0.024524442851543427
step: 720, loss: 0.10691261291503906
step: 730, loss: 0.10413170605897903
step: 740, loss: 0.0569768026471138
step: 750, loss: 0.03268030658364296
step: 760, loss: 0.09464550763368607
step: 770, loss: 0.12684865295886993
step: 780, loss: 0.1282791644334793
step: 790, loss: 0.12864406406879425
step: 800, loss: 0.14499428868293762
step: 810, loss: 0.22979435324668884
step: 820, loss: 0.03688890486955643
step: 830, loss: 0.014285065233707428
step: 840, loss: 0.08043432980775833
step: 850, loss: 0.07876323908567429
step: 860, loss: 0.1777808517217636
step: 870, loss: 0.060338445007801056
step: 880, loss: 0.058342330157756805
step: 890, loss: 0.09791553765535355
step: 900, loss: 0.047579195350408554
step: 910, loss: 0.01798473671078682
step: 920, loss: 0.09080187231302261
step: 930, loss: 0.14393796026706696
step: 940, loss: 0.14425379037857056
step: 950, loss: 0.0978897288441658
step: 960, loss: 0.2011064738035202
step: 970, loss: 0.06180393323302269
epoch 6: dev_f1=0.9309056956115779, f1=0.925207756232687, best_f1=0.927404718693285
step: 0, loss: 0.16292960941791534
step: 10, loss: 0.0730811133980751
step: 20, loss: 0.033418480306863785
step: 30, loss: 0.04845106229186058
step: 40, loss: 0.10500453412532806
step: 50, loss: 0.050514668226242065
step: 60, loss: 0.09968917816877365
step: 70, loss: 0.06816891580820084
step: 80, loss: 0.10306835919618607
step: 90, loss: 0.05063601955771446
step: 100, loss: 0.06953082978725433
step: 110, loss: 0.045654620975255966
step: 120, loss: 0.11278372257947922
step: 130, loss: 0.11206771433353424
step: 140, loss: 0.13905255496501923
step: 150, loss: 0.07252863049507141
step: 160, loss: 0.08457374572753906
step: 170, loss: 0.12095662206411362
step: 180, loss: 0.09416380524635315
step: 190, loss: 0.1002376526594162
step: 200, loss: 0.20240819454193115
step: 210, loss: 0.08718477189540863
step: 220, loss: 0.05012523755431175
step: 230, loss: 0.0698302611708641
step: 240, loss: 0.09081880003213882
step: 250, loss: 0.16137376427650452
step: 260, loss: 0.03142965957522392
step: 270, loss: 0.04492972418665886
step: 280, loss: 0.11705252528190613
step: 290, loss: 0.20723192393779755
step: 300, loss: 0.1757526695728302
step: 310, loss: 0.18589213490486145
step: 320, loss: 0.06906576454639435
step: 330, loss: 0.08333516120910645
step: 340, loss: 0.1957506388425827
step: 350, loss: 0.05556504428386688
step: 360, loss: 0.06875988095998764
step: 370, loss: 0.14551253616809845
step: 380, loss: 0.08345569670200348
step: 390, loss: 0.1344444304704666
step: 400, loss: 0.1448792666196823
step: 410, loss: 0.10329089313745499
step: 420, loss: 0.10221066325902939
step: 430, loss: 0.06821431964635849
step: 440, loss: 0.12098144739866257
step: 450, loss: 0.10793907195329666
step: 460, loss: 0.16413389146327972
step: 470, loss: 0.08822445571422577
step: 480, loss: 0.10161793231964111
step: 490, loss: 0.00015008616901468486
step: 500, loss: 0.09189727902412415
step: 510, loss: 0.10561799257993698
step: 520, loss: 0.038927145302295685
step: 530, loss: 0.056418754160404205
step: 540, loss: 0.11155977100133896
step: 550, loss: 0.08686374872922897
step: 560, loss: 0.033459942787885666
step: 570, loss: 0.18311633169651031
step: 580, loss: 0.045671433210372925
step: 590, loss: 0.034862447530031204
step: 600, loss: 0.14705093204975128
step: 610, loss: 0.03170279040932655
step: 620, loss: 0.032341357320547104
step: 630, loss: 0.08192450553178787
step: 640, loss: 0.049804747104644775
step: 650, loss: 0.09753504395484924
step: 660, loss: 0.14746199548244476
step: 670, loss: 0.019644087180495262
step: 680, loss: 0.08421523123979568
step: 690, loss: 0.16011950373649597
step: 700, loss: 0.17036089301109314
step: 710, loss: 0.1913544237613678
step: 720, loss: 0.15066172182559967
step: 730, loss: 0.08320047706365585
step: 740, loss: 0.05648809298872948
step: 750, loss: 0.07591533660888672
step: 760, loss: 0.07097194343805313
step: 770, loss: 0.08165499567985535
step: 780, loss: 0.043478187173604965
step: 790, loss: 0.055728279054164886
step: 800, loss: 0.03291911631822586
step: 810, loss: 0.10432903468608856
step: 820, loss: 0.11029741913080215
step: 830, loss: 0.10405366122722626
step: 840, loss: 0.11302202939987183
step: 850, loss: 0.2310539186000824
step: 860, loss: 0.010546472854912281
step: 870, loss: 0.15975095331668854
step: 880, loss: 0.0566067099571228
step: 890, loss: 0.16733379662036896
step: 900, loss: 0.13622130453586578
step: 910, loss: 0.07353098690509796
step: 920, loss: 0.08567642420530319
step: 930, loss: 0.052125364542007446
step: 940, loss: 0.08187883347272873
step: 950, loss: 0.0487113855779171
step: 960, loss: 0.07421620190143585
step: 970, loss: 0.09173007309436798
epoch 7: dev_f1=0.9307832422586522, f1=0.9277326106594399, best_f1=0.927404718693285
step: 0, loss: 0.006365971639752388
step: 10, loss: 0.15181438624858856
step: 20, loss: 0.11078160256147385
step: 30, loss: 0.03492959588766098
step: 40, loss: 0.181649312376976
step: 50, loss: 0.19996784627437592
step: 60, loss: 0.16927261650562286
step: 70, loss: 0.06628188490867615
step: 80, loss: 0.12621062994003296
step: 90, loss: 0.06680607795715332
step: 100, loss: 0.060208410024642944
step: 110, loss: 0.061062440276145935
step: 120, loss: 0.12095849215984344
step: 130, loss: 0.08059760183095932
step: 140, loss: 0.12504151463508606
step: 150, loss: 0.12975086271762848
step: 160, loss: 0.029511498287320137
step: 170, loss: 0.034697216004133224
step: 180, loss: 0.09445051848888397
step: 190, loss: 0.05283726379275322
step: 200, loss: 0.09388835728168488
step: 210, loss: 0.16002538800239563
step: 220, loss: 0.1186637356877327
step: 230, loss: 0.1531815081834793
step: 240, loss: 0.019755467772483826
step: 250, loss: 0.0631917417049408
step: 260, loss: 0.01049780286848545
step: 270, loss: 0.08463509380817413
step: 280, loss: 0.13496318459510803
step: 290, loss: 0.03290986642241478
step: 300, loss: 0.01634993962943554
step: 310, loss: 0.08942311257123947
step: 320, loss: 0.04345948249101639
step: 330, loss: 0.12864215672016144
step: 340, loss: 0.07598625868558884
step: 350, loss: 0.1049049124121666
step: 360, loss: 0.1518477350473404
step: 370, loss: 0.14303025603294373
step: 380, loss: 0.08889342099428177
step: 390, loss: 0.12554976344108582
step: 400, loss: 0.19033460319042206
step: 410, loss: 0.04182641580700874
step: 420, loss: 0.09784417599439621
step: 430, loss: 0.12365397065877914
step: 440, loss: 0.07194224745035172
step: 450, loss: 0.10297975689172745
step: 460, loss: 0.22221042215824127
step: 470, loss: 0.11963385343551636
step: 480, loss: 0.11699575185775757
step: 490, loss: 0.05264996364712715
step: 500, loss: 0.18442831933498383
step: 510, loss: 0.0849093422293663
step: 520, loss: 0.12329268455505371
step: 530, loss: 0.07764413207769394
step: 540, loss: 0.0728195384144783
step: 550, loss: 0.0016805011546239257
step: 560, loss: 0.06508694589138031
step: 570, loss: 0.005564438179135323
step: 580, loss: 0.03999536857008934
step: 590, loss: 0.07078716158866882
step: 600, loss: 0.10381142050027847
step: 610, loss: 0.034059587866067886
step: 620, loss: 0.09368011355400085
step: 630, loss: 0.11069464683532715
step: 640, loss: 0.062154706567525864
step: 650, loss: 0.18331900238990784
step: 660, loss: 0.1026560440659523
step: 670, loss: 0.11007137596607208
step: 680, loss: 0.07009267807006836
step: 690, loss: 0.13207325339317322
step: 700, loss: 0.11073598265647888
step: 710, loss: 0.009493979625403881
step: 720, loss: 0.1265120655298233
step: 730, loss: 0.1327418088912964
step: 740, loss: 0.09228141605854034
step: 750, loss: 0.08175037801265717
step: 760, loss: 0.05629901587963104
step: 770, loss: 0.03653249144554138
step: 780, loss: 0.18927088379859924
step: 790, loss: 0.09484484046697617
step: 800, loss: 0.16337871551513672
step: 810, loss: 0.1002158373594284
step: 820, loss: 0.08742984384298325
step: 830, loss: 0.014180654659867287
step: 840, loss: 0.10713396221399307
step: 850, loss: 0.12698329985141754
step: 860, loss: 0.1420149952173233
step: 870, loss: 0.1940084546804428
step: 880, loss: 0.09486618638038635
step: 890, loss: 0.11614403128623962
step: 900, loss: 0.03966468945145607
step: 910, loss: 0.08987803757190704
step: 920, loss: 0.06533902883529663
step: 930, loss: 0.0492643266916275
step: 940, loss: 0.08672274649143219
step: 950, loss: 0.09291057288646698
step: 960, loss: 0.018865708261728287
step: 970, loss: 0.011034132912755013
epoch 8: dev_f1=0.9247506799637353, f1=0.918358141632837, best_f1=0.927404718693285
step: 0, loss: 0.12157758325338364
step: 10, loss: 0.07391227036714554
step: 20, loss: 0.06292516738176346
step: 30, loss: 0.07411366701126099
step: 40, loss: 0.05104926601052284
step: 50, loss: 0.02809404954314232
step: 60, loss: 0.08308565616607666
step: 70, loss: 0.035477153956890106
step: 80, loss: 0.1016223356127739
step: 90, loss: 0.12608635425567627
step: 100, loss: 0.09451639652252197
step: 110, loss: 0.12182753533124924
step: 120, loss: 0.06312411278486252
step: 130, loss: 0.05332120507955551
step: 140, loss: 0.09479498863220215
step: 150, loss: 0.14858174324035645
step: 160, loss: 0.0512053444981575
step: 170, loss: 0.09699021279811859
step: 180, loss: 0.1559542417526245
step: 190, loss: 0.16603294014930725
step: 200, loss: 0.07443920522928238
step: 210, loss: 0.16003648936748505
step: 220, loss: 0.16051629185676575
step: 230, loss: 0.019543305039405823
step: 240, loss: 0.0810990184545517
step: 250, loss: 0.11385339498519897
step: 260, loss: 0.14253394305706024
step: 270, loss: 0.08011624217033386
step: 280, loss: 0.11164994537830353
step: 290, loss: 0.20142430067062378
step: 300, loss: 0.05787781625986099
step: 310, loss: 0.06270427256822586
step: 320, loss: 0.023678814992308617
step: 330, loss: 0.1543809324502945
step: 340, loss: 0.07699275016784668
step: 350, loss: 0.06151070445775986
step: 360, loss: 0.002022302709519863
step: 370, loss: 0.09091675281524658
step: 380, loss: 0.051131222397089005
step: 390, loss: 0.04436427354812622
step: 400, loss: 0.05782453715801239
step: 410, loss: 0.0937882661819458
step: 420, loss: 0.14545172452926636
step: 430, loss: 0.062298282980918884
step: 440, loss: 0.11054012924432755
step: 450, loss: 0.152802512049675
step: 460, loss: 0.041127197444438934
step: 470, loss: 0.059143878519535065
step: 480, loss: 0.08408501744270325
step: 490, loss: 0.11754659563302994
step: 500, loss: 0.0300169475376606
step: 510, loss: 0.05880287289619446
step: 520, loss: 0.14685150980949402
step: 530, loss: 0.1071428433060646
step: 540, loss: 0.1503024399280548
step: 550, loss: 0.06924180686473846
step: 560, loss: 0.07121361792087555
step: 570, loss: 0.017833510413765907
step: 580, loss: 0.026107825338840485
step: 590, loss: 0.062463607639074326
step: 600, loss: 0.14735808968544006
step: 610, loss: 0.009961588308215141
step: 620, loss: 0.03006470762193203
step: 630, loss: 0.22097665071487427
step: 640, loss: 0.17233087122440338
step: 650, loss: 0.04606034979224205
step: 660, loss: 0.14377394318580627
step: 670, loss: 0.15110032260417938
step: 680, loss: 0.07497353851795197
step: 690, loss: 0.124583899974823
step: 700, loss: 0.09157688915729523
step: 710, loss: 0.03631264716386795
step: 720, loss: 0.1152087152004242
step: 730, loss: 0.18810872733592987
step: 740, loss: 0.05555681139230728
step: 750, loss: 0.07777218520641327
step: 760, loss: 0.12751944363117218
step: 770, loss: 0.3037552237510681
step: 780, loss: 0.22869543731212616
step: 790, loss: 0.07104785740375519
step: 800, loss: 0.06862485408782959
step: 810, loss: 0.20108526945114136
step: 820, loss: 0.05881122127175331
step: 830, loss: 0.15809015929698944
step: 840, loss: 0.10088911652565002
step: 850, loss: 0.07977881282567978
step: 860, loss: 0.12684044241905212
step: 870, loss: 0.08317267149686813
step: 880, loss: 0.0892351046204567
step: 890, loss: 0.09450855106115341
step: 900, loss: 0.047581665217876434
step: 910, loss: 0.13068847358226776
step: 920, loss: 0.029260825365781784
step: 930, loss: 0.08885740488767624
step: 940, loss: 0.09033290296792984
step: 950, loss: 0.02835160493850708
step: 960, loss: 0.024249080568552017
step: 970, loss: 0.0400463230907917
epoch 9: dev_f1=0.9255813953488372, f1=0.9279404927940492, best_f1=0.927404718693285
step: 0, loss: 0.060289084911346436
step: 10, loss: 0.09239830076694489
step: 20, loss: 0.028196612372994423
step: 30, loss: 0.009266993030905724
step: 40, loss: 0.17923739552497864
step: 50, loss: 0.03970832750201225
step: 60, loss: 0.001625691307708621
step: 70, loss: 0.11933419108390808
step: 80, loss: 0.05736300349235535
step: 90, loss: 0.07182038575410843
step: 100, loss: 0.03842625394463539
step: 110, loss: 0.00990340206772089
step: 120, loss: 0.03208991512656212
step: 130, loss: 0.11830487847328186
step: 140, loss: 0.05513089895248413
step: 150, loss: 0.23371417820453644
step: 160, loss: 0.04242194443941116
step: 170, loss: 0.07290460914373398
step: 180, loss: 0.04965701326727867
step: 190, loss: 0.13644979894161224
step: 200, loss: 0.04925093799829483
step: 210, loss: 0.1491551250219345
step: 220, loss: 0.025434521958231926
step: 230, loss: 0.0014341906644403934
step: 240, loss: 0.029043685644865036
step: 250, loss: 0.07979902625083923
step: 260, loss: 0.1333284080028534
step: 270, loss: 0.07607375830411911
step: 280, loss: 0.09859545528888702
step: 290, loss: 0.07027498632669449
step: 300, loss: 0.23890435695648193
step: 310, loss: 0.11855760961771011
step: 320, loss: 0.042812708765268326
step: 330, loss: 0.18481329083442688
step: 340, loss: 0.1167091429233551
step: 350, loss: 0.06264322251081467
step: 360, loss: 0.058060672134160995
step: 370, loss: 0.036541931331157684
step: 380, loss: 0.06947139650583267
step: 390, loss: 0.019865723326802254
step: 400, loss: 0.03646380826830864
step: 410, loss: 0.08556162565946579
step: 420, loss: 0.11267716437578201
step: 430, loss: 0.07000600546598434
step: 440, loss: 0.02054387889802456
step: 450, loss: 0.08133472502231598
step: 460, loss: 0.07820156216621399
step: 470, loss: 0.01634887233376503
step: 480, loss: 0.15240958333015442
step: 490, loss: 0.1232374832034111
step: 500, loss: 0.11699914932250977
step: 510, loss: 0.04795175418257713
step: 520, loss: 0.15331734716892242
step: 530, loss: 0.03809541463851929
step: 540, loss: 0.029377084225416183
step: 550, loss: 0.027218684554100037
step: 560, loss: 0.22304709255695343
step: 570, loss: 0.20679643750190735
step: 580, loss: 0.08456110209226608
step: 590, loss: 0.019194316118955612
step: 600, loss: 0.1058606207370758
step: 610, loss: 0.0812404528260231
step: 620, loss: 0.06357404589653015
step: 630, loss: 0.06518092751502991
step: 640, loss: 0.04425167292356491
step: 650, loss: 0.04053478688001633
step: 660, loss: 0.029771151021122932
step: 670, loss: 0.17027971148490906
step: 680, loss: 0.09508418291807175
step: 690, loss: 0.08530581742525101
step: 700, loss: 0.068929523229599
step: 710, loss: 0.042973946779966354
step: 720, loss: 0.08854696154594421
step: 730, loss: 0.0488419272005558
step: 740, loss: 0.08082106709480286
step: 750, loss: 0.08829315751791
step: 760, loss: 0.12800320982933044
step: 770, loss: 0.04096563160419464
step: 780, loss: 0.10991255939006805
step: 790, loss: 0.1373225450515747
step: 800, loss: 0.14556539058685303
step: 810, loss: 0.14818981289863586
step: 820, loss: 0.15511156618595123
step: 830, loss: 0.10466232895851135
step: 840, loss: 0.05069653317332268
step: 850, loss: 0.054653167724609375
step: 860, loss: 0.03486548364162445
step: 870, loss: 0.05825568735599518
step: 880, loss: 0.025708628818392754
step: 890, loss: 0.03840608149766922
step: 900, loss: 0.08483228087425232
step: 910, loss: 0.16477566957473755
step: 920, loss: 0.07532160729169846
step: 930, loss: 0.02113047055900097
step: 940, loss: 0.11805427819490433
step: 950, loss: 0.03989894688129425
step: 960, loss: 0.005632689222693443
step: 970, loss: 0.06804041564464569
epoch 10: dev_f1=0.9280442804428044, f1=0.9299771167048057, best_f1=0.927404718693285
step: 0, loss: 0.08351653069257736
step: 10, loss: 0.13255538046360016
step: 20, loss: 0.12410306930541992
step: 30, loss: 0.08922766149044037
step: 40, loss: 0.17910104990005493
step: 50, loss: 0.06823078542947769
step: 60, loss: 0.10188353806734085
step: 70, loss: 0.1014869213104248
step: 80, loss: 0.0915643572807312
step: 90, loss: 0.11159349232912064
step: 100, loss: 0.08089618384838104
step: 110, loss: 0.03396356478333473
step: 120, loss: 0.09428609162569046
step: 130, loss: 0.019819024950265884
step: 140, loss: 0.029769081622362137
step: 150, loss: 0.023914452642202377
step: 160, loss: 0.05943107232451439
step: 170, loss: 0.15871202945709229
step: 180, loss: 0.050524912774562836
step: 190, loss: 0.04558328539133072
step: 200, loss: 0.0891776755452156
step: 210, loss: 0.04050198569893837
step: 220, loss: 0.09275127202272415
step: 230, loss: 0.25080713629722595
step: 240, loss: 0.13916940987110138
step: 250, loss: 0.024158397689461708
step: 260, loss: 0.01360639650374651
step: 270, loss: 0.07599887251853943
step: 280, loss: 0.07005700469017029
step: 290, loss: 0.035127636045217514
step: 300, loss: 0.025909796357154846
step: 310, loss: 0.13655388355255127
step: 320, loss: 0.12309706211090088
step: 330, loss: 0.08675165474414825
step: 340, loss: 0.12959803640842438
step: 350, loss: 0.3034186065196991
step: 360, loss: 0.0705963745713234
step: 370, loss: 0.0028006916400045156
step: 380, loss: 0.14306405186653137
step: 390, loss: 0.22606420516967773
step: 400, loss: 0.2050696760416031
step: 410, loss: 0.07910943031311035
step: 420, loss: 0.08699992299079895
step: 430, loss: 0.06311395764350891
step: 440, loss: 0.05325893685221672
step: 450, loss: 0.04986494407057762
step: 460, loss: 0.05286739766597748
step: 470, loss: 0.07770197093486786
step: 480, loss: 0.10685210675001144
step: 490, loss: 0.05721025913953781
step: 500, loss: 0.04166068136692047
step: 510, loss: 0.05827660113573074
step: 520, loss: 0.09481514990329742
step: 530, loss: 0.13866542279720306
step: 540, loss: 0.08610982447862625
step: 550, loss: 0.08508455008268356
step: 560, loss: 0.1444922834634781
step: 570, loss: 0.09481443464756012
step: 580, loss: 1.4379475032910705e-05
step: 590, loss: 0.1441655158996582
step: 600, loss: 0.07370664179325104
step: 610, loss: 0.048030540347099304
step: 620, loss: 0.06954595446586609
step: 630, loss: 0.05225888267159462
step: 640, loss: 0.045464158058166504
step: 650, loss: 0.08712417632341385
step: 660, loss: 0.07339811325073242
step: 670, loss: 0.03561043366789818
step: 680, loss: 0.0835014283657074
step: 690, loss: 0.06803975999355316
step: 700, loss: 0.03825794905424118
step: 710, loss: 0.07252353429794312
step: 720, loss: 0.13022837042808533
step: 730, loss: 0.03668076545000076
step: 740, loss: 0.060494858771562576
step: 750, loss: 0.21421921253204346
step: 760, loss: 0.06758909672498703
step: 770, loss: 0.04534921050071716
step: 780, loss: 0.002978574950248003
step: 790, loss: 0.04748762398958206
step: 800, loss: 0.05129826068878174
step: 810, loss: 0.07944335788488388
step: 820, loss: 0.06969356536865234
step: 830, loss: 0.10878612101078033
step: 840, loss: 0.10060444474220276
step: 850, loss: 0.06437582522630692
step: 860, loss: 0.08127380907535553
step: 870, loss: 0.017189646139740944
step: 880, loss: 0.15059593319892883
step: 890, loss: 0.002833582693710923
step: 900, loss: 0.08196697384119034
step: 910, loss: 0.07769431173801422
step: 920, loss: 0.048944707959890366
step: 930, loss: 0.007954715751111507
step: 940, loss: 0.06397604197263718
step: 950, loss: 0.01495411153882742
step: 960, loss: 0.026930952444672585
step: 970, loss: 0.12012837082147598
epoch 11: dev_f1=0.923923006416132, f1=0.9227957971676565, best_f1=0.927404718693285
step: 0, loss: 0.02972804754972458
step: 10, loss: 0.07516222447156906
step: 20, loss: 0.04994278401136398
step: 30, loss: 0.043271537870168686
step: 40, loss: 0.0424673967063427
step: 50, loss: 0.059392381459474564
step: 60, loss: 0.025949494913220406
step: 70, loss: 0.06767726689577103
step: 80, loss: 0.06272167712450027
step: 90, loss: 0.056161586195230484
step: 100, loss: 0.11411932855844498
step: 110, loss: 0.1510692983865738
step: 120, loss: 0.06402187049388885
step: 130, loss: 0.040456000715494156
step: 140, loss: 0.10057943314313889
step: 150, loss: 0.028033938258886337
step: 160, loss: 0.045121341943740845
step: 170, loss: 0.07960014790296555
step: 180, loss: 0.023368315771222115
step: 190, loss: 0.03289074823260307
step: 200, loss: 0.06245410069823265
step: 210, loss: 0.008671393617987633
step: 220, loss: 0.02770119160413742
step: 230, loss: 0.08952416479587555
step: 240, loss: 0.2027023732662201
step: 250, loss: 0.03476940095424652
step: 260, loss: 0.09904796630144119
step: 270, loss: 0.16594763100147247
step: 280, loss: 0.06494016200304031
step: 290, loss: 0.1291576325893402
step: 300, loss: 0.07978302240371704
step: 310, loss: 0.06442645192146301
step: 320, loss: 0.03994521126151085
step: 330, loss: 0.057638753205537796
step: 340, loss: 0.004772714804857969
step: 350, loss: 0.07383330911397934
step: 360, loss: 0.05534304305911064
step: 370, loss: 0.1003323495388031
step: 380, loss: 0.02973484992980957
step: 390, loss: 0.029204033315181732
step: 400, loss: 0.018316293135285378
step: 410, loss: 0.12126951664686203
step: 420, loss: 0.04757864773273468
step: 430, loss: 0.0437912754714489
step: 440, loss: 0.09597271680831909
step: 450, loss: 0.0630277544260025
step: 460, loss: 0.049793027341365814
step: 470, loss: 0.040212783962488174
step: 480, loss: 0.12192067503929138
step: 490, loss: 0.043315667659044266
step: 500, loss: 0.09536148607730865
step: 510, loss: 0.09993832558393478
step: 520, loss: 0.1132613942027092
step: 530, loss: 0.10316019505262375
step: 540, loss: 0.03105878084897995
step: 550, loss: 0.0731959193944931
step: 560, loss: 0.0696788877248764
step: 570, loss: 0.030282985419034958
step: 580, loss: 0.03580459579825401
step: 590, loss: 0.1442483812570572
step: 600, loss: 0.023137152194976807
step: 610, loss: 0.10374189168214798
step: 620, loss: 0.09681025892496109
step: 630, loss: 0.02682630531489849
step: 640, loss: 0.029849378392100334
step: 650, loss: 0.10550037771463394
step: 660, loss: 0.0819719061255455
step: 670, loss: 0.02619551308453083
step: 680, loss: 0.12103938311338425
step: 690, loss: 0.04334906116127968
step: 700, loss: 0.12391731142997742
step: 710, loss: 0.05217522755265236
step: 720, loss: 0.14374080300331116
step: 730, loss: 0.08812075108289719
step: 740, loss: 0.15496672689914703
step: 750, loss: 0.04495396092534065
step: 760, loss: 0.036543045192956924
step: 770, loss: 0.061277005821466446
step: 780, loss: 0.11116625368595123
step: 790, loss: 0.036717310547828674
step: 800, loss: 0.06687325984239578
step: 810, loss: 0.015154166147112846
step: 820, loss: 0.027039209380745888
step: 830, loss: 0.05822368338704109
step: 840, loss: 0.06274164468050003
step: 850, loss: 0.00032761620241217315
step: 860, loss: 0.057508133351802826
step: 870, loss: 0.12136752903461456
step: 880, loss: 0.08270326256752014
step: 890, loss: 0.07053714245557785
step: 900, loss: 0.06705538183450699
step: 910, loss: 0.054322417825460434
step: 920, loss: 0.029416751116514206
step: 930, loss: 0.08900734037160873
step: 940, loss: 0.09431465715169907
step: 950, loss: 0.027167925611138344
step: 960, loss: 0.04434742033481598
step: 970, loss: 0.05663924291729927
epoch 12: dev_f1=0.9186155285313378, f1=0.9202797202797203, best_f1=0.927404718693285
step: 0, loss: 0.10227902233600616
step: 10, loss: 0.06452351808547974
step: 20, loss: 0.018700817599892616
step: 30, loss: 0.09781651198863983
step: 40, loss: 0.05045296251773834
step: 50, loss: 0.05932525917887688
step: 60, loss: 0.026834530755877495
step: 70, loss: 0.01464479137212038
step: 80, loss: 0.06043611094355583
step: 90, loss: 0.04570116475224495
step: 100, loss: 0.1392410397529602
step: 110, loss: 0.07926233112812042
step: 120, loss: 0.054659754037857056
step: 130, loss: 0.012268366292119026
step: 140, loss: 0.06209532916545868
step: 150, loss: 0.06358093023300171
step: 160, loss: 0.08195477724075317
step: 170, loss: 0.19244064390659332
step: 180, loss: 0.09358679503202438
step: 190, loss: 0.030974768102169037
step: 200, loss: 0.017480548471212387
step: 210, loss: 0.04280153289437294
step: 220, loss: 0.03763801231980324
step: 230, loss: 0.0672050416469574
step: 240, loss: 0.05339149013161659
step: 250, loss: 0.012883927673101425
step: 260, loss: 0.022466909140348434
step: 270, loss: 0.014229139313101768
step: 280, loss: 0.05265548825263977
step: 290, loss: 0.09660378843545914
step: 300, loss: 0.09307121485471725
step: 310, loss: 0.08997336030006409
step: 320, loss: 0.01588841900229454
step: 330, loss: 0.025873150676488876
step: 340, loss: 0.07928790897130966
step: 350, loss: 0.05113772675395012
step: 360, loss: 0.02722577378153801
step: 370, loss: 0.024344811215996742
step: 380, loss: 0.034477654844522476
step: 390, loss: 0.05337178334593773
step: 400, loss: 0.11060161143541336
step: 410, loss: 0.00040417909622192383
step: 420, loss: 0.03208598867058754
step: 430, loss: 0.08351460099220276
step: 440, loss: 0.17931950092315674
step: 450, loss: 0.047300804406404495
step: 460, loss: 0.08943886309862137
step: 470, loss: 0.0431518591940403
step: 480, loss: 0.14140674471855164
step: 490, loss: 0.037619490176439285
step: 500, loss: 0.02210244908928871
step: 510, loss: 0.0003368002362549305
step: 520, loss: 0.08803161233663559
step: 530, loss: 0.035419680178165436
step: 540, loss: 0.1326177716255188
step: 550, loss: 0.12092605233192444
step: 560, loss: 0.01733315736055374
step: 570, loss: 0.19698886573314667
step: 580, loss: 0.07732316106557846
step: 590, loss: 0.04305559769272804
step: 600, loss: 0.13533763587474823
step: 610, loss: 0.12560151517391205
step: 620, loss: 0.05380573868751526
step: 630, loss: 0.033569082617759705
step: 640, loss: 0.17064279317855835
step: 650, loss: 0.07634423673152924
step: 660, loss: 0.09813366830348969
step: 670, loss: 0.21129003167152405
step: 680, loss: 0.05118391290307045
step: 690, loss: 0.19404062628746033
step: 700, loss: 0.012946262024343014
step: 710, loss: 0.09737555682659149
step: 720, loss: 0.13651114702224731
step: 730, loss: 0.243087500333786
step: 740, loss: 0.049230434000492096
step: 750, loss: 0.06568103283643723
step: 760, loss: 0.07588668167591095
step: 770, loss: 0.046725593507289886
step: 780, loss: 0.09961973875761032
step: 790, loss: 0.07082986831665039
step: 800, loss: 0.10476420074701309
step: 810, loss: 0.08429747074842453
step: 820, loss: 0.008174438960850239
step: 830, loss: 0.06456787884235382
step: 840, loss: 0.007545472122728825
step: 850, loss: 0.06739345192909241
step: 860, loss: 0.08200006186962128
step: 870, loss: 0.09388318657875061
step: 880, loss: 0.05235809087753296
step: 890, loss: 0.08752290904521942
step: 900, loss: 0.0842483639717102
step: 910, loss: 0.15923745930194855
step: 920, loss: 0.006676648277789354
step: 930, loss: 0.06606563925743103
step: 940, loss: 0.09307791292667389
step: 950, loss: 0.10698530822992325
step: 960, loss: 0.06030298396945
step: 970, loss: 0.042754631489515305
epoch 13: dev_f1=0.9254004576659038, f1=0.9243466299862448, best_f1=0.927404718693285
step: 0, loss: 0.06544743478298187
step: 10, loss: 0.06554323434829712
step: 20, loss: 0.04764142259955406
step: 30, loss: 0.06713370233774185
step: 40, loss: 0.09498979151248932
step: 50, loss: 0.019669191911816597
step: 60, loss: 0.06966985017061234
step: 70, loss: 0.11148626357316971
step: 80, loss: 0.039666686207056046
step: 90, loss: 0.03458211570978165
step: 100, loss: 0.03904673457145691
step: 110, loss: 0.05746309459209442
step: 120, loss: 0.04421060159802437
step: 130, loss: 0.00843435525894165
step: 140, loss: 0.020516421645879745
step: 150, loss: 0.05445803329348564
step: 160, loss: 0.02567584067583084
step: 170, loss: 0.07358965277671814
step: 180, loss: 0.011485973373055458
step: 190, loss: 0.04014667868614197
step: 200, loss: 0.02395508624613285
step: 210, loss: 0.04780624806880951
step: 220, loss: 0.03189767524600029
step: 230, loss: 0.0641576424241066
step: 240, loss: 0.07173211127519608
step: 250, loss: 0.08726604282855988
step: 260, loss: 0.006370821036398411
step: 270, loss: 0.18454451858997345
step: 280, loss: 0.04145696759223938
step: 290, loss: 0.06775686889886856
step: 300, loss: 0.03800506517291069
step: 310, loss: 0.03432746231555939
step: 320, loss: 0.017268681898713112
step: 330, loss: 0.09685061872005463
step: 340, loss: 0.030048973858356476
step: 350, loss: 0.03596171364188194
step: 360, loss: 0.05076306313276291
step: 370, loss: 0.024179082363843918
step: 380, loss: 0.04613344743847847
step: 390, loss: 0.06028514727950096
step: 400, loss: 0.05897502973675728
step: 410, loss: 0.0721680223941803
step: 420, loss: 0.10458824038505554
step: 430, loss: 0.03862498328089714
step: 440, loss: 0.0223633274435997
step: 450, loss: 0.008482304401695728
step: 460, loss: 0.1314716339111328
step: 470, loss: 0.06453561782836914
step: 480, loss: 0.022634543478488922
step: 490, loss: 0.1485876441001892
step: 500, loss: 0.08463647961616516
step: 510, loss: 0.016185717657208443
step: 520, loss: 0.059448570013046265
step: 530, loss: 0.06266816705465317
step: 540, loss: 0.1491578370332718
step: 550, loss: 0.03532090038061142
step: 560, loss: 0.06381666660308838
step: 570, loss: 0.17670898139476776
step: 580, loss: 0.06806215643882751
step: 590, loss: 0.030062945559620857
step: 600, loss: 0.05992456525564194
step: 610, loss: 0.0919991284608841
step: 620, loss: 0.12273571640253067
step: 630, loss: 0.08115486800670624
step: 640, loss: 0.04618954658508301
step: 650, loss: 0.07012148946523666
step: 660, loss: 0.12575824558734894
step: 670, loss: 0.047317024320364
step: 680, loss: 0.09090502560138702
step: 690, loss: 0.020529957488179207
step: 700, loss: 0.17722517251968384
step: 710, loss: 0.08585327863693237
step: 720, loss: 0.07679957151412964
step: 730, loss: 0.052511099725961685
step: 740, loss: 0.09507059305906296
step: 750, loss: 0.04013391584157944
step: 760, loss: 0.004613109864294529
step: 770, loss: 0.06010431423783302
step: 780, loss: 0.07467780262231827
step: 790, loss: 0.05364920198917389
step: 800, loss: 0.0701088160276413
step: 810, loss: 0.0025736147072166204
step: 820, loss: 0.10562023520469666
step: 830, loss: 0.035866182297468185
step: 840, loss: 0.03765740618109703
step: 850, loss: 0.1235312968492508
step: 860, loss: 0.006671003066003323
step: 870, loss: 0.05775441229343414
step: 880, loss: 0.13452373445034027
step: 890, loss: 0.037632398307323456
step: 900, loss: 0.19090962409973145
step: 910, loss: 0.103092722594738
step: 920, loss: 0.053016018122434616
step: 930, loss: 0.052721086889505386
step: 940, loss: 0.09470323473215103
step: 950, loss: 0.010334857739508152
step: 960, loss: 0.010755877010524273
step: 970, loss: 0.08946480602025986
epoch 14: dev_f1=0.9250814332247558, f1=0.9288354898336414, best_f1=0.927404718693285
step: 0, loss: 0.09615868330001831
step: 10, loss: 0.04745247960090637
step: 20, loss: 0.05449080094695091
step: 30, loss: 0.0333341620862484
step: 40, loss: 0.020777100697159767
step: 50, loss: 0.049390632659196854
step: 60, loss: 0.0010836002184078097
step: 70, loss: 0.039061419665813446
step: 80, loss: 0.10609549283981323
step: 90, loss: 0.009087634272873402
step: 100, loss: 0.06801634281873703
step: 110, loss: 0.14431710541248322
step: 120, loss: 0.01855354756116867
step: 130, loss: 0.12322694063186646
step: 140, loss: 0.04768935590982437
step: 150, loss: 0.038873277604579926
step: 160, loss: 0.028355423361063004
step: 170, loss: 0.031261276453733444
step: 180, loss: 0.02938859909772873
step: 190, loss: 0.25559890270233154
step: 200, loss: 0.0600467324256897
step: 210, loss: 0.013779187574982643
step: 220, loss: 0.1372905671596527
step: 230, loss: 0.0471220500767231
step: 240, loss: 0.013746364042162895
step: 250, loss: 0.05366044491529465
step: 260, loss: 0.0203823484480381
step: 270, loss: 0.011075835675001144
step: 280, loss: 0.06730765849351883
step: 290, loss: 0.1449720859527588
step: 300, loss: 0.17680107057094574
step: 310, loss: 0.021353932097554207
step: 320, loss: 0.1936187595129013
step: 330, loss: 0.026506073772907257
step: 340, loss: 0.035961784422397614
step: 350, loss: 0.0160331092774868
step: 360, loss: 0.05752610042691231
step: 370, loss: 0.12820158898830414
step: 380, loss: 0.13842688500881195
step: 390, loss: 0.058562710881233215
step: 400, loss: 0.12418954819440842
step: 410, loss: 0.051918432116508484
step: 420, loss: 0.060428436845541
step: 430, loss: 0.05563027411699295
step: 440, loss: 0.022874340415000916
step: 450, loss: 0.052586138248443604
step: 460, loss: 0.03347024321556091
step: 470, loss: 0.13047011196613312
step: 480, loss: 0.042746204882860184
step: 490, loss: 0.09305673837661743
step: 500, loss: 0.090237557888031
step: 510, loss: 0.09433498978614807
step: 520, loss: 0.03669362515211105
step: 530, loss: 0.08571621775627136
step: 540, loss: 0.021768899634480476
step: 550, loss: 0.036190133541822433
step: 560, loss: 0.052812013775110245
step: 570, loss: 0.08387186378240585
step: 580, loss: 0.10466884076595306
step: 590, loss: 0.027391131967306137
step: 600, loss: 0.059201233088970184
step: 610, loss: 0.01177990436553955
step: 620, loss: 0.08740468323230743
step: 630, loss: 0.06942012161016464
step: 640, loss: 0.038820937275886536
step: 650, loss: 0.013540206477046013
step: 660, loss: 0.03456506505608559
step: 670, loss: 0.1432928740978241
step: 680, loss: 0.048849061131477356
step: 690, loss: 0.0869782418012619
step: 700, loss: 0.016555432230234146
step: 710, loss: 0.01098050270229578
step: 720, loss: 0.053142763674259186
step: 730, loss: 0.0720701813697815
step: 740, loss: 0.10011685639619827
step: 750, loss: 0.03204590082168579
step: 760, loss: 2.534624763939064e-05
step: 770, loss: 0.0785536840558052
step: 780, loss: 0.058227114379405975
step: 790, loss: 0.058933764696121216
step: 800, loss: 0.005359860137104988
step: 810, loss: 0.054872527718544006
step: 820, loss: 0.015934843569993973
step: 830, loss: 0.03791813179850578
step: 840, loss: 0.0026755868457257748
step: 850, loss: 0.06397183984518051
step: 860, loss: 0.09717673808336258
step: 870, loss: 0.07743993401527405
step: 880, loss: 0.014681094326078892
step: 890, loss: 0.14401206374168396
step: 900, loss: 0.0567123144865036
step: 910, loss: 0.1362789124250412
step: 920, loss: 0.14842890202999115
step: 930, loss: 0.0491572842001915
step: 940, loss: 0.10119891911745071
step: 950, loss: 0.003380566369742155
step: 960, loss: 0.022182263433933258
step: 970, loss: 0.11113930493593216
epoch 15: dev_f1=0.9244935543278084, f1=0.9297597042513862, best_f1=0.927404718693285
step: 0, loss: 0.007178441621363163
step: 10, loss: 0.019735118374228477
step: 20, loss: 0.05696675181388855
step: 30, loss: 0.07602895051240921
step: 40, loss: 0.023134412243962288
step: 50, loss: 0.08226657658815384
step: 60, loss: 0.07208584994077682
step: 70, loss: 0.07180318236351013
step: 80, loss: 0.037847451865673065
step: 90, loss: 0.016407819464802742
step: 100, loss: 0.06511130928993225
step: 110, loss: 0.044583167880773544
step: 120, loss: 0.025583893060684204
step: 130, loss: 0.03922349214553833
step: 140, loss: 0.12382054328918457
step: 150, loss: 0.05520593374967575
step: 160, loss: 0.056978773325681686
step: 170, loss: 0.048255693167448044
step: 180, loss: 0.04048594459891319
step: 190, loss: 0.019230321049690247
step: 200, loss: 0.043887555599212646
step: 210, loss: 0.023044614121317863
step: 220, loss: 0.03529733791947365
step: 230, loss: 0.0009473569807596505
step: 240, loss: 0.07237981259822845
step: 250, loss: 0.028599966317415237
step: 260, loss: 0.06631997972726822
step: 270, loss: 0.0004755084228236228
step: 280, loss: 0.0747859925031662
step: 290, loss: 0.11038503050804138
step: 300, loss: 0.0519111193716526
step: 310, loss: 0.08285325765609741
step: 320, loss: 0.03589080274105072
step: 330, loss: 0.016525495797395706
step: 340, loss: 0.05264104902744293
step: 350, loss: 0.029003778472542763
step: 360, loss: 0.10691637545824051
step: 370, loss: 0.02553940750658512
step: 380, loss: 0.07681514322757721
step: 390, loss: 0.0250073429197073
step: 400, loss: 0.03376547619700432
step: 410, loss: 0.04970302805304527
step: 420, loss: 0.053500931710004807
step: 430, loss: 0.011232011020183563
step: 440, loss: 0.04201589897274971
step: 450, loss: 0.11062055081129074
step: 460, loss: 0.15683040022850037
step: 470, loss: 0.020780859515070915
step: 480, loss: 0.036372147500514984
step: 490, loss: 0.06451499462127686
step: 500, loss: 0.029881644994020462
step: 510, loss: 0.06698982417583466
step: 520, loss: 0.027091441676020622
step: 530, loss: 0.05429324880242348
step: 540, loss: 0.026852643117308617
step: 550, loss: 0.08955968916416168
step: 560, loss: 0.026631023734807968
step: 570, loss: 0.07582934945821762
step: 580, loss: 0.06836040318012238
step: 590, loss: 0.07048135995864868
step: 600, loss: 0.022039176896214485
step: 610, loss: 0.018994972109794617
step: 620, loss: 0.06012757495045662
step: 630, loss: 0.07583173364400864
step: 640, loss: 0.06049797683954239
step: 650, loss: 0.0012688325950875878
step: 660, loss: 0.022891031578183174
step: 670, loss: 0.0319274477660656
step: 680, loss: 0.05560160055756569
step: 690, loss: 0.09687743335962296
step: 700, loss: 0.04075436294078827
step: 710, loss: 0.0274929441511631
step: 720, loss: 0.0053211841732263565
step: 730, loss: 0.034769456833601
step: 740, loss: 0.043160732835531235
step: 750, loss: 0.018536917865276337
step: 760, loss: 0.056816354393959045
step: 770, loss: 0.023536287248134613
step: 780, loss: 0.09204775840044022
step: 790, loss: 0.08867094665765762
step: 800, loss: 0.020940307527780533
step: 810, loss: 0.02526911161839962
step: 820, loss: 0.11393214762210846
step: 830, loss: 0.11679051071405411
step: 840, loss: 0.007067055441439152
step: 850, loss: 0.07278604060411453
step: 860, loss: 0.04312143847346306
step: 870, loss: 0.04744834825396538
step: 880, loss: 0.054680418223142624
step: 890, loss: 0.009924821555614471
step: 900, loss: 0.052374523133039474
step: 910, loss: 0.06051882356405258
step: 920, loss: 0.17206479609012604
step: 930, loss: 0.08438941091299057
step: 940, loss: 0.13825130462646484
step: 950, loss: 0.07455111294984818
step: 960, loss: 0.15334351360797882
step: 970, loss: 0.05030184984207153
epoch 16: dev_f1=0.9245194561650257, f1=0.9226441631504922, best_f1=0.927404718693285
step: 0, loss: 0.019272061064839363
step: 10, loss: 0.08393705636262894
step: 20, loss: 0.038470327854156494
step: 30, loss: 0.04935704171657562
step: 40, loss: 0.14270387589931488
step: 50, loss: 0.057885974645614624
step: 60, loss: 0.050528060644865036
step: 70, loss: 0.060559626668691635
step: 80, loss: 0.03025774098932743
step: 90, loss: 0.08450541645288467
step: 100, loss: 0.0509582981467247
step: 110, loss: 0.07849983870983124
step: 120, loss: 0.11874683201313019
step: 130, loss: 0.010043851099908352
step: 140, loss: 0.037348587065935135
step: 150, loss: 0.0677504613995552
step: 160, loss: 0.052778974175453186
step: 170, loss: 0.0798419788479805
step: 180, loss: 0.11531433463096619
step: 190, loss: 0.042765725404024124
step: 200, loss: 0.0002248268574476242
step: 210, loss: 0.002065539127215743
step: 220, loss: 0.08981786668300629
step: 230, loss: 0.03979143872857094
step: 240, loss: 0.03875300660729408
step: 250, loss: 0.0441257618367672
step: 260, loss: 0.05034264177083969
step: 270, loss: 0.05935543775558472
step: 280, loss: 0.049099188297986984
step: 290, loss: 0.08106604963541031
step: 300, loss: 0.039919164031744
step: 310, loss: 0.042012039572000504
step: 320, loss: 0.12366515398025513
step: 330, loss: 0.0010566703276708722
step: 340, loss: 0.07317254692316055
step: 350, loss: 0.07540743798017502
step: 360, loss: 0.09946182370185852
step: 370, loss: 0.05124107748270035
step: 380, loss: 0.025021018460392952
step: 390, loss: 0.08793079853057861
step: 400, loss: 0.00044038324267603457
step: 410, loss: 0.0356631726026535
step: 420, loss: 0.033492833375930786
step: 430, loss: 0.009960491210222244
step: 440, loss: 0.027442924678325653
step: 450, loss: 0.015201916918158531
step: 460, loss: 0.06163754314184189
step: 470, loss: 0.05799509212374687
step: 480, loss: 7.358272705459967e-05
step: 490, loss: 0.00031909203971736133
step: 500, loss: 0.015013078227639198
step: 510, loss: 0.041103389114141464
step: 520, loss: 0.05844675377011299
step: 530, loss: 0.08393478393554688
step: 540, loss: 0.08698973804712296
step: 550, loss: 0.08913970738649368
step: 560, loss: 0.046461429446935654
step: 570, loss: 0.04505530372262001
step: 580, loss: 0.03563162311911583
step: 590, loss: 0.11208958923816681
step: 600, loss: 0.0313364677131176
step: 610, loss: 0.034670550376176834
step: 620, loss: 0.07957254350185394
step: 630, loss: 0.17708860337734222
step: 640, loss: 0.027449985966086388
step: 650, loss: 0.014506972394883633
step: 660, loss: 0.021604813635349274
step: 670, loss: 0.07780994474887848
step: 680, loss: 0.07866470515727997
step: 690, loss: 0.037322089076042175
step: 700, loss: 0.18071497976779938
step: 710, loss: 0.011541115120053291
step: 720, loss: 0.030074991285800934
step: 730, loss: 0.09686806797981262
step: 740, loss: 0.0010960239451378584
step: 750, loss: 1.7660811863606796e-05
step: 760, loss: 0.058481764048337936
step: 770, loss: 0.044400736689567566
step: 780, loss: 0.042642638087272644
step: 790, loss: 0.030186912044882774
step: 800, loss: 0.029796913266181946
step: 810, loss: 0.004635080229490995
step: 820, loss: 0.10545575618743896
step: 830, loss: 0.0380881205201149
step: 840, loss: 0.014333568513393402
step: 850, loss: 0.029505548998713493
step: 860, loss: 0.015401511453092098
step: 870, loss: 0.0494425930082798
step: 880, loss: 0.07462816685438156
step: 890, loss: 0.041638050228357315
step: 900, loss: 0.04665321856737137
step: 910, loss: 0.06435151398181915
step: 920, loss: 0.11004158854484558
step: 930, loss: 0.022664330899715424
step: 940, loss: 0.00404787715524435
step: 950, loss: 0.026096822693943977
step: 960, loss: 0.016696101054549217
step: 970, loss: 0.038116808980703354
epoch 17: dev_f1=0.9251764705882354, f1=0.922859830667921, best_f1=0.927404718693285
step: 0, loss: 0.06779095530509949
step: 10, loss: 0.07487441599369049
step: 20, loss: 0.021030832082033157
step: 30, loss: 0.06024746596813202
step: 40, loss: 0.06145443022251129
step: 50, loss: 0.05093880742788315
step: 60, loss: 0.09741322696208954
step: 70, loss: 0.0007028690306469798
step: 80, loss: 0.05961696058511734
step: 90, loss: 0.0948353186249733
step: 100, loss: 0.024025019258260727
step: 110, loss: 0.10933171957731247
step: 120, loss: 0.017626119777560234
step: 130, loss: 0.0043992758728563786
step: 140, loss: 0.05560524761676788
step: 150, loss: 0.0703219547867775
step: 160, loss: 0.1252327561378479
step: 170, loss: 0.03341243043541908
step: 180, loss: 0.02355043776333332
step: 190, loss: 0.10452312976121902
step: 200, loss: 0.0430821068584919
step: 210, loss: 0.04065578058362007
step: 220, loss: 0.02381458878517151
step: 230, loss: 0.12945234775543213
step: 240, loss: 0.04363899305462837
step: 250, loss: 0.052994925528764725
step: 260, loss: 0.029958829283714294
step: 270, loss: 0.02463059313595295
step: 280, loss: 0.048380665481090546
step: 290, loss: 0.019782235845923424
step: 300, loss: 0.06101482734084129
step: 310, loss: 0.01230156421661377
step: 320, loss: 0.03976798802614212
step: 330, loss: 0.022480588406324387
step: 340, loss: 0.09664356708526611
step: 350, loss: 0.04372407868504524
step: 360, loss: 0.023085633292794228
step: 370, loss: 0.02950320951640606
step: 380, loss: 0.027054378762841225
step: 390, loss: 0.019894249737262726
step: 400, loss: 0.03784946724772453
step: 410, loss: 0.0633486807346344
step: 420, loss: 0.0073032379150390625
step: 430, loss: 0.05550624430179596
step: 440, loss: 0.08301682770252228
step: 450, loss: 0.03362962603569031
step: 460, loss: 0.0218794047832489
step: 470, loss: 0.0941210612654686
step: 480, loss: 0.05954273045063019
step: 490, loss: 0.02833222784101963
step: 500, loss: 0.06922760605812073
step: 510, loss: 0.10924730449914932
step: 520, loss: 0.0048399013467133045
step: 530, loss: 0.015387050807476044
step: 540, loss: 0.027236470952630043
step: 550, loss: 0.01775253936648369
step: 560, loss: 0.086358442902565
step: 570, loss: 0.10858936607837677
step: 580, loss: 0.024588318541646004
step: 590, loss: 0.07422102242708206
step: 600, loss: 0.017355766147375107
step: 610, loss: 0.03321249783039093
step: 620, loss: 0.01170277502387762
step: 630, loss: 0.020897556096315384
step: 640, loss: 0.015858611091971397
step: 650, loss: 0.04861073195934296
step: 660, loss: 0.12289226055145264
step: 670, loss: 0.09789624065160751
step: 680, loss: 0.052324432879686356
step: 690, loss: 0.11094627529382706
step: 700, loss: 0.05739868804812431
step: 710, loss: 0.0495668388903141
step: 720, loss: 0.03980228304862976
step: 730, loss: 0.05811949074268341
step: 740, loss: 0.014608139172196388
step: 750, loss: 4.061422441736795e-05
step: 760, loss: 0.025770805776119232
step: 770, loss: 0.03640275076031685
step: 780, loss: 0.053071532398462296
step: 790, loss: 0.043359700590372086
step: 800, loss: 0.1432695984840393
step: 810, loss: 0.08134840428829193
step: 820, loss: 0.06632497161626816
step: 830, loss: 0.10306180268526077
step: 840, loss: 0.050931982696056366
step: 850, loss: 0.09155779331922531
step: 860, loss: 0.0400456003844738
step: 870, loss: 0.15164974331855774
step: 880, loss: 0.01911146752536297
step: 890, loss: 0.03165069967508316
step: 900, loss: 0.08855317533016205
step: 910, loss: 0.03599228709936142
step: 920, loss: 0.033984407782554626
step: 930, loss: 0.0076353587210178375
step: 940, loss: 0.12692609429359436
step: 950, loss: 0.05622496083378792
step: 960, loss: 0.0869058296084404
step: 970, loss: 0.10125982761383057
epoch 18: dev_f1=0.9233627496516488, f1=0.9241507677989763, best_f1=0.927404718693285
step: 0, loss: 0.05660351738333702
step: 10, loss: 0.012556597590446472
step: 20, loss: 0.03198430687189102
step: 30, loss: 0.038346536457538605
step: 40, loss: 0.011362645775079727
step: 50, loss: 0.044870465993881226
step: 60, loss: 0.010245011188089848
step: 70, loss: 0.050760891288518906
step: 80, loss: 0.04604455083608627
step: 90, loss: 0.04225791618227959
step: 100, loss: 0.03933020681142807
step: 110, loss: 0.06877265125513077
step: 120, loss: 0.20012396574020386
step: 130, loss: 0.0001743302564136684
step: 140, loss: 0.08385784178972244
step: 150, loss: 0.08954702317714691
step: 160, loss: 0.04752231016755104
step: 170, loss: 0.04931949824094772
step: 180, loss: 0.04656730219721794
step: 190, loss: 0.06467597931623459
step: 200, loss: 0.00032112133339978755
step: 210, loss: 0.03818698227405548
step: 220, loss: 0.00015066952619235963
step: 230, loss: 0.00011838002683361992
step: 240, loss: 0.04297545179724693
step: 250, loss: 2.7710872018360533e-05
step: 260, loss: 0.05154859274625778
step: 270, loss: 0.1531197726726532
step: 280, loss: 0.05523338541388512
step: 290, loss: 0.07478924840688705
step: 300, loss: 0.07138612866401672
step: 310, loss: 0.04800441861152649
step: 320, loss: 0.04935291409492493
step: 330, loss: 0.05038582533597946
step: 340, loss: 0.07659135013818741
step: 350, loss: 0.06798388063907623
step: 360, loss: 0.061605699360370636
step: 370, loss: 0.12264850735664368
step: 380, loss: 0.040343668311834335
step: 390, loss: 0.07429146021604538
step: 400, loss: 0.03412692993879318
step: 410, loss: 0.023024743422865868
step: 420, loss: 4.943848034599796e-05
step: 430, loss: 0.027454320341348648
step: 440, loss: 0.07327847927808762
step: 450, loss: 0.09936006367206573
step: 460, loss: 0.06943193823099136
step: 470, loss: 0.026448767632246017
step: 480, loss: 0.07924515008926392
step: 490, loss: 0.024599464610219002
step: 500, loss: 0.05610274896025658
step: 510, loss: 0.08121343702077866
step: 520, loss: 0.011029301211237907
step: 530, loss: 0.05729991942644119
step: 540, loss: 5.172345117898658e-05
step: 550, loss: 0.18734470009803772
step: 560, loss: 0.022671839222311974
step: 570, loss: 0.01563134416937828
step: 580, loss: 0.011150683276355267
step: 590, loss: 0.057283125817775726
step: 600, loss: 0.062498223036527634
step: 610, loss: 0.0376230925321579
step: 620, loss: 0.05594949051737785
step: 630, loss: 0.04387460649013519
step: 640, loss: 0.10216978937387466
step: 650, loss: 0.02368844673037529
step: 660, loss: 0.015441805124282837
step: 670, loss: 0.07905112951993942
step: 680, loss: 0.04343903437256813
step: 690, loss: 0.023052403703331947
step: 700, loss: 0.029618769884109497
step: 710, loss: 0.016415460035204887
step: 720, loss: 0.07218462973833084
step: 730, loss: 0.05073440447449684
step: 740, loss: 0.04138287156820297
step: 750, loss: 0.022162631154060364
step: 760, loss: 0.08356419205665588
step: 770, loss: 0.16525444388389587
step: 780, loss: 0.05535029619932175
step: 790, loss: 0.06857404857873917
step: 800, loss: 0.09552709013223648
step: 810, loss: 0.021400004625320435
step: 820, loss: 0.07955903559923172
step: 830, loss: 0.04397206753492355
step: 840, loss: 0.02948213741183281
step: 850, loss: 0.0009901021840050817
step: 860, loss: 0.023876182734966278
step: 870, loss: 0.03999657928943634
step: 880, loss: 0.039740387350320816
step: 890, loss: 0.06130250543355942
step: 900, loss: 0.05361297354102135
step: 910, loss: 0.060337819159030914
step: 920, loss: 0.04004642367362976
step: 930, loss: 0.04326235130429268
step: 940, loss: 0.0002696486480999738
step: 950, loss: 0.043940674513578415
step: 960, loss: 0.0017038496444001794
step: 970, loss: 0.0954320952296257
epoch 19: dev_f1=0.9218530650444547, f1=0.922429906542056, best_f1=0.927404718693285
step: 0, loss: 0.06715919822454453
step: 10, loss: 0.07532987743616104
step: 20, loss: 0.07190898060798645
step: 30, loss: 0.10953476279973984
step: 40, loss: 0.037929363548755646
step: 50, loss: 0.043585725128650665
step: 60, loss: 0.05125444754958153
step: 70, loss: 0.0008565401076339185
step: 80, loss: 0.07556325942277908
step: 90, loss: 7.009584078332409e-05
step: 100, loss: 0.08366217464208603
step: 110, loss: 0.10009586811065674
step: 120, loss: 0.07359088957309723
step: 130, loss: 0.09082204848527908
step: 140, loss: 0.01768815703690052
step: 150, loss: 0.00010316525731468573
step: 160, loss: 0.02857418730854988
step: 170, loss: 0.0862211138010025
step: 180, loss: 0.06146084889769554
step: 190, loss: 0.013040885329246521
step: 200, loss: 0.0006038740393705666
step: 210, loss: 0.011582998558878899
step: 220, loss: 0.04995116591453552
step: 230, loss: 0.00013318999845068902
step: 240, loss: 0.2110128551721573
step: 250, loss: 0.12099360674619675
step: 260, loss: 0.00028585916152223945
step: 270, loss: 0.036423154175281525
step: 280, loss: 0.06369512528181076
step: 290, loss: 0.02238510549068451
step: 300, loss: 0.022366821765899658
step: 310, loss: 0.04015854001045227
step: 320, loss: 0.04028407856822014
step: 330, loss: 0.07517947256565094
step: 340, loss: 0.0003164003719575703
step: 350, loss: 0.04042460396885872
step: 360, loss: 0.06654026359319687
step: 370, loss: 0.12093587964773178
step: 380, loss: 0.05963660404086113
step: 390, loss: 0.04812419041991234
step: 400, loss: 0.09350588917732239
step: 410, loss: 0.030382374301552773
step: 420, loss: 0.03338140994310379
step: 430, loss: 0.030688276514410973
step: 440, loss: 0.00034702601260505617
step: 450, loss: 0.0004960146616213024
step: 460, loss: 0.025903245434165
step: 470, loss: 0.07550384104251862
step: 480, loss: 0.07043097168207169
step: 490, loss: 0.024495095014572144
step: 500, loss: 0.04571859538555145
step: 510, loss: 0.033582597970962524
step: 520, loss: 0.0584837906062603
step: 530, loss: 0.0012754467315971851
step: 540, loss: 0.06354726850986481
step: 550, loss: 0.0704367458820343
step: 560, loss: 0.0020535788498818874
step: 570, loss: 0.0005225883214734495
step: 580, loss: 0.03936201333999634
step: 590, loss: 0.0008116972167044878
step: 600, loss: 0.020785702392458916
step: 610, loss: 0.0013174809282645583
step: 620, loss: 0.0687389224767685
step: 630, loss: 0.02686639502644539
step: 640, loss: 0.04392670467495918
step: 650, loss: 0.027808863669633865
step: 660, loss: 0.00014252534310799092
step: 670, loss: 0.016897426918148994
step: 680, loss: 0.029562760144472122
step: 690, loss: 0.05106807127594948
step: 700, loss: 0.00011697666195686907
step: 710, loss: 0.051493529230356216
step: 720, loss: 0.056630443781614304
step: 730, loss: 0.056775547564029694
step: 740, loss: 0.05328205227851868
step: 750, loss: 8.13972201285651e-06
step: 760, loss: 0.05419667437672615
step: 770, loss: 0.02672477997839451
step: 780, loss: 0.05880020186305046
step: 790, loss: 0.02048403024673462
step: 800, loss: 0.038409605622291565
step: 810, loss: 0.11748531460762024
step: 820, loss: 0.1797005832195282
step: 830, loss: 0.03940196707844734
step: 840, loss: 0.01826588436961174
step: 850, loss: 0.06301790475845337
step: 860, loss: 0.013128863647580147
step: 870, loss: 0.04744085669517517
step: 880, loss: 0.025018367916345596
step: 890, loss: 0.044182032346725464
step: 900, loss: 0.12329519540071487
step: 910, loss: 0.011182693764567375
step: 920, loss: 0.2039952129125595
step: 930, loss: 0.025738682597875595
step: 940, loss: 0.04200015962123871
step: 950, loss: 0.027252020314335823
step: 960, loss: 0.021394694223999977
step: 970, loss: 4.781609459314495e-05
epoch 20: dev_f1=0.9201877934272301, f1=0.922138836772983, best_f1=0.927404718693285
