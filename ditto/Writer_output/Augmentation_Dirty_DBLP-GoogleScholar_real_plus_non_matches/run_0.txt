cuda
Device: cuda
step: 0, loss: 0.5403159260749817
step: 10, loss: 0.2138630598783493
step: 20, loss: 0.186432346701622
step: 30, loss: 0.3533259332180023
step: 40, loss: 0.3174486458301544
step: 50, loss: 0.1752064824104309
step: 60, loss: 0.14831236004829407
step: 70, loss: 0.4978314936161041
step: 80, loss: 0.3359014689922333
step: 90, loss: 0.15432696044445038
step: 100, loss: 0.09930411726236343
step: 110, loss: 0.21017901599407196
step: 120, loss: 0.34645017981529236
step: 130, loss: 0.21620096266269684
step: 140, loss: 0.1889430731534958
step: 150, loss: 0.06512656062841415
step: 160, loss: 0.26251938939094543
step: 170, loss: 0.07598793506622314
step: 180, loss: 0.1992402970790863
step: 190, loss: 0.13096804916858673
step: 200, loss: 0.13045893609523773
step: 210, loss: 0.2532423734664917
step: 220, loss: 0.07844734191894531
step: 230, loss: 0.11988827586174011
step: 240, loss: 0.17143890261650085
step: 250, loss: 0.19454777240753174
step: 260, loss: 0.13727328181266785
step: 270, loss: 0.04156718775629997
step: 280, loss: 0.12590542435646057
step: 290, loss: 0.1876707375049591
step: 300, loss: 0.1600184589624405
step: 310, loss: 0.19946156442165375
step: 320, loss: 0.08032714575529099
step: 330, loss: 0.21146667003631592
step: 340, loss: 0.26213064789772034
step: 350, loss: 0.2250288426876068
step: 360, loss: 0.1284458041191101
step: 370, loss: 0.2248382717370987
step: 380, loss: 0.2123134583234787
step: 390, loss: 0.2665748596191406
step: 400, loss: 0.20422032475471497
step: 410, loss: 0.11694496870040894
step: 420, loss: 0.20064803957939148
step: 430, loss: 0.06549494713544846
step: 440, loss: 0.4025525748729706
step: 450, loss: 0.097730852663517
step: 460, loss: 0.1769113838672638
step: 470, loss: 0.07655880600214005
step: 480, loss: 0.15050384402275085
step: 490, loss: 0.11536820977926254
step: 500, loss: 0.17117369174957275
step: 510, loss: 0.1431014984846115
step: 520, loss: 0.1135617196559906
step: 530, loss: 0.021676426753401756
step: 540, loss: 0.19650940597057343
step: 550, loss: 0.25284677743911743
step: 560, loss: 0.15872198343276978
step: 570, loss: 0.14819687604904175
step: 580, loss: 0.21104148030281067
step: 590, loss: 0.14570315182209015
step: 600, loss: 0.05768221244215965
step: 610, loss: 0.08898565173149109
step: 620, loss: 0.14334504306316376
step: 630, loss: 0.10703859478235245
step: 640, loss: 0.09674209356307983
step: 650, loss: 0.0970347449183464
step: 660, loss: 0.21233849227428436
step: 670, loss: 0.21677912771701813
step: 680, loss: 0.1882757693529129
step: 690, loss: 0.11135644465684891
step: 700, loss: 0.0963066965341568
step: 710, loss: 0.14892517030239105
step: 720, loss: 0.09829360991716385
step: 730, loss: 0.17016567289829254
step: 740, loss: 0.10675343126058578
step: 750, loss: 0.07411260902881622
step: 760, loss: 0.11562180519104004
step: 770, loss: 0.06336656957864761
step: 780, loss: 0.12163650989532471
step: 790, loss: 0.17568078637123108
step: 800, loss: 0.2031709998846054
step: 810, loss: 0.3202836215496063
step: 820, loss: 0.15605486929416656
step: 830, loss: 0.1156514436006546
step: 840, loss: 0.06732484698295593
step: 850, loss: 0.19013711810112
step: 860, loss: 0.1653449535369873
step: 870, loss: 0.19517679512500763
step: 880, loss: 0.14736421406269073
step: 890, loss: 0.14441639184951782
step: 900, loss: 0.08866927772760391
step: 910, loss: 0.2081020176410675
step: 920, loss: 0.1713482141494751
step: 930, loss: 0.05952973663806915
step: 940, loss: 0.20010536909103394
step: 950, loss: 0.11707543581724167
step: 960, loss: 0.1339506357908249
step: 970, loss: 0.0991949662566185
epoch 1: dev_f1=0.9195298372513563, f1=0.9132791327913279, best_f1=0.9132791327913279
step: 0, loss: 0.19809618592262268
step: 10, loss: 0.18104830384254456
step: 20, loss: 0.16920392215251923
step: 30, loss: 0.18470309674739838
step: 40, loss: 0.18203742802143097
step: 50, loss: 0.08663665503263474
step: 60, loss: 0.05639701336622238
step: 70, loss: 0.15466101467609406
step: 80, loss: 0.2305537760257721
step: 90, loss: 0.09031353890895844
step: 100, loss: 0.06304902583360672
step: 110, loss: 0.1612609624862671
step: 120, loss: 0.09061836451292038
step: 130, loss: 0.17355556786060333
step: 140, loss: 0.09789637476205826
step: 150, loss: 0.15100525319576263
step: 160, loss: 0.18688444793224335
step: 170, loss: 0.22898992896080017
step: 180, loss: 0.07732462882995605
step: 190, loss: 0.13782057166099548
step: 200, loss: 0.13063320517539978
step: 210, loss: 0.22676673531532288
step: 220, loss: 0.21819373965263367
step: 230, loss: 0.11729766428470612
step: 240, loss: 0.04723105952143669
step: 250, loss: 0.0780535414814949
step: 260, loss: 0.18191643059253693
step: 270, loss: 0.18330402672290802
step: 280, loss: 0.12442762404680252
step: 290, loss: 0.10606774687767029
step: 300, loss: 0.13322985172271729
step: 310, loss: 0.07393977046012878
step: 320, loss: 0.22316499054431915
step: 330, loss: 0.052787307649850845
step: 340, loss: 0.14579562842845917
step: 350, loss: 0.2129225879907608
step: 360, loss: 0.0709930956363678
step: 370, loss: 0.22845244407653809
step: 380, loss: 0.10829395800828934
step: 390, loss: 0.08134520798921585
step: 400, loss: 0.08463887125253677
step: 410, loss: 0.09787686914205551
step: 420, loss: 0.09999103844165802
step: 430, loss: 0.11429883539676666
step: 440, loss: 0.14979809522628784
step: 450, loss: 0.17816801369190216
step: 460, loss: 0.13249504566192627
step: 470, loss: 0.07552016526460648
step: 480, loss: 0.10513769090175629
step: 490, loss: 0.1479755938053131
step: 500, loss: 0.14658473432064056
step: 510, loss: 0.11422628164291382
step: 520, loss: 0.11884456872940063
step: 530, loss: 0.19481299817562103
step: 540, loss: 0.1836167275905609
step: 550, loss: 0.1802753061056137
step: 560, loss: 0.16807357966899872
step: 570, loss: 0.12530747056007385
step: 580, loss: 0.1917189508676529
step: 590, loss: 0.1157844215631485
step: 600, loss: 0.19382931292057037
step: 610, loss: 0.14912736415863037
step: 620, loss: 0.09711521863937378
step: 630, loss: 0.17432120442390442
step: 640, loss: 0.13838762044906616
step: 650, loss: 0.17234380543231964
step: 660, loss: 0.20307722687721252
step: 670, loss: 0.1052151620388031
step: 680, loss: 0.20843063294887543
step: 690, loss: 0.1007056012749672
step: 700, loss: 0.14436452090740204
step: 710, loss: 0.06587900966405869
step: 720, loss: 0.1430114209651947
step: 730, loss: 0.08788243681192398
step: 740, loss: 0.05858306214213371
step: 750, loss: 0.0967806875705719
step: 760, loss: 0.21213535964488983
step: 770, loss: 0.08762354403734207
step: 780, loss: 0.32407671213150024
step: 790, loss: 0.09332942217588425
step: 800, loss: 0.14733633399009705
step: 810, loss: 0.18999803066253662
step: 820, loss: 0.03973131999373436
step: 830, loss: 0.13303066790103912
step: 840, loss: 0.09817788004875183
step: 850, loss: 0.1965615302324295
step: 860, loss: 0.1951330453157425
step: 870, loss: 0.06986977905035019
step: 880, loss: 0.2308187484741211
step: 890, loss: 0.18665161728858948
step: 900, loss: 0.16798417270183563
step: 910, loss: 0.19816920161247253
step: 920, loss: 0.18837107717990875
step: 930, loss: 0.23880529403686523
step: 940, loss: 0.12595760822296143
step: 950, loss: 0.0764254704117775
step: 960, loss: 0.05991782248020172
step: 970, loss: 0.08567015826702118
epoch 2: dev_f1=0.9235100891600189, f1=0.9212121212121211, best_f1=0.9212121212121211
step: 0, loss: 0.11772450804710388
step: 10, loss: 0.16240547597408295
step: 20, loss: 0.14072538912296295
step: 30, loss: 0.15241137146949768
step: 40, loss: 0.08658331632614136
step: 50, loss: 0.05509784445166588
step: 60, loss: 0.06968466192483902
step: 70, loss: 0.018331855535507202
step: 80, loss: 0.1396256536245346
step: 90, loss: 0.07459000498056412
step: 100, loss: 0.04155490919947624
step: 110, loss: 0.08833137899637222
step: 120, loss: 0.1192341148853302
step: 130, loss: 0.1123318076133728
step: 140, loss: 0.07278266549110413
step: 150, loss: 0.047305792570114136
step: 160, loss: 0.06188983470201492
step: 170, loss: 0.12287505716085434
step: 180, loss: 0.09385618567466736
step: 190, loss: 0.02432112954556942
step: 200, loss: 0.1389080286026001
step: 210, loss: 0.2543596923351288
step: 220, loss: 0.12728668749332428
step: 230, loss: 0.21503131091594696
step: 240, loss: 0.07805317640304565
step: 250, loss: 0.12269783765077591
step: 260, loss: 0.11313013732433319
step: 270, loss: 0.08568067848682404
step: 280, loss: 0.04982772096991539
step: 290, loss: 0.233483225107193
step: 300, loss: 0.16383281350135803
step: 310, loss: 0.09660511463880539
step: 320, loss: 0.04958219453692436
step: 330, loss: 0.14997325837612152
step: 340, loss: 0.07014741003513336
step: 350, loss: 0.15742233395576477
step: 360, loss: 0.06329476088285446
step: 370, loss: 0.09429128468036652
step: 380, loss: 0.16810643672943115
step: 390, loss: 0.11369218677282333
step: 400, loss: 0.11567515134811401
step: 410, loss: 0.08800744265317917
step: 420, loss: 0.20098446309566498
step: 430, loss: 0.2165512889623642
step: 440, loss: 0.13983428478240967
step: 450, loss: 0.10055382549762726
step: 460, loss: 0.22514277696609497
step: 470, loss: 0.052635062485933304
step: 480, loss: 0.10218149423599243
step: 490, loss: 0.16417279839515686
step: 500, loss: 0.09075547009706497
step: 510, loss: 0.1570892482995987
step: 520, loss: 0.13501200079917908
step: 530, loss: 0.19514043629169464
step: 540, loss: 0.1794021874666214
step: 550, loss: 0.14459460973739624
step: 560, loss: 0.21038848161697388
step: 570, loss: 0.18483155965805054
step: 580, loss: 0.020180869847536087
step: 590, loss: 0.2348034530878067
step: 600, loss: 0.11431964486837387
step: 610, loss: 0.08027751743793488
step: 620, loss: 0.2401294857263565
step: 630, loss: 0.15714800357818604
step: 640, loss: 0.10348337888717651
step: 650, loss: 0.15273840725421906
step: 660, loss: 0.1120692789554596
step: 670, loss: 0.07860874384641647
step: 680, loss: 0.04718121886253357
step: 690, loss: 0.29846662282943726
step: 700, loss: 0.1763690859079361
step: 710, loss: 0.14774449169635773
step: 720, loss: 0.1331559419631958
step: 730, loss: 0.11351016163825989
step: 740, loss: 0.21374674141407013
step: 750, loss: 0.17793488502502441
step: 760, loss: 0.1635827273130417
step: 770, loss: 0.1698983758687973
step: 780, loss: 0.16027964651584625
step: 790, loss: 0.1909097284078598
step: 800, loss: 0.09325732290744781
step: 810, loss: 0.13398471474647522
step: 820, loss: 0.12287067621946335
step: 830, loss: 0.11445677280426025
step: 840, loss: 0.12401163578033447
step: 850, loss: 0.10500821471214294
step: 860, loss: 0.13188330829143524
step: 870, loss: 0.12857314944267273
step: 880, loss: 0.1435835361480713
step: 890, loss: 0.2210371345281601
step: 900, loss: 0.0636368915438652
step: 910, loss: 0.03857627883553505
step: 920, loss: 0.19317975640296936
step: 930, loss: 0.2079414278268814
step: 940, loss: 0.13677959144115448
step: 950, loss: 0.127043217420578
step: 960, loss: 0.10135996341705322
step: 970, loss: 0.09494129568338394
epoch 3: dev_f1=0.9358974358974358, f1=0.9275229357798166, best_f1=0.9275229357798166
step: 0, loss: 0.025223931297659874
step: 10, loss: 0.13537485897541046
step: 20, loss: 0.13504023849964142
step: 30, loss: 0.026051275432109833
step: 40, loss: 0.028616290539503098
step: 50, loss: 0.08612676709890366
step: 60, loss: 0.09844165295362473
step: 70, loss: 0.08672381192445755
step: 80, loss: 0.12071969360113144
step: 90, loss: 0.26298341155052185
step: 100, loss: 0.06175919622182846
step: 110, loss: 0.3087599277496338
step: 120, loss: 0.11327168345451355
step: 130, loss: 0.09233856201171875
step: 140, loss: 0.04834844172000885
step: 150, loss: 0.06307421624660492
step: 160, loss: 0.06892257183790207
step: 170, loss: 0.1030053123831749
step: 180, loss: 0.07891964167356491
step: 190, loss: 0.07817167788743973
step: 200, loss: 0.055178213864564896
step: 210, loss: 0.18288512527942657
step: 220, loss: 0.07786299288272858
step: 230, loss: 0.030069593340158463
step: 240, loss: 0.13253238797187805
step: 250, loss: 0.08310461044311523
step: 260, loss: 0.06961037963628769
step: 270, loss: 0.09025844186544418
step: 280, loss: 0.09287834912538528
step: 290, loss: 0.06313630193471909
step: 300, loss: 0.15996697545051575
step: 310, loss: 0.12008701264858246
step: 320, loss: 0.12974584102630615
step: 330, loss: 0.1385844498872757
step: 340, loss: 0.06504963338375092
step: 350, loss: 0.2835753858089447
step: 360, loss: 0.16106252372264862
step: 370, loss: 0.1878957599401474
step: 380, loss: 0.11254403740167618
step: 390, loss: 0.13286037743091583
step: 400, loss: 0.08191703259944916
step: 410, loss: 0.1337059885263443
step: 420, loss: 0.16373273730278015
step: 430, loss: 0.16986653208732605
step: 440, loss: 0.049019381403923035
step: 450, loss: 0.11004053056240082
step: 460, loss: 0.18238435685634613
step: 470, loss: 0.11667594313621521
step: 480, loss: 0.17017732560634613
step: 490, loss: 0.18997614085674286
step: 500, loss: 0.0004529816214926541
step: 510, loss: 0.08711408823728561
step: 520, loss: 0.13565689325332642
step: 530, loss: 0.10817661136388779
step: 540, loss: 0.0791865661740303
step: 550, loss: 0.06174414977431297
step: 560, loss: 0.15622448921203613
step: 570, loss: 0.14093399047851562
step: 580, loss: 0.16998954117298126
step: 590, loss: 0.2345825880765915
step: 600, loss: 0.07184676080942154
step: 610, loss: 0.0755409374833107
step: 620, loss: 0.08546137809753418
step: 630, loss: 0.21550258994102478
step: 640, loss: 0.06622808426618576
step: 650, loss: 0.1758347600698471
step: 660, loss: 0.09848649054765701
step: 670, loss: 0.0777556523680687
step: 680, loss: 0.044810015708208084
step: 690, loss: 0.3925272822380066
step: 700, loss: 0.060115568339824677
step: 710, loss: 0.09880147129297256
step: 720, loss: 0.1415390521287918
step: 730, loss: 0.1384989321231842
step: 740, loss: 0.14193812012672424
step: 750, loss: 0.17495878040790558
step: 760, loss: 0.09335164725780487
step: 770, loss: 0.1967335194349289
step: 780, loss: 0.08664128929376602
step: 790, loss: 0.11966414749622345
step: 800, loss: 0.15322934091091156
step: 810, loss: 0.08167567104101181
step: 820, loss: 0.11924789100885391
step: 830, loss: 0.13615335524082184
step: 840, loss: 0.10501554608345032
step: 850, loss: 0.06475348025560379
step: 860, loss: 0.0838710218667984
step: 870, loss: 0.28196680545806885
step: 880, loss: 0.08710867911577225
step: 890, loss: 0.09797374159097672
step: 900, loss: 0.03975270688533783
step: 910, loss: 0.1042686477303505
step: 920, loss: 0.17152796685695648
step: 930, loss: 0.03223366290330887
step: 940, loss: 0.19144827127456665
step: 950, loss: 0.12595529854297638
step: 960, loss: 0.14256428182125092
step: 970, loss: 0.07860174030065536
epoch 4: dev_f1=0.9277496548550391, f1=0.9230769230769231, best_f1=0.9275229357798166
step: 0, loss: 0.15813174843788147
step: 10, loss: 0.06794226169586182
step: 20, loss: 0.03924217075109482
step: 30, loss: 0.04515289515256882
step: 40, loss: 0.12095103412866592
step: 50, loss: 0.2185209095478058
step: 60, loss: 0.06679846346378326
step: 70, loss: 0.11829839646816254
step: 80, loss: 0.11952049285173416
step: 90, loss: 0.0870056003332138
step: 100, loss: 0.18023279309272766
step: 110, loss: 0.06178702786564827
step: 120, loss: 0.1664564162492752
step: 130, loss: 0.07531851530075073
step: 140, loss: 0.2852095365524292
step: 150, loss: 0.083746999502182
step: 160, loss: 0.09716229140758514
step: 170, loss: 0.07973639667034149
step: 180, loss: 0.04864982143044472
step: 190, loss: 0.17380337417125702
step: 200, loss: 0.05317734554409981
step: 210, loss: 0.05004546418786049
step: 220, loss: 0.06591209024190903
step: 230, loss: 0.06865186989307404
step: 240, loss: 0.11975127458572388
step: 250, loss: 0.05932542309165001
step: 260, loss: 0.05961187928915024
step: 270, loss: 0.17529579997062683
step: 280, loss: 0.07675763964653015
step: 290, loss: 0.09155098348855972
step: 300, loss: 0.06629616767168045
step: 310, loss: 0.05837370455265045
step: 320, loss: 0.17312641441822052
step: 330, loss: 0.11085008829832077
step: 340, loss: 0.07719153165817261
step: 350, loss: 0.1370144635438919
step: 360, loss: 0.09719281643629074
step: 370, loss: 0.18465639650821686
step: 380, loss: 0.06014440953731537
step: 390, loss: 0.09079954773187637
step: 400, loss: 0.040763381868600845
step: 410, loss: 0.12983737885951996
step: 420, loss: 0.029466763138771057
step: 430, loss: 0.10015790164470673
step: 440, loss: 0.17230431735515594
step: 450, loss: 0.13550953567028046
step: 460, loss: 0.11140605062246323
step: 470, loss: 0.20326709747314453
step: 480, loss: 0.050485022366046906
step: 490, loss: 0.14323920011520386
step: 500, loss: 0.08131404221057892
step: 510, loss: 0.10088420659303665
step: 520, loss: 0.10980591177940369
step: 530, loss: 0.07672575861215591
step: 540, loss: 0.09374436736106873
step: 550, loss: 0.09209001064300537
step: 560, loss: 0.23563922941684723
step: 570, loss: 0.03916299715638161
step: 580, loss: 0.07851450145244598
step: 590, loss: 0.24627579748630524
step: 600, loss: 0.3669464588165283
step: 610, loss: 0.05371867120265961
step: 620, loss: 0.09686996042728424
step: 630, loss: 0.1600486785173416
step: 640, loss: 0.07300229370594025
step: 650, loss: 0.07543594390153885
step: 660, loss: 0.11694763600826263
step: 670, loss: 0.1363069862127304
step: 680, loss: 0.047545112669467926
step: 690, loss: 0.061948053538799286
step: 700, loss: 0.13557997345924377
step: 710, loss: 0.09830398857593536
step: 720, loss: 0.2459523230791092
step: 730, loss: 0.13026462495326996
step: 740, loss: 0.120778888463974
step: 750, loss: 0.1854345202445984
step: 760, loss: 0.14087150990962982
step: 770, loss: 0.1377396583557129
step: 780, loss: 0.12055277079343796
step: 790, loss: 0.13460786640644073
step: 800, loss: 0.09852197021245956
step: 810, loss: 0.16353309154510498
step: 820, loss: 0.13558977842330933
step: 830, loss: 0.10364022105932236
step: 840, loss: 0.1645108163356781
step: 850, loss: 0.12026511877775192
step: 860, loss: 0.08507612347602844
step: 870, loss: 0.2978793680667877
step: 880, loss: 0.10293607413768768
step: 890, loss: 0.14281924068927765
step: 900, loss: 0.09364457428455353
step: 910, loss: 0.10496590286493301
step: 920, loss: 0.10476996749639511
step: 930, loss: 0.13680912554264069
step: 940, loss: 0.14399217069149017
step: 950, loss: 0.14572308957576752
step: 960, loss: 0.12842558324337006
step: 970, loss: 0.133980393409729
epoch 5: dev_f1=0.9298486932599725, f1=0.9267618608935975, best_f1=0.9275229357798166
step: 0, loss: 0.16612283885478973
step: 10, loss: 0.09863592684268951
step: 20, loss: 0.1067611426115036
step: 30, loss: 0.102789968252182
step: 40, loss: 0.11991360038518906
step: 50, loss: 0.052552029490470886
step: 60, loss: 0.10472995787858963
step: 70, loss: 0.13959728181362152
step: 80, loss: 0.027659764513373375
step: 90, loss: 0.05492832139134407
step: 100, loss: 0.015744278207421303
step: 110, loss: 0.08182473480701447
step: 120, loss: 0.1302817314863205
step: 130, loss: 0.03846203163266182
step: 140, loss: 0.0328102670609951
step: 150, loss: 0.030763227492570877
step: 160, loss: 0.08709347993135452
step: 170, loss: 0.12175548076629639
step: 180, loss: 0.07447204738855362
step: 190, loss: 0.16044893860816956
step: 200, loss: 0.05638420581817627
step: 210, loss: 0.14717236161231995
step: 220, loss: 0.10311407595872879
step: 230, loss: 0.26789167523384094
step: 240, loss: 0.33316531777381897
step: 250, loss: 0.10366173833608627
step: 260, loss: 0.14332465827465057
step: 270, loss: 0.09859484434127808
step: 280, loss: 0.0879613384604454
step: 290, loss: 0.05056130886077881
step: 300, loss: 0.1834699958562851
step: 310, loss: 0.131880983710289
step: 320, loss: 0.0942891538143158
step: 330, loss: 0.08601681888103485
step: 340, loss: 0.06382939964532852
step: 350, loss: 0.1047142818570137
step: 360, loss: 0.050565820187330246
step: 370, loss: 0.13006888329982758
step: 380, loss: 0.24206319451332092
step: 390, loss: 0.11011471599340439
step: 400, loss: 0.082619808614254
step: 410, loss: 0.08382125198841095
step: 420, loss: 0.12787273526191711
step: 430, loss: 0.06188040226697922
step: 440, loss: 0.07442234456539154
step: 450, loss: 0.10475853085517883
step: 460, loss: 0.059370994567871094
step: 470, loss: 0.08938781172037125
step: 480, loss: 0.20258498191833496
step: 490, loss: 0.06253860890865326
step: 500, loss: 0.12398642301559448
step: 510, loss: 0.051239337772130966
step: 520, loss: 0.07349614799022675
step: 530, loss: 0.09607052057981491
step: 540, loss: 0.2206810563802719
step: 550, loss: 0.028324885293841362
step: 560, loss: 0.17798642814159393
step: 570, loss: 0.0816359743475914
step: 580, loss: 0.11641602218151093
step: 590, loss: 0.06694906949996948
step: 600, loss: 0.06263911724090576
step: 610, loss: 0.03549925610423088
step: 620, loss: 0.08172488212585449
step: 630, loss: 0.054654963314533234
step: 640, loss: 0.03423294052481651
step: 650, loss: 0.10368717461824417
step: 660, loss: 0.027778463438153267
step: 670, loss: 0.10062088072299957
step: 680, loss: 0.27265065908432007
step: 690, loss: 0.06814556568861008
step: 700, loss: 0.19130069017410278
step: 710, loss: 0.11280501633882523
step: 720, loss: 0.08245571702718735
step: 730, loss: 0.05183083191514015
step: 740, loss: 0.13844001293182373
step: 750, loss: 0.10254237800836563
step: 760, loss: 0.07148062437772751
step: 770, loss: 0.13193966448307037
step: 780, loss: 0.10416360199451447
step: 790, loss: 0.08078356832265854
step: 800, loss: 0.050588466227054596
step: 810, loss: 0.12134852260351181
step: 820, loss: 0.12760944664478302
step: 830, loss: 0.10811123996973038
step: 840, loss: 0.06738869100809097
step: 850, loss: 0.10333635658025742
step: 860, loss: 0.08454713970422745
step: 870, loss: 0.044040828943252563
step: 880, loss: 0.09521583467721939
step: 890, loss: 0.07359211146831512
step: 900, loss: 0.08715524524450302
step: 910, loss: 0.11915627121925354
step: 920, loss: 0.15223592519760132
step: 930, loss: 0.0012287499848753214
step: 940, loss: 0.058019500225782394
step: 950, loss: 0.06575770676136017
step: 960, loss: 0.11253353953361511
step: 970, loss: 0.12427806854248047
epoch 6: dev_f1=0.9347426470588236, f1=0.9284738041002277, best_f1=0.9275229357798166
step: 0, loss: 0.10654603689908981
step: 10, loss: 0.18537165224552155
step: 20, loss: 0.0640983060002327
step: 30, loss: 0.016441021114587784
step: 40, loss: 0.10231950134038925
step: 50, loss: 0.015172957442700863
step: 60, loss: 4.070838986081071e-05
step: 70, loss: 0.037068963050842285
step: 80, loss: 0.12591393291950226
step: 90, loss: 0.03865049406886101
step: 100, loss: 0.08797282725572586
step: 110, loss: 0.12089578807353973
step: 120, loss: 0.11903765052556992
step: 130, loss: 0.13498157262802124
step: 140, loss: 0.10437388718128204
step: 150, loss: 0.19920867681503296
step: 160, loss: 0.138619065284729
step: 170, loss: 0.12111302465200424
step: 180, loss: 0.2343735545873642
step: 190, loss: 0.10045637935400009
step: 200, loss: 0.10335007309913635
step: 210, loss: 0.07920236140489578
step: 220, loss: 0.053386569023132324
step: 230, loss: 0.05902904272079468
step: 240, loss: 0.0640350729227066
step: 250, loss: 0.13823750615119934
step: 260, loss: 0.13085554540157318
step: 270, loss: 0.03261566534638405
step: 280, loss: 0.1109052300453186
step: 290, loss: 0.09180876612663269
step: 300, loss: 0.04108579456806183
step: 310, loss: 7.206651207525283e-05
step: 320, loss: 0.15769940614700317
step: 330, loss: 0.07404772937297821
step: 340, loss: 0.06136668846011162
step: 350, loss: 0.05137643963098526
step: 360, loss: 0.17999903857707977
step: 370, loss: 0.12326224148273468
step: 380, loss: 0.1317160427570343
step: 390, loss: 0.13813386857509613
step: 400, loss: 0.01463512796908617
step: 410, loss: 0.0976962298154831
step: 420, loss: 0.09992412477731705
step: 430, loss: 0.055992696434259415
step: 440, loss: 0.037440139800310135
step: 450, loss: 0.08137404173612595
step: 460, loss: 0.007978682406246662
step: 470, loss: 0.10016103833913803
step: 480, loss: 0.09255268424749374
step: 490, loss: 0.15045702457427979
step: 500, loss: 0.11053288727998734
step: 510, loss: 0.14607517421245575
step: 520, loss: 0.13351871073246002
step: 530, loss: 0.0863645076751709
step: 540, loss: 0.20583467185497284
step: 550, loss: 0.11225338280200958
step: 560, loss: 0.08374830335378647
step: 570, loss: 0.07687626779079437
step: 580, loss: 0.07534219324588776
step: 590, loss: 0.13691537082195282
step: 600, loss: 0.0712437555193901
step: 610, loss: 0.030007416382431984
step: 620, loss: 0.12517954409122467
step: 630, loss: 0.20869186520576477
step: 640, loss: 0.08175525814294815
step: 650, loss: 0.06636044383049011
step: 660, loss: 0.10276573151350021
step: 670, loss: 0.09524296224117279
step: 680, loss: 0.061977677047252655
step: 690, loss: 0.02072008326649666
step: 700, loss: 0.09115031361579895
step: 710, loss: 0.1115759015083313
step: 720, loss: 0.09214530885219574
step: 730, loss: 0.1593836098909378
step: 740, loss: 0.12553496658802032
step: 750, loss: 0.0640580877661705
step: 760, loss: 0.20250004529953003
step: 770, loss: 0.07435549795627594
step: 780, loss: 0.08396407961845398
step: 790, loss: 0.2051713466644287
step: 800, loss: 0.3363819122314453
step: 810, loss: 0.08465328067541122
step: 820, loss: 0.05017836019396782
step: 830, loss: 0.11295711249113083
step: 840, loss: 0.058518290519714355
step: 850, loss: 0.17338398098945618
step: 860, loss: 0.1109485849738121
step: 870, loss: 0.12921838462352753
step: 880, loss: 0.07877909392118454
step: 890, loss: 0.18528349697589874
step: 900, loss: 0.19378288090229034
step: 910, loss: 0.04533190652728081
step: 920, loss: 0.06825420260429382
step: 930, loss: 0.07601441442966461
step: 940, loss: 0.12131983786821365
step: 950, loss: 0.10246335715055466
step: 960, loss: 0.0638781413435936
step: 970, loss: 0.05381643399596214
epoch 7: dev_f1=0.922077922077922, f1=0.9208831646734131, best_f1=0.9275229357798166
step: 0, loss: 0.058155469596385956
step: 10, loss: 0.10034458339214325
step: 20, loss: 0.16859635710716248
step: 30, loss: 0.05942476913332939
step: 40, loss: 0.08448587357997894
step: 50, loss: 0.06364279240369797
step: 60, loss: 0.06345637142658234
step: 70, loss: 0.05613896623253822
step: 80, loss: 0.060269441455602646
step: 90, loss: 0.09767920523881912
step: 100, loss: 0.07301688939332962
step: 110, loss: 0.09381289035081863
step: 120, loss: 0.10894504189491272
step: 130, loss: 0.15733712911605835
step: 140, loss: 0.06964875757694244
step: 150, loss: 0.04713843762874603
step: 160, loss: 0.1626870036125183
step: 170, loss: 0.16883878409862518
step: 180, loss: 0.069435715675354
step: 190, loss: 0.039108000695705414
step: 200, loss: 0.028943970799446106
step: 210, loss: 0.12497062981128693
step: 220, loss: 0.08210013061761856
step: 230, loss: 0.04833849519491196
step: 240, loss: 0.04494698345661163
step: 250, loss: 0.09409353137016296
step: 260, loss: 0.08863788098096848
step: 270, loss: 0.08548193424940109
step: 280, loss: 0.12231170386075974
step: 290, loss: 0.08236042410135269
step: 300, loss: 0.0681038573384285
step: 310, loss: 0.020296454429626465
step: 320, loss: 0.12492458522319794
step: 330, loss: 0.10548293590545654
step: 340, loss: 0.09585482627153397
step: 350, loss: 0.07708228379487991
step: 360, loss: 0.12695331871509552
step: 370, loss: 0.06020818650722504
step: 380, loss: 0.08862338215112686
step: 390, loss: 0.11986666917800903
step: 400, loss: 0.1004701480269432
step: 410, loss: 0.006750404369086027
step: 420, loss: 0.041489504277706146
step: 430, loss: 0.15945105254650116
step: 440, loss: 0.1041247695684433
step: 450, loss: 0.04955483227968216
step: 460, loss: 0.0912543460726738
step: 470, loss: 0.07606124877929688
step: 480, loss: 0.061510853469371796
step: 490, loss: 0.09101516753435135
step: 500, loss: 0.1385517567396164
step: 510, loss: 0.06012784317135811
step: 520, loss: 0.036760833114385605
step: 530, loss: 0.18024404346942902
step: 540, loss: 0.11587374657392502
step: 550, loss: 0.01261904463171959
step: 560, loss: 0.040468357503414154
step: 570, loss: 0.09852803498506546
step: 580, loss: 0.21969914436340332
step: 590, loss: 0.05031983181834221
step: 600, loss: 0.08071523159742355
step: 610, loss: 0.0828753411769867
step: 620, loss: 0.12142863869667053
step: 630, loss: 0.08685322105884552
step: 640, loss: 0.05775272846221924
step: 650, loss: 0.07740224152803421
step: 660, loss: 0.16217905282974243
step: 670, loss: 0.09132891148328781
step: 680, loss: 0.06685454398393631
step: 690, loss: 0.06705743074417114
step: 700, loss: 0.07749126106500626
step: 710, loss: 0.1311793029308319
step: 720, loss: 0.06455740332603455
step: 730, loss: 0.11490913480520248
step: 740, loss: 0.05797605589032173
step: 750, loss: 0.1033923551440239
step: 760, loss: 0.10826954245567322
step: 770, loss: 0.01698870211839676
step: 780, loss: 0.12210026383399963
step: 790, loss: 0.0626545399427414
step: 800, loss: 0.14530998468399048
step: 810, loss: 0.05862985923886299
step: 820, loss: 0.06273237615823746
step: 830, loss: 0.08004516363143921
step: 840, loss: 0.08075902611017227
step: 850, loss: 0.08439730107784271
step: 860, loss: 0.05589912459254265
step: 870, loss: 0.08518195152282715
step: 880, loss: 0.08106075972318649
step: 890, loss: 0.02044788934290409
step: 900, loss: 0.08255927264690399
step: 910, loss: 0.041948102414608
step: 920, loss: 0.13964331150054932
step: 930, loss: 0.15262436866760254
step: 940, loss: 0.008766873739659786
step: 950, loss: 0.14333361387252808
step: 960, loss: 0.039690662175416946
step: 970, loss: 0.10411829501390457
epoch 8: dev_f1=0.9296693060083837, f1=0.92814093648586, best_f1=0.9275229357798166
step: 0, loss: 0.12222538888454437
step: 10, loss: 0.08450380712747574
step: 20, loss: 0.028050513938069344
step: 30, loss: 0.06772657483816147
step: 40, loss: 0.07916198670864105
step: 50, loss: 0.1034039631485939
step: 60, loss: 0.07760419696569443
step: 70, loss: 0.06654960662126541
step: 80, loss: 0.030823981389403343
step: 90, loss: 0.07660070806741714
step: 100, loss: 0.17564654350280762
step: 110, loss: 0.07628974318504333
step: 120, loss: 0.14096197485923767
step: 130, loss: 0.07077779620885849
step: 140, loss: 0.05983196571469307
step: 150, loss: 0.04513693228363991
step: 160, loss: 0.06996642053127289
step: 170, loss: 0.0854669064283371
step: 180, loss: 0.016472216695547104
step: 190, loss: 0.1184505820274353
step: 200, loss: 0.042378898710012436
step: 210, loss: 0.11807042360305786
step: 220, loss: 0.08254965394735336
step: 230, loss: 0.029647234827280045
step: 240, loss: 0.07987464219331741
step: 250, loss: 0.09346766769886017
step: 260, loss: 0.09856533259153366
step: 270, loss: 0.05434487387537956
step: 280, loss: 0.18371479213237762
step: 290, loss: 0.11993905901908875
step: 300, loss: 0.0982198417186737
step: 310, loss: 0.09680831432342529
step: 320, loss: 0.07286132872104645
step: 330, loss: 0.06252646446228027
step: 340, loss: 0.0751456543803215
step: 350, loss: 0.1263590306043625
step: 360, loss: 0.051011960953474045
step: 370, loss: 0.18782088160514832
step: 380, loss: 0.10193381458520889
step: 390, loss: 0.03916475921869278
step: 400, loss: 0.001535292947664857
step: 410, loss: 0.061081234365701675
step: 420, loss: 0.08079992979764938
step: 430, loss: 0.03196322172880173
step: 440, loss: 0.032075926661491394
step: 450, loss: 0.06428305059671402
step: 460, loss: 0.06677955389022827
step: 470, loss: 0.015242094174027443
step: 480, loss: 0.18588489294052124
step: 490, loss: 0.041511304676532745
step: 500, loss: 0.1337801218032837
step: 510, loss: 0.1534002423286438
step: 520, loss: 0.12519635260105133
step: 530, loss: 0.22496730089187622
step: 540, loss: 0.04758927598595619
step: 550, loss: 0.039676327258348465
step: 560, loss: 0.04597076028585434
step: 570, loss: 0.1406617909669876
step: 580, loss: 0.08213616162538528
step: 590, loss: 0.11233291774988174
step: 600, loss: 0.04011544957756996
step: 610, loss: 0.027004655450582504
step: 620, loss: 0.0725465714931488
step: 630, loss: 0.14285336434841156
step: 640, loss: 0.095057412981987
step: 650, loss: 0.06453070789575577
step: 660, loss: 0.07094419002532959
step: 670, loss: 0.11328503489494324
step: 680, loss: 0.03223166614770889
step: 690, loss: 0.06620064377784729
step: 700, loss: 0.0365365669131279
step: 710, loss: 0.05919957906007767
step: 720, loss: 0.16266165673732758
step: 730, loss: 0.1560341864824295
step: 740, loss: 0.08029066026210785
step: 750, loss: 4.6763147111050785e-05
step: 760, loss: 0.09426285326480865
step: 770, loss: 0.0681406632065773
step: 780, loss: 0.10741424560546875
step: 790, loss: 0.08754973113536835
step: 800, loss: 0.105634905397892
step: 810, loss: 0.12241759151220322
step: 820, loss: 0.17909666895866394
step: 830, loss: 0.03477230295538902
step: 840, loss: 0.02536134049296379
step: 850, loss: 0.030466046184301376
step: 860, loss: 0.11365219950675964
step: 870, loss: 0.07830316573381424
step: 880, loss: 0.13234257698059082
step: 890, loss: 0.07708920538425446
step: 900, loss: 0.07330705225467682
step: 910, loss: 0.08364661782979965
step: 920, loss: 0.14697439968585968
step: 930, loss: 0.05714128538966179
step: 940, loss: 0.028250444680452347
step: 950, loss: 0.09671583026647568
step: 960, loss: 0.04853770509362221
step: 970, loss: 0.10311567038297653
epoch 9: dev_f1=0.9337042188224385, f1=0.9284064665127021, best_f1=0.9275229357798166
step: 0, loss: 0.015794238075613976
step: 10, loss: 0.0440654382109642
step: 20, loss: 0.008175012655556202
step: 30, loss: 0.1510503888130188
step: 40, loss: 0.04050859808921814
step: 50, loss: 0.04228535667061806
step: 60, loss: 0.16391389071941376
step: 70, loss: 0.04851670190691948
step: 80, loss: 0.07085160911083221
step: 90, loss: 0.05070580169558525
step: 100, loss: 0.10273610055446625
step: 110, loss: 0.08480376750230789
step: 120, loss: 0.21222639083862305
step: 130, loss: 0.011901072226464748
step: 140, loss: 0.00011980885756202042
step: 150, loss: 0.08471893519163132
step: 160, loss: 0.0238034650683403
step: 170, loss: 0.12119103968143463
step: 180, loss: 0.015894215553998947
step: 190, loss: 0.09307439625263214
step: 200, loss: 0.15875516831874847
step: 210, loss: 0.08861847966909409
step: 220, loss: 0.036276791244745255
step: 230, loss: 0.07294988632202148
step: 240, loss: 0.17955560982227325
step: 250, loss: 0.1750427484512329
step: 260, loss: 0.09943768382072449
step: 270, loss: 0.16720527410507202
step: 280, loss: 0.13587713241577148
step: 290, loss: 0.0789773091673851
step: 300, loss: 0.12068699300289154
step: 310, loss: 0.049910012632608414
step: 320, loss: 0.036381565034389496
step: 330, loss: 0.011973295360803604
step: 340, loss: 0.1548813432455063
step: 350, loss: 0.03464246541261673
step: 360, loss: 0.12346164882183075
step: 370, loss: 0.06767897307872772
step: 380, loss: 0.09922280162572861
step: 390, loss: 0.12656301259994507
step: 400, loss: 0.033698853105306625
step: 410, loss: 0.1431371122598648
step: 420, loss: 0.1267542541027069
step: 430, loss: 0.08454591780900955
step: 440, loss: 0.010394188575446606
step: 450, loss: 0.029908377677202225
step: 460, loss: 0.052842509001493454
step: 470, loss: 0.06448492407798767
step: 480, loss: 0.11426001787185669
step: 490, loss: 0.1001235842704773
step: 500, loss: 0.07125631719827652
step: 510, loss: 0.05235706642270088
step: 520, loss: 0.011511702090501785
step: 530, loss: 0.08609820157289505
step: 540, loss: 0.15769946575164795
step: 550, loss: 0.049458280205726624
step: 560, loss: 0.07214897125959396
step: 570, loss: 0.06897640228271484
step: 580, loss: 0.03060784935951233
step: 590, loss: 0.2637164890766144
step: 600, loss: 0.010781523771584034
step: 610, loss: 0.0011946724262088537
step: 620, loss: 0.06615684181451797
step: 630, loss: 0.06334319710731506
step: 640, loss: 0.1085776537656784
step: 650, loss: 0.029914256185293198
step: 660, loss: 0.051199771463871
step: 670, loss: 0.3046678602695465
step: 680, loss: 0.14650820195674896
step: 690, loss: 0.06861981004476547
step: 700, loss: 0.08850682526826859
step: 710, loss: 0.0664631575345993
step: 720, loss: 0.0642072781920433
step: 730, loss: 0.13070322573184967
step: 740, loss: 0.0244112778455019
step: 750, loss: 0.12822555005550385
step: 760, loss: 0.05310298502445221
step: 770, loss: 0.20221000909805298
step: 780, loss: 0.12460201978683472
step: 790, loss: 0.10162009298801422
step: 800, loss: 0.13326884806156158
step: 810, loss: 0.11494357883930206
step: 820, loss: 0.04431628808379173
step: 830, loss: 0.16611513495445251
step: 840, loss: 0.07588832825422287
step: 850, loss: 0.14676304161548615
step: 860, loss: 0.0992550477385521
step: 870, loss: 0.15573617815971375
step: 880, loss: 0.018493320792913437
step: 890, loss: 0.1462431252002716
step: 900, loss: 0.13232463598251343
step: 910, loss: 0.021953370422124863
step: 920, loss: 0.110173299908638
step: 930, loss: 0.06578964740037918
step: 940, loss: 0.18926672637462616
step: 950, loss: 0.07503120601177216
step: 960, loss: 0.1879408061504364
step: 970, loss: 0.0737297311425209
epoch 10: dev_f1=0.9305555555555556, f1=0.9264229523368811, best_f1=0.9275229357798166
step: 0, loss: 0.0960693284869194
step: 10, loss: 0.06913771480321884
step: 20, loss: 0.09206598252058029
step: 30, loss: 0.16231092810630798
step: 40, loss: 0.08099738508462906
step: 50, loss: 0.10962137579917908
step: 60, loss: 0.1600864678621292
step: 70, loss: 0.0671856477856636
step: 80, loss: 0.0857841894030571
step: 90, loss: 0.020652607083320618
step: 100, loss: 0.09327962249517441
step: 110, loss: 0.05922822281718254
step: 120, loss: 0.05160820856690407
step: 130, loss: 0.010085240937769413
step: 140, loss: 0.06352758407592773
step: 150, loss: 0.12686924636363983
step: 160, loss: 0.005325603298842907
step: 170, loss: 0.012597463093698025
step: 180, loss: 0.06615662574768066
step: 190, loss: 0.09995517134666443
step: 200, loss: 0.08006077259778976
step: 210, loss: 0.03082946129143238
step: 220, loss: 0.04029753431677818
step: 230, loss: 0.04941471293568611
step: 240, loss: 0.10767039656639099
step: 250, loss: 0.1619691252708435
step: 260, loss: 0.033884670585393906
step: 270, loss: 0.03524971380829811
step: 280, loss: 0.035495080053806305
step: 290, loss: 0.05926863104104996
step: 300, loss: 0.13882189989089966
step: 310, loss: 0.033067990094423294
step: 320, loss: 0.051426734775304794
step: 330, loss: 0.06366962939500809
step: 340, loss: 0.10464935004711151
step: 350, loss: 0.0795503482222557
step: 360, loss: 0.16755618155002594
step: 370, loss: 0.04067208990454674
step: 380, loss: 0.029916584491729736
step: 390, loss: 0.0274499598890543
step: 400, loss: 0.07966845482587814
step: 410, loss: 0.04939955100417137
step: 420, loss: 0.10234743356704712
step: 430, loss: 0.08622435480356216
step: 440, loss: 0.031069163233041763
step: 450, loss: 0.15529365837574005
step: 460, loss: 0.043139420449733734
step: 470, loss: 0.05398424342274666
step: 480, loss: 0.1125044897198677
step: 490, loss: 0.07915331423282623
step: 500, loss: 0.08764610439538956
step: 510, loss: 0.09956908226013184
step: 520, loss: 0.1167668029665947
step: 530, loss: 0.040553200989961624
step: 540, loss: 0.05608915910124779
step: 550, loss: 0.08767666667699814
step: 560, loss: 0.14599640667438507
step: 570, loss: 0.017452795058488846
step: 580, loss: 0.11532367765903473
step: 590, loss: 0.06971832364797592
step: 600, loss: 0.005497847683727741
step: 610, loss: 0.06986875087022781
step: 620, loss: 0.05000772699713707
step: 630, loss: 0.18557177484035492
step: 640, loss: 0.20008282363414764
step: 650, loss: 0.053376685827970505
step: 660, loss: 0.21140442788600922
step: 670, loss: 0.0696844831109047
step: 680, loss: 0.04499035328626633
step: 690, loss: 0.09854091703891754
step: 700, loss: 0.1248355433344841
step: 710, loss: 0.031175296753644943
step: 720, loss: 0.04443103075027466
step: 730, loss: 0.1299004852771759
step: 740, loss: 0.014427104033529758
step: 750, loss: 0.02252517081797123
step: 760, loss: 0.05988629162311554
step: 770, loss: 0.1384594440460205
step: 780, loss: 0.03720467537641525
step: 790, loss: 0.10800463706254959
step: 800, loss: 0.020617768168449402
step: 810, loss: 0.1565844565629959
step: 820, loss: 0.10434377938508987
step: 830, loss: 0.1375119388103485
step: 840, loss: 0.07766300439834595
step: 850, loss: 0.09015132486820221
step: 860, loss: 0.0691809132695198
step: 870, loss: 0.04359269142150879
step: 880, loss: 0.030805759131908417
step: 890, loss: 0.07702223211526871
step: 900, loss: 0.12059488147497177
step: 910, loss: 0.061769068241119385
step: 920, loss: 0.10767334699630737
step: 930, loss: 0.02938777580857277
step: 940, loss: 0.059359561651945114
step: 950, loss: 0.017998674884438515
step: 960, loss: 0.20901168882846832
step: 970, loss: 0.02624599263072014
epoch 11: dev_f1=0.9282428702851886, f1=0.9269870609981515, best_f1=0.9275229357798166
step: 0, loss: 0.04592614993453026
step: 10, loss: 0.04839416593313217
step: 20, loss: 0.05722704529762268
step: 30, loss: 0.09435974806547165
step: 40, loss: 0.20341329276561737
step: 50, loss: 0.14338436722755432
step: 60, loss: 0.024787968024611473
step: 70, loss: 0.10720371454954147
step: 80, loss: 0.1805986762046814
step: 90, loss: 0.1164713203907013
step: 100, loss: 0.021124619990587234
step: 110, loss: 0.021866558119654655
step: 120, loss: 0.0679241493344307
step: 130, loss: 0.0271951612085104
step: 140, loss: 0.18811585009098053
step: 150, loss: 0.08486708253622055
step: 160, loss: 0.13663677871227264
step: 170, loss: 0.04644421488046646
step: 180, loss: 0.02342560701072216
step: 190, loss: 0.0002215183194493875
step: 200, loss: 0.18593667447566986
step: 210, loss: 0.0262717604637146
step: 220, loss: 0.1902206838130951
step: 230, loss: 0.10852198302745819
step: 240, loss: 0.0651324987411499
step: 250, loss: 0.08288358896970749
step: 260, loss: 0.11866212636232376
step: 270, loss: 0.06325671821832657
step: 280, loss: 0.07307296991348267
step: 290, loss: 0.08459488302469254
step: 300, loss: 0.1589164435863495
step: 310, loss: 0.1294633448123932
step: 320, loss: 0.027914984151721
step: 330, loss: 0.05535047873854637
step: 340, loss: 0.11187980324029922
step: 350, loss: 0.0384189635515213
step: 360, loss: 0.028357069939374924
step: 370, loss: 0.14873006939888
step: 380, loss: 0.0761035829782486
step: 390, loss: 0.1603802889585495
step: 400, loss: 0.12945233285427094
step: 410, loss: 0.1576269418001175
step: 420, loss: 0.1432991921901703
step: 430, loss: 0.05835729464888573
step: 440, loss: 0.05611412227153778
step: 450, loss: 0.07277148216962814
step: 460, loss: 0.019019994884729385
step: 470, loss: 0.16433151066303253
step: 480, loss: 0.13681550323963165
step: 490, loss: 0.025943806394934654
step: 500, loss: 0.026500927284359932
step: 510, loss: 0.10875124484300613
step: 520, loss: 0.04427613690495491
step: 530, loss: 0.10595729947090149
step: 540, loss: 0.06585725396871567
step: 550, loss: 0.0651383027434349
step: 560, loss: 0.153117835521698
step: 570, loss: 0.08578360825777054
step: 580, loss: 0.10253889858722687
step: 590, loss: 0.04175352677702904
step: 600, loss: 0.14356546103954315
step: 610, loss: 0.026831796392798424
step: 620, loss: 0.026681577786803246
step: 630, loss: 0.19365882873535156
step: 640, loss: 0.11961612105369568
step: 650, loss: 0.15740475058555603
step: 660, loss: 0.012822980992496014
step: 670, loss: 0.04498818516731262
step: 680, loss: 0.06943731755018234
step: 690, loss: 0.04922185093164444
step: 700, loss: 0.029487373307347298
step: 710, loss: 0.05814775824546814
step: 720, loss: 0.018414679914712906
step: 730, loss: 0.11875706911087036
step: 740, loss: 0.048835523426532745
step: 750, loss: 0.16604164242744446
step: 760, loss: 0.17460015416145325
step: 770, loss: 0.07058510184288025
step: 780, loss: 0.11733513325452805
step: 790, loss: 0.07675939798355103
step: 800, loss: 0.12320627272129059
step: 810, loss: 0.1453505903482437
step: 820, loss: 0.06771422922611237
step: 830, loss: 0.10443397611379623
step: 840, loss: 0.017718512564897537
step: 850, loss: 0.17054001986980438
step: 860, loss: 0.0732978880405426
step: 870, loss: 0.11457722634077072
step: 880, loss: 0.07993480563163757
step: 890, loss: 0.10466930270195007
step: 900, loss: 0.08094216138124466
step: 910, loss: 0.06640726327896118
step: 920, loss: 0.06400656700134277
step: 930, loss: 0.08365871757268906
step: 940, loss: 0.14949579536914825
step: 950, loss: 0.10599967837333679
step: 960, loss: 0.08480425179004669
step: 970, loss: 0.03448311984539032
epoch 12: dev_f1=0.9300827966881325, f1=0.926605504587156, best_f1=0.9275229357798166
step: 0, loss: 0.03370347246527672
step: 10, loss: 0.12682200968265533
step: 20, loss: 0.041528407484292984
step: 30, loss: 0.0675187036395073
step: 40, loss: 0.04291364550590515
step: 50, loss: 0.03996887058019638
step: 60, loss: 0.10222571343183517
step: 70, loss: 0.056995537132024765
step: 80, loss: 0.24798627197742462
step: 90, loss: 0.07197827845811844
step: 100, loss: 0.11999119818210602
step: 110, loss: 0.05384192615747452
step: 120, loss: 0.07392507046461105
step: 130, loss: 0.03975624218583107
step: 140, loss: 0.03280407562851906
step: 150, loss: 0.012960681691765785
step: 160, loss: 0.05782751739025116
step: 170, loss: 0.08562743663787842
step: 180, loss: 0.053968966007232666
step: 190, loss: 0.10514900088310242
step: 200, loss: 0.01858656480908394
step: 210, loss: 0.040941983461380005
step: 220, loss: 0.2596319019794464
step: 230, loss: 0.2187974601984024
step: 240, loss: 0.07994824647903442
step: 250, loss: 0.12674863636493683
step: 260, loss: 0.08567716926336288
step: 270, loss: 0.029672082513570786
step: 280, loss: 0.06384766101837158
step: 290, loss: 0.0654202252626419
step: 300, loss: 0.08669503033161163
step: 310, loss: 0.08385276794433594
step: 320, loss: 0.034917689859867096
step: 330, loss: 0.03103511780500412
step: 340, loss: 0.06476126611232758
step: 350, loss: 0.013487335294485092
step: 360, loss: 0.12969765067100525
step: 370, loss: 0.06570685654878616
step: 380, loss: 0.052861008793115616
step: 390, loss: 0.20435447990894318
step: 400, loss: 0.00303342891857028
step: 410, loss: 0.05174000561237335
step: 420, loss: 0.15038904547691345
step: 430, loss: 0.16428236663341522
step: 440, loss: 0.04357811436057091
step: 450, loss: 0.04962839186191559
step: 460, loss: 0.08327285200357437
step: 470, loss: 0.057057030498981476
step: 480, loss: 0.10770191997289658
step: 490, loss: 0.010287409648299217
step: 500, loss: 0.028870875015854836
step: 510, loss: 0.14357709884643555
step: 520, loss: 0.06690096110105515
step: 530, loss: 0.09660016000270844
step: 540, loss: 0.044529758393764496
step: 550, loss: 0.1323096603155136
step: 560, loss: 0.043778952211141586
step: 570, loss: 0.10513286292552948
step: 580, loss: 0.0732712522149086
step: 590, loss: 0.06155853345990181
step: 600, loss: 0.18966522812843323
step: 610, loss: 0.03535648062825203
step: 620, loss: 0.13846847414970398
step: 630, loss: 0.07796177268028259
step: 640, loss: 0.053708817809820175
step: 650, loss: 0.07613957673311234
step: 660, loss: 0.07418078184127808
step: 670, loss: 0.19860140979290009
step: 680, loss: 0.07250478118658066
step: 690, loss: 0.0849844366312027
step: 700, loss: 0.02097584865987301
step: 710, loss: 0.10787568986415863
step: 720, loss: 0.13554604351520538
step: 730, loss: 0.06061391159892082
step: 740, loss: 0.07621468603610992
step: 750, loss: 0.03384573385119438
step: 760, loss: 0.028011955320835114
step: 770, loss: 0.016286540776491165
step: 780, loss: 0.035414814949035645
step: 790, loss: 0.08922011405229568
step: 800, loss: 0.09938248991966248
step: 810, loss: 0.03308553248643875
step: 820, loss: 0.16496212780475616
step: 830, loss: 0.13712693750858307
step: 840, loss: 0.13670985400676727
step: 850, loss: 0.04192031919956207
step: 860, loss: 0.018794653937220573
step: 870, loss: 0.023748870939016342
step: 880, loss: 0.15541954338550568
step: 890, loss: 0.02036760374903679
step: 900, loss: 0.04839126393198967
step: 910, loss: 0.2210404872894287
step: 920, loss: 0.06330826133489609
step: 930, loss: 0.08155199140310287
step: 940, loss: 0.03559762239456177
step: 950, loss: 0.034471165388822556
step: 960, loss: 0.1260112226009369
step: 970, loss: 0.08982211351394653
epoch 13: dev_f1=0.9297347603536529, f1=0.9237209302325581, best_f1=0.9275229357798166
step: 0, loss: 0.02507481724023819
step: 10, loss: 0.12383200973272324
step: 20, loss: 0.11953013390302658
step: 30, loss: 0.012610872276127338
step: 40, loss: 0.037646591663360596
step: 50, loss: 0.06549286842346191
step: 60, loss: 0.022513139992952347
step: 70, loss: 0.08700941503047943
step: 80, loss: 0.05718541890382767
step: 90, loss: 1.9460359908407554e-05
step: 100, loss: 0.04268874600529671
step: 110, loss: 0.022758904844522476
step: 120, loss: 0.010704650543630123
step: 130, loss: 0.007814040407538414
step: 140, loss: 0.023840535432100296
step: 150, loss: 0.17606671154499054
step: 160, loss: 0.053219035267829895
step: 170, loss: 0.014053145423531532
step: 180, loss: 0.16163130104541779
step: 190, loss: 0.08111009001731873
step: 200, loss: 0.0745786800980568
step: 210, loss: 0.03477500379085541
step: 220, loss: 0.061510100960731506
step: 230, loss: 0.026645123958587646
step: 240, loss: 0.025158582255244255
step: 250, loss: 0.015697365626692772
step: 260, loss: 0.037038497626781464
step: 270, loss: 0.05161391943693161
step: 280, loss: 0.04274538531899452
step: 290, loss: 0.029364734888076782
step: 300, loss: 0.02275230921804905
step: 310, loss: 0.08252184838056564
step: 320, loss: 0.03794680908322334
step: 330, loss: 0.02061387151479721
step: 340, loss: 0.05704290792346001
step: 350, loss: 0.03537437692284584
step: 360, loss: 0.0505426749587059
step: 370, loss: 0.09597627073526382
step: 380, loss: 0.06878454238176346
step: 390, loss: 0.06824345886707306
step: 400, loss: 0.15810495615005493
step: 410, loss: 0.139627143740654
step: 420, loss: 0.05544638633728027
step: 430, loss: 0.0703827366232872
step: 440, loss: 0.03557121008634567
step: 450, loss: 0.04925474524497986
step: 460, loss: 0.03193541243672371
step: 470, loss: 0.11069474369287491
step: 480, loss: 0.1241891011595726
step: 490, loss: 0.11645185947418213
step: 500, loss: 1.216670989379054e-05
step: 510, loss: 0.072323277592659
step: 520, loss: 0.1709929257631302
step: 530, loss: 0.08186260610818863
step: 540, loss: 0.009712021797895432
step: 550, loss: 0.0660991296172142
step: 560, loss: 0.05151337385177612
step: 570, loss: 0.10774490237236023
step: 580, loss: 0.060394659638404846
step: 590, loss: 0.023151161149144173
step: 600, loss: 0.2616339325904846
step: 610, loss: 0.08331778645515442
step: 620, loss: 0.05650094896554947
step: 630, loss: 0.09079844504594803
step: 640, loss: 0.04225380718708038
step: 650, loss: 0.0450437068939209
step: 660, loss: 0.10098974406719208
step: 670, loss: 0.04514274373650551
step: 680, loss: 0.015566880814731121
step: 690, loss: 0.026316309347748756
step: 700, loss: 0.008749229833483696
step: 710, loss: 0.01897328719496727
step: 720, loss: 0.023903867229819298
step: 730, loss: 0.004459589719772339
step: 740, loss: 0.08548921346664429
step: 750, loss: 0.05461578816175461
step: 760, loss: 0.10082248598337173
step: 770, loss: 0.08742482215166092
step: 780, loss: 0.15541359782218933
step: 790, loss: 0.0562252439558506
step: 800, loss: 0.04917226359248161
step: 810, loss: 0.03684424236416817
step: 820, loss: 0.08610222488641739
step: 830, loss: 0.048776593059301376
step: 840, loss: 0.06729549169540405
step: 850, loss: 0.13229864835739136
step: 860, loss: 0.03882400318980217
step: 870, loss: 0.024554193019866943
step: 880, loss: 0.08754193782806396
step: 890, loss: 0.028183983638882637
step: 900, loss: 0.046677540987730026
step: 910, loss: 0.05212470144033432
step: 920, loss: 0.13172854483127594
step: 930, loss: 0.011485651135444641
step: 940, loss: 0.050982579588890076
step: 950, loss: 0.06407754123210907
step: 960, loss: 0.04642941430211067
step: 970, loss: 0.05622658506035805
epoch 14: dev_f1=0.927536231884058, f1=0.9249417249417249, best_f1=0.9275229357798166
step: 0, loss: 0.0537215955555439
step: 10, loss: 0.05080019310116768
step: 20, loss: 0.07138426601886749
step: 30, loss: 0.02701718546450138
step: 40, loss: 0.05711636319756508
step: 50, loss: 0.04984351620078087
step: 60, loss: 0.003205705899745226
step: 70, loss: 0.08078353852033615
step: 80, loss: 0.013137159869074821
step: 90, loss: 0.12228915840387344
step: 100, loss: 0.02697824500501156
step: 110, loss: 0.04910571873188019
step: 120, loss: 0.006680759135633707
step: 130, loss: 0.03974674642086029
step: 140, loss: 0.06164450943470001
step: 150, loss: 0.06493628770112991
step: 160, loss: 0.038985833525657654
step: 170, loss: 0.05689995363354683
step: 180, loss: 0.049324095249176025
step: 190, loss: 0.00027517773560248315
step: 200, loss: 0.07025811821222305
step: 210, loss: 1.2900551155325957e-05
step: 220, loss: 0.04696044325828552
step: 230, loss: 0.04311053454875946
step: 240, loss: 0.06805852055549622
step: 250, loss: 0.027080802246928215
step: 260, loss: 0.035771872848272324
step: 270, loss: 0.020301973447203636
step: 280, loss: 0.06822923570871353
step: 290, loss: 0.04107805714011192
step: 300, loss: 0.06481529027223587
step: 310, loss: 0.011924167163670063
step: 320, loss: 0.07778115570545197
step: 330, loss: 0.005473720375448465
step: 340, loss: 0.048227325081825256
step: 350, loss: 0.13094832003116608
step: 360, loss: 0.1290065497159958
step: 370, loss: 0.05036851763725281
step: 380, loss: 0.049510132521390915
step: 390, loss: 0.0033423788845539093
step: 400, loss: 0.11865133047103882
step: 410, loss: 0.04372747242450714
step: 420, loss: 0.09509287029504776
step: 430, loss: 0.051851969212293625
step: 440, loss: 0.0629790648818016
step: 450, loss: 0.0804436132311821
step: 460, loss: 0.03422621265053749
step: 470, loss: 0.10883413255214691
step: 480, loss: 0.04806092754006386
step: 490, loss: 0.08526534587144852
step: 500, loss: 0.04113180562853813
step: 510, loss: 0.05217425152659416
step: 520, loss: 0.06957384943962097
step: 530, loss: 0.1356503814458847
step: 540, loss: 0.04806584119796753
step: 550, loss: 0.06494497507810593
step: 560, loss: 0.06339237093925476
step: 570, loss: 0.08386493474245071
step: 580, loss: 0.02430093102157116
step: 590, loss: 0.0888885110616684
step: 600, loss: 0.08431251347064972
step: 610, loss: 0.005729298107326031
step: 620, loss: 0.12062428146600723
step: 630, loss: 0.030141957104206085
step: 640, loss: 0.06715798377990723
step: 650, loss: 0.02275431901216507
step: 660, loss: 0.12674424052238464
step: 670, loss: 0.11040516942739487
step: 680, loss: 0.0006046686321496964
step: 690, loss: 0.06130794808268547
step: 700, loss: 0.046676602214574814
step: 710, loss: 0.08673684298992157
step: 720, loss: 0.00044040894135832787
step: 730, loss: 0.09322777390480042
step: 740, loss: 0.06328704953193665
step: 750, loss: 0.016967682167887688
step: 760, loss: 0.029246395453810692
step: 770, loss: 0.05444914102554321
step: 780, loss: 0.020235028117895126
step: 790, loss: 0.03264852613210678
step: 800, loss: 0.035374484956264496
step: 810, loss: 0.06748617440462112
step: 820, loss: 0.12515892088413239
step: 830, loss: 0.03606219217181206
step: 840, loss: 0.016300052404403687
step: 850, loss: 0.10260642319917679
step: 860, loss: 0.05128778889775276
step: 870, loss: 0.014205515384674072
step: 880, loss: 0.09260816872119904
step: 890, loss: 0.054187990725040436
step: 900, loss: 0.06484434753656387
step: 910, loss: 0.03881759196519852
step: 920, loss: 0.07882363349199295
step: 930, loss: 0.13974864780902863
step: 940, loss: 0.018315233290195465
step: 950, loss: 0.032700058072805405
step: 960, loss: 0.0506562814116478
step: 970, loss: 0.08605723828077316
epoch 15: dev_f1=0.931892907468295, f1=0.9286047596826879, best_f1=0.9275229357798166
step: 0, loss: 0.04148539528250694
step: 10, loss: 0.06886570900678635
step: 20, loss: 0.05957355350255966
step: 30, loss: 0.06379677355289459
step: 40, loss: 0.11123533546924591
step: 50, loss: 7.816965808160603e-05
step: 60, loss: 0.003911295905709267
step: 70, loss: 0.007799680810421705
step: 80, loss: 0.040876604616642
step: 90, loss: 0.06789267063140869
step: 100, loss: 0.02377181500196457
step: 110, loss: 0.06708935648202896
step: 120, loss: 0.015212980099022388
step: 130, loss: 0.036416832357645035
step: 140, loss: 0.0782681480050087
step: 150, loss: 0.008385445922613144
step: 160, loss: 0.017408285290002823
step: 170, loss: 0.023598279803991318
step: 180, loss: 0.0420101173222065
step: 190, loss: 0.10471799969673157
step: 200, loss: 0.06195690855383873
step: 210, loss: 0.03152274712920189
step: 220, loss: 0.05941319838166237
step: 230, loss: 0.04495543614029884
step: 240, loss: 0.01101817935705185
step: 250, loss: 0.07430917769670486
step: 260, loss: 0.030544254928827286
step: 270, loss: 0.12302009016275406
step: 280, loss: 0.07239548116922379
step: 290, loss: 0.04330437630414963
step: 300, loss: 0.07679247111082077
step: 310, loss: 0.09409397095441818
step: 320, loss: 0.21338100731372833
step: 330, loss: 0.03762967884540558
step: 340, loss: 0.03281388431787491
step: 350, loss: 0.012426027096807957
step: 360, loss: 0.07398947328329086
step: 370, loss: 0.12398268282413483
step: 380, loss: 0.05791030824184418
step: 390, loss: 0.12762965261936188
step: 400, loss: 0.02608468569815159
step: 410, loss: 0.023237459361553192
step: 420, loss: 0.1524987667798996
step: 430, loss: 0.03629171848297119
step: 440, loss: 0.010442497208714485
step: 450, loss: 0.02181328274309635
step: 460, loss: 0.03238707408308983
step: 470, loss: 0.03188306838274002
step: 480, loss: 0.05252962186932564
step: 490, loss: 0.007551481481641531
step: 500, loss: 0.00024112500250339508
step: 510, loss: 0.1721336841583252
step: 520, loss: 0.040132075548172
step: 530, loss: 0.00045082828728482127
step: 540, loss: 0.03609159216284752
step: 550, loss: 0.1543918401002884
step: 560, loss: 0.0946173369884491
step: 570, loss: 0.0347265750169754
step: 580, loss: 0.00011141954018967226
step: 590, loss: 0.17324964702129364
step: 600, loss: 0.049824781715869904
step: 610, loss: 0.12785431742668152
step: 620, loss: 0.08844161033630371
step: 630, loss: 0.05462081357836723
step: 640, loss: 0.04060214012861252
step: 650, loss: 0.0753583237528801
step: 660, loss: 0.0739540159702301
step: 670, loss: 0.06135407090187073
step: 680, loss: 0.059294573962688446
step: 690, loss: 0.040356338024139404
step: 700, loss: 0.08682441711425781
step: 710, loss: 0.06472043693065643
step: 720, loss: 0.011298679746687412
step: 730, loss: 0.09313201904296875
step: 740, loss: 0.11200185865163803
step: 750, loss: 0.03546901047229767
step: 760, loss: 0.04542263224720955
step: 770, loss: 0.018435457721352577
step: 780, loss: 0.1071399599313736
step: 790, loss: 0.023094508796930313
step: 800, loss: 0.02169571816921234
step: 810, loss: 0.068574458360672
step: 820, loss: 0.00021786917932331562
step: 830, loss: 0.09943047165870667
step: 840, loss: 0.11341800540685654
step: 850, loss: 0.04562161862850189
step: 860, loss: 0.04744020476937294
step: 870, loss: 0.04079786688089371
step: 880, loss: 0.06064922362565994
step: 890, loss: 0.0025233274791389704
step: 900, loss: 0.026023749262094498
step: 910, loss: 0.009453730657696724
step: 920, loss: 0.08332327753305435
step: 930, loss: 0.0611121729016304
step: 940, loss: 0.09349329024553299
step: 950, loss: 0.12154693156480789
step: 960, loss: 0.0352863147854805
step: 970, loss: 0.0007266260799951851
epoch 16: dev_f1=0.9306930693069307, f1=0.924092409240924, best_f1=0.9275229357798166
step: 0, loss: 0.03263411670923233
step: 10, loss: 0.030647825449705124
step: 20, loss: 0.0669383555650711
step: 30, loss: 0.05698420852422714
step: 40, loss: 0.08182714879512787
step: 50, loss: 0.010624122805893421
step: 60, loss: 0.018424859270453453
step: 70, loss: 0.06016065925359726
step: 80, loss: 0.04084475710988045
step: 90, loss: 0.03321532532572746
step: 100, loss: 0.016880489885807037
step: 110, loss: 0.03340611234307289
step: 120, loss: 0.005174686200916767
step: 130, loss: 2.251849218737334e-05
step: 140, loss: 0.028094984591007233
step: 150, loss: 0.07507269829511642
step: 160, loss: 0.01785382069647312
step: 170, loss: 0.07911599427461624
step: 180, loss: 0.03997022658586502
step: 190, loss: 0.08857234567403793
step: 200, loss: 0.054982949048280716
step: 210, loss: 0.053153738379478455
step: 220, loss: 0.08445236831903458
step: 230, loss: 0.054018378257751465
step: 240, loss: 0.02416500449180603
step: 250, loss: 0.05011781305074692
step: 260, loss: 0.05878325551748276
step: 270, loss: 0.01996752992272377
step: 280, loss: 0.0901554748415947
step: 290, loss: 0.10378146916627884
step: 300, loss: 0.05360531806945801
step: 310, loss: 0.0985620990395546
step: 320, loss: 0.0258144810795784
step: 330, loss: 0.056902967393398285
step: 340, loss: 0.08900316804647446
step: 350, loss: 0.09439308941364288
step: 360, loss: 0.09068115055561066
step: 370, loss: 0.027019381523132324
step: 380, loss: 0.09895484894514084
step: 390, loss: 0.0063942051492631435
step: 400, loss: 0.011015181429684162
step: 410, loss: 0.12662675976753235
step: 420, loss: 0.03217534348368645
step: 430, loss: 0.05109482258558273
step: 440, loss: 0.05042422190308571
step: 450, loss: 0.09538698941469193
step: 460, loss: 0.08123929053544998
step: 470, loss: 0.10142157226800919
step: 480, loss: 0.17806558310985565
step: 490, loss: 0.07260674238204956
step: 500, loss: 0.010613517835736275
step: 510, loss: 0.08995066583156586
step: 520, loss: 0.038600001484155655
step: 530, loss: 0.05328509584069252
step: 540, loss: 0.05807805433869362
step: 550, loss: 0.11605440080165863
step: 560, loss: 0.04828444868326187
step: 570, loss: 0.053777456283569336
step: 580, loss: 0.04446228966116905
step: 590, loss: 0.07205459475517273
step: 600, loss: 0.022232402116060257
step: 610, loss: 0.11511678993701935
step: 620, loss: 0.05783167481422424
step: 630, loss: 0.03183621168136597
step: 640, loss: 0.12699535489082336
step: 650, loss: 0.0796721950173378
step: 660, loss: 0.061492759734392166
step: 670, loss: 0.027067016810178757
step: 680, loss: 0.034773241728544235
step: 690, loss: 0.07881974428892136
step: 700, loss: 0.08093197643756866
step: 710, loss: 0.12000416964292526
step: 720, loss: 0.09678077697753906
step: 730, loss: 0.062466513365507126
step: 740, loss: 0.05667845159769058
step: 750, loss: 0.030477259308099747
step: 760, loss: 0.1545078307390213
step: 770, loss: 0.06620562076568604
step: 780, loss: 0.018283192068338394
step: 790, loss: 0.051085762679576874
step: 800, loss: 0.1105227842926979
step: 810, loss: 0.07091556489467621
step: 820, loss: 0.01335437037050724
step: 830, loss: 0.06080830469727516
step: 840, loss: 0.07056978344917297
step: 850, loss: 0.19658714532852173
step: 860, loss: 0.057897090911865234
step: 870, loss: 0.05250629782676697
step: 880, loss: 0.10503821820020676
step: 890, loss: 0.026110196486115456
step: 900, loss: 0.121306873857975
step: 910, loss: 0.11631576716899872
step: 920, loss: 0.01903146505355835
step: 930, loss: 0.04689805954694748
step: 940, loss: 0.13511969149112701
step: 950, loss: 0.0026411758735775948
step: 960, loss: 0.06773416697978973
step: 970, loss: 0.03477422147989273
epoch 17: dev_f1=0.931377188831046, f1=0.9208905731880626, best_f1=0.9275229357798166
step: 0, loss: 0.04578496888279915
step: 10, loss: 0.05810794234275818
step: 20, loss: 0.010808022692799568
step: 30, loss: 0.07097237557172775
step: 40, loss: 0.05794442445039749
step: 50, loss: 0.0905899778008461
step: 60, loss: 0.04661430045962334
step: 70, loss: 0.02398388460278511
step: 80, loss: 0.04342799633741379
step: 90, loss: 0.14228877425193787
step: 100, loss: 0.16554541885852814
step: 110, loss: 0.04133068025112152
step: 120, loss: 0.04239024594426155
step: 130, loss: 0.042930953204631805
step: 140, loss: 0.030770007520914078
step: 150, loss: 0.02192782424390316
step: 160, loss: 0.11160176992416382
step: 170, loss: 0.011066172271966934
step: 180, loss: 0.07627042382955551
step: 190, loss: 0.06548622250556946
step: 200, loss: 0.08795159310102463
step: 210, loss: 0.031384557485580444
step: 220, loss: 0.07300321012735367
step: 230, loss: 0.02449912019073963
step: 240, loss: 0.0656597912311554
step: 250, loss: 0.021079588681459427
step: 260, loss: 0.07268048822879791
step: 270, loss: 0.06688150763511658
step: 280, loss: 0.05404840409755707
step: 290, loss: 0.04345908761024475
step: 300, loss: 0.05200384184718132
step: 310, loss: 0.09206033498048782
step: 320, loss: 0.020880941301584244
step: 330, loss: 0.06517475098371506
step: 340, loss: 0.014958103187382221
step: 350, loss: 0.00017868306895252317
step: 360, loss: 2.0335699446150102e-05
step: 370, loss: 0.014059184119105339
step: 380, loss: 0.055796124041080475
step: 390, loss: 0.07120589911937714
step: 400, loss: 0.020013295114040375
step: 410, loss: 0.02390488050878048
step: 420, loss: 0.023537425324320793
step: 430, loss: 0.07093114405870438
step: 440, loss: 6.526867218781263e-05
step: 450, loss: 9.547871741233394e-06
step: 460, loss: 0.06740681827068329
step: 470, loss: 0.034230295568704605
step: 480, loss: 0.10683530569076538
step: 490, loss: 0.07417687028646469
step: 500, loss: 0.015376245602965355
step: 510, loss: 0.0015007082838565111
step: 520, loss: 0.11058257520198822
step: 530, loss: 0.08976364880800247
step: 540, loss: 0.06762152910232544
step: 550, loss: 0.04232317581772804
step: 560, loss: 0.08177974820137024
step: 570, loss: 0.1029093936085701
step: 580, loss: 0.061576277017593384
step: 590, loss: 0.044460479170084
step: 600, loss: 0.0010596350766718388
step: 610, loss: 0.05820123851299286
step: 620, loss: 0.07077844440937042
step: 630, loss: 0.05743171647191048
step: 640, loss: 0.05363565310835838
step: 650, loss: 0.06091843545436859
step: 660, loss: 0.09454523026943207
step: 670, loss: 0.1226315125823021
step: 680, loss: 0.06641659885644913
step: 690, loss: 0.011540506035089493
step: 700, loss: 0.03732746094465256
step: 710, loss: 0.04212997481226921
step: 720, loss: 0.14027179777622223
step: 730, loss: 0.07083649188280106
step: 740, loss: 0.08075672388076782
step: 750, loss: 0.06275772303342819
step: 760, loss: 2.7491149012348615e-05
step: 770, loss: 0.13242226839065552
step: 780, loss: 0.029253095388412476
step: 790, loss: 0.06056904047727585
step: 800, loss: 0.02561940811574459
step: 810, loss: 0.005586267448961735
step: 820, loss: 0.010714917443692684
step: 830, loss: 0.052238527685403824
step: 840, loss: 0.09131979942321777
step: 850, loss: 0.1294248402118683
step: 860, loss: 0.09480944275856018
step: 870, loss: 0.059705059975385666
step: 880, loss: 0.041252005845308304
step: 890, loss: 0.013929164968430996
step: 900, loss: 0.05707566812634468
step: 910, loss: 0.09238003939390182
step: 920, loss: 0.008322827517986298
step: 930, loss: 0.061174292117357254
step: 940, loss: 0.0726955235004425
step: 950, loss: 0.08170255273580551
step: 960, loss: 0.13427186012268066
step: 970, loss: 0.016306020319461823
epoch 18: dev_f1=0.9298823529411765, f1=0.9223573433115062, best_f1=0.9275229357798166
step: 0, loss: 0.1006496250629425
step: 10, loss: 0.022743966430425644
step: 20, loss: 0.06018000468611717
step: 30, loss: 0.08899859338998795
step: 40, loss: 0.08153195679187775
step: 50, loss: 0.02466629445552826
step: 60, loss: 0.12614093720912933
step: 70, loss: 0.005870739929378033
step: 80, loss: 0.08116789907217026
step: 90, loss: 0.03820190951228142
step: 100, loss: 0.04535309597849846
step: 110, loss: 0.06345122307538986
step: 120, loss: 0.04032604768872261
step: 130, loss: 0.06866631656885147
step: 140, loss: 0.026942281052470207
step: 150, loss: 0.10217802226543427
step: 160, loss: 0.025267286226153374
step: 170, loss: 0.05799293890595436
step: 180, loss: 0.07288987934589386
step: 190, loss: 0.14051637053489685
step: 200, loss: 0.04333949089050293
step: 210, loss: 0.13040898740291595
step: 220, loss: 0.02842460572719574
step: 230, loss: 0.024239204823970795
step: 240, loss: 0.0014520463300868869
step: 250, loss: 0.09692303091287613
step: 260, loss: 0.04038815200328827
step: 270, loss: 0.06732223182916641
step: 280, loss: 0.040765151381492615
step: 290, loss: 0.02469085156917572
step: 300, loss: 0.07502084225416183
step: 310, loss: 0.03697413578629494
step: 320, loss: 0.09042750298976898
step: 330, loss: 0.015451430343091488
step: 340, loss: 2.03749423235422e-05
step: 350, loss: 0.022011900320649147
step: 360, loss: 0.06678063422441483
step: 370, loss: 0.056713324040174484
step: 380, loss: 0.055317848920822144
step: 390, loss: 2.6279834855813533e-05
step: 400, loss: 0.026120934635400772
step: 410, loss: 0.009665675461292267
step: 420, loss: 0.06361046433448792
step: 430, loss: 0.038377970457077026
step: 440, loss: 0.08005093038082123
step: 450, loss: 0.13115528225898743
step: 460, loss: 0.10240373760461807
step: 470, loss: 9.336179937236011e-05
step: 480, loss: 0.1234762966632843
step: 490, loss: 0.04652984067797661
step: 500, loss: 0.07088900357484818
step: 510, loss: 0.05278830975294113
step: 520, loss: 0.031083600595593452
step: 530, loss: 0.08005513995885849
step: 540, loss: 0.036730214953422546
step: 550, loss: 0.018416643142700195
step: 560, loss: 0.048772186040878296
step: 570, loss: 0.116946280002594
step: 580, loss: 0.07396599650382996
step: 590, loss: 0.09366346895694733
step: 600, loss: 0.05391897261142731
step: 610, loss: 0.04570205137133598
step: 620, loss: 0.060483336448669434
step: 630, loss: 0.026901278644800186
step: 640, loss: 0.05386677756905556
step: 650, loss: 0.01725269854068756
step: 660, loss: 0.07042087614536285
step: 670, loss: 0.10744910687208176
step: 680, loss: 0.05906634405255318
step: 690, loss: 0.0013948436826467514
step: 700, loss: 0.12270812690258026
step: 710, loss: 0.08712884783744812
step: 720, loss: 0.028468823060393333
step: 730, loss: 0.11047614365816116
step: 740, loss: 0.16982661187648773
step: 750, loss: 0.01719658635556698
step: 760, loss: 0.013652332127094269
step: 770, loss: 0.04490695521235466
step: 780, loss: 0.07125832140445709
step: 790, loss: 0.03037974424660206
step: 800, loss: 0.09547454118728638
step: 810, loss: 0.11000452935695648
step: 820, loss: 0.05749315768480301
step: 830, loss: 0.07047992944717407
step: 840, loss: 0.0062255337834358215
step: 850, loss: 0.014654630795121193
step: 860, loss: 0.018365634605288506
step: 870, loss: 0.04486120492219925
step: 880, loss: 0.011266057379543781
step: 890, loss: 0.14168772101402283
step: 900, loss: 0.0004459442861843854
step: 910, loss: 0.047240566462278366
step: 920, loss: 0.022102115675807
step: 930, loss: 0.032294947654008865
step: 940, loss: 0.0366223119199276
step: 950, loss: 0.095810167491436
step: 960, loss: 0.019449764862656593
step: 970, loss: 0.1072460189461708
epoch 19: dev_f1=0.9301227573182248, f1=0.924092409240924, best_f1=0.9275229357798166
step: 0, loss: 0.09095536172389984
step: 10, loss: 0.032456424087285995
step: 20, loss: 0.009640618227422237
step: 30, loss: 0.03793938830494881
step: 40, loss: 0.02502504177391529
step: 50, loss: 0.0316738560795784
step: 60, loss: 0.05935036391019821
step: 70, loss: 0.03211341053247452
step: 80, loss: 0.035776376724243164
step: 90, loss: 1.1045417522836942e-05
step: 100, loss: 0.06261739134788513
step: 110, loss: 2.7576837965170853e-05
step: 120, loss: 0.04945274069905281
step: 130, loss: 0.06008725240826607
step: 140, loss: 0.04252653196454048
step: 150, loss: 0.05388704314827919
step: 160, loss: 0.041420355439186096
step: 170, loss: 0.013530263677239418
step: 180, loss: 0.11901966482400894
step: 190, loss: 0.00028763755108229816
step: 200, loss: 0.05903644487261772
step: 210, loss: 0.020277203992009163
step: 220, loss: 0.010324304923415184
step: 230, loss: 0.07602453976869583
step: 240, loss: 0.1157519593834877
step: 250, loss: 5.425616109278053e-05
step: 260, loss: 0.00016243458958342671
step: 270, loss: 0.06447377800941467
step: 280, loss: 0.033389363437891006
step: 290, loss: 0.05218726769089699
step: 300, loss: 0.08997006714344025
step: 310, loss: 0.07368230819702148
step: 320, loss: 0.03054857812821865
step: 330, loss: 0.051410481333732605
step: 340, loss: 0.06014377623796463
step: 350, loss: 0.1069571003317833
step: 360, loss: 0.05229386314749718
step: 370, loss: 0.034813445061445236
step: 380, loss: 0.016236213967204094
step: 390, loss: 2.0272382244002074e-05
step: 400, loss: 0.025676660239696503
step: 410, loss: 0.12736141681671143
step: 420, loss: 0.045436590909957886
step: 430, loss: 0.03795824944972992
step: 440, loss: 0.11505238711833954
step: 450, loss: 0.03058447688817978
step: 460, loss: 0.06913642585277557
step: 470, loss: 0.12379736453294754
step: 480, loss: 4.685496605816297e-05
step: 490, loss: 0.035239093005657196
step: 500, loss: 0.07174135744571686
step: 510, loss: 0.02972753904759884
step: 520, loss: 0.06169569492340088
step: 530, loss: 0.059538211673498154
step: 540, loss: 0.08966189622879028
step: 550, loss: 0.026359155774116516
step: 560, loss: 0.06990399956703186
step: 570, loss: 0.05538921430706978
step: 580, loss: 0.06212498992681503
step: 590, loss: 0.08281460404396057
step: 600, loss: 0.0015416651731356978
step: 610, loss: 0.08696088194847107
step: 620, loss: 0.08395952731370926
step: 630, loss: 0.04460281878709793
step: 640, loss: 0.017227765172719955
step: 650, loss: 0.053286436945199966
step: 660, loss: 0.15358024835586548
step: 670, loss: 0.05943867936730385
step: 680, loss: 0.09953130781650543
step: 690, loss: 0.019362254068255424
step: 700, loss: 0.07520792633295059
step: 710, loss: 0.025798004120588303
step: 720, loss: 3.138144893455319e-05
step: 730, loss: 0.03333882614970207
step: 740, loss: 0.08913689106702805
step: 750, loss: 0.05150104686617851
step: 760, loss: 0.01449554692953825
step: 770, loss: 0.025081060826778412
step: 780, loss: 0.08960520476102829
step: 790, loss: 0.05004172399640083
step: 800, loss: 0.08970299363136292
step: 810, loss: 0.04212058335542679
step: 820, loss: 0.055559009313583374
step: 830, loss: 0.08084066212177277
step: 840, loss: 0.04096350073814392
step: 850, loss: 0.08760762214660645
step: 860, loss: 0.054542068392038345
step: 870, loss: 0.04528265446424484
step: 880, loss: 0.019413713365793228
step: 890, loss: 0.05994010716676712
step: 900, loss: 0.05101904645562172
step: 910, loss: 0.028244201093912125
step: 920, loss: 0.07501468807458878
step: 930, loss: 2.0380453861434944e-05
step: 940, loss: 0.06015847623348236
step: 950, loss: 0.04846173897385597
step: 960, loss: 2.4470289645250887e-05
step: 970, loss: 0.021547360345721245
epoch 20: dev_f1=0.9288742345737163, f1=0.924953095684803, best_f1=0.9275229357798166
