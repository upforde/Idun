cuda
Device: cuda
step: 0, loss: 0.565779983997345
step: 10, loss: 0.2741701602935791
step: 20, loss: 0.48654282093048096
step: 30, loss: 0.16745643317699432
step: 40, loss: 0.6104758977890015
step: 50, loss: 0.24137581884860992
step: 60, loss: 0.3137648105621338
step: 70, loss: 0.23704424500465393
step: 80, loss: 0.17720350623130798
step: 90, loss: 0.18788589537143707
step: 100, loss: 0.21782256662845612
step: 110, loss: 0.1307474672794342
step: 120, loss: 0.29054999351501465
step: 130, loss: 0.2627663016319275
step: 140, loss: 0.20005950331687927
step: 150, loss: 0.35619479417800903
step: 160, loss: 0.147035613656044
step: 170, loss: 0.12875929474830627
step: 180, loss: 0.0982782319188118
step: 190, loss: 0.17218422889709473
step: 200, loss: 0.2034856379032135
step: 210, loss: 0.14476464688777924
step: 220, loss: 0.18686485290527344
step: 230, loss: 0.24243883788585663
step: 240, loss: 0.1932401955127716
step: 250, loss: 0.19908463954925537
step: 260, loss: 0.2037992775440216
step: 270, loss: 0.12529043853282928
step: 280, loss: 0.11785934865474701
step: 290, loss: 0.12691256403923035
step: 300, loss: 0.24259960651397705
step: 310, loss: 0.10161413252353668
step: 320, loss: 0.06095476076006889
step: 330, loss: 0.11623721569776535
step: 340, loss: 0.04899739846587181
step: 350, loss: 0.13625480234622955
step: 360, loss: 0.16816936433315277
step: 370, loss: 0.10122474282979965
step: 380, loss: 0.30923447012901306
step: 390, loss: 0.19412581622600555
step: 400, loss: 0.04785273224115372
step: 410, loss: 0.13165290653705597
step: 420, loss: 0.2272091954946518
step: 430, loss: 0.06273073703050613
step: 440, loss: 0.1923108696937561
step: 450, loss: 0.2114209532737732
step: 460, loss: 0.1601172685623169
step: 470, loss: 0.07890841364860535
step: 480, loss: 0.34409037232398987
step: 490, loss: 0.11700595915317535
step: 500, loss: 0.06315156072378159
step: 510, loss: 0.09359898418188095
step: 520, loss: 0.2055729329586029
step: 530, loss: 0.04577863588929176
step: 540, loss: 0.28589779138565063
step: 550, loss: 0.12840785086154938
step: 560, loss: 0.0692722424864769
step: 570, loss: 0.24344371259212494
step: 580, loss: 0.13201875984668732
step: 590, loss: 0.08700791001319885
step: 600, loss: 0.0846845731139183
step: 610, loss: 0.15389269590377808
step: 620, loss: 0.09880946576595306
step: 630, loss: 0.17755064368247986
step: 640, loss: 0.13908231258392334
step: 650, loss: 0.16012214124202728
step: 660, loss: 0.06554192304611206
step: 670, loss: 0.16848976910114288
step: 680, loss: 0.11336405575275421
step: 690, loss: 0.17195646464824677
step: 700, loss: 0.12831388413906097
step: 710, loss: 0.15191364288330078
step: 720, loss: 0.18815277516841888
step: 730, loss: 0.2421485185623169
step: 740, loss: 0.1187518909573555
step: 750, loss: 0.1824711263179779
step: 760, loss: 0.11815103143453598
step: 770, loss: 0.332795649766922
step: 780, loss: 0.10700169950723648
step: 790, loss: 0.0889296755194664
step: 800, loss: 0.041414741426706314
step: 810, loss: 0.119049571454525
step: 820, loss: 0.16953516006469727
step: 830, loss: 0.15884600579738617
step: 840, loss: 0.06087854504585266
step: 850, loss: 0.11140575259923935
step: 860, loss: 0.05858497694134712
step: 870, loss: 0.21470890939235687
step: 880, loss: 0.16556759178638458
step: 890, loss: 0.3829104006290436
step: 900, loss: 0.13642865419387817
step: 910, loss: 0.15602609515190125
step: 920, loss: 0.3065004050731659
step: 930, loss: 0.09245803207159042
step: 940, loss: 0.08347390592098236
step: 950, loss: 0.10761460661888123
step: 960, loss: 0.27010053396224976
step: 970, loss: 0.040521807968616486
epoch 1: dev_f1=0.8920993227990971, f1=0.8870106761565836, best_f1=0.8870106761565836
step: 0, loss: 0.13785696029663086
step: 10, loss: 0.09129799902439117
step: 20, loss: 0.14906762540340424
step: 30, loss: 0.09260577708482742
step: 40, loss: 0.07241271436214447
step: 50, loss: 0.0686834380030632
step: 60, loss: 0.10876353830099106
step: 70, loss: 0.15504132211208344
step: 80, loss: 0.14245383441448212
step: 90, loss: 0.07805312424898148
step: 100, loss: 0.11426235735416412
step: 110, loss: 0.11847835779190063
step: 120, loss: 0.09469360113143921
step: 130, loss: 0.22293467819690704
step: 140, loss: 0.11080119758844376
step: 150, loss: 0.15560436248779297
step: 160, loss: 0.09419656544923782
step: 170, loss: 0.11015235632658005
step: 180, loss: 0.07700332999229431
step: 190, loss: 0.09494110196828842
step: 200, loss: 0.20760658383369446
step: 210, loss: 0.08823318779468536
step: 220, loss: 0.05389148369431496
step: 230, loss: 0.12933789193630219
step: 240, loss: 0.06801043450832367
step: 250, loss: 0.12485788017511368
step: 260, loss: 0.10247914493083954
step: 270, loss: 0.08711790293455124
step: 280, loss: 0.22145478427410126
step: 290, loss: 0.16235871613025665
step: 300, loss: 0.04028015583753586
step: 310, loss: 0.151234969496727
step: 320, loss: 0.12849073112010956
step: 330, loss: 0.2573775351047516
step: 340, loss: 0.10234721750020981
step: 350, loss: 0.11754069477319717
step: 360, loss: 0.2653180956840515
step: 370, loss: 0.07493142783641815
step: 380, loss: 0.14385920763015747
step: 390, loss: 0.09013606607913971
step: 400, loss: 0.1535210758447647
step: 410, loss: 0.18668150901794434
step: 420, loss: 0.1582176685333252
step: 430, loss: 0.06420418620109558
step: 440, loss: 0.09133671969175339
step: 450, loss: 0.23524227738380432
step: 460, loss: 0.11525172740221024
step: 470, loss: 0.07289230078458786
step: 480, loss: 0.019994521513581276
step: 490, loss: 0.1776810884475708
step: 500, loss: 0.11486299335956573
step: 510, loss: 0.18941909074783325
step: 520, loss: 0.12496404349803925
step: 530, loss: 0.029932111501693726
step: 540, loss: 0.053850241005420685
step: 550, loss: 0.08472232520580292
step: 560, loss: 0.07300311326980591
step: 570, loss: 0.36526647210121155
step: 580, loss: 0.21396556496620178
step: 590, loss: 0.2937394380569458
step: 600, loss: 0.24835099279880524
step: 610, loss: 0.05704750493168831
step: 620, loss: 0.15017877519130707
step: 630, loss: 0.006027905270457268
step: 640, loss: 0.16158588230609894
step: 650, loss: 0.11091189831495285
step: 660, loss: 0.10452410578727722
step: 670, loss: 0.21276023983955383
step: 680, loss: 0.022618144750595093
step: 690, loss: 0.11643798649311066
step: 700, loss: 0.06911601126194
step: 710, loss: 0.08462090790271759
step: 720, loss: 0.2344055324792862
step: 730, loss: 0.08164037764072418
step: 740, loss: 0.1281442791223526
step: 750, loss: 0.13093239068984985
step: 760, loss: 0.051292210817337036
step: 770, loss: 0.09810707718133926
step: 780, loss: 0.070350781083107
step: 790, loss: 0.06275609135627747
step: 800, loss: 0.10586067289113998
step: 810, loss: 0.19428233802318573
step: 820, loss: 0.1532953679561615
step: 830, loss: 0.09027876704931259
step: 840, loss: 0.13507722318172455
step: 850, loss: 0.1193731352686882
step: 860, loss: 0.16185960173606873
step: 870, loss: 0.09767905622720718
step: 880, loss: 0.143496572971344
step: 890, loss: 0.07226154953241348
step: 900, loss: 0.03637214004993439
step: 910, loss: 0.2050386369228363
step: 920, loss: 0.1157538965344429
step: 930, loss: 0.27648597955703735
step: 940, loss: 0.2116008847951889
step: 950, loss: 0.10459311306476593
step: 960, loss: 0.13599459826946259
step: 970, loss: 0.031916458159685135
epoch 2: dev_f1=0.9179104477611941, f1=0.9215777262180975, best_f1=0.9215777262180975
step: 0, loss: 0.2160334438085556
step: 10, loss: 0.13401232659816742
step: 20, loss: 0.09990794211626053
step: 30, loss: 0.1160200834274292
step: 40, loss: 0.1344124674797058
step: 50, loss: 0.20677617192268372
step: 60, loss: 0.03946494311094284
step: 70, loss: 0.07281024754047394
step: 80, loss: 0.059406980872154236
step: 90, loss: 0.1231909766793251
step: 100, loss: 0.09808553755283356
step: 110, loss: 0.041726984083652496
step: 120, loss: 0.1202801913022995
step: 130, loss: 0.13512824475765228
step: 140, loss: 0.14403052628040314
step: 150, loss: 0.037669338285923004
step: 160, loss: 0.10877390950918198
step: 170, loss: 0.1407863199710846
step: 180, loss: 0.23667150735855103
step: 190, loss: 0.039836153388023376
step: 200, loss: 0.05439085513353348
step: 210, loss: 0.04991314932703972
step: 220, loss: 0.09534268081188202
step: 230, loss: 0.05208835378289223
step: 240, loss: 0.17334114015102386
step: 250, loss: 0.036093857139348984
step: 260, loss: 0.07213150709867477
step: 270, loss: 0.13637375831604004
step: 280, loss: 0.07382112741470337
step: 290, loss: 0.145930215716362
step: 300, loss: 0.12980417907238007
step: 310, loss: 0.1263333112001419
step: 320, loss: 0.06415633857250214
step: 330, loss: 0.06944235414266586
step: 340, loss: 0.08771833032369614
step: 350, loss: 0.1396605521440506
step: 360, loss: 0.08287329226732254
step: 370, loss: 0.04517913982272148
step: 380, loss: 0.17688068747520447
step: 390, loss: 0.03262798488140106
step: 400, loss: 0.16937853395938873
step: 410, loss: 0.17583811283111572
step: 420, loss: 0.15393376350402832
step: 430, loss: 0.07921189814805984
step: 440, loss: 0.06337179988622665
step: 450, loss: 0.07189761102199554
step: 460, loss: 0.06348857283592224
step: 470, loss: 0.10818023234605789
step: 480, loss: 0.09234479814767838
step: 490, loss: 0.08392656594514847
step: 500, loss: 0.09670792520046234
step: 510, loss: 0.15244057774543762
step: 520, loss: 0.08996567130088806
step: 530, loss: 0.12980057299137115
step: 540, loss: 0.16506341099739075
step: 550, loss: 0.06917131692171097
step: 560, loss: 0.09408529847860336
step: 570, loss: 0.04272967576980591
step: 580, loss: 0.0394434928894043
step: 590, loss: 0.10595827549695969
step: 600, loss: 0.1372673213481903
step: 610, loss: 0.12767431139945984
step: 620, loss: 0.17220661044120789
step: 630, loss: 0.06947159022092819
step: 640, loss: 0.09155861288309097
step: 650, loss: 0.10800142586231232
step: 660, loss: 0.06365131586790085
step: 670, loss: 0.06630133092403412
step: 680, loss: 0.14774994552135468
step: 690, loss: 0.05386072397232056
step: 700, loss: 0.060091111809015274
step: 710, loss: 0.055520717054605484
step: 720, loss: 0.07902747392654419
step: 730, loss: 0.12367656826972961
step: 740, loss: 0.026651989668607712
step: 750, loss: 0.05619363486766815
step: 760, loss: 0.12560957670211792
step: 770, loss: 0.059996314346790314
step: 780, loss: 0.07993381470441818
step: 790, loss: 0.15663138031959534
step: 800, loss: 0.06437898427248001
step: 810, loss: 0.09799958765506744
step: 820, loss: 0.2778225541114807
step: 830, loss: 0.11324062198400497
step: 840, loss: 0.1412045806646347
step: 850, loss: 0.12168147414922714
step: 860, loss: 0.12278059870004654
step: 870, loss: 0.1509413868188858
step: 880, loss: 0.06544334441423416
step: 890, loss: 0.07866152375936508
step: 900, loss: 0.018609654158353806
step: 910, loss: 0.1461767703294754
step: 920, loss: 0.28897324204444885
step: 930, loss: 0.16616980731487274
step: 940, loss: 0.04052628576755524
step: 950, loss: 0.0963362529873848
step: 960, loss: 0.09369923174381256
step: 970, loss: 0.10901748389005661
epoch 3: dev_f1=0.9329660238751147, f1=0.9314442413162706, best_f1=0.9314442413162706
step: 0, loss: 0.1872374415397644
step: 10, loss: 0.21198856830596924
step: 20, loss: 0.11764124035835266
step: 30, loss: 0.042957793921232224
step: 40, loss: 0.04780750349164009
step: 50, loss: 0.18590949475765228
step: 60, loss: 0.0655701607465744
step: 70, loss: 0.08889885991811752
step: 80, loss: 0.11687355488538742
step: 90, loss: 0.09668630361557007
step: 100, loss: 0.15463145077228546
step: 110, loss: 0.18227633833885193
step: 120, loss: 0.15731269121170044
step: 130, loss: 0.09650903940200806
step: 140, loss: 0.13280436396598816
step: 150, loss: 0.14105871319770813
step: 160, loss: 0.19071254134178162
step: 170, loss: 0.14896440505981445
step: 180, loss: 0.0230206698179245
step: 190, loss: 0.04259467497467995
step: 200, loss: 0.2086857557296753
step: 210, loss: 0.04023423790931702
step: 220, loss: 0.04696532338857651
step: 230, loss: 0.03660466521978378
step: 240, loss: 0.18121954798698425
step: 250, loss: 0.11625202745199203
step: 260, loss: 0.08693739026784897
step: 270, loss: 0.031512778252363205
step: 280, loss: 0.06231943517923355
step: 290, loss: 0.07061842828989029
step: 300, loss: 0.1421240270137787
step: 310, loss: 0.1332114040851593
step: 320, loss: 0.10136620700359344
step: 330, loss: 0.1327379196882248
step: 340, loss: 0.1875918209552765
step: 350, loss: 0.27310416102409363
step: 360, loss: 0.11016660183668137
step: 370, loss: 0.19305293262004852
step: 380, loss: 0.09261595457792282
step: 390, loss: 0.117869533598423
step: 400, loss: 0.1303953230381012
step: 410, loss: 0.13143284618854523
step: 420, loss: 0.13110117614269257
step: 430, loss: 0.05755098909139633
step: 440, loss: 0.14137518405914307
step: 450, loss: 0.009413203224539757
step: 460, loss: 0.08672621846199036
step: 470, loss: 0.1650502234697342
step: 480, loss: 0.14802435040473938
step: 490, loss: 0.1265614926815033
step: 500, loss: 0.15519240498542786
step: 510, loss: 0.06863472610712051
step: 520, loss: 0.052298255264759064
step: 530, loss: 0.10749564319849014
step: 540, loss: 0.02075125277042389
step: 550, loss: 0.021228797733783722
step: 560, loss: 0.061083462089300156
step: 570, loss: 0.33570700883865356
step: 580, loss: 0.044062744826078415
step: 590, loss: 0.08059240132570267
step: 600, loss: 0.08013516664505005
step: 610, loss: 0.03978801146149635
step: 620, loss: 0.0830211266875267
step: 630, loss: 0.09923939406871796
step: 640, loss: 0.10072729736566544
step: 650, loss: 0.13143549859523773
step: 660, loss: 0.13315172493457794
step: 670, loss: 0.10090424120426178
step: 680, loss: 0.17631487548351288
step: 690, loss: 0.042324405163526535
step: 700, loss: 0.11214342713356018
step: 710, loss: 0.04287216439843178
step: 720, loss: 0.1389172375202179
step: 730, loss: 0.08424512296915054
step: 740, loss: 0.10898813605308533
step: 750, loss: 0.12600676715373993
step: 760, loss: 0.13106535375118256
step: 770, loss: 0.16623865067958832
step: 780, loss: 0.05379658564925194
step: 790, loss: 0.06094946339726448
step: 800, loss: 0.09012167155742645
step: 810, loss: 0.13381505012512207
step: 820, loss: 0.11249485611915588
step: 830, loss: 0.19360944628715515
step: 840, loss: 0.2758390009403229
step: 850, loss: 0.16239887475967407
step: 860, loss: 0.20610199868679047
step: 870, loss: 0.09170913696289062
step: 880, loss: 0.08170311152935028
step: 890, loss: 0.06773298978805542
step: 900, loss: 0.031826503574848175
step: 910, loss: 0.10508628934621811
step: 920, loss: 0.07159209996461868
step: 930, loss: 0.15722694993019104
step: 940, loss: 0.04955551028251648
step: 950, loss: 0.17465616762638092
step: 960, loss: 0.1954953372478485
step: 970, loss: 0.15809817612171173
epoch 4: dev_f1=0.9346314325452018, f1=0.9320297951582867, best_f1=0.9320297951582867
step: 0, loss: 0.11981212347745895
step: 10, loss: 0.08997639268636703
step: 20, loss: 0.07293511927127838
step: 30, loss: 0.010395343415439129
step: 40, loss: 0.030651219189167023
step: 50, loss: 0.07459614425897598
step: 60, loss: 0.11682192236185074
step: 70, loss: 0.1441723257303238
step: 80, loss: 0.014781069941818714
step: 90, loss: 0.10991315543651581
step: 100, loss: 0.14137111604213715
step: 110, loss: 0.09264601767063141
step: 120, loss: 0.0766133964061737
step: 130, loss: 0.04265334829688072
step: 140, loss: 0.04256715625524521
step: 150, loss: 0.0667819082736969
step: 160, loss: 0.15365009009838104
step: 170, loss: 0.1319950819015503
step: 180, loss: 0.08072538673877716
step: 190, loss: 0.10078312456607819
step: 200, loss: 0.032657720148563385
step: 210, loss: 0.06374023109674454
step: 220, loss: 0.03448369354009628
step: 230, loss: 0.1410972774028778
step: 240, loss: 0.12268190085887909
step: 250, loss: 0.03789593279361725
step: 260, loss: 0.09781315177679062
step: 270, loss: 0.056546296924352646
step: 280, loss: 0.046527065336704254
step: 290, loss: 0.13665488362312317
step: 300, loss: 0.08579200506210327
step: 310, loss: 0.07538663595914841
step: 320, loss: 0.15054863691329956
step: 330, loss: 0.18303588032722473
step: 340, loss: 0.040482115000486374
step: 350, loss: 0.08488480001688004
step: 360, loss: 0.03917654603719711
step: 370, loss: 0.14075052738189697
step: 380, loss: 0.17081625759601593
step: 390, loss: 0.10101210325956345
step: 400, loss: 0.07813268154859543
step: 410, loss: 0.02583746798336506
step: 420, loss: 0.09026271849870682
step: 430, loss: 0.0816144347190857
step: 440, loss: 0.10693778842687607
step: 450, loss: 0.10392124950885773
step: 460, loss: 0.12057947367429733
step: 470, loss: 0.28322434425354004
step: 480, loss: 0.20590730011463165
step: 490, loss: 0.16869686543941498
step: 500, loss: 0.15202690660953522
step: 510, loss: 0.07369429618120193
step: 520, loss: 0.032176632434129715
step: 530, loss: 0.12870356440544128
step: 540, loss: 0.0960104912519455
step: 550, loss: 0.047895558178424835
step: 560, loss: 0.08925957977771759
step: 570, loss: 0.14702743291854858
step: 580, loss: 0.09604855626821518
step: 590, loss: 0.02777969092130661
step: 600, loss: 0.07518214732408524
step: 610, loss: 0.09028744697570801
step: 620, loss: 0.17460313439369202
step: 630, loss: 0.10282624512910843
step: 640, loss: 0.10658160597085953
step: 650, loss: 0.0021544729825109243
step: 660, loss: 0.058852095156908035
step: 670, loss: 0.22017063200473785
step: 680, loss: 0.056730005890131
step: 690, loss: 0.22867248952388763
step: 700, loss: 0.07859985530376434
step: 710, loss: 0.04576168954372406
step: 720, loss: 0.08861187845468521
step: 730, loss: 0.010616449639201164
step: 740, loss: 0.05482693389058113
step: 750, loss: 0.05121864378452301
step: 760, loss: 0.10417988896369934
step: 770, loss: 0.07305985689163208
step: 780, loss: 0.09911166876554489
step: 790, loss: 0.20783162117004395
step: 800, loss: 0.07026050984859467
step: 810, loss: 0.06499045342206955
step: 820, loss: 0.25909796357154846
step: 830, loss: 0.04180467128753662
step: 840, loss: 0.13097074627876282
step: 850, loss: 0.17891761660575867
step: 860, loss: 0.03244255483150482
step: 870, loss: 0.12101799249649048
step: 880, loss: 0.16937783360481262
step: 890, loss: 0.12974311411380768
step: 900, loss: 0.09115500748157501
step: 910, loss: 0.09191443771123886
step: 920, loss: 0.08602048456668854
step: 930, loss: 0.13037243485450745
step: 940, loss: 0.12290247529745102
step: 950, loss: 0.07538776844739914
step: 960, loss: 0.2765447199344635
step: 970, loss: 0.09410085529088974
epoch 5: dev_f1=0.9284712482468443, f1=0.9239332096474954, best_f1=0.9320297951582867
step: 0, loss: 0.23358145356178284
step: 10, loss: 0.18616171181201935
step: 20, loss: 0.14622724056243896
step: 30, loss: 0.042228758335113525
step: 40, loss: 0.14067606627941132
step: 50, loss: 0.02154095098376274
step: 60, loss: 0.07845406979322433
step: 70, loss: 0.03884798288345337
step: 80, loss: 0.12774090468883514
step: 90, loss: 0.20041191577911377
step: 100, loss: 0.13766099512577057
step: 110, loss: 0.1656496673822403
step: 120, loss: 0.1327456384897232
step: 130, loss: 0.16565826535224915
step: 140, loss: 0.13298830389976501
step: 150, loss: 0.03508707880973816
step: 160, loss: 0.16446629166603088
step: 170, loss: 0.10338620841503143
step: 180, loss: 0.05856660380959511
step: 190, loss: 0.06638967990875244
step: 200, loss: 0.10765175521373749
step: 210, loss: 0.048760026693344116
step: 220, loss: 0.0717681273818016
step: 230, loss: 0.09988809376955032
step: 240, loss: 0.05105419456958771
step: 250, loss: 0.013270535506308079
step: 260, loss: 0.05773390084505081
step: 270, loss: 0.09711725264787674
step: 280, loss: 0.08374051749706268
step: 290, loss: 0.15164054930210114
step: 300, loss: 0.06562822312116623
step: 310, loss: 0.21170996129512787
step: 320, loss: 0.09845966100692749
step: 330, loss: 0.03367024287581444
step: 340, loss: 0.13229738175868988
step: 350, loss: 0.1163240522146225
step: 360, loss: 0.12297132611274719
step: 370, loss: 0.11691571027040482
step: 380, loss: 0.10844358056783676
step: 390, loss: 0.07920720428228378
step: 400, loss: 0.08551637828350067
step: 410, loss: 0.10725890100002289
step: 420, loss: 0.03267524763941765
step: 430, loss: 0.10881230980157852
step: 440, loss: 0.1439010053873062
step: 450, loss: 0.00760439271107316
step: 460, loss: 0.22364109754562378
step: 470, loss: 0.20656751096248627
step: 480, loss: 0.0736636146903038
step: 490, loss: 0.06460357457399368
step: 500, loss: 0.08919672667980194
step: 510, loss: 0.12229549884796143
step: 520, loss: 0.09883740544319153
step: 530, loss: 0.07475978136062622
step: 540, loss: 0.038317203521728516
step: 550, loss: 0.07087907940149307
step: 560, loss: 0.1800038367509842
step: 570, loss: 0.2429463267326355
step: 580, loss: 0.11577575653791428
step: 590, loss: 0.022059237584471703
step: 600, loss: 0.025396551936864853
step: 610, loss: 0.05322431027889252
step: 620, loss: 0.03727451339364052
step: 630, loss: 0.1194678246974945
step: 640, loss: 0.1024254709482193
step: 650, loss: 0.32457005977630615
step: 660, loss: 0.09257512539625168
step: 670, loss: 0.09726127982139587
step: 680, loss: 0.07945603877305984
step: 690, loss: 0.070372574031353
step: 700, loss: 0.059784743934869766
step: 710, loss: 0.08616700023412704
step: 720, loss: 0.11650732904672623
step: 730, loss: 0.06876635551452637
step: 740, loss: 0.17998766899108887
step: 750, loss: 0.05075819417834282
step: 760, loss: 0.10873784124851227
step: 770, loss: 0.3011620044708252
step: 780, loss: 0.14641320705413818
step: 790, loss: 0.11912171542644501
step: 800, loss: 0.13391946256160736
step: 810, loss: 0.07948312163352966
step: 820, loss: 0.06335224211215973
step: 830, loss: 0.08635962009429932
step: 840, loss: 0.1517629623413086
step: 850, loss: 0.09692994505167007
step: 860, loss: 0.05709197372198105
step: 870, loss: 0.12016583234071732
step: 880, loss: 0.13808035850524902
step: 890, loss: 0.03193991631269455
step: 900, loss: 0.10425393283367157
step: 910, loss: 0.13138651847839355
step: 920, loss: 0.10112839192152023
step: 930, loss: 0.07499749958515167
step: 940, loss: 0.04791555926203728
step: 950, loss: 0.09508267790079117
step: 960, loss: 0.07332462817430496
step: 970, loss: 0.12578366696834564
epoch 6: dev_f1=0.9330254041570438, f1=0.9348127600554785, best_f1=0.9320297951582867
step: 0, loss: 0.09397467970848083
step: 10, loss: 0.16825690865516663
step: 20, loss: 0.08510586619377136
step: 30, loss: 0.0987885445356369
step: 40, loss: 0.0754028931260109
step: 50, loss: 0.03113899752497673
step: 60, loss: 0.12295655906200409
step: 70, loss: 0.23000600934028625
step: 80, loss: 0.07093984633684158
step: 90, loss: 0.0852128118276596
step: 100, loss: 0.11322453618049622
step: 110, loss: 0.2730834484100342
step: 120, loss: 0.14631283283233643
step: 130, loss: 0.05727089196443558
step: 140, loss: 0.0630687028169632
step: 150, loss: 0.017696218565106392
step: 160, loss: 0.06416182219982147
step: 170, loss: 0.11557324975728989
step: 180, loss: 0.08979282528162003
step: 190, loss: 0.1021331250667572
step: 200, loss: 0.07982674241065979
step: 210, loss: 0.061179324984550476
step: 220, loss: 0.07935584336519241
step: 230, loss: 0.07444687187671661
step: 240, loss: 0.11903659999370575
step: 250, loss: 0.1516668200492859
step: 260, loss: 0.04017193242907524
step: 270, loss: 0.1249600499868393
step: 280, loss: 0.08458799868822098
step: 290, loss: 0.117604561150074
step: 300, loss: 0.10923955589532852
step: 310, loss: 0.050478000193834305
step: 320, loss: 0.04652968421578407
step: 330, loss: 0.03943340480327606
step: 340, loss: 0.1370489001274109
step: 350, loss: 0.10770630836486816
step: 360, loss: 0.09261178970336914
step: 370, loss: 0.23426416516304016
step: 380, loss: 0.09834342449903488
step: 390, loss: 0.05932208523154259
step: 400, loss: 0.08879423886537552
step: 410, loss: 0.19535201787948608
step: 420, loss: 0.11902686953544617
step: 430, loss: 0.07449399679899216
step: 440, loss: 0.11108966171741486
step: 450, loss: 0.19466634094715118
step: 460, loss: 0.03643956035375595
step: 470, loss: 0.11388028413057327
step: 480, loss: 0.0672914981842041
step: 490, loss: 0.03186940401792526
step: 500, loss: 0.018906855955719948
step: 510, loss: 0.009493120014667511
step: 520, loss: 0.06523792445659637
step: 530, loss: 0.14211435616016388
step: 540, loss: 0.052227821201086044
step: 550, loss: 0.02945072203874588
step: 560, loss: 0.03266613557934761
step: 570, loss: 0.04509851709008217
step: 580, loss: 0.045364461839199066
step: 590, loss: 0.18419721722602844
step: 600, loss: 0.13876496255397797
step: 610, loss: 0.07413837313652039
step: 620, loss: 0.05091483145952225
step: 630, loss: 0.11653225868940353
step: 640, loss: 0.07145056873559952
step: 650, loss: 0.061713945120573044
step: 660, loss: 0.08685418963432312
step: 670, loss: 0.09484491497278214
step: 680, loss: 0.029386484995484352
step: 690, loss: 0.04136176034808159
step: 700, loss: 0.08153748512268066
step: 710, loss: 0.20936453342437744
step: 720, loss: 0.050953254103660583
step: 730, loss: 0.039717137813568115
step: 740, loss: 0.05285711586475372
step: 750, loss: 0.27365842461586
step: 760, loss: 0.07939144223928452
step: 770, loss: 0.1722314953804016
step: 780, loss: 0.08148679882287979
step: 790, loss: 0.10201520472764969
step: 800, loss: 0.033882733434438705
step: 810, loss: 0.047000519931316376
step: 820, loss: 0.15746717154979706
step: 830, loss: 0.06508622318506241
step: 840, loss: 0.08855153620243073
step: 850, loss: 0.1803918331861496
step: 860, loss: 0.2207784652709961
step: 870, loss: 0.09161919355392456
step: 880, loss: 0.06023642420768738
step: 890, loss: 0.011057461611926556
step: 900, loss: 0.10450457781553268
step: 910, loss: 0.05506691709160805
step: 920, loss: 0.12269634753465652
step: 930, loss: 0.07587938010692596
step: 940, loss: 0.17968875169754028
step: 950, loss: 0.0984097272157669
step: 960, loss: 0.16925179958343506
step: 970, loss: 0.06461763381958008
epoch 7: dev_f1=0.9346826126954921, f1=0.926672777268561, best_f1=0.926672777268561
step: 0, loss: 0.11827057600021362
step: 10, loss: 0.1227198913693428
step: 20, loss: 0.10241488367319107
step: 30, loss: 0.1313149482011795
step: 40, loss: 0.07461446523666382
step: 50, loss: 0.16775788366794586
step: 60, loss: 0.06296831369400024
step: 70, loss: 0.012890965677797794
step: 80, loss: 0.10947463661432266
step: 90, loss: 0.11739230155944824
step: 100, loss: 0.07729972898960114
step: 110, loss: 0.011819683015346527
step: 120, loss: 0.10656792670488358
step: 130, loss: 0.1136927455663681
step: 140, loss: 0.1655588299036026
step: 150, loss: 0.054400719702243805
step: 160, loss: 0.07430937886238098
step: 170, loss: 0.01385329756885767
step: 180, loss: 0.0982227623462677
step: 190, loss: 0.16460426151752472
step: 200, loss: 0.08957720547914505
step: 210, loss: 0.06258788704872131
step: 220, loss: 0.06212567910552025
step: 230, loss: 0.06999880075454712
step: 240, loss: 0.10383889824151993
step: 250, loss: 0.15242823958396912
step: 260, loss: 0.09154248982667923
step: 270, loss: 0.055662550032138824
step: 280, loss: 0.09637850522994995
step: 290, loss: 0.028219200670719147
step: 300, loss: 0.09038253128528595
step: 310, loss: 0.11275861412286758
step: 320, loss: 0.06548553705215454
step: 330, loss: 0.08191164582967758
step: 340, loss: 0.08378681540489197
step: 350, loss: 0.1573430299758911
step: 360, loss: 0.06361417472362518
step: 370, loss: 0.08362168073654175
step: 380, loss: 0.06313663721084595
step: 390, loss: 0.03286977857351303
step: 400, loss: 0.09270790219306946
step: 410, loss: 0.11124126613140106
step: 420, loss: 0.09224780648946762
step: 430, loss: 0.07697626203298569
step: 440, loss: 0.08312618732452393
step: 450, loss: 0.04830972105264664
step: 460, loss: 0.041979335248470306
step: 470, loss: 0.2640199661254883
step: 480, loss: 0.055575381964445114
step: 490, loss: 0.057171404361724854
step: 500, loss: 0.08665548264980316
step: 510, loss: 0.03356990963220596
step: 520, loss: 0.10104751586914062
step: 530, loss: 0.13314040005207062
step: 540, loss: 0.10319360345602036
step: 550, loss: 0.07530534267425537
step: 560, loss: 0.1261344850063324
step: 570, loss: 0.3283396363258362
step: 580, loss: 0.12651558220386505
step: 590, loss: 0.05659002065658569
step: 600, loss: 0.032113395631313324
step: 610, loss: 0.083099365234375
step: 620, loss: 0.026727894321084023
step: 630, loss: 0.08048585057258606
step: 640, loss: 0.21757926046848297
step: 650, loss: 0.07542606443166733
step: 660, loss: 0.10699724406003952
step: 670, loss: 0.12873400747776031
step: 680, loss: 0.03423704206943512
step: 690, loss: 0.16858887672424316
step: 700, loss: 0.13637013733386993
step: 710, loss: 0.09624147415161133
step: 720, loss: 0.10991980135440826
step: 730, loss: 0.08171064406633377
step: 740, loss: 0.21456512808799744
step: 750, loss: 0.09095741808414459
step: 760, loss: 0.2298474907875061
step: 770, loss: 0.10222901403903961
step: 780, loss: 0.15035566687583923
step: 790, loss: 0.11723512411117554
step: 800, loss: 0.12053264677524567
step: 810, loss: 0.045392099767923355
step: 820, loss: 0.06791355460882187
step: 830, loss: 0.13358290493488312
step: 840, loss: 0.10670964419841766
step: 850, loss: 0.06884535402059555
step: 860, loss: 0.06128746271133423
step: 870, loss: 0.16115520894527435
step: 880, loss: 0.1819571852684021
step: 890, loss: 0.16457471251487732
step: 900, loss: 0.06845444440841675
step: 910, loss: 0.09153016656637192
step: 920, loss: 0.07718616724014282
step: 930, loss: 0.08456253260374069
step: 940, loss: 0.257160484790802
step: 950, loss: 0.15736229717731476
step: 960, loss: 0.15663278102874756
step: 970, loss: 0.04117029905319214
epoch 8: dev_f1=0.9380281690140844, f1=0.9321478708469817, best_f1=0.9321478708469817
step: 0, loss: 0.07768475264310837
step: 10, loss: 0.09269464761018753
step: 20, loss: 0.08402236551046371
step: 30, loss: 0.05415445566177368
step: 40, loss: 0.2073529064655304
step: 50, loss: 0.09467760473489761
step: 60, loss: 0.060018353164196014
step: 70, loss: 0.04648425057530403
step: 80, loss: 0.06577064096927643
step: 90, loss: 0.062413401901721954
step: 100, loss: 0.1523684710264206
step: 110, loss: 0.07489294558763504
step: 120, loss: 0.1489306539297104
step: 130, loss: 0.08210486173629761
step: 140, loss: 0.06638534367084503
step: 150, loss: 0.07615844160318375
step: 160, loss: 0.029043758288025856
step: 170, loss: 0.08169857412576675
step: 180, loss: 0.05189806967973709
step: 190, loss: 0.018177663907408714
step: 200, loss: 0.0882769301533699
step: 210, loss: 0.10651490092277527
step: 220, loss: 0.05074441432952881
step: 230, loss: 0.06485053151845932
step: 240, loss: 0.16563858091831207
step: 250, loss: 0.09039948135614395
step: 260, loss: 0.08360719680786133
step: 270, loss: 0.12245383113622665
step: 280, loss: 0.14658750593662262
step: 290, loss: 0.03726853057742119
step: 300, loss: 0.0846041738986969
step: 310, loss: 0.025836577638983727
step: 320, loss: 0.03757845610380173
step: 330, loss: 0.17078496515750885
step: 340, loss: 0.07424142211675644
step: 350, loss: 0.1586870551109314
step: 360, loss: 0.10384446382522583
step: 370, loss: 0.13664942979812622
step: 380, loss: 0.1544700413942337
step: 390, loss: 0.09070339053869247
step: 400, loss: 0.023317119106650352
step: 410, loss: 0.10953696072101593
step: 420, loss: 0.053995098918676376
step: 430, loss: 0.1902281939983368
step: 440, loss: 0.1319398730993271
step: 450, loss: 0.09436327964067459
step: 460, loss: 0.1414676159620285
step: 470, loss: 0.12923789024353027
step: 480, loss: 0.13786642253398895
step: 490, loss: 0.10811370611190796
step: 500, loss: 0.07312685251235962
step: 510, loss: 0.1549818515777588
step: 520, loss: 0.15146182477474213
step: 530, loss: 0.1748698651790619
step: 540, loss: 0.0023843925446271896
step: 550, loss: 0.11641975492238998
step: 560, loss: 0.04046621546149254
step: 570, loss: 0.07509180158376694
step: 580, loss: 0.2122945785522461
step: 590, loss: 0.09711911529302597
step: 600, loss: 0.10402519255876541
step: 610, loss: 0.13009154796600342
step: 620, loss: 0.012236460112035275
step: 630, loss: 0.11338497698307037
step: 640, loss: 0.0506407804787159
step: 650, loss: 0.07139482349157333
step: 660, loss: 0.08892818540334702
step: 670, loss: 0.07291632890701294
step: 680, loss: 0.021860478445887566
step: 690, loss: 0.054474830627441406
step: 700, loss: 0.10753370076417923
step: 710, loss: 0.071407251060009
step: 720, loss: 0.03531291335821152
step: 730, loss: 0.079012431204319
step: 740, loss: 0.04013008624315262
step: 750, loss: 0.3328336179256439
step: 760, loss: 0.11088066548109055
step: 770, loss: 0.13830801844596863
step: 780, loss: 0.07264784723520279
step: 790, loss: 0.08975998312234879
step: 800, loss: 0.052530739456415176
step: 810, loss: 0.10215967893600464
step: 820, loss: 0.11450746655464172
step: 830, loss: 0.02275209315121174
step: 840, loss: 0.08860255777835846
step: 850, loss: 0.09152854233980179
step: 860, loss: 0.09130091220140457
step: 870, loss: 0.0836867019534111
step: 880, loss: 0.20842790603637695
step: 890, loss: 0.08308461308479309
step: 900, loss: 0.06607974320650101
step: 910, loss: 0.12590165436267853
step: 920, loss: 0.08422762155532837
step: 930, loss: 0.05807909369468689
step: 940, loss: 0.06262937933206558
step: 950, loss: 0.09789347648620605
step: 960, loss: 0.16437318921089172
step: 970, loss: 0.0031215574126690626
epoch 9: dev_f1=0.9295380307979467, f1=0.9272388059701492, best_f1=0.9321478708469817
step: 0, loss: 0.1242961511015892
step: 10, loss: 0.06001604348421097
step: 20, loss: 0.1892079859972
step: 30, loss: 0.05968141555786133
step: 40, loss: 0.15160883963108063
step: 50, loss: 0.025144832208752632
step: 60, loss: 0.05951788276433945
step: 70, loss: 0.024025168269872665
step: 80, loss: 0.06086470186710358
step: 90, loss: 0.04308447241783142
step: 100, loss: 0.07495029270648956
step: 110, loss: 0.015995018184185028
step: 120, loss: 0.02206696942448616
step: 130, loss: 0.07758349925279617
step: 140, loss: 0.03598819300532341
step: 150, loss: 0.09131763875484467
step: 160, loss: 0.08533181250095367
step: 170, loss: 0.00328270997852087
step: 180, loss: 0.022152522578835487
step: 190, loss: 0.07016544044017792
step: 200, loss: 0.03566335514187813
step: 210, loss: 0.06544733792543411
step: 220, loss: 0.005747402086853981
step: 230, loss: 0.16378170251846313
step: 240, loss: 0.17084920406341553
step: 250, loss: 0.08248840272426605
step: 260, loss: 0.04406001791357994
step: 270, loss: 0.04204634949564934
step: 280, loss: 0.23763547837734222
step: 290, loss: 0.07966077327728271
step: 300, loss: 0.15598110854625702
step: 310, loss: 0.08778738975524902
step: 320, loss: 0.07278884202241898
step: 330, loss: 0.037285834550857544
step: 340, loss: 0.04857635498046875
step: 350, loss: 0.09396322071552277
step: 360, loss: 0.09480439871549606
step: 370, loss: 0.07201188802719116
step: 380, loss: 0.030575979501008987
step: 390, loss: 0.055595580488443375
step: 400, loss: 0.09418308734893799
step: 410, loss: 0.05491989105939865
step: 420, loss: 0.029395490884780884
step: 430, loss: 0.12512516975402832
step: 440, loss: 0.04700099304318428
step: 450, loss: 0.022607337683439255
step: 460, loss: 0.11389957368373871
step: 470, loss: 0.08056521415710449
step: 480, loss: 0.10386054217815399
step: 490, loss: 0.011399440467357635
step: 500, loss: 0.09561897069215775
step: 510, loss: 0.19233636558055878
step: 520, loss: 0.08152996748685837
step: 530, loss: 0.05075845867395401
step: 540, loss: 0.05054746940732002
step: 550, loss: 0.13133902847766876
step: 560, loss: 0.007441610563546419
step: 570, loss: 0.0351707860827446
step: 580, loss: 0.055477071553468704
step: 590, loss: 0.044358447194099426
step: 600, loss: 0.1315205693244934
step: 610, loss: 0.09307236969470978
step: 620, loss: 0.035325974225997925
step: 630, loss: 0.07180508971214294
step: 640, loss: 0.02045256830751896
step: 650, loss: 0.07335454225540161
step: 660, loss: 0.06931710243225098
step: 670, loss: 0.12524302303791046
step: 680, loss: 0.11899956315755844
step: 690, loss: 0.07877624779939651
step: 700, loss: 0.033881865441799164
step: 710, loss: 0.07261578738689423
step: 720, loss: 0.06572801619768143
step: 730, loss: 0.1434818059206009
step: 740, loss: 0.18630795180797577
step: 750, loss: 0.039321236312389374
step: 760, loss: 0.06605534255504608
step: 770, loss: 0.18217670917510986
step: 780, loss: 0.10235079377889633
step: 790, loss: 0.02990327589213848
step: 800, loss: 0.06625167280435562
step: 810, loss: 0.07802965492010117
step: 820, loss: 0.11683976650238037
step: 830, loss: 0.13494974374771118
step: 840, loss: 0.17059065401554108
step: 850, loss: 0.0809803307056427
step: 860, loss: 0.08876142650842667
step: 870, loss: 0.11516005545854568
step: 880, loss: 0.028851646929979324
step: 890, loss: 0.009936376474797726
step: 900, loss: 0.028247622773051262
step: 910, loss: 0.04277706891298294
step: 920, loss: 0.05238284915685654
step: 930, loss: 0.029882337898015976
step: 940, loss: 0.0627637580037117
step: 950, loss: 0.06150102615356445
step: 960, loss: 0.10640296339988708
step: 970, loss: 0.0954330563545227
epoch 10: dev_f1=0.932825154835636, f1=0.9245372567631704, best_f1=0.9321478708469817
step: 0, loss: 0.07631661742925644
step: 10, loss: 0.06827642023563385
step: 20, loss: 0.08510757982730865
step: 30, loss: 0.08291230350732803
step: 40, loss: 0.09162507951259613
step: 50, loss: 0.03352566435933113
step: 60, loss: 0.11843020468950272
step: 70, loss: 0.062037572264671326
step: 80, loss: 0.08167016506195068
step: 90, loss: 0.06085247918963432
step: 100, loss: 0.08334790170192719
step: 110, loss: 0.011879975907504559
step: 120, loss: 0.12372367084026337
step: 130, loss: 0.11224578320980072
step: 140, loss: 0.051449984312057495
step: 150, loss: 0.03692130744457245
step: 160, loss: 0.0030589585658162832
step: 170, loss: 0.006117367185652256
step: 180, loss: 2.8906008083140478e-05
step: 190, loss: 0.1386765092611313
step: 200, loss: 0.11577766388654709
step: 210, loss: 0.07272088527679443
step: 220, loss: 0.05466528981924057
step: 230, loss: 0.08871915936470032
step: 240, loss: 0.08808532357215881
step: 250, loss: 0.12607206404209137
step: 260, loss: 0.10753180831670761
step: 270, loss: 0.046482570469379425
step: 280, loss: 0.030547097325325012
step: 290, loss: 0.08102194219827652
step: 300, loss: 0.05438076704740524
step: 310, loss: 0.05229226499795914
step: 320, loss: 0.06997515261173248
step: 330, loss: 0.11925534904003143
step: 340, loss: 0.07282375544309616
step: 350, loss: 0.0813058614730835
step: 360, loss: 0.03161732107400894
step: 370, loss: 0.01824892684817314
step: 380, loss: 0.016031157225370407
step: 390, loss: 0.010710026137530804
step: 400, loss: 0.0960480198264122
step: 410, loss: 0.1319836527109146
step: 420, loss: 0.11636350303888321
step: 430, loss: 0.06083732843399048
step: 440, loss: 0.08667750656604767
step: 450, loss: 0.09295885264873505
step: 460, loss: 0.07539335638284683
step: 470, loss: 0.0440145879983902
step: 480, loss: 0.08941313624382019
step: 490, loss: 0.13443246483802795
step: 500, loss: 0.04000798240303993
step: 510, loss: 0.05023347958922386
step: 520, loss: 0.05784090980887413
step: 530, loss: 0.07230118662118912
step: 540, loss: 0.035623881965875626
step: 550, loss: 0.11729263514280319
step: 560, loss: 0.037608712911605835
step: 570, loss: 0.06554990261793137
step: 580, loss: 0.019326122477650642
step: 590, loss: 0.09681935608386993
step: 600, loss: 0.09973315894603729
step: 610, loss: 0.07005757838487625
step: 620, loss: 0.02587973326444626
step: 630, loss: 0.08738425374031067
step: 640, loss: 0.00720477569848299
step: 650, loss: 0.02962564304471016
step: 660, loss: 0.2147998958826065
step: 670, loss: 0.06195327639579773
step: 680, loss: 0.06931329518556595
step: 690, loss: 0.20316915214061737
step: 700, loss: 0.05071771889925003
step: 710, loss: 0.050894711166620255
step: 720, loss: 0.02073126658797264
step: 730, loss: 0.07559726387262344
step: 740, loss: 0.05714114010334015
step: 750, loss: 0.16228175163269043
step: 760, loss: 0.1832561194896698
step: 770, loss: 0.012421850115060806
step: 780, loss: 0.03161840885877609
step: 790, loss: 0.013598278164863586
step: 800, loss: 0.17998984456062317
step: 810, loss: 0.173045814037323
step: 820, loss: 0.17183437943458557
step: 830, loss: 0.06053836643695831
step: 840, loss: 0.055516667664051056
step: 850, loss: 0.10201878100633621
step: 860, loss: 0.024699723348021507
step: 870, loss: 0.1197584941983223
step: 880, loss: 0.10284456610679626
step: 890, loss: 0.0362052321434021
step: 900, loss: 0.07061482965946198
step: 910, loss: 0.003988468553870916
step: 920, loss: 0.10076893866062164
step: 930, loss: 0.06012741103768349
step: 940, loss: 0.13911400735378265
step: 950, loss: 0.04391774907708168
step: 960, loss: 0.053682416677474976
step: 970, loss: 0.05986976623535156
epoch 11: dev_f1=0.9310661764705882, f1=0.9289667896678966, best_f1=0.9321478708469817
step: 0, loss: 0.06473185122013092
step: 10, loss: 0.07889758050441742
step: 20, loss: 0.06137046217918396
step: 30, loss: 0.0730043426156044
step: 40, loss: 0.16481173038482666
step: 50, loss: 0.05506566911935806
step: 60, loss: 0.06324885040521622
step: 70, loss: 0.09778375178575516
step: 80, loss: 0.013072283007204533
step: 90, loss: 0.13803249597549438
step: 100, loss: 0.06877417862415314
step: 110, loss: 0.1454392671585083
step: 120, loss: 0.03762197867035866
step: 130, loss: 0.04168838635087013
step: 140, loss: 0.023179972544312477
step: 150, loss: 0.10057029873132706
step: 160, loss: 0.0047029671259224415
step: 170, loss: 0.17603929340839386
step: 180, loss: 0.03018459677696228
step: 190, loss: 0.021826177835464478
step: 200, loss: 0.04144718870520592
step: 210, loss: 0.09406033158302307
step: 220, loss: 0.055501002818346024
step: 230, loss: 0.04072260484099388
step: 240, loss: 0.12632957100868225
step: 250, loss: 0.09963545948266983
step: 260, loss: 0.07883234322071075
step: 270, loss: 0.1853155493736267
step: 280, loss: 0.028011294081807137
step: 290, loss: 0.035392262041568756
step: 300, loss: 0.033409811556339264
step: 310, loss: 0.02291279286146164
step: 320, loss: 0.059739239513874054
step: 330, loss: 0.01494645792990923
step: 340, loss: 0.04953577741980553
step: 350, loss: 1.681938192632515e-05
step: 360, loss: 0.3579757511615753
step: 370, loss: 0.0660194605588913
step: 380, loss: 0.04434464871883392
step: 390, loss: 0.05627839267253876
step: 400, loss: 0.15646542608737946
step: 410, loss: 0.10449569672346115
step: 420, loss: 0.0015321526443585753
step: 430, loss: 0.06067950651049614
step: 440, loss: 0.009504142217338085
step: 450, loss: 0.0487159825861454
step: 460, loss: 0.08702964335680008
step: 470, loss: 0.031506042927503586
step: 480, loss: 0.06839708983898163
step: 490, loss: 0.040491294115781784
step: 500, loss: 0.04316040500998497
step: 510, loss: 0.02862038090825081
step: 520, loss: 0.04029092937707901
step: 530, loss: 0.03534231334924698
step: 540, loss: 0.06944618374109268
step: 550, loss: 0.020381148904561996
step: 560, loss: 0.0948307067155838
step: 570, loss: 0.014379498548805714
step: 580, loss: 0.11209005862474442
step: 590, loss: 0.09868326783180237
step: 600, loss: 0.024396831169724464
step: 610, loss: 0.045956891030073166
step: 620, loss: 0.07788936048746109
step: 630, loss: 0.07271835952997208
step: 640, loss: 0.03885132819414139
step: 650, loss: 0.10436548292636871
step: 660, loss: 0.03294431418180466
step: 670, loss: 0.041844822466373444
step: 680, loss: 0.11108098924160004
step: 690, loss: 0.05821320414543152
step: 700, loss: 0.1336808055639267
step: 710, loss: 0.03642457723617554
step: 720, loss: 0.07560789585113525
step: 730, loss: 0.04436050355434418
step: 740, loss: 0.019492698833346367
step: 750, loss: 0.020830590277910233
step: 760, loss: 0.07226798683404922
step: 770, loss: 0.009853461757302284
step: 780, loss: 0.06560888886451721
step: 790, loss: 0.09456662088632584
step: 800, loss: 0.06851218640804291
step: 810, loss: 0.08555785566568375
step: 820, loss: 0.027372151613235474
step: 830, loss: 0.10357796400785446
step: 840, loss: 0.09852325916290283
step: 850, loss: 0.03349374979734421
step: 860, loss: 0.022572264075279236
step: 870, loss: 0.08744582533836365
step: 880, loss: 0.12456487119197845
step: 890, loss: 0.12230762094259262
step: 900, loss: 0.06714406609535217
step: 910, loss: 0.0659889504313469
step: 920, loss: 0.14213015139102936
step: 930, loss: 0.09406669437885284
step: 940, loss: 0.2157643735408783
step: 950, loss: 0.12319276481866837
step: 960, loss: 0.07728371024131775
step: 970, loss: 0.0751211866736412
epoch 12: dev_f1=0.9297094657919399, f1=0.923943661971831, best_f1=0.9321478708469817
step: 0, loss: 0.11721361428499222
step: 10, loss: 0.05208447575569153
step: 20, loss: 0.052008286118507385
step: 30, loss: 0.05113532394170761
step: 40, loss: 0.027161192148923874
step: 50, loss: 0.1668374389410019
step: 60, loss: 0.09028589725494385
step: 70, loss: 0.08988311886787415
step: 80, loss: 0.08792677521705627
step: 90, loss: 0.13167375326156616
step: 100, loss: 0.02821650356054306
step: 110, loss: 0.09411828964948654
step: 120, loss: 0.09384553879499435
step: 130, loss: 0.07779265195131302
step: 140, loss: 0.030369466170668602
step: 150, loss: 0.09668959677219391
step: 160, loss: 0.10554404556751251
step: 170, loss: 0.061252038925886154
step: 180, loss: 0.1034194752573967
step: 190, loss: 0.04842599481344223
step: 200, loss: 0.22714054584503174
step: 210, loss: 0.017030594870448112
step: 220, loss: 0.020035961642861366
step: 230, loss: 0.08895109593868256
step: 240, loss: 0.004942570813000202
step: 250, loss: 0.0900883749127388
step: 260, loss: 0.11289586126804352
step: 270, loss: 0.11243356764316559
step: 280, loss: 0.09650260210037231
step: 290, loss: 0.0663854107260704
step: 300, loss: 0.02942592278122902
step: 310, loss: 0.06348692625761032
step: 320, loss: 0.07653802633285522
step: 330, loss: 0.21508969366550446
step: 340, loss: 0.032694436609745026
step: 350, loss: 0.036818698048591614
step: 360, loss: 0.09447191655635834
step: 370, loss: 0.0660887137055397
step: 380, loss: 0.06872482597827911
step: 390, loss: 0.15407441556453705
step: 400, loss: 0.08480408042669296
step: 410, loss: 0.024846438318490982
step: 420, loss: 0.05864609032869339
step: 430, loss: 0.10045334696769714
step: 440, loss: 0.09057793021202087
step: 450, loss: 2.501420931366738e-05
step: 460, loss: 0.08801001310348511
step: 470, loss: 0.04090462625026703
step: 480, loss: 0.0030707167461514473
step: 490, loss: 0.05361979454755783
step: 500, loss: 0.15734565258026123
step: 510, loss: 0.04098980873823166
step: 520, loss: 0.018931277096271515
step: 530, loss: 0.0163031704723835
step: 540, loss: 0.03559158369898796
step: 550, loss: 0.11015509068965912
step: 560, loss: 0.05983276292681694
step: 570, loss: 0.12497183680534363
step: 580, loss: 0.014342873357236385
step: 590, loss: 0.061194583773612976
step: 600, loss: 0.04002460837364197
step: 610, loss: 0.030004460364580154
step: 620, loss: 0.08771248906850815
step: 630, loss: 0.06295926868915558
step: 640, loss: 0.05421067029237747
step: 650, loss: 0.13752734661102295
step: 660, loss: 0.12654976546764374
step: 670, loss: 0.1363237351179123
step: 680, loss: 0.01964639499783516
step: 690, loss: 0.08432637155056
step: 700, loss: 0.03945044428110123
step: 710, loss: 0.055479951202869415
step: 720, loss: 0.06791897118091583
step: 730, loss: 0.07439225167036057
step: 740, loss: 0.05380675196647644
step: 750, loss: 0.08214610069990158
step: 760, loss: 0.028651755303144455
step: 770, loss: 0.059672821313142776
step: 780, loss: 0.012431003153324127
step: 790, loss: 0.012404615059494972
step: 800, loss: 0.03337499126791954
step: 810, loss: 0.07728343456983566
step: 820, loss: 0.1396937370300293
step: 830, loss: 0.02141776867210865
step: 840, loss: 0.07714759558439255
step: 850, loss: 0.03949351981282234
step: 860, loss: 0.048945650458335876
step: 870, loss: 0.034633368253707886
step: 880, loss: 0.013654173351824284
step: 890, loss: 0.031208809465169907
step: 900, loss: 0.02162809483706951
step: 910, loss: 0.053877100348472595
step: 920, loss: 0.09152396768331528
step: 930, loss: 0.08855855464935303
step: 940, loss: 0.0473552942276001
step: 950, loss: 0.04909896105527878
step: 960, loss: 0.15452048182487488
step: 970, loss: 0.013608441688120365
epoch 13: dev_f1=0.9268518518518517, f1=0.9262180974477957, best_f1=0.9321478708469817
step: 0, loss: 0.1407282054424286
step: 10, loss: 0.07314340770244598
step: 20, loss: 0.06290065497159958
step: 30, loss: 0.05084315687417984
step: 40, loss: 0.0844830572605133
step: 50, loss: 1.2650968528760131e-05
step: 60, loss: 0.09251030534505844
step: 70, loss: 0.05054239556193352
step: 80, loss: 0.07991501688957214
step: 90, loss: 0.022960234433412552
step: 100, loss: 0.1493070423603058
step: 110, loss: 0.023145372048020363
step: 120, loss: 0.09699127823114395
step: 130, loss: 0.03212432563304901
step: 140, loss: 0.08326846361160278
step: 150, loss: 0.09008774906396866
step: 160, loss: 0.03231330215930939
step: 170, loss: 0.056856364011764526
step: 180, loss: 0.04537913575768471
step: 190, loss: 0.03710811585187912
step: 200, loss: 0.024066658690571785
step: 210, loss: 0.009641464799642563
step: 220, loss: 0.06452766060829163
step: 230, loss: 0.03290573135018349
step: 240, loss: 0.027044953778386116
step: 250, loss: 0.060311950743198395
step: 260, loss: 0.019220812246203423
step: 270, loss: 0.07894270122051239
step: 280, loss: 0.031779780983924866
step: 290, loss: 0.02377297729253769
step: 300, loss: 0.06495416164398193
step: 310, loss: 0.12115778028964996
step: 320, loss: 0.030035803094506264
step: 330, loss: 0.11866327375173569
step: 340, loss: 0.04051366448402405
step: 350, loss: 0.07895645499229431
step: 360, loss: 0.03557788208127022
step: 370, loss: 0.1502642035484314
step: 380, loss: 0.07089600712060928
step: 390, loss: 0.029457343742251396
step: 400, loss: 0.06760282069444656
step: 410, loss: 0.0014280491741374135
step: 420, loss: 0.015802696347236633
step: 430, loss: 0.026172645390033722
step: 440, loss: 0.030802946537733078
step: 450, loss: 0.11987867206335068
step: 460, loss: 0.15093417465686798
step: 470, loss: 0.0006960831815376878
step: 480, loss: 0.04043208062648773
step: 490, loss: 0.0798264667391777
step: 500, loss: 0.07987282425165176
step: 510, loss: 0.04246087744832039
step: 520, loss: 0.055969513952732086
step: 530, loss: 0.0789811760187149
step: 540, loss: 0.04094541817903519
step: 550, loss: 0.04561220854520798
step: 560, loss: 0.06929115951061249
step: 570, loss: 0.10871458798646927
step: 580, loss: 0.07241275161504745
step: 590, loss: 0.02767764963209629
step: 600, loss: 0.06812078505754471
step: 610, loss: 0.11088313907384872
step: 620, loss: 0.11239674687385559
step: 630, loss: 0.038871970027685165
step: 640, loss: 0.06447361409664154
step: 650, loss: 0.030947670340538025
step: 660, loss: 0.0535992830991745
step: 670, loss: 0.06867881119251251
step: 680, loss: 0.028063703328371048
step: 690, loss: 0.06485079973936081
step: 700, loss: 0.028005896136164665
step: 710, loss: 0.10031548887491226
step: 720, loss: 0.08531851321458817
step: 730, loss: 0.05618791654706001
step: 740, loss: 0.036066196858882904
step: 750, loss: 0.09052664041519165
step: 760, loss: 0.023280272260308266
step: 770, loss: 0.00040293586789630353
step: 780, loss: 0.06845957040786743
step: 790, loss: 0.012662742286920547
step: 800, loss: 0.10946965217590332
step: 810, loss: 0.1538224220275879
step: 820, loss: 0.01340002566576004
step: 830, loss: 0.06231759116053581
step: 840, loss: 0.07916900515556335
step: 850, loss: 0.04822416231036186
step: 860, loss: 0.06974852085113525
step: 870, loss: 0.08273034542798996
step: 880, loss: 0.0031951258424669504
step: 890, loss: 0.07908522337675095
step: 900, loss: 0.03499932959675789
step: 910, loss: 0.20778661966323853
step: 920, loss: 0.14889948070049286
step: 930, loss: 0.037828538566827774
step: 940, loss: 0.04711649566888809
step: 950, loss: 0.05540691316127777
step: 960, loss: 0.05279473960399628
step: 970, loss: 0.07876221835613251
epoch 14: dev_f1=0.9367205542725173, f1=0.92814093648586, best_f1=0.9321478708469817
step: 0, loss: 0.018313424661755562
step: 10, loss: 0.03789568319916725
step: 20, loss: 0.05028637871146202
step: 30, loss: 0.03500699624419212
step: 40, loss: 0.03588477149605751
step: 50, loss: 0.031621869653463364
step: 60, loss: 0.08860290050506592
step: 70, loss: 0.11347782611846924
step: 80, loss: 0.011538481339812279
step: 90, loss: 0.051196109503507614
step: 100, loss: 0.059848614037036896
step: 110, loss: 0.05864715203642845
step: 120, loss: 0.04937684163451195
step: 130, loss: 0.020572345703840256
step: 140, loss: 0.0015817531384527683
step: 150, loss: 0.020746340975165367
step: 160, loss: 0.0004978852230124176
step: 170, loss: 0.011195006780326366
step: 180, loss: 0.018478697165846825
step: 190, loss: 0.11092554032802582
step: 200, loss: 0.09249948710203171
step: 210, loss: 0.018339863047003746
step: 220, loss: 0.0438745953142643
step: 230, loss: 1.2550394785648677e-05
step: 240, loss: 0.029055040329694748
step: 250, loss: 0.00115278922021389
step: 260, loss: 0.10963703691959381
step: 270, loss: 0.0431499220430851
step: 280, loss: 0.12009322643280029
step: 290, loss: 0.046357717365026474
step: 300, loss: 0.06316639482975006
step: 310, loss: 0.17323727905750275
step: 320, loss: 0.07183689624071121
step: 330, loss: 0.09138084948062897
step: 340, loss: 0.0414728969335556
step: 350, loss: 0.00017888344882521778
step: 360, loss: 0.0329112783074379
step: 370, loss: 0.16393937170505524
step: 380, loss: 0.07717297226190567
step: 390, loss: 0.03643491864204407
step: 400, loss: 0.07143145054578781
step: 410, loss: 0.04626162350177765
step: 420, loss: 0.006036541890352964
step: 430, loss: 0.014675535261631012
step: 440, loss: 0.05247257649898529
step: 450, loss: 0.08838975429534912
step: 460, loss: 0.010087658651173115
step: 470, loss: 0.014480534009635448
step: 480, loss: 0.1470482349395752
step: 490, loss: 0.09095124900341034
step: 500, loss: 0.06576094031333923
step: 510, loss: 0.08847866952419281
step: 520, loss: 0.055611591786146164
step: 530, loss: 5.474912541103549e-05
step: 540, loss: 0.0011070657055824995
step: 550, loss: 0.020805692300200462
step: 560, loss: 0.0706792026758194
step: 570, loss: 0.09800280630588531
step: 580, loss: 0.064700648188591
step: 590, loss: 0.07329124957323074
step: 600, loss: 0.053215302526950836
step: 610, loss: 0.04711546748876572
step: 620, loss: 0.08074460923671722
step: 630, loss: 0.03200197592377663
step: 640, loss: 0.053257472813129425
step: 650, loss: 0.08459173142910004
step: 660, loss: 0.03722933679819107
step: 670, loss: 0.043693557381629944
step: 680, loss: 0.13697442412376404
step: 690, loss: 0.0720498114824295
step: 700, loss: 0.05562778189778328
step: 710, loss: 0.03927173465490341
step: 720, loss: 0.10102716833353043
step: 730, loss: 0.00788633432239294
step: 740, loss: 0.0832178145647049
step: 750, loss: 0.1025334894657135
step: 760, loss: 0.05090726912021637
step: 770, loss: 0.060014501214027405
step: 780, loss: 0.06904769688844681
step: 790, loss: 0.0734403058886528
step: 800, loss: 0.06768713146448135
step: 810, loss: 0.04662409797310829
step: 820, loss: 0.1000460684299469
step: 830, loss: 0.07794947922229767
step: 840, loss: 0.1552344560623169
step: 850, loss: 0.047942858189344406
step: 860, loss: 0.04934041574597359
step: 870, loss: 0.06044910475611687
step: 880, loss: 0.10816943645477295
step: 890, loss: 0.04758618772029877
step: 900, loss: 0.01940907910466194
step: 910, loss: 0.05627043917775154
step: 920, loss: 0.08133707195520401
step: 930, loss: 0.030962733551859856
step: 940, loss: 0.017756644636392593
step: 950, loss: 0.09320284426212311
step: 960, loss: 0.10642530024051666
step: 970, loss: 0.0380467027425766
epoch 15: dev_f1=0.9335180055401663, f1=0.9289012003693443, best_f1=0.9321478708469817
step: 0, loss: 0.028625186532735825
step: 10, loss: 0.09399586170911789
step: 20, loss: 0.04059869796037674
step: 30, loss: 0.06159447878599167
step: 40, loss: 0.05824673920869827
step: 50, loss: 0.04483991116285324
step: 60, loss: 0.028637224808335304
step: 70, loss: 0.12159179151058197
step: 80, loss: 0.016362519934773445
step: 90, loss: 0.10125871747732162
step: 100, loss: 0.01900222711265087
step: 110, loss: 0.07934684306383133
step: 120, loss: 0.0228397436439991
step: 130, loss: 0.09217947721481323
step: 140, loss: 0.01107663381844759
step: 150, loss: 3.6859139072475955e-05
step: 160, loss: 0.050611838698387146
step: 170, loss: 0.06797024607658386
step: 180, loss: 0.047870125621557236
step: 190, loss: 0.2337050884962082
step: 200, loss: 0.06582771986722946
step: 210, loss: 0.03319208696484566
step: 220, loss: 0.0003420368302613497
step: 230, loss: 0.0037038910668343306
step: 240, loss: 0.020632965490221977
step: 250, loss: 8.871293539414182e-05
step: 260, loss: 0.06769946217536926
step: 270, loss: 0.04041432961821556
step: 280, loss: 0.0739075168967247
step: 290, loss: 0.03399856016039848
step: 300, loss: 0.13284189999103546
step: 310, loss: 0.04414927214384079
step: 320, loss: 0.08397193998098373
step: 330, loss: 0.0648256242275238
step: 340, loss: 0.07111943513154984
step: 350, loss: 0.07536942511796951
step: 360, loss: 0.009160916320979595
step: 370, loss: 0.05805247277021408
step: 380, loss: 0.04400218650698662
step: 390, loss: 0.0281817726790905
step: 400, loss: 0.056650638580322266
step: 410, loss: 0.003449580864980817
step: 420, loss: 0.0009420454152859747
step: 430, loss: 0.05204605683684349
step: 440, loss: 0.09110725671052933
step: 450, loss: 0.07747537642717361
step: 460, loss: 0.05335488170385361
step: 470, loss: 0.0601641908288002
step: 480, loss: 0.06271647661924362
step: 490, loss: 0.031854916363954544
step: 500, loss: 0.07260258495807648
step: 510, loss: 0.0319814570248127
step: 520, loss: 0.06896097213029861
step: 530, loss: 0.03803202137351036
step: 540, loss: 0.06478005647659302
step: 550, loss: 0.0031066318042576313
step: 560, loss: 0.049522824585437775
step: 570, loss: 0.026335805654525757
step: 580, loss: 0.07857692241668701
step: 590, loss: 0.029352540150284767
step: 600, loss: 0.14936698973178864
step: 610, loss: 0.1438097059726715
step: 620, loss: 0.042482949793338776
step: 630, loss: 0.08468271791934967
step: 640, loss: 0.09893260896205902
step: 650, loss: 0.06495874375104904
step: 660, loss: 0.08214664459228516
step: 670, loss: 0.016553692519664764
step: 680, loss: 0.00015156040899455547
step: 690, loss: 0.18935514986515045
step: 700, loss: 0.03814813867211342
step: 710, loss: 0.03710012137889862
step: 720, loss: 0.10340778529644012
step: 730, loss: 0.0860779732465744
step: 740, loss: 0.07986284792423248
step: 750, loss: 0.2265062779188156
step: 760, loss: 0.07499533146619797
step: 770, loss: 0.0439431332051754
step: 780, loss: 0.05331381410360336
step: 790, loss: 0.11385282874107361
step: 800, loss: 0.018170038238167763
step: 810, loss: 0.1003153994679451
step: 820, loss: 0.05914539471268654
step: 830, loss: 0.0616949126124382
step: 840, loss: 0.017440177500247955
step: 850, loss: 0.03006107173860073
step: 860, loss: 0.02141711115837097
step: 870, loss: 0.13461989164352417
step: 880, loss: 0.05986872315406799
step: 890, loss: 0.025391967967152596
step: 900, loss: 0.041401609778404236
step: 910, loss: 0.02267947793006897
step: 920, loss: 0.07680440694093704
step: 930, loss: 0.14586417376995087
step: 940, loss: 0.060990285128355026
step: 950, loss: 0.022372577339410782
step: 960, loss: 0.10413502156734467
step: 970, loss: 0.028697440400719643
epoch 16: dev_f1=0.9317757009345794, f1=0.9274418604651162, best_f1=0.9321478708469817
step: 0, loss: 0.05117274820804596
step: 10, loss: 0.0872521921992302
step: 20, loss: 0.08143726736307144
step: 30, loss: 0.03993799909949303
step: 40, loss: 0.04361827298998833
step: 50, loss: 0.039974395185709
step: 60, loss: 0.024755965918302536
step: 70, loss: 0.03848233073949814
step: 80, loss: 0.041582416743040085
step: 90, loss: 0.07223933190107346
step: 100, loss: 0.027078142389655113
step: 110, loss: 0.11738588660955429
step: 120, loss: 0.009755116887390614
step: 130, loss: 0.024505702778697014
step: 140, loss: 0.12114285677671432
step: 150, loss: 0.03711520507931709
step: 160, loss: 0.02680102176964283
step: 170, loss: 0.07777975499629974
step: 180, loss: 0.04458862543106079
step: 190, loss: 0.016905833035707474
step: 200, loss: 0.10148989409208298
step: 210, loss: 0.04514473304152489
step: 220, loss: 0.10815407335758209
step: 230, loss: 0.05478493496775627
step: 240, loss: 0.02257799170911312
step: 250, loss: 0.07218709588050842
step: 260, loss: 0.01901431754231453
step: 270, loss: 0.03680986166000366
step: 280, loss: 0.043377168476581573
step: 290, loss: 0.0939989909529686
step: 300, loss: 0.10323089361190796
step: 310, loss: 0.04039755463600159
step: 320, loss: 0.03596896678209305
step: 330, loss: 0.1279827356338501
step: 340, loss: 0.0004204973520245403
step: 350, loss: 0.06206114962697029
step: 360, loss: 3.622700023697689e-05
step: 370, loss: 0.007742761168628931
step: 380, loss: 0.01981404423713684
step: 390, loss: 0.023629968985915184
step: 400, loss: 0.036828987300395966
step: 410, loss: 0.048216886818408966
step: 420, loss: 0.034428633749485016
step: 430, loss: 0.029370250180363655
step: 440, loss: 0.1046750545501709
step: 450, loss: 0.07726564258337021
step: 460, loss: 0.08309698849916458
step: 470, loss: 0.02206026017665863
step: 480, loss: 0.05721106007695198
step: 490, loss: 0.08366288989782333
step: 500, loss: 0.05015067756175995
step: 510, loss: 0.002792676445096731
step: 520, loss: 0.013624785467982292
step: 530, loss: 0.05573706328868866
step: 540, loss: 0.07698938250541687
step: 550, loss: 0.03219394385814667
step: 560, loss: 0.05964533984661102
step: 570, loss: 0.057072412222623825
step: 580, loss: 0.09946243464946747
step: 590, loss: 0.030395610257983208
step: 600, loss: 0.04689110442996025
step: 610, loss: 0.09460188448429108
step: 620, loss: 0.03443048149347305
step: 630, loss: 0.11428213119506836
step: 640, loss: 0.03848431631922722
step: 650, loss: 0.04231860116124153
step: 660, loss: 0.0855197161436081
step: 670, loss: 0.0026060892269015312
step: 680, loss: 0.053541429340839386
step: 690, loss: 0.026479318737983704
step: 700, loss: 0.07440498471260071
step: 710, loss: 0.01917663961648941
step: 720, loss: 0.011427068151533604
step: 730, loss: 0.025135595351457596
step: 740, loss: 0.05301803722977638
step: 750, loss: 0.11878827959299088
step: 760, loss: 0.0255318321287632
step: 770, loss: 0.024467267096042633
step: 780, loss: 0.04156946390867233
step: 790, loss: 0.0405738539993763
step: 800, loss: 0.014817038550972939
step: 810, loss: 0.05772315710783005
step: 820, loss: 0.07642664760351181
step: 830, loss: 0.10098700225353241
step: 840, loss: 0.0927870124578476
step: 850, loss: 0.036498308181762695
step: 860, loss: 0.06130077689886093
step: 870, loss: 0.1485956311225891
step: 880, loss: 0.04133687540888786
step: 890, loss: 0.0679735392332077
step: 900, loss: 0.035787470638751984
step: 910, loss: 0.15447567403316498
step: 920, loss: 0.06557148694992065
step: 930, loss: 0.010106701403856277
step: 940, loss: 6.519773160107434e-05
step: 950, loss: 0.13755196332931519
step: 960, loss: 0.10585296154022217
step: 970, loss: 0.07937337458133698
epoch 17: dev_f1=0.9312267657992565, f1=0.9262865090403337, best_f1=0.9321478708469817
step: 0, loss: 0.019495030865073204
step: 10, loss: 0.013510935008525848
step: 20, loss: 0.04162546619772911
step: 30, loss: 0.12198886275291443
step: 40, loss: 0.0425109788775444
step: 50, loss: 0.09440196305513382
step: 60, loss: 0.030263163149356842
step: 70, loss: 0.09230966120958328
step: 80, loss: 0.0669746994972229
step: 90, loss: 0.022205155342817307
step: 100, loss: 0.03184607997536659
step: 110, loss: 0.0010309841018170118
step: 120, loss: 8.229861850850284e-05
step: 130, loss: 0.05984883010387421
step: 140, loss: 0.03919459879398346
step: 150, loss: 0.06233254820108414
step: 160, loss: 0.00017669927910901606
step: 170, loss: 0.043596334755420685
step: 180, loss: 0.04899618774652481
step: 190, loss: 0.02490203268826008
step: 200, loss: 0.13653063774108887
step: 210, loss: 0.00030740504735149443
step: 220, loss: 0.06918854266405106
step: 230, loss: 0.0377187505364418
step: 240, loss: 0.004991088528186083
step: 250, loss: 0.028485232964158058
step: 260, loss: 0.023468462750315666
step: 270, loss: 0.06264577805995941
step: 280, loss: 0.03295315429568291
step: 290, loss: 0.03633024916052818
step: 300, loss: 0.020113855600357056
step: 310, loss: 0.03215309977531433
step: 320, loss: 0.0493755042552948
step: 330, loss: 0.08757828921079636
step: 340, loss: 0.023845015093684196
step: 350, loss: 0.03066428378224373
step: 360, loss: 0.050364941358566284
step: 370, loss: 0.06016926094889641
step: 380, loss: 0.025895165279507637
step: 390, loss: 0.024534063413739204
step: 400, loss: 0.05129766836762428
step: 410, loss: 0.06771040707826614
step: 420, loss: 0.05077729746699333
step: 430, loss: 0.022700579836964607
step: 440, loss: 0.04978400468826294
step: 450, loss: 0.05316159129142761
step: 460, loss: 0.05689150467514992
step: 470, loss: 0.06009813770651817
step: 480, loss: 0.07572028040885925
step: 490, loss: 0.062275808304548264
step: 500, loss: 0.0604243129491806
step: 510, loss: 0.08655429631471634
step: 520, loss: 0.2694174647331238
step: 530, loss: 0.08406024426221848
step: 540, loss: 0.03435167670249939
step: 550, loss: 0.023322757333517075
step: 560, loss: 0.047088123857975006
step: 570, loss: 0.04736597090959549
step: 580, loss: 0.017281077802181244
step: 590, loss: 0.03541732579469681
step: 600, loss: 0.12188056111335754
step: 610, loss: 0.04563777148723602
step: 620, loss: 0.12047618627548218
step: 630, loss: 0.05593632534146309
step: 640, loss: 0.000617547775618732
step: 650, loss: 0.12075626105070114
step: 660, loss: 0.11056879907846451
step: 670, loss: 3.310565807623789e-05
step: 680, loss: 0.05357237160205841
step: 690, loss: 0.03768870607018471
step: 700, loss: 0.03361273929476738
step: 710, loss: 0.05321032553911209
step: 720, loss: 0.05197688937187195
step: 730, loss: 0.0516376756131649
step: 740, loss: 0.035523004829883575
step: 750, loss: 0.07484974712133408
step: 760, loss: 0.09872625768184662
step: 770, loss: 0.10232580453157425
step: 780, loss: 0.030099719762802124
step: 790, loss: 8.343862282345071e-05
step: 800, loss: 0.04021304100751877
step: 810, loss: 0.08199828863143921
step: 820, loss: 0.020242206752300262
step: 830, loss: 0.02153537981212139
step: 840, loss: 0.03858327493071556
step: 850, loss: 0.01603023335337639
step: 860, loss: 0.04367688670754433
step: 870, loss: 0.044121503829956055
step: 880, loss: 0.036817971616983414
step: 890, loss: 0.026846347376704216
step: 900, loss: 0.05275552719831467
step: 910, loss: 0.019057415425777435
step: 920, loss: 0.03936108946800232
step: 930, loss: 0.0049423580057919025
step: 940, loss: 0.02717611752450466
step: 950, loss: 0.044377926737070084
step: 960, loss: 0.0687807947397232
step: 970, loss: 0.06777782738208771
epoch 18: dev_f1=0.929840972871843, f1=0.9259431765253843, best_f1=0.9321478708469817
step: 0, loss: 0.04707783833146095
step: 10, loss: 0.05796277895569801
step: 20, loss: 0.06256304681301117
step: 30, loss: 0.01968356780707836
step: 40, loss: 0.03467318043112755
step: 50, loss: 0.11901034414768219
step: 60, loss: 0.04419916495680809
step: 70, loss: 0.03616941720247269
step: 80, loss: 9.213056182488799e-05
step: 90, loss: 0.056498587131500244
step: 100, loss: 0.048299290239810944
step: 110, loss: 0.010257881134748459
step: 120, loss: 0.016608238220214844
step: 130, loss: 0.04349245876073837
step: 140, loss: 0.01564459316432476
step: 150, loss: 0.023868771269917488
step: 160, loss: 0.09069143235683441
step: 170, loss: 0.14054736495018005
step: 180, loss: 4.209365579299629e-05
step: 190, loss: 0.01816546358168125
step: 200, loss: 4.15950344176963e-05
step: 210, loss: 0.04666173830628395
step: 220, loss: 0.05179809033870697
step: 230, loss: 0.14076849818229675
step: 240, loss: 0.030098939314484596
step: 250, loss: 0.08942841738462448
step: 260, loss: 0.059981439262628555
step: 270, loss: 0.020322076976299286
step: 280, loss: 0.019892027601599693
step: 290, loss: 0.02502039074897766
step: 300, loss: 0.031229302287101746
step: 310, loss: 0.061851102858781815
step: 320, loss: 0.02096541039645672
step: 330, loss: 0.06495837867259979
step: 340, loss: 0.010280478745698929
step: 350, loss: 0.06867866218090057
step: 360, loss: 0.026279017329216003
step: 370, loss: 0.06500744819641113
step: 380, loss: 0.00010833353007910773
step: 390, loss: 0.10317092388868332
step: 400, loss: 0.07106077671051025
step: 410, loss: 0.06251341104507446
step: 420, loss: 0.15093301236629486
step: 430, loss: 0.027507832273840904
step: 440, loss: 0.03294643014669418
step: 450, loss: 0.04517365247011185
step: 460, loss: 0.05710076540708542
step: 470, loss: 0.03926818072795868
step: 480, loss: 0.07492517679929733
step: 490, loss: 0.10652374476194382
step: 500, loss: 0.05099725350737572
step: 510, loss: 0.05475340038537979
step: 520, loss: 0.07538947463035583
step: 530, loss: 0.026951787993311882
step: 540, loss: 0.0007331995293498039
step: 550, loss: 0.035922858864068985
step: 560, loss: 0.04675919562578201
step: 570, loss: 0.0602688305079937
step: 580, loss: 0.06888138502836227
step: 590, loss: 0.06302101910114288
step: 600, loss: 0.019201751798391342
step: 610, loss: 0.13232067227363586
step: 620, loss: 0.0966009646654129
step: 630, loss: 0.08830554783344269
step: 640, loss: 0.0358501635491848
step: 650, loss: 0.061474595218896866
step: 660, loss: 0.039985597133636475
step: 670, loss: 0.026343585923314095
step: 680, loss: 0.009224220179021358
step: 690, loss: 0.04767260327935219
step: 700, loss: 0.03742688521742821
step: 710, loss: 0.09361220896244049
step: 720, loss: 0.06402302533388138
step: 730, loss: 0.031020570546388626
step: 740, loss: 0.07006104290485382
step: 750, loss: 0.03780370205640793
step: 760, loss: 0.05595079064369202
step: 770, loss: 0.07193853706121445
step: 780, loss: 0.05749582499265671
step: 790, loss: 0.01835043728351593
step: 800, loss: 2.3768696337356232e-05
step: 810, loss: 0.02307361736893654
step: 820, loss: 0.09892714023590088
step: 830, loss: 0.02597140707075596
step: 840, loss: 0.02007768303155899
step: 850, loss: 0.09937580674886703
step: 860, loss: 0.03352808952331543
step: 870, loss: 0.024143870919942856
step: 880, loss: 0.00010600547102512792
step: 890, loss: 0.1422402262687683
step: 900, loss: 0.09755250066518784
step: 910, loss: 0.001556970295496285
step: 920, loss: 0.03851306065917015
step: 930, loss: 0.04768199473619461
step: 940, loss: 0.04250830411911011
step: 950, loss: 0.0008547366014681756
step: 960, loss: 0.1197601705789566
step: 970, loss: 0.07472049444913864
epoch 19: dev_f1=0.930276087973795, f1=0.9260299625468165, best_f1=0.9321478708469817
step: 0, loss: 0.012921156361699104
step: 10, loss: 0.023241598159074783
step: 20, loss: 0.09531298279762268
step: 30, loss: 0.0013801846653223038
step: 40, loss: 0.040522556751966476
step: 50, loss: 9.6513656899333e-05
step: 60, loss: 0.0028604392427951097
step: 70, loss: 0.03239249065518379
step: 80, loss: 0.0221746563911438
step: 90, loss: 0.02778542786836624
step: 100, loss: 0.052835024893283844
step: 110, loss: 3.5122789995511994e-05
step: 120, loss: 0.06946790218353271
step: 130, loss: 0.06734399497509003
step: 140, loss: 0.020541729405522346
step: 150, loss: 0.0698755607008934
step: 160, loss: 0.14662790298461914
step: 170, loss: 0.03232298418879509
step: 180, loss: 0.03208518400788307
step: 190, loss: 0.0004882458597421646
step: 200, loss: 0.10908954590559006
step: 210, loss: 0.044684037566185
step: 220, loss: 0.0439467690885067
step: 230, loss: 0.06616457551717758
step: 240, loss: 0.05028523877263069
step: 250, loss: 0.034157056361436844
step: 260, loss: 0.0716862827539444
step: 270, loss: 0.10500893741846085
step: 280, loss: 0.019068803638219833
step: 290, loss: 0.09156088531017303
step: 300, loss: 0.032015565782785416
step: 310, loss: 0.0105582345277071
step: 320, loss: 0.06276460736989975
step: 330, loss: 0.020734040066599846
step: 340, loss: 0.018779287114739418
step: 350, loss: 0.01930258795619011
step: 360, loss: 4.673402145272121e-05
step: 370, loss: 0.0771009549498558
step: 380, loss: 0.029336251318454742
step: 390, loss: 0.0005280444747768342
step: 400, loss: 0.035813480615615845
step: 410, loss: 0.03997063636779785
step: 420, loss: 0.05711044743657112
step: 430, loss: 0.024499785155057907
step: 440, loss: 0.05792037025094032
step: 450, loss: 0.03729649633169174
step: 460, loss: 0.11592169106006622
step: 470, loss: 0.0692986398935318
step: 480, loss: 0.04917527362704277
step: 490, loss: 0.09366051852703094
step: 500, loss: 0.015997078269720078
step: 510, loss: 0.02140374295413494
step: 520, loss: 0.007422204595059156
step: 530, loss: 0.07078186422586441
step: 540, loss: 0.026189956814050674
step: 550, loss: 0.07349427789449692
step: 560, loss: 0.06428173929452896
step: 570, loss: 0.017592832446098328
step: 580, loss: 0.06099510192871094
step: 590, loss: 0.03173993155360222
step: 600, loss: 0.0350913405418396
step: 610, loss: 0.03529535233974457
step: 620, loss: 0.026788845658302307
step: 630, loss: 0.048243988305330276
step: 640, loss: 0.030901342630386353
step: 650, loss: 0.17072463035583496
step: 660, loss: 0.10795487463474274
step: 670, loss: 0.041898421943187714
step: 680, loss: 0.04360143840312958
step: 690, loss: 0.060677316039800644
step: 700, loss: 0.01527925580739975
step: 710, loss: 0.02762731909751892
step: 720, loss: 0.07403126358985901
step: 730, loss: 0.05593132972717285
step: 740, loss: 0.03694190829992294
step: 750, loss: 0.03343517705798149
step: 760, loss: 0.0895824283361435
step: 770, loss: 0.21509191393852234
step: 780, loss: 0.03965545445680618
step: 790, loss: 0.05811256915330887
step: 800, loss: 0.06700918823480606
step: 810, loss: 0.08747706562280655
step: 820, loss: 0.05809234827756882
step: 830, loss: 0.13117405772209167
step: 840, loss: 0.04169202223420143
step: 850, loss: 0.05088323727250099
step: 860, loss: 0.11383340507745743
step: 870, loss: 0.01904870942234993
step: 880, loss: 0.029929712414741516
step: 890, loss: 0.04140821471810341
step: 900, loss: 0.05930325388908386
step: 910, loss: 0.02131451480090618
step: 920, loss: 0.05277658626437187
step: 930, loss: 0.020022166892886162
step: 940, loss: 0.034735098481178284
step: 950, loss: 0.020521624013781548
step: 960, loss: 0.033767227083444595
step: 970, loss: 0.028982434421777725
epoch 20: dev_f1=0.9272898961284232, f1=0.9251764705882354, best_f1=0.9321478708469817
