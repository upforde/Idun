cuda
Device: cuda
step: 0, loss: 0.682881772518158
step: 10, loss: 0.095888651907444
step: 20, loss: 0.42717018723487854
step: 30, loss: 0.24156031012535095
step: 40, loss: 0.23123446106910706
step: 50, loss: 0.26480352878570557
step: 60, loss: 0.4848646819591522
step: 70, loss: 0.6065780520439148
step: 80, loss: 0.26846441626548767
step: 90, loss: 0.21047016978263855
step: 100, loss: 0.09185758233070374
step: 110, loss: 0.06556280702352524
step: 120, loss: 0.3076523244380951
step: 130, loss: 0.20347940921783447
step: 140, loss: 0.3278840482234955
step: 150, loss: 0.2695692479610443
step: 160, loss: 0.1222720593214035
step: 170, loss: 0.23363418877124786
step: 180, loss: 0.3178924024105072
step: 190, loss: 0.3480927646160126
step: 200, loss: 0.14622707664966583
step: 210, loss: 0.26193591952323914
step: 220, loss: 0.2656159996986389
step: 230, loss: 0.21655894815921783
step: 240, loss: 0.25118809938430786
step: 250, loss: 0.2741934061050415
step: 260, loss: 0.18773125112056732
step: 270, loss: 0.10934022068977356
step: 280, loss: 0.24109667539596558
step: 290, loss: 0.17580674588680267
step: 300, loss: 0.25709375739097595
step: 310, loss: 0.158539280295372
step: 320, loss: 0.1965595781803131
step: 330, loss: 0.12907491624355316
step: 340, loss: 0.211442768573761
step: 350, loss: 0.12544260919094086
step: 360, loss: 0.19228285551071167
step: 370, loss: 0.21596986055374146
step: 380, loss: 0.1939515918493271
epoch 1: dev_f1=0.5569620253164558, f1=0.4746666666666667, best_f1=0.4746666666666667
step: 0, loss: 0.19572752714157104
step: 10, loss: 0.4685609042644501
step: 20, loss: 0.07789276540279388
step: 30, loss: 0.10465943813323975
step: 40, loss: 0.1257159560918808
step: 50, loss: 0.0545654259622097
step: 60, loss: 0.13727882504463196
step: 70, loss: 0.16639433801174164
step: 80, loss: 0.07795892655849457
step: 90, loss: 0.19080498814582825
step: 100, loss: 0.2654082179069519
step: 110, loss: 0.2778830826282501
step: 120, loss: 0.10788888484239578
step: 130, loss: 0.3489598333835602
step: 140, loss: 0.13723121583461761
step: 150, loss: 0.14051352441310883
step: 160, loss: 0.3518751263618469
step: 170, loss: 0.1193951964378357
step: 180, loss: 0.18374407291412354
step: 190, loss: 0.3062664866447449
step: 200, loss: 0.20749670267105103
step: 210, loss: 0.4346001148223877
step: 220, loss: 0.21104833483695984
step: 230, loss: 0.0643775463104248
step: 240, loss: 0.2479984015226364
step: 250, loss: 0.21159766614437103
step: 260, loss: 0.16756141185760498
step: 270, loss: 0.29689478874206543
step: 280, loss: 0.3230283856391907
step: 290, loss: 0.09356541186571121
step: 300, loss: 0.2449028044939041
step: 310, loss: 0.2762130796909332
step: 320, loss: 0.14197498559951782
step: 330, loss: 0.15276022255420685
step: 340, loss: 0.10000160336494446
step: 350, loss: 0.19685937464237213
step: 360, loss: 0.19882814586162567
step: 370, loss: 0.1618066281080246
step: 380, loss: 0.1999913454055786
epoch 2: dev_f1=0.6758241758241759, f1=0.5132743362831859, best_f1=0.5132743362831859
step: 0, loss: 0.06411001086235046
step: 10, loss: 0.10327619314193726
step: 20, loss: 0.06975441426038742
step: 30, loss: 0.09578502178192139
step: 40, loss: 0.23660361766815186
step: 50, loss: 0.027219537645578384
step: 60, loss: 0.03456790745258331
step: 70, loss: 0.030549580231308937
step: 80, loss: 0.12137233465909958
step: 90, loss: 0.03332798555493355
step: 100, loss: 0.04954257607460022
step: 110, loss: 0.13885197043418884
step: 120, loss: 0.058384161442518234
step: 130, loss: 0.20974889397621155
step: 140, loss: 0.04745658487081528
step: 150, loss: 0.05749344080686569
step: 160, loss: 0.2600836157798767
step: 170, loss: 0.22019949555397034
step: 180, loss: 0.03840417042374611
step: 190, loss: 0.13914506137371063
step: 200, loss: 0.19495320320129395
step: 210, loss: 0.08533608913421631
step: 220, loss: 0.04370269924402237
step: 230, loss: 0.1328304260969162
step: 240, loss: 0.10032127797603607
step: 250, loss: 0.2627832591533661
step: 260, loss: 0.11604032665491104
step: 270, loss: 0.012632365338504314
step: 280, loss: 0.1029067188501358
step: 290, loss: 0.051035962998867035
step: 300, loss: 0.14500847458839417
step: 310, loss: 0.07333166897296906
step: 320, loss: 0.023915134370326996
step: 330, loss: 0.1137576699256897
step: 340, loss: 0.08708764612674713
step: 350, loss: 0.21472996473312378
step: 360, loss: 0.13648565113544464
step: 370, loss: 0.1015937402844429
step: 380, loss: 0.08215335011482239
epoch 3: dev_f1=0.7321867321867322, f1=0.5378590078328982, best_f1=0.5378590078328982
step: 0, loss: 0.11922934651374817
step: 10, loss: 0.20645712316036224
step: 20, loss: 0.14511989057064056
step: 30, loss: 0.017508680000901222
step: 40, loss: 0.18236775696277618
step: 50, loss: 0.025126276537775993
step: 60, loss: 0.06692831218242645
step: 70, loss: 0.09659668058156967
step: 80, loss: 0.0761539414525032
step: 90, loss: 0.044922877103090286
step: 100, loss: 0.4490756690502167
step: 110, loss: 0.031386204063892365
step: 120, loss: 0.06557408720254898
step: 130, loss: 0.15181417763233185
step: 140, loss: 0.04577638953924179
step: 150, loss: 0.28181973099708557
step: 160, loss: 0.046076253056526184
step: 170, loss: 0.010219661518931389
step: 180, loss: 0.06781673431396484
step: 190, loss: 0.2000340074300766
step: 200, loss: 0.19039981067180634
step: 210, loss: 0.06603307276964188
step: 220, loss: 0.10377417504787445
step: 230, loss: 0.13852933049201965
step: 240, loss: 0.0633154809474945
step: 250, loss: 0.006533932406455278
step: 260, loss: 0.026812871918082237
step: 270, loss: 0.12645289301872253
step: 280, loss: 0.15152068436145782
step: 290, loss: 0.07984021306037903
step: 300, loss: 0.04463747888803482
step: 310, loss: 0.05925271660089493
step: 320, loss: 0.011543191969394684
step: 330, loss: 0.24117368459701538
step: 340, loss: 0.1277664750814438
step: 350, loss: 0.028544239699840546
step: 360, loss: 0.27802395820617676
step: 370, loss: 0.06749092042446136
step: 380, loss: 0.07644789665937424
epoch 4: dev_f1=0.7317073170731708, f1=0.5051546391752577, best_f1=0.5378590078328982
step: 0, loss: 0.07443574070930481
step: 10, loss: 0.009761510416865349
step: 20, loss: 0.1511908620595932
step: 30, loss: 0.08846648037433624
step: 40, loss: 0.014602863229811192
step: 50, loss: 0.09338685125112534
step: 60, loss: 0.03101181983947754
step: 70, loss: 0.008464977145195007
step: 80, loss: 0.0021118903532624245
step: 90, loss: 0.09386701881885529
step: 100, loss: 0.009583476930856705
step: 110, loss: 0.2418370097875595
step: 120, loss: 0.031339555978775024
step: 130, loss: 0.018399329856038094
step: 140, loss: 0.048279378563165665
step: 150, loss: 0.03099081851541996
step: 160, loss: 0.07419326901435852
step: 170, loss: 0.17132733762264252
step: 180, loss: 0.020035650581121445
step: 190, loss: 0.006847319193184376
step: 200, loss: 0.11436651647090912
step: 210, loss: 0.010437272489070892
step: 220, loss: 0.025774499401450157
step: 230, loss: 0.010457208380103111
step: 240, loss: 0.01208097767084837
step: 250, loss: 0.08577089756727219
step: 260, loss: 0.020704464986920357
step: 270, loss: 0.032518062740564346
step: 280, loss: 0.050859540700912476
step: 290, loss: 0.06470604985952377
step: 300, loss: 0.05319641903042793
step: 310, loss: 0.07373081892728806
step: 320, loss: 0.0856378972530365
step: 330, loss: 0.03345919027924538
step: 340, loss: 0.18241830170154572
step: 350, loss: 0.05085861682891846
step: 360, loss: 0.27558374404907227
step: 370, loss: 0.12817473709583282
step: 380, loss: 0.027957620099186897
epoch 5: dev_f1=0.7185929648241205, f1=0.5026455026455026, best_f1=0.5378590078328982
step: 0, loss: 0.018068792298436165
step: 10, loss: 0.24300643801689148
step: 20, loss: 0.0041698068380355835
step: 30, loss: 0.04559781402349472
step: 40, loss: 0.07748793810606003
step: 50, loss: 0.017504693940281868
step: 60, loss: 0.014250807464122772
step: 70, loss: 0.024069933220744133
step: 80, loss: 0.018518606200814247
step: 90, loss: 0.02824672870337963
step: 100, loss: 0.013518662191927433
step: 110, loss: 0.1920507550239563
step: 120, loss: 0.17758449912071228
step: 130, loss: 0.00874100811779499
step: 140, loss: 0.008692190982401371
step: 150, loss: 0.006820689886808395
step: 160, loss: 0.029194409027695656
step: 170, loss: 0.03654706850647926
step: 180, loss: 0.014116437174379826
step: 190, loss: 0.07989431917667389
step: 200, loss: 0.012386704795062542
step: 210, loss: 0.03737388178706169
step: 220, loss: 0.1466427892446518
step: 230, loss: 0.03581833466887474
step: 240, loss: 0.06645555794239044
step: 250, loss: 0.008022771216928959
step: 260, loss: 0.07859703153371811
step: 270, loss: 0.04705347120761871
step: 280, loss: 0.039550039917230606
step: 290, loss: 0.14352144300937653
step: 300, loss: 0.01899995654821396
step: 310, loss: 0.003587105078622699
step: 320, loss: 0.06280792504549026
step: 330, loss: 0.029170528054237366
step: 340, loss: 0.001778785022906959
step: 350, loss: 0.04220243915915489
step: 360, loss: 0.02405991405248642
step: 370, loss: 0.015229523181915283
step: 380, loss: 0.15743699669837952
epoch 6: dev_f1=0.7725118483412323, f1=0.5418719211822659, best_f1=0.5418719211822659
step: 0, loss: 0.06302747875452042
step: 10, loss: 0.004220584407448769
step: 20, loss: 0.1251353919506073
step: 30, loss: 0.07038287073373795
step: 40, loss: 0.07084955275058746
step: 50, loss: 0.03685401752591133
step: 60, loss: 0.0362318679690361
step: 70, loss: 0.08028371632099152
step: 80, loss: 0.010181915014982224
step: 90, loss: 0.02018759958446026
step: 100, loss: 0.003129403106868267
step: 110, loss: 0.0016449539689347148
step: 120, loss: 0.009632504545152187
step: 130, loss: 0.09878282994031906
step: 140, loss: 0.005525731015950441
step: 150, loss: 0.00712459534406662
step: 160, loss: 0.010741892270743847
step: 170, loss: 0.01475543063133955
step: 180, loss: 0.07146206498146057
step: 190, loss: 0.045153699815273285
step: 200, loss: 0.006285959389060736
step: 210, loss: 0.010017291642725468
step: 220, loss: 0.1105690598487854
step: 230, loss: 0.005158057436347008
step: 240, loss: 0.020219646394252777
step: 250, loss: 0.0022456764709204435
step: 260, loss: 0.014228740707039833
step: 270, loss: 0.0023761761840432882
step: 280, loss: 0.101706862449646
step: 290, loss: 0.07390765100717545
step: 300, loss: 0.09039448946714401
step: 310, loss: 0.055322881788015366
step: 320, loss: 0.024868465960025787
step: 330, loss: 0.06048990786075592
step: 340, loss: 0.00223771994933486
step: 350, loss: 0.001288901548832655
step: 360, loss: 0.019710814580321312
step: 370, loss: 0.03624323755502701
step: 380, loss: 0.004297269973903894
epoch 7: dev_f1=0.7321867321867322, f1=0.561038961038961, best_f1=0.5418719211822659
step: 0, loss: 0.04767340421676636
step: 10, loss: 0.0555928498506546
step: 20, loss: 0.0034934724681079388
step: 30, loss: 0.017352858558297157
step: 40, loss: 0.020513378083705902
step: 50, loss: 0.08575206249952316
step: 60, loss: 0.057569511234760284
step: 70, loss: 0.1527743935585022
step: 80, loss: 0.007329648360610008
step: 90, loss: 0.027334479615092278
step: 100, loss: 0.007338804192841053
step: 110, loss: 0.16780218482017517
step: 120, loss: 0.062351178377866745
step: 130, loss: 0.008196305483579636
step: 140, loss: 0.03263108804821968
step: 150, loss: 0.0011484305141493678
step: 160, loss: 0.0008406820124946535
step: 170, loss: 0.002621395979076624
step: 180, loss: 0.0379914827644825
step: 190, loss: 0.09678613394498825
step: 200, loss: 0.023339930921792984
step: 210, loss: 0.005387934390455484
step: 220, loss: 0.008898891508579254
step: 230, loss: 0.04035645350813866
step: 240, loss: 0.004612073767930269
step: 250, loss: 0.0022003441117703915
step: 260, loss: 0.0027755671180784702
step: 270, loss: 0.012566175311803818
step: 280, loss: 0.07820521295070648
step: 290, loss: 0.05095793306827545
step: 300, loss: 0.007803372573107481
step: 310, loss: 0.004908612929284573
step: 320, loss: 0.00021852234203834087
step: 330, loss: 0.0008389493450522423
step: 340, loss: 0.011059011332690716
step: 350, loss: 0.003172279102727771
step: 360, loss: 0.006826449651271105
step: 370, loss: 0.007860353216528893
step: 380, loss: 0.0217122845351696
epoch 8: dev_f1=0.7285714285714286, f1=0.565, best_f1=0.5418719211822659
step: 0, loss: 0.031025564298033714
step: 10, loss: 0.0016661774134263396
step: 20, loss: 0.002307556103914976
step: 30, loss: 0.000640916230622679
step: 40, loss: 0.003379101399332285
step: 50, loss: 0.0009398871916346252
step: 60, loss: 0.003117614658549428
step: 70, loss: 0.060552921146154404
step: 80, loss: 0.0020831290166825056
step: 90, loss: 0.002370761474594474
step: 100, loss: 0.001441320520825684
step: 110, loss: 0.0016655680956318974
step: 120, loss: 0.0017180218128487468
step: 130, loss: 0.01006298791617155
step: 140, loss: 0.0006519716698676348
step: 150, loss: 0.05811053141951561
step: 160, loss: 0.0052129290997982025
step: 170, loss: 0.013179249130189419
step: 180, loss: 0.050561707466840744
step: 190, loss: 0.0009204375674016774
step: 200, loss: 0.00528055801987648
step: 210, loss: 0.008284253068268299
step: 220, loss: 0.004770410712808371
step: 230, loss: 0.008360476233065128
step: 240, loss: 0.011829305440187454
step: 250, loss: 0.004527026321738958
step: 260, loss: 0.014001099392771721
step: 270, loss: 0.04252413287758827
step: 280, loss: 0.002393461065366864
step: 290, loss: 0.03168588504195213
step: 300, loss: 0.0072116428054869175
step: 310, loss: 0.14718644320964813
step: 320, loss: 0.06941953301429749
step: 330, loss: 0.0010294116800650954
step: 340, loss: 0.0016712585929781199
step: 350, loss: 0.012985189445316792
step: 360, loss: 0.1334066241979599
step: 370, loss: 0.0018640325870364904
step: 380, loss: 0.002826946321874857
epoch 9: dev_f1=0.7641025641025642, f1=0.6022099447513812, best_f1=0.5418719211822659
step: 0, loss: 0.05553519353270531
step: 10, loss: 0.002427896950393915
step: 20, loss: 0.04970649629831314
step: 30, loss: 0.0018352399347350001
step: 40, loss: 0.05444706231355667
step: 50, loss: 0.006169877015054226
step: 60, loss: 0.003574454691261053
step: 70, loss: 0.025462308898568153
step: 80, loss: 0.001458261744119227
step: 90, loss: 0.00221571559086442
step: 100, loss: 0.00067812146153301
step: 110, loss: 0.041586652398109436
step: 120, loss: 0.0028202058747410774
step: 130, loss: 0.04468298703432083
step: 140, loss: 0.005151466932147741
step: 150, loss: 0.0020625425968319178
step: 160, loss: 0.014888216741383076
step: 170, loss: 0.0012996845180168748
step: 180, loss: 0.1176832914352417
step: 190, loss: 0.0014718339079990983
step: 200, loss: 0.015209244564175606
step: 210, loss: 0.00021260719222482294
step: 220, loss: 0.004146845545619726
step: 230, loss: 0.001226925291121006
step: 240, loss: 0.00041944481199607253
step: 250, loss: 0.00018125200585927814
step: 260, loss: 0.007283312268555164
step: 270, loss: 0.0007538225618191063
step: 280, loss: 0.005544397514313459
step: 290, loss: 0.0019542279187589884
step: 300, loss: 0.018887603655457497
step: 310, loss: 0.003473946824669838
step: 320, loss: 0.0005223934422247112
step: 330, loss: 0.010137626901268959
step: 340, loss: 0.000401284167310223
step: 350, loss: 0.014899968169629574
step: 360, loss: 0.0012111522955819964
step: 370, loss: 0.007157783955335617
step: 380, loss: 0.054464925080537796
epoch 10: dev_f1=0.7268292682926828, f1=0.583756345177665, best_f1=0.5418719211822659
step: 0, loss: 0.0004829833924304694
step: 10, loss: 0.003391222096979618
step: 20, loss: 0.004671672824770212
step: 30, loss: 0.0006564854993484914
step: 40, loss: 0.0027479534037411213
step: 50, loss: 0.0011615734547376633
step: 60, loss: 0.008174370974302292
step: 70, loss: 0.0014104429865255952
step: 80, loss: 0.00026213875389657915
step: 90, loss: 0.001693477388471365
step: 100, loss: 0.05938929319381714
step: 110, loss: 0.0022438587620854378
step: 120, loss: 0.04066549986600876
step: 130, loss: 0.00025875691790133715
step: 140, loss: 0.008018997497856617
step: 150, loss: 0.0003604735538829118
step: 160, loss: 0.00435781292617321
step: 170, loss: 0.002182192634791136
step: 180, loss: 0.007406414486467838
step: 190, loss: 0.006610839627683163
step: 200, loss: 0.0012925765477120876
step: 210, loss: 0.0003373559156898409
step: 220, loss: 0.00012535111454781145
step: 230, loss: 0.0008608250063844025
step: 240, loss: 0.017923405393958092
step: 250, loss: 0.0018882047152146697
step: 260, loss: 0.002099537756294012
step: 270, loss: 0.004175605718046427
step: 280, loss: 0.0004785690107382834
step: 290, loss: 0.002854233141988516
step: 300, loss: 0.00039365151314996183
step: 310, loss: 0.0007376434514299035
step: 320, loss: 0.0011145067401230335
step: 330, loss: 0.002544648479670286
step: 340, loss: 0.00042604372720234096
step: 350, loss: 0.01797717809677124
step: 360, loss: 0.02052273415029049
step: 370, loss: 0.0037252341862767935
step: 380, loss: 0.0018287176499143243
epoch 11: dev_f1=0.7613941018766757, f1=0.5513196480938417, best_f1=0.5418719211822659
step: 0, loss: 0.00041394212166778743
step: 10, loss: 0.002708018757402897
step: 20, loss: 7.869917317293584e-05
step: 30, loss: 0.0029875733889639378
step: 40, loss: 0.020483436062932014
step: 50, loss: 0.00039870216278359294
step: 60, loss: 0.0005772090516984463
step: 70, loss: 0.027185693383216858
step: 80, loss: 0.0001610324834473431
step: 90, loss: 0.0005670425016433001
step: 100, loss: 0.0016870010877028108
step: 110, loss: 0.0004973047180101275
step: 120, loss: 0.016252975910902023
step: 130, loss: 0.0039664581418037415
step: 140, loss: 0.00023337248421739787
step: 150, loss: 0.005929835140705109
step: 160, loss: 0.0004902385990135372
step: 170, loss: 0.013249690644443035
step: 180, loss: 0.07587286829948425
step: 190, loss: 0.0021808163728564978
step: 200, loss: 0.07564083486795425
step: 210, loss: 0.010392763651907444
step: 220, loss: 0.0003388893383089453
step: 230, loss: 0.00026338690076954663
step: 240, loss: 0.000300110608804971
step: 250, loss: 0.0036717120092362165
step: 260, loss: 0.004440674092620611
step: 270, loss: 0.028988026082515717
step: 280, loss: 0.001835072529502213
step: 290, loss: 0.000702522462233901
step: 300, loss: 0.0038516598287969828
step: 310, loss: 0.00012506837083492428
step: 320, loss: 0.0006534279091283679
step: 330, loss: 0.009609438478946686
step: 340, loss: 0.0024330471642315388
step: 350, loss: 0.002187097677960992
step: 360, loss: 0.015871696174144745
step: 370, loss: 0.12203403562307358
step: 380, loss: 0.003282798919826746
epoch 12: dev_f1=0.7423822714681441, f1=0.5, best_f1=0.5418719211822659
step: 0, loss: 0.001139732194133103
step: 10, loss: 0.00020027034042868763
step: 20, loss: 0.00114584737457335
step: 30, loss: 0.000539777334779501
step: 40, loss: 0.0013045232044532895
step: 50, loss: 0.013591981492936611
step: 60, loss: 0.09600213915109634
step: 70, loss: 0.00021518419089261442
step: 80, loss: 0.0013258251128718257
step: 90, loss: 0.0017600650899112225
step: 100, loss: 0.0009059100993908942
step: 110, loss: 0.0007062151562422514
step: 120, loss: 0.00113513448741287
step: 130, loss: 0.001549764652736485
step: 140, loss: 0.0013264130102470517
step: 150, loss: 0.01624196209013462
step: 160, loss: 0.005453248042613268
step: 170, loss: 0.009205112233757973
step: 180, loss: 0.0004080356447957456
step: 190, loss: 0.019209643825888634
step: 200, loss: 0.0005691879196092486
step: 210, loss: 0.00019663703278638422
step: 220, loss: 0.0016568938735872507
step: 230, loss: 0.00020044579287059605
step: 240, loss: 0.0025340821593999863
step: 250, loss: 0.004047962836921215
step: 260, loss: 0.0007279396522790194
step: 270, loss: 0.004894924350082874
step: 280, loss: 0.0002873963094316423
step: 290, loss: 0.0013606904540210962
step: 300, loss: 0.0003381438145879656
step: 310, loss: 0.0005550189525820315
step: 320, loss: 0.00046470059896819293
step: 330, loss: 0.030224716290831566
step: 340, loss: 9.594409493729472e-05
step: 350, loss: 0.01995149254798889
step: 360, loss: 0.00020487667643465102
step: 370, loss: 0.09591255336999893
step: 380, loss: 0.009768381714820862
epoch 13: dev_f1=0.743455497382199, f1=0.5509641873278236, best_f1=0.5418719211822659
step: 0, loss: 0.0061102663166821
step: 10, loss: 0.01386768463999033
step: 20, loss: 0.0032987112645059824
step: 30, loss: 0.005918774288147688
step: 40, loss: 0.00023107347078621387
step: 50, loss: 9.675535693531856e-05
step: 60, loss: 0.0006206558900885284
step: 70, loss: 0.00011783714580815285
step: 80, loss: 0.0037993579171597958
step: 90, loss: 0.00103765819221735
step: 100, loss: 0.00043130028643645346
step: 110, loss: 0.00010752968955785036
step: 120, loss: 0.00013577860954683274
step: 130, loss: 0.00017005747940856963
step: 140, loss: 6.227470294106752e-05
step: 150, loss: 0.04503088817000389
step: 160, loss: 0.00045087479520589113
step: 170, loss: 0.019267916679382324
step: 180, loss: 0.001425348804332316
step: 190, loss: 0.00021449232008308172
step: 200, loss: 0.0004300096770748496
step: 210, loss: 0.001168437534943223
step: 220, loss: 0.00012568356760311872
step: 230, loss: 0.10344981402158737
step: 240, loss: 0.008328445255756378
step: 250, loss: 0.007045650854706764
step: 260, loss: 0.0035488551948219538
step: 270, loss: 0.0002599659492261708
step: 280, loss: 0.010922566056251526
step: 290, loss: 9.395351662533358e-05
step: 300, loss: 0.0010004714131355286
step: 310, loss: 0.0015551178948953748
step: 320, loss: 0.0011972126085311174
step: 330, loss: 0.002457386115565896
step: 340, loss: 0.01202333439141512
step: 350, loss: 0.0030975760892033577
step: 360, loss: 0.0010281713912263513
step: 370, loss: 0.0021617296151816845
step: 380, loss: 0.004205793607980013
epoch 14: dev_f1=0.7455919395465995, f1=0.5561497326203209, best_f1=0.5418719211822659
step: 0, loss: 0.037037890404462814
step: 10, loss: 0.001445592730306089
step: 20, loss: 0.0009769081370905042
step: 30, loss: 0.010431919246912003
step: 40, loss: 0.0014047215227037668
step: 50, loss: 0.00022437302686739713
step: 60, loss: 0.000145783691550605
step: 70, loss: 0.0006664302782155573
step: 80, loss: 0.0012600623304024339
step: 90, loss: 8.17318432382308e-05
step: 100, loss: 0.0001464962406316772
step: 110, loss: 0.0003830353089142591
step: 120, loss: 0.0015265572583302855
step: 130, loss: 0.0019013925921171904
step: 140, loss: 0.005575334653258324
step: 150, loss: 0.00036252467543818057
step: 160, loss: 0.0010155639611184597
step: 170, loss: 0.0004360400780569762
step: 180, loss: 0.00020777538884431124
step: 190, loss: 0.0031918976455926895
step: 200, loss: 0.00034910778049379587
step: 210, loss: 0.0015696707414463162
step: 220, loss: 0.0016630466561764479
step: 230, loss: 0.0025281617417931557
step: 240, loss: 0.005823199171572924
step: 250, loss: 0.00025267855380661786
step: 260, loss: 8.298249304061756e-05
step: 270, loss: 0.0004925469984300435
step: 280, loss: 6.346451118588448e-05
step: 290, loss: 0.00032242294400930405
step: 300, loss: 0.006555166561156511
step: 310, loss: 0.0001402922353008762
step: 320, loss: 0.0001390053948853165
step: 330, loss: 0.0013188878074288368
step: 340, loss: 0.00017435476183891296
step: 350, loss: 0.002002490684390068
step: 360, loss: 0.0004593687190208584
step: 370, loss: 0.003297381568700075
step: 380, loss: 9.198909538099542e-05
epoch 15: dev_f1=0.7409470752089136, f1=0.5269461077844312, best_f1=0.5418719211822659
step: 0, loss: 0.0003671066660899669
step: 10, loss: 0.00013432130799628794
step: 20, loss: 0.00020039845549035817
step: 30, loss: 0.0024907917249947786
step: 40, loss: 0.0009374918881803751
step: 50, loss: 9.887569467537105e-05
step: 60, loss: 5.1144590543117374e-05
step: 70, loss: 0.0005160876899026334
step: 80, loss: 0.0010854064021259546
step: 90, loss: 0.00010613405174808577
step: 100, loss: 0.0034928093664348125
step: 110, loss: 0.00025047193048521876
step: 120, loss: 0.010418236255645752
step: 130, loss: 0.0009289213921874762
step: 140, loss: 0.0006698999786749482
step: 150, loss: 0.0012981060426682234
step: 160, loss: 0.0006565845687873662
step: 170, loss: 0.0020377112086862326
step: 180, loss: 0.002685924293473363
step: 190, loss: 0.00012649864947889
step: 200, loss: 0.03908166289329529
step: 210, loss: 0.0005866036517545581
step: 220, loss: 0.00041498200153000653
step: 230, loss: 0.051350757479667664
step: 240, loss: 0.0008649014635011554
step: 250, loss: 0.0012349566677585244
step: 260, loss: 0.004666137509047985
step: 270, loss: 7.645846926607192e-05
step: 280, loss: 0.001156421029008925
step: 290, loss: 0.0009795627556741238
step: 300, loss: 0.0013958519557490945
step: 310, loss: 0.00010852715058717877
step: 320, loss: 4.6540109906345606e-05
step: 330, loss: 0.00011520882981130853
step: 340, loss: 0.00011026492575183511
step: 350, loss: 0.009249737486243248
step: 360, loss: 0.0018526848871260881
step: 370, loss: 0.00010364974878029898
step: 380, loss: 0.002926954533904791
epoch 16: dev_f1=0.7563025210084034, f1=0.4984802431610942, best_f1=0.5418719211822659
step: 0, loss: 0.0017013507895171642
step: 10, loss: 5.5014388635754585e-05
step: 20, loss: 0.004187947139143944
step: 30, loss: 5.181110100238584e-05
step: 40, loss: 7.125321280909702e-05
step: 50, loss: 5.110272832098417e-05
step: 60, loss: 4.6858040150254965e-05
step: 70, loss: 0.0001289712090510875
step: 80, loss: 0.005097314715385437
step: 90, loss: 9.64451755862683e-05
step: 100, loss: 0.0036976386327296495
step: 110, loss: 0.0001343726326012984
step: 120, loss: 0.0033537615090608597
step: 130, loss: 0.0021670956630259752
step: 140, loss: 0.00021661563368979841
step: 150, loss: 4.122177779208869e-05
step: 160, loss: 0.00020365130330901593
step: 170, loss: 0.0006249216385185719
step: 180, loss: 0.00013805757043883204
step: 190, loss: 0.07154819369316101
step: 200, loss: 0.00013482845679391176
step: 210, loss: 0.00012587738456204534
step: 220, loss: 0.0006641425425186753
step: 230, loss: 0.00017509839381091297
step: 240, loss: 5.976031388854608e-05
step: 250, loss: 0.0013181724352762103
step: 260, loss: 0.00035515541094355285
step: 270, loss: 0.0004380045284051448
step: 280, loss: 0.0007620738469995558
step: 290, loss: 0.0022301257122308016
step: 300, loss: 5.065487130195834e-05
step: 310, loss: 0.00025152479065582156
step: 320, loss: 8.307509415317327e-05
step: 330, loss: 8.969312330009416e-05
step: 340, loss: 0.0008289826801046729
step: 350, loss: 0.00024589430540800095
step: 360, loss: 9.896555275190622e-05
step: 370, loss: 0.0022992535959929228
step: 380, loss: 0.00115715223364532
epoch 17: dev_f1=0.7349081364829396, f1=0.5619834710743802, best_f1=0.5418719211822659
step: 0, loss: 0.0009746186551637948
step: 10, loss: 0.001649836776778102
step: 20, loss: 0.0010713055962696671
step: 30, loss: 0.0008022701949812472
step: 40, loss: 0.005551581270992756
step: 50, loss: 0.0003128699609078467
step: 60, loss: 0.00014793741866014898
step: 70, loss: 0.0021620162297040224
step: 80, loss: 8.798696944722906e-05
step: 90, loss: 0.002893580822274089
step: 100, loss: 7.046288374112919e-05
step: 110, loss: 0.00030809076270088553
step: 120, loss: 0.0004306489136070013
step: 130, loss: 0.0002286246744915843
step: 140, loss: 6.330964242806658e-05
step: 150, loss: 0.00018122729670722038
step: 160, loss: 0.00017086182197090238
step: 170, loss: 7.27460574125871e-05
step: 180, loss: 0.00021935635595582426
step: 190, loss: 0.0034953909926116467
step: 200, loss: 0.0011405954137444496
step: 210, loss: 0.00015317971701733768
step: 220, loss: 0.00047397444723173976
step: 230, loss: 3.371282582520507e-05
step: 240, loss: 0.006255504675209522
step: 250, loss: 0.00022442823683377355
step: 260, loss: 0.00012869617785327137
step: 270, loss: 0.0002988717460539192
step: 280, loss: 0.00016576077905483544
step: 290, loss: 0.00047794892452657223
step: 300, loss: 0.00015472297673113644
step: 310, loss: 0.0003332004707772285
step: 320, loss: 0.0003647637786343694
step: 330, loss: 0.00012054178660036996
step: 340, loss: 0.0001708380732452497
step: 350, loss: 3.566060695447959e-05
step: 360, loss: 0.0003942709881812334
step: 370, loss: 6.668033893220127e-05
step: 380, loss: 7.617371011292562e-05
epoch 18: dev_f1=0.75, f1=0.526610644257703, best_f1=0.5418719211822659
step: 0, loss: 0.0002862781402654946
step: 10, loss: 0.00024905381724238396
step: 20, loss: 4.527224155026488e-05
step: 30, loss: 0.0003207623667549342
step: 40, loss: 0.00011083095887443051
step: 50, loss: 0.00048584971227683127
step: 60, loss: 0.0034277765080332756
step: 70, loss: 0.01795598492026329
step: 80, loss: 0.000516990665346384
step: 90, loss: 0.00035437417682260275
step: 100, loss: 0.00021597645536530763
step: 110, loss: 0.015158849768340588
step: 120, loss: 0.00015583616914227605
step: 130, loss: 3.581740747904405e-05
step: 140, loss: 0.00029063946567475796
step: 150, loss: 0.0008819377981126308
step: 160, loss: 0.00041331606917083263
step: 170, loss: 0.0001249666092917323
step: 180, loss: 8.411497401539236e-05
step: 190, loss: 0.0011319741606712341
step: 200, loss: 0.0014330984558910131
step: 210, loss: 6.931278039701283e-05
step: 220, loss: 0.0011602970771491528
step: 230, loss: 0.002239819848909974
step: 240, loss: 5.61606721021235e-05
step: 250, loss: 8.168810018105432e-05
step: 260, loss: 0.00013231915363576263
step: 270, loss: 4.778392394655384e-05
step: 280, loss: 0.00010359247971791774
step: 290, loss: 0.00010141690290765837
step: 300, loss: 0.00021745079720858485
step: 310, loss: 6.763824785593897e-05
step: 320, loss: 0.00017014016339089721
step: 330, loss: 0.019793884828686714
step: 340, loss: 0.0004875438753515482
step: 350, loss: 0.000463081436464563
step: 360, loss: 0.0001040241404552944
step: 370, loss: 4.817060471395962e-05
step: 380, loss: 0.00029105370049364865
epoch 19: dev_f1=0.7393617021276595, f1=0.5363128491620112, best_f1=0.5418719211822659
step: 0, loss: 0.0026643320452421904
step: 10, loss: 0.0011377106420695782
step: 20, loss: 0.00033329922007396817
step: 30, loss: 0.0001222616556333378
step: 40, loss: 0.00047044287202879786
step: 50, loss: 0.00021255214232951403
step: 60, loss: 0.0001384992356179282
step: 70, loss: 0.0006727556465193629
step: 80, loss: 9.031823719851673e-05
step: 90, loss: 0.00020639099238906056
step: 100, loss: 0.0008197234128601849
step: 110, loss: 0.0010202444391325116
step: 120, loss: 0.00031257476075552404
step: 130, loss: 9.159593901131302e-05
step: 140, loss: 0.00010585195559542626
step: 150, loss: 9.696264896774665e-05
step: 160, loss: 0.00017294676217716187
step: 170, loss: 7.017250754870474e-05
step: 180, loss: 0.020796695724129677
step: 190, loss: 0.00014974517398513854
step: 200, loss: 0.0005127205513417721
step: 210, loss: 4.044387969770469e-05
step: 220, loss: 5.068595419288613e-05
step: 230, loss: 8.649898518342525e-05
step: 240, loss: 0.00019035261357203126
step: 250, loss: 0.003538585966452956
step: 260, loss: 8.819183858577162e-05
step: 270, loss: 6.648389535257593e-05
step: 280, loss: 0.0003734090132638812
step: 290, loss: 0.00037584116216748953
step: 300, loss: 7.346377242356539e-05
step: 310, loss: 0.0007996375788934529
step: 320, loss: 2.3994040020625107e-05
step: 330, loss: 0.0023283029440790415
step: 340, loss: 0.0007710063364356756
step: 350, loss: 8.005353447515517e-05
step: 360, loss: 0.00011479730892460793
step: 370, loss: 0.016393164172768593
step: 380, loss: 0.000110353619675152
epoch 20: dev_f1=0.75, f1=0.5280898876404495, best_f1=0.5418719211822659
