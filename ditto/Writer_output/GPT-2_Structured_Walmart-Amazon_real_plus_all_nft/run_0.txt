cuda
Device: cuda
step: 0, loss: 0.6213386654853821
step: 10, loss: 0.5280177593231201
step: 20, loss: 0.3025774359703064
step: 30, loss: 0.3741168975830078
step: 40, loss: 0.1483781486749649
step: 50, loss: 0.23113742470741272
step: 60, loss: 0.19016605615615845
step: 70, loss: 0.3136528432369232
step: 80, loss: 0.33809518814086914
step: 90, loss: 0.45441028475761414
step: 100, loss: 0.41561436653137207
step: 110, loss: 0.24283063411712646
step: 120, loss: 0.22877895832061768
step: 130, loss: 0.08036701381206512
step: 140, loss: 0.3345871567726135
step: 150, loss: 0.3197327256202698
step: 160, loss: 0.24996642768383026
step: 170, loss: 0.22909896075725555
step: 180, loss: 0.4036414921283722
step: 190, loss: 0.576271653175354
step: 200, loss: 0.4695032835006714
step: 210, loss: 0.3717762231826782
step: 220, loss: 0.2072402834892273
step: 230, loss: 0.2596338987350464
step: 240, loss: 0.31540805101394653
step: 250, loss: 0.18907709419727325
step: 260, loss: 0.24883244931697845
step: 270, loss: 0.3386906683444977
step: 280, loss: 0.21979638934135437
step: 290, loss: 0.4932996928691864
step: 300, loss: 0.25240257382392883
step: 310, loss: 0.248413547873497
step: 320, loss: 0.22894592583179474
step: 330, loss: 0.2891046404838562
step: 340, loss: 0.3429056406021118
step: 350, loss: 0.28013455867767334
step: 360, loss: 0.4485854506492615
step: 370, loss: 0.15379436314105988
step: 380, loss: 0.11855217814445496
epoch 1: dev_f1=0.5789473684210527, f1=0.4039408866995074, best_f1=0.4039408866995074
step: 0, loss: 0.16563785076141357
step: 10, loss: 0.12030330300331116
step: 20, loss: 0.17351841926574707
step: 30, loss: 0.2615197002887726
step: 40, loss: 0.2099306881427765
step: 50, loss: 0.36389005184173584
step: 60, loss: 0.09338092803955078
step: 70, loss: 0.12872560322284698
step: 80, loss: 0.19660501182079315
step: 90, loss: 0.10998068749904633
step: 100, loss: 0.14119397103786469
step: 110, loss: 0.276622474193573
step: 120, loss: 0.10366601496934891
step: 130, loss: 0.1984659731388092
step: 140, loss: 0.11082873493432999
step: 150, loss: 0.17867623269557953
step: 160, loss: 0.506332516670227
step: 170, loss: 0.07803557813167572
step: 180, loss: 0.05882754921913147
step: 190, loss: 0.344209760427475
step: 200, loss: 0.17423954606056213
step: 210, loss: 0.19731536507606506
step: 220, loss: 0.11003541201353073
step: 230, loss: 0.1919535994529724
step: 240, loss: 0.17336690425872803
step: 250, loss: 0.1824299693107605
step: 260, loss: 0.23936675488948822
step: 270, loss: 0.13631977140903473
step: 280, loss: 0.06274387240409851
step: 290, loss: 0.09822890907526016
step: 300, loss: 0.10517414659261703
step: 310, loss: 0.2079566866159439
step: 320, loss: 0.07768175005912781
step: 330, loss: 0.20099571347236633
step: 340, loss: 0.2831942141056061
step: 350, loss: 0.21294015645980835
step: 360, loss: 0.20600323379039764
step: 370, loss: 0.23985916376113892
step: 380, loss: 0.2073184996843338
epoch 2: dev_f1=0.7532467532467532, f1=0.4726224783861671, best_f1=0.4726224783861671
step: 0, loss: 0.09672544151544571
step: 10, loss: 0.2149897664785385
step: 20, loss: 0.18805846571922302
step: 30, loss: 0.1193990558385849
step: 40, loss: 0.19639745354652405
step: 50, loss: 0.091641366481781
step: 60, loss: 0.15086178481578827
step: 70, loss: 0.044413529336452484
step: 80, loss: 0.08732785284519196
step: 90, loss: 0.10984750092029572
step: 100, loss: 0.14299386739730835
step: 110, loss: 0.37227892875671387
step: 120, loss: 0.25055018067359924
step: 130, loss: 0.14674867689609528
step: 140, loss: 0.27770259976387024
step: 150, loss: 0.09458526223897934
step: 160, loss: 0.13996410369873047
step: 170, loss: 0.03048062138259411
step: 180, loss: 0.06980191916227341
step: 190, loss: 0.16119131445884705
step: 200, loss: 0.18121087551116943
step: 210, loss: 0.387911319732666
step: 220, loss: 0.19491155445575714
step: 230, loss: 0.052777595818042755
step: 240, loss: 0.05299696326255798
step: 250, loss: 0.09150420874357224
step: 260, loss: 0.040491968393325806
step: 270, loss: 0.2451028972864151
step: 280, loss: 0.1340775489807129
step: 290, loss: 0.20672263205051422
step: 300, loss: 0.23064526915550232
step: 310, loss: 0.11066290736198425
step: 320, loss: 0.08234390616416931
step: 330, loss: 0.05582180991768837
step: 340, loss: 0.09690184146165848
step: 350, loss: 0.1839452087879181
step: 360, loss: 0.13058151304721832
step: 370, loss: 0.18765242397785187
step: 380, loss: 0.04350161552429199
epoch 3: dev_f1=0.763819095477387, f1=0.584022038567493, best_f1=0.584022038567493
step: 0, loss: 0.29361429810523987
step: 10, loss: 0.04689352586865425
step: 20, loss: 0.16858193278312683
step: 30, loss: 0.14362971484661102
step: 40, loss: 0.03372117504477501
step: 50, loss: 0.20751553773880005
step: 60, loss: 0.08613622188568115
step: 70, loss: 0.17040249705314636
step: 80, loss: 0.009626761078834534
step: 90, loss: 0.10097406804561615
step: 100, loss: 0.020748943090438843
step: 110, loss: 0.046905700117349625
step: 120, loss: 0.0357246920466423
step: 130, loss: 0.1510849893093109
step: 140, loss: 0.21450887620449066
step: 150, loss: 0.08038518577814102
step: 160, loss: 0.16737128794193268
step: 170, loss: 0.1486702859401703
step: 180, loss: 0.14807647466659546
step: 190, loss: 0.15351064503192902
step: 200, loss: 0.11081115901470184
step: 210, loss: 0.08125917613506317
step: 220, loss: 0.0802149772644043
step: 230, loss: 0.1372377723455429
step: 240, loss: 0.04226475954055786
step: 250, loss: 0.055441100150346756
step: 260, loss: 0.14684854447841644
step: 270, loss: 0.04644782468676567
step: 280, loss: 0.04921724274754524
step: 290, loss: 0.02376740239560604
step: 300, loss: 0.10573215782642365
step: 310, loss: 0.05916261300444603
step: 320, loss: 0.008766989223659039
step: 330, loss: 0.23012614250183105
step: 340, loss: 0.11682211607694626
step: 350, loss: 0.023107031360268593
step: 360, loss: 0.08981163054704666
step: 370, loss: 0.08195225149393082
step: 380, loss: 0.05115283653140068
epoch 4: dev_f1=0.7421052631578948, f1=0.564841498559078, best_f1=0.584022038567493
step: 0, loss: 0.03083324059844017
step: 10, loss: 0.03500621020793915
step: 20, loss: 0.010483265854418278
step: 30, loss: 0.018609359860420227
step: 40, loss: 0.1350587159395218
step: 50, loss: 0.014054426923394203
step: 60, loss: 0.02324502170085907
step: 70, loss: 0.014464304782450199
step: 80, loss: 0.0485093891620636
step: 90, loss: 0.009598420932888985
step: 100, loss: 0.008556772023439407
step: 110, loss: 0.1954713761806488
step: 120, loss: 0.04746394231915474
step: 130, loss: 0.08623703569173813
step: 140, loss: 0.031642355024814606
step: 150, loss: 0.07357446849346161
step: 160, loss: 0.03894438594579697
step: 170, loss: 0.03665899857878685
step: 180, loss: 0.13238774240016937
step: 190, loss: 0.09609638899564743
step: 200, loss: 0.014262812212109566
step: 210, loss: 0.039524540305137634
step: 220, loss: 0.019271010532975197
step: 230, loss: 0.027780231088399887
step: 240, loss: 0.07402822375297546
step: 250, loss: 0.008686873130500317
step: 260, loss: 0.15233676135540009
step: 270, loss: 0.17523370683193207
step: 280, loss: 0.02955409698188305
step: 290, loss: 0.09537110477685928
step: 300, loss: 0.06588763743638992
step: 310, loss: 0.0923011302947998
step: 320, loss: 0.03348637744784355
step: 330, loss: 0.05554590001702309
step: 340, loss: 0.023635445162653923
step: 350, loss: 0.09763965010643005
step: 360, loss: 0.048242826014757156
step: 370, loss: 0.08308564126491547
step: 380, loss: 0.09697148948907852
epoch 5: dev_f1=0.7397260273972603, f1=0.5290697674418604, best_f1=0.584022038567493
step: 0, loss: 0.029934432357549667
step: 10, loss: 0.01785966381430626
step: 20, loss: 0.03752107918262482
step: 30, loss: 0.023418541997671127
step: 40, loss: 0.053411372005939484
step: 50, loss: 0.004328559152781963
step: 60, loss: 0.008832482621073723
step: 70, loss: 0.03362834453582764
step: 80, loss: 0.07174056023359299
step: 90, loss: 0.008405023254454136
step: 100, loss: 0.1259821355342865
step: 110, loss: 0.052581384778022766
step: 120, loss: 0.019928472116589546
step: 130, loss: 0.03487580642104149
step: 140, loss: 0.14287815988063812
step: 150, loss: 0.06939258426427841
step: 160, loss: 0.012606566771864891
step: 170, loss: 0.0027592102997004986
step: 180, loss: 0.1350228190422058
step: 190, loss: 0.0324469693005085
step: 200, loss: 0.0433649942278862
step: 210, loss: 0.06126847490668297
step: 220, loss: 0.024101678282022476
step: 230, loss: 0.0024439783301204443
step: 240, loss: 0.008654600009322166
step: 250, loss: 0.05168262869119644
step: 260, loss: 0.09262121468782425
step: 270, loss: 0.010609663091599941
step: 280, loss: 0.018811898306012154
step: 290, loss: 0.015112007968127728
step: 300, loss: 0.08399622142314911
step: 310, loss: 0.054788049310445786
step: 320, loss: 0.09065074473619461
step: 330, loss: 0.008486844599246979
step: 340, loss: 0.006731043104082346
step: 350, loss: 0.1814439743757248
step: 360, loss: 0.10239528119564056
step: 370, loss: 0.14747829735279083
step: 380, loss: 0.006832079961895943
epoch 6: dev_f1=0.7662650602409639, f1=0.6448362720403021, best_f1=0.6448362720403021
step: 0, loss: 0.02027405984699726
step: 10, loss: 0.01598893664777279
step: 20, loss: 0.02166413515806198
step: 30, loss: 0.0029612898360937834
step: 40, loss: 0.03305380046367645
step: 50, loss: 0.02499793842434883
step: 60, loss: 0.21140819787979126
step: 70, loss: 0.044606100767850876
step: 80, loss: 0.022776052355766296
step: 90, loss: 0.03637611120939255
step: 100, loss: 0.006634657736867666
step: 110, loss: 0.06181996688246727
step: 120, loss: 0.02128421701490879
step: 130, loss: 0.02112000249326229
step: 140, loss: 0.027484627440571785
step: 150, loss: 0.05395038425922394
step: 160, loss: 0.08533182740211487
step: 170, loss: 0.07489439845085144
step: 180, loss: 0.004898116923868656
step: 190, loss: 0.00539515633136034
step: 200, loss: 0.005244581028819084
step: 210, loss: 0.06623249500989914
step: 220, loss: 0.046061061322689056
step: 230, loss: 0.010727962478995323
step: 240, loss: 0.22591374814510345
step: 250, loss: 0.10255643725395203
step: 260, loss: 0.21418467164039612
step: 270, loss: 0.06343052536249161
step: 280, loss: 0.03897709771990776
step: 290, loss: 0.037387121468782425
step: 300, loss: 0.13308930397033691
step: 310, loss: 0.02479906938970089
step: 320, loss: 0.09883623570203781
step: 330, loss: 0.04887734726071358
step: 340, loss: 0.012745557352900505
step: 350, loss: 0.052636079490184784
step: 360, loss: 0.02426943928003311
step: 370, loss: 0.0353132039308548
step: 380, loss: 0.11240214109420776
epoch 7: dev_f1=0.7180722891566265, f1=0.5891472868217054, best_f1=0.6448362720403021
step: 0, loss: 0.0222591795027256
step: 10, loss: 0.016159754246473312
step: 20, loss: 0.10524431616067886
step: 30, loss: 0.002521748188883066
step: 40, loss: 0.018097318708896637
step: 50, loss: 0.022128945216536522
step: 60, loss: 0.0032534690108150244
step: 70, loss: 0.09851286560297012
step: 80, loss: 0.011792080476880074
step: 90, loss: 0.06345313787460327
step: 100, loss: 0.03965568169951439
step: 110, loss: 0.016044119372963905
step: 120, loss: 0.03499104082584381
step: 130, loss: 0.022412961348891258
step: 140, loss: 0.0018745639827102423
step: 150, loss: 0.03554188087582588
step: 160, loss: 0.048584453761577606
step: 170, loss: 0.0017032918985933065
step: 180, loss: 0.005429341923445463
step: 190, loss: 0.0012567806988954544
step: 200, loss: 0.0006846237811259925
step: 210, loss: 0.012833182699978352
step: 220, loss: 0.2085505723953247
step: 230, loss: 0.045705873519182205
step: 240, loss: 0.05211740732192993
step: 250, loss: 0.050142381340265274
step: 260, loss: 0.014804881066083908
step: 270, loss: 0.013027235865592957
step: 280, loss: 0.058939121663570404
step: 290, loss: 0.027125176042318344
step: 300, loss: 0.027607114985585213
step: 310, loss: 0.00954311341047287
step: 320, loss: 0.004937904421240091
step: 330, loss: 0.00044479992357082665
step: 340, loss: 0.03668774291872978
step: 350, loss: 0.009591339156031609
step: 360, loss: 0.044502321630716324
step: 370, loss: 0.013955957256257534
step: 380, loss: 0.021146899089217186
epoch 8: dev_f1=0.7542579075425789, f1=0.6126582278481012, best_f1=0.6448362720403021
step: 0, loss: 0.006322041153907776
step: 10, loss: 0.015024282969534397
step: 20, loss: 0.0015240127686411142
step: 30, loss: 0.014706567861139774
step: 40, loss: 0.001679001608863473
step: 50, loss: 0.03557860478758812
step: 60, loss: 0.007252875715494156
step: 70, loss: 0.00474210549145937
step: 80, loss: 0.004006899427622557
step: 90, loss: 0.023450128734111786
step: 100, loss: 0.0028802137821912766
step: 110, loss: 0.0006701735546812415
step: 120, loss: 0.021509945392608643
step: 130, loss: 0.0020565905142575502
step: 140, loss: 0.06932232528924942
step: 150, loss: 0.0006280661909841001
step: 160, loss: 0.021629365161061287
step: 170, loss: 0.0006735004717484117
step: 180, loss: 0.30510300397872925
step: 190, loss: 0.0002658263547345996
step: 200, loss: 0.0209115631878376
step: 210, loss: 0.0016220572870224714
step: 220, loss: 0.0029958689119666815
step: 230, loss: 0.008343297056853771
step: 240, loss: 0.001207982306368649
step: 250, loss: 0.00994238629937172
step: 260, loss: 0.0005911130574531853
step: 270, loss: 0.009454802609980106
step: 280, loss: 0.0093917865306139
step: 290, loss: 0.07290690392255783
step: 300, loss: 0.006781294476240873
step: 310, loss: 0.005501157138496637
step: 320, loss: 0.0033929962664842606
step: 330, loss: 0.011686258018016815
step: 340, loss: 0.0167721938341856
step: 350, loss: 0.04755427688360214
step: 360, loss: 0.013180439360439777
step: 370, loss: 0.14993615448474884
step: 380, loss: 0.00021108238433953375
epoch 9: dev_f1=0.7560321715817695, f1=0.5942857142857143, best_f1=0.6448362720403021
step: 0, loss: 0.02557690255343914
step: 10, loss: 0.03908831626176834
step: 20, loss: 0.014659968204796314
step: 30, loss: 0.052219294011592865
step: 40, loss: 0.008652646094560623
step: 50, loss: 0.021771874278783798
step: 60, loss: 0.0031904219649732113
step: 70, loss: 0.00029824176453985274
step: 80, loss: 0.004798094276338816
step: 90, loss: 0.0007851584232412279
step: 100, loss: 0.002495302353054285
step: 110, loss: 0.037261828780174255
step: 120, loss: 0.005553900729864836
step: 130, loss: 0.0038769058883190155
step: 140, loss: 0.0011395784094929695
step: 150, loss: 0.0016612886684015393
step: 160, loss: 0.03729649633169174
step: 170, loss: 0.0071821147575974464
step: 180, loss: 0.13852667808532715
step: 190, loss: 0.006498574744910002
step: 200, loss: 0.0014223232865333557
step: 210, loss: 0.0015725819393992424
step: 220, loss: 0.0005254598218016326
step: 230, loss: 0.01147883664816618
step: 240, loss: 0.0008412963943555951
step: 250, loss: 0.05245840176939964
step: 260, loss: 0.0008499081013724208
step: 270, loss: 0.0004206740704830736
step: 280, loss: 0.0011776386527344584
step: 290, loss: 0.0009857562836259604
step: 300, loss: 0.0013176527572795749
step: 310, loss: 0.008162287063896656
step: 320, loss: 0.0005480538820847869
step: 330, loss: 0.02245255373418331
step: 340, loss: 0.11645941436290741
step: 350, loss: 0.011037925258278847
step: 360, loss: 0.016354436054825783
step: 370, loss: 0.005662056151777506
step: 380, loss: 0.0015905768377706409
epoch 10: dev_f1=0.7379134860050889, f1=0.5931758530183727, best_f1=0.6448362720403021
step: 0, loss: 0.000534581602551043
step: 10, loss: 0.0005590955261141062
step: 20, loss: 0.0008300993358716369
step: 30, loss: 0.004831599537283182
step: 40, loss: 0.00746378256008029
step: 50, loss: 0.003716236213222146
step: 60, loss: 0.0008807976264506578
step: 70, loss: 0.06486095488071442
step: 80, loss: 0.0016650642501190305
step: 90, loss: 0.0008513040374964476
step: 100, loss: 0.030040830373764038
step: 110, loss: 0.003212114330381155
step: 120, loss: 0.0008829334983602166
step: 130, loss: 0.0004098276549484581
step: 140, loss: 0.0007164696580730379
step: 150, loss: 0.002528715180233121
step: 160, loss: 0.0001872486318461597
step: 170, loss: 0.00136648491024971
step: 180, loss: 0.0019033083226531744
step: 190, loss: 0.00020149418560322374
step: 200, loss: 0.001490550464950502
step: 210, loss: 0.0009388627368025482
step: 220, loss: 0.005903343670070171
step: 230, loss: 0.001131021068431437
step: 240, loss: 0.003598395036533475
step: 250, loss: 0.012009432539343834
step: 260, loss: 0.003738244529813528
step: 270, loss: 0.1449204981327057
step: 280, loss: 0.2153814733028412
step: 290, loss: 0.00554010272026062
step: 300, loss: 0.001136170350946486
step: 310, loss: 0.0034942282363772392
step: 320, loss: 0.0010368915973231196
step: 330, loss: 0.0045388322323560715
step: 340, loss: 0.0004614303179550916
step: 350, loss: 0.0011088005267083645
step: 360, loss: 0.0057244691997766495
step: 370, loss: 0.0002939913247246295
step: 380, loss: 0.0015938275028020144
epoch 11: dev_f1=0.7384615384615385, f1=0.6129032258064516, best_f1=0.6448362720403021
step: 0, loss: 0.00025216088397428393
step: 10, loss: 0.003321247175335884
step: 20, loss: 0.00027034443337470293
step: 30, loss: 0.00016486221284139901
step: 40, loss: 0.0004032660217490047
step: 50, loss: 0.011797389015555382
step: 60, loss: 0.0009704020339995623
step: 70, loss: 0.03145407512784004
step: 80, loss: 0.0016928863478824496
step: 90, loss: 0.000569007417652756
step: 100, loss: 0.0010247546015307307
step: 110, loss: 0.019029660150408745
step: 120, loss: 0.0006752884364686906
step: 130, loss: 0.03979121893644333
step: 140, loss: 0.012608637101948261
step: 150, loss: 0.0016468495596200228
step: 160, loss: 0.002330590970814228
step: 170, loss: 0.00015198146866168827
step: 180, loss: 0.026202553883194923
step: 190, loss: 0.01610935851931572
step: 200, loss: 0.009020261466503143
step: 210, loss: 0.05121743306517601
step: 220, loss: 0.03714354708790779
step: 230, loss: 0.00029598979745060205
step: 240, loss: 0.06465540826320648
step: 250, loss: 0.0007102829986251891
step: 260, loss: 0.0026919152587652206
step: 270, loss: 0.00013358533033169806
step: 280, loss: 0.0006507521611638367
step: 290, loss: 0.0002769031561911106
step: 300, loss: 0.01159296277910471
step: 310, loss: 0.0007049957057461143
step: 320, loss: 0.0004914519959129393
step: 330, loss: 0.024122342467308044
step: 340, loss: 0.0007391502149403095
step: 350, loss: 0.10798956453800201
step: 360, loss: 0.0028896695002913475
step: 370, loss: 0.002754719229415059
step: 380, loss: 0.0005216720746830106
epoch 12: dev_f1=0.7567567567567567, f1=0.5819209039548022, best_f1=0.6448362720403021
step: 0, loss: 0.0014524892903864384
step: 10, loss: 0.0027172169648110867
step: 20, loss: 0.017607228830456734
step: 30, loss: 0.00014153790834825486
step: 40, loss: 0.0012861501891165972
step: 50, loss: 0.0045074294321238995
step: 60, loss: 0.00734871719032526
step: 70, loss: 0.036077987402677536
step: 80, loss: 0.0010440832702443004
step: 90, loss: 0.001351729966700077
step: 100, loss: 0.011533213779330254
step: 110, loss: 0.15952880680561066
step: 120, loss: 0.0021683957893401384
step: 130, loss: 0.003407053416594863
step: 140, loss: 0.0006858381675556302
step: 150, loss: 0.00011285195068921894
step: 160, loss: 0.00043846771586686373
step: 170, loss: 0.002709074644371867
step: 180, loss: 0.0038123363628983498
step: 190, loss: 0.0008415681077167392
step: 200, loss: 0.0002959317062050104
step: 210, loss: 0.00046160182682797313
step: 220, loss: 0.0007733111851848662
step: 230, loss: 0.00018689285207074136
step: 240, loss: 0.055244576185941696
step: 250, loss: 0.0009952826658263803
step: 260, loss: 0.0014719526516273618
step: 270, loss: 0.00018424437439534813
step: 280, loss: 0.00021584575006272644
step: 290, loss: 0.028231745585799217
step: 300, loss: 0.001207259250804782
step: 310, loss: 0.00014375252067111433
step: 320, loss: 0.0002698262978810817
step: 330, loss: 0.005837658885866404
step: 340, loss: 9.487989154877141e-05
step: 350, loss: 0.03139548748731613
step: 360, loss: 0.0010653375647962093
step: 370, loss: 0.02326667122542858
step: 380, loss: 0.00015517559950239956
epoch 13: dev_f1=0.7574931880108992, f1=0.5843373493975903, best_f1=0.6448362720403021
step: 0, loss: 0.0014483281411230564
step: 10, loss: 0.004260237328708172
step: 20, loss: 0.00013030249101575464
step: 30, loss: 0.00010895877494476736
step: 40, loss: 0.006093247327953577
step: 50, loss: 0.0014507186133414507
step: 60, loss: 0.00032642149017192423
step: 70, loss: 0.0009366165613755584
step: 80, loss: 0.009820694103837013
step: 90, loss: 0.0005904511199332774
step: 100, loss: 0.00015256166807375848
step: 110, loss: 0.00026632496155798435
step: 120, loss: 0.00039398137596435845
step: 130, loss: 6.611639400944114e-05
step: 140, loss: 0.00044445382081903517
step: 150, loss: 0.00024090809165500104
step: 160, loss: 0.006431588903069496
step: 170, loss: 0.00013463088544085622
step: 180, loss: 0.0001677395193837583
step: 190, loss: 0.00010728448978625238
step: 200, loss: 0.0055547659285366535
step: 210, loss: 0.03597107529640198
step: 220, loss: 0.002554363338276744
step: 230, loss: 0.00015346934378612787
step: 240, loss: 0.004192197695374489
step: 250, loss: 0.0014458921505138278
step: 260, loss: 0.0020963631104677916
step: 270, loss: 0.0016858699964359403
step: 280, loss: 0.002298570703715086
step: 290, loss: 0.0012486104387789965
step: 300, loss: 0.002001340501010418
step: 310, loss: 0.0003042999596800655
step: 320, loss: 0.001954096369445324
step: 330, loss: 0.003150149015709758
step: 340, loss: 0.006090010982006788
step: 350, loss: 0.00046893343096598983
step: 360, loss: 0.00017657600983511657
step: 370, loss: 0.0006492711254395545
step: 380, loss: 0.00018169039685744792
epoch 14: dev_f1=0.7786259541984734, f1=0.6259946949602122, best_f1=0.6259946949602122
step: 0, loss: 0.00019592326134443283
step: 10, loss: 0.010778753086924553
step: 20, loss: 0.015727169811725616
step: 30, loss: 0.00032723613549023867
step: 40, loss: 0.0001091748708859086
step: 50, loss: 0.0003108446835540235
step: 60, loss: 0.00037659346708096564
step: 70, loss: 0.002186577534303069
step: 80, loss: 0.001069249352440238
step: 90, loss: 0.0012738563818857074
step: 100, loss: 0.0003593439469113946
step: 110, loss: 0.0003833971277344972
step: 120, loss: 0.0005836231866851449
step: 130, loss: 8.02203212515451e-05
step: 140, loss: 0.0008215953130275011
step: 150, loss: 0.0007665833691135049
step: 160, loss: 4.632513810065575e-05
step: 170, loss: 9.770833275979385e-05
step: 180, loss: 0.0014850798761472106
step: 190, loss: 0.004747392144054174
step: 200, loss: 0.0023406073451042175
step: 210, loss: 6.767879676772282e-05
step: 220, loss: 8.376270125154406e-05
step: 230, loss: 0.0010231009218841791
step: 240, loss: 0.0124101797118783
step: 250, loss: 0.0014767451211810112
step: 260, loss: 0.0017259715823456645
step: 270, loss: 0.006959863472729921
step: 280, loss: 0.0002392463356954977
step: 290, loss: 0.00013382444740273058
step: 300, loss: 0.006168218795210123
step: 310, loss: 0.006622167769819498
step: 320, loss: 0.00046448924695141613
step: 330, loss: 0.0004268526390660554
step: 340, loss: 0.0001387797819916159
step: 350, loss: 0.0001026561003527604
step: 360, loss: 0.0011857362696900964
step: 370, loss: 0.0011627448257058859
step: 380, loss: 0.005516575183719397
epoch 15: dev_f1=0.7783505154639175, f1=0.6287262872628726, best_f1=0.6259946949602122
step: 0, loss: 0.0004200757248327136
step: 10, loss: 6.47523847874254e-05
step: 20, loss: 0.0004531180893536657
step: 30, loss: 0.00020625274919439107
step: 40, loss: 0.00028044276405125856
step: 50, loss: 0.0002533149963710457
step: 60, loss: 0.00021616945741698146
step: 70, loss: 0.0006487576174549758
step: 80, loss: 0.000575386337004602
step: 90, loss: 0.052492305636405945
step: 100, loss: 0.014916062355041504
step: 110, loss: 0.0005773521261289716
step: 120, loss: 6.564879731740803e-05
step: 130, loss: 0.0008817262714728713
step: 140, loss: 0.0008881943067535758
step: 150, loss: 0.00042129625217057765
step: 160, loss: 0.00025103389634750783
step: 170, loss: 0.00064535450655967
step: 180, loss: 0.00017273231060244143
step: 190, loss: 0.002744195982813835
step: 200, loss: 0.0005233794800005853
step: 210, loss: 0.0001441955246264115
step: 220, loss: 0.012036430649459362
step: 230, loss: 0.0003331360057927668
step: 240, loss: 0.00014369380369316787
step: 250, loss: 0.0003835116804111749
step: 260, loss: 0.001193902106024325
step: 270, loss: 9.459463035454974e-05
step: 280, loss: 0.00020114780636504292
step: 290, loss: 0.0016823800979182124
step: 300, loss: 0.010734849609434605
step: 310, loss: 0.0001649655750952661
step: 320, loss: 0.000739369890652597
step: 330, loss: 0.00011688670929288492
step: 340, loss: 0.00032533073681406677
step: 350, loss: 0.013902281410992146
step: 360, loss: 0.12365835160017014
step: 370, loss: 5.737305764341727e-05
step: 380, loss: 8.973509829957038e-05
epoch 16: dev_f1=0.7745358090185677, f1=0.6174863387978142, best_f1=0.6259946949602122
step: 0, loss: 6.768010644009337e-05
step: 10, loss: 0.00025681123952381313
step: 20, loss: 0.0025522641371935606
step: 30, loss: 8.786370017332956e-05
step: 40, loss: 0.00011374878522474319
step: 50, loss: 0.000567785813473165
step: 60, loss: 0.00010494824527995661
step: 70, loss: 0.00028901308542117476
step: 80, loss: 0.0004847524978686124
step: 90, loss: 0.00022716139210388064
step: 100, loss: 0.00036613832344301045
step: 110, loss: 0.000474277330795303
step: 120, loss: 0.00048539350973442197
step: 130, loss: 0.0017510037869215012
step: 140, loss: 0.00021195334556978196
step: 150, loss: 0.00514264777302742
step: 160, loss: 0.00014421275409404188
step: 170, loss: 0.00012470035289879888
step: 180, loss: 0.00012990800314582884
step: 190, loss: 0.00012026189506286755
step: 200, loss: 0.00020729786774609238
step: 210, loss: 0.00044270470971241593
step: 220, loss: 4.060427818330936e-05
step: 230, loss: 0.005657020024955273
step: 240, loss: 6.602572102565318e-05
step: 250, loss: 0.05167165398597717
step: 260, loss: 0.00015207036631181836
step: 270, loss: 0.00027122662868350744
step: 280, loss: 0.0008068516035564244
step: 290, loss: 0.007903378456830978
step: 300, loss: 0.0005189728108234704
step: 310, loss: 4.149766027694568e-05
step: 320, loss: 0.0006177047034725547
step: 330, loss: 0.0012389144394546747
step: 340, loss: 0.00034205170231871307
step: 350, loss: 0.004608440212905407
step: 360, loss: 0.0011759866029024124
step: 370, loss: 0.0001536022318759933
step: 380, loss: 0.002602239605039358
epoch 17: dev_f1=0.7577937649880095, f1=0.6390243902439025, best_f1=0.6259946949602122
step: 0, loss: 0.0005697672022506595
step: 10, loss: 0.00010350849333917722
step: 20, loss: 0.00025515048764646053
step: 30, loss: 0.1330912858247757
step: 40, loss: 0.00011536029342096299
step: 50, loss: 0.00023612107906956226
step: 60, loss: 0.00010773084795800969
step: 70, loss: 0.00035018895869143307
step: 80, loss: 0.00028302078135311604
step: 90, loss: 0.00016282872820738703
step: 100, loss: 7.269126217579469e-05
step: 110, loss: 0.0012065406190231442
step: 120, loss: 0.0005389081197790802
step: 130, loss: 6.0511734773172066e-05
step: 140, loss: 0.000534623337443918
step: 150, loss: 0.0018230262212455273
step: 160, loss: 0.0007298045675270259
step: 170, loss: 0.0001580088573973626
step: 180, loss: 0.0020454360637813807
step: 190, loss: 4.722698577097617e-05
step: 200, loss: 0.002036701887845993
step: 210, loss: 0.0012231129221618176
step: 220, loss: 0.0017814058810472488
step: 230, loss: 9.228345152223483e-05
step: 240, loss: 0.00011791470024036244
step: 250, loss: 0.0009067734354175627
step: 260, loss: 4.779256778419949e-05
step: 270, loss: 0.0002208771911682561
step: 280, loss: 0.000226852236664854
step: 290, loss: 0.0005025141290389001
step: 300, loss: 0.000473484251415357
step: 310, loss: 0.00011625376646406949
step: 320, loss: 0.00038205599412322044
step: 330, loss: 0.003291172906756401
step: 340, loss: 0.0003108101664111018
step: 350, loss: 0.0007284621824510396
step: 360, loss: 0.0003571752749849111
step: 370, loss: 0.0007471650606021285
step: 380, loss: 0.00029972672928124666
epoch 18: dev_f1=0.7643979057591622, f1=0.6246575342465753, best_f1=0.6259946949602122
step: 0, loss: 7.237095996970311e-05
step: 10, loss: 0.00022877003357280046
step: 20, loss: 0.00015151099069043994
step: 30, loss: 0.00011111218918813393
step: 40, loss: 0.00012005327153019607
step: 50, loss: 8.840114605845883e-05
step: 60, loss: 0.0015117345610633492
step: 70, loss: 0.0002138817508239299
step: 80, loss: 0.00010966184345306829
step: 90, loss: 0.0001310482039116323
step: 100, loss: 0.004523301962763071
step: 110, loss: 0.00023476892965845764
step: 120, loss: 0.00025215165806002915
step: 130, loss: 4.827361772186123e-05
step: 140, loss: 0.003858320415019989
step: 150, loss: 7.887979882070795e-05
step: 160, loss: 0.0006091368850320578
step: 170, loss: 0.0005318184266798198
step: 180, loss: 0.00024242197105195373
step: 190, loss: 0.0002058637619484216
step: 200, loss: 0.0007430752157233655
step: 210, loss: 0.07623935490846634
step: 220, loss: 0.00032264174660667777
step: 230, loss: 0.0003022697928827256
step: 240, loss: 0.0008608692442066967
step: 250, loss: 0.00036240744520910084
step: 260, loss: 0.004745258018374443
step: 270, loss: 0.0002806604315992445
step: 280, loss: 0.0002945871965494007
step: 290, loss: 0.0005848589353263378
step: 300, loss: 9.204549132846296e-05
step: 310, loss: 8.774992602411658e-05
step: 320, loss: 7.116023334674537e-05
step: 330, loss: 0.00020437607599887997
step: 340, loss: 0.0021241807844489813
step: 350, loss: 0.002986930077895522
step: 360, loss: 0.004352078307420015
step: 370, loss: 0.00013318867422640324
step: 380, loss: 0.0030557115096598864
epoch 19: dev_f1=0.7651715039577835, f1=0.6140845070422535, best_f1=0.6259946949602122
step: 0, loss: 0.00019631319446489215
step: 10, loss: 0.016389230266213417
step: 20, loss: 0.00038733307155780494
step: 30, loss: 0.0005243598716333508
step: 40, loss: 7.385732169495896e-05
step: 50, loss: 8.246194920502603e-05
step: 60, loss: 6.623302033403888e-05
step: 70, loss: 9.989469253923744e-05
step: 80, loss: 5.883935955353081e-05
step: 90, loss: 0.0001368855737382546
step: 100, loss: 0.0016231281915679574
step: 110, loss: 8.300345507450402e-05
step: 120, loss: 0.002610104391351342
step: 130, loss: 0.00014296571316663176
step: 140, loss: 0.00020647962810471654
step: 150, loss: 0.00010853694402612746
step: 160, loss: 0.00013427098747342825
step: 170, loss: 5.826573760714382e-05
step: 180, loss: 0.008478458039462566
step: 190, loss: 3.748993913177401e-05
step: 200, loss: 0.0013367881765589118
step: 210, loss: 0.0003871808585245162
step: 220, loss: 0.0001181259794975631
step: 230, loss: 0.0004376439901534468
step: 240, loss: 0.00012138206511735916
step: 250, loss: 0.0002913580974563956
step: 260, loss: 0.0003052965912502259
step: 270, loss: 6.876392581034452e-05
step: 280, loss: 0.0006543813506141305
step: 290, loss: 0.0003388454206287861
step: 300, loss: 0.0006500151357613504
step: 310, loss: 0.0010679817060008645
step: 320, loss: 0.0009484401089139283
step: 330, loss: 0.00015870788774918765
step: 340, loss: 0.00013677064271178097
step: 350, loss: 6.399706762749702e-05
step: 360, loss: 0.0002899956307373941
step: 370, loss: 0.0001310311781708151
step: 380, loss: 0.002456266200169921
epoch 20: dev_f1=0.7596899224806202, f1=0.6132596685082873, best_f1=0.6259946949602122
