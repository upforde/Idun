cuda
Device: cuda
step: 0, loss: 1.0232059955596924
step: 10, loss: 0.234884113073349
step: 20, loss: 0.22778846323490143
step: 30, loss: 0.3039112687110901
step: 40, loss: 0.3098725378513336
step: 50, loss: 0.1017865389585495
step: 60, loss: 0.47700777649879456
step: 70, loss: 0.44346243143081665
step: 80, loss: 0.5111862421035767
step: 90, loss: 0.374271035194397
step: 100, loss: 0.39409855008125305
step: 110, loss: 0.3004836440086365
step: 120, loss: 0.2972027063369751
step: 130, loss: 0.4209403097629547
step: 140, loss: 0.22309157252311707
step: 150, loss: 0.21825088560581207
step: 160, loss: 0.29566752910614014
step: 170, loss: 0.24347910284996033
step: 180, loss: 0.26311594247817993
step: 190, loss: 0.30845925211906433
step: 200, loss: 0.3489975929260254
step: 210, loss: 0.29914429783821106
step: 220, loss: 0.15494124591350555
step: 230, loss: 0.13968488574028015
step: 240, loss: 0.2583374083042145
step: 250, loss: 0.22853226959705353
step: 260, loss: 0.19341251254081726
step: 270, loss: 0.19704319536685944
step: 280, loss: 0.29352685809135437
step: 290, loss: 0.17440417408943176
step: 300, loss: 0.21725516021251678
step: 310, loss: 0.1800558716058731
step: 320, loss: 0.2072463035583496
step: 330, loss: 0.2461252063512802
step: 340, loss: 0.2002050280570984
step: 350, loss: 0.12041095644235611
step: 360, loss: 0.10597186535596848
step: 370, loss: 0.1586569845676422
step: 380, loss: 0.321085661649704
epoch 1: dev_f1=0.5982142857142857, f1=0.535796766743649, best_f1=0.535796766743649
step: 0, loss: 0.23939302563667297
step: 10, loss: 0.27003735303878784
step: 20, loss: 0.30813130736351013
step: 30, loss: 0.25645583868026733
step: 40, loss: 0.3085741102695465
step: 50, loss: 0.2971431612968445
step: 60, loss: 0.0869688093662262
step: 70, loss: 0.2017105370759964
step: 80, loss: 0.503068208694458
step: 90, loss: 0.41833752393722534
step: 100, loss: 0.08236146718263626
step: 110, loss: 0.17611560225486755
step: 120, loss: 0.12695559859275818
step: 130, loss: 0.41666802763938904
step: 140, loss: 0.3072276711463928
step: 150, loss: 0.09626920521259308
step: 160, loss: 0.11066645383834839
step: 170, loss: 0.41591599583625793
step: 180, loss: 0.1908828616142273
step: 190, loss: 0.1313799023628235
step: 200, loss: 0.14075766503810883
step: 210, loss: 0.6882319450378418
step: 220, loss: 0.06974705308675766
step: 230, loss: 0.4119728207588196
step: 240, loss: 0.12575793266296387
step: 250, loss: 0.22941923141479492
step: 260, loss: 0.18099772930145264
step: 270, loss: 0.08460730314254761
step: 280, loss: 0.14090874791145325
step: 290, loss: 0.4561039209365845
step: 300, loss: 0.18680083751678467
step: 310, loss: 0.06127658858895302
step: 320, loss: 0.4525061547756195
step: 330, loss: 0.17339980602264404
step: 340, loss: 0.1341853141784668
step: 350, loss: 0.08040038496255875
step: 360, loss: 0.052952248603105545
step: 370, loss: 0.14057251811027527
step: 380, loss: 0.19001710414886475
epoch 2: dev_f1=0.7480519480519481, f1=0.6354166666666666, best_f1=0.6354166666666666
step: 0, loss: 0.07180540263652802
step: 10, loss: 0.06943605840206146
step: 20, loss: 0.12954039871692657
step: 30, loss: 0.12844069302082062
step: 40, loss: 0.04660786688327789
step: 50, loss: 0.20875801146030426
step: 60, loss: 0.1126062422990799
step: 70, loss: 0.10748999565839767
step: 80, loss: 0.0686786025762558
step: 90, loss: 0.09641404449939728
step: 100, loss: 0.214270681142807
step: 110, loss: 0.09059429168701172
step: 120, loss: 0.16395878791809082
step: 130, loss: 0.16516849398612976
step: 140, loss: 0.2682248055934906
step: 150, loss: 0.1497291475534439
step: 160, loss: 0.13758958876132965
step: 170, loss: 0.26967912912368774
step: 180, loss: 0.1532706320285797
step: 190, loss: 0.17104187607765198
step: 200, loss: 0.18417885899543762
step: 210, loss: 0.14761042594909668
step: 220, loss: 0.07013033330440521
step: 230, loss: 0.06234513223171234
step: 240, loss: 0.09164108335971832
step: 250, loss: 0.1390724927186966
step: 260, loss: 0.2384646236896515
step: 270, loss: 0.16308680176734924
step: 280, loss: 0.06371068954467773
step: 290, loss: 0.29766473174095154
step: 300, loss: 0.08206711709499359
step: 310, loss: 0.1627419888973236
step: 320, loss: 0.12107698619365692
step: 330, loss: 0.23002703487873077
step: 340, loss: 0.16346144676208496
step: 350, loss: 0.05915530025959015
step: 360, loss: 0.019001612439751625
step: 370, loss: 0.08752278238534927
step: 380, loss: 0.1413569450378418
epoch 3: dev_f1=0.7877237851662403, f1=0.6235955056179776, best_f1=0.6235955056179776
step: 0, loss: 0.03606908395886421
step: 10, loss: 0.16262252628803253
step: 20, loss: 0.019165771082043648
step: 30, loss: 0.013537266291677952
step: 40, loss: 0.0724397823214531
step: 50, loss: 0.04533517360687256
step: 60, loss: 0.03614671155810356
step: 70, loss: 0.07049556821584702
step: 80, loss: 0.10790043324232101
step: 90, loss: 0.02897198684513569
step: 100, loss: 0.05682562664151192
step: 110, loss: 0.041186243295669556
step: 120, loss: 0.1012808233499527
step: 130, loss: 0.2847636342048645
step: 140, loss: 0.1053716242313385
step: 150, loss: 0.047410693019628525
step: 160, loss: 0.18898284435272217
step: 170, loss: 0.09891384094953537
step: 180, loss: 0.17923811078071594
step: 190, loss: 0.16417044401168823
step: 200, loss: 0.15544472634792328
step: 210, loss: 0.11687058210372925
step: 220, loss: 0.2501852214336395
step: 230, loss: 0.009026654995977879
step: 240, loss: 0.14100730419158936
step: 250, loss: 0.040236879140138626
step: 260, loss: 0.03964963182806969
step: 270, loss: 0.1186193898320198
step: 280, loss: 0.10622633248567581
step: 290, loss: 0.06574761122465134
step: 300, loss: 0.06216009333729744
step: 310, loss: 0.05482718348503113
step: 320, loss: 0.08814181387424469
step: 330, loss: 0.07765205949544907
step: 340, loss: 0.012116319499909878
step: 350, loss: 0.05938565358519554
step: 360, loss: 0.20246930420398712
step: 370, loss: 0.10981691628694534
step: 380, loss: 0.03428094834089279
epoch 4: dev_f1=0.7531806615776082, f1=0.5888594164456232, best_f1=0.6235955056179776
step: 0, loss: 0.02250995859503746
step: 10, loss: 0.0830404981970787
step: 20, loss: 0.23908044397830963
step: 30, loss: 0.02899588830769062
step: 40, loss: 0.031363680958747864
step: 50, loss: 0.0160420723259449
step: 60, loss: 0.13095812499523163
step: 70, loss: 0.04043905436992645
step: 80, loss: 0.19400213658809662
step: 90, loss: 0.06887739151716232
step: 100, loss: 0.021539168432354927
step: 110, loss: 0.05112827569246292
step: 120, loss: 0.12625598907470703
step: 130, loss: 0.1633511483669281
step: 140, loss: 0.0890219658613205
step: 150, loss: 0.007483978755772114
step: 160, loss: 0.009419399313628674
step: 170, loss: 0.09722757339477539
step: 180, loss: 0.05487003177404404
step: 190, loss: 0.028931651264429092
step: 200, loss: 0.1827358603477478
step: 210, loss: 0.1108766496181488
step: 220, loss: 0.04467807337641716
step: 230, loss: 0.013185291551053524
step: 240, loss: 0.021067960187792778
step: 250, loss: 0.03139534592628479
step: 260, loss: 0.0015706764534115791
step: 270, loss: 0.17764344811439514
step: 280, loss: 0.02596290595829487
step: 290, loss: 0.12491209805011749
step: 300, loss: 0.03924685716629028
step: 310, loss: 0.11301976442337036
step: 320, loss: 0.14272715151309967
step: 330, loss: 0.020304834470152855
step: 340, loss: 0.06381065398454666
step: 350, loss: 0.2427006959915161
step: 360, loss: 0.13881704211235046
step: 370, loss: 0.007214367389678955
step: 380, loss: 0.05178659409284592
epoch 5: dev_f1=0.7989556135770235, f1=0.6666666666666667, best_f1=0.6666666666666667
step: 0, loss: 0.04284089803695679
step: 10, loss: 0.04163222014904022
step: 20, loss: 0.07394886761903763
step: 30, loss: 0.06248616427183151
step: 40, loss: 0.007325083948671818
step: 50, loss: 0.012188298627734184
step: 60, loss: 0.07463254779577255
step: 70, loss: 0.016668308526277542
step: 80, loss: 0.010978177189826965
step: 90, loss: 0.013318542391061783
step: 100, loss: 0.022371189668774605
step: 110, loss: 0.15436644852161407
step: 120, loss: 0.011310405097901821
step: 130, loss: 0.010894406586885452
step: 140, loss: 0.08684518933296204
step: 150, loss: 0.05212007090449333
step: 160, loss: 0.023598236963152885
step: 170, loss: 0.17051519453525543
step: 180, loss: 0.020762966945767403
step: 190, loss: 0.02606092020869255
step: 200, loss: 0.13191185891628265
step: 210, loss: 0.04120103269815445
step: 220, loss: 0.028327664360404015
step: 230, loss: 0.03956814482808113
step: 240, loss: 0.0170477032661438
step: 250, loss: 0.012697461992502213
step: 260, loss: 0.010776788927614689
step: 270, loss: 0.008162816986441612
step: 280, loss: 0.008888600394129753
step: 290, loss: 0.11571016907691956
step: 300, loss: 0.009328103624284267
step: 310, loss: 0.004206911660730839
step: 320, loss: 0.22202952206134796
step: 330, loss: 0.015450546517968178
step: 340, loss: 0.035968609154224396
step: 350, loss: 0.012760421261191368
step: 360, loss: 0.1018282026052475
step: 370, loss: 0.0023928890004754066
step: 380, loss: 0.003982459660619497
epoch 6: dev_f1=0.8203753351206434, f1=0.608433734939759, best_f1=0.608433734939759
step: 0, loss: 0.009532451629638672
step: 10, loss: 0.0582047775387764
step: 20, loss: 0.018645528703927994
step: 30, loss: 0.08454421907663345
step: 40, loss: 0.08032591640949249
step: 50, loss: 0.05003467947244644
step: 60, loss: 0.005219670012593269
step: 70, loss: 0.027666619047522545
step: 80, loss: 0.02611680142581463
step: 90, loss: 0.004790693987160921
step: 100, loss: 0.056418947875499725
step: 110, loss: 0.010597811080515385
step: 120, loss: 0.05795351788401604
step: 130, loss: 0.047967709600925446
step: 140, loss: 0.012677482329308987
step: 150, loss: 0.011057008057832718
step: 160, loss: 0.004006409086287022
step: 170, loss: 0.004925527609884739
step: 180, loss: 0.021654419600963593
step: 190, loss: 0.003691201563924551
step: 200, loss: 0.019297391176223755
step: 210, loss: 0.027131129056215286
step: 220, loss: 0.11900113523006439
step: 230, loss: 0.048385459929704666
step: 240, loss: 0.011043617501854897
step: 250, loss: 0.0023850908037275076
step: 260, loss: 0.007944184355437756
step: 270, loss: 0.0030687765683978796
step: 280, loss: 0.05711090937256813
step: 290, loss: 0.013909870758652687
step: 300, loss: 0.06403294950723648
step: 310, loss: 0.003407674841582775
step: 320, loss: 0.029806990176439285
step: 330, loss: 0.0404282808303833
step: 340, loss: 0.031390685588121414
step: 350, loss: 0.0254948902875185
step: 360, loss: 0.012408548966050148
step: 370, loss: 0.006782554555684328
step: 380, loss: 0.10729901492595673
epoch 7: dev_f1=0.7777777777777777, f1=0.656, best_f1=0.608433734939759
step: 0, loss: 0.0253138467669487
step: 10, loss: 0.018360795453190804
step: 20, loss: 0.029973668977618217
step: 30, loss: 0.015223786234855652
step: 40, loss: 0.017016055062413216
step: 50, loss: 0.09634712338447571
step: 60, loss: 0.040376365184783936
step: 70, loss: 0.001042610383592546
step: 80, loss: 0.0006284642149694264
step: 90, loss: 0.24978366494178772
step: 100, loss: 0.025728093460202217
step: 110, loss: 0.0040792301297187805
step: 120, loss: 0.010127509012818336
step: 130, loss: 0.0008903691777959466
step: 140, loss: 0.03251823037862778
step: 150, loss: 0.0032982067205011845
step: 160, loss: 0.011767005547881126
step: 170, loss: 0.07261961698532104
step: 180, loss: 0.06549414992332458
step: 190, loss: 0.044803280383348465
step: 200, loss: 0.04426492005586624
step: 210, loss: 0.000880171253811568
step: 220, loss: 0.0777873545885086
step: 230, loss: 0.07999035716056824
step: 240, loss: 0.02397940866649151
step: 250, loss: 0.01569276489317417
step: 260, loss: 0.0025792443193495274
step: 270, loss: 0.03484971076250076
step: 280, loss: 0.1293087601661682
step: 290, loss: 0.05172263830900192
step: 300, loss: 0.03824789449572563
step: 310, loss: 0.016355210915207863
step: 320, loss: 0.017487144097685814
step: 330, loss: 0.06917712092399597
step: 340, loss: 0.0008738029282540083
step: 350, loss: 0.041972815990448
step: 360, loss: 0.018265895545482635
step: 370, loss: 0.0073468927294015884
step: 380, loss: 0.006084388587623835
epoch 8: dev_f1=0.80719794344473, f1=0.6543535620052771, best_f1=0.608433734939759
step: 0, loss: 0.016645753756165504
step: 10, loss: 0.09835640341043472
step: 20, loss: 0.026780065149068832
step: 30, loss: 0.012183433398604393
step: 40, loss: 0.006874225568026304
step: 50, loss: 0.0022008325904607773
step: 60, loss: 0.00037437077844515443
step: 70, loss: 0.0023698383010923862
step: 80, loss: 0.010536309331655502
step: 90, loss: 0.008034635335206985
step: 100, loss: 0.0021972269751131535
step: 110, loss: 0.0012987476075068116
step: 120, loss: 0.0024028196930885315
step: 130, loss: 0.001952112652361393
step: 140, loss: 0.015176626853644848
step: 150, loss: 0.011466076597571373
step: 160, loss: 0.05542147532105446
step: 170, loss: 0.04503512382507324
step: 180, loss: 0.0048814029432833195
step: 190, loss: 0.005436392035335302
step: 200, loss: 0.09399047493934631
step: 210, loss: 0.015796197578310966
step: 220, loss: 0.01534652803093195
step: 230, loss: 0.1641627997159958
step: 240, loss: 0.001076134154573083
step: 250, loss: 0.009826659224927425
step: 260, loss: 0.10635228455066681
step: 270, loss: 0.010800541378557682
step: 280, loss: 0.08051092177629471
step: 290, loss: 0.02172549068927765
step: 300, loss: 0.004317216109484434
step: 310, loss: 0.0014874640619382262
step: 320, loss: 0.07580538839101791
step: 330, loss: 0.0006840694695711136
step: 340, loss: 0.0010514432797208428
step: 350, loss: 0.012200890108942986
step: 360, loss: 0.0029465898405760527
step: 370, loss: 0.03646913915872574
step: 380, loss: 0.04056284949183464
epoch 9: dev_f1=0.7828282828282827, f1=0.6277777777777778, best_f1=0.608433734939759
step: 0, loss: 0.02764817886054516
step: 10, loss: 0.02647923305630684
step: 20, loss: 0.0006593289435841143
step: 30, loss: 0.009249688126146793
step: 40, loss: 0.00043987081153318286
step: 50, loss: 0.00154366425704211
step: 60, loss: 0.0007577165379188955
step: 70, loss: 0.0010180807439610362
step: 80, loss: 0.0002742926590144634
step: 90, loss: 0.0016979282954707742
step: 100, loss: 0.0015683285892009735
step: 110, loss: 0.0022938286419957876
step: 120, loss: 0.02964007295668125
step: 130, loss: 0.02565188892185688
step: 140, loss: 0.006373013369739056
step: 150, loss: 0.0009406512835994363
step: 160, loss: 0.0010011467384174466
step: 170, loss: 0.0007650804473087192
step: 180, loss: 0.0015998895978555083
step: 190, loss: 0.012612121179699898
step: 200, loss: 0.018779009580612183
step: 210, loss: 0.000586911803111434
step: 220, loss: 0.014975814148783684
step: 230, loss: 0.0013803550973534584
step: 240, loss: 0.0004142804828006774
step: 250, loss: 0.012972907163202763
step: 260, loss: 0.014316832646727562
step: 270, loss: 0.07082957774400711
step: 280, loss: 0.0016559798968955874
step: 290, loss: 0.050597552210092545
step: 300, loss: 0.0077200522646307945
step: 310, loss: 0.004104467574506998
step: 320, loss: 0.0018724835244938731
step: 330, loss: 0.0011411691084504128
step: 340, loss: 0.0019523409428074956
step: 350, loss: 0.003078984096646309
step: 360, loss: 0.0036242520436644554
step: 370, loss: 0.06426330655813217
step: 380, loss: 0.09809236228466034
epoch 10: dev_f1=0.8295165394402036, f1=0.6914893617021276, best_f1=0.6914893617021276
step: 0, loss: 0.0007065976969897747
step: 10, loss: 0.0020467243157327175
step: 20, loss: 0.0026589571498334408
step: 30, loss: 0.013326107524335384
step: 40, loss: 0.00941593386232853
step: 50, loss: 0.00016649170720484108
step: 60, loss: 0.00186322838999331
step: 70, loss: 0.0015347603475674987
step: 80, loss: 0.004045137204229832
step: 90, loss: 0.020920949056744576
step: 100, loss: 0.1238137036561966
step: 110, loss: 0.020528946071863174
step: 120, loss: 0.005306570325046778
step: 130, loss: 0.0015684833051636815
step: 140, loss: 0.004701248370110989
step: 150, loss: 0.000985725549980998
step: 160, loss: 0.002801059978082776
step: 170, loss: 0.008723918348550797
step: 180, loss: 0.01430534664541483
step: 190, loss: 0.0007559331716038287
step: 200, loss: 0.0011600194266065955
step: 210, loss: 0.008116686716675758
step: 220, loss: 0.0008772523724474013
step: 230, loss: 0.0005190263036638498
step: 240, loss: 0.05774202570319176
step: 250, loss: 0.002425695536658168
step: 260, loss: 0.011260651051998138
step: 270, loss: 0.026443136855959892
step: 280, loss: 0.0021688223350793123
step: 290, loss: 0.0007835763972252607
step: 300, loss: 0.03145374730229378
step: 310, loss: 0.00019715844246093184
step: 320, loss: 0.00040558597538620234
step: 330, loss: 0.005501998122781515
step: 340, loss: 0.001881796051748097
step: 350, loss: 0.00018519224249757826
step: 360, loss: 0.001268029329366982
step: 370, loss: 0.00802715215831995
step: 380, loss: 0.008217177353799343
epoch 11: dev_f1=0.8041775456919059, f1=0.6426592797783933, best_f1=0.6914893617021276
step: 0, loss: 0.006048910785466433
step: 10, loss: 0.0077030896209180355
step: 20, loss: 0.004450359847396612
step: 30, loss: 0.05703624337911606
step: 40, loss: 0.007265130989253521
step: 50, loss: 0.000616982695646584
step: 60, loss: 0.0013082403456792235
step: 70, loss: 0.0014855990884825587
step: 80, loss: 0.0006157244206406176
step: 90, loss: 0.015623648650944233
step: 100, loss: 0.0076574403792619705
step: 110, loss: 0.002455627080053091
step: 120, loss: 0.00015913941024336964
step: 130, loss: 0.0007488682167604566
step: 140, loss: 0.0018542835023254156
step: 150, loss: 0.022748246788978577
step: 160, loss: 0.000869416689965874
step: 170, loss: 0.0004222126735839993
step: 180, loss: 0.005237855017185211
step: 190, loss: 0.009584754705429077
step: 200, loss: 0.015058644115924835
step: 210, loss: 0.002984514692798257
step: 220, loss: 0.008493748493492603
step: 230, loss: 0.005207380745559931
step: 240, loss: 0.0028908816166222095
step: 250, loss: 0.04234868288040161
step: 260, loss: 0.00029747007647529244
step: 270, loss: 0.0010233783395960927
step: 280, loss: 0.012994284741580486
step: 290, loss: 0.0005401528906077147
step: 300, loss: 0.009240769781172276
step: 310, loss: 0.0007648851023986936
step: 320, loss: 0.0045549990609288216
step: 330, loss: 0.0009531781543046236
step: 340, loss: 0.0012846972094848752
step: 350, loss: 0.0004536266496870667
step: 360, loss: 0.0038262992165982723
step: 370, loss: 0.00040533466381020844
step: 380, loss: 0.0008842495153658092
epoch 12: dev_f1=0.8223350253807106, f1=0.6277777777777778, best_f1=0.6914893617021276
step: 0, loss: 0.0018518760334700346
step: 10, loss: 0.0007872963324189186
step: 20, loss: 0.0016273284563794732
step: 30, loss: 0.001842442899942398
step: 40, loss: 0.0010259299306198955
step: 50, loss: 0.0004875795857515186
step: 60, loss: 0.05860899016261101
step: 70, loss: 0.006549570243805647
step: 80, loss: 0.2201724350452423
step: 90, loss: 0.0002589896321296692
step: 100, loss: 0.0017279665917158127
step: 110, loss: 0.0012890853686258197
step: 120, loss: 0.0005857704090885818
step: 130, loss: 0.0022017851006239653
step: 140, loss: 0.0009918728610500693
step: 150, loss: 0.0004043248773086816
step: 160, loss: 0.0035420625936239958
step: 170, loss: 0.004072831477969885
step: 180, loss: 0.0014908674638718367
step: 190, loss: 0.004358634352684021
step: 200, loss: 0.0031724011059850454
step: 210, loss: 0.0030747544951736927
step: 220, loss: 0.00019955862080678344
step: 230, loss: 0.007795970421284437
step: 240, loss: 0.0002623671607580036
step: 250, loss: 0.0036204608622938395
step: 260, loss: 0.0030363670084625483
step: 270, loss: 0.015009667724370956
step: 280, loss: 0.002678802004083991
step: 290, loss: 0.0014592083171010017
step: 300, loss: 0.0028937847819179296
step: 310, loss: 0.012938087806105614
step: 320, loss: 0.0014403678942471743
step: 330, loss: 0.002879856387153268
step: 340, loss: 4.6023436880204827e-05
step: 350, loss: 0.00022805656772106886
step: 360, loss: 0.0004931207513436675
step: 370, loss: 0.001094990991987288
step: 380, loss: 0.00024005967134144157
epoch 13: dev_f1=0.8286445012787724, f1=0.6885245901639343, best_f1=0.6914893617021276
step: 0, loss: 0.00016441819025203586
step: 10, loss: 0.00101260538212955
step: 20, loss: 0.0008203748147934675
step: 30, loss: 0.0006843243027105927
step: 40, loss: 0.012119606137275696
step: 50, loss: 9.139142639469355e-05
step: 60, loss: 0.0032632602378726006
step: 70, loss: 0.004360532853752375
step: 80, loss: 0.005230722948908806
step: 90, loss: 0.00010850077524082735
step: 100, loss: 0.010465681552886963
step: 110, loss: 0.00021978025324642658
step: 120, loss: 0.023684542626142502
step: 130, loss: 0.0030728336423635483
step: 140, loss: 0.0005352288717404008
step: 150, loss: 0.0013555571204051375
step: 160, loss: 0.002146015875041485
step: 170, loss: 0.0013481638161465526
step: 180, loss: 0.00013628351734951138
step: 190, loss: 0.004855024162679911
step: 200, loss: 0.009914577938616276
step: 210, loss: 0.001234745723195374
step: 220, loss: 0.00014533557987306267
step: 230, loss: 0.0490088127553463
step: 240, loss: 0.0015594178112223744
step: 250, loss: 0.002393171191215515
step: 260, loss: 0.0006585787632502615
step: 270, loss: 0.0003121423942502588
step: 280, loss: 0.0005754810990765691
step: 290, loss: 0.053050555288791656
step: 300, loss: 0.03457015007734299
step: 310, loss: 0.015377292409539223
step: 320, loss: 0.00012701623199973255
step: 330, loss: 0.008058145642280579
step: 340, loss: 0.0022477926686406136
step: 350, loss: 0.0009232083684764802
step: 360, loss: 0.12591873109340668
step: 370, loss: 0.0016112664015963674
step: 380, loss: 0.023256290704011917
epoch 14: dev_f1=0.8080808080808081, f1=0.6614583333333333, best_f1=0.6914893617021276
step: 0, loss: 5.083363430458121e-05
step: 10, loss: 0.0006609780830331147
step: 20, loss: 0.11284195631742477
step: 30, loss: 0.0001277524424949661
step: 40, loss: 0.028690285980701447
step: 50, loss: 0.0009516262798570096
step: 60, loss: 0.00038760522147640586
step: 70, loss: 0.0011363666271790862
step: 80, loss: 0.0016103339148685336
step: 90, loss: 0.0007161637768149376
step: 100, loss: 0.00015822486602701247
step: 110, loss: 0.00021318398648872972
step: 120, loss: 0.0004123881517443806
step: 130, loss: 0.029127126559615135
step: 140, loss: 0.00024080972070805728
step: 150, loss: 0.012478041462600231
step: 160, loss: 0.024534178897738457
step: 170, loss: 0.00022573440219275653
step: 180, loss: 0.0009202841320075095
step: 190, loss: 4.831318074138835e-05
step: 200, loss: 0.0006276750937104225
step: 210, loss: 0.0005311029381118715
step: 220, loss: 0.0003984272771049291
step: 230, loss: 0.0018135429127141833
step: 240, loss: 0.0002605131594464183
step: 250, loss: 0.001246549771167338
step: 260, loss: 0.009671349078416824
step: 270, loss: 7.195029320428148e-05
step: 280, loss: 0.00021445141464937478
step: 290, loss: 0.000436220143456012
step: 300, loss: 0.000507344666402787
step: 310, loss: 0.001973950071260333
step: 320, loss: 0.00023374574084300548
step: 330, loss: 0.00011593743693083525
step: 340, loss: 0.09068199247121811
step: 350, loss: 0.018764978274703026
step: 360, loss: 0.00022840047313366085
step: 370, loss: 0.000145747369970195
step: 380, loss: 0.0047414712607860565
epoch 15: dev_f1=0.7948717948717949, f1=0.6464088397790055, best_f1=0.6914893617021276
step: 0, loss: 0.033412326127290726
step: 10, loss: 0.00074107846012339
step: 20, loss: 0.00023840409994591027
step: 30, loss: 0.004836011212319136
step: 40, loss: 0.00017935234063770622
step: 50, loss: 0.0003786435700021684
step: 60, loss: 8.159839489962906e-05
step: 70, loss: 6.277967622736469e-05
step: 80, loss: 0.012724421918392181
step: 90, loss: 0.0001182119594886899
step: 100, loss: 0.0030368622392416
step: 110, loss: 0.0003607052785810083
step: 120, loss: 0.008636911399662495
step: 130, loss: 0.0008033736958168447
step: 140, loss: 0.0012389952316880226
step: 150, loss: 0.0005864148261025548
step: 160, loss: 0.00018084586190525442
step: 170, loss: 0.016331637278199196
step: 180, loss: 0.0003269737644586712
step: 190, loss: 0.0003189431154169142
step: 200, loss: 0.00016844748461153358
step: 210, loss: 0.002479426795616746
step: 220, loss: 0.0014978749677538872
step: 230, loss: 9.762006811797619e-05
step: 240, loss: 0.0006693517789244652
step: 250, loss: 0.00042601986206136644
step: 260, loss: 0.0007657312671653926
step: 270, loss: 0.0012790171895176172
step: 280, loss: 0.00014546288002748042
step: 290, loss: 0.00951385498046875
step: 300, loss: 0.010930871590971947
step: 310, loss: 0.0013072403380647302
step: 320, loss: 0.0033044249285012484
step: 330, loss: 0.0009063940378837287
step: 340, loss: 0.003349976846948266
step: 350, loss: 0.005225176457315683
step: 360, loss: 0.00020912254694849253
step: 370, loss: 0.0028087731916457415
step: 380, loss: 0.011208104901015759
epoch 16: dev_f1=0.813895781637717, f1=0.6615384615384615, best_f1=0.6914893617021276
step: 0, loss: 0.0002595286932773888
step: 10, loss: 0.00012980858446098864
step: 20, loss: 0.0007020409102551639
step: 30, loss: 0.0005927290767431259
step: 40, loss: 0.0011588077759370208
step: 50, loss: 0.0016902972711250186
step: 60, loss: 8.548099140170962e-05
step: 70, loss: 0.0005415857885964215
step: 80, loss: 0.0009946750942617655
step: 90, loss: 0.001430313102900982
step: 100, loss: 0.00012890117068309337
step: 110, loss: 0.00012165318184997886
step: 120, loss: 0.0001975500927073881
step: 130, loss: 0.00643517542630434
step: 140, loss: 0.00033298207563348114
step: 150, loss: 0.0017248466610908508
step: 160, loss: 7.99672634457238e-05
step: 170, loss: 0.0003081667236983776
step: 180, loss: 0.000650305300951004
step: 190, loss: 8.706554217496887e-05
step: 200, loss: 0.00012128150410717353
step: 210, loss: 0.00015865963359829038
step: 220, loss: 0.0002833608305081725
step: 230, loss: 0.0003438110579736531
step: 240, loss: 9.759476233739406e-05
step: 250, loss: 0.000542895111721009
step: 260, loss: 0.0002198216097895056
step: 270, loss: 0.005969294812530279
step: 280, loss: 0.0007208869792521
step: 290, loss: 0.001402126275934279
step: 300, loss: 0.0005103091825731099
step: 310, loss: 0.0805903971195221
step: 320, loss: 0.000518201501108706
step: 330, loss: 0.0031384970061481
step: 340, loss: 0.03331337124109268
step: 350, loss: 0.0006975302239879966
step: 360, loss: 0.0001577322545927018
step: 370, loss: 0.00016793067334219813
step: 380, loss: 0.00023790109844412655
epoch 17: dev_f1=0.7969543147208122, f1=0.6296296296296295, best_f1=0.6914893617021276
step: 0, loss: 0.00041322046308778226
step: 10, loss: 0.00013424355711322278
step: 20, loss: 0.00013953194138593972
step: 30, loss: 0.013619830831885338
step: 40, loss: 4.982814789400436e-05
step: 50, loss: 0.0030894787050783634
step: 60, loss: 0.0033141854219138622
step: 70, loss: 0.0006126807420514524
step: 80, loss: 0.00010126802226295695
step: 90, loss: 0.0008831751765683293
step: 100, loss: 0.00021219377231318504
step: 110, loss: 0.00014357853797264397
step: 120, loss: 0.0001938322966452688
step: 130, loss: 0.0031332538928836584
step: 140, loss: 0.0006904799374751747
step: 150, loss: 2.444489291519858e-05
step: 160, loss: 0.0290832556784153
step: 170, loss: 0.00041627176688052714
step: 180, loss: 6.403417501132935e-05
step: 190, loss: 9.840878192335367e-05
step: 200, loss: 0.00027071102522313595
step: 210, loss: 0.0022612307220697403
step: 220, loss: 0.0014961735578253865
step: 230, loss: 0.0007982238894328475
step: 240, loss: 0.000207926903385669
step: 250, loss: 0.0006018924177624285
step: 260, loss: 3.8409179978771135e-05
step: 270, loss: 0.009239285252988338
step: 280, loss: 0.000639578327536583
step: 290, loss: 0.000906609755475074
step: 300, loss: 0.00013838423183187842
step: 310, loss: 0.0002861164102796465
step: 320, loss: 0.00017135858070105314
step: 330, loss: 0.0004621846601366997
step: 340, loss: 0.00021580292377620935
step: 350, loss: 0.0004240612906869501
step: 360, loss: 0.00040024175541475415
step: 370, loss: 0.00011535683734109625
step: 380, loss: 0.00012914006947539747
epoch 18: dev_f1=0.8030303030303031, f1=0.6718346253229973, best_f1=0.6914893617021276
step: 0, loss: 6.058134385966696e-05
step: 10, loss: 4.12700064771343e-05
step: 20, loss: 0.0005397857166826725
step: 30, loss: 0.00030697634792886674
step: 40, loss: 0.0002502285351511091
step: 50, loss: 4.725235339719802e-05
step: 60, loss: 5.555000461754389e-05
step: 70, loss: 0.00011817508493550122
step: 80, loss: 7.479377381969243e-05
step: 90, loss: 0.00017916643992066383
step: 100, loss: 0.0028733660001307726
step: 110, loss: 9.550707181915641e-05
step: 120, loss: 0.00032948152511380613
step: 130, loss: 5.8383866416988894e-05
step: 140, loss: 6.31526272627525e-05
step: 150, loss: 0.00034302103449590504
step: 160, loss: 0.0021027009934186935
step: 170, loss: 0.0004086099797859788
step: 180, loss: 4.422287020133808e-05
step: 190, loss: 0.00013061627396382391
step: 200, loss: 0.0013958867639303207
step: 210, loss: 0.0012130573159083724
step: 220, loss: 6.951359682716429e-05
step: 230, loss: 0.0004526591510511935
step: 240, loss: 0.000180615927092731
step: 250, loss: 0.0003114169230684638
step: 260, loss: 0.00012908274948131293
step: 270, loss: 0.00031189460423775017
step: 280, loss: 0.0015611788257956505
step: 290, loss: 0.00016451228293590248
step: 300, loss: 0.00014472957991529256
step: 310, loss: 0.00012376875383779407
step: 320, loss: 0.00036086616455577314
step: 330, loss: 0.00010005271906265989
step: 340, loss: 5.209682058193721e-05
step: 350, loss: 0.03406829014420509
step: 360, loss: 0.00011705312499543652
step: 370, loss: 5.410907760960981e-05
step: 380, loss: 0.0008277228916995227
epoch 19: dev_f1=0.8040712468193384, f1=0.6561679790026247, best_f1=0.6914893617021276
step: 0, loss: 0.002132114488631487
step: 10, loss: 8.583543240092695e-05
step: 20, loss: 0.0010004988871514797
step: 30, loss: 0.002967169741168618
step: 40, loss: 0.0003001375589519739
step: 50, loss: 0.0006026906194165349
step: 60, loss: 0.0001294246467296034
step: 70, loss: 0.0001184930297313258
step: 80, loss: 0.0001234937080880627
step: 90, loss: 0.0002251082769362256
step: 100, loss: 0.00024274081806652248
step: 110, loss: 0.00017391789879184216
step: 120, loss: 0.0008349982090294361
step: 130, loss: 0.00012641612556762993
step: 140, loss: 0.0003193976008333266
step: 150, loss: 0.00020382758521009237
step: 160, loss: 5.4509800975210965e-05
step: 170, loss: 0.0011247587390244007
step: 180, loss: 7.904541416792199e-05
step: 190, loss: 5.292357673170045e-05
step: 200, loss: 3.0337694624904543e-05
step: 210, loss: 0.00011838844511657953
step: 220, loss: 0.00011558583355508745
step: 230, loss: 0.0009672945598140359
step: 240, loss: 9.504970512352884e-05
step: 250, loss: 0.00015844334848225117
step: 260, loss: 0.002672939794138074
step: 270, loss: 0.003006970975548029
step: 280, loss: 5.991521538817324e-05
step: 290, loss: 0.0005573389353230596
step: 300, loss: 5.499833423527889e-05
step: 310, loss: 0.0001375585561618209
step: 320, loss: 4.7708828788017854e-05
step: 330, loss: 0.00011612899106694385
step: 340, loss: 0.000882146880030632
step: 350, loss: 0.0001782551989890635
step: 360, loss: 0.00038027972914278507
step: 370, loss: 3.4281507396372035e-05
step: 380, loss: 0.0022770820651203394
epoch 20: dev_f1=0.8040712468193384, f1=0.6506666666666667, best_f1=0.6914893617021276
