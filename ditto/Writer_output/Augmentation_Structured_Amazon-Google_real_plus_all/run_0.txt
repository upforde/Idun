cuda
Device: cuda
step: 0, loss: 0.9195374250411987
step: 10, loss: 0.38354742527008057
step: 20, loss: 0.4142574667930603
step: 30, loss: 0.23659344017505646
step: 40, loss: 0.14623534679412842
step: 50, loss: 0.371767520904541
step: 60, loss: 0.4724147319793701
step: 70, loss: 0.16136613488197327
step: 80, loss: 0.4121684432029724
step: 90, loss: 0.15077468752861023
step: 100, loss: 0.17439614236354828
step: 110, loss: 0.3238942623138428
step: 120, loss: 0.20937038958072662
step: 130, loss: 0.49515843391418457
step: 140, loss: 0.23783855140209198
step: 150, loss: 0.3524237275123596
step: 160, loss: 0.4584753215312958
step: 170, loss: 0.1429130733013153
step: 180, loss: 0.2847095727920532
step: 190, loss: 0.06653381884098053
step: 200, loss: 0.12685810029506683
step: 210, loss: 0.3546750545501709
step: 220, loss: 0.12788528203964233
step: 230, loss: 0.10873602330684662
step: 240, loss: 0.12765288352966309
step: 250, loss: 0.2518652677536011
step: 260, loss: 0.18197192251682281
step: 270, loss: 0.2839535176753998
step: 280, loss: 0.1573537141084671
step: 290, loss: 0.1554272323846817
step: 300, loss: 0.10877154022455215
step: 310, loss: 0.18595704436302185
step: 320, loss: 0.2249738723039627
step: 330, loss: 0.24964891374111176
step: 340, loss: 0.08935307711362839
step: 350, loss: 0.16237784922122955
step: 360, loss: 0.08781155198812485
step: 370, loss: 0.28071609139442444
step: 380, loss: 0.21858006715774536
step: 390, loss: 0.03593431040644646
step: 400, loss: 0.05480535328388214
step: 410, loss: 0.12195280194282532
step: 420, loss: 0.09153847396373749
epoch 1: dev_f1=0.6107142857142858, f1=0.6073298429319373, best_f1=0.6073298429319373
step: 0, loss: 0.17455090582370758
step: 10, loss: 0.2135831117630005
step: 20, loss: 0.11987007409334183
step: 30, loss: 0.2591343820095062
step: 40, loss: 0.12886647880077362
step: 50, loss: 0.1024264544248581
step: 60, loss: 0.09454174339771271
step: 70, loss: 0.21213938295841217
step: 80, loss: 0.11883583664894104
step: 90, loss: 0.08722107857465744
step: 100, loss: 0.048368047922849655
step: 110, loss: 0.31300103664398193
step: 120, loss: 0.06797781586647034
step: 130, loss: 0.13145053386688232
step: 140, loss: 0.16275881230831146
step: 150, loss: 0.06680815666913986
step: 160, loss: 0.07766003161668777
step: 170, loss: 0.14518685638904572
step: 180, loss: 0.11254755407571793
step: 190, loss: 0.18241511285305023
step: 200, loss: 0.22424471378326416
step: 210, loss: 0.02270931750535965
step: 220, loss: 0.13417477905750275
step: 230, loss: 0.18026162683963776
step: 240, loss: 0.12505385279655457
step: 250, loss: 0.17037364840507507
step: 260, loss: 0.10119293630123138
step: 270, loss: 0.1555757075548172
step: 280, loss: 0.10657257586717606
step: 290, loss: 0.24580807983875275
step: 300, loss: 0.04257126897573471
step: 310, loss: 0.06409267336130142
step: 320, loss: 0.10769973695278168
step: 330, loss: 0.08438874781131744
step: 340, loss: 0.09214899688959122
step: 350, loss: 0.18139497935771942
step: 360, loss: 0.07110844552516937
step: 370, loss: 0.1064641922712326
step: 380, loss: 0.12018166482448578
step: 390, loss: 0.019062919542193413
step: 400, loss: 0.113668292760849
step: 410, loss: 0.08425640314817429
step: 420, loss: 0.05740310624241829
epoch 2: dev_f1=0.686411149825784, f1=0.6773618538324421, best_f1=0.6773618538324421
step: 0, loss: 0.08084112405776978
step: 10, loss: 0.10228235274553299
step: 20, loss: 0.09413012117147446
step: 30, loss: 0.18101470172405243
step: 40, loss: 0.1012386605143547
step: 50, loss: 0.11432646214962006
step: 60, loss: 0.05971114709973335
step: 70, loss: 0.10261902213096619
step: 80, loss: 0.15503036975860596
step: 90, loss: 0.0738520398736
step: 100, loss: 0.04443758353590965
step: 110, loss: 0.0513206422328949
step: 120, loss: 0.07383757084608078
step: 130, loss: 0.25157079100608826
step: 140, loss: 0.1127818375825882
step: 150, loss: 0.14835095405578613
step: 160, loss: 0.022090129554271698
step: 170, loss: 0.11958257108926773
step: 180, loss: 0.09081650525331497
step: 190, loss: 0.1785358339548111
step: 200, loss: 0.2199089080095291
step: 210, loss: 0.07110867649316788
step: 220, loss: 0.1117970421910286
step: 230, loss: 0.23674850165843964
step: 240, loss: 0.042994312942028046
step: 250, loss: 0.12311052531003952
step: 260, loss: 0.2520832121372223
step: 270, loss: 0.061081524938344955
step: 280, loss: 0.11204137653112411
step: 290, loss: 0.07860489189624786
step: 300, loss: 0.12454169988632202
step: 310, loss: 0.16889719665050507
step: 320, loss: 0.09965116530656815
step: 330, loss: 0.20264539122581482
step: 340, loss: 0.16227230429649353
step: 350, loss: 0.04519525170326233
step: 360, loss: 0.06415627151727676
step: 370, loss: 0.17651551961898804
step: 380, loss: 0.025775669142603874
step: 390, loss: 0.10575312376022339
step: 400, loss: 0.10429579019546509
step: 410, loss: 0.046167727559804916
step: 420, loss: 0.13496257364749908
epoch 3: dev_f1=0.6872586872586872, f1=0.6745098039215686, best_f1=0.6745098039215686
step: 0, loss: 0.1500668227672577
step: 10, loss: 0.05574369803071022
step: 20, loss: 0.0928066223859787
step: 30, loss: 0.250428706407547
step: 40, loss: 0.12660443782806396
step: 50, loss: 0.09469028562307358
step: 60, loss: 0.19937662780284882
step: 70, loss: 0.1645636260509491
step: 80, loss: 0.06589631736278534
step: 90, loss: 0.03481229767203331
step: 100, loss: 0.12501703202724457
step: 110, loss: 0.02979794517159462
step: 120, loss: 0.16090252995491028
step: 130, loss: 0.08876539766788483
step: 140, loss: 0.11798419803380966
step: 150, loss: 0.2075442671775818
step: 160, loss: 0.057174116373062134
step: 170, loss: 0.16840629279613495
step: 180, loss: 0.01816217601299286
step: 190, loss: 0.11054951697587967
step: 200, loss: 0.10645583271980286
step: 210, loss: 0.1310219019651413
step: 220, loss: 0.08585697412490845
step: 230, loss: 0.1531890481710434
step: 240, loss: 0.15132443606853485
step: 250, loss: 0.1307692974805832
step: 260, loss: 0.13560529053211212
step: 270, loss: 0.22102077305316925
step: 280, loss: 0.06806784868240356
step: 290, loss: 0.09628397226333618
step: 300, loss: 0.0456831119954586
step: 310, loss: 0.09466822445392609
step: 320, loss: 0.09693360328674316
step: 330, loss: 0.14174316823482513
step: 340, loss: 0.08196379989385605
step: 350, loss: 0.13565514981746674
step: 360, loss: 0.0786360651254654
step: 370, loss: 0.18787690997123718
step: 380, loss: 0.03558364510536194
step: 390, loss: 0.09383317828178406
step: 400, loss: 0.048672955483198166
step: 410, loss: 0.19060581922531128
step: 420, loss: 0.09760291874408722
epoch 4: dev_f1=0.6826758147512864, f1=0.6937394247038917, best_f1=0.6745098039215686
step: 0, loss: 0.10536622256040573
step: 10, loss: 0.18183380365371704
step: 20, loss: 0.004179434385150671
step: 30, loss: 0.05594596639275551
step: 40, loss: 0.09134624898433685
step: 50, loss: 0.06730743497610092
step: 60, loss: 0.09446874260902405
step: 70, loss: 0.09216435998678207
step: 80, loss: 0.18021366000175476
step: 90, loss: 0.10809030383825302
step: 100, loss: 0.17904381453990936
step: 110, loss: 0.09507694095373154
step: 120, loss: 0.05606310814619064
step: 130, loss: 0.10647726058959961
step: 140, loss: 0.1128135472536087
step: 150, loss: 0.20200803875923157
step: 160, loss: 0.08137721568346024
step: 170, loss: 0.1144881397485733
step: 180, loss: 0.03445783257484436
step: 190, loss: 0.02898452617228031
step: 200, loss: 0.03602990880608559
step: 210, loss: 0.029522283002734184
step: 220, loss: 0.13038425147533417
step: 230, loss: 0.01890043169260025
step: 240, loss: 0.07919912040233612
step: 250, loss: 0.13416869938373566
step: 260, loss: 0.11110661923885345
step: 270, loss: 0.05337248370051384
step: 280, loss: 0.04945579916238785
step: 290, loss: 0.10443524271249771
step: 300, loss: 0.09873071312904358
step: 310, loss: 0.07840318232774734
step: 320, loss: 0.21200688183307648
step: 330, loss: 0.1485982984304428
step: 340, loss: 0.143894761800766
step: 350, loss: 0.0600966140627861
step: 360, loss: 0.05461202561855316
step: 370, loss: 0.02254101261496544
step: 380, loss: 0.07114481925964355
step: 390, loss: 0.10568106174468994
step: 400, loss: 0.031444862484931946
step: 410, loss: 0.09314677864313126
step: 420, loss: 0.07420558482408524
epoch 5: dev_f1=0.7074074074074074, f1=0.6464646464646464, best_f1=0.6464646464646464
step: 0, loss: 0.09067012369632721
step: 10, loss: 0.08296244591474533
step: 20, loss: 0.04521050304174423
step: 30, loss: 0.16661106050014496
step: 40, loss: 0.07819066941738129
step: 50, loss: 0.02930506318807602
step: 60, loss: 0.0930805653333664
step: 70, loss: 0.17480586469173431
step: 80, loss: 0.04746429622173309
step: 90, loss: 0.08440428227186203
step: 100, loss: 0.1939341276884079
step: 110, loss: 0.08699692785739899
step: 120, loss: 0.031509049236774445
step: 130, loss: 0.20939669013023376
step: 140, loss: 0.10625535249710083
step: 150, loss: 0.07092616707086563
step: 160, loss: 0.036891236901283264
step: 170, loss: 0.03149877116084099
step: 180, loss: 0.03138188272714615
step: 190, loss: 0.07086209207773209
step: 200, loss: 0.09865843504667282
step: 210, loss: 0.04555152729153633
step: 220, loss: 0.3025270402431488
step: 230, loss: 0.10732952505350113
step: 240, loss: 0.03422838822007179
step: 250, loss: 0.05132943019270897
step: 260, loss: 0.0911632627248764
step: 270, loss: 0.020121188834309578
step: 280, loss: 0.1802774965763092
step: 290, loss: 0.09321096539497375
step: 300, loss: 0.01970772072672844
step: 310, loss: 0.09981844574213028
step: 320, loss: 0.05573725700378418
step: 330, loss: 0.09948984533548355
step: 340, loss: 0.11435844749212265
step: 350, loss: 0.042663078755140305
step: 360, loss: 0.12072736024856567
step: 370, loss: 0.04776337370276451
step: 380, loss: 0.036688100546598434
step: 390, loss: 0.029897024855017662
step: 400, loss: 0.022788742557168007
step: 410, loss: 0.04780472069978714
step: 420, loss: 0.08093810826539993
epoch 6: dev_f1=0.7323943661971831, f1=0.6986301369863015, best_f1=0.6986301369863015
step: 0, loss: 0.1740865856409073
step: 10, loss: 0.1487240344285965
step: 20, loss: 0.12819094955921173
step: 30, loss: 0.00714580062776804
step: 40, loss: 0.057125918567180634
step: 50, loss: 0.16678661108016968
step: 60, loss: 0.12283985316753387
step: 70, loss: 0.10326040536165237
step: 80, loss: 0.029818907380104065
step: 90, loss: 0.2004123032093048
step: 100, loss: 0.10219276696443558
step: 110, loss: 0.1160442903637886
step: 120, loss: 0.13991183042526245
step: 130, loss: 0.07052919268608093
step: 140, loss: 0.0672813206911087
step: 150, loss: 0.2202237844467163
step: 160, loss: 0.14149019122123718
step: 170, loss: 0.07415997982025146
step: 180, loss: 0.10728863626718521
step: 190, loss: 0.0956006795167923
step: 200, loss: 0.059196289628744125
step: 210, loss: 0.19239550828933716
step: 220, loss: 0.09221114218235016
step: 230, loss: 0.0886717438697815
step: 240, loss: 0.14804603159427643
step: 250, loss: 0.09304120391607285
step: 260, loss: 0.05203976482152939
step: 270, loss: 0.08488114178180695
step: 280, loss: 0.03691834211349487
step: 290, loss: 0.10337191075086594
step: 300, loss: 0.10637646168470383
step: 310, loss: 0.13173995912075043
step: 320, loss: 0.051678579300642014
step: 330, loss: 0.2973276674747467
step: 340, loss: 0.08327097445726395
step: 350, loss: 0.05768701806664467
step: 360, loss: 0.0947672426700592
step: 370, loss: 0.08697688579559326
step: 380, loss: 0.044600050896406174
step: 390, loss: 0.06847687065601349
step: 400, loss: 0.16209319233894348
step: 410, loss: 0.17483970522880554
step: 420, loss: 0.07559508830308914
epoch 7: dev_f1=0.7205882352941176, f1=0.7041198501872659, best_f1=0.6986301369863015
step: 0, loss: 0.04431380331516266
step: 10, loss: 0.07111302018165588
step: 20, loss: 0.05701293796300888
step: 30, loss: 0.13279491662979126
step: 40, loss: 0.036060482263565063
step: 50, loss: 0.047116320580244064
step: 60, loss: 0.1304934024810791
step: 70, loss: 0.1336500495672226
step: 80, loss: 0.13049831986427307
step: 90, loss: 0.13939806818962097
step: 100, loss: 0.10570919513702393
step: 110, loss: 0.09699676185846329
step: 120, loss: 0.12176712602376938
step: 130, loss: 0.12674476206302643
step: 140, loss: 0.10076173394918442
step: 150, loss: 0.16967011988162994
step: 160, loss: 0.01783839613199234
step: 170, loss: 0.08874434977769852
step: 180, loss: 0.09270709753036499
step: 190, loss: 0.10213912278413773
step: 200, loss: 0.11394750326871872
step: 210, loss: 0.13767091929912567
step: 220, loss: 0.0833873301744461
step: 230, loss: 0.12874490022659302
step: 240, loss: 0.09028790891170502
step: 250, loss: 0.07089031487703323
step: 260, loss: 0.12701132893562317
step: 270, loss: 0.11686064302921295
step: 280, loss: 0.03988471254706383
step: 290, loss: 0.08774162828922272
step: 300, loss: 0.05017570033669472
step: 310, loss: 0.02841850370168686
step: 320, loss: 0.0763314962387085
step: 330, loss: 0.03849124535918236
step: 340, loss: 0.06641758233308792
step: 350, loss: 0.12453431636095047
step: 360, loss: 0.06274042278528214
step: 370, loss: 0.10093962401151657
step: 380, loss: 0.093996562063694
step: 390, loss: 0.1216711774468422
step: 400, loss: 0.1952148675918579
step: 410, loss: 0.08871271461248398
step: 420, loss: 0.07428091764450073
epoch 8: dev_f1=0.7309833024118738, f1=0.7174721189591078, best_f1=0.6986301369863015
step: 0, loss: 0.042463306337594986
step: 10, loss: 0.16886171698570251
step: 20, loss: 0.034230466932058334
step: 30, loss: 0.08712974190711975
step: 40, loss: 0.0933937355875969
step: 50, loss: 0.09525834023952484
step: 60, loss: 0.038575347512960434
step: 70, loss: 0.08027107268571854
step: 80, loss: 0.0670936331152916
step: 90, loss: 0.07998508960008621
step: 100, loss: 0.07144825905561447
step: 110, loss: 0.09876929223537445
step: 120, loss: 0.11155789345502853
step: 130, loss: 0.02279806323349476
step: 140, loss: 0.06897487491369247
step: 150, loss: 0.09730259329080582
step: 160, loss: 0.15350738167762756
step: 170, loss: 0.11843089759349823
step: 180, loss: 0.09220012277364731
step: 190, loss: 0.03560202568769455
step: 200, loss: 0.06946511566638947
step: 210, loss: 0.03194066137075424
step: 220, loss: 0.04203403741121292
step: 230, loss: 0.15766571462154388
step: 240, loss: 0.0034496395383030176
step: 250, loss: 0.05890722945332527
step: 260, loss: 0.05380750820040703
step: 270, loss: 0.09238167107105255
step: 280, loss: 0.08885648101568222
step: 290, loss: 0.17394860088825226
step: 300, loss: 0.06035419553518295
step: 310, loss: 0.078884556889534
step: 320, loss: 0.10793055593967438
step: 330, loss: 0.008683966472744942
step: 340, loss: 0.10291611403226852
step: 350, loss: 0.025496765971183777
step: 360, loss: 0.1369934231042862
step: 370, loss: 0.07265646755695343
step: 380, loss: 0.0706530511379242
step: 390, loss: 0.0737193152308464
step: 400, loss: 0.11618141829967499
step: 410, loss: 0.06326015293598175
step: 420, loss: 0.06610473990440369
epoch 9: dev_f1=0.7145421903052064, f1=0.6994535519125683, best_f1=0.6986301369863015
step: 0, loss: 0.09603572636842728
step: 10, loss: 0.050978560000658035
step: 20, loss: 0.08614154905080795
step: 30, loss: 0.10974156856536865
step: 40, loss: 0.09484102576971054
step: 50, loss: 0.1310623586177826
step: 60, loss: 0.06737517565488815
step: 70, loss: 0.11848761886358261
step: 80, loss: 0.0466127023100853
step: 90, loss: 0.0007601271499879658
step: 100, loss: 0.06757508218288422
step: 110, loss: 0.09416323900222778
step: 120, loss: 0.09953790158033371
step: 130, loss: 0.08454223722219467
step: 140, loss: 0.07544786483049393
step: 150, loss: 0.027527444064617157
step: 160, loss: 0.13744153082370758
step: 170, loss: 0.11433223634958267
step: 180, loss: 0.035015933215618134
step: 190, loss: 0.15200531482696533
step: 200, loss: 0.08329017460346222
step: 210, loss: 0.0781560018658638
step: 220, loss: 0.10337653011083603
step: 230, loss: 0.15751957893371582
step: 240, loss: 0.036043912172317505
step: 250, loss: 0.11544306576251984
step: 260, loss: 0.030351130291819572
step: 270, loss: 0.07868088781833649
step: 280, loss: 0.034293871372938156
step: 290, loss: 0.03650401532649994
step: 300, loss: 0.024340098723769188
step: 310, loss: 0.0821985974907875
step: 320, loss: 0.036159783601760864
step: 330, loss: 0.15736086666584015
step: 340, loss: 0.04803258925676346
step: 350, loss: 0.09086385369300842
step: 360, loss: 0.07925548404455185
step: 370, loss: 0.12500298023223877
step: 380, loss: 0.055659737437963486
step: 390, loss: 0.1444711983203888
step: 400, loss: 0.1934572458267212
step: 410, loss: 0.04421135410666466
step: 420, loss: 0.1440393626689911
epoch 10: dev_f1=0.7224334600760457, f1=0.69140625, best_f1=0.6986301369863015
step: 0, loss: 0.14305707812309265
step: 10, loss: 0.03523927181959152
step: 20, loss: 0.11800068616867065
step: 30, loss: 0.019846174865961075
step: 40, loss: 0.1818608194589615
step: 50, loss: 0.09291758388280869
step: 60, loss: 0.056273289024829865
step: 70, loss: 0.07770885527133942
step: 80, loss: 0.032849378883838654
step: 90, loss: 0.12762108445167542
step: 100, loss: 0.07990942150354385
step: 110, loss: 0.05173402652144432
step: 120, loss: 0.02240675501525402
step: 130, loss: 0.02870183065533638
step: 140, loss: 0.06786134093999863
step: 150, loss: 0.054407864809036255
step: 160, loss: 0.18834584951400757
step: 170, loss: 0.07481569796800613
step: 180, loss: 0.029582232236862183
step: 190, loss: 0.17165270447731018
step: 200, loss: 0.13238494098186493
step: 210, loss: 0.14358985424041748
step: 220, loss: 0.05477051064372063
step: 230, loss: 0.03478957712650299
step: 240, loss: 0.08641571551561356
step: 250, loss: 0.05542811006307602
step: 260, loss: 0.12266680598258972
step: 270, loss: 0.156027153134346
step: 280, loss: 0.04492993280291557
step: 290, loss: 0.029676681384444237
step: 300, loss: 0.13517065346240997
step: 310, loss: 0.05861659348011017
step: 320, loss: 0.047892022877931595
step: 330, loss: 0.09932689368724823
step: 340, loss: 0.04453369602560997
step: 350, loss: 0.05056196451187134
step: 360, loss: 0.14010170102119446
step: 370, loss: 0.05543339252471924
step: 380, loss: 0.13254527747631073
step: 390, loss: 0.06338697671890259
step: 400, loss: 0.11646880209445953
step: 410, loss: 0.04966849833726883
step: 420, loss: 0.04435098543763161
epoch 11: dev_f1=0.7197106690777577, f1=0.7161410018552876, best_f1=0.6986301369863015
step: 0, loss: 0.02788814716041088
step: 10, loss: 0.11826125532388687
step: 20, loss: 0.03279762342572212
step: 30, loss: 0.10147327184677124
step: 40, loss: 0.015768982470035553
step: 50, loss: 0.07354488223791122
step: 60, loss: 0.09891931712627411
step: 70, loss: 0.07678759843111038
step: 80, loss: 0.026053784415125847
step: 90, loss: 0.03411944583058357
step: 100, loss: 0.025001326575875282
step: 110, loss: 0.060428135097026825
step: 120, loss: 0.11903249472379684
step: 130, loss: 0.03833149001002312
step: 140, loss: 0.03773046284914017
step: 150, loss: 0.10153227299451828
step: 160, loss: 0.12110050022602081
step: 170, loss: 0.07729487866163254
step: 180, loss: 0.07299282401800156
step: 190, loss: 0.11306752264499664
step: 200, loss: 0.04037408530712128
step: 210, loss: 0.10450528562068939
step: 220, loss: 0.10303802788257599
step: 230, loss: 0.025963151827454567
step: 240, loss: 0.05144277215003967
step: 250, loss: 0.09270650893449783
step: 260, loss: 0.08148887753486633
step: 270, loss: 0.0809086486697197
step: 280, loss: 0.10869954526424408
step: 290, loss: 0.0837143212556839
step: 300, loss: 0.0983351543545723
step: 310, loss: 0.09293709695339203
step: 320, loss: 0.008842035196721554
step: 330, loss: 0.04571976140141487
step: 340, loss: 0.0005189258372411132
step: 350, loss: 0.08081256598234177
step: 360, loss: 0.05308113619685173
step: 370, loss: 0.1474614292383194
step: 380, loss: 0.04754813760519028
step: 390, loss: 0.05947253480553627
step: 400, loss: 0.032936327159404755
step: 410, loss: 0.056604351848363876
step: 420, loss: 0.05838801711797714
epoch 12: dev_f1=0.7183098591549295, f1=0.7107142857142857, best_f1=0.6986301369863015
step: 0, loss: 0.10054633021354675
step: 10, loss: 0.09289393573999405
step: 20, loss: 0.12453249096870422
step: 30, loss: 0.01867631822824478
step: 40, loss: 0.02855704165995121
step: 50, loss: 0.11005383729934692
step: 60, loss: 0.13017255067825317
step: 70, loss: 0.08187780529260635
step: 80, loss: 0.07297290116548538
step: 90, loss: 0.045425113290548325
step: 100, loss: 0.1344340592622757
step: 110, loss: 0.031914155930280685
step: 120, loss: 0.05607205256819725
step: 130, loss: 0.05015278980135918
step: 140, loss: 0.0372498482465744
step: 150, loss: 0.11274610459804535
step: 160, loss: 0.05101843550801277
step: 170, loss: 0.013215060345828533
step: 180, loss: 0.038720112293958664
step: 190, loss: 0.16270479559898376
step: 200, loss: 0.015074314549565315
step: 210, loss: 0.05094882473349571
step: 220, loss: 0.1500258445739746
step: 230, loss: 0.06184950843453407
step: 240, loss: 0.052041906863451004
step: 250, loss: 0.09763067960739136
step: 260, loss: 0.005095312837511301
step: 270, loss: 0.029253466054797173
step: 280, loss: 0.0010543341049924493
step: 290, loss: 0.06554962694644928
step: 300, loss: 0.0606546513736248
step: 310, loss: 0.15307694673538208
step: 320, loss: 0.23591545224189758
step: 330, loss: 0.04193292558193207
step: 340, loss: 0.021365154534578323
step: 350, loss: 0.12918682396411896
step: 360, loss: 0.07475022226572037
step: 370, loss: 0.1940382868051529
step: 380, loss: 0.05389803647994995
step: 390, loss: 0.11662355065345764
step: 400, loss: 0.12112191319465637
step: 410, loss: 0.023865683004260063
step: 420, loss: 0.09527137875556946
epoch 13: dev_f1=0.7269372693726938, f1=0.7178502879078695, best_f1=0.6986301369863015
step: 0, loss: 0.036944977939128876
step: 10, loss: 0.06180617958307266
step: 20, loss: 0.07171622663736343
step: 30, loss: 0.06824221462011337
step: 40, loss: 0.09437771886587143
step: 50, loss: 0.006840994115918875
step: 60, loss: 0.06755947321653366
step: 70, loss: 0.05341130122542381
step: 80, loss: 0.057577889412641525
step: 90, loss: 0.046661123633384705
step: 100, loss: 0.11208653450012207
step: 110, loss: 0.0789802297949791
step: 120, loss: 0.03377877548336983
step: 130, loss: 0.184291273355484
step: 140, loss: 0.05260567367076874
step: 150, loss: 0.13306023180484772
step: 160, loss: 0.08984313160181046
step: 170, loss: 0.11782924085855484
step: 180, loss: 0.10623865574598312
step: 190, loss: 0.01655971072614193
step: 200, loss: 0.11256256699562073
step: 210, loss: 0.07233884185552597
step: 220, loss: 0.12254167348146439
step: 230, loss: 0.00014545013254974037
step: 240, loss: 0.07394791394472122
step: 250, loss: 0.04266968369483948
step: 260, loss: 0.1338106393814087
step: 270, loss: 0.006071378942579031
step: 280, loss: 0.07847407460212708
step: 290, loss: 0.10179882496595383
step: 300, loss: 0.2251904457807541
step: 310, loss: 0.058280907571315765
step: 320, loss: 0.05584486946463585
step: 330, loss: 0.04407176747918129
step: 340, loss: 0.09537285566329956
step: 350, loss: 0.051433663815259933
step: 360, loss: 0.1145719513297081
step: 370, loss: 0.09935766458511353
step: 380, loss: 0.14992350339889526
step: 390, loss: 0.19846674799919128
step: 400, loss: 0.0668000802397728
step: 410, loss: 0.057417310774326324
step: 420, loss: 0.05073520913720131
epoch 14: dev_f1=0.7180451127819548, f1=0.7086614173228346, best_f1=0.6986301369863015
step: 0, loss: 0.047193266451358795
step: 10, loss: 0.09571263939142227
step: 20, loss: 0.08646371960639954
step: 30, loss: 0.03181608021259308
step: 40, loss: 0.058831606060266495
step: 50, loss: 0.014900180511176586
step: 60, loss: 0.029326166957616806
step: 70, loss: 0.03968926891684532
step: 80, loss: 0.002251541707664728
step: 90, loss: 0.06865963339805603
step: 100, loss: 0.11326567083597183
step: 110, loss: 0.10760638862848282
step: 120, loss: 0.16736309230327606
step: 130, loss: 0.12247250229120255
step: 140, loss: 0.03193262219429016
step: 150, loss: 0.058413662016391754
step: 160, loss: 0.05304870009422302
step: 170, loss: 0.07241176068782806
step: 180, loss: 0.006977657321840525
step: 190, loss: 0.07344668358564377
step: 200, loss: 0.05042741075158119
step: 210, loss: 0.08314388245344162
step: 220, loss: 0.047632887959480286
step: 230, loss: 0.09270189702510834
step: 240, loss: 0.16832004487514496
step: 250, loss: 0.013929366134107113
step: 260, loss: 0.03116452880203724
step: 270, loss: 0.18070362508296967
step: 280, loss: 0.008003488183021545
step: 290, loss: 0.022297879680991173
step: 300, loss: 0.09757961332798004
step: 310, loss: 0.003974799532443285
step: 320, loss: 0.11859088391065598
step: 330, loss: 0.1591683179140091
step: 340, loss: 0.11429114639759064
step: 350, loss: 0.08831734955310822
step: 360, loss: 0.07347985357046127
step: 370, loss: 0.013387794606387615
step: 380, loss: 0.04665311425924301
step: 390, loss: 0.1340833455324173
step: 400, loss: 0.009071742184460163
step: 410, loss: 0.13940756022930145
step: 420, loss: 0.08106563985347748
epoch 15: dev_f1=0.7215686274509804, f1=0.6920000000000001, best_f1=0.6986301369863015
step: 0, loss: 0.07577799260616302
step: 10, loss: 0.04113156348466873
step: 20, loss: 0.03410476818680763
step: 30, loss: 0.028685063123703003
step: 40, loss: 0.07859207689762115
step: 50, loss: 0.10820317268371582
step: 60, loss: 0.043784573674201965
step: 70, loss: 0.08554847538471222
step: 80, loss: 0.04300948977470398
step: 90, loss: 0.14423461258411407
step: 100, loss: 0.06454123556613922
step: 110, loss: 0.02325260639190674
step: 120, loss: 0.06206599250435829
step: 130, loss: 0.14163832366466522
step: 140, loss: 0.032367534935474396
step: 150, loss: 0.06751218438148499
step: 160, loss: 0.09162348508834839
step: 170, loss: 0.047131121158599854
step: 180, loss: 0.00965421088039875
step: 190, loss: 0.11280304193496704
step: 200, loss: 0.04006465896964073
step: 210, loss: 0.06887955963611603
step: 220, loss: 0.0739600658416748
step: 230, loss: 0.09360065311193466
step: 240, loss: 0.03744116425514221
step: 250, loss: 0.02864779345691204
step: 260, loss: 0.022670598700642586
step: 270, loss: 0.15483424067497253
step: 280, loss: 0.013726220466196537
step: 290, loss: 0.09817633777856827
step: 300, loss: 0.027350062504410744
step: 310, loss: 0.05859401077032089
step: 320, loss: 0.08038024604320526
step: 330, loss: 0.04226416349411011
step: 340, loss: 0.061869386583566666
step: 350, loss: 0.061753854155540466
step: 360, loss: 0.05129091814160347
step: 370, loss: 0.08814579993486404
step: 380, loss: 0.07699386775493622
step: 390, loss: 0.0866173505783081
step: 400, loss: 0.05108678340911865
step: 410, loss: 0.0031739016994833946
step: 420, loss: 0.022540628910064697
epoch 16: dev_f1=0.719851576994434, f1=0.6899224806201552, best_f1=0.6986301369863015
step: 0, loss: 0.13819287717342377
step: 10, loss: 0.08618990331888199
step: 20, loss: 0.11037053167819977
step: 30, loss: 0.042820043861866
step: 40, loss: 0.04002583026885986
step: 50, loss: 0.06694965809583664
step: 60, loss: 0.04828532785177231
step: 70, loss: 0.09050151705741882
step: 80, loss: 0.010922805406153202
step: 90, loss: 0.0768047422170639
step: 100, loss: 0.07632976025342941
step: 110, loss: 0.02472931519150734
step: 120, loss: 0.09106514602899551
step: 130, loss: 0.04067370668053627
step: 140, loss: 4.808951780432835e-05
step: 150, loss: 0.06059859320521355
step: 160, loss: 0.04976191371679306
step: 170, loss: 0.034003227949142456
step: 180, loss: 0.061489272862672806
step: 190, loss: 0.03724616765975952
step: 200, loss: 0.030237052589654922
step: 210, loss: 0.1388622522354126
step: 220, loss: 0.01908314786851406
step: 230, loss: 0.07994774729013443
step: 240, loss: 0.06392164528369904
step: 250, loss: 0.03500141575932503
step: 260, loss: 0.10882862657308578
step: 270, loss: 0.030538078397512436
step: 280, loss: 0.0217521283775568
step: 290, loss: 0.06741335242986679
step: 300, loss: 0.042430080473423004
step: 310, loss: 0.016744667664170265
step: 320, loss: 0.004733751527965069
step: 330, loss: 0.02863769792020321
step: 340, loss: 0.006747807841747999
step: 350, loss: 0.05847032368183136
step: 360, loss: 0.06166927516460419
step: 370, loss: 0.021943621337413788
step: 380, loss: 0.022251654416322708
step: 390, loss: 0.04182429984211922
step: 400, loss: 0.0847674310207367
step: 410, loss: 0.1530352234840393
step: 420, loss: 0.08725373446941376
epoch 17: dev_f1=0.7212475633528266, f1=0.7008196721311475, best_f1=0.6986301369863015
step: 0, loss: 0.06503629684448242
step: 10, loss: 0.07760239392518997
step: 20, loss: 0.0023965551517903805
step: 30, loss: 0.06223633885383606
step: 40, loss: 0.003417776897549629
step: 50, loss: 0.017848439514636993
step: 60, loss: 0.013345970772206783
step: 70, loss: 0.06792446970939636
step: 80, loss: 0.0725458562374115
step: 90, loss: 0.03953009843826294
step: 100, loss: 0.10074874013662338
step: 110, loss: 0.12641356885433197
step: 120, loss: 0.014084314927458763
step: 130, loss: 0.056861501187086105
step: 140, loss: 0.05053061619400978
step: 150, loss: 0.04377071186900139
step: 160, loss: 0.008867033757269382
step: 170, loss: 0.07514273375272751
step: 180, loss: 0.03609856218099594
step: 190, loss: 0.03919666260480881
step: 200, loss: 0.14193661510944366
step: 210, loss: 0.0721745491027832
step: 220, loss: 0.025352034717798233
step: 230, loss: 0.09365177154541016
step: 240, loss: 0.05280851572751999
step: 250, loss: 0.07264626771211624
step: 260, loss: 0.027112646028399467
step: 270, loss: 0.13669659197330475
step: 280, loss: 0.09732504189014435
step: 290, loss: 0.07345052808523178
step: 300, loss: 0.0320502445101738
step: 310, loss: 2.306282658537384e-05
step: 320, loss: 0.0013670993503183126
step: 330, loss: 0.034760236740112305
step: 340, loss: 0.036679234355688095
step: 350, loss: 0.08845008164644241
step: 360, loss: 0.15049076080322266
step: 370, loss: 0.03384308144450188
step: 380, loss: 0.07590830326080322
step: 390, loss: 0.010871993377804756
step: 400, loss: 0.00015783272101543844
step: 410, loss: 0.034691061824560165
step: 420, loss: 0.03948872163891792
epoch 18: dev_f1=0.7122153209109731, f1=0.6956521739130435, best_f1=0.6986301369863015
step: 0, loss: 0.019626948982477188
step: 10, loss: 0.05196298286318779
step: 20, loss: 0.038060061633586884
step: 30, loss: 0.04681278020143509
step: 40, loss: 0.048969537019729614
step: 50, loss: 0.09681854397058487
step: 60, loss: 0.0855627954006195
step: 70, loss: 0.10636968910694122
step: 80, loss: 0.14873236417770386
step: 90, loss: 0.044324327260255814
step: 100, loss: 0.028775393962860107
step: 110, loss: 0.05774344876408577
step: 120, loss: 0.038078490644693375
step: 130, loss: 4.659463229472749e-05
step: 140, loss: 0.02123819850385189
step: 150, loss: 0.03269375488162041
step: 160, loss: 0.1404404193162918
step: 170, loss: 0.046943046152591705
step: 180, loss: 0.07119938731193542
step: 190, loss: 0.08794356882572174
step: 200, loss: 0.014049015007913113
step: 210, loss: 0.056563593447208405
step: 220, loss: 0.06501520425081253
step: 230, loss: 0.020702097564935684
step: 240, loss: 0.03072558343410492
step: 250, loss: 0.0866924524307251
step: 260, loss: 0.022869516164064407
step: 270, loss: 0.07321934401988983
step: 280, loss: 0.02269626595079899
step: 290, loss: 0.12199810147285461
step: 300, loss: 0.07172637432813644
step: 310, loss: 0.0683995708823204
step: 320, loss: 0.07083792239427567
step: 330, loss: 0.04007907211780548
step: 340, loss: 0.016811737790703773
step: 350, loss: 0.06860079616308212
step: 360, loss: 0.04247841611504555
step: 370, loss: 0.23206160962581635
step: 380, loss: 0.0007717743865214288
step: 390, loss: 0.09066684544086456
step: 400, loss: 0.06897234916687012
step: 410, loss: 0.02523065358400345
step: 420, loss: 0.08247777819633484
epoch 19: dev_f1=0.7104722792607804, f1=0.7021276595744681, best_f1=0.6986301369863015
step: 0, loss: 0.07282748073339462
step: 10, loss: 0.07923649996519089
step: 20, loss: 0.07311820983886719
step: 30, loss: 4.968669236404821e-05
step: 40, loss: 0.07999315112829208
step: 50, loss: 0.02231708914041519
step: 60, loss: 0.03715893253684044
step: 70, loss: 0.012700938619673252
step: 80, loss: 0.06760930269956589
step: 90, loss: 0.05053699016571045
step: 100, loss: 0.03424694761633873
step: 110, loss: 0.027628516778349876
step: 120, loss: 0.017137274146080017
step: 130, loss: 0.06892619282007217
step: 140, loss: 0.09427457302808762
step: 150, loss: 0.006593714002519846
step: 160, loss: 0.04934839531779289
step: 170, loss: 0.03738951310515404
step: 180, loss: 0.027223750948905945
step: 190, loss: 0.0022667867597192526
step: 200, loss: 0.09817475080490112
step: 210, loss: 0.06832317262887955
step: 220, loss: 0.07713668793439865
step: 230, loss: 0.04383450001478195
step: 240, loss: 0.09705853462219238
step: 250, loss: 0.028816118836402893
step: 260, loss: 0.06386491656303406
step: 270, loss: 4.544059629552066e-05
step: 280, loss: 0.018165348097682
step: 290, loss: 0.01749708503484726
step: 300, loss: 0.07244308292865753
step: 310, loss: 0.1374855935573578
step: 320, loss: 0.053720321506261826
step: 330, loss: 0.07393062114715576
step: 340, loss: 0.063822440803051
step: 350, loss: 0.07451556622982025
step: 360, loss: 0.13846248388290405
step: 370, loss: 0.06522887945175171
step: 380, loss: 0.04749125614762306
step: 390, loss: 0.04056260734796524
step: 400, loss: 0.057610440999269485
step: 410, loss: 0.014007782563567162
step: 420, loss: 0.09077341854572296
epoch 20: dev_f1=0.7076271186440679, f1=0.7019867549668874, best_f1=0.6986301369863015
