cuda
Device: cuda
step: 0, loss: 0.5918594598770142
step: 10, loss: 0.2586168348789215
step: 20, loss: 0.3762897551059723
step: 30, loss: 0.18759861588478088
step: 40, loss: 0.5072988271713257
step: 50, loss: 0.11657492071390152
step: 60, loss: 0.11697675287723541
step: 70, loss: 0.1386011391878128
step: 80, loss: 0.3318207859992981
step: 90, loss: 0.19321997463703156
step: 100, loss: 0.3783905804157257
step: 110, loss: 0.2498609870672226
step: 120, loss: 0.3533632755279541
step: 130, loss: 0.17421691119670868
step: 140, loss: 0.041242215782403946
step: 150, loss: 0.14790041744709015
step: 160, loss: 0.02593202143907547
step: 170, loss: 0.12096188962459564
step: 180, loss: 0.021003298461437225
step: 190, loss: 0.0674637109041214
step: 200, loss: 0.3340330719947815
step: 210, loss: 0.30900371074676514
step: 220, loss: 0.32086360454559326
step: 230, loss: 0.1446031779050827
step: 240, loss: 0.2701178193092346
step: 250, loss: 0.17956072092056274
step: 260, loss: 0.14203371107578278
step: 270, loss: 0.14642439782619476
step: 280, loss: 0.20803530514240265
step: 290, loss: 0.16255968809127808
step: 300, loss: 0.19561977684497833
step: 310, loss: 0.07518279552459717
step: 320, loss: 0.2387470304965973
step: 330, loss: 0.04715973138809204
step: 340, loss: 0.1474284827709198
step: 350, loss: 0.07840244472026825
step: 360, loss: 0.14015376567840576
step: 370, loss: 0.06869286298751831
step: 380, loss: 0.0693468227982521
step: 390, loss: 0.0680893212556839
step: 400, loss: 0.13127607107162476
step: 410, loss: 0.2295088917016983
step: 420, loss: 0.07902602106332779
epoch 1: dev_f1=0.6363636363636364, f1=0.6562500000000001, best_f1=0.6562500000000001
step: 0, loss: 0.268178790807724
step: 10, loss: 0.13327057659626007
step: 20, loss: 0.09044363349676132
step: 30, loss: 0.055973075330257416
step: 40, loss: 0.05111739784479141
step: 50, loss: 0.13128142058849335
step: 60, loss: 0.17604929208755493
step: 70, loss: 0.13848747313022614
step: 80, loss: 0.06277115643024445
step: 90, loss: 0.12832674384117126
step: 100, loss: 0.1846441924571991
step: 110, loss: 0.12457311153411865
step: 120, loss: 0.06602075695991516
step: 130, loss: 0.10563275218009949
step: 140, loss: 0.3228304982185364
step: 150, loss: 0.07285100221633911
step: 160, loss: 0.15129992365837097
step: 170, loss: 0.06933051347732544
step: 180, loss: 0.02409067377448082
step: 190, loss: 0.14868289232254028
step: 200, loss: 0.12801653146743774
step: 210, loss: 0.1679830253124237
step: 220, loss: 0.17878574132919312
step: 230, loss: 0.13790501654148102
step: 240, loss: 0.13174942135810852
step: 250, loss: 0.14206138253211975
step: 260, loss: 0.20064103603363037
step: 270, loss: 0.15500953793525696
step: 280, loss: 0.09882091730833054
step: 290, loss: 0.14357274770736694
step: 300, loss: 0.09874559193849564
step: 310, loss: 0.0450495108962059
step: 320, loss: 0.05897046998143196
step: 330, loss: 0.11011090874671936
step: 340, loss: 0.11442553251981735
step: 350, loss: 0.08473071455955505
step: 360, loss: 0.09264906495809555
step: 370, loss: 0.06265918910503387
step: 380, loss: 0.2374183088541031
step: 390, loss: 0.15992087125778198
step: 400, loss: 0.09085094183683395
step: 410, loss: 0.10630115866661072
step: 420, loss: 0.09270544350147247
epoch 2: dev_f1=0.6903765690376569, f1=0.6735537190082646, best_f1=0.6735537190082646
step: 0, loss: 0.10548898577690125
step: 10, loss: 0.040670134127140045
step: 20, loss: 0.12419889867305756
step: 30, loss: 0.10599764436483383
step: 40, loss: 0.1877654790878296
step: 50, loss: 0.05062112212181091
step: 60, loss: 0.14965789020061493
step: 70, loss: 0.06954103708267212
step: 80, loss: 0.1837846040725708
step: 90, loss: 0.031090201810002327
step: 100, loss: 0.07521696388721466
step: 110, loss: 0.1633249819278717
step: 120, loss: 0.1294194608926773
step: 130, loss: 0.14322128891944885
step: 140, loss: 0.0955277755856514
step: 150, loss: 0.16039706766605377
step: 160, loss: 0.10405689477920532
step: 170, loss: 0.2177041918039322
step: 180, loss: 0.05361206457018852
step: 190, loss: 0.106510229408741
step: 200, loss: 0.03492898494005203
step: 210, loss: 0.08674736320972443
step: 220, loss: 0.10089018940925598
step: 230, loss: 0.08953218907117844
step: 240, loss: 0.020305419340729713
step: 250, loss: 0.07723677158355713
step: 260, loss: 0.2670626938343048
step: 270, loss: 0.04927677661180496
step: 280, loss: 0.11424906551837921
step: 290, loss: 0.14651404321193695
step: 300, loss: 0.16964790225028992
step: 310, loss: 0.1704583466053009
step: 320, loss: 0.12972019612789154
step: 330, loss: 0.09343761205673218
step: 340, loss: 0.25148439407348633
step: 350, loss: 0.12063538283109665
step: 360, loss: 0.022544099017977715
step: 370, loss: 0.05351988598704338
step: 380, loss: 0.13848784565925598
step: 390, loss: 0.1765841543674469
step: 400, loss: 0.2073594033718109
step: 410, loss: 0.11073209345340729
step: 420, loss: 0.10212154686450958
epoch 3: dev_f1=0.7303370786516855, f1=0.7134724857685009, best_f1=0.7134724857685009
step: 0, loss: 0.12255054712295532
step: 10, loss: 0.19972796738147736
step: 20, loss: 0.03315358608961105
step: 30, loss: 0.13165168464183807
step: 40, loss: 0.12250641733407974
step: 50, loss: 0.14999136328697205
step: 60, loss: 0.11503762006759644
step: 70, loss: 0.14461788535118103
step: 80, loss: 0.12982632219791412
step: 90, loss: 0.07920484244823456
step: 100, loss: 0.09431865811347961
step: 110, loss: 0.0578390434384346
step: 120, loss: 0.09277267009019852
step: 130, loss: 0.04723555967211723
step: 140, loss: 0.1769189089536667
step: 150, loss: 0.17432257533073425
step: 160, loss: 0.190372034907341
step: 170, loss: 0.021092750132083893
step: 180, loss: 0.061987023800611496
step: 190, loss: 0.06836839020252228
step: 200, loss: 0.0990782156586647
step: 210, loss: 0.1604565531015396
step: 220, loss: 0.05920669808983803
step: 230, loss: 0.15727688372135162
step: 240, loss: 0.09974944591522217
step: 250, loss: 0.048739850521087646
step: 260, loss: 0.0414101779460907
step: 270, loss: 0.06576548516750336
step: 280, loss: 0.04745766520500183
step: 290, loss: 0.047237690538167953
step: 300, loss: 0.07835321128368378
step: 310, loss: 0.15297016501426697
step: 320, loss: 0.21486665308475494
step: 330, loss: 0.10142491012811661
step: 340, loss: 0.22277499735355377
step: 350, loss: 0.159316286444664
step: 360, loss: 0.14973029494285583
step: 370, loss: 0.18744207918643951
step: 380, loss: 0.14738094806671143
step: 390, loss: 0.11647608131170273
step: 400, loss: 0.04779154807329178
step: 410, loss: 0.11536486446857452
step: 420, loss: 0.116999551653862
epoch 4: dev_f1=0.6937901498929335, f1=0.6637931034482758, best_f1=0.7134724857685009
step: 0, loss: 0.05757446587085724
step: 10, loss: 0.04753654822707176
step: 20, loss: 0.18602493405342102
step: 30, loss: 0.09905295073986053
step: 40, loss: 0.10343893617391586
step: 50, loss: 0.07799993455410004
step: 60, loss: 0.00017749967810232192
step: 70, loss: 0.10259377956390381
step: 80, loss: 0.049255043268203735
step: 90, loss: 0.11248914897441864
step: 100, loss: 0.08536592125892639
step: 110, loss: 0.13235710561275482
step: 120, loss: 0.1496257483959198
step: 130, loss: 0.15606147050857544
step: 140, loss: 0.17638397216796875
step: 150, loss: 0.030759278684854507
step: 160, loss: 0.09246449172496796
step: 170, loss: 0.07914932817220688
step: 180, loss: 0.14712592959403992
step: 190, loss: 0.0555204413831234
step: 200, loss: 0.06896420568227768
step: 210, loss: 0.05167683586478233
step: 220, loss: 0.21485494077205658
step: 230, loss: 0.12330430001020432
step: 240, loss: 0.0476490743458271
step: 250, loss: 0.0584469698369503
step: 260, loss: 0.054044876247644424
step: 270, loss: 0.08029909431934357
step: 280, loss: 0.10609810799360275
step: 290, loss: 0.1391196846961975
step: 300, loss: 0.16917330026626587
step: 310, loss: 0.12900638580322266
step: 320, loss: 0.033771075308322906
step: 330, loss: 0.16917558014392853
step: 340, loss: 0.11894512921571732
step: 350, loss: 0.08922559767961502
step: 360, loss: 0.2340761423110962
step: 370, loss: 0.09827370196580887
step: 380, loss: 0.09389958530664444
step: 390, loss: 0.13040733337402344
step: 400, loss: 0.050373438745737076
step: 410, loss: 0.1659287065267563
step: 420, loss: 0.06087726727128029
epoch 5: dev_f1=0.6939571150097466, f1=0.6679841897233202, best_f1=0.7134724857685009
step: 0, loss: 0.08972442150115967
step: 10, loss: 0.05687335506081581
step: 20, loss: 0.0772598460316658
step: 30, loss: 0.12039858102798462
step: 40, loss: 0.1084475964307785
step: 50, loss: 0.02329183742403984
step: 60, loss: 0.09316644817590714
step: 70, loss: 0.09648320078849792
step: 80, loss: 0.11868972331285477
step: 90, loss: 0.07041876018047333
step: 100, loss: 0.04516105353832245
step: 110, loss: 0.07708965241909027
step: 120, loss: 0.04024844989180565
step: 130, loss: 0.05019485950469971
step: 140, loss: 0.025754543021321297
step: 150, loss: 0.0556611604988575
step: 160, loss: 0.06995372474193573
step: 170, loss: 0.16288074851036072
step: 180, loss: 0.10436535626649857
step: 190, loss: 0.04785677045583725
step: 200, loss: 0.03309263661503792
step: 210, loss: 0.0032772673293948174
step: 220, loss: 0.12015088647603989
step: 230, loss: 0.05962929502129555
step: 240, loss: 0.09521114081144333
step: 250, loss: 0.06626833975315094
step: 260, loss: 0.04971039295196533
step: 270, loss: 0.11533878743648529
step: 280, loss: 0.09470704942941666
step: 290, loss: 0.09535655379295349
step: 300, loss: 0.07856858521699905
step: 310, loss: 0.13302066922187805
step: 320, loss: 0.08992379158735275
step: 330, loss: 0.10421639680862427
step: 340, loss: 0.038296282291412354
step: 350, loss: 0.025812903419137
step: 360, loss: 0.06061619892716408
step: 370, loss: 0.09826638549566269
step: 380, loss: 0.27697381377220154
step: 390, loss: 0.08151189237833023
step: 400, loss: 0.07069738209247589
step: 410, loss: 0.02966272458434105
step: 420, loss: 0.06360533833503723
epoch 6: dev_f1=0.7123809523809524, f1=0.7015503875968991, best_f1=0.7134724857685009
step: 0, loss: 0.08551271259784698
step: 10, loss: 0.0035847234539687634
step: 20, loss: 0.09090234339237213
step: 30, loss: 0.2830120027065277
step: 40, loss: 0.10165109485387802
step: 50, loss: 0.015037811361253262
step: 60, loss: 0.030555671080946922
step: 70, loss: 0.04888804256916046
step: 80, loss: 0.06720321625471115
step: 90, loss: 0.1007482185959816
step: 100, loss: 0.17813920974731445
step: 110, loss: 0.0879170224070549
step: 120, loss: 0.10473888367414474
step: 130, loss: 0.08211180567741394
step: 140, loss: 0.09411881864070892
step: 150, loss: 0.20553311705589294
step: 160, loss: 0.042575545608997345
step: 170, loss: 0.08964438736438751
step: 180, loss: 0.02986476570367813
step: 190, loss: 0.09421651810407639
step: 200, loss: 0.08745869249105453
step: 210, loss: 0.04654504731297493
step: 220, loss: 0.07073300331830978
step: 230, loss: 0.11133487522602081
step: 240, loss: 0.026023201644420624
step: 250, loss: 0.09771363437175751
step: 260, loss: 0.08372671157121658
step: 270, loss: 0.14090783894062042
step: 280, loss: 0.0836045891046524
step: 290, loss: 0.05267005041241646
step: 300, loss: 0.0670737773180008
step: 310, loss: 0.10994012653827667
step: 320, loss: 0.030792059376835823
step: 330, loss: 0.09995817393064499
step: 340, loss: 0.07493473589420319
step: 350, loss: 0.09849850833415985
step: 360, loss: 0.08217638731002808
step: 370, loss: 0.05658893287181854
step: 380, loss: 0.07920924574136734
step: 390, loss: 0.04335586726665497
step: 400, loss: 0.09919805824756622
step: 410, loss: 0.03782753646373749
step: 420, loss: 0.14234162867069244
epoch 7: dev_f1=0.7294117647058824, f1=0.72265625, best_f1=0.7134724857685009
step: 0, loss: 0.15882906317710876
step: 10, loss: 0.09589903056621552
step: 20, loss: 0.05123285949230194
step: 30, loss: 0.0624687485396862
step: 40, loss: 0.033543843775987625
step: 50, loss: 0.10951898992061615
step: 60, loss: 0.10472439974546432
step: 70, loss: 0.12461262941360474
step: 80, loss: 0.0889459028840065
step: 90, loss: 0.14486126601696014
step: 100, loss: 0.1275836080312729
step: 110, loss: 0.031981661915779114
step: 120, loss: 0.19013075530529022
step: 130, loss: 0.11259664595127106
step: 140, loss: 0.09439262747764587
step: 150, loss: 0.018956301733851433
step: 160, loss: 0.05751489847898483
step: 170, loss: 0.03752836585044861
step: 180, loss: 0.08648665994405746
step: 190, loss: 0.0748596042394638
step: 200, loss: 0.01649378426373005
step: 210, loss: 0.032851554453372955
step: 220, loss: 0.08053700625896454
step: 230, loss: 0.04968680068850517
step: 240, loss: 0.1019565761089325
step: 250, loss: 0.11188620328903198
step: 260, loss: 0.017130590975284576
step: 270, loss: 0.11706005036830902
step: 280, loss: 0.08249491453170776
step: 290, loss: 0.03575742617249489
step: 300, loss: 0.14008483290672302
step: 310, loss: 0.0842428132891655
step: 320, loss: 0.08859920501708984
step: 330, loss: 0.09521861374378204
step: 340, loss: 0.10111226886510849
step: 350, loss: 0.06316354125738144
step: 360, loss: 0.1347261369228363
step: 370, loss: 0.08773195743560791
step: 380, loss: 0.08632834255695343
step: 390, loss: 0.07379666715860367
step: 400, loss: 0.018308280035853386
step: 410, loss: 0.0201368760317564
step: 420, loss: 0.18050995469093323
epoch 8: dev_f1=0.7183364839319472, f1=0.6828358208955224, best_f1=0.7134724857685009
step: 0, loss: 0.03191874548792839
step: 10, loss: 0.05722412094473839
step: 20, loss: 0.0928424522280693
step: 30, loss: 0.0761515200138092
step: 40, loss: 0.09949121624231339
step: 50, loss: 0.2095770537853241
step: 60, loss: 0.09631940722465515
step: 70, loss: 0.11117958277463913
step: 80, loss: 0.021845843642950058
step: 90, loss: 0.09172675013542175
step: 100, loss: 0.00011213977995794266
step: 110, loss: 0.060335442423820496
step: 120, loss: 0.13444781303405762
step: 130, loss: 0.026287397369742393
step: 140, loss: 0.07693658024072647
step: 150, loss: 0.04799472540616989
step: 160, loss: 0.0903281718492508
step: 170, loss: 0.04882122948765755
step: 180, loss: 0.05981343984603882
step: 190, loss: 0.03927896171808243
step: 200, loss: 0.07835101336240768
step: 210, loss: 0.08553480356931686
step: 220, loss: 0.09974851459264755
step: 230, loss: 0.05607222020626068
step: 240, loss: 0.04686340317130089
step: 250, loss: 0.172122523188591
step: 260, loss: 0.032771140336990356
step: 270, loss: 0.08551432192325592
step: 280, loss: 0.04118717834353447
step: 290, loss: 0.03818545863032341
step: 300, loss: 0.044041309505701065
step: 310, loss: 0.1601533740758896
step: 320, loss: 0.09281237423419952
step: 330, loss: 0.05597440525889397
step: 340, loss: 0.07335715740919113
step: 350, loss: 0.10873737186193466
step: 360, loss: 0.08305281400680542
step: 370, loss: 0.07534537464380264
step: 380, loss: 0.10304700583219528
step: 390, loss: 0.11995507776737213
step: 400, loss: 0.17351283133029938
step: 410, loss: 0.050812967121601105
step: 420, loss: 0.08791359513998032
epoch 9: dev_f1=0.7134502923976609, f1=0.6841046277665995, best_f1=0.7134724857685009
step: 0, loss: 0.044597040861845016
step: 10, loss: 0.047029249370098114
step: 20, loss: 0.02953791618347168
step: 30, loss: 0.030248545110225677
step: 40, loss: 0.030804088339209557
step: 50, loss: 0.050937142223119736
step: 60, loss: 0.006314598023891449
step: 70, loss: 0.12280050665140152
step: 80, loss: 0.09384062141180038
step: 90, loss: 0.12388230115175247
step: 100, loss: 0.030495325103402138
step: 110, loss: 0.06129762902855873
step: 120, loss: 0.07377420365810394
step: 130, loss: 0.023041097447276115
step: 140, loss: 0.05259155109524727
step: 150, loss: 0.0412922129034996
step: 160, loss: 0.14413169026374817
step: 170, loss: 0.00024951653904281557
step: 180, loss: 0.08154390007257462
step: 190, loss: 0.038156505674123764
step: 200, loss: 0.08835645020008087
step: 210, loss: 0.0572257898747921
step: 220, loss: 0.058949921280145645
step: 230, loss: 0.03530900180339813
step: 240, loss: 0.0001655796804698184
step: 250, loss: 0.17240944504737854
step: 260, loss: 0.0003486592904664576
step: 270, loss: 0.06361397355794907
step: 280, loss: 0.17796149849891663
step: 290, loss: 0.09863729774951935
step: 300, loss: 0.1636631339788437
step: 310, loss: 0.03649601712822914
step: 320, loss: 0.030614126473665237
step: 330, loss: 0.023132771253585815
step: 340, loss: 0.10937577486038208
step: 350, loss: 0.06645097583532333
step: 360, loss: 0.12318385392427444
step: 370, loss: 0.185991108417511
step: 380, loss: 0.040003612637519836
step: 390, loss: 0.011149069294333458
step: 400, loss: 0.06690759211778641
step: 410, loss: 0.04960935562849045
step: 420, loss: 0.13424834609031677
epoch 10: dev_f1=0.7387033398821218, f1=0.7165354330708661, best_f1=0.7165354330708661
step: 0, loss: 0.02244456484913826
step: 10, loss: 0.007038435898721218
step: 20, loss: 0.05257311090826988
step: 30, loss: 0.06378006935119629
step: 40, loss: 0.048160817474126816
step: 50, loss: 6.373308860929683e-05
step: 60, loss: 0.13037261366844177
step: 70, loss: 0.017841480672359467
step: 80, loss: 0.03436557576060295
step: 90, loss: 0.005492671392858028
step: 100, loss: 0.07304207980632782
step: 110, loss: 0.05435309559106827
step: 120, loss: 0.05254867672920227
step: 130, loss: 0.21711722016334534
step: 140, loss: 0.07022906094789505
step: 150, loss: 0.14057308435440063
step: 160, loss: 0.03330792114138603
step: 170, loss: 0.12130431085824966
step: 180, loss: 0.02973792888224125
step: 190, loss: 0.07355982810258865
step: 200, loss: 0.09183008223772049
step: 210, loss: 0.1318170428276062
step: 220, loss: 0.036802761256694794
step: 230, loss: 0.1565183401107788
step: 240, loss: 0.04988913983106613
step: 250, loss: 0.08971597254276276
step: 260, loss: 0.0895690992474556
step: 270, loss: 0.05211436748504639
step: 280, loss: 0.02397003024816513
step: 290, loss: 0.1259980946779251
step: 300, loss: 0.07727161049842834
step: 310, loss: 0.10900609940290451
step: 320, loss: 0.09687574207782745
step: 330, loss: 0.022214557975530624
step: 340, loss: 0.1346672624349594
step: 350, loss: 0.019547972828149796
step: 360, loss: 0.0227015633136034
step: 370, loss: 0.04628147557377815
step: 380, loss: 0.060186080634593964
step: 390, loss: 0.04557494819164276
step: 400, loss: 0.057247649878263474
step: 410, loss: 0.040200911462306976
step: 420, loss: 0.1197831928730011
epoch 11: dev_f1=0.7190569744597249, f1=0.7106796116504855, best_f1=0.7165354330708661
step: 0, loss: 0.04945233836770058
step: 10, loss: 0.025737784802913666
step: 20, loss: 0.013400758616626263
step: 30, loss: 0.05105781555175781
step: 40, loss: 0.0056801168248057365
step: 50, loss: 0.03519254922866821
step: 60, loss: 0.09963218867778778
step: 70, loss: 0.0707014948129654
step: 80, loss: 0.03857313469052315
step: 90, loss: 0.11760273575782776
step: 100, loss: 0.1174856498837471
step: 110, loss: 0.06489569693803787
step: 120, loss: 0.06842666864395142
step: 130, loss: 0.03411014750599861
step: 140, loss: 0.07818708568811417
step: 150, loss: 0.08625289797782898
step: 160, loss: 0.028728820383548737
step: 170, loss: 0.09041108191013336
step: 180, loss: 0.09203289449214935
step: 190, loss: 0.04319878667593002
step: 200, loss: 0.026305969804525375
step: 210, loss: 0.021420439705252647
step: 220, loss: 0.029591554775834084
step: 230, loss: 0.10714242607355118
step: 240, loss: 0.10426840931177139
step: 250, loss: 0.19557815790176392
step: 260, loss: 0.04621803015470505
step: 270, loss: 0.07228289544582367
step: 280, loss: 0.10228649526834488
step: 290, loss: 0.10791461914777756
step: 300, loss: 0.04257269948720932
step: 310, loss: 0.00890490971505642
step: 320, loss: 0.0006890979711897671
step: 330, loss: 0.09092263877391815
step: 340, loss: 0.001906436518765986
step: 350, loss: 0.039170682430267334
step: 360, loss: 0.05451831966638565
step: 370, loss: 0.0655631572008133
step: 380, loss: 0.09243350476026535
step: 390, loss: 0.05034118518233299
step: 400, loss: 0.08689690381288528
step: 410, loss: 0.08500364422798157
step: 420, loss: 0.020162904635071754
epoch 12: dev_f1=0.7258064516129032, f1=0.689655172413793, best_f1=0.7165354330708661
step: 0, loss: 0.045128487050533295
step: 10, loss: 0.10232612490653992
step: 20, loss: 0.07946187257766724
step: 30, loss: 0.026651006191968918
step: 40, loss: 0.019849296659231186
step: 50, loss: 0.0816987156867981
step: 60, loss: 0.06668691337108612
step: 70, loss: 0.08096303790807724
step: 80, loss: 0.08101610094308853
step: 90, loss: 0.01552300900220871
step: 100, loss: 0.02397105097770691
step: 110, loss: 0.06834312528371811
step: 120, loss: 0.10285308957099915
step: 130, loss: 0.07043279707431793
step: 140, loss: 0.018214767798781395
step: 150, loss: 0.070754274725914
step: 160, loss: 0.060780592262744904
step: 170, loss: 0.0964084193110466
step: 180, loss: 0.07868669182062149
step: 190, loss: 0.062276870012283325
step: 200, loss: 0.10204850137233734
step: 210, loss: 0.07755611836910248
step: 220, loss: 0.105885349214077
step: 230, loss: 0.14225803315639496
step: 240, loss: 0.027110405266284943
step: 250, loss: 0.048182256519794464
step: 260, loss: 0.014432764612138271
step: 270, loss: 0.09743351489305496
step: 280, loss: 0.03339695930480957
step: 290, loss: 0.010436546057462692
step: 300, loss: 0.04418313130736351
step: 310, loss: 0.1902981996536255
step: 320, loss: 0.07782183587551117
step: 330, loss: 0.043522436171770096
step: 340, loss: 0.0295430775731802
step: 350, loss: 0.027754133567214012
step: 360, loss: 0.08107095956802368
step: 370, loss: 0.054017677903175354
step: 380, loss: 0.18539078533649445
step: 390, loss: 0.1126132532954216
step: 400, loss: 0.05610065907239914
step: 410, loss: 0.06006399169564247
step: 420, loss: 0.14257878065109253
epoch 13: dev_f1=0.7112068965517242, f1=0.7030567685589519, best_f1=0.7165354330708661
step: 0, loss: 0.006452194415032864
step: 10, loss: 0.018158821389079094
step: 20, loss: 0.06078090891242027
step: 30, loss: 0.029992587864398956
step: 40, loss: 0.05649850517511368
step: 50, loss: 0.11358019709587097
step: 60, loss: 0.04424809664487839
step: 70, loss: 0.03158961609005928
step: 80, loss: 0.03587741404771805
step: 90, loss: 0.07414130121469498
step: 100, loss: 0.040932755917310715
step: 110, loss: 0.07243208587169647
step: 120, loss: 0.12642306089401245
step: 130, loss: 0.04362848401069641
step: 140, loss: 0.07390309870243073
step: 150, loss: 0.015505517832934856
step: 160, loss: 0.11500222235918045
step: 170, loss: 0.0773148462176323
step: 180, loss: 0.005533032119274139
step: 190, loss: 0.01321436371654272
step: 200, loss: 0.027931615710258484
step: 210, loss: 0.024489114060997963
step: 220, loss: 0.009524133987724781
step: 230, loss: 0.017419449985027313
step: 240, loss: 0.1490800529718399
step: 250, loss: 0.050590880215168
step: 260, loss: 0.10846853256225586
step: 270, loss: 0.1024852991104126
step: 280, loss: 0.3200135827064514
step: 290, loss: 0.0006421029684133828
step: 300, loss: 0.048910390585660934
step: 310, loss: 0.12884633243083954
step: 320, loss: 0.05591811239719391
step: 330, loss: 0.06706112623214722
step: 340, loss: 0.07299954444169998
step: 350, loss: 0.03214512765407562
step: 360, loss: 0.1546013206243515
step: 370, loss: 0.07234810292720795
step: 380, loss: 0.002567980671301484
step: 390, loss: 0.12228824943304062
step: 400, loss: 0.26534831523895264
step: 410, loss: 0.05757917836308479
step: 420, loss: 0.08092848211526871
epoch 14: dev_f1=0.7130801687763714, f1=0.7081545064377682, best_f1=0.7165354330708661
step: 0, loss: 0.09594652056694031
step: 10, loss: 0.012301689013838768
step: 20, loss: 0.07953866571187973
step: 30, loss: 0.06921780854463577
step: 40, loss: 0.05232000723481178
step: 50, loss: 0.031440816819667816
step: 60, loss: 0.06398757547140121
step: 70, loss: 0.10390395671129227
step: 80, loss: 0.008977197110652924
step: 90, loss: 0.036147721111774445
step: 100, loss: 0.04057668149471283
step: 110, loss: 0.08213812857866287
step: 120, loss: 0.07306007295846939
step: 130, loss: 0.046819206327199936
step: 140, loss: 0.09139832109212875
step: 150, loss: 0.030823422595858574
step: 160, loss: 0.008705519139766693
step: 170, loss: 0.023070454597473145
step: 180, loss: 0.1073337122797966
step: 190, loss: 0.15464143455028534
step: 200, loss: 0.027247251942753792
step: 210, loss: 0.1298390030860901
step: 220, loss: 0.058691900223493576
step: 230, loss: 0.04698130860924721
step: 240, loss: 0.23328649997711182
step: 250, loss: 0.07538716495037079
step: 260, loss: 0.058416157960891724
step: 270, loss: 0.08114880323410034
step: 280, loss: 0.11973190307617188
step: 290, loss: 0.022866947576403618
step: 300, loss: 0.013840198516845703
step: 310, loss: 0.016494983807206154
step: 320, loss: 0.11647205799818039
step: 330, loss: 0.1749105602502823
step: 340, loss: 0.0722728744149208
step: 350, loss: 0.04249286279082298
step: 360, loss: 0.020386943593621254
step: 370, loss: 0.10863019526004791
step: 380, loss: 0.199968159198761
step: 390, loss: 0.022210558876395226
step: 400, loss: 0.07277684658765793
step: 410, loss: 0.10600098967552185
step: 420, loss: 0.012314610183238983
epoch 15: dev_f1=0.7257383966244726, f1=0.7114967462039045, best_f1=0.7165354330708661
step: 0, loss: 0.022935079410672188
step: 10, loss: 0.0737040713429451
step: 20, loss: 0.0982268750667572
step: 30, loss: 0.04887714609503746
step: 40, loss: 0.01788727194070816
step: 50, loss: 0.019096411764621735
step: 60, loss: 0.055991578847169876
step: 70, loss: 0.05945631489157677
step: 80, loss: 0.01707306131720543
step: 90, loss: 0.03543455898761749
step: 100, loss: 0.0184861421585083
step: 110, loss: 0.02161037176847458
step: 120, loss: 0.04477206990122795
step: 130, loss: 0.07140495628118515
step: 140, loss: 0.09856967628002167
step: 150, loss: 0.056997381150722504
step: 160, loss: 0.04314275085926056
step: 170, loss: 0.05705792456865311
step: 180, loss: 0.05165528878569603
step: 190, loss: 0.04570101201534271
step: 200, loss: 0.06096511706709862
step: 210, loss: 0.038750384002923965
step: 220, loss: 0.09200694411993027
step: 230, loss: 0.041237011551856995
step: 240, loss: 0.10504230856895447
step: 250, loss: 0.048866864293813705
step: 260, loss: 0.03988947346806526
step: 270, loss: 0.13285192847251892
step: 280, loss: 0.06589405238628387
step: 290, loss: 0.13306614756584167
step: 300, loss: 0.03617678955197334
step: 310, loss: 0.04168787971138954
step: 320, loss: 0.08045484870672226
step: 330, loss: 0.11464633047580719
step: 340, loss: 0.015224205330014229
step: 350, loss: 0.06735868006944656
step: 360, loss: 0.1061435341835022
step: 370, loss: 0.019027868285775185
step: 380, loss: 0.1534726321697235
step: 390, loss: 0.05538371950387955
step: 400, loss: 4.948068817611784e-05
step: 410, loss: 0.04881274700164795
step: 420, loss: 0.026081303134560585
epoch 16: dev_f1=0.7161016949152543, f1=0.7010752688172043, best_f1=0.7165354330708661
step: 0, loss: 0.04899976775050163
step: 10, loss: 0.05776852369308472
step: 20, loss: 0.03999611735343933
step: 30, loss: 0.0728415697813034
step: 40, loss: 0.08142655342817307
step: 50, loss: 0.06466789543628693
step: 60, loss: 0.11577822268009186
step: 70, loss: 0.038831163197755814
step: 80, loss: 0.03847237303853035
step: 90, loss: 0.005198714789003134
step: 100, loss: 0.07206790149211884
step: 110, loss: 0.01318751834332943
step: 120, loss: 0.10630021244287491
step: 130, loss: 0.05045785382390022
step: 140, loss: 0.0921425148844719
step: 150, loss: 0.025713806971907616
step: 160, loss: 0.0766717791557312
step: 170, loss: 0.09903401136398315
step: 180, loss: 0.07447460293769836
step: 190, loss: 0.0748642310500145
step: 200, loss: 0.038576558232307434
step: 210, loss: 0.07505222409963608
step: 220, loss: 0.020863784477114677
step: 230, loss: 0.01976482756435871
step: 240, loss: 0.13450314104557037
step: 250, loss: 0.0018179743783548474
step: 260, loss: 0.049491629004478455
step: 270, loss: 0.11701344698667526
step: 280, loss: 0.00030030723428353667
step: 290, loss: 0.08092422038316727
step: 300, loss: 0.02355319820344448
step: 310, loss: 0.023042047396302223
step: 320, loss: 0.20749357342720032
step: 330, loss: 0.030442580580711365
step: 340, loss: 0.021015038713812828
step: 350, loss: 0.044537752866744995
step: 360, loss: 0.033955905586481094
step: 370, loss: 0.06815654784440994
step: 380, loss: 0.09276030957698822
step: 390, loss: 0.05276095122098923
step: 400, loss: 0.010081308893859386
step: 410, loss: 0.05138290673494339
step: 420, loss: 0.036372244358062744
epoch 17: dev_f1=0.7145790554414784, f1=0.7085953878406709, best_f1=0.7165354330708661
step: 0, loss: 0.05558047443628311
step: 10, loss: 0.06127806380391121
step: 20, loss: 0.06291418522596359
step: 30, loss: 0.03198276087641716
step: 40, loss: 0.06639880686998367
step: 50, loss: 0.014969481155276299
step: 60, loss: 0.07029841840267181
step: 70, loss: 0.04552515968680382
step: 80, loss: 0.0665012001991272
step: 90, loss: 0.07238764315843582
step: 100, loss: 0.036086320877075195
step: 110, loss: 0.08504176884889603
step: 120, loss: 0.16830217838287354
step: 130, loss: 0.04267100244760513
step: 140, loss: 0.052899204194545746
step: 150, loss: 0.00821065902709961
step: 160, loss: 0.042874082922935486
step: 170, loss: 0.10100386291742325
step: 180, loss: 0.03966164588928223
step: 190, loss: 0.0790192186832428
step: 200, loss: 0.058316707611083984
step: 210, loss: 0.0735631063580513
step: 220, loss: 0.016610363498330116
step: 230, loss: 0.01605933904647827
step: 240, loss: 0.0866973027586937
step: 250, loss: 0.016161015257239342
step: 260, loss: 0.08696964383125305
step: 270, loss: 0.028268810361623764
step: 280, loss: 3.125005969195627e-05
step: 290, loss: 0.06492307037115097
step: 300, loss: 0.059278372675180435
step: 310, loss: 0.06936831772327423
step: 320, loss: 0.0919487401843071
step: 330, loss: 0.0015316256321966648
step: 340, loss: 0.03604527562856674
step: 350, loss: 0.1328948587179184
step: 360, loss: 0.00029070250457152724
step: 370, loss: 0.07285501807928085
step: 380, loss: 0.06792587786912918
step: 390, loss: 0.04179827496409416
step: 400, loss: 0.015444768592715263
step: 410, loss: 0.08351428806781769
step: 420, loss: 0.015673870220780373
epoch 18: dev_f1=0.6984815618221258, f1=0.7045951859956238, best_f1=0.7165354330708661
step: 0, loss: 0.032034266740083694
step: 10, loss: 0.025758670642971992
step: 20, loss: 0.11601047217845917
step: 30, loss: 0.004623533226549625
step: 40, loss: 0.14285503327846527
step: 50, loss: 0.04847239702939987
step: 60, loss: 0.04402189329266548
step: 70, loss: 0.07291670143604279
step: 80, loss: 0.02329244278371334
step: 90, loss: 0.03262878581881523
step: 100, loss: 0.07196786254644394
step: 110, loss: 0.09921983629465103
step: 120, loss: 0.037845365703105927
step: 130, loss: 0.06268804520368576
step: 140, loss: 0.12126830965280533
step: 150, loss: 0.03509931638836861
step: 160, loss: 0.15026217699050903
step: 170, loss: 0.01677146926522255
step: 180, loss: 0.01862332411110401
step: 190, loss: 0.013459356501698494
step: 200, loss: 0.09818079322576523
step: 210, loss: 0.0826815590262413
step: 220, loss: 0.07084685564041138
step: 230, loss: 0.05227847397327423
step: 240, loss: 0.0416594073176384
step: 250, loss: 0.03614410385489464
step: 260, loss: 0.01798202097415924
step: 270, loss: 0.0318036787211895
step: 280, loss: 0.13237334787845612
step: 290, loss: 0.003066943259909749
step: 300, loss: 0.03397231176495552
step: 310, loss: 0.009624620899558067
step: 320, loss: 0.01829758659005165
step: 330, loss: 0.07930426299571991
step: 340, loss: 0.06631296873092651
step: 350, loss: 0.04276951774954796
step: 360, loss: 0.04624699801206589
step: 370, loss: 0.0725967064499855
step: 380, loss: 0.01786876656115055
step: 390, loss: 0.10856667160987854
step: 400, loss: 0.030992474406957626
step: 410, loss: 0.07071631401777267
step: 420, loss: 0.04491303861141205
epoch 19: dev_f1=0.6954643628509719, f1=0.7114967462039045, best_f1=0.7165354330708661
step: 0, loss: 0.03276403620839119
step: 10, loss: 0.0001233623770531267
step: 20, loss: 0.1270763874053955
step: 30, loss: 0.03269754722714424
step: 40, loss: 0.07126720994710922
step: 50, loss: 0.03491517901420593
step: 60, loss: 0.013031067326664925
step: 70, loss: 0.11296519637107849
step: 80, loss: 0.07353842258453369
step: 90, loss: 0.020089125260710716
step: 100, loss: 0.05670011416077614
step: 110, loss: 0.03000437095761299
step: 120, loss: 0.014304634183645248
step: 130, loss: 0.05505106598138809
step: 140, loss: 0.0785064548254013
step: 150, loss: 0.08483126759529114
step: 160, loss: 0.052112605422735214
step: 170, loss: 0.034911222755908966
step: 180, loss: 0.0903247520327568
step: 190, loss: 0.0007608391460962594
step: 200, loss: 0.024629829451441765
step: 210, loss: 0.0446280837059021
step: 220, loss: 0.03952603414654732
step: 230, loss: 0.08047229051589966
step: 240, loss: 0.030774664133787155
step: 250, loss: 0.017476368695497513
step: 260, loss: 0.046450141817331314
step: 270, loss: 0.06771903485059738
step: 280, loss: 0.028258066624403
step: 290, loss: 0.13969860970973969
step: 300, loss: 0.060859616845846176
step: 310, loss: 0.044310711324214935
step: 320, loss: 0.0005416098865680397
step: 330, loss: 0.10472702980041504
step: 340, loss: 0.05614420771598816
step: 350, loss: 0.0451536625623703
step: 360, loss: 0.06966593861579895
step: 370, loss: 0.08089864253997803
step: 380, loss: 0.011068536899983883
step: 390, loss: 0.007662652991712093
step: 400, loss: 0.01088848989456892
step: 410, loss: 0.01690993830561638
step: 420, loss: 0.04246971383690834
epoch 20: dev_f1=0.6885964912280701, f1=0.7048458149779736, best_f1=0.7165354330708661
