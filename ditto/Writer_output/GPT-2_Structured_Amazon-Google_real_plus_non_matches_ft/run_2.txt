cuda
Device: cuda
step: 0, loss: 0.9729793071746826
step: 10, loss: 0.2547399699687958
step: 20, loss: 0.15547184646129608
step: 30, loss: 0.15858164429664612
step: 40, loss: 0.035982243716716766
step: 50, loss: 0.16866523027420044
step: 60, loss: 0.038094863295555115
step: 70, loss: 0.39147794246673584
step: 80, loss: 0.2544940412044525
step: 90, loss: 0.1672307401895523
step: 100, loss: 0.16731072962284088
step: 110, loss: 0.28501102328300476
step: 120, loss: 0.11866696923971176
step: 130, loss: 0.13763082027435303
step: 140, loss: 0.050277624279260635
step: 150, loss: 0.13097625970840454
step: 160, loss: 0.20437026023864746
step: 170, loss: 0.14703336358070374
step: 180, loss: 0.0868385061621666
step: 190, loss: 0.14092013239860535
step: 200, loss: 0.11766104400157928
step: 210, loss: 0.22543998062610626
step: 220, loss: 0.15307769179344177
step: 230, loss: 0.01129771675914526
step: 240, loss: 0.16918842494487762
step: 250, loss: 0.01999090239405632
step: 260, loss: 0.295081228017807
step: 270, loss: 0.21158306300640106
step: 280, loss: 0.12832069396972656
step: 290, loss: 0.12202693521976471
step: 300, loss: 0.12714460492134094
step: 310, loss: 0.12546828389167786
step: 320, loss: 0.12792038917541504
step: 330, loss: 0.26988840103149414
step: 340, loss: 0.07703202217817307
step: 350, loss: 0.0664890706539154
step: 360, loss: 0.10455287247896194
step: 370, loss: 0.040300771594047546
step: 380, loss: 0.1574062556028366
step: 390, loss: 0.10466668754816055
step: 400, loss: 0.1597267985343933
epoch 1: dev_f1=0.6344827586206896, f1=0.6352087114337568, best_f1=0.6352087114337568
step: 0, loss: 0.04063965752720833
step: 10, loss: 0.2030118703842163
step: 20, loss: 0.06115928292274475
step: 30, loss: 0.03415411710739136
step: 40, loss: 0.16140103340148926
step: 50, loss: 0.011665592901408672
step: 60, loss: 0.02607358992099762
step: 70, loss: 0.09863696247339249
step: 80, loss: 0.37621888518333435
step: 90, loss: 0.0893188938498497
step: 100, loss: 0.04003971442580223
step: 110, loss: 0.24778009951114655
step: 120, loss: 0.07676363736391068
step: 130, loss: 0.05268805846571922
step: 140, loss: 0.11645086109638214
step: 150, loss: 0.2029806226491928
step: 160, loss: 0.17319974303245544
step: 170, loss: 0.1342388242483139
step: 180, loss: 0.16943560540676117
step: 190, loss: 0.1875348687171936
step: 200, loss: 0.15195661783218384
step: 210, loss: 0.2594209611415863
step: 220, loss: 0.13006220757961273
step: 230, loss: 0.09882540255784988
step: 240, loss: 0.03719896450638771
step: 250, loss: 0.03140498697757721
step: 260, loss: 0.017787344753742218
step: 270, loss: 0.09437810629606247
step: 280, loss: 0.08981816470623016
step: 290, loss: 0.05103062465786934
step: 300, loss: 0.07045578956604004
step: 310, loss: 0.15125933289527893
step: 320, loss: 0.046649593859910965
step: 330, loss: 0.16223204135894775
step: 340, loss: 0.059987325221300125
step: 350, loss: 0.023102516308426857
step: 360, loss: 0.04144003242254257
step: 370, loss: 0.20060966908931732
step: 380, loss: 0.09368305653333664
step: 390, loss: 0.05688471719622612
step: 400, loss: 0.28075549006462097
epoch 2: dev_f1=0.6533333333333333, f1=0.6518847006651884, best_f1=0.6518847006651884
step: 0, loss: 0.10186456888914108
step: 10, loss: 0.020708099007606506
step: 20, loss: 0.025889934971928596
step: 30, loss: 0.07210859656333923
step: 40, loss: 0.06912312656641006
step: 50, loss: 0.012695829384028912
step: 60, loss: 0.14396809041500092
step: 70, loss: 0.11317960917949677
step: 80, loss: 0.06791210174560547
step: 90, loss: 0.17878973484039307
step: 100, loss: 0.057668402791023254
step: 110, loss: 0.00904855877161026
step: 120, loss: 0.06690946966409683
step: 130, loss: 0.272818922996521
step: 140, loss: 0.027609949931502342
step: 150, loss: 0.04193524643778801
step: 160, loss: 0.006899870466440916
step: 170, loss: 0.10924222320318222
step: 180, loss: 0.006116397213190794
step: 190, loss: 0.09115082770586014
step: 200, loss: 0.5313685536384583
step: 210, loss: 0.03053578920662403
step: 220, loss: 0.02779470570385456
step: 230, loss: 0.044894106686115265
step: 240, loss: 0.01945585384964943
step: 250, loss: 0.026933278888463974
step: 260, loss: 0.04794770106673241
step: 270, loss: 0.01946549490094185
step: 280, loss: 0.10158753395080566
step: 290, loss: 0.040679898113012314
step: 300, loss: 0.056567151099443436
step: 310, loss: 0.05172829329967499
step: 320, loss: 0.09214074164628983
step: 330, loss: 0.020569074898958206
step: 340, loss: 0.09980317950248718
step: 350, loss: 0.1233128011226654
step: 360, loss: 0.0898158922791481
step: 370, loss: 0.11851435899734497
step: 380, loss: 0.13174490630626678
step: 390, loss: 0.08495074510574341
step: 400, loss: 0.036940790712833405
epoch 3: dev_f1=0.6577946768060837, f1=0.6821428571428572, best_f1=0.6821428571428572
step: 0, loss: 0.10847198963165283
step: 10, loss: 0.02207859233021736
step: 20, loss: 0.06730979681015015
step: 30, loss: 0.11151426285505295
step: 40, loss: 0.008341633714735508
step: 50, loss: 0.015000066719949245
step: 60, loss: 0.022755682468414307
step: 70, loss: 0.05395139008760452
step: 80, loss: 0.01294020190834999
step: 90, loss: 0.102375328540802
step: 100, loss: 0.013241761364042759
step: 110, loss: 0.04407774284482002
step: 120, loss: 0.007589921820908785
step: 130, loss: 0.03899398073554039
step: 140, loss: 0.00608844356611371
step: 150, loss: 0.11009354889392853
step: 160, loss: 0.016880366951227188
step: 170, loss: 0.011115393601357937
step: 180, loss: 0.04828060045838356
step: 190, loss: 0.007771216332912445
step: 200, loss: 0.09446392953395844
step: 210, loss: 0.015840450301766396
step: 220, loss: 0.00375790405087173
step: 230, loss: 0.0010940919164568186
step: 240, loss: 0.12980493903160095
step: 250, loss: 0.019986238330602646
step: 260, loss: 0.04546254873275757
step: 270, loss: 0.06153227761387825
step: 280, loss: 0.05347860977053642
step: 290, loss: 0.1262405514717102
step: 300, loss: 0.0789625495672226
step: 310, loss: 0.07803988456726074
step: 320, loss: 0.007891486398875713
step: 330, loss: 0.03556513786315918
step: 340, loss: 0.05698784440755844
step: 350, loss: 0.014957214705646038
step: 360, loss: 0.01505110040307045
step: 370, loss: 0.014555804431438446
step: 380, loss: 0.010115498676896095
step: 390, loss: 0.0062231747433543205
step: 400, loss: 0.0014465624699369073
epoch 4: dev_f1=0.6653992395437263, f1=0.6516853932584269, best_f1=0.6516853932584269
step: 0, loss: 0.00548872584477067
step: 10, loss: 0.13341069221496582
step: 20, loss: 0.07976836711168289
step: 30, loss: 0.019878564402461052
step: 40, loss: 0.022142061963677406
step: 50, loss: 0.04099959135055542
step: 60, loss: 0.07383660972118378
step: 70, loss: 0.13048693537712097
step: 80, loss: 0.007671361323446035
step: 90, loss: 0.020023563876748085
step: 100, loss: 0.09551703929901123
step: 110, loss: 0.028652874752879143
step: 120, loss: 0.03749582916498184
step: 130, loss: 0.07317888736724854
step: 140, loss: 0.0007607961888425052
step: 150, loss: 0.0556531585752964
step: 160, loss: 0.07461338490247726
step: 170, loss: 0.03432334214448929
step: 180, loss: 0.07915722578763962
step: 190, loss: 0.011409523896872997
step: 200, loss: 0.008462077006697655
step: 210, loss: 0.0622902438044548
step: 220, loss: 0.0500728040933609
step: 230, loss: 0.014510484412312508
step: 240, loss: 0.03159860149025917
step: 250, loss: 0.061775460839271545
step: 260, loss: 0.009209818206727505
step: 270, loss: 0.03132213279604912
step: 280, loss: 0.002524455776438117
step: 290, loss: 0.009438691660761833
step: 300, loss: 0.0427156463265419
step: 310, loss: 0.03997950255870819
step: 320, loss: 0.327291876077652
step: 330, loss: 0.14240072667598724
step: 340, loss: 0.02589733712375164
step: 350, loss: 0.012411003932356834
step: 360, loss: 0.043699923902750015
step: 370, loss: 0.08388151228427887
step: 380, loss: 0.011938586831092834
step: 390, loss: 0.021701352670788765
step: 400, loss: 0.0240410678088665
epoch 5: dev_f1=0.6864564007421151, f1=0.7129798903107862, best_f1=0.7129798903107862
step: 0, loss: 0.011007425375282764
step: 10, loss: 0.05618244782090187
step: 20, loss: 0.00035725219640880823
step: 30, loss: 0.03298868611454964
step: 40, loss: 0.007010079454630613
step: 50, loss: 0.06766702979803085
step: 60, loss: 0.1017482653260231
step: 70, loss: 0.01015795674175024
step: 80, loss: 0.011082451790571213
step: 90, loss: 0.007217478472739458
step: 100, loss: 0.027905689552426338
step: 110, loss: 0.00891731958836317
step: 120, loss: 0.004724624566733837
step: 130, loss: 0.016079826280474663
step: 140, loss: 0.04746628925204277
step: 150, loss: 0.02881111204624176
step: 160, loss: 0.030124174430966377
step: 170, loss: 0.029957395046949387
step: 180, loss: 0.06497642397880554
step: 190, loss: 0.0010788536164909601
step: 200, loss: 0.0007382780313491821
step: 210, loss: 0.007204709108918905
step: 220, loss: 0.18606597185134888
step: 230, loss: 0.07990379631519318
step: 240, loss: 0.001882084528915584
step: 250, loss: 0.017787666991353035
step: 260, loss: 0.032025501132011414
step: 270, loss: 0.03804674744606018
step: 280, loss: 0.018942587077617645
step: 290, loss: 0.08248308300971985
step: 300, loss: 0.006678003817796707
step: 310, loss: 0.07882851362228394
step: 320, loss: 0.009499725885689259
step: 330, loss: 0.007783432025462389
step: 340, loss: 0.0042386846616864204
step: 350, loss: 0.004976371303200722
step: 360, loss: 0.15321733057498932
step: 370, loss: 0.04419507831335068
step: 380, loss: 0.12426486611366272
step: 390, loss: 0.0008636092534288764
step: 400, loss: 0.056915562599897385
epoch 6: dev_f1=0.6652806652806652, f1=0.6947368421052633, best_f1=0.7129798903107862
step: 0, loss: 0.005628491751849651
step: 10, loss: 0.013206537812948227
step: 20, loss: 0.005738628562539816
step: 30, loss: 0.00616793055087328
step: 40, loss: 0.0005466302391141653
step: 50, loss: 0.0034992527216672897
step: 60, loss: 0.015033051371574402
step: 70, loss: 0.05604691803455353
step: 80, loss: 0.004615216515958309
step: 90, loss: 0.006356530357152224
step: 100, loss: 0.005107021424919367
step: 110, loss: 0.025920817628502846
step: 120, loss: 0.11430981755256653
step: 130, loss: 0.04373517259955406
step: 140, loss: 0.009019963443279266
step: 150, loss: 0.16298508644104004
step: 160, loss: 0.0027611057739704847
step: 170, loss: 0.0030270705465227365
step: 180, loss: 0.017253505066037178
step: 190, loss: 0.05421335622668266
step: 200, loss: 0.025767451152205467
step: 210, loss: 0.00941163208335638
step: 220, loss: 0.1346132904291153
step: 230, loss: 0.038896262645721436
step: 240, loss: 0.004478657152503729
step: 250, loss: 0.019228164106607437
step: 260, loss: 0.07013695687055588
step: 270, loss: 0.026312202215194702
step: 280, loss: 0.0019313560333102942
step: 290, loss: 0.0017032624455168843
step: 300, loss: 0.008796601556241512
step: 310, loss: 0.0022921490017324686
step: 320, loss: 0.01331349927932024
step: 330, loss: 0.029125148430466652
step: 340, loss: 0.13489608466625214
step: 350, loss: 0.004030442796647549
step: 360, loss: 0.002811085432767868
step: 370, loss: 0.00024162934278137982
step: 380, loss: 0.029078051447868347
step: 390, loss: 0.0024299242068082094
step: 400, loss: 0.0032242508605122566
epoch 7: dev_f1=0.6818181818181818, f1=0.6909788867562379, best_f1=0.7129798903107862
step: 0, loss: 0.0550418384373188
step: 10, loss: 0.004903517197817564
step: 20, loss: 0.0393318235874176
step: 30, loss: 0.004948498215526342
step: 40, loss: 0.01946621760725975
step: 50, loss: 0.002355166943743825
step: 60, loss: 0.04726092517375946
step: 70, loss: 0.0010582022368907928
step: 80, loss: 0.018012000247836113
step: 90, loss: 0.004411805421113968
step: 100, loss: 0.00043004268081858754
step: 110, loss: 0.08318410068750381
step: 120, loss: 0.004554990213364363
step: 130, loss: 0.014212176203727722
step: 140, loss: 0.025744611397385597
step: 150, loss: 0.010855965316295624
step: 160, loss: 0.03062271885573864
step: 170, loss: 0.13979804515838623
step: 180, loss: 0.011876814067363739
step: 190, loss: 0.030999572947621346
step: 200, loss: 0.04447199031710625
step: 210, loss: 0.010248956270515919
step: 220, loss: 0.003439293708652258
step: 230, loss: 0.04469691216945648
step: 240, loss: 0.006033238954842091
step: 250, loss: 0.002334993565455079
step: 260, loss: 0.31776750087738037
step: 270, loss: 0.0007349478546530008
step: 280, loss: 0.0008338788175024092
step: 290, loss: 0.02519853040575981
step: 300, loss: 0.043423186987638474
step: 310, loss: 0.013669121079146862
step: 320, loss: 0.000955078867264092
step: 330, loss: 0.000630254449788481
step: 340, loss: 0.029987961053848267
step: 350, loss: 0.21295388042926788
step: 360, loss: 0.003572718007490039
step: 370, loss: 0.0016790402587503195
step: 380, loss: 0.023399803787469864
step: 390, loss: 0.0177408829331398
step: 400, loss: 0.007037348113954067
epoch 8: dev_f1=0.688034188034188, f1=0.6849894291754756, best_f1=0.6849894291754756
step: 0, loss: 0.02441123127937317
step: 10, loss: 0.021826911717653275
step: 20, loss: 0.0041629294864833355
step: 30, loss: 0.02649838477373123
step: 40, loss: 0.01824374496936798
step: 50, loss: 0.028993681073188782
step: 60, loss: 0.0009813831420615315
step: 70, loss: 0.0006278858636505902
step: 80, loss: 0.02588331513106823
step: 90, loss: 0.0004187614540569484
step: 100, loss: 0.004176148679107428
step: 110, loss: 0.04294273257255554
step: 120, loss: 0.04408757761120796
step: 130, loss: 0.0011393995955586433
step: 140, loss: 0.0014029683079570532
step: 150, loss: 0.03790721297264099
step: 160, loss: 0.0003844330785796046
step: 170, loss: 0.04484187439084053
step: 180, loss: 0.0009223883971571922
step: 190, loss: 0.0004929961869493127
step: 200, loss: 0.006831346079707146
step: 210, loss: 0.00406435364857316
step: 220, loss: 0.0029013671446591616
step: 230, loss: 0.0008477687952108681
step: 240, loss: 0.04124975576996803
step: 250, loss: 0.03312310203909874
step: 260, loss: 0.0023404164239764214
step: 270, loss: 0.001485363463871181
step: 280, loss: 0.10520341992378235
step: 290, loss: 0.005327362101525068
step: 300, loss: 0.0031441273167729378
step: 310, loss: 0.046517062932252884
step: 320, loss: 0.0052351574413478374
step: 330, loss: 0.0014524911530315876
step: 340, loss: 0.0006177783943712711
step: 350, loss: 0.002546625677496195
step: 360, loss: 0.01297702081501484
step: 370, loss: 0.00408694613724947
step: 380, loss: 0.03247915580868721
step: 390, loss: 0.052416615188121796
step: 400, loss: 0.016165142878890038
epoch 9: dev_f1=0.6814516129032259, f1=0.7091633466135459, best_f1=0.6849894291754756
step: 0, loss: 0.039507877081632614
step: 10, loss: 0.009177331812679768
step: 20, loss: 0.0010970571311190724
step: 30, loss: 0.007226666435599327
step: 40, loss: 0.024614684283733368
step: 50, loss: 0.03615066409111023
step: 60, loss: 0.00332663138397038
step: 70, loss: 0.000729672668967396
step: 80, loss: 0.00475113233551383
step: 90, loss: 0.030603138729929924
step: 100, loss: 0.008846224285662174
step: 110, loss: 0.010679950006306171
step: 120, loss: 0.00017940023099072278
step: 130, loss: 0.011845014989376068
step: 140, loss: 0.0005371402367018163
step: 150, loss: 0.04158598929643631
step: 160, loss: 0.0006382085266523063
step: 170, loss: 0.00029752732370980084
step: 180, loss: 0.01786053739488125
step: 190, loss: 0.0002065318258246407
step: 200, loss: 0.0007717998814769089
step: 210, loss: 0.00013902317732572556
step: 220, loss: 0.0001974231272470206
step: 230, loss: 0.08554065972566605
step: 240, loss: 0.1241227239370346
step: 250, loss: 0.009092932567000389
step: 260, loss: 0.004878943786025047
step: 270, loss: 0.0012086600763723254
step: 280, loss: 0.0028065636288374662
step: 290, loss: 0.023490022867918015
step: 300, loss: 0.0008024584967643023
step: 310, loss: 0.00291887647472322
step: 320, loss: 0.004217036999762058
step: 330, loss: 0.03701386600732803
step: 340, loss: 0.01975860632956028
step: 350, loss: 0.0008528651669621468
step: 360, loss: 0.0026366140227764845
step: 370, loss: 0.014402328059077263
step: 380, loss: 0.005482402630150318
step: 390, loss: 0.0011632491368800402
step: 400, loss: 0.01122700609266758
epoch 10: dev_f1=0.6636363636363636, f1=0.6726457399103138, best_f1=0.6849894291754756
step: 0, loss: 0.00036764604737982154
step: 10, loss: 0.00042883766582235694
step: 20, loss: 0.011329165659844875
step: 30, loss: 0.0002851653262041509
step: 40, loss: 0.018564140424132347
step: 50, loss: 0.012875872664153576
step: 60, loss: 0.03280718997120857
step: 70, loss: 0.0010837976587936282
step: 80, loss: 0.007098647765815258
step: 90, loss: 0.1566815823316574
step: 100, loss: 0.0007070883875712752
step: 110, loss: 0.05793185904622078
step: 120, loss: 0.007784195244312286
step: 130, loss: 0.002987681422382593
step: 140, loss: 0.020479045808315277
step: 150, loss: 0.0032009982969611883
step: 160, loss: 0.0019237552769482136
step: 170, loss: 0.0033784674014896154
step: 180, loss: 0.052134789526462555
step: 190, loss: 0.0020186963956803083
step: 200, loss: 0.008279184810817242
step: 210, loss: 0.011245331726968288
step: 220, loss: 0.0007430241093970835
step: 230, loss: 0.007930578663945198
step: 240, loss: 0.03302635997533798
step: 250, loss: 0.0012236065231263638
step: 260, loss: 0.02008630521595478
step: 270, loss: 0.08746003359556198
step: 280, loss: 0.004937732592225075
step: 290, loss: 0.018417369574308395
step: 300, loss: 0.00023837773187551647
step: 310, loss: 0.00028783766902051866
step: 320, loss: 0.03141525387763977
step: 330, loss: 0.0022445828653872013
step: 340, loss: 0.005436392035335302
step: 350, loss: 0.013807094655930996
step: 360, loss: 0.003535481868311763
step: 370, loss: 0.00132117816247046
step: 380, loss: 0.0003010647196788341
step: 390, loss: 0.0005444801645353436
step: 400, loss: 0.06319718807935715
epoch 11: dev_f1=0.6652267818574515, f1=0.6652542372881356, best_f1=0.6849894291754756
step: 0, loss: 0.006656920071691275
step: 10, loss: 0.0003530761750880629
step: 20, loss: 0.0006099868332967162
step: 30, loss: 0.02356654405593872
step: 40, loss: 0.00035199898411519825
step: 50, loss: 0.00015338936646003276
step: 60, loss: 0.025541620329022408
step: 70, loss: 0.0006218128837645054
step: 80, loss: 7.492591976188123e-05
step: 90, loss: 0.010399049147963524
step: 100, loss: 0.03663453087210655
step: 110, loss: 0.00034162154770456254
step: 120, loss: 0.023635055869817734
step: 130, loss: 0.00012511097884271294
step: 140, loss: 0.0003425595350563526
step: 150, loss: 0.21714285016059875
step: 160, loss: 0.0003335896471980959
step: 170, loss: 0.013457200489938259
step: 180, loss: 0.00025602985988371074
step: 190, loss: 0.014212612994015217
step: 200, loss: 0.031193813309073448
step: 210, loss: 0.0022019173484295607
step: 220, loss: 0.009836893528699875
step: 230, loss: 0.035539500415325165
step: 240, loss: 0.0008952919743023813
step: 250, loss: 0.02951553463935852
step: 260, loss: 0.002401664387434721
step: 270, loss: 0.006391916889697313
step: 280, loss: 0.0056300777941942215
step: 290, loss: 0.012926299124956131
step: 300, loss: 0.005204665008932352
step: 310, loss: 0.003713438520208001
step: 320, loss: 0.0001534874754725024
step: 330, loss: 0.07029915601015091
step: 340, loss: 0.08918266743421555
step: 350, loss: 0.0004978434881195426
step: 360, loss: 0.041779689490795135
step: 370, loss: 0.00013322982704266906
step: 380, loss: 0.0005740817287005484
step: 390, loss: 0.019800325855612755
step: 400, loss: 0.0005038294475525618
epoch 12: dev_f1=0.6593406593406593, f1=0.6651982378854626, best_f1=0.6849894291754756
step: 0, loss: 0.0007138701039366424
step: 10, loss: 0.0009656783659011126
step: 20, loss: 0.0002281975030200556
step: 30, loss: 0.00044133220217190683
step: 40, loss: 0.000689593842253089
step: 50, loss: 0.013942491263151169
step: 60, loss: 0.00022051791893318295
step: 70, loss: 0.00447772815823555
step: 80, loss: 0.002485681092366576
step: 90, loss: 0.0010134839685633779
step: 100, loss: 0.005515888333320618
step: 110, loss: 0.0006420405698008835
step: 120, loss: 0.0005804860848002136
step: 130, loss: 0.001971488120034337
step: 140, loss: 0.05408145859837532
step: 150, loss: 4.7461675421800464e-05
step: 160, loss: 0.0001233140501426533
step: 170, loss: 8.854693442117423e-05
step: 180, loss: 0.00018688751151785254
step: 190, loss: 0.019251760095357895
step: 200, loss: 0.0002998867421410978
step: 210, loss: 0.017628107219934464
step: 220, loss: 0.035669125616550446
step: 230, loss: 0.0010205680737271905
step: 240, loss: 0.00020091871556360275
step: 250, loss: 0.002522688591852784
step: 260, loss: 7.763804023852572e-05
step: 270, loss: 6.396717071766034e-05
step: 280, loss: 0.0113298324868083
step: 290, loss: 0.053596772253513336
step: 300, loss: 0.012551900930702686
step: 310, loss: 0.007121435832232237
step: 320, loss: 0.0018290927400812507
step: 330, loss: 0.0001280398719245568
step: 340, loss: 0.01545643713325262
step: 350, loss: 0.024216482415795326
step: 360, loss: 0.0020750868134200573
step: 370, loss: 0.0003135973820462823
step: 380, loss: 0.00022838744916953146
step: 390, loss: 0.05578802525997162
step: 400, loss: 0.004378690849989653
epoch 13: dev_f1=0.6455981941309257, f1=0.6444444444444445, best_f1=0.6849894291754756
step: 0, loss: 0.00012284028343856335
step: 10, loss: 0.0036673906724900007
step: 20, loss: 0.0002482195559423417
step: 30, loss: 0.001205777982249856
step: 40, loss: 0.0004358031146693975
step: 50, loss: 0.00016722941654734313
step: 60, loss: 0.004461849108338356
step: 70, loss: 0.0019188238075003028
step: 80, loss: 0.04785500839352608
step: 90, loss: 0.00013850763207301497
step: 100, loss: 5.3015261073596776e-05
step: 110, loss: 0.0023805375676602125
step: 120, loss: 0.0012272646417841315
step: 130, loss: 0.0017826834227889776
step: 140, loss: 0.06699012219905853
step: 150, loss: 0.004325021058320999
step: 160, loss: 0.002925806911662221
step: 170, loss: 0.0005282291676849127
step: 180, loss: 0.0008774080197326839
step: 190, loss: 0.002066671848297119
step: 200, loss: 0.00041325303027406335
step: 210, loss: 0.00012799720570910722
step: 220, loss: 0.00010402938642073423
step: 230, loss: 0.0003794612712226808
step: 240, loss: 0.0002765389217529446
step: 250, loss: 0.002071319380775094
step: 260, loss: 4.317398997955024e-05
step: 270, loss: 0.02057419903576374
step: 280, loss: 0.028705572709441185
step: 290, loss: 0.0002690163382794708
step: 300, loss: 0.029851699247956276
step: 310, loss: 0.005881157703697681
step: 320, loss: 6.755774666089565e-05
step: 330, loss: 4.339371662354097e-05
step: 340, loss: 0.00020709903037641197
step: 350, loss: 0.0003478805301710963
step: 360, loss: 0.002145736012607813
step: 370, loss: 0.0002879873209167272
step: 380, loss: 0.00026656987029127777
step: 390, loss: 0.0006993981078267097
step: 400, loss: 0.00025609240401536226
epoch 14: dev_f1=0.6623093681917211, f1=0.6807610993657505, best_f1=0.6849894291754756
step: 0, loss: 0.03638741746544838
step: 10, loss: 0.00027630338445305824
step: 20, loss: 0.00012528477236628532
step: 30, loss: 0.00025896693114191294
step: 40, loss: 0.0007336026756092906
step: 50, loss: 0.0005063874996267259
step: 60, loss: 0.0014077696250751615
step: 70, loss: 0.00030718647758476436
step: 80, loss: 0.11243564635515213
step: 90, loss: 0.0002624698681756854
step: 100, loss: 7.010481203906238e-05
step: 110, loss: 0.0008297403692267835
step: 120, loss: 4.497371628531255e-05
step: 130, loss: 0.0017286661313846707
step: 140, loss: 0.001928226207382977
step: 150, loss: 7.533200550824404e-05
step: 160, loss: 0.020698294043540955
step: 170, loss: 0.0006412250804714859
step: 180, loss: 9.428006887901574e-05
step: 190, loss: 0.0012303149560466409
step: 200, loss: 4.276487015886232e-05
step: 210, loss: 0.00011036899377359077
step: 220, loss: 0.006990604568272829
step: 230, loss: 0.0023669616784900427
step: 240, loss: 0.00022403063485398889
step: 250, loss: 0.0015409403713420033
step: 260, loss: 0.00014208223728928715
step: 270, loss: 7.909881242085248e-05
step: 280, loss: 0.0007182186236605048
step: 290, loss: 0.026403311640024185
step: 300, loss: 0.030243540182709694
step: 310, loss: 0.0007710017962381244
step: 320, loss: 0.0007349209045059979
step: 330, loss: 0.0010932813165709376
step: 340, loss: 0.004697318654507399
step: 350, loss: 0.00023685087217018008
step: 360, loss: 3.8532769394805655e-05
step: 370, loss: 4.939025529893115e-05
step: 380, loss: 0.0007324691978283226
step: 390, loss: 0.0018550349632278085
step: 400, loss: 0.0018042944138869643
epoch 15: dev_f1=0.6681715575620767, f1=0.6768558951965066, best_f1=0.6849894291754756
step: 0, loss: 0.0024493765085935593
step: 10, loss: 3.2260188163490966e-05
step: 20, loss: 0.0010527861304581165
step: 30, loss: 0.00013729746569879353
step: 40, loss: 2.9291342798387632e-05
step: 50, loss: 0.00024605978978797793
step: 60, loss: 0.00027651572600007057
step: 70, loss: 0.0001738423597998917
step: 80, loss: 0.0007548684370703995
step: 90, loss: 0.002228950848802924
step: 100, loss: 0.004119424149394035
step: 110, loss: 0.0011391110019758344
step: 120, loss: 0.0009795182850211859
step: 130, loss: 9.530210081720725e-05
step: 140, loss: 0.0005683128838427365
step: 150, loss: 0.0271940715610981
step: 160, loss: 0.021283980458974838
step: 170, loss: 0.024625394493341446
step: 180, loss: 0.00010054296581074595
step: 190, loss: 0.12248209118843079
step: 200, loss: 4.134742630412802e-05
step: 210, loss: 0.04614419490098953
step: 220, loss: 0.0007023761863820255
step: 230, loss: 0.001114026876166463
step: 240, loss: 0.0006948207737877965
step: 250, loss: 0.0024519485887140036
step: 260, loss: 0.0006618358893319964
step: 270, loss: 0.00029309766250662506
step: 280, loss: 0.0003559931938070804
step: 290, loss: 7.178298983490095e-05
step: 300, loss: 0.0004487618862185627
step: 310, loss: 0.01870184764266014
step: 320, loss: 0.00020173544180579484
step: 330, loss: 0.026873517781496048
step: 340, loss: 0.0005419785738922656
step: 350, loss: 0.031139230355620384
step: 360, loss: 0.004330763127654791
step: 370, loss: 0.0001207008317578584
step: 380, loss: 0.00012382953718770295
step: 390, loss: 0.00013618890079669654
step: 400, loss: 3.595160160330124e-05
epoch 16: dev_f1=0.6638115631691649, f1=0.6820083682008369, best_f1=0.6849894291754756
step: 0, loss: 0.1490478217601776
step: 10, loss: 0.0006376001983880997
step: 20, loss: 0.02255263552069664
step: 30, loss: 0.0010613248450681567
step: 40, loss: 0.0007527040434069932
step: 50, loss: 0.00034356091055087745
step: 60, loss: 0.015310914255678654
step: 70, loss: 9.627391409594566e-05
step: 80, loss: 5.350169521989301e-05
step: 90, loss: 0.00010165205458179116
step: 100, loss: 8.413162140641361e-05
step: 110, loss: 0.0045254905708134174
step: 120, loss: 0.02545017935335636
step: 130, loss: 7.174319762270898e-05
step: 140, loss: 0.034024856984615326
step: 150, loss: 0.0001216964956256561
step: 160, loss: 0.0018842899007722735
step: 170, loss: 0.04984859749674797
step: 180, loss: 0.022304145619273186
step: 190, loss: 0.0016811825335025787
step: 200, loss: 0.025263579562306404
step: 210, loss: 6.808286707382649e-05
step: 220, loss: 3.862555240630172e-05
step: 230, loss: 6.566485535586253e-05
step: 240, loss: 0.007118088658899069
step: 250, loss: 4.841111513087526e-05
step: 260, loss: 6.113138078944758e-05
step: 270, loss: 0.04692518338561058
step: 280, loss: 6.203162047313526e-05
step: 290, loss: 0.0029978679958730936
step: 300, loss: 5.056000372860581e-05
step: 310, loss: 9.66573425102979e-05
step: 320, loss: 3.1205505365505815e-05
step: 330, loss: 0.00013413347187452018
step: 340, loss: 0.0006034227553755045
step: 350, loss: 0.0014927523443475366
step: 360, loss: 0.00028400763403624296
step: 370, loss: 0.006589720491319895
step: 380, loss: 0.0003372302744537592
step: 390, loss: 0.010724269784986973
step: 400, loss: 3.6345882108435035e-05
epoch 17: dev_f1=0.6750524109014675, f1=0.6846473029045643, best_f1=0.6849894291754756
step: 0, loss: 0.002711912151426077
step: 10, loss: 0.0004403416533023119
step: 20, loss: 2.6333416826673783e-05
step: 30, loss: 0.00028756388928741217
step: 40, loss: 6.371764175128192e-05
step: 50, loss: 0.0005881515680812299
step: 60, loss: 2.6233024982502684e-05
step: 70, loss: 0.0003084736817982048
step: 80, loss: 0.00013059192860964686
step: 90, loss: 0.03325969725847244
step: 100, loss: 0.0010150712914764881
step: 110, loss: 0.0024767538998275995
step: 120, loss: 5.5618285841774195e-05
step: 130, loss: 7.414906576741487e-05
step: 140, loss: 0.007972817867994308
step: 150, loss: 0.00014646005001850426
step: 160, loss: 8.329593401867896e-05
step: 170, loss: 0.00382073107175529
step: 180, loss: 0.0002949305344372988
step: 190, loss: 7.79458787292242e-05
step: 200, loss: 0.000232897320529446
step: 210, loss: 0.008432349190115929
step: 220, loss: 2.5357474441989325e-05
step: 230, loss: 0.00030027818866074085
step: 240, loss: 0.0003644277458079159
step: 250, loss: 0.00011215214180992916
step: 260, loss: 0.0004096828633919358
step: 270, loss: 0.00010345121700083837
step: 280, loss: 3.284852937213145e-05
step: 290, loss: 4.388385423226282e-05
step: 300, loss: 0.00015501493180636317
step: 310, loss: 0.0017176145920529962
step: 320, loss: 0.024077974259853363
step: 330, loss: 5.5052216339390725e-05
step: 340, loss: 0.0009941770695149899
step: 350, loss: 0.000628629932180047
step: 360, loss: 0.007573333103209734
step: 370, loss: 0.0004150767344981432
step: 380, loss: 7.908755651442334e-05
step: 390, loss: 0.04673467576503754
step: 400, loss: 0.010078012943267822
epoch 18: dev_f1=0.6609071274298056, f1=0.6680584551148224, best_f1=0.6849894291754756
step: 0, loss: 5.7851157180266455e-05
step: 10, loss: 0.001334102125838399
step: 20, loss: 0.00026913831243291497
step: 30, loss: 8.418376091867685e-05
step: 40, loss: 0.006772990338504314
step: 50, loss: 0.001631752122193575
step: 60, loss: 0.00029664349858649075
step: 70, loss: 3.775410368689336e-05
step: 80, loss: 0.0006453573587350547
step: 90, loss: 7.904324593255296e-05
step: 100, loss: 0.001374334329739213
step: 110, loss: 0.0006661390652880073
step: 120, loss: 0.005237752106040716
step: 130, loss: 0.0001167719456134364
step: 140, loss: 0.00012847116158809513
step: 150, loss: 0.00013668404426425695
step: 160, loss: 0.06102672591805458
step: 170, loss: 0.00010811417450895533
step: 180, loss: 5.45943075849209e-05
step: 190, loss: 0.0003979668254032731
step: 200, loss: 5.67040333407931e-05
step: 210, loss: 7.483216904802248e-05
step: 220, loss: 0.0002876396756619215
step: 230, loss: 4.839083339902572e-05
step: 240, loss: 0.001270623179152608
step: 250, loss: 0.0002603065804578364
step: 260, loss: 0.0007736455299891531
step: 270, loss: 0.03481362760066986
step: 280, loss: 0.006110557354986668
step: 290, loss: 0.00028616987401619554
step: 300, loss: 0.00021745126286987215
step: 310, loss: 6.902345921844244e-05
step: 320, loss: 6.336491060210392e-05
step: 330, loss: 0.00035971973557025194
step: 340, loss: 0.001052643870934844
step: 350, loss: 3.9218088204506785e-05
step: 360, loss: 2.8362754164845683e-05
step: 370, loss: 7.644229481229559e-05
step: 380, loss: 3.936653956770897e-05
step: 390, loss: 2.3994029106688686e-05
step: 400, loss: 7.978539360919967e-05
epoch 19: dev_f1=0.6607142857142857, f1=0.6695464362850972, best_f1=0.6849894291754756
step: 0, loss: 0.0030141680035740137
step: 10, loss: 5.1643386541400105e-05
step: 20, loss: 1.9594712284742855e-05
step: 30, loss: 0.00016492261784151196
step: 40, loss: 0.00031602420494891703
step: 50, loss: 6.798744288971648e-05
step: 60, loss: 4.234537482261658e-05
step: 70, loss: 7.895975431893021e-05
step: 80, loss: 5.178898209123872e-05
step: 90, loss: 4.3370291678002104e-05
step: 100, loss: 0.00124841439537704
step: 110, loss: 0.00014131383795756847
step: 120, loss: 2.0961795598850586e-05
step: 130, loss: 2.0283672711229883e-05
step: 140, loss: 0.0005259488243609667
step: 150, loss: 7.679827831452712e-05
step: 160, loss: 0.003909073770046234
step: 170, loss: 3.2643365557305515e-05
step: 180, loss: 0.0007157573127187788
step: 190, loss: 0.0007732563535682857
step: 200, loss: 0.02956802397966385
step: 210, loss: 6.764955469407141e-05
step: 220, loss: 4.251189238857478e-05
step: 230, loss: 8.660557068651542e-05
step: 240, loss: 0.0012226981343701482
step: 250, loss: 4.096276097698137e-05
step: 260, loss: 0.00010056408791569993
step: 270, loss: 4.284899841877632e-05
step: 280, loss: 0.0011333645088598132
step: 290, loss: 8.002894901437685e-05
step: 300, loss: 0.0007932408479973674
step: 310, loss: 0.00019412509573157877
step: 320, loss: 4.080857615917921e-05
step: 330, loss: 0.00014746155648026615
step: 340, loss: 0.0006782610435038805
step: 350, loss: 0.0013202090049162507
step: 360, loss: 9.756406507221982e-05
step: 370, loss: 4.659316618926823e-05
step: 380, loss: 0.010021490976214409
step: 390, loss: 0.07040601968765259
step: 400, loss: 3.2606465538265184e-05
epoch 20: dev_f1=0.6651884700665189, f1=0.6666666666666666, best_f1=0.6849894291754756
