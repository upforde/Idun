cuda
Device: cuda
step: 0, loss: 0.5785384774208069
step: 10, loss: 0.014537972398102283
step: 20, loss: 0.10819794982671738
step: 30, loss: 0.13751710951328278
step: 40, loss: 0.2389245331287384
step: 50, loss: 0.06434398144483566
step: 60, loss: 0.13375505805015564
step: 70, loss: 0.14289715886116028
step: 80, loss: 0.2840169072151184
step: 90, loss: 0.19688552618026733
step: 100, loss: 0.20241740345954895
step: 110, loss: 0.18804877996444702
step: 120, loss: 0.15695811808109283
step: 130, loss: 0.15525265038013458
step: 140, loss: 0.14107513427734375
step: 150, loss: 0.24462676048278809
step: 160, loss: 0.2300291806459427
step: 170, loss: 0.08202701061964035
step: 180, loss: 0.19421198964118958
step: 190, loss: 0.1971699446439743
step: 200, loss: 0.06006057932972908
step: 210, loss: 0.2134220004081726
step: 220, loss: 0.16522224247455597
step: 230, loss: 0.22065198421478271
step: 240, loss: 0.0646001473069191
step: 250, loss: 0.07217766344547272
step: 260, loss: 0.10972855240106583
step: 270, loss: 0.23649296164512634
step: 280, loss: 0.04106346517801285
step: 290, loss: 0.0870479941368103
step: 300, loss: 0.18308505415916443
step: 310, loss: 0.1527765840291977
step: 320, loss: 0.21400147676467896
step: 330, loss: 0.1707868129014969
step: 340, loss: 0.12435203045606613
step: 350, loss: 0.08549316972494125
step: 360, loss: 0.1445726901292801
step: 370, loss: 0.15536881983280182
step: 380, loss: 0.1926821768283844
step: 390, loss: 0.0443195179104805
step: 400, loss: 0.041822779923677444
epoch 1: dev_f1=0.6270783847980999, f1=0.6057692307692307, best_f1=0.6057692307692307
step: 0, loss: 0.13311132788658142
step: 10, loss: 0.08408408612012863
step: 20, loss: 0.0371144562959671
step: 30, loss: 0.03080514818429947
step: 40, loss: 0.03321153670549393
step: 50, loss: 0.014680174179375172
step: 60, loss: 0.2288409024477005
step: 70, loss: 0.1145985871553421
step: 80, loss: 0.1841096431016922
step: 90, loss: 0.08555309474468231
step: 100, loss: 0.04634900763630867
step: 110, loss: 0.15536090731620789
step: 120, loss: 0.11543590575456619
step: 130, loss: 0.03951481357216835
step: 140, loss: 0.1279725730419159
step: 150, loss: 0.09345009177923203
step: 160, loss: 0.0829448401927948
step: 170, loss: 0.029066817834973335
step: 180, loss: 0.22358930110931396
step: 190, loss: 0.09192536771297455
step: 200, loss: 0.07896975427865982
step: 210, loss: 0.2614733874797821
step: 220, loss: 0.018749374896287918
step: 230, loss: 0.04390348494052887
step: 240, loss: 0.06676013767719269
step: 250, loss: 0.030096134170889854
step: 260, loss: 0.04443485289812088
step: 270, loss: 0.03833651915192604
step: 280, loss: 0.1841018944978714
step: 290, loss: 0.10196834802627563
step: 300, loss: 0.14177563786506653
step: 310, loss: 0.1657349169254303
step: 320, loss: 0.07075940072536469
step: 330, loss: 0.07219728082418442
step: 340, loss: 0.14435264468193054
step: 350, loss: 0.07232306897640228
step: 360, loss: 0.2824760973453522
step: 370, loss: 0.07249925285577774
step: 380, loss: 0.13189585506916046
step: 390, loss: 0.2219919115304947
step: 400, loss: 0.17049925029277802
epoch 2: dev_f1=0.689419795221843, f1=0.6998284734133791, best_f1=0.6998284734133791
step: 0, loss: 0.05624806880950928
step: 10, loss: 0.13074888288974762
step: 20, loss: 0.028212418779730797
step: 30, loss: 0.03668457642197609
step: 40, loss: 0.04074990749359131
step: 50, loss: 0.04354951158165932
step: 60, loss: 0.025269683450460434
step: 70, loss: 0.026986729353666306
step: 80, loss: 0.11766283959150314
step: 90, loss: 0.1536613553762436
step: 100, loss: 0.056896597146987915
step: 110, loss: 0.01832374930381775
step: 120, loss: 0.055789366364479065
step: 130, loss: 0.23579572141170502
step: 140, loss: 0.07621951401233673
step: 150, loss: 0.1045415997505188
step: 160, loss: 0.18752190470695496
step: 170, loss: 0.24646686017513275
step: 180, loss: 0.020963458344340324
step: 190, loss: 0.15099376440048218
step: 200, loss: 0.06067948415875435
step: 210, loss: 0.10095209628343582
step: 220, loss: 0.08066798746585846
step: 230, loss: 0.022994903847575188
step: 240, loss: 0.1745602786540985
step: 250, loss: 0.04186435788869858
step: 260, loss: 0.18042394518852234
step: 270, loss: 0.24653571844100952
step: 280, loss: 0.0302811898291111
step: 290, loss: 0.038838841021060944
step: 300, loss: 0.042165882885456085
step: 310, loss: 0.035585563629865646
step: 320, loss: 0.027177559211850166
step: 330, loss: 0.11524678021669388
step: 340, loss: 0.03504481539130211
step: 350, loss: 0.018971184268593788
step: 360, loss: 0.014934341423213482
step: 370, loss: 0.029741397127509117
step: 380, loss: 0.0077681513503193855
step: 390, loss: 0.08516445010900497
step: 400, loss: 0.10828668624162674
epoch 3: dev_f1=0.681081081081081, f1=0.6927374301675977, best_f1=0.6998284734133791
step: 0, loss: 0.07220771163702011
step: 10, loss: 0.026674795895814896
step: 20, loss: 0.0005506325396709144
step: 30, loss: 0.019419636577367783
step: 40, loss: 0.03344149887561798
step: 50, loss: 0.0038051146548241377
step: 60, loss: 0.09219019114971161
step: 70, loss: 0.057851772755384445
step: 80, loss: 0.06550320237874985
step: 90, loss: 0.029823830351233482
step: 100, loss: 0.028525274246931076
step: 110, loss: 0.14311033487319946
step: 120, loss: 0.15111257135868073
step: 130, loss: 0.0032807865645736456
step: 140, loss: 0.02277747169137001
step: 150, loss: 0.012070617638528347
step: 160, loss: 0.06611476838588715
step: 170, loss: 0.015188361518085003
step: 180, loss: 0.015758343040943146
step: 190, loss: 0.061286333948373795
step: 200, loss: 0.003113451646640897
step: 210, loss: 0.00483687873929739
step: 220, loss: 0.042968012392520905
step: 230, loss: 0.00413196487352252
step: 240, loss: 0.15367382764816284
step: 250, loss: 0.1686418354511261
step: 260, loss: 0.061890535056591034
step: 270, loss: 0.14368821680545807
step: 280, loss: 0.045562904328107834
step: 290, loss: 0.09272976219654083
step: 300, loss: 0.014345536008477211
step: 310, loss: 0.0609392374753952
step: 320, loss: 0.043652042746543884
step: 330, loss: 0.12160951644182205
step: 340, loss: 0.012013882398605347
step: 350, loss: 0.2988296449184418
step: 360, loss: 0.10486146062612534
step: 370, loss: 0.04687466844916344
step: 380, loss: 0.10336709767580032
step: 390, loss: 0.03458455577492714
step: 400, loss: 0.003793157171458006
epoch 4: dev_f1=0.6976744186046512, f1=0.6724137931034482, best_f1=0.6724137931034482
step: 0, loss: 0.02329115755856037
step: 10, loss: 0.09242915362119675
step: 20, loss: 0.10152026265859604
step: 30, loss: 0.05058640241622925
step: 40, loss: 0.0639597624540329
step: 50, loss: 0.05459347739815712
step: 60, loss: 0.0034121510107070208
step: 70, loss: 0.013329827226698399
step: 80, loss: 0.03138293698430061
step: 90, loss: 0.005599450320005417
step: 100, loss: 0.00567249208688736
step: 110, loss: 0.026798458769917488
step: 120, loss: 0.012255733832716942
step: 130, loss: 0.0038889891002327204
step: 140, loss: 0.07194069772958755
step: 150, loss: 0.005312693305313587
step: 160, loss: 0.009545007720589638
step: 170, loss: 0.0951559767127037
step: 180, loss: 0.10766275227069855
step: 190, loss: 0.017327234148979187
step: 200, loss: 0.0030048235785216093
step: 210, loss: 0.0034116217866539955
step: 220, loss: 0.02390207163989544
step: 230, loss: 0.03714832663536072
step: 240, loss: 0.004825367592275143
step: 250, loss: 0.002728087594732642
step: 260, loss: 0.04684014618396759
step: 270, loss: 0.017089292407035828
step: 280, loss: 0.011085025034844875
step: 290, loss: 0.026274126023054123
step: 300, loss: 0.03830529376864433
step: 310, loss: 0.050532016903162
step: 320, loss: 0.0027356352657079697
step: 330, loss: 0.012560306116938591
step: 340, loss: 0.013809054158627987
step: 350, loss: 0.2005668729543686
step: 360, loss: 0.05271529406309128
step: 370, loss: 0.09582595527172089
step: 380, loss: 0.07268491387367249
step: 390, loss: 0.03951988369226456
step: 400, loss: 0.01858230121433735
epoch 5: dev_f1=0.6884531590413945, f1=0.6607538802660754, best_f1=0.6724137931034482
step: 0, loss: 0.044456299394369125
step: 10, loss: 0.005290361121296883
step: 20, loss: 0.04481508955359459
step: 30, loss: 0.010459096170961857
step: 40, loss: 0.03128710761666298
step: 50, loss: 0.11591081321239471
step: 60, loss: 0.012455171905457973
step: 70, loss: 0.020682087168097496
step: 80, loss: 0.04162023589015007
step: 90, loss: 0.0007291818619705737
step: 100, loss: 0.02326117642223835
step: 110, loss: 0.00915246270596981
step: 120, loss: 0.03125283867120743
step: 130, loss: 0.006961515638977289
step: 140, loss: 0.04686886817216873
step: 150, loss: 0.07449202239513397
step: 160, loss: 0.045191023498773575
step: 170, loss: 0.00016248055908363312
step: 180, loss: 0.0034910908434540033
step: 190, loss: 0.025999538600444794
step: 200, loss: 0.008411316201090813
step: 210, loss: 0.04464060068130493
step: 220, loss: 0.02534761279821396
step: 230, loss: 0.015187607146799564
step: 240, loss: 0.017019540071487427
step: 250, loss: 0.00036343876854516566
step: 260, loss: 0.01732821576297283
step: 270, loss: 0.01523202657699585
step: 280, loss: 0.0055690607987344265
step: 290, loss: 0.01598614826798439
step: 300, loss: 0.011513945646584034
step: 310, loss: 0.0014676451683044434
step: 320, loss: 0.0047569721937179565
step: 330, loss: 0.03411766141653061
step: 340, loss: 0.0084533104673028
step: 350, loss: 0.05091961473226547
step: 360, loss: 0.009802850894629955
step: 370, loss: 0.03331010043621063
step: 380, loss: 0.0374872200191021
step: 390, loss: 0.06651603430509567
step: 400, loss: 0.005952826235443354
epoch 6: dev_f1=0.6796875, f1=0.6944444444444444, best_f1=0.6724137931034482
step: 0, loss: 0.014970913529396057
step: 10, loss: 0.00035591909545473754
step: 20, loss: 0.037028051912784576
step: 30, loss: 0.011332917958498001
step: 40, loss: 0.008934268727898598
step: 50, loss: 0.07598668336868286
step: 60, loss: 0.00026748617528937757
step: 70, loss: 0.024739881977438927
step: 80, loss: 0.06283842772245407
step: 90, loss: 0.04915058612823486
step: 100, loss: 0.0500904880464077
step: 110, loss: 0.005982344038784504
step: 120, loss: 0.13372664153575897
step: 130, loss: 0.002728717867285013
step: 140, loss: 0.09864652901887894
step: 150, loss: 0.021436292678117752
step: 160, loss: 0.0031272529158741236
step: 170, loss: 0.004202729556709528
step: 180, loss: 0.014543267898261547
step: 190, loss: 0.0593966543674469
step: 200, loss: 0.1053413525223732
step: 210, loss: 0.0007961390656419098
step: 220, loss: 0.062354788184165955
step: 230, loss: 0.016124838963150978
step: 240, loss: 0.006237377412617207
step: 250, loss: 0.03903518244624138
step: 260, loss: 0.014375821687281132
step: 270, loss: 0.019536111503839493
step: 280, loss: 0.10575926303863525
step: 290, loss: 0.0008594619575887918
step: 300, loss: 0.0323491208255291
step: 310, loss: 0.07887040078639984
step: 320, loss: 0.033910755068063736
step: 330, loss: 0.005525835324078798
step: 340, loss: 0.011792201548814774
step: 350, loss: 0.01613593101501465
step: 360, loss: 0.020875535905361176
step: 370, loss: 0.10061675310134888
step: 380, loss: 0.024806512519717216
step: 390, loss: 0.05647539719939232
step: 400, loss: 0.011567306704819202
epoch 7: dev_f1=0.6832298136645963, f1=0.6952965235173825, best_f1=0.6724137931034482
step: 0, loss: 0.03222440183162689
step: 10, loss: 0.05993643030524254
step: 20, loss: 0.1082371175289154
step: 30, loss: 0.06916993111371994
step: 40, loss: 0.024781884625554085
step: 50, loss: 0.049170639365911484
step: 60, loss: 0.009555681608617306
step: 70, loss: 0.001721177832223475
step: 80, loss: 0.015471113845705986
step: 90, loss: 0.014562839642167091
step: 100, loss: 0.004070485010743141
step: 110, loss: 0.0003871693625114858
step: 120, loss: 0.01972217485308647
step: 130, loss: 0.004206623416393995
step: 140, loss: 0.05900626257061958
step: 150, loss: 0.004588933661580086
step: 160, loss: 0.030294325202703476
step: 170, loss: 0.0016837085131555796
step: 180, loss: 0.0352325476706028
step: 190, loss: 0.0009707906865514815
step: 200, loss: 0.049930401146411896
step: 210, loss: 0.0016573338070884347
step: 220, loss: 0.025419417768716812
step: 230, loss: 0.01008249819278717
step: 240, loss: 0.007491713389754295
step: 250, loss: 0.0019383991602808237
step: 260, loss: 0.0018387016607448459
step: 270, loss: 0.06202024221420288
step: 280, loss: 0.007954071275889874
step: 290, loss: 0.0003950877289753407
step: 300, loss: 0.013209786266088486
step: 310, loss: 0.00030309095745906234
step: 320, loss: 0.006909277755767107
step: 330, loss: 0.008045661263167858
step: 340, loss: 0.0010573704494163394
step: 350, loss: 0.000979483826085925
step: 360, loss: 0.1566600352525711
step: 370, loss: 0.004821556154638529
step: 380, loss: 0.0040222289972007275
step: 390, loss: 0.0029205135069787502
step: 400, loss: 0.0035643514711409807
epoch 8: dev_f1=0.6787148594377509, f1=0.6993865030674846, best_f1=0.6724137931034482
step: 0, loss: 0.005594434216618538
step: 10, loss: 0.0005942789721302688
step: 20, loss: 0.0023460385855287313
step: 30, loss: 0.03974730893969536
step: 40, loss: 0.005441713612526655
step: 50, loss: 0.01498416904360056
step: 60, loss: 0.07335630804300308
step: 70, loss: 0.0446024164557457
step: 80, loss: 0.0012918722350150347
step: 90, loss: 0.060213107615709305
step: 100, loss: 0.03458896651864052
step: 110, loss: 0.0005049865576438606
step: 120, loss: 5.3107491112314165e-05
step: 130, loss: 0.0033868644386529922
step: 140, loss: 0.00853748433291912
step: 150, loss: 8.700980833964422e-05
step: 160, loss: 0.0003767887828871608
step: 170, loss: 0.010561132803559303
step: 180, loss: 0.00022065133089199662
step: 190, loss: 0.0007778048748150468
step: 200, loss: 0.003613682696595788
step: 210, loss: 0.0026334598660469055
step: 220, loss: 0.006371422670781612
step: 230, loss: 0.014579872600734234
step: 240, loss: 0.04086904972791672
step: 250, loss: 0.017160765826702118
step: 260, loss: 0.015701066702604294
step: 270, loss: 0.00043853948591277003
step: 280, loss: 0.006385713815689087
step: 290, loss: 0.007409567479044199
step: 300, loss: 0.00553445890545845
step: 310, loss: 0.0055424245074391365
step: 320, loss: 0.008859873749315739
step: 330, loss: 0.008618953637778759
step: 340, loss: 0.007337619084864855
step: 350, loss: 0.008817494846880436
step: 360, loss: 0.005387163255363703
step: 370, loss: 0.006820364389568567
step: 380, loss: 0.012705814093351364
step: 390, loss: 0.012859808281064034
step: 400, loss: 0.015626924112439156
epoch 9: dev_f1=0.7052023121387283, f1=0.6858237547892722, best_f1=0.6858237547892722
step: 0, loss: 0.0034454865381121635
step: 10, loss: 0.04353993386030197
step: 20, loss: 0.08786319941282272
step: 30, loss: 0.0014641088200733066
step: 40, loss: 0.001018579350784421
step: 50, loss: 0.005052765365689993
step: 60, loss: 0.011753716506063938
step: 70, loss: 0.015188613906502724
step: 80, loss: 0.014691609889268875
step: 90, loss: 0.001428612507879734
step: 100, loss: 0.0006314915954135358
step: 110, loss: 0.0009165321243926883
step: 120, loss: 0.0008594667888246477
step: 130, loss: 8.337237522937357e-05
step: 140, loss: 0.001625300501473248
step: 150, loss: 0.008220260962843895
step: 160, loss: 0.002330564893782139
step: 170, loss: 0.0004232620703987777
step: 180, loss: 0.00012624608643818647
step: 190, loss: 0.004448845982551575
step: 200, loss: 0.0001611086045159027
step: 210, loss: 0.0008380634826608002
step: 220, loss: 0.00946131069213152
step: 230, loss: 0.01295046228915453
step: 240, loss: 0.035452935844659805
step: 250, loss: 0.0026591429486870766
step: 260, loss: 0.006992017384618521
step: 270, loss: 0.02186228334903717
step: 280, loss: 0.007761790417134762
step: 290, loss: 0.0036081806756556034
step: 300, loss: 0.01221565529704094
step: 310, loss: 0.02333521470427513
step: 320, loss: 0.02829316444694996
step: 330, loss: 0.004994986113160849
step: 340, loss: 0.023646561428904533
step: 350, loss: 0.0033974526450037956
step: 360, loss: 0.12087973952293396
step: 370, loss: 0.01925799250602722
step: 380, loss: 0.0004156420473009348
step: 390, loss: 0.09274331480264664
step: 400, loss: 0.00010875127190956846
epoch 10: dev_f1=0.6843267108167771, f1=0.6799116997792494, best_f1=0.6858237547892722
step: 0, loss: 0.014873519539833069
step: 10, loss: 0.00018952084064949304
step: 20, loss: 0.006593553815037012
step: 30, loss: 0.00019897385209333152
step: 40, loss: 0.00045634174603037536
step: 50, loss: 0.00774367107078433
step: 60, loss: 0.05477391183376312
step: 70, loss: 0.0004515309992711991
step: 80, loss: 0.0004908975679427385
step: 90, loss: 0.0009053327376022935
step: 100, loss: 0.014703851193189621
step: 110, loss: 0.04108702018857002
step: 120, loss: 0.0005121628637425601
step: 130, loss: 0.05678937956690788
step: 140, loss: 0.0028535162564367056
step: 150, loss: 0.03233399614691734
step: 160, loss: 0.011579092592000961
step: 170, loss: 0.005929573439061642
step: 180, loss: 0.021350597962737083
step: 190, loss: 0.0019641711842268705
step: 200, loss: 0.0006964444182813168
step: 210, loss: 0.00994310062378645
step: 220, loss: 0.06480672955513
step: 230, loss: 0.0031316254753619432
step: 240, loss: 0.00043145494419150054
step: 250, loss: 0.0014892169274389744
step: 260, loss: 0.04160832613706589
step: 270, loss: 0.04486590996384621
step: 280, loss: 0.011244903318583965
step: 290, loss: 0.001139882137067616
step: 300, loss: 0.000306059344438836
step: 310, loss: 0.08129888772964478
step: 320, loss: 0.00013739080168306828
step: 330, loss: 0.001842569443397224
step: 340, loss: 0.007450451608747244
step: 350, loss: 0.00455714063718915
step: 360, loss: 0.10787004232406616
step: 370, loss: 0.00038204589509405196
step: 380, loss: 0.0007872704300098121
step: 390, loss: 0.0016630575992166996
step: 400, loss: 0.0007031686836853623
epoch 11: dev_f1=0.6858237547892722, f1=0.700952380952381, best_f1=0.6858237547892722
step: 0, loss: 0.005127986893057823
step: 10, loss: 0.0016711247153580189
step: 20, loss: 0.05035155266523361
step: 30, loss: 9.71000044955872e-05
step: 40, loss: 0.002277059480547905
step: 50, loss: 0.0020136754028499126
step: 60, loss: 0.0003054306434933096
step: 70, loss: 0.008353892713785172
step: 80, loss: 0.09686246514320374
step: 90, loss: 0.00015301466919481754
step: 100, loss: 0.0002759914204943925
step: 110, loss: 0.006862869020551443
step: 120, loss: 0.00027448893524706364
step: 130, loss: 4.557487045531161e-05
step: 140, loss: 0.01042614784091711
step: 150, loss: 0.0017861189553514123
step: 160, loss: 0.0007803434855304658
step: 170, loss: 0.12573139369487762
step: 180, loss: 0.0002509636105969548
step: 190, loss: 0.005328962113708258
step: 200, loss: 0.001783159445039928
step: 210, loss: 0.00010837968875421211
step: 220, loss: 0.000760361785069108
step: 230, loss: 0.014256189577281475
step: 240, loss: 0.018842412158846855
step: 250, loss: 0.0009199481573887169
step: 260, loss: 0.013737092725932598
step: 270, loss: 0.0018129979725927114
step: 280, loss: 0.00012231216533109546
step: 290, loss: 0.012957479804754257
step: 300, loss: 0.004816489759832621
step: 310, loss: 0.01832200586795807
step: 320, loss: 0.007645093835890293
step: 330, loss: 0.002881322056055069
step: 340, loss: 0.0014866313431411982
step: 350, loss: 0.0002557941770646721
step: 360, loss: 0.0016118453349918127
step: 370, loss: 0.0029060207307338715
step: 380, loss: 0.017178287729620934
step: 390, loss: 0.002724466845393181
step: 400, loss: 6.472747190855443e-05
epoch 12: dev_f1=0.6741573033707866, f1=0.6577181208053691, best_f1=0.6858237547892722
step: 0, loss: 0.00011787191033363342
step: 10, loss: 0.00011444231495261192
step: 20, loss: 0.0004277525586076081
step: 30, loss: 0.00028010885580442846
step: 40, loss: 0.002631781855598092
step: 50, loss: 0.015118705108761787
step: 60, loss: 0.10937316715717316
step: 70, loss: 0.033785346895456314
step: 80, loss: 0.0023373672738671303
step: 90, loss: 0.004229956306517124
step: 100, loss: 0.02360965684056282
step: 110, loss: 0.028557468205690384
step: 120, loss: 0.00022204765991773456
step: 130, loss: 0.0012195351300761104
step: 140, loss: 0.019581962376832962
step: 150, loss: 0.00021821285190526396
step: 160, loss: 0.0016193119809031487
step: 170, loss: 8.903884008759633e-05
step: 180, loss: 0.008553653955459595
step: 190, loss: 0.10233993083238602
step: 200, loss: 0.0006941815954633057
step: 210, loss: 0.0010003084316849709
step: 220, loss: 0.07207604497671127
step: 230, loss: 0.00043624185491353273
step: 240, loss: 4.16578259319067e-05
step: 250, loss: 0.04257645830512047
step: 260, loss: 0.05871138349175453
step: 270, loss: 0.003696943400427699
step: 280, loss: 0.0024958872236311436
step: 290, loss: 0.02592972293496132
step: 300, loss: 0.0010417484445497394
step: 310, loss: 2.662421866261866e-05
step: 320, loss: 0.006038202438503504
step: 330, loss: 0.0004983393009752035
step: 340, loss: 6.378198304446414e-05
step: 350, loss: 9.562124614603817e-05
step: 360, loss: 0.0012484986800700426
step: 370, loss: 0.01817191392183304
step: 380, loss: 0.00013034060248173773
step: 390, loss: 0.0008136602118611336
step: 400, loss: 0.006558181252330542
epoch 13: dev_f1=0.685589519650655, f1=0.6739130434782609, best_f1=0.6858237547892722
step: 0, loss: 0.0005875853821635246
step: 10, loss: 0.0013292519142851233
step: 20, loss: 0.0012475245166569948
step: 30, loss: 0.009256691671907902
step: 40, loss: 0.00011710258695529774
step: 50, loss: 0.0011208585929125547
step: 60, loss: 0.0005135200335644186
step: 70, loss: 0.00023435115872416645
step: 80, loss: 0.00023175253591034561
step: 90, loss: 0.003647101577371359
step: 100, loss: 0.00013628955639433116
step: 110, loss: 0.0025349424686282873
step: 120, loss: 0.005670695565640926
step: 130, loss: 0.0001013426372082904
step: 140, loss: 0.005546695087105036
step: 150, loss: 7.608180021634325e-05
step: 160, loss: 0.0001200605693156831
step: 170, loss: 0.007244108244776726
step: 180, loss: 3.0941402656026185e-05
step: 190, loss: 0.001164731802418828
step: 200, loss: 0.06362312287092209
step: 210, loss: 7.18865921953693e-05
step: 220, loss: 0.00013588956790044904
step: 230, loss: 0.0001674917439231649
step: 240, loss: 3.080366150243208e-05
step: 250, loss: 0.0020824717357754707
step: 260, loss: 0.0004329975345171988
step: 270, loss: 6.945816130610183e-05
step: 280, loss: 4.332452590460889e-05
step: 290, loss: 0.06726286560297012
step: 300, loss: 0.025222379714250565
step: 310, loss: 0.023074155673384666
step: 320, loss: 0.012904769740998745
step: 330, loss: 0.017230946570634842
step: 340, loss: 0.0015534249832853675
step: 350, loss: 0.033195868134498596
step: 360, loss: 7.544229447375983e-05
step: 370, loss: 0.008546729572117329
step: 380, loss: 2.7465775929158553e-05
step: 390, loss: 7.371014362433925e-05
step: 400, loss: 0.00027213836438022554
epoch 14: dev_f1=0.6724511930585683, f1=0.673728813559322, best_f1=0.6858237547892722
step: 0, loss: 0.0010358324507251382
step: 10, loss: 0.0001778559380909428
step: 20, loss: 2.596476042526774e-05
step: 30, loss: 6.868151831440628e-05
step: 40, loss: 0.045771703124046326
step: 50, loss: 0.00035903576645068824
step: 60, loss: 0.00011000746599165723
step: 70, loss: 0.00013416357978712767
step: 80, loss: 0.04708163067698479
step: 90, loss: 0.00016248483734671026
step: 100, loss: 3.613159788073972e-05
step: 110, loss: 8.30550561659038e-05
step: 120, loss: 3.518620360409841e-05
step: 130, loss: 0.01767653040587902
step: 140, loss: 0.00021319114603102207
step: 150, loss: 0.19389210641384125
step: 160, loss: 0.024748163297772408
step: 170, loss: 0.00015632838767487556
step: 180, loss: 0.0002181286399718374
step: 190, loss: 7.956237095640972e-05
step: 200, loss: 0.0009364525321871042
step: 210, loss: 0.004189257975667715
step: 220, loss: 9.213422163156793e-05
step: 230, loss: 0.000908448884729296
step: 240, loss: 0.0018907836638391018
step: 250, loss: 4.918141712551005e-05
step: 260, loss: 0.017887668684124947
step: 270, loss: 0.10961271822452545
step: 280, loss: 0.00021584094793070108
step: 290, loss: 9.902777674142271e-05
step: 300, loss: 0.0010167432483285666
step: 310, loss: 0.004949640017002821
step: 320, loss: 0.020752551034092903
step: 330, loss: 0.0003836701507680118
step: 340, loss: 0.0017936115618795156
step: 350, loss: 0.00031023527844808996
step: 360, loss: 0.0003413975064177066
step: 370, loss: 5.163534660823643e-05
step: 380, loss: 0.00310099171474576
step: 390, loss: 0.009311860427260399
step: 400, loss: 0.0006084026535972953
epoch 15: dev_f1=0.6870897155361051, f1=0.654945054945055, best_f1=0.6858237547892722
step: 0, loss: 0.00010782208119053394
step: 10, loss: 0.002019366715103388
step: 20, loss: 3.3169129892485216e-05
step: 30, loss: 0.022800805047154427
step: 40, loss: 0.011224623769521713
step: 50, loss: 0.012909874320030212
step: 60, loss: 0.0009901236044242978
step: 70, loss: 5.865784623892978e-05
step: 80, loss: 0.0004504320095293224
step: 90, loss: 0.00033519123098813
step: 100, loss: 0.004292227793484926
step: 110, loss: 0.018462231382727623
step: 120, loss: 0.00010622214176692069
step: 130, loss: 0.0026301464531570673
step: 140, loss: 4.546458876575343e-05
step: 150, loss: 0.00033352774335071445
step: 160, loss: 0.0006131231202743948
step: 170, loss: 0.0016792021924629807
step: 180, loss: 0.004708581138402224
step: 190, loss: 5.328395127435215e-05
step: 200, loss: 0.05673141032457352
step: 210, loss: 6.970119284233078e-05
step: 220, loss: 0.0008449101587757468
step: 230, loss: 0.03771853819489479
step: 240, loss: 0.0002167085331166163
step: 250, loss: 0.0005454615456983447
step: 260, loss: 5.4001371609047055e-05
step: 270, loss: 0.08007589727640152
step: 280, loss: 0.00412884633988142
step: 290, loss: 4.985463237971999e-05
step: 300, loss: 0.0008262249175459146
step: 310, loss: 0.0008792430744506419
step: 320, loss: 0.00036996457492932677
step: 330, loss: 0.049293823540210724
step: 340, loss: 0.0001022701253532432
step: 350, loss: 0.025876382365822792
step: 360, loss: 3.907300560967997e-05
step: 370, loss: 5.4293108405545354e-05
step: 380, loss: 0.000867924652993679
step: 390, loss: 0.00018750771414488554
step: 400, loss: 0.0001828954555094242
epoch 16: dev_f1=0.6451612903225806, f1=0.6467889908256881, best_f1=0.6858237547892722
step: 0, loss: 0.0007019484764896333
step: 10, loss: 0.13056935369968414
step: 20, loss: 3.257324715377763e-05
step: 30, loss: 0.0004082962987013161
step: 40, loss: 0.011779987253248692
step: 50, loss: 0.007997017353773117
step: 60, loss: 0.002749457722529769
step: 70, loss: 0.0010003630304709077
step: 80, loss: 0.0011586297769099474
step: 90, loss: 0.04675529524683952
step: 100, loss: 2.7540550945559517e-05
step: 110, loss: 5.082421921542846e-05
step: 120, loss: 0.0003444961039349437
step: 130, loss: 0.00018602804630063474
step: 140, loss: 0.0003422885783948004
step: 150, loss: 0.00014061584079172462
step: 160, loss: 7.472128345398232e-05
step: 170, loss: 0.003711981698870659
step: 180, loss: 0.008973633870482445
step: 190, loss: 0.0010845479555428028
step: 200, loss: 0.0003828890039585531
step: 210, loss: 0.0013484283117577434
step: 220, loss: 8.735083974897861e-05
step: 230, loss: 0.00018732759053818882
step: 240, loss: 0.00015764034469611943
step: 250, loss: 0.0009163516806438565
step: 260, loss: 0.0002621553430799395
step: 270, loss: 8.218473521992564e-05
step: 280, loss: 0.00018661694775801152
step: 290, loss: 3.456963167991489e-05
step: 300, loss: 0.00035188032779842615
step: 310, loss: 0.0027224335353821516
step: 320, loss: 0.00015481506125070155
step: 330, loss: 3.909127553924918e-05
step: 340, loss: 0.006217258051037788
step: 350, loss: 0.017645319923758507
step: 360, loss: 0.00014820278738625348
step: 370, loss: 9.74090289673768e-05
step: 380, loss: 9.430004865862429e-05
step: 390, loss: 2.7723042876459658e-05
step: 400, loss: 0.0004003978392574936
epoch 17: dev_f1=0.6752688172043011, f1=0.6623093681917211, best_f1=0.6858237547892722
step: 0, loss: 5.329753184923902e-05
step: 10, loss: 0.032928287982940674
step: 20, loss: 0.004058238118886948
step: 30, loss: 0.00024410065088886768
step: 40, loss: 0.001098064472898841
step: 50, loss: 5.780300125479698e-05
step: 60, loss: 4.135534618399106e-05
step: 70, loss: 0.00016613521438557655
step: 80, loss: 8.251866529462859e-05
step: 90, loss: 0.0016869158716872334
step: 100, loss: 0.0001195063377963379
step: 110, loss: 5.951127241132781e-05
step: 120, loss: 0.004804524127393961
step: 130, loss: 0.00025930587435141206
step: 140, loss: 0.00038999345269985497
step: 150, loss: 5.205913839745335e-05
step: 160, loss: 0.00011597432603593916
step: 170, loss: 0.00011139229172840714
step: 180, loss: 0.00017609357018955052
step: 190, loss: 0.004213515669107437
step: 200, loss: 0.02390533685684204
step: 210, loss: 6.0437905631260946e-05
step: 220, loss: 6.453592504840344e-05
step: 230, loss: 5.3197116358205676e-05
step: 240, loss: 0.00041151195182465017
step: 250, loss: 9.9338183645159e-05
step: 260, loss: 4.269542114343494e-05
step: 270, loss: 9.705123375169933e-05
step: 280, loss: 0.0014194025425240397
step: 290, loss: 3.6621640902012587e-05
step: 300, loss: 0.0001724278408801183
step: 310, loss: 4.284550959710032e-05
step: 320, loss: 0.0008682885090820491
step: 330, loss: 7.63883872423321e-05
step: 340, loss: 0.010905591771006584
step: 350, loss: 3.487333742668852e-05
step: 360, loss: 0.00012138167949160561
step: 370, loss: 0.00013172718172427267
step: 380, loss: 0.010561014525592327
step: 390, loss: 8.277539745904505e-05
step: 400, loss: 0.0001242702128365636
epoch 18: dev_f1=0.6710526315789473, f1=0.6505494505494506, best_f1=0.6858237547892722
step: 0, loss: 0.002105042105540633
step: 10, loss: 0.00015013742086011916
step: 20, loss: 0.038626331835985184
step: 30, loss: 0.00017537237727083266
step: 40, loss: 2.4843431674526073e-05
step: 50, loss: 0.0033508301712572575
step: 60, loss: 0.00012727247667498887
step: 70, loss: 4.9714435590431094e-05
step: 80, loss: 0.00381563906557858
step: 90, loss: 2.8467964511946775e-05
step: 100, loss: 5.055817746324465e-05
step: 110, loss: 0.0004143786209169775
step: 120, loss: 7.606697909068316e-05
step: 130, loss: 0.0006725471466779709
step: 140, loss: 2.215402855654247e-05
step: 150, loss: 0.21120543777942657
step: 160, loss: 0.001641912735067308
step: 170, loss: 0.00022967458062339574
step: 180, loss: 0.0008335079764947295
step: 190, loss: 4.939059726893902e-05
step: 200, loss: 0.00020297257287893444
step: 210, loss: 3.979171742685139e-05
step: 220, loss: 5.157850682735443e-05
step: 230, loss: 0.042066629976034164
step: 240, loss: 0.0004184729477856308
step: 250, loss: 0.0060531264171004295
step: 260, loss: 0.0001415296137565747
step: 270, loss: 0.0024733697064220905
step: 280, loss: 0.00016479770420119166
step: 290, loss: 0.0002701060438994318
step: 300, loss: 5.971661084913649e-05
step: 310, loss: 0.0001247390464413911
step: 320, loss: 0.0004218551912344992
step: 330, loss: 5.6462456996086985e-05
step: 340, loss: 0.00014494471543002874
step: 350, loss: 0.04362533241510391
step: 360, loss: 5.981800859444775e-05
step: 370, loss: 0.003065434517338872
step: 380, loss: 0.0001257343974430114
step: 390, loss: 0.00013800222950521857
step: 400, loss: 0.00030582206090912223
epoch 19: dev_f1=0.6636971046770601, f1=0.6516853932584269, best_f1=0.6858237547892722
step: 0, loss: 0.035000238567590714
step: 10, loss: 0.0025289312470704317
step: 20, loss: 0.00011118742258986458
step: 30, loss: 0.018183862790465355
step: 40, loss: 2.9704038752242923e-05
step: 50, loss: 0.010273382067680359
step: 60, loss: 0.0013599066296592355
step: 70, loss: 0.0004153650370426476
step: 80, loss: 0.0016278534894809127
step: 90, loss: 0.015951387584209442
step: 100, loss: 3.889985600835644e-05
step: 110, loss: 5.8249130233889446e-05
step: 120, loss: 0.00012424458691384643
step: 130, loss: 0.0002869646705221385
step: 140, loss: 0.012110481038689613
step: 150, loss: 9.49734530877322e-05
step: 160, loss: 5.9147954743821174e-05
step: 170, loss: 0.00010971329902531579
step: 180, loss: 0.0001104746843338944
step: 190, loss: 0.00792454369366169
step: 200, loss: 0.0064293877221643925
step: 210, loss: 0.15080522000789642
step: 220, loss: 0.0014294893480837345
step: 230, loss: 6.491593376267701e-05
step: 240, loss: 0.017938915640115738
step: 250, loss: 0.008621261455118656
step: 260, loss: 8.628379146102816e-05
step: 270, loss: 0.00011484396236483008
step: 280, loss: 3.3831758628366515e-05
step: 290, loss: 0.010764305479824543
step: 300, loss: 0.00045492907520383596
step: 310, loss: 0.0025603764224797487
step: 320, loss: 0.0005477647646330297
step: 330, loss: 0.004741714335978031
step: 340, loss: 0.0003971628029830754
step: 350, loss: 0.0017919522942975163
step: 360, loss: 0.00029000747599639
step: 370, loss: 0.0019489018013700843
step: 380, loss: 0.00020064697309862822
step: 390, loss: 6.6234621044714e-05
step: 400, loss: 0.0001751807430991903
epoch 20: dev_f1=0.6637168141592921, f1=0.6577777777777778, best_f1=0.6858237547892722
cuda
Device: cuda
step: 0, loss: 0.5748866200447083
step: 10, loss: 0.014227762818336487
step: 20, loss: 0.10347389429807663
step: 30, loss: 0.13876311480998993
step: 40, loss: 0.23166902363300323
step: 50, loss: 0.06846991926431656
step: 60, loss: 0.13268020749092102
step: 70, loss: 0.14380134642124176
step: 80, loss: 0.2541418969631195
step: 90, loss: 0.13014395534992218
step: 100, loss: 0.2054539918899536
step: 110, loss: 0.2077585756778717
step: 120, loss: 0.09571124613285065
step: 130, loss: 0.17705778777599335
step: 140, loss: 0.1603976935148239
step: 150, loss: 0.20731088519096375
step: 160, loss: 0.23541490733623505
step: 170, loss: 0.08088652789592743
step: 180, loss: 0.17739814519882202
step: 190, loss: 0.2023889273405075
step: 200, loss: 0.08369409292936325
step: 210, loss: 0.1675775647163391
step: 220, loss: 0.1735699623823166
step: 230, loss: 0.26107195019721985
step: 240, loss: 0.047245338559150696
step: 250, loss: 0.04928961768746376
step: 260, loss: 0.08307433873414993
step: 270, loss: 0.14729899168014526
step: 280, loss: 0.05314799025654793
step: 290, loss: 0.056799910962581635
step: 300, loss: 0.18660183250904083
step: 310, loss: 0.10742297023534775
step: 320, loss: 0.18368400633335114
step: 330, loss: 0.1837628185749054
step: 340, loss: 0.12161128968000412
step: 350, loss: 0.0940813273191452
step: 360, loss: 0.10507335513830185
step: 370, loss: 0.1646321415901184
step: 380, loss: 0.14834795892238617
step: 390, loss: 0.042198970913887024
step: 400, loss: 0.06050010025501251
epoch 1: dev_f1=0.6372093023255814, f1=0.6211764705882353, best_f1=0.6211764705882353
step: 0, loss: 0.13932131230831146
step: 10, loss: 0.07212559878826141
step: 20, loss: 0.03440539166331291
step: 30, loss: 0.021994182839989662
step: 40, loss: 0.03371540084481239
step: 50, loss: 0.014043614268302917
step: 60, loss: 0.1873319447040558
step: 70, loss: 0.07239076495170593
step: 80, loss: 0.13989706337451935
step: 90, loss: 0.08151906728744507
step: 100, loss: 0.04256231337785721
step: 110, loss: 0.23481090366840363
step: 120, loss: 0.08554588258266449
step: 130, loss: 0.037218037992715836
step: 140, loss: 0.10077599436044693
step: 150, loss: 0.07265874743461609
step: 160, loss: 0.1310146450996399
step: 170, loss: 0.012285488657653332
step: 180, loss: 0.18953484296798706
step: 190, loss: 0.07444728165864944
step: 200, loss: 0.07161416113376617
step: 210, loss: 0.2788255214691162
step: 220, loss: 0.037192340940237045
step: 230, loss: 0.02591840736567974
step: 240, loss: 0.05780782923102379
step: 250, loss: 0.03745001181960106
step: 260, loss: 0.06596466898918152
step: 270, loss: 0.06356702744960785
step: 280, loss: 0.11288300901651382
step: 290, loss: 0.1583571881055832
step: 300, loss: 0.16374719142913818
step: 310, loss: 0.11022702604532242
step: 320, loss: 0.04378233477473259
step: 330, loss: 0.10626662522554398
step: 340, loss: 0.20363692939281464
step: 350, loss: 0.0756886899471283
step: 360, loss: 0.13817836344242096
step: 370, loss: 0.075033999979496
step: 380, loss: 0.10155948251485825
step: 390, loss: 0.15855225920677185
step: 400, loss: 0.09346412122249603
epoch 2: dev_f1=0.6962699822380106, f1=0.7155635062611806, best_f1=0.7155635062611806
step: 0, loss: 0.02747335471212864
step: 10, loss: 0.100313201546669
step: 20, loss: 0.047016844153404236
step: 30, loss: 0.04682980105280876
step: 40, loss: 0.029357967898249626
step: 50, loss: 0.022390903905034065
step: 60, loss: 0.09203885495662689
step: 70, loss: 0.022522635757923126
step: 80, loss: 0.1336231231689453
step: 90, loss: 0.07341822981834412
step: 100, loss: 0.05928681790828705
step: 110, loss: 0.03936883062124252
step: 120, loss: 0.06089288368821144
step: 130, loss: 0.13810515403747559
step: 140, loss: 0.03668615594506264
step: 150, loss: 0.07002466917037964
step: 160, loss: 0.11946109682321548
step: 170, loss: 0.37286603450775146
step: 180, loss: 0.06338046491146088
step: 190, loss: 0.24033278226852417
step: 200, loss: 0.04235734045505524
step: 210, loss: 0.05696123465895653
step: 220, loss: 0.04797903075814247
step: 230, loss: 0.04020059108734131
step: 240, loss: 0.29777976870536804
step: 250, loss: 0.02893025055527687
step: 260, loss: 0.1466587632894516
step: 270, loss: 0.24868346750736237
step: 280, loss: 0.040564704686403275
step: 290, loss: 0.01589280553162098
step: 300, loss: 0.02119157649576664
step: 310, loss: 0.035249412059783936
step: 320, loss: 0.039216410368680954
step: 330, loss: 0.06148580089211464
step: 340, loss: 0.056476809084415436
step: 350, loss: 0.0290223378688097
step: 360, loss: 0.0032046448905020952
step: 370, loss: 0.03134505823254585
step: 380, loss: 0.017917104065418243
step: 390, loss: 0.07586727291345596
step: 400, loss: 0.14977534115314484
epoch 3: dev_f1=0.6653543307086613, f1=0.6848249027237354, best_f1=0.7155635062611806
step: 0, loss: 0.046300631016492844
step: 10, loss: 0.10673830658197403
step: 20, loss: 0.0006490167579613626
step: 30, loss: 0.018690068274736404
step: 40, loss: 0.11533299088478088
step: 50, loss: 0.0006550048710778356
step: 60, loss: 0.1282033622264862
step: 70, loss: 0.04054693505167961
step: 80, loss: 0.06143828108906746
step: 90, loss: 0.05434105917811394
step: 100, loss: 0.04345916584134102
step: 110, loss: 0.10665439069271088
step: 120, loss: 0.0995909720659256
step: 130, loss: 0.004444507881999016
step: 140, loss: 0.029118655249476433
step: 150, loss: 0.006965368054807186
step: 160, loss: 0.052213672548532486
step: 170, loss: 0.0059623559936881065
step: 180, loss: 0.011730830185115337
step: 190, loss: 0.07269904762506485
step: 200, loss: 0.002611355623230338
step: 210, loss: 0.0033329103607684374
step: 220, loss: 0.03925039619207382
step: 230, loss: 0.01207872573286295
step: 240, loss: 0.13161513209342957
step: 250, loss: 0.11707988381385803
step: 260, loss: 0.08684919029474258
step: 270, loss: 0.1460907906293869
step: 280, loss: 0.010646961629390717
step: 290, loss: 0.10146740823984146
step: 300, loss: 0.03274805471301079
step: 310, loss: 0.07635045796632767
step: 320, loss: 0.06011079624295235
step: 330, loss: 0.09070329368114471
step: 340, loss: 0.002325616776943207
step: 350, loss: 0.11585690826177597
step: 360, loss: 0.10650649666786194
step: 370, loss: 0.02448257803916931
step: 380, loss: 0.08283751457929611
step: 390, loss: 0.016077114269137383
step: 400, loss: 0.00642833998426795
epoch 4: dev_f1=0.6923076923076923, f1=0.7052023121387283, best_f1=0.7155635062611806
step: 0, loss: 0.046878352761268616
step: 10, loss: 0.09806273132562637
step: 20, loss: 0.02622569538652897
step: 30, loss: 0.036619603633880615
step: 40, loss: 0.07094670832157135
step: 50, loss: 0.004859392065554857
step: 60, loss: 0.0021897819824516773
step: 70, loss: 0.039890844374895096
step: 80, loss: 0.07822616398334503
step: 90, loss: 0.08937464654445648
step: 100, loss: 0.02514420449733734
step: 110, loss: 0.014142832718789577
step: 120, loss: 0.02163570746779442
step: 130, loss: 0.003390904748812318
step: 140, loss: 0.04220818355679512
step: 150, loss: 0.008443283848464489
step: 160, loss: 0.008917998522520065
step: 170, loss: 0.055672816932201385
step: 180, loss: 0.1204061508178711
step: 190, loss: 0.006094415206462145
step: 200, loss: 0.003540651872754097
step: 210, loss: 0.0076318359933793545
step: 220, loss: 0.04557667672634125
step: 230, loss: 0.01581406779587269
step: 240, loss: 0.012639505788683891
step: 250, loss: 0.026528973132371902
step: 260, loss: 0.07080500572919846
step: 270, loss: 0.11238587647676468
step: 280, loss: 0.03516530618071556
step: 290, loss: 0.010343192145228386
step: 300, loss: 0.003318204777315259
step: 310, loss: 0.07123295962810516
step: 320, loss: 0.00539581011980772
step: 330, loss: 0.0065520452335476875
step: 340, loss: 0.005255000665783882
step: 350, loss: 0.3650517463684082
step: 360, loss: 0.07111288607120514
step: 370, loss: 0.05800878629088402
step: 380, loss: 0.04054447263479233
step: 390, loss: 0.034598369151353836
step: 400, loss: 0.032727986574172974
epoch 5: dev_f1=0.6843100189035918, f1=0.6755218216318785, best_f1=0.7155635062611806
step: 0, loss: 0.02316122315824032
step: 10, loss: 0.0013120159273967147
step: 20, loss: 0.015030661597847939
step: 30, loss: 0.01186302024871111
step: 40, loss: 0.01971014216542244
step: 50, loss: 0.1003362238407135
step: 60, loss: 0.0017290936084464192
step: 70, loss: 0.08112697303295135
step: 80, loss: 0.0431683324277401
step: 90, loss: 0.001672525075264275
step: 100, loss: 0.03666999191045761
step: 110, loss: 0.020050231367349625
step: 120, loss: 0.03214326128363609
step: 130, loss: 0.0008802075171843171
step: 140, loss: 0.017643634229898453
step: 150, loss: 0.05641058832406998
step: 160, loss: 0.026221608743071556
step: 170, loss: 0.00042929925257340074
step: 180, loss: 0.015476502478122711
step: 190, loss: 0.030779562890529633
step: 200, loss: 0.0030621900223195553
step: 210, loss: 0.025110282003879547
step: 220, loss: 0.023862572386860847
step: 230, loss: 0.014974026940762997
step: 240, loss: 0.012749987654387951
step: 250, loss: 0.0010048167314380407
step: 260, loss: 0.09916234016418457
step: 270, loss: 0.053256429731845856
step: 280, loss: 0.0415894016623497
step: 290, loss: 0.03203902021050453
step: 300, loss: 0.004914374556392431
step: 310, loss: 0.008664403110742569
step: 320, loss: 0.005035736132413149
step: 330, loss: 0.04559415951371193
step: 340, loss: 0.009029708802700043
step: 350, loss: 0.01732059381902218
step: 360, loss: 0.005452367011457682
step: 370, loss: 0.027055582031607628
step: 380, loss: 0.05456524342298508
step: 390, loss: 0.08396369218826294
step: 400, loss: 0.01481469627469778
epoch 6: dev_f1=0.701627486437613, f1=0.7031802120141344, best_f1=0.7031802120141344
step: 0, loss: 0.02230391837656498
step: 10, loss: 0.00010137535718968138
step: 20, loss: 0.031605202704668045
step: 30, loss: 0.04944872483611107
step: 40, loss: 0.0020407584961503744
step: 50, loss: 0.020103543996810913
step: 60, loss: 0.014943467453122139
step: 70, loss: 0.008082490414381027
step: 80, loss: 0.05474426969885826
step: 90, loss: 0.01940751075744629
step: 100, loss: 0.031017232686281204
step: 110, loss: 0.011722074821591377
step: 120, loss: 0.04260862246155739
step: 130, loss: 0.008814471773803234
step: 140, loss: 0.03581823408603668
step: 150, loss: 0.0010416049044579268
step: 160, loss: 0.023147404193878174
step: 170, loss: 0.005980257876217365
step: 180, loss: 0.030970919877290726
step: 190, loss: 0.00851589534431696
step: 200, loss: 0.12192554771900177
step: 210, loss: 0.00044895170140080154
step: 220, loss: 0.04299736022949219
step: 230, loss: 0.018591005355119705
step: 240, loss: 0.0037932994309812784
step: 250, loss: 0.015405548736453056
step: 260, loss: 0.016545409336686134
step: 270, loss: 0.07799473404884338
step: 280, loss: 0.013928070664405823
step: 290, loss: 0.0017528734169900417
step: 300, loss: 0.032718464732170105
step: 310, loss: 0.1100832000374794
step: 320, loss: 0.08121645450592041
step: 330, loss: 0.016943424940109253
step: 340, loss: 0.021293705329298973
step: 350, loss: 0.012877514585852623
step: 360, loss: 0.017562059685587883
step: 370, loss: 0.015938788652420044
step: 380, loss: 0.008681956678628922
step: 390, loss: 0.05351121723651886
step: 400, loss: 0.018137959763407707
epoch 7: dev_f1=0.6956521739130435, f1=0.6764091858037578, best_f1=0.7031802120141344
step: 0, loss: 0.012719245627522469
step: 10, loss: 0.06422538310289383
step: 20, loss: 0.005326278042048216
step: 30, loss: 0.07243701815605164
step: 40, loss: 0.06776553392410278
step: 50, loss: 0.04968052729964256
step: 60, loss: 0.039413101971149445
step: 70, loss: 0.0002197542053181678
step: 80, loss: 0.03438827022910118
step: 90, loss: 0.0607498474419117
step: 100, loss: 0.0051025100983679295
step: 110, loss: 0.0008873333572410047
step: 120, loss: 0.02027938701212406
step: 130, loss: 0.009180927649140358
step: 140, loss: 0.10237687826156616
step: 150, loss: 0.19195738434791565
step: 160, loss: 0.019904127344489098
step: 170, loss: 0.06564238667488098
step: 180, loss: 0.04286894574761391
step: 190, loss: 0.019056836143136024
step: 200, loss: 0.062129318714141846
step: 210, loss: 0.03587445616722107
step: 220, loss: 0.04218272492289543
step: 230, loss: 0.04050743579864502
step: 240, loss: 0.024535372853279114
step: 250, loss: 0.002027068054303527
step: 260, loss: 0.002073809504508972
step: 270, loss: 0.012318597175180912
step: 280, loss: 0.11539187282323837
step: 290, loss: 0.00244919047690928
step: 300, loss: 0.005506434477865696
step: 310, loss: 0.00035470922011882067
step: 320, loss: 0.004061018582433462
step: 330, loss: 0.03779133781790733
step: 340, loss: 0.001797896227799356
step: 350, loss: 0.00014130596537142992
step: 360, loss: 0.0016214969800785184
step: 370, loss: 0.0008929576142691076
step: 380, loss: 0.009355143643915653
step: 390, loss: 0.0009210489806719124
step: 400, loss: 0.00298035959713161
epoch 8: dev_f1=0.6823027718550108, f1=0.7148760330578512, best_f1=0.7031802120141344
step: 0, loss: 0.030912596732378006
step: 10, loss: 0.004663258790969849
step: 20, loss: 0.02489463984966278
step: 30, loss: 0.04958419129252434
step: 40, loss: 0.0015075302217155695
step: 50, loss: 0.0755663737654686
step: 60, loss: 0.07969383150339127
step: 70, loss: 0.052424825727939606
step: 80, loss: 0.0010969163849949837
step: 90, loss: 0.009088875725865364
step: 100, loss: 0.01802627369761467
step: 110, loss: 0.004374918062239885
step: 120, loss: 0.00031467003282159567
step: 130, loss: 0.00989111140370369
step: 140, loss: 0.006280973553657532
step: 150, loss: 0.0003901057061739266
step: 160, loss: 8.168388740159571e-05
step: 170, loss: 0.004415495786815882
step: 180, loss: 8.148854249157012e-05
step: 190, loss: 0.000805453397333622
step: 200, loss: 0.0016842209734022617
step: 210, loss: 0.01342566404491663
step: 220, loss: 0.00464885076507926
step: 230, loss: 0.018462078645825386
step: 240, loss: 0.04421025887131691
step: 250, loss: 0.014459606260061264
step: 260, loss: 0.0015286573907360435
step: 270, loss: 0.0002387662825640291
step: 280, loss: 0.0016125643160194159
step: 290, loss: 0.002885266672819853
step: 300, loss: 0.006806487683206797
step: 310, loss: 0.0049445307813584805
step: 320, loss: 0.006713555194437504
step: 330, loss: 0.0015191547572612762
step: 340, loss: 0.0011155300308018923
step: 350, loss: 0.048694245517253876
step: 360, loss: 0.002707727486267686
step: 370, loss: 0.016082528978586197
step: 380, loss: 0.0016352132661268115
step: 390, loss: 0.011692823842167854
step: 400, loss: 0.0010387883521616459
epoch 9: dev_f1=0.7176220806794054, f1=0.6916666666666667, best_f1=0.6916666666666667
step: 0, loss: 0.013434811495244503
step: 10, loss: 0.0012747404398396611
step: 20, loss: 0.04481860622763634
step: 30, loss: 0.0002182883908972144
step: 40, loss: 0.005262947175651789
step: 50, loss: 0.008888760581612587
step: 60, loss: 0.014022679068148136
step: 70, loss: 0.005500972270965576
step: 80, loss: 0.0015870695933699608
step: 90, loss: 0.00010665781883290038
step: 100, loss: 0.006112330127507448
step: 110, loss: 0.0002205038326792419
step: 120, loss: 0.002020494779571891
step: 130, loss: 0.001807495253160596
step: 140, loss: 0.0018063896568492055
step: 150, loss: 0.0870092511177063
step: 160, loss: 0.003963021095842123
step: 170, loss: 0.11859843134880066
step: 180, loss: 0.0009944700868800282
step: 190, loss: 0.007648860104382038
step: 200, loss: 0.00018772424664348364
step: 210, loss: 0.0012367359595373273
step: 220, loss: 0.00033968911156989634
step: 230, loss: 0.005794331897050142
step: 240, loss: 0.010652626864612103
step: 250, loss: 0.023627255111932755
step: 260, loss: 0.006180516444146633
step: 270, loss: 0.014359146356582642
step: 280, loss: 0.00197017565369606
step: 290, loss: 0.003915483132004738
step: 300, loss: 0.006337952334433794
step: 310, loss: 0.00296158529818058
step: 320, loss: 0.0023120346013456583
step: 330, loss: 0.012873135507106781
step: 340, loss: 0.003062792122364044
step: 350, loss: 0.0029405902605503798
step: 360, loss: 0.02854200266301632
step: 370, loss: 0.05287781357765198
step: 380, loss: 0.0007907435647211969
step: 390, loss: 0.04851756989955902
step: 400, loss: 0.000448616745416075
epoch 10: dev_f1=0.6918238993710691, f1=0.711018711018711, best_f1=0.6916666666666667
step: 0, loss: 0.0003063688927795738
step: 10, loss: 0.0005471687763929367
step: 20, loss: 0.010385622270405293
step: 30, loss: 0.00024078250862658024
step: 40, loss: 0.00562698021531105
step: 50, loss: 0.01137014664709568
step: 60, loss: 0.027703512459993362
step: 70, loss: 0.004293073434382677
step: 80, loss: 0.0030152401886880398
step: 90, loss: 0.009158965200185776
step: 100, loss: 0.021901389583945274
step: 110, loss: 0.00747067853808403
step: 120, loss: 0.0767698734998703
step: 130, loss: 0.003323625773191452
step: 140, loss: 0.000509212666656822
step: 150, loss: 0.009539446793496609
step: 160, loss: 0.011362733319401741
step: 170, loss: 0.0029405499808490276
step: 180, loss: 0.029581908136606216
step: 190, loss: 0.014306729659438133
step: 200, loss: 0.001120328321121633
step: 210, loss: 0.011472961865365505
step: 220, loss: 0.003051141509786248
step: 230, loss: 0.0015398852992802858
step: 240, loss: 0.0009640341741032898
step: 250, loss: 0.03253433108329773
step: 260, loss: 0.02977084368467331
step: 270, loss: 0.00031283573480322957
step: 280, loss: 0.0033116170670837164
step: 290, loss: 0.000250241399044171
step: 300, loss: 0.00014648030628450215
step: 310, loss: 0.11126775294542313
step: 320, loss: 8.887022704584524e-05
step: 330, loss: 0.0032663389574736357
step: 340, loss: 0.0020873623434454203
step: 350, loss: 0.06282301247119904
step: 360, loss: 0.0016751873772591352
step: 370, loss: 0.011428434401750565
step: 380, loss: 0.00025169490254484117
step: 390, loss: 0.006065207067877054
step: 400, loss: 0.0016289671184495091
epoch 11: dev_f1=0.6883910386965376, f1=0.7032520325203253, best_f1=0.6916666666666667
step: 0, loss: 0.0015472800005227327
step: 10, loss: 0.003938652109354734
step: 20, loss: 0.0010956506012007594
step: 30, loss: 0.00010275650856783614
step: 40, loss: 0.0019862386398017406
step: 50, loss: 0.0011288728564977646
step: 60, loss: 0.001798162586055696
step: 70, loss: 0.014154970645904541
step: 80, loss: 0.06034032255411148
step: 90, loss: 0.0020127336028963327
step: 100, loss: 0.004930934868752956
step: 110, loss: 0.005781855899840593
step: 120, loss: 0.11134154349565506
step: 130, loss: 3.249768997193314e-05
step: 140, loss: 0.011432446539402008
step: 150, loss: 0.0023001343943178654
step: 160, loss: 0.0006399962585419416
step: 170, loss: 0.0022555855102837086
step: 180, loss: 0.0002793344028759748
step: 190, loss: 0.001306081423535943
step: 200, loss: 0.01404188945889473
step: 210, loss: 0.00011030700261471793
step: 220, loss: 0.000833556114230305
step: 230, loss: 0.017766868695616722
step: 240, loss: 0.004368703346699476
step: 250, loss: 0.00015682110097259283
step: 260, loss: 0.004717269446700811
step: 270, loss: 0.013353978283703327
step: 280, loss: 0.0003983942442573607
step: 290, loss: 0.007647787220776081
step: 300, loss: 0.023299671709537506
step: 310, loss: 0.002985236467793584
step: 320, loss: 0.018368903547525406
step: 330, loss: 0.004693483468145132
step: 340, loss: 0.0003968778473790735
step: 350, loss: 0.0016075033927336335
step: 360, loss: 5.234190757619217e-05
step: 370, loss: 0.00021992699475958943
step: 380, loss: 0.03371293842792511
step: 390, loss: 0.00021628323884215206
step: 400, loss: 0.000261684792349115
epoch 12: dev_f1=0.6621315192743764, f1=0.6785714285714286, best_f1=0.6916666666666667
step: 0, loss: 0.00010937583283521235
step: 10, loss: 8.821223309496418e-05
step: 20, loss: 0.0015362754929810762
step: 30, loss: 0.04152735695242882
step: 40, loss: 0.00010175108764087781
step: 50, loss: 0.041311152279376984
step: 60, loss: 0.16545984148979187
step: 70, loss: 0.0010017917957156897
step: 80, loss: 0.010516930371522903
step: 90, loss: 7.239401020342484e-05
step: 100, loss: 0.003914480097591877
step: 110, loss: 0.03937358036637306
step: 120, loss: 0.00019103761587757617
step: 130, loss: 0.002337587298825383
step: 140, loss: 0.060425642877817154
step: 150, loss: 7.848186942283064e-05
step: 160, loss: 0.0011837789788842201
step: 170, loss: 6.974209827603772e-05
step: 180, loss: 0.006102873012423515
step: 190, loss: 0.0017990042688325047
step: 200, loss: 0.0008069588802754879
step: 210, loss: 6.296193168964237e-05
step: 220, loss: 0.027042778208851814
step: 230, loss: 0.00029937829822301865
step: 240, loss: 1.975496343220584e-05
step: 250, loss: 0.007277914322912693
step: 260, loss: 0.13119567930698395
step: 270, loss: 0.006851070560514927
step: 280, loss: 0.0011362163349986076
step: 290, loss: 0.0999579057097435
step: 300, loss: 0.005044780671596527
step: 310, loss: 0.00014547455066349357
step: 320, loss: 0.010793661698698997
step: 330, loss: 0.00021112874674145132
step: 340, loss: 0.0001236681273439899
step: 350, loss: 0.0001475067692808807
step: 360, loss: 0.009241930209100246
step: 370, loss: 0.01972332037985325
step: 380, loss: 0.0008390467264689505
step: 390, loss: 0.01076769270002842
step: 400, loss: 0.003841688157990575
epoch 13: dev_f1=0.6763485477178423, f1=0.7104722792607804, best_f1=0.6916666666666667
step: 0, loss: 0.007234805729240179
step: 10, loss: 0.021688541397452354
step: 20, loss: 0.00014094279322307557
step: 30, loss: 0.0004756404960062355
step: 40, loss: 0.00012332366895861924
step: 50, loss: 0.015228855423629284
step: 60, loss: 0.011188914068043232
step: 70, loss: 8.757404430070892e-05
step: 80, loss: 0.001526620821096003
step: 90, loss: 0.0010240767151117325
step: 100, loss: 0.0054077706299722195
step: 110, loss: 0.00011792238365160301
step: 120, loss: 0.00045134464744478464
step: 130, loss: 0.00014099851250648499
step: 140, loss: 0.0006685692351311445
step: 150, loss: 0.00040787371108308434
step: 160, loss: 0.0001459067570976913
step: 170, loss: 0.09794912487268448
step: 180, loss: 0.00013817740546073765
step: 190, loss: 0.0017529147444292903
step: 200, loss: 0.016028493642807007
step: 210, loss: 6.00628845859319e-05
step: 220, loss: 0.00010246566671412438
step: 230, loss: 0.00012782819976564497
step: 240, loss: 4.841085319640115e-05
step: 250, loss: 0.0008674005512148142
step: 260, loss: 0.00017812101577874273
step: 270, loss: 0.00030211822013370693
step: 280, loss: 7.808975351508707e-05
step: 290, loss: 0.003055423265323043
step: 300, loss: 0.004975982941687107
step: 310, loss: 0.0016882207710295916
step: 320, loss: 0.004213870037347078
step: 330, loss: 0.0008833647589199245
step: 340, loss: 0.0001317584392381832
step: 350, loss: 0.02498696558177471
step: 360, loss: 0.0003245372499804944
step: 370, loss: 0.013073810376226902
step: 380, loss: 0.00012947357026860118
step: 390, loss: 0.00027221007621847093
step: 400, loss: 0.07978950440883636
epoch 14: dev_f1=0.6605504587155964, f1=0.6919642857142858, best_f1=0.6916666666666667
step: 0, loss: 0.00019164597324561328
step: 10, loss: 0.00033454858930781484
step: 20, loss: 5.750851414632052e-05
step: 30, loss: 0.00024216114252340049
step: 40, loss: 0.038651347160339355
step: 50, loss: 0.0006776322843506932
step: 60, loss: 0.0002419217344140634
step: 70, loss: 0.00045440279063768685
step: 80, loss: 0.03185321390628815
step: 90, loss: 6.242386007215828e-05
step: 100, loss: 0.00146997079718858
step: 110, loss: 0.00037370811332948506
step: 120, loss: 7.111059676390141e-05
step: 130, loss: 0.01943141594529152
step: 140, loss: 0.00010679174738470465
step: 150, loss: 0.006114547606557608
step: 160, loss: 0.0008696425938978791
step: 170, loss: 0.0003199644561391324
step: 180, loss: 0.000216978820390068
step: 190, loss: 0.00011746876407414675
step: 200, loss: 0.00024391408078372478
step: 210, loss: 0.007611106149852276
step: 220, loss: 0.0001796793658286333
step: 230, loss: 0.016370534896850586
step: 240, loss: 0.0011333961738273501
step: 250, loss: 0.0006395892123691738
step: 260, loss: 0.00010825218487298116
step: 270, loss: 0.0439799427986145
step: 280, loss: 0.0583205372095108
step: 290, loss: 0.00010707677574828267
step: 300, loss: 0.0001634445070521906
step: 310, loss: 0.0357636883854866
step: 320, loss: 0.017943939194083214
step: 330, loss: 0.0009707142016850412
step: 340, loss: 0.0002314747398486361
step: 350, loss: 0.0004918428603559732
step: 360, loss: 0.00011453375191194937
step: 370, loss: 7.43493510526605e-05
step: 380, loss: 0.0031468698289245367
step: 390, loss: 0.00013672011846210808
step: 400, loss: 4.7104829718591645e-05
epoch 15: dev_f1=0.6711711711711711, f1=0.7074235807860262, best_f1=0.6916666666666667
step: 0, loss: 8.004676055861637e-05
step: 10, loss: 4.868530231760815e-05
step: 20, loss: 2.5603541871532798e-05
step: 30, loss: 0.01801825687289238
step: 40, loss: 0.000914553296752274
step: 50, loss: 5.859610973857343e-05
step: 60, loss: 0.00021968179498799145
step: 70, loss: 7.811548857716843e-05
step: 80, loss: 0.00015342429105658084
step: 90, loss: 0.0005117126274853945
step: 100, loss: 0.026675378903746605
step: 110, loss: 0.004419602919369936
step: 120, loss: 0.002001506742089987
step: 130, loss: 0.00014719781756866723
step: 140, loss: 0.000138486095238477
step: 150, loss: 5.8102225011680275e-05
step: 160, loss: 0.0017235873965546489
step: 170, loss: 0.00012291020539123565
step: 180, loss: 0.054308343678712845
step: 190, loss: 4.713151793112047e-05
step: 200, loss: 0.02424803376197815
step: 210, loss: 2.9722481485805474e-05
step: 220, loss: 0.0001354062551399693
step: 230, loss: 0.0015966776991263032
step: 240, loss: 0.0012494998518377542
step: 250, loss: 0.00014780613128095865
step: 260, loss: 0.00015652629372198135
step: 270, loss: 0.00735155725851655
step: 280, loss: 0.00011630991502897814
step: 290, loss: 3.500789534882642e-05
step: 300, loss: 0.000536418694537133
step: 310, loss: 2.6624149541021325e-05
step: 320, loss: 0.008622054941952229
step: 330, loss: 0.0036795400083065033
step: 340, loss: 0.020858030766248703
step: 350, loss: 0.0453500896692276
step: 360, loss: 3.4616710763657466e-05
step: 370, loss: 4.045233072247356e-05
step: 380, loss: 4.433511276147328e-05
step: 390, loss: 0.0006016553961671889
step: 400, loss: 0.0021388810127973557
epoch 16: dev_f1=0.6788154897494305, f1=0.6844444444444444, best_f1=0.6916666666666667
step: 0, loss: 0.003277730429545045
step: 10, loss: 0.020705146715044975
step: 20, loss: 2.8434240448405035e-05
step: 30, loss: 0.00046817862312309444
step: 40, loss: 0.0089772529900074
step: 50, loss: 0.02247147634625435
step: 60, loss: 0.01206277310848236
step: 70, loss: 0.00017950292385648936
step: 80, loss: 0.0003831421781796962
step: 90, loss: 0.047628119587898254
step: 100, loss: 2.9979273676872253e-05
step: 110, loss: 4.1771378164412454e-05
step: 120, loss: 0.00019296389655210078
step: 130, loss: 2.6843714294955134e-05
step: 140, loss: 5.520089325727895e-05
step: 150, loss: 7.317544077523053e-05
step: 160, loss: 9.869215864455327e-05
step: 170, loss: 0.017206482589244843
step: 180, loss: 0.0005074972286820412
step: 190, loss: 7.019426993792877e-05
step: 200, loss: 5.91022617300041e-05
step: 210, loss: 0.0006372492644004524
step: 220, loss: 6.542129267472774e-05
step: 230, loss: 6.095652861404233e-05
step: 240, loss: 0.0001604227436473593
step: 250, loss: 0.004512104205787182
step: 260, loss: 4.9748283345252275e-05
step: 270, loss: 0.0001726573973428458
step: 280, loss: 0.0001897243782877922
step: 290, loss: 5.565512765315361e-05
step: 300, loss: 7.021517376415431e-05
step: 310, loss: 0.004802248906344175
step: 320, loss: 0.00036146232741884887
step: 330, loss: 4.567153155221604e-05
step: 340, loss: 0.05312251299619675
step: 350, loss: 0.00012056709238095209
step: 360, loss: 0.0034089020919054747
step: 370, loss: 4.7108169383136556e-05
step: 380, loss: 0.00020008705905638635
step: 390, loss: 1.7002072127070278e-05
step: 400, loss: 0.00011691192776197568
epoch 17: dev_f1=0.6879271070615034, f1=0.6696428571428572, best_f1=0.6916666666666667
step: 0, loss: 9.097893052967265e-05
step: 10, loss: 0.039510443806648254
step: 20, loss: 0.0010913321748375893
step: 30, loss: 0.0001583121920702979
step: 40, loss: 0.00014025448763277382
step: 50, loss: 2.3456881535821594e-05
step: 60, loss: 4.7779190936125815e-05
step: 70, loss: 0.00020459949155338109
step: 80, loss: 8.603325841249898e-05
step: 90, loss: 0.0013806245988234878
step: 100, loss: 0.0001360423630103469
step: 110, loss: 0.006433798000216484
step: 120, loss: 0.0011613044189289212
step: 130, loss: 0.00016689510084688663
step: 140, loss: 0.07501573860645294
step: 150, loss: 9.021681034937501e-05
step: 160, loss: 9.75520524661988e-05
step: 170, loss: 1.8123322661267594e-05
step: 180, loss: 4.877555329585448e-05
step: 190, loss: 1.6417199731222354e-05
step: 200, loss: 0.05922533944249153
step: 210, loss: 5.9479443734744564e-05
step: 220, loss: 2.4820528778946027e-05
step: 230, loss: 6.399954872904345e-05
step: 240, loss: 0.00015652732690796256
step: 250, loss: 4.428857209859416e-05
step: 260, loss: 0.00011259761959081516
step: 270, loss: 3.746606671484187e-05
step: 280, loss: 0.004430553410202265
step: 290, loss: 5.475489160744473e-05
step: 300, loss: 0.00044405454536899924
step: 310, loss: 4.2116524127777666e-05
step: 320, loss: 0.016803687438368797
step: 330, loss: 2.711875640670769e-05
step: 340, loss: 0.003899924922734499
step: 350, loss: 2.758346454356797e-05
step: 360, loss: 4.419862671056762e-05
step: 370, loss: 0.00010143269901163876
step: 380, loss: 0.030808579176664352
step: 390, loss: 0.0002868326846510172
step: 400, loss: 0.0002170185325667262
epoch 18: dev_f1=0.6831460674157304, f1=0.6943231441048036, best_f1=0.6916666666666667
step: 0, loss: 0.0015168929239735007
step: 10, loss: 2.4057027985691093e-05
step: 20, loss: 0.008284136652946472
step: 30, loss: 0.0003224225074518472
step: 40, loss: 1.9091865397058427e-05
step: 50, loss: 0.003895176574587822
step: 60, loss: 0.00014094094512984157
step: 70, loss: 0.00034411720116622746
step: 80, loss: 0.004763455595821142
step: 90, loss: 1.6588550352025777e-05
step: 100, loss: 0.0002655040589161217
step: 110, loss: 0.0002043481799773872
step: 120, loss: 3.777097663260065e-05
step: 130, loss: 0.0005826411652378738
step: 140, loss: 1.4204424587660469e-05
step: 150, loss: 0.000817287596873939
step: 160, loss: 0.001015364658087492
step: 170, loss: 4.190946128801443e-05
step: 180, loss: 0.0008605651673860848
step: 190, loss: 0.00013461525668390095
step: 200, loss: 0.00011380841897334903
step: 210, loss: 6.876164115965366e-05
step: 220, loss: 0.011559884063899517
step: 230, loss: 0.09923241287469864
step: 240, loss: 7.792875840095803e-05
step: 250, loss: 0.002489908132702112
step: 260, loss: 0.00028547082911245525
step: 270, loss: 0.016443228349089622
step: 280, loss: 0.00022521609207615256
step: 290, loss: 0.0008901928667910397
step: 300, loss: 0.00010957678023260087
step: 310, loss: 6.241057417355478e-05
step: 320, loss: 0.00012809514009859413
step: 330, loss: 0.00014517028466798365
step: 340, loss: 0.0003728436422534287
step: 350, loss: 0.03404464200139046
step: 360, loss: 4.031142088933848e-05
step: 370, loss: 0.0002239875466329977
step: 380, loss: 0.011535737663507462
step: 390, loss: 0.00013164978008717299
step: 400, loss: 0.00011355322931194678
epoch 19: dev_f1=0.6636155606407322, f1=0.6890380313199105, best_f1=0.6916666666666667
step: 0, loss: 0.00016557435446884483
step: 10, loss: 0.00029433899908326566
step: 20, loss: 0.00019008161325473338
step: 30, loss: 0.031020166352391243
step: 40, loss: 4.4057149352738634e-05
step: 50, loss: 0.0007939593051560223
step: 60, loss: 8.131304639391601e-05
step: 70, loss: 0.00039490501512773335
step: 80, loss: 0.00020595124806277454
step: 90, loss: 0.002140627708286047
step: 100, loss: 3.02388707495993e-05
step: 110, loss: 3.719402593560517e-05
step: 120, loss: 9.983860945794731e-05
step: 130, loss: 0.0003494801349006593
step: 140, loss: 0.006459358613938093
step: 150, loss: 7.395508873742074e-05
step: 160, loss: 0.05966605246067047
step: 170, loss: 0.0002666913205757737
step: 180, loss: 0.00010903275688178837
step: 190, loss: 0.00031511508859694004
step: 200, loss: 0.00016658104141242802
step: 210, loss: 0.015474280342459679
step: 220, loss: 0.0001479065540479496
step: 230, loss: 2.9729719244642183e-05
step: 240, loss: 0.017124362289905548
step: 250, loss: 0.0010825711069628596
step: 260, loss: 1.8726796042756177e-05
step: 270, loss: 3.738708983291872e-05
step: 280, loss: 1.9185023120371625e-05
step: 290, loss: 3.640056820586324e-05
step: 300, loss: 0.0006508156075142324
step: 310, loss: 4.9417696573073044e-05
step: 320, loss: 0.00483489315956831
step: 330, loss: 0.000926231499761343
step: 340, loss: 7.767646457068622e-05
step: 350, loss: 0.018360938876867294
step: 360, loss: 0.030109332874417305
step: 370, loss: 0.00015026280016172677
step: 380, loss: 6.131615373305976e-05
step: 390, loss: 0.0001949485158547759
step: 400, loss: 5.447793228086084e-05
epoch 20: dev_f1=0.6832579185520362, f1=0.6917960088691797, best_f1=0.6916666666666667
