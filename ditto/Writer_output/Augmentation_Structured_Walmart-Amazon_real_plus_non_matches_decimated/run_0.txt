cuda
Device: cuda
step: 0, loss: 0.6667890548706055
step: 10, loss: 0.24242737889289856
step: 20, loss: 0.3247165381908417
step: 30, loss: 0.2630627155303955
step: 40, loss: 0.1557750403881073
step: 50, loss: 0.23044461011886597
step: 60, loss: 0.13946984708309174
step: 70, loss: 0.488856703042984
step: 80, loss: 0.3057745695114136
step: 90, loss: 0.3121833801269531
step: 100, loss: 0.06191451475024223
step: 110, loss: 0.3314967453479767
step: 120, loss: 0.1400851011276245
step: 130, loss: 0.211945042014122
step: 140, loss: 0.049506016075611115
step: 150, loss: 0.23915652930736542
step: 160, loss: 0.13074927031993866
step: 170, loss: 0.16833022236824036
step: 180, loss: 0.18349623680114746
step: 190, loss: 0.20350851118564606
step: 200, loss: 0.1826685667037964
step: 210, loss: 0.05775372311472893
step: 220, loss: 0.36909106373786926
step: 230, loss: 0.10923047363758087
step: 240, loss: 0.042256712913513184
step: 250, loss: 0.08520784229040146
step: 260, loss: 0.01698797196149826
step: 270, loss: 0.17284566164016724
step: 280, loss: 0.2907000780105591
step: 290, loss: 0.03655547648668289
step: 300, loss: 0.15627063810825348
step: 310, loss: 0.13431903719902039
step: 320, loss: 0.3897998631000519
step: 330, loss: 0.19075100123882294
step: 340, loss: 0.39832067489624023
step: 350, loss: 0.27796733379364014
step: 360, loss: 0.08937898278236389
epoch 1: dev_f1=0.5283018867924528, f1=0.5185185185185186, best_f1=0.5185185185185186
step: 0, loss: 0.033391695469617844
step: 10, loss: 0.25923940539360046
step: 20, loss: 0.21044231951236725
step: 30, loss: 0.06593605130910873
step: 40, loss: 0.12904897332191467
step: 50, loss: 0.19291777908802032
step: 60, loss: 0.16733765602111816
step: 70, loss: 0.3116495907306671
step: 80, loss: 0.06656920909881592
step: 90, loss: 0.1351267695426941
step: 100, loss: 0.1254664659500122
step: 110, loss: 0.027296282351017
step: 120, loss: 0.06875718384981155
step: 130, loss: 0.0823315903544426
step: 140, loss: 0.013446100056171417
step: 150, loss: 0.10073792934417725
step: 160, loss: 0.11070828884840012
step: 170, loss: 0.2098519653081894
step: 180, loss: 0.2790210247039795
step: 190, loss: 0.29682618379592896
step: 200, loss: 0.08887799084186554
step: 210, loss: 0.12094923108816147
step: 220, loss: 0.22935748100280762
step: 230, loss: 0.27578204870224
step: 240, loss: 0.10063402354717255
step: 250, loss: 0.09021008759737015
step: 260, loss: 0.10961892455816269
step: 270, loss: 0.12786416709423065
step: 280, loss: 0.06349164992570877
step: 290, loss: 0.08772303909063339
step: 300, loss: 0.11322231590747833
step: 310, loss: 0.23793715238571167
step: 320, loss: 0.11222998797893524
step: 330, loss: 0.12625296413898468
step: 340, loss: 0.04044937342405319
step: 350, loss: 0.21937376260757446
step: 360, loss: 0.03291197121143341
epoch 2: dev_f1=0.6829268292682927, f1=0.6959064327485379, best_f1=0.6959064327485379
step: 0, loss: 0.06206563115119934
step: 10, loss: 0.1399223953485489
step: 20, loss: 0.06945307552814484
step: 30, loss: 0.06967735290527344
step: 40, loss: 0.06276612728834152
step: 50, loss: 0.07821857929229736
step: 60, loss: 0.1331290900707245
step: 70, loss: 0.11338718235492706
step: 80, loss: 0.020642785355448723
step: 90, loss: 0.2354673147201538
step: 100, loss: 0.0107466671615839
step: 110, loss: 0.029446685686707497
step: 120, loss: 0.0832991972565651
step: 130, loss: 0.10359001159667969
step: 140, loss: 0.19579283893108368
step: 150, loss: 0.061258457601070404
step: 160, loss: 0.06550133973360062
step: 170, loss: 0.05754941329360008
step: 180, loss: 0.07179967314004898
step: 190, loss: 0.08472202718257904
step: 200, loss: 0.07745577394962311
step: 210, loss: 0.37984439730644226
step: 220, loss: 0.009402253665030003
step: 230, loss: 0.14564621448516846
step: 240, loss: 0.04939255490899086
step: 250, loss: 0.08435112982988358
step: 260, loss: 0.14557908475399017
step: 270, loss: 0.04851490259170532
step: 280, loss: 0.09773367643356323
step: 290, loss: 0.08127018064260483
step: 300, loss: 0.1359628140926361
step: 310, loss: 0.10091118514537811
step: 320, loss: 0.05270370468497276
step: 330, loss: 0.11319173872470856
step: 340, loss: 0.06924639642238617
step: 350, loss: 0.10441327095031738
step: 360, loss: 0.04201384261250496
epoch 3: dev_f1=0.7531806615776082, f1=0.7601078167115903, best_f1=0.7601078167115903
step: 0, loss: 0.18775685131549835
step: 10, loss: 0.05557655543088913
step: 20, loss: 0.06919659674167633
step: 30, loss: 0.08507724851369858
step: 40, loss: 0.013281220570206642
step: 50, loss: 0.1147068589925766
step: 60, loss: 0.00553206168115139
step: 70, loss: 0.06252806633710861
step: 80, loss: 0.09953946620225906
step: 90, loss: 0.014828605577349663
step: 100, loss: 0.024350345134735107
step: 110, loss: 0.09306715428829193
step: 120, loss: 0.15927425026893616
step: 130, loss: 0.024990078061819077
step: 140, loss: 0.03350234031677246
step: 150, loss: 0.06204988434910774
step: 160, loss: 0.07144366949796677
step: 170, loss: 0.02341860719025135
step: 180, loss: 0.08600057661533356
step: 190, loss: 0.03338664770126343
step: 200, loss: 0.02151934616267681
step: 210, loss: 0.07577288895845413
step: 220, loss: 0.017866015434265137
step: 230, loss: 0.09404274821281433
step: 240, loss: 0.1518435925245285
step: 250, loss: 0.015667445957660675
step: 260, loss: 0.036218561232089996
step: 270, loss: 0.15561628341674805
step: 280, loss: 0.07090362161397934
step: 290, loss: 0.015889182686805725
step: 300, loss: 0.10849227756261826
step: 310, loss: 0.03508972004055977
step: 320, loss: 0.15659818053245544
step: 330, loss: 0.0898328647017479
step: 340, loss: 0.07043753564357758
step: 350, loss: 0.001505797728896141
step: 360, loss: 0.04174595698714256
epoch 4: dev_f1=0.7047146401985112, f1=0.7345844504021448, best_f1=0.7601078167115903
step: 0, loss: 0.053808558732271194
step: 10, loss: 0.05780123919248581
step: 20, loss: 0.11026415228843689
step: 30, loss: 0.022682132199406624
step: 40, loss: 0.03778942674398422
step: 50, loss: 0.10684829205274582
step: 60, loss: 0.05842164158821106
step: 70, loss: 0.007950646802783012
step: 80, loss: 0.012992284260690212
step: 90, loss: 0.04522591456770897
step: 100, loss: 0.06755638122558594
step: 110, loss: 0.03761737421154976
step: 120, loss: 0.044384971261024475
step: 130, loss: 0.06242740899324417
step: 140, loss: 0.05270623788237572
step: 150, loss: 0.09593530744314194
step: 160, loss: 0.1453297883272171
step: 170, loss: 0.16634884476661682
step: 180, loss: 0.03996999189257622
step: 190, loss: 0.2498299479484558
step: 200, loss: 0.08289191871881485
step: 210, loss: 0.0721377581357956
step: 220, loss: 0.04937531426548958
step: 230, loss: 0.03182103857398033
step: 240, loss: 0.05087686702609062
step: 250, loss: 0.08929719775915146
step: 260, loss: 0.10770406574010849
step: 270, loss: 0.07847820967435837
step: 280, loss: 0.05542224273085594
step: 290, loss: 0.024319617077708244
step: 300, loss: 0.0592992827296257
step: 310, loss: 0.031341925263404846
step: 320, loss: 0.03686375916004181
step: 330, loss: 0.11765734851360321
step: 340, loss: 0.029302271082997322
step: 350, loss: 0.22696633636951447
step: 360, loss: 0.07163365930318832
epoch 5: dev_f1=0.7239583333333334, f1=0.7374005305039788, best_f1=0.7601078167115903
step: 0, loss: 0.07677298039197922
step: 10, loss: 0.019827406853437424
step: 20, loss: 0.0023306237999349833
step: 30, loss: 0.0922974944114685
step: 40, loss: 0.0343337245285511
step: 50, loss: 0.06630438566207886
step: 60, loss: 0.03293976932764053
step: 70, loss: 0.015312151052057743
step: 80, loss: 0.01280874852091074
step: 90, loss: 0.05869286134839058
step: 100, loss: 0.001855703303590417
step: 110, loss: 0.14308036863803864
step: 120, loss: 0.06951187551021576
step: 130, loss: 0.02546030282974243
step: 140, loss: 0.1077168732881546
step: 150, loss: 0.017452264204621315
step: 160, loss: 0.0035968937445431948
step: 170, loss: 0.01816718839108944
step: 180, loss: 0.08461317420005798
step: 190, loss: 0.0858435332775116
step: 200, loss: 0.07535220682621002
step: 210, loss: 0.06052803993225098
step: 220, loss: 0.03460480272769928
step: 230, loss: 0.06168943643569946
step: 240, loss: 0.012228102423250675
step: 250, loss: 0.09029744565486908
step: 260, loss: 0.05130233243107796
step: 270, loss: 0.062289316207170486
step: 280, loss: 0.027162812650203705
step: 290, loss: 0.01026187464594841
step: 300, loss: 0.06612139940261841
step: 310, loss: 0.05429646745324135
step: 320, loss: 0.29200515151023865
step: 330, loss: 0.14666594564914703
step: 340, loss: 0.0912296250462532
step: 350, loss: 0.010924043133854866
step: 360, loss: 0.037349116057157516
epoch 6: dev_f1=0.7414634146341464, f1=0.7664974619289339, best_f1=0.7601078167115903
step: 0, loss: 0.08569099754095078
step: 10, loss: 0.010011063888669014
step: 20, loss: 0.0018643757794052362
step: 30, loss: 0.015374221839010715
step: 40, loss: 0.10353084653615952
step: 50, loss: 0.05385220795869827
step: 60, loss: 0.056538935750722885
step: 70, loss: 0.025479353964328766
step: 80, loss: 0.02849293127655983
step: 90, loss: 0.0336579866707325
step: 100, loss: 0.05264654755592346
step: 110, loss: 0.02521953359246254
step: 120, loss: 0.001446211477741599
step: 130, loss: 0.05696383863687515
step: 140, loss: 0.0906669870018959
step: 150, loss: 0.17238670587539673
step: 160, loss: 0.004835965111851692
step: 170, loss: 0.0825490802526474
step: 180, loss: 0.02698635309934616
step: 190, loss: 0.057954154908657074
step: 200, loss: 0.05766052380204201
step: 210, loss: 0.01831561140716076
step: 220, loss: 0.03922237083315849
step: 230, loss: 0.06732693314552307
step: 240, loss: 0.04591623321175575
step: 250, loss: 0.02821223996579647
step: 260, loss: 0.005753215868026018
step: 270, loss: 0.06887827813625336
step: 280, loss: 0.11836875975131989
step: 290, loss: 0.020267115905880928
step: 300, loss: 0.055759821087121964
step: 310, loss: 0.02198649011552334
step: 320, loss: 0.011516837403178215
step: 330, loss: 0.04205053299665451
step: 340, loss: 0.15344999730587006
step: 350, loss: 0.08621376007795334
step: 360, loss: 0.031705621629953384
epoch 7: dev_f1=0.7365728900255755, f1=0.7473118279569892, best_f1=0.7601078167115903
step: 0, loss: 0.029656924307346344
step: 10, loss: 0.018838906660676003
step: 20, loss: 0.005901034455746412
step: 30, loss: 0.15155485272407532
step: 40, loss: 0.011846533045172691
step: 50, loss: 0.06673361361026764
step: 60, loss: 0.0011019888333976269
step: 70, loss: 0.008164656348526478
step: 80, loss: 0.047126591205596924
step: 90, loss: 0.06878263503313065
step: 100, loss: 0.05682898312807083
step: 110, loss: 0.01863008737564087
step: 120, loss: 0.028476547449827194
step: 130, loss: 0.01226774137467146
step: 140, loss: 0.04276885464787483
step: 150, loss: 0.05606864392757416
step: 160, loss: 0.01757090538740158
step: 170, loss: 0.030596325173974037
step: 180, loss: 0.04149598255753517
step: 190, loss: 0.0761478841304779
step: 200, loss: 0.10334787517786026
step: 210, loss: 0.05804988741874695
step: 220, loss: 0.06666873395442963
step: 230, loss: 0.037932138890028
step: 240, loss: 0.017452305182814598
step: 250, loss: 0.18069463968276978
step: 260, loss: 0.0065312799997627735
step: 270, loss: 0.03485869616270065
step: 280, loss: 0.07574182748794556
step: 290, loss: 0.05668046697974205
step: 300, loss: 0.003732857294380665
step: 310, loss: 0.010830443352460861
step: 320, loss: 0.032885752618312836
step: 330, loss: 0.02208850532770157
step: 340, loss: 0.011201341636478901
step: 350, loss: 0.0063660964369773865
step: 360, loss: 0.09849083423614502
epoch 8: dev_f1=0.7305699481865285, f1=0.7520435967302452, best_f1=0.7601078167115903
step: 0, loss: 0.0828361064195633
step: 10, loss: 0.018753914162516594
step: 20, loss: 0.026409292593598366
step: 30, loss: 0.011599162593483925
step: 40, loss: 0.008679532445967197
step: 50, loss: 0.03800962120294571
step: 60, loss: 0.039946239441633224
step: 70, loss: 0.015810701996088028
step: 80, loss: 0.07835667580366135
step: 90, loss: 0.03530118986964226
step: 100, loss: 0.03539634495973587
step: 110, loss: 0.00477322144433856
step: 120, loss: 0.047097183763980865
step: 130, loss: 0.013164063915610313
step: 140, loss: 0.1099284365773201
step: 150, loss: 0.007483842317014933
step: 160, loss: 0.061396293342113495
step: 170, loss: 0.10661346465349197
step: 180, loss: 0.025309834629297256
step: 190, loss: 0.10268809646368027
step: 200, loss: 0.030259229242801666
step: 210, loss: 0.012708772905170918
step: 220, loss: 0.005553722381591797
step: 230, loss: 0.00749505078420043
step: 240, loss: 0.163264662027359
step: 250, loss: 0.07602806389331818
step: 260, loss: 0.09669670462608337
step: 270, loss: 0.03422543779015541
step: 280, loss: 0.07251888513565063
step: 290, loss: 0.06733806431293488
step: 300, loss: 0.02156291902065277
step: 310, loss: 0.023879271000623703
step: 320, loss: 0.05209980905056
step: 330, loss: 0.18919892609119415
step: 340, loss: 0.08633062243461609
step: 350, loss: 0.009788197465240955
step: 360, loss: 0.014189328998327255
epoch 9: dev_f1=0.7566137566137565, f1=0.7541899441340784, best_f1=0.7541899441340784
step: 0, loss: 0.031036078929901123
step: 10, loss: 0.1001143753528595
step: 20, loss: 0.010401088744401932
step: 30, loss: 0.0068950653076171875
step: 40, loss: 0.06339506804943085
step: 50, loss: 0.0283917598426342
step: 60, loss: 0.017308272421360016
step: 70, loss: 0.06576882302761078
step: 80, loss: 0.0039147548377513885
step: 90, loss: 0.02966351807117462
step: 100, loss: 0.0014117121463641524
step: 110, loss: 0.04797063395380974
step: 120, loss: 0.023053916171193123
step: 130, loss: 0.11360333859920502
step: 140, loss: 0.052231479436159134
step: 150, loss: 0.06793458014726639
step: 160, loss: 0.01474696584045887
step: 170, loss: 0.021237792447209358
step: 180, loss: 0.14449633657932281
step: 190, loss: 0.028198884800076485
step: 200, loss: 0.08054884523153305
step: 210, loss: 0.03015437163412571
step: 220, loss: 0.10250657051801682
step: 230, loss: 0.16960668563842773
step: 240, loss: 0.03524480760097504
step: 250, loss: 0.05533449351787567
step: 260, loss: 0.03184819221496582
step: 270, loss: 0.04328029230237007
step: 280, loss: 0.023553410544991493
step: 290, loss: 0.015185709111392498
step: 300, loss: 0.00030150750535540283
step: 310, loss: 0.1046421155333519
step: 320, loss: 0.037059757858514786
step: 330, loss: 0.10356372594833374
step: 340, loss: 0.057307008653879166
step: 350, loss: 0.014887116849422455
step: 360, loss: 0.010431839153170586
epoch 10: dev_f1=0.7272727272727273, f1=0.6988636363636365, best_f1=0.7541899441340784
step: 0, loss: 0.03331286087632179
step: 10, loss: 0.053088605403900146
step: 20, loss: 0.04631126672029495
step: 30, loss: 0.007967425510287285
step: 40, loss: 0.09921427071094513
step: 50, loss: 0.005615954753011465
step: 60, loss: 0.06658448278903961
step: 70, loss: 0.003935741726309061
step: 80, loss: 0.019082598388195038
step: 90, loss: 0.009962199255824089
step: 100, loss: 0.05475616082549095
step: 110, loss: 4.498438283917494e-05
step: 120, loss: 0.0165693536400795
step: 130, loss: 0.015070093795657158
step: 140, loss: 0.06197671219706535
step: 150, loss: 0.026402713730931282
step: 160, loss: 0.031242432072758675
step: 170, loss: 0.08035920560359955
step: 180, loss: 0.006616635248064995
step: 190, loss: 0.006694030947983265
step: 200, loss: 0.011166638694703579
step: 210, loss: 0.0007058819173835218
step: 220, loss: 0.031722865998744965
step: 230, loss: 0.07507483661174774
step: 240, loss: 0.0296940878033638
step: 250, loss: 0.028124364092946053
step: 260, loss: 0.02718031033873558
step: 270, loss: 0.0059481170028448105
step: 280, loss: 0.0035365642979741096
step: 290, loss: 0.07321033626794815
step: 300, loss: 0.018365632742643356
step: 310, loss: 0.0712270438671112
step: 320, loss: 0.0058759362436831
step: 330, loss: 0.07116512209177017
step: 340, loss: 0.15449050068855286
step: 350, loss: 0.0023815708700567484
step: 360, loss: 0.017689470201730728
epoch 11: dev_f1=0.7351351351351353, f1=0.7478753541076487, best_f1=0.7541899441340784
step: 0, loss: 0.004303957801312208
step: 10, loss: 0.03826220706105232
step: 20, loss: 0.03117411397397518
step: 30, loss: 0.06874780356884003
step: 40, loss: 0.016507623717188835
step: 50, loss: 0.0042694550938904285
step: 60, loss: 0.0783052146434784
step: 70, loss: 0.012563299387693405
step: 80, loss: 0.022223396226763725
step: 90, loss: 0.15606451034545898
step: 100, loss: 0.04251832142472267
step: 110, loss: 0.03186550363898277
step: 120, loss: 0.045918453484773636
step: 130, loss: 0.030615055933594704
step: 140, loss: 0.07498878240585327
step: 150, loss: 0.11680612713098526
step: 160, loss: 0.0379016287624836
step: 170, loss: 0.01388043724000454
step: 180, loss: 0.007977851666510105
step: 190, loss: 0.05611911416053772
step: 200, loss: 0.015909908339381218
step: 210, loss: 0.025567740201950073
step: 220, loss: 0.06726407259702682
step: 230, loss: 0.008991341106593609
step: 240, loss: 0.00023032115132082254
step: 250, loss: 2.7454923838377e-05
step: 260, loss: 0.0463864766061306
step: 270, loss: 0.0010512761073186994
step: 280, loss: 0.06893425434827805
step: 290, loss: 0.06458723545074463
step: 300, loss: 0.011175361461937428
step: 310, loss: 0.12314227968454361
step: 320, loss: 0.022920284420251846
step: 330, loss: 0.01450546458363533
step: 340, loss: 0.061395253986120224
step: 350, loss: 0.027085503563284874
step: 360, loss: 0.03242956101894379
epoch 12: dev_f1=0.7248677248677249, f1=0.7683923705722071, best_f1=0.7541899441340784
step: 0, loss: 0.009087963029742241
step: 10, loss: 0.018146179616451263
step: 20, loss: 0.0026624181773513556
step: 30, loss: 0.057817380875349045
step: 40, loss: 0.02844785340130329
step: 50, loss: 0.05319203808903694
step: 60, loss: 0.06641533225774765
step: 70, loss: 0.0037356605753302574
step: 80, loss: 0.06694188714027405
step: 90, loss: 0.03068646788597107
step: 100, loss: 0.018841903656721115
step: 110, loss: 0.009847084991633892
step: 120, loss: 0.0027393288910388947
step: 130, loss: 0.006227852776646614
step: 140, loss: 0.058417145162820816
step: 150, loss: 0.00013580387167166919
step: 160, loss: 0.06025614216923714
step: 170, loss: 0.0014894765336066484
step: 180, loss: 0.0193990059196949
step: 190, loss: 0.07648542523384094
step: 200, loss: 0.04461396858096123
step: 210, loss: 0.00040975495357997715
step: 220, loss: 0.07585814595222473
step: 230, loss: 0.012970305047929287
step: 240, loss: 0.1735566258430481
step: 250, loss: 0.02545422874391079
step: 260, loss: 0.0077916341833770275
step: 270, loss: 0.00235407124273479
step: 280, loss: 0.005350017920136452
step: 290, loss: 0.005732307676225901
step: 300, loss: 7.872225251048803e-05
step: 310, loss: 0.006351157557219267
step: 320, loss: 0.0070008994080126286
step: 330, loss: 0.036997731775045395
step: 340, loss: 0.04469381645321846
step: 350, loss: 0.003946282900869846
step: 360, loss: 0.022667845711112022
epoch 13: dev_f1=0.7550000000000001, f1=0.7512953367875648, best_f1=0.7541899441340784
step: 0, loss: 0.0729074478149414
step: 10, loss: 0.018353961408138275
step: 20, loss: 0.0040386999025940895
step: 30, loss: 0.0005596793489530683
step: 40, loss: 0.2797025442123413
step: 50, loss: 0.0682673454284668
step: 60, loss: 0.0056311641819775105
step: 70, loss: 0.003740199375897646
step: 80, loss: 0.0679456815123558
step: 90, loss: 0.042526908218860626
step: 100, loss: 0.005341123789548874
step: 110, loss: 0.035674337297677994
step: 120, loss: 0.013419466093182564
step: 130, loss: 0.022925086319446564
step: 140, loss: 0.015610340051352978
step: 150, loss: 0.0005649863742291927
step: 160, loss: 0.052580464631319046
step: 170, loss: 0.0008849226287566125
step: 180, loss: 0.013056903146207333
step: 190, loss: 0.04109722003340721
step: 200, loss: 0.07122140377759933
step: 210, loss: 0.02311050333082676
step: 220, loss: 0.03266112133860588
step: 230, loss: 0.07872985303401947
step: 240, loss: 0.009282909333705902
step: 250, loss: 0.05371977388858795
step: 260, loss: 0.0005835560150444508
step: 270, loss: 0.010361476801335812
step: 280, loss: 0.020246751606464386
step: 290, loss: 0.0012240057112649083
step: 300, loss: 0.014467276632785797
step: 310, loss: 0.019180675968527794
step: 320, loss: 0.0454590879380703
step: 330, loss: 0.03079032711684704
step: 340, loss: 0.02662072144448757
step: 350, loss: 0.0051139104180037975
step: 360, loss: 0.006757556926459074
epoch 14: dev_f1=0.7571801566579635, f1=0.7472527472527473, best_f1=0.7472527472527473
step: 0, loss: 0.011084637604653835
step: 10, loss: 0.001426331582479179
step: 20, loss: 0.02615642175078392
step: 30, loss: 0.057382531464099884
step: 40, loss: 0.07463518530130386
step: 50, loss: 0.025610340759158134
step: 60, loss: 0.0142778055742383
step: 70, loss: 0.0019256249070167542
step: 80, loss: 0.0007716344553045928
step: 90, loss: 0.0010255674133077264
step: 100, loss: 0.015905151143670082
step: 110, loss: 0.04945538938045502
step: 120, loss: 0.0001063497838913463
step: 130, loss: 0.0266692154109478
step: 140, loss: 0.05610557645559311
step: 150, loss: 0.04822347313165665
step: 160, loss: 0.009441375732421875
step: 170, loss: 0.024857748299837112
step: 180, loss: 0.04402736574411392
step: 190, loss: 0.007125989068299532
step: 200, loss: 0.06135023012757301
step: 210, loss: 0.034537557512521744
step: 220, loss: 0.0006278097280301154
step: 230, loss: 0.0007973895408213139
step: 240, loss: 0.002746655372902751
step: 250, loss: 0.0018327685538679361
step: 260, loss: 0.014521067962050438
step: 270, loss: 0.0004149597662035376
step: 280, loss: 0.03966705873608589
step: 290, loss: 0.055162135511636734
step: 300, loss: 0.06965120136737823
step: 310, loss: 0.0008020612876862288
step: 320, loss: 0.02085350826382637
step: 330, loss: 0.07829225063323975
step: 340, loss: 0.04681824892759323
step: 350, loss: 0.041593972593545914
step: 360, loss: 0.026593191549181938
epoch 15: dev_f1=0.7132169576059851, f1=0.7234042553191489, best_f1=0.7472527472527473
step: 0, loss: 0.0002317827456863597
step: 10, loss: 0.0055588046088814735
step: 20, loss: 0.009639718569815159
step: 30, loss: 0.0014618737623095512
step: 40, loss: 0.010257357731461525
step: 50, loss: 0.09844724833965302
step: 60, loss: 0.03645459935069084
step: 70, loss: 0.004033044911921024
step: 80, loss: 0.006596371531486511
step: 90, loss: 0.029732801020145416
step: 100, loss: 0.05984615907073021
step: 110, loss: 0.05026526749134064
step: 120, loss: 0.0013574321055784822
step: 130, loss: 0.01394069567322731
step: 140, loss: 0.013340629637241364
step: 150, loss: 0.014451330527663231
step: 160, loss: 0.08134844899177551
step: 170, loss: 0.0049760290421545506
step: 180, loss: 4.4905147660756484e-05
step: 190, loss: 0.0676414743065834
step: 200, loss: 0.0018481225706636906
step: 210, loss: 0.04035467654466629
step: 220, loss: 0.00319843553006649
step: 230, loss: 0.05533061921596527
step: 240, loss: 0.00016597607464063913
step: 250, loss: 0.023308776319026947
step: 260, loss: 0.0037168911658227444
step: 270, loss: 0.0823751837015152
step: 280, loss: 0.00020198103447910398
step: 290, loss: 3.938521695090458e-05
step: 300, loss: 3.982018824899569e-05
step: 310, loss: 0.2197379618883133
step: 320, loss: 0.02336348034441471
step: 330, loss: 0.04270369932055473
step: 340, loss: 0.00020093389321118593
step: 350, loss: 0.0002215406420873478
step: 360, loss: 0.0014421980595216155
epoch 16: dev_f1=0.7371273712737126, f1=0.7341040462427746, best_f1=0.7472527472527473
step: 0, loss: 0.0011019074590876698
step: 10, loss: 0.005525022745132446
step: 20, loss: 0.02909751981496811
step: 30, loss: 0.06611286848783493
step: 40, loss: 0.00019592071475926787
step: 50, loss: 0.007906794548034668
step: 60, loss: 5.4931591876083985e-05
step: 70, loss: 0.015079513192176819
step: 80, loss: 0.0004941440420225263
step: 90, loss: 0.002744809491559863
step: 100, loss: 0.024244574829936028
step: 110, loss: 0.0017119449330493808
step: 120, loss: 0.00017472570470999926
step: 130, loss: 0.0522342324256897
step: 140, loss: 4.208466998534277e-05
step: 150, loss: 0.045602813363075256
step: 160, loss: 0.06179173290729523
step: 170, loss: 0.09097998589277267
step: 180, loss: 0.03809526935219765
step: 190, loss: 0.047737281769514084
step: 200, loss: 0.019807137548923492
step: 210, loss: 0.0031757201068103313
step: 220, loss: 0.04127097129821777
step: 230, loss: 0.037463102489709854
step: 240, loss: 0.04320254549384117
step: 250, loss: 0.04190992936491966
step: 260, loss: 0.03099989704787731
step: 270, loss: 0.004694581031799316
step: 280, loss: 0.000295292935334146
step: 290, loss: 0.0004794912529177964
step: 300, loss: 0.018726766109466553
step: 310, loss: 0.0509205125272274
step: 320, loss: 0.029400471597909927
step: 330, loss: 0.001272865803912282
step: 340, loss: 0.020633850246667862
step: 350, loss: 0.0003670596342999488
step: 360, loss: 0.019502516835927963
epoch 17: dev_f1=0.7317073170731708, f1=0.7493540051679587, best_f1=0.7472527472527473
step: 0, loss: 2.610992123663891e-05
step: 10, loss: 0.0026739216409623623
step: 20, loss: 0.033638373017311096
step: 30, loss: 0.00011922267731279135
step: 40, loss: 0.007147541735321283
step: 50, loss: 0.0006113827112130821
step: 60, loss: 0.01502630952745676
step: 70, loss: 0.015715699642896652
step: 80, loss: 0.002295693615451455
step: 90, loss: 0.00010134163312613964
step: 100, loss: 0.0002785332908388227
step: 110, loss: 0.01190662570297718
step: 120, loss: 0.005644721910357475
step: 130, loss: 0.021421706303954124
step: 140, loss: 0.004473076667636633
step: 150, loss: 6.42049708403647e-05
step: 160, loss: 0.00012943363981321454
step: 170, loss: 0.0003624098317231983
step: 180, loss: 0.09154514223337173
step: 190, loss: 0.00048609619261696935
step: 200, loss: 0.027728380635380745
step: 210, loss: 0.014142217114567757
step: 220, loss: 0.0270063653588295
step: 230, loss: 8.171182707883418e-05
step: 240, loss: 0.013724132440984249
step: 250, loss: 0.03007226437330246
step: 260, loss: 0.0004007563693448901
step: 270, loss: 0.00010575415217317641
step: 280, loss: 0.002033146796748042
step: 290, loss: 0.015375974588096142
step: 300, loss: 0.0003011664957739413
step: 310, loss: 0.015740910544991493
step: 320, loss: 0.001006056205369532
step: 330, loss: 7.709688361501321e-05
step: 340, loss: 0.00010989019938278943
step: 350, loss: 0.00020072489860467613
step: 360, loss: 0.00043109196121804416
epoch 18: dev_f1=0.7342995169082126, f1=0.7448979591836734, best_f1=0.7472527472527473
step: 0, loss: 3.9288039261009544e-05
step: 10, loss: 6.339751416817307e-05
step: 20, loss: 0.0008288479875773191
step: 30, loss: 0.001450901385396719
step: 40, loss: 0.1017259731888771
step: 50, loss: 0.04165268689393997
step: 60, loss: 0.04427913576364517
step: 70, loss: 0.002612988231703639
step: 80, loss: 0.00012613773287739605
step: 90, loss: 0.05713711306452751
step: 100, loss: 0.0734870657324791
step: 110, loss: 0.00015295145567506552
step: 120, loss: 0.006853159982711077
step: 130, loss: 0.0006071097450330853
step: 140, loss: 0.011298507452011108
step: 150, loss: 0.03439619019627571
step: 160, loss: 0.016879314556717873
step: 170, loss: 0.041019607335329056
step: 180, loss: 0.03558719530701637
step: 190, loss: 0.000558357045520097
step: 200, loss: 0.013403637334704399
step: 210, loss: 0.02713020145893097
step: 220, loss: 0.001729814917780459
step: 230, loss: 0.007521177176386118
step: 240, loss: 0.01572326570749283
step: 250, loss: 0.01417701318860054
step: 260, loss: 0.000361438374966383
step: 270, loss: 0.02505854144692421
step: 280, loss: 8.635530684841797e-05
step: 290, loss: 0.029472937807440758
step: 300, loss: 0.004311044700443745
step: 310, loss: 0.0007692257058806717
step: 320, loss: 0.052895788103342056
step: 330, loss: 0.00025377367273904383
step: 340, loss: 0.009392285719513893
step: 350, loss: 0.039428818970918655
step: 360, loss: 3.196159013896249e-05
epoch 19: dev_f1=0.717557251908397, f1=0.7393617021276595, best_f1=0.7472527472527473
step: 0, loss: 0.0031316333916038275
step: 10, loss: 0.012768019922077656
step: 20, loss: 0.0004504779353737831
step: 30, loss: 0.014123798348009586
step: 40, loss: 0.01932220160961151
step: 50, loss: 8.054787758737803e-05
step: 60, loss: 0.012152919545769691
step: 70, loss: 0.0026589510962367058
step: 80, loss: 0.07630207389593124
step: 90, loss: 2.5781979275052436e-05
step: 100, loss: 0.022620314732193947
step: 110, loss: 0.05106266960501671
step: 120, loss: 0.016118422150611877
step: 130, loss: 0.05952375382184982
step: 140, loss: 0.06299107521772385
step: 150, loss: 4.4035157770849764e-05
step: 160, loss: 0.02009487710893154
step: 170, loss: 0.004458166658878326
step: 180, loss: 0.0027873290237039328
step: 190, loss: 0.008201084099709988
step: 200, loss: 0.027853302657604218
step: 210, loss: 4.8503348807571456e-05
step: 220, loss: 0.016090374439954758
step: 230, loss: 0.020221276208758354
step: 240, loss: 0.01932722143828869
step: 250, loss: 0.00029347537201829255
step: 260, loss: 0.0026622998993843794
step: 270, loss: 0.0003401794529054314
step: 280, loss: 0.003695204621180892
step: 290, loss: 0.0464295893907547
step: 300, loss: 0.0031822642777115107
step: 310, loss: 0.06041755527257919
step: 320, loss: 0.028162332251667976
step: 330, loss: 0.04593854025006294
step: 340, loss: 0.011560690589249134
step: 350, loss: 0.0004500985087361187
step: 360, loss: 0.07279610633850098
epoch 20: dev_f1=0.7229551451187335, f1=0.743801652892562, best_f1=0.7472527472527473
