cuda
Device: cuda
step: 0, loss: 0.7977784276008606
step: 10, loss: 0.24076484143733978
step: 20, loss: 0.23136384785175323
step: 30, loss: 0.13809780776500702
step: 40, loss: 0.24247314035892487
step: 50, loss: 0.23036696016788483
step: 60, loss: 0.14766670763492584
step: 70, loss: 0.23541277647018433
step: 80, loss: 0.14083418250083923
step: 90, loss: 0.03365889564156532
step: 100, loss: 0.45957323908805847
step: 110, loss: 0.1332910656929016
step: 120, loss: 0.20478984713554382
step: 130, loss: 0.1375778764486313
step: 140, loss: 0.020911945030093193
step: 150, loss: 0.3410223424434662
step: 160, loss: 0.14019373059272766
step: 170, loss: 0.04357665032148361
step: 180, loss: 0.21701392531394958
step: 190, loss: 0.2953507900238037
step: 200, loss: 0.21317178010940552
step: 210, loss: 0.04105705767869949
step: 220, loss: 0.25826263427734375
step: 230, loss: 0.060072753578424454
step: 240, loss: 0.0912260040640831
step: 250, loss: 0.12534897029399872
step: 260, loss: 0.27924591302871704
step: 270, loss: 0.20739825069904327
step: 280, loss: 0.14524520933628082
step: 290, loss: 0.0530211515724659
step: 300, loss: 0.18927182257175446
step: 310, loss: 0.15269283950328827
step: 320, loss: 0.16425591707229614
step: 330, loss: 0.14758792519569397
step: 340, loss: 0.009795095771551132
step: 350, loss: 0.23606359958648682
step: 360, loss: 0.07315706461668015
epoch 1: dev_f1=0.550632911392405, f1=0.5098039215686274, best_f1=0.5098039215686274
step: 0, loss: 0.08067325502634048
step: 10, loss: 0.1163468062877655
step: 20, loss: 0.085954450070858
step: 30, loss: 0.08205205947160721
step: 40, loss: 0.0966888964176178
step: 50, loss: 0.16019366681575775
step: 60, loss: 0.3033490777015686
step: 70, loss: 0.009525739587843418
step: 80, loss: 0.1284097582101822
step: 90, loss: 0.023679394274950027
step: 100, loss: 0.06193500757217407
step: 110, loss: 0.0874989777803421
step: 120, loss: 0.23875413835048676
step: 130, loss: 0.050601355731487274
step: 140, loss: 0.027425261214375496
step: 150, loss: 0.010085432790219784
step: 160, loss: 0.12530650198459625
step: 170, loss: 0.05393240973353386
step: 180, loss: 0.13477522134780884
step: 190, loss: 0.06446350365877151
step: 200, loss: 0.10471150279045105
step: 210, loss: 0.12232320010662079
step: 220, loss: 0.14716312289237976
step: 230, loss: 0.09680549055337906
step: 240, loss: 0.20725657045841217
step: 250, loss: 0.12006641179323196
step: 260, loss: 0.16646388173103333
step: 270, loss: 0.1167495995759964
step: 280, loss: 0.019486475735902786
step: 290, loss: 0.061039045453071594
step: 300, loss: 0.17345549166202545
step: 310, loss: 0.10756658017635345
step: 320, loss: 0.3601157069206238
step: 330, loss: 0.22247038781642914
step: 340, loss: 0.22488071024417877
step: 350, loss: 0.051787201315164566
step: 360, loss: 0.14480844140052795
epoch 2: dev_f1=0.7197802197802198, f1=0.7327823691460055, best_f1=0.7327823691460055
step: 0, loss: 0.0756925642490387
step: 10, loss: 0.16626259684562683
step: 20, loss: 0.07472675293684006
step: 30, loss: 0.15304437279701233
step: 40, loss: 0.10117226839065552
step: 50, loss: 0.06335601955652237
step: 60, loss: 0.1672883927822113
step: 70, loss: 0.15350009500980377
step: 80, loss: 0.043593019247055054
step: 90, loss: 0.05485226586461067
step: 100, loss: 0.08109527081251144
step: 110, loss: 0.1401156336069107
step: 120, loss: 0.045149125158786774
step: 130, loss: 0.26428893208503723
step: 140, loss: 0.08301906287670135
step: 150, loss: 0.032798346132040024
step: 160, loss: 0.032126106321811676
step: 170, loss: 0.08579155057668686
step: 180, loss: 0.11278307437896729
step: 190, loss: 0.005682328250259161
step: 200, loss: 0.11205429583787918
step: 210, loss: 0.2733651101589203
step: 220, loss: 0.0851253792643547
step: 230, loss: 0.02877628803253174
step: 240, loss: 0.04222756624221802
step: 250, loss: 0.02047896385192871
step: 260, loss: 0.056937940418720245
step: 270, loss: 0.13977602124214172
step: 280, loss: 0.09994463622570038
step: 290, loss: 0.1386338621377945
step: 300, loss: 0.3055759072303772
step: 310, loss: 0.03277886286377907
step: 320, loss: 0.09337110817432404
step: 330, loss: 0.025999179109930992
step: 340, loss: 0.0769796147942543
step: 350, loss: 0.04886594042181969
step: 360, loss: 0.09925807267427444
epoch 3: dev_f1=0.7121951219512195, f1=0.7525773195876289, best_f1=0.7327823691460055
step: 0, loss: 0.14192511141300201
step: 10, loss: 0.05621762573719025
step: 20, loss: 0.06534657627344131
step: 30, loss: 0.0013248224277049303
step: 40, loss: 0.06582629680633545
step: 50, loss: 0.16116106510162354
step: 60, loss: 0.011885615065693855
step: 70, loss: 0.03668783977627754
step: 80, loss: 0.08966460078954697
step: 90, loss: 0.0768657699227333
step: 100, loss: 0.13629265129566193
step: 110, loss: 0.05317769944667816
step: 120, loss: 0.1756143867969513
step: 130, loss: 0.022783422842621803
step: 140, loss: 0.09318534284830093
step: 150, loss: 0.08035914599895477
step: 160, loss: 0.03083845041692257
step: 170, loss: 0.04686186835169792
step: 180, loss: 0.0840383768081665
step: 190, loss: 0.09087197482585907
step: 200, loss: 0.05319127440452576
step: 210, loss: 0.06403517723083496
step: 220, loss: 0.351248174905777
step: 230, loss: 0.0024841565173119307
step: 240, loss: 0.03237851336598396
step: 250, loss: 0.10868889838457108
step: 260, loss: 0.05003131926059723
step: 270, loss: 0.02389836497604847
step: 280, loss: 0.1454160213470459
step: 290, loss: 0.14373067021369934
step: 300, loss: 0.07550671696662903
step: 310, loss: 0.08669236302375793
step: 320, loss: 0.06991703063249588
step: 330, loss: 0.09183990955352783
step: 340, loss: 0.042163681238889694
step: 350, loss: 0.017175080254673958
step: 360, loss: 0.12032603472471237
epoch 4: dev_f1=0.7417582417582418, f1=0.7186629526462396, best_f1=0.7186629526462396
step: 0, loss: 0.045168135315179825
step: 10, loss: 0.06042267754673958
step: 20, loss: 0.0028156284242868423
step: 30, loss: 0.09666016697883606
step: 40, loss: 0.01012478955090046
step: 50, loss: 0.07346043735742569
step: 60, loss: 0.022826753556728363
step: 70, loss: 0.06301416456699371
step: 80, loss: 0.07427732646465302
step: 90, loss: 0.016996119171380997
step: 100, loss: 0.021356509998440742
step: 110, loss: 0.037552110850811005
step: 120, loss: 0.08076488226652145
step: 130, loss: 0.0319288894534111
step: 140, loss: 0.06030205264687538
step: 150, loss: 0.03436104953289032
step: 160, loss: 0.014179772697389126
step: 170, loss: 0.10204844176769257
step: 180, loss: 0.047074493020772934
step: 190, loss: 0.044467926025390625
step: 200, loss: 0.09506382793188095
step: 210, loss: 0.06874588131904602
step: 220, loss: 0.2547457218170166
step: 230, loss: 0.03533323109149933
step: 240, loss: 0.05165619030594826
step: 250, loss: 0.09714112430810928
step: 260, loss: 0.0782698318362236
step: 270, loss: 0.10997524112462997
step: 280, loss: 0.11165587604045868
step: 290, loss: 0.06893117725849152
step: 300, loss: 0.1352744996547699
step: 310, loss: 0.061928872019052505
step: 320, loss: 0.16274720430374146
step: 330, loss: 0.015179905109107494
step: 340, loss: 0.06172989681363106
step: 350, loss: 0.06155664473772049
step: 360, loss: 0.012208263389766216
epoch 5: dev_f1=0.739795918367347, f1=0.7216494845360825, best_f1=0.7186629526462396
step: 0, loss: 0.10491245985031128
step: 10, loss: 0.0597749724984169
step: 20, loss: 0.11709609627723694
step: 30, loss: 0.04977693781256676
step: 40, loss: 0.011957576498389244
step: 50, loss: 0.08004984259605408
step: 60, loss: 0.06343132257461548
step: 70, loss: 0.010280814953148365
step: 80, loss: 0.054495830088853836
step: 90, loss: 0.05029936879873276
step: 100, loss: 0.015840252861380577
step: 110, loss: 0.07050333172082901
step: 120, loss: 0.09905701875686646
step: 130, loss: 0.11983266472816467
step: 140, loss: 0.007491174153983593
step: 150, loss: 0.06430384516716003
step: 160, loss: 0.015023890882730484
step: 170, loss: 0.032221078872680664
step: 180, loss: 0.006104545202106237
step: 190, loss: 0.08751878142356873
step: 200, loss: 0.0019693919457495213
step: 210, loss: 0.0029737462755292654
step: 220, loss: 0.0737907662987709
step: 230, loss: 0.06463489681482315
step: 240, loss: 0.032388415187597275
step: 250, loss: 0.041645437479019165
step: 260, loss: 0.0503791905939579
step: 270, loss: 0.0683894231915474
step: 280, loss: 0.06656894087791443
step: 290, loss: 0.10455768555402756
step: 300, loss: 0.050772856920957565
step: 310, loss: 0.0925208032131195
step: 320, loss: 0.017016883939504623
step: 330, loss: 0.04060647636651993
step: 340, loss: 0.020216763019561768
step: 350, loss: 0.011108346283435822
step: 360, loss: 0.07606352120637894
epoch 6: dev_f1=0.720626631853786, f1=0.7296587926509187, best_f1=0.7186629526462396
step: 0, loss: 0.02977236919105053
step: 10, loss: 0.0626591145992279
step: 20, loss: 0.06641127914190292
step: 30, loss: 0.11590518802404404
step: 40, loss: 0.011106710880994797
step: 50, loss: 0.10155434906482697
step: 60, loss: 0.023785633966326714
step: 70, loss: 0.01274692453444004
step: 80, loss: 0.05315109342336655
step: 90, loss: 0.027996383607387543
step: 100, loss: 0.026198945939540863
step: 110, loss: 0.008900909684598446
step: 120, loss: 0.05933290719985962
step: 130, loss: 0.048371508717536926
step: 140, loss: 0.08304939419031143
step: 150, loss: 0.030254974961280823
step: 160, loss: 0.031529735773801804
step: 170, loss: 0.0855206623673439
step: 180, loss: 0.05841987207531929
step: 190, loss: 0.11295809596776962
step: 200, loss: 0.030871093273162842
step: 210, loss: 0.02609049528837204
step: 220, loss: 0.004025509115308523
step: 230, loss: 0.018700195476412773
step: 240, loss: 0.05394371598958969
step: 250, loss: 0.0001125227936427109
step: 260, loss: 0.02422771044075489
step: 270, loss: 0.010175580158829689
step: 280, loss: 0.0009368086466565728
step: 290, loss: 0.11730019748210907
step: 300, loss: 0.022545101121068
step: 310, loss: 0.00022023171186447144
step: 320, loss: 0.038932397961616516
step: 330, loss: 0.009644300676882267
step: 340, loss: 0.08759405463933945
step: 350, loss: 0.048603758215904236
step: 360, loss: 0.08649254590272903
epoch 7: dev_f1=0.7405541561712846, f1=0.7329842931937172, best_f1=0.7186629526462396
step: 0, loss: 0.015247518196702003
step: 10, loss: 0.11855626851320267
step: 20, loss: 0.022144610062241554
step: 30, loss: 0.03154445439577103
step: 40, loss: 0.11754973977804184
step: 50, loss: 0.046435289084911346
step: 60, loss: 0.02966586872935295
step: 70, loss: 0.009590357542037964
step: 80, loss: 0.0743151605129242
step: 90, loss: 0.0013173730112612247
step: 100, loss: 0.01483649667352438
step: 110, loss: 0.051666319370269775
step: 120, loss: 0.10135471075773239
step: 130, loss: 0.04068689048290253
step: 140, loss: 0.08608634769916534
step: 150, loss: 0.021087050437927246
step: 160, loss: 4.951113078277558e-05
step: 170, loss: 0.04215756803750992
step: 180, loss: 0.02853955700993538
step: 190, loss: 0.011920463293790817
step: 200, loss: 0.001687560579739511
step: 210, loss: 0.01977960392832756
step: 220, loss: 0.05380946397781372
step: 230, loss: 0.021798107773065567
step: 240, loss: 0.0015533323166891932
step: 250, loss: 0.03435703366994858
step: 260, loss: 0.10947923362255096
step: 270, loss: 0.036129653453826904
step: 280, loss: 0.03320660442113876
step: 290, loss: 0.037827976047992706
step: 300, loss: 0.0005062840064056218
step: 310, loss: 0.03851384297013283
step: 320, loss: 0.07579901814460754
step: 330, loss: 0.07749515771865845
step: 340, loss: 0.001638572895899415
step: 350, loss: 0.12234494090080261
step: 360, loss: 0.010342681780457497
epoch 8: dev_f1=0.7445255474452556, f1=0.7300771208226221, best_f1=0.7300771208226221
step: 0, loss: 0.06088491156697273
step: 10, loss: 0.07043152302503586
step: 20, loss: 0.06498100608587265
step: 30, loss: 0.037785809487104416
step: 40, loss: 0.05116930976510048
step: 50, loss: 0.02046521008014679
step: 60, loss: 0.01106896623969078
step: 70, loss: 0.08078041672706604
step: 80, loss: 0.11497430503368378
step: 90, loss: 0.05887240543961525
step: 100, loss: 0.061917442828416824
step: 110, loss: 0.03248846158385277
step: 120, loss: 0.13480836153030396
step: 130, loss: 0.09606562554836273
step: 140, loss: 0.043734561651945114
step: 150, loss: 0.0065545630641281605
step: 160, loss: 0.0017144038574770093
step: 170, loss: 0.0338016077876091
step: 180, loss: 0.031169328838586807
step: 190, loss: 0.01574626937508583
step: 200, loss: 0.008884124457836151
step: 210, loss: 0.008383971638977528
step: 220, loss: 0.06567957997322083
step: 230, loss: 0.008092601783573627
step: 240, loss: 0.0066774082370102406
step: 250, loss: 0.01977308839559555
step: 260, loss: 8.844572585076094e-05
step: 270, loss: 0.09948080033063889
step: 280, loss: 0.024428000673651695
step: 290, loss: 0.05494385585188866
step: 300, loss: 0.02961544319987297
step: 310, loss: 0.029119662940502167
step: 320, loss: 0.032738156616687775
step: 330, loss: 0.030045200139284134
step: 340, loss: 0.017951563000679016
step: 350, loss: 0.07625749707221985
step: 360, loss: 0.06282612681388855
epoch 9: dev_f1=0.7506426735218509, f1=0.7351351351351353, best_f1=0.7351351351351353
step: 0, loss: 0.0893181711435318
step: 10, loss: 0.04751510173082352
step: 20, loss: 0.013398618437349796
step: 30, loss: 0.027916621416807175
step: 40, loss: 0.008371139876544476
step: 50, loss: 0.0664086565375328
step: 60, loss: 0.022099895402789116
step: 70, loss: 0.03763335943222046
step: 80, loss: 7.762082532281056e-05
step: 90, loss: 0.03187822178006172
step: 100, loss: 0.03101923130452633
step: 110, loss: 0.12049929052591324
step: 120, loss: 0.014092909172177315
step: 130, loss: 0.058312952518463135
step: 140, loss: 0.035552602261304855
step: 150, loss: 0.0024613975547254086
step: 160, loss: 0.020022766664624214
step: 170, loss: 0.02072913385927677
step: 180, loss: 0.040306687355041504
step: 190, loss: 0.004573175683617592
step: 200, loss: 0.019966378808021545
step: 210, loss: 0.06992357969284058
step: 220, loss: 0.15578092634677887
step: 230, loss: 0.0008598743588663638
step: 240, loss: 0.026245558634400368
step: 250, loss: 0.01050704438239336
step: 260, loss: 0.09973594546318054
step: 270, loss: 0.02235034853219986
step: 280, loss: 0.008618484251201153
step: 290, loss: 0.045884355902671814
step: 300, loss: 0.03984071686863899
step: 310, loss: 0.012617734260857105
step: 320, loss: 0.059370048344135284
step: 330, loss: 0.002428361214697361
step: 340, loss: 0.1626124382019043
step: 350, loss: 0.0673334002494812
step: 360, loss: 0.11762836575508118
epoch 10: dev_f1=0.7223719676549865, f1=0.707182320441989, best_f1=0.7351351351351353
step: 0, loss: 0.039346843957901
step: 10, loss: 0.003288448555395007
step: 20, loss: 0.0015810762997716665
step: 30, loss: 0.004191369749605656
step: 40, loss: 6.11002542427741e-05
step: 50, loss: 0.007707471959292889
step: 60, loss: 0.0452754870057106
step: 70, loss: 0.07710667699575424
step: 80, loss: 0.025322550907731056
step: 90, loss: 0.04515838250517845
step: 100, loss: 0.046064216643571854
step: 110, loss: 0.06345917284488678
step: 120, loss: 0.041585806757211685
step: 130, loss: 0.07323367148637772
step: 140, loss: 0.01197052001953125
step: 150, loss: 0.007438648492097855
step: 160, loss: 0.004441521596163511
step: 170, loss: 0.060345351696014404
step: 180, loss: 0.029920669272542
step: 190, loss: 0.00031750346533954144
step: 200, loss: 0.07417908310890198
step: 210, loss: 0.0669061467051506
step: 220, loss: 0.030148465186357498
step: 230, loss: 0.04121732711791992
step: 240, loss: 0.004474823363125324
step: 250, loss: 0.00014131357602309436
step: 260, loss: 0.09312369674444199
step: 270, loss: 0.031161852180957794
step: 280, loss: 0.11228455603122711
step: 290, loss: 3.461810774751939e-05
step: 300, loss: 0.03176892176270485
step: 310, loss: 0.016663983464241028
step: 320, loss: 0.14033810794353485
step: 330, loss: 0.03126360476016998
step: 340, loss: 0.03909562900662422
step: 350, loss: 0.05077251419425011
step: 360, loss: 0.008168046362698078
epoch 11: dev_f1=0.7439353099730459, f1=0.7267605633802817, best_f1=0.7351351351351353
step: 0, loss: 0.034762945026159286
step: 10, loss: 0.020711960271000862
step: 20, loss: 0.0006357914535328746
step: 30, loss: 9.49601671891287e-05
step: 40, loss: 0.0026955497451126575
step: 50, loss: 0.017209278419613838
step: 60, loss: 0.09643055498600006
step: 70, loss: 0.08319057524204254
step: 80, loss: 0.03756755590438843
step: 90, loss: 0.0274388175457716
step: 100, loss: 0.007643790449947119
step: 110, loss: 0.009679545648396015
step: 120, loss: 0.0022365122567862272
step: 130, loss: 0.008616712875664234
step: 140, loss: 0.0018082046881318092
step: 150, loss: 0.06265813857316971
step: 160, loss: 0.0005410184385254979
step: 170, loss: 0.002769891871139407
step: 180, loss: 0.0014181238366290927
step: 190, loss: 0.028364285826683044
step: 200, loss: 0.035836152732372284
step: 210, loss: 0.003758837468922138
step: 220, loss: 0.00019248445460107177
step: 230, loss: 0.006387867499142885
step: 240, loss: 0.017606191337108612
step: 250, loss: 2.6944338969769888e-05
step: 260, loss: 0.0002451259351801127
step: 270, loss: 0.016906416043639183
step: 280, loss: 0.013662717305123806
step: 290, loss: 2.845657945726998e-05
step: 300, loss: 0.09299902617931366
step: 310, loss: 0.02674000710248947
step: 320, loss: 0.009765533730387688
step: 330, loss: 0.12325325608253479
step: 340, loss: 0.020765839144587517
step: 350, loss: 0.03080638498067856
step: 360, loss: 3.285821003373712e-05
epoch 12: dev_f1=0.7252747252747253, f1=0.7093023255813953, best_f1=0.7351351351351353
step: 0, loss: 0.0585147999227047
step: 10, loss: 0.058201927691698074
step: 20, loss: 0.035471901297569275
step: 30, loss: 0.058733973652124405
step: 40, loss: 0.0014970594784244895
step: 50, loss: 0.08161070942878723
step: 60, loss: 0.05087550729513168
step: 70, loss: 0.034890685230493546
step: 80, loss: 0.012417975813150406
step: 90, loss: 0.026877818629145622
step: 100, loss: 0.0723884329199791
step: 110, loss: 0.038734667003154755
step: 120, loss: 3.0937586416257545e-05
step: 130, loss: 0.032969679683446884
step: 140, loss: 0.04581044614315033
step: 150, loss: 0.06640135496854782
step: 160, loss: 0.04544175788760185
step: 170, loss: 0.057793207466602325
step: 180, loss: 0.017956364899873734
step: 190, loss: 0.004217197652906179
step: 200, loss: 0.0317704975605011
step: 210, loss: 0.1049165353178978
step: 220, loss: 0.003149089403450489
step: 230, loss: 0.12212276458740234
step: 240, loss: 0.04672268033027649
step: 250, loss: 0.0174599327147007
step: 260, loss: 0.03135215491056442
step: 270, loss: 0.0027667817194014788
step: 280, loss: 1.6219772078329697e-05
step: 290, loss: 0.023406989872455597
step: 300, loss: 0.06222277134656906
step: 310, loss: 0.007916496135294437
step: 320, loss: 0.002979984739795327
step: 330, loss: 0.014073318801820278
step: 340, loss: 0.017679359763860703
step: 350, loss: 0.02875100076198578
step: 360, loss: 0.04120057448744774
epoch 13: dev_f1=0.7302452316076293, f1=0.7215909090909091, best_f1=0.7351351351351353
step: 0, loss: 0.008863777853548527
step: 10, loss: 0.05404508858919144
step: 20, loss: 0.0348394401371479
step: 30, loss: 0.06429684162139893
step: 40, loss: 0.05309651792049408
step: 50, loss: 0.160567969083786
step: 60, loss: 0.00171366473659873
step: 70, loss: 0.0013326809275895357
step: 80, loss: 0.09052974730730057
step: 90, loss: 0.004208873026072979
step: 100, loss: 0.029153335839509964
step: 110, loss: 0.0801505371928215
step: 120, loss: 0.02175339125096798
step: 130, loss: 0.025287389755249023
step: 140, loss: 0.018171191215515137
step: 150, loss: 0.011766829527914524
step: 160, loss: 0.0019311342621222138
step: 170, loss: 0.0016678053652867675
step: 180, loss: 0.04858919978141785
step: 190, loss: 0.021497702226042747
step: 200, loss: 0.029352249577641487
step: 210, loss: 0.05032613128423691
step: 220, loss: 0.015475358814001083
step: 230, loss: 0.022986222058534622
step: 240, loss: 0.015887733548879623
step: 250, loss: 0.05631355941295624
step: 260, loss: 0.0031526447273790836
step: 270, loss: 2.3788534235791303e-05
step: 280, loss: 0.0033865186851471663
step: 290, loss: 0.0153514938428998
step: 300, loss: 0.08806291222572327
step: 310, loss: 0.08495885133743286
step: 320, loss: 0.0003434254031162709
step: 330, loss: 0.05166883021593094
step: 340, loss: 0.0444108285009861
step: 350, loss: 0.023977523669600487
step: 360, loss: 0.03696815297007561
epoch 14: dev_f1=0.7241379310344828, f1=0.7015706806282722, best_f1=0.7351351351351353
step: 0, loss: 0.0008595356484875083
step: 10, loss: 0.0010436618467792869
step: 20, loss: 2.4608225430711173e-05
step: 30, loss: 0.1344992071390152
step: 40, loss: 0.0003587314276956022
step: 50, loss: 0.0453730933368206
step: 60, loss: 0.022500479593873024
step: 70, loss: 0.015137830749154091
step: 80, loss: 0.0044014668092131615
step: 90, loss: 1.7747061065165326e-05
step: 100, loss: 0.035562049597501755
step: 110, loss: 0.001761926687322557
step: 120, loss: 0.03291294351220131
step: 130, loss: 0.02009037509560585
step: 140, loss: 1.7285150534007698e-05
step: 150, loss: 0.03589891269803047
step: 160, loss: 0.022138547152280807
step: 170, loss: 0.002068627392873168
step: 180, loss: 0.04451495036482811
step: 190, loss: 9.856326505541801e-05
step: 200, loss: 0.0023611034266650677
step: 210, loss: 0.00601961649954319
step: 220, loss: 0.01945708692073822
step: 230, loss: 0.00035344171919859946
step: 240, loss: 0.09333185851573944
step: 250, loss: 0.0026443125680088997
step: 260, loss: 0.005180181469768286
step: 270, loss: 0.00655784597620368
step: 280, loss: 0.023556267842650414
step: 290, loss: 0.051646776497364044
step: 300, loss: 0.03191416710615158
step: 310, loss: 0.0038350154645740986
step: 320, loss: 0.008573364466428757
step: 330, loss: 0.01136767864227295
step: 340, loss: 0.010269301943480968
step: 350, loss: 0.060014523565769196
step: 360, loss: 0.005554440896958113
epoch 15: dev_f1=0.7100271002710027, f1=0.7036011080332409, best_f1=0.7351351351351353
step: 0, loss: 0.0019258859101682901
step: 10, loss: 0.030207009986042976
step: 20, loss: 0.011593678966164589
step: 30, loss: 0.058605317026376724
step: 40, loss: 0.0032758344896137714
step: 50, loss: 0.006232603453099728
step: 60, loss: 0.0001393599814036861
step: 70, loss: 0.025085555389523506
step: 80, loss: 0.020960364490747452
step: 90, loss: 0.06581760197877884
step: 100, loss: 0.026567799970507622
step: 110, loss: 0.003921308554708958
step: 120, loss: 0.13527147471904755
step: 130, loss: 3.5370903788134456e-05
step: 140, loss: 0.01813581958413124
step: 150, loss: 0.016143683344125748
step: 160, loss: 0.007606456521898508
step: 170, loss: 0.005722979083657265
step: 180, loss: 0.008579562418162823
step: 190, loss: 0.01199430413544178
step: 200, loss: 0.0002689847315195948
step: 210, loss: 0.01602703519165516
step: 220, loss: 0.035111624747514725
step: 230, loss: 0.03410107642412186
step: 240, loss: 0.001056817825883627
step: 250, loss: 0.05232851207256317
step: 260, loss: 0.06172911450266838
step: 270, loss: 0.13310685753822327
step: 280, loss: 0.001982220681384206
step: 290, loss: 0.0009603988728486001
step: 300, loss: 0.042481884360313416
step: 310, loss: 1.5806275769136846e-05
step: 320, loss: 0.04942161589860916
step: 330, loss: 0.003307854989543557
step: 340, loss: 0.00035998845123685896
step: 350, loss: 0.007202739827334881
step: 360, loss: 0.024723060429096222
epoch 16: dev_f1=0.704225352112676, f1=0.686046511627907, best_f1=0.7351351351351353
step: 0, loss: 1.7303789718425833e-05
step: 10, loss: 0.01755756139755249
step: 20, loss: 0.06881766766309738
step: 30, loss: 0.016711754724383354
step: 40, loss: 0.01697380468249321
step: 50, loss: 0.00406178692355752
step: 60, loss: 0.0023459824733436108
step: 70, loss: 0.030610164627432823
step: 80, loss: 0.09625893831253052
step: 90, loss: 0.05847815424203873
step: 100, loss: 0.0003262438694946468
step: 110, loss: 0.019391339272260666
step: 120, loss: 1.984799382626079e-05
step: 130, loss: 7.111523154890165e-05
step: 140, loss: 0.009667936712503433
step: 150, loss: 0.009258342906832695
step: 160, loss: 0.04909331724047661
step: 170, loss: 0.009851313196122646
step: 180, loss: 0.0017168528866022825
step: 190, loss: 0.028856361284852028
step: 200, loss: 0.05721456930041313
step: 210, loss: 0.0028275884687900543
step: 220, loss: 0.01238692831248045
step: 230, loss: 0.03528863564133644
step: 240, loss: 2.1661857317667454e-05
step: 250, loss: 0.042454786598682404
step: 260, loss: 0.04914548248052597
step: 270, loss: 0.06374134868383408
step: 280, loss: 0.10467406362295151
step: 290, loss: 0.06405529379844666
step: 300, loss: 0.015388933941721916
step: 310, loss: 0.0010781517485156655
step: 320, loss: 0.02307361178100109
step: 330, loss: 0.04023488983511925
step: 340, loss: 0.0018023756565526128
step: 350, loss: 0.028503824025392532
step: 360, loss: 1.4681247193948366e-05
epoch 17: dev_f1=0.707774798927614, f1=0.7005649717514124, best_f1=0.7351351351351353
step: 0, loss: 0.025086985900998116
step: 10, loss: 9.313588816439733e-05
step: 20, loss: 2.2336209440254606e-05
step: 30, loss: 0.0003184340021107346
step: 40, loss: 0.01628187485039234
step: 50, loss: 0.0357104055583477
step: 60, loss: 0.02101053297519684
step: 70, loss: 0.02252628467977047
step: 80, loss: 0.032547593116760254
step: 90, loss: 0.001234266790561378
step: 100, loss: 0.0001278071285923943
step: 110, loss: 0.08354005217552185
step: 120, loss: 0.0006305194110609591
step: 130, loss: 0.021364975720643997
step: 140, loss: 0.07575864344835281
step: 150, loss: 0.019514568150043488
step: 160, loss: 0.0014594892272725701
step: 170, loss: 0.0004454801674000919
step: 180, loss: 0.05955168977379799
step: 190, loss: 0.0005029382300563157
step: 200, loss: 0.02084588073194027
step: 210, loss: 2.1222369468887337e-05
step: 220, loss: 0.01569996029138565
step: 230, loss: 0.03382702171802521
step: 240, loss: 0.12060026079416275
step: 250, loss: 0.030978651717305183
step: 260, loss: 0.0008610111544840038
step: 270, loss: 0.021381529048085213
step: 280, loss: 0.021174350753426552
step: 290, loss: 0.0849166214466095
step: 300, loss: 0.007962003350257874
step: 310, loss: 0.0012602051720023155
step: 320, loss: 7.907103281468153e-05
step: 330, loss: 0.01983073726296425
step: 340, loss: 0.007338536437600851
step: 350, loss: 0.0005470938631333411
step: 360, loss: 0.006075046490877867
epoch 18: dev_f1=0.7222222222222222, f1=0.6961651917404129, best_f1=0.7351351351351353
step: 0, loss: 0.007276586722582579
step: 10, loss: 0.0006708201253786683
step: 20, loss: 0.015078999102115631
step: 30, loss: 0.021043511107563972
step: 40, loss: 0.005956314504146576
step: 50, loss: 0.053516536951065063
step: 60, loss: 0.011267836205661297
step: 70, loss: 0.0373772569000721
step: 80, loss: 0.013860178180038929
step: 90, loss: 0.03470039367675781
step: 100, loss: 0.0020285106729716063
step: 110, loss: 0.05444571375846863
step: 120, loss: 0.0007724542520008981
step: 130, loss: 0.009444491937756538
step: 140, loss: 0.013486656360328197
step: 150, loss: 0.00012680201325565577
step: 160, loss: 0.033850304782390594
step: 170, loss: 0.0005154478712938726
step: 180, loss: 0.00011827400885522366
step: 190, loss: 0.0005237613222561777
step: 200, loss: 0.01868429034948349
step: 210, loss: 0.02953444793820381
step: 220, loss: 7.873701542848721e-05
step: 230, loss: 0.00012649368727579713
step: 240, loss: 8.524735312676057e-05
step: 250, loss: 1.710624019324314e-05
step: 260, loss: 0.03446383401751518
step: 270, loss: 0.038155823945999146
step: 280, loss: 0.00017773840227164328
step: 290, loss: 0.0002662080805748701
step: 300, loss: 2.1132771507836878e-05
step: 310, loss: 0.0030452038627117872
step: 320, loss: 0.0012231678701937199
step: 330, loss: 0.00038641842547804117
step: 340, loss: 0.0005505427252501249
step: 350, loss: 0.0321657694876194
step: 360, loss: 0.0048112873919308186
epoch 19: dev_f1=0.7058823529411765, f1=0.6900584795321637, best_f1=0.7351351351351353
step: 0, loss: 0.00817389041185379
step: 10, loss: 0.00024652929278090596
step: 20, loss: 8.152039663400501e-05
step: 30, loss: 0.02859482169151306
step: 40, loss: 1.6193453120649792e-05
step: 50, loss: 0.025467274710536003
step: 60, loss: 0.005192565266042948
step: 70, loss: 0.00011636913404799998
step: 80, loss: 0.0008008804288692772
step: 90, loss: 1.5821125998627394e-05
step: 100, loss: 1.308681476075435e-05
step: 110, loss: 0.0009058937430381775
step: 120, loss: 2.0462257452891208e-05
step: 130, loss: 0.0004880872438661754
step: 140, loss: 0.0033284907694905996
step: 150, loss: 1.2766473446390592e-05
step: 160, loss: 0.0015348768793046474
step: 170, loss: 0.003990077879279852
step: 180, loss: 0.0009120217873714864
step: 190, loss: 0.00044645395246334374
step: 200, loss: 0.000555110105779022
step: 210, loss: 0.05812603235244751
step: 220, loss: 7.760056178085506e-05
step: 230, loss: 0.000555393984541297
step: 240, loss: 0.04055345430970192
step: 250, loss: 0.03970544785261154
step: 260, loss: 0.00045405220589600503
step: 270, loss: 0.0002952535287477076
step: 280, loss: 0.020419087260961533
step: 290, loss: 0.003099041525274515
step: 300, loss: 2.077105818898417e-05
step: 310, loss: 9.999782923841849e-05
step: 320, loss: 0.05244611203670502
step: 330, loss: 0.003503825981169939
step: 340, loss: 0.0006732075707986951
step: 350, loss: 0.019374649971723557
step: 360, loss: 0.00042948927148245275
epoch 20: dev_f1=0.7123287671232876, f1=0.6954022988505747, best_f1=0.7351351351351353
