cuda
Device: cuda
step: 0, loss: 0.4994332790374756
step: 10, loss: 0.2798444330692291
step: 20, loss: 0.02523813769221306
step: 30, loss: 0.22896987199783325
step: 40, loss: 0.09411530196666718
step: 50, loss: 0.1317952275276184
step: 60, loss: 0.15193547308444977
step: 70, loss: 0.12288893759250641
step: 80, loss: 0.141479954123497
step: 90, loss: 0.12048911303281784
step: 100, loss: 0.2209578901529312
step: 110, loss: 0.19979287683963776
step: 120, loss: 0.2441525012254715
step: 130, loss: 0.045833948999643326
step: 140, loss: 0.14516472816467285
step: 150, loss: 0.19149567186832428
step: 160, loss: 0.07340574264526367
step: 170, loss: 0.46262818574905396
step: 180, loss: 0.18359550833702087
step: 190, loss: 0.019873978570103645
step: 200, loss: 0.16570645570755005
step: 210, loss: 0.18753176927566528
step: 220, loss: 0.07304680347442627
step: 230, loss: 0.08521812409162521
step: 240, loss: 0.4267410933971405
step: 250, loss: 0.02460024505853653
step: 260, loss: 0.18979409337043762
step: 270, loss: 0.026965739205479622
step: 280, loss: 0.0663987398147583
step: 290, loss: 0.11711222678422928
step: 300, loss: 0.2865370512008667
step: 310, loss: 0.25130903720855713
step: 320, loss: 0.24379213154315948
step: 330, loss: 0.2755734920501709
step: 340, loss: 0.19255080819129944
step: 350, loss: 0.14008846879005432
step: 360, loss: 0.02120673842728138
epoch 1: dev_f1=0.6130952380952381, f1=0.6781609195402298, best_f1=0.6781609195402298
step: 0, loss: 0.1083928644657135
step: 10, loss: 0.14226600527763367
step: 20, loss: 0.21696454286575317
step: 30, loss: 0.030576210469007492
step: 40, loss: 0.19614078104496002
step: 50, loss: 0.042512763291597366
step: 60, loss: 0.17386668920516968
step: 70, loss: 0.15702193975448608
step: 80, loss: 0.16980606317520142
step: 90, loss: 0.05511058121919632
step: 100, loss: 0.24879497289657593
step: 110, loss: 0.06622243672609329
step: 120, loss: 0.14748652279376984
step: 130, loss: 0.0925925225019455
step: 140, loss: 0.13130082190036774
step: 150, loss: 0.04019588977098465
step: 160, loss: 0.03798089176416397
step: 170, loss: 0.15176132321357727
step: 180, loss: 0.04894670099020004
step: 190, loss: 0.20240360498428345
step: 200, loss: 0.13872160017490387
step: 210, loss: 0.09064160287380219
step: 220, loss: 0.052898794412612915
step: 230, loss: 0.11294829100370407
step: 240, loss: 0.08819352090358734
step: 250, loss: 0.40630093216896057
step: 260, loss: 0.24198956787586212
step: 270, loss: 0.10866998881101608
step: 280, loss: 0.22960755228996277
step: 290, loss: 0.052536122500896454
step: 300, loss: 0.1430392861366272
step: 310, loss: 0.045833222568035126
step: 320, loss: 0.1429535299539566
step: 330, loss: 0.010555049404501915
step: 340, loss: 0.02314266934990883
step: 350, loss: 0.0714321881532669
step: 360, loss: 0.21980085968971252
epoch 2: dev_f1=0.6929133858267716, f1=0.7604166666666666, best_f1=0.7604166666666666
step: 0, loss: 0.16192999482154846
step: 10, loss: 0.11890631169080734
step: 20, loss: 0.053010810166597366
step: 30, loss: 0.009276767261326313
step: 40, loss: 0.07639088481664658
step: 50, loss: 0.0745004191994667
step: 60, loss: 0.11812467873096466
step: 70, loss: 0.04584566876292229
step: 80, loss: 0.24020661413669586
step: 90, loss: 0.03118326887488365
step: 100, loss: 0.08766363561153412
step: 110, loss: 0.15934224426746368
step: 120, loss: 0.01855952851474285
step: 130, loss: 0.0033228397369384766
step: 140, loss: 0.19034452736377716
step: 150, loss: 0.03868801146745682
step: 160, loss: 0.058654457330703735
step: 170, loss: 0.023548651486635208
step: 180, loss: 0.05245664343237877
step: 190, loss: 0.11251398175954819
step: 200, loss: 0.018236838281154633
step: 210, loss: 0.04214850440621376
step: 220, loss: 0.10613711178302765
step: 230, loss: 0.15043728053569794
step: 240, loss: 0.05874387174844742
step: 250, loss: 0.043625373393297195
step: 260, loss: 0.01657877117395401
step: 270, loss: 0.02592994086444378
step: 280, loss: 0.2040405422449112
step: 290, loss: 0.10902948677539825
step: 300, loss: 0.12206588685512543
step: 310, loss: 0.13298651576042175
step: 320, loss: 0.04894161969423294
step: 330, loss: 0.013918483629822731
step: 340, loss: 0.037882398813962936
step: 350, loss: 0.0678463727235794
step: 360, loss: 0.049425236880779266
epoch 3: dev_f1=0.7331536388140162, f1=0.7967479674796748, best_f1=0.7967479674796748
step: 0, loss: 0.0017892996547743678
step: 10, loss: 0.06312627345323563
step: 20, loss: 0.0026691691018640995
step: 30, loss: 0.0006280182278715074
step: 40, loss: 0.06915217638015747
step: 50, loss: 0.04082980006933212
step: 60, loss: 0.23152731359004974
step: 70, loss: 0.07333911955356598
step: 80, loss: 0.12906590104103088
step: 90, loss: 0.08245815336704254
step: 100, loss: 0.1368248015642166
step: 110, loss: 0.04014766961336136
step: 120, loss: 0.04181164875626564
step: 130, loss: 0.051924534142017365
step: 140, loss: 0.05798979103565216
step: 150, loss: 0.10477500408887863
step: 160, loss: 0.09590760618448257
step: 170, loss: 0.028546510264277458
step: 180, loss: 0.13893893361091614
step: 190, loss: 0.0290365032851696
step: 200, loss: 0.1352897584438324
step: 210, loss: 0.20434647798538208
step: 220, loss: 0.11979151517152786
step: 230, loss: 0.0168372243642807
step: 240, loss: 0.040547024458646774
step: 250, loss: 0.023963533341884613
step: 260, loss: 0.016883330419659615
step: 270, loss: 0.059199657291173935
step: 280, loss: 0.0035763466730713844
step: 290, loss: 0.06206269934773445
step: 300, loss: 0.05671711266040802
step: 310, loss: 0.006107212509959936
step: 320, loss: 0.004672709386795759
step: 330, loss: 0.10233621299266815
step: 340, loss: 0.09330396354198456
step: 350, loss: 0.0680161640048027
step: 360, loss: 0.07643835991621017
epoch 4: dev_f1=0.7222222222222223, f1=0.7628865979381442, best_f1=0.7967479674796748
step: 0, loss: 0.09548503905534744
step: 10, loss: 0.08751370012760162
step: 20, loss: 0.09178087115287781
step: 30, loss: 0.0882968083024025
step: 40, loss: 0.06915147602558136
step: 50, loss: 0.044198717921972275
step: 60, loss: 0.08844728022813797
step: 70, loss: 0.014002514071762562
step: 80, loss: 0.06564934551715851
step: 90, loss: 0.15442055463790894
step: 100, loss: 0.027921222150325775
step: 110, loss: 0.008548134006559849
step: 120, loss: 0.05247964337468147
step: 130, loss: 0.022673098370432854
step: 140, loss: 0.05900617316365242
step: 150, loss: 0.04907893389463425
step: 160, loss: 0.048203177750110626
step: 170, loss: 0.06278440356254578
step: 180, loss: 0.15624023973941803
step: 190, loss: 0.07717578113079071
step: 200, loss: 0.135982945561409
step: 210, loss: 0.05102800950407982
step: 220, loss: 0.0859580710530281
step: 230, loss: 0.05929507687687874
step: 240, loss: 0.05337205529212952
step: 250, loss: 0.037405744194984436
step: 260, loss: 0.14018765091896057
step: 270, loss: 0.12448403984308243
step: 280, loss: 0.030363380908966064
step: 290, loss: 0.05224421247839928
step: 300, loss: 0.04569171741604805
step: 310, loss: 0.022366803139448166
step: 320, loss: 0.03683364391326904
step: 330, loss: 0.01624617539346218
step: 340, loss: 0.0005603449535556138
step: 350, loss: 0.024841180071234703
step: 360, loss: 0.027429504320025444
epoch 5: dev_f1=0.7196029776674937, f1=0.7692307692307693, best_f1=0.7967479674796748
step: 0, loss: 0.0407898835837841
step: 10, loss: 0.05643347650766373
step: 20, loss: 0.05802304670214653
step: 30, loss: 0.06519683450460434
step: 40, loss: 0.04363090172410011
step: 50, loss: 0.029017137363553047
step: 60, loss: 0.10047174245119095
step: 70, loss: 0.019307512789964676
step: 80, loss: 0.18613001704216003
step: 90, loss: 0.2135007530450821
step: 100, loss: 0.06497286260128021
step: 110, loss: 0.026129543781280518
step: 120, loss: 0.05883321538567543
step: 130, loss: 0.16516762971878052
step: 140, loss: 0.07515999674797058
step: 150, loss: 0.07919426262378693
step: 160, loss: 0.06540416181087494
step: 170, loss: 0.014268036000430584
step: 180, loss: 0.026081586256623268
step: 190, loss: 0.0744500383734703
step: 200, loss: 0.009425722993910313
step: 210, loss: 0.015535092912614346
step: 220, loss: 0.04142739251255989
step: 230, loss: 0.054774459451436996
step: 240, loss: 0.059618789702653885
step: 250, loss: 0.10795829445123672
step: 260, loss: 0.05080946534872055
step: 270, loss: 0.015649661421775818
step: 280, loss: 0.08623647689819336
step: 290, loss: 0.06042720377445221
step: 300, loss: 0.06885019689798355
step: 310, loss: 0.08725021779537201
step: 320, loss: 0.02388416789472103
step: 330, loss: 0.019748816266655922
step: 340, loss: 0.08205340802669525
step: 350, loss: 0.10381868481636047
step: 360, loss: 0.057763613760471344
epoch 6: dev_f1=0.6886792452830188, f1=0.7107843137254902, best_f1=0.7967479674796748
step: 0, loss: 0.018727652728557587
step: 10, loss: 0.11986071616411209
step: 20, loss: 0.03967864438891411
step: 30, loss: 0.031015632674098015
step: 40, loss: 0.24497227370738983
step: 50, loss: 0.026411432772874832
step: 60, loss: 0.039935532957315445
step: 70, loss: 0.09607753157615662
step: 80, loss: 0.04744328185915947
step: 90, loss: 0.08244821429252625
step: 100, loss: 0.03977416828274727
step: 110, loss: 0.040552135556936264
step: 120, loss: 0.06292101740837097
step: 130, loss: 0.03291913494467735
step: 140, loss: 0.015833286568522453
step: 150, loss: 0.02596355974674225
step: 160, loss: 0.06828365474939346
step: 170, loss: 0.13507236540317535
step: 180, loss: 0.002180191921070218
step: 190, loss: 0.015217882581055164
step: 200, loss: 0.054597366601228714
step: 210, loss: 0.06962648779153824
step: 220, loss: 0.062329839915037155
step: 230, loss: 0.009997139684855938
step: 240, loss: 0.0005814540199935436
step: 250, loss: 0.03967016562819481
step: 260, loss: 0.016635509207844734
step: 270, loss: 0.0736657902598381
step: 280, loss: 0.019457893446087837
step: 290, loss: 0.07605589181184769
step: 300, loss: 0.0670880451798439
step: 310, loss: 0.040744006633758545
step: 320, loss: 0.031514402478933334
step: 330, loss: 0.0022652933839708567
step: 340, loss: 0.028688164427876472
step: 350, loss: 0.0041220602579414845
step: 360, loss: 0.10865617543458939
epoch 7: dev_f1=0.7136363636363636, f1=0.7450980392156864, best_f1=0.7967479674796748
step: 0, loss: 0.032151397317647934
step: 10, loss: 0.003151391865685582
step: 20, loss: 0.13800685107707977
step: 30, loss: 0.016284415498375893
step: 40, loss: 0.01860516332089901
step: 50, loss: 0.08781076222658157
step: 60, loss: 0.07577165216207504
step: 70, loss: 0.051386479288339615
step: 80, loss: 0.04116478189826012
step: 90, loss: 0.028912242501974106
step: 100, loss: 0.00011510079639265314
step: 110, loss: 0.06196204572916031
step: 120, loss: 0.07879160344600677
step: 130, loss: 0.04167254641652107
step: 140, loss: 0.01903611049056053
step: 150, loss: 0.07861096411943436
step: 160, loss: 0.009939093142747879
step: 170, loss: 0.029959773644804955
step: 180, loss: 0.004906808957457542
step: 190, loss: 0.04345814883708954
step: 200, loss: 0.0467977412045002
step: 210, loss: 0.021304650232195854
step: 220, loss: 0.005562483333051205
step: 230, loss: 0.011866516433656216
step: 240, loss: 0.08974093943834305
step: 250, loss: 0.02910502441227436
step: 260, loss: 0.013105843216180801
step: 270, loss: 0.039931025356054306
step: 280, loss: 0.02586136944591999
step: 290, loss: 0.057960912585258484
step: 300, loss: 0.06544000655412674
step: 310, loss: 0.04196305200457573
step: 320, loss: 0.024300288408994675
step: 330, loss: 0.09010942280292511
step: 340, loss: 0.07354187220335007
step: 350, loss: 0.04477452486753464
step: 360, loss: 0.07099588215351105
epoch 8: dev_f1=0.75, f1=0.7870619946091645, best_f1=0.7870619946091645
step: 0, loss: 0.07947764545679092
step: 10, loss: 0.01372604351490736
step: 20, loss: 0.18188928067684174
step: 30, loss: 0.100989930331707
step: 40, loss: 0.04925494268536568
step: 50, loss: 0.018483350053429604
step: 60, loss: 0.03686019778251648
step: 70, loss: 0.008784251287579536
step: 80, loss: 0.04643235728144646
step: 90, loss: 0.007017636671662331
step: 100, loss: 0.04760867357254028
step: 110, loss: 0.17910942435264587
step: 120, loss: 0.01776251569390297
step: 130, loss: 0.06307734549045563
step: 140, loss: 0.05272240191698074
step: 150, loss: 0.03201550990343094
step: 160, loss: 0.03879030793905258
step: 170, loss: 7.932538574095815e-05
step: 180, loss: 0.014193546958267689
step: 190, loss: 0.02445550635457039
step: 200, loss: 0.03317597135901451
step: 210, loss: 0.022447150200605392
step: 220, loss: 0.01698416844010353
step: 230, loss: 0.14675937592983246
step: 240, loss: 0.010371679440140724
step: 250, loss: 0.19561386108398438
step: 260, loss: 0.0792129635810852
step: 270, loss: 0.029395397752523422
step: 280, loss: 0.04869186505675316
step: 290, loss: 0.07124391943216324
step: 300, loss: 0.05663503333926201
step: 310, loss: 0.011976051144301891
step: 320, loss: 0.03400539979338646
step: 330, loss: 0.0019449213286861777
step: 340, loss: 0.028478041291236877
step: 350, loss: 0.084691621363163
step: 360, loss: 9.715148189570755e-05
epoch 9: dev_f1=0.7379679144385027, f1=0.7675070028011204, best_f1=0.7870619946091645
step: 0, loss: 0.09372156113386154
step: 10, loss: 0.0006643786327913404
step: 20, loss: 6.648626003880054e-05
step: 30, loss: 0.05340297892689705
step: 40, loss: 0.06305171549320221
step: 50, loss: 6.494110857602209e-05
step: 60, loss: 0.05012461170554161
step: 70, loss: 0.0647636204957962
step: 80, loss: 0.057054489850997925
step: 90, loss: 0.07977227121591568
step: 100, loss: 0.03886420279741287
step: 110, loss: 0.004416689742356539
step: 120, loss: 0.16876544058322906
step: 130, loss: 0.02753583714365959
step: 140, loss: 0.007323884405195713
step: 150, loss: 0.043342478573322296
step: 160, loss: 0.03506183996796608
step: 170, loss: 0.014330434612929821
step: 180, loss: 0.018104515969753265
step: 190, loss: 0.05504272133111954
step: 200, loss: 0.05801195278763771
step: 210, loss: 0.08358427882194519
step: 220, loss: 0.02938194014132023
step: 230, loss: 0.020641576498746872
step: 240, loss: 0.10349853336811066
step: 250, loss: 0.030025793239474297
step: 260, loss: 0.10660146921873093
step: 270, loss: 0.01796177588403225
step: 280, loss: 0.0645165964961052
step: 290, loss: 0.10259494930505753
step: 300, loss: 0.01676780730485916
step: 310, loss: 0.031518686562776566
step: 320, loss: 0.16220319271087646
step: 330, loss: 0.016840757802128792
step: 340, loss: 0.0009620965574868023
step: 350, loss: 0.011605474166572094
step: 360, loss: 0.02296971157193184
epoch 10: dev_f1=0.7519181585677749, f1=0.7466666666666666, best_f1=0.7466666666666666
step: 0, loss: 0.035228800028562546
step: 10, loss: 0.0001445329253328964
step: 20, loss: 0.01644980162382126
step: 30, loss: 0.054980263113975525
step: 40, loss: 0.039836764335632324
step: 50, loss: 0.0002731224230956286
step: 60, loss: 0.03194655850529671
step: 70, loss: 0.0796165019273758
step: 80, loss: 0.0561206191778183
step: 90, loss: 0.06795922666788101
step: 100, loss: 0.019441703334450722
step: 110, loss: 0.03406977653503418
step: 120, loss: 0.10340775549411774
step: 130, loss: 0.030568480491638184
step: 140, loss: 0.03450163081288338
step: 150, loss: 0.01904413476586342
step: 160, loss: 0.10181277245283127
step: 170, loss: 0.053183071315288544
step: 180, loss: 0.0001784428022801876
step: 190, loss: 0.03017769195139408
step: 200, loss: 0.1429343819618225
step: 210, loss: 0.010868831537663937
step: 220, loss: 0.018630513921380043
step: 230, loss: 0.007432363461703062
step: 240, loss: 0.024623647332191467
step: 250, loss: 0.0065679787658154964
step: 260, loss: 0.05283958092331886
step: 270, loss: 0.022836102172732353
step: 280, loss: 0.016307158395648003
step: 290, loss: 0.04009067639708519
step: 300, loss: 0.0004433297726791352
step: 310, loss: 6.118338933447376e-05
step: 320, loss: 0.1316942423582077
step: 330, loss: 0.21066275238990784
step: 340, loss: 0.05401504412293434
step: 350, loss: 0.041258808225393295
step: 360, loss: 0.013484797440469265
epoch 11: dev_f1=0.7519181585677749, f1=0.7588075880758809, best_f1=0.7466666666666666
step: 0, loss: 0.03538670018315315
step: 10, loss: 0.18172737956047058
step: 20, loss: 0.025159262120723724
step: 30, loss: 0.004019671585410833
step: 40, loss: 0.058809395879507065
step: 50, loss: 0.004218237940222025
step: 60, loss: 0.02461770921945572
step: 70, loss: 0.032801590859889984
step: 80, loss: 0.022651446983218193
step: 90, loss: 0.015443887561559677
step: 100, loss: 0.018753657117486
step: 110, loss: 0.008276764303445816
step: 120, loss: 0.004856858402490616
step: 130, loss: 0.0028342443984001875
step: 140, loss: 0.0001353152620140463
step: 150, loss: 0.030393563210964203
step: 160, loss: 0.03788307309150696
step: 170, loss: 0.012195231392979622
step: 180, loss: 0.007200349122285843
step: 190, loss: 0.00010907240357482806
step: 200, loss: 0.05552171543240547
step: 210, loss: 0.013389174826443195
step: 220, loss: 0.054597899317741394
step: 230, loss: 0.003486380446702242
step: 240, loss: 0.06689473986625671
step: 250, loss: 0.027990475296974182
step: 260, loss: 0.029756074771285057
step: 270, loss: 0.05434479936957359
step: 280, loss: 0.005614584777504206
step: 290, loss: 0.013679439201951027
step: 300, loss: 0.015586847439408302
step: 310, loss: 0.0024513339158147573
step: 320, loss: 0.1077057421207428
step: 330, loss: 0.015434643253684044
step: 340, loss: 0.044859372079372406
step: 350, loss: 0.0008640276500955224
step: 360, loss: 0.0032173851504921913
epoch 12: dev_f1=0.7306791569086649, f1=0.7475247524752476, best_f1=0.7466666666666666
step: 0, loss: 0.0005559175042435527
step: 10, loss: 0.026899144053459167
step: 20, loss: 0.022872673347592354
step: 30, loss: 4.100244041183032e-05
step: 40, loss: 0.001842172583565116
step: 50, loss: 0.1294655203819275
step: 60, loss: 0.011846150271594524
step: 70, loss: 0.0071898638270795345
step: 80, loss: 0.09088273346424103
step: 90, loss: 0.024962909519672394
step: 100, loss: 0.0031939102336764336
step: 110, loss: 0.00020396080799400806
step: 120, loss: 0.03319967910647392
step: 130, loss: 0.08176811039447784
step: 140, loss: 0.08777184784412384
step: 150, loss: 0.0020231902599334717
step: 160, loss: 0.0003704146365635097
step: 170, loss: 0.032460253685712814
step: 180, loss: 0.02932603843510151
step: 190, loss: 0.08954034000635147
step: 200, loss: 0.018065685406327248
step: 210, loss: 0.0058674621395766735
step: 220, loss: 0.030076172202825546
step: 230, loss: 0.024909861385822296
step: 240, loss: 0.0015814868966117501
step: 250, loss: 0.13283032178878784
step: 260, loss: 0.10609152168035507
step: 270, loss: 0.018942121416330338
step: 280, loss: 0.001571870525367558
step: 290, loss: 0.031034620478749275
step: 300, loss: 0.032298315316438675
step: 310, loss: 0.0022373395040631294
step: 320, loss: 0.031164437532424927
step: 330, loss: 0.0001603918062755838
step: 340, loss: 0.021146200597286224
step: 350, loss: 0.03549816459417343
step: 360, loss: 0.0294899120926857
epoch 13: dev_f1=0.7430025445292621, f1=0.7421052631578948, best_f1=0.7466666666666666
step: 0, loss: 0.06031250208616257
step: 10, loss: 0.09378156065940857
step: 20, loss: 0.028366148471832275
step: 30, loss: 0.01840231753885746
step: 40, loss: 0.02894158475100994
step: 50, loss: 0.028847625479102135
step: 60, loss: 0.015112094581127167
step: 70, loss: 0.002092816401273012
step: 80, loss: 0.029470546171069145
step: 90, loss: 0.0001715933613013476
step: 100, loss: 0.014932586811482906
step: 110, loss: 0.024261148646473885
step: 120, loss: 0.012752091512084007
step: 130, loss: 0.04138043522834778
step: 140, loss: 0.025548618286848068
step: 150, loss: 0.05265210196375847
step: 160, loss: 0.02486324869096279
step: 170, loss: 0.00040280725806951523
step: 180, loss: 0.0001508942514192313
step: 190, loss: 0.0007207409362308681
step: 200, loss: 0.011242286302149296
step: 210, loss: 0.16880889236927032
step: 220, loss: 0.048713527619838715
step: 230, loss: 0.0017415162874385715
step: 240, loss: 0.046380896121263504
step: 250, loss: 0.0027601495385169983
step: 260, loss: 0.0009097146685235202
step: 270, loss: 0.0202009454369545
step: 280, loss: 0.000454614229965955
step: 290, loss: 0.025952601805329323
step: 300, loss: 4.022240682388656e-05
step: 310, loss: 0.05024383217096329
step: 320, loss: 0.11083071678876877
step: 330, loss: 0.06429850310087204
step: 340, loss: 0.00010429976100567728
step: 350, loss: 0.0023758828174322844
step: 360, loss: 0.0047671133652329445
epoch 14: dev_f1=0.736318407960199, f1=0.7526315789473683, best_f1=0.7466666666666666
step: 0, loss: 0.05001313239336014
step: 10, loss: 0.0023030799347907305
step: 20, loss: 0.05899261683225632
step: 30, loss: 0.0006034743855707347
step: 40, loss: 0.006911140866577625
step: 50, loss: 0.005125316325575113
step: 60, loss: 0.06962050497531891
step: 70, loss: 0.06052706390619278
step: 80, loss: 0.019949976354837418
step: 90, loss: 0.029961124062538147
step: 100, loss: 0.01991921290755272
step: 110, loss: 0.001350942300632596
step: 120, loss: 0.05212404206395149
step: 130, loss: 0.0022846609354019165
step: 140, loss: 9.846127068158239e-05
step: 150, loss: 0.006143900565803051
step: 160, loss: 0.004209169186651707
step: 170, loss: 0.0007973579922690988
step: 180, loss: 7.250990893226117e-05
step: 190, loss: 0.0029037820640951395
step: 200, loss: 0.011223518289625645
step: 210, loss: 0.0405954048037529
step: 220, loss: 0.00588645925745368
step: 230, loss: 0.005453882738947868
step: 240, loss: 0.04488307982683182
step: 250, loss: 0.012160416692495346
step: 260, loss: 5.4315147281158715e-05
step: 270, loss: 0.03190790116786957
step: 280, loss: 0.03598663955926895
step: 290, loss: 0.0040413495153188705
step: 300, loss: 0.03479046747088432
step: 310, loss: 0.024957600980997086
step: 320, loss: 0.03458490967750549
step: 330, loss: 4.8909882025327533e-05
step: 340, loss: 0.11791137605905533
step: 350, loss: 0.04079452529549599
step: 360, loss: 0.00013777849380858243
epoch 15: dev_f1=0.7247058823529412, f1=0.7461928934010152, best_f1=0.7466666666666666
step: 0, loss: 0.03057084046304226
step: 10, loss: 0.019800037145614624
step: 20, loss: 0.054786566644907
step: 30, loss: 0.004459845833480358
step: 40, loss: 0.04050058126449585
step: 50, loss: 0.010323903523385525
step: 60, loss: 0.03366043418645859
step: 70, loss: 0.0010869785910472274
step: 80, loss: 0.022779427468776703
step: 90, loss: 0.008183490484952927
step: 100, loss: 0.030860424041748047
step: 110, loss: 0.05571598932147026
step: 120, loss: 0.0017679787706583738
step: 130, loss: 0.08273500204086304
step: 140, loss: 0.053449902683496475
step: 150, loss: 0.029198652133345604
step: 160, loss: 0.03662489727139473
step: 170, loss: 0.020583797246217728
step: 180, loss: 0.006774631328880787
step: 190, loss: 0.04732947796583176
step: 200, loss: 1.8562877812655643e-05
step: 210, loss: 0.02641293592751026
step: 220, loss: 0.0004169444437138736
step: 230, loss: 0.03248531371355057
step: 240, loss: 0.0009719936642795801
step: 250, loss: 0.008074081502854824
step: 260, loss: 0.08660246431827545
step: 270, loss: 0.02067675068974495
step: 280, loss: 0.0007046835380606353
step: 290, loss: 0.019127391278743744
step: 300, loss: 0.023443974554538727
step: 310, loss: 0.0008220124873332679
step: 320, loss: 0.030905015766620636
step: 330, loss: 4.288376294425689e-05
step: 340, loss: 0.006585479713976383
step: 350, loss: 0.018755055963993073
step: 360, loss: 0.026317335665225983
epoch 16: dev_f1=0.7336683417085428, f1=0.7413333333333334, best_f1=0.7466666666666666
step: 0, loss: 0.04203606769442558
step: 10, loss: 0.00026049246662296355
step: 20, loss: 3.797995304921642e-05
step: 30, loss: 0.030236894264817238
step: 40, loss: 0.03940730169415474
step: 50, loss: 0.06916546076536179
step: 60, loss: 0.0017824156675487757
step: 70, loss: 0.024038217961788177
step: 80, loss: 0.00016719471022952348
step: 90, loss: 0.023347456008195877
step: 100, loss: 0.03415074571967125
step: 110, loss: 0.032644111663103104
step: 120, loss: 0.007156072184443474
step: 130, loss: 0.007000913377851248
step: 140, loss: 2.4828606910887174e-05
step: 150, loss: 0.002473958535119891
step: 160, loss: 0.031685955822467804
step: 170, loss: 0.0032679515425115824
step: 180, loss: 3.1904797651804984e-05
step: 190, loss: 0.004967419430613518
step: 200, loss: 0.07288617640733719
step: 210, loss: 0.024926818907260895
step: 220, loss: 0.026446595788002014
step: 230, loss: 0.020817209035158157
step: 240, loss: 0.03259258344769478
step: 250, loss: 0.038138896226882935
step: 260, loss: 0.00166160031221807
step: 270, loss: 0.03302198275923729
step: 280, loss: 0.0001984485425055027
step: 290, loss: 0.042523641139268875
step: 300, loss: 0.04191054031252861
step: 310, loss: 0.021533019840717316
step: 320, loss: 0.019384946674108505
step: 330, loss: 0.044250018894672394
step: 340, loss: 0.04617950692772865
step: 350, loss: 5.4649764933856204e-05
step: 360, loss: 0.0017288264352828264
epoch 17: dev_f1=0.7281553398058251, f1=0.744186046511628, best_f1=0.7466666666666666
step: 0, loss: 0.025510014966130257
step: 10, loss: 3.806610038736835e-05
step: 20, loss: 0.0034895921126008034
step: 30, loss: 0.00012365779548417777
step: 40, loss: 0.03121812641620636
step: 50, loss: 0.003386285388842225
step: 60, loss: 7.820382597856224e-05
step: 70, loss: 0.04220152646303177
step: 80, loss: 0.009189669974148273
step: 90, loss: 0.005068912170827389
step: 100, loss: 0.017419347539544106
step: 110, loss: 0.05771925672888756
step: 120, loss: 0.03281324356794357
step: 130, loss: 0.022934112697839737
step: 140, loss: 0.047812335193157196
step: 150, loss: 0.05206475406885147
step: 160, loss: 0.06166701391339302
step: 170, loss: 0.04365247115492821
step: 180, loss: 0.03331636264920235
step: 190, loss: 0.026788748800754547
step: 200, loss: 0.0008327796240337193
step: 210, loss: 0.01199045404791832
step: 220, loss: 0.04793825373053551
step: 230, loss: 3.872640445479192e-05
step: 240, loss: 0.040112461894750595
step: 250, loss: 0.019967300817370415
step: 260, loss: 0.020767226815223694
step: 270, loss: 0.00017323069914709777
step: 280, loss: 0.00042518804548308253
step: 290, loss: 0.061518095433712006
step: 300, loss: 0.031616561114788055
step: 310, loss: 0.06457822769880295
step: 320, loss: 3.576819290174171e-05
step: 330, loss: 0.00034013157710433006
step: 340, loss: 0.04579531028866768
step: 350, loss: 0.05382903665304184
step: 360, loss: 0.0001520354999229312
epoch 18: dev_f1=0.7227722772277227, f1=0.7401574803149608, best_f1=0.7466666666666666
step: 0, loss: 0.018926555290818214
step: 10, loss: 0.009335247799754143
step: 20, loss: 0.011578056961297989
step: 30, loss: 0.0002246914809802547
step: 40, loss: 0.04072920233011246
step: 50, loss: 0.03342810645699501
step: 60, loss: 0.011718005873262882
step: 70, loss: 0.023695608600974083
step: 80, loss: 0.10513339191675186
step: 90, loss: 0.027352511882781982
step: 100, loss: 0.05165679380297661
step: 110, loss: 0.025578351691365242
step: 120, loss: 0.02637656033039093
step: 130, loss: 0.001202535699121654
step: 140, loss: 0.08487845212221146
step: 150, loss: 0.02510528452694416
step: 160, loss: 0.013964246958494186
step: 170, loss: 0.08083684742450714
step: 180, loss: 0.07089797407388687
step: 190, loss: 3.997878229711205e-05
step: 200, loss: 0.00991024635732174
step: 210, loss: 0.00016749874339438975
step: 220, loss: 0.025828596204519272
step: 230, loss: 0.013449505902826786
step: 240, loss: 0.00021572057448793203
step: 250, loss: 0.01460358314216137
step: 260, loss: 0.000290389871224761
step: 270, loss: 0.052404552698135376
step: 280, loss: 7.664470467716455e-05
step: 290, loss: 0.0417366698384285
step: 300, loss: 0.0013075442984700203
step: 310, loss: 0.030830450356006622
step: 320, loss: 0.10732405632734299
step: 330, loss: 0.023923449218273163
step: 340, loss: 0.00027859798865392804
step: 350, loss: 0.040343355387449265
step: 360, loss: 0.03164178878068924
epoch 19: dev_f1=0.7204030226700252, f1=0.7467362924281985, best_f1=0.7466666666666666
step: 0, loss: 0.058981578797101974
step: 10, loss: 0.03667610138654709
step: 20, loss: 5.850961315445602e-05
step: 30, loss: 9.121897164732218e-05
step: 40, loss: 0.014382944442331791
step: 50, loss: 0.024509521201252937
step: 60, loss: 0.03605411946773529
step: 70, loss: 0.03297685086727142
step: 80, loss: 0.0008669142262078822
step: 90, loss: 0.024500997737050056
step: 100, loss: 0.025259986519813538
step: 110, loss: 0.02073931135237217
step: 120, loss: 0.06710834801197052
step: 130, loss: 0.0014380943030118942
step: 140, loss: 0.024866383522748947
step: 150, loss: 0.05344383791089058
step: 160, loss: 1.769117807270959e-05
step: 170, loss: 0.04214528948068619
step: 180, loss: 0.00016921300266403705
step: 190, loss: 0.02622535452246666
step: 200, loss: 0.024934589862823486
step: 210, loss: 0.00032392548746429384
step: 220, loss: 0.057351671159267426
step: 230, loss: 0.022198520600795746
step: 240, loss: 0.00012159311881987378
step: 250, loss: 0.0005399833898991346
step: 260, loss: 0.03371588885784149
step: 270, loss: 0.001718222163617611
step: 280, loss: 0.00039403873961418867
step: 290, loss: 0.05502861365675926
step: 300, loss: 0.0910743996500969
step: 310, loss: 0.00011429697769926861
step: 320, loss: 0.00015599391190335155
step: 330, loss: 0.0001455167803214863
step: 340, loss: 0.028184354305267334
step: 350, loss: 0.0017171386862173676
step: 360, loss: 9.560103353578597e-05
epoch 20: dev_f1=0.7178217821782177, f1=0.7409326424870466, best_f1=0.7466666666666666
