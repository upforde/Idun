cuda
Device: cuda
step: 0, loss: 0.45908358693122864
step: 10, loss: 0.4078560769557953
step: 20, loss: 0.2210990935564041
step: 30, loss: 0.2899388372898102
step: 40, loss: 0.4536430835723877
step: 50, loss: 0.4448070824146271
step: 60, loss: 0.2827107608318329
step: 70, loss: 0.4566623270511627
step: 80, loss: 0.36284419894218445
step: 90, loss: 0.3868189752101898
step: 100, loss: 0.4398927390575409
step: 110, loss: 0.30163851380348206
step: 120, loss: 0.3019677698612213
step: 130, loss: 0.2530210018157959
step: 140, loss: 0.2940081059932709
step: 150, loss: 0.31984394788742065
step: 160, loss: 0.21934233605861664
step: 170, loss: 0.3431815803050995
step: 180, loss: 0.4350733458995819
step: 190, loss: 0.12861551344394684
step: 200, loss: 0.19181467592716217
step: 210, loss: 0.14285725355148315
step: 220, loss: 0.12670095264911652
step: 230, loss: 0.06960779428482056
step: 240, loss: 0.23208829760551453
step: 250, loss: 0.11294227838516235
step: 260, loss: 0.15094417333602905
step: 270, loss: 0.08252997696399689
step: 280, loss: 0.23546934127807617
step: 290, loss: 0.26315048336982727
step: 300, loss: 0.17080026865005493
step: 310, loss: 0.41320887207984924
step: 320, loss: 0.05579233169555664
step: 330, loss: 0.10807979851961136
step: 340, loss: 0.15983636677265167
step: 350, loss: 0.2792562246322632
epoch 1: dev_f1=0.7499999999999999, f1=0.7163561076604555, best_f1=0.7163561076604555
step: 0, loss: 0.12059663981199265
step: 10, loss: 0.16289854049682617
step: 20, loss: 0.14582079648971558
step: 30, loss: 0.15971429646015167
step: 40, loss: 0.09198236465454102
step: 50, loss: 0.18442928791046143
step: 60, loss: 0.11101169139146805
step: 70, loss: 0.21170489490032196
step: 80, loss: 0.12443055212497711
step: 90, loss: 0.09316874295473099
step: 100, loss: 0.12448301911354065
step: 110, loss: 0.16312648355960846
step: 120, loss: 0.14647501707077026
step: 130, loss: 0.036999430507421494
step: 140, loss: 0.1595517098903656
step: 150, loss: 0.13245104253292084
step: 160, loss: 0.12974244356155396
step: 170, loss: 0.09799862653017044
step: 180, loss: 0.09702128171920776
step: 190, loss: 0.12153181433677673
step: 200, loss: 0.1511472761631012
step: 210, loss: 0.12809792160987854
step: 220, loss: 0.17714689671993256
step: 230, loss: 0.18203072249889374
step: 240, loss: 0.17092812061309814
step: 250, loss: 0.04252786934375763
step: 260, loss: 0.11822547018527985
step: 270, loss: 0.15584097802639008
step: 280, loss: 0.0667581856250763
step: 290, loss: 0.22951625287532806
step: 300, loss: 0.1062675341963768
step: 310, loss: 0.07948948442935944
step: 320, loss: 0.15221703052520752
step: 330, loss: 0.1025870218873024
step: 340, loss: 0.07303687930107117
step: 350, loss: 0.31049302220344543
epoch 2: dev_f1=0.7494145199063231, f1=0.7702407002188184, best_f1=0.7163561076604555
step: 0, loss: 0.19684654474258423
step: 10, loss: 0.06425841152667999
step: 20, loss: 0.12444695830345154
step: 30, loss: 0.21243171393871307
step: 40, loss: 0.09451524913311005
step: 50, loss: 0.23690161108970642
step: 60, loss: 0.14405038952827454
step: 70, loss: 0.10373648256063461
step: 80, loss: 0.11867786198854446
step: 90, loss: 0.10660155862569809
step: 100, loss: 0.0761120617389679
step: 110, loss: 0.08711766451597214
step: 120, loss: 0.07236088067293167
step: 130, loss: 0.17756177484989166
step: 140, loss: 0.12000998854637146
step: 150, loss: 0.13399022817611694
step: 160, loss: 0.18777614831924438
step: 170, loss: 0.23648661375045776
step: 180, loss: 0.08341849595308304
step: 190, loss: 0.19848689436912537
step: 200, loss: 0.11427248269319534
step: 210, loss: 0.13682343065738678
step: 220, loss: 0.11519856750965118
step: 230, loss: 0.10378458350896835
step: 240, loss: 0.08643819391727448
step: 250, loss: 0.10180869698524475
step: 260, loss: 0.12952452898025513
step: 270, loss: 0.014990882948040962
step: 280, loss: 0.15831221640110016
step: 290, loss: 0.14876414835453033
step: 300, loss: 0.09050288051366806
step: 310, loss: 0.18876127898693085
step: 320, loss: 0.09546603262424469
step: 330, loss: 0.0320521779358387
step: 340, loss: 0.19838833808898926
step: 350, loss: 0.18319302797317505
epoch 3: dev_f1=0.7937915742793792, f1=0.7665952890792291, best_f1=0.7665952890792291
step: 0, loss: 0.15912984311580658
step: 10, loss: 0.09614982455968857
step: 20, loss: 0.0020401307847350836
step: 30, loss: 0.06251461803913116
step: 40, loss: 0.07323187589645386
step: 50, loss: 0.11706472933292389
step: 60, loss: 0.14543722569942474
step: 70, loss: 0.02213258109986782
step: 80, loss: 0.07546478509902954
step: 90, loss: 0.16566047072410583
step: 100, loss: 0.16306842863559723
step: 110, loss: 0.10682150721549988
step: 120, loss: 0.11877454817295074
step: 130, loss: 0.06617733091115952
step: 140, loss: 0.05039210245013237
step: 150, loss: 0.0720304474234581
step: 160, loss: 0.1137571781873703
step: 170, loss: 0.20084182918071747
step: 180, loss: 0.15936514735221863
step: 190, loss: 0.11548051983118057
step: 200, loss: 0.05442839115858078
step: 210, loss: 0.14146378636360168
step: 220, loss: 0.11829444766044617
step: 230, loss: 0.1715509295463562
step: 240, loss: 0.11121606826782227
step: 250, loss: 0.10041698068380356
step: 260, loss: 0.083249032497406
step: 270, loss: 0.13643023371696472
step: 280, loss: 0.09945473819971085
step: 290, loss: 0.06291580945253372
step: 300, loss: 0.14235255122184753
step: 310, loss: 0.03480452671647072
step: 320, loss: 0.11214011162519455
step: 330, loss: 0.07243682444095612
step: 340, loss: 0.07597242295742035
step: 350, loss: 0.11836255341768265
epoch 4: dev_f1=0.8306264501160093, f1=0.7802690582959642, best_f1=0.7802690582959642
step: 0, loss: 0.1373707503080368
step: 10, loss: 0.12448983639478683
step: 20, loss: 0.015199222601950169
step: 30, loss: 0.05711696296930313
step: 40, loss: 0.1331145465373993
step: 50, loss: 0.10463187098503113
step: 60, loss: 0.044850680977106094
step: 70, loss: 0.11707867681980133
step: 80, loss: 0.062119219452142715
step: 90, loss: 0.058513447642326355
step: 100, loss: 0.09240785241127014
step: 110, loss: 0.05553717166185379
step: 120, loss: 0.07830355316400528
step: 130, loss: 0.052881475538015366
step: 140, loss: 0.07086293399333954
step: 150, loss: 0.18127921223640442
step: 160, loss: 0.12375102937221527
step: 170, loss: 0.09376224875450134
step: 180, loss: 0.12179061770439148
step: 190, loss: 0.09779787808656693
step: 200, loss: 0.028885668143630028
step: 210, loss: 0.11944584548473358
step: 220, loss: 0.08970199525356293
step: 230, loss: 0.11533743143081665
step: 240, loss: 0.10463928431272507
step: 250, loss: 0.13201621174812317
step: 260, loss: 0.25654783844947815
step: 270, loss: 0.09424356371164322
step: 280, loss: 0.19748491048812866
step: 290, loss: 0.13254426419734955
step: 300, loss: 0.1443474441766739
step: 310, loss: 0.07380090653896332
step: 320, loss: 0.12236703187227249
step: 330, loss: 0.14649398624897003
step: 340, loss: 0.11447115242481232
step: 350, loss: 0.04126904159784317
epoch 5: dev_f1=0.8111888111888111, f1=0.8063063063063063, best_f1=0.7802690582959642
step: 0, loss: 0.12690062820911407
step: 10, loss: 0.08036566525697708
step: 20, loss: 0.10736744105815887
step: 30, loss: 0.16535061597824097
step: 40, loss: 0.0915209949016571
step: 50, loss: 0.018363727256655693
step: 60, loss: 0.06510122120380402
step: 70, loss: 0.15376044809818268
step: 80, loss: 0.08087298274040222
step: 90, loss: 0.13832762837409973
step: 100, loss: 0.09228633344173431
step: 110, loss: 0.07869309931993484
step: 120, loss: 0.1140044704079628
step: 130, loss: 0.0739947110414505
step: 140, loss: 0.14779847860336304
step: 150, loss: 0.1448521614074707
step: 160, loss: 0.07741469889879227
step: 170, loss: 0.07665251195430756
step: 180, loss: 0.013154920190572739
step: 190, loss: 0.11686816066503525
step: 200, loss: 0.04605856537818909
step: 210, loss: 0.09569568932056427
step: 220, loss: 0.1012398973107338
step: 230, loss: 0.07281458377838135
step: 240, loss: 0.08677466958761215
step: 250, loss: 0.14980261027812958
step: 260, loss: 0.08102365583181381
step: 270, loss: 0.1712888479232788
step: 280, loss: 0.10557658225297928
step: 290, loss: 0.060287367552518845
step: 300, loss: 0.049074649810791016
step: 310, loss: 0.0888066440820694
step: 320, loss: 0.0618416927754879
step: 330, loss: 0.058762263506650925
step: 340, loss: 0.026976890861988068
step: 350, loss: 0.03363213315606117
epoch 6: dev_f1=0.8380952380952381, f1=0.817155756207675, best_f1=0.817155756207675
step: 0, loss: 0.13062724471092224
step: 10, loss: 0.0931883230805397
step: 20, loss: 0.16738750040531158
step: 30, loss: 0.038563184440135956
step: 40, loss: 0.14878802001476288
step: 50, loss: 0.1532662808895111
step: 60, loss: 0.06855564564466476
step: 70, loss: 0.23519890010356903
step: 80, loss: 0.09339535236358643
step: 90, loss: 0.07618656009435654
step: 100, loss: 0.08988439291715622
step: 110, loss: 0.11641839146614075
step: 120, loss: 0.07099123299121857
step: 130, loss: 0.08133530616760254
step: 140, loss: 0.09889032691717148
step: 150, loss: 0.11061699688434601
step: 160, loss: 0.0414651557803154
step: 170, loss: 0.1265142858028412
step: 180, loss: 0.2461823970079422
step: 190, loss: 0.1031881794333458
step: 200, loss: 0.10103599727153778
step: 210, loss: 0.0696549192070961
step: 220, loss: 0.05445283651351929
step: 230, loss: 0.15596771240234375
step: 240, loss: 0.05492826923727989
step: 250, loss: 0.07676303386688232
step: 260, loss: 0.09939752519130707
step: 270, loss: 0.14174029231071472
step: 280, loss: 0.13882428407669067
step: 290, loss: 0.020282110199332237
step: 300, loss: 0.08852171897888184
step: 310, loss: 0.0453704372048378
step: 320, loss: 0.07602442800998688
step: 330, loss: 0.11184371262788773
step: 340, loss: 0.04293477162718773
step: 350, loss: 0.14901942014694214
epoch 7: dev_f1=0.8230088495575221, f1=0.7695560253699789, best_f1=0.817155756207675
step: 0, loss: 0.06609256565570831
step: 10, loss: 0.12325447052717209
step: 20, loss: 0.127910777926445
step: 30, loss: 0.12585824728012085
step: 40, loss: 0.06242932751774788
step: 50, loss: 0.053846001625061035
step: 60, loss: 0.058365002274513245
step: 70, loss: 0.07421523332595825
step: 80, loss: 0.07899071276187897
step: 90, loss: 0.1408853679895401
step: 100, loss: 0.15668202936649323
step: 110, loss: 0.044449273496866226
step: 120, loss: 0.06334320455789566
step: 130, loss: 0.08347505331039429
step: 140, loss: 0.02003115974366665
step: 150, loss: 0.15859058499336243
step: 160, loss: 0.04656773805618286
step: 170, loss: 0.19955933094024658
step: 180, loss: 0.28296107053756714
step: 190, loss: 0.16687323153018951
step: 200, loss: 0.08487388491630554
step: 210, loss: 0.09070226550102234
step: 220, loss: 0.09953536838293076
step: 230, loss: 0.07248706370592117
step: 240, loss: 0.03233736380934715
step: 250, loss: 0.055840134620666504
step: 260, loss: 0.10430736839771271
step: 270, loss: 0.05936359986662865
step: 280, loss: 0.001589267048984766
step: 290, loss: 0.1219501867890358
step: 300, loss: 0.11503815650939941
step: 310, loss: 0.032273489981889725
step: 320, loss: 0.07366562634706497
step: 330, loss: 0.008045615628361702
step: 340, loss: 0.08577845245599747
step: 350, loss: 0.044792093336582184
epoch 8: dev_f1=0.8254716981132074, f1=0.8314087759815242, best_f1=0.817155756207675
step: 0, loss: 0.11382924020290375
step: 10, loss: 0.07859078794717789
step: 20, loss: 0.056230466812849045
step: 30, loss: 0.05977797135710716
step: 40, loss: 0.030900180339813232
step: 50, loss: 0.034798357635736465
step: 60, loss: 0.07875200361013412
step: 70, loss: 0.07681507617235184
step: 80, loss: 0.03177203610539436
step: 90, loss: 0.14815187454223633
step: 100, loss: 0.10110736638307571
step: 110, loss: 0.05014025792479515
step: 120, loss: 0.1487158238887787
step: 130, loss: 0.08671858161687851
step: 140, loss: 0.0716191902756691
step: 150, loss: 0.13074339926242828
step: 160, loss: 0.17442134022712708
step: 170, loss: 0.07968560606241226
step: 180, loss: 0.055372413247823715
step: 190, loss: 0.07069994509220123
step: 200, loss: 0.06778348982334137
step: 210, loss: 0.019134510308504105
step: 220, loss: 0.08746934682130814
step: 230, loss: 0.08139369636774063
step: 240, loss: 0.06481019407510757
step: 250, loss: 0.05846952274441719
step: 260, loss: 0.05800032615661621
step: 270, loss: 0.051487162709236145
step: 280, loss: 0.04926586151123047
step: 290, loss: 0.09261636435985565
step: 300, loss: 0.020145151764154434
step: 310, loss: 0.13435067236423492
step: 320, loss: 0.03207053989171982
step: 330, loss: 0.03802431747317314
step: 340, loss: 0.05823415145277977
step: 350, loss: 0.15992002189159393
epoch 9: dev_f1=0.8498845265588914, f1=0.8246013667425968, best_f1=0.8246013667425968
step: 0, loss: 0.1004180908203125
step: 10, loss: 0.04576745629310608
step: 20, loss: 0.10498736053705215
step: 30, loss: 0.030971180647611618
step: 40, loss: 0.026573363691568375
step: 50, loss: 0.1351248174905777
step: 60, loss: 0.05134138464927673
step: 70, loss: 0.07817357033491135
step: 80, loss: 0.11526808142662048
step: 90, loss: 0.09254950284957886
step: 100, loss: 0.15506576001644135
step: 110, loss: 0.029037216678261757
step: 120, loss: 0.0827108770608902
step: 130, loss: 0.1760505586862564
step: 140, loss: 0.08447353541851044
step: 150, loss: 0.05539177730679512
step: 160, loss: 0.05921611934900284
step: 170, loss: 0.05840131640434265
step: 180, loss: 0.06776869297027588
step: 190, loss: 0.08863403648138046
step: 200, loss: 0.07352210581302643
step: 210, loss: 0.0952904000878334
step: 220, loss: 0.1131095439195633
step: 230, loss: 0.09624040126800537
step: 240, loss: 0.1225719302892685
step: 250, loss: 0.20763427019119263
step: 260, loss: 0.05523199215531349
step: 270, loss: 0.06489773839712143
step: 280, loss: 0.0004319560539443046
step: 290, loss: 0.051403339952230453
step: 300, loss: 0.03779216855764389
step: 310, loss: 0.1605646312236786
step: 320, loss: 0.028445418924093246
step: 330, loss: 0.13922852277755737
step: 340, loss: 0.07963975518941879
step: 350, loss: 0.08213907480239868
epoch 10: dev_f1=0.8364485981308412, f1=0.7963386727688786, best_f1=0.8246013667425968
step: 0, loss: 0.07948437333106995
step: 10, loss: 0.026286423206329346
step: 20, loss: 0.02092018350958824
step: 30, loss: 0.09227894246578217
step: 40, loss: 0.0821266621351242
step: 50, loss: 0.13353383541107178
step: 60, loss: 0.04432714357972145
step: 70, loss: 0.03315126895904541
step: 80, loss: 5.3123316320125014e-05
step: 90, loss: 0.04910661652684212
step: 100, loss: 0.23896127939224243
step: 110, loss: 0.09303652495145798
step: 120, loss: 0.06651857495307922
step: 130, loss: 0.042919956147670746
step: 140, loss: 0.07838810980319977
step: 150, loss: 0.00048350513679906726
step: 160, loss: 0.00037799531128257513
step: 170, loss: 0.15813970565795898
step: 180, loss: 0.06976892799139023
step: 190, loss: 0.1038169115781784
step: 200, loss: 0.1544496864080429
step: 210, loss: 0.032460760325193405
step: 220, loss: 0.09059961885213852
step: 230, loss: 0.08305321633815765
step: 240, loss: 0.06856288760900497
step: 250, loss: 0.0673726350069046
step: 260, loss: 0.13349606096744537
step: 270, loss: 0.0819823369383812
step: 280, loss: 0.11809705942869186
step: 290, loss: 0.0799081027507782
step: 300, loss: 0.08230674266815186
step: 310, loss: 0.14923076331615448
step: 320, loss: 0.0426737479865551
step: 330, loss: 0.1217576265335083
step: 340, loss: 0.08662277460098267
step: 350, loss: 0.09674922376871109
epoch 11: dev_f1=0.851258581235698, f1=0.8172043010752689, best_f1=0.8172043010752689
step: 0, loss: 0.0014941877452656627
step: 10, loss: 0.12692216038703918
step: 20, loss: 0.014970006421208382
step: 30, loss: 0.06111466512084007
step: 40, loss: 0.09044556319713593
step: 50, loss: 0.039058852940797806
step: 60, loss: 0.16190554201602936
step: 70, loss: 0.06776415556669235
step: 80, loss: 0.11937666684389114
step: 90, loss: 0.0440833754837513
step: 100, loss: 0.07671831548213959
step: 110, loss: 0.09079717099666595
step: 120, loss: 0.07274030148983002
step: 130, loss: 0.019165532663464546
step: 140, loss: 0.030115660279989243
step: 150, loss: 0.1104554682970047
step: 160, loss: 0.1332717388868332
step: 170, loss: 0.06234392151236534
step: 180, loss: 0.053715985268354416
step: 190, loss: 0.08636286854743958
step: 200, loss: 0.09279733896255493
step: 210, loss: 0.049160927534103394
step: 220, loss: 0.09774544090032578
step: 230, loss: 0.10176122933626175
step: 240, loss: 0.035493481904268265
step: 250, loss: 0.06359859555959702
step: 260, loss: 0.05084292218089104
step: 270, loss: 0.03239360824227333
step: 280, loss: 0.024920834228396416
step: 290, loss: 0.07238004356622696
step: 300, loss: 0.04535674676299095
step: 310, loss: 0.02217939682304859
step: 320, loss: 0.06701697409152985
step: 330, loss: 0.10373317450284958
step: 340, loss: 0.022046538069844246
step: 350, loss: 0.06742657721042633
epoch 12: dev_f1=0.8452655889145497, f1=0.7876106194690266, best_f1=0.8172043010752689
step: 0, loss: 0.05267075076699257
step: 10, loss: 0.055174570530653
step: 20, loss: 0.041221778839826584
step: 30, loss: 0.09102731198072433
step: 40, loss: 0.06429202109575272
step: 50, loss: 0.02558530680835247
step: 60, loss: 0.17381350696086884
step: 70, loss: 0.030739136040210724
step: 80, loss: 0.04999370127916336
step: 90, loss: 0.07404680550098419
step: 100, loss: 0.057766471058130264
step: 110, loss: 0.1826368123292923
step: 120, loss: 0.06170349940657616
step: 130, loss: 0.05081441253423691
step: 140, loss: 0.1649860143661499
step: 150, loss: 0.07489632070064545
step: 160, loss: 0.15925270318984985
step: 170, loss: 0.047735393047332764
step: 180, loss: 0.016322514042258263
step: 190, loss: 0.09532719850540161
step: 200, loss: 0.04194704070687294
step: 210, loss: 0.10169055312871933
step: 220, loss: 0.035170234739780426
step: 230, loss: 0.10689111053943634
step: 240, loss: 0.06388925015926361
step: 250, loss: 0.02107413299381733
step: 260, loss: 0.047818128019571304
step: 270, loss: 0.06083035469055176
step: 280, loss: 0.12713275849819183
step: 290, loss: 0.062464743852615356
step: 300, loss: 0.0755314975976944
step: 310, loss: 0.02301487885415554
step: 320, loss: 0.09587991237640381
step: 330, loss: 0.031120803207159042
step: 340, loss: 0.00040885451016947627
step: 350, loss: 0.08014753460884094
epoch 13: dev_f1=0.830188679245283, f1=0.7946428571428571, best_f1=0.8172043010752689
step: 0, loss: 0.11845949292182922
step: 10, loss: 0.010356828570365906
step: 20, loss: 0.03910953924059868
step: 30, loss: 0.07374352961778641
step: 40, loss: 0.0006098256562836468
step: 50, loss: 0.11374310404062271
step: 60, loss: 0.007155156694352627
step: 70, loss: 0.11145690828561783
step: 80, loss: 0.12126712501049042
step: 90, loss: 0.09414752572774887
step: 100, loss: 0.058185890316963196
step: 110, loss: 0.05849400907754898
step: 120, loss: 0.062427449971437454
step: 130, loss: 0.06661097705364227
step: 140, loss: 0.042382702231407166
step: 150, loss: 0.1259116232395172
step: 160, loss: 0.0939590334892273
step: 170, loss: 0.04491427168250084
step: 180, loss: 0.029900483787059784
step: 190, loss: 0.03990807756781578
step: 200, loss: 0.06677978485822678
step: 210, loss: 0.012864024378359318
step: 220, loss: 0.006550750695168972
step: 230, loss: 0.03784457594156265
step: 240, loss: 0.038762081414461136
step: 250, loss: 0.02964712120592594
step: 260, loss: 0.016938982531428337
step: 270, loss: 0.07903973013162613
step: 280, loss: 0.04843097925186157
step: 290, loss: 0.06735933572053909
step: 300, loss: 0.027076423168182373
step: 310, loss: 0.04855715483427048
step: 320, loss: 0.0732412114739418
step: 330, loss: 0.1338946372270584
step: 340, loss: 0.06502300500869751
step: 350, loss: 0.0542386919260025
epoch 14: dev_f1=0.8459770114942529, f1=0.7921225382932167, best_f1=0.8172043010752689
step: 0, loss: 0.023562388494610786
step: 10, loss: 0.017392124980688095
step: 20, loss: 0.06214434280991554
step: 30, loss: 0.021424047648906708
step: 40, loss: 0.07417194545269012
step: 50, loss: 0.08618653565645218
step: 60, loss: 0.055385902523994446
step: 70, loss: 0.01252004411071539
step: 80, loss: 0.023057112470269203
step: 90, loss: 0.06678170710802078
step: 100, loss: 0.022629965096712112
step: 110, loss: 0.0675499439239502
step: 120, loss: 0.06333182007074356
step: 130, loss: 0.06646401435136795
step: 140, loss: 0.024091560393571854
step: 150, loss: 0.09231210500001907
step: 160, loss: 0.028963938355445862
step: 170, loss: 0.047911662608385086
step: 180, loss: 0.05498427525162697
step: 190, loss: 0.06140854209661484
step: 200, loss: 0.08372576534748077
step: 210, loss: 0.0077797831036150455
step: 220, loss: 0.04415108636021614
step: 230, loss: 0.09992899000644684
step: 240, loss: 0.13408154249191284
step: 250, loss: 0.1015964075922966
step: 260, loss: 0.10833039879798889
step: 270, loss: 0.09550333023071289
step: 280, loss: 0.057549744844436646
step: 290, loss: 0.06796962767839432
step: 300, loss: 0.03293437510728836
step: 310, loss: 0.08256252110004425
step: 320, loss: 0.12512752413749695
step: 330, loss: 0.05668306350708008
step: 340, loss: 0.02071581780910492
step: 350, loss: 0.018220018595457077
epoch 15: dev_f1=0.8450704225352113, f1=0.7973273942093541, best_f1=0.8172043010752689
step: 0, loss: 0.022616583853960037
step: 10, loss: 0.04261709004640579
step: 20, loss: 0.12387685477733612
step: 30, loss: 0.07833114266395569
step: 40, loss: 2.8542424843180925e-05
step: 50, loss: 0.10216835141181946
step: 60, loss: 0.10158232599496841
step: 70, loss: 0.05391988530755043
step: 80, loss: 0.05817962810397148
step: 90, loss: 4.452524444786832e-05
step: 100, loss: 0.017187952995300293
step: 110, loss: 0.03974984213709831
step: 120, loss: 0.06730116158723831
step: 130, loss: 0.044063568115234375
step: 140, loss: 0.0994001105427742
step: 150, loss: 0.09628304839134216
step: 160, loss: 0.05607014149427414
step: 170, loss: 0.0244425218552351
step: 180, loss: 0.038050636649131775
step: 190, loss: 0.042518239468336105
step: 200, loss: 0.11601819097995758
step: 210, loss: 0.00021197590103838593
step: 220, loss: 9.155395673587918e-05
step: 230, loss: 0.14680959284305573
step: 240, loss: 0.0388522744178772
step: 250, loss: 0.060343578457832336
step: 260, loss: 0.052510663866996765
step: 270, loss: 0.14963264763355255
step: 280, loss: 0.06300078332424164
step: 290, loss: 0.15512226521968842
step: 300, loss: 0.0710425078868866
step: 310, loss: 0.1111627146601677
step: 320, loss: 0.06482298672199249
step: 330, loss: 0.13206176459789276
step: 340, loss: 0.060233939439058304
step: 350, loss: 0.07835587859153748
epoch 16: dev_f1=0.850467289719626, f1=0.8080357142857143, best_f1=0.8172043010752689
step: 0, loss: 0.04955735057592392
step: 10, loss: 0.08852461725473404
step: 20, loss: 0.06766031682491302
step: 30, loss: 0.10093079507350922
step: 40, loss: 0.06996576488018036
step: 50, loss: 0.09005352109670639
step: 60, loss: 0.03373284637928009
step: 70, loss: 0.06237773969769478
step: 80, loss: 0.08434940874576569
step: 90, loss: 0.006610484793782234
step: 100, loss: 0.043075334280729294
step: 110, loss: 0.1048508957028389
step: 120, loss: 0.050145771354436874
step: 130, loss: 0.1418686807155609
step: 140, loss: 0.10583768039941788
step: 150, loss: 0.09029701352119446
step: 160, loss: 0.1190386712551117
step: 170, loss: 0.12140657007694244
step: 180, loss: 0.08802768588066101
step: 190, loss: 0.03311687335371971
step: 200, loss: 0.06720111519098282
step: 210, loss: 0.03800176456570625
step: 220, loss: 0.022713666781783104
step: 230, loss: 0.1488022804260254
step: 240, loss: 0.09173113852739334
step: 250, loss: 0.005185540299862623
step: 260, loss: 0.07432030886411667
step: 270, loss: 0.03688092529773712
step: 280, loss: 0.05941947177052498
step: 290, loss: 0.11705438792705536
step: 300, loss: 0.05674836039543152
step: 310, loss: 0.03270629793405533
step: 320, loss: 0.03084154613316059
step: 330, loss: 0.010147906839847565
step: 340, loss: 0.04015888273715973
step: 350, loss: 0.01922404021024704
epoch 17: dev_f1=0.8393285371702638, f1=0.8009153318077803, best_f1=0.8172043010752689
step: 0, loss: 0.0971481055021286
step: 10, loss: 0.13425566256046295
step: 20, loss: 0.015005527064204216
step: 30, loss: 0.12446678429841995
step: 40, loss: 0.041164200752973557
step: 50, loss: 0.10570214688777924
step: 60, loss: 0.09753807634115219
step: 70, loss: 0.07908732444047928
step: 80, loss: 0.014009025879204273
step: 90, loss: 0.06403785943984985
step: 100, loss: 0.13323114812374115
step: 110, loss: 0.039462629705667496
step: 120, loss: 0.01441989652812481
step: 130, loss: 0.06937462836503983
step: 140, loss: 0.030734442174434662
step: 150, loss: 0.040761835873126984
step: 160, loss: 0.000547373725567013
step: 170, loss: 0.04825276508927345
step: 180, loss: 0.08116443455219269
step: 190, loss: 0.10262319445610046
step: 200, loss: 0.1254931092262268
step: 210, loss: 0.052710916846990585
step: 220, loss: 0.13230986893177032
step: 230, loss: 0.027612727135419846
step: 240, loss: 0.041267409920692444
step: 250, loss: 0.02328312210738659
step: 260, loss: 0.056639134883880615
step: 270, loss: 0.06777035444974899
step: 280, loss: 0.05112097039818764
step: 290, loss: 0.01880815252661705
step: 300, loss: 0.012429781258106232
step: 310, loss: 0.018893886357545853
step: 320, loss: 0.00867178663611412
step: 330, loss: 0.05170333757996559
step: 340, loss: 0.036903299391269684
step: 350, loss: 0.042918860912323
epoch 18: dev_f1=0.821256038647343, f1=0.7926267281105991, best_f1=0.8172043010752689
step: 0, loss: 0.08879248052835464
step: 10, loss: 0.05354142189025879
step: 20, loss: 0.10212069004774094
step: 30, loss: 0.034496355801820755
step: 40, loss: 0.05063765496015549
step: 50, loss: 0.037295080721378326
step: 60, loss: 0.0541972741484642
step: 70, loss: 0.07951675355434418
step: 80, loss: 0.07596477121114731
step: 90, loss: 0.013671095483005047
step: 100, loss: 0.03800920397043228
step: 110, loss: 0.019816674292087555
step: 120, loss: 0.024523647502064705
step: 130, loss: 0.05529468506574631
step: 140, loss: 0.04081275314092636
step: 150, loss: 0.021974969655275345
step: 160, loss: 0.0736466720700264
step: 170, loss: 0.06628991663455963
step: 180, loss: 0.06128952279686928
step: 190, loss: 0.053418200463056564
step: 200, loss: 0.13439017534255981
step: 210, loss: 0.1517881602048874
step: 220, loss: 0.04404202476143837
step: 230, loss: 0.02256026677787304
step: 240, loss: 0.012539002113044262
step: 250, loss: 0.014719774946570396
step: 260, loss: 0.08668456971645355
step: 270, loss: 0.10559029877185822
step: 280, loss: 0.09035155922174454
step: 290, loss: 0.000246991723543033
step: 300, loss: 0.045872464776039124
step: 310, loss: 0.02408675104379654
step: 320, loss: 0.06007535755634308
step: 330, loss: 0.11061052232980728
step: 340, loss: 0.1125226840376854
step: 350, loss: 0.08701600879430771
epoch 19: dev_f1=0.8040712468193385, f1=0.7630922693266833, best_f1=0.8172043010752689
step: 0, loss: 0.0897594764828682
step: 10, loss: 0.043017804622650146
step: 20, loss: 0.05390210822224617
step: 30, loss: 0.020861133933067322
step: 40, loss: 0.06241714581847191
step: 50, loss: 0.018429908901453018
step: 60, loss: 0.021462008357048035
step: 70, loss: 0.0224763136357069
step: 80, loss: 0.017596160992980003
step: 90, loss: 0.08280249685049057
step: 100, loss: 0.06461875140666962
step: 110, loss: 0.11502232402563095
step: 120, loss: 0.04351174831390381
step: 130, loss: 0.026971913874149323
step: 140, loss: 0.022914230823516846
step: 150, loss: 0.04991864785552025
step: 160, loss: 0.05344383046030998
step: 170, loss: 0.046125784516334534
step: 180, loss: 0.01688505709171295
step: 190, loss: 0.039279479533433914
step: 200, loss: 0.0728762149810791
step: 210, loss: 0.09129493683576584
step: 220, loss: 0.08588053286075592
step: 230, loss: 0.03921894356608391
step: 240, loss: 0.043202128261327744
step: 250, loss: 0.07480017095804214
step: 260, loss: 0.15493056178092957
step: 270, loss: 0.031874507665634155
step: 280, loss: 0.0690670758485794
step: 290, loss: 0.022058025002479553
step: 300, loss: 0.10956882685422897
step: 310, loss: 0.034263890236616135
step: 320, loss: 0.028182687237858772
step: 330, loss: 0.03182102367281914
step: 340, loss: 0.06402215361595154
step: 350, loss: 0.005500052124261856
epoch 20: dev_f1=0.8079800498753117, f1=0.7777777777777778, best_f1=0.8172043010752689
