cuda
Device: cuda
step: 0, loss: 0.5758970379829407
step: 10, loss: 0.29136961698532104
step: 20, loss: 0.549018919467926
step: 30, loss: 0.38437628746032715
step: 40, loss: 0.4514372944831848
step: 50, loss: 0.16491547226905823
step: 60, loss: 0.3979267477989197
step: 70, loss: 0.2492544949054718
step: 80, loss: 1.03007173538208
step: 90, loss: 0.3530399799346924
step: 100, loss: 0.16180886328220367
step: 110, loss: 0.14695078134536743
step: 120, loss: 0.2778609097003937
step: 130, loss: 0.28811100125312805
step: 140, loss: 0.29551535844802856
step: 150, loss: 0.26992467045783997
step: 160, loss: 0.4605601727962494
step: 170, loss: 0.2911771237850189
step: 180, loss: 0.13613957166671753
step: 190, loss: 0.2854818105697632
step: 200, loss: 0.2593011260032654
step: 210, loss: 0.24802632629871368
step: 220, loss: 0.323317289352417
step: 230, loss: 0.19259434938430786
step: 240, loss: 0.32239001989364624
step: 250, loss: 0.24775199592113495
step: 260, loss: 0.09771368652582169
step: 270, loss: 0.37390515208244324
step: 280, loss: 0.2439674437046051
step: 290, loss: 0.27683666348457336
step: 300, loss: 0.063481904566288
step: 310, loss: 0.17051725089550018
step: 320, loss: 0.2405901849269867
step: 330, loss: 0.19462336599826813
step: 340, loss: 0.2076379656791687
step: 350, loss: 0.149050772190094
epoch 1: dev_f1=0.7240618101545254, f1=0.7272727272727274, best_f1=0.7272727272727274
step: 0, loss: 0.15297242999076843
step: 10, loss: 0.1119680255651474
step: 20, loss: 0.1442844420671463
step: 30, loss: 0.115876205265522
step: 40, loss: 0.058921411633491516
step: 50, loss: 0.21786215901374817
step: 60, loss: 0.12337921559810638
step: 70, loss: 0.14988142251968384
step: 80, loss: 0.15161587297916412
step: 90, loss: 0.06953147053718567
step: 100, loss: 0.2375529706478119
step: 110, loss: 0.18490368127822876
step: 120, loss: 0.168309286236763
step: 130, loss: 0.29569295048713684
step: 140, loss: 0.1150466799736023
step: 150, loss: 0.09860466420650482
step: 160, loss: 0.17812976241111755
step: 170, loss: 0.29255861043930054
step: 180, loss: 0.11566036194562912
step: 190, loss: 0.15229499340057373
step: 200, loss: 0.12452320754528046
step: 210, loss: 0.2862589359283447
step: 220, loss: 0.15678253769874573
step: 230, loss: 0.20047509670257568
step: 240, loss: 0.19972433149814606
step: 250, loss: 0.2094702124595642
step: 260, loss: 0.20220738649368286
step: 270, loss: 0.2475486844778061
step: 280, loss: 0.17822720110416412
step: 290, loss: 0.14854998886585236
step: 300, loss: 0.08232986181974411
step: 310, loss: 0.12972380220890045
step: 320, loss: 0.3800201416015625
step: 330, loss: 0.40416964888572693
step: 340, loss: 0.12921682000160217
step: 350, loss: 0.04622228816151619
epoch 2: dev_f1=0.8098434004474273, f1=0.7573221757322176, best_f1=0.7573221757322176
step: 0, loss: 0.1712866872549057
step: 10, loss: 0.16905459761619568
step: 20, loss: 0.09322495758533478
step: 30, loss: 0.08225759863853455
step: 40, loss: 0.20003986358642578
step: 50, loss: 0.12472983449697495
step: 60, loss: 0.011185926385223866
step: 70, loss: 0.07627636194229126
step: 80, loss: 0.1691441535949707
step: 90, loss: 0.33750662207603455
step: 100, loss: 0.09466240555047989
step: 110, loss: 0.0812814012169838
step: 120, loss: 0.16695302724838257
step: 130, loss: 0.02843247540295124
step: 140, loss: 0.09409390389919281
step: 150, loss: 0.17454025149345398
step: 160, loss: 0.05808185786008835
step: 170, loss: 0.03051694855093956
step: 180, loss: 0.1662309169769287
step: 190, loss: 0.031109344214200974
step: 200, loss: 0.21363146603107452
step: 210, loss: 0.06101219356060028
step: 220, loss: 0.06855121999979019
step: 230, loss: 0.08276813477277756
step: 240, loss: 0.17510008811950684
step: 250, loss: 0.05051770806312561
step: 260, loss: 0.17278696596622467
step: 270, loss: 0.07301890850067139
step: 280, loss: 0.10358155518770218
step: 290, loss: 0.06119771674275398
step: 300, loss: 0.16274815797805786
step: 310, loss: 0.06588874757289886
step: 320, loss: 0.15366072952747345
step: 330, loss: 0.1165580004453659
step: 340, loss: 0.17323718965053558
step: 350, loss: 0.1250193566083908
epoch 3: dev_f1=0.7773109243697479, f1=0.7316103379721671, best_f1=0.7573221757322176
step: 0, loss: 0.04743902385234833
step: 10, loss: 0.10515748709440231
step: 20, loss: 0.08659908920526505
step: 30, loss: 0.03727756068110466
step: 40, loss: 0.13868151605129242
step: 50, loss: 0.1326909065246582
step: 60, loss: 0.1413014829158783
step: 70, loss: 0.06045008450746536
step: 80, loss: 0.19786034524440765
step: 90, loss: 0.12440010905265808
step: 100, loss: 0.07654136419296265
step: 110, loss: 0.03821833059191704
step: 120, loss: 0.09361816942691803
step: 130, loss: 0.06484806537628174
step: 140, loss: 0.061409492045640945
step: 150, loss: 0.16982048749923706
step: 160, loss: 0.13861891627311707
step: 170, loss: 0.10019422322511673
step: 180, loss: 0.15817366540431976
step: 190, loss: 0.18815642595291138
step: 200, loss: 0.08225036412477493
step: 210, loss: 0.10058098286390305
step: 220, loss: 0.06503217667341232
step: 230, loss: 0.15766280889511108
step: 240, loss: 0.06069022789597511
step: 250, loss: 0.17269495129585266
step: 260, loss: 0.07205448299646378
step: 270, loss: 0.09506748616695404
step: 280, loss: 0.0849435105919838
step: 290, loss: 0.12956832349300385
step: 300, loss: 0.15098433196544647
step: 310, loss: 0.16870953142642975
step: 320, loss: 0.06125624105334282
step: 330, loss: 0.07068037241697311
step: 340, loss: 0.07611218094825745
step: 350, loss: 0.08687515556812286
epoch 4: dev_f1=0.8142857142857144, f1=0.8037383177570093, best_f1=0.8037383177570093
step: 0, loss: 0.11328131705522537
step: 10, loss: 0.06662842631340027
step: 20, loss: 0.08871030807495117
step: 30, loss: 0.08902406692504883
step: 40, loss: 0.06687258183956146
step: 50, loss: 0.053520333021879196
step: 60, loss: 0.12018347531557083
step: 70, loss: 0.08271997421979904
step: 80, loss: 0.12478838115930557
step: 90, loss: 0.07018475234508514
step: 100, loss: 0.04958140105009079
step: 110, loss: 0.046725086867809296
step: 120, loss: 0.015500710345804691
step: 130, loss: 0.21228154003620148
step: 140, loss: 0.09326381981372833
step: 150, loss: 0.050351884216070175
step: 160, loss: 0.14498458802700043
step: 170, loss: 0.07662739604711533
step: 180, loss: 0.04554842785000801
step: 190, loss: 0.04017683491110802
step: 200, loss: 0.10610797256231308
step: 210, loss: 0.054794080555438995
step: 220, loss: 0.061765678226947784
step: 230, loss: 0.07880034297704697
step: 240, loss: 0.15681879222393036
step: 250, loss: 0.0951499342918396
step: 260, loss: 0.10442543774843216
step: 270, loss: 0.03971908241510391
step: 280, loss: 0.0978243425488472
step: 290, loss: 0.15600964426994324
step: 300, loss: 0.1288689374923706
step: 310, loss: 0.19613301753997803
step: 320, loss: 0.042265769094228745
step: 330, loss: 0.07266347110271454
step: 340, loss: 0.1518300175666809
step: 350, loss: 0.22632832825183868
epoch 5: dev_f1=0.8142857142857144, f1=0.7888631090487238, best_f1=0.8037383177570093
step: 0, loss: 0.0744745209813118
step: 10, loss: 0.2267143726348877
step: 20, loss: 0.04177238419651985
step: 30, loss: 0.1321115642786026
step: 40, loss: 0.043149325996637344
step: 50, loss: 0.02330091781914234
step: 60, loss: 0.06278874725103378
step: 70, loss: 0.025127490982413292
step: 80, loss: 0.15495382249355316
step: 90, loss: 0.05456016957759857
step: 100, loss: 0.06516855955123901
step: 110, loss: 0.0874345675110817
step: 120, loss: 0.13885226845741272
step: 130, loss: 0.04163575544953346
step: 140, loss: 0.15747785568237305
step: 150, loss: 0.25747543573379517
step: 160, loss: 0.11460438370704651
step: 170, loss: 0.17757093906402588
step: 180, loss: 0.025023335590958595
step: 190, loss: 0.03573818877339363
step: 200, loss: 0.1283969134092331
step: 210, loss: 0.06520794332027435
step: 220, loss: 0.11436777561903
step: 230, loss: 0.13281047344207764
step: 240, loss: 0.07228805869817734
step: 250, loss: 0.06201422959566116
step: 260, loss: 0.16049052774906158
step: 270, loss: 9.46062064031139e-05
step: 280, loss: 0.11169000715017319
step: 290, loss: 0.06706695258617401
step: 300, loss: 0.08087418228387833
step: 310, loss: 0.09616486728191376
step: 320, loss: 0.08791568130254745
step: 330, loss: 0.008915971964597702
step: 340, loss: 0.1468854546546936
step: 350, loss: 0.032212093472480774
epoch 6: dev_f1=0.8046511627906976, f1=0.8018018018018017, best_f1=0.8037383177570093
step: 0, loss: 0.14485692977905273
step: 10, loss: 0.12275002896785736
step: 20, loss: 0.10503952205181122
step: 30, loss: 0.1948826014995575
step: 40, loss: 0.07093944400548935
step: 50, loss: 0.0785788744688034
step: 60, loss: 0.04779667779803276
step: 70, loss: 0.06540443003177643
step: 80, loss: 0.09564800560474396
step: 90, loss: 0.094712994992733
step: 100, loss: 0.10535942018032074
step: 110, loss: 0.1827971339225769
step: 120, loss: 0.1267746239900589
step: 130, loss: 0.02594972588121891
step: 140, loss: 0.00012879206042271107
step: 150, loss: 0.12035252898931503
step: 160, loss: 0.14838144183158875
step: 170, loss: 0.12491574883460999
step: 180, loss: 0.17041507363319397
step: 190, loss: 0.18851594626903534
step: 200, loss: 0.08014051616191864
step: 210, loss: 0.058489687740802765
step: 220, loss: 0.16857898235321045
step: 230, loss: 0.1143033504486084
step: 240, loss: 0.0437297560274601
step: 250, loss: 0.05629304051399231
step: 260, loss: 0.07680270075798035
step: 270, loss: 0.16312232613563538
step: 280, loss: 0.07636968046426773
step: 290, loss: 0.07782864570617676
step: 300, loss: 0.07723185420036316
step: 310, loss: 0.18986104428768158
step: 320, loss: 0.10824453830718994
step: 330, loss: 0.03293544054031372
step: 340, loss: 0.028509117662906647
step: 350, loss: 0.0913543701171875
epoch 7: dev_f1=0.8291571753986333, f1=0.7939262472885034, best_f1=0.7939262472885034
step: 0, loss: 0.04425056278705597
step: 10, loss: 0.0295865461230278
step: 20, loss: 0.05219925194978714
step: 30, loss: 0.04705716669559479
step: 40, loss: 0.038010578602552414
step: 50, loss: 0.07326330244541168
step: 60, loss: 0.0680525079369545
step: 70, loss: 0.06552863121032715
step: 80, loss: 0.035775117576122284
step: 90, loss: 0.029834521934390068
step: 100, loss: 0.03144546225667
step: 110, loss: 0.07689075171947479
step: 120, loss: 0.08094502240419388
step: 130, loss: 0.07703471183776855
step: 140, loss: 0.05386173352599144
step: 150, loss: 0.09789054840803146
step: 160, loss: 0.15357397496700287
step: 170, loss: 0.07730303704738617
step: 180, loss: 0.07781469821929932
step: 190, loss: 0.07390660047531128
step: 200, loss: 0.08102758228778839
step: 210, loss: 0.09608850628137589
step: 220, loss: 0.0564923994243145
step: 230, loss: 0.048281386494636536
step: 240, loss: 0.11188666522502899
step: 250, loss: 0.019375044852495193
step: 260, loss: 0.09582629054784775
step: 270, loss: 0.0906880795955658
step: 280, loss: 0.027796262875199318
step: 290, loss: 0.04427685961127281
step: 300, loss: 0.02747667208313942
step: 310, loss: 0.16947409510612488
step: 320, loss: 0.06151069328188896
step: 330, loss: 0.11241664737462997
step: 340, loss: 0.0808299332857132
step: 350, loss: 0.0647866502404213
epoch 8: dev_f1=0.8066037735849056, f1=0.7682119205298014, best_f1=0.7939262472885034
step: 0, loss: 0.06899011135101318
step: 10, loss: 0.029210573062300682
step: 20, loss: 0.07871471345424652
step: 30, loss: 0.05122046172618866
step: 40, loss: 0.09543304890394211
step: 50, loss: 0.27633053064346313
step: 60, loss: 0.0743311420083046
step: 70, loss: 0.04723246395587921
step: 80, loss: 0.06613936275243759
step: 90, loss: 0.002914601471275091
step: 100, loss: 0.07304952293634415
step: 110, loss: 0.08782599121332169
step: 120, loss: 0.04202816262841225
step: 130, loss: 0.13255412876605988
step: 140, loss: 0.1245037093758583
step: 150, loss: 0.1305546909570694
step: 160, loss: 0.08435406535863876
step: 170, loss: 0.07323183864355087
step: 180, loss: 0.11213355511426926
step: 190, loss: 0.05778351053595543
step: 200, loss: 0.11667010933160782
step: 210, loss: 0.12287218868732452
step: 220, loss: 0.0874355286359787
step: 230, loss: 0.160024031996727
step: 240, loss: 0.12160352617502213
step: 250, loss: 0.07048790901899338
step: 260, loss: 0.09650862962007523
step: 270, loss: 0.17996744811534882
step: 280, loss: 0.07868550717830658
step: 290, loss: 0.062336474657058716
step: 300, loss: 0.0353611595928669
step: 310, loss: 0.05532020330429077
step: 320, loss: 0.053734373301267624
step: 330, loss: 0.1857537478208542
step: 340, loss: 0.07675319910049438
step: 350, loss: 0.016617508605122566
epoch 9: dev_f1=0.8207547169811321, f1=0.7945823927765238, best_f1=0.7939262472885034
step: 0, loss: 0.131855770945549
step: 10, loss: 0.23352493345737457
step: 20, loss: 0.07758291065692902
step: 30, loss: 0.04646745324134827
step: 40, loss: 0.03392820805311203
step: 50, loss: 0.13203978538513184
step: 60, loss: 0.061399009078741074
step: 70, loss: 0.08541946858167648
step: 80, loss: 0.20320698618888855
step: 90, loss: 0.08913322538137436
step: 100, loss: 0.0856306403875351
step: 110, loss: 0.04008739814162254
step: 120, loss: 0.07718748599290848
step: 130, loss: 0.06471375375986099
step: 140, loss: 0.09985408186912537
step: 150, loss: 0.1168278232216835
step: 160, loss: 0.0687188059091568
step: 170, loss: 0.07750334590673447
step: 180, loss: 0.07909126579761505
step: 190, loss: 0.045519277453422546
step: 200, loss: 0.12532302737236023
step: 210, loss: 0.10259368270635605
step: 220, loss: 0.061060287058353424
step: 230, loss: 0.08740116655826569
step: 240, loss: 0.06971002370119095
step: 250, loss: 0.1453307718038559
step: 260, loss: 0.12655048072338104
step: 270, loss: 0.11925485730171204
step: 280, loss: 0.15143783390522003
step: 290, loss: 0.12230966985225677
step: 300, loss: 0.13832369446754456
step: 310, loss: 0.03529758006334305
step: 320, loss: 0.07252195477485657
step: 330, loss: 0.1341916024684906
step: 340, loss: 0.056651558727025986
step: 350, loss: 0.041336845606565475
epoch 10: dev_f1=0.8144578313253013, f1=0.789838337182448, best_f1=0.7939262472885034
step: 0, loss: 0.11336208134889603
step: 10, loss: 0.08869704604148865
step: 20, loss: 0.14806725084781647
step: 30, loss: 0.11134008318185806
step: 40, loss: 0.07783901691436768
step: 50, loss: 0.015096727758646011
step: 60, loss: 0.14564743638038635
step: 70, loss: 0.05310841649770737
step: 80, loss: 0.21298156678676605
step: 90, loss: 0.06252366304397583
step: 100, loss: 0.06845319271087646
step: 110, loss: 0.02404315210878849
step: 120, loss: 0.021828820928931236
step: 130, loss: 0.048298947513103485
step: 140, loss: 0.1437435746192932
step: 150, loss: 0.052975647151470184
step: 160, loss: 0.04346441105008125
step: 170, loss: 0.0637943297624588
step: 180, loss: 0.129098579287529
step: 190, loss: 0.028227118775248528
step: 200, loss: 0.014430037699639797
step: 210, loss: 0.18100975453853607
step: 220, loss: 0.05718162655830383
step: 230, loss: 0.09604290872812271
step: 240, loss: 0.00010631053010001779
step: 250, loss: 0.04874596744775772
step: 260, loss: 0.050784625113010406
step: 270, loss: 0.04405231773853302
step: 280, loss: 0.077016681432724
step: 290, loss: 0.06666477024555206
step: 300, loss: 0.1785147786140442
step: 310, loss: 0.02508772909641266
step: 320, loss: 0.054294634610414505
step: 330, loss: 0.10019703954458237
step: 340, loss: 0.14592263102531433
step: 350, loss: 0.03981706127524376
epoch 11: dev_f1=0.8346055979643764, f1=0.7990074441687345, best_f1=0.7990074441687345
step: 0, loss: 0.12601019442081451
step: 10, loss: 0.06621537357568741
step: 20, loss: 0.03208233788609505
step: 30, loss: 0.05144461244344711
step: 40, loss: 0.04025623947381973
step: 50, loss: 0.00040735487709753215
step: 60, loss: 0.026900388300418854
step: 70, loss: 0.015241115354001522
step: 80, loss: 0.15288472175598145
step: 90, loss: 0.029889632016420364
step: 100, loss: 0.14828211069107056
step: 110, loss: 0.045556340366601944
step: 120, loss: 0.14646121859550476
step: 130, loss: 0.11094314604997635
step: 140, loss: 0.08496107906103134
step: 150, loss: 0.07001911848783493
step: 160, loss: 0.17027276754379272
step: 170, loss: 0.08488953113555908
step: 180, loss: 0.03959198668599129
step: 190, loss: 0.035183727741241455
step: 200, loss: 0.000684896600432694
step: 210, loss: 0.040369912981987
step: 220, loss: 0.057871222496032715
step: 230, loss: 0.03371105343103409
step: 240, loss: 0.03606567904353142
step: 250, loss: 0.05382435768842697
step: 260, loss: 0.10430727899074554
step: 270, loss: 0.0046625034883618355
step: 280, loss: 0.05377433821558952
step: 290, loss: 0.0946640819311142
step: 300, loss: 0.11519720405340195
step: 310, loss: 0.05457242205739021
step: 320, loss: 0.05697822570800781
step: 330, loss: 0.006612225901335478
step: 340, loss: 0.07909610867500305
step: 350, loss: 0.1104944497346878
epoch 12: dev_f1=0.8305489260143198, f1=0.8097345132743362, best_f1=0.7990074441687345
step: 0, loss: 0.08052760362625122
step: 10, loss: 0.04272466525435448
step: 20, loss: 0.137116476893425
step: 30, loss: 0.08966556191444397
step: 40, loss: 0.04347831383347511
step: 50, loss: 0.042504068464040756
step: 60, loss: 0.05922235548496246
step: 70, loss: 0.10835413634777069
step: 80, loss: 0.08928409218788147
step: 90, loss: 0.07962488383054733
step: 100, loss: 0.03629567474126816
step: 110, loss: 0.10892995446920395
step: 120, loss: 0.10400933027267456
step: 130, loss: 0.05817199498414993
step: 140, loss: 0.04255707934498787
step: 150, loss: 0.014025234617292881
step: 160, loss: 0.0655934065580368
step: 170, loss: 0.028728613629937172
step: 180, loss: 0.014973508194088936
step: 190, loss: 0.0446600541472435
step: 200, loss: 0.046813253313302994
step: 210, loss: 0.014447587542235851
step: 220, loss: 0.16029438376426697
step: 230, loss: 0.04979448765516281
step: 240, loss: 0.06103842332959175
step: 250, loss: 0.06701298803091049
step: 260, loss: 0.05866868793964386
step: 270, loss: 0.10133035480976105
step: 280, loss: 0.14515647292137146
step: 290, loss: 0.020442616194486618
step: 300, loss: 0.04635760933160782
step: 310, loss: 0.10736142098903656
step: 320, loss: 0.03294201195240021
step: 330, loss: 0.06842503696680069
step: 340, loss: 0.01800703816115856
step: 350, loss: 0.13296280801296234
epoch 13: dev_f1=0.8136363636363636, f1=0.7844827586206897, best_f1=0.7990074441687345
step: 0, loss: 0.12893353402614594
step: 10, loss: 0.08744193613529205
step: 20, loss: 0.1449684202671051
step: 30, loss: 0.061000920832157135
step: 40, loss: 0.11850248277187347
step: 50, loss: 0.024514999240636826
step: 60, loss: 0.08564373105764389
step: 70, loss: 0.14716850221157074
step: 80, loss: 0.090876005589962
step: 90, loss: 0.0715654119849205
step: 100, loss: 0.04400918632745743
step: 110, loss: 0.05346781760454178
step: 120, loss: 0.07054830342531204
step: 130, loss: 0.13085293769836426
step: 140, loss: 0.08787999302148819
step: 150, loss: 0.06773979961872101
step: 160, loss: 0.012537120841443539
step: 170, loss: 0.07059501111507416
step: 180, loss: 5.3461233619600534e-05
step: 190, loss: 0.07903078198432922
step: 200, loss: 0.08059374988079071
step: 210, loss: 0.05035683140158653
step: 220, loss: 0.008835560642182827
step: 230, loss: 0.047482989728450775
step: 240, loss: 0.014191975817084312
step: 250, loss: 0.13184955716133118
step: 260, loss: 0.04031980782747269
step: 270, loss: 0.018395502120256424
step: 280, loss: 0.10591614246368408
step: 290, loss: 0.0579707995057106
step: 300, loss: 0.07648655772209167
step: 310, loss: 0.0355711504817009
step: 320, loss: 0.16153085231781006
step: 330, loss: 0.05847141891717911
step: 340, loss: 0.07232233136892319
step: 350, loss: 0.05321398749947548
epoch 14: dev_f1=0.8085106382978723, f1=0.782608695652174, best_f1=0.7990074441687345
step: 0, loss: 0.00010394529817858711
step: 10, loss: 0.04638666659593582
step: 20, loss: 0.07029581815004349
step: 30, loss: 0.11764028668403625
step: 40, loss: 0.020758550614118576
step: 50, loss: 0.03070586919784546
step: 60, loss: 0.01750231347978115
step: 70, loss: 0.03317410126328468
step: 80, loss: 0.10452209413051605
step: 90, loss: 0.002404557541012764
step: 100, loss: 0.09318052977323532
step: 110, loss: 0.12123758345842361
step: 120, loss: 0.11742416769266129
step: 130, loss: 0.07986433804035187
step: 140, loss: 0.07489628344774246
step: 150, loss: 0.06979136168956757
step: 160, loss: 0.03213103860616684
step: 170, loss: 0.06263760477304459
step: 180, loss: 0.03405667096376419
step: 190, loss: 0.009286749176681042
step: 200, loss: 0.04985831677913666
step: 210, loss: 0.08154351264238358
step: 220, loss: 0.05866168439388275
step: 230, loss: 0.019999824464321136
step: 240, loss: 0.0593780055642128
step: 250, loss: 0.0721249207854271
step: 260, loss: 0.05412202328443527
step: 270, loss: 0.10777705907821655
step: 280, loss: 0.021370740607380867
step: 290, loss: 0.1149357408285141
step: 300, loss: 0.04012415558099747
step: 310, loss: 0.04776780307292938
step: 320, loss: 0.030122969299554825
step: 330, loss: 0.02411818876862526
step: 340, loss: 0.11552801728248596
step: 350, loss: 0.013336247764527798
epoch 15: dev_f1=0.8188235294117647, f1=0.7785234899328858, best_f1=0.7990074441687345
step: 0, loss: 0.05506463721394539
step: 10, loss: 0.05700952932238579
step: 20, loss: 0.14703698456287384
step: 30, loss: 0.0559079684317112
step: 40, loss: 0.09836748987436295
step: 50, loss: 0.03847577050328255
step: 60, loss: 0.05909299850463867
step: 70, loss: 0.032540637999773026
step: 80, loss: 0.04750277101993561
step: 90, loss: 0.07848745584487915
step: 100, loss: 0.031717851758003235
step: 110, loss: 0.12571433186531067
step: 120, loss: 0.017832588404417038
step: 130, loss: 0.006028229370713234
step: 140, loss: 0.07252724468708038
step: 150, loss: 0.15653978288173676
step: 160, loss: 0.06959554553031921
step: 170, loss: 0.05373388156294823
step: 180, loss: 0.1001548171043396
step: 190, loss: 0.042275309562683105
step: 200, loss: 0.0861775130033493
step: 210, loss: 0.046534597873687744
step: 220, loss: 0.0672263577580452
step: 230, loss: 0.08603315055370331
step: 240, loss: 0.08615750819444656
step: 250, loss: 0.03423937410116196
step: 260, loss: 0.011124376207590103
step: 270, loss: 0.029512053355574608
step: 280, loss: 0.08145736902952194
step: 290, loss: 0.1170172244310379
step: 300, loss: 0.08880933374166489
step: 310, loss: 0.051237210631370544
step: 320, loss: 0.06329254806041718
step: 330, loss: 0.1117086410522461
step: 340, loss: 0.048617273569107056
step: 350, loss: 0.07177168130874634
epoch 16: dev_f1=0.8123515439429927, f1=0.7706013363028953, best_f1=0.7990074441687345
step: 0, loss: 0.10643331706523895
step: 10, loss: 0.017885250970721245
step: 20, loss: 0.06747646629810333
step: 30, loss: 0.06564676016569138
step: 40, loss: 0.04960165172815323
step: 50, loss: 0.06506792455911636
step: 60, loss: 0.06629181653261185
step: 70, loss: 0.05575306713581085
step: 80, loss: 0.06660691648721695
step: 90, loss: 0.017210107296705246
step: 100, loss: 0.08929326385259628
step: 110, loss: 0.06713679432868958
step: 120, loss: 0.08658147603273392
step: 130, loss: 3.1935269362293184e-05
step: 140, loss: 0.009908272884786129
step: 150, loss: 0.05449941009283066
step: 160, loss: 0.05046544224023819
step: 170, loss: 0.05365794897079468
step: 180, loss: 0.0473010316491127
step: 190, loss: 0.04265203699469566
step: 200, loss: 0.07830455899238586
step: 210, loss: 0.07005292177200317
step: 220, loss: 0.13451842963695526
step: 230, loss: 0.017431648448109627
step: 240, loss: 0.046706508845090866
step: 250, loss: 0.04850281402468681
step: 260, loss: 0.07386514544487
step: 270, loss: 0.05550985038280487
step: 280, loss: 0.02101794257760048
step: 290, loss: 0.0631275400519371
step: 300, loss: 0.08362432569265366
step: 310, loss: 0.09712132811546326
step: 320, loss: 0.07107033580541611
step: 330, loss: 0.05297717824578285
step: 340, loss: 0.037155717611312866
step: 350, loss: 0.10166143625974655
epoch 17: dev_f1=0.7960199004975125, f1=0.7553444180522566, best_f1=0.7990074441687345
step: 0, loss: 0.05058330297470093
step: 10, loss: 0.06031003221869469
step: 20, loss: 0.050080474466085434
step: 30, loss: 0.006716499105095863
step: 40, loss: 0.039539970457553864
step: 50, loss: 0.11714252084493637
step: 60, loss: 0.037329886108636856
step: 70, loss: 0.06781744956970215
step: 80, loss: 0.08861643075942993
step: 90, loss: 0.06317847967147827
step: 100, loss: 0.0627211332321167
step: 110, loss: 0.1746848076581955
step: 120, loss: 0.09193170815706253
step: 130, loss: 0.06870433688163757
step: 140, loss: 0.0007891579298302531
step: 150, loss: 0.08849570155143738
step: 160, loss: 2.5569561330485158e-05
step: 170, loss: 0.01907973177731037
step: 180, loss: 0.07567927241325378
step: 190, loss: 0.0502253919839859
step: 200, loss: 0.04727489501237869
step: 210, loss: 0.07284121960401535
step: 220, loss: 0.07249078899621964
step: 230, loss: 0.06714185327291489
step: 240, loss: 0.03766005486249924
step: 250, loss: 0.11336112022399902
step: 260, loss: 0.048368241637945175
step: 270, loss: 0.10008407384157181
step: 280, loss: 0.05321310833096504
step: 290, loss: 0.055917344987392426
step: 300, loss: 0.028789011761546135
step: 310, loss: 0.05071297287940979
step: 320, loss: 0.005913390778005123
step: 330, loss: 0.0868329331278801
step: 340, loss: 0.04698500782251358
step: 350, loss: 0.06972666084766388
epoch 18: dev_f1=0.8057553956834533, f1=0.7551487414187643, best_f1=0.7990074441687345
step: 0, loss: 0.03991907835006714
step: 10, loss: 0.05513228476047516
step: 20, loss: 0.08237501978874207
step: 30, loss: 9.89464097074233e-05
step: 40, loss: 0.08043843507766724
step: 50, loss: 0.04984188824892044
step: 60, loss: 0.0822407528758049
step: 70, loss: 0.031859733164310455
step: 80, loss: 0.127170592546463
step: 90, loss: 0.0325203612446785
step: 100, loss: 0.09142687171697617
step: 110, loss: 0.03167871758341789
step: 120, loss: 0.01853245124220848
step: 130, loss: 0.08091091364622116
step: 140, loss: 0.22972138226032257
step: 150, loss: 0.0854669138789177
step: 160, loss: 0.04819118231534958
step: 170, loss: 0.03650611266493797
step: 180, loss: 0.10775943845510483
step: 190, loss: 0.0951819121837616
step: 200, loss: 0.04064019024372101
step: 210, loss: 0.04317367076873779
step: 220, loss: 0.10072221606969833
step: 230, loss: 0.22299855947494507
step: 240, loss: 0.06864479929208755
step: 250, loss: 0.10706724226474762
step: 260, loss: 0.005715715698897839
step: 270, loss: 0.12185899168252945
step: 280, loss: 0.045570679008960724
step: 290, loss: 0.09172651916742325
step: 300, loss: 0.07530023902654648
step: 310, loss: 0.08894038945436478
step: 320, loss: 0.04925893619656563
step: 330, loss: 0.01426544226706028
step: 340, loss: 0.03881058096885681
step: 350, loss: 0.16327574849128723
epoch 19: dev_f1=0.8, f1=0.7546296296296297, best_f1=0.7990074441687345
step: 0, loss: 0.015371794812381268
step: 10, loss: 0.051198821514844894
step: 20, loss: 0.01011303998529911
step: 30, loss: 0.017281776294112206
step: 40, loss: 0.04731924459338188
step: 50, loss: 0.08463262766599655
step: 60, loss: 0.02619885839521885
step: 70, loss: 4.776522473548539e-05
step: 80, loss: 0.034609440714120865
step: 90, loss: 0.04675472900271416
step: 100, loss: 0.07421623915433884
step: 110, loss: 0.057566843926906586
step: 120, loss: 0.08931905776262283
step: 130, loss: 0.012979971244931221
step: 140, loss: 0.02841302379965782
step: 150, loss: 3.3399610401829705e-05
step: 160, loss: 0.06000880151987076
step: 170, loss: 0.07950876653194427
step: 180, loss: 0.10565156489610672
step: 190, loss: 0.037893105298280716
step: 200, loss: 0.11568285524845123
step: 210, loss: 0.06977742165327072
step: 220, loss: 0.06122094765305519
step: 230, loss: 0.00016874086577445269
step: 240, loss: 0.031180495396256447
step: 250, loss: 0.08423632383346558
step: 260, loss: 0.07048939168453217
step: 270, loss: 0.052736617624759674
step: 280, loss: 0.07376174628734589
step: 290, loss: 0.04141457751393318
step: 300, loss: 0.040862951427698135
step: 310, loss: 0.07431086152791977
step: 320, loss: 0.07145564258098602
step: 330, loss: 0.05549236014485359
step: 340, loss: 0.009664634242653847
step: 350, loss: 0.09282895922660828
epoch 20: dev_f1=0.8, f1=0.7517730496453902, best_f1=0.7990074441687345
