cuda
Device: cuda
step: 0, loss: 0.5853824615478516
step: 10, loss: 0.1698218584060669
step: 20, loss: 0.296061635017395
step: 30, loss: 0.3061862885951996
step: 40, loss: 0.5522986054420471
step: 50, loss: 0.32894596457481384
step: 60, loss: 0.5618082284927368
step: 70, loss: 0.2509988248348236
step: 80, loss: 0.3509988486766815
step: 90, loss: 0.3135267198085785
step: 100, loss: 0.3997914493083954
step: 110, loss: 0.3676918148994446
step: 120, loss: 0.43312278389930725
step: 130, loss: 0.3927285075187683
step: 140, loss: 0.21510016918182373
step: 150, loss: 0.21445956826210022
step: 160, loss: 0.264370322227478
step: 170, loss: 0.19989614188671112
step: 180, loss: 0.21694649755954742
step: 190, loss: 0.3472292721271515
step: 200, loss: 0.15239118039608002
step: 210, loss: 0.21653355658054352
step: 220, loss: 0.07884982973337173
step: 230, loss: 0.217758908867836
step: 240, loss: 0.29069244861602783
step: 250, loss: 0.18456293642520905
step: 260, loss: 0.11789831519126892
step: 270, loss: 0.2265094369649887
step: 280, loss: 0.20737239718437195
step: 290, loss: 0.1267525851726532
step: 300, loss: 0.328451544046402
step: 310, loss: 0.1663646697998047
step: 320, loss: 0.14118540287017822
step: 330, loss: 0.1361754983663559
step: 340, loss: 0.15680071711540222
step: 350, loss: 0.1566227227449417
epoch 1: dev_f1=0.7218390804597702, f1=0.7500000000000001, best_f1=0.7500000000000001
step: 0, loss: 0.10153183341026306
step: 10, loss: 0.2088131308555603
step: 20, loss: 0.1631651073694229
step: 30, loss: 0.17687544226646423
step: 40, loss: 0.12185074388980865
step: 50, loss: 0.1755087971687317
step: 60, loss: 0.22028511762619019
step: 70, loss: 0.16973841190338135
step: 80, loss: 0.3419281244277954
step: 90, loss: 0.25301164388656616
step: 100, loss: 0.3382405638694763
step: 110, loss: 0.23797224462032318
step: 120, loss: 0.1727524846792221
step: 130, loss: 0.2509287893772125
step: 140, loss: 0.16190236806869507
step: 150, loss: 0.21112070977687836
step: 160, loss: 0.19595324993133545
step: 170, loss: 0.2633357346057892
step: 180, loss: 0.09961351007223129
step: 190, loss: 0.23845601081848145
step: 200, loss: 0.21357496082782745
step: 210, loss: 0.10709933191537857
step: 220, loss: 0.2463177889585495
step: 230, loss: 0.10863989591598511
step: 240, loss: 0.11036171019077301
step: 250, loss: 0.17236745357513428
step: 260, loss: 0.09581650048494339
step: 270, loss: 0.1266762763261795
step: 280, loss: 0.2668271064758301
step: 290, loss: 0.1488496959209442
step: 300, loss: 0.1490783542394638
step: 310, loss: 0.11965414136648178
step: 320, loss: 0.09073922783136368
step: 330, loss: 0.11953391134738922
step: 340, loss: 0.061811864376068115
step: 350, loss: 0.06727553904056549
epoch 2: dev_f1=0.7706855791962176, f1=0.7767441860465116, best_f1=0.7767441860465116
step: 0, loss: 0.18347206711769104
step: 10, loss: 0.16166871786117554
step: 20, loss: 0.03574264422059059
step: 30, loss: 0.05875714495778084
step: 40, loss: 0.15581877529621124
step: 50, loss: 0.1241268515586853
step: 60, loss: 0.04160325974225998
step: 70, loss: 0.17962560057640076
step: 80, loss: 0.06358671188354492
step: 90, loss: 0.09397372603416443
step: 100, loss: 0.05272292345762253
step: 110, loss: 0.19316330552101135
step: 120, loss: 0.050039444118738174
step: 130, loss: 0.17042894661426544
step: 140, loss: 0.09995389729738235
step: 150, loss: 0.11129927635192871
step: 160, loss: 0.13900531828403473
step: 170, loss: 0.23964807391166687
step: 180, loss: 0.04782106354832649
step: 190, loss: 0.1404089629650116
step: 200, loss: 0.20236532390117645
step: 210, loss: 0.05908169597387314
step: 220, loss: 0.07961319386959076
step: 230, loss: 0.09292520582675934
step: 240, loss: 0.08701159060001373
step: 250, loss: 0.06243032589554787
step: 260, loss: 0.10073556751012802
step: 270, loss: 0.07706931978464127
step: 280, loss: 0.08572833985090256
step: 290, loss: 0.27752485871315
step: 300, loss: 0.12772434949874878
step: 310, loss: 0.14932993054389954
step: 320, loss: 0.07179134339094162
step: 330, loss: 0.10361351072788239
step: 340, loss: 0.2434835433959961
step: 350, loss: 0.04435360059142113
epoch 3: dev_f1=0.810304449648712, f1=0.8036951501154735, best_f1=0.8036951501154735
step: 0, loss: 0.05454820767045021
step: 10, loss: 0.0360153429210186
step: 20, loss: 0.042216964066028595
step: 30, loss: 0.052929531782865524
step: 40, loss: 0.07374432682991028
step: 50, loss: 0.031349893659353256
step: 60, loss: 0.051726121455430984
step: 70, loss: 0.05369303375482559
step: 80, loss: 0.0691070482134819
step: 90, loss: 0.03287184610962868
step: 100, loss: 0.12391974776983261
step: 110, loss: 0.10798434913158417
step: 120, loss: 0.216362863779068
step: 130, loss: 0.11639571934938431
step: 140, loss: 0.03134938329458237
step: 150, loss: 0.020847344771027565
step: 160, loss: 0.0734863206744194
step: 170, loss: 0.13878118991851807
step: 180, loss: 0.09309816360473633
step: 190, loss: 0.17883789539337158
step: 200, loss: 0.24511902034282684
step: 210, loss: 0.19181156158447266
step: 220, loss: 0.12741272151470184
step: 230, loss: 0.03798151761293411
step: 240, loss: 0.13922186195850372
step: 250, loss: 0.08204932510852814
step: 260, loss: 0.13606463372707367
step: 270, loss: 0.033497609198093414
step: 280, loss: 0.05857465788722038
step: 290, loss: 0.08970454335212708
step: 300, loss: 0.1137794628739357
step: 310, loss: 0.10259822756052017
step: 320, loss: 0.06706815212965012
step: 330, loss: 0.21090996265411377
step: 340, loss: 0.04450199380517006
step: 350, loss: 0.23078303039073944
epoch 4: dev_f1=0.7935034802784221, f1=0.7990867579908676, best_f1=0.8036951501154735
step: 0, loss: 0.14581190049648285
step: 10, loss: 0.0423954539000988
step: 20, loss: 0.045682184398174286
step: 30, loss: 0.24714767932891846
step: 40, loss: 0.08257894217967987
step: 50, loss: 0.08728514611721039
step: 60, loss: 0.05462921783328056
step: 70, loss: 0.033981889486312866
step: 80, loss: 0.13964536786079407
step: 90, loss: 0.18618269264698029
step: 100, loss: 0.05761575326323509
step: 110, loss: 0.06882321834564209
step: 120, loss: 0.07759673148393631
step: 130, loss: 0.0973399356007576
step: 140, loss: 0.12198803573846817
step: 150, loss: 0.044108711183071136
step: 160, loss: 0.11185387521982193
step: 170, loss: 0.04174879938364029
step: 180, loss: 0.22008362412452698
step: 190, loss: 0.08884034305810928
step: 200, loss: 0.07186716794967651
step: 210, loss: 0.054064784198999405
step: 220, loss: 0.08960031718015671
step: 230, loss: 0.1739930808544159
step: 240, loss: 0.08348815888166428
step: 250, loss: 0.07185202836990356
step: 260, loss: 0.049139607697725296
step: 270, loss: 0.026583217084407806
step: 280, loss: 0.14997556805610657
step: 290, loss: 0.11058720201253891
step: 300, loss: 0.07103029638528824
step: 310, loss: 0.07329287379980087
step: 320, loss: 0.06965076178312302
step: 330, loss: 0.0033762522507458925
step: 340, loss: 0.09055496752262115
step: 350, loss: 0.0800638198852539
epoch 5: dev_f1=0.8302752293577982, f1=0.8140043763676149, best_f1=0.8140043763676149
step: 0, loss: 0.07340212166309357
step: 10, loss: 0.06513140350580215
step: 20, loss: 0.05874694138765335
step: 30, loss: 0.13339820504188538
step: 40, loss: 0.08345707505941391
step: 50, loss: 0.33395203948020935
step: 60, loss: 0.06949426233768463
step: 70, loss: 0.022783465683460236
step: 80, loss: 0.1390141248703003
step: 90, loss: 0.12910096347332
step: 100, loss: 0.0911937803030014
step: 110, loss: 0.014565127901732922
step: 120, loss: 0.15291227400302887
step: 130, loss: 0.03566109389066696
step: 140, loss: 0.06734885275363922
step: 150, loss: 0.03252975642681122
step: 160, loss: 0.13038599491119385
step: 170, loss: 0.06632724404335022
step: 180, loss: 0.09909431636333466
step: 190, loss: 0.09190863370895386
step: 200, loss: 0.047587450593709946
step: 210, loss: 0.04824090376496315
step: 220, loss: 0.10414880514144897
step: 230, loss: 0.14911332726478577
step: 240, loss: 0.07531202584505081
step: 250, loss: 0.0925578773021698
step: 260, loss: 0.2427338808774948
step: 270, loss: 0.10221675038337708
step: 280, loss: 0.09291800111532211
step: 290, loss: 0.06880172342061996
step: 300, loss: 0.0665779635310173
step: 310, loss: 0.053409554064273834
step: 320, loss: 0.1307574361562729
step: 330, loss: 0.09299540519714355
step: 340, loss: 0.10310947149991989
step: 350, loss: 0.09125910699367523
epoch 6: dev_f1=0.821852731591449, f1=0.8275862068965516, best_f1=0.8140043763676149
step: 0, loss: 0.12020263820886612
step: 10, loss: 0.031942009925842285
step: 20, loss: 0.046685591340065
step: 30, loss: 0.03368533402681351
step: 40, loss: 0.0656106173992157
step: 50, loss: 0.09626882523298264
step: 60, loss: 0.10828307271003723
step: 70, loss: 0.04964912310242653
step: 80, loss: 0.006452661473304033
step: 90, loss: 0.22581258416175842
step: 100, loss: 0.039726853370666504
step: 110, loss: 0.024675624445080757
step: 120, loss: 0.11248098313808441
step: 130, loss: 0.14699798822402954
step: 140, loss: 0.09673396497964859
step: 150, loss: 0.03952193632721901
step: 160, loss: 0.10997837781906128
step: 170, loss: 0.09542161226272583
step: 180, loss: 0.05556283891201019
step: 190, loss: 0.14001156389713287
step: 200, loss: 0.312875896692276
step: 210, loss: 0.05879286676645279
step: 220, loss: 0.0808209627866745
step: 230, loss: 0.14276830852031708
step: 240, loss: 0.07841750979423523
step: 250, loss: 0.11555066704750061
step: 260, loss: 0.11582400649785995
step: 270, loss: 0.01739756017923355
step: 280, loss: 0.051884450018405914
step: 290, loss: 0.07037249207496643
step: 300, loss: 0.02628089115023613
step: 310, loss: 0.03314901143312454
step: 320, loss: 0.2565409541130066
step: 330, loss: 0.16348201036453247
step: 340, loss: 0.09039779007434845
step: 350, loss: 0.0963987335562706
epoch 7: dev_f1=0.8275862068965517, f1=0.8076923076923078, best_f1=0.8140043763676149
step: 0, loss: 0.04548546299338341
step: 10, loss: 0.06694619357585907
step: 20, loss: 0.05315643921494484
step: 30, loss: 0.1397370547056198
step: 40, loss: 0.11258720606565475
step: 50, loss: 0.10872696340084076
step: 60, loss: 0.02260192483663559
step: 70, loss: 0.07803734391927719
step: 80, loss: 0.04479879513382912
step: 90, loss: 0.023828737437725067
step: 100, loss: 0.04846487566828728
step: 110, loss: 0.08635353296995163
step: 120, loss: 0.09935534000396729
step: 130, loss: 0.22075395286083221
step: 140, loss: 0.12167985737323761
step: 150, loss: 0.07879583537578583
step: 160, loss: 0.10796215385198593
step: 170, loss: 0.05060911178588867
step: 180, loss: 0.01997552253305912
step: 190, loss: 0.039131492376327515
step: 200, loss: 0.09028399735689163
step: 210, loss: 0.06929662078619003
step: 220, loss: 0.07705298066139221
step: 230, loss: 0.048951320350170135
step: 240, loss: 0.03205142542719841
step: 250, loss: 0.11168108135461807
step: 260, loss: 0.06090814992785454
step: 270, loss: 0.1414145529270172
step: 280, loss: 0.09931513667106628
step: 290, loss: 0.020562030375003815
step: 300, loss: 0.05543236806988716
step: 310, loss: 0.05620386451482773
step: 320, loss: 0.04572068899869919
step: 330, loss: 0.0252290740609169
step: 340, loss: 0.13661031424999237
step: 350, loss: 0.16435544192790985
epoch 8: dev_f1=0.8265524625267666, f1=0.8016877637130801, best_f1=0.8140043763676149
step: 0, loss: 0.062185995280742645
step: 10, loss: 0.062076400965452194
step: 20, loss: 0.07151877135038376
step: 30, loss: 0.09650459885597229
step: 40, loss: 0.09246786683797836
step: 50, loss: 0.028562437742948532
step: 60, loss: 0.0004013828875031322
step: 70, loss: 0.05195401981472969
step: 80, loss: 0.11924084275960922
step: 90, loss: 0.07994669675827026
step: 100, loss: 0.029498104006052017
step: 110, loss: 0.09877723455429077
step: 120, loss: 0.0609922930598259
step: 130, loss: 0.13569216430187225
step: 140, loss: 0.013853318057954311
step: 150, loss: 0.002145162783563137
step: 160, loss: 0.10217036306858063
step: 170, loss: 0.09065275639295578
step: 180, loss: 0.04660886153578758
step: 190, loss: 0.07399706542491913
step: 200, loss: 0.11256373673677444
step: 210, loss: 0.06633292883634567
step: 220, loss: 0.12548863887786865
step: 230, loss: 0.12313222885131836
step: 240, loss: 0.08209704607725143
step: 250, loss: 0.09255488216876984
step: 260, loss: 0.06180112436413765
step: 270, loss: 0.022991253063082695
step: 280, loss: 0.04468970373272896
step: 290, loss: 0.09287527203559875
step: 300, loss: 0.09127429127693176
step: 310, loss: 0.09822483360767365
step: 320, loss: 0.1261311024427414
step: 330, loss: 0.12525741755962372
step: 340, loss: 0.09033773094415665
step: 350, loss: 0.051033083349466324
epoch 9: dev_f1=0.8296943231441049, f1=0.8152866242038216, best_f1=0.8140043763676149
step: 0, loss: 0.05828498676419258
step: 10, loss: 0.06851008534431458
step: 20, loss: 0.07246415317058563
step: 30, loss: 0.07834398001432419
step: 40, loss: 0.11411643773317337
step: 50, loss: 0.061157479882240295
step: 60, loss: 0.19027140736579895
step: 70, loss: 0.0742405354976654
step: 80, loss: 0.043007027357816696
step: 90, loss: 0.07484161853790283
step: 100, loss: 0.0960543230175972
step: 110, loss: 0.128891259431839
step: 120, loss: 0.07381846755743027
step: 130, loss: 0.10818064957857132
step: 140, loss: 0.1140996664762497
step: 150, loss: 0.09536516666412354
step: 160, loss: 0.03894616290926933
step: 170, loss: 0.04363474249839783
step: 180, loss: 0.0872691422700882
step: 190, loss: 0.07709521055221558
step: 200, loss: 0.03467106819152832
step: 210, loss: 0.2554786801338196
step: 220, loss: 0.06627534329891205
step: 230, loss: 0.08592148125171661
step: 240, loss: 0.048729561269283295
step: 250, loss: 0.06249816715717316
step: 260, loss: 0.10061979293823242
step: 270, loss: 0.12547406554222107
step: 280, loss: 0.04146398603916168
step: 290, loss: 0.024611106142401695
step: 300, loss: 0.07274244725704193
step: 310, loss: 0.036351148039102554
step: 320, loss: 0.04214426502585411
step: 330, loss: 0.06610378623008728
step: 340, loss: 0.05327929928898811
step: 350, loss: 0.1516135334968567
epoch 10: dev_f1=0.8356164383561643, f1=0.8307692307692308, best_f1=0.8307692307692308
step: 0, loss: 0.12429820746183395
step: 10, loss: 0.061182595789432526
step: 20, loss: 0.06879068166017532
step: 30, loss: 0.053819652646780014
step: 40, loss: 0.05046301335096359
step: 50, loss: 0.058067936450242996
step: 60, loss: 0.04328743368387222
step: 70, loss: 0.1701408326625824
step: 80, loss: 0.05426666885614395
step: 90, loss: 0.13173718750476837
step: 100, loss: 0.046749748289585114
step: 110, loss: 0.01815495826303959
step: 120, loss: 0.0645543709397316
step: 130, loss: 0.09226556867361069
step: 140, loss: 0.11872614920139313
step: 150, loss: 0.12857933342456818
step: 160, loss: 0.054566510021686554
step: 170, loss: 0.07679237425327301
step: 180, loss: 0.035638026893138885
step: 190, loss: 0.022326910868287086
step: 200, loss: 0.031971126794815063
step: 210, loss: 0.06418497860431671
step: 220, loss: 0.1132175549864769
step: 230, loss: 0.13504967093467712
step: 240, loss: 0.047072216868400574
step: 250, loss: 0.08904466778039932
step: 260, loss: 0.06371334940195084
step: 270, loss: 0.10407942533493042
step: 280, loss: 0.08687504380941391
step: 290, loss: 0.17584086954593658
step: 300, loss: 0.2083936631679535
step: 310, loss: 0.023696601390838623
step: 320, loss: 0.016814598813652992
step: 330, loss: 0.06275976449251175
step: 340, loss: 0.011264718137681484
step: 350, loss: 0.08326984196901321
epoch 11: dev_f1=0.8253968253968255, f1=0.8333333333333333, best_f1=0.8307692307692308
step: 0, loss: 0.11780734360218048
step: 10, loss: 0.05954287201166153
step: 20, loss: 0.0867500901222229
step: 30, loss: 0.14239953458309174
step: 40, loss: 0.05979878082871437
step: 50, loss: 0.030899714678525925
step: 60, loss: 0.07951117306947708
step: 70, loss: 0.0738612711429596
step: 80, loss: 0.027689514681696892
step: 90, loss: 0.027462409809231758
step: 100, loss: 0.07148464769124985
step: 110, loss: 0.10743513703346252
step: 120, loss: 0.04138705134391785
step: 130, loss: 0.04769293963909149
step: 140, loss: 0.14952176809310913
step: 150, loss: 0.05525261163711548
step: 160, loss: 0.04689599573612213
step: 170, loss: 0.03865132853388786
step: 180, loss: 0.12994806468486786
step: 190, loss: 0.11585437506437302
step: 200, loss: 0.14660033583641052
step: 210, loss: 0.04820379987359047
step: 220, loss: 0.10677976161241531
step: 230, loss: 0.13059450685977936
step: 240, loss: 0.09124312549829483
step: 250, loss: 0.12924660742282867
step: 260, loss: 0.09387052804231644
step: 270, loss: 0.04234674572944641
step: 280, loss: 0.0405610129237175
step: 290, loss: 0.06941548734903336
step: 300, loss: 0.08739608526229858
step: 310, loss: 0.0955134704709053
step: 320, loss: 0.09319248795509338
step: 330, loss: 0.040329594165086746
step: 340, loss: 0.08601817488670349
step: 350, loss: 0.06493707001209259
epoch 12: dev_f1=0.8264058679706602, f1=0.8483412322274881, best_f1=0.8307692307692308
step: 0, loss: 0.03372171148657799
step: 10, loss: 0.08315658569335938
step: 20, loss: 0.08698570728302002
step: 30, loss: 0.07575283199548721
step: 40, loss: 0.058711547404527664
step: 50, loss: 0.017269611358642578
step: 60, loss: 0.05064316466450691
step: 70, loss: 0.09554804861545563
step: 80, loss: 0.07099289447069168
step: 90, loss: 0.12274804711341858
step: 100, loss: 0.09543556720018387
step: 110, loss: 0.013264643028378487
step: 120, loss: 0.14337237179279327
step: 130, loss: 0.09318406879901886
step: 140, loss: 0.07889899611473083
step: 150, loss: 0.12391360104084015
step: 160, loss: 0.10002324730157852
step: 170, loss: 0.05232628434896469
step: 180, loss: 0.0480988472700119
step: 190, loss: 0.03959998860955238
step: 200, loss: 0.14830729365348816
step: 210, loss: 0.2224535495042801
step: 220, loss: 0.13091138005256653
step: 230, loss: 0.013441385701298714
step: 240, loss: 0.0019152992172166705
step: 250, loss: 0.036972079426050186
step: 260, loss: 0.00739788543432951
step: 270, loss: 0.12993644177913666
step: 280, loss: 0.021392596885561943
step: 290, loss: 0.03335363790392876
step: 300, loss: 0.12350646406412125
step: 310, loss: 0.0016069344710558653
step: 320, loss: 0.07447812706232071
step: 330, loss: 0.040398843586444855
step: 340, loss: 0.06847207248210907
step: 350, loss: 0.024302585050463676
epoch 13: dev_f1=0.8329411764705882, f1=0.8359550561797753, best_f1=0.8307692307692308
step: 0, loss: 0.053148508071899414
step: 10, loss: 0.031109364703297615
step: 20, loss: 0.10102031379938126
step: 30, loss: 0.08977624773979187
step: 40, loss: 0.048563167452812195
step: 50, loss: 0.03520916774868965
step: 60, loss: 0.03378698602318764
step: 70, loss: 0.07940316200256348
step: 80, loss: 0.09667637944221497
step: 90, loss: 0.10930553823709488
step: 100, loss: 9.28789158933796e-05
step: 110, loss: 0.1257319152355194
step: 120, loss: 0.049279894679784775
step: 130, loss: 0.019955411553382874
step: 140, loss: 0.025439776480197906
step: 150, loss: 0.06280356645584106
step: 160, loss: 0.08498195558786392
step: 170, loss: 0.14521002769470215
step: 180, loss: 0.056887030601501465
step: 190, loss: 0.04657168313860893
step: 200, loss: 0.052939996123313904
step: 210, loss: 0.1424257904291153
step: 220, loss: 0.03489989414811134
step: 230, loss: 0.0684753805398941
step: 240, loss: 0.0728524774312973
step: 250, loss: 0.16088540852069855
step: 260, loss: 0.13820071518421173
step: 270, loss: 0.11508852988481522
step: 280, loss: 0.07009711116552353
step: 290, loss: 0.024229440838098526
step: 300, loss: 0.04701845347881317
step: 310, loss: 0.10629685968160629
step: 320, loss: 0.04339371621608734
step: 330, loss: 0.1637725681066513
step: 340, loss: 0.17529942095279694
step: 350, loss: 0.019619211554527283
epoch 14: dev_f1=0.8365384615384616, f1=0.851258581235698, best_f1=0.851258581235698
step: 0, loss: 0.04916999489068985
step: 10, loss: 7.07623185007833e-05
step: 20, loss: 0.1035417914390564
step: 30, loss: 0.09295285493135452
step: 40, loss: 0.032931894063949585
step: 50, loss: 0.00041200872510671616
step: 60, loss: 0.02623850852251053
step: 70, loss: 0.1037062332034111
step: 80, loss: 0.047540999948978424
step: 90, loss: 0.11535363644361496
step: 100, loss: 0.06907147914171219
step: 110, loss: 0.05190587416291237
step: 120, loss: 0.04027673602104187
step: 130, loss: 0.05880067124962807
step: 140, loss: 0.09476678818464279
step: 150, loss: 0.10481489449739456
step: 160, loss: 0.05547309294342995
step: 170, loss: 0.07320388406515121
step: 180, loss: 0.0722494050860405
step: 190, loss: 0.09467577934265137
step: 200, loss: 0.2909894585609436
step: 210, loss: 0.057124294340610504
step: 220, loss: 0.06380239874124527
step: 230, loss: 0.10072196274995804
step: 240, loss: 0.10442850738763809
step: 250, loss: 0.09328428655862808
step: 260, loss: 0.04477423056960106
step: 270, loss: 0.06131346523761749
step: 280, loss: 0.011868040077388287
step: 290, loss: 0.030972380191087723
step: 300, loss: 0.0969005897641182
step: 310, loss: 0.06341787427663803
step: 320, loss: 0.023894865065813065
step: 330, loss: 0.10520035773515701
step: 340, loss: 0.08309772610664368
step: 350, loss: 0.11169596016407013
epoch 15: dev_f1=0.8298368298368297, f1=0.8185840707964601, best_f1=0.851258581235698
step: 0, loss: 0.012164890766143799
step: 10, loss: 0.08786079287528992
step: 20, loss: 0.07147859036922455
step: 30, loss: 0.15163305401802063
step: 40, loss: 0.1391201913356781
step: 50, loss: 0.03971123322844505
step: 60, loss: 0.1796608716249466
step: 70, loss: 7.710258796578273e-05
step: 80, loss: 0.08473099023103714
step: 90, loss: 0.09549658000469208
step: 100, loss: 0.00010091879812534899
step: 110, loss: 0.024993611499667168
step: 120, loss: 0.021549580618739128
step: 130, loss: 0.03987269103527069
step: 140, loss: 0.07633432000875473
step: 150, loss: 0.027629896998405457
step: 160, loss: 0.08071323484182358
step: 170, loss: 0.06981891393661499
step: 180, loss: 0.09239813685417175
step: 190, loss: 0.09549839794635773
step: 200, loss: 0.15565302968025208
step: 210, loss: 0.09587496519088745
step: 220, loss: 0.05503344163298607
step: 230, loss: 0.06517482548952103
step: 240, loss: 0.010889695957303047
step: 250, loss: 0.024524152278900146
step: 260, loss: 0.004559868946671486
step: 270, loss: 0.032101817429065704
step: 280, loss: 0.046947211027145386
step: 290, loss: 0.08342770487070084
step: 300, loss: 0.08667493611574173
step: 310, loss: 0.08635798841714859
step: 320, loss: 0.10626779496669769
step: 330, loss: 0.018412817269563675
step: 340, loss: 0.05863713473081589
step: 350, loss: 0.08899518847465515
epoch 16: dev_f1=0.819753086419753, f1=0.8486238532110092, best_f1=0.851258581235698
step: 0, loss: 0.055165521800518036
step: 10, loss: 0.00013385922648012638
step: 20, loss: 0.09608930349349976
step: 30, loss: 0.05940588191151619
step: 40, loss: 0.005656572058796883
step: 50, loss: 0.06282810866832733
step: 60, loss: 0.0003245109401177615
step: 70, loss: 0.08682823181152344
step: 80, loss: 0.06086127832531929
step: 90, loss: 0.10902205854654312
step: 100, loss: 0.07043658941984177
step: 110, loss: 0.026446746662259102
step: 120, loss: 0.05792911723256111
step: 130, loss: 0.07219185680150986
step: 140, loss: 0.08534101396799088
step: 150, loss: 0.04787818714976311
step: 160, loss: 0.06488854438066483
step: 170, loss: 0.0132043631747365
step: 180, loss: 0.030679091811180115
step: 190, loss: 0.030841505154967308
step: 200, loss: 0.06760767847299576
step: 210, loss: 0.06737800687551498
step: 220, loss: 0.05946171656250954
step: 230, loss: 3.995575025328435e-05
step: 240, loss: 0.0942210778594017
step: 250, loss: 0.11146431416273117
step: 260, loss: 0.0798148438334465
step: 270, loss: 0.02014465443789959
step: 280, loss: 0.03292546793818474
step: 290, loss: 0.06871289759874344
step: 300, loss: 0.12765328586101532
step: 310, loss: 0.010429300367832184
step: 320, loss: 0.06995739042758942
step: 330, loss: 0.0655892938375473
step: 340, loss: 0.03996306657791138
step: 350, loss: 0.06556006520986557
epoch 17: dev_f1=0.8274231678486996, f1=0.8442437923250564, best_f1=0.851258581235698
step: 0, loss: 0.07475559413433075
step: 10, loss: 0.03688118979334831
step: 20, loss: 0.15170811116695404
step: 30, loss: 0.08712895959615707
step: 40, loss: 0.0003603503864724189
step: 50, loss: 0.1109083816409111
step: 60, loss: 0.034079741686582565
step: 70, loss: 0.034537240862846375
step: 80, loss: 0.030112048611044884
step: 90, loss: 0.05003081634640694
step: 100, loss: 8.990438800537959e-05
step: 110, loss: 0.07613632082939148
step: 120, loss: 0.050252802670001984
step: 130, loss: 0.1558326631784439
step: 140, loss: 0.08074495941400528
step: 150, loss: 0.04915597662329674
step: 160, loss: 0.2074621617794037
step: 170, loss: 0.1033637523651123
step: 180, loss: 0.06418495625257492
step: 190, loss: 0.048817701637744904
step: 200, loss: 0.05969619378447533
step: 210, loss: 0.00732759665697813
step: 220, loss: 0.0733640119433403
step: 230, loss: 0.02362891286611557
step: 240, loss: 0.13029144704341888
step: 250, loss: 0.09291933476924896
step: 260, loss: 0.037726029753685
step: 270, loss: 0.09266054630279541
step: 280, loss: 0.05474982038140297
step: 290, loss: 0.08084725588560104
step: 300, loss: 0.1092415601015091
step: 310, loss: 0.019079962745308876
step: 320, loss: 0.02523968741297722
step: 330, loss: 0.09880755841732025
step: 340, loss: 0.12728172540664673
step: 350, loss: 0.12664814293384552
epoch 18: dev_f1=0.8300970873786409, f1=0.8397291196388262, best_f1=0.851258581235698
step: 0, loss: 0.09736368060112
step: 10, loss: 0.08218555152416229
step: 20, loss: 0.05570213496685028
step: 30, loss: 0.02249094471335411
step: 40, loss: 0.07871686667203903
step: 50, loss: 0.013483535498380661
step: 60, loss: 0.0837920755147934
step: 70, loss: 0.1598169058561325
step: 80, loss: 0.07953575253486633
step: 90, loss: 0.029613200575113297
step: 100, loss: 0.10886707156896591
step: 110, loss: 0.03895968571305275
step: 120, loss: 0.059043481945991516
step: 130, loss: 0.1714726686477661
step: 140, loss: 0.062173184007406235
step: 150, loss: 0.03409472107887268
step: 160, loss: 0.09960848093032837
step: 170, loss: 0.07965324819087982
step: 180, loss: 0.11393237113952637
step: 190, loss: 0.0341351144015789
step: 200, loss: 0.08244010806083679
step: 210, loss: 0.013936090283095837
step: 220, loss: 0.07635122537612915
step: 230, loss: 0.04130217060446739
step: 240, loss: 0.018183397129178047
step: 250, loss: 0.07726460695266724
step: 260, loss: 0.000629340996965766
step: 270, loss: 0.02999921329319477
step: 280, loss: 0.08958224207162857
step: 290, loss: 0.10831964761018753
step: 300, loss: 0.023509755730628967
step: 310, loss: 0.0417383648455143
step: 320, loss: 0.06070195138454437
step: 330, loss: 0.07153631001710892
step: 340, loss: 0.0608428418636322
step: 350, loss: 0.0683618038892746
epoch 19: dev_f1=0.8385542168674698, f1=0.847380410022779, best_f1=0.847380410022779
step: 0, loss: 0.0842357873916626
step: 10, loss: 0.056393101811409
step: 20, loss: 0.026737047359347343
step: 30, loss: 0.27892687916755676
step: 40, loss: 0.11867226660251617
step: 50, loss: 0.038989678025245667
step: 60, loss: 0.06511728465557098
step: 70, loss: 0.08187123388051987
step: 80, loss: 0.05617539584636688
step: 90, loss: 0.04732535034418106
step: 100, loss: 0.03024565987288952
step: 110, loss: 0.028971215710043907
step: 120, loss: 0.03355804458260536
step: 130, loss: 0.056039124727249146
step: 140, loss: 0.007300117984414101
step: 150, loss: 0.08486220985651016
step: 160, loss: 0.05996180698275566
step: 170, loss: 0.11117575317621231
step: 180, loss: 0.06037069857120514
step: 190, loss: 0.08928836137056351
step: 200, loss: 0.048527125269174576
step: 210, loss: 0.0974777564406395
step: 220, loss: 0.08760151267051697
step: 230, loss: 0.08857067674398422
step: 240, loss: 0.02229062095284462
step: 250, loss: 0.030857108533382416
step: 260, loss: 0.08042719960212708
step: 270, loss: 0.10671544075012207
step: 280, loss: 0.09920188784599304
step: 290, loss: 0.05193988233804703
step: 300, loss: 0.11275561153888702
step: 310, loss: 0.029662583023309708
step: 320, loss: 0.05089975893497467
step: 330, loss: 0.07239771634340286
step: 340, loss: 0.0006181137869134545
step: 350, loss: 0.06841986626386642
epoch 20: dev_f1=0.8138957816377173, f1=0.8524590163934426, best_f1=0.847380410022779
