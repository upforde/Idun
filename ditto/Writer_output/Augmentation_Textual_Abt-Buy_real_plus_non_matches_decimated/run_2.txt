cuda
Device: cuda
step: 0, loss: 0.898540198802948
step: 10, loss: 0.24028176069259644
step: 20, loss: 0.13338704407215118
step: 30, loss: 0.25890523195266724
step: 40, loss: 0.1560247242450714
step: 50, loss: 0.3291344940662384
step: 60, loss: 0.0785098746418953
step: 70, loss: 0.22784548997879028
step: 80, loss: 0.24228382110595703
step: 90, loss: 0.17186523973941803
step: 100, loss: 0.35746344923973083
step: 110, loss: 0.22131091356277466
step: 120, loss: 0.35067376494407654
step: 130, loss: 0.17360855638980865
step: 140, loss: 0.20621266961097717
step: 150, loss: 0.12525467574596405
step: 160, loss: 0.21309548616409302
step: 170, loss: 0.11506649851799011
step: 180, loss: 0.31227558851242065
step: 190, loss: 0.14428497850894928
step: 200, loss: 0.15793786942958832
step: 210, loss: 0.15348951518535614
step: 220, loss: 0.05185537785291672
step: 230, loss: 0.03665369376540184
step: 240, loss: 0.19846922159194946
step: 250, loss: 0.0902005210518837
step: 260, loss: 0.14137370884418488
step: 270, loss: 0.2194185107946396
step: 280, loss: 0.14041896164417267
step: 290, loss: 0.0928923487663269
step: 300, loss: 0.19165784120559692
step: 310, loss: 0.1734618991613388
step: 320, loss: 0.07034418731927872
step: 330, loss: 0.08792345225811005
epoch 1: dev_f1=0.6795180722891566, f1=0.6907449209932279, best_f1=0.6907449209932279
step: 0, loss: 0.10061945766210556
step: 10, loss: 0.148584246635437
step: 20, loss: 0.17869801819324493
step: 30, loss: 0.04514226317405701
step: 40, loss: 0.15320274233818054
step: 50, loss: 0.20315606892108917
step: 60, loss: 0.043329980224370956
step: 70, loss: 0.2523402273654938
step: 80, loss: 0.12245313078165054
step: 90, loss: 0.1357017606496811
step: 100, loss: 0.05507582053542137
step: 110, loss: 0.05990016087889671
step: 120, loss: 0.06947210431098938
step: 130, loss: 0.32496464252471924
step: 140, loss: 0.07398756593465805
step: 150, loss: 0.029488511383533478
step: 160, loss: 0.05096585303544998
step: 170, loss: 0.16718655824661255
step: 180, loss: 0.15050314366817474
step: 190, loss: 0.11677797883749008
step: 200, loss: 0.2006535828113556
step: 210, loss: 0.08050044625997543
step: 220, loss: 0.2568916380405426
step: 230, loss: 0.06188962981104851
step: 240, loss: 0.10267417877912521
step: 250, loss: 0.07226505875587463
step: 260, loss: 0.15002413094043732
step: 270, loss: 0.2070910483598709
step: 280, loss: 0.06338975578546524
step: 290, loss: 0.11778176575899124
step: 300, loss: 0.13006342947483063
step: 310, loss: 0.06425000727176666
step: 320, loss: 0.029647311195731163
step: 330, loss: 0.01313667744398117
epoch 2: dev_f1=0.7427293064876958, f1=0.7440860215053762, best_f1=0.7440860215053762
step: 0, loss: 0.06517096608877182
step: 10, loss: 0.09190858900547028
step: 20, loss: 0.21250614523887634
step: 30, loss: 0.06877949088811874
step: 40, loss: 0.04415075108408928
step: 50, loss: 0.0471825897693634
step: 60, loss: 0.09655184298753738
step: 70, loss: 0.09247501939535141
step: 80, loss: 0.060332946479320526
step: 90, loss: 0.028805511072278023
step: 100, loss: 0.16754616796970367
step: 110, loss: 0.21020011603832245
step: 120, loss: 0.1191042885184288
step: 130, loss: 0.15046945214271545
step: 140, loss: 0.12961222231388092
step: 150, loss: 0.05882081389427185
step: 160, loss: 0.10591538995504379
step: 170, loss: 0.07794530689716339
step: 180, loss: 0.13325534760951996
step: 190, loss: 0.06407235562801361
step: 200, loss: 0.12498138099908829
step: 210, loss: 0.13109177350997925
step: 220, loss: 0.07817184180021286
step: 230, loss: 0.11624818295240402
step: 240, loss: 0.04915944114327431
step: 250, loss: 0.10516876727342606
step: 260, loss: 0.05966830626130104
step: 270, loss: 0.17083196341991425
step: 280, loss: 0.08421296626329422
step: 290, loss: 0.17484009265899658
step: 300, loss: 0.10140431672334671
step: 310, loss: 0.07216526567935944
step: 320, loss: 0.12467032670974731
step: 330, loss: 0.038260944187641144
epoch 3: dev_f1=0.7935779816513762, f1=0.799097065462754, best_f1=0.799097065462754
step: 0, loss: 0.17072604596614838
step: 10, loss: 0.038096386939287186
step: 20, loss: 0.04127326235175133
step: 30, loss: 0.14924196898937225
step: 40, loss: 0.15484820306301117
step: 50, loss: 0.18344417214393616
step: 60, loss: 0.09712894260883331
step: 70, loss: 0.1502455621957779
step: 80, loss: 0.09353429079055786
step: 90, loss: 0.07963141053915024
step: 100, loss: 0.08931957185268402
step: 110, loss: 0.05494794249534607
step: 120, loss: 0.10673190653324127
step: 130, loss: 0.18539418280124664
step: 140, loss: 0.00817499402910471
step: 150, loss: 0.02043905109167099
step: 160, loss: 0.08842065185308456
step: 170, loss: 0.15370933711528778
step: 180, loss: 0.08883780241012573
step: 190, loss: 0.10603132098913193
step: 200, loss: 0.05131952092051506
step: 210, loss: 0.07697794586420059
step: 220, loss: 0.037105657160282135
step: 230, loss: 0.04692671447992325
step: 240, loss: 0.055995672941207886
step: 250, loss: 0.13998043537139893
step: 260, loss: 0.09142610430717468
step: 270, loss: 0.1393105685710907
step: 280, loss: 0.13656511902809143
step: 290, loss: 0.13706886768341064
step: 300, loss: 0.048131607472896576
step: 310, loss: 0.0906679779291153
step: 320, loss: 0.06903641670942307
step: 330, loss: 0.18593421578407288
epoch 4: dev_f1=0.8034557235421166, f1=0.7736263736263737, best_f1=0.7736263736263737
step: 0, loss: 0.06526259332895279
step: 10, loss: 0.07143828272819519
step: 20, loss: 0.07495084404945374
step: 30, loss: 0.17676858603954315
step: 40, loss: 0.0815444365143776
step: 50, loss: 0.18926623463630676
step: 60, loss: 0.06456942111253738
step: 70, loss: 0.1044716015458107
step: 80, loss: 0.1474819779396057
step: 90, loss: 0.11440152674913406
step: 100, loss: 0.05249090865254402
step: 110, loss: 0.07753008604049683
step: 120, loss: 0.08783495426177979
step: 130, loss: 0.1589125394821167
step: 140, loss: 0.04624846577644348
step: 150, loss: 0.17520257830619812
step: 160, loss: 0.14329029619693756
step: 170, loss: 0.08889436721801758
step: 180, loss: 0.08470047265291214
step: 190, loss: 0.1281673163175583
step: 200, loss: 0.04376770555973053
step: 210, loss: 0.0006713423645123839
step: 220, loss: 0.10264138877391815
step: 230, loss: 0.1299402266740799
step: 240, loss: 0.10505135357379913
step: 250, loss: 0.08258283883333206
step: 260, loss: 0.09513133764266968
step: 270, loss: 0.09094440937042236
step: 280, loss: 0.04868227243423462
step: 290, loss: 0.1341007798910141
step: 300, loss: 0.13014960289001465
step: 310, loss: 0.08010032027959824
step: 320, loss: 0.13379685580730438
step: 330, loss: 0.16563992202281952
epoch 5: dev_f1=0.7829787234042553, f1=0.7639484978540773, best_f1=0.7736263736263737
step: 0, loss: 0.088535375893116
step: 10, loss: 0.07811012119054794
step: 20, loss: 0.14189694821834564
step: 30, loss: 0.07321319729089737
step: 40, loss: 0.07656419277191162
step: 50, loss: 0.14265461266040802
step: 60, loss: 0.026410570368170738
step: 70, loss: 0.09510654211044312
step: 80, loss: 0.1234782338142395
step: 90, loss: 0.06662268936634064
step: 100, loss: 0.022354265674948692
step: 110, loss: 0.0008389794384129345
step: 120, loss: 0.13167013227939606
step: 130, loss: 0.012182863429188728
step: 140, loss: 0.16525974869728088
step: 150, loss: 0.10784253478050232
step: 160, loss: 0.07080741226673126
step: 170, loss: 0.10246909409761429
step: 180, loss: 0.02325071394443512
step: 190, loss: 0.09119594097137451
step: 200, loss: 0.11641886830329895
step: 210, loss: 0.05731361731886864
step: 220, loss: 0.05242336541414261
step: 230, loss: 0.13253167271614075
step: 240, loss: 0.11213259398937225
step: 250, loss: 0.19304192066192627
step: 260, loss: 0.11656712740659714
step: 270, loss: 0.22038346529006958
step: 280, loss: 0.05672868341207504
step: 290, loss: 0.10807342827320099
step: 300, loss: 0.05701282620429993
step: 310, loss: 0.07047971338033676
step: 320, loss: 0.18151456117630005
step: 330, loss: 0.09939123690128326
epoch 6: dev_f1=0.7765726681127982, f1=0.7705627705627706, best_f1=0.7736263736263737
step: 0, loss: 0.10307194292545319
step: 10, loss: 0.03677232563495636
step: 20, loss: 0.10771212726831436
step: 30, loss: 0.07680810987949371
step: 40, loss: 0.07243413478136063
step: 50, loss: 0.0806846171617508
step: 60, loss: 0.09427310526371002
step: 70, loss: 0.0642281174659729
step: 80, loss: 0.1285383552312851
step: 90, loss: 0.13315095007419586
step: 100, loss: 0.0812486857175827
step: 110, loss: 0.007162841968238354
step: 120, loss: 0.0008064809371717274
step: 130, loss: 0.0652763769030571
step: 140, loss: 0.0672326534986496
step: 150, loss: 0.07284823060035706
step: 160, loss: 0.10899748653173447
step: 170, loss: 0.10982990264892578
step: 180, loss: 0.08044326305389404
step: 190, loss: 0.16702976822853088
step: 200, loss: 0.13815394043922424
step: 210, loss: 0.19441816210746765
step: 220, loss: 0.04958716779947281
step: 230, loss: 0.05322563275694847
step: 240, loss: 0.10942745208740234
step: 250, loss: 0.17224515974521637
step: 260, loss: 0.1573544591665268
step: 270, loss: 0.16750721633434296
step: 280, loss: 0.0603388249874115
step: 290, loss: 0.1729145050048828
step: 300, loss: 0.08387456834316254
step: 310, loss: 0.013418881222605705
step: 320, loss: 0.1122409850358963
step: 330, loss: 0.10390887409448624
epoch 7: dev_f1=0.784, f1=0.7600000000000001, best_f1=0.7736263736263737
step: 0, loss: 0.14363804459571838
step: 10, loss: 0.12986893951892853
step: 20, loss: 0.08753431588411331
step: 30, loss: 0.12783686816692352
step: 40, loss: 0.08135735243558884
step: 50, loss: 0.09377235174179077
step: 60, loss: 0.047837235033512115
step: 70, loss: 0.17371921241283417
step: 80, loss: 0.06465975195169449
step: 90, loss: 0.026040909811854362
step: 100, loss: 0.017581069841980934
step: 110, loss: 0.04101173207163811
step: 120, loss: 0.029544267803430557
step: 130, loss: 0.02693488448858261
step: 140, loss: 0.024899069219827652
step: 150, loss: 0.07989440858364105
step: 160, loss: 0.11562465876340866
step: 170, loss: 0.05288771539926529
step: 180, loss: 0.11140507459640503
step: 190, loss: 0.2278411090373993
step: 200, loss: 0.10371001809835434
step: 210, loss: 0.14287221431732178
step: 220, loss: 0.07866617292165756
step: 230, loss: 0.06537129729986191
step: 240, loss: 0.14737968146800995
step: 250, loss: 0.06389317661523819
step: 260, loss: 0.1493120640516281
step: 270, loss: 0.09660372883081436
step: 280, loss: 0.04191344231367111
step: 290, loss: 0.06700634956359863
step: 300, loss: 0.09329663217067719
step: 310, loss: 0.1347537338733673
step: 320, loss: 0.06498519331216812
step: 330, loss: 0.1374477595090866
epoch 8: dev_f1=0.8058968058968059, f1=0.8009708737864077, best_f1=0.8009708737864077
step: 0, loss: 0.12751644849777222
step: 10, loss: 0.07341460883617401
step: 20, loss: 0.042132891714572906
step: 30, loss: 0.1492306888103485
step: 40, loss: 0.08926654607057571
step: 50, loss: 0.03061790205538273
step: 60, loss: 0.08494912832975388
step: 70, loss: 0.05724077671766281
step: 80, loss: 0.05667658522725105
step: 90, loss: 0.061176151037216187
step: 100, loss: 0.03560186177492142
step: 110, loss: 0.06266825646162033
step: 120, loss: 0.06231526657938957
step: 130, loss: 0.10342568904161453
step: 140, loss: 0.006246999371796846
step: 150, loss: 0.042106375098228455
step: 160, loss: 0.06160884350538254
step: 170, loss: 0.19772817194461823
step: 180, loss: 0.08478378504514694
step: 190, loss: 0.060536958277225494
step: 200, loss: 0.04054662585258484
step: 210, loss: 0.08824478089809418
step: 220, loss: 0.07020442932844162
step: 230, loss: 0.05910669267177582
step: 240, loss: 0.0955413207411766
step: 250, loss: 0.07953859120607376
step: 260, loss: 0.03944801911711693
step: 270, loss: 0.19595983624458313
step: 280, loss: 0.09021098166704178
step: 290, loss: 0.018142173066735268
step: 300, loss: 0.03631870821118355
step: 310, loss: 0.10410283505916595
step: 320, loss: 0.10485230386257172
step: 330, loss: 0.07131259143352509
epoch 9: dev_f1=0.8179551122194514, f1=0.8070175438596492, best_f1=0.8070175438596492
step: 0, loss: 0.08895961940288544
step: 10, loss: 0.12450592964887619
step: 20, loss: 0.1079137772321701
step: 30, loss: 5.0103662943001837e-05
step: 40, loss: 0.010520144365727901
step: 50, loss: 0.06824399530887604
step: 60, loss: 0.05491717532277107
step: 70, loss: 0.07725810259580612
step: 80, loss: 0.07129126042127609
step: 90, loss: 0.11514771729707718
step: 100, loss: 0.19057415425777435
step: 110, loss: 0.07976572215557098
step: 120, loss: 0.06331576406955719
step: 130, loss: 0.057456981390714645
step: 140, loss: 0.14250878989696503
step: 150, loss: 0.05530499666929245
step: 160, loss: 0.047514498233795166
step: 170, loss: 0.028422854840755463
step: 180, loss: 0.058803826570510864
step: 190, loss: 0.06538137793540955
step: 200, loss: 0.004643941763788462
step: 210, loss: 0.15114007890224457
step: 220, loss: 0.09181829541921616
step: 230, loss: 0.057892780750989914
step: 240, loss: 0.015831656754016876
step: 250, loss: 0.20581616461277008
step: 260, loss: 0.07151489704847336
step: 270, loss: 0.02272692508995533
step: 280, loss: 0.06368137896060944
step: 290, loss: 0.11145105212926865
step: 300, loss: 0.08324579149484634
step: 310, loss: 0.12497007846832275
step: 320, loss: 0.021921854466199875
step: 330, loss: 0.11362932622432709
epoch 10: dev_f1=0.8, f1=0.8076923076923078, best_f1=0.8070175438596492
step: 0, loss: 0.1485966295003891
step: 10, loss: 0.1074647381901741
step: 20, loss: 0.08337264508008957
step: 30, loss: 0.09402503073215485
step: 40, loss: 0.02334851399064064
step: 50, loss: 0.06243954598903656
step: 60, loss: 0.06641504913568497
step: 70, loss: 0.12345894426107407
step: 80, loss: 0.08975357562303543
step: 90, loss: 0.12071146816015244
step: 100, loss: 0.12608526647090912
step: 110, loss: 0.12784940004348755
step: 120, loss: 0.09111644327640533
step: 130, loss: 0.07470493763685226
step: 140, loss: 0.07260828465223312
step: 150, loss: 0.03805860877037048
step: 160, loss: 0.06330522149801254
step: 170, loss: 0.061917807906866074
step: 180, loss: 0.039443012326955795
step: 190, loss: 0.11843796074390411
step: 200, loss: 0.04166955128312111
step: 210, loss: 0.08367887884378433
step: 220, loss: 0.11201797425746918
step: 230, loss: 0.08455107361078262
step: 240, loss: 0.03644043207168579
step: 250, loss: 0.23075738549232483
step: 260, loss: 0.024998735636472702
step: 270, loss: 0.24314510822296143
step: 280, loss: 0.05559613183140755
step: 290, loss: 0.05743168294429779
step: 300, loss: 0.06374617666006088
step: 310, loss: 0.06756628304719925
step: 320, loss: 0.09886611253023148
step: 330, loss: 0.04373299330472946
epoch 11: dev_f1=0.8074245939675173, f1=0.8141176470588235, best_f1=0.8070175438596492
step: 0, loss: 0.07782366871833801
step: 10, loss: 0.06888896226882935
step: 20, loss: 0.03124237060546875
step: 30, loss: 0.08361896872520447
step: 40, loss: 0.056091923266649246
step: 50, loss: 0.0006429501809179783
step: 60, loss: 0.03556772693991661
step: 70, loss: 0.1106424331665039
step: 80, loss: 0.09598074853420258
step: 90, loss: 0.10363438725471497
step: 100, loss: 0.044545162469148636
step: 110, loss: 0.11742407083511353
step: 120, loss: 0.08491822332143784
step: 130, loss: 0.14663219451904297
step: 140, loss: 0.1851367950439453
step: 150, loss: 0.03574644401669502
step: 160, loss: 0.05087175592780113
step: 170, loss: 0.060869913548231125
step: 180, loss: 0.05295860394835472
step: 190, loss: 0.06158750504255295
step: 200, loss: 0.11603119224309921
step: 210, loss: 0.11081474274396896
step: 220, loss: 0.06653891503810883
step: 230, loss: 0.1431616246700287
step: 240, loss: 0.07499463111162186
step: 250, loss: 0.026301223784685135
step: 260, loss: 0.07616917043924332
step: 270, loss: 0.04856133460998535
step: 280, loss: 0.06733949482440948
step: 290, loss: 0.035062432289123535
step: 300, loss: 0.1975715607404709
step: 310, loss: 0.04030077904462814
step: 320, loss: 0.07228873670101166
step: 330, loss: 0.15739232301712036
epoch 12: dev_f1=0.8110831234256927, f1=0.7939698492462312, best_f1=0.8070175438596492
step: 0, loss: 0.10647880285978317
step: 10, loss: 0.08688923716545105
step: 20, loss: 0.06906367838382721
step: 30, loss: 0.043469060212373734
step: 40, loss: 0.0656132847070694
step: 50, loss: 0.1307412087917328
step: 60, loss: 0.014782662503421307
step: 70, loss: 0.06648053973913193
step: 80, loss: 0.05793303996324539
step: 90, loss: 0.08559756726026535
step: 100, loss: 0.1557430475950241
step: 110, loss: 0.11466024070978165
step: 120, loss: 0.12225472182035446
step: 130, loss: 0.04466424509882927
step: 140, loss: 0.00018051759980153292
step: 150, loss: 0.06329566985368729
step: 160, loss: 0.06064639613032341
step: 170, loss: 0.10824479907751083
step: 180, loss: 0.07546405494213104
step: 190, loss: 0.16190819442272186
step: 200, loss: 0.09316090494394302
step: 210, loss: 0.0001007944592856802
step: 220, loss: 0.11603043973445892
step: 230, loss: 0.12196598201990128
step: 240, loss: 0.05236285924911499
step: 250, loss: 0.1655064970254898
step: 260, loss: 0.060075752437114716
step: 270, loss: 0.073295958340168
step: 280, loss: 0.08724384754896164
step: 290, loss: 0.027352305129170418
step: 300, loss: 0.11633878201246262
step: 310, loss: 0.13994185626506805
step: 320, loss: 0.11522878706455231
step: 330, loss: 0.12185042351484299
epoch 13: dev_f1=0.8060453400503778, f1=0.798994974874372, best_f1=0.8070175438596492
step: 0, loss: 0.08852486312389374
step: 10, loss: 0.08723192662000656
step: 20, loss: 0.09998376667499542
step: 30, loss: 0.08746398985385895
step: 40, loss: 0.08185967057943344
step: 50, loss: 0.09626107662916183
step: 60, loss: 0.2559221088886261
step: 70, loss: 0.02906646952033043
step: 80, loss: 0.0893772542476654
step: 90, loss: 0.09304674714803696
step: 100, loss: 0.012413841672241688
step: 110, loss: 0.15238073468208313
step: 120, loss: 0.171377494931221
step: 130, loss: 0.08352062106132507
step: 140, loss: 0.09735919535160065
step: 150, loss: 0.13269539177417755
step: 160, loss: 0.044546909630298615
step: 170, loss: 0.14794547855854034
step: 180, loss: 0.05261390283703804
step: 190, loss: 0.07189001888036728
step: 200, loss: 0.07186810672283173
step: 210, loss: 5.984309973428026e-05
step: 220, loss: 0.06642640382051468
step: 230, loss: 0.14724640548229218
step: 240, loss: 0.035580381751060486
step: 250, loss: 0.21255093812942505
step: 260, loss: 0.16249027848243713
step: 270, loss: 0.16691234707832336
step: 280, loss: 0.025342199951410294
step: 290, loss: 0.08018622547388077
step: 300, loss: 0.10051432251930237
step: 310, loss: 0.10840194672346115
step: 320, loss: 0.04923774302005768
step: 330, loss: 0.11509367823600769
epoch 14: dev_f1=0.8117359413202935, f1=0.792079207920792, best_f1=0.8070175438596492
step: 0, loss: 0.036122843623161316
step: 10, loss: 0.050570402294397354
step: 20, loss: 0.0751555785536766
step: 30, loss: 0.0475936233997345
step: 40, loss: 0.0671660527586937
step: 50, loss: 0.04043986648321152
step: 60, loss: 0.01941869594156742
step: 70, loss: 0.07166079431772232
step: 80, loss: 0.07093432545661926
step: 90, loss: 0.03934352844953537
step: 100, loss: 0.07353600114583969
step: 110, loss: 0.018885063007473946
step: 120, loss: 0.1223139539361
step: 130, loss: 0.06115688011050224
step: 140, loss: 0.05016392841935158
step: 150, loss: 0.02738955058157444
step: 160, loss: 0.0722639411687851
step: 170, loss: 0.07360311597585678
step: 180, loss: 0.0002893864584621042
step: 190, loss: 0.08117339760065079
step: 200, loss: 0.1021876186132431
step: 210, loss: 0.19348463416099548
step: 220, loss: 0.03554961457848549
step: 230, loss: 0.10006892681121826
step: 240, loss: 0.042990487068891525
step: 250, loss: 0.09279682487249374
step: 260, loss: 0.06359975785017014
step: 270, loss: 0.08303914219141006
step: 280, loss: 0.05079926550388336
step: 290, loss: 0.12672218680381775
step: 300, loss: 0.05254663899540901
step: 310, loss: 0.1088038757443428
step: 320, loss: 0.08189450204372406
step: 330, loss: 0.10553411394357681
epoch 15: dev_f1=0.7990867579908676, f1=0.8111888111888111, best_f1=0.8070175438596492
step: 0, loss: 0.0894290953874588
step: 10, loss: 0.033524490892887115
step: 20, loss: 0.025779694318771362
step: 30, loss: 0.11289648711681366
step: 40, loss: 0.03585495054721832
step: 50, loss: 0.02498442307114601
step: 60, loss: 0.04927583411335945
step: 70, loss: 0.08195970207452774
step: 80, loss: 0.09188544005155563
step: 90, loss: 0.049429137259721756
step: 100, loss: 0.09935726970434189
step: 110, loss: 0.028303740546107292
step: 120, loss: 0.06991899758577347
step: 130, loss: 0.14066214859485626
step: 140, loss: 0.05153461545705795
step: 150, loss: 0.10761917382478714
step: 160, loss: 0.10130102932453156
step: 170, loss: 0.1381687968969345
step: 180, loss: 0.11204833537340164
step: 190, loss: 6.019322609063238e-05
step: 200, loss: 0.06806687265634537
step: 210, loss: 0.04265254735946655
step: 220, loss: 0.05497858673334122
step: 230, loss: 0.04271828755736351
step: 240, loss: 0.07156585901975632
step: 250, loss: 0.0721919909119606
step: 260, loss: 0.0011639026924967766
step: 270, loss: 0.15857720375061035
step: 280, loss: 0.09694407880306244
step: 290, loss: 0.04728635773062706
step: 300, loss: 0.04907200485467911
step: 310, loss: 0.10011272877454758
step: 320, loss: 0.09853164851665497
step: 330, loss: 0.09178459644317627
epoch 16: dev_f1=0.8096280087527353, f1=0.7955056179775281, best_f1=0.8070175438596492
step: 0, loss: 0.06598113477230072
step: 10, loss: 0.080108642578125
step: 20, loss: 0.04934583976864815
step: 30, loss: 0.06935560703277588
step: 40, loss: 0.05809667333960533
step: 50, loss: 0.14355884492397308
step: 60, loss: 0.120355024933815
step: 70, loss: 0.08022525161504745
step: 80, loss: 0.11396162211894989
step: 90, loss: 0.03403927758336067
step: 100, loss: 0.05977689102292061
step: 110, loss: 0.1490219384431839
step: 120, loss: 0.11854057013988495
step: 130, loss: 0.06031879037618637
step: 140, loss: 0.10944689810276031
step: 150, loss: 0.10521923005580902
step: 160, loss: 0.08620969951152802
step: 170, loss: 0.021930363029241562
step: 180, loss: 0.03546588122844696
step: 190, loss: 0.06925992667675018
step: 200, loss: 0.11188343912363052
step: 210, loss: 0.07634890824556351
step: 220, loss: 0.07802026718854904
step: 230, loss: 0.052647367119789124
step: 240, loss: 3.913800173904747e-05
step: 250, loss: 0.09504779428243637
step: 260, loss: 0.057478636503219604
step: 270, loss: 0.0690586045384407
step: 280, loss: 0.09402909129858017
step: 290, loss: 0.09101073443889618
step: 300, loss: 0.0029719399753957987
step: 310, loss: 0.0634135827422142
step: 320, loss: 0.046201083809137344
step: 330, loss: 0.0699584037065506
epoch 17: dev_f1=0.8162291169451074, f1=0.8087167070217919, best_f1=0.8070175438596492
step: 0, loss: 0.06432747095823288
step: 10, loss: 0.1307866871356964
step: 20, loss: 0.018411332741379738
step: 30, loss: 0.03509247303009033
step: 40, loss: 0.06050560250878334
step: 50, loss: 0.08191263675689697
step: 60, loss: 0.1090560108423233
step: 70, loss: 0.048191796988248825
step: 80, loss: 0.06371863186359406
step: 90, loss: 0.03264837712049484
step: 100, loss: 0.1291961371898651
step: 110, loss: 0.09427657723426819
step: 120, loss: 0.026919610798358917
step: 130, loss: 0.03398169204592705
step: 140, loss: 0.05872732028365135
step: 150, loss: 0.05376436933875084
step: 160, loss: 0.11167844384908676
step: 170, loss: 0.02540966123342514
step: 180, loss: 0.03214792162179947
step: 190, loss: 0.03465135022997856
step: 200, loss: 0.054122522473335266
step: 210, loss: 0.09345239400863647
step: 220, loss: 0.17702630162239075
step: 230, loss: 0.04613185301423073
step: 240, loss: 0.016611486673355103
step: 250, loss: 0.1533431112766266
step: 260, loss: 0.08673276007175446
step: 270, loss: 0.00022391611128114164
step: 280, loss: 0.06686845421791077
step: 290, loss: 0.04423573613166809
step: 300, loss: 0.10598728805780411
step: 310, loss: 0.11878850311040878
step: 320, loss: 0.0612001046538353
step: 330, loss: 0.04352787137031555
epoch 18: dev_f1=0.8095238095238095, f1=0.8, best_f1=0.8070175438596492
step: 0, loss: 0.04051560163497925
step: 10, loss: 0.04336477816104889
step: 20, loss: 0.07519378513097763
step: 30, loss: 0.07238762080669403
step: 40, loss: 0.07672417163848877
step: 50, loss: 0.021306997165083885
step: 60, loss: 0.051152873784303665
step: 70, loss: 0.05672554671764374
step: 80, loss: 0.10925520211458206
step: 90, loss: 0.029811544343829155
step: 100, loss: 0.033848077058792114
step: 110, loss: 0.06036624684929848
step: 120, loss: 4.243383227731101e-05
step: 130, loss: 0.05900833383202553
step: 140, loss: 0.06683377921581268
step: 150, loss: 0.08715268224477768
step: 160, loss: 0.09891946613788605
step: 170, loss: 0.008261126466095448
step: 180, loss: 0.01386164128780365
step: 190, loss: 0.042489439249038696
step: 200, loss: 0.11670945584774017
step: 210, loss: 0.08238295465707779
step: 220, loss: 0.08624617010354996
step: 230, loss: 0.01411740668118
step: 240, loss: 0.07603629678487778
step: 250, loss: 0.11596352607011795
step: 260, loss: 0.002170227700844407
step: 270, loss: 0.12474163621664047
step: 280, loss: 0.08820091187953949
step: 290, loss: 0.09833432734012604
step: 300, loss: 0.04785025492310524
step: 310, loss: 0.05126947537064552
step: 320, loss: 0.12849977612495422
step: 330, loss: 0.11145500838756561
epoch 19: dev_f1=0.8132387706855791, f1=0.8028846153846153, best_f1=0.8070175438596492
step: 0, loss: 0.1332283914089203
step: 10, loss: 0.070297971367836
step: 20, loss: 0.15764905512332916
step: 30, loss: 0.05515895411372185
step: 40, loss: 0.12104742228984833
step: 50, loss: 0.12396709620952606
step: 60, loss: 0.11088378727436066
step: 70, loss: 0.06353921443223953
step: 80, loss: 0.015276501886546612
step: 90, loss: 0.04472251981496811
step: 100, loss: 0.06122633442282677
step: 110, loss: 0.027433577924966812
step: 120, loss: 0.07154227048158646
step: 130, loss: 0.10121883451938629
step: 140, loss: 0.08558890968561172
step: 150, loss: 0.04514297470450401
step: 160, loss: 0.006268860772252083
step: 170, loss: 0.09727250039577484
step: 180, loss: 0.01844639889895916
step: 190, loss: 0.04519836977124214
step: 200, loss: 0.035995371639728546
step: 210, loss: 0.0756516382098198
step: 220, loss: 0.08123461902141571
step: 230, loss: 0.048587653785943985
step: 240, loss: 0.029696010053157806
step: 250, loss: 0.10320812463760376
step: 260, loss: 0.018778178840875626
step: 270, loss: 0.0679347887635231
step: 280, loss: 0.023394908756017685
step: 290, loss: 0.04657657444477081
step: 300, loss: 0.034866735339164734
step: 310, loss: 0.017666228115558624
step: 320, loss: 0.028641236945986748
step: 330, loss: 0.05543667450547218
epoch 20: dev_f1=0.8048192771084338, f1=0.7990314769975787, best_f1=0.8070175438596492
