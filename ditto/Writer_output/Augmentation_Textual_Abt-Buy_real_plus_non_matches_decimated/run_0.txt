cuda
Device: cuda
step: 0, loss: 0.6338095664978027
step: 10, loss: 0.31750884652137756
step: 20, loss: 0.48390817642211914
step: 30, loss: 0.1482745260000229
step: 40, loss: 0.13960333168506622
step: 50, loss: 0.14921851456165314
step: 60, loss: 0.3910028636455536
step: 70, loss: 0.22388093173503876
step: 80, loss: 0.13042011857032776
step: 90, loss: 0.1560141146183014
step: 100, loss: 0.13583506643772125
step: 110, loss: 0.4919632375240326
step: 120, loss: 0.2227979451417923
step: 130, loss: 0.2874997854232788
step: 140, loss: 0.43083709478378296
step: 150, loss: 0.18825098872184753
step: 160, loss: 0.2372259944677353
step: 170, loss: 0.1103348433971405
step: 180, loss: 0.20324380695819855
step: 190, loss: 0.16862787306308746
step: 200, loss: 0.14238061010837555
step: 210, loss: 0.28462472558021545
step: 220, loss: 0.2651072144508362
step: 230, loss: 0.08380614966154099
step: 240, loss: 0.1944461613893509
step: 250, loss: 0.08639180660247803
step: 260, loss: 0.22170740365982056
step: 270, loss: 0.04601483792066574
step: 280, loss: 0.1075936034321785
step: 290, loss: 0.04793800786137581
step: 300, loss: 0.16064786911010742
step: 310, loss: 0.13030540943145752
step: 320, loss: 0.3512597382068634
step: 330, loss: 0.15971149504184723
epoch 1: dev_f1=0.6666666666666666, f1=0.6619385342789599, best_f1=0.6619385342789599
step: 0, loss: 0.0544067919254303
step: 10, loss: 0.06289244443178177
step: 20, loss: 0.07175122946500778
step: 30, loss: 0.25639796257019043
step: 40, loss: 0.07771271467208862
step: 50, loss: 0.1974591165781021
step: 60, loss: 0.22025951743125916
step: 70, loss: 0.12360595166683197
step: 80, loss: 0.13124817609786987
step: 90, loss: 0.19258496165275574
step: 100, loss: 0.15188877284526825
step: 110, loss: 0.20827950537204742
step: 120, loss: 0.09150011092424393
step: 130, loss: 0.04769846051931381
step: 140, loss: 0.1794680804014206
step: 150, loss: 0.0971548855304718
step: 160, loss: 0.09998670220375061
step: 170, loss: 0.016106154769659042
step: 180, loss: 0.009465514682233334
step: 190, loss: 0.08517169952392578
step: 200, loss: 0.11462992429733276
step: 210, loss: 0.059842534363269806
step: 220, loss: 0.2161172777414322
step: 230, loss: 0.2170775830745697
step: 240, loss: 0.1451035439968109
step: 250, loss: 0.11864721775054932
step: 260, loss: 0.06786221265792847
step: 270, loss: 0.06759274750947952
step: 280, loss: 0.16536399722099304
step: 290, loss: 0.21021920442581177
step: 300, loss: 0.21466204524040222
step: 310, loss: 0.23967236280441284
step: 320, loss: 0.020377160981297493
step: 330, loss: 0.11928972601890564
epoch 2: dev_f1=0.7262135922330099, f1=0.7290448343079922, best_f1=0.7290448343079922
step: 0, loss: 0.2036544531583786
step: 10, loss: 0.017150260508060455
step: 20, loss: 0.05708308145403862
step: 30, loss: 0.11976365745067596
step: 40, loss: 0.12735669314861298
step: 50, loss: 0.20584531128406525
step: 60, loss: 0.08545965701341629
step: 70, loss: 0.12032174319028854
step: 80, loss: 0.16317524015903473
step: 90, loss: 0.09869737178087234
step: 100, loss: 0.12873035669326782
step: 110, loss: 0.10799746215343475
step: 120, loss: 0.1269233673810959
step: 130, loss: 0.12309025228023529
step: 140, loss: 0.14054501056671143
step: 150, loss: 0.10623393207788467
step: 160, loss: 0.18498162925243378
step: 170, loss: 0.060325492173433304
step: 180, loss: 0.148862823843956
step: 190, loss: 0.1244981586933136
step: 200, loss: 0.012412210926413536
step: 210, loss: 0.14670132100582123
step: 220, loss: 0.18860717117786407
step: 230, loss: 0.1314374953508377
step: 240, loss: 0.08169735968112946
step: 250, loss: 0.12837561964988708
step: 260, loss: 0.2168808877468109
step: 270, loss: 0.15395759046077728
step: 280, loss: 0.1453949362039566
step: 290, loss: 0.17362713813781738
step: 300, loss: 0.07919973134994507
step: 310, loss: 0.06787990033626556
step: 320, loss: 0.15324534475803375
step: 330, loss: 0.17082829773426056
epoch 3: dev_f1=0.7238095238095237, f1=0.7378190255220417, best_f1=0.7290448343079922
step: 0, loss: 0.1839861124753952
step: 10, loss: 0.11238319426774979
step: 20, loss: 0.01777675189077854
step: 30, loss: 0.2001989483833313
step: 40, loss: 0.0994221493601799
step: 50, loss: 0.11986728012561798
step: 60, loss: 0.0637279525399208
step: 70, loss: 0.16432662308216095
step: 80, loss: 0.17033320665359497
step: 90, loss: 0.18358401954174042
step: 100, loss: 0.024619344621896744
step: 110, loss: 0.16041956841945648
step: 120, loss: 0.07182525098323822
step: 130, loss: 0.10322978347539902
step: 140, loss: 0.11025616526603699
step: 150, loss: 0.09507665783166885
step: 160, loss: 0.11056596785783768
step: 170, loss: 0.11755028367042542
step: 180, loss: 0.15606719255447388
step: 190, loss: 0.102570079267025
step: 200, loss: 0.07978763431310654
step: 210, loss: 0.06234569847583771
step: 220, loss: 0.06838279217481613
step: 230, loss: 0.030109256505966187
step: 240, loss: 0.039405882358551025
step: 250, loss: 0.19448797404766083
step: 260, loss: 0.17500442266464233
step: 270, loss: 0.20308667421340942
step: 280, loss: 0.045895472168922424
step: 290, loss: 0.11298897862434387
step: 300, loss: 0.30318161845207214
step: 310, loss: 0.09376242011785507
step: 320, loss: 0.03438422083854675
step: 330, loss: 0.32693570852279663
epoch 4: dev_f1=0.7969924812030076, f1=0.7745098039215688, best_f1=0.7745098039215688
step: 0, loss: 0.022202763706445694
step: 10, loss: 0.04617984592914581
step: 20, loss: 0.1897936761379242
step: 30, loss: 0.05538788437843323
step: 40, loss: 0.1336093246936798
step: 50, loss: 0.06399327516555786
step: 60, loss: 0.09852404147386551
step: 70, loss: 0.1893773227930069
step: 80, loss: 0.16007903218269348
step: 90, loss: 0.13077248632907867
step: 100, loss: 0.2226594239473343
step: 110, loss: 0.06229449808597565
step: 120, loss: 0.17258737981319427
step: 130, loss: 0.12689277529716492
step: 140, loss: 0.06802442669868469
step: 150, loss: 0.0024905940517783165
step: 160, loss: 0.04739805683493614
step: 170, loss: 0.10580553114414215
step: 180, loss: 0.06076057627797127
step: 190, loss: 0.07588165253400803
step: 200, loss: 0.08973974734544754
step: 210, loss: 0.10315433889627457
step: 220, loss: 0.17978186905384064
step: 230, loss: 0.0571671724319458
step: 240, loss: 0.15886174142360687
step: 250, loss: 0.10021763294935226
step: 260, loss: 0.03810429945588112
step: 270, loss: 0.1250491887331009
step: 280, loss: 0.05557073652744293
step: 290, loss: 0.13842296600341797
step: 300, loss: 0.08869250118732452
step: 310, loss: 0.1061670109629631
step: 320, loss: 0.1353355199098587
step: 330, loss: 0.08550199866294861
epoch 5: dev_f1=0.7926078028747433, f1=0.7630522088353413, best_f1=0.7745098039215688
step: 0, loss: 0.07359997183084488
step: 10, loss: 0.06366313248872757
step: 20, loss: 0.14900317788124084
step: 30, loss: 0.1302795261144638
step: 40, loss: 0.17425619065761566
step: 50, loss: 0.06848865747451782
step: 60, loss: 0.0278201662003994
step: 70, loss: 0.06134703382849693
step: 80, loss: 0.08428448438644409
step: 90, loss: 0.14023883640766144
step: 100, loss: 0.07660064101219177
step: 110, loss: 0.10195894539356232
step: 120, loss: 0.054498329758644104
step: 130, loss: 0.04628205671906471
step: 140, loss: 0.14928121864795685
step: 150, loss: 0.08886903524398804
step: 160, loss: 0.058704350143671036
step: 170, loss: 0.044606227427721024
step: 180, loss: 0.10440623015165329
step: 190, loss: 0.033341605216264725
step: 200, loss: 0.10888470709323883
step: 210, loss: 0.08594557642936707
step: 220, loss: 0.09657768905162811
step: 230, loss: 0.05667744576931
step: 240, loss: 0.019557442516088486
step: 250, loss: 0.11380919814109802
step: 260, loss: 0.12889985740184784
step: 270, loss: 0.039345528930425644
step: 280, loss: 0.0914822593331337
step: 290, loss: 0.11497145891189575
step: 300, loss: 0.07931547611951828
step: 310, loss: 0.08082333207130432
step: 320, loss: 0.11204004287719727
step: 330, loss: 0.03511807695031166
epoch 6: dev_f1=0.8054919908466818, f1=0.7902869757174392, best_f1=0.7902869757174392
step: 0, loss: 0.205121710896492
step: 10, loss: 0.10090190917253494
step: 20, loss: 0.10218721628189087
step: 30, loss: 0.05830598250031471
step: 40, loss: 0.03111370839178562
step: 50, loss: 0.06316520273685455
step: 60, loss: 0.08950460702180862
step: 70, loss: 0.023139525204896927
step: 80, loss: 0.06271099299192429
step: 90, loss: 0.09630999714136124
step: 100, loss: 0.037588026374578476
step: 110, loss: 0.08898475766181946
step: 120, loss: 0.0943281501531601
step: 130, loss: 0.02312532812356949
step: 140, loss: 0.099937804043293
step: 150, loss: 0.11760850995779037
step: 160, loss: 0.07426399737596512
step: 170, loss: 0.07937019318342209
step: 180, loss: 0.19483333826065063
step: 190, loss: 0.03205634281039238
step: 200, loss: 0.05053666979074478
step: 210, loss: 0.0852251723408699
step: 220, loss: 0.09522140771150589
step: 230, loss: 0.15049493312835693
step: 240, loss: 0.06262437999248505
step: 250, loss: 0.09055066108703613
step: 260, loss: 0.1975339949131012
step: 270, loss: 0.05615822225809097
step: 280, loss: 0.04365115985274315
step: 290, loss: 0.06653547286987305
step: 300, loss: 7.65608565416187e-05
step: 310, loss: 0.05436815693974495
step: 320, loss: 0.17788146436214447
step: 330, loss: 0.16694673895835876
epoch 7: dev_f1=0.8144578313253013, f1=0.8038277511961723, best_f1=0.8038277511961723
step: 0, loss: 0.08780477941036224
step: 10, loss: 0.08787311613559723
step: 20, loss: 0.14008454978466034
step: 30, loss: 0.13450796902179718
step: 40, loss: 0.1166391670703888
step: 50, loss: 0.08204656839370728
step: 60, loss: 0.09107059240341187
step: 70, loss: 0.0331127755343914
step: 80, loss: 0.04009855538606644
step: 90, loss: 0.06731472909450531
step: 100, loss: 0.045600775629282
step: 110, loss: 0.09767784178256989
step: 120, loss: 0.09639076143503189
step: 130, loss: 0.03626681864261627
step: 140, loss: 0.039192281663417816
step: 150, loss: 0.06090101972222328
step: 160, loss: 0.17360103130340576
step: 170, loss: 0.11199293285608292
step: 180, loss: 0.010339121334254742
step: 190, loss: 0.0953604057431221
step: 200, loss: 0.09542059898376465
step: 210, loss: 0.10582808405160904
step: 220, loss: 0.1104888916015625
step: 230, loss: 0.16004851460456848
step: 240, loss: 0.07003384828567505
step: 250, loss: 0.1946614533662796
step: 260, loss: 0.10189680755138397
step: 270, loss: 0.058456238359212875
step: 280, loss: 0.14619603753089905
step: 290, loss: 0.030242275446653366
step: 300, loss: 0.07369456440210342
step: 310, loss: 0.1513707935810089
step: 320, loss: 0.12479042261838913
step: 330, loss: 0.12004758417606354
epoch 8: dev_f1=0.8285077951002228, f1=0.8130434782608696, best_f1=0.8130434782608696
step: 0, loss: 0.1337587535381317
step: 10, loss: 0.059278007596731186
step: 20, loss: 0.026738300919532776
step: 30, loss: 0.029954591765999794
step: 40, loss: 0.10553240031003952
step: 50, loss: 0.06643480062484741
step: 60, loss: 0.03510259836912155
step: 70, loss: 0.0960002988576889
step: 80, loss: 0.0687708631157875
step: 90, loss: 0.1145557314157486
step: 100, loss: 0.0556381531059742
step: 110, loss: 0.035910602658987045
step: 120, loss: 0.10790286213159561
step: 130, loss: 0.057145919650793076
step: 140, loss: 0.14126598834991455
step: 150, loss: 0.18618354201316833
step: 160, loss: 0.11508243530988693
step: 170, loss: 0.10770481824874878
step: 180, loss: 0.16881190240383148
step: 190, loss: 0.05412879213690758
step: 200, loss: 0.07354574650526047
step: 210, loss: 0.037835150957107544
step: 220, loss: 0.05432741343975067
step: 230, loss: 0.1723363995552063
step: 240, loss: 0.16818074882030487
step: 250, loss: 0.1251329630613327
step: 260, loss: 0.09813199937343597
step: 270, loss: 0.0723511278629303
step: 280, loss: 0.027656765654683113
step: 290, loss: 0.02570204623043537
step: 300, loss: 0.14924973249435425
step: 310, loss: 0.13202010095119476
step: 320, loss: 0.08668392896652222
step: 330, loss: 0.05869586393237114
epoch 9: dev_f1=0.789838337182448, f1=0.7837837837837838, best_f1=0.8130434782608696
step: 0, loss: 0.1286400854587555
step: 10, loss: 0.07240030169487
step: 20, loss: 0.008633513003587723
step: 30, loss: 0.043126244097948074
step: 40, loss: 0.02957792580127716
step: 50, loss: 0.060067351907491684
step: 60, loss: 0.11556661128997803
step: 70, loss: 0.12965451180934906
step: 80, loss: 0.08011878281831741
step: 90, loss: 0.12751127779483795
step: 100, loss: 0.02545088157057762
step: 110, loss: 0.07593761384487152
step: 120, loss: 0.08405525982379913
step: 130, loss: 0.07160967588424683
step: 140, loss: 0.1079973354935646
step: 150, loss: 0.08444595336914062
step: 160, loss: 0.11980155110359192
step: 170, loss: 0.06553937494754791
step: 180, loss: 0.015220819041132927
step: 190, loss: 0.14229416847229004
step: 200, loss: 0.18972522020339966
step: 210, loss: 0.11273600906133652
step: 220, loss: 0.08807632327079773
step: 230, loss: 0.1496460735797882
step: 240, loss: 0.003943346440792084
step: 250, loss: 0.2835007607936859
step: 260, loss: 0.10680399090051651
step: 270, loss: 0.024202780798077583
step: 280, loss: 0.03817932680249214
step: 290, loss: 0.031099265441298485
step: 300, loss: 0.0793084129691124
step: 310, loss: 0.060789454728364944
step: 320, loss: 0.08107849210500717
step: 330, loss: 0.09039010107517242
epoch 10: dev_f1=0.8146453089244851, f1=0.8202764976958525, best_f1=0.8130434782608696
step: 0, loss: 0.054679036140441895
step: 10, loss: 0.06275837868452072
step: 20, loss: 0.055796049535274506
step: 30, loss: 0.04428066313266754
step: 40, loss: 0.13397514820098877
step: 50, loss: 0.1397884041070938
step: 60, loss: 0.12239138782024384
step: 70, loss: 0.034614406526088715
step: 80, loss: 0.10523252189159393
step: 90, loss: 0.09883887320756912
step: 100, loss: 0.05460621789097786
step: 110, loss: 0.01365566998720169
step: 120, loss: 0.11883999407291412
step: 130, loss: 0.0394936241209507
step: 140, loss: 0.2648659348487854
step: 150, loss: 0.07064733654260635
step: 160, loss: 0.09551364183425903
step: 170, loss: 0.1919081211090088
step: 180, loss: 0.10472172498703003
step: 190, loss: 0.03209855407476425
step: 200, loss: 0.2706630527973175
step: 210, loss: 0.13238880038261414
step: 220, loss: 0.18727809190750122
step: 230, loss: 0.19992992281913757
step: 240, loss: 0.03346044942736626
step: 250, loss: 0.1861092895269394
step: 260, loss: 0.03974110260605812
step: 270, loss: 0.00010697717516450211
step: 280, loss: 0.10399331152439117
step: 290, loss: 0.11934161931276321
step: 300, loss: 0.0694650337100029
step: 310, loss: 0.15985018014907837
step: 320, loss: 0.06659004092216492
step: 330, loss: 0.13818345963954926
epoch 11: dev_f1=0.8264840182648402, f1=0.8251121076233184, best_f1=0.8130434782608696
step: 0, loss: 0.061923280358314514
step: 10, loss: 0.08483945578336716
step: 20, loss: 0.02252901904284954
step: 30, loss: 0.09602659195661545
step: 40, loss: 0.18768344819545746
step: 50, loss: 0.05165997892618179
step: 60, loss: 0.04841293394565582
step: 70, loss: 0.03513162583112717
step: 80, loss: 0.10113642364740372
step: 90, loss: 0.1355283409357071
step: 100, loss: 0.10061123222112656
step: 110, loss: 0.1309102326631546
step: 120, loss: 0.07663784921169281
step: 130, loss: 0.08566967397928238
step: 140, loss: 0.09486091136932373
step: 150, loss: 0.0932704284787178
step: 160, loss: 0.06626501679420471
step: 170, loss: 0.1069459468126297
step: 180, loss: 0.06252183020114899
step: 190, loss: 0.02032499574124813
step: 200, loss: 0.022156713530421257
step: 210, loss: 0.04016751050949097
step: 220, loss: 0.07513502985239029
step: 230, loss: 0.09647772461175919
step: 240, loss: 0.08000991493463516
step: 250, loss: 0.05803006514906883
step: 260, loss: 0.08850890398025513
step: 270, loss: 0.075140081346035
step: 280, loss: 0.17729422450065613
step: 290, loss: 0.04650396481156349
step: 300, loss: 0.09873491525650024
step: 310, loss: 0.03137269243597984
step: 320, loss: 0.0946282148361206
step: 330, loss: 0.025156132876873016
epoch 12: dev_f1=0.8285714285714285, f1=0.8226950354609929, best_f1=0.8226950354609929
step: 0, loss: 0.05017298460006714
step: 10, loss: 0.07937757670879364
step: 20, loss: 0.08774584531784058
step: 30, loss: 0.10417809337377548
step: 40, loss: 0.1056472510099411
step: 50, loss: 0.036296188831329346
step: 60, loss: 0.11933689564466476
step: 70, loss: 0.006176421418786049
step: 80, loss: 0.053333546966314316
step: 90, loss: 0.027308624237775803
step: 100, loss: 0.07353310286998749
step: 110, loss: 0.1032186821103096
step: 120, loss: 0.12262297421693802
step: 130, loss: 0.05889357253909111
step: 140, loss: 0.0815454050898552
step: 150, loss: 0.04821345955133438
step: 160, loss: 0.14290820062160492
step: 170, loss: 0.10581856966018677
step: 180, loss: 0.15585771203041077
step: 190, loss: 0.0801430195569992
step: 200, loss: 0.1461867392063141
step: 210, loss: 0.09046058356761932
step: 220, loss: 0.10220369696617126
step: 230, loss: 0.0724070593714714
step: 240, loss: 0.08848271518945694
step: 250, loss: 0.10595426708459854
step: 260, loss: 0.07860437035560608
step: 270, loss: 0.04131092503666878
step: 280, loss: 0.09823522716760635
step: 290, loss: 0.14179353415966034
step: 300, loss: 0.06188121438026428
step: 310, loss: 0.0001165221183327958
step: 320, loss: 0.03491111844778061
step: 330, loss: 0.11530391126871109
epoch 13: dev_f1=0.8344988344988344, f1=0.8256880733944955, best_f1=0.8256880733944955
step: 0, loss: 0.10473102331161499
step: 10, loss: 0.06580819189548492
step: 20, loss: 0.12317438423633575
step: 30, loss: 0.11403389275074005
step: 40, loss: 0.16589760780334473
step: 50, loss: 0.048538804054260254
step: 60, loss: 0.08463270962238312
step: 70, loss: 0.07145026326179504
step: 80, loss: 0.05655456706881523
step: 90, loss: 0.04524875804781914
step: 100, loss: 0.02924298867583275
step: 110, loss: 0.06141234561800957
step: 120, loss: 0.04538562521338463
step: 130, loss: 0.028087081387639046
step: 140, loss: 0.034560639411211014
step: 150, loss: 0.04215911403298378
step: 160, loss: 0.06949004530906677
step: 170, loss: 0.05952971801161766
step: 180, loss: 0.09434378892183304
step: 190, loss: 0.03721659630537033
step: 200, loss: 0.12990239262580872
step: 210, loss: 0.06137009710073471
step: 220, loss: 0.03977314010262489
step: 230, loss: 0.08807820826768875
step: 240, loss: 0.0733511745929718
step: 250, loss: 0.0369207039475441
step: 260, loss: 0.08479548245668411
step: 270, loss: 0.08685939759016037
step: 280, loss: 0.08515103906393051
step: 290, loss: 0.006734143942594528
step: 300, loss: 0.06471378356218338
step: 310, loss: 0.1478201150894165
step: 320, loss: 0.06177378445863724
step: 330, loss: 0.08394476771354675
epoch 14: dev_f1=0.8089330024813897, f1=0.803921568627451, best_f1=0.8256880733944955
step: 0, loss: 0.2017895132303238
step: 10, loss: 0.0658864751458168
step: 20, loss: 0.07112379372119904
step: 30, loss: 0.037207867950201035
step: 40, loss: 0.048006970435380936
step: 50, loss: 0.18978095054626465
step: 60, loss: 0.1785881221294403
step: 70, loss: 0.09433425962924957
step: 80, loss: 0.08255412429571152
step: 90, loss: 0.10077184438705444
step: 100, loss: 0.15162482857704163
step: 110, loss: 0.031139476224780083
step: 120, loss: 0.15036793053150177
step: 130, loss: 0.05332545191049576
step: 140, loss: 0.0864279642701149
step: 150, loss: 0.010954120196402073
step: 160, loss: 0.07331942021846771
step: 170, loss: 0.19120052456855774
step: 180, loss: 0.05954893305897713
step: 190, loss: 0.1202159896492958
step: 200, loss: 0.05170479416847229
step: 210, loss: 0.055130183696746826
step: 220, loss: 0.024524714797735214
step: 230, loss: 0.14803817868232727
step: 240, loss: 0.15545672178268433
step: 250, loss: 0.12313512712717056
step: 260, loss: 0.10280263423919678
step: 270, loss: 0.02459576725959778
step: 280, loss: 0.060611698776483536
step: 290, loss: 0.09565465152263641
step: 300, loss: 0.025356652215123177
step: 310, loss: 0.09009478241205215
step: 320, loss: 0.030195362865924835
step: 330, loss: 0.07592236250638962
epoch 15: dev_f1=0.826923076923077, f1=0.8349056603773586, best_f1=0.8256880733944955
step: 0, loss: 0.07788631319999695
step: 10, loss: 0.017889367416501045
step: 20, loss: 0.0862816572189331
step: 30, loss: 0.13329248130321503
step: 40, loss: 0.11331973224878311
step: 50, loss: 0.13033810257911682
step: 60, loss: 0.055436164140701294
step: 70, loss: 0.04077775031328201
step: 80, loss: 0.04740814119577408
step: 90, loss: 0.040223900228738785
step: 100, loss: 0.039118554443120956
step: 110, loss: 0.1041315495967865
step: 120, loss: 0.09810298681259155
step: 130, loss: 0.08550246059894562
step: 140, loss: 0.03834034875035286
step: 150, loss: 0.13616447150707245
step: 160, loss: 0.029580911621451378
step: 170, loss: 0.06817498058080673
step: 180, loss: 0.07254301756620407
step: 190, loss: 0.09031078219413757
step: 200, loss: 0.001953453291207552
step: 210, loss: 0.0693870484828949
step: 220, loss: 0.09236845374107361
step: 230, loss: 0.051941417157649994
step: 240, loss: 0.08305992186069489
step: 250, loss: 0.10062041878700256
step: 260, loss: 0.039565760642290115
step: 270, loss: 0.05695047974586487
step: 280, loss: 0.027191225439310074
step: 290, loss: 0.07759562879800797
step: 300, loss: 0.11943209916353226
step: 310, loss: 0.0600489005446434
step: 320, loss: 0.1602184772491455
step: 330, loss: 0.1257094293832779
epoch 16: dev_f1=0.8163265306122449, f1=0.8214285714285715, best_f1=0.8256880733944955
step: 0, loss: 0.1272583305835724
step: 10, loss: 0.07021139562129974
step: 20, loss: 0.04311484470963478
step: 30, loss: 0.03627341613173485
step: 40, loss: 0.06865015625953674
step: 50, loss: 0.05953028425574303
step: 60, loss: 0.028828214854002
step: 70, loss: 0.040602438151836395
step: 80, loss: 0.08134903013706207
step: 90, loss: 0.11454235762357712
step: 100, loss: 0.07357687503099442
step: 110, loss: 0.1549820899963379
step: 120, loss: 0.022685717791318893
step: 130, loss: 0.04635906219482422
step: 140, loss: 0.11362011730670929
step: 150, loss: 0.026995224878191948
step: 160, loss: 0.03235485032200813
step: 170, loss: 0.09503936767578125
step: 180, loss: 0.07232756167650223
step: 190, loss: 0.09696730226278305
step: 200, loss: 0.027846356853842735
step: 210, loss: 0.09473863989114761
step: 220, loss: 0.18544812500476837
step: 230, loss: 0.06998039036989212
step: 240, loss: 0.03499014675617218
step: 250, loss: 0.06218453869223595
step: 260, loss: 0.14655469357967377
step: 270, loss: 0.05480173975229263
step: 280, loss: 0.059670209884643555
step: 290, loss: 0.05719979852437973
step: 300, loss: 0.053824663162231445
step: 310, loss: 0.09869212657213211
step: 320, loss: 0.06169556453824043
step: 330, loss: 0.04602711275219917
epoch 17: dev_f1=0.8229665071770335, f1=0.8262910798122066, best_f1=0.8256880733944955
step: 0, loss: 0.07382678240537643
step: 10, loss: 0.02342335321009159
step: 20, loss: 0.10996890068054199
step: 30, loss: 0.06294913589954376
step: 40, loss: 0.012575608678162098
step: 50, loss: 0.03646192327141762
step: 60, loss: 0.08796299248933792
step: 70, loss: 0.07442556321620941
step: 80, loss: 0.05461614206433296
step: 90, loss: 0.07373394072055817
step: 100, loss: 0.138553649187088
step: 110, loss: 0.11290297657251358
step: 120, loss: 0.07718927413225174
step: 130, loss: 0.07568801939487457
step: 140, loss: 0.06545228511095047
step: 150, loss: 0.12025725096464157
step: 160, loss: 0.07412665337324142
step: 170, loss: 0.05131004750728607
step: 180, loss: 0.06999431550502777
step: 190, loss: 0.03582103177905083
step: 200, loss: 0.18510855734348297
step: 210, loss: 0.027638383209705353
step: 220, loss: 0.016866609454154968
step: 230, loss: 0.08771418780088425
step: 240, loss: 0.012853965163230896
step: 250, loss: 0.07009713351726532
step: 260, loss: 0.03233710303902626
step: 270, loss: 0.05027380213141441
step: 280, loss: 0.1550857126712799
step: 290, loss: 0.032809995114803314
step: 300, loss: 0.023322677239775658
step: 310, loss: 0.06964899599552155
step: 320, loss: 0.028285397216677666
step: 330, loss: 0.11803285032510757
epoch 18: dev_f1=0.8199052132701422, f1=0.8158508158508158, best_f1=0.8256880733944955
step: 0, loss: 0.05983712151646614
step: 10, loss: 0.10564615577459335
step: 20, loss: 0.18333783745765686
step: 30, loss: 0.009265867993235588
step: 40, loss: 0.14232943952083588
step: 50, loss: 0.038162313401699066
step: 60, loss: 0.10376455634832382
step: 70, loss: 0.083633653819561
step: 80, loss: 0.07628460973501205
step: 90, loss: 0.04783668369054794
step: 100, loss: 0.055585846304893494
step: 110, loss: 0.11077233403921127
step: 120, loss: 0.10257429629564285
step: 130, loss: 0.14742803573608398
step: 140, loss: 0.06019126996397972
step: 150, loss: 0.09548401087522507
step: 160, loss: 0.03709888830780983
step: 170, loss: 0.0013075232272967696
step: 180, loss: 0.03487411513924599
step: 190, loss: 0.09788821637630463
step: 200, loss: 0.12847717106342316
step: 210, loss: 0.008472200483083725
step: 220, loss: 0.06479594856500626
step: 230, loss: 0.09624265879392624
step: 240, loss: 0.07330262660980225
step: 250, loss: 0.1267463117837906
step: 260, loss: 0.08350028097629547
step: 270, loss: 0.03537015616893768
step: 280, loss: 0.07589168846607208
step: 290, loss: 0.03543072193861008
step: 300, loss: 0.06886705011129379
step: 310, loss: 0.12186447530984879
step: 320, loss: 0.08521724492311478
step: 330, loss: 0.07115361094474792
epoch 19: dev_f1=0.8047058823529412, f1=0.8091954022988505, best_f1=0.8256880733944955
step: 0, loss: 0.15725429356098175
step: 10, loss: 0.05514691025018692
step: 20, loss: 0.07421525567770004
step: 30, loss: 0.11238475888967514
step: 40, loss: 0.06866220384836197
step: 50, loss: 0.07133137434720993
step: 60, loss: 0.19620737433433533
step: 70, loss: 0.13850827515125275
step: 80, loss: 0.023839853703975677
step: 90, loss: 0.0615047886967659
step: 100, loss: 0.06035103648900986
step: 110, loss: 0.028577201068401337
step: 120, loss: 0.050399526953697205
step: 130, loss: 0.017005544155836105
step: 140, loss: 0.06074952334165573
step: 150, loss: 0.024370810016989708
step: 160, loss: 0.12159478664398193
step: 170, loss: 0.029252661392092705
step: 180, loss: 0.03447413444519043
step: 190, loss: 0.08136658370494843
step: 200, loss: 0.111025869846344
step: 210, loss: 0.16652536392211914
step: 220, loss: 0.12390385568141937
step: 230, loss: 0.053423766046762466
step: 240, loss: 0.030225971713662148
step: 250, loss: 0.01816852204501629
step: 260, loss: 0.05316570773720741
step: 270, loss: 0.0558580607175827
step: 280, loss: 0.14203418791294098
step: 290, loss: 0.015553060919046402
step: 300, loss: 0.11737294495105743
step: 310, loss: 0.1006886437535286
step: 320, loss: 0.04115317761898041
step: 330, loss: 0.07958944886922836
epoch 20: dev_f1=0.794188861985472, f1=0.8162291169451074, best_f1=0.8256880733944955
