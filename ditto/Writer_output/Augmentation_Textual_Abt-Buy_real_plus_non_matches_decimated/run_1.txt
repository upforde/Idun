cuda
Device: cuda
step: 0, loss: 0.6237910389900208
step: 10, loss: 0.44138142466545105
step: 20, loss: 0.3426471948623657
step: 30, loss: 0.21294572949409485
step: 40, loss: 0.21946987509727478
step: 50, loss: 0.38686931133270264
step: 60, loss: 0.43894556164741516
step: 70, loss: 0.31296393275260925
step: 80, loss: 0.4077061414718628
step: 90, loss: 0.333464115858078
step: 100, loss: 0.23711521923542023
step: 110, loss: 0.1299588978290558
step: 120, loss: 0.13191944360733032
step: 130, loss: 0.23291632533073425
step: 140, loss: 0.22124584019184113
step: 150, loss: 0.11203979700803757
step: 160, loss: 0.3091927766799927
step: 170, loss: 0.17073018848896027
step: 180, loss: 0.2755981385707855
step: 190, loss: 0.16707666218280792
step: 200, loss: 0.2995409667491913
step: 210, loss: 0.2233273983001709
step: 220, loss: 0.02795150689780712
step: 230, loss: 0.2131389081478119
step: 240, loss: 0.12416602671146393
step: 250, loss: 0.022621961310505867
step: 260, loss: 0.19176383316516876
step: 270, loss: 0.05174114555120468
step: 280, loss: 0.15016035735607147
step: 290, loss: 0.09461143612861633
step: 300, loss: 0.029590226709842682
step: 310, loss: 0.08736244589090347
step: 320, loss: 0.1502738893032074
step: 330, loss: 0.06155755743384361
epoch 1: dev_f1=0.7090464547677261, f1=0.7441860465116279, best_f1=0.7441860465116279
step: 0, loss: 0.08054877072572708
step: 10, loss: 0.24952059984207153
step: 20, loss: 0.20666198432445526
step: 30, loss: 0.01527167297899723
step: 40, loss: 0.1956220120191574
step: 50, loss: 0.10424759238958359
step: 60, loss: 0.2295311838388443
step: 70, loss: 0.10493464022874832
step: 80, loss: 0.08581388741731644
step: 90, loss: 0.17127929627895355
step: 100, loss: 0.05073198303580284
step: 110, loss: 0.1337016373872757
step: 120, loss: 0.06164339929819107
step: 130, loss: 0.13469411432743073
step: 140, loss: 0.07085765153169632
step: 150, loss: 0.08354685455560684
step: 160, loss: 0.17523016035556793
step: 170, loss: 0.12139538675546646
step: 180, loss: 0.12438304722309113
step: 190, loss: 0.12231913954019547
step: 200, loss: 0.0938728004693985
step: 210, loss: 0.19570142030715942
step: 220, loss: 0.13933953642845154
step: 230, loss: 0.008169208653271198
step: 240, loss: 0.0820903331041336
step: 250, loss: 0.065529465675354
step: 260, loss: 0.1095297634601593
step: 270, loss: 0.14545542001724243
step: 280, loss: 0.1891128271818161
step: 290, loss: 0.05196206271648407
step: 300, loss: 0.19441398978233337
step: 310, loss: 0.1550327092409134
step: 320, loss: 0.12944167852401733
step: 330, loss: 0.1272960752248764
epoch 2: dev_f1=0.7604395604395604, f1=0.732758620689655, best_f1=0.732758620689655
step: 0, loss: 0.1787005215883255
step: 10, loss: 0.0448572114109993
step: 20, loss: 0.10489596426486969
step: 30, loss: 0.099363312125206
step: 40, loss: 0.05456874892115593
step: 50, loss: 0.10400958359241486
step: 60, loss: 0.20444723963737488
step: 70, loss: 0.1050134003162384
step: 80, loss: 0.05150850489735603
step: 90, loss: 0.011124405078589916
step: 100, loss: 0.11247751861810684
step: 110, loss: 0.15934301912784576
step: 120, loss: 0.14097201824188232
step: 130, loss: 0.12030728161334991
step: 140, loss: 0.14520587027072906
step: 150, loss: 0.05935852229595184
step: 160, loss: 0.10553981363773346
step: 170, loss: 0.09310397505760193
step: 180, loss: 0.056875646114349365
step: 190, loss: 0.08891989290714264
step: 200, loss: 0.19779372215270996
step: 210, loss: 0.09712766110897064
step: 220, loss: 0.11776119470596313
step: 230, loss: 0.13110099732875824
step: 240, loss: 0.12770920991897583
step: 250, loss: 0.09087903797626495
step: 260, loss: 0.1204000860452652
step: 270, loss: 0.11707990616559982
step: 280, loss: 0.10146081447601318
step: 290, loss: 0.1306508183479309
step: 300, loss: 0.06445322185754776
step: 310, loss: 0.12774449586868286
step: 320, loss: 0.049244120717048645
step: 330, loss: 0.08522176742553711
epoch 3: dev_f1=0.776470588235294, f1=0.7775280898876404, best_f1=0.7775280898876404
step: 0, loss: 0.08853273838758469
step: 10, loss: 0.05873465538024902
step: 20, loss: 0.10821333527565002
step: 30, loss: 0.08059971034526825
step: 40, loss: 0.1272536963224411
step: 50, loss: 0.09727922081947327
step: 60, loss: 0.07313332706689835
step: 70, loss: 0.04385673254728317
step: 80, loss: 0.06882694363594055
step: 90, loss: 0.09822432696819305
step: 100, loss: 0.18657207489013672
step: 110, loss: 0.10305450856685638
step: 120, loss: 0.07043109834194183
step: 130, loss: 0.09908092021942139
step: 140, loss: 0.11690838634967804
step: 150, loss: 0.08177922666072845
step: 160, loss: 0.061345167458057404
step: 170, loss: 0.007617991883307695
step: 180, loss: 0.06463568657636642
step: 190, loss: 0.16106835007667542
step: 200, loss: 0.1363067775964737
step: 210, loss: 0.10605800151824951
step: 220, loss: 0.07659925520420074
step: 230, loss: 0.15851661562919617
step: 240, loss: 0.07852470129728317
step: 250, loss: 0.07972164452075958
step: 260, loss: 0.09153998643159866
step: 270, loss: 0.15097960829734802
step: 280, loss: 0.19224967062473297
step: 290, loss: 0.13269267976284027
step: 300, loss: 0.11086827516555786
step: 310, loss: 0.18066492676734924
step: 320, loss: 0.09762393683195114
step: 330, loss: 0.07990194112062454
epoch 4: dev_f1=0.8026607538802661, f1=0.787878787878788, best_f1=0.787878787878788
step: 0, loss: 0.12242405861616135
step: 10, loss: 0.1413489133119583
step: 20, loss: 0.06854161620140076
step: 30, loss: 0.04067658260464668
step: 40, loss: 0.14710721373558044
step: 50, loss: 0.09965815395116806
step: 60, loss: 0.12935400009155273
step: 70, loss: 0.023099035024642944
step: 80, loss: 0.04200327396392822
step: 90, loss: 0.055664002895355225
step: 100, loss: 0.0790439173579216
step: 110, loss: 0.04451391473412514
step: 120, loss: 0.11142236739397049
step: 130, loss: 0.12789428234100342
step: 140, loss: 0.14041048288345337
step: 150, loss: 0.1654265969991684
step: 160, loss: 0.0602041520178318
step: 170, loss: 0.07486779987812042
step: 180, loss: 0.026675697416067123
step: 190, loss: 0.09300310909748077
step: 200, loss: 0.051702842116355896
step: 210, loss: 0.11246423423290253
step: 220, loss: 0.12197740375995636
step: 230, loss: 0.019103609025478363
step: 240, loss: 0.0435832180082798
step: 250, loss: 0.14988183975219727
step: 260, loss: 0.1957327276468277
step: 270, loss: 0.023745296522974968
step: 280, loss: 0.06806304305791855
step: 290, loss: 0.1654476523399353
step: 300, loss: 0.06878192722797394
step: 310, loss: 0.07438074052333832
step: 320, loss: 0.10749632865190506
step: 330, loss: 0.10584811121225357
epoch 5: dev_f1=0.834862385321101, f1=0.7844036697247706, best_f1=0.7844036697247706
step: 0, loss: 0.12414859980344772
step: 10, loss: 0.17048554122447968
step: 20, loss: 0.1449432373046875
step: 30, loss: 0.09690931439399719
step: 40, loss: 0.1578720062971115
step: 50, loss: 0.053549669682979584
step: 60, loss: 0.02760366164147854
step: 70, loss: 0.19900423288345337
step: 80, loss: 0.06731091439723969
step: 90, loss: 0.13348211348056793
step: 100, loss: 0.07353885471820831
step: 110, loss: 0.05513826385140419
step: 120, loss: 0.13339844346046448
step: 130, loss: 0.10118311643600464
step: 140, loss: 0.046462688595056534
step: 150, loss: 0.15574286878108978
step: 160, loss: 0.1021442860364914
step: 170, loss: 0.10193056613206863
step: 180, loss: 0.10940820723772049
step: 190, loss: 0.04802994057536125
step: 200, loss: 0.2590932250022888
step: 210, loss: 0.07418859750032425
step: 220, loss: 0.0739118754863739
step: 230, loss: 0.0004849235119763762
step: 240, loss: 0.09159644693136215
step: 250, loss: 0.05885748192667961
step: 260, loss: 0.06550775468349457
step: 270, loss: 0.07293602079153061
step: 280, loss: 0.15486517548561096
step: 290, loss: 0.08030421286821365
step: 300, loss: 0.1544254571199417
step: 310, loss: 0.08483435213565826
step: 320, loss: 0.02735789306461811
step: 330, loss: 0.3589618504047394
epoch 6: dev_f1=0.8226950354609929, f1=0.8036951501154735, best_f1=0.7844036697247706
step: 0, loss: 0.17315779626369476
step: 10, loss: 0.15256120264530182
step: 20, loss: 0.1890348196029663
step: 30, loss: 0.07010117173194885
step: 40, loss: 0.08479292690753937
step: 50, loss: 0.09496061503887177
step: 60, loss: 0.07684769481420517
step: 70, loss: 0.08244413137435913
step: 80, loss: 0.1282152533531189
step: 90, loss: 0.07009442150592804
step: 100, loss: 0.2150496542453766
step: 110, loss: 0.125847727060318
step: 120, loss: 0.1306723803281784
step: 130, loss: 0.0812809020280838
step: 140, loss: 0.06321398168802261
step: 150, loss: 0.052624985575675964
step: 160, loss: 0.057304497808218
step: 170, loss: 0.015647754073143005
step: 180, loss: 0.02544422820210457
step: 190, loss: 0.061671677976846695
step: 200, loss: 0.07621069997549057
step: 210, loss: 0.07403029501438141
step: 220, loss: 0.07218021899461746
step: 230, loss: 0.13892647624015808
step: 240, loss: 0.10594206303358078
step: 250, loss: 0.07708954811096191
step: 260, loss: 0.10666163265705109
step: 270, loss: 0.1174422949552536
step: 280, loss: 0.06651037931442261
step: 290, loss: 0.07060167193412781
step: 300, loss: 0.08567606657743454
step: 310, loss: 0.12518899142742157
step: 320, loss: 0.15493813157081604
step: 330, loss: 0.10903674364089966
epoch 7: dev_f1=0.8115942028985508, f1=0.7884615384615384, best_f1=0.7844036697247706
step: 0, loss: 0.038223445415496826
step: 10, loss: 0.14750124514102936
step: 20, loss: 0.06788130104541779
step: 30, loss: 0.0412980318069458
step: 40, loss: 0.1213047206401825
step: 50, loss: 0.06628233194351196
step: 60, loss: 0.07210737466812134
step: 70, loss: 0.0979170948266983
step: 80, loss: 0.17463409900665283
step: 90, loss: 0.11614333838224411
step: 100, loss: 0.20117488503456116
step: 110, loss: 0.05845051631331444
step: 120, loss: 0.08587416261434555
step: 130, loss: 0.07404615730047226
step: 140, loss: 0.03560055047273636
step: 150, loss: 0.15276360511779785
step: 160, loss: 0.13360345363616943
step: 170, loss: 0.1299566775560379
step: 180, loss: 0.1277742236852646
step: 190, loss: 0.16131427884101868
step: 200, loss: 0.005890425760298967
step: 210, loss: 0.10564835369586945
step: 220, loss: 0.031777072697877884
step: 230, loss: 0.05165160447359085
step: 240, loss: 0.155710831284523
step: 250, loss: 0.11846708506345749
step: 260, loss: 0.15696801245212555
step: 270, loss: 0.0897989496588707
step: 280, loss: 0.08826674520969391
step: 290, loss: 0.17106100916862488
step: 300, loss: 0.10232747346162796
step: 310, loss: 0.05692504346370697
step: 320, loss: 0.07644300162792206
step: 330, loss: 0.15017090737819672
epoch 8: dev_f1=0.8203991130820399, f1=0.8043010752688172, best_f1=0.7844036697247706
step: 0, loss: 0.09287948161363602
step: 10, loss: 0.09702032059431076
step: 20, loss: 0.07689414918422699
step: 30, loss: 0.12373081594705582
step: 40, loss: 0.0035754924174398184
step: 50, loss: 0.00982418842613697
step: 60, loss: 0.07262419164180756
step: 70, loss: 0.05558280274271965
step: 80, loss: 0.07252225279808044
step: 90, loss: 0.10098764300346375
step: 100, loss: 0.12817037105560303
step: 110, loss: 0.05879024788737297
step: 120, loss: 0.12300252169370651
step: 130, loss: 0.08057866990566254
step: 140, loss: 0.11043450981378555
step: 150, loss: 0.04236525297164917
step: 160, loss: 0.03416150063276291
step: 170, loss: 0.05894479155540466
step: 180, loss: 0.07037840038537979
step: 190, loss: 0.12978099286556244
step: 200, loss: 0.06368716806173325
step: 210, loss: 0.08867309987545013
step: 220, loss: 0.1204073503613472
step: 230, loss: 0.09831870347261429
step: 240, loss: 0.15996834635734558
step: 250, loss: 0.0972588062286377
step: 260, loss: 0.10206127166748047
step: 270, loss: 0.1484740972518921
step: 280, loss: 0.12535086274147034
step: 290, loss: 0.061721377074718475
step: 300, loss: 0.10288001596927643
step: 310, loss: 0.12335655838251114
step: 320, loss: 0.033320099115371704
step: 330, loss: 0.0864623636007309
epoch 9: dev_f1=0.8130841121495326, f1=0.8119266055045871, best_f1=0.7844036697247706
step: 0, loss: 0.056483808904886246
step: 10, loss: 0.173995703458786
step: 20, loss: 0.03884976729750633
step: 30, loss: 0.12279336899518967
step: 40, loss: 0.038898032158613205
step: 50, loss: 0.042656902223825455
step: 60, loss: 0.03348812460899353
step: 70, loss: 0.07001817971467972
step: 80, loss: 0.13627120852470398
step: 90, loss: 0.07118883728981018
step: 100, loss: 0.11381945759057999
step: 110, loss: 0.15822388231754303
step: 120, loss: 0.09474294632673264
step: 130, loss: 0.03423970192670822
step: 140, loss: 0.10990548878908157
step: 150, loss: 0.11908014863729477
step: 160, loss: 0.14226101338863373
step: 170, loss: 0.08559292554855347
step: 180, loss: 0.06210944429039955
step: 190, loss: 0.11906617879867554
step: 200, loss: 0.023744136095046997
step: 210, loss: 0.07910874485969543
step: 220, loss: 0.13428349792957306
step: 230, loss: 0.03824832662940025
step: 240, loss: 0.1025671735405922
step: 250, loss: 0.05883791297674179
step: 260, loss: 0.06195281073451042
step: 270, loss: 0.15019357204437256
step: 280, loss: 0.09936857968568802
step: 290, loss: 0.18014757335186005
step: 300, loss: 0.13181784749031067
step: 310, loss: 0.11656138300895691
step: 320, loss: 0.15452568233013153
step: 330, loss: 0.05787736177444458
epoch 10: dev_f1=0.8106904231625837, f1=0.7799564270152506, best_f1=0.7844036697247706
step: 0, loss: 0.11670807003974915
step: 10, loss: 0.0664396658539772
step: 20, loss: 0.1283339262008667
step: 30, loss: 0.07267433404922485
step: 40, loss: 0.05598554387688637
step: 50, loss: 0.08630842715501785
step: 60, loss: 0.0715840607881546
step: 70, loss: 0.11672183871269226
step: 80, loss: 0.15348488092422485
step: 90, loss: 0.02030952461063862
step: 100, loss: 0.005505564622581005
step: 110, loss: 0.10098131000995636
step: 120, loss: 0.292798787355423
step: 130, loss: 0.09952162951231003
step: 140, loss: 0.026027394458651543
step: 150, loss: 0.0705685019493103
step: 160, loss: 0.1129416674375534
step: 170, loss: 0.07036474347114563
step: 180, loss: 0.05400469899177551
step: 190, loss: 0.09248965233564377
step: 200, loss: 0.06015035882592201
step: 210, loss: 0.07670903950929642
step: 220, loss: 0.03171488270163536
step: 230, loss: 0.045918289572000504
step: 240, loss: 0.13412709534168243
step: 250, loss: 0.07104930281639099
step: 260, loss: 0.07763313502073288
step: 270, loss: 0.10482525080442429
step: 280, loss: 0.08024568110704422
step: 290, loss: 0.059615977108478546
step: 300, loss: 0.059173911809921265
step: 310, loss: 0.028645548969507217
step: 320, loss: 0.12384885549545288
step: 330, loss: 0.12753134965896606
epoch 11: dev_f1=0.8211009174311925, f1=0.8044943820224719, best_f1=0.7844036697247706
step: 0, loss: 0.11922949552536011
step: 10, loss: 0.12222927808761597
step: 20, loss: 0.041364636272192
step: 30, loss: 0.11941991001367569
step: 40, loss: 0.08040507137775421
step: 50, loss: 0.08096465468406677
step: 60, loss: 0.07801216840744019
step: 70, loss: 0.09359396249055862
step: 80, loss: 0.05349619314074516
step: 90, loss: 0.007172544952481985
step: 100, loss: 0.01618189923465252
step: 110, loss: 0.014184634201228619
step: 120, loss: 0.06065164506435394
step: 130, loss: 0.16389571130275726
step: 140, loss: 0.08297622948884964
step: 150, loss: 0.09581344574689865
step: 160, loss: 0.2607828378677368
step: 170, loss: 0.12145961821079254
step: 180, loss: 0.18232059478759766
step: 190, loss: 0.14149639010429382
step: 200, loss: 0.1196131706237793
step: 210, loss: 0.2064865082502365
step: 220, loss: 0.0674310028553009
step: 230, loss: 0.10153742134571075
step: 240, loss: 0.1458093672990799
step: 250, loss: 0.12127705663442612
step: 260, loss: 0.02985045686364174
step: 270, loss: 0.08369214832782745
step: 280, loss: 0.03257826715707779
step: 290, loss: 0.1364603489637375
step: 300, loss: 0.041284915059804916
step: 310, loss: 0.04127614200115204
step: 320, loss: 0.1204257681965828
step: 330, loss: 0.1306055635213852
epoch 12: dev_f1=0.8120649651972157, f1=0.8251121076233184, best_f1=0.7844036697247706
step: 0, loss: 0.10161386430263519
step: 10, loss: 0.05576682835817337
step: 20, loss: 0.14869749546051025
step: 30, loss: 0.1200781911611557
step: 40, loss: 0.08571535348892212
step: 50, loss: 0.11355018615722656
step: 60, loss: 0.10183339565992355
step: 70, loss: 0.13965797424316406
step: 80, loss: 0.13846495747566223
step: 90, loss: 0.10049507021903992
step: 100, loss: 0.07165797054767609
step: 110, loss: 0.08839043229818344
step: 120, loss: 0.04820449277758598
step: 130, loss: 0.05650206655263901
step: 140, loss: 0.08333636820316315
step: 150, loss: 0.09550359100103378
step: 160, loss: 0.04770695045590401
step: 170, loss: 0.024029284715652466
step: 180, loss: 0.052713438868522644
step: 190, loss: 0.03165731579065323
step: 200, loss: 0.10472802817821503
step: 210, loss: 0.07271205633878708
step: 220, loss: 0.12351826578378677
step: 230, loss: 0.09048151969909668
step: 240, loss: 0.06979691237211227
step: 250, loss: 0.14469468593597412
step: 260, loss: 0.102657750248909
step: 270, loss: 0.12349210679531097
step: 280, loss: 0.11987151205539703
step: 290, loss: 0.09871968626976013
step: 300, loss: 0.07211630046367645
step: 310, loss: 0.19242526590824127
step: 320, loss: 0.05338319391012192
step: 330, loss: 0.09502973407506943
epoch 13: dev_f1=0.8251748251748252, f1=0.8126410835214447, best_f1=0.7844036697247706
step: 0, loss: 0.1509963721036911
step: 10, loss: 0.05605334788560867
step: 20, loss: 0.13879980146884918
step: 30, loss: 0.12975698709487915
step: 40, loss: 0.07810492068529129
step: 50, loss: 0.09321513772010803
step: 60, loss: 0.11236708611249924
step: 70, loss: 0.105133056640625
step: 80, loss: 0.1106133684515953
step: 90, loss: 0.1355038732290268
step: 100, loss: 0.14459635317325592
step: 110, loss: 0.059879738837480545
step: 120, loss: 2.9593204089906067e-05
step: 130, loss: 0.007006100378930569
step: 140, loss: 0.11025604605674744
step: 150, loss: 0.11242057383060455
step: 160, loss: 0.17094698548316956
step: 170, loss: 0.034780532121658325
step: 180, loss: 6.452610978158191e-05
step: 190, loss: 0.061022259294986725
step: 200, loss: 0.10794223099946976
step: 210, loss: 0.05739545822143555
step: 220, loss: 0.10288985818624496
step: 230, loss: 0.10551012307405472
step: 240, loss: 0.05530160292983055
step: 250, loss: 0.09380829334259033
step: 260, loss: 0.0519963763654232
step: 270, loss: 0.08745957911014557
step: 280, loss: 0.13096857070922852
step: 290, loss: 0.04272325336933136
step: 300, loss: 0.07125888019800186
step: 310, loss: 0.08515030890703201
step: 320, loss: 0.20969325304031372
step: 330, loss: 0.037185993045568466
epoch 14: dev_f1=0.8246445497630333, f1=0.8271028037383177, best_f1=0.7844036697247706
step: 0, loss: 0.04420873522758484
step: 10, loss: 0.0983729287981987
step: 20, loss: 0.05719827115535736
step: 30, loss: 0.030185438692569733
step: 40, loss: 0.08283978700637817
step: 50, loss: 0.07287777215242386
step: 60, loss: 0.03501267358660698
step: 70, loss: 0.014437139965593815
step: 80, loss: 0.051957882940769196
step: 90, loss: 0.0348370298743248
step: 100, loss: 0.015112110413610935
step: 110, loss: 0.09461186826229095
step: 120, loss: 0.07652608305215836
step: 130, loss: 0.20837320387363434
step: 140, loss: 0.11209822446107864
step: 150, loss: 0.1191464439034462
step: 160, loss: 0.020642362534999847
step: 170, loss: 0.04993276298046112
step: 180, loss: 0.07237144559621811
step: 190, loss: 0.08579041063785553
step: 200, loss: 0.04216841980814934
step: 210, loss: 0.06778497993946075
step: 220, loss: 0.02758822962641716
step: 230, loss: 0.0441126748919487
step: 240, loss: 0.0832885205745697
step: 250, loss: 0.11492323875427246
step: 260, loss: 0.09528942406177521
step: 270, loss: 0.07764832675457001
step: 280, loss: 0.022166095674037933
step: 290, loss: 0.12037073820829391
step: 300, loss: 0.01632831245660782
step: 310, loss: 0.12234458327293396
step: 320, loss: 0.14123651385307312
step: 330, loss: 0.017178772017359734
epoch 15: dev_f1=0.8205128205128204, f1=0.7981651376146789, best_f1=0.7844036697247706
step: 0, loss: 0.05514238402247429
step: 10, loss: 0.1715090423822403
step: 20, loss: 0.10240259766578674
step: 30, loss: 0.059078115969896317
step: 40, loss: 0.07690612971782684
step: 50, loss: 0.08832815289497375
step: 60, loss: 2.5379702492500655e-05
step: 70, loss: 0.027898186817765236
step: 80, loss: 0.11777571588754654
step: 90, loss: 0.10390335321426392
step: 100, loss: 0.0899229496717453
step: 110, loss: 0.05551658943295479
step: 120, loss: 0.024822931736707687
step: 130, loss: 0.047333795577287674
step: 140, loss: 0.07858015596866608
step: 150, loss: 0.06443416327238083
step: 160, loss: 0.06764233857393265
step: 170, loss: 0.03936797380447388
step: 180, loss: 0.038077060133218765
step: 190, loss: 0.11513596773147583
step: 200, loss: 0.045856181532144547
step: 210, loss: 0.06502211093902588
step: 220, loss: 0.03758713975548744
step: 230, loss: 0.03332943469285965
step: 240, loss: 0.09844652563333511
step: 250, loss: 0.1258915513753891
step: 260, loss: 0.05681401863694191
step: 270, loss: 0.06865008175373077
step: 280, loss: 0.00942117627710104
step: 290, loss: 0.0759807601571083
step: 300, loss: 0.10351316630840302
step: 310, loss: 0.05107887461781502
step: 320, loss: 0.12782053649425507
step: 330, loss: 0.03835374489426613
epoch 16: dev_f1=0.794044665012407, f1=0.8132387706855791, best_f1=0.7844036697247706
step: 0, loss: 0.07919365167617798
step: 10, loss: 0.10728123784065247
step: 20, loss: 0.13831545412540436
step: 30, loss: 0.1244165226817131
step: 40, loss: 0.09165732562541962
step: 50, loss: 0.03469541296362877
step: 60, loss: 0.06545552611351013
step: 70, loss: 0.06278789788484573
step: 80, loss: 0.023467333987355232
step: 90, loss: 0.09335153549909592
step: 100, loss: 0.09454221278429031
step: 110, loss: 0.039629653096199036
step: 120, loss: 0.04663948342204094
step: 130, loss: 0.03624662011861801
step: 140, loss: 0.07114949822425842
step: 150, loss: 0.07475778460502625
step: 160, loss: 0.02423005923628807
step: 170, loss: 0.013071845285594463
step: 180, loss: 0.0016406512586399913
step: 190, loss: 0.3117445707321167
step: 200, loss: 0.10324469208717346
step: 210, loss: 0.04415614902973175
step: 220, loss: 0.0886458232998848
step: 230, loss: 0.14666883647441864
step: 240, loss: 0.12988390028476715
step: 250, loss: 0.04750625416636467
step: 260, loss: 0.09042393416166306
step: 270, loss: 0.1130475103855133
step: 280, loss: 0.025881744921207428
step: 290, loss: 0.02345765382051468
step: 300, loss: 0.05816428363323212
step: 310, loss: 0.09402616322040558
step: 320, loss: 0.1139817088842392
step: 330, loss: 0.14515021443367004
epoch 17: dev_f1=0.8165137614678899, f1=0.817155756207675, best_f1=0.7844036697247706
step: 0, loss: 0.04710014909505844
step: 10, loss: 0.07587766647338867
step: 20, loss: 0.039472125470638275
step: 30, loss: 0.05686558037996292
step: 40, loss: 0.16841574013233185
step: 50, loss: 0.08844447135925293
step: 60, loss: 0.11776452511548996
step: 70, loss: 0.07484149187803268
step: 80, loss: 0.08056174218654633
step: 90, loss: 0.023042844608426094
step: 100, loss: 0.04867764189839363
step: 110, loss: 0.08288774639368057
step: 120, loss: 0.048611775040626526
step: 130, loss: 0.07317624986171722
step: 140, loss: 0.04250546544790268
step: 150, loss: 0.15347513556480408
step: 160, loss: 0.02363889291882515
step: 170, loss: 0.012204212136566639
step: 180, loss: 0.0001105025876313448
step: 190, loss: 0.02537066861987114
step: 200, loss: 0.05854329466819763
step: 210, loss: 0.10285767912864685
step: 220, loss: 0.03805812448263168
step: 230, loss: 0.12396617233753204
step: 240, loss: 0.14902403950691223
step: 250, loss: 0.09528513997793198
step: 260, loss: 0.009891361929476261
step: 270, loss: 0.038352251052856445
step: 280, loss: 0.03794430196285248
step: 290, loss: 0.030138298869132996
step: 300, loss: 0.1058354377746582
step: 310, loss: 0.09887100011110306
step: 320, loss: 0.08380946516990662
step: 330, loss: 0.07849209755659103
epoch 18: dev_f1=0.7980295566502462, f1=0.8095238095238095, best_f1=0.7844036697247706
step: 0, loss: 0.0875721201300621
step: 10, loss: 0.021238572895526886
step: 20, loss: 0.048104435205459595
step: 30, loss: 0.04819792881608009
step: 40, loss: 0.040829818695783615
step: 50, loss: 0.08440796285867691
step: 60, loss: 0.0687725618481636
step: 70, loss: 0.05771445110440254
step: 80, loss: 0.08131715655326843
step: 90, loss: 0.03812692314386368
step: 100, loss: 0.04131972789764404
step: 110, loss: 0.05187442526221275
step: 120, loss: 0.0700189545750618
step: 130, loss: 0.0796922966837883
step: 140, loss: 0.055905651301145554
step: 150, loss: 0.1257752627134323
step: 160, loss: 0.12452183663845062
step: 170, loss: 0.0940939337015152
step: 180, loss: 0.10139773786067963
step: 190, loss: 0.05942954495549202
step: 200, loss: 0.0708564817905426
step: 210, loss: 0.05230279639363289
step: 220, loss: 0.0792553648352623
step: 230, loss: 0.061154045164585114
step: 240, loss: 0.13984103500843048
step: 250, loss: 0.07718654721975327
step: 260, loss: 0.1062198132276535
step: 270, loss: 0.08506949245929718
step: 280, loss: 0.07874377071857452
step: 290, loss: 0.08323430269956589
step: 300, loss: 0.16473370790481567
step: 310, loss: 0.07762313634157181
step: 320, loss: 0.1313367635011673
step: 330, loss: 0.029870828613638878
epoch 19: dev_f1=0.7990196078431373, f1=0.8179669030732861, best_f1=0.7844036697247706
step: 0, loss: 0.09485408663749695
step: 10, loss: 0.02814258448779583
step: 20, loss: 0.04060789570212364
step: 30, loss: 0.10203409940004349
step: 40, loss: 0.06653951108455658
step: 50, loss: 0.04795512557029724
step: 60, loss: 0.04797304421663284
step: 70, loss: 0.08509155362844467
step: 80, loss: 0.13385482132434845
step: 90, loss: 0.035704948008060455
step: 100, loss: 0.04752543568611145
step: 110, loss: 0.008187566883862019
step: 120, loss: 0.031629156321287155
step: 130, loss: 0.0745789036154747
step: 140, loss: 0.06553146988153458
step: 150, loss: 0.056711722165346146
step: 160, loss: 0.0291484072804451
step: 170, loss: 0.022685037925839424
step: 180, loss: 0.037867557257413864
step: 190, loss: 0.1379641890525818
step: 200, loss: 0.05875520780682564
step: 210, loss: 0.08613922446966171
step: 220, loss: 0.020870741456747055
step: 230, loss: 0.159379243850708
step: 240, loss: 0.03537820652127266
step: 250, loss: 0.0192861445248127
step: 260, loss: 0.09823515266180038
step: 270, loss: 0.1498652845621109
step: 280, loss: 0.02159593440592289
step: 290, loss: 0.11235471814870834
step: 300, loss: 0.08227762579917908
step: 310, loss: 0.056428201496601105
step: 320, loss: 0.021907484158873558
step: 330, loss: 0.03778643161058426
epoch 20: dev_f1=0.7910447761194029, f1=0.8038277511961723, best_f1=0.7844036697247706
