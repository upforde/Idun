cuda
Device: cuda
step: 0, loss: 0.6762601137161255
step: 10, loss: 0.4281019866466522
step: 20, loss: 0.28592127561569214
step: 30, loss: 0.43007567524909973
step: 40, loss: 0.22912752628326416
step: 50, loss: 0.16599294543266296
step: 60, loss: 0.08503010869026184
step: 70, loss: 0.3995119333267212
step: 80, loss: 0.23232032358646393
step: 90, loss: 0.1959701031446457
step: 100, loss: 0.04581126570701599
step: 110, loss: 0.24085502326488495
step: 120, loss: 0.19001074135303497
step: 130, loss: 0.2378731071949005
step: 140, loss: 0.22499477863311768
step: 150, loss: 0.1928642839193344
step: 160, loss: 0.22286416590213776
step: 170, loss: 0.27880755066871643
step: 180, loss: 0.09733830392360687
step: 190, loss: 0.22874993085861206
step: 200, loss: 0.3122000992298126
step: 210, loss: 0.10324724018573761
step: 220, loss: 0.2327573001384735
step: 230, loss: 0.056754738092422485
step: 240, loss: 0.1061302125453949
step: 250, loss: 0.06009269505739212
step: 260, loss: 0.1840745359659195
step: 270, loss: 0.1637367457151413
step: 280, loss: 0.23159386217594147
step: 290, loss: 0.14608420431613922
step: 300, loss: 0.23844362795352936
step: 310, loss: 0.07161154597997665
step: 320, loss: 0.24422922730445862
step: 330, loss: 0.11711766570806503
step: 340, loss: 0.08707836270332336
step: 350, loss: 0.12786708772182465
step: 360, loss: 0.1415170282125473
step: 370, loss: 0.1250769942998886
step: 380, loss: 0.07769531011581421
step: 390, loss: 0.15216821432113647
step: 400, loss: 0.17201492190361023
step: 410, loss: 0.13020841777324677
step: 420, loss: 0.16757667064666748
step: 430, loss: 0.11733036488294601
step: 440, loss: 0.12002323567867279
step: 450, loss: 0.10104114562273026
step: 460, loss: 0.13220196962356567
epoch 1: dev_f1=0.984304932735426, f1=0.9727272727272728, best_f1=0.9727272727272728
step: 0, loss: 0.11429004371166229
step: 10, loss: 0.09588675945997238
step: 20, loss: 0.19327813386917114
step: 30, loss: 0.04112246632575989
step: 40, loss: 0.19310761988162994
step: 50, loss: 0.02196507155895233
step: 60, loss: 0.09263879060745239
step: 70, loss: 0.03681274130940437
step: 80, loss: 0.07288859039545059
step: 90, loss: 0.15724724531173706
step: 100, loss: 0.03767748177051544
step: 110, loss: 0.05521690472960472
step: 120, loss: 0.09317608922719955
step: 130, loss: 0.07641247659921646
step: 140, loss: 0.2346058487892151
step: 150, loss: 0.3026163578033447
step: 160, loss: 0.11495842784643173
step: 170, loss: 0.11517438292503357
step: 180, loss: 0.09040230512619019
step: 190, loss: 0.019065121188759804
step: 200, loss: 0.10679405927658081
step: 210, loss: 0.13354337215423584
step: 220, loss: 0.08190813660621643
step: 230, loss: 0.0949278175830841
step: 240, loss: 0.1123565211892128
step: 250, loss: 0.07996751368045807
step: 260, loss: 0.11622224003076553
step: 270, loss: 0.11020459979772568
step: 280, loss: 0.19978797435760498
step: 290, loss: 0.08142807334661484
step: 300, loss: 0.032806046307086945
step: 310, loss: 0.17804986238479614
step: 320, loss: 0.21925561130046844
step: 330, loss: 0.0956091359257698
step: 340, loss: 0.17936119437217712
step: 350, loss: 0.13253815472126007
step: 360, loss: 0.05875730514526367
step: 370, loss: 0.14547105133533478
step: 380, loss: 0.10203131288290024
step: 390, loss: 0.07658576220273972
step: 400, loss: 0.11581940203905106
step: 410, loss: 0.12106811255216599
step: 420, loss: 0.1088360995054245
step: 430, loss: 0.11022896319627762
step: 440, loss: 0.0874500572681427
step: 450, loss: 0.10284750908613205
step: 460, loss: 0.06499762088060379
epoch 2: dev_f1=0.9876265466816648, f1=0.9741282339707535, best_f1=0.9741282339707535
step: 0, loss: 0.21894824504852295
step: 10, loss: 0.07746029645204544
step: 20, loss: 0.0914507508277893
step: 30, loss: 0.06421567499637604
step: 40, loss: 0.04383185878396034
step: 50, loss: 0.15992717444896698
step: 60, loss: 0.01514002587646246
step: 70, loss: 0.0745568796992302
step: 80, loss: 0.16635069251060486
step: 90, loss: 0.08102021366357803
step: 100, loss: 0.019014498218894005
step: 110, loss: 0.041074927896261215
step: 120, loss: 0.12424498051404953
step: 130, loss: 0.19801917672157288
step: 140, loss: 0.044015977531671524
step: 150, loss: 0.03300722315907478
step: 160, loss: 0.1526588499546051
step: 170, loss: 0.014864075928926468
step: 180, loss: 0.041621334850788116
step: 190, loss: 0.17288756370544434
step: 200, loss: 0.023067986592650414
step: 210, loss: 0.10116036236286163
step: 220, loss: 0.10271883755922318
step: 230, loss: 0.06557440757751465
step: 240, loss: 0.09752208739519119
step: 250, loss: 0.006149515975266695
step: 260, loss: 0.060712847858667374
step: 270, loss: 0.22908686101436615
step: 280, loss: 0.04803789407014847
step: 290, loss: 0.0706116333603859
step: 300, loss: 0.03268997743725777
step: 310, loss: 0.17235244810581207
step: 320, loss: 0.060503289103507996
step: 330, loss: 0.051983729004859924
step: 340, loss: 0.0187547504901886
step: 350, loss: 0.027329757809638977
step: 360, loss: 0.03867506980895996
step: 370, loss: 0.026933901011943817
step: 380, loss: 0.07224429398775101
step: 390, loss: 0.013685261830687523
step: 400, loss: 0.07155448943376541
step: 410, loss: 0.21170562505722046
step: 420, loss: 0.06923367083072662
step: 430, loss: 0.052582234144210815
step: 440, loss: 0.0658489465713501
step: 450, loss: 0.06426820158958435
step: 460, loss: 0.13531216979026794
epoch 3: dev_f1=0.9910112359550561, f1=0.9764309764309763, best_f1=0.9764309764309763
step: 0, loss: 0.0446549691259861
step: 10, loss: 0.13451164960861206
step: 20, loss: 0.022181151434779167
step: 30, loss: 0.08985444903373718
step: 40, loss: 0.0830235481262207
step: 50, loss: 0.10077092796564102
step: 60, loss: 0.06869734823703766
step: 70, loss: 0.018781794235110283
step: 80, loss: 0.04308547452092171
step: 90, loss: 0.09002073109149933
step: 100, loss: 0.024848729372024536
step: 110, loss: 0.1561770886182785
step: 120, loss: 0.07946668565273285
step: 130, loss: 0.013832363300025463
step: 140, loss: 0.03643796965479851
step: 150, loss: 0.021909289062023163
step: 160, loss: 0.0906258076429367
step: 170, loss: 0.05934509262442589
step: 180, loss: 0.07263264805078506
step: 190, loss: 0.20477807521820068
step: 200, loss: 0.09655378758907318
step: 210, loss: 0.10170111805200577
step: 220, loss: 0.03530139476060867
step: 230, loss: 0.022972311824560165
step: 240, loss: 0.00609999056905508
step: 250, loss: 0.11970555037260056
step: 260, loss: 0.029942795634269714
step: 270, loss: 0.11100506037473679
step: 280, loss: 0.08644763380289078
step: 290, loss: 0.06320840120315552
step: 300, loss: 0.022974161431193352
step: 310, loss: 0.05831030756235123
step: 320, loss: 0.12443169951438904
step: 330, loss: 0.06938565522432327
step: 340, loss: 0.008925674483180046
step: 350, loss: 0.08059858530759811
step: 360, loss: 0.06488842517137527
step: 370, loss: 0.16691455245018005
step: 380, loss: 0.026288622990250587
step: 390, loss: 0.13847574591636658
step: 400, loss: 0.17733004689216614
step: 410, loss: 0.09505529701709747
step: 420, loss: 0.1475573182106018
step: 430, loss: 0.07195357233285904
step: 440, loss: 0.1112477034330368
step: 450, loss: 0.10434449464082718
step: 460, loss: 0.10976581275463104
epoch 4: dev_f1=0.9921436588103255, f1=0.9788182831661093, best_f1=0.9788182831661093
step: 0, loss: 0.13779857754707336
step: 10, loss: 0.06668206304311752
step: 20, loss: 0.03195551037788391
step: 30, loss: 0.15442024171352386
step: 40, loss: 0.09236788004636765
step: 50, loss: 0.15036116540431976
step: 60, loss: 0.03844271972775459
step: 70, loss: 0.039004262536764145
step: 80, loss: 0.013605449348688126
step: 90, loss: 0.05506715178489685
step: 100, loss: 0.05937865376472473
step: 110, loss: 0.10669577121734619
step: 120, loss: 0.103558748960495
step: 130, loss: 0.08826641738414764
step: 140, loss: 0.03764697536826134
step: 150, loss: 0.10314587503671646
step: 160, loss: 0.16639769077301025
step: 170, loss: 0.06184571981430054
step: 180, loss: 0.0054275174625217915
step: 190, loss: 0.035708893090486526
step: 200, loss: 0.06907055526971817
step: 210, loss: 0.028238551691174507
step: 220, loss: 0.05662044510245323
step: 230, loss: 0.032340895384550095
step: 240, loss: 0.0077361008152365685
step: 250, loss: 0.046974264085292816
step: 260, loss: 0.22643747925758362
step: 270, loss: 0.05997469276189804
step: 280, loss: 0.010937616229057312
step: 290, loss: 0.025842946022748947
step: 300, loss: 0.03211984410881996
step: 310, loss: 0.1586070954799652
step: 320, loss: 0.01866806298494339
step: 330, loss: 0.1097036749124527
step: 340, loss: 0.0271665807813406
step: 350, loss: 0.08521681278944016
step: 360, loss: 0.13999906182289124
step: 370, loss: 0.1363014280796051
step: 380, loss: 0.07080637663602829
step: 390, loss: 0.17792457342147827
step: 400, loss: 0.028875097632408142
step: 410, loss: 0.05889023095369339
step: 420, loss: 0.0816340446472168
step: 430, loss: 0.07168257981538773
step: 440, loss: 0.08688053488731384
step: 450, loss: 0.023793116211891174
step: 460, loss: 0.02059301733970642
epoch 5: dev_f1=0.9898074745186863, f1=0.9806598407281, best_f1=0.9788182831661093
step: 0, loss: 0.2415139526128769
step: 10, loss: 0.027229897677898407
step: 20, loss: 0.03455554321408272
step: 30, loss: 0.034492213279008865
step: 40, loss: 0.010385475121438503
step: 50, loss: 0.11771313846111298
step: 60, loss: 0.03720203414559364
step: 70, loss: 0.095942921936512
step: 80, loss: 0.03818405792117119
step: 90, loss: 0.06872477382421494
step: 100, loss: 0.08080359548330307
step: 110, loss: 0.006324069574475288
step: 120, loss: 0.18278992176055908
step: 130, loss: 0.05207674950361252
step: 140, loss: 0.007427786476910114
step: 150, loss: 0.019918056204915047
step: 160, loss: 0.025517499074339867
step: 170, loss: 0.0502312034368515
step: 180, loss: 0.06292959302663803
step: 190, loss: 0.10698554664850235
step: 200, loss: 0.029204174876213074
step: 210, loss: 0.10686120390892029
step: 220, loss: 0.036002267152071
step: 230, loss: 0.08008536696434021
step: 240, loss: 0.09056931734085083
step: 250, loss: 0.07117830961942673
step: 260, loss: 0.008714837022125721
step: 270, loss: 0.03346092998981476
step: 280, loss: 0.10096033662557602
step: 290, loss: 0.039223480969667435
step: 300, loss: 0.07833702117204666
step: 310, loss: 0.09374172240495682
step: 320, loss: 0.016072016209363937
step: 330, loss: 0.19728277623653412
step: 340, loss: 0.01258623506873846
step: 350, loss: 0.08682713657617569
step: 360, loss: 0.026502909138798714
step: 370, loss: 0.02728169783949852
step: 380, loss: 0.05423518270254135
step: 390, loss: 0.06577825546264648
step: 400, loss: 0.13768810033798218
step: 410, loss: 0.023304948583245277
step: 420, loss: 0.07190023362636566
step: 430, loss: 0.025703255087137222
step: 440, loss: 0.045770078897476196
step: 450, loss: 0.025920528918504715
step: 460, loss: 0.02421196550130844
epoch 6: dev_f1=0.9932584269662922, f1=0.9809203142536477, best_f1=0.9809203142536477
step: 0, loss: 0.015555628575384617
step: 10, loss: 0.061880793422460556
step: 20, loss: 0.0333893820643425
step: 30, loss: 0.0059416769072413445
step: 40, loss: 0.10579454898834229
step: 50, loss: 0.03423198312520981
step: 60, loss: 0.03888990730047226
step: 70, loss: 0.05320724844932556
step: 80, loss: 0.0001022933647618629
step: 90, loss: 0.026633644476532936
step: 100, loss: 0.08536827564239502
step: 110, loss: 0.07809983938932419
step: 120, loss: 0.036366984248161316
step: 130, loss: 0.028159748762845993
step: 140, loss: 0.08270995318889618
step: 150, loss: 0.07517321407794952
step: 160, loss: 0.05204615741968155
step: 170, loss: 0.03913077712059021
step: 180, loss: 0.12145679444074631
step: 190, loss: 0.08021610975265503
step: 200, loss: 0.027898330241441727
step: 210, loss: 0.0702536553144455
step: 220, loss: 0.13196918368339539
step: 230, loss: 0.04626711085438728
step: 240, loss: 0.03290900960564613
step: 250, loss: 0.055300023406744
step: 260, loss: 0.05953224375844002
step: 270, loss: 0.024114493280649185
step: 280, loss: 0.028980379924178123
step: 290, loss: 0.036533892154693604
step: 300, loss: 0.07568834722042084
step: 310, loss: 0.017989592626690865
step: 320, loss: 0.028201673179864883
step: 330, loss: 0.018210308626294136
step: 340, loss: 0.12425985932350159
step: 350, loss: 0.09843749552965164
step: 360, loss: 0.036381665617227554
step: 370, loss: 0.09775430709123611
step: 380, loss: 0.02849743887782097
step: 390, loss: 0.024899443611502647
step: 400, loss: 0.06367182731628418
step: 410, loss: 0.06262724846601486
step: 420, loss: 0.055248476564884186
step: 430, loss: 0.11915101110935211
step: 440, loss: 0.021207785233855247
step: 450, loss: 6.709012086503208e-05
step: 460, loss: 0.024487579241394997
epoch 7: dev_f1=0.9899216125419933, f1=0.9776785714285714, best_f1=0.9809203142536477
step: 0, loss: 0.04942306876182556
step: 10, loss: 0.05076274275779724
step: 20, loss: 0.10787443071603775
step: 30, loss: 0.015205916948616505
step: 40, loss: 0.1125994622707367
step: 50, loss: 0.017181020230054855
step: 60, loss: 0.009976936504244804
step: 70, loss: 0.08440613746643066
step: 80, loss: 0.018857935443520546
step: 90, loss: 0.016890523955225945
step: 100, loss: 0.1640748232603073
step: 110, loss: 0.045379363000392914
step: 120, loss: 0.10859393328428268
step: 130, loss: 0.12244674563407898
step: 140, loss: 0.01870192401111126
step: 150, loss: 0.158119797706604
step: 160, loss: 0.05556317791342735
step: 170, loss: 0.09394748508930206
step: 180, loss: 0.105563223361969
step: 190, loss: 0.029757816344499588
step: 200, loss: 0.041609425097703934
step: 210, loss: 0.006109514739364386
step: 220, loss: 0.03215828537940979
step: 230, loss: 0.01383538544178009
step: 240, loss: 0.04366040602326393
step: 250, loss: 0.0059660947881639
step: 260, loss: 0.0011999926064163446
step: 270, loss: 0.07628471404314041
step: 280, loss: 0.013310362584888935
step: 290, loss: 0.035061996430158615
step: 300, loss: 0.07338443398475647
step: 310, loss: 0.007108396850526333
step: 320, loss: 0.01566091738641262
step: 330, loss: 0.03134142607450485
step: 340, loss: 0.1653047353029251
step: 350, loss: 0.034792281687259674
step: 360, loss: 0.07608556002378464
step: 370, loss: 0.006932753603905439
step: 380, loss: 0.02884852886199951
step: 390, loss: 0.08655340224504471
step: 400, loss: 0.0762643963098526
step: 410, loss: 0.12469033151865005
step: 420, loss: 0.02479122392833233
step: 430, loss: 0.03121362254023552
step: 440, loss: 0.11732643097639084
step: 450, loss: 0.21623095870018005
step: 460, loss: 0.04773734137415886
epoch 8: dev_f1=0.9921259842519685, f1=0.9798657718120806, best_f1=0.9809203142536477
step: 0, loss: 0.07419770956039429
step: 10, loss: 0.04670495539903641
step: 20, loss: 0.016227146610617638
step: 30, loss: 0.0445278100669384
step: 40, loss: 0.08813540637493134
step: 50, loss: 0.02269669994711876
step: 60, loss: 0.025491535663604736
step: 70, loss: 0.013061611913144588
step: 80, loss: 0.07129783183336258
step: 90, loss: 0.020506808534264565
step: 100, loss: 0.0001636135420994833
step: 110, loss: 0.07899846881628036
step: 120, loss: 0.011374370194971561
step: 130, loss: 0.07839661836624146
step: 140, loss: 0.005843888036906719
step: 150, loss: 0.016240354627370834
step: 160, loss: 0.08571522682905197
step: 170, loss: 0.015351125970482826
step: 180, loss: 0.06179908290505409
step: 190, loss: 0.00015940816956572235
step: 200, loss: 0.0594964399933815
step: 210, loss: 0.017402518540620804
step: 220, loss: 0.024303331971168518
step: 230, loss: 0.02371714450418949
step: 240, loss: 0.13738085329532623
step: 250, loss: 0.04462963715195656
step: 260, loss: 0.031612053513526917
step: 270, loss: 0.0736706405878067
step: 280, loss: 0.0929734855890274
step: 290, loss: 0.02208714373409748
step: 300, loss: 0.07341417670249939
step: 310, loss: 0.006146575789898634
step: 320, loss: 0.017675144597887993
step: 330, loss: 0.21206408739089966
step: 340, loss: 0.14118996262550354
step: 350, loss: 0.06048743426799774
step: 360, loss: 0.008808005601167679
step: 370, loss: 0.0732356533408165
step: 380, loss: 0.07492385804653168
step: 390, loss: 0.07629004120826721
step: 400, loss: 0.04132583737373352
step: 410, loss: 0.08693425357341766
step: 420, loss: 0.04720505326986313
step: 430, loss: 0.023099666461348534
step: 440, loss: 0.06656930595636368
step: 450, loss: 0.06701633334159851
step: 460, loss: 0.04205595701932907
epoch 9: dev_f1=0.9921436588103255, f1=0.9876265466816648, best_f1=0.9809203142536477
step: 0, loss: 0.06939713656902313
step: 10, loss: 0.11600443720817566
step: 20, loss: 0.058898959308862686
step: 30, loss: 0.019294079393148422
step: 40, loss: 0.0009975869907066226
step: 50, loss: 0.007031060289591551
step: 60, loss: 0.09818686544895172
step: 70, loss: 0.02815684676170349
step: 80, loss: 0.012248256243765354
step: 90, loss: 0.07613486796617508
step: 100, loss: 0.03688901662826538
step: 110, loss: 0.01024494506418705
step: 120, loss: 0.06798478960990906
step: 130, loss: 0.009351680986583233
step: 140, loss: 0.0849577784538269
step: 150, loss: 0.07454143464565277
step: 160, loss: 0.2516191005706787
step: 170, loss: 0.03675136715173721
step: 180, loss: 0.16392162442207336
step: 190, loss: 0.03678382188081741
step: 200, loss: 0.04667755961418152
step: 210, loss: 0.07701358199119568
step: 220, loss: 0.14605343341827393
step: 230, loss: 0.14195296168327332
step: 240, loss: 0.12769387662410736
step: 250, loss: 0.02526564709842205
step: 260, loss: 0.011445090174674988
step: 270, loss: 0.005230807699263096
step: 280, loss: 0.09920285642147064
step: 290, loss: 0.08923434466123581
step: 300, loss: 0.014477308839559555
step: 310, loss: 0.10417230427265167
step: 320, loss: 0.01628165692090988
step: 330, loss: 0.019192231819033623
step: 340, loss: 0.020713357254862785
step: 350, loss: 0.02431008592247963
step: 360, loss: 0.04250030219554901
step: 370, loss: 0.025122418999671936
step: 380, loss: 0.01377039309591055
step: 390, loss: 0.09226001054048538
step: 400, loss: 0.07048124819993973
step: 410, loss: 0.10735566914081573
step: 420, loss: 0.0699022114276886
step: 430, loss: 0.08174850046634674
step: 440, loss: 0.014300277456641197
step: 450, loss: 0.034919388592243195
step: 460, loss: 0.07962983101606369
epoch 10: dev_f1=0.9932584269662922, f1=0.9798206278026906, best_f1=0.9809203142536477
step: 0, loss: 0.009289925917983055
step: 10, loss: 0.03051072731614113
step: 20, loss: 0.0801454409956932
step: 30, loss: 0.00015265916590578854
step: 40, loss: 0.0025157583877444267
step: 50, loss: 0.030507514253258705
step: 60, loss: 0.0055565377697348595
step: 70, loss: 0.051435548812150955
step: 80, loss: 0.06345672160387039
step: 90, loss: 0.019970230758190155
step: 100, loss: 0.0623379610478878
step: 110, loss: 0.1326819360256195
step: 120, loss: 0.00092349573969841
step: 130, loss: 0.043787382543087006
step: 140, loss: 0.10741694271564484
step: 150, loss: 0.0047434368170797825
step: 160, loss: 0.03067367896437645
step: 170, loss: 0.019435031339526176
step: 180, loss: 0.02521493285894394
step: 190, loss: 0.05791416019201279
step: 200, loss: 0.06947003304958344
step: 210, loss: 0.01844804175198078
step: 220, loss: 0.06599777936935425
step: 230, loss: 0.17824731767177582
step: 240, loss: 0.08178557455539703
step: 250, loss: 0.04017600044608116
step: 260, loss: 0.025142252445220947
step: 270, loss: 0.057733722031116486
step: 280, loss: 0.05874837562441826
step: 290, loss: 0.030779169872403145
step: 300, loss: 0.02374390885233879
step: 310, loss: 0.04479004442691803
step: 320, loss: 0.06680823862552643
step: 330, loss: 0.05557166039943695
step: 340, loss: 0.027690671384334564
step: 350, loss: 0.08462756127119064
step: 360, loss: 0.0422796905040741
step: 370, loss: 0.1224365234375
step: 380, loss: 0.11150169372558594
step: 390, loss: 0.009427490644156933
step: 400, loss: 0.07986107468605042
step: 410, loss: 0.003955797757953405
step: 420, loss: 0.058501988649368286
step: 430, loss: 0.06356045603752136
step: 440, loss: 0.10093813389539719
step: 450, loss: 0.033953845500946045
step: 460, loss: 0.01570698246359825
epoch 11: dev_f1=0.992108229988726, f1=0.9841628959276018, best_f1=0.9809203142536477
step: 0, loss: 0.00276390602812171
step: 10, loss: 0.07598556578159332
step: 20, loss: 0.0747746154665947
step: 30, loss: 0.04528503865003586
step: 40, loss: 0.050416696816682816
step: 50, loss: 0.12174088507890701
step: 60, loss: 0.1648567169904709
step: 70, loss: 0.036526795476675034
step: 80, loss: 0.013287712819874287
step: 90, loss: 0.07099323719739914
step: 100, loss: 0.03677485138177872
step: 110, loss: 0.04636366665363312
step: 120, loss: 0.03330311179161072
step: 130, loss: 0.020455431193113327
step: 140, loss: 0.004350876901298761
step: 150, loss: 0.04308903589844704
step: 160, loss: 0.010541808791458607
step: 170, loss: 0.06283421814441681
step: 180, loss: 0.03289465978741646
step: 190, loss: 0.0939183458685875
step: 200, loss: 0.0046356432139873505
step: 210, loss: 0.07498981803655624
step: 220, loss: 0.09551182389259338
step: 230, loss: 0.006938104517757893
step: 240, loss: 0.000646666216198355
step: 250, loss: 0.01341237872838974
step: 260, loss: 0.0841953307390213
step: 270, loss: 0.018643708899617195
step: 280, loss: 0.04835481941699982
step: 290, loss: 0.023049376904964447
step: 300, loss: 0.032799553126096725
step: 310, loss: 0.023046256974339485
step: 320, loss: 0.004381824284791946
step: 330, loss: 0.05851849168539047
step: 340, loss: 0.07995018362998962
step: 350, loss: 0.01981358975172043
step: 360, loss: 0.020974760875105858
step: 370, loss: 0.06916246563196182
step: 380, loss: 0.02814696915447712
step: 390, loss: 0.03728301078081131
step: 400, loss: 0.01498933881521225
step: 410, loss: 0.07848058640956879
step: 420, loss: 0.0744888186454773
step: 430, loss: 0.03168291971087456
step: 440, loss: 0.007591295056045055
step: 450, loss: 0.04075353220105171
step: 460, loss: 0.04135299474000931
epoch 12: dev_f1=0.992108229988726, f1=0.9809203142536477, best_f1=0.9809203142536477
step: 0, loss: 0.0196058452129364
step: 10, loss: 0.010163291357457638
step: 20, loss: 0.037565458565950394
step: 30, loss: 0.09715662151575089
step: 40, loss: 0.018222004175186157
step: 50, loss: 0.03337099030613899
step: 60, loss: 0.04275419935584068
step: 70, loss: 0.02333415299654007
step: 80, loss: 0.11821375787258148
step: 90, loss: 0.09359409660100937
step: 100, loss: 0.03842811658978462
step: 110, loss: 0.02661270648241043
step: 120, loss: 0.12474038451910019
step: 130, loss: 0.04962131753563881
step: 140, loss: 0.10493150353431702
step: 150, loss: 0.009257158264517784
step: 160, loss: 0.048853799700737
step: 170, loss: 0.03427118808031082
step: 180, loss: 0.014034345746040344
step: 190, loss: 0.03523331135511398
step: 200, loss: 0.0021559300366789103
step: 210, loss: 0.04257829487323761
step: 220, loss: 0.009689233265817165
step: 230, loss: 0.029016783460974693
step: 240, loss: 0.07710453122854233
step: 250, loss: 0.007142160087823868
step: 260, loss: 0.03229217231273651
step: 270, loss: 0.031603820621967316
step: 280, loss: 0.013302997685968876
step: 290, loss: 0.08530115336179733
step: 300, loss: 0.06239848583936691
step: 310, loss: 0.017124591395258904
step: 320, loss: 0.028843216598033905
step: 330, loss: 0.02581678330898285
step: 340, loss: 0.04479190334677696
step: 350, loss: 0.04862663522362709
step: 360, loss: 0.027230780571699142
step: 370, loss: 0.016564950346946716
step: 380, loss: 0.012949764728546143
step: 390, loss: 0.007216236554086208
step: 400, loss: 0.006821722723543644
step: 410, loss: 0.041046395897865295
step: 420, loss: 0.05190451815724373
step: 430, loss: 0.05321221426129341
step: 440, loss: 0.07410591095685959
step: 450, loss: 0.06933549046516418
step: 460, loss: 0.06759998202323914
epoch 13: dev_f1=0.990990990990991, f1=0.9821029082774049, best_f1=0.9809203142536477
step: 0, loss: 0.0010165105341002345
step: 10, loss: 0.026909545063972473
step: 20, loss: 0.008251245133578777
step: 30, loss: 0.08484793454408646
step: 40, loss: 0.016720376908779144
step: 50, loss: 0.07363738864660263
step: 60, loss: 0.0628477931022644
step: 70, loss: 0.02729976363480091
step: 80, loss: 0.03984472528100014
step: 90, loss: 0.03306460380554199
step: 100, loss: 0.029593005776405334
step: 110, loss: 0.020715024322271347
step: 120, loss: 0.05044020712375641
step: 130, loss: 0.08707620203495026
step: 140, loss: 0.06696265190839767
step: 150, loss: 0.021082095801830292
step: 160, loss: 0.009060545824468136
step: 170, loss: 0.00014353789447341114
step: 180, loss: 0.01460667047649622
step: 190, loss: 0.05619433894753456
step: 200, loss: 0.037819501012563705
step: 210, loss: 0.050457533448934555
step: 220, loss: 0.06697966903448105
step: 230, loss: 0.005897346884012222
step: 240, loss: 0.030431874096393585
step: 250, loss: 0.005654106382280588
step: 260, loss: 0.029903477057814598
step: 270, loss: 0.026992283761501312
step: 280, loss: 0.008721837773919106
step: 290, loss: 0.1630726307630539
step: 300, loss: 0.05565911903977394
step: 310, loss: 0.05392872542142868
step: 320, loss: 0.1062387228012085
step: 330, loss: 0.04871699586510658
step: 340, loss: 0.02058393508195877
step: 350, loss: 0.02570265345275402
step: 360, loss: 0.05243662744760513
step: 370, loss: 0.01211970392614603
step: 380, loss: 0.08874588459730148
step: 390, loss: 0.054383259266614914
step: 400, loss: 0.017271023243665695
step: 410, loss: 0.0035489327274262905
step: 420, loss: 0.08238721638917923
step: 430, loss: 0.016662193462252617
step: 440, loss: 0.08020380139350891
step: 450, loss: 0.04213152825832367
step: 460, loss: 0.006578081287443638
epoch 14: dev_f1=0.9921436588103255, f1=0.9832402234636871, best_f1=0.9809203142536477
step: 0, loss: 0.059127047657966614
step: 10, loss: 0.10959833115339279
step: 20, loss: 0.026532139629125595
step: 30, loss: 0.04935666173696518
step: 40, loss: 0.016488291323184967
step: 50, loss: 0.04974580928683281
step: 60, loss: 1.4953146092011593e-05
step: 70, loss: 0.014737405814230442
step: 80, loss: 0.05341750755906105
step: 90, loss: 0.00836669560521841
step: 100, loss: 0.006601512897759676
step: 110, loss: 0.08216667175292969
step: 120, loss: 0.012696835212409496
step: 130, loss: 0.0006334912613965571
step: 140, loss: 0.04633581265807152
step: 150, loss: 0.03471512719988823
step: 160, loss: 0.03982355445623398
step: 170, loss: 0.026109039783477783
step: 180, loss: 0.06509781628847122
step: 190, loss: 0.020711705088615417
step: 200, loss: 0.029317431151866913
step: 210, loss: 0.07068084925413132
step: 220, loss: 0.07720682770013809
step: 230, loss: 0.06882322579622269
step: 240, loss: 0.0021613212302327156
step: 250, loss: 0.019270073622465134
step: 260, loss: 0.09231796860694885
step: 270, loss: 0.04320022463798523
step: 280, loss: 0.04992708936333656
step: 290, loss: 0.09470892697572708
step: 300, loss: 0.003668059827759862
step: 310, loss: 0.05046975985169411
step: 320, loss: 0.00943882204592228
step: 330, loss: 0.03233269602060318
step: 340, loss: 0.023000352084636688
step: 350, loss: 0.0802651047706604
step: 360, loss: 0.026784153655171394
step: 370, loss: 0.082587331533432
step: 380, loss: 0.022136790677905083
step: 390, loss: 0.055471569299697876
step: 400, loss: 0.027717147022485733
step: 410, loss: 0.001609346829354763
step: 420, loss: 0.003751934040337801
step: 430, loss: 0.00018932324019260705
step: 440, loss: 0.020277203992009163
step: 450, loss: 0.06992914527654648
step: 460, loss: 0.03125249966979027
epoch 15: dev_f1=0.992108229988726, f1=0.9831271091113611, best_f1=0.9809203142536477
step: 0, loss: 0.041524991393089294
step: 10, loss: 0.00845263246446848
step: 20, loss: 0.0024406714364886284
step: 30, loss: 0.00676178140565753
step: 40, loss: 0.031019415706396103
step: 50, loss: 0.0166616290807724
step: 60, loss: 0.05392410606145859
step: 70, loss: 0.010542571544647217
step: 80, loss: 0.020856397226452827
step: 90, loss: 0.043972622603178024
step: 100, loss: 0.04834258556365967
step: 110, loss: 0.02911088615655899
step: 120, loss: 8.227671060012653e-05
step: 130, loss: 0.01910712569952011
step: 140, loss: 0.0205241646617651
step: 150, loss: 0.020220771431922913
step: 160, loss: 0.0001745550544001162
step: 170, loss: 4.075892866239883e-05
step: 180, loss: 0.08144015073776245
step: 190, loss: 0.06462537497282028
step: 200, loss: 0.11276638507843018
step: 210, loss: 0.04784369096159935
step: 220, loss: 0.12099339812994003
step: 230, loss: 0.03728114813566208
step: 240, loss: 0.05698284134268761
step: 250, loss: 0.001586177502758801
step: 260, loss: 0.057162318378686905
step: 270, loss: 0.03891897201538086
step: 280, loss: 0.022275656461715698
step: 290, loss: 0.023249061778187752
step: 300, loss: 0.01877417229115963
step: 310, loss: 0.03931538015604019
step: 320, loss: 0.052087701857089996
step: 330, loss: 0.1772451102733612
step: 340, loss: 0.020805858075618744
step: 350, loss: 0.012341341935098171
step: 360, loss: 0.06669966876506805
step: 370, loss: 0.01921624131500721
step: 380, loss: 0.04002856835722923
step: 390, loss: 0.03549977019429207
step: 400, loss: 0.11195602267980576
step: 410, loss: 0.07039864361286163
step: 420, loss: 0.06373295933008194
step: 430, loss: 0.03921283408999443
step: 440, loss: 0.03263373672962189
step: 450, loss: 0.07080921530723572
step: 460, loss: 0.06570598483085632
epoch 16: dev_f1=0.9932432432432432, f1=0.9832402234636871, best_f1=0.9809203142536477
step: 0, loss: 0.0668966993689537
step: 10, loss: 0.03957938775420189
step: 20, loss: 0.0010739059653133154
step: 30, loss: 0.0803215503692627
step: 40, loss: 0.05119332671165466
step: 50, loss: 0.08686137199401855
step: 60, loss: 0.06802570074796677
step: 70, loss: 0.02005593851208687
step: 80, loss: 0.013324961997568607
step: 90, loss: 0.04905136674642563
step: 100, loss: 0.0240121278911829
step: 110, loss: 0.052812181413173676
step: 120, loss: 0.02436545491218567
step: 130, loss: 0.02780689112842083
step: 140, loss: 0.0001701266155578196
step: 150, loss: 0.029016323387622833
step: 160, loss: 0.010628893040120602
step: 170, loss: 9.234388562617823e-05
step: 180, loss: 5.55124061065726e-05
step: 190, loss: 0.024319328367710114
step: 200, loss: 0.000209018136956729
step: 210, loss: 0.022300327196717262
step: 220, loss: 0.01776151731610298
step: 230, loss: 0.031080249696969986
step: 240, loss: 0.0004449145926628262
step: 250, loss: 0.020702095702290535
step: 260, loss: 0.0316949263215065
step: 270, loss: 0.047609299421310425
step: 280, loss: 0.0068816086277365685
step: 290, loss: 0.03950290009379387
step: 300, loss: 0.023202674463391304
step: 310, loss: 2.584459252830129e-05
step: 320, loss: 0.03851751610636711
step: 330, loss: 0.0008879988454282284
step: 340, loss: 0.09439211338758469
step: 350, loss: 0.05150696262717247
step: 360, loss: 0.07019136101007462
step: 370, loss: 8.241708565037698e-05
step: 380, loss: 0.041308559477329254
step: 390, loss: 0.00016179050726350397
step: 400, loss: 0.07056033611297607
step: 410, loss: 0.04254327714443207
step: 420, loss: 1.2725480701192282e-05
step: 430, loss: 3.394309533177875e-05
step: 440, loss: 0.018459418788552284
step: 450, loss: 0.02287944220006466
step: 460, loss: 5.1761031500063837e-05
epoch 17: dev_f1=0.9932432432432432, f1=0.9821029082774049, best_f1=0.9809203142536477
step: 0, loss: 0.01495645847171545
step: 10, loss: 0.06704429537057877
step: 20, loss: 0.0026897687930613756
step: 30, loss: 0.054545316845178604
step: 40, loss: 0.0026702741160988808
step: 50, loss: 0.06009091064333916
step: 60, loss: 0.060493163764476776
step: 70, loss: 0.06958338618278503
step: 80, loss: 0.00026325712678954005
step: 90, loss: 0.043861065059900284
step: 100, loss: 0.023965943604707718
step: 110, loss: 0.0499718151986599
step: 120, loss: 0.06335948407649994
step: 130, loss: 0.023093581199645996
step: 140, loss: 0.02367376908659935
step: 150, loss: 0.04873691499233246
step: 160, loss: 0.03986461088061333
step: 170, loss: 0.03228769451379776
step: 180, loss: 0.03763312101364136
step: 190, loss: 0.038568783551454544
step: 200, loss: 0.00014421093510463834
step: 210, loss: 0.04772916063666344
step: 220, loss: 0.04153485968708992
step: 230, loss: 0.00029154191724956036
step: 240, loss: 0.06814190745353699
step: 250, loss: 0.05411863699555397
step: 260, loss: 0.020675858482718468
step: 270, loss: 0.017002178356051445
step: 280, loss: 0.04098300635814667
step: 290, loss: 0.06147712469100952
step: 300, loss: 0.017690807580947876
step: 310, loss: 2.6596546376822516e-05
step: 320, loss: 0.012966837733983994
step: 330, loss: 0.04747554287314415
step: 340, loss: 0.04416797682642937
step: 350, loss: 0.02914154902100563
step: 360, loss: 0.05547196790575981
step: 370, loss: 0.02135058306157589
step: 380, loss: 0.03636539354920387
step: 390, loss: 0.0530049130320549
step: 400, loss: 0.11206304281949997
step: 410, loss: 0.0001438794715795666
step: 420, loss: 0.11143161356449127
step: 430, loss: 0.042789965867996216
step: 440, loss: 0.023030007258057594
step: 450, loss: 0.06122036650776863
step: 460, loss: 0.023471198976039886
epoch 18: dev_f1=0.992108229988726, f1=0.9831649831649831, best_f1=0.9809203142536477
step: 0, loss: 3.4742854040814564e-05
step: 10, loss: 0.0941675677895546
step: 20, loss: 0.03501860797405243
step: 30, loss: 0.03338606655597687
step: 40, loss: 0.04211624339222908
step: 50, loss: 0.021399788558483124
step: 60, loss: 2.1159101379453205e-05
step: 70, loss: 0.1109243854880333
step: 80, loss: 0.0016186714638024569
step: 90, loss: 0.018984638154506683
step: 100, loss: 1.965042065421585e-05
step: 110, loss: 0.022320060059428215
step: 120, loss: 0.0471871979534626
step: 130, loss: 0.016171904280781746
step: 140, loss: 0.02491295151412487
step: 150, loss: 0.00023092536139301956
step: 160, loss: 0.044950615614652634
step: 170, loss: 0.00870266929268837
step: 180, loss: 0.0005664346972480416
step: 190, loss: 0.01555839367210865
step: 200, loss: 0.027871113270521164
step: 210, loss: 0.010724109597504139
step: 220, loss: 0.012755189090967178
step: 230, loss: 0.09176535159349442
step: 240, loss: 2.828793913067784e-05
step: 250, loss: 0.026329280808568
step: 260, loss: 0.02679312415421009
step: 270, loss: 0.016909129917621613
step: 280, loss: 0.0004146930295974016
step: 290, loss: 0.021911464631557465
step: 300, loss: 0.05994143709540367
step: 310, loss: 0.010313715785741806
step: 320, loss: 0.023125840350985527
step: 330, loss: 0.02695579268038273
step: 340, loss: 0.042161330580711365
step: 350, loss: 0.055189210921525955
step: 360, loss: 0.036044154316186905
step: 370, loss: 0.08832074701786041
step: 380, loss: 0.01876281574368477
step: 390, loss: 0.024536140263080597
step: 400, loss: 0.022207166999578476
step: 410, loss: 2.5177936549880542e-05
step: 420, loss: 0.04100775718688965
step: 430, loss: 0.05152944102883339
step: 440, loss: 0.047579359263181686
step: 450, loss: 0.00010774841939564794
step: 460, loss: 0.02658887207508087
epoch 19: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9809203142536477
step: 0, loss: 0.13787850737571716
step: 10, loss: 0.04132094979286194
step: 20, loss: 0.04373915493488312
step: 30, loss: 0.02481362782418728
step: 40, loss: 3.142436980851926e-05
step: 50, loss: 0.021428091451525688
step: 60, loss: 0.012380316853523254
step: 70, loss: 0.03662759065628052
step: 80, loss: 0.01924888603389263
step: 90, loss: 2.7583824703469872e-05
step: 100, loss: 0.025893796235322952
step: 110, loss: 0.07176772505044937
step: 120, loss: 6.693560862913728e-05
step: 130, loss: 0.0003560510231181979
step: 140, loss: 0.039745643734931946
step: 150, loss: 0.0001465448149247095
step: 160, loss: 0.05013793334364891
step: 170, loss: 0.06400765478610992
step: 180, loss: 0.050051599740982056
step: 190, loss: 0.0660017803311348
step: 200, loss: 0.011636685580015182
step: 210, loss: 0.02283165231347084
step: 220, loss: 0.023956703022122383
step: 230, loss: 7.555317279184237e-05
step: 240, loss: 2.879800376831554e-05
step: 250, loss: 0.04930790513753891
step: 260, loss: 8.225264900829643e-05
step: 270, loss: 0.026681995019316673
step: 280, loss: 0.018256140872836113
step: 290, loss: 0.07035285979509354
step: 300, loss: 0.022207804024219513
step: 310, loss: 0.07630854099988937
step: 320, loss: 0.008923185057938099
step: 330, loss: 0.022854546085000038
step: 340, loss: 0.02398526668548584
step: 350, loss: 0.044027671217918396
step: 360, loss: 5.742007851949893e-05
step: 370, loss: 0.007927436381578445
step: 380, loss: 0.017522180452942848
step: 390, loss: 0.00039314330206252635
step: 400, loss: 0.040069565176963806
step: 410, loss: 0.024240242317318916
step: 420, loss: 0.0369991697371006
step: 430, loss: 0.03225946053862572
step: 440, loss: 2.1221780116320588e-05
step: 450, loss: 0.04120836406946182
step: 460, loss: 0.07556913048028946
epoch 20: dev_f1=0.9932432432432432, f1=0.9831649831649831, best_f1=0.9809203142536477
