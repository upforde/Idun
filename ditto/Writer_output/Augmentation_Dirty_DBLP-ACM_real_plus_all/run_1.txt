cuda
Device: cuda
step: 0, loss: 0.6500034332275391
step: 10, loss: 0.4393480122089386
step: 20, loss: 0.3002888858318329
step: 30, loss: 0.26638007164001465
step: 40, loss: 0.29415297508239746
step: 50, loss: 0.1427873969078064
step: 60, loss: 0.19102789461612701
step: 70, loss: 0.3387397825717926
step: 80, loss: 0.264126718044281
step: 90, loss: 0.12088329344987869
step: 100, loss: 0.21511654555797577
step: 110, loss: 0.11682891845703125
step: 120, loss: 0.1923157423734665
step: 130, loss: 0.246934711933136
step: 140, loss: 0.09874497354030609
step: 150, loss: 0.213560551404953
step: 160, loss: 0.1254630982875824
step: 170, loss: 0.16612543165683746
step: 180, loss: 0.10440636426210403
step: 190, loss: 0.12199929356575012
step: 200, loss: 0.23769813776016235
step: 210, loss: 0.16068951785564423
step: 220, loss: 0.07057300955057144
step: 230, loss: 0.1403246819972992
step: 240, loss: 0.13312865793704987
step: 250, loss: 0.10611952841281891
step: 260, loss: 0.19318220019340515
step: 270, loss: 0.10500688850879669
step: 280, loss: 0.023444131016731262
step: 290, loss: 0.17088155448436737
step: 300, loss: 0.1656549870967865
step: 310, loss: 0.11539819091558456
step: 320, loss: 0.11676151305437088
step: 330, loss: 0.06560360640287399
step: 340, loss: 0.11254040896892548
step: 350, loss: 0.12242401391267776
step: 360, loss: 0.12550033628940582
step: 370, loss: 0.09304444491863251
step: 380, loss: 0.1353185623884201
step: 390, loss: 0.08972316980361938
step: 400, loss: 0.11997320502996445
step: 410, loss: 0.04883146286010742
step: 420, loss: 0.03495363891124725
step: 430, loss: 0.1325409859418869
step: 440, loss: 0.08694252371788025
step: 450, loss: 0.11307232081890106
step: 460, loss: 0.06611665338277817
epoch 1: dev_f1=0.9808342728297633, f1=0.9648127128263336, best_f1=0.9648127128263336
step: 0, loss: 0.16191206872463226
step: 10, loss: 0.06930185854434967
step: 20, loss: 0.08831103146076202
step: 30, loss: 0.16782207787036896
step: 40, loss: 0.022823495790362358
step: 50, loss: 0.04660415276885033
step: 60, loss: 0.04144152253866196
step: 70, loss: 0.17980793118476868
step: 80, loss: 0.10589767247438431
step: 90, loss: 0.07231994718313217
step: 100, loss: 0.20407281816005707
step: 110, loss: 0.03722833842039108
step: 120, loss: 0.10497410595417023
step: 130, loss: 0.13343746960163116
step: 140, loss: 0.11091797053813934
step: 150, loss: 0.05190950632095337
step: 160, loss: 0.021568432450294495
step: 170, loss: 0.16130317747592926
step: 180, loss: 0.06119103357195854
step: 190, loss: 0.04812122881412506
step: 200, loss: 0.08953103423118591
step: 210, loss: 0.016799386590719223
step: 220, loss: 0.07627023011445999
step: 230, loss: 0.1163138672709465
step: 240, loss: 0.16261033713817596
step: 250, loss: 0.08244258910417557
step: 260, loss: 0.058302633464336395
step: 270, loss: 0.03244733437895775
step: 280, loss: 0.13676053285598755
step: 290, loss: 0.05613461881875992
step: 300, loss: 0.0494702011346817
step: 310, loss: 0.03701835125684738
step: 320, loss: 0.061163585633039474
step: 330, loss: 0.15925335884094238
step: 340, loss: 0.09980674833059311
step: 350, loss: 0.008161565288901329
step: 360, loss: 0.10192779451608658
step: 370, loss: 0.10173831135034561
step: 380, loss: 0.02578137069940567
step: 390, loss: 0.24073901772499084
step: 400, loss: 0.07491892576217651
step: 410, loss: 0.06047691032290459
step: 420, loss: 0.025704415515065193
step: 430, loss: 0.05127209052443504
step: 440, loss: 0.10250236839056015
step: 450, loss: 0.10479021817445755
step: 460, loss: 0.04846300929784775
epoch 2: dev_f1=0.9898534385569334, f1=0.9797297297297298, best_f1=0.9797297297297298
step: 0, loss: 0.0007721568108536303
step: 10, loss: 0.11148311197757721
step: 20, loss: 0.06919015944004059
step: 30, loss: 0.06197398155927658
step: 40, loss: 0.08624198287725449
step: 50, loss: 0.07976506650447845
step: 60, loss: 0.018569335341453552
step: 70, loss: 0.07165727764368057
step: 80, loss: 0.06377775967121124
step: 90, loss: 0.09693645685911179
step: 100, loss: 0.06645635515451431
step: 110, loss: 0.16542889177799225
step: 120, loss: 0.01061196904629469
step: 130, loss: 0.08673560619354248
step: 140, loss: 0.029229499399662018
step: 150, loss: 0.01852978952229023
step: 160, loss: 0.05316656827926636
step: 170, loss: 0.14658547937870026
step: 180, loss: 0.109488844871521
step: 190, loss: 0.015034847892820835
step: 200, loss: 0.16004882752895355
step: 210, loss: 0.10614527761936188
step: 220, loss: 0.13040557503700256
step: 230, loss: 0.03379087895154953
step: 240, loss: 0.03667224198579788
step: 250, loss: 0.21658051013946533
step: 260, loss: 0.06956163048744202
step: 270, loss: 0.21660076081752777
step: 280, loss: 0.03493516892194748
step: 290, loss: 0.06983792036771774
step: 300, loss: 0.11834768950939178
step: 310, loss: 0.016176875680685043
step: 320, loss: 0.13388709723949432
step: 330, loss: 0.11257468163967133
step: 340, loss: 0.05374263599514961
step: 350, loss: 0.07387837767601013
step: 360, loss: 0.10737112164497375
step: 370, loss: 0.09127295762300491
step: 380, loss: 0.011019941419363022
step: 390, loss: 0.06876575201749802
step: 400, loss: 0.02778513729572296
step: 410, loss: 0.08590438216924667
step: 420, loss: 0.028312796726822853
step: 430, loss: 0.10357742756605148
step: 440, loss: 0.020624013617634773
step: 450, loss: 0.11090626567602158
step: 460, loss: 0.045400407165288925
epoch 3: dev_f1=0.992108229988726, f1=0.9807909604519773, best_f1=0.9807909604519773
step: 0, loss: 0.05360540375113487
step: 10, loss: 0.022555910050868988
step: 20, loss: 0.046303149312734604
step: 30, loss: 0.12395539879798889
step: 40, loss: 0.16507592797279358
step: 50, loss: 0.06028525158762932
step: 60, loss: 0.08100302517414093
step: 70, loss: 0.1275625377893448
step: 80, loss: 0.14146296679973602
step: 90, loss: 0.05387779697775841
step: 100, loss: 0.15760307013988495
step: 110, loss: 0.1538882553577423
step: 120, loss: 0.04696854576468468
step: 130, loss: 0.06359931826591492
step: 140, loss: 0.052549876272678375
step: 150, loss: 0.029654473066329956
step: 160, loss: 0.14537334442138672
step: 170, loss: 0.07294704020023346
step: 180, loss: 0.06712349504232407
step: 190, loss: 0.030353588983416557
step: 200, loss: 0.022840194404125214
step: 210, loss: 0.0580916702747345
step: 220, loss: 0.035383421927690506
step: 230, loss: 0.02723478339612484
step: 240, loss: 0.07442528009414673
step: 250, loss: 0.17852090299129486
step: 260, loss: 0.021922700107097626
step: 270, loss: 0.04681205749511719
step: 280, loss: 0.143254816532135
step: 290, loss: 0.08743655681610107
step: 300, loss: 0.03147827461361885
step: 310, loss: 0.060897741466760635
step: 320, loss: 0.09338371455669403
step: 330, loss: 0.0847184956073761
step: 340, loss: 0.14384621381759644
step: 350, loss: 0.009452186524868011
step: 360, loss: 0.0411776602268219
step: 370, loss: 0.01271834783256054
step: 380, loss: 0.11980298161506653
step: 390, loss: 0.14304928481578827
step: 400, loss: 0.02785593271255493
step: 410, loss: 0.040659304708242416
step: 420, loss: 0.0724475309252739
step: 430, loss: 0.06335503607988358
step: 440, loss: 0.060151152312755585
step: 450, loss: 0.07395291328430176
step: 460, loss: 0.15924744307994843
epoch 4: dev_f1=0.9921436588103255, f1=0.9809203142536477, best_f1=0.9809203142536477
step: 0, loss: 0.19936063885688782
step: 10, loss: 0.12973441183567047
step: 20, loss: 0.03410439193248749
step: 30, loss: 0.05580289289355278
step: 40, loss: 0.1488320678472519
step: 50, loss: 0.04734615981578827
step: 60, loss: 0.07450231164693832
step: 70, loss: 0.08687559515237808
step: 80, loss: 0.072699636220932
step: 90, loss: 0.04569399729371071
step: 100, loss: 0.07447873800992966
step: 110, loss: 0.18870413303375244
step: 120, loss: 0.03595399856567383
step: 130, loss: 0.07697062939405441
step: 140, loss: 0.08784501999616623
step: 150, loss: 0.08191460371017456
step: 160, loss: 0.018735259771347046
step: 170, loss: 0.12736767530441284
step: 180, loss: 0.029279280453920364
step: 190, loss: 0.12736491858959198
step: 200, loss: 0.09675067663192749
step: 210, loss: 0.09952132403850555
step: 220, loss: 0.06604327261447906
step: 230, loss: 0.16600756347179413
step: 240, loss: 0.12659013271331787
step: 250, loss: 0.03160829842090607
step: 260, loss: 0.02857048064470291
step: 270, loss: 0.08085545152425766
step: 280, loss: 0.009415869601070881
step: 290, loss: 0.018702233210206032
step: 300, loss: 0.014231090433895588
step: 310, loss: 0.0067374068312346935
step: 320, loss: 0.08289702981710434
step: 330, loss: 0.021201517432928085
step: 340, loss: 0.026848481968045235
step: 350, loss: 0.0499364510178566
step: 360, loss: 0.03166722133755684
step: 370, loss: 0.06262227892875671
step: 380, loss: 0.08079615980386734
step: 390, loss: 0.06458177417516708
step: 400, loss: 0.01552870124578476
step: 410, loss: 0.02343766763806343
step: 420, loss: 0.07213924825191498
step: 430, loss: 0.02622106298804283
step: 440, loss: 0.07480616867542267
step: 450, loss: 0.08848781138658524
step: 460, loss: 0.13112543523311615
epoch 5: dev_f1=0.9910313901345291, f1=0.977728285077951, best_f1=0.9809203142536477
step: 0, loss: 0.011079518124461174
step: 10, loss: 0.08904501050710678
step: 20, loss: 0.046399615705013275
step: 30, loss: 0.048499319702386856
step: 40, loss: 0.04832281917333603
step: 50, loss: 0.10232026875019073
step: 60, loss: 0.06584841012954712
step: 70, loss: 0.0839042216539383
step: 80, loss: 0.05987213924527168
step: 90, loss: 0.06699875742197037
step: 100, loss: 0.026843568310141563
step: 110, loss: 0.055486101657152176
step: 120, loss: 0.046008143573999405
step: 130, loss: 0.17699533700942993
step: 140, loss: 0.08756520599126816
step: 150, loss: 0.12346968054771423
step: 160, loss: 0.0286954864859581
step: 170, loss: 0.06376916915178299
step: 180, loss: 0.13725776970386505
step: 190, loss: 0.18160869181156158
step: 200, loss: 0.04094158485531807
step: 210, loss: 0.09375932812690735
step: 220, loss: 0.07086837291717529
step: 230, loss: 0.13894771039485931
step: 240, loss: 0.058699771761894226
step: 250, loss: 0.14105673134326935
step: 260, loss: 0.019919177517294884
step: 270, loss: 0.07590880990028381
step: 280, loss: 0.04658263176679611
step: 290, loss: 0.018983211368322372
step: 300, loss: 0.14735251665115356
step: 310, loss: 0.06510321795940399
step: 320, loss: 0.006317830644547939
step: 330, loss: 0.03570406883955002
step: 340, loss: 0.07899744063615799
step: 350, loss: 0.15408478677272797
step: 360, loss: 0.1236334890127182
step: 370, loss: 0.09095347672700882
step: 380, loss: 0.22845232486724854
step: 390, loss: 0.024702850729227066
step: 400, loss: 0.08235624432563782
step: 410, loss: 0.047986820340156555
step: 420, loss: 0.06351455301046371
step: 430, loss: 0.07094567269086838
step: 440, loss: 0.12444937229156494
step: 450, loss: 0.11346691101789474
step: 460, loss: 0.01932574436068535
epoch 6: dev_f1=0.9887640449438202, f1=0.9820224719101124, best_f1=0.9809203142536477
step: 0, loss: 0.06483401358127594
step: 10, loss: 0.06701784580945969
step: 20, loss: 0.15515047311782837
step: 30, loss: 0.015240327455103397
step: 40, loss: 0.012449903413653374
step: 50, loss: 0.0742083191871643
step: 60, loss: 0.07723860442638397
step: 70, loss: 0.09467534720897675
step: 80, loss: 0.0649125799536705
step: 90, loss: 0.07482022047042847
step: 100, loss: 0.11774304509162903
step: 110, loss: 0.10266956686973572
step: 120, loss: 0.07288920879364014
step: 130, loss: 0.08185292035341263
step: 140, loss: 0.042936597019433975
step: 150, loss: 0.05475331097841263
step: 160, loss: 0.20233626663684845
step: 170, loss: 0.018133070319890976
step: 180, loss: 0.10741408914327621
step: 190, loss: 0.028359808027744293
step: 200, loss: 0.13766580820083618
step: 210, loss: 0.05765580013394356
step: 220, loss: 0.11167214810848236
step: 230, loss: 0.030698763206601143
step: 240, loss: 0.15530145168304443
step: 250, loss: 0.10975481569766998
step: 260, loss: 0.010782802477478981
step: 270, loss: 0.033084686845541
step: 280, loss: 0.01701859012246132
step: 290, loss: 0.023914719000458717
step: 300, loss: 2.4273622329928912e-05
step: 310, loss: 0.06592262536287308
step: 320, loss: 0.12021809071302414
step: 330, loss: 0.0346997007727623
step: 340, loss: 0.10110512375831604
step: 350, loss: 0.03806403651833534
step: 360, loss: 0.08761376887559891
step: 370, loss: 0.1193949431180954
step: 380, loss: 0.023107945919036865
step: 390, loss: 0.05796029791235924
step: 400, loss: 0.002531361998990178
step: 410, loss: 0.053750913590192795
step: 420, loss: 0.04683072492480278
step: 430, loss: 0.04499257728457451
step: 440, loss: 0.05086236447095871
step: 450, loss: 0.11197322607040405
step: 460, loss: 0.08482590317726135
epoch 7: dev_f1=0.9910313901345291, f1=0.983277591973244, best_f1=0.9809203142536477
step: 0, loss: 0.06284336745738983
step: 10, loss: 0.09817183017730713
step: 20, loss: 0.02437477558851242
step: 30, loss: 0.0038243657909333706
step: 40, loss: 0.01881329156458378
step: 50, loss: 0.05157036334276199
step: 60, loss: 0.07933906465768814
step: 70, loss: 0.06042942404747009
step: 80, loss: 0.1250605434179306
step: 90, loss: 0.01962796039879322
step: 100, loss: 0.04204625263810158
step: 110, loss: 0.04710562527179718
step: 120, loss: 0.00957562681287527
step: 130, loss: 0.019077405333518982
step: 140, loss: 0.07448854297399521
step: 150, loss: 0.06009548529982567
step: 160, loss: 0.1093917265534401
step: 170, loss: 0.009292985312640667
step: 180, loss: 0.026826493442058563
step: 190, loss: 0.0707583874464035
step: 200, loss: 0.04670114070177078
step: 210, loss: 0.09311500191688538
step: 220, loss: 0.13423913717269897
step: 230, loss: 0.03891606628894806
step: 240, loss: 0.045809436589479446
step: 250, loss: 0.07947587966918945
step: 260, loss: 0.01288975216448307
step: 270, loss: 8.435477502644062e-05
step: 280, loss: 5.1685816288227215e-05
step: 290, loss: 0.06773416697978973
step: 300, loss: 0.11490415781736374
step: 310, loss: 0.06600000709295273
step: 320, loss: 0.06828345358371735
step: 330, loss: 0.013781925663352013
step: 340, loss: 0.038028791546821594
step: 350, loss: 0.06359828263521194
step: 360, loss: 0.03630264848470688
step: 370, loss: 0.12690141797065735
step: 380, loss: 0.09515449404716492
step: 390, loss: 0.021451037377119064
step: 400, loss: 0.07393064349889755
step: 410, loss: 0.056037649512290955
step: 420, loss: 0.15380437672138214
step: 430, loss: 0.10618187487125397
step: 440, loss: 0.08255240321159363
step: 450, loss: 0.012239704839885235
step: 460, loss: 0.04653260111808777
epoch 8: dev_f1=0.9898762654668166, f1=0.9819819819819819, best_f1=0.9809203142536477
step: 0, loss: 0.07450183480978012
step: 10, loss: 0.023588191717863083
step: 20, loss: 0.07476622611284256
step: 30, loss: 0.00013967939594294876
step: 40, loss: 0.05504839867353439
step: 50, loss: 0.029385164380073547
step: 60, loss: 0.019284136593341827
step: 70, loss: 0.04907206818461418
step: 80, loss: 0.0313517302274704
step: 90, loss: 0.05612551048398018
step: 100, loss: 0.05563049018383026
step: 110, loss: 0.040679533034563065
step: 120, loss: 0.02240891382098198
step: 130, loss: 0.13804364204406738
step: 140, loss: 0.07277257740497589
step: 150, loss: 0.02099718153476715
step: 160, loss: 0.031168628484010696
step: 170, loss: 0.07196489721536636
step: 180, loss: 0.06454696506261826
step: 190, loss: 0.06218506023287773
step: 200, loss: 0.012671095319092274
step: 210, loss: 0.0738251656293869
step: 220, loss: 0.029326889663934708
step: 230, loss: 0.07144951820373535
step: 240, loss: 0.11381912231445312
step: 250, loss: 0.1009320393204689
step: 260, loss: 0.030912723392248154
step: 270, loss: 0.0376250185072422
step: 280, loss: 0.02016611583530903
step: 290, loss: 0.01795976422727108
step: 300, loss: 0.039510853588581085
step: 310, loss: 0.01341126300394535
step: 320, loss: 0.11822101473808289
step: 330, loss: 0.053599052131175995
step: 340, loss: 0.028127729892730713
step: 350, loss: 0.11714886128902435
step: 360, loss: 0.06045225262641907
step: 370, loss: 0.048995569348335266
step: 380, loss: 0.07416118681430817
step: 390, loss: 0.05475889891386032
step: 400, loss: 0.06469085812568665
step: 410, loss: 0.09399396181106567
step: 420, loss: 0.17272673547267914
step: 430, loss: 0.012603356502950191
step: 440, loss: 0.1194976419210434
step: 450, loss: 0.025321921333670616
step: 460, loss: 0.10686582326889038
epoch 9: dev_f1=0.9887387387387387, f1=0.9808342728297633, best_f1=0.9809203142536477
step: 0, loss: 0.033939655870199203
step: 10, loss: 0.0895269587635994
step: 20, loss: 0.13677248358726501
step: 30, loss: 0.08041031658649445
step: 40, loss: 0.03445550054311752
step: 50, loss: 0.09243933856487274
step: 60, loss: 0.0784289538860321
step: 70, loss: 0.06518400460481644
step: 80, loss: 0.07081722468137741
step: 90, loss: 0.05670313537120819
step: 100, loss: 0.1248156949877739
step: 110, loss: 0.05463535711169243
step: 120, loss: 0.02410922199487686
step: 130, loss: 0.030007291585206985
step: 140, loss: 0.08089376240968704
step: 150, loss: 0.05748285353183746
step: 160, loss: 0.024653201922774315
step: 170, loss: 0.04529288783669472
step: 180, loss: 0.0063887969590723515
step: 190, loss: 0.029638247564435005
step: 200, loss: 0.052037257701158524
step: 210, loss: 0.014755330048501492
step: 220, loss: 0.1227022111415863
step: 230, loss: 0.049270279705524445
step: 240, loss: 0.0028955014422535896
step: 250, loss: 0.05855131521821022
step: 260, loss: 0.10277161002159119
step: 270, loss: 0.07552953064441681
step: 280, loss: 0.06040286272764206
step: 290, loss: 0.11126358807086945
step: 300, loss: 0.020898565649986267
step: 310, loss: 0.013907818123698235
step: 320, loss: 0.0454283244907856
step: 330, loss: 0.08760111033916473
step: 340, loss: 0.03960712254047394
step: 350, loss: 0.027820657938718796
step: 360, loss: 0.024297457188367844
step: 370, loss: 0.060417015105485916
step: 380, loss: 0.00696110213175416
step: 390, loss: 0.050291527062654495
step: 400, loss: 0.05804877728223801
step: 410, loss: 0.055594414472579956
step: 420, loss: 0.03257422149181366
step: 430, loss: 0.024928316473960876
step: 440, loss: 0.09570209681987762
step: 450, loss: 0.03986642509698868
step: 460, loss: 0.03731546923518181
epoch 10: dev_f1=0.990990990990991, f1=0.9797297297297298, best_f1=0.9809203142536477
step: 0, loss: 0.04082996025681496
step: 10, loss: 0.03798113763332367
step: 20, loss: 0.015044944360852242
step: 30, loss: 0.04716114699840546
step: 40, loss: 0.05319751426577568
step: 50, loss: 0.03861900418996811
step: 60, loss: 0.09507893025875092
step: 70, loss: 0.0015685141552239656
step: 80, loss: 0.04138217493891716
step: 90, loss: 0.0023520037066191435
step: 100, loss: 0.04789343476295471
step: 110, loss: 0.04366137087345123
step: 120, loss: 0.0886320099234581
step: 130, loss: 0.03636282682418823
step: 140, loss: 0.0565003827214241
step: 150, loss: 0.03713884949684143
step: 160, loss: 0.05475575104355812
step: 170, loss: 0.10559548437595367
step: 180, loss: 0.12625472247600555
step: 190, loss: 0.007916422560811043
step: 200, loss: 0.13521352410316467
step: 210, loss: 0.12136678397655487
step: 220, loss: 0.06820473074913025
step: 230, loss: 0.03311538323760033
step: 240, loss: 0.05074947699904442
step: 250, loss: 0.06265590339899063
step: 260, loss: 0.07126767933368683
step: 270, loss: 0.25812625885009766
step: 280, loss: 0.06366868317127228
step: 290, loss: 0.08472573012113571
step: 300, loss: 0.03648671507835388
step: 310, loss: 0.03304717689752579
step: 320, loss: 0.06617982685565948
step: 330, loss: 0.021543197333812714
step: 340, loss: 0.10476958751678467
step: 350, loss: 0.054695822298526764
step: 360, loss: 0.07285338640213013
step: 370, loss: 0.01955590583384037
step: 380, loss: 0.02790587767958641
step: 390, loss: 0.10020942240953445
step: 400, loss: 0.0305927786976099
step: 410, loss: 0.03242277726531029
step: 420, loss: 0.12629224359989166
step: 430, loss: 0.11127742379903793
step: 440, loss: 0.06625774502754211
step: 450, loss: 0.024737441912293434
step: 460, loss: 0.0652424767613411
epoch 11: dev_f1=0.9898762654668166, f1=0.9808342728297633, best_f1=0.9809203142536477
step: 0, loss: 0.012985181994736195
step: 10, loss: 0.023242294788360596
step: 20, loss: 0.05518301576375961
step: 30, loss: 0.025592420250177383
step: 40, loss: 0.00885464996099472
step: 50, loss: 0.00931328721344471
step: 60, loss: 0.03921924903988838
step: 70, loss: 0.032147664576768875
step: 80, loss: 0.07593297958374023
step: 90, loss: 0.07589232176542282
step: 100, loss: 0.00914344098418951
step: 110, loss: 0.2949897050857544
step: 120, loss: 0.02685907483100891
step: 130, loss: 0.026553159579634666
step: 140, loss: 0.03701876848936081
step: 150, loss: 0.046475477516651154
step: 160, loss: 1.7922078768606298e-05
step: 170, loss: 0.014858359470963478
step: 180, loss: 0.0015535493148490787
step: 190, loss: 0.09263955056667328
step: 200, loss: 0.013725005090236664
step: 210, loss: 0.10849211364984512
step: 220, loss: 0.05947533994913101
step: 230, loss: 0.022037610411643982
step: 240, loss: 0.15973129868507385
step: 250, loss: 0.04434390366077423
step: 260, loss: 0.00039129352080635726
step: 270, loss: 0.05097539722919464
step: 280, loss: 0.07495839148759842
step: 290, loss: 0.025143008679151535
step: 300, loss: 0.09165006130933762
step: 310, loss: 0.07027997076511383
step: 320, loss: 0.044643666595220566
step: 330, loss: 0.09772401303052902
step: 340, loss: 0.05104769766330719
step: 350, loss: 0.08755863457918167
step: 360, loss: 0.07094351947307587
step: 370, loss: 0.040327731519937515
step: 380, loss: 0.05699843913316727
step: 390, loss: 0.05429026857018471
step: 400, loss: 0.0018941429443657398
step: 410, loss: 0.035676974803209305
step: 420, loss: 0.10264331847429276
step: 430, loss: 0.06563307344913483
step: 440, loss: 0.09185443818569183
step: 450, loss: 0.05427408963441849
step: 460, loss: 0.20701639354228973
epoch 12: dev_f1=0.9898534385569334, f1=0.9820224719101124, best_f1=0.9809203142536477
step: 0, loss: 0.05739739537239075
step: 10, loss: 0.04195449873805046
step: 20, loss: 0.018547935411334038
step: 30, loss: 0.004165487829595804
step: 40, loss: 0.009050358086824417
step: 50, loss: 0.0953657329082489
step: 60, loss: 0.04751094430685043
step: 70, loss: 0.011767741292715073
step: 80, loss: 8.506314770784229e-05
step: 90, loss: 0.028454257175326347
step: 100, loss: 0.006527184043079615
step: 110, loss: 0.021926799789071083
step: 120, loss: 0.062471188604831696
step: 130, loss: 0.024371998384594917
step: 140, loss: 0.04470092058181763
step: 150, loss: 0.05372409150004387
step: 160, loss: 0.00012162535131210461
step: 170, loss: 0.10209782421588898
step: 180, loss: 0.029704006388783455
step: 190, loss: 0.088838592171669
step: 200, loss: 0.02295057848095894
step: 210, loss: 0.017116524279117584
step: 220, loss: 0.09195305407047272
step: 230, loss: 0.0692487433552742
step: 240, loss: 0.046631935983896255
step: 250, loss: 0.022402655333280563
step: 260, loss: 0.053096603602170944
step: 270, loss: 0.03291924670338631
step: 280, loss: 0.04674377664923668
step: 290, loss: 0.11050379276275635
step: 300, loss: 0.052068036049604416
step: 310, loss: 0.02324819192290306
step: 320, loss: 0.024297775700688362
step: 330, loss: 0.08355638384819031
step: 340, loss: 0.06494322419166565
step: 350, loss: 0.0527808703482151
step: 360, loss: 0.0005024900892749429
step: 370, loss: 0.0933779627084732
step: 380, loss: 0.03362635523080826
step: 390, loss: 0.0731310173869133
step: 400, loss: 0.02244408242404461
step: 410, loss: 0.1820075809955597
step: 420, loss: 0.03466623276472092
step: 430, loss: 0.0188978873193264
step: 440, loss: 0.043383803218603134
step: 450, loss: 0.10763907432556152
step: 460, loss: 0.038466814905405045
epoch 13: dev_f1=0.9898534385569334, f1=0.9773755656108598, best_f1=0.9809203142536477
step: 0, loss: 0.001877237344160676
step: 10, loss: 0.04577739164233208
step: 20, loss: 0.08253943920135498
step: 30, loss: 0.04852531477808952
step: 40, loss: 0.00033227010862901807
step: 50, loss: 0.09005957841873169
step: 60, loss: 0.02845216915011406
step: 70, loss: 0.04218793660402298
step: 80, loss: 0.017891157418489456
step: 90, loss: 0.07581434398889542
step: 100, loss: 0.03558176010847092
step: 110, loss: 0.06087633967399597
step: 120, loss: 0.0021976314019411802
step: 130, loss: 0.01575981080532074
step: 140, loss: 0.06555668264627457
step: 150, loss: 0.06442143768072128
step: 160, loss: 0.04540714621543884
step: 170, loss: 0.06645303964614868
step: 180, loss: 0.02207329496741295
step: 190, loss: 0.044964294880628586
step: 200, loss: 0.07245234400033951
step: 210, loss: 0.006927088834345341
step: 220, loss: 0.02256905473768711
step: 230, loss: 0.0033085355535149574
step: 240, loss: 0.11884257197380066
step: 250, loss: 0.06412822008132935
step: 260, loss: 6.0474107158370316e-05
step: 270, loss: 0.03648784011602402
step: 280, loss: 0.024686314165592194
step: 290, loss: 0.02953748032450676
step: 300, loss: 0.10217930376529694
step: 310, loss: 0.030319247394800186
step: 320, loss: 0.02300022915005684
step: 330, loss: 0.0005505862063728273
step: 340, loss: 0.05788309499621391
step: 350, loss: 0.1032717227935791
step: 360, loss: 0.07432827353477478
step: 370, loss: 0.02317444048821926
step: 380, loss: 0.0043041338212788105
step: 390, loss: 0.20477737486362457
step: 400, loss: 0.002094242488965392
step: 410, loss: 0.020169567316770554
step: 420, loss: 0.008226427249610424
step: 430, loss: 0.048325315117836
step: 440, loss: 0.02225654572248459
step: 450, loss: 0.10050324350595474
step: 460, loss: 0.013777786865830421
epoch 14: dev_f1=0.9898305084745763, f1=0.9785310734463276, best_f1=0.9809203142536477
step: 0, loss: 0.027571843937039375
step: 10, loss: 0.019381897523999214
step: 20, loss: 0.03250144049525261
step: 30, loss: 0.03443138673901558
step: 40, loss: 0.046240486204624176
step: 50, loss: 0.04391228035092354
step: 60, loss: 0.007530422415584326
step: 70, loss: 0.015387386083602905
step: 80, loss: 0.038920775055885315
step: 90, loss: 0.10072296857833862
step: 100, loss: 0.00011863339750561863
step: 110, loss: 0.043481677770614624
step: 120, loss: 0.03272619470953941
step: 130, loss: 0.019527561962604523
step: 140, loss: 0.18676918745040894
step: 150, loss: 0.04952342435717583
step: 160, loss: 0.10930375754833221
step: 170, loss: 0.02332940883934498
step: 180, loss: 0.01824199967086315
step: 190, loss: 0.14588329195976257
step: 200, loss: 0.03447841852903366
step: 210, loss: 0.009427749551832676
step: 220, loss: 0.0004355857672635466
step: 230, loss: 0.0001067035918822512
step: 240, loss: 0.044858649373054504
step: 250, loss: 0.00881171878427267
step: 260, loss: 0.014956637285649776
step: 270, loss: 0.05115779489278793
step: 280, loss: 0.0232061967253685
step: 290, loss: 0.11470824480056763
step: 300, loss: 0.0010347723728045821
step: 310, loss: 0.011757888831198215
step: 320, loss: 0.03177928179502487
step: 330, loss: 0.01621686853468418
step: 340, loss: 0.02674640342593193
step: 350, loss: 0.04648938402533531
step: 360, loss: 0.01918935962021351
step: 370, loss: 0.0003625545941758901
step: 380, loss: 0.01887117512524128
step: 390, loss: 0.042743634432554245
step: 400, loss: 0.0002029698807746172
step: 410, loss: 0.027584481984376907
step: 420, loss: 0.0690847784280777
step: 430, loss: 0.14533348381519318
step: 440, loss: 0.01993909664452076
step: 450, loss: 0.1103193387389183
step: 460, loss: 0.06073806807398796
epoch 15: dev_f1=0.990990990990991, f1=0.9808342728297633, best_f1=0.9809203142536477
step: 0, loss: 0.04058064520359039
step: 10, loss: 0.09087128937244415
step: 20, loss: 0.030416784808039665
step: 30, loss: 0.039055824279785156
step: 40, loss: 0.03388754650950432
step: 50, loss: 0.032235853374004364
step: 60, loss: 0.025123609229922295
step: 70, loss: 0.021378424018621445
step: 80, loss: 1.5772619008203037e-05
step: 90, loss: 0.00046440106234513223
step: 100, loss: 0.03191136196255684
step: 110, loss: 0.04159044846892357
step: 120, loss: 0.04481726512312889
step: 130, loss: 0.010606463998556137
step: 140, loss: 0.04094519838690758
step: 150, loss: 0.04265148192644119
step: 160, loss: 0.03237675130367279
step: 170, loss: 0.04005163162946701
step: 180, loss: 6.0283156926743686e-05
step: 190, loss: 0.07661391794681549
step: 200, loss: 0.06066754460334778
step: 210, loss: 0.031829748302698135
step: 220, loss: 0.0160438884049654
step: 230, loss: 0.06386803835630417
step: 240, loss: 0.04553396999835968
step: 250, loss: 0.004715200047940016
step: 260, loss: 0.022040167823433876
step: 270, loss: 0.04875703155994415
step: 280, loss: 0.022802680730819702
step: 290, loss: 0.0844528004527092
step: 300, loss: 0.08468889445066452
step: 310, loss: 0.044746123254299164
step: 320, loss: 0.04860832169651985
step: 330, loss: 3.9060887502273545e-05
step: 340, loss: 0.06895387172698975
step: 350, loss: 0.0789199247956276
step: 360, loss: 0.03199014440178871
step: 370, loss: 0.02139497548341751
step: 380, loss: 0.034765709191560745
step: 390, loss: 0.02769273705780506
step: 400, loss: 0.0033331485465168953
step: 410, loss: 0.035162609070539474
step: 420, loss: 0.004882946144789457
step: 430, loss: 0.04410868138074875
step: 440, loss: 0.02711659111082554
step: 450, loss: 0.047252357006073
step: 460, loss: 0.02281814068555832
epoch 16: dev_f1=0.9909706546275394, f1=0.9773755656108598, best_f1=0.9809203142536477
step: 0, loss: 0.00018126043141819537
step: 10, loss: 0.021476201713085175
step: 20, loss: 0.0427890308201313
step: 30, loss: 0.02220163866877556
step: 40, loss: 0.17453506588935852
step: 50, loss: 0.047971613705158234
step: 60, loss: 0.0037735134828835726
step: 70, loss: 2.801824848575052e-05
step: 80, loss: 0.05344117805361748
step: 90, loss: 0.06991661339998245
step: 100, loss: 0.04135497286915779
step: 110, loss: 0.08337704837322235
step: 120, loss: 0.02333229035139084
step: 130, loss: 0.01755540445446968
step: 140, loss: 2.7529633371159434e-05
step: 150, loss: 7.544698746642098e-05
step: 160, loss: 0.0004589111777022481
step: 170, loss: 4.073210948263295e-05
step: 180, loss: 0.05332663655281067
step: 190, loss: 0.06551820039749146
step: 200, loss: 0.0387665256857872
step: 210, loss: 0.04168745502829552
step: 220, loss: 0.05626211687922478
step: 230, loss: 0.048275526612997055
step: 240, loss: 1.6398395018768497e-05
step: 250, loss: 0.025105804204940796
step: 260, loss: 0.00037651610909961164
step: 270, loss: 0.043239839375019073
step: 280, loss: 0.082914337515831
step: 290, loss: 0.04868445172905922
step: 300, loss: 0.029785972088575363
step: 310, loss: 0.0006455849506892264
step: 320, loss: 0.02656332403421402
step: 330, loss: 0.01870540715754032
step: 340, loss: 0.0027332978788763285
step: 350, loss: 0.004619285464286804
step: 360, loss: 0.018536429852247238
step: 370, loss: 0.01990356110036373
step: 380, loss: 0.015052485279738903
step: 390, loss: 0.013947864063084126
step: 400, loss: 0.03832961618900299
step: 410, loss: 0.0940011739730835
step: 420, loss: 0.0002060629049083218
step: 430, loss: 0.06197907030582428
step: 440, loss: 0.0009805895388126373
step: 450, loss: 0.06732684373855591
step: 460, loss: 0.04384792968630791
epoch 17: dev_f1=0.9898534385569334, f1=0.976271186440678, best_f1=0.9809203142536477
step: 0, loss: 0.00019830507517326623
step: 10, loss: 0.045348767191171646
step: 20, loss: 0.04284011572599411
step: 30, loss: 0.02822796255350113
step: 40, loss: 0.020139075815677643
step: 50, loss: 2.065236185444519e-05
step: 60, loss: 0.0003208811685908586
step: 70, loss: 0.0006792921340093017
step: 80, loss: 0.0034428949002176523
step: 90, loss: 0.00020275077258702368
step: 100, loss: 0.0013436274603009224
step: 110, loss: 0.1830577850341797
step: 120, loss: 0.039428889751434326
step: 130, loss: 0.07104797661304474
step: 140, loss: 9.450941433897242e-05
step: 150, loss: 0.05220363661646843
step: 160, loss: 0.11895369738340378
step: 170, loss: 0.01749199628829956
step: 180, loss: 0.051477476954460144
step: 190, loss: 0.0005043537239544094
step: 200, loss: 0.00223818002268672
step: 210, loss: 0.01533186063170433
step: 220, loss: 0.04657639190554619
step: 230, loss: 0.06927374750375748
step: 240, loss: 0.03124239854514599
step: 250, loss: 0.04134141281247139
step: 260, loss: 0.06493503600358963
step: 270, loss: 0.02626538835465908
step: 280, loss: 0.10817272961139679
step: 290, loss: 0.0007985779084265232
step: 300, loss: 0.07499143481254578
step: 310, loss: 0.01467504445463419
step: 320, loss: 0.062366921454668045
step: 330, loss: 0.036060865968465805
step: 340, loss: 0.03003806807100773
step: 350, loss: 0.013970782049000263
step: 360, loss: 0.04592078924179077
step: 370, loss: 0.023494968190789223
step: 380, loss: 0.06254927068948746
step: 390, loss: 0.020575175061821938
step: 400, loss: 0.018216315656900406
step: 410, loss: 0.00013263466826174408
step: 420, loss: 0.03632635995745659
step: 430, loss: 0.02284804731607437
step: 440, loss: 0.02315361797809601
step: 450, loss: 0.007872301153838634
step: 460, loss: 0.0033060116693377495
epoch 18: dev_f1=0.9909706546275394, f1=0.9785310734463276, best_f1=0.9809203142536477
step: 0, loss: 0.057968512177467346
step: 10, loss: 0.007498063147068024
step: 20, loss: 0.018662773072719574
step: 30, loss: 1.238261211256031e-05
step: 40, loss: 0.05690731108188629
step: 50, loss: 0.02608947455883026
step: 60, loss: 0.042644210159778595
step: 70, loss: 0.030177228152751923
step: 80, loss: 0.04600915685296059
step: 90, loss: 0.05549013987183571
step: 100, loss: 0.001425012364052236
step: 110, loss: 0.0279842559248209
step: 120, loss: 4.1876075556501746e-05
step: 130, loss: 0.05829741433262825
step: 140, loss: 0.048246126621961594
step: 150, loss: 0.10783132910728455
step: 160, loss: 0.013568839058279991
step: 170, loss: 0.025526398792862892
step: 180, loss: 0.009457843378186226
step: 190, loss: 0.0025335021782666445
step: 200, loss: 0.04752466455101967
step: 210, loss: 0.037315815687179565
step: 220, loss: 0.05421820282936096
step: 230, loss: 0.04241139069199562
step: 240, loss: 0.0035028583370149136
step: 250, loss: 0.05177907273173332
step: 260, loss: 0.08215148001909256
step: 270, loss: 7.603305130032822e-05
step: 280, loss: 0.037436168640851974
step: 290, loss: 0.06013810634613037
step: 300, loss: 0.023311831057071686
step: 310, loss: 0.06725459545850754
step: 320, loss: 0.018112780526280403
step: 330, loss: 0.034979961812496185
step: 340, loss: 0.06484322994947433
step: 350, loss: 0.05483272671699524
step: 360, loss: 0.00010042299254564568
step: 370, loss: 0.028655650094151497
step: 380, loss: 0.018361762166023254
step: 390, loss: 0.018987298011779785
step: 400, loss: 0.050049617886543274
step: 410, loss: 1.8108195945387706e-05
step: 420, loss: 0.00027422321727499366
step: 430, loss: 0.002624071668833494
step: 440, loss: 0.04574131965637207
step: 450, loss: 0.06166217103600502
step: 460, loss: 0.025251396000385284
epoch 19: dev_f1=0.9909706546275394, f1=0.9796839729119639, best_f1=0.9809203142536477
step: 0, loss: 0.07241301238536835
step: 10, loss: 0.07479283213615417
step: 20, loss: 0.04821576923131943
step: 30, loss: 0.04446810483932495
step: 40, loss: 0.026651572436094284
step: 50, loss: 0.04490101337432861
step: 60, loss: 0.02884853072464466
step: 70, loss: 0.042071156203746796
step: 80, loss: 2.0998008039896376e-05
step: 90, loss: 0.0395507737994194
step: 100, loss: 0.04239749535918236
step: 110, loss: 0.053072571754455566
step: 120, loss: 0.030450157821178436
step: 130, loss: 0.005680108442902565
step: 140, loss: 0.03208979591727257
step: 150, loss: 0.023629605770111084
step: 160, loss: 0.009356264024972916
step: 170, loss: 0.0214548297226429
step: 180, loss: 0.07115812599658966
step: 190, loss: 0.059891656041145325
step: 200, loss: 0.07557682693004608
step: 210, loss: 0.06829804927110672
step: 220, loss: 0.05886237695813179
step: 230, loss: 0.034624531865119934
step: 240, loss: 0.024695785716176033
step: 250, loss: 0.08123503625392914
step: 260, loss: 1.9482584320940077e-05
step: 270, loss: 0.01600293442606926
step: 280, loss: 0.019812051206827164
step: 290, loss: 0.03761826455593109
step: 300, loss: 0.02576272562146187
step: 310, loss: 0.04578641802072525
step: 320, loss: 0.04520951956510544
step: 330, loss: 0.03801831975579262
step: 340, loss: 0.0397571325302124
step: 350, loss: 0.013724184595048428
step: 360, loss: 0.028335487470030785
step: 370, loss: 5.0658225518418476e-05
step: 380, loss: 4.435547816683538e-05
step: 390, loss: 0.07133776694536209
step: 400, loss: 0.017892513424158096
step: 410, loss: 0.030707743018865585
step: 420, loss: 0.03539060056209564
step: 430, loss: 0.030019886791706085
step: 440, loss: 0.030298380181193352
step: 450, loss: 0.00829123705625534
step: 460, loss: 0.018780488520860672
epoch 20: dev_f1=0.9909706546275394, f1=0.9785310734463276, best_f1=0.9809203142536477
