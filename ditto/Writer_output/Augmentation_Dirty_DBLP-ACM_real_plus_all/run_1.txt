cuda
Device: cuda
step: 0, loss: 0.7389647364616394
step: 10, loss: 0.4546229839324951
step: 20, loss: 0.5043415427207947
step: 30, loss: 0.3775680363178253
step: 40, loss: 0.2531885504722595
step: 50, loss: 0.2604309022426605
step: 60, loss: 0.2713380455970764
step: 70, loss: 0.07533866912126541
step: 80, loss: 0.282722145318985
step: 90, loss: 0.2877160608768463
step: 100, loss: 0.11909350007772446
step: 110, loss: 0.22314654290676117
step: 120, loss: 0.05044132098555565
step: 130, loss: 0.14235694706439972
step: 140, loss: 0.20238278806209564
step: 150, loss: 0.07695726305246353
step: 160, loss: 0.38630855083465576
step: 170, loss: 0.1845349818468094
step: 180, loss: 0.12215479463338852
step: 190, loss: 0.08670369535684586
step: 200, loss: 0.17384234070777893
step: 210, loss: 0.11602744460105896
step: 220, loss: 0.12102195620536804
step: 230, loss: 0.16151124238967896
step: 240, loss: 0.09039566665887833
step: 250, loss: 0.14076654613018036
step: 260, loss: 0.2111428827047348
step: 270, loss: 0.19091485440731049
step: 280, loss: 0.0919472873210907
step: 290, loss: 0.08208072930574417
step: 300, loss: 0.12504784762859344
step: 310, loss: 0.20007602870464325
step: 320, loss: 0.14529550075531006
step: 330, loss: 0.08127984404563904
step: 340, loss: 0.034088701009750366
step: 350, loss: 0.0697287917137146
step: 360, loss: 0.2304418534040451
step: 370, loss: 0.08740484714508057
step: 380, loss: 0.08636261522769928
step: 390, loss: 0.15195009112358093
step: 400, loss: 0.3154076337814331
step: 410, loss: 0.04757058247923851
step: 420, loss: 0.07247143983840942
step: 430, loss: 0.057785067707300186
step: 440, loss: 0.07220914959907532
step: 450, loss: 0.008121377788484097
step: 460, loss: 0.05874136462807655
epoch 1: dev_f1=0.9773755656108598, f1=0.9783352337514253, best_f1=0.9783352337514253
step: 0, loss: 0.030031800270080566
step: 10, loss: 0.15758109092712402
step: 20, loss: 0.3316899538040161
step: 30, loss: 0.05254923924803734
step: 40, loss: 0.0310650747269392
step: 50, loss: 0.1207721158862114
step: 60, loss: 0.146180659532547
step: 70, loss: 0.18622617423534393
step: 80, loss: 0.18541914224624634
step: 90, loss: 0.1247706487774849
step: 100, loss: 0.06859413534402847
step: 110, loss: 0.034898821264505386
step: 120, loss: 0.010106110014021397
step: 130, loss: 0.06600205600261688
step: 140, loss: 0.04059009253978729
step: 150, loss: 0.06832549721002579
step: 160, loss: 0.11391166597604752
step: 170, loss: 0.04161358252167702
step: 180, loss: 0.05628962814807892
step: 190, loss: 0.06396540999412537
step: 200, loss: 0.042021047323942184
step: 210, loss: 0.09936382621526718
step: 220, loss: 0.05794890597462654
step: 230, loss: 0.09845353662967682
step: 240, loss: 0.06641579419374466
step: 250, loss: 0.16793124377727509
step: 260, loss: 0.041160792112350464
step: 270, loss: 0.06171029433608055
step: 280, loss: 0.06294635683298111
step: 290, loss: 0.056119780987501144
step: 300, loss: 0.0015576551668345928
step: 310, loss: 0.14236682653427124
step: 320, loss: 0.13248707354068756
step: 330, loss: 0.08713585138320923
step: 340, loss: 0.0003948080993723124
step: 350, loss: 0.15717485547065735
step: 360, loss: 0.11549188196659088
step: 370, loss: 0.08025386929512024
step: 380, loss: 0.09676314145326614
step: 390, loss: 0.06482195854187012
step: 400, loss: 0.06673599779605865
step: 410, loss: 0.06450797617435455
step: 420, loss: 0.06458306312561035
step: 430, loss: 0.042120181024074554
step: 440, loss: 0.06975790113210678
step: 450, loss: 0.0845482274889946
step: 460, loss: 0.03486831113696098
epoch 2: dev_f1=0.9876265466816648, f1=0.9852774631936579, best_f1=0.9852774631936579
step: 0, loss: 0.05038735270500183
step: 10, loss: 0.11124752461910248
step: 20, loss: 0.09777126461267471
step: 30, loss: 0.0433066226541996
step: 40, loss: 0.08166748285293579
step: 50, loss: 0.057924289256334305
step: 60, loss: 0.022519927471876144
step: 70, loss: 0.14011436700820923
step: 80, loss: 0.06019250676035881
step: 90, loss: 0.07933145761489868
step: 100, loss: 0.053305014967918396
step: 110, loss: 0.021416276693344116
step: 120, loss: 0.04307474195957184
step: 130, loss: 0.13994604349136353
step: 140, loss: 0.09193107485771179
step: 150, loss: 0.021238533779978752
step: 160, loss: 0.12721703946590424
step: 170, loss: 0.03228306397795677
step: 180, loss: 0.061024658381938934
step: 190, loss: 0.07896512746810913
step: 200, loss: 0.0826704353094101
step: 210, loss: 0.08165767788887024
step: 220, loss: 0.09421150386333466
step: 230, loss: 0.051515985280275345
step: 240, loss: 0.09475375711917877
step: 250, loss: 0.03175226226449013
step: 260, loss: 0.1533648818731308
step: 270, loss: 0.10417944192886353
step: 280, loss: 0.08008505403995514
step: 290, loss: 0.05924249067902565
step: 300, loss: 0.006668590009212494
step: 310, loss: 0.025499925017356873
step: 320, loss: 0.014801526442170143
step: 330, loss: 0.10063529759645462
step: 340, loss: 0.04229405149817467
step: 350, loss: 0.062095630913972855
step: 360, loss: 0.01630442962050438
step: 370, loss: 0.11022797971963882
step: 380, loss: 0.006557940039783716
step: 390, loss: 0.024181511253118515
step: 400, loss: 0.007087730336934328
step: 410, loss: 0.11827056854963303
step: 420, loss: 0.15415087342262268
step: 430, loss: 0.023915981873869896
step: 440, loss: 0.04433572292327881
step: 450, loss: 0.17029403150081635
step: 460, loss: 0.08008471876382828
epoch 3: dev_f1=0.9899216125419933, f1=0.984304932735426, best_f1=0.984304932735426
step: 0, loss: 0.11603891849517822
step: 10, loss: 0.025088869035243988
step: 20, loss: 0.06805948168039322
step: 30, loss: 0.018840668722987175
step: 40, loss: 0.21323494613170624
step: 50, loss: 0.061412300914525986
step: 60, loss: 0.009057114832103252
step: 70, loss: 0.023821040987968445
step: 80, loss: 0.11007926613092422
step: 90, loss: 0.025550097227096558
step: 100, loss: 0.00838558655232191
step: 110, loss: 0.16503684222698212
step: 120, loss: 0.0261132400482893
step: 130, loss: 0.10059161484241486
step: 140, loss: 0.09809143096208572
step: 150, loss: 4.2939755076076835e-05
step: 160, loss: 0.02739693969488144
step: 170, loss: 0.018720760941505432
step: 180, loss: 0.05062577500939369
step: 190, loss: 0.022873396053910255
step: 200, loss: 0.07684151828289032
step: 210, loss: 0.0290994830429554
step: 220, loss: 0.06103154271841049
step: 230, loss: 0.075799860060215
step: 240, loss: 0.14742659032344818
step: 250, loss: 0.06831824779510498
step: 260, loss: 0.043485432863235474
step: 270, loss: 0.08309280872344971
step: 280, loss: 0.0663100928068161
step: 290, loss: 0.06705966591835022
step: 300, loss: 0.16035203635692596
step: 310, loss: 0.04460056871175766
step: 320, loss: 0.02990156225860119
step: 330, loss: 0.08361605554819107
step: 340, loss: 0.001169291092082858
step: 350, loss: 0.007402257062494755
step: 360, loss: 0.09492286294698715
step: 370, loss: 0.046428270637989044
step: 380, loss: 0.13472285866737366
step: 390, loss: 0.08193183690309525
step: 400, loss: 0.04754391312599182
step: 410, loss: 0.07866193354129791
step: 420, loss: 0.08173581957817078
step: 430, loss: 0.06887570768594742
step: 440, loss: 0.0005411214660853148
step: 450, loss: 0.028535550460219383
step: 460, loss: 0.07676774263381958
epoch 4: dev_f1=0.9921436588103255, f1=0.9788182831661093, best_f1=0.9788182831661093
step: 0, loss: 0.015494031831622124
step: 10, loss: 0.016853466629981995
step: 20, loss: 0.057432226836681366
step: 30, loss: 0.06629115343093872
step: 40, loss: 0.009370974265038967
step: 50, loss: 0.053363136947155
step: 60, loss: 0.07497219741344452
step: 70, loss: 0.052676256746053696
step: 80, loss: 0.05579409375786781
step: 90, loss: 0.081255704164505
step: 100, loss: 0.04162945970892906
step: 110, loss: 0.1418629139661789
step: 120, loss: 0.015425324440002441
step: 130, loss: 0.07097040861845016
step: 140, loss: 0.08626744151115417
step: 150, loss: 0.11689327657222748
step: 160, loss: 0.024670301005244255
step: 170, loss: 0.11987707018852234
step: 180, loss: 0.07870509475469589
step: 190, loss: 0.013984055258333683
step: 200, loss: 0.11581039428710938
step: 210, loss: 0.014733340591192245
step: 220, loss: 0.008076830767095089
step: 230, loss: 0.0915021151304245
step: 240, loss: 0.061512548476457596
step: 250, loss: 0.05578334629535675
step: 260, loss: 0.07961349934339523
step: 270, loss: 0.10479415208101273
step: 280, loss: 0.05378996953368187
step: 290, loss: 0.0402822270989418
step: 300, loss: 0.014300956390798092
step: 310, loss: 0.02429048903286457
step: 320, loss: 0.10452022403478622
step: 330, loss: 0.10534235090017319
step: 340, loss: 0.027960989624261856
step: 350, loss: 0.04451657086610794
step: 360, loss: 0.06232517212629318
step: 370, loss: 0.12294358015060425
step: 380, loss: 0.0970248132944107
step: 390, loss: 0.08824887126684189
step: 400, loss: 0.1264159381389618
step: 410, loss: 0.01563436910510063
step: 420, loss: 0.0640694871544838
step: 430, loss: 0.06854301691055298
step: 440, loss: 0.03329017758369446
step: 450, loss: 0.07725397497415543
step: 460, loss: 0.027515342459082603
epoch 5: dev_f1=0.9898989898989898, f1=0.980963045912654, best_f1=0.9788182831661093
step: 0, loss: 0.030323851853609085
step: 10, loss: 0.0833854004740715
step: 20, loss: 0.15982364118099213
step: 30, loss: 0.00673119630664587
step: 40, loss: 0.015110805630683899
step: 50, loss: 0.008093408308923244
step: 60, loss: 0.012107381597161293
step: 70, loss: 0.03929596394300461
step: 80, loss: 0.06529147177934647
step: 90, loss: 0.0570514053106308
step: 100, loss: 0.058050528168678284
step: 110, loss: 0.03934784606099129
step: 120, loss: 0.009600543417036533
step: 130, loss: 0.03899279609322548
step: 140, loss: 0.06321348249912262
step: 150, loss: 0.043897949159145355
step: 160, loss: 0.0005862062098458409
step: 170, loss: 0.06208622455596924
step: 180, loss: 0.016748841851949692
step: 190, loss: 0.13013191521167755
step: 200, loss: 0.05740266665816307
step: 210, loss: 0.10576532781124115
step: 220, loss: 0.13542453944683075
step: 230, loss: 0.1723478138446808
step: 240, loss: 0.07179872691631317
step: 250, loss: 0.03195422515273094
step: 260, loss: 0.08015195280313492
step: 270, loss: 0.0195758119225502
step: 280, loss: 0.052299924194812775
step: 290, loss: 0.0662158876657486
step: 300, loss: 0.02420334704220295
step: 310, loss: 0.00015550902753602713
step: 320, loss: 0.14051270484924316
step: 330, loss: 0.005960067268460989
step: 340, loss: 0.08730952441692352
step: 350, loss: 0.03457563742995262
step: 360, loss: 0.011422314681112766
step: 370, loss: 0.046947792172431946
step: 380, loss: 0.0949767604470253
step: 390, loss: 0.09828858077526093
step: 400, loss: 0.018339386209845543
step: 410, loss: 0.02612747810781002
step: 420, loss: 0.06830315291881561
step: 430, loss: 0.022772159427404404
step: 440, loss: 0.0786152109503746
step: 450, loss: 0.18552598357200623
step: 460, loss: 0.0837714821100235
epoch 6: dev_f1=0.9898989898989898, f1=0.984304932735426, best_f1=0.9788182831661093
step: 0, loss: 0.03406766429543495
step: 10, loss: 0.24251891672611237
step: 20, loss: 0.12286962568759918
step: 30, loss: 0.0875958800315857
step: 40, loss: 0.08220719546079636
step: 50, loss: 0.04368142411112785
step: 60, loss: 0.07006832957267761
step: 70, loss: 0.030622033402323723
step: 80, loss: 0.04691879823803902
step: 90, loss: 0.0753905326128006
step: 100, loss: 0.023067068308591843
step: 110, loss: 0.13756629824638367
step: 120, loss: 0.14658039808273315
step: 130, loss: 0.017330732196569443
step: 140, loss: 0.0592908039689064
step: 150, loss: 0.0255013145506382
step: 160, loss: 0.03284536302089691
step: 170, loss: 0.14239901304244995
step: 180, loss: 0.08807571977376938
step: 190, loss: 0.02065996453166008
step: 200, loss: 0.05934743210673332
step: 210, loss: 6.523614138131961e-05
step: 220, loss: 0.0930468887090683
step: 230, loss: 0.06439273059368134
step: 240, loss: 0.07867156714200974
step: 250, loss: 0.03389894217252731
step: 260, loss: 0.06386927515268326
step: 270, loss: 0.01178235188126564
step: 280, loss: 0.10633798688650131
step: 290, loss: 0.03479927405714989
step: 300, loss: 0.10741245746612549
step: 310, loss: 0.02056577056646347
step: 320, loss: 0.09860491007566452
step: 330, loss: 0.03161018341779709
step: 340, loss: 0.09906714409589767
step: 350, loss: 0.06143081933259964
step: 360, loss: 0.06299019604921341
step: 370, loss: 0.1599336564540863
step: 380, loss: 0.10787943750619888
step: 390, loss: 0.013917377218604088
step: 400, loss: 0.061940599232912064
step: 410, loss: 0.11359786987304688
step: 420, loss: 0.026563528925180435
step: 430, loss: 0.019792089238762856
step: 440, loss: 0.09072273224592209
step: 450, loss: 0.07095026224851608
step: 460, loss: 0.0874158963561058
epoch 7: dev_f1=0.9820224719101124, f1=0.9765363128491621, best_f1=0.9788182831661093
step: 0, loss: 0.0670570358633995
step: 10, loss: 0.05812026932835579
step: 20, loss: 0.007292369846254587
step: 30, loss: 0.04697748273611069
step: 40, loss: 0.1097094863653183
step: 50, loss: 0.07897506654262543
step: 60, loss: 0.021423082798719406
step: 70, loss: 0.008624392561614513
step: 80, loss: 0.11754904687404633
step: 90, loss: 0.02690708637237549
step: 100, loss: 0.049726177006959915
step: 110, loss: 0.05278903618454933
step: 120, loss: 0.016452671959996223
step: 130, loss: 0.1560862958431244
step: 140, loss: 0.07099329680204391
step: 150, loss: 0.022758185863494873
step: 160, loss: 0.11246242374181747
step: 170, loss: 0.06867022812366486
step: 180, loss: 0.08754952251911163
step: 190, loss: 0.06271522492170334
step: 200, loss: 0.046982284635305405
step: 210, loss: 4.611915210261941e-05
step: 220, loss: 0.08004333078861237
step: 230, loss: 0.06231483072042465
step: 240, loss: 0.046641796827316284
step: 250, loss: 0.03680603951215744
step: 260, loss: 0.022427324205636978
step: 270, loss: 0.09186934679746628
step: 280, loss: 0.009950905106961727
step: 290, loss: 0.01248723641037941
step: 300, loss: 0.09169599413871765
step: 310, loss: 0.008171658031642437
step: 320, loss: 0.07740359008312225
step: 330, loss: 0.045038387179374695
step: 340, loss: 0.05301704257726669
step: 350, loss: 0.03961649537086487
step: 360, loss: 0.11906822770833969
step: 370, loss: 0.05262626335024834
step: 380, loss: 0.1138257384300232
step: 390, loss: 0.17169228196144104
step: 400, loss: 0.0158745888620615
step: 410, loss: 0.08025424182415009
step: 420, loss: 0.07965034246444702
step: 430, loss: 0.06461545825004578
step: 440, loss: 0.013458836823701859
step: 450, loss: 0.18826936185359955
step: 460, loss: 0.24950836598873138
epoch 8: dev_f1=0.9887387387387387, f1=0.9787234042553192, best_f1=0.9788182831661093
step: 0, loss: 0.0840739756822586
step: 10, loss: 0.059778038412332535
step: 20, loss: 0.08169405162334442
step: 30, loss: 0.060357626527547836
step: 40, loss: 0.05150622874498367
step: 50, loss: 0.09066426008939743
step: 60, loss: 0.025816384702920914
step: 70, loss: 0.05274257808923721
step: 80, loss: 0.08310543745756149
step: 90, loss: 0.040119778364896774
step: 100, loss: 0.13301363587379456
step: 110, loss: 0.07308817654848099
step: 120, loss: 0.05826517939567566
step: 130, loss: 0.009847653098404408
step: 140, loss: 0.18425646424293518
step: 150, loss: 0.014298399910330772
step: 160, loss: 0.03181075677275658
step: 170, loss: 0.014018589630723
step: 180, loss: 0.08531461656093597
step: 190, loss: 0.11731912195682526
step: 200, loss: 0.004221996292471886
step: 210, loss: 0.06303328275680542
step: 220, loss: 0.007372490130364895
step: 230, loss: 0.05768582224845886
step: 240, loss: 0.02379649318754673
step: 250, loss: 0.025118118152022362
step: 260, loss: 0.03621438518166542
step: 270, loss: 0.013134666718542576
step: 280, loss: 0.02969539910554886
step: 290, loss: 0.12208226323127747
step: 300, loss: 0.010738126933574677
step: 310, loss: 0.03217417001724243
step: 320, loss: 0.004609374795109034
step: 330, loss: 0.01410367339849472
step: 340, loss: 0.04409201070666313
step: 350, loss: 0.04725991189479828
step: 360, loss: 0.10114593803882599
step: 370, loss: 0.052950527518987656
step: 380, loss: 0.018581440672278404
step: 390, loss: 0.1480446308851242
step: 400, loss: 0.07195616513490677
step: 410, loss: 0.14314347505569458
step: 420, loss: 0.05815064162015915
step: 430, loss: 0.08399789780378342
step: 440, loss: 0.07411711663007736
step: 450, loss: 0.023403573781251907
step: 460, loss: 0.07237802445888519
epoch 9: dev_f1=0.9921259842519685, f1=0.9832026875699889, best_f1=0.9788182831661093
step: 0, loss: 0.044689107686281204
step: 10, loss: 0.02270539663732052
step: 20, loss: 0.07579884678125381
step: 30, loss: 0.0844421461224556
step: 40, loss: 0.011071776039898396
step: 50, loss: 0.04533335193991661
step: 60, loss: 0.014716286212205887
step: 70, loss: 0.01870594173669815
step: 80, loss: 0.055067747831344604
step: 90, loss: 0.012851275503635406
step: 100, loss: 0.02306363731622696
step: 110, loss: 0.1471337378025055
step: 120, loss: 0.004100576043128967
step: 130, loss: 0.017266323789954185
step: 140, loss: 0.07687821984291077
step: 150, loss: 0.04281480982899666
step: 160, loss: 0.05882774665951729
step: 170, loss: 0.024829423055052757
step: 180, loss: 0.030687034130096436
step: 190, loss: 0.06608638912439346
step: 200, loss: 0.007712102495133877
step: 210, loss: 0.06716105341911316
step: 220, loss: 0.045332860201597214
step: 230, loss: 0.018078723922371864
step: 240, loss: 0.0014577909605577588
step: 250, loss: 0.03329792991280556
step: 260, loss: 0.019281158223748207
step: 270, loss: 0.09344381093978882
step: 280, loss: 0.04246792197227478
step: 290, loss: 0.0361238531768322
step: 300, loss: 0.024848422035574913
step: 310, loss: 0.14251603186130524
step: 320, loss: 0.05830509215593338
step: 330, loss: 0.03277774155139923
step: 340, loss: 0.0009999695466831326
step: 350, loss: 0.017469244077801704
step: 360, loss: 0.10547946393489838
step: 370, loss: 0.0690811350941658
step: 380, loss: 0.025486266240477562
step: 390, loss: 0.005381665658205748
step: 400, loss: 0.03749379515647888
step: 410, loss: 0.20765553414821625
step: 420, loss: 0.08678315579891205
step: 430, loss: 0.06405560672283173
step: 440, loss: 0.06287701427936554
step: 450, loss: 0.0750110000371933
step: 460, loss: 0.016675498336553574
epoch 10: dev_f1=0.9899216125419933, f1=0.9820224719101124, best_f1=0.9788182831661093
step: 0, loss: 0.026641935110092163
step: 10, loss: 0.0423930287361145
step: 20, loss: 0.015393748879432678
step: 30, loss: 0.0050694807432591915
step: 40, loss: 0.058114055544137955
step: 50, loss: 0.062083713710308075
step: 60, loss: 0.06912895292043686
step: 70, loss: 0.0037305650766938925
step: 80, loss: 0.03199918940663338
step: 90, loss: 0.005871064029633999
step: 100, loss: 0.05563180893659592
step: 110, loss: 0.17337392270565033
step: 120, loss: 0.07851258665323257
step: 130, loss: 0.022709866985678673
step: 140, loss: 0.056906841695308685
step: 150, loss: 0.0357295386493206
step: 160, loss: 0.020074447616934776
step: 170, loss: 0.013042662292718887
step: 180, loss: 0.09757642447948456
step: 190, loss: 0.01822064444422722
step: 200, loss: 0.04937747120857239
step: 210, loss: 0.026608292013406754
step: 220, loss: 0.015096370130777359
step: 230, loss: 0.03516357019543648
step: 240, loss: 0.02189113385975361
step: 250, loss: 0.04551689326763153
step: 260, loss: 0.15256331861019135
step: 270, loss: 0.06165532395243645
step: 280, loss: 0.003661302849650383
step: 290, loss: 0.018091781064867973
step: 300, loss: 0.0014501642435789108
step: 310, loss: 0.15342682600021362
step: 320, loss: 0.030775010585784912
step: 330, loss: 0.04451456665992737
step: 340, loss: 0.03815007954835892
step: 350, loss: 0.01412791758775711
step: 360, loss: 0.05901582911610603
step: 370, loss: 0.10168080776929855
step: 380, loss: 0.0015049988869577646
step: 390, loss: 0.13098610937595367
step: 400, loss: 0.11304943263530731
step: 410, loss: 0.004414686001837254
step: 420, loss: 0.01944701373577118
step: 430, loss: 0.029188815504312515
step: 440, loss: 0.01445827167481184
step: 450, loss: 0.11458637565374374
step: 460, loss: 0.05247786268591881
epoch 11: dev_f1=0.9932584269662922, f1=0.9843400447427293, best_f1=0.9843400447427293
step: 0, loss: 0.09305094182491302
step: 10, loss: 0.03749675676226616
step: 20, loss: 0.016311870887875557
step: 30, loss: 0.00140963529702276
step: 40, loss: 0.05601699277758598
step: 50, loss: 0.052179377526044846
step: 60, loss: 0.00892442837357521
step: 70, loss: 0.031366851180791855
step: 80, loss: 0.018812865018844604
step: 90, loss: 0.044304147362709045
step: 100, loss: 0.026616189628839493
step: 110, loss: 0.021642809733748436
step: 120, loss: 0.05278179049491882
step: 130, loss: 0.07329554855823517
step: 140, loss: 0.021994279697537422
step: 150, loss: 0.041857022792100906
step: 160, loss: 0.029821302741765976
step: 170, loss: 0.0022075665183365345
step: 180, loss: 0.10125970095396042
step: 190, loss: 0.046808306127786636
step: 200, loss: 0.09286380559206009
step: 210, loss: 0.02364177815616131
step: 220, loss: 0.06277374178171158
step: 230, loss: 0.03251280263066292
step: 240, loss: 0.021354833617806435
step: 250, loss: 2.3584199880133383e-05
step: 260, loss: 0.013584689237177372
step: 270, loss: 0.002267886186018586
step: 280, loss: 0.0338096022605896
step: 290, loss: 0.016967052593827248
step: 300, loss: 3.96768627979327e-05
step: 310, loss: 0.01611117646098137
step: 320, loss: 0.054826006293296814
step: 330, loss: 0.009201017208397388
step: 340, loss: 0.00043918838491663337
step: 350, loss: 0.005527441389858723
step: 360, loss: 0.12237157672643661
step: 370, loss: 0.04350399971008301
step: 380, loss: 0.002088577952235937
step: 390, loss: 0.015079287812113762
step: 400, loss: 0.09946922957897186
step: 410, loss: 0.10225887596607208
step: 420, loss: 0.08703414350748062
step: 430, loss: 0.03330383822321892
step: 440, loss: 0.06594213843345642
step: 450, loss: 0.012478990480303764
step: 460, loss: 0.007872299291193485
epoch 12: dev_f1=0.9887640449438202, f1=0.9810479375696767, best_f1=0.9843400447427293
step: 0, loss: 0.040204502642154694
step: 10, loss: 0.03500114381313324
step: 20, loss: 0.05404525622725487
step: 30, loss: 0.022481046617031097
step: 40, loss: 0.236364483833313
step: 50, loss: 0.00865272618830204
step: 60, loss: 0.049555979669094086
step: 70, loss: 0.0015569223323836923
step: 80, loss: 0.027301698923110962
step: 90, loss: 0.0478142574429512
step: 100, loss: 0.05222452059388161
step: 110, loss: 0.02030782215297222
step: 120, loss: 0.20435771346092224
step: 130, loss: 0.046052947640419006
step: 140, loss: 0.02656654827296734
step: 150, loss: 0.00031078566098585725
step: 160, loss: 0.08842366933822632
step: 170, loss: 0.039071887731552124
step: 180, loss: 0.008277901448309422
step: 190, loss: 0.042909327894449234
step: 200, loss: 0.01553285401314497
step: 210, loss: 0.05342698097229004
step: 220, loss: 0.025652406737208366
step: 230, loss: 0.06803999841213226
step: 240, loss: 0.0019205206772312522
step: 250, loss: 0.002511821687221527
step: 260, loss: 0.029939129948616028
step: 270, loss: 0.06867296993732452
step: 280, loss: 0.042400553822517395
step: 290, loss: 0.04276903346180916
step: 300, loss: 0.1201191321015358
step: 310, loss: 0.0001469964045099914
step: 320, loss: 0.04580814391374588
step: 330, loss: 0.02144143171608448
step: 340, loss: 0.1646774858236313
step: 350, loss: 6.73608883516863e-05
step: 360, loss: 0.10355933755636215
step: 370, loss: 0.07483141124248505
step: 380, loss: 0.12347777932882309
step: 390, loss: 0.10735204815864563
step: 400, loss: 0.08875801414251328
step: 410, loss: 0.05687691271305084
step: 420, loss: 3.9277616451727226e-05
step: 430, loss: 0.04036349803209305
step: 440, loss: 0.025575270876288414
step: 450, loss: 0.05053943395614624
step: 460, loss: 0.0216330885887146
epoch 13: dev_f1=0.9910112359550561, f1=0.9821029082774049, best_f1=0.9843400447427293
step: 0, loss: 0.0002088410110445693
step: 10, loss: 0.0005336620379239321
step: 20, loss: 0.03889504820108414
step: 30, loss: 0.0007857451564632356
step: 40, loss: 0.0001010756241157651
step: 50, loss: 0.046054694801568985
step: 60, loss: 0.02224850468337536
step: 70, loss: 0.015978394076228142
step: 80, loss: 0.049469538033008575
step: 90, loss: 0.03960290923714638
step: 100, loss: 0.09832745790481567
step: 110, loss: 0.046489231288433075
step: 120, loss: 0.0010217521339654922
step: 130, loss: 0.0852525532245636
step: 140, loss: 0.02235441468656063
step: 150, loss: 0.02243613824248314
step: 160, loss: 0.0004252942744642496
step: 170, loss: 0.028604736551642418
step: 180, loss: 0.00014985990128479898
step: 190, loss: 0.01280897855758667
step: 200, loss: 0.06960791349411011
step: 210, loss: 0.041659411042928696
step: 220, loss: 0.05149979144334793
step: 230, loss: 0.024326996877789497
step: 240, loss: 0.007011359091848135
step: 250, loss: 6.010585275362246e-05
step: 260, loss: 0.034665677696466446
step: 270, loss: 0.0003689487057272345
step: 280, loss: 0.041043393313884735
step: 290, loss: 2.1062192899989896e-05
step: 300, loss: 0.017050763592123985
step: 310, loss: 0.025662951171398163
step: 320, loss: 0.03732260689139366
step: 330, loss: 0.03684212267398834
step: 340, loss: 0.023244185373187065
step: 350, loss: 0.042218029499053955
step: 360, loss: 0.0456126444041729
step: 370, loss: 0.02551289089024067
step: 380, loss: 0.053620584309101105
step: 390, loss: 0.0898457020521164
step: 400, loss: 0.014940042980015278
step: 410, loss: 0.0018792070914059877
step: 420, loss: 0.018598441034555435
step: 430, loss: 0.02277996763586998
step: 440, loss: 0.02023014985024929
step: 450, loss: 0.039579302072525024
step: 460, loss: 0.060369882732629776
epoch 14: dev_f1=0.9921436588103255, f1=0.9832026875699889, best_f1=0.9843400447427293
step: 0, loss: 0.025469478219747543
step: 10, loss: 0.014516623690724373
step: 20, loss: 0.023617783561348915
step: 30, loss: 9.90834305412136e-05
step: 40, loss: 0.019425351172685623
step: 50, loss: 0.02630005031824112
step: 60, loss: 0.0005272309645079076
step: 70, loss: 0.07807286828756332
step: 80, loss: 0.040848515927791595
step: 90, loss: 0.02312881499528885
step: 100, loss: 0.014848855324089527
step: 110, loss: 0.004916357807815075
step: 120, loss: 0.024779187515378
step: 130, loss: 0.07220402359962463
step: 140, loss: 0.0008783516241237521
step: 150, loss: 0.02665741927921772
step: 160, loss: 0.09053806960582733
step: 170, loss: 0.0982825756072998
step: 180, loss: 0.046723730862140656
step: 190, loss: 0.04489997774362564
step: 200, loss: 0.02976228855550289
step: 210, loss: 0.0002246494113933295
step: 220, loss: 0.11483526974916458
step: 230, loss: 8.826748671708629e-05
step: 240, loss: 0.02932952716946602
step: 250, loss: 0.039853256195783615
step: 260, loss: 0.06221779063344002
step: 270, loss: 0.04447203502058983
step: 280, loss: 0.0004928786074742675
step: 290, loss: 0.04355929046869278
step: 300, loss: 0.08574823290109634
step: 310, loss: 0.0914526879787445
step: 320, loss: 0.016430743038654327
step: 330, loss: 7.519801147282124e-05
step: 340, loss: 0.004850158467888832
step: 350, loss: 0.0376148521900177
step: 360, loss: 4.4434680603444576e-05
step: 370, loss: 0.006625472102314234
step: 380, loss: 0.029403340071439743
step: 390, loss: 0.062177058309316635
step: 400, loss: 0.018516002222895622
step: 410, loss: 0.0008752550929784775
step: 420, loss: 0.07310396432876587
step: 430, loss: 0.07807189971208572
step: 440, loss: 0.024892976507544518
step: 450, loss: 0.028824489563703537
step: 460, loss: 0.0001407041127094999
epoch 15: dev_f1=0.9921259842519685, f1=0.984304932735426, best_f1=0.9843400447427293
step: 0, loss: 0.08613527566194534
step: 10, loss: 0.09888816624879837
step: 20, loss: 0.023358546197414398
step: 30, loss: 0.06359768658876419
step: 40, loss: 0.022770477458834648
step: 50, loss: 0.09737805277109146
step: 60, loss: 0.00022479801555164158
step: 70, loss: 0.041090622544288635
step: 80, loss: 0.08063645660877228
step: 90, loss: 0.0003916153509635478
step: 100, loss: 0.0012106156209483743
step: 110, loss: 0.06955461204051971
step: 120, loss: 0.018150126561522484
step: 130, loss: 0.0633382648229599
step: 140, loss: 0.01729583740234375
step: 150, loss: 0.025016942992806435
step: 160, loss: 0.0873839482665062
step: 170, loss: 0.01987050287425518
step: 180, loss: 0.07416307181119919
step: 190, loss: 0.0889645591378212
step: 200, loss: 0.06402439624071121
step: 210, loss: 0.02074497938156128
step: 220, loss: 0.0004725271137431264
step: 230, loss: 0.03784186765551567
step: 240, loss: 0.04366437718272209
step: 250, loss: 0.07470913231372833
step: 260, loss: 0.07984918355941772
step: 270, loss: 8.842071110848337e-05
step: 280, loss: 0.023912740871310234
step: 290, loss: 0.028186345472931862
step: 300, loss: 0.018983645364642143
step: 310, loss: 0.10642776638269424
step: 320, loss: 0.00044913325109519064
step: 330, loss: 0.05367017537355423
step: 340, loss: 0.01764417439699173
step: 350, loss: 0.0023272077087312937
step: 360, loss: 0.025887222960591316
step: 370, loss: 0.019667111337184906
step: 380, loss: 0.02285817451775074
step: 390, loss: 0.020325250923633575
step: 400, loss: 0.02060362882912159
step: 410, loss: 0.0208384171128273
step: 420, loss: 0.022758418694138527
step: 430, loss: 0.04223659634590149
step: 440, loss: 0.039417803287506104
step: 450, loss: 0.0028879090677946806
step: 460, loss: 4.870552584179677e-05
epoch 16: dev_f1=0.9932584269662922, f1=0.984304932735426, best_f1=0.9843400447427293
step: 0, loss: 0.0001302612799918279
step: 10, loss: 0.0011218093568459153
step: 20, loss: 0.020164158195257187
step: 30, loss: 0.02851647138595581
step: 40, loss: 0.015955232083797455
step: 50, loss: 0.02380707859992981
step: 60, loss: 0.00016300998686347157
step: 70, loss: 0.04193517193198204
step: 80, loss: 0.06123373657464981
step: 90, loss: 0.017559675499796867
step: 100, loss: 0.0006576069281436503
step: 110, loss: 0.019074294716119766
step: 120, loss: 0.03888912871479988
step: 130, loss: 0.024998748674988747
step: 140, loss: 0.09097275137901306
step: 150, loss: 0.022212032228708267
step: 160, loss: 0.0043152086436748505
step: 170, loss: 0.03758442774415016
step: 180, loss: 0.0024917430710047483
step: 190, loss: 0.01886056177318096
step: 200, loss: 0.031138980761170387
step: 210, loss: 0.005693214479833841
step: 220, loss: 0.00030634598806500435
step: 230, loss: 0.03623153641819954
step: 240, loss: 0.00016869140381459147
step: 250, loss: 0.00020349140686448663
step: 260, loss: 0.0003916531568393111
step: 270, loss: 0.040358059108257294
step: 280, loss: 0.043084003031253815
step: 290, loss: 0.0006864124443382025
step: 300, loss: 0.02652718685567379
step: 310, loss: 0.08215409517288208
step: 320, loss: 0.057476431131362915
step: 330, loss: 0.06802671402692795
step: 340, loss: 0.00016119977226480842
step: 350, loss: 0.05046931654214859
step: 360, loss: 0.0001466320682084188
step: 370, loss: 0.023803237825632095
step: 380, loss: 0.04100737348198891
step: 390, loss: 0.06952093541622162
step: 400, loss: 0.05769328027963638
step: 410, loss: 0.04020087793469429
step: 420, loss: 0.05315948277711868
step: 430, loss: 0.00024324403784703463
step: 440, loss: 0.019978202879428864
step: 450, loss: 0.013865436427295208
step: 460, loss: 0.017439236864447594
epoch 17: dev_f1=0.9932584269662922, f1=0.9831649831649831, best_f1=0.9843400447427293
step: 0, loss: 0.057045672088861465
step: 10, loss: 0.027882006019353867
step: 20, loss: 0.0001082755989045836
step: 30, loss: 0.00023453609901480377
step: 40, loss: 0.0017220234731212258
step: 50, loss: 0.0308522991836071
step: 60, loss: 0.00018129115051124245
step: 70, loss: 0.0001611788320587948
step: 80, loss: 5.800123471999541e-05
step: 90, loss: 0.07071686536073685
step: 100, loss: 0.04767373204231262
step: 110, loss: 0.020810412243008614
step: 120, loss: 0.02743801474571228
step: 130, loss: 0.03257519379258156
step: 140, loss: 0.023986469954252243
step: 150, loss: 0.042695093899965286
step: 160, loss: 0.06172696128487587
step: 170, loss: 0.06370680779218674
step: 180, loss: 0.0017253959085792303
step: 190, loss: 0.06124453991651535
step: 200, loss: 0.026510421186685562
step: 210, loss: 0.05577544867992401
step: 220, loss: 0.0199139267206192
step: 230, loss: 0.019816556945443153
step: 240, loss: 0.04167237505316734
step: 250, loss: 0.051297083497047424
step: 260, loss: 0.00043751264456659555
step: 270, loss: 0.04010749235749245
step: 280, loss: 7.979152724146843e-05
step: 290, loss: 0.05063742399215698
step: 300, loss: 0.019289469346404076
step: 310, loss: 0.00022314846864901483
step: 320, loss: 0.011889674700796604
step: 330, loss: 0.014040672220289707
step: 340, loss: 0.022250989452004433
step: 350, loss: 0.04330285266041756
step: 360, loss: 0.00030162237817421556
step: 370, loss: 0.02306855283677578
step: 380, loss: 0.0001732403616188094
step: 390, loss: 0.0011552651412785053
step: 400, loss: 0.017532601952552795
step: 410, loss: 0.05783519893884659
step: 420, loss: 0.03726334497332573
step: 430, loss: 0.14313659071922302
step: 440, loss: 0.03020486794412136
step: 450, loss: 0.1224655956029892
step: 460, loss: 7.420625479426235e-05
epoch 18: dev_f1=0.9921259842519685, f1=0.9831649831649831, best_f1=0.9843400447427293
step: 0, loss: 0.03005916252732277
step: 10, loss: 0.0006500349845737219
step: 20, loss: 0.014855110086500645
step: 30, loss: 0.01779980957508087
step: 40, loss: 0.059672676026821136
step: 50, loss: 7.849401299608871e-05
step: 60, loss: 0.024096520617604256
step: 70, loss: 0.10322622209787369
step: 80, loss: 0.023917360231280327
step: 90, loss: 0.07169035077095032
step: 100, loss: 0.022126443684101105
step: 110, loss: 0.07766484469175339
step: 120, loss: 0.058994438499212265
step: 130, loss: 0.026292912662029266
step: 140, loss: 0.03713119029998779
step: 150, loss: 0.049117282032966614
step: 160, loss: 0.05122549086809158
step: 170, loss: 9.254699398297817e-05
step: 180, loss: 0.00021422813006211072
step: 190, loss: 0.07867909222841263
step: 200, loss: 0.01827634871006012
step: 210, loss: 0.042353492230176926
step: 220, loss: 0.019515540450811386
step: 230, loss: 0.0620914027094841
step: 240, loss: 0.03312554582953453
step: 250, loss: 0.0526253879070282
step: 260, loss: 2.2510697817779146e-05
step: 270, loss: 0.00024126670905388892
step: 280, loss: 0.01862356811761856
step: 290, loss: 0.04446562007069588
step: 300, loss: 0.024730676785111427
step: 310, loss: 0.03379443287849426
step: 320, loss: 0.0626644492149353
step: 330, loss: 0.0544600710272789
step: 340, loss: 0.022694336250424385
step: 350, loss: 7.010337867541239e-05
step: 360, loss: 0.051188088953495026
step: 370, loss: 8.317895117215812e-05
step: 380, loss: 8.515442459611222e-05
step: 390, loss: 0.05364333838224411
step: 400, loss: 0.0439283587038517
step: 410, loss: 0.24456830322742462
step: 420, loss: 0.04519588127732277
step: 430, loss: 0.00010117779311258346
step: 440, loss: 0.06168249994516373
step: 450, loss: 0.021370921283960342
step: 460, loss: 0.06390248239040375
epoch 19: dev_f1=0.9932584269662922, f1=0.9831649831649831, best_f1=0.9843400447427293
step: 0, loss: 0.045575518161058426
step: 10, loss: 0.0001314295659540221
step: 20, loss: 6.291674799285829e-05
step: 30, loss: 0.022016607224941254
step: 40, loss: 0.002873537130653858
step: 50, loss: 0.10876041650772095
step: 60, loss: 0.03960489481687546
step: 70, loss: 0.044771213084459305
step: 80, loss: 0.029065271839499474
step: 90, loss: 0.05259120464324951
step: 100, loss: 0.10965778678655624
step: 110, loss: 0.034923043102025986
step: 120, loss: 0.012264097109436989
step: 130, loss: 0.00025618073414079845
step: 140, loss: 0.036755893379449844
step: 150, loss: 0.00010350470984121785
step: 160, loss: 0.00011441956303315237
step: 170, loss: 0.07644741982221603
step: 180, loss: 5.0831236876547337e-05
step: 190, loss: 0.024688301607966423
step: 200, loss: 0.05552630499005318
step: 210, loss: 0.021400393918156624
step: 220, loss: 0.01802210323512554
step: 230, loss: 0.023610936477780342
step: 240, loss: 0.05962182208895683
step: 250, loss: 0.013348712585866451
step: 260, loss: 0.04249466210603714
step: 270, loss: 0.04078587517142296
step: 280, loss: 0.04240316525101662
step: 290, loss: 0.07452066242694855
step: 300, loss: 0.022421708330512047
step: 310, loss: 0.06018555536866188
step: 320, loss: 0.024270903319120407
step: 330, loss: 0.03911115974187851
step: 340, loss: 0.021942220628261566
step: 350, loss: 0.00044889937271364033
step: 360, loss: 0.020994577556848526
step: 370, loss: 0.04939664155244827
step: 380, loss: 0.0184759721159935
step: 390, loss: 0.03805376961827278
step: 400, loss: 0.04981975629925728
step: 410, loss: 0.019855720922350883
step: 420, loss: 0.015171796083450317
step: 430, loss: 0.02227887697517872
step: 440, loss: 0.000412406719988212
step: 450, loss: 6.3689672970213e-05
step: 460, loss: 0.06447876244783401
epoch 20: dev_f1=0.9921259842519685, f1=0.9831649831649831, best_f1=0.9843400447427293
