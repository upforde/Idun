cuda
Device: cuda
step: 0, loss: 0.7106969952583313
step: 10, loss: 0.5068784356117249
step: 20, loss: 0.48178744316101074
step: 30, loss: 0.15150128304958344
step: 40, loss: 0.27697518467903137
step: 50, loss: 0.3118923604488373
step: 60, loss: 0.08705759048461914
step: 70, loss: 0.18276900053024292
step: 80, loss: 0.2990485429763794
step: 90, loss: 0.1708488166332245
step: 100, loss: 0.17025120556354523
step: 110, loss: 0.15499533712863922
step: 120, loss: 0.16246482729911804
step: 130, loss: 0.3006288409233093
step: 140, loss: 0.16022495925426483
step: 150, loss: 0.19142231345176697
step: 160, loss: 0.06290873140096664
step: 170, loss: 0.1596938520669937
step: 180, loss: 0.17307758331298828
step: 190, loss: 0.1815659999847412
step: 200, loss: 0.06322847306728363
step: 210, loss: 0.11776542663574219
step: 220, loss: 0.12472300231456757
step: 230, loss: 0.27052271366119385
step: 240, loss: 0.11805737763643265
step: 250, loss: 0.19644829630851746
step: 260, loss: 0.251719206571579
step: 270, loss: 0.12258132547140121
step: 280, loss: 0.2458224594593048
step: 290, loss: 0.23610801994800568
step: 300, loss: 0.09113415330648422
step: 310, loss: 0.15935012698173523
step: 320, loss: 0.03843475878238678
step: 330, loss: 0.17480045557022095
step: 340, loss: 0.265959233045578
step: 350, loss: 0.15741245448589325
step: 360, loss: 0.21609291434288025
step: 370, loss: 0.1019473671913147
step: 380, loss: 0.08822623640298843
step: 390, loss: 0.08682218194007874
step: 400, loss: 0.24604789912700653
step: 410, loss: 0.15396250784397125
step: 420, loss: 0.17025908827781677
step: 430, loss: 0.08271122723817825
step: 440, loss: 0.08997852355241776
step: 450, loss: 0.01822594925761223
step: 460, loss: 0.23805928230285645
epoch 1: dev_f1=0.9796839729119639, f1=0.9761634506242906, best_f1=0.9761634506242906
step: 0, loss: 0.07798314094543457
step: 10, loss: 0.00222998159006238
step: 20, loss: 0.15367628633975983
step: 30, loss: 0.10142998397350311
step: 40, loss: 0.10248884558677673
step: 50, loss: 0.057017721235752106
step: 60, loss: 0.12161885201931
step: 70, loss: 0.12507711350917816
step: 80, loss: 0.11277318745851517
step: 90, loss: 0.08407370746135712
step: 100, loss: 0.0580475740134716
step: 110, loss: 0.12734898924827576
step: 120, loss: 0.11118154972791672
step: 130, loss: 0.009236271493136883
step: 140, loss: 0.0851312205195427
step: 150, loss: 0.041601698845624924
step: 160, loss: 0.13193506002426147
step: 170, loss: 0.13647188246250153
step: 180, loss: 0.13260461390018463
step: 190, loss: 0.19613589346408844
step: 200, loss: 0.1716584861278534
step: 210, loss: 0.09060452878475189
step: 220, loss: 0.10801345109939575
step: 230, loss: 0.09779451042413712
step: 240, loss: 0.015202202834188938
step: 250, loss: 0.09667934477329254
step: 260, loss: 0.1724337339401245
step: 270, loss: 0.09061912447214127
step: 280, loss: 0.04190867394208908
step: 290, loss: 0.10486826300621033
step: 300, loss: 0.1197003647685051
step: 310, loss: 0.04448961839079857
step: 320, loss: 0.10590323805809021
step: 330, loss: 0.07398462295532227
step: 340, loss: 0.03535822406411171
step: 350, loss: 0.07769344002008438
step: 360, loss: 0.0702432319521904
step: 370, loss: 0.04096726328134537
step: 380, loss: 0.008844953961670399
step: 390, loss: 0.07913848757743835
step: 400, loss: 0.05802721902728081
step: 410, loss: 0.20022107660770416
step: 420, loss: 0.16358354687690735
step: 430, loss: 0.07856719195842743
step: 440, loss: 0.07708076387643814
step: 450, loss: 0.2508598566055298
step: 460, loss: 0.10290933400392532
epoch 2: dev_f1=0.9798657718120806, f1=0.963718820861678, best_f1=0.963718820861678
step: 0, loss: 0.1096658930182457
step: 10, loss: 0.08661046624183655
step: 20, loss: 0.07268185168504715
step: 30, loss: 0.10926755517721176
step: 40, loss: 0.0906003937125206
step: 50, loss: 0.19209934771060944
step: 60, loss: 0.17031478881835938
step: 70, loss: 0.036044131964445114
step: 80, loss: 0.07069671154022217
step: 90, loss: 0.060075536370277405
step: 100, loss: 0.08632342517375946
step: 110, loss: 0.07096953690052032
step: 120, loss: 0.062138721346855164
step: 130, loss: 0.08319981396198273
step: 140, loss: 0.09326352179050446
step: 150, loss: 0.12559790909290314
step: 160, loss: 0.06952472776174545
step: 170, loss: 0.11473632603883743
step: 180, loss: 0.11075790226459503
step: 190, loss: 0.09853080660104752
step: 200, loss: 0.048196133226156235
step: 210, loss: 0.06872273236513138
step: 220, loss: 0.05263642966747284
step: 230, loss: 0.15729428827762604
step: 240, loss: 0.1900167465209961
step: 250, loss: 0.06562641263008118
step: 260, loss: 0.07013587653636932
step: 270, loss: 0.02272484451532364
step: 280, loss: 0.023374998942017555
step: 290, loss: 0.042394500225782394
step: 300, loss: 0.11875760555267334
step: 310, loss: 0.02464710734784603
step: 320, loss: 0.0898754820227623
step: 330, loss: 0.1786288619041443
step: 340, loss: 0.07667361199855804
step: 350, loss: 0.05228285491466522
step: 360, loss: 0.026067227125167847
step: 370, loss: 0.16869919002056122
step: 380, loss: 0.12169268727302551
step: 390, loss: 0.17920438945293427
step: 400, loss: 0.0690983310341835
step: 410, loss: 0.05588248372077942
step: 420, loss: 0.10135708749294281
step: 430, loss: 0.12797287106513977
step: 440, loss: 0.15089721977710724
step: 450, loss: 0.05966176092624664
step: 460, loss: 0.13714757561683655
epoch 3: dev_f1=0.9810055865921787, f1=0.978675645342312, best_f1=0.978675645342312
step: 0, loss: 0.10265183448791504
step: 10, loss: 0.03149862214922905
step: 20, loss: 0.039694078266620636
step: 30, loss: 0.13246263563632965
step: 40, loss: 0.15723443031311035
step: 50, loss: 0.10776030272245407
step: 60, loss: 0.10621253401041031
step: 70, loss: 0.08029719442129135
step: 80, loss: 0.06081877648830414
step: 90, loss: 0.06774916499853134
step: 100, loss: 0.04730293154716492
step: 110, loss: 0.05580722168087959
step: 120, loss: 0.10849541425704956
step: 130, loss: 0.05953894555568695
step: 140, loss: 0.024421734735369682
step: 150, loss: 0.04325277358293533
step: 160, loss: 0.06807905435562134
step: 170, loss: 0.01684989407658577
step: 180, loss: 0.026961904019117355
step: 190, loss: 0.0739993304014206
step: 200, loss: 0.1067611500620842
step: 210, loss: 0.07318133860826492
step: 220, loss: 0.15084011852741241
step: 230, loss: 0.05355534330010414
step: 240, loss: 0.07523304969072342
step: 250, loss: 0.08971458673477173
step: 260, loss: 0.04447118565440178
step: 270, loss: 0.14366698265075684
step: 280, loss: 0.05174744501709938
step: 290, loss: 0.15571816265583038
step: 300, loss: 0.11729832738637924
step: 310, loss: 0.14437666535377502
step: 320, loss: 0.11821409314870834
step: 330, loss: 0.04506848007440567
step: 340, loss: 0.14182345569133759
step: 350, loss: 0.021525420248508453
step: 360, loss: 0.07298510521650314
step: 370, loss: 0.18163515627384186
step: 380, loss: 0.09201455861330032
step: 390, loss: 0.16613103449344635
step: 400, loss: 0.22150281071662903
step: 410, loss: 0.08081486076116562
step: 420, loss: 0.09118063002824783
step: 430, loss: 0.24120542407035828
step: 440, loss: 0.010925768874585629
step: 450, loss: 0.0533808209002018
step: 460, loss: 0.08286941796541214
epoch 4: dev_f1=0.9910112359550561, f1=0.9774266365688488, best_f1=0.9774266365688488
step: 0, loss: 0.12463876605033875
step: 10, loss: 0.03311033546924591
step: 20, loss: 0.06846263259649277
step: 30, loss: 0.09944061189889908
step: 40, loss: 0.018028942868113518
step: 50, loss: 0.07222048193216324
step: 60, loss: 0.06427094340324402
step: 70, loss: 0.11867170035839081
step: 80, loss: 0.06564733386039734
step: 90, loss: 0.01611069217324257
step: 100, loss: 0.07365483045578003
step: 110, loss: 0.021376974880695343
step: 120, loss: 0.07584892958402634
step: 130, loss: 0.08167097717523575
step: 140, loss: 0.05586681142449379
step: 150, loss: 0.021759776398539543
step: 160, loss: 0.11760393530130386
step: 170, loss: 0.04374624416232109
step: 180, loss: 0.08015837520360947
step: 190, loss: 0.10001306235790253
step: 200, loss: 0.08823124319314957
step: 210, loss: 0.046588361263275146
step: 220, loss: 0.01813017576932907
step: 230, loss: 0.028807608410716057
step: 240, loss: 0.05097311735153198
step: 250, loss: 0.06680536270141602
step: 260, loss: 0.02068048156797886
step: 270, loss: 0.09305115789175034
step: 280, loss: 0.08100705593824387
step: 290, loss: 0.19698059558868408
step: 300, loss: 0.09127332270145416
step: 310, loss: 0.10704000294208527
step: 320, loss: 0.04392935335636139
step: 330, loss: 0.04783383756875992
step: 340, loss: 0.019738778471946716
step: 350, loss: 0.0038651193026453257
step: 360, loss: 0.15747909247875214
step: 370, loss: 0.13426609337329865
step: 380, loss: 0.21232151985168457
step: 390, loss: 0.1368577778339386
step: 400, loss: 0.07176005095243454
step: 410, loss: 0.10056392848491669
step: 420, loss: 0.012044025585055351
step: 430, loss: 0.0264514721930027
step: 440, loss: 0.037176623940467834
step: 450, loss: 0.04695964604616165
step: 460, loss: 0.0007476749015040696
epoch 5: dev_f1=0.9898074745186863, f1=0.9829738933030647, best_f1=0.9774266365688488
step: 0, loss: 0.03764468804001808
step: 10, loss: 0.1532781571149826
step: 20, loss: 0.06441666185855865
step: 30, loss: 0.014425690285861492
step: 40, loss: 0.006989000830799341
step: 50, loss: 0.1490027904510498
step: 60, loss: 0.07008037716150284
step: 70, loss: 0.01845676638185978
step: 80, loss: 0.10957802832126617
step: 90, loss: 0.09844416379928589
step: 100, loss: 0.05230221152305603
step: 110, loss: 0.08069858700037003
step: 120, loss: 0.04933936148881912
step: 130, loss: 0.04231255501508713
step: 140, loss: 0.10851799696683884
step: 150, loss: 0.049834515899419785
step: 160, loss: 0.20945630967617035
step: 170, loss: 0.059379685670137405
step: 180, loss: 0.08122028410434723
step: 190, loss: 0.014991715550422668
step: 200, loss: 0.046625830233097076
step: 210, loss: 0.037371449172496796
step: 220, loss: 0.20165257155895233
step: 230, loss: 0.11490072309970856
step: 240, loss: 0.10219278931617737
step: 250, loss: 0.014319400303065777
step: 260, loss: 0.014728709124028683
step: 270, loss: 0.056022386997938156
step: 280, loss: 0.007184751331806183
step: 290, loss: 0.08542574197053909
step: 300, loss: 0.11147376894950867
step: 310, loss: 0.04995369911193848
step: 320, loss: 0.12289489060640335
step: 330, loss: 0.06178784742951393
step: 340, loss: 0.07251147925853729
step: 350, loss: 0.1187569722533226
step: 360, loss: 0.05520256608724594
step: 370, loss: 0.12198708206415176
step: 380, loss: 0.028578616678714752
step: 390, loss: 0.07601811736822128
step: 400, loss: 0.03674692288041115
step: 410, loss: 0.1289212852716446
step: 420, loss: 0.050432655960321426
step: 430, loss: 0.05516641587018967
step: 440, loss: 0.06980469822883606
step: 450, loss: 0.058959782123565674
step: 460, loss: 0.0879661962389946
epoch 6: dev_f1=0.9864864864864865, f1=0.9764837625979844, best_f1=0.9774266365688488
step: 0, loss: 0.047920018434524536
step: 10, loss: 0.017580540850758553
step: 20, loss: 0.00834606308490038
step: 30, loss: 0.06922997534275055
step: 40, loss: 0.16317343711853027
step: 50, loss: 0.11150022596120834
step: 60, loss: 0.11740485578775406
step: 70, loss: 0.023397359997034073
step: 80, loss: 0.13525982201099396
step: 90, loss: 0.07271332293748856
step: 100, loss: 0.16866853833198547
step: 110, loss: 0.031499892473220825
step: 120, loss: 0.10565885901451111
step: 130, loss: 0.11158272624015808
step: 140, loss: 0.04976586624979973
step: 150, loss: 0.02441471815109253
step: 160, loss: 0.06816770136356354
step: 170, loss: 0.07096477597951889
step: 180, loss: 0.18399211764335632
step: 190, loss: 0.02410649135708809
step: 200, loss: 0.011694688349962234
step: 210, loss: 0.049592383205890656
step: 220, loss: 0.1131727546453476
step: 230, loss: 0.14050844311714172
step: 240, loss: 0.03806126490235329
step: 250, loss: 0.04123697057366371
step: 260, loss: 0.10445401072502136
step: 270, loss: 0.044696033000946045
step: 280, loss: 0.042809903621673584
step: 290, loss: 0.021457897499203682
step: 300, loss: 0.07164334505796432
step: 310, loss: 0.023722240701317787
step: 320, loss: 0.12026366591453552
step: 330, loss: 0.04306061193346977
step: 340, loss: 0.11383675038814545
step: 350, loss: 0.036279838532209396
step: 360, loss: 0.06546535342931747
step: 370, loss: 0.050361305475234985
step: 380, loss: 0.04535086825489998
step: 390, loss: 0.08903484046459198
step: 400, loss: 0.06914455443620682
step: 410, loss: 0.037420760840177536
step: 420, loss: 0.11973708122968674
step: 430, loss: 0.05084226652979851
step: 440, loss: 0.1974020153284073
step: 450, loss: 0.0925312489271164
step: 460, loss: 0.07410925626754761
epoch 7: dev_f1=0.990990990990991, f1=0.9809203142536477, best_f1=0.9774266365688488
step: 0, loss: 0.10248304903507233
step: 10, loss: 0.12294116616249084
step: 20, loss: 0.05609704554080963
step: 30, loss: 0.0032950802706182003
step: 40, loss: 0.11673248559236526
step: 50, loss: 0.04470256716012955
step: 60, loss: 0.10726384818553925
step: 70, loss: 0.013007470406591892
step: 80, loss: 0.03373892977833748
step: 90, loss: 0.038596395403146744
step: 100, loss: 0.21844926476478577
step: 110, loss: 0.09500747919082642
step: 120, loss: 0.020848769694566727
step: 130, loss: 0.08045993745326996
step: 140, loss: 0.008153634145855904
step: 150, loss: 0.1024857684969902
step: 160, loss: 0.08899276703596115
step: 170, loss: 0.10858096927404404
step: 180, loss: 0.08421872556209564
step: 190, loss: 0.04765579104423523
step: 200, loss: 0.07068102061748505
step: 210, loss: 0.09381020814180374
step: 220, loss: 0.029988355934619904
step: 230, loss: 0.05648493394255638
step: 240, loss: 0.01198574434965849
step: 250, loss: 0.13014236092567444
step: 260, loss: 0.14727944135665894
step: 270, loss: 0.06496647000312805
step: 280, loss: 0.11827120929956436
step: 290, loss: 0.035956572741270065
step: 300, loss: 0.11018642038106918
step: 310, loss: 0.014980216510593891
step: 320, loss: 0.10144440084695816
step: 330, loss: 0.016276026144623756
step: 340, loss: 0.05830327793955803
step: 350, loss: 0.08713746815919876
step: 360, loss: 0.09752319008111954
step: 370, loss: 0.011345276609063148
step: 380, loss: 0.015348544344305992
step: 390, loss: 0.04996068403124809
step: 400, loss: 0.09632697701454163
step: 410, loss: 0.06097472459077835
step: 420, loss: 0.170914888381958
step: 430, loss: 0.05648147314786911
step: 440, loss: 0.053028520196676254
step: 450, loss: 0.03146262839436531
step: 460, loss: 0.0623696893453598
epoch 8: dev_f1=0.9842696629213483, f1=0.9785310734463276, best_f1=0.9774266365688488
step: 0, loss: 0.06069081276655197
step: 10, loss: 0.08402672410011292
step: 20, loss: 0.05066817253828049
step: 30, loss: 0.11644536256790161
step: 40, loss: 0.12734420597553253
step: 50, loss: 0.005107835866510868
step: 60, loss: 0.07886317372322083
step: 70, loss: 0.11410769820213318
step: 80, loss: 0.14495538175106049
step: 90, loss: 0.10787732154130936
step: 100, loss: 0.05262916162610054
step: 110, loss: 0.13294406235218048
step: 120, loss: 0.07670941948890686
step: 130, loss: 0.04744862765073776
step: 140, loss: 0.035345613956451416
step: 150, loss: 0.12484037131071091
step: 160, loss: 0.12112340331077576
step: 170, loss: 0.10255983471870422
step: 180, loss: 0.07928958535194397
step: 190, loss: 0.07898202538490295
step: 200, loss: 0.04151300713419914
step: 210, loss: 0.07403343915939331
step: 220, loss: 0.1033419817686081
step: 230, loss: 0.025906549766659737
step: 240, loss: 0.021034955978393555
step: 250, loss: 0.07102436572313309
step: 260, loss: 0.14086905121803284
step: 270, loss: 0.08266483247280121
step: 280, loss: 0.0027765717823058367
step: 290, loss: 0.06934596598148346
step: 300, loss: 0.007164353039115667
step: 310, loss: 0.06194532662630081
step: 320, loss: 0.030961986631155014
step: 330, loss: 0.10490413010120392
step: 340, loss: 0.019358744844794273
step: 350, loss: 0.10957638174295425
step: 360, loss: 0.02279011346399784
step: 370, loss: 0.04867719113826752
step: 380, loss: 0.0026488597504794598
step: 390, loss: 0.02627270482480526
step: 400, loss: 0.0814501941204071
step: 410, loss: 0.002724143210798502
step: 420, loss: 0.12076667696237564
step: 430, loss: 0.13812921941280365
step: 440, loss: 0.10228632390499115
step: 450, loss: 0.06605122983455658
step: 460, loss: 0.018926862627267838
epoch 9: dev_f1=0.9943630214205187, f1=0.9808773903262092, best_f1=0.9808773903262092
step: 0, loss: 0.16533832252025604
step: 10, loss: 0.04593374952673912
step: 20, loss: 0.052673351019620895
step: 30, loss: 0.06072874739766121
step: 40, loss: 0.13861504197120667
step: 50, loss: 0.028605274856090546
step: 60, loss: 0.037207238376140594
step: 70, loss: 0.08699946850538254
step: 80, loss: 0.07649890333414078
step: 90, loss: 0.174549862742424
step: 100, loss: 0.011174038052558899
step: 110, loss: 0.02643805928528309
step: 120, loss: 0.05090821534395218
step: 130, loss: 0.05546676367521286
step: 140, loss: 0.007674947381019592
step: 150, loss: 0.20823806524276733
step: 160, loss: 0.07304297387599945
step: 170, loss: 0.08184178173542023
step: 180, loss: 0.031546302139759064
step: 190, loss: 0.13220490515232086
step: 200, loss: 0.04369431361556053
step: 210, loss: 0.13389356434345245
step: 220, loss: 0.07297539710998535
step: 230, loss: 0.1503744125366211
step: 240, loss: 0.025808077305555344
step: 250, loss: 0.052926283329725266
step: 260, loss: 0.02942219376564026
step: 270, loss: 0.12306815385818481
step: 280, loss: 0.09829128533601761
step: 290, loss: 0.051655419170856476
step: 300, loss: 0.0631619542837143
step: 310, loss: 0.044623225927352905
step: 320, loss: 0.14459170401096344
step: 330, loss: 0.04981232061982155
step: 340, loss: 0.09017327427864075
step: 350, loss: 0.057739730924367905
step: 360, loss: 0.058710936456918716
step: 370, loss: 0.0990365743637085
step: 380, loss: 0.06621003150939941
step: 390, loss: 0.004551331512629986
step: 400, loss: 0.041376180946826935
step: 410, loss: 0.05721937119960785
step: 420, loss: 0.07792266458272934
step: 430, loss: 0.007175148464739323
step: 440, loss: 0.07546311616897583
step: 450, loss: 0.08309576660394669
step: 460, loss: 0.10195855051279068
epoch 10: dev_f1=0.9898989898989898, f1=0.9809203142536477, best_f1=0.9808773903262092
step: 0, loss: 0.08831201493740082
step: 10, loss: 0.010008508339524269
step: 20, loss: 0.0787348598241806
step: 30, loss: 0.056658580899238586
step: 40, loss: 0.01283873151987791
step: 50, loss: 0.09721019119024277
step: 60, loss: 0.06382967531681061
step: 70, loss: 0.047569647431373596
step: 80, loss: 0.0014029210433363914
step: 90, loss: 0.0440264455974102
step: 100, loss: 0.01796763949096203
step: 110, loss: 0.03081139549612999
step: 120, loss: 0.02570054866373539
step: 130, loss: 0.052781395614147186
step: 140, loss: 0.011811030097305775
step: 150, loss: 0.005610053427517414
step: 160, loss: 0.00047697845729999244
step: 170, loss: 0.11031973361968994
step: 180, loss: 0.0024264974053949118
step: 190, loss: 0.059414591640233994
step: 200, loss: 0.05832348018884659
step: 210, loss: 0.0005889086751267314
step: 220, loss: 0.052863843739032745
step: 230, loss: 0.06396766752004623
step: 240, loss: 0.04340476915240288
step: 250, loss: 0.052490003407001495
step: 260, loss: 0.029709119349718094
step: 270, loss: 0.003963453695178032
step: 280, loss: 0.06953373551368713
step: 290, loss: 0.005786675959825516
step: 300, loss: 0.04049693048000336
step: 310, loss: 0.02918822318315506
step: 320, loss: 0.017809536308050156
step: 330, loss: 0.0666547492146492
step: 340, loss: 0.0006424903986044228
step: 350, loss: 0.0929027795791626
step: 360, loss: 0.15664207935333252
step: 370, loss: 0.05625460669398308
step: 380, loss: 0.042873602360486984
step: 390, loss: 0.04671036824584007
step: 400, loss: 0.10120335966348648
step: 410, loss: 0.06577130407094955
step: 420, loss: 0.015360482968389988
step: 430, loss: 0.008716916665434837
step: 440, loss: 0.06696943193674088
step: 450, loss: 0.01910875365138054
step: 460, loss: 0.13379241526126862
epoch 11: dev_f1=0.990990990990991, f1=0.9820627802690582, best_f1=0.9808773903262092
step: 0, loss: 0.003318716073408723
step: 10, loss: 0.06727832555770874
step: 20, loss: 0.055426180362701416
step: 30, loss: 0.02593880146741867
step: 40, loss: 0.002071667928248644
step: 50, loss: 0.002749904291704297
step: 60, loss: 0.016282472759485245
step: 70, loss: 0.023390188813209534
step: 80, loss: 0.009646841324865818
step: 90, loss: 0.13023126125335693
step: 100, loss: 0.05066363885998726
step: 110, loss: 0.026276912540197372
step: 120, loss: 0.018757639452815056
step: 130, loss: 0.09018366783857346
step: 140, loss: 0.10888943076133728
step: 150, loss: 0.030675001442432404
step: 160, loss: 0.0867423266172409
step: 170, loss: 0.0656948834657669
step: 180, loss: 0.045982230454683304
step: 190, loss: 0.020958635956048965
step: 200, loss: 0.06879536807537079
step: 210, loss: 0.1270066350698471
step: 220, loss: 0.05616123601794243
step: 230, loss: 0.02624741941690445
step: 240, loss: 0.027003014460206032
step: 250, loss: 0.03432842716574669
step: 260, loss: 0.04131373018026352
step: 270, loss: 0.11256864666938782
step: 280, loss: 0.025615522637963295
step: 290, loss: 0.01240836177021265
step: 300, loss: 0.13292868435382843
step: 310, loss: 0.06467047333717346
step: 320, loss: 0.03866695985198021
step: 330, loss: 4.404130595503375e-05
step: 340, loss: 0.05846042186021805
step: 350, loss: 0.0775003433227539
step: 360, loss: 0.020291374996304512
step: 370, loss: 0.02540699951350689
step: 380, loss: 0.07661464065313339
step: 390, loss: 0.03588860481977463
step: 400, loss: 0.032565440982580185
step: 410, loss: 0.04079003259539604
step: 420, loss: 0.11692355573177338
step: 430, loss: 0.027498776093125343
step: 440, loss: 0.04060468077659607
step: 450, loss: 0.029471049085259438
step: 460, loss: 0.05963234230875969
epoch 12: dev_f1=0.990990990990991, f1=0.9864864864864865, best_f1=0.9808773903262092
step: 0, loss: 0.022699717432260513
step: 10, loss: 0.045417752116918564
step: 20, loss: 0.000286399939795956
step: 30, loss: 0.07342256605625153
step: 40, loss: 0.004260164685547352
step: 50, loss: 0.021120334044098854
step: 60, loss: 0.04967232793569565
step: 70, loss: 0.00026953741325996816
step: 80, loss: 0.0646250918507576
step: 90, loss: 0.03162851557135582
step: 100, loss: 0.01504148356616497
step: 110, loss: 0.020567728206515312
step: 120, loss: 0.09885198622941971
step: 130, loss: 0.05397382751107216
step: 140, loss: 0.0883367657661438
step: 150, loss: 0.027046341449022293
step: 160, loss: 0.02460215985774994
step: 170, loss: 0.026840437203645706
step: 180, loss: 0.009755251929163933
step: 190, loss: 0.030565369874238968
step: 200, loss: 9.820687409956008e-05
step: 210, loss: 0.028797730803489685
step: 220, loss: 0.0690324455499649
step: 230, loss: 0.05279989913105965
step: 240, loss: 0.033400390297174454
step: 250, loss: 0.021898804232478142
step: 260, loss: 0.10608304291963577
step: 270, loss: 0.05591244995594025
step: 280, loss: 0.05086125060915947
step: 290, loss: 0.02089129015803337
step: 300, loss: 0.031001316383481026
step: 310, loss: 0.0005919979885220528
step: 320, loss: 0.01657526195049286
step: 330, loss: 0.0008220473537221551
step: 340, loss: 0.04108823090791702
step: 350, loss: 0.061025410890579224
step: 360, loss: 0.09116743505001068
step: 370, loss: 0.06211382895708084
step: 380, loss: 0.0033157216385006905
step: 390, loss: 0.04261317849159241
step: 400, loss: 0.0707140862941742
step: 410, loss: 0.023158114403486252
step: 420, loss: 0.03285295143723488
step: 430, loss: 0.12685319781303406
step: 440, loss: 0.12698808312416077
step: 450, loss: 0.032856475561857224
step: 460, loss: 0.030293870717287064
epoch 13: dev_f1=0.9887640449438202, f1=0.980963045912654, best_f1=0.9808773903262092
step: 0, loss: 0.0009188946569338441
step: 10, loss: 0.019400224089622498
step: 20, loss: 0.02645329385995865
step: 30, loss: 0.04411647096276283
step: 40, loss: 0.07718747854232788
step: 50, loss: 0.07520034164190292
step: 60, loss: 0.07717832922935486
step: 70, loss: 0.04979143291711807
step: 80, loss: 0.004637379664927721
step: 90, loss: 0.07454469799995422
step: 100, loss: 0.0021652597934007645
step: 110, loss: 0.001202722080051899
step: 120, loss: 0.10596894472837448
step: 130, loss: 0.036523010581731796
step: 140, loss: 0.039341673254966736
step: 150, loss: 0.02614445425570011
step: 160, loss: 0.01873750612139702
step: 170, loss: 0.034244898706674576
step: 180, loss: 0.02529599331319332
step: 190, loss: 0.01747526414692402
step: 200, loss: 0.032098185271024704
step: 210, loss: 0.01739605888724327
step: 220, loss: 0.1373303085565567
step: 230, loss: 0.035234734416007996
step: 240, loss: 0.024197684600949287
step: 250, loss: 0.030918283388018608
step: 260, loss: 0.019893703982234
step: 270, loss: 0.05872544273734093
step: 280, loss: 0.021477488800883293
step: 290, loss: 0.041586991399526596
step: 300, loss: 0.0009271180024370551
step: 310, loss: 0.01883661188185215
step: 320, loss: 0.016061468049883842
step: 330, loss: 0.054680682718753815
step: 340, loss: 0.03412824869155884
step: 350, loss: 0.04729365557432175
step: 360, loss: 0.054780442267656326
step: 370, loss: 0.015059071592986584
step: 380, loss: 0.04339652135968208
step: 390, loss: 0.1883971244096756
step: 400, loss: 0.00028322756406851113
step: 410, loss: 0.0013920707860961556
step: 420, loss: 0.09390369802713394
step: 430, loss: 0.002893010387197137
step: 440, loss: 0.0177322831004858
step: 450, loss: 0.08531071990728378
step: 460, loss: 0.02267993614077568
epoch 14: dev_f1=0.9886877828054299, f1=0.9774774774774775, best_f1=0.9808773903262092
step: 0, loss: 0.0321517288684845
step: 10, loss: 0.05617842450737953
step: 20, loss: 0.011584349907934666
step: 30, loss: 0.08241694420576096
step: 40, loss: 0.06885133683681488
step: 50, loss: 0.03610794618725777
step: 60, loss: 0.0034205906558781862
step: 70, loss: 0.1030239462852478
step: 80, loss: 0.01915191486477852
step: 90, loss: 0.04153604432940483
step: 100, loss: 0.0006095581338740885
step: 110, loss: 0.09889180958271027
step: 120, loss: 0.0003685248957481235
step: 130, loss: 0.031609613448381424
step: 140, loss: 0.029571330174803734
step: 150, loss: 0.07372653484344482
step: 160, loss: 0.05401570722460747
step: 170, loss: 0.05107182636857033
step: 180, loss: 0.03907439857721329
step: 190, loss: 0.013148719444870949
step: 200, loss: 0.02234131284058094
step: 210, loss: 0.019790830090641975
step: 220, loss: 0.06808267533779144
step: 230, loss: 0.05665694922208786
step: 240, loss: 0.03548334911465645
step: 250, loss: 0.014385193586349487
step: 260, loss: 0.026858177036046982
step: 270, loss: 0.053416039794683456
step: 280, loss: 0.03351868689060211
step: 290, loss: 0.029302485287189484
step: 300, loss: 0.027621885761618614
step: 310, loss: 0.02330981194972992
step: 320, loss: 0.023383624851703644
step: 330, loss: 0.0517190620303154
step: 340, loss: 0.006404800806194544
step: 350, loss: 0.02418060228228569
step: 360, loss: 0.0324508361518383
step: 370, loss: 0.03178289905190468
step: 380, loss: 0.06037352979183197
step: 390, loss: 0.02591336891055107
step: 400, loss: 0.0016240807017311454
step: 410, loss: 0.002748149447143078
step: 420, loss: 0.03852046653628349
step: 430, loss: 0.004410837776958942
step: 440, loss: 0.06347145885229111
step: 450, loss: 0.07660512626171112
step: 460, loss: 0.02667245641350746
epoch 15: dev_f1=0.9899216125419933, f1=0.9810055865921787, best_f1=0.9808773903262092
step: 0, loss: 0.02611074410378933
step: 10, loss: 0.05223147198557854
step: 20, loss: 0.04861529543995857
step: 30, loss: 0.06339865177869797
step: 40, loss: 0.13093093037605286
step: 50, loss: 0.0009255933691747487
step: 60, loss: 0.07213740795850754
step: 70, loss: 0.05205971375107765
step: 80, loss: 0.02371601201593876
step: 90, loss: 0.06314460188150406
step: 100, loss: 0.05231179669499397
step: 110, loss: 0.02084987983107567
step: 120, loss: 0.06160604953765869
step: 130, loss: 0.0003594097215682268
step: 140, loss: 0.02423390932381153
step: 150, loss: 0.13266174495220184
step: 160, loss: 0.00020021696400362998
step: 170, loss: 0.03679492697119713
step: 180, loss: 0.08962742984294891
step: 190, loss: 0.023211108520627022
step: 200, loss: 0.07023385167121887
step: 210, loss: 0.04171544313430786
step: 220, loss: 0.051954980939626694
step: 230, loss: 0.023854481056332588
step: 240, loss: 0.06219543144106865
step: 250, loss: 0.01060718297958374
step: 260, loss: 0.0003215985489077866
step: 270, loss: 0.09414233267307281
step: 280, loss: 0.06190035119652748
step: 290, loss: 0.09121958166360855
step: 300, loss: 0.09019411355257034
step: 310, loss: 0.00043250893941149116
step: 320, loss: 0.09942606091499329
step: 330, loss: 9.595243318472058e-05
step: 340, loss: 0.09188515692949295
step: 350, loss: 0.028475897386670113
step: 360, loss: 0.02403467707335949
step: 370, loss: 0.036764029413461685
step: 380, loss: 0.00022870258544571698
step: 390, loss: 0.08895619958639145
step: 400, loss: 0.02618132345378399
step: 410, loss: 0.09712348878383636
step: 420, loss: 0.04737913981080055
step: 430, loss: 0.01065891794860363
step: 440, loss: 0.04679154232144356
step: 450, loss: 0.017548581585288048
step: 460, loss: 0.052237436175346375
epoch 16: dev_f1=0.9887892376681614, f1=0.9798206278026906, best_f1=0.9808773903262092
step: 0, loss: 0.022873898968100548
step: 10, loss: 0.08618468046188354
step: 20, loss: 0.0493931882083416
step: 30, loss: 0.017279215157032013
step: 40, loss: 0.020471617579460144
step: 50, loss: 9.713136387290433e-05
step: 60, loss: 0.020427340641617775
step: 70, loss: 0.0003013143432326615
step: 80, loss: 0.04908018931746483
step: 90, loss: 0.004315061029046774
step: 100, loss: 0.02959948405623436
step: 110, loss: 0.025108348578214645
step: 120, loss: 0.04158906266093254
step: 130, loss: 0.020214645192027092
step: 140, loss: 6.34577008895576e-05
step: 150, loss: 0.058464616537094116
step: 160, loss: 0.04118594899773598
step: 170, loss: 0.04625610262155533
step: 180, loss: 0.06533204764127731
step: 190, loss: 0.05288371443748474
step: 200, loss: 0.023108316585421562
step: 210, loss: 0.00012935350241605192
step: 220, loss: 0.03651402145624161
step: 230, loss: 0.0003113522252533585
step: 240, loss: 0.07676292210817337
step: 250, loss: 0.03842352703213692
step: 260, loss: 0.00010515361645957455
step: 270, loss: 0.05996279418468475
step: 280, loss: 0.03199461102485657
step: 290, loss: 0.021192770451307297
step: 300, loss: 0.04494064301252365
step: 310, loss: 0.021241851150989532
step: 320, loss: 0.0781949982047081
step: 330, loss: 0.051675278693437576
step: 340, loss: 8.543321746401489e-05
step: 350, loss: 0.12697255611419678
step: 360, loss: 0.04089285060763359
step: 370, loss: 0.016473475843667984
step: 380, loss: 0.035712555050849915
step: 390, loss: 0.08293705433607101
step: 400, loss: 2.526625758036971e-05
step: 410, loss: 0.10235393047332764
step: 420, loss: 0.06263105571269989
step: 430, loss: 0.08114244788885117
step: 440, loss: 0.027274811640381813
step: 450, loss: 0.05703793093562126
step: 460, loss: 0.05441323295235634
epoch 17: dev_f1=0.990990990990991, f1=0.9831271091113611, best_f1=0.9808773903262092
step: 0, loss: 0.0008866250282153487
step: 10, loss: 0.03782240301370621
step: 20, loss: 0.03948349878191948
step: 30, loss: 0.0653453841805458
step: 40, loss: 0.026539960876107216
step: 50, loss: 0.0256224125623703
step: 60, loss: 0.053389303386211395
step: 70, loss: 0.032714713364839554
step: 80, loss: 0.02183684892952442
step: 90, loss: 0.05120740085840225
step: 100, loss: 0.04571681469678879
step: 110, loss: 0.0004977891221642494
step: 120, loss: 0.0618182048201561
step: 130, loss: 0.06911875307559967
step: 140, loss: 0.01653740182518959
step: 150, loss: 0.04515371844172478
step: 160, loss: 0.08730980008840561
step: 170, loss: 0.02111881785094738
step: 180, loss: 0.0004919046768918633
step: 190, loss: 0.05505288392305374
step: 200, loss: 0.00027882191352546215
step: 210, loss: 0.03455277159810066
step: 220, loss: 0.00022821180755272508
step: 230, loss: 0.0389123409986496
step: 240, loss: 0.011007147841155529
step: 250, loss: 0.049589890986680984
step: 260, loss: 0.13100357353687286
step: 270, loss: 0.01776210404932499
step: 280, loss: 0.05157960206270218
step: 290, loss: 0.032903820276260376
step: 300, loss: 0.1201043501496315
step: 310, loss: 0.04447976127266884
step: 320, loss: 0.03525594249367714
step: 330, loss: 1.5832218196010217e-05
step: 340, loss: 0.01879965513944626
step: 350, loss: 0.10268688946962357
step: 360, loss: 0.06860192120075226
step: 370, loss: 0.0010044374503195286
step: 380, loss: 0.08862565457820892
step: 390, loss: 0.021098680794239044
step: 400, loss: 0.002276729792356491
step: 410, loss: 0.038099076598882675
step: 420, loss: 0.030440207570791245
step: 430, loss: 0.05363572761416435
step: 440, loss: 7.461332279490307e-05
step: 450, loss: 0.08623623847961426
step: 460, loss: 0.020798392593860626
epoch 18: dev_f1=0.9887640449438202, f1=0.9832026875699889, best_f1=0.9808773903262092
step: 0, loss: 0.06541186571121216
step: 10, loss: 0.03833901137113571
step: 20, loss: 0.00011792973964475095
step: 30, loss: 0.05843964219093323
step: 40, loss: 0.04253052547574043
step: 50, loss: 0.0001371505786664784
step: 60, loss: 0.0003466557536739856
step: 70, loss: 0.017894599586725235
step: 80, loss: 0.051803164184093475
step: 90, loss: 0.06374868750572205
step: 100, loss: 0.001263730227947235
step: 110, loss: 0.026608726009726524
step: 120, loss: 0.11970514804124832
step: 130, loss: 0.10458112508058548
step: 140, loss: 0.07794246077537537
step: 150, loss: 0.041039034724235535
step: 160, loss: 0.015095832757651806
step: 170, loss: 0.00017208617646247149
step: 180, loss: 0.010419820435345173
step: 190, loss: 0.0001811563561204821
step: 200, loss: 0.05333174392580986
step: 210, loss: 0.04292704910039902
step: 220, loss: 2.266710544063244e-05
step: 230, loss: 0.11454702913761139
step: 240, loss: 0.044625915586948395
step: 250, loss: 0.055519700050354004
step: 260, loss: 0.027925841510295868
step: 270, loss: 0.0007473210571333766
step: 280, loss: 8.509073086315766e-05
step: 290, loss: 0.015457142144441605
step: 300, loss: 0.08220373839139938
step: 310, loss: 0.06986963748931885
step: 320, loss: 0.10551133751869202
step: 330, loss: 0.026437388733029366
step: 340, loss: 0.02791774831712246
step: 350, loss: 0.10829783976078033
step: 360, loss: 0.04463152214884758
step: 370, loss: 0.023938577622175217
step: 380, loss: 0.02256156876683235
step: 390, loss: 0.07826447486877441
step: 400, loss: 0.017141608521342278
step: 410, loss: 0.021247461438179016
step: 420, loss: 0.0010693402728065848
step: 430, loss: 0.023739702999591827
step: 440, loss: 0.11888296157121658
step: 450, loss: 0.017386246472597122
step: 460, loss: 0.2705669403076172
epoch 19: dev_f1=0.9898989898989898, f1=0.9832026875699889, best_f1=0.9808773903262092
step: 0, loss: 0.024329014122486115
step: 10, loss: 0.06085551530122757
step: 20, loss: 0.020891286432743073
step: 30, loss: 0.03578813001513481
step: 40, loss: 0.03349338471889496
step: 50, loss: 0.018913159146904945
step: 60, loss: 0.09657468646764755
step: 70, loss: 0.052621081471443176
step: 80, loss: 0.06690530478954315
step: 90, loss: 0.01796615496277809
step: 100, loss: 0.042307861149311066
step: 110, loss: 0.04729526862502098
step: 120, loss: 0.00014968504547141492
step: 130, loss: 0.09229972213506699
step: 140, loss: 0.0700363889336586
step: 150, loss: 0.021844401955604553
step: 160, loss: 0.00014653036487288773
step: 170, loss: 0.02032369002699852
step: 180, loss: 0.02498544380068779
step: 190, loss: 0.026210902258753777
step: 200, loss: 0.017687061801552773
step: 210, loss: 0.08198446780443192
step: 220, loss: 0.024240031838417053
step: 230, loss: 0.00020979827968403697
step: 240, loss: 0.018798217177391052
step: 250, loss: 0.019072692841291428
step: 260, loss: 0.256875216960907
step: 270, loss: 0.01215321570634842
step: 280, loss: 0.03932608664035797
step: 290, loss: 0.045696649700403214
step: 300, loss: 0.06130491942167282
step: 310, loss: 0.03451566398143768
step: 320, loss: 7.337007264140993e-05
step: 330, loss: 0.08026871830224991
step: 340, loss: 0.01800728403031826
step: 350, loss: 0.00016832859546411783
step: 360, loss: 0.08268742263317108
step: 370, loss: 0.03251694142818451
step: 380, loss: 0.02052629552781582
step: 390, loss: 0.01940150186419487
step: 400, loss: 0.04012276977300644
step: 410, loss: 0.02044060081243515
step: 420, loss: 0.0001403770875185728
step: 430, loss: 0.0001738220453262329
step: 440, loss: 0.034296777099370956
step: 450, loss: 0.0355566032230854
step: 460, loss: 0.018842412158846855
epoch 20: dev_f1=0.9898534385569334, f1=0.9819819819819819, best_f1=0.9808773903262092
