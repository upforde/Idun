cuda
Device: cuda
step: 0, loss: 0.7623928785324097
step: 10, loss: 0.5310306549072266
step: 20, loss: 0.47936728596687317
step: 30, loss: 0.5008103847503662
step: 40, loss: 0.5552754998207092
step: 50, loss: 0.1480003446340561
step: 60, loss: 0.14902913570404053
step: 70, loss: 0.22107620537281036
step: 80, loss: 0.19388490915298462
step: 90, loss: 0.2883504629135132
step: 100, loss: 0.19313527643680573
step: 110, loss: 0.3624269962310791
step: 120, loss: 0.2392176240682602
step: 130, loss: 0.08675970882177353
step: 140, loss: 0.10815437138080597
step: 150, loss: 0.0768337994813919
step: 160, loss: 0.174559086561203
step: 170, loss: 0.11685481667518616
step: 180, loss: 0.2633212208747864
step: 190, loss: 0.12833857536315918
step: 200, loss: 0.1881387084722519
step: 210, loss: 0.22271110117435455
step: 220, loss: 0.22382041811943054
step: 230, loss: 0.22068233788013458
step: 240, loss: 0.19100481271743774
step: 250, loss: 0.18330229818820953
step: 260, loss: 0.04240674152970314
step: 270, loss: 0.1417754888534546
step: 280, loss: 0.12445775419473648
step: 290, loss: 0.10162581503391266
step: 300, loss: 0.14089816808700562
step: 310, loss: 0.08746829628944397
step: 320, loss: 0.05273890122771263
step: 330, loss: 0.07429782301187515
step: 340, loss: 0.2956167459487915
step: 350, loss: 0.06934197247028351
step: 360, loss: 0.15018674731254578
step: 370, loss: 0.14452052116394043
step: 380, loss: 0.14051984250545502
step: 390, loss: 0.16420336067676544
step: 400, loss: 0.09595003724098206
step: 410, loss: 0.07943987101316452
step: 420, loss: 0.22611595690250397
step: 430, loss: 0.061796896159648895
step: 440, loss: 0.1213642880320549
step: 450, loss: 0.129710391163826
step: 460, loss: 0.05362987518310547
epoch 1: dev_f1=0.9544468546637743, f1=0.9529025191675794, best_f1=0.9529025191675794
step: 0, loss: 0.09761001169681549
step: 10, loss: 0.07579739391803741
step: 20, loss: 0.038996148854494095
step: 30, loss: 0.15161964297294617
step: 40, loss: 0.06863989681005478
step: 50, loss: 0.01546302530914545
step: 60, loss: 0.18664202094078064
step: 70, loss: 0.164273202419281
step: 80, loss: 0.041589103639125824
step: 90, loss: 0.1446317881345749
step: 100, loss: 0.06634242087602615
step: 110, loss: 0.12281736731529236
step: 120, loss: 0.10585897415876389
step: 130, loss: 0.17587555944919586
step: 140, loss: 0.030987804755568504
step: 150, loss: 0.02075515128672123
step: 160, loss: 0.04359935224056244
step: 170, loss: 0.053417228162288666
step: 180, loss: 0.04110788181424141
step: 190, loss: 0.06665913760662079
step: 200, loss: 0.14790265262126923
step: 210, loss: 0.13903219997882843
step: 220, loss: 0.041513774544000626
step: 230, loss: 0.12897539138793945
step: 240, loss: 0.12415187060832977
step: 250, loss: 0.08658940345048904
step: 260, loss: 0.07791420072317123
step: 270, loss: 0.06124288961291313
step: 280, loss: 0.13931742310523987
step: 290, loss: 0.05282536521553993
step: 300, loss: 0.07852604985237122
step: 310, loss: 0.016984088346362114
step: 320, loss: 0.14295455813407898
step: 330, loss: 0.02363733761012554
step: 340, loss: 0.1549096405506134
step: 350, loss: 0.05656380206346512
step: 360, loss: 0.06390143185853958
step: 370, loss: 0.13703760504722595
step: 380, loss: 0.09936420619487762
step: 390, loss: 0.045682817697525024
step: 400, loss: 0.05135165527462959
step: 410, loss: 0.059190552681684494
step: 420, loss: 0.018397625535726547
step: 430, loss: 0.05343857407569885
step: 440, loss: 0.11287666112184525
step: 450, loss: 0.09457534551620483
step: 460, loss: 0.09653827548027039
epoch 2: dev_f1=0.9887387387387387, f1=0.9796380090497738, best_f1=0.9796380090497738
step: 0, loss: 0.031076302751898766
step: 10, loss: 0.062439680099487305
step: 20, loss: 0.04388703405857086
step: 30, loss: 0.05457305535674095
step: 40, loss: 0.052797380834817886
step: 50, loss: 0.09962660819292068
step: 60, loss: 0.00968602392822504
step: 70, loss: 0.13875950872898102
step: 80, loss: 0.00930588785558939
step: 90, loss: 0.24146044254302979
step: 100, loss: 0.03214972838759422
step: 110, loss: 0.06787662208080292
step: 120, loss: 0.06849181652069092
step: 130, loss: 0.13310101628303528
step: 140, loss: 0.158833310008049
step: 150, loss: 0.010093886405229568
step: 160, loss: 0.0980299562215805
step: 170, loss: 0.014552421867847443
step: 180, loss: 0.07224002480506897
step: 190, loss: 0.03993644565343857
step: 200, loss: 0.20153141021728516
step: 210, loss: 0.06518290936946869
step: 220, loss: 0.051589690148830414
step: 230, loss: 0.09480283409357071
step: 240, loss: 0.17468492686748505
step: 250, loss: 0.05310489237308502
step: 260, loss: 0.06134087219834328
step: 270, loss: 0.0579504668712616
step: 280, loss: 0.046409301459789276
step: 290, loss: 0.10686733573675156
step: 300, loss: 0.0451023243367672
step: 310, loss: 0.13205675780773163
step: 320, loss: 0.1061580628156662
step: 330, loss: 0.04492900148034096
step: 340, loss: 0.28452441096305847
step: 350, loss: 0.01766965724527836
step: 360, loss: 0.08162704855203629
step: 370, loss: 0.025975223630666733
step: 380, loss: 0.007497951854020357
step: 390, loss: 0.00016275775851681828
step: 400, loss: 0.07281418889760971
step: 410, loss: 0.037891410291194916
step: 420, loss: 0.13668885827064514
step: 430, loss: 0.07019796967506409
step: 440, loss: 0.017577242106199265
step: 450, loss: 0.2152928113937378
step: 460, loss: 0.07753267884254456
epoch 3: dev_f1=0.9876543209876544, f1=0.9829738933030647, best_f1=0.9796380090497738
step: 0, loss: 0.1823662519454956
step: 10, loss: 0.07916716486215591
step: 20, loss: 0.07953054457902908
step: 30, loss: 0.038931045681238174
step: 40, loss: 0.17016778886318207
step: 50, loss: 0.05373641476035118
step: 60, loss: 0.0021825633011758327
step: 70, loss: 0.018554911017417908
step: 80, loss: 0.07141174376010895
step: 90, loss: 0.10871340334415436
step: 100, loss: 0.0230063758790493
step: 110, loss: 0.1668987274169922
step: 120, loss: 0.058469608426094055
step: 130, loss: 0.19083259999752045
step: 140, loss: 0.07444917410612106
step: 150, loss: 0.1491660326719284
step: 160, loss: 0.07132790237665176
step: 170, loss: 0.06710749119520187
step: 180, loss: 0.10834135860204697
step: 190, loss: 0.09916800260543823
step: 200, loss: 0.047070231288671494
step: 210, loss: 0.03818795457482338
step: 220, loss: 0.03453399986028671
step: 230, loss: 0.07192225009202957
step: 240, loss: 0.12460347265005112
step: 250, loss: 0.03270101547241211
step: 260, loss: 0.06623473018407822
step: 270, loss: 0.06455215066671371
step: 280, loss: 0.09132930636405945
step: 290, loss: 0.14831578731536865
step: 300, loss: 0.10337670147418976
step: 310, loss: 0.07467394322156906
step: 320, loss: 0.013866147957742214
step: 330, loss: 0.06615280359983444
step: 340, loss: 0.06972023844718933
step: 350, loss: 0.1127428263425827
step: 360, loss: 0.014468378387391567
step: 370, loss: 0.11867436021566391
step: 380, loss: 0.15413083136081696
step: 390, loss: 0.04000048711895943
step: 400, loss: 0.09616976976394653
step: 410, loss: 0.12178380787372589
step: 420, loss: 0.001292188186198473
step: 430, loss: 0.054455772042274475
step: 440, loss: 0.07044588774442673
step: 450, loss: 0.13457252085208893
step: 460, loss: 0.04798826575279236
epoch 4: dev_f1=0.987598647125141, f1=0.9772727272727272, best_f1=0.9796380090497738
step: 0, loss: 0.07088401168584824
step: 10, loss: 0.07688247412443161
step: 20, loss: 0.11951489746570587
step: 30, loss: 0.03776305541396141
step: 40, loss: 0.2892947494983673
step: 50, loss: 0.12046461552381516
step: 60, loss: 0.07847559452056885
step: 70, loss: 0.026553042232990265
step: 80, loss: 0.11124624311923981
step: 90, loss: 0.06701872497797012
step: 100, loss: 0.023016653954982758
step: 110, loss: 0.0654839426279068
step: 120, loss: 0.10430015623569489
step: 130, loss: 0.19993388652801514
step: 140, loss: 0.048650242388248444
step: 150, loss: 0.040343716740608215
step: 160, loss: 0.04967520385980606
step: 170, loss: 0.08637268841266632
step: 180, loss: 0.1375473588705063
step: 190, loss: 0.07239256054162979
step: 200, loss: 0.15708601474761963
step: 210, loss: 0.05374069884419441
step: 220, loss: 0.01712794601917267
step: 230, loss: 0.094218410551548
step: 240, loss: 0.07176931947469711
step: 250, loss: 0.11321540921926498
step: 260, loss: 0.07412201166152954
step: 270, loss: 0.027702495455741882
step: 280, loss: 0.055081602185964584
step: 290, loss: 0.035469092428684235
step: 300, loss: 0.006917061284184456
step: 310, loss: 0.02579277567565441
step: 320, loss: 0.031668178737163544
step: 330, loss: 0.026889417320489883
step: 340, loss: 0.1029415875673294
step: 350, loss: 0.024644503369927406
step: 360, loss: 0.11724593490362167
step: 370, loss: 0.029175180941820145
step: 380, loss: 0.0021922762971371412
step: 390, loss: 0.07652394473552704
step: 400, loss: 0.029892541468143463
step: 410, loss: 0.06857467442750931
step: 420, loss: 0.08578404039144516
step: 430, loss: 0.05055895447731018
step: 440, loss: 0.0753064751625061
step: 450, loss: 0.13104534149169922
step: 460, loss: 0.05298743024468422
epoch 5: dev_f1=0.9898074745186863, f1=0.9875424688561721, best_f1=0.9875424688561721
step: 0, loss: 0.08659255504608154
step: 10, loss: 0.06654032319784164
step: 20, loss: 0.1290937215089798
step: 30, loss: 0.0977775901556015
step: 40, loss: 0.11585180461406708
step: 50, loss: 0.06785529851913452
step: 60, loss: 0.05762648582458496
step: 70, loss: 0.04599296674132347
step: 80, loss: 0.023450514301657677
step: 90, loss: 0.08084138482809067
step: 100, loss: 0.028128184378147125
step: 110, loss: 0.027259379625320435
step: 120, loss: 0.10081473737955093
step: 130, loss: 0.02010936848819256
step: 140, loss: 0.036291010677814484
step: 150, loss: 0.11646866053342819
step: 160, loss: 0.015186281874775887
step: 170, loss: 0.05146924778819084
step: 180, loss: 0.042863406240940094
step: 190, loss: 0.034256599843502045
step: 200, loss: 0.19543376564979553
step: 210, loss: 0.2583716809749603
step: 220, loss: 0.07431770116090775
step: 230, loss: 0.0883239135146141
step: 240, loss: 0.10481424629688263
step: 250, loss: 0.13630275428295135
step: 260, loss: 0.046603500843048096
step: 270, loss: 0.1035950556397438
step: 280, loss: 0.09787202626466751
step: 290, loss: 0.007496931124478579
step: 300, loss: 0.11589746177196503
step: 310, loss: 0.05473985895514488
step: 320, loss: 0.08277442306280136
step: 330, loss: 0.11581580340862274
step: 340, loss: 0.06221294030547142
step: 350, loss: 0.09107351303100586
step: 360, loss: 0.08489847928285599
step: 370, loss: 0.07188063114881516
step: 380, loss: 0.009485442191362381
step: 390, loss: 0.04490341618657112
step: 400, loss: 0.03672538325190544
step: 410, loss: 0.08190396428108215
step: 420, loss: 0.08440195024013519
step: 430, loss: 0.061295170336961746
step: 440, loss: 0.07815989851951599
step: 450, loss: 0.09586004167795181
step: 460, loss: 0.11496327072381973
epoch 6: dev_f1=0.990990990990991, f1=0.9809203142536477, best_f1=0.9809203142536477
step: 0, loss: 0.05624061077833176
step: 10, loss: 0.07131446897983551
step: 20, loss: 0.027487481012940407
step: 30, loss: 0.05611497163772583
step: 40, loss: 0.1428072303533554
step: 50, loss: 0.08336255699396133
step: 60, loss: 0.008063233457505703
step: 70, loss: 0.09407636523246765
step: 80, loss: 0.04694635421037674
step: 90, loss: 0.079173743724823
step: 100, loss: 0.08381454646587372
step: 110, loss: 0.0642186850309372
step: 120, loss: 0.018590813502669334
step: 130, loss: 0.030819658190011978
step: 140, loss: 0.019436506554484367
step: 150, loss: 0.0807507336139679
step: 160, loss: 0.2747046947479248
step: 170, loss: 0.18563182651996613
step: 180, loss: 0.037535570561885834
step: 190, loss: 0.08032401651144028
step: 200, loss: 0.0816739946603775
step: 210, loss: 0.09003698825836182
step: 220, loss: 0.013532126322388649
step: 230, loss: 0.042948782444000244
step: 240, loss: 0.03253963217139244
step: 250, loss: 0.01657676137983799
step: 260, loss: 0.07606245577335358
step: 270, loss: 0.1328345537185669
step: 280, loss: 0.08680843561887741
step: 290, loss: 0.11982706934213638
step: 300, loss: 0.07133009284734726
step: 310, loss: 0.13446684181690216
step: 320, loss: 0.05490686371922493
step: 330, loss: 0.016104701906442642
step: 340, loss: 0.0194049421697855
step: 350, loss: 0.008187941275537014
step: 360, loss: 0.06569952517747879
step: 370, loss: 0.07198383659124374
step: 380, loss: 0.05478465557098389
step: 390, loss: 0.0757252424955368
step: 400, loss: 0.17531795799732208
step: 410, loss: 0.0647573322057724
step: 420, loss: 0.01685839146375656
step: 430, loss: 0.024219239130616188
step: 440, loss: 0.0251159705221653
step: 450, loss: 0.02666643261909485
step: 460, loss: 0.17762024700641632
epoch 7: dev_f1=0.9876819708846584, f1=0.9799554565701558, best_f1=0.9809203142536477
step: 0, loss: 0.022792719304561615
step: 10, loss: 0.13325531780719757
step: 20, loss: 0.1043662503361702
step: 30, loss: 0.1915934830904007
step: 40, loss: 0.03900968283414841
step: 50, loss: 0.06417116522789001
step: 60, loss: 0.125414177775383
step: 70, loss: 0.06959004700183868
step: 80, loss: 0.027662761509418488
step: 90, loss: 0.0015529878437519073
step: 100, loss: 0.07355312258005142
step: 110, loss: 0.04820002242922783
step: 120, loss: 0.07281038910150528
step: 130, loss: 0.009721806272864342
step: 140, loss: 0.1479133814573288
step: 150, loss: 0.1166222020983696
step: 160, loss: 0.19307838380336761
step: 170, loss: 0.09816649556159973
step: 180, loss: 0.029600415378808975
step: 190, loss: 0.008141129277646542
step: 200, loss: 0.04339970648288727
step: 210, loss: 0.050508130341768265
step: 220, loss: 0.010998496785759926
step: 230, loss: 0.07758043706417084
step: 240, loss: 0.06638403236865997
step: 250, loss: 0.05441713705658913
step: 260, loss: 0.0473388247191906
step: 270, loss: 0.0274632778018713
step: 280, loss: 0.022634809836745262
step: 290, loss: 0.11292892694473267
step: 300, loss: 0.11511698365211487
step: 310, loss: 0.048124730587005615
step: 320, loss: 0.22887107729911804
step: 330, loss: 0.07630109786987305
step: 340, loss: 0.007848038338124752
step: 350, loss: 0.06721813231706619
step: 360, loss: 0.08317821472883224
step: 370, loss: 0.10065235942602158
step: 380, loss: 0.16975639760494232
step: 390, loss: 0.17953135073184967
step: 400, loss: 0.11113220453262329
step: 410, loss: 0.017229633405804634
step: 420, loss: 0.032035522162914276
step: 430, loss: 0.17440803349018097
step: 440, loss: 0.1055644154548645
step: 450, loss: 0.047927629202604294
step: 460, loss: 0.09781357645988464
epoch 8: dev_f1=0.9909706546275394, f1=0.9797297297297298, best_f1=0.9809203142536477
step: 0, loss: 0.006176677066832781
step: 10, loss: 0.046047359704971313
step: 20, loss: 0.018829962238669395
step: 30, loss: 0.08598654717206955
step: 40, loss: 0.07468102127313614
step: 50, loss: 0.002087041735649109
step: 60, loss: 0.03487219661474228
step: 70, loss: 0.02969781681895256
step: 80, loss: 0.04199201241135597
step: 90, loss: 0.12812036275863647
step: 100, loss: 0.0941723883152008
step: 110, loss: 0.17443345487117767
step: 120, loss: 0.004589152988046408
step: 130, loss: 0.0498693585395813
step: 140, loss: 0.07001304626464844
step: 150, loss: 0.015305683016777039
step: 160, loss: 0.037916261702775955
step: 170, loss: 0.01220331247895956
step: 180, loss: 0.009272800758481026
step: 190, loss: 0.06692038476467133
step: 200, loss: 0.07958965003490448
step: 210, loss: 0.010336156003177166
step: 220, loss: 0.04167354106903076
step: 230, loss: 0.1268814355134964
step: 240, loss: 0.01595575362443924
step: 250, loss: 0.07123229652643204
step: 260, loss: 0.050379663705825806
step: 270, loss: 0.03671606257557869
step: 280, loss: 0.0063802460208535194
step: 290, loss: 0.04578620567917824
step: 300, loss: 0.10241836309432983
step: 310, loss: 0.07761590927839279
step: 320, loss: 0.036053773015737534
step: 330, loss: 0.06765103340148926
step: 340, loss: 0.0833452045917511
step: 350, loss: 0.03860114887356758
step: 360, loss: 0.1143851950764656
step: 370, loss: 0.0713922381401062
step: 380, loss: 0.07473766058683395
step: 390, loss: 0.08504427969455719
step: 400, loss: 0.025010880082845688
step: 410, loss: 0.06940779089927673
step: 420, loss: 0.02317417785525322
step: 430, loss: 0.03411295637488365
step: 440, loss: 0.0056969840079545975
step: 450, loss: 0.017712857574224472
step: 460, loss: 0.020649772137403488
epoch 9: dev_f1=0.990990990990991, f1=0.9820224719101124, best_f1=0.9809203142536477
step: 0, loss: 0.10511429607868195
step: 10, loss: 0.11814503371715546
step: 20, loss: 0.03448466956615448
step: 30, loss: 0.11496780812740326
step: 40, loss: 0.03844419866800308
step: 50, loss: 0.06805112212896347
step: 60, loss: 0.0030765936244279146
step: 70, loss: 0.05252071097493172
step: 80, loss: 0.00813382863998413
step: 90, loss: 0.05153564736247063
step: 100, loss: 0.01611124537885189
step: 110, loss: 0.04688006266951561
step: 120, loss: 0.07574622333049774
step: 130, loss: 0.06245935708284378
step: 140, loss: 3.423712041694671e-05
step: 150, loss: 0.15012399852275848
step: 160, loss: 0.047505710273981094
step: 170, loss: 0.031170466914772987
step: 180, loss: 0.06024891510605812
step: 190, loss: 0.0316854827105999
step: 200, loss: 0.07418590039014816
step: 210, loss: 0.059138279408216476
step: 220, loss: 0.07388786971569061
step: 230, loss: 0.025956440716981888
step: 240, loss: 0.009484742768108845
step: 250, loss: 0.02466462552547455
step: 260, loss: 0.011654929257929325
step: 270, loss: 0.03618757426738739
step: 280, loss: 0.08389906585216522
step: 290, loss: 0.07986226677894592
step: 300, loss: 0.06716576963663101
step: 310, loss: 0.06612802296876907
step: 320, loss: 0.041770704090595245
step: 330, loss: 0.036840543150901794
step: 340, loss: 0.04546518996357918
step: 350, loss: 0.03336627036333084
step: 360, loss: 0.0164712592959404
step: 370, loss: 0.09005434811115265
step: 380, loss: 0.1245514303445816
step: 390, loss: 0.027955228462815285
step: 400, loss: 0.11868706345558167
step: 410, loss: 0.10280425101518631
step: 420, loss: 0.03557198494672775
step: 430, loss: 0.08375620096921921
step: 440, loss: 0.05364036187529564
step: 450, loss: 0.006969117559492588
step: 460, loss: 0.07488499581813812
epoch 10: dev_f1=0.990990990990991, f1=0.9829738933030647, best_f1=0.9809203142536477
step: 0, loss: 0.024219712242484093
step: 10, loss: 0.04002952203154564
step: 20, loss: 0.033947695046663284
step: 30, loss: 0.020868323743343353
step: 40, loss: 0.07708165049552917
step: 50, loss: 0.09613379836082458
step: 60, loss: 0.030840788036584854
step: 70, loss: 0.004905828274786472
step: 80, loss: 0.0959443598985672
step: 90, loss: 0.019332103431224823
step: 100, loss: 0.07985401153564453
step: 110, loss: 0.0986706092953682
step: 120, loss: 0.03525076061487198
step: 130, loss: 0.06321348249912262
step: 140, loss: 0.0422542467713356
step: 150, loss: 0.0010168717708438635
step: 160, loss: 0.08066343516111374
step: 170, loss: 0.05170312151312828
step: 180, loss: 0.016826830804347992
step: 190, loss: 0.07531362771987915
step: 200, loss: 0.07586237043142319
step: 210, loss: 0.027482206001877785
step: 220, loss: 0.14475882053375244
step: 230, loss: 0.10589788854122162
step: 240, loss: 0.1618533432483673
step: 250, loss: 0.1318555325269699
step: 260, loss: 0.0005773465381935239
step: 270, loss: 0.028661208227276802
step: 280, loss: 0.15618400275707245
step: 290, loss: 0.10434766113758087
step: 300, loss: 0.04190150275826454
step: 310, loss: 0.09487149119377136
step: 320, loss: 0.038690242916345596
step: 330, loss: 0.08709896355867386
step: 340, loss: 0.04146016016602516
step: 350, loss: 0.021015213802456856
step: 360, loss: 0.11472178995609283
step: 370, loss: 0.04182005301117897
step: 380, loss: 0.04136551544070244
step: 390, loss: 0.09192366898059845
step: 400, loss: 0.009378000162541866
step: 410, loss: 0.05230797454714775
step: 420, loss: 0.009163763374090195
step: 430, loss: 0.01878170110285282
step: 440, loss: 0.022125985473394394
step: 450, loss: 0.060895681381225586
step: 460, loss: 0.07123301178216934
epoch 11: dev_f1=0.9932432432432432, f1=0.9832026875699889, best_f1=0.9832026875699889
step: 0, loss: 0.04609616473317146
step: 10, loss: 0.11287594586610794
step: 20, loss: 0.016214419156312943
step: 30, loss: 0.002718754578381777
step: 40, loss: 0.001024467870593071
step: 50, loss: 3.410526187508367e-05
step: 60, loss: 0.0170059222728014
step: 70, loss: 0.05350886657834053
step: 80, loss: 0.09163989126682281
step: 90, loss: 0.039051394909620285
step: 100, loss: 0.03437977284193039
step: 110, loss: 0.05982554331421852
step: 120, loss: 0.04927310347557068
step: 130, loss: 0.03016606718301773
step: 140, loss: 0.03546459600329399
step: 150, loss: 0.08862875401973724
step: 160, loss: 0.04034958779811859
step: 170, loss: 0.07854481041431427
step: 180, loss: 0.09964887797832489
step: 190, loss: 0.028644900768995285
step: 200, loss: 0.08755698055028915
step: 210, loss: 0.020686853677034378
step: 220, loss: 0.07856105268001556
step: 230, loss: 0.0845927819609642
step: 240, loss: 0.1656508445739746
step: 250, loss: 0.04593110457062721
step: 260, loss: 0.04789309203624725
step: 270, loss: 0.04253491759300232
step: 280, loss: 0.05821190029382706
step: 290, loss: 0.09050662070512772
step: 300, loss: 0.061673641204833984
step: 310, loss: 0.061497557908296585
step: 320, loss: 0.06763770431280136
step: 330, loss: 0.06641926616430283
step: 340, loss: 0.05019178241491318
step: 350, loss: 0.010459821671247482
step: 360, loss: 0.06851942837238312
step: 370, loss: 0.05080406740307808
step: 380, loss: 0.009465555660426617
step: 390, loss: 0.04580473154783249
step: 400, loss: 0.04177484288811684
step: 410, loss: 2.8210464734002016e-05
step: 420, loss: 0.11544136703014374
step: 430, loss: 0.023877423256635666
step: 440, loss: 0.026201719418168068
step: 450, loss: 0.014371005818247795
step: 460, loss: 0.07094066590070724
epoch 12: dev_f1=0.9910112359550561, f1=0.9832026875699889, best_f1=0.9832026875699889
step: 0, loss: 0.05386681109666824
step: 10, loss: 0.050857555121183395
step: 20, loss: 0.028421854600310326
step: 30, loss: 0.03408356010913849
step: 40, loss: 0.04128031060099602
step: 50, loss: 0.039106279611587524
step: 60, loss: 0.018053889274597168
step: 70, loss: 6.90800734446384e-05
step: 80, loss: 0.033551644533872604
step: 90, loss: 0.06739195436239243
step: 100, loss: 0.10778574645519257
step: 110, loss: 0.029568787664175034
step: 120, loss: 0.025735000148415565
step: 130, loss: 0.05944543704390526
step: 140, loss: 0.0010331457015126944
step: 150, loss: 0.02689868025481701
step: 160, loss: 0.04647773504257202
step: 170, loss: 0.06815460324287415
step: 180, loss: 0.048720404505729675
step: 190, loss: 0.06836395710706711
step: 200, loss: 0.09104811400175095
step: 210, loss: 0.1629689335823059
step: 220, loss: 0.07957599312067032
step: 230, loss: 0.04083997756242752
step: 240, loss: 0.08195073902606964
step: 250, loss: 0.027595823630690575
step: 260, loss: 0.083238884806633
step: 270, loss: 0.04584266617894173
step: 280, loss: 0.05562811717391014
step: 290, loss: 0.00801257137209177
step: 300, loss: 0.03249501809477806
step: 310, loss: 0.014231720939278603
step: 320, loss: 0.06081823259592056
step: 330, loss: 0.0789160504937172
step: 340, loss: 0.07858794182538986
step: 350, loss: 0.019855380058288574
step: 360, loss: 0.03919098526239395
step: 370, loss: 0.014448651112616062
step: 380, loss: 0.0004566460847854614
step: 390, loss: 0.04233198240399361
step: 400, loss: 0.01710541546344757
step: 410, loss: 0.014137965627014637
step: 420, loss: 0.002398646203801036
step: 430, loss: 0.076946921646595
step: 440, loss: 0.03435660898685455
step: 450, loss: 0.026019826531410217
step: 460, loss: 0.13751794397830963
epoch 13: dev_f1=0.9898534385569334, f1=0.9831649831649831, best_f1=0.9832026875699889
step: 0, loss: 0.05940335616469383
step: 10, loss: 0.01620366983115673
step: 20, loss: 0.056307606399059296
step: 30, loss: 0.027199262753129005
step: 40, loss: 0.01775411143898964
step: 50, loss: 0.12263809144496918
step: 60, loss: 0.014791256748139858
step: 70, loss: 0.011918848380446434
step: 80, loss: 0.17800483107566833
step: 90, loss: 0.04504314810037613
step: 100, loss: 0.03056631237268448
step: 110, loss: 0.034793920814991
step: 120, loss: 0.1650538593530655
step: 130, loss: 0.03402361273765564
step: 140, loss: 0.0612209290266037
step: 150, loss: 0.1456831693649292
step: 160, loss: 0.0428629145026207
step: 170, loss: 0.24130775034427643
step: 180, loss: 0.09327640384435654
step: 190, loss: 0.02832760661840439
step: 200, loss: 0.031264327466487885
step: 210, loss: 0.00024131046666298062
step: 220, loss: 0.030033085495233536
step: 230, loss: 0.05814312398433685
step: 240, loss: 0.028654582798480988
step: 250, loss: 0.18003208935260773
step: 260, loss: 0.0071286289021372795
step: 270, loss: 0.12016049772500992
step: 280, loss: 0.08159848302602768
step: 290, loss: 0.07892633974552155
step: 300, loss: 0.0855029970407486
step: 310, loss: 0.03299563378095627
step: 320, loss: 0.036789990961551666
step: 330, loss: 0.03476940095424652
step: 340, loss: 0.06975694000720978
step: 350, loss: 0.017441971227526665
step: 360, loss: 0.008305906318128109
step: 370, loss: 0.06835372745990753
step: 380, loss: 0.036213938146829605
step: 390, loss: 0.05774511769413948
step: 400, loss: 0.000722850498277694
step: 410, loss: 0.08208513259887695
step: 420, loss: 0.056104086339473724
step: 430, loss: 0.08625815063714981
step: 440, loss: 0.09082631021738052
step: 450, loss: 0.10525911301374435
step: 460, loss: 0.06576447188854218
epoch 14: dev_f1=0.9898534385569334, f1=0.9831271091113611, best_f1=0.9832026875699889
step: 0, loss: 0.03539859876036644
step: 10, loss: 0.1837719827890396
step: 20, loss: 0.07812277227640152
step: 30, loss: 0.12946295738220215
step: 40, loss: 0.03444494307041168
step: 50, loss: 0.03284253925085068
step: 60, loss: 0.04406476765871048
step: 70, loss: 0.06621424853801727
step: 80, loss: 0.05238913744688034
step: 90, loss: 0.07614324241876602
step: 100, loss: 0.0006733420304954052
step: 110, loss: 0.0005160050932317972
step: 120, loss: 0.030676644295454025
step: 130, loss: 0.03349132463335991
step: 140, loss: 0.05347400903701782
step: 150, loss: 0.047243088483810425
step: 160, loss: 0.014720320701599121
step: 170, loss: 0.0640011876821518
step: 180, loss: 0.016856325790286064
step: 190, loss: 0.1628667563199997
step: 200, loss: 0.04998258873820305
step: 210, loss: 0.0016930998535826802
step: 220, loss: 0.11958196759223938
step: 230, loss: 0.022641213610768318
step: 240, loss: 0.030504044145345688
step: 250, loss: 0.0821690708398819
step: 260, loss: 0.05037034675478935
step: 270, loss: 0.034298375248909
step: 280, loss: 0.03329960256814957
step: 290, loss: 0.05630010738968849
step: 300, loss: 0.0005838586948812008
step: 310, loss: 0.04802674055099487
step: 320, loss: 0.04247283935546875
step: 330, loss: 0.0013419378083199263
step: 340, loss: 0.02170291170477867
step: 350, loss: 0.10334132611751556
step: 360, loss: 0.044725630432367325
step: 370, loss: 0.024281658232212067
step: 380, loss: 0.0012109533417969942
step: 390, loss: 0.00908289011567831
step: 400, loss: 0.019160054624080658
step: 410, loss: 0.07402065396308899
step: 420, loss: 0.04950966686010361
step: 430, loss: 0.0026811049319803715
step: 440, loss: 0.028941314667463303
step: 450, loss: 0.04550383985042572
step: 460, loss: 0.052388761192560196
epoch 15: dev_f1=0.9898762654668166, f1=0.9831649831649831, best_f1=0.9832026875699889
step: 0, loss: 0.09175009280443192
step: 10, loss: 0.046028293669223785
step: 20, loss: 9.411012433702126e-05
step: 30, loss: 0.018100598827004433
step: 40, loss: 0.005042828619480133
step: 50, loss: 0.022394562140107155
step: 60, loss: 0.028015028685331345
step: 70, loss: 0.05287349224090576
step: 80, loss: 0.09550502896308899
step: 90, loss: 0.034026846289634705
step: 100, loss: 0.016268448904156685
step: 110, loss: 0.01403290405869484
step: 120, loss: 0.033105265349149704
step: 130, loss: 0.03946509212255478
step: 140, loss: 0.026267115026712418
step: 150, loss: 0.012323345988988876
step: 160, loss: 0.06761310249567032
step: 170, loss: 0.06277823448181152
step: 180, loss: 0.07035647332668304
step: 190, loss: 1.5187786630121991e-05
step: 200, loss: 0.03885886073112488
step: 210, loss: 0.017836937680840492
step: 220, loss: 0.025088615715503693
step: 230, loss: 0.02526686154305935
step: 240, loss: 0.1849348545074463
step: 250, loss: 0.03564266115427017
step: 260, loss: 0.0703522264957428
step: 270, loss: 0.0013631185283884406
step: 280, loss: 0.13836702704429626
step: 290, loss: 0.10872119665145874
step: 300, loss: 0.030518224462866783
step: 310, loss: 3.522464248817414e-05
step: 320, loss: 0.029732173308730125
step: 330, loss: 8.242938201874495e-05
step: 340, loss: 0.0008820230141282082
step: 350, loss: 0.08933068066835403
step: 360, loss: 0.05096477270126343
step: 370, loss: 0.00039177684811875224
step: 380, loss: 0.0394718311727047
step: 390, loss: 0.029716769233345985
step: 400, loss: 0.020408712327480316
step: 410, loss: 0.03023303486406803
step: 420, loss: 0.034079134464263916
step: 430, loss: 0.08758736401796341
step: 440, loss: 0.03024779073894024
step: 450, loss: 0.012399664148688316
step: 460, loss: 0.11196788400411606
epoch 16: dev_f1=0.9910112359550561, f1=0.984304932735426, best_f1=0.9832026875699889
step: 0, loss: 0.055228233337402344
step: 10, loss: 0.018444376066327095
step: 20, loss: 0.024800656363368034
step: 30, loss: 0.02449745684862137
step: 40, loss: 0.07789842039346695
step: 50, loss: 0.09906519949436188
step: 60, loss: 0.02004595287144184
step: 70, loss: 0.05580933392047882
step: 80, loss: 0.027977516874670982
step: 90, loss: 0.03908618912100792
step: 100, loss: 0.023310590535402298
step: 110, loss: 0.00042758198105730116
step: 120, loss: 0.047319453209638596
step: 130, loss: 0.05580743029713631
step: 140, loss: 0.035698242485523224
step: 150, loss: 0.03397016227245331
step: 160, loss: 0.08954661339521408
step: 170, loss: 0.040768835693597794
step: 180, loss: 0.016461562365293503
step: 190, loss: 0.03018072247505188
step: 200, loss: 0.06953184306621552
step: 210, loss: 0.09734609723091125
step: 220, loss: 0.019312655553221703
step: 230, loss: 0.05692486837506294
step: 240, loss: 0.000698812014888972
step: 250, loss: 0.018922390416264534
step: 260, loss: 0.02169470489025116
step: 270, loss: 0.020657794550061226
step: 280, loss: 0.1817142367362976
step: 290, loss: 0.030149037018418312
step: 300, loss: 0.056241948157548904
step: 310, loss: 0.004879913758486509
step: 320, loss: 0.08731622248888016
step: 330, loss: 0.09628806263208389
step: 340, loss: 0.022812971845269203
step: 350, loss: 0.04319900646805763
step: 360, loss: 0.15149472653865814
step: 370, loss: 0.013186653144657612
step: 380, loss: 0.019487300887703896
step: 390, loss: 0.0016417769948020577
step: 400, loss: 0.03485092148184776
step: 410, loss: 0.04565870016813278
step: 420, loss: 0.09568056464195251
step: 430, loss: 0.027673520147800446
step: 440, loss: 0.06023821979761124
step: 450, loss: 0.01854611188173294
step: 460, loss: 0.03801238164305687
epoch 17: dev_f1=0.9898989898989898, f1=0.9831649831649831, best_f1=0.9832026875699889
step: 0, loss: 0.028790533542633057
step: 10, loss: 0.00018309563165530562
step: 20, loss: 0.029798539355397224
step: 30, loss: 0.002598165301606059
step: 40, loss: 0.04519108682870865
step: 50, loss: 0.09788857400417328
step: 60, loss: 0.04529581964015961
step: 70, loss: 0.011708728969097137
step: 80, loss: 0.021113133057951927
step: 90, loss: 0.022209160029888153
step: 100, loss: 0.034976206719875336
step: 110, loss: 0.0002271825505886227
step: 120, loss: 0.014562083408236504
step: 130, loss: 0.00017346246750093997
step: 140, loss: 0.05067378282546997
step: 150, loss: 0.0007473267032764852
step: 160, loss: 0.021311340853571892
step: 170, loss: 0.001324115670286119
step: 180, loss: 0.040667567402124405
step: 190, loss: 0.029163485392928123
step: 200, loss: 0.03962121531367302
step: 210, loss: 0.05800900608301163
step: 220, loss: 0.04631761461496353
step: 230, loss: 0.0001727246562950313
step: 240, loss: 0.04997645318508148
step: 250, loss: 0.06426861137151718
step: 260, loss: 0.05432708561420441
step: 270, loss: 0.03940626233816147
step: 280, loss: 0.0009140814654529095
step: 290, loss: 0.052474357187747955
step: 300, loss: 0.07190123200416565
step: 310, loss: 0.021337052807211876
step: 320, loss: 0.017789820209145546
step: 330, loss: 0.012015598826110363
step: 340, loss: 0.01669924333691597
step: 350, loss: 0.04593593254685402
step: 360, loss: 0.00013925244275014848
step: 370, loss: 4.612844713847153e-05
step: 380, loss: 0.030350815504789352
step: 390, loss: 0.02629329264163971
step: 400, loss: 5.015731949242763e-05
step: 410, loss: 0.009381333366036415
step: 420, loss: 0.08333738893270493
step: 430, loss: 0.04247957840561867
step: 440, loss: 0.034345842897892
step: 450, loss: 0.01841297186911106
step: 460, loss: 0.022499537095427513
epoch 18: dev_f1=0.9920724801812004, f1=0.9829738933030647, best_f1=0.9832026875699889
step: 0, loss: 0.017318157479166985
step: 10, loss: 0.026644384488463402
step: 20, loss: 0.05541173741221428
step: 30, loss: 0.0002030829491559416
step: 40, loss: 0.02445846050977707
step: 50, loss: 0.04667367413640022
step: 60, loss: 0.09274356812238693
step: 70, loss: 0.013847237452864647
step: 80, loss: 0.07447630167007446
step: 90, loss: 0.005245062056928873
step: 100, loss: 0.006682444363832474
step: 110, loss: 0.00016190315363928676
step: 120, loss: 0.016248324885964394
step: 130, loss: 0.04471004009246826
step: 140, loss: 0.02859208546578884
step: 150, loss: 0.0017171320505440235
step: 160, loss: 0.04962681233882904
step: 170, loss: 0.0738501250743866
step: 180, loss: 0.00014683668268844485
step: 190, loss: 0.04447587579488754
step: 200, loss: 0.06305903941392899
step: 210, loss: 0.07726652920246124
step: 220, loss: 8.870651799952611e-05
step: 230, loss: 0.0001407611125614494
step: 240, loss: 0.025583311915397644
step: 250, loss: 0.0569625161588192
step: 260, loss: 0.0605802983045578
step: 270, loss: 0.07252421230077744
step: 280, loss: 0.01902022212743759
step: 290, loss: 0.14263753592967987
step: 300, loss: 0.12522268295288086
step: 310, loss: 0.016035808250308037
step: 320, loss: 9.32645343709737e-05
step: 330, loss: 0.037722233682870865
step: 340, loss: 0.02492145448923111
step: 350, loss: 0.03874902427196503
step: 360, loss: 0.021467192098498344
step: 370, loss: 0.020113635808229446
step: 380, loss: 0.06512777507305145
step: 390, loss: 0.021553441882133484
step: 400, loss: 0.02313792146742344
step: 410, loss: 0.006235790438950062
step: 420, loss: 0.02303190529346466
step: 430, loss: 0.022449862211942673
step: 440, loss: 0.018895287066698074
step: 450, loss: 0.10106965899467468
step: 460, loss: 0.01712227426469326
epoch 19: dev_f1=0.9909502262443439, f1=0.9841269841269841, best_f1=0.9832026875699889
step: 0, loss: 0.05733140558004379
step: 10, loss: 0.03912820667028427
step: 20, loss: 0.03213076293468475
step: 30, loss: 0.0466887541115284
step: 40, loss: 0.000722588796634227
step: 50, loss: 0.018608560785651207
step: 60, loss: 0.05855216830968857
step: 70, loss: 0.10303600132465363
step: 80, loss: 0.06270363926887512
step: 90, loss: 0.02425982430577278
step: 100, loss: 0.020482072606682777
step: 110, loss: 0.05813203752040863
step: 120, loss: 0.005391544196754694
step: 130, loss: 0.023779407143592834
step: 140, loss: 7.05949860275723e-05
step: 150, loss: 0.020555676892399788
step: 160, loss: 0.028677349910140038
step: 170, loss: 0.0004897165927104652
step: 180, loss: 0.02070007473230362
step: 190, loss: 0.0010231059277430177
step: 200, loss: 0.062207844108343124
step: 210, loss: 0.044185422360897064
step: 220, loss: 0.00044438772602006793
step: 230, loss: 0.05090823397040367
step: 240, loss: 0.01885678991675377
step: 250, loss: 0.044338274747133255
step: 260, loss: 0.02073195017874241
step: 270, loss: 0.05115533992648125
step: 280, loss: 0.03749421611428261
step: 290, loss: 0.009685046039521694
step: 300, loss: 0.08997797220945358
step: 310, loss: 0.0647808313369751
step: 320, loss: 0.07562902569770813
step: 330, loss: 0.07586102932691574
step: 340, loss: 0.09498563408851624
step: 350, loss: 0.01021437719464302
step: 360, loss: 0.05533957481384277
step: 370, loss: 0.07650281488895416
step: 380, loss: 0.05577874928712845
step: 390, loss: 0.06383249163627625
step: 400, loss: 0.05220169574022293
step: 410, loss: 0.02504104934632778
step: 420, loss: 0.03058535046875477
step: 430, loss: 0.006352894473820925
step: 440, loss: 0.01363623421639204
step: 450, loss: 0.00037772662471979856
step: 460, loss: 0.0360366590321064
epoch 20: dev_f1=0.9920724801812004, f1=0.9794988610478361, best_f1=0.9832026875699889
