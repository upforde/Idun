cuda
Device: cuda
step: 0, loss: 0.5639399290084839
step: 10, loss: 0.5248996019363403
step: 20, loss: 0.4285011291503906
step: 30, loss: 0.18930181860923767
step: 40, loss: 0.20534943044185638
step: 50, loss: 0.2146771401166916
step: 60, loss: 0.2332579791545868
step: 70, loss: 0.23424722254276276
step: 80, loss: 0.12506867945194244
step: 90, loss: 0.19129185378551483
step: 100, loss: 0.37781810760498047
step: 110, loss: 0.1846168488264084
step: 120, loss: 0.08242879807949066
step: 130, loss: 0.16372525691986084
step: 140, loss: 0.2620411217212677
step: 150, loss: 0.31880366802215576
step: 160, loss: 0.18326488137245178
step: 170, loss: 0.12881846725940704
step: 180, loss: 0.170577734708786
step: 190, loss: 0.20896564424037933
step: 200, loss: 0.11414249986410141
step: 210, loss: 0.09404592961072922
step: 220, loss: 0.21506845951080322
step: 230, loss: 0.1085016056895256
step: 240, loss: 0.1523902267217636
step: 250, loss: 0.16809958219528198
step: 260, loss: 0.11582458019256592
step: 270, loss: 0.1449711173772812
step: 280, loss: 0.1060609295964241
step: 290, loss: 0.08304831385612488
step: 300, loss: 0.030538668856024742
step: 310, loss: 0.05413517355918884
step: 320, loss: 0.01799498312175274
step: 330, loss: 0.21220144629478455
step: 340, loss: 0.08165515214204788
step: 350, loss: 0.04491453617811203
step: 360, loss: 0.07721526175737381
step: 370, loss: 0.05709809064865112
step: 380, loss: 0.12009342014789581
step: 390, loss: 0.025057323276996613
step: 400, loss: 0.17383792996406555
step: 410, loss: 0.20932182669639587
step: 420, loss: 0.1492110639810562
step: 430, loss: 0.04196895286440849
step: 440, loss: 0.03452959656715393
step: 450, loss: 0.22790180146694183
step: 460, loss: 0.1590796411037445
epoch 1: dev_f1=0.9876819708846584, f1=0.9752252252252253, best_f1=0.9752252252252253
step: 0, loss: 0.14537456631660461
step: 10, loss: 0.06720390170812607
step: 20, loss: 0.124574676156044
step: 30, loss: 0.06463827192783356
step: 40, loss: 0.14067089557647705
step: 50, loss: 0.15665897727012634
step: 60, loss: 0.1636170744895935
step: 70, loss: 0.12415201216936111
step: 80, loss: 0.1533055305480957
step: 90, loss: 0.09601479768753052
step: 100, loss: 0.08136992156505585
step: 110, loss: 0.06886934489011765
step: 120, loss: 0.024209335446357727
step: 130, loss: 0.037007782608270645
step: 140, loss: 0.12958362698554993
step: 150, loss: 0.0899198055267334
step: 160, loss: 0.07989563792943954
step: 170, loss: 0.12700851261615753
step: 180, loss: 0.11008159071207047
step: 190, loss: 0.07253976911306381
step: 200, loss: 0.08308522403240204
step: 210, loss: 0.0975634753704071
step: 220, loss: 0.09484981000423431
step: 230, loss: 0.15249435603618622
step: 240, loss: 0.13189417123794556
step: 250, loss: 0.04364403337240219
step: 260, loss: 0.020979588851332664
step: 270, loss: 0.040534790605306625
step: 280, loss: 0.1321900337934494
step: 290, loss: 0.0876857116818428
step: 300, loss: 0.017038721591234207
step: 310, loss: 0.03555711358785629
step: 320, loss: 0.05422809347510338
step: 330, loss: 0.17184123396873474
step: 340, loss: 0.11802659928798676
step: 350, loss: 0.06394356489181519
step: 360, loss: 0.08043214678764343
step: 370, loss: 0.07553693652153015
step: 380, loss: 0.12540511786937714
step: 390, loss: 0.20706546306610107
step: 400, loss: 0.017197826877236366
step: 410, loss: 0.040787141770124435
step: 420, loss: 0.025285417214035988
step: 430, loss: 0.027429893612861633
step: 440, loss: 0.12119243294000626
step: 450, loss: 0.005637448281049728
step: 460, loss: 0.06814752519130707
epoch 2: dev_f1=0.976324689966178, f1=0.978675645342312, best_f1=0.9752252252252253
step: 0, loss: 0.1124648004770279
step: 10, loss: 0.0593031570315361
step: 20, loss: 0.15948370099067688
step: 30, loss: 0.05680778995156288
step: 40, loss: 0.018365712836384773
step: 50, loss: 0.10409168899059296
step: 60, loss: 0.1689058542251587
step: 70, loss: 0.22213126718997955
step: 80, loss: 0.03323012962937355
step: 90, loss: 0.18806350231170654
step: 100, loss: 0.18024437129497528
step: 110, loss: 0.05096522718667984
step: 120, loss: 0.19120286405086517
step: 130, loss: 0.06258296966552734
step: 140, loss: 0.14453038573265076
step: 150, loss: 0.03789714723825455
step: 160, loss: 0.10519178956747055
step: 170, loss: 0.026976214721798897
step: 180, loss: 0.015074843540787697
step: 190, loss: 0.0280213113874197
step: 200, loss: 0.10316374897956848
step: 210, loss: 0.02900567092001438
step: 220, loss: 0.06310863047838211
step: 230, loss: 0.050799693912267685
step: 240, loss: 0.025537947192788124
step: 250, loss: 0.07393555343151093
step: 260, loss: 0.07166329026222229
step: 270, loss: 0.029766835272312164
step: 280, loss: 0.06244928762316704
step: 290, loss: 0.09664788097143173
step: 300, loss: 0.1751316785812378
step: 310, loss: 0.07642306387424469
step: 320, loss: 0.08768580853939056
step: 330, loss: 0.09987352043390274
step: 340, loss: 0.018827233463525772
step: 350, loss: 0.04592033475637436
step: 360, loss: 0.1688392460346222
step: 370, loss: 0.11077775806188583
step: 380, loss: 0.10957454890012741
step: 390, loss: 0.024869564920663834
step: 400, loss: 0.05424857884645462
step: 410, loss: 0.029971886426210403
step: 420, loss: 0.19245629012584686
step: 430, loss: 0.024754252284765244
step: 440, loss: 0.05111874267458916
step: 450, loss: 0.15197116136550903
step: 460, loss: 0.09879462420940399
epoch 3: dev_f1=0.9909706546275394, f1=0.9808773903262092, best_f1=0.9808773903262092
step: 0, loss: 0.05517536774277687
step: 10, loss: 0.03818177804350853
step: 20, loss: 0.15515603125095367
step: 30, loss: 0.05070410296320915
step: 40, loss: 0.04995087906718254
step: 50, loss: 0.06929057091474533
step: 60, loss: 0.12824766337871552
step: 70, loss: 0.09083230048418045
step: 80, loss: 0.05147765949368477
step: 90, loss: 0.06641687452793121
step: 100, loss: 0.0899793952703476
step: 110, loss: 0.08835183084011078
step: 120, loss: 0.10065117478370667
step: 130, loss: 0.08428948372602463
step: 140, loss: 0.07910284399986267
step: 150, loss: 0.05841054022312164
step: 160, loss: 0.09392347186803818
step: 170, loss: 0.10871092230081558
step: 180, loss: 0.047390975058078766
step: 190, loss: 0.10838217288255692
step: 200, loss: 0.05896113067865372
step: 210, loss: 0.02941129170358181
step: 220, loss: 0.009387616999447346
step: 230, loss: 0.09474749863147736
step: 240, loss: 0.07857760787010193
step: 250, loss: 0.0028393517713993788
step: 260, loss: 0.20475561916828156
step: 270, loss: 0.07213596254587173
step: 280, loss: 0.13303160667419434
step: 290, loss: 0.036488767713308334
step: 300, loss: 0.17214278876781464
step: 310, loss: 0.059837259352207184
step: 320, loss: 0.03957914561033249
step: 330, loss: 0.12873394787311554
step: 340, loss: 0.011197537183761597
step: 350, loss: 0.06093384698033333
step: 360, loss: 0.08902401477098465
step: 370, loss: 0.06013055518269539
step: 380, loss: 0.06052166968584061
step: 390, loss: 0.10596675425767899
step: 400, loss: 0.15311285853385925
step: 410, loss: 0.0886497050523758
step: 420, loss: 0.03332311660051346
step: 430, loss: 0.05276256427168846
step: 440, loss: 0.03420150652527809
step: 450, loss: 0.06018213555216789
step: 460, loss: 0.09994044899940491
epoch 4: dev_f1=0.9898762654668166, f1=0.9819413092550789, best_f1=0.9808773903262092
step: 0, loss: 0.0314079225063324
step: 10, loss: 0.08063866198062897
step: 20, loss: 0.1416693478822708
step: 30, loss: 0.08638829737901688
step: 40, loss: 0.1276889145374298
step: 50, loss: 0.10624898225069046
step: 60, loss: 0.03532325476408005
step: 70, loss: 0.014705505222082138
step: 80, loss: 0.00991816632449627
step: 90, loss: 0.07345264405012131
step: 100, loss: 0.008216013200581074
step: 110, loss: 0.016804274171590805
step: 120, loss: 0.01362795289605856
step: 130, loss: 0.02064451202750206
step: 140, loss: 0.05725624039769173
step: 150, loss: 0.06410791724920273
step: 160, loss: 0.15740308165550232
step: 170, loss: 0.00914720818400383
step: 180, loss: 0.037579745054244995
step: 190, loss: 0.013441801071166992
step: 200, loss: 0.013651525601744652
step: 210, loss: 0.04120083153247833
step: 220, loss: 0.08856182545423508
step: 230, loss: 0.06888501346111298
step: 240, loss: 0.05686487257480621
step: 250, loss: 0.08884147554636002
step: 260, loss: 0.09821725636720657
step: 270, loss: 0.005947645753622055
step: 280, loss: 0.05461229011416435
step: 290, loss: 0.11719441413879395
step: 300, loss: 0.11605795472860336
step: 310, loss: 0.06534206867218018
step: 320, loss: 0.0948585495352745
step: 330, loss: 0.10047624260187149
step: 340, loss: 0.022984283044934273
step: 350, loss: 0.09861943870782852
step: 360, loss: 0.054476529359817505
step: 370, loss: 0.07954982668161392
step: 380, loss: 0.1562202125787735
step: 390, loss: 0.09965455532073975
step: 400, loss: 0.03859880939126015
step: 410, loss: 0.048141464591026306
step: 420, loss: 0.01349577121436596
step: 430, loss: 0.030195366591215134
step: 440, loss: 0.04989640787243843
step: 450, loss: 0.18224294483661652
step: 460, loss: 0.07412491738796234
epoch 5: dev_f1=0.9921259842519685, f1=0.9808773903262092, best_f1=0.9808773903262092
step: 0, loss: 0.01835312508046627
step: 10, loss: 0.10640252381563187
step: 20, loss: 0.061984386295080185
step: 30, loss: 0.026162395253777504
step: 40, loss: 0.05456242710351944
step: 50, loss: 0.0631905198097229
step: 60, loss: 0.027554161846637726
step: 70, loss: 0.016980834305286407
step: 80, loss: 0.13431230187416077
step: 90, loss: 0.09829268604516983
step: 100, loss: 0.025073852390050888
step: 110, loss: 0.27035436034202576
step: 120, loss: 0.17488212883472443
step: 130, loss: 0.06777963787317276
step: 140, loss: 0.027618465945124626
step: 150, loss: 0.0815856009721756
step: 160, loss: 0.02094564214348793
step: 170, loss: 0.07214778661727905
step: 180, loss: 0.07665173709392548
step: 190, loss: 0.16743461787700653
step: 200, loss: 0.05563221126794815
step: 210, loss: 0.038662366569042206
step: 220, loss: 0.07174977660179138
step: 230, loss: 0.0689220055937767
step: 240, loss: 0.08492162078619003
step: 250, loss: 0.11274632811546326
step: 260, loss: 0.019919581711292267
step: 270, loss: 0.09887299686670303
step: 280, loss: 0.0399455651640892
step: 290, loss: 0.12029879540205002
step: 300, loss: 0.02127690054476261
step: 310, loss: 0.07939976453781128
step: 320, loss: 0.02445594221353531
step: 330, loss: 0.03313419967889786
step: 340, loss: 0.01644747145473957
step: 350, loss: 0.09058869630098343
step: 360, loss: 0.041219063103199005
step: 370, loss: 0.1064128428697586
step: 380, loss: 0.10709665715694427
step: 390, loss: 0.08326488733291626
step: 400, loss: 0.059530165046453476
step: 410, loss: 0.17488831281661987
step: 420, loss: 0.12181204557418823
step: 430, loss: 0.1221267357468605
step: 440, loss: 0.009751692414283752
step: 450, loss: 0.06846372038125992
step: 460, loss: 0.04384627193212509
epoch 6: dev_f1=0.9921612541993281, f1=0.9821428571428571, best_f1=0.9821428571428571
step: 0, loss: 0.01757024973630905
step: 10, loss: 0.11880680918693542
step: 20, loss: 0.06405968219041824
step: 30, loss: 0.0974680483341217
step: 40, loss: 0.008229865692555904
step: 50, loss: 0.04592880234122276
step: 60, loss: 0.09161598235368729
step: 70, loss: 0.06059698015451431
step: 80, loss: 0.06798724085092545
step: 90, loss: 0.11347485333681107
step: 100, loss: 0.06346923857927322
step: 110, loss: 0.11083988845348358
step: 120, loss: 0.10320241749286652
step: 130, loss: 0.01866348646581173
step: 140, loss: 0.05694511905312538
step: 150, loss: 0.07017803192138672
step: 160, loss: 0.20892898738384247
step: 170, loss: 0.06022325158119202
step: 180, loss: 0.12348323315382004
step: 190, loss: 0.021704083308577538
step: 200, loss: 0.118995800614357
step: 210, loss: 0.046773817390203476
step: 220, loss: 0.020666591823101044
step: 230, loss: 0.01018755417317152
step: 240, loss: 0.029212109744548798
step: 250, loss: 0.06954850256443024
step: 260, loss: 0.0369977131485939
step: 270, loss: 0.18547336757183075
step: 280, loss: 0.2405667006969452
step: 290, loss: 0.03578657656908035
step: 300, loss: 0.02332022413611412
step: 310, loss: 0.14405077695846558
step: 320, loss: 0.01890009641647339
step: 330, loss: 0.05044998228549957
step: 340, loss: 0.060278311371803284
step: 350, loss: 0.013478120788931847
step: 360, loss: 0.017868028953671455
step: 370, loss: 0.1494131088256836
step: 380, loss: 0.04193806275725365
step: 390, loss: 0.08189105242490768
step: 400, loss: 0.02923290617763996
step: 410, loss: 0.14525292813777924
step: 420, loss: 0.002566550625488162
step: 430, loss: 0.00573752773925662
step: 440, loss: 0.166859433054924
step: 450, loss: 0.17818410694599152
step: 460, loss: 0.022791486233472824
epoch 7: dev_f1=0.9886877828054299, f1=0.984090909090909, best_f1=0.9821428571428571
step: 0, loss: 0.006538040470331907
step: 10, loss: 0.06072616949677467
step: 20, loss: 0.01673441007733345
step: 30, loss: 0.033210862427949905
step: 40, loss: 0.07030456513166428
step: 50, loss: 0.00887689646333456
step: 60, loss: 0.05872120335698128
step: 70, loss: 0.013505026698112488
step: 80, loss: 0.008368496783077717
step: 90, loss: 0.07917486876249313
step: 100, loss: 0.01524694636464119
step: 110, loss: 0.10949139297008514
step: 120, loss: 0.015139960683882236
step: 130, loss: 0.045290056616067886
step: 140, loss: 0.01685917004942894
step: 150, loss: 0.0627945140004158
step: 160, loss: 0.013983982615172863
step: 170, loss: 0.056318845599889755
step: 180, loss: 0.1316065639257431
step: 190, loss: 0.0821109488606453
step: 200, loss: 0.08813609182834625
step: 210, loss: 0.04912798851728439
step: 220, loss: 0.04760314151644707
step: 230, loss: 0.13081298768520355
step: 240, loss: 0.06098814308643341
step: 250, loss: 0.1242903620004654
step: 260, loss: 0.052673276513814926
step: 270, loss: 0.016341283917427063
step: 280, loss: 0.0866469144821167
step: 290, loss: 0.06565751880407333
step: 300, loss: 0.042683083564043045
step: 310, loss: 0.025507161393761635
step: 320, loss: 0.012632422149181366
step: 330, loss: 0.16321495175361633
step: 340, loss: 0.026501573622226715
step: 350, loss: 0.04448549076914787
step: 360, loss: 0.11090829968452454
step: 370, loss: 0.058583714067935944
step: 380, loss: 0.06706076115369797
step: 390, loss: 0.0622611902654171
step: 400, loss: 0.07481662929058075
step: 410, loss: 0.09182530641555786
step: 420, loss: 0.07284506410360336
step: 430, loss: 0.030451569706201553
step: 440, loss: 0.1857125461101532
step: 450, loss: 0.05890316888689995
step: 460, loss: 0.10263342410326004
epoch 8: dev_f1=0.9875706214689265, f1=0.9784824462061155, best_f1=0.9821428571428571
step: 0, loss: 0.02276236191391945
step: 10, loss: 0.1332504153251648
step: 20, loss: 0.03823095187544823
step: 30, loss: 0.038415320217609406
step: 40, loss: 0.09223190695047379
step: 50, loss: 0.10071654617786407
step: 60, loss: 0.024050317704677582
step: 70, loss: 0.006001350004225969
step: 80, loss: 0.041148025542497635
step: 90, loss: 0.04760679602622986
step: 100, loss: 0.0355750247836113
step: 110, loss: 0.02147984318435192
step: 120, loss: 0.15853923559188843
step: 130, loss: 0.01821172423660755
step: 140, loss: 0.07956112921237946
step: 150, loss: 0.13803991675376892
step: 160, loss: 0.011303393170237541
step: 170, loss: 0.02319643273949623
step: 180, loss: 0.14928941428661346
step: 190, loss: 0.0963769480586052
step: 200, loss: 0.1931440234184265
step: 210, loss: 0.0195632204413414
step: 220, loss: 0.035262200981378555
step: 230, loss: 0.01738731935620308
step: 240, loss: 0.07875397056341171
step: 250, loss: 0.004426371306180954
step: 260, loss: 0.07796021550893784
step: 270, loss: 0.06652462482452393
step: 280, loss: 0.006541662849485874
step: 290, loss: 0.06868962198495865
step: 300, loss: 0.04004321247339249
step: 310, loss: 0.018587207421660423
step: 320, loss: 0.00456191785633564
step: 330, loss: 0.012996364384889603
step: 340, loss: 0.05518011748790741
step: 350, loss: 0.061351630836725235
step: 360, loss: 0.0970674604177475
step: 370, loss: 0.034601014107465744
step: 380, loss: 0.00013862534251529723
step: 390, loss: 0.08320363610982895
step: 400, loss: 0.04240149259567261
step: 410, loss: 0.053661808371543884
step: 420, loss: 0.11306534707546234
step: 430, loss: 0.0016789169749245048
step: 440, loss: 0.03538285940885544
step: 450, loss: 0.07526389509439468
step: 460, loss: 0.01844118721783161
epoch 9: dev_f1=0.9898762654668166, f1=0.9821029082774049, best_f1=0.9821428571428571
step: 0, loss: 0.00478821387514472
step: 10, loss: 0.04615410417318344
step: 20, loss: 0.02057536691427231
step: 30, loss: 0.012487889267504215
step: 40, loss: 0.006935473997145891
step: 50, loss: 0.03288055583834648
step: 60, loss: 0.023846322670578957
step: 70, loss: 0.03040394000709057
step: 80, loss: 0.13077539205551147
step: 90, loss: 0.10241176187992096
step: 100, loss: 0.047386862337589264
step: 110, loss: 0.02214706689119339
step: 120, loss: 0.04415171965956688
step: 130, loss: 0.024921825155615807
step: 140, loss: 0.02005993016064167
step: 150, loss: 0.057868801057338715
step: 160, loss: 0.055237818509340286
step: 170, loss: 0.0862116888165474
step: 180, loss: 0.03087039664387703
step: 190, loss: 0.026674417778849602
step: 200, loss: 0.12893623113632202
step: 210, loss: 0.011140509508550167
step: 220, loss: 0.06908894330263138
step: 230, loss: 0.04373568668961525
step: 240, loss: 0.024139875546097755
step: 250, loss: 0.025087138637900352
step: 260, loss: 0.052342500537633896
step: 270, loss: 0.014014816842973232
step: 280, loss: 0.07548072189092636
step: 290, loss: 0.06475986540317535
step: 300, loss: 0.04505316540598869
step: 310, loss: 0.02984161302447319
step: 320, loss: 0.16007624566555023
step: 330, loss: 0.3184497654438019
step: 340, loss: 0.06258606165647507
step: 350, loss: 0.00540171517059207
step: 360, loss: 0.0988280177116394
step: 370, loss: 0.01253631804138422
step: 380, loss: 0.003681657137349248
step: 390, loss: 0.06566260010004044
step: 400, loss: 0.034653183072805405
step: 410, loss: 0.06263487786054611
step: 420, loss: 0.013684111647307873
step: 430, loss: 0.031613338738679886
step: 440, loss: 0.15835271775722504
step: 450, loss: 0.007101088296622038
step: 460, loss: 0.05290691927075386
epoch 10: dev_f1=0.990990990990991, f1=0.9798657718120806, best_f1=0.9821428571428571
step: 0, loss: 0.03347048908472061
step: 10, loss: 0.031173191964626312
step: 20, loss: 0.05153747648000717
step: 30, loss: 0.0057444460690021515
step: 40, loss: 0.00017687339277472347
step: 50, loss: 0.0940210297703743
step: 60, loss: 0.053406547755002975
step: 70, loss: 0.03692937269806862
step: 80, loss: 0.03194807097315788
step: 90, loss: 0.044935908168554306
step: 100, loss: 0.0601813979446888
step: 110, loss: 0.08239539712667465
step: 120, loss: 0.08103668689727783
step: 130, loss: 0.07756233960390091
step: 140, loss: 0.009427512995898724
step: 150, loss: 0.0024653852451592684
step: 160, loss: 0.0020749119576066732
step: 170, loss: 0.03483826667070389
step: 180, loss: 0.08058985322713852
step: 190, loss: 0.07297881692647934
step: 200, loss: 0.039180632680654526
step: 210, loss: 0.04877229407429695
step: 220, loss: 0.029970472678542137
step: 230, loss: 0.029990147799253464
step: 240, loss: 0.06243116408586502
step: 250, loss: 0.0007411448168568313
step: 260, loss: 0.10793744772672653
step: 270, loss: 0.024821549654006958
step: 280, loss: 0.015583103522658348
step: 290, loss: 0.04863817244768143
step: 300, loss: 0.029806891456246376
step: 310, loss: 0.043061356991529465
step: 320, loss: 0.027948053553700447
step: 330, loss: 0.06446798890829086
step: 340, loss: 0.10825137048959732
step: 350, loss: 0.057668741792440414
step: 360, loss: 0.021101312711834908
step: 370, loss: 0.004239778034389019
step: 380, loss: 0.00916675291955471
step: 390, loss: 0.004123657010495663
step: 400, loss: 0.07037226110696793
step: 410, loss: 0.0847124233841896
step: 420, loss: 0.0655369907617569
step: 430, loss: 0.05887980759143829
step: 440, loss: 0.028730671852827072
step: 450, loss: 0.15717479586601257
step: 460, loss: 0.02733692340552807
epoch 11: dev_f1=0.9898534385569334, f1=0.9787709497206705, best_f1=0.9821428571428571
step: 0, loss: 0.03578760847449303
step: 10, loss: 0.05679285153746605
step: 20, loss: 0.025404298678040504
step: 30, loss: 0.004173227120190859
step: 40, loss: 0.0898156389594078
step: 50, loss: 0.006188724655658007
step: 60, loss: 0.00495054991915822
step: 70, loss: 0.028807973489165306
step: 80, loss: 0.03089401312172413
step: 90, loss: 0.053435374051332474
step: 100, loss: 0.008221418596804142
step: 110, loss: 0.057431288063526154
step: 120, loss: 0.19421425461769104
step: 130, loss: 0.018827129155397415
step: 140, loss: 1.479668208048679e-05
step: 150, loss: 0.04003159701824188
step: 160, loss: 0.036061156541109085
step: 170, loss: 0.031868383288383484
step: 180, loss: 0.10763396322727203
step: 190, loss: 0.04542072117328644
step: 200, loss: 0.0002775641914922744
step: 210, loss: 0.030247801914811134
step: 220, loss: 0.04408703371882439
step: 230, loss: 0.09303051978349686
step: 240, loss: 0.11053026467561722
step: 250, loss: 0.05214942246675491
step: 260, loss: 0.06730344146490097
step: 270, loss: 0.03265487030148506
step: 280, loss: 0.04196171462535858
step: 290, loss: 0.04313654452562332
step: 300, loss: 0.026252076029777527
step: 310, loss: 0.023161066696047783
step: 320, loss: 0.03336486592888832
step: 330, loss: 0.0769350603222847
step: 340, loss: 0.07269930839538574
step: 350, loss: 0.09216149896383286
step: 360, loss: 0.0025205842684954405
step: 370, loss: 0.02892274223268032
step: 380, loss: 0.06384613364934921
step: 390, loss: 0.04954395815730095
step: 400, loss: 0.02429739199578762
step: 410, loss: 0.058148711919784546
step: 420, loss: 0.0376497320830822
step: 430, loss: 0.00041285192128270864
step: 440, loss: 0.044889580458402634
step: 450, loss: 0.06253339350223541
step: 460, loss: 0.06698097288608551
epoch 12: dev_f1=0.990990990990991, f1=0.978675645342312, best_f1=0.9821428571428571
step: 0, loss: 0.04600336402654648
step: 10, loss: 0.05035201832652092
step: 20, loss: 0.11401838064193726
step: 30, loss: 0.07830847799777985
step: 40, loss: 0.02849959209561348
step: 50, loss: 0.0020215860567986965
step: 60, loss: 0.016336318105459213
step: 70, loss: 0.07819166779518127
step: 80, loss: 0.0008127925102598965
step: 90, loss: 0.048806603997945786
step: 100, loss: 0.047613292932510376
step: 110, loss: 0.05521848052740097
step: 120, loss: 0.0006421138532459736
step: 130, loss: 0.04073341190814972
step: 140, loss: 0.044243209064006805
step: 150, loss: 0.04425635561347008
step: 160, loss: 2.857574145309627e-05
step: 170, loss: 0.02454480715095997
step: 180, loss: 0.05140391364693642
step: 190, loss: 0.005453594960272312
step: 200, loss: 0.06606892496347427
step: 210, loss: 0.024477945640683174
step: 220, loss: 0.023759961128234863
step: 230, loss: 0.0019471498671919107
step: 240, loss: 0.08076102286577225
step: 250, loss: 0.0688193291425705
step: 260, loss: 0.06783536076545715
step: 270, loss: 0.06712176650762558
step: 280, loss: 0.015365377999842167
step: 290, loss: 0.026400376111268997
step: 300, loss: 0.256671279668808
step: 310, loss: 0.00607063015922904
step: 320, loss: 0.11422548443078995
step: 330, loss: 0.0284989345818758
step: 340, loss: 0.04536151885986328
step: 350, loss: 0.00031379875144921243
step: 360, loss: 0.030062278732657433
step: 370, loss: 0.13205058872699738
step: 380, loss: 0.027700532227754593
step: 390, loss: 0.02640368975698948
step: 400, loss: 0.086590476334095
step: 410, loss: 6.3768369727768e-05
step: 420, loss: 0.036864932626485825
step: 430, loss: 0.01735672913491726
step: 440, loss: 0.04684358462691307
step: 450, loss: 0.11617542058229446
step: 460, loss: 0.04243314638733864
epoch 13: dev_f1=0.9898989898989898, f1=0.9766925638179801, best_f1=0.9821428571428571
step: 0, loss: 0.0401160754263401
step: 10, loss: 0.041399095207452774
step: 20, loss: 0.020802229642868042
step: 30, loss: 0.03643929585814476
step: 40, loss: 0.06404155492782593
step: 50, loss: 0.03906850889325142
step: 60, loss: 0.018511710688471794
step: 70, loss: 0.02059454657137394
step: 80, loss: 0.0004546449054032564
step: 90, loss: 0.03744662180542946
step: 100, loss: 0.024724822491407394
step: 110, loss: 0.0010216723894700408
step: 120, loss: 0.05764386057853699
step: 130, loss: 0.05232656002044678
step: 140, loss: 0.022889042273163795
step: 150, loss: 0.03728187456727028
step: 160, loss: 0.016320807859301567
step: 170, loss: 0.10104558616876602
step: 180, loss: 0.05305694416165352
step: 190, loss: 0.06496552377939224
step: 200, loss: 0.002749875420704484
step: 210, loss: 0.03853977471590042
step: 220, loss: 0.04751761257648468
step: 230, loss: 0.033270854502916336
step: 240, loss: 6.36884942650795e-05
step: 250, loss: 0.06942789256572723
step: 260, loss: 0.034904759377241135
step: 270, loss: 0.06038666516542435
step: 280, loss: 0.02332453429698944
step: 290, loss: 0.025069979950785637
step: 300, loss: 0.032972224056720734
step: 310, loss: 0.04348485916852951
step: 320, loss: 0.04542333260178566
step: 330, loss: 0.001721266540698707
step: 340, loss: 0.06649002432823181
step: 350, loss: 0.005818693432956934
step: 360, loss: 0.029106082394719124
step: 370, loss: 0.0014037027722224593
step: 380, loss: 0.07067122310400009
step: 390, loss: 0.0012639969354495406
step: 400, loss: 0.04378844425082207
step: 410, loss: 0.02289377897977829
step: 420, loss: 0.021472807973623276
step: 430, loss: 0.004482673481106758
step: 440, loss: 0.016990043222904205
step: 450, loss: 0.019793707877397537
step: 460, loss: 0.029495302587747574
epoch 14: dev_f1=0.9909706546275394, f1=0.9819004524886877, best_f1=0.9821428571428571
step: 0, loss: 0.04336602985858917
step: 10, loss: 0.06313850730657578
step: 20, loss: 0.03791392594575882
step: 30, loss: 0.025893734768033028
step: 40, loss: 0.016812335699796677
step: 50, loss: 0.023228824138641357
step: 60, loss: 0.04499012604355812
step: 70, loss: 0.0001034032175084576
step: 80, loss: 0.046417564153671265
step: 90, loss: 0.0068001169711351395
step: 100, loss: 0.014652417972683907
step: 110, loss: 0.056439969688653946
step: 120, loss: 0.02016063779592514
step: 130, loss: 0.04800020903348923
step: 140, loss: 0.05163620412349701
step: 150, loss: 0.03072899952530861
step: 160, loss: 0.07196611166000366
step: 170, loss: 0.03333837538957596
step: 180, loss: 0.005026255268603563
step: 190, loss: 0.020209213718771935
step: 200, loss: 6.776477675884962e-05
step: 210, loss: 0.0001921787770697847
step: 220, loss: 0.023586489260196686
step: 230, loss: 0.05680810287594795
step: 240, loss: 0.09146487712860107
step: 250, loss: 0.0645584911108017
step: 260, loss: 0.030487727373838425
step: 270, loss: 0.0851060077548027
step: 280, loss: 0.015801161527633667
step: 290, loss: 0.044772252440452576
step: 300, loss: 0.04239323362708092
step: 310, loss: 0.0005550353089347482
step: 320, loss: 0.05104316398501396
step: 330, loss: 0.02153387852013111
step: 340, loss: 0.020616671070456505
step: 350, loss: 0.0002610122028272599
step: 360, loss: 0.014896346256136894
step: 370, loss: 0.026830343529582024
step: 380, loss: 0.04000799357891083
step: 390, loss: 0.06503690779209137
step: 400, loss: 0.05752803012728691
step: 410, loss: 0.04470326751470566
step: 420, loss: 0.020471567288041115
step: 430, loss: 0.042569417506456375
step: 440, loss: 0.0002940854465123266
step: 450, loss: 0.030889760702848434
step: 460, loss: 0.04405964910984039
epoch 15: dev_f1=0.9898762654668166, f1=0.9788182831661093, best_f1=0.9821428571428571
step: 0, loss: 0.00033813167829066515
step: 10, loss: 0.041631970554590225
step: 20, loss: 0.0016128112329170108
step: 30, loss: 0.027020685374736786
step: 40, loss: 0.03021370619535446
step: 50, loss: 0.1118159219622612
step: 60, loss: 0.06388463824987411
step: 70, loss: 0.02610115148127079
step: 80, loss: 0.0005850386223755777
step: 90, loss: 0.0007933183806017041
step: 100, loss: 0.0011814277386292815
step: 110, loss: 0.02153363823890686
step: 120, loss: 0.06652778387069702
step: 130, loss: 0.030115002766251564
step: 140, loss: 0.042728547006845474
step: 150, loss: 0.006031583528965712
step: 160, loss: 0.000133889087010175
step: 170, loss: 0.01648806221783161
step: 180, loss: 0.020436357706785202
step: 190, loss: 0.03528713434934616
step: 200, loss: 0.025018107146024704
step: 210, loss: 0.027454297989606857
step: 220, loss: 0.010969891212880611
step: 230, loss: 0.13257010281085968
step: 240, loss: 6.633911107201129e-05
step: 250, loss: 0.025555510073900223
step: 260, loss: 0.01997961662709713
step: 270, loss: 0.09095245599746704
step: 280, loss: 0.038320139050483704
step: 290, loss: 0.038836557418107986
step: 300, loss: 0.024723906069993973
step: 310, loss: 0.0653095692396164
step: 320, loss: 0.0797836184501648
step: 330, loss: 9.301225509261712e-05
step: 340, loss: 0.0281068105250597
step: 350, loss: 0.05035717040300369
step: 360, loss: 0.029582608491182327
step: 370, loss: 0.055626530200242996
step: 380, loss: 0.017359495162963867
step: 390, loss: 0.022593887522816658
step: 400, loss: 0.026149598881602287
step: 410, loss: 0.018963804468512535
step: 420, loss: 0.0638413280248642
step: 430, loss: 0.0004033978621009737
step: 440, loss: 0.00021875678794458508
step: 450, loss: 0.021692665293812752
step: 460, loss: 0.0015652410220354795
epoch 16: dev_f1=0.9898762654668166, f1=0.980963045912654, best_f1=0.9821428571428571
step: 0, loss: 0.022114595398306847
step: 10, loss: 0.12450758367776871
step: 20, loss: 0.021579312160611153
step: 30, loss: 0.02334311045706272
step: 40, loss: 0.03911334276199341
step: 50, loss: 0.05690794438123703
step: 60, loss: 0.039416033774614334
step: 70, loss: 0.055374663323163986
step: 80, loss: 0.02450593002140522
step: 90, loss: 0.007627577055245638
step: 100, loss: 0.0022655916400253773
step: 110, loss: 0.0009942632168531418
step: 120, loss: 0.001674547791481018
step: 130, loss: 8.667953807162121e-05
step: 140, loss: 0.024021027609705925
step: 150, loss: 0.019123416393995285
step: 160, loss: 0.06136592850089073
step: 170, loss: 0.0003700809320434928
step: 180, loss: 0.08565745502710342
step: 190, loss: 0.021890789270401
step: 200, loss: 0.03011651150882244
step: 210, loss: 0.045769404619932175
step: 220, loss: 0.05378343164920807
step: 230, loss: 0.05929645523428917
step: 240, loss: 0.02797538973391056
step: 250, loss: 0.017667876556515694
step: 260, loss: 0.027780402451753616
step: 270, loss: 0.0376129150390625
step: 280, loss: 0.026115117594599724
step: 290, loss: 0.04426101595163345
step: 300, loss: 4.102588718524203e-05
step: 310, loss: 0.018363969400525093
step: 320, loss: 0.06343565136194229
step: 330, loss: 0.02033461257815361
step: 340, loss: 0.02279168926179409
step: 350, loss: 0.061406347900629044
step: 360, loss: 0.022261599078774452
step: 370, loss: 2.008630872296635e-05
step: 380, loss: 0.00010337185813114047
step: 390, loss: 0.015801861882209778
step: 400, loss: 7.996692875167355e-05
step: 410, loss: 0.010335310362279415
step: 420, loss: 0.022267354652285576
step: 430, loss: 0.09108790010213852
step: 440, loss: 0.0008294328581541777
step: 450, loss: 0.023826314136385918
step: 460, loss: 0.04430568590760231
epoch 17: dev_f1=0.9910313901345291, f1=0.978865406006674, best_f1=0.9821428571428571
step: 0, loss: 0.024916071444749832
step: 10, loss: 0.06674738228321075
step: 20, loss: 0.019990697503089905
step: 30, loss: 0.06512560695409775
step: 40, loss: 0.03511691465973854
step: 50, loss: 0.026619382202625275
step: 60, loss: 0.03357861936092377
step: 70, loss: 0.00014089373871684074
step: 80, loss: 0.07939805835485458
step: 90, loss: 0.055190954357385635
step: 100, loss: 0.0597248300909996
step: 110, loss: 0.025854378938674927
step: 120, loss: 0.011914228089153767
step: 130, loss: 0.04081202670931816
step: 140, loss: 0.06020656228065491
step: 150, loss: 0.06789088249206543
step: 160, loss: 0.07576952129602432
step: 170, loss: 0.023128416389226913
step: 180, loss: 0.04235310107469559
step: 190, loss: 0.015758976340293884
step: 200, loss: 0.06266774237155914
step: 210, loss: 0.023593422025442123
step: 220, loss: 0.037080973386764526
step: 230, loss: 5.607483035419136e-05
step: 240, loss: 0.021888725459575653
step: 250, loss: 0.0638265460729599
step: 260, loss: 0.042951662093400955
step: 270, loss: 0.006059297826141119
step: 280, loss: 0.08346294611692429
step: 290, loss: 0.025079866871237755
step: 300, loss: 0.021830813959240913
step: 310, loss: 0.02660432644188404
step: 320, loss: 0.037151090800762177
step: 330, loss: 0.05046660080552101
step: 340, loss: 0.024438168853521347
step: 350, loss: 0.017391355708241463
step: 360, loss: 0.023785291239619255
step: 370, loss: 0.05400606989860535
step: 380, loss: 0.004120992496609688
step: 390, loss: 0.05234374850988388
step: 400, loss: 0.02266354113817215
step: 410, loss: 0.07506939768791199
step: 420, loss: 0.030584653839468956
step: 430, loss: 0.024270666763186455
step: 440, loss: 0.0281439907848835
step: 450, loss: 0.10670292377471924
step: 460, loss: 0.05091322585940361
epoch 18: dev_f1=0.9898762654668166, f1=0.980963045912654, best_f1=0.9821428571428571
step: 0, loss: 0.05913896486163139
step: 10, loss: 0.0010350096272304654
step: 20, loss: 0.059578027576208115
step: 30, loss: 0.04226072505116463
step: 40, loss: 0.024740280583500862
step: 50, loss: 0.07250973582267761
step: 60, loss: 4.786703357240185e-05
step: 70, loss: 0.04440140724182129
step: 80, loss: 0.01970309019088745
step: 90, loss: 0.03823929280042648
step: 100, loss: 0.02467332035303116
step: 110, loss: 0.0001682573347352445
step: 120, loss: 0.00015746084682177752
step: 130, loss: 0.034921593964099884
step: 140, loss: 0.02238638512790203
step: 150, loss: 0.07770746946334839
step: 160, loss: 0.07303570955991745
step: 170, loss: 0.04530865326523781
step: 180, loss: 0.07811735570430756
step: 190, loss: 0.021070363000035286
step: 200, loss: 0.04622327536344528
step: 210, loss: 0.037245284765958786
step: 220, loss: 0.02098422683775425
step: 230, loss: 0.02004464529454708
step: 240, loss: 0.020690158009529114
step: 250, loss: 0.04604227840900421
step: 260, loss: 0.020767930895090103
step: 270, loss: 0.09397374838590622
step: 280, loss: 0.02546485885977745
step: 290, loss: 0.03751245513558388
step: 300, loss: 0.025144606828689575
step: 310, loss: 1.5426132449647412e-05
step: 320, loss: 0.07360430061817169
step: 330, loss: 0.024435074999928474
step: 340, loss: 0.10280647873878479
step: 350, loss: 2.8781569199054502e-05
step: 360, loss: 0.07673908025026321
step: 370, loss: 0.08305040001869202
step: 380, loss: 0.021792368963360786
step: 390, loss: 0.0005759429768659174
step: 400, loss: 0.02219509705901146
step: 410, loss: 0.041925098747015
step: 420, loss: 0.02620493248105049
step: 430, loss: 0.017218846827745438
step: 440, loss: 0.00941795390099287
step: 450, loss: 0.05787079781293869
step: 460, loss: 0.024539513513445854
epoch 19: dev_f1=0.9898762654668166, f1=0.980963045912654, best_f1=0.9821428571428571
step: 0, loss: 3.4800534194801e-05
step: 10, loss: 0.02631705068051815
step: 20, loss: 0.00021724647376686335
step: 30, loss: 0.019490588456392288
step: 40, loss: 0.01679561845958233
step: 50, loss: 0.061260372400283813
step: 60, loss: 0.039509519934654236
step: 70, loss: 0.020077118650078773
step: 80, loss: 0.022023744881153107
step: 90, loss: 0.03227974846959114
step: 100, loss: 0.016898605972528458
step: 110, loss: 0.08427387475967407
step: 120, loss: 0.021075546741485596
step: 130, loss: 0.03374427929520607
step: 140, loss: 0.09782086312770844
step: 150, loss: 0.060058336704969406
step: 160, loss: 1.902753865579143e-05
step: 170, loss: 0.0668587014079094
step: 180, loss: 0.08140906691551208
step: 190, loss: 0.0846346914768219
step: 200, loss: 0.06314960867166519
step: 210, loss: 0.02006259374320507
step: 220, loss: 0.046102214604616165
step: 230, loss: 0.01812509074807167
step: 240, loss: 0.020563248544931412
step: 250, loss: 0.030123114585876465
step: 260, loss: 0.018575042486190796
step: 270, loss: 0.03969372808933258
step: 280, loss: 0.038934376090765
step: 290, loss: 0.058678314089775085
step: 300, loss: 8.430010348092765e-05
step: 310, loss: 0.03794179856777191
step: 320, loss: 0.00019090432033408433
step: 330, loss: 0.046006303280591965
step: 340, loss: 0.00922782626003027
step: 350, loss: 0.027486873790621758
step: 360, loss: 0.02023088000714779
step: 370, loss: 0.07883039116859436
step: 380, loss: 0.023524396121501923
step: 390, loss: 0.021233968436717987
step: 400, loss: 0.01706426963210106
step: 410, loss: 0.05080882087349892
step: 420, loss: 0.00010992505121976137
step: 430, loss: 0.0972607433795929
step: 440, loss: 0.000654450966976583
step: 450, loss: 0.102848581969738
step: 460, loss: 0.02302439510822296
epoch 20: dev_f1=0.9898762654668166, f1=0.980963045912654, best_f1=0.9821428571428571
