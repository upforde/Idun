cuda
Device: cuda
step: 0, loss: 0.7338420152664185
step: 10, loss: 0.5092413425445557
step: 20, loss: 0.4161645174026489
step: 30, loss: 0.17968124151229858
step: 40, loss: 0.1429111808538437
step: 50, loss: 0.2279384434223175
step: 60, loss: 0.36936867237091064
step: 70, loss: 0.22884400188922882
step: 80, loss: 0.13244464993476868
step: 90, loss: 0.32172590494155884
step: 100, loss: 0.1467905044555664
step: 110, loss: 0.1938733011484146
step: 120, loss: 0.11916657537221909
step: 130, loss: 0.24506798386573792
step: 140, loss: 0.23711708188056946
step: 150, loss: 0.5381222367286682
step: 160, loss: 0.1891440451145172
step: 170, loss: 0.09916049242019653
step: 180, loss: 0.15841086208820343
step: 190, loss: 0.0824936106801033
step: 200, loss: 0.18070410192012787
step: 210, loss: 0.23665523529052734
step: 220, loss: 0.1772572100162506
step: 230, loss: 0.2283935844898224
step: 240, loss: 0.18294759094715118
step: 250, loss: 0.14530418813228607
step: 260, loss: 0.10966742783784866
step: 270, loss: 0.15747371315956116
step: 280, loss: 0.14523304998874664
step: 290, loss: 0.05966024473309517
step: 300, loss: 0.23025637865066528
step: 310, loss: 0.1271859109401703
step: 320, loss: 0.13964714109897614
step: 330, loss: 0.08626111596822739
step: 340, loss: 0.08533652126789093
step: 350, loss: 0.2056485265493393
step: 360, loss: 0.08242146670818329
step: 370, loss: 0.06698344647884369
step: 380, loss: 0.12338513135910034
step: 390, loss: 0.09936396777629852
step: 400, loss: 0.23699264228343964
step: 410, loss: 0.18715494871139526
step: 420, loss: 0.07789073884487152
step: 430, loss: 0.03733064606785774
step: 440, loss: 0.06414994597434998
step: 450, loss: 0.14567381143569946
step: 460, loss: 0.06000012904405594
epoch 1: dev_f1=0.9842342342342343, f1=0.9785310734463276, best_f1=0.9785310734463276
step: 0, loss: 0.016357505694031715
step: 10, loss: 0.05030371621251106
step: 20, loss: 0.12028398364782333
step: 30, loss: 0.14356611669063568
step: 40, loss: 0.18731465935707092
step: 50, loss: 0.1401878446340561
step: 60, loss: 0.18228520452976227
step: 70, loss: 0.028018957003951073
step: 80, loss: 0.02914297766983509
step: 90, loss: 0.14273516833782196
step: 100, loss: 0.007416852284222841
step: 110, loss: 0.036777958273887634
step: 120, loss: 0.041342802345752716
step: 130, loss: 0.049655020236968994
step: 140, loss: 0.027627846226096153
step: 150, loss: 0.07904472202062607
step: 160, loss: 0.13010291755199432
step: 170, loss: 0.1721343845129013
step: 180, loss: 0.13121753931045532
step: 190, loss: 0.044487692415714264
step: 200, loss: 0.021211091428995132
step: 210, loss: 0.23252545297145844
step: 220, loss: 0.03818211704492569
step: 230, loss: 0.2820729911327362
step: 240, loss: 0.1049363762140274
step: 250, loss: 0.09873983263969421
step: 260, loss: 0.174874946475029
step: 270, loss: 0.10785696655511856
step: 280, loss: 0.08357752859592438
step: 290, loss: 0.036471378058195114
step: 300, loss: 0.062031280249357224
step: 310, loss: 0.09251149743795395
step: 320, loss: 0.028983736410737038
step: 330, loss: 0.058739662170410156
step: 340, loss: 0.03014199435710907
step: 350, loss: 0.1217263862490654
step: 360, loss: 0.0785917267203331
step: 370, loss: 0.14841808378696442
step: 380, loss: 0.12123847752809525
step: 390, loss: 0.09309534728527069
step: 400, loss: 0.040384676307439804
step: 410, loss: 0.11015155911445618
step: 420, loss: 0.08707530796527863
step: 430, loss: 0.06635352969169617
step: 440, loss: 0.08641281723976135
step: 450, loss: 0.12787866592407227
step: 460, loss: 0.10897666215896606
epoch 2: dev_f1=0.9819819819819819, f1=0.9751693002257337, best_f1=0.9785310734463276
step: 0, loss: 0.0637156143784523
step: 10, loss: 0.09389746934175491
step: 20, loss: 0.057852715253829956
step: 30, loss: 0.19646181166172028
step: 40, loss: 0.11043770611286163
step: 50, loss: 0.1366090476512909
step: 60, loss: 0.031154992058873177
step: 70, loss: 0.05483805015683174
step: 80, loss: 0.05777083709836006
step: 90, loss: 0.017507784068584442
step: 100, loss: 0.027900323271751404
step: 110, loss: 0.12580443918704987
step: 120, loss: 0.0784110277891159
step: 130, loss: 0.0068449298851192
step: 140, loss: 0.049633242189884186
step: 150, loss: 0.06298046559095383
step: 160, loss: 0.06859616190195084
step: 170, loss: 0.17455479502677917
step: 180, loss: 0.046968262642621994
step: 190, loss: 0.058748308569192886
step: 200, loss: 0.048170655965805054
step: 210, loss: 0.01721246913075447
step: 220, loss: 0.00608882075175643
step: 230, loss: 0.03710426762700081
step: 240, loss: 0.043907977640628815
step: 250, loss: 0.08824863284826279
step: 260, loss: 0.01675412617623806
step: 270, loss: 0.06846310943365097
step: 280, loss: 0.047185998409986496
step: 290, loss: 0.057545583695173264
step: 300, loss: 0.13613826036453247
step: 310, loss: 0.17469556629657745
step: 320, loss: 0.04535982012748718
step: 330, loss: 0.07408364862203598
step: 340, loss: 0.1270962804555893
step: 350, loss: 0.06008823215961456
step: 360, loss: 0.009813033975660801
step: 370, loss: 0.055618707090616226
step: 380, loss: 0.08008822053670883
step: 390, loss: 0.08058032393455505
step: 400, loss: 0.14097607135772705
step: 410, loss: 0.1322934627532959
step: 420, loss: 0.06745614111423492
step: 430, loss: 0.046047747135162354
step: 440, loss: 0.00973463524132967
step: 450, loss: 0.05822433903813362
step: 460, loss: 0.07706799358129501
epoch 3: dev_f1=0.9887892376681614, f1=0.9821428571428571, best_f1=0.9821428571428571
step: 0, loss: 0.08125843107700348
step: 10, loss: 0.13335449993610382
step: 20, loss: 0.09615699201822281
step: 30, loss: 0.08866264671087265
step: 40, loss: 0.0597759447991848
step: 50, loss: 0.06656833738088608
step: 60, loss: 0.01057201623916626
step: 70, loss: 0.01996336318552494
step: 80, loss: 0.021167265251278877
step: 90, loss: 0.09657768905162811
step: 100, loss: 0.05767572298645973
step: 110, loss: 0.1633618324995041
step: 120, loss: 0.011209694668650627
step: 130, loss: 0.014789053238928318
step: 140, loss: 0.08421576768159866
step: 150, loss: 0.00023761473130434752
step: 160, loss: 0.07022204995155334
step: 170, loss: 0.05966652184724808
step: 180, loss: 0.09207326173782349
step: 190, loss: 0.08238019049167633
step: 200, loss: 0.06467871367931366
step: 210, loss: 0.03047630749642849
step: 220, loss: 0.07423488795757294
step: 230, loss: 0.009271163493394852
step: 240, loss: 0.03799515590071678
step: 250, loss: 0.09684870392084122
step: 260, loss: 0.12254255264997482
step: 270, loss: 0.0003973876591771841
step: 280, loss: 0.011354263871908188
step: 290, loss: 0.07277985662221909
step: 300, loss: 0.13955458998680115
step: 310, loss: 0.09121827781200409
step: 320, loss: 0.026471395045518875
step: 330, loss: 0.08221545815467834
step: 340, loss: 0.019162779673933983
step: 350, loss: 0.06855582445859909
step: 360, loss: 0.06789352744817734
step: 370, loss: 0.018448904156684875
step: 380, loss: 0.008120850659906864
step: 390, loss: 0.05406317114830017
step: 400, loss: 0.06284121423959732
step: 410, loss: 0.04005526378750801
step: 420, loss: 0.2004820704460144
step: 430, loss: 0.0316259041428566
step: 440, loss: 0.1463194489479065
step: 450, loss: 0.0006002040463499725
step: 460, loss: 0.08591526746749878
epoch 4: dev_f1=0.9921259842519685, f1=0.9819819819819819, best_f1=0.9819819819819819
step: 0, loss: 0.0325276255607605
step: 10, loss: 0.11090841144323349
step: 20, loss: 0.026237474754452705
step: 30, loss: 0.13000693917274475
step: 40, loss: 0.10735509544610977
step: 50, loss: 0.0971713587641716
step: 60, loss: 0.014555252157151699
step: 70, loss: 0.2724110782146454
step: 80, loss: 0.09131450206041336
step: 90, loss: 0.05160859227180481
step: 100, loss: 0.056709226220846176
step: 110, loss: 0.041584763675928116
step: 120, loss: 0.031100504100322723
step: 130, loss: 0.02947780303657055
step: 140, loss: 0.030826661735773087
step: 150, loss: 0.01794504001736641
step: 160, loss: 0.0681617334485054
step: 170, loss: 0.06303074955940247
step: 180, loss: 0.008902105502784252
step: 190, loss: 0.009591649286448956
step: 200, loss: 0.06103897839784622
step: 210, loss: 0.0010260912822559476
step: 220, loss: 0.036696866154670715
step: 230, loss: 0.09104997664690018
step: 240, loss: 0.03451529145240784
step: 250, loss: 0.14967899024486542
step: 260, loss: 0.0369475856423378
step: 270, loss: 0.015231122262775898
step: 280, loss: 0.11161522567272186
step: 290, loss: 0.010577769950032234
step: 300, loss: 0.005962925963103771
step: 310, loss: 0.01482202298939228
step: 320, loss: 0.0893566906452179
step: 330, loss: 0.16092191636562347
step: 340, loss: 0.02325349673628807
step: 350, loss: 0.14868217706680298
step: 360, loss: 0.07630203664302826
step: 370, loss: 0.0165395624935627
step: 380, loss: 0.006615395657718182
step: 390, loss: 0.11215689033269882
step: 400, loss: 0.07171086221933365
step: 410, loss: 0.007537905592471361
step: 420, loss: 0.12697306275367737
step: 430, loss: 0.009887594729661942
step: 440, loss: 0.02675563283264637
step: 450, loss: 0.09291784465312958
step: 460, loss: 0.07566559314727783
epoch 5: dev_f1=0.987598647125141, f1=0.9819413092550789, best_f1=0.9819819819819819
step: 0, loss: 0.1984485685825348
step: 10, loss: 0.05775448679924011
step: 20, loss: 0.07414694875478745
step: 30, loss: 0.03501645103096962
step: 40, loss: 0.05386160686612129
step: 50, loss: 0.09628557413816452
step: 60, loss: 0.0828414112329483
step: 70, loss: 0.017043324187397957
step: 80, loss: 0.03538571670651436
step: 90, loss: 0.02230060286819935
step: 100, loss: 0.0631999596953392
step: 110, loss: 0.03903896361589432
step: 120, loss: 0.023733725771307945
step: 130, loss: 0.06402277946472168
step: 140, loss: 0.017342528328299522
step: 150, loss: 0.03652964532375336
step: 160, loss: 0.08047640323638916
step: 170, loss: 0.05345278978347778
step: 180, loss: 0.07481084764003754
step: 190, loss: 0.015063820406794548
step: 200, loss: 0.044925205409526825
step: 210, loss: 0.06498796492815018
step: 220, loss: 0.08220890164375305
step: 230, loss: 0.04910854622721672
step: 240, loss: 0.14087919890880585
step: 250, loss: 0.10261888802051544
step: 260, loss: 0.04077436402440071
step: 270, loss: 0.016060393303632736
step: 280, loss: 0.04954381287097931
step: 290, loss: 0.03751085326075554
step: 300, loss: 0.09794425219297409
step: 310, loss: 0.08536682277917862
step: 320, loss: 0.13025200366973877
step: 330, loss: 0.19569861888885498
step: 340, loss: 0.015599897131323814
step: 350, loss: 0.009318576194345951
step: 360, loss: 0.0076340436935424805
step: 370, loss: 0.011385781690478325
step: 380, loss: 0.08370326459407806
step: 390, loss: 0.18845856189727783
step: 400, loss: 0.052487876266241074
step: 410, loss: 0.11690175533294678
step: 420, loss: 0.09032206982374191
step: 430, loss: 0.11938513070344925
step: 440, loss: 0.0971931666135788
step: 450, loss: 0.0068392083048820496
step: 460, loss: 0.0996558740735054
epoch 6: dev_f1=0.990990990990991, f1=0.9808342728297633, best_f1=0.9819819819819819
step: 0, loss: 0.12114840000867844
step: 10, loss: 0.06630561500787735
step: 20, loss: 0.03891286626458168
step: 30, loss: 0.055244240909814835
step: 40, loss: 0.04975275695323944
step: 50, loss: 0.08930888026952744
step: 60, loss: 0.06673941016197205
step: 70, loss: 0.047241441905498505
step: 80, loss: 0.04534159600734711
step: 90, loss: 0.06939856708049774
step: 100, loss: 0.01503095030784607
step: 110, loss: 0.006922877859324217
step: 120, loss: 0.00834696926176548
step: 130, loss: 0.01236946415156126
step: 140, loss: 0.10160863399505615
step: 150, loss: 0.08973319083452225
step: 160, loss: 0.059542134404182434
step: 170, loss: 0.049643490463495255
step: 180, loss: 0.18565170466899872
step: 190, loss: 0.10695613920688629
step: 200, loss: 0.05205164849758148
step: 210, loss: 0.043087054044008255
step: 220, loss: 0.018554113805294037
step: 230, loss: 0.09158607572317123
step: 240, loss: 0.07658746838569641
step: 250, loss: 0.04155115410685539
step: 260, loss: 0.023700326681137085
step: 270, loss: 0.06942702829837799
step: 280, loss: 0.09899883717298508
step: 290, loss: 0.06545677036046982
step: 300, loss: 0.010493863373994827
step: 310, loss: 0.049679242074489594
step: 320, loss: 0.2156989872455597
step: 330, loss: 0.04522043466567993
step: 340, loss: 0.09229311347007751
step: 350, loss: 0.06401131302118301
step: 360, loss: 0.060636404901742935
step: 370, loss: 0.05897822603583336
step: 380, loss: 0.137670636177063
step: 390, loss: 0.06198848411440849
step: 400, loss: 0.012230142951011658
step: 410, loss: 0.11449603736400604
step: 420, loss: 0.05016588419675827
step: 430, loss: 0.0395689532160759
step: 440, loss: 0.00948171317577362
step: 450, loss: 0.04928138107061386
step: 460, loss: 0.05734472721815109
epoch 7: dev_f1=0.987598647125141, f1=0.9796839729119639, best_f1=0.9819819819819819
step: 0, loss: 0.06579305231571198
step: 10, loss: 0.019131502136588097
step: 20, loss: 0.03648296743631363
step: 30, loss: 0.13343994319438934
step: 40, loss: 0.06060435622930527
step: 50, loss: 0.01680273376405239
step: 60, loss: 0.056258466094732285
step: 70, loss: 0.0015425782185047865
step: 80, loss: 0.07945669442415237
step: 90, loss: 0.007475787308067083
step: 100, loss: 0.013482771813869476
step: 110, loss: 0.05266374349594116
step: 120, loss: 0.018729299306869507
step: 130, loss: 0.1441224068403244
step: 140, loss: 0.03517214208841324
step: 150, loss: 0.03757035732269287
step: 160, loss: 0.0380411259829998
step: 170, loss: 0.17900674045085907
step: 180, loss: 0.11958183348178864
step: 190, loss: 0.13919048011302948
step: 200, loss: 0.11633654683828354
step: 210, loss: 0.08867256343364716
step: 220, loss: 0.024812759831547737
step: 230, loss: 0.006915300153195858
step: 240, loss: 0.06798963993787766
step: 250, loss: 0.006304584909230471
step: 260, loss: 0.12337087839841843
step: 270, loss: 0.044142238795757294
step: 280, loss: 0.045939166098833084
step: 290, loss: 0.027576062828302383
step: 300, loss: 0.015319117344915867
step: 310, loss: 0.13197912275791168
step: 320, loss: 0.005425420124083757
step: 330, loss: 0.06253393739461899
step: 340, loss: 0.0729016363620758
step: 350, loss: 0.14555837213993073
step: 360, loss: 6.968388333916664e-05
step: 370, loss: 0.07754851877689362
step: 380, loss: 0.1046818345785141
step: 390, loss: 0.010701683349907398
step: 400, loss: 0.05809623748064041
step: 410, loss: 0.006048575975000858
step: 420, loss: 0.12350612878799438
step: 430, loss: 0.017859242856502533
step: 440, loss: 0.029481204226613045
step: 450, loss: 0.06949957460165024
step: 460, loss: 0.017617996782064438
epoch 8: dev_f1=0.992108229988726, f1=0.9797752808988766, best_f1=0.9819819819819819
step: 0, loss: 0.02742353081703186
step: 10, loss: 0.04931348189711571
step: 20, loss: 0.028168193995952606
step: 30, loss: 0.08071216940879822
step: 40, loss: 0.1505752056837082
step: 50, loss: 0.06088988482952118
step: 60, loss: 0.08276501297950745
step: 70, loss: 0.06728199869394302
step: 80, loss: 0.010762350633740425
step: 90, loss: 0.19439458847045898
step: 100, loss: 0.07104284316301346
step: 110, loss: 0.04320845752954483
step: 120, loss: 0.027260389178991318
step: 130, loss: 0.03828304633498192
step: 140, loss: 0.08557344228029251
step: 150, loss: 0.01090224925428629
step: 160, loss: 0.0028855581767857075
step: 170, loss: 0.04015754163265228
step: 180, loss: 0.017404254525899887
step: 190, loss: 0.04826789349317551
step: 200, loss: 0.05321579426527023
step: 210, loss: 0.001755723264068365
step: 220, loss: 0.07806048542261124
step: 230, loss: 0.07817450165748596
step: 240, loss: 0.013322330079972744
step: 250, loss: 0.09804398566484451
step: 260, loss: 0.06936267018318176
step: 270, loss: 0.04198623076081276
step: 280, loss: 0.059806939214468
step: 290, loss: 0.00436520716175437
step: 300, loss: 0.057247865945100784
step: 310, loss: 0.041817959398031235
step: 320, loss: 0.0713426023721695
step: 330, loss: 0.049753256142139435
step: 340, loss: 0.08938328921794891
step: 350, loss: 0.050720881670713425
step: 360, loss: 0.011797755025327206
step: 370, loss: 0.004728921689093113
step: 380, loss: 0.00947869848459959
step: 390, loss: 0.05228659138083458
step: 400, loss: 0.15999317169189453
step: 410, loss: 0.015236102044582367
step: 420, loss: 0.1193203553557396
step: 430, loss: 0.04277382418513298
step: 440, loss: 0.07717647403478622
step: 450, loss: 0.06636075675487518
step: 460, loss: 0.07200493663549423
epoch 9: dev_f1=0.9898534385569334, f1=0.9797297297297298, best_f1=0.9819819819819819
step: 0, loss: 0.008533414453268051
step: 10, loss: 0.05057739466428757
step: 20, loss: 0.013616146519780159
step: 30, loss: 0.04165647551417351
step: 40, loss: 0.1666312962770462
step: 50, loss: 0.028706718236207962
step: 60, loss: 0.00900824461132288
step: 70, loss: 0.02209950052201748
step: 80, loss: 0.05193593353033066
step: 90, loss: 0.0216243676841259
step: 100, loss: 0.016997406259179115
step: 110, loss: 0.04845516011118889
step: 120, loss: 0.04039473086595535
step: 130, loss: 0.07537039369344711
step: 140, loss: 0.020670520141720772
step: 150, loss: 0.01269469317048788
step: 160, loss: 0.03774934262037277
step: 170, loss: 0.02676529809832573
step: 180, loss: 0.10792779177427292
step: 190, loss: 0.04390398785471916
step: 200, loss: 0.10379153490066528
step: 210, loss: 4.650026676245034e-05
step: 220, loss: 0.0262700617313385
step: 230, loss: 0.025598863139748573
step: 240, loss: 0.0296375323086977
step: 250, loss: 0.016025174409151077
step: 260, loss: 0.11936398595571518
step: 270, loss: 0.010972259566187859
step: 280, loss: 0.025069648399949074
step: 290, loss: 0.034681010991334915
step: 300, loss: 0.029642825946211815
step: 310, loss: 0.06999492645263672
step: 320, loss: 0.061384350061416626
step: 330, loss: 0.017099529504776
step: 340, loss: 0.06559227406978607
step: 350, loss: 0.04001926630735397
step: 360, loss: 0.055033985525369644
step: 370, loss: 0.0693855732679367
step: 380, loss: 0.15422067046165466
step: 390, loss: 0.0021757541690021753
step: 400, loss: 0.00031101747299544513
step: 410, loss: 0.07271990180015564
step: 420, loss: 0.02657388336956501
step: 430, loss: 0.02568908967077732
step: 440, loss: 0.04555418714880943
step: 450, loss: 0.044932473450899124
step: 460, loss: 0.024705007672309875
epoch 10: dev_f1=0.9875424688561721, f1=0.9808342728297633, best_f1=0.9819819819819819
step: 0, loss: 0.07391062378883362
step: 10, loss: 0.013257245533168316
step: 20, loss: 0.045040640980005264
step: 30, loss: 0.078489288687706
step: 40, loss: 0.0031380874570459127
step: 50, loss: 0.022379275411367416
step: 60, loss: 0.012912691570818424
step: 70, loss: 0.016811594367027283
step: 80, loss: 0.005416808184236288
step: 90, loss: 0.023663219064474106
step: 100, loss: 0.015515938401222229
step: 110, loss: 0.07346855103969574
step: 120, loss: 0.002628869144245982
step: 130, loss: 0.0430520661175251
step: 140, loss: 0.017519745975732803
step: 150, loss: 0.014772143214941025
step: 160, loss: 0.04047659412026405
step: 170, loss: 0.021694522351026535
step: 180, loss: 0.12017753720283508
step: 190, loss: 0.045510899275541306
step: 200, loss: 0.022956063970923424
step: 210, loss: 0.07250066101551056
step: 220, loss: 0.0022653164342045784
step: 230, loss: 0.09685312211513519
step: 240, loss: 0.06201232969760895
step: 250, loss: 0.09411454945802689
step: 260, loss: 0.01571345515549183
step: 270, loss: 0.06445879489183426
step: 280, loss: 0.08246173709630966
step: 290, loss: 0.015133067965507507
step: 300, loss: 0.06417343765497208
step: 310, loss: 0.018786977976560593
step: 320, loss: 0.05363280698657036
step: 330, loss: 0.1533307582139969
step: 340, loss: 0.054445572197437286
step: 350, loss: 0.10829993337392807
step: 360, loss: 0.04574297368526459
step: 370, loss: 0.0320507176220417
step: 380, loss: 0.020415928214788437
step: 390, loss: 0.014949813485145569
step: 400, loss: 0.0036258066538721323
step: 410, loss: 0.02054552547633648
step: 420, loss: 0.025097504258155823
step: 430, loss: 0.04924437031149864
step: 440, loss: 0.0018733390606939793
step: 450, loss: 0.028096672147512436
step: 460, loss: 0.019027376547455788
epoch 11: dev_f1=0.992108229988726, f1=0.9831271091113611, best_f1=0.9819819819819819
step: 0, loss: 0.049418602138757706
step: 10, loss: 0.03481372445821762
step: 20, loss: 0.10985248535871506
step: 30, loss: 0.04136994853615761
step: 40, loss: 0.02753564529120922
step: 50, loss: 0.003944179508835077
step: 60, loss: 0.02256978489458561
step: 70, loss: 0.07021385431289673
step: 80, loss: 0.005888332612812519
step: 90, loss: 0.023287639021873474
step: 100, loss: 0.035766199231147766
step: 110, loss: 0.026606008410453796
step: 120, loss: 0.014670888893306255
step: 130, loss: 0.1266595870256424
step: 140, loss: 0.05798198655247688
step: 150, loss: 0.003834505332633853
step: 160, loss: 0.08724653720855713
step: 170, loss: 0.0016126629197970033
step: 180, loss: 0.029740583151578903
step: 190, loss: 0.0007435892475768924
step: 200, loss: 0.03868106007575989
step: 210, loss: 2.8847478461102583e-05
step: 220, loss: 0.008144187740981579
step: 230, loss: 0.001392584410496056
step: 240, loss: 0.00039022817509248853
step: 250, loss: 0.000617170357145369
step: 260, loss: 0.0022680838592350483
step: 270, loss: 0.06950263679027557
step: 280, loss: 0.00026312668342143297
step: 290, loss: 0.08386149257421494
step: 300, loss: 0.062499649822711945
step: 310, loss: 0.041353825479745865
step: 320, loss: 0.014380432665348053
step: 330, loss: 0.16706447303295135
step: 340, loss: 0.017303071916103363
step: 350, loss: 0.04360419884324074
step: 360, loss: 0.09047701209783554
step: 370, loss: 0.011480270884931087
step: 380, loss: 0.035508908331394196
step: 390, loss: 0.050157614052295685
step: 400, loss: 0.0005992542137391865
step: 410, loss: 0.055962033569812775
step: 420, loss: 0.019026976078748703
step: 430, loss: 0.0025715602096170187
step: 440, loss: 0.00024510285584256053
step: 450, loss: 0.04912050813436508
step: 460, loss: 0.03341341391205788
epoch 12: dev_f1=0.9909502262443439, f1=0.9841269841269841, best_f1=0.9819819819819819
step: 0, loss: 0.0009128365200012922
step: 10, loss: 0.06304950267076492
step: 20, loss: 0.0005605833139270544
step: 30, loss: 0.06167716160416603
step: 40, loss: 0.04244355112314224
step: 50, loss: 0.05882830172777176
step: 60, loss: 0.07343803346157074
step: 70, loss: 0.023952510207891464
step: 80, loss: 0.054002005606889725
step: 90, loss: 7.891509449109435e-05
step: 100, loss: 0.011315874755382538
step: 110, loss: 0.03726497292518616
step: 120, loss: 0.0027397358790040016
step: 130, loss: 0.19745710492134094
step: 140, loss: 0.002469843253493309
step: 150, loss: 0.05691065639257431
step: 160, loss: 0.11448624730110168
step: 170, loss: 0.0065626115538179874
step: 180, loss: 0.0020072993356734514
step: 190, loss: 0.000734771485440433
step: 200, loss: 0.08204790204763412
step: 210, loss: 0.01369597390294075
step: 220, loss: 2.7368078008294106e-05
step: 230, loss: 0.04080737754702568
step: 240, loss: 0.023455005139112473
step: 250, loss: 0.0009807221358641982
step: 260, loss: 0.020915217697620392
step: 270, loss: 0.005958119407296181
step: 280, loss: 0.004912873264402151
step: 290, loss: 0.28598257899284363
step: 300, loss: 0.08614392578601837
step: 310, loss: 0.004865913651883602
step: 320, loss: 0.11860120296478271
step: 330, loss: 0.02117243967950344
step: 340, loss: 0.02497291751205921
step: 350, loss: 0.029323797672986984
step: 360, loss: 0.02122638188302517
step: 370, loss: 0.07619689404964447
step: 380, loss: 0.02199063077569008
step: 390, loss: 0.01860487088561058
step: 400, loss: 0.0780196562409401
step: 410, loss: 0.01931302808225155
step: 420, loss: 3.515743082971312e-05
step: 430, loss: 0.037534937262535095
step: 440, loss: 0.0598791129887104
step: 450, loss: 0.026112239807844162
step: 460, loss: 0.018070023506879807
epoch 13: dev_f1=0.9887387387387387, f1=0.980963045912654, best_f1=0.9819819819819819
step: 0, loss: 0.032253362238407135
step: 10, loss: 0.000135422422317788
step: 20, loss: 0.001361523987725377
step: 30, loss: 0.034089405089616776
step: 40, loss: 0.045129939913749695
step: 50, loss: 0.02364245615899563
step: 60, loss: 0.018825244158506393
step: 70, loss: 0.07479693740606308
step: 80, loss: 0.08596491813659668
step: 90, loss: 0.11289482563734055
step: 100, loss: 0.016827603802084923
step: 110, loss: 0.0006560381152667105
step: 120, loss: 0.04665377736091614
step: 130, loss: 0.08964627236127853
step: 140, loss: 0.03793913871049881
step: 150, loss: 0.082670658826828
step: 160, loss: 0.06904581934213638
step: 170, loss: 0.006573919206857681
step: 180, loss: 0.022940637543797493
step: 190, loss: 0.08568976819515228
step: 200, loss: 0.07580874860286713
step: 210, loss: 0.05625181272625923
step: 220, loss: 0.1107136532664299
step: 230, loss: 0.03613903746008873
step: 240, loss: 0.0925450325012207
step: 250, loss: 0.0418429858982563
step: 260, loss: 0.00014119682600721717
step: 270, loss: 0.0044699497520923615
step: 280, loss: 0.04833894968032837
step: 290, loss: 0.00033594403066672385
step: 300, loss: 0.06285634636878967
step: 310, loss: 0.016425667330622673
step: 320, loss: 0.01776692643761635
step: 330, loss: 0.026676418259739876
step: 340, loss: 0.021368924528360367
step: 350, loss: 0.021927718073129654
step: 360, loss: 0.0665924921631813
step: 370, loss: 0.042411476373672485
step: 380, loss: 0.03721983730792999
step: 390, loss: 0.001184003078378737
step: 400, loss: 0.01909547857940197
step: 410, loss: 0.08459164202213287
step: 420, loss: 0.05355829373002052
step: 430, loss: 0.23639163374900818
step: 440, loss: 0.07173554599285126
step: 450, loss: 0.03530275449156761
step: 460, loss: 0.001098315347917378
epoch 14: dev_f1=0.9898534385569334, f1=0.9842696629213483, best_f1=0.9819819819819819
step: 0, loss: 0.04081316292285919
step: 10, loss: 0.04994891211390495
step: 20, loss: 0.0006378805264830589
step: 30, loss: 0.03881710022687912
step: 40, loss: 0.03919029235839844
step: 50, loss: 0.03744558244943619
step: 60, loss: 0.0005135286482982337
step: 70, loss: 0.06808800995349884
step: 80, loss: 0.00035517269861884415
step: 90, loss: 0.016912825405597687
step: 100, loss: 0.0001016040550894104
step: 110, loss: 0.015569782815873623
step: 120, loss: 0.021841619163751602
step: 130, loss: 0.042658980935811996
step: 140, loss: 0.01851658709347248
step: 150, loss: 0.0003383226285222918
step: 160, loss: 0.029035622254014015
step: 170, loss: 0.05352618917822838
step: 180, loss: 0.08768461644649506
step: 190, loss: 0.08183911442756653
step: 200, loss: 0.02705824375152588
step: 210, loss: 0.018763357773423195
step: 220, loss: 0.004776036832481623
step: 230, loss: 0.05041251331567764
step: 240, loss: 0.06626542657613754
step: 250, loss: 2.0950319594703615e-05
step: 260, loss: 0.04502590373158455
step: 270, loss: 0.011812600307166576
step: 280, loss: 0.03992433100938797
step: 290, loss: 0.02521289885044098
step: 300, loss: 0.023320408537983894
step: 310, loss: 0.02783781848847866
step: 320, loss: 0.054484739899635315
step: 330, loss: 0.009711027145385742
step: 340, loss: 0.03944362699985504
step: 350, loss: 0.0010006000520661473
step: 360, loss: 0.05279708281159401
step: 370, loss: 0.060672979801893234
step: 380, loss: 0.0037199947983026505
step: 390, loss: 0.0207475908100605
step: 400, loss: 0.0005232632393017411
step: 410, loss: 0.018023205921053886
step: 420, loss: 0.10087010264396667
step: 430, loss: 0.02927049808204174
step: 440, loss: 0.09639676660299301
step: 450, loss: 0.02882782556116581
step: 460, loss: 0.03702963516116142
epoch 15: dev_f1=0.987598647125141, f1=0.9786276715410572, best_f1=0.9819819819819819
step: 0, loss: 0.09312859177589417
step: 10, loss: 0.05844172090291977
step: 20, loss: 0.0014515764778479934
step: 30, loss: 0.04137502983212471
step: 40, loss: 0.05703026056289673
step: 50, loss: 0.015809716656804085
step: 60, loss: 0.00013902626233175397
step: 70, loss: 0.026679109781980515
step: 80, loss: 0.01678786799311638
step: 90, loss: 0.02412143535912037
step: 100, loss: 0.03754933178424835
step: 110, loss: 0.013641287572681904
step: 120, loss: 0.025893080979585648
step: 130, loss: 0.01363454945385456
step: 140, loss: 0.0007193662459030747
step: 150, loss: 0.0001891302817966789
step: 160, loss: 0.0004926004912704229
step: 170, loss: 0.022910019382834435
step: 180, loss: 0.04094955697655678
step: 190, loss: 0.05012570321559906
step: 200, loss: 8.830031583784148e-05
step: 210, loss: 0.0009893988026306033
step: 220, loss: 0.0297000203281641
step: 230, loss: 0.05322332680225372
step: 240, loss: 0.019528765231370926
step: 250, loss: 0.07450465112924576
step: 260, loss: 0.045356784015893936
step: 270, loss: 0.03517065942287445
step: 280, loss: 0.024374516680836678
step: 290, loss: 0.00010573239705991
step: 300, loss: 0.11072634905576706
step: 310, loss: 0.039753593504428864
step: 320, loss: 0.04895346611738205
step: 330, loss: 0.05443885922431946
step: 340, loss: 0.02101326175034046
step: 350, loss: 0.04401443898677826
step: 360, loss: 0.041938818991184235
step: 370, loss: 0.022538935765624046
step: 380, loss: 0.03794315829873085
step: 390, loss: 0.00029622812871821225
step: 400, loss: 0.00017745890363585204
step: 410, loss: 0.09691212326288223
step: 420, loss: 0.01104496605694294
step: 430, loss: 0.025194333866238594
step: 440, loss: 0.023960307240486145
step: 450, loss: 0.06057136133313179
step: 460, loss: 0.037229783833026886
epoch 16: dev_f1=0.9920903954802259, f1=0.9819819819819819, best_f1=0.9819819819819819
step: 0, loss: 0.07959159463644028
step: 10, loss: 0.023775218054652214
step: 20, loss: 0.026086950674653053
step: 30, loss: 0.028707286342978477
step: 40, loss: 0.04615157097578049
step: 50, loss: 0.024961039423942566
step: 60, loss: 0.03439457714557648
step: 70, loss: 0.04069500416517258
step: 80, loss: 0.08515708893537521
step: 90, loss: 0.00037547750980593264
step: 100, loss: 0.07739610224962234
step: 110, loss: 0.06572026759386063
step: 120, loss: 0.05259019136428833
step: 130, loss: 0.044801194220781326
step: 140, loss: 0.03022603504359722
step: 150, loss: 0.0385584719479084
step: 160, loss: 0.05576181039214134
step: 170, loss: 0.04667213186621666
step: 180, loss: 0.0460895374417305
step: 190, loss: 0.010953112505376339
step: 200, loss: 0.04632066935300827
step: 210, loss: 0.032924748957157135
step: 220, loss: 4.1846942622214556e-05
step: 230, loss: 0.021031498908996582
step: 240, loss: 0.07893846184015274
step: 250, loss: 0.07194551080465317
step: 260, loss: 0.05115643888711929
step: 270, loss: 0.04833012819290161
step: 280, loss: 0.04816736280918121
step: 290, loss: 0.06426748633384705
step: 300, loss: 0.06744607537984848
step: 310, loss: 0.059354085475206375
step: 320, loss: 0.023037858307361603
step: 330, loss: 0.04458960145711899
step: 340, loss: 0.04425838962197304
step: 350, loss: 0.0007927315891720355
step: 360, loss: 0.05613749474287033
step: 370, loss: 0.05871405452489853
step: 380, loss: 0.01071346364915371
step: 390, loss: 0.02335631661117077
step: 400, loss: 0.0018333622720092535
step: 410, loss: 0.02831571362912655
step: 420, loss: 0.10012149065732956
step: 430, loss: 0.05902360379695892
step: 440, loss: 0.02282903902232647
step: 450, loss: 0.05989477038383484
step: 460, loss: 0.0665321946144104
epoch 17: dev_f1=0.992108229988726, f1=0.9808342728297633, best_f1=0.9819819819819819
step: 0, loss: 0.00011767889373004436
step: 10, loss: 0.02487451396882534
step: 20, loss: 0.026853200048208237
step: 30, loss: 0.02406127378344536
step: 40, loss: 0.0005175041733309627
step: 50, loss: 0.027409357950091362
step: 60, loss: 0.07524721324443817
step: 70, loss: 0.02478010393679142
step: 80, loss: 0.060686711221933365
step: 90, loss: 0.03694327548146248
step: 100, loss: 2.0134653823333792e-05
step: 110, loss: 0.04242310672998428
step: 120, loss: 0.07013710588216782
step: 130, loss: 0.04903216287493706
step: 140, loss: 0.0493721142411232
step: 150, loss: 0.017466481775045395
step: 160, loss: 0.020307574421167374
step: 170, loss: 0.05859269201755524
step: 180, loss: 1.358968802378513e-05
step: 190, loss: 0.05065969005227089
step: 200, loss: 0.0383271649479866
step: 210, loss: 0.02344592474400997
step: 220, loss: 0.0754491463303566
step: 230, loss: 0.022087058052420616
step: 240, loss: 0.022431500256061554
step: 250, loss: 0.025000082328915596
step: 260, loss: 5.999478162266314e-05
step: 270, loss: 0.015263625420629978
step: 280, loss: 5.631300882669166e-05
step: 290, loss: 0.06442808359861374
step: 300, loss: 0.020365046337246895
step: 310, loss: 0.020582620054483414
step: 320, loss: 0.04185517132282257
step: 330, loss: 0.01643378660082817
step: 340, loss: 0.02295634150505066
step: 350, loss: 0.024075232446193695
step: 360, loss: 0.07686387002468109
step: 370, loss: 0.02478770725429058
step: 380, loss: 0.04684595391154289
step: 390, loss: 0.05223841220140457
step: 400, loss: 0.031852226704359055
step: 410, loss: 8.421418169746175e-05
step: 420, loss: 0.02205757051706314
step: 430, loss: 9.025565668707713e-05
step: 440, loss: 0.0419384241104126
step: 450, loss: 0.028692064806818962
step: 460, loss: 0.0675160363316536
epoch 18: dev_f1=0.9909706546275394, f1=0.9819819819819819, best_f1=0.9819819819819819
step: 0, loss: 0.032157283276319504
step: 10, loss: 0.10622332990169525
step: 20, loss: 0.00010644292342476547
step: 30, loss: 0.022770661860704422
step: 40, loss: 0.015370026230812073
step: 50, loss: 0.0010588266886770725
step: 60, loss: 0.02573644183576107
step: 70, loss: 0.0732497125864029
step: 80, loss: 0.02226507104933262
step: 90, loss: 0.025464540347456932
step: 100, loss: 0.01581704244017601
step: 110, loss: 0.02859053574502468
step: 120, loss: 0.12368690222501755
step: 130, loss: 0.0005650805542245507
step: 140, loss: 0.016484921798110008
step: 150, loss: 0.02644333429634571
step: 160, loss: 0.057037610560655594
step: 170, loss: 0.0002926018205471337
step: 180, loss: 0.06539953500032425
step: 190, loss: 0.11177507787942886
step: 200, loss: 0.035191744565963745
step: 210, loss: 0.019937751814723015
step: 220, loss: 0.023492269217967987
step: 230, loss: 0.024428848177194595
step: 240, loss: 4.0116472519002855e-05
step: 250, loss: 0.043747980147600174
step: 260, loss: 0.0001854730653576553
step: 270, loss: 3.4044660424115136e-05
step: 280, loss: 0.019907336682081223
step: 290, loss: 0.04027128592133522
step: 300, loss: 0.021598078310489655
step: 310, loss: 0.06289399415254593
step: 320, loss: 0.011477756313979626
step: 330, loss: 0.02219771221280098
step: 340, loss: 1.6994348698062822e-05
step: 350, loss: 0.04406418278813362
step: 360, loss: 0.026094643399119377
step: 370, loss: 3.669027137220837e-05
step: 380, loss: 4.6733861381653696e-05
step: 390, loss: 0.02172079123556614
step: 400, loss: 0.04252457246184349
step: 410, loss: 7.860211917432025e-05
step: 420, loss: 0.018652474507689476
step: 430, loss: 0.03909596428275108
step: 440, loss: 0.0385475791990757
step: 450, loss: 0.0724509209394455
step: 460, loss: 0.00031295380904339254
epoch 19: dev_f1=0.9920903954802259, f1=0.9819819819819819, best_f1=0.9819819819819819
step: 0, loss: 0.0347435399889946
step: 10, loss: 0.01885966770350933
step: 20, loss: 8.998769044410437e-05
step: 30, loss: 0.04610084369778633
step: 40, loss: 0.03192643076181412
step: 50, loss: 2.682438207557425e-05
step: 60, loss: 0.019773859530687332
step: 70, loss: 0.042821403592824936
step: 80, loss: 0.021370545029640198
step: 90, loss: 4.2674288124544546e-05
step: 100, loss: 0.04679042473435402
step: 110, loss: 0.024775976315140724
step: 120, loss: 0.00012447420158423483
step: 130, loss: 0.09009891748428345
step: 140, loss: 0.0380738191306591
step: 150, loss: 0.00041427466203458607
step: 160, loss: 0.01808159612119198
step: 170, loss: 0.027257675305008888
step: 180, loss: 0.0002391021844232455
step: 190, loss: 0.016971440985798836
step: 200, loss: 0.02680792659521103
step: 210, loss: 0.00036666818778030574
step: 220, loss: 0.0031769517809152603
step: 230, loss: 0.04577954113483429
step: 240, loss: 2.159092946385499e-05
step: 250, loss: 0.02464756928384304
step: 260, loss: 0.029469773173332214
step: 270, loss: 0.020774178206920624
step: 280, loss: 6.635246973019093e-05
step: 290, loss: 0.0014802021905779839
step: 300, loss: 0.020817315205931664
step: 310, loss: 0.051306307315826416
step: 320, loss: 0.04185082018375397
step: 330, loss: 0.019534945487976074
step: 340, loss: 0.06425466388463974
step: 350, loss: 0.04022466018795967
step: 360, loss: 0.0479833222925663
step: 370, loss: 0.06789099425077438
step: 380, loss: 0.040664173662662506
step: 390, loss: 0.024188455194234848
step: 400, loss: 0.025602199137210846
step: 410, loss: 0.09226273000240326
step: 420, loss: 0.0009738007211126387
step: 430, loss: 0.02412247285246849
step: 440, loss: 0.0882594883441925
step: 450, loss: 0.10401376336812973
step: 460, loss: 0.045171644538640976
epoch 20: dev_f1=0.9920903954802259, f1=0.9819819819819819, best_f1=0.9819819819819819
