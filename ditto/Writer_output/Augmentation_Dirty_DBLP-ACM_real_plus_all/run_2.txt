cuda
Device: cuda
step: 0, loss: 0.7022638320922852
step: 10, loss: 0.5373093485832214
step: 20, loss: 0.564866304397583
step: 30, loss: 0.32144612073898315
step: 40, loss: 0.15574829280376434
step: 50, loss: 0.2950102388858795
step: 60, loss: 0.08435142040252686
step: 70, loss: 0.16436493396759033
step: 80, loss: 0.12278420478105545
step: 90, loss: 0.19053427875041962
step: 100, loss: 0.1359606832265854
step: 110, loss: 0.2322055548429489
step: 120, loss: 0.05320356786251068
step: 130, loss: 0.11054447293281555
step: 140, loss: 0.11277322471141815
step: 150, loss: 0.1193033829331398
step: 160, loss: 0.08965498954057693
step: 170, loss: 0.2590833902359009
step: 180, loss: 0.17247126996517181
step: 190, loss: 0.021182840690016747
step: 200, loss: 0.16795744001865387
step: 210, loss: 0.16658064723014832
step: 220, loss: 0.1267348974943161
step: 230, loss: 0.09422837197780609
step: 240, loss: 0.1885114312171936
step: 250, loss: 0.14124123752117157
step: 260, loss: 0.12718191742897034
step: 270, loss: 0.07110344618558884
step: 280, loss: 0.23945753276348114
step: 290, loss: 0.17272324860095978
step: 300, loss: 0.2304832637310028
step: 310, loss: 0.21626687049865723
step: 320, loss: 0.07351216673851013
step: 330, loss: 0.2524719834327698
step: 340, loss: 0.06802469491958618
step: 350, loss: 0.13364438712596893
step: 360, loss: 0.08103104680776596
step: 370, loss: 0.07577253878116608
step: 380, loss: 0.07779993116855621
step: 390, loss: 0.07800335437059402
step: 400, loss: 0.09574757516384125
step: 410, loss: 0.05442110076546669
step: 420, loss: 0.054329972714185715
step: 430, loss: 0.017833162099123
step: 440, loss: 0.1155252531170845
step: 450, loss: 0.04089370742440224
step: 460, loss: 0.04564687982201576
epoch 1: dev_f1=0.9887387387387387, f1=0.9808342728297633, best_f1=0.9808342728297633
step: 0, loss: 0.05585707724094391
step: 10, loss: 0.09376001358032227
step: 20, loss: 0.0848710760474205
step: 30, loss: 0.0697232037782669
step: 40, loss: 0.031260889023542404
step: 50, loss: 0.04910845682024956
step: 60, loss: 0.07235663384199142
step: 70, loss: 0.05913741514086723
step: 80, loss: 0.06409288197755814
step: 90, loss: 0.13615663349628448
step: 100, loss: 0.11081093549728394
step: 110, loss: 0.04646182805299759
step: 120, loss: 0.059761032462120056
step: 130, loss: 0.08802632242441177
step: 140, loss: 0.03982476890087128
step: 150, loss: 0.06148529797792435
step: 160, loss: 0.09481362998485565
step: 170, loss: 0.14859145879745483
step: 180, loss: 0.045946501195430756
step: 190, loss: 0.022272653877735138
step: 200, loss: 0.08738905191421509
step: 210, loss: 0.10193988680839539
step: 220, loss: 0.09253212809562683
step: 230, loss: 0.047039780765771866
step: 240, loss: 0.22125975787639618
step: 250, loss: 0.03415782004594803
step: 260, loss: 0.17778640985488892
step: 270, loss: 0.005642202217131853
step: 280, loss: 0.07671079784631729
step: 290, loss: 0.08788993954658508
step: 300, loss: 0.02233894169330597
step: 310, loss: 0.08128806203603745
step: 320, loss: 0.013180381618440151
step: 330, loss: 0.038571618497371674
step: 340, loss: 0.14484325051307678
step: 350, loss: 0.06952694803476334
step: 360, loss: 0.02414173260331154
step: 370, loss: 0.13281236588954926
step: 380, loss: 0.0785585343837738
step: 390, loss: 0.03878123685717583
step: 400, loss: 0.023945461958646774
step: 410, loss: 0.03051462396979332
step: 420, loss: 0.16099722683429718
step: 430, loss: 0.027485495433211327
step: 440, loss: 0.06789306551218033
step: 450, loss: 0.0413244366645813
step: 460, loss: 0.02537882886826992
epoch 2: dev_f1=0.9865168539325843, f1=0.9763779527559054, best_f1=0.9808342728297633
step: 0, loss: 0.15474814176559448
step: 10, loss: 0.07349035143852234
step: 20, loss: 0.016693243756890297
step: 30, loss: 0.058718081563711166
step: 40, loss: 0.0714988261461258
step: 50, loss: 0.020900560542941093
step: 60, loss: 0.10267575085163116
step: 70, loss: 0.10023520886898041
step: 80, loss: 0.09993210434913635
step: 90, loss: 0.1278652399778366
step: 100, loss: 0.07578783482313156
step: 110, loss: 0.03132243454456329
step: 120, loss: 0.07060345262289047
step: 130, loss: 0.12929466366767883
step: 140, loss: 0.0689782202243805
step: 150, loss: 0.151787668466568
step: 160, loss: 0.09992201626300812
step: 170, loss: 0.027654403820633888
step: 180, loss: 0.0811871811747551
step: 190, loss: 0.09693952649831772
step: 200, loss: 0.08541791141033173
step: 210, loss: 0.2036324441432953
step: 220, loss: 0.05517098680138588
step: 230, loss: 0.032007552683353424
step: 240, loss: 0.14599661529064178
step: 250, loss: 0.0389602854847908
step: 260, loss: 0.04984242841601372
step: 270, loss: 0.037284966558218
step: 280, loss: 0.08394543081521988
step: 290, loss: 0.07695430517196655
step: 300, loss: 0.17553412914276123
step: 310, loss: 0.1396258920431137
step: 320, loss: 0.08104804158210754
step: 330, loss: 0.05152682214975357
step: 340, loss: 0.10412414371967316
step: 350, loss: 0.10877474397420883
step: 360, loss: 0.018355760723352432
step: 370, loss: 0.062207628041505814
step: 380, loss: 0.036523304879665375
step: 390, loss: 0.019007444381713867
step: 400, loss: 0.21012328565120697
step: 410, loss: 0.11697208136320114
step: 420, loss: 0.013374359346926212
step: 430, loss: 0.05652251094579697
step: 440, loss: 0.13571833074092865
step: 450, loss: 0.1394934207201004
step: 460, loss: 0.11119280010461807
epoch 3: dev_f1=0.9876819708846584, f1=0.9776286353467561, best_f1=0.9808342728297633
step: 0, loss: 0.28561773896217346
step: 10, loss: 0.05555329471826553
step: 20, loss: 0.04331617429852486
step: 30, loss: 0.030573802068829536
step: 40, loss: 0.11360280960798264
step: 50, loss: 0.07615866512060165
step: 60, loss: 0.13574372231960297
step: 70, loss: 0.13744615018367767
step: 80, loss: 0.20076671242713928
step: 90, loss: 0.09911129623651505
step: 100, loss: 0.12159208953380585
step: 110, loss: 0.03424189239740372
step: 120, loss: 0.07264561951160431
step: 130, loss: 0.09546837210655212
step: 140, loss: 0.1215861365199089
step: 150, loss: 0.07203070819377899
step: 160, loss: 0.058462854474782944
step: 170, loss: 0.08611450344324112
step: 180, loss: 0.09090500324964523
step: 190, loss: 0.03604823350906372
step: 200, loss: 0.10905956476926804
step: 210, loss: 0.10859404504299164
step: 220, loss: 0.06508107483386993
step: 230, loss: 0.03513567894697189
step: 240, loss: 0.014036407694220543
step: 250, loss: 0.06302731484174728
step: 260, loss: 0.08229714632034302
step: 270, loss: 0.020096052438020706
step: 280, loss: 0.018538223579525948
step: 290, loss: 0.025209812447428703
step: 300, loss: 0.11505196243524551
step: 310, loss: 0.060283854603767395
step: 320, loss: 0.09310019761323929
step: 330, loss: 0.17293769121170044
step: 340, loss: 0.12541717290878296
step: 350, loss: 0.0514170303940773
step: 360, loss: 0.13847219944000244
step: 370, loss: 0.012653104960918427
step: 380, loss: 0.08571290224790573
step: 390, loss: 0.1862410008907318
step: 400, loss: 0.025650132447481155
step: 410, loss: 0.05227518081665039
step: 420, loss: 0.0004722508601844311
step: 430, loss: 0.07830813527107239
step: 440, loss: 0.10623437911272049
step: 450, loss: 0.1393391191959381
step: 460, loss: 0.14584608376026154
epoch 4: dev_f1=0.9794520547945206, f1=0.9797297297297298, best_f1=0.9808342728297633
step: 0, loss: 0.07531330734491348
step: 10, loss: 0.049889981746673584
step: 20, loss: 0.21048057079315186
step: 30, loss: 0.05051327124238014
step: 40, loss: 0.09142094850540161
step: 50, loss: 0.058151353150606155
step: 60, loss: 0.04541940614581108
step: 70, loss: 0.00877349078655243
step: 80, loss: 0.10456869751214981
step: 90, loss: 0.02268362045288086
step: 100, loss: 0.055329471826553345
step: 110, loss: 0.24700956046581268
step: 120, loss: 0.0208359993994236
step: 130, loss: 0.12362374365329742
step: 140, loss: 0.07496027648448944
step: 150, loss: 0.04961559548974037
step: 160, loss: 0.06509450823068619
step: 170, loss: 0.07688292115926743
step: 180, loss: 0.0339696891605854
step: 190, loss: 0.045323166996240616
step: 200, loss: 0.006625148002058268
step: 210, loss: 0.1264469027519226
step: 220, loss: 0.03581763058900833
step: 230, loss: 0.09691615402698517
step: 240, loss: 0.02312665432691574
step: 250, loss: 0.04843291640281677
step: 260, loss: 0.15183740854263306
step: 270, loss: 0.09661631286144257
step: 280, loss: 0.09399928152561188
step: 290, loss: 0.004856344312429428
step: 300, loss: 0.06972187757492065
step: 310, loss: 0.13525080680847168
step: 320, loss: 0.02648305892944336
step: 330, loss: 0.051617223769426346
step: 340, loss: 0.10155171900987625
step: 350, loss: 0.08156976848840714
step: 360, loss: 0.03657342493534088
step: 370, loss: 0.2975761294364929
step: 380, loss: 0.02792758122086525
step: 390, loss: 0.1491161435842514
step: 400, loss: 0.07245015352964401
step: 410, loss: 0.0119145717471838
step: 420, loss: 0.005233773496001959
step: 430, loss: 0.0002087906323140487
step: 440, loss: 0.28621453046798706
step: 450, loss: 0.04855627194046974
step: 460, loss: 0.05108088254928589
epoch 5: dev_f1=0.9898305084745763, f1=0.9785310734463276, best_f1=0.9785310734463276
step: 0, loss: 0.05252957344055176
step: 10, loss: 0.10159110277891159
step: 20, loss: 0.027061015367507935
step: 30, loss: 0.027248384431004524
step: 40, loss: 0.07835321873426437
step: 50, loss: 0.009323391132056713
step: 60, loss: 0.018169963732361794
step: 70, loss: 0.0781451016664505
step: 80, loss: 0.041007403284311295
step: 90, loss: 0.02544214576482773
step: 100, loss: 0.03523659706115723
step: 110, loss: 0.17736399173736572
step: 120, loss: 0.07692047208547592
step: 130, loss: 0.24099886417388916
step: 140, loss: 0.07822670042514801
step: 150, loss: 0.0724639967083931
step: 160, loss: 0.05948251113295555
step: 170, loss: 0.057078830897808075
step: 180, loss: 0.08143351972103119
step: 190, loss: 0.07340845465660095
step: 200, loss: 0.04937408119440079
step: 210, loss: 0.04682449251413345
step: 220, loss: 0.05804554373025894
step: 230, loss: 0.07877106219530106
step: 240, loss: 0.02882951684296131
step: 250, loss: 0.19061611592769623
step: 260, loss: 0.07153089344501495
step: 270, loss: 0.0617634616792202
step: 280, loss: 0.08135756850242615
step: 290, loss: 0.07235604524612427
step: 300, loss: 0.05363035574555397
step: 310, loss: 0.11123509705066681
step: 320, loss: 0.11453330516815186
step: 330, loss: 0.02805354818701744
step: 340, loss: 0.12466168403625488
step: 350, loss: 0.027744991704821587
step: 360, loss: 0.10662315040826797
step: 370, loss: 0.12422624975442886
step: 380, loss: 0.04839485138654709
step: 390, loss: 0.0824887827038765
step: 400, loss: 7.12012333679013e-05
step: 410, loss: 0.04141179844737053
step: 420, loss: 0.18390364944934845
step: 430, loss: 0.07059609144926071
step: 440, loss: 0.09355790913105011
step: 450, loss: 0.16560636460781097
step: 460, loss: 0.11667996644973755
epoch 6: dev_f1=0.9865470852017937, f1=0.978675645342312, best_f1=0.9785310734463276
step: 0, loss: 0.053076859563589096
step: 10, loss: 0.056246932595968246
step: 20, loss: 0.030499164015054703
step: 30, loss: 0.06422131508588791
step: 40, loss: 0.010062510147690773
step: 50, loss: 0.06759294122457504
step: 60, loss: 0.1014767438173294
step: 70, loss: 0.08742121607065201
step: 80, loss: 0.015919264405965805
step: 90, loss: 0.06907490640878677
step: 100, loss: 0.19270062446594238
step: 110, loss: 0.025879746302962303
step: 120, loss: 0.042026128619909286
step: 130, loss: 0.08363359421491623
step: 140, loss: 0.05098973959684372
step: 150, loss: 0.07394497096538544
step: 160, loss: 0.07766684889793396
step: 170, loss: 0.1505136340856552
step: 180, loss: 0.031076999381184578
step: 190, loss: 0.06637858599424362
step: 200, loss: 0.048162247985601425
step: 210, loss: 0.06321351230144501
step: 220, loss: 0.07422139495611191
step: 230, loss: 0.009575131349265575
step: 240, loss: 0.015619708225131035
step: 250, loss: 0.05183633416891098
step: 260, loss: 0.06295819580554962
step: 270, loss: 0.09860936552286148
step: 280, loss: 0.0068510351702570915
step: 290, loss: 0.10942217707633972
step: 300, loss: 0.05825638398528099
step: 310, loss: 0.2385408729314804
step: 320, loss: 0.08302111178636551
step: 330, loss: 0.09813370555639267
step: 340, loss: 0.023538371548056602
step: 350, loss: 0.03569694980978966
step: 360, loss: 0.02532329224050045
step: 370, loss: 0.1075328141450882
step: 380, loss: 0.12600477039813995
step: 390, loss: 0.13214999437332153
step: 400, loss: 0.11311759054660797
step: 410, loss: 0.031324245035648346
step: 420, loss: 0.0860927402973175
step: 430, loss: 0.034415408968925476
step: 440, loss: 0.0241357684135437
step: 450, loss: 0.021323174238204956
step: 460, loss: 0.04311468079686165
epoch 7: dev_f1=0.9898762654668166, f1=0.9798206278026906, best_f1=0.9798206278026906
step: 0, loss: 0.09497237950563431
step: 10, loss: 0.06221911311149597
step: 20, loss: 0.029474152252078056
step: 30, loss: 0.07155413925647736
step: 40, loss: 0.04016837477684021
step: 50, loss: 0.009866653941571712
step: 60, loss: 0.011959305964410305
step: 70, loss: 0.05782412737607956
step: 80, loss: 0.07014977931976318
step: 90, loss: 0.11271446943283081
step: 100, loss: 0.10847216844558716
step: 110, loss: 0.012529365718364716
step: 120, loss: 0.0033455912489444017
step: 130, loss: 0.17445635795593262
step: 140, loss: 0.02036602795124054
step: 150, loss: 0.12006248533725739
step: 160, loss: 0.14645326137542725
step: 170, loss: 0.08911730349063873
step: 180, loss: 0.03080488182604313
step: 190, loss: 0.14773282408714294
step: 200, loss: 0.06384647637605667
step: 210, loss: 0.0522712878882885
step: 220, loss: 0.018227213993668556
step: 230, loss: 0.025357047095894814
step: 240, loss: 0.03287487104535103
step: 250, loss: 0.13128189742565155
step: 260, loss: 0.04087138548493385
step: 270, loss: 0.06992332637310028
step: 280, loss: 0.09347046911716461
step: 290, loss: 0.0027242342475801706
step: 300, loss: 0.11218222230672836
step: 310, loss: 0.07533659785985947
step: 320, loss: 0.04086925834417343
step: 330, loss: 0.07596233487129211
step: 340, loss: 0.10254782438278198
step: 350, loss: 0.01607883907854557
step: 360, loss: 0.037640366703271866
step: 370, loss: 0.08175652474164963
step: 380, loss: 0.07220765948295593
step: 390, loss: 0.0784112811088562
step: 400, loss: 0.04875275492668152
step: 410, loss: 0.06662642955780029
step: 420, loss: 0.11762586236000061
step: 430, loss: 0.019443858414888382
step: 440, loss: 0.06424160301685333
step: 450, loss: 0.08970964699983597
step: 460, loss: 0.005557510070502758
epoch 8: dev_f1=0.9819819819819819, f1=0.9772727272727272, best_f1=0.9798206278026906
step: 0, loss: 0.11153872311115265
step: 10, loss: 0.10448521375656128
step: 20, loss: 0.04643980413675308
step: 30, loss: 0.05398054048418999
step: 40, loss: 0.04158010333776474
step: 50, loss: 0.07418233901262283
step: 60, loss: 0.0015081061283126473
step: 70, loss: 0.03717486932873726
step: 80, loss: 0.1538330465555191
step: 90, loss: 0.057287830859422684
step: 100, loss: 0.09420850872993469
step: 110, loss: 0.03317832574248314
step: 120, loss: 0.04012889042496681
step: 130, loss: 0.06853792816400528
step: 140, loss: 0.1948966383934021
step: 150, loss: 0.10727788507938385
step: 160, loss: 0.044835273176431656
step: 170, loss: 0.005911435931921005
step: 180, loss: 0.002759815426543355
step: 190, loss: 0.08469916135072708
step: 200, loss: 0.010580281727015972
step: 210, loss: 0.08989470452070236
step: 220, loss: 0.0757264643907547
step: 230, loss: 0.048361800611019135
step: 240, loss: 0.030521105974912643
step: 250, loss: 0.04118547588586807
step: 260, loss: 0.03694319352507591
step: 270, loss: 0.09642044454813004
step: 280, loss: 0.031006384640932083
step: 290, loss: 0.03410518169403076
step: 300, loss: 0.06254508346319199
step: 310, loss: 0.08281193673610687
step: 320, loss: 0.07610979676246643
step: 330, loss: 0.013503031805157661
step: 340, loss: 0.1325506716966629
step: 350, loss: 0.12766364216804504
step: 360, loss: 0.14385758340358734
step: 370, loss: 0.0023910861928015947
step: 380, loss: 0.05065646395087242
step: 390, loss: 0.009507052600383759
step: 400, loss: 0.06049482151865959
step: 410, loss: 0.09937367588281631
step: 420, loss: 0.021861227229237556
step: 430, loss: 0.09024793654680252
step: 440, loss: 0.03970247507095337
step: 450, loss: 0.07409412413835526
step: 460, loss: 0.02292398177087307
epoch 9: dev_f1=0.9921259842519685, f1=0.9786276715410572, best_f1=0.9786276715410572
step: 0, loss: 0.0853513851761818
step: 10, loss: 0.027665438130497932
step: 20, loss: 0.06562702357769012
step: 30, loss: 0.00462737400084734
step: 40, loss: 0.012774303555488586
step: 50, loss: 0.08572543412446976
step: 60, loss: 0.016766762360930443
step: 70, loss: 0.12081155925989151
step: 80, loss: 0.03436797112226486
step: 90, loss: 0.09696529805660248
step: 100, loss: 0.03486398980021477
step: 110, loss: 0.12242314219474792
step: 120, loss: 0.08310875296592712
step: 130, loss: 0.07693347334861755
step: 140, loss: 0.14098338782787323
step: 150, loss: 0.07859155535697937
step: 160, loss: 0.06814635545015335
step: 170, loss: 0.050717514008283615
step: 180, loss: 0.0360286571085453
step: 190, loss: 0.07414405047893524
step: 200, loss: 0.08966898918151855
step: 210, loss: 0.016537826508283615
step: 220, loss: 0.029712650924921036
step: 230, loss: 0.14987604320049286
step: 240, loss: 0.06654803454875946
step: 250, loss: 0.06071166694164276
step: 260, loss: 0.0316835455596447
step: 270, loss: 0.06629889458417892
step: 280, loss: 0.07932125777006149
step: 290, loss: 0.04700394719839096
step: 300, loss: 0.02743425965309143
step: 310, loss: 0.039305541664361954
step: 320, loss: 0.0006388654001057148
step: 330, loss: 0.04151959717273712
step: 340, loss: 0.0902785211801529
step: 350, loss: 0.011553511954843998
step: 360, loss: 0.09620004892349243
step: 370, loss: 0.08057835698127747
step: 380, loss: 0.040602296590805054
step: 390, loss: 0.08885078877210617
step: 400, loss: 0.0606284961104393
step: 410, loss: 0.05092192441225052
step: 420, loss: 0.04481402039527893
step: 430, loss: 0.1049172431230545
step: 440, loss: 0.04518607258796692
step: 450, loss: 0.10194394737482071
step: 460, loss: 0.033839888870716095
epoch 10: dev_f1=0.9921436588103255, f1=0.9786276715410572, best_f1=0.9786276715410572
step: 0, loss: 0.03522689640522003
step: 10, loss: 0.044761333614587784
step: 20, loss: 0.07210385799407959
step: 30, loss: 0.0384858101606369
step: 40, loss: 0.007548066787421703
step: 50, loss: 0.053109921514987946
step: 60, loss: 0.080754853785038
step: 70, loss: 0.06857044249773026
step: 80, loss: 0.05766548216342926
step: 90, loss: 0.019455071538686752
step: 100, loss: 0.017921486869454384
step: 110, loss: 0.0036485104355961084
step: 120, loss: 0.04534236341714859
step: 130, loss: 0.024280648678541183
step: 140, loss: 0.021238841116428375
step: 150, loss: 0.037918902933597565
step: 160, loss: 0.11884176731109619
step: 170, loss: 0.05848221108317375
step: 180, loss: 0.00019570061704143882
step: 190, loss: 0.0010255337692797184
step: 200, loss: 0.08740609139204025
step: 210, loss: 0.0450608991086483
step: 220, loss: 0.0045015159994363785
step: 230, loss: 0.02283662185072899
step: 240, loss: 0.08328820765018463
step: 250, loss: 0.09072567522525787
step: 260, loss: 0.06392727792263031
step: 270, loss: 0.05146857723593712
step: 280, loss: 0.05698027461767197
step: 290, loss: 0.062032584100961685
step: 300, loss: 0.016753723844885826
step: 310, loss: 0.0012602927163243294
step: 320, loss: 0.044976796954870224
step: 330, loss: 0.05786764621734619
step: 340, loss: 5.484774010255933e-05
step: 350, loss: 0.05162789300084114
step: 360, loss: 0.005344635806977749
step: 370, loss: 0.054177675396203995
step: 380, loss: 0.05519438162446022
step: 390, loss: 0.03262888267636299
step: 400, loss: 0.030505994334816933
step: 410, loss: 0.06820283830165863
step: 420, loss: 0.06241212412714958
step: 430, loss: 0.040232572704553604
step: 440, loss: 0.04807142913341522
step: 450, loss: 0.018142763525247574
step: 460, loss: 0.05320337414741516
epoch 11: dev_f1=0.9887892376681614, f1=0.9774774774774775, best_f1=0.9786276715410572
step: 0, loss: 0.1103886067867279
step: 10, loss: 0.1132931262254715
step: 20, loss: 0.004954678472131491
step: 30, loss: 0.07862916588783264
step: 40, loss: 0.06808128952980042
step: 50, loss: 0.09154961258172989
step: 60, loss: 0.028490355238318443
step: 70, loss: 0.05750858038663864
step: 80, loss: 0.040005162358284
step: 90, loss: 0.01836921088397503
step: 100, loss: 0.015781013295054436
step: 110, loss: 0.08740583807229996
step: 120, loss: 0.080231212079525
step: 130, loss: 0.07479414343833923
step: 140, loss: 0.05497577786445618
step: 150, loss: 0.06435545533895493
step: 160, loss: 0.006023930851370096
step: 170, loss: 0.05050160735845566
step: 180, loss: 0.09395764768123627
step: 190, loss: 0.043021440505981445
step: 200, loss: 0.0064012035727500916
step: 210, loss: 0.058710161596536636
step: 220, loss: 0.05480639636516571
step: 230, loss: 0.05142613872885704
step: 240, loss: 0.05401923507452011
step: 250, loss: 0.060462597757577896
step: 260, loss: 0.12138140946626663
step: 270, loss: 0.03920550271868706
step: 280, loss: 0.0319700725376606
step: 290, loss: 0.04951648786664009
step: 300, loss: 0.0027795645873993635
step: 310, loss: 0.0659753680229187
step: 320, loss: 0.0014945444418117404
step: 330, loss: 0.021495770663022995
step: 340, loss: 0.0661187544465065
step: 350, loss: 0.05186730623245239
step: 360, loss: 0.02073381096124649
step: 370, loss: 0.10719209164381027
step: 380, loss: 0.009711386635899544
step: 390, loss: 0.03898949176073074
step: 400, loss: 0.059738751500844955
step: 410, loss: 0.033633049577474594
step: 420, loss: 0.010757803916931152
step: 430, loss: 0.017470084130764008
step: 440, loss: 0.09773772954940796
step: 450, loss: 0.0029180513229221106
step: 460, loss: 0.038900479674339294
epoch 12: dev_f1=0.9921259842519685, f1=0.976324689966178, best_f1=0.9786276715410572
step: 0, loss: 0.08901672065258026
step: 10, loss: 0.0885750949382782
step: 20, loss: 0.08302164077758789
step: 30, loss: 0.0189512986689806
step: 40, loss: 0.03987247496843338
step: 50, loss: 0.06472525000572205
step: 60, loss: 0.045632749795913696
step: 70, loss: 0.06652919203042984
step: 80, loss: 0.056038592010736465
step: 90, loss: 0.0019678333774209023
step: 100, loss: 0.08876902610063553
step: 110, loss: 0.035439975559711456
step: 120, loss: 0.025123147293925285
step: 130, loss: 0.00469641899690032
step: 140, loss: 0.058265212923288345
step: 150, loss: 0.029659617692232132
step: 160, loss: 0.10689274221658707
step: 170, loss: 0.03244863450527191
step: 180, loss: 0.0232635959982872
step: 190, loss: 0.03376280516386032
step: 200, loss: 0.04410379007458687
step: 210, loss: 0.01566186547279358
step: 220, loss: 0.21633504331111908
step: 230, loss: 0.020167171955108643
step: 240, loss: 0.04523836821317673
step: 250, loss: 0.043736040592193604
step: 260, loss: 0.12918096780776978
step: 270, loss: 0.010916385799646378
step: 280, loss: 0.04010353237390518
step: 290, loss: 0.04820391163229942
step: 300, loss: 0.03717375174164772
step: 310, loss: 0.05376439541578293
step: 320, loss: 0.04447818547487259
step: 330, loss: 0.03501914069056511
step: 340, loss: 0.023389501497149467
step: 350, loss: 0.09910610318183899
step: 360, loss: 0.03504379466176033
step: 370, loss: 0.03447922691702843
step: 380, loss: 0.040913354605436325
step: 390, loss: 0.0003611540305428207
step: 400, loss: 0.03240465000271797
step: 410, loss: 0.02587037906050682
step: 420, loss: 0.042751964181661606
step: 430, loss: 0.0015630065463483334
step: 440, loss: 0.06355317682027817
step: 450, loss: 0.022132331505417824
step: 460, loss: 0.00039119727443903685
epoch 13: dev_f1=0.9887133182844244, f1=0.9773755656108598, best_f1=0.9786276715410572
step: 0, loss: 0.00011096767411800101
step: 10, loss: 0.02122730389237404
step: 20, loss: 0.004565888084471226
step: 30, loss: 0.039248958230018616
step: 40, loss: 0.020957989618182182
step: 50, loss: 0.05542663112282753
step: 60, loss: 0.05162164568901062
step: 70, loss: 0.21363307535648346
step: 80, loss: 0.07020173966884613
step: 90, loss: 0.09240532666444778
step: 100, loss: 0.00010295972606400028
step: 110, loss: 0.058367565274238586
step: 120, loss: 0.0659240111708641
step: 130, loss: 0.03880574554204941
step: 140, loss: 0.03251919150352478
step: 150, loss: 0.01898675039410591
step: 160, loss: 0.04012579098343849
step: 170, loss: 0.07427038252353668
step: 180, loss: 0.06744527816772461
step: 190, loss: 0.03072238527238369
step: 200, loss: 0.0004756269045174122
step: 210, loss: 0.02689250372350216
step: 220, loss: 0.032133202999830246
step: 230, loss: 0.00012020429858239368
step: 240, loss: 0.08185666799545288
step: 250, loss: 0.0323336087167263
step: 260, loss: 0.02153458073735237
step: 270, loss: 0.003435573074966669
step: 280, loss: 0.03764842078089714
step: 290, loss: 0.019692212343215942
step: 300, loss: 0.049212731420993805
step: 310, loss: 0.04047472029924393
step: 320, loss: 0.030031047761440277
step: 330, loss: 0.08483586460351944
step: 340, loss: 0.0454307422041893
step: 350, loss: 5.0709924835246056e-05
step: 360, loss: 0.008214877918362617
step: 370, loss: 0.02477884851396084
step: 380, loss: 0.04263288527727127
step: 390, loss: 0.042170293629169464
step: 400, loss: 0.111986443400383
step: 410, loss: 0.11720962077379227
step: 420, loss: 0.001566265826113522
step: 430, loss: 0.05210372433066368
step: 440, loss: 0.05546339228749275
step: 450, loss: 0.026199396699666977
step: 460, loss: 0.03246140107512474
epoch 14: dev_f1=0.9921436588103255, f1=0.978675645342312, best_f1=0.9786276715410572
step: 0, loss: 0.019818034023046494
step: 10, loss: 0.08818883448839188
step: 20, loss: 0.03561859950423241
step: 30, loss: 0.045848652720451355
step: 40, loss: 0.06978216767311096
step: 50, loss: 0.04448368027806282
step: 60, loss: 0.03195276856422424
step: 70, loss: 0.03678141161799431
step: 80, loss: 0.06133721023797989
step: 90, loss: 0.07375438511371613
step: 100, loss: 0.031155085191130638
step: 110, loss: 0.03694948926568031
step: 120, loss: 0.04568733274936676
step: 130, loss: 0.011343228630721569
step: 140, loss: 0.0070959050208330154
step: 150, loss: 0.0006385187152773142
step: 160, loss: 0.019900333136320114
step: 170, loss: 0.08789940178394318
step: 180, loss: 0.0742667019367218
step: 190, loss: 0.03318112716078758
step: 200, loss: 0.027134576812386513
step: 210, loss: 0.036195315420627594
step: 220, loss: 0.08900754898786545
step: 230, loss: 0.0182794202119112
step: 240, loss: 0.00014866709534544498
step: 250, loss: 0.034546129405498505
step: 260, loss: 0.01805911958217621
step: 270, loss: 7.418813038384542e-05
step: 280, loss: 0.049100518226623535
step: 290, loss: 0.05228126049041748
step: 300, loss: 6.737836520187557e-05
step: 310, loss: 0.05426079034805298
step: 320, loss: 0.0896042212843895
step: 330, loss: 0.08504261076450348
step: 340, loss: 0.07402581721544266
step: 350, loss: 0.04603029042482376
step: 360, loss: 0.022035444155335426
step: 370, loss: 0.00013880591723136604
step: 380, loss: 0.038498010486364365
step: 390, loss: 0.057267557829618454
step: 400, loss: 0.07646791636943817
step: 410, loss: 0.02338324673473835
step: 420, loss: 0.018126657232642174
step: 430, loss: 0.020160075277090073
step: 440, loss: 0.0392644889652729
step: 450, loss: 0.0795038715004921
step: 460, loss: 0.05722034350037575
epoch 15: dev_f1=0.9886877828054299, f1=0.9727272727272728, best_f1=0.9786276715410572
step: 0, loss: 0.019481953233480453
step: 10, loss: 0.07627706229686737
step: 20, loss: 0.01606646366417408
step: 30, loss: 0.0637694001197815
step: 40, loss: 0.047056764364242554
step: 50, loss: 0.000451062893262133
step: 60, loss: 0.0407322458922863
step: 70, loss: 0.0032763981726020575
step: 80, loss: 0.04813489317893982
step: 90, loss: 0.00029706672648899257
step: 100, loss: 0.0013166124699637294
step: 110, loss: 0.07543226331472397
step: 120, loss: 0.0003156182647217065
step: 130, loss: 0.06466244906187057
step: 140, loss: 0.04426353797316551
step: 150, loss: 0.021066561341285706
step: 160, loss: 0.05289663374423981
step: 170, loss: 0.00024189366376958787
step: 180, loss: 0.02984108030796051
step: 190, loss: 0.021485893055796623
step: 200, loss: 0.036298930644989014
step: 210, loss: 0.055679239332675934
step: 220, loss: 0.06707017868757248
step: 230, loss: 0.049389906227588654
step: 240, loss: 0.06448298692703247
step: 250, loss: 0.037948381155729294
step: 260, loss: 0.016436539590358734
step: 270, loss: 0.000140798045322299
step: 280, loss: 0.00035441582440398633
step: 290, loss: 0.00029836961766704917
step: 300, loss: 0.037667062133550644
step: 310, loss: 0.12743423879146576
step: 320, loss: 0.026964545249938965
step: 330, loss: 0.03631431236863136
step: 340, loss: 0.0001915539614856243
step: 350, loss: 0.09279251843690872
step: 360, loss: 0.026376349851489067
step: 370, loss: 0.023744767531752586
step: 380, loss: 0.040254317224025726
step: 390, loss: 0.028964417055249214
step: 400, loss: 0.03723562881350517
step: 410, loss: 0.0009163348004221916
step: 420, loss: 0.06834211945533752
step: 430, loss: 0.04295928031206131
step: 440, loss: 0.00023639699793420732
step: 450, loss: 0.04545898362994194
step: 460, loss: 0.024652916938066483
epoch 16: dev_f1=0.9887133182844244, f1=0.976324689966178, best_f1=0.9786276715410572
step: 0, loss: 0.04227666184306145
step: 10, loss: 0.06757760792970657
step: 20, loss: 0.0031236899085342884
step: 30, loss: 0.042999155819416046
step: 40, loss: 0.03982333466410637
step: 50, loss: 0.0008635311387479305
step: 60, loss: 0.022788885980844498
step: 70, loss: 0.03468628227710724
step: 80, loss: 0.011666616424918175
step: 90, loss: 0.046010006219148636
step: 100, loss: 0.019192883744835854
step: 110, loss: 0.05372001230716705
step: 120, loss: 0.030619869008660316
step: 130, loss: 0.0006033849203959107
step: 140, loss: 0.00017777095490600914
step: 150, loss: 0.0011017217766493559
step: 160, loss: 6.284020491875708e-05
step: 170, loss: 0.021106356754899025
step: 180, loss: 0.08173469454050064
step: 190, loss: 0.1362561136484146
step: 200, loss: 0.03460937365889549
step: 210, loss: 0.04445052519440651
step: 220, loss: 0.04499856010079384
step: 230, loss: 0.09103551506996155
step: 240, loss: 0.014988481998443604
step: 250, loss: 0.05077680945396423
step: 260, loss: 0.05398116260766983
step: 270, loss: 0.08319853991270065
step: 280, loss: 0.022465573623776436
step: 290, loss: 0.06424769014120102
step: 300, loss: 0.07043106108903885
step: 310, loss: 0.00012337364023551345
step: 320, loss: 0.044054411351680756
step: 330, loss: 0.04394545033574104
step: 340, loss: 0.05707348883152008
step: 350, loss: 0.024440528824925423
step: 360, loss: 0.03382740169763565
step: 370, loss: 0.0021208173129707575
step: 380, loss: 0.04787416011095047
step: 390, loss: 0.04432452842593193
step: 400, loss: 0.046790339052677155
step: 410, loss: 0.04489055275917053
step: 420, loss: 6.831616337876767e-05
step: 430, loss: 0.05818692222237587
step: 440, loss: 0.046790093183517456
step: 450, loss: 0.023736728355288506
step: 460, loss: 0.07871843129396439
epoch 17: dev_f1=0.9898762654668166, f1=0.9785794813979707, best_f1=0.9786276715410572
step: 0, loss: 0.033229418098926544
step: 10, loss: 0.057922665029764175
step: 20, loss: 0.07672369480133057
step: 30, loss: 0.0013996200868859887
step: 40, loss: 0.001739850384183228
step: 50, loss: 0.07603553682565689
step: 60, loss: 0.02342081069946289
step: 70, loss: 0.03662169352173805
step: 80, loss: 0.03398708254098892
step: 90, loss: 9.317762305727229e-05
step: 100, loss: 0.04192880541086197
step: 110, loss: 0.05230362340807915
step: 120, loss: 0.030304213985800743
step: 130, loss: 0.02612747624516487
step: 140, loss: 0.009853922761976719
step: 150, loss: 0.063768669962883
step: 160, loss: 9.227709961123765e-05
step: 170, loss: 0.029691770672798157
step: 180, loss: 0.022818082943558693
step: 190, loss: 0.0410207100212574
step: 200, loss: 0.024694982916116714
step: 210, loss: 0.00010065508831758052
step: 220, loss: 0.00015467744378838688
step: 230, loss: 0.00013274062075652182
step: 240, loss: 0.04816180840134621
step: 250, loss: 0.025118347257375717
step: 260, loss: 0.018779758363962173
step: 270, loss: 0.03984379395842552
step: 280, loss: 0.034463539719581604
step: 290, loss: 5.727505777031183e-05
step: 300, loss: 0.019687466323375702
step: 310, loss: 0.1202029436826706
step: 320, loss: 0.024665623903274536
step: 330, loss: 0.058611150830984116
step: 340, loss: 0.00024017532996367663
step: 350, loss: 0.03998037800192833
step: 360, loss: 0.026780160143971443
step: 370, loss: 0.023984165862202644
step: 380, loss: 0.05260613188147545
step: 390, loss: 0.03332705423235893
step: 400, loss: 0.009645950980484486
step: 410, loss: 7.665326120331883e-05
step: 420, loss: 0.02609701082110405
step: 430, loss: 0.043727390468120575
step: 440, loss: 5.080056143924594e-05
step: 450, loss: 0.023408617824316025
step: 460, loss: 0.06389079988002777
epoch 18: dev_f1=0.9898534385569334, f1=0.9786276715410572, best_f1=0.9786276715410572
step: 0, loss: 0.017176292836666107
step: 10, loss: 0.040565066039562225
step: 20, loss: 0.02270691469311714
step: 30, loss: 0.10622699558734894
step: 40, loss: 0.00014555547386407852
step: 50, loss: 0.09988480806350708
step: 60, loss: 0.03041273169219494
step: 70, loss: 0.06963106244802475
step: 80, loss: 0.04995986074209213
step: 90, loss: 0.029662953689694405
step: 100, loss: 6.986918742768466e-05
step: 110, loss: 7.870019908295944e-05
step: 120, loss: 0.00020100493566133082
step: 130, loss: 0.01978694088757038
step: 140, loss: 0.05687066540122032
step: 150, loss: 0.05420687049627304
step: 160, loss: 0.018081961199641228
step: 170, loss: 0.06627226620912552
step: 180, loss: 0.037717849016189575
step: 190, loss: 0.002541039837524295
step: 200, loss: 0.00239831255748868
step: 210, loss: 0.0427943654358387
step: 220, loss: 0.04369660094380379
step: 230, loss: 1.4252815162763e-05
step: 240, loss: 0.10734616965055466
step: 250, loss: 0.01875508949160576
step: 260, loss: 0.017899159342050552
step: 270, loss: 0.04296174645423889
step: 280, loss: 0.05763006582856178
step: 290, loss: 0.08240576088428497
step: 300, loss: 0.039157819002866745
step: 310, loss: 0.024231592193245888
step: 320, loss: 0.021240483969449997
step: 330, loss: 5.4593212553299963e-05
step: 340, loss: 0.0985577404499054
step: 350, loss: 0.044201306998729706
step: 360, loss: 0.042214713990688324
step: 370, loss: 0.10653780400753021
step: 380, loss: 0.042363833636045456
step: 390, loss: 0.018837757408618927
step: 400, loss: 0.025518212467432022
step: 410, loss: 9.415105159860104e-05
step: 420, loss: 0.023587815463542938
step: 430, loss: 0.020267164334654808
step: 440, loss: 0.08499523252248764
step: 450, loss: 0.01902751997113228
step: 460, loss: 0.026942050084471703
epoch 19: dev_f1=0.9898534385569334, f1=0.9786276715410572, best_f1=0.9786276715410572
step: 0, loss: 0.017931295558810234
step: 10, loss: 0.044919926673173904
step: 20, loss: 0.06757604330778122
step: 30, loss: 0.018120044842362404
step: 40, loss: 0.06586967408657074
step: 50, loss: 0.01901250332593918
step: 60, loss: 0.11566467583179474
step: 70, loss: 0.017097419127821922
step: 80, loss: 0.022393377497792244
step: 90, loss: 7.578961231047288e-05
step: 100, loss: 0.017646508291363716
step: 110, loss: 0.06764484941959381
step: 120, loss: 0.025294318795204163
step: 130, loss: 0.02643582411110401
step: 140, loss: 0.041844576597213745
step: 150, loss: 0.0004706550680566579
step: 160, loss: 0.04141494259238243
step: 170, loss: 0.03684299811720848
step: 180, loss: 0.02028154395520687
step: 190, loss: 0.031518157571554184
step: 200, loss: 0.041525013744831085
step: 210, loss: 0.017975982278585434
step: 220, loss: 0.012682666070759296
step: 230, loss: 0.0751635804772377
step: 240, loss: 0.048589833080768585
step: 250, loss: 0.08741363137960434
step: 260, loss: 0.02325393259525299
step: 270, loss: 0.04285437613725662
step: 280, loss: 0.02480464242398739
step: 290, loss: 0.019567403942346573
step: 300, loss: 0.01435605064034462
step: 310, loss: 3.5648165066959336e-05
step: 320, loss: 0.02693762630224228
step: 330, loss: 2.8049846150679514e-05
step: 340, loss: 0.06269163638353348
step: 350, loss: 0.06986721605062485
step: 360, loss: 0.02058575674891472
step: 370, loss: 0.05328261852264404
step: 380, loss: 0.042856622487306595
step: 390, loss: 0.01909293420612812
step: 400, loss: 0.023862332105636597
step: 410, loss: 0.019445255398750305
step: 420, loss: 0.04933047294616699
step: 430, loss: 0.12614254653453827
step: 440, loss: 0.12232202291488647
step: 450, loss: 0.07119213789701462
step: 460, loss: 0.017140422016382217
epoch 20: dev_f1=0.9898534385569334, f1=0.9786276715410572, best_f1=0.9786276715410572
