cuda
Device: cuda
step: 0, loss: 0.8301391005516052
step: 10, loss: 0.385850191116333
step: 20, loss: 0.5064187049865723
step: 30, loss: 0.5042822957038879
step: 40, loss: 0.35943689942359924
step: 50, loss: 0.24299031496047974
step: 60, loss: 0.19538514316082
step: 70, loss: 0.24778038263320923
step: 80, loss: 0.2807972729206085
step: 90, loss: 0.4143848419189453
step: 100, loss: 0.1816335767507553
step: 110, loss: 0.16065314412117004
step: 120, loss: 0.0910477489233017
step: 130, loss: 0.23758554458618164
step: 140, loss: 0.18484178185462952
step: 150, loss: 0.17446176707744598
step: 160, loss: 0.16793830692768097
step: 170, loss: 0.2106572687625885
step: 180, loss: 0.2516593635082245
step: 190, loss: 0.1275426149368286
step: 200, loss: 0.14738088846206665
step: 210, loss: 0.014498761855065823
step: 220, loss: 0.07802525162696838
step: 230, loss: 0.18631742894649506
step: 240, loss: 0.3104761838912964
step: 250, loss: 0.03149913623929024
step: 260, loss: 0.09241940081119537
step: 270, loss: 0.2309384047985077
step: 280, loss: 0.10648736357688904
step: 290, loss: 0.190741166472435
step: 300, loss: 0.1674761176109314
step: 310, loss: 0.17137034237384796
step: 320, loss: 0.09968950599431992
step: 330, loss: 0.12283332645893097
step: 340, loss: 0.13607977330684662
step: 350, loss: 0.10188594460487366
step: 360, loss: 0.04962905868887901
step: 370, loss: 0.04322139918804169
step: 380, loss: 0.08992590755224228
step: 390, loss: 0.015800826251506805
step: 400, loss: 0.047111187130212784
step: 410, loss: 0.10362433642148972
step: 420, loss: 0.15084004402160645
step: 430, loss: 0.0661851167678833
step: 440, loss: 0.062344133853912354
step: 450, loss: 0.20144023001194
step: 460, loss: 0.16054600477218628
epoch 1: dev_f1=0.9741863075196409, f1=0.9693530079455165, best_f1=0.9693530079455165
step: 0, loss: 0.09035833925008774
step: 10, loss: 0.02694547362625599
step: 20, loss: 0.06674838811159134
step: 30, loss: 0.1664217710494995
step: 40, loss: 0.03787911683320999
step: 50, loss: 0.09964918345212936
step: 60, loss: 0.08386167883872986
step: 70, loss: 0.1435689479112625
step: 80, loss: 0.026129795238375664
step: 90, loss: 0.08715327829122543
step: 100, loss: 0.18326592445373535
step: 110, loss: 0.08524300903081894
step: 120, loss: 0.04885660856962204
step: 130, loss: 0.01034641731530428
step: 140, loss: 0.02909352257847786
step: 150, loss: 0.09100974351167679
step: 160, loss: 0.04830620437860489
step: 170, loss: 0.04444675147533417
step: 180, loss: 0.07612545043230057
step: 190, loss: 0.14003397524356842
step: 200, loss: 0.07484311610460281
step: 210, loss: 0.06222737580537796
step: 220, loss: 0.12086056172847748
step: 230, loss: 0.10490915179252625
step: 240, loss: 0.06341627240180969
step: 250, loss: 0.15341374278068542
step: 260, loss: 0.049304164946079254
step: 270, loss: 0.09657564759254456
step: 280, loss: 0.00599754648283124
step: 290, loss: 0.1056809201836586
step: 300, loss: 0.15164409577846527
step: 310, loss: 0.07419291138648987
step: 320, loss: 0.17116504907608032
step: 330, loss: 0.12196045368909836
step: 340, loss: 0.027907464653253555
step: 350, loss: 0.1368265002965927
step: 360, loss: 0.13818731904029846
step: 370, loss: 0.06778766959905624
step: 380, loss: 0.13001348078250885
step: 390, loss: 0.11280648410320282
step: 400, loss: 0.017689622938632965
step: 410, loss: 0.03211509808897972
step: 420, loss: 0.0611979216337204
step: 430, loss: 0.046589355915784836
step: 440, loss: 0.11301575601100922
step: 450, loss: 0.10429306328296661
step: 460, loss: 0.020374903455376625
epoch 2: dev_f1=0.990990990990991, f1=0.9853438556933484, best_f1=0.9853438556933484
step: 0, loss: 0.0282079316675663
step: 10, loss: 0.03135107830166817
step: 20, loss: 0.031374990940093994
step: 30, loss: 0.046557262539863586
step: 40, loss: 0.06817124783992767
step: 50, loss: 0.008151308633387089
step: 60, loss: 0.12052436918020248
step: 70, loss: 0.06084500998258591
step: 80, loss: 0.040606435388326645
step: 90, loss: 0.14382480084896088
step: 100, loss: 0.09937339276075363
step: 110, loss: 0.03666328638792038
step: 120, loss: 0.07791706919670105
step: 130, loss: 0.03269270062446594
step: 140, loss: 0.06740844994783401
step: 150, loss: 0.05599356070160866
step: 160, loss: 0.1452179253101349
step: 170, loss: 0.1368161141872406
step: 180, loss: 0.11012034863233566
step: 190, loss: 0.018680231645703316
step: 200, loss: 0.08394191414117813
step: 210, loss: 0.02315552346408367
step: 220, loss: 0.03372889384627342
step: 230, loss: 0.06738567352294922
step: 240, loss: 0.05077434331178665
step: 250, loss: 0.14892670512199402
step: 260, loss: 0.05942939966917038
step: 270, loss: 0.01728679984807968
step: 280, loss: 0.1513098031282425
step: 290, loss: 0.038827624171972275
step: 300, loss: 0.012164968997240067
step: 310, loss: 0.261504590511322
step: 320, loss: 0.03988063335418701
step: 330, loss: 0.057826049625873566
step: 340, loss: 0.17825843393802643
step: 350, loss: 0.02600112557411194
step: 360, loss: 0.06530268490314484
step: 370, loss: 0.017923599109053612
step: 380, loss: 0.1651037335395813
step: 390, loss: 0.1024787575006485
step: 400, loss: 0.08163103461265564
step: 410, loss: 0.0681576058268547
step: 420, loss: 0.03859390690922737
step: 430, loss: 0.010949503630399704
step: 440, loss: 0.11748437583446503
step: 450, loss: 0.0511738546192646
step: 460, loss: 0.07831360399723053
epoch 3: dev_f1=0.9785794813979707, f1=0.9670079635949943, best_f1=0.9853438556933484
step: 0, loss: 0.04041999578475952
step: 10, loss: 0.1695922613143921
step: 20, loss: 0.2600470185279846
step: 30, loss: 0.1949729174375534
step: 40, loss: 0.08334854245185852
step: 50, loss: 0.08889417350292206
step: 60, loss: 0.10643897205591202
step: 70, loss: 0.09405045211315155
step: 80, loss: 0.01018071174621582
step: 90, loss: 0.08014616370201111
step: 100, loss: 0.07933644950389862
step: 110, loss: 0.12398506700992584
step: 120, loss: 0.010597282089293003
step: 130, loss: 0.1973739117383957
step: 140, loss: 0.08366328477859497
step: 150, loss: 0.0569491907954216
step: 160, loss: 0.0514514297246933
step: 170, loss: 0.05930091068148613
step: 180, loss: 0.06898121535778046
step: 190, loss: 0.02220458723604679
step: 200, loss: 0.08432956784963608
step: 210, loss: 0.0386972613632679
step: 220, loss: 0.04997937008738518
step: 230, loss: 0.11899897456169128
step: 240, loss: 0.06098337471485138
step: 250, loss: 0.23689669370651245
step: 260, loss: 0.13957521319389343
step: 270, loss: 0.03186725825071335
step: 280, loss: 0.08321790397167206
step: 290, loss: 0.17945076525211334
step: 300, loss: 0.04624142497777939
step: 310, loss: 0.010671096853911877
step: 320, loss: 0.027713369578123093
step: 330, loss: 0.09343811124563217
step: 340, loss: 0.022428590804338455
step: 350, loss: 0.10603784769773483
step: 360, loss: 0.0855867937207222
step: 370, loss: 0.07627726346254349
step: 380, loss: 0.07695896923542023
step: 390, loss: 0.03302318975329399
step: 400, loss: 0.015560540370643139
step: 410, loss: 0.05516287684440613
step: 420, loss: 0.09951841086149216
step: 430, loss: 0.0473332442343235
step: 440, loss: 0.029312273487448692
step: 450, loss: 0.14274294674396515
step: 460, loss: 0.2537376880645752
epoch 4: dev_f1=0.9726651480637813, f1=0.9752252252252253, best_f1=0.9853438556933484
step: 0, loss: 0.1253533512353897
step: 10, loss: 0.11009182780981064
step: 20, loss: 0.0895179957151413
step: 30, loss: 0.18875868618488312
step: 40, loss: 0.06998574733734131
step: 50, loss: 0.10338062793016434
step: 60, loss: 0.05689217150211334
step: 70, loss: 0.1056244820356369
step: 80, loss: 0.11869961768388748
step: 90, loss: 0.07387895882129669
step: 100, loss: 0.02289554849267006
step: 110, loss: 0.03794241324067116
step: 120, loss: 0.1338670700788498
step: 130, loss: 0.083584725856781
step: 140, loss: 0.01243333239108324
step: 150, loss: 0.019320502877235413
step: 160, loss: 0.02210017666220665
step: 170, loss: 0.01319363433867693
step: 180, loss: 0.06201392039656639
step: 190, loss: 0.04157955199480057
step: 200, loss: 5.1429506129352376e-05
step: 210, loss: 0.04825584217905998
step: 220, loss: 0.0854746550321579
step: 230, loss: 0.10801692306995392
step: 240, loss: 0.02766280062496662
step: 250, loss: 0.27388796210289
step: 260, loss: 0.034044090658426285
step: 270, loss: 0.21134784817695618
step: 280, loss: 0.0480579249560833
step: 290, loss: 0.024571716785430908
step: 300, loss: 0.05929991975426674
step: 310, loss: 0.001919904607348144
step: 320, loss: 0.05307897552847862
step: 330, loss: 0.011279186233878136
step: 340, loss: 0.09790816158056259
step: 350, loss: 0.010602145455777645
step: 360, loss: 0.11372911930084229
step: 370, loss: 0.08710649609565735
step: 380, loss: 0.1096092164516449
step: 390, loss: 0.028867056593298912
step: 400, loss: 0.06992269307374954
step: 410, loss: 0.08997795730829239
step: 420, loss: 0.06469590216875076
step: 430, loss: 0.007657630834728479
step: 440, loss: 0.007698093540966511
step: 450, loss: 0.0614672414958477
step: 460, loss: 0.01751970686018467
epoch 5: dev_f1=0.9865771812080537, f1=0.9820224719101124, best_f1=0.9853438556933484
step: 0, loss: 0.050142571330070496
step: 10, loss: 0.03392557054758072
step: 20, loss: 0.07625135034322739
step: 30, loss: 0.016315044835209846
step: 40, loss: 0.11574776470661163
step: 50, loss: 0.10124139487743378
step: 60, loss: 0.23015917837619781
step: 70, loss: 0.11659500002861023
step: 80, loss: 0.09168841689825058
step: 90, loss: 0.01385589875280857
step: 100, loss: 0.025289038196206093
step: 110, loss: 0.054440323263406754
step: 120, loss: 0.1355106234550476
step: 130, loss: 0.12811170518398285
step: 140, loss: 0.0278621818870306
step: 150, loss: 0.02478521317243576
step: 160, loss: 0.13214004039764404
step: 170, loss: 0.030839061364531517
step: 180, loss: 0.06882183998823166
step: 190, loss: 0.06775036454200745
step: 200, loss: 0.07034780830144882
step: 210, loss: 0.010845508426427841
step: 220, loss: 0.11851231753826141
step: 230, loss: 0.059507858008146286
step: 240, loss: 0.07771049439907074
step: 250, loss: 0.08224386721849442
step: 260, loss: 0.0634966641664505
step: 270, loss: 0.08196991682052612
step: 280, loss: 0.09163467586040497
step: 290, loss: 0.034253377467393875
step: 300, loss: 0.06944157928228378
step: 310, loss: 0.11493624746799469
step: 320, loss: 0.007982531562447548
step: 330, loss: 0.053631871938705444
step: 340, loss: 0.05856245756149292
step: 350, loss: 0.015016259625554085
step: 360, loss: 0.018509559333324432
step: 370, loss: 0.13124337792396545
step: 380, loss: 0.05020098760724068
step: 390, loss: 0.022023633122444153
step: 400, loss: 0.03219598904252052
step: 410, loss: 0.19151557981967926
step: 420, loss: 0.030143816024065018
step: 430, loss: 0.1348908394575119
step: 440, loss: 0.018576549366116524
step: 450, loss: 0.061261214315891266
step: 460, loss: 0.02598269097507
epoch 6: dev_f1=0.9887640449438202, f1=0.9797297297297298, best_f1=0.9853438556933484
step: 0, loss: 0.08172444999217987
step: 10, loss: 0.0975235104560852
step: 20, loss: 0.07076839357614517
step: 30, loss: 0.009147658944129944
step: 40, loss: 0.01666046306490898
step: 50, loss: 0.08313876390457153
step: 60, loss: 0.16786082088947296
step: 70, loss: 0.036631207913160324
step: 80, loss: 0.018701260909438133
step: 90, loss: 0.09727249294519424
step: 100, loss: 0.10409728437662125
step: 110, loss: 0.07605808973312378
step: 120, loss: 0.149574413895607
step: 130, loss: 0.0674934983253479
step: 140, loss: 0.07130148261785507
step: 150, loss: 0.06935696303844452
step: 160, loss: 0.10574524104595184
step: 170, loss: 0.01794533059000969
step: 180, loss: 0.06168665364384651
step: 190, loss: 0.18542569875717163
step: 200, loss: 0.06611202657222748
step: 210, loss: 0.0684051364660263
step: 220, loss: 0.009644409641623497
step: 230, loss: 0.03963316231966019
step: 240, loss: 0.09959670901298523
step: 250, loss: 0.21921393275260925
step: 260, loss: 0.1974162757396698
step: 270, loss: 0.03157588094472885
step: 280, loss: 0.04390230029821396
step: 290, loss: 0.15064775943756104
step: 300, loss: 0.040948353707790375
step: 310, loss: 0.17343595623970032
step: 320, loss: 0.09277033805847168
step: 330, loss: 0.07938654720783234
step: 340, loss: 0.19027763605117798
step: 350, loss: 0.29360657930374146
step: 360, loss: 0.06129809096455574
step: 370, loss: 0.057637106627225876
step: 380, loss: 0.07329719513654709
step: 390, loss: 0.09295299649238586
step: 400, loss: 0.08604173362255096
step: 410, loss: 0.041390128433704376
step: 420, loss: 0.13442184031009674
step: 430, loss: 0.17539241909980774
step: 440, loss: 0.06043010950088501
step: 450, loss: 0.007495158817619085
step: 460, loss: 0.028302161023020744
epoch 7: dev_f1=0.9876819708846584, f1=0.9787709497206705, best_f1=0.9853438556933484
step: 0, loss: 0.050140928477048874
step: 10, loss: 0.10052365064620972
step: 20, loss: 0.06364016979932785
step: 30, loss: 0.043265584856271744
step: 40, loss: 0.08509516716003418
step: 50, loss: 0.06043746694922447
step: 60, loss: 0.05537476763129234
step: 70, loss: 0.2042875438928604
step: 80, loss: 0.03080795519053936
step: 90, loss: 0.011113890446722507
step: 100, loss: 0.018529174849390984
step: 110, loss: 0.11603628844022751
step: 120, loss: 0.19586032629013062
step: 130, loss: 0.12470050901174545
step: 140, loss: 0.011371416039764881
step: 150, loss: 0.032472044229507446
step: 160, loss: 0.06325145810842514
step: 170, loss: 0.05895082652568817
step: 180, loss: 0.14574572443962097
step: 190, loss: 0.0966518446803093
step: 200, loss: 0.04476094990968704
step: 210, loss: 0.0835869312286377
step: 220, loss: 0.0827447772026062
step: 230, loss: 0.012067549861967564
step: 240, loss: 0.025308052077889442
step: 250, loss: 0.0025089120026677847
step: 260, loss: 0.15394547581672668
step: 270, loss: 0.07428156584501266
step: 280, loss: 0.030800607055425644
step: 290, loss: 0.025805579498410225
step: 300, loss: 0.10649249702692032
step: 310, loss: 0.13293780386447906
step: 320, loss: 0.030101217329502106
step: 330, loss: 0.06858742237091064
step: 340, loss: 0.06722049415111542
step: 350, loss: 7.527327397838235e-05
step: 360, loss: 0.11439970880746841
step: 370, loss: 0.04988131672143936
step: 380, loss: 3.503443440422416e-05
step: 390, loss: 0.07921992987394333
step: 400, loss: 0.08144401758909225
step: 410, loss: 0.08597364276647568
step: 420, loss: 0.0939098671078682
step: 430, loss: 0.06090708076953888
step: 440, loss: 0.04719436913728714
step: 450, loss: 0.06393137574195862
step: 460, loss: 0.04570309445261955
epoch 8: dev_f1=0.9910313901345291, f1=0.9797752808988766, best_f1=0.9797752808988766
step: 0, loss: 0.016987567767500877
step: 10, loss: 0.03909977152943611
step: 20, loss: 0.060972683131694794
step: 30, loss: 0.011587887071073055
step: 40, loss: 0.0569523461163044
step: 50, loss: 7.007638487266377e-05
step: 60, loss: 0.02016303315758705
step: 70, loss: 0.0699913427233696
step: 80, loss: 0.19297781586647034
step: 90, loss: 0.05981696769595146
step: 100, loss: 0.036099836230278015
step: 110, loss: 0.11200986802577972
step: 120, loss: 0.024450864642858505
step: 130, loss: 0.011695514433085918
step: 140, loss: 0.07330834865570068
step: 150, loss: 0.07583659142255783
step: 160, loss: 0.1453009843826294
step: 170, loss: 0.05029639974236488
step: 180, loss: 0.09253733605146408
step: 190, loss: 0.14323101937770844
step: 200, loss: 0.126286119222641
step: 210, loss: 0.06553100049495697
step: 220, loss: 0.04696648567914963
step: 230, loss: 0.13826878368854523
step: 240, loss: 0.1835789978504181
step: 250, loss: 0.02003953419625759
step: 260, loss: 0.014372492209076881
step: 270, loss: 0.07422498613595963
step: 280, loss: 0.10885113477706909
step: 290, loss: 0.10070467740297318
step: 300, loss: 0.101933054625988
step: 310, loss: 0.07312910258769989
step: 320, loss: 0.10187629610300064
step: 330, loss: 0.05118197202682495
step: 340, loss: 0.042740244418382645
step: 350, loss: 0.047165680676698685
step: 360, loss: 0.04665149003267288
step: 370, loss: 0.0568312332034111
step: 380, loss: 0.12372937798500061
step: 390, loss: 0.13903427124023438
step: 400, loss: 0.11196569353342056
step: 410, loss: 0.017266444861888885
step: 420, loss: 0.07498528063297272
step: 430, loss: 0.10505662113428116
step: 440, loss: 0.18688325583934784
step: 450, loss: 0.02127629891037941
step: 460, loss: 0.028006020933389664
epoch 9: dev_f1=0.9887892376681614, f1=0.9809203142536477, best_f1=0.9797752808988766
step: 0, loss: 0.014723646454513073
step: 10, loss: 0.017817577347159386
step: 20, loss: 0.020330248400568962
step: 30, loss: 0.11478651314973831
step: 40, loss: 0.07086018472909927
step: 50, loss: 0.061405666172504425
step: 60, loss: 0.043971363455057144
step: 70, loss: 0.13233070075511932
step: 80, loss: 2.1535481209866703e-05
step: 90, loss: 0.024944650009274483
step: 100, loss: 0.06409116089344025
step: 110, loss: 0.07049188017845154
step: 120, loss: 0.09400436282157898
step: 130, loss: 0.07872133702039719
step: 140, loss: 0.09409728646278381
step: 150, loss: 0.06645645946264267
step: 160, loss: 0.04162751883268356
step: 170, loss: 0.06718145310878754
step: 180, loss: 0.004432454705238342
step: 190, loss: 0.13341283798217773
step: 200, loss: 0.1245252937078476
step: 210, loss: 0.04385312274098396
step: 220, loss: 0.02364807389676571
step: 230, loss: 0.14927981793880463
step: 240, loss: 0.03948770835995674
step: 250, loss: 0.0505196712911129
step: 260, loss: 0.03849497810006142
step: 270, loss: 0.16778656840324402
step: 280, loss: 0.02114345133304596
step: 290, loss: 0.027503278106451035
step: 300, loss: 0.09880039840936661
step: 310, loss: 0.06325331330299377
step: 320, loss: 3.67438406101428e-05
step: 330, loss: 0.043899696320295334
step: 340, loss: 0.048739753663539886
step: 350, loss: 0.12053246796131134
step: 360, loss: 0.04902903363108635
step: 370, loss: 0.0793527141213417
step: 380, loss: 0.04364638403058052
step: 390, loss: 0.030779728665947914
step: 400, loss: 0.06735959649085999
step: 410, loss: 0.08751087635755539
step: 420, loss: 0.03497473523020744
step: 430, loss: 0.017918843775987625
step: 440, loss: 0.05128467455506325
step: 450, loss: 0.03446166589856148
step: 460, loss: 0.09210488200187683
epoch 10: dev_f1=0.9921259842519685, f1=0.9798206278026906, best_f1=0.9798206278026906
step: 0, loss: 0.040272776037454605
step: 10, loss: 0.03766055405139923
step: 20, loss: 0.11391980201005936
step: 30, loss: 0.08478914946317673
step: 40, loss: 0.08804339170455933
step: 50, loss: 0.04790337383747101
step: 60, loss: 0.029423464089632034
step: 70, loss: 0.06138147413730621
step: 80, loss: 0.00954238511621952
step: 90, loss: 0.1491229087114334
step: 100, loss: 0.009168597869575024
step: 110, loss: 0.13057558238506317
step: 120, loss: 0.06425368040800095
step: 130, loss: 0.04373030364513397
step: 140, loss: 2.7908390620723367e-05
step: 150, loss: 0.026433778926730156
step: 160, loss: 0.013053415343165398
step: 170, loss: 0.0028213344048708677
step: 180, loss: 0.01727139577269554
step: 190, loss: 0.013486233539879322
step: 200, loss: 0.034698862582445145
step: 210, loss: 0.057852599769830704
step: 220, loss: 0.04719672352075577
step: 230, loss: 0.05072558671236038
step: 240, loss: 0.11139821261167526
step: 250, loss: 0.013129163533449173
step: 260, loss: 0.04512057453393936
step: 270, loss: 6.923620094312355e-05
step: 280, loss: 0.07472632080316544
step: 290, loss: 0.08303099870681763
step: 300, loss: 0.0900561586022377
step: 310, loss: 0.03358369693160057
step: 320, loss: 0.08833419531583786
step: 330, loss: 0.05281108617782593
step: 340, loss: 0.048073604702949524
step: 350, loss: 0.10639477521181107
step: 360, loss: 0.05636152625083923
step: 370, loss: 0.05198349431157112
step: 380, loss: 0.04667404294013977
step: 390, loss: 0.06603764742612839
step: 400, loss: 0.0628947988152504
step: 410, loss: 0.04309511184692383
step: 420, loss: 0.09718278050422668
step: 430, loss: 0.07800222188234329
step: 440, loss: 0.018449753522872925
step: 450, loss: 0.05902295187115669
step: 460, loss: 0.0934412032365799
epoch 11: dev_f1=0.9932432432432432, f1=0.9820224719101124, best_f1=0.9820224719101124
step: 0, loss: 0.006765441969037056
step: 10, loss: 0.010839041322469711
step: 20, loss: 0.05162711814045906
step: 30, loss: 0.002380445133894682
step: 40, loss: 0.058164749294519424
step: 50, loss: 0.010380427353084087
step: 60, loss: 0.23933018743991852
step: 70, loss: 0.000381756603019312
step: 80, loss: 0.10347599536180496
step: 90, loss: 0.08264344930648804
step: 100, loss: 0.09885081648826599
step: 110, loss: 0.09950782358646393
step: 120, loss: 0.04384860396385193
step: 130, loss: 0.11197948455810547
step: 140, loss: 0.14667877554893494
step: 150, loss: 0.0046655647456645966
step: 160, loss: 0.0046997349709272385
step: 170, loss: 0.010596588253974915
step: 180, loss: 0.050879720598459244
step: 190, loss: 0.08388195931911469
step: 200, loss: 0.010529754683375359
step: 210, loss: 0.03785908967256546
step: 220, loss: 0.03417621925473213
step: 230, loss: 0.12570883333683014
step: 240, loss: 0.11525387316942215
step: 250, loss: 0.06627458333969116
step: 260, loss: 0.06826866418123245
step: 270, loss: 0.05842138081789017
step: 280, loss: 0.05356324464082718
step: 290, loss: 0.18575447797775269
step: 300, loss: 0.0316149964928627
step: 310, loss: 0.0014366413233801723
step: 320, loss: 0.00021736975759267807
step: 330, loss: 0.014289564453065395
step: 340, loss: 0.015517784282565117
step: 350, loss: 0.023221256211400032
step: 360, loss: 0.04412590712308884
step: 370, loss: 0.022964337840676308
step: 380, loss: 0.033474285155534744
step: 390, loss: 0.09014944732189178
step: 400, loss: 0.04063330590724945
step: 410, loss: 0.030452081933617592
step: 420, loss: 0.012919601984322071
step: 430, loss: 0.07871649414300919
step: 440, loss: 0.09660697728395462
step: 450, loss: 0.04709043353796005
step: 460, loss: 0.03836771473288536
epoch 12: dev_f1=0.9910313901345291, f1=0.9810479375696767, best_f1=0.9820224719101124
step: 0, loss: 0.05577145144343376
step: 10, loss: 0.053124867379665375
step: 20, loss: 0.03883054107427597
step: 30, loss: 0.03153247386217117
step: 40, loss: 0.028613179922103882
step: 50, loss: 0.07100526243448257
step: 60, loss: 0.005630888976156712
step: 70, loss: 0.08802676945924759
step: 80, loss: 0.02970292791724205
step: 90, loss: 0.06795623898506165
step: 100, loss: 0.15555788576602936
step: 110, loss: 0.07710234820842743
step: 120, loss: 0.027577977627515793
step: 130, loss: 0.023672722280025482
step: 140, loss: 0.10127875208854675
step: 150, loss: 0.032225750386714935
step: 160, loss: 0.007198019418865442
step: 170, loss: 0.05205759406089783
step: 180, loss: 0.03299660608172417
step: 190, loss: 0.04372093826532364
step: 200, loss: 0.02399972453713417
step: 210, loss: 0.03194228187203407
step: 220, loss: 0.00020371834398247302
step: 230, loss: 0.0001107115313061513
step: 240, loss: 8.131358481477946e-05
step: 250, loss: 0.04320695623755455
step: 260, loss: 0.04389262944459915
step: 270, loss: 0.021901726722717285
step: 280, loss: 0.021215077489614487
step: 290, loss: 0.09087434411048889
step: 300, loss: 0.052347488701343536
step: 310, loss: 0.04360160604119301
step: 320, loss: 1.65661440405529e-05
step: 330, loss: 0.028776030987501144
step: 340, loss: 0.032413505017757416
step: 350, loss: 0.16650758683681488
step: 360, loss: 0.0007751425728201866
step: 370, loss: 0.027512868866324425
step: 380, loss: 0.010391942225396633
step: 390, loss: 0.006762301549315453
step: 400, loss: 0.01132359728217125
step: 410, loss: 0.1292644739151001
step: 420, loss: 0.010442093014717102
step: 430, loss: 0.05329271778464317
step: 440, loss: 0.04974282905459404
step: 450, loss: 0.060602232813835144
step: 460, loss: 0.012418900616466999
epoch 13: dev_f1=0.9876265466816648, f1=0.9798206278026906, best_f1=0.9820224719101124
step: 0, loss: 0.04437971115112305
step: 10, loss: 0.00011839740182040259
step: 20, loss: 0.05252915993332863
step: 30, loss: 0.05311116203665733
step: 40, loss: 0.09528468549251556
step: 50, loss: 0.08257018029689789
step: 60, loss: 0.0011631996603682637
step: 70, loss: 0.06827010214328766
step: 80, loss: 0.021941721439361572
step: 90, loss: 0.04226602241396904
step: 100, loss: 3.6733548768097535e-05
step: 110, loss: 0.1016632542014122
step: 120, loss: 0.02121751941740513
step: 130, loss: 0.031795140355825424
step: 140, loss: 0.03395187854766846
step: 150, loss: 0.0015745182754471898
step: 160, loss: 0.028342250734567642
step: 170, loss: 0.05503682792186737
step: 180, loss: 0.050108421593904495
step: 190, loss: 0.015579447150230408
step: 200, loss: 0.012125568464398384
step: 210, loss: 0.004841606132686138
step: 220, loss: 0.030395248904824257
step: 230, loss: 0.030445685610175133
step: 240, loss: 0.0016579489456489682
step: 250, loss: 0.04947741702198982
step: 260, loss: 0.0658511072397232
step: 270, loss: 0.01037189457565546
step: 280, loss: 0.0901096984744072
step: 290, loss: 0.026831887662410736
step: 300, loss: 0.0792088508605957
step: 310, loss: 0.019997088238596916
step: 320, loss: 0.04307973012328148
step: 330, loss: 0.052405595779418945
step: 340, loss: 0.04597851261496544
step: 350, loss: 0.0627567395567894
step: 360, loss: 0.08574940264225006
step: 370, loss: 0.1731814444065094
step: 380, loss: 0.002699862467125058
step: 390, loss: 0.023359227925539017
step: 400, loss: 0.1346789300441742
step: 410, loss: 0.03620683774352074
step: 420, loss: 0.027330664917826653
step: 430, loss: 0.06394779682159424
step: 440, loss: 0.1294718235731125
step: 450, loss: 0.047144416719675064
step: 460, loss: 0.039928555488586426
epoch 14: dev_f1=0.9898762654668166, f1=0.9797752808988766, best_f1=0.9820224719101124
step: 0, loss: 0.004663825500756502
step: 10, loss: 0.011021396145224571
step: 20, loss: 0.025334488600492477
step: 30, loss: 0.03616112098097801
step: 40, loss: 0.00010065788228530437
step: 50, loss: 0.09225641191005707
step: 60, loss: 0.046327851712703705
step: 70, loss: 0.08992232382297516
step: 80, loss: 0.09054930508136749
step: 90, loss: 0.02382444031536579
step: 100, loss: 0.0010933688608929515
step: 110, loss: 0.004128863103687763
step: 120, loss: 0.0004958108766004443
step: 130, loss: 0.17633791267871857
step: 140, loss: 0.0860859677195549
step: 150, loss: 0.05499610677361488
step: 160, loss: 0.04386579990386963
step: 170, loss: 0.08956532925367355
step: 180, loss: 0.05804635211825371
step: 190, loss: 0.018963459879159927
step: 200, loss: 0.08662177622318268
step: 210, loss: 0.027779513970017433
step: 220, loss: 0.004977628123015165
step: 230, loss: 0.01807844638824463
step: 240, loss: 0.026156827807426453
step: 250, loss: 0.05114073306322098
step: 260, loss: 0.02348904125392437
step: 270, loss: 0.03097984753549099
step: 280, loss: 0.053861670196056366
step: 290, loss: 0.01771646738052368
step: 300, loss: 0.021721094846725464
step: 310, loss: 0.024237418547272682
step: 320, loss: 0.01776919886469841
step: 330, loss: 0.10042961686849594
step: 340, loss: 0.16182401776313782
step: 350, loss: 0.029548538848757744
step: 360, loss: 0.09231488406658173
step: 370, loss: 0.019989944994449615
step: 380, loss: 0.07344971597194672
step: 390, loss: 0.047211337834596634
step: 400, loss: 0.01609480194747448
step: 410, loss: 0.04833121597766876
step: 420, loss: 0.05010874569416046
step: 430, loss: 0.022469770163297653
step: 440, loss: 0.031673938035964966
step: 450, loss: 0.05517909675836563
step: 460, loss: 0.10393194854259491
epoch 15: dev_f1=0.9899216125419933, f1=0.9821029082774049, best_f1=0.9820224719101124
step: 0, loss: 0.05560164153575897
step: 10, loss: 0.05788721889257431
step: 20, loss: 0.07458589226007462
step: 30, loss: 0.019178200513124466
step: 40, loss: 0.027398353442549706
step: 50, loss: 0.06341693550348282
step: 60, loss: 0.003560346085578203
step: 70, loss: 0.017959311604499817
step: 80, loss: 0.13215163350105286
step: 90, loss: 0.03320096433162689
step: 100, loss: 0.020098410546779633
step: 110, loss: 0.020083876326680183
step: 120, loss: 0.011353102512657642
step: 130, loss: 0.04573117941617966
step: 140, loss: 0.05816134437918663
step: 150, loss: 0.020164314657449722
step: 160, loss: 0.058319441974163055
step: 170, loss: 0.021257847547531128
step: 180, loss: 0.07440263032913208
step: 190, loss: 0.02916250377893448
step: 200, loss: 0.05526072531938553
step: 210, loss: 0.03318403661251068
step: 220, loss: 0.06717132031917572
step: 230, loss: 0.013988703489303589
step: 240, loss: 0.00029362758505158126
step: 250, loss: 0.012125922366976738
step: 260, loss: 0.05902542546391487
step: 270, loss: 0.11238039284944534
step: 280, loss: 0.06565622985363007
step: 290, loss: 0.05600149929523468
step: 300, loss: 0.04110414907336235
step: 310, loss: 0.04394009709358215
step: 320, loss: 0.052980244159698486
step: 330, loss: 0.04020442068576813
step: 340, loss: 0.04364361986517906
step: 350, loss: 0.03683962672948837
step: 360, loss: 0.03563293069601059
step: 370, loss: 0.02429591678082943
step: 380, loss: 0.00014919618843123317
step: 390, loss: 0.011886127293109894
step: 400, loss: 0.040509019047021866
step: 410, loss: 0.03079589642584324
step: 420, loss: 0.0659622997045517
step: 430, loss: 0.02597617916762829
step: 440, loss: 0.06261418014764786
step: 450, loss: 0.11192243546247482
step: 460, loss: 0.032269518822431564
epoch 16: dev_f1=0.9898762654668166, f1=0.9820627802690582, best_f1=0.9820224719101124
step: 0, loss: 0.04650312289595604
step: 10, loss: 0.007078427355736494
step: 20, loss: 0.00012902100570499897
step: 30, loss: 0.025776803493499756
step: 40, loss: 0.010114992037415504
step: 50, loss: 0.014891352504491806
step: 60, loss: 0.001084047369658947
step: 70, loss: 0.06046281009912491
step: 80, loss: 0.03464525192975998
step: 90, loss: 0.003822273574769497
step: 100, loss: 0.020209798589348793
step: 110, loss: 0.05133109539747238
step: 120, loss: 0.03376106917858124
step: 130, loss: 0.028750453144311905
step: 140, loss: 0.020339036360383034
step: 150, loss: 0.047142285853624344
step: 160, loss: 0.026366783306002617
step: 170, loss: 0.023304790258407593
step: 180, loss: 0.000971793255303055
step: 190, loss: 0.13105694949626923
step: 200, loss: 0.04235083609819412
step: 210, loss: 0.11712101846933365
step: 220, loss: 0.036021988838911057
step: 230, loss: 0.03481291979551315
step: 240, loss: 0.0800744891166687
step: 250, loss: 0.027255671098828316
step: 260, loss: 2.2927137251826935e-05
step: 270, loss: 0.014446593821048737
step: 280, loss: 0.011449635028839111
step: 290, loss: 0.10772788524627686
step: 300, loss: 0.043850142508745193
step: 310, loss: 0.006913877557963133
step: 320, loss: 0.045617349445819855
step: 330, loss: 0.08650973439216614
step: 340, loss: 1.2438586963980924e-05
step: 350, loss: 0.07067244499921799
step: 360, loss: 0.0013857518788427114
step: 370, loss: 0.06330561637878418
step: 380, loss: 0.03779344633221626
step: 390, loss: 0.051174841821193695
step: 400, loss: 0.06241704523563385
step: 410, loss: 0.02237832359969616
step: 420, loss: 0.026589004322886467
step: 430, loss: 0.07710200548171997
step: 440, loss: 0.07552823424339294
step: 450, loss: 1.0981993000314105e-05
step: 460, loss: 0.06540196388959885
epoch 17: dev_f1=0.9910112359550561, f1=0.9808773903262092, best_f1=0.9820224719101124
step: 0, loss: 0.03992746025323868
step: 10, loss: 0.15110249817371368
step: 20, loss: 0.08223184198141098
step: 30, loss: 0.008353509940207005
step: 40, loss: 0.08796737343072891
step: 50, loss: 0.019959906116127968
step: 60, loss: 0.019223807379603386
step: 70, loss: 0.022232098504900932
step: 80, loss: 0.053397949784994125
step: 90, loss: 0.047496531158685684
step: 100, loss: 0.04988687112927437
step: 110, loss: 0.010961178690195084
step: 120, loss: 0.038816340267658234
step: 130, loss: 0.027025358751416206
step: 140, loss: 0.033367980271577835
step: 150, loss: 0.04888305068016052
step: 160, loss: 0.09643122553825378
step: 170, loss: 0.08565262705087662
step: 180, loss: 0.0005145285394974053
step: 190, loss: 0.04229295626282692
step: 200, loss: 0.07234659790992737
step: 210, loss: 0.035907626152038574
step: 220, loss: 1.5075925148266833e-05
step: 230, loss: 0.04460517317056656
step: 240, loss: 0.06654169410467148
step: 250, loss: 0.05805548280477524
step: 260, loss: 0.02351406216621399
step: 270, loss: 0.029514595866203308
step: 280, loss: 0.0006747268489561975
step: 290, loss: 0.032492294907569885
step: 300, loss: 0.02946624718606472
step: 310, loss: 0.07182786613702774
step: 320, loss: 0.02571640908718109
step: 330, loss: 0.08449326455593109
step: 340, loss: 0.023304607719182968
step: 350, loss: 0.02700570784509182
step: 360, loss: 0.05031318590044975
step: 370, loss: 0.014370458200573921
step: 380, loss: 0.029656054452061653
step: 390, loss: 0.044436417520046234
step: 400, loss: 0.04708341509103775
step: 410, loss: 1.0300328540324699e-05
step: 420, loss: 0.04522030055522919
step: 430, loss: 0.044613320380449295
step: 440, loss: 0.006795148365199566
step: 450, loss: 0.06083088368177414
step: 460, loss: 0.06358282268047333
epoch 18: dev_f1=0.9910112359550561, f1=0.9819819819819819, best_f1=0.9820224719101124
step: 0, loss: 0.08707620203495026
step: 10, loss: 0.04148634150624275
step: 20, loss: 0.03663133084774017
step: 30, loss: 0.03770497068762779
step: 40, loss: 0.04784742742776871
step: 50, loss: 0.015366539359092712
step: 60, loss: 0.04553991183638573
step: 70, loss: 0.0004327604256104678
step: 80, loss: 0.03456861525774002
step: 90, loss: 0.05009462684392929
step: 100, loss: 0.0016830979147925973
step: 110, loss: 0.02034144476056099
step: 120, loss: 0.0315827913582325
step: 130, loss: 0.00020637927809730172
step: 140, loss: 0.02029905468225479
step: 150, loss: 0.03925572708249092
step: 160, loss: 0.19213473796844482
step: 170, loss: 0.037008706480264664
step: 180, loss: 0.025255950167775154
step: 190, loss: 0.02861071191728115
step: 200, loss: 5.568325286731124e-05
step: 210, loss: 0.0538797453045845
step: 220, loss: 0.07308225333690643
step: 230, loss: 0.00030802341643720865
step: 240, loss: 0.006501134485006332
step: 250, loss: 0.05420681834220886
step: 260, loss: 0.056264761835336685
step: 270, loss: 0.14447544515132904
step: 280, loss: 0.035761140286922455
step: 290, loss: 0.010718918405473232
step: 300, loss: 0.040851712226867676
step: 310, loss: 7.265598105732352e-05
step: 320, loss: 0.027541516348719597
step: 330, loss: 0.0309761930257082
step: 340, loss: 0.026316441595554352
step: 350, loss: 0.04380381479859352
step: 360, loss: 6.967997614992782e-05
step: 370, loss: 0.022347338497638702
step: 380, loss: 0.09968031942844391
step: 390, loss: 0.08094488084316254
step: 400, loss: 0.0747964158654213
step: 410, loss: 0.07014895230531693
step: 420, loss: 0.018392160534858704
step: 430, loss: 0.022064851596951485
step: 440, loss: 0.02955051325261593
step: 450, loss: 0.02360944263637066
step: 460, loss: 0.0001807740773074329
epoch 19: dev_f1=0.9910112359550561, f1=0.9819819819819819, best_f1=0.9820224719101124
step: 0, loss: 0.042480744421482086
step: 10, loss: 0.06134224310517311
step: 20, loss: 0.07002744823694229
step: 30, loss: 3.129649849142879e-05
step: 40, loss: 0.04513048753142357
step: 50, loss: 0.0014277828158810735
step: 60, loss: 0.021724358201026917
step: 70, loss: 0.008803785778582096
step: 80, loss: 0.04420122131705284
step: 90, loss: 0.018283111974596977
step: 100, loss: 0.058195021003484726
step: 110, loss: 0.12419043481349945
step: 120, loss: 0.04767309129238129
step: 130, loss: 0.04285791516304016
step: 140, loss: 0.011023115366697311
step: 150, loss: 0.042175933718681335
step: 160, loss: 0.016373760998249054
step: 170, loss: 0.03514482453465462
step: 180, loss: 0.06382298469543457
step: 190, loss: 0.038023412227630615
step: 200, loss: 3.728131559910253e-05
step: 210, loss: 0.019871706143021584
step: 220, loss: 0.04664037749171257
step: 230, loss: 0.08616023510694504
step: 240, loss: 0.045985039323568344
step: 250, loss: 0.01733972877264023
step: 260, loss: 0.0006462156306952238
step: 270, loss: 0.0001623974385438487
step: 280, loss: 0.020870350301265717
step: 290, loss: 0.0002807425626087934
step: 300, loss: 0.03774816542863846
step: 310, loss: 0.019074425101280212
step: 320, loss: 5.380523361964151e-05
step: 330, loss: 0.027758564800024033
step: 340, loss: 0.014358749613165855
step: 350, loss: 0.02591799758374691
step: 360, loss: 0.022381708025932312
step: 370, loss: 0.0318387933075428
step: 380, loss: 0.0010880695190280676
step: 390, loss: 0.04549606889486313
step: 400, loss: 0.04693321883678436
step: 410, loss: 0.09709697961807251
step: 420, loss: 0.04294521361589432
step: 430, loss: 0.020889097824692726
step: 440, loss: 0.05090777575969696
step: 450, loss: 0.00037036064895801246
step: 460, loss: 0.08414699137210846
epoch 20: dev_f1=0.9921259842519685, f1=0.9819819819819819, best_f1=0.9820224719101124
