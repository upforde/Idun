cuda
Device: cuda
step: 0, loss: 0.5736690163612366
step: 10, loss: 0.1536247581243515
step: 20, loss: 0.2217477411031723
step: 30, loss: 0.2197437733411789
step: 40, loss: 0.036682479083538055
step: 50, loss: 0.1423293948173523
step: 60, loss: 0.228580042719841
step: 70, loss: 0.13587702810764313
step: 80, loss: 0.22269389033317566
step: 90, loss: 0.33387377858161926
step: 100, loss: 0.3487466275691986
step: 110, loss: 0.21530139446258545
step: 120, loss: 0.036831170320510864
step: 130, loss: 0.032310184091329575
step: 140, loss: 0.2883310616016388
step: 150, loss: 0.1587654948234558
step: 160, loss: 0.21111829578876495
step: 170, loss: 0.13496962189674377
step: 180, loss: 0.11618705838918686
step: 190, loss: 0.12682360410690308
step: 200, loss: 0.13720370829105377
step: 210, loss: 0.11375837028026581
step: 220, loss: 0.20945149660110474
step: 230, loss: 0.19294942915439606
step: 240, loss: 0.03205971419811249
step: 250, loss: 0.12951630353927612
step: 260, loss: 0.032675907015800476
step: 270, loss: 0.0831853598356247
step: 280, loss: 0.0660351887345314
step: 290, loss: 0.029246026650071144
step: 300, loss: 0.14397047460079193
step: 310, loss: 0.0889734998345375
step: 320, loss: 0.02041710913181305
step: 330, loss: 0.11718272417783737
step: 340, loss: 0.13547150790691376
step: 350, loss: 0.16521143913269043
step: 360, loss: 0.2150351107120514
epoch 1: dev_f1=0.4421906693711968, f1=0.4204081632653061, best_f1=0.4204081632653061
step: 0, loss: 0.30722224712371826
step: 10, loss: 0.02466459386050701
step: 20, loss: 0.1427777111530304
step: 30, loss: 0.3170086145401001
step: 40, loss: 0.04741976782679558
step: 50, loss: 0.0912582278251648
step: 60, loss: 0.0249398835003376
step: 70, loss: 0.15909555554389954
step: 80, loss: 0.18368025124073029
step: 90, loss: 0.19721107184886932
step: 100, loss: 0.1630520224571228
step: 110, loss: 0.1902465671300888
step: 120, loss: 0.03756348788738251
step: 130, loss: 0.1066402718424797
step: 140, loss: 0.22849413752555847
step: 150, loss: 0.010116859339177608
step: 160, loss: 0.07413176447153091
step: 170, loss: 0.06278050690889359
step: 180, loss: 0.07275721430778503
step: 190, loss: 0.08967550098896027
step: 200, loss: 0.03287704288959503
step: 210, loss: 0.06041787564754486
step: 220, loss: 0.10899274796247482
step: 230, loss: 0.11709381639957428
step: 240, loss: 0.07008114457130432
step: 250, loss: 0.1851622760295868
step: 260, loss: 0.08222463726997375
step: 270, loss: 0.13366375863552094
step: 280, loss: 0.2584265172481537
step: 290, loss: 0.14371518790721893
step: 300, loss: 0.14557424187660217
step: 310, loss: 0.021443191915750504
step: 320, loss: 0.06465881317853928
step: 330, loss: 0.0369553379714489
step: 340, loss: 0.03649817407131195
step: 350, loss: 0.07733990252017975
step: 360, loss: 0.04938863590359688
epoch 2: dev_f1=0.6000000000000001, f1=0.6347607052896725, best_f1=0.6347607052896725
step: 0, loss: 0.03384522721171379
step: 10, loss: 0.05078934133052826
step: 20, loss: 0.04701609909534454
step: 30, loss: 0.1269707977771759
step: 40, loss: 0.11526040732860565
step: 50, loss: 0.053820881992578506
step: 60, loss: 0.04049018397927284
step: 70, loss: 0.015642566606402397
step: 80, loss: 0.05650339275598526
step: 90, loss: 0.14637397229671478
step: 100, loss: 0.12339939922094345
step: 110, loss: 0.012857556343078613
step: 120, loss: 0.004977373406291008
step: 130, loss: 0.06332934647798538
step: 140, loss: 0.19380871951580048
step: 150, loss: 0.04497229680418968
step: 160, loss: 0.1870950311422348
step: 170, loss: 0.016012772917747498
step: 180, loss: 0.0027135894633829594
step: 190, loss: 0.036590155214071274
step: 200, loss: 0.07611603289842606
step: 210, loss: 0.027451707050204277
step: 220, loss: 0.006797377951443195
step: 230, loss: 0.05012670159339905
step: 240, loss: 0.02200421877205372
step: 250, loss: 0.022044988349080086
step: 260, loss: 0.111628957092762
step: 270, loss: 0.021172167733311653
step: 280, loss: 0.21920399367809296
step: 290, loss: 0.019768619909882545
step: 300, loss: 0.27686113119125366
step: 310, loss: 0.13171827793121338
step: 320, loss: 0.015280179679393768
step: 330, loss: 0.0052232821471989155
step: 340, loss: 0.21733450889587402
step: 350, loss: 0.005512121133506298
step: 360, loss: 0.12553368508815765
epoch 3: dev_f1=0.6487935656836461, f1=0.6091954022988505, best_f1=0.6091954022988505
step: 0, loss: 0.0454895906150341
step: 10, loss: 0.06835871934890747
step: 20, loss: 0.06735660135746002
step: 30, loss: 0.0407734178006649
step: 40, loss: 0.050522297620773315
step: 50, loss: 0.005956435576081276
step: 60, loss: 0.04540069401264191
step: 70, loss: 0.0009667348931543529
step: 80, loss: 0.014169920235872269
step: 90, loss: 0.11243196576833725
step: 100, loss: 0.0033873068168759346
step: 110, loss: 0.04212884604930878
step: 120, loss: 0.09114943444728851
step: 130, loss: 0.011476707644760609
step: 140, loss: 0.07209219038486481
step: 150, loss: 0.02913740649819374
step: 160, loss: 0.028376106172800064
step: 170, loss: 0.0200885571539402
step: 180, loss: 0.01264152955263853
step: 190, loss: 0.004310705233365297
step: 200, loss: 0.09475579112768173
step: 210, loss: 0.09699234366416931
step: 220, loss: 0.015570747666060925
step: 230, loss: 0.00879498291760683
step: 240, loss: 0.011340768076479435
step: 250, loss: 0.011589037254452705
step: 260, loss: 0.030075805261731148
step: 270, loss: 0.0051142494194209576
step: 280, loss: 0.0596187599003315
step: 290, loss: 0.06776495277881622
step: 300, loss: 0.018552273511886597
step: 310, loss: 0.016596758738160133
step: 320, loss: 0.22450603544712067
step: 330, loss: 0.009435595944523811
step: 340, loss: 0.04461776465177536
step: 350, loss: 0.0779445692896843
step: 360, loss: 0.11287610977888107
epoch 4: dev_f1=0.6465753424657535, f1=0.625, best_f1=0.6091954022988505
step: 0, loss: 0.014364859089255333
step: 10, loss: 0.006507747806608677
step: 20, loss: 0.0025262124836444855
step: 30, loss: 0.018283305689692497
step: 40, loss: 0.004854502622038126
step: 50, loss: 0.13437135517597198
step: 60, loss: 0.018988195806741714
step: 70, loss: 0.07899916172027588
step: 80, loss: 0.2567920684814453
step: 90, loss: 0.07028492540121078
step: 100, loss: 0.09030509740114212
step: 110, loss: 0.003592866938561201
step: 120, loss: 0.002664875937625766
step: 130, loss: 0.00031263043638318777
step: 140, loss: 0.1195671483874321
step: 150, loss: 0.08397740125656128
step: 160, loss: 0.04588824138045311
step: 170, loss: 0.11449261009693146
step: 180, loss: 0.03961064666509628
step: 190, loss: 0.08636201173067093
step: 200, loss: 0.011747465468943119
step: 210, loss: 0.018136149272322655
step: 220, loss: 0.009506587870419025
step: 230, loss: 0.007726543582975864
step: 240, loss: 0.00183277134783566
step: 250, loss: 0.048966992646455765
step: 260, loss: 0.013489247299730778
step: 270, loss: 0.002931845374405384
step: 280, loss: 0.054006725549697876
step: 290, loss: 0.022475561127066612
step: 300, loss: 0.07813024520874023
step: 310, loss: 0.007606653030961752
step: 320, loss: 0.020478632301092148
step: 330, loss: 0.026487385854125023
step: 340, loss: 0.0060486625880002975
step: 350, loss: 0.2197747379541397
step: 360, loss: 0.014281178824603558
epoch 5: dev_f1=0.664864864864865, f1=0.6457142857142857, best_f1=0.6457142857142857
step: 0, loss: 0.0033739577047526836
step: 10, loss: 0.02855130471289158
step: 20, loss: 0.0015266076661646366
step: 30, loss: 0.005572112277150154
step: 40, loss: 0.000856697850394994
step: 50, loss: 0.006705444306135178
step: 60, loss: 0.006974006537348032
step: 70, loss: 0.035591304302215576
step: 80, loss: 0.0039019060786813498
step: 90, loss: 0.0002064007130684331
step: 100, loss: 0.005667555145919323
step: 110, loss: 0.0025596378836780787
step: 120, loss: 0.01799505203962326
step: 130, loss: 0.009665006771683693
step: 140, loss: 0.03583715856075287
step: 150, loss: 0.007018882781267166
step: 160, loss: 0.14280034601688385
step: 170, loss: 0.0007420795736834407
step: 180, loss: 0.08916861563920975
step: 190, loss: 0.014040431007742882
step: 200, loss: 0.0011078923707827926
step: 210, loss: 0.00604366697371006
step: 220, loss: 0.06042167916893959
step: 230, loss: 0.009775211103260517
step: 240, loss: 0.005289173219352961
step: 250, loss: 0.0049630627036094666
step: 260, loss: 0.0023264680057764053
step: 270, loss: 0.10645022988319397
step: 280, loss: 0.06946846842765808
step: 290, loss: 0.018775520846247673
step: 300, loss: 0.00910172052681446
step: 310, loss: 0.001114075188525021
step: 320, loss: 0.005897134076803923
step: 330, loss: 0.002911601448431611
step: 340, loss: 0.005557295400649309
step: 350, loss: 0.00047731411177664995
step: 360, loss: 0.08522327244281769
epoch 6: dev_f1=0.6753246753246753, f1=0.6455026455026456, best_f1=0.6455026455026456
step: 0, loss: 0.023700285702943802
step: 10, loss: 0.0032239281572401524
step: 20, loss: 0.020974567160010338
step: 30, loss: 0.04055403545498848
step: 40, loss: 0.0017232068348675966
step: 50, loss: 0.008473970927298069
step: 60, loss: 0.005962036550045013
step: 70, loss: 0.036652788519859314
step: 80, loss: 0.0002216510329162702
step: 90, loss: 0.0015995042631402612
step: 100, loss: 0.04050343856215477
step: 110, loss: 0.05680658668279648
step: 120, loss: 0.018470369279384613
step: 130, loss: 0.0019688184838742018
step: 140, loss: 0.0012399943079799414
step: 150, loss: 0.044167328625917435
step: 160, loss: 0.05615299195051193
step: 170, loss: 0.016884086653590202
step: 180, loss: 0.00515457708388567
step: 190, loss: 0.01291845552623272
step: 200, loss: 0.004837741144001484
step: 210, loss: 0.008443973027169704
step: 220, loss: 0.106221042573452
step: 230, loss: 0.05698073282837868
step: 240, loss: 0.006062670610845089
step: 250, loss: 0.04725438728928566
step: 260, loss: 0.0009242588421329856
step: 270, loss: 0.0039527760818600655
step: 280, loss: 0.012274129316210747
step: 290, loss: 0.001883230172097683
step: 300, loss: 0.0002919324324466288
step: 310, loss: 0.00021597897284664214
step: 320, loss: 0.0023912377655506134
step: 330, loss: 0.12594468891620636
step: 340, loss: 0.017399605363607407
step: 350, loss: 0.0005523593863472342
step: 360, loss: 0.044683005660772324
epoch 7: dev_f1=0.7169811320754718, f1=0.7178082191780822, best_f1=0.7178082191780822
step: 0, loss: 0.00047996308421716094
step: 10, loss: 0.11923567205667496
step: 20, loss: 0.012585984542965889
step: 30, loss: 0.002938471967354417
step: 40, loss: 0.009984144940972328
step: 50, loss: 0.039903998374938965
step: 60, loss: 0.040524084120988846
step: 70, loss: 0.0006117805023677647
step: 80, loss: 0.001859518582932651
step: 90, loss: 0.02962382696568966
step: 100, loss: 0.0015704247634857893
step: 110, loss: 0.0051857405342161655
step: 120, loss: 0.1720832735300064
step: 130, loss: 0.012966602109372616
step: 140, loss: 0.014048818498849869
step: 150, loss: 0.00024303450481966138
step: 160, loss: 0.022131677716970444
step: 170, loss: 0.08874686062335968
step: 180, loss: 0.07449048012495041
step: 190, loss: 0.01225138921290636
step: 200, loss: 0.07392144203186035
step: 210, loss: 0.014811898581683636
step: 220, loss: 0.009339438751339912
step: 230, loss: 0.0017761943163350224
step: 240, loss: 0.0003729403833858669
step: 250, loss: 0.005593983922153711
step: 260, loss: 0.005920985713601112
step: 270, loss: 9.905140177579597e-05
step: 280, loss: 0.10876365751028061
step: 290, loss: 0.0003646477416623384
step: 300, loss: 0.020123174414038658
step: 310, loss: 0.008502393960952759
step: 320, loss: 0.005445087794214487
step: 330, loss: 9.845785825746134e-05
step: 340, loss: 0.0007111578597687185
step: 350, loss: 0.0029997574165463448
step: 360, loss: 0.017246395349502563
epoch 8: dev_f1=0.6919191919191918, f1=0.7081081081081081, best_f1=0.7178082191780822
step: 0, loss: 0.01963389478623867
step: 10, loss: 0.013163619674742222
step: 20, loss: 0.001047491910867393
step: 30, loss: 0.0055131069384515285
step: 40, loss: 0.0004098280915059149
step: 50, loss: 0.0068124691024422646
step: 60, loss: 0.000149507584865205
step: 70, loss: 0.16424207389354706
step: 80, loss: 0.0010242946445941925
step: 90, loss: 0.000388262327760458
step: 100, loss: 0.002011155942454934
step: 110, loss: 0.00115127582103014
step: 120, loss: 0.013153181411325932
step: 130, loss: 0.000856767816003412
step: 140, loss: 0.00010321567970095202
step: 150, loss: 0.0010568761499598622
step: 160, loss: 0.0003094398998655379
step: 170, loss: 0.0011736698215827346
step: 180, loss: 0.0005122140282765031
step: 190, loss: 0.002911854302510619
step: 200, loss: 0.025864150375127792
step: 210, loss: 0.008831816725432873
step: 220, loss: 0.008327602408826351
step: 230, loss: 0.0007045113597996533
step: 240, loss: 0.0013100901851430535
step: 250, loss: 0.0016794308321550488
step: 260, loss: 0.0003061847819481045
step: 270, loss: 0.039493363350629807
step: 280, loss: 0.04988744854927063
step: 290, loss: 0.01249583438038826
step: 300, loss: 0.0027438823599368334
step: 310, loss: 0.000733716762624681
step: 320, loss: 0.003466223366558552
step: 330, loss: 0.0010500019416213036
step: 340, loss: 0.00017547584138810635
step: 350, loss: 0.0798153206706047
step: 360, loss: 0.029633376747369766
epoch 9: dev_f1=0.6543535620052771, f1=0.6833333333333333, best_f1=0.7178082191780822
step: 0, loss: 0.010383796878159046
step: 10, loss: 0.01296292245388031
step: 20, loss: 0.004567069932818413
step: 30, loss: 0.0009723138646222651
step: 40, loss: 0.0006984415813349187
step: 50, loss: 0.017871400341391563
step: 60, loss: 0.0008688608068041503
step: 70, loss: 0.0007039814372546971
step: 80, loss: 0.05876588448882103
step: 90, loss: 0.033860161900520325
step: 100, loss: 0.0072110197506845
step: 110, loss: 0.0003669045108836144
step: 120, loss: 0.0014492286136373878
step: 130, loss: 0.00015182295464910567
step: 140, loss: 0.00037503193016164005
step: 150, loss: 0.0003144991642329842
step: 160, loss: 0.0013770945370197296
step: 170, loss: 0.0006443782476708293
step: 180, loss: 0.016462204977869987
step: 190, loss: 0.0014312374405562878
step: 200, loss: 0.0013585113920271397
step: 210, loss: 0.00179352518171072
step: 220, loss: 0.0005118706612847745
step: 230, loss: 0.001490335795097053
step: 240, loss: 0.0020938848610967398
step: 250, loss: 0.00016812060493975878
step: 260, loss: 0.0010380580788478255
step: 270, loss: 0.013363725505769253
step: 280, loss: 0.020021576434373856
step: 290, loss: 0.0006883571622893214
step: 300, loss: 0.0012273599859327078
step: 310, loss: 0.00042100570863112807
step: 320, loss: 0.00045222078915685415
step: 330, loss: 0.0005176525446586311
step: 340, loss: 0.0010312265949323773
step: 350, loss: 0.09370173513889313
step: 360, loss: 0.0019774828106164932
epoch 10: dev_f1=0.6991869918699186, f1=0.7195467422096318, best_f1=0.7178082191780822
step: 0, loss: 0.006815018597990274
step: 10, loss: 0.0031703414861112833
step: 20, loss: 0.0021934923715889454
step: 30, loss: 0.0003740983083844185
step: 40, loss: 0.0009329635067842901
step: 50, loss: 0.05921894684433937
step: 60, loss: 0.00268511101603508
step: 70, loss: 0.0007395922439172864
step: 80, loss: 0.0001433070719940588
step: 90, loss: 0.0035389279946684837
step: 100, loss: 0.0050864736549556255
step: 110, loss: 0.0010904510272666812
step: 120, loss: 0.00032904051477089524
step: 130, loss: 0.00024899482377804816
step: 140, loss: 0.00027668653638102114
step: 150, loss: 0.00035664276219904423
step: 160, loss: 0.000323664047755301
step: 170, loss: 0.001332513289526105
step: 180, loss: 0.0008253759588114917
step: 190, loss: 0.1287027895450592
step: 200, loss: 0.00041136681102216244
step: 210, loss: 0.0006191078573465347
step: 220, loss: 0.0006516605499200523
step: 230, loss: 0.0006324733840301633
step: 240, loss: 0.0008566107717342675
step: 250, loss: 0.005637447815388441
step: 260, loss: 0.020637083798646927
step: 270, loss: 0.00027023220900446177
step: 280, loss: 0.00018674781313166022
step: 290, loss: 0.00030059294658713043
step: 300, loss: 0.004184728022664785
step: 310, loss: 0.00018048200581688434
step: 320, loss: 0.001936590182594955
step: 330, loss: 0.014395849779248238
step: 340, loss: 0.0003142578061670065
step: 350, loss: 0.0005061008268967271
step: 360, loss: 0.00037058614543639123
epoch 11: dev_f1=0.6886075949367089, f1=0.6846361185983827, best_f1=0.7178082191780822
step: 0, loss: 0.00028012756956741214
step: 10, loss: 0.0004267965559847653
step: 20, loss: 0.00037661712849512696
step: 30, loss: 0.0004627876915037632
step: 40, loss: 0.0008247128571383655
step: 50, loss: 0.00011553887452464551
step: 60, loss: 0.0003679145302157849
step: 70, loss: 0.005568086635321379
step: 80, loss: 0.0002773741143755615
step: 90, loss: 0.0005551805370487273
step: 100, loss: 0.0007167801377363503
step: 110, loss: 0.059829823672771454
step: 120, loss: 0.0008557508117519319
step: 130, loss: 0.0005546819884330034
step: 140, loss: 0.00043242203537374735
step: 150, loss: 0.0002996043476741761
step: 160, loss: 0.08987759798765182
step: 170, loss: 0.011186836287379265
step: 180, loss: 0.002666745102033019
step: 190, loss: 0.00019783487368840724
step: 200, loss: 0.00044244842138141394
step: 210, loss: 0.0005897241062484682
step: 220, loss: 0.002851377706974745
step: 230, loss: 0.0003608096158131957
step: 240, loss: 0.0006757108494639397
step: 250, loss: 0.00037037479341961443
step: 260, loss: 0.0007416837615892291
step: 270, loss: 0.008044200018048286
step: 280, loss: 0.030563335865736008
step: 290, loss: 0.0009326180443167686
step: 300, loss: 0.00035608100006356835
step: 310, loss: 0.0031725771259516478
step: 320, loss: 0.00012113712728023529
step: 330, loss: 0.054843686521053314
step: 340, loss: 0.0005310171982273459
step: 350, loss: 0.0013512970181182027
step: 360, loss: 0.0006195881287567317
epoch 12: dev_f1=0.7103274559193955, f1=0.6885245901639343, best_f1=0.7178082191780822
step: 0, loss: 0.0008781201904639602
step: 10, loss: 0.0001182452542707324
step: 20, loss: 0.00013666324957739562
step: 30, loss: 0.0011560007696971297
step: 40, loss: 0.0001341660536127165
step: 50, loss: 0.04677571728825569
step: 60, loss: 0.01554329413920641
step: 70, loss: 0.05159307271242142
step: 80, loss: 0.00024401208793278784
step: 90, loss: 0.0014353225706145167
step: 100, loss: 0.0005032960907556117
step: 110, loss: 0.0009777173399925232
step: 120, loss: 0.00015986361540853977
step: 130, loss: 0.002961464924737811
step: 140, loss: 0.00020124281581956893
step: 150, loss: 0.00027049393975175917
step: 160, loss: 0.0006802410935051739
step: 170, loss: 0.00014410838775802404
step: 180, loss: 0.0002850032760761678
step: 190, loss: 0.0009418386616744101
step: 200, loss: 6.111776019679382e-05
step: 210, loss: 0.0006106939981691539
step: 220, loss: 0.0005460135289467871
step: 230, loss: 7.926634134491906e-05
step: 240, loss: 0.0005983719602227211
step: 250, loss: 0.00011686742800520733
step: 260, loss: 0.0002451117034070194
step: 270, loss: 0.0006903133471496403
step: 280, loss: 0.00018264696700498462
step: 290, loss: 0.0002715839655138552
step: 300, loss: 0.00030084518948569894
step: 310, loss: 0.00011215711856493726
step: 320, loss: 0.0026072340551763773
step: 330, loss: 0.0002707404491957277
step: 340, loss: 0.009101674892008305
step: 350, loss: 0.16222625970840454
step: 360, loss: 6.831563223386183e-05
epoch 13: dev_f1=0.699228791773779, f1=0.6885245901639343, best_f1=0.7178082191780822
step: 0, loss: 0.00024856338859535754
step: 10, loss: 0.0008077479433268309
step: 20, loss: 0.00025092854048125446
step: 30, loss: 0.00010439300240250304
step: 40, loss: 0.0037557934410870075
step: 50, loss: 0.0002031484618782997
step: 60, loss: 0.00018218056357000023
step: 70, loss: 0.00011286301742075011
step: 80, loss: 6.034782563801855e-05
step: 90, loss: 0.0003132130950689316
step: 100, loss: 0.0012020331341773272
step: 110, loss: 0.0005548958433791995
step: 120, loss: 0.0014522597193717957
step: 130, loss: 0.004289256874471903
step: 140, loss: 0.04321243613958359
step: 150, loss: 0.09744833409786224
step: 160, loss: 0.0005123862065374851
step: 170, loss: 0.0002787212433759123
step: 180, loss: 0.0006846502074040473
step: 190, loss: 0.001526520703919232
step: 200, loss: 0.0005811765440739691
step: 210, loss: 0.0004895398742519319
step: 220, loss: 0.0011649668449535966
step: 230, loss: 0.09359689801931381
step: 240, loss: 0.00023574837541673332
step: 250, loss: 0.00016427415539510548
step: 260, loss: 0.0006305748247541487
step: 270, loss: 6.656195182586089e-05
step: 280, loss: 0.0007340437150560319
step: 290, loss: 7.571382593596354e-05
step: 300, loss: 6.054541881894693e-05
step: 310, loss: 0.00036988992360420525
step: 320, loss: 5.6321416195714846e-05
step: 330, loss: 0.00043866451596841216
step: 340, loss: 0.00042249300167895854
step: 350, loss: 0.0004650746122933924
step: 360, loss: 0.0011044663842767477
epoch 14: dev_f1=0.695890410958904, f1=0.6629834254143646, best_f1=0.7178082191780822
step: 0, loss: 0.00014020530215930194
step: 10, loss: 0.0004468474362511188
step: 20, loss: 0.0003906615311279893
step: 30, loss: 0.0011096615344285965
step: 40, loss: 0.00021245547395665199
step: 50, loss: 0.00022571881709154695
step: 60, loss: 0.004175274632871151
step: 70, loss: 0.00022526206157635897
step: 80, loss: 0.0005843214457854629
step: 90, loss: 0.0010052209254354239
step: 100, loss: 0.003792964154854417
step: 110, loss: 0.002729377942159772
step: 120, loss: 0.01625959202647209
step: 130, loss: 0.004138173069804907
step: 140, loss: 0.00011580729187699035
step: 150, loss: 9.107659570872784e-05
step: 160, loss: 0.0001356019201921299
step: 170, loss: 0.0017746352823451161
step: 180, loss: 0.003838564967736602
step: 190, loss: 0.00020876499183941633
step: 200, loss: 0.0022440850734710693
step: 210, loss: 0.0008612508536316454
step: 220, loss: 0.0003234775795135647
step: 230, loss: 0.15008501708507538
step: 240, loss: 6.54997638775967e-05
step: 250, loss: 0.0006719111697748303
step: 260, loss: 0.0005317003233358264
step: 270, loss: 0.000785420706961304
step: 280, loss: 0.000239841770962812
step: 290, loss: 0.00020744545327033848
step: 300, loss: 0.00021771159663330764
step: 310, loss: 0.0012653133599087596
step: 320, loss: 0.0005370714352466166
step: 330, loss: 0.00016658294771332294
step: 340, loss: 0.011744325049221516
step: 350, loss: 0.00039839267265051603
step: 360, loss: 5.49346768821124e-05
epoch 15: dev_f1=0.6951871657754011, f1=0.6902173913043479, best_f1=0.7178082191780822
step: 0, loss: 0.00010802121687447652
step: 10, loss: 0.00010606396244838834
step: 20, loss: 0.00037979843909852207
step: 30, loss: 0.00014407903654500842
step: 40, loss: 0.00011803791858255863
step: 50, loss: 0.00010458828182891011
step: 60, loss: 0.0002607923815958202
step: 70, loss: 9.679616778157651e-05
step: 80, loss: 0.0001475436583859846
step: 90, loss: 6.842365837655962e-05
step: 100, loss: 0.0015861078863963485
step: 110, loss: 0.00018395425286144018
step: 120, loss: 0.00017007681890390813
step: 130, loss: 9.74259091890417e-05
step: 140, loss: 0.0002285898954141885
step: 150, loss: 0.00569929787889123
step: 160, loss: 0.0016411903779953718
step: 170, loss: 7.871553680161014e-05
step: 180, loss: 0.001393509330227971
step: 190, loss: 0.00011495695071062073
step: 200, loss: 3.5139652027282864e-05
step: 210, loss: 7.205631845863536e-05
step: 220, loss: 0.0007752329693175852
step: 230, loss: 0.003835199400782585
step: 240, loss: 0.00035842976649291813
step: 250, loss: 0.000504585390444845
step: 260, loss: 4.46643061877694e-05
step: 270, loss: 9.697426139609888e-05
step: 280, loss: 0.0002033006021520123
step: 290, loss: 0.0008642630418762565
step: 300, loss: 0.0005214411066845059
step: 310, loss: 0.0002550773206166923
step: 320, loss: 4.297669147490524e-05
step: 330, loss: 5.9729434724431485e-05
step: 340, loss: 0.0016552943270653486
step: 350, loss: 0.00016621925169602036
step: 360, loss: 0.0007808945374563336
epoch 16: dev_f1=0.7157360406091372, f1=0.6965699208443272, best_f1=0.7178082191780822
step: 0, loss: 7.509990246035159e-05
step: 10, loss: 0.0008906026487238705
step: 20, loss: 0.00018065287440549582
step: 30, loss: 6.794170622015372e-05
step: 40, loss: 0.00018327806901652366
step: 50, loss: 0.00010147173452423885
step: 60, loss: 0.00245486618950963
step: 70, loss: 0.00012885930482298136
step: 80, loss: 0.00044345189235173166
step: 90, loss: 0.00029947521397843957
step: 100, loss: 0.00014111601922195405
step: 110, loss: 0.00011233928671572357
step: 120, loss: 7.922375516500324e-05
step: 130, loss: 0.0002160939620807767
step: 140, loss: 0.00013569083239417523
step: 150, loss: 7.441830530297011e-05
step: 160, loss: 0.00012694593169726431
step: 170, loss: 4.885303133050911e-05
step: 180, loss: 0.0007315436960197985
step: 190, loss: 0.00013356296403799206
step: 200, loss: 0.00012673466699197888
step: 210, loss: 0.00036562708555720747
step: 220, loss: 0.04664633423089981
step: 230, loss: 6.324402056634426e-05
step: 240, loss: 6.939607555978e-05
step: 250, loss: 0.00015883524611126631
step: 260, loss: 9.738279914017767e-05
step: 270, loss: 5.933100692345761e-05
step: 280, loss: 0.0040170857682824135
step: 290, loss: 0.00029033812461420894
step: 300, loss: 0.00013614463387057185
step: 310, loss: 0.00016470470291096717
step: 320, loss: 0.0004138010845053941
step: 330, loss: 8.253158011939377e-05
step: 340, loss: 0.00012762421101797372
step: 350, loss: 0.0002749245031736791
step: 360, loss: 0.00014680527965538204
epoch 17: dev_f1=0.6965699208443272, f1=0.670360110803324, best_f1=0.7178082191780822
step: 0, loss: 0.0009288000292144716
step: 10, loss: 0.00012871332000941038
step: 20, loss: 4.4895889004692435e-05
step: 30, loss: 0.00018906465265899897
step: 40, loss: 6.036448394297622e-05
step: 50, loss: 0.00021553071564994752
step: 60, loss: 0.00016749069618526846
step: 70, loss: 7.356592686846852e-05
step: 80, loss: 8.635119593236595e-05
step: 90, loss: 0.0008392621530219913
step: 100, loss: 0.00016255419177468866
step: 110, loss: 4.507392077357508e-05
step: 120, loss: 0.00022546910622622818
step: 130, loss: 0.00011026832362404093
step: 140, loss: 8.540661656297743e-05
step: 150, loss: 0.00019290976342745125
step: 160, loss: 5.489150862558745e-05
step: 170, loss: 0.10396528244018555
step: 180, loss: 2.6780431653605774e-05
step: 190, loss: 0.002028219634667039
step: 200, loss: 0.0002211457904195413
step: 210, loss: 9.723662515170872e-05
step: 220, loss: 7.77805908001028e-05
step: 230, loss: 8.0647281720303e-05
step: 240, loss: 0.0018039781134575605
step: 250, loss: 0.0002835443592630327
step: 260, loss: 0.0001417704625055194
step: 270, loss: 0.00011909038585145026
step: 280, loss: 0.0014040067326277494
step: 290, loss: 0.0004404100764077157
step: 300, loss: 0.00013199412205722183
step: 310, loss: 5.450690878205933e-05
step: 320, loss: 9.343741839984432e-05
step: 330, loss: 0.00010357912833569571
step: 340, loss: 0.00010502438817638904
step: 350, loss: 8.783536759437993e-05
step: 360, loss: 0.00015579657338093966
epoch 18: dev_f1=0.7308641975308642, f1=0.7052631578947368, best_f1=0.7052631578947368
step: 0, loss: 0.00015798676759004593
step: 10, loss: 3.564564394764602e-05
step: 20, loss: 0.0006903434405103326
step: 30, loss: 0.00010412949632154778
step: 40, loss: 5.621693344437517e-05
step: 50, loss: 0.00011880735110025853
step: 60, loss: 8.725660882191733e-05
step: 70, loss: 5.714624057873152e-05
step: 80, loss: 8.797476766631007e-05
step: 90, loss: 0.00011616481060627848
step: 100, loss: 0.00015320803504437208
step: 110, loss: 7.37488444428891e-05
step: 120, loss: 9.064444020623341e-05
step: 130, loss: 0.00022259532124735415
step: 140, loss: 6.72957394272089e-05
step: 150, loss: 4.209709368296899e-05
step: 160, loss: 0.00017819115601014346
step: 170, loss: 0.0001842610799940303
step: 180, loss: 0.00012660378706641495
step: 190, loss: 0.00019399114535190165
step: 200, loss: 9.601455531083047e-05
step: 210, loss: 9.008235792862251e-05
step: 220, loss: 0.000957679410930723
step: 230, loss: 7.606513099744916e-05
step: 240, loss: 0.00010545628902036697
step: 250, loss: 2.669104105734732e-05
step: 260, loss: 4.003708090749569e-05
step: 270, loss: 0.000307900074403733
step: 280, loss: 7.11110042175278e-05
step: 290, loss: 0.00015136468573473394
step: 300, loss: 0.0006311467150226235
step: 310, loss: 2.6135887310374528e-05
step: 320, loss: 0.00032470544101670384
step: 330, loss: 0.00014718608872499317
step: 340, loss: 0.0002824135881382972
step: 350, loss: 4.8253983550239354e-05
step: 360, loss: 6.48273344268091e-05
epoch 19: dev_f1=0.7168831168831169, f1=0.6741573033707865, best_f1=0.7052631578947368
step: 0, loss: 0.00013938653864897788
step: 10, loss: 2.7942303859163076e-05
step: 20, loss: 8.573864761274308e-05
step: 30, loss: 5.8482499298406765e-05
step: 40, loss: 0.0001992274628719315
step: 50, loss: 0.00021147723600734025
step: 60, loss: 0.0016279590781778097
step: 70, loss: 0.00020387949189171195
step: 80, loss: 0.0012357672676444054
step: 90, loss: 0.00038090269663371146
step: 100, loss: 0.00013234236394055188
step: 110, loss: 3.7518100725719705e-05
step: 120, loss: 9.507514914730564e-05
step: 130, loss: 6.934408884262666e-05
step: 140, loss: 5.3298728744266555e-05
step: 150, loss: 0.0013334117829799652
step: 160, loss: 0.0001441647909814492
step: 170, loss: 4.9733185733202845e-05
step: 180, loss: 7.82337156124413e-05
step: 190, loss: 0.0001365425268886611
step: 200, loss: 9.62119156611152e-05
step: 210, loss: 9.722678805701435e-05
step: 220, loss: 5.5702021199977025e-05
step: 230, loss: 4.897515827906318e-05
step: 240, loss: 0.00012966865324415267
step: 250, loss: 8.470933244097978e-05
step: 260, loss: 0.00021264447423163801
step: 270, loss: 0.0027509434148669243
step: 280, loss: 0.00013377061986830086
step: 290, loss: 7.13769841240719e-05
step: 300, loss: 0.00014583869779016823
step: 310, loss: 8.449087181361392e-05
step: 320, loss: 3.551190093276091e-05
step: 330, loss: 3.3678472391329706e-05
step: 340, loss: 0.0003222223313059658
step: 350, loss: 0.00017491991457063705
step: 360, loss: 0.0002931761846411973
epoch 20: dev_f1=0.7230769230769232, f1=0.6831955922865013, best_f1=0.7052631578947368
