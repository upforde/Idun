cuda
Device: cuda
step: 0, loss: 0.9989861249923706
step: 10, loss: 0.239113911986351
step: 20, loss: 0.05617562308907509
step: 30, loss: 0.061412084847688675
step: 40, loss: 0.1375887244939804
step: 50, loss: 0.23950235545635223
step: 60, loss: 0.2292872965335846
step: 70, loss: 0.23834866285324097
step: 80, loss: 0.23317819833755493
step: 90, loss: 0.4355410039424896
step: 100, loss: 0.14201678335666656
step: 110, loss: 0.047299824655056
step: 120, loss: 0.3230462670326233
step: 130, loss: 0.1674899011850357
step: 140, loss: 0.1362299621105194
step: 150, loss: 0.04521603882312775
step: 160, loss: 0.2173835039138794
step: 170, loss: 0.019697096198797226
step: 180, loss: 0.13262173533439636
step: 190, loss: 0.2106807678937912
step: 200, loss: 0.3541494309902191
step: 210, loss: 0.12631508708000183
step: 220, loss: 0.06731078773736954
step: 230, loss: 0.44933971762657166
step: 240, loss: 0.22649459540843964
step: 250, loss: 0.22710749506950378
step: 260, loss: 0.37906312942504883
step: 270, loss: 0.29306745529174805
step: 280, loss: 0.1256953775882721
step: 290, loss: 0.21454164385795593
step: 300, loss: 0.20078027248382568
step: 310, loss: 0.03628711402416229
step: 320, loss: 0.03059825859963894
step: 330, loss: 0.39925041794776917
step: 340, loss: 0.10809575766324997
step: 350, loss: 0.042615149170160294
step: 360, loss: 0.2744702994823456
epoch 1: dev_f1=0.34782608695652173, f1=0.3935185185185185, best_f1=0.3935185185185185
step: 0, loss: 0.22398990392684937
step: 10, loss: 0.0932248905301094
step: 20, loss: 0.3028463125228882
step: 30, loss: 0.047245096415281296
step: 40, loss: 0.15871219336986542
step: 50, loss: 0.30570530891418457
step: 60, loss: 0.043436985462903976
step: 70, loss: 0.16672945022583008
step: 80, loss: 0.14448675513267517
step: 90, loss: 0.2156866490840912
step: 100, loss: 0.17791275680065155
step: 110, loss: 0.2174278199672699
step: 120, loss: 0.11414314061403275
step: 130, loss: 0.022462954744696617
step: 140, loss: 0.1627248227596283
step: 150, loss: 0.17751608788967133
step: 160, loss: 0.07685187458992004
step: 170, loss: 0.1014844998717308
step: 180, loss: 0.2753423750400543
step: 190, loss: 0.047376833856105804
step: 200, loss: 0.07338371872901917
step: 210, loss: 0.137898787856102
step: 220, loss: 0.12145564705133438
step: 230, loss: 0.11751362681388855
step: 240, loss: 0.2376946210861206
step: 250, loss: 0.1002216562628746
step: 260, loss: 0.18538731336593628
step: 270, loss: 0.2514137029647827
step: 280, loss: 0.03855011612176895
step: 290, loss: 0.10080954432487488
step: 300, loss: 0.23074564337730408
step: 310, loss: 0.0485403873026371
step: 320, loss: 0.17658185958862305
step: 330, loss: 0.14331674575805664
step: 340, loss: 0.11524967849254608
step: 350, loss: 0.16743029654026031
step: 360, loss: 0.2775324285030365
epoch 2: dev_f1=0.5036674816625918, f1=0.5078651685393258, best_f1=0.5078651685393258
step: 0, loss: 0.06202013045549393
step: 10, loss: 0.05356408655643463
step: 20, loss: 0.10381731390953064
step: 30, loss: 0.2200397551059723
step: 40, loss: 0.07796531170606613
step: 50, loss: 0.011994892731308937
step: 60, loss: 0.018630478531122208
step: 70, loss: 0.07770580798387527
step: 80, loss: 0.05778360366821289
step: 90, loss: 0.015952972695231438
step: 100, loss: 0.04070940613746643
step: 110, loss: 0.10549430549144745
step: 120, loss: 0.06788856536149979
step: 130, loss: 0.03168191760778427
step: 140, loss: 0.1980694830417633
step: 150, loss: 0.0961279422044754
step: 160, loss: 0.06904757022857666
step: 170, loss: 0.054886769503355026
step: 180, loss: 0.037214238196611404
step: 190, loss: 0.05477158725261688
step: 200, loss: 0.15148352086544037
step: 210, loss: 0.045213907957077026
step: 220, loss: 0.06427814811468124
step: 230, loss: 0.11542190611362457
step: 240, loss: 0.02169535495340824
step: 250, loss: 0.12286090105772018
step: 260, loss: 0.04877001419663429
step: 270, loss: 0.05470578745007515
step: 280, loss: 0.08294446021318436
step: 290, loss: 0.18945759534835815
step: 300, loss: 0.05939448997378349
step: 310, loss: 0.04488367214798927
step: 320, loss: 0.0934307649731636
step: 330, loss: 0.04506387934088707
step: 340, loss: 0.03491872549057007
step: 350, loss: 0.04583924636244774
step: 360, loss: 0.01708708330988884
epoch 3: dev_f1=0.625668449197861, f1=0.6453333333333333, best_f1=0.6453333333333333
step: 0, loss: 0.07799515873193741
step: 10, loss: 0.048910364508628845
step: 20, loss: 0.0833892896771431
step: 30, loss: 0.2257061004638672
step: 40, loss: 0.12251720577478409
step: 50, loss: 0.003958176821470261
step: 60, loss: 0.10217594355344772
step: 70, loss: 0.03234591335058212
step: 80, loss: 0.13950376212596893
step: 90, loss: 0.04734666272997856
step: 100, loss: 0.015759553760290146
step: 110, loss: 0.10512395948171616
step: 120, loss: 0.025525173172354698
step: 130, loss: 0.028774911537766457
step: 140, loss: 0.16679273545742035
step: 150, loss: 0.005067612510174513
step: 160, loss: 0.1380537450313568
step: 170, loss: 0.05695158615708351
step: 180, loss: 0.012484675273299217
step: 190, loss: 0.022350922226905823
step: 200, loss: 0.08853871375322342
step: 210, loss: 0.009887047111988068
step: 220, loss: 0.2293415069580078
step: 230, loss: 0.004362534731626511
step: 240, loss: 0.11721400171518326
step: 250, loss: 0.11240258812904358
step: 260, loss: 0.015526390634477139
step: 270, loss: 0.02966136299073696
step: 280, loss: 0.11947154998779297
step: 290, loss: 0.05467663332819939
step: 300, loss: 0.007982476614415646
step: 310, loss: 0.06194205954670906
step: 320, loss: 0.0023615476675331593
step: 330, loss: 0.037040915340185165
step: 340, loss: 0.05677591636776924
step: 350, loss: 0.04510321840643883
step: 360, loss: 0.010673019103705883
epoch 4: dev_f1=0.6510416666666666, f1=0.6541554959785524, best_f1=0.6541554959785524
step: 0, loss: 0.00357622723095119
step: 10, loss: 0.030264489352703094
step: 20, loss: 0.022191155701875687
step: 30, loss: 0.05143945664167404
step: 40, loss: 0.11975829303264618
step: 50, loss: 0.11596200615167618
step: 60, loss: 0.021752679720520973
step: 70, loss: 0.0016101897927001119
step: 80, loss: 0.05366018787026405
step: 90, loss: 0.011519687250256538
step: 100, loss: 0.05947767570614815
step: 110, loss: 0.006692040711641312
step: 120, loss: 0.04392056167125702
step: 130, loss: 0.04468157887458801
step: 140, loss: 0.04534440115094185
step: 150, loss: 0.03890826180577278
step: 160, loss: 0.010547571815550327
step: 170, loss: 0.19523072242736816
step: 180, loss: 0.012807093560695648
step: 190, loss: 0.010614562779664993
step: 200, loss: 0.08295789361000061
step: 210, loss: 0.0006824344163760543
step: 220, loss: 0.03020729124546051
step: 230, loss: 0.006065067835152149
step: 240, loss: 0.10335162281990051
step: 250, loss: 0.006773917470127344
step: 260, loss: 0.00721700070425868
step: 270, loss: 0.0010051067220047116
step: 280, loss: 0.040709465742111206
step: 290, loss: 0.028429927304387093
step: 300, loss: 0.07002495974302292
step: 310, loss: 0.013902795501053333
step: 320, loss: 0.016843214631080627
step: 330, loss: 0.03709062933921814
step: 340, loss: 0.13220632076263428
step: 350, loss: 0.021250173449516296
step: 360, loss: 0.022673340514302254
epoch 5: dev_f1=0.7015706806282722, f1=0.636604774535809, best_f1=0.636604774535809
step: 0, loss: 0.029279015958309174
step: 10, loss: 0.002449355088174343
step: 20, loss: 0.0007874795119278133
step: 30, loss: 0.007825658656656742
step: 40, loss: 0.003335727844387293
step: 50, loss: 0.000394621049053967
step: 60, loss: 0.1315774917602539
step: 70, loss: 0.0005135097890160978
step: 80, loss: 0.022232865914702415
step: 90, loss: 0.007027536164969206
step: 100, loss: 0.0005737071624025702
step: 110, loss: 0.06278761476278305
step: 120, loss: 0.011042682453989983
step: 130, loss: 0.024309489876031876
step: 140, loss: 0.0019863848574459553
step: 150, loss: 0.09795249998569489
step: 160, loss: 0.0035211099311709404
step: 170, loss: 0.038060322403907776
step: 180, loss: 0.009132785722613335
step: 190, loss: 0.0019800676964223385
step: 200, loss: 0.002514815190806985
step: 210, loss: 0.003663074690848589
step: 220, loss: 0.008463962934911251
step: 230, loss: 0.03709792718291283
step: 240, loss: 0.0001979677617782727
step: 250, loss: 0.015641450881958008
step: 260, loss: 0.026293287053704262
step: 270, loss: 0.06561842560768127
step: 280, loss: 0.0355033352971077
step: 290, loss: 0.017525410279631615
step: 300, loss: 0.012294461950659752
step: 310, loss: 0.00016625149874016643
step: 320, loss: 0.0016841883771121502
step: 330, loss: 0.015812117606401443
step: 340, loss: 0.07386118918657303
step: 350, loss: 0.004188537131994963
step: 360, loss: 0.015033659525215626
epoch 6: dev_f1=0.6470588235294117, f1=0.625, best_f1=0.636604774535809
step: 0, loss: 0.05663810670375824
step: 10, loss: 0.00638230238109827
step: 20, loss: 0.0008911839104257524
step: 30, loss: 0.002843900118023157
step: 40, loss: 0.01442006416618824
step: 50, loss: 0.029121268540620804
step: 60, loss: 0.0003835626703221351
step: 70, loss: 0.053806520998477936
step: 80, loss: 0.006135010160505772
step: 90, loss: 0.0004202545096632093
step: 100, loss: 0.005359185393899679
step: 110, loss: 0.0069237868301570415
step: 120, loss: 0.010836313478648663
step: 130, loss: 0.00038272718666121364
step: 140, loss: 0.014682403765618801
step: 150, loss: 0.004458678886294365
step: 160, loss: 0.0065230438485741615
step: 170, loss: 0.01182835828512907
step: 180, loss: 0.02152155339717865
step: 190, loss: 0.04131351783871651
step: 200, loss: 0.0033568169455975294
step: 210, loss: 0.006456146948039532
step: 220, loss: 0.010350357741117477
step: 230, loss: 0.0030907217878848314
step: 240, loss: 0.01681487262248993
step: 250, loss: 0.0008925540023483336
step: 260, loss: 0.0016831543762236834
step: 270, loss: 0.0020252554677426815
step: 280, loss: 0.009900032542645931
step: 290, loss: 0.00025064588407985866
step: 300, loss: 0.0010015566367655993
step: 310, loss: 0.10001380741596222
step: 320, loss: 0.0029729900415986776
step: 330, loss: 0.018077263608574867
step: 340, loss: 0.002333699492737651
step: 350, loss: 0.03734523057937622
step: 360, loss: 0.0996951013803482
epoch 7: dev_f1=0.6330275229357798, f1=0.6447058823529411, best_f1=0.636604774535809
step: 0, loss: 0.0029036072082817554
step: 10, loss: 0.01554995495826006
step: 20, loss: 0.01488808449357748
step: 30, loss: 0.013913316652178764
step: 40, loss: 0.0026803866494446993
step: 50, loss: 0.0008223532931879163
step: 60, loss: 0.0014374750899150968
step: 70, loss: 0.001241312245838344
step: 80, loss: 0.0006115960422903299
step: 90, loss: 0.015767427161335945
step: 100, loss: 0.000593759526964277
step: 110, loss: 0.0015068546636030078
step: 120, loss: 0.0010499721392989159
step: 130, loss: 0.04345649108290672
step: 140, loss: 0.014023497700691223
step: 150, loss: 0.0026026770938187838
step: 160, loss: 0.008430215530097485
step: 170, loss: 0.005183900706470013
step: 180, loss: 0.0008917347295209765
step: 190, loss: 0.0001351133978459984
step: 200, loss: 0.0031201811507344246
step: 210, loss: 0.0005427769501693547
step: 220, loss: 0.00025814262335188687
step: 230, loss: 0.0007577507058158517
step: 240, loss: 0.0001773164258338511
step: 250, loss: 0.0288479533046484
step: 260, loss: 0.0006260890513658524
step: 270, loss: 0.002625248394906521
step: 280, loss: 0.0007043693913146853
step: 290, loss: 0.009380157105624676
step: 300, loss: 0.00019715043890755624
step: 310, loss: 0.022728806361556053
step: 320, loss: 0.0019423742778599262
step: 330, loss: 0.0017505186842754483
step: 340, loss: 0.012149577960371971
step: 350, loss: 0.10264582931995392
step: 360, loss: 0.04013754799962044
epoch 8: dev_f1=0.653927813163482, f1=0.630669546436285, best_f1=0.636604774535809
step: 0, loss: 0.0071943108923733234
step: 10, loss: 0.0013404149794951081
step: 20, loss: 0.00046119155013002455
step: 30, loss: 0.0010706819593906403
step: 40, loss: 0.0004564357514027506
step: 50, loss: 0.00011545862071216106
step: 60, loss: 0.0042679933831095695
step: 70, loss: 0.0927901342511177
step: 80, loss: 0.0007617093506269157
step: 90, loss: 0.0018386401934549212
step: 100, loss: 0.02446221001446247
step: 110, loss: 0.0696716457605362
step: 120, loss: 0.0007393085397779942
step: 130, loss: 0.03818461671471596
step: 140, loss: 0.001512938062660396
step: 150, loss: 0.002020925749093294
step: 160, loss: 0.030731484293937683
step: 170, loss: 0.0013126609846949577
step: 180, loss: 0.008213876746594906
step: 190, loss: 0.0022045555524528027
step: 200, loss: 0.0002536746906116605
step: 210, loss: 0.000653949158731848
step: 220, loss: 0.10595162212848663
step: 230, loss: 0.03845476731657982
step: 240, loss: 0.015658734366297722
step: 250, loss: 0.0019843303598463535
step: 260, loss: 0.006698353681713343
step: 270, loss: 6.855684478068724e-05
step: 280, loss: 0.0010316408006474376
step: 290, loss: 0.00039789476431906223
step: 300, loss: 0.0012887570774182677
step: 310, loss: 0.20895831286907196
step: 320, loss: 0.00012370756303425878
step: 330, loss: 0.011665706522762775
step: 340, loss: 0.00031351877260021865
step: 350, loss: 9.320542449131608e-05
step: 360, loss: 0.001390376128256321
epoch 9: dev_f1=0.6264367816091954, f1=0.6432748538011697, best_f1=0.636604774535809
step: 0, loss: 0.0019559161737561226
step: 10, loss: 0.004727058578282595
step: 20, loss: 0.0005833524628542364
step: 30, loss: 4.203868957119994e-05
step: 40, loss: 0.00022393967083189636
step: 50, loss: 0.013546153903007507
step: 60, loss: 0.08119730651378632
step: 70, loss: 0.00013903922808822244
step: 80, loss: 0.0005015531787648797
step: 90, loss: 0.001369241625070572
step: 100, loss: 0.0004254764353390783
step: 110, loss: 0.0007675390224903822
step: 120, loss: 0.00018694932805374265
step: 130, loss: 0.0011641327291727066
step: 140, loss: 0.004838457331061363
step: 150, loss: 6.166338425828144e-05
step: 160, loss: 0.00024314656911883503
step: 170, loss: 0.00046956760343164206
step: 180, loss: 0.0007474693120457232
step: 190, loss: 0.0008730841800570488
step: 200, loss: 0.0019721672870218754
step: 210, loss: 0.05776619911193848
step: 220, loss: 8.183102181646973e-05
step: 230, loss: 0.0003313039487693459
step: 240, loss: 0.014242062345147133
step: 250, loss: 8.071798220044002e-05
step: 260, loss: 0.00013977543858345598
step: 270, loss: 4.307949711801484e-05
step: 280, loss: 0.012732402421534061
step: 290, loss: 0.00028670267784036696
step: 300, loss: 0.0041900938376784325
step: 310, loss: 0.0009585321531631052
step: 320, loss: 0.00026959364186041057
step: 330, loss: 4.148593870922923e-05
step: 340, loss: 0.00023442583915311843
step: 350, loss: 0.0007626673905178905
step: 360, loss: 0.0021163043566048145
epoch 10: dev_f1=0.6451612903225806, f1=0.69, best_f1=0.636604774535809
step: 0, loss: 0.0004236543318256736
step: 10, loss: 0.17500881850719452
step: 20, loss: 5.963787771179341e-05
step: 30, loss: 0.0001381347537972033
step: 40, loss: 0.0002279559848830104
step: 50, loss: 0.00022170518059283495
step: 60, loss: 0.0002249773679068312
step: 70, loss: 0.013442834839224815
step: 80, loss: 0.0006472296663559973
step: 90, loss: 0.0008199236472137272
step: 100, loss: 0.0002543893351685256
step: 110, loss: 0.00044691134826280177
step: 120, loss: 0.0012783999554812908
step: 130, loss: 0.0017506403382867575
step: 140, loss: 0.00499010318890214
step: 150, loss: 4.190261461189948e-05
step: 160, loss: 0.00319313514046371
step: 170, loss: 0.059872936457395554
step: 180, loss: 0.0013940081698819995
step: 190, loss: 0.0037750822957605124
step: 200, loss: 0.0007218086975626647
step: 210, loss: 0.014032968319952488
step: 220, loss: 0.0002153104724129662
step: 230, loss: 0.0016447104280814528
step: 240, loss: 0.00013486953685060143
step: 250, loss: 0.0028716507367789745
step: 260, loss: 0.00014005060074850917
step: 270, loss: 0.001906629535369575
step: 280, loss: 0.10244249552488327
step: 290, loss: 0.003223083447664976
step: 300, loss: 0.00040615067700855434
step: 310, loss: 0.00015240094217006117
step: 320, loss: 0.013580065220594406
step: 330, loss: 0.01287067774683237
step: 340, loss: 0.00014694467245135456
step: 350, loss: 0.0017551988130435348
step: 360, loss: 0.0007416357984766364
epoch 11: dev_f1=0.6969696969696969, f1=0.7005076142131978, best_f1=0.636604774535809
step: 0, loss: 7.241856656037271e-05
step: 10, loss: 0.0026619932614266872
step: 20, loss: 0.00029488897416740656
step: 30, loss: 0.00020014020265080035
step: 40, loss: 0.0015335798962041736
step: 50, loss: 0.003177021397277713
step: 60, loss: 0.006740400567650795
step: 70, loss: 0.00157423154450953
step: 80, loss: 0.02261439338326454
step: 90, loss: 0.00012225107639096677
step: 100, loss: 0.0007258624536916614
step: 110, loss: 0.0019492852734401822
step: 120, loss: 0.00014155122335068882
step: 130, loss: 0.0002522141148801893
step: 140, loss: 0.00021358521189540625
step: 150, loss: 0.0005356571637094021
step: 160, loss: 0.000180596427526325
step: 170, loss: 4.3124611693201587e-05
step: 180, loss: 0.0006363490247167647
step: 190, loss: 0.008146644569933414
step: 200, loss: 7.878545875428244e-05
step: 210, loss: 0.00020203374151606113
step: 220, loss: 0.004385736770927906
step: 230, loss: 8.608804637333378e-05
step: 240, loss: 0.00023170468921307474
step: 250, loss: 0.0006694794865325093
step: 260, loss: 0.0001713570236461237
step: 270, loss: 0.0010325945913791656
step: 280, loss: 0.00022095689200796187
step: 290, loss: 0.0893181785941124
step: 300, loss: 0.0008592700469307601
step: 310, loss: 0.0015173905994743109
step: 320, loss: 5.947240788373165e-05
step: 330, loss: 8.692223491379991e-05
step: 340, loss: 0.06038545444607735
step: 350, loss: 0.02266901731491089
step: 360, loss: 0.0038151980843394995
epoch 12: dev_f1=0.6947368421052632, f1=0.6811989100817438, best_f1=0.636604774535809
step: 0, loss: 3.436868064454757e-05
step: 10, loss: 0.00018285843543708324
step: 20, loss: 0.018072644248604774
step: 30, loss: 0.0013729424681514502
step: 40, loss: 0.00023693028197158128
step: 50, loss: 6.972838309593499e-05
step: 60, loss: 0.00017142326396424323
step: 70, loss: 0.00019358946883585304
step: 80, loss: 0.003057979280129075
step: 90, loss: 0.0006836501997895539
step: 100, loss: 0.0003046283673029393
step: 110, loss: 0.00018236196774523705
step: 120, loss: 0.00023769043036736548
step: 130, loss: 0.0006022816523909569
step: 140, loss: 0.0008354816818609834
step: 150, loss: 0.00914214551448822
step: 160, loss: 0.0010271893115714192
step: 170, loss: 0.04135477915406227
step: 180, loss: 3.0490813514916226e-05
step: 190, loss: 0.014471412636339664
step: 200, loss: 0.00023008027346804738
step: 210, loss: 0.0006365444278344512
step: 220, loss: 0.033513959497213364
step: 230, loss: 0.00023397164477501065
step: 240, loss: 0.0013889017282053828
step: 250, loss: 0.00789431668817997
step: 260, loss: 0.0003889779909513891
step: 270, loss: 0.02915078215301037
step: 280, loss: 0.00044719077413901687
step: 290, loss: 0.0013339394936338067
step: 300, loss: 0.003310662228614092
step: 310, loss: 0.00011755740706576034
step: 320, loss: 0.037387896329164505
step: 330, loss: 0.000928630237467587
step: 340, loss: 0.0003896697307936847
step: 350, loss: 0.00025933003053069115
step: 360, loss: 0.00014057126827538013
epoch 13: dev_f1=0.6684491978609626, f1=0.6648199445983378, best_f1=0.636604774535809
step: 0, loss: 8.650127711007372e-05
step: 10, loss: 7.455722516169772e-05
step: 20, loss: 0.0060423994436860085
step: 30, loss: 0.0013112942688167095
step: 40, loss: 0.0015991580439731479
step: 50, loss: 0.07879628986120224
step: 60, loss: 0.00027455895906314254
step: 70, loss: 0.0012702387757599354
step: 80, loss: 0.000187715922947973
step: 90, loss: 0.15642790496349335
step: 100, loss: 2.6228895876556635e-05
step: 110, loss: 0.001135922153480351
step: 120, loss: 0.02138080634176731
step: 130, loss: 0.00026065477868542075
step: 140, loss: 0.0008706767694093287
step: 150, loss: 0.000446327991085127
step: 160, loss: 0.0007435914012603462
step: 170, loss: 0.0002874505880754441
step: 180, loss: 0.0012301072711125016
step: 190, loss: 7.220385305117816e-05
step: 200, loss: 0.0001030217608786188
step: 210, loss: 0.000673751113936305
step: 220, loss: 0.01452084630727768
step: 230, loss: 0.0008838879293762147
step: 240, loss: 0.0008242634357884526
step: 250, loss: 0.0008546203025616705
step: 260, loss: 0.0015766858123242855
step: 270, loss: 0.00023502277326770127
step: 280, loss: 0.00018619395268615335
step: 290, loss: 0.00012934234109707177
step: 300, loss: 0.00013603296247310936
step: 310, loss: 0.00012833555229008198
step: 320, loss: 0.001583840581588447
step: 330, loss: 9.093467087950557e-05
step: 340, loss: 0.0002698495227377862
step: 350, loss: 0.0005110117490403354
step: 360, loss: 0.0001988561125472188
epoch 14: dev_f1=0.6629834254143646, f1=0.6934097421203439, best_f1=0.636604774535809
step: 0, loss: 0.16710510849952698
step: 10, loss: 0.003255559364333749
step: 20, loss: 0.0005725586088374257
step: 30, loss: 0.0006226787809282541
step: 40, loss: 2.595631667645648e-05
step: 50, loss: 0.000887980917468667
step: 60, loss: 0.00039324353565461934
step: 70, loss: 0.00020245804626028985
step: 80, loss: 0.0001182569467346184
step: 90, loss: 0.00013983060489408672
step: 100, loss: 4.667791290557943e-05
step: 110, loss: 0.0001382149785058573
step: 120, loss: 0.0017517863307148218
step: 130, loss: 0.0009892910020425916
step: 140, loss: 0.00024911738000810146
step: 150, loss: 0.0068974802270531654
step: 160, loss: 0.00016053064609877765
step: 170, loss: 6.491384556284174e-05
step: 180, loss: 2.2332063963403925e-05
step: 190, loss: 0.00219675712287426
step: 200, loss: 0.01183161698281765
step: 210, loss: 0.0005537325050681829
step: 220, loss: 0.00011306318629067391
step: 230, loss: 0.00034513964783400297
step: 240, loss: 0.0031702916603535414
step: 250, loss: 2.4808963644318283e-05
step: 260, loss: 0.00023864360991865396
step: 270, loss: 1.1749491022783332e-05
step: 280, loss: 0.15657354891300201
step: 290, loss: 0.0020691314712166786
step: 300, loss: 3.3138658181997016e-05
step: 310, loss: 3.106677468167618e-05
step: 320, loss: 3.763617132790387e-05
step: 330, loss: 1.3183699593355414e-05
step: 340, loss: 1.4554483641404659e-05
step: 350, loss: 0.00020472347387112677
step: 360, loss: 3.564377402653918e-05
epoch 15: dev_f1=0.676923076923077, f1=0.6986666666666667, best_f1=0.636604774535809
step: 0, loss: 0.028734279796481133
step: 10, loss: 1.5944091501296498e-05
step: 20, loss: 0.00012005297321593389
step: 30, loss: 3.058121001231484e-05
step: 40, loss: 0.0005606815684586763
step: 50, loss: 0.0001424501824658364
step: 60, loss: 5.6648415920790285e-05
step: 70, loss: 0.00024303342797793448
step: 80, loss: 1.7631171431276016e-05
step: 90, loss: 0.0013414850691333413
step: 100, loss: 9.569127723807469e-05
step: 110, loss: 5.426528150564991e-05
step: 120, loss: 0.0001701237342786044
step: 130, loss: 0.00040504508069716394
step: 140, loss: 0.000129113148432225
step: 150, loss: 0.0006234566099010408
step: 160, loss: 0.00044834217987954617
step: 170, loss: 4.7147012082859874e-05
step: 180, loss: 4.501184230321087e-05
step: 190, loss: 0.0007299158023670316
step: 200, loss: 5.9261223213979974e-05
step: 210, loss: 0.0005720903282053769
step: 220, loss: 0.0025521519128233194
step: 230, loss: 3.779966209549457e-05
step: 240, loss: 0.00010310154902981594
step: 250, loss: 0.001686258940026164
step: 260, loss: 2.1519404981518164e-05
step: 270, loss: 0.0005606323247775435
step: 280, loss: 0.0008645190391689539
step: 290, loss: 0.00022654846543446183
step: 300, loss: 7.282076694536954e-05
step: 310, loss: 7.749434735160321e-05
step: 320, loss: 3.0322111342684366e-05
step: 330, loss: 0.00031290168408304453
step: 340, loss: 7.464352529495955e-05
step: 350, loss: 0.0005505671724677086
step: 360, loss: 1.627550409466494e-05
epoch 16: dev_f1=0.6700507614213198, f1=0.7131782945736433, best_f1=0.636604774535809
step: 0, loss: 0.0031582205556333065
step: 10, loss: 0.0025889051612466574
step: 20, loss: 0.00041433543083257973
step: 30, loss: 1.6536363546038046e-05
step: 40, loss: 0.00020663476607296616
step: 50, loss: 2.544478229538072e-05
step: 60, loss: 0.0001662994473008439
step: 70, loss: 0.02281007170677185
step: 80, loss: 5.121389403939247e-05
step: 90, loss: 0.016533508896827698
step: 100, loss: 4.5378386857919395e-05
step: 110, loss: 0.0003170422569382936
step: 120, loss: 7.227136666188017e-05
step: 130, loss: 0.0005542596336454153
step: 140, loss: 8.022861584322527e-05
step: 150, loss: 0.0006748171290382743
step: 160, loss: 0.0001635691587580368
step: 170, loss: 0.0012174149742349982
step: 180, loss: 9.822344873100519e-05
step: 190, loss: 2.880113424907904e-05
step: 200, loss: 0.011555146425962448
step: 210, loss: 0.045580197125673294
step: 220, loss: 5.586815677816048e-05
step: 230, loss: 0.0005703461356461048
step: 240, loss: 0.0002720995107665658
step: 250, loss: 1.6797095668152906e-05
step: 260, loss: 0.00042682792991399765
step: 270, loss: 0.003991022706031799
step: 280, loss: 3.0525763577315956e-05
step: 290, loss: 0.0006503476179204881
step: 300, loss: 0.0004417963791638613
step: 310, loss: 5.5290151067310944e-05
step: 320, loss: 0.00033004299621097744
step: 330, loss: 7.173805352067575e-05
step: 340, loss: 0.00018138547602575272
step: 350, loss: 0.0006255173939280212
step: 360, loss: 1.5187790268100798e-05
epoch 17: dev_f1=0.6666666666666666, f1=0.6880000000000001, best_f1=0.636604774535809
step: 0, loss: 0.0006037302664481103
step: 10, loss: 0.00011324782826704904
step: 20, loss: 0.000443885539425537
step: 30, loss: 2.90085154119879e-05
step: 40, loss: 8.249154780060053e-05
step: 50, loss: 2.1799349269713275e-05
step: 60, loss: 0.0003786752058658749
step: 70, loss: 2.4872177164070308e-05
step: 80, loss: 8.951784548116848e-05
step: 90, loss: 0.0025883279740810394
step: 100, loss: 0.0002411370223853737
step: 110, loss: 5.662425610353239e-05
step: 120, loss: 0.007482481189072132
step: 130, loss: 0.000885560701135546
step: 140, loss: 1.9676099327625707e-05
step: 150, loss: 0.0005314690642990172
step: 160, loss: 0.0004854915605392307
step: 170, loss: 0.0008348365663550794
step: 180, loss: 0.00017518381355330348
step: 190, loss: 3.2435527828056365e-05
step: 200, loss: 0.0003644149983301759
step: 210, loss: 0.0018065646290779114
step: 220, loss: 0.006570796947926283
step: 230, loss: 0.00017417788330931216
step: 240, loss: 2.499006768630352e-05
step: 250, loss: 0.0001417174789821729
step: 260, loss: 1.2420023267623037e-05
step: 270, loss: 0.0002275221049785614
step: 280, loss: 0.00045808579307049513
step: 290, loss: 1.6938589396886528e-05
step: 300, loss: 0.0003456041740719229
step: 310, loss: 5.1147217163816094e-05
step: 320, loss: 0.00014745150110684335
step: 330, loss: 0.00016526116814929992
step: 340, loss: 2.140742799383588e-05
step: 350, loss: 0.001045360928401351
step: 360, loss: 0.00010493827721802518
epoch 18: dev_f1=0.6522911051212938, f1=0.6705202312138729, best_f1=0.636604774535809
step: 0, loss: 0.0001954470935743302
step: 10, loss: 0.0002697710588108748
step: 20, loss: 0.00020844821119681
step: 30, loss: 0.0009501582244411111
step: 40, loss: 5.2008574130013585e-05
step: 50, loss: 3.5893455788027495e-05
step: 60, loss: 0.00012040455476380885
step: 70, loss: 3.6243869544705376e-05
step: 80, loss: 2.8800970540032722e-05
step: 90, loss: 0.0002633862604852766
step: 100, loss: 1.0736219337559305e-05
step: 110, loss: 4.302588786231354e-05
step: 120, loss: 5.4048941819928586e-05
step: 130, loss: 5.6846656661946326e-05
step: 140, loss: 3.190711868228391e-05
step: 150, loss: 0.00019112516019959003
step: 160, loss: 5.134152161190286e-05
step: 170, loss: 6.354403012664989e-05
step: 180, loss: 3.966505028074607e-05
step: 190, loss: 0.016056453809142113
step: 200, loss: 0.0001576924551045522
step: 210, loss: 5.511692143045366e-05
step: 220, loss: 8.502820128342137e-05
step: 230, loss: 0.00012579551548697054
step: 240, loss: 4.132952381041832e-05
step: 250, loss: 0.0007748699863441288
step: 260, loss: 4.8536585381953046e-05
step: 270, loss: 0.00015171813720371574
step: 280, loss: 0.043372705578804016
step: 290, loss: 3.909201404894702e-05
step: 300, loss: 3.423139060032554e-05
step: 310, loss: 1.2323153896431904e-05
step: 320, loss: 3.129889955744147e-05
step: 330, loss: 4.7601275582564995e-05
step: 340, loss: 0.001275181770324707
step: 350, loss: 0.00011031882604584098
step: 360, loss: 0.0004427473177202046
epoch 19: dev_f1=0.6505376344086021, f1=0.6762177650429799, best_f1=0.636604774535809
step: 0, loss: 9.177526226267219e-05
step: 10, loss: 4.026366150355898e-05
step: 20, loss: 0.0012094626436010003
step: 30, loss: 0.00010973405005643144
step: 40, loss: 2.991011569974944e-05
step: 50, loss: 0.0020086108706891537
step: 60, loss: 3.787290916079655e-05
step: 70, loss: 5.215593773755245e-05
step: 80, loss: 2.0964740542694926e-05
step: 90, loss: 1.039349808706902e-05
step: 100, loss: 0.0008787791593931615
step: 110, loss: 9.569546818966046e-05
step: 120, loss: 2.2682181224809028e-05
step: 130, loss: 0.00011041955440305173
step: 140, loss: 0.0008982291910797358
step: 150, loss: 0.0001013238143059425
step: 160, loss: 8.969656482804567e-05
step: 170, loss: 0.00010744111204985529
step: 180, loss: 1.5153929780353792e-05
step: 190, loss: 2.0394274542923085e-05
step: 200, loss: 7.999497029231861e-05
step: 210, loss: 0.00010907281102845445
step: 220, loss: 0.00040549575351178646
step: 230, loss: 0.0006241007940843701
step: 240, loss: 1.7493659470346756e-05
step: 250, loss: 0.00014601726434193552
step: 260, loss: 6.050741649232805e-05
step: 270, loss: 1.945914118550718e-05
step: 280, loss: 0.00010822540934896097
step: 290, loss: 0.0006052007083781064
step: 300, loss: 0.035876400768756866
step: 310, loss: 5.5291577155003324e-05
step: 320, loss: 6.231817678781226e-05
step: 330, loss: 8.598226122558117e-05
step: 340, loss: 9.697229688754305e-05
step: 350, loss: 0.0015946675557643175
step: 360, loss: 5.110737765789963e-05
epoch 20: dev_f1=0.6576819407008087, f1=0.6742857142857143, best_f1=0.636604774535809
