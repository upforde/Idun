cuda
Device: cuda
step: 0, loss: 0.828280508518219
step: 10, loss: 0.35539156198501587
step: 20, loss: 0.23581816256046295
step: 30, loss: 0.3337629437446594
step: 40, loss: 0.43586236238479614
step: 50, loss: 0.16809134185314178
step: 60, loss: 0.062423594295978546
step: 70, loss: 0.23733247816562653
step: 80, loss: 0.14077994227409363
step: 90, loss: 0.309283584356308
step: 100, loss: 0.17872600257396698
step: 110, loss: 0.08174315094947815
step: 120, loss: 0.10681385546922684
step: 130, loss: 0.11702398955821991
step: 140, loss: 0.053143810480833054
step: 150, loss: 0.031183330342173576
step: 160, loss: 0.31302693486213684
step: 170, loss: 0.09618094563484192
step: 180, loss: 0.06748213618993759
step: 190, loss: 0.03220465034246445
step: 200, loss: 0.01430548820644617
step: 210, loss: 0.20766957104206085
step: 220, loss: 0.10290771722793579
step: 230, loss: 0.12048640847206116
step: 240, loss: 0.07383450120687485
step: 250, loss: 0.04120379313826561
step: 260, loss: 0.14949358999729156
step: 270, loss: 0.015556235797703266
step: 280, loss: 0.0008715428994037211
step: 290, loss: 0.03173813596367836
step: 300, loss: 0.0010901257628574967
step: 310, loss: 0.16464772820472717
step: 320, loss: 0.1555611491203308
step: 330, loss: 0.07247065007686615
step: 340, loss: 0.18791735172271729
step: 350, loss: 0.10487952083349228
step: 360, loss: 0.07303863763809204
step: 370, loss: 0.01802193559706211
step: 380, loss: 0.06492095440626144
step: 390, loss: 0.003796317847445607
step: 400, loss: 0.14800341427326202
step: 410, loss: 0.05871528387069702
step: 420, loss: 0.21573686599731445
epoch 1: dev_f1=0.9797752808988766, f1=0.9718785151856018, best_f1=0.9718785151856018
step: 0, loss: 0.1681598573923111
step: 10, loss: 0.024454087018966675
step: 20, loss: 0.028557665646076202
step: 30, loss: 0.05248918756842613
step: 40, loss: 0.12917163968086243
step: 50, loss: 0.038326624780893326
step: 60, loss: 0.09819751977920532
step: 70, loss: 0.09898805618286133
step: 80, loss: 0.05757526308298111
step: 90, loss: 0.11463960260152817
step: 100, loss: 0.0342441089451313
step: 110, loss: 0.055320754647254944
step: 120, loss: 0.156564399600029
step: 130, loss: 0.033918216824531555
step: 140, loss: 0.03192135691642761
step: 150, loss: 0.05205991119146347
step: 160, loss: 0.06750506162643433
step: 170, loss: 0.024985823780298233
step: 180, loss: 0.07777328044176102
step: 190, loss: 0.15691308677196503
step: 200, loss: 0.023063134402036667
step: 210, loss: 0.0775885283946991
step: 220, loss: 0.10219898819923401
step: 230, loss: 0.054417964071035385
step: 240, loss: 0.1963598132133484
step: 250, loss: 0.11219383031129837
step: 260, loss: 0.03524471074342728
step: 270, loss: 0.10473819077014923
step: 280, loss: 0.08458545058965683
step: 290, loss: 0.09491565823554993
step: 300, loss: 0.016977589577436447
step: 310, loss: 0.1789710819721222
step: 320, loss: 0.02309444546699524
step: 330, loss: 0.12073403596878052
step: 340, loss: 0.08918736129999161
step: 350, loss: 0.027844781056046486
step: 360, loss: 0.02420678734779358
step: 370, loss: 0.013773715123534203
step: 380, loss: 0.08605597168207169
step: 390, loss: 0.015024452470242977
step: 400, loss: 0.0008401864324696362
step: 410, loss: 0.07662564516067505
step: 420, loss: 0.12687911093235016
epoch 2: dev_f1=0.9819004524886877, f1=0.9796839729119639, best_f1=0.9796839729119639
step: 0, loss: 0.01916920579969883
step: 10, loss: 0.11606590449810028
step: 20, loss: 0.18713422119617462
step: 30, loss: 0.0765012800693512
step: 40, loss: 0.02369893714785576
step: 50, loss: 0.07789918035268784
step: 60, loss: 0.0471651628613472
step: 70, loss: 0.07639652490615845
step: 80, loss: 0.02115754783153534
step: 90, loss: 0.06433633714914322
step: 100, loss: 0.07412563264369965
step: 110, loss: 0.027543479576706886
step: 120, loss: 0.07647691667079926
step: 130, loss: 0.028583375737071037
step: 140, loss: 0.03942074254155159
step: 150, loss: 0.02293548174202442
step: 160, loss: 0.07964147627353668
step: 170, loss: 0.04589433968067169
step: 180, loss: 0.01971215382218361
step: 190, loss: 0.020425261929631233
step: 200, loss: 0.010833345353603363
step: 210, loss: 0.07066095620393753
step: 220, loss: 0.11853256821632385
step: 230, loss: 0.0636434406042099
step: 240, loss: 0.05653270706534386
step: 250, loss: 0.056763533502817154
step: 260, loss: 0.05853140726685524
step: 270, loss: 0.07603876292705536
step: 280, loss: 0.013935999013483524
step: 290, loss: 0.10778528451919556
step: 300, loss: 0.06771401315927505
step: 310, loss: 0.11780403554439545
step: 320, loss: 0.012148302048444748
step: 330, loss: 0.015948548913002014
step: 340, loss: 0.004418364260345697
step: 350, loss: 0.14423784613609314
step: 360, loss: 0.007600368931889534
step: 370, loss: 0.10700776427984238
step: 380, loss: 0.16279979050159454
step: 390, loss: 0.0651291236281395
step: 400, loss: 0.05955295264720917
step: 410, loss: 0.015029443427920341
step: 420, loss: 0.11899466067552567
epoch 3: dev_f1=0.9899216125419933, f1=0.9854748603351955, best_f1=0.9854748603351955
step: 0, loss: 0.11031568795442581
step: 10, loss: 0.07914245873689651
step: 20, loss: 0.06477649509906769
step: 30, loss: 0.07668113708496094
step: 40, loss: 0.025657258927822113
step: 50, loss: 0.07817236334085464
step: 60, loss: 0.057944249361753464
step: 70, loss: 0.0423494353890419
step: 80, loss: 0.06535428762435913
step: 90, loss: 0.06051931530237198
step: 100, loss: 0.07465364038944244
step: 110, loss: 0.018974823877215385
step: 120, loss: 0.03583702817559242
step: 130, loss: 0.07099442183971405
step: 140, loss: 0.10571953654289246
step: 150, loss: 0.0614861398935318
step: 160, loss: 0.02241108939051628
step: 170, loss: 0.059444770216941833
step: 180, loss: 0.07398787885904312
step: 190, loss: 0.059038493782281876
step: 200, loss: 0.01308727078139782
step: 210, loss: 0.15172310173511505
step: 220, loss: 0.07701758295297623
step: 230, loss: 0.010945472866296768
step: 240, loss: 0.07537918537855148
step: 250, loss: 0.008681432344019413
step: 260, loss: 0.021930035203695297
step: 270, loss: 0.028587758541107178
step: 280, loss: 0.09202278405427933
step: 290, loss: 0.016886839643120766
step: 300, loss: 0.07846558839082718
step: 310, loss: 0.2559429705142975
step: 320, loss: 0.0485105998814106
step: 330, loss: 0.05853931978344917
step: 340, loss: 0.04423573240637779
step: 350, loss: 0.013729546219110489
step: 360, loss: 0.1007675752043724
step: 370, loss: 0.019271744415163994
step: 380, loss: 0.0698690116405487
step: 390, loss: 0.1193028911948204
step: 400, loss: 0.04164886102080345
step: 410, loss: 0.02392960898578167
step: 420, loss: 0.11806587129831314
epoch 4: dev_f1=0.988814317673378, f1=0.9776785714285714, best_f1=0.9854748603351955
step: 0, loss: 0.06004539132118225
step: 10, loss: 0.03760306537151337
step: 20, loss: 0.008400228805840015
step: 30, loss: 0.037454213947057724
step: 40, loss: 0.1316029131412506
step: 50, loss: 0.03073073923587799
step: 60, loss: 0.15398302674293518
step: 70, loss: 0.014259498566389084
step: 80, loss: 0.022656036540865898
step: 90, loss: 0.02786296419799328
step: 100, loss: 0.05180643871426582
step: 110, loss: 0.011023664847016335
step: 120, loss: 0.006405472755432129
step: 130, loss: 0.14998836815357208
step: 140, loss: 0.013606022112071514
step: 150, loss: 0.013621296733617783
step: 160, loss: 0.03060215711593628
step: 170, loss: 0.04238497093319893
step: 180, loss: 0.03418160602450371
step: 190, loss: 0.0672512799501419
step: 200, loss: 0.06857793033123016
step: 210, loss: 0.02437012642621994
step: 220, loss: 0.029929570853710175
step: 230, loss: 0.03877934440970421
step: 240, loss: 0.022467682138085365
step: 250, loss: 0.08043643832206726
step: 260, loss: 0.025000151246786118
step: 270, loss: 0.06360780447721481
step: 280, loss: 0.033064018934965134
step: 290, loss: 0.07203226536512375
step: 300, loss: 0.03387412428855896
step: 310, loss: 0.009222433902323246
step: 320, loss: 0.05495511367917061
step: 330, loss: 0.14177002012729645
step: 340, loss: 0.06272276490926743
step: 350, loss: 0.025346213951706886
step: 360, loss: 0.07730599492788315
step: 370, loss: 0.027705596759915352
step: 380, loss: 0.06864959001541138
step: 390, loss: 0.04932006075978279
step: 400, loss: 0.11056606471538544
step: 410, loss: 0.04049326479434967
step: 420, loss: 0.11373265832662582
epoch 5: dev_f1=0.9887640449438202, f1=0.9841628959276018, best_f1=0.9854748603351955
step: 0, loss: 0.10487589240074158
step: 10, loss: 0.16003020107746124
step: 20, loss: 0.035586804151535034
step: 30, loss: 0.06841307133436203
step: 40, loss: 0.08478434383869171
step: 50, loss: 0.06893538683652878
step: 60, loss: 0.00021689858112949878
step: 70, loss: 0.019719788804650307
step: 80, loss: 0.030306991189718246
step: 90, loss: 0.0863671526312828
step: 100, loss: 0.15656882524490356
step: 110, loss: 0.09639782458543777
step: 120, loss: 0.13617250323295593
step: 130, loss: 0.018893862143158913
step: 140, loss: 0.03118942491710186
step: 150, loss: 0.06258562952280045
step: 160, loss: 0.04562448710203171
step: 170, loss: 0.009081996977329254
step: 180, loss: 0.06968041509389877
step: 190, loss: 0.04465215653181076
step: 200, loss: 4.027277827844955e-05
step: 210, loss: 0.07229945808649063
step: 220, loss: 2.953734110633377e-05
step: 230, loss: 0.15925340354442596
step: 240, loss: 0.07110564410686493
step: 250, loss: 0.04498373717069626
step: 260, loss: 0.040323566645383835
step: 270, loss: 0.07393971085548401
step: 280, loss: 0.07431244850158691
step: 290, loss: 0.013369854539632797
step: 300, loss: 0.07933896034955978
step: 310, loss: 0.06402339786291122
step: 320, loss: 0.12136892229318619
step: 330, loss: 0.05863877385854721
step: 340, loss: 0.007846292108297348
step: 350, loss: 0.021478157490491867
step: 360, loss: 0.06969891488552094
step: 370, loss: 0.006758121307939291
step: 380, loss: 0.021953098475933075
step: 390, loss: 0.14448796212673187
step: 400, loss: 0.10549918562173843
step: 410, loss: 0.052227944135665894
step: 420, loss: 0.006058350671082735
epoch 6: dev_f1=0.9921436588103255, f1=0.9831271091113611, best_f1=0.9831271091113611
step: 0, loss: 0.05912207067012787
step: 10, loss: 0.01288452185690403
step: 20, loss: 0.0204080231487751
step: 30, loss: 0.024246059358119965
step: 40, loss: 0.005060181487351656
step: 50, loss: 0.01065844763070345
step: 60, loss: 0.10357900708913803
step: 70, loss: 0.1367221623659134
step: 80, loss: 0.05749940127134323
step: 90, loss: 0.04531417042016983
step: 100, loss: 0.012176921591162682
step: 110, loss: 0.0955023318529129
step: 120, loss: 0.21214567124843597
step: 130, loss: 0.005566422827541828
step: 140, loss: 0.008463566191494465
step: 150, loss: 0.14844320714473724
step: 160, loss: 0.09659135341644287
step: 170, loss: 0.01122540794312954
step: 180, loss: 0.19039225578308105
step: 190, loss: 0.04239242896437645
step: 200, loss: 0.01673099212348461
step: 210, loss: 0.08737204223871231
step: 220, loss: 0.048629436641931534
step: 230, loss: 0.07027396559715271
step: 240, loss: 0.1506376713514328
step: 250, loss: 0.11797051131725311
step: 260, loss: 0.06977944076061249
step: 270, loss: 0.09286914020776749
step: 280, loss: 0.16969643533229828
step: 290, loss: 0.018839430063962936
step: 300, loss: 0.023235348984599113
step: 310, loss: 0.06478113681077957
step: 320, loss: 0.045065075159072876
step: 330, loss: 0.07241341471672058
step: 340, loss: 0.053160399198532104
step: 350, loss: 0.045459333807229996
step: 360, loss: 0.07550065964460373
step: 370, loss: 0.037079598754644394
step: 380, loss: 0.09632128477096558
step: 390, loss: 0.0181016493588686
step: 400, loss: 0.0032026697881519794
step: 410, loss: 0.043808501213788986
step: 420, loss: 0.02042359486222267
epoch 7: dev_f1=0.9932432432432432, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.00583257619291544
step: 10, loss: 0.009753678925335407
step: 20, loss: 0.06409654021263123
step: 30, loss: 0.00431216461583972
step: 40, loss: 0.010914202779531479
step: 50, loss: 0.07390949875116348
step: 60, loss: 0.009705452248454094
step: 70, loss: 0.09937908500432968
step: 80, loss: 0.060332972556352615
step: 90, loss: 0.030137039721012115
step: 100, loss: 0.016088830307126045
step: 110, loss: 0.15157943964004517
step: 120, loss: 0.008401748724281788
step: 130, loss: 0.07100711762905121
step: 140, loss: 0.14186541736125946
step: 150, loss: 0.11718405038118362
step: 160, loss: 0.09674220532178879
step: 170, loss: 0.11859255284070969
step: 180, loss: 0.016081199049949646
step: 190, loss: 0.05078024044632912
step: 200, loss: 0.05552766099572182
step: 210, loss: 0.06592339277267456
step: 220, loss: 0.016854047775268555
step: 230, loss: 0.008028467185795307
step: 240, loss: 0.011539421044290066
step: 250, loss: 0.013126404955983162
step: 260, loss: 0.00630261842161417
step: 270, loss: 0.005339516326785088
step: 280, loss: 0.04550440236926079
step: 290, loss: 0.0686381608247757
step: 300, loss: 0.013155163265764713
step: 310, loss: 0.018979191780090332
step: 320, loss: 0.013943523168563843
step: 330, loss: 0.15715843439102173
step: 340, loss: 0.010922201909124851
step: 350, loss: 0.01543640997260809
step: 360, loss: 0.00011806051770690829
step: 370, loss: 0.08714047819375992
step: 380, loss: 0.027582406997680664
step: 390, loss: 0.050581809133291245
step: 400, loss: 0.013249741867184639
step: 410, loss: 0.012543720193207264
step: 420, loss: 0.007042490411549807
epoch 8: dev_f1=0.9932279909706545, f1=0.9875424688561721, best_f1=0.9854096520763187
step: 0, loss: 0.0620763935148716
step: 10, loss: 0.054633304476737976
step: 20, loss: 0.07796824723482132
step: 30, loss: 0.0914657935500145
step: 40, loss: 0.02607065439224243
step: 50, loss: 0.0900411605834961
step: 60, loss: 0.06125127151608467
step: 70, loss: 0.08397667855024338
step: 80, loss: 0.010372358374297619
step: 90, loss: 0.07843244820833206
step: 100, loss: 0.0065786573104560375
step: 110, loss: 0.00860549695789814
step: 120, loss: 0.07610039412975311
step: 130, loss: 0.013310406357049942
step: 140, loss: 0.0039048749022185802
step: 150, loss: 0.006260626018047333
step: 160, loss: 0.10360530018806458
step: 170, loss: 0.01217718981206417
step: 180, loss: 0.04215652868151665
step: 190, loss: 0.09493057429790497
step: 200, loss: 0.022954504936933517
step: 210, loss: 0.003742652479559183
step: 220, loss: 0.020866192877292633
step: 230, loss: 0.10787308216094971
step: 240, loss: 0.0376008003950119
step: 250, loss: 0.06388422846794128
step: 260, loss: 0.07014446705579758
step: 270, loss: 0.0068605029955506325
step: 280, loss: 0.023413730785250664
step: 290, loss: 0.08399853110313416
step: 300, loss: 0.059492580592632294
step: 310, loss: 0.005997269414365292
step: 320, loss: 0.01915775239467621
step: 330, loss: 0.015820026397705078
step: 340, loss: 0.011107681319117546
step: 350, loss: 0.01208109688013792
step: 360, loss: 0.14465846121311188
step: 370, loss: 0.004916348960250616
step: 380, loss: 0.054051678627729416
step: 390, loss: 0.03237137198448181
step: 400, loss: 0.06866689771413803
step: 410, loss: 0.0658326968550682
step: 420, loss: 0.009485363028943539
epoch 9: dev_f1=0.992108229988726, f1=0.9876819708846584, best_f1=0.9854096520763187
step: 0, loss: 0.0996602401137352
step: 10, loss: 0.0550013966858387
step: 20, loss: 0.026801953092217445
step: 30, loss: 0.028676019981503487
step: 40, loss: 0.045154280960559845
step: 50, loss: 0.0047821346670389175
step: 60, loss: 0.029235154390335083
step: 70, loss: 0.005585239734500647
step: 80, loss: 0.06092667952179909
step: 90, loss: 0.015625927597284317
step: 100, loss: 0.048806603997945786
step: 110, loss: 0.023809315636754036
step: 120, loss: 0.06568337976932526
step: 130, loss: 0.02079819142818451
step: 140, loss: 0.0871942937374115
step: 150, loss: 0.05372810363769531
step: 160, loss: 0.012297692708671093
step: 170, loss: 0.049848757684230804
step: 180, loss: 0.0889008641242981
step: 190, loss: 0.07098253071308136
step: 200, loss: 0.03146710619330406
step: 210, loss: 0.007224451284855604
step: 220, loss: 0.006989645771682262
step: 230, loss: 0.009592539630830288
step: 240, loss: 0.0037756934762001038
step: 250, loss: 0.01925991289317608
step: 260, loss: 0.020828021690249443
step: 270, loss: 0.1358439326286316
step: 280, loss: 0.015299810096621513
step: 290, loss: 0.03363553434610367
step: 300, loss: 0.04952554404735565
step: 310, loss: 0.009996762499213219
step: 320, loss: 0.03634677827358246
step: 330, loss: 0.04942723363637924
step: 340, loss: 0.003609615145251155
step: 350, loss: 0.288600355386734
step: 360, loss: 0.01709366776049137
step: 370, loss: 0.0377422571182251
step: 380, loss: 0.05684838443994522
step: 390, loss: 0.033508699387311935
step: 400, loss: 0.11861070245504379
step: 410, loss: 0.07342429459095001
step: 420, loss: 0.01198491919785738
epoch 10: dev_f1=0.9943757030371203, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.03851333260536194
step: 10, loss: 0.010655873455107212
step: 20, loss: 0.11458688229322433
step: 30, loss: 0.023573413491249084
step: 40, loss: 0.017600197345018387
step: 50, loss: 0.00419380608946085
step: 60, loss: 0.0007789917872287333
step: 70, loss: 0.079611636698246
step: 80, loss: 0.004593578167259693
step: 90, loss: 0.005940615199506283
step: 100, loss: 0.12116431444883347
step: 110, loss: 0.0031907688826322556
step: 120, loss: 0.021747779101133347
step: 130, loss: 0.10750602185726166
step: 140, loss: 0.03940620645880699
step: 150, loss: 0.02666008286178112
step: 160, loss: 0.09371928125619888
step: 170, loss: 0.06975086778402328
step: 180, loss: 0.011552304960787296
step: 190, loss: 0.05114034563302994
step: 200, loss: 0.08900085091590881
step: 210, loss: 0.016244860365986824
step: 220, loss: 0.032103873789310455
step: 230, loss: 0.08830184489488602
step: 240, loss: 0.004399583209306002
step: 250, loss: 0.008173773065209389
step: 260, loss: 0.002369506284594536
step: 270, loss: 0.03399704396724701
step: 280, loss: 0.042111705988645554
step: 290, loss: 0.00320152728818357
step: 300, loss: 0.058813903480768204
step: 310, loss: 0.05893571674823761
step: 320, loss: 0.02855575457215309
step: 330, loss: 0.019325673580169678
step: 340, loss: 0.0687517449259758
step: 350, loss: 0.05294649675488472
step: 360, loss: 0.08229723572731018
step: 370, loss: 0.15027602016925812
step: 380, loss: 0.0001620255206944421
step: 390, loss: 0.011062229983508587
step: 400, loss: 0.004279947839677334
step: 410, loss: 0.02524617686867714
step: 420, loss: 0.017477186396718025
epoch 11: dev_f1=0.9921259842519685, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.010525861755013466
step: 10, loss: 0.06778343766927719
step: 20, loss: 0.06987900286912918
step: 30, loss: 0.0414850115776062
step: 40, loss: 0.03911109268665314
step: 50, loss: 0.0035606054589152336
step: 60, loss: 0.0216990914195776
step: 70, loss: 0.006369140464812517
step: 80, loss: 0.0045503308065235615
step: 90, loss: 0.00801047682762146
step: 100, loss: 0.025449378415942192
step: 110, loss: 0.020839501172304153
step: 120, loss: 0.02387372963130474
step: 130, loss: 0.009377595037221909
step: 140, loss: 0.0344749391078949
step: 150, loss: 0.06089426577091217
step: 160, loss: 0.03199603036046028
step: 170, loss: 0.022546591237187386
step: 180, loss: 0.10257712751626968
step: 190, loss: 0.01881304755806923
step: 200, loss: 0.06437043100595474
step: 210, loss: 0.042078837752342224
step: 220, loss: 0.033797021955251694
step: 230, loss: 0.03755804896354675
step: 240, loss: 0.09085411578416824
step: 250, loss: 0.04120345786213875
step: 260, loss: 0.028104985132813454
step: 270, loss: 0.09464557468891144
step: 280, loss: 0.048085011541843414
step: 290, loss: 0.02210375666618347
step: 300, loss: 0.11734743416309357
step: 310, loss: 0.008029626682400703
step: 320, loss: 0.039296913892030716
step: 330, loss: 0.021806059405207634
step: 340, loss: 0.08325792849063873
step: 350, loss: 0.038358647376298904
step: 360, loss: 0.004368950612843037
step: 370, loss: 0.02600911259651184
step: 380, loss: 0.02556437812745571
step: 390, loss: 0.0003745389694813639
step: 400, loss: 0.02609572373330593
step: 410, loss: 0.022081052884459496
step: 420, loss: 0.051772765815258026
epoch 12: dev_f1=0.9898305084745763, f1=0.9853107344632768, best_f1=0.9854096520763187
step: 0, loss: 0.019146647304296494
step: 10, loss: 0.00016485674132127315
step: 20, loss: 0.02832156978547573
step: 30, loss: 0.044874146580696106
step: 40, loss: 0.06534554064273834
step: 50, loss: 0.035836804658174515
step: 60, loss: 0.01959710381925106
step: 70, loss: 0.02141702175140381
step: 80, loss: 0.0006741023389622569
step: 90, loss: 0.01669316366314888
step: 100, loss: 0.005332360044121742
step: 110, loss: 4.127089414396323e-05
step: 120, loss: 0.015639711171388626
step: 130, loss: 0.03586839139461517
step: 140, loss: 0.0057264347560703754
step: 150, loss: 6.468751962529495e-05
step: 160, loss: 0.044370345771312714
step: 170, loss: 0.026147641241550446
step: 180, loss: 0.021873261779546738
step: 190, loss: 0.00171753391623497
step: 200, loss: 0.03572380542755127
step: 210, loss: 0.0693177580833435
step: 220, loss: 0.03727297484874725
step: 230, loss: 0.02898649498820305
step: 240, loss: 0.03267616033554077
step: 250, loss: 0.05443171411752701
step: 260, loss: 0.033866047859191895
step: 270, loss: 0.20381389558315277
step: 280, loss: 0.006843759678304195
step: 290, loss: 0.005886985920369625
step: 300, loss: 0.11102493107318878
step: 310, loss: 0.046349383890628815
step: 320, loss: 0.0007534784963354468
step: 330, loss: 0.01672147773206234
step: 340, loss: 0.0815369114279747
step: 350, loss: 0.037304893136024475
step: 360, loss: 0.0002878359518945217
step: 370, loss: 0.08835700154304504
step: 380, loss: 0.025585757568478584
step: 390, loss: 0.02076520025730133
step: 400, loss: 0.0011158324778079987
step: 410, loss: 0.0019833447877317667
step: 420, loss: 0.0010973050957545638
epoch 13: dev_f1=0.992108229988726, f1=0.984304932735426, best_f1=0.9854096520763187
step: 0, loss: 3.355842636665329e-05
step: 10, loss: 0.0009890657383948565
step: 20, loss: 0.01743619330227375
step: 30, loss: 0.0001825213257689029
step: 40, loss: 0.024216026067733765
step: 50, loss: 0.0689225047826767
step: 60, loss: 0.014215904287993908
step: 70, loss: 0.06883866339921951
step: 80, loss: 0.07458173483610153
step: 90, loss: 0.03223365545272827
step: 100, loss: 0.044159747660160065
step: 110, loss: 0.0250360369682312
step: 120, loss: 0.020853610709309578
step: 130, loss: 0.026783524081110954
step: 140, loss: 0.05915652960538864
step: 150, loss: 0.08022920042276382
step: 160, loss: 0.009932628832757473
step: 170, loss: 0.024697555229067802
step: 180, loss: 0.0005642246687784791
step: 190, loss: 0.00037513775168918073
step: 200, loss: 0.041156694293022156
step: 210, loss: 0.0001352747349301353
step: 220, loss: 0.00011023232946172357
step: 230, loss: 0.06704453378915787
step: 240, loss: 0.07055813074111938
step: 250, loss: 0.021158326417207718
step: 260, loss: 1.8461572835803963e-05
step: 270, loss: 0.00011735183943528682
step: 280, loss: 8.477583469357342e-05
step: 290, loss: 0.02824043668806553
step: 300, loss: 0.03427495062351227
step: 310, loss: 0.027361806482076645
step: 320, loss: 5.379292997531593e-05
step: 330, loss: 0.006504639983177185
step: 340, loss: 0.1818050891160965
step: 350, loss: 0.016375282779335976
step: 360, loss: 0.02603553794324398
step: 370, loss: 0.023838134482502937
step: 380, loss: 0.00028539213235490024
step: 390, loss: 5.9710033383453265e-05
step: 400, loss: 0.05937248468399048
step: 410, loss: 0.002915274817496538
step: 420, loss: 0.10131686180830002
epoch 14: dev_f1=0.9910112359550561, f1=0.9832026875699889, best_f1=0.9854096520763187
step: 0, loss: 0.038665566593408585
step: 10, loss: 0.0002086241147480905
step: 20, loss: 0.03355272114276886
step: 30, loss: 0.0369047150015831
step: 40, loss: 0.006818328518420458
step: 50, loss: 0.030746472999453545
step: 60, loss: 0.007724228780716658
step: 70, loss: 0.0420154370367527
step: 80, loss: 0.0006106218206696212
step: 90, loss: 0.0001464613451389596
step: 100, loss: 0.07725314795970917
step: 110, loss: 0.024227935820817947
step: 120, loss: 0.010228109546005726
step: 130, loss: 0.042330287396907806
step: 140, loss: 0.02119886875152588
step: 150, loss: 0.04673255607485771
step: 160, loss: 0.05768141150474548
step: 170, loss: 5.5186152167152613e-05
step: 180, loss: 0.029715856537222862
step: 190, loss: 0.02267993427813053
step: 200, loss: 0.02291582152247429
step: 210, loss: 0.02334740199148655
step: 220, loss: 0.046085864305496216
step: 230, loss: 0.0037730704061686993
step: 240, loss: 0.02316189743578434
step: 250, loss: 0.020772971212863922
step: 260, loss: 0.019135097041726112
step: 270, loss: 0.0013406905345618725
step: 280, loss: 0.04259389266371727
step: 290, loss: 0.02192571572959423
step: 300, loss: 0.0413612425327301
step: 310, loss: 0.019507452845573425
step: 320, loss: 0.023509573191404343
step: 330, loss: 0.019061602652072906
step: 340, loss: 0.03349823132157326
step: 350, loss: 0.04412856325507164
step: 360, loss: 0.039676275104284286
step: 370, loss: 0.05262862145900726
step: 380, loss: 0.0024785271380096674
step: 390, loss: 0.00010687417670851573
step: 400, loss: 0.03069504350423813
step: 410, loss: 0.018889380618929863
step: 420, loss: 0.012316765263676643
epoch 15: dev_f1=0.9909706546275394, f1=0.9832026875699889, best_f1=0.9854096520763187
step: 0, loss: 0.020875126123428345
step: 10, loss: 0.00011804966197814792
step: 20, loss: 0.04198632016777992
step: 30, loss: 0.00010257038229610771
step: 40, loss: 0.007554336916655302
step: 50, loss: 0.05161859095096588
step: 60, loss: 0.07224166393280029
step: 70, loss: 0.11718814074993134
step: 80, loss: 0.042935021221637726
step: 90, loss: 0.07904991507530212
step: 100, loss: 0.030230766162276268
step: 110, loss: 0.0030406543519347906
step: 120, loss: 0.0240118820220232
step: 130, loss: 0.0008624537149444222
step: 140, loss: 0.022764533758163452
step: 150, loss: 0.013858649879693985
step: 160, loss: 0.00012398783292155713
step: 170, loss: 0.00015802493726368994
step: 180, loss: 0.00030029541812837124
step: 190, loss: 0.00010513576125958934
step: 200, loss: 0.024758387356996536
step: 210, loss: 0.049957554787397385
step: 220, loss: 0.04543763026595116
step: 230, loss: 0.00014862307580187917
step: 240, loss: 0.00012710847659036517
step: 250, loss: 0.04292439669370651
step: 260, loss: 0.05048031732439995
step: 270, loss: 0.04278760775923729
step: 280, loss: 0.027671964839100838
step: 290, loss: 0.020288018509745598
step: 300, loss: 0.03500998020172119
step: 310, loss: 0.0463283509016037
step: 320, loss: 0.00017179026326630265
step: 330, loss: 0.00010674608347471803
step: 340, loss: 0.021771129220724106
step: 350, loss: 0.025556933134794235
step: 360, loss: 0.00010659638792276382
step: 370, loss: 0.019587133079767227
step: 380, loss: 0.023281434550881386
step: 390, loss: 0.01971365697681904
step: 400, loss: 0.025619808584451675
step: 410, loss: 0.024975547567009926
step: 420, loss: 0.013998416252434254
epoch 16: dev_f1=0.992108229988726, f1=0.9831649831649831, best_f1=0.9854096520763187
step: 0, loss: 0.039970166981220245
step: 10, loss: 0.00018762941181194037
step: 20, loss: 0.050011761486530304
step: 30, loss: 0.044667746871709824
step: 40, loss: 0.18485212326049805
step: 50, loss: 0.04507838934659958
step: 60, loss: 0.00028273864882066846
step: 70, loss: 0.09429250657558441
step: 80, loss: 0.05396897718310356
step: 90, loss: 0.00016235734801739454
step: 100, loss: 0.0008976325625553727
step: 110, loss: 3.419600398046896e-05
step: 120, loss: 0.04419209808111191
step: 130, loss: 0.021749531850218773
step: 140, loss: 0.046849071979522705
step: 150, loss: 0.020537134259939194
step: 160, loss: 0.04154539480805397
step: 170, loss: 0.019906949251890182
step: 180, loss: 0.001138006802648306
step: 190, loss: 0.019741764292120934
step: 200, loss: 0.041225627064704895
step: 210, loss: 0.019919363781809807
step: 220, loss: 0.025439247488975525
step: 230, loss: 0.02158983238041401
step: 240, loss: 0.055284302681684494
step: 250, loss: 0.06669283658266068
step: 260, loss: 0.02349126897752285
step: 270, loss: 0.025378916412591934
step: 280, loss: 0.0175851471722126
step: 290, loss: 8.972635259851813e-05
step: 300, loss: 0.00023803315707482398
step: 310, loss: 0.03779950365424156
step: 320, loss: 0.0009602149366401136
step: 330, loss: 0.014506391249597073
step: 340, loss: 0.03280055895447731
step: 350, loss: 0.02071532793343067
step: 360, loss: 0.06211717054247856
step: 370, loss: 3.772586933337152e-05
step: 380, loss: 0.07812712341547012
step: 390, loss: 0.00013055720773991197
step: 400, loss: 0.09346624463796616
step: 410, loss: 0.02215946465730667
step: 420, loss: 0.022708192467689514
epoch 17: dev_f1=0.992108229988726, f1=0.984304932735426, best_f1=0.9854096520763187
step: 0, loss: 0.0002044174907496199
step: 10, loss: 0.03590844199061394
step: 20, loss: 0.043432142585515976
step: 30, loss: 0.0021719117648899555
step: 40, loss: 0.027366656810045242
step: 50, loss: 0.023951411247253418
step: 60, loss: 0.0004887999384663999
step: 70, loss: 0.02472681738436222
step: 80, loss: 0.04135662689805031
step: 90, loss: 0.06555003672838211
step: 100, loss: 0.040769848972558975
step: 110, loss: 0.06440207362174988
step: 120, loss: 0.02260172925889492
step: 130, loss: 0.042772553861141205
step: 140, loss: 0.0007296703406609595
step: 150, loss: 0.021960748359560966
step: 160, loss: 4.303743480704725e-05
step: 170, loss: 6.605459930142388e-05
step: 180, loss: 0.023405954241752625
step: 190, loss: 0.025362500920891762
step: 200, loss: 0.021013168618083
step: 210, loss: 0.022227328270673752
step: 220, loss: 0.06060005724430084
step: 230, loss: 0.040909867733716965
step: 240, loss: 0.02346605248749256
step: 250, loss: 0.015871204435825348
step: 260, loss: 0.02853742055594921
step: 270, loss: 0.04557303711771965
step: 280, loss: 0.03896106407046318
step: 290, loss: 0.0486043356359005
step: 300, loss: 0.03975178301334381
step: 310, loss: 9.35531425056979e-05
step: 320, loss: 0.022280452772974968
step: 330, loss: 0.02333865687251091
step: 340, loss: 8.200074807973579e-05
step: 350, loss: 0.04534129425883293
step: 360, loss: 0.019638922065496445
step: 370, loss: 0.022526582702994347
step: 380, loss: 0.021405301988124847
step: 390, loss: 0.021508878096938133
step: 400, loss: 0.04022311046719551
step: 410, loss: 0.020509861409664154
step: 420, loss: 0.0004226767923682928
epoch 18: dev_f1=0.992108229988726, f1=0.984304932735426, best_f1=0.9854096520763187
step: 0, loss: 0.048425789922475815
step: 10, loss: 0.062184762209653854
step: 20, loss: 0.050117384642362595
step: 30, loss: 0.02074485644698143
step: 40, loss: 0.024252787232398987
step: 50, loss: 0.08172669261693954
step: 60, loss: 0.027823567390441895
step: 70, loss: 0.00010684879089239985
step: 80, loss: 0.02052164636552334
step: 90, loss: 0.0005253828130662441
step: 100, loss: 0.0001300600270042196
step: 110, loss: 0.021147361025214195
step: 120, loss: 0.026679836213588715
step: 130, loss: 6.299184315139428e-05
step: 140, loss: 0.05813215672969818
step: 150, loss: 0.023009827360510826
step: 160, loss: 0.0014472982147708535
step: 170, loss: 3.126633237116039e-05
step: 180, loss: 0.045111071318387985
step: 190, loss: 0.0001722397282719612
step: 200, loss: 0.04027578979730606
step: 210, loss: 0.032905708998441696
step: 220, loss: 0.0013396010035648942
step: 230, loss: 5.058895476395264e-05
step: 240, loss: 5.754144149250351e-05
step: 250, loss: 0.023429017513990402
step: 260, loss: 0.04015819728374481
step: 270, loss: 8.785342652117833e-05
step: 280, loss: 7.592735346406698e-05
step: 290, loss: 0.00024645423400215805
step: 300, loss: 0.025768738240003586
step: 310, loss: 0.1197245791554451
step: 320, loss: 0.027548762038350105
step: 330, loss: 0.06321341544389725
step: 340, loss: 0.0003590344567783177
step: 350, loss: 0.0001539198710815981
step: 360, loss: 0.04772426187992096
step: 370, loss: 0.0659804716706276
step: 380, loss: 0.04186231642961502
step: 390, loss: 1.4297383131633978e-05
step: 400, loss: 0.02396007813513279
step: 410, loss: 0.048881612718105316
step: 420, loss: 0.08393120765686035
epoch 19: dev_f1=0.992108229988726, f1=0.984304932735426, best_f1=0.9854096520763187
step: 0, loss: 0.061470627784729004
step: 10, loss: 0.0504252165555954
step: 20, loss: 0.0251887496560812
step: 30, loss: 0.00010597613436402753
step: 40, loss: 0.022821353748440742
step: 50, loss: 0.00020169548224657774
step: 60, loss: 0.03713618591427803
step: 70, loss: 0.04208549112081528
step: 80, loss: 0.019414285197854042
step: 90, loss: 0.01738595962524414
step: 100, loss: 0.00013878644676879048
step: 110, loss: 0.05980704724788666
step: 120, loss: 0.04028340056538582
step: 130, loss: 0.022480836138129234
step: 140, loss: 0.019124770537018776
step: 150, loss: 0.04648614674806595
step: 160, loss: 0.04547778144478798
step: 170, loss: 0.022509610280394554
step: 180, loss: 0.040489502251148224
step: 190, loss: 0.04355392977595329
step: 200, loss: 0.045568615198135376
step: 210, loss: 2.8983329684706405e-05
step: 220, loss: 0.05976926162838936
step: 230, loss: 0.01995784230530262
step: 240, loss: 0.05784373730421066
step: 250, loss: 0.01575186289846897
step: 260, loss: 4.212073690723628e-05
step: 270, loss: 0.05388006567955017
step: 280, loss: 0.04295969009399414
step: 290, loss: 0.028068576008081436
step: 300, loss: 2.007371949730441e-05
step: 310, loss: 0.01885906234383583
step: 320, loss: 0.026984283700585365
step: 330, loss: 0.020109916105866432
step: 340, loss: 0.06142802909016609
step: 350, loss: 0.0005527872708626091
step: 360, loss: 0.018900658935308456
step: 370, loss: 3.646956611191854e-05
step: 380, loss: 0.046308450400829315
step: 390, loss: 0.042943209409713745
step: 400, loss: 0.021756697446107864
step: 410, loss: 0.04703698679804802
step: 420, loss: 0.041406504809856415
epoch 20: dev_f1=0.992108229988726, f1=0.984304932735426, best_f1=0.9854096520763187
