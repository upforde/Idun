cuda
Device: cuda
step: 0, loss: 0.5866603851318359
step: 10, loss: 0.380427747964859
step: 20, loss: 0.22641849517822266
step: 30, loss: 0.2837687134742737
step: 40, loss: 0.09966559708118439
step: 50, loss: 0.12576238811016083
step: 60, loss: 0.14729319512844086
step: 70, loss: 0.1358518749475479
step: 80, loss: 0.18675507605075836
step: 90, loss: 0.06309682875871658
step: 100, loss: 0.06523102521896362
step: 110, loss: 0.13966001570224762
step: 120, loss: 0.05736913904547691
step: 130, loss: 0.11717071384191513
step: 140, loss: 0.28248831629753113
step: 150, loss: 0.020438237115740776
step: 160, loss: 0.09859195351600647
step: 170, loss: 0.08318102359771729
step: 180, loss: 0.01344767864793539
step: 190, loss: 0.2805100381374359
step: 200, loss: 0.05667547136545181
step: 210, loss: 0.18788789212703705
step: 220, loss: 0.0646049752831459
step: 230, loss: 0.03737852722406387
step: 240, loss: 0.004036483820527792
step: 250, loss: 0.0541934035718441
step: 260, loss: 0.23290619254112244
step: 270, loss: 0.03198476508259773
step: 280, loss: 0.09982233494520187
step: 290, loss: 0.0673980787396431
step: 300, loss: 0.12343886494636536
step: 310, loss: 0.029638594016432762
step: 320, loss: 0.09218061715364456
step: 330, loss: 0.03621052950620651
step: 340, loss: 0.09099406003952026
step: 350, loss: 0.01805220916867256
step: 360, loss: 0.08845199644565582
step: 370, loss: 0.07611937075853348
step: 380, loss: 0.014628222212195396
step: 390, loss: 0.0633096769452095
step: 400, loss: 0.01721346750855446
step: 410, loss: 0.07423659414052963
step: 420, loss: 0.08390330523252487
epoch 1: dev_f1=0.990990990990991, f1=0.9853768278965129, best_f1=0.9853768278965129
step: 0, loss: 0.037500448524951935
step: 10, loss: 0.03143621236085892
step: 20, loss: 0.03447441756725311
step: 30, loss: 0.055166617035865784
step: 40, loss: 0.006451440509408712
step: 50, loss: 0.025776037946343422
step: 60, loss: 0.0596788115799427
step: 70, loss: 0.008513009175658226
step: 80, loss: 0.07193899154663086
step: 90, loss: 0.06626564264297485
step: 100, loss: 0.040048278868198395
step: 110, loss: 0.011610791087150574
step: 120, loss: 0.03333231434226036
step: 130, loss: 0.016761017963290215
step: 140, loss: 0.15719269216060638
step: 150, loss: 0.12900976836681366
step: 160, loss: 0.043978240340948105
step: 170, loss: 0.08506206423044205
step: 180, loss: 0.10970637202262878
step: 190, loss: 0.11062387377023697
step: 200, loss: 0.021443620324134827
step: 210, loss: 0.06937970966100693
step: 220, loss: 0.008510270155966282
step: 230, loss: 0.013850180432200432
step: 240, loss: 0.09982673823833466
step: 250, loss: 0.06326527148485184
step: 260, loss: 0.09287898987531662
step: 270, loss: 0.10661854594945908
step: 280, loss: 0.09496123343706131
step: 290, loss: 0.16068215668201447
step: 300, loss: 0.173722505569458
step: 310, loss: 0.048042889684438705
step: 320, loss: 0.06733086705207825
step: 330, loss: 0.00025794532848522067
step: 340, loss: 0.08812202513217926
step: 350, loss: 0.1138654574751854
step: 360, loss: 0.11556659638881683
step: 370, loss: 0.13205580413341522
step: 380, loss: 0.04408219829201698
step: 390, loss: 0.017158033326268196
step: 400, loss: 0.030508320778608322
step: 410, loss: 0.034966081380844116
step: 420, loss: 0.09108750522136688
epoch 2: dev_f1=0.9714285714285714, f1=0.9561403508771931, best_f1=0.9853768278965129
step: 0, loss: 0.028032269328832626
step: 10, loss: 0.08893058449029922
step: 20, loss: 0.010625883005559444
step: 30, loss: 0.09256559610366821
step: 40, loss: 0.06917551159858704
step: 50, loss: 0.041670601814985275
step: 60, loss: 0.016881832852959633
step: 70, loss: 0.03634681552648544
step: 80, loss: 0.011689853854477406
step: 90, loss: 0.11277516186237335
step: 100, loss: 0.012692372314631939
step: 110, loss: 0.22156073153018951
step: 120, loss: 0.033730532974004745
step: 130, loss: 0.08988352864980698
step: 140, loss: 0.07052182406187057
step: 150, loss: 0.13248297572135925
step: 160, loss: 0.056577280163764954
step: 170, loss: 0.022423144429922104
step: 180, loss: 0.0872354581952095
step: 190, loss: 0.008184460923075676
step: 200, loss: 0.13226193189620972
step: 210, loss: 0.03221781924366951
step: 220, loss: 0.16443629562854767
step: 230, loss: 0.007786905393004417
step: 240, loss: 0.08218048512935638
step: 250, loss: 0.07487395405769348
step: 260, loss: 0.09522141516208649
step: 270, loss: 0.05128410831093788
step: 280, loss: 0.0394439734518528
step: 290, loss: 0.049733784049749374
step: 300, loss: 0.06008657440543175
step: 310, loss: 0.10656680166721344
step: 320, loss: 0.007672654464840889
step: 330, loss: 0.004499755334109068
step: 340, loss: 0.006105782929807901
step: 350, loss: 0.188645139336586
step: 360, loss: 0.07543941587209702
step: 370, loss: 0.09936989843845367
step: 380, loss: 0.03049531951546669
step: 390, loss: 0.0246169101446867
step: 400, loss: 0.07349438220262527
step: 410, loss: 0.08874108642339706
step: 420, loss: 0.03427903726696968
epoch 3: dev_f1=0.9887892376681614, f1=0.9786276715410572, best_f1=0.9853768278965129
step: 0, loss: 0.04225775599479675
step: 10, loss: 0.05167132243514061
step: 20, loss: 0.036611735820770264
step: 30, loss: 0.04117705300450325
step: 40, loss: 0.1829742044210434
step: 50, loss: 0.08429188281297684
step: 60, loss: 0.23249076306819916
step: 70, loss: 0.047540176659822464
step: 80, loss: 0.005656919442117214
step: 90, loss: 0.008471657522022724
step: 100, loss: 0.07682164758443832
step: 110, loss: 0.06584646552801132
step: 120, loss: 0.07007499039173126
step: 130, loss: 0.00425270339474082
step: 140, loss: 0.08133352547883987
step: 150, loss: 0.00038232721271924675
step: 160, loss: 0.024570981040596962
step: 170, loss: 0.023671584203839302
step: 180, loss: 0.0843815878033638
step: 190, loss: 0.15527883172035217
step: 200, loss: 0.007901725359261036
step: 210, loss: 0.05290761590003967
step: 220, loss: 0.02923186682164669
step: 230, loss: 0.01373338047415018
step: 240, loss: 0.1604960560798645
step: 250, loss: 0.0076028271578252316
step: 260, loss: 0.04418380185961723
step: 270, loss: 0.04624585807323456
step: 280, loss: 0.02662498876452446
step: 290, loss: 0.0344129242002964
step: 300, loss: 0.017038043588399887
step: 310, loss: 0.07260662317276001
step: 320, loss: 0.0183725543320179
step: 330, loss: 0.11226331442594528
step: 340, loss: 0.051037952303886414
step: 350, loss: 0.07681188732385635
step: 360, loss: 0.028246046975255013
step: 370, loss: 0.15799273550510406
step: 380, loss: 0.14357250928878784
step: 390, loss: 0.061269741505384445
step: 400, loss: 0.06746671348810196
step: 410, loss: 0.08225587755441666
step: 420, loss: 0.0057896641083061695
epoch 4: dev_f1=0.9898534385569334, f1=0.9841269841269841, best_f1=0.9853768278965129
step: 0, loss: 0.01266222819685936
step: 10, loss: 0.16064932942390442
step: 20, loss: 0.01067720539867878
step: 30, loss: 0.17621362209320068
step: 40, loss: 0.1292920857667923
step: 50, loss: 0.14305441081523895
step: 60, loss: 0.08579743653535843
step: 70, loss: 0.012782013043761253
step: 80, loss: 0.0814330205321312
step: 90, loss: 0.00016243966820184141
step: 100, loss: 0.013836420141160488
step: 110, loss: 0.07290749996900558
step: 120, loss: 3.875709080602974e-05
step: 130, loss: 0.18945752084255219
step: 140, loss: 0.10592439025640488
step: 150, loss: 0.16041448712348938
step: 160, loss: 0.022481048479676247
step: 170, loss: 0.12493057548999786
step: 180, loss: 0.013788423500955105
step: 190, loss: 0.13512487709522247
step: 200, loss: 0.08846308290958405
step: 210, loss: 0.020481057465076447
step: 220, loss: 0.0641484186053276
step: 230, loss: 0.03562396392226219
step: 240, loss: 0.01076914370059967
step: 250, loss: 0.014100462198257446
step: 260, loss: 0.03331707417964935
step: 270, loss: 0.07328099757432938
step: 280, loss: 0.015988031402230263
step: 290, loss: 0.07090703397989273
step: 300, loss: 0.06823468953371048
step: 310, loss: 0.028860023245215416
step: 320, loss: 9.176509774988517e-05
step: 330, loss: 0.3327639102935791
step: 340, loss: 0.08188284188508987
step: 350, loss: 0.1473061591386795
step: 360, loss: 0.011787418276071548
step: 370, loss: 0.1291740983724594
step: 380, loss: 0.06718340516090393
step: 390, loss: 0.08141135424375534
step: 400, loss: 0.031767573207616806
step: 410, loss: 0.0566701702773571
step: 420, loss: 0.18080264329910278
epoch 5: dev_f1=0.9932735426008968, f1=0.9800884955752212, best_f1=0.9800884955752212
step: 0, loss: 0.08577854186296463
step: 10, loss: 0.01881946623325348
step: 20, loss: 0.020043306052684784
step: 30, loss: 0.09005847573280334
step: 40, loss: 0.007898223586380482
step: 50, loss: 0.08097093552350998
step: 60, loss: 0.015106534585356712
step: 70, loss: 0.18040254712104797
step: 80, loss: 0.006662310101091862
step: 90, loss: 0.03067852556705475
step: 100, loss: 0.04957440495491028
step: 110, loss: 0.09315980225801468
step: 120, loss: 0.08710175007581711
step: 130, loss: 0.017679374665021896
step: 140, loss: 0.14731164276599884
step: 150, loss: 0.01305711455643177
step: 160, loss: 0.028492078185081482
step: 170, loss: 0.13857878744602203
step: 180, loss: 0.008156338706612587
step: 190, loss: 0.005306936800479889
step: 200, loss: 0.021636314690113068
step: 210, loss: 0.003801490180194378
step: 220, loss: 0.21218138933181763
step: 230, loss: 0.019023098051548004
step: 240, loss: 0.10906340181827545
step: 250, loss: 0.0630633682012558
step: 260, loss: 0.05693627521395683
step: 270, loss: 0.005669477395713329
step: 280, loss: 0.0742165595293045
step: 290, loss: 0.008487259037792683
step: 300, loss: 0.07581451535224915
step: 310, loss: 0.04428790137171745
step: 320, loss: 0.0764300599694252
step: 330, loss: 0.04775141552090645
step: 340, loss: 0.10087376832962036
step: 350, loss: 0.023123737424612045
step: 360, loss: 0.06657548248767853
step: 370, loss: 0.005575569812208414
step: 380, loss: 0.023447729647159576
step: 390, loss: 0.12413544207811356
step: 400, loss: 0.018102504312992096
step: 410, loss: 0.01995524764060974
step: 420, loss: 0.027865076437592506
epoch 6: dev_f1=0.9899216125419933, f1=0.9810055865921787, best_f1=0.9800884955752212
step: 0, loss: 0.05798599123954773
step: 10, loss: 0.014894385822117329
step: 20, loss: 0.08299893885850906
step: 30, loss: 0.08028087764978409
step: 40, loss: 0.010319499298930168
step: 50, loss: 0.10166934877634048
step: 60, loss: 0.11402022838592529
step: 70, loss: 0.11953690648078918
step: 80, loss: 0.005115187726914883
step: 90, loss: 0.1272893100976944
step: 100, loss: 0.03696415200829506
step: 110, loss: 0.04596521332859993
step: 120, loss: 0.001959631685167551
step: 130, loss: 0.03195280581712723
step: 140, loss: 0.004332168959081173
step: 150, loss: 0.015190289355814457
step: 160, loss: 0.00855153240263462
step: 170, loss: 0.07968843728303909
step: 180, loss: 0.09679529070854187
step: 190, loss: 0.008374917320907116
step: 200, loss: 0.16019488871097565
step: 210, loss: 0.12330232560634613
step: 220, loss: 0.07205682247877121
step: 230, loss: 0.0695895403623581
step: 240, loss: 0.12642769515514374
step: 250, loss: 0.14701518416404724
step: 260, loss: 0.01971890777349472
step: 270, loss: 0.015848156064748764
step: 280, loss: 0.12010543048381805
step: 290, loss: 0.007870086468756199
step: 300, loss: 0.10323204100131989
step: 310, loss: 0.06498520076274872
step: 320, loss: 0.08408450335264206
step: 330, loss: 0.005982628092169762
step: 340, loss: 0.051819778978824615
step: 350, loss: 0.0807110145688057
step: 360, loss: 0.010715465992689133
step: 370, loss: 0.01630401983857155
step: 380, loss: 0.01223771646618843
step: 390, loss: 0.019438546150922775
step: 400, loss: 0.06353261321783066
step: 410, loss: 0.11289002746343613
step: 420, loss: 0.03519406169652939
epoch 7: dev_f1=0.9910313901345291, f1=0.9843400447427293, best_f1=0.9800884955752212
step: 0, loss: 0.06884244829416275
step: 10, loss: 0.2650921940803528
step: 20, loss: 0.02706611156463623
step: 30, loss: 0.031143708154559135
step: 40, loss: 0.08283351361751556
step: 50, loss: 0.08654404431581497
step: 60, loss: 0.12519142031669617
step: 70, loss: 0.044477034360170364
step: 80, loss: 0.027752919122576714
step: 90, loss: 0.05946185812354088
step: 100, loss: 0.0003033453249372542
step: 110, loss: 0.16354160010814667
step: 120, loss: 0.06589425355195999
step: 130, loss: 0.018802322447299957
step: 140, loss: 0.023801501840353012
step: 150, loss: 0.001319721806794405
step: 160, loss: 0.009704167023301125
step: 170, loss: 0.06145787239074707
step: 180, loss: 0.06797831505537033
step: 190, loss: 0.05654958263039589
step: 200, loss: 0.009095711633563042
step: 210, loss: 0.13564687967300415
step: 220, loss: 0.02056194841861725
step: 230, loss: 0.14326709508895874
step: 240, loss: 0.02049117349088192
step: 250, loss: 0.0697939395904541
step: 260, loss: 0.09316127002239227
step: 270, loss: 0.04862504452466965
step: 280, loss: 0.00385420024394989
step: 290, loss: 0.0644872859120369
step: 300, loss: 0.003356281900778413
step: 310, loss: 0.09722410142421722
step: 320, loss: 0.09209008514881134
step: 330, loss: 0.0019853292033076286
step: 340, loss: 0.08995868265628815
step: 350, loss: 0.03670347481966019
step: 360, loss: 0.028808461502194405
step: 370, loss: 0.0761728584766388
step: 380, loss: 0.055686697363853455
step: 390, loss: 0.05868653580546379
step: 400, loss: 0.011271841824054718
step: 410, loss: 0.004602691624313593
step: 420, loss: 0.002122534206137061
epoch 8: dev_f1=0.9910313901345291, f1=0.9832402234636871, best_f1=0.9800884955752212
step: 0, loss: 0.07816356420516968
step: 10, loss: 0.005487233400344849
step: 20, loss: 0.00017922476399689913
step: 30, loss: 0.01445707492530346
step: 40, loss: 0.08037880063056946
step: 50, loss: 0.007175583858042955
step: 60, loss: 6.911616947036237e-05
step: 70, loss: 0.061308637261390686
step: 80, loss: 0.08876610547304153
step: 90, loss: 0.03347543627023697
step: 100, loss: 0.025389140471816063
step: 110, loss: 0.009587465785443783
step: 120, loss: 0.01760500855743885
step: 130, loss: 0.0975312665104866
step: 140, loss: 0.21838971972465515
step: 150, loss: 0.049024175852537155
step: 160, loss: 0.046548567712306976
step: 170, loss: 0.024722618982195854
step: 180, loss: 0.005317064467817545
step: 190, loss: 0.15963265299797058
step: 200, loss: 0.0169448871165514
step: 210, loss: 0.01867397129535675
step: 220, loss: 0.027026429772377014
step: 230, loss: 0.14338357746601105
step: 240, loss: 0.07589273154735565
step: 250, loss: 0.06836313009262085
step: 260, loss: 0.011383045464754105
step: 270, loss: 0.007789820898324251
step: 280, loss: 0.03965063393115997
step: 290, loss: 0.06386226415634155
step: 300, loss: 0.08782889693975449
step: 310, loss: 0.018297646194696426
step: 320, loss: 0.006881347857415676
step: 330, loss: 0.014689646661281586
step: 340, loss: 0.015054985880851746
step: 350, loss: 0.03727976232767105
step: 360, loss: 0.04065670818090439
step: 370, loss: 0.12052386999130249
step: 380, loss: 0.1387094110250473
step: 390, loss: 0.010484710335731506
step: 400, loss: 0.007132868282496929
step: 410, loss: 0.05527767911553383
step: 420, loss: 0.04348393529653549
epoch 9: dev_f1=0.9921612541993281, f1=0.9821029082774049, best_f1=0.9800884955752212
step: 0, loss: 0.05648074671626091
step: 10, loss: 0.013342568650841713
step: 20, loss: 0.004107671789824963
step: 30, loss: 0.02499370463192463
step: 40, loss: 0.058366868644952774
step: 50, loss: 0.031330157071352005
step: 60, loss: 0.004537031054496765
step: 70, loss: 0.0552041120827198
step: 80, loss: 0.008069243282079697
step: 90, loss: 0.04285848140716553
step: 100, loss: 0.03393810614943504
step: 110, loss: 0.03485921397805214
step: 120, loss: 0.018587378785014153
step: 130, loss: 0.0002586349146440625
step: 140, loss: 0.02847171388566494
step: 150, loss: 0.03314383327960968
step: 160, loss: 0.025749437510967255
step: 170, loss: 0.07652024179697037
step: 180, loss: 0.07244245707988739
step: 190, loss: 0.034962788224220276
step: 200, loss: 0.007513089571148157
step: 210, loss: 0.0530497245490551
step: 220, loss: 0.03348521515727043
step: 230, loss: 0.035426653921604156
step: 240, loss: 0.02725614607334137
step: 250, loss: 0.009804069064557552
step: 260, loss: 0.041208647191524506
step: 270, loss: 0.010364368557929993
step: 280, loss: 0.09050533920526505
step: 290, loss: 0.04707421734929085
step: 300, loss: 0.004218969028443098
step: 310, loss: 0.01675584726035595
step: 320, loss: 0.009882726706564426
step: 330, loss: 0.013372461311519146
step: 340, loss: 0.12299323081970215
step: 350, loss: 0.07850483059883118
step: 360, loss: 0.022074561566114426
step: 370, loss: 0.07547269761562347
step: 380, loss: 0.06973784416913986
step: 390, loss: 0.02571353316307068
step: 400, loss: 0.10917841643095016
step: 410, loss: 0.06185600534081459
step: 420, loss: 0.015108279883861542
epoch 10: dev_f1=0.9898989898989898, f1=0.9876543209876544, best_f1=0.9800884955752212
step: 0, loss: 0.017290528863668442
step: 10, loss: 0.0019973597954958677
step: 20, loss: 0.00030287139816209674
step: 30, loss: 0.000496842316351831
step: 40, loss: 4.0983584767673165e-05
step: 50, loss: 0.04215433448553085
step: 60, loss: 0.006248683203011751
step: 70, loss: 0.05465544015169144
step: 80, loss: 0.03878651559352875
step: 90, loss: 0.033000294119119644
step: 100, loss: 0.004457765258848667
step: 110, loss: 0.051727112382650375
step: 120, loss: 0.016303230077028275
step: 130, loss: 0.005335950758308172
step: 140, loss: 0.02669762633740902
step: 150, loss: 0.09403866529464722
step: 160, loss: 0.03207933157682419
step: 170, loss: 0.14085304737091064
step: 180, loss: 0.02824055589735508
step: 190, loss: 0.044400766491889954
step: 200, loss: 0.02181094139814377
step: 210, loss: 0.08285167813301086
step: 220, loss: 0.01656806282699108
step: 230, loss: 0.1062987819314003
step: 240, loss: 0.012924356386065483
step: 250, loss: 0.1573912799358368
step: 260, loss: 0.05882953479886055
step: 270, loss: 0.0016475524753332138
step: 280, loss: 0.01779308170080185
step: 290, loss: 0.0333501398563385
step: 300, loss: 0.020670071244239807
step: 310, loss: 0.062479808926582336
step: 320, loss: 0.00023617052647750825
step: 330, loss: 0.0009469082579016685
step: 340, loss: 0.01953040435910225
step: 350, loss: 0.030039120465517044
step: 360, loss: 0.012420961633324623
step: 370, loss: 0.02821691334247589
step: 380, loss: 0.036414481699466705
step: 390, loss: 0.20038765668869019
step: 400, loss: 0.044483482837677
step: 410, loss: 0.00919029675424099
step: 420, loss: 0.000374388211639598
epoch 11: dev_f1=0.9932279909706545, f1=0.9864253393665158, best_f1=0.9800884955752212
step: 0, loss: 0.06119314953684807
step: 10, loss: 0.03020818531513214
step: 20, loss: 0.04640911519527435
step: 30, loss: 0.051251672208309174
step: 40, loss: 0.01850144937634468
step: 50, loss: 0.0367007702589035
step: 60, loss: 0.0354214683175087
step: 70, loss: 0.025289637967944145
step: 80, loss: 0.10837620496749878
step: 90, loss: 0.032316144555807114
step: 100, loss: 0.02927759476006031
step: 110, loss: 0.0003114640712738037
step: 120, loss: 0.04129790887236595
step: 130, loss: 0.05575517937541008
step: 140, loss: 0.0008274532738141716
step: 150, loss: 2.304049485246651e-05
step: 160, loss: 0.05957220867276192
step: 170, loss: 0.017409546300768852
step: 180, loss: 0.024203656241297722
step: 190, loss: 0.024946637451648712
step: 200, loss: 0.0011358843185007572
step: 210, loss: 0.017656469717621803
step: 220, loss: 0.0012467517517507076
step: 230, loss: 0.052347540855407715
step: 240, loss: 0.1391507387161255
step: 250, loss: 0.05628405511379242
step: 260, loss: 0.0378093346953392
step: 270, loss: 0.005170992575585842
step: 280, loss: 0.09682664275169373
step: 290, loss: 0.04124976322054863
step: 300, loss: 0.040318649262189865
step: 310, loss: 0.0008509381441399455
step: 320, loss: 0.041154153645038605
step: 330, loss: 0.0020242827013134956
step: 340, loss: 0.0022276281379163265
step: 350, loss: 0.021502066403627396
step: 360, loss: 0.040783584117889404
step: 370, loss: 0.0002970996720250696
step: 380, loss: 0.08973363786935806
step: 390, loss: 0.013444284908473492
step: 400, loss: 0.07125133275985718
step: 410, loss: 0.11434938758611679
step: 420, loss: 0.03908846899867058
epoch 12: dev_f1=0.9921436588103255, f1=0.9810055865921787, best_f1=0.9800884955752212
step: 0, loss: 0.018912116065621376
step: 10, loss: 0.08393923938274384
step: 20, loss: 0.00044462556252256036
step: 30, loss: 0.007083399221301079
step: 40, loss: 0.002541744615882635
step: 50, loss: 0.020459450781345367
step: 60, loss: 0.04783647507429123
step: 70, loss: 0.0002453196793794632
step: 80, loss: 0.00029499910306185484
step: 90, loss: 0.01141486968845129
step: 100, loss: 0.0008967891917563975
step: 110, loss: 0.02297186851501465
step: 120, loss: 0.049215830862522125
step: 130, loss: 0.016413196921348572
step: 140, loss: 0.0019513109000399709
step: 150, loss: 0.026657717302441597
step: 160, loss: 0.03278142958879471
step: 170, loss: 0.020926643162965775
step: 180, loss: 0.0001383739581797272
step: 190, loss: 0.022586677223443985
step: 200, loss: 0.0005063266144134104
step: 210, loss: 0.019608667120337486
step: 220, loss: 0.013922315090894699
step: 230, loss: 0.060752276331186295
step: 240, loss: 0.04564106836915016
step: 250, loss: 0.0003113964630756527
step: 260, loss: 0.0004845430376008153
step: 270, loss: 0.00015312725736293942
step: 280, loss: 0.055514201521873474
step: 290, loss: 0.016093654558062553
step: 300, loss: 0.0005798760685138404
step: 310, loss: 0.04432560130953789
step: 320, loss: 0.019146714359521866
step: 330, loss: 0.02173667401075363
step: 340, loss: 0.054389141499996185
step: 350, loss: 0.04699653387069702
step: 360, loss: 0.058875422924757004
step: 370, loss: 0.023319441825151443
step: 380, loss: 0.0215432308614254
step: 390, loss: 0.06020111218094826
step: 400, loss: 0.008487884886562824
step: 410, loss: 0.03924930840730667
step: 420, loss: 0.01893002539873123
epoch 13: dev_f1=0.9887387387387387, f1=0.9820627802690582, best_f1=0.9800884955752212
step: 0, loss: 0.03712579235434532
step: 10, loss: 0.05016778036952019
step: 20, loss: 0.022855151444673538
step: 30, loss: 0.013006538152694702
step: 40, loss: 0.01921926625072956
step: 50, loss: 0.0032624229788780212
step: 60, loss: 0.0008099914412014186
step: 70, loss: 0.02266685478389263
step: 80, loss: 0.022168757393956184
step: 90, loss: 0.006731647532433271
step: 100, loss: 0.00011030213499907404
step: 110, loss: 0.02763538435101509
step: 120, loss: 0.00010273758380208164
step: 130, loss: 0.036397963762283325
step: 140, loss: 0.0002622842148412019
step: 150, loss: 0.04488058760762215
step: 160, loss: 0.000201670583919622
step: 170, loss: 0.04664711654186249
step: 180, loss: 0.04310988634824753
step: 190, loss: 0.05738908052444458
step: 200, loss: 6.493312685051933e-05
step: 210, loss: 0.0011979718692600727
step: 220, loss: 0.030758751556277275
step: 230, loss: 0.042863279581069946
step: 240, loss: 0.0007126359851099551
step: 250, loss: 0.0096070421859622
step: 260, loss: 0.012917902320623398
step: 270, loss: 0.028661295771598816
step: 280, loss: 0.00030866789165884256
step: 290, loss: 0.06864502280950546
step: 300, loss: 0.024810077622532845
step: 310, loss: 0.030201800167560577
step: 320, loss: 0.051994439214468
step: 330, loss: 0.0006751467008143663
step: 340, loss: 0.03743433207273483
step: 350, loss: 0.0006509433733299375
step: 360, loss: 0.000606866437010467
step: 370, loss: 0.024501925334334373
step: 380, loss: 0.08354464173316956
step: 390, loss: 0.06002479046583176
step: 400, loss: 0.05878710001707077
step: 410, loss: 0.0008526733727194369
step: 420, loss: 0.01976909302175045
epoch 14: dev_f1=0.9910112359550561, f1=0.9843400447427293, best_f1=0.9800884955752212
step: 0, loss: 0.04159439355134964
step: 10, loss: 0.009924381040036678
step: 20, loss: 0.02698754332959652
step: 30, loss: 3.999613909400068e-05
step: 40, loss: 0.00033824684214778244
step: 50, loss: 0.002307130955159664
step: 60, loss: 0.07784488797187805
step: 70, loss: 0.02099268138408661
step: 80, loss: 1.1689876373566221e-05
step: 90, loss: 0.022866100072860718
step: 100, loss: 0.022197533398866653
step: 110, loss: 0.02025419846177101
step: 120, loss: 0.01928812824189663
step: 130, loss: 0.0704663097858429
step: 140, loss: 8.918358798837289e-05
step: 150, loss: 0.03860192745923996
step: 160, loss: 0.04526891931891441
step: 170, loss: 0.016120675951242447
step: 180, loss: 0.005183511413633823
step: 190, loss: 0.050286490470170975
step: 200, loss: 0.013353172689676285
step: 210, loss: 6.0665508499369025e-05
step: 220, loss: 0.058812178671360016
step: 230, loss: 0.02429758571088314
step: 240, loss: 0.02029733546078205
step: 250, loss: 0.07080064713954926
step: 260, loss: 0.0001172168631455861
step: 270, loss: 0.0737147182226181
step: 280, loss: 0.0011685536010190845
step: 290, loss: 1.0326435585739091e-05
step: 300, loss: 0.050811123102903366
step: 310, loss: 0.021797526627779007
step: 320, loss: 0.0005214450648054481
step: 330, loss: 0.043416623026132584
step: 340, loss: 0.00023064104607328773
step: 350, loss: 0.04603785276412964
step: 360, loss: 0.023331057280302048
step: 370, loss: 0.033216800540685654
step: 380, loss: 0.0002792634186334908
step: 390, loss: 0.03882632777094841
step: 400, loss: 3.77003125322517e-05
step: 410, loss: 0.048589352518320084
step: 420, loss: 0.01885301060974598
epoch 15: dev_f1=0.9887133182844244, f1=0.9808773903262092, best_f1=0.9800884955752212
step: 0, loss: 0.03939758613705635
step: 10, loss: 0.023417608812451363
step: 20, loss: 0.03498423844575882
step: 30, loss: 0.018520893529057503
step: 40, loss: 0.01840577833354473
step: 50, loss: 0.015805894508957863
step: 60, loss: 7.485081005143002e-05
step: 70, loss: 0.020678341388702393
step: 80, loss: 0.02019527554512024
step: 90, loss: 7.01868993928656e-05
step: 100, loss: 0.00037910291575826705
step: 110, loss: 0.05871061608195305
step: 120, loss: 0.0003951212274841964
step: 130, loss: 0.018882934004068375
step: 140, loss: 0.043701909482479095
step: 150, loss: 0.07225368171930313
step: 160, loss: 0.021258467808365822
step: 170, loss: 0.029899833723902702
step: 180, loss: 0.0359821543097496
step: 190, loss: 0.04413416236639023
step: 200, loss: 0.025958361104130745
step: 210, loss: 3.4811739169526845e-05
step: 220, loss: 0.019983628764748573
step: 230, loss: 5.288519605528563e-05
step: 240, loss: 0.010952148586511612
step: 250, loss: 0.00015914611867628992
step: 260, loss: 0.04451652988791466
step: 270, loss: 0.0003256032650824636
step: 280, loss: 0.00016843678895384073
step: 290, loss: 0.02303437329828739
step: 300, loss: 0.022514592856168747
step: 310, loss: 0.04135088250041008
step: 320, loss: 0.07737225294113159
step: 330, loss: 0.0538901686668396
step: 340, loss: 0.015067903324961662
step: 350, loss: 0.05064335837960243
step: 360, loss: 0.00033371345489285886
step: 370, loss: 0.01921641267836094
step: 380, loss: 9.310643508797511e-05
step: 390, loss: 0.0010945659596472979
step: 400, loss: 0.03087584860622883
step: 410, loss: 0.024360332638025284
step: 420, loss: 0.018605144694447517
epoch 16: dev_f1=0.9909706546275394, f1=0.9830124575311437, best_f1=0.9800884955752212
step: 0, loss: 0.05331111699342728
step: 10, loss: 0.00011609704961301759
step: 20, loss: 0.025881730020046234
step: 30, loss: 0.021194899454712868
step: 40, loss: 0.0001951048761839047
step: 50, loss: 0.04623686149716377
step: 60, loss: 8.492164488416165e-05
step: 70, loss: 0.0006712268805131316
step: 80, loss: 0.00019402601174078882
step: 90, loss: 4.2240502807544544e-05
step: 100, loss: 0.07965551316738129
step: 110, loss: 0.0256179291754961
step: 120, loss: 0.033124811947345734
step: 130, loss: 0.06377166509628296
step: 140, loss: 0.040268924087285995
step: 150, loss: 0.00012730172602459788
step: 160, loss: 0.04661708325147629
step: 170, loss: 0.05815122276544571
step: 180, loss: 6.313399353530258e-05
step: 190, loss: 0.03978017717599869
step: 200, loss: 0.006179577670991421
step: 210, loss: 0.018783841282129288
step: 220, loss: 0.08422235399484634
step: 230, loss: 0.060262829065322876
step: 240, loss: 0.02156674861907959
step: 250, loss: 0.00039417282096110284
step: 260, loss: 0.043260298669338226
step: 270, loss: 9.218470950145274e-05
step: 280, loss: 0.03611548990011215
step: 290, loss: 0.0007715912652201951
step: 300, loss: 0.018588950857520103
step: 310, loss: 0.05202242732048035
step: 320, loss: 0.0004734914982691407
step: 330, loss: 0.04401855915784836
step: 340, loss: 0.04776841402053833
step: 350, loss: 0.023672005161643028
step: 360, loss: 0.01858498342335224
step: 370, loss: 0.02070613019168377
step: 380, loss: 3.1478852179134265e-05
step: 390, loss: 6.43088060314767e-05
step: 400, loss: 0.07456918060779572
step: 410, loss: 0.028244134038686752
step: 420, loss: 0.07262315601110458
epoch 17: dev_f1=0.9898534385569334, f1=0.9820224719101124, best_f1=0.9800884955752212
step: 0, loss: 0.03147311881184578
step: 10, loss: 0.014327188953757286
step: 20, loss: 6.339305400615558e-05
step: 30, loss: 0.024191636592149734
step: 40, loss: 0.07266177237033844
step: 50, loss: 0.019424287602305412
step: 60, loss: 0.025476938113570213
step: 70, loss: 7.347808423219249e-05
step: 80, loss: 0.017725573852658272
step: 90, loss: 0.00016482127830386162
step: 100, loss: 0.052908603101968765
step: 110, loss: 0.014788459986448288
step: 120, loss: 0.0604894794523716
step: 130, loss: 0.017014730721712112
step: 140, loss: 0.01950947940349579
step: 150, loss: 5.483934000949375e-05
step: 160, loss: 0.01742103323340416
step: 170, loss: 0.01807158626616001
step: 180, loss: 0.000704239821061492
step: 190, loss: 0.021854907274246216
step: 200, loss: 0.04656589776277542
step: 210, loss: 0.03655347228050232
step: 220, loss: 0.019815685227513313
step: 230, loss: 0.04190026968717575
step: 240, loss: 0.006424502469599247
step: 250, loss: 0.0418015718460083
step: 260, loss: 0.02144809253513813
step: 270, loss: 0.040459733456373215
step: 280, loss: 0.05198051407933235
step: 290, loss: 5.6995602790266275e-05
step: 300, loss: 0.026547221466898918
step: 310, loss: 0.020174339413642883
step: 320, loss: 4.5748427510261536e-05
step: 330, loss: 0.02490358240902424
step: 340, loss: 0.07009419798851013
step: 350, loss: 0.02144109457731247
step: 360, loss: 7.553844625363126e-05
step: 370, loss: 0.025468502193689346
step: 380, loss: 0.0475909523665905
step: 390, loss: 0.020784955471754074
step: 400, loss: 0.0009624410304240882
step: 410, loss: 0.040886398404836655
step: 420, loss: 0.0794619768857956
epoch 18: dev_f1=0.9899216125419933, f1=0.9832402234636871, best_f1=0.9800884955752212
step: 0, loss: 0.025269418954849243
step: 10, loss: 0.017195919528603554
step: 20, loss: 0.02682499773800373
step: 30, loss: 0.045340538024902344
step: 40, loss: 0.00017300220497418195
step: 50, loss: 0.02077414095401764
step: 60, loss: 0.018031509593129158
step: 70, loss: 3.6251374694984406e-05
step: 80, loss: 0.00043977893074043095
step: 90, loss: 0.019552726298570633
step: 100, loss: 2.4396591470576823e-05
step: 110, loss: 0.02033359743654728
step: 120, loss: 7.780404848745093e-05
step: 130, loss: 0.05435217544436455
step: 140, loss: 0.0214582197368145
step: 150, loss: 0.04556181654334068
step: 160, loss: 0.00016191360191442072
step: 170, loss: 7.918394840089604e-05
step: 180, loss: 0.028805997222661972
step: 190, loss: 0.031234711408615112
step: 200, loss: 0.0436716265976429
step: 210, loss: 0.02726087160408497
step: 220, loss: 0.021652648225426674
step: 230, loss: 0.05142964422702789
step: 240, loss: 4.309052019380033e-05
step: 250, loss: 0.03722526505589485
step: 260, loss: 0.020342033356428146
step: 270, loss: 0.020972535014152527
step: 280, loss: 0.023126481100916862
step: 290, loss: 0.014743172563612461
step: 300, loss: 0.014589021913707256
step: 310, loss: 0.04422745853662491
step: 320, loss: 0.020085373893380165
step: 330, loss: 0.07298950105905533
step: 340, loss: 0.0011000951053574681
step: 350, loss: 0.04063621535897255
step: 360, loss: 0.026761021465063095
step: 370, loss: 0.00012812556815333664
step: 380, loss: 0.0630238801240921
step: 390, loss: 0.00010870395635720342
step: 400, loss: 0.042158093303442
step: 410, loss: 0.02239864319562912
step: 420, loss: 0.06493239849805832
epoch 19: dev_f1=0.9898534385569334, f1=0.9808773903262092, best_f1=0.9800884955752212
step: 0, loss: 0.00041956891072914004
step: 10, loss: 0.0757826715707779
step: 20, loss: 0.022866033017635345
step: 30, loss: 0.07682163268327713
step: 40, loss: 0.032992780208587646
step: 50, loss: 0.021008675917983055
step: 60, loss: 0.016626114025712013
step: 70, loss: 0.022360287606716156
step: 80, loss: 6.74760522088036e-05
step: 90, loss: 0.04828767850995064
step: 100, loss: 0.034274958074092865
step: 110, loss: 0.14518895745277405
step: 120, loss: 0.056554533541202545
step: 130, loss: 0.07605156302452087
step: 140, loss: 9.385847806697711e-05
step: 150, loss: 0.015357675962150097
step: 160, loss: 0.024674050509929657
step: 170, loss: 0.02570466510951519
step: 180, loss: 7.315842958632857e-05
step: 190, loss: 0.024917995557188988
step: 200, loss: 0.0171855129301548
step: 210, loss: 9.469153155805543e-05
step: 220, loss: 0.0610436275601387
step: 230, loss: 0.07880906015634537
step: 240, loss: 0.020269004628062248
step: 250, loss: 7.01297540217638e-05
step: 260, loss: 0.016860302537679672
step: 270, loss: 0.02767273411154747
step: 280, loss: 0.05385471135377884
step: 290, loss: 1.9626168068498373e-05
step: 300, loss: 6.746177677996457e-05
step: 310, loss: 0.040373656898736954
step: 320, loss: 0.0001482302905060351
step: 330, loss: 0.02316305972635746
step: 340, loss: 0.024845566600561142
step: 350, loss: 0.01957794651389122
step: 360, loss: 0.037374503910541534
step: 370, loss: 8.419114601565525e-05
step: 380, loss: 0.02558736316859722
step: 390, loss: 0.0002210273378295824
step: 400, loss: 0.000170264087500982
step: 410, loss: 7.737499981885776e-05
step: 420, loss: 3.984103022958152e-05
epoch 20: dev_f1=0.9898534385569334, f1=0.9808773903262092, best_f1=0.9800884955752212
