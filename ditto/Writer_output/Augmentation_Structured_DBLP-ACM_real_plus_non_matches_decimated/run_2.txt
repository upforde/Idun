cuda
Device: cuda
step: 0, loss: 0.7912613749504089
step: 10, loss: 0.24939186871051788
step: 20, loss: 0.4052123725414276
step: 30, loss: 0.31454896926879883
step: 40, loss: 0.48555880784988403
step: 50, loss: 0.3026990294456482
step: 60, loss: 0.5972972512245178
step: 70, loss: 0.2959098815917969
step: 80, loss: 0.14852742850780487
step: 90, loss: 0.2095402479171753
step: 100, loss: 0.1217191219329834
step: 110, loss: 0.15071871876716614
step: 120, loss: 0.16698096692562103
step: 130, loss: 0.16955813765525818
step: 140, loss: 0.060672011226415634
step: 150, loss: 0.020677119493484497
step: 160, loss: 0.1438187062740326
step: 170, loss: 0.02464311756193638
step: 180, loss: 0.09122256189584732
step: 190, loss: 0.053430620580911636
step: 200, loss: 0.15980376303195953
step: 210, loss: 0.0891040563583374
step: 220, loss: 0.10682828724384308
step: 230, loss: 0.10023953765630722
step: 240, loss: 0.039969880133867264
step: 250, loss: 0.05866732820868492
step: 260, loss: 0.1248096451163292
step: 270, loss: 0.06941312551498413
step: 280, loss: 0.021866705268621445
step: 290, loss: 0.2072649449110031
step: 300, loss: 0.09126917272806168
step: 310, loss: 0.12043119966983795
step: 320, loss: 0.025971056893467903
step: 330, loss: 0.021691786125302315
step: 340, loss: 0.10535477101802826
step: 350, loss: 0.13478080928325653
step: 360, loss: 0.04696596413850784
step: 370, loss: 0.030706064775586128
step: 380, loss: 0.09692175686359406
step: 390, loss: 0.1222890317440033
step: 400, loss: 0.10490633547306061
step: 410, loss: 0.08355743438005447
step: 420, loss: 0.07141411304473877
epoch 1: dev_f1=0.9875141884222476, f1=0.9794988610478361, best_f1=0.9794988610478361
step: 0, loss: 0.08964382112026215
step: 10, loss: 0.038015227764844894
step: 20, loss: 0.05015048012137413
step: 30, loss: 0.018628932535648346
step: 40, loss: 0.11144619435071945
step: 50, loss: 0.09366260468959808
step: 60, loss: 0.05179121345281601
step: 70, loss: 0.0554056316614151
step: 80, loss: 0.022680846974253654
step: 90, loss: 0.05183225870132446
step: 100, loss: 0.046900674700737
step: 110, loss: 0.09196766465902328
step: 120, loss: 0.06852677464485168
step: 130, loss: 0.07994247227907181
step: 140, loss: 0.04070933908224106
step: 150, loss: 0.024612678214907646
step: 160, loss: 0.08311019837856293
step: 170, loss: 0.11635656654834747
step: 180, loss: 0.055294062942266464
step: 190, loss: 0.07013557851314545
step: 200, loss: 0.023893848061561584
step: 210, loss: 0.05752536654472351
step: 220, loss: 0.08547147363424301
step: 230, loss: 0.010172060690820217
step: 240, loss: 0.06260357797145844
step: 250, loss: 0.027456363663077354
step: 260, loss: 0.011957320384681225
step: 270, loss: 0.043067142367362976
step: 280, loss: 0.08151040226221085
step: 290, loss: 0.041735511273145676
step: 300, loss: 0.06499212235212326
step: 310, loss: 0.025450196117162704
step: 320, loss: 0.01746276393532753
step: 330, loss: 0.03286378085613251
step: 340, loss: 0.0614447221159935
step: 350, loss: 0.11663269996643066
step: 360, loss: 0.0704626515507698
step: 370, loss: 0.054119206964969635
step: 380, loss: 0.027739189565181732
step: 390, loss: 0.06250820308923721
step: 400, loss: 0.18805964291095734
step: 410, loss: 0.01278231292963028
step: 420, loss: 0.007262689992785454
epoch 2: dev_f1=0.9932432432432432, f1=0.9831271091113611, best_f1=0.9831271091113611
step: 0, loss: 0.07602620124816895
step: 10, loss: 0.07964959740638733
step: 20, loss: 0.07751581072807312
step: 30, loss: 0.057198505848646164
step: 40, loss: 0.01997990719974041
step: 50, loss: 0.023421401157975197
step: 60, loss: 0.17501544952392578
step: 70, loss: 0.023541299626231194
step: 80, loss: 0.1622597873210907
step: 90, loss: 0.06773398816585541
step: 100, loss: 0.012168090790510178
step: 110, loss: 0.08221768587827682
step: 120, loss: 0.03061065450310707
step: 130, loss: 0.14274048805236816
step: 140, loss: 0.11147040873765945
step: 150, loss: 0.10992419719696045
step: 160, loss: 0.06723813712596893
step: 170, loss: 0.14474013447761536
step: 180, loss: 0.07327079027891159
step: 190, loss: 0.07488539069890976
step: 200, loss: 0.07898630201816559
step: 210, loss: 0.17596374452114105
step: 220, loss: 0.02024928852915764
step: 230, loss: 0.0424436554312706
step: 240, loss: 0.0856836587190628
step: 250, loss: 0.017024602741003036
step: 260, loss: 0.027637260034680367
step: 270, loss: 0.044369786977767944
step: 280, loss: 0.08524450659751892
step: 290, loss: 0.11989428102970123
step: 300, loss: 0.03203187137842178
step: 310, loss: 0.028354376554489136
step: 320, loss: 0.07230544835329056
step: 330, loss: 0.027879193425178528
step: 340, loss: 0.05723044276237488
step: 350, loss: 0.016732661053538322
step: 360, loss: 0.09450487047433853
step: 370, loss: 0.030572306364774704
step: 380, loss: 0.06151904910802841
step: 390, loss: 0.08792419731616974
step: 400, loss: 0.028061354532837868
step: 410, loss: 0.08368433266878128
step: 420, loss: 0.024306753650307655
epoch 3: dev_f1=0.9887387387387387, f1=0.9796839729119639, best_f1=0.9831271091113611
step: 0, loss: 0.1331178992986679
step: 10, loss: 0.08399681746959686
step: 20, loss: 0.07240203022956848
step: 30, loss: 0.025435199961066246
step: 40, loss: 0.03119604103267193
step: 50, loss: 0.007586031686514616
step: 60, loss: 0.026967931538820267
step: 70, loss: 0.030172523111104965
step: 80, loss: 0.03831273689866066
step: 90, loss: 0.09741432219743729
step: 100, loss: 0.09198704361915588
step: 110, loss: 0.012047539465129375
step: 120, loss: 0.14413565397262573
step: 130, loss: 0.13305114209651947
step: 140, loss: 0.08541849255561829
step: 150, loss: 0.02659723162651062
step: 160, loss: 0.08552463352680206
step: 170, loss: 0.011173790320754051
step: 180, loss: 0.11301174014806747
step: 190, loss: 0.07068976759910583
step: 200, loss: 0.018736008554697037
step: 210, loss: 0.010020491667091846
step: 220, loss: 0.012920229695737362
step: 230, loss: 0.018424920737743378
step: 240, loss: 0.003320676740258932
step: 250, loss: 0.12697844207286835
step: 260, loss: 0.025999465957283974
step: 270, loss: 0.07691849768161774
step: 280, loss: 0.11458663642406464
step: 290, loss: 0.013737941160798073
step: 300, loss: 0.035470396280288696
step: 310, loss: 0.048604607582092285
step: 320, loss: 0.011427497491240501
step: 330, loss: 0.018286418169736862
step: 340, loss: 0.016316376626491547
step: 350, loss: 0.04240613803267479
step: 360, loss: 0.10873043537139893
step: 370, loss: 0.01863456331193447
step: 380, loss: 0.07700043171644211
step: 390, loss: 0.09550178050994873
step: 400, loss: 0.005941764451563358
step: 410, loss: 0.06708910316228867
step: 420, loss: 0.018085535615682602
epoch 4: dev_f1=0.9898534385569334, f1=0.9887387387387387, best_f1=0.9831271091113611
step: 0, loss: 0.08533909916877747
step: 10, loss: 0.01619504578411579
step: 20, loss: 0.010798964649438858
step: 30, loss: 0.025343820452690125
step: 40, loss: 0.09078164398670197
step: 50, loss: 0.07292980700731277
step: 60, loss: 0.05663314834237099
step: 70, loss: 0.12546800076961517
step: 80, loss: 0.004624524619430304
step: 90, loss: 0.05332988128066063
step: 100, loss: 0.05720703676342964
step: 110, loss: 0.012141719460487366
step: 120, loss: 0.05579259246587753
step: 130, loss: 0.028071748092770576
step: 140, loss: 0.05780060216784477
step: 150, loss: 0.0015765692805871367
step: 160, loss: 0.09005148708820343
step: 170, loss: 0.0010849899845197797
step: 180, loss: 0.1138727143406868
step: 190, loss: 0.06387737393379211
step: 200, loss: 0.13926342129707336
step: 210, loss: 0.020704271271824837
step: 220, loss: 0.09104732424020767
step: 230, loss: 0.11456923186779022
step: 240, loss: 0.08806990832090378
step: 250, loss: 0.03433249518275261
step: 260, loss: 0.14751353859901428
step: 270, loss: 0.02279147319495678
step: 280, loss: 0.1198541447520256
step: 290, loss: 0.053371965885162354
step: 300, loss: 0.006257192697376013
step: 310, loss: 0.06269565224647522
step: 320, loss: 0.1314026117324829
step: 330, loss: 0.1391865611076355
step: 340, loss: 0.01868499256670475
step: 350, loss: 0.012853875756263733
step: 360, loss: 0.043820638209581375
step: 370, loss: 3.424965325393714e-05
step: 380, loss: 0.08193790167570114
step: 390, loss: 0.06386838853359222
step: 400, loss: 0.058105453848838806
step: 410, loss: 0.032982237637043
step: 420, loss: 0.06131954491138458
epoch 5: dev_f1=0.9921436588103255, f1=0.9832402234636871, best_f1=0.9831271091113611
step: 0, loss: 0.015497663989663124
step: 10, loss: 0.013459553010761738
step: 20, loss: 0.03539139777421951
step: 30, loss: 0.07156016677618027
step: 40, loss: 0.013983202166855335
step: 50, loss: 0.09990141540765762
step: 60, loss: 0.036431074142456055
step: 70, loss: 0.062316011637449265
step: 80, loss: 0.03272753953933716
step: 90, loss: 0.10135582834482193
step: 100, loss: 0.05386389419436455
step: 110, loss: 0.19297562539577484
step: 120, loss: 0.07523661106824875
step: 130, loss: 0.07492652535438538
step: 140, loss: 0.1404954493045807
step: 150, loss: 0.11512238532304764
step: 160, loss: 0.0488935150206089
step: 170, loss: 0.010781040415167809
step: 180, loss: 0.013682307675480843
step: 190, loss: 0.05038927495479584
step: 200, loss: 0.1510307937860489
step: 210, loss: 0.033889878541231155
step: 220, loss: 0.011051565408706665
step: 230, loss: 0.010629065334796906
step: 240, loss: 0.07069005817174911
step: 250, loss: 0.07626902312040329
step: 260, loss: 0.12667964398860931
step: 270, loss: 0.04267435148358345
step: 280, loss: 0.06939610838890076
step: 290, loss: 0.06482933461666107
step: 300, loss: 0.10564611107110977
step: 310, loss: 0.031644925475120544
step: 320, loss: 0.013222064822912216
step: 330, loss: 0.1554044783115387
step: 340, loss: 0.11286339163780212
step: 350, loss: 0.007892130874097347
step: 360, loss: 0.07262172549962997
step: 370, loss: 0.07976731657981873
step: 380, loss: 0.05058525502681732
step: 390, loss: 0.09942646324634552
step: 400, loss: 0.014652206562459469
step: 410, loss: 0.06670624762773514
step: 420, loss: 0.07842166721820831
epoch 6: dev_f1=0.9921259842519685, f1=0.9876543209876544, best_f1=0.9831271091113611
step: 0, loss: 0.008115875534713268
step: 10, loss: 0.02274782955646515
step: 20, loss: 0.07473613321781158
step: 30, loss: 0.005921346601098776
step: 40, loss: 0.0645730122923851
step: 50, loss: 0.13605016469955444
step: 60, loss: 0.04116259887814522
step: 70, loss: 0.0911339670419693
step: 80, loss: 0.1428816318511963
step: 90, loss: 0.03380926698446274
step: 100, loss: 0.007754261139780283
step: 110, loss: 0.10182835161685944
step: 120, loss: 0.07558983564376831
step: 130, loss: 0.09280771762132645
step: 140, loss: 0.07930606603622437
step: 150, loss: 0.029665149748325348
step: 160, loss: 0.07178089767694473
step: 170, loss: 0.009960131719708443
step: 180, loss: 0.14549268782138824
step: 190, loss: 0.10919490456581116
step: 200, loss: 0.009310685098171234
step: 210, loss: 0.007714209612458944
step: 220, loss: 0.0041615040972828865
step: 230, loss: 0.008854067884385586
step: 240, loss: 0.06773485988378525
step: 250, loss: 0.02684251219034195
step: 260, loss: 0.05955378711223602
step: 270, loss: 0.012200002558529377
step: 280, loss: 0.08374717831611633
step: 290, loss: 0.11220691353082657
step: 300, loss: 0.0830080509185791
step: 310, loss: 0.04429248720407486
step: 320, loss: 0.011074607260525227
step: 330, loss: 0.008841363713145256
step: 340, loss: 0.06364555656909943
step: 350, loss: 0.01662255823612213
step: 360, loss: 0.08765803277492523
step: 370, loss: 0.10253390669822693
step: 380, loss: 0.007807579357177019
step: 390, loss: 0.02823132462799549
step: 400, loss: 0.015100885182619095
step: 410, loss: 0.05264724791049957
step: 420, loss: 0.025828251615166664
epoch 7: dev_f1=0.9932432432432432, f1=0.9865168539325843, best_f1=0.9831271091113611
step: 0, loss: 0.007928029634058475
step: 10, loss: 0.01337710116058588
step: 20, loss: 0.04949915036559105
step: 30, loss: 0.016615021973848343
step: 40, loss: 0.09090974926948547
step: 50, loss: 0.05935225263237953
step: 60, loss: 0.029644731432199478
step: 70, loss: 0.01957831159234047
step: 80, loss: 0.1344434916973114
step: 90, loss: 0.02940441109240055
step: 100, loss: 0.04861225560307503
step: 110, loss: 0.0792296975851059
step: 120, loss: 0.011874714866280556
step: 130, loss: 0.11933685839176178
step: 140, loss: 0.025929240509867668
step: 150, loss: 0.006218119990080595
step: 160, loss: 0.10431179404258728
step: 170, loss: 0.07478837668895721
step: 180, loss: 0.12109191715717316
step: 190, loss: 0.08248893916606903
step: 200, loss: 0.07923919707536697
step: 210, loss: 0.009770793840289116
step: 220, loss: 0.007232924457639456
step: 230, loss: 0.0722515881061554
step: 240, loss: 0.058637991547584534
step: 250, loss: 0.028761781752109528
step: 260, loss: 0.07341354340314865
step: 270, loss: 0.07078009098768234
step: 280, loss: 0.07443766295909882
step: 290, loss: 0.0968090295791626
step: 300, loss: 0.025412365794181824
step: 310, loss: 0.007642113137990236
step: 320, loss: 0.015427620150148869
step: 330, loss: 0.010894781909883022
step: 340, loss: 0.003609823063015938
step: 350, loss: 0.014082638546824455
step: 360, loss: 0.10856153070926666
step: 370, loss: 0.009266959503293037
step: 380, loss: 0.004572083707898855
step: 390, loss: 0.0628705695271492
step: 400, loss: 0.05294005945324898
step: 410, loss: 0.030755184590816498
step: 420, loss: 0.057234857231378555
epoch 8: dev_f1=0.9921612541993281, f1=0.9799554565701558, best_f1=0.9831271091113611
step: 0, loss: 0.010747527703642845
step: 10, loss: 0.023333005607128143
step: 20, loss: 0.01234451960772276
step: 30, loss: 0.0006277006468735635
step: 40, loss: 0.016678621992468834
step: 50, loss: 0.05357496440410614
step: 60, loss: 0.02341623418033123
step: 70, loss: 0.006871427875012159
step: 80, loss: 0.03695869818329811
step: 90, loss: 0.1555633693933487
step: 100, loss: 0.03247538208961487
step: 110, loss: 0.023541342467069626
step: 120, loss: 0.01486976258456707
step: 130, loss: 0.036857981234788895
step: 140, loss: 0.0032344998326152563
step: 150, loss: 0.08036158233880997
step: 160, loss: 0.010225042700767517
step: 170, loss: 0.016747524961829185
step: 180, loss: 0.01526772789657116
step: 190, loss: 0.03073602356016636
step: 200, loss: 0.08480153232812881
step: 210, loss: 0.010744738392531872
step: 220, loss: 0.017230048775672913
step: 230, loss: 0.06154971569776535
step: 240, loss: 0.08375910669565201
step: 250, loss: 0.007649470120668411
step: 260, loss: 0.05811242014169693
step: 270, loss: 0.021202299743890762
step: 280, loss: 0.03796977549791336
step: 290, loss: 0.10194295644760132
step: 300, loss: 0.019076863303780556
step: 310, loss: 0.03899000585079193
step: 320, loss: 0.0095022888854146
step: 330, loss: 0.040422115474939346
step: 340, loss: 0.06710375100374222
step: 350, loss: 0.1318654865026474
step: 360, loss: 0.015624172985553741
step: 370, loss: 0.01897650770843029
step: 380, loss: 0.03532032668590546
step: 390, loss: 0.07755866646766663
step: 400, loss: 8.789057028479874e-05
step: 410, loss: 0.014359571039676666
step: 420, loss: 0.08994509279727936
epoch 9: dev_f1=0.9921259842519685, f1=0.9842696629213483, best_f1=0.9831271091113611
step: 0, loss: 0.09597782045602798
step: 10, loss: 0.0600116141140461
step: 20, loss: 0.0054125552996993065
step: 30, loss: 0.07316315174102783
step: 40, loss: 0.005001494195312262
step: 50, loss: 0.05411785840988159
step: 60, loss: 0.058384574949741364
step: 70, loss: 0.06178543344140053
step: 80, loss: 0.0649576336145401
step: 90, loss: 0.10310878604650497
step: 100, loss: 0.02847110852599144
step: 110, loss: 0.009277175180613995
step: 120, loss: 0.12036910653114319
step: 130, loss: 0.1823650598526001
step: 140, loss: 0.1727496087551117
step: 150, loss: 0.15519823133945465
step: 160, loss: 0.09226866066455841
step: 170, loss: 0.017908696085214615
step: 180, loss: 0.01201082393527031
step: 190, loss: 0.1268010288476944
step: 200, loss: 0.00434882752597332
step: 210, loss: 0.04765666648745537
step: 220, loss: 0.010873652994632721
step: 230, loss: 0.08286306262016296
step: 240, loss: 0.029645705595612526
step: 250, loss: 0.09564763307571411
step: 260, loss: 0.005093206651508808
step: 270, loss: 0.0332440584897995
step: 280, loss: 0.02986602485179901
step: 290, loss: 0.01957404799759388
step: 300, loss: 0.03591779246926308
step: 310, loss: 0.06523848325014114
step: 320, loss: 0.023042624816298485
step: 330, loss: 0.047518420964479446
step: 340, loss: 0.009340468794107437
step: 350, loss: 0.0035786102525889874
step: 360, loss: 0.09278421103954315
step: 370, loss: 0.06677651405334473
step: 380, loss: 0.0295344740152359
step: 390, loss: 0.0001675047678872943
step: 400, loss: 0.016124418005347252
step: 410, loss: 0.00447577890008688
step: 420, loss: 0.048420846462249756
epoch 10: dev_f1=0.9932584269662922, f1=0.9833147942157954, best_f1=0.9833147942157954
step: 0, loss: 0.09480662643909454
step: 10, loss: 0.12644778192043304
step: 20, loss: 0.015798021107912064
step: 30, loss: 0.013968519866466522
step: 40, loss: 0.0021895214449614286
step: 50, loss: 0.0016024590004235506
step: 60, loss: 0.0594395250082016
step: 70, loss: 0.0011586891487240791
step: 80, loss: 0.09951585531234741
step: 90, loss: 0.06064073368906975
step: 100, loss: 0.006358222104609013
step: 110, loss: 0.002750139217823744
step: 120, loss: 0.13609030842781067
step: 130, loss: 0.13799366354942322
step: 140, loss: 0.015019174665212631
step: 150, loss: 0.04255281388759613
step: 160, loss: 0.001781875966116786
step: 170, loss: 0.06660038232803345
step: 180, loss: 0.0489366389811039
step: 190, loss: 0.0012718518264591694
step: 200, loss: 0.01611713320016861
step: 210, loss: 0.05346202105283737
step: 220, loss: 0.035001374781131744
step: 230, loss: 1.5079833247000352e-05
step: 240, loss: 0.025016723200678825
step: 250, loss: 0.005594499409198761
step: 260, loss: 0.001119205029681325
step: 270, loss: 0.026001449674367905
step: 280, loss: 0.008568897843360901
step: 290, loss: 0.049172405153512955
step: 300, loss: 0.03142232447862625
step: 310, loss: 0.07226873189210892
step: 320, loss: 0.002634905744343996
step: 330, loss: 0.15798431634902954
step: 340, loss: 1.5660949429729953e-05
step: 350, loss: 0.08399684727191925
step: 360, loss: 0.07254139333963394
step: 370, loss: 0.049837395548820496
step: 380, loss: 0.01665380597114563
step: 390, loss: 0.05817176029086113
step: 400, loss: 0.07459977269172668
step: 410, loss: 0.0015108011430129409
step: 420, loss: 0.0019174024928361177
epoch 11: dev_f1=0.9932584269662922, f1=0.9833147942157954, best_f1=0.9833147942157954
step: 0, loss: 0.040910784155130386
step: 10, loss: 0.016468193382024765
step: 20, loss: 0.06958204507827759
step: 30, loss: 0.0005589502980001271
step: 40, loss: 0.027125336229801178
step: 50, loss: 0.1210721880197525
step: 60, loss: 0.06201448664069176
step: 70, loss: 0.028432374820113182
step: 80, loss: 0.048315536230802536
step: 90, loss: 0.055833302438259125
step: 100, loss: 0.014013181440532207
step: 110, loss: 0.0073043713346123695
step: 120, loss: 0.06903448700904846
step: 130, loss: 0.05310897156596184
step: 140, loss: 0.005244296044111252
step: 150, loss: 0.04919051751494408
step: 160, loss: 0.029390059411525726
step: 170, loss: 0.0011522008571773767
step: 180, loss: 0.043493904173374176
step: 190, loss: 0.0031975852325558662
step: 200, loss: 0.00010509932326385751
step: 210, loss: 0.04607376456260681
step: 220, loss: 0.018989594653248787
step: 230, loss: 0.0010162638500332832
step: 240, loss: 0.01931029185652733
step: 250, loss: 0.0745648443698883
step: 260, loss: 0.1046888679265976
step: 270, loss: 0.016176633536815643
step: 280, loss: 0.008591534569859505
step: 290, loss: 0.11924746632575989
step: 300, loss: 0.0010537386406213045
step: 310, loss: 0.04172739014029503
step: 320, loss: 0.033825669437646866
step: 330, loss: 0.058049097657203674
step: 340, loss: 0.03302443400025368
step: 350, loss: 0.0047272806987166405
step: 360, loss: 0.0028723126742988825
step: 370, loss: 0.038561657071113586
step: 380, loss: 0.08955001085996628
step: 390, loss: 0.0020278405863791704
step: 400, loss: 0.012756259180605412
step: 410, loss: 0.10040602833032608
step: 420, loss: 0.08895479887723923
epoch 12: dev_f1=0.9910313901345291, f1=0.9822616407982262, best_f1=0.9833147942157954
step: 0, loss: 0.003102374728769064
step: 10, loss: 0.03367745131254196
step: 20, loss: 2.5668730813777074e-05
step: 30, loss: 0.00809062272310257
step: 40, loss: 0.053889449685811996
step: 50, loss: 0.021980606019496918
step: 60, loss: 0.0056189862079918385
step: 70, loss: 0.00015922434977255762
step: 80, loss: 6.425339233828709e-05
step: 90, loss: 0.01645885966718197
step: 100, loss: 0.0007038245676085353
step: 110, loss: 0.08741907775402069
step: 120, loss: 0.0221575815230608
step: 130, loss: 0.07473563402891159
step: 140, loss: 0.04229166731238365
step: 150, loss: 0.018643740564584732
step: 160, loss: 0.0004978288779966533
step: 170, loss: 0.0013339635916054249
step: 180, loss: 0.021270206198096275
step: 190, loss: 0.09213252365589142
step: 200, loss: 0.01685282401740551
step: 210, loss: 0.08048706501722336
step: 220, loss: 0.032871611416339874
step: 230, loss: 0.02455027587711811
step: 240, loss: 0.00852719135582447
step: 250, loss: 0.02882518619298935
step: 260, loss: 0.04837367311120033
step: 270, loss: 0.04580029472708702
step: 280, loss: 0.04465732350945473
step: 290, loss: 8.073526987573132e-05
step: 300, loss: 0.002166335005313158
step: 310, loss: 0.003643037285655737
step: 320, loss: 0.03167231008410454
step: 330, loss: 0.015042072162032127
step: 340, loss: 0.0601210817694664
step: 350, loss: 0.05535029619932175
step: 360, loss: 0.0002381884551141411
step: 370, loss: 0.048900384455919266
step: 380, loss: 0.057025469839572906
step: 390, loss: 0.000740290037356317
step: 400, loss: 0.022619009017944336
step: 410, loss: 0.07152780145406723
step: 420, loss: 0.022504935041069984
epoch 13: dev_f1=0.9943757030371203, f1=0.9865470852017937, best_f1=0.9865470852017937
step: 0, loss: 0.043810296803712845
step: 10, loss: 0.029606470838189125
step: 20, loss: 0.011492684483528137
step: 30, loss: 0.043617311865091324
step: 40, loss: 0.047695502638816833
step: 50, loss: 0.030105270445346832
step: 60, loss: 0.0009221577201969922
step: 70, loss: 0.08830656856298447
step: 80, loss: 0.06102605536580086
step: 90, loss: 0.05456224083900452
step: 100, loss: 0.05666293948888779
step: 110, loss: 0.0001133716432377696
step: 120, loss: 0.023512698709964752
step: 130, loss: 0.08983615040779114
step: 140, loss: 0.032178327441215515
step: 150, loss: 0.03918083757162094
step: 160, loss: 0.020772578194737434
step: 170, loss: 0.09384936094284058
step: 180, loss: 0.02835793048143387
step: 190, loss: 0.02814781479537487
step: 200, loss: 0.0015142719494178891
step: 210, loss: 0.052523449063301086
step: 220, loss: 0.022696787491440773
step: 230, loss: 0.047359369695186615
step: 240, loss: 0.015038193203508854
step: 250, loss: 0.005643322132527828
step: 260, loss: 0.0001856790913734585
step: 270, loss: 0.027128618210554123
step: 280, loss: 0.07052646577358246
step: 290, loss: 0.02755245938897133
step: 300, loss: 0.0022493614815175533
step: 310, loss: 0.03702360391616821
step: 320, loss: 0.03709785267710686
step: 330, loss: 0.02466157265007496
step: 340, loss: 0.006628883071243763
step: 350, loss: 0.0264549870043993
step: 360, loss: 0.020736105740070343
step: 370, loss: 0.02669546939432621
step: 380, loss: 0.021980319172143936
step: 390, loss: 0.013384898193180561
step: 400, loss: 0.027145028114318848
step: 410, loss: 0.0007143247057683766
step: 420, loss: 0.019708048552274704
epoch 14: dev_f1=0.9932735426008968, f1=0.983277591973244, best_f1=0.9865470852017937
step: 0, loss: 0.002617595950141549
step: 10, loss: 0.043346405029296875
step: 20, loss: 0.0006783456774428487
step: 30, loss: 0.00017992843640968204
step: 40, loss: 0.05288591608405113
step: 50, loss: 0.017726575955748558
step: 60, loss: 0.04369107633829117
step: 70, loss: 0.024963712319731712
step: 80, loss: 0.00023439510550815612
step: 90, loss: 0.04496891051530838
step: 100, loss: 0.006440037861466408
step: 110, loss: 1.160790452559013e-05
step: 120, loss: 0.0006133118877187371
step: 130, loss: 0.0998520702123642
step: 140, loss: 0.002730048494413495
step: 150, loss: 0.014546677470207214
step: 160, loss: 0.02290499210357666
step: 170, loss: 0.0622701570391655
step: 180, loss: 0.0004165766295045614
step: 190, loss: 0.0030928037595003843
step: 200, loss: 0.0003926173667423427
step: 210, loss: 9.484639303991571e-05
step: 220, loss: 0.020699620246887207
step: 230, loss: 0.07583790272474289
step: 240, loss: 0.0671929121017456
step: 250, loss: 0.020906632766127586
step: 260, loss: 0.0009852498769760132
step: 270, loss: 0.0008476932998746634
step: 280, loss: 0.018957074731588364
step: 290, loss: 0.025663668289780617
step: 300, loss: 0.05300840735435486
step: 310, loss: 0.035036541521549225
step: 320, loss: 0.05493761971592903
step: 330, loss: 0.02843913622200489
step: 340, loss: 0.07693778723478317
step: 350, loss: 0.04854778200387955
step: 360, loss: 0.03809817135334015
step: 370, loss: 0.027215145528316498
step: 380, loss: 0.04823421314358711
step: 390, loss: 3.3337415516143665e-05
step: 400, loss: 0.03084295056760311
step: 410, loss: 0.07018312811851501
step: 420, loss: 0.02662079967558384
epoch 15: dev_f1=0.9932584269662922, f1=0.9821029082774049, best_f1=0.9865470852017937
step: 0, loss: 2.9154636649764143e-05
step: 10, loss: 0.022875629365444183
step: 20, loss: 0.021181847900152206
step: 30, loss: 0.005366621073335409
step: 40, loss: 0.024325940757989883
step: 50, loss: 0.0017143613658845425
step: 60, loss: 0.0044403779320418835
step: 70, loss: 0.018794329836964607
step: 80, loss: 0.00021355526405386627
step: 90, loss: 0.02809682860970497
step: 100, loss: 0.03943619132041931
step: 110, loss: 0.03874320536851883
step: 120, loss: 0.000937785895075649
step: 130, loss: 5.052013148088008e-05
step: 140, loss: 0.00025674610515125096
step: 150, loss: 0.03545694798231125
step: 160, loss: 0.05248699337244034
step: 170, loss: 6.7573731939774e-05
step: 180, loss: 0.07330173999071121
step: 190, loss: 0.025173703208565712
step: 200, loss: 0.06352795660495758
step: 210, loss: 0.00024194363504648209
step: 220, loss: 0.07579486817121506
step: 230, loss: 0.01780248060822487
step: 240, loss: 0.023016056045889854
step: 250, loss: 0.00017860344087239355
step: 260, loss: 0.0007707867189310491
step: 270, loss: 0.029296068474650383
step: 280, loss: 0.06239805370569229
step: 290, loss: 0.006403569597750902
step: 300, loss: 0.04023033007979393
step: 310, loss: 0.024136977270245552
step: 320, loss: 0.041215766221284866
step: 330, loss: 6.389900954673067e-05
step: 340, loss: 0.019253423437476158
step: 350, loss: 0.00019155639165546745
step: 360, loss: 0.021782126277685165
step: 370, loss: 0.07069678604602814
step: 380, loss: 0.02252431958913803
step: 390, loss: 0.028725972399115562
step: 400, loss: 0.017027786001563072
step: 410, loss: 0.049983177334070206
step: 420, loss: 0.04090118780732155
epoch 16: dev_f1=0.9932735426008968, f1=0.9810479375696767, best_f1=0.9865470852017937
step: 0, loss: 0.002258912194520235
step: 10, loss: 0.07049010694026947
step: 20, loss: 0.0002864821581169963
step: 30, loss: 0.020563285797834396
step: 40, loss: 0.02927633561193943
step: 50, loss: 0.006009195931255817
step: 60, loss: 0.05890240892767906
step: 70, loss: 0.04965278506278992
step: 80, loss: 0.027990290895104408
step: 90, loss: 0.08026362955570221
step: 100, loss: 0.041642967611551285
step: 110, loss: 0.040263332426548004
step: 120, loss: 0.015437867492437363
step: 130, loss: 0.04069095104932785
step: 140, loss: 0.04455309733748436
step: 150, loss: 0.015318794175982475
step: 160, loss: 0.00018877058755606413
step: 170, loss: 0.05066806077957153
step: 180, loss: 0.042135145515203476
step: 190, loss: 0.06030493229627609
step: 200, loss: 3.1892010156298056e-05
step: 210, loss: 2.556479194026906e-05
step: 220, loss: 0.01243938785046339
step: 230, loss: 0.02531123161315918
step: 240, loss: 1.0155087693419773e-05
step: 250, loss: 0.026555975899100304
step: 260, loss: 1.511312075308524e-05
step: 270, loss: 3.288657535449602e-05
step: 280, loss: 0.035405345261096954
step: 290, loss: 0.046984124928712845
step: 300, loss: 0.02118980698287487
step: 310, loss: 0.0023636198602616787
step: 320, loss: 0.06709447503089905
step: 330, loss: 0.00016733571828808635
step: 340, loss: 0.008213123306632042
step: 350, loss: 0.018565792590379715
step: 360, loss: 0.001613460248336196
step: 370, loss: 0.08564809709787369
step: 380, loss: 2.4386092263739556e-05
step: 390, loss: 0.02061719261109829
step: 400, loss: 9.195695747621357e-05
step: 410, loss: 0.022533118724822998
step: 420, loss: 0.009256315417587757
epoch 17: dev_f1=0.9932432432432432, f1=0.9854096520763187, best_f1=0.9865470852017937
step: 0, loss: 0.047790151089429855
step: 10, loss: 0.00013145555567461997
step: 20, loss: 0.02228398062288761
step: 30, loss: 0.069390669465065
step: 40, loss: 6.283346738200635e-05
step: 50, loss: 0.017886769026517868
step: 60, loss: 0.03200637921690941
step: 70, loss: 1.3731280887441244e-05
step: 80, loss: 0.06007646024227142
step: 90, loss: 9.455680992687121e-05
step: 100, loss: 0.043049611151218414
step: 110, loss: 0.00015910279762465507
step: 120, loss: 0.024266112595796585
step: 130, loss: 0.04317159578204155
step: 140, loss: 0.017053883522748947
step: 150, loss: 0.005508998408913612
step: 160, loss: 0.025133581832051277
step: 170, loss: 0.04723348841071129
step: 180, loss: 0.018514351919293404
step: 190, loss: 0.040505263954401016
step: 200, loss: 0.057221923023462296
step: 210, loss: 3.986859883298166e-05
step: 220, loss: 0.005649340804666281
step: 230, loss: 0.04870705306529999
step: 240, loss: 0.03618805110454559
step: 250, loss: 0.02038554474711418
step: 260, loss: 0.041839778423309326
step: 270, loss: 0.024359077215194702
step: 280, loss: 0.03844811022281647
step: 290, loss: 0.017015136778354645
step: 300, loss: 0.03525818884372711
step: 310, loss: 8.277929737232625e-05
step: 320, loss: 7.143601396819577e-05
step: 330, loss: 0.07767105847597122
step: 340, loss: 0.01934351772069931
step: 350, loss: 0.02306651510298252
step: 360, loss: 7.355510751949623e-05
step: 370, loss: 0.029474429786205292
step: 380, loss: 0.00013542843225877732
step: 390, loss: 0.03754175454378128
step: 400, loss: 0.0004196690279059112
step: 410, loss: 0.04059033840894699
step: 420, loss: 0.0002981928118970245
epoch 18: dev_f1=0.9943883277216611, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.022941818460822105
step: 10, loss: 0.00014667556388303638
step: 20, loss: 3.944764830521308e-05
step: 30, loss: 5.9408539527794346e-05
step: 40, loss: 0.00021068388014100492
step: 50, loss: 0.022098997607827187
step: 60, loss: 0.06923196464776993
step: 70, loss: 0.03771723806858063
step: 80, loss: 0.018855798989534378
step: 90, loss: 0.02375807613134384
step: 100, loss: 0.00012108129885746166
step: 110, loss: 0.04861375689506531
step: 120, loss: 0.07366032153367996
step: 130, loss: 0.02504963055253029
step: 140, loss: 0.008083769120275974
step: 150, loss: 0.014764439314603806
step: 160, loss: 0.02751127816736698
step: 170, loss: 0.08480431884527206
step: 180, loss: 4.518436253420077e-05
step: 190, loss: 0.01544236484915018
step: 200, loss: 0.02833804488182068
step: 210, loss: 0.05125560611486435
step: 220, loss: 2.5577568521839567e-05
step: 230, loss: 0.04693114757537842
step: 240, loss: 4.317733692005277e-05
step: 250, loss: 1.0371140888310038e-05
step: 260, loss: 0.023347381502389908
step: 270, loss: 0.04875035211443901
step: 280, loss: 0.018894212320446968
step: 290, loss: 0.000140892225317657
step: 300, loss: 0.023657917976379395
step: 310, loss: 0.03613240644335747
step: 320, loss: 0.054641079157590866
step: 330, loss: 0.016214236617088318
step: 340, loss: 7.247550820466131e-05
step: 350, loss: 0.04537852853536606
step: 360, loss: 0.02479945309460163
step: 370, loss: 0.02433466911315918
step: 380, loss: 0.0212246086448431
step: 390, loss: 0.01892849989235401
step: 400, loss: 0.02781430445611477
step: 410, loss: 0.04019767418503761
step: 420, loss: 0.05063728615641594
epoch 19: dev_f1=0.992108229988726, f1=0.9854096520763187, best_f1=0.9854096520763187
step: 0, loss: 0.04694622382521629
step: 10, loss: 2.992179724969901e-05
step: 20, loss: 5.953582513029687e-05
step: 30, loss: 0.00011930571054108441
step: 40, loss: 0.0001225607265951112
step: 50, loss: 6.29952919553034e-05
step: 60, loss: 0.08763925731182098
step: 70, loss: 0.021541554480791092
step: 80, loss: 0.020507479086518288
step: 90, loss: 0.026021132245659828
step: 100, loss: 9.268478606827557e-06
step: 110, loss: 0.009749935939908028
step: 120, loss: 6.95208873366937e-05
step: 130, loss: 0.000141836644615978
step: 140, loss: 0.0001598299277247861
step: 150, loss: 0.02484942600131035
step: 160, loss: 0.042218033224344254
step: 170, loss: 0.07034707814455032
step: 180, loss: 0.022074399515986443
step: 190, loss: 0.030924726277589798
step: 200, loss: 0.03946634382009506
step: 210, loss: 0.009914430789649487
step: 220, loss: 0.04055742174386978
step: 230, loss: 0.04416647553443909
step: 240, loss: 5.785943358205259e-05
step: 250, loss: 0.015132357366383076
step: 260, loss: 0.0001048201957019046
step: 270, loss: 0.03039715625345707
step: 280, loss: 0.04232927784323692
step: 290, loss: 0.01720004715025425
step: 300, loss: 0.027041777968406677
step: 310, loss: 0.030776221305131912
step: 320, loss: 0.05975858494639397
step: 330, loss: 0.00017942579870577902
step: 340, loss: 0.010080848820507526
step: 350, loss: 0.026272185146808624
step: 360, loss: 0.04451921954751015
step: 370, loss: 0.025994280353188515
step: 380, loss: 0.02134948968887329
step: 390, loss: 9.119467904383782e-06
step: 400, loss: 0.00425887294113636
step: 410, loss: 0.10809667408466339
step: 420, loss: 0.011186781339347363
epoch 20: dev_f1=0.9909706546275394, f1=0.9854096520763187, best_f1=0.9854096520763187
