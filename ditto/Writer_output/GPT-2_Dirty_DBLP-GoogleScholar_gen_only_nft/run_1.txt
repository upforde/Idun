cuda
Device: cuda
step: 0, loss: 0.7349871397018433
step: 10, loss: 0.387765496969223
step: 20, loss: 0.5168018937110901
step: 30, loss: 0.5509897470474243
step: 40, loss: 0.37845921516418457
step: 50, loss: 0.39139020442962646
step: 60, loss: 0.5533252954483032
step: 70, loss: 0.3130483627319336
step: 80, loss: 0.452557235956192
step: 90, loss: 0.5026220083236694
step: 100, loss: 0.6164181232452393
step: 110, loss: 0.45535963773727417
step: 120, loss: 0.38504183292388916
step: 130, loss: 0.3228454291820526
step: 140, loss: 0.2627065181732178
step: 150, loss: 0.4766418933868408
step: 160, loss: 0.3850318491458893
step: 170, loss: 0.3466334342956543
step: 180, loss: 0.30914920568466187
step: 190, loss: 0.33840566873550415
step: 200, loss: 0.25591763854026794
step: 210, loss: 0.3950338065624237
step: 220, loss: 0.3696598410606384
step: 230, loss: 0.5049422383308411
step: 240, loss: 0.43246030807495117
step: 250, loss: 0.3059355914592743
step: 260, loss: 0.4030531942844391
step: 270, loss: 0.2096145749092102
step: 280, loss: 0.26021772623062134
step: 290, loss: 0.23246848583221436
step: 300, loss: 0.2471252828836441
step: 310, loss: 0.29196974635124207
step: 320, loss: 0.286210834980011
step: 330, loss: 0.26828819513320923
step: 340, loss: 0.34470894932746887
step: 350, loss: 0.3385499119758606
step: 360, loss: 0.18876110017299652
step: 370, loss: 0.3632674813270569
step: 380, loss: 0.2566450536251068
step: 390, loss: 0.1951703429222107
step: 400, loss: 0.5896230340003967
step: 410, loss: 0.0564349964261055
step: 420, loss: 0.4227261543273926
step: 430, loss: 0.31901127099990845
step: 440, loss: 0.29345694184303284
step: 450, loss: 0.3108292520046234
step: 460, loss: 0.4352808892726898
step: 470, loss: 0.14305196702480316
step: 480, loss: 0.2542940676212311
step: 490, loss: 0.16993845999240875
epoch 1: dev_f1=0.8365724381625441, f1=0.7877422262280307, best_f1=0.7877422262280307
step: 0, loss: 0.16671670973300934
step: 10, loss: 0.1626429706811905
step: 20, loss: 0.2123641073703766
step: 30, loss: 0.3242098093032837
step: 40, loss: 0.15395501255989075
step: 50, loss: 0.27022525668144226
step: 60, loss: 0.3684694468975067
step: 70, loss: 0.39085519313812256
step: 80, loss: 0.292265921831131
step: 90, loss: 0.19177010655403137
step: 100, loss: 0.23270665109157562
step: 110, loss: 0.3395804464817047
step: 120, loss: 0.1953919231891632
step: 130, loss: 0.25897446274757385
step: 140, loss: 0.22241391241550446
step: 150, loss: 0.21366599202156067
step: 160, loss: 0.3361041843891144
step: 170, loss: 0.25202977657318115
step: 180, loss: 0.28872472047805786
step: 190, loss: 0.02114119939506054
step: 200, loss: 0.31339290738105774
step: 210, loss: 0.12735792994499207
step: 220, loss: 0.17911143600940704
step: 230, loss: 0.23944008350372314
step: 240, loss: 0.26983240246772766
step: 250, loss: 0.09942123293876648
step: 260, loss: 0.2918033301830292
step: 270, loss: 0.13500483334064484
step: 280, loss: 0.24115824699401855
step: 290, loss: 0.36450445652008057
step: 300, loss: 0.35459256172180176
step: 310, loss: 0.3611806333065033
step: 320, loss: 0.271345853805542
step: 330, loss: 0.2904088497161865
step: 340, loss: 0.19424854218959808
step: 350, loss: 0.22035269439220428
step: 360, loss: 0.1636306792497635
step: 370, loss: 0.24776867032051086
step: 380, loss: 0.19926661252975464
step: 390, loss: 0.23577982187271118
step: 400, loss: 0.5256249904632568
step: 410, loss: 0.30923402309417725
step: 420, loss: 0.07072892785072327
step: 430, loss: 0.2898913323879242
step: 440, loss: 0.1284194439649582
step: 450, loss: 0.1753590852022171
step: 460, loss: 0.20792439579963684
step: 470, loss: 0.27246716618537903
step: 480, loss: 0.18248726427555084
step: 490, loss: 0.1450839340686798
epoch 2: dev_f1=0.8678537956888472, f1=0.7733333333333333, best_f1=0.7733333333333333
step: 0, loss: 0.2653179168701172
step: 10, loss: 0.17633487284183502
step: 20, loss: 0.11048025637865067
step: 30, loss: 0.08218063414096832
step: 40, loss: 0.3381800651550293
step: 50, loss: 0.3274123966693878
step: 60, loss: 0.1342577338218689
step: 70, loss: 0.18363496661186218
step: 80, loss: 0.05875310301780701
step: 90, loss: 0.12480875849723816
step: 100, loss: 0.07465803623199463
step: 110, loss: 0.22989529371261597
step: 120, loss: 0.09662844985723495
step: 130, loss: 0.24007830023765564
step: 140, loss: 0.06149191036820412
step: 150, loss: 0.24443572759628296
step: 160, loss: 0.32878491282463074
step: 170, loss: 0.21632163226604462
step: 180, loss: 0.13460050523281097
step: 190, loss: 0.11390580236911774
step: 200, loss: 0.2883816659450531
step: 210, loss: 0.1639806479215622
step: 220, loss: 0.08112656325101852
step: 230, loss: 0.23105961084365845
step: 240, loss: 0.1510377675294876
step: 250, loss: 0.09145420789718628
step: 260, loss: 0.11845991015434265
step: 270, loss: 0.27509215474128723
step: 280, loss: 0.15508446097373962
step: 290, loss: 0.20496557652950287
step: 300, loss: 0.10462687909603119
step: 310, loss: 0.30655139684677124
step: 320, loss: 0.09627524018287659
step: 330, loss: 0.09800923615694046
step: 340, loss: 0.08436745405197144
step: 350, loss: 0.053719352930784225
step: 360, loss: 0.18301156163215637
step: 370, loss: 0.2786598205566406
step: 380, loss: 0.24717146158218384
step: 390, loss: 0.1901513934135437
step: 400, loss: 0.11362545192241669
step: 410, loss: 0.10365720093250275
step: 420, loss: 0.42945918440818787
step: 430, loss: 0.0643257200717926
step: 440, loss: 0.060319844633340836
step: 450, loss: 0.13677899539470673
step: 460, loss: 0.19362658262252808
step: 470, loss: 0.11580787599086761
step: 480, loss: 0.08959317207336426
step: 490, loss: 0.20898403227329254
epoch 3: dev_f1=0.850909090909091, f1=0.7083725305738475, best_f1=0.7733333333333333
step: 0, loss: 0.15635664761066437
step: 10, loss: 0.1370737999677658
step: 20, loss: 0.08453753590583801
step: 30, loss: 0.04851279780268669
step: 40, loss: 0.020948681980371475
step: 50, loss: 0.04065384343266487
step: 60, loss: 0.04479082301259041
step: 70, loss: 0.10718444734811783
step: 80, loss: 0.0972636342048645
step: 90, loss: 0.18374136090278625
step: 100, loss: 0.06343456357717514
step: 110, loss: 0.059559114277362823
step: 120, loss: 0.09777974337339401
step: 130, loss: 0.07578091323375702
step: 140, loss: 0.049526941031217575
step: 150, loss: 0.18985527753829956
step: 160, loss: 0.10091160237789154
step: 170, loss: 0.08858717232942581
step: 180, loss: 0.09366805851459503
step: 190, loss: 0.20794875919818878
step: 200, loss: 0.18212680518627167
step: 210, loss: 0.2008092999458313
step: 220, loss: 0.04536481574177742
step: 230, loss: 0.15233543515205383
step: 240, loss: 0.05767747759819031
step: 250, loss: 0.1729312539100647
step: 260, loss: 0.16581843793392181
step: 270, loss: 0.17931869626045227
step: 280, loss: 0.09188034385442734
step: 290, loss: 0.2366526573896408
step: 300, loss: 0.13201822340488434
step: 310, loss: 0.12398295104503632
step: 320, loss: 0.08956532925367355
step: 330, loss: 0.04952820762991905
step: 340, loss: 0.10305879265069962
step: 350, loss: 0.2710583209991455
step: 360, loss: 0.10881229490041733
step: 370, loss: 0.0914166271686554
step: 380, loss: 0.05429176241159439
step: 390, loss: 0.05656861141324043
step: 400, loss: 0.17928345501422882
step: 410, loss: 0.19315646588802338
step: 420, loss: 0.08921348303556442
step: 430, loss: 0.06282516568899155
step: 440, loss: 0.11846814304590225
step: 450, loss: 0.024921633303165436
step: 460, loss: 0.1982504427433014
step: 470, loss: 0.01960562728345394
step: 480, loss: 0.13086608052253723
step: 490, loss: 0.1283421367406845
epoch 4: dev_f1=0.8325266214908035, f1=0.6600831600831601, best_f1=0.7733333333333333
step: 0, loss: 0.09179452061653137
step: 10, loss: 0.33628103137016296
step: 20, loss: 0.08311816304922104
step: 30, loss: 0.0425301231443882
step: 40, loss: 0.07965616881847382
step: 50, loss: 0.00516904704272747
step: 60, loss: 0.004438277333974838
step: 70, loss: 0.16421273350715637
step: 80, loss: 0.015482685528695583
step: 90, loss: 0.04344864562153816
step: 100, loss: 0.06003095582127571
step: 110, loss: 0.03537397459149361
step: 120, loss: 0.10784851759672165
step: 130, loss: 0.030141310766339302
step: 140, loss: 0.11235571652650833
step: 150, loss: 0.010586351156234741
step: 160, loss: 0.020131081342697144
step: 170, loss: 0.11684085428714752
step: 180, loss: 0.02991361729800701
step: 190, loss: 0.08624574542045593
step: 200, loss: 0.004278309643268585
step: 210, loss: 0.05493258684873581
step: 220, loss: 0.0103414012119174
step: 230, loss: 0.007511933334171772
step: 240, loss: 0.14997170865535736
step: 250, loss: 0.09067656099796295
step: 260, loss: 0.14784181118011475
step: 270, loss: 0.1706288456916809
step: 280, loss: 0.07864074409008026
step: 290, loss: 0.06727159768342972
step: 300, loss: 0.06065990403294563
step: 310, loss: 0.05889742448925972
step: 320, loss: 0.08357047289609909
step: 330, loss: 0.06592974066734314
step: 340, loss: 0.012903274036943913
step: 350, loss: 0.0898955762386322
step: 360, loss: 0.04792771488428116
step: 370, loss: 0.1559106409549713
step: 380, loss: 0.14947442710399628
step: 390, loss: 0.24372705817222595
step: 400, loss: 0.08105893433094025
step: 410, loss: 0.1851000189781189
step: 420, loss: 0.17163829505443573
step: 430, loss: 0.08653347194194794
step: 440, loss: 0.22164024412631989
step: 450, loss: 0.03774290159344673
step: 460, loss: 0.02320990525186062
step: 470, loss: 0.04996481165289879
step: 480, loss: 0.03417978435754776
step: 490, loss: 0.04652433097362518
epoch 5: dev_f1=0.8340929808568824, f1=0.6666666666666667, best_f1=0.7733333333333333
step: 0, loss: 0.0568946972489357
step: 10, loss: 0.02701498009264469
step: 20, loss: 0.029622942209243774
step: 30, loss: 0.04859613999724388
step: 40, loss: 0.02555743418633938
step: 50, loss: 0.00433408422395587
step: 60, loss: 0.0020341158378869295
step: 70, loss: 0.029046010226011276
step: 80, loss: 0.0015823374269530177
step: 90, loss: 0.03553447872400284
step: 100, loss: 0.07244016975164413
step: 110, loss: 0.023457171395421028
step: 120, loss: 0.01390770822763443
step: 130, loss: 0.01806056872010231
step: 140, loss: 0.02852308377623558
step: 150, loss: 0.03869754448533058
step: 160, loss: 0.010469963774085045
step: 170, loss: 0.09453544020652771
step: 180, loss: 0.2031005322933197
step: 190, loss: 0.06991954892873764
step: 200, loss: 0.17062048614025116
step: 210, loss: 0.08376527577638626
step: 220, loss: 0.0069712866097688675
step: 230, loss: 0.1721290796995163
step: 240, loss: 0.13818144798278809
step: 250, loss: 0.30558308959007263
step: 260, loss: 0.21116819977760315
step: 270, loss: 0.08563105016946793
step: 280, loss: 0.031245343387126923
step: 290, loss: 0.036424342542886734
step: 300, loss: 0.0042967176996171474
step: 310, loss: 0.055335935205221176
step: 320, loss: 0.017055226489901543
step: 330, loss: 0.07446745783090591
step: 340, loss: 0.11285046488046646
step: 350, loss: 0.07236793637275696
step: 360, loss: 0.013772833161056042
step: 370, loss: 0.12399059534072876
step: 380, loss: 0.16194714605808258
step: 390, loss: 0.00750620337203145
step: 400, loss: 0.005726221948862076
step: 410, loss: 0.2333875596523285
step: 420, loss: 0.016053158789873123
step: 430, loss: 0.03264077752828598
step: 440, loss: 0.08526947349309921
step: 450, loss: 0.04638425260782242
step: 460, loss: 0.1344604194164276
step: 470, loss: 0.019905827939510345
step: 480, loss: 0.09343133866786957
step: 490, loss: 0.008942806161940098
epoch 6: dev_f1=0.8406961178045516, f1=0.6751652502360718, best_f1=0.7733333333333333
step: 0, loss: 0.05330578610301018
step: 10, loss: 0.009111146442592144
step: 20, loss: 0.005160152446478605
step: 30, loss: 0.019395405426621437
step: 40, loss: 0.0018240369390696287
step: 50, loss: 0.010301424190402031
step: 60, loss: 0.05944338068366051
step: 70, loss: 0.003059378592297435
step: 80, loss: 0.036495570093393326
step: 90, loss: 0.011235072277486324
step: 100, loss: 0.2481060028076172
step: 110, loss: 0.0201503187417984
step: 120, loss: 0.04217233136296272
step: 130, loss: 0.058317914605140686
step: 140, loss: 0.12205657362937927
step: 150, loss: 0.00327496905811131
step: 160, loss: 0.06709738820791245
step: 170, loss: 0.05301707237958908
step: 180, loss: 0.026040269061923027
step: 190, loss: 0.029644669964909554
step: 200, loss: 0.011638324707746506
step: 210, loss: 0.11465595662593842
step: 220, loss: 0.03398404270410538
step: 230, loss: 0.018425000831484795
step: 240, loss: 0.11057762801647186
step: 250, loss: 0.002734350971877575
step: 260, loss: 0.006192674860358238
step: 270, loss: 0.05797746777534485
step: 280, loss: 0.09847060590982437
step: 290, loss: 0.12505196034908295
step: 300, loss: 0.03339730203151703
step: 310, loss: 0.0013898232718929648
step: 320, loss: 0.059247154742479324
step: 330, loss: 0.0023379428312182426
step: 340, loss: 0.04460681229829788
step: 350, loss: 0.02263542264699936
step: 360, loss: 0.07542910426855087
step: 370, loss: 0.03958093374967575
step: 380, loss: 0.05783122777938843
step: 390, loss: 0.04760785773396492
step: 400, loss: 0.06711044162511826
step: 410, loss: 0.021079309284687042
step: 420, loss: 0.08591916412115097
step: 430, loss: 0.013308366760611534
step: 440, loss: 0.028191594406962395
step: 450, loss: 0.03135557472705841
step: 460, loss: 0.04934864118695259
step: 470, loss: 0.019582360982894897
step: 480, loss: 0.015284095890820026
step: 490, loss: 0.009503261186182499
epoch 7: dev_f1=0.8180242634315426, f1=0.6762075134168157, best_f1=0.7733333333333333
step: 0, loss: 0.08092118054628372
step: 10, loss: 0.0004907959373667836
step: 20, loss: 0.004686673171818256
step: 30, loss: 0.003017468610778451
step: 40, loss: 0.024948008358478546
step: 50, loss: 0.0006032706005498767
step: 60, loss: 0.02772635966539383
step: 70, loss: 0.0004618189122993499
step: 80, loss: 0.009524170309305191
step: 90, loss: 0.023257719352841377
step: 100, loss: 0.07015873491764069
step: 110, loss: 0.07682742178440094
step: 120, loss: 0.04680604860186577
step: 130, loss: 0.03260122612118721
step: 140, loss: 0.0005361468065530062
step: 150, loss: 0.0013906940585002303
step: 160, loss: 0.005359864793717861
step: 170, loss: 0.01224568486213684
step: 180, loss: 0.008856182917952538
step: 190, loss: 0.10587984323501587
step: 200, loss: 0.004392034374177456
step: 210, loss: 0.0008182909805327654
step: 220, loss: 0.02916647121310234
step: 230, loss: 0.08012118935585022
step: 240, loss: 0.011815955862402916
step: 250, loss: 0.04009835049510002
step: 260, loss: 0.012352540157735348
step: 270, loss: 0.006577831692993641
step: 280, loss: 0.00669693760573864
step: 290, loss: 0.007758837193250656
step: 300, loss: 0.015949392691254616
step: 310, loss: 0.0316573828458786
step: 320, loss: 0.1654690057039261
step: 330, loss: 0.1047762781381607
step: 340, loss: 0.0008862073300406337
step: 350, loss: 0.011989162303507328
step: 360, loss: 0.053918447345495224
step: 370, loss: 0.004740274511277676
step: 380, loss: 0.0057970695197582245
step: 390, loss: 0.06949122250080109
step: 400, loss: 0.041735727339982986
step: 410, loss: 0.013847405090928078
step: 420, loss: 0.006355908699333668
step: 430, loss: 0.06976313889026642
step: 440, loss: 0.011465175077319145
step: 450, loss: 0.025828907266259193
step: 460, loss: 0.014969932846724987
step: 470, loss: 0.12390479445457458
step: 480, loss: 0.007075243163853884
step: 490, loss: 0.058746546506881714
epoch 8: dev_f1=0.8371886120996442, f1=0.6688648139425342, best_f1=0.7733333333333333
step: 0, loss: 0.008512057363986969
step: 10, loss: 0.013294250704348087
step: 20, loss: 0.037546250969171524
step: 30, loss: 0.00888791959732771
step: 40, loss: 0.003155413083732128
step: 50, loss: 0.025117622688412666
step: 60, loss: 0.00177213444840163
step: 70, loss: 0.018473166972398758
step: 80, loss: 0.0349738709628582
step: 90, loss: 0.0022786289919167757
step: 100, loss: 0.08594837784767151
step: 110, loss: 0.0007723341113887727
step: 120, loss: 0.10240504890680313
step: 130, loss: 0.009179888293147087
step: 140, loss: 0.07703692466020584
step: 150, loss: 0.0006668565911240876
step: 160, loss: 0.09729956090450287
step: 170, loss: 0.06815611571073532
step: 180, loss: 0.0003792696224991232
step: 190, loss: 0.0347624309360981
step: 200, loss: 0.012995416298508644
step: 210, loss: 0.15024888515472412
step: 220, loss: 0.0009816351812332869
step: 230, loss: 0.010053729638457298
step: 240, loss: 0.0031824971083551645
step: 250, loss: 0.028550954535603523
step: 260, loss: 0.04406850039958954
step: 270, loss: 0.008053835481405258
step: 280, loss: 0.08839844912290573
step: 290, loss: 0.01202418189495802
step: 300, loss: 0.009506973437964916
step: 310, loss: 0.0044364044442772865
step: 320, loss: 0.0183018296957016
step: 330, loss: 0.04740943759679794
step: 340, loss: 0.019093304872512817
step: 350, loss: 0.006235742475837469
step: 360, loss: 0.0012950545642524958
step: 370, loss: 0.001665230724029243
step: 380, loss: 0.009780460968613625
step: 390, loss: 0.007727272808551788
step: 400, loss: 0.008924816735088825
step: 410, loss: 0.039832234382629395
step: 420, loss: 0.0010639633983373642
step: 430, loss: 0.006931399926543236
step: 440, loss: 0.037967339158058167
step: 450, loss: 0.01357138529419899
step: 460, loss: 0.06661031395196915
step: 470, loss: 0.05264447629451752
step: 480, loss: 0.0005567912012338638
step: 490, loss: 0.03375527635216713
epoch 9: dev_f1=0.8024158757549611, f1=0.639784946236559, best_f1=0.7733333333333333
step: 0, loss: 0.004191801883280277
step: 10, loss: 0.0012987364316359162
step: 20, loss: 0.002644782653078437
step: 30, loss: 0.04202685132622719
step: 40, loss: 0.005302828270941973
step: 50, loss: 0.01628641039133072
step: 60, loss: 0.0023063761182129383
step: 70, loss: 0.11745563894510269
step: 80, loss: 0.00044217705726623535
step: 90, loss: 0.08236870169639587
step: 100, loss: 0.06038951501250267
step: 110, loss: 0.026253795251250267
step: 120, loss: 0.00030930849607102573
step: 130, loss: 0.011304174549877644
step: 140, loss: 0.025542553514242172
step: 150, loss: 0.007799919229000807
step: 160, loss: 0.07067987322807312
step: 170, loss: 0.02055082842707634
step: 180, loss: 0.001772871590219438
step: 190, loss: 0.005772469099611044
step: 200, loss: 0.001490649301558733
step: 210, loss: 0.0071393344551324844
step: 220, loss: 0.00889343861490488
step: 230, loss: 0.010870200581848621
step: 240, loss: 0.026319414377212524
step: 250, loss: 0.05467623472213745
step: 260, loss: 0.016475070267915726
step: 270, loss: 0.0007339832372963428
step: 280, loss: 0.004087978508323431
step: 290, loss: 0.023554565384984016
step: 300, loss: 0.002552222926169634
step: 310, loss: 0.25014328956604004
step: 320, loss: 0.00048377623897977173
step: 330, loss: 0.010238753631711006
step: 340, loss: 0.0004540833760984242
step: 350, loss: 0.0031971349380910397
step: 360, loss: 0.06629209220409393
step: 370, loss: 0.0013325298205018044
step: 380, loss: 0.0029801258351653814
step: 390, loss: 0.018614787608385086
step: 400, loss: 0.0032175418455153704
step: 410, loss: 0.05741330236196518
step: 420, loss: 0.0066205160692334175
step: 430, loss: 0.002327206078916788
step: 440, loss: 0.0006209617131389678
step: 450, loss: 0.005504053086042404
step: 460, loss: 0.005357605405151844
step: 470, loss: 0.004889747593551874
step: 480, loss: 0.006728051695972681
step: 490, loss: 0.05215965583920479
epoch 10: dev_f1=0.8462255358807081, f1=0.6623634558093346, best_f1=0.7733333333333333
step: 0, loss: 0.005483522545546293
step: 10, loss: 0.008357740007340908
step: 20, loss: 0.011191285215318203
step: 30, loss: 0.019616080448031425
step: 40, loss: 0.00302664702758193
step: 50, loss: 0.002133105881512165
step: 60, loss: 0.02550935372710228
step: 70, loss: 0.0001594003551872447
step: 80, loss: 0.002383587649092078
step: 90, loss: 0.013508039526641369
step: 100, loss: 0.013848567381501198
step: 110, loss: 0.005838717333972454
step: 120, loss: 0.012880813330411911
step: 130, loss: 0.02424539439380169
step: 140, loss: 0.012815588153898716
step: 150, loss: 0.0017722210614010692
step: 160, loss: 0.0005485331639647484
step: 170, loss: 0.002032921416684985
step: 180, loss: 0.0004971895250491798
step: 190, loss: 0.015957923606038094
step: 200, loss: 0.0007411942933686078
step: 210, loss: 0.014392306096851826
step: 220, loss: 0.003853532252833247
step: 230, loss: 0.0007450171979144216
step: 240, loss: 0.01013226993381977
step: 250, loss: 0.03879532217979431
step: 260, loss: 0.029263198375701904
step: 270, loss: 0.18708691000938416
step: 280, loss: 0.017031189054250717
step: 290, loss: 0.00482146767899394
step: 300, loss: 0.04319082573056221
step: 310, loss: 0.0040514059364795685
step: 320, loss: 0.001334035536274314
step: 330, loss: 0.0019854228012263775
step: 340, loss: 0.0019500942435115576
step: 350, loss: 0.0018322853138670325
step: 360, loss: 0.0018683954840525985
step: 370, loss: 0.00041456552571617067
step: 380, loss: 0.00605016527697444
step: 390, loss: 0.033251453191041946
step: 400, loss: 0.010448004119098186
step: 410, loss: 0.0007441359339281917
step: 420, loss: 0.005129101686179638
step: 430, loss: 0.06462269276380539
step: 440, loss: 0.01202247105538845
step: 450, loss: 0.010548579506576061
step: 460, loss: 0.0001634833461139351
step: 470, loss: 0.00581237580627203
step: 480, loss: 0.01851869747042656
step: 490, loss: 0.012471807189285755
epoch 11: dev_f1=0.8506375227686702, f1=0.6776859504132232, best_f1=0.7733333333333333
step: 0, loss: 0.07893859595060349
step: 10, loss: 0.003155013080686331
step: 20, loss: 0.05908305570483208
step: 30, loss: 0.0035649321507662535
step: 40, loss: 0.021400941535830498
step: 50, loss: 0.000560443033464253
step: 60, loss: 0.0007414136198349297
step: 70, loss: 0.00011228245421079919
step: 80, loss: 0.00032372004352509975
step: 90, loss: 0.010974460281431675
step: 100, loss: 0.06578439474105835
step: 110, loss: 0.0007156619103625417
step: 120, loss: 0.004862762521952391
step: 130, loss: 0.0006287891883403063
step: 140, loss: 0.0017483144765719771
step: 150, loss: 0.03672708943486214
step: 160, loss: 0.001983008347451687
step: 170, loss: 4.373636329546571e-05
step: 180, loss: 0.06698422133922577
step: 190, loss: 0.002632510382682085
step: 200, loss: 0.001183337182737887
step: 210, loss: 0.0015515548875555396
step: 220, loss: 0.0007219616672955453
step: 230, loss: 0.0009032023372128606
step: 240, loss: 0.0007516213809140027
step: 250, loss: 0.00041328385123051703
step: 260, loss: 0.006601820699870586
step: 270, loss: 0.00047875166637822986
step: 280, loss: 0.004484310746192932
step: 290, loss: 0.0017459304071962833
step: 300, loss: 7.114816253306344e-05
step: 310, loss: 0.00011299631296424195
step: 320, loss: 0.05183248594403267
step: 330, loss: 0.0011002515675500035
step: 340, loss: 0.004470103420317173
step: 350, loss: 0.033110275864601135
step: 360, loss: 0.0030458380933851004
step: 370, loss: 0.00037980478373356164
step: 380, loss: 0.0013423656346276402
step: 390, loss: 0.07070187479257584
step: 400, loss: 0.002522167284041643
step: 410, loss: 0.0707128494977951
step: 420, loss: 0.0009141088812611997
step: 430, loss: 0.0006781242555007339
step: 440, loss: 0.09673605114221573
step: 450, loss: 0.0031305416487157345
step: 460, loss: 0.0011907849693670869
step: 470, loss: 0.0221390463411808
step: 480, loss: 0.028981536626815796
step: 490, loss: 0.00892173033207655
epoch 12: dev_f1=0.8334928229665072, f1=0.644137224782386, best_f1=0.7733333333333333
step: 0, loss: 0.0012996860314160585
step: 10, loss: 0.00046093013952486217
step: 20, loss: 0.006746566854417324
step: 30, loss: 0.00032852907315827906
step: 40, loss: 0.009942703880369663
step: 50, loss: 0.05911702662706375
step: 60, loss: 0.0038372615817934275
step: 70, loss: 0.0002881046093534678
step: 80, loss: 0.0011542332358658314
step: 90, loss: 0.005045867525041103
step: 100, loss: 0.00013291994400788099
step: 110, loss: 0.00028641015524044633
step: 120, loss: 0.0002726113598328084
step: 130, loss: 0.009566080756485462
step: 140, loss: 0.0033253999426960945
step: 150, loss: 0.0002768274862319231
step: 160, loss: 0.04211314767599106
step: 170, loss: 0.06810928881168365
step: 180, loss: 0.00021073361858725548
step: 190, loss: 0.0005916142254136503
step: 200, loss: 0.0002985561150126159
step: 210, loss: 0.0005591351655311882
step: 220, loss: 0.0010384807828813791
step: 230, loss: 0.0003387710894457996
step: 240, loss: 0.00017896243662107736
step: 250, loss: 0.0006858971319161355
step: 260, loss: 0.002436926821246743
step: 270, loss: 0.005838137585669756
step: 280, loss: 0.0008313710568472743
step: 290, loss: 0.020786721259355545
step: 300, loss: 0.009081786498427391
step: 310, loss: 0.0009040352306328714
step: 320, loss: 0.0012588518438860774
step: 330, loss: 0.0027517364360392094
step: 340, loss: 0.030776314437389374
step: 350, loss: 3.948339508497156e-05
step: 360, loss: 0.0009873432572931051
step: 370, loss: 0.027345238253474236
step: 380, loss: 0.00075796979945153
step: 390, loss: 0.0007848067325539887
step: 400, loss: 0.0024256715551018715
step: 410, loss: 0.0002074952208204195
step: 420, loss: 0.006808115169405937
step: 430, loss: 0.002086646156385541
step: 440, loss: 0.0037765062879770994
step: 450, loss: 0.0005868676817044616
step: 460, loss: 0.0001520064106443897
step: 470, loss: 0.007673920132219791
step: 480, loss: 0.012053659185767174
step: 490, loss: 0.00047756070853210986
epoch 13: dev_f1=0.8193218764514631, f1=0.6305418719211822, best_f1=0.7733333333333333
step: 0, loss: 8.50557626108639e-05
step: 10, loss: 5.102564682601951e-05
step: 20, loss: 9.421521826880053e-05
step: 30, loss: 0.005404419731348753
step: 40, loss: 0.03769058361649513
step: 50, loss: 0.00011108641774626449
step: 60, loss: 0.00023588689509779215
step: 70, loss: 0.00015016236284282058
step: 80, loss: 0.00012276625784579664
step: 90, loss: 0.00705476151779294
step: 100, loss: 0.0029303831979632378
step: 110, loss: 8.82325111888349e-05
step: 120, loss: 0.0011714552529156208
step: 130, loss: 0.0006118717137724161
step: 140, loss: 0.0013264566659927368
step: 150, loss: 0.0006090673268772662
step: 160, loss: 0.020775413140654564
step: 170, loss: 0.0012464041355997324
step: 180, loss: 0.007889621891081333
step: 190, loss: 0.0017485256539657712
step: 200, loss: 0.0007833951967768371
step: 210, loss: 0.0019160776864737272
step: 220, loss: 8.124519081320614e-05
step: 230, loss: 0.0074310265481472015
step: 240, loss: 0.0003826977626886219
step: 250, loss: 0.00023906439309939742
step: 260, loss: 0.00902367290109396
step: 270, loss: 0.0004877178289461881
step: 280, loss: 7.270638889167458e-05
step: 290, loss: 0.0005376411718316376
step: 300, loss: 0.00014693754201289266
step: 310, loss: 0.00043253719923086464
step: 320, loss: 0.0017364394152536988
step: 330, loss: 0.0029697101563215256
step: 340, loss: 0.0017225822666659951
step: 350, loss: 0.0005445285933092237
step: 360, loss: 0.0006122315535321832
step: 370, loss: 0.00011645074846455827
step: 380, loss: 0.00058693066239357
step: 390, loss: 0.0020899733062833548
step: 400, loss: 0.0009110018727369606
step: 410, loss: 0.006253919564187527
step: 420, loss: 0.00017798991757445037
step: 430, loss: 0.000126935206935741
step: 440, loss: 0.00010650832700775936
step: 450, loss: 0.033580370247364044
step: 460, loss: 0.024835797026753426
step: 470, loss: 0.07949983328580856
step: 480, loss: 0.0008939126273617148
step: 490, loss: 0.0009770485339686275
epoch 14: dev_f1=0.848927430397079, f1=0.6967252017085904, best_f1=0.7733333333333333
step: 0, loss: 0.0028354772366583347
step: 10, loss: 0.006313162390142679
step: 20, loss: 0.0002653975097928196
step: 30, loss: 0.006540199741721153
step: 40, loss: 0.02407957799732685
step: 50, loss: 0.00023190597130451351
step: 60, loss: 0.000526792835444212
step: 70, loss: 0.0003190679708495736
step: 80, loss: 0.0007113137980923057
step: 90, loss: 0.0008776502800174057
step: 100, loss: 0.0008926617447286844
step: 110, loss: 0.004030698444694281
step: 120, loss: 0.0017294528661295772
step: 130, loss: 5.8907105994876474e-05
step: 140, loss: 0.014310246333479881
step: 150, loss: 0.0004999430384486914
step: 160, loss: 0.00014925625873729587
step: 170, loss: 0.005059071816504002
step: 180, loss: 0.001226529129780829
step: 190, loss: 0.000144719539093785
step: 200, loss: 0.005053156986832619
step: 210, loss: 0.0017093735514208674
step: 220, loss: 6.078923252061941e-05
step: 230, loss: 0.013627966865897179
step: 240, loss: 0.0003170916170347482
step: 250, loss: 0.012219123542308807
step: 260, loss: 0.0002738863986451179
step: 270, loss: 0.01738792285323143
step: 280, loss: 0.00021912714873906225
step: 290, loss: 6.998805474722758e-05
step: 300, loss: 5.7123157603200525e-05
step: 310, loss: 0.0018678297055885196
step: 320, loss: 0.08699443936347961
step: 330, loss: 0.00018606912635732442
step: 340, loss: 0.00033469227491877973
step: 350, loss: 0.003409588010981679
step: 360, loss: 0.0003087511286139488
step: 370, loss: 0.004391311202198267
step: 380, loss: 0.002451431006193161
step: 390, loss: 0.00013655924703925848
step: 400, loss: 0.007603528909385204
step: 410, loss: 0.024033602327108383
step: 420, loss: 0.000928729132283479
step: 430, loss: 0.03813472017645836
step: 440, loss: 0.0005132866790518165
step: 450, loss: 0.0001894510060083121
step: 460, loss: 0.04587864503264427
step: 470, loss: 0.0017480440437793732
step: 480, loss: 0.0564291775226593
step: 490, loss: 0.00026484535192139447
epoch 15: dev_f1=0.8479477611940298, f1=0.6749379652605458, best_f1=0.7733333333333333
step: 0, loss: 0.0005605962360277772
step: 10, loss: 2.3021440938464366e-05
step: 20, loss: 0.0009130033431574702
step: 30, loss: 0.0008834628970362246
step: 40, loss: 0.03056086227297783
step: 50, loss: 0.0054339077323675156
step: 60, loss: 0.0005162341403774917
step: 70, loss: 5.3702467994298786e-05
step: 80, loss: 6.250030128285289e-05
step: 90, loss: 0.00015709063154645264
step: 100, loss: 0.03651122748851776
step: 110, loss: 0.0002689049288164824
step: 120, loss: 0.0012506645871326327
step: 130, loss: 0.00012529418745543808
step: 140, loss: 0.00016236689407378435
step: 150, loss: 0.002914676209911704
step: 160, loss: 0.028618013486266136
step: 170, loss: 0.00012736444477923214
step: 180, loss: 0.0001900432980619371
step: 190, loss: 0.13640671968460083
step: 200, loss: 0.0002998288255184889
step: 210, loss: 0.004601440392434597
step: 220, loss: 0.018415726721286774
step: 230, loss: 0.01250921655446291
step: 240, loss: 0.0002835150226019323
step: 250, loss: 0.0007261076825670898
step: 260, loss: 8.608849748270586e-05
step: 270, loss: 4.2524217860773206e-05
step: 280, loss: 5.7675493735587224e-05
step: 290, loss: 0.0002627478679642081
step: 300, loss: 4.890685886493884e-05
step: 310, loss: 0.0024403827264904976
step: 320, loss: 0.0002668005763553083
step: 330, loss: 0.014719830825924873
step: 340, loss: 0.00017775337619241327
step: 350, loss: 0.0001262666191905737
step: 360, loss: 9.822664287639782e-05
step: 370, loss: 0.0057296124286949635
step: 380, loss: 0.07097601145505905
step: 390, loss: 0.0021095778793096542
step: 400, loss: 0.012698470614850521
step: 410, loss: 0.0031531858257949352
step: 420, loss: 0.026632118970155716
step: 430, loss: 0.0024609556421637535
step: 440, loss: 0.00018288342107553035
step: 450, loss: 5.919827162870206e-05
step: 460, loss: 0.00290368078276515
step: 470, loss: 0.0007528496207669377
step: 480, loss: 0.0019094812450930476
step: 490, loss: 0.0007401456823572516
epoch 16: dev_f1=0.8190298507462686, f1=0.6502463054187193, best_f1=0.7733333333333333
step: 0, loss: 0.0021934921387583017
step: 10, loss: 0.021554866805672646
step: 20, loss: 0.00038517965003848076
step: 30, loss: 0.0029410887509584427
step: 40, loss: 0.0002854930644389242
step: 50, loss: 0.005583167541772127
step: 60, loss: 0.021312596276402473
step: 70, loss: 6.720246165059507e-05
step: 80, loss: 0.009256208315491676
step: 90, loss: 0.0066856746561825275
step: 100, loss: 0.0020535031799227
step: 110, loss: 4.1476578189758584e-05
step: 120, loss: 0.00017381169891450554
step: 130, loss: 0.005156359169632196
step: 140, loss: 0.0005073717911727726
step: 150, loss: 8.91029485501349e-05
step: 160, loss: 0.02464597299695015
step: 170, loss: 0.00011582135630305856
step: 180, loss: 0.012149238027632236
step: 190, loss: 0.0008848700090311468
step: 200, loss: 0.001551354886032641
step: 210, loss: 0.00012847413017880172
step: 220, loss: 0.00029483187245205045
step: 230, loss: 0.00015498798165936023
step: 240, loss: 3.757421291084029e-05
step: 250, loss: 7.805481436662376e-05
step: 260, loss: 9.249298454960808e-05
step: 270, loss: 0.0003558480821084231
step: 280, loss: 0.0014475565403699875
step: 290, loss: 0.00011093002103734761
step: 300, loss: 0.00013392677647061646
step: 310, loss: 0.001048646867275238
step: 320, loss: 0.0002684815553948283
step: 330, loss: 0.0003783987485803664
step: 340, loss: 0.03641179949045181
step: 350, loss: 0.00015045033069327474
step: 360, loss: 9.233641321770847e-05
step: 370, loss: 0.02084728144109249
step: 380, loss: 0.0006657428457401693
step: 390, loss: 0.011365026235580444
step: 400, loss: 0.049309100955724716
step: 410, loss: 0.00010191899491474032
step: 420, loss: 6.817996472818777e-05
step: 430, loss: 5.440261520561762e-05
step: 440, loss: 0.0001790950627764687
step: 450, loss: 0.0008065290749073029
step: 460, loss: 0.00016633262566756457
step: 470, loss: 8.249892562162131e-05
step: 480, loss: 0.0006993627175688744
step: 490, loss: 0.0010227230377495289
epoch 17: dev_f1=0.8182232346241458, f1=0.6574162679425838, best_f1=0.7733333333333333
step: 0, loss: 8.590686047682539e-05
step: 10, loss: 0.016496574506163597
step: 20, loss: 0.0002298561594216153
step: 30, loss: 3.0671457352582365e-05
step: 40, loss: 0.00026465943665243685
step: 50, loss: 0.002232450060546398
step: 60, loss: 0.023477703332901
step: 70, loss: 0.0005543766310438514
step: 80, loss: 0.000430265034083277
step: 90, loss: 0.005206723231822252
step: 100, loss: 8.744498336454853e-05
step: 110, loss: 0.00011046084546251222
step: 120, loss: 0.012731758877635002
step: 130, loss: 7.100736547727138e-05
step: 140, loss: 4.548935976345092e-05
step: 150, loss: 0.00011185559560544789
step: 160, loss: 0.02787979133427143
step: 170, loss: 9.037597192218527e-05
step: 180, loss: 0.00017421841039322317
step: 190, loss: 0.0008092016796581447
step: 200, loss: 0.00010078020568471402
step: 210, loss: 0.000255012622801587
step: 220, loss: 0.00010240809933748096
step: 230, loss: 0.0004333319957368076
step: 240, loss: 0.00020174476958345622
step: 250, loss: 0.010760152712464333
step: 260, loss: 0.014170840382575989
step: 270, loss: 0.0001224330480908975
step: 280, loss: 0.002172882901504636
step: 290, loss: 0.0014800948556512594
step: 300, loss: 0.0006147152162156999
step: 310, loss: 0.00019406626233831048
step: 320, loss: 0.00010472472058609128
step: 330, loss: 5.0252834626007825e-05
step: 340, loss: 0.04350738227367401
step: 350, loss: 0.0007781352032907307
step: 360, loss: 0.0009179685730487108
step: 370, loss: 0.0024158302694559097
step: 380, loss: 0.00011241864558542147
step: 390, loss: 0.00019986620463896543
step: 400, loss: 0.00014951832417864352
step: 410, loss: 0.000899838749319315
step: 420, loss: 0.00024299044162034988
step: 430, loss: 7.574657502118498e-05
step: 440, loss: 0.00020230640075169504
step: 450, loss: 0.00613365788012743
step: 460, loss: 0.00012555523426271975
step: 470, loss: 0.0009600314660929143
step: 480, loss: 0.0009156276937574148
step: 490, loss: 0.0029959373641759157
epoch 18: dev_f1=0.8333333333333334, f1=0.6545454545454547, best_f1=0.7733333333333333
step: 0, loss: 0.00014317543536890298
step: 10, loss: 0.0003781265113502741
step: 20, loss: 0.00011328221444273368
step: 30, loss: 0.00023132990463636816
step: 40, loss: 0.0017922427505254745
step: 50, loss: 0.0008222172036767006
step: 60, loss: 0.0001420270127709955
step: 70, loss: 0.00021693226881325245
step: 80, loss: 0.015156942419707775
step: 90, loss: 8.033077756408602e-05
step: 100, loss: 2.550644967413973e-05
step: 110, loss: 0.00015798956155776978
step: 120, loss: 3.973798447987065e-05
step: 130, loss: 4.5678665628656745e-05
step: 140, loss: 0.0003762721607927233
step: 150, loss: 0.013989477418363094
step: 160, loss: 0.0003264180268160999
step: 170, loss: 4.6121247578412294e-05
step: 180, loss: 0.00019437067385297269
step: 190, loss: 4.418229218572378e-05
step: 200, loss: 0.0017954803770408034
step: 210, loss: 0.0010867657838389277
step: 220, loss: 0.000258865999057889
step: 230, loss: 8.945469016907737e-05
step: 240, loss: 0.00013990906882099807
step: 250, loss: 2.431413122394588e-05
step: 260, loss: 0.0004277041007298976
step: 270, loss: 0.0005629367078654468
step: 280, loss: 6.770390609744936e-05
step: 290, loss: 0.0055855512619018555
step: 300, loss: 4.7244382585631683e-05
step: 310, loss: 0.00017526806914247572
step: 320, loss: 3.837189797195606e-05
step: 330, loss: 0.00012048040662193671
step: 340, loss: 0.00011301428457954898
step: 350, loss: 5.1834711484843865e-05
step: 360, loss: 6.66807172819972e-05
step: 370, loss: 0.0015908314380794764
step: 380, loss: 0.0013555791229009628
step: 390, loss: 0.004587139468640089
step: 400, loss: 2.8322445359663107e-05
step: 410, loss: 0.0001806048967409879
step: 420, loss: 0.00426115607842803
step: 430, loss: 0.00012029064237140119
step: 440, loss: 0.00026701242313720286
step: 450, loss: 0.0005425402196124196
step: 460, loss: 0.0009494356927461922
step: 470, loss: 0.00012147275265306234
step: 480, loss: 3.901600939570926e-05
step: 490, loss: 3.734733763849363e-05
epoch 19: dev_f1=0.8324175824175823, f1=0.6592341250605914, best_f1=0.7733333333333333
step: 0, loss: 6.863084126962349e-05
step: 10, loss: 6.927041249582544e-05
step: 20, loss: 0.00010957118502119556
step: 30, loss: 0.00018832928617484868
step: 40, loss: 6.605726957786828e-05
step: 50, loss: 0.00129496562294662
step: 60, loss: 7.599391392432153e-05
step: 70, loss: 0.023702194914221764
step: 80, loss: 3.388965706108138e-05
step: 90, loss: 0.004778524395078421
step: 100, loss: 0.0001636393863009289
step: 110, loss: 2.9331638870644383e-05
step: 120, loss: 0.0011033039772883058
step: 130, loss: 3.8952446629991755e-05
step: 140, loss: 0.0014950510812923312
step: 150, loss: 0.001209199195727706
step: 160, loss: 4.2972806113539264e-05
step: 170, loss: 0.00015535038255620748
step: 180, loss: 5.71890632272698e-05
step: 190, loss: 0.00041970823076553643
step: 200, loss: 0.00649371650069952
step: 210, loss: 0.0015432729851454496
step: 220, loss: 0.0001657283864915371
step: 230, loss: 4.550087032839656e-05
step: 240, loss: 0.00021127171930857003
step: 250, loss: 3.6051656934432685e-05
step: 260, loss: 0.0004052474978379905
step: 270, loss: 0.046500883996486664
step: 280, loss: 0.00030240879277698696
step: 290, loss: 0.0008006708230823278
step: 300, loss: 0.01454281434416771
step: 310, loss: 4.933074160362594e-05
step: 320, loss: 0.00017916255455929786
step: 330, loss: 4.302347224438563e-05
step: 340, loss: 0.004800084978342056
step: 350, loss: 0.0015339052770286798
step: 360, loss: 0.00015803244605194777
step: 370, loss: 0.00044515496119856834
step: 380, loss: 2.144985592167359e-05
step: 390, loss: 3.7070280086481944e-05
step: 400, loss: 0.0005385944969020784
step: 410, loss: 2.887690243369434e-05
step: 420, loss: 0.0003831285866908729
step: 430, loss: 6.885787297505885e-05
step: 440, loss: 7.435648876708001e-05
step: 450, loss: 0.0004256097017787397
step: 460, loss: 0.0009209548006765544
step: 470, loss: 2.0414096070453525e-05
step: 480, loss: 0.0013551759766414762
step: 490, loss: 0.022740263491868973
epoch 20: dev_f1=0.8306010928961749, f1=0.6618635926993276, best_f1=0.7733333333333333
