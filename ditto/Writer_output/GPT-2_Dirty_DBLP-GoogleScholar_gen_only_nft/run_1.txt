cuda
Device: cuda
step: 0, loss: 0.725701630115509
step: 10, loss: 0.5900331735610962
step: 20, loss: 0.4948883056640625
step: 30, loss: 0.3534712791442871
step: 40, loss: 0.4741235375404358
step: 50, loss: 0.3387729525566101
step: 60, loss: 0.4835875630378723
step: 70, loss: 0.44760817289352417
step: 80, loss: 0.34026482701301575
step: 90, loss: 0.28792309761047363
step: 100, loss: 0.2759595215320587
step: 110, loss: 0.37593647837638855
step: 120, loss: 0.8477311134338379
step: 130, loss: 0.43498173356056213
step: 140, loss: 0.3160476088523865
step: 150, loss: 0.4508287310600281
step: 160, loss: 0.29928725957870483
step: 170, loss: 0.2879144549369812
step: 180, loss: 0.3279365301132202
step: 190, loss: 0.5694441795349121
step: 200, loss: 0.26066848635673523
step: 210, loss: 0.34771373867988586
step: 220, loss: 0.254004567861557
step: 230, loss: 0.3589852750301361
step: 240, loss: 0.3033800721168518
step: 250, loss: 0.1814926713705063
step: 260, loss: 0.062395740300416946
step: 270, loss: 0.26136109232902527
step: 280, loss: 0.5090948939323425
step: 290, loss: 0.30220288038253784
step: 300, loss: 0.35988807678222656
step: 310, loss: 0.33751535415649414
step: 320, loss: 0.2594403624534607
step: 330, loss: 0.468371719121933
step: 340, loss: 0.32206234335899353
step: 350, loss: 0.22922652959823608
step: 360, loss: 0.40336889028549194
step: 370, loss: 0.4420706331729889
step: 380, loss: 0.35880246758461
step: 390, loss: 0.30416053533554077
step: 400, loss: 0.14727681875228882
step: 410, loss: 0.2392227053642273
epoch 1: dev_f1=0.8511235955056179, f1=0.7938638542665388, best_f1=0.7938638542665388
step: 0, loss: 0.14330627024173737
step: 10, loss: 0.22666816413402557
step: 20, loss: 0.280671626329422
step: 30, loss: 0.1384274959564209
step: 40, loss: 0.3911837935447693
step: 50, loss: 0.09063006937503815
step: 60, loss: 0.3165363073348999
step: 70, loss: 0.3663548529148102
step: 80, loss: 0.23546048998832703
step: 90, loss: 0.23584531247615814
step: 100, loss: 0.26685577630996704
step: 110, loss: 0.21154984831809998
step: 120, loss: 0.2523263692855835
step: 130, loss: 0.20866769552230835
step: 140, loss: 0.2581651508808136
step: 150, loss: 0.4775654375553131
step: 160, loss: 0.27309367060661316
step: 170, loss: 0.21774311363697052
step: 180, loss: 0.1277822107076645
step: 190, loss: 0.16664175689220428
step: 200, loss: 0.2504110336303711
step: 210, loss: 0.24765440821647644
step: 220, loss: 0.18460777401924133
step: 230, loss: 0.15755484998226166
step: 240, loss: 0.17022141814231873
step: 250, loss: 0.20108044147491455
step: 260, loss: 0.1818230003118515
step: 270, loss: 0.17895421385765076
step: 280, loss: 0.41154617071151733
step: 290, loss: 0.39245378971099854
step: 300, loss: 0.28920677304267883
step: 310, loss: 0.3116121292114258
step: 320, loss: 0.3475313186645508
step: 330, loss: 0.3938027024269104
step: 340, loss: 0.19433344900608063
step: 350, loss: 0.2749905288219452
step: 360, loss: 0.3241211175918579
step: 370, loss: 0.24505534768104553
step: 380, loss: 0.37586066126823425
step: 390, loss: 0.12999819219112396
step: 400, loss: 0.2145034521818161
step: 410, loss: 0.27712738513946533
epoch 2: dev_f1=0.8455988455988455, f1=0.719262295081967, best_f1=0.7938638542665388
step: 0, loss: 0.22067131102085114
step: 10, loss: 0.19545726478099823
step: 20, loss: 0.11940748989582062
step: 30, loss: 0.06411737948656082
step: 40, loss: 0.10330571979284286
step: 50, loss: 0.18134482204914093
step: 60, loss: 0.13473089039325714
step: 70, loss: 0.04874666407704353
step: 80, loss: 0.18964087963104248
step: 90, loss: 0.07804631441831589
step: 100, loss: 0.1731289029121399
step: 110, loss: 0.19943827390670776
step: 120, loss: 0.15636391937732697
step: 130, loss: 0.150678351521492
step: 140, loss: 0.061853326857089996
step: 150, loss: 0.20219381153583527
step: 160, loss: 0.16848130524158478
step: 170, loss: 0.21153968572616577
step: 180, loss: 0.279649943113327
step: 190, loss: 0.244747132062912
step: 200, loss: 0.17294804751873016
step: 210, loss: 0.13759931921958923
step: 220, loss: 0.14662787318229675
step: 230, loss: 0.16127067804336548
step: 240, loss: 0.20334845781326294
step: 250, loss: 0.3266112208366394
step: 260, loss: 0.10636593401432037
step: 270, loss: 0.272941917181015
step: 280, loss: 0.25735071301460266
step: 290, loss: 0.1636011153459549
step: 300, loss: 0.21770301461219788
step: 310, loss: 0.34484899044036865
step: 320, loss: 0.1802225112915039
step: 330, loss: 0.2513284683227539
step: 340, loss: 0.1010766476392746
step: 350, loss: 0.18107770383358002
step: 360, loss: 0.06635192036628723
step: 370, loss: 0.23944230377674103
step: 380, loss: 0.08749999105930328
step: 390, loss: 0.34810152649879456
step: 400, loss: 0.1847168207168579
step: 410, loss: 0.4478148818016052
epoch 3: dev_f1=0.847922192749779, f1=0.7350661194710443, best_f1=0.7938638542665388
step: 0, loss: 0.05338091030716896
step: 10, loss: 0.045400869101285934
step: 20, loss: 0.01693415455520153
step: 30, loss: 0.06885449588298798
step: 40, loss: 0.14373984932899475
step: 50, loss: 0.48797786235809326
step: 60, loss: 0.050598934292793274
step: 70, loss: 0.1599891483783722
step: 80, loss: 0.085472971200943
step: 90, loss: 0.19276955723762512
step: 100, loss: 0.05474356561899185
step: 110, loss: 0.2673305571079254
step: 120, loss: 0.06763015687465668
step: 130, loss: 0.09186107665300369
step: 140, loss: 0.06976823508739471
step: 150, loss: 0.2643333971500397
step: 160, loss: 0.12366311997175217
step: 170, loss: 0.0348484180867672
step: 180, loss: 0.051115963608026505
step: 190, loss: 0.32540324330329895
step: 200, loss: 0.10295891761779785
step: 210, loss: 0.06413841992616653
step: 220, loss: 0.1681796759366989
step: 230, loss: 0.111528679728508
step: 240, loss: 0.028019443154335022
step: 250, loss: 0.18719348311424255
step: 260, loss: 0.0983777567744255
step: 270, loss: 0.12327753007411957
step: 280, loss: 0.2571733295917511
step: 290, loss: 0.11682199686765671
step: 300, loss: 0.20034395158290863
step: 310, loss: 0.0668589174747467
step: 320, loss: 0.19463220238685608
step: 330, loss: 0.05776708573102951
step: 340, loss: 0.07554592192173004
step: 350, loss: 0.07072705030441284
step: 360, loss: 0.2231115698814392
step: 370, loss: 0.15529653429985046
step: 380, loss: 0.0682835504412651
step: 390, loss: 0.10392127931118011
step: 400, loss: 0.05244576558470726
step: 410, loss: 0.02742672525346279
epoch 4: dev_f1=0.8631484794275492, f1=0.729245283018868, best_f1=0.729245283018868
step: 0, loss: 0.04707450792193413
step: 10, loss: 0.08163648843765259
step: 20, loss: 0.028553849086165428
step: 30, loss: 0.16583161056041718
step: 40, loss: 0.0833510011434555
step: 50, loss: 0.19401612877845764
step: 60, loss: 0.05643514171242714
step: 70, loss: 0.1106603667140007
step: 80, loss: 0.10634376108646393
step: 90, loss: 0.060710564255714417
step: 100, loss: 0.048949677497148514
step: 110, loss: 0.03664661943912506
step: 120, loss: 0.2256847321987152
step: 130, loss: 0.03752557933330536
step: 140, loss: 0.12197574228048325
step: 150, loss: 0.08720037341117859
step: 160, loss: 0.04168110713362694
step: 170, loss: 0.11331784725189209
step: 180, loss: 0.12119103223085403
step: 190, loss: 0.1414225846529007
step: 200, loss: 0.04522264748811722
step: 210, loss: 0.05709516257047653
step: 220, loss: 0.20287394523620605
step: 230, loss: 0.06703101843595505
step: 240, loss: 0.026978321373462677
step: 250, loss: 0.2216891050338745
step: 260, loss: 0.06638999283313751
step: 270, loss: 0.17583490908145905
step: 280, loss: 0.1031719446182251
step: 290, loss: 0.05355266109108925
step: 300, loss: 0.11516892164945602
step: 310, loss: 0.0762825757265091
step: 320, loss: 0.08072000741958618
step: 330, loss: 0.04800295829772949
step: 340, loss: 0.05078497156500816
step: 350, loss: 0.08402343094348907
step: 360, loss: 0.02668219432234764
step: 370, loss: 0.0610177181661129
step: 380, loss: 0.06495986133813858
step: 390, loss: 0.05700681731104851
step: 400, loss: 0.1655513048171997
step: 410, loss: 0.027882186695933342
epoch 5: dev_f1=0.8418181818181819, f1=0.6880076445293837, best_f1=0.729245283018868
step: 0, loss: 0.04207015782594681
step: 10, loss: 0.027792207896709442
step: 20, loss: 0.09524107724428177
step: 30, loss: 0.03176932781934738
step: 40, loss: 0.02682492695748806
step: 50, loss: 0.07833875715732574
step: 60, loss: 0.09549463540315628
step: 70, loss: 0.04884215444326401
step: 80, loss: 0.04231307655572891
step: 90, loss: 0.024402890354394913
step: 100, loss: 0.11769327521324158
step: 110, loss: 0.017069533467292786
step: 120, loss: 0.08018101751804352
step: 130, loss: 0.07156486809253693
step: 140, loss: 0.14511865377426147
step: 150, loss: 0.06697217375040054
step: 160, loss: 0.12736958265304565
step: 170, loss: 0.08203831315040588
step: 180, loss: 0.060131512582302094
step: 190, loss: 0.04017753154039383
step: 200, loss: 0.04300020635128021
step: 210, loss: 0.20966656506061554
step: 220, loss: 0.07724417746067047
step: 230, loss: 0.051795244216918945
step: 240, loss: 0.0329132117331028
step: 250, loss: 0.036240894347429276
step: 260, loss: 0.03455040603876114
step: 270, loss: 0.127291738986969
step: 280, loss: 0.051695454865694046
step: 290, loss: 0.055714067071676254
step: 300, loss: 0.10024650394916534
step: 310, loss: 0.056247126311063766
step: 320, loss: 0.07784553617238998
step: 330, loss: 0.061059366911649704
step: 340, loss: 0.11031500995159149
step: 350, loss: 0.12721467018127441
step: 360, loss: 0.06565477699041367
step: 370, loss: 0.028131656348705292
step: 380, loss: 0.1766524761915207
step: 390, loss: 0.250549852848053
step: 400, loss: 0.02381085604429245
step: 410, loss: 0.06527768075466156
epoch 6: dev_f1=0.8260089686098654, f1=0.6774500475737394, best_f1=0.729245283018868
step: 0, loss: 0.026537446305155754
step: 10, loss: 0.06761425733566284
step: 20, loss: 0.014121982268989086
step: 30, loss: 0.006802810821682215
step: 40, loss: 0.017132490873336792
step: 50, loss: 0.01607576012611389
step: 60, loss: 0.01187004055827856
step: 70, loss: 0.012161990627646446
step: 80, loss: 0.049256108701229095
step: 90, loss: 0.03560204431414604
step: 100, loss: 0.04443805292248726
step: 110, loss: 0.024014493450522423
step: 120, loss: 0.08640280365943909
step: 130, loss: 0.046680595725774765
step: 140, loss: 0.025736605748534203
step: 150, loss: 0.08014446496963501
step: 160, loss: 0.005039549898356199
step: 170, loss: 0.036190688610076904
step: 180, loss: 0.010598897002637386
step: 190, loss: 0.014586888253688812
step: 200, loss: 0.0555691197514534
step: 210, loss: 0.003213840536773205
step: 220, loss: 0.18511611223220825
step: 230, loss: 0.10722610354423523
step: 240, loss: 0.11366386711597443
step: 250, loss: 0.053866490721702576
step: 260, loss: 0.008002380840480328
step: 270, loss: 0.017719276249408722
step: 280, loss: 0.018055859953165054
step: 290, loss: 0.04799295589327812
step: 300, loss: 0.00338386045768857
step: 310, loss: 0.11402131617069244
step: 320, loss: 0.004878262057900429
step: 330, loss: 0.16488325595855713
step: 340, loss: 0.0302866380661726
step: 350, loss: 0.01032006461173296
step: 360, loss: 0.02682805247604847
step: 370, loss: 0.018783416599035263
step: 380, loss: 0.013122914358973503
step: 390, loss: 0.028318973258137703
step: 400, loss: 0.010986587032675743
step: 410, loss: 0.0920005738735199
epoch 7: dev_f1=0.8431808085295425, f1=0.6947069943289226, best_f1=0.729245283018868
step: 0, loss: 0.004859317094087601
step: 10, loss: 0.012323065660893917
step: 20, loss: 0.10816437751054764
step: 30, loss: 0.0061264606192708015
step: 40, loss: 0.018066395074129105
step: 50, loss: 0.011013493873178959
step: 60, loss: 0.002042160602286458
step: 70, loss: 0.05357237532734871
step: 80, loss: 0.054816462099552155
step: 90, loss: 0.15883933007717133
step: 100, loss: 0.004258883185684681
step: 110, loss: 0.050405558198690414
step: 120, loss: 0.02821926958858967
step: 130, loss: 0.06361588090658188
step: 140, loss: 0.008728555403649807
step: 150, loss: 0.00708769541233778
step: 160, loss: 0.11149395257234573
step: 170, loss: 0.0656699389219284
step: 180, loss: 0.07509609311819077
step: 190, loss: 0.19886164367198944
step: 200, loss: 0.004036590922623873
step: 210, loss: 0.036085646599531174
step: 220, loss: 0.05629834160208702
step: 230, loss: 0.007944880053400993
step: 240, loss: 0.011289771646261215
step: 250, loss: 0.016404060646891594
step: 260, loss: 0.009037981741130352
step: 270, loss: 0.015774885192513466
step: 280, loss: 0.08106793463230133
step: 290, loss: 0.0757487490773201
step: 300, loss: 0.014744610525667667
step: 310, loss: 0.013557810336351395
step: 320, loss: 0.006880881730467081
step: 330, loss: 0.024602247402071953
step: 340, loss: 0.020355980843305588
step: 350, loss: 0.040940944105386734
step: 360, loss: 0.04630009084939957
step: 370, loss: 0.10585729032754898
step: 380, loss: 0.1749267727136612
step: 390, loss: 0.020583514124155045
step: 400, loss: 0.013400119729340076
step: 410, loss: 0.24044691026210785
epoch 8: dev_f1=0.8428635749662313, f1=0.6991869918699187, best_f1=0.729245283018868
step: 0, loss: 0.030758174136281013
step: 10, loss: 0.011723079718649387
step: 20, loss: 0.004242567345499992
step: 30, loss: 0.011812204495072365
step: 40, loss: 0.08363180607557297
step: 50, loss: 0.004048107657581568
step: 60, loss: 0.0508304201066494
step: 70, loss: 0.00759543152526021
step: 80, loss: 0.08720413595438004
step: 90, loss: 0.00787191092967987
step: 100, loss: 0.047382891178131104
step: 110, loss: 0.1055334061384201
step: 120, loss: 0.0035080849193036556
step: 130, loss: 0.003803777042776346
step: 140, loss: 0.041388191282749176
step: 150, loss: 0.012609921395778656
step: 160, loss: 0.04354015737771988
step: 170, loss: 0.024802055209875107
step: 180, loss: 0.00047461179201491177
step: 190, loss: 0.009618689306080341
step: 200, loss: 0.021234318614006042
step: 210, loss: 0.014209299348294735
step: 220, loss: 0.03198728337883949
step: 230, loss: 0.006395142991095781
step: 240, loss: 0.04237663000822067
step: 250, loss: 0.010880907997488976
step: 260, loss: 0.008334723301231861
step: 270, loss: 0.0008997829863801599
step: 280, loss: 0.048852257430553436
step: 290, loss: 0.02954118885099888
step: 300, loss: 0.0066995094530284405
step: 310, loss: 0.0030458029359579086
step: 320, loss: 0.005999228451400995
step: 330, loss: 0.0012682867236435413
step: 340, loss: 0.04979809373617172
step: 350, loss: 0.0014052129117771983
step: 360, loss: 0.010776096023619175
step: 370, loss: 0.005952170584350824
step: 380, loss: 0.008645860478281975
step: 390, loss: 0.039593543857336044
step: 400, loss: 0.002107191365212202
step: 410, loss: 0.0002182112802984193
epoch 9: dev_f1=0.8148796498905909, f1=0.6794171220400729, best_f1=0.729245283018868
step: 0, loss: 0.008069073781371117
step: 10, loss: 0.0005379859358072281
step: 20, loss: 0.022458741441369057
step: 30, loss: 0.003998313564807177
step: 40, loss: 0.020338350906968117
step: 50, loss: 0.03813574090600014
step: 60, loss: 0.021190861240029335
step: 70, loss: 0.026886658743023872
step: 80, loss: 0.009161747992038727
step: 90, loss: 0.013921363279223442
step: 100, loss: 0.0074896556325256824
step: 110, loss: 0.13969585299491882
step: 120, loss: 0.0035794146824628115
step: 130, loss: 0.044058218598365784
step: 140, loss: 0.10575729608535767
step: 150, loss: 0.006276831962168217
step: 160, loss: 0.016503751277923584
step: 170, loss: 0.00831904448568821
step: 180, loss: 0.004673535469919443
step: 190, loss: 0.021425092592835426
step: 200, loss: 0.002641387050971389
step: 210, loss: 0.0047231074422597885
step: 220, loss: 0.00851747952401638
step: 230, loss: 0.06094701588153839
step: 240, loss: 0.005671392660588026
step: 250, loss: 0.03999446704983711
step: 260, loss: 0.001698467880487442
step: 270, loss: 0.0009323228150606155
step: 280, loss: 0.0026636915281414986
step: 290, loss: 0.09212426841259003
step: 300, loss: 0.10517691820859909
step: 310, loss: 0.007398098707199097
step: 320, loss: 0.004307862836867571
step: 330, loss: 0.049028430134058
step: 340, loss: 0.14417840540409088
step: 350, loss: 0.0615529865026474
step: 360, loss: 0.0008717509917914867
step: 370, loss: 0.04219454154372215
step: 380, loss: 0.007127381861209869
step: 390, loss: 0.120513916015625
step: 400, loss: 0.004019506275653839
step: 410, loss: 0.0006397537072189152
epoch 10: dev_f1=0.8151041666666666, f1=0.6790067720090293, best_f1=0.729245283018868
step: 0, loss: 0.033993154764175415
step: 10, loss: 0.0014222207246348262
step: 20, loss: 0.0010350660886615515
step: 30, loss: 0.005689006764441729
step: 40, loss: 0.003604363417252898
step: 50, loss: 0.0009481182205490768
step: 60, loss: 0.004647527355700731
step: 70, loss: 0.0019935653544962406
step: 80, loss: 0.0004327204660512507
step: 90, loss: 0.00862763449549675
step: 100, loss: 0.002927689114585519
step: 110, loss: 0.04276184365153313
step: 120, loss: 0.0031237660441547632
step: 130, loss: 0.11571640521287918
step: 140, loss: 0.1165827214717865
step: 150, loss: 0.004857586231082678
step: 160, loss: 0.0033895408269017935
step: 170, loss: 0.019158465787768364
step: 180, loss: 0.00025078735779970884
step: 190, loss: 0.003610657760873437
step: 200, loss: 0.007881092838943005
step: 210, loss: 0.08879801630973816
step: 220, loss: 0.0004712862428277731
step: 230, loss: 0.03077692911028862
step: 240, loss: 0.031126948073506355
step: 250, loss: 0.0007190763135440648
step: 260, loss: 0.05195004865527153
step: 270, loss: 0.007914181798696518
step: 280, loss: 0.0013324021128937602
step: 290, loss: 0.00048044411232694983
step: 300, loss: 0.020952805876731873
step: 310, loss: 0.0002553460362832993
step: 320, loss: 0.0020864317193627357
step: 330, loss: 0.003340405412018299
step: 340, loss: 0.00017697217117529362
step: 350, loss: 0.0006432649097405374
step: 360, loss: 0.00031391138327308
step: 370, loss: 0.0023588950280100107
step: 380, loss: 0.03502749651670456
step: 390, loss: 0.00507384492084384
step: 400, loss: 0.0008687696536071599
step: 410, loss: 0.06521318852901459
epoch 11: dev_f1=0.8577878103837472, f1=0.7258834765998088, best_f1=0.729245283018868
step: 0, loss: 0.007164621725678444
step: 10, loss: 0.003033873625099659
step: 20, loss: 0.12839269638061523
step: 30, loss: 0.0027439971454441547
step: 40, loss: 0.12120354175567627
step: 50, loss: 0.0033700664062052965
step: 60, loss: 0.021093197166919708
step: 70, loss: 0.004213192965835333
step: 80, loss: 0.026842689141631126
step: 90, loss: 0.0020664071198552847
step: 100, loss: 0.021926211193203926
step: 110, loss: 0.0019737770780920982
step: 120, loss: 0.0005439721280708909
step: 130, loss: 0.0005596755654551089
step: 140, loss: 0.01720231957733631
step: 150, loss: 0.00039401990943588316
step: 160, loss: 0.0011149811325594783
step: 170, loss: 0.0019176746718585491
step: 180, loss: 0.0014398309867829084
step: 190, loss: 0.0007800321327522397
step: 200, loss: 0.0008194821421056986
step: 210, loss: 0.004705030471086502
step: 220, loss: 0.0009854886448010802
step: 230, loss: 0.006897070445120335
step: 240, loss: 0.002054587472230196
step: 250, loss: 0.018371736630797386
step: 260, loss: 0.016522299498319626
step: 270, loss: 0.0024865693412721157
step: 280, loss: 0.04432066157460213
step: 290, loss: 0.004651335533708334
step: 300, loss: 0.11041294038295746
step: 310, loss: 0.0016744063468649983
step: 320, loss: 0.016784749925136566
step: 330, loss: 0.08310748636722565
step: 340, loss: 0.017566081136465073
step: 350, loss: 0.00788300670683384
step: 360, loss: 0.007370384875684977
step: 370, loss: 0.06630618125200272
step: 380, loss: 0.038790807127952576
step: 390, loss: 0.024157483130693436
step: 400, loss: 0.002947213128209114
step: 410, loss: 0.0002613308315631002
epoch 12: dev_f1=0.8417749887942626, f1=0.7037565382786495, best_f1=0.729245283018868
step: 0, loss: 0.010366169735789299
step: 10, loss: 0.004745934158563614
step: 20, loss: 0.005065929610282183
step: 30, loss: 0.011588255874812603
step: 40, loss: 0.00018816448573488742
step: 50, loss: 0.008642592467367649
step: 60, loss: 0.0004366554203443229
step: 70, loss: 0.0024788647424429655
step: 80, loss: 0.0031011535320430994
step: 90, loss: 0.00028735515661537647
step: 100, loss: 0.0004033028380945325
step: 110, loss: 0.002216173568740487
step: 120, loss: 0.0003147265233565122
step: 130, loss: 0.047611020505428314
step: 140, loss: 0.0009454396786168218
step: 150, loss: 0.00043732195626944304
step: 160, loss: 0.0011844211257994175
step: 170, loss: 0.006412110757082701
step: 180, loss: 7.216852100100368e-05
step: 190, loss: 0.0006786150042898953
step: 200, loss: 0.045093655586242676
step: 210, loss: 0.0007412813720293343
step: 220, loss: 0.009833249263465405
step: 230, loss: 0.0012705938424915075
step: 240, loss: 0.00025805365294218063
step: 250, loss: 0.0004336973070167005
step: 260, loss: 0.0005851737223565578
step: 270, loss: 0.0004521683731582016
step: 280, loss: 0.03386642038822174
step: 290, loss: 0.0003271761233918369
step: 300, loss: 0.047582030296325684
step: 310, loss: 0.02379186823964119
step: 320, loss: 0.0014898886438459158
step: 330, loss: 0.0004436190356500447
step: 340, loss: 0.0029678528662770987
step: 350, loss: 0.002885444788262248
step: 360, loss: 0.03160954266786575
step: 370, loss: 0.06425396353006363
step: 380, loss: 0.0002646877837833017
step: 390, loss: 0.0011261936742812395
step: 400, loss: 0.0003520906902849674
step: 410, loss: 0.0009408186888322234
epoch 13: dev_f1=0.8173836698858649, f1=0.670299727520436, best_f1=0.729245283018868
step: 0, loss: 0.0009663563105277717
step: 10, loss: 0.0007388619123958051
step: 20, loss: 0.018239540979266167
step: 30, loss: 0.003990659490227699
step: 40, loss: 0.0001614870416233316
step: 50, loss: 0.009349570609629154
step: 60, loss: 0.0017763117793947458
step: 70, loss: 0.00039659818867221475
step: 80, loss: 0.0012455829419195652
step: 90, loss: 0.024233102798461914
step: 100, loss: 0.01526834536343813
step: 110, loss: 0.0010566014098003507
step: 120, loss: 0.0007097694324329495
step: 130, loss: 0.001053262734785676
step: 140, loss: 0.005063246935606003
step: 150, loss: 0.0005141220754012465
step: 160, loss: 0.004600321874022484
step: 170, loss: 0.000935207586735487
step: 180, loss: 0.00034607204725034535
step: 190, loss: 0.007059299387037754
step: 200, loss: 0.011679451912641525
step: 210, loss: 0.0005401134840212762
step: 220, loss: 0.04406818002462387
step: 230, loss: 0.0002294944424647838
step: 240, loss: 0.0010366210481151938
step: 250, loss: 0.005713000427931547
step: 260, loss: 0.001408992102369666
step: 270, loss: 0.0039595672860741615
step: 280, loss: 0.008307571522891521
step: 290, loss: 0.015005049295723438
step: 300, loss: 0.00016956434410531074
step: 310, loss: 0.04610106348991394
step: 320, loss: 0.0006999867036938667
step: 330, loss: 0.0010214147623628378
step: 340, loss: 0.0006155046867206693
step: 350, loss: 0.0002027667942456901
step: 360, loss: 0.00016001873882487416
step: 370, loss: 0.0007604780257679522
step: 380, loss: 0.0015631156275048852
step: 390, loss: 0.0009132989798672497
step: 400, loss: 0.002653334056958556
step: 410, loss: 0.00011878157965838909
epoch 14: dev_f1=0.8246977547495683, f1=0.6823104693140795, best_f1=0.729245283018868
step: 0, loss: 0.0008620413136668503
step: 10, loss: 0.0031236358918249607
step: 20, loss: 0.002495519118383527
step: 30, loss: 0.004683481529355049
step: 40, loss: 0.001750909723341465
step: 50, loss: 0.0019064872758463025
step: 60, loss: 0.0004727394552901387
step: 70, loss: 6.44316096440889e-05
step: 80, loss: 0.0012607238022610545
step: 90, loss: 0.015256569720804691
step: 100, loss: 0.0015312449540942907
step: 110, loss: 0.000380621146177873
step: 120, loss: 0.0007455245358869433
step: 130, loss: 0.002135464921593666
step: 140, loss: 0.0005130261997692287
step: 150, loss: 0.004422073718160391
step: 160, loss: 0.0004960132646374404
step: 170, loss: 0.0034670543391257524
step: 180, loss: 0.00022850888490211219
step: 190, loss: 0.0001766533387126401
step: 200, loss: 4.710540815722197e-05
step: 210, loss: 0.0022425344213843346
step: 220, loss: 6.636299804085866e-05
step: 230, loss: 4.987742431694642e-05
step: 240, loss: 0.07732945680618286
step: 250, loss: 0.0005524868029169738
step: 260, loss: 0.008749139495193958
step: 270, loss: 0.003344219410791993
step: 280, loss: 9.969573875423521e-05
step: 290, loss: 0.000910034344997257
step: 300, loss: 0.0013914917362853885
step: 310, loss: 0.00046631970326416194
step: 320, loss: 0.0035641484428197145
step: 330, loss: 0.001053250627592206
step: 340, loss: 0.0003562968922778964
step: 350, loss: 4.311391603550874e-05
step: 360, loss: 0.004990807268768549
step: 370, loss: 0.009564805775880814
step: 380, loss: 0.014584247954189777
step: 390, loss: 0.003533235751092434
step: 400, loss: 0.008456552401185036
step: 410, loss: 0.0007349859806708992
epoch 15: dev_f1=0.8489208633093525, f1=0.701187648456057, best_f1=0.729245283018868
step: 0, loss: 0.0012707486748695374
step: 10, loss: 0.00016185743152163923
step: 20, loss: 8.143981540342793e-05
step: 30, loss: 0.019863851368427277
step: 40, loss: 0.0008669958333484828
step: 50, loss: 0.018466860055923462
step: 60, loss: 0.0006507229409180582
step: 70, loss: 0.00780991418287158
step: 80, loss: 0.010930981487035751
step: 90, loss: 0.0009000360150821507
step: 100, loss: 0.0004767220816574991
step: 110, loss: 0.0056350077502429485
step: 120, loss: 0.004609279800206423
step: 130, loss: 0.001595289446413517
step: 140, loss: 0.0775328204035759
step: 150, loss: 0.00025073954020626843
step: 160, loss: 4.3557174649322405e-05
step: 170, loss: 0.0013935052556917071
step: 180, loss: 0.0008533265790902078
step: 190, loss: 0.00021675345487892628
step: 200, loss: 0.0002601505257189274
step: 210, loss: 0.00033481084392406046
step: 220, loss: 0.0009132305858656764
step: 230, loss: 0.0012211004504933953
step: 240, loss: 0.00035004079109057784
step: 250, loss: 0.00021801868570037186
step: 260, loss: 0.1939832866191864
step: 270, loss: 0.004919247701764107
step: 280, loss: 0.030691638588905334
step: 290, loss: 0.0430118627846241
step: 300, loss: 0.0004353643162176013
step: 310, loss: 0.045374900102615356
step: 320, loss: 0.0003904047189280391
step: 330, loss: 0.005381146911531687
step: 340, loss: 0.00010055922757601365
step: 350, loss: 0.007849863730370998
step: 360, loss: 0.0012424798915162683
step: 370, loss: 0.016267992556095123
step: 380, loss: 0.003253370989114046
step: 390, loss: 0.00021629805269185454
step: 400, loss: 0.0002672930422704667
step: 410, loss: 7.484739762730896e-05
epoch 16: dev_f1=0.8433628318584071, f1=0.7031032885595182, best_f1=0.729245283018868
step: 0, loss: 0.00017160804418381304
step: 10, loss: 4.3389321945142e-05
step: 20, loss: 0.0002383220853516832
step: 30, loss: 0.0020813741721212864
step: 40, loss: 0.006237630732357502
step: 50, loss: 0.0001406835945090279
step: 60, loss: 0.0004054236342199147
step: 70, loss: 0.00017826978000812232
step: 80, loss: 0.00018840181292034686
step: 90, loss: 0.01720081828534603
step: 100, loss: 0.008607008494436741
step: 110, loss: 0.08180621266365051
step: 120, loss: 0.0001407740346621722
step: 130, loss: 0.001685500144958496
step: 140, loss: 0.000399950600694865
step: 150, loss: 0.0008594660903327167
step: 160, loss: 0.030251141637563705
step: 170, loss: 0.07655441761016846
step: 180, loss: 0.0028199017979204655
step: 190, loss: 0.002034310717135668
step: 200, loss: 0.03327509015798569
step: 210, loss: 0.00013755392865277827
step: 220, loss: 0.00019578650244511664
step: 230, loss: 0.000701635901350528
step: 240, loss: 7.287806511158124e-05
step: 250, loss: 0.0005023659323342144
step: 260, loss: 0.0011624598409980536
step: 270, loss: 0.00024798320373520255
step: 280, loss: 0.0003148167161270976
step: 290, loss: 0.002680764067918062
step: 300, loss: 0.00013380216842051595
step: 310, loss: 0.0006610265118069947
step: 320, loss: 0.001298557035624981
step: 330, loss: 0.0004508980200625956
step: 340, loss: 0.00011844241089420393
step: 350, loss: 0.0005890291067771614
step: 360, loss: 0.00010490455315448344
step: 370, loss: 0.0009628660045564175
step: 380, loss: 0.03200480341911316
step: 390, loss: 0.00024361323448829353
step: 400, loss: 0.0003575649461708963
step: 410, loss: 0.002206511329859495
epoch 17: dev_f1=0.8423841059602649, f1=0.6937644341801387, best_f1=0.729245283018868
step: 0, loss: 0.0011241076281294227
step: 10, loss: 0.009341718629002571
step: 20, loss: 0.0008789451094344258
step: 30, loss: 0.0001783861662261188
step: 40, loss: 0.0002535433159209788
step: 50, loss: 0.004321230575442314
step: 60, loss: 0.00024211012350860983
step: 70, loss: 3.981036206823774e-05
step: 80, loss: 0.005616982001811266
step: 90, loss: 0.004743670113384724
step: 100, loss: 0.0015350084286183119
step: 110, loss: 0.0003809675690717995
step: 120, loss: 8.167090709321201e-05
step: 130, loss: 0.0004265018505975604
step: 140, loss: 0.00011879519297508523
step: 150, loss: 0.04040362685918808
step: 160, loss: 0.00023170684289652854
step: 170, loss: 0.0001299064460908994
step: 180, loss: 0.0002963377919513732
step: 190, loss: 0.0005951330531388521
step: 200, loss: 0.0019005162175744772
step: 210, loss: 0.00032254846883006394
step: 220, loss: 0.001407214323990047
step: 230, loss: 0.0057024541310966015
step: 240, loss: 0.00034665645216591656
step: 250, loss: 8.785964746493846e-05
step: 260, loss: 0.0004423819773364812
step: 270, loss: 0.011516407132148743
step: 280, loss: 0.0007820563041605055
step: 290, loss: 0.0003172595170326531
step: 300, loss: 0.0005873714108020067
step: 310, loss: 0.0002024725399678573
step: 320, loss: 9.635065362090245e-05
step: 330, loss: 0.0009406865574419498
step: 340, loss: 8.297659951495007e-05
step: 350, loss: 0.000181710347533226
step: 360, loss: 0.002117541152983904
step: 370, loss: 0.00022199358500074595
step: 380, loss: 0.00022169912699609995
step: 390, loss: 0.00010981553350575268
step: 400, loss: 6.008192212902941e-05
step: 410, loss: 8.376834739465266e-05
epoch 18: dev_f1=0.8269565217391305, f1=0.6864864864864866, best_f1=0.729245283018868
step: 0, loss: 0.00036068924237042665
step: 10, loss: 0.0003605844103731215
step: 20, loss: 0.00275069335475564
step: 30, loss: 0.00011875364725710824
step: 40, loss: 0.009181479923427105
step: 50, loss: 0.0012188877444714308
step: 60, loss: 0.0006699029472656548
step: 70, loss: 0.0016074173618108034
step: 80, loss: 0.0008663525222800672
step: 90, loss: 0.0027210665866732597
step: 100, loss: 0.0017812030855566263
step: 110, loss: 9.09528971533291e-05
step: 120, loss: 0.0007115027983672917
step: 130, loss: 0.0010433016577735543
step: 140, loss: 0.00023330505064222962
step: 150, loss: 0.0006953870179131627
step: 160, loss: 0.00020009840955026448
step: 170, loss: 2.9809049010509625e-05
step: 180, loss: 0.00010662282875273377
step: 190, loss: 0.0026163647416979074
step: 200, loss: 9.686029807198793e-05
step: 210, loss: 0.020323701202869415
step: 220, loss: 0.0007140020607039332
step: 230, loss: 0.00016013272397685796
step: 240, loss: 0.03714318573474884
step: 250, loss: 0.00015268140123225749
step: 260, loss: 0.005423768889158964
step: 270, loss: 0.0003786453162319958
step: 280, loss: 0.0003062638861592859
step: 290, loss: 0.0009692767634987831
step: 300, loss: 0.005606300663203001
step: 310, loss: 0.01161572989076376
step: 320, loss: 0.00036241853376850486
step: 330, loss: 0.001537233591079712
step: 340, loss: 0.0003750527394004166
step: 350, loss: 0.00022493231517728418
step: 360, loss: 0.00013853948621544987
step: 370, loss: 0.00010820804163813591
step: 380, loss: 0.003915827255696058
step: 390, loss: 0.002094317926093936
step: 400, loss: 0.001185751287266612
step: 410, loss: 0.004944483749568462
epoch 19: dev_f1=0.8370663153271849, f1=0.688539741219963, best_f1=0.729245283018868
step: 0, loss: 0.0002285985101480037
step: 10, loss: 0.00040236738277599216
step: 20, loss: 0.0005102566792629659
step: 30, loss: 0.005101134534925222
step: 40, loss: 0.07470488548278809
step: 50, loss: 0.0011034061899408698
step: 60, loss: 4.399390672915615e-05
step: 70, loss: 7.661320705665275e-05
step: 80, loss: 0.042519859969615936
step: 90, loss: 7.09400701452978e-05
step: 100, loss: 0.00037782188155688345
step: 110, loss: 0.00035115450737066567
step: 120, loss: 0.0012187473475933075
step: 130, loss: 0.0007298974669538438
step: 140, loss: 0.0011052604531869292
step: 150, loss: 8.665112545713782e-05
step: 160, loss: 8.342806540895253e-05
step: 170, loss: 0.00021817474043928087
step: 180, loss: 0.0006008254713378847
step: 190, loss: 0.00012546654033940285
step: 200, loss: 0.00039874864160083234
step: 210, loss: 6.605641829082742e-05
step: 220, loss: 4.83171570522245e-05
step: 230, loss: 0.0007556398049928248
step: 240, loss: 0.00011393665772629902
step: 250, loss: 7.69754551583901e-05
step: 260, loss: 0.0007592581096105278
step: 270, loss: 0.00012161071208538488
step: 280, loss: 0.0016468801768496633
step: 290, loss: 0.009317874908447266
step: 300, loss: 5.8732355682877824e-05
step: 310, loss: 0.0008161311270669103
step: 320, loss: 0.0005866645951755345
step: 330, loss: 0.00015567067021038383
step: 340, loss: 0.00029804211226291955
step: 350, loss: 0.00032823291257955134
step: 360, loss: 8.015380444703624e-05
step: 370, loss: 9.423884330317378e-05
step: 380, loss: 5.7919929531635717e-05
step: 390, loss: 0.00014840786752756685
step: 400, loss: 3.753466080524959e-05
step: 410, loss: 0.062215544283390045
epoch 20: dev_f1=0.838964458095656, f1=0.6891454965357968, best_f1=0.729245283018868
