cuda
Device: cuda
step: 0, loss: 0.8162203431129456
step: 10, loss: 0.4148871898651123
step: 20, loss: 0.33485639095306396
step: 30, loss: 0.44456759095191956
step: 40, loss: 0.4635290205478668
step: 50, loss: 0.5775421857833862
step: 60, loss: 0.2131272405385971
step: 70, loss: 0.660973310470581
step: 80, loss: 0.3343062698841095
step: 90, loss: 0.42415475845336914
step: 100, loss: 0.3490849435329437
step: 110, loss: 0.28856173157691956
step: 120, loss: 0.41103416681289673
step: 130, loss: 0.34591853618621826
step: 140, loss: 0.5647355914115906
step: 150, loss: 0.31583961844444275
step: 160, loss: 0.48747363686561584
step: 170, loss: 0.3733471930027008
step: 180, loss: 0.4404664635658264
step: 190, loss: 0.4835926592350006
step: 200, loss: 0.3771178722381592
step: 210, loss: 0.46996545791625977
step: 220, loss: 0.5522358417510986
step: 230, loss: 0.443519651889801
step: 240, loss: 0.4252610206604004
step: 250, loss: 0.25769785046577454
step: 260, loss: 0.08748405426740646
step: 270, loss: 0.1935374140739441
step: 280, loss: 0.22495853900909424
step: 290, loss: 0.19480878114700317
step: 300, loss: 0.32610827684402466
step: 310, loss: 0.25860852003097534
step: 320, loss: 0.3862658441066742
step: 330, loss: 0.19742222130298615
step: 340, loss: 0.307047963142395
step: 350, loss: 0.3780747950077057
step: 360, loss: 0.3326948285102844
step: 370, loss: 0.20832383632659912
step: 380, loss: 0.2907337546348572
step: 390, loss: 0.28367316722869873
step: 400, loss: 0.32545003294944763
step: 410, loss: 0.245424285531044
step: 420, loss: 0.29120558500289917
step: 430, loss: 0.26275867223739624
step: 440, loss: 0.28324612975120544
step: 450, loss: 0.23064884543418884
step: 460, loss: 0.23300182819366455
step: 470, loss: 0.49359002709388733
step: 480, loss: 0.3074478805065155
step: 490, loss: 0.3825232684612274
step: 500, loss: 0.11759963631629944
step: 510, loss: 0.2349998503923416
step: 520, loss: 0.296466588973999
epoch 1: dev_f1=0.8581623550401427, f1=0.7983193277310924, best_f1=0.7983193277310924
step: 0, loss: 0.18122006952762604
step: 10, loss: 0.198552206158638
step: 20, loss: 0.09128562361001968
step: 30, loss: 0.150029256939888
step: 40, loss: 0.434137761592865
step: 50, loss: 0.101561538875103
step: 60, loss: 0.2439851015806198
step: 70, loss: 0.330984890460968
step: 80, loss: 0.12214777618646622
step: 90, loss: 0.4871440827846527
step: 100, loss: 0.27667999267578125
step: 110, loss: 0.20835325121879578
step: 120, loss: 0.1728125661611557
step: 130, loss: 0.2563789188861847
step: 140, loss: 0.3054156005382538
step: 150, loss: 0.17099419236183167
step: 160, loss: 0.21765422821044922
step: 170, loss: 0.25699126720428467
step: 180, loss: 0.4038728177547455
step: 190, loss: 0.170114204287529
step: 200, loss: 0.1684885025024414
step: 210, loss: 0.10451149195432663
step: 220, loss: 0.16213366389274597
step: 230, loss: 0.2086474746465683
step: 240, loss: 0.488488107919693
step: 250, loss: 0.3318830728530884
step: 260, loss: 0.08402851223945618
step: 270, loss: 0.2809266149997711
step: 280, loss: 0.13698065280914307
step: 290, loss: 0.33767423033714294
step: 300, loss: 0.18110421299934387
step: 310, loss: 0.16277477145195007
step: 320, loss: 0.20698456466197968
step: 330, loss: 0.272520512342453
step: 340, loss: 0.1162140890955925
step: 350, loss: 0.19501766562461853
step: 360, loss: 0.14668922126293182
step: 370, loss: 0.25713565945625305
step: 380, loss: 0.16992753744125366
step: 390, loss: 0.3151148855686188
step: 400, loss: 0.09022359549999237
step: 410, loss: 0.11396121978759766
step: 420, loss: 0.16923682391643524
step: 430, loss: 0.14843328297138214
step: 440, loss: 0.1773991882801056
step: 450, loss: 0.13444297015666962
step: 460, loss: 0.21322740614414215
step: 470, loss: 0.21515850722789764
step: 480, loss: 0.3299828767776489
step: 490, loss: 0.156703382730484
step: 500, loss: 0.2611427307128906
step: 510, loss: 0.15215237438678741
step: 520, loss: 0.4096761643886566
epoch 2: dev_f1=0.8552631578947368, f1=0.7178464606181456, best_f1=0.7983193277310924
step: 0, loss: 0.23599277436733246
step: 10, loss: 0.31851309537887573
step: 20, loss: 0.11471034586429596
step: 30, loss: 0.09214907884597778
step: 40, loss: 0.2594536244869232
step: 50, loss: 0.2187349498271942
step: 60, loss: 0.09933669865131378
step: 70, loss: 0.08628332614898682
step: 80, loss: 0.1325787901878357
step: 90, loss: 0.36286768317222595
step: 100, loss: 0.0374627485871315
step: 110, loss: 0.1966136246919632
step: 120, loss: 0.17809130251407623
step: 130, loss: 0.13882897794246674
step: 140, loss: 0.2710898816585541
step: 150, loss: 0.0691911056637764
step: 160, loss: 0.17740191519260406
step: 170, loss: 0.1756313443183899
step: 180, loss: 0.15885253250598907
step: 190, loss: 0.06460448354482651
step: 200, loss: 0.09027431905269623
step: 210, loss: 0.18513309955596924
step: 220, loss: 0.22576454281806946
step: 230, loss: 0.15899866819381714
step: 240, loss: 0.09044194966554642
step: 250, loss: 0.1968657374382019
step: 260, loss: 0.2749900221824646
step: 270, loss: 0.286373496055603
step: 280, loss: 0.11346115171909332
step: 290, loss: 0.1384088546037674
step: 300, loss: 0.22098621726036072
step: 310, loss: 0.23113058507442474
step: 320, loss: 0.04591277986764908
step: 330, loss: 0.1249704360961914
step: 340, loss: 0.07541124522686005
step: 350, loss: 0.17102165520191193
step: 360, loss: 0.08005557209253311
step: 370, loss: 0.06998106092214584
step: 380, loss: 0.13825881481170654
step: 390, loss: 0.03105798177421093
step: 400, loss: 0.3129833936691284
step: 410, loss: 0.07126738131046295
step: 420, loss: 0.04367382824420929
step: 430, loss: 0.20199376344680786
step: 440, loss: 0.05549275875091553
step: 450, loss: 0.1153077781200409
step: 460, loss: 0.043166033923625946
step: 470, loss: 0.26103347539901733
step: 480, loss: 0.12468200922012329
step: 490, loss: 0.179148331284523
step: 500, loss: 0.12770920991897583
step: 510, loss: 0.325521856546402
step: 520, loss: 0.14955401420593262
epoch 3: dev_f1=0.867680958967266, f1=0.7251575375666505, best_f1=0.7251575375666505
step: 0, loss: 0.07603281736373901
step: 10, loss: 0.06763219833374023
step: 20, loss: 0.117646224796772
step: 30, loss: 0.15239304304122925
step: 40, loss: 0.023841936141252518
step: 50, loss: 0.13937145471572876
step: 60, loss: 0.07098653167486191
step: 70, loss: 0.22368068993091583
step: 80, loss: 0.15099219977855682
step: 90, loss: 0.15738606452941895
step: 100, loss: 0.07045422494411469
step: 110, loss: 0.013306178152561188
step: 120, loss: 0.15492655336856842
step: 130, loss: 0.0928301215171814
step: 140, loss: 0.05212441831827164
step: 150, loss: 0.09305728226900101
step: 160, loss: 0.0527728907763958
step: 170, loss: 0.11089256405830383
step: 180, loss: 0.039781227707862854
step: 190, loss: 0.24771486222743988
step: 200, loss: 0.05434928089380264
step: 210, loss: 0.019138140603899956
step: 220, loss: 0.14129342138767242
step: 230, loss: 0.14943093061447144
step: 240, loss: 0.08833181858062744
step: 250, loss: 0.2071610987186432
step: 260, loss: 0.02726241759955883
step: 270, loss: 0.035734906792640686
step: 280, loss: 0.2167542576789856
step: 290, loss: 0.10425512492656708
step: 300, loss: 0.1902986466884613
step: 310, loss: 0.0962868183851242
step: 320, loss: 0.0562814325094223
step: 330, loss: 0.28848564624786377
step: 340, loss: 0.08950146287679672
step: 350, loss: 0.17737382650375366
step: 360, loss: 0.08889982849359512
step: 370, loss: 0.20942296087741852
step: 380, loss: 0.11622948199510574
step: 390, loss: 0.15641666948795319
step: 400, loss: 0.13841882348060608
step: 410, loss: 0.117336705327034
step: 420, loss: 0.30108240246772766
step: 430, loss: 0.04623298719525337
step: 440, loss: 0.04325345158576965
step: 450, loss: 0.016457419842481613
step: 460, loss: 0.10040722042322159
step: 470, loss: 0.09894674271345139
step: 480, loss: 0.03944621980190277
step: 490, loss: 0.2226809412240982
step: 500, loss: 0.025789137929677963
step: 510, loss: 0.078687384724617
step: 520, loss: 0.0728306993842125
epoch 4: dev_f1=0.8806584362139919, f1=0.7248908296943232, best_f1=0.7248908296943232
step: 0, loss: 0.10356219112873077
step: 10, loss: 0.07936681807041168
step: 20, loss: 0.30792316794395447
step: 30, loss: 0.09884120523929596
step: 40, loss: 0.03431447967886925
step: 50, loss: 0.025712838396430016
step: 60, loss: 0.07938610762357712
step: 70, loss: 0.028338193893432617
step: 80, loss: 0.09398553520441055
step: 90, loss: 0.11407354474067688
step: 100, loss: 0.006317140068858862
step: 110, loss: 0.08746012300252914
step: 120, loss: 0.0112469382584095
step: 130, loss: 0.07599180191755295
step: 140, loss: 0.10612300783395767
step: 150, loss: 0.06491822749376297
step: 160, loss: 0.09814916551113129
step: 170, loss: 0.19495809078216553
step: 180, loss: 0.11369598656892776
step: 190, loss: 0.06010650470852852
step: 200, loss: 0.10436490923166275
step: 210, loss: 0.16292224824428558
step: 220, loss: 0.1572200506925583
step: 230, loss: 0.22785525023937225
step: 240, loss: 0.03096110001206398
step: 250, loss: 0.0593191459774971
step: 260, loss: 0.059292059391736984
step: 270, loss: 0.1300915777683258
step: 280, loss: 0.015180547721683979
step: 290, loss: 0.28219717741012573
step: 300, loss: 0.024466030299663544
step: 310, loss: 0.15940576791763306
step: 320, loss: 0.21145156025886536
step: 330, loss: 0.028318172320723534
step: 340, loss: 0.04047628864645958
step: 350, loss: 0.18416665494441986
step: 360, loss: 0.010424547828733921
step: 370, loss: 0.08725675195455551
step: 380, loss: 0.2984605133533478
step: 390, loss: 0.02732117474079132
step: 400, loss: 0.16730956733226776
step: 410, loss: 0.05933457985520363
step: 420, loss: 0.06233642250299454
step: 430, loss: 0.09174248576164246
step: 440, loss: 0.07685156166553497
step: 450, loss: 0.13392086327075958
step: 460, loss: 0.04255824536085129
step: 470, loss: 0.078071728348732
step: 480, loss: 0.11518341302871704
step: 490, loss: 0.14634621143341064
step: 500, loss: 0.05549384281039238
step: 510, loss: 0.03407914564013481
step: 520, loss: 0.05180928483605385
epoch 5: dev_f1=0.8686956521739131, f1=0.7460815047021945, best_f1=0.7248908296943232
step: 0, loss: 0.044010017067193985
step: 10, loss: 0.011968164704740047
step: 20, loss: 0.0018691064324229956
step: 30, loss: 0.11425597965717316
step: 40, loss: 0.001361437258310616
step: 50, loss: 0.08459702134132385
step: 60, loss: 0.05017101764678955
step: 70, loss: 0.18782609701156616
step: 80, loss: 0.01094760186970234
step: 90, loss: 0.03171147033572197
step: 100, loss: 0.03956647589802742
step: 110, loss: 0.012069079093635082
step: 120, loss: 0.006706728134304285
step: 130, loss: 0.020493479445576668
step: 140, loss: 0.13872367143630981
step: 150, loss: 0.05740761011838913
step: 160, loss: 0.1596904993057251
step: 170, loss: 0.06754928082227707
step: 180, loss: 0.14542046189308167
step: 190, loss: 0.3328853249549866
step: 200, loss: 0.05890042334794998
step: 210, loss: 0.007890346460044384
step: 220, loss: 0.02880985662341118
step: 230, loss: 0.04369957745075226
step: 240, loss: 0.016608290374279022
step: 250, loss: 0.03972896933555603
step: 260, loss: 0.038183849304914474
step: 270, loss: 0.11416032910346985
step: 280, loss: 0.0980127826333046
step: 290, loss: 0.013060184195637703
step: 300, loss: 0.1731744408607483
step: 310, loss: 0.16779738664627075
step: 320, loss: 0.07683289796113968
step: 330, loss: 0.03347184136509895
step: 340, loss: 0.0381743498146534
step: 350, loss: 0.13240642845630646
step: 360, loss: 0.11162736266851425
step: 370, loss: 0.027460377663373947
step: 380, loss: 0.07069645076990128
step: 390, loss: 0.1484832763671875
step: 400, loss: 0.030652590095996857
step: 410, loss: 0.049108993262052536
step: 420, loss: 0.01571880653500557
step: 430, loss: 0.07900063693523407
step: 440, loss: 0.07331540435552597
step: 450, loss: 0.009665343910455704
step: 460, loss: 0.0358320027589798
step: 470, loss: 0.04732532054185867
step: 480, loss: 0.05811517313122749
step: 490, loss: 0.07405751943588257
step: 500, loss: 0.021832803264260292
step: 510, loss: 0.07667302340269089
step: 520, loss: 0.06123358756303787
epoch 6: dev_f1=0.8836772983114447, f1=0.711932101847229, best_f1=0.711932101847229
step: 0, loss: 0.11546000093221664
step: 10, loss: 0.02368801087141037
step: 20, loss: 0.007424958515912294
step: 30, loss: 0.019049022346735
step: 40, loss: 0.012264290824532509
step: 50, loss: 0.14641398191452026
step: 60, loss: 0.10168225318193436
step: 70, loss: 0.07824381440877914
step: 80, loss: 0.010138334706425667
step: 90, loss: 0.04796703904867172
step: 100, loss: 0.08324597775936127
step: 110, loss: 0.01695772260427475
step: 120, loss: 0.08135063946247101
step: 130, loss: 0.10302220284938812
step: 140, loss: 0.031121322885155678
step: 150, loss: 0.03238750249147415
step: 160, loss: 0.06151571869850159
step: 170, loss: 0.014107122085988522
step: 180, loss: 0.043163396418094635
step: 190, loss: 0.027441756799817085
step: 200, loss: 0.2666746973991394
step: 210, loss: 0.09607558697462082
step: 220, loss: 0.04038116708397865
step: 230, loss: 0.01762331835925579
step: 240, loss: 0.007628890220075846
step: 250, loss: 0.030864886939525604
step: 260, loss: 0.011819078586995602
step: 270, loss: 0.03890204057097435
step: 280, loss: 0.04337351396679878
step: 290, loss: 0.025580475106835365
step: 300, loss: 0.18704462051391602
step: 310, loss: 0.017568454146385193
step: 320, loss: 0.07442033290863037
step: 330, loss: 0.07054479420185089
step: 340, loss: 0.1038942039012909
step: 350, loss: 0.04649839550256729
step: 360, loss: 0.004544280003756285
step: 370, loss: 0.07191801071166992
step: 380, loss: 0.006775044370442629
step: 390, loss: 0.010169047862291336
step: 400, loss: 0.14377719163894653
step: 410, loss: 0.026779187843203545
step: 420, loss: 0.043066687881946564
step: 430, loss: 0.16303397715091705
step: 440, loss: 0.09821005910634995
step: 450, loss: 0.018571406602859497
step: 460, loss: 0.08829987049102783
step: 470, loss: 0.00753501383587718
step: 480, loss: 0.08360753953456879
step: 490, loss: 0.04724518954753876
step: 500, loss: 0.00744258938357234
step: 510, loss: 0.1875918209552765
step: 520, loss: 0.0165740754455328
epoch 7: dev_f1=0.8680652680652681, f1=0.7073170731707317, best_f1=0.711932101847229
step: 0, loss: 0.06081303209066391
step: 10, loss: 0.057740721851587296
step: 20, loss: 0.010390747338533401
step: 30, loss: 0.0907660499215126
step: 40, loss: 0.005347274709492922
step: 50, loss: 0.04727835953235626
step: 60, loss: 0.0007626371807418764
step: 70, loss: 0.014988943934440613
step: 80, loss: 0.019105033949017525
step: 90, loss: 0.07131163030862808
step: 100, loss: 0.12621665000915527
step: 110, loss: 0.007136283442378044
step: 120, loss: 0.06760724633932114
step: 130, loss: 0.1543993055820465
step: 140, loss: 0.07969286292791367
step: 150, loss: 0.00996844470500946
step: 160, loss: 0.052069809287786484
step: 170, loss: 0.08496806770563126
step: 180, loss: 0.0039380332455039024
step: 190, loss: 0.02193395048379898
step: 200, loss: 0.0035345768555998802
step: 210, loss: 0.0005776472971774638
step: 220, loss: 0.001107488409616053
step: 230, loss: 0.027821628376841545
step: 240, loss: 0.057615332305431366
step: 250, loss: 0.010535123758018017
step: 260, loss: 0.055570632219314575
step: 270, loss: 0.027877071872353554
step: 280, loss: 0.00918908603489399
step: 290, loss: 0.12350208312273026
step: 300, loss: 0.013705380260944366
step: 310, loss: 0.007705835159868002
step: 320, loss: 0.05587450787425041
step: 330, loss: 0.039320848882198334
step: 340, loss: 0.007080791983753443
step: 350, loss: 0.02040082961320877
step: 360, loss: 0.03716066852211952
step: 370, loss: 0.02391652949154377
step: 380, loss: 0.12692028284072876
step: 390, loss: 0.013365642167627811
step: 400, loss: 0.013066495768725872
step: 410, loss: 0.13275285065174103
step: 420, loss: 0.004643904510885477
step: 430, loss: 0.03592566028237343
step: 440, loss: 0.028554532676935196
step: 450, loss: 0.003202290739864111
step: 460, loss: 0.05252953618764877
step: 470, loss: 0.007447490934282541
step: 480, loss: 0.014239638112485409
step: 490, loss: 0.050430744886398315
step: 500, loss: 0.04066953808069229
step: 510, loss: 0.02312908135354519
step: 520, loss: 0.007424530573189259
epoch 8: dev_f1=0.8680811808118081, f1=0.6943620178041543, best_f1=0.711932101847229
step: 0, loss: 0.004163460806012154
step: 10, loss: 0.0023088513407856226
step: 20, loss: 0.0071203093975782394
step: 30, loss: 0.05548113211989403
step: 40, loss: 0.02954154461622238
step: 50, loss: 0.0035594142973423004
step: 60, loss: 0.013056522235274315
step: 70, loss: 0.11041946709156036
step: 80, loss: 0.001062049064785242
step: 90, loss: 0.04377886280417442
step: 100, loss: 0.06969524174928665
step: 110, loss: 0.06377825140953064
step: 120, loss: 0.028579145669937134
step: 130, loss: 0.001901704352349043
step: 140, loss: 0.00634495634585619
step: 150, loss: 0.08266744762659073
step: 160, loss: 0.016993002966046333
step: 170, loss: 0.05284339562058449
step: 180, loss: 0.014028111472725868
step: 190, loss: 0.003857152769342065
step: 200, loss: 0.017332736402750015
step: 210, loss: 0.04560216888785362
step: 220, loss: 0.00624215230345726
step: 230, loss: 0.13901720941066742
step: 240, loss: 0.009955808520317078
step: 250, loss: 0.011501030996441841
step: 260, loss: 0.007939017377793789
step: 270, loss: 0.021916599944233894
step: 280, loss: 0.015148037113249302
step: 290, loss: 0.20118628442287445
step: 300, loss: 0.012484744191169739
step: 310, loss: 0.0047701261937618256
step: 320, loss: 0.0005132423830218613
step: 330, loss: 0.0037244847044348717
step: 340, loss: 0.003591117449104786
step: 350, loss: 0.04739701375365257
step: 360, loss: 0.008465522900223732
step: 370, loss: 0.1566961258649826
step: 380, loss: 0.008106669411063194
step: 390, loss: 0.015568245202302933
step: 400, loss: 0.12062554061412811
step: 410, loss: 0.0658031702041626
step: 420, loss: 0.022623611614108086
step: 430, loss: 0.013452187180519104
step: 440, loss: 0.01658027060329914
step: 450, loss: 0.09765169024467468
step: 460, loss: 0.016605697572231293
step: 470, loss: 0.0015804949216544628
step: 480, loss: 0.00366658391430974
step: 490, loss: 0.006429252214729786
step: 500, loss: 0.06360287219285965
step: 510, loss: 0.08214589208364487
step: 520, loss: 0.0028225677087903023
epoch 9: dev_f1=0.8576528335564482, f1=0.6936416184971098, best_f1=0.711932101847229
step: 0, loss: 0.007979361340403557
step: 10, loss: 0.02205667831003666
step: 20, loss: 0.004992670379579067
step: 30, loss: 0.0019408739171922207
step: 40, loss: 0.004597327206283808
step: 50, loss: 0.025607304647564888
step: 60, loss: 0.010346841998398304
step: 70, loss: 0.0025193870533257723
step: 80, loss: 0.0018203570507466793
step: 90, loss: 0.026242617517709732
step: 100, loss: 0.0012568264501169324
step: 110, loss: 0.019030798226594925
step: 120, loss: 0.015065154992043972
step: 130, loss: 0.015454765409231186
step: 140, loss: 0.04313528537750244
step: 150, loss: 0.03419975936412811
step: 160, loss: 0.02957620844244957
step: 170, loss: 0.00046355745871551335
step: 180, loss: 0.033845096826553345
step: 190, loss: 0.015792468562722206
step: 200, loss: 0.0020337942987680435
step: 210, loss: 0.0003213590243831277
step: 220, loss: 0.00481690838932991
step: 230, loss: 0.0030715330503880978
step: 240, loss: 0.0026120664551854134
step: 250, loss: 0.001037966227158904
step: 260, loss: 0.011234142817556858
step: 270, loss: 0.009391365572810173
step: 280, loss: 0.009261585772037506
step: 290, loss: 0.0005264058709144592
step: 300, loss: 0.02181738056242466
step: 310, loss: 0.0017887587891891599
step: 320, loss: 0.0022660098038613796
step: 330, loss: 0.0007108761346898973
step: 340, loss: 0.009674684144556522
step: 350, loss: 0.0017118194373324513
step: 360, loss: 0.032404132187366486
step: 370, loss: 0.018087996169924736
step: 380, loss: 0.0005843211547471583
step: 390, loss: 0.014816603623330593
step: 400, loss: 0.012950022704899311
step: 410, loss: 0.007448557298630476
step: 420, loss: 0.0037876295391470194
step: 430, loss: 0.016207940876483917
step: 440, loss: 0.005359962582588196
step: 450, loss: 0.0019049190450459719
step: 460, loss: 0.014891929924488068
step: 470, loss: 0.005129867233335972
step: 480, loss: 0.012660461477935314
step: 490, loss: 0.01816502772271633
step: 500, loss: 0.0024959740694612265
step: 510, loss: 0.006259188987314701
step: 520, loss: 0.01709832437336445
epoch 10: dev_f1=0.8300738809213386, f1=0.6855835240274598, best_f1=0.711932101847229
step: 0, loss: 0.0007915948517620564
step: 10, loss: 0.02107916586101055
step: 20, loss: 0.01966264471411705
step: 30, loss: 0.01573359966278076
step: 40, loss: 0.029741356149315834
step: 50, loss: 0.0006121573387645185
step: 60, loss: 0.03154727816581726
step: 70, loss: 0.015287503600120544
step: 80, loss: 0.08389685302972794
step: 90, loss: 0.018987851217389107
step: 100, loss: 0.00023465062258765101
step: 110, loss: 0.11507762223482132
step: 120, loss: 0.001053776009939611
step: 130, loss: 0.0037633220199495554
step: 140, loss: 0.0001342545438092202
step: 150, loss: 0.0004876888997387141
step: 160, loss: 0.036584023386240005
step: 170, loss: 0.00385619536973536
step: 180, loss: 0.0008896040380932391
step: 190, loss: 0.0004057729383930564
step: 200, loss: 0.0009926155908033252
step: 210, loss: 0.0035503539256751537
step: 220, loss: 0.0006650103023275733
step: 230, loss: 0.05025133118033409
step: 240, loss: 0.0010834609856829047
step: 250, loss: 0.014966067858040333
step: 260, loss: 0.05528227612376213
step: 270, loss: 0.003602430457249284
step: 280, loss: 0.0009455945109948516
step: 290, loss: 0.0019455725559964776
step: 300, loss: 0.003862702287733555
step: 310, loss: 0.16077831387519836
step: 320, loss: 0.020845118910074234
step: 330, loss: 0.07673662155866623
step: 340, loss: 0.004551205318421125
step: 350, loss: 0.11949446052312851
step: 360, loss: 0.008373130112886429
step: 370, loss: 0.018114175647497177
step: 380, loss: 0.0002870349562726915
step: 390, loss: 0.00011620514851529151
step: 400, loss: 0.011865063570439816
step: 410, loss: 0.16502025723457336
step: 420, loss: 0.05278431624174118
step: 430, loss: 0.0074059125036001205
step: 440, loss: 0.0031344543676823378
step: 450, loss: 0.033172979950904846
step: 460, loss: 0.005050163250416517
step: 470, loss: 0.05280546098947525
step: 480, loss: 0.08617198467254639
step: 490, loss: 0.0061457231640815735
step: 500, loss: 0.03294135630130768
step: 510, loss: 0.02671615406870842
step: 520, loss: 0.0021959305740892887
epoch 11: dev_f1=0.8805970149253732, f1=0.7149231531978184, best_f1=0.711932101847229
step: 0, loss: 0.050872985273599625
step: 10, loss: 0.13810956478118896
step: 20, loss: 0.04990199953317642
step: 30, loss: 0.0074545154348015785
step: 40, loss: 0.009679903276264668
step: 50, loss: 0.001763910404406488
step: 60, loss: 0.0089793149381876
step: 70, loss: 0.0006995617295615375
step: 80, loss: 0.0002479073009453714
step: 90, loss: 0.007614452391862869
step: 100, loss: 0.0011068243766203523
step: 110, loss: 0.08288948237895966
step: 120, loss: 0.0003167146642226726
step: 130, loss: 0.004500371869653463
step: 140, loss: 0.14713479578495026
step: 150, loss: 0.012618512846529484
step: 160, loss: 0.09269260615110397
step: 170, loss: 0.0015165754593908787
step: 180, loss: 0.005210904870182276
step: 190, loss: 0.016904126852750778
step: 200, loss: 0.00021474406821653247
step: 210, loss: 0.00793758500367403
step: 220, loss: 0.04586699232459068
step: 230, loss: 0.06553727388381958
step: 240, loss: 0.0003040698647964746
step: 250, loss: 0.03468470275402069
step: 260, loss: 0.005450088530778885
step: 270, loss: 0.025733597576618195
step: 280, loss: 0.00024424961884506047
step: 290, loss: 0.0007950821309350431
step: 300, loss: 0.0006765203434042633
step: 310, loss: 0.0001651569764362648
step: 320, loss: 0.035204026848077774
step: 330, loss: 0.03556380793452263
step: 340, loss: 0.00043744570575654507
step: 350, loss: 0.03451531380414963
step: 360, loss: 0.01535086054354906
step: 370, loss: 0.002789352787658572
step: 380, loss: 0.00015861420251894742
step: 390, loss: 0.019731979817152023
step: 400, loss: 0.0003649235877674073
step: 410, loss: 0.03915095329284668
step: 420, loss: 0.0008747954270802438
step: 430, loss: 0.014058161526918411
step: 440, loss: 0.04434835910797119
step: 450, loss: 0.0026950675528496504
step: 460, loss: 0.08153572678565979
step: 470, loss: 0.025581734254956245
step: 480, loss: 0.008487519808113575
step: 490, loss: 0.0004274046514183283
step: 500, loss: 0.04729064181447029
step: 510, loss: 0.001452482189051807
step: 520, loss: 0.009824810549616814
epoch 12: dev_f1=0.8340008900756565, f1=0.6588235294117646, best_f1=0.711932101847229
step: 0, loss: 0.00045142596354708076
step: 10, loss: 0.0069005731493234634
step: 20, loss: 0.004197474103420973
step: 30, loss: 0.013755938038229942
step: 40, loss: 0.03204993158578873
step: 50, loss: 0.002425983315333724
step: 60, loss: 0.04100000113248825
step: 70, loss: 0.0005620893789455295
step: 80, loss: 0.0027938522398471832
step: 90, loss: 0.0024041193537414074
step: 100, loss: 0.002642008475959301
step: 110, loss: 0.09767016023397446
step: 120, loss: 0.010460928082466125
step: 130, loss: 0.0003700451925396919
step: 140, loss: 0.0012185565428808331
step: 150, loss: 0.004468490835279226
step: 160, loss: 0.0005852014874108136
step: 170, loss: 0.0002498860703781247
step: 180, loss: 0.003070462727919221
step: 190, loss: 0.0010756286792457104
step: 200, loss: 0.004191303625702858
step: 210, loss: 0.07081975787878036
step: 220, loss: 0.005425856448709965
step: 230, loss: 0.0005797757185064256
step: 240, loss: 0.02777649275958538
step: 250, loss: 0.0007738757994957268
step: 260, loss: 0.014344682916998863
step: 270, loss: 0.03471832349896431
step: 280, loss: 0.017827533185482025
step: 290, loss: 0.10070466250181198
step: 300, loss: 0.07244166731834412
step: 310, loss: 0.0022132177837193012
step: 320, loss: 0.000136804417707026
step: 330, loss: 0.001812940463423729
step: 340, loss: 0.002154029905796051
step: 350, loss: 0.0002179984439862892
step: 360, loss: 7.014289440121502e-05
step: 370, loss: 0.0005588122876361012
step: 380, loss: 0.0014666339848190546
step: 390, loss: 0.0005046696169301867
step: 400, loss: 0.0002158644492737949
step: 410, loss: 0.008232465013861656
step: 420, loss: 0.020463183522224426
step: 430, loss: 0.1256684511899948
step: 440, loss: 0.015633920207619667
step: 450, loss: 0.0008261635666713119
step: 460, loss: 0.0518665537238121
step: 470, loss: 0.10596701502799988
step: 480, loss: 0.008784005418419838
step: 490, loss: 0.017399301752448082
step: 500, loss: 0.009570995345711708
step: 510, loss: 0.0005945006851106882
step: 520, loss: 0.00021248622215352952
epoch 13: dev_f1=0.865518845974872, f1=0.6878097125867195, best_f1=0.711932101847229
step: 0, loss: 0.00025838203146122396
step: 10, loss: 0.0037962447386235
step: 20, loss: 0.03615064173936844
step: 30, loss: 0.00017450717859901488
step: 40, loss: 9.090521052712575e-05
step: 50, loss: 0.0005998527631163597
step: 60, loss: 0.0003563504433259368
step: 70, loss: 0.023416677489876747
step: 80, loss: 0.00140054477378726
step: 90, loss: 0.0038049318827688694
step: 100, loss: 0.008945005014538765
step: 110, loss: 0.00043878794531337917
step: 120, loss: 0.0352061465382576
step: 130, loss: 0.02589734084904194
step: 140, loss: 0.00010324460890842602
step: 150, loss: 0.003002892015501857
step: 160, loss: 0.020862402394413948
step: 170, loss: 0.01530539896339178
step: 180, loss: 0.0009734789491631091
step: 190, loss: 0.00023548153694719076
step: 200, loss: 0.0033471763599663973
step: 210, loss: 0.020028023049235344
step: 220, loss: 0.00047533883480355144
step: 230, loss: 0.003354363376274705
step: 240, loss: 0.0010410584509372711
step: 250, loss: 0.005196345504373312
step: 260, loss: 0.0008619185537099838
step: 270, loss: 9.257742203772068e-05
step: 280, loss: 0.0009103032643906772
step: 290, loss: 0.004569056443870068
step: 300, loss: 0.04562580958008766
step: 310, loss: 6.160030898172408e-05
step: 320, loss: 0.0004485176468733698
step: 330, loss: 0.0050537968054413795
step: 340, loss: 0.0005101396236568689
step: 350, loss: 0.0008487371960654855
step: 360, loss: 0.0002603868197184056
step: 370, loss: 0.00039703870425000787
step: 380, loss: 0.0001576454087626189
step: 390, loss: 0.006502413656562567
step: 400, loss: 0.006790248677134514
step: 410, loss: 0.0181395523250103
step: 420, loss: 0.0025311310309916735
step: 430, loss: 0.0002967407926917076
step: 440, loss: 0.0005624183686450124
step: 450, loss: 0.00029971060575917363
step: 460, loss: 0.008849084377288818
step: 470, loss: 0.00028073409339413047
step: 480, loss: 0.01367871556431055
step: 490, loss: 0.002038028556853533
step: 500, loss: 0.005363024305552244
step: 510, loss: 0.0025299997068941593
step: 520, loss: 0.000843835121486336
epoch 14: dev_f1=0.8621307072515667, f1=0.6890676762896356, best_f1=0.711932101847229
step: 0, loss: 0.00042686244705691934
step: 10, loss: 0.0061244904063642025
step: 20, loss: 0.00552118755877018
step: 30, loss: 0.0014055167557671666
step: 40, loss: 0.0001323467877227813
step: 50, loss: 0.0014807186089456081
step: 60, loss: 0.005316657014191151
step: 70, loss: 0.001060190494172275
step: 80, loss: 0.001697115134447813
step: 90, loss: 4.418700700625777e-05
step: 100, loss: 0.004545221570879221
step: 110, loss: 0.0014624708564952016
step: 120, loss: 0.0004499770002439618
step: 130, loss: 0.0005403822287917137
step: 140, loss: 0.0012421616120263934
step: 150, loss: 0.0012063155882060528
step: 160, loss: 7.845048094168305e-05
step: 170, loss: 0.0378212109208107
step: 180, loss: 0.0006370876799337566
step: 190, loss: 0.00011101310519734398
step: 200, loss: 0.000695998955052346
step: 210, loss: 0.0011044214479625225
step: 220, loss: 9.219826461048797e-05
step: 230, loss: 0.0004070670693181455
step: 240, loss: 0.09881920367479324
step: 250, loss: 0.0004700662975665182
step: 260, loss: 0.0005004457198083401
step: 270, loss: 0.0009207632392644882
step: 280, loss: 9.422050788998604e-05
step: 290, loss: 0.003081436036154628
step: 300, loss: 0.004571607802063227
step: 310, loss: 0.0008401459781453013
step: 320, loss: 0.01639873906970024
step: 330, loss: 0.026600535959005356
step: 340, loss: 0.001153918681666255
step: 350, loss: 0.010269666090607643
step: 360, loss: 0.00015551343676634133
step: 370, loss: 0.004114948678761721
step: 380, loss: 0.0007021889323368669
step: 390, loss: 0.00015038027777336538
step: 400, loss: 0.00015207621618174016
step: 410, loss: 0.007264174520969391
step: 420, loss: 0.027894331142306328
step: 430, loss: 0.0004379639576654881
step: 440, loss: 0.0005027949227951467
step: 450, loss: 0.0002863733097910881
step: 460, loss: 0.06204298883676529
step: 470, loss: 0.0006175523158162832
step: 480, loss: 0.00013960727665107697
step: 490, loss: 0.0009456959669478238
step: 500, loss: 0.0015957348514348269
step: 510, loss: 0.00032099292729981244
step: 520, loss: 0.023263130336999893
epoch 15: dev_f1=0.8637392485287461, f1=0.6947674418604651, best_f1=0.711932101847229
step: 0, loss: 0.01601880043745041
step: 10, loss: 0.0001161040854640305
step: 20, loss: 0.0002920640690717846
step: 30, loss: 3.894767360179685e-05
step: 40, loss: 0.12682488560676575
step: 50, loss: 0.0001377026055706665
step: 60, loss: 0.013248617760837078
step: 70, loss: 0.007886065170168877
step: 80, loss: 4.6427641791524366e-05
step: 90, loss: 0.0005486709414981306
step: 100, loss: 0.0005554754752665758
step: 110, loss: 0.014756823889911175
step: 120, loss: 0.0035182880237698555
step: 130, loss: 0.0005928132450208068
step: 140, loss: 0.001849664724431932
step: 150, loss: 0.0006250369478948414
step: 160, loss: 0.089069664478302
step: 170, loss: 3.609618215705268e-05
step: 180, loss: 0.002053708303719759
step: 190, loss: 0.006041003856807947
step: 200, loss: 0.0001123377078329213
step: 210, loss: 0.039181943982839584
step: 220, loss: 0.00013882278290111572
step: 230, loss: 0.004430084954947233
step: 240, loss: 0.00016979077190626413
step: 250, loss: 0.03994650021195412
step: 260, loss: 0.0030471752397716045
step: 270, loss: 0.00013738313282374293
step: 280, loss: 4.9083279009209946e-05
step: 290, loss: 0.024215474724769592
step: 300, loss: 8.570692443754524e-05
step: 310, loss: 0.0001602070697117597
step: 320, loss: 0.00038769154343754053
step: 330, loss: 0.0012936254497617483
step: 340, loss: 0.024791069328784943
step: 350, loss: 3.389144330867566e-05
step: 360, loss: 0.0003282309917267412
step: 370, loss: 0.06959664076566696
step: 380, loss: 0.00025053200079128146
step: 390, loss: 0.005096591077744961
step: 400, loss: 0.0004274016246199608
step: 410, loss: 0.00021701602963730693
step: 420, loss: 0.00039765253313817084
step: 430, loss: 0.023337921127676964
step: 440, loss: 0.00010531202860875055
step: 450, loss: 0.000719776377081871
step: 460, loss: 0.00693992106243968
step: 470, loss: 0.0016189664602279663
step: 480, loss: 0.004274480510503054
step: 490, loss: 0.0005322268698364496
step: 500, loss: 0.00025707637541927397
step: 510, loss: 0.0010653733043000102
step: 520, loss: 3.7624617107212543e-05
epoch 16: dev_f1=0.8744228993536473, f1=0.7038327526132405, best_f1=0.711932101847229
step: 0, loss: 4.568792428472079e-05
step: 10, loss: 0.0014756435994058847
step: 20, loss: 0.00021149979147594422
step: 30, loss: 0.00016994579345919192
step: 40, loss: 0.0006695009651593864
step: 50, loss: 0.003082669572904706
step: 60, loss: 0.003351598046720028
step: 70, loss: 0.04916510358452797
step: 80, loss: 0.00026732374681159854
step: 90, loss: 0.0001043899537762627
step: 100, loss: 0.0003682595561258495
step: 110, loss: 0.00028952048160135746
step: 120, loss: 0.0006032451638020575
step: 130, loss: 0.00015686200640629977
step: 140, loss: 0.00032037621713243425
step: 150, loss: 0.0036300253123044968
step: 160, loss: 5.712205893360078e-05
step: 170, loss: 0.003040813375264406
step: 180, loss: 0.012440372258424759
step: 190, loss: 0.00020713955746032298
step: 200, loss: 0.0018509265501052141
step: 210, loss: 0.008942090906202793
step: 220, loss: 0.0009803518187254667
step: 230, loss: 0.00029882241506129503
step: 240, loss: 0.00012733167386613786
step: 250, loss: 0.00026549544418230653
step: 260, loss: 0.0007579349912703037
step: 270, loss: 0.00011297362652840093
step: 280, loss: 0.00033495761454105377
step: 290, loss: 0.0004586400755215436
step: 300, loss: 0.00013665863662026823
step: 310, loss: 0.0005718878237530589
step: 320, loss: 0.00031652580946683884
step: 330, loss: 0.0003838462580461055
step: 340, loss: 0.002078956225886941
step: 350, loss: 0.008995461277663708
step: 360, loss: 0.0002903119311667979
step: 370, loss: 0.0010333661921322346
step: 380, loss: 0.03454389423131943
step: 390, loss: 9.084905468625948e-05
step: 400, loss: 0.034352511167526245
step: 410, loss: 0.01953657902777195
step: 420, loss: 6.297372601693496e-05
step: 430, loss: 0.010301560163497925
step: 440, loss: 0.00011448463919805363
step: 450, loss: 7.487023685825989e-05
step: 460, loss: 0.004423824138939381
step: 470, loss: 0.00043556204764172435
step: 480, loss: 0.0008762968936935067
step: 490, loss: 0.004084770567715168
step: 500, loss: 5.099717600387521e-05
step: 510, loss: 0.00254583521746099
step: 520, loss: 6.143173959571868e-05
epoch 17: dev_f1=0.8702651515151515, f1=0.6871165644171778, best_f1=0.711932101847229
step: 0, loss: 0.00014884590927977115
step: 10, loss: 0.004667443223297596
step: 20, loss: 2.2581922166864388e-05
step: 30, loss: 0.0006603219080716372
step: 40, loss: 0.00018510468362364918
step: 50, loss: 0.0001700098509900272
step: 60, loss: 0.0004906090325675905
step: 70, loss: 0.00037762857391498983
step: 80, loss: 0.00046014919644221663
step: 90, loss: 0.0003676695632748306
step: 100, loss: 0.00025502516655251384
step: 110, loss: 0.0008334608864970505
step: 120, loss: 0.00010539200593484566
step: 130, loss: 9.916450653690845e-05
step: 140, loss: 0.0002094668452627957
step: 150, loss: 0.012297594919800758
step: 160, loss: 0.0023017325438559055
step: 170, loss: 0.0001690079370746389
step: 180, loss: 0.003811639966443181
step: 190, loss: 0.00019303796580061316
step: 200, loss: 0.0002646262582857162
step: 210, loss: 0.009124762378633022
step: 220, loss: 9.809833863982931e-05
step: 230, loss: 0.00044737555435858667
step: 240, loss: 0.008695250377058983
step: 250, loss: 0.018535254523158073
step: 260, loss: 0.0007281174184754491
step: 270, loss: 0.0011232548858970404
step: 280, loss: 3.512518742354587e-05
step: 290, loss: 5.2349969337228686e-05
step: 300, loss: 9.837214747676626e-05
step: 310, loss: 0.0003232566232327372
step: 320, loss: 0.0008007133728824556
step: 330, loss: 5.2302348194643855e-05
step: 340, loss: 0.00020219071302562952
step: 350, loss: 0.00020630037761293352
step: 360, loss: 0.00021230064157862216
step: 370, loss: 0.001578649622388184
step: 380, loss: 0.029692841693758965
step: 390, loss: 8.173245441867039e-05
step: 400, loss: 0.0008382092928513885
step: 410, loss: 3.847244806820527e-05
step: 420, loss: 0.025480102747678757
step: 430, loss: 0.00011546535097295418
step: 440, loss: 0.010091963224112988
step: 450, loss: 0.00016140256775543094
step: 460, loss: 0.00047992606414482
step: 470, loss: 0.0003155242884531617
step: 480, loss: 0.0002703089267015457
step: 490, loss: 0.00010313622624380514
step: 500, loss: 0.00017438174108974636
step: 510, loss: 0.0012137414887547493
step: 520, loss: 7.409039972117171e-05
epoch 18: dev_f1=0.866913123844732, f1=0.6982248520710059, best_f1=0.711932101847229
step: 0, loss: 6.834310624981299e-05
step: 10, loss: 0.0023785755038261414
step: 20, loss: 0.00012743790284730494
step: 30, loss: 0.0002723262005019933
step: 40, loss: 0.0002461642143316567
step: 50, loss: 0.0017140767304226756
step: 60, loss: 0.0008083833381533623
step: 70, loss: 7.364504563156515e-05
step: 80, loss: 0.0012634663144126534
step: 90, loss: 8.393331518163905e-05
step: 100, loss: 0.0001208582179970108
step: 110, loss: 0.018830761313438416
step: 120, loss: 0.0011500022374093533
step: 130, loss: 0.00018522281607147306
step: 140, loss: 0.002530248137190938
step: 150, loss: 0.006249425932765007
step: 160, loss: 0.00027603303897194564
step: 170, loss: 0.0003024452307727188
step: 180, loss: 8.47020564833656e-05
step: 190, loss: 0.00010152188042411581
step: 200, loss: 0.0007047749240882695
step: 210, loss: 0.0001995671627810225
step: 220, loss: 0.015173699706792831
step: 230, loss: 0.009981675073504448
step: 240, loss: 0.00041136439540423453
step: 250, loss: 9.397049871040508e-05
step: 260, loss: 6.077546640881337e-05
step: 270, loss: 0.0458764024078846
step: 280, loss: 0.00463842460885644
step: 290, loss: 0.007318517658859491
step: 300, loss: 0.0004809431848116219
step: 310, loss: 0.00042085081804543734
step: 320, loss: 0.00011857068602694198
step: 330, loss: 0.00014240953896660358
step: 340, loss: 0.0006142318015918136
step: 350, loss: 0.007008071523159742
step: 360, loss: 0.005499456077814102
step: 370, loss: 0.00011808783892774954
step: 380, loss: 0.0005395920597948134
step: 390, loss: 4.636594167095609e-05
step: 400, loss: 7.967105193529278e-05
step: 410, loss: 0.0002711160050239414
step: 420, loss: 0.0002447461592964828
step: 430, loss: 0.0010647266171872616
step: 440, loss: 3.881179145537317e-05
step: 450, loss: 0.00020528245659079403
step: 460, loss: 0.00013943910016678274
step: 470, loss: 0.0004458730109035969
step: 480, loss: 4.271824946044944e-05
step: 490, loss: 7.640267722308636e-05
step: 500, loss: 0.00027408081223256886
step: 510, loss: 0.0004354786651674658
step: 520, loss: 6.084906272008084e-05
epoch 19: dev_f1=0.8674033149171271, f1=0.6947055912914398, best_f1=0.711932101847229
step: 0, loss: 0.00023365177912637591
step: 10, loss: 0.0002590981312096119
step: 20, loss: 0.03552839905023575
step: 30, loss: 0.0003110271936748177
step: 40, loss: 0.003236644435673952
step: 50, loss: 0.0008734798175282776
step: 60, loss: 0.044052138924598694
step: 70, loss: 7.154253398766741e-05
step: 80, loss: 0.017784517258405685
step: 90, loss: 0.0001914820895763114
step: 100, loss: 0.010270876809954643
step: 110, loss: 0.021938152611255646
step: 120, loss: 9.581838821759447e-05
step: 130, loss: 7.135830674087629e-05
step: 140, loss: 0.05031931772828102
step: 150, loss: 0.0001741345477057621
step: 160, loss: 0.00026708966470323503
step: 170, loss: 3.368591933394782e-05
step: 180, loss: 0.03470761701464653
step: 190, loss: 0.00011008400906575844
step: 200, loss: 7.209993782453239e-05
step: 210, loss: 0.0032152996864169836
step: 220, loss: 0.0003262135141994804
step: 230, loss: 7.583312981296331e-05
step: 240, loss: 0.00011261629697401077
step: 250, loss: 0.0166633278131485
step: 260, loss: 0.0006897194543853402
step: 270, loss: 0.0005185003392398357
step: 280, loss: 0.024495171383023262
step: 290, loss: 8.346512913703918e-05
step: 300, loss: 6.878487329231575e-05
step: 310, loss: 0.0006908956565894186
step: 320, loss: 0.02769049070775509
step: 330, loss: 0.00021635278244502842
step: 340, loss: 2.567016963439528e-05
step: 350, loss: 0.0001228596520377323
step: 360, loss: 0.001855641370639205
step: 370, loss: 0.00015414218069054186
step: 380, loss: 4.391034963191487e-05
step: 390, loss: 0.033486612141132355
step: 400, loss: 0.02035633660852909
step: 410, loss: 3.830649075098336e-05
step: 420, loss: 0.0005651095416396856
step: 430, loss: 0.0013044349616393447
step: 440, loss: 3.9696020394330844e-05
step: 450, loss: 9.401569695910439e-05
step: 460, loss: 0.00014550233026966453
step: 470, loss: 0.0002150922518922016
step: 480, loss: 0.00035259383730590343
step: 490, loss: 0.00021262234076857567
step: 500, loss: 6.36734621366486e-05
step: 510, loss: 0.0001444295048713684
step: 520, loss: 9.960633178707212e-05
epoch 20: dev_f1=0.867680958967266, f1=0.697029702970297, best_f1=0.711932101847229
