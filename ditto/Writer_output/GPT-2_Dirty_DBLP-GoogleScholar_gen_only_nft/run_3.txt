cuda
Device: cuda
step: 0, loss: 0.9849283695220947
step: 10, loss: 0.5556520223617554
step: 20, loss: 0.4856635630130768
step: 30, loss: 0.39357221126556396
step: 40, loss: 0.40875986218452454
step: 50, loss: 0.6008017659187317
step: 60, loss: 0.34157341718673706
step: 70, loss: 0.5066656470298767
step: 80, loss: 0.35531577467918396
step: 90, loss: 0.2553228735923767
step: 100, loss: 0.45644551515579224
step: 110, loss: 0.38694924116134644
step: 120, loss: 0.520624577999115
step: 130, loss: 0.3675473630428314
step: 140, loss: 0.18291907012462616
step: 150, loss: 0.3994397222995758
step: 160, loss: 0.321208119392395
step: 170, loss: 0.3337080180644989
step: 180, loss: 0.40234196186065674
step: 190, loss: 0.39878129959106445
step: 200, loss: 0.4938848912715912
step: 210, loss: 0.34595397114753723
step: 220, loss: 0.4203491508960724
step: 230, loss: 0.35117682814598083
step: 240, loss: 0.23883196711540222
step: 250, loss: 0.11681912839412689
step: 260, loss: 0.34373050928115845
step: 270, loss: 0.30673491954803467
step: 280, loss: 0.27486252784729004
step: 290, loss: 0.2696876525878906
step: 300, loss: 0.1687893569469452
step: 310, loss: 0.2885148227214813
step: 320, loss: 0.35027721524238586
step: 330, loss: 0.4389401078224182
step: 340, loss: 0.28687146306037903
step: 350, loss: 0.17874224483966827
step: 360, loss: 0.3514176607131958
step: 370, loss: 0.23333360254764557
step: 380, loss: 0.2953372895717621
step: 390, loss: 0.41430360078811646
step: 400, loss: 0.28135672211647034
step: 410, loss: 0.33429449796676636
step: 420, loss: 0.27991682291030884
step: 430, loss: 0.45210567116737366
step: 440, loss: 0.11825799942016602
step: 450, loss: 0.6024094223976135
step: 460, loss: 0.41440144181251526
step: 470, loss: 0.5105549693107605
step: 480, loss: 0.41524985432624817
step: 490, loss: 0.5795985460281372
epoch 1: dev_f1=0.8348623853211008, f1=0.777830412126954, best_f1=0.777830412126954
step: 0, loss: 0.21740664541721344
step: 10, loss: 0.278099000453949
step: 20, loss: 0.18173956871032715
step: 30, loss: 0.17944000661373138
step: 40, loss: 0.08773604780435562
step: 50, loss: 0.3658097982406616
step: 60, loss: 0.26716387271881104
step: 70, loss: 0.18172889947891235
step: 80, loss: 0.2853178381919861
step: 90, loss: 0.2252151221036911
step: 100, loss: 0.2576476037502289
step: 110, loss: 0.3932243585586548
step: 120, loss: 0.1859138309955597
step: 130, loss: 0.16754746437072754
step: 140, loss: 0.1615711897611618
step: 150, loss: 0.46620362997055054
step: 160, loss: 0.38966280221939087
step: 170, loss: 0.37314289808273315
step: 180, loss: 0.3648079037666321
step: 190, loss: 0.4454493522644043
step: 200, loss: 0.2787642478942871
step: 210, loss: 0.1890907734632492
step: 220, loss: 0.3066917657852173
step: 230, loss: 0.13327018916606903
step: 240, loss: 0.19284111261367798
step: 250, loss: 0.37427055835723877
step: 260, loss: 0.25984159111976624
step: 270, loss: 0.2604472041130066
step: 280, loss: 0.24477344751358032
step: 290, loss: 0.30316609144210815
step: 300, loss: 0.1668836623430252
step: 310, loss: 0.16270458698272705
step: 320, loss: 0.141664057970047
step: 330, loss: 0.1236916184425354
step: 340, loss: 0.6760990619659424
step: 350, loss: 0.11759112775325775
step: 360, loss: 0.16679050028324127
step: 370, loss: 0.4169330894947052
step: 380, loss: 0.22496578097343445
step: 390, loss: 0.3487788736820221
step: 400, loss: 0.14051476120948792
step: 410, loss: 0.10025355964899063
step: 420, loss: 0.22449523210525513
step: 430, loss: 0.45419079065322876
step: 440, loss: 0.3938959240913391
step: 450, loss: 0.31013384461402893
step: 460, loss: 0.3516210913658142
step: 470, loss: 0.22354179620742798
step: 480, loss: 0.15436561405658722
step: 490, loss: 0.2162173092365265
epoch 2: dev_f1=0.8385345997286296, f1=0.7465914433474377, best_f1=0.7465914433474377
step: 0, loss: 0.14470171928405762
step: 10, loss: 0.2547752857208252
step: 20, loss: 0.07405898720026016
step: 30, loss: 0.09504866600036621
step: 40, loss: 0.21360638737678528
step: 50, loss: 0.2262851446866989
step: 60, loss: 0.16173888742923737
step: 70, loss: 0.3022616505622864
step: 80, loss: 0.08087339997291565
step: 90, loss: 0.08681727200746536
step: 100, loss: 0.3339998424053192
step: 110, loss: 0.19809478521347046
step: 120, loss: 0.18604202568531036
step: 130, loss: 0.10336542129516602
step: 140, loss: 0.19222745299339294
step: 150, loss: 0.15134574472904205
step: 160, loss: 0.08670041710138321
step: 170, loss: 0.3032936751842499
step: 180, loss: 0.3241545259952545
step: 190, loss: 0.13839267194271088
step: 200, loss: 0.2692810893058777
step: 210, loss: 0.12845857441425323
step: 220, loss: 0.12578806281089783
step: 230, loss: 0.06747251003980637
step: 240, loss: 0.12150900065898895
step: 250, loss: 0.06719619035720825
step: 260, loss: 0.17312481999397278
step: 270, loss: 0.39906150102615356
step: 280, loss: 0.3058302104473114
step: 290, loss: 0.22802039980888367
step: 300, loss: 0.22521919012069702
step: 310, loss: 0.2824525237083435
step: 320, loss: 0.2053793966770172
step: 330, loss: 0.19354498386383057
step: 340, loss: 0.403993159532547
step: 350, loss: 0.2469889521598816
step: 360, loss: 0.1684565395116806
step: 370, loss: 0.18685881793498993
step: 380, loss: 0.39418548345565796
step: 390, loss: 0.09190326184034348
step: 400, loss: 0.05064728483557701
step: 410, loss: 0.17819885909557343
step: 420, loss: 0.22248251736164093
step: 430, loss: 0.41545480489730835
step: 440, loss: 0.1203581839799881
step: 450, loss: 0.08727310597896576
step: 460, loss: 0.16269904375076294
step: 470, loss: 0.18682901561260223
step: 480, loss: 0.2605534493923187
step: 490, loss: 0.22305253148078918
epoch 3: dev_f1=0.8321902149062643, f1=0.6990384615384615, best_f1=0.7465914433474377
step: 0, loss: 0.14146149158477783
step: 10, loss: 0.1932264268398285
step: 20, loss: 0.31840771436691284
step: 30, loss: 0.0908869281411171
step: 40, loss: 0.10620278865098953
step: 50, loss: 0.20630423724651337
step: 60, loss: 0.1015981063246727
step: 70, loss: 0.04241608455777168
step: 80, loss: 0.12113925814628601
step: 90, loss: 0.19044123589992523
step: 100, loss: 0.1363341361284256
step: 110, loss: 0.09566350281238556
step: 120, loss: 0.0844220444560051
step: 130, loss: 0.0788552314043045
step: 140, loss: 0.07649175822734833
step: 150, loss: 0.31421974301338196
step: 160, loss: 0.22982920706272125
step: 170, loss: 0.13935339450836182
step: 180, loss: 0.11375865340232849
step: 190, loss: 0.13910192251205444
step: 200, loss: 0.07578732073307037
step: 210, loss: 0.043626923114061356
step: 220, loss: 0.06474746763706207
step: 230, loss: 0.10719236731529236
step: 240, loss: 0.11738747358322144
step: 250, loss: 0.03952253609895706
step: 260, loss: 0.16212905943393707
step: 270, loss: 0.07621389627456665
step: 280, loss: 0.03800592198967934
step: 290, loss: 0.07194311916828156
step: 300, loss: 0.07364361733198166
step: 310, loss: 0.14201389253139496
step: 320, loss: 0.4624784588813782
step: 330, loss: 0.20859654247760773
step: 340, loss: 0.241757333278656
step: 350, loss: 0.10139773786067963
step: 360, loss: 0.10476922243833542
step: 370, loss: 0.05565245822072029
step: 380, loss: 0.10913431644439697
step: 390, loss: 0.04750099778175354
step: 400, loss: 0.18111228942871094
step: 410, loss: 0.1059325560927391
step: 420, loss: 0.1483280062675476
step: 430, loss: 0.12574230134487152
step: 440, loss: 0.11813358962535858
step: 450, loss: 0.08390265703201294
step: 460, loss: 0.16514262557029724
step: 470, loss: 0.12139689922332764
step: 480, loss: 0.1744454950094223
step: 490, loss: 0.17807415127754211
epoch 4: dev_f1=0.8755244755244754, f1=0.7171117705242336, best_f1=0.7171117705242336
step: 0, loss: 0.1251567155122757
step: 10, loss: 0.0788225531578064
step: 20, loss: 0.15622203052043915
step: 30, loss: 0.07354946434497833
step: 40, loss: 0.05633219704031944
step: 50, loss: 0.047667521983385086
step: 60, loss: 0.19825966656208038
step: 70, loss: 0.015101986937224865
step: 80, loss: 0.12614761292934418
step: 90, loss: 0.1497005671262741
step: 100, loss: 0.13488046824932098
step: 110, loss: 0.1812630295753479
step: 120, loss: 0.1114024743437767
step: 130, loss: 0.018983900547027588
step: 140, loss: 0.2835143804550171
step: 150, loss: 0.07059057056903839
step: 160, loss: 0.12358392030000687
step: 170, loss: 0.21269382536411285
step: 180, loss: 0.026842785999178886
step: 190, loss: 0.10799263417720795
step: 200, loss: 0.11787348240613937
step: 210, loss: 0.03096056915819645
step: 220, loss: 0.10164842009544373
step: 230, loss: 0.026736224070191383
step: 240, loss: 0.17283284664154053
step: 250, loss: 0.2605478763580322
step: 260, loss: 0.06080763041973114
step: 270, loss: 0.08056655526161194
step: 280, loss: 0.03196326270699501
step: 290, loss: 0.016182322055101395
step: 300, loss: 0.05620156601071358
step: 310, loss: 0.10935042798519135
step: 320, loss: 0.14714598655700684
step: 330, loss: 0.2351040244102478
step: 340, loss: 0.016435373574495316
step: 350, loss: 0.06012166291475296
step: 360, loss: 0.13671398162841797
step: 370, loss: 0.14324147999286652
step: 380, loss: 0.017982322722673416
step: 390, loss: 0.12025857716798782
step: 400, loss: 0.08233597874641418
step: 410, loss: 0.0968022271990776
step: 420, loss: 0.03653033822774887
step: 430, loss: 0.025880951434373856
step: 440, loss: 0.6024581789970398
step: 450, loss: 0.11517979949712753
step: 460, loss: 0.059195276349782944
step: 470, loss: 0.05968180298805237
step: 480, loss: 0.02120729349553585
step: 490, loss: 0.11051808297634125
epoch 5: dev_f1=0.8793024323083983, f1=0.729769494850417, best_f1=0.729769494850417
step: 0, loss: 0.13216587901115417
step: 10, loss: 0.06273762136697769
step: 20, loss: 0.021525690332055092
step: 30, loss: 0.2443561553955078
step: 40, loss: 0.19478993117809296
step: 50, loss: 0.15585638582706451
step: 60, loss: 0.09765242785215378
step: 70, loss: 0.04788875952363014
step: 80, loss: 0.07311678677797318
step: 90, loss: 0.005580426659435034
step: 100, loss: 0.006743245292454958
step: 110, loss: 0.039528556168079376
step: 120, loss: 0.060792990028858185
step: 130, loss: 0.07284741848707199
step: 140, loss: 0.058929383754730225
step: 150, loss: 0.010420854203402996
step: 160, loss: 0.2706727087497711
step: 170, loss: 0.07410962879657745
step: 180, loss: 0.06501209735870361
step: 190, loss: 0.0889095664024353
step: 200, loss: 0.07353691011667252
step: 210, loss: 0.008383607491850853
step: 220, loss: 0.022217271849513054
step: 230, loss: 0.03587755933403969
step: 240, loss: 0.12020237743854523
step: 250, loss: 0.018027152866125107
step: 260, loss: 0.0336751714348793
step: 270, loss: 0.05079661309719086
step: 280, loss: 0.03478621691465378
step: 290, loss: 0.03777753934264183
step: 300, loss: 0.00983458198606968
step: 310, loss: 0.04518017917871475
step: 320, loss: 0.1046057790517807
step: 330, loss: 0.01468739565461874
step: 340, loss: 0.026155985891819
step: 350, loss: 0.040910955518484116
step: 360, loss: 0.06035251542925835
step: 370, loss: 0.003096463857218623
step: 380, loss: 0.051240529865026474
step: 390, loss: 0.24586698412895203
step: 400, loss: 0.10912422835826874
step: 410, loss: 0.1778239756822586
step: 420, loss: 0.028927551582455635
step: 430, loss: 0.10299696028232574
step: 440, loss: 0.16462615132331848
step: 450, loss: 0.16274693608283997
step: 460, loss: 0.05873424932360649
step: 470, loss: 0.041221484541893005
step: 480, loss: 0.0012627821415662766
step: 490, loss: 0.13193093240261078
epoch 6: dev_f1=0.8546853779990945, f1=0.7178757705073494, best_f1=0.729769494850417
step: 0, loss: 0.01520783081650734
step: 10, loss: 0.01917700096964836
step: 20, loss: 0.005057702772319317
step: 30, loss: 0.029923653230071068
step: 40, loss: 0.058904070407152176
step: 50, loss: 0.009969878010451794
step: 60, loss: 0.013654615730047226
step: 70, loss: 0.08947372436523438
step: 80, loss: 0.004595321603119373
step: 90, loss: 0.020205028355121613
step: 100, loss: 0.1752965748310089
step: 110, loss: 0.0073034618981182575
step: 120, loss: 0.004252944607287645
step: 130, loss: 0.012233900837600231
step: 140, loss: 0.1227189153432846
step: 150, loss: 0.029530970379710197
step: 160, loss: 0.051372230052948
step: 170, loss: 0.0007778172148391604
step: 180, loss: 0.08399994671344757
step: 190, loss: 0.008269600570201874
step: 200, loss: 0.08970039337873459
step: 210, loss: 0.001229489454999566
step: 220, loss: 0.030269784852862358
step: 230, loss: 0.0010838251328095794
step: 240, loss: 0.0013594714691862464
step: 250, loss: 0.13314460217952728
step: 260, loss: 0.025533221662044525
step: 270, loss: 0.005705666728317738
step: 280, loss: 0.01566515676677227
step: 290, loss: 0.05393333360552788
step: 300, loss: 0.03265932574868202
step: 310, loss: 0.022595476359128952
step: 320, loss: 0.036511167883872986
step: 330, loss: 0.06612949818372726
step: 340, loss: 0.023906217887997627
step: 350, loss: 0.07724113017320633
step: 360, loss: 0.002503875410184264
step: 370, loss: 0.051449473947286606
step: 380, loss: 0.01875157281756401
step: 390, loss: 0.02782030589878559
step: 400, loss: 0.023988867178559303
step: 410, loss: 0.008451982401311398
step: 420, loss: 0.017861027270555496
step: 430, loss: 0.02816205844283104
step: 440, loss: 0.16271854937076569
step: 450, loss: 0.01046021655201912
step: 460, loss: 0.30759188532829285
step: 470, loss: 0.10789617151021957
step: 480, loss: 0.004029315896332264
step: 490, loss: 0.08213579654693604
epoch 7: dev_f1=0.8559782608695652, f1=0.7143538388173581, best_f1=0.729769494850417
step: 0, loss: 0.030799178406596184
step: 10, loss: 0.07139750570058823
step: 20, loss: 0.09365250170230865
step: 30, loss: 0.023563630878925323
step: 40, loss: 0.0031177119817584753
step: 50, loss: 0.06462430208921432
step: 60, loss: 0.07641927152872086
step: 70, loss: 0.07176724076271057
step: 80, loss: 0.005592388100922108
step: 90, loss: 0.02841656468808651
step: 100, loss: 0.0626528337597847
step: 110, loss: 0.0605526864528656
step: 120, loss: 0.04404553398489952
step: 130, loss: 0.15058276057243347
step: 140, loss: 0.11084456741809845
step: 150, loss: 0.17271117866039276
step: 160, loss: 0.01938542164862156
step: 170, loss: 0.01600475050508976
step: 180, loss: 0.030857007950544357
step: 190, loss: 0.014431887306272984
step: 200, loss: 0.08714762330055237
step: 210, loss: 0.015697529539465904
step: 220, loss: 0.041343964636325836
step: 230, loss: 0.005851304158568382
step: 240, loss: 0.008268001489341259
step: 250, loss: 0.009699567221105099
step: 260, loss: 0.012493355199694633
step: 270, loss: 0.06360122561454773
step: 280, loss: 0.010252514854073524
step: 290, loss: 0.036047883331775665
step: 300, loss: 0.0207978542894125
step: 310, loss: 0.006283874623477459
step: 320, loss: 0.06940969824790955
step: 330, loss: 0.07204608619213104
step: 340, loss: 0.07927542924880981
step: 350, loss: 0.002151971450075507
step: 360, loss: 0.046487390995025635
step: 370, loss: 0.05988050997257233
step: 380, loss: 0.008176012896001339
step: 390, loss: 0.005951713304966688
step: 400, loss: 0.011568685062229633
step: 410, loss: 0.04412074759602547
step: 420, loss: 0.000626749882940203
step: 430, loss: 0.004818830173462629
step: 440, loss: 0.05125730112195015
step: 450, loss: 0.05025182291865349
step: 460, loss: 0.03841915726661682
step: 470, loss: 0.061648134142160416
step: 480, loss: 0.012920276261866093
step: 490, loss: 0.0006919901352375746
epoch 8: dev_f1=0.8601083032490975, f1=0.7144879660217084, best_f1=0.729769494850417
step: 0, loss: 0.000596539699472487
step: 10, loss: 0.009302482008934021
step: 20, loss: 0.0015046674525365233
step: 30, loss: 0.01568303443491459
step: 40, loss: 0.16245199739933014
step: 50, loss: 0.001474766293540597
step: 60, loss: 0.0024571288377046585
step: 70, loss: 0.006748225074261427
step: 80, loss: 0.0027566782664507627
step: 90, loss: 0.019701816141605377
step: 100, loss: 0.039305899292230606
step: 110, loss: 0.015493866056203842
step: 120, loss: 0.11201129853725433
step: 130, loss: 0.001715371967293322
step: 140, loss: 0.03254595398902893
step: 150, loss: 0.005123425275087357
step: 160, loss: 0.0739462599158287
step: 170, loss: 0.0440780334174633
step: 180, loss: 0.020009227097034454
step: 190, loss: 0.00733912643045187
step: 200, loss: 0.0027772141620516777
step: 210, loss: 0.004315051715821028
step: 220, loss: 0.0041065579280257225
step: 230, loss: 0.09480555355548859
step: 240, loss: 0.0036038155667483807
step: 250, loss: 0.03731072321534157
step: 260, loss: 0.06747943162918091
step: 270, loss: 0.0077905431389808655
step: 280, loss: 0.01672545075416565
step: 290, loss: 0.002630894770845771
step: 300, loss: 0.006925509311258793
step: 310, loss: 0.06293472647666931
step: 320, loss: 0.05296563357114792
step: 330, loss: 0.0017664809711277485
step: 340, loss: 0.00888058077543974
step: 350, loss: 0.004224811214953661
step: 360, loss: 0.01924656704068184
step: 370, loss: 0.008854512125253677
step: 380, loss: 0.015638424083590508
step: 390, loss: 0.004821216221898794
step: 400, loss: 0.004947611130774021
step: 410, loss: 0.03813359513878822
step: 420, loss: 0.02838830091059208
step: 430, loss: 0.002035850193351507
step: 440, loss: 0.010749081149697304
step: 450, loss: 0.08678334206342697
step: 460, loss: 0.00461121741682291
step: 470, loss: 0.039719805121421814
step: 480, loss: 0.019949594512581825
step: 490, loss: 0.014227118343114853
epoch 9: dev_f1=0.836989247311828, f1=0.691597008358997, best_f1=0.729769494850417
step: 0, loss: 0.024406099691987038
step: 10, loss: 0.001754309399984777
step: 20, loss: 0.007355509325861931
step: 30, loss: 0.004137329291552305
step: 40, loss: 0.0019172943430021405
step: 50, loss: 0.037791721522808075
step: 60, loss: 0.02667153999209404
step: 70, loss: 0.020138327032327652
step: 80, loss: 0.0003865812614094466
step: 90, loss: 0.014221093617379665
step: 100, loss: 0.018830807879567146
step: 110, loss: 0.029399318620562553
step: 120, loss: 0.06759427487850189
step: 130, loss: 0.0778476670384407
step: 140, loss: 0.019628243520855904
step: 150, loss: 0.03336865454912186
step: 160, loss: 0.00027925774338655174
step: 170, loss: 0.03847075253725052
step: 180, loss: 0.01959981769323349
step: 190, loss: 0.0046577053144574165
step: 200, loss: 0.0018097157590091228
step: 210, loss: 0.0027089586947113276
step: 220, loss: 0.04747142270207405
step: 230, loss: 0.001916517037898302
step: 240, loss: 0.0015119879972189665
step: 250, loss: 0.02362007647752762
step: 260, loss: 0.06654272228479385
step: 270, loss: 0.0005057270755060017
step: 280, loss: 0.011725271120667458
step: 290, loss: 0.0032252673991024494
step: 300, loss: 0.029504386708140373
step: 310, loss: 0.09831665456295013
step: 320, loss: 0.2538194954395294
step: 330, loss: 0.04609649255871773
step: 340, loss: 0.020597264170646667
step: 350, loss: 0.09324221312999725
step: 360, loss: 0.1349010169506073
step: 370, loss: 0.008194810710847378
step: 380, loss: 0.044491492211818695
step: 390, loss: 0.008682562038302422
step: 400, loss: 0.05985371768474579
step: 410, loss: 0.024372834712266922
step: 420, loss: 0.116561658680439
step: 430, loss: 0.006200428120791912
step: 440, loss: 0.0021760817617177963
step: 450, loss: 0.0023535422515124083
step: 460, loss: 0.002580248052254319
step: 470, loss: 0.0007963835960254073
step: 480, loss: 0.0017498685047030449
step: 490, loss: 0.006706565618515015
epoch 10: dev_f1=0.8325188804975566, f1=0.6890442890442889, best_f1=0.729769494850417
step: 0, loss: 0.0011932023335248232
step: 10, loss: 0.0019469255348667502
step: 20, loss: 0.13922855257987976
step: 30, loss: 0.0015492390375584364
step: 40, loss: 0.0161358080804348
step: 50, loss: 0.031712256371974945
step: 60, loss: 0.0014824505196884274
step: 70, loss: 0.023861994966864586
step: 80, loss: 0.00034203039831481874
step: 90, loss: 0.0033633955754339695
step: 100, loss: 0.11866894364356995
step: 110, loss: 0.0024158216547220945
step: 120, loss: 0.008414605632424355
step: 130, loss: 0.00028515662415884435
step: 140, loss: 0.0019679765682667494
step: 150, loss: 0.0030666631646454334
step: 160, loss: 0.0013704283628612757
step: 170, loss: 0.01013439241796732
step: 180, loss: 0.010636783204972744
step: 190, loss: 9.390408376930282e-05
step: 200, loss: 0.004246354103088379
step: 210, loss: 0.003147950628772378
step: 220, loss: 0.00059355708071962
step: 230, loss: 0.002467060461640358
step: 240, loss: 0.00039556549745611846
step: 250, loss: 0.00491744838654995
step: 260, loss: 0.055494729429483414
step: 270, loss: 0.00022481226187665015
step: 280, loss: 0.00047463318333029747
step: 290, loss: 0.009955580346286297
step: 300, loss: 0.0015420073177665472
step: 310, loss: 0.00022826259373687208
step: 320, loss: 0.05308333784341812
step: 330, loss: 0.01695522479712963
step: 340, loss: 0.00010482814104761928
step: 350, loss: 0.0278023611754179
step: 360, loss: 0.004127985797822475
step: 370, loss: 0.004022944252938032
step: 380, loss: 0.0004232491191942245
step: 390, loss: 0.04497934877872467
step: 400, loss: 0.004642365500330925
step: 410, loss: 0.00025446031941100955
step: 420, loss: 0.09728317707777023
step: 430, loss: 0.00022863516642246395
step: 440, loss: 0.009999176487326622
step: 450, loss: 0.022612346336245537
step: 460, loss: 0.04143562540411949
step: 470, loss: 0.0010225597070530057
step: 480, loss: 0.027972711250185966
step: 490, loss: 0.0029462098609656096
epoch 11: dev_f1=0.8393556813234654, f1=0.7004484304932735, best_f1=0.729769494850417
step: 0, loss: 0.00011011149763362482
step: 10, loss: 0.0066470373421907425
step: 20, loss: 0.0015930727822706103
step: 30, loss: 0.0022171256132423878
step: 40, loss: 0.001214723102748394
step: 50, loss: 0.0018324611010029912
step: 60, loss: 0.00020738410239573568
step: 70, loss: 0.0004855043371208012
step: 80, loss: 0.011945752426981926
step: 90, loss: 0.005110130179673433
step: 100, loss: 0.005494191776961088
step: 110, loss: 0.008594275452196598
step: 120, loss: 0.02974492311477661
step: 130, loss: 0.010869720950722694
step: 140, loss: 0.0017002241220325232
step: 150, loss: 0.007553152274340391
step: 160, loss: 0.012121319770812988
step: 170, loss: 0.002771561499685049
step: 180, loss: 0.03135515749454498
step: 190, loss: 0.004108692519366741
step: 200, loss: 0.0024585078936070204
step: 210, loss: 0.007072771433740854
step: 220, loss: 0.0002203091571573168
step: 230, loss: 0.03657212108373642
step: 240, loss: 0.025812257081270218
step: 250, loss: 0.006258310750126839
step: 260, loss: 0.30597513914108276
step: 270, loss: 0.023340484127402306
step: 280, loss: 0.020839732140302658
step: 290, loss: 0.00013764883624389768
step: 300, loss: 0.002427510917186737
step: 310, loss: 0.0003708599542733282
step: 320, loss: 0.00017311982810497284
step: 330, loss: 9.440047870157287e-05
step: 340, loss: 0.0003545708314049989
step: 350, loss: 0.009200730361044407
step: 360, loss: 0.03625325858592987
step: 370, loss: 0.0003099072491750121
step: 380, loss: 0.005590134300291538
step: 390, loss: 0.0004655627708416432
step: 400, loss: 0.01539922971278429
step: 410, loss: 0.005052585154771805
step: 420, loss: 0.0014479677192866802
step: 430, loss: 0.026932215318083763
step: 440, loss: 0.01262193825095892
step: 450, loss: 0.0005086774472147226
step: 460, loss: 0.0025635850615799427
step: 470, loss: 0.02242153510451317
step: 480, loss: 0.004095475655049086
step: 490, loss: 0.013645983301103115
epoch 12: dev_f1=0.8352730528200538, f1=0.6865950490425035, best_f1=0.729769494850417
step: 0, loss: 0.00030567016801796854
step: 10, loss: 0.002876907354220748
step: 20, loss: 0.0005584438913501799
step: 30, loss: 0.008381431922316551
step: 40, loss: 0.0002406648563919589
step: 50, loss: 0.001359295449219644
step: 60, loss: 0.03197862207889557
step: 70, loss: 0.00017361137724947184
step: 80, loss: 0.0008905970025807619
step: 90, loss: 0.00020788064284715801
step: 100, loss: 0.002200836781412363
step: 110, loss: 0.0241972878575325
step: 120, loss: 0.00066934380447492
step: 130, loss: 0.002412877744063735
step: 140, loss: 0.000816220068372786
step: 150, loss: 0.000883620698004961
step: 160, loss: 0.03045043535530567
step: 170, loss: 0.0029297899454832077
step: 180, loss: 0.005897406954318285
step: 190, loss: 0.0024362877011299133
step: 200, loss: 0.0008154397364705801
step: 210, loss: 0.0005337689653970301
step: 220, loss: 0.01843445561826229
step: 230, loss: 0.0001936718908837065
step: 240, loss: 0.016315314918756485
step: 250, loss: 0.00037833990063518286
step: 260, loss: 0.0004523654642980546
step: 270, loss: 0.0009701596572995186
step: 280, loss: 0.002480696653947234
step: 290, loss: 0.0008809036226011813
step: 300, loss: 0.19923663139343262
step: 310, loss: 0.0027127040084451437
step: 320, loss: 0.002343253931030631
step: 330, loss: 0.0018579516327008605
step: 340, loss: 0.00022185040870681405
step: 350, loss: 0.0005436891806311905
step: 360, loss: 0.0003172486904077232
step: 370, loss: 0.00039390771416947246
step: 380, loss: 0.004659172613173723
step: 390, loss: 0.0009297016076743603
step: 400, loss: 0.0015397819224745035
step: 410, loss: 0.007287039887160063
step: 420, loss: 0.000506479584146291
step: 430, loss: 0.0020133540965616703
step: 440, loss: 4.991298192180693e-05
step: 450, loss: 0.00012654883903451264
step: 460, loss: 0.025236045941710472
step: 470, loss: 0.0001231360511155799
step: 480, loss: 0.021369043737649918
step: 490, loss: 0.00028001985629089177
epoch 13: dev_f1=0.8454342984409801, f1=0.7177344475394615, best_f1=0.729769494850417
step: 0, loss: 0.0004940383951179683
step: 10, loss: 0.00037268444430083036
step: 20, loss: 0.1165793389081955
step: 30, loss: 0.019575176760554314
step: 40, loss: 0.040265485644340515
step: 50, loss: 0.0005716115701943636
step: 60, loss: 0.00010742952872533351
step: 70, loss: 0.0002998816198669374
step: 80, loss: 0.0003732902405317873
step: 90, loss: 0.01388534065335989
step: 100, loss: 0.0002673923154361546
step: 110, loss: 0.01382950134575367
step: 120, loss: 0.01475362479686737
step: 130, loss: 0.0702652633190155
step: 140, loss: 0.001167741371318698
step: 150, loss: 0.0011019086232408881
step: 160, loss: 0.0006745877326466143
step: 170, loss: 0.0006213682354427874
step: 180, loss: 0.0002829011937137693
step: 190, loss: 0.001097142230719328
step: 200, loss: 0.0001958710781764239
step: 210, loss: 0.0018267846899107099
step: 220, loss: 0.0003592435969039798
step: 230, loss: 0.006189513020217419
step: 240, loss: 0.0005485597066581249
step: 250, loss: 0.01925206184387207
step: 260, loss: 0.0006333680939860642
step: 270, loss: 0.00531493965536356
step: 280, loss: 0.00022263647406361997
step: 290, loss: 0.00024343394034076482
step: 300, loss: 0.004228407051414251
step: 310, loss: 0.0056220716796815395
step: 320, loss: 0.0015359980752691627
step: 330, loss: 0.00015600444748997688
step: 340, loss: 9.960343595594168e-05
step: 350, loss: 0.0030269369017332792
step: 360, loss: 0.10143924504518509
step: 370, loss: 0.0009848015615716577
step: 380, loss: 0.001040264731273055
step: 390, loss: 7.361012103501707e-05
step: 400, loss: 0.009292013943195343
step: 410, loss: 5.432516263681464e-05
step: 420, loss: 6.010753713781014e-05
step: 430, loss: 0.0031227348372340202
step: 440, loss: 6.567644595634192e-05
step: 450, loss: 7.962481322465464e-05
step: 460, loss: 0.000305602588923648
step: 470, loss: 0.001017542788758874
step: 480, loss: 0.0019138972274959087
step: 490, loss: 0.00019772298401221633
epoch 14: dev_f1=0.8511223087494274, f1=0.7082926829268293, best_f1=0.729769494850417
step: 0, loss: 0.0003991267876699567
step: 10, loss: 0.00021661672508344054
step: 20, loss: 0.04127446562051773
step: 30, loss: 0.00020559236872941256
step: 40, loss: 0.0002165642799809575
step: 50, loss: 0.0002970594505313784
step: 60, loss: 0.00037649943260475993
step: 70, loss: 0.012692689895629883
step: 80, loss: 0.0037259769160300493
step: 90, loss: 5.8643978263717145e-05
step: 100, loss: 0.00573665602132678
step: 110, loss: 0.0004890785785391927
step: 120, loss: 0.01394136343151331
step: 130, loss: 0.0005561331054195762
step: 140, loss: 0.01932426542043686
step: 150, loss: 0.0011284482898190618
step: 160, loss: 0.023494970053434372
step: 170, loss: 0.0072761718183755875
step: 180, loss: 0.05446607619524002
step: 190, loss: 0.002055105520412326
step: 200, loss: 0.0006855992833152413
step: 210, loss: 0.051892735064029694
step: 220, loss: 0.00016284255252685398
step: 230, loss: 0.0075031002052128315
step: 240, loss: 0.0017776571912690997
step: 250, loss: 0.00015473256644327193
step: 260, loss: 0.00019101561338175088
step: 270, loss: 0.01395916286855936
step: 280, loss: 0.08728811889886856
step: 290, loss: 0.007569475565105677
step: 300, loss: 0.022554369643330574
step: 310, loss: 0.0002201281167799607
step: 320, loss: 0.0002796986373141408
step: 330, loss: 0.0029248560313135386
step: 340, loss: 0.0003815880627371371
step: 350, loss: 6.358657265082002e-05
step: 360, loss: 0.0009661666699685156
step: 370, loss: 0.00015609707043040544
step: 380, loss: 0.0003347655583638698
step: 390, loss: 0.00020972482161596417
step: 400, loss: 5.066986705060117e-05
step: 410, loss: 0.01043669693171978
step: 420, loss: 0.0010461395140737295
step: 430, loss: 0.000138051706016995
step: 440, loss: 0.006811240687966347
step: 450, loss: 0.00020204452448524535
step: 460, loss: 0.00039121805457398295
step: 470, loss: 0.0002409833250567317
step: 480, loss: 0.012421853840351105
step: 490, loss: 0.0004262365400791168
epoch 15: dev_f1=0.8463949843260189, f1=0.7064959696538644, best_f1=0.729769494850417
step: 0, loss: 0.0012811030028387904
step: 10, loss: 0.00017892611504066736
step: 20, loss: 0.00020898861112073064
step: 30, loss: 0.0004795449785888195
step: 40, loss: 0.0004282190348021686
step: 50, loss: 0.0002582303714007139
step: 60, loss: 8.244407217716798e-05
step: 70, loss: 4.778349830303341e-05
step: 80, loss: 0.0011917189694941044
step: 90, loss: 0.013031651265919209
step: 100, loss: 0.0005246395594440401
step: 110, loss: 9.815113298827782e-05
step: 120, loss: 0.00010986127745127305
step: 130, loss: 6.056415804778226e-05
step: 140, loss: 0.0017889628652483225
step: 150, loss: 0.0003361658309586346
step: 160, loss: 0.00017446937272325158
step: 170, loss: 0.0002475273795425892
step: 180, loss: 0.00024644166114740074
step: 190, loss: 0.00030492761288769543
step: 200, loss: 0.000374355586245656
step: 210, loss: 0.00019417869043536484
step: 220, loss: 0.0010769139043986797
step: 230, loss: 8.454019553028047e-05
step: 240, loss: 0.000871252384968102
step: 250, loss: 0.0002571633958723396
step: 260, loss: 0.16183847188949585
step: 270, loss: 0.00010234561341349036
step: 280, loss: 5.189432340557687e-05
step: 290, loss: 0.0015024507883936167
step: 300, loss: 0.00017037328507285565
step: 310, loss: 0.0004264074086677283
step: 320, loss: 0.007818935438990593
step: 330, loss: 0.0002423396217636764
step: 340, loss: 0.0005322624929249287
step: 350, loss: 0.0001247741747647524
step: 360, loss: 0.0012597660534083843
step: 370, loss: 0.0012500863522291183
step: 380, loss: 0.0001883126824395731
step: 390, loss: 0.001506586093455553
step: 400, loss: 0.0001255617680726573
step: 410, loss: 0.00015854969387874007
step: 420, loss: 0.00015829349285922945
step: 430, loss: 0.0001703173911664635
step: 440, loss: 0.00020396678883116692
step: 450, loss: 0.015762409195303917
step: 460, loss: 0.0011080848053097725
step: 470, loss: 0.0008481428376398981
step: 480, loss: 0.0004687932087108493
step: 490, loss: 0.0005412007449194789
epoch 16: dev_f1=0.8555758683729434, f1=0.6961594555177444, best_f1=0.729769494850417
step: 0, loss: 3.8836464227642864e-05
step: 10, loss: 0.00037845983752049506
step: 20, loss: 0.009017759934067726
step: 30, loss: 7.56895897211507e-05
step: 40, loss: 0.0004422370111569762
step: 50, loss: 3.161559288855642e-05
step: 60, loss: 0.0025168710853904486
step: 70, loss: 0.00042633016710169613
step: 80, loss: 5.573679300141521e-05
step: 90, loss: 0.0006157313473522663
step: 100, loss: 0.006128575652837753
step: 110, loss: 0.0003695092455018312
step: 120, loss: 0.0005916421650908887
step: 130, loss: 4.938970960211009e-05
step: 140, loss: 0.00044444421655498445
step: 150, loss: 0.010587730444967747
step: 160, loss: 0.0020887635182589293
step: 170, loss: 0.00584292272105813
step: 180, loss: 0.00042100780410692096
step: 190, loss: 0.0011479636887088418
step: 200, loss: 6.376257806550711e-05
step: 210, loss: 0.0023401665966957808
step: 220, loss: 6.029189535183832e-05
step: 230, loss: 9.196691826218739e-05
step: 240, loss: 0.030301567167043686
step: 250, loss: 0.01550504844635725
step: 260, loss: 0.00015467127377633005
step: 270, loss: 6.890104850754142e-05
step: 280, loss: 9.4962990260683e-05
step: 290, loss: 0.002751019550487399
step: 300, loss: 0.0007411487167701125
step: 310, loss: 0.0005753887817263603
step: 320, loss: 4.9520844186190516e-05
step: 330, loss: 0.00024753084289841354
step: 340, loss: 0.00012914114631712437
step: 350, loss: 0.008993935771286488
step: 360, loss: 0.0009756937506608665
step: 370, loss: 0.00045041507109999657
step: 380, loss: 0.0001232658833032474
step: 390, loss: 0.03638878092169762
step: 400, loss: 3.6194098356645554e-05
step: 410, loss: 9.514297562418506e-05
step: 420, loss: 0.000311344803776592
step: 430, loss: 0.024887388572096825
step: 440, loss: 0.0002140430297004059
step: 450, loss: 9.989509271690622e-05
step: 460, loss: 0.00026201203581877053
step: 470, loss: 0.0024047328624874353
step: 480, loss: 0.000413648464018479
step: 490, loss: 0.0009267961140722036
epoch 17: dev_f1=0.8469433288710397, f1=0.7072599531615925, best_f1=0.729769494850417
step: 0, loss: 2.800979564199224e-05
step: 10, loss: 5.489867544383742e-05
step: 20, loss: 6.173952715471387e-05
step: 30, loss: 0.008166877552866936
step: 40, loss: 2.524218325561378e-05
step: 50, loss: 4.4315933337202296e-05
step: 60, loss: 0.008919904008507729
step: 70, loss: 0.000125361344544217
step: 80, loss: 3.7628069549100474e-05
step: 90, loss: 0.0004627869348041713
step: 100, loss: 6.522319745272398e-05
step: 110, loss: 0.0001715217949822545
step: 120, loss: 0.00014628989447373897
step: 130, loss: 0.034467507153749466
step: 140, loss: 8.50837241159752e-05
step: 150, loss: 0.00012397310638334602
step: 160, loss: 6.26057808403857e-05
step: 170, loss: 0.00014225137419998646
step: 180, loss: 0.0003146746021229774
step: 190, loss: 4.658141915570013e-05
step: 200, loss: 4.0049184462986887e-05
step: 210, loss: 0.00012969368253834546
step: 220, loss: 0.007248666137456894
step: 230, loss: 5.980992136755958e-05
step: 240, loss: 9.324679558631033e-05
step: 250, loss: 0.00044061176595278084
step: 260, loss: 0.003049176884815097
step: 270, loss: 0.0011353036388754845
step: 280, loss: 0.014065036550164223
step: 290, loss: 0.0011940993135794997
step: 300, loss: 0.00010675972589524463
step: 310, loss: 0.05240049213171005
step: 320, loss: 0.0002095222589559853
step: 330, loss: 0.0013295725220814347
step: 340, loss: 4.5725337258772925e-05
step: 350, loss: 3.2632833608658984e-05
step: 360, loss: 0.00025448828819207847
step: 370, loss: 3.136618033749983e-05
step: 380, loss: 6.331511394819245e-05
step: 390, loss: 0.00899225752800703
step: 400, loss: 3.921205643564463e-05
step: 410, loss: 0.0001088813878595829
step: 420, loss: 0.0047959228977561
step: 430, loss: 0.0004559650842566043
step: 440, loss: 0.0008746678940951824
step: 450, loss: 0.014367451891303062
step: 460, loss: 0.02612638659775257
step: 470, loss: 6.0764192312490195e-05
step: 480, loss: 0.0008509509498253465
step: 490, loss: 0.0032088083680719137
epoch 18: dev_f1=0.8337109198006344, f1=0.6858513189448441, best_f1=0.729769494850417
step: 0, loss: 0.015407353639602661
step: 10, loss: 0.00026386009994894266
step: 20, loss: 5.11761027155444e-05
step: 30, loss: 0.00010083561937790364
step: 40, loss: 0.00017627052147872746
step: 50, loss: 0.00028961122734472156
step: 60, loss: 8.557210821891204e-05
step: 70, loss: 0.00010363485489506274
step: 80, loss: 0.0007935717585496604
step: 90, loss: 7.307007035706192e-05
step: 100, loss: 0.04885571449995041
step: 110, loss: 4.596813960233703e-05
step: 120, loss: 0.010580756701529026
step: 130, loss: 5.352387597667985e-05
step: 140, loss: 0.00046590398414991796
step: 150, loss: 0.000524797011166811
step: 160, loss: 5.132365913596004e-05
step: 170, loss: 0.0002677083539310843
step: 180, loss: 0.0024583921767771244
step: 190, loss: 0.00011297963646939024
step: 200, loss: 4.02960431529209e-05
step: 210, loss: 0.0002401268866378814
step: 220, loss: 4.730939326691441e-05
step: 230, loss: 0.00026769869145937264
step: 240, loss: 0.015024172142148018
step: 250, loss: 0.013896872289478779
step: 260, loss: 0.0010153185576200485
step: 270, loss: 0.0001848125393735245
step: 280, loss: 0.02500191144645214
step: 290, loss: 6.037372077116743e-05
step: 300, loss: 0.0006092123221606016
step: 310, loss: 0.00021181494230404496
step: 320, loss: 0.010534737259149551
step: 330, loss: 0.00017381273210048676
step: 340, loss: 5.0229529733769596e-05
step: 350, loss: 8.333272853633389e-05
step: 360, loss: 0.0001144950874731876
step: 370, loss: 0.00010520216164877638
step: 380, loss: 0.00022025813814252615
step: 390, loss: 0.012825870886445045
step: 400, loss: 0.00037053486448712647
step: 410, loss: 0.0015678550116717815
step: 420, loss: 3.8089823647169396e-05
step: 430, loss: 0.0004635240766219795
step: 440, loss: 3.830073546851054e-05
step: 450, loss: 8.395970507990569e-05
step: 460, loss: 0.0008166038314811885
step: 470, loss: 5.460404645418748e-05
step: 480, loss: 0.00010552018648013473
step: 490, loss: 0.02678648754954338
epoch 19: dev_f1=0.8502772643253235, f1=0.6928429423459245, best_f1=0.729769494850417
step: 0, loss: 0.024150997400283813
step: 10, loss: 0.0003394347440917045
step: 20, loss: 5.621122181764804e-05
step: 30, loss: 0.00659586675465107
step: 40, loss: 3.361207927810028e-05
step: 50, loss: 0.005053888075053692
step: 60, loss: 0.00011581390572246164
step: 70, loss: 0.00029477401403710246
step: 80, loss: 0.00016770533693488687
step: 90, loss: 0.0003065415658056736
step: 100, loss: 0.04366765543818474
step: 110, loss: 3.901318632415496e-05
step: 120, loss: 0.014356186613440514
step: 130, loss: 0.0002326564717805013
step: 140, loss: 2.8013517294311896e-05
step: 150, loss: 4.040859857923351e-05
step: 160, loss: 6.660750659648329e-05
step: 170, loss: 7.622576231369749e-05
step: 180, loss: 0.004764121025800705
step: 190, loss: 0.00013205851428210735
step: 200, loss: 0.02582915499806404
step: 210, loss: 3.217461926396936e-05
step: 220, loss: 0.000267570314463228
step: 230, loss: 0.00035217919503338635
step: 240, loss: 0.008752493187785149
step: 250, loss: 0.002041073050349951
step: 260, loss: 3.562696656445041e-05
step: 270, loss: 3.843560261884704e-05
step: 280, loss: 5.33272759639658e-05
step: 290, loss: 3.823019869741984e-05
step: 300, loss: 4.4762567995348945e-05
step: 310, loss: 3.98580014007166e-05
step: 320, loss: 3.278041913290508e-05
step: 330, loss: 9.504579065833241e-05
step: 340, loss: 7.996989734238014e-05
step: 350, loss: 4.9981139454757795e-05
step: 360, loss: 0.006869114935398102
step: 370, loss: 6.224869139259681e-05
step: 380, loss: 7.396801811410114e-05
step: 390, loss: 0.0035610608756542206
step: 400, loss: 5.281931589706801e-05
step: 410, loss: 0.0001344308111583814
step: 420, loss: 0.0014980037230998278
step: 430, loss: 6.530391692649573e-05
step: 440, loss: 0.000201153801754117
step: 450, loss: 0.00043915482820011675
step: 460, loss: 0.00019463477656245232
step: 470, loss: 0.0001193592106574215
step: 480, loss: 0.0011367484694346786
step: 490, loss: 7.661258860025555e-05
epoch 20: dev_f1=0.8482886216466234, f1=0.6911618669314796, best_f1=0.729769494850417
