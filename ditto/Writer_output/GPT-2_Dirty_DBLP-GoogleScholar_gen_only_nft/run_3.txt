cuda
Device: cuda
step: 0, loss: 0.6340423822402954
step: 10, loss: 0.49368396401405334
step: 20, loss: 0.4743177592754364
step: 30, loss: 0.5565995573997498
step: 40, loss: 0.5320320129394531
step: 50, loss: 0.62364262342453
step: 60, loss: 0.5149121880531311
step: 70, loss: 0.49140122532844543
step: 80, loss: 0.39080139994621277
step: 90, loss: 0.40801048278808594
step: 100, loss: 0.37155988812446594
step: 110, loss: 0.29769575595855713
step: 120, loss: 0.43717995285987854
step: 130, loss: 0.46899276971817017
step: 140, loss: 0.5169170498847961
step: 150, loss: 0.22794078290462494
step: 160, loss: 0.5161838531494141
step: 170, loss: 0.2759644091129303
step: 180, loss: 0.29346340894699097
step: 190, loss: 0.27037692070007324
step: 200, loss: 0.5134254097938538
step: 210, loss: 0.31870126724243164
step: 220, loss: 0.44513267278671265
step: 230, loss: 0.23012129962444305
step: 240, loss: 0.2235831618309021
step: 250, loss: 0.42291271686553955
step: 260, loss: 0.26107290387153625
step: 270, loss: 0.4171154797077179
step: 280, loss: 0.23372025787830353
step: 290, loss: 0.3858790695667267
step: 300, loss: 0.4406045973300934
step: 310, loss: 0.40819573402404785
step: 320, loss: 0.3629137873649597
step: 330, loss: 0.3951466381549835
step: 340, loss: 0.317807137966156
step: 350, loss: 0.24049602448940277
step: 360, loss: 0.5685285329818726
step: 370, loss: 0.3703216016292572
step: 380, loss: 0.28950923681259155
step: 390, loss: 0.28010687232017517
step: 400, loss: 0.294599711894989
step: 410, loss: 0.3704310357570648
epoch 1: dev_f1=0.8326180257510729, f1=0.7507598784194528, best_f1=0.7507598784194528
step: 0, loss: 0.2665020823478699
step: 10, loss: 0.36641380190849304
step: 20, loss: 0.3375135362148285
step: 30, loss: 0.177544966340065
step: 40, loss: 0.16007927060127258
step: 50, loss: 0.259324848651886
step: 60, loss: 0.142957866191864
step: 70, loss: 0.25017067790031433
step: 80, loss: 0.15511271357536316
step: 90, loss: 0.23065313696861267
step: 100, loss: 0.17905567586421967
step: 110, loss: 0.31466466188430786
step: 120, loss: 0.21180039644241333
step: 130, loss: 0.47521764039993286
step: 140, loss: 0.2831254005432129
step: 150, loss: 0.3494178056716919
step: 160, loss: 0.13245998322963715
step: 170, loss: 0.13800737261772156
step: 180, loss: 0.33859899640083313
step: 190, loss: 0.24168811738491058
step: 200, loss: 0.3109728693962097
step: 210, loss: 0.40124860405921936
step: 220, loss: 0.36779141426086426
step: 230, loss: 0.18587657809257507
step: 240, loss: 0.09474130719900131
step: 250, loss: 0.20393402874469757
step: 260, loss: 0.27642014622688293
step: 270, loss: 0.17850305140018463
step: 280, loss: 0.1334313005208969
step: 290, loss: 0.2599222958087921
step: 300, loss: 0.23593838512897491
step: 310, loss: 0.17278710007667542
step: 320, loss: 0.3464164435863495
step: 330, loss: 0.31120872497558594
step: 340, loss: 0.09998810291290283
step: 350, loss: 0.30792343616485596
step: 360, loss: 0.16120243072509766
step: 370, loss: 0.14347568154335022
step: 380, loss: 0.19916117191314697
step: 390, loss: 0.1331843137741089
step: 400, loss: 0.3799169957637787
step: 410, loss: 0.41168949007987976
epoch 2: dev_f1=0.863013698630137, f1=0.767953102100635, best_f1=0.767953102100635
step: 0, loss: 0.26066312193870544
step: 10, loss: 0.10441652685403824
step: 20, loss: 0.1418372243642807
step: 30, loss: 0.06542445719242096
step: 40, loss: 0.31452617049217224
step: 50, loss: 0.21486088633537292
step: 60, loss: 0.1945856511592865
step: 70, loss: 0.0764111652970314
step: 80, loss: 0.2824481427669525
step: 90, loss: 0.4473945200443268
step: 100, loss: 0.24206210672855377
step: 110, loss: 0.05744878947734833
step: 120, loss: 0.20447538793087006
step: 130, loss: 0.13828939199447632
step: 140, loss: 0.2500705420970917
step: 150, loss: 0.14027133584022522
step: 160, loss: 0.26788681745529175
step: 170, loss: 0.39836642146110535
step: 180, loss: 0.29487720131874084
step: 190, loss: 0.19799530506134033
step: 200, loss: 0.11725634336471558
step: 210, loss: 0.27625444531440735
step: 220, loss: 0.15233275294303894
step: 230, loss: 0.22648818790912628
step: 240, loss: 0.06016365438699722
step: 250, loss: 0.3327791690826416
step: 260, loss: 0.15679322183132172
step: 270, loss: 0.12817655503749847
step: 280, loss: 0.11149716377258301
step: 290, loss: 0.13755691051483154
step: 300, loss: 0.14573009312152863
step: 310, loss: 0.10664665699005127
step: 320, loss: 0.11671320348978043
step: 330, loss: 0.0912540853023529
step: 340, loss: 0.1049543023109436
step: 350, loss: 0.19736966490745544
step: 360, loss: 0.20261405408382416
step: 370, loss: 0.09021265804767609
step: 380, loss: 0.039192840456962585
step: 390, loss: 0.27295982837677
step: 400, loss: 0.07162200659513474
step: 410, loss: 0.24582985043525696
epoch 3: dev_f1=0.8400000000000001, f1=0.692191435768262, best_f1=0.767953102100635
step: 0, loss: 0.13699889183044434
step: 10, loss: 0.037222977727651596
step: 20, loss: 0.2090272754430771
step: 30, loss: 0.16769269108772278
step: 40, loss: 0.05573038384318352
step: 50, loss: 0.03403357043862343
step: 60, loss: 0.13613586127758026
step: 70, loss: 0.21077992022037506
step: 80, loss: 0.06664998829364777
step: 90, loss: 0.06891871988773346
step: 100, loss: 0.1540897935628891
step: 110, loss: 0.24469393491744995
step: 120, loss: 0.08781018108129501
step: 130, loss: 0.18106764554977417
step: 140, loss: 0.1426040679216385
step: 150, loss: 0.056010425090789795
step: 160, loss: 0.0761081799864769
step: 170, loss: 0.10611477494239807
step: 180, loss: 0.019901767373085022
step: 190, loss: 0.28789159655570984
step: 200, loss: 0.17097724974155426
step: 210, loss: 0.06415025144815445
step: 220, loss: 0.06922597438097
step: 230, loss: 0.23525716364383698
step: 240, loss: 0.17724309861660004
step: 250, loss: 0.16375750303268433
step: 260, loss: 0.16219165921211243
step: 270, loss: 0.11414863914251328
step: 280, loss: 0.07447858154773712
step: 290, loss: 0.22879455983638763
step: 300, loss: 0.08940967172384262
step: 310, loss: 0.10042531043291092
step: 320, loss: 0.13694460690021515
step: 330, loss: 0.03856648504734039
step: 340, loss: 0.1878942847251892
step: 350, loss: 0.17699070274829865
step: 360, loss: 0.10270629823207855
step: 370, loss: 0.05668332055211067
step: 380, loss: 0.13045614957809448
step: 390, loss: 0.05340275540947914
step: 400, loss: 0.05726132541894913
step: 410, loss: 0.14044836163520813
epoch 4: dev_f1=0.854368932038835, f1=0.7147058823529412, best_f1=0.767953102100635
step: 0, loss: 0.016783636063337326
step: 10, loss: 0.14784076809883118
step: 20, loss: 0.07501926273107529
step: 30, loss: 0.034071486443281174
step: 40, loss: 0.0375472754240036
step: 50, loss: 0.15930692851543427
step: 60, loss: 0.23169353604316711
step: 70, loss: 0.09624317288398743
step: 80, loss: 0.024230457842350006
step: 90, loss: 0.10965067893266678
step: 100, loss: 0.044495146721601486
step: 110, loss: 0.10129525512456894
step: 120, loss: 0.013347805477678776
step: 130, loss: 0.007771960459649563
step: 140, loss: 0.21836069226264954
step: 150, loss: 0.14445224404335022
step: 160, loss: 0.050198547542095184
step: 170, loss: 0.09267895668745041
step: 180, loss: 0.118789903819561
step: 190, loss: 0.14249250292778015
step: 200, loss: 0.025339027866721153
step: 210, loss: 0.07609497755765915
step: 220, loss: 0.26869475841522217
step: 230, loss: 0.04714144393801689
step: 240, loss: 0.030970444902777672
step: 250, loss: 0.13005690276622772
step: 260, loss: 0.06045475974678993
step: 270, loss: 0.08351156115531921
step: 280, loss: 0.16215956211090088
step: 290, loss: 0.10206077247858047
step: 300, loss: 0.0977783277630806
step: 310, loss: 0.08425510674715042
step: 320, loss: 0.021876579150557518
step: 330, loss: 0.09064039587974548
step: 340, loss: 0.11370115727186203
step: 350, loss: 0.039630454033613205
step: 360, loss: 0.21138618886470795
step: 370, loss: 0.1949864774942398
step: 380, loss: 0.030140701681375504
step: 390, loss: 0.06775538623332977
step: 400, loss: 0.06384178251028061
step: 410, loss: 0.1671316772699356
epoch 5: dev_f1=0.8506581933726736, f1=0.7078810759792354, best_f1=0.767953102100635
step: 0, loss: 0.04672146216034889
step: 10, loss: 0.1552022248506546
step: 20, loss: 0.013889852911233902
step: 30, loss: 0.047615762799978256
step: 40, loss: 0.005713409278541803
step: 50, loss: 0.10080382972955704
step: 60, loss: 0.010070493444800377
step: 70, loss: 0.046835046261548996
step: 80, loss: 0.07815247029066086
step: 90, loss: 0.03592012822628021
step: 100, loss: 0.0916537493467331
step: 110, loss: 0.08009246736764908
step: 120, loss: 0.023086437955498695
step: 130, loss: 0.08642825484275818
step: 140, loss: 0.03885654732584953
step: 150, loss: 0.10855967551469803
step: 160, loss: 0.1336810141801834
step: 170, loss: 0.06250767409801483
step: 180, loss: 0.0483475923538208
step: 190, loss: 0.1210944652557373
step: 200, loss: 0.12107490003108978
step: 210, loss: 0.012960094958543777
step: 220, loss: 0.007098340429365635
step: 230, loss: 0.061703938990831375
step: 240, loss: 0.07961287349462509
step: 250, loss: 0.014878939837217331
step: 260, loss: 0.039015352725982666
step: 270, loss: 0.17424660921096802
step: 280, loss: 0.03384760022163391
step: 290, loss: 0.04832998290657997
step: 300, loss: 0.012064254842698574
step: 310, loss: 0.034158527851104736
step: 320, loss: 0.06039603799581528
step: 330, loss: 0.01241935882717371
step: 340, loss: 0.10591503977775574
step: 350, loss: 0.07850607484579086
step: 360, loss: 0.19923259317874908
step: 370, loss: 0.1326635777950287
step: 380, loss: 0.028384240344166756
step: 390, loss: 0.08100928366184235
step: 400, loss: 0.04534877836704254
step: 410, loss: 0.02994040586054325
epoch 6: dev_f1=0.829842931937173, f1=0.6928702010968921, best_f1=0.767953102100635
step: 0, loss: 0.06624149531126022
step: 10, loss: 0.06352827697992325
step: 20, loss: 0.011514059267938137
step: 30, loss: 0.053765520453453064
step: 40, loss: 0.04367990419268608
step: 50, loss: 0.06677667051553726
step: 60, loss: 0.022347670048475266
step: 70, loss: 0.003933683503419161
step: 80, loss: 0.009412931278347969
step: 90, loss: 0.03911967948079109
step: 100, loss: 0.02717410773038864
step: 110, loss: 0.023865271359682083
step: 120, loss: 0.08719412982463837
step: 130, loss: 0.2576705515384674
step: 140, loss: 0.10439130663871765
step: 150, loss: 0.09742164611816406
step: 160, loss: 0.008205508813261986
step: 170, loss: 0.13179224729537964
step: 180, loss: 0.005098639987409115
step: 190, loss: 0.1240297257900238
step: 200, loss: 0.07202830910682678
step: 210, loss: 0.002342857187613845
step: 220, loss: 0.11113592982292175
step: 230, loss: 0.07494587451219559
step: 240, loss: 0.03743407130241394
step: 250, loss: 0.01165526732802391
step: 260, loss: 0.06204826384782791
step: 270, loss: 0.02422259747982025
step: 280, loss: 0.08594169467687607
step: 290, loss: 0.07577423751354218
step: 300, loss: 0.10491275042295456
step: 310, loss: 0.0018507252680137753
step: 320, loss: 0.06719259172677994
step: 330, loss: 0.014681479893624783
step: 340, loss: 0.011830458417534828
step: 350, loss: 0.06253954768180847
step: 360, loss: 0.18341657519340515
step: 370, loss: 0.016953974962234497
step: 380, loss: 0.06764910370111465
step: 390, loss: 0.05808330327272415
step: 400, loss: 0.05591917783021927
step: 410, loss: 0.054300881922245026
epoch 7: dev_f1=0.8373947718210013, f1=0.7012025901942646, best_f1=0.767953102100635
step: 0, loss: 0.04193461686372757
step: 10, loss: 0.01384770218282938
step: 20, loss: 0.01409665122628212
step: 30, loss: 0.026089699938893318
step: 40, loss: 0.03426152095198631
step: 50, loss: 0.02155478484928608
step: 60, loss: 0.09025291353464127
step: 70, loss: 0.021766554564237595
step: 80, loss: 0.007234388496726751
step: 90, loss: 0.0021768822334706783
step: 100, loss: 0.003611344611272216
step: 110, loss: 0.09159506857395172
step: 120, loss: 0.0622122585773468
step: 130, loss: 0.02237376943230629
step: 140, loss: 0.06840784847736359
step: 150, loss: 0.12414582818746567
step: 160, loss: 0.0283548291772604
step: 170, loss: 0.02721656858921051
step: 180, loss: 0.05665641650557518
step: 190, loss: 0.041102536022663116
step: 200, loss: 0.08327969163656235
step: 210, loss: 0.0168899018317461
step: 220, loss: 0.015271065756678581
step: 230, loss: 0.04746168479323387
step: 240, loss: 0.00618618493899703
step: 250, loss: 0.037548698484897614
step: 260, loss: 0.09876187145709991
step: 270, loss: 0.008964176289737225
step: 280, loss: 0.14310826361179352
step: 290, loss: 0.1289154589176178
step: 300, loss: 0.06534957140684128
step: 310, loss: 0.07228709757328033
step: 320, loss: 0.0791597068309784
step: 330, loss: 0.005962086375802755
step: 340, loss: 0.08033376187086105
step: 350, loss: 0.24078723788261414
step: 360, loss: 0.030156873166561127
step: 370, loss: 0.09708105772733688
step: 380, loss: 0.05660666897892952
step: 390, loss: 0.026526931673288345
step: 400, loss: 0.026114609092473984
step: 410, loss: 0.09155842661857605
epoch 8: dev_f1=0.833477135461605, f1=0.6967624259005928, best_f1=0.767953102100635
step: 0, loss: 0.13589845597743988
step: 10, loss: 0.0007477120961993933
step: 20, loss: 0.026022206991910934
step: 30, loss: 0.0026123702991753817
step: 40, loss: 0.027209704741835594
step: 50, loss: 0.009972243569791317
step: 60, loss: 0.059192437678575516
step: 70, loss: 0.04918255656957626
step: 80, loss: 0.0005040628602728248
step: 90, loss: 0.15283429622650146
step: 100, loss: 0.0761014074087143
step: 110, loss: 0.1139427050948143
step: 120, loss: 0.021958712488412857
step: 130, loss: 0.08515182137489319
step: 140, loss: 0.007003838196396828
step: 150, loss: 0.04407043755054474
step: 160, loss: 0.04929911717772484
step: 170, loss: 0.002809507306665182
step: 180, loss: 0.0022818257566541433
step: 190, loss: 0.0056351106613874435
step: 200, loss: 0.000727611593902111
step: 210, loss: 0.01893535815179348
step: 220, loss: 0.005670404992997646
step: 230, loss: 0.0010234650690108538
step: 240, loss: 0.04182235896587372
step: 250, loss: 0.004326953087002039
step: 260, loss: 0.06446690857410431
step: 270, loss: 0.006146096624433994
step: 280, loss: 0.05543673038482666
step: 290, loss: 0.04652057960629463
step: 300, loss: 0.0006793832289986312
step: 310, loss: 0.00895426794886589
step: 320, loss: 0.09679099917411804
step: 330, loss: 0.017574604600667953
step: 340, loss: 0.012579106725752354
step: 350, loss: 0.014534040354192257
step: 360, loss: 0.028492938727140427
step: 370, loss: 0.008347091265022755
step: 380, loss: 0.0005071833147667348
step: 390, loss: 0.041208505630493164
step: 400, loss: 0.09882976114749908
step: 410, loss: 0.00288739544339478
epoch 9: dev_f1=0.8400349650349651, f1=0.7048658481127785, best_f1=0.767953102100635
step: 0, loss: 0.04117349535226822
step: 10, loss: 0.02135992795228958
step: 20, loss: 0.054742101579904556
step: 30, loss: 0.011847462505102158
step: 40, loss: 0.001633637584745884
step: 50, loss: 0.01346080843359232
step: 60, loss: 0.0031109664123505354
step: 70, loss: 0.025643298402428627
step: 80, loss: 0.03812341019511223
step: 90, loss: 0.0038813669234514236
step: 100, loss: 0.017229733988642693
step: 110, loss: 0.0032431851141154766
step: 120, loss: 0.10362124443054199
step: 130, loss: 0.11120368540287018
step: 140, loss: 0.04400872439146042
step: 150, loss: 0.06685242801904678
step: 160, loss: 0.015580309554934502
step: 170, loss: 0.007187962532043457
step: 180, loss: 0.0031654061749577522
step: 190, loss: 0.00957432109862566
step: 200, loss: 0.003536262782290578
step: 210, loss: 0.010946393013000488
step: 220, loss: 0.0034633870236575603
step: 230, loss: 0.002744557335972786
step: 240, loss: 0.002316983649507165
step: 250, loss: 0.0663081705570221
step: 260, loss: 0.008847633376717567
step: 270, loss: 0.08586116135120392
step: 280, loss: 0.05139471963047981
step: 290, loss: 0.016853688284754753
step: 300, loss: 0.13858652114868164
step: 310, loss: 0.016349779441952705
step: 320, loss: 0.09577451646327972
step: 330, loss: 0.0012315905187278986
step: 340, loss: 0.0018840323900803924
step: 350, loss: 0.0008050655014812946
step: 360, loss: 0.0025949159171432257
step: 370, loss: 0.017286084592342377
step: 380, loss: 0.001932633575052023
step: 390, loss: 0.0006618411280214787
step: 400, loss: 0.08888433873653412
step: 410, loss: 0.0007646383601240814
epoch 10: dev_f1=0.8512728896828943, f1=0.7044264635887673, best_f1=0.767953102100635
step: 0, loss: 0.0525689497590065
step: 10, loss: 0.002293060068041086
step: 20, loss: 0.010592876933515072
step: 30, loss: 0.04151168838143349
step: 40, loss: 0.01978485658764839
step: 50, loss: 0.03959408029913902
step: 60, loss: 0.0035301020834594965
step: 70, loss: 0.004536801017820835
step: 80, loss: 0.015401928685605526
step: 90, loss: 0.0039732796140015125
step: 100, loss: 0.0012033659731969237
step: 110, loss: 0.004482811316847801
step: 120, loss: 0.001499112811870873
step: 130, loss: 0.012088161893188953
step: 140, loss: 0.00198157737031579
step: 150, loss: 0.031375814229249954
step: 160, loss: 0.038731466978788376
step: 170, loss: 0.0007243190775625408
step: 180, loss: 0.03570674732327461
step: 190, loss: 0.003103377763181925
step: 200, loss: 0.0017838929779827595
step: 210, loss: 0.0012804415309801698
step: 220, loss: 0.03798768296837807
step: 230, loss: 0.08370120078325272
step: 240, loss: 0.0067688473500311375
step: 250, loss: 0.10946565866470337
step: 260, loss: 0.0018554398557171226
step: 270, loss: 0.010452186688780785
step: 280, loss: 0.009530194103717804
step: 290, loss: 0.015699420124292374
step: 300, loss: 0.006952568423002958
step: 310, loss: 0.004973545204848051
step: 320, loss: 0.019226685166358948
step: 330, loss: 0.003139796433970332
step: 340, loss: 0.018891939893364906
step: 350, loss: 0.08304738998413086
step: 360, loss: 0.015647465363144875
step: 370, loss: 0.02624782919883728
step: 380, loss: 0.001939770532771945
step: 390, loss: 0.13508087396621704
step: 400, loss: 0.08438365161418915
step: 410, loss: 0.01165758352726698
epoch 11: dev_f1=0.8323949761801646, f1=0.7118491921005385, best_f1=0.767953102100635
step: 0, loss: 0.05301821604371071
step: 10, loss: 0.021181056275963783
step: 20, loss: 0.0017125967424362898
step: 30, loss: 0.10597231984138489
step: 40, loss: 0.0003091797698289156
step: 50, loss: 0.011347910389304161
step: 60, loss: 0.03520816192030907
step: 70, loss: 0.03079383447766304
step: 80, loss: 0.0430293008685112
step: 90, loss: 0.04973141476511955
step: 100, loss: 0.0007093921303749084
step: 110, loss: 0.004913759883493185
step: 120, loss: 0.003605929668992758
step: 130, loss: 0.05753622576594353
step: 140, loss: 0.00017975945957005024
step: 150, loss: 0.004495623055845499
step: 160, loss: 0.00784341525286436
step: 170, loss: 0.023615894839167595
step: 180, loss: 0.013919149525463581
step: 190, loss: 0.0020188631024211645
step: 200, loss: 0.013459957204759121
step: 210, loss: 0.04610007256269455
step: 220, loss: 0.004958480130881071
step: 230, loss: 0.005791930016130209
step: 240, loss: 0.01615450158715248
step: 250, loss: 0.013458536006510258
step: 260, loss: 0.00028513502911664546
step: 270, loss: 0.0020951491314917803
step: 280, loss: 0.00032278121216222644
step: 290, loss: 0.002200161339715123
step: 300, loss: 0.027072811499238014
step: 310, loss: 0.05269494280219078
step: 320, loss: 0.03179406374692917
step: 330, loss: 0.000415160262491554
step: 340, loss: 0.00039516016840934753
step: 350, loss: 0.0014401617227122188
step: 360, loss: 0.0022485980298370123
step: 370, loss: 0.01759445108473301
step: 380, loss: 0.001142435590736568
step: 390, loss: 0.0003802414867095649
step: 400, loss: 0.005692023318260908
step: 410, loss: 0.023747852072119713
epoch 12: dev_f1=0.8197424892703862, f1=0.7007943512797882, best_f1=0.767953102100635
step: 0, loss: 0.0003308607847429812
step: 10, loss: 0.00023291446268558502
step: 20, loss: 0.0001257022377103567
step: 30, loss: 0.0009548710659146309
step: 40, loss: 0.0008447212167084217
step: 50, loss: 0.004112109076231718
step: 60, loss: 0.0029089052695780993
step: 70, loss: 0.09851372987031937
step: 80, loss: 0.0050047473050653934
step: 90, loss: 0.004444772843271494
step: 100, loss: 0.001053658314049244
step: 110, loss: 0.0022189035080373287
step: 120, loss: 0.003885518293827772
step: 130, loss: 0.06359224766492844
step: 140, loss: 0.0008786422549746931
step: 150, loss: 0.00033041651477105916
step: 160, loss: 0.0007164667476899922
step: 170, loss: 0.0032116177026182413
step: 180, loss: 0.0001058309426298365
step: 190, loss: 0.012439767830073833
step: 200, loss: 0.04044076427817345
step: 210, loss: 0.0032800068147480488
step: 220, loss: 0.12131799012422562
step: 230, loss: 0.018931951373815536
step: 240, loss: 0.0004011470009572804
step: 250, loss: 0.0005904841236770153
step: 260, loss: 0.029219120740890503
step: 270, loss: 0.005694820545613766
step: 280, loss: 0.0018661919748410583
step: 290, loss: 0.001293692272156477
step: 300, loss: 0.0001822881167754531
step: 310, loss: 8.65285110194236e-05
step: 320, loss: 0.0029127292800694704
step: 330, loss: 0.01203982811421156
step: 340, loss: 0.006197314243763685
step: 350, loss: 0.000346044689649716
step: 360, loss: 0.00011002313840435818
step: 370, loss: 0.014078800566494465
step: 380, loss: 0.0048871892504394054
step: 390, loss: 0.10017513483762741
step: 400, loss: 0.006938608828932047
step: 410, loss: 0.00042184715857729316
epoch 13: dev_f1=0.8438308886971527, f1=0.7306833407771325, best_f1=0.767953102100635
step: 0, loss: 0.015537706203758717
step: 10, loss: 0.0008674027631059289
step: 20, loss: 0.0010873489081859589
step: 30, loss: 0.0016822797479107976
step: 40, loss: 0.0006950808456167579
step: 50, loss: 0.05082882195711136
step: 60, loss: 0.051199063658714294
step: 70, loss: 0.0007490223506465554
step: 80, loss: 0.008064945228397846
step: 90, loss: 0.008053324185311794
step: 100, loss: 0.0012361814733594656
step: 110, loss: 0.00010159149678656831
step: 120, loss: 0.0009453583043068647
step: 130, loss: 0.005491843447089195
step: 140, loss: 0.00016634086205158383
step: 150, loss: 0.0003726938448380679
step: 160, loss: 0.00018500181613489985
step: 170, loss: 0.0006393090006895363
step: 180, loss: 0.0006113971467129886
step: 190, loss: 0.0006404712330549955
step: 200, loss: 0.0009944699704647064
step: 210, loss: 0.003986097872257233
step: 220, loss: 0.00248113926500082
step: 230, loss: 0.0027333947364240885
step: 240, loss: 0.0005487603484652936
step: 250, loss: 0.016442691907286644
step: 260, loss: 0.029823841527104378
step: 270, loss: 0.0001536523923277855
step: 280, loss: 0.0015520628076046705
step: 290, loss: 0.017009448260068893
step: 300, loss: 0.001271669170819223
step: 310, loss: 0.0004291175282560289
step: 320, loss: 0.0015792973572388291
step: 330, loss: 0.03687747195363045
step: 340, loss: 0.0006381149287335575
step: 350, loss: 0.017067093402147293
step: 360, loss: 0.0019232380436733365
step: 370, loss: 0.0004912897711619735
step: 380, loss: 0.00035571272019296885
step: 390, loss: 0.004671833943575621
step: 400, loss: 0.0037812255322933197
step: 410, loss: 0.00016678826068527997
epoch 14: dev_f1=0.8252386882523869, f1=0.7105038428693425, best_f1=0.767953102100635
step: 0, loss: 0.0029828178230673075
step: 10, loss: 0.0025890201795846224
step: 20, loss: 0.0014328825054690242
step: 30, loss: 0.000924176478292793
step: 40, loss: 0.00032433122396469116
step: 50, loss: 0.001993985380977392
step: 60, loss: 0.08666394650936127
step: 70, loss: 0.00013972906162962317
step: 80, loss: 0.0034757195971906185
step: 90, loss: 0.004086654633283615
step: 100, loss: 0.001582946628332138
step: 110, loss: 0.00017782924987841398
step: 120, loss: 0.0019111927831545472
step: 130, loss: 0.00030838552629575133
step: 140, loss: 0.11205869168043137
step: 150, loss: 0.001139473170042038
step: 160, loss: 0.004149794112890959
step: 170, loss: 0.0008056442602537572
step: 180, loss: 0.015144025906920433
step: 190, loss: 0.0018223935039713979
step: 200, loss: 0.0003113742859568447
step: 210, loss: 0.000525217386893928
step: 220, loss: 0.002756566507741809
step: 230, loss: 0.01922328770160675
step: 240, loss: 0.0036764617543667555
step: 250, loss: 8.612521196482703e-05
step: 260, loss: 0.011099468916654587
step: 270, loss: 0.08829644322395325
step: 280, loss: 0.004450374282896519
step: 290, loss: 0.12866374850273132
step: 300, loss: 0.001022537355311215
step: 310, loss: 0.023232702165842056
step: 320, loss: 0.041753221303224564
step: 330, loss: 0.0002242926275357604
step: 340, loss: 0.0006742414552718401
step: 350, loss: 0.0002816864871419966
step: 360, loss: 0.00020065944408997893
step: 370, loss: 0.00031347485492005944
step: 380, loss: 0.0001715695980237797
step: 390, loss: 0.0017318511381745338
step: 400, loss: 0.00024184456560760736
step: 410, loss: 0.0006194497691467404
epoch 15: dev_f1=0.8314225053078556, f1=0.7055187637969095, best_f1=0.767953102100635
step: 0, loss: 0.0009604937513358891
step: 10, loss: 0.0005347758997231722
step: 20, loss: 0.0007337803253903985
step: 30, loss: 0.10530795902013779
step: 40, loss: 0.001748556038364768
step: 50, loss: 0.005516160279512405
step: 60, loss: 0.0007016775198280811
step: 70, loss: 0.0005757530452683568
step: 80, loss: 0.05645854026079178
step: 90, loss: 0.0016786172054708004
step: 100, loss: 0.05287842079997063
step: 110, loss: 0.00027505483012646437
step: 120, loss: 0.0015706236008554697
step: 130, loss: 0.0008779666386544704
step: 140, loss: 0.004638987593352795
step: 150, loss: 0.0004301353183109313
step: 160, loss: 0.0003509535454213619
step: 170, loss: 0.000284561887383461
step: 180, loss: 0.0009360677213408053
step: 190, loss: 0.000126044440548867
step: 200, loss: 0.0010142708197236061
step: 210, loss: 0.05545417219400406
step: 220, loss: 0.001507327426224947
step: 230, loss: 0.000321781262755394
step: 240, loss: 0.0001540273369755596
step: 250, loss: 0.029227381572127342
step: 260, loss: 0.03900482505559921
step: 270, loss: 0.0005911959451623261
step: 280, loss: 0.006448274943977594
step: 290, loss: 0.0004954346222802997
step: 300, loss: 0.0007246803725138307
step: 310, loss: 0.0007022566860541701
step: 320, loss: 0.0002957805118057877
step: 330, loss: 0.03158479556441307
step: 340, loss: 0.0006447097985073924
step: 350, loss: 0.03628934547305107
step: 360, loss: 0.0028193225152790546
step: 370, loss: 0.00021774647757411003
step: 380, loss: 0.0020389880519360304
step: 390, loss: 0.00042069086339324713
step: 400, loss: 0.0005670514656230807
step: 410, loss: 0.0017924468265846372
epoch 16: dev_f1=0.8430413517118719, f1=0.7105882352941177, best_f1=0.767953102100635
step: 0, loss: 0.006999193225055933
step: 10, loss: 0.00029876039479859173
step: 20, loss: 0.011163435876369476
step: 30, loss: 0.0005211700918152928
step: 40, loss: 0.0006493921391665936
step: 50, loss: 0.007115650922060013
step: 60, loss: 0.00048307463293895125
step: 70, loss: 0.00023939373204484582
step: 80, loss: 0.000177540146978572
step: 90, loss: 8.317372703459114e-05
step: 100, loss: 0.001732178614474833
step: 110, loss: 0.013497802428901196
step: 120, loss: 0.0002713013091124594
step: 130, loss: 0.03284122422337532
step: 140, loss: 9.082858014153317e-05
step: 150, loss: 0.000884125183802098
step: 160, loss: 0.0003403034061193466
step: 170, loss: 0.00016853232227731496
step: 180, loss: 0.0008072098135016859
step: 190, loss: 0.0004137443902436644
step: 200, loss: 0.004428710322827101
step: 210, loss: 0.0005206753266975284
step: 220, loss: 0.0014993792865425348
step: 230, loss: 0.0017482979455962777
step: 240, loss: 0.00021106351050548255
step: 250, loss: 0.0010092402808368206
step: 260, loss: 5.861918180016801e-05
step: 270, loss: 0.0004356442077551037
step: 280, loss: 0.00046653495519421995
step: 290, loss: 5.036657603341155e-05
step: 300, loss: 0.00021564014605246484
step: 310, loss: 0.004615429788827896
step: 320, loss: 0.00018631019338499755
step: 330, loss: 0.00036251189885661006
step: 340, loss: 0.00011525450827321038
step: 350, loss: 0.00025176943745464087
step: 360, loss: 0.009572171606123447
step: 370, loss: 0.000303539534797892
step: 380, loss: 0.0030019355472177267
step: 390, loss: 0.004780616611242294
step: 400, loss: 0.0016967230476439
step: 410, loss: 0.0024802833795547485
epoch 17: dev_f1=0.8378258948298719, f1=0.7154696132596684, best_f1=0.767953102100635
step: 0, loss: 0.00015925821207929403
step: 10, loss: 0.0006640771171078086
step: 20, loss: 0.0005573920789174736
step: 30, loss: 0.00023792849970050156
step: 40, loss: 0.0028672965709120035
step: 50, loss: 0.022050492465496063
step: 60, loss: 0.00010567766730673611
step: 70, loss: 0.00011882122635142878
step: 80, loss: 0.0006262609967961907
step: 90, loss: 0.011365687474608421
step: 100, loss: 5.5760578106855974e-05
step: 110, loss: 0.00032971365726552904
step: 120, loss: 7.54527427488938e-05
step: 130, loss: 5.741235872847028e-05
step: 140, loss: 0.0001944921095855534
step: 150, loss: 0.00032542122062295675
step: 160, loss: 0.001403873786330223
step: 170, loss: 0.001850940054282546
step: 180, loss: 0.0001774635020410642
step: 190, loss: 0.00020924967247992754
step: 200, loss: 8.916300430428237e-05
step: 210, loss: 0.0016724368324503303
step: 220, loss: 0.0005565984174609184
step: 230, loss: 0.0002262799971504137
step: 240, loss: 0.00030870098271407187
step: 250, loss: 7.031494169496e-05
step: 260, loss: 0.0006351047777570784
step: 270, loss: 0.009170200675725937
step: 280, loss: 0.006064928602427244
step: 290, loss: 0.00013183485134504735
step: 300, loss: 0.0011670776875689626
step: 310, loss: 0.008713463321328163
step: 320, loss: 0.0010454811854287982
step: 330, loss: 0.00074812863022089
step: 340, loss: 0.019833654165267944
step: 350, loss: 0.006830940954387188
step: 360, loss: 0.0004972764290869236
step: 370, loss: 0.00025454728165641427
step: 380, loss: 0.00043676685891114175
step: 390, loss: 0.00033334395266138017
step: 400, loss: 0.002370263682678342
step: 410, loss: 0.00010759550059447065
epoch 18: dev_f1=0.8349429323968394, f1=0.7116001834021092, best_f1=0.767953102100635
step: 0, loss: 0.00019827927462756634
step: 10, loss: 0.0008798474445939064
step: 20, loss: 0.000158671333338134
step: 30, loss: 0.015329889953136444
step: 40, loss: 0.0012284956173971295
step: 50, loss: 8.704797073733062e-05
step: 60, loss: 0.0020207474008202553
step: 70, loss: 6.505698547698557e-05
step: 80, loss: 0.0002268520911457017
step: 90, loss: 0.004692263435572386
step: 100, loss: 0.001034598215483129
step: 110, loss: 0.0002582127053756267
step: 120, loss: 0.0009715226478874683
step: 130, loss: 8.448405424132943e-05
step: 140, loss: 0.0002103435981553048
step: 150, loss: 0.00012143336061853915
step: 160, loss: 0.0049033742398023605
step: 170, loss: 0.00024152496189344674
step: 180, loss: 0.0004564722767099738
step: 190, loss: 0.00022554096358362585
step: 200, loss: 8.352018630830571e-05
step: 210, loss: 0.028035299852490425
step: 220, loss: 0.012057249434292316
step: 230, loss: 0.023191401734948158
step: 240, loss: 0.0004551800375338644
step: 250, loss: 0.0005465602735057473
step: 260, loss: 0.06706066429615021
step: 270, loss: 0.003927719313651323
step: 280, loss: 0.0005428448785096407
step: 290, loss: 0.00029931863537058234
step: 300, loss: 0.025179371237754822
step: 310, loss: 0.0001767204375937581
step: 320, loss: 0.00030665736994706094
step: 330, loss: 0.00022178211656864733
step: 340, loss: 9.777515515452251e-05
step: 350, loss: 0.00022750519565306604
step: 360, loss: 0.001010138657875359
step: 370, loss: 0.0011482381960377097
step: 380, loss: 0.00011589640052989125
step: 390, loss: 0.0010112265590578318
step: 400, loss: 0.001994173740968108
step: 410, loss: 0.00020378331828396767
epoch 19: dev_f1=0.8331108144192257, f1=0.7041337668369716, best_f1=0.767953102100635
step: 0, loss: 0.0007619088864885271
step: 10, loss: 0.00017999589908868074
step: 20, loss: 0.0014162983279675245
step: 30, loss: 0.00028956556343473494
step: 40, loss: 0.0002675284631550312
step: 50, loss: 0.0003969712706748396
step: 60, loss: 0.0021995585411787033
step: 70, loss: 0.0005643151816911995
step: 80, loss: 0.00014115596422925591
step: 90, loss: 0.0025451944675296545
step: 100, loss: 0.0002655700081959367
step: 110, loss: 6.714410847052932e-05
step: 120, loss: 6.078113801777363e-05
step: 130, loss: 7.71872146287933e-05
step: 140, loss: 0.0012394437799230218
step: 150, loss: 7.752620876999572e-05
step: 160, loss: 0.004754670429974794
step: 170, loss: 0.011196300387382507
step: 180, loss: 7.034149166429415e-05
step: 190, loss: 0.00011002446262864396
step: 200, loss: 0.005239552352577448
step: 210, loss: 2.820338158926461e-05
step: 220, loss: 0.00023625926405657083
step: 230, loss: 0.0010820695897564292
step: 240, loss: 4.555108898784965e-05
step: 250, loss: 0.0003968412056565285
step: 260, loss: 0.0001367036602459848
step: 270, loss: 8.138731209328398e-05
step: 280, loss: 0.00027199549367651343
step: 290, loss: 0.00011380742216715589
step: 300, loss: 6.69243891024962e-05
step: 310, loss: 5.6592936743982136e-05
step: 320, loss: 0.003590045031160116
step: 330, loss: 0.0001347564539173618
step: 340, loss: 0.0028684011194854975
step: 350, loss: 0.002863359171897173
step: 360, loss: 0.001357428845949471
step: 370, loss: 0.0001257829717360437
step: 380, loss: 0.0002666106738615781
step: 390, loss: 0.004825797863304615
step: 400, loss: 2.5152694433927536e-05
step: 410, loss: 4.669880945584737e-05
epoch 20: dev_f1=0.8350287483414418, f1=0.7042513863216265, best_f1=0.767953102100635
