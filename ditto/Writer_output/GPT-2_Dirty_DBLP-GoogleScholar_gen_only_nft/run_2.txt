cuda
Device: cuda
step: 0, loss: 0.6300323009490967
step: 10, loss: 0.5524566769599915
step: 20, loss: 0.30900660157203674
step: 30, loss: 0.49598291516304016
step: 40, loss: 0.5251308083534241
step: 50, loss: 0.4694877564907074
step: 60, loss: 0.3136528730392456
step: 70, loss: 0.49232953786849976
step: 80, loss: 0.4239165782928467
step: 90, loss: 0.37681928277015686
step: 100, loss: 0.4070671796798706
step: 110, loss: 0.4734940826892853
step: 120, loss: 0.3786499500274658
step: 130, loss: 0.21318700909614563
step: 140, loss: 0.22601200640201569
step: 150, loss: 0.3375750482082367
step: 160, loss: 0.5217976570129395
step: 170, loss: 0.3859185576438904
step: 180, loss: 0.3086242973804474
step: 190, loss: 0.1889144331216812
step: 200, loss: 0.35197460651397705
step: 210, loss: 0.16827775537967682
step: 220, loss: 0.2894475758075714
step: 230, loss: 0.27344876527786255
step: 240, loss: 0.27664750814437866
step: 250, loss: 0.42445746064186096
step: 260, loss: 0.19127337634563446
step: 270, loss: 0.2512376606464386
step: 280, loss: 0.34988734126091003
step: 290, loss: 0.39365074038505554
step: 300, loss: 0.13827252388000488
step: 310, loss: 0.3677903115749359
step: 320, loss: 0.46841126680374146
step: 330, loss: 0.17631658911705017
step: 340, loss: 0.28859829902648926
step: 350, loss: 0.29788437485694885
step: 360, loss: 0.18006719648838043
step: 370, loss: 0.14197160303592682
step: 380, loss: 0.3107835352420807
step: 390, loss: 0.2215181291103363
step: 400, loss: 0.1518283635377884
step: 410, loss: 0.3998856842517853
step: 420, loss: 0.17549718916416168
step: 430, loss: 0.06545945256948471
step: 440, loss: 0.23541375994682312
step: 450, loss: 0.20655934512615204
step: 460, loss: 0.21876586973667145
step: 470, loss: 0.3470473885536194
step: 480, loss: 0.3122173249721527
step: 490, loss: 0.20650167763233185
epoch 1: dev_f1=0.8205128205128205, f1=0.7269174401563264, best_f1=0.7269174401563264
step: 0, loss: 0.43388330936431885
step: 10, loss: 0.21767745912075043
step: 20, loss: 0.27493804693222046
step: 30, loss: 0.19563989341259003
step: 40, loss: 0.20175576210021973
step: 50, loss: 0.31190115213394165
step: 60, loss: 0.307630717754364
step: 70, loss: 0.22919955849647522
step: 80, loss: 0.24916498363018036
step: 90, loss: 0.12719441950321198
step: 100, loss: 0.25990474224090576
step: 110, loss: 0.13126711547374725
step: 120, loss: 0.2426804006099701
step: 130, loss: 0.28712722659111023
step: 140, loss: 0.08574433624744415
step: 150, loss: 0.26130691170692444
step: 160, loss: 0.33305874466896057
step: 170, loss: 0.41470572352409363
step: 180, loss: 0.282512366771698
step: 190, loss: 0.14684338867664337
step: 200, loss: 0.12305687367916107
step: 210, loss: 0.3302832245826721
step: 220, loss: 0.23649951815605164
step: 230, loss: 0.2090761661529541
step: 240, loss: 0.15644659101963043
step: 250, loss: 0.16534622013568878
step: 260, loss: 0.040826473385095596
step: 270, loss: 0.2326279878616333
step: 280, loss: 0.26526322960853577
step: 290, loss: 0.17903666198253632
step: 300, loss: 0.18150024116039276
step: 310, loss: 0.16232457756996155
step: 320, loss: 0.23662875592708588
step: 330, loss: 0.1565328985452652
step: 340, loss: 0.12913697957992554
step: 350, loss: 0.1623675674200058
step: 360, loss: 0.12442334741353989
step: 370, loss: 0.24996614456176758
step: 380, loss: 0.13186562061309814
step: 390, loss: 0.07211019098758698
step: 400, loss: 0.11391705274581909
step: 410, loss: 0.12217281758785248
step: 420, loss: 0.16931438446044922
step: 430, loss: 0.1460888534784317
step: 440, loss: 0.23230789601802826
step: 450, loss: 0.12762399017810822
step: 460, loss: 0.23099595308303833
step: 470, loss: 0.3540383577346802
step: 480, loss: 0.30820348858833313
step: 490, loss: 0.17240294814109802
epoch 2: dev_f1=0.8838077461502567, f1=0.7673509286412512, best_f1=0.7673509286412512
step: 0, loss: 0.21851946413516998
step: 10, loss: 0.09626871347427368
step: 20, loss: 0.07574771344661713
step: 30, loss: 0.15720222890377045
step: 40, loss: 0.06760836392641068
step: 50, loss: 0.08133088797330856
step: 60, loss: 0.1832476705312729
step: 70, loss: 0.39567556977272034
step: 80, loss: 0.1212417259812355
step: 90, loss: 0.15085767209529877
step: 100, loss: 0.1205376610159874
step: 110, loss: 0.1366117149591446
step: 120, loss: 0.3390657603740692
step: 130, loss: 0.2756405472755432
step: 140, loss: 0.1837390512228012
step: 150, loss: 0.09591592103242874
step: 160, loss: 0.07579829543828964
step: 170, loss: 0.22961732745170593
step: 180, loss: 0.09190083295106888
step: 190, loss: 0.20449750125408173
step: 200, loss: 0.09000012278556824
step: 210, loss: 0.20283259451389313
step: 220, loss: 0.3237488567829132
step: 230, loss: 0.16886459290981293
step: 240, loss: 0.2634935975074768
step: 250, loss: 0.38040614128112793
step: 260, loss: 0.06820596754550934
step: 270, loss: 0.21773050725460052
step: 280, loss: 0.20197226107120514
step: 290, loss: 0.11161959171295166
step: 300, loss: 0.18033984303474426
step: 310, loss: 0.10854395478963852
step: 320, loss: 0.3680146038532257
step: 330, loss: 0.2245737612247467
step: 340, loss: 0.28891709446907043
step: 350, loss: 0.10298951715230942
step: 360, loss: 0.17455758154392242
step: 370, loss: 0.22207610309123993
step: 380, loss: 0.16965587437152863
step: 390, loss: 0.19670109450817108
step: 400, loss: 0.1240818053483963
step: 410, loss: 0.15884286165237427
step: 420, loss: 0.20647093653678894
step: 430, loss: 0.14557555317878723
step: 440, loss: 0.18556921184062958
step: 450, loss: 0.27029141783714294
step: 460, loss: 0.21157804131507874
step: 470, loss: 0.20746029913425446
step: 480, loss: 0.0714641809463501
step: 490, loss: 0.12755627930164337
epoch 3: dev_f1=0.8705457825890844, f1=0.7224299065420562, best_f1=0.7673509286412512
step: 0, loss: 0.07786697149276733
step: 10, loss: 0.05538506060838699
step: 20, loss: 0.011778697371482849
step: 30, loss: 0.01923695206642151
step: 40, loss: 0.06891603767871857
step: 50, loss: 0.2266077995300293
step: 60, loss: 0.07711197435855865
step: 70, loss: 0.1928122192621231
step: 80, loss: 0.09822013229131699
step: 90, loss: 0.04579060524702072
step: 100, loss: 0.09345817565917969
step: 110, loss: 0.13262370228767395
step: 120, loss: 0.08968982100486755
step: 130, loss: 0.023203613236546516
step: 140, loss: 0.09221555292606354
step: 150, loss: 0.2234344631433487
step: 160, loss: 0.16202563047409058
step: 170, loss: 0.11307323724031448
step: 180, loss: 0.055817168205976486
step: 190, loss: 0.21766185760498047
step: 200, loss: 0.14557279646396637
step: 210, loss: 0.1555035263299942
step: 220, loss: 0.12707819044589996
step: 230, loss: 0.05679447948932648
step: 240, loss: 0.2798766791820526
step: 250, loss: 0.1763581484556198
step: 260, loss: 0.292888343334198
step: 270, loss: 0.08914130181074142
step: 280, loss: 0.04060674458742142
step: 290, loss: 0.04372924938797951
step: 300, loss: 0.17934851348400116
step: 310, loss: 0.06936121731996536
step: 320, loss: 0.05566739663481712
step: 330, loss: 0.7109480500221252
step: 340, loss: 0.18358731269836426
step: 350, loss: 0.06225411221385002
step: 360, loss: 0.07238677889108658
step: 370, loss: 0.1992168128490448
step: 380, loss: 0.03674574941396713
step: 390, loss: 0.0648282989859581
step: 400, loss: 0.09243914484977722
step: 410, loss: 0.05711555480957031
step: 420, loss: 0.14695300161838531
step: 430, loss: 0.052719809114933014
step: 440, loss: 0.06275990605354309
step: 450, loss: 0.043117865920066833
step: 460, loss: 0.14137177169322968
step: 470, loss: 0.22274315357208252
step: 480, loss: 0.15873928368091583
step: 490, loss: 0.1821909099817276
epoch 4: dev_f1=0.8511821974965229, f1=0.6650148662041625, best_f1=0.7673509286412512
step: 0, loss: 0.0880146324634552
step: 10, loss: 0.0159259345382452
step: 20, loss: 0.10236366093158722
step: 30, loss: 0.039219677448272705
step: 40, loss: 0.07152699679136276
step: 50, loss: 0.03948795050382614
step: 60, loss: 0.13046187162399292
step: 70, loss: 0.00973657425493002
step: 80, loss: 0.05630670115351677
step: 90, loss: 0.09186835587024689
step: 100, loss: 0.07283087819814682
step: 110, loss: 0.01129220798611641
step: 120, loss: 0.16253520548343658
step: 130, loss: 0.22266694903373718
step: 140, loss: 0.04466356709599495
step: 150, loss: 0.005834578536450863
step: 160, loss: 0.07574094831943512
step: 170, loss: 0.015969760715961456
step: 180, loss: 0.15712645649909973
step: 190, loss: 0.16779525578022003
step: 200, loss: 0.025958074256777763
step: 210, loss: 0.09950155019760132
step: 220, loss: 0.12316881865262985
step: 230, loss: 0.2501096725463867
step: 240, loss: 0.02670767903327942
step: 250, loss: 0.11179941147565842
step: 260, loss: 0.06767424196004868
step: 270, loss: 0.07004541158676147
step: 280, loss: 0.04655785858631134
step: 290, loss: 0.02546171471476555
step: 300, loss: 0.03965889289975166
step: 310, loss: 0.0400463230907917
step: 320, loss: 0.13339748978614807
step: 330, loss: 0.06764821708202362
step: 340, loss: 0.07814020663499832
step: 350, loss: 0.08422379195690155
step: 360, loss: 0.1923544555902481
step: 370, loss: 0.07124058902263641
step: 380, loss: 0.15362204611301422
step: 390, loss: 0.19925087690353394
step: 400, loss: 0.09151911735534668
step: 410, loss: 0.05495297163724899
step: 420, loss: 0.09263220429420471
step: 430, loss: 0.05142407864332199
step: 440, loss: 0.10854806005954742
step: 450, loss: 0.04271477088332176
step: 460, loss: 0.11477558314800262
step: 470, loss: 0.2475510835647583
step: 480, loss: 0.24969486892223358
step: 490, loss: 0.017163293436169624
epoch 5: dev_f1=0.8838060384263495, f1=0.7342623738587217, best_f1=0.7673509286412512
step: 0, loss: 0.07002896815538406
step: 10, loss: 0.06976872682571411
step: 20, loss: 0.08731189370155334
step: 30, loss: 0.0863351970911026
step: 40, loss: 0.10864242166280746
step: 50, loss: 0.00658559612929821
step: 60, loss: 0.03193323686718941
step: 70, loss: 0.005100168753415346
step: 80, loss: 0.036866094917058945
step: 90, loss: 0.05655207484960556
step: 100, loss: 0.05069347098469734
step: 110, loss: 0.03279788792133331
step: 120, loss: 0.03110101819038391
step: 130, loss: 0.01762123592197895
step: 140, loss: 0.03176666423678398
step: 150, loss: 0.030976276844739914
step: 160, loss: 0.03146003931760788
step: 170, loss: 0.0012090887175872922
step: 180, loss: 0.02310418337583542
step: 190, loss: 0.029189979657530785
step: 200, loss: 0.15461649000644684
step: 210, loss: 0.24049168825149536
step: 220, loss: 0.021152684465050697
step: 230, loss: 0.025976786389946938
step: 240, loss: 0.04411759972572327
step: 250, loss: 0.07626593112945557
step: 260, loss: 0.22528059780597687
step: 270, loss: 0.14191946387290955
step: 280, loss: 0.05785475671291351
step: 290, loss: 0.09036249667406082
step: 300, loss: 0.039262741804122925
step: 310, loss: 0.009237128309905529
step: 320, loss: 0.22703900933265686
step: 330, loss: 0.025149067863821983
step: 340, loss: 0.04548413306474686
step: 350, loss: 0.09771735221147537
step: 360, loss: 0.01898384466767311
step: 370, loss: 0.024218793958425522
step: 380, loss: 0.024030214175581932
step: 390, loss: 0.049798548221588135
step: 400, loss: 0.013021769933402538
step: 410, loss: 0.022313855588436127
step: 420, loss: 0.027964521199464798
step: 430, loss: 0.09841667115688324
step: 440, loss: 0.024952201172709465
step: 450, loss: 0.008847092278301716
step: 460, loss: 0.030793899670243263
step: 470, loss: 0.06645745038986206
step: 480, loss: 0.05555948615074158
step: 490, loss: 0.031959883868694305
epoch 6: dev_f1=0.8625636279500232, f1=0.6988775012201075, best_f1=0.7673509286412512
step: 0, loss: 0.01328241266310215
step: 10, loss: 0.006825678516179323
step: 20, loss: 0.01292283833026886
step: 30, loss: 0.0431438647210598
step: 40, loss: 0.044094379991292953
step: 50, loss: 0.019323423504829407
step: 60, loss: 0.017684925347566605
step: 70, loss: 0.024084025993943214
step: 80, loss: 0.023174935951828957
step: 90, loss: 0.018558776006102562
step: 100, loss: 0.010128694586455822
step: 110, loss: 0.06342192739248276
step: 120, loss: 0.1070307269692421
step: 130, loss: 0.09245747327804565
step: 140, loss: 0.03442854434251785
step: 150, loss: 0.06598503142595291
step: 160, loss: 0.0043456340208649635
step: 170, loss: 0.012149783782660961
step: 180, loss: 0.06890290975570679
step: 190, loss: 0.010207746177911758
step: 200, loss: 0.020264511927962303
step: 210, loss: 0.06919415295124054
step: 220, loss: 0.008797035552561283
step: 230, loss: 0.058870185166597366
step: 240, loss: 0.009663454256951809
step: 250, loss: 0.003034408437088132
step: 260, loss: 0.08525927364826202
step: 270, loss: 0.015961837023496628
step: 280, loss: 0.0588952898979187
step: 290, loss: 0.012201285921037197
step: 300, loss: 0.06411039084196091
step: 310, loss: 0.018571887165308
step: 320, loss: 0.006572053302079439
step: 330, loss: 0.21869909763336182
step: 340, loss: 0.007324376609176397
step: 350, loss: 0.093548484146595
step: 360, loss: 0.013157973065972328
step: 370, loss: 0.0374133475124836
step: 380, loss: 0.024680597707629204
step: 390, loss: 0.32482919096946716
step: 400, loss: 0.009302368387579918
step: 410, loss: 0.12440595030784607
step: 420, loss: 0.04989437386393547
step: 430, loss: 0.026689235121011734
step: 440, loss: 0.029499445110559464
step: 450, loss: 0.006632495205849409
step: 460, loss: 0.02449261024594307
step: 470, loss: 0.01506924070417881
step: 480, loss: 0.11802033334970474
step: 490, loss: 0.0010295080719515681
epoch 7: dev_f1=0.8544512482336316, f1=0.6666666666666667, best_f1=0.7673509286412512
step: 0, loss: 0.031220871955156326
step: 10, loss: 0.0859009325504303
step: 20, loss: 0.00402073236182332
step: 30, loss: 0.017677925527095795
step: 40, loss: 0.0029238287825137377
step: 50, loss: 0.04936063289642334
step: 60, loss: 0.002379816258326173
step: 70, loss: 0.01189716812223196
step: 80, loss: 0.011409128084778786
step: 90, loss: 0.004845832008868456
step: 100, loss: 0.005606776103377342
step: 110, loss: 0.003203003667294979
step: 120, loss: 0.0009822582360357046
step: 130, loss: 0.03637978434562683
step: 140, loss: 0.055105939507484436
step: 150, loss: 0.1945902556180954
step: 160, loss: 0.17063981294631958
step: 170, loss: 0.003200103994458914
step: 180, loss: 0.002432882785797119
step: 190, loss: 0.01425083726644516
step: 200, loss: 0.0003170401614625007
step: 210, loss: 0.0021577738225460052
step: 220, loss: 0.052315328270196915
step: 230, loss: 0.021906305104494095
step: 240, loss: 0.07709310203790665
step: 250, loss: 0.06155651807785034
step: 260, loss: 0.049716319888830185
step: 270, loss: 0.008694810792803764
step: 280, loss: 0.05968918278813362
step: 290, loss: 0.004694093018770218
step: 300, loss: 0.014502491801977158
step: 310, loss: 0.034178104251623154
step: 320, loss: 0.0060855611227452755
step: 330, loss: 0.02537984773516655
step: 340, loss: 0.010512634180486202
step: 350, loss: 0.0017183379968628287
step: 360, loss: 0.00832452718168497
step: 370, loss: 0.035265155136585236
step: 380, loss: 0.0995962843298912
step: 390, loss: 0.01915241964161396
step: 400, loss: 0.005056857131421566
step: 410, loss: 0.037910789251327515
step: 420, loss: 0.045484788715839386
step: 430, loss: 0.04137655720114708
step: 440, loss: 0.0017991173081099987
step: 450, loss: 0.0032332579139620066
step: 460, loss: 0.008321394212543964
step: 470, loss: 0.04108816757798195
step: 480, loss: 0.055584609508514404
step: 490, loss: 0.02686292678117752
epoch 8: dev_f1=0.8725264611136678, f1=0.6995603321934539, best_f1=0.7673509286412512
step: 0, loss: 0.0132211335003376
step: 10, loss: 0.14115652441978455
step: 20, loss: 0.11365979164838791
step: 30, loss: 0.0016829374944791198
step: 40, loss: 0.009922172874212265
step: 50, loss: 0.07218056917190552
step: 60, loss: 0.028520049527287483
step: 70, loss: 0.008010263554751873
step: 80, loss: 0.004207053687423468
step: 90, loss: 0.011573211289942265
step: 100, loss: 0.0043756403028965
step: 110, loss: 0.06629039347171783
step: 120, loss: 0.11014558374881744
step: 130, loss: 0.022987758740782738
step: 140, loss: 0.010217675007879734
step: 150, loss: 0.010779089294373989
step: 160, loss: 0.023254550993442535
step: 170, loss: 0.02418973110616207
step: 180, loss: 0.0010636508231982589
step: 190, loss: 0.005877535790205002
step: 200, loss: 0.035719599574804306
step: 210, loss: 0.013154454529285431
step: 220, loss: 0.0038265392649918795
step: 230, loss: 0.001469527604058385
step: 240, loss: 0.003829608205705881
step: 250, loss: 0.020284296944737434
step: 260, loss: 0.006292122881859541
step: 270, loss: 0.0007560307276435196
step: 280, loss: 0.001549731707200408
step: 290, loss: 0.020333746448159218
step: 300, loss: 0.01482947077602148
step: 310, loss: 0.005223962012678385
step: 320, loss: 0.020617837086319923
step: 330, loss: 0.01951923407614231
step: 340, loss: 0.005195463541895151
step: 350, loss: 0.016661860048770905
step: 360, loss: 0.00950034148991108
step: 370, loss: 0.13333095610141754
step: 380, loss: 0.07091232389211655
step: 390, loss: 0.0003412074875086546
step: 400, loss: 0.006427571643143892
step: 410, loss: 0.01090717688202858
step: 420, loss: 0.0670597031712532
step: 430, loss: 0.022131608799099922
step: 440, loss: 0.02060367912054062
step: 450, loss: 0.0009292575414292514
step: 460, loss: 0.10438057780265808
step: 470, loss: 0.013550079427659512
step: 480, loss: 0.03658420220017433
step: 490, loss: 0.004771213047206402
epoch 9: dev_f1=0.8608852755194218, f1=0.6976076555023923, best_f1=0.7673509286412512
step: 0, loss: 0.016604356467723846
step: 10, loss: 0.004243858158588409
step: 20, loss: 0.0010287076001986861
step: 30, loss: 0.0024168507661670446
step: 40, loss: 0.008968796581029892
step: 50, loss: 0.0021583344787359238
step: 60, loss: 0.0008917744853533804
step: 70, loss: 0.028151221573352814
step: 80, loss: 0.005234174430370331
step: 90, loss: 0.00517155509442091
step: 100, loss: 0.0009474356775172055
step: 110, loss: 0.011059729382395744
step: 120, loss: 0.006856309715658426
step: 130, loss: 0.1223692074418068
step: 140, loss: 0.011669738218188286
step: 150, loss: 0.0019488584948703647
step: 160, loss: 0.026139436289668083
step: 170, loss: 0.001785949687473476
step: 180, loss: 0.009500938467681408
step: 190, loss: 0.004287329502403736
step: 200, loss: 0.0030100184958428144
step: 210, loss: 0.04976513236761093
step: 220, loss: 0.107563316822052
step: 230, loss: 0.10777396708726883
step: 240, loss: 0.015117836184799671
step: 250, loss: 0.020780213177204132
step: 260, loss: 0.0019386170897632837
step: 270, loss: 0.016544826328754425
step: 280, loss: 0.030682021751999855
step: 290, loss: 0.0001347159268334508
step: 300, loss: 0.009023595601320267
step: 310, loss: 0.046984005719423294
step: 320, loss: 0.12023772299289703
step: 330, loss: 0.003571463981643319
step: 340, loss: 0.02036745846271515
step: 350, loss: 0.0003642903466243297
step: 360, loss: 0.0135774165391922
step: 370, loss: 0.004123799968510866
step: 380, loss: 0.0005221187602728605
step: 390, loss: 0.00207720510661602
step: 400, loss: 0.020778736099600792
step: 410, loss: 0.033765971660614014
step: 420, loss: 0.0026149738114327192
step: 430, loss: 0.001970225013792515
step: 440, loss: 0.006070771720260382
step: 450, loss: 0.0005666015786118805
step: 460, loss: 0.00311257760040462
step: 470, loss: 0.004060626029968262
step: 480, loss: 0.04550441354513168
step: 490, loss: 0.035738829523324966
epoch 10: dev_f1=0.8295964125560539, f1=0.6796577946768061, best_f1=0.7673509286412512
step: 0, loss: 0.0009677029447630048
step: 10, loss: 0.002023636829108
step: 20, loss: 0.025556445121765137
step: 30, loss: 0.0165295097976923
step: 40, loss: 0.008242708630859852
step: 50, loss: 0.01583489589393139
step: 60, loss: 0.008849355392158031
step: 70, loss: 0.00011812691809609532
step: 80, loss: 0.0020745238289237022
step: 90, loss: 0.0033530285581946373
step: 100, loss: 0.000496463559102267
step: 110, loss: 0.015496313571929932
step: 120, loss: 0.006843956653028727
step: 130, loss: 0.016808440908789635
step: 140, loss: 0.022434810176491737
step: 150, loss: 0.05557820573449135
step: 160, loss: 0.0004815148713532835
step: 170, loss: 0.012115539982914925
step: 180, loss: 0.00022904298384673893
step: 190, loss: 0.0034734380897134542
step: 200, loss: 0.2114434540271759
step: 210, loss: 0.022647231817245483
step: 220, loss: 0.02123497612774372
step: 230, loss: 0.003335819113999605
step: 240, loss: 0.06862978637218475
step: 250, loss: 0.007533583324402571
step: 260, loss: 0.0032226769253611565
step: 270, loss: 0.001368792145512998
step: 280, loss: 0.058481406420469284
step: 290, loss: 0.0061410157941281796
step: 300, loss: 0.06887280195951462
step: 310, loss: 0.0001411992561770603
step: 320, loss: 0.0003075625281780958
step: 330, loss: 0.0033966258633881807
step: 340, loss: 0.001816170639358461
step: 350, loss: 0.008034659549593925
step: 360, loss: 0.0031916366424411535
step: 370, loss: 0.008349774405360222
step: 380, loss: 0.005555240903049707
step: 390, loss: 0.01083296351134777
step: 400, loss: 0.0008803274831734598
step: 410, loss: 0.11291610449552536
step: 420, loss: 0.0019201337127014995
step: 430, loss: 7.392163388431072e-05
step: 440, loss: 0.048179741948843
step: 450, loss: 0.0004276377148926258
step: 460, loss: 0.0379331074655056
step: 470, loss: 0.0051892963238060474
step: 480, loss: 0.0004564224509522319
step: 490, loss: 0.011624163947999477
epoch 11: dev_f1=0.8557258791704238, f1=0.6912529550827422, best_f1=0.7673509286412512
step: 0, loss: 0.00027412152849137783
step: 10, loss: 0.0035468062851577997
step: 20, loss: 0.0003470191149972379
step: 30, loss: 0.0007652811473235488
step: 40, loss: 0.001382598653435707
step: 50, loss: 0.06596064567565918
step: 60, loss: 0.020103026181459427
step: 70, loss: 0.0023574726656079292
step: 80, loss: 0.002295378828421235
step: 90, loss: 0.010425998829305172
step: 100, loss: 0.007577262353152037
step: 110, loss: 0.013389253057539463
step: 120, loss: 0.0005488703027367592
step: 130, loss: 0.00034542856155894697
step: 140, loss: 0.034034837037324905
step: 150, loss: 9.370952466269955e-05
step: 160, loss: 0.05337229743599892
step: 170, loss: 0.02333706058561802
step: 180, loss: 0.014598965644836426
step: 190, loss: 0.04620066657662392
step: 200, loss: 0.00434194877743721
step: 210, loss: 0.0010318707209080458
step: 220, loss: 0.04727323353290558
step: 230, loss: 0.0006524949567392468
step: 240, loss: 0.0008118627010844648
step: 250, loss: 0.016616135835647583
step: 260, loss: 0.013326016254723072
step: 270, loss: 0.0015809691976755857
step: 280, loss: 0.06329338997602463
step: 290, loss: 0.007990354672074318
step: 300, loss: 0.002402512589469552
step: 310, loss: 0.001799502526409924
step: 320, loss: 0.0003940117312595248
step: 330, loss: 0.026153985410928726
step: 340, loss: 0.0792277455329895
step: 350, loss: 0.001404886948876083
step: 360, loss: 0.00027532168314792216
step: 370, loss: 0.0006463791360147297
step: 380, loss: 0.00015035965770948678
step: 390, loss: 0.016709567978978157
step: 400, loss: 0.0006909481016919017
step: 410, loss: 0.0012042478192597628
step: 420, loss: 0.00333750550635159
step: 430, loss: 0.0001862034114310518
step: 440, loss: 0.0001303243188885972
step: 450, loss: 0.0005477287340909243
step: 460, loss: 0.0005305800586938858
step: 470, loss: 0.010820194147527218
step: 480, loss: 0.026013650000095367
step: 490, loss: 0.05457255616784096
epoch 12: dev_f1=0.8501362397820165, f1=0.6666666666666667, best_f1=0.7673509286412512
step: 0, loss: 0.007875092327594757
step: 10, loss: 0.02705247700214386
step: 20, loss: 0.005708874668926001
step: 30, loss: 0.00017690127424430102
step: 40, loss: 0.0010098221246153116
step: 50, loss: 0.05689399689435959
step: 60, loss: 0.0030629627872258425
step: 70, loss: 0.00010408511298010126
step: 80, loss: 0.004203154239803553
step: 90, loss: 0.010073885321617126
step: 100, loss: 0.014117317274212837
step: 110, loss: 0.0003456509148236364
step: 120, loss: 0.06900148838758469
step: 130, loss: 0.0010185508290305734
step: 140, loss: 0.014436907134950161
step: 150, loss: 0.0010100736981257796
step: 160, loss: 0.0026670536026358604
step: 170, loss: 0.002540075918659568
step: 180, loss: 0.023904256522655487
step: 190, loss: 0.0028552794829010963
step: 200, loss: 0.002183199394494295
step: 210, loss: 0.032680489122867584
step: 220, loss: 0.002100463956594467
step: 230, loss: 0.03511736914515495
step: 240, loss: 0.0002869180461857468
step: 250, loss: 0.000797386048361659
step: 260, loss: 0.004985357169061899
step: 270, loss: 0.0016665344592183828
step: 280, loss: 0.0006898994324728847
step: 290, loss: 0.00029060657834634185
step: 300, loss: 0.012788396328687668
step: 310, loss: 0.0031039060559123755
step: 320, loss: 0.0005586030310951173
step: 330, loss: 0.04374763369560242
step: 340, loss: 0.0002705430088099092
step: 350, loss: 0.001781876664608717
step: 360, loss: 0.00039557344280183315
step: 370, loss: 0.0037044433411210775
step: 380, loss: 0.01139967143535614
step: 390, loss: 0.007041997741907835
step: 400, loss: 0.00152475549839437
step: 410, loss: 9.140124166151509e-05
step: 420, loss: 0.009425850585103035
step: 430, loss: 0.005961178336292505
step: 440, loss: 0.029789794236421585
step: 450, loss: 0.0020216060802340508
step: 460, loss: 0.036604177206754684
step: 470, loss: 0.005339683964848518
step: 480, loss: 0.0010714295785874128
step: 490, loss: 0.0015947717474773526
epoch 13: dev_f1=0.8531073446327684, f1=0.6686567164179105, best_f1=0.7673509286412512
step: 0, loss: 0.00719261821359396
step: 10, loss: 0.00021216324239503592
step: 20, loss: 0.001741325482726097
step: 30, loss: 0.002818011911585927
step: 40, loss: 0.0003750552423298359
step: 50, loss: 0.0008298435132019222
step: 60, loss: 0.0001650546328164637
step: 70, loss: 0.0029112829361110926
step: 80, loss: 0.0008058013045229018
step: 90, loss: 0.00036171829560771585
step: 100, loss: 0.0004481743380893022
step: 110, loss: 7.649238978046924e-05
step: 120, loss: 0.0007772375247441232
step: 130, loss: 0.0012088384246453643
step: 140, loss: 0.00034506243537180126
step: 150, loss: 0.0013013278366997838
step: 160, loss: 0.0005914426292292774
step: 170, loss: 0.0020649819634854794
step: 180, loss: 0.0001502778468420729
step: 190, loss: 0.0892939567565918
step: 200, loss: 0.001067322096787393
step: 210, loss: 0.00013371848035603762
step: 220, loss: 0.00045835896162316203
step: 230, loss: 9.45451101870276e-05
step: 240, loss: 0.0027404995635151863
step: 250, loss: 0.0017650375375524163
step: 260, loss: 0.0013186606811359525
step: 270, loss: 0.0035510484594851732
step: 280, loss: 0.0019418307347223163
step: 290, loss: 0.00024752237368375063
step: 300, loss: 0.02215523272752762
step: 310, loss: 0.0011409601429477334
step: 320, loss: 0.00028457140433602035
step: 330, loss: 0.08449020981788635
step: 340, loss: 7.583682599943131e-05
step: 350, loss: 0.00023950661125127226
step: 360, loss: 0.00034046522341668606
step: 370, loss: 0.001088651828467846
step: 380, loss: 0.0003185583627782762
step: 390, loss: 0.0004036345926579088
step: 400, loss: 0.0003472066018730402
step: 410, loss: 0.0029848902486264706
step: 420, loss: 0.007861423306167126
step: 430, loss: 7.26072394172661e-05
step: 440, loss: 0.0008597176056355238
step: 450, loss: 0.000935270159970969
step: 460, loss: 0.0002259953471366316
step: 470, loss: 0.0009404302691109478
step: 480, loss: 0.00077102764043957
step: 490, loss: 0.001794522162526846
epoch 14: dev_f1=0.8520499108734403, f1=0.6903981264637002, best_f1=0.7673509286412512
step: 0, loss: 0.057970792055130005
step: 10, loss: 0.0006408748449757695
step: 20, loss: 0.009244969114661217
step: 30, loss: 0.0007884196238592267
step: 40, loss: 0.0009499485022388399
step: 50, loss: 6.218778435140848e-05
step: 60, loss: 0.0013531169388443232
step: 70, loss: 0.0007814805721864104
step: 80, loss: 0.00015165130025707185
step: 90, loss: 0.002817682921886444
step: 100, loss: 0.007159197703003883
step: 110, loss: 0.007196370977908373
step: 120, loss: 0.009077060967683792
step: 130, loss: 0.0009416955290362239
step: 140, loss: 0.0018234802410006523
step: 150, loss: 0.009329428896307945
step: 160, loss: 0.03953114524483681
step: 170, loss: 0.008533589541912079
step: 180, loss: 0.0002171424712287262
step: 190, loss: 4.077135236002505e-05
step: 200, loss: 0.09712203592061996
step: 210, loss: 0.001296794624067843
step: 220, loss: 0.09525628387928009
step: 230, loss: 0.00579867884516716
step: 240, loss: 0.005018808878958225
step: 250, loss: 0.0044203996658325195
step: 260, loss: 0.00021801509137731045
step: 270, loss: 9.402476280229166e-05
step: 280, loss: 0.002450665459036827
step: 290, loss: 0.0072527783922851086
step: 300, loss: 0.0006936660502105951
step: 310, loss: 0.0009284501429647207
step: 320, loss: 0.00021713812020607293
step: 330, loss: 0.0007316648261621594
step: 340, loss: 5.80284686293453e-05
step: 350, loss: 0.0017069437308236957
step: 360, loss: 0.0010039799381047487
step: 370, loss: 0.026469750329852104
step: 380, loss: 0.00028094562003389
step: 390, loss: 0.01674555242061615
step: 400, loss: 0.0006160079501569271
step: 410, loss: 0.006508105434477329
step: 420, loss: 0.0002248835953650996
step: 430, loss: 0.001497190911322832
step: 440, loss: 0.005703652743250132
step: 450, loss: 0.00011020371312042698
step: 460, loss: 0.00012483875616453588
step: 470, loss: 0.017233163118362427
step: 480, loss: 0.00683836592361331
step: 490, loss: 0.004218849819153547
epoch 15: dev_f1=0.8568832348932304, f1=0.6757281553398059, best_f1=0.7673509286412512
step: 0, loss: 6.701835081912577e-05
step: 10, loss: 9.015105024445802e-05
step: 20, loss: 8.672737749293447e-05
step: 30, loss: 7.219046528916806e-05
step: 40, loss: 0.001037578214891255
step: 50, loss: 0.02574191614985466
step: 60, loss: 0.012813285924494267
step: 70, loss: 0.0029803935904055834
step: 80, loss: 0.00011593972885748371
step: 90, loss: 7.369804370682687e-05
step: 100, loss: 0.0005424427217803895
step: 110, loss: 0.001684393733739853
step: 120, loss: 0.011125225573778152
step: 130, loss: 0.000132883942569606
step: 140, loss: 6.642833614023402e-05
step: 150, loss: 0.00031685663270764053
step: 160, loss: 0.00019104094826616347
step: 170, loss: 0.1352565586566925
step: 180, loss: 0.0005970687489025295
step: 190, loss: 0.011645820923149586
step: 200, loss: 7.252940122270957e-05
step: 210, loss: 0.006388820707798004
step: 220, loss: 4.529594298219308e-05
step: 230, loss: 0.00011231911776121706
step: 240, loss: 0.0008762176148593426
step: 250, loss: 5.933965076110326e-05
step: 260, loss: 0.0002963400911539793
step: 270, loss: 0.07428698986768723
step: 280, loss: 0.0006653269520029426
step: 290, loss: 5.605085607385263e-05
step: 300, loss: 0.0008000811794772744
step: 310, loss: 0.0018808012828230858
step: 320, loss: 0.0211663618683815
step: 330, loss: 0.00010319748980691656
step: 340, loss: 0.000623757834546268
step: 350, loss: 9.356327791465446e-05
step: 360, loss: 0.006243328098207712
step: 370, loss: 0.00010612291225697845
step: 380, loss: 6.66261839796789e-05
step: 390, loss: 0.00023736973525956273
step: 400, loss: 0.00020512237097136676
step: 410, loss: 0.0008184118778444827
step: 420, loss: 8.338467159774154e-05
step: 430, loss: 0.0017699293093755841
step: 440, loss: 4.427662133821286e-05
step: 450, loss: 8.981073187896982e-05
step: 460, loss: 0.0002061183622572571
step: 470, loss: 0.20945408940315247
step: 480, loss: 0.0017640399746596813
step: 490, loss: 0.009575212374329567
epoch 16: dev_f1=0.8552158273381295, f1=0.6825548141086749, best_f1=0.7673509286412512
step: 0, loss: 0.0004859606851823628
step: 10, loss: 0.00010944588575512171
step: 20, loss: 0.00025248571182601154
step: 30, loss: 0.0009031851077452302
step: 40, loss: 6.43754392513074e-05
step: 50, loss: 5.502730709849857e-05
step: 60, loss: 0.04892836883664131
step: 70, loss: 0.00047377991722896695
step: 80, loss: 0.00023716373834758997
step: 90, loss: 0.0005302168428897858
step: 100, loss: 0.00012862333096563816
step: 110, loss: 0.0002570739889051765
step: 120, loss: 0.008844802156090736
step: 130, loss: 0.0008534135995432734
step: 140, loss: 0.011958267539739609
step: 150, loss: 0.0005090528284199536
step: 160, loss: 0.015373507514595985
step: 170, loss: 0.00015901151346042752
step: 180, loss: 0.00017798933549784124
step: 190, loss: 0.0018835723167285323
step: 200, loss: 0.0010100725339725614
step: 210, loss: 0.000865345646161586
step: 220, loss: 0.000331119546899572
step: 230, loss: 0.00016567502461839467
step: 240, loss: 0.0017309827962890267
step: 250, loss: 0.0005236637080088258
step: 260, loss: 6.712873437209055e-05
step: 270, loss: 0.00017729881801642478
step: 280, loss: 0.0002406102285021916
step: 290, loss: 0.0011398891219869256
step: 300, loss: 0.00018931878730654716
step: 310, loss: 0.005740789696574211
step: 320, loss: 0.0001293946843361482
step: 330, loss: 0.037771470844745636
step: 340, loss: 5.5251584853976965e-05
step: 350, loss: 4.150101449340582e-05
step: 360, loss: 0.000478422298328951
step: 370, loss: 0.0016392187681049109
step: 380, loss: 0.0001869613042799756
step: 390, loss: 0.00024466856848448515
step: 400, loss: 0.002166436053812504
step: 410, loss: 0.002780892187729478
step: 420, loss: 4.066704786964692e-05
step: 430, loss: 0.05431855097413063
step: 440, loss: 0.02337045781314373
step: 450, loss: 0.0008172644302248955
step: 460, loss: 0.007864460349082947
step: 470, loss: 0.0005433036130852997
step: 480, loss: 0.046233199536800385
step: 490, loss: 0.0031823015306144953
epoch 17: dev_f1=0.8461885430762293, f1=0.6743515850144092, best_f1=0.7673509286412512
step: 0, loss: 0.01679481565952301
step: 10, loss: 8.652392716612667e-05
step: 20, loss: 0.00010200189717579633
step: 30, loss: 0.00793729443103075
step: 40, loss: 0.0002045050641754642
step: 50, loss: 0.0007320301956497133
step: 60, loss: 5.5147258535725996e-05
step: 70, loss: 0.00016961168148554862
step: 80, loss: 0.00036157964495941997
step: 90, loss: 0.01813722401857376
step: 100, loss: 0.021109336987137794
step: 110, loss: 6.993300485191867e-05
step: 120, loss: 4.4390762923285365e-05
step: 130, loss: 6.262915121624246e-05
step: 140, loss: 9.587771637598053e-05
step: 150, loss: 0.0001676002430031076
step: 160, loss: 0.01624297723174095
step: 170, loss: 0.0021176638547331095
step: 180, loss: 4.153802365181036e-05
step: 190, loss: 3.278503572801128e-05
step: 200, loss: 0.0008680523606017232
step: 210, loss: 0.013326282612979412
step: 220, loss: 6.216090696398169e-05
step: 230, loss: 0.03306950256228447
step: 240, loss: 4.44250472355634e-05
step: 250, loss: 0.001434289151802659
step: 260, loss: 0.003303214907646179
step: 270, loss: 0.00021877950348425657
step: 280, loss: 0.00012769225577358156
step: 290, loss: 4.910320058115758e-05
step: 300, loss: 0.0005362630472518504
step: 310, loss: 0.0001668155746301636
step: 320, loss: 0.00020982346904929727
step: 330, loss: 8.352370787179098e-05
step: 340, loss: 0.002507495693862438
step: 350, loss: 0.00011058090603910387
step: 360, loss: 0.00011290093243587762
step: 370, loss: 0.0001327153149759397
step: 380, loss: 0.038070131093263626
step: 390, loss: 0.00015187051030807197
step: 400, loss: 4.836256994167343e-05
step: 410, loss: 5.2648159908130765e-05
step: 420, loss: 8.26694376883097e-05
step: 430, loss: 0.0001615763030713424
step: 440, loss: 5.7842717069434e-05
step: 450, loss: 9.139108442468569e-05
step: 460, loss: 0.004054599907249212
step: 470, loss: 0.00021389579342212528
step: 480, loss: 6.149488763185218e-05
step: 490, loss: 0.01531942468136549
epoch 18: dev_f1=0.8444248567650947, f1=0.6917014371812703, best_f1=0.7673509286412512
step: 0, loss: 0.0024799101520329714
step: 10, loss: 0.001782041508704424
step: 20, loss: 0.06751204282045364
step: 30, loss: 0.004125935956835747
step: 40, loss: 0.024249868467450142
step: 50, loss: 0.0004792766412720084
step: 60, loss: 0.0002562998270150274
step: 70, loss: 0.02383158542215824
step: 80, loss: 0.00021820791880600154
step: 90, loss: 5.156708357390016e-05
step: 100, loss: 0.00012666477414313704
step: 110, loss: 0.0005068934406153858
step: 120, loss: 0.0003746245929505676
step: 130, loss: 8.94829208846204e-05
step: 140, loss: 0.00016918359324336052
step: 150, loss: 4.651679046219215e-05
step: 160, loss: 0.000165934456163086
step: 170, loss: 0.0010706376051530242
step: 180, loss: 0.0002436529321130365
step: 190, loss: 6.392604700522497e-05
step: 200, loss: 7.036232273094356e-05
step: 210, loss: 6.625217793043703e-05
step: 220, loss: 0.00023379102640319616
step: 230, loss: 0.00015917583368718624
step: 240, loss: 2.804269752232358e-05
step: 250, loss: 0.00035556586226448417
step: 260, loss: 0.0004149627638980746
step: 270, loss: 9.862627484835684e-05
step: 280, loss: 0.00038137644878588617
step: 290, loss: 6.647670670645311e-05
step: 300, loss: 4.229204569128342e-05
step: 310, loss: 7.914913294371217e-05
step: 320, loss: 8.260190952569246e-05
step: 330, loss: 0.0007417266606353223
step: 340, loss: 0.00012500712182372808
step: 350, loss: 3.286254286649637e-05
step: 360, loss: 3.637549889390357e-05
step: 370, loss: 4.6972661948530003e-05
step: 380, loss: 4.0153485315386206e-05
step: 390, loss: 0.0010725522879511118
step: 400, loss: 0.002293950179591775
step: 410, loss: 0.00017810691497288644
step: 420, loss: 0.012854636646807194
step: 430, loss: 9.307945583714172e-05
step: 440, loss: 5.112621147418395e-05
step: 450, loss: 9.27430737647228e-05
step: 460, loss: 3.0356419301824644e-05
step: 470, loss: 0.0003012204251717776
step: 480, loss: 0.00027860430418513715
step: 490, loss: 0.0002178214053856209
epoch 19: dev_f1=0.8555240793201133, f1=0.6636085626911314, best_f1=0.7673509286412512
step: 0, loss: 0.002250893507152796
step: 10, loss: 0.0028089273255318403
step: 20, loss: 0.003175972728058696
step: 30, loss: 0.09155496954917908
step: 40, loss: 0.00022675463696941733
step: 50, loss: 0.0004247659526299685
step: 60, loss: 0.0003238336357753724
step: 70, loss: 0.02525198645889759
step: 80, loss: 0.0018843603320419788
step: 90, loss: 0.00024025252787396312
step: 100, loss: 5.378229252528399e-05
step: 110, loss: 3.5396336897974834e-05
step: 120, loss: 3.322414340800606e-05
step: 130, loss: 3.940353053621948e-05
step: 140, loss: 0.003090574638918042
step: 150, loss: 8.746665116632357e-05
step: 160, loss: 7.464906957466155e-05
step: 170, loss: 0.0001607494632480666
step: 180, loss: 0.041931379586458206
step: 190, loss: 0.00453589903190732
step: 200, loss: 8.302809874294326e-05
step: 210, loss: 0.00041544807027094066
step: 220, loss: 0.00017299047613050789
step: 230, loss: 0.03078780323266983
step: 240, loss: 0.0003912042884621769
step: 250, loss: 7.306312909349799e-05
step: 260, loss: 6.813542859163135e-05
step: 270, loss: 0.0016083590453490615
step: 280, loss: 0.0002543687878642231
step: 290, loss: 0.00023869385768193752
step: 300, loss: 3.154440855723806e-05
step: 310, loss: 3.5939876397605985e-05
step: 320, loss: 0.00011881654791068286
step: 330, loss: 5.3766616474604234e-05
step: 340, loss: 0.00044475318281911314
step: 350, loss: 0.002239925554022193
step: 360, loss: 0.001159059233032167
step: 370, loss: 0.00012813686043955386
step: 380, loss: 0.0008285726071335375
step: 390, loss: 0.00022440134489443153
step: 400, loss: 4.6913817641325295e-05
step: 410, loss: 3.1056522857397795e-05
step: 420, loss: 0.00017339216719847172
step: 430, loss: 3.6296747566666454e-05
step: 440, loss: 0.00012040490400977433
step: 450, loss: 0.0004192358173895627
step: 460, loss: 0.015252235345542431
step: 470, loss: 2.372213566559367e-05
step: 480, loss: 7.763888424960896e-05
step: 490, loss: 0.00012628208787646145
epoch 20: dev_f1=0.8475336322869954, f1=0.6812351543942994, best_f1=0.7673509286412512
