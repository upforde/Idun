cuda
Device: cuda
step: 0, loss: 0.7022583484649658
step: 10, loss: 0.554100751876831
step: 20, loss: 0.665643036365509
step: 30, loss: 0.38713905215263367
step: 40, loss: 0.44994503259658813
step: 50, loss: 0.6371169090270996
step: 60, loss: 0.5759354829788208
step: 70, loss: 0.32678908109664917
step: 80, loss: 0.4760357439517975
step: 90, loss: 0.37278759479522705
step: 100, loss: 0.2932250499725342
step: 110, loss: 0.3907787501811981
step: 120, loss: 0.24183006584644318
step: 130, loss: 0.4620729684829712
step: 140, loss: 0.3712230324745178
step: 150, loss: 0.32020220160484314
step: 160, loss: 0.2755374610424042
step: 170, loss: 0.3224250078201294
step: 180, loss: 0.45335814356803894
step: 190, loss: 0.4401824176311493
step: 200, loss: 0.40347781777381897
step: 210, loss: 0.36227524280548096
step: 220, loss: 0.30049851536750793
step: 230, loss: 0.354214072227478
step: 240, loss: 0.46624380350112915
step: 250, loss: 0.3002249598503113
step: 260, loss: 0.3217895030975342
step: 270, loss: 0.3861384391784668
step: 280, loss: 0.22892305254936218
step: 290, loss: 0.3992217183113098
step: 300, loss: 0.4703978896141052
step: 310, loss: 0.1624465435743332
step: 320, loss: 0.456500768661499
step: 330, loss: 0.2150191068649292
step: 340, loss: 0.20318304002285004
step: 350, loss: 0.24349574744701385
step: 360, loss: 0.2269565910100937
step: 370, loss: 0.4403506815433502
step: 380, loss: 0.3938421607017517
step: 390, loss: 0.3729104697704315
step: 400, loss: 0.42685621976852417
step: 410, loss: 0.3866056799888611
epoch 1: dev_f1=0.8274185707340788, f1=0.7576064908722109, best_f1=0.7576064908722109
step: 0, loss: 0.21529413759708405
step: 10, loss: 0.23588714003562927
step: 20, loss: 0.3151788115501404
step: 30, loss: 0.07191654294729233
step: 40, loss: 0.3035008907318115
step: 50, loss: 0.73489910364151
step: 60, loss: 0.3148704767227173
step: 70, loss: 0.20222586393356323
step: 80, loss: 0.2313757985830307
step: 90, loss: 0.3271164298057556
step: 100, loss: 0.30049920082092285
step: 110, loss: 0.24082766473293304
step: 120, loss: 0.10052075982093811
step: 130, loss: 0.2857416272163391
step: 140, loss: 0.2968514859676361
step: 150, loss: 0.20366686582565308
step: 160, loss: 0.2666011154651642
step: 170, loss: 0.09346089512109756
step: 180, loss: 0.14818716049194336
step: 190, loss: 0.18745045363903046
step: 200, loss: 0.2686064541339874
step: 210, loss: 0.25897806882858276
step: 220, loss: 0.22442671656608582
step: 230, loss: 0.37689530849456787
step: 240, loss: 0.3246694803237915
step: 250, loss: 0.28894951939582825
step: 260, loss: 0.4003264605998993
step: 270, loss: 0.15085293352603912
step: 280, loss: 0.1829480677843094
step: 290, loss: 0.24721723794937134
step: 300, loss: 0.230444073677063
step: 310, loss: 0.40707382559776306
step: 320, loss: 0.0739046186208725
step: 330, loss: 0.11564303934574127
step: 340, loss: 0.1709059178829193
step: 350, loss: 0.32061874866485596
step: 360, loss: 0.1973850280046463
step: 370, loss: 0.16499483585357666
step: 380, loss: 0.18672923743724823
step: 390, loss: 0.2349003404378891
step: 400, loss: 0.13269832730293274
step: 410, loss: 0.09294695407152176
epoch 2: dev_f1=0.8830926874708895, f1=0.7940327237728584, best_f1=0.7940327237728584
step: 0, loss: 0.2617393732070923
step: 10, loss: 0.0814245194196701
step: 20, loss: 0.11769744008779526
step: 30, loss: 0.1401413232088089
step: 40, loss: 0.34610334038734436
step: 50, loss: 0.13233795762062073
step: 60, loss: 0.03603483363986015
step: 70, loss: 0.145132377743721
step: 80, loss: 0.08726376295089722
step: 90, loss: 0.09533103555440903
step: 100, loss: 0.23369336128234863
step: 110, loss: 0.3948177695274353
step: 120, loss: 0.16964091360569
step: 130, loss: 0.23477119207382202
step: 140, loss: 0.1439533531665802
step: 150, loss: 0.1202731803059578
step: 160, loss: 0.13835002481937408
step: 170, loss: 0.13132262229919434
step: 180, loss: 0.24948397278785706
step: 190, loss: 0.2924708127975464
step: 200, loss: 0.1587710678577423
step: 210, loss: 0.22136923670768738
step: 220, loss: 0.46538984775543213
step: 230, loss: 0.15453660488128662
step: 240, loss: 0.2692238390445709
step: 250, loss: 0.11459501832723618
step: 260, loss: 0.21403378248214722
step: 270, loss: 0.37333300709724426
step: 280, loss: 0.08885980397462845
step: 290, loss: 0.2443186342716217
step: 300, loss: 0.3520922064781189
step: 310, loss: 0.23950663208961487
step: 320, loss: 0.14039848744869232
step: 330, loss: 0.22873525321483612
step: 340, loss: 0.28774601221084595
step: 350, loss: 0.19827353954315186
step: 360, loss: 0.1871558129787445
step: 370, loss: 0.1383069008588791
step: 380, loss: 0.24153897166252136
step: 390, loss: 0.16016657650470734
step: 400, loss: 0.19018146395683289
step: 410, loss: 0.03579261153936386
epoch 3: dev_f1=0.86331569664903, f1=0.736988847583643, best_f1=0.7940327237728584
step: 0, loss: 0.18536368012428284
step: 10, loss: 0.14143171906471252
step: 20, loss: 0.09847155958414078
step: 30, loss: 0.12839847803115845
step: 40, loss: 0.3680454194545746
step: 50, loss: 0.06542857736349106
step: 60, loss: 0.16672971844673157
step: 70, loss: 0.16205346584320068
step: 80, loss: 0.16801317036151886
step: 90, loss: 0.11566249281167984
step: 100, loss: 0.18295949697494507
step: 110, loss: 0.11026403307914734
step: 120, loss: 0.21536681056022644
step: 130, loss: 0.1104697585105896
step: 140, loss: 0.06480927765369415
step: 150, loss: 0.16279184818267822
step: 160, loss: 0.13814707100391388
step: 170, loss: 0.1330278366804123
step: 180, loss: 0.032762475311756134
step: 190, loss: 0.1737249195575714
step: 200, loss: 0.2733312249183655
step: 210, loss: 0.2082165777683258
step: 220, loss: 0.07756614685058594
step: 230, loss: 0.06813327223062515
step: 240, loss: 0.044251296669244766
step: 250, loss: 0.10411657392978668
step: 260, loss: 0.09033620357513428
step: 270, loss: 0.08181696385145187
step: 280, loss: 0.16789358854293823
step: 290, loss: 0.18405269086360931
step: 300, loss: 0.21148435771465302
step: 310, loss: 0.08994900435209274
step: 320, loss: 0.014793436974287033
step: 330, loss: 0.06382547318935394
step: 340, loss: 0.15678374469280243
step: 350, loss: 0.276679664850235
step: 360, loss: 0.10910360515117645
step: 370, loss: 0.025571729987859726
step: 380, loss: 0.018871579319238663
step: 390, loss: 0.137703076004982
step: 400, loss: 0.17968648672103882
step: 410, loss: 0.3269074857234955
epoch 4: dev_f1=0.8610586011342155, f1=0.7086934417895272, best_f1=0.7940327237728584
step: 0, loss: 0.10335253179073334
step: 10, loss: 0.027711940929293633
step: 20, loss: 0.14321382343769073
step: 30, loss: 0.19462165236473083
step: 40, loss: 0.09885940700769424
step: 50, loss: 0.14237897098064423
step: 60, loss: 0.05108577385544777
step: 70, loss: 0.05895132198929787
step: 80, loss: 0.009884139522910118
step: 90, loss: 0.041586969047784805
step: 100, loss: 0.013367456384003162
step: 110, loss: 0.10206939280033112
step: 120, loss: 0.06799919158220291
step: 130, loss: 0.08215480297803879
step: 140, loss: 0.11717812716960907
step: 150, loss: 0.03940213471651077
step: 160, loss: 0.054924897849559784
step: 170, loss: 0.08700820058584213
step: 180, loss: 0.06856179982423782
step: 190, loss: 0.07955177873373032
step: 200, loss: 0.19564056396484375
step: 210, loss: 0.0800945907831192
step: 220, loss: 0.12041228264570236
step: 230, loss: 0.039580799639225006
step: 240, loss: 0.042811498045921326
step: 250, loss: 0.07509835809469223
step: 260, loss: 0.06361053884029388
step: 270, loss: 0.018819620832800865
step: 280, loss: 0.056211236864328384
step: 290, loss: 0.07579084485769272
step: 300, loss: 0.18994760513305664
step: 310, loss: 0.06471395492553711
step: 320, loss: 0.060706693679094315
step: 330, loss: 0.0887303426861763
step: 340, loss: 0.03198247775435448
step: 350, loss: 0.041012559086084366
step: 360, loss: 0.13852787017822266
step: 370, loss: 0.05878854915499687
step: 380, loss: 0.29609590768814087
step: 390, loss: 0.07109574228525162
step: 400, loss: 0.05652092397212982
step: 410, loss: 0.19375941157341003
epoch 5: dev_f1=0.8580498866213152, f1=0.7195767195767198, best_f1=0.7940327237728584
step: 0, loss: 0.012400892563164234
step: 10, loss: 0.03480445221066475
step: 20, loss: 0.08832543343305588
step: 30, loss: 0.024982931092381477
step: 40, loss: 0.0774994045495987
step: 50, loss: 0.05122407153248787
step: 60, loss: 0.23874200880527496
step: 70, loss: 0.10664030909538269
step: 80, loss: 0.053659018129110336
step: 90, loss: 0.03298719972372055
step: 100, loss: 0.04967944696545601
step: 110, loss: 0.08272247016429901
step: 120, loss: 0.042349472641944885
step: 130, loss: 0.14423857629299164
step: 140, loss: 0.03505773842334747
step: 150, loss: 0.09383628517389297
step: 160, loss: 0.021350590512156487
step: 170, loss: 0.03739490360021591
step: 180, loss: 0.041346121579408646
step: 190, loss: 0.18263380229473114
step: 200, loss: 0.05870126560330391
step: 210, loss: 0.04252438619732857
step: 220, loss: 0.12252800911664963
step: 230, loss: 0.01325386855751276
step: 240, loss: 0.057995911687612534
step: 250, loss: 0.05557253211736679
step: 260, loss: 0.08485312759876251
step: 270, loss: 0.061868298798799515
step: 280, loss: 0.11110579967498779
step: 290, loss: 0.2188236266374588
step: 300, loss: 0.16320990025997162
step: 310, loss: 0.08069983869791031
step: 320, loss: 0.05015920475125313
step: 330, loss: 0.0872926414012909
step: 340, loss: 0.04047808051109314
step: 350, loss: 0.05289046838879585
step: 360, loss: 0.1335221827030182
step: 370, loss: 0.08231649547815323
step: 380, loss: 0.14150597155094147
step: 390, loss: 0.17774510383605957
step: 400, loss: 0.037009336054325104
step: 410, loss: 0.0241096168756485
epoch 6: dev_f1=0.8775413711583925, f1=0.7098099640472522, best_f1=0.7940327237728584
step: 0, loss: 0.047858066856861115
step: 10, loss: 0.0406789556145668
step: 20, loss: 0.009972598403692245
step: 30, loss: 0.09853323549032211
step: 40, loss: 0.09238316863775253
step: 50, loss: 0.19320343434810638
step: 60, loss: 0.053540609776973724
step: 70, loss: 0.005548706278204918
step: 80, loss: 0.046208303421735764
step: 90, loss: 0.013469718396663666
step: 100, loss: 0.01457655243575573
step: 110, loss: 0.027519475668668747
step: 120, loss: 0.009053708985447884
step: 130, loss: 0.0431336872279644
step: 140, loss: 0.014132078737020493
step: 150, loss: 0.017901990562677383
step: 160, loss: 0.025072937831282616
step: 170, loss: 0.059322480112314224
step: 180, loss: 0.04227446764707565
step: 190, loss: 0.11113400757312775
step: 200, loss: 0.06391012668609619
step: 210, loss: 0.05134323611855507
step: 220, loss: 0.041984252631664276
step: 230, loss: 0.08029104024171829
step: 240, loss: 0.11161584407091141
step: 250, loss: 0.012820675037801266
step: 260, loss: 0.005650158505886793
step: 270, loss: 0.09788397699594498
step: 280, loss: 0.016033004969358444
step: 290, loss: 0.04307354986667633
step: 300, loss: 0.021526414901018143
step: 310, loss: 0.004457398783415556
step: 320, loss: 0.17771348357200623
step: 330, loss: 0.07205928862094879
step: 340, loss: 0.03664536401629448
step: 350, loss: 0.035297147929668427
step: 360, loss: 0.014915572479367256
step: 370, loss: 0.03118710219860077
step: 380, loss: 0.03650929406285286
step: 390, loss: 0.051611606031656265
step: 400, loss: 0.07739777863025665
step: 410, loss: 0.020369205623865128
epoch 7: dev_f1=0.8663251047973917, f1=0.7094861660079053, best_f1=0.7940327237728584
step: 0, loss: 0.0431387685239315
step: 10, loss: 0.0946648120880127
step: 20, loss: 0.016353288665413857
step: 30, loss: 0.003795288736000657
step: 40, loss: 0.05726996436715126
step: 50, loss: 0.006641015410423279
step: 60, loss: 0.004874286707490683
step: 70, loss: 0.029406554996967316
step: 80, loss: 0.023264314979314804
step: 90, loss: 0.01027288194745779
step: 100, loss: 0.02528679557144642
step: 110, loss: 0.026052098721265793
step: 120, loss: 0.002754567889496684
step: 130, loss: 0.01712816022336483
step: 140, loss: 0.02401741035282612
step: 150, loss: 0.002405772916972637
step: 160, loss: 0.007484142202883959
step: 170, loss: 0.03382236137986183
step: 180, loss: 0.10359472036361694
step: 190, loss: 0.00892200879752636
step: 200, loss: 0.0026819580234587193
step: 210, loss: 0.008117267861962318
step: 220, loss: 0.008870860561728477
step: 230, loss: 0.06039823219180107
step: 240, loss: 0.006114881951361895
step: 250, loss: 0.025342164561152458
step: 260, loss: 0.07964426279067993
step: 270, loss: 0.1642167866230011
step: 280, loss: 0.06461575627326965
step: 290, loss: 0.04755034297704697
step: 300, loss: 0.016508273780345917
step: 310, loss: 0.00195092405192554
step: 320, loss: 0.0010097279446199536
step: 330, loss: 0.04804730415344238
step: 340, loss: 0.14186690747737885
step: 350, loss: 0.12986792623996735
step: 360, loss: 0.011562728323042393
step: 370, loss: 0.0078054992482066154
step: 380, loss: 0.10075950622558594
step: 390, loss: 0.0015524399932473898
step: 400, loss: 0.09624364227056503
step: 410, loss: 0.004293271340429783
epoch 8: dev_f1=0.8707607699358386, f1=0.7216294859359845, best_f1=0.7940327237728584
step: 0, loss: 0.0016870030667632818
step: 10, loss: 0.009389834478497505
step: 20, loss: 0.017184795811772346
step: 30, loss: 0.007269343361258507
step: 40, loss: 0.01683279685676098
step: 50, loss: 0.02182396501302719
step: 60, loss: 0.04598361626267433
step: 70, loss: 0.014841750264167786
step: 80, loss: 0.18497557938098907
step: 90, loss: 0.007315178867429495
step: 100, loss: 0.024956928566098213
step: 110, loss: 0.007271150592714548
step: 120, loss: 0.11612287163734436
step: 130, loss: 0.03729022294282913
step: 140, loss: 0.0038155249785631895
step: 150, loss: 0.020893683657050133
step: 160, loss: 0.0050675091333687305
step: 170, loss: 0.0045731267891824245
step: 180, loss: 0.009377355687320232
step: 190, loss: 0.0430634431540966
step: 200, loss: 0.009330186061561108
step: 210, loss: 0.02661624364554882
step: 220, loss: 0.01084714476019144
step: 230, loss: 0.042680997401475906
step: 240, loss: 0.0045678880997002125
step: 250, loss: 0.05464082583785057
step: 260, loss: 0.0570574626326561
step: 270, loss: 0.007370417937636375
step: 280, loss: 0.00161240273155272
step: 290, loss: 0.008970142342150211
step: 300, loss: 0.0896529108285904
step: 310, loss: 0.009602339938282967
step: 320, loss: 0.059014227241277695
step: 330, loss: 0.0029306020587682724
step: 340, loss: 0.09530576318502426
step: 350, loss: 0.0059557585045695305
step: 360, loss: 0.0028604271356016397
step: 370, loss: 0.02788626030087471
step: 380, loss: 0.007321770768612623
step: 390, loss: 0.11733317375183105
step: 400, loss: 0.009802710264921188
step: 410, loss: 0.016422085464000702
epoch 9: dev_f1=0.8563685636856369, f1=0.6997590361445784, best_f1=0.7940327237728584
step: 0, loss: 0.00553858932107687
step: 10, loss: 0.0024766100104898214
step: 20, loss: 0.07338132709264755
step: 30, loss: 0.002165100071579218
step: 40, loss: 0.009951440617442131
step: 50, loss: 0.0014983662404119968
step: 60, loss: 0.04556575417518616
step: 70, loss: 0.005310975015163422
step: 80, loss: 0.010315632447600365
step: 90, loss: 0.03286860138177872
step: 100, loss: 0.009574384428560734
step: 110, loss: 0.04019183665513992
step: 120, loss: 0.02380071021616459
step: 130, loss: 0.002107693813741207
step: 140, loss: 0.023052949458360672
step: 150, loss: 0.0653168112039566
step: 160, loss: 0.039433423429727554
step: 170, loss: 0.003093426814302802
step: 180, loss: 0.03395874425768852
step: 190, loss: 0.031729090958833694
step: 200, loss: 0.0005965065793134272
step: 210, loss: 0.013538596220314503
step: 220, loss: 0.11584813892841339
step: 230, loss: 0.031669504940509796
step: 240, loss: 0.0008911985205486417
step: 250, loss: 0.010865375399589539
step: 260, loss: 0.0013094715541228652
step: 270, loss: 0.0010606255382299423
step: 280, loss: 0.03778592869639397
step: 290, loss: 0.007352357730269432
step: 300, loss: 0.013900043442845345
step: 310, loss: 0.0027779103256762028
step: 320, loss: 0.004291069693863392
step: 330, loss: 0.0010911693098023534
step: 340, loss: 0.005908329039812088
step: 350, loss: 0.003509886097162962
step: 360, loss: 0.01813117228448391
step: 370, loss: 0.014575902372598648
step: 380, loss: 0.0003557884192559868
step: 390, loss: 0.005608771461993456
step: 400, loss: 0.009415724314749241
step: 410, loss: 0.00032954488415271044
epoch 10: dev_f1=0.862410071942446, f1=0.7119126720455624, best_f1=0.7940327237728584
step: 0, loss: 0.0030666969250887632
step: 10, loss: 0.02229435183107853
step: 20, loss: 0.001338516129180789
step: 30, loss: 0.012072992511093616
step: 40, loss: 0.005565390922129154
step: 50, loss: 0.0011425730772316456
step: 60, loss: 0.004659170284867287
step: 70, loss: 0.03806905448436737
step: 80, loss: 0.006101707927882671
step: 90, loss: 0.04411207512021065
step: 100, loss: 0.204183429479599
step: 110, loss: 0.10686257481575012
step: 120, loss: 0.012408535927534103
step: 130, loss: 0.0018771744798868895
step: 140, loss: 0.003051937324926257
step: 150, loss: 0.003045281395316124
step: 160, loss: 0.00045737368054687977
step: 170, loss: 0.014776710420846939
step: 180, loss: 0.0028683801647275686
step: 190, loss: 0.005576442927122116
step: 200, loss: 0.009082923643290997
step: 210, loss: 0.011295496486127377
step: 220, loss: 0.0033849021419882774
step: 230, loss: 0.061814069747924805
step: 240, loss: 0.011546339839696884
step: 250, loss: 0.04789786785840988
step: 260, loss: 0.040958404541015625
step: 270, loss: 0.007183900568634272
step: 280, loss: 0.0011461192043498158
step: 290, loss: 0.059578441083431244
step: 300, loss: 0.033976271748542786
step: 310, loss: 0.011903046630322933
step: 320, loss: 0.005486160516738892
step: 330, loss: 0.0036124112084507942
step: 340, loss: 0.0033833521883934736
step: 350, loss: 0.000622057996224612
step: 360, loss: 0.19239091873168945
step: 370, loss: 0.008495197631418705
step: 380, loss: 0.040821973234415054
step: 390, loss: 0.007725967559963465
step: 400, loss: 0.0022188397124409676
step: 410, loss: 0.11562534421682358
epoch 11: dev_f1=0.8558599012123934, f1=0.7036859741503112, best_f1=0.7940327237728584
step: 0, loss: 0.04065902531147003
step: 10, loss: 0.03545199707150459
step: 20, loss: 0.010546371340751648
step: 30, loss: 0.002643885789439082
step: 40, loss: 0.03814136981964111
step: 50, loss: 0.006810895167291164
step: 60, loss: 0.0004379424499347806
step: 70, loss: 0.00243062200024724
step: 80, loss: 0.03013390675187111
step: 90, loss: 0.0014935367507860065
step: 100, loss: 0.0011721075279638171
step: 110, loss: 0.0022805347107350826
step: 120, loss: 0.004388784058392048
step: 130, loss: 0.0002231218240922317
step: 140, loss: 0.008796289563179016
step: 150, loss: 0.012670128606259823
step: 160, loss: 0.012552361004054546
step: 170, loss: 0.000567569921258837
step: 180, loss: 0.0012852289946749806
step: 190, loss: 0.002580614062026143
step: 200, loss: 0.09987015277147293
step: 210, loss: 0.004600379150360823
step: 220, loss: 0.0008387871203012764
step: 230, loss: 0.0009492939570918679
step: 240, loss: 0.0007459695334546268
step: 250, loss: 0.005360135342925787
step: 260, loss: 0.04495204985141754
step: 270, loss: 0.009430086240172386
step: 280, loss: 0.0036081308498978615
step: 290, loss: 0.0017364724772050977
step: 300, loss: 0.0008491736953146756
step: 310, loss: 0.0006423527374863625
step: 320, loss: 0.0016806075582280755
step: 330, loss: 0.00226145563647151
step: 340, loss: 0.00060603569727391
step: 350, loss: 0.033759213984012604
step: 360, loss: 0.013602062128484249
step: 370, loss: 0.0078915199264884
step: 380, loss: 0.07674282789230347
step: 390, loss: 0.02317233942449093
step: 400, loss: 0.0015677284682169557
step: 410, loss: 0.000229584431508556
epoch 12: dev_f1=0.8566226672735548, f1=0.7034883720930233, best_f1=0.7940327237728584
step: 0, loss: 0.005993959493935108
step: 10, loss: 0.003264565719291568
step: 20, loss: 0.005854814779013395
step: 30, loss: 0.001272815396077931
step: 40, loss: 0.00029840675415471196
step: 50, loss: 0.00021909376664552838
step: 60, loss: 0.00016819000302348286
step: 70, loss: 0.0009369630133733153
step: 80, loss: 0.0005167739582248032
step: 90, loss: 0.00017920180107466877
step: 100, loss: 0.005468633957207203
step: 110, loss: 0.05979999154806137
step: 120, loss: 0.007496063131839037
step: 130, loss: 0.0025138380005955696
step: 140, loss: 0.006738919764757156
step: 150, loss: 0.012908834964036942
step: 160, loss: 0.00882964301854372
step: 170, loss: 0.002199418842792511
step: 180, loss: 0.001333078253082931
step: 190, loss: 0.006082393694669008
step: 200, loss: 0.0011713029816746712
step: 210, loss: 0.0007294951938092709
step: 220, loss: 0.05306854471564293
step: 230, loss: 0.014833963476121426
step: 240, loss: 0.02045908384025097
step: 250, loss: 0.0027053195517510176
step: 260, loss: 0.009765624068677425
step: 270, loss: 0.0009741696994751692
step: 280, loss: 0.00346661196090281
step: 290, loss: 0.0007638294482603669
step: 300, loss: 0.03702351078391075
step: 310, loss: 0.00570884020999074
step: 320, loss: 0.0033797663636505604
step: 330, loss: 0.06998560577630997
step: 340, loss: 0.0016038371250033379
step: 350, loss: 0.0031324552837759256
step: 360, loss: 0.006184720434248447
step: 370, loss: 0.0006707469583489001
step: 380, loss: 0.008577132597565651
step: 390, loss: 0.004856593441218138
step: 400, loss: 0.00021925143664702773
step: 410, loss: 0.00010899456538027152
epoch 13: dev_f1=0.8649411764705882, f1=0.7068354430379747, best_f1=0.7940327237728584
step: 0, loss: 0.01686117798089981
step: 10, loss: 0.0027809087187051773
step: 20, loss: 0.0051593659445643425
step: 30, loss: 0.021296152845025063
step: 40, loss: 0.0018460339633747935
step: 50, loss: 0.00016740505816414952
step: 60, loss: 0.019176198169589043
step: 70, loss: 0.0005547499167732894
step: 80, loss: 0.059998344630002975
step: 90, loss: 0.00015627298853360116
step: 100, loss: 0.0013003537897020578
step: 110, loss: 0.00019227140001021326
step: 120, loss: 0.005926110781729221
step: 130, loss: 0.0015411368804052472
step: 140, loss: 0.003032270586118102
step: 150, loss: 0.010889441706240177
step: 160, loss: 0.022484393790364265
step: 170, loss: 0.05285872519016266
step: 180, loss: 0.0003658015630207956
step: 190, loss: 0.002667541615664959
step: 200, loss: 0.00010587360156932846
step: 210, loss: 0.000887732021510601
step: 220, loss: 0.0008187363273464143
step: 230, loss: 0.007488616276532412
step: 240, loss: 0.08545912057161331
step: 250, loss: 0.00046296525397337973
step: 260, loss: 0.008190760388970375
step: 270, loss: 0.007041071075946093
step: 280, loss: 0.046693459153175354
step: 290, loss: 0.00041720186709426343
step: 300, loss: 0.01350643951445818
step: 310, loss: 0.0005230817478150129
step: 320, loss: 0.0015324115520343184
step: 330, loss: 0.007018030621111393
step: 340, loss: 0.030330030247569084
step: 350, loss: 0.0023079426027834415
step: 360, loss: 0.005476316902786493
step: 370, loss: 0.01665901206433773
step: 380, loss: 0.0005750006530433893
step: 390, loss: 0.000441032083472237
step: 400, loss: 0.0012145962100476027
step: 410, loss: 0.08303113281726837
epoch 14: dev_f1=0.8627268496975337, f1=0.704112337011033, best_f1=0.7940327237728584
step: 0, loss: 0.0022874062415212393
step: 10, loss: 8.741454075789079e-05
step: 20, loss: 0.0012706245761364698
step: 30, loss: 0.013727812096476555
step: 40, loss: 0.0146416537463665
step: 50, loss: 0.0002501652925275266
step: 60, loss: 0.0005367512931115925
step: 70, loss: 0.0005198293947614729
step: 80, loss: 0.028797507286071777
step: 90, loss: 0.0006821751594543457
step: 100, loss: 0.09122329950332642
step: 110, loss: 0.08825518935918808
step: 120, loss: 0.00026386542594991624
step: 130, loss: 0.0193474180996418
step: 140, loss: 0.00045226624934002757
step: 150, loss: 0.00023108463210519403
step: 160, loss: 0.00019684508151840419
step: 170, loss: 0.0016796133713796735
step: 180, loss: 0.0008030581520870328
step: 190, loss: 0.0004611726035363972
step: 200, loss: 0.0003755037032533437
step: 210, loss: 0.00097931909840554
step: 220, loss: 0.00012963151675648987
step: 230, loss: 0.001777835190296173
step: 240, loss: 0.000227676922804676
step: 250, loss: 0.00053028465481475
step: 260, loss: 0.0005728178075514734
step: 270, loss: 0.016996396705508232
step: 280, loss: 0.0006524283671751618
step: 290, loss: 0.005479681305587292
step: 300, loss: 0.011146117933094501
step: 310, loss: 0.0056032054126262665
step: 320, loss: 0.0004266591276973486
step: 330, loss: 0.0001376928121317178
step: 340, loss: 0.011001835577189922
step: 350, loss: 0.00013143711839802563
step: 360, loss: 0.00015371966583188623
step: 370, loss: 0.0010561717208474874
step: 380, loss: 8.196780981961638e-05
step: 390, loss: 0.0004569340089801699
step: 400, loss: 0.01866304874420166
step: 410, loss: 0.0007774045807309449
epoch 15: dev_f1=0.8422010004547521, f1=0.6803827751196172, best_f1=0.7940327237728584
step: 0, loss: 0.00028875068528577685
step: 10, loss: 0.0031261586118489504
step: 20, loss: 0.00011333348084008321
step: 30, loss: 0.0002566171169746667
step: 40, loss: 8.688004163559526e-05
step: 50, loss: 0.0005773710436187685
step: 60, loss: 0.001249054097570479
step: 70, loss: 0.0003690939338412136
step: 80, loss: 0.0007695614476688206
step: 90, loss: 0.0005739468615502119
step: 100, loss: 0.014515312388539314
step: 110, loss: 0.0034003700129687786
step: 120, loss: 0.0036815027706325054
step: 130, loss: 0.10269087553024292
step: 140, loss: 0.00136326695792377
step: 150, loss: 0.002926370594650507
step: 160, loss: 0.0022024239879101515
step: 170, loss: 0.0313170962035656
step: 180, loss: 0.0020601789001375437
step: 190, loss: 0.019998585805296898
step: 200, loss: 0.0012508129002526402
step: 210, loss: 0.0013229218311607838
step: 220, loss: 0.07383911311626434
step: 230, loss: 0.008524737320840359
step: 240, loss: 0.018195688724517822
step: 250, loss: 0.0010307016782462597
step: 260, loss: 0.0073512038215994835
step: 270, loss: 0.00028815396944992244
step: 280, loss: 0.0003659320645965636
step: 290, loss: 0.026955310255289078
step: 300, loss: 0.0005932319327257574
step: 310, loss: 0.00041502213571220636
step: 320, loss: 0.001910150283947587
step: 330, loss: 0.002959823003038764
step: 340, loss: 0.0027113454416394234
step: 350, loss: 0.00048279116163030267
step: 360, loss: 0.0004967648419551551
step: 370, loss: 0.0002578924468252808
step: 380, loss: 0.001724494039081037
step: 390, loss: 0.00024366885190829635
step: 400, loss: 0.00012619461631402373
step: 410, loss: 0.013838068582117558
epoch 16: dev_f1=0.8526504941599282, f1=0.7087144920558497, best_f1=0.7940327237728584
step: 0, loss: 0.00018285341502632946
step: 10, loss: 0.0018126608338207006
step: 20, loss: 0.00812485534697771
step: 30, loss: 0.023642433807253838
step: 40, loss: 0.00014688289957121015
step: 50, loss: 0.0012111926916986704
step: 60, loss: 0.0011060112155973911
step: 70, loss: 0.0009586629457771778
step: 80, loss: 0.0009722667746245861
step: 90, loss: 0.013485743664205074
step: 100, loss: 0.00017446614219807088
step: 110, loss: 0.0011817500926554203
step: 120, loss: 0.0001636462693568319
step: 130, loss: 0.004007683601230383
step: 140, loss: 0.00012397149112075567
step: 150, loss: 0.04400312155485153
step: 160, loss: 0.00022543927480001003
step: 170, loss: 0.0004976646741852164
step: 180, loss: 0.004866157658398151
step: 190, loss: 0.00025401139282621443
step: 200, loss: 0.00039477282552979887
step: 210, loss: 0.00023326546943280846
step: 220, loss: 0.059951215982437134
step: 230, loss: 0.00022300287673715502
step: 240, loss: 7.236211968120188e-05
step: 250, loss: 6.477564602391794e-05
step: 260, loss: 0.0003389331977814436
step: 270, loss: 0.00043196583283133805
step: 280, loss: 0.0005938620888628066
step: 290, loss: 0.00014176114927977324
step: 300, loss: 0.001934428233653307
step: 310, loss: 0.007907809689640999
step: 320, loss: 0.0005258916062302887
step: 330, loss: 0.0014180537546053529
step: 340, loss: 8.041323599172756e-05
step: 350, loss: 0.002045322908088565
step: 360, loss: 0.004842080175876617
step: 370, loss: 0.0008963376167230308
step: 380, loss: 0.003703243099153042
step: 390, loss: 0.0006872943486087024
step: 400, loss: 0.0005853634211234748
step: 410, loss: 0.0017512434860691428
epoch 17: dev_f1=0.8568790397045244, f1=0.702012763868434, best_f1=0.7940327237728584
step: 0, loss: 0.00011316564632579684
step: 10, loss: 0.00015534179692622274
step: 20, loss: 9.345047874376178e-05
step: 30, loss: 0.000217840337427333
step: 40, loss: 0.0005276303272694349
step: 50, loss: 0.0002888754243031144
step: 60, loss: 0.0023987595923244953
step: 70, loss: 0.0002634660922922194
step: 80, loss: 0.00018872540385928005
step: 90, loss: 0.0006035335827618837
step: 100, loss: 0.0020265139173716307
step: 110, loss: 0.01311546377837658
step: 120, loss: 0.00015135547437239438
step: 130, loss: 0.0010220824042335153
step: 140, loss: 0.0005378111382015049
step: 150, loss: 0.000164166689501144
step: 160, loss: 0.0018721586093306541
step: 170, loss: 0.018365878611803055
step: 180, loss: 0.008420503698289394
step: 190, loss: 0.00023342391068581492
step: 200, loss: 0.00010321578156435862
step: 210, loss: 0.00038835161831229925
step: 220, loss: 0.006300428416579962
step: 230, loss: 7.99813205958344e-05
step: 240, loss: 8.138207340380177e-05
step: 250, loss: 8.394084579776973e-05
step: 260, loss: 5.2586179663194343e-05
step: 270, loss: 4.974140028934926e-05
step: 280, loss: 0.0002879997482523322
step: 290, loss: 0.00024614075664430857
step: 300, loss: 0.00015911886293906718
step: 310, loss: 0.0005069178878329694
step: 320, loss: 0.09980681538581848
step: 330, loss: 0.007901022210717201
step: 340, loss: 0.00013448843674268574
step: 350, loss: 0.003820432350039482
step: 360, loss: 0.002012643264606595
step: 370, loss: 0.00015995958528947085
step: 380, loss: 0.0030126520432531834
step: 390, loss: 0.002895310055464506
step: 400, loss: 0.006597752682864666
step: 410, loss: 0.00011720426118699834
epoch 18: dev_f1=0.8607126330402591, f1=0.7047713717693838, best_f1=0.7940327237728584
step: 0, loss: 4.929392889607698e-05
step: 10, loss: 0.0004620250838343054
step: 20, loss: 0.0004003489448223263
step: 30, loss: 0.00010522652155486867
step: 40, loss: 0.00012350625183898956
step: 50, loss: 6.525371281895787e-05
step: 60, loss: 0.0011469684541225433
step: 70, loss: 0.00019682107085827738
step: 80, loss: 0.0005260572070255876
step: 90, loss: 0.00044093813630752265
step: 100, loss: 0.00038460089126601815
step: 110, loss: 0.00022270700719673187
step: 120, loss: 0.0025010216049849987
step: 130, loss: 0.00023536568915005773
step: 140, loss: 0.0050805555656552315
step: 150, loss: 0.00016163599502760917
step: 160, loss: 0.00011235933197895065
step: 170, loss: 0.0134692108258605
step: 180, loss: 6.088666123105213e-05
step: 190, loss: 0.0008094973745755851
step: 200, loss: 0.014117917977273464
step: 210, loss: 0.00017423996177967638
step: 220, loss: 0.00017897463112603873
step: 230, loss: 0.00020151269563939422
step: 240, loss: 8.903157140593976e-05
step: 250, loss: 0.00013241929991636425
step: 260, loss: 0.0001710883661871776
step: 270, loss: 0.012225186452269554
step: 280, loss: 6.51194786769338e-05
step: 290, loss: 0.0006846740143373609
step: 300, loss: 0.00018060689035337418
step: 310, loss: 0.0012188508408144116
step: 320, loss: 0.01816275715827942
step: 330, loss: 0.00022976625768933445
step: 340, loss: 0.00018888934573624283
step: 350, loss: 0.00373620493337512
step: 360, loss: 0.002744810190051794
step: 370, loss: 0.0001756027340888977
step: 380, loss: 5.055630026618019e-05
step: 390, loss: 0.00017034092161338776
step: 400, loss: 0.00026554547366686165
step: 410, loss: 0.00013601285172626376
epoch 19: dev_f1=0.859122401847575, f1=0.6927651139742319, best_f1=0.7940327237728584
step: 0, loss: 0.0007692028302699327
step: 10, loss: 0.00010341082088416442
step: 20, loss: 8.542330760974437e-05
step: 30, loss: 0.029952509328722954
step: 40, loss: 0.00026467590942047536
step: 50, loss: 0.0010991459712386131
step: 60, loss: 0.0006390390335582197
step: 70, loss: 0.00014998356346040964
step: 80, loss: 0.00043650923180393875
step: 90, loss: 0.008646681904792786
step: 100, loss: 0.00038931454764679074
step: 110, loss: 0.00030671467538923025
step: 120, loss: 0.000177700916538015
step: 130, loss: 0.000430378713645041
step: 140, loss: 0.00036313693271949887
step: 150, loss: 0.000109120286651887
step: 160, loss: 0.002592290285974741
step: 170, loss: 0.00012477027485147119
step: 180, loss: 0.0008468445157632232
step: 190, loss: 0.0011439048685133457
step: 200, loss: 0.00041475307079963386
step: 210, loss: 7.877273310441524e-05
step: 220, loss: 0.00012158341269241646
step: 230, loss: 0.0011859096121042967
step: 240, loss: 0.015685323625802994
step: 250, loss: 6.586153176613152e-05
step: 260, loss: 0.00012525383499450982
step: 270, loss: 0.0004611400654539466
step: 280, loss: 0.00010641038534231484
step: 290, loss: 0.01370430737733841
step: 300, loss: 0.000706894148606807
step: 310, loss: 0.0027139168232679367
step: 320, loss: 0.009696797467768192
step: 330, loss: 0.003912278451025486
step: 340, loss: 0.00014187954366207123
step: 350, loss: 4.956437987857498e-05
step: 360, loss: 6.236379704205319e-05
step: 370, loss: 0.012203301303088665
step: 380, loss: 8.855741180013865e-05
step: 390, loss: 0.0007634597131982446
step: 400, loss: 0.053230319172143936
step: 410, loss: 0.0015752301551401615
epoch 20: dev_f1=0.8631090487238979, f1=0.6989032901296112, best_f1=0.7940327237728584
