cuda
Device: cuda
step: 0, loss: 0.5611940026283264
step: 10, loss: 0.4230383336544037
step: 20, loss: 0.04224954918026924
step: 30, loss: 0.16532108187675476
step: 40, loss: 0.13873779773712158
step: 50, loss: 0.13514012098312378
step: 60, loss: 0.1453414410352707
step: 70, loss: 0.04210527986288071
step: 80, loss: 0.37705036997795105
step: 90, loss: 0.20644769072532654
step: 100, loss: 0.5827910900115967
step: 110, loss: 0.1403067708015442
step: 120, loss: 0.13172326982021332
step: 130, loss: 0.1068158745765686
step: 140, loss: 0.1298552006483078
step: 150, loss: 0.217378169298172
step: 160, loss: 0.10160838067531586
step: 170, loss: 0.16724960505962372
step: 180, loss: 0.11915155500173569
step: 190, loss: 0.03516565263271332
step: 200, loss: 0.26591935753822327
step: 210, loss: 0.10776977986097336
step: 220, loss: 0.14161211252212524
step: 230, loss: 0.10496824234724045
step: 240, loss: 0.02572803758084774
step: 250, loss: 0.12289823591709137
step: 260, loss: 0.18988892436027527
step: 270, loss: 0.1102527603507042
step: 280, loss: 0.15062719583511353
step: 290, loss: 0.7000879049301147
step: 300, loss: 0.14374640583992004
step: 310, loss: 0.28879648447036743
step: 320, loss: 0.30681055784225464
step: 330, loss: 0.20313596725463867
step: 340, loss: 0.1567259132862091
step: 350, loss: 0.1674261838197708
step: 360, loss: 0.02592959627509117
epoch 1: dev_f1=0.6607669616519174, f1=0.6552706552706553, best_f1=0.6552706552706553
step: 0, loss: 0.20346921682357788
step: 10, loss: 0.137211874127388
step: 20, loss: 0.10696765780448914
step: 30, loss: 0.11951948702335358
step: 40, loss: 0.1778445541858673
step: 50, loss: 0.17136667668819427
step: 60, loss: 0.07591310888528824
step: 70, loss: 0.09089656919240952
step: 80, loss: 0.06855697184801102
step: 90, loss: 0.06667099893093109
step: 100, loss: 0.021057847887277603
step: 110, loss: 0.17522118985652924
step: 120, loss: 0.06593556702136993
step: 130, loss: 0.08496291935443878
step: 140, loss: 0.2929592728614807
step: 150, loss: 0.06437934190034866
step: 160, loss: 0.028392141684889793
step: 170, loss: 0.2105930596590042
step: 180, loss: 0.1552128791809082
step: 190, loss: 0.03422515094280243
step: 200, loss: 0.27856338024139404
step: 210, loss: 0.09321258217096329
step: 220, loss: 0.13034848868846893
step: 230, loss: 0.17860998213291168
step: 240, loss: 0.09927358478307724
step: 250, loss: 0.018152059987187386
step: 260, loss: 0.03933977708220482
step: 270, loss: 0.10071472078561783
step: 280, loss: 0.08103703707456589
step: 290, loss: 0.18506939709186554
step: 300, loss: 0.12037115544080734
step: 310, loss: 0.2015858143568039
step: 320, loss: 0.03395569324493408
step: 330, loss: 0.07550784945487976
step: 340, loss: 0.04430554062128067
step: 350, loss: 0.0983530730009079
step: 360, loss: 0.05497925356030464
epoch 2: dev_f1=0.6713615023474179, f1=0.660332541567696, best_f1=0.660332541567696
step: 0, loss: 0.0669945478439331
step: 10, loss: 0.11207616329193115
step: 20, loss: 0.070584736764431
step: 30, loss: 0.10727301985025406
step: 40, loss: 0.00836894754320383
step: 50, loss: 0.08365426957607269
step: 60, loss: 0.06928686797618866
step: 70, loss: 0.10481627285480499
step: 80, loss: 0.01599174179136753
step: 90, loss: 0.16683967411518097
step: 100, loss: 0.08557608723640442
step: 110, loss: 0.1154613345861435
step: 120, loss: 0.03863759711384773
step: 130, loss: 0.13386772572994232
step: 140, loss: 0.12926015257835388
step: 150, loss: 0.13064579665660858
step: 160, loss: 0.29166609048843384
step: 170, loss: 0.18210558593273163
step: 180, loss: 0.1263161599636078
step: 190, loss: 0.10617967694997787
step: 200, loss: 0.1001409962773323
step: 210, loss: 0.02890619821846485
step: 220, loss: 0.1314946562051773
step: 230, loss: 0.03477833420038223
step: 240, loss: 0.09877478331327438
step: 250, loss: 0.051392339169979095
step: 260, loss: 0.3291545808315277
step: 270, loss: 0.017741413787007332
step: 280, loss: 0.06827633082866669
step: 290, loss: 0.11449149996042252
step: 300, loss: 0.0701884850859642
step: 310, loss: 0.060113441199064255
step: 320, loss: 0.05167408660054207
step: 330, loss: 0.14752443134784698
step: 340, loss: 0.14091083407402039
step: 350, loss: 0.08795272558927536
step: 360, loss: 0.18180733919143677
epoch 3: dev_f1=0.7295285359801489, f1=0.7438423645320198, best_f1=0.7438423645320198
step: 0, loss: 0.3295370638370514
step: 10, loss: 0.2621934413909912
step: 20, loss: 0.09920820593833923
step: 30, loss: 0.0022987292613834143
step: 40, loss: 0.08207137137651443
step: 50, loss: 0.05062101408839226
step: 60, loss: 0.21253955364227295
step: 70, loss: 0.08481191098690033
step: 80, loss: 0.13178908824920654
step: 90, loss: 0.0654584988951683
step: 100, loss: 0.11097483336925507
step: 110, loss: 0.048161547631025314
step: 120, loss: 0.035360049456357956
step: 130, loss: 0.07629158347845078
step: 140, loss: 0.05956288054585457
step: 150, loss: 0.10784389078617096
step: 160, loss: 0.08221925050020218
step: 170, loss: 0.055523741990327835
step: 180, loss: 0.08991385996341705
step: 190, loss: 0.3080763518810272
step: 200, loss: 0.12974736094474792
step: 210, loss: 0.033577993512153625
step: 220, loss: 0.10203120112419128
step: 230, loss: 0.04266917333006859
step: 240, loss: 0.06486544758081436
step: 250, loss: 0.06947821378707886
step: 260, loss: 0.031841374933719635
step: 270, loss: 0.07493621110916138
step: 280, loss: 0.037434257566928864
step: 290, loss: 0.06362485885620117
step: 300, loss: 0.03636443242430687
step: 310, loss: 0.036602385342121124
step: 320, loss: 0.049605969339609146
step: 330, loss: 0.07751621305942535
step: 340, loss: 0.18571217358112335
step: 350, loss: 0.061215560883283615
step: 360, loss: 0.0773555114865303
epoch 4: dev_f1=0.7580645161290323, f1=0.7374301675977653, best_f1=0.7374301675977653
step: 0, loss: 0.09623692184686661
step: 10, loss: 0.06546562910079956
step: 20, loss: 0.09211905300617218
step: 30, loss: 0.07883203029632568
step: 40, loss: 0.132386714220047
step: 50, loss: 0.08817626535892487
step: 60, loss: 0.13929568231105804
step: 70, loss: 0.007224631495773792
step: 80, loss: 0.18524669110774994
step: 90, loss: 0.08328237384557724
step: 100, loss: 0.01129800733178854
step: 110, loss: 0.031324680894613266
step: 120, loss: 0.000642766070086509
step: 130, loss: 0.0735316351056099
step: 140, loss: 0.037451181560754776
step: 150, loss: 0.21300987899303436
step: 160, loss: 0.15951241552829742
step: 170, loss: 0.2847214937210083
step: 180, loss: 0.09229184687137604
step: 190, loss: 0.09143941849470139
step: 200, loss: 0.204973503947258
step: 210, loss: 0.15405051410198212
step: 220, loss: 0.027593202888965607
step: 230, loss: 0.07576639205217361
step: 240, loss: 0.05481676012277603
step: 250, loss: 0.1270301192998886
step: 260, loss: 0.04492554813623428
step: 270, loss: 0.12619401514530182
step: 280, loss: 0.10924474895000458
step: 290, loss: 0.0806848481297493
step: 300, loss: 0.1804153174161911
step: 310, loss: 0.08551450073719025
step: 320, loss: 0.05068379268050194
step: 330, loss: 0.08936645090579987
step: 340, loss: 0.12342672049999237
step: 350, loss: 0.10124664753675461
step: 360, loss: 0.11301690340042114
epoch 5: dev_f1=0.7540983606557378, f1=0.7182320441988949, best_f1=0.7374301675977653
step: 0, loss: 0.0458962619304657
step: 10, loss: 0.051843445748090744
step: 20, loss: 0.07615561038255692
step: 30, loss: 0.1224561408162117
step: 40, loss: 0.148418590426445
step: 50, loss: 0.07024028152227402
step: 60, loss: 0.09942369908094406
step: 70, loss: 0.07630456984043121
step: 80, loss: 0.08595678955316544
step: 90, loss: 0.04330732300877571
step: 100, loss: 0.05266574025154114
step: 110, loss: 0.03986441344022751
step: 120, loss: 0.13182498514652252
step: 130, loss: 0.06734730303287506
step: 140, loss: 0.054779596626758575
step: 150, loss: 0.07020244002342224
step: 160, loss: 0.08143004029989243
step: 170, loss: 0.058775462210178375
step: 180, loss: 0.17118912935256958
step: 190, loss: 0.17589548230171204
step: 200, loss: 0.11788343638181686
step: 210, loss: 0.19432076811790466
step: 220, loss: 0.027815353125333786
step: 230, loss: 0.07887845486402512
step: 240, loss: 0.07097768783569336
step: 250, loss: 0.15669836103916168
step: 260, loss: 0.02987040765583515
step: 270, loss: 0.0776347815990448
step: 280, loss: 0.047229256480932236
step: 290, loss: 0.1861504763364792
step: 300, loss: 0.08525863289833069
step: 310, loss: 0.11929517984390259
step: 320, loss: 0.09542450308799744
step: 330, loss: 0.05852162837982178
step: 340, loss: 0.05743492394685745
step: 350, loss: 0.04454287886619568
step: 360, loss: 0.07185310870409012
epoch 6: dev_f1=0.768, f1=0.7119565217391304, best_f1=0.7119565217391304
step: 0, loss: 0.05829183757305145
step: 10, loss: 0.19584082067012787
step: 20, loss: 0.11565203964710236
step: 30, loss: 0.08600687235593796
step: 40, loss: 0.068595752120018
step: 50, loss: 0.2525309920310974
step: 60, loss: 0.1210763081908226
step: 70, loss: 0.09783612936735153
step: 80, loss: 0.08185404539108276
step: 90, loss: 0.11565209925174713
step: 100, loss: 0.09291769564151764
step: 110, loss: 0.12294963002204895
step: 120, loss: 0.057224128395318985
step: 130, loss: 0.11106403172016144
step: 140, loss: 0.02485440857708454
step: 150, loss: 0.02298743836581707
step: 160, loss: 0.04276707023382187
step: 170, loss: 0.06209490820765495
step: 180, loss: 0.012545746751129627
step: 190, loss: 0.20485840737819672
step: 200, loss: 0.06930416077375412
step: 210, loss: 0.07958493381738663
step: 220, loss: 0.07309528440237045
step: 230, loss: 0.08186575770378113
step: 240, loss: 0.11855840682983398
step: 250, loss: 0.125771164894104
step: 260, loss: 0.04004143923521042
step: 270, loss: 0.04234309867024422
step: 280, loss: 0.07093801349401474
step: 290, loss: 0.1319102793931961
step: 300, loss: 0.12158507108688354
step: 310, loss: 0.16333678364753723
step: 320, loss: 0.08485797792673111
step: 330, loss: 0.07384231686592102
step: 340, loss: 0.13275299966335297
step: 350, loss: 0.06442660093307495
step: 360, loss: 0.1336427927017212
epoch 7: dev_f1=0.7611940298507462, f1=0.7064935064935065, best_f1=0.7119565217391304
step: 0, loss: 0.04497542977333069
step: 10, loss: 0.10476869344711304
step: 20, loss: 0.01661607250571251
step: 30, loss: 0.08659321814775467
step: 40, loss: 0.041540104895830154
step: 50, loss: 0.021504564210772514
step: 60, loss: 0.024762943387031555
step: 70, loss: 0.08339212089776993
step: 80, loss: 0.02383357658982277
step: 90, loss: 0.013862128369510174
step: 100, loss: 0.05301026254892349
step: 110, loss: 0.013332664035260677
step: 120, loss: 0.09645868092775345
step: 130, loss: 0.0345349982380867
step: 140, loss: 0.039871133863925934
step: 150, loss: 0.06904767453670502
step: 160, loss: 0.15744446218013763
step: 170, loss: 0.021181194111704826
step: 180, loss: 0.08130082488059998
step: 190, loss: 0.09590823948383331
step: 200, loss: 0.1296260952949524
step: 210, loss: 0.10785737633705139
step: 220, loss: 0.04267865791916847
step: 230, loss: 0.0028648485895246267
step: 240, loss: 0.04963814839720726
step: 250, loss: 0.04090411588549614
step: 260, loss: 0.0692337304353714
step: 270, loss: 0.042080946266651154
step: 280, loss: 0.05440197139978409
step: 290, loss: 0.05975054204463959
step: 300, loss: 0.000602745683863759
step: 310, loss: 0.08148229122161865
step: 320, loss: 0.05225295200943947
step: 330, loss: 0.10704509913921356
step: 340, loss: 0.11207561939954758
step: 350, loss: 0.17469322681427002
step: 360, loss: 0.06067405641078949
epoch 8: dev_f1=0.753315649867374, f1=0.721311475409836, best_f1=0.7119565217391304
step: 0, loss: 0.022434059530496597
step: 10, loss: 0.0075819892808794975
step: 20, loss: 0.0756959393620491
step: 30, loss: 0.04447823390364647
step: 40, loss: 0.004095941316336393
step: 50, loss: 0.17845644056797028
step: 60, loss: 0.09886693954467773
step: 70, loss: 0.06473571062088013
step: 80, loss: 0.048854053020477295
step: 90, loss: 0.07454405725002289
step: 100, loss: 0.10821636021137238
step: 110, loss: 0.07704649865627289
step: 120, loss: 0.09244894236326218
step: 130, loss: 0.16693684458732605
step: 140, loss: 0.04267755523324013
step: 150, loss: 0.13096004724502563
step: 160, loss: 0.10548046231269836
step: 170, loss: 0.08013493567705154
step: 180, loss: 0.12408953160047531
step: 190, loss: 0.09388837963342667
step: 200, loss: 0.15868917107582092
step: 210, loss: 0.026845481246709824
step: 220, loss: 0.10373716056346893
step: 230, loss: 0.06881020218133926
step: 240, loss: 0.06305096298456192
step: 250, loss: 0.0620594322681427
step: 260, loss: 0.05731474980711937
step: 270, loss: 0.12928996980190277
step: 280, loss: 0.07518190890550613
step: 290, loss: 0.05245983973145485
step: 300, loss: 0.05306901037693024
step: 310, loss: 0.027041681110858917
step: 320, loss: 0.11985472589731216
step: 330, loss: 0.100847028195858
step: 340, loss: 0.06691908836364746
step: 350, loss: 0.03831974044442177
step: 360, loss: 0.069569431245327
epoch 9: dev_f1=0.76, f1=0.7263427109974423, best_f1=0.7119565217391304
step: 0, loss: 0.07468099892139435
step: 10, loss: 0.05851152539253235
step: 20, loss: 0.07961145043373108
step: 30, loss: 0.17015880346298218
step: 40, loss: 0.012136820703744888
step: 50, loss: 0.017566446214914322
step: 60, loss: 0.03315666690468788
step: 70, loss: 0.0744064450263977
step: 80, loss: 0.21513602137565613
step: 90, loss: 0.05446222797036171
step: 100, loss: 0.058307476341724396
step: 110, loss: 0.03293021023273468
step: 120, loss: 0.10346567630767822
step: 130, loss: 0.03833037614822388
step: 140, loss: 0.08557850122451782
step: 150, loss: 0.06433934718370438
step: 160, loss: 0.004704026505351067
step: 170, loss: 0.003029475687071681
step: 180, loss: 0.071153923869133
step: 190, loss: 0.1550806611776352
step: 200, loss: 0.019458197057247162
step: 210, loss: 0.18015170097351074
step: 220, loss: 0.08368945866823196
step: 230, loss: 0.025384634733200073
step: 240, loss: 0.05563042312860489
step: 250, loss: 0.03516969084739685
step: 260, loss: 0.10719969868659973
step: 270, loss: 0.030505191534757614
step: 280, loss: 0.07202659547328949
step: 290, loss: 0.051243171095848083
step: 300, loss: 0.0541096106171608
step: 310, loss: 0.05393482372164726
step: 320, loss: 0.09185957908630371
step: 330, loss: 0.06982634961605072
step: 340, loss: 0.11595489084720612
step: 350, loss: 0.033720456063747406
step: 360, loss: 0.05938875302672386
epoch 10: dev_f1=0.753315649867374, f1=0.7183908045977011, best_f1=0.7119565217391304
step: 0, loss: 0.027360059320926666
step: 10, loss: 0.10246995091438293
step: 20, loss: 0.035933613777160645
step: 30, loss: 0.13455630838871002
step: 40, loss: 0.09539411962032318
step: 50, loss: 0.07803558558225632
step: 60, loss: 0.014096922241151333
step: 70, loss: 0.026533422991633415
step: 80, loss: 0.03144202381372452
step: 90, loss: 0.0301189124584198
step: 100, loss: 0.032805025577545166
step: 110, loss: 0.04922724515199661
step: 120, loss: 0.03280213847756386
step: 130, loss: 0.03357681632041931
step: 140, loss: 0.015798987820744514
step: 150, loss: 0.026091067120432854
step: 160, loss: 0.017612947151064873
step: 170, loss: 0.13675431907176971
step: 180, loss: 0.06842902302742004
step: 190, loss: 0.12030413001775742
step: 200, loss: 0.03172951191663742
step: 210, loss: 0.10378168523311615
step: 220, loss: 0.004822179675102234
step: 230, loss: 0.19408877193927765
step: 240, loss: 0.11611375212669373
step: 250, loss: 0.11411519348621368
step: 260, loss: 0.05554671958088875
step: 270, loss: 0.025284990668296814
step: 280, loss: 0.11114557087421417
step: 290, loss: 0.03116476908326149
step: 300, loss: 0.03700687736272812
step: 310, loss: 0.10376749187707901
step: 320, loss: 0.058597221970558167
step: 330, loss: 0.019733969122171402
step: 340, loss: 0.07149437814950943
step: 350, loss: 0.03608536720275879
step: 360, loss: 0.13478438556194305
epoch 11: dev_f1=0.7444168734491315, f1=0.7142857142857143, best_f1=0.7119565217391304
step: 0, loss: 0.08017690479755402
step: 10, loss: 0.08425672352313995
step: 20, loss: 0.028947774320840836
step: 30, loss: 0.040842846035957336
step: 40, loss: 0.027237726375460625
step: 50, loss: 0.014551926404237747
step: 60, loss: 0.08083619177341461
step: 70, loss: 0.0636030063033104
step: 80, loss: 0.04883104935288429
step: 90, loss: 0.16278435289859772
step: 100, loss: 0.01449998002499342
step: 110, loss: 0.05108267441391945
step: 120, loss: 0.02738535776734352
step: 130, loss: 0.015519555658102036
step: 140, loss: 0.05343535915017128
step: 150, loss: 0.20936992764472961
step: 160, loss: 0.050072796642780304
step: 170, loss: 0.10285386443138123
step: 180, loss: 0.00024302329984493554
step: 190, loss: 0.04041169211268425
step: 200, loss: 0.03378120809793472
step: 210, loss: 0.10867714136838913
step: 220, loss: 0.022621965035796165
step: 230, loss: 0.29085075855255127
step: 240, loss: 0.08186544477939606
step: 250, loss: 0.032154787331819534
step: 260, loss: 0.08651583641767502
step: 270, loss: 0.06914748251438141
step: 280, loss: 0.06112274155020714
step: 290, loss: 0.19214873015880585
step: 300, loss: 0.02547488734126091
step: 310, loss: 0.07274606078863144
step: 320, loss: 0.08335310965776443
step: 330, loss: 0.031251050531864166
step: 340, loss: 0.04596852883696556
step: 350, loss: 0.09428822249174118
step: 360, loss: 0.021493636071681976
epoch 12: dev_f1=0.7318181818181819, f1=0.712962962962963, best_f1=0.7119565217391304
step: 0, loss: 0.07942646741867065
step: 10, loss: 0.09974062442779541
step: 20, loss: 0.03511396422982216
step: 30, loss: 0.00020481174578890204
step: 40, loss: 0.020197169855237007
step: 50, loss: 0.014590054750442505
step: 60, loss: 0.033424168825149536
step: 70, loss: 0.048457980155944824
step: 80, loss: 0.07468079775571823
step: 90, loss: 0.08692453801631927
step: 100, loss: 0.11186622828245163
step: 110, loss: 0.008114043623209
step: 120, loss: 0.033496372401714325
step: 130, loss: 0.08213620632886887
step: 140, loss: 0.06255245208740234
step: 150, loss: 0.031055940315127373
step: 160, loss: 0.0933350920677185
step: 170, loss: 0.15110333263874054
step: 180, loss: 0.06207043677568436
step: 190, loss: 0.02760736271739006
step: 200, loss: 0.02819858491420746
step: 210, loss: 0.05771929398179054
step: 220, loss: 0.03754701837897301
step: 230, loss: 0.007216583471745253
step: 240, loss: 0.04643895849585533
step: 250, loss: 0.016378818079829216
step: 260, loss: 0.12370477616786957
step: 270, loss: 0.11264567822217941
step: 280, loss: 0.1107887327671051
step: 290, loss: 0.034752678126096725
step: 300, loss: 0.04010123014450073
step: 310, loss: 0.01832794025540352
step: 320, loss: 0.0999167263507843
step: 330, loss: 0.18088485300540924
step: 340, loss: 0.006393505726009607
step: 350, loss: 0.11115157604217529
step: 360, loss: 0.15337932109832764
epoch 13: dev_f1=0.7032418952618454, f1=0.6840731070496084, best_f1=0.7119565217391304
step: 0, loss: 0.048591479659080505
step: 10, loss: 0.013209406286478043
step: 20, loss: 0.05097409337759018
step: 30, loss: 0.08581013232469559
step: 40, loss: 0.01737317442893982
step: 50, loss: 0.0071843829937279224
step: 60, loss: 0.036321692168712616
step: 70, loss: 0.10426712036132812
step: 80, loss: 0.07598324120044708
step: 90, loss: 0.014562279917299747
step: 100, loss: 0.10261872410774231
step: 110, loss: 0.01568194478750229
step: 120, loss: 0.06252261251211166
step: 130, loss: 0.030445529147982597
step: 140, loss: 0.0004732955130748451
step: 150, loss: 0.02359152026474476
step: 160, loss: 0.04085046797990799
step: 170, loss: 0.1192089319229126
step: 180, loss: 0.16291770339012146
step: 190, loss: 0.15379472076892853
step: 200, loss: 0.16258513927459717
step: 210, loss: 0.07800709456205368
step: 220, loss: 0.06005660444498062
step: 230, loss: 0.07274649292230606
step: 240, loss: 0.070417620241642
step: 250, loss: 0.10573489218950272
step: 260, loss: 0.016317956149578094
step: 270, loss: 0.051346566528081894
step: 280, loss: 0.05017094686627388
step: 290, loss: 0.05586644262075424
step: 300, loss: 0.03336339816451073
step: 310, loss: 5.162958041182719e-05
step: 320, loss: 0.04442842677235603
step: 330, loss: 0.05867568403482437
step: 340, loss: 0.05517783388495445
step: 350, loss: 0.07816235721111298
step: 360, loss: 0.029482856392860413
epoch 14: dev_f1=0.7096774193548386, f1=0.7078384798099762, best_f1=0.7119565217391304
step: 0, loss: 0.11897245794534683
step: 10, loss: 0.03689495846629143
step: 20, loss: 0.11697995662689209
step: 30, loss: 0.041378188878297806
step: 40, loss: 0.07380621135234833
step: 50, loss: 0.011980005539953709
step: 60, loss: 0.08072961121797562
step: 70, loss: 0.03650893643498421
step: 80, loss: 0.09890560805797577
step: 90, loss: 0.053592801094055176
step: 100, loss: 0.0053930748254060745
step: 110, loss: 0.07942177355289459
step: 120, loss: 0.05820069462060928
step: 130, loss: 0.056341737508773804
step: 140, loss: 2.8132526495028287e-05
step: 150, loss: 0.09874549508094788
step: 160, loss: 0.050790850073099136
step: 170, loss: 0.02494099549949169
step: 180, loss: 0.10125956684350967
step: 190, loss: 0.06492244452238083
step: 200, loss: 0.03258059546351433
step: 210, loss: 0.13949638605117798
step: 220, loss: 0.005503425374627113
step: 230, loss: 0.03573654592037201
step: 240, loss: 0.0076166256330907345
step: 250, loss: 0.09174156188964844
step: 260, loss: 0.12059784680604935
step: 270, loss: 0.029497912153601646
step: 280, loss: 0.11677008867263794
step: 290, loss: 0.07484252750873566
step: 300, loss: 0.03354852646589279
step: 310, loss: 0.009600605815649033
step: 320, loss: 0.018064789474010468
step: 330, loss: 0.02906063199043274
step: 340, loss: 0.025096483528614044
step: 350, loss: 0.03881719708442688
step: 360, loss: 0.03546147793531418
epoch 15: dev_f1=0.719047619047619, f1=0.7213930348258706, best_f1=0.7119565217391304
step: 0, loss: 0.09832017868757248
step: 10, loss: 0.04191901907324791
step: 20, loss: 0.055453814566135406
step: 30, loss: 0.03583066910505295
step: 40, loss: 0.0002486171433702111
step: 50, loss: 0.0056686727330088615
step: 60, loss: 0.016251906752586365
step: 70, loss: 0.01714027114212513
step: 80, loss: 3.538827149895951e-05
step: 90, loss: 0.07548835873603821
step: 100, loss: 0.09052226692438126
step: 110, loss: 0.09109306335449219
step: 120, loss: 0.012700450606644154
step: 130, loss: 0.06994613260030746
step: 140, loss: 0.010858697816729546
step: 150, loss: 0.012719223275780678
step: 160, loss: 0.0968087762594223
step: 170, loss: 0.018317589536309242
step: 180, loss: 0.14233937859535217
step: 190, loss: 0.01994936168193817
step: 200, loss: 0.04641513153910637
step: 210, loss: 0.06911485642194748
step: 220, loss: 0.020165368914604187
step: 230, loss: 0.030732328072190285
step: 240, loss: 0.0560113750398159
step: 250, loss: 0.023506464436650276
step: 260, loss: 0.004560230765491724
step: 270, loss: 0.06450501829385757
step: 280, loss: 0.07468635588884354
step: 290, loss: 0.053340934216976166
step: 300, loss: 0.10106977820396423
step: 310, loss: 0.07562357932329178
step: 320, loss: 0.03868677094578743
step: 330, loss: 0.07279688864946365
step: 340, loss: 0.08165919780731201
step: 350, loss: 0.09847572445869446
step: 360, loss: 0.07261145114898682
epoch 16: dev_f1=0.7399999999999999, f1=0.7234042553191489, best_f1=0.7119565217391304
step: 0, loss: 0.07197152078151703
step: 10, loss: 0.033893559128046036
step: 20, loss: 0.08773516863584518
step: 30, loss: 0.03324759379029274
step: 40, loss: 0.012143936939537525
step: 50, loss: 0.011696302331984043
step: 60, loss: 0.048180099576711655
step: 70, loss: 0.11717477440834045
step: 80, loss: 0.02517571672797203
step: 90, loss: 0.00420644786208868
step: 100, loss: 0.029784146696329117
step: 110, loss: 0.025366351008415222
step: 120, loss: 0.045515816658735275
step: 130, loss: 0.03563665971159935
step: 140, loss: 0.024254698306322098
step: 150, loss: 0.03271270543336868
step: 160, loss: 0.025872517377138138
step: 170, loss: 0.09470649063587189
step: 180, loss: 0.017309507355093956
step: 190, loss: 0.022926371544599533
step: 200, loss: 0.01182399969547987
step: 210, loss: 0.12695558369159698
step: 220, loss: 0.014133731834590435
step: 230, loss: 0.049273472279310226
step: 240, loss: 0.035055726766586304
step: 250, loss: 0.0367608368396759
step: 260, loss: 0.025027798488736153
step: 270, loss: 0.09171970933675766
step: 280, loss: 0.010711194016039371
step: 290, loss: 0.06424146890640259
step: 300, loss: 0.042925313115119934
step: 310, loss: 0.036218125373125076
step: 320, loss: 0.02415131963789463
step: 330, loss: 0.016169708222150803
step: 340, loss: 0.06993851810693741
step: 350, loss: 0.04085272550582886
step: 360, loss: 0.14206475019454956
epoch 17: dev_f1=0.7281553398058251, f1=0.7226463104325699, best_f1=0.7119565217391304
step: 0, loss: 0.07460051029920578
step: 10, loss: 0.029648078605532646
step: 20, loss: 0.058429017663002014
step: 30, loss: 0.056895624846220016
step: 40, loss: 0.004450046923011541
step: 50, loss: 0.052780818194150925
step: 60, loss: 0.06720174849033356
step: 70, loss: 0.0007224404253065586
step: 80, loss: 0.03504899889230728
step: 90, loss: 0.020868301391601562
step: 100, loss: 0.02610829286277294
step: 110, loss: 0.058120280504226685
step: 120, loss: 0.13589078187942505
step: 130, loss: 0.050362128764390945
step: 140, loss: 0.04399701580405235
step: 150, loss: 0.08232535421848297
step: 160, loss: 0.11415480077266693
step: 170, loss: 0.032963041216135025
step: 180, loss: 2.1777397705591284e-05
step: 190, loss: 0.08616326004266739
step: 200, loss: 0.015195004642009735
step: 210, loss: 0.01363831665366888
step: 220, loss: 0.07230880856513977
step: 230, loss: 0.022077756002545357
step: 240, loss: 0.02262314036488533
step: 250, loss: 0.0387425497174263
step: 260, loss: 0.031095651909708977
step: 270, loss: 0.06402607262134552
step: 280, loss: 0.12081057578325272
step: 290, loss: 0.1221829280257225
step: 300, loss: 0.046066757291555405
step: 310, loss: 0.043420448899269104
step: 320, loss: 0.06481912732124329
step: 330, loss: 0.026441199705004692
step: 340, loss: 0.06837600469589233
step: 350, loss: 0.02680128626525402
step: 360, loss: 0.012407110072672367
epoch 18: dev_f1=0.7125307125307127, f1=0.7272727272727272, best_f1=0.7119565217391304
step: 0, loss: 0.04376918077468872
step: 10, loss: 0.005359351634979248
step: 20, loss: 0.04208819195628166
step: 30, loss: 0.02551119774580002
step: 40, loss: 0.02827564626932144
step: 50, loss: 0.025452643632888794
step: 60, loss: 2.158394636353478e-05
step: 70, loss: 0.07579687237739563
step: 80, loss: 0.03144088760018349
step: 90, loss: 0.03819722682237625
step: 100, loss: 0.07581958174705505
step: 110, loss: 0.005512943957000971
step: 120, loss: 0.05857713147997856
step: 130, loss: 0.0766155868768692
step: 140, loss: 0.040289826691150665
step: 150, loss: 0.07503338903188705
step: 160, loss: 0.05647147819399834
step: 170, loss: 0.030451219528913498
step: 180, loss: 0.024887938052415848
step: 190, loss: 0.05029994621872902
step: 200, loss: 0.0758322924375534
step: 210, loss: 0.008409367874264717
step: 220, loss: 0.020534247159957886
step: 230, loss: 0.007910664193332195
step: 240, loss: 0.06994181871414185
step: 250, loss: 0.011630108579993248
step: 260, loss: 0.038071487098932266
step: 270, loss: 0.05429958552122116
step: 280, loss: 0.048579610884189606
step: 290, loss: 1.461418105463963e-05
step: 300, loss: 0.004234913270920515
step: 310, loss: 0.034425415098667145
step: 320, loss: 0.035066843032836914
step: 330, loss: 0.04198586195707321
step: 340, loss: 0.036254070699214935
step: 350, loss: 0.032678283751010895
step: 360, loss: 0.06762905418872833
epoch 19: dev_f1=0.7222222222222223, f1=0.7248677248677249, best_f1=0.7119565217391304
step: 0, loss: 0.06426391005516052
step: 10, loss: 0.02747783064842224
step: 20, loss: 0.04937784746289253
step: 30, loss: 0.04026772081851959
step: 40, loss: 0.10953601449728012
step: 50, loss: 0.01991247944533825
step: 60, loss: 0.050425175577402115
step: 70, loss: 0.017214639112353325
step: 80, loss: 0.042754292488098145
step: 90, loss: 0.0916103646159172
step: 100, loss: 0.02621411345899105
step: 110, loss: 0.0810411274433136
step: 120, loss: 0.05885343253612518
step: 130, loss: 0.018266813829541206
step: 140, loss: 0.02571917697787285
step: 150, loss: 0.08708769083023071
step: 160, loss: 0.03578422963619232
step: 170, loss: 0.019884729757905006
step: 180, loss: 0.24571369588375092
step: 190, loss: 0.06939562410116196
step: 200, loss: 0.0014086298178881407
step: 210, loss: 0.10847290605306625
step: 220, loss: 0.02512727677822113
step: 230, loss: 0.02302049659192562
step: 240, loss: 0.002598945051431656
step: 250, loss: 0.006816226989030838
step: 260, loss: 0.0577579103410244
step: 270, loss: 0.038609828799963
step: 280, loss: 0.12846693396568298
step: 290, loss: 0.025013400241732597
step: 300, loss: 0.023140238597989082
step: 310, loss: 0.0034238463267683983
step: 320, loss: 0.04472319409251213
step: 330, loss: 0.05156194418668747
step: 340, loss: 0.03810904547572136
step: 350, loss: 0.028470836579799652
step: 360, loss: 0.0035369088873267174
epoch 20: dev_f1=0.7268170426065164, f1=0.7210526315789473, best_f1=0.7119565217391304
