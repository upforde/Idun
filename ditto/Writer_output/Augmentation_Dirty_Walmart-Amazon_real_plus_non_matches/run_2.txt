cuda
Device: cuda
step: 0, loss: 0.7713603973388672
step: 10, loss: 0.13428442180156708
step: 20, loss: 0.13990309834480286
step: 30, loss: 0.3366495370864868
step: 40, loss: 0.15097033977508545
step: 50, loss: 0.24329257011413574
step: 60, loss: 0.3207826316356659
step: 70, loss: 0.3177775740623474
step: 80, loss: 0.2328258752822876
step: 90, loss: 0.023833969607949257
step: 100, loss: 0.22657984495162964
step: 110, loss: 0.138525128364563
step: 120, loss: 0.04750778526067734
step: 130, loss: 0.2286917269229889
step: 140, loss: 0.02935613878071308
step: 150, loss: 0.13919022679328918
step: 160, loss: 0.2829020023345947
step: 170, loss: 0.0981554463505745
step: 180, loss: 0.10263794660568237
step: 190, loss: 0.21074411273002625
step: 200, loss: 0.17496348917484283
step: 210, loss: 0.10748891532421112
step: 220, loss: 0.05328216031193733
step: 230, loss: 0.2820760905742645
step: 240, loss: 0.02569984644651413
step: 250, loss: 0.14036442339420319
step: 260, loss: 0.13923172652721405
step: 270, loss: 0.03720109537243843
step: 280, loss: 0.11935941874980927
step: 290, loss: 0.2717761993408203
step: 300, loss: 0.12324903160333633
step: 310, loss: 0.21171310544013977
step: 320, loss: 0.15429270267486572
step: 330, loss: 0.17969749867916107
step: 340, loss: 0.11688460409641266
step: 350, loss: 0.10071806609630585
step: 360, loss: 0.05878230929374695
epoch 1: dev_f1=0.5680473372781065, f1=0.5840336134453781, best_f1=0.5840336134453781
step: 0, loss: 0.2724514901638031
step: 10, loss: 0.17619837820529938
step: 20, loss: 0.12145446240901947
step: 30, loss: 0.24849586188793182
step: 40, loss: 0.1349317878484726
step: 50, loss: 0.029618002474308014
step: 60, loss: 0.08416800945997238
step: 70, loss: 0.22323250770568848
step: 80, loss: 0.008381067775189877
step: 90, loss: 0.1396816223859787
step: 100, loss: 0.1625296026468277
step: 110, loss: 0.19130778312683105
step: 120, loss: 0.16753730177879333
step: 130, loss: 0.19879484176635742
step: 140, loss: 0.24541068077087402
step: 150, loss: 0.1339656263589859
step: 160, loss: 0.038921602070331573
step: 170, loss: 0.22659055888652802
step: 180, loss: 0.3329201936721802
step: 190, loss: 0.11444474011659622
step: 200, loss: 0.099192775785923
step: 210, loss: 0.15532469749450684
step: 220, loss: 0.08761870861053467
step: 230, loss: 0.01848270371556282
step: 240, loss: 0.2627079486846924
step: 250, loss: 0.1749606728553772
step: 260, loss: 0.08010073006153107
step: 270, loss: 0.10356263816356659
step: 280, loss: 0.19193607568740845
step: 290, loss: 0.10987940430641174
step: 300, loss: 0.3761032819747925
step: 310, loss: 0.14719612896442413
step: 320, loss: 0.14630065858364105
step: 330, loss: 0.2714194655418396
step: 340, loss: 0.10288980603218079
step: 350, loss: 0.04928023740649223
step: 360, loss: 0.13231347501277924
epoch 2: dev_f1=0.7216494845360825, f1=0.7272727272727273, best_f1=0.7272727272727273
step: 0, loss: 0.08026118576526642
step: 10, loss: 0.22014713287353516
step: 20, loss: 0.050439417362213135
step: 30, loss: 0.03632767125964165
step: 40, loss: 0.03739895671606064
step: 50, loss: 0.3844001293182373
step: 60, loss: 0.0923617035150528
step: 70, loss: 0.01510298065841198
step: 80, loss: 0.10087036341428757
step: 90, loss: 0.11737930029630661
step: 100, loss: 0.015474297106266022
step: 110, loss: 0.1671561747789383
step: 120, loss: 0.06061433255672455
step: 130, loss: 0.14079147577285767
step: 140, loss: 0.11827755719423294
step: 150, loss: 0.055502746254205704
step: 160, loss: 0.13544981181621552
step: 170, loss: 0.3789905905723572
step: 180, loss: 0.1188972070813179
step: 190, loss: 0.07797005772590637
step: 200, loss: 0.12706536054611206
step: 210, loss: 0.39459002017974854
step: 220, loss: 0.09695975482463837
step: 230, loss: 0.16762220859527588
step: 240, loss: 0.07829928398132324
step: 250, loss: 0.06740639358758926
step: 260, loss: 0.050553202629089355
step: 270, loss: 0.09403259307146072
step: 280, loss: 0.12794643640518188
step: 290, loss: 0.13637186586856842
step: 300, loss: 0.09594524651765823
step: 310, loss: 0.026681974530220032
step: 320, loss: 0.15356245636940002
step: 330, loss: 0.29922378063201904
step: 340, loss: 0.08902082592248917
step: 350, loss: 0.06877356767654419
step: 360, loss: 0.15670232474803925
epoch 3: dev_f1=0.7399999999999999, f1=0.7167919799498748, best_f1=0.7167919799498748
step: 0, loss: 0.13244329392910004
step: 10, loss: 0.08836019784212112
step: 20, loss: 0.1044551283121109
step: 30, loss: 0.1514165699481964
step: 40, loss: 0.18908759951591492
step: 50, loss: 0.10956151783466339
step: 60, loss: 0.1334153413772583
step: 70, loss: 0.23231181502342224
step: 80, loss: 0.16281238198280334
step: 90, loss: 0.09319982677698135
step: 100, loss: 0.03969934210181236
step: 110, loss: 0.16611012816429138
step: 120, loss: 0.03937339782714844
step: 130, loss: 0.08969374001026154
step: 140, loss: 0.03941341117024422
step: 150, loss: 0.14539234340190887
step: 160, loss: 0.11069047451019287
step: 170, loss: 0.07178942114114761
step: 180, loss: 0.04545507952570915
step: 190, loss: 0.0969860777258873
step: 200, loss: 0.10345364362001419
step: 210, loss: 0.04390322417020798
step: 220, loss: 0.15242618322372437
step: 230, loss: 0.08665119111537933
step: 240, loss: 0.0644652470946312
step: 250, loss: 0.09043236821889877
step: 260, loss: 0.12967586517333984
step: 270, loss: 0.04214777052402496
step: 280, loss: 0.09638661891222
step: 290, loss: 0.02892935276031494
step: 300, loss: 0.11191737651824951
step: 310, loss: 0.29174506664276123
step: 320, loss: 0.12623187899589539
step: 330, loss: 0.1700485348701477
step: 340, loss: 0.42156174778938293
step: 350, loss: 0.1358216404914856
step: 360, loss: 0.12355529516935349
epoch 4: dev_f1=0.7350000000000001, f1=0.7204030226700252, best_f1=0.7167919799498748
step: 0, loss: 0.031794045120477676
step: 10, loss: 0.1052192896604538
step: 20, loss: 0.07762804627418518
step: 30, loss: 0.1011929139494896
step: 40, loss: 0.056095171719789505
step: 50, loss: 0.06123189255595207
step: 60, loss: 0.09573247283697128
step: 70, loss: 0.07897766679525375
step: 80, loss: 0.14475831389427185
step: 90, loss: 0.08355224877595901
step: 100, loss: 0.022366434335708618
step: 110, loss: 0.07887578010559082
step: 120, loss: 0.0529012568295002
step: 130, loss: 0.1216888427734375
step: 140, loss: 0.06794494390487671
step: 150, loss: 0.06462132930755615
step: 160, loss: 0.07422162592411041
step: 170, loss: 0.28126296401023865
step: 180, loss: 0.1263856440782547
step: 190, loss: 0.021079398691654205
step: 200, loss: 0.3070567548274994
step: 210, loss: 0.0017898606602102518
step: 220, loss: 0.039576731622219086
step: 230, loss: 0.01690017059445381
step: 240, loss: 0.057657577097415924
step: 250, loss: 0.05174092948436737
step: 260, loss: 0.0418754443526268
step: 270, loss: 0.07670819759368896
step: 280, loss: 0.04765470698475838
step: 290, loss: 0.07009537518024445
step: 300, loss: 0.09319732338190079
step: 310, loss: 0.03673838824033737
step: 320, loss: 0.05478455498814583
step: 330, loss: 0.030934391543269157
step: 340, loss: 0.10681916028261185
step: 350, loss: 0.1026669517159462
step: 360, loss: 0.060784392058849335
epoch 5: dev_f1=0.6666666666666666, f1=0.6435185185185186, best_f1=0.7167919799498748
step: 0, loss: 0.06188971549272537
step: 10, loss: 0.022470509633421898
step: 20, loss: 0.06556571274995804
step: 30, loss: 0.06856558471918106
step: 40, loss: 0.035243406891822815
step: 50, loss: 0.10372601449489594
step: 60, loss: 0.017957929521799088
step: 70, loss: 0.0867142304778099
step: 80, loss: 0.07816014438867569
step: 90, loss: 0.1251869946718216
step: 100, loss: 0.016989128664135933
step: 110, loss: 0.10946642607450485
step: 120, loss: 0.11076922714710236
step: 130, loss: 0.1495220959186554
step: 140, loss: 0.04238075017929077
step: 150, loss: 0.11626843363046646
step: 160, loss: 0.0006064784247428179
step: 170, loss: 0.08304914087057114
step: 180, loss: 0.4040749669075012
step: 190, loss: 0.07259971648454666
step: 200, loss: 0.07611410319805145
step: 210, loss: 0.08065225183963776
step: 220, loss: 0.10108573734760284
step: 230, loss: 0.16327697038650513
step: 240, loss: 0.11160523444414139
step: 250, loss: 0.09525714814662933
step: 260, loss: 0.2546001374721527
step: 270, loss: 0.02429591864347458
step: 280, loss: 0.056184183806180954
step: 290, loss: 0.05148438364267349
step: 300, loss: 0.15785501897335052
step: 310, loss: 0.22021417319774628
step: 320, loss: 0.05921399965882301
step: 330, loss: 0.12569867074489594
step: 340, loss: 0.039795368909835815
step: 350, loss: 0.04402514547109604
step: 360, loss: 0.13061514496803284
epoch 6: dev_f1=0.752, f1=0.7601078167115903, best_f1=0.7601078167115903
step: 0, loss: 0.06101970747113228
step: 10, loss: 0.11886436492204666
step: 20, loss: 0.07693146169185638
step: 30, loss: 0.07472900301218033
step: 40, loss: 0.10735752433538437
step: 50, loss: 0.10596077144145966
step: 60, loss: 0.051752302795648575
step: 70, loss: 0.10567762702703476
step: 80, loss: 0.07038520276546478
step: 90, loss: 0.07298963516950607
step: 100, loss: 0.1396678388118744
step: 110, loss: 0.11871365457773209
step: 120, loss: 0.020836150273680687
step: 130, loss: 0.08007420599460602
step: 140, loss: 0.06187629699707031
step: 150, loss: 0.042458754032850266
step: 160, loss: 0.06537368893623352
step: 170, loss: 0.08938462287187576
step: 180, loss: 0.07613297551870346
step: 190, loss: 0.07686034590005875
step: 200, loss: 0.055061277002096176
step: 210, loss: 0.0437462218105793
step: 220, loss: 0.12763406336307526
step: 230, loss: 0.07214169949293137
step: 240, loss: 0.11110799014568329
step: 250, loss: 0.028802385553717613
step: 260, loss: 0.074862040579319
step: 270, loss: 0.030254565179347992
step: 280, loss: 0.03200890123844147
step: 290, loss: 0.10085226595401764
step: 300, loss: 0.06711738556623459
step: 310, loss: 0.07942389696836472
step: 320, loss: 0.14852555096149445
step: 330, loss: 0.03976001217961311
step: 340, loss: 0.01831887662410736
step: 350, loss: 0.11076866835355759
step: 360, loss: 0.06013914570212364
epoch 7: dev_f1=0.7450980392156864, f1=0.7461928934010152, best_f1=0.7601078167115903
step: 0, loss: 0.10124484449625015
step: 10, loss: 0.0731506273150444
step: 20, loss: 0.02094159834086895
step: 30, loss: 0.06876615434885025
step: 40, loss: 0.0696638822555542
step: 50, loss: 0.08960689604282379
step: 60, loss: 0.10187043249607086
step: 70, loss: 0.02839413285255432
step: 80, loss: 0.05417719483375549
step: 90, loss: 0.015512854792177677
step: 100, loss: 0.031379181891679764
step: 110, loss: 0.10403458774089813
step: 120, loss: 0.09783033281564713
step: 130, loss: 0.10045035928487778
step: 140, loss: 0.0009225443936884403
step: 150, loss: 0.019565783441066742
step: 160, loss: 0.020795907825231552
step: 170, loss: 0.02924065850675106
step: 180, loss: 0.07286186516284943
step: 190, loss: 0.14837275445461273
step: 200, loss: 0.12406690418720245
step: 210, loss: 0.05037481337785721
step: 220, loss: 0.07839326560497284
step: 230, loss: 0.09356732666492462
step: 240, loss: 0.13700126111507416
step: 250, loss: 0.05619950592517853
step: 260, loss: 0.07753762602806091
step: 270, loss: 0.13250091671943665
step: 280, loss: 0.06354355812072754
step: 290, loss: 0.08473165333271027
step: 300, loss: 0.13837435841560364
step: 310, loss: 0.04176166653633118
step: 320, loss: 0.09893842786550522
step: 330, loss: 0.027415001764893532
step: 340, loss: 0.0024327882565557957
step: 350, loss: 0.07386405020952225
step: 360, loss: 0.06585423648357391
epoch 8: dev_f1=0.75, f1=0.721311475409836, best_f1=0.7601078167115903
step: 0, loss: 0.05429384857416153
step: 10, loss: 0.05074014514684677
step: 20, loss: 0.0367572084069252
step: 30, loss: 0.10263041406869888
step: 40, loss: 0.07349776476621628
step: 50, loss: 0.04673653841018677
step: 60, loss: 0.09418231248855591
step: 70, loss: 0.06340263783931732
step: 80, loss: 0.22885340452194214
step: 90, loss: 0.02824813313782215
step: 100, loss: 0.024812696501612663
step: 110, loss: 0.05828225612640381
step: 120, loss: 0.07342225313186646
step: 130, loss: 0.07852263003587723
step: 140, loss: 0.09474453330039978
step: 150, loss: 0.0398232527077198
step: 160, loss: 0.06958841532468796
step: 170, loss: 0.12799528241157532
step: 180, loss: 0.11897094547748566
step: 190, loss: 0.10439126938581467
step: 200, loss: 0.061106983572244644
step: 210, loss: 0.10492126643657684
step: 220, loss: 0.08411279320716858
step: 230, loss: 0.013279457576572895
step: 240, loss: 0.13084033131599426
step: 250, loss: 0.008314646780490875
step: 260, loss: 0.04336322844028473
step: 270, loss: 0.08336307853460312
step: 280, loss: 0.0773492306470871
step: 290, loss: 0.01744801551103592
step: 300, loss: 0.051024261862039566
step: 310, loss: 0.038774218410253525
step: 320, loss: 0.14721424877643585
step: 330, loss: 0.07664941251277924
step: 340, loss: 0.040488988161087036
step: 350, loss: 0.038565751165151596
step: 360, loss: 0.10119668394327164
epoch 9: dev_f1=0.7353760445682451, f1=0.7062146892655367, best_f1=0.7601078167115903
step: 0, loss: 0.1401173323392868
step: 10, loss: 0.10352707654237747
step: 20, loss: 0.09385941177606583
step: 30, loss: 0.0531076043844223
step: 40, loss: 0.07399985939264297
step: 50, loss: 0.08194195479154587
step: 60, loss: 0.018359772861003876
step: 70, loss: 0.07036620378494263
step: 80, loss: 0.05064552649855614
step: 90, loss: 0.1678689420223236
step: 100, loss: 0.08451072871685028
step: 110, loss: 0.010465355589985847
step: 120, loss: 0.01022418960928917
step: 130, loss: 0.0370129756629467
step: 140, loss: 0.035407181829214096
step: 150, loss: 0.10269545018672943
step: 160, loss: 0.019519934430718422
step: 170, loss: 0.16401396691799164
step: 180, loss: 0.047731664031744
step: 190, loss: 0.13904541730880737
step: 200, loss: 0.06949217617511749
step: 210, loss: 0.015222175978124142
step: 220, loss: 0.03301134333014488
step: 230, loss: 0.09271728992462158
step: 240, loss: 0.08523289859294891
step: 250, loss: 0.04140383377671242
step: 260, loss: 0.022912990301847458
step: 270, loss: 0.11254007369279861
step: 280, loss: 0.03795388713479042
step: 290, loss: 0.007497879210859537
step: 300, loss: 0.08791176229715347
step: 310, loss: 0.060237035155296326
step: 320, loss: 0.07617533206939697
step: 330, loss: 0.06377355009317398
step: 340, loss: 0.08851169794797897
step: 350, loss: 0.06364592909812927
step: 360, loss: 0.024690505117177963
epoch 10: dev_f1=0.7253886010362695, f1=0.7229551451187335, best_f1=0.7601078167115903
step: 0, loss: 0.046180061995983124
step: 10, loss: 0.05706443265080452
step: 20, loss: 0.10053341090679169
step: 30, loss: 0.12273683398962021
step: 40, loss: 0.0697275772690773
step: 50, loss: 0.06678307056427002
step: 60, loss: 0.011935283429920673
step: 70, loss: 0.03690000995993614
step: 80, loss: 0.02999405562877655
step: 90, loss: 0.07502623647451401
step: 100, loss: 0.03561457619071007
step: 110, loss: 0.08063136041164398
step: 120, loss: 0.034415386617183685
step: 130, loss: 0.013833551667630672
step: 140, loss: 0.05103999376296997
step: 150, loss: 0.020181460306048393
step: 160, loss: 0.07662230730056763
step: 170, loss: 0.011456599459052086
step: 180, loss: 0.047929562628269196
step: 190, loss: 0.04144419729709625
step: 200, loss: 0.018822450190782547
step: 210, loss: 0.2839178144931793
step: 220, loss: 0.08037668466567993
step: 230, loss: 0.03978953883051872
step: 240, loss: 0.043683186173439026
step: 250, loss: 0.0288730226457119
step: 260, loss: 0.0231807678937912
step: 270, loss: 0.02894134446978569
step: 280, loss: 0.029691288247704506
step: 290, loss: 0.00014521038974635303
step: 300, loss: 0.01634014956653118
step: 310, loss: 0.1332261562347412
step: 320, loss: 0.031077256426215172
step: 330, loss: 0.07950591295957565
step: 340, loss: 0.0563729852437973
step: 350, loss: 0.05268396437168121
step: 360, loss: 0.023148775100708008
epoch 11: dev_f1=0.7095115681233932, f1=0.7040000000000001, best_f1=0.7601078167115903
step: 0, loss: 0.08848819136619568
step: 10, loss: 0.031714484095573425
step: 20, loss: 0.0702240914106369
step: 30, loss: 0.00011330605047987774
step: 40, loss: 0.05625004321336746
step: 50, loss: 0.02426244504749775
step: 60, loss: 0.05604752525687218
step: 70, loss: 0.0782223790884018
step: 80, loss: 0.030008330941200256
step: 90, loss: 0.15076179802417755
step: 100, loss: 0.029929116368293762
step: 110, loss: 0.041089992970228195
step: 120, loss: 0.0425662063062191
step: 130, loss: 0.013676845468580723
step: 140, loss: 0.09875478595495224
step: 150, loss: 0.0627993792295456
step: 160, loss: 0.007702327333390713
step: 170, loss: 0.06844132393598557
step: 180, loss: 0.24445615708827972
step: 190, loss: 0.14842146635055542
step: 200, loss: 0.038671817630529404
step: 210, loss: 0.040290653705596924
step: 220, loss: 0.06313032656908035
step: 230, loss: 0.066949263215065
step: 240, loss: 0.04972155764698982
step: 250, loss: 0.04080888256430626
step: 260, loss: 0.024950645864009857
step: 270, loss: 0.06410463154315948
step: 280, loss: 0.02505931630730629
step: 290, loss: 0.1004621833562851
step: 300, loss: 0.03070243075489998
step: 310, loss: 0.0710463598370552
step: 320, loss: 0.09203528612852097
step: 330, loss: 0.03706471621990204
step: 340, loss: 0.08367955684661865
step: 350, loss: 0.022506948560476303
step: 360, loss: 0.019200187176465988
epoch 12: dev_f1=0.7254408060453401, f1=0.7071240105540898, best_f1=0.7601078167115903
step: 0, loss: 0.03968137875199318
step: 10, loss: 0.04262201115489006
step: 20, loss: 0.06717978417873383
step: 30, loss: 0.0003970474353991449
step: 40, loss: 0.07733087986707687
step: 50, loss: 0.11708501726388931
step: 60, loss: 0.04784110188484192
step: 70, loss: 0.06382804363965988
step: 80, loss: 0.0546700693666935
step: 90, loss: 0.08319542557001114
step: 100, loss: 0.06016196683049202
step: 110, loss: 0.030570518225431442
step: 120, loss: 0.0063257841393351555
step: 130, loss: 0.016660332679748535
step: 140, loss: 0.05423426628112793
step: 150, loss: 0.042685363441705704
step: 160, loss: 0.01454880740493536
step: 170, loss: 0.06679604947566986
step: 180, loss: 0.04827552288770676
step: 190, loss: 0.05511920899152756
step: 200, loss: 0.014438275247812271
step: 210, loss: 0.06270665675401688
step: 220, loss: 0.06281258165836334
step: 230, loss: 0.03809468075633049
step: 240, loss: 0.05261337384581566
step: 250, loss: 0.05005699768662453
step: 260, loss: 0.016016196459531784
step: 270, loss: 0.03846049681305885
step: 280, loss: 0.10008283704519272
step: 290, loss: 0.0776909589767456
step: 300, loss: 0.15687671303749084
step: 310, loss: 0.028871793299913406
step: 320, loss: 0.06827644258737564
step: 330, loss: 0.0007741483277641237
step: 340, loss: 0.09689702093601227
step: 350, loss: 0.07283205538988113
step: 360, loss: 0.0035682166926562786
epoch 13: dev_f1=0.7157360406091372, f1=0.7093333333333335, best_f1=0.7601078167115903
step: 0, loss: 0.012726700864732265
step: 10, loss: 0.027169186621904373
step: 20, loss: 0.06006532534956932
step: 30, loss: 0.012660748325288296
step: 40, loss: 0.022968722507357597
step: 50, loss: 0.04639272764325142
step: 60, loss: 0.06146891787648201
step: 70, loss: 0.0026306789368391037
step: 80, loss: 0.01728815957903862
step: 90, loss: 2.5748617190402e-05
step: 100, loss: 0.05442218482494354
step: 110, loss: 0.015867212787270546
step: 120, loss: 0.044958651065826416
step: 130, loss: 0.02643734961748123
step: 140, loss: 0.07119252532720566
step: 150, loss: 0.04860803112387657
step: 160, loss: 0.14279921352863312
step: 170, loss: 0.026485636830329895
step: 180, loss: 0.026349663734436035
step: 190, loss: 0.09805256873369217
step: 200, loss: 0.05427825078368187
step: 210, loss: 0.19051507115364075
step: 220, loss: 0.08953350782394409
step: 230, loss: 0.10191771388053894
step: 240, loss: 0.03131210058927536
step: 250, loss: 0.008757767267525196
step: 260, loss: 0.018843762576580048
step: 270, loss: 0.052380699664354324
step: 280, loss: 0.2240765541791916
step: 290, loss: 0.17107246816158295
step: 300, loss: 0.008289109915494919
step: 310, loss: 0.025239156559109688
step: 320, loss: 0.04270877689123154
step: 330, loss: 0.04714067652821541
step: 340, loss: 0.10677128285169601
step: 350, loss: 0.049284446984529495
step: 360, loss: 0.06887344270944595
epoch 14: dev_f1=0.7230769230769232, f1=0.6925207756232686, best_f1=0.7601078167115903
step: 0, loss: 0.09970682114362717
step: 10, loss: 0.014019139111042023
step: 20, loss: 0.013682618737220764
step: 30, loss: 0.11044051498174667
step: 40, loss: 0.02397565171122551
step: 50, loss: 0.001429363852366805
step: 60, loss: 0.018579965457320213
step: 70, loss: 0.03446866571903229
step: 80, loss: 0.016571348533034325
step: 90, loss: 0.06640072166919708
step: 100, loss: 0.1032104641199112
step: 110, loss: 0.027772536501288414
step: 120, loss: 0.08469192683696747
step: 130, loss: 0.08290563523769379
step: 140, loss: 0.021996673196554184
step: 150, loss: 0.030182328075170517
step: 160, loss: 0.023052355274558067
step: 170, loss: 0.04113065078854561
step: 180, loss: 0.0013358767610043287
step: 190, loss: 0.010242697782814503
step: 200, loss: 0.0382465235888958
step: 210, loss: 0.012494913302361965
step: 220, loss: 0.02067793905735016
step: 230, loss: 0.022914117202162743
step: 240, loss: 0.15822733938694
step: 250, loss: 0.1254161298274994
step: 260, loss: 0.04365847632288933
step: 270, loss: 0.06188191473484039
step: 280, loss: 0.05954446271061897
step: 290, loss: 0.07564951479434967
step: 300, loss: 0.02638091705739498
step: 310, loss: 0.1407220959663391
step: 320, loss: 0.025878388434648514
step: 330, loss: 0.03061186894774437
step: 340, loss: 0.003699199529364705
step: 350, loss: 0.09438043087720871
step: 360, loss: 0.07574409991502762
epoch 15: dev_f1=0.7204030226700252, f1=0.7253333333333334, best_f1=0.7601078167115903
step: 0, loss: 0.03630544990301132
step: 10, loss: 0.01858152635395527
step: 20, loss: 0.027619928121566772
step: 30, loss: 0.046320706605911255
step: 40, loss: 0.023707319051027298
step: 50, loss: 0.02098695933818817
step: 60, loss: 0.013851244002580643
step: 70, loss: 0.07214662432670593
step: 80, loss: 0.0912482738494873
step: 90, loss: 0.08483927696943283
step: 100, loss: 0.011574530974030495
step: 110, loss: 0.03354084864258766
step: 120, loss: 0.030671583488583565
step: 130, loss: 0.013284709304571152
step: 140, loss: 0.053054362535476685
step: 150, loss: 0.10951357334852219
step: 160, loss: 0.01636688783764839
step: 170, loss: 0.0013807949144393206
step: 180, loss: 0.055151473730802536
step: 190, loss: 0.02550196275115013
step: 200, loss: 0.10443832725286484
step: 210, loss: 0.045080266892910004
step: 220, loss: 0.019070588052272797
step: 230, loss: 0.006193138193339109
step: 240, loss: 0.03150071203708649
step: 250, loss: 0.03026656247675419
step: 260, loss: 0.013845086097717285
step: 270, loss: 0.050022248178720474
step: 280, loss: 0.06376679241657257
step: 290, loss: 0.043278664350509644
step: 300, loss: 0.01921221613883972
step: 310, loss: 0.03974003717303276
step: 320, loss: 0.005974126514047384
step: 330, loss: 0.07998580485582352
step: 340, loss: 0.0015314535703510046
step: 350, loss: 0.1150444895029068
step: 360, loss: 0.07879548519849777
epoch 16: dev_f1=0.7053140096618358, f1=0.689119170984456, best_f1=0.7601078167115903
step: 0, loss: 0.06665670871734619
step: 10, loss: 0.051874227821826935
step: 20, loss: 0.17649133503437042
step: 30, loss: 0.015386554412543774
step: 40, loss: 0.05611790344119072
step: 50, loss: 0.02598053216934204
step: 60, loss: 0.01699385978281498
step: 70, loss: 0.06671474128961563
step: 80, loss: 0.1096600592136383
step: 90, loss: 0.04278425872325897
step: 100, loss: 0.08979856222867966
step: 110, loss: 0.06631694734096527
step: 120, loss: 0.023289676755666733
step: 130, loss: 0.06986135244369507
step: 140, loss: 0.15176711976528168
step: 150, loss: 0.03244373947381973
step: 160, loss: 0.051884911954402924
step: 170, loss: 0.04774165526032448
step: 180, loss: 0.02865912765264511
step: 190, loss: 0.030174048617482185
step: 200, loss: 0.07077889144420624
step: 210, loss: 0.060967568308115005
step: 220, loss: 0.017782438546419144
step: 230, loss: 0.002802202245220542
step: 240, loss: 0.06950979679822922
step: 250, loss: 0.0021183565258979797
step: 260, loss: 0.0626675933599472
step: 270, loss: 0.027692154049873352
step: 280, loss: 0.015986178070306778
step: 290, loss: 0.05487360805273056
step: 300, loss: 0.048002228140830994
step: 310, loss: 0.016342392191290855
step: 320, loss: 0.029066000133752823
step: 330, loss: 7.140662637539208e-05
step: 340, loss: 0.016294829547405243
step: 350, loss: 0.0015903743915259838
step: 360, loss: 0.033413659781217575
epoch 17: dev_f1=0.696103896103896, f1=0.7027027027027027, best_f1=0.7601078167115903
step: 0, loss: 0.0731121227145195
step: 10, loss: 0.052328579127788544
step: 20, loss: 0.030152181163430214
step: 30, loss: 0.030137840658426285
step: 40, loss: 0.049834609031677246
step: 50, loss: 0.03429514542222023
step: 60, loss: 0.012389636598527431
step: 70, loss: 0.025364819914102554
step: 80, loss: 0.03332427144050598
step: 90, loss: 0.04865962266921997
step: 100, loss: 0.021658718585968018
step: 110, loss: 0.06146962195634842
step: 120, loss: 0.020754700526595116
step: 130, loss: 0.019166691228747368
step: 140, loss: 0.00480901962146163
step: 150, loss: 0.06887179613113403
step: 160, loss: 0.0004911762662231922
step: 170, loss: 0.0424669049680233
step: 180, loss: 0.06565293669700623
step: 190, loss: 0.038882043212652206
step: 200, loss: 0.010481107980012894
step: 210, loss: 0.04149957373738289
step: 220, loss: 0.020149895921349525
step: 230, loss: 0.003927418030798435
step: 240, loss: 0.058276839554309845
step: 250, loss: 0.022506380453705788
step: 260, loss: 0.024650581181049347
step: 270, loss: 0.03286934271454811
step: 280, loss: 0.01100103184580803
step: 290, loss: 0.019677354022860527
step: 300, loss: 0.014236987568438053
step: 310, loss: 0.0002028882154263556
step: 320, loss: 0.031467363238334656
step: 330, loss: 0.08038031309843063
step: 340, loss: 0.03714032098650932
step: 350, loss: 0.07143451273441315
step: 360, loss: 0.07207021117210388
epoch 18: dev_f1=0.7107843137254902, f1=0.7095115681233932, best_f1=0.7601078167115903
step: 0, loss: 0.04667559266090393
step: 10, loss: 0.016977373510599136
step: 20, loss: 0.03456297144293785
step: 30, loss: 0.05180215835571289
step: 40, loss: 0.07853975892066956
step: 50, loss: 0.03360338509082794
step: 60, loss: 0.020183240994811058
step: 70, loss: 0.0006388885085470974
step: 80, loss: 9.537683217786252e-05
step: 90, loss: 0.09085866063833237
step: 100, loss: 0.07018357515335083
step: 110, loss: 0.03713623434305191
step: 120, loss: 0.014723284170031548
step: 130, loss: 0.061185117810964584
step: 140, loss: 0.03939475864171982
step: 150, loss: 0.03464208170771599
step: 160, loss: 0.0209890678524971
step: 170, loss: 0.05025196447968483
step: 180, loss: 0.09158884733915329
step: 190, loss: 0.051652103662490845
step: 200, loss: 0.03355807811021805
step: 210, loss: 0.04908674210309982
step: 220, loss: 0.011451780796051025
step: 230, loss: 0.051809631288051605
step: 240, loss: 0.0014602942392230034
step: 250, loss: 0.06516334414482117
step: 260, loss: 0.03365350514650345
step: 270, loss: 0.024432605132460594
step: 280, loss: 0.026599165052175522
step: 290, loss: 0.14012190699577332
step: 300, loss: 0.01044583972543478
step: 310, loss: 0.022428343072533607
step: 320, loss: 0.02713676169514656
step: 330, loss: 0.002202064963057637
step: 340, loss: 0.0021864143200218678
step: 350, loss: 0.002591467695310712
step: 360, loss: 0.06291106343269348
epoch 19: dev_f1=0.7047146401985112, f1=0.7031250000000001, best_f1=0.7601078167115903
step: 0, loss: 0.024927610531449318
step: 10, loss: 0.001342869596555829
step: 20, loss: 0.053320858627557755
step: 30, loss: 0.08194946497678757
step: 40, loss: 0.0020721894688904285
step: 50, loss: 0.0027909702621400356
step: 60, loss: 0.009654617868363857
step: 70, loss: 0.061712607741355896
step: 80, loss: 0.03135870769619942
step: 90, loss: 0.05678476393222809
step: 100, loss: 0.03173636645078659
step: 110, loss: 0.05862050503492355
step: 120, loss: 0.010826794430613518
step: 130, loss: 0.000317755009746179
step: 140, loss: 0.0024201571941375732
step: 150, loss: 0.090944804251194
step: 160, loss: 0.07887794822454453
step: 170, loss: 0.12236029654741287
step: 180, loss: 0.008134833537042141
step: 190, loss: 0.036417387425899506
step: 200, loss: 0.07587458193302155
step: 210, loss: 0.009074391797184944
step: 220, loss: 0.06598249077796936
step: 230, loss: 0.01374802365899086
step: 240, loss: 0.0271888617426157
step: 250, loss: 0.05947902798652649
step: 260, loss: 0.013678744435310364
step: 270, loss: 0.0031529846601188183
step: 280, loss: 4.01418874389492e-05
step: 290, loss: 0.010957634076476097
step: 300, loss: 0.012989884242415428
step: 310, loss: 0.06198161095380783
step: 320, loss: 0.07258883118629456
step: 330, loss: 0.0034732590429484844
step: 340, loss: 0.012443085201084614
step: 350, loss: 0.07799671590328217
step: 360, loss: 0.009850692003965378
epoch 20: dev_f1=0.6808510638297872, f1=0.6923076923076923, best_f1=0.7601078167115903
