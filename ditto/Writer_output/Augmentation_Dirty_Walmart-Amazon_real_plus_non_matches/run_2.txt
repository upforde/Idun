cuda
Device: cuda
step: 0, loss: 0.561151385307312
step: 10, loss: 0.47145792841911316
step: 20, loss: 0.08793094009160995
step: 30, loss: 0.13567928969860077
step: 40, loss: 0.15021288394927979
step: 50, loss: 0.14057721197605133
step: 60, loss: 0.14561066031455994
step: 70, loss: 0.04493814334273338
step: 80, loss: 0.37906715273857117
step: 90, loss: 0.2200947254896164
step: 100, loss: 0.45251479744911194
step: 110, loss: 0.13863743841648102
step: 120, loss: 0.13147546350955963
step: 130, loss: 0.13114048540592194
step: 140, loss: 0.1230286955833435
step: 150, loss: 0.22474683821201324
step: 160, loss: 0.11296466737985611
step: 170, loss: 0.1717512607574463
step: 180, loss: 0.10590871423482895
step: 190, loss: 0.02457866445183754
step: 200, loss: 0.20734240114688873
step: 210, loss: 0.11414585262537003
step: 220, loss: 0.17337971925735474
step: 230, loss: 0.09405612200498581
step: 240, loss: 0.0605013445019722
step: 250, loss: 0.1303536295890808
step: 260, loss: 0.2065289318561554
step: 270, loss: 0.09915340691804886
step: 280, loss: 0.1414363831281662
step: 290, loss: 0.5444462895393372
step: 300, loss: 0.10381388664245605
step: 310, loss: 0.310828298330307
step: 320, loss: 0.2166292816400528
step: 330, loss: 0.1687304973602295
step: 340, loss: 0.16669093072414398
step: 350, loss: 0.1377456784248352
step: 360, loss: 0.028859950602054596
epoch 1: dev_f1=0.5666666666666667, f1=0.5548387096774193, best_f1=0.5548387096774193
step: 0, loss: 0.17603671550750732
step: 10, loss: 0.163463294506073
step: 20, loss: 0.14787156879901886
step: 30, loss: 0.11311441659927368
step: 40, loss: 0.17982301115989685
step: 50, loss: 0.08875563740730286
step: 60, loss: 0.11104927211999893
step: 70, loss: 0.11085957288742065
step: 80, loss: 0.11794202774763107
step: 90, loss: 0.06264884769916534
step: 100, loss: 0.0553145632147789
step: 110, loss: 0.09670918434858322
step: 120, loss: 0.11093343049287796
step: 130, loss: 0.08967071771621704
step: 140, loss: 0.34962692856788635
step: 150, loss: 0.09063424170017242
step: 160, loss: 0.018563946709036827
step: 170, loss: 0.12537482380867004
step: 180, loss: 0.15288060903549194
step: 190, loss: 0.05436945706605911
step: 200, loss: 0.33123117685317993
step: 210, loss: 0.10119994729757309
step: 220, loss: 0.1127178817987442
step: 230, loss: 0.29400157928466797
step: 240, loss: 0.10746421664953232
step: 250, loss: 0.009169178083539009
step: 260, loss: 0.067566879093647
step: 270, loss: 0.10185174643993378
step: 280, loss: 0.08792150765657425
step: 290, loss: 0.19030369818210602
step: 300, loss: 0.17276521027088165
step: 310, loss: 0.26737040281295776
step: 320, loss: 0.023037094622850418
step: 330, loss: 0.09715266525745392
step: 340, loss: 0.03190537542104721
step: 350, loss: 0.11526942253112793
step: 360, loss: 0.050330132246017456
epoch 2: dev_f1=0.6596194503171248, f1=0.6722338204592901, best_f1=0.6722338204592901
step: 0, loss: 0.08384990692138672
step: 10, loss: 0.09637723118066788
step: 20, loss: 0.05601824074983597
step: 30, loss: 0.14259931445121765
step: 40, loss: 0.02657724916934967
step: 50, loss: 0.05792868882417679
step: 60, loss: 0.06658254563808441
step: 70, loss: 0.10294503718614578
step: 80, loss: 0.03524771332740784
step: 90, loss: 0.09754938632249832
step: 100, loss: 0.16746127605438232
step: 110, loss: 0.10401631891727448
step: 120, loss: 0.05816659703850746
step: 130, loss: 0.10304240137338638
step: 140, loss: 0.07843579351902008
step: 150, loss: 0.12179774045944214
step: 160, loss: 0.13042940199375153
step: 170, loss: 0.250661164522171
step: 180, loss: 0.13427814841270447
step: 190, loss: 0.09006059169769287
step: 200, loss: 0.06853538751602173
step: 210, loss: 0.0228906087577343
step: 220, loss: 0.11237683892250061
step: 230, loss: 0.04880991950631142
step: 240, loss: 0.09911683201789856
step: 250, loss: 0.07669307291507721
step: 260, loss: 0.2784613072872162
step: 270, loss: 0.01784714311361313
step: 280, loss: 0.07331234216690063
step: 290, loss: 0.23228968679904938
step: 300, loss: 0.1074201911687851
step: 310, loss: 0.04314475506544113
step: 320, loss: 0.07170797139406204
step: 330, loss: 0.15659455955028534
step: 340, loss: 0.14732666313648224
step: 350, loss: 0.08473985642194748
step: 360, loss: 0.20791523158550262
epoch 3: dev_f1=0.707774798927614, f1=0.7109974424552431, best_f1=0.7109974424552431
step: 0, loss: 0.3084694743156433
step: 10, loss: 0.1956370770931244
step: 20, loss: 0.22233110666275024
step: 30, loss: 0.010981885716319084
step: 40, loss: 0.1347745805978775
step: 50, loss: 0.09530633687973022
step: 60, loss: 0.14469392597675323
step: 70, loss: 0.07062291353940964
step: 80, loss: 0.11509488523006439
step: 90, loss: 0.07454485446214676
step: 100, loss: 0.1186080276966095
step: 110, loss: 0.11542738974094391
step: 120, loss: 0.07011275738477707
step: 130, loss: 0.09070771187543869
step: 140, loss: 0.05707015469670296
step: 150, loss: 0.08017493039369583
step: 160, loss: 0.043080735951662064
step: 170, loss: 0.08168544620275497
step: 180, loss: 0.09188996255397797
step: 190, loss: 0.2699962258338928
step: 200, loss: 0.10157396644353867
step: 210, loss: 0.05518056079745293
step: 220, loss: 0.07781840860843658
step: 230, loss: 0.042160652577877045
step: 240, loss: 0.08718476444482803
step: 250, loss: 0.09570319950580597
step: 260, loss: 0.04926088824868202
step: 270, loss: 0.08935242891311646
step: 280, loss: 0.04675432667136192
step: 290, loss: 0.08306679129600525
step: 300, loss: 0.03360654041171074
step: 310, loss: 0.03917843848466873
step: 320, loss: 0.04877477139234543
step: 330, loss: 0.1024278849363327
step: 340, loss: 0.17637941241264343
step: 350, loss: 0.059893038123846054
step: 360, loss: 0.12261459231376648
epoch 4: dev_f1=0.7352185089974292, f1=0.7189873417721518, best_f1=0.7189873417721518
step: 0, loss: 0.07796978205442429
step: 10, loss: 0.0632234439253807
step: 20, loss: 0.11277750879526138
step: 30, loss: 0.10307184606790543
step: 40, loss: 0.12048453092575073
step: 50, loss: 0.0819774717092514
step: 60, loss: 0.19505129754543304
step: 70, loss: 0.03899667039513588
step: 80, loss: 0.12243445962667465
step: 90, loss: 0.06327042728662491
step: 100, loss: 0.039048340171575546
step: 110, loss: 0.024474600329995155
step: 120, loss: 0.0006741636316291988
step: 130, loss: 0.07384979724884033
step: 140, loss: 0.06779739260673523
step: 150, loss: 0.15649665892124176
step: 160, loss: 0.17247100174427032
step: 170, loss: 0.10515432804822922
step: 180, loss: 0.10584099590778351
step: 190, loss: 0.09825113415718079
step: 200, loss: 0.05835219845175743
step: 210, loss: 0.16151395440101624
step: 220, loss: 0.016935376450419426
step: 230, loss: 0.0992313101887703
step: 240, loss: 0.06370425224304199
step: 250, loss: 0.15392492711544037
step: 260, loss: 0.044572990387678146
step: 270, loss: 0.1313076615333557
step: 280, loss: 0.07177911698818207
step: 290, loss: 0.0824272409081459
step: 300, loss: 0.19560959935188293
step: 310, loss: 0.08930643647909164
step: 320, loss: 0.05369345098733902
step: 330, loss: 0.07455319166183472
step: 340, loss: 0.09804078191518784
step: 350, loss: 0.08494642376899719
step: 360, loss: 0.10571758449077606
epoch 5: dev_f1=0.7363420427553444, f1=0.7027027027027027, best_f1=0.7027027027027027
step: 0, loss: 0.026565006002783775
step: 10, loss: 0.058925561606884
step: 20, loss: 0.06927717477083206
step: 30, loss: 0.10957218706607819
step: 40, loss: 0.15239068865776062
step: 50, loss: 0.10150988399982452
step: 60, loss: 0.09860540926456451
step: 70, loss: 0.08512365072965622
step: 80, loss: 0.08963073790073395
step: 90, loss: 0.05310424044728279
step: 100, loss: 0.09340421110391617
step: 110, loss: 0.0274590365588665
step: 120, loss: 0.07454570382833481
step: 130, loss: 0.07216061651706696
step: 140, loss: 0.12702567875385284
step: 150, loss: 0.1088254302740097
step: 160, loss: 0.21859095990657806
step: 170, loss: 0.065288245677948
step: 180, loss: 0.1240408718585968
step: 190, loss: 0.12888403236865997
step: 200, loss: 0.12564082443714142
step: 210, loss: 0.18972769379615784
step: 220, loss: 0.012211157940328121
step: 230, loss: 0.1373748481273651
step: 240, loss: 0.08406753093004227
step: 250, loss: 0.1282990574836731
step: 260, loss: 0.022715337574481964
step: 270, loss: 0.08393730223178864
step: 280, loss: 0.03672846034169197
step: 290, loss: 0.16055001318454742
step: 300, loss: 0.08909118175506592
step: 310, loss: 0.12228795140981674
step: 320, loss: 0.13471557199954987
step: 330, loss: 0.0539143905043602
step: 340, loss: 0.05443008616566658
step: 350, loss: 0.052957482635974884
step: 360, loss: 0.07976215332746506
epoch 6: dev_f1=0.7263922518159805, f1=0.6859903381642513, best_f1=0.7027027027027027
step: 0, loss: 0.06115712225437164
step: 10, loss: 0.20781899988651276
step: 20, loss: 0.11618856340646744
step: 30, loss: 0.09527289867401123
step: 40, loss: 0.10763691365718842
step: 50, loss: 0.1946476399898529
step: 60, loss: 0.06284759193658829
step: 70, loss: 0.07902764528989792
step: 80, loss: 0.08115415275096893
step: 90, loss: 0.13862912356853485
step: 100, loss: 0.33760982751846313
step: 110, loss: 0.09975036233663559
step: 120, loss: 0.0976528525352478
step: 130, loss: 0.12577766180038452
step: 140, loss: 0.04128827527165413
step: 150, loss: 0.036469731479883194
step: 160, loss: 0.03588704764842987
step: 170, loss: 0.059680718928575516
step: 180, loss: 0.010993591509759426
step: 190, loss: 0.09429845958948135
step: 200, loss: 0.08286970108747482
step: 210, loss: 0.10562897473573685
step: 220, loss: 0.0628470629453659
step: 230, loss: 0.07639598101377487
step: 240, loss: 0.1337449699640274
step: 250, loss: 0.12337396293878555
step: 260, loss: 0.03526103496551514
step: 270, loss: 0.0341494046151638
step: 280, loss: 0.05928902328014374
step: 290, loss: 0.12625443935394287
step: 300, loss: 0.10266906023025513
step: 310, loss: 0.16202537715435028
step: 320, loss: 0.07101055234670639
step: 330, loss: 0.06290126591920853
step: 340, loss: 0.10823319107294083
step: 350, loss: 0.07991805672645569
step: 360, loss: 0.07927139848470688
epoch 7: dev_f1=0.7170731707317073, f1=0.7209876543209877, best_f1=0.7027027027027027
step: 0, loss: 0.03273122385144234
step: 10, loss: 0.11346353590488434
step: 20, loss: 0.023771528154611588
step: 30, loss: 0.07655744254589081
step: 40, loss: 0.03289029747247696
step: 50, loss: 0.019609615206718445
step: 60, loss: 0.010630992241203785
step: 70, loss: 0.06111626699566841
step: 80, loss: 0.04319151118397713
step: 90, loss: 0.013454513624310493
step: 100, loss: 0.04545946791768074
step: 110, loss: 0.02161422185599804
step: 120, loss: 0.09209877997636795
step: 130, loss: 0.0368788056075573
step: 140, loss: 0.07223425060510635
step: 150, loss: 0.06232556700706482
step: 160, loss: 0.14982540905475616
step: 170, loss: 0.03621605783700943
step: 180, loss: 0.11316831409931183
step: 190, loss: 0.11606208235025406
step: 200, loss: 0.1547144055366516
step: 210, loss: 0.046740707010030746
step: 220, loss: 0.07078900933265686
step: 230, loss: 0.004358053207397461
step: 240, loss: 0.042352963238954544
step: 250, loss: 0.03413056954741478
step: 260, loss: 0.08603207021951675
step: 270, loss: 0.05839250236749649
step: 280, loss: 0.04336908832192421
step: 290, loss: 0.09651482105255127
step: 300, loss: 0.014676661230623722
step: 310, loss: 0.07069592922925949
step: 320, loss: 0.05588509142398834
step: 330, loss: 0.11347079277038574
step: 340, loss: 0.08872273564338684
step: 350, loss: 0.13348202407360077
step: 360, loss: 0.05151604488492012
epoch 8: dev_f1=0.75177304964539, f1=0.7113163972286375, best_f1=0.7113163972286375
step: 0, loss: 0.01654500886797905
step: 10, loss: 0.0028570452705025673
step: 20, loss: 0.06527139991521835
step: 30, loss: 0.0657675489783287
step: 40, loss: 0.004038644954562187
step: 50, loss: 0.2302148938179016
step: 60, loss: 0.07350802421569824
step: 70, loss: 0.07107977569103241
step: 80, loss: 0.07022682577371597
step: 90, loss: 0.0871356725692749
step: 100, loss: 0.12411722540855408
step: 110, loss: 0.06317619234323502
step: 120, loss: 0.07751515507698059
step: 130, loss: 0.1352815330028534
step: 140, loss: 0.03922425955533981
step: 150, loss: 0.08803954720497131
step: 160, loss: 0.10695625841617584
step: 170, loss: 0.06525910645723343
step: 180, loss: 0.09969370812177658
step: 190, loss: 0.07116692513227463
step: 200, loss: 0.14139586687088013
step: 210, loss: 0.01846933178603649
step: 220, loss: 0.08773254603147507
step: 230, loss: 0.038646433502435684
step: 240, loss: 0.09051015228033066
step: 250, loss: 0.09068147838115692
step: 260, loss: 0.06839347630739212
step: 270, loss: 0.16843459010124207
step: 280, loss: 0.09844505041837692
step: 290, loss: 0.03719520568847656
step: 300, loss: 0.072426937520504
step: 310, loss: 0.03057168982923031
step: 320, loss: 0.038268979638814926
step: 330, loss: 0.09833046793937683
step: 340, loss: 0.10804618895053864
step: 350, loss: 0.04583819583058357
step: 360, loss: 0.035818394273519516
epoch 9: dev_f1=0.7378640776699029, f1=0.708433734939759, best_f1=0.7113163972286375
step: 0, loss: 0.06652730703353882
step: 10, loss: 0.06791911274194717
step: 20, loss: 0.07255323976278305
step: 30, loss: 0.09663037210702896
step: 40, loss: 0.033031679689884186
step: 50, loss: 0.04338206350803375
step: 60, loss: 0.07677844911813736
step: 70, loss: 0.03169644623994827
step: 80, loss: 0.19097676873207092
step: 90, loss: 0.07005840539932251
step: 100, loss: 0.06457288563251495
step: 110, loss: 0.034711696207523346
step: 120, loss: 0.05844101682305336
step: 130, loss: 0.05485295131802559
step: 140, loss: 0.07735506445169449
step: 150, loss: 0.07178376615047455
step: 160, loss: 0.013700166717171669
step: 170, loss: 0.00895786751061678
step: 180, loss: 0.04195669665932655
step: 190, loss: 0.09854909777641296
step: 200, loss: 0.01338251680135727
step: 210, loss: 0.08688797801733017
step: 220, loss: 0.07376924157142639
step: 230, loss: 0.03091125376522541
step: 240, loss: 0.059878673404455185
step: 250, loss: 0.0545928031206131
step: 260, loss: 0.06282705813646317
step: 270, loss: 0.043707434087991714
step: 280, loss: 0.07736928015947342
step: 290, loss: 0.026476336643099785
step: 300, loss: 0.08783300966024399
step: 310, loss: 0.06674142926931381
step: 320, loss: 0.0578925758600235
step: 330, loss: 0.0832931250333786
step: 340, loss: 0.08050702512264252
step: 350, loss: 0.01362593937665224
step: 360, loss: 0.06705524027347565
epoch 10: dev_f1=0.7455919395465995, f1=0.7139240506329113, best_f1=0.7113163972286375
step: 0, loss: 0.022662730887532234
step: 10, loss: 0.08346012979745865
step: 20, loss: 0.0336119681596756
step: 30, loss: 0.09557081758975983
step: 40, loss: 0.22590892016887665
step: 50, loss: 0.05669894069433212
step: 60, loss: 0.019875528290867805
step: 70, loss: 0.05544877052307129
step: 80, loss: 0.03402871638536453
step: 90, loss: 0.023290487006306648
step: 100, loss: 0.045196812599897385
step: 110, loss: 0.024676796048879623
step: 120, loss: 0.026773225516080856
step: 130, loss: 0.007456940598785877
step: 140, loss: 0.028285225853323936
step: 150, loss: 0.0277017243206501
step: 160, loss: 0.013071169145405293
step: 170, loss: 0.09106449782848358
step: 180, loss: 0.08014995604753494
step: 190, loss: 0.04704543203115463
step: 200, loss: 0.04815240576863289
step: 210, loss: 0.112483449280262
step: 220, loss: 0.0025026111397892237
step: 230, loss: 0.1503543108701706
step: 240, loss: 0.09210149198770523
step: 250, loss: 0.10020836442708969
step: 260, loss: 0.06350740045309067
step: 270, loss: 0.023483317345380783
step: 280, loss: 0.08051886409521103
step: 290, loss: 0.0385935977101326
step: 300, loss: 0.03769542649388313
step: 310, loss: 0.10509209334850311
step: 320, loss: 0.14085476100444794
step: 330, loss: 0.03749992698431015
step: 340, loss: 0.04368044435977936
step: 350, loss: 0.02685459703207016
step: 360, loss: 0.16716034710407257
epoch 11: dev_f1=0.7090464547677262, f1=0.7041564792176039, best_f1=0.7113163972286375
step: 0, loss: 0.0764039158821106
step: 10, loss: 0.07782380282878876
step: 20, loss: 0.02939220704138279
step: 30, loss: 0.03219335898756981
step: 40, loss: 0.03573361039161682
step: 50, loss: 0.012960933148860931
step: 60, loss: 0.09799830615520477
step: 70, loss: 0.06479920446872711
step: 80, loss: 0.07059292495250702
step: 90, loss: 0.1280553936958313
step: 100, loss: 0.032203029841184616
step: 110, loss: 0.05766943842172623
step: 120, loss: 0.041849080473184586
step: 130, loss: 0.01569455675780773
step: 140, loss: 0.1033233106136322
step: 150, loss: 0.05119619145989418
step: 160, loss: 0.06830453872680664
step: 170, loss: 0.09862032532691956
step: 180, loss: 0.0010034715523943305
step: 190, loss: 0.04388291761279106
step: 200, loss: 0.03974003717303276
step: 210, loss: 0.0719163715839386
step: 220, loss: 0.020413128659129143
step: 230, loss: 0.04906688258051872
step: 240, loss: 0.06333652138710022
step: 250, loss: 0.03111913800239563
step: 260, loss: 0.06724736839532852
step: 270, loss: 0.06435082852840424
step: 280, loss: 0.05263670161366463
step: 290, loss: 0.11954928934574127
step: 300, loss: 0.041152093559503555
step: 310, loss: 0.17858508229255676
step: 320, loss: 0.07145202904939651
step: 330, loss: 0.0407661609351635
step: 340, loss: 0.030793974176049232
step: 350, loss: 0.09655538201332092
step: 360, loss: 0.020246759057044983
epoch 12: dev_f1=0.7365591397849462, f1=0.6906077348066297, best_f1=0.7113163972286375
step: 0, loss: 0.1455879658460617
step: 10, loss: 0.05903362110257149
step: 20, loss: 0.02594095468521118
step: 30, loss: 0.0005671399994753301
step: 40, loss: 0.008566092699766159
step: 50, loss: 0.017178764566779137
step: 60, loss: 0.04424762725830078
step: 70, loss: 0.054680418223142624
step: 80, loss: 0.0761248916387558
step: 90, loss: 0.07767942547798157
step: 100, loss: 0.08239129185676575
step: 110, loss: 0.00783535372465849
step: 120, loss: 0.07430990040302277
step: 130, loss: 0.06695542484521866
step: 140, loss: 0.11430700868368149
step: 150, loss: 0.042261406779289246
step: 160, loss: 0.08284150809049606
step: 170, loss: 0.13386011123657227
step: 180, loss: 0.04280149191617966
step: 190, loss: 0.03632142394781113
step: 200, loss: 0.043025750666856766
step: 210, loss: 0.09217457473278046
step: 220, loss: 0.031238559633493423
step: 230, loss: 0.006379289552569389
step: 240, loss: 0.02539810724556446
step: 250, loss: 0.0011683411430567503
step: 260, loss: 0.1456751823425293
step: 270, loss: 0.09450212121009827
step: 280, loss: 0.08042199164628983
step: 290, loss: 0.04001650586724281
step: 300, loss: 0.057759009301662445
step: 310, loss: 0.011173446662724018
step: 320, loss: 0.06351320445537567
step: 330, loss: 0.08071967214345932
step: 340, loss: 0.002176061738282442
step: 350, loss: 0.09292531758546829
step: 360, loss: 0.1988140195608139
epoch 13: dev_f1=0.744186046511628, f1=0.7214854111405835, best_f1=0.7113163972286375
step: 0, loss: 0.03725956752896309
step: 10, loss: 0.014658371917903423
step: 20, loss: 0.035568613559007645
step: 30, loss: 0.07535690069198608
step: 40, loss: 0.016091996803879738
step: 50, loss: 0.0010871200356632471
step: 60, loss: 0.0638757050037384
step: 70, loss: 0.13920177519321442
step: 80, loss: 0.038215767592191696
step: 90, loss: 0.009407475590705872
step: 100, loss: 0.07424741983413696
step: 110, loss: 0.049817636609077454
step: 120, loss: 0.05862558260560036
step: 130, loss: 0.020439883694052696
step: 140, loss: 5.2744904678547755e-05
step: 150, loss: 0.006408851593732834
step: 160, loss: 0.03888818621635437
step: 170, loss: 0.13322420418262482
step: 180, loss: 0.2621748149394989
step: 190, loss: 0.09467212110757828
step: 200, loss: 0.10988341271877289
step: 210, loss: 0.09477346390485764
step: 220, loss: 0.040094681084156036
step: 230, loss: 0.07724234461784363
step: 240, loss: 0.09441675245761871
step: 250, loss: 0.07958447188138962
step: 260, loss: 0.006600973661988974
step: 270, loss: 0.03858156502246857
step: 280, loss: 0.04703449457883835
step: 290, loss: 0.037321168929338455
step: 300, loss: 0.047522664070129395
step: 310, loss: 0.00039245677180588245
step: 320, loss: 0.034310098737478256
step: 330, loss: 0.06810904294252396
step: 340, loss: 0.06826729327440262
step: 350, loss: 0.03956330567598343
step: 360, loss: 0.026302790269255638
epoch 14: dev_f1=0.7074829931972788, f1=0.7123287671232876, best_f1=0.7113163972286375
step: 0, loss: 0.07906156033277512
step: 10, loss: 0.030340051278471947
step: 20, loss: 0.1643068492412567
step: 30, loss: 0.05677972361445427
step: 40, loss: 0.09715111553668976
step: 50, loss: 0.0212706346064806
step: 60, loss: 0.04546680673956871
step: 70, loss: 0.020766405388712883
step: 80, loss: 0.07778557389974594
step: 90, loss: 0.03030216135084629
step: 100, loss: 0.0007292850059457123
step: 110, loss: 0.08311719447374344
step: 120, loss: 0.06360501796007156
step: 130, loss: 0.03427448123693466
step: 140, loss: 0.00014375361206475645
step: 150, loss: 0.0720888078212738
step: 160, loss: 0.05382950231432915
step: 170, loss: 0.015092135407030582
step: 180, loss: 0.10705380886793137
step: 190, loss: 0.07154087722301483
step: 200, loss: 0.035615112632513046
step: 210, loss: 0.08086193352937698
step: 220, loss: 0.0015183660434558988
step: 230, loss: 0.03002559021115303
step: 240, loss: 0.010132531635463238
step: 250, loss: 0.07414527982473373
step: 260, loss: 0.047659341245889664
step: 270, loss: 0.026194337755441666
step: 280, loss: 0.14803798496723175
step: 290, loss: 0.046519067138433456
step: 300, loss: 0.03632262721657753
step: 310, loss: 0.012339902110397816
step: 320, loss: 0.02353409305214882
step: 330, loss: 0.030051523819565773
step: 340, loss: 0.05283452197909355
step: 350, loss: 0.05118018388748169
step: 360, loss: 0.04959381744265556
epoch 15: dev_f1=0.6920980926430518, f1=0.717391304347826, best_f1=0.7113163972286375
step: 0, loss: 0.06549343466758728
step: 10, loss: 0.043283961713314056
step: 20, loss: 0.059739235788583755
step: 30, loss: 0.02865281142294407
step: 40, loss: 0.007653535809367895
step: 50, loss: 0.003741129767149687
step: 60, loss: 0.029333950951695442
step: 70, loss: 0.044384777545928955
step: 80, loss: 0.000263532274402678
step: 90, loss: 0.044519733637571335
step: 100, loss: 0.06753874570131302
step: 110, loss: 0.1733037382364273
step: 120, loss: 0.029733791947364807
step: 130, loss: 0.0043990155681967735
step: 140, loss: 0.059944622218608856
step: 150, loss: 0.012204357422888279
step: 160, loss: 0.01621098816394806
step: 170, loss: 0.008549551479518414
step: 180, loss: 0.13809552788734436
step: 190, loss: 0.018811305984854698
step: 200, loss: 0.00985020399093628
step: 210, loss: 0.1275143325328827
step: 220, loss: 0.012351282872259617
step: 230, loss: 0.01576007716357708
step: 240, loss: 0.04475691542029381
step: 250, loss: 0.023547042161226273
step: 260, loss: 0.006852701772004366
step: 270, loss: 0.14559775590896606
step: 280, loss: 0.07738193869590759
step: 290, loss: 0.06906561553478241
step: 300, loss: 0.08897215127944946
step: 310, loss: 0.04569464921951294
step: 320, loss: 0.035150978714227676
step: 330, loss: 0.06896582245826721
step: 340, loss: 0.052002642303705215
step: 350, loss: 0.0795058086514473
step: 360, loss: 0.06688423454761505
epoch 16: dev_f1=0.7150259067357513, f1=0.7116883116883116, best_f1=0.7113163972286375
step: 0, loss: 0.06320517510175705
step: 10, loss: 0.016907477751374245
step: 20, loss: 0.07708779722452164
step: 30, loss: 0.07810384035110474
step: 40, loss: 0.016903094947338104
step: 50, loss: 0.004260231740772724
step: 60, loss: 0.02151673473417759
step: 70, loss: 0.0631532147526741
step: 80, loss: 0.004215282388031483
step: 90, loss: 0.024583755061030388
step: 100, loss: 0.1033160388469696
step: 110, loss: 0.019757116213440895
step: 120, loss: 0.037152595818042755
step: 130, loss: 0.04269383102655411
step: 140, loss: 0.02786373160779476
step: 150, loss: 0.02533334493637085
step: 160, loss: 0.023565951734781265
step: 170, loss: 0.08477053791284561
step: 180, loss: 0.014842650853097439
step: 190, loss: 0.12461142241954803
step: 200, loss: 0.010724043473601341
step: 210, loss: 0.11588750034570694
step: 220, loss: 0.0020467808935791254
step: 230, loss: 0.041590798646211624
step: 240, loss: 0.010990620590746403
step: 250, loss: 0.0491187609732151
step: 260, loss: 0.02127484790980816
step: 270, loss: 0.06805573403835297
step: 280, loss: 0.05490991473197937
step: 290, loss: 0.05547471344470978
step: 300, loss: 0.030420642346143723
step: 310, loss: 0.010400056838989258
step: 320, loss: 0.02508770301938057
step: 330, loss: 0.005217608995735645
step: 340, loss: 0.11106904596090317
step: 350, loss: 0.06030582636594772
step: 360, loss: 0.140236496925354
epoch 17: dev_f1=0.7389162561576355, f1=0.7245657568238213, best_f1=0.7113163972286375
step: 0, loss: 0.06888899952173233
step: 10, loss: 0.01206875778734684
step: 20, loss: 0.02102048695087433
step: 30, loss: 0.04815605282783508
step: 40, loss: 0.006266712211072445
step: 50, loss: 0.05239684879779816
step: 60, loss: 0.08015067875385284
step: 70, loss: 0.01157825905829668
step: 80, loss: 0.0220811627805233
step: 90, loss: 0.026456177234649658
step: 100, loss: 0.03057059831917286
step: 110, loss: 0.06686421483755112
step: 120, loss: 0.125419482588768
step: 130, loss: 0.06194043532013893
step: 140, loss: 0.03570709750056267
step: 150, loss: 0.049640920013189316
step: 160, loss: 0.1309046596288681
step: 170, loss: 0.027349846437573433
step: 180, loss: 2.6705785785452463e-05
step: 190, loss: 0.08456781506538391
step: 200, loss: 0.004801460541784763
step: 210, loss: 0.02706378884613514
step: 220, loss: 0.04532483592629433
step: 230, loss: 0.013291810639202595
step: 240, loss: 0.022067705169320107
step: 250, loss: 0.015781082212924957
step: 260, loss: 0.04685990512371063
step: 270, loss: 0.04803881794214249
step: 280, loss: 0.1571732461452484
step: 290, loss: 0.10607095062732697
step: 300, loss: 0.06325757503509521
step: 310, loss: 0.028705397620797157
step: 320, loss: 0.020640738308429718
step: 330, loss: 0.031323179602622986
step: 340, loss: 0.005544944666326046
step: 350, loss: 0.018766503781080246
step: 360, loss: 0.002423047088086605
epoch 18: dev_f1=0.7105263157894737, f1=0.7096774193548386, best_f1=0.7113163972286375
step: 0, loss: 0.01798016019165516
step: 10, loss: 0.0034639325458556414
step: 20, loss: 0.08936697244644165
step: 30, loss: 0.03635812923312187
step: 40, loss: 0.054295845329761505
step: 50, loss: 0.023570775985717773
step: 60, loss: 2.909718568844255e-05
step: 70, loss: 0.07296139001846313
step: 80, loss: 0.03614212945103645
step: 90, loss: 0.018086880445480347
step: 100, loss: 0.07970832288265228
step: 110, loss: 0.003416844177991152
step: 120, loss: 0.08179548382759094
step: 130, loss: 0.04909732565283775
step: 140, loss: 0.03190165013074875
step: 150, loss: 0.07413274049758911
step: 160, loss: 0.07134094834327698
step: 170, loss: 0.039241962134838104
step: 180, loss: 0.02049056626856327
step: 190, loss: 0.07142274081707001
step: 200, loss: 0.09119755774736404
step: 210, loss: 0.04642592743039131
step: 220, loss: 0.010180935263633728
step: 230, loss: 0.028489956632256508
step: 240, loss: 0.02527003362774849
step: 250, loss: 0.020719066262245178
step: 260, loss: 0.018293319270014763
step: 270, loss: 0.09565425664186478
step: 280, loss: 0.03598551079630852
step: 290, loss: 1.6148977010743693e-05
step: 300, loss: 0.019243812188506126
step: 310, loss: 0.02111106365919113
step: 320, loss: 0.04088080674409866
step: 330, loss: 0.0324288085103035
step: 340, loss: 0.03605756536126137
step: 350, loss: 0.04011014103889465
step: 360, loss: 0.046717144548892975
epoch 19: dev_f1=0.7027027027027027, f1=0.6939890710382514, best_f1=0.7113163972286375
step: 0, loss: 0.06723868101835251
step: 10, loss: 0.02486969716846943
step: 20, loss: 0.026579201221466064
step: 30, loss: 0.027309942990541458
step: 40, loss: 0.06453090906143188
step: 50, loss: 0.0005124429007992148
step: 60, loss: 0.014395302161574364
step: 70, loss: 0.011365699581801891
step: 80, loss: 0.033546123653650284
step: 90, loss: 0.045469485223293304
step: 100, loss: 0.050684768706560135
step: 110, loss: 0.051928095519542694
step: 120, loss: 0.13522623479366302
step: 130, loss: 0.011904126033186913
step: 140, loss: 0.01693619415163994
step: 150, loss: 0.08915542811155319
step: 160, loss: 0.031185735017061234
step: 170, loss: 0.03222737833857536
step: 180, loss: 0.11322102695703506
step: 190, loss: 0.026986557990312576
step: 200, loss: 0.0010934558231383562
step: 210, loss: 0.0773957222700119
step: 220, loss: 0.010835958644747734
step: 230, loss: 0.04293612018227577
step: 240, loss: 0.0007064442615956068
step: 250, loss: 0.04117739573121071
step: 260, loss: 0.03186705708503723
step: 270, loss: 0.0328788235783577
step: 280, loss: 0.12297800928354263
step: 290, loss: 0.011348886415362358
step: 300, loss: 0.01799839362502098
step: 310, loss: 0.019143715500831604
step: 320, loss: 0.03412588685750961
step: 330, loss: 0.07568109035491943
step: 340, loss: 0.07275774329900742
step: 350, loss: 0.025850145146250725
step: 360, loss: 0.0033545326441526413
epoch 20: dev_f1=0.6975476839237057, f1=0.6885245901639343, best_f1=0.7113163972286375
