cuda
Device: cuda
step: 0, loss: 0.7113456726074219
step: 10, loss: 0.30945074558258057
step: 20, loss: 0.3599419891834259
step: 30, loss: 0.2367696762084961
step: 40, loss: 0.13806088268756866
step: 50, loss: 0.400384783744812
step: 60, loss: 0.3862459361553192
step: 70, loss: 0.13833625614643097
step: 80, loss: 0.0601671040058136
step: 90, loss: 0.31257888674736023
step: 100, loss: 0.14550361037254333
step: 110, loss: 0.15759964287281036
step: 120, loss: 0.21871471405029297
step: 130, loss: 0.06951555609703064
step: 140, loss: 0.15162396430969238
step: 150, loss: 0.2724059224128723
step: 160, loss: 0.17364050447940826
step: 170, loss: 0.2573402225971222
step: 180, loss: 0.06966560333967209
step: 190, loss: 0.08920243382453918
step: 200, loss: 0.22461912035942078
step: 210, loss: 0.3365268409252167
step: 220, loss: 0.08907385915517807
step: 230, loss: 0.14526081085205078
step: 240, loss: 0.16109882295131683
step: 250, loss: 0.3181137144565582
step: 260, loss: 0.09321665018796921
step: 270, loss: 0.0947994813323021
step: 280, loss: 0.01783197745680809
step: 290, loss: 0.03825926035642624
step: 300, loss: 0.04079578071832657
step: 310, loss: 0.1662682145833969
step: 320, loss: 0.2017011046409607
step: 330, loss: 0.1092735230922699
step: 340, loss: 0.12343745678663254
step: 350, loss: 0.1008133590221405
step: 360, loss: 0.09137747436761856
epoch 1: dev_f1=0.5955056179775281, f1=0.6178861788617885, best_f1=0.6178861788617885
step: 0, loss: 0.24339202046394348
step: 10, loss: 0.03458912670612335
step: 20, loss: 0.11482681334018707
step: 30, loss: 0.15274430811405182
step: 40, loss: 0.04665994271636009
step: 50, loss: 0.07884275168180466
step: 60, loss: 0.08410624414682388
step: 70, loss: 0.10727764666080475
step: 80, loss: 0.18411999940872192
step: 90, loss: 0.21714456379413605
step: 100, loss: 0.08534079790115356
step: 110, loss: 0.15381211042404175
step: 120, loss: 0.035483647137880325
step: 130, loss: 0.0953049510717392
step: 140, loss: 0.17492391169071198
step: 150, loss: 0.18310663104057312
step: 160, loss: 0.01343866903334856
step: 170, loss: 0.21618440747261047
step: 180, loss: 0.08419940620660782
step: 190, loss: 0.03734970837831497
step: 200, loss: 0.11104772984981537
step: 210, loss: 0.3439731299877167
step: 220, loss: 0.09854614734649658
step: 230, loss: 0.1492961049079895
step: 240, loss: 0.0668097585439682
step: 250, loss: 0.35553839802742004
step: 260, loss: 0.1060870960354805
step: 270, loss: 0.10861451178789139
step: 280, loss: 0.14041565358638763
step: 290, loss: 0.16150476038455963
step: 300, loss: 0.14927655458450317
step: 310, loss: 0.03244062513113022
step: 320, loss: 0.06517290323972702
step: 330, loss: 0.2878325879573822
step: 340, loss: 0.1603461503982544
step: 350, loss: 0.0800824910402298
step: 360, loss: 0.08006195724010468
epoch 2: dev_f1=0.6717171717171717, f1=0.694300518134715, best_f1=0.694300518134715
step: 0, loss: 0.09356188774108887
step: 10, loss: 0.2028486728668213
step: 20, loss: 0.21246302127838135
step: 30, loss: 0.19488252699375153
step: 40, loss: 0.12049971520900726
step: 50, loss: 0.1569279581308365
step: 60, loss: 0.14220866560935974
step: 70, loss: 0.13000071048736572
step: 80, loss: 0.12603378295898438
step: 90, loss: 0.10764119029045105
step: 100, loss: 0.10060989111661911
step: 110, loss: 0.08177357912063599
step: 120, loss: 0.042932841926813126
step: 130, loss: 0.12593644857406616
step: 140, loss: 0.05320063233375549
step: 150, loss: 0.14715731143951416
step: 160, loss: 0.09931393712759018
step: 170, loss: 0.04044605419039726
step: 180, loss: 0.10585365444421768
step: 190, loss: 0.0339573472738266
step: 200, loss: 0.11914367973804474
step: 210, loss: 0.022652210667729378
step: 220, loss: 0.1471758335828781
step: 230, loss: 0.07767697423696518
step: 240, loss: 0.14746415615081787
step: 250, loss: 0.11724980920553207
step: 260, loss: 0.010207516141235828
step: 270, loss: 0.20251856744289398
step: 280, loss: 0.08406469225883484
step: 290, loss: 0.08420497924089432
step: 300, loss: 0.1879613697528839
step: 310, loss: 0.234045147895813
step: 320, loss: 0.0765548050403595
step: 330, loss: 0.11315368860960007
step: 340, loss: 0.1497061401605606
step: 350, loss: 0.2472120076417923
step: 360, loss: 0.07540260255336761
epoch 3: dev_f1=0.7479674796747967, f1=0.6975476839237057, best_f1=0.6975476839237057
step: 0, loss: 0.1076277419924736
step: 10, loss: 0.10892627388238907
step: 20, loss: 0.1118960753083229
step: 30, loss: 0.040709078311920166
step: 40, loss: 0.1356959044933319
step: 50, loss: 0.07016733288764954
step: 60, loss: 0.20775219798088074
step: 70, loss: 0.010194766335189342
step: 80, loss: 0.0766240581870079
step: 90, loss: 0.08323555439710617
step: 100, loss: 0.14208486676216125
step: 110, loss: 0.16910411417484283
step: 120, loss: 0.041970521211624146
step: 130, loss: 0.11092548072338104
step: 140, loss: 0.053065426647663116
step: 150, loss: 0.17005187273025513
step: 160, loss: 0.03832302615046501
step: 170, loss: 0.2069402039051056
step: 180, loss: 0.17022638022899628
step: 190, loss: 0.03616869077086449
step: 200, loss: 0.0572991743683815
step: 210, loss: 0.0686972588300705
step: 220, loss: 0.20722860097885132
step: 230, loss: 0.11725042760372162
step: 240, loss: 0.08886148780584335
step: 250, loss: 0.04959176108241081
step: 260, loss: 0.08933661878108978
step: 270, loss: 0.08298644423484802
step: 280, loss: 0.050924886018037796
step: 290, loss: 0.1243017315864563
step: 300, loss: 0.17614547908306122
step: 310, loss: 0.04930833354592323
step: 320, loss: 0.07751086354255676
step: 330, loss: 0.030668361112475395
step: 340, loss: 0.13339269161224365
step: 350, loss: 0.016881100833415985
step: 360, loss: 0.02577042765915394
epoch 4: dev_f1=0.6916890080428955, f1=0.6721311475409837, best_f1=0.6975476839237057
step: 0, loss: 0.09552036970853806
step: 10, loss: 0.046893831342458725
step: 20, loss: 0.14451880753040314
step: 30, loss: 0.08964316546916962
step: 40, loss: 0.010921075008809566
step: 50, loss: 0.14063291251659393
step: 60, loss: 0.09153547883033752
step: 70, loss: 0.14031882584095
step: 80, loss: 0.12155738472938538
step: 90, loss: 0.013642649166285992
step: 100, loss: 0.1489993929862976
step: 110, loss: 0.1791812777519226
step: 120, loss: 0.05231136456131935
step: 130, loss: 0.08579118549823761
step: 140, loss: 0.06853014975786209
step: 150, loss: 0.08573973923921585
step: 160, loss: 0.12541992962360382
step: 170, loss: 0.09298403561115265
step: 180, loss: 0.04135705158114433
step: 190, loss: 0.03591930493712425
step: 200, loss: 0.1960214376449585
step: 210, loss: 0.14739562571048737
step: 220, loss: 0.05040676146745682
step: 230, loss: 0.03036515600979328
step: 240, loss: 0.09816776216030121
step: 250, loss: 0.10308541357517242
step: 260, loss: 0.11438307166099548
step: 270, loss: 0.04871038347482681
step: 280, loss: 0.09830837696790695
step: 290, loss: 0.11320830881595612
step: 300, loss: 0.05136856436729431
step: 310, loss: 0.13083073496818542
step: 320, loss: 0.10037022083997726
step: 330, loss: 0.08493588864803314
step: 340, loss: 0.20652718842029572
step: 350, loss: 0.21552994847297668
step: 360, loss: 0.21053281426429749
epoch 5: dev_f1=0.7430025445292621, f1=0.7544303797468355, best_f1=0.6975476839237057
step: 0, loss: 0.0673501044511795
step: 10, loss: 0.17395317554473877
step: 20, loss: 0.07167045027017593
step: 30, loss: 0.0688508152961731
step: 40, loss: 0.06977709382772446
step: 50, loss: 0.12156698107719421
step: 60, loss: 0.08054427057504654
step: 70, loss: 0.2094850391149521
step: 80, loss: 0.08749653398990631
step: 90, loss: 0.020245257765054703
step: 100, loss: 0.01938651129603386
step: 110, loss: 0.07019871473312378
step: 120, loss: 0.08859456330537796
step: 130, loss: 0.12850521504878998
step: 140, loss: 0.06600873917341232
step: 150, loss: 0.11277487128973007
step: 160, loss: 0.18612928688526154
step: 170, loss: 0.15606172382831573
step: 180, loss: 0.056773800402879715
step: 190, loss: 0.0002595366968307644
step: 200, loss: 0.09577223658561707
step: 210, loss: 0.14147336781024933
step: 220, loss: 0.049519751220941544
step: 230, loss: 0.04691518470644951
step: 240, loss: 0.0007436822634190321
step: 250, loss: 0.25733160972595215
step: 260, loss: 0.055682163685560226
step: 270, loss: 0.11113719642162323
step: 280, loss: 0.08510666340589523
step: 290, loss: 0.09161131829023361
step: 300, loss: 0.038604263216257095
step: 310, loss: 0.05470554158091545
step: 320, loss: 0.25885817408561707
step: 330, loss: 0.13031117618083954
step: 340, loss: 0.21319156885147095
step: 350, loss: 0.1350180059671402
step: 360, loss: 0.05369149520993233
epoch 6: dev_f1=0.7193877551020408, f1=0.7115902964959568, best_f1=0.6975476839237057
step: 0, loss: 0.07313518971204758
step: 10, loss: 0.09121932834386826
step: 20, loss: 0.10266447067260742
step: 30, loss: 0.10134192556142807
step: 40, loss: 0.11376804858446121
step: 50, loss: 0.0694839134812355
step: 60, loss: 0.029276249930262566
step: 70, loss: 0.326277494430542
step: 80, loss: 0.13699345290660858
step: 90, loss: 0.04818494990468025
step: 100, loss: 0.09734402596950531
step: 110, loss: 0.058670420199632645
step: 120, loss: 0.17068135738372803
step: 130, loss: 0.09585156291723251
step: 140, loss: 0.08018431067466736
step: 150, loss: 0.05417043715715408
step: 160, loss: 0.0486220121383667
step: 170, loss: 0.057559628039598465
step: 180, loss: 0.02552526630461216
step: 190, loss: 0.08972763270139694
step: 200, loss: 0.0527908056974411
step: 210, loss: 0.03145749494433403
step: 220, loss: 0.10927315056324005
step: 230, loss: 0.05380547419190407
step: 240, loss: 0.01576904207468033
step: 250, loss: 0.07111174613237381
step: 260, loss: 0.03376885503530502
step: 270, loss: 0.05473978817462921
step: 280, loss: 0.03377280756831169
step: 290, loss: 0.06496328860521317
step: 300, loss: 0.2246549129486084
step: 310, loss: 0.10572242736816406
step: 320, loss: 0.0325394943356514
step: 330, loss: 0.07617063820362091
step: 340, loss: 0.08134519308805466
step: 350, loss: 0.10228851437568665
step: 360, loss: 0.03560013324022293
epoch 7: dev_f1=0.733509234828496, f1=0.7219251336898397, best_f1=0.6975476839237057
step: 0, loss: 0.06810080260038376
step: 10, loss: 0.12999248504638672
step: 20, loss: 0.09002210199832916
step: 30, loss: 0.09355692565441132
step: 40, loss: 0.06113608181476593
step: 50, loss: 0.11796808987855911
step: 60, loss: 0.017412787303328514
step: 70, loss: 0.0009895447874441743
step: 80, loss: 0.03625888749957085
step: 90, loss: 0.08913959562778473
step: 100, loss: 0.08021315932273865
step: 110, loss: 0.06337422132492065
step: 120, loss: 0.04937709495425224
step: 130, loss: 0.03950268775224686
step: 140, loss: 0.06330874562263489
step: 150, loss: 0.09203241020441055
step: 160, loss: 0.19624051451683044
step: 170, loss: 0.05602706968784332
step: 180, loss: 0.03121791034936905
step: 190, loss: 0.0789196565747261
step: 200, loss: 0.13164737820625305
step: 210, loss: 0.1283016949892044
step: 220, loss: 0.0994376614689827
step: 230, loss: 0.19562377035617828
step: 240, loss: 0.07782980799674988
step: 250, loss: 0.07107431441545486
step: 260, loss: 0.0921846404671669
step: 270, loss: 0.05499637871980667
step: 280, loss: 0.04668649286031723
step: 290, loss: 0.05104583129286766
step: 300, loss: 0.1489550769329071
step: 310, loss: 0.054635170847177505
step: 320, loss: 0.15473245084285736
step: 330, loss: 0.056814804673194885
step: 340, loss: 0.039701271802186966
step: 350, loss: 0.04049677774310112
step: 360, loss: 0.15251624584197998
epoch 8: dev_f1=0.733509234828496, f1=0.7302452316076293, best_f1=0.6975476839237057
step: 0, loss: 0.0051214732229709625
step: 10, loss: 0.04968699812889099
step: 20, loss: 0.05792858451604843
step: 30, loss: 0.0590037927031517
step: 40, loss: 0.02125813066959381
step: 50, loss: 0.10554865002632141
step: 60, loss: 0.08149371296167374
step: 70, loss: 0.018256301060318947
step: 80, loss: 0.04839242994785309
step: 90, loss: 0.0904119610786438
step: 100, loss: 0.08817669004201889
step: 110, loss: 0.05588974431157112
step: 120, loss: 0.06969186663627625
step: 130, loss: 0.13063926994800568
step: 140, loss: 0.06884584575891495
step: 150, loss: 0.020379969850182533
step: 160, loss: 0.020708663389086723
step: 170, loss: 0.0524657778441906
step: 180, loss: 0.06231139600276947
step: 190, loss: 0.06606665253639221
step: 200, loss: 0.09785371273756027
step: 210, loss: 0.0854526162147522
step: 220, loss: 0.1660078465938568
step: 230, loss: 0.0915178433060646
step: 240, loss: 0.04518767446279526
step: 250, loss: 0.05786070600152016
step: 260, loss: 0.11223704367876053
step: 270, loss: 0.06990743428468704
step: 280, loss: 0.03542771562933922
step: 290, loss: 0.2462535798549652
step: 300, loss: 0.1314370036125183
step: 310, loss: 0.07918296009302139
step: 320, loss: 0.04596571996808052
step: 330, loss: 0.0907939150929451
step: 340, loss: 0.06096304953098297
step: 350, loss: 0.07775824517011642
step: 360, loss: 0.0641566812992096
epoch 9: dev_f1=0.7232876712328767, f1=0.7084468664850135, best_f1=0.6975476839237057
step: 0, loss: 0.1294761449098587
step: 10, loss: 0.09474770724773407
step: 20, loss: 0.0009638890624046326
step: 30, loss: 0.05019882321357727
step: 40, loss: 0.09927289187908173
step: 50, loss: 0.062073007225990295
step: 60, loss: 0.03156245872378349
step: 70, loss: 0.06108850613236427
step: 80, loss: 0.001530506182461977
step: 90, loss: 0.14133784174919128
step: 100, loss: 0.06932119280099869
step: 110, loss: 0.1527346521615982
step: 120, loss: 0.025896284729242325
step: 130, loss: 0.03813467174768448
step: 140, loss: 0.12406780570745468
step: 150, loss: 0.04719028249382973
step: 160, loss: 0.013059105724096298
step: 170, loss: 0.07357084006071091
step: 180, loss: 0.001132718869484961
step: 190, loss: 0.09532756358385086
step: 200, loss: 0.031457286328077316
step: 210, loss: 0.061304010450839996
step: 220, loss: 0.04461044445633888
step: 230, loss: 0.06734757870435715
step: 240, loss: 0.054554473608732224
step: 250, loss: 0.018201284110546112
step: 260, loss: 0.11019563674926758
step: 270, loss: 0.029111145064234734
step: 280, loss: 0.036712780594825745
step: 290, loss: 0.014502445235848427
step: 300, loss: 0.08059484511613846
step: 310, loss: 0.020343562588095665
step: 320, loss: 0.020922912284731865
step: 330, loss: 0.0748458132147789
step: 340, loss: 0.09728935360908508
step: 350, loss: 0.10993926972150803
step: 360, loss: 0.0107665304094553
epoch 10: dev_f1=0.7424242424242425, f1=0.7268041237113403, best_f1=0.6975476839237057
step: 0, loss: 0.05656084045767784
step: 10, loss: 0.08856759965419769
step: 20, loss: 0.10270727425813675
step: 30, loss: 0.06769663095474243
step: 40, loss: 0.08031181246042252
step: 50, loss: 0.0002980003773700446
step: 60, loss: 0.0358080118894577
step: 70, loss: 0.0846031904220581
step: 80, loss: 0.005429390352219343
step: 90, loss: 0.06437705457210541
step: 100, loss: 0.15017135441303253
step: 110, loss: 0.12953397631645203
step: 120, loss: 0.02788596972823143
step: 130, loss: 0.07731706649065018
step: 140, loss: 0.025159772485494614
step: 150, loss: 0.0526813380420208
step: 160, loss: 0.041816022247076035
step: 170, loss: 0.06079437956213951
step: 180, loss: 0.08515655994415283
step: 190, loss: 0.0007839889731258154
step: 200, loss: 0.09338323771953583
step: 210, loss: 0.08621448278427124
step: 220, loss: 0.08943378925323486
step: 230, loss: 0.007475373800843954
step: 240, loss: 0.07106340676546097
step: 250, loss: 0.0003043603210244328
step: 260, loss: 0.09666730463504791
step: 270, loss: 0.07993622124195099
step: 280, loss: 0.13150259852409363
step: 290, loss: 0.027666384354233742
step: 300, loss: 0.04250681772828102
step: 310, loss: 0.10491229593753815
step: 320, loss: 0.05593269318342209
step: 330, loss: 0.08632224798202515
step: 340, loss: 0.06533202528953552
step: 350, loss: 0.10650694370269775
step: 360, loss: 0.06223248317837715
epoch 11: dev_f1=0.7548209366391184, f1=0.7282913165266107, best_f1=0.7282913165266107
step: 0, loss: 0.0015697809867560863
step: 10, loss: 0.0636240616440773
step: 20, loss: 0.02791699953377247
step: 30, loss: 0.16421103477478027
step: 40, loss: 0.15334977209568024
step: 50, loss: 0.06919337809085846
step: 60, loss: 0.1115889921784401
step: 70, loss: 0.0879012793302536
step: 80, loss: 0.05128934606909752
step: 90, loss: 0.04147731885313988
step: 100, loss: 0.06409059464931488
step: 110, loss: 0.02354353666305542
step: 120, loss: 0.04554200544953346
step: 130, loss: 0.14288686215877533
step: 140, loss: 0.005980882793664932
step: 150, loss: 0.02884395234286785
step: 160, loss: 0.017417289316654205
step: 170, loss: 0.05140537768602371
step: 180, loss: 0.05894462391734123
step: 190, loss: 0.09235737472772598
step: 200, loss: 0.07185964286327362
step: 210, loss: 0.015566233545541763
step: 220, loss: 0.06886711716651917
step: 230, loss: 0.05258840695023537
step: 240, loss: 0.036712225526571274
step: 250, loss: 0.19883514940738678
step: 260, loss: 0.02069585770368576
step: 270, loss: 0.10598015785217285
step: 280, loss: 0.052981387823820114
step: 290, loss: 0.024817077443003654
step: 300, loss: 0.0270485021173954
step: 310, loss: 0.0011858547804877162
step: 320, loss: 0.021264314651489258
step: 330, loss: 0.0806007906794548
step: 340, loss: 0.018004652112722397
step: 350, loss: 0.06051108241081238
step: 360, loss: 0.061074838042259216
epoch 12: dev_f1=0.7174447174447175, f1=0.712871287128713, best_f1=0.7282913165266107
step: 0, loss: 3.367215322214179e-05
step: 10, loss: 0.04871073365211487
step: 20, loss: 0.06799986213445663
step: 30, loss: 0.08394566923379898
step: 40, loss: 0.0049653248861432076
step: 50, loss: 0.00010866535012610257
step: 60, loss: 0.006814748514443636
step: 70, loss: 0.014891743659973145
step: 80, loss: 0.023350045084953308
step: 90, loss: 0.03533723205327988
step: 100, loss: 0.06308174133300781
step: 110, loss: 0.02552807331085205
step: 120, loss: 0.2579004466533661
step: 130, loss: 0.008300411514937878
step: 140, loss: 0.031223755329847336
step: 150, loss: 0.00918533094227314
step: 160, loss: 0.06509777903556824
step: 170, loss: 0.09662043303251266
step: 180, loss: 0.08126597106456757
step: 190, loss: 0.10923194140195847
step: 200, loss: 0.014599545858800411
step: 210, loss: 0.04136175289750099
step: 220, loss: 0.027325959876179695
step: 230, loss: 0.029858140274882317
step: 240, loss: 0.0008243285701610148
step: 250, loss: 0.00474941823631525
step: 260, loss: 0.050418153405189514
step: 270, loss: 0.032651789486408234
step: 280, loss: 0.005333140958100557
step: 290, loss: 0.05164964869618416
step: 300, loss: 0.04434959217905998
step: 310, loss: 0.032643627375364304
step: 320, loss: 0.02332698181271553
step: 330, loss: 0.07741023600101471
step: 340, loss: 0.10461273789405823
step: 350, loss: 0.10071788728237152
step: 360, loss: 0.06559782475233078
epoch 13: dev_f1=0.7338501291989663, f1=0.7142857142857143, best_f1=0.7282913165266107
step: 0, loss: 0.06762729585170746
step: 10, loss: 0.05487540364265442
step: 20, loss: 0.0003261567617300898
step: 30, loss: 0.01805814914405346
step: 40, loss: 0.02510308101773262
step: 50, loss: 0.04623774066567421
step: 60, loss: 0.08200197666883469
step: 70, loss: 0.03383942320942879
step: 80, loss: 0.05127379670739174
step: 90, loss: 0.020559456199407578
step: 100, loss: 0.08818341791629791
step: 110, loss: 0.0430273599922657
step: 120, loss: 0.055963389575481415
step: 130, loss: 0.06929885596036911
step: 140, loss: 0.008611397817730904
step: 150, loss: 0.09591477364301682
step: 160, loss: 0.06905905902385712
step: 170, loss: 0.02265262044966221
step: 180, loss: 0.07506435364484787
step: 190, loss: 0.007171190343797207
step: 200, loss: 0.004101351834833622
step: 210, loss: 0.09208504855632782
step: 220, loss: 0.07334601134061813
step: 230, loss: 0.0588238500058651
step: 240, loss: 0.11783283203840256
step: 250, loss: 0.07485738396644592
step: 260, loss: 0.08454044163227081
step: 270, loss: 0.13066968321800232
step: 280, loss: 0.06775445491075516
step: 290, loss: 0.028878072276711464
step: 300, loss: 0.05056324228644371
step: 310, loss: 0.21834637224674225
step: 320, loss: 0.05148852616548538
step: 330, loss: 0.07175297290086746
step: 340, loss: 0.0687643513083458
step: 350, loss: 0.051239512860774994
step: 360, loss: 0.0008176292758435011
epoch 14: dev_f1=0.7083333333333333, f1=0.7046070460704608, best_f1=0.7282913165266107
step: 0, loss: 0.042505763471126556
step: 10, loss: 0.044190142303705215
step: 20, loss: 0.02192358300089836
step: 30, loss: 0.09744419157505035
step: 40, loss: 0.1029355600476265
step: 50, loss: 0.0904914140701294
step: 60, loss: 0.08184096217155457
step: 70, loss: 0.07628632336854935
step: 80, loss: 0.055911242961883545
step: 90, loss: 0.01977379620075226
step: 100, loss: 0.046801839023828506
step: 110, loss: 0.02080320194363594
step: 120, loss: 0.049009814858436584
step: 130, loss: 0.06969723105430603
step: 140, loss: 0.01795119233429432
step: 150, loss: 0.04446734860539436
step: 160, loss: 0.0520489439368248
step: 170, loss: 0.014568046666681767
step: 180, loss: 0.024957560002803802
step: 190, loss: 0.06132010370492935
step: 200, loss: 0.03716989606618881
step: 210, loss: 0.05379626154899597
step: 220, loss: 0.03150898963212967
step: 230, loss: 0.025744624435901642
step: 240, loss: 0.005976015701889992
step: 250, loss: 0.08574333786964417
step: 260, loss: 0.04149486869573593
step: 270, loss: 0.046735454350709915
step: 280, loss: 0.03293154761195183
step: 290, loss: 0.07156825810670853
step: 300, loss: 7.547144923591986e-05
step: 310, loss: 0.01961127482354641
step: 320, loss: 0.09888453781604767
step: 330, loss: 0.03502979502081871
step: 340, loss: 0.12523360550403595
step: 350, loss: 0.013234755955636501
step: 360, loss: 0.035965241491794586
epoch 15: dev_f1=0.7352185089974292, f1=0.7267904509283819, best_f1=0.7282913165266107
step: 0, loss: 0.02528858557343483
step: 10, loss: 0.048259176313877106
step: 20, loss: 0.003365854499861598
step: 30, loss: 0.00014826992992311716
step: 40, loss: 0.1776512712240219
step: 50, loss: 0.03405914083123207
step: 60, loss: 0.0032849726267158985
step: 70, loss: 0.018564455211162567
step: 80, loss: 0.11173359304666519
step: 90, loss: 0.018140442669391632
step: 100, loss: 0.0782829076051712
step: 110, loss: 0.027401238679885864
step: 120, loss: 0.01142942626029253
step: 130, loss: 0.0533190481364727
step: 140, loss: 0.10663514584302902
step: 150, loss: 0.013329717330634594
step: 160, loss: 0.014083839021623135
step: 170, loss: 2.5230854589608498e-05
step: 180, loss: 0.05972093716263771
step: 190, loss: 0.12291868776082993
step: 200, loss: 0.04130949079990387
step: 210, loss: 0.002282444853335619
step: 220, loss: 0.09118492156267166
step: 230, loss: 0.05614728108048439
step: 240, loss: 0.042972784489393234
step: 250, loss: 0.087494395673275
step: 260, loss: 0.09655140340328217
step: 270, loss: 0.10533689707517624
step: 280, loss: 0.004179996903985739
step: 290, loss: 0.03189191222190857
step: 300, loss: 0.06728417426347733
step: 310, loss: 0.09066900610923767
step: 320, loss: 0.015127807855606079
step: 330, loss: 0.03159482777118683
step: 340, loss: 0.026391692459583282
step: 350, loss: 0.02521444484591484
step: 360, loss: 0.0013465300435200334
epoch 16: dev_f1=0.7336683417085428, f1=0.7268041237113403, best_f1=0.7282913165266107
step: 0, loss: 0.04213840514421463
step: 10, loss: 0.0033982316963374615
step: 20, loss: 0.030873261392116547
step: 30, loss: 0.017004378139972687
step: 40, loss: 0.004631076008081436
step: 50, loss: 0.12168622761964798
step: 60, loss: 0.08715111017227173
step: 70, loss: 0.1427786499261856
step: 80, loss: 0.034926146268844604
step: 90, loss: 0.06517767161130905
step: 100, loss: 0.019584428519010544
step: 110, loss: 0.010074974037706852
step: 120, loss: 0.054229557514190674
step: 130, loss: 0.04737243428826332
step: 140, loss: 0.029957672581076622
step: 150, loss: 0.07294270396232605
step: 160, loss: 0.05196055769920349
step: 170, loss: 0.09145329147577286
step: 180, loss: 0.09559263288974762
step: 190, loss: 0.01862931251525879
step: 200, loss: 0.0389416329562664
step: 210, loss: 0.033564094454050064
step: 220, loss: 0.08656907081604004
step: 230, loss: 0.03922175616025925
step: 240, loss: 0.036649156361818314
step: 250, loss: 0.07779403775930405
step: 260, loss: 0.08330830931663513
step: 270, loss: 0.07980739325284958
step: 280, loss: 0.06372778862714767
step: 290, loss: 0.04815474897623062
step: 300, loss: 0.0432053804397583
step: 310, loss: 0.0006593547877855599
step: 320, loss: 0.06439273059368134
step: 330, loss: 0.02729644440114498
step: 340, loss: 0.0036148347426205873
step: 350, loss: 0.06728479266166687
step: 360, loss: 0.07597776502370834
epoch 17: dev_f1=0.7586206896551724, f1=0.7262872628726287, best_f1=0.7262872628726287
step: 0, loss: 0.011483105830848217
step: 10, loss: 0.14575383067131042
step: 20, loss: 0.02900627627968788
step: 30, loss: 0.08478590846061707
step: 40, loss: 0.002633793978020549
step: 50, loss: 0.0638500303030014
step: 60, loss: 0.03917079418897629
step: 70, loss: 0.03226713091135025
step: 80, loss: 0.00947435200214386
step: 90, loss: 0.02672426402568817
step: 100, loss: 0.018533917143940926
step: 110, loss: 7.762398308841512e-05
step: 120, loss: 0.013478090986609459
step: 130, loss: 0.09487498551607132
step: 140, loss: 0.009554709307849407
step: 150, loss: 0.04563058540225029
step: 160, loss: 0.08246873319149017
step: 170, loss: 0.07050490379333496
step: 180, loss: 0.05203825607895851
step: 190, loss: 0.01794256456196308
step: 200, loss: 0.03271263837814331
step: 210, loss: 0.09149273484945297
step: 220, loss: 0.15754827857017517
step: 230, loss: 0.03142349794507027
step: 240, loss: 0.04384550452232361
step: 250, loss: 0.031431645154953
step: 260, loss: 0.0037201608065515757
step: 270, loss: 0.028330150991678238
step: 280, loss: 0.022796690464019775
step: 290, loss: 0.00499320961534977
step: 300, loss: 0.011731022037565708
step: 310, loss: 0.009003926068544388
step: 320, loss: 0.0080350236967206
step: 330, loss: 0.10229869931936264
step: 340, loss: 0.030237480998039246
step: 350, loss: 0.1600935012102127
step: 360, loss: 0.07276337593793869
epoch 18: dev_f1=0.721311475409836, f1=0.7150837988826816, best_f1=0.7262872628726287
step: 0, loss: 0.01646427996456623
step: 10, loss: 0.04618486389517784
step: 20, loss: 0.012197241187095642
step: 30, loss: 0.017766743898391724
step: 40, loss: 0.033078793436288834
step: 50, loss: 0.002027660608291626
step: 60, loss: 0.011164474301040173
step: 70, loss: 0.003720683977007866
step: 80, loss: 0.015392925590276718
step: 90, loss: 0.0001304009201703593
step: 100, loss: 0.08257920295000076
step: 110, loss: 0.033604156225919724
step: 120, loss: 0.022399336099624634
step: 130, loss: 0.06954678893089294
step: 140, loss: 0.01746806874871254
step: 150, loss: 0.11126178503036499
step: 160, loss: 3.3625121432123706e-05
step: 170, loss: 0.03242822736501694
step: 180, loss: 0.07366251945495605
step: 190, loss: 0.04287892207503319
step: 200, loss: 0.012278727255761623
step: 210, loss: 0.046561047434806824
step: 220, loss: 0.018353162333369255
step: 230, loss: 0.04460371658205986
step: 240, loss: 0.021591942757368088
step: 250, loss: 0.04766661301255226
step: 260, loss: 0.07720787078142166
step: 270, loss: 0.05203671753406525
step: 280, loss: 0.059244997799396515
step: 290, loss: 0.044432856142520905
step: 300, loss: 0.040646281093358994
step: 310, loss: 0.051486723124980927
step: 320, loss: 0.0487976036965847
step: 330, loss: 0.0005382055533118546
step: 340, loss: 0.12471619248390198
step: 350, loss: 0.017971975728869438
step: 360, loss: 0.029340028762817383
epoch 19: dev_f1=0.7306666666666668, f1=0.7127659574468086, best_f1=0.7262872628726287
step: 0, loss: 0.014378107152879238
step: 10, loss: 0.025930915027856827
step: 20, loss: 0.07127240300178528
step: 30, loss: 0.0018986576469615102
step: 40, loss: 0.09439613670110703
step: 50, loss: 0.013407978229224682
step: 60, loss: 0.07310643047094345
step: 70, loss: 0.0005803792737424374
step: 80, loss: 0.027255389839410782
step: 90, loss: 0.07081186026334763
step: 100, loss: 0.0023814095184206963
step: 110, loss: 0.00941031239926815
step: 120, loss: 0.017621397972106934
step: 130, loss: 0.05140533670783043
step: 140, loss: 0.023498184978961945
step: 150, loss: 0.001568418345414102
step: 160, loss: 0.006960185244679451
step: 170, loss: 0.020841727033257484
step: 180, loss: 0.03645806014537811
step: 190, loss: 0.02388770878314972
step: 200, loss: 0.007323510944843292
step: 210, loss: 0.051171474158763885
step: 220, loss: 0.01593407243490219
step: 230, loss: 0.02146444097161293
step: 240, loss: 0.06642799824476242
step: 250, loss: 0.00028599248616956174
step: 260, loss: 0.03233737125992775
step: 270, loss: 0.057567499577999115
step: 280, loss: 0.0009946036152541637
step: 290, loss: 0.03834467753767967
step: 300, loss: 0.06580800563097
step: 310, loss: 0.029674354940652847
step: 320, loss: 0.00017345100059174
step: 330, loss: 0.008145916275680065
step: 340, loss: 0.05646715685725212
step: 350, loss: 0.0013743730960413814
step: 360, loss: 0.03520715609192848
epoch 20: dev_f1=0.7142857142857142, f1=0.7197802197802198, best_f1=0.7262872628726287
