cuda
Device: cuda
step: 0, loss: 0.9920861721038818
step: 10, loss: 0.38246530294418335
step: 20, loss: 0.1469300240278244
step: 30, loss: 0.13594000041484833
step: 40, loss: 0.2249482423067093
step: 50, loss: 0.1524377316236496
step: 60, loss: 0.2445092648267746
step: 70, loss: 0.239924356341362
step: 80, loss: 0.14571379125118256
step: 90, loss: 0.3394298851490021
step: 100, loss: 0.23583737015724182
step: 110, loss: 0.0660332441329956
step: 120, loss: 0.3098290264606476
step: 130, loss: 0.054984766989946365
step: 140, loss: 0.02611096389591694
step: 150, loss: 0.06369893252849579
step: 160, loss: 0.11835666745901108
step: 170, loss: 0.11456972360610962
step: 180, loss: 0.22307060658931732
step: 190, loss: 0.2958325743675232
step: 200, loss: 0.3862210512161255
step: 210, loss: 0.0197422057390213
step: 220, loss: 0.12524659931659698
step: 230, loss: 0.029217170551419258
step: 240, loss: 0.24952203035354614
step: 250, loss: 0.21009333431720734
step: 260, loss: 0.14152565598487854
step: 270, loss: 0.05678127706050873
step: 280, loss: 0.13972434401512146
step: 290, loss: 0.28901207447052
step: 300, loss: 0.07648634910583496
step: 310, loss: 0.17017659544944763
step: 320, loss: 0.1506466418504715
step: 330, loss: 0.11961159855127335
step: 340, loss: 0.072630375623703
step: 350, loss: 0.08152507245540619
step: 360, loss: 0.058591149747371674
epoch 1: dev_f1=0.6036585365853658, f1=0.5714285714285714, best_f1=0.5714285714285714
step: 0, loss: 0.009249924682080746
step: 10, loss: 0.15778636932373047
step: 20, loss: 0.3094030022621155
step: 30, loss: 0.5175958275794983
step: 40, loss: 0.03248884901404381
step: 50, loss: 0.026246212422847748
step: 60, loss: 0.07509539276361465
step: 70, loss: 0.06938844174146652
step: 80, loss: 0.18617211282253265
step: 90, loss: 0.13809441030025482
step: 100, loss: 0.014360273256897926
step: 110, loss: 0.15871009230613708
step: 120, loss: 0.15743492543697357
step: 130, loss: 0.1527063548564911
step: 140, loss: 0.022081734612584114
step: 150, loss: 0.09851434081792831
step: 160, loss: 0.0821247398853302
step: 170, loss: 0.1361997276544571
step: 180, loss: 0.11445549130439758
step: 190, loss: 0.23447886109352112
step: 200, loss: 0.05922726169228554
step: 210, loss: 0.08833436667919159
step: 220, loss: 0.04701932892203331
step: 230, loss: 0.133396178483963
step: 240, loss: 0.07346194982528687
step: 250, loss: 0.18164820969104767
step: 260, loss: 0.19840671122074127
step: 270, loss: 0.11411456763744354
step: 280, loss: 0.08194272220134735
step: 290, loss: 0.17298096418380737
step: 300, loss: 0.2475258708000183
step: 310, loss: 0.0374225489795208
step: 320, loss: 0.3348391056060791
step: 330, loss: 0.14194534718990326
step: 340, loss: 0.09131769835948944
step: 350, loss: 0.013428526930510998
step: 360, loss: 0.12823700904846191
epoch 2: dev_f1=0.707182320441989, f1=0.6855524079320112, best_f1=0.6855524079320112
step: 0, loss: 0.07693519443273544
step: 10, loss: 0.0813537985086441
step: 20, loss: 0.05062934383749962
step: 30, loss: 0.11366990208625793
step: 40, loss: 0.23744364082813263
step: 50, loss: 0.15982873737812042
step: 60, loss: 0.1232401505112648
step: 70, loss: 0.295421302318573
step: 80, loss: 0.12183133512735367
step: 90, loss: 0.11151852458715439
step: 100, loss: 0.07948414236307144
step: 110, loss: 0.06647226214408875
step: 120, loss: 0.30208584666252136
step: 130, loss: 0.0673351138830185
step: 140, loss: 0.18032193183898926
step: 150, loss: 0.13601739704608917
step: 160, loss: 0.16918069124221802
step: 170, loss: 0.061899736523628235
step: 180, loss: 0.07921215891838074
step: 190, loss: 0.11038369685411453
step: 200, loss: 0.14318230748176575
step: 210, loss: 0.13463501632213593
step: 220, loss: 0.08596022427082062
step: 230, loss: 0.13518942892551422
step: 240, loss: 0.07709147036075592
step: 250, loss: 0.08162493258714676
step: 260, loss: 0.15319432318210602
step: 270, loss: 0.29609277844429016
step: 280, loss: 0.05967244878411293
step: 290, loss: 0.0516199916601181
step: 300, loss: 0.1858978122472763
step: 310, loss: 0.1254698634147644
step: 320, loss: 0.07440391927957535
step: 330, loss: 0.07448432594537735
step: 340, loss: 0.20148001611232758
step: 350, loss: 0.041943587362766266
step: 360, loss: 0.06608159840106964
epoch 3: dev_f1=0.6925373134328358, f1=0.6959064327485379, best_f1=0.6855524079320112
step: 0, loss: 0.03524365648627281
step: 10, loss: 0.08731027692556381
step: 20, loss: 0.007688494399189949
step: 30, loss: 0.0575108677148819
step: 40, loss: 0.11233964562416077
step: 50, loss: 0.1521451771259308
step: 60, loss: 0.07782153785228729
step: 70, loss: 0.027772285044193268
step: 80, loss: 0.06179559603333473
step: 90, loss: 0.04860970377922058
step: 100, loss: 0.0865630954504013
step: 110, loss: 0.21153980493545532
step: 120, loss: 0.08402311056852341
step: 130, loss: 0.04733652621507645
step: 140, loss: 0.3135001063346863
step: 150, loss: 0.1538374274969101
step: 160, loss: 0.024763453751802444
step: 170, loss: 0.1638091802597046
step: 180, loss: 0.33609095215797424
step: 190, loss: 0.0731981173157692
step: 200, loss: 0.07943768799304962
step: 210, loss: 0.09563232213258743
step: 220, loss: 0.12048369646072388
step: 230, loss: 0.042943231761455536
step: 240, loss: 0.03676905855536461
step: 250, loss: 0.07186036556959152
step: 260, loss: 0.09975576400756836
step: 270, loss: 0.11868772655725479
step: 280, loss: 0.15987356007099152
step: 290, loss: 0.08416201919317245
step: 300, loss: 0.13084378838539124
step: 310, loss: 0.05632536858320236
step: 320, loss: 0.04827932268381119
step: 330, loss: 0.03456409275531769
step: 340, loss: 0.1778019219636917
step: 350, loss: 0.13516834378242493
step: 360, loss: 0.1811610609292984
epoch 4: dev_f1=0.7462686567164178, f1=0.7454068241469817, best_f1=0.7454068241469817
step: 0, loss: 0.05807487294077873
step: 10, loss: 0.025969380512833595
step: 20, loss: 0.10825435072183609
step: 30, loss: 0.09389270097017288
step: 40, loss: 0.061618831008672714
step: 50, loss: 0.09705860167741776
step: 60, loss: 0.07340729236602783
step: 70, loss: 0.09124968945980072
step: 80, loss: 0.07479077577590942
step: 90, loss: 0.10477009415626526
step: 100, loss: 0.14113835990428925
step: 110, loss: 0.09551944583654404
step: 120, loss: 0.04763757437467575
step: 130, loss: 0.07689540833234787
step: 140, loss: 0.06326457113027573
step: 150, loss: 0.014300107955932617
step: 160, loss: 0.056599706411361694
step: 170, loss: 0.026484640315175056
step: 180, loss: 0.11298145353794098
step: 190, loss: 0.023512283340096474
step: 200, loss: 0.03699276223778725
step: 210, loss: 0.12766991555690765
step: 220, loss: 0.04412209615111351
step: 230, loss: 0.10535912960767746
step: 240, loss: 0.02386246807873249
step: 250, loss: 0.0672973170876503
step: 260, loss: 0.10095982998609543
step: 270, loss: 0.06662094593048096
step: 280, loss: 0.05575812980532646
step: 290, loss: 0.07784389704465866
step: 300, loss: 0.0831306055188179
step: 310, loss: 0.01628902740776539
step: 320, loss: 0.09389059245586395
step: 330, loss: 0.12392464280128479
step: 340, loss: 0.046285029500722885
step: 350, loss: 0.08699320256710052
step: 360, loss: 0.05656180903315544
epoch 5: dev_f1=0.7287671232876712, f1=0.7127071823204421, best_f1=0.7454068241469817
step: 0, loss: 0.15322858095169067
step: 10, loss: 0.053456589579582214
step: 20, loss: 0.023329265415668488
step: 30, loss: 0.1432555913925171
step: 40, loss: 0.02637661248445511
step: 50, loss: 0.08871317654848099
step: 60, loss: 0.09218543767929077
step: 70, loss: 0.023514633998274803
step: 80, loss: 0.04475158080458641
step: 90, loss: 0.10275454819202423
step: 100, loss: 0.07134651392698288
step: 110, loss: 0.10882425308227539
step: 120, loss: 0.2422136515378952
step: 130, loss: 0.10851112753152847
step: 140, loss: 0.03977007046341896
step: 150, loss: 0.07904712855815887
step: 160, loss: 0.10919070243835449
step: 170, loss: 0.1566668450832367
step: 180, loss: 0.08294349163770676
step: 190, loss: 0.07919155806303024
step: 200, loss: 0.0892794132232666
step: 210, loss: 0.10159651935100555
step: 220, loss: 0.03579998388886452
step: 230, loss: 0.08465902507305145
step: 240, loss: 0.05350084975361824
step: 250, loss: 0.1870936006307602
step: 260, loss: 0.06792458891868591
step: 270, loss: 0.0834081694483757
step: 280, loss: 0.03770400956273079
step: 290, loss: 0.11146806180477142
step: 300, loss: 0.059951815754175186
step: 310, loss: 0.1481616050004959
step: 320, loss: 0.08396800607442856
step: 330, loss: 0.023822929710149765
step: 340, loss: 0.08134068548679352
step: 350, loss: 0.13416388630867004
step: 360, loss: 0.06658517569303513
epoch 6: dev_f1=0.7409326424870466, f1=0.7172774869109948, best_f1=0.7454068241469817
step: 0, loss: 0.12218768149614334
step: 10, loss: 0.13202117383480072
step: 20, loss: 0.09554833173751831
step: 30, loss: 0.03781051188707352
step: 40, loss: 0.10998588800430298
step: 50, loss: 0.023395946249365807
step: 60, loss: 0.07431220263242722
step: 70, loss: 0.0682753175497055
step: 80, loss: 0.07241921126842499
step: 90, loss: 0.08541533350944519
step: 100, loss: 0.12019982933998108
step: 110, loss: 0.18860174715518951
step: 120, loss: 0.05580563470721245
step: 130, loss: 0.12245984375476837
step: 140, loss: 0.07184186577796936
step: 150, loss: 0.10357259213924408
step: 160, loss: 0.08715508878231049
step: 170, loss: 0.11822754144668579
step: 180, loss: 0.11510609835386276
step: 190, loss: 0.09969896823167801
step: 200, loss: 0.01560408715158701
step: 210, loss: 0.09955489635467529
step: 220, loss: 0.021756649017333984
step: 230, loss: 0.0882878452539444
step: 240, loss: 0.14444082975387573
step: 250, loss: 0.16421008110046387
step: 260, loss: 0.04123624414205551
step: 270, loss: 0.10006538778543472
step: 280, loss: 0.06135552376508713
step: 290, loss: 0.07705686241388321
step: 300, loss: 0.016132010146975517
step: 310, loss: 0.033003367483615875
step: 320, loss: 0.0537232980132103
step: 330, loss: 0.12381613254547119
step: 340, loss: 0.14279282093048096
step: 350, loss: 0.04981532320380211
step: 360, loss: 0.12780961394309998
epoch 7: dev_f1=0.7487179487179487, f1=0.7268041237113403, best_f1=0.7268041237113403
step: 0, loss: 0.03892354667186737
step: 10, loss: 0.06258474290370941
step: 20, loss: 0.10500319302082062
step: 30, loss: 0.04466509073972702
step: 40, loss: 0.058501262217760086
step: 50, loss: 0.0457926020026207
step: 60, loss: 0.04922701045870781
step: 70, loss: 0.0001646065793465823
step: 80, loss: 0.07118198275566101
step: 90, loss: 0.05246451869606972
step: 100, loss: 0.0381661057472229
step: 110, loss: 0.11846120655536652
step: 120, loss: 0.06929673254489899
step: 130, loss: 0.03417079523205757
step: 140, loss: 0.019437452778220177
step: 150, loss: 0.07799822092056274
step: 160, loss: 0.008381625637412071
step: 170, loss: 0.09278254210948944
step: 180, loss: 0.05865172669291496
step: 190, loss: 0.021220233291387558
step: 200, loss: 0.14111179113388062
step: 210, loss: 0.03076218068599701
step: 220, loss: 0.06304603815078735
step: 230, loss: 0.07339245826005936
step: 240, loss: 0.05958765000104904
step: 250, loss: 0.14015169441699982
step: 260, loss: 0.019591962918639183
step: 270, loss: 0.08722633868455887
step: 280, loss: 0.036374133080244064
step: 290, loss: 0.07782413810491562
step: 300, loss: 0.01998910680413246
step: 310, loss: 0.06350190937519073
step: 320, loss: 0.048950470983982086
step: 330, loss: 0.06117745861411095
step: 340, loss: 0.05722849816083908
step: 350, loss: 0.06873741745948792
step: 360, loss: 0.032226163893938065
epoch 8: dev_f1=0.7647058823529412, f1=0.7258064516129032, best_f1=0.7258064516129032
step: 0, loss: 0.08071805536746979
step: 10, loss: 0.003926391247659922
step: 20, loss: 0.06024884060025215
step: 30, loss: 0.1083916425704956
step: 40, loss: 0.07082527130842209
step: 50, loss: 0.11093728989362717
step: 60, loss: 0.04020778462290764
step: 70, loss: 0.03875219076871872
step: 80, loss: 0.08896306157112122
step: 90, loss: 0.05714833736419678
step: 100, loss: 0.14259369671344757
step: 110, loss: 0.021024346351623535
step: 120, loss: 0.0860886350274086
step: 130, loss: 0.08212004601955414
step: 140, loss: 0.013375756330788136
step: 150, loss: 0.01186333131045103
step: 160, loss: 0.11516369879245758
step: 170, loss: 0.020002475008368492
step: 180, loss: 0.016107000410556793
step: 190, loss: 0.04040230065584183
step: 200, loss: 0.012076716870069504
step: 210, loss: 0.04155886918306351
step: 220, loss: 0.0002835454943124205
step: 230, loss: 0.13710619509220123
step: 240, loss: 0.05714544281363487
step: 250, loss: 0.07349938899278641
step: 260, loss: 0.1192002221941948
step: 270, loss: 0.05380742624402046
step: 280, loss: 0.07766102254390717
step: 290, loss: 0.11923236399888992
step: 300, loss: 0.05175301432609558
step: 310, loss: 0.06580425798892975
step: 320, loss: 0.10690604895353317
step: 330, loss: 0.10150834172964096
step: 340, loss: 0.04124944657087326
step: 350, loss: 0.1387554109096527
step: 360, loss: 0.08680998533964157
epoch 9: dev_f1=0.7448979591836734, f1=0.711340206185567, best_f1=0.7258064516129032
step: 0, loss: 0.04703472554683685
step: 10, loss: 0.074073426425457
step: 20, loss: 0.05069421976804733
step: 30, loss: 0.0009983748896047473
step: 40, loss: 0.05497943237423897
step: 50, loss: 0.1037551686167717
step: 60, loss: 0.01853305660188198
step: 70, loss: 0.007538268808275461
step: 80, loss: 0.008864667266607285
step: 90, loss: 0.040169235318899155
step: 100, loss: 0.28418034315109253
step: 110, loss: 0.051331426948308945
step: 120, loss: 0.10148011893033981
step: 130, loss: 0.08941976726055145
step: 140, loss: 0.07597403973340988
step: 150, loss: 0.021216608583927155
step: 160, loss: 0.04748266562819481
step: 170, loss: 0.15778179466724396
step: 180, loss: 0.026052584871649742
step: 190, loss: 0.0043855090625584126
step: 200, loss: 0.057196587324142456
step: 210, loss: 0.04062655195593834
step: 220, loss: 0.23920361697673798
step: 230, loss: 0.11713794618844986
step: 240, loss: 0.03333384543657303
step: 250, loss: 0.1002698689699173
step: 260, loss: 0.1254579722881317
step: 270, loss: 0.07118943333625793
step: 280, loss: 0.07672671973705292
step: 290, loss: 0.026074910536408424
step: 300, loss: 0.039039429277181625
step: 310, loss: 0.06012428551912308
step: 320, loss: 0.0038010887801647186
step: 330, loss: 0.016888150945305824
step: 340, loss: 0.030367078259587288
step: 350, loss: 0.1453581303358078
step: 360, loss: 0.05451088398694992
epoch 10: dev_f1=0.7244897959183673, f1=0.712468193384224, best_f1=0.7258064516129032
step: 0, loss: 0.06404585391283035
step: 10, loss: 0.012770078144967556
step: 20, loss: 0.03507216274738312
step: 30, loss: 0.050012312829494476
step: 40, loss: 0.05710358917713165
step: 50, loss: 0.026556601747870445
step: 60, loss: 0.05359089374542236
step: 70, loss: 0.02851676568388939
step: 80, loss: 0.01807936280965805
step: 90, loss: 0.13633723556995392
step: 100, loss: 0.007072143722325563
step: 110, loss: 0.05169730633497238
step: 120, loss: 0.041623182594776154
step: 130, loss: 0.09936975687742233
step: 140, loss: 0.07779098302125931
step: 150, loss: 0.13861025869846344
step: 160, loss: 0.07798904180526733
step: 170, loss: 0.10647566616535187
step: 180, loss: 0.08329298347234726
step: 190, loss: 0.06759877502918243
step: 200, loss: 0.047883134335279465
step: 210, loss: 0.01738715171813965
step: 220, loss: 0.06987915188074112
step: 230, loss: 0.08549906313419342
step: 240, loss: 0.03975377976894379
step: 250, loss: 0.1622552126646042
step: 260, loss: 0.07457882910966873
step: 270, loss: 0.020571039989590645
step: 280, loss: 0.17859280109405518
step: 290, loss: 0.04737517982721329
step: 300, loss: 0.0838300958275795
step: 310, loss: 0.0152067756280303
step: 320, loss: 0.12955190241336823
step: 330, loss: 0.059059109538793564
step: 340, loss: 0.11022230237722397
step: 350, loss: 0.07267551124095917
step: 360, loss: 0.023841695860028267
epoch 11: dev_f1=0.7405405405405405, f1=0.6756756756756755, best_f1=0.7258064516129032
step: 0, loss: 0.12109155207872391
step: 10, loss: 0.028026646003127098
step: 20, loss: 0.058136235922575
step: 30, loss: 0.07977348566055298
step: 40, loss: 0.10225775092840195
step: 50, loss: 0.035673558712005615
step: 60, loss: 0.1158839613199234
step: 70, loss: 0.09838870912790298
step: 80, loss: 0.0479951947927475
step: 90, loss: 0.005331674125045538
step: 100, loss: 0.07207132875919342
step: 110, loss: 0.00432497588917613
step: 120, loss: 0.05015715956687927
step: 130, loss: 0.012833014130592346
step: 140, loss: 0.020990774035453796
step: 150, loss: 0.0950154960155487
step: 160, loss: 0.07693185657262802
step: 170, loss: 0.1254243701696396
step: 180, loss: 0.029838282614946365
step: 190, loss: 0.0321410596370697
step: 200, loss: 0.10807783156633377
step: 210, loss: 0.0947176069021225
step: 220, loss: 0.05042649060487747
step: 230, loss: 0.06467251479625702
step: 240, loss: 0.07714297622442245
step: 250, loss: 0.03693624958395958
step: 260, loss: 0.06686830520629883
step: 270, loss: 0.03609911724925041
step: 280, loss: 0.04914099723100662
step: 290, loss: 0.0050528934225440025
step: 300, loss: 0.05874500051140785
step: 310, loss: 0.05665936321020126
step: 320, loss: 0.04246009141206741
step: 330, loss: 0.06394314020872116
step: 340, loss: 0.1055605486035347
step: 350, loss: 0.0508001483976841
step: 360, loss: 0.05719892680644989
epoch 12: dev_f1=0.7671957671957672, f1=0.6923076923076923, best_f1=0.6923076923076923
step: 0, loss: 0.0930219516158104
step: 10, loss: 0.050457894802093506
step: 20, loss: 0.07597261667251587
step: 30, loss: 0.06399262696504593
step: 40, loss: 0.08402830362319946
step: 50, loss: 0.06804186850786209
step: 60, loss: 0.048427801579236984
step: 70, loss: 0.03869440406560898
step: 80, loss: 0.052090007811784744
step: 90, loss: 0.018640480935573578
step: 100, loss: 0.05632102116942406
step: 110, loss: 0.008448571898043156
step: 120, loss: 0.027652665972709656
step: 130, loss: 0.07251700013875961
step: 140, loss: 0.2501390874385834
step: 150, loss: 0.016350263729691505
step: 160, loss: 0.033223532140254974
step: 170, loss: 0.04375745356082916
step: 180, loss: 0.0733247622847557
step: 190, loss: 0.017233749851584435
step: 200, loss: 0.02809036709368229
step: 210, loss: 0.05021108314394951
step: 220, loss: 0.022139251232147217
step: 230, loss: 0.032830674201250076
step: 240, loss: 0.04142564535140991
step: 250, loss: 0.05488121509552002
step: 260, loss: 0.03883935511112213
step: 270, loss: 0.10279253125190735
step: 280, loss: 0.17333902418613434
step: 290, loss: 0.005359466653317213
step: 300, loss: 0.11637900024652481
step: 310, loss: 0.0746711790561676
step: 320, loss: 0.016839629039168358
step: 330, loss: 0.0206731166690588
step: 340, loss: 0.052983179688453674
step: 350, loss: 0.020466523244976997
step: 360, loss: 0.08865056931972504
epoch 13: dev_f1=0.7371007371007371, f1=0.7015706806282722, best_f1=0.6923076923076923
step: 0, loss: 0.040070828050374985
step: 10, loss: 0.044523078948259354
step: 20, loss: 0.1182435154914856
step: 30, loss: 0.010067246854305267
step: 40, loss: 0.005730551201850176
step: 50, loss: 0.02721332013607025
step: 60, loss: 0.06750847399234772
step: 70, loss: 0.0390390045940876
step: 80, loss: 0.1145607978105545
step: 90, loss: 0.02315904013812542
step: 100, loss: 0.0077358088456094265
step: 110, loss: 0.06877157837152481
step: 120, loss: 0.02233080193400383
step: 130, loss: 0.09291580319404602
step: 140, loss: 0.06763514876365662
step: 150, loss: 0.01861790008842945
step: 160, loss: 0.04862421005964279
step: 170, loss: 0.03115824982523918
step: 180, loss: 0.027809763327240944
step: 190, loss: 0.05176675692200661
step: 200, loss: 0.03041144460439682
step: 210, loss: 0.17678914964199066
step: 220, loss: 0.021118979901075363
step: 230, loss: 0.038164496421813965
step: 240, loss: 0.08166980743408203
step: 250, loss: 0.030279699712991714
step: 260, loss: 6.728141306666657e-05
step: 270, loss: 0.07126873731613159
step: 280, loss: 0.06924998015165329
step: 290, loss: 0.00029914191691204906
step: 300, loss: 0.029696093872189522
step: 310, loss: 0.03496047481894493
step: 320, loss: 0.012605398893356323
step: 330, loss: 0.037741683423519135
step: 340, loss: 0.05683817341923714
step: 350, loss: 0.006081966683268547
step: 360, loss: 0.041399035602808
epoch 14: dev_f1=0.7352185089974292, f1=0.7105263157894737, best_f1=0.6923076923076923
step: 0, loss: 0.05037929117679596
step: 10, loss: 0.02053111605346203
step: 20, loss: 0.04686493054032326
step: 30, loss: 0.12180060148239136
step: 40, loss: 0.026261955499649048
step: 50, loss: 0.046128273010253906
step: 60, loss: 0.02654438279569149
step: 70, loss: 0.0492718368768692
step: 80, loss: 0.027234448119997978
step: 90, loss: 0.05017802119255066
step: 100, loss: 0.1411651372909546
step: 110, loss: 0.00984086375683546
step: 120, loss: 0.012416037730872631
step: 130, loss: 0.03804419934749603
step: 140, loss: 0.05405355244874954
step: 150, loss: 0.01136204693466425
step: 160, loss: 0.08349611610174179
step: 170, loss: 0.08878227323293686
step: 180, loss: 0.0705629363656044
step: 190, loss: 0.014620018191635609
step: 200, loss: 0.044223617762327194
step: 210, loss: 0.05479763075709343
step: 220, loss: 0.009431839920580387
step: 230, loss: 0.043239034712314606
step: 240, loss: 0.01208979357033968
step: 250, loss: 0.08452745527029037
step: 260, loss: 0.0032648094929754734
step: 270, loss: 0.018611818552017212
step: 280, loss: 0.0001579983945703134
step: 290, loss: 0.004941046703606844
step: 300, loss: 0.044567547738552094
step: 310, loss: 0.024276556447148323
step: 320, loss: 0.0319950245320797
step: 330, loss: 0.04611298441886902
step: 340, loss: 0.03844357281923294
step: 350, loss: 0.10139402002096176
step: 360, loss: 0.13720430433750153
epoch 15: dev_f1=0.7321867321867322, f1=0.6923076923076923, best_f1=0.6923076923076923
step: 0, loss: 0.018867649137973785
step: 10, loss: 0.00029004557291045785
step: 20, loss: 0.05551031604409218
step: 30, loss: 0.06929440796375275
step: 40, loss: 0.026473520323634148
step: 50, loss: 0.0800594836473465
step: 60, loss: 0.017327196896076202
step: 70, loss: 0.020183254033327103
step: 80, loss: 0.048847947269678116
step: 90, loss: 0.12808947265148163
step: 100, loss: 0.009526236914098263
step: 110, loss: 0.018192211166024208
step: 120, loss: 0.022060006856918335
step: 130, loss: 0.07355117797851562
step: 140, loss: 0.021157439798116684
step: 150, loss: 0.020789925009012222
step: 160, loss: 0.13430428504943848
step: 170, loss: 0.039929408580064774
step: 180, loss: 0.017072737216949463
step: 190, loss: 0.09178837388753891
step: 200, loss: 0.03172677755355835
step: 210, loss: 0.06569068878889084
step: 220, loss: 0.002380179474130273
step: 230, loss: 0.08284838497638702
step: 240, loss: 0.03723204508423805
step: 250, loss: 0.09715530276298523
step: 260, loss: 0.023727549239993095
step: 270, loss: 0.02429014816880226
step: 280, loss: 0.051835138350725174
step: 290, loss: 0.06520971655845642
step: 300, loss: 0.016517823562026024
step: 310, loss: 0.060102738440036774
step: 320, loss: 0.04414509981870651
step: 330, loss: 0.0834551528096199
step: 340, loss: 0.03648420795798302
step: 350, loss: 0.08346813917160034
step: 360, loss: 0.030765101313591003
epoch 16: dev_f1=0.7320954907161804, f1=0.6906077348066297, best_f1=0.6923076923076923
step: 0, loss: 0.06926457583904266
step: 10, loss: 0.05620300769805908
step: 20, loss: 0.052218247205019
step: 30, loss: 0.02875078283250332
step: 40, loss: 0.00497426139190793
step: 50, loss: 0.06764634698629379
step: 60, loss: 0.007757207378745079
step: 70, loss: 0.05505746603012085
step: 80, loss: 0.020405661314725876
step: 90, loss: 0.02082575298845768
step: 100, loss: 0.03678877651691437
step: 110, loss: 0.050077568739652634
step: 120, loss: 0.040455520153045654
step: 130, loss: 0.09227675199508667
step: 140, loss: 0.0003363668511155993
step: 150, loss: 0.04180346056818962
step: 160, loss: 0.0030280184000730515
step: 170, loss: 0.007762535475194454
step: 180, loss: 0.0023800325579941273
step: 190, loss: 0.07395704090595245
step: 200, loss: 0.08529426902532578
step: 210, loss: 0.01953248493373394
step: 220, loss: 0.05232422426342964
step: 230, loss: 0.040052518248558044
step: 240, loss: 0.025616271421313286
step: 250, loss: 0.0182806309312582
step: 260, loss: 0.00238237576559186
step: 270, loss: 0.0696709081530571
step: 280, loss: 0.03511429578065872
step: 290, loss: 0.007518368307501078
step: 300, loss: 0.05418512597680092
step: 310, loss: 0.04006625711917877
step: 320, loss: 0.06497444957494736
step: 330, loss: 0.04322458431124687
step: 340, loss: 0.058527808636426926
step: 350, loss: 0.03467589616775513
step: 360, loss: 0.014832793734967709
epoch 17: dev_f1=0.7443037974683544, f1=0.7150259067357513, best_f1=0.6923076923076923
step: 0, loss: 0.04696871340274811
step: 10, loss: 0.04568016901612282
step: 20, loss: 2.6512501790421084e-05
step: 30, loss: 0.044413670897483826
step: 40, loss: 0.04361886531114578
step: 50, loss: 0.08767075836658478
step: 60, loss: 0.01799778826534748
step: 70, loss: 0.03536679968237877
step: 80, loss: 0.03077336587011814
step: 90, loss: 0.022772131487727165
step: 100, loss: 0.03079124540090561
step: 110, loss: 0.08747690916061401
step: 120, loss: 0.06444217264652252
step: 130, loss: 0.023210912942886353
step: 140, loss: 0.06458023190498352
step: 150, loss: 0.03590678051114082
step: 160, loss: 0.03001042641699314
step: 170, loss: 0.02657884731888771
step: 180, loss: 0.05484630912542343
step: 190, loss: 0.024769984185695648
step: 200, loss: 0.0014105717418715358
step: 210, loss: 0.02799401991069317
step: 220, loss: 0.023247143253684044
step: 230, loss: 0.05219956487417221
step: 240, loss: 0.02864721044898033
step: 250, loss: 7.084807293722406e-05
step: 260, loss: 0.006746647879481316
step: 270, loss: 0.11122182756662369
step: 280, loss: 0.01203210186213255
step: 290, loss: 0.08061299473047256
step: 300, loss: 0.061962854117155075
step: 310, loss: 0.07979533821344376
step: 320, loss: 0.028089720755815506
step: 330, loss: 0.03665003925561905
step: 340, loss: 0.09731075912714005
step: 350, loss: 0.0010079368948936462
step: 360, loss: 0.0022368566133081913
epoch 18: dev_f1=0.7331536388140162, f1=0.696629213483146, best_f1=0.6923076923076923
step: 0, loss: 0.05371252819895744
step: 10, loss: 0.009394606575369835
step: 20, loss: 0.07225055247545242
step: 30, loss: 0.03407489135861397
step: 40, loss: 0.0248134583234787
step: 50, loss: 0.008639737032353878
step: 60, loss: 0.005434017162770033
step: 70, loss: 0.0007516629411838949
step: 80, loss: 0.025575365871191025
step: 90, loss: 0.029573630541563034
step: 100, loss: 0.010425837710499763
step: 110, loss: 0.02504933811724186
step: 120, loss: 0.005156489089131355
step: 130, loss: 0.006575571373105049
step: 140, loss: 0.011657292023301125
step: 150, loss: 0.004594789817929268
step: 160, loss: 0.048872869461774826
step: 170, loss: 0.029824597761034966
step: 180, loss: 0.1010894775390625
step: 190, loss: 0.03224444389343262
step: 200, loss: 0.03054066002368927
step: 210, loss: 0.009306386113166809
step: 220, loss: 0.03123653680086136
step: 230, loss: 0.06926146894693375
step: 240, loss: 0.05158267542719841
step: 250, loss: 0.026175059378147125
step: 260, loss: 0.007705495692789555
step: 270, loss: 0.11162633448839188
step: 280, loss: 0.10003481805324554
step: 290, loss: 0.053152408450841904
step: 300, loss: 0.1439209133386612
step: 310, loss: 0.010651870630681515
step: 320, loss: 0.004124199040234089
step: 330, loss: 0.04767582193017006
step: 340, loss: 0.06950005143880844
step: 350, loss: 0.058779675513505936
step: 360, loss: 0.06413660943508148
epoch 19: dev_f1=0.7365728900255755, f1=0.6947368421052632, best_f1=0.6923076923076923
step: 0, loss: 0.12205171585083008
step: 10, loss: 0.0399974025785923
step: 20, loss: 0.015606704168021679
step: 30, loss: 0.04472675547003746
step: 40, loss: 0.00013779030996374786
step: 50, loss: 0.014999083243310452
step: 60, loss: 0.07891081273555756
step: 70, loss: 0.0555025078356266
step: 80, loss: 0.02842894196510315
step: 90, loss: 0.0618160106241703
step: 100, loss: 0.033499181270599365
step: 110, loss: 0.048133786767721176
step: 120, loss: 0.03082929737865925
step: 130, loss: 0.01959172636270523
step: 140, loss: 0.0345238596200943
step: 150, loss: 0.027523091062903404
step: 160, loss: 0.05952423810958862
step: 170, loss: 3.15227298415266e-05
step: 180, loss: 0.02687220647931099
step: 190, loss: 0.028804147616028786
step: 200, loss: 0.03810190409421921
step: 210, loss: 0.029587002471089363
step: 220, loss: 0.0007153056212700903
step: 230, loss: 0.04606817290186882
step: 240, loss: 0.004976381082087755
step: 250, loss: 0.004813170060515404
step: 260, loss: 0.014868983067572117
step: 270, loss: 0.029227368533611298
step: 280, loss: 0.02942577190697193
step: 290, loss: 0.034204550087451935
step: 300, loss: 0.0521886870265007
step: 310, loss: 0.05687152221798897
step: 320, loss: 0.01777513325214386
step: 330, loss: 0.13371393084526062
step: 340, loss: 0.025270599871873856
step: 350, loss: 0.06892925500869751
step: 360, loss: 0.04231097921729088
epoch 20: dev_f1=0.7428571428571429, f1=0.6861702127659575, best_f1=0.6923076923076923
