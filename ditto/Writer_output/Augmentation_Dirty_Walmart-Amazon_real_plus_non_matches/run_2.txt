cuda
Device: cuda
step: 0, loss: 0.6464435458183289
step: 10, loss: 0.17783194780349731
step: 20, loss: 0.1628655344247818
step: 30, loss: 0.2379237413406372
step: 40, loss: 0.3775366544723511
step: 50, loss: 0.31462499499320984
step: 60, loss: 0.04360699653625488
step: 70, loss: 0.14197951555252075
step: 80, loss: 0.23220577836036682
step: 90, loss: 0.233671173453331
step: 100, loss: 0.35708892345428467
step: 110, loss: 0.05816212669014931
step: 120, loss: 0.1482713520526886
step: 130, loss: 0.22971321642398834
step: 140, loss: 0.13393226265907288
step: 150, loss: 0.04676516354084015
step: 160, loss: 0.21192853152751923
step: 170, loss: 0.06634353846311569
step: 180, loss: 0.12254523485898972
step: 190, loss: 0.020891908556222916
step: 200, loss: 0.20334869623184204
step: 210, loss: 0.2703997790813446
step: 220, loss: 0.23866915702819824
step: 230, loss: 0.22530952095985413
step: 240, loss: 0.15457633137702942
step: 250, loss: 0.1340179294347763
step: 260, loss: 0.11691547185182571
step: 270, loss: 0.08885525912046432
step: 280, loss: 0.2398756742477417
step: 290, loss: 0.13676708936691284
step: 300, loss: 0.05138901621103287
step: 310, loss: 0.11168643087148666
step: 320, loss: 0.12379501014947891
step: 330, loss: 0.03566750884056091
step: 340, loss: 0.04544667899608612
step: 350, loss: 0.03798560053110123
step: 360, loss: 0.137643501162529
epoch 1: dev_f1=0.5391304347826088, f1=0.5491071428571429, best_f1=0.5491071428571429
step: 0, loss: 0.11249207705259323
step: 10, loss: 0.20610874891281128
step: 20, loss: 0.32671916484832764
step: 30, loss: 0.26613083481788635
step: 40, loss: 0.13990014791488647
step: 50, loss: 0.13412946462631226
step: 60, loss: 0.1627601683139801
step: 70, loss: 0.20137280225753784
step: 80, loss: 0.02660675346851349
step: 90, loss: 0.12359577417373657
step: 100, loss: 0.101223886013031
step: 110, loss: 0.1740494817495346
step: 120, loss: 0.08287188410758972
step: 130, loss: 0.12639255821704865
step: 140, loss: 0.252946138381958
step: 150, loss: 0.20863783359527588
step: 160, loss: 0.040266554802656174
step: 170, loss: 0.20971325039863586
step: 180, loss: 0.07537750154733658
step: 190, loss: 0.1830669492483139
step: 200, loss: 0.3431777358055115
step: 210, loss: 0.28995394706726074
step: 220, loss: 0.11637891829013824
step: 230, loss: 0.05934425815939903
step: 240, loss: 0.1044180765748024
step: 250, loss: 0.13788484036922455
step: 260, loss: 0.2210426926612854
step: 270, loss: 0.024761347100138664
step: 280, loss: 0.21668283641338348
step: 290, loss: 0.2642711400985718
step: 300, loss: 0.09754985570907593
step: 310, loss: 0.2571936547756195
step: 320, loss: 0.265531986951828
step: 330, loss: 0.18862800300121307
step: 340, loss: 0.24452896416187286
step: 350, loss: 0.034835826605558395
step: 360, loss: 0.1386701464653015
epoch 2: dev_f1=0.6821345707656613, f1=0.6853146853146854, best_f1=0.6853146853146854
step: 0, loss: 0.0901198461651802
step: 10, loss: 0.10583432018756866
step: 20, loss: 0.16274118423461914
step: 30, loss: 0.019605014473199844
step: 40, loss: 0.14272624254226685
step: 50, loss: 0.11406724900007248
step: 60, loss: 0.053584277629852295
step: 70, loss: 0.10001581162214279
step: 80, loss: 0.17938131093978882
step: 90, loss: 0.062494877725839615
step: 100, loss: 0.0883299708366394
step: 110, loss: 0.16057607531547546
step: 120, loss: 0.02635241113603115
step: 130, loss: 0.07347609102725983
step: 140, loss: 0.11514591425657272
step: 150, loss: 0.13007067143917084
step: 160, loss: 0.040621183812618256
step: 170, loss: 0.08503632992506027
step: 180, loss: 0.16687831282615662
step: 190, loss: 0.17770692706108093
step: 200, loss: 0.11645502597093582
step: 210, loss: 0.13094313442707062
step: 220, loss: 0.17120380699634552
step: 230, loss: 0.16066144406795502
step: 240, loss: 0.1373579204082489
step: 250, loss: 0.1425214260816574
step: 260, loss: 0.12712839245796204
step: 270, loss: 0.08669685572385788
step: 280, loss: 0.11666341125965118
step: 290, loss: 0.06584938615560532
step: 300, loss: 0.16958153247833252
step: 310, loss: 0.2626340389251709
step: 320, loss: 0.07604647427797318
step: 330, loss: 0.08481594175100327
step: 340, loss: 0.10270873457193375
step: 350, loss: 0.13449504971504211
step: 360, loss: 0.16692498326301575
epoch 3: dev_f1=0.7027027027027027, f1=0.7016706443914081, best_f1=0.7016706443914081
step: 0, loss: 0.08070523291826248
step: 10, loss: 0.22338856756687164
step: 20, loss: 0.03611576184630394
step: 30, loss: 0.15283966064453125
step: 40, loss: 0.06676484644412994
step: 50, loss: 0.09116408228874207
step: 60, loss: 0.11898820102214813
step: 70, loss: 0.06879720836877823
step: 80, loss: 0.15386173129081726
step: 90, loss: 0.03180546313524246
step: 100, loss: 0.09060847759246826
step: 110, loss: 0.06582634150981903
step: 120, loss: 0.07394026219844818
step: 130, loss: 0.003598189912736416
step: 140, loss: 0.15391504764556885
step: 150, loss: 0.10909643769264221
step: 160, loss: 0.039087045937776566
step: 170, loss: 0.0771399661898613
step: 180, loss: 0.06592429429292679
step: 190, loss: 0.056901417672634125
step: 200, loss: 0.0812368392944336
step: 210, loss: 0.08845865726470947
step: 220, loss: 0.155366450548172
step: 230, loss: 0.052016470581293106
step: 240, loss: 0.041284218430519104
step: 250, loss: 0.0989253893494606
step: 260, loss: 0.10657280683517456
step: 270, loss: 0.01670043356716633
step: 280, loss: 0.13025283813476562
step: 290, loss: 0.2306157350540161
step: 300, loss: 0.1768752932548523
step: 310, loss: 0.10689754784107208
step: 320, loss: 0.0798938199877739
step: 330, loss: 0.08705997467041016
step: 340, loss: 0.18413017690181732
step: 350, loss: 0.05594012141227722
step: 360, loss: 0.15641707181930542
epoch 4: dev_f1=0.6886792452830188, f1=0.6941747572815534, best_f1=0.7016706443914081
step: 0, loss: 0.05881271883845329
step: 10, loss: 0.051866646856069565
step: 20, loss: 0.36045387387275696
step: 30, loss: 0.07684668153524399
step: 40, loss: 0.08229624480009079
step: 50, loss: 0.17579761147499084
step: 60, loss: 0.03749160096049309
step: 70, loss: 0.10699038952589035
step: 80, loss: 0.011056399904191494
step: 90, loss: 0.046990517526865005
step: 100, loss: 0.03560061380267143
step: 110, loss: 0.07642437517642975
step: 120, loss: 0.07134778052568436
step: 130, loss: 0.12827123701572418
step: 140, loss: 0.017761824652552605
step: 150, loss: 0.05990711972117424
step: 160, loss: 0.09516067802906036
step: 170, loss: 0.02719130553305149
step: 180, loss: 0.1447077840566635
step: 190, loss: 0.020464453846216202
step: 200, loss: 0.05266282334923744
step: 210, loss: 0.06603249162435532
step: 220, loss: 0.11701063811779022
step: 230, loss: 0.06282517313957214
step: 240, loss: 0.07186753302812576
step: 250, loss: 0.06674126535654068
step: 260, loss: 0.02910131774842739
step: 270, loss: 0.04060712084174156
step: 280, loss: 0.04475124180316925
step: 290, loss: 0.06303887069225311
step: 300, loss: 0.11866559833288193
step: 310, loss: 0.08563444763422012
step: 320, loss: 0.10350637137889862
step: 330, loss: 0.07760992646217346
step: 340, loss: 0.006859305314719677
step: 350, loss: 0.055556558072566986
step: 360, loss: 0.09596027433872223
epoch 5: dev_f1=0.7175925925925926, f1=0.691764705882353, best_f1=0.691764705882353
step: 0, loss: 0.10509607940912247
step: 10, loss: 0.14512281119823456
step: 20, loss: 0.030539384111762047
step: 30, loss: 0.06922399252653122
step: 40, loss: 0.04167957603931427
step: 50, loss: 0.08046896755695343
step: 60, loss: 0.059962790459394455
step: 70, loss: 0.07676756381988525
step: 80, loss: 0.024473674595355988
step: 90, loss: 0.12572212517261505
step: 100, loss: 0.06856688112020493
step: 110, loss: 0.08687742054462433
step: 120, loss: 0.03374696522951126
step: 130, loss: 0.06969154626131058
step: 140, loss: 0.1467076539993286
step: 150, loss: 0.09374158084392548
step: 160, loss: 0.04181860014796257
step: 170, loss: 0.1255032867193222
step: 180, loss: 0.048167310655117035
step: 190, loss: 0.13495786488056183
step: 200, loss: 0.042551010847091675
step: 210, loss: 0.13487409055233002
step: 220, loss: 0.19683662056922913
step: 230, loss: 0.04145428538322449
step: 240, loss: 0.029284900054335594
step: 250, loss: 0.024300402030348778
step: 260, loss: 0.1467771828174591
step: 270, loss: 0.04957731440663338
step: 280, loss: 0.02860160730779171
step: 290, loss: 0.2929159998893738
step: 300, loss: 0.1313183456659317
step: 310, loss: 0.030149735510349274
step: 320, loss: 0.03397025913000107
step: 330, loss: 0.1584313064813614
step: 340, loss: 0.02714110165834427
step: 350, loss: 0.04403792321681976
step: 360, loss: 0.12315091490745544
epoch 6: dev_f1=0.7276995305164319, f1=0.676470588235294, best_f1=0.676470588235294
step: 0, loss: 0.06951113045215607
step: 10, loss: 0.05498169735074043
step: 20, loss: 0.06953372061252594
step: 30, loss: 0.030972108244895935
step: 40, loss: 0.1367838978767395
step: 50, loss: 0.0767822116613388
step: 60, loss: 0.042577434331178665
step: 70, loss: 0.08104756474494934
step: 80, loss: 0.2133214771747589
step: 90, loss: 0.014637716114521027
step: 100, loss: 0.09519640356302261
step: 110, loss: 0.08243679255247116
step: 120, loss: 0.05651083216071129
step: 130, loss: 0.03626437112689018
step: 140, loss: 0.05380092188715935
step: 150, loss: 0.08797872066497803
step: 160, loss: 0.08995628356933594
step: 170, loss: 0.03363507613539696
step: 180, loss: 0.037903524935245514
step: 190, loss: 0.17307278513908386
step: 200, loss: 0.16739590466022491
step: 210, loss: 0.05962047725915909
step: 220, loss: 0.11361978203058243
step: 230, loss: 0.14092223346233368
step: 240, loss: 0.10397057980298996
step: 250, loss: 0.00278526172041893
step: 260, loss: 0.08013468235731125
step: 270, loss: 0.06858491897583008
step: 280, loss: 0.13278600573539734
step: 290, loss: 0.043968476355075836
step: 300, loss: 0.05997737869620323
step: 310, loss: 0.06436364352703094
step: 320, loss: 0.05683829262852669
step: 330, loss: 0.13131235539913177
step: 340, loss: 0.02517339400947094
step: 350, loss: 0.03637181967496872
step: 360, loss: 0.031112007796764374
epoch 7: dev_f1=0.7544303797468355, f1=0.7029702970297028, best_f1=0.7029702970297028
step: 0, loss: 0.06374712288379669
step: 10, loss: 0.04843541979789734
step: 20, loss: 0.02806861139833927
step: 30, loss: 0.03199804574251175
step: 40, loss: 0.07131581753492355
step: 50, loss: 0.043180953711271286
step: 60, loss: 0.03741578012704849
step: 70, loss: 0.022406522184610367
step: 80, loss: 0.09519049525260925
step: 90, loss: 0.0589032918214798
step: 100, loss: 0.08510562032461166
step: 110, loss: 0.10613014549016953
step: 120, loss: 0.05059101805090904
step: 130, loss: 0.0884258896112442
step: 140, loss: 0.025821074843406677
step: 150, loss: 0.05340044945478439
step: 160, loss: 0.03650979697704315
step: 170, loss: 0.12700225412845612
step: 180, loss: 0.07603025436401367
step: 190, loss: 0.03786958009004593
step: 200, loss: 0.10774923861026764
step: 210, loss: 0.10919441282749176
step: 220, loss: 0.08113577216863632
step: 230, loss: 0.08791499584913254
step: 240, loss: 0.022789180278778076
step: 250, loss: 0.057706207036972046
step: 260, loss: 0.09016735106706619
step: 270, loss: 0.06350669264793396
step: 280, loss: 0.12002474069595337
step: 290, loss: 0.13754993677139282
step: 300, loss: 0.053462427109479904
step: 310, loss: 0.03143933415412903
step: 320, loss: 0.12705890834331512
step: 330, loss: 0.11410504579544067
step: 340, loss: 0.09470885992050171
step: 350, loss: 0.05577055737376213
step: 360, loss: 0.07073143124580383
epoch 8: dev_f1=0.719047619047619, f1=0.7146282973621103, best_f1=0.7029702970297028
step: 0, loss: 0.08246532827615738
step: 10, loss: 0.10671314597129822
step: 20, loss: 0.11033154278993607
step: 30, loss: 0.0920596644282341
step: 40, loss: 0.15863052010536194
step: 50, loss: 0.05547141656279564
step: 60, loss: 0.04457370191812515
step: 70, loss: 0.09372974932193756
step: 80, loss: 0.04708762466907501
step: 90, loss: 0.006456139497458935
step: 100, loss: 0.012371097691357136
step: 110, loss: 0.04914239048957825
step: 120, loss: 0.01104583777487278
step: 130, loss: 0.08796565234661102
step: 140, loss: 0.03162653371691704
step: 150, loss: 0.032784901559352875
step: 160, loss: 0.07963261008262634
step: 170, loss: 5.951038474449888e-05
step: 180, loss: 0.15208564698696136
step: 190, loss: 0.0763312578201294
step: 200, loss: 0.02417122758924961
step: 210, loss: 0.0919988825917244
step: 220, loss: 0.01882445625960827
step: 230, loss: 0.07744663953781128
step: 240, loss: 0.09086810052394867
step: 250, loss: 0.03195147216320038
step: 260, loss: 0.11237593740224838
step: 270, loss: 0.042046044021844864
step: 280, loss: 0.06805821508169174
step: 290, loss: 0.08089404553174973
step: 300, loss: 0.04109400883316994
step: 310, loss: 0.03503769636154175
step: 320, loss: 0.06715170294046402
step: 330, loss: 0.1377255618572235
step: 340, loss: 0.044069644063711166
step: 350, loss: 0.02077733352780342
step: 360, loss: 0.17683742940425873
epoch 9: dev_f1=0.7156862745098039, f1=0.6990291262135921, best_f1=0.7029702970297028
step: 0, loss: 0.025260653346776962
step: 10, loss: 0.21299408376216888
step: 20, loss: 0.06241440773010254
step: 30, loss: 0.06334186345338821
step: 40, loss: 0.03163620084524155
step: 50, loss: 0.03851526603102684
step: 60, loss: 0.00040188798448070884
step: 70, loss: 0.030035505071282387
step: 80, loss: 0.09634871780872345
step: 90, loss: 0.027133779600262642
step: 100, loss: 0.0248100645840168
step: 110, loss: 0.07402993738651276
step: 120, loss: 0.059767454862594604
step: 130, loss: 0.04859507828950882
step: 140, loss: 0.0303579680621624
step: 150, loss: 0.05398596078157425
step: 160, loss: 0.045658692717552185
step: 170, loss: 0.025873275473713875
step: 180, loss: 0.03818042203783989
step: 190, loss: 0.04983668029308319
step: 200, loss: 0.03620843216776848
step: 210, loss: 0.03692268952727318
step: 220, loss: 0.048710089176893234
step: 230, loss: 0.14393532276153564
step: 240, loss: 0.055106401443481445
step: 250, loss: 0.11875926703214645
step: 260, loss: 0.059808697551488876
step: 270, loss: 0.04340001940727234
step: 280, loss: 0.15251566469669342
step: 290, loss: 0.009967800229787827
step: 300, loss: 0.0479695089161396
step: 310, loss: 0.00044407701352611184
step: 320, loss: 0.058047134429216385
step: 330, loss: 0.04613541066646576
step: 340, loss: 0.04310053214430809
step: 350, loss: 0.01581379771232605
step: 360, loss: 9.438630513614044e-05
epoch 10: dev_f1=0.7314578005115089, f1=0.7022900763358778, best_f1=0.7029702970297028
step: 0, loss: 0.019187767058610916
step: 10, loss: 0.07273802906274796
step: 20, loss: 0.13059847056865692
step: 30, loss: 0.041905052959918976
step: 40, loss: 0.06126292422413826
step: 50, loss: 0.04712241142988205
step: 60, loss: 0.03686686232686043
step: 70, loss: 0.05102304369211197
step: 80, loss: 0.06429076194763184
step: 90, loss: 0.03807417303323746
step: 100, loss: 0.055943313986063004
step: 110, loss: 0.020621804520487785
step: 120, loss: 0.07293760031461716
step: 130, loss: 0.10807917267084122
step: 140, loss: 0.08920431137084961
step: 150, loss: 0.02531570754945278
step: 160, loss: 0.10088762640953064
step: 170, loss: 0.07224536687135696
step: 180, loss: 0.04236893355846405
step: 190, loss: 0.07405074685811996
step: 200, loss: 0.06271515786647797
step: 210, loss: 0.08290635049343109
step: 220, loss: 0.06054482236504555
step: 230, loss: 0.1871885508298874
step: 240, loss: 0.02320941351354122
step: 250, loss: 0.00022881769109517336
step: 260, loss: 0.04162383824586868
step: 270, loss: 0.10587146133184433
step: 280, loss: 0.018465545028448105
step: 290, loss: 0.07345418632030487
step: 300, loss: 0.04445841535925865
step: 310, loss: 0.03858357295393944
step: 320, loss: 0.04332449287176132
step: 330, loss: 0.08274296671152115
step: 340, loss: 0.03632213547825813
step: 350, loss: 0.05686516687273979
step: 360, loss: 0.06143706664443016
epoch 11: dev_f1=0.741687979539642, f1=0.6852791878172589, best_f1=0.7029702970297028
step: 0, loss: 0.00022965826792642474
step: 10, loss: 0.07438192516565323
step: 20, loss: 0.10730729252099991
step: 30, loss: 0.09089630842208862
step: 40, loss: 0.04385754466056824
step: 50, loss: 0.01667238213121891
step: 60, loss: 0.09617757052183151
step: 70, loss: 0.04269300028681755
step: 80, loss: 0.06955539435148239
step: 90, loss: 0.06879610568284988
step: 100, loss: 0.09196833521127701
step: 110, loss: 0.09601499885320663
step: 120, loss: 0.02117074467241764
step: 130, loss: 0.008463864214718342
step: 140, loss: 0.04822040721774101
step: 150, loss: 0.0409526601433754
step: 160, loss: 0.08699969202280045
step: 170, loss: 0.006011459976434708
step: 180, loss: 0.00868474505841732
step: 190, loss: 0.0002821820671670139
step: 200, loss: 0.03469095751643181
step: 210, loss: 0.08836394548416138
step: 220, loss: 0.08789520710706711
step: 230, loss: 0.03472514450550079
step: 240, loss: 0.12827996909618378
step: 250, loss: 0.0640476867556572
step: 260, loss: 0.06911968439817429
step: 270, loss: 0.03727572411298752
step: 280, loss: 0.045280952006578445
step: 290, loss: 0.0005861070239916444
step: 300, loss: 0.04242025688290596
step: 310, loss: 0.042546603828668594
step: 320, loss: 0.06282082945108414
step: 330, loss: 0.05055601894855499
step: 340, loss: 0.018452133983373642
step: 350, loss: 0.08117827028036118
step: 360, loss: 0.03030790388584137
epoch 12: dev_f1=0.7325301204819277, f1=0.6904761904761906, best_f1=0.7029702970297028
step: 0, loss: 0.05254899710416794
step: 10, loss: 0.03603212535381317
step: 20, loss: 0.1837935596704483
step: 30, loss: 0.03273257985711098
step: 40, loss: 0.008952056989073753
step: 50, loss: 0.049077462404966354
step: 60, loss: 0.0242206621915102
step: 70, loss: 0.0003323160344734788
step: 80, loss: 0.05149155855178833
step: 90, loss: 0.03723391145467758
step: 100, loss: 0.12382664531469345
step: 110, loss: 0.05200020596385002
step: 120, loss: 0.0606468990445137
step: 130, loss: 0.10606438666582108
step: 140, loss: 0.03349187597632408
step: 150, loss: 0.11989607661962509
step: 160, loss: 0.0774368941783905
step: 170, loss: 0.06225571408867836
step: 180, loss: 0.08951059728860855
step: 190, loss: 0.05996264889836311
step: 200, loss: 0.015676159411668777
step: 210, loss: 0.06436439603567123
step: 220, loss: 0.024431198835372925
step: 230, loss: 0.039172589778900146
step: 240, loss: 0.04546353965997696
step: 250, loss: 0.03129168599843979
step: 260, loss: 0.07593148201704025
step: 270, loss: 0.0689777359366417
step: 280, loss: 0.000714586116373539
step: 290, loss: 0.029165515676140785
step: 300, loss: 0.0060455072671175
step: 310, loss: 0.10849335044622421
step: 320, loss: 0.050455451011657715
step: 330, loss: 0.026133550330996513
step: 340, loss: 0.015362736769020557
step: 350, loss: 0.08972601592540741
step: 360, loss: 0.00013458094326779246
epoch 13: dev_f1=0.7346938775510203, f1=0.7025641025641026, best_f1=0.7029702970297028
step: 0, loss: 0.0418650358915329
step: 10, loss: 0.026448853313922882
step: 20, loss: 0.047032635658979416
step: 30, loss: 0.022978002205491066
step: 40, loss: 0.012356490828096867
step: 50, loss: 0.016286905854940414
step: 60, loss: 0.022220240905880928
step: 70, loss: 0.013690761290490627
step: 80, loss: 0.07971199601888657
step: 90, loss: 0.01696963980793953
step: 100, loss: 0.04427118971943855
step: 110, loss: 0.03660641983151436
step: 120, loss: 0.0819222629070282
step: 130, loss: 0.06875474750995636
step: 140, loss: 0.060449812561273575
step: 150, loss: 0.03480982780456543
step: 160, loss: 0.056614287197589874
step: 170, loss: 0.08308418095111847
step: 180, loss: 0.05310172960162163
step: 190, loss: 0.00013704464072361588
step: 200, loss: 0.10580836981534958
step: 210, loss: 0.0784393846988678
step: 220, loss: 0.013348911888897419
step: 230, loss: 0.003430417040362954
step: 240, loss: 0.06577461957931519
step: 250, loss: 0.14643296599388123
step: 260, loss: 0.042646374553442
step: 270, loss: 0.0806308314204216
step: 280, loss: 0.07752678543329239
step: 290, loss: 0.01819753088057041
step: 300, loss: 0.047607582062482834
step: 310, loss: 0.04080972075462341
step: 320, loss: 0.016905497759580612
step: 330, loss: 0.05173575133085251
step: 340, loss: 0.04820176959037781
step: 350, loss: 0.03641149029135704
step: 360, loss: 0.051507871598005295
epoch 14: dev_f1=0.7373493975903614, f1=0.6842105263157895, best_f1=0.7029702970297028
step: 0, loss: 0.0815761387348175
step: 10, loss: 0.008304692804813385
step: 20, loss: 0.009127658791840076
step: 30, loss: 0.12188027799129486
step: 40, loss: 0.01155281625688076
step: 50, loss: 0.12395080924034119
step: 60, loss: 0.02889670431613922
step: 70, loss: 0.12310686707496643
step: 80, loss: 0.02782745659351349
step: 90, loss: 0.017111288383603096
step: 100, loss: 0.0933813750743866
step: 110, loss: 0.016400521621108055
step: 120, loss: 0.00466088205575943
step: 130, loss: 0.04634028673171997
step: 140, loss: 0.06671332567930222
step: 150, loss: 0.07227090001106262
step: 160, loss: 0.01590590924024582
step: 170, loss: 0.0297872181981802
step: 180, loss: 0.022164389491081238
step: 190, loss: 0.042728491127491
step: 200, loss: 0.009732173755764961
step: 210, loss: 0.07367337495088577
step: 220, loss: 0.08771815150976181
step: 230, loss: 0.05560343340039253
step: 240, loss: 0.034689564257860184
step: 250, loss: 0.047950197011232376
step: 260, loss: 0.04422888532280922
step: 270, loss: 0.02273724041879177
step: 280, loss: 0.02058059722185135
step: 290, loss: 9.894788672681898e-05
step: 300, loss: 0.08659239113330841
step: 310, loss: 0.060191355645656586
step: 320, loss: 0.043969325721263885
step: 330, loss: 0.021090606227517128
step: 340, loss: 0.005087056662887335
step: 350, loss: 0.088057741522789
step: 360, loss: 0.07739842683076859
epoch 15: dev_f1=0.7455012853470436, f1=0.7268041237113403, best_f1=0.7029702970297028
step: 0, loss: 0.005206987727433443
step: 10, loss: 0.09896772354841232
step: 20, loss: 0.11710222065448761
step: 30, loss: 0.019968733191490173
step: 40, loss: 0.002304079942405224
step: 50, loss: 0.05541491508483887
step: 60, loss: 0.09875118732452393
step: 70, loss: 0.06871529668569565
step: 80, loss: 0.016346408054232597
step: 90, loss: 0.004316221456974745
step: 100, loss: 0.017010662704706192
step: 110, loss: 0.012691687792539597
step: 120, loss: 0.006246459670364857
step: 130, loss: 0.025844227522611618
step: 140, loss: 0.04595831409096718
step: 150, loss: 0.1334415078163147
step: 160, loss: 0.10179752111434937
step: 170, loss: 0.11638248711824417
step: 180, loss: 0.018456676974892616
step: 190, loss: 0.006917793769389391
step: 200, loss: 0.011000287719070911
step: 210, loss: 0.05791686847805977
step: 220, loss: 0.0023680757731199265
step: 230, loss: 0.04203707352280617
step: 240, loss: 0.02466592937707901
step: 250, loss: 0.03992493823170662
step: 260, loss: 0.0611131452023983
step: 270, loss: 0.05984451621770859
step: 280, loss: 0.06029129400849342
step: 290, loss: 0.3487040102481842
step: 300, loss: 0.08620565384626389
step: 310, loss: 0.10427536815404892
step: 320, loss: 0.06785427033901215
step: 330, loss: 0.14231784641742706
step: 340, loss: 0.08398545533418655
step: 350, loss: 0.001040496164932847
step: 360, loss: 0.060343578457832336
epoch 16: dev_f1=0.7420147420147422, f1=0.7073170731707316, best_f1=0.7029702970297028
step: 0, loss: 0.03313382342457771
step: 10, loss: 0.06503694504499435
step: 20, loss: 0.1166916936635971
step: 30, loss: 0.04949093610048294
step: 40, loss: 0.009319866076111794
step: 50, loss: 0.012769362889230251
step: 60, loss: 0.06902330368757248
step: 70, loss: 0.004092455375939608
step: 80, loss: 0.012541004456579685
step: 90, loss: 0.02692173607647419
step: 100, loss: 0.11849639564752579
step: 110, loss: 0.0049942112527787685
step: 120, loss: 0.01368086226284504
step: 130, loss: 7.278172415681183e-05
step: 140, loss: 0.0020829313434660435
step: 150, loss: 0.07087821513414383
step: 160, loss: 0.02668716013431549
step: 170, loss: 0.024891719222068787
step: 180, loss: 0.05683550611138344
step: 190, loss: 0.05773264914751053
step: 200, loss: 0.07726364582777023
step: 210, loss: 0.019483255222439766
step: 220, loss: 0.03609709069132805
step: 230, loss: 0.082797572016716
step: 240, loss: 0.14743739366531372
step: 250, loss: 0.053341373801231384
step: 260, loss: 0.009171498008072376
step: 270, loss: 0.005607074126601219
step: 280, loss: 0.010617695748806
step: 290, loss: 0.005491248797625303
step: 300, loss: 0.0014924100833013654
step: 310, loss: 0.04307042807340622
step: 320, loss: 0.07390272617340088
step: 330, loss: 0.030094029381871223
step: 340, loss: 0.00031783871236257255
step: 350, loss: 0.03687569871544838
step: 360, loss: 0.09146943688392639
epoch 17: dev_f1=0.7286063569682152, f1=0.6780487804878049, best_f1=0.7029702970297028
step: 0, loss: 0.030570901930332184
step: 10, loss: 0.07358724623918533
step: 20, loss: 0.01688442938029766
step: 30, loss: 0.037665337324142456
step: 40, loss: 0.029375849291682243
step: 50, loss: 0.03890353441238403
step: 60, loss: 0.06401453912258148
step: 70, loss: 0.04954872652888298
step: 80, loss: 0.00042949276394210756
step: 90, loss: 0.026365188881754875
step: 100, loss: 0.00887991487979889
step: 110, loss: 0.03130770102143288
step: 120, loss: 0.030109822750091553
step: 130, loss: 0.04021714627742767
step: 140, loss: 0.09752655774354935
step: 150, loss: 0.013176387175917625
step: 160, loss: 0.0686618760228157
step: 170, loss: 0.10273321717977524
step: 180, loss: 0.001156978658400476
step: 190, loss: 0.013590370304882526
step: 200, loss: 0.009757251478731632
step: 210, loss: 0.02897707000374794
step: 220, loss: 0.08125562965869904
step: 230, loss: 0.0974925234913826
step: 240, loss: 0.032347798347473145
step: 250, loss: 0.13356588780879974
step: 260, loss: 0.13986165821552277
step: 270, loss: 0.04840751364827156
step: 280, loss: 0.17288926243782043
step: 290, loss: 0.03485766053199768
step: 300, loss: 0.05346263200044632
step: 310, loss: 0.04648149758577347
step: 320, loss: 0.009082315489649773
step: 330, loss: 0.031616080552339554
step: 340, loss: 0.017262523993849754
step: 350, loss: 0.05501657351851463
step: 360, loss: 0.034817297011613846
epoch 18: dev_f1=0.7440633245382585, f1=0.7105263157894737, best_f1=0.7029702970297028
step: 0, loss: 0.017279841005802155
step: 10, loss: 5.6776894780341536e-05
step: 20, loss: 0.04289669543504715
step: 30, loss: 0.06474969536066055
step: 40, loss: 0.08581690490245819
step: 50, loss: 0.0006228811107575893
step: 60, loss: 0.05111652985215187
step: 70, loss: 0.029247211292386055
step: 80, loss: 0.09075861424207687
step: 90, loss: 0.002002494875341654
step: 100, loss: 0.008900096639990807
step: 110, loss: 0.004545527510344982
step: 120, loss: 0.07772251218557358
step: 130, loss: 0.059139225631952286
step: 140, loss: 0.02704516425728798
step: 150, loss: 0.07597281783819199
step: 160, loss: 0.03259821981191635
step: 170, loss: 0.0023970291949808598
step: 180, loss: 0.007857748307287693
step: 190, loss: 0.13251550495624542
step: 200, loss: 0.001760020386427641
step: 210, loss: 0.06351028382778168
step: 220, loss: 0.014328579418361187
step: 230, loss: 0.013024549931287766
step: 240, loss: 0.018299056217074394
step: 250, loss: 0.03818243741989136
step: 260, loss: 0.03630036115646362
step: 270, loss: 0.013139587827026844
step: 280, loss: 0.01805262640118599
step: 290, loss: 0.0376993827521801
step: 300, loss: 0.03736335411667824
step: 310, loss: 0.022184694185853004
step: 320, loss: 0.02600925602018833
step: 330, loss: 0.0056869215331971645
step: 340, loss: 0.018274463713169098
step: 350, loss: 0.13217206299304962
step: 360, loss: 0.0020120376721024513
epoch 19: dev_f1=0.7390180878552972, f1=0.7043701799485862, best_f1=0.7029702970297028
step: 0, loss: 0.011026579886674881
step: 10, loss: 0.10437073558568954
step: 20, loss: 0.0013661201810464263
step: 30, loss: 0.012140518054366112
step: 40, loss: 0.006542020011693239
step: 50, loss: 0.06353118270635605
step: 60, loss: 0.08437874913215637
step: 70, loss: 0.0005157751147635281
step: 80, loss: 3.271785317338072e-05
step: 90, loss: 0.029475493356585503
step: 100, loss: 0.003719995031133294
step: 110, loss: 0.02498893067240715
step: 120, loss: 0.04173862561583519
step: 130, loss: 0.00776823190972209
step: 140, loss: 0.007821624167263508
step: 150, loss: 0.03775421530008316
step: 160, loss: 0.0001654257212067023
step: 170, loss: 0.029789071530103683
step: 180, loss: 0.006234185770153999
step: 190, loss: 0.00017254338308703154
step: 200, loss: 0.006517153233289719
step: 210, loss: 0.01388727780431509
step: 220, loss: 0.03789559379220009
step: 230, loss: 0.04929928109049797
step: 240, loss: 0.021785881370306015
step: 250, loss: 0.049292173236608505
step: 260, loss: 0.017410174012184143
step: 270, loss: 0.018576059490442276
step: 280, loss: 0.04879701882600784
step: 290, loss: 0.046549178659915924
step: 300, loss: 0.0002630040980875492
step: 310, loss: 0.12079397588968277
step: 320, loss: 0.0006324534770101309
step: 330, loss: 0.08551034331321716
step: 340, loss: 0.2960951030254364
step: 350, loss: 8.784151577856392e-05
step: 360, loss: 0.00036099355202168226
epoch 20: dev_f1=0.7393617021276595, f1=0.7124010554089709, best_f1=0.7029702970297028
