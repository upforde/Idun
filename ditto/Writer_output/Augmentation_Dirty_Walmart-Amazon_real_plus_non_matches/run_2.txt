cuda
Device: cuda
step: 0, loss: 0.742333710193634
step: 10, loss: 0.24793753027915955
step: 20, loss: 0.4575485289096832
step: 30, loss: 0.090115487575531
step: 40, loss: 0.03027508221566677
step: 50, loss: 0.047464001923799515
step: 60, loss: 0.03607366606593132
step: 70, loss: 0.13526540994644165
step: 80, loss: 0.13007782399654388
step: 90, loss: 0.4717249870300293
step: 100, loss: 0.15824271738529205
step: 110, loss: 0.13744474947452545
step: 120, loss: 0.2395956814289093
step: 130, loss: 0.21652232110500336
step: 140, loss: 0.21578171849250793
step: 150, loss: 0.1468798816204071
step: 160, loss: 0.13154715299606323
step: 170, loss: 0.03715071082115173
step: 180, loss: 0.21679887175559998
step: 190, loss: 0.2706759572029114
step: 200, loss: 0.11781045794487
step: 210, loss: 0.34142017364501953
step: 220, loss: 0.04489539936184883
step: 230, loss: 0.19896185398101807
step: 240, loss: 0.2432454377412796
step: 250, loss: 0.15203729271888733
step: 260, loss: 0.014113013632595539
step: 270, loss: 0.13546794652938843
step: 280, loss: 0.09876274317502975
step: 290, loss: 0.0903947576880455
step: 300, loss: 0.1283213347196579
step: 310, loss: 0.07138790190219879
step: 320, loss: 0.1027659997344017
step: 330, loss: 0.15909257531166077
step: 340, loss: 0.14762632548809052
step: 350, loss: 0.21207892894744873
step: 360, loss: 0.17160092294216156
epoch 1: dev_f1=0.5722222222222222, f1=0.5978835978835979, best_f1=0.5978835978835979
step: 0, loss: 0.1041000708937645
step: 10, loss: 0.17039722204208374
step: 20, loss: 0.04369742050766945
step: 30, loss: 0.084178127348423
step: 40, loss: 0.09788734465837479
step: 50, loss: 0.044768597930669785
step: 60, loss: 0.12354198098182678
step: 70, loss: 0.16235247254371643
step: 80, loss: 0.10597269237041473
step: 90, loss: 0.18881607055664062
step: 100, loss: 0.14282214641571045
step: 110, loss: 0.3844035565853119
step: 120, loss: 0.21965010464191437
step: 130, loss: 0.18415740132331848
step: 140, loss: 0.026828281581401825
step: 150, loss: 0.05548050254583359
step: 160, loss: 0.18940934538841248
step: 170, loss: 0.10150425136089325
step: 180, loss: 0.01628187671303749
step: 190, loss: 0.22387643158435822
step: 200, loss: 0.10731635987758636
step: 210, loss: 0.1333896368741989
step: 220, loss: 0.024719011038541794
step: 230, loss: 0.1231703832745552
step: 240, loss: 0.09330753237009048
step: 250, loss: 0.13550403714179993
step: 260, loss: 0.1724550724029541
step: 270, loss: 0.12906882166862488
step: 280, loss: 0.14042653143405914
step: 290, loss: 0.08716023713350296
step: 300, loss: 0.085835300385952
step: 310, loss: 0.04428985342383385
step: 320, loss: 0.1886540949344635
step: 330, loss: 0.18053333461284637
step: 340, loss: 0.09020226448774338
step: 350, loss: 0.17382733523845673
step: 360, loss: 0.10589790344238281
epoch 2: dev_f1=0.6685393258426966, f1=0.6894736842105263, best_f1=0.6894736842105263
step: 0, loss: 0.15349100530147552
step: 10, loss: 0.17186009883880615
step: 20, loss: 0.05224503576755524
step: 30, loss: 0.12351878732442856
step: 40, loss: 0.11287451535463333
step: 50, loss: 0.019306769594550133
step: 60, loss: 0.037372130900621414
step: 70, loss: 0.23228830099105835
step: 80, loss: 0.02353793941438198
step: 90, loss: 0.17194689810276031
step: 100, loss: 0.14324292540550232
step: 110, loss: 0.11932820826768875
step: 120, loss: 0.10862026363611221
step: 130, loss: 0.08606534451246262
step: 140, loss: 0.06386131048202515
step: 150, loss: 0.1151886060833931
step: 160, loss: 0.09848081320524216
step: 170, loss: 0.10691208392381668
step: 180, loss: 0.13238897919654846
step: 190, loss: 0.05178750306367874
step: 200, loss: 0.10396246612071991
step: 210, loss: 0.09292131662368774
step: 220, loss: 0.12002147734165192
step: 230, loss: 0.09249132871627808
step: 240, loss: 0.14453621208667755
step: 250, loss: 0.14741410315036774
step: 260, loss: 0.0932588130235672
step: 270, loss: 0.05922737717628479
step: 280, loss: 0.08108238875865936
step: 290, loss: 0.06727495044469833
step: 300, loss: 0.10148429870605469
step: 310, loss: 0.0922740176320076
step: 320, loss: 0.019651295617222786
step: 330, loss: 0.11264597624540329
step: 340, loss: 0.21550582349300385
step: 350, loss: 0.14953969419002533
step: 360, loss: 0.12564720213413239
epoch 3: dev_f1=0.6389496717724289, f1=0.6860986547085202, best_f1=0.6894736842105263
step: 0, loss: 0.019725237041711807
step: 10, loss: 0.05226743966341019
step: 20, loss: 0.12928584218025208
step: 30, loss: 0.09555653482675552
step: 40, loss: 0.1156865656375885
step: 50, loss: 0.11635155975818634
step: 60, loss: 0.0860217958688736
step: 70, loss: 0.06350990384817123
step: 80, loss: 0.07052706927061081
step: 90, loss: 0.0005522001883946359
step: 100, loss: 0.039751071482896805
step: 110, loss: 0.10962603241205215
step: 120, loss: 0.04520975798368454
step: 130, loss: 0.0643574446439743
step: 140, loss: 0.08367561548948288
step: 150, loss: 0.18576253950595856
step: 160, loss: 0.1087142676115036
step: 170, loss: 0.07620012760162354
step: 180, loss: 0.10396227985620499
step: 190, loss: 0.19563411176204681
step: 200, loss: 0.06766591966152191
step: 210, loss: 0.1454956829547882
step: 220, loss: 0.13672921061515808
step: 230, loss: 0.15039972960948944
step: 240, loss: 0.06984322518110275
step: 250, loss: 0.18704035878181458
step: 260, loss: 0.1858859807252884
step: 270, loss: 0.16810977458953857
step: 280, loss: 0.11992251873016357
step: 290, loss: 0.005547418259084225
step: 300, loss: 0.0933319702744484
step: 310, loss: 0.1885433793067932
step: 320, loss: 0.05883084982633591
step: 330, loss: 0.13034550845623016
step: 340, loss: 0.08241068571805954
step: 350, loss: 0.07065872848033905
step: 360, loss: 0.11161468178033829
epoch 4: dev_f1=0.7365591397849462, f1=0.7214854111405835, best_f1=0.7214854111405835
step: 0, loss: 0.09045224636793137
step: 10, loss: 0.061886660754680634
step: 20, loss: 0.1519966721534729
step: 30, loss: 0.08887218683958054
step: 40, loss: 0.14808788895606995
step: 50, loss: 0.019015764817595482
step: 60, loss: 0.06998402625322342
step: 70, loss: 0.03814270347356796
step: 80, loss: 0.04402925446629524
step: 90, loss: 0.0667710229754448
step: 100, loss: 0.05258794128894806
step: 110, loss: 0.019966473802924156
step: 120, loss: 0.0197233147919178
step: 130, loss: 0.13690775632858276
step: 140, loss: 0.0762191042304039
step: 150, loss: 0.0390043780207634
step: 160, loss: 0.09256324917078018
step: 170, loss: 0.09628227353096008
step: 180, loss: 0.04932119697332382
step: 190, loss: 0.11492356657981873
step: 200, loss: 0.0889502465724945
step: 210, loss: 0.10996297001838684
step: 220, loss: 0.07409678399562836
step: 230, loss: 0.09164537489414215
step: 240, loss: 0.0075686597265303135
step: 250, loss: 0.11109760403633118
step: 260, loss: 0.05369914695620537
step: 270, loss: 0.05225222557783127
step: 280, loss: 0.09401261806488037
step: 290, loss: 0.08441145718097687
step: 300, loss: 0.056083422154188156
step: 310, loss: 0.2772802710533142
step: 320, loss: 0.10467050224542618
step: 330, loss: 0.09121242165565491
step: 340, loss: 0.04669788107275963
step: 350, loss: 0.09491663426160812
step: 360, loss: 0.09545841068029404
epoch 5: dev_f1=0.7294685990338164, f1=0.7107843137254902, best_f1=0.7214854111405835
step: 0, loss: 0.04073331505060196
step: 10, loss: 0.09050511568784714
step: 20, loss: 0.1167936772108078
step: 30, loss: 0.09139624238014221
step: 40, loss: 0.10227954387664795
step: 50, loss: 0.050020284950733185
step: 60, loss: 0.011518017388880253
step: 70, loss: 0.10551954060792923
step: 80, loss: 0.046720925718545914
step: 90, loss: 0.047233231365680695
step: 100, loss: 0.18694093823432922
step: 110, loss: 0.10909911245107651
step: 120, loss: 0.07629053294658661
step: 130, loss: 0.05944887921214104
step: 140, loss: 0.09066065400838852
step: 150, loss: 0.2730824053287506
step: 160, loss: 0.02698718011379242
step: 170, loss: 0.08798667043447495
step: 180, loss: 0.0952916145324707
step: 190, loss: 0.11662090569734573
step: 200, loss: 0.06870148330926895
step: 210, loss: 0.08895586431026459
step: 220, loss: 0.13979259133338928
step: 230, loss: 0.08229663223028183
step: 240, loss: 0.08192428946495056
step: 250, loss: 0.13625721633434296
step: 260, loss: 0.08308716118335724
step: 270, loss: 0.07451862096786499
step: 280, loss: 0.06545031070709229
step: 290, loss: 0.02669292502105236
step: 300, loss: 0.14067059755325317
step: 310, loss: 0.07282936573028564
step: 320, loss: 0.019579218700528145
step: 330, loss: 0.03444894030690193
step: 340, loss: 0.16320082545280457
step: 350, loss: 0.04225969687104225
step: 360, loss: 0.058993369340896606
epoch 6: dev_f1=0.6776859504132231, f1=0.6927374301675977, best_f1=0.7214854111405835
step: 0, loss: 0.05379484221339226
step: 10, loss: 0.0357348769903183
step: 20, loss: 0.042940206825733185
step: 30, loss: 0.09611790627241135
step: 40, loss: 0.03981396183371544
step: 50, loss: 0.06384305655956268
step: 60, loss: 0.06803702563047409
step: 70, loss: 0.04924970120191574
step: 80, loss: 0.07518559694290161
step: 90, loss: 0.08413807302713394
step: 100, loss: 0.081366628408432
step: 110, loss: 0.010343651287257671
step: 120, loss: 0.041871022433042526
step: 130, loss: 0.12516507506370544
step: 140, loss: 0.08114299923181534
step: 150, loss: 0.13877932727336884
step: 160, loss: 0.06964322179555893
step: 170, loss: 0.05134282261133194
step: 180, loss: 0.034933581948280334
step: 190, loss: 0.11020879447460175
step: 200, loss: 0.12484483420848846
step: 210, loss: 0.02633916772902012
step: 220, loss: 0.0861288532614708
step: 230, loss: 0.10595165193080902
step: 240, loss: 0.12225539982318878
step: 250, loss: 0.02766261249780655
step: 260, loss: 0.12114407122135162
step: 270, loss: 0.08445680886507034
step: 280, loss: 0.17648138105869293
step: 290, loss: 0.06308767199516296
step: 300, loss: 0.09245187789201736
step: 310, loss: 0.13854800164699554
step: 320, loss: 0.10465696454048157
step: 330, loss: 0.045207712799310684
step: 340, loss: 0.018762359395623207
step: 350, loss: 0.025747444480657578
step: 360, loss: 0.07177925109863281
epoch 7: dev_f1=0.7187499999999999, f1=0.7150259067357513, best_f1=0.7214854111405835
step: 0, loss: 0.026442745700478554
step: 10, loss: 0.03865129500627518
step: 20, loss: 0.06854894757270813
step: 30, loss: 0.04200894385576248
step: 40, loss: 0.031369540840387344
step: 50, loss: 0.09867585450410843
step: 60, loss: 0.08326179534196854
step: 70, loss: 0.13829520344734192
step: 80, loss: 0.04728126898407936
step: 90, loss: 0.003927300218492746
step: 100, loss: 0.04010651633143425
step: 110, loss: 0.08759389817714691
step: 120, loss: 0.11346308887004852
step: 130, loss: 0.07131973654031754
step: 140, loss: 0.018963966518640518
step: 150, loss: 0.0006997891468927264
step: 160, loss: 0.09252453595399857
step: 170, loss: 0.03617621585726738
step: 180, loss: 0.05880354717373848
step: 190, loss: 0.0701964795589447
step: 200, loss: 0.10107644647359848
step: 210, loss: 0.03805004805326462
step: 220, loss: 0.10501234233379364
step: 230, loss: 0.039733950048685074
step: 240, loss: 0.04796327278017998
step: 250, loss: 0.025091156363487244
step: 260, loss: 0.14858770370483398
step: 270, loss: 0.060224499553442
step: 280, loss: 0.042938120663166046
step: 290, loss: 0.03911706432700157
step: 300, loss: 0.042515870183706284
step: 310, loss: 0.023937126621603966
step: 320, loss: 0.020012592896819115
step: 330, loss: 0.08122024685144424
step: 340, loss: 0.02514069899916649
step: 350, loss: 0.04662572219967842
step: 360, loss: 0.057386595755815506
epoch 8: dev_f1=0.7546174142480211, f1=0.7371273712737126, best_f1=0.7371273712737126
step: 0, loss: 0.02328488975763321
step: 10, loss: 0.0821910947561264
step: 20, loss: 0.11229898035526276
step: 30, loss: 0.03755748271942139
step: 40, loss: 0.03089064545929432
step: 50, loss: 0.07862073928117752
step: 60, loss: 0.05910301208496094
step: 70, loss: 0.05782768130302429
step: 80, loss: 0.20109106600284576
step: 90, loss: 0.03531302884221077
step: 100, loss: 0.028098447248339653
step: 110, loss: 0.01215929351747036
step: 120, loss: 0.03474380448460579
step: 130, loss: 0.033957790583372116
step: 140, loss: 0.03440665453672409
step: 150, loss: 0.030532734468579292
step: 160, loss: 0.07060739398002625
step: 170, loss: 0.02836751751601696
step: 180, loss: 0.06302139163017273
step: 190, loss: 0.05067746713757515
step: 200, loss: 0.0751594677567482
step: 210, loss: 0.08636385202407837
step: 220, loss: 0.10723148286342621
step: 230, loss: 0.0434679239988327
step: 240, loss: 0.08915776759386063
step: 250, loss: 0.020400363951921463
step: 260, loss: 0.08243289589881897
step: 270, loss: 0.11970730870962143
step: 280, loss: 0.021667027845978737
step: 290, loss: 0.08843913674354553
step: 300, loss: 0.06129397079348564
step: 310, loss: 0.022355610504746437
step: 320, loss: 0.04582446813583374
step: 330, loss: 0.011320601217448711
step: 340, loss: 0.07582104951143265
step: 350, loss: 0.042701609432697296
step: 360, loss: 0.023974213749170303
epoch 9: dev_f1=0.7479674796747967, f1=0.707182320441989, best_f1=0.7371273712737126
step: 0, loss: 0.09880281984806061
step: 10, loss: 0.04795239120721817
step: 20, loss: 0.018801016733050346
step: 30, loss: 0.13203205168247223
step: 40, loss: 0.0458916611969471
step: 50, loss: 0.014950018376111984
step: 60, loss: 0.035063985735177994
step: 70, loss: 0.01637890748679638
step: 80, loss: 0.05826462432742119
step: 90, loss: 0.088044673204422
step: 100, loss: 0.11936318129301071
step: 110, loss: 0.1242244616150856
step: 120, loss: 0.010639895685017109
step: 130, loss: 0.03433491662144661
step: 140, loss: 0.1343359351158142
step: 150, loss: 0.09401504695415497
step: 160, loss: 0.12513813376426697
step: 170, loss: 0.0665392354130745
step: 180, loss: 0.09036421030759811
step: 190, loss: 0.13097065687179565
step: 200, loss: 0.034192558377981186
step: 210, loss: 0.021223273128271103
step: 220, loss: 0.014088690280914307
step: 230, loss: 0.06393544375896454
step: 240, loss: 0.04016914591193199
step: 250, loss: 0.03266920894384384
step: 260, loss: 0.04536714404821396
step: 270, loss: 0.05971226096153259
step: 280, loss: 0.09999386221170425
step: 290, loss: 0.04439404979348183
step: 300, loss: 0.09614251554012299
step: 310, loss: 0.05597614496946335
step: 320, loss: 0.13664011657238007
step: 330, loss: 0.07995069026947021
step: 340, loss: 0.07920967787504196
step: 350, loss: 0.02263704687356949
step: 360, loss: 0.04977802559733391
epoch 10: dev_f1=0.7239583333333334, f1=0.7008086253369272, best_f1=0.7371273712737126
step: 0, loss: 0.08679357171058655
step: 10, loss: 0.11588490009307861
step: 20, loss: 0.0038298475556075573
step: 30, loss: 0.07610586285591125
step: 40, loss: 0.011267462745308876
step: 50, loss: 0.1367928683757782
step: 60, loss: 0.0076245772652328014
step: 70, loss: 0.12057729810476303
step: 80, loss: 0.14102156460285187
step: 90, loss: 0.044552017003297806
step: 100, loss: 0.054430995136499405
step: 110, loss: 0.05660111457109451
step: 120, loss: 0.025496359914541245
step: 130, loss: 0.15187054872512817
step: 140, loss: 0.09492029249668121
step: 150, loss: 0.07523350417613983
step: 160, loss: 0.04006856679916382
step: 170, loss: 0.15476924180984497
step: 180, loss: 0.10664606839418411
step: 190, loss: 0.05592852085828781
step: 200, loss: 0.13519856333732605
step: 210, loss: 0.001611055457033217
step: 220, loss: 0.0024234787560999393
step: 230, loss: 0.01423614751547575
step: 240, loss: 0.13527700304985046
step: 250, loss: 0.037665955722332
step: 260, loss: 0.051599644124507904
step: 270, loss: 0.05899554118514061
step: 280, loss: 0.06447094678878784
step: 290, loss: 0.0866287499666214
step: 300, loss: 0.06105324625968933
step: 310, loss: 0.00015339019591920078
step: 320, loss: 0.06631893664598465
step: 330, loss: 0.14912079274654388
step: 340, loss: 0.03332826867699623
step: 350, loss: 0.015011521987617016
step: 360, loss: 0.1100645437836647
epoch 11: dev_f1=0.761904761904762, f1=0.7135416666666666, best_f1=0.7135416666666666
step: 0, loss: 0.0955156683921814
step: 10, loss: 0.08576969057321548
step: 20, loss: 0.06139552965760231
step: 30, loss: 0.03206896036863327
step: 40, loss: 0.06311862170696259
step: 50, loss: 4.377073855721392e-05
step: 60, loss: 0.08606041967868805
step: 70, loss: 0.024600567296147346
step: 80, loss: 0.026279203593730927
step: 90, loss: 0.13817355036735535
step: 100, loss: 0.2059505581855774
step: 110, loss: 0.022653238847851753
step: 120, loss: 0.019121281802654266
step: 130, loss: 0.034058745950460434
step: 140, loss: 0.046409640461206436
step: 150, loss: 0.038341883569955826
step: 160, loss: 0.028297342360019684
step: 170, loss: 0.025885524228215218
step: 180, loss: 0.03466426208615303
step: 190, loss: 0.06456316262483597
step: 200, loss: 0.07239458709955215
step: 210, loss: 0.07175303995609283
step: 220, loss: 0.024381181225180626
step: 230, loss: 0.0062102703377604485
step: 240, loss: 0.054524797946214676
step: 250, loss: 0.06974329054355621
step: 260, loss: 0.018677331507205963
step: 270, loss: 0.03221263363957405
step: 280, loss: 0.02084946073591709
step: 290, loss: 0.03474307432770729
step: 300, loss: 0.07928898185491562
step: 310, loss: 0.017180072143673897
step: 320, loss: 0.06449227780103683
step: 330, loss: 0.042859598994255066
step: 340, loss: 0.07776366174221039
step: 350, loss: 0.0445699468255043
step: 360, loss: 0.04491288587450981
epoch 12: dev_f1=0.7263681592039801, f1=0.7236180904522613, best_f1=0.7135416666666666
step: 0, loss: 0.04273566976189613
step: 10, loss: 0.12805604934692383
step: 20, loss: 0.10095828771591187
step: 30, loss: 0.02539980039000511
step: 40, loss: 0.030267959460616112
step: 50, loss: 0.042940083891153336
step: 60, loss: 0.17284587025642395
step: 70, loss: 0.07193082571029663
step: 80, loss: 0.010653087869286537
step: 90, loss: 0.049013860523700714
step: 100, loss: 0.01610087789595127
step: 110, loss: 0.07474277168512344
step: 120, loss: 0.040022604167461395
step: 130, loss: 0.17404447495937347
step: 140, loss: 0.017307698726654053
step: 150, loss: 0.0697876513004303
step: 160, loss: 0.01200513169169426
step: 170, loss: 0.0851990133523941
step: 180, loss: 0.007689326535910368
step: 190, loss: 0.016691531985998154
step: 200, loss: 0.033177051693201065
step: 210, loss: 0.05635880306363106
step: 220, loss: 0.0268225260078907
step: 230, loss: 0.07626929879188538
step: 240, loss: 0.013951655477285385
step: 250, loss: 0.01325554121285677
step: 260, loss: 0.000357496872311458
step: 270, loss: 0.03560847416520119
step: 280, loss: 0.05316179618239403
step: 290, loss: 0.03852183371782303
step: 300, loss: 0.07493667304515839
step: 310, loss: 0.026137812063097954
step: 320, loss: 0.13559849560260773
step: 330, loss: 0.02577677182853222
step: 340, loss: 0.00022903212811797857
step: 350, loss: 0.05347733199596405
step: 360, loss: 0.08848623186349869
epoch 13: dev_f1=0.7200000000000001, f1=0.7024128686327078, best_f1=0.7135416666666666
step: 0, loss: 0.026427781209349632
step: 10, loss: 0.007119533605873585
step: 20, loss: 0.058220990002155304
step: 30, loss: 0.027974000200629234
step: 40, loss: 0.006419776007533073
step: 50, loss: 0.07434026896953583
step: 60, loss: 0.008519568480551243
step: 70, loss: 0.1280999630689621
step: 80, loss: 0.07297281920909882
step: 90, loss: 0.08955658227205276
step: 100, loss: 0.06798794865608215
step: 110, loss: 0.01981094665825367
step: 120, loss: 9.000748104881495e-05
step: 130, loss: 0.07451677322387695
step: 140, loss: 0.06944990158081055
step: 150, loss: 0.07773589342832565
step: 160, loss: 0.22272473573684692
step: 170, loss: 0.15372776985168457
step: 180, loss: 0.0810922309756279
step: 190, loss: 0.10806763917207718
step: 200, loss: 0.057053595781326294
step: 210, loss: 0.07976485788822174
step: 220, loss: 0.0662928968667984
step: 230, loss: 0.013896647840738297
step: 240, loss: 0.06347052752971649
step: 250, loss: 0.04516313597559929
step: 260, loss: 0.03638271987438202
step: 270, loss: 0.03989315405488014
step: 280, loss: 0.03482823446393013
step: 290, loss: 0.036165546625852585
step: 300, loss: 0.03224014863371849
step: 310, loss: 0.024768320843577385
step: 320, loss: 0.06137216463685036
step: 330, loss: 0.026017898693680763
step: 340, loss: 0.025958586484193802
step: 350, loss: 0.035667162388563156
step: 360, loss: 0.08142964541912079
epoch 14: dev_f1=0.7196029776674937, f1=0.7230769230769232, best_f1=0.7135416666666666
step: 0, loss: 0.03352416306734085
step: 10, loss: 0.02790158800780773
step: 20, loss: 0.07000038027763367
step: 30, loss: 0.02303256094455719
step: 40, loss: 0.03390061482787132
step: 50, loss: 0.039545077830553055
step: 60, loss: 0.03132491186261177
step: 70, loss: 0.0397527776658535
step: 80, loss: 0.07144679129123688
step: 90, loss: 0.009979534894227982
step: 100, loss: 0.05944279208779335
step: 110, loss: 0.002010541269555688
step: 120, loss: 0.020513594150543213
step: 130, loss: 0.043951068073511124
step: 140, loss: 0.04091368988156319
step: 150, loss: 0.025937240570783615
step: 160, loss: 0.07132051885128021
step: 170, loss: 0.025501728057861328
step: 180, loss: 0.021721720695495605
step: 190, loss: 0.006385871674865484
step: 200, loss: 0.03515307232737541
step: 210, loss: 0.023624107241630554
step: 220, loss: 0.1506013423204422
step: 230, loss: 0.05461899936199188
step: 240, loss: 0.07552264630794525
step: 250, loss: 0.09239645302295685
step: 260, loss: 0.00791774969547987
step: 270, loss: 0.08795212209224701
step: 280, loss: 0.06353432685136795
step: 290, loss: 0.06175393983721733
step: 300, loss: 0.20620201528072357
step: 310, loss: 0.05800849199295044
step: 320, loss: 0.06238279864192009
step: 330, loss: 0.017903150990605354
step: 340, loss: 0.02787504717707634
step: 350, loss: 0.08485148102045059
step: 360, loss: 0.02268132194876671
epoch 15: dev_f1=0.7277227722772278, f1=0.6969696969696969, best_f1=0.7135416666666666
step: 0, loss: 0.05750994011759758
step: 10, loss: 0.00044001147034578025
step: 20, loss: 0.020931977778673172
step: 30, loss: 0.07111068814992905
step: 40, loss: 0.11618880182504654
step: 50, loss: 0.110999695956707
step: 60, loss: 0.025154542177915573
step: 70, loss: 0.04808402433991432
step: 80, loss: 0.02614700235426426
step: 90, loss: 0.03986523672938347
step: 100, loss: 0.05829067900776863
step: 110, loss: 0.05451207980513573
step: 120, loss: 0.018184363842010498
step: 130, loss: 0.048369716852903366
step: 140, loss: 0.13536125421524048
step: 150, loss: 0.023687757551670074
step: 160, loss: 0.04048094525933266
step: 170, loss: 0.03937714546918869
step: 180, loss: 0.020154200494289398
step: 190, loss: 0.02510211244225502
step: 200, loss: 0.05608723312616348
step: 210, loss: 0.08713904023170471
step: 220, loss: 0.015002807602286339
step: 230, loss: 0.026435447856783867
step: 240, loss: 0.045988261699676514
step: 250, loss: 0.05227276682853699
step: 260, loss: 0.05646222457289696
step: 270, loss: 0.04219871759414673
step: 280, loss: 0.09141584485769272
step: 290, loss: 0.04503321275115013
step: 300, loss: 0.12021385133266449
step: 310, loss: 0.06763342022895813
step: 320, loss: 0.033368196338415146
step: 330, loss: 0.03657975420355797
step: 340, loss: 0.035494424402713776
step: 350, loss: 0.09945163875818253
step: 360, loss: 0.016177630051970482
epoch 16: dev_f1=0.7257617728531854, f1=0.6648199445983378, best_f1=0.7135416666666666
step: 0, loss: 0.026140503585338593
step: 10, loss: 0.0959729477763176
step: 20, loss: 0.005248579196631908
step: 30, loss: 0.008788524195551872
step: 40, loss: 0.03906981274485588
step: 50, loss: 0.00757801067084074
step: 60, loss: 0.08612359315156937
step: 70, loss: 0.07035446912050247
step: 80, loss: 0.04793553054332733
step: 90, loss: 0.006618571933358908
step: 100, loss: 0.007915944792330265
step: 110, loss: 0.0008020579698495567
step: 120, loss: 0.1022394523024559
step: 130, loss: 0.06476641446352005
step: 140, loss: 0.10916164517402649
step: 150, loss: 0.03521265834569931
step: 160, loss: 0.017518360167741776
step: 170, loss: 0.02753131091594696
step: 180, loss: 0.1079326868057251
step: 190, loss: 0.026101581752300262
step: 200, loss: 0.01386323757469654
step: 210, loss: 0.04584292322397232
step: 220, loss: 0.009772232733666897
step: 230, loss: 0.002803529379889369
step: 240, loss: 0.03920085355639458
step: 250, loss: 0.04327942430973053
step: 260, loss: 0.04026929289102554
step: 270, loss: 0.07628826051950455
step: 280, loss: 0.08397568762302399
step: 290, loss: 0.022659117355942726
step: 300, loss: 0.01223628968000412
step: 310, loss: 0.0592975914478302
step: 320, loss: 0.005904398392885923
step: 330, loss: 0.08539752662181854
step: 340, loss: 0.047130659222602844
step: 350, loss: 0.02810010500252247
step: 360, loss: 0.0919341966509819
epoch 17: dev_f1=0.7282051282051282, f1=0.7091836734693878, best_f1=0.7135416666666666
step: 0, loss: 0.023341497406363487
step: 10, loss: 0.051751017570495605
step: 20, loss: 0.004791730549186468
step: 30, loss: 0.05224102735519409
step: 40, loss: 0.055794451385736465
step: 50, loss: 0.08110048621892929
step: 60, loss: 0.10763207077980042
step: 70, loss: 0.02854948118329048
step: 80, loss: 0.035919442772865295
step: 90, loss: 0.029942553490400314
step: 100, loss: 0.05591978877782822
step: 110, loss: 0.06559110432863235
step: 120, loss: 0.008128189481794834
step: 130, loss: 0.057388752698898315
step: 140, loss: 0.030757147818803787
step: 150, loss: 0.01838097907602787
step: 160, loss: 0.02745511755347252
step: 170, loss: 0.016446972265839577
step: 180, loss: 0.03951000049710274
step: 190, loss: 0.11175497621297836
step: 200, loss: 0.12313231080770493
step: 210, loss: 0.12040381133556366
step: 220, loss: 0.00117160240188241
step: 230, loss: 0.04228401556611061
step: 240, loss: 0.0402500256896019
step: 250, loss: 0.026185650378465652
step: 260, loss: 0.05419442802667618
step: 270, loss: 0.07490302622318268
step: 280, loss: 3.1775442039361224e-05
step: 290, loss: 0.04304172471165657
step: 300, loss: 0.006053881719708443
step: 310, loss: 0.03420748934149742
step: 320, loss: 0.05330505594611168
step: 330, loss: 0.01763726957142353
step: 340, loss: 0.01797487400472164
step: 350, loss: 0.04149806126952171
step: 360, loss: 0.06247715279459953
epoch 18: dev_f1=0.721227621483376, f1=0.7028423772609819, best_f1=0.7135416666666666
step: 0, loss: 0.003937068395316601
step: 10, loss: 0.007407654542475939
step: 20, loss: 0.0018615858862176538
step: 30, loss: 0.006521630100905895
step: 40, loss: 0.02430485002696514
step: 50, loss: 0.023127321153879166
step: 60, loss: 0.018089216202497482
step: 70, loss: 0.030580196529626846
step: 80, loss: 0.008843939751386642
step: 90, loss: 0.031859658658504486
step: 100, loss: 0.024856548756361008
step: 110, loss: 0.01425965130329132
step: 120, loss: 0.11040428280830383
step: 130, loss: 0.08369981497526169
step: 140, loss: 0.0018209291156381369
step: 150, loss: 0.08696083724498749
step: 160, loss: 0.03394007310271263
step: 170, loss: 0.011372094042599201
step: 180, loss: 0.002797044115141034
step: 190, loss: 0.0011921594850718975
step: 200, loss: 0.02600395493209362
step: 210, loss: 0.0149112269282341
step: 220, loss: 0.06566809117794037
step: 230, loss: 0.16649188101291656
step: 240, loss: 0.020554840564727783
step: 250, loss: 0.0253995880484581
step: 260, loss: 8.343473746208474e-05
step: 270, loss: 0.0013258890248835087
step: 280, loss: 0.09265700727701187
step: 290, loss: 0.11637630313634872
step: 300, loss: 0.026014186441898346
step: 310, loss: 0.007463955320417881
step: 320, loss: 0.038701266050338745
step: 330, loss: 0.04095687344670296
step: 340, loss: 0.054618000984191895
step: 350, loss: 0.08267239481210709
step: 360, loss: 0.0929548591375351
epoch 19: dev_f1=0.7100271002710027, f1=0.7036011080332409, best_f1=0.7135416666666666
step: 0, loss: 0.10309017449617386
step: 10, loss: 0.02556603215634823
step: 20, loss: 0.08897940069437027
step: 30, loss: 0.11346465349197388
step: 40, loss: 0.016803860664367676
step: 50, loss: 0.03545170649886131
step: 60, loss: 0.020886193960905075
step: 70, loss: 0.09232237935066223
step: 80, loss: 0.04210248962044716
step: 90, loss: 0.009497849270701408
step: 100, loss: 0.06547703593969345
step: 110, loss: 0.0006344455177895725
step: 120, loss: 0.08469484746456146
step: 130, loss: 0.03577204421162605
step: 140, loss: 3.248347275075503e-05
step: 150, loss: 0.02007044479250908
step: 160, loss: 0.10024113953113556
step: 170, loss: 0.034770868718624115
step: 180, loss: 0.0002823268878273666
step: 190, loss: 0.04619988799095154
step: 200, loss: 0.009478980675339699
step: 210, loss: 0.06782466173171997
step: 220, loss: 0.0643792524933815
step: 230, loss: 0.018003087490797043
step: 240, loss: 0.08608625084161758
step: 250, loss: 0.049013614654541016
step: 260, loss: 0.008258501999080181
step: 270, loss: 0.019734540954232216
step: 280, loss: 0.06359802186489105
step: 290, loss: 0.0024634632281959057
step: 300, loss: 0.04118368402123451
step: 310, loss: 0.13505010306835175
step: 320, loss: 0.050181422382593155
step: 330, loss: 0.031952038407325745
step: 340, loss: 0.04678121209144592
step: 350, loss: 0.07157420367002487
step: 360, loss: 0.012195847928524017
epoch 20: dev_f1=0.7061994609164419, f1=0.7032967032967032, best_f1=0.7135416666666666
