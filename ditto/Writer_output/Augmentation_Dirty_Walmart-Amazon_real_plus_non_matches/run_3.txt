cuda
Device: cuda
step: 0, loss: 0.7048178911209106
step: 10, loss: 0.00763201666995883
step: 20, loss: 0.38404780626296997
step: 30, loss: 0.14418897032737732
step: 40, loss: 0.24209600687026978
step: 50, loss: 0.05761140584945679
step: 60, loss: 0.22788730263710022
step: 70, loss: 0.1450130194425583
step: 80, loss: 0.059740226715803146
step: 90, loss: 0.036065585911273956
step: 100, loss: 0.13881337642669678
step: 110, loss: 0.08602551370859146
step: 120, loss: 0.12438726425170898
step: 130, loss: 0.03370768204331398
step: 140, loss: 0.39476466178894043
step: 150, loss: 0.2146422266960144
step: 160, loss: 0.16461004316806793
step: 170, loss: 0.13465502858161926
step: 180, loss: 0.3337334990501404
step: 190, loss: 0.3222986161708832
step: 200, loss: 0.1294124275445938
step: 210, loss: 0.1161578968167305
step: 220, loss: 0.14049787819385529
step: 230, loss: 0.17094673216342926
step: 240, loss: 0.18213874101638794
step: 250, loss: 0.02052168920636177
step: 260, loss: 0.28072237968444824
step: 270, loss: 0.16868993639945984
step: 280, loss: 0.2605092525482178
step: 290, loss: 0.13555753231048584
step: 300, loss: 0.14450019598007202
step: 310, loss: 0.19186538457870483
step: 320, loss: 0.47253039479255676
step: 330, loss: 0.25947532057762146
step: 340, loss: 0.11509154736995697
step: 350, loss: 0.30216333270072937
step: 360, loss: 0.07599464803934097
epoch 1: dev_f1=0.6625386996904025, f1=0.6272189349112427, best_f1=0.6272189349112427
step: 0, loss: 0.2020021229982376
step: 10, loss: 0.10116701573133469
step: 20, loss: 0.09819652885198593
step: 30, loss: 0.10851867496967316
step: 40, loss: 0.11316055059432983
step: 50, loss: 0.4297545850276947
step: 60, loss: 0.2479211837053299
step: 70, loss: 0.07450545579195023
step: 80, loss: 0.24301353096961975
step: 90, loss: 0.03958984464406967
step: 100, loss: 0.08735309541225433
step: 110, loss: 0.3730980455875397
step: 120, loss: 0.029401510953903198
step: 130, loss: 0.3156842887401581
step: 140, loss: 0.12428724765777588
step: 150, loss: 0.06704496592283249
step: 160, loss: 0.14837141335010529
step: 170, loss: 0.040786489844322205
step: 180, loss: 0.183223694562912
step: 190, loss: 0.1407570242881775
step: 200, loss: 0.12220724672079086
step: 210, loss: 0.18124108016490936
step: 220, loss: 0.16564927995204926
step: 230, loss: 0.09068509936332703
step: 240, loss: 0.3450835943222046
step: 250, loss: 0.20860901474952698
step: 260, loss: 0.21426256000995636
step: 270, loss: 0.3139871656894684
step: 280, loss: 0.10466627776622772
step: 290, loss: 0.208618625998497
step: 300, loss: 0.050116561353206635
step: 310, loss: 0.12409429252147675
step: 320, loss: 0.1163063496351242
step: 330, loss: 0.041081734001636505
step: 340, loss: 0.13812442123889923
step: 350, loss: 0.0018960795132443309
step: 360, loss: 0.0940217450261116
epoch 2: dev_f1=0.7407407407407407, f1=0.7308641975308642, best_f1=0.7308641975308642
step: 0, loss: 0.17494624853134155
step: 10, loss: 0.1661331057548523
step: 20, loss: 0.09519656002521515
step: 30, loss: 0.11490009725093842
step: 40, loss: 0.09449197351932526
step: 50, loss: 0.07415325939655304
step: 60, loss: 0.0729934573173523
step: 70, loss: 0.24243390560150146
step: 80, loss: 0.08093594759702682
step: 90, loss: 0.1304904669523239
step: 100, loss: 0.07416802644729614
step: 110, loss: 0.28116071224212646
step: 120, loss: 0.10699682682752609
step: 130, loss: 0.10232914984226227
step: 140, loss: 0.17756034433841705
step: 150, loss: 0.06647744029760361
step: 160, loss: 0.0461980439722538
step: 170, loss: 0.07977776974439621
step: 180, loss: 0.17193686962127686
step: 190, loss: 0.15641266107559204
step: 200, loss: 0.10452890396118164
step: 210, loss: 0.12556438148021698
step: 220, loss: 0.1871817708015442
step: 230, loss: 0.13080328702926636
step: 240, loss: 0.08760302513837814
step: 250, loss: 0.15336287021636963
step: 260, loss: 0.06957482546567917
step: 270, loss: 0.03076278604567051
step: 280, loss: 0.24366305768489838
step: 290, loss: 0.04184235259890556
step: 300, loss: 0.17240090668201447
step: 310, loss: 0.08772465586662292
step: 320, loss: 0.20604567229747772
step: 330, loss: 0.08800553530454636
step: 340, loss: 0.05718543007969856
step: 350, loss: 0.2500472962856293
step: 360, loss: 0.0837583988904953
epoch 3: dev_f1=0.7403598971722366, f1=0.7139240506329113, best_f1=0.7308641975308642
step: 0, loss: 0.03409494832158089
step: 10, loss: 0.10068297386169434
step: 20, loss: 0.020764315500855446
step: 30, loss: 0.12732405960559845
step: 40, loss: 0.10959767550230026
step: 50, loss: 0.05507209897041321
step: 60, loss: 0.1183645948767662
step: 70, loss: 0.13443730771541595
step: 80, loss: 0.14386363327503204
step: 90, loss: 0.16941148042678833
step: 100, loss: 0.1434791088104248
step: 110, loss: 0.03593199700117111
step: 120, loss: 0.006360000930726528
step: 130, loss: 0.032055504620075226
step: 140, loss: 0.09470082819461823
step: 150, loss: 0.09612995386123657
step: 160, loss: 0.11177528649568558
step: 170, loss: 0.02357768826186657
step: 180, loss: 0.06268420070409775
step: 190, loss: 0.2232946753501892
step: 200, loss: 0.07157342880964279
step: 210, loss: 0.013652771711349487
step: 220, loss: 0.07220892608165741
step: 230, loss: 0.07422889769077301
step: 240, loss: 0.1446514129638672
step: 250, loss: 0.02622845396399498
step: 260, loss: 0.08834430575370789
step: 270, loss: 0.14014935493469238
step: 280, loss: 0.18075178563594818
step: 290, loss: 0.00843898020684719
step: 300, loss: 0.22633840143680573
step: 310, loss: 0.057665884494781494
step: 320, loss: 0.11754990369081497
step: 330, loss: 0.09994707256555557
step: 340, loss: 0.11518256366252899
step: 350, loss: 0.006345753557980061
step: 360, loss: 0.05548134818673134
epoch 4: dev_f1=0.7567567567567567, f1=0.7115902964959568, best_f1=0.7115902964959568
step: 0, loss: 0.07982957363128662
step: 10, loss: 0.040528494864702225
step: 20, loss: 0.09264080971479416
step: 30, loss: 0.053695712238550186
step: 40, loss: 0.1189998984336853
step: 50, loss: 0.11318628489971161
step: 60, loss: 0.09588371217250824
step: 70, loss: 0.19482643902301788
step: 80, loss: 0.07903365790843964
step: 90, loss: 0.09296993911266327
step: 100, loss: 0.05002371221780777
step: 110, loss: 0.10375036299228668
step: 120, loss: 0.0314171239733696
step: 130, loss: 0.04807664081454277
step: 140, loss: 0.1330590844154358
step: 150, loss: 0.15912514925003052
step: 160, loss: 0.09629839658737183
step: 170, loss: 0.10294395685195923
step: 180, loss: 0.10613913089036942
step: 190, loss: 0.12976160645484924
step: 200, loss: 0.05882454290986061
step: 210, loss: 0.08597768098115921
step: 220, loss: 0.22323788702487946
step: 230, loss: 0.07771805673837662
step: 240, loss: 0.12448611110448837
step: 250, loss: 0.05928972736001015
step: 260, loss: 0.02200808934867382
step: 270, loss: 0.12197476625442505
step: 280, loss: 0.15349552035331726
step: 290, loss: 0.18786481022834778
step: 300, loss: 0.03357388451695442
step: 310, loss: 0.05505897104740143
step: 320, loss: 0.15802381932735443
step: 330, loss: 0.08692719042301178
step: 340, loss: 0.10582046955823898
step: 350, loss: 0.11131522804498672
step: 360, loss: 0.10183008760213852
epoch 5: dev_f1=0.7651331719128329, f1=0.7438423645320198, best_f1=0.7438423645320198
step: 0, loss: 0.030109917744994164
step: 10, loss: 0.06376388669013977
step: 20, loss: 0.04616431146860123
step: 30, loss: 0.07499013096094131
step: 40, loss: 0.042117889970541
step: 50, loss: 0.12290842831134796
step: 60, loss: 0.047184884548187256
step: 70, loss: 0.06344746798276901
step: 80, loss: 0.008040310814976692
step: 90, loss: 0.06904144585132599
step: 100, loss: 0.012466449290513992
step: 110, loss: 0.14887845516204834
step: 120, loss: 0.0011328952386975288
step: 130, loss: 0.07981114834547043
step: 140, loss: 0.09319661557674408
step: 150, loss: 0.08590284734964371
step: 160, loss: 0.03154417872428894
step: 170, loss: 0.14001967012882233
step: 180, loss: 0.08165577054023743
step: 190, loss: 0.09716814011335373
step: 200, loss: 0.04125256836414337
step: 210, loss: 0.0419396236538887
step: 220, loss: 0.1281905621290207
step: 230, loss: 0.04319626837968826
step: 240, loss: 0.006306123454123735
step: 250, loss: 0.17282462120056152
step: 260, loss: 0.07268314808607101
step: 270, loss: 0.06023017689585686
step: 280, loss: 0.024547390639781952
step: 290, loss: 0.028263002634048462
step: 300, loss: 0.12534984946250916
step: 310, loss: 0.03590743988752365
step: 320, loss: 0.12897168099880219
step: 330, loss: 0.08065275847911835
step: 340, loss: 0.14299727976322174
step: 350, loss: 0.05816614255309105
step: 360, loss: 0.10852353274822235
epoch 6: dev_f1=0.7593052109181142, f1=0.7352185089974292, best_f1=0.7438423645320198
step: 0, loss: 0.06141778826713562
step: 10, loss: 0.041619494557380676
step: 20, loss: 0.07345028966665268
step: 30, loss: 0.11108483374118805
step: 40, loss: 0.03202182799577713
step: 50, loss: 0.10425525903701782
step: 60, loss: 0.06352599710226059
step: 70, loss: 0.09042735397815704
step: 80, loss: 0.05092576891183853
step: 90, loss: 0.09003627300262451
step: 100, loss: 0.06758314371109009
step: 110, loss: 0.10259274393320084
step: 120, loss: 0.027920398861169815
step: 130, loss: 0.05725743994116783
step: 140, loss: 0.022137898951768875
step: 150, loss: 0.03926407918334007
step: 160, loss: 0.0652497336268425
step: 170, loss: 0.12928567826747894
step: 180, loss: 0.09440240263938904
step: 190, loss: 0.09234858304262161
step: 200, loss: 0.04215192049741745
step: 210, loss: 0.04497391730546951
step: 220, loss: 0.20446699857711792
step: 230, loss: 0.09976965934038162
step: 240, loss: 0.04950037598609924
step: 250, loss: 0.14757223427295685
step: 260, loss: 0.09190741181373596
step: 270, loss: 0.16499702632427216
step: 280, loss: 0.1365702897310257
step: 290, loss: 0.048689354211091995
step: 300, loss: 0.2773396372795105
step: 310, loss: 0.1455223262310028
step: 320, loss: 0.10044223070144653
step: 330, loss: 0.06744491308927536
step: 340, loss: 0.10780880600214005
step: 350, loss: 0.09943186491727829
step: 360, loss: 0.1126038208603859
epoch 7: dev_f1=0.7679558011049724, f1=0.7126436781609196, best_f1=0.7126436781609196
step: 0, loss: 0.09174185991287231
step: 10, loss: 0.05879821628332138
step: 20, loss: 0.08733367919921875
step: 30, loss: 0.08591346442699432
step: 40, loss: 0.08665768802165985
step: 50, loss: 0.0620405413210392
step: 60, loss: 0.03807460889220238
step: 70, loss: 0.07743248343467712
step: 80, loss: 0.03801630809903145
step: 90, loss: 0.0466846227645874
step: 100, loss: 0.10908185690641403
step: 110, loss: 0.047282926738262177
step: 120, loss: 0.1034088134765625
step: 130, loss: 0.057113684713840485
step: 140, loss: 0.07061290740966797
step: 150, loss: 0.10674306750297546
step: 160, loss: 0.15137062966823578
step: 170, loss: 0.04876759275794029
step: 180, loss: 0.09893272072076797
step: 190, loss: 0.08804143965244293
step: 200, loss: 0.07458607852458954
step: 210, loss: 0.11458201706409454
step: 220, loss: 0.07954062521457672
step: 230, loss: 0.08632712066173553
step: 240, loss: 0.09129020571708679
step: 250, loss: 0.04699864238500595
step: 260, loss: 0.017786361277103424
step: 270, loss: 0.1234709694981575
step: 280, loss: 0.0385710746049881
step: 290, loss: 0.044967781752347946
step: 300, loss: 0.021325208246707916
step: 310, loss: 0.19410689175128937
step: 320, loss: 0.1549740433692932
step: 330, loss: 0.06907536089420319
step: 340, loss: 0.03606035187840462
step: 350, loss: 0.1604633629322052
step: 360, loss: 0.04929685592651367
epoch 8: dev_f1=0.7386934673366835, f1=0.7525773195876289, best_f1=0.7126436781609196
step: 0, loss: 0.08698597550392151
step: 10, loss: 0.05850386247038841
step: 20, loss: 0.028842244297266006
step: 30, loss: 0.030494775623083115
step: 40, loss: 0.003883377183228731
step: 50, loss: 0.05105362460017204
step: 60, loss: 0.12339727580547333
step: 70, loss: 0.08921031653881073
step: 80, loss: 0.08260758221149445
step: 90, loss: 0.04101937264204025
step: 100, loss: 0.03448477014899254
step: 110, loss: 0.1321592926979065
step: 120, loss: 0.07719262689352036
step: 130, loss: 0.07938886433839798
step: 140, loss: 0.1616045981645584
step: 150, loss: 0.04683808982372284
step: 160, loss: 0.05300963297486305
step: 170, loss: 0.09923805296421051
step: 180, loss: 0.08620890229940414
step: 190, loss: 0.08849382400512695
step: 200, loss: 0.0925341323018074
step: 210, loss: 0.015211970545351505
step: 220, loss: 0.0711020678281784
step: 230, loss: 0.055925577878952026
step: 240, loss: 0.09197867661714554
step: 250, loss: 0.18293265998363495
step: 260, loss: 0.10688906908035278
step: 270, loss: 0.00017167093756143004
step: 280, loss: 0.05826529487967491
step: 290, loss: 0.1337171196937561
step: 300, loss: 0.10157939791679382
step: 310, loss: 0.05209501460194588
step: 320, loss: 0.12162216007709503
step: 330, loss: 0.06712564080953598
step: 340, loss: 0.08363215625286102
step: 350, loss: 0.0408940315246582
step: 360, loss: 0.08568144589662552
epoch 9: dev_f1=0.7735368956743003, f1=0.7519582245430808, best_f1=0.7519582245430808
step: 0, loss: 0.08208870887756348
step: 10, loss: 0.1099032312631607
step: 20, loss: 0.09442318230867386
step: 30, loss: 0.07158150523900986
step: 40, loss: 0.042777784168720245
step: 50, loss: 0.06885067373514175
step: 60, loss: 0.055984266102313995
step: 70, loss: 0.09608536958694458
step: 80, loss: 0.06529709696769714
step: 90, loss: 0.21288879215717316
step: 100, loss: 0.015498804859817028
step: 110, loss: 0.06906256824731827
step: 120, loss: 0.09496848285198212
step: 130, loss: 0.059992533177137375
step: 140, loss: 0.05599531531333923
step: 150, loss: 0.04376918822526932
step: 160, loss: 0.08924403041601181
step: 170, loss: 0.0823695957660675
step: 180, loss: 0.08276095986366272
step: 190, loss: 0.13581451773643494
step: 200, loss: 0.12451741844415665
step: 210, loss: 0.06346352398395538
step: 220, loss: 0.08208725601434708
step: 230, loss: 0.06647463887929916
step: 240, loss: 0.05125913769006729
step: 250, loss: 0.06673604995012283
step: 260, loss: 0.1612219214439392
step: 270, loss: 0.10253243148326874
step: 280, loss: 0.057105328887701035
step: 290, loss: 0.00014937004016246647
step: 300, loss: 0.15003563463687897
step: 310, loss: 0.09027720242738724
step: 320, loss: 0.12502942979335785
step: 330, loss: 0.15904583036899567
step: 340, loss: 0.09366419911384583
step: 350, loss: 0.06140902638435364
step: 360, loss: 0.02356649935245514
epoch 10: dev_f1=0.7295285359801489, f1=0.7357512953367874, best_f1=0.7519582245430808
step: 0, loss: 0.09631972014904022
step: 10, loss: 0.06544331461191177
step: 20, loss: 0.020603133365511894
step: 30, loss: 0.051875825971364975
step: 40, loss: 0.08828247338533401
step: 50, loss: 0.021083801984786987
step: 60, loss: 0.03287874162197113
step: 70, loss: 0.11727970838546753
step: 80, loss: 0.14608098566532135
step: 90, loss: 0.05747409909963608
step: 100, loss: 0.025208592414855957
step: 110, loss: 0.1688099205493927
step: 120, loss: 0.08853892236948013
step: 130, loss: 0.10775444656610489
step: 140, loss: 0.03241788223385811
step: 150, loss: 0.06212110072374344
step: 160, loss: 0.030179008841514587
step: 170, loss: 0.040580201894044876
step: 180, loss: 0.0471789687871933
step: 190, loss: 0.046562738716602325
step: 200, loss: 0.09796451777219772
step: 210, loss: 0.09884658455848694
step: 220, loss: 0.12407632917165756
step: 230, loss: 0.04099048301577568
step: 240, loss: 0.0159391388297081
step: 250, loss: 0.03279981389641762
step: 260, loss: 0.1380607783794403
step: 270, loss: 0.044920504093170166
step: 280, loss: 0.03380348160862923
step: 290, loss: 0.20610858500003815
step: 300, loss: 0.019862100481987
step: 310, loss: 0.0720023587346077
step: 320, loss: 0.26903048157691956
step: 330, loss: 0.15471073985099792
step: 340, loss: 0.024882372468709946
step: 350, loss: 0.15606620907783508
step: 360, loss: 0.07183080911636353
epoch 11: dev_f1=0.7440758293838864, f1=0.7241379310344828, best_f1=0.7519582245430808
step: 0, loss: 0.058455392718315125
step: 10, loss: 0.05488746985793114
step: 20, loss: 0.06380639225244522
step: 30, loss: 0.04757341742515564
step: 40, loss: 0.045107316225767136
step: 50, loss: 0.0038270994555205107
step: 60, loss: 0.0005197206046432257
step: 70, loss: 0.04246966913342476
step: 80, loss: 0.10216923803091049
step: 90, loss: 0.0797622799873352
step: 100, loss: 0.06741208583116531
step: 110, loss: 0.05446828156709671
step: 120, loss: 0.055765703320503235
step: 130, loss: 0.019519440829753876
step: 140, loss: 0.0826890841126442
step: 150, loss: 0.08980504423379898
step: 160, loss: 0.2003766894340515
step: 170, loss: 0.1164533868432045
step: 180, loss: 0.05434446409344673
step: 190, loss: 0.06722158193588257
step: 200, loss: 0.06926532834768295
step: 210, loss: 0.0010819107992574573
step: 220, loss: 0.061827413737773895
step: 230, loss: 0.1002567782998085
step: 240, loss: 0.01115179993212223
step: 250, loss: 0.038496728986501694
step: 260, loss: 0.081448033452034
step: 270, loss: 0.0707639753818512
step: 280, loss: 0.02650878205895424
step: 290, loss: 0.03335905075073242
step: 300, loss: 0.03511839359998703
step: 310, loss: 0.06946901977062225
step: 320, loss: 0.04312046244740486
step: 330, loss: 0.021651756018400192
step: 340, loss: 0.04148180037736893
step: 350, loss: 0.019061245024204254
step: 360, loss: 0.028133464977145195
epoch 12: dev_f1=0.7350000000000001, f1=0.7225130890052356, best_f1=0.7519582245430808
step: 0, loss: 0.08088190108537674
step: 10, loss: 0.033428117632865906
step: 20, loss: 0.04143240302801132
step: 30, loss: 0.0877033993601799
step: 40, loss: 0.0277743861079216
step: 50, loss: 0.010976719669997692
step: 60, loss: 0.04784807562828064
step: 70, loss: 0.09940911829471588
step: 80, loss: 0.015899475663900375
step: 90, loss: 0.028165902942419052
step: 100, loss: 0.02580197900533676
step: 110, loss: 0.021288301795721054
step: 120, loss: 0.09126152098178864
step: 130, loss: 0.018308881670236588
step: 140, loss: 0.0335988849401474
step: 150, loss: 0.045683588832616806
step: 160, loss: 0.0886518731713295
step: 170, loss: 0.019925687462091446
step: 180, loss: 0.013905148953199387
step: 190, loss: 0.008642137981951237
step: 200, loss: 0.012367851100862026
step: 210, loss: 0.056992147117853165
step: 220, loss: 0.0005760720232501626
step: 230, loss: 0.03925192356109619
step: 240, loss: 0.04248248413205147
step: 250, loss: 0.07986298948526382
step: 260, loss: 0.07210543006658554
step: 270, loss: 0.08108092099428177
step: 280, loss: 0.02547881379723549
step: 290, loss: 0.1030195951461792
step: 300, loss: 0.02477370947599411
step: 310, loss: 0.025904810056090355
step: 320, loss: 0.027336467057466507
step: 330, loss: 0.039405740797519684
step: 340, loss: 0.12728740274906158
step: 350, loss: 0.04592040181159973
step: 360, loss: 0.029443547129631042
epoch 13: dev_f1=0.7429906542056074, f1=0.7286063569682152, best_f1=0.7519582245430808
step: 0, loss: 0.007866148836910725
step: 10, loss: 0.015890082344412804
step: 20, loss: 0.06838824599981308
step: 30, loss: 0.045452799648046494
step: 40, loss: 0.08065000921487808
step: 50, loss: 0.03217468038201332
step: 60, loss: 0.1921793520450592
step: 70, loss: 0.045644089579582214
step: 80, loss: 0.08187607675790787
step: 90, loss: 0.05938325077295303
step: 100, loss: 0.016408348456025124
step: 110, loss: 0.0005282009369693696
step: 120, loss: 0.045238085091114044
step: 130, loss: 0.0001123961919802241
step: 140, loss: 0.052580494433641434
step: 150, loss: 0.040167275816202164
step: 160, loss: 0.04880991205573082
step: 170, loss: 0.0584385059773922
step: 180, loss: 0.2478388100862503
step: 190, loss: 0.06647111475467682
step: 200, loss: 0.0721648707985878
step: 210, loss: 0.018666958436369896
step: 220, loss: 0.042476993054151535
step: 230, loss: 0.020439298823475838
step: 240, loss: 0.0901215523481369
step: 250, loss: 0.02981332130730152
step: 260, loss: 0.021726593375205994
step: 270, loss: 0.0001359232992399484
step: 280, loss: 0.09934079647064209
step: 290, loss: 0.02902788668870926
step: 300, loss: 0.026986215263605118
step: 310, loss: 0.0541841946542263
step: 320, loss: 0.08200429379940033
step: 330, loss: 0.03831314295530319
step: 340, loss: 0.02325570583343506
step: 350, loss: 0.03001534752547741
step: 360, loss: 0.010196452029049397
epoch 14: dev_f1=0.7229551451187335, f1=0.7046070460704608, best_f1=0.7519582245430808
step: 0, loss: 0.0370764434337616
step: 10, loss: 0.04205455258488655
step: 20, loss: 0.025661731138825417
step: 30, loss: 0.09326741844415665
step: 40, loss: 0.007414905820041895
step: 50, loss: 0.005515419412404299
step: 60, loss: 0.03559083864092827
step: 70, loss: 0.028001200407743454
step: 80, loss: 0.029257502406835556
step: 90, loss: 0.08975495398044586
step: 100, loss: 0.05615554004907608
step: 110, loss: 0.06287366896867752
step: 120, loss: 0.09563034027814865
step: 130, loss: 0.08458870649337769
step: 140, loss: 0.07861299067735672
step: 150, loss: 0.10894421488046646
step: 160, loss: 0.06576762348413467
step: 170, loss: 0.07820597290992737
step: 180, loss: 0.030268734320998192
step: 190, loss: 0.004499198868870735
step: 200, loss: 0.14850108325481415
step: 210, loss: 0.1054406389594078
step: 220, loss: 0.015289540402591228
step: 230, loss: 0.036249034106731415
step: 240, loss: 0.050581224262714386
step: 250, loss: 0.012767940759658813
step: 260, loss: 0.023113274946808815
step: 270, loss: 0.00012052678357576951
step: 280, loss: 0.032157160341739655
step: 290, loss: 0.02836422249674797
step: 300, loss: 0.012189229018986225
step: 310, loss: 0.054772958159446716
step: 320, loss: 0.02709580399096012
step: 330, loss: 0.013795960694551468
step: 340, loss: 0.0340479239821434
step: 350, loss: 0.022853901609778404
step: 360, loss: 0.13586731255054474
epoch 15: dev_f1=0.7532467532467532, f1=0.7326203208556149, best_f1=0.7519582245430808
step: 0, loss: 0.059472840279340744
step: 10, loss: 0.09057310968637466
step: 20, loss: 0.08487438410520554
step: 30, loss: 0.0621788427233696
step: 40, loss: 0.02606671303510666
step: 50, loss: 0.05593860521912575
step: 60, loss: 0.03247811645269394
step: 70, loss: 0.06263737380504608
step: 80, loss: 0.013220700435340405
step: 90, loss: 0.023729154840111732
step: 100, loss: 0.22267185151576996
step: 110, loss: 0.10370620340108871
step: 120, loss: 0.08357621729373932
step: 130, loss: 0.08280770480632782
step: 140, loss: 0.02816552296280861
step: 150, loss: 0.034579552710056305
step: 160, loss: 0.03239146247506142
step: 170, loss: 0.011103305965662003
step: 180, loss: 0.010036420077085495
step: 190, loss: 0.10030551999807358
step: 200, loss: 0.02767283469438553
step: 210, loss: 0.07024288922548294
step: 220, loss: 0.01361687108874321
step: 230, loss: 0.005352839361876249
step: 240, loss: 0.017346074804663658
step: 250, loss: 0.1619396060705185
step: 260, loss: 0.04153163358569145
step: 270, loss: 0.016780277714133263
step: 280, loss: 0.02751666121184826
step: 290, loss: 0.2195960432291031
step: 300, loss: 0.04140592738986015
step: 310, loss: 0.09403473138809204
step: 320, loss: 0.041763707995414734
step: 330, loss: 0.08523405343294144
step: 340, loss: 0.020196346566081047
step: 350, loss: 0.04080555960536003
step: 360, loss: 0.04854464530944824
epoch 16: dev_f1=0.736842105263158, f1=0.7065217391304348, best_f1=0.7519582245430808
step: 0, loss: 0.011520595289766788
step: 10, loss: 0.08779609948396683
step: 20, loss: 0.0023039488587528467
step: 30, loss: 0.0014660789165645838
step: 40, loss: 0.07355181127786636
step: 50, loss: 0.0020904853008687496
step: 60, loss: 0.05248456448316574
step: 70, loss: 0.010689370334148407
step: 80, loss: 0.004470413085073233
step: 90, loss: 0.06604287773370743
step: 100, loss: 0.18422438204288483
step: 110, loss: 0.0581413172185421
step: 120, loss: 0.008482325822114944
step: 130, loss: 0.06523861736059189
step: 140, loss: 0.04964746907353401
step: 150, loss: 0.025907551869750023
step: 160, loss: 0.07415353506803513
step: 170, loss: 0.09329729527235031
step: 180, loss: 0.006136871874332428
step: 190, loss: 0.05643768608570099
step: 200, loss: 0.061639297753572464
step: 210, loss: 0.0740264430642128
step: 220, loss: 6.760988617315888e-05
step: 230, loss: 0.03170398250222206
step: 240, loss: 0.09132201969623566
step: 250, loss: 0.024306315928697586
step: 260, loss: 0.032908596098423004
step: 270, loss: 0.0728849470615387
step: 280, loss: 0.026688670739531517
step: 290, loss: 0.05680884048342705
step: 300, loss: 0.04499250277876854
step: 310, loss: 0.022129332646727562
step: 320, loss: 0.14096702635288239
step: 330, loss: 3.7346075259847566e-05
step: 340, loss: 0.03161923587322235
step: 350, loss: 0.08746890723705292
step: 360, loss: 0.03312024846673012
epoch 17: dev_f1=0.7468030690537084, f1=0.7393617021276595, best_f1=0.7519582245430808
step: 0, loss: 0.04615386947989464
step: 10, loss: 0.056197281926870346
step: 20, loss: 0.03318191319704056
step: 30, loss: 0.04958920180797577
step: 40, loss: 0.01522869523614645
step: 50, loss: 0.02965005487203598
step: 60, loss: 0.00015887751942500472
step: 70, loss: 0.053312163800001144
step: 80, loss: 0.018892986699938774
step: 90, loss: 0.07179765403270721
step: 100, loss: 0.023497313261032104
step: 110, loss: 0.0418439619243145
step: 120, loss: 0.1292828619480133
step: 130, loss: 0.014702653512358665
step: 140, loss: 0.03886926546692848
step: 150, loss: 2.2805827029515058e-05
step: 160, loss: 0.034105993807315826
step: 170, loss: 0.05247747525572777
step: 180, loss: 0.06978312879800797
step: 190, loss: 0.013527236878871918
step: 200, loss: 0.017521385103464127
step: 210, loss: 0.06289839744567871
step: 220, loss: 0.04619584232568741
step: 230, loss: 0.129558727145195
step: 240, loss: 0.0036141767632216215
step: 250, loss: 0.08422014862298965
step: 260, loss: 0.03944106772542
step: 270, loss: 0.04016730934381485
step: 280, loss: 0.030901212245225906
step: 290, loss: 0.04503040760755539
step: 300, loss: 0.02023020200431347
step: 310, loss: 0.03075680509209633
step: 320, loss: 0.0003018369898200035
step: 330, loss: 0.020548537373542786
step: 340, loss: 0.07146558910608292
step: 350, loss: 0.08547624200582504
step: 360, loss: 0.012708373367786407
epoch 18: dev_f1=0.7393617021276595, f1=0.7, best_f1=0.7519582245430808
step: 0, loss: 0.014004090800881386
step: 10, loss: 0.00011610132787609473
step: 20, loss: 7.005555380601436e-05
step: 30, loss: 0.00678010331466794
step: 40, loss: 0.06683558225631714
step: 50, loss: 0.09763474762439728
step: 60, loss: 0.09023263305425644
step: 70, loss: 0.01784357987344265
step: 80, loss: 0.019441116601228714
step: 90, loss: 0.04255461320281029
step: 100, loss: 0.046345096081495285
step: 110, loss: 0.017556296661496162
step: 120, loss: 0.02636258490383625
step: 130, loss: 0.0818355530500412
step: 140, loss: 0.11385349184274673
step: 150, loss: 0.01797395572066307
step: 160, loss: 0.03763078898191452
step: 170, loss: 0.07377877086400986
step: 180, loss: 0.08008842915296555
step: 190, loss: 0.041956350207328796
step: 200, loss: 0.06445062905550003
step: 210, loss: 0.11048557609319687
step: 220, loss: 0.09795568883419037
step: 230, loss: 0.08577228337526321
step: 240, loss: 0.022063933312892914
step: 250, loss: 2.9547753001679666e-05
step: 260, loss: 0.0705525130033493
step: 270, loss: 0.12903949618339539
step: 280, loss: 0.047689564526081085
step: 290, loss: 0.0322907418012619
step: 300, loss: 0.05374675244092941
step: 310, loss: 0.027853935956954956
step: 320, loss: 0.07771508395671844
step: 330, loss: 0.0019246537704020739
step: 340, loss: 0.0004713477101176977
step: 350, loss: 0.027208559215068817
step: 360, loss: 0.10467678308486938
epoch 19: dev_f1=0.7439353099730459, f1=0.696629213483146, best_f1=0.7519582245430808
step: 0, loss: 0.11456823348999023
step: 10, loss: 0.0204909760504961
step: 20, loss: 0.06929469853639603
step: 30, loss: 0.026282180100679398
step: 40, loss: 0.04546843469142914
step: 50, loss: 0.03616757690906525
step: 60, loss: 0.0011264797067269683
step: 70, loss: 0.0001891779393190518
step: 80, loss: 0.03528669476509094
step: 90, loss: 0.009906475432217121
step: 100, loss: 0.10637162625789642
step: 110, loss: 0.008509930223226547
step: 120, loss: 0.0014893386978656054
step: 130, loss: 0.033731281757354736
step: 140, loss: 0.06528861075639725
step: 150, loss: 0.05924762040376663
step: 160, loss: 0.00423126807436347
step: 170, loss: 0.02972792461514473
step: 180, loss: 0.0002966606698464602
step: 190, loss: 0.04100382700562477
step: 200, loss: 0.0001425451337127015
step: 210, loss: 0.04160212352871895
step: 220, loss: 0.0006210427382029593
step: 230, loss: 0.013815588317811489
step: 240, loss: 0.031764134764671326
step: 250, loss: 0.050885219126939774
step: 260, loss: 0.02729540877044201
step: 270, loss: 0.03170212730765343
step: 280, loss: 0.03953531011939049
step: 290, loss: 0.029817555099725723
step: 300, loss: 0.025376934558153152
step: 310, loss: 0.05459454655647278
step: 320, loss: 0.006224567536264658
step: 330, loss: 0.03687195107340813
step: 340, loss: 0.0010427505476400256
step: 350, loss: 0.006677529308944941
step: 360, loss: 0.021349091082811356
epoch 20: dev_f1=0.7349081364829396, f1=0.6942148760330578, best_f1=0.7519582245430808
