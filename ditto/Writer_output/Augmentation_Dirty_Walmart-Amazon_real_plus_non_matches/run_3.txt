cuda
Device: cuda
step: 0, loss: 0.5985187888145447
step: 10, loss: 0.46126145124435425
step: 20, loss: 0.14253060519695282
step: 30, loss: 0.14051605761051178
step: 40, loss: 0.25456053018569946
step: 50, loss: 0.25254037976264954
step: 60, loss: 0.059124432504177094
step: 70, loss: 0.1447451263666153
step: 80, loss: 0.1412600874900818
step: 90, loss: 0.21940432488918304
step: 100, loss: 0.23554909229278564
step: 110, loss: 0.21095681190490723
step: 120, loss: 0.13214164972305298
step: 130, loss: 0.1483708620071411
step: 140, loss: 0.1963571459054947
step: 150, loss: 0.08781416714191437
step: 160, loss: 0.11679819971323013
step: 170, loss: 0.29022249579429626
step: 180, loss: 0.3807416558265686
step: 190, loss: 0.12105472385883331
step: 200, loss: 0.1802804321050644
step: 210, loss: 0.23446927964687347
step: 220, loss: 0.10477513074874878
step: 230, loss: 0.16811098158359528
step: 240, loss: 0.4468860626220703
step: 250, loss: 0.04243042320013046
step: 260, loss: 0.14173084497451782
step: 270, loss: 0.17118148505687714
step: 280, loss: 0.04186813160777092
step: 290, loss: 0.04725551977753639
step: 300, loss: 0.07657267153263092
step: 310, loss: 0.06417516618967056
step: 320, loss: 0.034233082085847855
step: 330, loss: 0.16165979206562042
step: 340, loss: 0.296630322933197
step: 350, loss: 0.07344943284988403
step: 360, loss: 0.04878845810890198
epoch 1: dev_f1=0.6378896882494005, f1=0.6328502415458938, best_f1=0.6328502415458938
step: 0, loss: 0.10140394419431686
step: 10, loss: 0.12521259486675262
step: 20, loss: 0.19317492842674255
step: 30, loss: 0.09538312256336212
step: 40, loss: 0.27323293685913086
step: 50, loss: 0.06147313863039017
step: 60, loss: 0.25242894887924194
step: 70, loss: 0.03241899609565735
step: 80, loss: 0.09046657383441925
step: 90, loss: 0.10130183398723602
step: 100, loss: 0.042710352689027786
step: 110, loss: 0.16683557629585266
step: 120, loss: 0.051478516310453415
step: 130, loss: 0.1460322141647339
step: 140, loss: 0.29880040884017944
step: 150, loss: 0.1165064349770546
step: 160, loss: 0.139946848154068
step: 170, loss: 0.04900890216231346
step: 180, loss: 0.17456671595573425
step: 190, loss: 0.17802394926548004
step: 200, loss: 0.03493263199925423
step: 210, loss: 0.11155586689710617
step: 220, loss: 0.053130730986595154
step: 230, loss: 0.13770072162151337
step: 240, loss: 0.13384529948234558
step: 250, loss: 0.21991464495658875
step: 260, loss: 0.07714138925075531
step: 270, loss: 0.17735834419727325
step: 280, loss: 0.25264737010002136
step: 290, loss: 0.12068265676498413
step: 300, loss: 0.06647837907075882
step: 310, loss: 0.12072514742612839
step: 320, loss: 0.27467241883277893
step: 330, loss: 0.16711010038852692
step: 340, loss: 0.05441911518573761
step: 350, loss: 0.16260769963264465
step: 360, loss: 0.07900597155094147
epoch 2: dev_f1=0.7263922518159805, f1=0.7203791469194313, best_f1=0.7203791469194313
step: 0, loss: 0.21699725091457367
step: 10, loss: 0.05722452327609062
step: 20, loss: 0.07320744544267654
step: 30, loss: 0.05848805233836174
step: 40, loss: 0.15422610938549042
step: 50, loss: 0.15207690000534058
step: 60, loss: 0.08249980211257935
step: 70, loss: 0.027835840359330177
step: 80, loss: 0.1587396264076233
step: 90, loss: 0.1221029981970787
step: 100, loss: 0.03151385113596916
step: 110, loss: 0.044154271483421326
step: 120, loss: 0.1805291771888733
step: 130, loss: 0.1325729340314865
step: 140, loss: 0.2186729460954666
step: 150, loss: 0.1780342310667038
step: 160, loss: 0.11937005072832108
step: 170, loss: 0.10993968695402145
step: 180, loss: 0.08662495762109756
step: 190, loss: 0.04838519170880318
step: 200, loss: 0.10701271891593933
step: 210, loss: 0.10838573426008224
step: 220, loss: 0.1938224583864212
step: 230, loss: 0.056427426636219025
step: 240, loss: 0.09251474589109421
step: 250, loss: 0.04168171435594559
step: 260, loss: 0.15819214284420013
step: 270, loss: 0.20459257066249847
step: 280, loss: 0.17293332517147064
step: 290, loss: 0.06551972031593323
step: 300, loss: 0.06534729897975922
step: 310, loss: 0.09120402485132217
step: 320, loss: 0.0699988454580307
step: 330, loss: 0.28430119156837463
step: 340, loss: 0.07086930423974991
step: 350, loss: 0.040593959391117096
step: 360, loss: 0.10023000836372375
epoch 3: dev_f1=0.7142857142857142, f1=0.7252124645892353, best_f1=0.7203791469194313
step: 0, loss: 0.0733393132686615
step: 10, loss: 0.14471225440502167
step: 20, loss: 0.10641820728778839
step: 30, loss: 0.07576729357242584
step: 40, loss: 0.14880289137363434
step: 50, loss: 0.09841610491275787
step: 60, loss: 0.1328701227903366
step: 70, loss: 0.05885938182473183
step: 80, loss: 0.07982411235570908
step: 90, loss: 0.020184626802802086
step: 100, loss: 0.15842407941818237
step: 110, loss: 0.11789776384830475
step: 120, loss: 0.06360882520675659
step: 130, loss: 0.11366734653711319
step: 140, loss: 0.05435432121157646
step: 150, loss: 0.2587026357650757
step: 160, loss: 0.14363732933998108
step: 170, loss: 0.06602921336889267
step: 180, loss: 0.1249508485198021
step: 190, loss: 0.12318800389766693
step: 200, loss: 0.06387539952993393
step: 210, loss: 0.10748805105686188
step: 220, loss: 0.20133818686008453
step: 230, loss: 0.0882095992565155
step: 240, loss: 0.07586695998907089
step: 250, loss: 0.19157597422599792
step: 260, loss: 0.05906651169061661
step: 270, loss: 0.060623522847890854
step: 280, loss: 0.08969852328300476
step: 290, loss: 0.2840634286403656
step: 300, loss: 0.18982639908790588
step: 310, loss: 0.09405163675546646
step: 320, loss: 0.04773347079753876
step: 330, loss: 0.2055313140153885
step: 340, loss: 0.06323833018541336
step: 350, loss: 0.2052883803844452
step: 360, loss: 0.05520523339509964
epoch 4: dev_f1=0.7472527472527473, f1=0.7533875338753386, best_f1=0.7533875338753386
step: 0, loss: 0.11690196394920349
step: 10, loss: 0.028902411460876465
step: 20, loss: 0.02488209493458271
step: 30, loss: 0.12144079804420471
step: 40, loss: 0.09828227013349533
step: 50, loss: 0.053519830107688904
step: 60, loss: 0.059444233775138855
step: 70, loss: 0.05118201673030853
step: 80, loss: 0.13458508253097534
step: 90, loss: 0.17617878317832947
step: 100, loss: 0.2805268168449402
step: 110, loss: 0.1012425497174263
step: 120, loss: 0.09514562040567398
step: 130, loss: 0.18382658064365387
step: 140, loss: 0.20038476586341858
step: 150, loss: 0.1902800351381302
step: 160, loss: 0.09058638662099838
step: 170, loss: 0.018928002566099167
step: 180, loss: 0.04165217652916908
step: 190, loss: 0.05729959160089493
step: 200, loss: 0.10854299366474152
step: 210, loss: 0.025808122009038925
step: 220, loss: 0.043746720999479294
step: 230, loss: 0.2269306480884552
step: 240, loss: 0.044903501868247986
step: 250, loss: 0.09040077030658722
step: 260, loss: 0.022307448089122772
step: 270, loss: 0.17240697145462036
step: 280, loss: 0.16507753729820251
step: 290, loss: 0.1054130271077156
step: 300, loss: 0.02030079998075962
step: 310, loss: 0.1459675282239914
step: 320, loss: 0.13927821815013885
step: 330, loss: 0.16536451876163483
step: 340, loss: 0.05075757950544357
step: 350, loss: 0.05961497500538826
step: 360, loss: 0.11095735430717468
epoch 5: dev_f1=0.6977886977886977, f1=0.7117794486215538, best_f1=0.7533875338753386
step: 0, loss: 0.0549301840364933
step: 10, loss: 0.0509534515440464
step: 20, loss: 0.06603184342384338
step: 30, loss: 0.05483255907893181
step: 40, loss: 0.03198486939072609
step: 50, loss: 0.10168951004743576
step: 60, loss: 0.014359614811837673
step: 70, loss: 0.12563277781009674
step: 80, loss: 0.08404254168272018
step: 90, loss: 0.04975517466664314
step: 100, loss: 0.0022436128929257393
step: 110, loss: 0.09122288972139359
step: 120, loss: 0.030027754604816437
step: 130, loss: 0.05386161431670189
step: 140, loss: 0.046815019100904465
step: 150, loss: 0.060013383626937866
step: 160, loss: 0.05261078104376793
step: 170, loss: 0.12115371972322464
step: 180, loss: 0.10867677628993988
step: 190, loss: 0.07078049331903458
step: 200, loss: 0.033893510699272156
step: 210, loss: 0.11651261150836945
step: 220, loss: 0.06424739211797714
step: 230, loss: 0.12465130537748337
step: 240, loss: 0.025543319061398506
step: 250, loss: 0.06334511190652847
step: 260, loss: 0.07187183201313019
step: 270, loss: 0.22963938117027283
step: 280, loss: 0.0012016082182526588
step: 290, loss: 0.052689239382743835
step: 300, loss: 0.014516633935272694
step: 310, loss: 0.1024012342095375
step: 320, loss: 0.06943904608488083
step: 330, loss: 0.15042462944984436
step: 340, loss: 0.1064765676856041
step: 350, loss: 0.03653377667069435
step: 360, loss: 0.06748374551534653
epoch 6: dev_f1=0.7245657568238213, f1=0.751842751842752, best_f1=0.7533875338753386
step: 0, loss: 0.14132589101791382
step: 10, loss: 0.1280798465013504
step: 20, loss: 0.08873072266578674
step: 30, loss: 0.03506188839673996
step: 40, loss: 0.12991508841514587
step: 50, loss: 0.09596049040555954
step: 60, loss: 0.03822994977235794
step: 70, loss: 0.13164609670639038
step: 80, loss: 0.11977869272232056
step: 90, loss: 0.060164276510477066
step: 100, loss: 0.05919763445854187
step: 110, loss: 0.07019749283790588
step: 120, loss: 0.02063814364373684
step: 130, loss: 0.08265206217765808
step: 140, loss: 0.1236841157078743
step: 150, loss: 0.11167124658823013
step: 160, loss: 0.09289152175188065
step: 170, loss: 0.049119796603918076
step: 180, loss: 0.06591224670410156
step: 190, loss: 0.07447966933250427
step: 200, loss: 0.04047052562236786
step: 210, loss: 0.053572557866573334
step: 220, loss: 0.14043191075325012
step: 230, loss: 0.09647906571626663
step: 240, loss: 0.08003348112106323
step: 250, loss: 0.14589689671993256
step: 260, loss: 0.0570090152323246
step: 270, loss: 0.024165861308574677
step: 280, loss: 0.029096368700265884
step: 290, loss: 0.06160314753651619
step: 300, loss: 0.02140706777572632
step: 310, loss: 0.31194159388542175
step: 320, loss: 0.11119185388088226
step: 330, loss: 0.06985557079315186
step: 340, loss: 0.02307397872209549
step: 350, loss: 0.08363862335681915
step: 360, loss: 0.04372863844037056
epoch 7: dev_f1=0.7473684210526317, f1=0.745308310991957, best_f1=0.745308310991957
step: 0, loss: 0.1422511637210846
step: 10, loss: 0.16073082387447357
step: 20, loss: 0.11414700746536255
step: 30, loss: 0.02318297140300274
step: 40, loss: 0.06520748138427734
step: 50, loss: 0.08710730075836182
step: 60, loss: 0.0620865523815155
step: 70, loss: 0.10091722011566162
step: 80, loss: 0.01803782396018505
step: 90, loss: 0.11472289264202118
step: 100, loss: 0.07961954921483994
step: 110, loss: 0.157419353723526
step: 120, loss: 0.19722019135951996
step: 130, loss: 0.0634998306632042
step: 140, loss: 0.022885313257575035
step: 150, loss: 0.1914863884449005
step: 160, loss: 0.02401730604469776
step: 170, loss: 0.25277823209762573
step: 180, loss: 0.1422952562570572
step: 190, loss: 0.014240468852221966
step: 200, loss: 0.04375903680920601
step: 210, loss: 0.06458675861358643
step: 220, loss: 0.027815191075205803
step: 230, loss: 0.02207000181078911
step: 240, loss: 0.04623463749885559
step: 250, loss: 0.04168972745537758
step: 260, loss: 0.11814863979816437
step: 270, loss: 0.09870235621929169
step: 280, loss: 0.017800336703658104
step: 290, loss: 0.033676277846097946
step: 300, loss: 0.07138613611459732
step: 310, loss: 0.10708168148994446
step: 320, loss: 0.11409395933151245
step: 330, loss: 0.03407571092247963
step: 340, loss: 0.046054624021053314
step: 350, loss: 0.015753814950585365
step: 360, loss: 0.08785603195428848
epoch 8: dev_f1=0.7540983606557378, f1=0.7267904509283819, best_f1=0.7267904509283819
step: 0, loss: 0.058216359466314316
step: 10, loss: 0.047679364681243896
step: 20, loss: 0.07379569858312607
step: 30, loss: 0.05438831448554993
step: 40, loss: 0.01649373024702072
step: 50, loss: 0.1246645525097847
step: 60, loss: 0.10429103672504425
step: 70, loss: 0.09798058867454529
step: 80, loss: 0.05166833847761154
step: 90, loss: 0.02478460967540741
step: 100, loss: 0.07671244442462921
step: 110, loss: 0.03709132969379425
step: 120, loss: 0.05020521953701973
step: 130, loss: 0.042081933468580246
step: 140, loss: 0.09984957426786423
step: 150, loss: 0.06112575903534889
step: 160, loss: 0.04955346882343292
step: 170, loss: 0.08655962347984314
step: 180, loss: 0.09190605580806732
step: 190, loss: 0.06167511269450188
step: 200, loss: 0.09206914901733398
step: 210, loss: 0.034626591950654984
step: 220, loss: 0.054037775844335556
step: 230, loss: 0.03228289633989334
step: 240, loss: 0.055314261466264725
step: 250, loss: 0.06373949348926544
step: 260, loss: 0.1464698314666748
step: 270, loss: 0.06293302774429321
step: 280, loss: 0.09916187822818756
step: 290, loss: 0.07392223179340363
step: 300, loss: 0.11649315804243088
step: 310, loss: 0.05818507820367813
step: 320, loss: 0.13427439332008362
step: 330, loss: 0.009821446612477303
step: 340, loss: 0.08251047879457474
step: 350, loss: 0.005339265335351229
step: 360, loss: 0.03311436250805855
epoch 9: dev_f1=0.7540983606557378, f1=0.699724517906336, best_f1=0.7267904509283819
step: 0, loss: 0.05041946470737457
step: 10, loss: 0.0007458398467861116
step: 20, loss: 0.17674724757671356
step: 30, loss: 0.04429830610752106
step: 40, loss: 0.08951787650585175
step: 50, loss: 0.11785347759723663
step: 60, loss: 0.07425335049629211
step: 70, loss: 0.00675022229552269
step: 80, loss: 0.132146954536438
step: 90, loss: 0.06069687753915787
step: 100, loss: 0.07704358547925949
step: 110, loss: 0.03005325049161911
step: 120, loss: 0.050228845328092575
step: 130, loss: 0.10878325998783112
step: 140, loss: 0.09191063046455383
step: 150, loss: 0.08170191198587418
step: 160, loss: 0.04099949449300766
step: 170, loss: 0.12658432126045227
step: 180, loss: 0.051712628453969955
step: 190, loss: 0.020404769107699394
step: 200, loss: 0.08834215998649597
step: 210, loss: 0.03715504705905914
step: 220, loss: 0.11364810168743134
step: 230, loss: 0.0778033509850502
step: 240, loss: 0.0678381621837616
step: 250, loss: 0.03782482445240021
step: 260, loss: 0.068808913230896
step: 270, loss: 0.05948523059487343
step: 280, loss: 0.03536214679479599
step: 290, loss: 0.10190416127443314
step: 300, loss: 0.05229876935482025
step: 310, loss: 0.11818639189004898
step: 320, loss: 0.08962861448526382
step: 330, loss: 0.04739171639084816
step: 340, loss: 0.054014652967453
step: 350, loss: 0.05572929605841637
step: 360, loss: 0.02334108017385006
epoch 10: dev_f1=0.7331670822942644, f1=0.7346938775510203, best_f1=0.7267904509283819
step: 0, loss: 0.01739593595266342
step: 10, loss: 0.024056725203990936
step: 20, loss: 0.02260679192841053
step: 30, loss: 0.02346150577068329
step: 40, loss: 0.02687324769794941
step: 50, loss: 0.11297079175710678
step: 60, loss: 0.01641375571489334
step: 70, loss: 0.02745210751891136
step: 80, loss: 0.03209654614329338
step: 90, loss: 0.11525662988424301
step: 100, loss: 0.06048668920993805
step: 110, loss: 0.06575494259595871
step: 120, loss: 0.09090238064527512
step: 130, loss: 0.09046119451522827
step: 140, loss: 0.14091356098651886
step: 150, loss: 0.0694841668009758
step: 160, loss: 0.03223380073904991
step: 170, loss: 0.11456407606601715
step: 180, loss: 0.09947139769792557
step: 190, loss: 0.08111279457807541
step: 200, loss: 0.11358613520860672
step: 210, loss: 0.07107795774936676
step: 220, loss: 0.1188042089343071
step: 230, loss: 0.0030898076947778463
step: 240, loss: 0.1459970623254776
step: 250, loss: 0.08141078799962997
step: 260, loss: 0.024936869740486145
step: 270, loss: 0.04658357799053192
step: 280, loss: 0.062306202948093414
step: 290, loss: 0.015625543892383575
step: 300, loss: 0.05381056293845177
step: 310, loss: 0.02718605101108551
step: 320, loss: 0.0546073280274868
step: 330, loss: 0.03145843744277954
step: 340, loss: 0.044324830174446106
step: 350, loss: 0.06595765799283981
step: 360, loss: 0.07156087458133698
epoch 11: dev_f1=0.741687979539642, f1=0.7197943444730078, best_f1=0.7267904509283819
step: 0, loss: 0.062368862330913544
step: 10, loss: 0.15980780124664307
step: 20, loss: 0.039902396500110626
step: 30, loss: 0.038978736847639084
step: 40, loss: 0.06080156937241554
step: 50, loss: 0.047894999384880066
step: 60, loss: 0.12862595915794373
step: 70, loss: 0.07250016182661057
step: 80, loss: 0.08423066139221191
step: 90, loss: 0.09830471873283386
step: 100, loss: 0.077366903424263
step: 110, loss: 0.10773913562297821
step: 120, loss: 0.07750687003135681
step: 130, loss: 0.09963615238666534
step: 140, loss: 0.20623405277729034
step: 150, loss: 0.02784588374197483
step: 160, loss: 0.0548984631896019
step: 170, loss: 0.032700855284929276
step: 180, loss: 0.07695332914590836
step: 190, loss: 0.050520289689302444
step: 200, loss: 0.030970584601163864
step: 210, loss: 0.08434434235095978
step: 220, loss: 0.05494095757603645
step: 230, loss: 0.0889357477426529
step: 240, loss: 0.07717514783143997
step: 250, loss: 0.03862018510699272
step: 260, loss: 0.047019246965646744
step: 270, loss: 0.05138064920902252
step: 280, loss: 0.0754561498761177
step: 290, loss: 0.12052201479673386
step: 300, loss: 0.006732647307217121
step: 310, loss: 0.15928374230861664
step: 320, loss: 0.1471535861492157
step: 330, loss: 0.15120252966880798
step: 340, loss: 0.022385304793715477
step: 350, loss: 0.057044390588998795
step: 360, loss: 0.14474914968013763
epoch 12: dev_f1=0.7527472527472527, f1=0.7159090909090909, best_f1=0.7267904509283819
step: 0, loss: 0.03324579820036888
step: 10, loss: 0.027191264554858208
step: 20, loss: 0.11763997375965118
step: 30, loss: 0.08626218885183334
step: 40, loss: 0.06031531095504761
step: 50, loss: 0.057129018008708954
step: 60, loss: 0.03846559301018715
step: 70, loss: 0.01671597920358181
step: 80, loss: 0.04862459376454353
step: 90, loss: 2.63782603724394e-05
step: 100, loss: 0.1046510711312294
step: 110, loss: 0.05513621121644974
step: 120, loss: 0.037187978625297546
step: 130, loss: 0.26490139961242676
step: 140, loss: 0.09491753578186035
step: 150, loss: 0.07443960756063461
step: 160, loss: 0.06965615600347519
step: 170, loss: 0.03030608966946602
step: 180, loss: 0.06420134752988815
step: 190, loss: 0.02105126902461052
step: 200, loss: 0.101995550096035
step: 210, loss: 0.014376940205693245
step: 220, loss: 0.13665805757045746
step: 230, loss: 0.036445315927267075
step: 240, loss: 0.08638907968997955
step: 250, loss: 0.08250682055950165
step: 260, loss: 0.03132994845509529
step: 270, loss: 0.05010967329144478
step: 280, loss: 3.0591436370741576e-05
step: 290, loss: 0.03624538704752922
step: 300, loss: 0.11776071786880493
step: 310, loss: 0.12877929210662842
step: 320, loss: 0.13947346806526184
step: 330, loss: 0.1634911447763443
step: 340, loss: 0.07154139131307602
step: 350, loss: 0.07792922109365463
step: 360, loss: 0.054602060467004776
epoch 13: dev_f1=0.7277777777777779, f1=0.7272727272727272, best_f1=0.7267904509283819
step: 0, loss: 0.021348344162106514
step: 10, loss: 0.06237092986702919
step: 20, loss: 0.2196943312883377
step: 30, loss: 0.04015156626701355
step: 40, loss: 0.03229478746652603
step: 50, loss: 0.030081933364272118
step: 60, loss: 0.173812136054039
step: 70, loss: 0.04725395515561104
step: 80, loss: 0.018993733450770378
step: 90, loss: 0.0626327320933342
step: 100, loss: 0.043703626841306686
step: 110, loss: 0.022541675716638565
step: 120, loss: 0.012826717458665371
step: 130, loss: 0.0418168269097805
step: 140, loss: 0.05921159312129021
step: 150, loss: 0.1021580845117569
step: 160, loss: 0.00011189920041942969
step: 170, loss: 0.05482882261276245
step: 180, loss: 0.017108937725424767
step: 190, loss: 0.16408857703208923
step: 200, loss: 0.09012763947248459
step: 210, loss: 0.13464047014713287
step: 220, loss: 0.06060162931680679
step: 230, loss: 0.011307377368211746
step: 240, loss: 0.025623157620429993
step: 250, loss: 0.006344374734908342
step: 260, loss: 0.028988495469093323
step: 270, loss: 0.10208509117364883
step: 280, loss: 0.1544196754693985
step: 290, loss: 0.0862589105963707
step: 300, loss: 0.046470046043395996
step: 310, loss: 0.05923723429441452
step: 320, loss: 0.07498648762702942
step: 330, loss: 0.044238459318876266
step: 340, loss: 0.050988662987947464
step: 350, loss: 0.08428778499364853
step: 360, loss: 0.10098163783550262
epoch 14: dev_f1=0.7272727272727272, f1=0.7239583333333334, best_f1=0.7267904509283819
step: 0, loss: 0.023903068155050278
step: 10, loss: 0.06850937008857727
step: 20, loss: 0.07442490011453629
step: 30, loss: 0.029624540358781815
step: 40, loss: 0.0643361508846283
step: 50, loss: 0.0892975777387619
step: 60, loss: 0.006570116616785526
step: 70, loss: 0.07726491242647171
step: 80, loss: 0.10112574696540833
step: 90, loss: 0.06976571679115295
step: 100, loss: 0.06785961240530014
step: 110, loss: 0.04546968266367912
step: 120, loss: 0.04988124594092369
step: 130, loss: 0.04460142180323601
step: 140, loss: 0.03170455992221832
step: 150, loss: 0.0031522547360509634
step: 160, loss: 0.05948849394917488
step: 170, loss: 0.057400576770305634
step: 180, loss: 0.03548597916960716
step: 190, loss: 0.12649045884609222
step: 200, loss: 0.12212375551462173
step: 210, loss: 0.018038414418697357
step: 220, loss: 0.13517744839191437
step: 230, loss: 0.001267618383280933
step: 240, loss: 0.04325322434306145
step: 250, loss: 0.032593995332717896
step: 260, loss: 0.009702323004603386
step: 270, loss: 0.1081058531999588
step: 280, loss: 0.046883806586265564
step: 290, loss: 0.04861403629183769
step: 300, loss: 0.00010873252904275432
step: 310, loss: 0.02468075230717659
step: 320, loss: 0.08137397468090057
step: 330, loss: 0.009908747859299183
step: 340, loss: 0.012384101748466492
step: 350, loss: 0.11335760354995728
step: 360, loss: 0.056348882615566254
epoch 15: dev_f1=0.717391304347826, f1=0.7223719676549865, best_f1=0.7267904509283819
step: 0, loss: 0.056308403611183167
step: 10, loss: 0.04730275273323059
step: 20, loss: 0.06453797966241837
step: 30, loss: 0.21793735027313232
step: 40, loss: 0.039163339883089066
step: 50, loss: 0.006021050736308098
step: 60, loss: 0.020442627370357513
step: 70, loss: 0.08702222257852554
step: 80, loss: 0.010492262430489063
step: 90, loss: 0.08364327251911163
step: 100, loss: 0.11667993664741516
step: 110, loss: 0.0028536757454276085
step: 120, loss: 0.1028599664568901
step: 130, loss: 0.20369692146778107
step: 140, loss: 0.06502880901098251
step: 150, loss: 0.03624105453491211
step: 160, loss: 0.10666171461343765
step: 170, loss: 0.02970999851822853
step: 180, loss: 0.057469721883535385
step: 190, loss: 0.07275306433439255
step: 200, loss: 0.04136234149336815
step: 210, loss: 0.02439434826374054
step: 220, loss: 0.05937059596180916
step: 230, loss: 0.10732416808605194
step: 240, loss: 0.0679437518119812
step: 250, loss: 0.02982691302895546
step: 260, loss: 0.101956807076931
step: 270, loss: 0.10088545829057693
step: 280, loss: 0.04358186200261116
step: 290, loss: 0.07422411441802979
step: 300, loss: 0.06639561057090759
step: 310, loss: 0.08653980493545532
step: 320, loss: 0.0446888729929924
step: 330, loss: 0.039725273847579956
step: 340, loss: 0.044125523418188095
step: 350, loss: 0.05868494138121605
step: 360, loss: 0.1066942811012268
epoch 16: dev_f1=0.7124010554089709, f1=0.7306666666666668, best_f1=0.7267904509283819
step: 0, loss: 0.04837518557906151
step: 10, loss: 0.029513221234083176
step: 20, loss: 0.0928860753774643
step: 30, loss: 0.0049735382199287415
step: 40, loss: 0.05984896048903465
step: 50, loss: 0.09465492516756058
step: 60, loss: 0.08757161349058151
step: 70, loss: 0.02872510813176632
step: 80, loss: 0.06639312952756882
step: 90, loss: 0.02927841618657112
step: 100, loss: 0.0483371838927269
step: 110, loss: 0.019172677770256996
step: 120, loss: 0.01562261488288641
step: 130, loss: 0.12903490662574768
step: 140, loss: 0.04606594890356064
step: 150, loss: 0.026995528489351273
step: 160, loss: 0.06883388012647629
step: 170, loss: 0.0008180272416211665
step: 180, loss: 0.07044161856174469
step: 190, loss: 0.030269941315054893
step: 200, loss: 0.058652013540267944
step: 210, loss: 0.05300898104906082
step: 220, loss: 0.03174610435962677
step: 230, loss: 0.0424933023750782
step: 240, loss: 0.03502851352095604
step: 250, loss: 0.17219911515712738
step: 260, loss: 0.0002626267960295081
step: 270, loss: 0.022594600915908813
step: 280, loss: 0.08620104193687439
step: 290, loss: 0.07087739557027817
step: 300, loss: 0.10627481341362
step: 310, loss: 0.08594616502523422
step: 320, loss: 0.008111643604934216
step: 330, loss: 0.0440085306763649
step: 340, loss: 0.01843630149960518
step: 350, loss: 0.14148496091365814
step: 360, loss: 0.025649158284068108
epoch 17: dev_f1=0.7142857142857143, f1=0.7195767195767196, best_f1=0.7267904509283819
step: 0, loss: 0.11294178664684296
step: 10, loss: 0.04095132648944855
step: 20, loss: 0.033503174781799316
step: 30, loss: 0.003986909985542297
step: 40, loss: 0.08844732493162155
step: 50, loss: 0.02836351841688156
step: 60, loss: 0.009439397603273392
step: 70, loss: 0.03442920744419098
step: 80, loss: 0.12132987380027771
step: 90, loss: 0.032862648367881775
step: 100, loss: 0.025094319134950638
step: 110, loss: 0.02459871955215931
step: 120, loss: 0.08429378271102905
step: 130, loss: 0.0360281765460968
step: 140, loss: 0.026579149067401886
step: 150, loss: 0.08818011730909348
step: 160, loss: 0.03341462090611458
step: 170, loss: 0.021370355039834976
step: 180, loss: 0.14206351339817047
step: 190, loss: 0.027373716235160828
step: 200, loss: 7.875433220760897e-05
step: 210, loss: 0.00011876262578880414
step: 220, loss: 0.08504008501768112
step: 230, loss: 0.0585043802857399
step: 240, loss: 0.08370770514011383
step: 250, loss: 0.0018620596965774894
step: 260, loss: 0.06922028213739395
step: 270, loss: 0.07335106283426285
step: 280, loss: 0.029368851333856583
step: 290, loss: 0.08124770224094391
step: 300, loss: 0.019058238714933395
step: 310, loss: 0.08616390079259872
step: 320, loss: 0.03826669976115227
step: 330, loss: 0.02554275095462799
step: 340, loss: 0.04787718504667282
step: 350, loss: 0.024658864364027977
step: 360, loss: 0.03413509204983711
epoch 18: dev_f1=0.7061855670103092, f1=0.7291666666666667, best_f1=0.7267904509283819
step: 0, loss: 0.03775884583592415
step: 10, loss: 0.06792265921831131
step: 20, loss: 0.05584149807691574
step: 30, loss: 0.03036290779709816
step: 40, loss: 0.07124360650777817
step: 50, loss: 0.01686323992908001
step: 60, loss: 0.018414383754134178
step: 70, loss: 0.0355001837015152
step: 80, loss: 0.03464318811893463
step: 90, loss: 0.0979774072766304
step: 100, loss: 0.07322971522808075
step: 110, loss: 0.09773683547973633
step: 120, loss: 0.05705811828374863
step: 130, loss: 0.08240850269794464
step: 140, loss: 0.0879940316081047
step: 150, loss: 0.05510926619172096
step: 160, loss: 0.06804190576076508
step: 170, loss: 0.030119776725769043
step: 180, loss: 0.04878394305706024
step: 190, loss: 0.0401405468583107
step: 200, loss: 0.06771058589220047
step: 210, loss: 0.02534557692706585
step: 220, loss: 0.006171885412186384
step: 230, loss: 0.03687150776386261
step: 240, loss: 0.016996126621961594
step: 250, loss: 0.06292248517274857
step: 260, loss: 0.12340901792049408
step: 270, loss: 0.01243186928331852
step: 280, loss: 0.003498133271932602
step: 290, loss: 0.05055397003889084
step: 300, loss: 0.002310971263796091
step: 310, loss: 0.0554555281996727
step: 320, loss: 0.026987362653017044
step: 330, loss: 0.04174230620265007
step: 340, loss: 0.13688744604587555
step: 350, loss: 0.009902732446789742
step: 360, loss: 0.10703227669000626
epoch 19: dev_f1=0.7052023121387283, f1=0.6744868035190615, best_f1=0.7267904509283819
step: 0, loss: 0.10368509590625763
step: 10, loss: 0.004119107965379953
step: 20, loss: 0.06256961822509766
step: 30, loss: 0.040297981351614
step: 40, loss: 0.016422949731349945
step: 50, loss: 0.019826795905828476
step: 60, loss: 0.07677286863327026
step: 70, loss: 0.059902410954236984
step: 80, loss: 0.020366739481687546
step: 90, loss: 0.11078004539012909
step: 100, loss: 0.010194999165832996
step: 110, loss: 0.02148842066526413
step: 120, loss: 0.006704283412545919
step: 130, loss: 0.03706841170787811
step: 140, loss: 0.016371389850974083
step: 150, loss: 0.18207941949367523
step: 160, loss: 0.09856210649013519
step: 170, loss: 0.021742848679423332
step: 180, loss: 0.04798111692070961
step: 190, loss: 0.007611406501382589
step: 200, loss: 0.062266092747449875
step: 210, loss: 0.02178310416638851
step: 220, loss: 0.05867970734834671
step: 230, loss: 0.04869454726576805
step: 240, loss: 0.060671769082546234
step: 250, loss: 0.0020931996405124664
step: 260, loss: 0.10482215136289597
step: 270, loss: 0.08417613804340363
step: 280, loss: 0.03464652597904205
step: 290, loss: 0.017920099198818207
step: 300, loss: 0.011154360137879848
step: 310, loss: 4.690340210800059e-05
step: 320, loss: 0.06557013094425201
step: 330, loss: 0.05001037195324898
step: 340, loss: 0.04992979019880295
step: 350, loss: 0.015883145853877068
step: 360, loss: 0.002150285989046097
epoch 20: dev_f1=0.7102272727272727, f1=0.6840579710144928, best_f1=0.7267904509283819
