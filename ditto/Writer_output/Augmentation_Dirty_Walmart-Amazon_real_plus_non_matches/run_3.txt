cuda
Device: cuda
step: 0, loss: 0.7047262191772461
step: 10, loss: 0.007521721534430981
step: 20, loss: 0.3946576714515686
step: 30, loss: 0.14368653297424316
step: 40, loss: 0.23609109222888947
step: 50, loss: 0.0685730129480362
step: 60, loss: 0.23414957523345947
step: 70, loss: 0.1509770005941391
step: 80, loss: 0.06213952228426933
step: 90, loss: 0.03675715997815132
step: 100, loss: 0.13643616437911987
step: 110, loss: 0.0893218070268631
step: 120, loss: 0.12134064733982086
step: 130, loss: 0.053990498185157776
step: 140, loss: 0.3869574964046478
step: 150, loss: 0.20111888647079468
step: 160, loss: 0.1301903873682022
step: 170, loss: 0.15329675376415253
step: 180, loss: 0.3293221592903137
step: 190, loss: 0.33516842126846313
step: 200, loss: 0.13476696610450745
step: 210, loss: 0.11031816899776459
step: 220, loss: 0.12238991260528564
step: 230, loss: 0.20765411853790283
step: 240, loss: 0.13469460606575012
step: 250, loss: 0.05401381105184555
step: 260, loss: 0.3286339044570923
step: 270, loss: 0.15059636533260345
step: 280, loss: 0.3000277578830719
step: 290, loss: 0.10290620476007462
step: 300, loss: 0.13667072355747223
step: 310, loss: 0.16296057403087616
step: 320, loss: 0.4232562780380249
step: 330, loss: 0.270051509141922
step: 340, loss: 0.10545814782381058
step: 350, loss: 0.2845771908760071
step: 360, loss: 0.07206859439611435
epoch 1: dev_f1=0.6910994764397905, f1=0.6263157894736843, best_f1=0.6263157894736843
step: 0, loss: 0.2194589227437973
step: 10, loss: 0.08327038586139679
step: 20, loss: 0.09382038563489914
step: 30, loss: 0.1710825115442276
step: 40, loss: 0.10733236372470856
step: 50, loss: 0.36910107731819153
step: 60, loss: 0.3032395839691162
step: 70, loss: 0.06730030477046967
step: 80, loss: 0.2661665976047516
step: 90, loss: 0.07031785696744919
step: 100, loss: 0.09323154389858246
step: 110, loss: 0.4758901298046112
step: 120, loss: 0.05476715415716171
step: 130, loss: 0.3268367350101471
step: 140, loss: 0.09221679717302322
step: 150, loss: 0.06890025734901428
step: 160, loss: 0.13741908967494965
step: 170, loss: 0.028029749169945717
step: 180, loss: 0.15158285200595856
step: 190, loss: 0.2004980891942978
step: 200, loss: 0.11071987450122833
step: 210, loss: 0.20228251814842224
step: 220, loss: 0.18938305974006653
step: 230, loss: 0.07072656601667404
step: 240, loss: 0.3075181543827057
step: 250, loss: 0.20930632948875427
step: 260, loss: 0.1740005761384964
step: 270, loss: 0.3855820894241333
step: 280, loss: 0.11928052455186844
step: 290, loss: 0.22856180369853973
step: 300, loss: 0.05941498652100563
step: 310, loss: 0.12451264262199402
step: 320, loss: 0.11483266949653625
step: 330, loss: 0.027704983949661255
step: 340, loss: 0.12831313908100128
step: 350, loss: 0.005819610320031643
step: 360, loss: 0.07698369771242142
epoch 2: dev_f1=0.7083333333333333, f1=0.7204030226700252, best_f1=0.7204030226700252
step: 0, loss: 0.14667131006717682
step: 10, loss: 0.08397697657346725
step: 20, loss: 0.08895503729581833
step: 30, loss: 0.10782123357057571
step: 40, loss: 0.07553382217884064
step: 50, loss: 0.08046115934848785
step: 60, loss: 0.049564044922590256
step: 70, loss: 0.12985879182815552
step: 80, loss: 0.07708003371953964
step: 90, loss: 0.17272834479808807
step: 100, loss: 0.06359390914440155
step: 110, loss: 0.24377059936523438
step: 120, loss: 0.09376777708530426
step: 130, loss: 0.07554441690444946
step: 140, loss: 0.1598542332649231
step: 150, loss: 0.053490977734327316
step: 160, loss: 0.06753135472536087
step: 170, loss: 0.0989966168999672
step: 180, loss: 0.11501818150281906
step: 190, loss: 0.12637020647525787
step: 200, loss: 0.07318343222141266
step: 210, loss: 0.15486332774162292
step: 220, loss: 0.11119547486305237
step: 230, loss: 0.13573706150054932
step: 240, loss: 0.12369430810213089
step: 250, loss: 0.12949693202972412
step: 260, loss: 0.07769578695297241
step: 270, loss: 0.02502298727631569
step: 280, loss: 0.16152901947498322
step: 290, loss: 0.04113195091485977
step: 300, loss: 0.22588683664798737
step: 310, loss: 0.10353247821331024
step: 320, loss: 0.2228352427482605
step: 330, loss: 0.11508162319660187
step: 340, loss: 0.04328322410583496
step: 350, loss: 0.19399593770503998
step: 360, loss: 0.09545466303825378
epoch 3: dev_f1=0.7447916666666665, f1=0.7387862796833773, best_f1=0.7387862796833773
step: 0, loss: 0.03071436658501625
step: 10, loss: 0.12665970623493195
step: 20, loss: 0.009380482137203217
step: 30, loss: 0.1362166553735733
step: 40, loss: 0.14562052488327026
step: 50, loss: 0.05169694125652313
step: 60, loss: 0.18186478316783905
step: 70, loss: 0.07748830318450928
step: 80, loss: 0.22747915983200073
step: 90, loss: 0.07873009145259857
step: 100, loss: 0.13712340593338013
step: 110, loss: 0.05076204985380173
step: 120, loss: 0.030321210622787476
step: 130, loss: 0.08309726417064667
step: 140, loss: 0.16631987690925598
step: 150, loss: 0.09282328188419342
step: 160, loss: 0.09782890230417252
step: 170, loss: 0.029235253110527992
step: 180, loss: 0.11155111342668533
step: 190, loss: 0.1587238758802414
step: 200, loss: 0.055267926305532455
step: 210, loss: 0.02651749923825264
step: 220, loss: 0.06621823459863663
step: 230, loss: 0.04146797955036163
step: 240, loss: 0.19669543206691742
step: 250, loss: 0.03287326544523239
step: 260, loss: 0.24792596697807312
step: 270, loss: 0.15543106198310852
step: 280, loss: 0.1746741235256195
step: 290, loss: 0.006937929429113865
step: 300, loss: 0.2743767499923706
step: 310, loss: 0.0515335351228714
step: 320, loss: 0.20819231867790222
step: 330, loss: 0.11732278019189835
step: 340, loss: 0.09081398695707321
step: 350, loss: 0.01223660446703434
step: 360, loss: 0.060794830322265625
epoch 4: dev_f1=0.7656612529002319, f1=0.7398568019093079, best_f1=0.7398568019093079
step: 0, loss: 0.06866481155157089
step: 10, loss: 0.031351156532764435
step: 20, loss: 0.10524661839008331
step: 30, loss: 0.059438735246658325
step: 40, loss: 0.09837345033884048
step: 50, loss: 0.10492529720067978
step: 60, loss: 0.17442749440670013
step: 70, loss: 0.08122862875461578
step: 80, loss: 0.09235132485628128
step: 90, loss: 0.09283256530761719
step: 100, loss: 0.07211293280124664
step: 110, loss: 0.08028912544250488
step: 120, loss: 0.041726045310497284
step: 130, loss: 0.06329885870218277
step: 140, loss: 0.09859353303909302
step: 150, loss: 0.16971763968467712
step: 160, loss: 0.08757762610912323
step: 170, loss: 0.13194027543067932
step: 180, loss: 0.13115264475345612
step: 190, loss: 0.10460419952869415
step: 200, loss: 0.06836920976638794
step: 210, loss: 0.10269984602928162
step: 220, loss: 0.10822466015815735
step: 230, loss: 0.06378381699323654
step: 240, loss: 0.1265934705734253
step: 250, loss: 0.07479915022850037
step: 260, loss: 0.016786014661192894
step: 270, loss: 0.09513765573501587
step: 280, loss: 0.1344275027513504
step: 290, loss: 0.12778259813785553
step: 300, loss: 0.03733813762664795
step: 310, loss: 0.09056808799505234
step: 320, loss: 0.11980215460062027
step: 330, loss: 0.07646740227937698
step: 340, loss: 0.13583692908287048
step: 350, loss: 0.12584391236305237
step: 360, loss: 0.10509668290615082
epoch 5: dev_f1=0.7626666666666667, f1=0.734375, best_f1=0.7398568019093079
step: 0, loss: 0.050051044672727585
step: 10, loss: 0.05210109055042267
step: 20, loss: 0.04283706471323967
step: 30, loss: 0.06013547629117966
step: 40, loss: 0.06463462114334106
step: 50, loss: 0.1052524745464325
step: 60, loss: 0.06468144804239273
step: 70, loss: 0.06307973712682724
step: 80, loss: 0.0001752642565406859
step: 90, loss: 0.06879714131355286
step: 100, loss: 0.0290534645318985
step: 110, loss: 0.09798784554004669
step: 120, loss: 0.010746200568974018
step: 130, loss: 0.0531558059155941
step: 140, loss: 0.10550453513860703
step: 150, loss: 0.08736433833837509
step: 160, loss: 0.012034351006150246
step: 170, loss: 0.14530697464942932
step: 180, loss: 0.07781120389699936
step: 190, loss: 0.03828129544854164
step: 200, loss: 0.07286012917757034
step: 210, loss: 0.03669751062989235
step: 220, loss: 0.13132518529891968
step: 230, loss: 0.049524225294589996
step: 240, loss: 0.006495586596429348
step: 250, loss: 0.118800088763237
step: 260, loss: 0.08468034863471985
step: 270, loss: 0.05914808809757233
step: 280, loss: 0.04851772263646126
step: 290, loss: 0.036402378231287
step: 300, loss: 0.10020069032907486
step: 310, loss: 0.04056505113840103
step: 320, loss: 0.08882797509431839
step: 330, loss: 0.07370125502347946
step: 340, loss: 0.09153585135936737
step: 350, loss: 0.052117977291345596
step: 360, loss: 0.08791454136371613
epoch 6: dev_f1=0.751219512195122, f1=0.7290640394088671, best_f1=0.7398568019093079
step: 0, loss: 0.06860504299402237
step: 10, loss: 0.057631317526102066
step: 20, loss: 0.05859570577740669
step: 30, loss: 0.07751411199569702
step: 40, loss: 0.03362175449728966
step: 50, loss: 0.08286209404468536
step: 60, loss: 0.06835340708494186
step: 70, loss: 0.10796640813350677
step: 80, loss: 0.047703079879283905
step: 90, loss: 0.12174972146749496
step: 100, loss: 0.07953881472349167
step: 110, loss: 0.07550046592950821
step: 120, loss: 0.015487662516534328
step: 130, loss: 0.04118380323052406
step: 140, loss: 0.022058257833123207
step: 150, loss: 0.042675092816352844
step: 160, loss: 0.07113799452781677
step: 170, loss: 0.1330925077199936
step: 180, loss: 0.05567130818963051
step: 190, loss: 0.10482687503099442
step: 200, loss: 0.05745095759630203
step: 210, loss: 0.04147956520318985
step: 220, loss: 0.11134158074855804
step: 230, loss: 0.08726102858781815
step: 240, loss: 0.05496229976415634
step: 250, loss: 0.1346723586320877
step: 260, loss: 0.08119846135377884
step: 270, loss: 0.15152888000011444
step: 280, loss: 0.11985716223716736
step: 290, loss: 0.07959883660078049
step: 300, loss: 0.05936712771654129
step: 310, loss: 0.1775142252445221
step: 320, loss: 0.09392458200454712
step: 330, loss: 0.05430474877357483
step: 340, loss: 0.12880165874958038
step: 350, loss: 0.09773079305887222
step: 360, loss: 0.07494360953569412
epoch 7: dev_f1=0.7753086419753086, f1=0.7435897435897435, best_f1=0.7435897435897435
step: 0, loss: 0.08959805965423584
step: 10, loss: 0.04997706040740013
step: 20, loss: 0.09508665651082993
step: 30, loss: 0.08209624886512756
step: 40, loss: 0.07713969051837921
step: 50, loss: 0.0752078965306282
step: 60, loss: 0.049241021275520325
step: 70, loss: 0.06697138398885727
step: 80, loss: 0.029667209833860397
step: 90, loss: 0.06623681634664536
step: 100, loss: 0.12472903728485107
step: 110, loss: 0.04773508757352829
step: 120, loss: 0.12351296097040176
step: 130, loss: 0.03338593989610672
step: 140, loss: 0.06627002358436584
step: 150, loss: 0.08280555158853531
step: 160, loss: 0.18620280921459198
step: 170, loss: 0.03171192854642868
step: 180, loss: 0.0641254186630249
step: 190, loss: 0.07533249258995056
step: 200, loss: 0.06611493229866028
step: 210, loss: 0.18848086893558502
step: 220, loss: 0.0559011735022068
step: 230, loss: 0.09534510970115662
step: 240, loss: 0.08919273316860199
step: 250, loss: 0.06019861623644829
step: 260, loss: 0.03216276317834854
step: 270, loss: 0.17848965525627136
step: 280, loss: 0.037825316190719604
step: 290, loss: 0.041021231561899185
step: 300, loss: 0.011480990797281265
step: 310, loss: 0.10077303647994995
step: 320, loss: 0.11956396698951721
step: 330, loss: 0.06990697234869003
step: 340, loss: 0.04551107436418533
step: 350, loss: 0.11411339044570923
step: 360, loss: 0.058235831558704376
epoch 8: dev_f1=0.7531806615776082, f1=0.7295918367346937, best_f1=0.7435897435897435
step: 0, loss: 0.046887364238500595
step: 10, loss: 0.05734376236796379
step: 20, loss: 0.01364297978579998
step: 30, loss: 0.01756102219223976
step: 40, loss: 0.03702423721551895
step: 50, loss: 0.07353855669498444
step: 60, loss: 0.13825242221355438
step: 70, loss: 0.060272157192230225
step: 80, loss: 0.07466233521699905
step: 90, loss: 0.035283561795949936
step: 100, loss: 0.032097261399030685
step: 110, loss: 0.12822075188159943
step: 120, loss: 0.06513429433107376
step: 130, loss: 0.0846242755651474
step: 140, loss: 0.23654726147651672
step: 150, loss: 0.0961608812212944
step: 160, loss: 0.058160748332738876
step: 170, loss: 0.08651088923215866
step: 180, loss: 0.035562798380851746
step: 190, loss: 0.05085478723049164
step: 200, loss: 0.0820692628622055
step: 210, loss: 0.037125278264284134
step: 220, loss: 0.02796206623315811
step: 230, loss: 0.0568261444568634
step: 240, loss: 0.0799098089337349
step: 250, loss: 0.17405518889427185
step: 260, loss: 0.1095159500837326
step: 270, loss: 0.0014590155333280563
step: 280, loss: 0.07291456311941147
step: 290, loss: 0.10939297080039978
step: 300, loss: 0.02935686707496643
step: 310, loss: 0.09038686007261276
step: 320, loss: 0.16370107233524323
step: 330, loss: 0.0706300139427185
step: 340, loss: 0.08752798289060593
step: 350, loss: 0.04573068767786026
step: 360, loss: 0.08295157551765442
epoch 9: dev_f1=0.7642679900744417, f1=0.7448979591836734, best_f1=0.7435897435897435
step: 0, loss: 0.08800525218248367
step: 10, loss: 0.13915874063968658
step: 20, loss: 0.08493423461914062
step: 30, loss: 0.06678446382284164
step: 40, loss: 0.06288719922304153
step: 50, loss: 0.06433465331792831
step: 60, loss: 0.03814459219574928
step: 70, loss: 0.10221502929925919
step: 80, loss: 0.06844757497310638
step: 90, loss: 0.09929876029491425
step: 100, loss: 0.023503758013248444
step: 110, loss: 0.08537983894348145
step: 120, loss: 0.09216012060642242
step: 130, loss: 0.05743696540594101
step: 140, loss: 0.05719843879342079
step: 150, loss: 0.036261770874261856
step: 160, loss: 0.058253683149814606
step: 170, loss: 0.05416933819651604
step: 180, loss: 0.059759095311164856
step: 190, loss: 0.09874755889177322
step: 200, loss: 0.06980397552251816
step: 210, loss: 0.04200752452015877
step: 220, loss: 0.06303741782903671
step: 230, loss: 0.04551496356725693
step: 240, loss: 0.015671471133828163
step: 250, loss: 0.10576284676790237
step: 260, loss: 0.07755442708730698
step: 270, loss: 0.1836242526769638
step: 280, loss: 0.10616748780012131
step: 290, loss: 5.7728419051272795e-05
step: 300, loss: 0.1251286119222641
step: 310, loss: 0.08441311120986938
step: 320, loss: 0.10822232812643051
step: 330, loss: 0.0846404954791069
step: 340, loss: 0.13301493227481842
step: 350, loss: 0.05515926331281662
step: 360, loss: 0.02660844475030899
epoch 10: dev_f1=0.7297297297297296, f1=0.7096774193548386, best_f1=0.7435897435897435
step: 0, loss: 0.10991843789815903
step: 10, loss: 0.053155239671468735
step: 20, loss: 0.017164895310997963
step: 30, loss: 0.047799497842788696
step: 40, loss: 0.051573190838098526
step: 50, loss: 0.027845121920108795
step: 60, loss: 0.036849986761808395
step: 70, loss: 0.12139589339494705
step: 80, loss: 0.1623176485300064
step: 90, loss: 0.05585616081953049
step: 100, loss: 0.006835111882537603
step: 110, loss: 0.09106069058179855
step: 120, loss: 0.07341105490922928
step: 130, loss: 0.08362041413784027
step: 140, loss: 0.01672479696571827
step: 150, loss: 0.034912217408418655
step: 160, loss: 0.02817423641681671
step: 170, loss: 0.06850481778383255
step: 180, loss: 0.013360060751438141
step: 190, loss: 0.04494748264551163
step: 200, loss: 0.08625919371843338
step: 210, loss: 0.1053726002573967
step: 220, loss: 0.10757536441087723
step: 230, loss: 0.06583091616630554
step: 240, loss: 0.05038497596979141
step: 250, loss: 0.016519073396921158
step: 260, loss: 0.3552394509315491
step: 270, loss: 0.055047810077667236
step: 280, loss: 0.036392468959093094
step: 290, loss: 0.4604511559009552
step: 300, loss: 0.08120077103376389
step: 310, loss: 0.06147509068250656
step: 320, loss: 0.17944484949111938
step: 330, loss: 0.13122649490833282
step: 340, loss: 0.01868082955479622
step: 350, loss: 0.2320837676525116
step: 360, loss: 0.05677264183759689
epoch 11: dev_f1=0.7475728155339805, f1=0.7178217821782177, best_f1=0.7435897435897435
step: 0, loss: 0.07222393900156021
step: 10, loss: 0.04660589620471001
step: 20, loss: 0.09393389523029327
step: 30, loss: 0.026063481345772743
step: 40, loss: 0.05246701091527939
step: 50, loss: 0.0015014988603070378
step: 60, loss: 0.002348479116335511
step: 70, loss: 0.07783912867307663
step: 80, loss: 0.05073452368378639
step: 90, loss: 0.08415327221155167
step: 100, loss: 0.10208475589752197
step: 110, loss: 0.06343258172273636
step: 120, loss: 0.052228257060050964
step: 130, loss: 0.007297266740351915
step: 140, loss: 0.011079357005655766
step: 150, loss: 0.07866742461919785
step: 160, loss: 0.1997598260641098
step: 170, loss: 0.2804822623729706
step: 180, loss: 0.11681229621171951
step: 190, loss: 0.06193557009100914
step: 200, loss: 0.0601709820330143
step: 210, loss: 0.011691469699144363
step: 220, loss: 0.04725944995880127
step: 230, loss: 0.11286637932062149
step: 240, loss: 0.018596244975924492
step: 250, loss: 0.034302227199077606
step: 260, loss: 0.08880820870399475
step: 270, loss: 0.1571648269891739
step: 280, loss: 0.04915419593453407
step: 290, loss: 0.0018839057302102447
step: 300, loss: 0.05135268345475197
step: 310, loss: 0.05072096735239029
step: 320, loss: 0.04666554555296898
step: 330, loss: 0.01756902039051056
step: 340, loss: 0.0375126414000988
step: 350, loss: 0.03572561591863632
step: 360, loss: 0.0316920205950737
epoch 12: dev_f1=0.7696335078534032, f1=0.7100271002710027, best_f1=0.7435897435897435
step: 0, loss: 0.0634632483124733
step: 10, loss: 0.046823807060718536
step: 20, loss: 0.01739543490111828
step: 30, loss: 0.07542316615581512
step: 40, loss: 0.02945493906736374
step: 50, loss: 0.006659835111349821
step: 60, loss: 0.04752659797668457
step: 70, loss: 0.16325737535953522
step: 80, loss: 0.016261814162135124
step: 90, loss: 0.040193527936935425
step: 100, loss: 0.017629794776439667
step: 110, loss: 0.06544508039951324
step: 120, loss: 0.04821927472949028
step: 130, loss: 0.018368953838944435
step: 140, loss: 0.0280366912484169
step: 150, loss: 0.04236657917499542
step: 160, loss: 0.08677273988723755
step: 170, loss: 0.016309214755892754
step: 180, loss: 0.022546587511897087
step: 190, loss: 0.005449794698506594
step: 200, loss: 0.006132909096777439
step: 210, loss: 0.039612043648958206
step: 220, loss: 0.0022144385147839785
step: 230, loss: 0.030145669355988503
step: 240, loss: 0.06315088272094727
step: 250, loss: 0.10107409209012985
step: 260, loss: 0.055533986538648605
step: 270, loss: 0.10641460865736008
step: 280, loss: 0.00990370474755764
step: 290, loss: 0.07169134169816971
step: 300, loss: 0.006897458806633949
step: 310, loss: 0.025032948702573776
step: 320, loss: 0.027574453502893448
step: 330, loss: 0.03564215078949928
step: 340, loss: 0.07973700016736984
step: 350, loss: 0.04053875431418419
step: 360, loss: 0.04794657230377197
epoch 13: dev_f1=0.7549019607843136, f1=0.7254901960784313, best_f1=0.7435897435897435
step: 0, loss: 0.03036661073565483
step: 10, loss: 0.03299446403980255
step: 20, loss: 0.01805262267589569
step: 30, loss: 0.04444406181573868
step: 40, loss: 0.04280894249677658
step: 50, loss: 0.040640939027071
step: 60, loss: 0.0524844266474247
step: 70, loss: 0.04620815068483353
step: 80, loss: 0.10270950943231583
step: 90, loss: 0.04392287880182266
step: 100, loss: 0.012383862398564816
step: 110, loss: 0.01610555313527584
step: 120, loss: 0.039834730327129364
step: 130, loss: 0.0007943766540847719
step: 140, loss: 0.021476833149790764
step: 150, loss: 0.017798541113734245
step: 160, loss: 0.02240980789065361
step: 170, loss: 0.0694664716720581
step: 180, loss: 0.14054402709007263
step: 190, loss: 0.03974708914756775
step: 200, loss: 0.027466842904686928
step: 210, loss: 0.008640887215733528
step: 220, loss: 0.07190250605344772
step: 230, loss: 0.03910008445382118
step: 240, loss: 0.07610347867012024
step: 250, loss: 0.02512689307332039
step: 260, loss: 0.015102929435670376
step: 270, loss: 0.00013821333413943648
step: 280, loss: 0.06683245301246643
step: 290, loss: 0.025942567735910416
step: 300, loss: 0.03473507985472679
step: 310, loss: 0.016170039772987366
step: 320, loss: 0.06139873340725899
step: 330, loss: 0.014585128054022789
step: 340, loss: 0.07426595687866211
step: 350, loss: 0.016980847343802452
step: 360, loss: 0.0232955664396286
epoch 14: dev_f1=0.7428571428571429, f1=0.6985645933014354, best_f1=0.7435897435897435
step: 0, loss: 0.031151417642831802
step: 10, loss: 0.012152058072388172
step: 20, loss: 0.027334578335285187
step: 30, loss: 0.06997428834438324
step: 40, loss: 0.012027833610773087
step: 50, loss: 0.005405791569501162
step: 60, loss: 0.07794759422540665
step: 70, loss: 0.040449898689985275
step: 80, loss: 0.014319108799099922
step: 90, loss: 0.07829666137695312
step: 100, loss: 0.059936054050922394
step: 110, loss: 0.060542840510606766
step: 120, loss: 0.05348372459411621
step: 130, loss: 0.13626688718795776
step: 140, loss: 0.03737621381878853
step: 150, loss: 0.10992615669965744
step: 160, loss: 0.051770247519016266
step: 170, loss: 0.09871784597635269
step: 180, loss: 0.020203357562422752
step: 190, loss: 0.002293909899890423
step: 200, loss: 0.11863909661769867
step: 210, loss: 0.07060765475034714
step: 220, loss: 0.004970950074493885
step: 230, loss: 0.02289467677474022
step: 240, loss: 0.03450704365968704
step: 250, loss: 0.012436341494321823
step: 260, loss: 0.008589442819356918
step: 270, loss: 4.929802526021376e-05
step: 280, loss: 0.15192893147468567
step: 290, loss: 0.029856206849217415
step: 300, loss: 0.04108147323131561
step: 310, loss: 0.06702686846256256
step: 320, loss: 0.03862088918685913
step: 330, loss: 0.023874850943684578
step: 340, loss: 0.02523905783891678
step: 350, loss: 0.03205590322613716
step: 360, loss: 0.12818193435668945
epoch 15: dev_f1=0.7282321899736147, f1=0.6827956989247312, best_f1=0.7435897435897435
step: 0, loss: 0.06419927626848221
step: 10, loss: 0.05480002611875534
step: 20, loss: 0.11273209005594254
step: 30, loss: 0.06896903365850449
step: 40, loss: 0.027898289263248444
step: 50, loss: 0.08069230616092682
step: 60, loss: 0.08583032339811325
step: 70, loss: 0.054661933332681656
step: 80, loss: 0.02416093647480011
step: 90, loss: 0.02786073088645935
step: 100, loss: 0.2396208941936493
step: 110, loss: 0.08564808964729309
step: 120, loss: 0.09247293323278427
step: 130, loss: 0.09249667823314667
step: 140, loss: 0.08344538509845734
step: 150, loss: 0.04445715248584747
step: 160, loss: 0.045850712805986404
step: 170, loss: 0.015908682718873024
step: 180, loss: 0.007563836872577667
step: 190, loss: 0.06754054129123688
step: 200, loss: 0.02014302648603916
step: 210, loss: 0.050157252699136734
step: 220, loss: 0.015120144933462143
step: 230, loss: 0.0011429984588176012
step: 240, loss: 0.015823738649487495
step: 250, loss: 0.21234914660453796
step: 260, loss: 0.05033797025680542
step: 270, loss: 0.005657783709466457
step: 280, loss: 0.011508556082844734
step: 290, loss: 0.13352352380752563
step: 300, loss: 0.0405106320977211
step: 310, loss: 0.05986229330301285
step: 320, loss: 0.05063910409808159
step: 330, loss: 0.10562821477651596
step: 340, loss: 0.06321438401937485
step: 350, loss: 0.042893607169389725
step: 360, loss: 0.08183090388774872
epoch 16: dev_f1=0.7409326424870466, f1=0.7108753315649867, best_f1=0.7435897435897435
step: 0, loss: 0.014869294129312038
step: 10, loss: 0.07558723539113998
step: 20, loss: 0.00488300109282136
step: 30, loss: 0.005329015664756298
step: 40, loss: 0.06513209640979767
step: 50, loss: 0.0030802469700574875
step: 60, loss: 0.045228298753499985
step: 70, loss: 0.038198065012693405
step: 80, loss: 0.007609298452734947
step: 90, loss: 0.016527574509382248
step: 100, loss: 0.05018463730812073
step: 110, loss: 0.07174103707075119
step: 120, loss: 0.022765841335058212
step: 130, loss: 0.02441103383898735
step: 140, loss: 0.043280068784952164
step: 150, loss: 0.02626839652657509
step: 160, loss: 0.06241796910762787
step: 170, loss: 0.07955009490251541
step: 180, loss: 0.015351465903222561
step: 190, loss: 0.06861512362957001
step: 200, loss: 0.04497430846095085
step: 210, loss: 0.076888307929039
step: 220, loss: 6.55193070997484e-05
step: 230, loss: 0.00532293226569891
step: 240, loss: 0.10640560835599899
step: 250, loss: 0.02655470184981823
step: 260, loss: 0.005457413382828236
step: 270, loss: 0.06277211010456085
step: 280, loss: 0.011945239268243313
step: 290, loss: 0.024800052866339684
step: 300, loss: 0.04498222470283508
step: 310, loss: 0.023201676085591316
step: 320, loss: 0.08889266103506088
step: 330, loss: 0.00025761601864360273
step: 340, loss: 0.041252560913562775
step: 350, loss: 0.06911075115203857
step: 360, loss: 0.022311702370643616
epoch 17: dev_f1=0.7418546365914787, f1=0.7314578005115089, best_f1=0.7435897435897435
step: 0, loss: 0.08212147653102875
step: 10, loss: 0.05220005288720131
step: 20, loss: 0.018596285954117775
step: 30, loss: 0.03473145142197609
step: 40, loss: 0.01185251772403717
step: 50, loss: 0.03201590105891228
step: 60, loss: 0.0004269380879122764
step: 70, loss: 0.13239040970802307
step: 80, loss: 0.03832630813121796
step: 90, loss: 0.11758360266685486
step: 100, loss: 0.024175027385354042
step: 110, loss: 0.06486258655786514
step: 120, loss: 0.03131844475865364
step: 130, loss: 0.019189294427633286
step: 140, loss: 0.09278149902820587
step: 150, loss: 5.7574656239012256e-05
step: 160, loss: 0.02508988231420517
step: 170, loss: 0.06266342103481293
step: 180, loss: 0.03206941485404968
step: 190, loss: 0.012131576426327229
step: 200, loss: 0.017022553831338882
step: 210, loss: 0.06322693824768066
step: 220, loss: 0.02670486643910408
step: 230, loss: 0.07540732622146606
step: 240, loss: 0.003919955808669329
step: 250, loss: 0.0387989841401577
step: 260, loss: 0.012432930059731007
step: 270, loss: 0.021544575691223145
step: 280, loss: 0.028906818479299545
step: 290, loss: 0.03771936893463135
step: 300, loss: 0.0010528225684538484
step: 310, loss: 0.05385095253586769
step: 320, loss: 0.0016427122754976153
step: 330, loss: 0.026707258075475693
step: 340, loss: 0.08021476864814758
step: 350, loss: 0.056011855602264404
step: 360, loss: 0.022845501080155373
epoch 18: dev_f1=0.744186046511628, f1=0.7116883116883116, best_f1=0.7435897435897435
step: 0, loss: 7.905298116384074e-05
step: 10, loss: 0.00018532335525378585
step: 20, loss: 2.949206464109011e-05
step: 30, loss: 0.008155398070812225
step: 40, loss: 0.05407007038593292
step: 50, loss: 0.0896574854850769
step: 60, loss: 0.08465605974197388
step: 70, loss: 0.005006982013583183
step: 80, loss: 0.021840227767825127
step: 90, loss: 0.06016562879085541
step: 100, loss: 0.05624885484576225
step: 110, loss: 0.0007077677873894572
step: 120, loss: 0.0021589724346995354
step: 130, loss: 0.05936579033732414
step: 140, loss: 0.07037590444087982
step: 150, loss: 0.011100632138550282
step: 160, loss: 0.08734563738107681
step: 170, loss: 0.09498143196105957
step: 180, loss: 0.12073806673288345
step: 190, loss: 0.0530129000544548
step: 200, loss: 0.036996494978666306
step: 210, loss: 0.11487996578216553
step: 220, loss: 0.0994056984782219
step: 230, loss: 0.09351430088281631
step: 240, loss: 0.01871587708592415
step: 250, loss: 3.809638292295858e-05
step: 260, loss: 0.04305821284651756
step: 270, loss: 0.11827106028795242
step: 280, loss: 0.03951357305049896
step: 290, loss: 0.07063428312540054
step: 300, loss: 0.08730020374059677
step: 310, loss: 0.049732815474271774
step: 320, loss: 0.011265208013355732
step: 330, loss: 0.004997481591999531
step: 340, loss: 0.000249627250013873
step: 350, loss: 0.02054748870432377
step: 360, loss: 0.08656159788370132
epoch 19: dev_f1=0.7387862796833773, f1=0.7055702917771883, best_f1=0.7435897435897435
step: 0, loss: 0.10058958828449249
step: 10, loss: 0.04340328276157379
step: 20, loss: 0.01569412462413311
step: 30, loss: 0.030544625595211983
step: 40, loss: 0.10413650423288345
step: 50, loss: 0.00895677786320448
step: 60, loss: 0.006849850993603468
step: 70, loss: 0.00027921341825276613
step: 80, loss: 0.020928656682372093
step: 90, loss: 0.011480172164738178
step: 100, loss: 0.07905212044715881
step: 110, loss: 0.032359104603528976
step: 120, loss: 0.00013503814989235252
step: 130, loss: 0.04735937714576721
step: 140, loss: 0.05684347450733185
step: 150, loss: 0.05762185528874397
step: 160, loss: 0.04039592668414116
step: 170, loss: 0.028635727241635323
step: 180, loss: 0.011593403294682503
step: 190, loss: 0.006642994936555624
step: 200, loss: 0.0004078951897099614
step: 210, loss: 0.023018913343548775
step: 220, loss: 0.00011760428606066853
step: 230, loss: 0.012474391609430313
step: 240, loss: 0.03252008184790611
step: 250, loss: 0.05125490203499794
step: 260, loss: 0.028621716424822807
step: 270, loss: 0.015350237488746643
step: 280, loss: 0.03576494753360748
step: 290, loss: 0.033365897834300995
step: 300, loss: 0.01306594256311655
step: 310, loss: 0.05659825727343559
step: 320, loss: 0.00456454511731863
step: 330, loss: 0.07146815955638885
step: 340, loss: 0.003999849781394005
step: 350, loss: 0.015231417492032051
step: 360, loss: 0.013425185345113277
epoch 20: dev_f1=0.7287234042553191, f1=0.6986666666666667, best_f1=0.7435897435897435
