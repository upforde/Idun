cuda
Device: cuda
step: 0, loss: 0.5902308821678162
step: 10, loss: 0.2408377081155777
step: 20, loss: 0.2274145931005478
step: 30, loss: 0.029403088614344597
step: 40, loss: 0.15920621156692505
step: 50, loss: 0.24258647859096527
step: 60, loss: 0.15012793242931366
step: 70, loss: 0.1436455249786377
step: 80, loss: 0.1365242451429367
step: 90, loss: 0.2282102257013321
step: 100, loss: 0.148682102560997
step: 110, loss: 0.1444167047739029
step: 120, loss: 0.22808651626110077
step: 130, loss: 0.058559298515319824
step: 140, loss: 0.14128804206848145
step: 150, loss: 0.13924604654312134
step: 160, loss: 0.21278594434261322
step: 170, loss: 0.2940134108066559
step: 180, loss: 0.21691851317882538
step: 190, loss: 0.21910415589809418
step: 200, loss: 0.2159610092639923
step: 210, loss: 0.05892537906765938
step: 220, loss: 0.04732618108391762
step: 230, loss: 0.30247458815574646
step: 240, loss: 0.12611958384513855
step: 250, loss: 0.12228529900312424
step: 260, loss: 0.08064872026443481
step: 270, loss: 0.19253481924533844
step: 280, loss: 0.474222332239151
step: 290, loss: 0.1426640748977661
step: 300, loss: 0.1163240298628807
step: 310, loss: 0.1496647596359253
step: 320, loss: 0.22810348868370056
step: 330, loss: 0.1805027276277542
step: 340, loss: 0.15873552858829498
step: 350, loss: 0.23015306890010834
step: 360, loss: 0.0289580300450325
epoch 1: dev_f1=0.5865384615384616, f1=0.5949656750572082, best_f1=0.5949656750572082
step: 0, loss: 0.03785726800560951
step: 10, loss: 0.19840283691883087
step: 20, loss: 0.41021284461021423
step: 30, loss: 0.154552161693573
step: 40, loss: 0.1802903115749359
step: 50, loss: 0.17900758981704712
step: 60, loss: 0.018871743232011795
step: 70, loss: 0.03640314191579819
step: 80, loss: 0.02020392194390297
step: 90, loss: 0.03930291533470154
step: 100, loss: 0.019526083022356033
step: 110, loss: 0.06945264339447021
step: 120, loss: 0.12825655937194824
step: 130, loss: 0.08677692711353302
step: 140, loss: 0.35786908864974976
step: 150, loss: 0.12623734772205353
step: 160, loss: 0.09760085493326187
step: 170, loss: 0.23554731905460358
step: 180, loss: 0.05640283226966858
step: 190, loss: 0.012885578908026218
step: 200, loss: 0.1486176699399948
step: 210, loss: 0.15627455711364746
step: 220, loss: 0.2014414668083191
step: 230, loss: 0.14862149953842163
step: 240, loss: 0.12814480066299438
step: 250, loss: 0.16735106706619263
step: 260, loss: 0.3364693820476532
step: 270, loss: 0.26201027631759644
step: 280, loss: 0.1325664073228836
step: 290, loss: 0.10245552659034729
step: 300, loss: 0.014582431875169277
step: 310, loss: 0.11647839844226837
step: 320, loss: 0.07605120539665222
step: 330, loss: 0.22162792086601257
step: 340, loss: 0.11268804967403412
step: 350, loss: 0.04533547908067703
step: 360, loss: 0.05970711633563042
epoch 2: dev_f1=0.7135416666666666, f1=0.6683673469387754, best_f1=0.6683673469387754
step: 0, loss: 0.16384229063987732
step: 10, loss: 0.08418408036231995
step: 20, loss: 0.09651046246290207
step: 30, loss: 0.06171953305602074
step: 40, loss: 0.13883374631404877
step: 50, loss: 0.11498796939849854
step: 60, loss: 0.09585654735565186
step: 70, loss: 0.0839231088757515
step: 80, loss: 0.1847708374261856
step: 90, loss: 0.154236301779747
step: 100, loss: 0.037372887134552
step: 110, loss: 0.07824203372001648
step: 120, loss: 0.11577681452035904
step: 130, loss: 0.358142226934433
step: 140, loss: 0.12056928873062134
step: 150, loss: 0.10450682044029236
step: 160, loss: 0.08488572388887405
step: 170, loss: 0.12179698050022125
step: 180, loss: 0.1114388182759285
step: 190, loss: 0.09494224190711975
step: 200, loss: 0.07245492190122604
step: 210, loss: 0.16988463699817657
step: 220, loss: 0.12445032596588135
step: 230, loss: 0.06338062137365341
step: 240, loss: 0.040218815207481384
step: 250, loss: 0.07540284842252731
step: 260, loss: 0.1658501774072647
step: 270, loss: 0.04650929942727089
step: 280, loss: 0.16189154982566833
step: 290, loss: 0.2191052883863449
step: 300, loss: 0.0647900402545929
step: 310, loss: 0.2018921971321106
step: 320, loss: 0.07287660241127014
step: 330, loss: 0.15172560513019562
step: 340, loss: 0.047619350254535675
step: 350, loss: 0.1640932559967041
step: 360, loss: 0.031527452170848846
epoch 3: dev_f1=0.7138964577656676, f1=0.6949602122015915, best_f1=0.6949602122015915
step: 0, loss: 0.10419098287820816
step: 10, loss: 0.14368197321891785
step: 20, loss: 0.048560820519924164
step: 30, loss: 0.09664429724216461
step: 40, loss: 0.07411734759807587
step: 50, loss: 0.1888914406299591
step: 60, loss: 0.062320906668901443
step: 70, loss: 0.09558067470788956
step: 80, loss: 0.24058175086975098
step: 90, loss: 0.12595990300178528
step: 100, loss: 0.03241207078099251
step: 110, loss: 0.09109169989824295
step: 120, loss: 0.024007586762309074
step: 130, loss: 0.1861044466495514
step: 140, loss: 0.032981932163238525
step: 150, loss: 0.14842106401920319
step: 160, loss: 0.08477572351694107
step: 170, loss: 0.2079373300075531
step: 180, loss: 0.03704797476530075
step: 190, loss: 0.03978274390101433
step: 200, loss: 0.09960009157657623
step: 210, loss: 0.16160522401332855
step: 220, loss: 0.11893706768751144
step: 230, loss: 0.2688438296318054
step: 240, loss: 0.08655298501253128
step: 250, loss: 0.03767632320523262
step: 260, loss: 0.0852418765425682
step: 270, loss: 0.04686138406395912
step: 280, loss: 0.07544602453708649
step: 290, loss: 0.1093880906701088
step: 300, loss: 0.0805581733584404
step: 310, loss: 0.09841818362474442
step: 320, loss: 0.029206110164523125
step: 330, loss: 0.12371402233839035
step: 340, loss: 0.11903822422027588
step: 350, loss: 0.09595649689435959
step: 360, loss: 0.004276507534086704
epoch 4: dev_f1=0.7158469945355191, f1=0.7127071823204421, best_f1=0.7127071823204421
step: 0, loss: 0.0898054987192154
step: 10, loss: 0.05368871986865997
step: 20, loss: 0.0924772322177887
step: 30, loss: 0.15281891822814941
step: 40, loss: 0.1211152970790863
step: 50, loss: 0.06217477470636368
step: 60, loss: 0.03164852410554886
step: 70, loss: 0.08984352648258209
step: 80, loss: 0.04701874777674675
step: 90, loss: 0.0034676874056458473
step: 100, loss: 0.09485606849193573
step: 110, loss: 0.05185023322701454
step: 120, loss: 0.09794478118419647
step: 130, loss: 0.16915246844291687
step: 140, loss: 0.1114313080906868
step: 150, loss: 0.13108409941196442
step: 160, loss: 0.11619260907173157
step: 170, loss: 0.058047741651535034
step: 180, loss: 0.076184943318367
step: 190, loss: 0.04146356135606766
step: 200, loss: 0.09111861139535904
step: 210, loss: 0.13165637850761414
step: 220, loss: 0.24583622813224792
step: 230, loss: 0.05257464200258255
step: 240, loss: 0.07594846189022064
step: 250, loss: 0.02562510222196579
step: 260, loss: 0.05358845740556717
step: 270, loss: 0.12460112571716309
step: 280, loss: 0.12269624322652817
step: 290, loss: 0.0952165499329567
step: 300, loss: 0.014235978946089745
step: 310, loss: 0.015808098018169403
step: 320, loss: 0.05364872142672539
step: 330, loss: 0.21995609998703003
step: 340, loss: 0.057399626821279526
step: 350, loss: 0.08442708104848862
step: 360, loss: 0.07932228595018387
epoch 5: dev_f1=0.7254901960784313, f1=0.6977886977886977, best_f1=0.6977886977886977
step: 0, loss: 0.17262284457683563
step: 10, loss: 0.09135247766971588
step: 20, loss: 0.1165783554315567
step: 30, loss: 0.10213922709226608
step: 40, loss: 0.08322582393884659
step: 50, loss: 0.09839639812707901
step: 60, loss: 0.05012532323598862
step: 70, loss: 0.24141070246696472
step: 80, loss: 0.07759203016757965
step: 90, loss: 0.10334299504756927
step: 100, loss: 0.1082167774438858
step: 110, loss: 0.0524890273809433
step: 120, loss: 0.018987976014614105
step: 130, loss: 0.05109412968158722
step: 140, loss: 0.10766145586967468
step: 150, loss: 0.05960233509540558
step: 160, loss: 0.032300811260938644
step: 170, loss: 0.18754298985004425
step: 180, loss: 0.12596549093723297
step: 190, loss: 0.05025952309370041
step: 200, loss: 0.0999915823340416
step: 210, loss: 0.01422885712236166
step: 220, loss: 0.08732575178146362
step: 230, loss: 0.052856769412755966
step: 240, loss: 0.019705770537257195
step: 250, loss: 0.09598897397518158
step: 260, loss: 0.11987742781639099
step: 270, loss: 0.2129196971654892
step: 280, loss: 0.1138089969754219
step: 290, loss: 0.034655846655368805
step: 300, loss: 0.03384491056203842
step: 310, loss: 0.3673361539840698
step: 320, loss: 0.08853083103895187
step: 330, loss: 0.028468742966651917
step: 340, loss: 0.12372229993343353
step: 350, loss: 0.07765939831733704
step: 360, loss: 0.05658679082989693
epoch 6: dev_f1=0.7100000000000001, f1=0.6915422885572139, best_f1=0.6977886977886977
step: 0, loss: 0.047117069363594055
step: 10, loss: 0.08452729135751724
step: 20, loss: 0.03313351422548294
step: 30, loss: 0.0014340529451146722
step: 40, loss: 0.08198437094688416
step: 50, loss: 0.037032365798950195
step: 60, loss: 0.007797968573868275
step: 70, loss: 0.023776825517416
step: 80, loss: 0.02239226922392845
step: 90, loss: 0.057733628898859024
step: 100, loss: 0.020891660824418068
step: 110, loss: 0.06446360796689987
step: 120, loss: 0.125434011220932
step: 130, loss: 0.0209413543343544
step: 140, loss: 0.09993497282266617
step: 150, loss: 0.041868727654218674
step: 160, loss: 0.09362858533859253
step: 170, loss: 0.08291105926036835
step: 180, loss: 0.0770145133137703
step: 190, loss: 0.14364267885684967
step: 200, loss: 0.06499166786670685
step: 210, loss: 0.1281241476535797
step: 220, loss: 0.1018466204404831
step: 230, loss: 0.035285815596580505
step: 240, loss: 0.10743307322263718
step: 250, loss: 0.028424076735973358
step: 260, loss: 0.1471722424030304
step: 270, loss: 0.13504217565059662
step: 280, loss: 0.03162401542067528
step: 290, loss: 0.11229171603918076
step: 300, loss: 0.05373759567737579
step: 310, loss: 0.01732233725488186
step: 320, loss: 0.06283547729253769
step: 330, loss: 0.0656467080116272
step: 340, loss: 0.13718010485172272
step: 350, loss: 0.05984468385577202
step: 360, loss: 0.10416509211063385
epoch 7: dev_f1=0.6889952153110047, f1=0.6810551558752997, best_f1=0.6977886977886977
step: 0, loss: 0.06941463053226471
step: 10, loss: 0.12146762013435364
step: 20, loss: 0.12810122966766357
step: 30, loss: 0.09336310625076294
step: 40, loss: 0.14967191219329834
step: 50, loss: 0.08874385058879852
step: 60, loss: 0.012151357717812061
step: 70, loss: 0.10615191608667374
step: 80, loss: 0.03530573844909668
step: 90, loss: 0.04090283438563347
step: 100, loss: 0.07851233333349228
step: 110, loss: 0.11446290463209152
step: 120, loss: 0.0791066363453865
step: 130, loss: 0.04146241769194603
step: 140, loss: 0.07009267061948776
step: 150, loss: 0.0518488846719265
step: 160, loss: 0.005433742888271809
step: 170, loss: 0.07847031950950623
step: 180, loss: 0.07161565124988556
step: 190, loss: 0.09835385531187057
step: 200, loss: 0.07888451218605042
step: 210, loss: 0.0006022606394253671
step: 220, loss: 0.034755174070596695
step: 230, loss: 0.08371219038963318
step: 240, loss: 0.11794659495353699
step: 250, loss: 0.04131818935275078
step: 260, loss: 0.03309269994497299
step: 270, loss: 0.11861316114664078
step: 280, loss: 0.09649797528982162
step: 290, loss: 0.1574588567018509
step: 300, loss: 0.001602278440259397
step: 310, loss: 0.05474944785237312
step: 320, loss: 0.00405490817502141
step: 330, loss: 0.09325220435857773
step: 340, loss: 0.003932819236069918
step: 350, loss: 0.07232855260372162
step: 360, loss: 0.13077779114246368
epoch 8: dev_f1=0.7146171693735499, f1=0.6885245901639345, best_f1=0.6977886977886977
step: 0, loss: 0.04598989337682724
step: 10, loss: 0.010979541577398777
step: 20, loss: 0.07664759457111359
step: 30, loss: 0.06699328869581223
step: 40, loss: 0.009306992404162884
step: 50, loss: 0.059628963470458984
step: 60, loss: 0.019236065447330475
step: 70, loss: 0.021617956459522247
step: 80, loss: 0.08472680300474167
step: 90, loss: 0.04880470782518387
step: 100, loss: 0.022555191069841385
step: 110, loss: 0.0740462988615036
step: 120, loss: 0.05560336261987686
step: 130, loss: 0.07072895020246506
step: 140, loss: 0.10905702412128448
step: 150, loss: 0.1277669072151184
step: 160, loss: 0.025281637907028198
step: 170, loss: 0.10405357927083969
step: 180, loss: 0.026395827531814575
step: 190, loss: 0.060282450169324875
step: 200, loss: 0.05592232942581177
step: 210, loss: 0.0850927010178566
step: 220, loss: 0.06013171374797821
step: 230, loss: 0.030386190861463547
step: 240, loss: 0.03849317505955696
step: 250, loss: 0.02951493114233017
step: 260, loss: 0.09897711127996445
step: 270, loss: 0.01407187432050705
step: 280, loss: 0.12863248586654663
step: 290, loss: 0.06855641305446625
step: 300, loss: 0.14674831926822662
step: 310, loss: 0.0542374812066555
step: 320, loss: 0.1184762641787529
step: 330, loss: 0.07557443529367447
step: 340, loss: 0.05025448277592659
step: 350, loss: 0.015239259228110313
step: 360, loss: 0.10836221277713776
epoch 9: dev_f1=0.7323232323232323, f1=0.7376623376623376, best_f1=0.7376623376623376
step: 0, loss: 0.11277983337640762
step: 10, loss: 0.06588005274534225
step: 20, loss: 0.08950600028038025
step: 30, loss: 0.07061095535755157
step: 40, loss: 0.06403092294931412
step: 50, loss: 0.019877562299370766
step: 60, loss: 0.06811324506998062
step: 70, loss: 0.030275125056505203
step: 80, loss: 0.05022227019071579
step: 90, loss: 0.058877576142549515
step: 100, loss: 0.01842886209487915
step: 110, loss: 0.02261759340763092
step: 120, loss: 0.025607893243432045
step: 130, loss: 0.07414939999580383
step: 140, loss: 0.05385538190603256
step: 150, loss: 0.06357819586992264
step: 160, loss: 0.058180470019578934
step: 170, loss: 0.1423773169517517
step: 180, loss: 0.0413086861371994
step: 190, loss: 0.08538498729467392
step: 200, loss: 0.0977361723780632
step: 210, loss: 0.07966577261686325
step: 220, loss: 0.07817115634679794
step: 230, loss: 0.04603823274374008
step: 240, loss: 0.17898523807525635
step: 250, loss: 0.0747571811079979
step: 260, loss: 0.00034620059886947274
step: 270, loss: 0.043228745460510254
step: 280, loss: 0.020014794543385506
step: 290, loss: 0.08874820917844772
step: 300, loss: 0.04304998368024826
step: 310, loss: 0.06427821516990662
step: 320, loss: 0.02254764549434185
step: 330, loss: 0.03085234947502613
step: 340, loss: 0.020708169788122177
step: 350, loss: 0.0846266895532608
step: 360, loss: 0.02334129810333252
epoch 10: dev_f1=0.6649484536082474, f1=0.6734177215189875, best_f1=0.7376623376623376
step: 0, loss: 0.06365823745727539
step: 10, loss: 0.05861786752939224
step: 20, loss: 0.020619116723537445
step: 30, loss: 0.05748963728547096
step: 40, loss: 0.05983290076255798
step: 50, loss: 0.08291091024875641
step: 60, loss: 0.0839773416519165
step: 70, loss: 0.08810028433799744
step: 80, loss: 0.0019458073657006025
step: 90, loss: 0.06584027409553528
step: 100, loss: 0.08146887272596359
step: 110, loss: 0.11056497693061829
step: 120, loss: 0.06378612667322159
step: 130, loss: 0.11247066408395767
step: 140, loss: 0.09869884699583054
step: 150, loss: 0.07043218612670898
step: 160, loss: 0.04985025152564049
step: 170, loss: 0.007464567665010691
step: 180, loss: 0.051392074674367905
step: 190, loss: 0.1315980702638626
step: 200, loss: 0.006765277124941349
step: 210, loss: 0.005757682025432587
step: 220, loss: 0.014395982958376408
step: 230, loss: 0.17038530111312866
step: 240, loss: 0.005781281739473343
step: 250, loss: 0.03107975237071514
step: 260, loss: 0.1340775042772293
step: 270, loss: 0.058280088007450104
step: 280, loss: 0.021791502833366394
step: 290, loss: 0.17240490019321442
step: 300, loss: 0.09270858764648438
step: 310, loss: 0.07376652956008911
step: 320, loss: 0.022833935916423798
step: 330, loss: 0.076117143034935
step: 340, loss: 0.13817700743675232
step: 350, loss: 0.08420314639806747
step: 360, loss: 0.08737640082836151
epoch 11: dev_f1=0.7286432160804021, f1=0.7020202020202021, best_f1=0.7376623376623376
step: 0, loss: 0.02226574905216694
step: 10, loss: 0.1239381954073906
step: 20, loss: 0.015117829665541649
step: 30, loss: 0.024843942373991013
step: 40, loss: 0.08238877356052399
step: 50, loss: 0.016045454889535904
step: 60, loss: 0.07488378882408142
step: 70, loss: 0.06222232058644295
step: 80, loss: 0.0645049512386322
step: 90, loss: 0.04757954180240631
step: 100, loss: 0.03479621186852455
step: 110, loss: 0.06306322664022446
step: 120, loss: 0.04095176234841347
step: 130, loss: 0.04159865900874138
step: 140, loss: 0.09252158552408218
step: 150, loss: 0.0488227903842926
step: 160, loss: 0.0003171231073793024
step: 170, loss: 0.06012211740016937
step: 180, loss: 0.03635537624359131
step: 190, loss: 0.060607101768255234
step: 200, loss: 0.09333424270153046
step: 210, loss: 0.05237027257680893
step: 220, loss: 0.09902188926935196
step: 230, loss: 0.024937838315963745
step: 240, loss: 0.00991529319435358
step: 250, loss: 0.09157377481460571
step: 260, loss: 0.011877849698066711
step: 270, loss: 0.07287201285362244
step: 280, loss: 0.02407604455947876
step: 290, loss: 0.2808164358139038
step: 300, loss: 0.035974934697151184
step: 310, loss: 0.09016042947769165
step: 320, loss: 0.044337064027786255
step: 330, loss: 0.08013080805540085
step: 340, loss: 0.061855800449848175
step: 350, loss: 0.10328403860330582
step: 360, loss: 0.018802374601364136
epoch 12: dev_f1=0.7036144578313254, f1=0.6896551724137931, best_f1=0.7376623376623376
step: 0, loss: 0.03614386171102524
step: 10, loss: 0.0057692457921803
step: 20, loss: 0.02445613592863083
step: 30, loss: 0.06114182621240616
step: 40, loss: 0.06099807471036911
step: 50, loss: 0.032973211258649826
step: 60, loss: 0.03930606693029404
step: 70, loss: 0.06775142252445221
step: 80, loss: 0.05828288942575455
step: 90, loss: 0.03718193992972374
step: 100, loss: 0.07902006059885025
step: 110, loss: 0.026392944157123566
step: 120, loss: 0.06825646013021469
step: 130, loss: 0.037109918892383575
step: 140, loss: 0.0038598673418164253
step: 150, loss: 0.060156166553497314
step: 160, loss: 0.058393534272909164
step: 170, loss: 0.07214264571666718
step: 180, loss: 0.09400924295186996
step: 190, loss: 0.09292641282081604
step: 200, loss: 0.01913781836628914
step: 210, loss: 0.023824620991945267
step: 220, loss: 0.04370763152837753
step: 230, loss: 0.06205973029136658
step: 240, loss: 0.08352115750312805
step: 250, loss: 0.051372501999139786
step: 260, loss: 0.046762917190790176
step: 270, loss: 0.010490711778402328
step: 280, loss: 0.07389239966869354
step: 290, loss: 0.1645517200231552
step: 300, loss: 0.056225650012493134
step: 310, loss: 0.045230984687805176
step: 320, loss: 0.10578905045986176
step: 330, loss: 0.03125878423452377
step: 340, loss: 0.011271697469055653
step: 350, loss: 0.05595959350466728
step: 360, loss: 0.0424388088285923
epoch 13: dev_f1=0.7049608355091384, f1=0.6937669376693768, best_f1=0.7376623376623376
step: 0, loss: 0.09996691346168518
step: 10, loss: 0.07846395671367645
step: 20, loss: 0.05257704108953476
step: 30, loss: 0.04464157670736313
step: 40, loss: 0.053909678012132645
step: 50, loss: 0.029505446553230286
step: 60, loss: 0.06241350248456001
step: 70, loss: 0.11496584117412567
step: 80, loss: 0.03010861948132515
step: 90, loss: 0.05055489018559456
step: 100, loss: 0.16034173965454102
step: 110, loss: 0.0926596075296402
step: 120, loss: 0.16032983362674713
step: 130, loss: 0.08189031481742859
step: 140, loss: 0.05039946362376213
step: 150, loss: 0.07032949477434158
step: 160, loss: 0.11852040886878967
step: 170, loss: 0.00045304634841158986
step: 180, loss: 0.09345109760761261
step: 190, loss: 0.09830635040998459
step: 200, loss: 0.1238703727722168
step: 210, loss: 0.04848650470376015
step: 220, loss: 0.07757881283760071
step: 230, loss: 0.02882002666592598
step: 240, loss: 0.022956974804401398
step: 250, loss: 0.08274088054895401
step: 260, loss: 0.012611716985702515
step: 270, loss: 0.05268644168972969
step: 280, loss: 0.07381400465965271
step: 290, loss: 0.0311653483659029
step: 300, loss: 0.035696662962436676
step: 310, loss: 0.0009106498910114169
step: 320, loss: 0.09932807832956314
step: 330, loss: 0.08680621534585953
step: 340, loss: 0.02201443910598755
step: 350, loss: 0.06604243069887161
step: 360, loss: 0.03509267792105675
epoch 14: dev_f1=0.6997518610421836, f1=0.7043701799485862, best_f1=0.7376623376623376
step: 0, loss: 0.04212023317813873
step: 10, loss: 0.018133943900465965
step: 20, loss: 0.04741102457046509
step: 30, loss: 0.03378688171505928
step: 40, loss: 0.05259602516889572
step: 50, loss: 0.10933371633291245
step: 60, loss: 0.01671469956636429
step: 70, loss: 0.03440855070948601
step: 80, loss: 0.08534558117389679
step: 90, loss: 0.03478791192173958
step: 100, loss: 0.0003828752087429166
step: 110, loss: 0.0022987420670688152
step: 120, loss: 0.02926626242697239
step: 130, loss: 0.03982683643698692
step: 140, loss: 0.05005570128560066
step: 150, loss: 0.03417854756116867
step: 160, loss: 2.9272403480717912e-05
step: 170, loss: 0.07292468845844269
step: 180, loss: 0.03522790968418121
step: 190, loss: 0.02822115644812584
step: 200, loss: 0.008709087036550045
step: 210, loss: 0.10012076050043106
step: 220, loss: 0.05165568366646767
step: 230, loss: 0.022635869681835175
step: 240, loss: 0.010858191177248955
step: 250, loss: 0.02587968111038208
step: 260, loss: 0.022470567375421524
step: 270, loss: 0.08642037212848663
step: 280, loss: 0.046425435692071915
step: 290, loss: 0.02504326030611992
step: 300, loss: 0.0777282789349556
step: 310, loss: 0.11851238459348679
step: 320, loss: 0.06212873011827469
step: 330, loss: 0.020735209807753563
step: 340, loss: 0.08273899555206299
step: 350, loss: 0.022441186010837555
step: 360, loss: 0.11290603131055832
epoch 15: dev_f1=0.6779661016949152, f1=0.6715328467153285, best_f1=0.7376623376623376
step: 0, loss: 0.06628759950399399
step: 10, loss: 0.02148924581706524
step: 20, loss: 0.03586973994970322
step: 30, loss: 0.05692672356963158
step: 40, loss: 0.0013504312373697758
step: 50, loss: 0.03665614128112793
step: 60, loss: 0.048012640327215195
step: 70, loss: 0.06627801805734634
step: 80, loss: 0.09239417314529419
step: 90, loss: 0.07172850519418716
step: 100, loss: 0.046432312577962875
step: 110, loss: 0.07788820564746857
step: 120, loss: 0.1650630682706833
step: 130, loss: 0.07574383169412613
step: 140, loss: 0.00886572990566492
step: 150, loss: 0.04413359984755516
step: 160, loss: 0.05595926195383072
step: 170, loss: 0.04212550073862076
step: 180, loss: 0.005035827402025461
step: 190, loss: 0.019666563719511032
step: 200, loss: 0.03776349499821663
step: 210, loss: 0.10499638319015503
step: 220, loss: 0.0025934551376849413
step: 230, loss: 0.05762550234794617
step: 240, loss: 0.013795629143714905
step: 250, loss: 0.02547958865761757
step: 260, loss: 0.05845625698566437
step: 270, loss: 0.03372453525662422
step: 280, loss: 0.030812816694378853
step: 290, loss: 0.028496496379375458
step: 300, loss: 0.07612945139408112
step: 310, loss: 0.13065265119075775
step: 320, loss: 0.012254010885953903
step: 330, loss: 0.08549027144908905
step: 340, loss: 0.07584897428750992
step: 350, loss: 0.017156396061182022
step: 360, loss: 0.05782024934887886
epoch 16: dev_f1=0.7080103359173127, f1=0.6935483870967742, best_f1=0.7376623376623376
step: 0, loss: 0.009288142435252666
step: 10, loss: 0.006904080044478178
step: 20, loss: 0.0021895957179367542
step: 30, loss: 0.06661873310804367
step: 40, loss: 0.08826937526464462
step: 50, loss: 0.07429451495409012
step: 60, loss: 0.14291362464427948
step: 70, loss: 0.1849067509174347
step: 80, loss: 0.0008087468449957669
step: 90, loss: 0.08619042485952377
step: 100, loss: 0.017157550901174545
step: 110, loss: 0.016323402523994446
step: 120, loss: 0.004873923026025295
step: 130, loss: 0.045585308223962784
step: 140, loss: 0.1522667557001114
step: 150, loss: 0.040533389896154404
step: 160, loss: 0.1293487250804901
step: 170, loss: 0.03976093605160713
step: 180, loss: 0.09440801292657852
step: 190, loss: 0.07565014064311981
step: 200, loss: 0.01866350695490837
step: 210, loss: 0.006158523261547089
step: 220, loss: 0.03817334398627281
step: 230, loss: 0.051042765378952026
step: 240, loss: 0.00737660750746727
step: 250, loss: 0.000991427805274725
step: 260, loss: 0.008695111609995365
step: 270, loss: 0.00957274530082941
step: 280, loss: 0.03922261297702789
step: 290, loss: 0.07993633300065994
step: 300, loss: 0.04198088496923447
step: 310, loss: 2.6883923055720516e-05
step: 320, loss: 0.11856886744499207
step: 330, loss: 0.04096914827823639
step: 340, loss: 0.03794153407216072
step: 350, loss: 0.06248397380113602
step: 360, loss: 0.0060244291089475155
epoch 17: dev_f1=0.691292875989446, f1=0.6826666666666666, best_f1=0.7376623376623376
step: 0, loss: 0.006082167848944664
step: 10, loss: 0.06801706552505493
step: 20, loss: 0.066532202064991
step: 30, loss: 0.0009312125039286911
step: 40, loss: 0.005311619956046343
step: 50, loss: 0.02079702913761139
step: 60, loss: 0.01154877245426178
step: 70, loss: 0.0824345052242279
step: 80, loss: 0.027105556800961494
step: 90, loss: 0.022204212844371796
step: 100, loss: 0.025403205305337906
step: 110, loss: 0.06055266410112381
step: 120, loss: 0.07359080016613007
step: 130, loss: 0.004636756610125303
step: 140, loss: 0.0775868147611618
step: 150, loss: 0.00785383302718401
step: 160, loss: 0.04971444234251976
step: 170, loss: 0.005234849639236927
step: 180, loss: 0.04245911166071892
step: 190, loss: 0.05279744789004326
step: 200, loss: 0.04392927139997482
step: 210, loss: 0.048953671008348465
step: 220, loss: 0.06531792134046555
step: 230, loss: 0.022723626345396042
step: 240, loss: 0.04467695951461792
step: 250, loss: 0.06018752232193947
step: 260, loss: 0.05582857131958008
step: 270, loss: 0.0046528703533113
step: 280, loss: 0.02175995148718357
step: 290, loss: 0.02397514507174492
step: 300, loss: 0.02763001248240471
step: 310, loss: 0.006447992287576199
step: 320, loss: 2.648598274390679e-05
step: 330, loss: 0.10708288848400116
step: 340, loss: 0.03198015317320824
step: 350, loss: 0.024885062128305435
step: 360, loss: 0.013367202132940292
epoch 18: dev_f1=0.7005076142131978, f1=0.6947368421052632, best_f1=0.7376623376623376
step: 0, loss: 0.039178479462862015
step: 10, loss: 0.021039795130491257
step: 20, loss: 0.01743903197348118
step: 30, loss: 0.0826333612203598
step: 40, loss: 0.03055104799568653
step: 50, loss: 0.15537746250629425
step: 60, loss: 0.033258259296417236
step: 70, loss: 0.06856365501880646
step: 80, loss: 0.05297466740012169
step: 90, loss: 0.06568647176027298
step: 100, loss: 0.0462229959666729
step: 110, loss: 0.027352603152394295
step: 120, loss: 0.03778717666864395
step: 130, loss: 0.0612257719039917
step: 140, loss: 0.03163531795144081
step: 150, loss: 0.0042768619023263454
step: 160, loss: 0.018609970808029175
step: 170, loss: 0.037684131413698196
step: 180, loss: 0.08333444595336914
step: 190, loss: 0.011536363512277603
step: 200, loss: 0.07148372381925583
step: 210, loss: 0.024778753519058228
step: 220, loss: 0.025457432493567467
step: 230, loss: 0.020278608426451683
step: 240, loss: 0.04866145923733711
step: 250, loss: 0.10499358177185059
step: 260, loss: 0.0551467128098011
step: 270, loss: 0.06624368578195572
step: 280, loss: 0.04746531695127487
step: 290, loss: 0.00725488131865859
step: 300, loss: 0.056716904044151306
step: 310, loss: 0.031639788299798965
step: 320, loss: 0.019000042229890823
step: 330, loss: 1.756456731527578e-05
step: 340, loss: 0.009382132440805435
step: 350, loss: 0.037302758544683456
step: 360, loss: 0.024501238018274307
epoch 19: dev_f1=0.6997389033942559, f1=0.6863270777479893, best_f1=0.7376623376623376
step: 0, loss: 0.07861310243606567
step: 10, loss: 0.09327611327171326
step: 20, loss: 0.1172187328338623
step: 30, loss: 7.440868648700416e-05
step: 40, loss: 0.044792305678129196
step: 50, loss: 2.1971278329147026e-05
step: 60, loss: 0.00539080984890461
step: 70, loss: 0.023886801674962044
step: 80, loss: 0.017590785399079323
step: 90, loss: 0.029399210587143898
step: 100, loss: 0.024738460779190063
step: 110, loss: 0.025470418855547905
step: 120, loss: 0.12563563883304596
step: 130, loss: 0.057738546282052994
step: 140, loss: 0.00019363718456588686
step: 150, loss: 0.009635622613132
step: 160, loss: 0.06747681647539139
step: 170, loss: 0.10321691632270813
step: 180, loss: 0.014889425598084927
step: 190, loss: 0.05391194298863411
step: 200, loss: 0.009877845644950867
step: 210, loss: 0.05166000872850418
step: 220, loss: 0.0657937303185463
step: 230, loss: 0.08884666115045547
step: 240, loss: 0.032056376338005066
step: 250, loss: 0.008115797303617
step: 260, loss: 0.011270470917224884
step: 270, loss: 0.019444867968559265
step: 280, loss: 0.024849386885762215
step: 290, loss: 0.010452905669808388
step: 300, loss: 0.007580000441521406
step: 310, loss: 0.07025168091058731
step: 320, loss: 0.02431783266365528
step: 330, loss: 0.09356924146413803
step: 340, loss: 0.007007834501564503
step: 350, loss: 0.04107418283820152
step: 360, loss: 0.029482420533895493
epoch 20: dev_f1=0.7080103359173127, f1=0.6935483870967742, best_f1=0.7376623376623376
