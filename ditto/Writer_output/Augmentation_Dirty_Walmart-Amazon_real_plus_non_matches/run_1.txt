cuda
Device: cuda
step: 0, loss: 0.5731908679008484
step: 10, loss: 0.2752557396888733
step: 20, loss: 0.24072778224945068
step: 30, loss: 0.14286965131759644
step: 40, loss: 0.25005972385406494
step: 50, loss: 0.15226449072360992
step: 60, loss: 0.3695729970932007
step: 70, loss: 0.14146438241004944
step: 80, loss: 0.14657267928123474
step: 90, loss: 0.514743447303772
step: 100, loss: 0.2359054535627365
step: 110, loss: 0.31646591424942017
step: 120, loss: 0.22471804916858673
step: 130, loss: 0.2415638417005539
step: 140, loss: 0.12676061689853668
step: 150, loss: 0.23599272966384888
step: 160, loss: 0.6137271523475647
step: 170, loss: 0.13469547033309937
step: 180, loss: 0.16227999329566956
step: 190, loss: 0.24048353731632233
step: 200, loss: 0.03104577399790287
step: 210, loss: 0.22130997478961945
step: 220, loss: 0.07496386766433716
step: 230, loss: 0.21385744214057922
step: 240, loss: 0.12810158729553223
step: 250, loss: 0.33796629309654236
step: 260, loss: 0.2988983690738678
step: 270, loss: 0.060270290821790695
step: 280, loss: 0.12650325894355774
step: 290, loss: 0.15417025983333588
step: 300, loss: 0.324863463640213
step: 310, loss: 0.09766406565904617
step: 320, loss: 0.1734260767698288
step: 330, loss: 0.05073365196585655
step: 340, loss: 0.3700500428676605
step: 350, loss: 0.3977605998516083
step: 360, loss: 0.1268097311258316
epoch 1: dev_f1=0.6050420168067228, f1=0.6301369863013698, best_f1=0.6301369863013698
step: 0, loss: 0.07924939692020416
step: 10, loss: 0.16737817227840424
step: 20, loss: 0.362346887588501
step: 30, loss: 0.09738383442163467
step: 40, loss: 0.07405421882867813
step: 50, loss: 0.07657253742218018
step: 60, loss: 0.14637398719787598
step: 70, loss: 0.09625791013240814
step: 80, loss: 0.09211055189371109
step: 90, loss: 0.08028601109981537
step: 100, loss: 0.12101653963327408
step: 110, loss: 0.08679414540529251
step: 120, loss: 0.11606190353631973
step: 130, loss: 0.10616103559732437
step: 140, loss: 0.1311967670917511
step: 150, loss: 0.09109976142644882
step: 160, loss: 0.0662158727645874
step: 170, loss: 0.1275680959224701
step: 180, loss: 0.09877849370241165
step: 190, loss: 0.15054534375667572
step: 200, loss: 0.05234918370842934
step: 210, loss: 0.2606726288795471
step: 220, loss: 0.08464251458644867
step: 230, loss: 0.06974145770072937
step: 240, loss: 0.10045615583658218
step: 250, loss: 0.04916730523109436
step: 260, loss: 0.2059333473443985
step: 270, loss: 0.2184441089630127
step: 280, loss: 0.0724964439868927
step: 290, loss: 0.04913598299026489
step: 300, loss: 0.13496769964694977
step: 310, loss: 0.011831586249172688
step: 320, loss: 0.15778928995132446
step: 330, loss: 0.0847877785563469
step: 340, loss: 0.31343862414360046
step: 350, loss: 0.1997188925743103
step: 360, loss: 0.15313312411308289
epoch 2: dev_f1=0.676056338028169, f1=0.7029972752043598, best_f1=0.7029972752043598
step: 0, loss: 0.18944388628005981
step: 10, loss: 0.1447068303823471
step: 20, loss: 0.07429257780313492
step: 30, loss: 0.07122275978326797
step: 40, loss: 0.08855126798152924
step: 50, loss: 0.11389663815498352
step: 60, loss: 0.11622916907072067
step: 70, loss: 0.058503035455942154
step: 80, loss: 0.02230777218937874
step: 90, loss: 0.2669757008552551
step: 100, loss: 0.12431959062814713
step: 110, loss: 0.10547704994678497
step: 120, loss: 0.036947865039110184
step: 130, loss: 0.11749043315649033
step: 140, loss: 0.06410302966833115
step: 150, loss: 0.219801664352417
step: 160, loss: 0.07451809197664261
step: 170, loss: 0.11241049319505692
step: 180, loss: 0.01898290403187275
step: 190, loss: 0.03939255326986313
step: 200, loss: 0.10198910534381866
step: 210, loss: 0.08616127818822861
step: 220, loss: 0.09252133220434189
step: 230, loss: 0.10693151503801346
step: 240, loss: 0.03900869935750961
step: 250, loss: 0.03203614056110382
step: 260, loss: 0.06417835503816605
step: 270, loss: 0.11216588318347931
step: 280, loss: 0.17301198840141296
step: 290, loss: 0.07014995813369751
step: 300, loss: 0.0515608973801136
step: 310, loss: 0.1515020877122879
step: 320, loss: 0.04918312281370163
step: 330, loss: 0.1846410632133484
step: 340, loss: 0.10872041434049606
step: 350, loss: 0.05780882388353348
step: 360, loss: 0.14088694751262665
epoch 3: dev_f1=0.7579462102689486, f1=0.7542579075425789, best_f1=0.7542579075425789
step: 0, loss: 0.0562874972820282
step: 10, loss: 0.19662536680698395
step: 20, loss: 0.10082630068063736
step: 30, loss: 0.025589223951101303
step: 40, loss: 0.10779222100973129
step: 50, loss: 0.10340918600559235
step: 60, loss: 0.1479359269142151
step: 70, loss: 0.11754751205444336
step: 80, loss: 0.0948643684387207
step: 90, loss: 0.074122354388237
step: 100, loss: 0.06429976224899292
step: 110, loss: 0.14201891422271729
step: 120, loss: 0.04850063472986221
step: 130, loss: 0.04945635795593262
step: 140, loss: 0.07710375636816025
step: 150, loss: 0.1771264225244522
step: 160, loss: 0.07216130197048187
step: 170, loss: 0.14159005880355835
step: 180, loss: 0.1601734161376953
step: 190, loss: 0.08387000113725662
step: 200, loss: 0.14197134971618652
step: 210, loss: 0.05181979387998581
step: 220, loss: 0.05966288968920708
step: 230, loss: 0.13629814982414246
step: 240, loss: 0.08522749692201614
step: 250, loss: 0.05214444175362587
step: 260, loss: 0.10705024003982544
step: 270, loss: 0.2038198858499527
step: 280, loss: 0.08013799041509628
step: 290, loss: 0.07914378494024277
step: 300, loss: 0.11249731481075287
step: 310, loss: 0.16071707010269165
step: 320, loss: 0.052763719111680984
step: 330, loss: 0.10960597544908524
step: 340, loss: 0.0747951939702034
step: 350, loss: 0.03202106058597565
step: 360, loss: 0.0873044952750206
epoch 4: dev_f1=0.7241379310344828, f1=0.726775956284153, best_f1=0.7542579075425789
step: 0, loss: 0.13509535789489746
step: 10, loss: 0.050357695668935776
step: 20, loss: 0.037109024822711945
step: 30, loss: 0.08603651076555252
step: 40, loss: 0.06335509568452835
step: 50, loss: 0.039980996400117874
step: 60, loss: 0.06646209955215454
step: 70, loss: 0.07829789817333221
step: 80, loss: 0.09972237795591354
step: 90, loss: 0.0446317195892334
step: 100, loss: 0.054140958935022354
step: 110, loss: 0.04778309911489487
step: 120, loss: 0.04348726198077202
step: 130, loss: 0.11880417168140411
step: 140, loss: 0.058212313801050186
step: 150, loss: 0.1560768485069275
step: 160, loss: 0.03816568851470947
step: 170, loss: 0.14789032936096191
step: 180, loss: 0.12916746735572815
step: 190, loss: 0.13561174273490906
step: 200, loss: 0.22640255093574524
step: 210, loss: 0.008650506846606731
step: 220, loss: 0.08051005005836487
step: 230, loss: 0.05902943015098572
step: 240, loss: 0.17798469960689545
step: 250, loss: 0.07125304639339447
step: 260, loss: 0.019806984812021255
step: 270, loss: 0.0801861509680748
step: 280, loss: 0.05703383684158325
step: 290, loss: 0.005979760084301233
step: 300, loss: 0.18348844349384308
step: 310, loss: 0.10896972566843033
step: 320, loss: 0.0144380833953619
step: 330, loss: 0.15577936172485352
step: 340, loss: 0.06066560745239258
step: 350, loss: 0.027439594268798828
step: 360, loss: 0.07143132388591766
epoch 5: dev_f1=0.7545219638242895, f1=0.7525773195876289, best_f1=0.7542579075425789
step: 0, loss: 0.07821788638830185
step: 10, loss: 0.1064724251627922
step: 20, loss: 0.038436874747276306
step: 30, loss: 0.05718328431248665
step: 40, loss: 0.10109637677669525
step: 50, loss: 0.23548978567123413
step: 60, loss: 0.1006779819726944
step: 70, loss: 0.057720381766557693
step: 80, loss: 0.056045010685920715
step: 90, loss: 0.1346396654844284
step: 100, loss: 0.1224014163017273
step: 110, loss: 0.0781092718243599
step: 120, loss: 0.04776215925812721
step: 130, loss: 0.05753718689084053
step: 140, loss: 0.03845090791583061
step: 150, loss: 0.1619444489479065
step: 160, loss: 0.04040823131799698
step: 170, loss: 0.03493887558579445
step: 180, loss: 0.1300903707742691
step: 190, loss: 0.05577722191810608
step: 200, loss: 0.04999491199851036
step: 210, loss: 0.05943143367767334
step: 220, loss: 0.07325497269630432
step: 230, loss: 0.03704077750444412
step: 240, loss: 0.1408505141735077
step: 250, loss: 0.03845284879207611
step: 260, loss: 0.021996205672621727
step: 270, loss: 0.12799017131328583
step: 280, loss: 0.047637637704610825
step: 290, loss: 0.16530071198940277
step: 300, loss: 0.2433084100484848
step: 310, loss: 0.040351517498493195
step: 320, loss: 0.10025124996900558
step: 330, loss: 0.07609966397285461
step: 340, loss: 0.08242334425449371
step: 350, loss: 0.08300456404685974
step: 360, loss: 0.16561269760131836
epoch 6: dev_f1=0.7239583333333334, f1=0.746031746031746, best_f1=0.7542579075425789
step: 0, loss: 0.08301328867673874
step: 10, loss: 0.04261903464794159
step: 20, loss: 0.14060857892036438
step: 30, loss: 0.07480349391698837
step: 40, loss: 0.01818673312664032
step: 50, loss: 0.057617515325546265
step: 60, loss: 0.05484182760119438
step: 70, loss: 0.10112524032592773
step: 80, loss: 0.07728881388902664
step: 90, loss: 0.023250354453921318
step: 100, loss: 0.030234115198254585
step: 110, loss: 0.125330850481987
step: 120, loss: 0.08823004364967346
step: 130, loss: 0.09047220647335052
step: 140, loss: 0.06133231520652771
step: 150, loss: 0.045564357191324234
step: 160, loss: 0.09456265717744827
step: 170, loss: 0.2710469663143158
step: 180, loss: 0.2590804100036621
step: 190, loss: 0.044816754758358
step: 200, loss: 0.2878824770450592
step: 210, loss: 0.1667843908071518
step: 220, loss: 0.11306435614824295
step: 230, loss: 0.06476239860057831
step: 240, loss: 0.0525682158768177
step: 250, loss: 0.06331555545330048
step: 260, loss: 0.08462181687355042
step: 270, loss: 0.1845928132534027
step: 280, loss: 0.054631464183330536
step: 290, loss: 0.05396055430173874
step: 300, loss: 0.06157850846648216
step: 310, loss: 0.009763131849467754
step: 320, loss: 0.046136386692523956
step: 330, loss: 0.05418838933110237
step: 340, loss: 0.03132643923163414
step: 350, loss: 0.02065855823457241
step: 360, loss: 0.022779174149036407
epoch 7: dev_f1=0.7267904509283819, f1=0.7427055702917772, best_f1=0.7542579075425789
step: 0, loss: 0.1489676982164383
step: 10, loss: 0.056695397943258286
step: 20, loss: 0.08951578289270401
step: 30, loss: 0.036166880279779434
step: 40, loss: 0.03226893022656441
step: 50, loss: 0.02739657461643219
step: 60, loss: 0.05974329635500908
step: 70, loss: 0.12055395543575287
step: 80, loss: 0.08546047657728195
step: 90, loss: 0.07713832706212997
step: 100, loss: 0.07642504572868347
step: 110, loss: 0.08546046167612076
step: 120, loss: 0.044540129601955414
step: 130, loss: 0.06913713365793228
step: 140, loss: 0.03317088633775711
step: 150, loss: 0.07707204669713974
step: 160, loss: 0.029575403779745102
step: 170, loss: 0.07060670107603073
step: 180, loss: 0.07781277596950531
step: 190, loss: 0.15121199190616608
step: 200, loss: 0.0488310307264328
step: 210, loss: 0.045718610286712646
step: 220, loss: 0.14683519303798676
step: 230, loss: 0.1859947293996811
step: 240, loss: 0.0978383794426918
step: 250, loss: 0.060613907873630524
step: 260, loss: 0.018001066520810127
step: 270, loss: 0.07619360089302063
step: 280, loss: 0.1502344310283661
step: 290, loss: 0.04032932221889496
step: 300, loss: 0.13797827064990997
step: 310, loss: 0.16064275801181793
step: 320, loss: 0.03674173355102539
step: 330, loss: 0.032086778432130814
step: 340, loss: 0.11525849997997284
step: 350, loss: 0.0004700675781350583
step: 360, loss: 0.11891942471265793
epoch 8: dev_f1=0.7357512953367874, f1=0.743455497382199, best_f1=0.7542579075425789
step: 0, loss: 0.07631504535675049
step: 10, loss: 0.1278681755065918
step: 20, loss: 0.05664418265223503
step: 30, loss: 0.07364757359027863
step: 40, loss: 0.10214734077453613
step: 50, loss: 0.03318098559975624
step: 60, loss: 0.11691684275865555
step: 70, loss: 0.062076136469841
step: 80, loss: 0.08114206045866013
step: 90, loss: 0.0498729944229126
step: 100, loss: 0.037985481321811676
step: 110, loss: 0.04167355224490166
step: 120, loss: 0.06706660240888596
step: 130, loss: 0.06576091051101685
step: 140, loss: 0.11850237101316452
step: 150, loss: 0.061852674931287766
step: 160, loss: 0.06590306013822556
step: 170, loss: 0.06265000253915787
step: 180, loss: 0.03601326793432236
step: 190, loss: 0.14472311735153198
step: 200, loss: 0.07369541376829147
step: 210, loss: 0.00993154477328062
step: 220, loss: 0.019156992435455322
step: 230, loss: 0.07584507018327713
step: 240, loss: 0.02139810100197792
step: 250, loss: 0.07835077494382858
step: 260, loss: 0.11059869080781937
step: 270, loss: 0.06287235021591187
step: 280, loss: 0.1324365884065628
step: 290, loss: 0.07147461920976639
step: 300, loss: 0.19516369700431824
step: 310, loss: 0.11710342764854431
step: 320, loss: 0.03408446162939072
step: 330, loss: 0.0544595904648304
step: 340, loss: 0.030214326456189156
step: 350, loss: 0.030460067093372345
step: 360, loss: 0.08892420679330826
epoch 9: dev_f1=0.7309644670050761, f1=0.7183462532299743, best_f1=0.7542579075425789
step: 0, loss: 0.05995549261569977
step: 10, loss: 0.06201482564210892
step: 20, loss: 0.001808297005482018
step: 30, loss: 0.08283731341362
step: 40, loss: 0.1058976948261261
step: 50, loss: 0.04953331872820854
step: 60, loss: 0.04960282891988754
step: 70, loss: 0.09612556546926498
step: 80, loss: 0.02748931758105755
step: 90, loss: 0.042527079582214355
step: 100, loss: 0.03577425703406334
step: 110, loss: 0.0470244474709034
step: 120, loss: 0.01243487000465393
step: 130, loss: 0.06446222960948944
step: 140, loss: 0.11047646403312683
step: 150, loss: 0.0019724515732377768
step: 160, loss: 0.00228930008597672
step: 170, loss: 0.0009742503752931952
step: 180, loss: 0.10499539226293564
step: 190, loss: 0.09222669154405594
step: 200, loss: 0.08315326273441315
step: 210, loss: 0.045850709080696106
step: 220, loss: 0.07189075648784637
step: 230, loss: 0.03454162925481796
step: 240, loss: 0.0305310171097517
step: 250, loss: 0.06458723545074463
step: 260, loss: 0.05149030312895775
step: 270, loss: 0.10917583853006363
step: 280, loss: 0.016531018540263176
step: 290, loss: 0.04727967455983162
step: 300, loss: 0.06664104014635086
step: 310, loss: 0.11509818583726883
step: 320, loss: 0.160239577293396
step: 330, loss: 0.08842168748378754
step: 340, loss: 0.02754758670926094
step: 350, loss: 0.05796924978494644
step: 360, loss: 0.09387664496898651
epoch 10: dev_f1=0.7268041237113403, f1=0.7306666666666668, best_f1=0.7542579075425789
step: 0, loss: 0.032817523926496506
step: 10, loss: 0.045633893460035324
step: 20, loss: 0.033484023064374924
step: 30, loss: 0.006961379200220108
step: 40, loss: 0.038098979741334915
step: 50, loss: 0.14867855608463287
step: 60, loss: 0.035237111151218414
step: 70, loss: 0.055648963898420334
step: 80, loss: 0.052958689630031586
step: 90, loss: 0.1150403544306755
step: 100, loss: 0.10875573754310608
step: 110, loss: 0.11342859268188477
step: 120, loss: 0.030166959390044212
step: 130, loss: 0.009972428902983665
step: 140, loss: 0.0609949566423893
step: 150, loss: 0.022098388522863388
step: 160, loss: 0.08044367283582687
step: 170, loss: 0.07106561213731766
step: 180, loss: 0.011943289078772068
step: 190, loss: 0.08403915911912918
step: 200, loss: 0.05773317068815231
step: 210, loss: 0.0624687522649765
step: 220, loss: 0.07945920526981354
step: 230, loss: 0.03029853291809559
step: 240, loss: 0.02884647808969021
step: 250, loss: 0.10071650892496109
step: 260, loss: 0.14519289135932922
step: 270, loss: 0.06368568539619446
step: 280, loss: 0.020039519295096397
step: 290, loss: 0.016673456877470016
step: 300, loss: 0.04576784372329712
step: 310, loss: 0.1106487512588501
step: 320, loss: 0.18788278102874756
step: 330, loss: 0.11243579536676407
step: 340, loss: 0.11121692508459091
step: 350, loss: 0.09229626506567001
step: 360, loss: 0.11453723907470703
epoch 11: dev_f1=0.7538461538461538, f1=0.7506426735218509, best_f1=0.7542579075425789
step: 0, loss: 0.08848018944263458
step: 10, loss: 0.09197862446308136
step: 20, loss: 0.03731410205364227
step: 30, loss: 0.0317973718047142
step: 40, loss: 0.04682198166847229
step: 50, loss: 0.06872571259737015
step: 60, loss: 0.0714622288942337
step: 70, loss: 0.08568032085895538
step: 80, loss: 0.07846885174512863
step: 90, loss: 0.09440216422080994
step: 100, loss: 0.02699623629450798
step: 110, loss: 0.10132603347301483
step: 120, loss: 0.0884510800242424
step: 130, loss: 0.049985259771347046
step: 140, loss: 0.04112475737929344
step: 150, loss: 0.15319836139678955
step: 160, loss: 0.05152275040745735
step: 170, loss: 0.06569515913724899
step: 180, loss: 0.0246898140758276
step: 190, loss: 0.039276134222745895
step: 200, loss: 0.07238800823688507
step: 210, loss: 0.02525857463479042
step: 220, loss: 6.185667007230222e-05
step: 230, loss: 0.041438695043325424
step: 240, loss: 0.044196661561727524
step: 250, loss: 0.07629023492336273
step: 260, loss: 0.05434748902916908
step: 270, loss: 0.1872544139623642
step: 280, loss: 0.12955133616924286
step: 290, loss: 0.05824047699570656
step: 300, loss: 0.046278372406959534
step: 310, loss: 0.055069223046302795
step: 320, loss: 0.042097058147192
step: 330, loss: 0.08354290574789047
step: 340, loss: 0.0007041459903120995
step: 350, loss: 0.09504744410514832
step: 360, loss: 0.07464855909347534
epoch 12: dev_f1=0.7658402203856748, f1=0.7458563535911602, best_f1=0.7458563535911602
step: 0, loss: 0.08678038418292999
step: 10, loss: 0.11234081536531448
step: 20, loss: 0.04251553490757942
step: 30, loss: 0.049804262816905975
step: 40, loss: 0.08143263310194016
step: 50, loss: 0.016970999538898468
step: 60, loss: 0.10136684775352478
step: 70, loss: 0.09570235013961792
step: 80, loss: 0.04380204156041145
step: 90, loss: 0.08809442073106766
step: 100, loss: 0.022478802129626274
step: 110, loss: 0.022776052355766296
step: 120, loss: 0.019953150302171707
step: 130, loss: 0.05704056844115257
step: 140, loss: 0.023522935807704926
step: 150, loss: 0.09863604605197906
step: 160, loss: 0.013961298391222954
step: 170, loss: 0.13592369854450226
step: 180, loss: 0.06172269955277443
step: 190, loss: 0.06274542212486267
step: 200, loss: 0.09573595970869064
step: 210, loss: 0.14620117843151093
step: 220, loss: 0.04468775540590286
step: 230, loss: 0.0937327891588211
step: 240, loss: 0.01849321275949478
step: 250, loss: 0.168644517660141
step: 260, loss: 0.05765059217810631
step: 270, loss: 0.10159293562173843
step: 280, loss: 0.06881124526262283
step: 290, loss: 0.05547093600034714
step: 300, loss: 0.08397381007671356
step: 310, loss: 0.028238588944077492
step: 320, loss: 0.036848798394203186
step: 330, loss: 0.050914645195007324
step: 340, loss: 0.07220958173274994
step: 350, loss: 0.10171360522508621
step: 360, loss: 0.04409993812441826
epoch 13: dev_f1=0.7277777777777779, f1=0.707774798927614, best_f1=0.7458563535911602
step: 0, loss: 0.006156728137284517
step: 10, loss: 0.022009452804923058
step: 20, loss: 0.02919899858534336
step: 30, loss: 0.052225470542907715
step: 40, loss: 0.029715092852711678
step: 50, loss: 0.03304038196802139
step: 60, loss: 0.07139091193675995
step: 70, loss: 0.030542530119419098
step: 80, loss: 0.03607194125652313
step: 90, loss: 0.14401088654994965
step: 100, loss: 0.028704378753900528
step: 110, loss: 0.17048679292201996
step: 120, loss: 0.025845829397439957
step: 130, loss: 0.07463991641998291
step: 140, loss: 0.023528551682829857
step: 150, loss: 0.09577406197786331
step: 160, loss: 0.061107270419597626
step: 170, loss: 0.04924210160970688
step: 180, loss: 0.01740257255733013
step: 190, loss: 0.10707931220531464
step: 200, loss: 0.04272669553756714
step: 210, loss: 0.0058393459767103195
step: 220, loss: 0.038787029683589935
step: 230, loss: 0.025033794343471527
step: 240, loss: 0.05821940675377846
step: 250, loss: 0.06272845715284348
step: 260, loss: 0.047541458159685135
step: 270, loss: 0.09070604294538498
step: 280, loss: 0.09281159937381744
step: 290, loss: 0.008644704706966877
step: 300, loss: 0.040789034217596054
step: 310, loss: 0.06050366163253784
step: 320, loss: 0.06590169668197632
step: 330, loss: 0.04166858643293381
step: 340, loss: 0.09552861750125885
step: 350, loss: 0.0826859176158905
step: 360, loss: 0.0066397287882864475
epoch 14: dev_f1=0.7403598971722366, f1=0.7308641975308642, best_f1=0.7458563535911602
step: 0, loss: 0.03981509432196617
step: 10, loss: 0.017191672697663307
step: 20, loss: 0.015288209542632103
step: 30, loss: 0.06992709636688232
step: 40, loss: 0.08014576882123947
step: 50, loss: 0.05408073961734772
step: 60, loss: 0.07172286510467529
step: 70, loss: 0.1471927911043167
step: 80, loss: 0.043790414929389954
step: 90, loss: 0.04389442875981331
step: 100, loss: 0.01399994920939207
step: 110, loss: 0.10310856997966766
step: 120, loss: 0.02217361517250538
step: 130, loss: 0.12022065371274948
step: 140, loss: 0.018473194912075996
step: 150, loss: 0.03878007456660271
step: 160, loss: 0.09705697000026703
step: 170, loss: 0.015519813634455204
step: 180, loss: 0.046678781509399414
step: 190, loss: 0.019681748002767563
step: 200, loss: 0.0002074082294711843
step: 210, loss: 0.011962030082941055
step: 220, loss: 0.013412194326519966
step: 230, loss: 0.04285038262605667
step: 240, loss: 0.06529109179973602
step: 250, loss: 0.010668117552995682
step: 260, loss: 0.050747666507959366
step: 270, loss: 0.01763993501663208
step: 280, loss: 0.039499279111623764
step: 290, loss: 0.04467865824699402
step: 300, loss: 0.0042192572727799416
step: 310, loss: 0.0035662814043462276
step: 320, loss: 0.02964610792696476
step: 330, loss: 0.05766013264656067
step: 340, loss: 0.01900864951312542
step: 350, loss: 0.09912661463022232
step: 360, loss: 0.05524742975831032
epoch 15: dev_f1=0.7254408060453401, f1=0.7342995169082126, best_f1=0.7458563535911602
step: 0, loss: 0.009130304679274559
step: 10, loss: 0.07364333420991898
step: 20, loss: 0.017760513350367546
step: 30, loss: 0.00010612523328745738
step: 40, loss: 0.06724777817726135
step: 50, loss: 0.1301639825105667
step: 60, loss: 0.02615886554121971
step: 70, loss: 0.021162914112210274
step: 80, loss: 0.029300883412361145
step: 90, loss: 0.007928725332021713
step: 100, loss: 0.021989434957504272
step: 110, loss: 0.06340526789426804
step: 120, loss: 0.0690745860338211
step: 130, loss: 0.006305449642241001
step: 140, loss: 0.021542077884078026
step: 150, loss: 0.007363073527812958
step: 160, loss: 0.029816491529345512
step: 170, loss: 0.012608661316335201
step: 180, loss: 0.09088053554296494
step: 190, loss: 0.007948288694024086
step: 200, loss: 0.03424838185310364
step: 210, loss: 0.04452946037054062
step: 220, loss: 0.028282111510634422
step: 230, loss: 0.08246634155511856
step: 240, loss: 0.010912342928349972
step: 250, loss: 0.012032950296998024
step: 260, loss: 0.02375488542020321
step: 270, loss: 0.004566379822790623
step: 280, loss: 0.0046920934692025185
step: 290, loss: 0.05233168974518776
step: 300, loss: 0.08604390919208527
step: 310, loss: 0.10204117745161057
step: 320, loss: 0.03800724446773529
step: 330, loss: 0.08780871331691742
step: 340, loss: 0.026148885488510132
step: 350, loss: 0.18591824173927307
step: 360, loss: 0.06253567337989807
epoch 16: dev_f1=0.7233009708737864, f1=0.7277108433734939, best_f1=0.7458563535911602
step: 0, loss: 0.05419522151350975
step: 10, loss: 0.07832514494657516
step: 20, loss: 0.00981801189482212
step: 30, loss: 0.057657934725284576
step: 40, loss: 0.018711064010858536
step: 50, loss: 0.03195720165967941
step: 60, loss: 0.08891654014587402
step: 70, loss: 0.009713437408208847
step: 80, loss: 0.05235786736011505
step: 90, loss: 0.024621659889817238
step: 100, loss: 0.11871010810136795
step: 110, loss: 0.020962346345186234
step: 120, loss: 0.0693325325846672
step: 130, loss: 0.04308111593127251
step: 140, loss: 0.017861900851130486
step: 150, loss: 0.20359422266483307
step: 160, loss: 0.06576480716466904
step: 170, loss: 0.00416959822177887
step: 180, loss: 0.013127257116138935
step: 190, loss: 0.10368963330984116
step: 200, loss: 0.08486814796924591
step: 210, loss: 0.05814960226416588
step: 220, loss: 0.016422979533672333
step: 230, loss: 0.033074550330638885
step: 240, loss: 0.020187603309750557
step: 250, loss: 0.04510940983891487
step: 260, loss: 0.06588409841060638
step: 270, loss: 0.11626218259334564
step: 280, loss: 0.05312419682741165
step: 290, loss: 0.06010238453745842
step: 300, loss: 0.05423615872859955
step: 310, loss: 5.624781260848977e-05
step: 320, loss: 0.0322013683617115
step: 330, loss: 0.007031374145299196
step: 340, loss: 0.005401983857154846
step: 350, loss: 0.04746260121464729
step: 360, loss: 0.026773149147629738
epoch 17: dev_f1=0.7131782945736433, f1=0.7411167512690356, best_f1=0.7458563535911602
step: 0, loss: 0.005290485918521881
step: 10, loss: 0.0461667962372303
step: 20, loss: 0.012691019102931023
step: 30, loss: 0.05242006853222847
step: 40, loss: 0.08033938705921173
step: 50, loss: 0.02857738919556141
step: 60, loss: 0.03552887961268425
step: 70, loss: 0.021909715607762337
step: 80, loss: 0.003602665150538087
step: 90, loss: 0.09739461541175842
step: 100, loss: 0.036812372505664825
step: 110, loss: 0.050434935837984085
step: 120, loss: 0.022109422832727432
step: 130, loss: 0.028689272701740265
step: 140, loss: 0.03346102684736252
step: 150, loss: 0.023871159180998802
step: 160, loss: 0.04415065795183182
step: 170, loss: 0.055379725992679596
step: 180, loss: 0.02513110637664795
step: 190, loss: 0.001840845332480967
step: 200, loss: 0.05633416771888733
step: 210, loss: 0.0376620888710022
step: 220, loss: 0.0600070022046566
step: 230, loss: 0.09449723362922668
step: 240, loss: 0.0075658331625163555
step: 250, loss: 0.04738222807645798
step: 260, loss: 0.021704694256186485
step: 270, loss: 0.08012332767248154
step: 280, loss: 0.05711151286959648
step: 290, loss: 0.07196994870901108
step: 300, loss: 0.005181963089853525
step: 310, loss: 0.009245553985238075
step: 320, loss: 0.03721874579787254
step: 330, loss: 0.035791508853435516
step: 340, loss: 0.0491463728249073
step: 350, loss: 0.029362566769123077
step: 360, loss: 0.02313416637480259
epoch 18: dev_f1=0.720626631853786, f1=0.7323232323232323, best_f1=0.7458563535911602
step: 0, loss: 0.060113877058029175
step: 10, loss: 0.05097708851099014
step: 20, loss: 0.10425888001918793
step: 30, loss: 0.021279586479067802
step: 40, loss: 0.017943834885954857
step: 50, loss: 0.0627550333738327
step: 60, loss: 0.04525075852870941
step: 70, loss: 0.06056186184287071
step: 80, loss: 0.024338629096746445
step: 90, loss: 0.011543331667780876
step: 100, loss: 0.08183906227350235
step: 110, loss: 1.8760159946396016e-05
step: 120, loss: 0.05680537596344948
step: 130, loss: 0.0454469658434391
step: 140, loss: 0.01195450872182846
step: 150, loss: 0.08950498700141907
step: 160, loss: 0.01525301393121481
step: 170, loss: 0.05935494229197502
step: 180, loss: 0.049291759729385376
step: 190, loss: 0.02955520525574684
step: 200, loss: 0.02213173918426037
step: 210, loss: 0.07392166554927826
step: 220, loss: 8.548158803023398e-05
step: 230, loss: 0.04987140744924545
step: 240, loss: 0.10635476559400558
step: 250, loss: 0.01719222404062748
step: 260, loss: 0.02886378951370716
step: 270, loss: 0.08434752374887466
step: 280, loss: 0.008360384032130241
step: 290, loss: 0.06940300762653351
step: 300, loss: 0.033777203410863876
step: 310, loss: 2.4057409973465838e-05
step: 320, loss: 0.000959648285061121
step: 330, loss: 0.021284734830260277
step: 340, loss: 0.0027758742216974497
step: 350, loss: 0.04202156513929367
step: 360, loss: 0.07301059365272522
epoch 19: dev_f1=0.7119565217391304, f1=0.7169811320754718, best_f1=0.7458563535911602
step: 0, loss: 0.05200860649347305
step: 10, loss: 0.0041121067479252815
step: 20, loss: 0.02164830081164837
step: 30, loss: 0.0391029454767704
step: 40, loss: 0.03002537041902542
step: 50, loss: 0.030700746923685074
step: 60, loss: 0.04896673187613487
step: 70, loss: 0.028389601036906242
step: 80, loss: 0.026208654046058655
step: 90, loss: 0.0420067124068737
step: 100, loss: 0.014575286768376827
step: 110, loss: 0.016602113842964172
step: 120, loss: 0.09335433691740036
step: 130, loss: 0.03750484436750412
step: 140, loss: 0.012103206478059292
step: 150, loss: 1.762391002557706e-05
step: 160, loss: 0.04799086973071098
step: 170, loss: 0.007957314141094685
step: 180, loss: 0.017561789602041245
step: 190, loss: 0.023166289553046227
step: 200, loss: 0.06377991288900375
step: 210, loss: 0.004563434515148401
step: 220, loss: 0.036144983023405075
step: 230, loss: 0.114812470972538
step: 240, loss: 0.0487525537610054
step: 250, loss: 0.1529017835855484
step: 260, loss: 0.19176527857780457
step: 270, loss: 0.030103499069809914
step: 280, loss: 0.011940909549593925
step: 290, loss: 0.05438566207885742
step: 300, loss: 0.0027117093559354544
step: 310, loss: 0.053289156407117844
step: 320, loss: 0.03617481142282486
step: 330, loss: 0.016518456861376762
step: 340, loss: 0.03550667688250542
step: 350, loss: 0.14880771934986115
step: 360, loss: 0.05134781822562218
epoch 20: dev_f1=0.7093333333333335, f1=0.7098445595854923, best_f1=0.7458563535911602
