cuda
Device: cuda
step: 0, loss: 0.6380385160446167
step: 10, loss: 0.4506688416004181
step: 20, loss: 0.09739472717046738
step: 30, loss: 0.026599684730172157
step: 40, loss: 0.2312171310186386
step: 50, loss: 0.040601979941129684
step: 60, loss: 0.1356508880853653
step: 70, loss: 0.09078016132116318
step: 80, loss: 0.08902537077665329
step: 90, loss: 0.029512451961636543
step: 100, loss: 0.3538847267627716
step: 110, loss: 0.39183109998703003
step: 120, loss: 0.23127715289592743
step: 130, loss: 0.23028959333896637
step: 140, loss: 0.028733961284160614
step: 150, loss: 0.028528735041618347
step: 160, loss: 0.4250279366970062
step: 170, loss: 0.16572722792625427
step: 180, loss: 0.28880226612091064
step: 190, loss: 0.3486418128013611
step: 200, loss: 0.1377301961183548
step: 210, loss: 0.08708595484495163
step: 220, loss: 0.1304037719964981
step: 230, loss: 0.12185277789831161
step: 240, loss: 0.03497370332479477
step: 250, loss: 0.03071979433298111
step: 260, loss: 0.1403789520263672
step: 270, loss: 0.31188884377479553
step: 280, loss: 0.08242064714431763
step: 290, loss: 0.07889223098754883
step: 300, loss: 0.09179837256669998
step: 310, loss: 0.2008512169122696
step: 320, loss: 0.14275604486465454
step: 330, loss: 0.0611080601811409
step: 340, loss: 0.01314490009099245
step: 350, loss: 0.09042646735906601
step: 360, loss: 0.09099426865577698
epoch 1: dev_f1=0.45312500000000006, f1=0.4699248120300752, best_f1=0.4699248120300752
step: 0, loss: 0.11863585561513901
step: 10, loss: 0.17029984295368195
step: 20, loss: 0.07870016247034073
step: 30, loss: 0.1105974093079567
step: 40, loss: 0.0668250322341919
step: 50, loss: 0.1466996818780899
step: 60, loss: 0.35959509015083313
step: 70, loss: 0.3268536329269409
step: 80, loss: 0.09507502615451813
step: 90, loss: 0.1910327970981598
step: 100, loss: 0.05914882570505142
step: 110, loss: 0.20813603699207306
step: 120, loss: 0.15885043144226074
step: 130, loss: 0.15128757059574127
step: 140, loss: 0.032893866300582886
step: 150, loss: 0.08867717534303665
step: 160, loss: 0.20994696021080017
step: 170, loss: 0.25400251150131226
step: 180, loss: 0.11785893887281418
step: 190, loss: 0.09436935931444168
step: 200, loss: 0.14038661122322083
step: 210, loss: 0.049673814326524734
step: 220, loss: 0.032349154353141785
step: 230, loss: 0.13324469327926636
step: 240, loss: 0.2824166417121887
step: 250, loss: 0.10876757651567459
step: 260, loss: 0.07477669417858124
step: 270, loss: 0.17421190440654755
step: 280, loss: 0.16601142287254333
step: 290, loss: 0.19775930047035217
step: 300, loss: 0.04147728160023689
step: 310, loss: 0.12576863169670105
step: 320, loss: 0.12949958443641663
step: 330, loss: 0.08998461812734604
step: 340, loss: 0.037344880402088165
step: 350, loss: 0.17571011185646057
step: 360, loss: 0.04019758105278015
epoch 2: dev_f1=0.7210526315789473, f1=0.7290640394088671, best_f1=0.7290640394088671
step: 0, loss: 0.01103891246020794
step: 10, loss: 0.0501302145421505
step: 20, loss: 0.14367897808551788
step: 30, loss: 0.0435497984290123
step: 40, loss: 0.0628695860505104
step: 50, loss: 0.13655629754066467
step: 60, loss: 0.05774072930216789
step: 70, loss: 0.2454107403755188
step: 80, loss: 0.06641049683094025
step: 90, loss: 0.19665667414665222
step: 100, loss: 0.15444931387901306
step: 110, loss: 0.09703123569488525
step: 120, loss: 0.08640206605195999
step: 130, loss: 0.10418099910020828
step: 140, loss: 0.10442101210355759
step: 150, loss: 0.10099118202924728
step: 160, loss: 0.18760095536708832
step: 170, loss: 0.06174498051404953
step: 180, loss: 0.10848929733037949
step: 190, loss: 0.09044632315635681
step: 200, loss: 0.07248037308454514
step: 210, loss: 0.13256551325321198
step: 220, loss: 0.20690572261810303
step: 230, loss: 0.10780921578407288
step: 240, loss: 0.025658469647169113
step: 250, loss: 0.06353982537984848
step: 260, loss: 0.13049311935901642
step: 270, loss: 0.12111736834049225
step: 280, loss: 0.24278701841831207
step: 290, loss: 0.20157770812511444
step: 300, loss: 0.1328553855419159
step: 310, loss: 0.08577856421470642
step: 320, loss: 0.023688064888119698
step: 330, loss: 0.0668443888425827
step: 340, loss: 0.13798518478870392
step: 350, loss: 0.3472162187099457
step: 360, loss: 0.05532529950141907
epoch 3: dev_f1=0.7286063569682152, f1=0.7030878859857482, best_f1=0.7030878859857482
step: 0, loss: 0.03590729832649231
step: 10, loss: 0.0858694314956665
step: 20, loss: 0.11586557328701019
step: 30, loss: 0.27266407012939453
step: 40, loss: 0.07065825164318085
step: 50, loss: 0.022925158962607384
step: 60, loss: 0.1418585181236267
step: 70, loss: 0.04558972641825676
step: 80, loss: 0.13336624205112457
step: 90, loss: 0.12962926924228668
step: 100, loss: 0.07255059480667114
step: 110, loss: 0.12383056432008743
step: 120, loss: 0.08849213272333145
step: 130, loss: 0.1315135657787323
step: 140, loss: 0.1171429455280304
step: 150, loss: 0.042334750294685364
step: 160, loss: 0.2023325264453888
step: 170, loss: 0.1374005824327469
step: 180, loss: 0.18593856692314148
step: 190, loss: 0.09732896834611893
step: 200, loss: 0.1625649333000183
step: 210, loss: 0.0740090012550354
step: 220, loss: 0.07826364785432816
step: 230, loss: 0.2027888000011444
step: 240, loss: 0.014703750610351562
step: 250, loss: 0.11686621606349945
step: 260, loss: 0.047363873571157455
step: 270, loss: 0.08171147108078003
step: 280, loss: 0.10272296518087387
step: 290, loss: 0.07408750057220459
step: 300, loss: 0.03462423011660576
step: 310, loss: 0.13145726919174194
step: 320, loss: 0.04163481667637825
step: 330, loss: 0.29278674721717834
step: 340, loss: 0.16820979118347168
step: 350, loss: 0.07452615350484848
step: 360, loss: 0.09891489893198013
epoch 4: dev_f1=0.7650273224043715, f1=0.7098591549295775, best_f1=0.7098591549295775
step: 0, loss: 0.07080778479576111
step: 10, loss: 0.08005686849355698
step: 20, loss: 0.04238612949848175
step: 30, loss: 0.04167519137263298
step: 40, loss: 0.09091318398714066
step: 50, loss: 0.09754637628793716
step: 60, loss: 0.16753938794136047
step: 70, loss: 0.07715798169374466
step: 80, loss: 0.19333043694496155
step: 90, loss: 0.07962043583393097
step: 100, loss: 0.08520278334617615
step: 110, loss: 0.13894881308078766
step: 120, loss: 0.1695629060268402
step: 130, loss: 0.08627624064683914
step: 140, loss: 0.08550846576690674
step: 150, loss: 0.0790889635682106
step: 160, loss: 0.02101270854473114
step: 170, loss: 0.022725868970155716
step: 180, loss: 0.025311661884188652
step: 190, loss: 0.0841384306550026
step: 200, loss: 0.040436021983623505
step: 210, loss: 0.0443190298974514
step: 220, loss: 0.06301198154687881
step: 230, loss: 0.124068483710289
step: 240, loss: 0.059476904571056366
step: 250, loss: 0.05789484083652496
step: 260, loss: 0.05460139364004135
step: 270, loss: 0.047001246362924576
step: 280, loss: 0.18577750027179718
step: 290, loss: 0.18027491867542267
step: 300, loss: 0.1045231744647026
step: 310, loss: 0.1357055902481079
step: 320, loss: 0.06905337423086166
step: 330, loss: 0.0475388765335083
step: 340, loss: 0.12864521145820618
step: 350, loss: 0.13832944631576538
step: 360, loss: 0.32927772402763367
epoch 5: dev_f1=0.7630331753554501, f1=0.7226107226107227, best_f1=0.7098591549295775
step: 0, loss: 0.03595694527029991
step: 10, loss: 0.0631694570183754
step: 20, loss: 0.08972612023353577
step: 30, loss: 0.05792533978819847
step: 40, loss: 0.04657835140824318
step: 50, loss: 0.039690036326646805
step: 60, loss: 0.0014250660315155983
step: 70, loss: 0.13185492157936096
step: 80, loss: 0.08993200957775116
step: 90, loss: 0.08955401927232742
step: 100, loss: 0.043402742594480515
step: 110, loss: 0.09609837830066681
step: 120, loss: 0.059545695781707764
step: 130, loss: 0.08462419360876083
step: 140, loss: 0.05596311390399933
step: 150, loss: 0.042474426329135895
step: 160, loss: 0.03418060019612312
step: 170, loss: 0.0759250819683075
step: 180, loss: 0.14874035120010376
step: 190, loss: 0.08508370816707611
step: 200, loss: 0.14366143941879272
step: 210, loss: 0.07884831726551056
step: 220, loss: 0.050592828541994095
step: 230, loss: 0.04909689351916313
step: 240, loss: 0.13514557480812073
step: 250, loss: 0.05130092054605484
step: 260, loss: 0.08016417920589447
step: 270, loss: 0.04475816339254379
step: 280, loss: 0.053920529782772064
step: 290, loss: 0.08141389489173889
step: 300, loss: 0.1302107274532318
step: 310, loss: 0.34424737095832825
step: 320, loss: 0.11987487226724625
step: 330, loss: 0.11876550316810608
step: 340, loss: 0.16364625096321106
step: 350, loss: 0.022506922483444214
step: 360, loss: 0.0415252186357975
epoch 6: dev_f1=0.7086247086247086, f1=0.6775700934579438, best_f1=0.7098591549295775
step: 0, loss: 0.0294534582644701
step: 10, loss: 0.05106784403324127
step: 20, loss: 0.0832282155752182
step: 30, loss: 0.06263509392738342
step: 40, loss: 0.04362679645419121
step: 50, loss: 0.05357187241315842
step: 60, loss: 0.07111482322216034
step: 70, loss: 0.11636076867580414
step: 80, loss: 0.09812730550765991
step: 90, loss: 0.11125961691141129
step: 100, loss: 0.021861853078007698
step: 110, loss: 0.06309764832258224
step: 120, loss: 0.06479289382696152
step: 130, loss: 0.14644159376621246
step: 140, loss: 0.026475749909877777
step: 150, loss: 0.0021790575701743364
step: 160, loss: 0.05586829409003258
step: 170, loss: 0.13403692841529846
step: 180, loss: 0.12400413304567337
step: 190, loss: 0.12345877289772034
step: 200, loss: 0.009916791692376137
step: 210, loss: 0.07495461404323578
step: 220, loss: 0.2288692146539688
step: 230, loss: 0.12028279155492783
step: 240, loss: 0.04484490305185318
step: 250, loss: 0.0434674397110939
step: 260, loss: 0.06435476243495941
step: 270, loss: 0.17074927687644958
step: 280, loss: 0.039982639253139496
step: 290, loss: 0.10736974328756332
step: 300, loss: 0.04386644810438156
step: 310, loss: 0.13618093729019165
step: 320, loss: 0.05659061297774315
step: 330, loss: 0.16376937925815582
step: 340, loss: 0.05099603906273842
step: 350, loss: 0.056798066943883896
step: 360, loss: 0.09216799587011337
epoch 7: dev_f1=0.7475247524752476, f1=0.739454094292804, best_f1=0.7098591549295775
step: 0, loss: 0.01143584679812193
step: 10, loss: 0.0762188658118248
step: 20, loss: 0.08982108533382416
step: 30, loss: 0.0564565509557724
step: 40, loss: 0.09509394317865372
step: 50, loss: 0.07239743322134018
step: 60, loss: 0.09833374619483948
step: 70, loss: 0.01491090003401041
step: 80, loss: 0.03877873346209526
step: 90, loss: 0.03213776275515556
step: 100, loss: 0.06540083140134811
step: 110, loss: 0.07720944285392761
step: 120, loss: 0.030723007395863533
step: 130, loss: 0.09065302461385727
step: 140, loss: 0.1830359548330307
step: 150, loss: 0.05066569522023201
step: 160, loss: 0.009826240129768848
step: 170, loss: 0.04186159372329712
step: 180, loss: 0.016359155997633934
step: 190, loss: 0.02767898514866829
step: 200, loss: 0.01086985319852829
step: 210, loss: 0.05065232142806053
step: 220, loss: 0.047865841537714005
step: 230, loss: 0.13509343564510345
step: 240, loss: 0.04850465804338455
step: 250, loss: 0.0918244794011116
step: 260, loss: 0.13861587643623352
step: 270, loss: 0.009395800530910492
step: 280, loss: 0.04716339707374573
step: 290, loss: 0.18470896780490875
step: 300, loss: 0.02957778051495552
step: 310, loss: 0.03664787486195564
step: 320, loss: 0.01903100684285164
step: 330, loss: 0.03588263317942619
step: 340, loss: 0.13497135043144226
step: 350, loss: 0.0015193542931228876
step: 360, loss: 0.054315898567438126
epoch 8: dev_f1=0.7817745803357313, f1=0.7341176470588235, best_f1=0.7341176470588235
step: 0, loss: 0.11231281608343124
step: 10, loss: 0.05509541928768158
step: 20, loss: 0.11895139515399933
step: 30, loss: 0.060957182198762894
step: 40, loss: 0.20523224771022797
step: 50, loss: 0.022901661694049835
step: 60, loss: 0.19409112632274628
step: 70, loss: 0.051937926560640335
step: 80, loss: 0.08884557336568832
step: 90, loss: 9.166378004010767e-05
step: 100, loss: 0.12438776344060898
step: 110, loss: 0.04486166313290596
step: 120, loss: 0.05386216938495636
step: 130, loss: 0.1669498085975647
step: 140, loss: 0.1690487265586853
step: 150, loss: 0.024614179506897926
step: 160, loss: 0.049458932131528854
step: 170, loss: 0.02493179403245449
step: 180, loss: 0.11953725665807724
step: 190, loss: 0.04352300614118576
step: 200, loss: 0.01871756836771965
step: 210, loss: 0.042965445667505264
step: 220, loss: 0.05823807045817375
step: 230, loss: 0.016563013195991516
step: 240, loss: 0.012692894786596298
step: 250, loss: 0.06904970854520798
step: 260, loss: 0.0882844403386116
step: 270, loss: 0.10290764272212982
step: 280, loss: 0.03408944606781006
step: 290, loss: 0.06047675013542175
step: 300, loss: 0.027503684163093567
step: 310, loss: 0.12504218518733978
step: 320, loss: 0.1025298684835434
step: 330, loss: 0.048793449997901917
step: 340, loss: 0.01351605448871851
step: 350, loss: 0.06064449995756149
step: 360, loss: 0.09439818561077118
epoch 9: dev_f1=0.779746835443038, f1=0.7628865979381442, best_f1=0.7341176470588235
step: 0, loss: 0.061910904943943024
step: 10, loss: 0.0763634666800499
step: 20, loss: 0.05119365081191063
step: 30, loss: 0.02643679268658161
step: 40, loss: 0.15128934383392334
step: 50, loss: 0.16126352548599243
step: 60, loss: 0.03939087316393852
step: 70, loss: 0.10764104872941971
step: 80, loss: 0.03802883252501488
step: 90, loss: 0.13890765607357025
step: 100, loss: 0.02524665556848049
step: 110, loss: 0.07051075994968414
step: 120, loss: 0.07559189945459366
step: 130, loss: 0.10093174129724503
step: 140, loss: 0.029389595612883568
step: 150, loss: 0.1356089860200882
step: 160, loss: 0.008701247163116932
step: 170, loss: 0.14979690313339233
step: 180, loss: 0.05491605028510094
step: 190, loss: 0.025325721129775047
step: 200, loss: 0.10080758482217789
step: 210, loss: 0.02454507350921631
step: 220, loss: 0.06966971606016159
step: 230, loss: 0.13170532882213593
step: 240, loss: 0.14836184680461884
step: 250, loss: 0.04548996314406395
step: 260, loss: 0.02100548706948757
step: 270, loss: 0.06686682999134064
step: 280, loss: 0.1837325096130371
step: 290, loss: 0.02406345307826996
step: 300, loss: 0.04524749517440796
step: 310, loss: 0.11201068013906479
step: 320, loss: 0.09774745255708694
step: 330, loss: 0.13213734328746796
step: 340, loss: 0.08263456076383591
step: 350, loss: 0.05396847799420357
step: 360, loss: 0.04070151969790459
epoch 10: dev_f1=0.6870588235294117, f1=0.6990740740740741, best_f1=0.7341176470588235
step: 0, loss: 0.05607512593269348
step: 10, loss: 0.023274533450603485
step: 20, loss: 0.00014135573292151093
step: 30, loss: 0.012379228137433529
step: 40, loss: 0.051284946501255035
step: 50, loss: 0.09584572166204453
step: 60, loss: 0.06090301647782326
step: 70, loss: 0.009465619921684265
step: 80, loss: 0.044088322669267654
step: 90, loss: 0.045570291578769684
step: 100, loss: 0.021770240738987923
step: 110, loss: 0.1352425068616867
step: 120, loss: 0.009823002852499485
step: 130, loss: 0.06406742334365845
step: 140, loss: 0.03431195020675659
step: 150, loss: 0.027772199362516403
step: 160, loss: 0.013867427594959736
step: 170, loss: 0.028216473758220673
step: 180, loss: 0.013998536393046379
step: 190, loss: 0.0362553596496582
step: 200, loss: 0.05128796026110649
step: 210, loss: 0.08652056753635406
step: 220, loss: 0.053289994597435
step: 230, loss: 0.042577363550662994
step: 240, loss: 0.04202059656381607
step: 250, loss: 0.14208130538463593
step: 260, loss: 0.11428499221801758
step: 270, loss: 0.0002055284276138991
step: 280, loss: 0.037068452686071396
step: 290, loss: 0.03044503927230835
step: 300, loss: 0.025281498208642006
step: 310, loss: 0.045299068093299866
step: 320, loss: 0.025513283908367157
step: 330, loss: 0.060242872685194016
step: 340, loss: 0.1780635416507721
step: 350, loss: 0.013667920604348183
step: 360, loss: 0.06977830082178116
epoch 11: dev_f1=0.7500000000000001, f1=0.7312348668280872, best_f1=0.7341176470588235
step: 0, loss: 0.11054939031600952
step: 10, loss: 0.06206385791301727
step: 20, loss: 0.07233325392007828
step: 30, loss: 0.007146480493247509
step: 40, loss: 0.018392637372016907
step: 50, loss: 0.1873699575662613
step: 60, loss: 0.02902001142501831
step: 70, loss: 0.07446848601102829
step: 80, loss: 0.08229626715183258
step: 90, loss: 0.07961474359035492
step: 100, loss: 0.021756060421466827
step: 110, loss: 0.00010371984535595402
step: 120, loss: 0.035903871059417725
step: 130, loss: 0.04349194094538689
step: 140, loss: 0.031389907002449036
step: 150, loss: 0.12498138099908829
step: 160, loss: 0.0012328589800745249
step: 170, loss: 0.09603489190340042
step: 180, loss: 0.07265398651361465
step: 190, loss: 0.072300024330616
step: 200, loss: 0.030472531914711
step: 210, loss: 0.06095793470740318
step: 220, loss: 0.02986426278948784
step: 230, loss: 0.06603541970252991
step: 240, loss: 0.15633243322372437
step: 250, loss: 0.1616627424955368
step: 260, loss: 0.045113660395145416
step: 270, loss: 0.04924250766634941
step: 280, loss: 0.15783913433551788
step: 290, loss: 0.07804819941520691
step: 300, loss: 0.048081040382385254
step: 310, loss: 0.045974086970090866
step: 320, loss: 0.10639195889234543
step: 330, loss: 0.07883965969085693
step: 340, loss: 0.08388608694076538
step: 350, loss: 0.03186415135860443
step: 360, loss: 0.12304040789604187
epoch 12: dev_f1=0.752, f1=0.7545219638242895, best_f1=0.7341176470588235
step: 0, loss: 0.05078059434890747
step: 10, loss: 0.08031487464904785
step: 20, loss: 0.005881554447114468
step: 30, loss: 0.004385540261864662
step: 40, loss: 0.036498431116342545
step: 50, loss: 0.041703276336193085
step: 60, loss: 0.11242729425430298
step: 70, loss: 0.07059420645236969
step: 80, loss: 0.04188992455601692
step: 90, loss: 0.10806084424257278
step: 100, loss: 0.005833747331053019
step: 110, loss: 0.0021360961254686117
step: 120, loss: 0.013683846220374107
step: 130, loss: 0.004244654905050993
step: 140, loss: 0.0893963873386383
step: 150, loss: 0.11215014010667801
step: 160, loss: 0.12748654186725616
step: 170, loss: 0.06953217834234238
step: 180, loss: 0.06777900457382202
step: 190, loss: 0.02695533260703087
step: 200, loss: 0.09492713958024979
step: 210, loss: 0.11012795567512512
step: 220, loss: 0.09582055360078812
step: 230, loss: 0.03860580548644066
step: 240, loss: 0.05364356189966202
step: 250, loss: 0.018614454194903374
step: 260, loss: 0.011298345401883125
step: 270, loss: 0.06287600845098495
step: 280, loss: 0.059519559144973755
step: 290, loss: 0.076688751578331
step: 300, loss: 0.039883796125650406
step: 310, loss: 0.051823828369379044
step: 320, loss: 0.08250696212053299
step: 330, loss: 0.09488856792449951
step: 340, loss: 0.035228755325078964
step: 350, loss: 0.016966460272669792
step: 360, loss: 0.07217945158481598
epoch 13: dev_f1=0.734375, f1=0.7430025445292621, best_f1=0.7341176470588235
step: 0, loss: 0.01676592044532299
step: 10, loss: 0.062125105410814285
step: 20, loss: 0.0467839241027832
step: 30, loss: 0.0516541413962841
step: 40, loss: 0.026075351983308792
step: 50, loss: 0.024871084839105606
step: 60, loss: 0.008313622325658798
step: 70, loss: 0.015392111614346504
step: 80, loss: 0.06575314700603485
step: 90, loss: 0.03801402449607849
step: 100, loss: 0.05521285533905029
step: 110, loss: 0.029880380257964134
step: 120, loss: 0.027810707688331604
step: 130, loss: 0.06409902125597
step: 140, loss: 0.0697527602314949
step: 150, loss: 0.003494373755529523
step: 160, loss: 0.061399899423122406
step: 170, loss: 0.005309396889060736
step: 180, loss: 0.06302119046449661
step: 190, loss: 0.0008009671582840383
step: 200, loss: 0.11380843073129654
step: 210, loss: 0.021146854385733604
step: 220, loss: 0.00815847422927618
step: 230, loss: 0.06604035943746567
step: 240, loss: 0.006468466483056545
step: 250, loss: 0.036496639251708984
step: 260, loss: 0.017263272777199745
step: 270, loss: 0.0070503950119018555
step: 280, loss: 0.018190493807196617
step: 290, loss: 0.001466070651076734
step: 300, loss: 0.06560797244310379
step: 310, loss: 0.056776199489831924
step: 320, loss: 0.06443209201097488
step: 330, loss: 0.037848345935344696
step: 340, loss: 0.0018747770227491856
step: 350, loss: 2.9082873879815452e-05
step: 360, loss: 0.03174251317977905
epoch 14: dev_f1=0.714975845410628, f1=0.6939759036144578, best_f1=0.7341176470588235
step: 0, loss: 0.007892648689448833
step: 10, loss: 0.03306903690099716
step: 20, loss: 0.062063299119472504
step: 30, loss: 0.08035905659198761
step: 40, loss: 0.022374233230948448
step: 50, loss: 0.020205548033118248
step: 60, loss: 0.02914302982389927
step: 70, loss: 0.010698826052248478
step: 80, loss: 0.009359950199723244
step: 90, loss: 0.00013126636622473598
step: 100, loss: 0.08419987559318542
step: 110, loss: 0.04463287815451622
step: 120, loss: 0.09250567853450775
step: 130, loss: 0.057365819811820984
step: 140, loss: 0.012954939156770706
step: 150, loss: 0.11200365424156189
step: 160, loss: 0.2909620404243469
step: 170, loss: 0.04624345898628235
step: 180, loss: 0.05054626613855362
step: 190, loss: 0.010899108834564686
step: 200, loss: 0.10154956579208374
step: 210, loss: 0.03789543733000755
step: 220, loss: 0.060591135174036026
step: 230, loss: 0.03953089565038681
step: 240, loss: 0.07762189954519272
step: 250, loss: 0.06054013967514038
step: 260, loss: 0.06003473699092865
step: 270, loss: 0.053739987313747406
step: 280, loss: 0.029562339186668396
step: 290, loss: 0.00584216695278883
step: 300, loss: 0.0883844792842865
step: 310, loss: 0.057093147188425064
step: 320, loss: 0.003599483985453844
step: 330, loss: 0.13291317224502563
step: 340, loss: 0.03502799570560455
step: 350, loss: 4.4659456762019545e-05
step: 360, loss: 0.0327342189848423
epoch 15: dev_f1=0.7268041237113403, f1=0.732824427480916, best_f1=0.7341176470588235
step: 0, loss: 0.07720419764518738
step: 10, loss: 0.00041705486364662647
step: 20, loss: 0.001901431824080646
step: 30, loss: 0.03633835166692734
step: 40, loss: 0.06573381274938583
step: 50, loss: 0.014236853457987309
step: 60, loss: 0.06090370565652847
step: 70, loss: 0.0014839655486866832
step: 80, loss: 0.00017463834956288338
step: 90, loss: 0.035705842077732086
step: 100, loss: 0.020459910854697227
step: 110, loss: 0.003698532935231924
step: 120, loss: 0.05412593483924866
step: 130, loss: 0.029940977692604065
step: 140, loss: 0.027003653347492218
step: 150, loss: 0.014821033924818039
step: 160, loss: 0.07318875193595886
step: 170, loss: 0.010161911137402058
step: 180, loss: 0.029703006148338318
step: 190, loss: 0.055639468133449554
step: 200, loss: 0.07551318407058716
step: 210, loss: 0.0023992774076759815
step: 220, loss: 0.03131687641143799
step: 230, loss: 0.03600776940584183
step: 240, loss: 0.005820777732878923
step: 250, loss: 0.06748652458190918
step: 260, loss: 0.04117606207728386
step: 270, loss: 0.09186168015003204
step: 280, loss: 0.01014274638146162
step: 290, loss: 0.04442422091960907
step: 300, loss: 0.11503876000642776
step: 310, loss: 0.033644385635852814
step: 320, loss: 0.03716046363115311
step: 330, loss: 0.0014345149975270033
step: 340, loss: 0.02783159352838993
step: 350, loss: 0.08419077098369598
step: 360, loss: 0.014316425658762455
epoch 16: dev_f1=0.7286821705426356, f1=0.7384615384615385, best_f1=0.7341176470588235
step: 0, loss: 0.029777102172374725
step: 10, loss: 0.040323588997125626
step: 20, loss: 0.022190837189555168
step: 30, loss: 0.025124691426753998
step: 40, loss: 0.04467529430985451
step: 50, loss: 0.060904793441295624
step: 60, loss: 0.017851127311587334
step: 70, loss: 3.3420787076465786e-05
step: 80, loss: 0.04710917919874191
step: 90, loss: 0.10664641857147217
step: 100, loss: 0.04631869122385979
step: 110, loss: 0.015141939744353294
step: 120, loss: 0.01296965591609478
step: 130, loss: 0.03233501315116882
step: 140, loss: 0.010509572923183441
step: 150, loss: 0.01095498725771904
step: 160, loss: 0.041689563542604446
step: 170, loss: 0.07381266355514526
step: 180, loss: 0.09529578685760498
step: 190, loss: 2.8862776161986403e-05
step: 200, loss: 0.06638187170028687
step: 210, loss: 0.04748459532856941
step: 220, loss: 0.07537823915481567
step: 230, loss: 0.0032276923302561045
step: 240, loss: 0.008800799958407879
step: 250, loss: 0.028177984058856964
step: 260, loss: 0.016228921711444855
step: 270, loss: 0.008183681406080723
step: 280, loss: 2.5514027583994903e-05
step: 290, loss: 0.0004142052785027772
step: 300, loss: 0.07912642508745193
step: 310, loss: 0.025696011260151863
step: 320, loss: 0.035647839307785034
step: 330, loss: 0.06718406081199646
step: 340, loss: 0.0013375569833442569
step: 350, loss: 0.01606821082532406
step: 360, loss: 0.13610129058361053
epoch 17: dev_f1=0.7244897959183673, f1=0.7227722772277227, best_f1=0.7341176470588235
step: 0, loss: 0.012921593151986599
step: 10, loss: 0.0436604805290699
step: 20, loss: 0.008174418471753597
step: 30, loss: 0.06525223702192307
step: 40, loss: 0.1304643750190735
step: 50, loss: 0.00464435201138258
step: 60, loss: 0.0001491681468905881
step: 70, loss: 0.044670432806015015
step: 80, loss: 0.008271818049252033
step: 90, loss: 0.027465546503663063
step: 100, loss: 0.012954074889421463
step: 110, loss: 0.037092771381139755
step: 120, loss: 0.05355064570903778
step: 130, loss: 0.028178777545690536
step: 140, loss: 0.1353914588689804
step: 150, loss: 0.01462181843817234
step: 160, loss: 0.009968457743525505
step: 170, loss: 0.03631575033068657
step: 180, loss: 0.025674613192677498
step: 190, loss: 0.03155810758471489
step: 200, loss: 0.05290147662162781
step: 210, loss: 0.00044402165804058313
step: 220, loss: 0.0008047560113482177
step: 230, loss: 0.046138111501932144
step: 240, loss: 0.026698343455791473
step: 250, loss: 0.0011266552610322833
step: 260, loss: 0.0403006412088871
step: 270, loss: 0.06954003870487213
step: 280, loss: 0.04318748041987419
step: 290, loss: 0.031223071739077568
step: 300, loss: 0.034478943794965744
step: 310, loss: 0.08381155133247375
step: 320, loss: 0.06921545416116714
step: 330, loss: 0.04377421364188194
step: 340, loss: 0.0017259401502087712
step: 350, loss: 0.053039390593767166
step: 360, loss: 0.05584118887782097
epoch 18: dev_f1=0.7247956403269755, f1=0.7243243243243244, best_f1=0.7341176470588235
step: 0, loss: 0.017565736547112465
step: 10, loss: 0.05012993887066841
step: 20, loss: 0.0553591363132
step: 30, loss: 0.03726191446185112
step: 40, loss: 0.03277571126818657
step: 50, loss: 0.026001937687397003
step: 60, loss: 0.0006135844741947949
step: 70, loss: 0.003797459416091442
step: 80, loss: 0.1301126778125763
step: 90, loss: 0.08306653797626495
step: 100, loss: 0.02621716447174549
step: 110, loss: 0.024514151737093925
step: 120, loss: 0.0203220434486866
step: 130, loss: 0.009635320864617825
step: 140, loss: 0.0008024011622183025
step: 150, loss: 0.018901055678725243
step: 160, loss: 0.003486950183287263
step: 170, loss: 0.06652753800153732
step: 180, loss: 0.1098380759358406
step: 190, loss: 0.027062902227044106
step: 200, loss: 0.11669694632291794
step: 210, loss: 0.01918906159698963
step: 220, loss: 0.04798357933759689
step: 230, loss: 0.005351652391254902
step: 240, loss: 0.02356107346713543
step: 250, loss: 0.0028113005682826042
step: 260, loss: 0.0055511691607534885
step: 270, loss: 0.024615606293082237
step: 280, loss: 0.06514021754264832
step: 290, loss: 0.012924417853355408
step: 300, loss: 0.08286744356155396
step: 310, loss: 0.005248203407973051
step: 320, loss: 0.016678428277373314
step: 330, loss: 0.024032309651374817
step: 340, loss: 0.017126521095633507
step: 350, loss: 0.018499424681067467
step: 360, loss: 3.848387495963834e-05
epoch 19: dev_f1=0.7214854111405835, f1=0.7305699481865285, best_f1=0.7341176470588235
step: 0, loss: 0.042981673032045364
step: 10, loss: 0.036641474813222885
step: 20, loss: 0.014291434548795223
step: 30, loss: 0.007764196489006281
step: 40, loss: 0.030024975538253784
step: 50, loss: 0.05753926932811737
step: 60, loss: 0.08901067078113556
step: 70, loss: 0.001110140117816627
step: 80, loss: 0.060864970088005066
step: 90, loss: 0.008802823722362518
step: 100, loss: 0.040498729795217514
step: 110, loss: 0.08521541208028793
step: 120, loss: 0.04027850180864334
step: 130, loss: 0.015704002231359482
step: 140, loss: 0.018423326313495636
step: 150, loss: 0.037743233144283295
step: 160, loss: 0.06520602852106094
step: 170, loss: 0.058809615671634674
step: 180, loss: 0.014027873985469341
step: 190, loss: 0.051037684082984924
step: 200, loss: 0.00904370192438364
step: 210, loss: 0.020015306770801544
step: 220, loss: 0.10142695158720016
step: 230, loss: 0.027994897216558456
step: 240, loss: 0.004410490859299898
step: 250, loss: 0.04217921569943428
step: 260, loss: 0.05896298587322235
step: 270, loss: 0.05622793361544609
step: 280, loss: 0.0014060166431590915
step: 290, loss: 0.009194325655698776
step: 300, loss: 0.05813842639327049
step: 310, loss: 0.029091915115714073
step: 320, loss: 0.1131187304854393
step: 330, loss: 0.050754331052303314
step: 340, loss: 0.0024247178807854652
step: 350, loss: 0.004776502028107643
step: 360, loss: 0.04605122283101082
epoch 20: dev_f1=0.7229551451187335, f1=0.7365728900255755, best_f1=0.7341176470588235
