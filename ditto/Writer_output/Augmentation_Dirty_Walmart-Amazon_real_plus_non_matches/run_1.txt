cuda
Device: cuda
step: 0, loss: 0.8691009283065796
step: 10, loss: 0.24568863213062286
step: 20, loss: 0.06606565415859222
step: 30, loss: 0.16945970058441162
step: 40, loss: 0.14304852485656738
step: 50, loss: 0.14501531422138214
step: 60, loss: 0.12627534568309784
step: 70, loss: 0.23771704733371735
step: 80, loss: 0.24016590416431427
step: 90, loss: 0.14432914555072784
step: 100, loss: 0.2470451295375824
step: 110, loss: 0.14523273706436157
step: 120, loss: 0.15267710387706757
step: 130, loss: 0.23839542269706726
step: 140, loss: 0.237791046500206
step: 150, loss: 0.1364104300737381
step: 160, loss: 0.14603596925735474
step: 170, loss: 0.3365688920021057
step: 180, loss: 0.059400223195552826
step: 190, loss: 0.3733985722064972
step: 200, loss: 0.23016954958438873
step: 210, loss: 0.13688457012176514
step: 220, loss: 0.0636468306183815
step: 230, loss: 0.23242837190628052
step: 240, loss: 0.13378314673900604
step: 250, loss: 0.2990897297859192
step: 260, loss: 0.2230900526046753
step: 270, loss: 0.22681117057800293
step: 280, loss: 0.2416321039199829
step: 290, loss: 0.07836507260799408
step: 300, loss: 0.30438491702079773
step: 310, loss: 0.20141038298606873
step: 320, loss: 0.5661036968231201
step: 330, loss: 0.11942115426063538
step: 340, loss: 0.01818065159022808
step: 350, loss: 0.1362859606742859
step: 360, loss: 0.28208908438682556
epoch 1: dev_f1=0.21869040050858235, f1=0.22739018087855298, best_f1=0.22739018087855298
step: 0, loss: 0.19430935382843018
step: 10, loss: 0.04401477426290512
step: 20, loss: 0.1296943873167038
step: 30, loss: 0.20007528364658356
step: 40, loss: 0.07433894276618958
step: 50, loss: 0.45544883608818054
step: 60, loss: 0.06802758574485779
step: 70, loss: 0.053022801876068115
step: 80, loss: 0.1669420748949051
step: 90, loss: 0.13468581438064575
step: 100, loss: 0.22730927169322968
step: 110, loss: 0.013520804233849049
step: 120, loss: 0.10907232016324997
step: 130, loss: 0.02868458814918995
step: 140, loss: 0.15200762450695038
step: 150, loss: 0.12656092643737793
step: 160, loss: 0.2790603041648865
step: 170, loss: 0.153399258852005
step: 180, loss: 0.024753402918577194
step: 190, loss: 0.04511569067835808
step: 200, loss: 0.17981299757957458
step: 210, loss: 0.14727556705474854
step: 220, loss: 0.008686701767146587
step: 230, loss: 0.25087669491767883
step: 240, loss: 0.15507793426513672
step: 250, loss: 0.13646334409713745
step: 260, loss: 0.1396268904209137
step: 270, loss: 0.2916968762874603
step: 280, loss: 0.23126311600208282
step: 290, loss: 0.2239011526107788
step: 300, loss: 0.07003265619277954
step: 310, loss: 0.0931377038359642
step: 320, loss: 0.08272839337587357
step: 330, loss: 0.09622041881084442
step: 340, loss: 0.3950456380844116
step: 350, loss: 0.14571630954742432
step: 360, loss: 0.02324657142162323
epoch 2: dev_f1=0.7134831460674158, f1=0.7013698630136985, best_f1=0.7013698630136985
step: 0, loss: 0.2311525195837021
step: 10, loss: 0.1678064614534378
step: 20, loss: 0.13208796083927155
step: 30, loss: 0.28720763325691223
step: 40, loss: 0.2827093005180359
step: 50, loss: 0.11069846898317337
step: 60, loss: 0.12213670462369919
step: 70, loss: 0.18098331987857819
step: 80, loss: 0.11874343454837799
step: 90, loss: 0.14901986718177795
step: 100, loss: 0.09030800312757492
step: 110, loss: 0.10049409419298172
step: 120, loss: 0.022204440087080002
step: 130, loss: 0.2210085242986679
step: 140, loss: 0.2775947153568268
step: 150, loss: 0.10750137269496918
step: 160, loss: 0.18541166186332703
step: 170, loss: 0.14798270165920258
step: 180, loss: 0.1265113204717636
step: 190, loss: 0.20332050323486328
step: 200, loss: 0.04052435979247093
step: 210, loss: 0.182660311460495
step: 220, loss: 0.20408117771148682
step: 230, loss: 0.2009323388338089
step: 240, loss: 0.1696767657995224
step: 250, loss: 0.11713308095932007
step: 260, loss: 0.29268568754196167
step: 270, loss: 0.028280867263674736
step: 280, loss: 0.05657331272959709
step: 290, loss: 0.0842357650399208
step: 300, loss: 0.04759778082370758
step: 310, loss: 0.02880275994539261
step: 320, loss: 0.1587904393672943
step: 330, loss: 0.3213610053062439
step: 340, loss: 0.12055438756942749
step: 350, loss: 0.08203247934579849
step: 360, loss: 0.0447162427008152
epoch 3: dev_f1=0.7324675324675326, f1=0.7187499999999999, best_f1=0.7187499999999999
step: 0, loss: 0.12709353864192963
step: 10, loss: 0.18501587212085724
step: 20, loss: 0.1824483722448349
step: 30, loss: 0.19855116307735443
step: 40, loss: 0.026275208219885826
step: 50, loss: 0.13783754408359528
step: 60, loss: 0.11282920837402344
step: 70, loss: 0.05255008488893509
step: 80, loss: 0.06769947707653046
step: 90, loss: 0.23418653011322021
step: 100, loss: 0.0894884467124939
step: 110, loss: 0.017041701823472977
step: 120, loss: 0.31531521677970886
step: 130, loss: 0.13674892485141754
step: 140, loss: 0.06151173263788223
step: 150, loss: 0.1685478836297989
step: 160, loss: 0.021620051935315132
step: 170, loss: 0.10265649855136871
step: 180, loss: 0.041077688336372375
step: 190, loss: 0.05341755226254463
step: 200, loss: 0.07582089304924011
step: 210, loss: 0.08214014768600464
step: 220, loss: 0.10522618144750595
step: 230, loss: 0.10426049679517746
step: 240, loss: 0.13261958956718445
step: 250, loss: 0.08359066396951675
step: 260, loss: 0.14152321219444275
step: 270, loss: 0.12137794494628906
step: 280, loss: 0.12646682560443878
step: 290, loss: 0.07111763954162598
step: 300, loss: 0.17064706981182098
step: 310, loss: 0.170172780752182
step: 320, loss: 0.028850726783275604
step: 330, loss: 0.02873305417597294
step: 340, loss: 0.27318334579467773
step: 350, loss: 0.05926954001188278
step: 360, loss: 0.09328095614910126
epoch 4: dev_f1=0.7673267326732673, f1=0.7391304347826088, best_f1=0.7391304347826088
step: 0, loss: 0.06037502735853195
step: 10, loss: 0.05555326119065285
step: 20, loss: 0.045395947992801666
step: 30, loss: 0.07285360991954803
step: 40, loss: 0.0923425704240799
step: 50, loss: 0.05585869774222374
step: 60, loss: 0.0784333273768425
step: 70, loss: 0.055222850292921066
step: 80, loss: 0.0870668888092041
step: 90, loss: 0.17209666967391968
step: 100, loss: 0.0848100483417511
step: 110, loss: 0.0627712607383728
step: 120, loss: 0.0664730966091156
step: 130, loss: 0.11506197601556778
step: 140, loss: 0.09641693532466888
step: 150, loss: 0.020249050110578537
step: 160, loss: 0.03256059065461159
step: 170, loss: 0.1522495150566101
step: 180, loss: 0.0436447374522686
step: 190, loss: 0.08303041756153107
step: 200, loss: 0.026648206636309624
step: 210, loss: 0.06277348101139069
step: 220, loss: 0.11883308738470078
step: 230, loss: 0.08430510014295578
step: 240, loss: 0.06838015466928482
step: 250, loss: 0.0445147305727005
step: 260, loss: 0.09490744769573212
step: 270, loss: 0.09429501742124557
step: 280, loss: 0.08735421299934387
step: 290, loss: 0.06547994911670685
step: 300, loss: 0.15618254244327545
step: 310, loss: 0.13909406960010529
step: 320, loss: 0.03833123669028282
step: 330, loss: 0.03623500093817711
step: 340, loss: 0.06427545845508575
step: 350, loss: 0.13007356226444244
step: 360, loss: 0.14304786920547485
epoch 5: dev_f1=0.7896103896103895, f1=0.7506426735218509, best_f1=0.7506426735218509
step: 0, loss: 0.04289724677801132
step: 10, loss: 0.047944922000169754
step: 20, loss: 0.060011886060237885
step: 30, loss: 0.1704126000404358
step: 40, loss: 0.08842702955007553
step: 50, loss: 0.20887993276119232
step: 60, loss: 0.07849861681461334
step: 70, loss: 0.019488196820020676
step: 80, loss: 0.13487309217453003
step: 90, loss: 0.15156029164791107
step: 100, loss: 0.24670973420143127
step: 110, loss: 0.048448577523231506
step: 120, loss: 0.09554674476385117
step: 130, loss: 0.15125413239002228
step: 140, loss: 0.11702817678451538
step: 150, loss: 0.15460331737995148
step: 160, loss: 0.08060155063867569
step: 170, loss: 0.04717598482966423
step: 180, loss: 0.06615965068340302
step: 190, loss: 0.10831167548894882
step: 200, loss: 0.13692662119865417
step: 210, loss: 0.014462999068200588
step: 220, loss: 0.27381980419158936
step: 230, loss: 0.01759931445121765
step: 240, loss: 0.06742692738771439
step: 250, loss: 0.06626282632350922
step: 260, loss: 0.03889434412121773
step: 270, loss: 0.09126846492290497
step: 280, loss: 0.1640518605709076
step: 290, loss: 0.03923298791050911
step: 300, loss: 0.05940014123916626
step: 310, loss: 0.050813376903533936
step: 320, loss: 0.1344403773546219
step: 330, loss: 0.06515616178512573
step: 340, loss: 0.09429793804883957
step: 350, loss: 0.08359718322753906
step: 360, loss: 0.09233070909976959
epoch 6: dev_f1=0.7412935323383084, f1=0.7263681592039801, best_f1=0.7506426735218509
step: 0, loss: 0.027801506221294403
step: 10, loss: 0.03281587362289429
step: 20, loss: 0.0730731189250946
step: 30, loss: 0.04068645462393761
step: 40, loss: 0.1164882481098175
step: 50, loss: 0.016650144010782242
step: 60, loss: 0.04057607427239418
step: 70, loss: 0.07366178184747696
step: 80, loss: 0.01358078047633171
step: 90, loss: 0.1244320422410965
step: 100, loss: 0.08696617931127548
step: 110, loss: 0.06045369803905487
step: 120, loss: 0.04037754237651825
step: 130, loss: 0.01691596210002899
step: 140, loss: 0.052486613392829895
step: 150, loss: 0.10443378984928131
step: 160, loss: 0.017488757148385048
step: 170, loss: 0.05095800384879112
step: 180, loss: 0.15012714266777039
step: 190, loss: 0.1139286532998085
step: 200, loss: 0.008145628497004509
step: 210, loss: 0.018213622272014618
step: 220, loss: 0.01993243396282196
step: 230, loss: 0.10350282490253448
step: 240, loss: 0.08794388175010681
step: 250, loss: 0.03170618414878845
step: 260, loss: 0.08610853552818298
step: 270, loss: 0.09757693856954575
step: 280, loss: 0.017826765775680542
step: 290, loss: 0.03245202451944351
step: 300, loss: 0.07750023156404495
step: 310, loss: 0.08870753645896912
step: 320, loss: 0.08771439641714096
step: 330, loss: 0.046804025769233704
step: 340, loss: 0.05266860872507095
step: 350, loss: 0.05857790261507034
step: 360, loss: 0.0174420103430748
epoch 7: dev_f1=0.7263922518159805, f1=0.7196029776674937, best_f1=0.7506426735218509
step: 0, loss: 0.12363869696855545
step: 10, loss: 0.03698032721877098
step: 20, loss: 0.06552593410015106
step: 30, loss: 0.09393078833818436
step: 40, loss: 0.01245251577347517
step: 50, loss: 0.08334748446941376
step: 60, loss: 0.017490556463599205
step: 70, loss: 0.09580602496862411
step: 80, loss: 0.11545410752296448
step: 90, loss: 0.02815966308116913
step: 100, loss: 0.2483593374490738
step: 110, loss: 0.10464712232351303
step: 120, loss: 0.12618260085582733
step: 130, loss: 0.06585564464330673
step: 140, loss: 0.06179310381412506
step: 150, loss: 0.06872230768203735
step: 160, loss: 0.08956744521856308
step: 170, loss: 0.006860904395580292
step: 180, loss: 0.08665741235017776
step: 190, loss: 0.055053699761629105
step: 200, loss: 0.1415487378835678
step: 210, loss: 0.04638732224702835
step: 220, loss: 0.035007722675800323
step: 230, loss: 0.18991348147392273
step: 240, loss: 0.02359282411634922
step: 250, loss: 0.057593777775764465
step: 260, loss: 0.0905010998249054
step: 270, loss: 0.05464433506131172
step: 280, loss: 0.07693564146757126
step: 290, loss: 0.07210049778223038
step: 300, loss: 0.07893955707550049
step: 310, loss: 0.085865318775177
step: 320, loss: 0.05612226203083992
step: 330, loss: 0.14655932784080505
step: 340, loss: 0.16363650560379028
step: 350, loss: 0.13682736456394196
step: 360, loss: 0.018535133451223373
epoch 8: dev_f1=0.7427184466019418, f1=0.7131782945736433, best_f1=0.7506426735218509
step: 0, loss: 0.09362861514091492
step: 10, loss: 0.13481472432613373
step: 20, loss: 0.07898414880037308
step: 30, loss: 0.020817449316382408
step: 40, loss: 0.1413871943950653
step: 50, loss: 0.023182077333331108
step: 60, loss: 0.14264829456806183
step: 70, loss: 0.17312289774417877
step: 80, loss: 0.06486106663942337
step: 90, loss: 0.04928531125187874
step: 100, loss: 0.04455430433154106
step: 110, loss: 0.06993868201971054
step: 120, loss: 0.10469090193510056
step: 130, loss: 0.09259721636772156
step: 140, loss: 0.06739241629838943
step: 150, loss: 0.11357863992452621
step: 160, loss: 0.03222154825925827
step: 170, loss: 5.7523531722836196e-05
step: 180, loss: 0.08452856540679932
step: 190, loss: 0.05277078598737717
step: 200, loss: 0.08840441703796387
step: 210, loss: 0.054298195987939835
step: 220, loss: 0.0470602884888649
step: 230, loss: 0.024287762120366096
step: 240, loss: 0.12285687029361725
step: 250, loss: 0.028871288523077965
step: 260, loss: 0.06943719834089279
step: 270, loss: 0.0026852877344936132
step: 280, loss: 0.1953219622373581
step: 290, loss: 0.06370624154806137
step: 300, loss: 0.11543837189674377
step: 310, loss: 0.045804254710674286
step: 320, loss: 0.11534971743822098
step: 330, loss: 0.08664274960756302
step: 340, loss: 0.14210157096385956
step: 350, loss: 0.044790565967559814
step: 360, loss: 0.03161422163248062
epoch 9: dev_f1=0.7556675062972291, f1=0.7512953367875648, best_f1=0.7506426735218509
step: 0, loss: 0.07951880991458893
step: 10, loss: 0.02486845850944519
step: 20, loss: 0.0975302904844284
step: 30, loss: 0.017735203728079796
step: 40, loss: 0.0747276246547699
step: 50, loss: 0.0577935054898262
step: 60, loss: 0.07484249770641327
step: 70, loss: 0.010978980921208858
step: 80, loss: 0.01734292507171631
step: 90, loss: 0.18438081443309784
step: 100, loss: 0.025145357474684715
step: 110, loss: 0.08610542118549347
step: 120, loss: 0.04394491761922836
step: 130, loss: 0.017672935500741005
step: 140, loss: 0.017534730955958366
step: 150, loss: 0.03457030653953552
step: 160, loss: 0.13302384316921234
step: 170, loss: 0.08358587324619293
step: 180, loss: 0.007821504026651382
step: 190, loss: 0.10550950467586517
step: 200, loss: 0.18475572764873505
step: 210, loss: 0.052073534578084946
step: 220, loss: 0.03925339877605438
step: 230, loss: 0.060028742998838425
step: 240, loss: 0.11468096822500229
step: 250, loss: 0.00046072216355241835
step: 260, loss: 0.037516359239816666
step: 270, loss: 0.021934809163212776
step: 280, loss: 0.03929382190108299
step: 290, loss: 0.07824868708848953
step: 300, loss: 0.039326880127191544
step: 310, loss: 0.08626385033130646
step: 320, loss: 0.05362160876393318
step: 330, loss: 0.04549030587077141
step: 340, loss: 0.00987869594246149
step: 350, loss: 0.039004482328891754
step: 360, loss: 0.23127955198287964
epoch 10: dev_f1=0.7178217821782177, f1=0.6938775510204082, best_f1=0.7506426735218509
step: 0, loss: 0.06689337641000748
step: 10, loss: 0.021625109016895294
step: 20, loss: 0.02720649726688862
step: 30, loss: 0.05081327632069588
step: 40, loss: 0.060706060379743576
step: 50, loss: 0.028508702293038368
step: 60, loss: 4.154314228799194e-05
step: 70, loss: 0.04094981402158737
step: 80, loss: 0.05202963203191757
step: 90, loss: 0.00492494460195303
step: 100, loss: 0.13232001662254333
step: 110, loss: 0.02249915711581707
step: 120, loss: 0.13003882765769958
step: 130, loss: 0.09294837713241577
step: 140, loss: 0.14088593423366547
step: 150, loss: 0.08781728148460388
step: 160, loss: 0.025409922003746033
step: 170, loss: 0.01868782378733158
step: 180, loss: 0.028654523193836212
step: 190, loss: 0.0313086099922657
step: 200, loss: 0.04506790637969971
step: 210, loss: 0.04726482555270195
step: 220, loss: 0.08491258323192596
step: 230, loss: 4.799397720489651e-05
step: 240, loss: 0.03107045218348503
step: 250, loss: 0.08771663904190063
step: 260, loss: 0.17752420902252197
step: 270, loss: 0.048854075372219086
step: 280, loss: 0.04875238239765167
step: 290, loss: 0.12699182331562042
step: 300, loss: 0.11666527390480042
step: 310, loss: 0.0376184917986393
step: 320, loss: 0.04236997291445732
step: 330, loss: 0.09826268255710602
step: 340, loss: 0.06314083933830261
step: 350, loss: 0.057955458760261536
step: 360, loss: 0.10261734575033188
epoch 11: dev_f1=0.7616580310880829, f1=0.7526315789473683, best_f1=0.7506426735218509
step: 0, loss: 0.11457239836454391
step: 10, loss: 0.03609520196914673
step: 20, loss: 0.06227646768093109
step: 30, loss: 0.0256341602653265
step: 40, loss: 0.046309694647789
step: 50, loss: 0.15954825282096863
step: 60, loss: 0.011302337050437927
step: 70, loss: 0.12029261887073517
step: 80, loss: 0.05487038195133209
step: 90, loss: 0.04203445091843605
step: 100, loss: 0.025965649634599686
step: 110, loss: 0.04012900963425636
step: 120, loss: 0.09431494027376175
step: 130, loss: 0.028728408738970757
step: 140, loss: 0.05923086032271385
step: 150, loss: 0.07970467954874039
step: 160, loss: 0.07724159955978394
step: 170, loss: 0.048640113323926926
step: 180, loss: 0.045880693942308426
step: 190, loss: 0.05201695114374161
step: 200, loss: 0.01687948778271675
step: 210, loss: 0.0897337943315506
step: 220, loss: 0.044248390942811966
step: 230, loss: 0.06845756620168686
step: 240, loss: 0.09789688140153885
step: 250, loss: 0.02492009662091732
step: 260, loss: 0.01583029329776764
step: 270, loss: 0.15292280912399292
step: 280, loss: 0.029886825010180473
step: 290, loss: 0.031289584934711456
step: 300, loss: 0.042824022471904755
step: 310, loss: 0.00916023924946785
step: 320, loss: 0.002667793072760105
step: 330, loss: 0.051477089524269104
step: 340, loss: 0.027376534417271614
step: 350, loss: 0.17336852848529816
step: 360, loss: 0.050197962671518326
epoch 12: dev_f1=0.7555555555555555, f1=0.7376237623762376, best_f1=0.7506426735218509
step: 0, loss: 0.06067236140370369
step: 10, loss: 0.03247419744729996
step: 20, loss: 0.08079052716493607
step: 30, loss: 0.024479849264025688
step: 40, loss: 0.027580417692661285
step: 50, loss: 0.02414330467581749
step: 60, loss: 3.3935433748411015e-05
step: 70, loss: 0.07107275724411011
step: 80, loss: 0.01979406550526619
step: 90, loss: 0.008958866819739342
step: 100, loss: 0.05690917745232582
step: 110, loss: 0.06582730263471603
step: 120, loss: 0.017818542197346687
step: 130, loss: 0.0014262197073549032
step: 140, loss: 0.0001584292622283101
step: 150, loss: 0.11937259882688522
step: 160, loss: 0.08312802016735077
step: 170, loss: 0.06370469927787781
step: 180, loss: 0.00040177872870117426
step: 190, loss: 0.04743216559290886
step: 200, loss: 0.048713598400354385
step: 210, loss: 0.02073439210653305
step: 220, loss: 0.0311285313218832
step: 230, loss: 0.10669650882482529
step: 240, loss: 0.013551361858844757
step: 250, loss: 0.03821521997451782
step: 260, loss: 0.12782253324985504
step: 270, loss: 0.13355892896652222
step: 280, loss: 0.09338302910327911
step: 290, loss: 0.06182405352592468
step: 300, loss: 0.06575683504343033
step: 310, loss: 0.05146699398756027
step: 320, loss: 0.028647711500525475
step: 330, loss: 0.0003635156317614019
step: 340, loss: 0.07196079194545746
step: 350, loss: 0.047082796692848206
step: 360, loss: 0.15228010714054108
epoch 13: dev_f1=0.748235294117647, f1=0.7506053268765133, best_f1=0.7506426735218509
step: 0, loss: 0.14288859069347382
step: 10, loss: 0.0001875014859251678
step: 20, loss: 0.058747436851263046
step: 30, loss: 0.05425582081079483
step: 40, loss: 0.03047770820558071
step: 50, loss: 0.02029423601925373
step: 60, loss: 0.03534550219774246
step: 70, loss: 0.027592450380325317
step: 80, loss: 0.028756044805049896
step: 90, loss: 0.034722547978162766
step: 100, loss: 0.034999314695596695
step: 110, loss: 0.03317293897271156
step: 120, loss: 0.04406091198325157
step: 130, loss: 0.0696839839220047
step: 140, loss: 0.13731780648231506
step: 150, loss: 0.017115352675318718
step: 160, loss: 0.05173907428979874
step: 170, loss: 0.1738021820783615
step: 180, loss: 0.0458146370947361
step: 190, loss: 0.010093430988490582
step: 200, loss: 0.0002245583018520847
step: 210, loss: 0.003024532226845622
step: 220, loss: 0.10184942185878754
step: 230, loss: 0.058791905641555786
step: 240, loss: 0.08033321797847748
step: 250, loss: 0.003178293351083994
step: 260, loss: 0.00027631365810520947
step: 270, loss: 0.05600544810295105
step: 280, loss: 0.03491074964404106
step: 290, loss: 0.04249674081802368
step: 300, loss: 0.028535526245832443
step: 310, loss: 0.009439077228307724
step: 320, loss: 0.10245252400636673
step: 330, loss: 0.07151629030704498
step: 340, loss: 0.018830155953764915
step: 350, loss: 0.03263554349541664
step: 360, loss: 0.07504857331514359
epoch 14: dev_f1=0.7468671679197996, f1=0.7526315789473683, best_f1=0.7506426735218509
step: 0, loss: 0.024752497673034668
step: 10, loss: 0.042386494576931
step: 20, loss: 0.03837611898779869
step: 30, loss: 0.05518370494246483
step: 40, loss: 0.0742814764380455
step: 50, loss: 0.03427134081721306
step: 60, loss: 0.02216842956840992
step: 70, loss: 0.11281558126211166
step: 80, loss: 0.055549442768096924
step: 90, loss: 0.044692445546388626
step: 100, loss: 0.09234936535358429
step: 110, loss: 0.05004283785820007
step: 120, loss: 0.0006871774676255882
step: 130, loss: 0.07008162140846252
step: 140, loss: 0.08023706078529358
step: 150, loss: 0.09317769855260849
step: 160, loss: 0.04435093700885773
step: 170, loss: 0.028980420902371407
step: 180, loss: 0.036880314350128174
step: 190, loss: 0.014276847243309021
step: 200, loss: 0.031341664493083954
step: 210, loss: 0.08768749237060547
step: 220, loss: 0.05442948639392853
step: 230, loss: 0.07411079108715057
step: 240, loss: 0.03379537910223007
step: 250, loss: 0.012014101259410381
step: 260, loss: 0.028568224981427193
step: 270, loss: 0.023691099137067795
step: 280, loss: 0.04514459893107414
step: 290, loss: 0.03217246010899544
step: 300, loss: 0.051862139254808426
step: 310, loss: 0.07373812794685364
step: 320, loss: 0.00030102863092906773
step: 330, loss: 0.11701846867799759
step: 340, loss: 0.04874422773718834
step: 350, loss: 0.07298630475997925
step: 360, loss: 0.09487718343734741
epoch 15: dev_f1=0.7105882352941176, f1=0.7205882352941175, best_f1=0.7506426735218509
step: 0, loss: 0.008145739324390888
step: 10, loss: 0.01837112195789814
step: 20, loss: 0.09847655147314072
step: 30, loss: 0.06717636436223984
step: 40, loss: 0.007469593081623316
step: 50, loss: 0.06341337412595749
step: 60, loss: 2.6691188395489007e-05
step: 70, loss: 0.027966542169451714
step: 80, loss: 0.040074482560157776
step: 90, loss: 0.0442417711019516
step: 100, loss: 0.05994149297475815
step: 110, loss: 0.00014613028906751424
step: 120, loss: 0.04760861024260521
step: 130, loss: 0.08836212009191513
step: 140, loss: 0.05819089338183403
step: 150, loss: 0.08186694234609604
step: 160, loss: 0.026457756757736206
step: 170, loss: 0.08637510240077972
step: 180, loss: 0.04136575013399124
step: 190, loss: 0.049212560057640076
step: 200, loss: 0.05052243545651436
step: 210, loss: 0.07674276828765869
step: 220, loss: 0.0609290674328804
step: 230, loss: 0.05199466273188591
step: 240, loss: 0.0004959715879522264
step: 250, loss: 0.03908877074718475
step: 260, loss: 0.02710246481001377
step: 270, loss: 0.044728610664606094
step: 280, loss: 0.024526862427592278
step: 290, loss: 0.02809540182352066
step: 300, loss: 0.05619054287672043
step: 310, loss: 0.01890060491859913
step: 320, loss: 0.1586315780878067
step: 330, loss: 0.015266514383256435
step: 340, loss: 0.05618129298090935
step: 350, loss: 0.10790298134088516
step: 360, loss: 0.03117111511528492
epoch 16: dev_f1=0.7383863080684596, f1=0.7336683417085428, best_f1=0.7506426735218509
step: 0, loss: 2.8661726901191287e-05
step: 10, loss: 0.04500873386859894
step: 20, loss: 0.005456005688756704
step: 30, loss: 0.058606404811143875
step: 40, loss: 0.06706319749355316
step: 50, loss: 0.04621138423681259
step: 60, loss: 0.07752560079097748
step: 70, loss: 0.034121233969926834
step: 80, loss: 0.022085700184106827
step: 90, loss: 0.04963615909218788
step: 100, loss: 0.06157577037811279
step: 110, loss: 0.013896459713578224
step: 120, loss: 0.10223856568336487
step: 130, loss: 0.016208607703447342
step: 140, loss: 0.008841353468596935
step: 150, loss: 0.03164450451731682
step: 160, loss: 0.11746156215667725
step: 170, loss: 0.0006444950122386217
step: 180, loss: 0.043439920991659164
step: 190, loss: 0.058215636759996414
step: 200, loss: 0.02388087660074234
step: 210, loss: 0.09884938597679138
step: 220, loss: 0.053508877754211426
step: 230, loss: 0.009878324344754219
step: 240, loss: 0.023926246911287308
step: 250, loss: 0.019011888653039932
step: 260, loss: 0.012578314170241356
step: 270, loss: 0.062103744596242905
step: 280, loss: 0.06103524938225746
step: 290, loss: 0.0011561050778254867
step: 300, loss: 0.12028409540653229
step: 310, loss: 0.02169632352888584
step: 320, loss: 0.08910229057073593
step: 330, loss: 0.012122047133743763
step: 340, loss: 0.023271575570106506
step: 350, loss: 0.003817067015916109
step: 360, loss: 0.0009666929254308343
epoch 17: dev_f1=0.7418546365914787, f1=0.7124010554089709, best_f1=0.7506426735218509
step: 0, loss: 0.08940903842449188
step: 10, loss: 0.03356131538748741
step: 20, loss: 0.045489974319934845
step: 30, loss: 0.047064363956451416
step: 40, loss: 0.05997807905077934
step: 50, loss: 0.023156974464654922
step: 60, loss: 0.03459644317626953
step: 70, loss: 0.0456598661839962
step: 80, loss: 0.056149452924728394
step: 90, loss: 0.10671045631170273
step: 100, loss: 0.00674926582723856
step: 110, loss: 0.048099908977746964
step: 120, loss: 0.02265143394470215
step: 130, loss: 0.006552941165864468
step: 140, loss: 0.060131512582302094
step: 150, loss: 0.01589527539908886
step: 160, loss: 0.05435185879468918
step: 170, loss: 0.1759270578622818
step: 180, loss: 0.02669874019920826
step: 190, loss: 0.07066702842712402
step: 200, loss: 0.05572967976331711
step: 210, loss: 0.021420983597636223
step: 220, loss: 0.03989305719733238
step: 230, loss: 0.017333412542939186
step: 240, loss: 0.006296762265264988
step: 250, loss: 0.05238087475299835
step: 260, loss: 2.226547076134011e-05
step: 270, loss: 0.10583307594060898
step: 280, loss: 0.05853433161973953
step: 290, loss: 0.022515378892421722
step: 300, loss: 0.08105263113975525
step: 310, loss: 0.01102072186768055
step: 320, loss: 0.05289356783032417
step: 330, loss: 0.13331061601638794
step: 340, loss: 0.008694524876773357
step: 350, loss: 0.09045927971601486
step: 360, loss: 0.14637638628482819
epoch 18: dev_f1=0.7341772151898734, f1=0.7291666666666667, best_f1=0.7506426735218509
step: 0, loss: 0.024294082075357437
step: 10, loss: 0.027990423142910004
step: 20, loss: 0.004375365097075701
step: 30, loss: 0.00487420754507184
step: 40, loss: 0.019142543897032738
step: 50, loss: 0.0020997661631554365
step: 60, loss: 0.0356893390417099
step: 70, loss: 0.02950271964073181
step: 80, loss: 0.027121594175696373
step: 90, loss: 0.07300427556037903
step: 100, loss: 0.05872369557619095
step: 110, loss: 0.004578207619488239
step: 120, loss: 0.014257574453949928
step: 130, loss: 0.018163468688726425
step: 140, loss: 0.02334931306540966
step: 150, loss: 0.07441087812185287
step: 160, loss: 0.00017793782171793282
step: 170, loss: 0.0031135063618421555
step: 180, loss: 0.1338552087545395
step: 190, loss: 0.03140890225768089
step: 200, loss: 0.05156545341014862
step: 210, loss: 0.00013912365830037743
step: 220, loss: 0.0031114642042666674
step: 230, loss: 0.05541936308145523
step: 240, loss: 0.0847231075167656
step: 250, loss: 0.043968938291072845
step: 260, loss: 0.0005126251489855349
step: 270, loss: 0.011525405570864677
step: 280, loss: 0.02866365760564804
step: 290, loss: 0.02573343925178051
step: 300, loss: 0.04329182580113411
step: 310, loss: 0.22532624006271362
step: 320, loss: 0.04015366733074188
step: 330, loss: 0.10407832264900208
step: 340, loss: 0.05073374882340431
step: 350, loss: 0.08414110541343689
step: 360, loss: 0.06644495576620102
epoch 19: dev_f1=0.7183462532299743, f1=0.7115902964959568, best_f1=0.7506426735218509
step: 0, loss: 0.04016832262277603
step: 10, loss: 0.03508719056844711
step: 20, loss: 0.016226425766944885
step: 30, loss: 0.014769027940928936
step: 40, loss: 0.033543020486831665
step: 50, loss: 0.035428889095783234
step: 60, loss: 0.02512063831090927
step: 70, loss: 1.7236754501936957e-05
step: 80, loss: 0.049199920147657394
step: 90, loss: 0.010150594636797905
step: 100, loss: 0.023787004873156548
step: 110, loss: 0.01733572967350483
step: 120, loss: 1.6759928257670254e-05
step: 130, loss: 1.6171281458809972e-05
step: 140, loss: 0.040040843188762665
step: 150, loss: 0.02591799758374691
step: 160, loss: 0.08195765316486359
step: 170, loss: 0.023200176656246185
step: 180, loss: 0.07009199261665344
step: 190, loss: 0.04716739431023598
step: 200, loss: 0.062138836830854416
step: 210, loss: 0.00018682390509638935
step: 220, loss: 0.0004965877742506564
step: 230, loss: 0.09589603543281555
step: 240, loss: 0.04566312953829765
step: 250, loss: 0.030881749466061592
step: 260, loss: 0.06045956909656525
step: 270, loss: 0.0717446357011795
step: 280, loss: 1.850692387961317e-05
step: 290, loss: 0.04825585335493088
step: 300, loss: 0.02518903836607933
step: 310, loss: 0.07005855441093445
step: 320, loss: 0.0001328062789980322
step: 330, loss: 0.0271221324801445
step: 340, loss: 0.03503552824258804
step: 350, loss: 0.042885955423116684
step: 360, loss: 0.06230220943689346
epoch 20: dev_f1=0.7135416666666666, f1=0.7046070460704608, best_f1=0.7506426735218509
