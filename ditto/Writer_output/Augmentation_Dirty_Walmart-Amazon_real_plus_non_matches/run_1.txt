cuda
Device: cuda
step: 0, loss: 0.5621689558029175
step: 10, loss: 0.16387015581130981
step: 20, loss: 0.3193795382976532
step: 30, loss: 0.04062226787209511
step: 40, loss: 0.23139256238937378
step: 50, loss: 0.364190012216568
step: 60, loss: 0.14786413311958313
step: 70, loss: 0.1366748958826065
step: 80, loss: 0.03380367159843445
step: 90, loss: 0.2210627794265747
step: 100, loss: 0.053133539855480194
step: 110, loss: 0.13572341203689575
step: 120, loss: 0.5347212553024292
step: 130, loss: 0.1186528429389
step: 140, loss: 0.2079007625579834
step: 150, loss: 0.16989588737487793
step: 160, loss: 0.15832510590553284
step: 170, loss: 0.11195414513349533
step: 180, loss: 0.289335697889328
step: 190, loss: 0.1296868771314621
step: 200, loss: 0.03895503282546997
step: 210, loss: 0.24247516691684723
step: 220, loss: 0.22224801778793335
step: 230, loss: 0.12470337748527527
step: 240, loss: 0.038301289081573486
step: 250, loss: 0.24171841144561768
step: 260, loss: 0.03665059059858322
step: 270, loss: 0.2153257429599762
step: 280, loss: 0.15302518010139465
step: 290, loss: 0.018257850781083107
step: 300, loss: 0.23795121908187866
step: 310, loss: 0.1179020032286644
step: 320, loss: 0.17908543348312378
step: 330, loss: 0.09408821910619736
step: 340, loss: 0.3589721620082855
step: 350, loss: 0.12134221196174622
step: 360, loss: 0.13072839379310608
epoch 1: dev_f1=0.6014669926650367, f1=0.639423076923077, best_f1=0.639423076923077
step: 0, loss: 0.05741492658853531
step: 10, loss: 0.10106385499238968
step: 20, loss: 0.07168513536453247
step: 30, loss: 0.040870822966098785
step: 40, loss: 0.08012986183166504
step: 50, loss: 0.1671864539384842
step: 60, loss: 0.26920658349990845
step: 70, loss: 0.257412314414978
step: 80, loss: 0.2093958705663681
step: 90, loss: 0.04144987091422081
step: 100, loss: 0.06745566427707672
step: 110, loss: 0.13444378972053528
step: 120, loss: 0.07053760439157486
step: 130, loss: 0.081053227186203
step: 140, loss: 0.027724653482437134
step: 150, loss: 0.19471785426139832
step: 160, loss: 0.047580111771821976
step: 170, loss: 0.19309933483600616
step: 180, loss: 0.1550866663455963
step: 190, loss: 0.08644924312829971
step: 200, loss: 0.08600355684757233
step: 210, loss: 0.004708604421466589
step: 220, loss: 0.08670735359191895
step: 230, loss: 0.1181718036532402
step: 240, loss: 0.03317129611968994
step: 250, loss: 0.026380015537142754
step: 260, loss: 0.06296360492706299
step: 270, loss: 0.14287112653255463
step: 280, loss: 0.14738228917121887
step: 290, loss: 0.1714741587638855
step: 300, loss: 0.13067877292633057
step: 310, loss: 0.021740075200796127
step: 320, loss: 0.2285606563091278
step: 330, loss: 0.24373748898506165
step: 340, loss: 0.07357078790664673
step: 350, loss: 0.2219822108745575
step: 360, loss: 0.05609258636832237
epoch 2: dev_f1=0.7195767195767196, f1=0.7443037974683544, best_f1=0.7443037974683544
step: 0, loss: 0.053846824914216995
step: 10, loss: 0.0502605102956295
step: 20, loss: 0.0721573680639267
step: 30, loss: 0.035373181104660034
step: 40, loss: 0.22224657237529755
step: 50, loss: 0.03467406705021858
step: 60, loss: 0.04408270865678787
step: 70, loss: 0.17687314748764038
step: 80, loss: 0.09239166229963303
step: 90, loss: 0.05468546599149704
step: 100, loss: 0.04873683303594589
step: 110, loss: 0.0523202121257782
step: 120, loss: 0.11711271852254868
step: 130, loss: 0.084363654255867
step: 140, loss: 0.157631516456604
step: 150, loss: 0.1508779674768448
step: 160, loss: 0.26077547669410706
step: 170, loss: 0.21301396191120148
step: 180, loss: 0.026985514909029007
step: 190, loss: 0.012890085577964783
step: 200, loss: 0.03964495286345482
step: 210, loss: 0.08807215094566345
step: 220, loss: 0.09529737383127213
step: 230, loss: 0.17341575026512146
step: 240, loss: 0.11860242486000061
step: 250, loss: 0.1772875189781189
step: 260, loss: 0.04227316379547119
step: 270, loss: 0.11179491877555847
step: 280, loss: 0.08907334506511688
step: 290, loss: 0.1188187375664711
step: 300, loss: 0.16579735279083252
step: 310, loss: 0.08117901533842087
step: 320, loss: 0.07323849201202393
step: 330, loss: 0.1823311746120453
step: 340, loss: 0.16721326112747192
step: 350, loss: 0.06913583725690842
step: 360, loss: 0.16601279377937317
epoch 3: dev_f1=0.7365591397849462, f1=0.7253333333333334, best_f1=0.7253333333333334
step: 0, loss: 0.07132822275161743
step: 10, loss: 0.1492152363061905
step: 20, loss: 0.08697053045034409
step: 30, loss: 0.14063000679016113
step: 40, loss: 0.04398519918322563
step: 50, loss: 0.03226212039589882
step: 60, loss: 0.12557579576969147
step: 70, loss: 0.04527497664093971
step: 80, loss: 0.045734673738479614
step: 90, loss: 0.06293036788702011
step: 100, loss: 0.09326796233654022
step: 110, loss: 0.16417911648750305
step: 120, loss: 0.040458329021930695
step: 130, loss: 0.09158217161893845
step: 140, loss: 0.08957839012145996
step: 150, loss: 0.0738568976521492
step: 160, loss: 0.07494518160820007
step: 170, loss: 0.06626924872398376
step: 180, loss: 0.05526687577366829
step: 190, loss: 0.12591059505939484
step: 200, loss: 0.07884085178375244
step: 210, loss: 0.047816433012485504
step: 220, loss: 0.0271085724234581
step: 230, loss: 0.08237376809120178
step: 240, loss: 0.22447124123573303
step: 250, loss: 0.11725509166717529
step: 260, loss: 0.14823247492313385
step: 270, loss: 0.16015031933784485
step: 280, loss: 0.05061362683773041
step: 290, loss: 0.03134039416909218
step: 300, loss: 0.12613339722156525
step: 310, loss: 0.21206708252429962
step: 320, loss: 0.17193818092346191
step: 330, loss: 0.08756832778453827
step: 340, loss: 0.21263904869556427
step: 350, loss: 0.1061595007777214
step: 360, loss: 0.014680587686598301
epoch 4: dev_f1=0.7286821705426356, f1=0.6737400530503979, best_f1=0.7253333333333334
step: 0, loss: 0.003974239807575941
step: 10, loss: 0.057136476039886475
step: 20, loss: 0.06681747734546661
step: 30, loss: 0.03829330950975418
step: 40, loss: 0.07614079117774963
step: 50, loss: 0.05194823071360588
step: 60, loss: 0.1826411634683609
step: 70, loss: 0.19566285610198975
step: 80, loss: 0.15130235254764557
step: 90, loss: 0.01637151651084423
step: 100, loss: 0.039724577218294144
step: 110, loss: 0.07351969182491302
step: 120, loss: 0.07536187767982483
step: 130, loss: 0.04104364663362503
step: 140, loss: 0.08619920909404755
step: 150, loss: 0.14383187890052795
step: 160, loss: 0.18745990097522736
step: 170, loss: 0.14013846218585968
step: 180, loss: 0.1694025993347168
step: 190, loss: 0.06578432023525238
step: 200, loss: 0.03040360100567341
step: 210, loss: 0.09439139813184738
step: 220, loss: 0.0737590342760086
step: 230, loss: 0.011883778497576714
step: 240, loss: 0.17710979282855988
step: 250, loss: 0.17722083628177643
step: 260, loss: 0.030431514605879784
step: 270, loss: 0.07195591926574707
step: 280, loss: 0.12110487371683121
step: 290, loss: 0.10835791379213333
step: 300, loss: 0.07161998003721237
step: 310, loss: 0.12119275331497192
step: 320, loss: 0.031316109001636505
step: 330, loss: 0.1034955084323883
step: 340, loss: 0.10443124175071716
step: 350, loss: 0.12651878595352173
step: 360, loss: 0.14996173977851868
epoch 5: dev_f1=0.7333333333333333, f1=0.6858789625360231, best_f1=0.7253333333333334
step: 0, loss: 0.01667587272822857
step: 10, loss: 0.1520480066537857
step: 20, loss: 0.0774005576968193
step: 30, loss: 0.09139522165060043
step: 40, loss: 0.13362941145896912
step: 50, loss: 0.083187036216259
step: 60, loss: 0.056671034544706345
step: 70, loss: 0.09008222073316574
step: 80, loss: 0.03804505988955498
step: 90, loss: 0.1287645846605301
step: 100, loss: 0.03303764760494232
step: 110, loss: 0.02816637046635151
step: 120, loss: 0.09374720603227615
step: 130, loss: 0.11446887999773026
step: 140, loss: 0.09012514352798462
step: 150, loss: 0.06848882883787155
step: 160, loss: 0.05665923282504082
step: 170, loss: 0.030929699540138245
step: 180, loss: 0.13025273382663727
step: 190, loss: 0.03050079755485058
step: 200, loss: 0.056465115398168564
step: 210, loss: 0.060455866158008575
step: 220, loss: 0.05337115004658699
step: 230, loss: 0.04041413217782974
step: 240, loss: 0.19962966442108154
step: 250, loss: 0.0423419363796711
step: 260, loss: 0.0621156208217144
step: 270, loss: 0.05773245543241501
step: 280, loss: 0.06819585710763931
step: 290, loss: 0.09584742784500122
step: 300, loss: 0.04393615573644638
step: 310, loss: 0.0970001146197319
step: 320, loss: 0.07371966540813446
step: 330, loss: 0.0910000279545784
step: 340, loss: 0.04514462873339653
step: 350, loss: 0.16158589720726013
step: 360, loss: 0.041236963123083115
epoch 6: dev_f1=0.7347931873479319, f1=0.7096774193548387, best_f1=0.7253333333333334
step: 0, loss: 0.09037443995475769
step: 10, loss: 0.05978275090456009
step: 20, loss: 0.03864869475364685
step: 30, loss: 0.10239160060882568
step: 40, loss: 0.00017203556490130723
step: 50, loss: 0.15674684941768646
step: 60, loss: 0.10392500460147858
step: 70, loss: 0.09646889567375183
step: 80, loss: 0.20073044300079346
step: 90, loss: 0.13536189496517181
step: 100, loss: 0.1490960419178009
step: 110, loss: 0.043048154562711716
step: 120, loss: 0.024183792993426323
step: 130, loss: 0.022647051140666008
step: 140, loss: 0.0778590589761734
step: 150, loss: 0.04878460243344307
step: 160, loss: 0.22724191844463348
step: 170, loss: 0.04023929685354233
step: 180, loss: 0.008884557522833347
step: 190, loss: 0.023293511942029
step: 200, loss: 0.035063691437244415
step: 210, loss: 0.15550436079502106
step: 220, loss: 0.10803390294313431
step: 230, loss: 0.02698662504553795
step: 240, loss: 0.08449999243021011
step: 250, loss: 0.07905987650156021
step: 260, loss: 0.069920614361763
step: 270, loss: 0.10999105125665665
step: 280, loss: 0.25461113452911377
step: 290, loss: 0.07784993201494217
step: 300, loss: 0.18757948279380798
step: 310, loss: 0.13587982952594757
step: 320, loss: 0.017454560846090317
step: 330, loss: 0.031242836266756058
step: 340, loss: 0.06298037618398666
step: 350, loss: 0.06229959800839424
step: 360, loss: 0.2163933515548706
epoch 7: dev_f1=0.7161125319693094, f1=0.7346938775510203, best_f1=0.7253333333333334
step: 0, loss: 0.1180734783411026
step: 10, loss: 0.23451662063598633
step: 20, loss: 0.026534149423241615
step: 30, loss: 0.053218115121126175
step: 40, loss: 0.071238674223423
step: 50, loss: 0.09907522052526474
step: 60, loss: 0.06348580121994019
step: 70, loss: 0.0715184286236763
step: 80, loss: 0.11416296660900116
step: 90, loss: 0.00040205460391007364
step: 100, loss: 0.03142862021923065
step: 110, loss: 0.0882781371474266
step: 120, loss: 0.015535756945610046
step: 130, loss: 0.06390498578548431
step: 140, loss: 0.01897207461297512
step: 150, loss: 0.04098441079258919
step: 160, loss: 0.08930421620607376
step: 170, loss: 0.1494140625
step: 180, loss: 0.050164397805929184
step: 190, loss: 0.04833535477519035
step: 200, loss: 0.050498370081186295
step: 210, loss: 0.04594118893146515
step: 220, loss: 0.07619732618331909
step: 230, loss: 0.07849126309156418
step: 240, loss: 0.018514230847358704
step: 250, loss: 0.004023406654596329
step: 260, loss: 0.05169783905148506
step: 270, loss: 0.05118100345134735
step: 280, loss: 0.10673033446073532
step: 290, loss: 0.024920092895627022
step: 300, loss: 0.08743439614772797
step: 310, loss: 0.16591626405715942
step: 320, loss: 0.06335099786520004
step: 330, loss: 0.038883909583091736
step: 340, loss: 0.06145172938704491
step: 350, loss: 0.013435627333819866
step: 360, loss: 0.041377633810043335
epoch 8: dev_f1=0.7263681592039801, f1=0.7178217821782177, best_f1=0.7253333333333334
step: 0, loss: 0.09741558134555817
step: 10, loss: 0.09913250058889389
step: 20, loss: 0.026348602026700974
step: 30, loss: 0.06165089085698128
step: 40, loss: 0.053174201399087906
step: 50, loss: 0.1274898648262024
step: 60, loss: 0.015074559487402439
step: 70, loss: 0.081630639731884
step: 80, loss: 0.025325395166873932
step: 90, loss: 0.048009585589170456
step: 100, loss: 0.03504107519984245
step: 110, loss: 0.03388063237071037
step: 120, loss: 0.21902413666248322
step: 130, loss: 0.053786229342222214
step: 140, loss: 0.029063353314995766
step: 150, loss: 0.03539377450942993
step: 160, loss: 0.026453698053956032
step: 170, loss: 0.09193795174360275
step: 180, loss: 0.017230309545993805
step: 190, loss: 0.12022578716278076
step: 200, loss: 0.1254768818616867
step: 210, loss: 0.05208861455321312
step: 220, loss: 0.04021128639578819
step: 230, loss: 0.03081834875047207
step: 240, loss: 0.0664413571357727
step: 250, loss: 0.08933525532484055
step: 260, loss: 0.03457873314619064
step: 270, loss: 0.06154052913188934
step: 280, loss: 0.06387681514024734
step: 290, loss: 0.070982426404953
step: 300, loss: 0.0561336874961853
step: 310, loss: 0.018369099125266075
step: 320, loss: 0.051065843552351
step: 330, loss: 0.03498603403568268
step: 340, loss: 0.033188171684741974
step: 350, loss: 0.09241874516010284
step: 360, loss: 0.021632280200719833
epoch 9: dev_f1=0.7479224376731302, f1=0.724233983286908, best_f1=0.724233983286908
step: 0, loss: 0.0777621939778328
step: 10, loss: 0.061723072081804276
step: 20, loss: 0.016460508108139038
step: 30, loss: 0.01894315518438816
step: 40, loss: 0.05436442792415619
step: 50, loss: 0.11198503524065018
step: 60, loss: 0.14589281380176544
step: 70, loss: 0.028934311121702194
step: 80, loss: 0.08802159130573273
step: 90, loss: 0.1008746400475502
step: 100, loss: 0.09371505677700043
step: 110, loss: 0.0008038834203034639
step: 120, loss: 0.044772688299417496
step: 130, loss: 0.05076046288013458
step: 140, loss: 0.035116687417030334
step: 150, loss: 0.15813258290290833
step: 160, loss: 0.04821443557739258
step: 170, loss: 0.03433661162853241
step: 180, loss: 0.0494745671749115
step: 190, loss: 0.04593770205974579
step: 200, loss: 0.10090585798025131
step: 210, loss: 0.06779161095619202
step: 220, loss: 0.05055394023656845
step: 230, loss: 0.05350657179951668
step: 240, loss: 0.051270388066768646
step: 250, loss: 0.06228979676961899
step: 260, loss: 0.0686066523194313
step: 270, loss: 0.04765492305159569
step: 280, loss: 0.10363692045211792
step: 290, loss: 0.012793531641364098
step: 300, loss: 0.03444879874587059
step: 310, loss: 0.11131342500448227
step: 320, loss: 0.12429072707891464
step: 330, loss: 0.04516726732254028
step: 340, loss: 0.08992677927017212
step: 350, loss: 0.05539049953222275
step: 360, loss: 0.11842645704746246
epoch 10: dev_f1=0.7529976019184653, f1=0.7350835322195705, best_f1=0.7350835322195705
step: 0, loss: 0.06869745999574661
step: 10, loss: 0.07276713103055954
step: 20, loss: 0.06014963984489441
step: 30, loss: 0.07204089313745499
step: 40, loss: 0.06611517071723938
step: 50, loss: 0.05238689109683037
step: 60, loss: 0.0300068911164999
step: 70, loss: 0.12891635298728943
step: 80, loss: 0.016778189688920975
step: 90, loss: 0.05110709369182587
step: 100, loss: 0.03193434327840805
step: 110, loss: 0.07009679824113846
step: 120, loss: 0.0813729390501976
step: 130, loss: 0.05285760015249252
step: 140, loss: 0.0462956503033638
step: 150, loss: 0.03695201501250267
step: 160, loss: 0.04276673123240471
step: 170, loss: 0.07592524588108063
step: 180, loss: 0.01026621088385582
step: 190, loss: 0.06354095041751862
step: 200, loss: 0.08597432076931
step: 210, loss: 0.043665964156389236
step: 220, loss: 0.011913858354091644
step: 230, loss: 0.20698419213294983
step: 240, loss: 0.0538434162735939
step: 250, loss: 0.06972996145486832
step: 260, loss: 0.05896751582622528
step: 270, loss: 0.08699318021535873
step: 280, loss: 0.11523254215717316
step: 290, loss: 0.07952211797237396
step: 300, loss: 0.07765525579452515
step: 310, loss: 0.09590566158294678
step: 320, loss: 0.08748944848775864
step: 330, loss: 0.07757699489593506
step: 340, loss: 0.014451258815824986
step: 350, loss: 0.06553982198238373
step: 360, loss: 0.05803823843598366
epoch 11: dev_f1=0.7268041237113403, f1=0.7422680412371134, best_f1=0.7350835322195705
step: 0, loss: 0.11552198976278305
step: 10, loss: 0.11705680191516876
step: 20, loss: 0.07112272828817368
step: 30, loss: 0.035400260239839554
step: 40, loss: 0.010228023864328861
step: 50, loss: 0.053204748779535294
step: 60, loss: 0.03079066053032875
step: 70, loss: 0.0958261489868164
step: 80, loss: 0.04035213962197304
step: 90, loss: 0.04482724145054817
step: 100, loss: 0.044412218034267426
step: 110, loss: 0.003675128100439906
step: 120, loss: 0.13454629480838776
step: 130, loss: 0.07029741257429123
step: 140, loss: 0.10346075892448425
step: 150, loss: 9.905493061523885e-05
step: 160, loss: 0.027115454897284508
step: 170, loss: 0.0503784604370594
step: 180, loss: 0.04690531641244888
step: 190, loss: 0.015010558068752289
step: 200, loss: 0.039746686816215515
step: 210, loss: 0.022894570603966713
step: 220, loss: 0.0917678028345108
step: 230, loss: 0.07216434180736542
step: 240, loss: 0.06809259206056595
step: 250, loss: 0.08821504563093185
step: 260, loss: 0.09139736741781235
step: 270, loss: 0.06680047512054443
step: 280, loss: 0.023304706439375877
step: 290, loss: 0.0767693966627121
step: 300, loss: 0.00025474620633758605
step: 310, loss: 0.009680327028036118
step: 320, loss: 0.1524639129638672
step: 330, loss: 0.16482390463352203
step: 340, loss: 0.019498301669955254
step: 350, loss: 0.0364210270345211
step: 360, loss: 0.022019987925887108
epoch 12: dev_f1=0.7188264058679708, f1=0.73, best_f1=0.7350835322195705
step: 0, loss: 0.06301464140415192
step: 10, loss: 0.06391096115112305
step: 20, loss: 0.02479785494506359
step: 30, loss: 0.036954786628484726
step: 40, loss: 0.061835892498493195
step: 50, loss: 0.025082258507609367
step: 60, loss: 0.09039580821990967
step: 70, loss: 0.05806625634431839
step: 80, loss: 0.1117532029747963
step: 90, loss: 0.005750048905611038
step: 100, loss: 0.028756368905305862
step: 110, loss: 0.00010523073433432728
step: 120, loss: 0.11913415044546127
step: 130, loss: 0.061900194734334946
step: 140, loss: 0.02980183996260166
step: 150, loss: 0.023616446182131767
step: 160, loss: 0.0004718757118098438
step: 170, loss: 0.09468085318803787
step: 180, loss: 0.07103530317544937
step: 190, loss: 0.030439674854278564
step: 200, loss: 0.04725978896021843
step: 210, loss: 0.010388314723968506
step: 220, loss: 0.08654084801673889
step: 230, loss: 0.08649913966655731
step: 240, loss: 0.10564402490854263
step: 250, loss: 0.047155555337667465
step: 260, loss: 0.06489244103431702
step: 270, loss: 0.030752776190638542
step: 280, loss: 0.04814736172556877
step: 290, loss: 0.06022553890943527
step: 300, loss: 0.026656458154320717
step: 310, loss: 0.05693148449063301
step: 320, loss: 0.14833788573741913
step: 330, loss: 0.06622385233640671
step: 340, loss: 0.17495611310005188
step: 350, loss: 0.04655901715159416
step: 360, loss: 0.06995303928852081
epoch 13: dev_f1=0.741687979539642, f1=0.739795918367347, best_f1=0.7350835322195705
step: 0, loss: 0.015479866415262222
step: 10, loss: 0.026933997869491577
step: 20, loss: 0.006358751095831394
step: 30, loss: 0.018400104716420174
step: 40, loss: 0.06208174675703049
step: 50, loss: 0.12427696585655212
step: 60, loss: 0.08442328125238419
step: 70, loss: 0.1083158329129219
step: 80, loss: 0.037945639342069626
step: 90, loss: 0.04313569515943527
step: 100, loss: 0.043066080659627914
step: 110, loss: 0.03324611857533455
step: 120, loss: 0.03208014369010925
step: 130, loss: 0.08490879088640213
step: 140, loss: 0.03971719741821289
step: 150, loss: 0.05708352476358414
step: 160, loss: 0.0331798754632473
step: 170, loss: 0.05359954759478569
step: 180, loss: 0.09742192924022675
step: 190, loss: 0.03747481480240822
step: 200, loss: 0.004110624082386494
step: 210, loss: 0.06573706865310669
step: 220, loss: 0.0009822315769270062
step: 230, loss: 0.036013808101415634
step: 240, loss: 0.0751696527004242
step: 250, loss: 0.09354381263256073
step: 260, loss: 0.07121607661247253
step: 270, loss: 0.0002523702278267592
step: 280, loss: 0.055030666291713715
step: 290, loss: 0.10086958110332489
step: 300, loss: 0.0005026260623708367
step: 310, loss: 0.05571811646223068
step: 320, loss: 0.03298967331647873
step: 330, loss: 0.006087941583245993
step: 340, loss: 7.002051279414445e-05
step: 350, loss: 0.016490455716848373
step: 360, loss: 0.05301090329885483
epoch 14: dev_f1=0.7423167848699763, f1=0.7445255474452556, best_f1=0.7350835322195705
step: 0, loss: 0.09428426623344421
step: 10, loss: 0.042196378111839294
step: 20, loss: 0.026442095637321472
step: 30, loss: 0.008549412712454796
step: 40, loss: 0.032075006514787674
step: 50, loss: 0.08683398365974426
step: 60, loss: 0.0002140999713446945
step: 70, loss: 0.07336188852787018
step: 80, loss: 0.012176970019936562
step: 90, loss: 0.06927336007356644
step: 100, loss: 7.821577310096473e-05
step: 110, loss: 0.04677804186940193
step: 120, loss: 0.041312359273433685
step: 130, loss: 0.05909612029790878
step: 140, loss: 0.10323762148618698
step: 150, loss: 0.04731456935405731
step: 160, loss: 0.0538194365799427
step: 170, loss: 0.08902725577354431
step: 180, loss: 0.016732407733798027
step: 190, loss: 0.06815079599618912
step: 200, loss: 0.06312638521194458
step: 210, loss: 0.1229022815823555
step: 220, loss: 0.07519689947366714
step: 230, loss: 0.006171530112624168
step: 240, loss: 0.015463517978787422
step: 250, loss: 0.01152244582772255
step: 260, loss: 0.035054631531238556
step: 270, loss: 0.11158549040555954
step: 280, loss: 0.0006836603279225528
step: 290, loss: 0.10064037889242172
step: 300, loss: 0.05240804702043533
step: 310, loss: 0.024298416450619698
step: 320, loss: 0.0591295063495636
step: 330, loss: 0.013275345787405968
step: 340, loss: 0.02304001711308956
step: 350, loss: 0.04382438585162163
step: 360, loss: 0.10681977868080139
epoch 15: dev_f1=0.7292817679558011, f1=0.723756906077348, best_f1=0.7350835322195705
step: 0, loss: 0.012691611424088478
step: 10, loss: 0.041709572076797485
step: 20, loss: 0.02207265980541706
step: 30, loss: 0.060695234686136246
step: 40, loss: 0.020495980978012085
step: 50, loss: 0.0603417307138443
step: 60, loss: 0.01856495812535286
step: 70, loss: 0.043562937527894974
step: 80, loss: 0.11104220151901245
step: 90, loss: 0.05135601386427879
step: 100, loss: 0.06705270707607269
step: 110, loss: 0.10630371421575546
step: 120, loss: 0.05331190302968025
step: 130, loss: 0.03882249817252159
step: 140, loss: 0.006382805295288563
step: 150, loss: 0.059098873287439346
step: 160, loss: 0.005742823705077171
step: 170, loss: 0.044300276786088943
step: 180, loss: 0.0019885299261659384
step: 190, loss: 0.015975410118699074
step: 200, loss: 0.07098814845085144
step: 210, loss: 0.16229325532913208
step: 220, loss: 0.032348062843084335
step: 230, loss: 0.12477552145719528
step: 240, loss: 4.243455987307243e-05
step: 250, loss: 0.003495875746011734
step: 260, loss: 0.022718774154782295
step: 270, loss: 0.07063091546297073
step: 280, loss: 0.09981747716665268
step: 290, loss: 0.06611357629299164
step: 300, loss: 0.07295966893434525
step: 310, loss: 0.03848573565483093
step: 320, loss: 0.08449948579072952
step: 330, loss: 0.012249230407178402
step: 340, loss: 0.04401141032576561
step: 350, loss: 0.07407116889953613
step: 360, loss: 6.476383714471012e-05
epoch 16: dev_f1=0.7282321899736147, f1=0.7223719676549865, best_f1=0.7350835322195705
step: 0, loss: 0.028983494266867638
step: 10, loss: 0.035343706607818604
step: 20, loss: 0.05831841006875038
step: 30, loss: 0.022943632677197456
step: 40, loss: 0.11887769401073456
step: 50, loss: 0.016390841454267502
step: 60, loss: 0.06425723433494568
step: 70, loss: 0.022699052467942238
step: 80, loss: 0.14657053351402283
step: 90, loss: 0.04445996135473251
step: 100, loss: 0.08202862739562988
step: 110, loss: 0.005779061000794172
step: 120, loss: 0.05806216970086098
step: 130, loss: 0.0016451729461550713
step: 140, loss: 0.06591040641069412
step: 150, loss: 0.0932021290063858
step: 160, loss: 0.028461376205086708
step: 170, loss: 0.006141153629869223
step: 180, loss: 0.020619872957468033
step: 190, loss: 0.014010919257998466
step: 200, loss: 0.027265742421150208
step: 210, loss: 0.012847633101046085
step: 220, loss: 0.02486051619052887
step: 230, loss: 0.027539070695638657
step: 240, loss: 0.020489126443862915
step: 250, loss: 0.09709221124649048
step: 260, loss: 0.02389359474182129
step: 270, loss: 0.10888298600912094
step: 280, loss: 3.007703162438702e-05
step: 290, loss: 0.01156497560441494
step: 300, loss: 0.013028030283749104
step: 310, loss: 0.003939187619835138
step: 320, loss: 0.006382150109857321
step: 330, loss: 0.0842098668217659
step: 340, loss: 0.04047162085771561
step: 350, loss: 0.09751205891370773
step: 360, loss: 0.03691906854510307
epoch 17: dev_f1=0.720626631853786, f1=0.7223719676549865, best_f1=0.7350835322195705
step: 0, loss: 0.036569882184267044
step: 10, loss: 0.060847796499729156
step: 20, loss: 0.027725331485271454
step: 30, loss: 0.03411218896508217
step: 40, loss: 0.013022533617913723
step: 50, loss: 0.030201507732272148
step: 60, loss: 0.0706711933016777
step: 70, loss: 0.08307064324617386
step: 80, loss: 0.012221405282616615
step: 90, loss: 0.00799629557877779
step: 100, loss: 0.0703352764248848
step: 110, loss: 0.10649009793996811
step: 120, loss: 0.023776330053806305
step: 130, loss: 0.05190291628241539
step: 140, loss: 0.05371031537652016
step: 150, loss: 0.00040688825538381934
step: 160, loss: 0.06007359176874161
step: 170, loss: 0.04657701775431633
step: 180, loss: 0.11104179173707962
step: 190, loss: 0.10732141137123108
step: 200, loss: 0.010682148858904839
step: 210, loss: 0.003208813024684787
step: 220, loss: 0.01643935777246952
step: 230, loss: 0.08729343116283417
step: 240, loss: 0.022886943072080612
step: 250, loss: 0.15176604688167572
step: 260, loss: 0.10557122528553009
step: 270, loss: 0.0319741927087307
step: 280, loss: 0.06739399582147598
step: 290, loss: 0.055537499487400055
step: 300, loss: 0.11912639439105988
step: 310, loss: 0.05332920327782631
step: 320, loss: 0.0004946736735291779
step: 330, loss: 0.014607383869588375
step: 340, loss: 0.04210341349244118
step: 350, loss: 0.031574588268995285
step: 360, loss: 0.09841698408126831
epoch 18: dev_f1=0.7109974424552431, f1=0.7187499999999999, best_f1=0.7350835322195705
step: 0, loss: 0.0040303803980350494
step: 10, loss: 0.036227159202098846
step: 20, loss: 0.021115170791745186
step: 30, loss: 0.02428188920021057
step: 40, loss: 0.02763991244137287
step: 50, loss: 0.01814943552017212
step: 60, loss: 0.08300596475601196
step: 70, loss: 0.03308907151222229
step: 80, loss: 0.016117798164486885
step: 90, loss: 0.07127472758293152
step: 100, loss: 4.622920459951274e-05
step: 110, loss: 0.03620321303606033
step: 120, loss: 0.052586257457733154
step: 130, loss: 0.061708930879831314
step: 140, loss: 0.022893279790878296
step: 150, loss: 0.04588161036372185
step: 160, loss: 0.03181060776114464
step: 170, loss: 0.020505113527178764
step: 180, loss: 0.01741630584001541
step: 190, loss: 0.07148844003677368
step: 200, loss: 0.06500598043203354
step: 210, loss: 0.02093116007745266
step: 220, loss: 0.04826202616095543
step: 230, loss: 0.02994474582374096
step: 240, loss: 0.011108522303402424
step: 250, loss: 0.06429941207170486
step: 260, loss: 0.038850415498018265
step: 270, loss: 0.0009228731505572796
step: 280, loss: 0.0612201988697052
step: 290, loss: 0.020923210307955742
step: 300, loss: 0.053442392498254776
step: 310, loss: 0.0380452461540699
step: 320, loss: 0.1374617964029312
step: 330, loss: 0.19192177057266235
step: 340, loss: 0.0714261531829834
step: 350, loss: 0.04280518367886543
step: 360, loss: 0.1798098087310791
epoch 19: dev_f1=0.7135416666666666, f1=0.7253333333333334, best_f1=0.7350835322195705
step: 0, loss: 0.002785374177619815
step: 10, loss: 3.2036667107604444e-05
step: 20, loss: 0.04174163565039635
step: 30, loss: 0.05269099026918411
step: 40, loss: 0.09523481875658035
step: 50, loss: 0.044771358370780945
step: 60, loss: 0.08720404654741287
step: 70, loss: 0.06084294617176056
step: 80, loss: 0.06501033157110214
step: 90, loss: 0.03100327029824257
step: 100, loss: 0.043283551931381226
step: 110, loss: 0.010122066363692284
step: 120, loss: 4.83703515783418e-05
step: 130, loss: 0.13743934035301208
step: 140, loss: 0.06837447732686996
step: 150, loss: 0.12062855064868927
step: 160, loss: 0.027701374143362045
step: 170, loss: 0.016272880136966705
step: 180, loss: 0.046892520040273666
step: 190, loss: 0.001858569448813796
step: 200, loss: 9.446629701415077e-05
step: 210, loss: 0.004326262511312962
step: 220, loss: 0.011345762759447098
step: 230, loss: 0.03149724751710892
step: 240, loss: 0.0007958831265568733
step: 250, loss: 0.010709983296692371
step: 260, loss: 0.00029002418159507215
step: 270, loss: 0.020916003733873367
step: 280, loss: 0.08939561992883682
step: 290, loss: 0.014435680583119392
step: 300, loss: 0.007339580915868282
step: 310, loss: 0.04752453416585922
step: 320, loss: 0.03518347069621086
step: 330, loss: 0.013006330467760563
step: 340, loss: 0.03877781704068184
step: 350, loss: 0.017571143805980682
step: 360, loss: 0.0007526195258833468
epoch 20: dev_f1=0.7108753315649867, f1=0.7262872628726287, best_f1=0.7350835322195705
