cuda
Device: cuda
step: 0, loss: 0.6343315243721008
step: 10, loss: 0.4272342324256897
step: 20, loss: 0.09232333302497864
step: 30, loss: 0.02652401104569435
step: 40, loss: 0.23278912901878357
step: 50, loss: 0.033409975469112396
step: 60, loss: 0.13359016180038452
step: 70, loss: 0.07940535247325897
step: 80, loss: 0.08917316794395447
step: 90, loss: 0.030212610960006714
step: 100, loss: 0.35042130947113037
step: 110, loss: 0.38532668352127075
step: 120, loss: 0.21937216818332672
step: 130, loss: 0.21774530410766602
step: 140, loss: 0.02389083057641983
step: 150, loss: 0.04583112895488739
step: 160, loss: 0.38657161593437195
step: 170, loss: 0.16612717509269714
step: 180, loss: 0.2724955677986145
step: 190, loss: 0.30762702226638794
step: 200, loss: 0.19538605213165283
step: 210, loss: 0.04617941007018089
step: 220, loss: 0.10176443308591843
step: 230, loss: 0.11510776728391647
step: 240, loss: 0.0516011081635952
step: 250, loss: 0.05911940708756447
step: 260, loss: 0.13703705370426178
step: 270, loss: 0.2988091707229614
step: 280, loss: 0.05868230760097504
step: 290, loss: 0.06585722416639328
step: 300, loss: 0.10832615941762924
step: 310, loss: 0.16283667087554932
step: 320, loss: 0.13997754454612732
step: 330, loss: 0.08540409058332443
step: 340, loss: 0.01001018937677145
step: 350, loss: 0.09102487564086914
step: 360, loss: 0.07081934064626694
epoch 1: dev_f1=0.6246851385390427, f1=0.6173469387755103, best_f1=0.6173469387755103
step: 0, loss: 0.08740628510713577
step: 10, loss: 0.16896355152130127
step: 20, loss: 0.06354952603578568
step: 30, loss: 0.09860905259847641
step: 40, loss: 0.057859327644109726
step: 50, loss: 0.12094201147556305
step: 60, loss: 0.35544946789741516
step: 70, loss: 0.2769726812839508
step: 80, loss: 0.11104360967874527
step: 90, loss: 0.14984799921512604
step: 100, loss: 0.058588359504938126
step: 110, loss: 0.15523116290569305
step: 120, loss: 0.15871012210845947
step: 130, loss: 0.1496678739786148
step: 140, loss: 0.034719858318567276
step: 150, loss: 0.09575023502111435
step: 160, loss: 0.15488310158252716
step: 170, loss: 0.2033633589744568
step: 180, loss: 0.16749413311481476
step: 190, loss: 0.10614841431379318
step: 200, loss: 0.1806173324584961
step: 210, loss: 0.059313129633665085
step: 220, loss: 0.027678659185767174
step: 230, loss: 0.15699222683906555
step: 240, loss: 0.30457404255867004
step: 250, loss: 0.1003982350230217
step: 260, loss: 0.08479488641023636
step: 270, loss: 0.19158074259757996
step: 280, loss: 0.16600286960601807
step: 290, loss: 0.22408416867256165
step: 300, loss: 0.04991809278726578
step: 310, loss: 0.1275467872619629
step: 320, loss: 0.08391920477151871
step: 330, loss: 0.07797384262084961
step: 340, loss: 0.04581821709871292
step: 350, loss: 0.1769224852323532
step: 360, loss: 0.0358843132853508
epoch 2: dev_f1=0.6818181818181819, f1=0.6917960088691796, best_f1=0.6917960088691796
step: 0, loss: 0.020634949207305908
step: 10, loss: 0.01843331940472126
step: 20, loss: 0.09456150233745575
step: 30, loss: 0.04616587609052658
step: 40, loss: 0.03178054094314575
step: 50, loss: 0.11983819305896759
step: 60, loss: 0.08267056196928024
step: 70, loss: 0.2697574198246002
step: 80, loss: 0.06225237622857094
step: 90, loss: 0.16366370022296906
step: 100, loss: 0.1296098828315735
step: 110, loss: 0.12418343126773834
step: 120, loss: 0.07019937038421631
step: 130, loss: 0.09758907556533813
step: 140, loss: 0.0834255963563919
step: 150, loss: 0.11939077824354172
step: 160, loss: 0.22650955617427826
step: 170, loss: 0.07490856200456619
step: 180, loss: 0.12728740274906158
step: 190, loss: 0.09491924941539764
step: 200, loss: 0.08695341646671295
step: 210, loss: 0.12861867249011993
step: 220, loss: 0.23302370309829712
step: 230, loss: 0.1267271637916565
step: 240, loss: 0.03887908160686493
step: 250, loss: 0.0457736998796463
step: 260, loss: 0.13764624297618866
step: 270, loss: 0.11480272561311722
step: 280, loss: 0.1379009485244751
step: 290, loss: 0.1808355450630188
step: 300, loss: 0.09639986604452133
step: 310, loss: 0.07883641868829727
step: 320, loss: 0.022326573729515076
step: 330, loss: 0.08360099047422409
step: 340, loss: 0.13312602043151855
step: 350, loss: 0.3125697076320648
step: 360, loss: 0.06185310706496239
epoch 3: dev_f1=0.6713947990543735, f1=0.6760563380281691, best_f1=0.6917960088691796
step: 0, loss: 0.039668768644332886
step: 10, loss: 0.07600568979978561
step: 20, loss: 0.08951634913682938
step: 30, loss: 0.2316516637802124
step: 40, loss: 0.11058725416660309
step: 50, loss: 0.031737249344587326
step: 60, loss: 0.15084359049797058
step: 70, loss: 0.025972997769713402
step: 80, loss: 0.14098019897937775
step: 90, loss: 0.0697803869843483
step: 100, loss: 0.0977330356836319
step: 110, loss: 0.10445068776607513
step: 120, loss: 0.11852974444627762
step: 130, loss: 0.04710023105144501
step: 140, loss: 0.129959374666214
step: 150, loss: 0.05326319858431816
step: 160, loss: 0.20937249064445496
step: 170, loss: 0.1340072900056839
step: 180, loss: 0.15600991249084473
step: 190, loss: 0.11205408722162247
step: 200, loss: 0.22651520371437073
step: 210, loss: 0.1173257902264595
step: 220, loss: 0.0877956748008728
step: 230, loss: 0.17544123530387878
step: 240, loss: 0.013023502193391323
step: 250, loss: 0.10365228354930878
step: 260, loss: 0.057226017117500305
step: 270, loss: 0.06880588084459305
step: 280, loss: 0.12580420076847076
step: 290, loss: 0.09752364456653595
step: 300, loss: 0.06634517014026642
step: 310, loss: 0.15528735518455505
step: 320, loss: 0.05650556832551956
step: 330, loss: 0.15507730841636658
step: 340, loss: 0.2047966569662094
step: 350, loss: 0.09005764126777649
step: 360, loss: 0.11676616966724396
epoch 4: dev_f1=0.7019498607242339, f1=0.7005347593582888, best_f1=0.7005347593582888
step: 0, loss: 0.09089331328868866
step: 10, loss: 0.06857966631650925
step: 20, loss: 0.04245055839419365
step: 30, loss: 0.032165512442588806
step: 40, loss: 0.09684055298566818
step: 50, loss: 0.13198377192020416
step: 60, loss: 0.20396289229393005
step: 70, loss: 0.09528140723705292
step: 80, loss: 0.10675468295812607
step: 90, loss: 0.0990900844335556
step: 100, loss: 0.09915072470903397
step: 110, loss: 0.09035397320985794
step: 120, loss: 0.14885082840919495
step: 130, loss: 0.0885501280426979
step: 140, loss: 0.10091783851385117
step: 150, loss: 0.07634025067090988
step: 160, loss: 0.02945130318403244
step: 170, loss: 0.08169141411781311
step: 180, loss: 0.019905144348740578
step: 190, loss: 0.049264777451753616
step: 200, loss: 0.05704545974731445
step: 210, loss: 0.037407662719488144
step: 220, loss: 0.1606907993555069
step: 230, loss: 0.10877183079719543
step: 240, loss: 0.07094373553991318
step: 250, loss: 0.03893163800239563
step: 260, loss: 0.06700188666582108
step: 270, loss: 0.004593174438923597
step: 280, loss: 0.11586029827594757
step: 290, loss: 0.15691863000392914
step: 300, loss: 0.09567662328481674
step: 310, loss: 0.1967780590057373
step: 320, loss: 0.07108204066753387
step: 330, loss: 0.0450272262096405
step: 340, loss: 0.11818217486143112
step: 350, loss: 0.09753580391407013
step: 360, loss: 0.26945260167121887
epoch 5: dev_f1=0.7474747474747474, f1=0.7281553398058251, best_f1=0.7281553398058251
step: 0, loss: 0.04193459451198578
step: 10, loss: 0.07771607488393784
step: 20, loss: 0.14896081387996674
step: 30, loss: 0.04860714077949524
step: 40, loss: 0.05237780883908272
step: 50, loss: 0.050056371837854385
step: 60, loss: 0.0017098417738452554
step: 70, loss: 0.11485366523265839
step: 80, loss: 0.0645841583609581
step: 90, loss: 0.0705290362238884
step: 100, loss: 0.05181121453642845
step: 110, loss: 0.08186905086040497
step: 120, loss: 0.0673854723572731
step: 130, loss: 0.10591161251068115
step: 140, loss: 0.07043135166168213
step: 150, loss: 0.06180863827466965
step: 160, loss: 0.017219968140125275
step: 170, loss: 0.0663873553276062
step: 180, loss: 0.1002272367477417
step: 190, loss: 0.09177441149950027
step: 200, loss: 0.1502794772386551
step: 210, loss: 0.05762447044253349
step: 220, loss: 0.03223118931055069
step: 230, loss: 0.09844525158405304
step: 240, loss: 0.0701332688331604
step: 250, loss: 0.05747562646865845
step: 260, loss: 0.07493800669908524
step: 270, loss: 0.04665325954556465
step: 280, loss: 0.04325418546795845
step: 290, loss: 0.0666724443435669
step: 300, loss: 0.11445644497871399
step: 310, loss: 0.13390634953975677
step: 320, loss: 0.2167491763830185
step: 330, loss: 0.12695549428462982
step: 340, loss: 0.1751127690076828
step: 350, loss: 0.024269945919513702
step: 360, loss: 0.08041325956583023
epoch 6: dev_f1=0.7061611374407583, f1=0.7107843137254902, best_f1=0.7281553398058251
step: 0, loss: 0.040011998265981674
step: 10, loss: 0.0403110645711422
step: 20, loss: 0.07567033171653748
step: 30, loss: 0.10549710690975189
step: 40, loss: 0.05064056068658829
step: 50, loss: 0.09166562557220459
step: 60, loss: 0.07608061283826828
step: 70, loss: 0.11276944726705551
step: 80, loss: 0.10944119095802307
step: 90, loss: 0.08611822128295898
step: 100, loss: 0.03324669972062111
step: 110, loss: 0.07210826873779297
step: 120, loss: 0.0650639533996582
step: 130, loss: 0.07948233187198639
step: 140, loss: 0.03609296306967735
step: 150, loss: 0.004679677076637745
step: 160, loss: 0.09410953521728516
step: 170, loss: 0.13292351365089417
step: 180, loss: 0.10668659210205078
step: 190, loss: 0.11525021493434906
step: 200, loss: 0.021419374272227287
step: 210, loss: 0.07096737623214722
step: 220, loss: 0.035526905208826065
step: 230, loss: 0.11071823537349701
step: 240, loss: 0.04025159403681755
step: 250, loss: 0.04389999806880951
step: 260, loss: 0.22950394451618195
step: 270, loss: 0.17993468046188354
step: 280, loss: 0.06605947762727737
step: 290, loss: 0.10989642143249512
step: 300, loss: 0.09164762496948242
step: 310, loss: 0.14705079793930054
step: 320, loss: 0.04915184527635574
step: 330, loss: 0.034030649811029434
step: 340, loss: 0.037588827311992645
step: 350, loss: 0.049056243151426315
step: 360, loss: 0.0930592268705368
epoch 7: dev_f1=0.6893203883495145, f1=0.7087378640776699, best_f1=0.7281553398058251
step: 0, loss: 0.015955446287989616
step: 10, loss: 0.06324247270822525
step: 20, loss: 0.09217214584350586
step: 30, loss: 0.06304585933685303
step: 40, loss: 0.09331058710813522
step: 50, loss: 0.07537964731454849
step: 60, loss: 0.037457358092069626
step: 70, loss: 0.02246166206896305
step: 80, loss: 0.09334389120340347
step: 90, loss: 0.05174783989787102
step: 100, loss: 0.09203051030635834
step: 110, loss: 0.09435942769050598
step: 120, loss: 0.03942697495222092
step: 130, loss: 0.08840494602918625
step: 140, loss: 0.07620257139205933
step: 150, loss: 0.04862980917096138
step: 160, loss: 0.005601608194410801
step: 170, loss: 0.049207862466573715
step: 180, loss: 0.014869565144181252
step: 190, loss: 0.0223656315356493
step: 200, loss: 0.031005429103970528
step: 210, loss: 0.06733536720275879
step: 220, loss: 0.058489955961704254
step: 230, loss: 0.21489232778549194
step: 240, loss: 0.1022239625453949
step: 250, loss: 0.08653119206428528
step: 260, loss: 0.0996202677488327
step: 270, loss: 0.010884598828852177
step: 280, loss: 0.07695791870355606
step: 290, loss: 0.09696011990308762
step: 300, loss: 0.032621610909700394
step: 310, loss: 0.029559675604104996
step: 320, loss: 0.029775269329547882
step: 330, loss: 0.032010432332754135
step: 340, loss: 0.11182674020528793
step: 350, loss: 0.018616987392306328
step: 360, loss: 0.05365082249045372
epoch 8: dev_f1=0.7272727272727273, f1=0.7241379310344828, best_f1=0.7281553398058251
step: 0, loss: 0.11809638887643814
step: 10, loss: 0.056236911565065384
step: 20, loss: 0.0813576802611351
step: 30, loss: 0.09040001779794693
step: 40, loss: 0.058958739042282104
step: 50, loss: 0.02471739612519741
step: 60, loss: 0.28798040747642517
step: 70, loss: 0.056130923330783844
step: 80, loss: 0.04178691655397415
step: 90, loss: 0.0001352610270259902
step: 100, loss: 0.07600126415491104
step: 110, loss: 0.04099256172776222
step: 120, loss: 0.045726995915174484
step: 130, loss: 0.1252467781305313
step: 140, loss: 0.11744684725999832
step: 150, loss: 0.021749090403318405
step: 160, loss: 0.04068842530250549
step: 170, loss: 0.016559040173888206
step: 180, loss: 0.09182438999414444
step: 190, loss: 0.08086980879306793
step: 200, loss: 0.018236681818962097
step: 210, loss: 0.06936255097389221
step: 220, loss: 0.06522747874259949
step: 230, loss: 0.03972665220499039
step: 240, loss: 0.021372979506850243
step: 250, loss: 0.06883715093135834
step: 260, loss: 0.07269830256700516
step: 270, loss: 0.10751819610595703
step: 280, loss: 0.05694818124175072
step: 290, loss: 0.07924878597259521
step: 300, loss: 0.030290596187114716
step: 310, loss: 0.22736260294914246
step: 320, loss: 0.09606242924928665
step: 330, loss: 0.037834424525499344
step: 340, loss: 0.02189715951681137
step: 350, loss: 0.058532603085041046
step: 360, loss: 0.08214419335126877
epoch 9: dev_f1=0.7373493975903614, f1=0.712871287128713, best_f1=0.7281553398058251
step: 0, loss: 0.06424479931592941
step: 10, loss: 0.06275975704193115
step: 20, loss: 0.04302612319588661
step: 30, loss: 0.03642341122031212
step: 40, loss: 0.08339998871088028
step: 50, loss: 0.1375989317893982
step: 60, loss: 0.05051339417695999
step: 70, loss: 0.059152234345674515
step: 80, loss: 0.04072144255042076
step: 90, loss: 0.11416588723659515
step: 100, loss: 0.0814846009016037
step: 110, loss: 0.08371314406394958
step: 120, loss: 0.09507228434085846
step: 130, loss: 0.10759489983320236
step: 140, loss: 0.07879741489887238
step: 150, loss: 0.08174372464418411
step: 160, loss: 0.010298222303390503
step: 170, loss: 0.06827735155820847
step: 180, loss: 0.05725625157356262
step: 190, loss: 0.04400579631328583
step: 200, loss: 0.08534570038318634
step: 210, loss: 0.016527535393834114
step: 220, loss: 0.06953657418489456
step: 230, loss: 0.14039766788482666
step: 240, loss: 0.10597240924835205
step: 250, loss: 0.06034266576170921
step: 260, loss: 0.03482252359390259
step: 270, loss: 0.05327748879790306
step: 280, loss: 0.07536634802818298
step: 290, loss: 0.017082110047340393
step: 300, loss: 0.03923288732767105
step: 310, loss: 0.08506008982658386
step: 320, loss: 0.06891386210918427
step: 330, loss: 0.11736796796321869
step: 340, loss: 0.07043152302503586
step: 350, loss: 0.06765919178724289
step: 360, loss: 0.04959399253129959
epoch 10: dev_f1=0.7312348668280872, f1=0.7184466019417476, best_f1=0.7281553398058251
step: 0, loss: 0.0593804307281971
step: 10, loss: 0.02674221619963646
step: 20, loss: 0.00013346484047360718
step: 30, loss: 0.03769485279917717
step: 40, loss: 0.048208221793174744
step: 50, loss: 0.07628471404314041
step: 60, loss: 0.04608922079205513
step: 70, loss: 0.01261455100029707
step: 80, loss: 0.04143267869949341
step: 90, loss: 0.03244456276297569
step: 100, loss: 0.03279512748122215
step: 110, loss: 0.18861012160778046
step: 120, loss: 0.008260606788098812
step: 130, loss: 0.08631633967161179
step: 140, loss: 0.04580799117684364
step: 150, loss: 0.043287813663482666
step: 160, loss: 0.0006504955235868692
step: 170, loss: 0.0741100013256073
step: 180, loss: 0.01984519325196743
step: 190, loss: 0.05404869094491005
step: 200, loss: 0.04839770495891571
step: 210, loss: 0.10804587602615356
step: 220, loss: 0.11071228981018066
step: 230, loss: 0.057291485369205475
step: 240, loss: 0.07122538238763809
step: 250, loss: 0.08829664438962936
step: 260, loss: 0.08234942704439163
step: 270, loss: 0.0007999301888048649
step: 280, loss: 0.03259654715657234
step: 290, loss: 0.06876376271247864
step: 300, loss: 0.033995840698480606
step: 310, loss: 0.033245012164115906
step: 320, loss: 0.02719487063586712
step: 330, loss: 0.04532988741993904
step: 340, loss: 0.11410976201295853
step: 350, loss: 0.00996262114495039
step: 360, loss: 0.078734390437603
epoch 11: dev_f1=0.722077922077922, f1=0.7263157894736842, best_f1=0.7281553398058251
step: 0, loss: 0.07829595357179642
step: 10, loss: 0.10517647117376328
step: 20, loss: 0.04464007541537285
step: 30, loss: 0.01582341268658638
step: 40, loss: 0.05256408452987671
step: 50, loss: 0.08393819630146027
step: 60, loss: 0.038358964025974274
step: 70, loss: 0.09751173853874207
step: 80, loss: 0.10243432223796844
step: 90, loss: 0.10068918019533157
step: 100, loss: 0.027897201478481293
step: 110, loss: 0.0005441035027615726
step: 120, loss: 0.11196000128984451
step: 130, loss: 0.024050965905189514
step: 140, loss: 0.021518966183066368
step: 150, loss: 0.11484424024820328
step: 160, loss: 0.011920304968953133
step: 170, loss: 0.062162846326828
step: 180, loss: 0.06031879782676697
step: 190, loss: 0.06243295967578888
step: 200, loss: 0.05351529270410538
step: 210, loss: 0.04114197567105293
step: 220, loss: 0.05164363980293274
step: 230, loss: 0.06811536848545074
step: 240, loss: 0.117587611079216
step: 250, loss: 0.15597261488437653
step: 260, loss: 0.07164361327886581
step: 270, loss: 0.022268030792474747
step: 280, loss: 0.12952065467834473
step: 290, loss: 0.068582683801651
step: 300, loss: 0.04809711501002312
step: 310, loss: 0.05585876852273941
step: 320, loss: 0.06636489182710648
step: 330, loss: 0.05917252600193024
step: 340, loss: 0.08755138516426086
step: 350, loss: 0.05027056857943535
step: 360, loss: 0.08966370671987534
epoch 12: dev_f1=0.7352941176470589, f1=0.7444168734491315, best_f1=0.7281553398058251
step: 0, loss: 0.061019416898489
step: 10, loss: 0.09559010714292526
step: 20, loss: 0.004260722082108259
step: 30, loss: 0.0345350056886673
step: 40, loss: 0.05271577835083008
step: 50, loss: 0.1851159781217575
step: 60, loss: 0.07841286808252335
step: 70, loss: 0.09484262764453888
step: 80, loss: 0.05827141925692558
step: 90, loss: 0.0820322036743164
step: 100, loss: 0.0017374438466504216
step: 110, loss: 0.002793842926621437
step: 120, loss: 0.005700162146240473
step: 130, loss: 0.0001285126490984112
step: 140, loss: 0.08442262560129166
step: 150, loss: 0.13672727346420288
step: 160, loss: 0.22682373225688934
step: 170, loss: 0.05380506440997124
step: 180, loss: 0.10492899268865585
step: 190, loss: 0.036916956305503845
step: 200, loss: 0.10469648987054825
step: 210, loss: 0.09366630017757416
step: 220, loss: 0.03866804391145706
step: 230, loss: 0.045652005821466446
step: 240, loss: 0.08537987619638443
step: 250, loss: 0.001226672437041998
step: 260, loss: 0.007541682105511427
step: 270, loss: 0.06263739615678787
step: 280, loss: 0.07887518405914307
step: 290, loss: 0.0834098532795906
step: 300, loss: 0.017273427918553352
step: 310, loss: 0.05339968204498291
step: 320, loss: 0.0832623615860939
step: 330, loss: 0.05329529196023941
step: 340, loss: 0.05639217421412468
step: 350, loss: 0.018972458317875862
step: 360, loss: 0.024053514003753662
epoch 13: dev_f1=0.7205542725173208, f1=0.7031963470319634, best_f1=0.7281553398058251
step: 0, loss: 0.01715998537838459
step: 10, loss: 0.053768400102853775
step: 20, loss: 0.016677258536219597
step: 30, loss: 0.11402612179517746
step: 40, loss: 0.03629462420940399
step: 50, loss: 0.011595332063734531
step: 60, loss: 0.003196198493242264
step: 70, loss: 0.00998103991150856
step: 80, loss: 0.05998256802558899
step: 90, loss: 0.022455578669905663
step: 100, loss: 0.07496335357427597
step: 110, loss: 0.01310076005756855
step: 120, loss: 0.045225683599710464
step: 130, loss: 0.07457857578992844
step: 140, loss: 0.03424091264605522
step: 150, loss: 0.03609253093600273
step: 160, loss: 0.045200079679489136
step: 170, loss: 0.018502162769436836
step: 180, loss: 0.026411518454551697
step: 190, loss: 0.028107520192861557
step: 200, loss: 0.09364815056324005
step: 210, loss: 0.05210166424512863
step: 220, loss: 0.030315203592181206
step: 230, loss: 0.039847273379564285
step: 240, loss: 3.301665492472239e-05
step: 250, loss: 0.021712614223361015
step: 260, loss: 0.01237097941339016
step: 270, loss: 0.007494938559830189
step: 280, loss: 0.0402698889374733
step: 290, loss: 0.012761211022734642
step: 300, loss: 0.1165430098772049
step: 310, loss: 0.05907236412167549
step: 320, loss: 0.08709058910608292
step: 330, loss: 0.020971626043319702
step: 340, loss: 0.0022129942663013935
step: 350, loss: 0.0006351026822812855
step: 360, loss: 0.04369805008172989
epoch 14: dev_f1=0.7105263157894737, f1=0.7049608355091384, best_f1=0.7281553398058251
step: 0, loss: 0.011889798566699028
step: 10, loss: 0.033915553241968155
step: 20, loss: 0.04356410726904869
step: 30, loss: 0.08161838352680206
step: 40, loss: 0.02207881771028042
step: 50, loss: 0.04480775445699692
step: 60, loss: 0.045039478689432144
step: 70, loss: 0.026748543605208397
step: 80, loss: 0.006064754445105791
step: 90, loss: 0.01153753511607647
step: 100, loss: 0.08208787441253662
step: 110, loss: 0.042277611792087555
step: 120, loss: 0.05112919583916664
step: 130, loss: 0.11242379993200302
step: 140, loss: 0.025380855426192284
step: 150, loss: 0.1188657209277153
step: 160, loss: 0.08183741569519043
step: 170, loss: 0.03078419715166092
step: 180, loss: 0.037016671150922775
step: 190, loss: 0.00083758874097839
step: 200, loss: 0.09884306788444519
step: 210, loss: 0.07395549863576889
step: 220, loss: 0.06917811930179596
step: 230, loss: 0.022825967520475388
step: 240, loss: 0.11745401471853256
step: 250, loss: 0.03949456661939621
step: 260, loss: 0.042331892997026443
step: 270, loss: 0.0933077335357666
step: 280, loss: 0.04161042347550392
step: 290, loss: 0.00045111263170838356
step: 300, loss: 0.05259418487548828
step: 310, loss: 0.056244898587465286
step: 320, loss: 0.01690467819571495
step: 330, loss: 0.06609086692333221
step: 340, loss: 0.12014365196228027
step: 350, loss: 0.00041055912151932716
step: 360, loss: 0.03441477566957474
epoch 15: dev_f1=0.6929133858267716, f1=0.707774798927614, best_f1=0.7281553398058251
step: 0, loss: 0.031914714723825455
step: 10, loss: 0.002945791697129607
step: 20, loss: 0.0007703967276029289
step: 30, loss: 0.008599105291068554
step: 40, loss: 0.021787572652101517
step: 50, loss: 0.01159189734607935
step: 60, loss: 0.010398426093161106
step: 70, loss: 0.0018627374665811658
step: 80, loss: 4.652041388908401e-05
step: 90, loss: 0.03208637610077858
step: 100, loss: 0.012437361292541027
step: 110, loss: 0.004607028793543577
step: 120, loss: 0.05952794849872589
step: 130, loss: 0.07455383986234665
step: 140, loss: 0.02579445205628872
step: 150, loss: 0.014953792095184326
step: 160, loss: 0.11134355515241623
step: 170, loss: 0.0005119126872159541
step: 180, loss: 0.03888217732310295
step: 190, loss: 0.04684339091181755
step: 200, loss: 0.09011897444725037
step: 210, loss: 0.026813311502337456
step: 220, loss: 0.023720456287264824
step: 230, loss: 0.04012759029865265
step: 240, loss: 0.002703032223507762
step: 250, loss: 0.058653831481933594
step: 260, loss: 0.026660988107323647
step: 270, loss: 0.12564197182655334
step: 280, loss: 0.018191881477832794
step: 290, loss: 0.03527000918984413
step: 300, loss: 0.13687552511692047
step: 310, loss: 0.011909743770956993
step: 320, loss: 0.04859365150332451
step: 330, loss: 0.003491354174911976
step: 340, loss: 0.038693223148584366
step: 350, loss: 0.07057810574769974
step: 360, loss: 0.02641969919204712
epoch 16: dev_f1=0.7189873417721518, f1=0.7037974683544304, best_f1=0.7281553398058251
step: 0, loss: 0.04613351449370384
step: 10, loss: 0.043946169316768646
step: 20, loss: 0.046728525310754776
step: 30, loss: 0.020008714869618416
step: 40, loss: 0.035148270428180695
step: 50, loss: 0.11863807588815689
step: 60, loss: 0.010284975171089172
step: 70, loss: 3.835784809780307e-05
step: 80, loss: 0.17992764711380005
step: 90, loss: 0.10279643535614014
step: 100, loss: 0.11866939812898636
step: 110, loss: 0.028982622548937798
step: 120, loss: 0.03096655383706093
step: 130, loss: 0.05112982541322708
step: 140, loss: 0.015781458467245102
step: 150, loss: 0.01571018621325493
step: 160, loss: 0.02271212637424469
step: 170, loss: 0.03934387490153313
step: 180, loss: 0.04736866056919098
step: 190, loss: 0.0007502139778807759
step: 200, loss: 0.034865424036979675
step: 210, loss: 0.061099279671907425
step: 220, loss: 0.11858589947223663
step: 230, loss: 0.02067328244447708
step: 240, loss: 0.0059908716939389706
step: 250, loss: 0.012234216555953026
step: 260, loss: 0.031187690794467926
step: 270, loss: 0.014219442382454872
step: 280, loss: 2.8427197321434505e-05
step: 290, loss: 0.008231954649090767
step: 300, loss: 0.06749095767736435
step: 310, loss: 0.04544087499380112
step: 320, loss: 0.04050586000084877
step: 330, loss: 0.06268910318613052
step: 340, loss: 0.0004546151321846992
step: 350, loss: 0.06433574855327606
step: 360, loss: 0.1471332162618637
epoch 17: dev_f1=0.717557251908397, f1=0.6938775510204082, best_f1=0.7281553398058251
step: 0, loss: 0.012898807413876057
step: 10, loss: 0.0038110781461000443
step: 20, loss: 0.00020581699209287763
step: 30, loss: 0.0736379399895668
step: 40, loss: 0.05602441728115082
step: 50, loss: 0.037523411214351654
step: 60, loss: 0.000188521618838422
step: 70, loss: 0.05397704243659973
step: 80, loss: 0.0242451298981905
step: 90, loss: 0.015607945621013641
step: 100, loss: 0.00014136241225060076
step: 110, loss: 0.04312988743185997
step: 120, loss: 0.04673511162400246
step: 130, loss: 0.003868533531203866
step: 140, loss: 0.18489155173301697
step: 150, loss: 0.04874485358595848
step: 160, loss: 0.02176194079220295
step: 170, loss: 0.012740512378513813
step: 180, loss: 0.08296489715576172
step: 190, loss: 0.01902134157717228
step: 200, loss: 0.07061686366796494
step: 210, loss: 0.0009405952296219766
step: 220, loss: 0.01410962175577879
step: 230, loss: 0.11707116663455963
step: 240, loss: 0.010107506066560745
step: 250, loss: 0.011149631813168526
step: 260, loss: 0.03620805963873863
step: 270, loss: 0.06837005913257599
step: 280, loss: 0.07486725598573685
step: 290, loss: 0.0792233794927597
step: 300, loss: 0.07232541590929031
step: 310, loss: 0.0504949577152729
step: 320, loss: 0.09788188338279724
step: 330, loss: 0.05075667053461075
step: 340, loss: 0.00020194152602925897
step: 350, loss: 0.07697444409132004
step: 360, loss: 0.09204407781362534
epoch 18: dev_f1=0.7192118226600984, f1=0.7213930348258706, best_f1=0.7281553398058251
step: 0, loss: 0.013771776109933853
step: 10, loss: 0.06671582162380219
step: 20, loss: 0.07642771303653717
step: 30, loss: 0.029664726927876472
step: 40, loss: 0.05045830458402634
step: 50, loss: 0.042925987392663956
step: 60, loss: 0.0010834838030859828
step: 70, loss: 0.0017430889420211315
step: 80, loss: 0.12303775548934937
step: 90, loss: 0.07646217942237854
step: 100, loss: 0.05083603784441948
step: 110, loss: 0.014468465931713581
step: 120, loss: 0.04605551064014435
step: 130, loss: 0.07458697259426117
step: 140, loss: 0.0006883021560497582
step: 150, loss: 0.010301363654434681
step: 160, loss: 0.008984699845314026
step: 170, loss: 0.08145790547132492
step: 180, loss: 0.11449061334133148
step: 190, loss: 0.029478391632437706
step: 200, loss: 0.015286929905414581
step: 210, loss: 0.004391250666230917
step: 220, loss: 0.01888657733798027
step: 230, loss: 0.0181867852807045
step: 240, loss: 0.0007051766151562333
step: 250, loss: 0.00045140774454921484
step: 260, loss: 0.020206263288855553
step: 270, loss: 0.02780097909271717
step: 280, loss: 0.06359875202178955
step: 290, loss: 0.014618935063481331
step: 300, loss: 0.05868064984679222
step: 310, loss: 0.006950116250663996
step: 320, loss: 0.006929073482751846
step: 330, loss: 0.03862639144062996
step: 340, loss: 0.029766421765089035
step: 350, loss: 0.012706474401056767
step: 360, loss: 0.00010562397801550105
epoch 19: dev_f1=0.7253333333333334, f1=0.7253333333333334, best_f1=0.7281553398058251
step: 0, loss: 0.08300147205591202
step: 10, loss: 0.037291258573532104
step: 20, loss: 0.014917174354195595
step: 30, loss: 0.008410090580582619
step: 40, loss: 0.016248637810349464
step: 50, loss: 0.06894058734178543
step: 60, loss: 0.20413081347942352
step: 70, loss: 0.0015526898205280304
step: 80, loss: 0.030735081061720848
step: 90, loss: 0.002255490282550454
step: 100, loss: 0.021568430587649345
step: 110, loss: 0.09888879954814911
step: 120, loss: 0.04766959324479103
step: 130, loss: 0.028747886419296265
step: 140, loss: 0.02941514551639557
step: 150, loss: 0.050683192908763885
step: 160, loss: 0.041371747851371765
step: 170, loss: 0.08693394809961319
step: 180, loss: 0.001998659921810031
step: 190, loss: 0.02690654620528221
step: 200, loss: 0.01115391869097948
step: 210, loss: 0.032625824213027954
step: 220, loss: 0.08690904080867767
step: 230, loss: 0.023788947612047195
step: 240, loss: 0.001449665054678917
step: 250, loss: 0.050890836864709854
step: 260, loss: 0.04970718175172806
step: 270, loss: 0.048615794628858566
step: 280, loss: 0.00048052918282337487
step: 290, loss: 0.06719334423542023
step: 300, loss: 0.037825096398591995
step: 310, loss: 0.033556871116161346
step: 320, loss: 0.12339890748262405
step: 330, loss: 0.05639757588505745
step: 340, loss: 0.00876904372125864
step: 350, loss: 0.005027439445257187
step: 360, loss: 0.01810157671570778
epoch 20: dev_f1=0.7219251336898397, f1=0.7234042553191489, best_f1=0.7281553398058251
