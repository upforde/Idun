cuda
Device: cuda
step: 0, loss: 0.7130715250968933
step: 10, loss: 0.23605114221572876
step: 20, loss: 0.22598089277744293
step: 30, loss: 0.14973287284374237
step: 40, loss: 0.2343992292881012
step: 50, loss: 0.37021443247795105
step: 60, loss: 0.18250809609889984
step: 70, loss: 0.05827704071998596
step: 80, loss: 0.1472501903772354
step: 90, loss: 0.2569400668144226
step: 100, loss: 0.235769122838974
step: 110, loss: 0.24042733013629913
step: 120, loss: 0.23520533740520477
step: 130, loss: 0.33822232484817505
step: 140, loss: 0.14333732426166534
step: 150, loss: 0.15296955406665802
step: 160, loss: 0.2321959286928177
step: 170, loss: 0.14073446393013
step: 180, loss: 0.13650473952293396
step: 190, loss: 0.23356708884239197
step: 200, loss: 0.3131822943687439
step: 210, loss: 0.1500677466392517
step: 220, loss: 0.13914857804775238
step: 230, loss: 0.3393985629081726
step: 240, loss: 0.04616028815507889
step: 250, loss: 0.3957090377807617
step: 260, loss: 0.08435569703578949
step: 270, loss: 0.4176420569419861
step: 280, loss: 0.3190214931964874
step: 290, loss: 0.05981411412358284
step: 300, loss: 0.12702275812625885
step: 310, loss: 0.22601303458213806
step: 320, loss: 0.13120721280574799
step: 330, loss: 0.12552939355373383
step: 340, loss: 0.29604485630989075
step: 350, loss: 0.016903912648558617
step: 360, loss: 0.186726912856102
epoch 1: dev_f1=0.22493224932249323, f1=0.2274562584118439, best_f1=0.2274562584118439
step: 0, loss: 0.1784399151802063
step: 10, loss: 0.13084836304187775
step: 20, loss: 0.21173766255378723
step: 30, loss: 0.11657131463289261
step: 40, loss: 0.2918010950088501
step: 50, loss: 0.2026149034500122
step: 60, loss: 0.12499778717756271
step: 70, loss: 0.11484123021364212
step: 80, loss: 0.25619807839393616
step: 90, loss: 0.30909621715545654
step: 100, loss: 0.02050158567726612
step: 110, loss: 0.13452112674713135
step: 120, loss: 0.34726372361183167
step: 130, loss: 0.051367636770009995
step: 140, loss: 0.18625284731388092
step: 150, loss: 0.18910935521125793
step: 160, loss: 0.10179571807384491
step: 170, loss: 0.08750434219837189
step: 180, loss: 0.1459069848060608
step: 190, loss: 0.12034810334444046
step: 200, loss: 0.037308432161808014
step: 210, loss: 0.13607580959796906
step: 220, loss: 0.17429086565971375
step: 230, loss: 0.11150220781564713
step: 240, loss: 0.22916428744792938
step: 250, loss: 0.09401500970125198
step: 260, loss: 0.06421564519405365
step: 270, loss: 0.19018737971782684
step: 280, loss: 0.11368846893310547
step: 290, loss: 0.11054089665412903
step: 300, loss: 0.20797386765480042
step: 310, loss: 0.20543116331100464
step: 320, loss: 0.035593487322330475
step: 330, loss: 0.1225324422121048
step: 340, loss: 0.0852755606174469
step: 350, loss: 0.15221883356571198
step: 360, loss: 0.1400080919265747
epoch 2: dev_f1=0.6888888888888888, f1=0.6420454545454545, best_f1=0.6420454545454545
step: 0, loss: 0.10220643877983093
step: 10, loss: 0.11127213388681412
step: 20, loss: 0.28772595524787903
step: 30, loss: 0.22115497291088104
step: 40, loss: 0.13534046709537506
step: 50, loss: 0.12399814277887344
step: 60, loss: 0.18121616542339325
step: 70, loss: 0.18963825702667236
step: 80, loss: 0.09181389212608337
step: 90, loss: 0.22112879157066345
step: 100, loss: 0.19106639921665192
step: 110, loss: 0.2882976830005646
step: 120, loss: 0.16082856059074402
step: 130, loss: 0.05352773517370224
step: 140, loss: 0.0011160013964399695
step: 150, loss: 0.23044529557228088
step: 160, loss: 0.020676521584391594
step: 170, loss: 0.0730801597237587
step: 180, loss: 0.12742313742637634
step: 190, loss: 0.2072332352399826
step: 200, loss: 0.08601170778274536
step: 210, loss: 0.35876211524009705
step: 220, loss: 0.1628848910331726
step: 230, loss: 0.06892611086368561
step: 240, loss: 0.13478092849254608
step: 250, loss: 0.08847882598638535
step: 260, loss: 0.154622882604599
step: 270, loss: 0.21586120128631592
step: 280, loss: 0.07954268902540207
step: 290, loss: 0.2376425415277481
step: 300, loss: 0.05914544686675072
step: 310, loss: 0.10076950490474701
step: 320, loss: 0.1398785561323166
step: 330, loss: 0.2554660439491272
step: 340, loss: 0.081118643283844
step: 350, loss: 0.18004368245601654
step: 360, loss: 0.04647882655262947
epoch 3: dev_f1=0.7174447174447175, f1=0.7182044887780549, best_f1=0.7182044887780549
step: 0, loss: 0.012408286333084106
step: 10, loss: 0.10329323261976242
step: 20, loss: 0.06596244871616364
step: 30, loss: 0.23412947356700897
step: 40, loss: 0.09910084307193756
step: 50, loss: 0.0334799662232399
step: 60, loss: 0.2971058487892151
step: 70, loss: 0.02353687398135662
step: 80, loss: 0.15668395161628723
step: 90, loss: 0.06663796305656433
step: 100, loss: 0.09404080361127853
step: 110, loss: 0.04311302304267883
step: 120, loss: 0.02816486544907093
step: 130, loss: 0.1021488606929779
step: 140, loss: 0.059368498623371124
step: 150, loss: 0.10910087078809738
step: 160, loss: 0.14500409364700317
step: 170, loss: 0.08723270893096924
step: 180, loss: 0.03615916520357132
step: 190, loss: 0.01153106614947319
step: 200, loss: 0.07458938658237457
step: 210, loss: 0.059330206364393234
step: 220, loss: 0.19080282747745514
step: 230, loss: 0.18832704424858093
step: 240, loss: 0.103701651096344
step: 250, loss: 0.04502015560865402
step: 260, loss: 0.12526826560497284
step: 270, loss: 0.05869913473725319
step: 280, loss: 0.15439918637275696
step: 290, loss: 0.1580258160829544
step: 300, loss: 0.008308300748467445
step: 310, loss: 0.07909712195396423
step: 320, loss: 0.03748578950762749
step: 330, loss: 0.13286365568637848
step: 340, loss: 0.09699252247810364
step: 350, loss: 0.09229107201099396
step: 360, loss: 0.17614075541496277
epoch 4: dev_f1=0.7572815533980581, f1=0.6799007444168734, best_f1=0.6799007444168734
step: 0, loss: 0.1173158809542656
step: 10, loss: 0.16340135037899017
step: 20, loss: 0.08028487116098404
step: 30, loss: 0.10807012021541595
step: 40, loss: 0.13937921822071075
step: 50, loss: 0.045575130730867386
step: 60, loss: 0.10664817690849304
step: 70, loss: 0.1519680917263031
step: 80, loss: 0.14762543141841888
step: 90, loss: 0.017903173342347145
step: 100, loss: 0.1151173934340477
step: 110, loss: 0.05284806340932846
step: 120, loss: 0.07583127170801163
step: 130, loss: 0.04225217550992966
step: 140, loss: 0.03687899932265282
step: 150, loss: 0.13833525776863098
step: 160, loss: 0.13475458323955536
step: 170, loss: 0.04732614755630493
step: 180, loss: 0.1347043216228485
step: 190, loss: 0.1070624366402626
step: 200, loss: 0.1199815571308136
step: 210, loss: 0.23649396002292633
step: 220, loss: 0.07725602388381958
step: 230, loss: 0.08254340291023254
step: 240, loss: 0.06050628423690796
step: 250, loss: 0.1233845204114914
step: 260, loss: 0.12966559827327728
step: 270, loss: 0.07384337484836578
step: 280, loss: 0.17599652707576752
step: 290, loss: 0.15228329598903656
step: 300, loss: 0.07797696441411972
step: 310, loss: 0.1299002319574356
step: 320, loss: 0.017950354143977165
step: 330, loss: 0.2978786528110504
step: 340, loss: 0.07628705352544785
step: 350, loss: 0.04268046095967293
step: 360, loss: 0.08739490807056427
epoch 5: dev_f1=0.7438423645320198, f1=0.656934306569343, best_f1=0.6799007444168734
step: 0, loss: 0.06857383251190186
step: 10, loss: 0.1661805361509323
step: 20, loss: 0.07034460455179214
step: 30, loss: 0.09019725024700165
step: 40, loss: 0.11797123402357101
step: 50, loss: 0.09174559265375137
step: 60, loss: 0.09009801596403122
step: 70, loss: 0.13694769144058228
step: 80, loss: 0.06307747960090637
step: 90, loss: 0.09524158388376236
step: 100, loss: 0.10408339649438858
step: 110, loss: 0.1264355480670929
step: 120, loss: 0.12549245357513428
step: 130, loss: 0.21253782510757446
step: 140, loss: 0.11860824376344681
step: 150, loss: 0.004340523388236761
step: 160, loss: 0.08419372141361237
step: 170, loss: 0.04073072969913483
step: 180, loss: 0.11694663017988205
step: 190, loss: 0.10788698494434357
step: 200, loss: 0.08870705217123032
step: 210, loss: 0.07560011744499207
step: 220, loss: 0.06140455603599548
step: 230, loss: 0.09799817949533463
step: 240, loss: 0.12616947293281555
step: 250, loss: 0.026959165930747986
step: 260, loss: 0.10233981162309647
step: 270, loss: 0.058191440999507904
step: 280, loss: 0.31917399168014526
step: 290, loss: 0.04962705448269844
step: 300, loss: 0.12917333841323853
step: 310, loss: 0.09492336958646774
step: 320, loss: 0.08374350517988205
step: 330, loss: 0.09732531011104584
step: 340, loss: 0.07352029532194138
step: 350, loss: 0.1187797263264656
step: 360, loss: 0.1253448873758316
epoch 6: dev_f1=0.7611548556430445, f1=0.7087912087912088, best_f1=0.7087912087912088
step: 0, loss: 0.09601996839046478
step: 10, loss: 0.17964980006217957
step: 20, loss: 0.11593127995729446
step: 30, loss: 0.07064514607191086
step: 40, loss: 0.12851043045520782
step: 50, loss: 0.07335860282182693
step: 60, loss: 0.05503084883093834
step: 70, loss: 0.1326761692762375
step: 80, loss: 0.13075122237205505
step: 90, loss: 0.07280412316322327
step: 100, loss: 0.02504131756722927
step: 110, loss: 0.10769772529602051
step: 120, loss: 0.08375241607427597
step: 130, loss: 0.04855840280652046
step: 140, loss: 0.14263638854026794
step: 150, loss: 0.14577651023864746
step: 160, loss: 0.0016237880336120725
step: 170, loss: 0.02685811184346676
step: 180, loss: 0.031625524163246155
step: 190, loss: 0.060778550803661346
step: 200, loss: 0.0944494754076004
step: 210, loss: 0.07047191262245178
step: 220, loss: 0.020451758056879044
step: 230, loss: 0.11529243737459183
step: 240, loss: 0.08754214644432068
step: 250, loss: 0.004951037000864744
step: 260, loss: 0.04379282519221306
step: 270, loss: 0.1040726974606514
step: 280, loss: 0.12243849039077759
step: 290, loss: 0.06809011846780777
step: 300, loss: 0.07606959342956543
step: 310, loss: 0.07114634662866592
step: 320, loss: 0.07939232140779495
step: 330, loss: 0.16605082154273987
step: 340, loss: 0.15710051357746124
step: 350, loss: 0.08454281836748123
step: 360, loss: 0.10589982569217682
epoch 7: dev_f1=0.7428571428571429, f1=0.7016706443914081, best_f1=0.7087912087912088
step: 0, loss: 0.12203071266412735
step: 10, loss: 0.10412068665027618
step: 20, loss: 0.06909069418907166
step: 30, loss: 0.059584349393844604
step: 40, loss: 0.12119504809379578
step: 50, loss: 0.019910147413611412
step: 60, loss: 0.017103347927331924
step: 70, loss: 0.09231308102607727
step: 80, loss: 0.11733342707157135
step: 90, loss: 0.05331457033753395
step: 100, loss: 0.14485806226730347
step: 110, loss: 0.08527740836143494
step: 120, loss: 0.08270508795976639
step: 130, loss: 0.042228519916534424
step: 140, loss: 0.09850955009460449
step: 150, loss: 0.4524969756603241
step: 160, loss: 0.03912825882434845
step: 170, loss: 0.07007865607738495
step: 180, loss: 0.06243212893605232
step: 190, loss: 0.11226841807365417
step: 200, loss: 0.077002614736557
step: 210, loss: 0.11943890154361725
step: 220, loss: 0.03156829997897148
step: 230, loss: 0.032188545912504196
step: 240, loss: 0.09354185312986374
step: 250, loss: 0.09082010388374329
step: 260, loss: 0.05784619599580765
step: 270, loss: 0.08615169674158096
step: 280, loss: 0.05503769963979721
step: 290, loss: 0.05501265823841095
step: 300, loss: 0.019484682008624077
step: 310, loss: 0.1593310683965683
step: 320, loss: 0.018268009647727013
step: 330, loss: 0.036052972078323364
step: 340, loss: 0.029372112825512886
step: 350, loss: 0.059874147176742554
step: 360, loss: 0.00556781655177474
epoch 8: dev_f1=0.7301587301587302, f1=0.6738544474393531, best_f1=0.7087912087912088
step: 0, loss: 0.0669192299246788
step: 10, loss: 0.07540560513734818
step: 20, loss: 0.20090313255786896
step: 30, loss: 0.09829318523406982
step: 40, loss: 0.0599399097263813
step: 50, loss: 0.06224941834807396
step: 60, loss: 0.06271447241306305
step: 70, loss: 0.1638193279504776
step: 80, loss: 0.07280520349740982
step: 90, loss: 0.05758698284626007
step: 100, loss: 0.019728993996977806
step: 110, loss: 0.11570988595485687
step: 120, loss: 0.0724572241306305
step: 130, loss: 0.10305684059858322
step: 140, loss: 0.05252593383193016
step: 150, loss: 0.06728798151016235
step: 160, loss: 0.07556521892547607
step: 170, loss: 0.049045007675886154
step: 180, loss: 0.10121646523475647
step: 190, loss: 0.024200784042477608
step: 200, loss: 0.05603116378188133
step: 210, loss: 0.09455296397209167
step: 220, loss: 0.03445228189229965
step: 230, loss: 0.027419529855251312
step: 240, loss: 0.03872958570718765
step: 250, loss: 0.06872358918190002
step: 260, loss: 0.04655971750617027
step: 270, loss: 0.0955735445022583
step: 280, loss: 0.030297329649329185
step: 290, loss: 0.07879197597503662
step: 300, loss: 0.22197593748569489
step: 310, loss: 0.13451695442199707
step: 320, loss: 0.10175073891878128
step: 330, loss: 0.15896795690059662
step: 340, loss: 0.04647320881485939
step: 350, loss: 0.08285066485404968
step: 360, loss: 0.055947981774806976
epoch 9: dev_f1=0.7506172839506173, f1=0.7095115681233932, best_f1=0.7087912087912088
step: 0, loss: 0.03942444175481796
step: 10, loss: 0.06695655733346939
step: 20, loss: 0.03636734560132027
step: 30, loss: 0.027796247974038124
step: 40, loss: 0.05822701379656792
step: 50, loss: 0.06617879867553711
step: 60, loss: 0.03052234835922718
step: 70, loss: 0.0640549436211586
step: 80, loss: 0.10153600573539734
step: 90, loss: 0.05768156051635742
step: 100, loss: 0.0004518555069807917
step: 110, loss: 0.039371564984321594
step: 120, loss: 0.0242631733417511
step: 130, loss: 0.029873481020331383
step: 140, loss: 0.06150436028838158
step: 150, loss: 0.11340470612049103
step: 160, loss: 0.11389170587062836
step: 170, loss: 0.06628977507352829
step: 180, loss: 0.07948637753725052
step: 190, loss: 0.07352647930383682
step: 200, loss: 0.01250049751251936
step: 210, loss: 0.043376002460718155
step: 220, loss: 0.020792784169316292
step: 230, loss: 0.08264704793691635
step: 240, loss: 0.03018837794661522
step: 250, loss: 0.0028666681610047817
step: 260, loss: 0.033877260982990265
step: 270, loss: 0.04789997637271881
step: 280, loss: 0.1504240781068802
step: 290, loss: 0.10505650192499161
step: 300, loss: 0.03445734828710556
step: 310, loss: 0.1507008671760559
step: 320, loss: 0.03981509059667587
step: 330, loss: 0.0896359235048294
step: 340, loss: 0.09735794365406036
step: 350, loss: 0.049537405371665955
step: 360, loss: 0.14476783573627472
epoch 10: dev_f1=0.7562189054726369, f1=0.7183462532299743, best_f1=0.7087912087912088
step: 0, loss: 0.042136721312999725
step: 10, loss: 0.04573005065321922
step: 20, loss: 0.00026923848781734705
step: 30, loss: 0.1565660536289215
step: 40, loss: 0.11218564957380295
step: 50, loss: 0.011514030396938324
step: 60, loss: 0.10244695842266083
step: 70, loss: 0.05202949792146683
step: 80, loss: 0.021510625258088112
step: 90, loss: 0.07046598941087723
step: 100, loss: 0.005706962198019028
step: 110, loss: 0.028958972543478012
step: 120, loss: 0.11253239214420319
step: 130, loss: 0.08858489245176315
step: 140, loss: 0.02674274332821369
step: 150, loss: 0.024492762982845306
step: 160, loss: 4.924628956359811e-05
step: 170, loss: 0.01929139718413353
step: 180, loss: 0.11377637088298798
step: 190, loss: 0.07371829450130463
step: 200, loss: 0.034226611256599426
step: 210, loss: 0.04037221893668175
step: 220, loss: 0.06575106829404831
step: 230, loss: 0.06294651329517365
step: 240, loss: 0.08348655700683594
step: 250, loss: 0.0001331879320787266
step: 260, loss: 0.02512119710445404
step: 270, loss: 0.07671742886304855
step: 280, loss: 0.12739139795303345
step: 290, loss: 0.1340920776128769
step: 300, loss: 0.12802258133888245
step: 310, loss: 0.1076926589012146
step: 320, loss: 0.029807044193148613
step: 330, loss: 0.07496188580989838
step: 340, loss: 0.07328716665506363
step: 350, loss: 0.01733892783522606
step: 360, loss: 0.0828394666314125
epoch 11: dev_f1=0.7419354838709677, f1=0.6839622641509433, best_f1=0.7087912087912088
step: 0, loss: 0.17233628034591675
step: 10, loss: 0.09654367715120316
step: 20, loss: 0.0019863799680024385
step: 30, loss: 0.04609052091836929
step: 40, loss: 0.085323765873909
step: 50, loss: 0.0986437126994133
step: 60, loss: 0.04362250491976738
step: 70, loss: 0.03506244719028473
step: 80, loss: 0.05298202112317085
step: 90, loss: 0.02420336939394474
step: 100, loss: 0.08570446074008942
step: 110, loss: 0.0283578522503376
step: 120, loss: 0.08623915165662766
step: 130, loss: 0.06017010658979416
step: 140, loss: 0.09962300956249237
step: 150, loss: 0.056718043982982635
step: 160, loss: 0.03409772366285324
step: 170, loss: 0.06572837382555008
step: 180, loss: 0.20507696270942688
step: 190, loss: 0.18704211711883545
step: 200, loss: 0.09659666568040848
step: 210, loss: 0.03212520852684975
step: 220, loss: 0.00028368987841531634
step: 230, loss: 0.037210267037153244
step: 240, loss: 0.00474228011444211
step: 250, loss: 0.06826334446668625
step: 260, loss: 0.07183795422315598
step: 270, loss: 0.05317680910229683
step: 280, loss: 0.061520107090473175
step: 290, loss: 0.0002442257246002555
step: 300, loss: 0.0769764631986618
step: 310, loss: 0.0920695960521698
step: 320, loss: 0.06420771032571793
step: 330, loss: 0.038972727954387665
step: 340, loss: 0.009841161780059338
step: 350, loss: 0.09550295025110245
step: 360, loss: 0.09119240194559097
epoch 12: dev_f1=0.7506426735218509, f1=0.6829268292682927, best_f1=0.7087912087912088
step: 0, loss: 0.039567794650793076
step: 10, loss: 0.00024155083519872278
step: 20, loss: 0.14642813801765442
step: 30, loss: 0.13144822418689728
step: 40, loss: 0.09531448036432266
step: 50, loss: 0.04961555451154709
step: 60, loss: 0.022412419319152832
step: 70, loss: 0.05346585065126419
step: 80, loss: 0.09365794062614441
step: 90, loss: 0.08970223367214203
step: 100, loss: 0.0662226527929306
step: 110, loss: 0.07583014667034149
step: 120, loss: 0.03918205574154854
step: 130, loss: 0.05966052785515785
step: 140, loss: 0.11361484974622726
step: 150, loss: 0.014348636381328106
step: 160, loss: 0.05390056595206261
step: 170, loss: 0.09455365687608719
step: 180, loss: 0.046973466873168945
step: 190, loss: 0.01215120404958725
step: 200, loss: 0.07440633326768875
step: 210, loss: 0.05792725831270218
step: 220, loss: 0.06408773362636566
step: 230, loss: 0.00012261948722880334
step: 240, loss: 0.16144542396068573
step: 250, loss: 0.12358605116605759
step: 260, loss: 0.037414997816085815
step: 270, loss: 0.11370813846588135
step: 280, loss: 0.150171160697937
step: 290, loss: 0.07919348776340485
step: 300, loss: 0.04328438267111778
step: 310, loss: 0.05502009019255638
step: 320, loss: 0.13731057941913605
step: 330, loss: 0.05961944907903671
step: 340, loss: 0.04151573032140732
step: 350, loss: 0.16193097829818726
step: 360, loss: 0.0005791281000711024
epoch 13: dev_f1=0.7176781002638523, f1=0.6684782608695653, best_f1=0.7087912087912088
step: 0, loss: 0.09580064564943314
step: 10, loss: 0.11487767100334167
step: 20, loss: 0.019998136907815933
step: 30, loss: 0.07527869939804077
step: 40, loss: 0.07457700371742249
step: 50, loss: 0.029835859313607216
step: 60, loss: 0.03374385088682175
step: 70, loss: 0.019073039293289185
step: 80, loss: 0.08992502838373184
step: 90, loss: 0.00796296913176775
step: 100, loss: 0.09292685240507126
step: 110, loss: 0.04067465662956238
step: 120, loss: 0.04829513281583786
step: 130, loss: 0.19126492738723755
step: 140, loss: 0.08329333364963531
step: 150, loss: 0.042930807918310165
step: 160, loss: 0.05249670147895813
step: 170, loss: 0.0640610083937645
step: 180, loss: 0.0973847508430481
step: 190, loss: 0.022857261821627617
step: 200, loss: 0.06981909275054932
step: 210, loss: 0.015099341049790382
step: 220, loss: 0.06852485239505768
step: 230, loss: 0.029326874762773514
step: 240, loss: 0.07610967010259628
step: 250, loss: 0.033730849623680115
step: 260, loss: 0.10562924295663834
step: 270, loss: 0.08551695197820663
step: 280, loss: 0.06253018230199814
step: 290, loss: 0.0050536165945231915
step: 300, loss: 0.0005327148828655481
step: 310, loss: 0.050708238035440445
step: 320, loss: 0.10486797243356705
step: 330, loss: 0.06402778625488281
step: 340, loss: 0.1439932882785797
step: 350, loss: 0.10772886127233505
step: 360, loss: 0.11542900651693344
epoch 14: dev_f1=0.7347931873479319, f1=0.675, best_f1=0.7087912087912088
step: 0, loss: 0.007875241339206696
step: 10, loss: 0.011362601071596146
step: 20, loss: 0.07452602684497833
step: 30, loss: 0.1003924012184143
step: 40, loss: 0.05930178612470627
step: 50, loss: 0.01638086512684822
step: 60, loss: 0.0006478883442468941
step: 70, loss: 0.02249027043581009
step: 80, loss: 0.007642198354005814
step: 90, loss: 0.04127144813537598
step: 100, loss: 0.09838352352380753
step: 110, loss: 0.027047183364629745
step: 120, loss: 0.04909733682870865
step: 130, loss: 0.06613671034574509
step: 140, loss: 0.004990090150386095
step: 150, loss: 0.09811211377382278
step: 160, loss: 0.037112921476364136
step: 170, loss: 0.039631158113479614
step: 180, loss: 0.09816401451826096
step: 190, loss: 0.0014566897880285978
step: 200, loss: 0.02877892181277275
step: 210, loss: 0.053205568343400955
step: 220, loss: 0.061750032007694244
step: 230, loss: 0.09440771490335464
step: 240, loss: 0.07706040143966675
step: 250, loss: 0.0838957130908966
step: 260, loss: 0.07288467884063721
step: 270, loss: 0.018581002950668335
step: 280, loss: 0.04351446032524109
step: 290, loss: 0.1300426572561264
step: 300, loss: 0.14407265186309814
step: 310, loss: 0.06545253843069077
step: 320, loss: 0.03940445929765701
step: 330, loss: 0.058980993926525116
step: 340, loss: 0.012367344461381435
step: 350, loss: 0.07679570466279984
step: 360, loss: 0.0864032581448555
epoch 15: dev_f1=0.7186761229314421, f1=0.6473429951690821, best_f1=0.7087912087912088
step: 0, loss: 0.009396371431648731
step: 10, loss: 0.05737319961190224
step: 20, loss: 0.03371035307645798
step: 30, loss: 0.03784143924713135
step: 40, loss: 0.01746929995715618
step: 50, loss: 0.021338144317269325
step: 60, loss: 0.11358461529016495
step: 70, loss: 0.059759799391031265
step: 80, loss: 0.046372462064027786
step: 90, loss: 0.04082931578159332
step: 100, loss: 0.06081492453813553
step: 110, loss: 0.016651172190904617
step: 120, loss: 0.030910445377230644
step: 130, loss: 0.05793366581201553
step: 140, loss: 0.0233902707695961
step: 150, loss: 0.01293509267270565
step: 160, loss: 0.0005415970226749778
step: 170, loss: 0.025129258632659912
step: 180, loss: 0.020577484741806984
step: 190, loss: 0.05104118958115578
step: 200, loss: 0.04349800571799278
step: 210, loss: 0.04934888333082199
step: 220, loss: 0.035829104483127594
step: 230, loss: 0.05800322815775871
step: 240, loss: 0.03689267486333847
step: 250, loss: 0.019414544105529785
step: 260, loss: 0.11865688115358353
step: 270, loss: 0.10163453221321106
step: 280, loss: 0.019780388101935387
step: 290, loss: 0.10104373842477798
step: 300, loss: 0.1182723417878151
step: 310, loss: 0.02183440513908863
step: 320, loss: 0.015008051879703999
step: 330, loss: 0.00773617485538125
step: 340, loss: 0.133766308426857
step: 350, loss: 0.14387014508247375
step: 360, loss: 0.047152359038591385
epoch 16: dev_f1=0.7357512953367874, f1=0.6788511749347258, best_f1=0.7087912087912088
step: 0, loss: 0.039208538830280304
step: 10, loss: 0.026107847690582275
step: 20, loss: 0.01923350989818573
step: 30, loss: 0.04010985419154167
step: 40, loss: 0.038256868720054626
step: 50, loss: 0.030383968725800514
step: 60, loss: 0.06481058150529861
step: 70, loss: 0.050536442548036575
step: 80, loss: 0.051017504185438156
step: 90, loss: 0.09175603836774826
step: 100, loss: 0.09955418109893799
step: 110, loss: 0.06558122485876083
step: 120, loss: 0.0054524000734090805
step: 130, loss: 0.06851097196340561
step: 140, loss: 0.06764005124568939
step: 150, loss: 0.06664559245109558
step: 160, loss: 0.01892353780567646
step: 170, loss: 0.045133281499147415
step: 180, loss: 0.15555629134178162
step: 190, loss: 0.03970400616526604
step: 200, loss: 0.00046706333523616195
step: 210, loss: 0.0029320060275495052
step: 220, loss: 0.06683550029993057
step: 230, loss: 0.0697430968284607
step: 240, loss: 0.0015738965012133121
step: 250, loss: 0.0835171565413475
step: 260, loss: 0.020847138017416
step: 270, loss: 0.039394620805978775
step: 280, loss: 0.018631642684340477
step: 290, loss: 0.1250976026058197
step: 300, loss: 0.012936615385115147
step: 310, loss: 0.04149097949266434
step: 320, loss: 0.08869744837284088
step: 330, loss: 0.042450912296772
step: 340, loss: 0.1019613966345787
step: 350, loss: 0.018034160137176514
step: 360, loss: 0.018672769889235497
epoch 17: dev_f1=0.7052341597796142, f1=0.6798866855524079, best_f1=0.7087912087912088
step: 0, loss: 0.02112722396850586
step: 10, loss: 0.024594560265541077
step: 20, loss: 0.05345020070672035
step: 30, loss: 0.022345878183841705
step: 40, loss: 0.06564945727586746
step: 50, loss: 0.030965741723775864
step: 60, loss: 0.10696595907211304
step: 70, loss: 0.03908311948180199
step: 80, loss: 0.02308989316225052
step: 90, loss: 0.02123705856502056
step: 100, loss: 0.007858793251216412
step: 110, loss: 0.017871547490358353
step: 120, loss: 0.03318493068218231
step: 130, loss: 0.036243606358766556
step: 140, loss: 0.04723384231328964
step: 150, loss: 0.021230673417448997
step: 160, loss: 0.0407235287129879
step: 170, loss: 0.021804440766572952
step: 180, loss: 0.0318535640835762
step: 190, loss: 0.02778022736310959
step: 200, loss: 0.01281534880399704
step: 210, loss: 0.05849386006593704
step: 220, loss: 0.06841395050287247
step: 230, loss: 0.008691342547535896
step: 240, loss: 0.009902140125632286
step: 250, loss: 0.06081198900938034
step: 260, loss: 0.08267142623662949
step: 270, loss: 0.00760632986202836
step: 280, loss: 0.01502671092748642
step: 290, loss: 0.16839928925037384
step: 300, loss: 0.011505858972668648
step: 310, loss: 0.052867647260427475
step: 320, loss: 0.0335831344127655
step: 330, loss: 0.038182370364665985
step: 340, loss: 0.03624473884701729
step: 350, loss: 0.17916715145111084
step: 360, loss: 0.04221269115805626
epoch 18: dev_f1=0.7204030226700252, f1=0.6597938144329897, best_f1=0.7087912087912088
step: 0, loss: 0.002038166858255863
step: 10, loss: 0.03346363827586174
step: 20, loss: 0.024952853098511696
step: 30, loss: 0.01175111997872591
step: 40, loss: 0.03660544753074646
step: 50, loss: 0.002554177539423108
step: 60, loss: 0.002510972321033478
step: 70, loss: 0.0004532702441792935
step: 80, loss: 0.0020744502544403076
step: 90, loss: 0.07661549746990204
step: 100, loss: 0.021478526294231415
step: 110, loss: 0.06480468809604645
step: 120, loss: 0.16316013038158417
step: 130, loss: 0.004183674696832895
step: 140, loss: 0.0684976801276207
step: 150, loss: 0.03380222246050835
step: 160, loss: 0.059410300105810165
step: 170, loss: 0.06860600411891937
step: 180, loss: 0.1004444882273674
step: 190, loss: 0.03352345898747444
step: 200, loss: 0.14016295969486237
step: 210, loss: 0.016740912571549416
step: 220, loss: 0.07278988510370255
step: 230, loss: 0.020345373079180717
step: 240, loss: 0.020875055342912674
step: 250, loss: 0.08476761728525162
step: 260, loss: 0.03794693201780319
step: 270, loss: 0.0426085889339447
step: 280, loss: 0.05239880457520485
step: 290, loss: 0.030930902808904648
step: 300, loss: 0.02785266935825348
step: 310, loss: 0.010243636555969715
step: 320, loss: 0.03922988474369049
step: 330, loss: 0.01188404019922018
step: 340, loss: 0.09476523101329803
step: 350, loss: 0.014904222451150417
step: 360, loss: 0.008829277008771896
epoch 19: dev_f1=0.7157894736842104, f1=0.6739130434782608, best_f1=0.7087912087912088
step: 0, loss: 0.05610673874616623
step: 10, loss: 0.07271896302700043
step: 20, loss: 0.03930410370230675
step: 30, loss: 0.05965995416045189
step: 40, loss: 0.01534084603190422
step: 50, loss: 0.06881677359342575
step: 60, loss: 0.005620939191430807
step: 70, loss: 0.022865144535899162
step: 80, loss: 0.04789484292268753
step: 90, loss: 0.1329837590456009
step: 100, loss: 0.01161341555416584
step: 110, loss: 4.603503111866303e-05
step: 120, loss: 0.001470630057156086
step: 130, loss: 0.010290509089827538
step: 140, loss: 0.05725056678056717
step: 150, loss: 0.06518140435218811
step: 160, loss: 0.03858174383640289
step: 170, loss: 0.07500535994768143
step: 180, loss: 0.0725870206952095
step: 190, loss: 0.1090807169675827
step: 200, loss: 0.026307374238967896
step: 210, loss: 0.13481420278549194
step: 220, loss: 0.06704890727996826
step: 230, loss: 0.06650394946336746
step: 240, loss: 0.015615235082805157
step: 250, loss: 0.010577189736068249
step: 260, loss: 0.081588976085186
step: 270, loss: 0.01341620460152626
step: 280, loss: 0.048855993896722794
step: 290, loss: 0.0798552855849266
step: 300, loss: 0.014399012550711632
step: 310, loss: 0.070757657289505
step: 320, loss: 0.07324478775262833
step: 330, loss: 0.1331716924905777
step: 340, loss: 0.02708781696856022
step: 350, loss: 0.029772117733955383
step: 360, loss: 0.026101993396878242
epoch 20: dev_f1=0.704225352112676, f1=0.6744868035190615, best_f1=0.7087912087912088
