cuda
Device: cuda
step: 0, loss: 0.9521549344062805
step: 10, loss: 0.016518592834472656
step: 20, loss: 0.16557936370372772
step: 30, loss: 0.03755314275622368
step: 40, loss: 0.48177585005760193
step: 50, loss: 0.16053269803524017
step: 60, loss: 0.3385683000087738
step: 70, loss: 0.4283013939857483
step: 80, loss: 0.14696718752384186
step: 90, loss: 0.3273577094078064
step: 100, loss: 0.04637943580746651
step: 110, loss: 0.2245587408542633
step: 120, loss: 0.048905398696660995
step: 130, loss: 0.3582354784011841
step: 140, loss: 0.3664141893386841
step: 150, loss: 0.158342182636261
step: 160, loss: 0.13323645293712616
step: 170, loss: 0.1340595781803131
step: 180, loss: 0.30721768736839294
step: 190, loss: 0.20555993914604187
step: 200, loss: 0.1871640980243683
step: 210, loss: 0.17705439031124115
step: 220, loss: 0.40841105580329895
step: 230, loss: 0.12446022033691406
step: 240, loss: 0.30746495723724365
step: 250, loss: 0.2836247682571411
step: 260, loss: 0.20874430239200592
step: 270, loss: 0.17928346991539001
step: 280, loss: 0.17010028660297394
step: 290, loss: 0.019826114177703857
step: 300, loss: 0.14042861759662628
step: 310, loss: 0.4516601860523224
step: 320, loss: 0.18993526697158813
step: 330, loss: 0.04721684753894806
step: 340, loss: 0.1053909957408905
step: 350, loss: 0.15318067371845245
step: 360, loss: 0.11069687455892563
epoch 1: dev_f1=0.6378896882494005, f1=0.6193853427895981, best_f1=0.6193853427895981
step: 0, loss: 0.17037491500377655
step: 10, loss: 0.03723630681633949
step: 20, loss: 0.28311875462532043
step: 30, loss: 0.13606733083724976
step: 40, loss: 0.4363689720630646
step: 50, loss: 0.08279497921466827
step: 60, loss: 0.141065776348114
step: 70, loss: 0.06617221236228943
step: 80, loss: 0.12709590792655945
step: 90, loss: 0.193955197930336
step: 100, loss: 0.21177110075950623
step: 110, loss: 0.177416130900383
step: 120, loss: 0.2616286277770996
step: 130, loss: 0.23155897855758667
step: 140, loss: 0.08360149711370468
step: 150, loss: 0.25985187292099
step: 160, loss: 0.035808537155389786
step: 170, loss: 0.08017648011445999
step: 180, loss: 0.11511367559432983
step: 190, loss: 0.11634641885757446
step: 200, loss: 0.07418970763683319
step: 210, loss: 0.12340038269758224
step: 220, loss: 0.19080936908721924
step: 230, loss: 0.16077949106693268
step: 240, loss: 0.06956475228071213
step: 250, loss: 0.11100342124700546
step: 260, loss: 0.12172998487949371
step: 270, loss: 0.08093692362308502
step: 280, loss: 0.019336232915520668
step: 290, loss: 0.1222161203622818
step: 300, loss: 0.16686120629310608
step: 310, loss: 0.16510696709156036
step: 320, loss: 0.24045602977275848
step: 330, loss: 0.16311779618263245
step: 340, loss: 0.2687029540538788
step: 350, loss: 0.07715795189142227
step: 360, loss: 0.018186090514063835
epoch 2: dev_f1=0.7488151658767772, f1=0.7458432304038005, best_f1=0.7458432304038005
step: 0, loss: 0.1872076392173767
step: 10, loss: 0.14470617473125458
step: 20, loss: 0.0062516420148313046
step: 30, loss: 0.0630790963768959
step: 40, loss: 0.1119852289557457
step: 50, loss: 0.037813156843185425
step: 60, loss: 0.10989508032798767
step: 70, loss: 0.1686536818742752
step: 80, loss: 0.0190814770758152
step: 90, loss: 0.045745376497507095
step: 100, loss: 0.13985201716423035
step: 110, loss: 0.02057836577296257
step: 120, loss: 0.17782120406627655
step: 130, loss: 0.059221263974905014
step: 140, loss: 0.06520944833755493
step: 150, loss: 0.12598705291748047
step: 160, loss: 0.07788629829883575
step: 170, loss: 0.10987149924039841
step: 180, loss: 0.09772440046072006
step: 190, loss: 0.08158449083566666
step: 200, loss: 0.06370481848716736
step: 210, loss: 0.1379907876253128
step: 220, loss: 0.11449071764945984
step: 230, loss: 0.025501985102891922
step: 240, loss: 0.1253964602947235
step: 250, loss: 0.11897850781679153
step: 260, loss: 0.23836751282215118
step: 270, loss: 0.15333883464336395
step: 280, loss: 0.09974115341901779
step: 290, loss: 0.0738886296749115
step: 300, loss: 0.11418598890304565
step: 310, loss: 0.15941928327083588
step: 320, loss: 0.08114353567361832
step: 330, loss: 0.19566409289836884
step: 340, loss: 0.09264817833900452
step: 350, loss: 0.11892936378717422
step: 360, loss: 0.05391871929168701
epoch 3: dev_f1=0.7684729064039408, f1=0.7506297229219143, best_f1=0.7506297229219143
step: 0, loss: 0.1439332515001297
step: 10, loss: 0.06640459597110748
step: 20, loss: 0.04699484258890152
step: 30, loss: 0.13853035867214203
step: 40, loss: 0.13038191199302673
step: 50, loss: 0.06868039816617966
step: 60, loss: 0.09192835539579391
step: 70, loss: 0.06452357769012451
step: 80, loss: 0.06140071153640747
step: 90, loss: 0.09021233767271042
step: 100, loss: 0.1431121975183487
step: 110, loss: 0.08181504160165787
step: 120, loss: 0.09337074309587479
step: 130, loss: 0.06349523365497589
step: 140, loss: 0.0581374354660511
step: 150, loss: 0.14965447783470154
step: 160, loss: 0.11321009695529938
step: 170, loss: 0.014590040780603886
step: 180, loss: 0.06768961995840073
step: 190, loss: 0.2526642382144928
step: 200, loss: 0.12751692533493042
step: 210, loss: 0.07285241782665253
step: 220, loss: 0.02146800421178341
step: 230, loss: 0.07693611085414886
step: 240, loss: 0.1049053892493248
step: 250, loss: 0.0270690880715847
step: 260, loss: 0.16429710388183594
step: 270, loss: 0.05801120027899742
step: 280, loss: 0.07843836396932602
step: 290, loss: 0.018144112080335617
step: 300, loss: 0.08502860367298126
step: 310, loss: 0.05685579776763916
step: 320, loss: 0.03281242772936821
step: 330, loss: 0.06266118586063385
step: 340, loss: 0.023586126044392586
step: 350, loss: 0.09904304891824722
step: 360, loss: 0.1553642302751541
epoch 4: dev_f1=0.7401574803149608, f1=0.7331536388140162, best_f1=0.7506297229219143
step: 0, loss: 0.07304073870182037
step: 10, loss: 0.05550093203783035
step: 20, loss: 0.1707206666469574
step: 30, loss: 0.01935732364654541
step: 40, loss: 0.06414788961410522
step: 50, loss: 0.07918044924736023
step: 60, loss: 0.03612295910716057
step: 70, loss: 0.044061146676540375
step: 80, loss: 0.11575531959533691
step: 90, loss: 0.10217168182134628
step: 100, loss: 0.02994048409163952
step: 110, loss: 0.14392203092575073
step: 120, loss: 0.1191900297999382
step: 130, loss: 0.054546378552913666
step: 140, loss: 0.09837905317544937
step: 150, loss: 0.07797913998365402
step: 160, loss: 0.18469016253948212
step: 170, loss: 0.14038048684597015
step: 180, loss: 0.11998899281024933
step: 190, loss: 0.06954700499773026
step: 200, loss: 0.0024668462574481964
step: 210, loss: 0.08589907735586166
step: 220, loss: 0.13313469290733337
step: 230, loss: 0.03969153016805649
step: 240, loss: 0.045222342014312744
step: 250, loss: 0.07509307563304901
step: 260, loss: 0.03238644078373909
step: 270, loss: 0.20552441477775574
step: 280, loss: 0.07398747652769089
step: 290, loss: 0.03250479698181152
step: 300, loss: 0.09493762254714966
step: 310, loss: 0.044113121926784515
step: 320, loss: 0.11244747787714005
step: 330, loss: 0.09025945514440536
step: 340, loss: 0.0739067941904068
step: 350, loss: 0.10819924622774124
step: 360, loss: 0.024148155003786087
epoch 5: dev_f1=0.7433155080213903, f1=0.7166666666666668, best_f1=0.7506297229219143
step: 0, loss: 0.05897793918848038
step: 10, loss: 0.039564941078424454
step: 20, loss: 0.18810270726680756
step: 30, loss: 0.06698787212371826
step: 40, loss: 0.0767814889550209
step: 50, loss: 0.08372685313224792
step: 60, loss: 0.09180314838886261
step: 70, loss: 0.008412675932049751
step: 80, loss: 0.08502432703971863
step: 90, loss: 0.05362487584352493
step: 100, loss: 0.08949635922908783
step: 110, loss: 0.057593997567892075
step: 120, loss: 0.1001877412199974
step: 130, loss: 0.09199531376361847
step: 140, loss: 0.07201576977968216
step: 150, loss: 0.16084569692611694
step: 160, loss: 0.06122533231973648
step: 170, loss: 0.060398515313863754
step: 180, loss: 0.033866699784994125
step: 190, loss: 0.007551128976047039
step: 200, loss: 0.04603869840502739
step: 210, loss: 0.25465402007102966
step: 220, loss: 0.06982917338609695
step: 230, loss: 0.014829560182988644
step: 240, loss: 0.06758429855108261
step: 250, loss: 0.09916406869888306
step: 260, loss: 0.057650238275527954
step: 270, loss: 0.06893916428089142
step: 280, loss: 0.0688127800822258
step: 290, loss: 0.021409664303064346
step: 300, loss: 0.15080523490905762
step: 310, loss: 0.04167680814862251
step: 320, loss: 0.07355907559394836
step: 330, loss: 0.10173626989126205
step: 340, loss: 0.12690143287181854
step: 350, loss: 0.17833390831947327
step: 360, loss: 0.0024440682027488947
epoch 6: dev_f1=0.7403598971722366, f1=0.696103896103896, best_f1=0.7506297229219143
step: 0, loss: 0.045111283659935
step: 10, loss: 0.04047334939241409
step: 20, loss: 0.14188647270202637
step: 30, loss: 0.12693804502487183
step: 40, loss: 0.020546529442071915
step: 50, loss: 0.06811364740133286
step: 60, loss: 0.050968628376722336
step: 70, loss: 0.12617699801921844
step: 80, loss: 0.08140257745981216
step: 90, loss: 0.06886707246303558
step: 100, loss: 0.24068278074264526
step: 110, loss: 0.062368977814912796
step: 120, loss: 0.17898595333099365
step: 130, loss: 0.09059052914381027
step: 140, loss: 0.10100913047790527
step: 150, loss: 0.10181096196174622
step: 160, loss: 0.11628498136997223
step: 170, loss: 0.11003005504608154
step: 180, loss: 0.08703981339931488
step: 190, loss: 0.0832323282957077
step: 200, loss: 0.15986137092113495
step: 210, loss: 0.04430362209677696
step: 220, loss: 0.023277688771486282
step: 230, loss: 0.03175436705350876
step: 240, loss: 0.178554967045784
step: 250, loss: 0.05732167139649391
step: 260, loss: 0.12088453769683838
step: 270, loss: 0.023917030543088913
step: 280, loss: 0.11461389064788818
step: 290, loss: 0.09072607755661011
step: 300, loss: 0.06888844072818756
step: 310, loss: 0.04005659371614456
step: 320, loss: 0.05771905183792114
step: 330, loss: 0.06902584433555603
step: 340, loss: 0.008068581111729145
step: 350, loss: 0.029119791463017464
step: 360, loss: 0.052382003515958786
epoch 7: dev_f1=0.7475247524752476, f1=0.7093333333333335, best_f1=0.7506297229219143
step: 0, loss: 0.014680271968245506
step: 10, loss: 0.06329144537448883
step: 20, loss: 0.06383144110441208
step: 30, loss: 0.10081985592842102
step: 40, loss: 0.08694640547037125
step: 50, loss: 0.10235196352005005
step: 60, loss: 0.029920676723122597
step: 70, loss: 0.04043487459421158
step: 80, loss: 0.10169214010238647
step: 90, loss: 0.03254551813006401
step: 100, loss: 0.042990896850824356
step: 110, loss: 0.06278929859399796
step: 120, loss: 0.04499362036585808
step: 130, loss: 0.0544486865401268
step: 140, loss: 0.07053950428962708
step: 150, loss: 0.05252016708254814
step: 160, loss: 0.030515870079398155
step: 170, loss: 0.38244009017944336
step: 180, loss: 0.04654088616371155
step: 190, loss: 0.0248572938144207
step: 200, loss: 0.02730054408311844
step: 210, loss: 0.08840706199407578
step: 220, loss: 0.027541857212781906
step: 230, loss: 0.014864565804600716
step: 240, loss: 0.16547392308712006
step: 250, loss: 0.10150884836912155
step: 260, loss: 0.4246675670146942
step: 270, loss: 0.02738996222615242
step: 280, loss: 0.03337498754262924
step: 290, loss: 0.05065779387950897
step: 300, loss: 0.045079607516527176
step: 310, loss: 0.07781356573104858
step: 320, loss: 0.022678375244140625
step: 330, loss: 0.0827983021736145
step: 340, loss: 0.07964779436588287
step: 350, loss: 0.06755835562944412
step: 360, loss: 0.1275297850370407
epoch 8: dev_f1=0.7401574803149608, f1=0.6666666666666666, best_f1=0.7506297229219143
step: 0, loss: 0.03909705579280853
step: 10, loss: 0.10361399501562119
step: 20, loss: 0.01850511133670807
step: 30, loss: 0.0769180878996849
step: 40, loss: 0.12385242432355881
step: 50, loss: 0.13767637312412262
step: 60, loss: 0.03107243776321411
step: 70, loss: 0.12177877128124237
step: 80, loss: 0.05909455195069313
step: 90, loss: 0.07849006354808807
step: 100, loss: 0.04195592552423477
step: 110, loss: 0.03143886476755142
step: 120, loss: 0.08743931353092194
step: 130, loss: 0.07034284621477127
step: 140, loss: 0.03351251035928726
step: 150, loss: 0.11212964355945587
step: 160, loss: 0.05639250576496124
step: 170, loss: 0.08348610252141953
step: 180, loss: 0.1138550341129303
step: 190, loss: 0.07084740698337555
step: 200, loss: 0.04501015320420265
step: 210, loss: 0.05170346796512604
step: 220, loss: 0.17477326095104218
step: 230, loss: 0.11102791130542755
step: 240, loss: 0.07093453407287598
step: 250, loss: 0.054620251059532166
step: 260, loss: 0.06691788882017136
step: 270, loss: 0.02053062617778778
step: 280, loss: 0.08642743527889252
step: 290, loss: 0.1621359884738922
step: 300, loss: 0.0469948872923851
step: 310, loss: 0.003977630753070116
step: 320, loss: 0.06899940967559814
step: 330, loss: 0.03205476701259613
step: 340, loss: 0.055970605462789536
step: 350, loss: 0.12167815864086151
step: 360, loss: 0.09802138805389404
epoch 9: dev_f1=0.7340425531914895, f1=0.6961325966850829, best_f1=0.7506297229219143
step: 0, loss: 0.10508676618337631
step: 10, loss: 0.02872927486896515
step: 20, loss: 0.06892212480306625
step: 30, loss: 0.028314562514424324
step: 40, loss: 0.16119667887687683
step: 50, loss: 0.04797528311610222
step: 60, loss: 0.07556435465812683
step: 70, loss: 0.004408589564263821
step: 80, loss: 0.01487022265791893
step: 90, loss: 0.052809249609708786
step: 100, loss: 0.09335921704769135
step: 110, loss: 0.0674552246928215
step: 120, loss: 0.08892367780208588
step: 130, loss: 0.10614605247974396
step: 140, loss: 0.03688764199614525
step: 150, loss: 0.05777366831898689
step: 160, loss: 0.071657195687294
step: 170, loss: 0.06543142348527908
step: 180, loss: 0.04185454547405243
step: 190, loss: 0.10371540486812592
step: 200, loss: 0.05951940640807152
step: 210, loss: 0.04609794169664383
step: 220, loss: 0.017321569845080376
step: 230, loss: 0.059250399470329285
step: 240, loss: 0.02906929701566696
step: 250, loss: 0.019289998337626457
step: 260, loss: 0.11862973868846893
step: 270, loss: 0.10419899970293045
step: 280, loss: 0.10150963068008423
step: 290, loss: 0.004818229004740715
step: 300, loss: 0.09250346571207047
step: 310, loss: 0.035021647810935974
step: 320, loss: 0.038026437163352966
step: 330, loss: 0.05092330649495125
step: 340, loss: 0.09965167939662933
step: 350, loss: 0.1087326928973198
step: 360, loss: 0.06591923534870148
epoch 10: dev_f1=0.7229551451187335, f1=0.676056338028169, best_f1=0.7506297229219143
step: 0, loss: 0.3490264117717743
step: 10, loss: 0.09404199570417404
step: 20, loss: 0.13322356343269348
step: 30, loss: 0.025516586378216743
step: 40, loss: 0.029638944193720818
step: 50, loss: 0.05903578922152519
step: 60, loss: 0.11250686645507812
step: 70, loss: 0.05368281900882721
step: 80, loss: 0.0006378850666806102
step: 90, loss: 0.08890533447265625
step: 100, loss: 0.030045829713344574
step: 110, loss: 0.06345051527023315
step: 120, loss: 0.018788045272231102
step: 130, loss: 0.09419211000204086
step: 140, loss: 0.03174387663602829
step: 150, loss: 0.10951493680477142
step: 160, loss: 0.009679592214524746
step: 170, loss: 0.06049582362174988
step: 180, loss: 0.10346779227256775
step: 190, loss: 0.1633249670267105
step: 200, loss: 0.07065041363239288
step: 210, loss: 0.11981864273548126
step: 220, loss: 0.08429497480392456
step: 230, loss: 0.0007721947622485459
step: 240, loss: 0.09373322129249573
step: 250, loss: 0.10534387826919556
step: 260, loss: 0.04663355275988579
step: 270, loss: 0.048088815063238144
step: 280, loss: 0.055501364171504974
step: 290, loss: 0.03603712096810341
step: 300, loss: 0.08081190288066864
step: 310, loss: 0.036436207592487335
step: 320, loss: 0.07869666814804077
step: 330, loss: 0.09143433719873428
step: 340, loss: 0.03433534502983093
step: 350, loss: 0.1118914783000946
step: 360, loss: 0.03140648454427719
epoch 11: dev_f1=0.7257617728531854, f1=0.6994219653179191, best_f1=0.7506297229219143
step: 0, loss: 0.01836363784968853
step: 10, loss: 0.10588610172271729
step: 20, loss: 0.11640916764736176
step: 30, loss: 0.024276813492178917
step: 40, loss: 0.0629325807094574
step: 50, loss: 0.09687693417072296
step: 60, loss: 0.07294819504022598
step: 70, loss: 0.006462812889367342
step: 80, loss: 0.01427983958274126
step: 90, loss: 0.03003164380788803
step: 100, loss: 0.09305453300476074
step: 110, loss: 0.06562071293592453
step: 120, loss: 0.08134696632623672
step: 130, loss: 0.042487211525440216
step: 140, loss: 3.663374445750378e-05
step: 150, loss: 0.04165523126721382
step: 160, loss: 0.034224532544612885
step: 170, loss: 0.043481796979904175
step: 180, loss: 3.983367423643358e-05
step: 190, loss: 0.018184201791882515
step: 200, loss: 0.0029227659106254578
step: 210, loss: 0.02984544262290001
step: 220, loss: 0.0269515048712492
step: 230, loss: 0.005082214716821909
step: 240, loss: 0.11983510106801987
step: 250, loss: 0.03726302832365036
step: 260, loss: 0.10627817362546921
step: 270, loss: 0.013453008607029915
step: 280, loss: 0.05709277093410492
step: 290, loss: 0.041052572429180145
step: 300, loss: 0.05306648835539818
step: 310, loss: 0.12787984311580658
step: 320, loss: 0.05226749926805496
step: 330, loss: 0.16798482835292816
step: 340, loss: 0.07137604057788849
step: 350, loss: 0.05909784510731697
step: 360, loss: 0.00752983707934618
epoch 12: dev_f1=0.7135678391959798, f1=0.6836734693877551, best_f1=0.7506297229219143
step: 0, loss: 0.03356769308447838
step: 10, loss: 0.02043929509818554
step: 20, loss: 0.10685677826404572
step: 30, loss: 0.04602741450071335
step: 40, loss: 0.09938381612300873
step: 50, loss: 0.04556473344564438
step: 60, loss: 0.008475925773382187
step: 70, loss: 0.09011183679103851
step: 80, loss: 0.07772044837474823
step: 90, loss: 0.09167055785655975
step: 100, loss: 0.14012522995471954
step: 110, loss: 0.014335191808640957
step: 120, loss: 0.04333262890577316
step: 130, loss: 0.010380692780017853
step: 140, loss: 0.0402815118432045
step: 150, loss: 0.0677332803606987
step: 160, loss: 0.042299214750528336
step: 170, loss: 0.12465395033359528
step: 180, loss: 0.01666603609919548
step: 190, loss: 0.1282702088356018
step: 200, loss: 0.045715443789958954
step: 210, loss: 0.052146218717098236
step: 220, loss: 0.09629242867231369
step: 230, loss: 0.06882979720830917
step: 240, loss: 0.06120304763317108
step: 250, loss: 0.06882915645837784
step: 260, loss: 0.06199228763580322
step: 270, loss: 0.014196082949638367
step: 280, loss: 0.12264992296695709
step: 290, loss: 0.1624809205532074
step: 300, loss: 0.02334357425570488
step: 310, loss: 0.03397739678621292
step: 320, loss: 0.2106611728668213
step: 330, loss: 0.02007662132382393
step: 340, loss: 0.001705993665382266
step: 350, loss: 0.2329198569059372
step: 360, loss: 0.040034692734479904
epoch 13: dev_f1=0.7427055702917772, f1=0.6961325966850829, best_f1=0.7506297229219143
step: 0, loss: 0.04813278838992119
step: 10, loss: 0.0328572615981102
step: 20, loss: 0.011174719780683517
step: 30, loss: 0.016566665843129158
step: 40, loss: 0.10458338260650635
step: 50, loss: 0.07185523211956024
step: 60, loss: 0.10514005273580551
step: 70, loss: 0.07414497435092926
step: 80, loss: 0.016620609909296036
step: 90, loss: 0.046210989356040955
step: 100, loss: 0.07903244346380234
step: 110, loss: 0.04597058147192001
step: 120, loss: 0.05971594154834747
step: 130, loss: 0.1959097683429718
step: 140, loss: 0.0038495692424476147
step: 150, loss: 0.02697979100048542
step: 160, loss: 0.1076337993144989
step: 170, loss: 0.050269562751054764
step: 180, loss: 0.03602524474263191
step: 190, loss: 0.01918335258960724
step: 200, loss: 0.0712275579571724
step: 210, loss: 0.019961100071668625
step: 220, loss: 0.031470395624637604
step: 230, loss: 0.027090931311249733
step: 240, loss: 0.07287973910570145
step: 250, loss: 0.04504988342523575
step: 260, loss: 0.10200008749961853
step: 270, loss: 0.03514443710446358
step: 280, loss: 0.0704566016793251
step: 290, loss: 0.13879436254501343
step: 300, loss: 0.052747249603271484
step: 310, loss: 0.0036896406672894955
step: 320, loss: 0.06224050745368004
step: 330, loss: 0.028676340356469154
step: 340, loss: 0.06366982311010361
step: 350, loss: 0.043418265879154205
step: 360, loss: 0.11288557946681976
epoch 14: dev_f1=0.7365728900255755, f1=0.6821705426356589, best_f1=0.7506297229219143
step: 0, loss: 3.920904782717116e-05
step: 10, loss: 0.10076434910297394
step: 20, loss: 0.04319612681865692
step: 30, loss: 0.022984299808740616
step: 40, loss: 0.041881121695041656
step: 50, loss: 0.03936983644962311
step: 60, loss: 0.05382730811834335
step: 70, loss: 0.0055841002613306046
step: 80, loss: 0.026118703186511993
step: 90, loss: 0.1664428412914276
step: 100, loss: 0.004597302060574293
step: 110, loss: 0.21139512956142426
step: 120, loss: 0.01497308537364006
step: 130, loss: 0.011222092434763908
step: 140, loss: 0.014320600777864456
step: 150, loss: 0.04263673722743988
step: 160, loss: 0.023105427622795105
step: 170, loss: 0.009196736849844456
step: 180, loss: 0.059862568974494934
step: 190, loss: 0.06862503290176392
step: 200, loss: 0.010393325239419937
step: 210, loss: 0.049855705350637436
step: 220, loss: 0.022346394136548042
step: 230, loss: 0.0367998443543911
step: 240, loss: 0.009526876732707024
step: 250, loss: 0.0652216374874115
step: 260, loss: 0.05473190173506737
step: 270, loss: 0.0230092890560627
step: 280, loss: 0.05025359243154526
step: 290, loss: 0.07950660586357117
step: 300, loss: 0.031693607568740845
step: 310, loss: 0.00408898526802659
step: 320, loss: 0.014320757240056992
step: 330, loss: 0.017097199335694313
step: 340, loss: 0.014344632625579834
step: 350, loss: 0.011300069279968739
step: 360, loss: 0.04926309734582901
epoch 15: dev_f1=0.7305699481865285, f1=0.693121693121693, best_f1=0.7506297229219143
step: 0, loss: 0.018089503049850464
step: 10, loss: 0.0025455066934227943
step: 20, loss: 0.04156748950481415
step: 30, loss: 0.004110955633223057
step: 40, loss: 0.03697378560900688
step: 50, loss: 0.07857734709978104
step: 60, loss: 0.07358773797750473
step: 70, loss: 0.022422712296247482
step: 80, loss: 0.010304698720574379
step: 90, loss: 0.015409203246235847
step: 100, loss: 0.057673029601573944
step: 110, loss: 0.04230695962905884
step: 120, loss: 0.0420270636677742
step: 130, loss: 0.07742077112197876
step: 140, loss: 0.10478487610816956
step: 150, loss: 0.0534612238407135
step: 160, loss: 0.012145712040364742
step: 170, loss: 0.0016689053736627102
step: 180, loss: 0.019883329048752785
step: 190, loss: 0.10811067372560501
step: 200, loss: 2.6188268748228438e-05
step: 210, loss: 0.03831501677632332
step: 220, loss: 0.08363695442676544
step: 230, loss: 0.010570747777819633
step: 240, loss: 2.5480554540990852e-05
step: 250, loss: 0.03466115519404411
step: 260, loss: 0.018129991367459297
step: 270, loss: 0.11590368300676346
step: 280, loss: 0.10038101673126221
step: 290, loss: 0.004045892506837845
step: 300, loss: 0.017332635819911957
step: 310, loss: 0.07314557582139969
step: 320, loss: 0.024248506873846054
step: 330, loss: 0.050218962132930756
step: 340, loss: 0.07001147419214249
step: 350, loss: 0.05491457134485245
step: 360, loss: 0.012591027654707432
epoch 16: dev_f1=0.7388888888888889, f1=0.6802325581395349, best_f1=0.7506297229219143
step: 0, loss: 0.01709955371916294
step: 10, loss: 0.028405262157320976
step: 20, loss: 0.03169422224164009
step: 30, loss: 0.026353705674409866
step: 40, loss: 0.038194045424461365
step: 50, loss: 0.011407722719013691
step: 60, loss: 0.06294583529233932
step: 70, loss: 0.04529311880469322
step: 80, loss: 0.029205789789557457
step: 90, loss: 0.012573592364788055
step: 100, loss: 0.0035502458922564983
step: 110, loss: 0.013401584699749947
step: 120, loss: 0.012106412090361118
step: 130, loss: 0.06133861094713211
step: 140, loss: 0.06724480539560318
step: 150, loss: 0.09486526995897293
step: 160, loss: 0.03417886048555374
step: 170, loss: 0.04708511009812355
step: 180, loss: 0.017140580341219902
step: 190, loss: 0.10968697816133499
step: 200, loss: 0.041081178933382034
step: 210, loss: 0.01789010688662529
step: 220, loss: 0.005543356295675039
step: 230, loss: 0.051524970680475235
step: 240, loss: 0.0023155100643634796
step: 250, loss: 0.016756420955061913
step: 260, loss: 0.03493897244334221
step: 270, loss: 0.04686512425541878
step: 280, loss: 0.09250466525554657
step: 290, loss: 0.01913747750222683
step: 300, loss: 0.009596516378223896
step: 310, loss: 0.007468606811016798
step: 320, loss: 0.13306966423988342
step: 330, loss: 0.023108379915356636
step: 340, loss: 0.047014132142066956
step: 350, loss: 0.02934562787413597
step: 360, loss: 0.023312538862228394
epoch 17: dev_f1=0.7282321899736147, f1=0.6850828729281768, best_f1=0.7506297229219143
step: 0, loss: 0.022335490211844444
step: 10, loss: 0.14786399900913239
step: 20, loss: 0.03774141147732735
step: 30, loss: 0.027290843427181244
step: 40, loss: 0.039941444993019104
step: 50, loss: 0.019795455038547516
step: 60, loss: 0.09616020321846008
step: 70, loss: 0.016572607681155205
step: 80, loss: 0.01515362598001957
step: 90, loss: 0.009045546874403954
step: 100, loss: 0.02283376269042492
step: 110, loss: 0.009587660431861877
step: 120, loss: 0.047960150986909866
step: 130, loss: 0.02624998800456524
step: 140, loss: 0.013388686813414097
step: 150, loss: 0.009750290773808956
step: 160, loss: 0.08465540409088135
step: 170, loss: 0.003924359567463398
step: 180, loss: 0.03986456245183945
step: 190, loss: 0.03440017253160477
step: 200, loss: 0.05698458105325699
step: 210, loss: 0.03637155890464783
step: 220, loss: 0.04639572650194168
step: 230, loss: 0.05070517212152481
step: 240, loss: 2.5093111617024988e-05
step: 250, loss: 0.05843260511755943
step: 260, loss: 0.0215971227735281
step: 270, loss: 0.017752045765519142
step: 280, loss: 0.11672621220350266
step: 290, loss: 0.003656727261841297
step: 300, loss: 0.05238422751426697
step: 310, loss: 0.06208069249987602
step: 320, loss: 0.10427387058734894
step: 330, loss: 0.08783690631389618
step: 340, loss: 0.06094047799706459
step: 350, loss: 0.05383957549929619
step: 360, loss: 0.13549838960170746
epoch 18: dev_f1=0.7300771208226221, f1=0.6842105263157895, best_f1=0.7506297229219143
step: 0, loss: 0.04928033426403999
step: 10, loss: 0.05073444917798042
step: 20, loss: 2.1520694645005278e-05
step: 30, loss: 0.03868287429213524
step: 40, loss: 0.015052367933094501
step: 50, loss: 0.06428483128547668
step: 60, loss: 0.07295797765254974
step: 70, loss: 0.004171343985944986
step: 80, loss: 0.02641892246901989
step: 90, loss: 0.021177973598241806
step: 100, loss: 0.0864185020327568
step: 110, loss: 0.029235433787107468
step: 120, loss: 0.010360661894083023
step: 130, loss: 0.034186720848083496
step: 140, loss: 0.051296669989824295
step: 150, loss: 0.05226202681660652
step: 160, loss: 0.006375119090080261
step: 170, loss: 0.012579613365232944
step: 180, loss: 0.05160588026046753
step: 190, loss: 0.06270052492618561
step: 200, loss: 0.030513916164636612
step: 210, loss: 0.03423872962594032
step: 220, loss: 0.05403871089220047
step: 230, loss: 0.07671856135129929
step: 240, loss: 0.013286988250911236
step: 250, loss: 0.09422696381807327
step: 260, loss: 0.07422738522291183
step: 270, loss: 0.010308775119483471
step: 280, loss: 0.06603062897920609
step: 290, loss: 0.07594842463731766
step: 300, loss: 0.01511993259191513
step: 310, loss: 0.01880495436489582
step: 320, loss: 0.01738300733268261
step: 330, loss: 0.012857154943048954
step: 340, loss: 0.012598171830177307
step: 350, loss: 0.10519442707300186
step: 360, loss: 0.016667697578668594
epoch 19: dev_f1=0.7228260869565217, f1=0.6611111111111111, best_f1=0.7506297229219143
step: 0, loss: 0.07401782274246216
step: 10, loss: 0.04030744358897209
step: 20, loss: 0.02849002741277218
step: 30, loss: 0.022485634312033653
step: 40, loss: 0.03620261326432228
step: 50, loss: 0.06678850948810577
step: 60, loss: 0.033851783722639084
step: 70, loss: 0.014127902686595917
step: 80, loss: 0.007895016111433506
step: 90, loss: 0.023308221250772476
step: 100, loss: 0.012624052353203297
step: 110, loss: 0.04104239121079445
step: 120, loss: 0.05016807094216347
step: 130, loss: 0.01145172119140625
step: 140, loss: 0.04224468395113945
step: 150, loss: 0.017780764028429985
step: 160, loss: 0.049172449856996536
step: 170, loss: 0.009608719497919083
step: 180, loss: 0.08607344329357147
step: 190, loss: 0.013859611004590988
step: 200, loss: 0.08505365252494812
step: 210, loss: 0.022800181061029434
step: 220, loss: 0.0008354024030268192
step: 230, loss: 0.10498320311307907
step: 240, loss: 0.036412157118320465
step: 250, loss: 0.05260523408651352
step: 260, loss: 0.0002446828002575785
step: 270, loss: 0.025352226570248604
step: 280, loss: 0.10030246526002884
step: 290, loss: 0.05166224017739296
step: 300, loss: 0.02705805003643036
step: 310, loss: 0.07497695833444595
step: 320, loss: 0.02843611314892769
step: 330, loss: 0.05774268880486488
step: 340, loss: 0.034602075815200806
step: 350, loss: 0.05650576204061508
step: 360, loss: 0.00015440768038388342
epoch 20: dev_f1=0.7142857142857142, f1=0.6590909090909091, best_f1=0.7506297229219143
