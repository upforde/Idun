cuda
Device: cuda
step: 0, loss: 0.6983970403671265
step: 10, loss: 0.2523561120033264
step: 20, loss: 0.14111420512199402
step: 30, loss: 0.043549228459596634
step: 40, loss: 0.15509511530399323
step: 50, loss: 0.23157359659671783
step: 60, loss: 0.14744816720485687
step: 70, loss: 0.24197524785995483
step: 80, loss: 0.14525099098682404
step: 90, loss: 0.14168208837509155
step: 100, loss: 0.05491981655359268
step: 110, loss: 0.4241733253002167
step: 120, loss: 0.22756177186965942
step: 130, loss: 0.24666224420070648
step: 140, loss: 0.31986358761787415
step: 150, loss: 0.23014596104621887
step: 160, loss: 0.4226788878440857
step: 170, loss: 0.1356401890516281
step: 180, loss: 0.04434118792414665
step: 190, loss: 0.2192165106534958
step: 200, loss: 0.13410721719264984
step: 210, loss: 0.14249356091022491
step: 220, loss: 0.1393926739692688
step: 230, loss: 0.2266780585050583
step: 240, loss: 0.36563998460769653
step: 250, loss: 0.2902173101902008
step: 260, loss: 0.027563245967030525
step: 270, loss: 0.2336324155330658
step: 280, loss: 0.07523726671934128
step: 290, loss: 0.08081280440092087
step: 300, loss: 0.1774669736623764
step: 310, loss: 0.1396990567445755
step: 320, loss: 0.20136933028697968
step: 330, loss: 0.15610449016094208
step: 340, loss: 0.15930432081222534
step: 350, loss: 0.2845975160598755
step: 360, loss: 0.13520082831382751
epoch 1: dev_f1=0.5845272206303725, f1=0.6077348066298343, best_f1=0.6077348066298343
step: 0, loss: 0.1831616312265396
step: 10, loss: 0.09238541126251221
step: 20, loss: 0.12784075736999512
step: 30, loss: 0.044458188116550446
step: 40, loss: 0.3276207149028778
step: 50, loss: 0.22243545949459076
step: 60, loss: 0.05419175326824188
step: 70, loss: 0.12031994014978409
step: 80, loss: 0.03307947516441345
step: 90, loss: 0.01291270274668932
step: 100, loss: 0.16386854648590088
step: 110, loss: 0.08347706496715546
step: 120, loss: 0.1249096542596817
step: 130, loss: 0.07348402589559555
step: 140, loss: 0.0680360198020935
step: 150, loss: 0.1352398693561554
step: 160, loss: 0.20923587679862976
step: 170, loss: 0.13166774809360504
step: 180, loss: 0.01199294999241829
step: 190, loss: 0.03061862103641033
step: 200, loss: 0.03886625915765762
step: 210, loss: 0.12714292109012604
step: 220, loss: 0.08858753740787506
step: 230, loss: 0.07750176638364792
step: 240, loss: 0.1530952751636505
step: 250, loss: 0.13004085421562195
step: 260, loss: 0.05067726969718933
step: 270, loss: 0.07264799624681473
step: 280, loss: 0.27448543906211853
step: 290, loss: 0.13962702453136444
step: 300, loss: 0.2661421000957489
step: 310, loss: 0.05425496771931648
step: 320, loss: 0.04538412019610405
step: 330, loss: 0.11815541237592697
step: 340, loss: 0.041242875158786774
step: 350, loss: 0.20851531624794006
step: 360, loss: 0.13615268468856812
epoch 2: dev_f1=0.721407624633431, f1=0.704225352112676, best_f1=0.704225352112676
step: 0, loss: 0.08709695190191269
step: 10, loss: 0.17239370942115784
step: 20, loss: 0.05758170038461685
step: 30, loss: 0.06714814156293869
step: 40, loss: 0.17539924383163452
step: 50, loss: 0.02766566537320614
step: 60, loss: 0.045323897153139114
step: 70, loss: 0.09340110421180725
step: 80, loss: 0.13017091155052185
step: 90, loss: 0.03846706449985504
step: 100, loss: 0.013135847635567188
step: 110, loss: 0.13944830000400543
step: 120, loss: 0.18464885652065277
step: 130, loss: 0.035163067281246185
step: 140, loss: 0.08861765265464783
step: 150, loss: 0.2872510552406311
step: 160, loss: 0.1321907341480255
step: 170, loss: 0.17830254137516022
step: 180, loss: 0.1063729003071785
step: 190, loss: 0.19206620752811432
step: 200, loss: 0.042383983731269836
step: 210, loss: 0.12664824724197388
step: 220, loss: 0.09613796323537827
step: 230, loss: 0.14276351034641266
step: 240, loss: 0.40279263257980347
step: 250, loss: 0.071505106985569
step: 260, loss: 0.12387201935052872
step: 270, loss: 0.1343260109424591
step: 280, loss: 0.04350299388170242
step: 290, loss: 0.118138387799263
step: 300, loss: 0.07151014357805252
step: 310, loss: 0.10869447141885757
step: 320, loss: 0.1151445284485817
step: 330, loss: 0.11749152094125748
step: 340, loss: 0.023809373378753662
step: 350, loss: 0.1552344262599945
step: 360, loss: 0.08331473171710968
epoch 3: dev_f1=0.7225130890052356, f1=0.7061855670103092, best_f1=0.7061855670103092
step: 0, loss: 0.13153699040412903
step: 10, loss: 0.07714705169200897
step: 20, loss: 0.08956149220466614
step: 30, loss: 0.06026548147201538
step: 40, loss: 0.1194261685013771
step: 50, loss: 0.02346491999924183
step: 60, loss: 0.11748920381069183
step: 70, loss: 0.07682927697896957
step: 80, loss: 0.09135151654481888
step: 90, loss: 0.1589488685131073
step: 100, loss: 0.2722509205341339
step: 110, loss: 0.05141936242580414
step: 120, loss: 0.16973461210727692
step: 130, loss: 0.08352229744195938
step: 140, loss: 0.10235145688056946
step: 150, loss: 0.09586992859840393
step: 160, loss: 0.04274755343794823
step: 170, loss: 0.1251375377178192
step: 180, loss: 0.12179718911647797
step: 190, loss: 0.07746423035860062
step: 200, loss: 0.11670669913291931
step: 210, loss: 0.026408186182379723
step: 220, loss: 0.10955417901277542
step: 230, loss: 0.05512942373752594
step: 240, loss: 0.12310580909252167
step: 250, loss: 0.14737695455551147
step: 260, loss: 0.07393438369035721
step: 270, loss: 0.09862619638442993
step: 280, loss: 0.022886402904987335
step: 290, loss: 0.17659109830856323
step: 300, loss: 0.19808967411518097
step: 310, loss: 0.10752388089895248
step: 320, loss: 0.3044067621231079
step: 330, loss: 0.1744871288537979
step: 340, loss: 0.10005716979503632
step: 350, loss: 0.15248440206050873
step: 360, loss: 0.0848207101225853
epoch 4: dev_f1=0.7345844504021448, f1=0.7142857142857143, best_f1=0.7142857142857143
step: 0, loss: 0.13660550117492676
step: 10, loss: 0.08668278902769089
step: 20, loss: 0.10259195417165756
step: 30, loss: 0.12738926708698273
step: 40, loss: 0.2646118700504303
step: 50, loss: 0.1153206005692482
step: 60, loss: 0.09580294787883759
step: 70, loss: 0.06371457874774933
step: 80, loss: 0.046698085963726044
step: 90, loss: 0.07816516607999802
step: 100, loss: 0.1183277890086174
step: 110, loss: 0.1418316513299942
step: 120, loss: 0.0984998568892479
step: 130, loss: 0.004104670602828264
step: 140, loss: 0.1619729995727539
step: 150, loss: 0.10320959240198135
step: 160, loss: 0.05869834125041962
step: 170, loss: 0.02095325104892254
step: 180, loss: 0.1415727436542511
step: 190, loss: 0.036705054342746735
step: 200, loss: 0.02831445075571537
step: 210, loss: 0.042791884392499924
step: 220, loss: 0.08132942020893097
step: 230, loss: 0.04712763801217079
step: 240, loss: 0.11616140604019165
step: 250, loss: 0.07332389801740646
step: 260, loss: 0.09097317606210709
step: 270, loss: 0.14867351949214935
step: 280, loss: 0.05801203101873398
step: 290, loss: 0.0889754593372345
step: 300, loss: 0.027153050526976585
step: 310, loss: 0.13008952140808105
step: 320, loss: 0.08951080590486526
step: 330, loss: 0.07477307319641113
step: 340, loss: 0.056807272136211395
step: 350, loss: 0.024537958204746246
step: 360, loss: 0.03519164398312569
epoch 5: dev_f1=0.7500000000000001, f1=0.7046070460704608, best_f1=0.7046070460704608
step: 0, loss: 0.1083725243806839
step: 10, loss: 0.07220149785280228
step: 20, loss: 0.16695821285247803
step: 30, loss: 0.04647064208984375
step: 40, loss: 0.07970826327800751
step: 50, loss: 0.0634165108203888
step: 60, loss: 0.04234748333692551
step: 70, loss: 0.008246677927672863
step: 80, loss: 0.06136481091380119
step: 90, loss: 0.05367887392640114
step: 100, loss: 0.06536395847797394
step: 110, loss: 0.11956489086151123
step: 120, loss: 0.0802123099565506
step: 130, loss: 0.11643234640359879
step: 140, loss: 0.027167154476046562
step: 150, loss: 0.09782444685697556
step: 160, loss: 0.05364495888352394
step: 170, loss: 0.10031451284885406
step: 180, loss: 0.055611416697502136
step: 190, loss: 0.05746793374419212
step: 200, loss: 0.06564515084028244
step: 210, loss: 0.13628600537776947
step: 220, loss: 0.021709023043513298
step: 230, loss: 0.045134905725717545
step: 240, loss: 0.032056208699941635
step: 250, loss: 0.08461605757474899
step: 260, loss: 0.03236375004053116
step: 270, loss: 0.07743905484676361
step: 280, loss: 0.0711437463760376
step: 290, loss: 0.06515266746282578
step: 300, loss: 0.17201554775238037
step: 310, loss: 0.0352834016084671
step: 320, loss: 0.09425864368677139
step: 330, loss: 0.16102588176727295
step: 340, loss: 0.03649277985095978
step: 350, loss: 0.26331716775894165
step: 360, loss: 0.04841812327504158
epoch 6: dev_f1=0.7306791569086649, f1=0.690307328605201, best_f1=0.7046070460704608
step: 0, loss: 0.05232646316289902
step: 10, loss: 0.1469692885875702
step: 20, loss: 0.10110193490982056
step: 30, loss: 0.07535586506128311
step: 40, loss: 0.07606886327266693
step: 50, loss: 0.09068069607019424
step: 60, loss: 0.04187507927417755
step: 70, loss: 0.04577255994081497
step: 80, loss: 0.13599653542041779
step: 90, loss: 0.2206394374370575
step: 100, loss: 0.12034835666418076
step: 110, loss: 0.05495613068342209
step: 120, loss: 0.08430079370737076
step: 130, loss: 0.025964166969060898
step: 140, loss: 0.249166339635849
step: 150, loss: 0.05843242630362511
step: 160, loss: 0.0003269662265665829
step: 170, loss: 0.02428581565618515
step: 180, loss: 0.09391624480485916
step: 190, loss: 0.006450022105127573
step: 200, loss: 0.06562191247940063
step: 210, loss: 0.2259838581085205
step: 220, loss: 0.05671065300703049
step: 230, loss: 0.16895954310894012
step: 240, loss: 0.07907380908727646
step: 250, loss: 0.06598274409770966
step: 260, loss: 0.054764993488788605
step: 270, loss: 0.07351798564195633
step: 280, loss: 0.021136827766895294
step: 290, loss: 0.07580539584159851
step: 300, loss: 0.09564477205276489
step: 310, loss: 0.030282681807875633
step: 320, loss: 0.07328144460916519
step: 330, loss: 0.06012675166130066
step: 340, loss: 0.07112815231084824
step: 350, loss: 0.04124688357114792
step: 360, loss: 0.021153606474399567
epoch 7: dev_f1=0.75, f1=0.7040816326530612, best_f1=0.7046070460704608
step: 0, loss: 0.1585557460784912
step: 10, loss: 0.10181940346956253
step: 20, loss: 0.0933842808008194
step: 30, loss: 0.07578247785568237
step: 40, loss: 0.05016694590449333
step: 50, loss: 0.020514560863375664
step: 60, loss: 0.10141130536794662
step: 70, loss: 0.043301235884428024
step: 80, loss: 0.06932640820741653
step: 90, loss: 0.01389299239963293
step: 100, loss: 0.15260794758796692
step: 110, loss: 0.0149840097874403
step: 120, loss: 0.051573775708675385
step: 130, loss: 0.08826521784067154
step: 140, loss: 0.13460920751094818
step: 150, loss: 0.032695889472961426
step: 160, loss: 0.06987149268388748
step: 170, loss: 0.0676102489233017
step: 180, loss: 0.030278516933321953
step: 190, loss: 0.02854120545089245
step: 200, loss: 0.12494052946567535
step: 210, loss: 0.11870504170656204
step: 220, loss: 0.13154707849025726
step: 230, loss: 0.04159018024802208
step: 240, loss: 0.04617936164140701
step: 250, loss: 0.1629321128129959
step: 260, loss: 0.09736459702253342
step: 270, loss: 0.09604305773973465
step: 280, loss: 0.051047198474407196
step: 290, loss: 0.046734850853681564
step: 300, loss: 0.09665006399154663
step: 310, loss: 0.05811743810772896
step: 320, loss: 0.13298089802265167
step: 330, loss: 0.09573448449373245
step: 340, loss: 0.2462579607963562
step: 350, loss: 0.07140612602233887
step: 360, loss: 0.12210623174905777
epoch 8: dev_f1=0.7395348837209302, f1=0.7242206235011991, best_f1=0.7046070460704608
step: 0, loss: 0.013364464044570923
step: 10, loss: 0.025512181222438812
step: 20, loss: 0.06152471527457237
step: 30, loss: 0.05913635343313217
step: 40, loss: 0.06376580893993378
step: 50, loss: 0.06905024498701096
step: 60, loss: 0.07111005485057831
step: 70, loss: 0.029169971123337746
step: 80, loss: 0.0406893752515316
step: 90, loss: 0.05524587631225586
step: 100, loss: 0.2575962245464325
step: 110, loss: 0.027315903455018997
step: 120, loss: 0.08587352186441422
step: 130, loss: 0.20440173149108887
step: 140, loss: 0.11243092268705368
step: 150, loss: 0.07132234424352646
step: 160, loss: 0.08721787482500076
step: 170, loss: 0.024591298773884773
step: 180, loss: 0.04683202877640724
step: 190, loss: 0.08593966066837311
step: 200, loss: 0.077265664935112
step: 210, loss: 0.03367676958441734
step: 220, loss: 0.1415010541677475
step: 230, loss: 0.05676213651895523
step: 240, loss: 0.10993373394012451
step: 250, loss: 0.058736830949783325
step: 260, loss: 0.07046466320753098
step: 270, loss: 0.05332887917757034
step: 280, loss: 0.03668723627924919
step: 290, loss: 0.11186660081148148
step: 300, loss: 0.045670993626117706
step: 310, loss: 0.048017293214797974
step: 320, loss: 0.07314956933259964
step: 330, loss: 0.04773012921214104
step: 340, loss: 0.12489168345928192
step: 350, loss: 0.08300599455833435
step: 360, loss: 0.20044083893299103
epoch 9: dev_f1=0.7393364928909952, f1=0.7114427860696517, best_f1=0.7046070460704608
step: 0, loss: 0.09020975977182388
step: 10, loss: 0.09943681210279465
step: 20, loss: 0.09212435036897659
step: 30, loss: 0.028926018625497818
step: 40, loss: 0.12024446576833725
step: 50, loss: 0.062136173248291016
step: 60, loss: 0.060036689043045044
step: 70, loss: 0.032284148037433624
step: 80, loss: 0.06500034034252167
step: 90, loss: 0.06368950009346008
step: 100, loss: 0.035323284566402435
step: 110, loss: 0.08780881017446518
step: 120, loss: 0.036047279834747314
step: 130, loss: 0.04499875754117966
step: 140, loss: 0.0623132586479187
step: 150, loss: 0.022835474461317062
step: 160, loss: 0.057723768055438995
step: 170, loss: 0.0908263623714447
step: 180, loss: 0.08210985362529755
step: 190, loss: 0.10262206941843033
step: 200, loss: 0.028703225776553154
step: 210, loss: 0.01325753703713417
step: 220, loss: 0.1208648532629013
step: 230, loss: 0.06609340012073517
step: 240, loss: 0.05851101875305176
step: 250, loss: 0.04122539982199669
step: 260, loss: 0.01749800704419613
step: 270, loss: 0.055724646896123886
step: 280, loss: 0.015022068284451962
step: 290, loss: 0.034014903008937836
step: 300, loss: 0.07409457117319107
step: 310, loss: 0.046915892511606216
step: 320, loss: 0.08619993925094604
step: 330, loss: 0.05181153491139412
step: 340, loss: 0.03546585515141487
step: 350, loss: 0.035968124866485596
step: 360, loss: 0.1154908537864685
epoch 10: dev_f1=0.7317073170731708, f1=0.676923076923077, best_f1=0.7046070460704608
step: 0, loss: 0.07192949205636978
step: 10, loss: 0.0016797315329313278
step: 20, loss: 0.07910648733377457
step: 30, loss: 0.05879867449402809
step: 40, loss: 0.027863813564181328
step: 50, loss: 0.04258081316947937
step: 60, loss: 0.021531006321310997
step: 70, loss: 0.052784401923418045
step: 80, loss: 0.07963748276233673
step: 90, loss: 0.020670631900429726
step: 100, loss: 6.001643123454414e-05
step: 110, loss: 0.07491622120141983
step: 120, loss: 0.07758591324090958
step: 130, loss: 0.10256372392177582
step: 140, loss: 0.1110013946890831
step: 150, loss: 0.00775041151791811
step: 160, loss: 0.03232823312282562
step: 170, loss: 0.018127774819731712
step: 180, loss: 0.10364214330911636
step: 190, loss: 0.03022409975528717
step: 200, loss: 0.07699485123157501
step: 210, loss: 0.02893858216702938
step: 220, loss: 0.05250504985451698
step: 230, loss: 0.11723008006811142
step: 240, loss: 0.008654276840388775
step: 250, loss: 0.004149723798036575
step: 260, loss: 0.021465864032506943
step: 270, loss: 0.04498537629842758
step: 280, loss: 0.04692525416612625
step: 290, loss: 0.04701872169971466
step: 300, loss: 0.09484317898750305
step: 310, loss: 0.01603379286825657
step: 320, loss: 0.11981175094842911
step: 330, loss: 0.13330945372581482
step: 340, loss: 0.023918980732560158
step: 350, loss: 0.049741461873054504
step: 360, loss: 0.03644774854183197
epoch 11: dev_f1=0.7455919395465995, f1=0.6701846965699209, best_f1=0.7046070460704608
step: 0, loss: 0.016680434346199036
step: 10, loss: 0.017528001219034195
step: 20, loss: 0.02024785801768303
step: 30, loss: 0.0577804297208786
step: 40, loss: 0.025642916560173035
step: 50, loss: 0.0735352411866188
step: 60, loss: 0.016643093898892403
step: 70, loss: 0.04989084228873253
step: 80, loss: 0.013262631371617317
step: 90, loss: 0.023635782301425934
step: 100, loss: 0.04800913482904434
step: 110, loss: 0.027934186160564423
step: 120, loss: 0.025693435221910477
step: 130, loss: 0.08620153367519379
step: 140, loss: 0.008011582307517529
step: 150, loss: 0.0394546203315258
step: 160, loss: 0.01655929535627365
step: 170, loss: 0.010058039799332619
step: 180, loss: 0.09775491058826447
step: 190, loss: 0.02287321537733078
step: 200, loss: 0.06601107865571976
step: 210, loss: 0.05263536050915718
step: 220, loss: 0.00019174115732312202
step: 230, loss: 0.0757417306303978
step: 240, loss: 0.11790943890810013
step: 250, loss: 0.14871717989444733
step: 260, loss: 0.03709542378783226
step: 270, loss: 0.13101282715797424
step: 280, loss: 0.07323023676872253
step: 290, loss: 0.06177607178688049
step: 300, loss: 0.11587260663509369
step: 310, loss: 0.14250943064689636
step: 320, loss: 0.08588492125272751
step: 330, loss: 0.05257662385702133
step: 340, loss: 0.02942739427089691
step: 350, loss: 0.06259296089410782
step: 360, loss: 0.09584034979343414
epoch 12: dev_f1=0.7315914489311164, f1=0.6921241050119331, best_f1=0.7046070460704608
step: 0, loss: 0.09289787709712982
step: 10, loss: 0.03334515169262886
step: 20, loss: 0.10295537114143372
step: 30, loss: 0.060889530926942825
step: 40, loss: 0.04607873409986496
step: 50, loss: 0.033229682594537735
step: 60, loss: 0.057081498205661774
step: 70, loss: 0.03599989414215088
step: 80, loss: 0.04648634418845177
step: 90, loss: 0.07193312048912048
step: 100, loss: 0.11040996760129929
step: 110, loss: 0.035416826605796814
step: 120, loss: 0.05834343656897545
step: 130, loss: 0.017605312168598175
step: 140, loss: 8.058606181293726e-05
step: 150, loss: 0.09531930834054947
step: 160, loss: 0.11112963408231735
step: 170, loss: 0.1146516352891922
step: 180, loss: 0.0030966841150075197
step: 190, loss: 0.21317198872566223
step: 200, loss: 0.09640966355800629
step: 210, loss: 0.06577756255865097
step: 220, loss: 0.04774557799100876
step: 230, loss: 0.03177233785390854
step: 240, loss: 0.08652529865503311
step: 250, loss: 0.06333444267511368
step: 260, loss: 0.03272825479507446
step: 270, loss: 0.014668344520032406
step: 280, loss: 0.03339631110429764
step: 290, loss: 0.049265455454587936
step: 300, loss: 0.0984761044383049
step: 310, loss: 0.05378323793411255
step: 320, loss: 0.00829953234642744
step: 330, loss: 0.09114721417427063
step: 340, loss: 0.04708433896303177
step: 350, loss: 0.04629756510257721
step: 360, loss: 0.03981512784957886
epoch 13: dev_f1=0.7207207207207207, f1=0.6504424778761062, best_f1=0.7046070460704608
step: 0, loss: 0.14717289805412292
step: 10, loss: 0.054365675896406174
step: 20, loss: 0.010912911035120487
step: 30, loss: 0.022209040820598602
step: 40, loss: 0.1198325902223587
step: 50, loss: 0.010855968110263348
step: 60, loss: 0.040571123361587524
step: 70, loss: 0.03790242224931717
step: 80, loss: 0.029979828745126724
step: 90, loss: 0.032794851809740067
step: 100, loss: 0.03459110110998154
step: 110, loss: 0.0931030884385109
step: 120, loss: 0.10558390617370605
step: 130, loss: 0.07946974039077759
step: 140, loss: 0.0322585366666317
step: 150, loss: 0.022848429158329964
step: 160, loss: 0.06201872602105141
step: 170, loss: 8.05930612841621e-05
step: 180, loss: 0.06860634684562683
step: 190, loss: 0.020880024880170822
step: 200, loss: 0.035670869052410126
step: 210, loss: 0.08153262734413147
step: 220, loss: 0.03998928144574165
step: 230, loss: 0.029878124594688416
step: 240, loss: 0.0998978465795517
step: 250, loss: 0.05552534759044647
step: 260, loss: 0.025605348870158195
step: 270, loss: 0.011078058741986752
step: 280, loss: 0.00817364826798439
step: 290, loss: 0.12437357753515244
step: 300, loss: 0.07143958657979965
step: 310, loss: 0.01168789155781269
step: 320, loss: 0.06972010433673859
step: 330, loss: 0.13242582976818085
step: 340, loss: 2.2206113499123603e-05
step: 350, loss: 0.0030723526142537594
step: 360, loss: 0.0525081492960453
epoch 14: dev_f1=0.7338501291989663, f1=0.6666666666666667, best_f1=0.7046070460704608
step: 0, loss: 0.03257037699222565
step: 10, loss: 0.06998835504055023
step: 20, loss: 0.05911168083548546
step: 30, loss: 0.00019665104628074914
step: 40, loss: 0.01495621632784605
step: 50, loss: 0.021461835131049156
step: 60, loss: 0.056957606226205826
step: 70, loss: 0.03260062262415886
step: 80, loss: 0.045809224247932434
step: 90, loss: 0.02446589805185795
step: 100, loss: 0.0782422125339508
step: 110, loss: 0.1464313268661499
step: 120, loss: 0.02778225764632225
step: 130, loss: 0.06077408790588379
step: 140, loss: 0.039938025176525116
step: 150, loss: 0.04405176639556885
step: 160, loss: 0.04618951678276062
step: 170, loss: 0.0784878209233284
step: 180, loss: 0.007684933952987194
step: 190, loss: 0.06620092689990997
step: 200, loss: 0.019122198224067688
step: 210, loss: 0.024179842323064804
step: 220, loss: 0.05983627960085869
step: 230, loss: 0.04547709971666336
step: 240, loss: 0.04049965739250183
step: 250, loss: 3.251710222684778e-05
step: 260, loss: 0.027406595647335052
step: 270, loss: 0.07725515961647034
step: 280, loss: 0.09438718110322952
step: 290, loss: 0.09285473078489304
step: 300, loss: 0.02988646924495697
step: 310, loss: 0.012760387733578682
step: 320, loss: 0.012612808495759964
step: 330, loss: 0.058582603931427
step: 340, loss: 0.01247237715870142
step: 350, loss: 0.005771450698375702
step: 360, loss: 0.03743579611182213
epoch 15: dev_f1=0.7346938775510203, f1=0.6863270777479893, best_f1=0.7046070460704608
step: 0, loss: 0.03219342604279518
step: 10, loss: 0.0003170770360156894
step: 20, loss: 0.12091416865587234
step: 30, loss: 0.021695664152503014
step: 40, loss: 0.03325149789452553
step: 50, loss: 0.008604130707681179
step: 60, loss: 0.05695075914263725
step: 70, loss: 0.09185367822647095
step: 80, loss: 0.003814809024333954
step: 90, loss: 0.055281076580286026
step: 100, loss: 0.1289544701576233
step: 110, loss: 0.07167212665081024
step: 120, loss: 0.06711561977863312
step: 130, loss: 0.03286578133702278
step: 140, loss: 0.12836286425590515
step: 150, loss: 0.022499941289424896
step: 160, loss: 0.04516364261507988
step: 170, loss: 0.013148766942322254
step: 180, loss: 0.008383725769817829
step: 190, loss: 0.07744389772415161
step: 200, loss: 0.0035434432793408632
step: 210, loss: 0.03747006878256798
step: 220, loss: 0.15978915989398956
step: 230, loss: 0.016311611980199814
step: 240, loss: 0.012787756510078907
step: 250, loss: 0.10561177134513855
step: 260, loss: 0.015258798375725746
step: 270, loss: 0.23489004373550415
step: 280, loss: 0.05780656635761261
step: 290, loss: 0.1226440966129303
step: 300, loss: 0.020094402134418488
step: 310, loss: 0.04711407795548439
step: 320, loss: 0.04684882238507271
step: 330, loss: 0.03585054725408554
step: 340, loss: 0.021019890904426575
step: 350, loss: 0.0067752655595541
step: 360, loss: 0.03798797354102135
epoch 16: dev_f1=0.7447916666666665, f1=0.7018469656992085, best_f1=0.7046070460704608
step: 0, loss: 0.029859522357583046
step: 10, loss: 0.1171635165810585
step: 20, loss: 0.03979545086622238
step: 30, loss: 0.012423451989889145
step: 40, loss: 0.02575267106294632
step: 50, loss: 0.031821396201848984
step: 60, loss: 0.0004804790369234979
step: 70, loss: 0.00011377032205928117
step: 80, loss: 0.05500931292772293
step: 90, loss: 5.74266305193305e-05
step: 100, loss: 0.07172955572605133
step: 110, loss: 0.026667967438697815
step: 120, loss: 0.05343062803149223
step: 130, loss: 0.004721373785287142
step: 140, loss: 0.1341228485107422
step: 150, loss: 0.0005889092572033405
step: 160, loss: 0.05509398132562637
step: 170, loss: 0.009053233079612255
step: 180, loss: 0.005585919599980116
step: 190, loss: 0.046612463891506195
step: 200, loss: 0.1319298893213272
step: 210, loss: 0.0796951949596405
step: 220, loss: 0.025893330574035645
step: 230, loss: 0.029590528458356857
step: 240, loss: 0.027785537764430046
step: 250, loss: 0.0594797357916832
step: 260, loss: 0.08027735352516174
step: 270, loss: 0.013974210247397423
step: 280, loss: 0.08741412311792374
step: 290, loss: 0.04320541396737099
step: 300, loss: 0.017977459356188774
step: 310, loss: 0.01884903945028782
step: 320, loss: 0.124204620718956
step: 330, loss: 0.026076871901750565
step: 340, loss: 0.07506450265645981
step: 350, loss: 0.04467299208045006
step: 360, loss: 0.12326670438051224
epoch 17: dev_f1=0.7379134860050889, f1=0.6870229007633588, best_f1=0.7046070460704608
step: 0, loss: 0.042586516588926315
step: 10, loss: 0.00029530833126045763
step: 20, loss: 0.023632464930415154
step: 30, loss: 0.0541677325963974
step: 40, loss: 0.020725857466459274
step: 50, loss: 0.005078619811683893
step: 60, loss: 0.04352109134197235
step: 70, loss: 0.06281650066375732
step: 80, loss: 0.02391389198601246
step: 90, loss: 0.07925578951835632
step: 100, loss: 0.026151174679398537
step: 110, loss: 0.012834548018872738
step: 120, loss: 0.018897391855716705
step: 130, loss: 0.014152878895401955
step: 140, loss: 0.005397236905992031
step: 150, loss: 0.01651116833090782
step: 160, loss: 0.0006572204874828458
step: 170, loss: 0.00029513443587347865
step: 180, loss: 0.029393162578344345
step: 190, loss: 0.05126466974616051
step: 200, loss: 0.07567209005355835
step: 210, loss: 0.08184923976659775
step: 220, loss: 0.0011558562982827425
step: 230, loss: 0.023320479318499565
step: 240, loss: 0.11436391621828079
step: 250, loss: 0.044052597135305405
step: 260, loss: 0.02419443055987358
step: 270, loss: 0.03481993451714516
step: 280, loss: 0.020055850967764854
step: 290, loss: 0.0895860344171524
step: 300, loss: 0.1067630797624588
step: 310, loss: 0.02271462418138981
step: 320, loss: 0.02269783243536949
step: 330, loss: 0.034292273223400116
step: 340, loss: 3.449829091550782e-05
step: 350, loss: 0.059682972729206085
step: 360, loss: 0.04038095474243164
epoch 18: dev_f1=0.7373737373737375, f1=0.6821705426356589, best_f1=0.7046070460704608
step: 0, loss: 0.045307308435440063
step: 10, loss: 0.09058113396167755
step: 20, loss: 0.013641423545777798
step: 30, loss: 0.0595809742808342
step: 40, loss: 0.015389308333396912
step: 50, loss: 0.042897846549749374
step: 60, loss: 0.005913423374295235
step: 70, loss: 0.01462389063090086
step: 80, loss: 0.02298511378467083
step: 90, loss: 0.004515794571489096
step: 100, loss: 0.038135841488838196
step: 110, loss: 0.08128514885902405
step: 120, loss: 0.046497639268636703
step: 130, loss: 0.06946083903312683
step: 140, loss: 0.034149155020713806
step: 150, loss: 0.0608920194208622
step: 160, loss: 0.2247752845287323
step: 170, loss: 0.04427090659737587
step: 180, loss: 0.04793824627995491
step: 190, loss: 0.04910716041922569
step: 200, loss: 0.010802428238093853
step: 210, loss: 0.011213412508368492
step: 220, loss: 0.05383693799376488
step: 230, loss: 0.0002554692036937922
step: 240, loss: 0.025373047217726707
step: 250, loss: 0.022330231964588165
step: 260, loss: 0.04094832018017769
step: 270, loss: 0.029727187007665634
step: 280, loss: 0.014346040785312653
step: 290, loss: 0.04551444947719574
step: 300, loss: 0.01648564077913761
step: 310, loss: 0.08940035849809647
step: 320, loss: 0.07772024720907211
step: 330, loss: 0.0049341232515871525
step: 340, loss: 0.007597319781780243
step: 350, loss: 0.050646934658288956
step: 360, loss: 0.01053653284907341
epoch 19: dev_f1=0.736842105263158, f1=0.6735218508997428, best_f1=0.7046070460704608
step: 0, loss: 0.014210203662514687
step: 10, loss: 0.0335768423974514
step: 20, loss: 0.03287350386381149
step: 30, loss: 0.06764721125364304
step: 40, loss: 0.017962466925382614
step: 50, loss: 0.013625793159008026
step: 60, loss: 0.0006267947028391063
step: 70, loss: 0.020825140178203583
step: 80, loss: 0.04820771515369415
step: 90, loss: 0.01306205615401268
step: 100, loss: 0.0034193156752735376
step: 110, loss: 0.000574186909943819
step: 120, loss: 0.0009000074351206422
step: 130, loss: 0.07077204436063766
step: 140, loss: 0.07186360657215118
step: 150, loss: 0.03059707023203373
step: 160, loss: 0.009649185463786125
step: 170, loss: 0.05229443684220314
step: 180, loss: 0.08427241444587708
step: 190, loss: 0.015594840981066227
step: 200, loss: 0.019848309457302094
step: 210, loss: 0.027669068425893784
step: 220, loss: 0.002109286142513156
step: 230, loss: 0.09614896774291992
step: 240, loss: 0.025883354246616364
step: 250, loss: 0.0017183361342176795
step: 260, loss: 0.008621951565146446
step: 270, loss: 0.027092762291431427
step: 280, loss: 0.012483501806855202
step: 290, loss: 0.0461839959025383
step: 300, loss: 0.04640910401940346
step: 310, loss: 0.019208863377571106
step: 320, loss: 2.162872624467127e-05
step: 330, loss: 0.02885729819536209
step: 340, loss: 0.03883884847164154
step: 350, loss: 0.022899080067873
step: 360, loss: 0.03508119285106659
epoch 20: dev_f1=0.7319587628865978, f1=0.6702412868632708, best_f1=0.7046070460704608
