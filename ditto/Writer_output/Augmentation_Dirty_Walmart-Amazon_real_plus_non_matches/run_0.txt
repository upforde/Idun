cuda
Device: cuda
step: 0, loss: 0.44919219613075256
step: 10, loss: 0.14969342947006226
step: 20, loss: 0.3090224862098694
step: 30, loss: 0.14738087356090546
step: 40, loss: 0.1439843475818634
step: 50, loss: 0.14614365994930267
step: 60, loss: 0.221457377076149
step: 70, loss: 0.29577094316482544
step: 80, loss: 0.3046160340309143
step: 90, loss: 0.3551802337169647
step: 100, loss: 0.1418735682964325
step: 110, loss: 0.12228331714868546
step: 120, loss: 0.1225762888789177
step: 130, loss: 0.3287815451622009
step: 140, loss: 0.2041362076997757
step: 150, loss: 0.022730519995093346
step: 160, loss: 0.29586464166641235
step: 170, loss: 0.22497636079788208
step: 180, loss: 0.03520561009645462
step: 190, loss: 0.11945963650941849
step: 200, loss: 0.06773896515369415
step: 210, loss: 0.01953515037894249
step: 220, loss: 0.04905668646097183
step: 230, loss: 0.3632461428642273
step: 240, loss: 0.1345594823360443
step: 250, loss: 0.13284829258918762
step: 260, loss: 0.0891522541642189
step: 270, loss: 0.1325439214706421
step: 280, loss: 0.02353309653699398
step: 290, loss: 0.1993798464536667
step: 300, loss: 0.09764101356267929
step: 310, loss: 0.22063377499580383
step: 320, loss: 0.16611343622207642
step: 330, loss: 0.3358893096446991
step: 340, loss: 0.04242275282740593
step: 350, loss: 0.11557243764400482
step: 360, loss: 0.25885117053985596
epoch 1: dev_f1=0.6065573770491802, f1=0.6170798898071626, best_f1=0.6170798898071626
step: 0, loss: 0.04495307803153992
step: 10, loss: 0.21970678865909576
step: 20, loss: 0.1423209011554718
step: 30, loss: 0.062326401472091675
step: 40, loss: 0.2876415550708771
step: 50, loss: 0.023137716576457024
step: 60, loss: 0.09440393000841141
step: 70, loss: 0.07546249032020569
step: 80, loss: 0.252651572227478
step: 90, loss: 0.16296932101249695
step: 100, loss: 0.023294983431696892
step: 110, loss: 0.09861540049314499
step: 120, loss: 0.08710166066884995
step: 130, loss: 0.13667277991771698
step: 140, loss: 0.22335855662822723
step: 150, loss: 0.07168833911418915
step: 160, loss: 0.2788006067276001
step: 170, loss: 0.03749726712703705
step: 180, loss: 0.11004380136728287
step: 190, loss: 0.08745961636304855
step: 200, loss: 0.10498499870300293
step: 210, loss: 0.058175042271614075
step: 220, loss: 0.0446353405714035
step: 230, loss: 0.2163902074098587
step: 240, loss: 0.22193805873394012
step: 250, loss: 0.11075259000062943
step: 260, loss: 0.26690050959587097
step: 270, loss: 0.151358962059021
step: 280, loss: 0.12740707397460938
step: 290, loss: 0.013042444363236427
step: 300, loss: 0.12937407195568085
step: 310, loss: 0.07786976546049118
step: 320, loss: 0.1570747345685959
step: 330, loss: 0.0667610839009285
step: 340, loss: 0.1214764267206192
step: 350, loss: 0.26950767636299133
step: 360, loss: 0.11186552047729492
epoch 2: dev_f1=0.6631578947368421, f1=0.6717557251908398, best_f1=0.6717557251908398
step: 0, loss: 0.2704300880432129
step: 10, loss: 0.14701659977436066
step: 20, loss: 0.16070574522018433
step: 30, loss: 0.08898665755987167
step: 40, loss: 0.07782187312841415
step: 50, loss: 0.15160486102104187
step: 60, loss: 0.22719039022922516
step: 70, loss: 0.04287633299827576
step: 80, loss: 0.058885905891656876
step: 90, loss: 0.1231762170791626
step: 100, loss: 0.11310134083032608
step: 110, loss: 0.18664272129535675
step: 120, loss: 0.1550246626138687
step: 130, loss: 0.1570255160331726
step: 140, loss: 0.0996728241443634
step: 150, loss: 0.2696560025215149
step: 160, loss: 0.0998651459813118
step: 170, loss: 0.17847579717636108
step: 180, loss: 0.07043270766735077
step: 190, loss: 0.09704452753067017
step: 200, loss: 0.11823996156454086
step: 210, loss: 0.15114888548851013
step: 220, loss: 0.179012268781662
step: 230, loss: 0.002456331392750144
step: 240, loss: 0.07685644924640656
step: 250, loss: 0.1627410352230072
step: 260, loss: 0.018396254628896713
step: 270, loss: 0.07291395217180252
step: 280, loss: 0.09549830853939056
step: 290, loss: 0.11813416332006454
step: 300, loss: 0.17841699719429016
step: 310, loss: 0.14094959199428558
step: 320, loss: 0.06985940784215927
step: 330, loss: 0.11987145990133286
step: 340, loss: 0.062431443482637405
step: 350, loss: 0.2012234777212143
step: 360, loss: 0.07190480828285217
epoch 3: dev_f1=0.7158469945355191, f1=0.7115902964959568, best_f1=0.7115902964959568
step: 0, loss: 0.03997495770454407
step: 10, loss: 0.16508807241916656
step: 20, loss: 0.23798486590385437
step: 30, loss: 0.11697235703468323
step: 40, loss: 0.12029264867305756
step: 50, loss: 0.0833260715007782
step: 60, loss: 0.07023149728775024
step: 70, loss: 0.13496918976306915
step: 80, loss: 0.119465172290802
step: 90, loss: 0.0992937833070755
step: 100, loss: 0.10262274742126465
step: 110, loss: 0.07257732003927231
step: 120, loss: 0.18359577655792236
step: 130, loss: 0.15315547585487366
step: 140, loss: 0.02375486120581627
step: 150, loss: 0.016638658940792084
step: 160, loss: 0.05751108378171921
step: 170, loss: 0.016900943592190742
step: 180, loss: 0.03261628746986389
step: 190, loss: 0.13873575627803802
step: 200, loss: 0.15093639492988586
step: 210, loss: 0.04670094698667526
step: 220, loss: 0.037901826202869415
step: 230, loss: 0.11903609335422516
step: 240, loss: 0.12280050665140152
step: 250, loss: 0.06952638179063797
step: 260, loss: 0.06604871153831482
step: 270, loss: 0.044733211398124695
step: 280, loss: 0.0369817279279232
step: 290, loss: 0.16055814921855927
step: 300, loss: 0.32304126024246216
step: 310, loss: 0.09777615964412689
step: 320, loss: 0.16348397731781006
step: 330, loss: 0.0453948974609375
step: 340, loss: 0.09697752445936203
step: 350, loss: 0.04122142493724823
step: 360, loss: 0.05220075696706772
epoch 4: dev_f1=0.7277108433734939, f1=0.7096774193548386, best_f1=0.7096774193548386
step: 0, loss: 0.06508085131645203
step: 10, loss: 0.08956819772720337
step: 20, loss: 0.1386551409959793
step: 30, loss: 0.08022341132164001
step: 40, loss: 0.03749343007802963
step: 50, loss: 0.18489883840084076
step: 60, loss: 0.06498435884714127
step: 70, loss: 0.10551727563142776
step: 80, loss: 0.04824843257665634
step: 90, loss: 0.023563403636217117
step: 100, loss: 0.148626446723938
step: 110, loss: 0.2552628517150879
step: 120, loss: 0.07881913334131241
step: 130, loss: 0.07566999644041061
step: 140, loss: 0.029515748843550682
step: 150, loss: 0.017841840162873268
step: 160, loss: 0.11793503910303116
step: 170, loss: 0.03168360888957977
step: 180, loss: 0.06909587234258652
step: 190, loss: 0.04236168786883354
step: 200, loss: 0.026338515803217888
step: 210, loss: 0.06124351918697357
step: 220, loss: 0.07906561344861984
step: 230, loss: 0.12244652211666107
step: 240, loss: 0.11846978962421417
step: 250, loss: 0.1513323187828064
step: 260, loss: 0.22945494949817657
step: 270, loss: 0.08448631316423416
step: 280, loss: 0.14251098036766052
step: 290, loss: 0.27886244654655457
step: 300, loss: 0.08938401937484741
step: 310, loss: 0.09914703667163849
step: 320, loss: 0.035024624317884445
step: 330, loss: 0.10418813675642014
step: 340, loss: 0.19908739626407623
step: 350, loss: 0.14909584820270538
step: 360, loss: 0.1706281453371048
epoch 5: dev_f1=0.7242206235011991, f1=0.6829268292682926, best_f1=0.7096774193548386
step: 0, loss: 0.09833402931690216
step: 10, loss: 0.016949636861681938
step: 20, loss: 0.02883063443005085
step: 30, loss: 0.06753789633512497
step: 40, loss: 0.05185702070593834
step: 50, loss: 0.14021435379981995
step: 60, loss: 0.10527380555868149
step: 70, loss: 0.09826156497001648
step: 80, loss: 0.07836305350065231
step: 90, loss: 0.037542324513196945
step: 100, loss: 0.15769849717617035
step: 110, loss: 0.1283968687057495
step: 120, loss: 0.11960968375205994
step: 130, loss: 0.11025228351354599
step: 140, loss: 0.06163199990987778
step: 150, loss: 0.08403092622756958
step: 160, loss: 0.05369209870696068
step: 170, loss: 0.09645487368106842
step: 180, loss: 0.12226206809282303
step: 190, loss: 0.06347385048866272
step: 200, loss: 0.09996362030506134
step: 210, loss: 0.021886087954044342
step: 220, loss: 0.10359808057546616
step: 230, loss: 0.06502614915370941
step: 240, loss: 0.07083722203969955
step: 250, loss: 0.03411252051591873
step: 260, loss: 0.05706844478845596
step: 270, loss: 0.1654180884361267
step: 280, loss: 0.12310642004013062
step: 290, loss: 0.23255398869514465
step: 300, loss: 0.08305779844522476
step: 310, loss: 0.180373877286911
step: 320, loss: 0.13900147378444672
step: 330, loss: 0.05558972433209419
step: 340, loss: 0.0753202736377716
step: 350, loss: 0.0003209912101738155
step: 360, loss: 0.11240512877702713
epoch 6: dev_f1=0.7389162561576355, f1=0.7344913151364764, best_f1=0.7344913151364764
step: 0, loss: 0.1762334704399109
step: 10, loss: 0.09486816078424454
step: 20, loss: 0.022773606702685356
step: 30, loss: 0.08072415739297867
step: 40, loss: 0.041557446122169495
step: 50, loss: 0.04548845440149307
step: 60, loss: 0.019762657582759857
step: 70, loss: 0.07137182354927063
step: 80, loss: 0.04309836030006409
step: 90, loss: 0.16780252754688263
step: 100, loss: 0.0003215832985006273
step: 110, loss: 0.12994132936000824
step: 120, loss: 0.033146098256111145
step: 130, loss: 0.30935460329055786
step: 140, loss: 0.07030679285526276
step: 150, loss: 0.13178499042987823
step: 160, loss: 0.07042212039232254
step: 170, loss: 0.0341009683907032
step: 180, loss: 0.03507082536816597
step: 190, loss: 0.05865366384387016
step: 200, loss: 0.11188427358865738
step: 210, loss: 0.07545441389083862
step: 220, loss: 0.13860850036144257
step: 230, loss: 0.07699143886566162
step: 240, loss: 0.02837948314845562
step: 250, loss: 0.04520481824874878
step: 260, loss: 0.02327233925461769
step: 270, loss: 0.02912130206823349
step: 280, loss: 0.09063026309013367
step: 290, loss: 0.06324109435081482
step: 300, loss: 0.057945676147937775
step: 310, loss: 0.08818695694208145
step: 320, loss: 0.03681972622871399
step: 330, loss: 0.10479748994112015
step: 340, loss: 0.1195174977183342
step: 350, loss: 0.0718136578798294
step: 360, loss: 0.11006642132997513
epoch 7: dev_f1=0.7300771208226221, f1=0.739795918367347, best_f1=0.7344913151364764
step: 0, loss: 0.13132308423519135
step: 10, loss: 0.09738465398550034
step: 20, loss: 0.04564286023378372
step: 30, loss: 0.060302652418613434
step: 40, loss: 0.0642344206571579
step: 50, loss: 0.036421097815036774
step: 60, loss: 0.12230788171291351
step: 70, loss: 0.045017044991254807
step: 80, loss: 0.06879405677318573
step: 90, loss: 0.044544246047735214
step: 100, loss: 0.06475740671157837
step: 110, loss: 0.16319896280765533
step: 120, loss: 0.06668324768543243
step: 130, loss: 0.08216780424118042
step: 140, loss: 0.07668465375900269
step: 150, loss: 0.14381638169288635
step: 160, loss: 0.05765334889292717
step: 170, loss: 0.06848834455013275
step: 180, loss: 0.0734691172838211
step: 190, loss: 0.10382571071386337
step: 200, loss: 0.029367681592702866
step: 210, loss: 0.0769098773598671
step: 220, loss: 0.0565415620803833
step: 230, loss: 0.10665235668420792
step: 240, loss: 0.08212307095527649
step: 250, loss: 0.12620176374912262
step: 260, loss: 0.10413636267185211
step: 270, loss: 0.05302100628614426
step: 280, loss: 0.05561024323105812
step: 290, loss: 0.05985676497220993
step: 300, loss: 0.19295154511928558
step: 310, loss: 0.03209657222032547
step: 320, loss: 0.07473187893629074
step: 330, loss: 0.21386340260505676
step: 340, loss: 0.08259216696023941
step: 350, loss: 0.09538349509239197
step: 360, loss: 0.141421377658844
epoch 8: dev_f1=0.711217183770883, f1=0.7011764705882353, best_f1=0.7344913151364764
step: 0, loss: 0.10195613652467728
step: 10, loss: 0.12139400839805603
step: 20, loss: 0.0020903998520225286
step: 30, loss: 0.07109834998846054
step: 40, loss: 0.043740130960941315
step: 50, loss: 0.032223448157310486
step: 60, loss: 0.10999187082052231
step: 70, loss: 0.08891430497169495
step: 80, loss: 0.08228234201669693
step: 90, loss: 0.0005922947893850505
step: 100, loss: 0.021724112331867218
step: 110, loss: 0.07649046182632446
step: 120, loss: 0.07474211603403091
step: 130, loss: 0.017513711005449295
step: 140, loss: 0.04428039491176605
step: 150, loss: 0.06177785247564316
step: 160, loss: 0.11967206746339798
step: 170, loss: 0.0809534564614296
step: 180, loss: 0.06943000853061676
step: 190, loss: 0.03513774648308754
step: 200, loss: 0.0582001693546772
step: 210, loss: 0.003673896426334977
step: 220, loss: 0.056664880365133286
step: 230, loss: 0.07796452939510345
step: 240, loss: 0.1328393518924713
step: 250, loss: 0.05552442744374275
step: 260, loss: 0.0761990025639534
step: 270, loss: 0.04571900516748428
step: 280, loss: 0.22408859431743622
step: 290, loss: 0.08051177859306335
step: 300, loss: 0.08686909079551697
step: 310, loss: 0.046329062432050705
step: 320, loss: 0.09585065394639969
step: 330, loss: 0.04483817517757416
step: 340, loss: 0.04793909564614296
step: 350, loss: 0.026298590004444122
step: 360, loss: 0.13966698944568634
epoch 9: dev_f1=0.7668393782383419, f1=0.7428571428571429, best_f1=0.7428571428571429
step: 0, loss: 0.07661858201026917
step: 10, loss: 0.05070562660694122
step: 20, loss: 0.04508161172270775
step: 30, loss: 0.123082235455513
step: 40, loss: 0.04240761697292328
step: 50, loss: 0.1251983940601349
step: 60, loss: 0.07587600499391556
step: 70, loss: 0.02127794176340103
step: 80, loss: 0.035039547830820084
step: 90, loss: 0.049194201827049255
step: 100, loss: 0.0013775007100775838
step: 110, loss: 0.06255937367677689
step: 120, loss: 0.021085401996970177
step: 130, loss: 0.029612518846988678
step: 140, loss: 0.02137380838394165
step: 150, loss: 0.10318038612604141
step: 160, loss: 0.10470781475305557
step: 170, loss: 0.061490610241889954
step: 180, loss: 0.04255875572562218
step: 190, loss: 0.0647302195429802
step: 200, loss: 0.06474541872739792
step: 210, loss: 0.05286865308880806
step: 220, loss: 0.045424941927194595
step: 230, loss: 0.0573900043964386
step: 240, loss: 0.035175006836652756
step: 250, loss: 0.023291559889912605
step: 260, loss: 0.003614393062889576
step: 270, loss: 0.09249891340732574
step: 280, loss: 0.15079399943351746
step: 290, loss: 0.021682851016521454
step: 300, loss: 0.00788811594247818
step: 310, loss: 0.025600140914320946
step: 320, loss: 0.08228559792041779
step: 330, loss: 0.0982559397816658
step: 340, loss: 0.16180598735809326
step: 350, loss: 0.025791307911276817
step: 360, loss: 0.07109647989273071
epoch 10: dev_f1=0.7540106951871658, f1=0.7244094488188976, best_f1=0.7428571428571429
step: 0, loss: 0.06662056595087051
step: 10, loss: 0.07118866592645645
step: 20, loss: 0.03080124408006668
step: 30, loss: 0.01716826669871807
step: 40, loss: 0.023796996101737022
step: 50, loss: 0.060842014849185944
step: 60, loss: 0.12063722312450409
step: 70, loss: 0.062046896666288376
step: 80, loss: 0.0958901047706604
step: 90, loss: 0.2750731408596039
step: 100, loss: 0.04024432972073555
step: 110, loss: 0.00044861200149171054
step: 120, loss: 0.0816885381937027
step: 130, loss: 5.1135331887053326e-05
step: 140, loss: 0.08745650202035904
step: 150, loss: 0.03121791034936905
step: 160, loss: 0.09353457391262054
step: 170, loss: 0.037189874798059464
step: 180, loss: 0.05048574134707451
step: 190, loss: 0.16835002601146698
step: 200, loss: 0.03802259638905525
step: 210, loss: 0.0401519350707531
step: 220, loss: 0.01976221799850464
step: 230, loss: 0.019232990220189095
step: 240, loss: 0.06616824865341187
step: 250, loss: 0.04404693469405174
step: 260, loss: 0.0676853209733963
step: 270, loss: 0.04839964583516121
step: 280, loss: 0.044202569872140884
step: 290, loss: 0.1874401867389679
step: 300, loss: 0.13600781559944153
step: 310, loss: 0.0934179276227951
step: 320, loss: 0.05779818817973137
step: 330, loss: 0.05329558625817299
step: 340, loss: 0.05810227990150452
step: 350, loss: 0.049876607954502106
step: 360, loss: 0.0399511493742466
epoch 11: dev_f1=0.7117794486215538, f1=0.6997518610421836, best_f1=0.7428571428571429
step: 0, loss: 0.024017833173274994
step: 10, loss: 0.06402351707220078
step: 20, loss: 0.07158245891332626
step: 30, loss: 0.113399438560009
step: 40, loss: 0.052980873733758926
step: 50, loss: 0.08037010580301285
step: 60, loss: 0.06861187517642975
step: 70, loss: 0.05120483785867691
step: 80, loss: 0.018970495089888573
step: 90, loss: 0.05015480890870094
step: 100, loss: 0.009914739988744259
step: 110, loss: 0.17453037202358246
step: 120, loss: 3.169760384480469e-05
step: 130, loss: 0.2527194023132324
step: 140, loss: 0.005954396445304155
step: 150, loss: 0.045622218400239944
step: 160, loss: 0.05797521770000458
step: 170, loss: 0.13213618099689484
step: 180, loss: 0.16557836532592773
step: 190, loss: 0.10406550765037537
step: 200, loss: 0.09673729538917542
step: 210, loss: 0.0655636116862297
step: 220, loss: 0.05504960939288139
step: 230, loss: 0.024156901985406876
step: 240, loss: 0.14265307784080505
step: 250, loss: 0.07613097876310349
step: 260, loss: 0.06665297597646713
step: 270, loss: 0.07294794917106628
step: 280, loss: 0.09727124869823456
step: 290, loss: 0.05767713487148285
step: 300, loss: 0.03486419469118118
step: 310, loss: 0.14380156993865967
step: 320, loss: 0.11977687478065491
step: 330, loss: 0.0537550151348114
step: 340, loss: 0.08266299217939377
step: 350, loss: 0.02782451920211315
step: 360, loss: 0.06817387044429779
epoch 12: dev_f1=0.735576923076923, f1=0.7220902612826603, best_f1=0.7428571428571429
step: 0, loss: 0.022683467715978622
step: 10, loss: 0.058667391538619995
step: 20, loss: 0.11654427647590637
step: 30, loss: 0.08339767158031464
step: 40, loss: 0.07808705419301987
step: 50, loss: 0.11903833597898483
step: 60, loss: 0.09273408353328705
step: 70, loss: 0.00015397901006508619
step: 80, loss: 0.02874097041785717
step: 90, loss: 0.09171958267688751
step: 100, loss: 0.025310195982456207
step: 110, loss: 0.04403230547904968
step: 120, loss: 0.07171975076198578
step: 130, loss: 0.0024508319329470396
step: 140, loss: 0.1537070870399475
step: 150, loss: 0.06282855570316315
step: 160, loss: 0.06387407332658768
step: 170, loss: 0.002949054818600416
step: 180, loss: 0.05961886793375015
step: 190, loss: 0.0941530168056488
step: 200, loss: 0.1479034423828125
step: 210, loss: 0.13867627084255219
step: 220, loss: 0.04492994770407677
step: 230, loss: 0.09716350585222244
step: 240, loss: 0.12639747560024261
step: 250, loss: 0.09845457971096039
step: 260, loss: 0.12464915961027145
step: 270, loss: 0.057086460292339325
step: 280, loss: 0.11866138875484467
step: 290, loss: 0.03871142119169235
step: 300, loss: 0.008141891099512577
step: 310, loss: 0.020686129108071327
step: 320, loss: 0.06233414635062218
step: 330, loss: 0.09892203658819199
step: 340, loss: 0.04676187038421631
step: 350, loss: 0.1960221230983734
step: 360, loss: 0.02501589246094227
epoch 13: dev_f1=0.7596899224806202, f1=0.7323232323232323, best_f1=0.7428571428571429
step: 0, loss: 0.05876656994223595
step: 10, loss: 0.11185656487941742
step: 20, loss: 0.10061574727296829
step: 30, loss: 0.14986814558506012
step: 40, loss: 0.12153299897909164
step: 50, loss: 0.015454269014298916
step: 60, loss: 0.0760011225938797
step: 70, loss: 0.02982480265200138
step: 80, loss: 0.0967782661318779
step: 90, loss: 0.059020742774009705
step: 100, loss: 0.03314048796892166
step: 110, loss: 0.04210309311747551
step: 120, loss: 0.019990909844636917
step: 130, loss: 0.04191496968269348
step: 140, loss: 0.017209049314260483
step: 150, loss: 0.021479997783899307
step: 160, loss: 0.11195763200521469
step: 170, loss: 0.047273579984903336
step: 180, loss: 0.0740477591753006
step: 190, loss: 0.02658291719853878
step: 200, loss: 0.04395585507154465
step: 210, loss: 0.09036300331354141
step: 220, loss: 0.015411783941090107
step: 230, loss: 0.04694325476884842
step: 240, loss: 0.04223286360502243
step: 250, loss: 0.01727522537112236
step: 260, loss: 0.026432925835251808
step: 270, loss: 0.022326765581965446
step: 280, loss: 0.029736990109086037
step: 290, loss: 0.028547964990139008
step: 300, loss: 0.024999868124723434
step: 310, loss: 0.004726415500044823
step: 320, loss: 0.0826551765203476
step: 330, loss: 0.00981969852000475
step: 340, loss: 0.009732450358569622
step: 350, loss: 0.04061524197459221
step: 360, loss: 0.03617576137185097
epoch 14: dev_f1=0.7430025445292621, f1=0.7111111111111111, best_f1=0.7428571428571429
step: 0, loss: 0.08528604358434677
step: 10, loss: 0.05519817769527435
step: 20, loss: 0.06816938519477844
step: 30, loss: 0.04578554630279541
step: 40, loss: 0.11856155842542648
step: 50, loss: 0.08644252270460129
step: 60, loss: 0.07929641753435135
step: 70, loss: 0.01271859835833311
step: 80, loss: 0.01532874908298254
step: 90, loss: 5.0045196985593066e-05
step: 100, loss: 0.011725857853889465
step: 110, loss: 0.052207767963409424
step: 120, loss: 0.010425448417663574
step: 130, loss: 0.059974223375320435
step: 140, loss: 0.058224745094776154
step: 150, loss: 0.03298771381378174
step: 160, loss: 0.007075524888932705
step: 170, loss: 0.02688026800751686
step: 180, loss: 0.2797704339027405
step: 190, loss: 0.09937215596437454
step: 200, loss: 0.16845329105854034
step: 210, loss: 0.02939668297767639
step: 220, loss: 0.10813035070896149
step: 230, loss: 0.08009327203035355
step: 240, loss: 0.20793232321739197
step: 250, loss: 0.032707445323467255
step: 260, loss: 0.049784742295742035
step: 270, loss: 0.09379538148641586
step: 280, loss: 0.05425460636615753
step: 290, loss: 0.018876638263463974
step: 300, loss: 0.021690916270017624
step: 310, loss: 0.0838746502995491
step: 320, loss: 0.020651359111070633
step: 330, loss: 0.07262513041496277
step: 340, loss: 0.06750556081533432
step: 350, loss: 0.11842042207717896
step: 360, loss: 0.05243472754955292
epoch 15: dev_f1=0.7202216066481995, f1=0.7002652519893899, best_f1=0.7428571428571429
step: 0, loss: 0.06439941376447678
step: 10, loss: 0.06868644803762436
step: 20, loss: 0.07862275838851929
step: 30, loss: 0.07798462361097336
step: 40, loss: 0.05870529264211655
step: 50, loss: 0.006322403904050589
step: 60, loss: 0.08957602083683014
step: 70, loss: 0.0030793638434261084
step: 80, loss: 0.012561509385704994
step: 90, loss: 0.0009243740933015943
step: 100, loss: 0.01954285055398941
step: 110, loss: 0.00015589340182486922
step: 120, loss: 0.10076653957366943
step: 130, loss: 0.029634684324264526
step: 140, loss: 0.23599651455879211
step: 150, loss: 0.07040737569332123
step: 160, loss: 0.013046612031757832
step: 170, loss: 0.07122692465782166
step: 180, loss: 0.0706632062792778
step: 190, loss: 0.12121490389108658
step: 200, loss: 0.05127210542559624
step: 210, loss: 0.07054120302200317
step: 220, loss: 0.030788203701376915
step: 230, loss: 0.009084971621632576
step: 240, loss: 0.10959986597299576
step: 250, loss: 0.03628425672650337
step: 260, loss: 0.04885009303689003
step: 270, loss: 0.11409120261669159
step: 280, loss: 0.030543949455022812
step: 290, loss: 0.07248739898204803
step: 300, loss: 0.04817333444952965
step: 310, loss: 0.06193288043141365
step: 320, loss: 0.07267827540636063
step: 330, loss: 0.08462125062942505
step: 340, loss: 0.028072688728570938
step: 350, loss: 0.06449141353368759
step: 360, loss: 0.06501194834709167
epoch 16: dev_f1=0.7146529562982005, f1=0.6917293233082706, best_f1=0.7428571428571429
step: 0, loss: 0.030207015573978424
step: 10, loss: 0.09124411642551422
step: 20, loss: 0.03760067746043205
step: 30, loss: 0.020303083583712578
step: 40, loss: 0.10521747171878815
step: 50, loss: 0.0003031384840141982
step: 60, loss: 0.04145805165171623
step: 70, loss: 0.002211947925388813
step: 80, loss: 0.029129717499017715
step: 90, loss: 0.08270740509033203
step: 100, loss: 0.02330475114285946
step: 110, loss: 0.08975362032651901
step: 120, loss: 0.025111902505159378
step: 130, loss: 0.09293351322412491
step: 140, loss: 0.027723044157028198
step: 150, loss: 0.03491421043872833
step: 160, loss: 0.17267479002475739
step: 170, loss: 0.020081283524632454
step: 180, loss: 0.029137207195162773
step: 190, loss: 0.04254494979977608
step: 200, loss: 0.017108598724007607
step: 210, loss: 0.03470255434513092
step: 220, loss: 0.060889892280101776
step: 230, loss: 0.05625041946768761
step: 240, loss: 0.1825731098651886
step: 250, loss: 0.0749051496386528
step: 260, loss: 0.026414262130856514
step: 270, loss: 0.06407859176397324
step: 280, loss: 0.012153067626059055
step: 290, loss: 0.07803581655025482
step: 300, loss: 0.06962995231151581
step: 310, loss: 0.033282261341810226
step: 320, loss: 0.01111131627112627
step: 330, loss: 0.05721096694469452
step: 340, loss: 0.07220261543989182
step: 350, loss: 0.007104500196874142
step: 360, loss: 0.02877057157456875
epoch 17: dev_f1=0.7010309278350515, f1=0.7103274559193955, best_f1=0.7428571428571429
step: 0, loss: 0.08598871529102325
step: 10, loss: 0.0587293766438961
step: 20, loss: 0.026692964136600494
step: 30, loss: 0.00030175887513905764
step: 40, loss: 0.012084410525858402
step: 50, loss: 0.09731530398130417
step: 60, loss: 0.08614052832126617
step: 70, loss: 0.048722781240940094
step: 80, loss: 0.028752993792295456
step: 90, loss: 0.0019342098385095596
step: 100, loss: 0.012784113176167011
step: 110, loss: 0.002681145677343011
step: 120, loss: 0.013559387065470219
step: 130, loss: 0.03848951309919357
step: 140, loss: 0.08007771521806717
step: 150, loss: 0.04339563846588135
step: 160, loss: 0.043311458081007004
step: 170, loss: 0.04462463781237602
step: 180, loss: 0.04978739842772484
step: 190, loss: 0.0007842945633456111
step: 200, loss: 0.008363994769752026
step: 210, loss: 0.06245114654302597
step: 220, loss: 0.04449370875954628
step: 230, loss: 0.04177495092153549
step: 240, loss: 5.0016988097922876e-05
step: 250, loss: 3.245263724238612e-05
step: 260, loss: 0.1239255741238594
step: 270, loss: 0.01219277735799551
step: 280, loss: 0.08211059123277664
step: 290, loss: 0.0875881165266037
step: 300, loss: 0.00011301557970000431
step: 310, loss: 0.06296978145837784
step: 320, loss: 0.01689017191529274
step: 330, loss: 0.09789370000362396
step: 340, loss: 0.00892969686537981
step: 350, loss: 0.025482788681983948
step: 360, loss: 0.0874917209148407
epoch 18: dev_f1=0.7032967032967032, f1=0.6880000000000001, best_f1=0.7428571428571429
step: 0, loss: 0.06005147099494934
step: 10, loss: 0.014929595403373241
step: 20, loss: 0.01737838424742222
step: 30, loss: 0.006342721171677113
step: 40, loss: 0.07233687490224838
step: 50, loss: 0.06553661078214645
step: 60, loss: 0.0008619868312962353
step: 70, loss: 0.01927425153553486
step: 80, loss: 0.02235008217394352
step: 90, loss: 0.02512771263718605
step: 100, loss: 0.04156958684325218
step: 110, loss: 0.09496783465147018
step: 120, loss: 0.049842167645692825
step: 130, loss: 0.049837030470371246
step: 140, loss: 0.09795045107603073
step: 150, loss: 0.009483135305345058
step: 160, loss: 0.02049935609102249
step: 170, loss: 0.012746898457407951
step: 180, loss: 0.020653214305639267
step: 190, loss: 0.06804247945547104
step: 200, loss: 0.057986631989479065
step: 210, loss: 0.019573461264371872
step: 220, loss: 0.018425822257995605
step: 230, loss: 0.011943175457417965
step: 240, loss: 0.036811232566833496
step: 250, loss: 0.03042689710855484
step: 260, loss: 0.1378568857908249
step: 270, loss: 0.03227514401078224
step: 280, loss: 0.03467503935098648
step: 290, loss: 0.016636420041322708
step: 300, loss: 6.970021786401048e-05
step: 310, loss: 0.017774958163499832
step: 320, loss: 0.0740879476070404
step: 330, loss: 0.05669945850968361
step: 340, loss: 0.00033685160451568663
step: 350, loss: 0.03553609177470207
step: 360, loss: 0.12945111095905304
epoch 19: dev_f1=0.6968838526912181, f1=0.6902173913043479, best_f1=0.7428571428571429
step: 0, loss: 0.0006092234398238361
step: 10, loss: 0.10796879231929779
step: 20, loss: 0.009419338777661324
step: 30, loss: 0.03568755462765694
step: 40, loss: 0.03499528765678406
step: 50, loss: 0.011205464601516724
step: 60, loss: 0.06917782127857208
step: 70, loss: 0.1279396265745163
step: 80, loss: 0.04208303987979889
step: 90, loss: 0.03359008580446243
step: 100, loss: 0.01631942018866539
step: 110, loss: 0.13938558101654053
step: 120, loss: 0.019462285563349724
step: 130, loss: 0.017273936420679092
step: 140, loss: 0.01603919081389904
step: 150, loss: 0.013647479936480522
step: 160, loss: 0.0011618873104453087
step: 170, loss: 0.08282284438610077
step: 180, loss: 0.04601909592747688
step: 190, loss: 0.008397375233471394
step: 200, loss: 0.04475134238600731
step: 210, loss: 0.05834926292300224
step: 220, loss: 0.02042510360479355
step: 230, loss: 0.030569061636924744
step: 240, loss: 0.002565377624705434
step: 250, loss: 0.02416907623410225
step: 260, loss: 0.050371550023555756
step: 270, loss: 0.01941215991973877
step: 280, loss: 0.00021050892246421427
step: 290, loss: 0.006660056300461292
step: 300, loss: 0.02623087540268898
step: 310, loss: 0.010955560021102428
step: 320, loss: 0.05231241136789322
step: 330, loss: 0.015594257973134518
step: 340, loss: 0.08361059427261353
step: 350, loss: 0.024476170539855957
step: 360, loss: 0.057454224675893784
epoch 20: dev_f1=0.6983240223463687, f1=0.6863270777479893, best_f1=0.7428571428571429
