cuda
Device: cuda
step: 0, loss: 0.7383354306221008
step: 10, loss: 0.3584865927696228
step: 20, loss: 0.13855576515197754
step: 30, loss: 0.24279583990573883
step: 40, loss: 0.07359854131937027
step: 50, loss: 0.23045116662979126
step: 60, loss: 0.1442396491765976
step: 70, loss: 0.2135891169309616
step: 80, loss: 0.1605263650417328
step: 90, loss: 0.22804827988147736
step: 100, loss: 0.22843138873577118
step: 110, loss: 0.25089526176452637
step: 120, loss: 0.04388444125652313
step: 130, loss: 0.13215678930282593
step: 140, loss: 0.2143758237361908
step: 150, loss: 0.13423646986484528
step: 160, loss: 0.29139697551727295
step: 170, loss: 0.115814208984375
step: 180, loss: 0.025423120707273483
step: 190, loss: 0.05555785819888115
step: 200, loss: 0.2447037696838379
step: 210, loss: 0.28754544258117676
step: 220, loss: 0.2983420789241791
step: 230, loss: 0.1139945238828659
step: 240, loss: 0.11762113124132156
step: 250, loss: 0.3375972509384155
step: 260, loss: 0.29117581248283386
step: 270, loss: 0.14090973138809204
step: 280, loss: 0.08344880491495132
step: 290, loss: 0.30726054310798645
step: 300, loss: 0.32713159918785095
step: 310, loss: 0.039732374250888824
step: 320, loss: 0.015408242121338844
step: 330, loss: 0.2059066891670227
step: 340, loss: 0.1643771529197693
step: 350, loss: 0.0717485100030899
step: 360, loss: 0.14846093952655792
epoch 1: dev_f1=0.5707196029776674, f1=0.5402843601895735, best_f1=0.5402843601895735
step: 0, loss: 0.26974552869796753
step: 10, loss: 0.2179294228553772
step: 20, loss: 0.13744108378887177
step: 30, loss: 0.11724045872688293
step: 40, loss: 0.1462954878807068
step: 50, loss: 0.017435062676668167
step: 60, loss: 0.09529456496238708
step: 70, loss: 0.14694879949092865
step: 80, loss: 0.2663707137107849
step: 90, loss: 0.12654271721839905
step: 100, loss: 0.12858547270298004
step: 110, loss: 0.25685790181159973
step: 120, loss: 0.015096941031515598
step: 130, loss: 0.05889776721596718
step: 140, loss: 0.11265408992767334
step: 150, loss: 0.1313500553369522
step: 160, loss: 0.05147508159279823
step: 170, loss: 0.06643427163362503
step: 180, loss: 0.21978087723255157
step: 190, loss: 0.08271514624357224
step: 200, loss: 0.38745275139808655
step: 210, loss: 0.09717287868261337
step: 220, loss: 0.07345025986433029
step: 230, loss: 0.2668014466762543
step: 240, loss: 0.027182932943105698
step: 250, loss: 0.06566551327705383
step: 260, loss: 0.05803500488400459
step: 270, loss: 0.18996590375900269
step: 280, loss: 0.07961788773536682
step: 290, loss: 0.06684990972280502
step: 300, loss: 0.15617066621780396
step: 310, loss: 0.01959555596113205
step: 320, loss: 0.28034108877182007
step: 330, loss: 0.267671674489975
step: 340, loss: 0.027190586552023888
step: 350, loss: 0.1409653276205063
step: 360, loss: 0.07948455214500427
epoch 2: dev_f1=0.7146282973621103, f1=0.7070217917675545, best_f1=0.7070217917675545
step: 0, loss: 0.057525940239429474
step: 10, loss: 0.2131168395280838
step: 20, loss: 0.12266483902931213
step: 30, loss: 0.07827600836753845
step: 40, loss: 0.1027299091219902
step: 50, loss: 0.02107313461601734
step: 60, loss: 0.12795135378837585
step: 70, loss: 0.06951200217008591
step: 80, loss: 0.13709966838359833
step: 90, loss: 0.13315491378307343
step: 100, loss: 0.11892352253198624
step: 110, loss: 0.06988115608692169
step: 120, loss: 0.16138550639152527
step: 130, loss: 0.019148902967572212
step: 140, loss: 0.1655992865562439
step: 150, loss: 0.021177371963858604
step: 160, loss: 0.04112496227025986
step: 170, loss: 0.030031105503439903
step: 180, loss: 0.12193356454372406
step: 190, loss: 0.07463771104812622
step: 200, loss: 0.2333889901638031
step: 210, loss: 0.07392323017120361
step: 220, loss: 0.1939048171043396
step: 230, loss: 0.05768764764070511
step: 240, loss: 0.05862513929605484
step: 250, loss: 0.12056601047515869
step: 260, loss: 0.1925332397222519
step: 270, loss: 0.2999388873577118
step: 280, loss: 0.1319945901632309
step: 290, loss: 0.22754400968551636
step: 300, loss: 0.21934768557548523
step: 310, loss: 0.04798343405127525
step: 320, loss: 0.1752113252878189
step: 330, loss: 0.06595201790332794
step: 340, loss: 0.04850499704480171
step: 350, loss: 0.13924407958984375
step: 360, loss: 0.20458658039569855
epoch 3: dev_f1=0.7374005305039788, f1=0.7253333333333334, best_f1=0.7253333333333334
step: 0, loss: 0.14630988240242004
step: 10, loss: 0.13273575901985168
step: 20, loss: 0.13947544991970062
step: 30, loss: 0.14761757850646973
step: 40, loss: 0.1195870041847229
step: 50, loss: 0.061794500797986984
step: 60, loss: 0.1322150081396103
step: 70, loss: 0.11914506554603577
step: 80, loss: 0.03039064072072506
step: 90, loss: 0.054065387696027756
step: 100, loss: 0.2724607586860657
step: 110, loss: 0.054795924574136734
step: 120, loss: 0.12984596192836761
step: 130, loss: 0.17120243608951569
step: 140, loss: 0.06195859983563423
step: 150, loss: 0.21212680637836456
step: 160, loss: 0.1319696605205536
step: 170, loss: 0.16726334393024445
step: 180, loss: 0.14439214766025543
step: 190, loss: 0.08444200456142426
step: 200, loss: 0.20464706420898438
step: 210, loss: 0.1544993668794632
step: 220, loss: 0.23389586806297302
step: 230, loss: 0.07142634689807892
step: 240, loss: 0.03814111277461052
step: 250, loss: 0.3889354169368744
step: 260, loss: 0.08890686929225922
step: 270, loss: 0.06982576847076416
step: 280, loss: 0.12727166712284088
step: 290, loss: 0.05833671614527702
step: 300, loss: 0.08906102925539017
step: 310, loss: 0.061879243701696396
step: 320, loss: 0.1911412626504898
step: 330, loss: 0.25336357951164246
step: 340, loss: 0.06593257188796997
step: 350, loss: 0.12970209121704102
step: 360, loss: 0.06076531484723091
epoch 4: dev_f1=0.7180722891566265, f1=0.7241379310344828, best_f1=0.7253333333333334
step: 0, loss: 0.2116556167602539
step: 10, loss: 0.04028492048382759
step: 20, loss: 0.15257763862609863
step: 30, loss: 0.020425576716661453
step: 40, loss: 0.051639147102832794
step: 50, loss: 0.09782472997903824
step: 60, loss: 0.19599047303199768
step: 70, loss: 0.10274121910333633
step: 80, loss: 0.07178173214197159
step: 90, loss: 0.09371629357337952
step: 100, loss: 0.0811595469713211
step: 110, loss: 0.05248922109603882
step: 120, loss: 0.11556324362754822
step: 130, loss: 0.0004297870909795165
step: 140, loss: 0.01591879315674305
step: 150, loss: 0.08268740773200989
step: 160, loss: 0.08360555768013
step: 170, loss: 0.03396516293287277
step: 180, loss: 0.06891196221113205
step: 190, loss: 0.020723190158605576
step: 200, loss: 0.07280925661325455
step: 210, loss: 0.10225038230419159
step: 220, loss: 0.04220437631011009
step: 230, loss: 0.1175156980752945
step: 240, loss: 0.06614464521408081
step: 250, loss: 0.22495312988758087
step: 260, loss: 0.04365159198641777
step: 270, loss: 0.047468796372413635
step: 280, loss: 0.09286149591207504
step: 290, loss: 0.028637921437621117
step: 300, loss: 0.08805980533361435
step: 310, loss: 0.01830286532640457
step: 320, loss: 0.10975838452577591
step: 330, loss: 0.2112693339586258
step: 340, loss: 0.17950360476970673
step: 350, loss: 0.0931762158870697
step: 360, loss: 0.07781657576560974
epoch 5: dev_f1=0.7348066298342542, f1=0.7048710601719199, best_f1=0.7253333333333334
step: 0, loss: 0.05133001133799553
step: 10, loss: 0.06531326472759247
step: 20, loss: 0.08224107325077057
step: 30, loss: 0.08800812065601349
step: 40, loss: 0.18603084981441498
step: 50, loss: 0.1478237360715866
step: 60, loss: 0.08772352337837219
step: 70, loss: 0.051189664751291275
step: 80, loss: 0.051960986107587814
step: 90, loss: 0.10982704907655716
step: 100, loss: 0.1015128567814827
step: 110, loss: 0.07632210850715637
step: 120, loss: 0.04921092838048935
step: 130, loss: 0.16518069803714752
step: 140, loss: 0.10702140629291534
step: 150, loss: 0.09497533738613129
step: 160, loss: 0.13285502791404724
step: 170, loss: 0.1392386108636856
step: 180, loss: 0.09857770055532455
step: 190, loss: 0.021275075152516365
step: 200, loss: 0.01022582408040762
step: 210, loss: 0.025363732129335403
step: 220, loss: 0.13326819241046906
step: 230, loss: 0.06060505658388138
step: 240, loss: 0.11482464522123337
step: 250, loss: 0.11941054463386536
step: 260, loss: 0.054582640528678894
step: 270, loss: 0.07291305810213089
step: 280, loss: 0.03212588280439377
step: 290, loss: 0.09055639803409576
step: 300, loss: 0.10038000345230103
step: 310, loss: 0.20814628899097443
step: 320, loss: 0.153153657913208
step: 330, loss: 0.1495332270860672
step: 340, loss: 0.04149675741791725
step: 350, loss: 0.07343567907810211
step: 360, loss: 0.06906048208475113
epoch 6: dev_f1=0.7506426735218509, f1=0.7329842931937172, best_f1=0.7329842931937172
step: 0, loss: 0.07214004546403885
step: 10, loss: 0.04511290416121483
step: 20, loss: 0.046584632247686386
step: 30, loss: 0.045151110738515854
step: 40, loss: 0.08971816301345825
step: 50, loss: 0.09461122006177902
step: 60, loss: 0.10027140378952026
step: 70, loss: 0.0016257533570751548
step: 80, loss: 0.13100410997867584
step: 90, loss: 0.0693032369017601
step: 100, loss: 0.12968425452709198
step: 110, loss: 0.019474567845463753
step: 120, loss: 0.0047853607684373856
step: 130, loss: 0.06347984075546265
step: 140, loss: 0.030764009803533554
step: 150, loss: 0.08457774668931961
step: 160, loss: 0.145234614610672
step: 170, loss: 0.15514647960662842
step: 180, loss: 0.017853083088994026
step: 190, loss: 0.0869465246796608
step: 200, loss: 0.03810938820242882
step: 210, loss: 0.043433498591184616
step: 220, loss: 0.061664607375860214
step: 230, loss: 0.11941000074148178
step: 240, loss: 0.10551745444536209
step: 250, loss: 0.07372302561998367
step: 260, loss: 0.06599266082048416
step: 270, loss: 0.12796412408351898
step: 280, loss: 0.0510677807033062
step: 290, loss: 0.03703446686267853
step: 300, loss: 0.0953727662563324
step: 310, loss: 0.12304471433162689
step: 320, loss: 0.006448093336075544
step: 330, loss: 0.12301468849182129
step: 340, loss: 0.10831401497125626
step: 350, loss: 0.32903754711151123
step: 360, loss: 0.002451439155265689
epoch 7: dev_f1=0.7506053268765133, f1=0.7414634146341464, best_f1=0.7329842931937172
step: 0, loss: 0.07187047600746155
step: 10, loss: 0.053602173924446106
step: 20, loss: 0.02585998736321926
step: 30, loss: 0.06359532475471497
step: 40, loss: 0.10395011305809021
step: 50, loss: 0.0605471096932888
step: 60, loss: 0.06825517863035202
step: 70, loss: 0.13280507922172546
step: 80, loss: 0.07062522321939468
step: 90, loss: 0.06591004133224487
step: 100, loss: 0.10958357155323029
step: 110, loss: 0.07924825698137283
step: 120, loss: 0.08658691495656967
step: 130, loss: 0.11338991671800613
step: 140, loss: 0.017115047201514244
step: 150, loss: 0.15048855543136597
step: 160, loss: 0.09618057310581207
step: 170, loss: 0.0812963992357254
step: 180, loss: 0.05603789910674095
step: 190, loss: 0.06921518594026566
step: 200, loss: 0.04259958490729332
step: 210, loss: 0.020117906853556633
step: 220, loss: 0.03915981948375702
step: 230, loss: 0.017944155260920525
step: 240, loss: 0.07712212204933167
step: 250, loss: 0.10007230937480927
step: 260, loss: 0.02747533656656742
step: 270, loss: 0.026824822649359703
step: 280, loss: 0.03652782365679741
step: 290, loss: 0.07563717663288116
step: 300, loss: 0.01970857009291649
step: 310, loss: 0.041854992508888245
step: 320, loss: 0.08435172587633133
step: 330, loss: 0.03121989592909813
step: 340, loss: 0.03982367366552353
step: 350, loss: 0.07090821117162704
step: 360, loss: 0.10230085253715515
epoch 8: dev_f1=0.7403598971722366, f1=0.745945945945946, best_f1=0.7329842931937172
step: 0, loss: 0.05387340858578682
step: 10, loss: 0.11378350108861923
step: 20, loss: 0.03941495716571808
step: 30, loss: 0.02199910581111908
step: 40, loss: 0.15309080481529236
step: 50, loss: 0.05370118096470833
step: 60, loss: 0.06256414949893951
step: 70, loss: 0.0603925958275795
step: 80, loss: 0.07502888888120651
step: 90, loss: 0.08140499144792557
step: 100, loss: 0.06597310304641724
step: 110, loss: 0.11255050450563431
step: 120, loss: 0.04764120653271675
step: 130, loss: 0.10147299617528915
step: 140, loss: 0.05853140354156494
step: 150, loss: 0.09819313138723373
step: 160, loss: 0.041617583483457565
step: 170, loss: 0.12056072801351547
step: 180, loss: 0.0006039715372025967
step: 190, loss: 0.00034637132193893194
step: 200, loss: 0.049413591623306274
step: 210, loss: 0.01854410395026207
step: 220, loss: 0.05994696542620659
step: 230, loss: 0.034930869936943054
step: 240, loss: 0.023935144767165184
step: 250, loss: 0.031904254108667374
step: 260, loss: 0.024833839386701584
step: 270, loss: 0.1649617701768875
step: 280, loss: 0.07881849259138107
step: 290, loss: 0.06936746090650558
step: 300, loss: 0.03546702116727829
step: 310, loss: 0.08053677529096603
step: 320, loss: 0.06249774247407913
step: 330, loss: 0.04633332043886185
step: 340, loss: 0.019802935421466827
step: 350, loss: 0.06804361194372177
step: 360, loss: 0.12179415673017502
epoch 9: dev_f1=0.7272727272727272, f1=0.7117794486215538, best_f1=0.7329842931937172
step: 0, loss: 0.0353829562664032
step: 10, loss: 0.08607460558414459
step: 20, loss: 0.05107482150197029
step: 30, loss: 0.10231835395097733
step: 40, loss: 0.06403541564941406
step: 50, loss: 0.090366430580616
step: 60, loss: 0.05347868800163269
step: 70, loss: 0.14503714442253113
step: 80, loss: 0.1349305510520935
step: 90, loss: 0.04514387622475624
step: 100, loss: 0.09229210019111633
step: 110, loss: 0.08696983009576797
step: 120, loss: 0.02386832796037197
step: 130, loss: 0.08389945328235626
step: 140, loss: 0.09094468504190445
step: 150, loss: 0.12630386650562286
step: 160, loss: 0.07350796461105347
step: 170, loss: 0.011398122645914555
step: 180, loss: 0.021056372672319412
step: 190, loss: 0.17408765852451324
step: 200, loss: 0.06672941148281097
step: 210, loss: 0.00023944795248098671
step: 220, loss: 0.048676807433366776
step: 230, loss: 0.013012961484491825
step: 240, loss: 0.073316290974617
step: 250, loss: 0.03588113933801651
step: 260, loss: 0.03621425852179527
step: 270, loss: 0.11119995266199112
step: 280, loss: 0.08362773060798645
step: 290, loss: 0.027956904843449593
step: 300, loss: 0.021944552659988403
step: 310, loss: 0.12073707580566406
step: 320, loss: 0.08842889964580536
step: 330, loss: 0.06718246638774872
step: 340, loss: 0.0005792999290861189
step: 350, loss: 4.862323112320155e-05
step: 360, loss: 0.06262647360563278
epoch 10: dev_f1=0.7506702412868632, f1=0.7338935574229692, best_f1=0.7338935574229692
step: 0, loss: 0.15467402338981628
step: 10, loss: 0.17902737855911255
step: 20, loss: 0.07084883749485016
step: 30, loss: 0.04798784852027893
step: 40, loss: 0.016239333897829056
step: 50, loss: 0.08742759376764297
step: 60, loss: 0.04125957190990448
step: 70, loss: 0.05281262472271919
step: 80, loss: 0.017310263589024544
step: 90, loss: 0.024029910564422607
step: 100, loss: 0.09092596173286438
step: 110, loss: 0.011280511505901814
step: 120, loss: 0.07678095251321793
step: 130, loss: 0.06662395596504211
step: 140, loss: 0.1035369485616684
step: 150, loss: 0.09459008276462555
step: 160, loss: 0.06423423439264297
step: 170, loss: 0.025749916210770607
step: 180, loss: 0.15454509854316711
step: 190, loss: 0.0682026669383049
step: 200, loss: 0.014731079339981079
step: 210, loss: 0.044685911387205124
step: 220, loss: 0.032469794154167175
step: 230, loss: 0.09506337344646454
step: 240, loss: 0.04813214763998985
step: 250, loss: 0.0297770444303751
step: 260, loss: 0.056094273924827576
step: 270, loss: 0.05241502821445465
step: 280, loss: 0.06346852332353592
step: 290, loss: 0.06456364691257477
step: 300, loss: 0.08140431344509125
step: 310, loss: 0.08317404240369797
step: 320, loss: 0.008259503170847893
step: 330, loss: 0.04918147623538971
step: 340, loss: 0.11738017201423645
step: 350, loss: 0.10510947555303574
step: 360, loss: 0.07170562446117401
epoch 11: dev_f1=0.7565011820330969, f1=0.7475728155339805, best_f1=0.7475728155339805
step: 0, loss: 0.06360556930303574
step: 10, loss: 0.10928067564964294
step: 20, loss: 0.05305787920951843
step: 30, loss: 0.059091467410326004
step: 40, loss: 0.030498770996928215
step: 50, loss: 7.679939881199971e-05
step: 60, loss: 0.011202676221728325
step: 70, loss: 0.1101514920592308
step: 80, loss: 0.06517373770475388
step: 90, loss: 0.02523237280547619
step: 100, loss: 0.0657847598195076
step: 110, loss: 0.10056565701961517
step: 120, loss: 0.03462203964591026
step: 130, loss: 0.05988115444779396
step: 140, loss: 0.023512668907642365
step: 150, loss: 0.07104653120040894
step: 160, loss: 0.03441112861037254
step: 170, loss: 0.03945460543036461
step: 180, loss: 0.047493066638708115
step: 190, loss: 0.06684187054634094
step: 200, loss: 0.1338065266609192
step: 210, loss: 0.013174956664443016
step: 220, loss: 7.685553282499313e-05
step: 230, loss: 0.07766890525817871
step: 240, loss: 0.012286423705518246
step: 250, loss: 0.043966472148895264
step: 260, loss: 0.07114661484956741
step: 270, loss: 0.14860795438289642
step: 280, loss: 0.06869196146726608
step: 290, loss: 0.029091356322169304
step: 300, loss: 0.029950983822345734
step: 310, loss: 0.026369407773017883
step: 320, loss: 0.07529444247484207
step: 330, loss: 0.04903755336999893
step: 340, loss: 0.060488417744636536
step: 350, loss: 0.0740138441324234
step: 360, loss: 0.10102701187133789
epoch 12: dev_f1=0.7710843373493975, f1=0.7405541561712846, best_f1=0.7405541561712846
step: 0, loss: 0.04959418252110481
step: 10, loss: 0.04042483866214752
step: 20, loss: 0.0002943449071608484
step: 30, loss: 0.05715271458029747
step: 40, loss: 0.018481776118278503
step: 50, loss: 0.03610214963555336
step: 60, loss: 0.015882421284914017
step: 70, loss: 0.039705708622932434
step: 80, loss: 0.07745172083377838
step: 90, loss: 0.035751823335886
step: 100, loss: 0.04652545601129532
step: 110, loss: 0.06416267156600952
step: 120, loss: 0.02780430018901825
step: 130, loss: 0.023505231365561485
step: 140, loss: 0.023666050285100937
step: 150, loss: 0.03767203539609909
step: 160, loss: 0.04359903559088707
step: 170, loss: 0.04169034585356712
step: 180, loss: 0.0355246365070343
step: 190, loss: 0.08269299566745758
step: 200, loss: 0.03799652308225632
step: 210, loss: 0.005088589619845152
step: 220, loss: 0.035036154091358185
step: 230, loss: 0.015263576991856098
step: 240, loss: 0.01650850847363472
step: 250, loss: 0.01690884493291378
step: 260, loss: 0.007644155528396368
step: 270, loss: 0.06994307041168213
step: 280, loss: 0.11237122863531113
step: 290, loss: 0.024961750954389572
step: 300, loss: 0.029846839606761932
step: 310, loss: 0.05133608728647232
step: 320, loss: 0.04324773699045181
step: 330, loss: 0.00963910948485136
step: 340, loss: 0.07420837879180908
step: 350, loss: 0.10696514695882797
step: 360, loss: 0.03109039179980755
epoch 13: dev_f1=0.7500000000000001, f1=0.7225130890052356, best_f1=0.7405541561712846
step: 0, loss: 0.004081627819687128
step: 10, loss: 0.041469089686870575
step: 20, loss: 0.03425990045070648
step: 30, loss: 0.0032576993107795715
step: 40, loss: 0.08975537121295929
step: 50, loss: 0.021582070738077164
step: 60, loss: 0.06396724283695221
step: 70, loss: 0.0656919777393341
step: 80, loss: 0.10739841312170029
step: 90, loss: 0.029084814712405205
step: 100, loss: 0.06132135167717934
step: 110, loss: 0.07649209350347519
step: 120, loss: 0.05925115942955017
step: 130, loss: 0.027091940864920616
step: 140, loss: 0.1448519229888916
step: 150, loss: 0.035150766372680664
step: 160, loss: 0.0966152548789978
step: 170, loss: 0.012544420547783375
step: 180, loss: 0.056690312922000885
step: 190, loss: 0.0864778533577919
step: 200, loss: 0.06346503645181656
step: 210, loss: 0.008072147145867348
step: 220, loss: 0.019733767956495285
step: 230, loss: 0.06345862150192261
step: 240, loss: 0.01026288140565157
step: 250, loss: 0.05914955213665962
step: 260, loss: 0.08942259848117828
step: 270, loss: 0.05449490249156952
step: 280, loss: 0.15544414520263672
step: 290, loss: 0.007362663745880127
step: 300, loss: 0.042897697538137436
step: 310, loss: 0.08978183567523956
step: 320, loss: 0.074160136282444
step: 330, loss: 0.061327818781137466
step: 340, loss: 0.06203429773449898
step: 350, loss: 0.03117690421640873
step: 360, loss: 0.08087138086557388
epoch 14: dev_f1=0.7393617021276595, f1=0.7186629526462396, best_f1=0.7405541561712846
step: 0, loss: 0.05103933811187744
step: 10, loss: 0.03611235320568085
step: 20, loss: 0.032000500708818436
step: 30, loss: 0.06612303853034973
step: 40, loss: 0.030345596373081207
step: 50, loss: 0.09159154444932938
step: 60, loss: 0.0036079739220440388
step: 70, loss: 0.0052648489363491535
step: 80, loss: 0.06430677324533463
step: 90, loss: 0.035895880311727524
step: 100, loss: 0.05507291480898857
step: 110, loss: 0.058087632060050964
step: 120, loss: 0.015411770902574062
step: 130, loss: 0.015880553051829338
step: 140, loss: 0.03184613585472107
step: 150, loss: 0.08427491039037704
step: 160, loss: 0.020466629415750504
step: 170, loss: 0.0660790205001831
step: 180, loss: 0.08633296936750412
step: 190, loss: 0.1125376895070076
step: 200, loss: 0.06875409185886383
step: 210, loss: 0.02381606213748455
step: 220, loss: 0.08711062371730804
step: 230, loss: 0.07185317575931549
step: 240, loss: 0.11773648858070374
step: 250, loss: 0.02297813817858696
step: 260, loss: 0.018893446773290634
step: 270, loss: 0.03462030738592148
step: 280, loss: 0.0036543041933327913
step: 290, loss: 0.07144290953874588
step: 300, loss: 0.028092680498957634
step: 310, loss: 0.032717280089855194
step: 320, loss: 0.0014153528027236462
step: 330, loss: 0.04579959437251091
step: 340, loss: 0.03381999209523201
step: 350, loss: 0.028726613149046898
step: 360, loss: 0.04996643587946892
epoch 15: dev_f1=0.7272727272727273, f1=0.7109974424552431, best_f1=0.7405541561712846
step: 0, loss: 0.055208757519721985
step: 10, loss: 0.0072867413982748985
step: 20, loss: 0.034557510167360306
step: 30, loss: 0.0184602290391922
step: 40, loss: 2.2951089704292826e-05
step: 50, loss: 0.00018440218991599977
step: 60, loss: 0.009549183771014214
step: 70, loss: 0.09102509915828705
step: 80, loss: 0.020326858386397362
step: 90, loss: 0.03728896379470825
step: 100, loss: 0.12477827817201614
step: 110, loss: 0.02327541448175907
step: 120, loss: 0.028231604024767876
step: 130, loss: 0.030767953023314476
step: 140, loss: 0.04818590730428696
step: 150, loss: 0.1031552106142044
step: 160, loss: 0.013269252143800259
step: 170, loss: 0.03885006532073021
step: 180, loss: 0.0027455491945147514
step: 190, loss: 0.12109241634607315
step: 200, loss: 0.02839651331305504
step: 210, loss: 0.05991754308342934
step: 220, loss: 0.11049108952283859
step: 230, loss: 0.09628507494926453
step: 240, loss: 0.09670079499483109
step: 250, loss: 0.031934842467308044
step: 260, loss: 0.016453219577670097
step: 270, loss: 0.03249278664588928
step: 280, loss: 0.05883374437689781
step: 290, loss: 0.06446973234415054
step: 300, loss: 0.044219281524419785
step: 310, loss: 0.002006599446758628
step: 320, loss: 0.019688166677951813
step: 330, loss: 0.050319068133831024
step: 340, loss: 0.0549883209168911
step: 350, loss: 0.06628525257110596
step: 360, loss: 0.03808706998825073
epoch 16: dev_f1=0.720626631853786, f1=0.7204301075268816, best_f1=0.7405541561712846
step: 0, loss: 0.054124459624290466
step: 10, loss: 0.04273885115981102
step: 20, loss: 0.051243122667074203
step: 30, loss: 0.03127698227763176
step: 40, loss: 0.019596409052610397
step: 50, loss: 2.2500242266687565e-05
step: 60, loss: 0.045152273029088974
step: 70, loss: 0.06835568696260452
step: 80, loss: 0.09070136398077011
step: 90, loss: 0.1427580565214157
step: 100, loss: 0.005160895176231861
step: 110, loss: 0.002688787644729018
step: 120, loss: 0.007774976547807455
step: 130, loss: 0.10323520749807358
step: 140, loss: 0.05337652936577797
step: 150, loss: 0.04301367700099945
step: 160, loss: 0.05892288312315941
step: 170, loss: 0.0139815304428339
step: 180, loss: 0.0962090864777565
step: 190, loss: 0.006635567173361778
step: 200, loss: 0.0076836515218019485
step: 210, loss: 0.07812158763408661
step: 220, loss: 0.04688194394111633
step: 230, loss: 0.04958232864737511
step: 240, loss: 0.08796185255050659
step: 250, loss: 0.016201021149754524
step: 260, loss: 0.023095499724149704
step: 270, loss: 0.041763827204704285
step: 280, loss: 5.815595432068221e-05
step: 290, loss: 0.05686337500810623
step: 300, loss: 0.01693306304514408
step: 310, loss: 0.006973278243094683
step: 320, loss: 0.031388621777296066
step: 330, loss: 0.011408217251300812
step: 340, loss: 0.02122555486857891
step: 350, loss: 6.835866224719211e-05
step: 360, loss: 0.04697994515299797
epoch 17: dev_f1=0.7310704960835509, f1=0.7029972752043598, best_f1=0.7405541561712846
step: 0, loss: 0.055854734033346176
step: 10, loss: 0.028811410069465637
step: 20, loss: 0.03744148090481758
step: 30, loss: 0.04039021581411362
step: 40, loss: 0.005741798784583807
step: 50, loss: 0.0010236888192594051
step: 60, loss: 0.05925625562667847
step: 70, loss: 0.029158519580960274
step: 80, loss: 0.07526858896017075
step: 90, loss: 0.019796686246991158
step: 100, loss: 0.0006217629415914416
step: 110, loss: 0.043679576367139816
step: 120, loss: 0.004274451173841953
step: 130, loss: 0.013796781189739704
step: 140, loss: 0.00020510060130618513
step: 150, loss: 0.05500175431370735
step: 160, loss: 0.04755856841802597
step: 170, loss: 0.020171957090497017
step: 180, loss: 0.01658506877720356
step: 190, loss: 0.03506612032651901
step: 200, loss: 0.003920278046280146
step: 210, loss: 0.025812828913331032
step: 220, loss: 0.02738364040851593
step: 230, loss: 0.028556590899825096
step: 240, loss: 0.0017243564361706376
step: 250, loss: 0.01658097840845585
step: 260, loss: 0.010849451646208763
step: 270, loss: 0.01136518083512783
step: 280, loss: 0.05314958468079567
step: 290, loss: 0.007162394467741251
step: 300, loss: 0.08345430344343185
step: 310, loss: 0.03929944336414337
step: 320, loss: 0.0543443039059639
step: 330, loss: 0.08517954498529434
step: 340, loss: 0.029400428757071495
step: 350, loss: 0.0202981848269701
step: 360, loss: 0.07423844933509827
epoch 18: dev_f1=0.7333333333333334, f1=0.7157894736842104, best_f1=0.7405541561712846
step: 0, loss: 0.005647944752126932
step: 10, loss: 0.06973031163215637
step: 20, loss: 0.01804661750793457
step: 30, loss: 0.00349768390879035
step: 40, loss: 0.07387051731348038
step: 50, loss: 0.01196978334337473
step: 60, loss: 0.08150073885917664
step: 70, loss: 0.01539446972310543
step: 80, loss: 0.06926878541707993
step: 90, loss: 0.04899312183260918
step: 100, loss: 0.008312433958053589
step: 110, loss: 0.0461832731962204
step: 120, loss: 0.05128185823559761
step: 130, loss: 0.014566244557499886
step: 140, loss: 0.029464922845363617
step: 150, loss: 0.01856025494635105
step: 160, loss: 0.07115005701780319
step: 170, loss: 0.0376453623175621
step: 180, loss: 0.02353338710963726
step: 190, loss: 0.1365150362253189
step: 200, loss: 0.041570935398340225
step: 210, loss: 0.00238779210485518
step: 220, loss: 0.036759231239557266
step: 230, loss: 0.0419023297727108
step: 240, loss: 0.024012666195631027
step: 250, loss: 0.07109638303518295
step: 260, loss: 0.043874144554138184
step: 270, loss: 0.11197080463171005
step: 280, loss: 0.067908376455307
step: 290, loss: 0.00038137586670927703
step: 300, loss: 0.028845543041825294
step: 310, loss: 0.08159040659666061
step: 320, loss: 0.09440761804580688
step: 330, loss: 0.03845624253153801
step: 340, loss: 0.03892666473984718
step: 350, loss: 0.08999164402484894
step: 360, loss: 0.031801797449588776
epoch 19: dev_f1=0.7391304347826086, f1=0.7206703910614525, best_f1=0.7405541561712846
step: 0, loss: 0.013414188288152218
step: 10, loss: 0.008056804537773132
step: 20, loss: 0.019807185977697372
step: 30, loss: 2.0231685994076543e-05
step: 40, loss: 2.6645428079064004e-05
step: 50, loss: 0.00201944587752223
step: 60, loss: 0.0638878121972084
step: 70, loss: 0.004199292976409197
step: 80, loss: 0.044537149369716644
step: 90, loss: 0.00835525430738926
step: 100, loss: 0.022393962368369102
step: 110, loss: 0.01122752670198679
step: 120, loss: 0.0005498119280673563
step: 130, loss: 0.03677010536193848
step: 140, loss: 0.04834621772170067
step: 150, loss: 0.031275663524866104
step: 160, loss: 5.3768479119753465e-05
step: 170, loss: 0.004597244784235954
step: 180, loss: 0.008842376992106438
step: 190, loss: 0.21966417133808136
step: 200, loss: 0.06474846601486206
step: 210, loss: 0.0021142452023923397
step: 220, loss: 0.003480116603896022
step: 230, loss: 0.0006678124191239476
step: 240, loss: 0.030439414083957672
step: 250, loss: 3.2010135328164324e-05
step: 260, loss: 0.010210624895989895
step: 270, loss: 2.0913488697260618e-05
step: 280, loss: 0.021778587251901627
step: 290, loss: 0.03947755694389343
step: 300, loss: 0.013240850530564785
step: 310, loss: 0.00847521424293518
step: 320, loss: 0.049736566841602325
step: 330, loss: 0.0005821791710332036
step: 340, loss: 0.01834247261285782
step: 350, loss: 2.7237741960561834e-05
step: 360, loss: 0.014711905270814896
epoch 20: dev_f1=0.7371273712737126, f1=0.7134831460674158, best_f1=0.7405541561712846
